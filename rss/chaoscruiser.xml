<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="css/feed.xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/" xmlns:og="http://ogp.me/ns#">
<channel>
<atom:link rel="self" href="http://192.168.1.4/fivefilters/makefulltextfeed.php?url=feed43.com%2Fchaoscruiser-jtks.xml&amp;max=5&amp;links=preserve&amp;exc=1" />
<atom:link rel="alternate" title="Source URL" href="http://feed43.com/chaoscruiser-jtks.xml" />
<atom:link rel="related" title="Subscribe to feed" href="http://www.subtome.com/#/subscribe?feeds=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed43.com%252Fchaoscruiser-jtks.xml%26max%3D5%26links%3Dpreserve%26exc%3D1&amp;back=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed43.com%252Fchaoscruiser-jtks.xml%26max%3D5%26links%3Dpreserve%26exc%3D1" />
<title>混沌巡洋舰</title>
<link>http://www.jintiankansha.me/column/ultiWL8Axg</link>
<description>混沌巡洋舰 - 今天看啥</description>
<ttl>360</ttl>
<item>
<title>基于一张规则表的人工智能</title>
<link>http://www.jintiankansha.me/t/q56XOgLetH</link>
<guid isPermaLink="true" >http://www.jintiankansha.me/t/q56XOgLetH</guid>
<description>&lt;p&gt;&lt;span data-offset-key=&quot;4ds8l-0-0&quot;&gt;我在过去对人工智能简史的描述中，把人工智能的整个历史描述成围绕一张规则表， 本文是基于这一想法的总结和扩展。我们说， 早期的AI发展史围绕如何人为构建这样一个规则表解决复杂问题， 而当下的AI则围绕如何让它在复杂的现象中自己归纳出这个规则表&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;bkglj-0-0&quot;&gt;我们说， 上帝通过制定规则从简单演绎出复杂。最初的原始人类在黑暗中摸索， 在众多的现象不知所措， 只能通过设立各色大神小神来缓解自己对不确定性的恐惧。 从多神宗教到一神宗教的跨度体现了一个从复杂中寻找简单的跨度， 这可能是基于一种隐隐的直觉，就是现象虽然多样， 但是背后的法则不应该如此复杂。 到了科学的时代， 这种思维在物理学里淋漓尽致起来，四大力学， 把分子原子间的作用力统一到电磁力， 把宏观物体的作用统一到引力和经典的动力方程， 已经是极致， 而后面的对这两者的统一构成了从相对论到杨米尔场的现代物理主线。  &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.5625&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibccd3W2SkazpguaDUmf1EWibibembXL81evOfRdy0cTz2qqulnss6iaFGmXLmdjuRu9GiayK86XIM1TVSg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;640&quot; /&gt;&lt;/p&gt;
&lt;p&gt;图: 简单规则生成复杂的极好例子， 元胞自动机， 每一步细胞的繁殖和阔算方法一定， 它最后形成的图案就定了， 规则可以很简单， 图案可以很复杂。 &lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;c1j7g-0-0&quot;&gt;另一方面， 这样的思想从智能科学诞生之出，也贯穿出来。 它在早期的可计算性中， 通过图灵机的构建。它认为存在这样的通用机器，能够和人类一样解决问题， 即使过程非常复杂， 你无非需要四个要素： 1， 输入 2， 中间状态 3， 规则表 4， 输出 并在时间上进行大量迭代， 就可以实现这个过程。 通过这个过程， 我们可以把一个输入转化为一个想要的输出。 如果我们能够在在有限的步骤里将一个输入转化为一个输出，据此解决一个实际问题， 那么这个问题就是可计算的。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.6114081996434938&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibccd3W2SkazpguaDUmf1EWibibBnC8zkibScsiccAOwoSH4Ld9vdiamljakNVOX5TKF69ywm3Qq2ic3IdhUw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;561&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;c00nl-0-0&quot;&gt;而冯诺依架构让它变成一个技术现实。 它通过可以存储程序的机器， 让人们通过把这些图灵规则表的指令变为计算机二极管的开合代码， 而让图灵纸袋的思想成为了一个每个工程师可以设计的现实。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;176de-0-0&quot;&gt;一个计算机程序， 最基本的部分包括一些简单的形式逻辑， 包括逻辑与或非， if else， for 循环这些。 其实本质上， if else 所描述的就是规则表， 规则里面通常涉及简单的逻辑， 最终通过for循环， 我们就可以得到我们要的东西。 比如一个中学生都会的排序算法， 我们无法需要做的是前面和后面的数比较大小， 然后一个if else进行换位， 最后一个for循环， 多长的序列都可以瞬间搞定。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;176de-0-0&quot;&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.40556900726392253&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibccd3W2SkazpguaDUmf1EWibibibEBCIwsAHiaGwDkFcYUeGLqHsuPP0ibBA7ibPX7OxPPq87Jr0NAtFjSibw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;826&quot; /&gt;&lt;/span&gt;&lt;/p&gt;


&lt;p&gt;&lt;span data-offset-key=&quot;b1ct2-0-0&quot;&gt;这就是用程序解决问题的核心思维， 给你一个再复杂手忙脚乱的问题， 只要这个问题可计算， 那么我们只需要设定好我们需要的规则表， 在有限的步骤里迭代， 最终机器总会给你解决。&lt;/span&gt;比如魔方问题， 一般的聪明小孩都很难在短时间解决问题， 但是， 事实上解决魔方问题有一套非常整齐的规则表（你想象打乱一个魔方其实比较容易的， 把它弄整齐是打乱的逆运算，但是破镜重圆总是难的）。 如果按照这个规则表执行若干步， 再困难的魔方也给你整出来。&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.75&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibccd3W2SkazpguaDUmf1EWibibz3zliaRoh4oEWf9QQOX3VMpbMFylumcHY7novvRnic1j7aN7R7pohRHQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;676&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;Image FocusPlugin--unfocused Image--isBlock&quot; data-ratio=&quot;0.44333333333333336&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibccd3W2SkazpguaDUmf1EWibibBqmPPsMKMLBUUyKWYnVsiaibg6hmZP9cADL9iak5yxuibvmosIG5ZUWbuw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;600&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;span data-offset-key=&quot;e13hv-0-0&quot;&gt;我们说规则表， 加上迭代等操作的思路可以解决大量的工程问题。我们曾经认为按照这样的思路我们可以解决整个智能的问题。 只是填入一张越来越大的表格。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;5g8h1-0-0&quot;&gt;但是它在通向智能的关键位置， 却停住了， 这个元凶 -就是- &lt;strong&gt;不确定性&lt;/strong&gt;。日常生活中很多东西无法轻易的总结出规则表来， 因为细小的规则实在太多了。 你可以想象我们有无数尺寸和规格各不相同的螺钉螺母。 每一种规格我们都要想一条if else，可悲的是这些螺钉和螺母几乎没有哪两对完全相同， 穷尽一个程序员一生也写不完这些程序。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;9mrot-0-0&quot;&gt;统计机器学习 - 机器判断规则&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span data-offset-key=&quot;6pfmt-0-0&quot;&gt;这个问题的解决方法十分自然又十分了不起：  能不能让机器自己学会这个表格， 而不是认为设定它呢？  这就是整个智能问题的第二步 - 学习。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span data-offset-key=&quot;eeh10-0-0&quot;&gt;整个学习问题的基石其实是古希腊人提出的归纳法和演绎法。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;17gbk-0-0&quot;&gt;伟大的希腊哲学家早就对学习的本质展开过探讨，它们把学习分类为&lt;/span&gt;&lt;span data-offset-key=&quot;17gbk-0-1&quot;&gt;归纳法和演绎法&lt;/span&gt;&lt;span data-offset-key=&quot;17gbk-0-2&quot;&gt;。所谓演绎法， 就是从用一定规则进行推理的过程。 苏格拉底是人，人都是会死的， 因此苏格拉底会死。 这就是三段论， 或者称为演绎法的根基。 而真正学习的过程，是这个演绎法的逆过程。 我们先知道一个特例， 然后通过特例，得到这个“人都是会死的” 知识， 再指导自己的行动。 学习是知识在脑子或者机器里面形成的过程， 怎么形成？ 这个过程被称为归纳法，也就是根据搜集到的特例比如苏格拉底死了这个事情，来归纳更一般的知识。归纳法， 我们来看我们需要提供给机器怎样的佐料来解决这个问题。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;6nhn2-0-0&quot;&gt;我们想象这样一台机器， 这个机器和之前说的规则机器类似， 唯一的区别是， 我们把大量的假设放在那里，让机器来连线。 我们要让它学习一个知识， 比如-什么人是否会死的。我们把人按照几个特征进行分类， 一个特征对应一个问题， 比如是否是哲学家， 是男还是女， 是白种人还是黄种人。 这些特征， 都对应会死或不会死这两个结论。 这样，你会得到多少个假设呢？ 组合数学告诉我们16种， 于是学习的任务就是给这16个假设和真或者假连接起来。 一旦一条线连起来， 我们就得到了一个新的知识，可以被用于在真实的世界做判断！ 就和之前说的规则机器一样。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;1bdeq-0-0&quot;&gt;我们首先给这个机器灌入所有的可能性， 那16种假设。 然后我们让机器来收集案例！ 比如机器收集到一个苏格拉底死了， 那么苏格拉蒂是什么？ 男性，白种人， 哲学家， 于是机器得到男性， 白种人， 哲学家，会死。 于是机器给机器输入亚里士多德， 柏拉图， 大卫休谟，机器都会告诉你会死。然后我们继续收集样例， 比如居里夫人死了， 然后机器会得到女性，白种人， 非哲学家，死了。 这样它能够做的判断就又多了很多！ 这样的思维范式，就是归纳法，由于我们列举的假设依然用到了人类已有的知识， 因此我们得到的这个机器，事实上是最接近规则机器的一台学习机， 我们可以称之为规则为主体的归纳法。我们直接把规则转化为了可以学习的对象。输入样例，得到一个是非的知识， 这个样例我们换个词叫数据， 这个机器我们换个词– 叫做分类器。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;9nnub-0-0&quot;&gt;整个有关统计的机器学习， 都可以看成让机器学习有效归纳的方法， 从数据里得到规则表， 再用规则表进行判断。前面的过程叫训练， 后面的过程叫测试。  如果这些规则是有关一个是非的命题， 它就是一个分类器， 如果它是一个连续数值的预测， 就是回归。 但是规则表的本质是不变的， 它就是让你填表，表格的横排和竖排已经有了， 一个叫特征， 一个叫实例。  特征是人为归纳好的， 而实例是我们人为收集的， 表格中有些地方是空的，  就是我们想要判断的东西， 需要机器来填的部分。 比如给你一百幸福和不幸的人的案例， 让你判断第101个人的情况。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;81s85-0-0&quot;&gt;刚刚的那个例子你应该已经体会到， 这个命题验证过程其实是一个组合爆炸的问题。我们把关于这个世界的互相矛盾的假设都丢尽机器。即使最简单的问题也会有无穷多的情况要判断 （特征的n次方）这种假设的数量随着问题的复杂度急速指数上升的过程，我们称之为维度灾难。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.5625&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibccd3W2SkazpguaDUmf1EWibib6XNRA36VEFMtlPlZQ2RpPXtla5u66LIcDmhkLUQuPecqg0IVicuibIwA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;640&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;span data-offset-key=&quot;ajopm-0-0&quot;&gt;而机器学习的各个算法， 让我们通过加入更多的假设， 来偷懒解决这个问题， 此处没有比决策树更典型的， 它的高阶版本xgboost成为机器学习竞赛的杀手锏。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;a9isr-0-0&quot;&gt;而决策树得核心智慧就是优先级算法简化命题数量。 虽然特征很多， 但是并不是每个特征都一样重要， 我们如果先按照最重要得特征进行判断， 依此往下， 你可能不需要2得N次方个情况， 而是按照树结构做N次判定即可。 优先级， 也是人类智慧得核心，事实上， &lt;strong&gt;我们永远在抓轻重缓急，在抓主要矛盾，&lt;/strong&gt; 无论是有意的还是无意的，当然大部分人的轻重缓急是按照时间来的，时间比较近的就是比较重要的， 这也是为什么很多人有拖延症。 很多人说到优先级算法很想到相亲， 其实这也是一种人类思维自然使用的决策树， 比如女生找男朋友通常心理都有一个优先级构成的树， 首先， 对方的年龄多大？ 如果对方年龄大于50岁直接pass， 然后看工资，如果工资小于20万直接pass，工资在20和30万间看下学历， 学历小于本科直接pass。 这其实就是一个决策树的结构。 每次pass， 就减少掉了一半需要判定的命题。 通过这种预设的二叉树逻辑， 一个本来需要2的n次方的步骤解决的事情， 可能只要n步了。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.7453703703703703&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibccd3W2SkazpguaDUmf1EWibibq5oBakMtQKgHb2Akq4jNYicdNNniarAhbtJNpWaJ7qOkbJDDKpTTB9MQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;8dl0e-0-0&quot;&gt;具体如何来学，树的根部是你选择的第一个特征， 更好的角度是把特征看成一个问题，树的根部是你要问的第一个问题， 根据这个问题的回答， 数据会在左边右边分成两组。 然后在每个答案的基础上， 你继续问下一个问题， 所谓的决策树的分叉， 每个枝杈就是一个新的问题。 如此，就会形成一个树的结构。构建这个树的主要难点， 在于要由机器决定哪个问题先问， 哪个问题后问， 如何选择这个优先顺序？我的要求就是， 每一次分化，我们都希望取得最多的信息，如分叉后一个树杈全是yes，一个全是no就是最好的效果， 如果达不到， 也让它尽可能接近这个效果。  这样一个一个问题问下去， 最终达到稳定后过程停止。  这样形成的决策树， 我们会形成任何一个情况下的优先级。 或许长的帅的人工资不重要。 或许学历高的人年龄不重要。 这种不同情况不停调整优先级的思维， 真的是被决策树利用到了极致！ 从原始数据里提炼的决策树， 可以对无限的新情况进行预测。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;fk0ce-0-0&quot;&gt;另一个得到这样的一个规则表的方法是线性假设。 线性分类器通过假定特征之间的相互独立， 使得命题的成立与否可以通过一个加权求和的关系表达， f=wx+b 。最后f如果大于0就是是， 小于0就是否。 线性分类器也是一种特别符合人认知习惯的模型：一般人在决策时候做的事情就是加权平均，比如你平时做分类（决策）， 你最想的一种状态是什么？你要把几个核心的要素放到一起， 按照他们的重要性加和，比如你今天要不要去看电影，可能取决于你的女朋友free否， 下不下雨和电影好不好看， 这个时候，我们可以把这些因素加权在一起， 在和一个我们给定的阈值做比较，大就去， 不大就不去， 这正权衡得失的做法， 就是线性分类器。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;a0m7b-0-0&quot;&gt;具体学习的过程， 我们从实例里归纳出每个特征对应的权重参数，然后进行判断。 只要参数都确定了， 也就是一次解决了所有的问题。 线性分类器的高级版本SVM已经超越了线性假设。 也是小数据下生成有效规则的大杀器。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;8te9f-0-0&quot;&gt;连接主义机器学习， 产生规则&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;fk6j-0-0&quot;&gt;刚刚说的那一套， 有一个问题你有没有注意到？ 我们最先提出的问题是让机器产生一个规则表， 而刚刚说的统计机器学习里， 更多的是让机器根据特征进行命题判断。 这其实是只进行了0.5步。 大家想象以下， 在真正的实践活动里， 你无法一开始就设定出一堆特征让它进行逻辑判断，在这个情况下如何得到我们所说的“规则”呢？ 如何让机器自己生成战胜“复杂”的程序呢？ 连接主义机器学习在一定程度解决了这个问题。  因为， 人类认识事物，生成规则， 其实是通过“概念”来的， &lt;strong&gt;“概念”是一个浓缩的信息载体， 通过它我们能够进行任何更复杂的推理。&lt;/strong&gt; 那么“概念”是如何生成的呢？ 它的载体正是下面说的联结主义的代言人神经网络。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;a5gsn-0-0&quot;&gt;神经网络&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span data-offset-key=&quot;dijog-0-0&quot;&gt;首先，神经网络是由神经细胞组成的。  一个神经细胞就是一个最小的认知单元， 何为认知单元， 就是把一定的数据组成起来，对它做出一个判断， 我们可以给它看成一个具有偏好的探测器。  联系机器学习，它就是刚刚说的线性分类器。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;cr2lq-0-0&quot;&gt;正确的分类，是认知的基础，我们对事物的感知比如色彩， 物体的形状等，其实都是离散的， 而物理信号是连续的， 比如光波， 声波。这里面的中间步骤就是模数转化， 把连续的信号转化成离散的样子， 这正是一个分类器干的事情。  一个单个神经元可以执行一个简单的基于感知信号的if else语句。 先收集一下特征做个加和， if大于一个值我就放电， 小于我就不放电，就这么简单。 晶体管当然也在干这个事情。 &lt;strong&gt;神经细胞与晶体管和计算机的根本区别在于可塑性。&lt;/strong&gt;或者更准确的说具有学习能力。从机器学习的角度看， 它实现的是一个可以学习的分类器，就和我们上次课讲的一样， 具有自己调整权重的能力， 也就是调整这个w1和w2.&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.5625&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibccd3W2SkazpguaDUmf1EWibib2NvE4HCXevrTz3VAnXzfIxaOZibibe1YnYGN84NF1XWqyKpNdsISR2aA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;640&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;3f6fb-0-0&quot;&gt;我们这个简化出来的模型，　正是所有人工神经网络的祖母　－　感知机。　从名字可以看出，&lt;/span&gt;&lt;span data-offset-key=&quot;3f6fb-0-1&quot;&gt;感知机算是最早的把连接主义引入机器学习的尝试。&lt;/span&gt; &lt;span data-offset-key=&quot;3f6fb-0-2&quot;&gt;它直接模拟Warren McCulloch 和 Walter Pitts 在1943 提出而来神经元的模型，  它的创始人 R 事实上制造了一台硬件装置的跟神经元器件装置。&lt;/span&gt;单个的感知机并不能比传统的机器学习多做一丁点的事情， 还要差一些。 但是把很多个感知机比较聪明的联系起来，就发生了一个质变。&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;5ui0b-0-0&quot;&gt;首先， 每个线性分类器， 刚刚讲过都是一个小的特征检测器， 具有自己的偏好，这个偏好刚好用一个直线表示， 左边是yes，右边是no， 那么多个神经元表达的是什么呢？ 很多条这样yes or no的直线！  最终的结果是什么呢？ 我们得到一个被一条条直线割的四分五裂的结构， 既混乱又没用！  这就好比每个信息收集者按照自己的偏好得到一个结论。幸好我们有那个头顶的神经元， 它就是最终的大法官， 它把每个人划分的方法， 做一个汇总。 大法官并不需要什么特殊的手段做汇总， 它所做到的，无非是逻辑运算， 所谓的“与”， “或”， “非”， 这个合并方法，可以得到一个非常复杂的判决结果。 你可以把大法官的工作看成是筛选， 我们要再空间里筛选出一个我们最终需要的形状来， 这有点像是小孩子玩的折纸游戏，每一次都这一条直线， 最终会得到一个边界非常复杂的图形。  其实这里面做的事情， 正是基础的逻辑运算， 一个简单的一层神经网络可以执行与或非这些基本的逻辑操作。事实上它的本质就是把简单的特征组合在一起形成一些原始的概念。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;4ud6e-0-0&quot;&gt;它是怎么做到的呢？ 学习。  生物神经网络的学习， 是通过一种叫做可塑性的性质进行调节的。 这种调控的法则十分简单。说的是神经细胞之间的连接随着它们的活动而变化， 这个变化的方法是， 如果有两个上游的神经元同时给一个共同的下游神经元提供输入， 那么这个共同的输入将导致那个弱的神经元连接的增强， 或者说权重的增强。 这个原理导致的结果是， 我们会形成对共同出现的特征的一种相关性提取。 比如一个香蕉的特征是黄色和长形， 一个猴子经常看到香蕉， 那么一个连接到黄色和长形这两种底层特征的细胞就会越来越敏感， 形成一个对香蕉敏感的细胞，我们简称香蕉细胞。 也就是说我们通过底层特征的“共现” 形成了一个简单的“概念”。 &lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;4ud6e-0-0&quot;&gt;上述过程被总结H&lt;/span&gt;ebian学习的一个过程。  我们可想象，一个两层以上的神经网络， 就可以表述香蕉， 苹果， 菠萝这些水果了， 它们无非是底层特征颜色，形状的不同组合而已。 而这些不同水果的概念， 就可以帮助我们形成更加复杂的规则表 ，比如让它根据客户的信息帮它推荐一个水果拼盘。 由此可见， 神经网络通过与或非进行简单特征的组合 ，再通过if esle进行判断选择合适的特征得到概念， 再通过下一层迭代得到概念有关的命题。 就可以生成比之前的传统机器学习复杂的多的规则表。而且我们可以想象出来， 迭代的层数越多，它生成的“概念”和“规则”就越复杂。  当然真实训练中我们用到的不是模仿生物版本的Hebian学习， 而是强大的多的反向传播算法。&lt;/p&gt;
&lt;p&gt;&lt;span data-offset-key=&quot;48v3r-0-0&quot;&gt;&lt;img data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/jrbyyXzrKkJqzpvQ60VcjgiacFu21XHHubic1vJveCSZ6PHEDDyJd1LZhn3z6ibqmBehPbx0icZx0ZXosoBaXWceQw/640?wx_fmt=png&quot; data-type=&quot;png&quot; class=&quot;&quot; data-ratio=&quot;1.6111111111111112&quot; data-w=&quot;360&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span data-offset-key=&quot;dmb6s-0-0&quot;&gt;事实上为了让这种生成“概念”得到“规则”的方法更加有效， 我们会加入一些无比强大的先验假设。 其中最有名的一组，  就叫CNN，它所做的，其实是对于图像这类巨大无比， 而局部特征不断重复的信息形式， 其实你可以写一个循环， 来让你的程序更有效。 循环里的模块每一步是可以共用的， 也就是卷积核。 卷积核一点点的卷个图像上的每个小块， 也就是循环的总体。 卷积核在每个图像局部做的， 事实上都是一个小的if esle 语句。 if像素之间符合某个关系，就是yes，否则No。这个结果， 最后被综合出来， 给下一层合成更复杂的图像特征。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.7298850574712644&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibccd3W2SkazpguaDUmf1EWibibJ7GaCXDzw2dMW8QiaAPh96svf1lqjLico2MoDlVUCfFZgIHkysrSaRibQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;870&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;4vk9r-0-0&quot;&gt;好了， 到目前为止， 说的都是和时间无关的规则。 而一开始讲到的真实的图灵机， 是和时间有关的规则。 那么如何得到一个和时间有关的规则表呢？ 如果要处理和时间相关的信息， 你必须要引入记忆， 引入内部状态， 而和刚刚说的一样， 这些含时间的规则要是可以学习的， 用数学的语言说， 就是要有一个连续可微的载体， 这个东西就是RNN。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;72qm9-0-0&quot;&gt;def step&lt;/span&gt;&lt;span data-offset-key=&quot;72qm9-0-1&quot;&gt;(self, x):&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span data-offset-key=&quot;di032-0-0&quot;&gt;# update the hidden state&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span data-offset-key=&quot;4f218-0-0&quot;&gt;self.h = np.tanh(np.dot(self.W_hh, self.h) + np.dot(self.W_xh, x))&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span data-offset-key=&quot;243tl-0-0&quot;&gt;# compute the output vector&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span data-offset-key=&quot;591p4-0-0&quot;&gt;y = np.dot(self.W_hy, self.h)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span data-offset-key=&quot;a1b57-0-0&quot;&gt;return&lt;/span&gt; &lt;span data-offset-key=&quot;a1b57-0-1&quot;&gt;y&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;g9on-0-0&quot;&gt;以上是RNN的python程序定义。 它说的无非是你有一个刚刚说的线性分类器组成的单隐层神经网络， 但是这一回，神经网络的输出， 要作为输入，重新回到神经网络的隐层里， 这个关键的增加， 就使得它具有了处理复杂时间信息的能力。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;5qh71-0-0&quot;&gt;这个结构，非但优雅，而且有效。一个非常重要的点是， 你知道信息的传播是有损耗的， 如果把RNN展开， 它事实上相当于一个和历史长度一样长的深度网络， 信息随着每个时间步骤往深度传播， 这个传播的信息是有损耗的， 到一定程度我就记不住之前的信息了， 当然如果你的学习学的足够好， Wij还是可以学到应该学的记忆长度。  &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;Image FocusPlugin--unfocused Image--isBlock&quot; data-ratio=&quot;0.26161790017211706&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibccd3W2SkazpguaDUmf1EWibibPf1BYBmsfuHXyspOv0uwulVbuy0UibqOib2grXtp4XpvWU4b6Pj3402Q/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;581&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;2ot4h-0-0&quot;&gt;&lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;&gt;&lt;/ins&gt;  事实上叫做“循环神经网络”  循环的本质是什么呢？    它其实正是你的程序里的for循环啊！ RNN的本质是， 在每个时间步里进行同样的操作， 这个操作无非是， 当下的输入， 和神经网络的状态两部分特征的逻辑组合（与或非）然后， 这个组合的结构进行一个if else的逻辑判断， yes or no， 根据这个，生成一个输出的结果， 这个结果， 要回传给神经网络隐层， 生成下一个隐层状态。 &lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;2ot4h-0-0&quot;&gt;大家看这其实就是图灵机的定义啊， 而RNN的本质， 就是一个可以通过微分方法学习的图灵机啊。 虽然每个步骤的规则和执行足够简单， 但是只要步数足够多， 却可以产生非常复杂的结果。  &lt;strong&gt;RNN学习的本质， 就是给你那个足够复杂的结果， 让你反演出那个足够简单的规则， 然后让它在新的环境下再去做预测与决策。&lt;/strong&gt; 我们可以看到， 这已经非常接近智能的本质了。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;5j932-0-0&quot;&gt;有关物理的世界和智能的世界&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;di5qc-0-0&quot;&gt;上面的这些思考无疑开始让人们想象我们所说的包含了逻辑推理， 情感，甚至意识的问题与物理世界的关系到底是什么。 我们说物理的世界里， 主宰一切的是微分方程。 一切因果关系， 都由微分方程所承载。 你有了不同不同微观粒子电磁力的描述，把它们放入薛定谔和狄拉克方程， 你就可以推出原子的不同性质。  这其实可以说是因果推理的极致了。 它甚至导致了机械的宿命论思想。当一切初始的原因输入系统， 那么它就回归于一个必然的结果。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;dl784-0-0&quot;&gt;到了非线性动力学的时代看似这点被混沌打破了，亚马逊的蝴蝶引起北美的飓风， 让通俗科学爱好折重新燃起了不可知论的希望，事实上并没有。  所谓的混沌， 无非是一种确定性下的不确定， 或者已知中的未知。 混沌的系统依然在一个被方程高度确定的洛伦兹吸引子里。&lt;/span&gt;到此处， 我认为微分方程依然是描述因果关系最精密的所在， 它可以在输入很少信息的时候， 得到最多的预测产出。&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;8i7lg-0-0&quot;&gt;在看刚刚的智能问题， 我们说， 整个智能问题， 到目前为止其实还是在围绕那张规则表， 只是我们的思路由制定规则表， 到了学习规则表。和物理比较， 目前的机器， 需要输入进去大量的数据， 才能生成一点十分简单的规则。 当然你可以举阿法狗下围棋的例子说明所生成的规则并没有那么简单， 可惜的是， 那些规则只适用于一些非常封闭而特定的领域。 而不像牛顿定律放之四海而皆准。  那么神经网络可不可以观测大量物体坠落的过程把万有引力定律给推出来呢？ 目前看是不能的。其实牛顿引力定律的得出是含有了大量的人类推理。 我们需要先知道物体运动改变和受力的关系， 然后通过观测物体的轨迹得到大量物体的受力情况，再在这些手里情况下得出某一种共同的作用力形式， 这是一个多么复杂的思维链条。 这对于目前统计的巨人， 而只懂得浅显的形式逻辑的神经网络，还是比较困难的。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;dsh1-0-0&quot;&gt;有关语言&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;8cbc-0-0&quot;&gt;讨论智能的问题离不开语言。从乔姆斯基开始， 人们就开始研究不同语言背后的共同语法基础。 其实如果深究语言问题， 我们会看到它和刚刚说的程序的联系。 &lt;strong&gt;语言无非是对世界的符号化，类似于给每个刚刚说的概念赋予一个符号。&lt;/strong&gt;而语言其实很像程序， 它就是对概念之间关系的表述。  我想语言和程序的区别可能在于语言更加模糊， 但是它对付不确定性的能力远远大于程序，因为这种模糊性， 让它具备了更好的适应能力， 可以表述那些用程序难以描述的事情。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;8cbc-0-0&quot;&gt; 但是本质上， 语言无非是一个现有概念的符号体系， 描绘概念和概念间的关系。这样看以往的深度学习NLP其实是走了一条南辕北辙的路， 我们把不同的词汇和句子压缩成词向量， 句向量喂给神经网络学习， 而事实上神经网络对这些符号背后的实体概念却一无所知。虽然词向量也能稍微的带有一点不同词语之间的语义距离， 但是这和真实世界所含有的信息量，也依然是差异巨大。 目前用图卷积网络解决NLP的思路，算是一个进步， 因为它更好的涵盖了整个符号世界的信息。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;blfe1-0-0&quot;&gt;语言， 好比一个巨大的人类经验和逻辑的宝库， 这个符号世界几乎就是真实世界的极好压缩体， 如果一天神经网络真正被赋予了语言的power，也就是能够真正理解这个符号世界， 或许离通用人工智能也就不远了。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;span data-offset-key=&quot;blfe1-0-0&quot;&gt;有关物理世界和语言世界的打通&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;blfe1-0-0&quot;&gt;刚刚说的精确的物理方程的世界， 和能够应付更多不确定性的模糊的语言， 之间又有哪些联系呢？  我的想法是， 物理的杀手锏微分方程， 当构成了一个非线性的动力学系统， 却可以通过它内在的定点， 极限环，吸引子等概念， 去接近那个模糊性的语言， 就好比在非线性动力学的世界里， 我们往往不再那么关于一个系统如何发展的暂态，很多不同的系统都归一于一个吸引子， 那么它们背后的逻辑可能就是类似的。 这或许会架起一座物理世界和语义世界的桥梁？  &lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;blfe1-0-0&quot;&gt;更多阅读&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651383991&amp;amp;idx=1&amp;amp;sn=26f543505499441e7f31cfb15177ff10&amp;amp;chksm=84f3c6f6b3844fe08f91bfec42c55b42d221f452c68d3820eb1612a6c09f39c06956d69f42ca&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-itemshowtype=&quot;0&quot; data-linktype=&quot;2&quot;&gt;当神经网络遇到神经科学-铁哥18年长文汇总&lt;/a&gt;&lt;br /&gt;&lt;/p&gt;

</description>
<pubDate>Mon, 25 Feb 2019 18:31:05 +0000</pubDate>
<dc:language>zh-CN</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.jintiankansha.me/t/q56XOgLetH</dc:identifier>
</item>
<item>
<title>东边日出西边雨：极端天气网络中的遥相关与超指数分布</title>
<link>http://www.jintiankansha.me/t/QkOJZ4teYL</link>
<guid isPermaLink="true" >http://www.jintiankansha.me/t/QkOJZ4teYL</guid>
<description>&lt;p data-mpa-powered-by=&quot;yiban.io&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.6661764705882353&quot; data-s=&quot;300,640&quot; data-type=&quot;jpeg&quot; data-w=&quot;680&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/wibWV1DB7tWIDnjf4EtfFejwpQJmErqCMG4rtOm0rxStSHkUcm6CUnLa7flsMwAILX9iaQqSUxSSicQRjEaicIKkPw/640?wx_fmt=jpeg&quot;/&gt;&lt;/p&gt;
&lt;section class=&quot;&quot; data-mpa-template-id=&quot;1258535&quot; data-mpa-color=&quot;null&quot; data-mpa-category=&quot;&amp;#x6536;&amp;#x85CF;&quot;&gt;
&lt;section class=&quot;&quot; data-mpa-template-id=&quot;1172402&quot; data-mpa-color=&quot;null&quot; data-mpa-category=&quot;fav&quot;&gt;&lt;section&gt;&lt;span&gt;&lt;strong mpa-from-tpl=&quot;t&quot;&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;导语&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;section readability=&quot;2.5&quot;&gt;&lt;section readability=&quot;5&quot;&gt;&lt;p&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;2月份的Nature主刊上的一篇论文，着眼于气象科学与复杂网络结合擦出的火花。这篇小文将带你以看侦探小说的视角，批判性地解读这篇论文，让你明白这篇文章在材料的呈现上有哪些值得借鉴之处。在文末，作者将结合该文，谈谈接下来可能的研究方向。&lt;/span&gt;&lt;/p&gt;
&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;
&lt;/section&gt;&lt;blockquote readability=&quot;7&quot;&gt;
&lt;p&gt;&lt;span&gt;论文题目：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;Complex networks reveal global pattern of extreme-rainfall teleconnections&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;论文地址：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;https://www.nature.com/articles/s41586-018-0872-x&lt;/span&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p mpa-paragraph-type=&quot;body&quot;&gt;复杂网络的应用，这些年间越来越广泛，但总有一些共通的规律，最典型的就是&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzIzMjQyNzQ5MA==&amp;amp;mid=2247490194&amp;amp;idx=1&amp;amp;sn=a85d1f0312d455ec7ef59c6b26c7a581&amp;amp;chksm=e894401fdfe3c9095db99fb55f9ecbd9962dbe50092d69b9fb944168cd378d930bb2fb1aacd6&amp;amp;scene=21#wechat_redirect&quot; data-linktype=&quot;2&quot;&gt;不同尺度下网络呈现相同性质的幂律法则&lt;/a&gt;。不过，凡事总有例外，&lt;span&gt;这篇Nature论文的研究成果&lt;/span&gt;能够打破幂律法则的现象，必然是颠覆式的发现。&lt;/p&gt;

&lt;p mpa-paragraph-type=&quot;body&quot;&gt;&lt;strong&gt;&lt;span&gt;论文摘要&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;section class=&quot;&quot; data-tools=&quot;135&amp;#x7F16;&amp;#x8F91;&amp;#x5668;&quot; data-id=&quot;72469&quot;&gt;&lt;section data-width=&quot;100%&quot;&gt;&lt;section readability=&quot;23&quot;&gt;&lt;section data-autoskip=&quot;1&quot; class=&quot;&quot; data-style=&quot;clear: none; margin-top: 0px; margin-bottom: 0px; line-height: 1.5em; text-align: right; color: inherit; border-color: rgb(239, 112, 96);&quot; readability=&quot;46&quot;&gt;&lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;/&gt; 
&lt;p&gt;&lt;span&gt;Climatic observables are often correlated across long spatial distances, and extreme events, such as heatwaves or floods, are typically assumed to be related to such&lt;/span&gt;&lt;span&gt;teleconnections&lt;/span&gt;&lt;span&gt;. &lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;Revealing atmospheric teleconnection patterns and understanding their underlying mechanisms is of great importance for weather forecasting in general and extreme-event prediction in particular, especially considering that the characteristics of extreme events have been suggested to change under ongoing anthropogenic climate change. &lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;Here we reveal the global coupling pattern of extreme-rainfall events by applying complex-network methodology to high-resolution satellite data and introducing a technique that corrects for multiple-comparison bias in functional networks. &lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;We find that the distance distribution of significant connections (P &lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;For longer distances, the probability of significant connections is much higher than expected from the scaling of the power law. &lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;We attribute the shorter, power-law-distributed connections to regional weather systems. &lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;The longer, super-power-law-distributed connections form a global rainfall teleconnection pattern that is probably controlled by upper-level Rossby waves. &lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;We show that extreme-rainfall events in the monsoon systems of south-central Asia, east Asia and Africa are significantly synchronized. Moreover, we uncover concise links between south-central Asia and the European and North American extratropics, as well as the Southern Hemisphere extratropics. &lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;Analysis of the atmospheric conditions that lead to these teleconnections confirms Rossby waves as the physical mechanism underlying these global teleconnection patterns and emphasizes their crucial role in dynamical tropical–extratropical couplings. &lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;Our results provide insights into the function of Rossby waves in creating stable, global-scale dependencies of extreme-rainfall events, and into the potential predictability of associated natural hazards.&lt;/span&gt;&lt;/p&gt;
&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p mpa-paragraph-type=&quot;body&quot;&gt;&lt;span&gt;可上下滑动查看论文摘要&lt;/span&gt;&lt;/p&gt;
&lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;/&gt; 
&lt;p mpa-paragraph-type=&quot;body&quot;&gt;&lt;span&gt;优质的摘要，第一句应该是背景介绍，目的是让读者知道这篇文章讲述的是哪个领域的发现。既然是背景，就要和日常生活有所联系，让读者能联想到&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzIzMjQyNzQ5MA==&amp;amp;mid=2247495932&amp;amp;idx=1&amp;amp;sn=ee1f07d4a50c6a75d3387d0c70e20e90&amp;amp;chksm=e897aa71dfe02367ffc43be660fe13378e85a14dfcce747daf01cf99c4767e4679af54feebbb&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-itemshowtype=&quot;0&quot; data-linktype=&quot;2&quot;&gt;最近的新闻报道&lt;/a&gt;。&lt;/span&gt;&lt;/p&gt;

&lt;p mpa-paragraph-type=&quot;body&quot;&gt;&lt;span&gt;本文的第一句指出气候现象，尤其是极端情况，例如高温，暴雨等在长距离上存在关联。近期美国的寒潮，跨越数个州，这还只算是区域性的气候关联，而欧洲、亚洲与美洲同时出现的极端寒冷，就属于文中提到的“&lt;strong&gt;遥相关&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;（teleconnection）&lt;/span&gt;&lt;span&gt;”了。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;

&lt;p mpa-paragraph-type=&quot;body&quot;&gt;说完了背景，要论述该现象的意义。假设弄清楚了气候中的遥相关，能解决什么现实问题？能带来哪些新的问题了？即如何扩展人类的认知边界。这是论述研究意义时要回答的模板问题。&lt;/p&gt;

&lt;p mpa-paragraph-type=&quot;body&quot;&gt;摘要第二句指出，对于极端天气的预测，如果能结合遥相关，那会更加精确。&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzIzMjQyNzQ5MA==&amp;amp;mid=2247495932&amp;amp;idx=1&amp;amp;sn=ee1f07d4a50c6a75d3387d0c70e20e90&amp;amp;chksm=e897aa71dfe02367ffc43be660fe13378e85a14dfcce747daf01cf99c4767e4679af54feebbb&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-itemshowtype=&quot;0&quot; data-linktype=&quot;2&quot;&gt;而极端气候现象的频繁发生&lt;span&gt;，很大的原因是人类活动的影响&lt;/span&gt;&lt;/a&gt;&lt;span&gt;，如果对极端气候现象的遥相关没有精准的描述，也就无从谈起人类的影响会不会带来改变。电影”后天“中描述的极端寒冷，在19年初出现在了新闻报道中，这说明极端气候离我们的生活并不遥远。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.563&quot; data-s=&quot;300,640&quot; data-type=&quot;jpeg&quot; data-w=&quot;1000&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/wibWV1DB7tWIDnjf4EtfFejwpQJmErqCMxIrnWOKibHTrHwViamS46mecjd9df3eBmkXuag3FVKpSLa6G9mKUDNIQ/640?wx_fmt=jpeg&quot;/&gt;&lt;/p&gt;
&lt;p mpa-paragraph-type=&quot;body&quot;&gt;&lt;strong&gt;&lt;span&gt;电影《后天》剧照&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;section class=&quot;&quot; data-mpa-template-id=&quot;1377480&quot; data-mpa-color=&quot;#ffffff&quot; data-mpa-category=&quot;&amp;#x6807;&amp;#x9898;&quot;&gt;

&lt;section data-mid=&quot;t4&quot;&gt;&lt;section data-preserve-color=&quot;t&quot; data-mid=&quot;&quot;&gt;&lt;section data-mid=&quot;&quot;&gt;&lt;p&gt;&lt;strong mpa-from-tpl=&quot;t&quot;&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;&lt;strong mpa-from-tpl=&quot;t&quot; mpa-is-content=&quot;t&quot;&gt;核心解读&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;
&lt;/section&gt;&lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;/&gt; &lt;p mpa-paragraph-type=&quot;body&quot;&gt;接下来概要总结文章的核心发现。一般是先介绍一个通用的结论，再详细的说一个经过详细研究的案例，最后再次用更具体的例子，指出研究的意义。但在此之前，需要先将研究的问题细化。&lt;br/&gt;&lt;/p&gt;

&lt;p mpa-paragraph-type=&quot;body&quot;&gt;&lt;strong&gt;&lt;span&gt;研究对象选择&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p mpa-paragraph-type=&quot;body&quot;&gt;本文从极端气候中选择了暴雨。我猜想，相比于酷暑或者极端严寒，除了数据收集更容易，更准确客观，暴雨的评判标准在不同的时间更具有一致性，不会受到全球变暖与城市热岛效应的影响。因此不需要根据时间进行校正。&lt;br/&gt;&lt;/p&gt;

&lt;p mpa-paragraph-type=&quot;body&quot;&gt;暴雨是一个仁者见仁的描述，科学上要研究，需要划一条线，来定义清楚何为暴雨。而在不同的区域，不同的年份，人们对暴雨的认知也有所不同。该研究中的设定是在一个地区所有下雨的日子中，如果这一天的降雨量超过了95%，那么这一天就算做是暴雨。&lt;/p&gt;

&lt;p mpa-paragraph-type=&quot;body&quot;&gt;&lt;span&gt;你也许会问这里95这个数字是怎么来的？我猜这篇论文的审稿人也问了这个问题，而为了应对审稿人的”刁难“，这篇论文的补充材料中将95%这个数字换成了90%-99.9%之间的一组数字，论证了不管你怎么定义暴雨这个事件，文章中的发现都差不多，这说明了该现象的鲁棒性。&lt;/span&gt;&lt;/p&gt;

&lt;p mpa-paragraph-type=&quot;body&quot;&gt;&lt;strong&gt;&lt;span&gt;研究数据与成果鲁棒性&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p mpa-paragraph-type=&quot;body&quot;&gt;接下来要看研究用到的数据，降雨量的评估如果是基于地面气象站的数据，这些手工记录的数据，不同的国家，不同的时段，需要规整，还会带着不可避免的缺失和误差，例如有些不靠谱地方出来的数据，也难以精准的记录降雨量。而该研究用的是高分辨率气象卫星TRMM&lt;span&gt;（ Tropical Rainfall Measurement Mission）&lt;/span&gt;提供的全球&lt;span&gt;（北纬50度到南维50度之间）&lt;/span&gt;1998-2016年间的降雨量数据。&lt;/p&gt;

&lt;p mpa-paragraph-type=&quot;body&quot;&gt;下图展示了在不同地方6-8月间，从57.6万次降雨数据中统计出的超过95%的降雨天对应的降雨量（图A），以及在这段时间里出现暴雨的天数（图B）。&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.589010989010989&quot; data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-w=&quot;910&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/wibWV1DB7tWIDnjf4EtfFejwpQJmErqCMj3WRl6JjY8NVFRqIN0wyO6ExSlyG3kpVTxQYKFOu9Nda4kWHKkl3Yg/640?wx_fmt=png&quot;/&gt;&lt;/p&gt;

&lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;/&gt; &lt;p mpa-paragraph-type=&quot;body&quot;&gt;可以看出处在雨季的南亚次大陆及东南亚，暴雨的天数高达40-60天，而在非洲中部的草原，这段时间也处在雨季。&lt;/p&gt;

&lt;p mpa-paragraph-type=&quot;body&quot;&gt;除了使用来自TRMM的数据，该研究还使用了Global Precipitation Climatology Project的低精度&lt;span&gt;卫星数据&lt;/span&gt;&lt;span&gt;（每一个经度和一个纬度算一个格子，而不是0.25个经度和纬度算一个格子），&lt;/span&gt;重现了其发现的规律，从而证明了该发现的鲁棒性。&lt;/p&gt;

&lt;p mpa-paragraph-type=&quot;body&quot;&gt;&lt;strong&gt;&lt;span&gt;验证普适性&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p mpa-paragraph-type=&quot;body&quot;&gt;而为了说明该发现具有普适性，需要看看在不同的季节，不同的区域之间，研究发现的规律是否都成立，而本文也做了这方面的研究。&lt;/p&gt;

&lt;p mpa-paragraph-type=&quot;body&quot;&gt;同时在方法学上，由于存在这么多的暴雨事件，而要确定两次暴雨之间是否有同步，需要逐个两两比较，这其中就可能将一些由于随机巧合错当成相关性同步。存在多重检验时，需要进行统计学上的校正，而不止是降低统计显著的P值，这是一个通用的注意点，所有涉及到P值的研究，都要看是否需要对多重检验进行校正。而在本文中，也针对该问题提出了相应的校正方法。&lt;/p&gt;
&lt;section class=&quot;&quot; data-mpa-template-id=&quot;1377480&quot; data-mpa-color=&quot;#ffffff&quot; data-mpa-category=&quot;&amp;#x6807;&amp;#x9898;&quot;&gt;

&lt;section data-mid=&quot;t4&quot;&gt;&lt;section data-preserve-color=&quot;t&quot; data-mid=&quot;&quot;&gt;&lt;section data-mid=&quot;&quot;&gt;&lt;p&gt;&lt;strong mpa-from-tpl=&quot;t&quot;&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;&lt;strong mpa-from-tpl=&quot;t&quot; mpa-is-content=&quot;t&quot;&gt;超幂律分布&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;
&lt;/section&gt;&lt;p mpa-paragraph-type=&quot;body&quot;&gt;接下来展示这篇文章中最重要的一张图，该图说明了极端气候的遥相关不符合幂律分布。&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.5429184549356223&quot; data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-w=&quot;466&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/wibWV1DB7tWIDnjf4EtfFejwpQJmErqCMTw1chibnS9Aszicf0JX4gpBOE0vdh4YFicibvAOraxCFkqTrReqkro0WqQ/640?wx_fmt=png&quot;/&gt;&lt;/p&gt;

&lt;p mpa-paragraph-type=&quot;body&quot;&gt;&lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;/&gt;  图中将暴雨在不同地区的时间序列的数据两两比较后，按P值小于0.001为显著，统计在不同的距离之间，暴雨发生有关系的的概率，图中的纵轴是概率分布函数。在100公里到2500公里之间，在经过了log处理的坐标轴上，概率分布于距离几乎完美的对应到了一条斜率接近-1的直线上&lt;span&gt;（图中左边的虚线）&lt;/span&gt;，按照这个规律，距离越远，暴雨事件同步发生的概率越低。&lt;/p&gt;

&lt;p mpa-paragraph-type=&quot;body&quot;&gt;但超过2500公里之后，幂律法则不起作用了，极端气候的相关性的概率随距离增加变高了，直到一万公里，暴雨的同步效应才再次随着时间降低。&lt;/p&gt;

&lt;p mpa-paragraph-type=&quot;body&quot;&gt;&lt;span&gt;下图是南北半球，冬季和夏季，热带与亚热带分开统计的同步概率与距离的趋势,可以看到超幂律分布都出现了.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-croporisrc=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/wibWV1DB7tWIDnjf4EtfFejwpQJmErqCMnFwG0MicrTicf7gg1d5sD405Peqib5ZyicyTFOH8J74BamPz7NRdT1lPhQ/640?wx_fmt=png&quot; data-cropx1=&quot;0&quot; data-cropx2=&quot;696&quot; data-cropy1=&quot;0&quot; data-cropy2=&quot;499.46762589928056&quot; data-ratio=&quot;0.7169540229885057&quot; data-s=&quot;300,640&quot; data-type=&quot;jpeg&quot; data-w=&quot;696&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/wibWV1DB7tWIDnjf4EtfFejwpQJmErqCMWdEOYgZP2cSfxgYJ0Pqfe7f3IvKEJQ6cnhurQwY6O06WLibE3GYVXbA/640?wx_fmt=jpeg&quot;/&gt;&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;&quot; data-croporisrc=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/wibWV1DB7tWIDnjf4EtfFejwpQJmErqCMqIyHnaRWCo7Jibh2jTObEyL9dsiaT5iaGnt5bLSicMrXWsYOEZpTojicGKg/640?wx_fmt=png&quot; data-cropx1=&quot;0&quot; data-cropx2=&quot;664&quot; data-cropy1=&quot;10.748201438848922&quot; data-cropy2=&quot;494.4172661870504&quot; data-ratio=&quot;0.7304216867469879&quot; data-s=&quot;300,640&quot; data-type=&quot;jpeg&quot; data-w=&quot;664&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/wibWV1DB7tWIDnjf4EtfFejwpQJmErqCMtM7BSXw5EzFlPME7tnqE1BYI8TcOIZXPiaa53UJkOe8kOBsAyTcqKpg/640?wx_fmt=jpeg&quot;/&gt;&lt;/p&gt;

&lt;p mpa-paragraph-type=&quot;body&quot;&gt;2500公里是什么概念，北京到深圳的直线距离是1950公里，也就意味着深圳的暴雨出现的先后和沈阳的同步程度不如深圳和漠河的暴雨，这个发现是不是像蝴蝶效应一样，有足够的有颠覆性？&lt;/p&gt;
&lt;section data-mpa-template-id=&quot;1377480&quot; data-mpa-color=&quot;#ffffff&quot; data-mpa-category=&quot;&amp;#x6807;&amp;#x9898;&quot;&gt;
&lt;section data-mid=&quot;t4&quot; readability=&quot;1&quot;&gt;&lt;section data-preserve-color=&quot;t&quot; data-mid=&quot;&quot; readability=&quot;2&quot;&gt;&lt;p&gt;&lt;strong mpa-from-tpl=&quot;t&quot;&gt;&lt;span&gt;气象领域的”Dragon-Kings“&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;
&lt;p&gt;&lt;span&gt;在过去的研究中，这类现象被称为”Dragon-Kings“，是黑天鹅现象的一种，用来说明为何预测会失败。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;

&lt;p mpa-paragraph-type=&quot;body&quot;&gt;该词来自于Didier Sornette在09年的论文，文中指出了&lt;strong&gt;&lt;span&gt;小处的规律不适用于大处&lt;/span&gt;&lt;/strong&gt;，例如在城市，金融市场，地震等，而背后的机制和沙堆临界原理及混沌现象中的相变有关，而该研究展示了在气象领域的”Dragon-Kings“。&lt;/p&gt;

&lt;p&gt;&lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;/&gt; &lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.3680870353581142&quot; data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-w=&quot;1103&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/wibWV1DB7tWIDnjf4EtfFejwpQJmErqCMgFjlGl6xOacW5j2vMatsic4ibY7tOVK6SUFVaXLHW0jKPs2xjQ6VJicxg/640?wx_fmt=png&quot;/&gt;&lt;/p&gt;

&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p mpa-paragraph-type=&quot;body&quot;&gt;&lt;span&gt;论文地址：&lt;/span&gt;&lt;/p&gt;
&lt;p mpa-paragraph-type=&quot;body&quot;&gt;&lt;span&gt;https://arxiv.org/abs/0907.4290&lt;/span&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p mpa-paragraph-type=&quot;body&quot;&gt;按照Dragon-Kings的理论，可以使用Kernel density预测遥相关出现的概率，而这正是上图右边（超过2500公里后）的实心线，而这与真实数据拟合的也很不错。虽然无法直接用混沌理论解释为何在气候中会出现超幂律分布（需要结合具体场景，例如全球大气的气流循环），但能够和之前的研究有所关联，能够支持并扩展前人的概率，也是好的论文写作必须的。&lt;/p&gt;
&lt;section class=&quot;&quot; data-mpa-template-id=&quot;1377480&quot; data-mpa-color=&quot;#ffffff&quot; data-mpa-category=&quot;&amp;#x6807;&amp;#x9898;&quot;&gt;

&lt;section data-mid=&quot;t4&quot;&gt;&lt;section data-preserve-color=&quot;t&quot; data-mid=&quot;&quot; readability=&quot;1&quot;&gt;&lt;section data-mid=&quot;&quot; readability=&quot;2&quot;&gt;&lt;p&gt;&lt;strong mpa-from-tpl=&quot;t&quot;&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;&lt;strong mpa-from-tpl=&quot;t&quot; mpa-is-content=&quot;t&quot;&gt;案例分析：印度中部的暴雨分布&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;
&lt;/section&gt;&lt;p mpa-paragraph-type=&quot;body&quot;&gt;接下来要对一个案例进行系统性的分析，文中选取了印度中部（南亚及中亚），下图展示了该点的暴雨和全球其他位置的暴雨同步关系的强弱，线越明显，同步的概率越大（图A），在图B，阴影区的深浅标识了这些区域与印度中部的同步概率超过了几个标准差。可以看出其中有很多条超过了2500公里的关联，而且这些关联很多是显著的（超过3-4个标准差，随机出现的概率只有不到0.1%)&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.8107302533532041&quot; data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-w=&quot;671&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/wibWV1DB7tWIDnjf4EtfFejwpQJmErqCMLIPHGgIKtPj3fMLJquP7WiadcOeE4r2PmAEnVPOcVUbsp6SqduypOTg/640?wx_fmt=png&quot;/&gt;&lt;/p&gt;

&lt;p mpa-paragraph-type=&quot;body&quot;&gt;那遥相关之间有没有因果关系了，如果总是一个地方先出现大暴雨，接着是一下个地方，那可以说是两者之间有因果性。&lt;/p&gt;

&lt;p mpa-paragraph-type=&quot;body&quot;&gt;下图展示的是印度中部和欧洲降雨的相关性，黑线代表是欧洲的暴雨是否会引领印度出现暴雨，在正的4-5天上，曲线有一个峰，而在负的8-9天上，也有一个峰，这说明相关性在这个案例上是双向的，不存在单边的因果关系。毕竟地球是一个球。&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.2710382513661202&quot; data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-w=&quot;915&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/wibWV1DB7tWIDnjf4EtfFejwpQJmErqCMYsicgElb2jLRcPwQHpdcicJR6sCRntnZAxsgibiaic0HOXXTjaia58l9yRJw/640?wx_fmt=png&quot;/&gt;&lt;/p&gt;

&lt;p mpa-paragraph-type=&quot;body&quot;&gt;最后再看看该如何解释这一现象，下图bc展示了第0天和第3天欧洲和南亚及中亚（SCA）的降雨情况，可以看到先是欧洲暴雨，3天后到了SCA地区，而d和e图展示了风向，将两张图结合起来，就可以看出是由于风吹起来了，才导致了先后的降雨。&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.3617929562433298&quot; data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-w=&quot;937&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/wibWV1DB7tWIDnjf4EtfFejwpQJmErqCM0s1LibCEDHobAuYxB7zgml6eSd9f2ViamicCOyFyXrWZQOo41yCK8icj0Q/640?wx_fmt=png&quot;/&gt;&lt;/p&gt;
&lt;section class=&quot;&quot; data-mpa-template-id=&quot;1377480&quot; data-mpa-color=&quot;#ffffff&quot; data-mpa-category=&quot;&amp;#x6807;&amp;#x9898;&quot;&gt;

&lt;section data-mid=&quot;t4&quot;&gt;&lt;section data-preserve-color=&quot;t&quot; data-mid=&quot;&quot;&gt;&lt;section data-mid=&quot;&quot;&gt;&lt;p&gt;&lt;strong mpa-from-tpl=&quot;t&quot;&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;&lt;strong mpa-from-tpl=&quot;t&quot; mpa-is-content=&quot;t&quot;&gt;思考延伸&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;
&lt;/section&gt;&lt;p mpa-paragraph-type=&quot;body&quot;&gt;总结来看，该文创新性的将复杂网络引入了气象领域，发现了超远程的关联在极端气候中持续存在。我读完后思考，除了暴雨，酷暑，严寒，以及旱灾等，都可以用该文的范式去研究，我猜测遥相关在气候中不止限于暴雨这一个案例。而如何在气象预报中，应用遥相关，也是值得关注的。&lt;/p&gt;

&lt;p mpa-paragraph-type=&quot;body&quot;&gt;如果说蝴蝶效应让人们开始关注到了远距离的天气现象之间存在相关性，那么这项研究则量化的指出在预测模型中，对多远的现象，根据两者之间同步的概率，应该给予多少相应的关注。&lt;/p&gt;

&lt;p mpa-paragraph-type=&quot;body&quot;&gt;而如果在不同的年份，例如在90年代和进十年间，极端气候间同步的规律有显著的不同，那最可能的解释是人类的活动造成的干扰，而在太阳&lt;span&gt;（黑子）&lt;/span&gt;的”11年“周期，厄尔尼诺现象对极端气候的影响，都是值得探索的方向。&lt;/p&gt;

&lt;blockquote readability=&quot;7&quot;&gt;
&lt;p&gt;&lt;span&gt;注：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;厄尔尼诺现象主要指太平洋东部和中部的热带海洋的海水温度异常地持续变暖，使整个世界气候模式发生变化，造成一些地区干旱而另一些地区又降雨量过多的现象。&lt;/span&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;/&gt; 
&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;1&quot; data-s=&quot;300,640&quot; data-type=&quot;jpeg&quot; data-w=&quot;736&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/wibWV1DB7tWIDnjf4EtfFejwpQJmErqCMRIhtnZU2ySf3jObCxzqibOeVZYStoaWfTKNIwaju1FfeEiaOzy89y61g/640?wx_fmt=jpeg&quot;/&gt;&lt;/p&gt;
&lt;p&gt; 留言精选&lt;/p&gt;

&lt;p&gt;&lt;span&gt;我不认为这是颠覆性的，遥相关这个词本身就是对幂律关系的否认，在大气科学领域是种普遍存在的现象，很多类似的遥相关已经被发现，比如enso，北极涛动等。分析方法通常是EOF即主成分分析。这篇论文应该说是在分析方法上创新，更定量了。btw，还没看什么是complex network。另外，地理统计学的方法也是研究空间相关的一种传统方法，有个地理学第一定律是其理论基础，简单讲是距离上越近的东西越相似Everything is related to everything else, but near things are more related to each other.显然大气现象不符合，但并不颠覆。我认为遥相关背后的基础是大气长波的存在，当然大气中有不同周期的波。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;更多阅读&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651383791&amp;amp;idx=1&amp;amp;sn=8d64cb59ba4d52cad925858badc4cdb3&amp;amp;chksm=84f3c9aeb38440b8856c467faa2c0786c7b97168f38e9e47b5aa92221a6d2dfa256f1bcfff9d&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-itemshowtype=&quot;0&quot; data-linktype=&quot;2&quot;&gt;Science重磅：“要想成功，快抱大腿！”&lt;/a&gt;&lt;br/&gt;&lt;/p&gt;
</description>
<pubDate>Sun, 24 Feb 2019 07:52:43 +0000</pubDate>
<dc:language>zh-CN</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.jintiankansha.me/t/QkOJZ4teYL</dc:identifier>
</item>
<item>
<title>AI最小入门指南（二）-- 人工智能简史</title>
<link>http://www.jintiankansha.me/t/faWzusH9s2</link>
<guid isPermaLink="true" >http://www.jintiankansha.me/t/faWzusH9s2</guid>
<description>&lt;p&gt;&lt;strong&gt;人类探索人工智能的初级阶段：基于规则运行的机器&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;我们这次的讲座从一个图片开始， 这张图片，记载了一个历史上非常有名的会议，叫做达特茅斯会议(Dartmouth Conference)&lt;/p&gt;
&lt;p&gt; &lt;img class=&quot;&quot; data-ratio=&quot;0.7363636363636363&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz/dcEP2tDMibce3GnvDlNCSjsGosHtINzN4F91ibRrKq5Uk6koNGbd9rib9NiapY6LibqcX9ia1kQon9KajfMQLdC6MJ6Q/640?wx_fmt=other&quot; data-type=&quot;other&quot; data-w=&quot;550&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;2006年，会议五十年后，当事人重聚达特茅斯。&lt;/span&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;这个会议上面坐的几个人物，堪称人工智能早期的奠基者。有shannon， minsky，司马贺等人，像这样的场景，人类的历史也没有几个，也许你会联想起物理学史的索尔维会议。但是肯定举不出三四个。为什么，这样的人物会在这个时间，齐聚一堂？他们的中心议题只有一个，人能否制造出像人类一样思考的机器， 这个人类的终极梦想。&lt;/p&gt;

&lt;p&gt;我们来从头开始， 还原这个故事。首先，智能， 智能是什么， 智能有哪些形式？也许你还会继续问， 如果人有智能？ 动物有没有？ 如果我们理解了智能，是否能够造出一个会思考的机器？ 这些问题， 我们都要回到智能的定义开始。 智能是什么？ 笼统的说智能是解决复杂问题的能力。无论是逻辑，还是语言， 还是运动， 本质上我们都在解决和生存息息相关的问题， 虽然我们从中发展出的技能有时远超那个原有的任务。    &lt;/p&gt;

&lt;p&gt;和智能有关的词语， 逻辑推理， 计划决策，学习应变，形式在多样，离不开的是， 解决问题， 简单到去寻找下一顿猎物， 还是众多异性里寻找配偶， 复杂到设计一个计划成为群体的领袖， 有了一个目标， 我们需要在环境条件进行行动，随机应变， 直到达到目标。  &lt;/p&gt;

&lt;p&gt;当然， 我们身上的这种能力有时候已经到了接近本能的地步， 我们已经并不能说出我们为什么会说话，或者看出那个人是我三天前会上见过的教授。如果回溯历史， 我们会发现，人的智能，主要可以归纳为语言和逻辑计算，通过这两个东西把一个复杂问题变成可以求解。我们通过理解事物（认知）来进行有效决策， 然后使得事物向着对我们有利的方向发展。&lt;/p&gt;

&lt;p&gt; 想象你在手中转动一个魔方， 你通过一系列的转动， 把它向着接近你目标的方向变化，直到得到最后的结果。  那么， 机器是否可以做类似的事情呢？   一个有效的假设是机器需要具备和人类似的东西， 也就是把一般问题求解的过程抽象出来就可以模拟智能。&lt;/p&gt;

&lt;p&gt; 在这方面做出伟大的贡献是阿兰图灵， 它认为存在这样的通用机器，能够和人类一样解决问题， 这就是图灵机的概念， 如果你需要实现这个， 无非需要四个要素： 1， 输入  2， 中间状态 3， 规则表  4， 输出  &lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.752&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibce3GnvDlNCSjsGosHtINzN4ZO9f7rZjvnAXiavt30SVHH5W0M4kaEIMVTZS8yLCgerszU6NDNZNDVQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;500&quot; /&gt;&lt;/p&gt;
&lt;p&gt; 机器的原型可以看做一个足够大的纸带， 纸带上有很多格子，格子上或者涂成黑色或者涂成白色，上面有一个机械昆虫可以在格子上跑来跑去， 我们就简单的假设成左右吧。  至于它是想往左跑还是往右跑， 在最简单的情况下只取决于纸带它所在位子的格子是黑还是白（输入），我们就假设白右左黑， 那么这条虫子就会无休止的左左右右循环下去， 外人看上去很像一个无休止的运动的小虫。&lt;/p&gt;

&lt;p&gt;显然这是一个毫无用处的数学游戏， 但是， 当我们给这样一个简单的模型加入两个东西，一个是中间状态， 一个是规则表，一个是虫子也可以改变外界环境（纸带）， 那么整个故事就大不一样。 比如我们规定虫子有个内在的状态， 就是饿与不饿， 然后根据他的这个内部状态，它可以对纸带施加不同的作用，见到白色的格子， 如果是饿了，就给他涂黑， 如果是饱了，就什么都不做， 一旦涂黑之后他的状态就由俄变成饱，而他走到黑子又会变成俄。 那么我们会看到一个什么图景？这样，游戏就会表现出一些真正复杂的模样， 纸带自身也开始变化， 再某个时刻， 纸带可能变成全黑， 而虫子也最终停下。&lt;/p&gt;

&lt;p&gt; 如果我们也可以给虫子指定不同的规则，比如饿的时候白左黑右， 饱的时候白右黑左， 他就可能会表现出任意复杂的运动来， 甚至表现的真的像一个在思考的虫子。为什么这样的虫子可以解决问题？  还记得我讲过得算法得概念吗？  我们可以想象一个最终要达到的状态，然后我们需要做的无需是设定这样一个过程， 使得通过若干步骤，得到最后这样一个结果。想下排序算法！    &lt;/p&gt;

&lt;p&gt;如何设计这样一个过程呢？ 这里面蕴含的真正思想，是可编程理论。&lt;strong&gt;问题的中心是那张规则表。输入和内部状态， 经过规则表得到一个行为， 行为改变了环境， 得到下一个状态，&lt;/strong&gt; 如果规则表设计的好， 我们几乎表达任何问题解答过程。&lt;/p&gt;

&lt;p&gt;为什么说很复杂的问题， 通常可以设定为一个比较简单的流程， 然后流程可以简化为一个规则表呢？简单的说， 因为复杂是简单中产生的，  一个简单的规则， 通过很多步骤， 就得到复杂。 一个非常有趣的例子是元胞自动机， 它可以极好的阐述一个简单的规则如何产生极为复杂的图案。  这个机器的原理是， 你有一个由无限多方格组成的纸带，在这个纸袋上，有一个细胞（黑色方格）开始生长繁殖， 扩散， 它的繁殖扩散原理非常简单， 因为假定它的行为只取决于周围两个方格的情况， 具体怎么决定的， 由一个规则表表示， 按照这个规则表，经过一定时间，这个细胞就会变成一个群， 这个群的形状可以很简单， 也可以任意复杂。 这个游戏用来阐述复杂是由简单产生的， 再复杂的现象， 都是简单的规则随时间推衍产生出来的。&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.7072368421052632&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibce3GnvDlNCSjsGosHtINzN4e5afZccgRz1y4eyMwQa76Qg3tyJX4Y6RCr7qzzZ0IpwricibuUocIwOw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;304&quot; /&gt;&lt;/p&gt;

&lt;p&gt; 如果你理解了这个原理， 你就会理解智能到底是什么， 我们为什么能够解决复杂问题，因为我们事实上用到了这个过程的逆过程， 我们有一个最后想要的结果比如娶得某国公主，然后由个初始状态比如你是一个贫困大学生，  然后你需要能够把它分解为一系列中间步骤，然后通过设立一套简单的规则达到那个最终结果， 如果真的实现了， 一个复杂的问题就解决了。 小到玩魔方，大到治理国家， 都可以用类似的方法解决。 &lt;/p&gt;

&lt;p&gt;比如魔方，如果你去随便的转动， 立刻就会疯掉。 但是， 这个问题存在一套非常固定的规则表（tetris）,  它对应有限个状况下的有限种操作。  就如同计算机程序的if， else语句， 在遇到什么色块的时候你要怎样转动， 只要按照这个简单的规则执行， 最终一定可以走出来。 而治国这样复杂的大问题，也无非是遵循有限的几条规则（不同的国家， 会把这个东西记载在不同的经典里， 从论语， 到自由大宪章）。&lt;/p&gt;

&lt;p&gt;上面的例子让我们可以感觉到规则机器的力量? 如果我们能够有效的获取人类总结的规则， 让机器来使用， 那这个机器不就实现了智能？ 这样的想法将导致人工智能的第一个霸主- 专家系统。 那么这套规则的存储形式是什么呢？  知识！ 各个学科的知识库！  人类几千年的解决问题的智慧是以知识的形式存储起来的， 有的知识， 以语言的形式保存， 有的，被一些逻辑或数学符号连接。&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.7724137931034483&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibce3GnvDlNCSjsGosHtINzN4EMnweBTefx25MDmy95pUS8MogFMiagxXweyGd3WQzry0JNsHWXhGLUw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;290&quot; /&gt;&lt;/p&gt;

&lt;p&gt;人是智能的， 首先在于人能够按这套规则， 在不同的情况下做出反应，解决掉问题！ 比如己所不欲勿施于人， 或者以牙还牙以眼还眼， 或者门当户对， 或者春捂秋冻， 都是这个规则表的形式。 放到那个刚刚说的图灵纸袋上， 说不定那个小机器人就能像我们一样在社会里拼杀，解决从小到大的任务！  所以， 直接模拟这套知识组成的规则系统， 就成为人类所认为的模拟智慧机器的第一步。我们把这些人类的知识和规则直接输送给所谓的智能体， 让它直接利用这人类几千年的知识来运行， 应该就可以解决各行各业，甚至所有的复杂系统。    这个想法导致专家系统的产生， 做这个系统的人， 通常称之为知识工程师。&lt;/p&gt;

&lt;p&gt;6，70年代的知识工程师试图把人类所有领域的专业知识一条一条的输入给计算机，从而解决这个世界所有只有人类才可以解决的问题。 如果你去了解早期的人工智能系统， 你会了解到Elisa这种语言机器人，还可以了解到xcon的公司， 给美国工厂制造知识系统。 而知识工程最狂野的梦想， 以一个称为cyn的机器，它试图把人类所有的知识输入到这个机器里， 然后这个机器就可以达到人一样的智能状态。&lt;/p&gt;

&lt;p&gt; 应该说， 在有限的情况下， 可以说它们的表现真的非常接近人类。知识机器参与到医学诊疗这样的复杂过程，并在某些特定领域表现超过人类。 可惜这个流派在长期的努力里，能够作用的事情非常有限。这样的企图最终失败了。&lt;/p&gt;

&lt;p&gt;你能猜到这个失败的原因吗？ 真实世界的情况太复杂了！而且能够被知识和规则所表现的，只是冰山浮出水面的一角。 还不要说那无处不在的随机性。 人类语言和数学符号表达的那部分知识， 在真实世界就是碰壁。 不要说想象约会这样复杂的情况。 就是让一个机器人走到房子外500米处给你倒垃圾， 你觉得你需要写多少人类的知识法则作为基础？ 比如遇到行人让一下， 遇到车辆让一下， 垃圾满了换一个这些，都是极为局限的情况了（再比如如何判定秃顶）。   再复杂的专家经验，也无法穷举无限的可能性，再细致的规则， 也无法表达那些连人都难以表达的规律，一旦真实情况超出了专家系统已经写入的可能，机器就抓瞎了。不要说应对变化的规则。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;二 会学习的机器&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Ok ， 怎么办， 我们要让机器学习到人类应对这种情况的本质-学习！  像人的头脑一样学习，能够从大量的经验里学习总结，从经验出发解决未出现的问题！ &lt;/p&gt;

&lt;p&gt;首先， 什么是学习， 我们理解学习的本质概念吗？ 你可能想说， 学习，就是变化， 对呀， 学习前后的你肯定是不一样的， 经过学习后，你的能力更强大， 你的知识更丰富。你是怎么学习的呢？ 读书？  根据经验学习？&lt;/p&gt;

&lt;p&gt;我们来展开上帝视觉， 从三个不同的角度看学习。&lt;/p&gt;

&lt;p&gt;伟大的希腊哲学家早就对学习的本质展开过探讨， 它们把学习分类为&lt;strong&gt;归纳法和演绎法&lt;/strong&gt;。苏格拉底是人， 人都是会死的， 因此苏格拉底会死。 这就是三段论， 或者称为演绎法的根基。 那么什么是知识呢？  人都是会死的就是知识。 如果我们把这个规则输入进去 ， 让机器给出一个答案， 那么这个过程就是刚刚讲到的专家系统。这显然不是学习，  那么反过来呢？ 反过来， 就是学习。我们先知道一个特例， 然后通过特例，得到这个“人都是会死的” 知识， 再指导自己的行动。 学习是知识在脑子或者机器里面形成的过程， 怎么形成？ 这个过程被称为归纳法，也就是根据搜集到的特例比如苏格拉底死了这个事情，来归纳更一般的知识。归纳法， 我们来看我们需要提供给机器怎样的佐料来解决这个问题。&lt;/p&gt;

&lt;p&gt;我们想象这样一台机器， 这个机器和之前说的规则机器类似， 唯一的区别是， 我们把大量的假设放在那里，让机器来连线。  我们要让它学习一个知识， 比如-什么人是否会死的。我们把人按照几个特征进行分类， 一个特征对应一个问题， 比如是否是哲学家， 是男还是女， 是白种人还是黄种人。 这些特征， 都对应会死或不会死这两个结论。 这样，你会得到多少个假设呢？  组合数学告诉我们16种， 于是学习的任务就是给这16个假设和真或者假连接起来。 一旦一条线连起来， 我们就得到了一个新的知识，可以被用于在真实的世界做判断！ 就和之前说的规则机器一样。&lt;/p&gt;

&lt;p&gt;我们首先给这个机器灌入所有的可能性， 那16种假设。 然后我们让机器来收集案例！   比如机器收集到一个苏格拉底死了， 那么苏格拉蒂是什么？ 男性，白种人， 哲学家，  于是机器得到男性， 白种人， 哲学家，会死。 于是机器给机器输入亚里士多德， 柏拉图， 大卫休谟，机器都会告诉你会死。然后我们继续收集样例， 比如居里夫人死了， 然后机器会得到女性，白种人， 非哲学家，死了。 这样它能够做的判断就又多了很多！  这样的思维范式，就是归纳法，由于我们列举的假设依然用到了人类已有的知识， 因此我们得到的这个机器，事实上是最接近规则机器的一台学习机， 我们可以称之为规则为主体的归纳法。我们直接把规则转化为了可以学习的对象。输入样例，得到一个是非的知识， 这个样例我们换个词叫数据， 这个机器我们换个词– 叫做分类器。&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.5903614457831325&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibce3GnvDlNCSjsGosHtINzN4ChMuwb9PMic4SIfHWzLXbZRAZILCAEFjllCeiaRmaeGXIgqefLmjSpzA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;332&quot; /&gt;&lt;/p&gt;

&lt;p&gt;我们把关于这个世界的互相矛盾的假设都丢尽机器。当然，事实上这个问题没有那么简单， 因为组成一个问题的假设可能成千上万。比如刚刚那个什么人会死的问题， 构成人的维度太多了， 远非三个，  比如年龄， 身高， 体重， 学历， 然后你要把所有的组成， 也就是这些特征所有不同的组合都做出会死或不会死的假设，再用刚才的统计机器的思路收集正负样本进行测试， 你看即使每个特征只有两个值， 你要验证的假设有多少个？（你立刻会感到指数爆炸的力量！ ）这种假设的数量随着问题的复杂度急速指数上升的过程，我们称之为维度灾难。一种极端的情况是，你要把所有的地球存在过的人都输入到电脑， 它才可以学会判断什么人会死， 这样构建的学习器显然失去了任何作用。  &lt;/p&gt;

&lt;p&gt;&lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;&gt;&lt;/ins&gt;  所以， 整个后面的机器学习工作， 都在围绕解决这个灾难。 显然， 一个好的学习器需要可以从比较少的样例里， 得到能够判断比这些样例多的多的结果，这个通常称为&lt;strong&gt;泛化能力&lt;/strong&gt;， 就好像一种推而广之的能力， 一个好的学习者， 还是一个好的学习器， 都是要有这种能力。  &lt;/p&gt;
&lt;p&gt; &lt;img class=&quot;&quot; data-ratio=&quot;0.7445945945945946&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibce3GnvDlNCSjsGosHtINzN4XExqvasWticuD9ehaBQuFeiazL5LEfoMicN72hz0eQJEZpp4IqichpMVAA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;740&quot; /&gt;&lt;/p&gt;
&lt;p&gt;机器学习学家为了这个做足了功课， 让我们有一些方法， 比如我们后面会细讲的决策树，这个方法非常接近刚刚说的那个把很多特征放在一起，构成不同假设后连线的问题， 但是它使用了一个关键性的知识， 那就是，不同的特征处并非平等，比如男性和女性， 很可能比哲学家有更重要的影响， 如果我们能够按照特征的不同等级做分组， 就可以极为轻松的解决这个问题，比如我们能够判断出男女是判断生死最终要的特征，男人都会死， 女人需要做进一步判断， 那么一瞬间，我们就解决掉了一半的假设， 只要是男人， 我们就和会死连在一起就好了。   &lt;/p&gt;

&lt;p&gt;我们用于归纳的数据永远是部分的真相， 最终在算法的使用阶段所遇到的数据却永远是新鲜的，这个问题， 归根到底， 就是机器学习的过拟合问题， 而它的根源，确是归纳法本身的问题， 就像尼古拉斯塔勒布的黑天鹅一样，你永远不会知道明天你的池塘是否会飞起一个黑天鹅，从而把你刚刚学到的天鹅都是白的假设给推翻。&lt;/p&gt;

&lt;p&gt;大家注意，上述这套思维本身是有局限性的。因为很多假设并非非黑即白。 可能我们继续收集数据， 发现又有一个叫xx的哲学家白人男性没有死， 这个时候机器不就傻眼了？ 这就是刚说的规则连线法的致命弱点， 落下了一个可能的解决方法就是概率。&lt;/p&gt;

&lt;p&gt;既然有限的数据无法得到一些肯定的答案，某个事实对或者不对，那为什么不给那些模棱两可的假设留下一些空间呢？ 我们保留所有可能的假设， 不要扔掉它们， 最初，我们给每个假设设定一个成立的可能性， 这就是概率（由于是学习前的概率，叫做先验概率）， 然后， 一旦数据到来， 我们不像之前一样直接给出连线得到是否， 而是调整这个概率。 你脑子里把这个概率想象成一个小红线， 小红线越长代表概率越高，如果这个答案支持这个假设，我们就把这个小红线拉长一条，代表我们更肯定这个假设是正确的， 这就是&lt;strong&gt;贝叶斯方法&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.6507936507936508&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibce3GnvDlNCSjsGosHtINzN4g0uc17cX0MZuBBLCyDyAgq6GUyqRPJm6BH6HZ4vibFR5DEVKWpZDtLw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;315&quot; /&gt;&lt;/p&gt;
&lt;p&gt;贝叶斯神父早已在两百多年前想到的这个方法， 可以说构成了机器学习的另一大基础流派，就是贝叶斯派。贝叶斯派试图把特征条件，到他们引发的结果， 用概率的箭头连接。 然后我们就得到了一个无比巨大的条件之间互相连接的关系网络，又称贝叶斯网络， 用这个方法，我们可以世界万物的联系浓缩进去， 比如刚说的白人， 男性，哲学家现在变成了被连接起来的三个方块，最后一个会死也一样，  这三个特征加上结论互相影响。 白人男性，可能比白人女性更容易是哲学家， 而这三个条件又在影响是否会死，我们通过不停的收集数据来修正每个小红箭头对应的概率，直到这个网络变得稳定和完美，它就可以源源不断的告诉我们事实。  &lt;/p&gt;

&lt;p&gt;人是极其的不擅长概率性思维的生物， 贝叶学派的人工智能，把学习的过程看作一个由结果推测原因出现概率的过程， 这样就可以得到一个规则的集合。 这一类学习方法， 事实和开始的符号推理某种程度是殊途同归的， 只是在此处， 我们更看重统计的概率。&lt;/p&gt;

&lt;p&gt;我们再次回到学习的本质。 刚刚说的归纳法和演绎法， 是古希腊哲人对学习的理解。而后来人对学习的理解则是完全不同的。 尤其是在生物学起步之后，达尔文的进化论， 到脑科学的出现， 人们开始从生物本质来研究学习是什么。 既然学习是人脑的专长， 那么我们是不是可以模拟人脑的物质基础，来实现学习， 或者说， 做一个机器大脑！&lt;/p&gt;
&lt;p&gt; &lt;img class=&quot;&quot; data-ratio=&quot;0.6661538461538462&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibce3GnvDlNCSjsGosHtINzN4VyICsZuoYToMtHG3ZdpOwUZ5DyibupFQtakRswXvUs5Em2xEibHrFBdQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;650&quot; /&gt;&lt;/p&gt;
&lt;p&gt;这是有可能的， 而且导致了机器学习的第二大分支， 连接主义。  连接主义认为， &lt;strong&gt;信息和概念存储在大脑的突触连接之间， 特定的连接形式对应特定的知识。&lt;/strong&gt; 如果我们要让机器能够学习， 就是要让它能够通过学习大脑的连接，来掌握特定的知识。  &lt;/p&gt;

&lt;p&gt;神经元是如何组织的这件事子啊很长时间对人类过于复杂，直到50年代的一天，一个叫hebb的老头提出了一个怪异的想法：人脑是一大堆神经元的网络，而网络权重可以随着自身活动变化，一起放电的细胞会加强彼此的联系，更加容易一起放电：  Hebb学习规则的结果是使神经网络能够提取训练集的统计特性，从而把输入信息按照它们的相似性程度划分为若干类。这一点与人类观察和认识世界的过程非常吻合，人类观察和认识世界在相当程度上就是在根据事物的统计特征进行分类。&lt;/p&gt;

&lt;p&gt;举个简单的例子， 说明， 学习， 就是改变连接。第一个是巴甫洛夫的条件反射实验：每次给狗喂食前都先响铃，时间一长，狗就会将铃声和食物联系起来。以后如果响铃但是不给食物，狗也会流口水。你怎么用hebb法则解决这个问题？ 假定铃声检验对应一个神经元， 食物检验对应一个神经元，  分泌口水对应一个神经元， 一开始食物检验可以引起口水， 但是我们每次给食都有一个铃声，记得一起活跃的神经元连接加强吗，铃声和口水经常一起活跃， 于是它们的连接就加强了。   下一次， 只有铃声， 没有食物， 狗也开始分泌唾液了。  &lt;/p&gt;

&lt;p&gt;我们来看看最早的把连接主义引入机器学习的尝试。 最早的连接主义尝试是模拟大脑的单个神经元， Warren McCulloch 和 Walter  Pitts  在1943 提出而来神经元的模型， 这个模型类似于某种二极管或逻辑门电路。 一定的输入进来，被神经元汇集加和， 如何这个和的总量大于一个阈值，神经元就放电， 小于一个阈值，神经元就不放电。   这个东西就好像某个微小的决定装置， 把很多因素加载在一起， 做一个最终的决策。 我们想象无数的二极管可以构成一个计算机，那么无数这这样的神经元不就可以构成一个具有计算功能的大脑吗？ 这就是感知器的概念。  好了， 这里哪来的学习功能呢？&lt;/p&gt;

&lt;p&gt;单个感知器的学习功能确实很弱， 原因在于，我们没有真正的多个神经元之间的连接。当然， 这里也不是没有可以学习的东西，比如对不同输入的权值是可以调节的。&lt;/p&gt;

&lt;p&gt;还记得我刚刚说的学习就是改变连接（权重）吗？ 假定我们要学习辨析两个概念，一个是苹果， 一个是香蕉，还是刚刚的方法， 我们通过一定的特征， 组成一些假设， 比如颜色和形状， 我们颜色只取黄色和红色， 形状只取圆型和长形， 然后结论是苹果或者香蕉。由此我们会得到8个假设。 然后我们要构建一个感知机对它进行判断。 假定感知机被连接到这四种输入特征上，  然后我们需要输出一个数， 来做判定， 一开始4个连接权重都是1，  并且我们给每个特征的值都设为1. 假定我们给它很多红苹果和黄香蕉的数据样例，  让它来判断， 一开始当然机器给出一样的数字完全无法判断。经过学习呢？ 那个对应黄色的权重会逐步调整为-1， 对应长条形的权重也会逐步调整成为-1， 这样经过一段时间， 香蕉呈现给这个感知机，它会给出-2， 苹果， 它会给出+2， 只要我们设定为大于0输出苹果， 小于0输出香蕉， 那么这个机器就可以判定苹果和香蕉了。&lt;/p&gt;
&lt;p&gt; &lt;img data-ratio=&quot;1.6111111111111112&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/jrbyyXzrKkJqzpvQ60VcjgiacFu21XHHubic1vJveCSZ6PHEDDyJd1LZhn3z6ibqmBehPbx0icZx0ZXosoBaXWceQw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;360&quot; /&gt;&lt;/p&gt;
&lt;p&gt;不过你很快会问万一出现几个黄苹果呢？ &lt;/p&gt;

&lt;p&gt;假定我的输入是三个要素， 今天的天气， 我的心情，  外面活动的人数来决定我去不去公园， 那么这三个要素对我决策的重要性就是我学习的目标，没有其他的了。那么此处学习的本质， 就是学习权重， 学习的方法， 依然是之前讲到的， 从特例里学习， 我们可以给定一个初始化的权重， 和一个惩罚函数。 我输入给这个网络一个不同天气情况， 心情， 活动人数， 我去没有去公园的数据， 这个时候感知器对每个情况下我最后去和没有去公园做预测，如果预测错误， 惩罚函数就会发生作用， 指导我向正确的方向调整权重， 就是学习的过程。&lt;/p&gt;
&lt;p&gt; &lt;br /&gt;&lt;/p&gt;
&lt;p&gt;事实上， 人们很快发现感知机的学习有巨大的局限性， 我们很快发现它连抑或这样基本的逻辑运算都无法执行，也就开始对他心灰意冷。  对感知机的失望导致连接主义机器学习的研究陷入低谷达15年， 指导一股新的力量的注入。&lt;/p&gt;

&lt;p&gt;这个新的力量， 来自一群好奇心极强的物理学家，在20世纪80年代， hopefiled提出了它的hopefield网络模型，这个模型受到了物理里的ising模型和自旋玻璃模型的启发，Hopefield发现，自旋玻璃和神经网络具有极大的相似性。 这些听起来是鬼话， 你可以这样理解， 这个模型里又很多的神经元，每个神经元可以看作一个个微小的磁极，它可以一种极为简单的方法影响周围的神经元，一个是兴奋（使得其他人和自己状态相同）， 一个是抑制（相反）。  如果我们用这个模型来表示神经网络， 那么整个问题变得极为简单。&lt;/p&gt;

&lt;p&gt;因为物理学家已经求解过自旋玻璃模型， 所以很多结论都可以直接套用到神经网络里面来。比如说自旋玻璃有个能量的概念， 大家不要慌张， 这个能量的概念无非说的是我们可以把磁极之间的相互作用总量表示成为一数学量。  然后物理学家直接剖出，系统要呆在能量最小的状态才稳定， 这样， 我么就直接得到那些最稳定的神经元活动态， 这是一种非常特定的状态。 就好像操场上训练的哨兵， 每个人都整齐划一的迈着正步，我们用一个词“模式”来形容。  这个整体的模式有什么作用呢？ 我们发现它可以表示和记忆信息！ &lt;/p&gt;

&lt;p&gt;比如说吧， 我要识别某些图片是否属于一个人的脸。你把这个图片用某个方式输入到这个网络里，刚不是说了网络会到达一个特定的状态吗，刚刚好，对应于同一个人脸的照片会导致神经网络到达一个同样的集体状态， 你想象你的照片引起那些神经元用一个姿态迈着正步走， 那么， 你的信息就算是被网络表征和记忆了， 这个网络具有了学习能力！&lt;/p&gt;

&lt;p&gt;这套想法的威力在于， 我们发现了问题的本质， 可能在于神经元的数量，即使每个神经元的能力已经愚蠢至极了， 只要我们能够有足够多的神经元，它也可以干很复杂的事情。这个想法， 引起了神经网络研究的一股旋风， 人们从不同领域开始涌入这个研究。有的人想用这个模型研究人脑， 有的人想用这个模型制造机器大脑， 前者派生出了计算神经科学，后者则导致了联结主义机器学习的复兴（研究猫的和研究机器猫的）。 这批人物里， 有个心理学进来的小伙子叫辛顿， 在漫长的时间里， 它将会把连接主义推向一个新的高潮。&lt;/p&gt;

&lt;p&gt;在漫长的联结主义低谷期， Hinton坚信神经网络既然作为生物智能的载体， 它一定会称为人工智能的救星， 在它的努力下， Hopefield网络很快演化称为新的更强大的模型如玻尔兹曼机， 玻尔兹曼机演化为受限玻尔兹曼机， 自编码器， 堆叠自编码器。算法的进步更多体现在学习方法的改进。 信息存储在无数神经元构成的网络连接里， 如何让它学进去， 也就是最难的问题。 一种叫反向传播的方法60年代就开始出现， 在hinton等人的持续改进下， 终于开始发挥作用，并逐步统治。 它的意思其实是把学习理解成为一个巨大的根据数据来优化的过程， 数据犹如一颗颗子弹打进来， 如果神经网络的预测错误 ，它就会在网络的连接之间一点点的引导网络权重的改变，虽然每次只改一点点， 最终当数据的量特别巨大，却发生一场质变。&lt;/p&gt;

&lt;p&gt;但这还不是全部， 人类很快从模拟人类大脑里汲取更多的养分，来辅助我的人工智能，比如说视觉识别，越是简单的事情， 我们越说不清自己是怎么想的， 我们唯一能做的是打开视神经， 把视神经的细节一一的融汇到神经网络里， 由此诞生了CNN和整个深度学习模型。&lt;/p&gt;

&lt;p&gt;当然，这只是这个故事的一部分，这个故事的另一部分， 是计算机硬件的进步，从原始的计算机， 286， 386 到奔腾， 到GPU计算，一次次的硬件突破，使得大规模的使用BP算法进行优化成为可能。 另一方面， 几个和hinton一样执着的人，一点点的在那里收集数据， 它们建立了一个叫Imagenet的数据库， 这个数据库收集了整个互联网的图像， 期待机器有一天能够理解它们。它们，与算法革命一起催生了深度学习革命。&lt;/p&gt;
&lt;p&gt;&lt;img data-ratio=&quot;1.0166666666666666&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/jrbyyXzrKkJqzpvQ60VcjgiacFu21XHHuFYrqltaPicLd3e23jyQPBrLHqMDU3s3zvC2Aaq6hicssOlvOfwSshyKQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;240&quot; /&gt;&lt;/p&gt;

&lt;p&gt;在这场革命的催生下， 机器不仅能够学习推理， 而且开始接管人类最重要的一种能力-直觉。 机器能够在图像中识别出猫狗， 你和我， 甚至也可以看出一个人的情绪。 能够掌握直觉， 正式深度学习最反直觉的地方。 构成我们决策的大量因子， 其实是我们自身都无法描述的隐形知识， 抑或直觉， 这些， 能够被神经网络学习。在此前连人自己都不理解是怎么发生的。&lt;/p&gt;

&lt;p&gt;CNN一旦出现就开始疯狂生长， 自从在Imagenet上对图像识别夺冠并出现人类 ， 网络越变越深， 出现了一个个名字怪异的新网络，如残差网络，谷歌网络这些， 而它们也一步步潜入那些人们起初没有想到的领域，比如语音识别， 甚至下围棋。而深度学习另一条主线， 沿着让机器听懂人类的语言， 一种叫LSTM的神经网络， 模拟了人类最奇妙的记忆能力， 而开始逐步的替代人类承担起类似翻译的作用。&lt;/p&gt;

&lt;p&gt;好了， 连接主义暂时段落， 我们继续沿着学习的本质来看还有哪些机器学习的流派。&lt;/p&gt;

&lt;p&gt;&lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;&gt;&lt;/ins&gt;  要真正的掌握人类的智能， 我们需要从硬件层面突破，这个突破的方法就是模拟人脑的结构。我们需要先研究人脑的结构， 尤其是智能组成的基础， 人脑神经网络来达到这点。我们刚刚谈到了模拟生物学习来实现人工智能。 事实上除了模拟大脑的算法。 还有一种更为本源的想法就是&lt;strong&gt;进化&lt;/strong&gt;论。 事实上， 整个由达尔文提出， 经过一两百年发展的进化论可以看作一种学习算法，只不过它在绵长的时间里所进行的，而且是被动型的学习。&lt;/p&gt;

&lt;p&gt;我们来看这个算法的细节以及为什么：&lt;/p&gt;

&lt;p&gt;首先生物的行为无论是否是大脑决定的必然都有其基因基础， 还记得我们之前说的图灵机吗？生命可以表达成为一大堆不同情况下的行为规则，这一堆行为规则其实就是DNA。 每一个碱基对如同规则表的字母。  进化算法就是对这套规则系统的学习和优化。学习的实现通过几步来实现：  1， 遗传， 亲代可以把编程传给子代   2， 变异， 这个过程中一些随机性因素导致编码变化  3， 性：  编码进行交叉  4，  环境不停改变  5， 自然选择， 合适的基因被挑选。  这样， 经过极为漫长的时间， 我们总可以得到一张适合的规则表。&lt;/p&gt;

&lt;p&gt;这就是自然里面， 以复杂制服复杂的方法， 再聪明的个体，也无法穷极变换无穷的环境的所有可能， 而自然挑选的进化算法虽然缓慢， 得到的物种却可以天衣无缝的嵌入环境。  我们可否师法自然把它用于学习算法呢？ 当然可以，我们几乎完全照搬上面的方法， 就可以得到一种和自然进化类似的算法，这一套方法可以教计算机得来几乎和人的运动类似的行为模式，也可以帮我们找到最佳的宏观经济调控政策。   &lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;1.222&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibce3GnvDlNCSjsGosHtINzN4mz72ticKkT97uufzQfUKPibhCVGIKl7wF9O1UWwFbtjsr8vasDM7gR2w/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;500&quot; /&gt;&lt;/p&gt;

&lt;p&gt;连接主义和进化算法分别代表了师法自然的两个不同流派，两者并行又相交。所谓相交， 两者一旦结合， 会产生更大的威力。 因为&lt;strong&gt;进化算法擅长的是做非常大尺度的变化&lt;/strong&gt;。比如进化， 可以把线虫一步步变成复杂的人类。但是缺点是效率低下， 要知道这个过程自然可是要用数十亿年。 而连接主义的神经网络， 要学习一套规则表示的速度要快很多 ， 因为它所用的BP算法， 好比不停的瞄准远方的靶子射击的过程， 你每次看到你的子弹离靶心的距离， 从而可以不停的调整枪位， 但是连接主义的方法需要一开始规定好网络的结构而不可以做更大规模的改动。如果用进化算法来设计网络框架， 再用BP来得到好的连接，这个过程就好很多了。 这也是自然先通过进化得到人类， 再让人类通过自己的头脑得到更复杂的知识和组织的过程。&lt;/p&gt;

&lt;p&gt;还有一个重要的思路来源于仿生的学习流派， 就是&lt;strong&gt;强化学习&lt;/strong&gt;， 这个学习流派说的：动物的学习多经过行为反馈， 它做出一个行为， 如果行为得到好的结果，这个行为就要被加强， 如果是坏的结果， 就要减弱。 这可比先要传递自己的DNA，在被自然选择的进化算法来的快多了。直接模仿这个思路的学习方法就是强化学习。 这个思路威力巨大，因为它解决了处在智能中心位置的决策问题，  一旦和连接主义碰撞， 就诞生了如今最强大的人工智能作品，阿法狗和阿法元。&lt;/p&gt;

&lt;p&gt;人工智能的这些不同的流派， 既来源不同， 又互相交叉。 那么， 一波三折的人工智能里， 当家花旦是深度学习， 这个来自连接主义学派的极大成之作。 然而即使是那些我们完全称之为深度学习的算法，也不是完全只用了连接主义一家。比如阿法狗和阿法元， 那里面自然用到了深度残差网络， 但是其更根基的部分确实包含了很多别家算法， 比如逻辑， 符号等学派观点的东西， 如果没有这些作为根基， 就谈不上这些成就。&lt;/p&gt;

&lt;p&gt;三 &lt;strong&gt;离终极算法有多远&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;回顾过去， AI极大流派如同做过山车一样起起伏伏，我们曾经崇拜符号主义忽略连接主义，现在正好反过来， 那么， 这样的历史是会不断的重演， 这样的螺线向上的S曲线还会重复， 抑或是我们已经进入了一个完全不同的新纪元？ 我认为， AI发展的真正瓶颈依然在于我们对人脑自身算法理解的透彻程度。&lt;/p&gt;

&lt;p&gt;有人认为， 所谓的终极算法， 正是人脑自身所使用的算法， 这种算法&lt;strong&gt;必然如同所有的物理规律一样， 具有某种大统一的形式， 而不会是声音一块， 图象一块， 逻辑思维又一块&lt;/strong&gt;。 假使人工智能的发展有一个上限，我认为这个上限应该存在于对这个终极算法的认知程度。 有某些证据表明， 我们在一步步的接近这个终极算法， 比如当下的卷积神经网络， 事实上既能够看画面， 又能听声音，具有我们所俗称的“&lt;strong&gt;抽象&lt;/strong&gt;”能力。 &lt;/p&gt;

&lt;p&gt;然而， 一旦深入到更深层的问题， 卷积网络， 加上LSTM这类的具有记忆的时序神经网络，能否解释我们的逻辑思维， 更深层的我们的目的和动机， 我们的自我意识， 我们就一问三不知了。 有可能， 这些东西本来就是一种进化的副产品， 也就是说， 我们虽然有自我意识，但它并不是解决一些复杂问题的必要条件，简单的说就是和智商无关，也有可能， 本来这个东西就是解决一些最复杂问题的基础， 可悲的是， 目前的任何心理， 或生物， 或数学理论， 对这个问题几乎一无所知。&lt;/p&gt;

&lt;p&gt;当然还有一些问题， 提示我们可能离真正的终极算法还有距离，比如大脑对数据的应用&lt;strong&gt;效率&lt;/strong&gt;和AI算法并非一个等级， 你看到一个数据， 就可以充分的提取里面的信息，比如看到一个陌生人的脸，你就记住他了， 但是对于目前的AI算法， 这是不可能的， 因为我们需要大量的照片输入让他掌握这件事。 我们可以轻松的在学完蛙泳的时候学习自由泳，这对于AI，就是一个困难的问题， 也就是说，同样的效率， 人类脑子能够从中很快提取到信息， 形成新的技能， AI算法却差的远。  这是为什呢？ 可能这里的挂件体现在一种被称为迁移学习的能力。虽然当下的深度学习算法也具备这一类举一反三的迁移学习能力，但是往往集中在一些真正非常相近的任务里， 人的表现却灵活的多。这是为什么呢？ 也许， 目前的AI算法缺少一种元学习的能力。何为&lt;strong&gt;元学习&lt;/strong&gt;， 就是提取一大类问题里类似的本质， 我们人类非常容易干的一个事情。 到底什么造成了人工神经网络和人的神经网路的差距， 还是未知的， 而这个问题也构成一个非常主流的研究方向。&lt;/p&gt;

&lt;p&gt;另外一个重要的蛛丝马迹是&lt;strong&gt;能耗比&lt;/strong&gt;。如果和人类相比， 人工智能系统完成同等任务的功耗是人的极多倍数（比如阿法狗是人脑消耗的三百倍， 3000MJ vs 10MJ 5小时比赛）。 如果耗能如此剧烈， 我们无法想象在能源紧张的地球可以很容易大量普及这样的智能。那么这个问题有没有解呢？  当然有， 一种， 是我们本身对能量提取的能力大大增强，比如小型可控核聚变实用化。 另一种， 依然要依靠算法的进步， 既然人脑可以做到的， 我们相信通过不断仿生机器也可以接近。 这一点上我们更多看到的信息是， 人工智能的能耗比和人相比，还是有很大差距的。&lt;/p&gt;

&lt;p&gt;我们离终极算法相差甚远的另一个重要原因可能是现实人类在解决的AI问题犹如一个个分离的孤岛， 比如说视觉是视觉， 自然语言是自然语言，这些孤岛并没有被打通。 相反， 人类的智慧里， 从来就没有分离的视觉， 运动或自然语言， 这点上看， 我们还处在AI的初级阶段。我们可以预想， 人类的智慧是不可能建立在一个个分离的认知孤岛上的， 我们的世界模型一定建立在把这些孤立的信息领域打通的基础上， 才可以做到真正对某个事物的认知，无论是一个苹果， 还是一只狗。另外， 人类的智慧是建立在沟通之上的， 人与人相互沟通结成社会， 社会基础上才有文明， 目前的人工智能体还没有沟通， 但不代表以后是不能的， 这点，也是一个目前的AI水平与强AI（超级算法）的距离所在。  &lt;/p&gt;

&lt;p&gt;有的人认为， 我们可以直接通过模拟大脑的神经元，组成一个和大脑类似复杂度的复杂系统， 让它自我学习和进化，从而实现强AI。 从我这个复杂系统专业的角度看， 这还是一个不太现实的事情。因为复杂系统里面最重要的是涌现，也就是说当组成一个集合的元素越来越多，相互作用越来越复杂，这个集合在某个特殊条件下会出现一些特殊的总体属性，比如强AI，自我意识。  但是我们几乎不可能指望只要我们堆积了那么多元素， 这个现象（相变）就一定会发生。&lt;/p&gt;

&lt;p&gt;至于回到那个未来人工智能曲线发展展望的话题， 我们可以看到， 这些不确定的因素都会使得这条发展曲线变得不可确定。 然而有一点是肯定的， 就是正在有越来越多非常聪明的人， 开始迅速的进入到这个领域， 越来越多的投资也在进来。 这说明， AI已经是势不可挡的称为人类历史的增长极， 即使有一些不确定性， 它却不可能再进入到一个停滞不前的低谷了， 我们也许不会一天两天就接近终极算法，但却一定会在细分领域取得一个又一个突破。无论是视觉， 自然语言， 还是运动控制。&lt;/p&gt;

&lt;p&gt;我觉的人工智能未来发展最大的变数， 在于人们是否能克服虚化浮躁的心态， 去真正的沉下心来做理论研究。 因为本质上，我们在人工智能的研究上所作的， 依然是在模拟人类大脑的奥秘。 我们越接近人类智慧的终极算法，就越能得到更好的人工智能算法。 &lt;/p&gt;

&lt;p&gt; 更多阅读&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651384053&amp;amp;idx=1&amp;amp;sn=a1292fa38d2b3da000555b4b5ba92849&amp;amp;chksm=84f3c6b4b3844fa27ee93534098a20d3dd745089558629a502bb3b3a264ab3c1a523dceaf01b&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-itemshowtype=&quot;0&quot; data-linktype=&quot;2&quot;&gt;给小白看的AI最小入门指南（一）&lt;/a&gt;&lt;br /&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651383991&amp;amp;idx=1&amp;amp;sn=26f543505499441e7f31cfb15177ff10&amp;amp;chksm=84f3c6f6b3844fe08f91bfec42c55b42d221f452c68d3820eb1612a6c09f39c06956d69f42ca&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-itemshowtype=&quot;0&quot; data-linktype=&quot;2&quot;&gt;当神经网络遇到神经科学-铁哥18年长文汇总&lt;/a&gt;&lt;br /&gt;&lt;/p&gt;












</description>
<pubDate>Sat, 23 Feb 2019 06:44:47 +0000</pubDate>
<dc:language>zh-CN</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.jintiankansha.me/t/faWzusH9s2</dc:identifier>
</item>
</channel>
</rss>