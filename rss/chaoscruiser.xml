<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="css/feed.xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/" xmlns:og="http://ogp.me/ns#">
<channel>
<atom:link rel="self" href="http://192.168.1.4/fivefilters/makefulltextfeed.php?url=feed43.com%2Fchaoscruiser-jtks.xml&amp;max=5&amp;links=preserve&amp;exc=1" />
<atom:link rel="alternate" title="Source URL" href="http://feed43.com/chaoscruiser-jtks.xml" />
<atom:link rel="related" title="Subscribe to feed" href="http://www.subtome.com/#/subscribe?feeds=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed43.com%252Fchaoscruiser-jtks.xml%26max%3D5%26links%3Dpreserve%26exc%3D1&amp;back=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed43.com%252Fchaoscruiser-jtks.xml%26max%3D5%26links%3Dpreserve%26exc%3D1" />
<title>混沌巡洋舰</title>
<link>http://www.jintiankansha.me/column/ultiWL8Axg</link>
<description>混沌巡洋舰 - 今天看啥</description>
<ttl>360</ttl>
<item>
<title>类脑计算背后的计算神经科学框架</title>
<link>http://www.jintiankansha.me/t/vxIBUoMiXU</link>
<guid isPermaLink="true" >http://www.jintiankansha.me/t/vxIBUoMiXU</guid>
<description>&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;类脑计算， 是一个新兴的名词， 其实换一个名字， 就是我之前研究的计算神经科学。&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;大家了解人工智能， 而不了解计算神经科学， 事实上两者的关系就是一颗硬币的两面。&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;这枚硬币就是智能算法本身。宇宙中产生智能的过程， 孕育了生物智能， 我们取其道行之， 得到人工智能。而从生物的神经系统取出这个算法的过程， 就是计算神经科学。&lt;/p&gt;
&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibccts2GdPDN5kPZiaKPh2I56p6fSCOUcXSn9B7KumHb0Cc8WKBCZSeC9cdn5xicSW9L9O4LJFmpN1KbA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;640&quot; width=&quot;640&quot;/&gt;&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;计算神经科学有两个使命，一个是直接解决生命智能有关的问题， 如困扰我们的心理疾病， 器质性的神经退行性疾病如老年痴呆。因为你只有懂得了算法出现问题的原因， 才能去修正它。&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;另一方面，计算神经科学得到的启发可以直接用于人工智能， 好比一个蓄水池， 它的水位足够高， 就可以流出一部分做人工智能算法的应用。当下的AI的核心重磅RNN和CNN，都和8，90年代这个算法的积累有关。&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;计算神经科学的算法和人工智能算法的本质不同在于计算神经科学考虑生物细节的影响，试图解释生物现象， 而人工智能把这条缰绳脱去了。而这条缰绳是否有意义也是计算神经科学的热点问题。&lt;/p&gt;
&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibccts2GdPDN5kPZiaKPh2I56p1icL6H5lWeZKfqhc3Y8LCIQJ0MrnwuyUjVhMnTCOfWrFibWPqqRiboqkQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;640&quot; width=&quot;640&quot;/&gt;&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;研究计算神经科学的方法我们可以总结一种层级型的思维方法。因为计算神经科学本质是一个桥梁学科。它连接了从最基本的生物物理层级， 到神经回路（网络）， 然后大尺度神经回路基础上涌现的动力系统，以及动力系统所carry的信息流， 而在信息尺度之上， 我们得到计算，或者算法本身， 在此基础上得到功能， 得到多种多样的心智现象， 这也就是最高层级。&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;&lt;span&gt;一 生物物理层次&lt;/span&gt;&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;最低层级的现象往往可以由生化实验所测量， 最高层级就是心理学或认知科学， 可以由心理实验测量。中间的那些层次生物神经科学家通过各种各种的成像记录间接获得。而这些层次间的联系就是计算神经科学。&lt;/p&gt;
&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibccts2GdPDN5kPZiaKPh2I56po3Mvq6XNocWFtLVamQ4DvRLCAfOToKx9NwgDLN7qpLeFRBM7XugLTQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;640&quot; width=&quot;640&quot;/&gt;&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;计算神经科学与人工智能的载体均是神经网络， 但是两者既有联系又有区别。这种区别主要体现在计算神经科学的神经网络试图用最简单的模型获取最多的生物真实性， 而AI的神经网络试图这种简化模型进一步工程化标准化最大化其功能。具体的区分度， 又在于神经元的细节， 连接懂得细节， 以及学习本身。&lt;/p&gt;
&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.737012987012987&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibccts2GdPDN5kPZiaKPh2I56pE5rrduLwkYFLND0bcvy6H0gzFZR8B3PsBkQjibhNFZ0qUanA074ZJAg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;616&quot; width=&quot;616&quot;/&gt;&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;生物神经细胞本身其实极为复杂， 一个细胞甚至堪比一个神经网络。树突收集信息， 胞体做出决策， 传递到轴突。&lt;/p&gt;
&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibccts2GdPDN5kPZiaKPh2I56pDRJ4FwpicCBYibjpVP3nicuydd2ddX0EgTA9AueVCT7icicWeNibn5kxcRaw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;640&quot; width=&quot;640&quot;/&gt;&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;Spike，神经元尖峰放电是生物神经网络的信息货币（bit），放电是一个典型的物理化学过程， 当输入超过某个阈值，细胞膜内外的钠离子和钾离子相继发放，引起一个由正反馈到负反馈主宰的过程， 由Hodykin Huxley 方程描述。&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;Häusser, Michael. &quot;The Hodgkin-Huxley theory of the action potential.&quot;&lt;em&gt;nature neuroscience&lt;/em&gt;3.11 (2000): 1165.&lt;/p&gt;
&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.48055555555555557&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibccts2GdPDN5kPZiaKPh2I56pgCTvCqEfX4E99JavBAILmsDkmr7E1FrIL88SNibUak7Yj4KvjHxepfA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;720&quot; width=&quot;822&quot;/&gt;&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;连续的尖峰放电把一个直流输入转化成脉冲输出 ， 这个脉冲频率由直流输入大小决定， 对外表现为脑电波。如我们数值的alpha或gamma波。&lt;/p&gt;
&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibccts2GdPDN5kPZiaKPh2I56poUJAq3Gcysuiagw4qicqgxUaY8R4ibY8vkRcKzrmw7Q92liaR8CpHW1GyA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;640&quot; width=&quot;640&quot;/&gt;&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;把脉冲神经元放在一起组成脉冲神经网络。&lt;/p&gt;
&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibccts2GdPDN5kPZiaKPh2I56pnKBJk0vJe1ZxxvVCUib2y6oWj5R7VS7NxNEhgwdjWOL7LJPdQeiaZ5Ag/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;640&quot; width=&quot;640&quot;/&gt;&lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;/&gt; &lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot;&gt;&lt;span&gt;这个步骤如何做一个大&lt;/span&gt;刀&lt;span&gt;阔斧的简化呢？&lt;/span&gt;&lt;span&gt;我们把单位时间窗口的输出spike个数简化为发放率， 刚刚说脉冲神经元的输入和输出是简单线性的， 那么这个线性关系被以上方程概括。&lt;/span&gt;&lt;span&gt;w描述每个神经树突对信息的敏感性。&lt;/span&gt;&lt;/p&gt;
&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibccts2GdPDN5kPZiaKPh2I56pMy1x1HqxycqTxuQQpxXVfLyDO5TjW05yCBnibl73RFRKJVggBTiazr6w/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;640&quot; width=&quot;640&quot;/&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;而神经脉冲那种输入超过阈值则引起正反馈的性质被一个非线性的门函数概括， 它可以是我们们熟悉的relu，sigmoid。&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;生物脉冲神经元和这种经过简化的实数神经元到底有何不同？　同样是前馈网络，脉冲神经元构成的网络，由于尖峰脉冲的时间结构， 它的发放可以携带和时间有关的信息，是当下的深度学习所使用的rate神经元不具备的。同时，不同尖峰脉冲神经元发放间的correlation 被认为可以编码信息。而脉冲神经元和rate数值神经元到底有无本质区别， 也成为各种学派的争论焦点。&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;&lt;span&gt;二 学习和网络架构层次&lt;/span&gt;&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;&lt;span&gt;1， 生物学习vs机器学习&lt;/span&gt;&lt;/p&gt;
&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibccts2GdPDN5kPZiaKPh2I56px8O4sqW3wCvxaUjjd6c2pA7g4U7ccs3LHHibsvXbLs9OTA001Ge64HQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;640&quot; width=&quot;640&quot;/&gt;&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;生物学习和机器学习的比较：同为学习， 生物学习和机器学习的本质相同而形式迥异。所谓本质相同， 它们都是输出导致的对自身的反馈， 且这种反馈的方向使得总体的信息增加而熵减少。&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;这就决定了，学习的过程需要的是输出的结果，被一个函数衡量， 作用到信息流动的载体，神经网络里， 使得新的输出向着某个确定方向变化 。&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;如果从一个较大的尺度看生物学习， 那么大部分的学习实质上是“进化” 。因为我们先天的已经具备大量的学习能力， 比如先验的语言能力（乔姆斯基）。而真正通过生物后天学习可以得到的， 反而是一小部分内容。&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;如果但看学习， 生物学习的关键词是Hebian学习， 神经可塑性和强化学习， 而机器学习是监督学习， 非监督学习和强化学习。&lt;/p&gt;
&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibccts2GdPDN5kPZiaKPh2I56pXw7s8gRWaeLKwEI7hBOF9JicRoe7RIIzicWtacw37GT0cQyAibGXyXzibA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;640&quot; width=&quot;640&quot;/&gt;&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;机器学习的基础是监督学习。这个对输出的度量由一个绝对真理的代表-导师提供，与它不匹配的时候， 一个错误信号向整个网络传递， 而最终网络结构向着减少这个错误的方向改变。&lt;/p&gt;
&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibccts2GdPDN5kPZiaKPh2I56pOxFia4qgOjHE12lO7cRa0XVoPRdzsAt9Z1VC7ia0ibbVJX1TysAvzWd3g/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;640&quot; width=&quot;640&quot;/&gt;&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot;&gt;&lt;span&gt;而生物学习的基础是无监督学习。它本质所&lt;/span&gt;做&lt;span&gt;的工作是相似度匹配。&lt;/span&gt;&lt;/p&gt;
&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibccts2GdPDN5kPZiaKPh2I56pqyiceDBCRib7RMmMy96EQ5sHy2Mrnmcs49FOlN5hE4jND1CKLqkibcdeA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;640&quot; width=&quot;640&quot;/&gt;&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;这种学习的基础正是著名的赫布法则， 它说的是当一个上游神经元可以引发下游神经元的放电， 它们的加强就会增强。&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;“Hebb suggested that such synaptic modification could produce neuronal&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;assemblies that reflect the relationships experienced during training.&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;For example, consider applying this rule to neurons that fire together during training&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;due to an association between a stimulus and a response. These neurons&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;would develop strong interconnections, and subsequent activation&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;of some of them by the stimulus could produce the synaptic drive needed&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;to activate the remaining neurons and generate the associated response.&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;赫布法则导致的一个直接结果是神经元集团的生成，对应一个经常一起发生的事件序列进行反应。这其实就是在挖掘事件间的相关性。把这种相关性学习直接写成数学公式， 我们会发现这种学习的效果类似PCA主成分分析，也就是通过学习神经元集团掌握了数据样例间的共同特征（oja's law），而不同的“相关特征组”就可能是概念形成的基础 。&lt;/p&gt;
&lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;/&gt; &lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibccts2GdPDN5kPZiaKPh2I56pCvBddAvwvVQiamicAIGg2KbWibibkUiaOlB9IEodpj3dQcX9v19GVev7j5Q/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;640&quot; width=&quot;640&quot;/&gt;&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibccts2GdPDN5kPZiaKPh2I56pcLydWv0thVj9vZqNgXR3esITyq0ibyyYFFJgkh7dUzt4XdtvCGhgkUA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;640&quot; width=&quot;640&quot;/&gt;&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;把上面的想法变成一个非常典型的例子， 通过无监督学习， 神经网络可以特征的共同出现（假设我们具有一组分别感受颜色和形状的细胞， 那么红色和圆形， 或者黄色和长形对应苹果和香蕉两个共同概念）来学习苹果和香蕉的概念。&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;那么通过这样的学习能否得到丰富复杂的生物大脑模型呢？答案是否定的， 因为生物的多样性建立在复杂的进化历程基础上， 这种长期与环境交互的“学习”被写在基因里 。这种进化的复杂性表现在神经元的种类， 网络的拓扑结构， 全脑连接等等因素上， 即使如此，我们可以发现不同神经网络的共性， 比如多层级结构(hierarchy structure)， 小世界网络(small world networks)， 兴奋抑制平衡(Dale Principle balanced network)等， 它们可能反应了神经网络的共同原则。同时我们可以通过这些原则给AI设计人工神经网络。&lt;/p&gt;
&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibccts2GdPDN5kPZiaKPh2I56p68KynrJMmTCBShy3HCtV7skecLA8dzBuk11tibEHvQibf3Kfnbe4PeoA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;640&quot; width=&quot;640&quot;/&gt;&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibccts2GdPDN5kPZiaKPh2I56ppJSAVwdMXMb2Nd18x2PyoibxnoibRHopbM6A4jTlHtItcm4uAWgF9Qyg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;640&quot; width=&quot;640&quot;/&gt;&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;目前我们对这些共同原则知之甚少， 比较程序的框架有efficient coding， sparse coding 或者 predictive coding。它们都处在我们下面要讲的编码层次。&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;&lt;span&gt;三 大脑信息编码层次&lt;/span&gt;&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;有了学习和通过进化与学习得到的结构，下一个level就是编码， 编码又分为大脑神经网络的编码和解码。这个层次的本质是信息的流动， 外界刺激需要通过编码被内在神经活动加载， 而后面内在神经活动需要通过解码等转化为肌肉的运动和语言等。&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;让我们来具体看几个生物计算系统的案例；　&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;１，　视网膜，　一个人们研究极为透彻的系统。　　&lt;/p&gt;
&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibccts2GdPDN5kPZiaKPh2I56pcvGvVXEVbR7cycfIyG7mqgTtvkbwmlhIsSxdlVcDQc1XibeNZHHhVQw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;640&quot; width=&quot;640&quot;/&gt;&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;视网膜看似如同照相机的ccd，　事实上确是一个非常核心的计算单元。视网膜其实是一个类似ＣＮＮ的典型多层神经网络。从最底层的感受色彩的像素，然后对物体的边缘进行对比度分析提出边缘，最终还可以对运动方向等一些信号进行处理（ganglia cells）。　视网膜是视觉神经编码的开始， 关于视网膜计算的根本编码原理被称为&lt;span&gt;efficient coding&lt;/span&gt;框架。这个框架说神经编码的根本在于maximize mutual information with input（增大神经活动与外部信号的互信息）， 的方向尽可能减少冗余的发放达到节能的目的。根据这个原则，我们可以理解视网膜编码对某些色彩或运动方向（如水平， 竖直方向）的编码精确度高于其它色彩或方向。&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;Barlow, Horace B. &quot;Possible principles underlying the transformation of sensory messages.&quot;&lt;em&gt;Sensory communication&lt;/em&gt;1 (1961): 217-234.&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;２，视觉皮层回路&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;视网膜之后， 主要的视觉运算在视皮层内进行， 与视网膜不同的是， 视皮层的运算需要涉及到视觉概念的处理。&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;不用多说， 视觉皮层回路的研究来是计算神经科学和人工智能的交叉点， 早期对视觉皮层的研究工作启发了CNN的工作（Witz）， 而当下的CNN则已经是计算神经科学经常用的工具。&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;CNN用到的大脑视觉编码处理原理称为层级编码， 用这个方法我们把可以把信息表征成从低级到高级的组合形式， 从而高效的表达概念， 如下图的桌子和祖母细胞的例子。&lt;/p&gt;
&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibccts2GdPDN5kPZiaKPh2I56pNzqZ890wiahjibj1Ycoia1mRQeLj9x2EaQg6Hzws4WI4ibXOHBWX0myDwA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;640&quot; width=&quot;640&quot;/&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;视觉问题是激发表征学习进步的核心。关于视觉表征一个非常基本的原理称为&lt;span&gt;sparse coding&lt;/span&gt;， sparse coding的基本假设是视觉信息的编码虽然看似高维繁复， 但是实质上常见的物体就那么多， 因此从有效的角度， 视觉回路完全由更智慧的方法用最小的神经元来编码它们。具体怎么做？你可以做一个字典， 这个字典里包含我们万千日常可见事物， 这些事物被称作引发神经元发放的隐变量， 事实上视皮层的神经元很大部分就是参与这些隐变量的表征。但是我用一个先验prior给不同的事物进行概率编码， 这样一些常见的事物如天空， 草地， 动物等就会占有那些最高频的词汇表， 而有更高的几率发放。由此导致的结果是视觉皮层的发放看起来非常稀疏（因为世界本来是低维的， 那些引发发放的常见事物就那么多， 所谓太阳之下并无新事）。这个原理和刚刚讲的efficient coding既相关又略有区别。&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;除了sparse coding， 视觉表征的另一个问题是如何表达视觉概念所包含的各种连续变化。比如一个人的头像， 你去对他进行各种旋转，表情的变化它还是那个人。事实上我们可以把它假定为一个空间的变换， 而概念相对这种变换是不变的。一个叫做DIsentangled representation的框架能够非常好的解释这种空间的实现。这个框架巧妙的利用空间的正交性， 把那些不影响概念的变化放到概念的正交空间里。&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;Chalk, Matthew, Olivier Marre, and Gašper Tkačik. &quot;Toward a unified theory of efficient, predictive, and sparse coding.&quot;&lt;em&gt;Proceedings of the National Academy of Sciences&lt;/em&gt;115.1 (2018): 186-191.&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;Higgins, Irina, et al. &quot;Towards a definition of disentangled representations.&quot;&lt;em&gt;arXiv preprint arXiv:1812.02230&lt;/em&gt;(2018).&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;&lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;/&gt;  Barello, Gabriel, Adam Charles, and Jonathan Pillow. &quot;Sparse-Coding Variational Auto-Encoders.&quot;&lt;em&gt;bioRxiv&lt;/em&gt;(2018): 399246.&lt;/p&gt;

&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibccts2GdPDN5kPZiaKPh2I56p8UYEdgECHICTYdFq8Cy85aY3GNzAcqTPl7goUf9RKfYp1ocqkibl7SA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;640&quot; width=&quot;640&quot;/&gt;&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;然而被动的表征不是视觉理解的全部， 因为人从来不是在机械的表征客观的世界， 而是不停的加入自己的主观修饰， 俗称脑补。比如你看到的底下的两个图篇都是非常有争议的错觉图， 舞女是左到右旋转还是从右向左旋转, 从来没有一个一致的答案。&lt;/p&gt;
&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.75&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibccts2GdPDN5kPZiaKPh2I56peOyhwibkZ91rYxZmcUL6tyiauYqA1RHFUg4RfMzibRQUG1HibNXz4WjibCw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;480&quot; width=&quot;480&quot;/&gt;&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;那么这些“脑补”的意义是什么？一个基本的理论框架下我们的大脑在进行预测性编码，也就是其实感知关心的并非当下， 而是未来，用信息学的语言说， 就是我们最大化的那个互信息， 是当下神经编码与未来的外界信号变化的互信息。&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;这里不能不提的就是Karl Friston大神的一系列关于自由能和预测编码的作品,　通过贝叶斯的概率预测来建立整套大脑运作的框架。　&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;Friston, Karl, and Stefan Kiebel. &quot;Predictive coding under the free-energy principle.&quot;&lt;em&gt;Philosophical Transactions of the Royal Society B: Biological Sciences&lt;/em&gt;364.1521 (2009): 1211-1221.&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;预测未来， 就离不开记忆。人脑认知的任何环节离不开记忆，来自我们记忆的信息时刻不停的塑造从感知，到认知，到决策的过程。&lt;/p&gt;
&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibccts2GdPDN5kPZiaKPh2I56p39u6vCCjYCgQHHgQBPjTpjUobHWFTdiatsSvuh346BSXPhHlrTQoQRw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;640&quot; width=&quot;640&quot;/&gt;&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;那么记忆是怎么实现的。计算神经科学对记忆的原理有着比当下深度学习深刻的多的理解。记忆分很多种， 从最短时间的工作记忆，到中间时间尺度的情景记忆， 到长时间尺度的记忆。首先，要搞定这些记忆的物理实现， 从刚刚讲的神经元层次解释清楚这些事情是如何构成的。最经典的莫过于hopefield吸引子网络对关联记忆的解释。这里说的是具备大量对称连接的循环神经网络， 可以把输入信息锁定在网络的固定内在状态里， 这些状态对应大量神经元体系的势能最低点（类似物理的spin glass model），活动动力系统的定点， 被称为吸引子。记忆的存储对应某种信息的吸引子的形成， 而记忆的提取类似于通过某些关联信息进入到这些吸引子里（如吃到某个儿时的食物联想到孩童时代）。&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;Hopfield, John J. &quot;Neural networks and physical systems with emergent collective computational abilities.&quot;&lt;em&gt;Proceedings of the national academy of sciences&lt;/em&gt;79.8 (1982): 2554-2558.&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;Amit, Daniel J., and Daniel J. Amit.&lt;em&gt;Modeling brain function: The world of attractor neural networks&lt;/em&gt;. Cambridge university press, 1992.&lt;/p&gt;
&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibccts2GdPDN5kPZiaKPh2I56pNtuGIlxWR61u5w8ouSAQvL29xwQP5RaoiazSe1elwspEBxq5rBqMzRQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;640&quot; width=&quot;640&quot;/&gt;&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;当然这个记忆解释了一些比较长期的记忆， 对于短期的记忆描述不佳。同样的循环神经网络， 也可以描述短期记忆。混沌边缘的蓄水池网络， 可以有效的通过网络内的“回声”保存这种过去的信息（暂留记忆），可以作为工作记忆的一种解释。&lt;/p&gt;
&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibccts2GdPDN5kPZiaKPh2I56pqNY4Zspob2Rf9bkEJ4RiaS4fWprK5m9e6szibnvmwY3t0bV8bAg2UZPw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;640&quot; width=&quot;640&quot;/&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;&lt;span&gt;四 高级功能层次， 决策，推理，情感....&lt;/span&gt;&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;有了感知和记忆， 另一个大脑计算的焦点就是如何决策。而决策问题的本质是如何通过奖励和惩罚调整行为， 这里一定包含的是行为， 环境受到行为的影响，&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;对于这些高层级的问题， 心理学是最早给出相关的线索， 比如强化学习。强化学习的基本框架如下图。&lt;/p&gt;
&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibccts2GdPDN5kPZiaKPh2I56ptOW37m17UUXqjPDL8bGBRagICPPG4xiagH0PDH2mDN7EurtOIwFQc7g/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;640&quot; width=&quot;640&quot;/&gt;&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;强化学习的最重要的反馈信号是多巴胺， 多巴胺奖励的调节回路如下图所示：&lt;/p&gt;
&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibccts2GdPDN5kPZiaKPh2I56pHE5d9iaSne7NQlVDEIdthYXEibjMKaBfu66uibDKIkfNjfTUHsibqlDGEw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;640&quot; width=&quot;640&quot;/&gt;&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;关于各种神经活动的高级模型如推理，我们所知道的不多 。而当下一个已经取得一定进展的方向， 是和导航相关的空间推理与表征，以及它们的载体place cells， grid cells。&lt;/p&gt;
&lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;/&gt; &lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibccts2GdPDN5kPZiaKPh2I56pict1gbwtBKRL6TMLlRx49YQCZUmPhtKCRfH97smbPxe89ib8DboWAWHQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;640&quot; width=&quot;640&quot;/&gt;&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;空间导航某种角度可以看作实现推理的第一步， 因为它把不同来源的感知信息（如视觉， 触碰， 肌肉动作）合成在一起， 对引发这些感知的共同外部信息， 如位置，空间进行推测。我们从某个地标开始， 向东500米， 向南500米， 与向南500米， 向东500米， 其实达到的目的是一致的， 通过视觉等信号大量观测到的这种不同路径组合但是目标的一致性，其实背后的概念正是位置引起的。能够通过整合感知信息对位置这正背后更本质的抽象事物进行推断， 某种程度与我们更广义的推理能力是相通的。&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;Using Grid Cells for Navigation Daniel Bush,1,2,5,∗Caswell Barry,3,5Daniel Manson,3,4andNeil Burgess1,2,∗∗&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;Generalisation of structural knowledge in the hippocampal-entorhinal system James C. R. Whittington,Timothy H. Muller,Shirley Mark,Caswell Barry,Timothy E. J. Behrens&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;Accurate Path Integration in Continuous Attractor Network Models of Grid Cells Yoram Burak , Ila R. Fiete&lt;/p&gt;
&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.6041666666666666&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibccts2GdPDN5kPZiaKPh2I56pJjWENVUehukHgGEZkY1iczDsx9jGwBGqn4PZEklfbdfmjMp6uhfk5Xw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;720&quot; width=&quot;850&quot;/&gt;
&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.36944444444444446&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibccts2GdPDN5kPZiaKPh2I56pTCr2P1mcBP7ohYOkHB8DKbOv4nubYCuRLyEKibIU5W7aTDAfk8ImQyw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;720&quot; width=&quot;2273&quot;/&gt;&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;Generalisation of structural knowledge in the hippocampal-entorhinal system&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;真正了解高层级的认知功能， 离不开理解多脑区的配合模式。这方面已有大量脑科学研究表明大脑在工作状态存在一个多脑区互相配合的default network。&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;一些多脑区模拟的先驱工作正在逐步帮我们揭开这个奥秘， 如下图的spaun。&lt;/p&gt;
&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibccts2GdPDN5kPZiaKPh2I56p2zm5WNSKNqQjyjRPZXgp8NeX2BdnaaW5c8DaeTlUSFrp7q26ygFa5w/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;640&quot; width=&quot;640&quot;/&gt;&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;在高级认知功能这块， 当下的一个趋势是，将深度学习和计算神经科学结合起来。而这种结合如果要进行的更有效， 首先要把硬件计算的效率提升上来，正如同过去的GPU计算引爆深度学习革命。而深度学习和计算神经科学的基本组成单元就有不同， 为了让它们在硬件尺度就可以统一，清华大学开发的具有异步融合功能的天机芯片算是开拓先河。&lt;/p&gt;
&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibccts2GdPDN5kPZiaKPh2I56pF6NyQ75lXdvtBQ39Mtpj6QfvqPT7pLo0Z5ZRzBwIicncfOBWCTy10cg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;640&quot; width=&quot;640&quot;/&gt;
&lt;br/&gt;更多阅读&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651384248&amp;amp;idx=1&amp;amp;sn=a1ad96c5dc3a782a56d6488ec0ae1683&amp;amp;chksm=84f3c7f9b3844eef018c9610475e660e38d8256f62045944effdd6bc0044a4938ea9f4203ee7&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-itemshowtype=&quot;0&quot; data-linktype=&quot;2&quot;&gt;2019计算与系统神经科学大会Cosyne 前沿研究汇总&lt;/a&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=207945043&amp;amp;idx=1&amp;amp;sn=9b6799ff0de34bae7f141ff95492e090&amp;amp;chksm=169fd31221e85a0406ed47906e6133c0e1177b4334dac9e5e4bdce09e491599949ae4017b7d4&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-itemshowtype=&quot;0&quot; data-linktype=&quot;2&quot;&gt;为什么你需要计算神经科学（上）&lt;/a&gt;&lt;br/&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=208053222&amp;amp;idx=1&amp;amp;sn=5a7feead10fa4210c3d160bc66c82b87&amp;amp;chksm=169d8da721ea04b14993d30bcaaa710d3dd6d7af2fa350131049058888a24b6b103d87888f32&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-itemshowtype=&quot;0&quot; data-linktype=&quot;2&quot;&gt;为什么你需要计算神经科学（下）&lt;/a&gt;&lt;br/&gt;</description>
<pubDate>Mon, 30 Sep 2019 04:26:01 +0000</pubDate>
<dc:language>zh-CN</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.jintiankansha.me/t/vxIBUoMiXU</dc:identifier>
</item>
<item>
<title>感谢那些允许我们犯错的老师</title>
<link>http://www.jintiankansha.me/t/iTpU6Wla64</link>
<guid isPermaLink="true" >http://www.jintiankansha.me/t/iTpU6Wla64</guid>
<description>&lt;p&gt;最近在看《生命和新物理学》这本书，这本书讲到通用复制器（Universial constructor），最典型的例子是元细胞自动机。借用通用复制器的概念，作者想表达的是生命的在复制中，既可以做软件，也可以做为硬件的属性。作为软件时，DNA作为控制生命生长发育繁殖的程序，而作为硬件时，DNA就是用以复制的模板，这是这样就可以做为软件，又可以做为硬件的特性，促成了生命在进化中，既可以可我复制，又不是完美到一成不变的复制。&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;1.45875&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcc9BWeBkjmmoglzGpR3A5cCRoXg0zXsdDWicFcLIbY0pZs5qkv9uyE08tQKEicjm5xR7fXhW48c7YOw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;800&quot; /&gt;&lt;/p&gt;

&lt;p&gt;这让我想起了老师，大刘的乡村教师中写道，高级文明之间的信息是直接复制的，这似乎是AI+教育所要达到的，以最高效的手段，完成信息的传输。然而这不是教师的本质，教师在人类智慧的传递中，有其作为软件的一面，例如讲课，批改作业，解答疑问；更有其作为硬件的一面，例如通过自己的行为和操守成为你的榜样，例如带着你做项目。前者传递的显性的，形式化的知识，后者则是隐性的，教会你关于怎么做才能让你也能传递知识的隐性知识。&lt;/p&gt;

&lt;p&gt;越是在教育的俩头，即最初的儿童阶段，和最后的硕博及职业教育阶段，教师作为硬件的属性就越明显。如果高级文明对教师如此陌生的话，那么这个文明将不可能进化到如此高的水平。老师要做的不是简单的传递信息，不是把学生的变得和自己的一模一样，这些AI比人类更擅长，老师要做的是分辨出学生的不同中那些是需要纠正的，那些是需要保留的。 苏联教育家苏霍姆林斯基说：教师是老一代人与年轻一代人之间的连结环节，他应该跳板而已。如果你们看到某一位教师在课堂上忠实地复述教科书，那就可以断定，这位教师距离教育工作的高度素养的境界还相差甚远。&lt;/p&gt;

&lt;p&gt;教育不是为生活做准备，教育就是生活本身。这话是美国哲学家约翰杜威说的，与这句话应和的是1984中的话，思想罪不会带来死亡，思想罪本身就是死亡。一个真正教师要做的，就是让你在一个充满枷锁的世界里如何去犯下思想罪又不被抓到，或者用当下流行的词来说，是快速低成本的试错。老师是人类历史中最古老的职业，没有之一，也注定会是最后一个被取代的职业（哥白尼原理），是教师即作为软件，又作为硬件的二元性，让教师成为了人类文化得以不断发展的必要充分条件。&lt;/p&gt;

&lt;p&gt;AI对教育的加成，只应该是仆人的角色，而不应该影响决策。旷世科技根据人脸识别来判定学生以及老师的表现，这只会破坏学生的认知多样性，让学生不敢试错。只有受过教育的人是自由的，因为教育的真正意义是自我理解，通过对自身的了解，认识到自己想要什么，适合做什么。教育是帮助被教育的人，给他们能发展自己的能力，完成他的人格，于人类文化上能尽一分子责任；不是把被教育的人，造成一种特别器具，给抱有他种目的人去应用的。&lt;/p&gt;

&lt;p&gt;感恩生命中遇到的所有包容，甚至鼓励我们犯错的老师，感谢他们的宽容与严厉成全了我的创造力。爱因斯坦说很好奇现代教育没有完全摧毁我们的创造力，但若是没有老师加以的限制，天马行空的幻想完全不是创造力。今天很多人转西游记中“闯下祸了不要说出为师的姓名”，六神磊磊对此的评价是，用心的老师会在学生面前暴露了软肋，所以才怕学生说出自己的名字来。而我的看法是，老师对学生说出这句话，那是对自己教学的成果有信心，对学生的能力有信心，觉得学生出去肯定能闯出一片天，说不定会跳过自己都无法越过的天花板，从而闯下祸自己也没有办法。&lt;/p&gt;

&lt;p&gt;更多阅读&lt;br /&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=208144963&amp;amp;idx=1&amp;amp;sn=e99ecdfd9796d93ff8cd1c987350b6a8&amp;amp;chksm=1693240221e4ad1402a8df6907523dd1bad815a0cbb259031dacd85ed60be0a37a7645d5563e&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-itemshowtype=&quot;0&quot; data-linktype=&quot;2&quot;&gt;从Minerva谈创新教育&lt;/a&gt;&lt;br /&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651382319&amp;amp;idx=1&amp;amp;sn=0a2c4a9e28e06156d792cdc93fa3be9e&amp;amp;chksm=84f3cc6eb3844578cfa3739fe356b4c5fe43858e99024eaf58b5158cb894a0faef890b34d394&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-itemshowtype=&quot;0&quot; data-linktype=&quot;2&quot;&gt;我们这一代的教育&lt;/a&gt;&lt;br /&gt;&lt;/p&gt;




</description>
<pubDate>Wed, 11 Sep 2019 04:14:12 +0000</pubDate>
<dc:language>zh-CN</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.jintiankansha.me/t/iTpU6Wla64</dc:identifier>
</item>
</channel>
</rss>