<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="css/feed.xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/" xmlns:og="http://ogp.me/ns#">
<channel>
<atom:link rel="self" href="http://192.168.1.4/fivefilters/makefulltextfeed.php?url=feed43.com%2Fchaoscruiser-jtks.xml&amp;max=5&amp;links=preserve&amp;exc=1" />
<atom:link rel="alternate" title="Source URL" href="http://feed43.com/chaoscruiser-jtks.xml" />
<atom:link rel="related" title="Subscribe to feed" href="http://www.subtome.com/#/subscribe?feeds=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed43.com%252Fchaoscruiser-jtks.xml%26max%3D5%26links%3Dpreserve%26exc%3D1&amp;back=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed43.com%252Fchaoscruiser-jtks.xml%26max%3D5%26links%3Dpreserve%26exc%3D1" />
<title>混沌巡洋舰</title>
<link>http://www.jintiankansha.me/column/ultiWL8Axg</link>
<description>混沌巡洋舰 - 今天看啥</description>
<ttl>360</ttl>
<item>
<title>[原创]《创造的本源》书评-从进化的角度看进化</title>
<link>http://www.jintiankansha.me/t/qNtoXCwHis</link>
<guid isPermaLink="true" >http://www.jintiankansha.me/t/qNtoXCwHis</guid>
<description>&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;1.3138888888888889&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibccoCoialgOpjXjlmC6esI7UCeSZLfP4oaPHCrBiaICIw9L6QLrYR8YBDjr5WaCeaIYj171ace85RSWg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1080&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;《创造的本源》是研究了一辈子蚂蚁的进化生物学家写的一本小册子，由20篇短小精炼的随笔组成，分成五个部分，分别是创造从何而来，什么阻碍了创造，什么促进了创造，自然给创造灵感，科学与人文的融合。关于创新的书很多，例如之前提到的&lt;/span&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651383522&amp;amp;idx=1&amp;amp;sn=ab9a5e820a8d4566c51912f206363cbc&amp;amp;chksm=84f3c8a3b38441b5a781dff83e24405fcf95f482d46713eabb83bd35c8266345f14ca5ba5e6c&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot;&gt;&lt;span&gt;创造力不是无中生有-读《The runaway Species》&lt;/span&gt;&lt;/a&gt;&lt;span&gt;，这本书的优点在于其从进化的角度去看这个问题。正如脱离了进化，生物学能提供的解释和建议都是瘸腿的，通过解释创造力的进化基础，这本书将科学和人文中的创意找到了共同之处，并由此提出了相应的建议。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;创造力是一个独属于人类的特征，但是却被人为的分成了俩部分，一部分叫做人文，关注是什么怎么办这样表面的近因，而科学关注的是引导该现象进化为当下状态的一系列事件，即关于为什么的终极因。科学研究宇宙中每一件可能存在的事物，而人文的疆域研究人类思想中每一件可能构想出的事情。俩者都以创新为根源。但如今科学日新月异，人文领域则在原地踏步，而科学与人文中间的第三种文化，则缺少实际的执行建议，这些都可以从本书中找到线索。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;人类是唯一一种会使用篝火的生物，火的使用让人在夜间有了安全，围着火的谈话开始涉及八卦和闲谈可以算是人文的启示。人们在篝火边讲的神话故事，让人的语言脱离了实用的信息交流，而能够传递虚构的概念。文化的演化受到生物天性的制约，这是由于艺术是通过风格和比喻的创新，引发审美惊喜，从而带给人持久的愉悦，而能够发挥作用的信号和信号组合，却是人类先天心智的共享部分。例如稀树草原假说，说的是不管哪个文化下，园艺师都偏好哪些类似非洲草原上的树木形状，文学家也总描述林中漫步的愉悦。而进来流行的心流状态，则是远古狩猎者集中注意力带来的极乐境界的重新。&lt;br /&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;在什么阻碍了创造这一小节中，作者要批判的是人类中心主义。人文学科关注的是人脑可能创造出的所有东西，但人脑具有通过学习某些特定行为方式并避免其他类型的行为方式的遗传倾向。为了弄清楚进化加在人脑创造能力上的限制，人文学科要以古生物学，人类学，心理学，进化生物学和神经生物学的最新成果为根基，但当前的人文学科存在与人类受限的感官体验中，对因果性也缺少有根据的解释，除非某件事物对人造成影响，否则他就没有意义，由于找不到什么东西与自身比较，因此也无法实现真正的自我理解和判断。书中写道，与其说人是万物的尺度，不如说万物是理解人的尺度，只有从多个角度，才能看清楚人的全貌&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;这带来的后果是科学拜物教，表面上重视科学，但却不关注科学思辨的那一面，只关注科学实际的使用，同时对人文学科忽略。人们不关注贫富差距坏境恶化的现实问题，对于纯理论的研究也敬而远之，但为了确保科学的成果不被导向歧路，人们需要对人文学科给予相应的关注。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;具体该怎么办？书中提出的群体选择理论是一条路，该理论指出社会行为的进化依据群体成员之间的亲缘度而发生，亲缘度越高，群体成员越可能共享资源，并在劳动上达成合作。每一位群体成员为此而在生存和繁殖上付出的代价，通过与其存在亲缘关系的成员身上相同的基因在数量上获得补偿。群体选择理论解释了人性中的善良天使可以不通过宗教或道德宣讲自然发生。而鲍德温效应这另一条路则指出基因与文化共同的进化。当一个习惯被某个个体证明书有用的，那该个体的其他突变出现频率也会增加，从而随着时间的推移，新的特征，不管是直接还是搭便车的，都成为了固定特征。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;上述的俩个科学发现，可以帮助人文科学摆脱对人类感知这个唯一裁判，从而帮助人文学科更好的理解人性的复杂与成因。而在本书的最后一部分，作者列出了四种人文如何帮助科学找到灵感的方式，分别是借助隐喻，寻找原型，探索荒岛和运用讽刺。用好这些方法，不管对科学工作者寻找新思路，还是向大众普及，都有所帮助。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;隐喻，就是发明新词汇和组合新词汇，为词语赋予全新意义的工具。在两个事物的本质特征进行对比的语句也属于隐喻。隐喻使得语言及其所表达的思想得到无限的扩增，使得语言能够及时指称新出现的概念，这一过程中反映了人类在那个时代具有的科学知识，并随着广泛的运用成为人的第二本能。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;原型是那些全人类熟悉的故事和图像，其并非由于文化或伟人等偶然因素形成的，而是根植于深厚历史之中的一部分，遵从这人类本能的遗传偏见。寻找原型，类似于马斯克说的第一性原理，从问题的本质寻找解决的方法，寻找通用的放之四海而皆准的规律。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;荒岛指的是那些渺无人迹的地方，属于一个自成一体的世界。类似于创业中所说的细分市场，对荒岛上生物的研究，往往能得出通用的规律，在一个不那么竞争激烈的领域，也能够更容易去发挥创造力。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;讽刺原来指的是将一个过程或实体的属性描述成与其截然相反的样貌，从而带来全新的意义。在科学领域，讽刺可以看成是对权威观点的一种革命性的改变，不去思考如何在现有的理论上改进，而是去看如果将现有的观点全盘翻面后会发现什么。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;总结来看。无论科学方法看起来和现实经验有多大差距，科学的视野多么广大或微观，所有的科学知识必须通过人类的思想进行处理，而人的思想不管多么的个性化与微妙，都拥有一个实体基础，都可以通过科学方法给予终极解释。人类理解自身的必须的不止是人文及科学，而是交融在一起的新的启蒙，而只有在这样学科融合的大坏境中，才能产生更多的创造。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;更多阅读&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651383522&amp;amp;idx=1&amp;amp;sn=ab9a5e820a8d4566c51912f206363cbc&amp;amp;chksm=84f3c8a3b38441b5a781dff83e24405fcf95f482d46713eabb83bd35c8266345f14ca5ba5e6c&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot;&gt;创造力不是无中生有-读《The runaway Species》&lt;/a&gt;&lt;br /&gt;&lt;/span&gt;&lt;/p&gt;

</description>
<pubDate>Sat, 15 Dec 2018 03:57:00 +0000</pubDate>
<dc:language>zh-CN</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.jintiankansha.me/t/qNtoXCwHis</dc:identifier>
</item>
<item>
<title>Alpha Zero登上Science封面- 听铁哥浅析阿尔法元</title>
<link>http://www.jintiankansha.me/t/NNQW9Ngv1Z</link>
<guid isPermaLink="true" >http://www.jintiankansha.me/t/NNQW9Ngv1Z</guid>
<description>&lt;section helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; sans=&quot;&quot; gb=&quot;&quot; yahei=&quot;&quot; ui=&quot;&quot; arial=&quot;&quot; sans-serif=&quot;&quot; justify=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;&gt;&lt;span&gt;&lt;strong mpa-from-tpl=&quot;t&quot;&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;导语&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;section helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; sans=&quot;&quot; gb=&quot;&quot; yahei=&quot;&quot; ui=&quot;&quot; arial=&quot;&quot; sans-serif=&quot;&quot; justify=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot; solid=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;&gt;&lt;section readability=&quot;2.5&quot;&gt;&lt;section readability=&quot;5&quot;&gt;&lt;p&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;从1997年“深蓝”击败国际象棋冠军卡斯帕罗夫，到2017年AlphaGo击败围棋冠军柯洁，AI 在与人类对抗训练中不断提高，而脱胎于 AlphaGo 的 AlphaZero 则完全脱离了人类棋谱的束缚，通过自我博弈，成为多种棋类游戏的王者。在最新一期 Science 中，首次全方位揭示了 AlphaZero 背后的原理。&lt;/span&gt;&lt;/p&gt;
&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;
&lt;p&gt;&lt;img data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCy68f4biajmzchV6stRScXfF9pGthBXRAX51xOibqwd9XYlre3OqVF7SibDeicR71zoFUeJGKhpXSMibQ/640?&quot; class=&quot;&quot; data-ratio=&quot;1.2716763005780347&quot; data-w=&quot;346&quot;/&gt;&lt;/p&gt;

&lt;p&gt;阿尔法元超越自己的大哥-阿尔法狗。 这一代算法被deepmind命名为Alphago Zero， 中文阿尔法元，“元” 含有起点，创世之意。 总之，就是从零开始 ，其实这个元字用意很深， 一方面说， 这个算法是不需要人类数据指导，也不需要它哥哥（阿法狗）指导，就自己演化出来。 另一方面也可以理解为它可以开启新纪元。&lt;br/&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;dt5il-0-0&quot;&gt;当然， 同时谷歌也宣传了它的TPU， 只需要4台TPU运行几天的功夫就可以了。 那么， 这次的大新闻是不是一个谷歌精心策划的商业广告，还是真的隐藏天机。铁哥就来给大家解读一下阿法元和其背后的深度强化学习，看看这次的大新闻算不算得从零到一。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;8ibcs-0-0&quot;&gt;如果大家了解计算机学下棋的事情，就会了解到几十年前，我们就已经用穷举法来解决棋类问题了，在国际象棋这类游戏里， 计算机会以比人脑快的多的速度推演两军对峙的未来，在运用零和游戏里固有的减少风险策略， 在1996年就可以让人类棋手甘拜下风。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;acaae-0-0&quot;&gt;穷举法不适用围棋，因为跟其灿若宇宙星辰的可能性搜索空间（每一步19*19可能，若干步骤后就是天文数字，这种由于可能性爆炸导致的悲剧也称为维度灾难），被称为人工智能界的mission impossible。 而在2015年， 梦幻被粉碎，原因在于深度卷积网络的幽灵终于潜入到了棋类游戏领域。 深度学习最擅长把高维度的问题自动的降维，从而解决了刚说过的维度灾难，如宇宙星辰般的搜索空间瞬间被压榨到很小，在此时的机器算法面前， 围棋无非是一个当年的国际象棋。&lt;/span&gt;&lt;/p&gt;


&lt;p&gt;&lt;img class=&quot;Image FocusPlugin--unfocused Image--isBlock&quot; data-ratio=&quot;0.5&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibccPns0lxHhsOFyp82BuMcps0Xjicz0kQJbhFWNb3Dev590WibnD2QZA8JbS69KEBdNIGTlzLDicZu2fQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;600&quot; height=&quot;300&quot; width=&quot;600&quot;/&gt;&lt;/p&gt;


&lt;p&gt;&lt;span data-offset-key=&quot;7ufh3-0-0&quot;&gt;然而当时立下首要功勋的深度卷积网络，却需要学习三千万组人类数据进行训练， 而整个训练过程需要的能量据说要耗费几吨煤炭。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;19ekg-0-0&quot;&gt;人们说，你秒杀人类智商的阿法狗无非是比人类看棋谱的速度快，难道还真的懂围棋吗？ 你所作的顶多是模仿，里面的强化学习到底有多少作用， 真的不知道。  &lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;389o-0-0&quot;&gt;然而今天，阿法元却能够在不用那3000万数据的时候来个完胜阿法狗。从人工智能的技术角度看， 这是强化学习的胜利， 在不进行监督学习的情况下， 就可以达到一个高于人类的境地。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;cf1o3-0-0&quot;&gt;为什么强化学习如此重要？ 让我们先比较一下监督学习和强化学习的基本思想。 监督学习， 强化学习和无监督学习是机器学习的三大框架。 某一个意义说，监督学习是给定输入和输出，机器来学习输入和输出的关系，一个好的监督学习算法犹如一个预言家， 它能够根据自己之前见过的输入输出关系来预测未知的输入。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;2psih-0-0&quot;&gt;强化学习呢？ 强化学习的三元素是状态，行为和环境奖励。 强化学习条件下， 学习者每一步看到的是它决策的行为结果， 然后导致下一步行动，为了最终游戏的胜利。 一句话说：强化学习强在决策。 监督学习是预言家，强化学习是决策家。&lt;/span&gt;&lt;/p&gt;


&lt;p&gt;&lt;img class=&quot;Image FocusPlugin--unfocused Image--isBlock&quot; data-ratio=&quot;0.48833333333333334&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibccPns0lxHhsOFyp82BuMcpsV4Mu5XbPHGfej0xjDpj72EibTct0ibav9n1Zzn4icv4IWzBMoaWTpialRA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;600&quot; height=&quot;293&quot; width=&quot;600&quot;/&gt;&lt;/p&gt;


&lt;p&gt;&lt;span data-offset-key=&quot;cj562-0-0&quot;&gt;我们一比就明白， 强化学习更像是一个日常决策中的人。我们看到一个老虎，监督学习帮你识别出来它是老虎，那么你可能刚说出来就被它吃了。 而强化学习告诉你赶紧跑，你可能活下来。 &lt;strong&gt;监督学习让你成为复读机，而强化学习让你称之为生物。&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;


&lt;p&gt;&lt;img class=&quot;Image FocusPlugin--unfocused Image--isBlock&quot; data-ratio=&quot;0.29333333333333333&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibccPns0lxHhsOFyp82BuMcpsRxyf7PuFXI3NXVG0IB5N90pmc0QIdZBnEibf4yWCUwhichupUZgjtQkQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;600&quot; height=&quot;176&quot; width=&quot;600&quot;/&gt;&lt;/p&gt;


&lt;p&gt;&lt;span data-offset-key=&quot;bfpem-0-0&quot;&gt;再深一点想，其实学习是为了生存，是赢得game of life（想想那些不太读书就能过得很好生活的真是深谙强化学习的道理）。 强化学习赋予机器以灵魂。监督学习的那些任务反而是在这个宗旨之下产生的。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;80nhn-0-0&quot;&gt;回到围棋， 我们看看强化学习如何决策： 我们在好好理解一些一下“强化” 二字， 强化的意味是： 强化优势经历，反过来，就是弱化劣势经历。当你走了一部棋导致不好结果，之后被选入这一步棋的概率就降低， 而导致胜利的选择被不停的强化，直到你每次都延着最佳路径前进。这听起来很像进化， 而与进化的区别是，进化是严酷的客观环境对随机变化的生物的选择，而强化学习里的单元可以通过梯度下降主动调整策略。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;a1bc6-0-0&quot;&gt;既然强化学习那么牛， 为什么阿法狗还用监督学习这个拐棍呢？一句话说，强化学习太难了！&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;8s35-0-0&quot;&gt;&lt;span data-text=&quot;true&quot;&gt;强化学习有两大难题：&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;ev461-0-0&quot;&gt;1， 奖励时间的不确定性： 今天的努力，可能明天回报， 可能十年后才有回报, 今天带来奖励的事情，明天可能就导致悲剧（比如吸毒很爽未来地狱） 对于游戏里的每一次决策，　你都无法获得立即的反馈，相比监督学习时时可以得到对和错的答案，这个信息实在太弱了， 用来指导学习，那是慢慢的（如何利用这个或有或无的信息，强化学习的一系列方法围绕而来，比如Q-learn）。 　&lt;/span&gt;&lt;/p&gt;
&lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;/&gt; 
&lt;p&gt;&lt;span data-offset-key=&quot;2l540-0-0&quot;&gt;2， 探索与收益的平衡难以掌握： 有的人一辈子抱残守缺，７岁玩泥巴未来就永远玩泥巴。 有的人一辈子都在探索不同的方向，但是换来换去最终庸庸碌碌。而只有恰当把握探索收益平衡的，比如说27岁前读书去不同国家，27岁开始认准一个方向成为大佬，30岁前各种风流倜傥，30岁选个知书达理另一半从一而终。 强化学习始终面临是探索更多空间，还是开始用现在经验收益的矛盾。　&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;3cja1-0-0&quot;&gt;&lt;span data-text=&quot;true&quot;&gt;这两点放到围棋这个搜索空间犹如宇宙星辰的游戏里，估计学习时间也要用生物进化的尺度算， 然而阿尔法元所用的强化学习算法，号称解决了这个问题。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;ajql2-0-0&quot;&gt;仔细看它和它哥哥阿尔法狗的差别没那么大， 只不过这一次的神经网络完全由强化学习训练， 和蒙特卡罗树得融合可以算是完美。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;6716o-0-0&quot;&gt;之前的阿尔法狗有策略和估值网络（都是深度卷积网络），策略负责把棋盘现在的状态转化为可能的行为概率， 这个东西被称为策略（policy，是由每个可能的行为概率构成的向量，简称策略向量） ，估值则是输入目前的棋盘状态得到最终结果的概率。 这两个网络在这一次被合成一个巨大的深度残差网络（卷积网络的一种）。&lt;/span&gt;&lt;/p&gt;


&lt;p&gt;&lt;img class=&quot;Image FocusPlugin--unfocused Image--isBlock&quot; data-ratio=&quot;0.9314079422382672&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibccPns0lxHhsOFyp82BuMcpsoH0hA9BP2pujxMyw7ZHia69xRjmMAibl7JhVWWsiaCaE9FebZrEpP0NKg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;554&quot; height=&quot;516&quot; width=&quot;554&quot;/&gt;&lt;/p&gt;


&lt;p&gt;&lt;span data-offset-key=&quot;7nudg-0-0&quot;&gt;Nature图： 深度卷积网络计算概率&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;8uljh-0-0&quot;&gt;深度卷积网络擅长整体对图像信息进行编码， 我们可以把这个巨大的残差网络所作的事情看成白日梦者对未来的总体规划。 多层卷积本身的天性决定它擅长从这种19*19的格子图像总结出意思来，强化学习的信息一旦可以训练网络，就会产生意想不到的效果。而之后MCTS蒙特卡罗树则对这种初步的结论进行实践修正。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;d3a31-0-0&quot;&gt;在这里回顾一下蒙特卡洛树是怎么工作的，说到蒙特卡洛， 这是大名鼎鼎的随机抽样方法。所谓树，大家一定可以想到决策树，树的节点是某一刻的状态，而枝杈代表一个决策（行为），而这里的蒙特卡洛树即生成整个决策树的过程，通过大量的实验（犹如蒙特卡洛抽样的过程）得到每个决策行为取胜的概率。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;d3a31-0-0&quot;&gt;决策树从一个状态s出发，每个分支代表一个可能行为（a），而且有一个代表最终赢率的分数与之对应，我们选择分数最高的那个行为继续展开（下一次行动），得到新的状态，用相同的规则行动，直到游戏结束， 最终赢的走法加一分， 输的走法减一分，依次往复模拟无数次后，就会得到从s出发不同决策赢得比赛的概率。 这个过程酷似进化选择算法， 就是让那些有优势的选择有更高的繁殖子代概率， 最终胜出。虽说这仅仅是阿尔法元的一小步，却包含了著名的Q-learning和马尔科夫决策树的思想。  &lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;qrgk-0-0&quot;&gt;我们来看每一步决策神经网络和蒙特卡洛树是怎么结合的： &lt;/span&gt;&lt;span data-offset-key=&quot;qrgk-0-1&quot;&gt;&lt;span data-text=&quot;true&quot;&gt;决策分为搜索阶段和行为阶段&lt;/span&gt;&lt;/span&gt;&lt;span data-offset-key=&quot;qrgk-0-2&quot;&gt;。假定现在我处在状态s，在搜索阶段神经网络对我所能做的所有行为（a）进行根据对未来的猜测进行预判&lt;/span&gt;，生成赢棋的概率v和策略向量p（s，a）。 当然这个预判开始很不靠谱， 蒙特卡洛树在此基础通过无数次模拟实践展开来（注意均是在状态s上），来实践出靠谱的策略向量pi（s，a）。&lt;/p&gt;

&lt;p&gt;有了神经网络的帮助，蒙特卡罗树展开不是瞎展开， 也不是从零开始，每一个树的新分支上，我们都通过神经网络给它一个是正确步骤的先验概率（P）和初始的赢率（V），代表走它通向胜利的概率。在神经网络助攻下，蒙特卡洛树可以更快的更新策略向量（每个行为选择的概率）。此时搜索阶段结束， 我们从这个策略向量里通过抽样得到我们最终进行的行为，是为行为阶段。 这下一步棋还真不容易啊！&lt;/p&gt;


&lt;p&gt;&lt;img class=&quot;Image FocusPlugin--unfocused Image--isBlock&quot; data-ratio=&quot;0.26666666666666666&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibccPns0lxHhsOFyp82BuMcpsiajKyaOtibGwOv1hLBtLtjgNtSAAYibPBwNaiapFvJPyWb8FFcsTOWCkibg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;600&quot; height=&quot;160&quot; width=&quot;600&quot;/&gt;&lt;/p&gt;


&lt;p&gt;&lt;span data-offset-key=&quot;77j4h-0-0&quot;&gt;Nature图： 策略更新的方法&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;a1pa3-0-0&quot;&gt;最终当游戏结束的时候，神经网络的权重开始更新，这个更新的过程里，我们把整个游戏的过程分成很多小段， 比较神经网络预测的概率和蒙特卡洛树算出来的（策略向量之间的差异），以及预测结果与最终结果的差距进行梯度下降（梯度由如下公式得到，此处混合之前的策略和估值网络）。&lt;/span&gt;&lt;/p&gt;


&lt;p&gt;&lt;img class=&quot;Image FocusPlugin--unfocused Image--isBlock&quot; data-ratio=&quot;0.14333333333333334&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibccPns0lxHhsOFyp82BuMcpsWbnhR49iaFicbgX6lQ8jibSQyN8WvXlZ5cYhTkh1u7EibTbDcbDMWal7Dg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;600&quot; height=&quot;86&quot; width=&quot;600&quot;/&gt;&lt;/p&gt;



&lt;p&gt;&lt;span data-offset-key=&quot;9jrnd-0-0&quot;&gt;这样周而复始，我们可以推断，最终神经网络的预测将越来越靠谱，和蒙特卡洛树给出的分析越来越一致。 而围棋的套路也会被一一发明出来，所谓无师自通。&lt;/span&gt;&lt;/p&gt;



&lt;p&gt;&lt;img class=&quot;Image FocusPlugin--unfocused Image--isBlock&quot; data-ratio=&quot;0.8633333333333333&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibccPns0lxHhsOFyp82BuMcpsQTc3L6c3EdUyfKoVVa0CpgQciacvMYiaHYcdDGYFQaps8Q0NOrXqoJJQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;600&quot; height=&quot;518&quot; width=&quot;600&quot;/&gt;&lt;/p&gt;


&lt;p&gt;&lt;span data-offset-key=&quot;5ibte-0-0&quot;&gt;Nature图： 看看右下的图，是不是很像人类选手常用的招！  &lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;9c2ea-0-0&quot;&gt;为什么说阿尔法元敢叫元？ 如果从技术角度看，这一次的阿尔法元没有那么多新的东西，而是在之前基础上让强化学习进行的更彻底了，然而它所展示的深度强化学习的应用未来，却是十分诱人的。&lt;/span&gt;&lt;/p&gt;



&lt;p&gt;&lt;img class=&quot;Image FocusPlugin--unfocused Image--isBlock&quot; data-ratio=&quot;0.35&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibccPns0lxHhsOFyp82BuMcpsRGYzWDxqCfib19LOQ0gfBSD7qFIIaSQ3bAfbA6ibr02JT5uPI4Oic2wiaw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;600&quot; height=&quot;210&quot; width=&quot;600&quot;/&gt;&lt;/p&gt;


&lt;p&gt;&lt;span data-offset-key=&quot;fmjkn-0-0&quot;&gt;图： 强化学习的胜利（蓝）对比监督学习（紫）和监督+强化学习（虚线）&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;987es-0-0&quot;&gt;首先，我们看到， 并不是每一件机器学习的事情， 都需要和数据，尤其是需要大量人力的标注数据死磕， 而是可以通过恰当的设立模拟器（比如此处用到的蒙卡树） 来弥补。阿尔法元不是不需要数据，而是数据都是自己模拟产生的。 模拟+深度强化学习， &lt;strong&gt;在简单的游戏规则下，一些复杂的行为范式可以进化出来，而且可以比人类设计的还好&lt;/strong&gt;， 这， 你就可以大开脑洞了。&lt;/span&gt;&lt;/p&gt;
&lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;/&gt; 
&lt;p&gt;&lt;span data-offset-key=&quot;ckimk-0-0&quot;&gt;这件事在很多设计性的工作里实在是太诱人了。 无论是设计新材料，建筑，还是衣服，&lt;strong&gt;这些可变维度很高的事物，你都可以想象设立一个模拟仿真环境，再设立一个相应的神经网络去做各种尝试，最终设计出的结果有一个奖惩函数反馈，来让这个网络来学习。&lt;/strong&gt;这就打破了深度学习创业只和手里有大量数据的垄断者相关的梦魇。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;8k7da-0-0&quot;&gt;这里的深度强化技术， 也才只展示了冰山一角， 在一类被称为SLAM的技术上， 深度强化学习被证明了强大的控制能力， 它能够驱动机器人在非常复杂的空间里进行探索无需GPS，对于这一类深度学习任务， 有别于alphago的任务，因为围棋属于完全信息的博弈， 而真正的空间探索，是通过感知系统探测到的不完全信息， 通过记忆在时间尺度上的综合，这一点，只有搬出大名鼎鼎的LSTM来对付了。&lt;/span&gt;&lt;/p&gt;


&lt;p&gt;&lt;img class=&quot;Image FocusPlugin--unfocused Image--isBlock&quot; data-ratio=&quot;0.6333333333333333&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibccPns0lxHhsOFyp82BuMcpskhySEVQXKxWy56LKHsAJ0XXnA0hdiaAua0iaZrdWHaTzGDjdAO0xMQibQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;600&quot; height=&quot;380&quot; width=&quot;600&quot;/&gt;&lt;/p&gt;



&lt;p&gt;&lt;span data-offset-key=&quot;4nqss-0-0&quot;&gt;能够控制运动的深度强化学习，迟早会改变工业界，它不仅是无人车里的核心技术， 更是对话，推荐系统， 金融交易， 甚至是图像识别的利器，几乎各类需要监督学习的事情，说到底强化学习都有实力。 你如果制造一个聊天机器人， 你当然希望它能够揣测你的意图和你谈情说爱而不是背书。 你要一个推荐系统， 你当然不需要它天天给你推你刚看过的小黄片，而是带着你探索一段BBC-性的秘密。  所以， 强化学习， 是人工智能的大势所趋啊。&lt;/span&gt;&lt;/p&gt;


&lt;p&gt;&lt;img class=&quot;Image FocusPlugin--unfocused Image--isBlock&quot; data-ratio=&quot;0.66&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibccPns0lxHhsOFyp82BuMcpsjUU1ewb6V3XTQvWIy5IuR5tHXrIBWdnPzhAQcE4h8zY3CB0KJXVAOQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;600&quot; height=&quot;396&quot; width=&quot;600&quot;/&gt;&lt;/p&gt;

&lt;p&gt;图：强化学习下的装配空间&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;Image FocusPlugin--unfocused Image--isBlock&quot; data-ratio=&quot;0.5631970260223048&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibccPns0lxHhsOFyp82BuMcps8ic1kUm8dgUofdWt4AT4wib66t7NzYhTzVm1ribBxPmeFjgFB0jJhgjPA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;538&quot; height=&quot;303&quot; width=&quot;538&quot;/&gt;&lt;/p&gt;

&lt;p&gt;图： 强化学习下的物流车间&lt;/p&gt;





&lt;p&gt;&lt;span data-offset-key=&quot;evrgp-0-0&quot;&gt;更有甚者，我们可以设立一个具有类似地球的物理环境的地方，让配备了深度强化学习系统的虚拟生物进行各种活动，看它们能否利用这个环境发现和利用其中的物理定律。&lt;/span&gt;&lt;/p&gt;
&lt;pre contenteditable-directive=&quot;&quot; mm-paste=&quot;&quot; ng-blur=&quot;editAreaBlur($event)&quot; ng-model=&quot;editAreaCtn&quot; ng-click=&quot;editAreaClick($event)&quot; ng-keyup=&quot;editAreaKeyup($event)&quot; ng-keydown=&quot;editAreaKeydown($event)&quot;&gt;
&lt;span&gt;&lt;br/&gt;&lt;/span&gt;
&lt;/pre&gt;
&lt;pre contenteditable-directive=&quot;&quot; mm-paste=&quot;&quot; ng-blur=&quot;editAreaBlur($event)&quot; ng-model=&quot;editAreaCtn&quot; ng-click=&quot;editAreaClick($event)&quot; ng-keyup=&quot;editAreaKeyup($event)&quot; ng-keydown=&quot;editAreaKeydown($event)&quot;&gt;
&lt;img data-s=&quot;300,640&quot; data-type=&quot;jpeg&quot; data-ratio=&quot;0.10966542750929369&quot; data-w=&quot;538&quot; class=&quot;&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz/dcEP2tDMibccdYT8ViaXic1q1ibC3U0Ub0WhaaX0dxl5oRO3YicRx7fSozVkP7Z5UfiaQdwyaxxEM5AZaMAGHjY4yS4Q/640?wx_fmt=jpeg&quot;/&gt;&lt;/pre&gt;



&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; sans=&quot;&quot; gb=&quot;&quot; yahei=&quot;&quot; ui=&quot;&quot; arial=&quot;&quot; sans-serif=&quot;&quot; justify=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;&gt;&lt;span data-offset-key=&quot;4csh-0-0&quot;&gt;铁哥本人的研究目前涉及深度强化学习与RNN的结合， 因此参与课程也是与铁哥结盟， 共同进军未来的深度强化学习世界的机会。&lt;/span&gt;&lt;/p&gt;

&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; sans=&quot;&quot; gb=&quot;&quot; yahei=&quot;&quot; ui=&quot;&quot; arial=&quot;&quot; sans-serif=&quot;&quot; justify=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;&gt;&lt;img class=&quot;&quot; data-ratio=&quot;10.284953395472703&quot; data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-w=&quot;751&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcfqJgX6L51kcnJ07DHpdBzq4CdJ7Pj2yE9q9ZGjIpLAQSMrWe8ricgP18icaBWjc39YTLsPLCvWsJNQ/640?wx_fmt=png&quot;/&gt;&lt;/p&gt;










</description>
<pubDate>Sun, 09 Dec 2018 02:05:53 +0000</pubDate>
<dc:language>zh-CN</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.jintiankansha.me/t/NNQW9Ngv1Z</dc:identifier>
</item>
</channel>
</rss>