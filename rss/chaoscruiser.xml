<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="css/feed.xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/" xmlns:og="http://ogp.me/ns#">
<channel>
<atom:link rel="self" href="http://192.168.1.4/fivefilters/makefulltextfeed.php?url=feed43.com%2Fchaoscruiser-jtks.xml&amp;max=5&amp;links=preserve&amp;exc=1" />
<atom:link rel="alternate" title="Source URL" href="http://feed43.com/chaoscruiser-jtks.xml" />
<atom:link rel="related" title="Subscribe to feed" href="http://www.subtome.com/#/subscribe?feeds=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed43.com%252Fchaoscruiser-jtks.xml%26max%3D5%26links%3Dpreserve%26exc%3D1&amp;back=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed43.com%252Fchaoscruiser-jtks.xml%26max%3D5%26links%3Dpreserve%26exc%3D1" />
<title>混沌巡洋舰</title>
<link>http://www.jintiankansha.me/column/ultiWL8Axg</link>
<description>混沌巡洋舰 - 今天看啥</description>
<ttl>360</ttl>
<item>
<title>随机网络中的智慧</title>
<link>http://www.jintiankansha.me/t/JIJMBiPkwj</link>
<guid isPermaLink="true" >http://www.jintiankansha.me/t/JIJMBiPkwj</guid>
<description>&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;网络是从人类智能到深度学习的基础，可能所有人都认为只有训练好的具有特定结构的网络才能具有功能，如同生物的功能是由结构决定的， 精巧设计的结构可以产生特定的功能， 大概高中生物老师就给我们灌输了这个观念。 而在网络的世界， 这就意味着你要某个功能，就要先产生那样的结构，比如一个具有特定结构的CNN。&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;然而， 可能你不知道的是， 一个随机连接的网络也具有功能。 什么叫随机啊？ 就是任意单元和单元之间连接与否是随机的， 看起来很混乱，它们居然能做事？ 不仅如此， 它能做的事情还很酷炫：比如， 预测火焰的形状演化。&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;注：火焰的跳动，是一个我们常说的混沌系统， 所谓难以用常规方法预测， 确可以一定程度被随机网络征服，这是一个以复杂对抗复杂，用无常应对无常的经典例子。&lt;/p&gt;
&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.5615384615384615&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcewMUIibIuV7JdontKCkatxCwjxNiat12Ber6FWgHTw70o1ib9sGxPaUWa4OqqzOeiax2iacJ4u5gENmyg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;520&quot; width=&quot;520&quot;/&gt;&lt;p&gt;Machine Learning&amp;amp;amp;amp;#39;s &amp;amp;amp;amp;#39;Amazing&amp;amp;amp;amp;#39; Ability to Predict Chaos&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;任何一个网络的连接都可以由一个矩阵来刻画， 刻画随机网络单元和单元之间的连接就是随机矩阵。&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; center=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;&lt;span&gt;&lt;strong&gt;1）什么是随机矩阵 ？&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;可能每个人都很清楚矩阵， 但是提到随机矩阵，就不是每个人都清楚了。 事实上， 随机矩阵是研究所有和网络有关的科学技术， 从机器学习到复杂系统， 极为重要的工具。 那么我们就一层层拨开随机矩阵的神秘面纱。&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;首先， 如果矩阵里每行每列的元素都从独立分布的高斯里抽样，那个， 这样的一个方阵称为随机矩阵。&lt;/p&gt;
&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.26666666666666666&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcewMUIibIuV7JdontKCkatxC8McjJVpeuZbYZ99fRzG8iaQ3wPFrKRgYPOtboFZMrO8q8PUUFhN9eKQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;720&quot; width=&quot;904&quot;/&gt;&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;看起来没什么乱用对吧？ 我们还是直接进入随机矩阵的数学物理本质： 事实上， 随机矩阵用于描述一个动力系统内不同元素间的相互作用， 具体的例子比如：&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;1， 描述一个马尔可夫过程的概率迁移矩阵： 矩阵可以用来描述一个马尔可夫过程的迁移矩阵， 那么该矩阵就定义了一个随机连接的图网络， 从i点到j点的迁移概率由对应的矩阵元素表达（因此每一行的和需要为1）。&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;2， 描述一个动力系统里任意的n个元素和n个元素的相互作用关系， 这n个元素， 既可以是人工或生物神经网络里的神经元， 也可以是生态系统里的各个物种， 或金融市场相互作用的交易者， 我们刚刚说的预测混沌的网络就符合这个类型。 此处随机矩阵就是随机网络的数学表示&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; center=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;&lt;strong&gt;&lt;span&gt;2）随机矩阵是怎样刻画一个动力系统的&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;这里， 我们从最简单的系统-二维的线性动力学系统开始， 二维的动力系统定义为：&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.17567567567567569&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_svg/hNWCQ9bibbzFWeywyrPJ78CTicqXAeOgPnF1ia9ib42miafRnAJLIbibIic2m4yt0P3oSjm9DZCB43s85xgsyY8RPsEMtDHM7avvK32/640?wx_fmt=svg&quot; data-type=&quot;svg&quot; data-w=&quot;148&quot;/&gt;&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.1780821917808219&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_svg/hNWCQ9bibbzFWeywyrPJ78CTicqXAeOgPnowJGOKPTyrK4ic68XPZBGq7z9RBj4YldHQByhk95mZgoFGHzVDRrzffibib3F2d9UHd/640?wx_fmt=svg&quot; data-type=&quot;svg&quot; data-w=&quot;146&quot;/&gt;&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;可以由一个a，b，c，d组成的二维矩阵（雅可比矩阵）刻画。 这个两两作用的系统在自然界比比皆是， 比如著名的猎手-猎物方程。&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;对于任何动力学系统， 我们都要先抓住它的定点， 而整个系统的性质， 由定点向外周扩散迎刃而解。 那么这个简单的线性系统有一个显而易见的定点就是x=0， y=0.&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;定点的作用就像一个巨大的吸引中心， 系统的演化无论多么复杂， 都是以某种形式围绕它展开。 这些展开形式可以被概括到一个叫相图的二维平面里， 这个平面是由二维系统的两个变量为坐标轴， 概括了系统从任何初始状态（x，y）开始演化， 它的未来发展轨迹。&lt;/p&gt;
&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.6458036984352774&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcewMUIibIuV7JdontKCkatxCLpIPMCcO48JalHajRLhT6yJs5FFAvKXryicGpqkIlNV8t4TgoHFK9Lw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;703&quot; width=&quot;703&quot;/&gt;&lt;p&gt;相图的做法非常简单， 只需要对任意状态求解其变化趋势(dx/dt, dy/dt)并在平面上用箭头表达， 我们就可以看到整个系统从任意点开始的未来走势。&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;有了定点后， 系统具体的演化方法则由它的雅可比矩阵决定。 在这里雅可比矩阵也就是abcd所确定的连接矩阵&lt;img class=&quot;rich_pages&quot; data-ratio=&quot;0.8115942028985508&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcewMUIibIuV7JdontKCkatxCKAUmF6GAyNmomkLGX8SVq0y4UFoChXoRZDC4hlxAV59copOqn0uvIA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;69&quot; helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; sans=&quot;&quot; gb=&quot;&quot; yahei=&quot;&quot; ui=&quot;&quot; arial=&quot;&quot; sans-serif=&quot;&quot;/&gt;这个矩阵里的各个元素，它将确定，随着时间，系统将去向何方。 我们可以按照特征矩阵的行列式A = ad -bc 以及迹（trace） a +d 作为坐标轴对系统分类。为什么是这两个东西， 你想一下， 矩阵本身由特征值决定， 在特征分解后，A代表特征值的乘积，trace是特征值的和， 这两个量体现了特征值的性质。 矩阵的特征值是一个复数， 对应复平面上的两个点。 这两个点的几何性质由刚刚说的行列式和迹决定。&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;数学的好处在于一次得到所有的可能性。 一切可能皆由定点展开， 这些情况按照定点稳定与否（演化是趋紧还是远离它）， 以及趋于（或远离）定点的方式展开。&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;我们通常用poincare diagram 来表达所有情况。 从左向右， 定点从稳定到不稳定（特征值由负到正），从下到上， 趋于或离开定点的方式由线性变换到旋转（特征值由实入虚， 此处以delta&lt;img class=&quot;&quot; data-ratio=&quot;0.22807017543859648&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_svg/hNWCQ9bibbzFWeywyrPJ78CTicqXAeOgPn0lfXOYcMnxjePpHrslD4IBgDFCypck09y8BmxcFPISX9GYICMLdSWQxTrgkgGCHI/640?wx_fmt=svg&quot; data-type=&quot;svg&quot; data-w=&quot;114&quot;/&gt; 为界）。方程你可以把整个解析解写出来&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;&lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;/&gt; &lt;img class=&quot;&quot; data-ratio=&quot;0.11764705882352941&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_svg/hNWCQ9bibbzFWeywyrPJ78CTicqXAeOgPnpHeZicycd3gUJqV0lQUgbRFkj75w6wsms7IPciavzOPeTuV5hCGCA7Y9u5Sibx8lJQ3/640?wx_fmt=svg&quot; data-type=&quot;svg&quot; data-w=&quot;272&quot;/&gt; X=（x，y）&lt;/p&gt;
&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.6486111111111111&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcewMUIibIuV7JdontKCkatxClGz8yibVYIEWOQ8sYH3ibHGO37cI3U3sJvKlMdjl7OxBsMKcnGGYRd8w/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;720&quot; width=&quot;720&quot;/&gt;&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;由如上的两个坐标轴和一个抛物线，我们把平面分割成了6个区域。 你只需要记住临界态的性质， 中间区域及其过渡。 抓住这个平面，就抓住了所有的二维线性动力系统。&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;y轴上半 - 此处特征值为纯虚数， 实部为0， 我们既不趋近也不远离， 这也就是周期运动， 或被称为极限环。 系统围绕定点做圆周运动，是稳定和不稳定的过度状态。 典型例子如二维谐振子 - 理解各种复杂的物理系统的毕达哥拉斯之剑。 加入一定非线性形式我们得到猎手-猎物方程， 狼和羊， 资本和劳动力矛盾下的振动平衡。 自然界还是人类现象中振动如此普遍， 背后正是这类动力关系的体现。&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.7513888888888889&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcewMUIibIuV7JdontKCkatxCE1mPUVMIS7t8P4tdgNPiak0C0qkfJRosgxqAuFW7W0cGPMa5uOfPexA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;720&quot; width=&quot;720&quot;/&gt;&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;X轴下半和det中间区域： 稳定定点， 代表趋势所致， 稳定定点可以预测事物的一般走势（稳定不变的平衡态，任何远离它的阴谋都将破灭），因为在它的管辖区域里， 无论如何折腾， 都回回到它， 因此稳定定点也可以用来存储信息。&lt;/p&gt;
&lt;img class=&quot;content_image lazy&quot; data-ratio=&quot;0.5222222222222223&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcewMUIibIuV7JdontKCkatxCJ44S6z9NENNpS3SzWW0gUjULgTXxDHZ1lxSAwypENapLL0JAO1IW9A/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;360&quot; width=&quot;360&quot;/&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;Y轴下半及整个下半平面：鞍点（Saddle）与上半的区别在于运动方式， 刚刚说的转动变成线性， 然而依然是从稳定到不稳定的临界，此处的效果是从一个特征向量方向你趋于定点（稳定），而另一个方向则远离（不稳定）。 这样的系统可以表示神经网络的决策或分类： 从一个方向得到的结果是A， 从另一些方向得到的结果是B，这就是天然的分类器。鞍点也用来介导一个动力系统的相变， 从一个方向你达到定点， 再在另外一个方向分离， 例如所有的热恋到失恋的过程。&lt;/p&gt;
&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;1&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcewMUIibIuV7JdontKCkatxCol66Ox1rBtdqhxjVbNYpRQnZ9kcm07I49ZvmhWNbsoTxWrgWxrqMpg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;720&quot; width=&quot;1200&quot;/&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;X轴： 刚刚那个图一个更加特殊的情况是X轴上（det 为0）的那些解，这条线的数学含义是我们某个特征值为0的情况（此时矩阵的迹为0）， 啥叫特征值为0？ 它意味着只要我们在这个为0的特征值所对应的特征向量，我们就有 &lt;img class=&quot;&quot; data-ratio=&quot;0.16883116883116883&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_svg/hNWCQ9bibbzFWeywyrPJ78CTicqXAeOgPnS2iaPDxw1nk7d9THKKpjIAry6HnZeicV7bkjqfQCF8Iib56aOjBOWjJdK5HXhmDACzC/640?wx_fmt=svg&quot; data-type=&quot;svg&quot; data-w=&quot;154&quot;/&gt; ，也就是所有解都是定点！ 而它导致的结果是所谓的线性吸引子， 定点不在是一点而是一条线（line attractor）。 我们会看到这个解在众多的问题里意义重大，比如神经编码 。这是因为线性吸引子是路径依赖的代言人， 你从不同的起点出发， 会停留在不同的位置上， 这就好像把初刻的历史凝固了下来，因为可以比单个稳定定点编码更复杂的信息-甚至是某种抽象关系。&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;下图表示一个更一般的非线性系统里的line attractor 。&lt;/p&gt;
&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.8024193548387096&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcewMUIibIuV7JdontKCkatxCdiboiaV3ic2pqcPDtHw5KoPsLV9KiaTyt1b9WHpaU8G7m7s6eFeiaerjFIQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;496&quot; width=&quot;496&quot;/&gt;&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;更多信息请见&lt;span class=&quot;visible&quot;&gt;def.fe.up.pt/dynamics/l&lt;/span&gt;&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; center=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;&lt;strong&gt;&lt;span&gt;3）随机矩阵和动力系统的联系&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;理解了二维系统， 你可以抓住它内在本质的东西， 然后一级级向高维延申。 我们回到我们的主题-随机矩阵， 随机矩阵刻画一个高维动力系统， 其不同单元间的连接是随机的。 如果我们假定高维系统依然是线性的， 那么它一般写成：&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.15028901734104047&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_svg/hNWCQ9bibbzFWeywyrPJ78CTicqXAeOgPnanMX88UT29ByXN3lcaycF9B8T9oC6HLC224Uv4hmegjGicLh08fqxfobB3JeEAob9/640?wx_fmt=svg&quot; data-type=&quot;svg&quot; data-w=&quot;173&quot;/&gt;&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;A是一个nxn的方阵， 由刚刚说的随机数确定。&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;首先， 寻找定点， &lt;img class=&quot;&quot; data-ratio=&quot;0.1590909090909091&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_svg/hNWCQ9bibbzFWeywyrPJ78CTicqXAeOgPnIUvq9flCPzXEXNH9pVebkwZIZ086vQuegLN74k3wPQgEWSkgCibZszD0cBdzB5w0l/640?wx_fmt=svg&quot; data-type=&quot;svg&quot; data-w=&quot;132&quot;/&gt; 这样的解有一个是肯定的，就是 &lt;img class=&quot;&quot; data-ratio=&quot;0.35714285714285715&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_svg/hNWCQ9bibbzFWeywyrPJ78CTicqXAeOgPnbiaeJw22g2oWBCovBJryiaYgfnrIo0icqq0uO2hNEW7wIUDX9jFY1Dxg3AtLHGaPsdR/640?wx_fmt=svg&quot; data-type=&quot;svg&quot; data-w=&quot;56&quot;/&gt;&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;其余性质将由矩阵的特征值和特征向量决定。 我们对连接矩阵A进行特征分解， 得到一系列的特征值和特征向量， 我首先让你猜一下如果你把它的特征值和特征向量在复平面上展开， 它们会长成什么样呢？&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;你依然从二维线性系统， 一个2x2的方阵入手。 这个矩阵的特征值如果你画在复平面上长什么样呢？ 这一类矩阵有两个最特别的情形， 一个对角线为0实对称 &lt;img class=&quot;&quot; data-ratio=&quot;0.3333333333333333&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_svg/hNWCQ9bibbzFWeywyrPJ78CTicqXAeOgPn5qFcSoict0B4Lgvxdicndsf6mIgozyLtNXsMYHz7qPDHSaucBQHscN4f0zrssdUy9r/640?wx_fmt=svg&quot; data-type=&quot;svg&quot; data-w=&quot;72&quot;/&gt; ， 一个对角线为0的反对称 &lt;img class=&quot;&quot; data-ratio=&quot;0.29545454545454547&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_svg/hNWCQ9bibbzFWeywyrPJ78CTicqXAeOgPnqoOjdvicdmlLqWWR0gc3FRZwHh9DGGPUjwhE73XhFJZb9ibBoowWq0BAiafxKiaECblL/640?wx_fmt=svg&quot; data-type=&quot;svg&quot; data-w=&quot;88&quot;/&gt;&lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;/&gt;   , 对于情况一我们得到的两个特征值是-a和a（假定非对角元素为a）， 对于情况2我们有-ai和ai也就是把它们换到虚轴上（这正是刚刚说的谐振子解）。 由此你进行一个类推， 如果我的矩阵的元素不在是这两个特殊情况而是随机的， 我只保证这些矩阵元素每个的期望均是0， 然后你要求出特征值的分布会是什么样的？ 刚刚的解一个是沿着实轴相对原点对称， 一个是沿着虚轴相对原点对称。 如果综合起来呢？ 在实轴和虚轴组成的复平面上， 我们会得到任意方向沿着原点对称的一组点， 从而组成最完美的一个图形- 也就是， 一个圆！ 具体求解请见论文（Introduction to Random Matrices-Theory and Practice）。&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;好了， 那么维度增加呢？ 当你的矩阵元素越来越多， 这个时候我的高维矩阵的特征值个数将等于我们的矩阵维数， 当这个数字达到一定程度， 我们任意一个矩阵的特征值都将逼近刚刚说的那个所有可能二维矩阵的特征分布， 也就是一个圆，至少非常接近！&lt;/p&gt;
&lt;img class=&quot;content_image lazy&quot; data-ratio=&quot;1.0338345864661653&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcewMUIibIuV7JdontKCkatxC4j1S0MTDia6yp4ibPqT8UsxOG04bkzt2XTlrtRkoHcwDb8eVKHKWN0Rg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;266&quot; width=&quot;266&quot;/&gt;&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;好了， 从这里我们可以立刻领悟到的是什么？ 特征向量和特征值携带所有矩阵的信息， 那么所有的随机矩阵的性质是类似的。这里只有一个东西是变化的， 就是圆的半径。 这个量有什么意义呢？还回到二维情况进行对比， 在我们刚刚的情况里 ， 矩阵的trace从小于0到大于0引起整个系统从稳定定点过度到一个不稳定定点， 而此处， 这个圆的半径， 正是起到类似的作用。&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;我们把整个动力方程写成：&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.1477832512315271&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_svg/hNWCQ9bibbzFWeywyrPJ78CTicqXAeOgPnriapf3Nw8S5f6Dtiat6gejb886Bpno7WU8Hia4gzLgHrEDJrbt8SvibQfvW2QKdpcM8n/640?wx_fmt=svg&quot; data-type=&quot;svg&quot; data-w=&quot;203&quot;/&gt;&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;那么矩阵A-I的特征值正负将决定整个系统的稳定性， 这里的情况是如何呢？ 记得刚刚说的我的矩阵A元素都符合是一个平均值为0的高斯分布吗？ A-I这个矩阵就是一个以-1为中心，以A的特征圆为半径的圆形区域， 如果这个圆的半径小于1， 那个特征值整体在负半平面， 系统会趋于稳定的解0。 而一旦半径大于1，这种稳定性就被打破，在高维的系统里， 当你无法回到定点（或闭合轨迹）， 那么登场的正是我们众所周知的混沌， 高维系统的演化进行永不停止的无序运动。 那么1呢？ 我们说， 这就是混沌和稳定的边缘， 记得在二维的系统里， 这个地方会催生非常多的有趣现象， 比如二维谐振子， 比如线性吸引子， 而这些在高维系统里依然正确， 我们会得到各种各样的复杂多解型， 比如-振动解。 而这正是和网络有关的众多有趣现象， 甚至生命本身， 产生的地点。&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;注：所谓混沌， 事实上是一大类不同动力学现象的统称， 它们的共同特点是从某个无限接近的初始点出发， 未来的轨迹是发散的。 混沌的最简单形式是三维非线性方程的洛伦兹吸引子， 在此情况下事实上我们的轨迹围绕这两个定点做某种“周期”运动， 只是这个周期无限复杂， 因此混沌并非等于失控， 而可以是非常复杂的信息载体。 而混沌也可以普遍的存在于高维的线性系统里。&lt;/p&gt;
&lt;img class=&quot;content_image lazy&quot; data-ratio=&quot;0.749034749034749&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcewMUIibIuV7JdontKCkatxCJFWtc8XaPkhftyiaq6ES61SvNy9iaHexmaVia6hLxUm79Uib71oGDf6Vpg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;259&quot; width=&quot;259&quot;/&gt;&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;我们说， 这个特征谱一来决定稳定性， 而来决定趋于定点的方式。 实数代表线性的推进， 虚数代表振动，具体是哪种方式推进， 则决定于你是否在某个特征值对应的特征向量方向上。 我们知道， 我们是一个高维的线性系统，在这个高维王国里， 光坐标轴就可以建立维数N个， 那么对应的就是N个特征向量方向。 由此决定了我们以不同的初始状态趋近定点， 可能的结果会非常复杂多变，运动模式趋于无限。&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; center=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;&lt;strong&gt;&lt;span&gt;4）基于这种理解我们可以做什么呢？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;1， 预测高维网络的一些基本性质： 虽然我们比较难完全预测高维系统的未来， 但是我们预测其稳定性， 我们看到， 当改变一个网络的一个基本属性， 比如连接强度， 就会让网络从稳定到不稳定，从稳定平衡趋于混沌， 那么对于生态系统和社会这意味着什么呢？ 有人说当系统的元素增加连接增强会使得系统更脆弱 ，更容易失衡， 但这仅是理解之一。 一个趋于稳定平衡的系统也通常没有什么功能。 而混沌本身， 确可以是秩序的载体。&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;2， 在混沌和稳定边缘的高维随机动力系统具有某种全能可塑性， 如果加上一定的非线性， 则可以包含极为丰富的动力学模式， 稳定定点，周期解， 不稳定定点， 混沌， 各类复杂的吸引子， 都可以在这个区域周围出现。这个区域动力学形式已经开始丰富， 又不像完全混沌那样难以控制， 因此是各类学习的最佳区域。&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;3， 制作机器学习工具。 我们说大型的随机网络本身就具备一定的学习能力， 而且在很多学习任务里可以匹配其它特定设计的机器学习模型。 这里一个比较著名的例子就是蓄水池网络。刚刚开始说的预测火焰的例子正是来自这里。&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;蓄水池网络的根基，正是2提到的混沌和稳定的边缘， 再加上非线性的激活函数, 以及外界环境的输入I。这个微小的非线性将把系统的复杂性再推一个高度， 事实上， 一个非线性的二维系统就可以表达多于一个的定点， 而非线性的三维系统就已经可以产生混沌。 一个非线性的高维混沌系统， 其数学复杂度已经接近解析的极限。&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.10358565737051793&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_svg/hNWCQ9bibbzFWeywyrPJ78CTicqXAeOgPnN1nUW53HeoYr2Ry5xUYibXEr3RZKSLlkwcVDyZyt7SLxiciaHNdpZapfjLoBT66Zb4T/640?wx_fmt=svg&quot; data-type=&quot;svg&quot; data-w=&quot;251&quot;/&gt;&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;-这也就是循环神经网络RNN。&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;制作一个蓄水池网络最重要的就是控制刚刚说的特征值的谱半径， 我们要让它处于稳定到混沌的临界状态，也就似乎那个谱半径接近1的状态。 在这个时候， 系统的动力学属性最为复杂，最为丰富。&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;蓄水池网络具有的一种能力是， 如果你给它一个复杂的时间序列输入（I）， 比如股市的变化， 它可以自动的抽取出这种变化背后的独立性因子，并在一定程度模拟出真实过程的动力关系（因为其自身存在足够丰富的动力关系， 以至于非常容易和真实的系统进行匹配）。 听着有点像PCA，但是PCA是线性的不包含时间， 而这里是一个非线性时间依赖的系统， 复杂性不可同日而语。&lt;/p&gt;
&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.4861111111111111&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcewMUIibIuV7JdontKCkatxCcGDiclEtwkrQFBuvibmaOkJ3Lad493AOc4iaWYTBMRPycFgeYDFtgpCAQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;720&quot; width=&quot;1507&quot;/&gt;&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;比如上面这个图， 我们的输入是真实世界一个很复杂的波动曲线（周期解和混沌间的过度）， 事实上多么复杂的波动背后催生它的因素不一定很复杂， 比如洛伦茨吸引子背后就仅仅是一个三维系统。&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;当这个波动输入到蓄水池网络里以后，蓄水池网络可以找寻到这种复杂背后的根基，并对这个信号的发展走势进行预测。&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;蓄水池运算的好处是不需要改变内在连接矩阵A， 我们唯一需要求解的是一个读出, 也就是&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.19117647058823528&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_svg/hNWCQ9bibbzFWeywyrPJ78CTicqXAeOgPngcdiav5ZPr116cgYOiaES2vzAAnC4oE31kKF3dWNGp89vO48GengsvicnalpG3cs12ia/640?wx_fmt=svg&quot; data-type=&quot;svg&quot; data-w=&quot;136&quot;/&gt;&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;就可以对时间序列进行预测, 比如文中开头提到的预测火焰形状的网络， 如下图， 这个过程包含两个阶段，一个是训练，一个是预测， 在训练阶段， RNN的作用事实上相当于一个auto-encoder-自编码器， 它得到一个火焰变化的输入， 通过网络重现这个输入。 而在预测阶段，我们不再有火焰变化的数据，我们直接把RNN输出的结果输入回网络，假设这个网络已经学好了， 那么这个输出就是正确的预测（下图为实际信号（上）于预测信号的比对（下））。 这种预测能力的背后， 正是在训练阶段，RNN高维网络里的某些成分， 抓住了真实系统变化背后的那些核心动因（自编码器的本质即压缩寻找主成分）。&lt;/p&gt;
&lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;/&gt; &lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.24861111111111112&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcewMUIibIuV7JdontKCkatxCx2r1rNtGlqOuBVzZjpKgTxzR5pT9hfp3GeF7QTgBzJ5Uk6PbibHY7zg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;720&quot; width=&quot;1146&quot;/&gt;&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.3472222222222222&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcewMUIibIuV7JdontKCkatxCIjicXAwkE1trAicP38ozM0I53IMCcax5mIfGgMmJUTkWWxhSNDZ3mQIg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;720&quot; width=&quot;1433&quot;/&gt;&lt;p&gt;Model-Free Prediction of Large Spatiotemporally Chaotic Systems from Data: A Reservoir Computing Approach&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;更深刻的学习（对A进行改变）： 我们还可以做什么呢？ 在刚刚讲到的各类复杂的动力学形式里， 我们看到，无论是稳定定点， 极限环，鞍点，还是线性吸引子事实上都是对世界普遍存在的信息流动形式的通用表达。 我们可以用它表达信息的提取和加工， 甚至某种程度的逻辑推理（决策），那么只要我们能够掌握一种学习形式有效的改变这个随机网络的连接，我们就有可能得到我们所需要的任何一种信息加工过程， 用几何语言说就是，在随机网络的周围， 存在着从毫无意义的运动到通用智能的几乎所有可能性， 打开这些可能的过程如同对随机网络进行一个微扰， 而这个微扰通常代表了某种网络和外在环境的耦合过程（学习）， 当网络的动力学在低维映射里包含了真实世界的动力学本身， 通常学习就成功了。&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;无论当下红极一时的鏖战星际争霸的网络，还是从脑电波中解码语言的网络， 无非是一种特殊的RNN（LSTM）加上一定的这种学习的结果。&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;真实世界的各种复杂网络， 从生物基因网络到神经网络，到生态网络或经济关系网络， 或许都是如此从随机网络逐步过渡出来的。 无论是通过学习，还是进化。 这或许可以揭示为什么人和猩猩基因差异没有大的情况下智力确是天壤之别， 以及类似人组成的社会受到地理条件影响的微小差异后引起的社会演化巨大差异。 或许， 这个规律可能揭示所有复杂网络到深度学习背后的本质。&lt;/p&gt;

&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;参考文献：&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;1 Sompolinsky H, Crisanti A, Sommers H J. Chaos in random neural networks[J]. Physical review letters, 1988, 61(3): 259&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;2 Pathak J, Hunt B, Gir&lt;span&gt;van M, et al. Model-free prediction of large spatiotemporally chaotic systems from data: A reservoir computing approach[J]. Physical review letters, 2018, 120(2): 024102.&lt;/span&gt;&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;&lt;span&gt;3 Maass W, Natschläger T, Markram H. Real-time computing without stable states: A new framework for neural computation based on perturbations[J]. Neural computation, 2002, 14(11): 2531-2560.&lt;/span&gt;&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;&lt;span&gt;4 Schrauwen B, Verstraeten D, Van Campenhout J. An overview of reservoir computing: theory, applications and implementations[C]//Proceedings of the 15th european symposium on artificial neural networks. p. 471-482 2007. 2007: 471-482.&lt;/span&gt;&lt;/p&gt;

&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;1.413888888888889&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcewMUIibIuV7JdontKCkatxCicN7RgeDric5XARttic2HBGErVTqBVutDiak5jzibNYgrsZRgQPrLwNGGmg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;720&quot; width=&quot;1080&quot;/&gt;
</description>
<pubDate>Wed, 01 May 2019 04:35:46 +0000</pubDate>
<dc:language>zh-CN</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.jintiankansha.me/t/JIJMBiPkwj</dc:identifier>
</item>
<item>
<title>强化学习理解的三重境界</title>
<link>http://www.jintiankansha.me/t/A5jNLvecGM</link>
<guid isPermaLink="true" >http://www.jintiankansha.me/t/A5jNLvecGM</guid>
<description>&lt;p&gt;&lt;span&gt;想像一下我们是人工智能体，我们有强化学习和监督学习可以选择，但干的事情是不一样的。&lt;/span&gt;&lt;span&gt;面对一只老虎的时候，如果只有监督学习就会反映出老虎两个字，但如果有强化学习就可以决定逃跑还是战斗，哪一个重要是非常明显的，因为在老虎面前你知道这是老虎是没有意义的，需要决定是不是要逃跑，所以要靠强化学习来决定你的行为。&lt;/span&gt;&lt;br /&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;强化学习有哪些实打实的应用呢？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;只要在问题里包含了动态的决策与控制，&lt;/span&gt; &lt;span&gt;都可以用到强化学习&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;1， 制造业&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;强化学习之于制药业有一种天然的契合 ， 把强化学习翻个牌子换个叫法， 也可以叫做控制论， 学习控制机器手的精确动作， 比如让它自动的做比目前所能及的更复杂的事情， 强化学习在制造业的应用潜力是显然的 。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt; &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.6617283950617284&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibce5vF9ib3b3HiaHGBxGjjGop8YBT4xfFfeIjiatN1CyyZZVqicS0kicw2faTLPZtvkZrkYV4mZ988CiaA1w/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;405&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;&lt;span&gt;2， &lt;/span&gt;&lt;strong&gt;&lt;span&gt;无人驾驶&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;这就不用多说了， 开车本质是个控制问题, 　自动驾驶不仅需要模拟人类行为，　还需要对前所未遇的情况进行决策，　这需要强化学习。　&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt; &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.5612009237875288&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibce5vF9ib3b3HiaHGBxGjjGop8BvCqcZ8G0tw81FlSBbLpUvJQkpvZ1WYK40jX7E00y9OknVic4PFNbYg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;433&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt; &lt;br /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;span&gt;3, &lt;/span&gt;&lt;strong&gt;&lt;span&gt;智能交通&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;智能交通， 显然这里包含了非常多的决策与控制问题， 就拿目前的共享汽车行业 ，滴滴和uber的派单系统时时都是一个动态的决策， 如何把正确的司机和乘客连接在一起， 如何让车辆调动到需求量最大的地方， 这些都要时时的考虑各种因素调整决策。我们说这里面既包含了效率的问题， 也包含了乘客的安全。比如这一次滴滴的事故如果修正强化学习的效用函数， 是有可能避免的。当然除了派单和调动问题， 在每个十字路口交通灯的控制等， 整个城市里的立体交通网络的协调， 本质都是强化学习问题， 所以强化学习在智能交通大有可为 。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt; &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.5841035120147874&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibce5vF9ib3b3HiaHGBxGjjGop8aEGBiaEgrS7f5yM8cFRoHfwKfEKKmCZRuo2O6r45scgkGPjwbnnajicw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;541&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt; &lt;br /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;span&gt;4，&lt;/span&gt;&lt;strong&gt;&lt;span&gt;金融&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;金融的核心， 交易， 是一个动态控制问题， 即使你不能完全预测明天股市的涨跌， 你依然需要直到我今天要不要下单，下多少单， 这，就是一个强化学习的决策， 它可以影响明天的股市， 也会在非常长远的时间里让我收益或亏损。机器交易，本质是个强化学习问题。当然，金融里能够应用强化学习的绝不仅仅这一个。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt; &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.4258720930232558&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibce5vF9ib3b3HiaHGBxGjjGop8p7o3Dgj17Ygk1o805cWk8rfcYsGpjVTrtThibodXLq2rIrwy2md0gAg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;688&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;5, 智能客服&lt;/span&gt;&lt;/strong&gt;&lt;br /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;智能客服本质是个强化学习问题， 如果你把它处理成监督学习问题， 那个对话机器人只能照猫画虎， 不能够真正从顾客的好恶的角度出发来发言， 而如果用强化学习， 那么机器人学习的就是如何正确的决策， 每句话都是为了最终讨得顾客欢心。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt; &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.562254259501966&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibce5vF9ib3b3HiaHGBxGjjGop8TsUlYnticNY3Cd22ziaa2IEQ3vtQQ3eeibia7P9IMc0wsK6SLvhZ84ATuw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;763&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt; &lt;br /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;6， 电商&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;电商的本事是如何吸引人买更多的东西， 因此我们买了一个东西后它总会在下面给我们推荐其它的东西。然后我们看到了一个新的东西， 又会点开下一个连接， 这样一步步的就买了一大堆东西， 这样在每一步给你展示不同东西吸引你上钩的过程， 也可以看作是电商系统的动态决策过程， 是一个强化学习问题。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt; &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.5674044265593562&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibce5vF9ib3b3HiaHGBxGjjGop8jydTibwaO24npwTStA4ftpBib5iaAWfnNib78yGGwsZvmpB98WAtHtS2uA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;497&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;7， 艺术创作&lt;/span&gt;&lt;/strong&gt;&lt;br /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;艺术创作领域看起来与强化学习无关， 事实上它可以很灵活的把人类的好恶加在强化学习的过程里，通过强化学习， 机器作曲可以自发的得到取悦于人的风格，也就是范式。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt; &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt; &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.47791798107255523&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibce5vF9ib3b3HiaHGBxGjjGop8ibb1jxhO04FDBz6DCPfIexGdKRsb3vYIIsRJGf4DibR1ZTTxDibxvJLtQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;634&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt; &lt;br /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;span&gt;让机器来决策，首先体现在如何模仿人类的决策。对于决策这个问题，&lt;/span&gt; &lt;span&gt;我们来看人类决策都要解决哪些难题。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;&gt;&lt;/ins&gt; &lt;p&gt;&lt;span&gt;强化学习最初的体现就是试错学习， 因此理解强化学习的第一个层次就是如何通过一个简单的机制在不确定的环境下进行试错， 掌握有用的信息。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.3946830265848671&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibce5vF9ib3b3HiaHGBxGjjGop8bDDGfnbVQmh1GEHdJu9H2RXBcjibpF1Lc9qDwvd5QzuUdwxtQiaQR61A/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1467&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;在这个框架下，&lt;/span&gt; &lt;span&gt;我们需要掌握的只有两个基本要素，&lt;/span&gt; &lt;span&gt;一个是行为，一个是奖励。&lt;/span&gt; &lt;span&gt;在这个级别的强化学习，&lt;/span&gt; &lt;span&gt;就是通过奖励，强化正确的行为&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;。&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt; &lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;所谓行为，行为的定义是有限的选项里选以恶搞，&lt;/span&gt; &lt;span&gt;所谓智能体的&lt;/span&gt;&lt;/span&gt;&lt;strong&gt;&lt;span&gt;决策&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;，走哪一个都有正确的可能，但是我们预先不知道这个东西。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;所谓奖励， 就是环境在智能体作出一个行为后， 给它的反馈。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;span&gt;大家看到，如果这个奖励是已知的，那么也就没有了任何的游戏需要进行的可能了。&lt;/span&gt; &lt;span&gt;你为什么要学？&lt;/span&gt; &lt;span&gt;每个行为得到的后果是不知道的啊！&lt;/span&gt;  &lt;span&gt;奖励具有随机性，&lt;/span&gt; &lt;span&gt;同样的条件性，&lt;/span&gt; &lt;span&gt;有的时候我们可以得到奖励，&lt;/span&gt; &lt;span&gt;有时候没有，&lt;/span&gt; &lt;span&gt;因此，&lt;/span&gt; &lt;span&gt;它也是一个随机变量，&lt;/span&gt; &lt;span&gt;理解这一点非常重要，&lt;/span&gt; &lt;span&gt;因此才可以理解很多的后面的算法。&lt;/span&gt; &lt;span&gt;奖励可以是正向的，也可以是负向的（惩罚）。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.69875&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibce5vF9ib3b3HiaHGBxGjjGop8AKZgMqIPKFjricunYfGg1bkaiaYA5g9khFDIwVa27VgyOaEka0GsJ5Cw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;800&quot; /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;我们迅速的切入一个强化学习的最小实用例子，&lt;/span&gt; &lt;span&gt;又被称为&lt;/span&gt;&lt;/span&gt;&lt;strong&gt;&lt;span&gt;多臂赌博机的例子&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;：&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span&gt;你去赌场玩的，&lt;/span&gt; &lt;span&gt;都知道这个机器的存在，&lt;/span&gt; &lt;span&gt;它的构造就是很多个长得一样的摇臂，每个对应不同的中奖概率，&lt;/span&gt; &lt;span&gt;你要玩&lt;/span&gt;N轮， 每次选择摇臂， 使得最终的收益最大。聪明的你一定可以设计一个方案， 让自己的收益最大， 怎么做呢？ &lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;首先， 你能不能一下子找到这里的行为和奖励是什么呢？&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;你能否设计一个算法解决这个问题呢？首先， 注意， 我此处的题设是N。假定这个N是一次你会怎么做？10次呢？无穷多次呢？&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.6067146282973621&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibce5vF9ib3b3HiaHGBxGjjGop8ZoLBicVgE11906kib5ODmUn9512MNlBfk4NpnpAGQ2xerLgSzdTF9fLg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1251&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;每次行动后带来不同的奖励&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;很自然的，我们就来到了这么一个问题，就是探索与收益的平衡，&lt;/span&gt; &lt;span&gt;只要&lt;/span&gt;N不是1或无穷， 你都会有如下的窘境。假如你开始就中了 ， 你会一直选择那个中奖的摇臂不放过吗？显然这可能是陷阱，因为还有收益更高的臂，或者只是这次的运气好。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;&lt;span&gt;反过来， 你会不停的随机试下去吗？显然不会， 因为存在收益比较高的臂。所以， 你就需要设计一个策略， 在有效探索的同时加大在那个最有收益可能的臂的概率， 每次玩， 又都增加你的信息。这就是一个极为典型的应对不确定的策略。&lt;/span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;而且，&lt;/span&gt; &lt;span&gt;可以直接用到产品设计上，&lt;/span&gt; &lt;span&gt;我们也可以把它看成一个特别有方向性的试错。&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;在这里你要形成的第一个观点就是：&lt;strong&gt;奖励是随机变量 为了量化奖励， 我们需要引入期望。&lt;/strong&gt;这，才是我们要优化的对象。我们所处的环境下，环境给我们的奖励分布是未知的，因此，你必须在一开始边测量， 边引入收益的机制。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;刚刚的游戏，&lt;/span&gt; &lt;span&gt;和真实世界的大多数问题相差甚远，&lt;/span&gt; &lt;span&gt;因为它每轮只有一步就可以看到奖励，而且这一次抽取，&lt;/span&gt; &lt;span&gt;和下一次抽取一点关联都没有。&lt;/span&gt; &lt;span&gt;而事实上世界上的大部分游戏是一个连续多步骤，步步相连的过程。比如各种棋类，扫地机器人（连续离散化）等，&lt;/span&gt; &lt;span&gt;这样的问题，&lt;/span&gt; &lt;span&gt;很快前面的问题就不管用了。我们需要完善我们的框架来改进前面的东西。&lt;/span&gt; &lt;span&gt;好了，假定你是在设计这个东西，&lt;/span&gt; &lt;span&gt;那么你要加入一个什么要素呢？&lt;/span&gt; &lt;span&gt;时间？&lt;/span&gt; &lt;span&gt; &lt;/span&gt;&lt;span&gt;步骤&lt;/span&gt;&lt;span&gt;?&lt;/span&gt;&lt;span&gt;   &lt;/span&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;No,  &lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;我们说， 解决这类问题， 首先引入的是状态。在围棋里， 你需要看到的是每一步其实你需要决策的信息都在当时的棋盘布局里，&lt;/span&gt;&lt;/strong&gt; &lt;span&gt;而在扫地的游戏里， 每一步的信息都在当下的位置里， 也就是说， 我们把这些某个时间步骤出现的所有有用信息或特征叫做一个状态。有了这个概念， 多步游戏就可以看成根据状态来决策的游戏。&lt;/span&gt;&lt;br /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;那么， 现在我所有的元素就是行为-状态-奖励，每一步， 我都要根据过去和当时的状态来决策此刻。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt; &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;&gt;&lt;/ins&gt; &lt;img class=&quot;&quot; data-ratio=&quot;0.8585365853658536&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibce5vF9ib3b3HiaHGBxGjjGop83Tz5VTWEvGO0sabfn3sVNC6JRnl8gPzTUSrrF3YycibRIBtmavic1zYw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;205&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;span&gt;这样我们就有&lt;/span&gt;state（observation）- action - reward 这样的一个组合。或者说环境给你一个state， 然后智能体得到一个action ， 这个action改变环境， 并且环境返回智能体一个reward，如此循环， 当然在真实的游戏下我们并没有这样机械的一步步的过程， 而是一个连续的整体， 这种机械的方法是为了让问题可以轻松的被一个程序解决。&lt;br /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;这样的思路和图灵最早提出的图灵机智能模型具有异曲同工之妙， 而图灵机被认为是智能产生的基本模型，因此你也可以理解为什么强化学习和强人工智能有关。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;从状态到行为&lt;/span&gt;action的函数，也就是刚刚提到的那个条件概率， 通常称之为&lt;/span&gt;&lt;strong&gt;&lt;span&gt;策略&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;，&lt;/span&gt; &lt;span&gt;犹如通常意义上说的战略，&lt;/span&gt; &lt;span&gt;也就是一个行为的指导方案。&lt;/span&gt; &lt;span&gt;当游戏结束的时候，&lt;/span&gt; &lt;span&gt;我们把所有环境给我们的奖励加在一起算分，&lt;/span&gt; &lt;span&gt;越好的策略得到的分数越高，&lt;/span&gt; &lt;span&gt;这就是强化学习的本质。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;TD学习&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;那么如何得到一个好的策略呢？这就是强化学习的中心问题， 大家以看就知道这本质上还是一个优化问题。那么整个后面的篇章都围绕这个展开。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;如何得到好的策略？在上个游戏里， 游戏没有很多步，而是一步就可以拿到奖励，这个游戏里， 游戏有很多步， 这里必然引入的一个基本问题就是， 如果我还有好多步才得到奖励， 那么根据奖励来强化学习，将是一个极为困难的事， 因为我今天的决策只能影响明天， 但是明天什么结果都看不到， 这将是一个十分令人绝望的事。因为还学习个什么啊， 没有奖励就没有强化。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;&lt;span&gt;你能否结合自己的生活设立一个解决方法呢？&lt;/span&gt;  &lt;span&gt;想想我们高中三年，都是为了高考，&lt;/span&gt; &lt;span&gt;但是我们其实中间有无数小目标啊，&lt;/span&gt; &lt;span&gt;比如各种期末考，期中考。再看金融的一个例子，如果你是一个潜力股，&lt;/span&gt; &lt;span&gt;你是可以在你得到最终的结果前贷到款的对吧？&lt;/span&gt; &lt;span&gt;也就是说，&lt;/span&gt; &lt;span&gt;虽然明天并没有任何实际的奖励，&lt;/span&gt; &lt;span&gt;我们可以引入一个虚构的量，它能够把未来的收益给量化，这就是价值函数。它代表的不是当下的收益，而是未来的收益。&lt;/span&gt;  &lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;&lt;span&gt;这里就有一个问题了，&lt;/span&gt; &lt;span&gt;如果这个奖励在一个月以后到达，&lt;/span&gt; &lt;span&gt;或者在一年之后到达，&lt;/span&gt; &lt;span&gt;这两种情况是否应该一视同仁呢？你可以以你的直观感受直接告诉我，&lt;/span&gt; &lt;span&gt;不可能的！&lt;/span&gt; &lt;span&gt;我们可以有一个心理学实验，就是马上给你&lt;/span&gt;50元和， 和一年后给你100元， 你愿意选择哪一个（举手）。好了， 这样的机制事实上有着非常强大的现实意义。它的隐含含义就是， 我们需要一个贴现因子， 来惩罚未来的收益。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;&lt;span&gt;在大多数情况下，&lt;/span&gt; &lt;span&gt;我们都生活在这样一种情况里，&lt;/span&gt; &lt;span&gt;我们的游戏里有小的奖励有大的奖励，&lt;/span&gt; &lt;span&gt;有今天的奖励有明天的奖励，&lt;/span&gt; &lt;span&gt;而游戏是连续的。&lt;/span&gt; &lt;span&gt;比如扫地机器人，&lt;/span&gt; &lt;span&gt;你可以想象成每扫一小块，&lt;/span&gt; &lt;span&gt;它就得到一个奖励，&lt;/span&gt; &lt;span&gt;这个时候价值函数将变成一个不同时间点的奖励的求和。&lt;/span&gt; &lt;span&gt;那么，&lt;/span&gt; &lt;span&gt;你有没有发现，&lt;/span&gt; &lt;span&gt;这个贴现因子本身更深刻的含义&lt;/span&gt;? &lt;span&gt;你能用它解释艰苦忍耐的人生观和即使享乐的人生观吗&lt;/span&gt;?&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;平衡当下和未来， 建立当下和未来的桥梁，正是强化学习的第二个基本矛盾。也因为如此，当下和未来收益的统一者，价值函数就成为了强化学习的核心概念。这个函数的定义方法是首先把当下的奖励和未来的奖励加在一起， 由于奖励本身就是随机变量且未来是不确定的， 我们要是把奖励都加在一起， 依然得到的是一个随机变量， 你要衡量一个随机变量的大小， 只能对它取期望。这样， 这个带着未来收益的期望， 就是我们对价值函数的最终定义。强化学习， 就变成了如何找到那么一个策略， 使得我们这个value函数达到最优。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;&lt;span&gt;然后我们来说，&lt;/span&gt; &lt;span&gt;强化学习的核心，&lt;/span&gt; &lt;span&gt;策略。&lt;/span&gt; &lt;span&gt;所谓策略，&lt;/span&gt; &lt;span&gt;无非是把当下的这个对未来的估值，&lt;/span&gt; &lt;span&gt;我们也可以看作趋势，&lt;/span&gt; &lt;span&gt;和我们要的行动联系起来。&lt;/span&gt; &lt;span&gt;我们干脆把可能的行动也放在这个价值的条件里面去，&lt;/span&gt; &lt;span&gt;也就是，&lt;/span&gt; &lt;span&gt;我们定义目前每个行动下的值函数，&lt;/span&gt; &lt;span&gt;给它起个酷炫的名字，叫&lt;/span&gt;action value， 每个行动的价值。我问你， 如果我有了这个函数， 该如何求得策略？ &lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;如果你告诉我这无非是找那个最高估值对应的行动，&lt;/span&gt; &lt;span&gt;恭喜你答对了。&lt;/span&gt; &lt;span&gt;你已经掌握了强化学习的精髓，&lt;/span&gt; &lt;span&gt;我们需要强化（选择）的行动，&lt;/span&gt; &lt;span&gt;就是那个使得整个走势，&lt;/span&gt; &lt;span&gt;也就是值函数最高的行动啊！&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;&lt;span&gt;但是，同时我要告诉你没有完全答对。&lt;/span&gt; &lt;span&gt;为什么？&lt;/span&gt;  &lt;span&gt;有没有同学能发现我刚刚的逻辑漏洞？&lt;/span&gt;&lt;/span&gt;&lt;span&gt;如果你告诉我老师，&lt;/span&gt; &lt;span&gt;哪里来的值函数，&lt;/span&gt; &lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;&gt;&lt;/ins&gt; &lt;span&gt;你怎么算出来的，&lt;/span&gt; &lt;span&gt;就是非常聪明。&lt;/span&gt; &lt;span&gt;刚刚讲了这么多，&lt;/span&gt; &lt;span&gt;我实际上是偷懒了啊，&lt;/span&gt; &lt;span&gt;我讲的都是一堆定义，&lt;/span&gt; &lt;span&gt;实际怎么操作却一点没讲。&lt;/span&gt; &lt;span&gt;你记得我说的，&lt;/span&gt; &lt;span&gt;我们求的是期望，就需要概率。&lt;/span&gt; &lt;span&gt;这个概率，&lt;/span&gt; &lt;span&gt;就是我的行为，&lt;/span&gt; &lt;span&gt;引起环境如何的改变的概率，&lt;/span&gt; &lt;span&gt;但是，&lt;/span&gt; &lt;span&gt;正如我们在赌博机里不知道每个臂的筹码，&lt;/span&gt; &lt;span&gt;这里我们也不会知道环境给我们反馈的概率。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;&lt;span&gt;对于这个问题的解决，&lt;/span&gt; &lt;span&gt;一个是笨办法，&lt;/span&gt; &lt;span&gt;一个是聪明办法。&lt;/span&gt;  &lt;span&gt;所谓笨办法，&lt;/span&gt; &lt;span&gt;就是不停的去实验，&lt;/span&gt; &lt;span&gt;从当下的状态和行为出发，&lt;/span&gt; &lt;span&gt;试它一万次测个平均，&lt;/span&gt; &lt;span&gt;所谓蒙特卡洛。&lt;/span&gt; &lt;span&gt;这个方法有着一个致命的弊病&lt;/span&gt; &lt;span&gt;，那就是你得等到游戏的结束才能更新一次&lt;/span&gt;v值，速度太慢了，而且想想有些时候你只能进行一次或几次游戏， 比如人生的游戏你只有一次， 你不能死了再回来， 所以这个方法就不那么给力了。怎么办呢？&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;然后我们看聪明方法，这个办法就是不等到游戏结束就更新。这个思维有点逆向。也就是你假定游戏已经结束了， 你从终局往回看整个游戏， 假定游戏结束的时候有一个终极的奖励刺激。这个时候， 你能马上更新的v函数一定是那个你离终局最近的状态。而如果你已经更新了这个状态， 那么它之前的那个状态呢？请你想一下， 我可不可以接着更新这个状态？当然， 我离终点奖励差两步， 所以我无非是把终点奖励乘以两次贴现。哦， 这样看可以， 同样的方法， 你可以不可以更新前三步， 前四步， 前5部， 前n步的状态？ &lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;&lt;span&gt;那么下一次游戏呢？&lt;/span&gt; &lt;span&gt;我是否还需要等到游戏的终局再更新呢？&lt;/span&gt;  No！在新的游戏里， 如果你走走走， 恰好达到了上次游戏里某个经过的状态， 你立刻会看到， 这里已经标记过了一个估值， &lt;span&gt;你可以怎么做？&lt;/span&gt; Ok， 你可以利用这个估值， 并用它来更新你之前的一步！ &lt;span&gt;因为你可以假定当你到大了这里，&lt;/span&gt; &lt;span&gt;一切的情景都是有过往经验支撑了，&lt;/span&gt; &lt;span&gt;如同你在一个城市里走走走，&lt;/span&gt; &lt;span&gt;误打误撞到了昨天走过的一条小路，&lt;/span&gt; &lt;span&gt;那么从这里，&lt;/span&gt; &lt;span&gt;一切都变成已知。&lt;/span&gt; &lt;span&gt;这个方法翻译成数学语言就是&lt;/span&gt;TD时间差分学习。 &lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;数学上的表现就是估值函数v的迭代表达式， 你每次格按照v的迭代式定义来更新v函数，这样多步之后v也会趋于正确的值。好比当你在开车的时候， 你险些撞车， 游戏没有终止， 但是足以让你使用这个惊险来更新值函数。另外一个例子是你打公交车去上班， 每过一个站你看一个时间， 看和你的预计是否有差别， 这每一站的时间， 足以让你不停的调整对最终实现时间的预期。&lt;/span&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;&lt;span&gt;我们看看这个故事背后的生物学故事。&lt;/span&gt;  &lt;span&gt;所谓的时间差分，&lt;/span&gt; &lt;span&gt;正是条件反射的基础。&lt;/span&gt; &lt;span&gt;你记得巴甫洛夫的狗吗？&lt;/span&gt; &lt;span&gt;摇铃和食物有什么关系？&lt;/span&gt; &lt;span&gt;食物就是我们说的终极的奖赏，&lt;/span&gt; &lt;span&gt;而终极奖赏之前，&lt;/span&gt; &lt;span&gt;摇铃是一个中间步骤，&lt;/span&gt; &lt;span&gt;由于大量的经历里，&lt;/span&gt; &lt;span&gt;摇铃都导致了食物，&lt;/span&gt; &lt;span&gt;所以，&lt;/span&gt; &lt;span&gt;狗就会学会，&lt;/span&gt; &lt;span&gt;摇铃就是那个终极奖赏前的状态，因此，&lt;/span&gt; &lt;span&gt;摇铃也应该得到一个更高的值函数。&lt;/span&gt; &lt;span&gt;这时候，&lt;/span&gt; &lt;span&gt;摇铃也就具有了某种奖励的性质，可以引起狗的流口水了。&lt;/span&gt; &lt;span&gt;因此你可以继续往前推，&lt;/span&gt; &lt;span&gt;你是否看到，&lt;/span&gt; &lt;span&gt;摇铃前还可以放置一个灯光，灯光之前还可以放一个声音呢？&lt;/span&gt;  &lt;span&gt;你是否看到了，&lt;/span&gt; &lt;span&gt;如果人生赢家是抱得美人归，&lt;/span&gt; &lt;span&gt;那之前的高考长夜，&lt;/span&gt; &lt;span&gt;之前的寒窗苦读，&lt;/span&gt; &lt;span&gt;之前的所有一切，&lt;/span&gt; &lt;span&gt;是不是都成为了我们趋之若鹜的奖励。&lt;/span&gt; TD学习， 是所有生物行为学习的基础。  &lt;span&gt;你可不可以用它的原理设计一个控制拖延症的方法呢？&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;&lt;span&gt;有了&lt;/span&gt;TD学习， 我们可以随时更新每个状态下所有可能行为对应的值函数， 这样， 我们就可以选择那个当下估值最高的选项来行动， 所谓策略的更新（比起之前的估值下的行动）。  &lt;span&gt;当然，&lt;/span&gt; &lt;span&gt;由于我们每次更新的时候，&lt;/span&gt; &lt;span&gt;我们仅仅是比之前多了一点信息，我们的这个值函数依然是不完美的，&lt;/span&gt; &lt;span&gt;幸运的是，&lt;/span&gt; &lt;span&gt;每个行为最终都导致我们进入一个新的状态，&lt;/span&gt; &lt;span&gt;使得我们进一步的获得了上一个状态的信息，从而进一步的优化我们的值函数，&lt;/span&gt; &lt;span&gt;若干论之后，&lt;/span&gt; &lt;span&gt;我们将会得到一个最优的值函数和策略。这样的迭代过程，&lt;/span&gt; &lt;span&gt;值函数的更新紧跟着一个行为，&lt;/span&gt; &lt;span&gt;如同一组拉丁舞曲。这个算法就是大名鼎鼎的&lt;/span&gt;salsa和Q学习（此处不做区分&lt;span&gt;）的简化版。&lt;/span&gt;  &lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;这就是强化学习的第二个阶段。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;然后我们来看强化学习的第三个阶段， 所谓用想象和世界模型来填补的阶段。&lt;/span&gt;&lt;span&gt;首先，&lt;/span&gt; &lt;span&gt;我们刚刚遗漏了一个重要的&lt;/span&gt;&lt;span&gt;point， 这个世界难道真的是如刚描述的只有几个有限的状态吗？肯定不是。我们真实生活的状态是无限的。那么，人脑是如何由有限战胜无限的？我们有联想，有想象。&lt;/span&gt; &lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;&gt;&lt;/ins&gt; &lt;span&gt; &lt;/span&gt;&lt;span&gt;这，也是强化学习的第三个阶段。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;首先，我们引入估值函数的近似解法。&lt;/span&gt; &lt;span&gt;刚刚说的值函数，&lt;/span&gt; &lt;span&gt;事实上如果永远都走不回之前的小路的时候，&lt;/span&gt; &lt;span&gt;你就不能用了。&lt;/span&gt;  &lt;/span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;但是，&lt;/span&gt; &lt;span&gt;如果你看到一个地方类似之前的走过，&lt;/span&gt; &lt;span&gt;你可不可以根据之前的经验判断呢？&lt;/span&gt; &lt;span&gt;当然，&lt;/span&gt; &lt;span&gt;所谓一朝被蛇咬，十年怕井绳。&lt;/span&gt; &lt;span&gt;你要引入一个东西，&lt;/span&gt; &lt;span&gt;具有从以往经验推测的能力&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;。&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt; &lt;span&gt;我们有没有学习过类似的东西？&lt;/span&gt; &lt;span&gt;所有的监督学习方法，&lt;/span&gt; &lt;span&gt;都是说这件事啊！&lt;/span&gt; &lt;span&gt;我们根据经验特征，从已知数据推知未知数据。&lt;/span&gt;  &lt;span&gt;由此我们得到值函数的近似算法。&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt; &lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;有了值函数的近似算法， 虽然看起来我们的体系已经相当完整，但是依然有一个比较严重的弊端， 那就是最终学到的策略只能确定性的， 根据定义 ，这个最优化的策略是每一次选取Q（s,a)里最大的那一个。可是在这个不确定的世界， 我们的最优化策略本身就需要包含随机性，我们真正的策略， 恰好是如何设定这个随机性。我们用要一个最微小的例子来说明，还是那个走方格的问题，骷髅就是有危险的意思，我们希望走到有奖励的地方。我只做一个小的改动将使得之前问题面目全非，之前的马尔科夫决策附加的条件就是当下的状态含有用来决策的所有信息，方格问题里， 这个信息就是位置坐标。而如果我没有位置这个信息， 取之以感知信息， 比如我只能感知我所在方格的周围两个方格有什么（下图中的骷髅或金币）。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;注意如果我们处在下图灰色方格的区域（左右各一个），此时相邻的两个方格的情况是完全一致的（白色），也就是说我无法确定我是处于左边还是右边的灰色方格， 这导致无法决策正确的行为（左边和右边的正确决策是相反的！一个向左一个向右， 但是我无法确定是哪一个！）。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;如果此时引入一个随机性的策略， 这个问题影刃而解，我无非子啊左右两个灰色的格子里制定左右各50%的策略， 这时候总是最终客户以达到宝藏，就是时间可能稍微长一点。这样的随机性的策略， 引入策略函数就可以可以很容易的学出来。这时候，我们的你策略及从一个状态下确定的行为函数， 变成了了状态的随机变量， 每个行为以一定的概率来取得。如果最初我们的Q学习里， 我们每一步选择那个动作状态的值函数最高的行为， 那么这里，我们就把这种选最大的行为变成一个称为softmax的函数， 它说的就是，我们依然倾向于选择那个值函数较高的行为， 但是， 其它的选项也是可以选择的， 选择的方法根据这个softmax函数。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;有模型学习&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;span&gt;刚刚讲的方法，通常称为无模型学习，所谓无模型，　就是当环境的动力学（也就是那两个条件概率，想象下棋的例子）不知道的时候，　我们通过直接抽样的方法来更新Ｑ（ａ，ｓ）和ｐｉ来进行控制住．这样做的一切基础在于环境是未知的，&lt;/span&gt; &lt;span&gt;我不知道环境是如何给我反馈，&lt;/span&gt; &lt;span&gt;假定你知道了环境反馈的方法，你会怎么做呢？&lt;/span&gt;  &lt;span&gt;显然，&lt;/span&gt; &lt;span&gt;你要做的是直接展开计算这个值函数而不是通过抽样更新！&lt;/span&gt; &lt;span&gt;这样，我们几乎每一步都会得到精确的值函数，&lt;/span&gt; &lt;span&gt;而游戏几乎会在瞬间得到最优策略！&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;&lt;span&gt;可是我们不知道这个世界给我们反馈的方法啊！&lt;/span&gt;  &lt;span&gt;这里，&lt;/span&gt; &lt;span&gt;我们可不可以在这个地方也引入一个机器学习的近似思想，&lt;/span&gt; &lt;span&gt;让我们通过在环境里取得的数据去近似这个世界模型呢？&lt;/span&gt; &lt;span&gt;当然可以的，&lt;/span&gt; &lt;span&gt;我们可以这么做！&lt;/span&gt; &lt;span&gt;所谓的环境反馈，&lt;/span&gt; &lt;span&gt;无非是下一步环境给我的状态，和给我的奖励，&lt;/span&gt; &lt;span&gt;我可以用监督学习的思想，&lt;/span&gt; &lt;span&gt;每走一步，&lt;/span&gt; &lt;span&gt;都收集环境给我的这两个数据，&lt;/span&gt; &lt;span&gt;然后，&lt;/span&gt; &lt;span&gt;我们就可以非常用我们的那些机器学习工具，&lt;/span&gt; &lt;span&gt;比如神经网络，&lt;/span&gt; &lt;span&gt;来计算它们和上一步环境状态，与我所做行为选择的关系。这样，&lt;/span&gt; &lt;span&gt;我就会得到一个可以学习的世界模型。&lt;/span&gt; &lt;span&gt;虽然它依然不是准确的，&lt;/span&gt; &lt;span&gt;却可以大大加速我得到准确的行动的性质。&lt;/span&gt;  &lt;span&gt;在此处，我们可可不可以学习创造一个世界模型，　来提高我们抽样学习的效率呢？　当然可以，　你不是由监督学习吗？&lt;/span&gt; &lt;span&gt;我们可以用类似监督学习的思路来把这个环境的动力学学出来啊！&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;&lt;span&gt;我们在这里就进入了有模型学习的范畴．　这个方法，又称为&lt;/span&gt;planning， 犹如一种做白日梦的能力，  &lt;span&gt;它可以通过自己构造的世界模型，&lt;/span&gt; &lt;span&gt;不停的想象某个步骤之上，&lt;/span&gt; &lt;span&gt;如果我采取某个行为后环境如何给我反馈，&lt;/span&gt; &lt;span&gt;得到如何奖赏，&lt;/span&gt; &lt;span&gt;结果，&lt;/span&gt; &lt;span&gt;我不需要不停试错，通过我脑子里的这个p&lt;/span&gt;lanning &lt;span&gt;，&lt;/span&gt; simulation &lt;span&gt;就可以获取关于某个行为该不该做的信息！&lt;/span&gt;  &lt;span&gt;虽然&lt;/span&gt;agent 并没有真正经历那些行为，　就好像经历过了一样，　这样agent 就如同获得了非常多的虚拟数据，　可以更准确的对未知的状态进行估值，　在数据极为稀缺高维诅咒极为明显的强化学习问题里，　这个效果是巨大的．好比正因为你瞻前顾后， 你才减少了很多错误！ &lt;span&gt;当然，&lt;/span&gt; &lt;span&gt;能够实用这个方法也是有条件的，&lt;/span&gt; &lt;span&gt;你觉得条件是什么呢？&lt;/span&gt; &lt;span&gt;如果你告诉我你必须确实能够掌握环境的套路，&lt;/span&gt; &lt;span&gt;给环境建立模型，&lt;/span&gt; &lt;span&gt;恭喜你答对了！&lt;/span&gt; &lt;span&gt;如果环境完全是不可琢磨的，&lt;/span&gt; &lt;span&gt;那么你最好的方法依然是直接试错的方法而非建模。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;&lt;span&gt;有模型学习的最好应用例子就是阿法狗。&lt;/span&gt;  &lt;span&gt;所有棋类游戏，&lt;/span&gt; &lt;span&gt;都实用一个叫马尔可夫决策的框架，&lt;/span&gt; &lt;span&gt;这个框架里，&lt;/span&gt; &lt;span&gt;下一步都只和这一步的状态相关。&lt;/span&gt; &lt;span&gt;然后，&lt;/span&gt; &lt;span&gt;我们的环境是什么呢？&lt;/span&gt; &lt;span&gt;假定你手里是黑子，那么你的&lt;/span&gt; &lt;span&gt;对手白字就是下一步的状态。&lt;/span&gt; &lt;span&gt;显然，如果你能够知道在你下某个棋的时候白字如何落子，&lt;/span&gt; &lt;span&gt;你就可以建立所谓的世界模型&lt;/span&gt; &lt;span&gt;。&lt;/span&gt; &lt;span&gt;阿法狗所用的方法是，&lt;/span&gt; &lt;span&gt;&lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;&gt;&lt;/ins&gt;  先备棋谱在推理。&lt;/span&gt; &lt;span&gt;所谓的背诵棋谱，就是说直接模拟大师下棋的直觉，&lt;/span&gt; &lt;span&gt;我可以通过看很多大师的下法，&lt;/span&gt; &lt;span&gt;了解无论是黑还是白的套路，&lt;/span&gt; &lt;span&gt;这个东西有一个&lt;/span&gt;CNN来完成。之后， 我来看如何能够加入推理， 这个推理的成分， 有一个叫做蒙特卡洛树搜索的过程完成， 怎么个玩法？ &lt;span&gt;就是在&lt;/span&gt;CNN的直接基础上， 我在大脑里多下几步，形成一个模拟过的走子过程，如此，我们就可以知道真实下去这一步， 白字最有可能如何反应，我会如何应对， 白字又如何反应， 这种直觉加推理的方法， 就是阿尔法狗建立世界模型的方法。有了这个方法， 阿尔法狗就可以战胜围棋最大的挑战， 宇宙星辰般的搜索空间，战胜人类。这样的思维方法， 如果你学会， 也是不可小觑的啊！&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;br /&gt;&lt;img data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcfqJgX6L51kcnJ07DHpdBzqCgYN1dD3XAMuRjXZuW8LY5OKAgKPmsVSQzPpDldvFT9aVgpMWrl06g/640?wx_fmt=png&quot; data-type=&quot;png&quot; class=&quot;&quot; data-ratio=&quot;0.5625&quot; data-w=&quot;800&quot; /&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;更多阅读&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651384317&amp;amp;idx=1&amp;amp;sn=329aeb82919ab6237bdb8f355e202311&amp;amp;chksm=84f3c7bcb3844eaab5197fecaba741c6cc97606ba41309729b18a2465e4357c53e81b523d2b2&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-itemshowtype=&quot;0&quot; data-linktype=&quot;2&quot;&gt;5分钟读懂强化学习之Q-learning&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651383664&amp;amp;idx=1&amp;amp;sn=89f11f166582925c041b960035f10c37&amp;amp;chksm=84f3c931b3844027a5c484c7af41f73dada1cb15a87fe4aa776fe293e45b66c0ea96e2e20c77&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-itemshowtype=&quot;0&quot; data-linktype=&quot;2&quot;&gt;强化学习最小手册&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651383610&amp;amp;idx=1&amp;amp;sn=eae53f91ea3bdb1d99464d3824175707&amp;amp;chksm=84f3c97bb384406dd3942d73be8d1dbe5a16815743990686d9054e1a3e9fa8fc42c8519ba270&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-itemshowtype=&quot;0&quot; data-linktype=&quot;2&quot;&gt;铁哥的强化学习特训课&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;

</description>
<pubDate>Fri, 19 Apr 2019 15:02:23 +0000</pubDate>
<dc:language>zh-CN</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.jintiankansha.me/t/A5jNLvecGM</dc:identifier>
</item>
</channel>
</rss>