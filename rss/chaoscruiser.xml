<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="css/feed.xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/" xmlns:og="http://ogp.me/ns#">
<channel>
<atom:link rel="self" href="http://192.168.1.4/fivefilters/makefulltextfeed.php?url=feed43.com%2Fchaoscruiser-jtks.xml&amp;max=5&amp;links=preserve&amp;exc=1" />
<atom:link rel="alternate" title="Source URL" href="http://feed43.com/chaoscruiser-jtks.xml" />
<atom:link rel="related" title="Subscribe to feed" href="http://www.subtome.com/#/subscribe?feeds=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed43.com%252Fchaoscruiser-jtks.xml%26max%3D5%26links%3Dpreserve%26exc%3D1&amp;back=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed43.com%252Fchaoscruiser-jtks.xml%26max%3D5%26links%3Dpreserve%26exc%3D1" />
<title>混沌巡洋舰</title>
<link>http://www.jintiankansha.me/column/ultiWL8Axg</link>
<description>混沌巡洋舰 - 今天看啥</description>
<ttl>360</ttl>
<item>
<title>基于一张“规则表”的人工智能</title>
<link>http://www.jintiankansha.me/t/WW3EirRLSj</link>
<guid isPermaLink="true" >http://www.jintiankansha.me/t/WW3EirRLSj</guid>
<description>&lt;p&gt;&lt;span data-offset-key=&quot;4ds8l-0-0&quot;&gt;我在过去对人工智能简史的描述中，把人工智能的整个历史描述成围绕一张规则表， 本文是基于这一想法的总结和扩展。我们说，早期的AI发展史围绕如何人为构建这样一个规则表解决复杂问题， 而当下的AI则围绕如何让它在复杂的现象中自己归纳出这个规则表。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;bkglj-0-0&quot;&gt;我们说，上帝通过制定规则从简单演绎出复杂。最初的原始人类在黑暗中摸索， 在众多的现象不知所措， 只能通过设立各色大神小神来缓解自己对不确定性的恐惧。 从多神宗教到一神宗教的跨度体现了一个从复杂中寻找简单的跨度， 这可能是基于一种隐隐的直觉，就是现象虽然多样， 但是背后的法则不应该如此复杂。 到了科学的时代， 这种思维在物理学里淋漓尽致起来，四大力学， 把分子原子间的作用力统一到电磁力， 把宏观物体的作用统一到引力和经典的动力方程， 已经是极致。 而后面的对这两者的统一构成了从广义相对论后的现代物理主线。  &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.5625&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibccd3W2SkazpguaDUmf1EWibibembXL81evOfRdy0cTz2qqulnss6iaFGmXLmdjuRu9GiayK86XIM1TVSg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;640&quot; /&gt;&lt;/p&gt;
&lt;p&gt;图: 简单规则生成复杂的极好例子， 元胞自动机， 每一步细胞的繁殖和扩散方法一定（左图黑格表述的， 从上一行到下一行的变化法则）， 它最后形成的图案就定了， 规则可以很简单， 图案可以很复杂。 &lt;/p&gt;

&lt;p&gt;&lt;strong&gt;早期的智能：  制定规则表 - 迭代&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz/dcEP2tDMibcfyNibceeGvVKo0qCGicGJ9lQ9J5zzOIxmTUAE4OYfwx25QZ2J2KLUic1lWYkMwelC8Ld30RF0FsibAPQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; class=&quot;&quot; data-ratio=&quot;0.1671875&quot; data-w=&quot;640&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;c1j7g-0-0&quot;&gt;另一方面，这样的思想从智能科学诞生之出，也贯穿出来。它在早期的可计算性中， 通过图灵机的构建。它认为存在这样的通用机器，能够和人类一样解决问题， 即使过程非常复杂， 你无非需要四个要素： &lt;strong&gt;1， 输入 2， 中间状态 3， 规则表 4， 输出。&lt;/strong&gt; 并在时间上进行大量迭代， 就可以实现这个过程。 通过这个过程， 我们可以把一个输入转化为一个想要的输出。 如果我们能够在在有限的步骤里将一个输入转化为一个输出，据此解决一个实际问题， 那么这个问题就是可计算的。&lt;/span&gt;&lt;/p&gt;


&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.6114081996434938&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibccd3W2SkazpguaDUmf1EWibibBnC8zkibScsiccAOwoSH4Ld9vdiamljakNVOX5TKF69ywm3Qq2ic3IdhUw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;561&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;图： 图灵纸袋， 一个在纸袋上根据一定规则表行走的机械昆虫， 机械昆虫具有一个内部状态， 并接受外部的输入，最终通过规则表找到对应的下一步输出。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;c00nl-0-0&quot;&gt;而冯诺依架构让它变成一个技术现实。 它通过可以存储程序的机器， 让人们通过把这些图灵规则表的指令变为计算机二极管的开合代码， 而让图灵纸袋的思想成为了一个每个工程师可以设计的现实，从此有了程序和程序员。 &lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;176de-0-0&quot;&gt;一个计算机程序， 最基本的部分包括一些简单的形式逻辑， 包括逻辑与或非， if else， for 循环这些。 其实本质上， if else 所描述的就是规则表， 规则里面通常涉及简单的逻辑， 最终通过for循环， 我们就可以得到我们要的东西。 比如一个中学生都会的排序算法， 我们无非需要做的是前面和后面的数比较大小， 然后一个if else进行换位， 最后一个for循环， 多长的序列都可以瞬间搞定。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;176de-0-0&quot;&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.40556900726392253&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibccd3W2SkazpguaDUmf1EWibibibEBCIwsAHiaGwDkFcYUeGLqHsuPP0ibBA7ibPX7OxPPq87Jr0NAtFjSibw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;826&quot; /&gt;&lt;/span&gt;&lt;/p&gt;


&lt;p&gt;&lt;span data-offset-key=&quot;b1ct2-0-0&quot;&gt;这就是用程序解决问题的核心思维， 给你一个再复杂手忙脚乱的问题， 只要这个问题可计算， 那么我们只需要设定好我们需要的规则表， 在有限的步骤里迭代， 最终机器总会给你解决。&lt;/span&gt;比如魔方问题， 一般的聪明小孩都很难在短时间解决问题， 但是， 事实上解决魔方问题有一套非常整齐的规则表（你想象打乱一个魔方其实比较容易的， 把它弄整齐是打乱的逆运算，但是破镜重圆总是难的）。 如果按照这个规则表执行若干步， 再困难的魔方也给你整出来。&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.75&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibccd3W2SkazpguaDUmf1EWibibz3zliaRoh4oEWf9QQOX3VMpbMFylumcHY7novvRnic1j7aN7R7pohRHQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;676&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;Image FocusPlugin--unfocused Image--isBlock&quot; data-ratio=&quot;0.44333333333333336&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibccd3W2SkazpguaDUmf1EWibibBqmPPsMKMLBUUyKWYnVsiaibg6hmZP9cADL9iak5yxuibvmosIG5ZUWbuw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;600&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;span data-offset-key=&quot;e13hv-0-0&quot;&gt;我们说规则表， 加上迭代等操作的思路可以解决大量的工程问题。我们曾经认为按照这样的思路我们可以解决整个智能的问题。 只是填入一张越来越大的表格。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;5g8h1-0-0&quot;&gt;但是它在通向智能的关键位置， 却停住了， 这个元凶 -就是- &lt;strong&gt;不确定性&lt;/strong&gt;。日常生活中很多东西无法轻易的总结出规则表来， 因为细小的规则实在太多了。 你可以想象我们有无数尺寸和规格各不相同的螺钉螺母。 每一种规格我们都要想一条if else，可悲的是这些螺钉和螺母几乎没有哪两对完全相同， 穷尽一个程序员一生也写不完这些程序。现实生活中的大部分问题属于这一类问题， 比如你无法轻易的写出一段程序来判断A男和B女是否合适结婚。 &lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;中期的智能： 让机器学会归纳规则表&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;5g8h1-0-0&quot;&gt;&lt;img data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz/dcEP2tDMibcfyNibceeGvVKo0qCGicGJ9lQ9J5zzOIxmTUAE4OYfwx25QZ2J2KLUic1lWYkMwelC8Ld30RF0FsibAPQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; class=&quot;&quot; data-ratio=&quot;0.1671875&quot; data-w=&quot;640&quot; /&gt;&lt;/span&gt;&lt;/p&gt;


&lt;p&gt;&lt;span data-offset-key=&quot;9mrot-0-0&quot;&gt;统计机器学习 - 机器判断规则&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;6pfmt-0-0&quot;&gt;这个问题的解决方法十分自然又十分了不起：  能不能让机器自己学会这个表格， 而不是认为设定它呢？  这就是整个智能问题的第二步 - 学习。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span data-offset-key=&quot;eeh10-0-0&quot;&gt;整个学习问题的基石其实是古希腊人提出的归纳法和演绎法。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;17gbk-0-0&quot;&gt;伟大的希腊哲学家早就对学习的本质展开过探讨，它们把学习分类为&lt;/span&gt;&lt;span data-offset-key=&quot;17gbk-0-1&quot;&gt;归纳法和演绎法&lt;/span&gt;&lt;span data-offset-key=&quot;17gbk-0-2&quot;&gt;。所谓演绎法， 就是从用一定规则进行推理的过程。 苏格拉底是人，人都是会死的， 因此苏格拉底会死。这就是三段论， 或者称为演绎法的根基。 而真正学习的过程，是这个演绎法的逆过程。我们先知道一个特例，然后通过特例，得到这个“人都是会死的” 知识，再指导自己的行动。 学习是知识在脑子或者机器里面形成的过程， 怎么形成？ 这个过程被称为归纳法，也就是根据搜集到的特例比如苏格拉底死了这个事情，来归纳更一般的知识。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.5625&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibccd3W2SkazpguaDUmf1EWibibmSX7rgCyJJfTKEhApOyARbIowfAnPvZVr0gFicQTQYD7WgfkLMcPbZw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;640&quot; /&gt;&lt;/p&gt;



&lt;p&gt;&lt;span data-offset-key=&quot;17gbk-0-2&quot;&gt;让机器实现归纳法， 我们来看我们需要提供给机器怎样的佐料来解决这个问题。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;6nhn2-0-0&quot;&gt;我们想象这样一台机器， 这个机器和之前说的规则机器类似， 唯一的区别是， 我们把大量的假设放在那里，让机器来连线。 我们要让它学习一个知识， 比如-什么人是否会死的。我们把人按照几个特征进行分类， 一个特征对应一个问题， 比如是否是哲学家， 是男还是女， 是白种人还是黄种人。 这些特征， 都对应会死或不会死这两个结论。 这样，你会得到多少个假设呢？ 组合数学告诉我们16种， 于是学习的任务就是给这16个假设和真或者假连接起来。 一旦一条线连起来， 我们就得到了一个新的知识，可以被用于在真实的世界做判断！ 就和之前说的规则机器一样。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.5625&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibccd3W2SkazpguaDUmf1EWibibeB6eia8YghicHCagGO02XX9WcmpmicrD1ya9UNmpAlIqbbygWzLKiarAVQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;640&quot; /&gt;&lt;/p&gt;


&lt;p&gt;&lt;span data-offset-key=&quot;1bdeq-0-0&quot;&gt;我们首先给这个机器灌入所有的可能性， 那16种假设。 然后我们让机器来收集案例！比如机器收集到一个苏格拉底死了， 那么苏格拉底是什么？ 男性，白种人， 哲学家， 于是机器得到男性， 白种人， 哲学家，会死。 于是机器给机器输入亚里士多德， 柏拉图， 大卫休谟，机器都会告诉你会死。然后我们继续收集样例， 比如居里夫人死了， 然后机器会得到女性，白种人， 非哲学家，死了。 这样它能够做的判断就又多了很多！ &lt;strong&gt;我们直接把规则转化为了可以学习的对象。输入样例，得到一个是非的知识， 这个样例我们换个词叫数据， 这个机器我们换个词– 叫做分类器。&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;&gt;&lt;/ins&gt; &lt;img class=&quot;&quot; data-ratio=&quot;0.5625&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibccd3W2SkazpguaDUmf1EWibibCChMBjNz3U3sMtU9kp7SpWibY4ocjf7OhopFnViaibcnR1aYIDpYKLaVg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;640&quot; /&gt;&lt;/p&gt;


&lt;p&gt;&lt;strong&gt;整个有关统计的机器学习， 都可以看成让机器学习有效归纳的方法， 从数据里得到规则表， 再用规则表进行判断。前面的过程叫训练， 后面的过程叫测试。 &lt;/strong&gt;&lt;span data-offset-key=&quot;9nnub-0-0&quot;&gt; 如果这些规则是有关一个是非的命题， 它就是一个分类器， 如果它是一个连续数值的预测， 就是回归。 但是规则表的本质是不变的， 它就是让你填表，表格的横排和竖排已经有了， 一个叫特征， 一个叫实例。 特征是人为归纳好的， 而实例是我们人为收集的， 表格中有些地方是空的，  就是我们想要判断的东西， 需要机器来填的部分。 比如给你一百幸福和不幸的人的案例， 让你判断第101个人的情况。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.7663197729422895&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibccd3W2SkazpguaDUmf1EWibibGeQKfN4oT43Gf7qPQGibnceOkVZRMtllFgcAHBwVIocWdibkMkFB9V1Q/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1057&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;图：机器从实例中学到分类的方法： 机器学习&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;81s85-0-0&quot;&gt;刚刚的那个例子你应该已经体会到， 这个命题验证过程其实是一个组合爆炸的问题。我们把关于这个世界的互相矛盾的假设都丢尽机器。即使最简单的问题也会有无穷多的情况要判断 （特征的n次方）这种假设的数量随着问题的复杂度急速指数上升的过程，我们称之为维度灾难。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.5625&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibccd3W2SkazpguaDUmf1EWibib6XNRA36VEFMtlPlZQ2RpPXtla5u66LIcDmhkLUQuPecqg0IVicuibIwA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;640&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;span data-offset-key=&quot;ajopm-0-0&quot;&gt;而机器学习的各个算法， 让我们通过加入更多的假设， 来偷懒解决这个问题， 此处没有比决策树更典型的， 它的高阶版本xgboost成为机器学习竞赛的杀手锏。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;a9isr-0-0&quot;&gt;而决策树得核心智慧就是优先级算法简化命题数量。 虽然特征很多， 但是并不是每个特征都一样重要， 我们如果先按照最重要得特征进行判断， 依此往下， 你可能不需要2得N次方个情况， 而是按照树结构做N次判定即可。 优先级， 也是人类智慧得核心。事实上， 我们永远在抓轻重缓急，在抓主要矛盾， 无论是有意的还是无意的，当然大部分人的轻重缓急是按照时间来的，时间比较近的就是比较重要的， 这也是为什么很多人有拖延症。 &lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;a9isr-0-0&quot;&gt;很多人说到优先级算法很想到相亲， 其实这也是一种人类思维自然使用的决策树， 比如女生找男朋友通常心理都有一个优先级构成的树， 首先， 对方的年龄多大？ 如果对方年龄大于50岁直接pass， 然后看工资，如果工资小于20万直接pass，工资在20和30万间看下学历， 学历小于本科直接pass。 这其实就是一个决策树的结构。 每次pass， 就减少掉了一半需要判定的命题。 通过这种预设的二叉树逻辑， 一个本来需要2的n次方的步骤解决的事情， 可能只要n步了。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.7453703703703703&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibccd3W2SkazpguaDUmf1EWibibq5oBakMtQKgHb2Akq4jNYicdNNniarAhbtJNpWaJ7qOkbJDDKpTTB9MQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;8dl0e-0-0&quot;&gt;具体如何来学，树的根部是你选择的第一个特征， 更好的角度是把特征看成一个问题，树的根部是你要问的第一个问题， 根据这个问题的回答， 数据会在左边右边分成两组。 然后在每个答案的基础上， 你继续问下一个问题， 所谓的决策树的分叉， 每个枝杈就是一个新的问题。 &lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;8dl0e-0-0&quot;&gt;如此，就会形成一个树的结构。构建这个树的主要难点， 在于要由机器决定哪个问题先问， 哪个问题后问， 如何选择这个优先顺序？我的要求就是， 每一次分化，我们都希望取得最多的信息，如分叉后一个树杈全是yes，一个全是no就是最好的效果， 如果达不到， 也让它尽可能接近这个效果。  这样一个一个问题问下去， 最终达到稳定后过程停止。  这样形成的决策树， 我们会形成任何一个情况下的优先级。 或许长的帅的人工资不重要。 或许学历高的人年龄不重要。 这种不同情况不停调整优先级的思维， 真的是被决策树利用到了极致！ 从原始数据里提炼的决策树， 可以对无限的新情况进行预测。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;fk0ce-0-0&quot;&gt;另一个得到这样的一个规则表的方法是线性假设。 线性分类器通过假定特征之间的相互独立， 使得命题的成立与否可以通过一个加权求和的关系表达， 即f=wx+b 。最后f如果大于0就是是， 小于0就是否。 线性分类器也是一种特别符合人认知习惯的模型：一般人在决策时候做的事情就是加权平均，比如你平时做分类（决策）， 你最想的一种状态是什么？你要把几个核心的要素放到一起， 按照他们的重要性加和，比如你今天要不要去看电影，可能取决于你的女朋友free否， 下不下雨和电影好不好看， 这个时候，我们可以把这些因素加权在一起， 在和一个我们给定的阈值做比较，大就去， 不大就不去， 这正权衡得失的做法， 就是线性分类器。线性分类器看上去是一个数学公式， 本质还是一个规则表， 只不过这里要学习的规则无非是每个特征给多少权重。最后在表格最后一列得到yes or no。 &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.9387096774193548&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibccd3W2SkazpguaDUmf1EWibibm99R31Z3g5uTib3k3mrK8kME4XDCicJ6HgXW6a31dQaFa9RABR3z7VHA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;620&quot; /&gt;&lt;/p&gt;
&lt;p&gt;图： 线性分类器， 一条直线代表一组权重， 把两组数据分的越开越好。 &lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;a0m7b-0-0&quot;&gt;具体学习的过程， 我们从实例里归纳出每个特征对应的权重参数，然后进行判断。 只要参数都确定了， 也就是一次解决了所有的问题。 线性分类器的高级版本SVM已经超越了线性假设。 也是小数据下生成有效规则的大杀器。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;span data-offset-key=&quot;a0m7b-0-0&quot;&gt;近期的智能： 让机器生成有效的规则 &lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;span data-offset-key=&quot;a0m7b-0-0&quot;&gt;&lt;img data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz/dcEP2tDMibcfyNibceeGvVKo0qCGicGJ9lQ9J5zzOIxmTUAE4OYfwx25QZ2J2KLUic1lWYkMwelC8Ld30RF0FsibAPQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; class=&quot;&quot; data-ratio=&quot;0.1671875&quot; data-w=&quot;640&quot; /&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;8te9f-0-0&quot;&gt;连接主义机器学习， 产生规则&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span data-offset-key=&quot;fk6j-0-0&quot;&gt;刚刚说的那一套， 有一个问题你有没有注意到？ 我们最先提出的问题是让机器产生一个规则表， 而刚刚说的统计机器学习里， 更多的是让机器根据定好的特征收集数据进行命题判断。 这其实离我们说的让机器自己得到规则表只进行了0.5步。&lt;strong&gt;大家想象下， 在真正的实践活动里， 你无法一开始就设定出一堆特征让它进行逻辑判断，在这个情况下如何得到我们所说的“规则”呢？ &lt;/strong&gt; 如何让机器自己生成战胜“复杂”的程序呢？ 连接主义机器学习在一定程度解决了这个问题。  因为， 人类认识事物，生成规则， 其实是通过“&lt;strong&gt;概念&lt;/strong&gt;”来的， “概念”是一个浓缩的信息载体， 通过它我们能够进行任何更复杂的推理。 那么“概念”是如何生成的呢？ 它的载体正是下面说的联结主义的代言人神经网络。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;a5gsn-0-0&quot;&gt;神经网络&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span data-offset-key=&quot;dijog-0-0&quot;&gt;首先，神经网络是由神经细胞组成的。  一个神经细胞就是一个最小的认知单元， 何为认知单元，就是把一定的数据组成起来，对它做出一个判断， 我们可以给它看成一个具有偏好的探测器。  联系机器学习，它就是刚刚说的线性分类器。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;cr2lq-0-0&quot;&gt;正确的分类，是认知的基础，我们对事物的感知比如色彩，物体的形状等，其实都是离散的，而物理信号是连续的，比如光波，声波。这里面的中间步骤就是模数转化，把连续的信号转化成离散的样子，这正是一个分类器干的事情。一个单个神经元可以执行一个简单的基于感知信号的if else语句。 先收集一下特征做个加和，if大于一个值我就放电，小于我就不放电，就这么简单。晶体管当然也在干这个事情。 神经细胞与晶体管和计算机的根本区别在于可塑性。或者更准确的说具有学习能力。从机器学习的角度看， 它实现的是一个可以学习的分类器，就和我们上次课讲的一样， 具有自己调整权重的能力， 也就是调整这个w1和w2.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.5625&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibccd3W2SkazpguaDUmf1EWibib2NvE4HCXevrTz3VAnXzfIxaOZibibe1YnYGN84NF1XWqyKpNdsISR2aA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;640&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;3f6fb-0-0&quot;&gt;我们这个简化出来的模型，正是所有人工神经网络的祖母－感知机。从名字可以看出，&lt;/span&gt;&lt;span data-offset-key=&quot;3f6fb-0-1&quot;&gt;感知机算是最早的把连接主义引入机器学习的尝试。&lt;/span&gt;&lt;span data-offset-key=&quot;3f6fb-0-2&quot;&gt; 它直接模拟Warren McCulloch 和 Walter Pitts 在1943 提出而来神经元的模型， 它的创始人 R 事实上制造了一台硬件装置的跟神经元器件装置。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;2b1gb-0-0&quot;&gt;单个的感知机并不能比传统的机器学习多做一丁点的事情， 还要差一些。 但是把很多个感知机比较聪明的联系起来，就发生了一个质变。&lt;/span&gt;首先， 每个线性分类器， 刚刚讲过都是一个小的特征检测器， 具有自己的偏好，这个偏好刚好用一个直线表示，左边是yes，右边是no， 那么多个神经元表达的是什么呢？ 很多条这样yes or no的直线！  最终的结果是什么呢？我们得到一个被一条条直线割的四分五裂的结构， 既混乱又没用！  这就好比每个信息收集者按照自己的偏好得到一个结论。所以， 多个神经之后，我们还要在头顶放一个神经元， 它就是最终的大法官， 它把每个人划分的方法， 做一个汇总。 大法官并不需要什么特殊的手段做汇总，&lt;strong&gt; 它所做到的，无非是逻辑运算， 所谓的“与”， “或”， “非”， 这个合并方法，把哪些被直线分开的四分五裂的块，就可以得到一个非常复杂的判决结果。 &lt;/strong&gt;你可以把大法官的工作看成是筛选， 我们要再空间里筛选出一个我们最终需要的形状来， 这有点像是小孩子玩的折纸游戏，每一次都这一条直线， 最终会得到一个边界非常复杂的图形。 其实这里面做的事情， 正是基础的逻辑运算， 一个简单的一层神经网络可以执行与或非这些基本的逻辑操作。事实上它的本质就是把简单的特征组合在一起形成一些原始的概念。&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.5758323057953144&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibccd3W2SkazpguaDUmf1EWibibuABrESypc6M08wlHD6dia0vL7GRLUKEQiby0Bicc47icreRupKWw5IHVVQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;811&quot; /&gt;&lt;/p&gt;
&lt;p&gt;它是怎么做到的呢？ 学习。 生物神经网络的学习， 是通过一种叫做hebbian可塑性的性质进行调节的。 这种调控的法则十分简单。说的是神经细胞之间的连接随着它们的活动而变化， 这个变化的方法是， 如果有两个上游的神经元同时给一个共同的下游神经元提供输入， 那么这个共同的输入将导致那个弱的神经元连接的增强， 或者说权重的增强。 这个原理导致的结果是， 我们会形成对共同出现的特征的一种相关性提取。 比如一个香蕉的特征是黄色和长形， 一个猴子经常看到香蕉， 那么一个连接到黄色和长形这两种底层特征的细胞就会越来越敏感， 形成一个对香蕉敏感的细胞，我们简称香蕉细胞。 也就是说我们通过底层特征的“共现” 形成了一个简单的“概念”。 上述过程被总结hebian学习的一个过程。  我们可想象，一个两层以上的神经网络， 就可以表述香蕉， 苹果， 菠萝这些水果了， 它们无非是底层特征颜色，形状的不同组合而已。 而这些不同水果的概念， 就可以帮助我们形成更加复杂的规则表 ，比如让它根据客户的信息帮它推荐一个水果拼盘。 由此可见， 神经网络通过与或非进行简单特征的组合 ，再通过if esle进行判断选择合适的特征得到概念， 再通过下一层迭代得到概念有关的命题。 就可以生成比之前的传统机器学习复杂的多的规则表。而且我们可以想象出来， 迭代的层数越多，它生成的“概念”和“规则”就越复杂。  &lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;48v3r-0-0&quot;&gt;当然真实训练中我们用到的不是模仿生物版本的hebbian学习， 而是强大的多的反向传播算法。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span data-offset-key=&quot;48v3r-0-0&quot;&gt;&lt;img data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/jrbyyXzrKkJqzpvQ60VcjgiacFu21XHHubic1vJveCSZ6PHEDDyJd1LZhn3z6ibqmBehPbx0icZx0ZXosoBaXWceQw/640?wx_fmt=png&quot; data-type=&quot;png&quot; class=&quot;&quot; data-ratio=&quot;1.6111111111111112&quot; data-w=&quot;360&quot; /&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;&gt;&lt;/ins&gt; &lt;span data-offset-key=&quot;dmb6s-0-0&quot;&gt;事实上为了让这种生成“概念”得到“规则”的方法更加有效， 我们会加入一些无比强大的先验假设。 其中最有名的一组，  就叫CNN，它所做的，其实是针对于图像这类巨大无比而局部特征不断重复的数据形式， 你可以写一个循环， 来让你的程序更有效。 循环里的每一步都对图像的局部特征进行提取， 由一个可以共用的卷积核实现。 卷积核一点点的卷过图像上的每个小块， 也就是循环的总体。 卷积核在每个图像局部做的， 事实上都是一个小的if esle 语句。 if像素之间符合某个关系，就是yes，否则No。这个结果， 最后被综合出来， 给下一层合成更复杂的图像特征。我们事实上通过学习的过程，让机器自动补全了循环每一步的这个if else语句。 &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.7298850574712644&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibccd3W2SkazpguaDUmf1EWibibJ7GaCXDzw2dMW8QiaAPh96svf1lqjLico2MoDlVUCfFZgIHkysrSaRibQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;870&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;4vk9r-0-0&quot;&gt;好了，到目前为止， 说的都是和时间无关的规则。 而一开始讲到的真实的图灵机， 是和时间有关的规则。 那么如何得到一个和时间有关的规则表呢？ 如果要处理和时间相关的信息， 你必须要引入记忆，引入内部状态， 而和刚刚说的一样， 这些含时间的规则要是可以学习的，用数学的语言说， 就是要有一个连续可微的载体， 这个东西就是RNN。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;72qm9-0-0&quot;&gt;def step&lt;/span&gt;&lt;span data-offset-key=&quot;72qm9-0-1&quot;&gt;(self, x):&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span data-offset-key=&quot;di032-0-0&quot;&gt;# update the hidden state&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span data-offset-key=&quot;4f218-0-0&quot;&gt;self.h = np.tanh(np.dot(self.W_hh, self.h) + np.dot(self.W_xh, x))&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span data-offset-key=&quot;243tl-0-0&quot;&gt;# compute the output vector&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span data-offset-key=&quot;591p4-0-0&quot;&gt;y = np.dot(self.W_hy, self.h)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span data-offset-key=&quot;a1b57-0-0&quot;&gt;return&lt;/span&gt;&lt;span data-offset-key=&quot;a1b57-0-1&quot;&gt; y&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;g9on-0-0&quot;&gt;以上是RNN的python程序定义。 它说的无非是你有一个刚刚说的线性分类器组成的单隐层神经网络，但是这一回，神经网络的输出，要作为输入，重新回到神经网络的隐层里， 这个关键的增加， 就使得它具有了处理复杂时间信息的能力。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;5qh71-0-0&quot;&gt;这个结构，非但优雅，而且有效。一个非常重要的点是， 你知道信息的传播是有损耗的， 如果把RNN展开， 它事实上相当于一个和历史长度一样长的深度网络， 信息随着每个时间步骤往深度传播， 这个传播的信息是有损耗的， 到一定程度我就记不住之前的信息了， 当然如果你的学习学的足够好， Wij还是可以学到应该学的记忆长度。  &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;Image FocusPlugin--unfocused Image--isBlock&quot; data-ratio=&quot;0.26161790017211706&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibccd3W2SkazpguaDUmf1EWibibPf1BYBmsfuHXyspOv0uwulVbuy0UibqOib2grXtp4XpvWU4b6Pj3402Q/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;581&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;2ot4h-0-0&quot;&gt;事实上叫做“循环神经网络”  循环的本质是什么呢？   它其实正是你的程序里的for循环啊！ RNN的本质是， 在每个时间步里进行同样的操作， 这个操作无非是， 当下的输入， 和神经网络的状态两部分特征的逻辑组合（与或非）然后， 这个组合的结构进行一个if else的逻辑判断， yes or no， 根据这个，生成一个输出的结果， 这个结果， 要回传给神经网络隐层， 生成下一个隐层状态。 大家看这其实就是图灵机的定义啊， 而RNN的本质， 就是一个可以通过微分方法学习的图灵机啊。 虽然每个步骤的规则和执行足够简单， 但是只要步数足够多， 却可以产生非常复杂的结果。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;2ot4h-0-0&quot;&gt;RNN学习的本质， 就是给你那个足够复杂的结果， 让你反演出那个足够简单的规则， 然后让它在新的环境下再去做预测与决策。 我们可以看到， 这已经非常接近智能的本质了。 那么RNN有没有可能学到真正类似人类的抽象思考能力， 具备人类类似的生成规则的能力呢？ 这可能才是后面真正的问题。 &lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;span data-offset-key=&quot;2ot4h-0-0&quot;&gt;让机器生成有关未来的规则-强化学习&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;span data-offset-key=&quot;2ot4h-0-0&quot;&gt;&lt;img data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz/dcEP2tDMibcfyNibceeGvVKo0qCGicGJ9lQ9J5zzOIxmTUAE4OYfwx25QZ2J2KLUic1lWYkMwelC8Ld30RF0FsibAPQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; class=&quot;&quot; data-ratio=&quot;0.1671875&quot; data-w=&quot;640&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;span data-offset-key=&quot;2ot4h-0-0&quot;&gt; &lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span data-offset-key=&quot;2ot4h-0-0&quot;&gt;强化学习&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; rgb=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;&gt;果说监督学习的基本框架已经是在生成用于判断（分类）的规则表， 那么强化学习， 就是生成一套直接用于行动的规则表， 这套语言的元素包括&lt;span&gt;状态， 行为， 观测， 奖励&lt;/span&gt;。 事实上， 强化学习所做的事情是从成功或失败的经历里去归纳行为的准则。 &lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; rgb=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;&gt;我开头讲的解魔方的问题， 如过让机器自己找到最短时间完成它的方法， 这就是强化学习所做的事情。 &lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; rgb=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;&gt;首先看&lt;span&gt;状态&lt;/span&gt;s， 状态是什么呢？ 它指的是智能体（agent）所在的环境里所有和游戏有关的信息， &lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; rgb=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;&gt;&lt;span&gt;再来看行为，所谓行为，是指智能体的&lt;/span&gt;&lt;span&gt;决策&lt;/span&gt;&lt;span&gt;，某种情况下我们可以认为它就是监督学习要求的那个y， 或者预测， 但一个决策与预测不同的是，我们并不能马上取得一个信号告诉我们这个决策对不对， 只有在游戏的最后 ，我们才能从整个游戏的收益反观当时的决策好坏。&lt;/span&gt;&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; rgb=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;&gt;寻找到从根据当下的状态s行动的一张规则表， 让我有最好的机会拿到奖励， 就是强化学习在做的事情。 &lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; rgb=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;&gt;而深度强化学习呢？  它就是把刚说的连接主义通过概念生成规则的方法，和此处的决策联系起来得到的框架。 &lt;/p&gt;


&lt;p&gt;&lt;strong&gt;&lt;span data-offset-key=&quot;2ot4h-0-0&quot;&gt;我们还差很远&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;span data-offset-key=&quot;2ot4h-0-0&quot;&gt;&lt;img data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz/dcEP2tDMibcfyNibceeGvVKo0qCGicGJ9lQ9J5zzOIxmTUAE4OYfwx25QZ2J2KLUic1lWYkMwelC8Ld30RF0FsibAPQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; class=&quot;&quot; data-ratio=&quot;0.1671875&quot; data-w=&quot;640&quot; /&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;说到所有上述的东西， 你会觉得我们已经无所不能， 既然机器能够自己填写程序， 自己生成规则表来适应多变的世界， 那我们还差什么呢？  我们说都是生成规则， 不同的规则效力差距万千，而目前的AI在此处也就是个小学生。 亚里士多德和牛顿都观测力学现象， 亚里士多德看到的是轻的气体向上飘，重的东西向下沉。 牛顿看到的是受力与加速度的关系。 这两种规则的归纳即使都能解释现象， 但是它们的泛化能力确是千差万别， 一个可以解释全宇宙， 另一个也就适应一些物体吧。 如同下图所示， 坏的规则总结只能解释数据实例周边一丁点的地方， 而好的规则呢， 它可以把点连城片！  &lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.7445945945945946&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibce3GnvDlNCSjsGosHtINzN4XExqvasWticuD9ehaBQuFeiazL5LEfoMicN72hz0eQJEZpp4IqichpMVAA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;740&quot; /&gt;&lt;/p&gt;
&lt;p&gt;我们说人类总结的规则解释力最强的地方是物理 ，因为物理里描述了客观实体间作用的因果联系，而非简单的相关性。 这恰恰是目前AI所不足的。 &lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;5j932-0-0&quot;&gt;有关物理的世界和智能的世界&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;di5qc-0-0&quot;&gt;上面的这些思考无疑开始让人们想象我们所说的包含了逻辑推理， 情感，甚至意识的问题与物理世界的关系到底是什么。 我们说物理的世界里， 主宰一切的是微分方程。 一切因果关系， 都由微分方程所承载。 你有了不同不同微观粒子电磁力的描述，把它们放入薛定谔和狄拉克方程， 你就可以推出原子的不同性质。  这其实可以说是因果推理的极致了。 它甚至导致了机械的宿命论思想。当一切初始的原因输入系统， 那么它就回归于一个必然的结果。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;dl784-0-0&quot;&gt;到了非线性动力学的时代看似这点被混沌打破了，亚马逊的蝴蝶引起北美的飓风， 让通俗科学爱好折重新燃起了不可知论的希望，事实上并没有。  所谓的混沌， 无非是一种确定性下的不确定， 或者已知中的未知。 混沌的系统依然在一个被方程高度确定的洛伦兹吸引子里。&lt;/span&gt;&lt;/p&gt;

&lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;&gt;&lt;/ins&gt; &lt;p&gt;&lt;span data-offset-key=&quot;af64u-0-0&quot;&gt;到此处， 我认为微分方程依然是描述因果关系最精密的所在， 它可以在输入很少信息的时候， 得到最多的预测产出。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;8i7lg-0-0&quot;&gt;在看刚刚的智能问题， 我们说， 整个智能问题， 到目前为止其实还是在围绕那张规则表， 只是我们的思路由制定规则表， 到了学习规则表。和物理比较， 目前的机器， 需要输入进去大量的数据， 才能生成一点十分简单的规则。 当然你可以举阿法狗下围棋的例子说明所生成的规则并没有那么简单， 可惜的是， 那些规则只适用于一些非常封闭而特定的领域。 而不像牛顿定律放之四海而皆准。  那么神经网络可不可以观测大量物体坠落的过程把万有引力定律给推出来呢？ 目前看是不能的。其实牛顿引力定律的得出是含有了大量的人类推理。 我们需要先知道物体运动改变和受力的关系， 然后通过观测物体的轨迹得到大量物体的受力情况，再在这些手里情况下得出某一种共同的作用力形式， 这是一个多么复杂的思维链条。 这对于目前统计的巨人， 而只懂得浅显的形式逻辑的神经网络，还是比较困难的。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;8i7lg-0-0&quot;&gt;如果我们可以用神经网络加上强化学习，诱导它掌握特别抽象而复杂的如受力，运动这样的概念，那将是不可想象的， 目前我们也并不清楚有没有那一天。 &lt;/span&gt;&lt;/p&gt;

&lt;p&gt;另一方面， 人类是通过符号组成的语言思考的， 目前AI总结和归纳符号的能力， 同人类的语言相比依然天差地别。 &lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;dsh1-0-0&quot;&gt;有关语言代表的符号世界&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span data-offset-key=&quot;8cbc-0-0&quot;&gt;讨论智能的问题离不开语言。从乔姆斯基开始，人们就开始研究不同语言背后的共同语法基础。 其实如果深究语言问题， 我们会看到它和刚刚说的程序的联系。 语言无非是对世界的符号化，类似于给每个刚刚说的概念赋予一个符号。而语言其实很像程序， 它就是对概念之间关系的表述。 当然数学也是一套伟大的符号系统。  语言和数学以及程序的区别可能在于语言更加模糊， 但是它对付不确定性的能力远远大于程序。  &lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;8cbc-0-0&quot;&gt;事实上， 人类语言很少有那种特征精确的关于几何关系和量值的描绘， 而似乎更多定性成分， 比如美丑，近， 远， 大，小。 我们可以想象在一个充满变化的世界那种特别精确的描述不一定十分有用。 恰恰因为这种模糊性，让它具备了更好的适应能力， 和泛化能力。 可以表述那些用程序难以描述的事情。 &lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;8cbc-0-0&quot;&gt;既然本质上语言无非是一个现有概念的符号体系，以往的深度学习NLP其实是走了一条南辕北辙的路，我们把不同的词汇和句子压缩成词向量， 句向量喂给神经网络学习， &lt;strong&gt;而事实上神经网络对这些符号背后的实体概念却一无所知。&lt;/strong&gt;虽然词向量也能稍微的带有一点不同词语之间的语义距离， 但是这和真实世界所含有的信息量，也依然是差异巨大。 目前用图卷积网络解决NLP的思路，算是一个进步， 因为它更好的涵盖了整个符号世界的信息。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;blfe1-0-0&quot;&gt;语言， 好比一个巨大的人类经验和逻辑的宝库， 这个符号世界几乎就是真实世界的最好压缩体， 如果一天神经网络真正被赋予了语言的power，也就是能够真正理解这个符号世界，或许离通用人工智能也就不远了。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;有关物理世界和语言世界的打通&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;blfe1-0-0&quot;&gt;刚刚说的精确的物理方程的世界， 和能够应付更多不确定性的模糊的语言， 之间又有哪些联系呢？  我的想法是， 物理的杀手锏微分方程， 当构成了一个非线性的动力学系统， 却可以通过它内在的定点， 极限环，吸引子等概念， 去接近那个模糊性的语言， 就好比在非线性动力学的世界里， 我们往往不再那么关于一个系统如何发展的暂态，很多不同的系统都归一于一个吸引子， 那么它们背后的逻辑可能就是类似的。 这或许会架起一座物理世界和语义世界的桥梁？  &lt;/span&gt;&lt;/p&gt;


&lt;p&gt;&lt;strong&gt;&lt;span data-offset-key=&quot;blfe1-0-0&quot;&gt;如何让机器学习符号&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;blfe1-0-0&quot;&gt;假定语言这样的高效符号系统是大脑产生的，那么我们是否可以根据脑科学的启发把这种能力赋予神经网络，来加强它的推理能力呢？ 如此可以延申的思考还很广很广。&lt;/span&gt;&lt;/p&gt;



&lt;p&gt;&lt;span data-offset-key=&quot;blfe1-0-0&quot;&gt;更多阅读&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651383991&amp;amp;idx=1&amp;amp;sn=26f543505499441e7f31cfb15177ff10&amp;amp;chksm=84f3c6f6b3844fe08f91bfec42c55b42d221f452c68d3820eb1612a6c09f39c06956d69f42ca&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-itemshowtype=&quot;0&quot; data-linktype=&quot;2&quot;&gt;当神经网络遇到神经科学-铁哥18年长文汇总&lt;/a&gt;&lt;br /&gt;&lt;/p&gt;

</description>
<pubDate>Tue, 26 Feb 2019 00:50:52 +0000</pubDate>
<dc:language>zh-CN</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.jintiankansha.me/t/WW3EirRLSj</dc:identifier>
</item>
<item>
<title>重新发现算术里的奥秘</title>
<link>http://www.jintiankansha.me/t/Twkyk6FqwC</link>
<guid isPermaLink="true" >http://www.jintiankansha.me/t/Twkyk6FqwC</guid>
<description>&lt;p&gt;本文源自混沌巡洋舰群聊，其中全部发言来自苑明理同学的聊天记录。&lt;/p&gt;

&lt;p&gt;现在计算科学正在一次深刻革命过程的早期。以深度学习为代表，人们对智能的探索，是打开了计算科学的另一个分支。&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;计算科学的现有的庞大分支，起源于对希尔伯特第十问题的研究；起源于1930年代的三个探索，当时建立了可计算性的概念；而后很多物理实现和后继概念是建立在冯诺依曼架构基础之上的，建立在程序、数据、控制这样的概念上。 &lt;/p&gt;

&lt;p&gt;仔细考虑图灵当时在起点的工作，其实他有深刻的考虑智能的问题。现今深度学习为代表的思路，从概念上讲，其实已经突破了冯诺依曼架构，它是从数据里自动学出来程序的思路。这一支与上一支分离的点足够深，它一定能开出不一样的花朵，长成不一样的大树。可学习性有可能是这一支的一个重要核心问题。 从两支分叉的地方再往下走，会看到计算、学习、智能、复杂、涌现是联系在一起的，是逻辑的与物理的交融地带。&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.75&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcenIthqEebeoxb2Luib6B1BgGs17uBsFJBr33RJZf0NQjK9uwAxibyOdsWXRkCQqYDXhbBxZvTRbT5w/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1496&quot; /&gt;&lt;/p&gt;

&lt;p&gt;很多可计算发展出来的技术，都是去解决一个“浮出水面”的问题，需要在一个清晰的边界内来处理。可实际上智能有一种能力，从混沌中，画出界限，把一侧的事情厘清。这种能力，是基于对意义的追寻。&lt;/p&gt;

&lt;p&gt;语言之意义的问题，更多涉及到跨代际的文化上，这个话题，不是讨论智能体个体的对一个刺激做出的意义的反馈，而是考虑文化中有些部分是被数学限定的。举例子来说。我们知道甲骨文中很多人名、地名都无法有效解读了，很多字的解读也众说纷纭；古代典籍的情况要好一些，但也有许多句读都不一致的解读。但是，另一方面，我们看到对数字的解读是非常稳定的，这个是可以问为什么的。这个就同我们造一台计算机或者计算器是类似的，你怎么知道你造的计算器符合你的预期？人类代际的知识传递，也是这个问题。&lt;/p&gt;

&lt;p&gt;所以，我想说的是，某种意义上，意义是一个幻觉，因为它依赖一个不断变化的上下文；某种意义上，它不是幻觉，它至少有坚固的内核非常稳定，甚至包括内核之外的很大一部分在千年的尺度上也是稳定的。最稳定的内核具有的特点是这些概念可以自举（self-bootstrap）。以数和命题逻辑为例，它们都是可以自举的形式系统。自举的意思是，我可以构造一个满足系统（数或者逻辑）形式上要求的例子（模型），来实现这个系统，从而给出一个坚实的意义基础。自举同时也在说，我在实现的时候，只利用系统（数或者逻辑）自身的符号体系，无需引入更多的外部资源。&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.3323308270676692&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcenIthqEebeoxb2Luib6B1BgehAOwrFPQNVInHNx2lpt3Yx0BicXKBJLts9fNLYTsyAu7T3ZfhUrBfw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1330&quot; /&gt;&lt;/p&gt;

&lt;p&gt;一致且完备，那么语言和世界就是等同的。一致性和完全性是讨论语言和世界的关系。我们有一个形式系统（语言） A，有一些模型（世界） B。如果模型 B 里的事物在形式系统 A 里都成立，我们说模型（世界）和形式系统（语言）是一致的；另一方面，如果形式系统（语言） A 里的句子在模型（世界） B 里都成立，我们说形式系统（语言）和模型（世界）是完备的。&lt;/p&gt;

&lt;p&gt;讨论中涉及的文章：&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&amp;amp;mid=2652038615&amp;amp;idx=1&amp;amp;sn=4fa951093f48fb4c4ee5a82bde06b67f&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-linktype=&quot;2&quot;&gt;实现强AI还靠模拟计算：不理解智能也完全可能构建出智能&lt;/a&gt;&lt;br /&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650757216&amp;amp;idx=2&amp;amp;sn=d67abe5c29951584c544e607ae893b6c&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-linktype=&quot;2&quot;&gt;Science：人工智能的发展离不开神经科学，先天结构或是下一个方向&lt;/a&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;铁哥的点评：逻辑里的因果关系确实是有客观物理实体的，它的一大体现就是微分方程，把受力和当下的状态输入进去，就会得到未来的情况。这就比纯统计的描述有效的多，也可以看作一种降维的手段，因为具有因果之后最终得到的世界模型会精简很多。非线性动力学也是个可能的切入点，例如经过统计学习的rnn可以从数据里自发学到程序，它借助动力学中的吸引子等概念沟通了两个世界&lt;/p&gt;

&lt;p&gt;下面的ppt，是本推文的要点。具体讨论了数学作为为何能表述世界，算术和其表达的意义有何关系？&lt;br /&gt;&lt;/p&gt;



&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.75&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcdFVUGGAzl9lYExu88XOItIoPwCaGk8dElN3BDBtAnwp3XNPiaXvFjPQfPOianO01A3MwAZcD1pibnrQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1280&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.75&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcdFVUGGAzl9lYExu88XOItIyGpaM00iaxPgFTzpEQflAt6a6Ou7TGgFDIySvmUhcDAxl82aEynK0CA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1280&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.75&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcdFVUGGAzl9lYExu88XOItIr0rsicoJXrdMibqN1e4sfhE1h4EIV0E3JM8Bj9PqqbwiadCXyoxJE3V7w/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1280&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.75&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcdFVUGGAzl9lYExu88XOItIo5Z1VFib0Ov9LdBq2QhGM6ovXeju29t5bjJWWZ1iaZjDjwkUfk9H4sxA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1280&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.75&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcdFVUGGAzl9lYExu88XOItIzLgNRKdqrsU7XIxVyV45yyu5fpluqYzUDqF2p0rhic7N6iaXyqHrAp8A/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1280&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.75&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcdFVUGGAzl9lYExu88XOItI1fiaws4fA8XKjXHlaKcOedMSYyXb7qKUpkQ4LaNuHAUvphEPuqONTvg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1280&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.75&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcdFVUGGAzl9lYExu88XOItIhcwibpdGOPEeMd9STptx4wscJau21pMCBpH2XWYPPxI9Hf4Hl6ibvfqA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1280&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.75&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcdFVUGGAzl9lYExu88XOItIGjNEo8fgO87gAQVDGn3Q3yD0j1BicsvPnibDScdTLkM23JS2F5kUmeNg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1280&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.75&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcdFVUGGAzl9lYExu88XOItIicJIBNEJXFp7oJ7AslgMdPzAsDEaic2iagfl75C7AqDWLIia2e96dicUhZg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1280&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.75&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcdFVUGGAzl9lYExu88XOItIghRZyoNxxyw4YSHvkFnXZVcNicPn5Eia5Ar4t4cNKk4FvDkto6saibiakw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1280&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.75&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcdFVUGGAzl9lYExu88XOItIUrRGJIQph2XibDRrarKyBmkqMhScKvhmGicQQ7wNb735EDYkVJZTrhew/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1280&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.75&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcdFVUGGAzl9lYExu88XOItIMOicygCLiaufm6snxGBn9QzAiaxrWMtl0ZpHGcgruPHzJK2bQVXafbQ7g/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1280&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.75&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcdFVUGGAzl9lYExu88XOItIWNQJcIV1YhNgYia4yWlyhX4l2yNwiatEMCQDhAMlpdw7iaB6bFsgrZgQA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1280&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.75&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcdFVUGGAzl9lYExu88XOItIWuRrKyc9YPicaLWkib9pZFSazuQUPFG79RhHfRBKfQZtMIN531rMlj0Q/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1280&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.75&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcdFVUGGAzl9lYExu88XOItIAich4O6yHEsI29CAIoXaUC6iczibKmcXgI8AXbZA3WZERgO83yCEaehFQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1280&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.75&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcdFVUGGAzl9lYExu88XOItI2u0dribqdrve2hLnEic4icPLYvUQYQH0b6Jbb4ic33VWzeFtkeFZ3VhYqQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1280&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.75&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcdFVUGGAzl9lYExu88XOItI1lcOF3Ty0f1jHiaChv2Eiawo6NMqWEHxmEww8Dnfqo5yhibCJzl8OqEPw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1280&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.75&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcdFVUGGAzl9lYExu88XOItItCoQAoOHqdpWtyPwslOLqbeTuCKmEiczib4bibiaGcSSY4PWm2p5icWtyWw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1280&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.75&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcdFVUGGAzl9lYExu88XOItI2Fr5I68RMoIxdUaW34G8XLicrEEhsgClSYLmXbQ8IKOq0ACdT1ylHng/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1280&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.75&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcdFVUGGAzl9lYExu88XOItIiceGtBs2Zc3qbD3ceBib1ZHWxB7v3Wg8Lic4YBGt5I49OhnqkFgP9RGtA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1280&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.75&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcdFVUGGAzl9lYExu88XOItIYr2uyQ95bpz2av6aFFQmkOTUsx7wsLbb8nhic7VW5CAYLalhubBibtkQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1280&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.75&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcdFVUGGAzl9lYExu88XOItIrOamyXn1FJbV82pOMI7B2ic4Mk9tHJwNEn1trCuvRJVWmrucEricq4fg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1280&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.75&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcdFVUGGAzl9lYExu88XOItIepu2oKK7iaBR0LSNYl5FJcM8KJFcOiciasaicXcndpPMWI33LdnQkWPLmQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1280&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.75&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcdFVUGGAzl9lYExu88XOItI04hl0IYj2zQgrBeztSic984hn0WlJKCRUwEy8ib5mIicl2XRiceteBQKpQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1280&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;&gt;&lt;/ins&gt; &lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.75&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcdFVUGGAzl9lYExu88XOItIV9JREqia9RtopMgCUx0ibHhNg1I8WibgdLjLJFHG29J9AOanYAhvd1EwA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1280&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.75&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcdFVUGGAzl9lYExu88XOItIRWnwlSSD83BXR0z1qYFJ9ReQJ5ztVYP9oiaibambu1q3VJE0IIKIsRVw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1280&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.75&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcdFVUGGAzl9lYExu88XOItIFITaEwvIkrFE0g0rkdrcDF6eJX4QukGNdibvY0Pia0fsKaEJ44BZqcPw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1280&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.75&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcdFVUGGAzl9lYExu88XOItIEKOgaTrulwT3sTeEOoujJspdL7Tj58kY98fpTxibpQlCx6wUAXib4JmQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1280&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.75&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcdFVUGGAzl9lYExu88XOItIWzCsdyHFz2Is9M5ErdiaIPPL15HfWDRUaTMtZIsr5XqIYSkcHbr4uqQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1280&quot; /&gt;&lt;/p&gt;
&lt;p&gt;更多阅读&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651381559&amp;amp;idx=1&amp;amp;sn=de8a6373f11d6feae834c27319f47a5a&amp;amp;chksm=84f3f176b3847860b3f55bcb3f955d8f4036f703d032cf71e7105506375461b2be7e02dc31cc&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-itemshowtype=&quot;0&quot; data-linktype=&quot;2&quot;&gt;理科博士们在一起会做什么？混沌巡洋舰社群采访纪实&lt;/a&gt;&lt;br /&gt;&lt;/p&gt;



</description>
<pubDate>Thu, 21 Feb 2019 22:35:34 +0000</pubDate>
<dc:language>zh-CN</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.jintiankansha.me/t/Twkyk6FqwC</dc:identifier>
</item>
</channel>
</rss>