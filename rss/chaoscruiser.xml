<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="css/feed.xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/" xmlns:og="http://ogp.me/ns#">
<channel>
<atom:link rel="self" href="http://192.168.1.4/fivefilters/makefulltextfeed.php?url=feed43.com%2Fchaoscruiser-jtks.xml&amp;max=5&amp;links=preserve&amp;exc=1" />
<atom:link rel="alternate" title="Source URL" href="http://feed43.com/chaoscruiser-jtks.xml" />
<atom:link rel="related" title="Subscribe to feed" href="http://www.subtome.com/#/subscribe?feeds=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed43.com%252Fchaoscruiser-jtks.xml%26max%3D5%26links%3Dpreserve%26exc%3D1&amp;back=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed43.com%252Fchaoscruiser-jtks.xml%26max%3D5%26links%3Dpreserve%26exc%3D1" />
<title>混沌巡洋舰</title>
<link>http://www.jintiankansha.me/column/ultiWL8Axg</link>
<description>混沌巡洋舰 - 今天看啥</description>
<ttl>360</ttl>
<item>
<title>学习如何学习</title>
<link>http://www.jintiankansha.me/t/PpuNvlXASr</link>
<guid isPermaLink="true" >http://www.jintiankansha.me/t/PpuNvlXASr</guid>
<description>&lt;p&gt;&lt;span&gt;学习，是一个看来熟悉，仔细想来，理解和掌握还不够深入的词。&lt;/span&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;从教育心理学角度，学习是指获取知识和经验的过程。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;从行为主义角度，学习是刺激与行为反应建立联结的过程。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;从认知心理学角度，学习是个体在其环境中对事物间关系认知的过程。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;在宏观的系统科学角度，学习是系统与环境交互产生的变化；&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;在微观的神经生物学角度，学习是神经网络中节点间连接的神经可塑性改变。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;而在如今热火朝天的人工智能领域，电脑通过机器学习模拟人脑的学习过程，从而完成相应的认知任务。根据要处理的问题类型，机器学习可以分为判断、预测、分类、聚类等几大问题领域；根据学习的样本是否需要标注预测量的真实值，机器学习可分为监督学习和无监督学习两大类；按照其模拟的人脑认知功能，机器学习可分为计算机视觉和图像识别（图像&lt;/span&gt;/&lt;span&gt;视频信息）、自然语言处理和语音识别（声波&lt;/span&gt;/&lt;span&gt;语音&lt;/span&gt;/&lt;span&gt;文字语言信息）、机器人操作行为几个大类；而根据其算法的核心原理，则可分为深度学习、强化学习、迁移学习、元学习等。&lt;/span&gt;&lt;/p&gt;


&lt;p&gt;&lt;span&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.5756676557863502&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcewI0VbWOXg0f7xEvQwP72u2c4oibia7J1190mOxKyqMj1xJHvh7GNPFaS8AM3OZd5JF7tTcNXCBjPQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;337&quot; /&gt;&lt;/span&gt;&lt;/p&gt;


&lt;p&gt;&lt;span&gt;有趣的是，这些算法的核心原理，又来源于人本身认知过程中的学习机制。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;比如深读学习的基础人工神经网络，就是模仿人脑中神经元与神经元间联结形成区域神经网络而来。在图像处理领域，人工神经网络模仿了人脑的视觉皮层对视觉信息的层次处理模式，即初级视觉皮层处理视神经投射过来的原始视觉图像信息，次级视觉皮层接收初级视觉皮层传递过来的信息，每一层提取不同的信息进行加工，最终整合形成视知觉。使用激活函数作为神经元，进而构建层层传递处理信息的人工神经网络，并根据网络的层次结构方向不同，分为卷积神经网络、循环神经网络等多种人工神经网络算法结构。而深度学习，其实就是基于大规模并行数据分析构建的多层级人工神经网络。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.7731958762886598&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcewI0VbWOXg0f7xEvQwP72uL7PTDcMSutK4YRDN9sdZbgSBw67AxUI1eL5vT5C690WJjctH7ymETQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;291&quot; /&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;强化学习，从宏观行为学角度，模仿的是条件反射学习现象；从微观神经生物学角度，模仿的是人脑神经环路中的奖励环路，而从系统科学角度，来源于“有效的系统控制基于及时有力的反馈”，可见，殊途同归。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.6376518218623481&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcewI0VbWOXg0f7xEvQwP72uKPMK7SyhFB9RjGIZSv1r7owiaNoxOsQkmSC2mYHOvxiaG5JlB2k7OT5w/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;494&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;在读论文时，我觉得很有意思的是，&lt;/span&gt;function&lt;span&gt;这个词，在神经科学里指的是功能，而在计算机领域指的是函数。其实有时候，功能，确实也可理解为函数。函数有输入有输出，呼吸功能同样有输入氧气，有输出二氧化碳。函数有内在的结构和算法，呼吸功能同样有其对应的肺泡支气管等结构，有血&lt;/span&gt;-&lt;span&gt;气交换等生理机制的算法。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;同理，在强化学习中，其马尔科夫决策过程包含一个环境状态集&lt;/span&gt;S&lt;span&gt;，系统行为集合&lt;/span&gt;A&lt;span&gt;，奖励函数&lt;/span&gt;R&lt;span&gt;和状态转移函数&lt;/span&gt;P&lt;span&gt;。而本身，在我们日常的学习过程中，也存在各种强化学习的形式。比如别人是环境&lt;/span&gt;S&lt;span&gt;，对别人说甜言蜜语是系统行为&lt;/span&gt;A&lt;span&gt;，说了甜言蜜语后别人的笑脸是奖励函数&lt;/span&gt;R&lt;span&gt;，此时我们接收到奖励，感觉心情更好，从而感觉环境（别人）对我们更友好，是状态转移函数&lt;/span&gt;P&lt;span&gt;。同理，也可把&lt;/span&gt;A&lt;span&gt;换成考试考高分，&lt;/span&gt;R&lt;span&gt;换成家长的表扬。&lt;/span&gt;&lt;/p&gt;
&lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;&gt;&lt;/ins&gt; 
&lt;p&gt;&lt;span&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.5555555555555556&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcewI0VbWOXg0f7xEvQwP72uKZzpmY9EDylohTyN81lRG2DcO4Mwibw0CISiaKVUPSiaCeZ1ekkVQMtZQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1080&quot; /&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;更有意思的是，&lt;strong&gt;基于动机的强化学习，引入了动机信号，从而实现更具自适应和多任务学习潜能的算法&lt;/strong&gt;；而&lt;strong&gt;在心理学中&lt;/strong&gt;，我们经常说的是，觉知你内在的需求，&lt;strong&gt;将你内心的动机“我要”作为你学习的动力&lt;/strong&gt;，基于好奇心、兴趣等内在的动力，比出于考试的排名、别人的表扬而学习，&lt;strong&gt;能学得更好，走得更远，也更能够承受压力&lt;/strong&gt;。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;再比如迁移学习，是将在其他任务中训练好的模型迁移到新的学习任务。而我们在知识学习的过程，也通常会通过调用旧的知识来理解新的知识，就比如我在学习机器学习这块的知识，就大量用了我在医学学习和脑科学研究中获得的系统生理功能机制、反馈调节、神经解剖、神经电生理、认知心理等方面涉及人脑智能的知识，来理解人工智能。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-ratio=&quot;0.80078125&quot; data-s=&quot;300,640&quot; data-type=&quot;jpeg&quot; data-w=&quot;1280&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/OJSpMjUE1PetSQNQ5MoQK1j20oCTgpFibLtJe9jERbot619jJ9saw6HNvfOXEiaR2SIWJCfeeNdoqibtwmiahDyOkQ/640?wx_fmt=jpeg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;以及元学习。因为这周上课刚给我的学生们讲了，学习如何学习。我告诉我的学生，我们&lt;strong&gt;在学习过程中&lt;/strong&gt;，比如做微积分的题，或者是做英文阅读理解，又或者是完成设计作业等学习任务时，&lt;strong&gt;不仅要关注我们的学习内容，还要关注我们的学习过程。&lt;/strong&gt;看下自己在学习过程中，更喜欢处理什么样的信息，是对数字更敏感，还是对文字更亲切。反思下我们学习的动机，是单纯因为有用，还是能从中感受到学习的乐趣，感受到学到知识的满足感。回头看下我们学习的过程，能集中注意力多长时间，怎么安排整个学习计划会更高效，我们是怎么将一个学习项目分解为多个子任务的。对这些学习过程的反思，就是磨刀不误砍柴工，优化和改进学习过程，不仅让我们学习更高效，也让我们更喜欢学习，得到更多的成长。&lt;/span&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;而在&lt;strong&gt;元学习中，其算法关注的是如何根据反馈优化学习过程参数&lt;/strong&gt;。在这一问题中，&lt;/span&gt;&lt;strong&gt;&lt;span&gt;运用梯度下降法对学习过程参数进行迭代，成为了与模型无关的元学习（&lt;/span&gt;Model-Agnostic Meta-learning&lt;span&gt;）的算法核心。&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;而我们在课堂教学中，教育学生学习如何学习的部分，就特别强调了分解学习任务的重要性，也就是说，给自己的学习难度设定一个合适的梯度。又是一个同词异意，哈哈！&lt;strong&gt;在元学习中，梯度是微积分中计算函数曲线方向变化率的表示向量；而在认知心理学中，梯度指的是学习目标间的难度距离&lt;/strong&gt;。更进一步说，正如维果茨基的&lt;/span&gt;“&lt;span&gt;最近发展区&lt;/span&gt;”&lt;span&gt;理论，选择在合适梯度范围的知识内容作为学习目标，可以用更少的学习成本取得更好的学习效果。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.5278219395866455&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_gif/dcEP2tDMibcewI0VbWOXg0f7xEvQwP72uiblFWtC4u4NL6cjwNRIIAO0KfBytRINZicicEAVyk7fSxuH5BX5LPx5Bg/640?wx_fmt=gif&quot; data-type=&quot;gif&quot; data-w=&quot;1258&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;该图展示OpenAI 提出的 meta-learning shared hierarchies（共享层次的元学习，MLSH），能学到层次化的策略，其中的主策略可以在一系列子策略中进行切换。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt; &lt;br /&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;人工智能与人脑智能的研究每天都有新的发展，人工智能在各个行业领域大显身手的同时，其对人脑智能的抽象表征，极大地简化了人脑认知生理的抽象描述。相信不久的将来，计算机建模能够模拟更高级的人脑功能，对精神症状进行更精细的计算机模拟，从而帮助人类更好的理解自身，并进一步促进心理治疗和精神疾病康复的发展。&lt;/span&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;参考文献主要是史忠植的《心智计算》，&lt;/span&gt;Michael Negnevitsky&lt;span&gt;的《人工智能智能系统指南》，汤晓鸥和陈玉琨主编的《人工智能基础（高中版）》以及&lt;/span&gt;Chelsea Finn2018&lt;span&gt;和&lt;/span&gt;2017&lt;span&gt;关于&lt;/span&gt;MAML&lt;span&gt;的论文。高中那个教程对于算法小白来说真的非常友好，《心智计算》对于有心理学背景的人来说，比从算法逻辑推导的《统计机器学习》真的友好很多。图片自己做的。如有错漏，欢迎指正。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;（本文作者为医学博士，脑科学研究者，感兴趣者欢迎加微信qiahaohexin与作者交流）&lt;/p&gt;

&lt;p&gt;相关阅读&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651384340&amp;amp;idx=1&amp;amp;sn=9d9a341777f1ffd2fb492df38df75736&amp;amp;chksm=84f3c455b3844d43cab9b2caded3e7cef2053775aca2574f4290395accba33d603f91cbba0af&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-itemshowtype=&quot;0&quot; data-linktype=&quot;2&quot;&gt;强化学习理解的三重境界&lt;/a&gt;&lt;br /&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651384302&amp;amp;idx=1&amp;amp;sn=740a7b8cd2ca65d84bfb5b177c2da3c2&amp;amp;chksm=84f3c7afb3844eb9a687340662498c7a664f54c9edf568e444ad866fba18c464f07f703330d5&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-itemshowtype=&quot;0&quot; data-linktype=&quot;2&quot;&gt;模拟人类思维的机器学习算法&lt;/a&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;查看作者更多好文，关注本文来自作者的个人公众号：&lt;/span&gt;&lt;span&gt;Dr.馨 &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;下面是作者的俩篇文&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;&gt;&lt;/ins&gt; &lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651381023&amp;amp;idx=1&amp;amp;sn=dbfa1ab7676451d87f212221fdb317b2&amp;amp;chksm=84f3f35eb3847a4853682158e17c7ec5bddd15820ff4058a5927d878c0943a36608a51a9a8d6&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-itemshowtype=&quot;0&quot; data-linktype=&quot;2&quot;&gt;关系&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651380853&amp;amp;idx=1&amp;amp;sn=7c551ef938ccc41ff13719e6407d4eb1&amp;amp;chksm=84f3f234b3847b221368fc84e2f84f7aa734e16e6e754248eeaa7e5c4931057cfaf3523c6a86&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-itemshowtype=&quot;0&quot; data-linktype=&quot;2&quot;&gt;&lt;span&gt;别听牛人吹苦逼，好好学习人家怎么解决问题&lt;/span&gt;&lt;/a&gt;&lt;br /&gt;&lt;/p&gt;
</description>
<pubDate>Sat, 18 May 2019 19:53:29 +0000</pubDate>
<dc:language>zh-CN</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.jintiankansha.me/t/PpuNvlXASr</dc:identifier>
</item>
<item>
<title>《Deep Medicine》读书笔记</title>
<link>http://www.jintiankansha.me/t/ccVOB7UQGV</link>
<guid isPermaLink="true" >http://www.jintiankansha.me/t/ccVOB7UQGV</guid>
<description>&lt;p&gt;&lt;span&gt;&lt;span&gt;不管中国还是美国，求医问药都是麻烦多多也机遇多多。当前医学面临那些问题，对理想的医学应该是怎样的，我们每个人都有自己的看法。今天介绍的这本书将帮你梳理对上述的俩个问题的思考。《&lt;/span&gt;Deep Medicine&lt;span&gt;》这本书今年&lt;/span&gt;&lt;span&gt;4&lt;/span&gt;&lt;span&gt;月在&lt;/span&gt;&lt;span&gt;Nature&lt;/span&gt;&lt;span&gt;和&lt;/span&gt;&lt;span&gt;Science&lt;/span&gt;&lt;span&gt;俩本杂志都有专门的文章推荐，书的作者是美国的网红医生，写过一系列医学相关的科普著作。在他最新的这本书中，作者回答&lt;/span&gt;&lt;span&gt;AI&lt;/span&gt;&lt;span&gt;技术的进步将如何改变医学。这本书的内容全面，引用充分，对&lt;/span&gt;&lt;span&gt;AI+&lt;/span&gt;&lt;span&gt;医学相关的创业和投资从业者有参考作用，可以从中看到全球有哪些正在探索的方向和初创企业，他们做到了什么程度，有那些可以借鉴的商业模式。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;1.5448916408668731&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcficr5vFeEAeN9BAXfPyia82v13qdCuvrjibu7b5J4WsibSO3g8cmZkUjgsbICK7L641dUlnAhia0u0XcQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;323&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt; &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;该书将深度医学分为三个部分，分别有深度的表型数据，深度神经网络的分析，更深的同情。先说第一点，身体的复杂性是宇宙间造物的极致，当身体出了问题，我们为了查出病源，需要追根究底，这就需要从出生以来所有的数据，各种各样的体检数据，可穿戴设备的持续监控，社交网络上的输入输出。利用这些数据，深度学习的模型最终要实现的是针对每个人，提供个性化的预防疾病方案并通过助推（nudge）来督促你执行。而深度医学的第三个要点是加深医疗从业者与患者的共情，通过技术进步，为医生节省出时间，从而让医生能够更多的和患者进行面对面的交流，让医生能够像对待一个活生生的人，而不是流水线上的一件产品式的对待患者。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt; &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-ratio=&quot;0.3367571533382245&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcficr5vFeEAeN9BAXfPyia82v3t5WPdFIt1EdalHyaLsia5Fc7IiaUGlwof1icvuibbWDibLkia3zIOYDmlNQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1363&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;书中给出的这个未来医学的理想图景，针对当前医学面临的几大问题，最显而易见的是误诊漏诊导致的医疗事故和医患矛盾与医疗资源浪费，好的医生就那么多，而即使最优秀的医生，也会有发挥不稳定的时候。深度医学中深度模型的部分，要解决的是这个问题，解法是将医生的每一项具体任务外包给专业化的AI模型，&lt;span&gt;AI&lt;/span&gt;适合去在一个细分领域做到超越人类的水平，例如解读放射科的影像，在医疗论文数据库中搜寻相近病例，&lt;span&gt;AI&lt;/span&gt;还可以提升特定任务的效率，例如减少医学影像检测所需的时间和带来辐射水平。外包的任务还可以是记录医生和患者的谈话，通过语音识别，让医生和患者的谈话能够自动变成电子病历，通过聊天机器人让患者能够随时可以咨询病情。效率低下的问题，就要通过细致的分工来解决。人机协作，是社会大分工必然的下一步，当分工越来越细，只从事一个细分任务的就应该是机器而不是人，而人所从事的整合与协调的工作则越来越重要。&lt;/span&gt;&lt;br /&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt; &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;当代医学的第二个问题是预防晚于治疗，人总是等到有病了才想起健康的重要，总是被各类自相矛盾的养生帖轰炸。针对这个问题，作者给出的解决方案总的方向没有错，可书中举出的例子，例如创业公司，具体的解决方案，却由于作者本身的临床背景，显得不如前一部分那么靠谱。但客观的来讲，涉及到预防，解决方案成熟且广泛落地的难度，远远大于临床相关的场景，不止需要更多的数据量，与隐私的保护的伦理问题也更为敏感，因此该领域有的大多是炒作概念，也不为奇。收集从小到大所有和人相关的数据，据此确定每个人的养生方案，这个梦想的难度在于任务的分解不是像临床那样是自上而下的。临床相关的任务分工，可以在一个个细分领域里逐个寻找突破，但要做到这么多来源数据的整合与分析，需要的不止是方法的突破，商业模式的重构，立法与观念的改变，无法日拱一卒这样渐进的方式，只能通过先在某一个概念上做出黑科技，通过一个个火种，点燃对阵你整个领域的热情。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt; &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;当代医学的第三个问题是医患之间信任的缺少，在美国表现为海量的医疗诉讼，在国内表现为医闹。但缺少互信是表，医患之间交流的困难才是真正的病因。当医生将重复性的工作交给机器，就能花更多的时间和患者交流，但这需要模型不止是更全面更准确且更新及时的诊断，还能够对诊断的结果给出解释，从而辅助医生和患者沟通，需要健康管理类的app做好隐私保护，同时还能方便的将结果导出。除了上述硬件上的改变，还需要在医疗从业者的选择和培训中增加对共情能力的关注。当&lt;span&gt;AI&lt;/span&gt;能够通过医师职业资格考试之后，我们要选择那些天生擅长沟通的人去当医生，而不是按照工程师的标准选择不善言辞者。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt; &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;span&gt;整体来看，这本书虽然其中列举的多是美国医疗系统的数据及其问题，不一定能代表中国国情，但通过阅读，能够系统化的了解学界与产业界针对AI+医疗提供了哪些解决方案，取得了什么样的突破。书中提出的深度医学的理想，更是契合医学同病不同方，不治已病治未病的智慧。对于医疗相关行业的从业者，可以从中了解未来医学的大势所趋，对于AI感兴趣的读者，也可以从中了解AI改变世界的具体场景。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;&lt;span&gt;更多阅读&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651384346&amp;amp;idx=1&amp;amp;sn=81625215fadd3b9e516d52163befdbbb&amp;amp;chksm=84f3c45bb3844d4d5e98ae6cd3c7d9f23ce4eb4371c40dccdb5c9dad90e55ee75a4e3a9073ed&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-itemshowtype=&quot;0&quot; data-linktype=&quot;2&quot;&gt;《大脑的故事》-六个关键词串起对大脑的系统性认识&lt;/a&gt;&lt;br /&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651384006&amp;amp;idx=1&amp;amp;sn=6a0e841a32aa1163f12b964ca447ff77&amp;amp;chksm=84f3c687b3844f91f69504a5f4ee1e7714e2a759f791843336909c7ce2c7bbd7e054af0c92c3&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-itemshowtype=&quot;0&quot; data-linktype=&quot;2&quot;&gt;深度学习在医疗与生物界的应用概述&lt;/a&gt;&lt;br /&gt;&lt;/span&gt;&lt;/p&gt;

</description>
<pubDate>Fri, 10 May 2019 12:32:34 +0000</pubDate>
<dc:language>zh-CN</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.jintiankansha.me/t/ccVOB7UQGV</dc:identifier>
</item>
<item>
<title>随机网络中的智慧</title>
<link>http://www.jintiankansha.me/t/VG3u69CoGB</link>
<guid isPermaLink="true" >http://www.jintiankansha.me/t/VG3u69CoGB</guid>
<description>&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;网络是从人类智能到深度学习的基础，可能所有人都认为只有训练好的具有特定结构的网络才能具有功能，如同生物的功能是由结构决定的， 精巧设计的结构可以产生特定的功能， 大概高中生物老师就给我们灌输了这个观念。 而在网络的世界， 这就意味着你要某个功能，就要先产生那样的结构，比如一个具有特定结构的CNN。&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;然而， 可能你不知道的是， 一个随机连接的网络也具有功能。 什么叫随机啊？ 就是任意单元和单元之间连接与否是随机的， 看起来很混乱，它们居然能做事？ 不仅如此， 它能做的事情还很酷炫：比如， 预测火焰的形状演化。&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;注：火焰的跳动，是一个我们常说的混沌系统， 所谓难以用常规方法预测， 确可以一定程度被随机网络征服，这是一个以复杂对抗复杂，用无常应对无常的经典例子。&lt;/p&gt;
&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.5615384615384615&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcewMUIibIuV7JdontKCkatxCwjxNiat12Ber6FWgHTw70o1ib9sGxPaUWa4OqqzOeiax2iacJ4u5gENmyg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;520&quot; width=&quot;520&quot;/&gt;&lt;p&gt;Machine Learning&amp;amp;amp;amp;#39;s &amp;amp;amp;amp;#39;Amazing&amp;amp;amp;amp;#39; Ability to Predict Chaos&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;任何一个网络的连接都可以由一个矩阵来刻画， 刻画随机网络单元和单元之间的连接就是随机矩阵。&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; center=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;&lt;span&gt;&lt;strong&gt;1）什么是随机矩阵 ？&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;可能每个人都很清楚矩阵， 但是提到随机矩阵，就不是每个人都清楚了。 事实上， 随机矩阵是研究所有和网络有关的科学技术， 从机器学习到复杂系统， 极为重要的工具。 那么我们就一层层拨开随机矩阵的神秘面纱。&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;首先， 如果矩阵里每行每列的元素都从独立分布的高斯里抽样，那个， 这样的一个方阵称为随机矩阵。&lt;/p&gt;
&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.26666666666666666&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcewMUIibIuV7JdontKCkatxC8McjJVpeuZbYZ99fRzG8iaQ3wPFrKRgYPOtboFZMrO8q8PUUFhN9eKQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;720&quot; width=&quot;904&quot;/&gt;&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;看起来没什么乱用对吧？ 我们还是直接进入随机矩阵的数学物理本质： 事实上， 随机矩阵用于描述一个动力系统内不同元素间的相互作用， 具体的例子比如：&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;1， 描述一个马尔可夫过程的概率迁移矩阵： 矩阵可以用来描述一个马尔可夫过程的迁移矩阵， 那么该矩阵就定义了一个随机连接的图网络， 从i点到j点的迁移概率由对应的矩阵元素表达（因此每一行的和需要为1）。&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;2， 描述一个动力系统里任意的n个元素和n个元素的相互作用关系， 这n个元素， 既可以是人工或生物神经网络里的神经元， 也可以是生态系统里的各个物种， 或金融市场相互作用的交易者， 我们刚刚说的预测混沌的网络就符合这个类型。 此处随机矩阵就是随机网络的数学表示&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; center=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;&lt;strong&gt;&lt;span&gt;2）随机矩阵是怎样刻画一个动力系统的&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;这里， 我们从最简单的系统-二维的线性动力学系统开始， 二维的动力系统定义为：&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.17567567567567569&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_svg/hNWCQ9bibbzFWeywyrPJ78CTicqXAeOgPnF1ia9ib42miafRnAJLIbibIic2m4yt0P3oSjm9DZCB43s85xgsyY8RPsEMtDHM7avvK32/640?wx_fmt=svg&quot; data-type=&quot;svg&quot; data-w=&quot;148&quot;/&gt;&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.1780821917808219&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_svg/hNWCQ9bibbzFWeywyrPJ78CTicqXAeOgPnowJGOKPTyrK4ic68XPZBGq7z9RBj4YldHQByhk95mZgoFGHzVDRrzffibib3F2d9UHd/640?wx_fmt=svg&quot; data-type=&quot;svg&quot; data-w=&quot;146&quot;/&gt;&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;可以由一个a，b，c，d组成的二维矩阵（雅可比矩阵）刻画。 这个两两作用的系统在自然界比比皆是， 比如著名的猎手-猎物方程。&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;对于任何动力学系统， 我们都要先抓住它的定点， 而整个系统的性质， 由定点向外周扩散迎刃而解。 那么这个简单的线性系统有一个显而易见的定点就是x=0， y=0.&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;定点的作用就像一个巨大的吸引中心， 系统的演化无论多么复杂， 都是以某种形式围绕它展开。 这些展开形式可以被概括到一个叫相图的二维平面里， 这个平面是由二维系统的两个变量为坐标轴， 概括了系统从任何初始状态（x，y）开始演化， 它的未来发展轨迹。&lt;/p&gt;
&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.6458036984352774&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcewMUIibIuV7JdontKCkatxCLpIPMCcO48JalHajRLhT6yJs5FFAvKXryicGpqkIlNV8t4TgoHFK9Lw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;703&quot; width=&quot;703&quot;/&gt;&lt;p&gt;相图的做法非常简单， 只需要对任意状态求解其变化趋势(dx/dt, dy/dt)并在平面上用箭头表达， 我们就可以看到整个系统从任意点开始的未来走势。&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;有了定点后， 系统具体的演化方法则由它的雅可比矩阵决定。 在这里雅可比矩阵也就是abcd所确定的连接矩阵&lt;img class=&quot;rich_pages&quot; data-ratio=&quot;0.8115942028985508&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcewMUIibIuV7JdontKCkatxCKAUmF6GAyNmomkLGX8SVq0y4UFoChXoRZDC4hlxAV59copOqn0uvIA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;69&quot; helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; sans=&quot;&quot; gb=&quot;&quot; yahei=&quot;&quot; ui=&quot;&quot; arial=&quot;&quot; sans-serif=&quot;&quot;/&gt;这个矩阵里的各个元素，它将确定，随着时间，系统将去向何方。 我们可以按照特征矩阵的行列式A = ad -bc 以及迹（trace） a +d 作为坐标轴对系统分类。为什么是这两个东西， 你想一下， 矩阵本身由特征值决定， 在特征分解后，A代表特征值的乘积，trace是特征值的和， 这两个量体现了特征值的性质。 矩阵的特征值是一个复数， 对应复平面上的两个点。 这两个点的几何性质由刚刚说的行列式和迹决定。&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;数学的好处在于一次得到所有的可能性。 一切可能皆由定点展开， 这些情况按照定点稳定与否（演化是趋紧还是远离它）， 以及趋于（或远离）定点的方式展开。&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;我们通常用poincare diagram 来表达所有情况。 从左向右， 定点从稳定到不稳定（特征值由负到正），从下到上， 趋于或离开定点的方式由线性变换到旋转（特征值由实入虚， 此处以delta&lt;img class=&quot;&quot; data-ratio=&quot;0.22807017543859648&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_svg/hNWCQ9bibbzFWeywyrPJ78CTicqXAeOgPn0lfXOYcMnxjePpHrslD4IBgDFCypck09y8BmxcFPISX9GYICMLdSWQxTrgkgGCHI/640?wx_fmt=svg&quot; data-type=&quot;svg&quot; data-w=&quot;114&quot;/&gt; 为界）。方程你可以把整个解析解写出来&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;&lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;/&gt; &lt;img class=&quot;&quot; data-ratio=&quot;0.11764705882352941&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_svg/hNWCQ9bibbzFWeywyrPJ78CTicqXAeOgPnpHeZicycd3gUJqV0lQUgbRFkj75w6wsms7IPciavzOPeTuV5hCGCA7Y9u5Sibx8lJQ3/640?wx_fmt=svg&quot; data-type=&quot;svg&quot; data-w=&quot;272&quot;/&gt; X=（x，y）&lt;/p&gt;
&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.6486111111111111&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcewMUIibIuV7JdontKCkatxClGz8yibVYIEWOQ8sYH3ibHGO37cI3U3sJvKlMdjl7OxBsMKcnGGYRd8w/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;720&quot; width=&quot;720&quot;/&gt;&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;由如上的两个坐标轴和一个抛物线，我们把平面分割成了6个区域。 你只需要记住临界态的性质， 中间区域及其过渡。 抓住这个平面，就抓住了所有的二维线性动力系统。&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;y轴上半 - 此处特征值为纯虚数， 实部为0， 我们既不趋近也不远离， 这也就是周期运动， 或被称为极限环。 系统围绕定点做圆周运动，是稳定和不稳定的过度状态。 典型例子如二维谐振子 - 理解各种复杂的物理系统的毕达哥拉斯之剑。 加入一定非线性形式我们得到猎手-猎物方程， 狼和羊， 资本和劳动力矛盾下的振动平衡。 自然界还是人类现象中振动如此普遍， 背后正是这类动力关系的体现。&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.7513888888888889&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcewMUIibIuV7JdontKCkatxCE1mPUVMIS7t8P4tdgNPiak0C0qkfJRosgxqAuFW7W0cGPMa5uOfPexA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;720&quot; width=&quot;720&quot;/&gt;&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;X轴下半和det中间区域： 稳定定点， 代表趋势所致， 稳定定点可以预测事物的一般走势（稳定不变的平衡态，任何远离它的阴谋都将破灭），因为在它的管辖区域里， 无论如何折腾， 都回回到它， 因此稳定定点也可以用来存储信息。&lt;/p&gt;
&lt;img class=&quot;content_image lazy&quot; data-ratio=&quot;0.5222222222222223&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcewMUIibIuV7JdontKCkatxCJ44S6z9NENNpS3SzWW0gUjULgTXxDHZ1lxSAwypENapLL0JAO1IW9A/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;360&quot; width=&quot;360&quot;/&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;Y轴下半及整个下半平面：鞍点（Saddle）与上半的区别在于运动方式， 刚刚说的转动变成线性， 然而依然是从稳定到不稳定的临界，此处的效果是从一个特征向量方向你趋于定点（稳定），而另一个方向则远离（不稳定）。 这样的系统可以表示神经网络的决策或分类： 从一个方向得到的结果是A， 从另一些方向得到的结果是B，这就是天然的分类器。鞍点也用来介导一个动力系统的相变， 从一个方向你达到定点， 再在另外一个方向分离， 例如所有的热恋到失恋的过程。&lt;/p&gt;
&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;1&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcewMUIibIuV7JdontKCkatxCol66Ox1rBtdqhxjVbNYpRQnZ9kcm07I49ZvmhWNbsoTxWrgWxrqMpg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;720&quot; width=&quot;1200&quot;/&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;X轴： 刚刚那个图一个更加特殊的情况是X轴上（det 为0）的那些解，这条线的数学含义是我们某个特征值为0的情况（此时矩阵的迹为0）， 啥叫特征值为0？ 它意味着只要我们在这个为0的特征值所对应的特征向量，我们就有 &lt;img class=&quot;&quot; data-ratio=&quot;0.16883116883116883&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_svg/hNWCQ9bibbzFWeywyrPJ78CTicqXAeOgPnS2iaPDxw1nk7d9THKKpjIAry6HnZeicV7bkjqfQCF8Iib56aOjBOWjJdK5HXhmDACzC/640?wx_fmt=svg&quot; data-type=&quot;svg&quot; data-w=&quot;154&quot;/&gt; ，也就是所有解都是定点！ 而它导致的结果是所谓的线性吸引子， 定点不在是一点而是一条线（line attractor）。 我们会看到这个解在众多的问题里意义重大，比如神经编码 。这是因为线性吸引子是路径依赖的代言人， 你从不同的起点出发， 会停留在不同的位置上， 这就好像把初刻的历史凝固了下来，因为可以比单个稳定定点编码更复杂的信息-甚至是某种抽象关系。&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;下图表示一个更一般的非线性系统里的line attractor 。&lt;/p&gt;
&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.8024193548387096&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcewMUIibIuV7JdontKCkatxCdiboiaV3ic2pqcPDtHw5KoPsLV9KiaTyt1b9WHpaU8G7m7s6eFeiaerjFIQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;496&quot; width=&quot;496&quot;/&gt;&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;更多信息请见&lt;span class=&quot;visible&quot;&gt;def.fe.up.pt/dynamics/l&lt;/span&gt;&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; center=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;&lt;strong&gt;&lt;span&gt;3）随机矩阵和动力系统的联系&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;理解了二维系统， 你可以抓住它内在本质的东西， 然后一级级向高维延申。 我们回到我们的主题-随机矩阵， 随机矩阵刻画一个高维动力系统， 其不同单元间的连接是随机的。 如果我们假定高维系统依然是线性的， 那么它一般写成：&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.15028901734104047&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_svg/hNWCQ9bibbzFWeywyrPJ78CTicqXAeOgPnanMX88UT29ByXN3lcaycF9B8T9oC6HLC224Uv4hmegjGicLh08fqxfobB3JeEAob9/640?wx_fmt=svg&quot; data-type=&quot;svg&quot; data-w=&quot;173&quot;/&gt;&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;A是一个nxn的方阵， 由刚刚说的随机数确定。&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;首先， 寻找定点， &lt;img class=&quot;&quot; data-ratio=&quot;0.1590909090909091&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_svg/hNWCQ9bibbzFWeywyrPJ78CTicqXAeOgPnIUvq9flCPzXEXNH9pVebkwZIZ086vQuegLN74k3wPQgEWSkgCibZszD0cBdzB5w0l/640?wx_fmt=svg&quot; data-type=&quot;svg&quot; data-w=&quot;132&quot;/&gt; 这样的解有一个是肯定的，就是 &lt;img class=&quot;&quot; data-ratio=&quot;0.35714285714285715&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_svg/hNWCQ9bibbzFWeywyrPJ78CTicqXAeOgPnbiaeJw22g2oWBCovBJryiaYgfnrIo0icqq0uO2hNEW7wIUDX9jFY1Dxg3AtLHGaPsdR/640?wx_fmt=svg&quot; data-type=&quot;svg&quot; data-w=&quot;56&quot;/&gt;&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;其余性质将由矩阵的特征值和特征向量决定。 我们对连接矩阵A进行特征分解， 得到一系列的特征值和特征向量， 我首先让你猜一下如果你把它的特征值和特征向量在复平面上展开， 它们会长成什么样呢？&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;你依然从二维线性系统， 一个2x2的方阵入手。 这个矩阵的特征值如果你画在复平面上长什么样呢？ 这一类矩阵有两个最特别的情形， 一个对角线为0实对称 &lt;img class=&quot;&quot; data-ratio=&quot;0.3333333333333333&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_svg/hNWCQ9bibbzFWeywyrPJ78CTicqXAeOgPn5qFcSoict0B4Lgvxdicndsf6mIgozyLtNXsMYHz7qPDHSaucBQHscN4f0zrssdUy9r/640?wx_fmt=svg&quot; data-type=&quot;svg&quot; data-w=&quot;72&quot;/&gt; ， 一个对角线为0的反对称 &lt;img class=&quot;&quot; data-ratio=&quot;0.29545454545454547&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_svg/hNWCQ9bibbzFWeywyrPJ78CTicqXAeOgPnqoOjdvicdmlLqWWR0gc3FRZwHh9DGGPUjwhE73XhFJZb9ibBoowWq0BAiafxKiaECblL/640?wx_fmt=svg&quot; data-type=&quot;svg&quot; data-w=&quot;88&quot;/&gt;&lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;/&gt;   , 对于情况一我们得到的两个特征值是-a和a（假定非对角元素为a）， 对于情况2我们有-ai和ai也就是把它们换到虚轴上（这正是刚刚说的谐振子解）。 由此你进行一个类推， 如果我的矩阵的元素不在是这两个特殊情况而是随机的， 我只保证这些矩阵元素每个的期望均是0， 然后你要求出特征值的分布会是什么样的？ 刚刚的解一个是沿着实轴相对原点对称， 一个是沿着虚轴相对原点对称。 如果综合起来呢？ 在实轴和虚轴组成的复平面上， 我们会得到任意方向沿着原点对称的一组点， 从而组成最完美的一个图形- 也就是， 一个圆！ 具体求解请见论文（Introduction to Random Matrices-Theory and Practice）。&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;好了， 那么维度增加呢？ 当你的矩阵元素越来越多， 这个时候我的高维矩阵的特征值个数将等于我们的矩阵维数， 当这个数字达到一定程度， 我们任意一个矩阵的特征值都将逼近刚刚说的那个所有可能二维矩阵的特征分布， 也就是一个圆，至少非常接近！&lt;/p&gt;
&lt;img class=&quot;content_image lazy&quot; data-ratio=&quot;1.0338345864661653&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcewMUIibIuV7JdontKCkatxC4j1S0MTDia6yp4ibPqT8UsxOG04bkzt2XTlrtRkoHcwDb8eVKHKWN0Rg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;266&quot; width=&quot;266&quot;/&gt;&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;好了， 从这里我们可以立刻领悟到的是什么？ 特征向量和特征值携带所有矩阵的信息， 那么所有的随机矩阵的性质是类似的。这里只有一个东西是变化的， 就是圆的半径。 这个量有什么意义呢？还回到二维情况进行对比， 在我们刚刚的情况里 ， 矩阵的trace从小于0到大于0引起整个系统从稳定定点过度到一个不稳定定点， 而此处， 这个圆的半径， 正是起到类似的作用。&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;我们把整个动力方程写成：&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.1477832512315271&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_svg/hNWCQ9bibbzFWeywyrPJ78CTicqXAeOgPnriapf3Nw8S5f6Dtiat6gejb886Bpno7WU8Hia4gzLgHrEDJrbt8SvibQfvW2QKdpcM8n/640?wx_fmt=svg&quot; data-type=&quot;svg&quot; data-w=&quot;203&quot;/&gt;&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;那么矩阵A-I的特征值正负将决定整个系统的稳定性， 这里的情况是如何呢？ 记得刚刚说的我的矩阵A元素都符合是一个平均值为0的高斯分布吗？ A-I这个矩阵就是一个以-1为中心，以A的特征圆为半径的圆形区域， 如果这个圆的半径小于1， 那个特征值整体在负半平面， 系统会趋于稳定的解0。 而一旦半径大于1，这种稳定性就被打破，在高维的系统里， 当你无法回到定点（或闭合轨迹）， 那么登场的正是我们众所周知的混沌， 高维系统的演化进行永不停止的无序运动。 那么1呢？ 我们说， 这就是混沌和稳定的边缘， 记得在二维的系统里， 这个地方会催生非常多的有趣现象， 比如二维谐振子， 比如线性吸引子， 而这些在高维系统里依然正确， 我们会得到各种各样的复杂多解型， 比如-振动解。 而这正是和网络有关的众多有趣现象， 甚至生命本身， 产生的地点。&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;注：所谓混沌， 事实上是一大类不同动力学现象的统称， 它们的共同特点是从某个无限接近的初始点出发， 未来的轨迹是发散的。 混沌的最简单形式是三维非线性方程的洛伦兹吸引子， 在此情况下事实上我们的轨迹围绕这两个定点做某种“周期”运动， 只是这个周期无限复杂， 因此混沌并非等于失控， 而可以是非常复杂的信息载体。 而混沌也可以普遍的存在于高维的线性系统里。&lt;/p&gt;
&lt;img class=&quot;content_image lazy&quot; data-ratio=&quot;0.749034749034749&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcewMUIibIuV7JdontKCkatxCJFWtc8XaPkhftyiaq6ES61SvNy9iaHexmaVia6hLxUm79Uib71oGDf6Vpg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;259&quot; width=&quot;259&quot;/&gt;&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;我们说， 这个特征谱一来决定稳定性， 而来决定趋于定点的方式。 实数代表线性的推进， 虚数代表振动，具体是哪种方式推进， 则决定于你是否在某个特征值对应的特征向量方向上。 我们知道， 我们是一个高维的线性系统，在这个高维王国里， 光坐标轴就可以建立维数N个， 那么对应的就是N个特征向量方向。 由此决定了我们以不同的初始状态趋近定点， 可能的结果会非常复杂多变，运动模式趋于无限。&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; center=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;&lt;strong&gt;&lt;span&gt;4）基于这种理解我们可以做什么呢？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;1， 预测高维网络的一些基本性质： 虽然我们比较难完全预测高维系统的未来， 但是我们预测其稳定性， 我们看到， 当改变一个网络的一个基本属性， 比如连接强度， 就会让网络从稳定到不稳定，从稳定平衡趋于混沌， 那么对于生态系统和社会这意味着什么呢？ 有人说当系统的元素增加连接增强会使得系统更脆弱 ，更容易失衡， 但这仅是理解之一。 一个趋于稳定平衡的系统也通常没有什么功能。 而混沌本身， 确可以是秩序的载体。&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;2， 在混沌和稳定边缘的高维随机动力系统具有某种全能可塑性， 如果加上一定的非线性， 则可以包含极为丰富的动力学模式， 稳定定点，周期解， 不稳定定点， 混沌， 各类复杂的吸引子， 都可以在这个区域周围出现。这个区域动力学形式已经开始丰富， 又不像完全混沌那样难以控制， 因此是各类学习的最佳区域。&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;3， 制作机器学习工具。 我们说大型的随机网络本身就具备一定的学习能力， 而且在很多学习任务里可以匹配其它特定设计的机器学习模型。 这里一个比较著名的例子就是蓄水池网络。刚刚开始说的预测火焰的例子正是来自这里。&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;蓄水池网络的根基，正是2提到的混沌和稳定的边缘， 再加上非线性的激活函数, 以及外界环境的输入I。这个微小的非线性将把系统的复杂性再推一个高度， 事实上， 一个非线性的二维系统就可以表达多于一个的定点， 而非线性的三维系统就已经可以产生混沌。 一个非线性的高维混沌系统， 其数学复杂度已经接近解析的极限。&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.10358565737051793&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_svg/hNWCQ9bibbzFWeywyrPJ78CTicqXAeOgPnN1nUW53HeoYr2Ry5xUYibXEr3RZKSLlkwcVDyZyt7SLxiciaHNdpZapfjLoBT66Zb4T/640?wx_fmt=svg&quot; data-type=&quot;svg&quot; data-w=&quot;251&quot;/&gt;&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;-这也就是循环神经网络RNN。&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;制作一个蓄水池网络最重要的就是控制刚刚说的特征值的谱半径， 我们要让它处于稳定到混沌的临界状态，也就似乎那个谱半径接近1的状态。 在这个时候， 系统的动力学属性最为复杂，最为丰富。&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;蓄水池网络具有的一种能力是， 如果你给它一个复杂的时间序列输入（I）， 比如股市的变化， 它可以自动的抽取出这种变化背后的独立性因子，并在一定程度模拟出真实过程的动力关系（因为其自身存在足够丰富的动力关系， 以至于非常容易和真实的系统进行匹配）。 听着有点像PCA，但是PCA是线性的不包含时间， 而这里是一个非线性时间依赖的系统， 复杂性不可同日而语。&lt;/p&gt;
&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.4861111111111111&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcewMUIibIuV7JdontKCkatxCcGDiclEtwkrQFBuvibmaOkJ3Lad493AOc4iaWYTBMRPycFgeYDFtgpCAQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;720&quot; width=&quot;1507&quot;/&gt;&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;比如上面这个图， 我们的输入是真实世界一个很复杂的波动曲线（周期解和混沌间的过度）， 事实上多么复杂的波动背后催生它的因素不一定很复杂， 比如洛伦茨吸引子背后就仅仅是一个三维系统。&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;当这个波动输入到蓄水池网络里以后，蓄水池网络可以找寻到这种复杂背后的根基，并对这个信号的发展走势进行预测。&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;蓄水池运算的好处是不需要改变内在连接矩阵A， 我们唯一需要求解的是一个读出, 也就是&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.19117647058823528&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_svg/hNWCQ9bibbzFWeywyrPJ78CTicqXAeOgPngcdiav5ZPr116cgYOiaES2vzAAnC4oE31kKF3dWNGp89vO48GengsvicnalpG3cs12ia/640?wx_fmt=svg&quot; data-type=&quot;svg&quot; data-w=&quot;136&quot;/&gt;&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;就可以对时间序列进行预测, 比如文中开头提到的预测火焰形状的网络， 如下图， 这个过程包含两个阶段，一个是训练，一个是预测， 在训练阶段， RNN的作用事实上相当于一个auto-encoder-自编码器， 它得到一个火焰变化的输入， 通过网络重现这个输入。 而在预测阶段，我们不再有火焰变化的数据，我们直接把RNN输出的结果输入回网络，假设这个网络已经学好了， 那么这个输出就是正确的预测（下图为实际信号（上）于预测信号的比对（下））。 这种预测能力的背后， 正是在训练阶段，RNN高维网络里的某些成分， 抓住了真实系统变化背后的那些核心动因（自编码器的本质即压缩寻找主成分）。&lt;/p&gt;
&lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;/&gt; &lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.24861111111111112&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcewMUIibIuV7JdontKCkatxCx2r1rNtGlqOuBVzZjpKgTxzR5pT9hfp3GeF7QTgBzJ5Uk6PbibHY7zg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;720&quot; width=&quot;1146&quot;/&gt;&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.3472222222222222&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcewMUIibIuV7JdontKCkatxCIjicXAwkE1trAicP38ozM0I53IMCcax5mIfGgMmJUTkWWxhSNDZ3mQIg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;720&quot; width=&quot;1433&quot;/&gt;&lt;p&gt;Model-Free Prediction of Large Spatiotemporally Chaotic Systems from Data: A Reservoir Computing Approach&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;更深刻的学习（对A进行改变）： 我们还可以做什么呢？ 在刚刚讲到的各类复杂的动力学形式里， 我们看到，无论是稳定定点， 极限环，鞍点，还是线性吸引子事实上都是对世界普遍存在的信息流动形式的通用表达。 我们可以用它表达信息的提取和加工， 甚至某种程度的逻辑推理（决策），那么只要我们能够掌握一种学习形式有效的改变这个随机网络的连接，我们就有可能得到我们所需要的任何一种信息加工过程， 用几何语言说就是，在随机网络的周围， 存在着从毫无意义的运动到通用智能的几乎所有可能性， 打开这些可能的过程如同对随机网络进行一个微扰， 而这个微扰通常代表了某种网络和外在环境的耦合过程（学习）， 当网络的动力学在低维映射里包含了真实世界的动力学本身， 通常学习就成功了。&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;无论当下红极一时的鏖战星际争霸的网络，还是从脑电波中解码语言的网络， 无非是一种特殊的RNN（LSTM）加上一定的这种学习的结果。&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;真实世界的各种复杂网络， 从生物基因网络到神经网络，到生态网络或经济关系网络， 或许都是如此从随机网络逐步过渡出来的。 无论是通过学习，还是进化。 这或许可以揭示为什么人和猩猩基因差异没有大的情况下智力确是天壤之别， 以及类似人组成的社会受到地理条件影响的微小差异后引起的社会演化巨大差异。 或许， 这个规律可能揭示所有复杂网络到深度学习背后的本质。&lt;/p&gt;

&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;参考文献：&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;1 Sompolinsky H, Crisanti A, Sommers H J. Chaos in random neural networks[J]. Physical review letters, 1988, 61(3): 259&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;2 Pathak J, Hunt B, Gir&lt;span&gt;van M, et al. Model-free prediction of large spatiotemporally chaotic systems from data: A reservoir computing approach[J]. Physical review letters, 2018, 120(2): 024102.&lt;/span&gt;&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;&lt;span&gt;3 Maass W, Natschläger T, Markram H. Real-time computing without stable states: A new framework for neural computation based on perturbations[J]. Neural computation, 2002, 14(11): 2531-2560.&lt;/span&gt;&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;&lt;span&gt;4 Schrauwen B, Verstraeten D, Van Campenhout J. An overview of reservoir computing: theory, applications and implementations[C]//Proceedings of the 15th european symposium on artificial neural networks. p. 471-482 2007. 2007: 471-482.&lt;/span&gt;&lt;/p&gt;

&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;1.413888888888889&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcewMUIibIuV7JdontKCkatxCicN7RgeDric5XARttic2HBGErVTqBVutDiak5jzibNYgrsZRgQPrLwNGGmg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;720&quot; width=&quot;1080&quot;/&gt;
</description>
<pubDate>Wed, 01 May 2019 23:40:00 +0000</pubDate>
<dc:language>zh-CN</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.jintiankansha.me/t/VG3u69CoGB</dc:identifier>
</item>
</channel>
</rss>