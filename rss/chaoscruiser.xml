<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="css/feed.xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/" xmlns:og="http://ogp.me/ns#">
<channel>
<atom:link rel="self" href="http://192.168.1.4/fivefilters/makefulltextfeed.php?url=feed43.com%2Fchaoscruiser-jtks.xml&amp;max=5&amp;links=preserve&amp;exc=1" />
<atom:link rel="alternate" title="Source URL" href="http://feed43.com/chaoscruiser-jtks.xml" />
<atom:link rel="related" title="Subscribe to feed" href="http://www.subtome.com/#/subscribe?feeds=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed43.com%252Fchaoscruiser-jtks.xml%26max%3D5%26links%3Dpreserve%26exc%3D1&amp;back=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed43.com%252Fchaoscruiser-jtks.xml%26max%3D5%26links%3Dpreserve%26exc%3D1" />
<title>混沌巡洋舰</title>
<link>http://www.jintiankansha.me/column/ultiWL8Axg</link>
<description>混沌巡洋舰 - 今天看啥</description>
<ttl>360</ttl>
<item>
<title>随机网络中的智慧</title>
<link>http://www.jintiankansha.me/t/VG3u69CoGB</link>
<guid isPermaLink="true" >http://www.jintiankansha.me/t/VG3u69CoGB</guid>
<description>&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;网络是从人类智能到深度学习的基础，可能所有人都认为只有训练好的具有特定结构的网络才能具有功能，如同生物的功能是由结构决定的， 精巧设计的结构可以产生特定的功能， 大概高中生物老师就给我们灌输了这个观念。 而在网络的世界， 这就意味着你要某个功能，就要先产生那样的结构，比如一个具有特定结构的CNN。&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;然而， 可能你不知道的是， 一个随机连接的网络也具有功能。 什么叫随机啊？ 就是任意单元和单元之间连接与否是随机的， 看起来很混乱，它们居然能做事？ 不仅如此， 它能做的事情还很酷炫：比如， 预测火焰的形状演化。&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;注：火焰的跳动，是一个我们常说的混沌系统， 所谓难以用常规方法预测， 确可以一定程度被随机网络征服，这是一个以复杂对抗复杂，用无常应对无常的经典例子。&lt;/p&gt;
&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.5615384615384615&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcewMUIibIuV7JdontKCkatxCwjxNiat12Ber6FWgHTw70o1ib9sGxPaUWa4OqqzOeiax2iacJ4u5gENmyg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;520&quot; width=&quot;520&quot;/&gt;&lt;p&gt;Machine Learning&amp;amp;amp;amp;#39;s &amp;amp;amp;amp;#39;Amazing&amp;amp;amp;amp;#39; Ability to Predict Chaos&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;任何一个网络的连接都可以由一个矩阵来刻画， 刻画随机网络单元和单元之间的连接就是随机矩阵。&lt;/p&gt;

</description>
<pubDate>Wed, 01 May 2019 23:40:00 +0000</pubDate>
<dc:language>zh-CN</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.jintiankansha.me/t/VG3u69CoGB</dc:identifier>
</item>
<item>
<title>随机网络中的智慧</title>
<link>http://www.jintiankansha.me/t/JIJMBiPkwj</link>
<guid isPermaLink="true" >http://www.jintiankansha.me/t/JIJMBiPkwj</guid>
<description>&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;网络是从人类智能到深度学习的基础，可能所有人都认为只有训练好的具有特定结构的网络才能具有功能，如同生物的功能是由结构决定的， 精巧设计的结构可以产生特定的功能， 大概高中生物老师就给我们灌输了这个观念。 而在网络的世界， 这就意味着你要某个功能，就要先产生那样的结构，比如一个具有特定结构的CNN。&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;然而， 可能你不知道的是， 一个随机连接的网络也具有功能。 什么叫随机啊？ 就是任意单元和单元之间连接与否是随机的， 看起来很混乱，它们居然能做事？ 不仅如此， 它能做的事情还很酷炫：比如， 预测火焰的形状演化。&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;注：火焰的跳动，是一个我们常说的混沌系统， 所谓难以用常规方法预测， 确可以一定程度被随机网络征服，这是一个以复杂对抗复杂，用无常应对无常的经典例子。&lt;/p&gt;
&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.5615384615384615&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcewMUIibIuV7JdontKCkatxCwjxNiat12Ber6FWgHTw70o1ib9sGxPaUWa4OqqzOeiax2iacJ4u5gENmyg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;520&quot; width=&quot;520&quot;/&gt;&lt;p&gt;Machine Learning&amp;amp;amp;amp;#39;s &amp;amp;amp;amp;#39;Amazing&amp;amp;amp;amp;#39; Ability to Predict Chaos&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;任何一个网络的连接都可以由一个矩阵来刻画， 刻画随机网络单元和单元之间的连接就是随机矩阵。&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; center=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;&lt;span&gt;&lt;strong&gt;1）什么是随机矩阵 ？&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;可能每个人都很清楚矩阵， 但是提到随机矩阵，就不是每个人都清楚了。 事实上， 随机矩阵是研究所有和网络有关的科学技术， 从机器学习到复杂系统， 极为重要的工具。 那么我们就一层层拨开随机矩阵的神秘面纱。&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;首先， 如果矩阵里每行每列的元素都从独立分布的高斯里抽样，那个， 这样的一个方阵称为随机矩阵。&lt;/p&gt;
&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.26666666666666666&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcewMUIibIuV7JdontKCkatxC8McjJVpeuZbYZ99fRzG8iaQ3wPFrKRgYPOtboFZMrO8q8PUUFhN9eKQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;720&quot; width=&quot;904&quot;/&gt;&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;看起来没什么乱用对吧？ 我们还是直接进入随机矩阵的数学物理本质： 事实上， 随机矩阵用于描述一个动力系统内不同元素间的相互作用， 具体的例子比如：&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;1， 描述一个马尔可夫过程的概率迁移矩阵： 矩阵可以用来描述一个马尔可夫过程的迁移矩阵， 那么该矩阵就定义了一个随机连接的图网络， 从i点到j点的迁移概率由对应的矩阵元素表达（因此每一行的和需要为1）。&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;2， 描述一个动力系统里任意的n个元素和n个元素的相互作用关系， 这n个元素， 既可以是人工或生物神经网络里的神经元， 也可以是生态系统里的各个物种， 或金融市场相互作用的交易者， 我们刚刚说的预测混沌的网络就符合这个类型。 此处随机矩阵就是随机网络的数学表示&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; center=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;&lt;strong&gt;&lt;span&gt;2）随机矩阵是怎样刻画一个动力系统的&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;这里， 我们从最简单的系统-二维的线性动力学系统开始， 二维的动力系统定义为：&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.17567567567567569&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_svg/hNWCQ9bibbzFWeywyrPJ78CTicqXAeOgPnF1ia9ib42miafRnAJLIbibIic2m4yt0P3oSjm9DZCB43s85xgsyY8RPsEMtDHM7avvK32/640?wx_fmt=svg&quot; data-type=&quot;svg&quot; data-w=&quot;148&quot;/&gt;&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.1780821917808219&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_svg/hNWCQ9bibbzFWeywyrPJ78CTicqXAeOgPnowJGOKPTyrK4ic68XPZBGq7z9RBj4YldHQByhk95mZgoFGHzVDRrzffibib3F2d9UHd/640?wx_fmt=svg&quot; data-type=&quot;svg&quot; data-w=&quot;146&quot;/&gt;&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;可以由一个a，b，c，d组成的二维矩阵（雅可比矩阵）刻画。 这个两两作用的系统在自然界比比皆是， 比如著名的猎手-猎物方程。&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;对于任何动力学系统， 我们都要先抓住它的定点， 而整个系统的性质， 由定点向外周扩散迎刃而解。 那么这个简单的线性系统有一个显而易见的定点就是x=0， y=0.&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;定点的作用就像一个巨大的吸引中心， 系统的演化无论多么复杂， 都是以某种形式围绕它展开。 这些展开形式可以被概括到一个叫相图的二维平面里， 这个平面是由二维系统的两个变量为坐标轴， 概括了系统从任何初始状态（x，y）开始演化， 它的未来发展轨迹。&lt;/p&gt;
&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.6458036984352774&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcewMUIibIuV7JdontKCkatxCLpIPMCcO48JalHajRLhT6yJs5FFAvKXryicGpqkIlNV8t4TgoHFK9Lw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;703&quot; width=&quot;703&quot;/&gt;&lt;p&gt;相图的做法非常简单， 只需要对任意状态求解其变化趋势(dx/dt, dy/dt)并在平面上用箭头表达， 我们就可以看到整个系统从任意点开始的未来走势。&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;有了定点后， 系统具体的演化方法则由它的雅可比矩阵决定。 在这里雅可比矩阵也就是abcd所确定的连接矩阵&lt;img class=&quot;rich_pages&quot; data-ratio=&quot;0.8115942028985508&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcewMUIibIuV7JdontKCkatxCKAUmF6GAyNmomkLGX8SVq0y4UFoChXoRZDC4hlxAV59copOqn0uvIA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;69&quot; helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; sans=&quot;&quot; gb=&quot;&quot; yahei=&quot;&quot; ui=&quot;&quot; arial=&quot;&quot; sans-serif=&quot;&quot;/&gt;这个矩阵里的各个元素，它将确定，随着时间，系统将去向何方。 我们可以按照特征矩阵的行列式A = ad -bc 以及迹（trace） a +d 作为坐标轴对系统分类。为什么是这两个东西， 你想一下， 矩阵本身由特征值决定， 在特征分解后，A代表特征值的乘积，trace是特征值的和， 这两个量体现了特征值的性质。 矩阵的特征值是一个复数， 对应复平面上的两个点。 这两个点的几何性质由刚刚说的行列式和迹决定。&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;数学的好处在于一次得到所有的可能性。 一切可能皆由定点展开， 这些情况按照定点稳定与否（演化是趋紧还是远离它）， 以及趋于（或远离）定点的方式展开。&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;我们通常用poincare diagram 来表达所有情况。 从左向右， 定点从稳定到不稳定（特征值由负到正），从下到上， 趋于或离开定点的方式由线性变换到旋转（特征值由实入虚， 此处以delta&lt;img class=&quot;&quot; data-ratio=&quot;0.22807017543859648&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_svg/hNWCQ9bibbzFWeywyrPJ78CTicqXAeOgPn0lfXOYcMnxjePpHrslD4IBgDFCypck09y8BmxcFPISX9GYICMLdSWQxTrgkgGCHI/640?wx_fmt=svg&quot; data-type=&quot;svg&quot; data-w=&quot;114&quot;/&gt; 为界）。方程你可以把整个解析解写出来&lt;/p&gt;

</description>
<pubDate>Wed, 01 May 2019 04:35:46 +0000</pubDate>
<dc:language>zh-CN</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.jintiankansha.me/t/JIJMBiPkwj</dc:identifier>
</item>
<item>
<title>AI中的幂率法则-通过Scaling来看AI的未来</title>
<link>http://www.jintiankansha.me/t/9eQ8xd2rMJ</link>
<guid isPermaLink="true" >http://www.jintiankansha.me/t/9eQ8xd2rMJ</guid>
<description>&lt;p&gt;这篇小文是源于《Possible mind》这本书的最后一篇随笔，上面是这个系列的前作，对于这本书感兴趣的小伙伴，这本书在今年7月将会由湛卢出版中文版的。&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651384297&amp;amp;idx=1&amp;amp;sn=27d3e3d3f0bbe0557c784f443014f9dd&amp;amp;chksm=84f3c7a8b3844ebe62cce0a60474c5d6dcb49af2d03598b93fd073a4095de500630aeb847ca6&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-itemshowtype=&quot;0&quot; data-linktype=&quot;2&quot;&gt;《Possible Mind》读书笔记-强人工智能的公理化思考&lt;/a&gt;&lt;br /&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651384268&amp;amp;idx=1&amp;amp;sn=07488417ce770804c65a42411735f94b&amp;amp;chksm=84f3c78db3844e9bf479069e7168e0756d9c2854120223650bad38128bd4d19f1f19545fb0f5&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-itemshowtype=&quot;0&quot; data-linktype=&quot;2&quot;&gt;让神经网络变得透明-因果推理对机器学习的八项助力&lt;/a&gt;&lt;br /&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651384252&amp;amp;idx=1&amp;amp;sn=bdc733e516f25b44a1b7bdfb6104d2b5&amp;amp;chksm=84f3c7fdb3844eeb9f82b2f7e0590f3514f5b9887c279ccdd5919004b59a8686353a85670742&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-itemshowtype=&quot;0&quot; data-linktype=&quot;2&quot;&gt;信息的俩种定义&lt;/a&gt;&lt;br /&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651384215&amp;amp;idx=1&amp;amp;sn=bd8e32534f656af0aecc8cba60b1a608&amp;amp;chksm=84f3c7d6b3844ec053cc3b7d853b18f8754135c8e074fd22ae2ca58cb76e82554aef9b13e111&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-itemshowtype=&quot;0&quot; data-linktype=&quot;2&quot;&gt;读《Possible Mind》，看25位大咖谈AI&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;当要解决的问题的规模指数化变化时，总会有哪些特征是线性变化的。幂率法则要告诉你的就是这些特征是存在的，幂率法则的道理由于其简单，因此变得极其具有普适性。（关于幂率法则，参考&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651382599&amp;amp;idx=1&amp;amp;sn=6685868146b23306992836c3abd77ab1&amp;amp;chksm=84f3cd06b384441063d08c6efacbdde5e8c3cd177b37f3a30fc70a037eb1ac31ecb704f21dee&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-itemshowtype=&quot;0&quot; data-linktype=&quot;2&quot;&gt;“Scale” 读书笔记-天下之大作于细&lt;/a&gt;)  当我们将AI的发展放到幂率法则的视角下，会发现历史上的AI低谷对应问题规模增加后带来的复杂度，而高潮则对应通过找到指数级增长中的线性特征来应对复杂性。&lt;/p&gt;

&lt;p&gt;例数历史中的AI低谷，首先是专家系统的预先设定的知识无法跟上现实问题的复杂性而衰落；之后是单个神经元的感知机无法应对非线性，之后是多层神经网络无法应对现实中非结构化的数据，而当前的深度学习热，也由于缺少解释性，模型的稳定性以及对常识与背景的理解，而有可能跌入低谷。&lt;/p&gt;

&lt;p&gt;说起深度学习的成功，算力的提升和数据量的增加是其俩大成功要素，而这俩点都依赖于香龙在信息论提出的数字化编码的通信系统具有的纠错能力。香龙发现，在数字化的通讯方式（例如用二进制），只要传输的数据中的噪音所占的比例低于一个阀值，那通过线性的增加传输数据的通量，可以指数级的减少整体信息出错的概率，直到信息传递的错误变得在实际中不可能出现。假设你要传递一个信息，你为了避免信息在传递中出错，你可以叫多个人来传递，人越多，总体信息出错的概率是指数级而不是线性下降的。这意味着传输的通道增加，带来的可以传递的信息数量是指数化增长的。如果随着越来越多的微电子元件，计算中传递的中间变量也等比例的出错，那就不可能会有摩尔定律。而随着通信的价格指数化的降低，更多的人将生活中越来越多的部分数字化，从而带来了可供处理的数据的指数化增加。&lt;/p&gt;

&lt;p&gt;除了以上的俩个维度，幂率法则在AI中的应用还体现在模型复杂度的线性增长带来了模型容量的指数级增长。当神经网络变得更深，在应对数据时可以使用的规则是之前规则和新增规则的俩俩组合。深度学习中常见的维度灾难，说的是待处理的数据有太多的维度，导致数据分布的很稀疏。而解决方法是将对问题的最优解的全局搜索变成局部受限下的搜索。剪纸的想法不新鲜，但深度学习通过逐步迭代的方式，将问题用一组可能不是最写实，但却最有利于解决问题的特征表示了出来。当OpenAI战神人类的dota选手时，机器眼中的地图是一个个的矩阵，虽然要解决的问题包含的可能性要多于宇宙中的原子。但将问题映射到便于问题解决的规律却是线性的。&lt;/p&gt;

&lt;p&gt;而当前机器学习缺少解释性的缺陷，我们的大脑中的种种决策，其背后的逻辑也是在外界看来是个不透明的黑箱。但为了让人类相互协作，相互共情，需要解释的是人类做出的行为，而不是行为背后的机理。这指出了应对机器学习模型指数化增加后带来的复杂性的方法，通过训练新的神经网络，来将元模型的行为归类到线性增长的框架中，从而解释模型做出的决策的目的因，而不是模型如何做出决策。&lt;/p&gt;

&lt;p&gt;AI要挑战的终极指数级增长，是如何用一个线性增长的规则合成出能够指数化扩展的自身。这方面自然界给出的例子的生物发育中，人具有的复杂性是指数级增长的，但如何制造人的基因却就是那么长。自然的解法是将发育的过程分成很多步，然后通过HOX基因来调控所有和发育有关的基因。当机器可以直接操纵物质世界中的基本粒子，来重构自身，涌现与进化的闭环就如同咬住自己尾巴的蛇，从原子到分子，从分子到细胞，再到组织，器官，生物体，互联的智能体，最后回到原子。&lt;/p&gt;

&lt;p&gt;通过幂率法则看待AI的历史，是将复杂系统的理论来解释为何复杂的系统是必然会发生的。当我们自身遇到指数化增长的选项的时候，也要看出其中那些因素是线性变化的。所谓的万变不离其宗，说的就是这个道理。&lt;br /&gt;&lt;/p&gt;
</description>
<pubDate>Sun, 21 Apr 2019 17:07:51 +0000</pubDate>
<dc:language>zh-CN</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.jintiankansha.me/t/9eQ8xd2rMJ</dc:identifier>
</item>
<item>
<title>《大脑的故事》-六个关键词串起对大脑的系统性认识</title>
<link>http://www.jintiankansha.me/t/BJpbXITniE</link>
<guid isPermaLink="true" >http://www.jintiankansha.me/t/BJpbXITniE</guid>
<description>&lt;p&gt;《大脑的故事》是4月份湛庐新出的一本科普书，该书的作者曾写过《创造的故事》（&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651383522&amp;amp;idx=1&amp;amp;sn=ab9a5e820a8d4566c51912f206363cbc&amp;amp;chksm=84f3c8a3b38441b5a781dff83e24405fcf95f482d46713eabb83bd35c8266345f14ca5ba5e6c&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-itemshowtype=&quot;0&quot; data-linktype=&quot;2&quot;&gt;点击查看读书笔记&lt;/a&gt;），他的一整套“自我进化”四部曲，还包括“自我的故事”，作为“西部世界”的科学顾问，他在这本承前启后的书中对神经科学带给普通人日常生活的启示这个话题，通过诸多大脑异常的患者的例子，导出了具有普遍性的建议。本文通过六个关键词，记录我阅读这本书的收获。&lt;/p&gt;

&lt;p&gt;&lt;img data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/ictmXdPJ7c5m6TnGiaBCqNNlFzBXWsO51eKzlSPuNicqQcZWKaF0utlXBUtB9Lfw5H4ibAtXV9icSE9f2OhbOMp8DgQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; class=&quot;&quot; data-ratio=&quot;1.3878504672897196&quot; data-w=&quot;428&quot; /&gt;&lt;/p&gt;

&lt;p&gt;第一章的关键词是&lt;strong&gt;可塑&lt;/strong&gt;性，孩子出生后，独立的神经员，在受到关爱的坏境下探索世界，神经员的连接突触从童年时的最高点，逐渐去掉多达50%不那么重要的部分，在青春期变得对自我认同格外看重，更爱冒险，对情绪更敏感。到了成年期之后，大脑仍然具有学习改变的能力，只是这时你需要比青春期额外的努力。在生命的每个时刻，记忆都在相互争抢着大脑中的连接，这导致了记忆具有可塑性，如果一段记忆很久都没有被激活，那这段记忆的细节就会淡忘，如果记忆在特定的环境下被唤醒，那问题的问法能部分决定回答。如果能减少当下的认知失调，记忆还可以被当下植入。记忆不止是记录之前发生了什么，失去了与记忆生成有关的海马体，我们不止无法建立新的记忆，也无法想象未来。而当我们老去，可以通过对大脑的训练例如保有责任心，生活有目标，保持忙碌，来减缓大脑的衰老。&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.9929859719438878&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcdDrONuiagA265oQoFTaJNGYqicCFIUqsJqYm149dNylRq8KIhLLm4qmbueM5Fc9MUc4oibW8CKzhpDQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;998&quot; /&gt;&lt;/p&gt;

&lt;p&gt;第二章的关键词是&lt;strong&gt;构建&lt;/strong&gt;，这章讲述大脑怎么认识外界。人要看到这个世界，需要的不只是视觉皮质对光子给予阐释，还涉及到对自身的认知。上图中一只小猫自己走，一只小猫小车载着走，俩者的视觉输入完全相同，但只有自己走的那只小猫，学会了将视觉和自己的运动匹配。不止如此，远在大脑接收信息之前，大脑就生成现实的图景，为了节省能量，大脑不提供完整的画面，我们高层的神经连接只汇报收到的视觉信号在那里和内部模型有误差。内部模型如此强大，以至于在某些情况下，我们只能看到我们预期的东西，例如面具的凹面还是在你看来是凸出来的。我们对时间的感觉，也是大脑构造出来的，当生死相关的时候，我们会以为时间变慢了，但实验却会告诉你这是幻觉，不同的感官的时间差，也会在大脑中被自动对齐。&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-copyright=&quot;0&quot; data-ratio=&quot;1.155925155925156&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcdDrONuiagA265oQoFTaJNGYiaPvGJk5ttDDHuCVF6tYOUnf90MnswRZ1cL3Sibic5eCoP3EAXrjLY5pg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;962&quot; /&gt;&lt;/p&gt;

&lt;p&gt;第三章的关键词是&lt;strong&gt;权衡&lt;/strong&gt;，这章的题目“谁说了算”预告这章的主题是意识。孰能生巧是大脑对重复问题节约能量的一种应对策略，无意识的操作，还能保证稳定性，就像在心流状态下的攀岩者表现的比有意识干预时更糟。无意识下的决策，除了上述优点，也容易受到环境因素的影响，例如外界或饮品的冷热绝对你对一个人的第一印象，这使得我们可以通过助推的方法，来改变人的决策。我们的偏好，在无意识的决策时，我们不知道为何会做出选择，即使我告诉你上图左边的照片瞳孔被放大过，你也让会觉得左边的面孔更有吸引力。但意识如同一家大公司的CEO，当一家公司有成千上万个分支的是否，就需要意识来从上而下的做长远打算。尽管CEO只接触公司运营的极少数细节，但通过CEO，大企业才成为一个整体。复杂系统通过意识反映出自身整体的模样。意识不过是大脑的一种错觉，通过是否让意识照亮，大脑在效率和灵活性，自上而下和自下而上之间随时进行权衡和切换。&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;第四章的关键词是&lt;strong&gt;多元&lt;/strong&gt;，人脑的灵活性体现在面对一个决策时，不同功能的脑区在相互竞争，取决于决策呈现的方式，例如在电车困境中是推一个人还是搬动把手。而面对包含了太多细节的选择，大脑根据身体的状态而不是逻辑来进行选择，这解释了我们为何无法抵御垃圾食品的诱惑。为何会为了此刻的享受而不去对未来进行投资，甚至甘愿上当。当我们的自我控制受到损耗之后，我们的决策会倾向于自动化处理，而当我们吃好睡好，就像加好了油的汽车，又能做出理性的判断了。但大脑的可塑性是我们可以预测未来，从而改变对未来奖励的预期，如果期待与现实失调，多巴胺会促使你在无意识的层面重新评估对不同选项的估值。如果你有预期自己未来会犯错，那意识的层面，逻辑推理让你可以提前限制自己的选项。大脑做出的每一项决策，都不是一个系统在起作用，大脑因其多元，而具有智能，也因为其多元，而容易出错，做出让人后悔的决定。&lt;/p&gt;

&lt;p&gt;第五章的关键词是&lt;strong&gt;共情&lt;/strong&gt;，人的大脑的最强大之处不在于能决策，而在于能够在无意识的图景上投射出人的情感，正如能够在动画片中，哪怕是几何图形的抽象动画片中投射出情感，人类，哪怕是婴儿的大脑都会同情弱者，会自然的渴望公正，这使得人与人之间的合作成为可能，使得宗教和道德成为可能，使得人们轻易的将自己与他人区分开，将某些微不足道的特征当成是将其“去人化”的依据，从而掩盖了人的共情能力，让人成为最危险的物种。人的共情能力是神经科学最需要关注的，因为我们不能回避这一刻在大脑回路里的真相，我们彼此需要，尽管你这一概念仅仅限于你皮肤包裹的范围。&lt;/p&gt;

&lt;p&gt;第六章的关键词是&lt;strong&gt;融合&lt;/strong&gt;，这章讨论大脑的未来，例如脑机接口，人工智能模拟大脑。作者举可变超感官传感器的例子，通过将听觉转换穿在衣服上背心的振动，让失聪的人能识别出口语词汇，或者让盲人通过背部的触觉去看到圆形的物体，通过机械手臂，让残疾的患者重新挥动四肢。这些现实中的迫切需求，不同于科幻，是黑科技可以起飞的基点。脑机融合的另一条路是从机器出发，例如通过模拟神经元的连接，在硅基上一比一的重现大脑，通过AI整合出和人脑运作机理不同，但具有意识的智能体。这一章的洞见不在于具体的例子，而在于指出脑科学第一次变成一门科学和应用相互促进的学科，通过对大脑的认知，我们正在改变我们自身，不是像过去那样间接的，无目的性，而是主动的有计划的。正如脑科学可以指导深度学习的发展，上文中我们大脑的特征，如何能在神经网络中重新，正在成为研究的主要目标。&lt;/p&gt;

&lt;p&gt;总结来看，对于普通人，大脑的可塑性让你不放弃对自我的提升，记忆是构建出来的提醒你别把自己的主观印象看的太坚不可摧，意识的协调与心流的动态调整让你意识到有时别想的太多，而多元的决策方式督促你多积累些思维捷径，而共情能力的获得与丧失能帮你解释为何人与人之间会有这么多样的互动，而人脑与机器的融合，则告诉你应当顺应大势所趋，对神经科学的进展保持关注。&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;更多阅读&lt;br /&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651384297&amp;amp;idx=2&amp;amp;sn=2e6205eb1776c0eccce5a3e7af082934&amp;amp;chksm=84f3c7a8b3844ebe70217025f68e868eb6566d15fa22ef32678b1ce0d9ce8c539ca79f0ecbac&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-itemshowtype=&quot;0&quot; data-linktype=&quot;2&quot;&gt;大脑最小自由能法则与我们对不确定性的态度&lt;/a&gt;&lt;br /&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651383843&amp;amp;idx=1&amp;amp;sn=41e82163f76edfe5ffe31a8518d5bafa&amp;amp;chksm=84f3c662b3844f7430b27f82522dd9414d6c481f6e63822d99deb8baf281be8681ea5c4413a7&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-itemshowtype=&quot;0&quot; data-linktype=&quot;2&quot;&gt;大脑的自由能假说-兼论认知科学与机器学习&lt;/a&gt;&lt;br /&gt;&lt;/p&gt;














</description>
<pubDate>Sat, 20 Apr 2019 15:53:32 +0000</pubDate>
<dc:language>zh-CN</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.jintiankansha.me/t/BJpbXITniE</dc:identifier>
</item>
</channel>
</rss>