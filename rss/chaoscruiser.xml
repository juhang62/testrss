<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="css/feed.xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/" xmlns:og="http://ogp.me/ns#">
<channel>
<atom:link rel="self" href="http://192.168.1.4/fivefilters/makefulltextfeed.php?url=feed43.com%2Fchaoscruiser-jtks.xml&amp;max=5&amp;links=preserve&amp;exc=1" />
<atom:link rel="alternate" title="Source URL" href="http://feed43.com/chaoscruiser-jtks.xml" />
<atom:link rel="related" title="Subscribe to feed" href="http://www.subtome.com/#/subscribe?feeds=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed43.com%252Fchaoscruiser-jtks.xml%26max%3D5%26links%3Dpreserve%26exc%3D1&amp;back=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed43.com%252Fchaoscruiser-jtks.xml%26max%3D5%26links%3Dpreserve%26exc%3D1" />
<title>混沌巡洋舰</title>
<link>http://www.jintiankansha.me/column/ultiWL8Axg</link>
<description>混沌巡洋舰 - 今天看啥</description>
<ttl>360</ttl>
<item>
<title>AI药物研发之惑：我们应如何提高药物研发的成功率</title>
<link>http://www.jintiankansha.me/t/x7GR8vCPNy</link>
<guid isPermaLink="true" >http://www.jintiankansha.me/t/x7GR8vCPNy</guid>
<description>&lt;p&gt;如果说化学阶段的目的是Be better的话，那么医学阶段的目标似乎又收缩了，变成了Be usable，然而真实的情况是大部分药物分子跨不过这个坎。在药物研发里有个谚语，叫做“Fail fast, Fail early”，这其实是求之不得的事情，因为如果拖到临床II期甚至III期临床再失败，将会造成摧毁整个公司市值的重大损失。&lt;/p&gt;

&lt;p&gt;这看起来似乎是荒谬的，如果前期的生物学机理和化学优化已经完善，为什么放到真人身上就砸了呢。但这个荒谬背后的原因是非常深刻的：药物分子在复杂的人体系统，尤其是具有基因和组学异质性的人群中的效应是难以捉摸的，在不同的维度上可以呈现出不同的usability。&lt;/p&gt;

&lt;p&gt;大部分的药物如果是在II期及之后失败，最大的问题可能不是因为药不好，而是以错误的方式用在了错误的人群中。很多药物其实在临床试验里并没有死透，如果我们知道自己错在那里，其实是有可能通过给药方案和适用范围的调整，达到新的临床终点。&lt;/p&gt;

&lt;p&gt;如果能够及时止损，及时选择合适的适应症，提高成功率的话，这才是真正值钱的地方。而这其实可以借助于机器学习对患者画像的洞察来实现，在临床试验开始之前就对这个药在大人群中的可用性，或是对哪些细分marker的人群可用，以及最重要的，哪些marker人群和临床终点无效做出判断。这样的洞见，在II期及以后的临床试验中都价值上亿！&lt;/p&gt;

&lt;p&gt;可以看到，目前的药物研发的流程，最大的矛盾集中在生物学阶段和医学阶段，相反，化学阶段反而是最成熟的部分。而如果只是在这个非瓶颈部分做优化，并不会显著提升药物研发的时间效率和回报率。&lt;/p&gt;

&lt;p&gt;因此我认为，如果AI药物研发的项目，仅仅是过去计算化学模拟，组学和药物开发自动化的延续，是用AI的工具去优化和加强已有的研发流程，这当然是一个最具可行性的前期策略，但是这并不是那么值钱的市场。这些针对药物研发中“化学”阶段的AI创业项目，做的普遍是容易做，但不是必须做的事情。如果只是提升当前的药物研发效率，那么AI药物研发公司的估值，显然有点高了。&lt;/p&gt;

&lt;p&gt;大型药企对这些创业项目的关注和支持，与其说是看好技术而去投资，不如说是出于财务KPI的考虑，以投资AI药物研发公司的方式，将非药企核心的研发业务外包给了CRO和这些“virtual biotech”的AI创业公司。&lt;/p&gt;

&lt;p&gt;这可以输出药企的优势：充沛的现金流投入，和临床开发“接盘”能力，而产生的收益又不会立即体现在损益表上，而是通过收购-商誉的调节，让报表变得更好看。当然，从投资的角度去看，我也认同这种商业逻辑。&lt;/p&gt;

&lt;p&gt;但真正具有极大价值的，应该是用AI重构药物研发的整体逻辑，这可以从两个方向进行努力：&lt;/p&gt;

&lt;p&gt;1，&lt;strong&gt;在生物学的阶段，甩开可理解性的限制，以无监督学习的方式去更高效寻找新机理和有效的新靶点，往外扩张成药的空间。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;2，&lt;strong&gt;在医学的阶段，结合患者画像参与到临床实验的决策中，以提高药物定位和过审的成功概率，尽早识别并kill掉无底洞的烂药，以免到了3期失败被坑死。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;这两个方向其实都体现出同一个理念，那就是应该用AI去提高药物研发的成功率，而非药物研发的运营效率，这两者是质和量的不同。如果能够直面“生物学”和“医学”阶段的Hard Problem，实现颠覆性创新，我相信，这会比在“化学”阶段做的任何渐进式创新，都更有价值。与诸君共勉！ &lt;/p&gt;
</description>
<pubDate>Tue, 02 Apr 2019 15:35:58 +0000</pubDate>
<dc:language>zh-CN</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.jintiankansha.me/t/x7GR8vCPNy</dc:identifier>
</item>
<item>
<title>预测神经网络预测准确性的普遍理论</title>
<link>http://www.jintiankansha.me/t/ctLLjVRfg2</link>
<guid isPermaLink="true" >http://www.jintiankansha.me/t/ctLLjVRfg2</guid>
<description>&lt;p&gt;Heavy-Tailed Universality Predicts Trends in Test Accuracies for Very Large Pre-Trained Deep Neural Networks 是今年1月24日在Arxiv上post的一篇论文。作者还有针对这个话题的一系列偏理论的文章，本篇是其中最实用的一篇&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-croporisrc=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcc8FWgochyYCx565Py8uo3cdXGY1uicfP1GvdpRUIsTzVeCW0jQBn23FMOTGtQu1BCFzKExl0uAKrA/0?wx_fmt=png&quot; data-cropx1=&quot;0&quot; data-cropx2=&quot;845&quot; data-cropy1=&quot;10.638489208633095&quot; data-cropy2=&quot;411.8615107913669&quot; data-ratio=&quot;0.4757396449704142&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcc8FWgochyYCx565Py8uo3cwDQ2Mb5ROibQ3rN9plKq3Sc88iafn561z58fbL7icweEuEmbPlLdYQZcg/640?wx_fmt=jpeg&quot; data-type=&quot;png&quot; data-w=&quot;845&quot; /&gt;&lt;/p&gt;


&lt;p&gt;这篇文章对神经网络的泛化能力建立了一个大一统性质的理论，不仅能够解释为何神经网络中的各种正则化手段有效，还能够用一个指标预测一个训练好的网络的泛化能力，这篇文章中有很多在我看来高深的数学，其中很多我觉得较难理解，因此这里只概述我理解的部分，写下这篇论文笔记，更多的是像行家请教。&lt;/p&gt;

&lt;p&gt;初学深度学习的时候，我被各种各样的正则化方法搞的很迷茫。传统的机器学习中就是增加L1或者L2正则项，到了深度学习，减少batch size，dropout，early stopping等很多看似完全不同的方法，都被称为正则化，似乎所有能够增加模型泛华能力的都是正则化方法。 有了这么多的正则化方法，对于有监督学习，使用同一数据训练的两个DNN，训练时用到了不同的超参数，不同的优化方法与正则方法，我们除了让模型在真实数据上跑一下，没有方法提前估计模型的泛化能力。如果能够通过对模型本身的分析，就能评估出模型相对的泛化能力，那在对模型进行fine-tune(微调)的时候，就能够起到指导。&lt;/p&gt;

&lt;p&gt;验证该理论的是数据来自真实世界中的神经网络，通过比较针对ImageNet数据集上的50个预训练过的DNN，在不改变模型的损失函数与网络结构，不需要重新训练模型，甚至不需要导入测试数据时，通过计算网络中每一层权重矩阵的Frobenius norm的指数平均值，发现该平均值和模型的预测准确性具有相关性，从而能通过上述指数，预测模型的泛化能力。用于验证的模型涵盖了15个不同的网络结构，例如VGG16，ResNet等，这说明了该方法对各类模型都适用。&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;inline-img&quot; data-ratio=&quot;0.4737394957983193&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcc8FWgochyYCx565Py8uo3cLZ2JXlDD2oOoiaeQrbgLYspwyNHwOBlgib2w2WZbF5Le1dzy1iaqica4QQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;952&quot; /&gt;&lt;/p&gt;

&lt;p&gt;这里展示了预训练的不同VGG和带批量正则化的VGG网络的表现，这里的横轴是该网络的预测准确性，纵轴是作者文中定义的评估模型范化能力的指标，左边的图是之前的方法，右边的是本文新提出的指标。可以看出这里拟合的很好，而且是接近线性的拟合。&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;inline-img&quot; data-ratio=&quot;0.5208333333333334&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcc8FWgochyYCx565Py8uo3cIDzvBEpuFumLXV3hMDZXofEIRVwjJcJNVIsgq9rfhicER0guqamqibOg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;912&quot; /&gt;&lt;/p&gt;
&lt;p&gt;上面反映的是不同的ResNet上的情况，除了部分离群点，文中提出指标也反映了模型相对的好坏。更多网络结构下的对比情况如下所示；&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;inline-img&quot; data-ratio=&quot;1.6070726915520628&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcc8FWgochyYCx565Py8uo3cSKGRj6zgA6HkgSGOYibORbAvR9eWDXZceSTxTrJkjHKozSS39Uiaz9rQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;509&quot; /&gt;&lt;/p&gt;
&lt;p&gt;该作者还提供了一个pytorch及Keras下的package，名为WeightWatcher，可以用一行代码，将训练好的模型当作参数传入，就可以计算出上述指标。笔者试用了，挺方便的。&lt;br /&gt;&lt;/p&gt;
&lt;p&gt;https://github.com/CalculatedContent/WeightWatcher&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-ratio=&quot;0.3822843822843823&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcc8FWgochyYCx565Py8uo3cxxK7f8OnePohbahEEibCBy5iacT6xBvAEkYJ8a0aHUPZFZBHOI2WzweQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;429&quot; /&gt;&lt;/p&gt;


&lt;p&gt;接下来要解释这背后的数学原理了，首先对每层网络的权重矩阵W，构建相关矩阵X&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;inline-img&quot; data-ratio=&quot;0.3722943722943723&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcc8FWgochyYCx565Py8uo3cJnDzhnOawRIiagfv2ibPHqvzy50PPID5En5xvo2tVGuY7sO6egd1gvBg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;231&quot; /&gt;&lt;/p&gt;
&lt;p&gt;对X计算矩阵的秩，将该矩阵的秩写成一系列秩的加权，将其称为Empirical Spectral Density (ESD)&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;inline-img&quot; data-ratio=&quot;0.24634146341463414&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcc8FWgochyYCx565Py8uo3cxM1RQcicDC73435khfQPCg8NzCf4ibOa9rMb8GmhNxP5BOIyETw965Tg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;410&quot; /&gt;&lt;/p&gt;
&lt;p&gt;之后作者指出可以用一个由随机数生成的矩阵的秩进行幂律运算，来拟合这个分布，这里引入了random matrix theory&lt;img class=&quot;inline-img&quot; data-ratio=&quot;0.2925764192139738&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcc8FWgochyYCx565Py8uo3cI6maPKuD2wiaUrTLC99T5ERNTjaHJLFbeic4K68FSEdYLApWnUWW3geg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;229&quot; /&gt;&lt;/p&gt;

&lt;p&gt;而这里的alpha则代表了幂律分布的尾巴有多长，对于ImageNet中的7500个权重矩阵，下图代表了不同矩阵最佳拟合的alpha落在不同区间的次数，图中70-80%的案例，图中的alpha都落在了2-4之间，也有少数极大的情况。&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;inline-img&quot; data-ratio=&quot;0.8426150121065376&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcc8FWgochyYCx565Py8uo3cDnwBxgKicJWXr26T9IJ10y9SdSusoutAm9dSbEH19gKtVI8CICJZmWw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;413&quot; /&gt;&lt;/p&gt;

&lt;p&gt;而上文中出现的用来预测模型预测精度的纵轴&lt;img class=&quot;inline-img&quot; data-ratio=&quot;0.8823529411764706&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcc8FWgochyYCx565Py8uo3ck9XN8klS5ic6EpFueJibs4MQS1I256uQz8mjSTrHgsOJ8g71eEwM6Bng/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;51&quot; /&gt;，就是所有层的加群平均， 不同深度的层数对应的权重由式中的beta控制，&lt;img class=&quot;inline-img&quot; data-ratio=&quot;0.2826086956521739&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcc8FWgochyYCx565Py8uo3c2gAwJB9ibQZX8qsOWHY5DPSu1KscbTJmibMBbQdGSYhdbfzeelk1mohQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;322&quot; /&gt;&lt;/p&gt;

&lt;p&gt;之后文章指出，正则化不管怎么去做，都是要避免权重矩阵的秩被过度长尾（heavy tailed)的随机矩阵拟合，也就是说上文中每一层都需要alpha值越小，网络在该层过拟合的风险越低。权重矩阵的秩呈现过度长尾的幂律分布，可以直观的想象成对于某些像素点赋予高的不合比例的权重，而这意味着该层网络的观察野受到了局限，对高权重位点的变化及其敏感，而这会使得模型更容易过拟合。因此将网络中每层的权重矩阵的alpha做权重衰减的加和，就可以用来评估模型是否过拟合。&lt;/p&gt;

&lt;p&gt;总结一下，本文提出的衡量模型相对泛化能力的普适性方法，利用了已有的成熟模型，发现规律，并将其用在指导新模型的训练，该方法可以用在迁移学习和模型微调中。这篇文章的数学我对其只看懂了皮毛，有一些问题，文中也没有给出解答，第一是对于非CNN系列的网络结构，例如capsule network，图卷积网络GCN等，该文的方法是否适用，第二是对于autoencoder系列的模型，如果以重构误差作为横轴，能否也通过文中的指标评价模型的泛化能力，第三点是该方法用在图像切割上，是不是也会有较好的效果，第四个问题是该方法在NLP任务中是否适用。&lt;/p&gt;

</description>
<pubDate>Thu, 28 Mar 2019 06:59:59 +0000</pubDate>
<dc:language>zh-CN</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.jintiankansha.me/t/ctLLjVRfg2</dc:identifier>
</item>
<item>
<title>贝叶斯推理实用入门</title>
<link>http://www.jintiankansha.me/t/EY2XU24xDA</link>
<guid isPermaLink="true" >http://www.jintiankansha.me/t/EY2XU24xDA</guid>
<description>&lt;p&gt;&lt;span helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; start=&quot;&quot; pre-wrap=&quot;&quot; rgb=&quot;&quot;&gt;什么是贝叶斯推理， 我早在过去的文章里分析过有关贝叶斯概率的知识， 例如&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651381931&amp;amp;idx=1&amp;amp;sn=2eb7ab8b5dadda70d74ae6289ef361f8&amp;amp;chksm=84f3ceeab38447fc736fd8a9e6494b663c12dfa3c347b37054d926751141bbe0ed61f0890d11&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-itemshowtype=&quot;0&quot; data-linktype=&quot;2&quot;&gt;朴素贝叶斯之实践篇&lt;/a&gt;，这次融入纽约大学weijima的方法论教程（http://www.cns.nyu.edu/malab/index.html），给大家一个更实用的版本。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;span helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; start=&quot;&quot; pre-wrap=&quot;&quot; rgb=&quot;&quot;&gt;一，什么是贝叶斯概率， 它于经典概率由什么关系.&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;e3m1u-0-0&quot;&gt;谈贝叶斯首先是用概率量化问题。 概率这件事大家都觉得自己很熟悉， 叫你说概率的定义 ， 你却不一定说的出。经典的概率， 说的是事件发生的可能性。 我们中学课本里说概率这个东西表述是一件事发生的频率， 这个频率就代表某件事发生的可能大小。 或者说这叫做客观概率。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;948n2-0-0&quot;&gt;而贝叶斯框架下的概率理论确从另一个角度给我们展开了答案，&lt;/span&gt; &lt;span data-offset-key=&quot;948n2-0-1&quot;&gt;他说概率是我们个人的一个主观概念， 表明我们对某个事物是否发生的相信程度&lt;/span&gt;&lt;span data-offset-key=&quot;948n2-0-2&quot;&gt;。 如同Pierre Lapalace说的: Probability theory is nothing but common sense reduced to calculation. 这正是贝叶斯流派的核心，换句话说，它解决的是来自外部的信息与我们大脑内信念的交互关系。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;d6jnh-0-0&quot;&gt;两种对于概率的解读区别了频率流派和贝叶斯流派。同时我们不难看出两者之间的联系， 你对一件事情发生的可能性估计正是基于某种频率的统计。 但是它们的区别在哪里呢？&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;bc3bn-0-0&quot;&gt;首先，给你下面的事件， 假定你带着孩子去看月亮， 然后孩子说月亮的属性是块奶酪， 你会跟它怎么说呢？  首先， 你一定知道月亮是一个石头的星球而非奶酪， 那么这件事你要如何去跟孩子说呢？ 首先我们生活在概率的世界， 你要和它说的是你可以认为月亮是石头或者奶酪， 但是你不要相信任何一个， 既然不相信， 你把它们称为假设1 和假设2，  然后你给它们各自一个数字来代表可能性的大小， 这就是概率。 然后我们看频率观和贝叶斯的区别&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;4h102-0-0&quot;&gt;1， 频率观的家长： 到天空做一些测量， 看看奶酪和石头的比例， 然后算出假设1和假设2的概率。  &lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;bj860-0-0&quot;&gt;2，  贝叶斯的家长：  孩子我们去不了天空， 但是我们可以想象下我们生活中的经验， 然后查看一下教科书。 首先， 教科书里说， 到目前为止，天空中发光的99.99%是石头。   然后，  再联想下生活经验， 如果是奶酪， 那么它确实是黄灿灿的发光， 因此生活证据显示， 月亮是奶酪的假设并不违和。 那么把两个综合一下， 通过一系列后面会说的公式， 你给出孩子它的观测结合书里的知识的合理性概率： 月亮是石头的概率99.9%。 贝叶斯通过承认我们自身的无知，给不同的假设以调整空间。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;Image FocusPlugin--unfocused Image--isBlock&quot; data-ratio=&quot;1.05&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcfVWt9ibVByEGjUWF8zEKAw6Er0r4hHxCTIVzGB4kdGibZPHZDLhufbpAYHZGMGIAKO3cGxYZ1ddJkg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;600&quot;/&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;f45d1-0-0&quot;&gt;哪个过程更合理？ 哪个方法更正确？ 你自行去分析。这里要说的是，&lt;/span&gt; &lt;span data-offset-key=&quot;f45d1-0-1&quot;&gt;在真实世界里， 我们所做的往往是把现象的经验推理， 和某种先验结合， 去估计事物的可能性，这正是贝叶斯的思路 . 没有人会对每件重要的事做无限的测量， 也不是所有事件都可以重复（分手不可以， 股灾不可以），这是我们唯一可以做的。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;7kf2h-0-0&quot;&gt;贝叶斯的数学公式十分简单， 一， 你要有先验概率P（A），二， 似然性  P（B|A）， 最终得到后验概率P（A|B）。这三者构成贝叶斯统计的三要素。&lt;/span&gt;似然性实用条件概率表达， 后验也用条件概率来表达， 基于此的贝叶斯定律数学方程极为简单：&lt;/p&gt;


&lt;p&gt;&lt;img class=&quot;Image FocusPlugin--unfocused Image--isBlock&quot; data-ratio=&quot;0.30434782608695654&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcfVWt9ibVByEGjUWF8zEKAw6KfJ3pWuOyaw1gf77HOwiaPIQef4gxPOfw3UcicvlTZB44OlFxQalW4lw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;184&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;span data-offset-key=&quot;dc4dh-0-0&quot;&gt;套用月亮的例子，P(A)代表月亮是奶酪的假设， P(B|A)代表现象黄色发光。 &lt;/span&gt;&lt;span data-offset-key=&quot;dc4dh-2-0&quot;&gt;即月亮是奶酪的先验概率，&lt;/span&gt; &lt;span data-offset-key=&quot;dc4dh-4-0&quot;&gt;是如果月亮是奶酪， 那么它是黄色发光的概率， 你得到前两者，就可以根据公式算出结合了证据之后的月亮是奶酪的后验概率。 这里比较难计算的是 P（B）&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;dc4dh-6-0&quot;&gt;事实上对它的计算你要把所有可以给出这个结果的假设都包含进来， 用概率的marginal law 展开每个假设之下观测到现象的概率， 比如这个问题里， 你就要把月亮是奶酪和石头两个假设都包含进来， 分别计算各自假设下发光现象的概率。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;a9l6h-0-0&quot;&gt;有一个非常有趣的现象是如果我们的先验概率审定为1或0（即肯定或否定某件事发生）， 那么无论我们如何增加证据你也依然得到同样的条件概率（此时P（A）=0 或 1 ， P（A|B）= 0或1） 这告诉我们的第一个经验就是不要过早的下论断， 下了论断你的预测也就无法进化了， 或者可以称之为信仰。&lt;/span&gt; &lt;span data-offset-key=&quot;a9l6h-0-1&quot;&gt;你如果想让你的认知进步，就要给各种假设留一点空间。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;8vg85-0-0&quot;&gt;贝叶斯分析的思路对于由证据的积累来推测一个事物发生的概率具有重大作用， 它告诉我们当我们要预测一个事物， 我们需要的是首先根据已有的经验和知识推断一个先验概率， 然后在新证据不断积累的情况下调整这个概率。整个通过积累证据来得到一个事件发生概率的过程我们称为贝叶斯分析。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;9df1h-0-0&quot;&gt;贝叶斯的数学计算主要考察对条件概率的实用。 但是有时候我们也不理解条件概率， 比如著名的辛普森案， 为了证明辛普森有杀妻之罪，检方说辛普森之前家暴的历史，而辩护律师说，美国有400万女性被丈夫或男友打过，而其中只有1432人被杀，概率是2800分之一。 这其实就是误用了条件概率， 因为辩护律师用的条件是家暴，用来推测的事件是男友杀人， 而事实上这里的条件是被杀而且有家暴，而要推测的事件是凶手是男友（事实上概率高达90%），这才是贝叶斯分析的正当用法， 而辩护律师却把完全在混淆条件与要验证的假设。&lt;/span&gt;&lt;/p&gt;


&lt;p&gt;&lt;img class=&quot;Image FocusPlugin--unfocused Image--isBlock&quot; data-ratio=&quot;0.7256637168141593&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcfVWt9ibVByEGjUWF8zEKAw6Mz8k7jElRSnzK5icqYic43ZDLRlJ104tBLOmufISqAIKOn4AcSK26t6g/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;452&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;span&gt;二， 把贝叶斯概率工具用来建模 &lt;/span&gt;&lt;/strong&gt;&lt;span data-offset-key=&quot;4mrm0-0-0&quot;&gt; &lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;blf3r-0-0&quot;&gt;贝叶斯概率是非常基础的统计知识， 有的人只把它当成统计， 而它在心理学，经济学， 神经科学等领域具有巨大潜力。&lt;/span&gt;为什么？  因为这类问题的研究对象往往具有极高的不确定性， 是由大量较低一级单元组成的复杂系统。 这就造成直接用物理学搞定分子结构解薛定谔方程的思路是不行的， 你不能把人的行为像氢原子光谱一样求解出来。&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;68f6s-0-0&quot;&gt;那么怎么办？ 纯统计？ 你可以做量表， 去统计所有可能的人的属性和和它们的行为之间的联系， 然后求一个皮尔森系数。 但是这样的方法虽然可以用， 但在量化和机器学习发展急速的今天还是naive了一点。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;83o4i-0-0&quot;&gt;一个折衷的方法？ 贝叶斯建模。 贝叶斯建模非常善于处理“黑箱” 问题，对付这种不好精确预测但有些用到一点建模的东西很关用。&lt;/span&gt;贝叶斯建模可以很快的把实验数据和理论做一个结合。 而且据说我们的大脑处理信息也确实符合贝叶斯框架。&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;34nj4-0-0&quot;&gt;你只要有假设先验， 有观测， 有似然性， 就可以用一个贝叶斯。这里的似然性，经常是由我们的理论模型提供的，而贝叶斯的框架可以把这个模型的参数迅速的推到出来。&lt;/span&gt;这同时也意味着，果你手里有几个不同的模型假设，有一些数据，贝叶斯会迅速告诉你哪个比较合理。&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;59t31-0-0&quot;&gt;比如你有两个截然不同的假设解释一种心理现象，贝叶斯方法迅速告诉你哪个更合理。&lt;/span&gt;我们通过下面的几个例子说明， 刚刚说了， 我们哟啊建立一个模型， 然后用贝叶斯把它转化为一个预测机器， 模型可以到多简单？ 请看下面的例子：&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;span&gt;1， 多个运动物体例子&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;Image FocusPlugin--unfocused Image--isBlock&quot; data-ratio=&quot;0.7189655172413794&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcfVWt9ibVByEGjUWF8zEKAw6G8nBbLmOjpRibvdBTUicIziaTCyph1aqj5rmRibhOepcyjSMRbqwImFUoQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;580&quot;/&gt;&lt;/p&gt;

&lt;p&gt;Bayesian modelling of behaviour (Weiji Ma)&lt;/p&gt;


&lt;p&gt;&lt;img class=&quot;Image FocusPlugin--unfocused Image--isBlock&quot; data-ratio=&quot;0.27166666666666667&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcfVWt9ibVByEGjUWF8zEKAw6PIWDfviat9RUnpEKZWGTeyFickUCWI3Y4a87gWWEybbH0iaicDoWOSxqew/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;600&quot;/&gt;&lt;/p&gt;

&lt;p&gt;Bayesian modelling of behaviour (Weiji Ma)&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;6cvit-0-0&quot;&gt;如果看到一组一起移动的物体， 比如上图， 人往往会倾向于认为它们是一个整体。这个现象被格式塔心理学解释为一宗天然的心理倾向。 而解释同样的现象， 你只需要搭建一个简单的贝叶斯概率模型：&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;7s7nn-0-0&quot;&gt;1， 找到两种可能的假设和现象， A 上面的五个物体是独立的， 刚好一起向上运动  B  上面的5个物体是一个整体  。 现象：  五个物体一起向上运动&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;3frem-0-0&quot;&gt;2， 找到A和B的先验概率：  先验可以。 基于知识或者大量过去的观测， 那么平时生活经验或者书本都会告诉你， 两种情况可能差距不大&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;7d852-0-0&quot;&gt;3，A和B得到现象的概率， 事实上它测量假设到现象的关联， 在这个情况下， A几乎一定得到现象， B， 如果每个物体向上或向下的概率是0.5， 那么你应该已经求出来了： 1/32&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;e7tph-0-0&quot;&gt;4， 合成后验概率 ：  A压倒B。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;4hcon-0-0&quot;&gt;所以， 我么倾向于认为A是对的，即使A和B都有成立的可能。 由此得到的推论是人有把一起移动的物体看成一个整体的趋势， 这符合格式塔原理。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span data-offset-key=&quot;49ij9-0-0&quot;&gt;2， 运动眩晕&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;du63j-0-0&quot;&gt;类似的方法可以解释很多我们日常生活中的一些现象，比如我们一个非常常见的现象， 晕船。&lt;/span&gt;关于晕船的一个重要的进化心理学理论说， 这是祖先的一个毒物排出反应， 因为祖先在尝到毒物之后会引起眩晕， 而这个时候呕吐可以排出毒物。 进化心理学用这个例子说明我们事实上生活在祖先的记忆感觉里。&lt;/p&gt;

&lt;p&gt;那么， 这个非常简单的模型假设成立的可能是多大呢？ 如果用贝叶斯方法来分析这个问题会有个很清楚的框架。在此处我们先预设眩晕确实是我们的大脑根据现象对世界做出了预测产生的反应， 我们在船舱里产生了眩晕， 我们有三个可能的模型：&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;a8v2n-0-0&quot;&gt;A， 我们的大脑检测到我们自己的运动， 是我们自己的运动导致我们的眼睛和前庭（vestibular） 的感觉&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;dfcs9-0-0&quot;&gt;B， 我们的大脑检测到了地面的运动， 我们自己的运动（摇摆）导致了我们的视觉感知， 而前庭（vestibular）则感觉到了船舱和地面的相对运动&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;2hlva-0-0&quot;&gt;C   我们的大脑检测到了我们吸入毒物。 毒物的作用导致了你自己的运动， 以及你所感知到的地面的剧烈晃动（幻觉）。  &lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;el956-0-0&quot;&gt;贝叶斯的分析框架告诉我们， A， 似然性为0， 因为因果关系是错的， 我们自己的运动只能解释我们的视觉感知。   B,  先验为0， 除非世界末日，我们的祖先几乎不会在车船这类快速运动的物体上活动  C， 这种情况确实会出现在祖先的生活里，先验不为0， 而一旦吸入毒物， 那么确实有可能产生幻觉， 因此似然性不为0 .  所以相对前两者， C最有可能。  当然细心的你会发现这里还是做了太多的假设，尤其对先验， 但是这无疑是一个相对合理的框架。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span data-offset-key=&quot;1g3p9-0-0&quot;&gt;3， 颜色误差&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;Image FocusPlugin--unfocused Image--isBlock&quot; data-ratio=&quot;0.36&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcfVWt9ibVByEGjUWF8zEKAw6B65coY3d19voMDpZe4orr4LVMC10w50ehMFn4T9nvEBCyoyyic0w5eg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;600&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;Image FocusPlugin--unfocused Image--isBlock&quot; data-ratio=&quot;0.6487455197132617&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcfVWt9ibVByEGjUWF8zEKAw6JYRicIOshSnHSQbdibGYCkYMBZNvyGNAcpLkibDKhBZaiaCCgs13sB9W8w/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;279&quot;/&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;88rvr-0-0&quot;&gt;你有没有印象这篇刷爆朋友圈的文章，  这个裙子的颜色是黑色还是金色？ 有的人猜是黑色， 有的人猜是金色，而它到底是什么颜色的？ 没有人知道。 这是不是说明客观世界是不存在的？ 还是说我们发现了一个检测乐观主义和悲观主义者的方法？  如果你在思考前面两个，那么你不懂贝叶斯。  事实上， 这个问题的实质是， 这条裙子的颜色确实是不确定的。 而我们在现实世界中对颜色的判断， 本来就是一个贝叶斯推断。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;129j9-0-0&quot;&gt;我们来看为什么，颜色事实上光谱决定的， 也是不同频率光的成分大小。 这里我们做个简化，我们只有黑白灰。 大家知道， 其实真实世界的物体本身谈不上颜色， 它只是在反射， 而入射光乘以反射率决定了我们看到的样子。 黑色的物体代表反射率为0，   白色的物体是1， 而中间就是灰色。 但是， 你记住， 你的研究只能检测反射光强，这个反射光强等于反射率乘以入射光强。 如果你的眼睛检测到一个反射光强， 而我们的物体识别问题实际上正是想找到反射率这个特征（它才与颜色相关）。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;129j9-0-0&quot;&gt;也就是说，我们的研究遇到一个两难处境。 它所收集的资料反射光强， 既包含反射率， 又包含入射光的信息。 我们得到的是一组反射率和入射光的组合， 那么我们究竟为什么会看到黑白灰的色彩呢？  原因是， 我们的大脑根据先验和似然性， 做了一个贝叶斯推断。  首先， 这里的先验是什么？ 我们在自然界中， 往往会根据时间现场的光线强度等对于入射光强做一个估计， 这个经验数值就是我们的先验（在这里最好把这个经验数值想成一个以最可能的值为中心的高斯分布）。 因为日常生活吗， 总归是在那几种光线下。然后根据刚刚的乘法法则（这个相当于似然性， 你有了反射度和入射光强， 可以完全确定你眼睛的检测光强，一个狄拉克函数）， 你可以推出反射度的后验分布， 这个分布的峰值， 正是你最可能看到的颜色。  &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;/&gt; &lt;img class=&quot;Image FocusPlugin--unfocused Image--isBlock&quot; data-ratio=&quot;0.3416666666666667&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcfVWt9ibVByEGjUWF8zEKAw6dF1FsW8e2icYA47C4OPNm2uWRYH9XnhVrE14vHuticpl98qE5mBL6hLw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;600&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;span data-offset-key=&quot;41g06-0-0&quot;&gt;这个实验解释了那个裙子的颜色问题， 你是看到黑色还是金色， 和你日常经验里对现场光强的先验有关， 看来酒吧里的DG和阳光下的建筑工程师的想法应该不太一样。  而这也在告诉我们， 我们看到的东西永远并非真实，由于我们接受的信息总是有限，我们在不自觉的做大量的脑补， 这些脑补， 组成了我们最终看到的世界。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;cor57-0-0&quot;&gt;你估计还记得旋转舞女的实验吧， 如果你理解了刚刚的颜色问题， 那么这个问题很容易解释。  你看到她是向右还是向左旋转？  不是有人引用来解释左脑还是右脑型人？  你还相信吗？ 旋转舞女是一个典型的信息不全， 而可以容纳不同的解释的问题。虽然说一些八卦的说法并不可靠， 如果人和人之间在对这类问题的回答上真有差异， 说不定会告诉我们一定所从未想到的东西（比如是什么导致了我们的先验？）。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;bntb2-0-0&quot;&gt;你可以举出无数这类脑补的例子，比如为什么一篇英语文章每个单词都只保留首尾字母你还能猜到一些？&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;Image FocusPlugin--unfocused Image--isBlock&quot; data-ratio=&quot;1.3318181818181818&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcfVWt9ibVByEGjUWF8zEKAw6NHqeGib34vQPm3ACQCqyCr9YpBwTyg4lr4xd5FnNlQ7KLSZxN2sQXog/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;220&quot;/&gt;&lt;/p&gt;


&lt;p&gt;&lt;strong&gt;&lt;span&gt;4， 和时间有关的因子预测&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;b7br4-0-0&quot;&gt;贝叶斯方法很擅长解决的一个问题就是和时间有关的因子预设。 假设你经常去以加喜爱的餐厅吃饭， 某一天你突然发现这家餐厅的菜突然就好吃了， 这可能是怎么回事呢？  是不是厨师换了呢？ 然而你没法进到餐厅里去看， 这个时候你会开始回想前几天吃的是不是味道也变化了你没有留意。 &lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;b7br4-0-0&quot;&gt;其实， 这里你已经开始进行一个贝叶斯推断过程了。 假定你每天来吃一次饭， 你想推测某个点开始厨师坏了的概率， 这就是一个经典的点推测问题。  这个问题之所以有难度， 是因为如果你把每次吃饭看作一次测量， 那么测量本身是有噪声的，这使得你比较难做出决断，到底是那天厨师心情不好做坏了饭，还是换了厨师。  这个问题的实用性不用多说， 无论是在医疗健康诊断问题里， 还是某段人际关系的变化（好好一段感情突然就变了？ No， 所有的突然变化都是潜在的蓄谋已久）。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;4qf18-0-0&quot;&gt;那么具体如何做呢?  事实上这已经开始涉及到很复杂的数学，回到贝叶斯本质， 先验在哪里， 似然性在哪里？ 在很多贝叶斯问题， 先验充满主观性， 这里也不例外， 在所有主观里最客观的就是假定它是一个常数， 也就是厨师变化的概率随时间是均匀的。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;4qf18-0-0&quot;&gt; 然后， 似然性呢 ?  似然性就是一个生成模型。 也就是给你一个内在的过程，比如厨师的变化， 然后推导出菜的味道的变化。 一个最简单可以放进去的模型， 就是转化概率随时间独立的马尔科夫过程。 有了这个生成模型， 你还会得到系列不同时间厨师变化假定下吃菜味道的分布。 这就完成了生成模型部分， 后面的工作很简单， 只要按照贝叶斯把它反过来，你就得到了给定观测下， 潜在因子（厨师）在不同时间段发生变化的概率分布。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt; &lt;strong&gt;&lt;span&gt;三 &lt;span&gt;贝叶斯推理究竟告诉我们什么&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;udk1-0-0&quot;&gt;传统的深度学习的特点是大量标注数据驱动的黑箱， 不太考虑概率分布。 而到了深度生成模型的时代，我们必须考虑概率分布， 因此深度生成模型和贝叶斯有着深刻的内在联系。 同时，贝叶斯框架通过结合有效的先验，可以做到用更少的数据达到更好的泛化效果， 也极为的符合深度学习的需求。 两者在网络训练的结合请参考深度贝叶斯&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;ba0s4-0-0&quot;&gt;贝叶斯分析里， 你会发现， &lt;strong&gt;你始终要有一个先验， 一个似然性， 而似然性事实上是某种简单的模型&lt;/strong&gt;（也可以很复杂！）。 事实上我们在我们的思维过程， 主动或被动， 正确或不正确的运用着贝叶斯，你所认可的事实里， 很多是你的推断。同样的客观数据面前，先验或似然性不同的人， 可以得出完全相反的结论。  教条的人可能给予了某个假设一个无限强的先验。 而容易被忽悠的大多数可能用到了过于简单的似然性模型， 比如用好人和恶棍解释很复杂的社会现象。 而自做聪明的人呢？ 可能用了一个对自己有利的解释模型， 而忽略了其它可能。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;ba0s4-0-0&quot;&gt;更多阅读&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span data-offset-key=&quot;ba0s4-0-0&quot;&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651383354&amp;amp;idx=1&amp;amp;sn=133519d77356bdae60ad9388c1f53cb5&amp;amp;chksm=84f3c87bb384416d488770175c676b9061c8168f7c84e10822f186fa8934009c67502279ba72&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-itemshowtype=&quot;0&quot; data-linktype=&quot;2&quot;&gt;贝叶斯大脑&lt;/a&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651382202&amp;amp;idx=1&amp;amp;sn=75d481a667221f328ed44ab76f241451&amp;amp;chksm=84f3cffbb38446edadae25d079a91e5f30592cf67a24e6bf60cf7314f3f60a5860e87cb91240&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-itemshowtype=&quot;0&quot; data-linktype=&quot;2&quot;&gt;趣味贝叶斯推理&lt;/a&gt;&lt;br/&gt;&lt;/p&gt;

</description>
<pubDate>Tue, 26 Mar 2019 16:02:37 +0000</pubDate>
<dc:language>zh-CN</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.jintiankansha.me/t/EY2XU24xDA</dc:identifier>
</item>
<item>
<title>让神经网络变得透明-因果推理对机器学习的八项助力</title>
<link>http://www.jintiankansha.me/t/7xSXhTttBM</link>
<guid isPermaLink="true" >http://www.jintiankansha.me/t/7xSXhTttBM</guid>
<description>&lt;p&gt;如今的AI已经能够在Dota2这样的对战游戏中战胜人类了，但游戏主播和解说却不需要担心自己失业，因为当前的神经网络还无法解释自己为何做出决定。我们可以训练另一个神经网络，对前一个神经网络做出的每一个决定，来预测人类会给予其什么样的解释。还拿Dota2举例子，可以训练一个神经网络，对操作游戏的AI点的每一个技能，买的每一个装备，去猜测人类会给予怎么解释。但当AI进化出人类想不到的策略时，就像围棋中Alpha Go已经能够走出人类棋手想不出的套路，上述策略就不行了。&lt;/p&gt;

&lt;p&gt;&lt;img data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibceE1piajBpf3TqrYxHmeibImWckebOwWJ4fsd31zBMibQVet43icCpicq509m0AAGXoDATR6LAql1KIfEQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; class=&quot;&quot; data-ratio=&quot;1.4970059880239521&quot; data-w=&quot;334&quot; /&gt;&lt;/p&gt;

&lt;p&gt;本文是《Possible Mind》（&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651384215&amp;amp;idx=1&amp;amp;sn=bd8e32534f656af0aecc8cba60b1a608&amp;amp;chksm=84f3c7d6b3844ec053cc3b7d853b18f8754135c8e074fd22ae2ca58cb76e82554aef9b13e111&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-itemshowtype=&quot;0&quot; data-linktype=&quot;2&quot;&gt;点击查看相关的读书笔记&lt;/a&gt;）系列读书笔记的第三篇，围绕因果推理的创始人，&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651383568&amp;amp;idx=1&amp;amp;sn=fb2a6857f18cf4de917111406ef9bd4f&amp;amp;chksm=84f3c951b3844047e23a00d5aca0f9acac4aa27580dabfa7096401a166b9ad3196b34de9d251&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-itemshowtype=&quot;0&quot; data-linktype=&quot;2&quot;&gt;《The book of why》&lt;/a&gt;的作者Judea Pearl的题为“The limitation of opaque machine learning”，延伸而写成。当前神经网络缺少解释性，其成功的原理是如魔法一般的黑盒子。当前提升模型解释性的方法，无论是注意力机制，对模型进行压缩，用线性的浅层的模型来模拟深层的模型，还是对隐藏层的权重可视化展示，都只是隔靴搔痒，无法带来质变。本文基于Judea Pearl的随笔以及他去年12月的一篇论文整合而成，先说明可解释的重要性，再讨论因果推理带来的本质改变，再详述因果推理对深度学习带来的八大助力。&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-ratio=&quot;0.5215736040609137&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcc6X0PFMnnyvydl7OaIk5BFoSUOFGsoGM4fGOgfiaU7oP7SBm1qzg8Ic3sicYT0ZVll1OKdKK5e584A/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;788&quot; /&gt;&lt;/p&gt;

&lt;p&gt;当扫地机器人遇到上图的情况，卡住了，如果其内部的AI能够正确的给出为何会卡住的解释，那下次机器人就会避免不平的环境，不管造成不平的是地毯还是掉在地上的衣物，这就提高了模型的可扩展性。能够给出解释，还可以帮助人更好与AI协作，假设每次扫地机器人能够告诉人自己今天因为那种原因卡住了，从而多花了多少分钟才扫完屋子，那这家的主人就可以下一次避免让家里出现地面不平的情况，从而让机器人能够更高效的工作，节约能源。而机器具有因果推理后，还会学到是自己清扫地毯的角度，使得地毯打折从而使得地面不平的，从而下次用其他的角度去清扫地毯覆盖的地方。&lt;/p&gt;

&lt;p&gt;这些都是实际的好处，而在《Possible mind》这本书中，借用哲学家Stephen Toulmin在1961年的书《Foresight and Understanding》中的对比，引入了巴比伦和雅典科学的区别，同样是预测天体的运行，四季的节律，巴比伦的预测在精确程度和一致性上都好过同时代的雅典人，但雅典的预测背后有神话去提供解释，并且当一种解释比另一种解释更符合时，前者会战胜后者，巴比伦式的精准预测，没有带给这个文明天文学，而古希腊则孕育了现代科学。&lt;/p&gt;

&lt;p&gt;类似的还有李约瑟之问，为何古代中国没有发展出科学，尽管其很长的一段时间中技术是领先全球的。比如勾股定理，明明中国人早在《周髀算经》中就有所记录，但西方人却称之为毕达哥拉斯定理。这里的区别在于前者只是从经验的层面记录了这个现象，而后者是对此给予了普遍化的证明。用机器学习的视角来看，前者无法确定这个规律的可扩展性如何，而后者保证了在所有的宇宙中，该规律都是适用的。&lt;/p&gt;

&lt;p&gt;借用这个对比，当前的深度学习，尽管取得了突飞猛进的进展，但由于其缺少可解释性，不透明，还是属于巴比伦式的。即使其在所有的游戏上，都战胜了人类，都需要花更少的能源即时间去训练，也不能算是能匹敌人脑的强人工智能。雅典的天文学者，可以根据自己的理论，去设计一个实验，来估算地球的半径，还和真实的结果相差不多，而巴比伦式的不透明的“天文知识”，则根本不会问出这样的问题。当今的大数据，不会用虚假的概念来讲故事，而根据《人类简史》中的论述，正是想象出的共同体，使得人类走进了文明时代。&lt;/p&gt;

&lt;p&gt;按照Judea Peral的分类，&lt;span&gt;认识世界分三个层次&lt;/span&gt;，最低的是关联，只需要观察就好，例如那些症状告诉医生这个人患病了，那些行为告诉我这个人容易被促销打动；再上一层是干预，也就是去通过行为去改变世界之后，看会发生什么，这个层次要回答的问题是吃药能不能治病，而最高的层次是反事实的推理，要达到这一层，需要想象力，需要反思，要回答的问题是如果我之前多一些锻炼，现在是不是就不会生病。&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-ratio=&quot;0.4044526901669759&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcc6X0PFMnnyvydl7OaIk5BFxWUOzYB4LibnMGkdNSe2zn74SnJzHMnRvGCtZ9226cutBZ2S1qeJYGg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1078&quot; /&gt;&lt;/p&gt;

&lt;p&gt;当前的有监督学习，是站在了认知阶梯的第一层，强化学习由于和坏境有所互动，是站在了第二层上，通过无监督学习，去预测下一秒会发生什么，根据类比来推测位置的情况，也是介于第一层和第二层之间的。不论是那种学习范式，都是基于统计的，得出的结论是概率性的。正如同不懂得证明勾股定理，永远也无法百分之百打包票说这个规律是普世的，当前基于统计的机器学习，如同三体中被智子锁死的地球科技，看似进步神速，但总会碰到天花板。&lt;/p&gt;

&lt;p&gt;Judea Pearl给出的解药是他发明的公理化式的因果推理图，想要详细了解的推荐下面的免费课程，&lt;span&gt;edx&lt;/span&gt;&lt;span&gt;平台上的，名为&lt;/span&gt;&lt;span&gt;Causal Diagrams: Draw Your Assumptions Before Your Conclusions。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.46193265007320644&quot; data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-w=&quot;1366&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibceE1piajBpf3TqrYxHmeibImWH4Zs7x6s6ZVY1ODPsY9vzs4zTme2ibBCM1aqicmicl4jM1p0ERNa3OiaTw/640?wx_fmt=png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;那如何机器学习在中加入因果推理了？回答是结构化因果模型（Structural Causal Models，下文简称SCM），通过有向图的形式，对常识中的因果作用方向的假设做结构化的建模，例如下图中x代表是否采取实验疗法，y代表从癌症中康复，z代表性别，那么对世界的模型就是性别可以决定一个人是否更可能会选择实验疗法，是否更容易从癌症中康复，但反方向的因果却是不现实的。&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-croporisrc=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcc6X0PFMnnyvydl7OaIk5BFkmIdVhnicKHGQYTyub3mlicxY5lTTz2ibIZ5BVOoYXQ6DSEdtjuDv1UZA/0?wx_fmt=png&quot; data-cropx1=&quot;0&quot; data-cropx2=&quot;364&quot; data-cropy1=&quot;13&quot; data-cropy2=&quot;124&quot; data-ratio=&quot;0.3076923076923077&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcc6X0PFMnnyvydl7OaIk5BFel6zNBrX1FuaFPE8xN15j0oer3GKTicFFpmtm7M3J0J0uD4POqaURPg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;364&quot; /&gt;&lt;/p&gt;

&lt;p&gt;有了因果图，那SCM就可以根据提问，来计算一个和因果推理的问题，究竟有多少数据的支持，不管这个问题位于上述的认知阶梯的第几层，都能够给予回答。这里的&lt;img class=&quot;rich_pages&quot; data-croporisrc=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcc6X0PFMnnyvydl7OaIk5BFWq1RlL2E9ySJjEkseRibSshqKcKKTjmTmguvnRBPhUtIRNriauX7npCw/0?wx_fmt=png&quot; data-cropx1=&quot;0&quot; data-cropx2=&quot;209&quot; data-cropy1=&quot;6&quot; data-cropy2=&quot;35&quot; data-ratio=&quot;0.13875598086124402&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcc6X0PFMnnyvydl7OaIk5BF1skbnL0pdd07gt5DyDqecNgQE8uGdoFfPgZ2oFaj0e6wcokLm8cnOw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;209&quot; /&gt;，也就是考虑不同性别下是否采取实验疗法对癌症康复的概率，而根据深度学习的模型，可以估算出真实的状况下的概率，如果发现俩者的差距很大，那因果推断的模型就可以对实验疗法导致癌症康复这个因果论断给予反驳，说明这是没有事实依据的，而不是只说明实验疗法和癌症治愈缺少统计显著性。&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-ratio=&quot;0.5781893004115226&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcc6X0PFMnnyvydl7OaIk5BFhdzw631DGKqudv649xN39sTpUam05u3XianZjiaxkAuPdX4KhZetEoAA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;486&quot; /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;那这对于解决当前机器学习缺少解释性的问题，又什么本质的改变了？这里列出Judea Pearl的八条回答：&lt;/p&gt;

&lt;p&gt;首先是让机器做的假设以人类容易理解的方式（因果图）呈现出来，从而&lt;span&gt;让模型更加透明&lt;/span&gt;，也让测试模型的推论的后人能够更精准的去检验模型的鲁棒性。可以说只有能够解释清楚自己每一步的推理的逻辑，模型才算具有了可证伪性，否则即使有一个不符合模型预测的事件，由于不确定其和模型的因果假设有什么关系，又该怎么区分这究竟是应该被去除的噪音还是能推翻整个认知模型的反例。&lt;/p&gt;

&lt;p&gt;第二点是通过因果推断，&lt;span&gt;去除混杂因素的影响&lt;/span&gt;。当前的机器学习，重要先进性数据清洗，特征提取，往往花在特征工程上的时间占到了全流程的大头。有了因果推断，就不必人，来根据常识去掉那些可能影响相关性的混杂因素，从而在更复杂的坏境下，做到端对端的学习。这使得模型能够超越建模者的认知局限，从而模拟真实坏境更复杂的相互作用。&lt;/p&gt;

&lt;p&gt;第三点是算法化的&lt;span&gt;回答反事实的问题&lt;/span&gt;。人类能够区分出充分条件和必要条件，能区分cause of effect与effect of cause，例如小明酒后游泳溺水而死，游戏是小明死亡的必要而不是充分条件，要回答这样的问题，就需要进行反事实的思考，去幻想如果小明没有游泳会怎样，如果游泳时小明没有喝酒会怎样。如果机器能够做这样的思考，那AI思考的模块化程度就会进一步提高，需要的训练数据也会减少，对于跨领域的迁移学习也会有所助力。&lt;/p&gt;

&lt;p&gt;第四个助力是&lt;span&gt;区分直接和间接的诱因&lt;/span&gt;，如果只有关联分析，那在较长的时间尺度上，就会面临如何区分是否之前的决定带来了奖励的问题，但如果能够将因果关系描述出来，并且根据数据来评价每一条因果链条的坚固程度，那就能够去解决强化学习中在较长的时间尺度上，该如何分配奖励的问题。区分了直接的诱因与通过第三方作用间接的影响，就能够判定数据中那些异常点处在间接影响的链条上，受到未知因素的影响，属于噪音，而对于处于直接因果链条上的，则异常不应该被视作是噪音，而是可以证伪模型的“黑天鹅”。&lt;/p&gt;

&lt;p&gt;第五个助力是&lt;span&gt;模型具有跨领域的适用性&lt;/span&gt;，还能够通过其他领域来验证该模型的鲁棒性。如果一个通过强化学习的智能体在一种游戏中表现优异，那预期换一个游戏，该模型也不会表现的太差，这种能力被称为domain adaptation，人类就有这个能力，例如dota玩的好的人，玩英雄联盟也不差。如果智能体是通过因果推理，来决定下一回合的policy，那这个思考过程就更像人类做决定时的所思所想，由此类比推出，智能体也会具有更好的domain adaptation。&lt;/p&gt;

&lt;p&gt;第六个助力&lt;span&gt;避免sampling bias&lt;/span&gt;，正如人类的认知偏见会让人丢掉那些对支持自己结论不适合的数据，人类在对机器建模时，也会展现出类似的认知偏见。如果机器具有了公理化的因果推理，那通过反事实的问题，就可以指出人类可能受到了采样偏见的影响。这指出了人机协作的新的可能性，不是机器只懂得找出相关性，从而指数级的放大人的认知偏见，而是机器根据人对世界的建模，去帮助人做人类不擅长的用数据找出偏见，从而带来一个更公平的模型。&lt;/p&gt;

&lt;p&gt;第七个助力是通过因果模型，来&lt;span&gt;判定数据集中是否存在数据缺失的问题&lt;/span&gt;。例如建模者以为女性不擅长数学，那用来训练该录取那个学生的分类器时女性申请者的样本就会很少，从而使得基于统计相关的模型预测女生不应该录取到数理相关的专业。但对于基于因果判定的模型，那只要对世界的假设中包含性别会影响是否报名数理相关专业这个因果联系，那模型就能够根据数据判定出这里存在着可能的数据缺失，从而提醒建模者注意。&lt;/p&gt;

&lt;p&gt;第八个助力是去&lt;span&gt;发现因果关系&lt;/span&gt;，例如遗传学中的孟德尔随机，就是利用了基因在有性生殖中自然会发生重组，来区别到底基因的差距与人身体表现出来的胖瘦高矮这样的表型到底是因果性还是相关性。现实中存在着诸多类似孟德尔随机的自然形成的与随机双盲实验等价的场景，通过让模型具有因果推断能力，就能够发现未知的因果关系。&lt;/p&gt;
&lt;p&gt;&lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;&gt;&lt;/ins&gt; &lt;img class=&quot;&quot; data-ratio=&quot;0.4863498483316481&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcc6X0PFMnnyvydl7OaIk5BFjuZl8uM1icZrPsLAef5gOxzIcwGK0GEkmibArREh39o98G0ibEztsXWVw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;989&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;附图是孟德尔随机的示意图&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;总结全文，当前的深度学习，这样model free的模式，无法达到人类水平的智力，只有增加了因果推断，才能像科学的精神孕育出持续不断的发现那样，让机器学习走到之前无法企及之地，例如上文列出的八种具体任务，都需要更高层次的思考。当前的深度学习，模型缺少解释性，可迁移性，也不够鲁棒，会由于一个像素的改变而彻底改变分类的结果。&lt;span&gt;所有的指数级增长都会有尽头，当前深度学习取得的成就，大多&lt;/span&gt;只是依赖计算资源和训练数据的指数化增加，&lt;span&gt;只有不断站在更高的认知阶梯，通过&lt;/span&gt;自我指称获得的递归式的思考，才是无限的增长模式。因此将因果模型引入下一代人工智能中，是充分且必要的。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;需要注意的是，因果推断的模型，依赖与建模者去根据常识或本领域背景，给定对因果关系运行的方向，如果这个假设有问题，那模型是无法从数据中发现人类建模者犯了因果倒置的问题的，这说明不管多么先进的模型，都需要建模者的智慧参与其中。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;参考文献：&lt;span&gt;The Seven Tools of Causal Inference with Reflections on Machine Learning&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;更多阅读&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651384252&amp;amp;idx=1&amp;amp;sn=bdc733e516f25b44a1b7bdfb6104d2b5&amp;amp;chksm=84f3c7fdb3844eeb9f82b2f7e0590f3514f5b9887c279ccdd5919004b59a8686353a85670742&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-itemshowtype=&quot;0&quot; data-linktype=&quot;2&quot;&gt;信息的俩种定义&lt;/a&gt;&lt;br /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651384244&amp;amp;idx=1&amp;amp;sn=b7ea9482daef936f6f433719ad419097&amp;amp;chksm=84f3c7f5b3844ee35fb7a98ae317ed19ea32a5e79f1529a8d0c7da2bfb361545443b03f0f5ba&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-itemshowtype=&quot;0&quot; data-linktype=&quot;2&quot;&gt;如何让神经网络具有好奇心&lt;/a&gt;&lt;br /&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651384215&amp;amp;idx=1&amp;amp;sn=bd8e32534f656af0aecc8cba60b1a608&amp;amp;chksm=84f3c7d6b3844ec053cc3b7d853b18f8754135c8e074fd22ae2ca58cb76e82554aef9b13e111&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-itemshowtype=&quot;0&quot; data-linktype=&quot;2&quot;&gt;读《Possible Mind》，看25位大咖谈AI&lt;/a&gt;&lt;br /&gt;&lt;/p&gt;
</description>
<pubDate>Sat, 23 Mar 2019 11:56:59 +0000</pubDate>
<dc:language>zh-CN</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.jintiankansha.me/t/7xSXhTttBM</dc:identifier>
</item>
</channel>
</rss>