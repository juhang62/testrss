<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="css/feed.xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/" xmlns:og="http://ogp.me/ns#">
<channel>
<atom:link rel="self" href="http://192.168.1.4/fivefilters/makefulltextfeed.php?url=feed43.com%2Fchaoscruiser-jtks.xml&amp;max=5&amp;links=preserve&amp;exc=1" />
<atom:link rel="alternate" title="Source URL" href="http://feed43.com/chaoscruiser-jtks.xml" />
<atom:link rel="related" title="Subscribe to feed" href="http://www.subtome.com/#/subscribe?feeds=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed43.com%252Fchaoscruiser-jtks.xml%26max%3D5%26links%3Dpreserve%26exc%3D1&amp;back=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed43.com%252Fchaoscruiser-jtks.xml%26max%3D5%26links%3Dpreserve%26exc%3D1" />
<title>混沌巡洋舰</title>
<link>http://www.jintiankansha.me/column/ultiWL8Axg</link>
<description>混沌巡洋舰 - 今天看啥</description>
<ttl>360</ttl>
<item>
<title>AI中的幂率法则-通过Scaling来看AI的未来</title>
<link>http://www.jintiankansha.me/t/9eQ8xd2rMJ</link>
<guid isPermaLink="true" >http://www.jintiankansha.me/t/9eQ8xd2rMJ</guid>
<description>&lt;p&gt;这篇小文是源于《Possible mind》这本书的最后一篇随笔，上面是这个系列的前作，对于这本书感兴趣的小伙伴，这本书在今年7月将会由湛卢出版中文版的。&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651384297&amp;amp;idx=1&amp;amp;sn=27d3e3d3f0bbe0557c784f443014f9dd&amp;amp;chksm=84f3c7a8b3844ebe62cce0a60474c5d6dcb49af2d03598b93fd073a4095de500630aeb847ca6&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-itemshowtype=&quot;0&quot; data-linktype=&quot;2&quot;&gt;《Possible Mind》读书笔记-强人工智能的公理化思考&lt;/a&gt;&lt;br /&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651384268&amp;amp;idx=1&amp;amp;sn=07488417ce770804c65a42411735f94b&amp;amp;chksm=84f3c78db3844e9bf479069e7168e0756d9c2854120223650bad38128bd4d19f1f19545fb0f5&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-itemshowtype=&quot;0&quot; data-linktype=&quot;2&quot;&gt;让神经网络变得透明-因果推理对机器学习的八项助力&lt;/a&gt;&lt;br /&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651384252&amp;amp;idx=1&amp;amp;sn=bdc733e516f25b44a1b7bdfb6104d2b5&amp;amp;chksm=84f3c7fdb3844eeb9f82b2f7e0590f3514f5b9887c279ccdd5919004b59a8686353a85670742&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-itemshowtype=&quot;0&quot; data-linktype=&quot;2&quot;&gt;信息的俩种定义&lt;/a&gt;&lt;br /&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651384215&amp;amp;idx=1&amp;amp;sn=bd8e32534f656af0aecc8cba60b1a608&amp;amp;chksm=84f3c7d6b3844ec053cc3b7d853b18f8754135c8e074fd22ae2ca58cb76e82554aef9b13e111&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-itemshowtype=&quot;0&quot; data-linktype=&quot;2&quot;&gt;读《Possible Mind》，看25位大咖谈AI&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;当要解决的问题的规模指数化变化时，总会有哪些特征是线性变化的。幂率法则要告诉你的就是这些特征是存在的，幂率法则的道理由于其简单，因此变得极其具有普适性。（关于幂率法则，参考&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651382599&amp;amp;idx=1&amp;amp;sn=6685868146b23306992836c3abd77ab1&amp;amp;chksm=84f3cd06b384441063d08c6efacbdde5e8c3cd177b37f3a30fc70a037eb1ac31ecb704f21dee&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-itemshowtype=&quot;0&quot; data-linktype=&quot;2&quot;&gt;“Scale” 读书笔记-天下之大作于细&lt;/a&gt;)  当我们将AI的发展放到幂率法则的视角下，会发现历史上的AI低谷对应问题规模增加后带来的复杂度，而高潮则对应通过找到指数级增长中的线性特征来应对复杂性。&lt;/p&gt;

&lt;p&gt;例数历史中的AI低谷，首先是专家系统的预先设定的知识无法跟上现实问题的复杂性而衰落；之后是单个神经元的感知机无法应对非线性，之后是多层神经网络无法应对现实中非结构化的数据，而当前的深度学习热，也由于缺少解释性，模型的稳定性以及对常识与背景的理解，而有可能跌入低谷。&lt;/p&gt;

&lt;p&gt;说起深度学习的成功，算力的提升和数据量的增加是其俩大成功要素，而这俩点都依赖于香龙在信息论提出的数字化编码的通信系统具有的纠错能力。香龙发现，在数字化的通讯方式（例如用二进制），只要传输的数据中的噪音所占的比例低于一个阀值，那通过线性的增加传输数据的通量，可以指数级的减少整体信息出错的概率，直到信息传递的错误变得在实际中不可能出现。假设你要传递一个信息，你为了避免信息在传递中出错，你可以叫多个人来传递，人越多，总体信息出错的概率是指数级而不是线性下降的。这意味着传输的通道增加，带来的可以传递的信息数量是指数化增长的。如果随着越来越多的微电子元件，计算中传递的中间变量也等比例的出错，那就不可能会有摩尔定律。而随着通信的价格指数化的降低，更多的人将生活中越来越多的部分数字化，从而带来了可供处理的数据的指数化增加。&lt;/p&gt;

&lt;p&gt;除了以上的俩个维度，幂率法则在AI中的应用还体现在模型复杂度的线性增长带来了模型容量的指数级增长。当神经网络变得更深，在应对数据时可以使用的规则是之前规则和新增规则的俩俩组合。深度学习中常见的维度灾难，说的是待处理的数据有太多的维度，导致数据分布的很稀疏。而解决方法是将对问题的最优解的全局搜索变成局部受限下的搜索。剪纸的想法不新鲜，但深度学习通过逐步迭代的方式，将问题用一组可能不是最写实，但却最有利于解决问题的特征表示了出来。当OpenAI战神人类的dota选手时，机器眼中的地图是一个个的矩阵，虽然要解决的问题包含的可能性要多于宇宙中的原子。但将问题映射到便于问题解决的规律却是线性的。&lt;/p&gt;

&lt;p&gt;而当前机器学习缺少解释性的缺陷，我们的大脑中的种种决策，其背后的逻辑也是在外界看来是个不透明的黑箱。但为了让人类相互协作，相互共情，需要解释的是人类做出的行为，而不是行为背后的机理。这指出了应对机器学习模型指数化增加后带来的复杂性的方法，通过训练新的神经网络，来将元模型的行为归类到线性增长的框架中，从而解释模型做出的决策的目的因，而不是模型如何做出决策。&lt;/p&gt;

&lt;p&gt;AI要挑战的终极指数级增长，是如何用一个线性增长的规则合成出能够指数化扩展的自身。这方面自然界给出的例子的生物发育中，人具有的复杂性是指数级增长的，但如何制造人的基因却就是那么长。自然的解法是将发育的过程分成很多步，然后通过HOX基因来调控所有和发育有关的基因。当机器可以直接操纵物质世界中的基本粒子，来重构自身，涌现与进化的闭环就如同咬住自己尾巴的蛇，从原子到分子，从分子到细胞，再到组织，器官，生物体，互联的智能体，最后回到原子。&lt;/p&gt;

&lt;p&gt;通过幂率法则看待AI的历史，是将复杂系统的理论来解释为何复杂的系统是必然会发生的。当我们自身遇到指数化增长的选项的时候，也要看出其中那些因素是线性变化的。所谓的万变不离其宗，说的就是这个道理。&lt;br /&gt;&lt;/p&gt;
</description>
<pubDate>Sun, 21 Apr 2019 17:07:51 +0000</pubDate>
<dc:language>zh-CN</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.jintiankansha.me/t/9eQ8xd2rMJ</dc:identifier>
</item>
<item>
<title>GAN的五个神奇应用场景</title>
<link>http://www.jintiankansha.me/t/ut0yzl0oXL</link>
<guid isPermaLink="true" >http://www.jintiankansha.me/t/ut0yzl0oXL</guid>
<description>&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.5039745627980922&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibccpZBbGf9HicIlJ9xNX1wImptoTntHRWibc2DKXtPvcUrGT46E9nSnTgHE3SE2gotHYibvcJMe3EH97Q/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;629&quot; /&gt;&lt;/p&gt;

&lt;p&gt;上图中的图片有什么共同点？回答是这些脸都是虚构的，是由GAN（对抗神经网络）生成的。自从2014年第一次提出之后，做为一种生成式的模型，不到五年的时间，GAN已经衍伸出很多意料之外的应用场景，本文简述其中五个，未来预期GAN会在更多的领域大放异彩。关于GAN的基础知识，可以参考&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651383280&amp;amp;idx=1&amp;amp;sn=a6fd903f2c47339c52dcea9eedf65851&amp;amp;chksm=84f3cbb1b38442a7f4aac491852e06c34794154946a3656bc4ac4805b1ef1b41cb4469ae8419&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-itemshowtype=&quot;0&quot; data-linktype=&quot;2&quot;&gt;对抗神经网络初探&lt;/a&gt;，GAN用在艺术品生成与风格迁移的具体案例分析，可以参考&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651383188&amp;amp;idx=1&amp;amp;sn=ec8d1090fe46741c14ccf7cc02b57c2c&amp;amp;chksm=84f3cbd5b38442c33ef70b698dd07f5b7aa954623fe3724e9f83b8e10a44b86a3777054395a4&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-itemshowtype=&quot;0&quot; data-linktype=&quot;2&quot;&gt;怎么样用深度学习取悦你的女朋友（有代码）&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;&lt;span&gt;&lt;strong&gt;1）图像编辑&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.3046875&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibccpZBbGf9HicIlJ9xNX1wImpibxozsleicRf8xpibetUEqojxAlsKLpNvKSD8UHJUUA4UMx2UVtE6c8Hg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;768&quot; /&gt;&lt;/p&gt;
&lt;p&gt;这简直是美图秀秀中的各种滤镜的升级版，给出一张原始的妹子图片，可以生成出金发版，卷发版，微笑版，还能ps出你的双胞胎兄弟长什么样。&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.2776470588235294&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibccpZBbGf9HicIlJ9xNX1wImpicms4hLEk6kaQpg3NhGPicW7Ebd3ObPQZEIL6qiaibibhYoymFFgkEebbFQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;850&quot; /&gt;&lt;/p&gt;

&lt;p&gt;不止是对人物进行定向的修改，还能修改图片中的坏境因素，例如上图中左图中是下雨的场景，右图是GAN生成的同样坏境但是没有下雨的照片，俩者人眼看来，就只能看出是否下雨这一个差异来。实现这样黑科技的，是GAN的一个变种，称为conditional GAN， 有了这项技术，就可以根据一个人小时候的照片，生成其长大后，年老后的样子，或者你上传你家狗狗的照片，然后再虚拟的坏境下给狗狗换衣服，然后你再购买你喜欢的狗狗衣服。这项技术也存在着被滥用的风险，比如生成虚拟的果照。关于技术细节，请阅读参考资料【1】与【2】。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;span&gt;2）恶意攻击检测&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;通过给深度神经网络一些特异生产的训练数据，深度学习生成的模型是可以被黑客攻击，利用甚至控制的。为了对抗这样的逆向攻击（adversarial attacks），可以训练对抗神经网络去生成更多的虚假训练数据作为假想敌，让模型在演习中去识别出这些虚假数据，就如同人类打疫苗，GAN生成的虚假数据让正在做分类的模型更加稳健。&lt;/p&gt;

&lt;p&gt;另一个在安全领域的应用的加密传输，在图片中，可以使用额外的像素来加密一段文字，从而你以为你接收的是一副普通的图片，但实际上通过解密，却可以发现其中包含了加密的信息。GAN的变种SSGAN，通过在传统的GAN模型中增加一个判别器，可以识别出这样加密后的图像，也可以用于更高效生成上述的加密信息。参考【3】&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-ratio=&quot;0.48792270531400966&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibccpZBbGf9HicIlJ9xNX1wImpgMvx77uaDrbhdsJxMs7MXoKJibbzIkl9wTZc9GGXgG7kNzU33kD1v7Q/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;621&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;span&gt;3）数据生成&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;在特定的应用场景下，例如医疗领域，缺少训练数据是应用深度学习的最大障碍。数据增强的传统做法是将原图像拉伸旋转剪切，但这毕竟还是原来的图像，通过使用GAN，能够生成更多类似的数据，如下图所示，右边是真实的图片，而左边是合成的训练数据，中间的是GAN生成后原始图片，之后经过了修饰，使得面部的肌肉和纹理更加真实。这个GAN生成的图片，通过了图灵测试，让眼科医生都无法分辨出。而随着生成出的数据被加入训练集，相同的模型在分类任务上的表现也有所提升，具体参考【4】。&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-ratio=&quot;0.3567251461988304&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibccpZBbGf9HicIlJ9xNX1wImpC1hzfPgQk6DEZ1Hb7c2cCxugLBRAMBoricpr6sAvrES9qvnM3eKtNow/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;342&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;span&gt;4）注意力预测&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;人类在看一张图片时，往往只关注特定的部分，而通过GAN模型，可以预测出人类关心的区域在哪里，下图展示的SalGAN预测出的图片中人类观测的热点区域，和真实的区域，以及之前模型的对比。SalGAN的预测不止更准确，而且能够包含很多之前模型没有预测到的区域。对注意力的预测，可以指导广告的投送，例如在电影中做植入广告前，可以先预测一下植入的区域是不是在注意力的热点区。类似的方法还可以反过来用，假设不同类型的人有不同的注意力热点模式，根据一个人关注图片中的那个部分，来对人进行归类。参考【5】&lt;/span&gt;&lt;strong&gt;&lt;span&gt;&lt;br /&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-copyright=&quot;0&quot; data-ratio=&quot;1.0885416666666667&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibccpZBbGf9HicIlJ9xNX1wImpWf4BsxOsENqRTTONtWNnEbsWhRk09BrfVJwqDcricksmLhjYH8Oib01w/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;768&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;span&gt;5）三维结构生成&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;img class=&quot;&quot; data-croporisrc=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibccpZBbGf9HicIlJ9xNX1wImpkbEaNCb1SkKe0kQ7FbvVjicovlwpK8NSwjOvWpcOdfur7gvLcFeudOA/0?wx_fmt=png&quot; data-cropx1=&quot;0&quot; data-cropx2=&quot;673&quot; data-cropy1=&quot;0&quot; data-cropy2=&quot;1231.0089928057555&quot; data-ratio=&quot;1.8276374442793462&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibccpZBbGf9HicIlJ9xNX1wImphoLlQnm3Jgwzib5XicY71ZBFibtx88ld99P8WdxwPq5d9ib8NCGIsRYCHw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;673&quot; /&gt;&lt;/span&gt;&lt;/p&gt;


&lt;p&gt;总结&lt;/p&gt;
&lt;p&gt;标注数据总是少数的，未标注的数据才是待开掘的金矿。GAN可以通过标注数据，生成模拟数据，也可以用在自监督学习中，让模型具备从部分标记的数据中学习的能力。本文只是列出了在图片上使用GAN的五种有趣的场景，在视频，有向图及自然语言处理上，GAN也有诸多应用，结合贝叶斯网络，GAN还可以应用在因果推理，参考文献【7】。&lt;/p&gt;


&lt;p&gt;&lt;span&gt;参考文献&lt;/span&gt;&lt;br /&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;【1】https:&lt;/span&gt;&lt;span&gt;//github.com/hezhangsprinter/ID-CGAN&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;【2】 https:&lt;/span&gt;&lt;span&gt;//arxiv.org/pdf/1611.06355.pdf&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;【3】 https:&lt;/span&gt;&lt;span&gt;//arxiv.org/ftp/arxiv/papers/1707/1707.01613.pdf&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;【4】 https:&lt;/span&gt;&lt;span&gt;//arxiv.org/pdf/1612.07828.pdf&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;【5】 https:&lt;/span&gt;&lt;span&gt;//arxiv.org/pdf/1701.01081.pdf&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;【6】 https:&lt;/span&gt;&lt;span&gt;//github.com/maxorange/pix2vox&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;【7】 https://arxiv.org/pdf/1810.07406.pdf&lt;/span&gt;&lt;/p&gt;
</description>
<pubDate>Sat, 13 Apr 2019 10:53:23 +0000</pubDate>
<dc:language>zh-CN</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.jintiankansha.me/t/ut0yzl0oXL</dc:identifier>
</item>
<item>
<title>当机器学习遇上进化算法</title>
<link>http://www.jintiankansha.me/t/ctzlXu0ZQQ</link>
<guid isPermaLink="true" >http://www.jintiankansha.me/t/ctzlXu0ZQQ</guid>
<description>&lt;p&gt;&lt;span data-offset-key=&quot;d5ucb-0-0&quot;&gt;进化，是生物智能演化的原动力。 学习， 是人类文明产生的原动力，也是当下红红火火的AI进步的原动力。 如果这两种神秘的力量结合， 我们会得到一个怎样的物种呢？虽然说这方面的尝试还不多， 不过我们已经可以在一些过去人的研究中见出端倪。 &lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;3l2r6-0-0&quot;&gt;首先，我们说两种算法的本质都是在做优化。 在充满随机性的世界里， 大部分的自然过程趋势是熵增，耗散，或者说随机性的增加。而唯有生物的进化和学习，却可以抵抗这种趋势，在随机中产生有序，产生结构。 &lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;mot5-0-0&quot;&gt;虽然都在做优化， 它们的优势和缺点也非常明显。  &lt;/span&gt;让我们来概述一下两种方法的核心。 &lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;1nhp4-0-0&quot;&gt;&lt;strong&gt;&lt;span&gt;进化算法vs机器学习&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;d6sib-0-0&quot;&gt;进化算法&lt;/span&gt;&lt;span data-offset-key=&quot;d6sib-0-1&quot;&gt;：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span data-offset-key=&quot;ea40g-0-0&quot;&gt;进化算法建立在基因之上，基因 - 可以理解为生命在各种条件下的一组行为策略。比如吃什么， 向什么方向移动，肤色的选择等。 这组策略被一套叫DNA的大分子固定， 也就是我们常常说的遗传编码 ， 它通过一个复杂的化学反应， 制造RNA和特定的蛋白质，而一切生命现象都是由特定蛋白质实现的， 我们简单的说就是生命策略， 比如在外界环境出现如何变化时候如何反应。 你可以把DNA的编码看成一系列的if else语句， 就是在某种条件下， 触发某个蛋白质， 实现某一个功能。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;Image FocusPlugin--unfocused Image--isBlock&quot; data-ratio=&quot;0.5166666666666667&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcebdNQcqmFd7cGXNcVMicbuUm28E0usZSQZpFdSE3NmGF9DUZ3KvPmSVU42OT6ruCf2icCJUaLLQdcQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;720&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;span data-offset-key=&quot;4o7te-0-0&quot;&gt;那么进化算法包含以下要素：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;span data-offset-key=&quot;d1jn4-0-0&quot;&gt;1，生物通过基因编码生存策略。 基因即一组可以编码蛋白质的生物大分子。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span data-offset-key=&quot;f6mpe-0-0&quot;&gt;2， 单组策略的存在时间有限， 它会以繁殖的形式得到一个和自己一样的策略， 但是这个过程不是完全精确的， 它会以一定的方式出错或者说变化， 这恰恰使得下一代的策略可以轻微的偏离上一代。 从而在一段时间里， 形成越来越多的策略，我们叫做基因池。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span data-offset-key=&quot;514bc-0-0&quot;&gt;3， 有的时候不同的基因会发生交叉， 也就是说把两组策略把各自的一部分给对方， 然后形成新的策略组合。 这种重组产生新的基因的速度会比变异快的多， 也就是我们说的交配。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span data-offset-key=&quot;577ih-0-0&quot;&gt;3， 环境会评估某个策略（DNA） 是不是适合自己， 这个通常由一个叫适应度函数的东西表达。 适应度越高， 基因就是越适应当下环境。这个适应度很像机器学习里的目标函数。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span data-offset-key=&quot;6ds96-0-0&quot;&gt;3， 经过一段时间， 适应环境的策略会比不适应的环境的策略得到更多的个体，因为它自身存活的概率更高， 这样， 最终环境里数量最多的， 是最适应环境的策略。这样的策略不一定有一个。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span data-offset-key=&quot;npng-0-0&quot;&gt;4， 环境会变化。当环境变化， 最适宜的策略发生变化， 这个时候最适合的策略也发生变化， 导致新的物种和生态系统的生成。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;5ll5m-0-0&quot;&gt;机器学习：&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;vaek-0-0&quot;&gt;理解机器学习最简单的角度是从一个计算机程序来看： 学习算法是一段特殊的程序。 &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span data-offset-key=&quot;et0m5-0-0&quot;&gt;如果说一段程序可以看做一连串从输入到输出的过程，无论是工程师还是程序员，我们都想通过设计来完成某种功能， 比如说你做一个网页， 你要画视觉图， UI图， 前端后端交互图，我们都是在给计算机设计一套解决具体问题的流程， 如做一个淘宝网。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span data-offset-key=&quot;698n-0-0&quot;&gt;而机器学习呢？ 机器学习是你不去设计， 而让计算机自己去磨，如同用一套很一般的模子里打磨出能够解决特定问题的武器。 这点上，机器学习做的正是” 自发能够产生解决问题的程序的程序” ， 一些机器学习的经典算法如线性回归， SVM， 神经网络， 它们单个都不能解决问题， 但是通过“学习”却可以一会去预测房价， 一会去寻找美女。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;65q35-0-0&quot;&gt;生物世界的学习与机器学习最接近的是强化学习。 强化学习的目标函数是未来的奖励总和， 智能体需要学习到合理的行为来实现奖励最大化。 最简单的强化学习即条件反射。 与进化算法非常类似的， 强化学习在优化行为策略， 但是与之不同的是， 强化学习的优化方法是下面要讲的梯度方法， 一种更为贪婪， 高效的优化方法。 &lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;5sdfg-0-0&quot;&gt;整个机器学习依靠的寻求最优的方法就是梯度优化， 这个方法相比进化算法， 更具方向性和目的性， 虽然我依然不知道我要寻找的那个最优是什么， 但是我每往前走一步， 都希望最大程度的接近它， 或者说贪婪的接近它， 这个时候我们就会设置一个目标函数（类似于进化算法里的适应度）， 然后我们让参数顺着最快速减少目标函数的方向去自动调整， 如下图。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;22t20-0-0&quot;&gt;深度学习作为机器学习的发展， 其成功几乎完全依靠了以反向传播为基础的梯度下降方法， 而事实上也是， 梯度下降在很多时候更加精准。但是， 如果你认为因为梯度下降完全优于进化算法的优化方法， 就错了。 &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;Image FocusPlugin--unfocused Image--isBlock&quot; data-ratio=&quot;0.71&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcebdNQcqmFd7cGXNcVMicbuUJ21wR3plUss5PTvxw9DibPwk4ic2JEDgxtT3501gC8kUrvicBNcYeibdIA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;600&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;span data-offset-key=&quot;cj6jk-0-0&quot;&gt;首先， 关于优化问题， 我最喜欢用的例子是一个小姑娘在山上采集蘑菇， 地势越低的地方蘑菇越多。 因而， 她需要找到一个最快的到达山谷的路径，小姑娘视力不好，因此她最好的做法就是用脚感受当下地势下降最快的方向往前走一步， 这就是梯度下降法。 在一个山谷形状比较简单的地方， 犹如上图， 你是很容易达到这个目标的。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;8h2dd-0-0&quot;&gt;然而真实世界的地形却并非如此简单， 比如下图，你看到无数的波峰和波谷。 每个波谷都代表一个局部最小值。 而事实上哪一个谷是最低谷， 这件事并没有那么容易。 如果你采用机器学习所使用的梯度下降， 则你极大可能会陷入到某个小的山谷里长期停滞。 当然， 在深度学习的问题里， 局部最优往往足够好了。 可是在最真实的情况下， 这下波峰和波谷的高低也可能是动态调整的， 今天的谷底可能是明天的波峰。 &lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;Image FocusPlugin--unfocused Image--isBlock&quot; data-ratio=&quot;0.7795275590551181&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcebdNQcqmFd7cGXNcVMicbuU17QfcbcRBgHOH2JbLXibBNmMSXicKic8bDcgpzuDzjJALoCMh5oY1qPtA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;254&quot;/&gt;&lt;/p&gt;

地形比较崎岖

&lt;p&gt;&lt;span data-offset-key=&quot;5sqjj-0-0&quot;&gt;而进化算法呢？ 进化算法就不一样了， 进化算法相当于一次释放出无数个小姑娘（基因池）， 这些小姑娘， 各自在这个崎岖的地形里试错寻找蘑菇丰盛的最低点。 每个人的搜索策略（每个人的基因）有不同。 虽然趋近每个小山谷的速度不如梯度下降。 但是最终找到那个最优解的可能反而还更快。 这里面最核心的是， 用一个群体替代个体， 在优化的同时更多的保持多样性。 就如同自然界的物种， 有些物种比如说熊猫，居然进化成那么可爱但是站动力不强的样子， 但是自然还是没有淘汰它。 因为这种当下看着不太有利的基因， 不一定在自然巨变中就一定是没有用的。 &lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;&lt;strong&gt;进化算法结合机器学习之最小案例&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;a5r3u-0-0&quot;&gt;废话少说，我们来看看把学习算法和进化算法合在一起， 会发生什么？ &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span data-offset-key=&quot;1uo9j-0-0&quot;&gt;我们从一篇1994年的文章开始看起（Learning and evolution in neural networks by Nolfi, Elman, &amp;amp; Parisi)  这篇文章的作者试图阐述一件事，就是如果进化和学习是相辅相成的，不仅进化可以促进学习能力的增加，反过来， 学习也会促进进化的过程 ， 造成类似于拉马克进化的效果。 &lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;8locs-0-0&quot;&gt;来看如下的儿童游戏：  在一个grid走方格任务里，模拟生物需要在最短的时间里收集足够多的食物（用F代表），  这个生物由一个菜鸟级的神经网络代表。 神经网络接受的输入数据来自周围的食物的方向和距离远近（一种视觉，足以让你找到临近的食物）。 它的行为呢？ 直线前进， 向左或向右转动。  神经网络的输出决定它的行为。 &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;Image FocusPlugin--unfocused Image--isBlock&quot; data-ratio=&quot;1.09&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcebdNQcqmFd7cGXNcVMicbuUV9iatorUapbf9rcXntx2JauE6mL9Ba4W2ico2aPL6C5RviaOe6PJq2Libw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;600&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;Image FocusPlugin--unfocused Image--isBlock&quot; data-ratio=&quot;1.2066666666666668&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcebdNQcqmFd7cGXNcVMicbuU0FIiarVqqeMibGvC4msB76n6D4g5VJukox91NFolZbsF4d2uzm52D07A/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;600&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;span data-offset-key=&quot;f7i75-0-0&quot;&gt;&lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;/&gt;  进化算法在这里具体管什么呢？ 由于网络只有7个隐层神经元， 和两个动作输出神经元， 它的策略就是由它们的权重表达的。 而一组权重， 就可以看作一组DNA。 我们一开始准备很多这样的权重， 代表不同的策略（基因池）然后放到略有不同的环境里让这些虚拟生物跑， 跑到一定时间，就开始看它们采集到的食物的数量（fitness适应度）， 那些食物采集比较少的生物， 而保留优胜者，经过这样一个经典的进化算法流程， 生物就可以学到上图所示的那种策略。 &lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;48t8l-0-0&quot;&gt;然而， 文章的发出者偏偏不是等闲之辈， 这个网络在干这件事之余还干的一件事是， 进行预测！ 不停的预测下一刻它会看到的东西 ，或者说理解它的动作将给它带来什么样的环境变化。你看， 这不就是当下大名鼎鼎的好奇心或预训练的前身吗， 看来还真的是我们总在重复前辈的思想。 &lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;2bp3v-0-0&quot;&gt;预测这个事情会产生什么效果呢？ 通过预测的对错（不停的把自己想到的和最终结果对比），它会开始进行学习，一个重点在于， 学习的过程只在代系之内， 也就是说比如100轮（一轮就是一次游戏）做一次进化算法的迭代， 那么学习可能是在这100轮里每轮都进行的， 但是学习的结果不会传递给下一代， 就好像你死了， 你头脑里的知识也消失了。   那么随之而来的是什么现象呢？ 学习不是就没有意义了吗？ &lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;frnfo-0-0&quot;&gt;不是。  在实验中我们发现， 这个预测性学习， 不仅仅是学会了预测， 而且， 它让虚拟生物在进化算法中得到的食物采集能力， 也就是说任务采集能力大大增加，也就是说，进化算法被监督学习助力了！  &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;Image FocusPlugin--unfocused Image--isBlock&quot; data-ratio=&quot;0.8316666666666667&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcebdNQcqmFd7cGXNcVMicbuU4ULZ0B3C9rBbaqEXMxw8lRIKTxn2iczickaP9ng3SC3f42XTZUtkILzw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;600&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;span data-offset-key=&quot;3qkv5-0-0&quot;&gt;这件事表明看上去匪夷所思， 它就好像是我们过去所说的拉马克进化的复兴。拉马克进化是说， 亲代在后来习得的能力是可以通过遗传传递给子代的， 用一句话就是“用进废退” 。如果你看上面的曲线， 仿佛是说监督学习的个体， 由于亲代可以把它监督学习的成果传递给下一代， 引起了具备监督学习的批次进化速度更快。 事实上呢？ 这是不可能的， 因为每一次学习到的权重并不会传递给子代， 虽然说传递是会发生的， 但是学习得到的权重改变却没有被传递。 &lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;am9ao-0-0&quot;&gt;那么学习是如何作用于进化的呢？用一句话概括这个过程的本质是： 学习使得进化的选择效应发生了变化。 那些通过监督学习能够最大程度的改变命运的个体，每一次被选择出来， 而非像在没有学习的版本里只是天生丽质被选择了。 一句话， 学习， 使得进化的选择更准确。 &lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;am9ao-0-0&quot;&gt;如果你这样理解这件事情， 还是会觉得有点民科， 我们可以给出一个比较数学的版本。 你依然想象一个高低不平的山区地图， 然后我们希望在上面寻找最小值。 每一个不同的策略， 代表地图上的一个点。 那么学习的效果是什么呢？学习可以在局部改变你的策略， 这就好比， 我们的策略可以从当下的一个点， 丰富到周围的很多点， 甚至是一个小的局域。 由于我们的地图是极度凹凸不平的， 可能在很小的局域里就包含了很多的地势变化。 一个没有学习的群体， 它的效果是在这个凹凸不平的地图上撒上很多点， 而有学习的呢？就是撒上很多小圆圈， 如果小圆圈所覆盖的地方包含了极小值， 我们就可以迅速的锁定它。 也就是说， 虽然学习本身的成果无法遗传， 通过学习， 我们才能更好判断哪些是值得保留的真正优势策略。 用优化的语言说就是学习通过局部优化增加了进化这个全局搜索器的效率。 &lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;76mfl-0-0&quot;&gt;好了 ， 这个游戏看起来有点简单， 但那时你一定不要小瞧简单的游戏， 做AI， 你就应该从toy model 里理解问题， 然后看你的想法是否salable， 可扩展。 恰恰是， 这篇文章的成果可以映射当下的一系列AI成果， 直到征服星际争霸的alpha-star。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;3im45-0-0&quot;&gt;如果你追溯这条线的发展， 你首先会看到。机器学习和进化算法， 在这篇文章后， 都得到了飞速发展， 但是机器学习要快很多。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span data-offset-key=&quot;f37a3-0-0&quot;&gt;然后你会看到， 进化算法开始桥悄悄进入很多机器学习框架。而且， 正在实现之前机器学习所完全不可能实现的任务。  &lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;f37a3-0-0&quot;&gt;&lt;strong&gt;进化算法结合机器学习带来的无限可能&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;91kr2-0-0&quot;&gt;首先， 进化算法的本质是一种集群算法， 通过集群， 遍历式的搜索策略空间。 这点， 就比梯度下降更好克服非线性问题里局部极小的问题。  而且在用梯度方法不好并行的一些问题里， 如RNN的训练， 这种方法却可以产生出并行的威力。 再有，进化算法可以帮助我们做梯度下降所难以实现的改变，梯度下降需要问题可以微分， 而进化算法就自由的多， 只要你能够定义适应度和策略就可以做。 它特别擅长做超参数的调整， 改进网络架构， 甚至可以改变学习算法本身。 一句话就是说， 进化算法迈大步， 梯度下降局部调。 这样的思路结合，可以解决相当困难的问题。&lt;strong&gt;最后， 进化算法更有遐想力的地方， 还在于它所带来的智能体间合作与博弈的可能。&lt;/strong&gt;&lt;strong&gt; &lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;7gvjq-0-0&quot;&gt;我们先来看合作， 后面的文章来自那个AI界的不为人赏识的教父级人物Schmidhuber： Accelerated Neural Evolution through Cooperatively Co-evolved Synapses  这篇08年左右的文章，将这种思路几乎用到了极致。这篇文章用进化算法直接解决了一个传统强化学习的经典任务pole balancing的较困难版本， 并且证明它在这类问题上比强化学习更有可扩展性。  联想到强化学习运用到现实生活中， 却经常碰壁， 原因就是鲁棒性差， 可扩展性不高，进化算法会是对它的一个极好补充。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span data-offset-key=&quot;7gvjq-0-0&quot;&gt; &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span data-offset-key=&quot;e9fdq-0-0&quot;&gt;那么何为合作？ 这篇文章里， Schmidhuber直接用进化算法来优化一个模块化的网络。 网络中的每个模块可以看作群体中的一个个体， 而它们的组合网络就可以解决更复杂的任务， 合作体现在网络模块之间的配合。 这点让人不仅想到那个群体和个体的界限问题。 人由不同的器官组成， 人脑由不同脑区组成， 社会由人组成， 这些都可以看作一种广义的合作。 如果每个个体都很优秀， 组成的国家很弱小， 它还是会灭亡，基因传不下去。因此， 进化就会鼓励合作。同样的道理， 在这个模块化的网络里， 进化算法会促进模块间更好的配合最终完成复杂的控制任务。  &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;Image FocusPlugin--unfocused Image--isBlock&quot; data-ratio=&quot;0.49666666666666665&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcebdNQcqmFd7cGXNcVMicbuUGLvwG9xbn0tm7TSwWNTZib3tskeNbqx6srB0X0KMv3hthKnODjVfC1w/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;600&quot;/&gt;&lt;/p&gt;

四个模块的网路， 网络权重由一组“染色体”编码Accelerated Neural Evolution through Cooperatively Co-evolved Synapses


&lt;p&gt;&lt;img class=&quot;Image FocusPlugin--unfocused Image--isBlock&quot; data-ratio=&quot;0.44666666666666666&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcebdNQcqmFd7cGXNcVMicbuU3I4iaACCKML0l7MSUFg64j8dF06cw8GzbKrmK3qkkciat1ficVfWcZD5A/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;600&quot;/&gt;&lt;/p&gt;

经典强化学习游戏， 平衡杆， 我们需要以恰当的方法移动小车，让上面的倒立单摆稳定。 这个游戏有很多复杂版本。

&lt;p&gt;&lt;span data-offset-key=&quot;33n2q-0-0&quot;&gt;进化算法和机器学习混合的最新应用案例 - AlphaStart： &lt;/span&gt;&lt;span data-offset-key=&quot;bf129-0-0&quot;&gt;AlphaStart, 在星际争霸这样级别的游戏击败人类， 应该说这是一个了不起的胜利， 因为星际争霸这个游戏比围棋要接近真实世界很多， 信息是局部的，远方的世界笼罩在黑雾里， 当下和未来是连续的， 战略需要跨越很多时间尺度。这些问题，需要比阿法狗更加复杂的接近方法。  AlphaStart以一个具有记忆的神经网络LSTM为基础， 然后用到的学习方法， 正是进化算法加机器学习（强化+监督学习）。应该说， 这才是这套方法的灵&lt;/span&gt;魂（参见AlphaStart: An Evolutionary Computation Perspective）。 &lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;40ln9-0-0&quot;&gt;它的思想简直是对1994文章的升华， 把拉马克进化真正用起来。 也就是说， 我们把一个最外层的代系间的进化过程， 和内层的持续不断的强化学习结合起来。 内层的学习会影响外层的进化。 更重要的是， 在这里， 我们通过进化引入了不同参数的网络（智能体）间的博弈。 那些从一个根基上产生的稍有不同的网络， 会通过学习来改变自己， 并在战斗中一决雌雄， 当一轮结束， 优胜者将改写失败者的基因， 但失败者不会马上消失，正如文章中所说：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span data-offset-key=&quot;4931d-0-0&quot;&gt;“The fittest solutions survive longer, naturally providing a form of elitism/hall of fame, but even ancestors that aren’t elites may be preserved, maintaining diversity.”&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;Image FocusPlugin--unfocused Image--isBlock&quot; data-ratio=&quot;0.505&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcebdNQcqmFd7cGXNcVMicbuUjvtRygbMC26iciauue49ngHF297rxjqqME094I8CgPhE1GW1DXhQsQwQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;600&quot;/&gt;&lt;/p&gt;

alphastar的进化历程图， 我们看到在每个时间点我们得到的都不是一个点， 而是一群点，代表我们式以族群为单元进化的， alaphastart不是一个网络

&lt;p&gt;&lt;span data-offset-key=&quot;9vqjg-0-0&quot;&gt;这样， 我们就鼓励了种群的多样性， 而得到一个在纳什均衡状态下多样化的解空间（一组不同策略的组合）。也就说， 最后的最优解不是一个网络， 一个是策略集群。 如此， 我们就可以玩转很复杂的问题。  保持多样性的好处还是在之前的小姑娘采蘑菇的例子说的，任何优化都是在高低不平的空间里寻找最低点， 而在星际这样复杂的游戏中， 整个地形都在缓慢或迅速的变化着， 之前处于劣势的个体，可能在下一个拐点变成处于优势的。 &lt;strong&gt;这也是进化算法的温情之处， 世界是充满不确定性的，因此我不要斩尽杀绝。&lt;/strong&gt;&lt;strong&gt; &lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;5ekui-0-0&quot;&gt;正如schmidhuber在上一篇文章说的， 这一类损失函数对应的地形动态变化的问题里， 那些传统的优化问题甚至会完全失效（稳定性丧失）， 而最后剩下的，会是进化算法。 &lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;2q9bl-0-0&quot;&gt;&lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;/&gt;  deepmind的宣传稿里有一个非常好的例子， 我不是星际玩家， 但是你应该可以很快理解。 大意说的是在早期具有优势的策略（比如用某种武器迅速偷袭对方的高风险策略）， 会随着时间发生变化， 有的时候， 这种变化完全不是之前基础的改进， 而是从完全不同的分支长出来的（比如早期通过增加工人取得经济优势，这与风险策略几乎相反，而这个策略后来居上）。如果你砍掉所有的分支， 你是否还能找到那个后期的优势策略呢？  那个后来最优的策略， 压根不是你先前的最优渐进发展出来的。     &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span data-offset-key=&quot;fd5mp-0-0&quot;&gt;“As the league progresses and new competitors are created, &lt;span helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; start=&quot;&quot; pre-wrap=&quot;&quot; rgb=&quot;&quot;&gt;new counterstrategies&lt;/span&gt; emerge that are able to defeat the earlier strategies. While some new competitors execute a strategy that is merely a refinement of a previous strategy, others discover drastically new strategies consisting of entirely new build orders, unit compositions, and micro-management plans&lt;/span&gt;&lt;span data-offset-key=&quot;fd5mp-6-0&quot;&gt;.“&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;6dcl7-0-0&quot;&gt;在进化算法和学习算法的结合里， 我们看到了一种AI发展的未来路径。 我们也看到了让AI从一个单个学习的网络， 发展到群体， 并通过群体间的合作和博弈促进发展的某种必要性。 在整个过程里， 我们看到人类自己智能产生和发展的影子。 这样的一条道路， 会给我们带来怎样的未来， 让我们拭目以待。&lt;/span&gt;&lt;/p&gt;


&lt;p&gt;&lt;span data-offset-key=&quot;6dcl7-0-0&quot;&gt;更多内容请关注作者新书&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibccvEGHcvx6vn7ibqucwWjTLJNQDiajMVL3arkx9IJnm10baZ1RjdLTN2KH6SKHZqnzyGO5K0G3dNOwg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; class=&quot;&quot; data-ratio=&quot;5.896&quot; data-w=&quot;750&quot; helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; normal=&quot;&quot;/&gt;&lt;/p&gt;

</description>
<pubDate>Fri, 12 Apr 2019 11:37:37 +0000</pubDate>
<dc:language>zh-CN</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.jintiankansha.me/t/ctzlXu0ZQQ</dc:identifier>
</item>
</channel>
</rss>