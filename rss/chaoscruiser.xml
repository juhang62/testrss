<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="css/feed.xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/" xmlns:og="http://ogp.me/ns#">
<channel>
<atom:link rel="self" href="http://192.168.1.4/fivefilters/makefulltextfeed.php?url=feed43.com%2Fchaoscruiser-jtks.xml&amp;max=5&amp;links=preserve&amp;exc=1" />
<atom:link rel="alternate" title="Source URL" href="http://feed43.com/chaoscruiser-jtks.xml" />
<atom:link rel="related" title="Subscribe to feed" href="http://www.subtome.com/#/subscribe?feeds=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed43.com%252Fchaoscruiser-jtks.xml%26max%3D5%26links%3Dpreserve%26exc%3D1&amp;back=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed43.com%252Fchaoscruiser-jtks.xml%26max%3D5%26links%3Dpreserve%26exc%3D1" />
<title>混沌巡洋舰</title>
<link>http://www.jintiankansha.me/column/ultiWL8Axg</link>
<description>混沌巡洋舰 - 今天看啥</description>
<ttl>360</ttl>
<item>
<title>随机网络中的智慧</title>
<link>http://www.jintiankansha.me/t/JIJMBiPkwj</link>
<guid isPermaLink="true" >http://www.jintiankansha.me/t/JIJMBiPkwj</guid>
<description>&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;网络是从人类智能到深度学习的基础，可能所有人都认为只有训练好的具有特定结构的网络才能具有功能，如同生物的功能是由结构决定的， 精巧设计的结构可以产生特定的功能， 大概高中生物老师就给我们灌输了这个观念。 而在网络的世界， 这就意味着你要某个功能，就要先产生那样的结构，比如一个具有特定结构的CNN。&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;然而， 可能你不知道的是， 一个随机连接的网络也具有功能。 什么叫随机啊？ 就是任意单元和单元之间连接与否是随机的， 看起来很混乱，它们居然能做事？ 不仅如此， 它能做的事情还很酷炫：比如， 预测火焰的形状演化。&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;注：火焰的跳动，是一个我们常说的混沌系统， 所谓难以用常规方法预测， 确可以一定程度被随机网络征服，这是一个以复杂对抗复杂，用无常应对无常的经典例子。&lt;/p&gt;
&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.5615384615384615&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcewMUIibIuV7JdontKCkatxCwjxNiat12Ber6FWgHTw70o1ib9sGxPaUWa4OqqzOeiax2iacJ4u5gENmyg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;520&quot; width=&quot;520&quot;/&gt;&lt;p&gt;Machine Learning&amp;amp;amp;amp;#39;s &amp;amp;amp;amp;#39;Amazing&amp;amp;amp;amp;#39; Ability to Predict Chaos&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;任何一个网络的连接都可以由一个矩阵来刻画， 刻画随机网络单元和单元之间的连接就是随机矩阵。&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; center=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;&lt;span&gt;&lt;strong&gt;1）什么是随机矩阵 ？&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;可能每个人都很清楚矩阵， 但是提到随机矩阵，就不是每个人都清楚了。 事实上， 随机矩阵是研究所有和网络有关的科学技术， 从机器学习到复杂系统， 极为重要的工具。 那么我们就一层层拨开随机矩阵的神秘面纱。&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;首先， 如果矩阵里每行每列的元素都从独立分布的高斯里抽样，那个， 这样的一个方阵称为随机矩阵。&lt;/p&gt;
&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.26666666666666666&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcewMUIibIuV7JdontKCkatxC8McjJVpeuZbYZ99fRzG8iaQ3wPFrKRgYPOtboFZMrO8q8PUUFhN9eKQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;720&quot; width=&quot;904&quot;/&gt;&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;看起来没什么乱用对吧？ 我们还是直接进入随机矩阵的数学物理本质： 事实上， 随机矩阵用于描述一个动力系统内不同元素间的相互作用， 具体的例子比如：&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;1， 描述一个马尔可夫过程的概率迁移矩阵： 矩阵可以用来描述一个马尔可夫过程的迁移矩阵， 那么该矩阵就定义了一个随机连接的图网络， 从i点到j点的迁移概率由对应的矩阵元素表达（因此每一行的和需要为1）。&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;2， 描述一个动力系统里任意的n个元素和n个元素的相互作用关系， 这n个元素， 既可以是人工或生物神经网络里的神经元， 也可以是生态系统里的各个物种， 或金融市场相互作用的交易者， 我们刚刚说的预测混沌的网络就符合这个类型。 此处随机矩阵就是随机网络的数学表示&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; center=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;&lt;strong&gt;&lt;span&gt;2）随机矩阵是怎样刻画一个动力系统的&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;这里， 我们从最简单的系统-二维的线性动力学系统开始， 二维的动力系统定义为：&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.17567567567567569&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_svg/hNWCQ9bibbzFWeywyrPJ78CTicqXAeOgPnF1ia9ib42miafRnAJLIbibIic2m4yt0P3oSjm9DZCB43s85xgsyY8RPsEMtDHM7avvK32/640?wx_fmt=svg&quot; data-type=&quot;svg&quot; data-w=&quot;148&quot;/&gt;&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.1780821917808219&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_svg/hNWCQ9bibbzFWeywyrPJ78CTicqXAeOgPnowJGOKPTyrK4ic68XPZBGq7z9RBj4YldHQByhk95mZgoFGHzVDRrzffibib3F2d9UHd/640?wx_fmt=svg&quot; data-type=&quot;svg&quot; data-w=&quot;146&quot;/&gt;&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;可以由一个a，b，c，d组成的二维矩阵（雅可比矩阵）刻画。 这个两两作用的系统在自然界比比皆是， 比如著名的猎手-猎物方程。&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;对于任何动力学系统， 我们都要先抓住它的定点， 而整个系统的性质， 由定点向外周扩散迎刃而解。 那么这个简单的线性系统有一个显而易见的定点就是x=0， y=0.&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;定点的作用就像一个巨大的吸引中心， 系统的演化无论多么复杂， 都是以某种形式围绕它展开。 这些展开形式可以被概括到一个叫相图的二维平面里， 这个平面是由二维系统的两个变量为坐标轴， 概括了系统从任何初始状态（x，y）开始演化， 它的未来发展轨迹。&lt;/p&gt;
&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data=&quot;&quot;/&gt;</description>
<pubDate>Wed, 01 May 2019 04:35:46 +0000</pubDate>
<dc:language>zh-CN</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.jintiankansha.me/t/JIJMBiPkwj</dc:identifier>
</item>
<item>
<title>强化学习理解的三重境界</title>
<link>http://www.jintiankansha.me/t/A5jNLvecGM</link>
<guid isPermaLink="true" >http://www.jintiankansha.me/t/A5jNLvecGM</guid>
<description>&lt;p&gt;&lt;span&gt;想像一下我们是人工智能体，我们有强化学习和监督学习可以选择，但干的事情是不一样的。&lt;/span&gt;&lt;span&gt;面对一只老虎的时候，如果只有监督学习就会反映出老虎两个字，但如果有强化学习就可以决定逃跑还是战斗，哪一个重要是非常明显的，因为在老虎面前你知道这是老虎是没有意义的，需要决定是不是要逃跑，所以要靠强化学习来决定你的行为。&lt;/span&gt;&lt;br /&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;强化学习有哪些实打实的应用呢？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;只要在问题里包含了动态的决策与控制，&lt;/span&gt; &lt;span&gt;都可以用到强化学习&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;1， 制造业&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;强化学习之于制药业有一种天然的契合 ， 把强化学习翻个牌子换个叫法， 也可以叫做控制论， 学习控制机器手的精确动作， 比如让它自动的做比目前所能及的更复杂的事情， 强化学习在制造业的应用潜力是显然的 。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt; &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.6617283950617284&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibce5vF9ib3b3HiaHGBxGjjGop8YBT4xfFfeIjiatN1CyyZZVqicS0kicw2faTLPZtvkZrkYV4mZ988CiaA1w/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;405&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;&lt;span&gt;2， &lt;/span&gt;&lt;strong&gt;&lt;span&gt;无人驾驶&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;这就不用多说了， 开车本质是个控制问题, 　自动驾驶不仅需要模拟人类行为，　还需要对前所未遇的情况进行决策，　这需要强化学习。　&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt; &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.5612009237875288&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibce5vF9ib3b3HiaHGBxGjjGop8BvCqcZ8G0tw81FlSBbLpUvJQkpvZ1WYK40jX7E00y9OknVic4PFNbYg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;433&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt; &lt;br /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;span&gt;3, &lt;/span&gt;&lt;strong&gt;&lt;span&gt;智能交通&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;智能交通， 显然这里包含了非常多的决策与控制问题， 就拿目前的共享汽车行业 ，滴滴和uber的派单系统时时都是一个动态的决策， 如何把正确的司机和乘客连接在一起， 如何让车辆调动到需求量最大的地方， 这些都要时时的考虑各种因素调整决策。我们说这里面既包含了效率的问题， 也包含了乘客的安全。比如这一次滴滴的事故如果修正强化学习的效用函数， 是有可能避免的。当然除了派单和调动问题， 在每个十字路口交通灯的控制等， 整个城市里的立体交通网络的协调， 本质都是强化学习问题， 所以强化学习在智能交通大有可为 。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt; &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.5841035120147874&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibce5vF9ib3b3HiaHGBxGjjGop8aEGBiaEgrS7f5yM8cFRoHfwKfEKKmCZRuo2O6r45scgkGPjwbnnajicw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;541&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt; &lt;br /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;span&gt;4，&lt;/span&gt;&lt;strong&gt;&lt;span&gt;金融&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;金融的核心， 交易， 是一个动态控制问题， 即使你不能完全预测明天股市的涨跌， 你依然需要直到我今天要不要下单，下多少单， 这，就是一个强化学习的决策， 它可以影响明天的股市， 也会在非常长远的时间里让我收益或亏损。机器交易，本质是个强化学习问题。当然，金融里能够应用强化学习的绝不仅仅这一个。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt; &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.4258720930232558&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibce5vF9ib3b3HiaHGBxGjjGop8p7o3Dgj17Ygk1o805cWk8rfcYsGpjVTrtThibodXLq2rIrwy2md0gAg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;688&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;5, 智能客服&lt;/span&gt;&lt;/strong&gt;&lt;br /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;智能客服本质是个强化学习问题， 如果你把它处理成监督学习问题， 那个对话机器人只能照猫画虎， 不能够真正从顾客的好恶的角度出发来发言， 而如果用强化学习， 那么机器人学习的就是如何正确的决策， 每句话都是为了最终讨得顾客欢心。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt; &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.562254259501966&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibce5vF9ib3b3HiaHGBxGjjGop8TsUlYnticNY3Cd22ziaa2IEQ3vtQQ3eeibia7P9IMc0wsK6SLvhZ84ATuw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;763&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt; &lt;br /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;6， 电商&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;电商的本事是如何吸引人买更多的东西， 因此我们买了一个东西后它总会在下面给我们推荐其它的东西。然后我们看到了一个新的东西， 又会点开下一个连接， 这样一步步的就买了一大堆东西， 这样在每一步给你展示不同东西吸引你上钩的过程， 也可以看作是电商系统的动态决策过程， 是一个强化学习问题。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt; &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.5674044265593562&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibce5vF9ib3b3HiaHGBxGjjGop8jydTibwaO24npwTStA4ftpBib5iaAWfnNib78yGGwsZvmpB98WAtHtS2uA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;497&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;7， 艺术创作&lt;/span&gt;&lt;/strong&gt;&lt;br /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;艺术创作领域看起来与强化学习无关， 事实上它可以很灵活的把人类的好恶加在强化学习的过程里，通过强化学习， 机器作曲可以自发的得到取悦于人的风格，也就是范式。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt; &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt; &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.47791798107255523&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibce5vF9ib3b3HiaHGBxGjjGop8ibb1jxhO04FDBz6DCPfIexGdKRsb3vYIIsRJGf4DibR1ZTTxDibxvJLtQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;634&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt; &lt;br /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;span&gt;让机器来决策，首先体现在如何模仿人类的决策。对于决策这个问题，&lt;/span&gt; &lt;span&gt;我们来看人类决策都要解决哪些难题。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;&gt;&lt;/ins&gt; &lt;p&gt;&lt;span&gt;强化学习最初的体现就是试错学习， 因此理解强化学习的第一个层次就是如何通过一个简单的机制在不确定的环境下进行试错， 掌握有用的信息。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.3946830265848671&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibce5vF9ib3b3HiaHGBxGjjGop8bDDGfnbVQmh1GEHdJu9H2RXBcjibpF1Lc9qDwvd5QzuUdwxtQiaQR61A/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1467&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;在这个框架下，&lt;/span&gt; &lt;span&gt;我们需要掌握的只有两个基本要素，&lt;/span&gt; &lt;span&gt;一个是行为，一个是奖励。&lt;/span&gt; &lt;span&gt;在这个级别的强化学习，&lt;/span&gt; &lt;span&gt;就是通过奖励，强化正确的行为&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;。&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt; &lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;所谓行为，行为的定义是有限的选项里选以恶搞，&lt;/span&gt; &lt;span&gt;所谓智能体的&lt;/span&gt;&lt;/span&gt;&lt;strong&gt;&lt;span&gt;决策&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;，走哪一个都有正确的可能，但是我们预先不知道这个东西。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;所谓奖励， 就是环境在智能体作出一个行为后， 给它的反馈。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;span&gt;大家看到，如果这个奖励是已知的，那么也就没有了任何的游戏需要进行的可能了。&lt;/span&gt; &lt;span&gt;你为什么要学？&lt;/span&gt; &lt;span&gt;每个行为得到的后果是不知道的啊！&lt;/span&gt;  &lt;span&gt;奖励具有随机性，&lt;/span&gt; &lt;span&gt;同样的条件性，&lt;/span&gt; &lt;span&gt;有的时候我们可以得到奖励，&lt;/span&gt; &lt;span&gt;有时候没有，&lt;/span&gt; &lt;span&gt;因此，&lt;/span&gt; &lt;span&gt;它也是一个随机变量，&lt;/span&gt; &lt;span&gt;理解这一点非常重要，&lt;/span&gt; &lt;span&gt;因此才可以理解很多的后面的算法。&lt;/span&gt; &lt;span&gt;奖励可以是正向的，也可以是负向的（惩罚）。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.69875&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibce5vF9ib3b3HiaHGBxGjjGop8AKZgMqIPKFjricunYfGg1bkaiaYA5g9khFDIwVa27VgyOaEka0GsJ5Cw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;800&quot; /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;我们迅速的切入一个强化学习的最小实用例子，&lt;/span&gt; &lt;span&gt;又被称为&lt;/span&gt;&lt;/span&gt;&lt;strong&gt;&lt;span&gt;多臂赌博机的例子&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;：&lt;/span&gt;&lt;/span&gt; &lt;span&gt;&lt;span&gt;你去赌场玩的，&lt;/span&gt; &lt;span&gt;都知道这个机器的存在，&lt;/span&gt; &lt;span&gt;它的构造就是很多个长得一样的摇臂，每个对应不同的中奖概率，&lt;/span&gt; &lt;span&gt;你要玩&lt;/span&gt;N轮， 每次选择摇臂， 使得最终的收益最大。聪明的你一定可以设计一个方案， 让自己的收益最大， 怎么做呢？ &lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;首先， 你能不能一下子找到这里的行为和奖励是什么呢？&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;你能否设计一个算法解决这个问题呢？首先， 注意， 我此处的题设是N。假定这个N是一次你会怎么做？10次呢？无穷多次呢？&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.6067146282973621&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibce5vF9ib3b3HiaHGBxGjjGop8ZoLBicVgE11906kib5ODmUn9512MNlBfk4NpnpAGQ2xerLgSzdTF9fLg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1251&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;每次行动后带来不同的奖励&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;很自然的，我们就来到了这么一个问题，就是探索与收益的平衡，&lt;/span&gt; &lt;span&gt;只要&lt;/span&gt;N不是1或无穷， 你都会有如下的窘境。假如你开始就中了 ， 你会一直选择那个中奖的摇臂不放过吗？显然这可能是陷阱，因为还有收益更高的臂，或者只是这次的运气好。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;&lt;span&gt;反过来， 你会不停的随机试下去吗？显然不会， 因为存在收益比较高的臂。所以， 你就需要设计一个策略， 在有效探索的同时加大在那个最有收益可能的臂的概率， 每次玩， 又都增加你的信息。这就是一个极为典型的应对不确定的策略。&lt;/span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;而且，&lt;/span&gt; &lt;span&gt;可以直接用到产品设计上，&lt;/span&gt; &lt;span&gt;我们也可以把它看成一个特别有方向性的试错。&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;在这里你要形成的第一个观点就是：&lt;strong&gt;奖励是随机变量 为了量化奖励， 我们需要引入期望。&lt;/strong&gt;这，才是我们要优化的对象。我们所处的环境下，环境给我们的奖励分布是未知的，因此，你必须在一开始边测量， 边引入收益的机制。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;刚刚的游戏，&lt;/span&gt; &lt;span&gt;和真实世界的大多数问题相差甚远，&lt;/span&gt; &lt;span&gt;因为它每轮只有一步就可以看到奖励，而且这一次抽取，&lt;/span&gt; &lt;span&gt;和下一次抽取一点关联都没有。&lt;/span&gt; &lt;span&gt;而事实上世界上的大部分游戏是一个连续多步骤，步步相连的过程。比如各种棋类，扫地机器人（连续离散化）等，&lt;/span&gt; &lt;span&gt;这样的问题，&lt;/span&gt; &lt;span&gt;很快前面的问题就不管用了。我们需要完善我们的框架来改进前面的东西。&lt;/span&gt; &lt;span&gt;好了，假定你是在设计这个东西，&lt;/span&gt; &lt;span&gt;那么你要加入一个什么要素呢？&lt;/span&gt; &lt;span&gt;时间？&lt;/span&gt; &lt;span&gt; &lt;/span&gt;&lt;span&gt;步骤&lt;/span&gt;&lt;span&gt;?&lt;/span&gt;&lt;span&gt;   &lt;/span&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;No,  &lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;我们说， 解决这类问题， 首先引入的是状态。在围棋里， 你需要看到的是每一步其实你需要决策的信息都在当时的棋盘布局里，&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
</description>
<pubDate>Fri, 19 Apr 2019 15:02:23 +0000</pubDate>
<dc:language>zh-CN</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.jintiankansha.me/t/A5jNLvecGM</dc:identifier>
</item>
</channel>
</rss>