<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="css/feed.xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/" xmlns:og="http://ogp.me/ns#">
<channel>
<atom:link rel="self" href="http://192.168.1.4/fivefilters/makefulltextfeed.php?url=feed43.com%2Fchaoscruiser-jtks.xml&amp;max=5&amp;links=preserve&amp;exc=1" />
<atom:link rel="alternate" title="Source URL" href="http://feed43.com/chaoscruiser-jtks.xml" />
<atom:link rel="related" title="Subscribe to feed" href="http://www.subtome.com/#/subscribe?feeds=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed43.com%252Fchaoscruiser-jtks.xml%26max%3D5%26links%3Dpreserve%26exc%3D1&amp;back=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed43.com%252Fchaoscruiser-jtks.xml%26max%3D5%26links%3Dpreserve%26exc%3D1" />
<title>混沌巡洋舰</title>
<link>http://www.jintiankansha.me/column/ultiWL8Axg</link>
<description>混沌巡洋舰 - 今天看啥</description>
<ttl>360</ttl>
<item>
<title>2018 人工智能十本好书汇总</title>
<link>http://www.jintiankansha.me/t/aD9ErCNZoC</link>
<guid isPermaLink="true" >http://www.jintiankansha.me/t/aD9ErCNZoC</guid>
<description>&lt;p&gt;搜索了一下，目前网上还没有关于人工智能的书单，那就做一个，该帖中的书有的我正在读，有的已经读完，有的要反复读。此帖列出了个人觉得值得读的AI有关的书籍，前七本有中文版，后三本只有英文版。点击可以查看相关的阅读笔记。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;1 &lt;/strong&gt;&lt;strong&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651383580&amp;amp;idx=1&amp;amp;sn=da0870102ecdc4a1802d28bb5db92574&amp;amp;chksm=84f3c95db384404bd330565babd688d50f11fac8a9cda914520f61f538c54eebf2f9466dd5c7&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-linktype=&quot;2&quot;&gt;生命3.0-在亿年的尺度下审视生命的演进&lt;/a&gt; 4星&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcfhUgyozt82nF10H6fM7N2I5IGlDsZRUJdqAQt12lv0XVbolvR3V2qtkGfbvMlvgaPCqV3YIVgulw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; class=&quot;&quot; data-ratio=&quot;1.2361111111111112&quot; data-w=&quot;1080&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;豆&lt;/span&gt;&lt;span&gt;整本书翻译的质量很高，全书语言流畅，而且对于极权主义等敏感话题也没有一丝一毫的删减。更难得的是，由于译者是原书作者的好友，因此在翻译的过程中，加入了一些新的内容，包括18年AI领域的新鲜事，因此可以看成原书的升级版。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;span&gt;2 &lt;/span&gt;&lt;span&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651383706&amp;amp;idx=1&amp;amp;sn=a1640b00320b0e43e769bff619cb78fc&amp;amp;chksm=84f3c9dbb38440cd0a807d9a8d72b9a4701191dd24af206c0703f2fa104ed1cae6b0758964f3&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-linktype=&quot;2&quot;&gt;机器与人-寻找人机之间的中间地带&lt;/a&gt; 4星&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;img data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/4G0E6zndVrwNdsCyVdkrS4rFebZbdWxs4KZfibicSV7Wze0NJHLEShMvhmPjQyXibloHVpibRUPXUzezZcprOkLgmA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; class=&quot;&quot; data-ratio=&quot;1&quot; data-w=&quot;1080&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;span&gt;原书是今年3月20号在美国出版的。作为关于AI如何改变工作的众多相关书籍中评分较高的一本，本书亚马逊评分高达4.4分。这本书讲述了如何更好的面对AI取代工作这一话题，本书核心观点是&lt;strong&gt;未来真正的风口是人与机器作为同盟去共同解决问题&lt;/strong&gt;&lt;span&gt;。未来的确会有很多工作要消失，但在人机之间的中间领域，则会诞生出更多新的工作，有的是将人的智慧手机起来，来协助机器，有的是配合机器，给更多人赋予超能力。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;3 &lt;/span&gt;&lt;/span&gt;&lt;/span&gt;深度学习 - 智能时代的核心驱动力量（即将出版） 4星&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;1&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcdYlYibF3kjoPmT8MwLlSg7xVbss3bl8cFI2tSEKBo4TuoETagYEo8cX1woKYngVVeJJj89hMMqmhQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;800&quot; /&gt;&lt;/p&gt;
&lt;p&gt;本书的作者很牛，是美国四大国家学院（国家科学院、国家医学院、国家工程院、国家艺术与科学学院）在世仅3位的“四院院士”之一，全球AI专业会议NIPS基金会主席。本书有两个相互交织的主题：人类智能是如何进化的，以及人工智能会如何演变。作者以亲历者视角回溯了深度学习浪潮在过去60年间的发展脉络与人工智能的螺旋上升，并前瞻性地预测了智能时代的商业图景。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;4&lt;/strong&gt; &lt;strong&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651383237&amp;amp;idx=1&amp;amp;sn=c9562cbdcfea785da928434973116aae&amp;amp;chksm=84f3cb84b3844292efc85670d09d9eb0405a7db370782fba722919ff40b7ed028a7825b12909&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-linktype=&quot;2&quot;&gt;人之彼岸&lt;/a&gt; 5星&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;img data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcdV5esuvsoSc6k8dG6TcBrCk9Sabyh4Ss7Ip2lUDSPXubicA4MW9dXicB2Bkt7qBJzEStTAnJRDIe1A/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; class=&quot;&quot; data-ratio=&quot;1.4455445544554455&quot; data-w=&quot;303&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;全书的六个故事和两篇非科幻的思索，相映成趣，思考中提到的观点，都在小说中有所呈现。整本书的主题，用作者的话可以看成是“人工智能在彼岸，我们在此岸。”也可以用书中提出的“逆图灵测试”来概括。图灵测试是通过人类无法分别和Ta交流的是人类还是电脑来判定智能水平的，而逆图灵测试则是通过呈现人类特有的性状，让人类能够和那些智能水平上已经不相上下的AI区分开来。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;5 AI极简经济学 4星&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;1.423148148148148&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcdYlYibF3kjoPmT8MwLlSg7xncwRyroOwQgD6EMMwvGzZSRqlFcE7kkDhkpfWADYU5YaNUwfp9QZtA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1080&quot; /&gt;&lt;br /&gt;&lt;/p&gt;
&lt;p&gt;本书作者哈尔·瓦里安是谷歌首席经济学家，这本书从经济学角度以预测机器看待人工智能，书中指出人工智能当前的突飞猛进给我们带来的其实不是智能，而是智能的一个关键组成部分——预测，通过人工智能，可以筛选出更符合大众口味的产品。这本书专业的从经济方面阐述该如何在依靠AI和人类自己的程度上，选择一个平衡点，让两者的不利点互相抵消。本书搭配了许多专业的图表设计和对比，从而帮助你更好的理解不同AI在不同场景下的回报率。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;  &lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;6 百面机器学习 5星&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;img class=&quot;&quot; data-ratio=&quot;1.3528064146620848&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcdYlYibF3kjoPmT8MwLlSg7xr1YlzNbRkwPlYexb1hqe8YcWyZa7rGlStZgukLfKLG5N9phWHibGHmw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;873&quot; /&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;年度最有用的一本书，但不适合新手，内容全面，需要你有基础。对于准备面试的同学，本书涵盖了许多面试过程中经常被问到的问题，而且也可以帮你梳理一下机器学习的知识点，绝对是你需要的，即使对于不找工作的同学，书中有许多工作中需要的技能和实例。这本书需要反复读。&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;7&lt;/strong&gt;&lt;strong&gt; 深度学习入门 基于Python的理论与实现 4星&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;img class=&quot;&quot; data-ratio=&quot;1.4074074074074074&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcdYlYibF3kjoPmT8MwLlSg7x9nRO7k2V8TO5YhH0qGbEUJfdrzAcgictkMOxWbMemuicxnxZTZ8NcGTg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1080&quot; /&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;对于深度学习入门而言，这是我推荐的第一本书.不同于基于常见的现有框架如pytorch，tensorflow等的入门书，这本书自己动手，从零做起，用基本的python语法和数学公式，实现了深度学习中最常用的算法。虽然本书不包含最新的研究和理论细节，但看懂了这本书，亲自动手实现了书中的算法。你才能够看懂最新的论文，并重复其中的结果。&lt;/p&gt;


&lt;p&gt;&lt;strong&gt;8 《Artificial Intuition》 4星&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651383444&amp;amp;idx=1&amp;amp;sn=94627b6e19ba9598afc551362f9e177a&amp;amp;chksm=84f3c8d5b38441c357851b92294f8b61bc24f08962f3dc399c7bc58287b52764f3c5e48961fb&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-linktype=&quot;2&quot;&gt;什么让深度学习与众不同-《Artificial Intuition》读书笔记上&lt;/a&gt; &lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651383460&amp;amp;idx=1&amp;amp;sn=944fe726d386556f7308539397e97c60&amp;amp;chksm=84f3c8e5b38441f39eeac95a9393604c8c8b7ac50719cfccaac495c59952c37457bcc2a11bbb&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-linktype=&quot;2&quot;&gt;《Artificial Intuition》读书笔记下 创造一种新的语言&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibccYIiakPnDqVYfVrM9X3EYsZGLotxVS5h91KtDP112o6bbt3R51psFZmLpicvzVbpB7iavODy3ZxZ11A/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; class=&quot;&quot; data-ratio=&quot;1.4984984984984986&quot; data-w=&quot;333&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;《Artificial Intuition》是今年2月新出版的一本书，工科背景的作者Carlos Perez在自述中说这是一本写给大众的深度学习入门书，书中讲述了&lt;/span&gt;&lt;span&gt;深度学习为什么说传统的机器学习有着显著的不同，为什么深度学习不是传统机器学习方法的小修小改，而是一个全新的物种，关键词是自组织，动态和负反馈（GAN中的猫鼠游戏，探索与利用的权衡）。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;9 &lt;/strong&gt;&lt;strong&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651383568&amp;amp;idx=1&amp;amp;sn=fb2a6857f18cf4de917111406ef9bd4f&amp;amp;chksm=84f3c951b3844047e23a00d5aca0f9acac4aa27580dabfa7096401a166b9ad3196b34de9d251&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-linktype=&quot;2&quot;&gt;从相关性到因果性-读《The book of Why》&lt;/a&gt;5星&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibceE1piajBpf3TqrYxHmeibImWckebOwWJ4fsd31zBMibQVet43icCpicq509m0AAGXoDATR6LAql1KIfEQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; class=&quot;&quot; data-ratio=&quot;1.4970059880239521&quot; data-w=&quot;334&quot; /&gt;&lt;/p&gt;
&lt;p&gt;这本书是因果推理和贝叶斯网络的奠基人Judea Peral和科普作家 Mackenzie, Dana合作写的一本因果推理的入门书，这本书中有太多技术的细节，虽披着科普书的称号，实际却是本科高年级水平的教科书。书中讲述了如何使用因果图来根据数据来判定两个事件之间是否有因果关系，以及如何使用因果推理去进行反事实的思考。做为对当前人工智能缺少因果推断的补充，该领域的应用前景和发展速度都值得关注。而tensorflow和pytorch也都在18年开始支持因果推断的新功能。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;10 《Machine Learning Yearning》 5星&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;&gt;&lt;/ins&gt; &lt;img data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcdVhqnC0Cm5SNibd1viaTJ5KIibx5hkQzibjYiakN3ibuRjTtIK0mOWEV6mkx69lNs43TViaO26WR8BJuCLg/640?wx_fmt=png&quot; data-type=&quot;png&quot; class=&quot;&quot; data-ratio=&quot;1.2906976744186047&quot; data-w=&quot;602&quot; /&gt;&lt;/p&gt;
&lt;p&gt;大神吴恩达写了一年多的书，目前还没有写完，整本书不是讲机器学习的算法，而是讲让在实践中做机器学习项目时采用的策略，简称学习策略 (learning strategy)。具体可以参考 &lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651383893&amp;amp;idx=1&amp;amp;sn=dc93d4f66c1856c5d24a8cd50ebf6e25&amp;amp;chksm=84f3c614b3844f026d4dd7b7fee9b7e83757e2e7a09a8ad7a1a49a81b0a1e8d7face379d572d&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-linktype=&quot;2&quot;&gt;长文解读吴恩达新书《Machine Learning Yearning》&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;最后说一本不是很推荐，但值得茶余饭后读一读的 《Hello World》 3星&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;1.5175718849840256&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcdYlYibF3kjoPmT8MwLlSg7xvZCPRpsXaXJCRI6xFBAbvDQAJZOq52WrnTAQdjdFuwxicJb62td6s9w/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;313&quot; /&gt;&lt;br /&gt;&lt;/p&gt;
&lt;p&gt;阅读这本书，是去年铁哥准备人工智能在现实生活中的影响时，叫我推荐几本书，我被这本书的标题吸引了。书中讲述了“算法”逐渐深入我们生活的方方面面（消费、医疗、保险、执法等等）的案例以及所造成冲击。不过书中的算法更多是统计相关的，而非新的机器学习算。本书虽然涵盖面很广，讨论却不够深刻。&lt;/p&gt;


&lt;p&gt;更多阅读&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651383857&amp;amp;idx=1&amp;amp;sn=3dfd440fcc825e37ed4ffb11820550e0&amp;amp;chksm=84f3c670b3844f66427b7088e96cdb21a234efaa544e784973b2e0ede2d403e4274e313a3b11&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-linktype=&quot;2&quot;&gt;五本年度好书速读速评&lt;/a&gt;&lt;br /&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651383323&amp;amp;idx=1&amp;amp;sn=1b954794ff6ea866a19d420a517ccab3&amp;amp;chksm=84f3c85ab384414c1df772db5510441e30a3c4983923280528e6296b7fc82603d7e23ec8c12a&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-linktype=&quot;2&quot;&gt;黑镜书单-列一列那些反思互联网和人工智能的30本警世之书&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651383036&amp;amp;idx=1&amp;amp;sn=a2bb5440452a54242600d27ec2fce4c6&amp;amp;chksm=84f3cabdb38443ab435f1b90080022b000913676a18c3c00b0e69258c9b9019e819bac537c98&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-linktype=&quot;2&quot;&gt;AI，大数据，复杂系统 最精 40本大书单&lt;/a&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;觉得不错，请点击“好看”，谢谢支持哦！&lt;/p&gt;






</description>
<pubDate>Sat, 12 Jan 2019 12:49:20 +0000</pubDate>
<dc:language>zh-CN</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.jintiankansha.me/t/aD9ErCNZoC</dc:identifier>
</item>
<item>
<title>《模型思维》读书笔记-Why How 以及多臂老虎机的案例分析</title>
<link>http://www.jintiankansha.me/t/suaRCxrWfr</link>
<guid isPermaLink="true" >http://www.jintiankansha.me/t/suaRCxrWfr</guid>
<description>&lt;p data-mpa-powered-by=&quot;yiban.io&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;556&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;313&quot; data-ratio=&quot;1.548165137614679&quot; data-s=&quot;300,640&quot; data-type=&quot;jpeg&quot; data-w=&quot;436&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/wibWV1DB7tWJ2R1UfAUJkF6bzYprmFEWeoA6b5jF6EX5HtIHXd0icAOUYl7tpOrM0wGpFplD1LmmIpj9aiaPLWH1Q/640?wx_fmt=jpeg&quot;/&gt;&lt;br/&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;&lt;span&gt;圣塔菲研究所外聘教授、密歇根大学复杂性研究中心主任斯科特·佩奇（Scott E Page）&lt;/span&gt;在Coursera上开设了一门名叫 &lt;em&gt;Model Thinking&lt;/em&gt; 的课程。&lt;/span&gt;&lt;span&gt;这门课以复杂系统的视角研究社会和经济学上的常见问题，介绍了十余个可以定量推演的模型。&lt;/span&gt;&lt;span&gt;佩奇教授还出版了多本畅销书，例如&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzIzMjQyNzQ5MA==&amp;amp;mid=2247493294&amp;amp;idx=1&amp;amp;sn=0661f59cb48309f32f08364845ba47c9&amp;amp;chksm=e897bc23dfe03535f5c21b1e1b837d655b53a78ed0448d4f3d62a56232de69d99c11db1ebc0d&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-linktype=&quot;2&quot;&gt;《多样性红利》&lt;/a&gt;一书，佩奇教授创造性地提出：&lt;span&gt;一个人是否聪明不是由智商决定的，而是取决于认知工具的多样性&lt;/span&gt;。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;238&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;293&quot; data-ratio=&quot;1.4&quot; data-s=&quot;300,640&quot; data-type=&quot;jpeg&quot; data-w=&quot;500&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/wibWV1DB7tWJ2R1UfAUJkF6bzYprmFEWedX8eR6VYtvkQwuh9wfTYDfdWI42GMFCBWkXwKsTt87xUcualyiaYlfQ/640?wx_fmt=jpeg&quot;/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;密西根大学教授斯科特·佩奇（Scott E Page）&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;&lt;span&gt;佩奇&lt;/span&gt;教授&lt;span&gt;为他的课程撰写了一本厚厚的教科书 &lt;em&gt;&lt;span&gt;The Model Thinker&lt;/span&gt;&lt;/em&gt;，&lt;/span&gt;在2018年11月份出版。全书分为29章，每一章都干货满满。书中不止列出了更多的模型，还系统性地展示了如何使用多种模型来分析现实社会中的问题。&lt;/span&gt;&lt;/p&gt;
&lt;section class=&quot;&quot; data-mpa-template-id=&quot;1507101&quot; data-mpa-color=&quot;null&quot; data-mpa-category=&quot;&amp;#x6536;&amp;#x85CF;&quot;&gt;&lt;br/&gt;&lt;section data-mid=&quot;t4&quot;&gt;&lt;section data-preserve-color=&quot;t&quot; data-mid=&quot;&quot; readability=&quot;1&quot;&gt;&lt;section data-mid=&quot;&quot; readability=&quot;2&quot;&gt;&lt;p mpa-is-content=&quot;t&quot;&gt;&lt;strong mpa-from-tpl=&quot;t&quot;&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;Why？ 世界太复杂，我们需要模型&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;
&lt;p&gt;&lt;span&gt;在从信息到智慧的每一步上，模型都可以成为上升的阶梯。&lt;span&gt;整理&lt;/span&gt;数据、提取信息，你需要通过建模来去伪存真；根据不同领域的信息，最终得出一个对大局、新情况或未来的判断，你需要预测性的模型去产生知识；而要知道在何时何地该提取哪些知识，则需要通过模型让隐藏的假设显现出来。根据作者的总结，模型的7种作用包括推理、解释、设计、沟通、指导行动、预测未来和探究可能性。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;

&lt;p&gt;&lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;/&gt; &lt;img class=&quot;&quot; data-ratio=&quot;0.5988538681948424&quot; data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-w=&quot;349&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/wibWV1DB7tWJ2R1UfAUJkF6bzYprmFEWeTtAa8kMG3dFicDJ96UUCrTRIicMtfDuLu3YV76BK3Hosf6gNtODVgsYA/640?wx_fmt=png&quot;/&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;类似的书还有《Algorithm to live by》。这本书讲的是用机器学习算法原理指导日程生活中的决策。关于如何决策，书中给出的回答是下图。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.7245508982035929&quot; data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-w=&quot;334&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/wibWV1DB7tWJ2R1UfAUJkF6bzYprmFEWe026Y5vyvloibzadQejG2cx8Fpy2j5ibVb1exXn6icwBvjg2GtZFTSTSsQ/640?wx_fmt=png&quot;/&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;这个框架没问题，但由于日常生活中要解决的问题都与他人有关，而人是具有主观能动性的，人的复杂性和多样性决定了任何模型都需要对模型中的人予以简化，从而使得模型不会像和真实国土一样大的地图那样全面却无用。而对人的简化有多种不同的方式，从这个逻辑起点出发，可以推演出不同的模型。没有一个模型适用于所有的坏境，但多样化的模型可以带来1+1 &amp;gt; 2的效应。&lt;/span&gt;&lt;/p&gt;
&lt;section class=&quot;&quot; data-mpa-template-id=&quot;1507101&quot; data-mpa-color=&quot;null&quot; data-mpa-category=&quot;&amp;#x6536;&amp;#x85CF;&quot;&gt;&lt;br/&gt;&lt;section data-mid=&quot;t4&quot;&gt;&lt;section data-preserve-color=&quot;t&quot; data-mid=&quot;&quot; readability=&quot;1&quot;&gt;&lt;section data-mid=&quot;&quot; readability=&quot;2&quot;&gt;&lt;p mpa-is-content=&quot;t&quot;&gt;&lt;strong mpa-from-tpl=&quot;t&quot;&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;How ？如何建模，不至于过度简化&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;
&lt;p&gt;&lt;strong&gt;&lt;span&gt;模型学习&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;学习一个模型，要搞清楚其组成结构、生成逻辑与应用场合。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;模型的组成结构除了实体和关系这些显式的部分，还包括模型对人和坏境做的假设。关于人的假设，包括：有绝对的理性及记忆力还是只能服从既定的规则、是否能够从过去的经验中学习、是否具有多个目标等。而关于环境的假设，包括：环境是否有多个属性、各个属性间是否相关、是否存在局部最优解、是否随着时间发生变化。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;生成逻辑则是一串数学公式和推算，指出在模型给定的假设下，会出现怎样的结论。&lt;/span&gt;&lt;span&gt;至于应用场景，一个模型可以在多个领域重复应用，一个模型也可嵌套进其他模型中，组成更大的模型，从而捕捉现实中更多的复杂性。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt; &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;人群建模&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;关于人群的模型，首先要讨论是人的多样性。通过三种概率分布（normal，lognormal，power），可以对&lt;strong&gt;人群的多样性&lt;/strong&gt;&lt;/span&gt; &lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;/&gt;  进行分类。三种分布对应着不同的假设，即不同时间点人获得的收益是否具有相关性，也包含着对环境的假设，即对人的评价取决于之前收益的加和或乘积。上述组合会产生上述的三种分布，以及一个长尾效应比幂律分布更显著的分布方式。&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;540&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;215&quot; data-ratio=&quot;0.3985209531635168&quot; data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-w=&quot;1217&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/wibWV1DB7tWK4YCtKg1aXKRia9dZ9e0EVIFw61PibnnApILQ5Y8xazYt22asP95Tic9Qib5uOwNcunuE6eMZmeWic5zg/640?wx_fmt=png&quot;/&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;对人群的多样性进行了分类，可以判定人群大小对其结果的影响，例如假设学习成绩是服从正态分布的，那么一个学校越小，其平均成绩就越有可能超越全国的平均水平，这不是由于小学校容易培养出好学生，仅仅是统计上较大规模的学校普遍更靠近平均水平。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt; &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;在考虑&lt;strong&gt;人与人的互动&lt;/strong&gt;时，从&lt;strong&gt;个人&lt;/strong&gt;的视角来看，可以根据外界对你决策反馈持续带来的收益（正、负、或者零）将模型分成三类。如果长远来看，外界没有对你的决策给予反馈，那你就可以使用线性模型去估计你决策的影响，可以通过P值来判断影响是否随机产生，可以通过R square来评估影响的大小。&lt;/span&gt;&lt;span&gt;如果外界总是满足你，那正反馈就会带来不稳定。反观《黑镜》的剧情，其中不少悲剧是由于科技进步带来的心想事成。而负反馈则会带来稳定和均衡。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt; &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;人不是在和一群人互动，而是在和&lt;strong&gt;一个个具体的人&lt;/strong&gt;互动。将人看成个体，就可以组成网络模型或者网格模型。网格模型将人放置在一个一维或者二维的棋盘中，一个人只能和附近有限个人互动；最典型的网格模型是生命游戏（game of life）。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;&lt;img class=&quot; __bg_gif&quot; data-ratio=&quot;0.5065963060686016&quot; data-type=&quot;gif&quot; data-w=&quot;379&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_gif/wibWV1DB7tWL04pOaYmBNsmhrwIWOzkMS7JHURK0zpSjwqHOqqUESePHU1EjIMtJ7P3cghrE4J6ic6eib4TVDOW2A/640?wx_fmt=gif&quot;/&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;而网络模型则可以让人与人之间自由连接，例如人际社交、网页间的链接、论文间的引用。而如果人与人之间的互动有不同的类型，那就可以将做同一类的人抽象为一个整体，从而产生系统动态（system dynamic）模型，例如下图所示：&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.5162162162162162&quot; data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-w=&quot;370&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/wibWV1DB7tWJ2R1UfAUJkF6bzYprmFEWe4D2wuvnPu34Dicj8Rraic1lMUSl8NrIjVff46csqgxAwLTLRGexnHmHw/640?wx_fmt=png&quot;/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;图中的面包店和排队的人可以看成网络中的节点，其属性是其当前的存量，受到已有消费者、面包师、潜在的消费者这三个资源池的影响&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt; &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;网络中的人不是孤立的，为了对其&lt;strong&gt;相互影响&lt;/strong&gt;建模，可以先将人分成几类，通过互动，人的分类会发生改变。例如疾病或者想法的传播。&lt;/span&gt;&lt;span&gt;为了引入人的不同，可以假定人有不同的阀值（threshold），只有影响足够强烈，才会被身边的人的影响。&lt;/span&gt;&lt;span&gt;为了引入待传播的思想的多样性，可以将人的偏好分为spatial（离自己越近越好）和hedonic（越多越好），再结合上不同的网络结构，就可以针对网络上思想的传播按照不同的方式进行建模。&lt;/span&gt;&lt;/p&gt;

&lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;/&gt; &lt;p&gt;&lt;span&gt;如果是为了预测，可以建立一个足够复杂的模型，但若是为了解释现象，或者探索未来的可能性，那就可以使用简单的模型，用足够简单的假设，让模型的推演重现出一部分直觉告诉你对的，再推翻一部分你本以为理所应当的结论。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt; &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;人与人不是只互动一次的，马尔可夫链反映了&lt;strong&gt;不同次互动对个人的影响&lt;/strong&gt;，而随机游走和路径依赖则可以看成是人与人持续互动所产生的模式的两个极端。互动的结果可能是合作，也可能相互的坑害，这其中就需要引入博弈论，引入经济学中的&lt;span&gt;信号传递模型（&lt;/span&gt;cost signal），引入群体选择与名望来解释为什么合作是可能的。这其中有足够多的模型，几本书也讲不完，这里就只是蜻蜓点水的带过。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt; &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;人与人之间的交往不止是个人行为，还涉及到&lt;strong&gt;制度的建立&lt;/strong&gt;。例如如何在一个团体内分配成功的果实，如何决定集体的行动，如何协调不同的偏好。你可以先列出你的规则需要满足的条件，如同《几何原本》中的公理系统，这些条件要简单且符合常识，然后去判断能不能找到一个满足这样要求的制度。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;有时你可以证明找不到满足全部条件的制度，那你就需要权衡到底要满足怎样的价值观，而有时则可以构建出来。例如夏普利值（Shapley Value），就是假设一个成员加入这个团体的顺序对其团队贡献度不应该有影响，因此对所有加入顺序下各个成员的贡献度进行加和平均。夏普利值可以用来解释为什么团队中有的人应该拿的多。虽然看起来有些人完成的成就不多，但是他们补足了团队的短板，例如下图的例子。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.6859756097560976&quot; data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-w=&quot;328&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/wibWV1DB7tWJ2R1UfAUJkF6bzYprmFEWeVOtH1FTCsP7ng46iaBTM8iciaM3bWD45nGB228qaWkeibLoibb1ler7f1vA/640?wx_fmt=png&quot;/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;每个人想出一个砖头的其他用途，图中A与C都想出了6个答案，但A应该从团队的奖励在获得更多，因为不管ABC三人谁先说，A都会丰富团队整体的创意&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt; &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;最关键的是，人是能够&lt;strong&gt;从错误中学习&lt;/strong&gt;的。&lt;em&gt;The Model Thinker &lt;/em&gt;这本书的最后也是最难的三章围绕学习展开，先对比了强化学习和社交学习：前者根据之前的行动的收益&lt;span&gt;来调整自己的认知&lt;/span&gt;，后者则根据他人的评价。不同的学习方式，可以导致囚徒困境中不同的纳什均衡在人群中成为主流。而当收益不固定时，多臂赌博机模型则能指出你该怎么平衡探索和收益。&lt;/span&gt;&lt;/p&gt;

&lt;section class=&quot;&quot; data-mpa-template-id=&quot;1507101&quot; data-mpa-color=&quot;null&quot; data-mpa-category=&quot;&amp;#x6536;&amp;#x85CF;&quot;&gt;&lt;section data-mid=&quot;t4&quot;&gt;&lt;section data-preserve-color=&quot;t&quot; data-mid=&quot;&quot;&gt;&lt;section data-mid=&quot;&quot;&gt;&lt;p mpa-is-content=&quot;t&quot;&gt;&lt;strong mpa-from-tpl=&quot;t&quot;&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;从模型到现实&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;
&lt;p&gt;&lt;span&gt;在这本书的最后一章，书中用十余个模型解释了现实生活中的贫富差距为何越演越烈：有的模型专注于富人为何越来越富，有的模型解释了为何种族间的贫富差距越拉越大，还有的模型解释了为何寒门难出贵子。&lt;/span&gt;&lt;/p&gt;

&lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;/&gt; &lt;p&gt;&lt;span&gt;模型思维的优势，不止体现在社会问题这样的经世济民中。对于年轻人来说，游戏中的模型思维更有趣。阅读这本书的时候，我一直在想书中的例子有哪些能够应用到杀人游戏中，例如马尔可夫链可以分析前后发言之间的关系，信息传播的模型可以预测投票的结果，如果能够写一本书，专门来讲如何在桌游中应用模型思维，那才真的有趣而有意义了！&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;


&lt;section class=&quot;&quot; data-mpa-template-id=&quot;1507101&quot; data-mpa-color=&quot;null&quot; data-mpa-category=&quot;&amp;#x6536;&amp;#x85CF;&quot;&gt;&lt;section data-mid=&quot;t4&quot;&gt;&lt;section data-preserve-color=&quot;t&quot; data-mid=&quot;&quot; readability=&quot;1&quot;&gt;&lt;section data-mid=&quot;&quot; readability=&quot;2&quot;&gt;&lt;p mpa-is-content=&quot;t&quot;&gt;&lt;strong mpa-from-tpl=&quot;t&quot;&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;模型思维范例： 多臂老虎机模型与Gittins Index&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;

&lt;p&gt;&lt;span&gt;假设一个赌场里有多台老虎机，你知道其中有几台被做过手脚，却不知道是哪几台，你有玩老虎机一百次的本钱，这时你要怎么做？要回答这个问题，你首先要假设人是理性的，他能记住每一次玩之后的结果，能够根据此进行学习。还要假设人是遵守预先设定的假设，这个人说会玩100次，就一定会玩100次，一定会玩100次，不管其中输赢的先后顺序。在现实中，这俩点都是不满足的，但作为建立模型的起点，可以先这样假设。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;&lt;span&gt;当我们放宽关于玩家的假设，我们可以看看不同的目标会对模型造成怎样的影响，假设赌场的目标可以是要在保证固定收益率的同时玩家尽可能的多玩，也可能是尽可能的提高利益率，在不同的目标下，可以探讨赌城该怎样设置被动手脚的老虎机的比例等更多问题。而将我们手机中的每个推送，每件新鲜事当成是一次老虎机的一次实验，也可扩展模型的适用范围。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;&lt;span&gt;回到最初的问题，最简单的方法是先在赌场中的每台机器上试验几次，之后找出收益最多的一个一直玩，这种策略被称作sample-then-greedy，类似于年轻时尝试几个行业，之后就一直在这个行业做下去。更好的策略是adaptive exploration，先每个老虎机玩一次，之后根据收益的比例，在下一轮的尝试中对各个老虎机分配相应的比例。这样的做法像同时尝试几个职业，之后那个职业做的好就逐渐对其投入更多的精力，而将其他的当成兼职，但总会多少对其分配一些经历。而更好的办法是&lt;/span&gt;&lt;/span&gt;&lt;span&gt;Gittins Index，其讲的是多臂老虎机中该怎么平衡&lt;/span&gt;&lt;span&gt;探索与利用（&lt;/span&gt;&lt;span&gt;explore vs exploit）的收益，其中利用了贝叶斯的思维，&lt;/span&gt;&lt;span&gt;考虑到了不确定性对未来决策的影响。&lt;/span&gt;&lt;/p&gt;


&lt;p&gt;&lt;span&gt;假设你本来有一个稳定获得500收益的机会，现在你多了一个抽奖选项，你有机会在接下来的回合获得1000单位的收益，90%的机会什么都得不到，请问你愿意为了这个抽奖的机会付出多少？&lt;/span&gt;&lt;span&gt;答案是假设你获得了抽奖的机会，你会在第一回合抽奖。第一次抽奖中了，那你就一直选这个这样你下一回合就能拿到1000单位的收益；如果没抽中，那就下一回合选稳妥的，这样你的预期收益是0.1×1000+0.9×500，因此你愿意为这个抽奖机会付出550单位。至于如何将Gitten Index的思路用在多臂老虎机中，读者可以自己思考。在强化学习中，多臂老虎机是一个经典的问题，还有更多的解放，这里只是借此展示模型思维的具体案例。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;更多阅读&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651383664&amp;amp;idx=1&amp;amp;sn=89f11f166582925c041b960035f10c37&amp;amp;chksm=84f3c931b3844027a5c484c7af41f73dada1cb15a87fe4aa776fe293e45b66c0ea96e2e20c77&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-linktype=&quot;2&quot;&gt;强化学习最小手册&lt;/a&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;


&lt;section class=&quot;&quot; data-mpa-template-id=&quot;1507101&quot; data-mpa-color=&quot;null&quot; data-mpa-category=&quot;&amp;#x6536;&amp;#x85CF;&quot;&gt;
&lt;/section&gt;

</description>
<pubDate>Fri, 11 Jan 2019 18:13:11 +0000</pubDate>
<dc:language>zh-CN</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.jintiankansha.me/t/suaRCxrWfr</dc:identifier>
</item>
<item>
<title>长文解读吴恩达新书《Machine Learning Yearning》</title>
<link>http://www.jintiankansha.me/t/bOuNks81mo</link>
<guid isPermaLink="true" >http://www.jintiankansha.me/t/bOuNks81mo</guid>
<description>&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;1.2906976744186047&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcdVhqnC0Cm5SNibd1viaTJ5KIibx5hkQzibjYiakN3ibuRjTtIK0mOWEV6mkx69lNs43TViaO26WR8BJuCLg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;602&quot;/&gt;&lt;/p&gt;
&lt;section class=&quot;&quot; data-mpa-template-id=&quot;882153&quot; data-mpa-color=&quot;null&quot; data-mpa-category=&quot;fav&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section class=&quot;&quot;&gt;1&lt;/section&gt;&lt;section&gt;学习策略&lt;/section&gt;&lt;section https:=&quot;&quot; left=&quot;&quot; no-repeat=&quot;&quot; rgb=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;/&gt;&lt;/section&gt;&lt;section/&gt;&lt;/section&gt;&lt;/section&gt;
&lt;p&gt;首先强调整本书不是讲机器学习的算法，而是讲让在实践中做机器学习项目时采用的策略，简称学习策略 (learning strategy)。该策略包括如何应对以下几个问题：&lt;/p&gt;

&lt;ol class=&quot; list-paddingleft-2&quot; readability=&quot;2&quot;&gt;&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;用完机器学习后效果不好怎么办？&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;在项目之前如何设定有效的目标？&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;如何有效的进行误差分析？&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;如何有效的识别误差来源？&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;如何解决数据分布不匹配问题？&lt;/p&gt;


&lt;/li&gt;
&lt;/ol&gt;&lt;section class=&quot;&quot; data-mpa-template-id=&quot;882500&quot; data-mpa-color=&quot;null&quot; data-mpa-category=&quot;fav&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section https:=&quot;&quot; inline-block=&quot;&quot; auto=&quot;&quot; no-repeat=&quot;&quot; top=&quot;&quot; rgb=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;&gt;&lt;p&gt;&lt;span&gt;1.1&lt;/span&gt;&lt;/p&gt;
&lt;/section&gt;&lt;section https:=&quot;&quot; inline-block=&quot;&quot; left=&quot;&quot; auto=&quot;&quot; no-repeat=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong mpa-from-tpl=&quot;t&quot;&gt;深度学习的起飞&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;/section&gt;&lt;/section&gt;&lt;section https:=&quot;&quot; inline-block=&quot;&quot; left=&quot;&quot; auto=&quot;&quot; no-repeat=&quot;&quot; top=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section class=&quot;&quot; data-mpa-template-id=&quot;998729&quot; data-mpa-color=&quot;null&quot; data-mpa-category=&quot;fav&quot; readability=&quot;1&quot;&gt;&lt;section readability=&quot;2&quot;&gt;&lt;p&gt;&lt;strong&gt;要点：深度学习的流行是因为现在有大量的数据和便宜的算力。&lt;/strong&gt;&lt;/p&gt;
&lt;/section&gt;&lt;/section&gt;
&lt;p&gt;深度学习可以不严谨的认为就是神经网络，而神经网络早在 1969 年就被研究了，而 1986 年 Hinton 的反向传播算法的论文也有效的提升了训练网络的速度，但为什么近些年深度学习才全面起飞呢？原因有三点：&lt;br/&gt;&lt;/p&gt;

&lt;ol class=&quot; list-paddingleft-2&quot; readability=&quot;0.5&quot;&gt;&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;&lt;strong&gt;大数据&lt;/strong&gt;：IoT 产生的图片，语音，文本等。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;&lt;strong&gt;高算力&lt;/strong&gt;：CPU 到 GPU 到 TPU。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;&lt;strong&gt;强算法&lt;/strong&gt;：数据增多了，算力便宜了，研究员才有能力来研究更强的算法。这是一个正循环过程。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;下图展示了四种模型的在数据量由小到大的表现。当数据量越来越大时，传统机器学习的表现会趋于平缓，喂它再多的数据也消化不了了。而深层神经网络对数据的非常饥渴，现在如果想要最先进 (state-of-the-art) 的表现，只有用“深度学习”加“大数据”！&lt;/p&gt;

&lt;p&gt;&lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;/&gt; &lt;img class=&quot;&quot; data-backh=&quot;359&quot; data-backw=&quot;558&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.643312101910828&quot; data-s=&quot;300,640&quot; data-type=&quot;jpeg&quot; data-w=&quot;942&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/e4kxNicDVcCFUP40nwDeoQEUnANXTlcCrvy4jZRNdrOM8dx3lhHTzWOcdfXiabQ6f5yFwOLdBtQzsrx0yPgNE5bA/640?&quot;/&gt;&lt;/p&gt;

&lt;p&gt;大神的图其实有些不准确，在 2000 年前数据不够多时，支撑向量机 (SVM) 的表现是稳定的压着神经网络的。更合理的图应该如下：&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;&quot; data-backh=&quot;359&quot; data-backw=&quot;558&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.6426299045599152&quot; data-s=&quot;300,640&quot; data-type=&quot;jpeg&quot; data-w=&quot;943&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/e4kxNicDVcCFUP40nwDeoQEUnANXTlcCriasQRgnibYUVovRV0n2mjrPNX5IC37cLfPbPMNNtknp13XUw4MVJzzng/640?&quot;/&gt;&lt;/p&gt;

&lt;section class=&quot;&quot; data-mpa-template-id=&quot;882500&quot; data-mpa-color=&quot;null&quot; data-mpa-category=&quot;fav&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section https:=&quot;&quot; inline-block=&quot;&quot; auto=&quot;&quot; no-repeat=&quot;&quot; top=&quot;&quot; rgb=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;&gt;&lt;p&gt;&lt;span&gt;1.2&lt;/span&gt;&lt;/p&gt;
&lt;/section&gt;&lt;section https:=&quot;&quot; inline-block=&quot;&quot; left=&quot;&quot; auto=&quot;&quot; no-repeat=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong mpa-from-tpl=&quot;t&quot;&gt;正交策略&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;/section&gt;&lt;/section&gt;&lt;section https:=&quot;&quot; inline-block=&quot;&quot; left=&quot;&quot; auto=&quot;&quot; no-repeat=&quot;&quot; top=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section class=&quot;&quot; data-mpa-template-id=&quot;998729&quot; data-mpa-color=&quot;null&quot; data-mpa-category=&quot;fav&quot; readability=&quot;1.5&quot;&gt;&lt;section readability=&quot;3&quot;&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;要点：机器学习每次只调试一个参数，保持其它参数不变。这种每次只改变模型某一性能的策略叫做正交策略。&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;/section&gt;&lt;/section&gt;
&lt;p&gt;“正交性”是几何学中的术语，通俗理解正交 (orthogonalization) 就是垂直。用在计算技术中：&lt;/p&gt;


&lt;p&gt;通常正交系统比非正交体统好，就像在线性代数中，正交向量比非正交向量好，如下图，你愿意用向量 a 和 b (正交) 还是用向量 c 和 d (非正交) 来表示 X?&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;&quot; data-backh=&quot;293&quot; data-backw=&quot;558&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.5260058881256133&quot; data-s=&quot;300,640&quot; data-type=&quot;jpeg&quot; data-w=&quot;1019&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/e4kxNicDVcCFUP40nwDeoQEUnANXTlcCrow9Oe1bdY67Lhib4VwLYKJsic03usDyKC68hZhnAcVibE6bSVWwGXsvOA/640?&quot;/&gt;&lt;/p&gt;

&lt;p&gt;同理，你愿意将表现 X 归结于因素 a 和 b (正交) 还是归结于因素 c 和 d (非正交)?&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;&quot; data-backh=&quot;293&quot; data-backw=&quot;558&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.5260058881256133&quot; data-s=&quot;300,640&quot; data-type=&quot;jpeg&quot; data-w=&quot;1019&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/e4kxNicDVcCFUP40nwDeoQEUnANXTlcCrGRiav4ICKfS3ovjiaJttzU8reiaepmp1icfiaK2iaAVR8r9DUL7BYFCzqqeg/640?&quot;/&gt;&lt;/p&gt;

&lt;p&gt;相信你的选择都是正交，因为只有正交，你调整一个组件不会影响到另一个组件。在神经网络模型中，以下四个命题是相互正交的：&lt;/p&gt;
&lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;/&gt; 
&lt;ol class=&quot; list-paddingleft-2&quot; readability=&quot;1&quot;&gt;&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;模型在训练集上的表现&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;模型在开发集上的表现&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;模型在测试集上的表现&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;模型在真实环境的表现&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;通常模型在训练集 (training set) 上训练，在开发集 (development set, dev set) 上调参，在测试集 (test set) 上评估，在真实环境中运用，因此模型的表现通常有以下关系&lt;/p&gt;

&lt;p&gt;    P&lt;span&gt;&lt;sub&gt;&lt;span&gt;训练集&lt;/span&gt;&lt;/sub&gt;&lt;/span&gt; &amp;gt; P&lt;span&gt;&lt;sub&gt;&lt;span&gt;开发集&lt;/span&gt;&lt;/sub&gt;&lt;/span&gt; &amp;gt; P&lt;span&gt;&lt;sub&gt;&lt;span&gt;测试集&lt;/span&gt;&lt;/sub&gt;&lt;/span&gt; &amp;gt; P&lt;span&gt;&lt;sub&gt;&lt;span&gt;真实环境&lt;/span&gt;&lt;/sub&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;因此当模型在&lt;/p&gt;

&lt;p&gt;P&lt;span&gt;&lt;sub&gt;&lt;span&gt;训练集&lt;/span&gt;&lt;/sub&gt;&lt;/span&gt; = 差&lt;/p&gt;


&lt;p&gt;P&lt;span&gt;&lt;sub&gt;&lt;span&gt;训练集&lt;/span&gt;&lt;/sub&gt;&lt;/span&gt; = 好，看 P&lt;span&gt;&lt;sub&gt;&lt;span&gt;开发集&lt;/span&gt;&lt;/sub&gt;&lt;/span&gt;&lt;/p&gt;

&lt;ul class=&quot; list-paddingleft-2&quot;&gt;&lt;li&gt;
&lt;p&gt;P&lt;span&gt;&lt;sub&gt;&lt;span&gt;开发集&lt;/span&gt;&lt;/sub&gt;&lt;/span&gt; = 差&lt;br/&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt; &lt;span&gt;最后，我觉得其实麦肯锡的“MECE 原则”比“正交策略”更适合描述此问题。MECE, 全称 Mutually Exclusive Collectively Exhausive，中文是“相互独立，完全穷尽”。它是一种解决问题的方法，对于一个大问题能不重叠不遗漏的分成子问题。正交策略只点出“相互独立”的性质，而 MECE 原则还包括“完全穷尽”性质，处理问题格局更大一些。&lt;/span&gt;&lt;/p&gt;

&lt;section class=&quot;&quot; data-mpa-template-id=&quot;882154&quot; data-mpa-color=&quot;null&quot; data-mpa-category=&quot;fav&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section class=&quot;&quot;&gt;2&lt;/section&gt;&lt;section&gt;目标设定&lt;/section&gt;&lt;section https:=&quot;&quot; left=&quot;&quot; no-repeat=&quot;&quot; rgb=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;/&gt;&lt;/section&gt;&lt;section/&gt;&lt;/section&gt;&lt;/section&gt;
&lt;p&gt;机器学习中需要划分训练集 (用于训模)，开发集 (用于调参) 和测试集 (用于评估)。为了更快更有效的开始项目，合理指定开发集测试集、选取单一指标、和迅速更换开发集测试集 (一旦出现问题) 是三大要点。接下来三小节会具体阐明。&lt;/p&gt;

&lt;section class=&quot;&quot; data-mpa-template-id=&quot;882500&quot; data-mpa-color=&quot;null&quot; data-mpa-category=&quot;fav&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section https:=&quot;&quot; inline-block=&quot;&quot; auto=&quot;&quot; no-repeat=&quot;&quot; top=&quot;&quot; rgb=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;&gt;&lt;p&gt;&lt;span&gt;2.1&lt;/span&gt;&lt;/p&gt;
&lt;/section&gt;&lt;section https:=&quot;&quot; inline-block=&quot;&quot; left=&quot;&quot; auto=&quot;&quot; no-repeat=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong mpa-from-tpl=&quot;t&quot;&gt;数据划分&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;/section&gt;&lt;/section&gt;&lt;section https:=&quot;&quot; inline-block=&quot;&quot; left=&quot;&quot; auto=&quot;&quot; no-repeat=&quot;&quot; top=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section class=&quot;&quot; data-mpa-template-id=&quot;998729&quot; data-mpa-color=&quot;null&quot; data-mpa-category=&quot;fav&quot; readability=&quot;2&quot;&gt;&lt;section readability=&quot;4&quot;&gt;&lt;p&gt;&lt;span&gt;&lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;/&gt; &lt;strong&gt;要点 1：划分训练-开发-测试，数据少可按传统的 60/20/20 划分，数据多可按的 98/1/1 划分。对开发集来说，具体百分比要看它是否能区分不同算法的指标 (比如精度)。&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;/section&gt;&lt;/section&gt;
&lt;p&gt;在大数据时代前，当样本数量不多 (小于一万) 的时候，通常将训练-开发-测试的比例设为 60/20/20；比如 10,000 个数据被随机分成 6,000 个用于训练，2,000 个用于开发，2,000 个用于测试。&lt;/p&gt;

&lt;p&gt;在大数据来临时，当样本数量很多(百万级别) 的时候，通常将训练-开发-测试的比例设为 98/1/1；比如 1,000,000 个数据个数据被随机分成 980,000 个用于训练，10,000 个用于开发，10,000 个用于测试。&lt;/p&gt;

&lt;p&gt;对开发集理数据数量的设定，应该遵循的准则是该数量能够检测不同算法或模型的区别，以便选择出更好的模型。比如模型 A 和 B 的精度是 90% 和 90.1%，两者差 0.1%。那么开发集&lt;/p&gt;

&lt;ul class=&quot; list-paddingleft-2&quot; readability=&quot;2&quot;&gt;&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;100 个数据不够，100×0.1% = 0.1 个数据，无法分辨 A 和 B 的差异&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;1&quot;&gt;
&lt;p&gt;1,000 个数据也不够，1,000×0.1% = 1 个数据，较难分辨 A 和 B 的差异&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;1&quot;&gt;
&lt;p&gt;10,000 个数据够了，10,000×0.1% = 10 个数据，容易分辨 A 和 B 的差异&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;对于测试集数据数量的设定，传统上是全部数据的 20% 到 30%；在大数据时代，我们不再用百分比，而是设定一个绝对数值，比如 1,000 到 10,000 个。&lt;/p&gt;

&lt;section class=&quot;&quot; data-mpa-template-id=&quot;998729&quot; data-mpa-color=&quot;null&quot; data-mpa-category=&quot;fav&quot; readability=&quot;1&quot;&gt;&lt;section readability=&quot;2&quot;&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;要点 2：训练集、开发集和测试集的数据要来自同一分布。&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;/section&gt;&lt;/section&gt;
&lt;p class=&quot;&quot;&gt;首先训练集和开发集的数据要来自同一分布，如果在 P 分布训练集上训练，又在 Q 分布开发集上调参，效果明显不会好。&lt;/p&gt;

&lt;p class=&quot;&quot;&gt;其次训练集和测试集的数据要来自同一分布，要不然训练误差和真实误差 (通常认为是测试误差)  之间的霍夫丁不等式不成立，那么整个计算学习理论也站不住脚了。&lt;/p&gt;

&lt;p class=&quot;&quot;&gt;最后开发集和测试集来源于同一分布。如果它们不来自同一分布，那么我们从开发集上选择的最佳模型往往在测试集上不会表现很好。举个例子，我们在开发集上找到最接近靶心的箭，但是测试集的靶心却远远偏离开发集的靶心，结果这支箭肯定无法射中测试集的靶心。&lt;/p&gt;

&lt;p class=&quot;&quot;&gt;下图总结了上面所有内容。&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;&quot; data-backh=&quot;449&quot; data-backw=&quot;559&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.8048780487804879&quot; data-s=&quot;300,640&quot; data-type=&quot;jpeg&quot; data-w=&quot;1271&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/e4kxNicDVcCH9EViaib3KEia4h875rFXoJiclWkEma9pJibG8qqX15aTleHkrAmtvO1Oz1cp7Wib4S8a8ZAic5mWsEO6fQ/640?wx_fmt=jpeg&quot;/&gt;&lt;/p&gt;

&lt;section class=&quot;&quot; data-mpa-template-id=&quot;882500&quot; data-mpa-color=&quot;null&quot; data-mpa-category=&quot;fav&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section https:=&quot;&quot; inline-block=&quot;&quot; auto=&quot;&quot; no-repeat=&quot;&quot; top=&quot;&quot; rgb=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;&gt;&lt;p&gt;&lt;span&gt;2.2&lt;/span&gt;&lt;/p&gt;
&lt;/section&gt;&lt;section https:=&quot;&quot; inline-block=&quot;&quot; left=&quot;&quot; auto=&quot;&quot; no-repeat=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;&gt;&lt;section&gt;&lt;p&gt;&lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;/&gt; &lt;span&gt;&lt;strong mpa-from-tpl=&quot;t&quot;&gt;指标选取&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;/section&gt;&lt;/section&gt;&lt;section https:=&quot;&quot; inline-block=&quot;&quot; left=&quot;&quot; auto=&quot;&quot; no-repeat=&quot;&quot; top=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section class=&quot;&quot; data-mpa-template-id=&quot;998729&quot; data-mpa-color=&quot;null&quot; data-mpa-category=&quot;fav&quot; readability=&quot;1&quot;&gt;&lt;section readability=&quot;2&quot;&gt;&lt;p&gt;&lt;strong&gt;要点 1：单值评价指标有助于比较不同模型的优劣，快速选择最优模型。&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;
&lt;/section&gt;&lt;/section&gt;
&lt;p&gt;大神举了个查准 (precision) 和查全 (recall) 的例子，如下表，A 比 B 全，B 比 A 准，那么该选哪个呢？你会发现当多个指标好坏不一致时，做决定不是那么容易。这时用 F1 分数将两者求调和平均，得知 A 比 B 高，选 A！&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;&quot; data-backh=&quot;68&quot; data-backw=&quot;499&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.13627254509018036&quot; data-s=&quot;300,640&quot; data-type=&quot;jpeg&quot; data-w=&quot;499&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/e4kxNicDVcCH9EViaib3KEia4h875rFXoJicl1REcm3sUrJ3GevyNwpp21kUmF7qXKTqbicS7UI0K9PVyjhszFq9dA3Q/640?wx_fmt=jpeg&quot;/&gt;&lt;/p&gt;

&lt;p&gt;我来举个更实际也更接地气 (如果你是 NBA 球迷) 的例子。每年 NBA 会评选 MVP，都会看每个球员的各项统计，比如得分、篮板、助攻等。&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;&quot; data-backh=&quot;75&quot; data-backw=&quot;559&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.1341991341991342&quot; data-s=&quot;300,640&quot; data-type=&quot;jpeg&quot; data-w=&quot;693&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/e4kxNicDVcCH9EViaib3KEia4h875rFXoJiclqqYp9XmSfLciaJQYddNJPgU7cZqAcAmmJCNoH5yS9EehVKso6FibsOfQ/640?wx_fmt=jpeg&quot;/&gt;&lt;/p&gt;

&lt;p&gt;光看各项统计很难决定 MVP 给谁，比如哈登得分和抢断最多，勒布朗最均衡，维斯布鲁克篮板助攻最多而且场均三双，如何做决定。用一个单值的效率指标 (Player Efficiency Rating, PER)，PER 是 ESPN 专栏作家 John Hollinger 提出来的，计算公式如下&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;&quot; data-backh=&quot;260&quot; data-backw=&quot;559&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.465625&quot; data-s=&quot;300,640&quot; data-type=&quot;jpeg&quot; data-w=&quot;1280&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/e4kxNicDVcCH9EViaib3KEia4h875rFXoJiclibYEjgKRzbZ8bNFqArDADicclxRbkxsfWhiacJoNw43LgY3bTJianjicYWA/640?wx_fmt=jpeg&quot;/&gt;&lt;/p&gt;

&lt;p&gt;公式很复杂，我们也需要关注细节，只需了解这个 PER 将得分、篮板、助攻、盖帽、抢断和其他很多因素综合起来得到一个单值指标 (single metric)。这样看哈登的效率 &lt;strong&gt;29.87&lt;/strong&gt; 最高，MVP 应该颁给他。&lt;/p&gt;

&lt;p&gt;&lt;span&gt;&lt;strong&gt;大神和我举的例子都说明了评估多项指标而决定时不容易，用简单平均或者复杂公式得出一个单值指标会有效快速的做出决定。&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;

&lt;section class=&quot;&quot; data-mpa-template-id=&quot;998729&quot; data-mpa-color=&quot;null&quot; data-mpa-category=&quot;fav&quot; readability=&quot;2&quot;&gt;&lt;section readability=&quot;4&quot;&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;要点 2：有时把综合所有指标构成单值评价指标很困难，可以把某些性能作为优化指标 (Optimizing Metric) 找最优值；而某些性能作为满意指标 (Satisficing Metric&lt;/strong&gt;&lt;/span&gt;&lt;strong&gt;）满足特定条件即可。&lt;/strong&gt;&lt;/p&gt;
&lt;/section&gt;&lt;/section&gt;
&lt;p&gt;大神举了个精度和运行时间的例子，如下表，A 最快但精度最低，C 最慢但精度最高，B 则在中间。通常很难给一个函数来综合精度和运行时间，我们可以根据自身需求来选择模型。&lt;/p&gt;

&lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;/&gt; 
&lt;p&gt;&lt;img class=&quot;&quot; data-backh=&quot;93&quot; data-backw=&quot;558&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.16755793226381463&quot; data-s=&quot;300,640&quot; data-type=&quot;jpeg&quot; data-w=&quot;561&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/e4kxNicDVcCH9EViaib3KEia4h875rFXoJiclhtQkiaDs8AGial7iblibibibxMhTN6K7gooZQpT3IQTiaIX6QKwRUCwLz35hg/640?wx_fmt=jpeg&quot;/&gt;&lt;/p&gt;


&lt;p&gt;如果&lt;/p&gt;
&lt;ul class=&quot; list-paddingleft-2&quot; readability=&quot;1&quot;&gt;&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;你 (一般人) &lt;span&gt;接受一定的运行时间&lt;/span&gt; (100ms 之内) 来&lt;span&gt;最大化精度&lt;/span&gt;，选 B&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;你 (土豪) &lt;span&gt;接受一定的运行时间&lt;/span&gt; (2000ms 之内) 来&lt;span&gt;最大化精度&lt;/span&gt;，选 C&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;你 (精度凡人) &lt;span&gt;接受一定的精度&lt;/span&gt; (89% 以上) 来&lt;span&gt;最小化运行时间&lt;/span&gt;，选 A&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;你 (精度狂人) &lt;span&gt;接受一定的精度&lt;/span&gt; (99% 以上) 来&lt;span&gt;最小化运行时间&lt;/span&gt;，选 C&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;span&gt;接受的指标&lt;/span&gt;称为&lt;span&gt;满意指标&lt;/span&gt; (&lt;span&gt;Satisficing Metric&lt;/span&gt;)，&lt;span&gt;而最大化或最小化的指标&lt;/span&gt;&lt;span&gt;称为&lt;/span&gt;&lt;span&gt;优化指标&lt;/span&gt;(&lt;span&gt;Optimizing Metric&lt;/span&gt;)。&lt;/p&gt;

&lt;p&gt;&lt;span&gt;继续刚才 &lt;/span&gt;&lt;span&gt;NBA &lt;/span&gt;&lt;span&gt;选 &lt;/span&gt;&lt;span&gt;MVP &lt;/span&gt;&lt;span&gt;的例子，有人会说效率高有什么用，带队赢球才是王道。没错，效率再高战绩倒数，你充其量就是个数据刷子&lt;/span&gt;&lt;span&gt; (&lt;/span&gt;&lt;span&gt;参考 &lt;/span&gt;&lt;span&gt;2010 &lt;/span&gt;&lt;span&gt;年森林狼的凯文乐福&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;&lt;span&gt;。考虑球队战绩后的表格如下，&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;&quot; data-backh=&quot;75&quot; data-backw=&quot;558&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.13439306358381503&quot; data-s=&quot;300,640&quot; data-type=&quot;jpeg&quot; data-w=&quot;692&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/e4kxNicDVcCH9EViaib3KEia4h875rFXoJiclmhptDF4FvVV3VITiaYpMq8aIAGBqhlDuJBx0Fqia2hpNs0G45O3L6dBg/640?wx_fmt=jpeg&quot;/&gt;&lt;/p&gt;

&lt;p&gt;把战绩当成满意指标，比如&lt;/p&gt;

&lt;ul class=&quot; list-paddingleft-2&quot; readability=&quot;1.5&quot;&gt;&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;所处球队 60 胜以上，效率最高的球员，只有哈登！&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;所处球队 50 胜以上，效率最高的球员，只有哈登！&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;所处球队 40 胜以上，效率最高的球员，是哈登 &amp;gt; 勒布朗 &amp;gt; 维斯布鲁克&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;所处球队 30 胜以上，效率最高的球员，可能还有别人，但是 30 胜能拿 MVP？&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;综上所述，今年 MVP 非我大火箭的大哈登所属！哇哈哈哈！&lt;/p&gt;
&lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;/&gt; 
&lt;p&gt;&lt;span&gt;&lt;strong&gt;大神和我举的例子都说明了如果多项指标没有一个简单的函数来综合，选用满意指标来筛选，再用优化指标来排序。注意，满意指标可能不止一个，但是优化指标一定只有一个！&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;

&lt;section class=&quot;&quot; data-mpa-template-id=&quot;882500&quot; data-mpa-color=&quot;null&quot; data-mpa-category=&quot;fav&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section https:=&quot;&quot; inline-block=&quot;&quot; auto=&quot;&quot; no-repeat=&quot;&quot; top=&quot;&quot; rgb=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;&gt;&lt;p&gt;&lt;span&gt;2.3&lt;/span&gt;&lt;/p&gt;
&lt;/section&gt;&lt;section https:=&quot;&quot; inline-block=&quot;&quot; left=&quot;&quot; auto=&quot;&quot; no-repeat=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong mpa-from-tpl=&quot;t&quot;&gt;迭代实施&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;/section&gt;&lt;/section&gt;&lt;section https:=&quot;&quot; inline-block=&quot;&quot; left=&quot;&quot; auto=&quot;&quot; no-repeat=&quot;&quot; top=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section class=&quot;&quot; data-mpa-template-id=&quot;998729&quot; data-mpa-color=&quot;null&quot; data-mpa-category=&quot;fav&quot; readability=&quot;1.5&quot;&gt;&lt;section readability=&quot;3&quot;&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;要点 1：开始新系统要快速进入迭代过程，先有各种思路，再用代码实现，再做试验看那些思路可行。该迭代过程越快，进度越快。&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;/section&gt;&lt;/section&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-backh=&quot;340&quot; data-backw=&quot;450&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.7555555555555555&quot; data-s=&quot;300,640&quot; data-type=&quot;jpeg&quot; data-w=&quot;450&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/e4kxNicDVcCH9EViaib3KEia4h875rFXoJiclwq7pXPPOt46k49HIyB7ur0mlXaEeylYsQoSaamm7UHgbsPfTEWMTAQ/640?wx_fmt=jpeg&quot;/&gt;&lt;/p&gt;

&lt;p&gt;“想思路– 写代码– 做试验”是一个迭代过程，做试验需要对比哪个模型在开发集和测试集上的表现好，因此快速划分开发集和测试集，快速制定单值指标是非常重要的。&lt;/p&gt;

&lt;section class=&quot;&quot; data-mpa-template-id=&quot;998729&quot; data-mpa-color=&quot;null&quot; data-mpa-category=&quot;fav&quot; readability=&quot;1.5&quot;&gt;&lt;section readability=&quot;3&quot;&gt;&lt;p&gt;&lt;strong&gt;要点 2：当发现原先设定的开发集、测试集或指标没有指向正确的方向，赶快换！&lt;/strong&gt;&lt;/p&gt;
&lt;/section&gt;&lt;/section&gt;
&lt;p&gt;大神给的建议，快速划分开发集和测试集，快速制定指标，赶快开始做项目，不要多想 (overthink)，但是有时开发集、测试集和指标可能是不完美的，如果出现以下三种情况，大神建议赶快换它们。&lt;/p&gt;

&lt;hr/&gt;&lt;p&gt;&lt;strong&gt;情况一&lt;/strong&gt;：开发集和测试集用的是网上高清图片，真实环境是手机拍的模糊图片。&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;&quot; data-backh=&quot;129&quot; data-backw=&quot;558&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.23203125&quot; data-s=&quot;300,640&quot; data-type=&quot;jpeg&quot; data-w=&quot;1280&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/e4kxNicDVcCH9EViaib3KEia4h875rFXoJiclFOoPKMQgQsY1vImicwiarNKtwTr6wcl95ibxC16khkpu0FAVVlCUKyK6Q/640?wx_fmt=jpeg&quot;/&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;解决方案&lt;/strong&gt;：收集从手机拍的照片放入开发集和测试集。&lt;/p&gt;
&lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;/&gt; 
&lt;hr/&gt;&lt;p&gt;&lt;strong&gt;情况二&lt;/strong&gt;：模型在开发集的表现比在测试集的表现好，这是过拟合开发集的信号。有句话说得好，当你过度折磨数据，数据会投降。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;解决方案&lt;/strong&gt;&lt;span&gt;：&lt;/span&gt;用一个大一点的开发集，或者换一个新的开发集。&lt;/p&gt;

&lt;hr/&gt;&lt;p&gt;&lt;strong&gt;情况三&lt;/strong&gt;：两个猫分类器 A 和 B，精度分别是 97% 和 95%，但是 A 会错将色情图片分类成猫，而 B 不会这样。从进度角度来说，A 模型好，但从用户角度来说，一定是 B 模型好。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;解决方案&lt;/strong&gt;&lt;span&gt;：&lt;/span&gt;改变之前单纯使用错误率作为评价标准，例如增加色情图片的权重，增加其被误分类的代价。代价函数改进如下：&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;&quot; data-backh=&quot;137&quot; data-backw=&quot;548&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.25&quot; data-s=&quot;300,640&quot; data-type=&quot;jpeg&quot; data-w=&quot;548&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/e4kxNicDVcCH9EViaib3KEia4h875rFXoJicl0MDrOX1dSrJ4IjsUjiawGy475ZdqM1S2q6hqNPHHffpe0D5uAibr1rEQ/640?wx_fmt=jpeg&quot;/&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;当图片 &lt;/span&gt;&lt;span&gt;i &lt;/span&gt;&lt;span&gt;是色情图片时，权重 &lt;/span&gt;&lt;span&gt;i &lt;/span&gt;&lt;span&gt;放 &lt;/span&gt;&lt;span&gt;10&lt;/span&gt;&lt;span&gt;，当图片 &lt;/span&gt;&lt;span&gt;i &lt;/span&gt;&lt;span&gt;是非色情图片时，权重 &lt;/span&gt;&lt;span&gt;i &lt;/span&gt;&lt;span&gt;放 &lt;/span&gt;&lt;span&gt;1&lt;/span&gt;&lt;span&gt;。&lt;/span&gt;&lt;/p&gt;


&lt;section class=&quot;&quot; data-mpa-template-id=&quot;882155&quot; data-mpa-color=&quot;null&quot; data-mpa-category=&quot;fav&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section class=&quot;&quot;&gt;3&lt;/section&gt;&lt;section&gt;误差分析&lt;/section&gt;&lt;section https:=&quot;&quot; left=&quot;&quot; no-repeat=&quot;&quot; rgb=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;/&gt;&lt;/section&gt;&lt;section/&gt;&lt;/section&gt;&lt;/section&gt;
&lt;p&gt;深度学习研究人员都愿意编写程序实施想法，而很少愿意手动做误差分析。他们认为这是浪费时间，其实通过误差分析可以权衡具体问题、优先安排项目、指出新的方向，而用在上面的时间可以帮助你节省很多时间和人力。&lt;/p&gt;

&lt;section class=&quot;&quot; data-mpa-template-id=&quot;882500&quot; data-mpa-color=&quot;null&quot; data-mpa-category=&quot;fav&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section https:=&quot;&quot; inline-block=&quot;&quot; auto=&quot;&quot; no-repeat=&quot;&quot; top=&quot;&quot; rgb=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;&gt;&lt;p&gt;&lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;/&gt; &lt;span&gt;3.1&lt;/span&gt;&lt;/p&gt;
&lt;/section&gt;&lt;section https:=&quot;&quot; inline-block=&quot;&quot; left=&quot;&quot; auto=&quot;&quot; no-repeat=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong mpa-from-tpl=&quot;t&quot;&gt;人工分析&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;/section&gt;&lt;/section&gt;&lt;section https:=&quot;&quot; inline-block=&quot;&quot; left=&quot;&quot; auto=&quot;&quot; no-repeat=&quot;&quot; top=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section class=&quot;&quot; data-mpa-template-id=&quot;998729&quot; data-mpa-color=&quot;null&quot; data-mpa-category=&quot;fav&quot; readability=&quot;1.5&quot;&gt;&lt;section readability=&quot;3&quot;&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;要点：人工错误分析能够避免花费大量的时间精力去做一些对提高模型性能收效甚微的工作，而专注解决影响模型正确率的主要问题。&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;/section&gt;&lt;/section&gt;
&lt;p&gt;&lt;span&gt;对于一个猫分类器模型，我们发现该模型会将一些狗的图片错误分类成猫。&lt;/span&gt;&lt;span&gt;在扩大狗的样本之前&lt;/span&gt;&lt;span&gt; (&lt;/span&gt;&lt;span&gt;可能花数月&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;&lt;span&gt;，我们可以手动做一下分析，统计一下全部错误样例里面多少个是狗就可以了。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;

&lt;p&gt;假设猫分类器模型的错误率是 10%，有 100 个误分类数据。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;情况一&lt;/strong&gt;：有 5 个样例是狗，即便它们全部分类正确，错误率也仅仅从 10% 减少到 9.5%，不值得去做。&lt;/p&gt;

&lt;p&gt;&lt;span&gt;    10% - 5/100 = 9.5%&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;情况二&lt;/strong&gt;：有 50 个样例是狗，如果它们全部分类正确，错误率却可以从 10% 减少到 5%，值得去做。&lt;/p&gt;

&lt;p&gt;&lt;span&gt;    10% - 50/100 = 5%&lt;/span&gt;&lt;/p&gt;

&lt;section class=&quot;&quot; data-mpa-template-id=&quot;882500&quot; data-mpa-color=&quot;null&quot; data-mpa-category=&quot;fav&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section https:=&quot;&quot; inline-block=&quot;&quot; auto=&quot;&quot; no-repeat=&quot;&quot; top=&quot;&quot; rgb=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;&gt;&lt;p&gt;&lt;span&gt;3.2&lt;/span&gt;&lt;/p&gt;
&lt;/section&gt;&lt;section https:=&quot;&quot; inline-block=&quot;&quot; left=&quot;&quot; auto=&quot;&quot; no-repeat=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong mpa-from-tpl=&quot;t&quot;&gt;并行分析&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;/section&gt;&lt;/section&gt;&lt;section https:=&quot;&quot; inline-block=&quot;&quot; left=&quot;&quot; auto=&quot;&quot; no-repeat=&quot;&quot; top=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section class=&quot;&quot; data-mpa-template-id=&quot;998729&quot; data-mpa-color=&quot;null&quot; data-mpa-category=&quot;fav&quot; readability=&quot;1&quot;&gt;&lt;section readability=&quot;2&quot;&gt;&lt;p&gt;&lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;/&gt; &lt;span&gt;&lt;strong&gt;&lt;span&gt;要点：并行分析统计误差类别，解决占百分比最大的问题。&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;/section&gt;&lt;/section&gt;
&lt;p&gt;&lt;span&gt;误差分析还同时评估多个影响模型性能的因素，通过各自在错误样本中所占的比例来判断其重要性。例如，猫分类器模型中，可能有以下改进模型的因素：&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;

&lt;ol class=&quot; list-paddingleft-2&quot; readability=&quot;-1&quot;&gt;&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;把狗误以为猫的图片&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;把大型猫科动物 (比如狮子、豹子) 误以为猫的图片&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;模糊的图片&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;span&gt;用表格来并行分析误分类图片，以单个错误分类样本为对象，分析每个样本错误分类的原因。&lt;/span&gt;&lt;/p&gt;


&lt;p&gt;&lt;img class=&quot;&quot; data-backh=&quot;134&quot; data-backw=&quot;558&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.24153846153846154&quot; data-s=&quot;300,640&quot; data-type=&quot;jpeg&quot; data-w=&quot;650&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/e4kxNicDVcCH9EViaib3KEia4h875rFXoJicl2ZcoErVGax4SonJiaBq9COUI3Lia0WgzmkGUfBz3kjZQMViaPZ6hL087Q/640?wx_fmt=jpeg&quot;/&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;注意每张图片需要改进的因素不止一个，比如图片 &lt;/span&gt;&lt;span&gt;3 &lt;/span&gt;&lt;span&gt;是雨天拍的狮子，那么“猫科动物”和“模糊”一栏下都打钩了。因此最后一列的百分比加起来并不等于 &lt;/span&gt;&lt;span&gt;100%&lt;/span&gt;&lt;span&gt;。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;

&lt;p&gt;通常来说，比例越大，影响越大，越应该花费时间和精力着重解决这一问题。这种误差分析让我们改进模型更加有针对性，从而提高效率。从上例来看，把精力放在改进“猫科动物”和“模糊”类图片比放在“狗”类图片，要明智的多。&lt;/p&gt;

&lt;section class=&quot;&quot; data-mpa-template-id=&quot;882500&quot; data-mpa-color=&quot;null&quot; data-mpa-category=&quot;fav&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section https:=&quot;&quot; inline-block=&quot;&quot; auto=&quot;&quot; no-repeat=&quot;&quot; top=&quot;&quot; rgb=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;&gt;&lt;p&gt;&lt;span&gt;3.3&lt;/span&gt;&lt;/p&gt;
&lt;/section&gt;&lt;section https:=&quot;&quot; inline-block=&quot;&quot; left=&quot;&quot; auto=&quot;&quot; no-repeat=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong mpa-from-tpl=&quot;t&quot;&gt;标记修正&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;/section&gt;&lt;/section&gt;&lt;section https:=&quot;&quot; inline-block=&quot;&quot; left=&quot;&quot; auto=&quot;&quot; no-repeat=&quot;&quot; top=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section class=&quot;&quot; data-mpa-template-id=&quot;998729&quot; data-mpa-color=&quot;null&quot; data-mpa-category=&quot;fav&quot; readability=&quot;1.5&quot;&gt;&lt;section readability=&quot;3&quot;&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;要点：在用深度学习时，在训练集上标记如果是随机标错，可忽略，如果是系统标错，要修正。在开发集和测试集上，用并行分析那一套。&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;/section&gt;&lt;/section&gt;
&lt;p&gt;&lt;span&gt;监督式学习中，训练样本有时候会出现输出 y 标记错误的情况。下图红框的可爱的白狗狗被人工错误的标记成了猫。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;

&lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;/&gt; &lt;p&gt;&lt;img class=&quot;&quot; data-backh=&quot;116&quot; data-backw=&quot;558&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.20625&quot; data-s=&quot;300,640&quot; data-type=&quot;jpeg&quot; data-w=&quot;1280&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/e4kxNicDVcCH9EViaib3KEia4h875rFXoJiclUx5pcYtVGFicQglFy4ee9WQdmJ39z19hglEuCKWLZ4l9BF3w76le1oQ/640?wx_fmt=jpeg&quot;/&gt;&lt;/p&gt;

&lt;p&gt;如果这些标记&lt;/p&gt;

&lt;ul class=&quot; list-paddingleft-2&quot; readability=&quot;0&quot;&gt;&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;&lt;span&gt;是随机标错 (比如不小心错误，或按错分类键) 的，那么深度学习算法对这种随机误差的鲁棒性是较强的，一般可以忽略无需修复。&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;&lt;span&gt;是系统标错 (比如认为白色可爱的狗就是猫) 的，那么深度学习算法对这种系统误差的鲁棒性是较差的，需要修正标记。&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在开发集上，用并行分析那一套，将“错误标记”作为一个可以改进误差的因素。如下图：&lt;/p&gt;


&lt;p&gt;&lt;img class=&quot;&quot; data-backh=&quot;160&quot; data-backw=&quot;558&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.2871287128712871&quot; data-s=&quot;300,640&quot; data-type=&quot;jpeg&quot; data-w=&quot;707&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/e4kxNicDVcCH9EViaib3KEia4h875rFXoJiclpuljok07yqTatV9VkSqwOL8jtTp4WWtNBaj4PRliaCib3Td3M65hl3tA/640?wx_fmt=jpeg&quot;/&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;情况一&lt;/strong&gt;&lt;span&gt;：假设开发误差为 10%，即便它们全部分类正确，错误率也仅仅减少&lt;/span&gt;&lt;span&gt;0.6%&lt;/span&gt;&lt;span&gt;，有 94% 的别的误差更需要先解决。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;    6% ×10% = &lt;span&gt;0.6%&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;    (10% - &lt;span&gt;0.6%&lt;/span&gt;) / 10% = 94%&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;情况二&lt;/strong&gt;&lt;span&gt;：假设你不停改进模型，直到开发误差为 2%，那么这个 &lt;span&gt;0.6%&lt;/span&gt; 就占现在总误差的 30%了，值得投入精力来解决。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;    &lt;span&gt;0.6% &lt;/span&gt;/ 2% = 30%&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;在测试集上用上面同样的方法。大神在他的书里提了两条建议：&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;

&lt;ol class=&quot; list-paddingleft-2&quot; readability=&quot;0&quot;&gt;&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;用同样过程对待开发集和测试集，保证它们里的数据在修正后还是来自同一分布&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;注意那种一开始标记错误的，而且也预测错误的数据。因为错错得对，因此也需要检查这类数据&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;section class=&quot;&quot; data-mpa-template-id=&quot;882500&quot; data-mpa-color=&quot;null&quot; data-mpa-category=&quot;fav&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section https:=&quot;&quot; inline-block=&quot;&quot; auto=&quot;&quot; no-repeat=&quot;&quot; top=&quot;&quot; rgb=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;&gt;&lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;/&gt; &lt;p&gt;&lt;span&gt;3.4&lt;/span&gt;&lt;/p&gt;
&lt;/section&gt;&lt;section https:=&quot;&quot; inline-block=&quot;&quot; left=&quot;&quot; auto=&quot;&quot; no-repeat=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong mpa-from-tpl=&quot;t&quot;&gt;大开发集&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;/section&gt;&lt;/section&gt;&lt;section https:=&quot;&quot; inline-block=&quot;&quot; left=&quot;&quot; auto=&quot;&quot; no-repeat=&quot;&quot; top=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section class=&quot;&quot; data-mpa-template-id=&quot;998729&quot; data-mpa-color=&quot;null&quot; data-mpa-category=&quot;fav&quot; readability=&quot;1.5&quot;&gt;&lt;section readability=&quot;3&quot;&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;要点：当开发集大时，分成两个子集，一个用来分析误差，一个用来调参防止过拟合。&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;/section&gt;&lt;/section&gt;
&lt;p&gt;&lt;span&gt;如果开发集很大，在分析误差时，可以将其分成两个子集 &lt;/span&gt;&lt;span&gt;A &lt;/span&gt;&lt;span&gt;和 &lt;/span&gt;&lt;span&gt;B&lt;/span&gt;&lt;span&gt;。只看一个子集 &lt;/span&gt;&lt;span&gt;A&lt;/span&gt;&lt;span&gt;，做误差分析改进错误，因此 &lt;/span&gt;&lt;span&gt;A &lt;/span&gt;&lt;span&gt;会慢慢被过拟合，这时用 &lt;/span&gt;&lt;span&gt;B &lt;/span&gt;&lt;span&gt;来调超参数。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;

&lt;ul class=&quot; list-paddingleft-2&quot; readability=&quot;0&quot;&gt;&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;子集 A 称为鹰眼开发集 (Eyeball dev set)，你只能用眼睛看这部分的数据来分析误差。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;子集 B 称为黑箱开发集 (Blackbox dev set)，你只能用这部分未知的数据来调参数。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;问题一&lt;/strong&gt;&lt;span&gt;：为什么花功夫分鹰眼开发集和黑箱开发集？&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;回答&lt;/strong&gt;：就是怕过拟合整个开发集。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;问题二&lt;/strong&gt;：这两个开发集的数据量应该多少？&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;回答&lt;/strong&gt;：根据主要误差率和错分类个数决定。比如误差率 5%，而通常 50 到 100 个错分类数据可以让你很容易识别主要错误来源 (比如模糊，比如大型猫科动物)，那么需要的鹰眼开发集大概包含 1,000 (50/5%) 到 2,000 (100/5%) 个数据。对于黑箱开发集，1,000 到 10,000 个数据都是合理的。&lt;/p&gt;

&lt;p&gt;大神强调，如果开发集数目不是那么大，鹰眼开发集更重要些，这是不需要黑箱开发集，那么误差分析和调参都在它上面做。&lt;/p&gt;

&lt;section class=&quot;&quot; data-mpa-template-id=&quot;882153&quot; data-mpa-color=&quot;null&quot; data-mpa-category=&quot;fav&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section class=&quot;&quot;&gt;4&lt;/section&gt;&lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;/&gt; &lt;section&gt;偏差方差&lt;/section&gt;&lt;section https:=&quot;&quot; left=&quot;&quot; no-repeat=&quot;&quot; rgb=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;/&gt;&lt;/section&gt;&lt;section/&gt;&lt;/section&gt;&lt;/section&gt;
&lt;p&gt;本章介绍的内容流程如下：&lt;/p&gt;

&lt;ol class=&quot; list-paddingleft-2&quot; readability=&quot;2&quot;&gt;&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;书中 (理论派) 对偏差方差的严谨定义 (实用性弱)&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;大神 (实用派) 对偏差方差的友好定义 (实用性强)&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;理论派和实用派中的最优误差&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;理论派和实用派中的偏差方差权衡，如何减小偏差和方差&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;从误差点 (单个偏差方差) 到误差线 (学习曲线)&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;section class=&quot;&quot; data-mpa-template-id=&quot;882500&quot; data-mpa-color=&quot;null&quot; data-mpa-category=&quot;fav&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section https:=&quot;&quot; inline-block=&quot;&quot; auto=&quot;&quot; no-repeat=&quot;&quot; top=&quot;&quot; rgb=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;&gt;&lt;p&gt;&lt;span&gt;4.1&lt;/span&gt;&lt;/p&gt;
&lt;/section&gt;&lt;section https:=&quot;&quot; inline-block=&quot;&quot; left=&quot;&quot; auto=&quot;&quot; no-repeat=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong mpa-from-tpl=&quot;t&quot;&gt;严谨定义&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;/section&gt;&lt;/section&gt;&lt;section https:=&quot;&quot; inline-block=&quot;&quot; left=&quot;&quot; auto=&quot;&quot; no-repeat=&quot;&quot; top=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section class=&quot;&quot; data-mpa-template-id=&quot;998729&quot; data-mpa-color=&quot;null&quot; data-mpa-category=&quot;fav&quot; readability=&quot;1&quot;&gt;&lt;section readability=&quot;2&quot;&gt;&lt;p&gt;&lt;strong&gt;要点：偏差和方差是误差的两大来源。&lt;/strong&gt;&lt;/p&gt;
&lt;/section&gt;&lt;/section&gt;
&lt;p&gt;从字面上来讲&lt;br/&gt;&lt;/p&gt;


&lt;p&gt;不明白偏差？想想“认知偏差”的定义，是人们常因自身或情境的原因使得知觉结果出现失真的现象，关键词是&lt;strong&gt;失真&lt;/strong&gt;，也就是人们预测与真实的差距。&lt;/p&gt;

&lt;p&gt;不明白方差？想想“统计方差”的定义，是各个数据与其算术平均数的离差平方和的平均数，关键词是&lt;strong&gt;离差&lt;/strong&gt;，也就是预测值的离散程度。&lt;/p&gt;

&lt;p&gt;套用上面定义，用一个真实例子(用面积来预测房价的线性回归模型) 来介绍偏差方差，我们需要以下类比：&lt;/p&gt;


&lt;p&gt;要讨论该模型的误差和方差，就要弄清该模型的&lt;strong&gt;真实误差&lt;/strong&gt;，而真实误差是测量模型在&lt;strong&gt;所有&lt;/strong&gt;数据上(训练用的，没见过的)。真实误差是不可能精确计算出的，因为里面涉及到没见过的数据，但是我们可以在不同的数据集上做线性回归得到不同的模型，如下图所示：&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;&quot; data-backh=&quot;224&quot; data-backw=&quot;558&quot; data-before-oversubscription-url=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/e4kxNicDVcCEFMSK7RFWcm9Exlfawn7iaZtHtweDfzrgicqSdPPmuwKjUbMTjGiaKB7IAPGEog8O6LDjESWxRMBc4w/0?wx_fmt=jpeg&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.4015625&quot; data-s=&quot;300,640&quot; data-type=&quot;jpeg&quot; data-w=&quot;1280&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/e4kxNicDVcCEFMSK7RFWcm9Exlfawn7iaZtHtweDfzrgicqSdPPmuwKjUbMTjGiaKB7IAPGEog8O6LDjESWxRMBc4w/640?&quot;/&gt;&lt;/p&gt;

&lt;p&gt;继续类比得到&lt;/p&gt;

&lt;ul class=&quot; list-paddingleft-2&quot; readability=&quot;4.5&quot;&gt;&lt;li readability=&quot;7&quot;&gt;
&lt;p&gt;预测值的期望：多套数据集 D&lt;span&gt;&lt;sub&gt;&lt;span&gt;1&lt;/span&gt;&lt;/sub&gt;&lt;/span&gt;, D&lt;span&gt;&lt;sub&gt;&lt;span&gt;2&lt;/span&gt;&lt;/sub&gt;&lt;/span&gt;,…, D&lt;span&gt;&lt;sub&gt;&lt;span&gt;m&lt;/span&gt;&lt;/sub&gt;&lt;/span&gt;上训练出来的模型 h&lt;span&gt;&lt;sup&gt;&lt;span&gt;(D1)&lt;/span&gt;&lt;/sup&gt;&lt;/span&gt;, h&lt;span&gt;&lt;sup&gt;&lt;span&gt;(D2) &lt;/span&gt;&lt;/sup&gt;&lt;/span&gt;,…, h&lt;span&gt;&lt;sup&gt;&lt;span&gt;(Dm)&lt;/span&gt;&lt;/sup&gt;&lt;/span&gt;, 再求其平均得到模型 f = E&lt;span&gt;&lt;sub&gt;&lt;span&gt;D&lt;/span&gt;&lt;/sub&gt;&lt;/span&gt;[h&lt;span&gt;&lt;sup&gt;&lt;span&gt;(D)&lt;/span&gt;&lt;/sup&gt;&lt;/span&gt;]&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;2&quot;&gt;
&lt;p&gt;预测值的离差：每个模型和平均模型的差距 h&lt;span&gt;&lt;sup&gt;&lt;span&gt;(D1)&lt;/span&gt;&lt;/sup&gt;&lt;/span&gt; - f, h&lt;span&gt;&lt;sup&gt;&lt;span&gt;(D2)&lt;/span&gt;&lt;/sup&gt;&lt;/span&gt; - f, …, h&lt;span&gt;&lt;sup&gt;&lt;span&gt;(Dm)&lt;/span&gt;&lt;/sup&gt;&lt;/span&gt; - f&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;再看偏差 (用平方差距表示) 和方差的数学定义就简单多了&lt;/p&gt;

&lt;p&gt;    偏差 = (&lt;span&gt;f&lt;/span&gt; - &lt;span&gt;g&lt;/span&gt;)&lt;span&gt;&lt;sup&gt;&lt;span&gt;2&lt;/span&gt;&lt;/sup&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;    方差 = E&lt;span&gt;&lt;sub&gt;&lt;span&gt;D&lt;/span&gt;&lt;/sub&gt;&lt;/span&gt;[(h&lt;span&gt;&lt;sup&gt;&lt;span&gt;(D)&lt;/span&gt;&lt;/sup&gt;&lt;/span&gt; &lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;/&gt;   - &lt;span&gt;f&lt;/span&gt;)&lt;span&gt;&lt;sup&gt;&lt;span&gt;2&lt;/span&gt;&lt;/sup&gt;&lt;/span&gt;]&lt;/p&gt;

&lt;p&gt;模型误差可分解成偏差和方差(为了简化问题，不考虑数据的噪声)，如下图所示：&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;&quot; data-backh=&quot;316&quot; data-backw=&quot;558&quot; data-before-oversubscription-url=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/e4kxNicDVcCEFMSK7RFWcm9Exlfawn7iaZoQSFnoNr2zuTSGF9QPe31AFL71E89jrbTrXj1vwwKum9AyM9ZQQsYw/0?wx_fmt=jpeg&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.5656660412757973&quot; data-s=&quot;300,640&quot; data-type=&quot;jpeg&quot; data-w=&quot;1066&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/e4kxNicDVcCEFMSK7RFWcm9Exlfawn7iaZoQSFnoNr2zuTSGF9QPe31AFL71E89jrbTrXj1vwwKum9AyM9ZQQsYw/640?&quot;/&gt;&lt;/p&gt;

&lt;p&gt;对着偏差方差的定义，上面的图不能再清楚。更多关于偏差方差的详情可参考&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzIzMjY0MjE1MA==&amp;amp;mid=2247483767&amp;amp;idx=1&amp;amp;sn=991489d0546b99a4b54e77652f91ad9e&amp;amp;chksm=e890827edfe70b6846503857ac79dafff23038b18a7b7fec6846828c92878d9cddd6765a99f5&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-linktype=&quot;2&quot;&gt;&lt;strong&gt;模型的评估和选择&lt;/strong&gt;&lt;/a&gt;一贴的 3.9 小节。&lt;/p&gt;

&lt;p&gt;现在问题是偏差和方差都不能精确的计算，因为目标函数 g 和数据分布 P(D) 都是未知的，“&lt;strong&gt;误差 = 偏差 + 方差&lt;/strong&gt;” 只是一个美丽的等式，而下节大神会给出能计算的偏差和方差的定义。尽管不能计算，上面等式也不是一无所用，至少在降低模型误差时我们有两个目标：&lt;/p&gt;

&lt;ol class=&quot; list-paddingleft-2&quot; readability=&quot;-1&quot;&gt;&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;在降低偏差时不要显著增加方差&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;在降低方差时不要显著增加偏差&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;听起来像废话，做起来不容易。&lt;/p&gt;

&lt;section class=&quot;&quot; data-mpa-template-id=&quot;882500&quot; data-mpa-color=&quot;null&quot; data-mpa-category=&quot;fav&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section https:=&quot;&quot; inline-block=&quot;&quot; auto=&quot;&quot; no-repeat=&quot;&quot; top=&quot;&quot; rgb=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;&gt;&lt;p&gt;&lt;span&gt;4.2&lt;/span&gt;&lt;/p&gt;
&lt;/section&gt;&lt;section https:=&quot;&quot; inline-block=&quot;&quot; left=&quot;&quot; auto=&quot;&quot; no-repeat=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong mpa-from-tpl=&quot;t&quot;&gt;大神定义&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;/section&gt;&lt;/section&gt;&lt;section https:=&quot;&quot; inline-block=&quot;&quot; left=&quot;&quot; auto=&quot;&quot; no-repeat=&quot;&quot; top=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section class=&quot;&quot; data-mpa-template-id=&quot;998729&quot; data-mpa-color=&quot;null&quot; data-mpa-category=&quot;fav&quot; readability=&quot;1.5&quot;&gt;&lt;section readability=&quot;3&quot;&gt;&lt;p&gt;&lt;strong&gt;要点：偏差是模型在训练集上的误差，方差是模型在开发集和训练集上的误差的差异。&lt;/strong&gt;&lt;/p&gt;
&lt;/section&gt;&lt;/section&gt;
&lt;p&gt;大神对偏差方差的定义为：&lt;/p&gt;


&lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;/&gt; &lt;p&gt;咋一看，这是什么定义？所以说我们脑洞不够大，比不了大神。从严谨定义开始&lt;/p&gt;

&lt;p&gt;    偏差 = (&lt;span&gt;平均模型&lt;/span&gt;误差 – &lt;span&gt;目标模型&lt;/span&gt;误差)&lt;span&gt;&lt;sup&gt;&lt;span&gt;2&lt;/span&gt;&lt;/sup&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;    方差 = E[(&lt;span&gt;某个模型&lt;/span&gt;误差 – &lt;span&gt;平均模型&lt;/span&gt;误差)&lt;span&gt;&lt;sup&gt;&lt;span&gt;2&lt;/span&gt;&lt;/sup&gt;&lt;/span&gt;]&lt;/p&gt;

&lt;p&gt;和大神定义靠拢需要以下不是很严谨的观点或假设：&lt;/p&gt;

&lt;ul class=&quot; list-paddingleft-2&quot; readability=&quot;1&quot;&gt;&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;&lt;span&gt;平均模型&lt;/span&gt;是在不同数据集上做平均，现在只有一个训练集 D&lt;span&gt;&lt;sub&gt;&lt;span&gt;train&lt;/span&gt;&lt;/sub&gt;&lt;/span&gt;，因此平均模型就是 f = h&lt;span&gt;&lt;sup&gt;&lt;span&gt;(train)&lt;/span&gt;&lt;/sup&gt;&lt;/span&gt;，平均模型误差 = 训练误差&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;&lt;span&gt;目标模型&lt;/span&gt;就是我们千方百计想要找的模型，找到的话目标模型误差 = 0&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;定义&lt;span&gt;某个模型&lt;/span&gt;误差是 f 在开发集 D&lt;span&gt;&lt;sub&gt;&lt;span&gt;dev &lt;/span&gt;&lt;/sub&gt;&lt;/span&gt;上的误差，假设方差就是在该 D&lt;span&gt;&lt;sub&gt;&lt;span&gt;dev&lt;/span&gt;&lt;/sub&gt;&lt;/span&gt; 划分时计算出来的&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;综上&lt;/p&gt;

&lt;p&gt;    偏差 = (训练误差 – 0)&lt;span&gt;&lt;sup&gt;&lt;span&gt;2&lt;/span&gt;&lt;/sup&gt;&lt;/span&gt; = 训练误差&lt;span&gt;&lt;sup&gt;&lt;span&gt;2&lt;/span&gt;&lt;/sup&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;    方差 = (开发误差 – 训练误差)&lt;span&gt;&lt;sup&gt;&lt;span&gt;2&lt;/span&gt;&lt;/sup&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;将上面方程右边再开方而定义为偏差和方差&lt;/p&gt;

&lt;p&gt;    偏差 = 训练误差&lt;/p&gt;
&lt;p&gt;    方差 = 开发误差 – 训练误差           &lt;/p&gt;

&lt;p&gt;方差开方之后会有正负号，但是开发误差一般都比训练误差&lt;strong&gt;大&lt;/strong&gt;，因为模型是从训练上得出来的，没可能在开发集的表现更好。&lt;/p&gt;

&lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;/&gt; &lt;p&gt;废了这么大的劲儿将偏差方差的“严谨定义”和“大神定义”联系起来，为了什么？就为了偏差和方差现在可以用训练误差和开发误差来&lt;strong&gt;量化&lt;/strong&gt;！看下面 4 个情景。&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;&quot; data-backh=&quot;152&quot; data-backw=&quot;558&quot; data-before-oversubscription-url=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/e4kxNicDVcCEFMSK7RFWcm9Exlfawn7iaZMUxg9BZuQMzh3MBqLkQlI8ibMicZuHP13yUgPmTqltffbdj2BQZo8b4A/0?wx_fmt=png&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.2738301559792028&quot; data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-w=&quot;577&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/e4kxNicDVcCEFMSK7RFWcm9Exlfawn7iaZMUxg9BZuQMzh3MBqLkQlI8ibMicZuHP13yUgPmTqltffbdj2BQZo8b4A/640?&quot;/&gt;&lt;/p&gt;

&lt;p&gt;如果你的模型达到情景 4 的表现，那么恭喜你成功了，其他情景的话还需要继续该模型，怎么改进就要看到底是偏差问题还是方差问题？怎么判断就要借助训练误差和开发误差。现在知道大神定义的偏差方差有用了吧。&lt;/p&gt;

&lt;section class=&quot;&quot; data-mpa-template-id=&quot;882500&quot; data-mpa-color=&quot;null&quot; data-mpa-category=&quot;fav&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section https:=&quot;&quot; inline-block=&quot;&quot; auto=&quot;&quot; no-repeat=&quot;&quot; top=&quot;&quot; rgb=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;&gt;&lt;p&gt;&lt;span&gt;4.3&lt;/span&gt;&lt;/p&gt;
&lt;/section&gt;&lt;section https:=&quot;&quot; inline-block=&quot;&quot; left=&quot;&quot; auto=&quot;&quot; no-repeat=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong mpa-from-tpl=&quot;t&quot;&gt;最优误差&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;/section&gt;&lt;/section&gt;&lt;section https:=&quot;&quot; inline-block=&quot;&quot; left=&quot;&quot; auto=&quot;&quot; no-repeat=&quot;&quot; top=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section class=&quot;&quot; data-mpa-template-id=&quot;998729&quot; data-mpa-color=&quot;null&quot; data-mpa-category=&quot;fav&quot; readability=&quot;1.5&quot;&gt;&lt;section readability=&quot;3&quot;&gt;&lt;p&gt;&lt;strong&gt;要点：偏差可分成“不可避免偏差”和“可避免偏差”，前者是客观存在而不可能减小的，努力减小的是后者。&lt;/strong&gt;&lt;/p&gt;
&lt;/section&gt;&lt;/section&gt;
&lt;p&gt;上节说如果找到一个模型就是目标模型的话，那么目标模型误差 = 0，这时&lt;br/&gt;&lt;/p&gt;

&lt;p&gt;    偏差 = 训练误差&lt;/p&gt;

&lt;p&gt;但是这种情况是理想化的，我们几乎不可能找到一个误差率为零的模型，换句话说最优误差接近于零但不等于零 (有些模型最优误差还可能很大，比如一个在很嘈杂背景下的一个语音识别器的最优误差高达 14%)。&lt;/p&gt;

&lt;p&gt;这个最优误差也是不可避免偏差 (unavoidable bias)，顾名思义就是误差无法减小的部分，那么可避免偏差 (avoid bias) 就是误差可以减小的部分。因此偏差又可以继续分解成&lt;/p&gt;

&lt;p&gt;    偏差 = 不可避免偏差 + 可避免偏差&lt;/p&gt;

&lt;p&gt;重新回顾上节情景 3，假设不可避免偏差有以下两种情况：&lt;/p&gt;


&lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;/&gt; &lt;p&gt;&lt;img class=&quot;&quot; data-backh=&quot;87&quot; data-backw=&quot;558&quot; data-before-oversubscription-url=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/e4kxNicDVcCEFMSK7RFWcm9Exlfawn7iaZR3IrV4WQoTKaCZHtW3cb6z5NcwgLfogdNOznLia3YonmA1sJPYzJKIA/0?wx_fmt=png&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.15460526315789475&quot; data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-w=&quot;608&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/e4kxNicDVcCEFMSK7RFWcm9Exlfawn7iaZR3IrV4WQoTKaCZHtW3cb6z5NcwgLfogdNOznLia3YonmA1sJPYzJKIA/640?&quot;/&gt;&lt;/p&gt;

&lt;p&gt;这样看，情况 A 还是高偏差高偏差，但情况 B 却是低偏差高偏差。确定最优误差的好处是让我们只关注可避免偏差，而之后需要减小的也是可避免偏差。&lt;br/&gt;&lt;/p&gt;

&lt;section class=&quot;&quot; data-mpa-template-id=&quot;882500&quot; data-mpa-color=&quot;null&quot; data-mpa-category=&quot;fav&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section https:=&quot;&quot; inline-block=&quot;&quot; auto=&quot;&quot; no-repeat=&quot;&quot; top=&quot;&quot; rgb=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;&gt;&lt;p&gt;&lt;span&gt;4.4&lt;/span&gt;&lt;/p&gt;
&lt;/section&gt;&lt;section https:=&quot;&quot; inline-block=&quot;&quot; left=&quot;&quot; auto=&quot;&quot; no-repeat=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong mpa-from-tpl=&quot;t&quot;&gt;两者权衡&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;/section&gt;&lt;/section&gt;&lt;section https:=&quot;&quot; inline-block=&quot;&quot; left=&quot;&quot; auto=&quot;&quot; no-repeat=&quot;&quot; top=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section class=&quot;&quot; data-mpa-template-id=&quot;998729&quot; data-mpa-color=&quot;null&quot; data-mpa-category=&quot;fav&quot; readability=&quot;1.5&quot;&gt;&lt;section readability=&quot;3&quot;&gt;&lt;p&gt;&lt;strong&gt;要点：在传统机器学习时代，减小偏差会增大方差，反之亦然。在深度学习时代，在减小可避免偏差时尽量不要显著增大方差，反之亦然。&lt;/strong&gt;&lt;/p&gt;
&lt;/section&gt;&lt;/section&gt;
&lt;p&gt;在传统机器学习时代，偏差和方差是有冲突的，称为偏差方差权衡。如下图：&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;&quot; data-backh=&quot;387&quot; data-backw=&quot;558&quot; data-before-oversubscription-url=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/e4kxNicDVcCEFMSK7RFWcm9Exlfawn7iaZmOIY5CkGatwMwLaRI6ic9j7VIbicxSDdbyhTJJLeJWI4icMpnAialVB3oQ/0?wx_fmt=jpeg&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.693723849372385&quot; data-s=&quot;300,640&quot; data-type=&quot;jpeg&quot; data-w=&quot;1195&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/e4kxNicDVcCEFMSK7RFWcm9Exlfawn7iaZmOIY5CkGatwMwLaRI6ic9j7VIbicxSDdbyhTJJLeJWI4icMpnAialVB3oQ/640?&quot;/&gt;&lt;/p&gt;



&lt;p&gt;减少偏差的方法 (提高模型复杂度) 包括：&lt;/p&gt;

&lt;ul class=&quot; list-paddingleft-2&quot;&gt;&lt;li&gt;
&lt;p&gt;增多特征&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;减少正则化&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;减少方差的方法 (降低模型复杂度或者增加数据) 包括：&lt;/p&gt;

&lt;ul class=&quot; list-paddingleft-2&quot;&gt;&lt;li&gt;
&lt;p&gt;收集更多数据&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;减少特征&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;增加正则化&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在深度学习时代，我们有大量的数据和更深的神经网络，很多时候我们减小偏差或方差是不会对另一方产生过多不良影响。我们的目标是&lt;/p&gt;

&lt;ol class=&quot; list-paddingleft-2&quot; readability=&quot;-1&quot;&gt;&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;&lt;strong&gt;减小可避免偏差时不要显著增加方差&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;&lt;strong&gt;减小方差时不要显著增加可避免偏差&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;减少偏差的方法包括：&lt;/p&gt;

&lt;ol class=&quot; list-paddingleft-2&quot; readability=&quot;2.140522875817&quot;&gt;&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;用更深的模型 (增加层数) 或更大的模型 (增加每层的神经元)&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;减少正则化作用 (L2, L1 和 dropout)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;训练更长时间&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;训练更好的优化算法 (Adam)&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-0.53684210526316&quot;&gt;
&lt;p&gt;通过在训练集上做误差分析 (见&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzIzMjY0MjE1MA==&amp;amp;mid=2247485767&amp;amp;idx=1&amp;amp;sn=423ea8fa376edcc0b82eceb62012f218&amp;amp;chksm=e8908a4edfe70358b1b8f71b1e8462167278c9352d2bcd3d8758fb7e4c6282fa8bf6c5f96125&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-linktype=&quot;2&quot;&gt;&lt;strong&gt;解读吴恩达新书的全球第一帖(上)&lt;/strong&gt;&lt;/a&gt;第 3 节)&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;寻找更好的神经网络架构&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;小结一下：&lt;/p&gt;

&lt;ul class=&quot; list-paddingleft-2&quot; readability=&quot;2&quot;&gt;&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;方法 1 在减小偏差时很容易增加方差，一般一旦发现方差变大就增加正则化来降低方差。&lt;br/&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;方法 2 在减小偏差时会增大方差，正则化一般不会单独使用。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;方法 3-6 都是直接减小训练误差，因而会同时减少偏差和方差。注意的是方法 6 更好的神经网络架构通常很难找到。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;&lt;strong&gt;最有效的是方法 1：用更深更大的模型配着正则化。&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;减少方差的方法包括：&lt;/p&gt;

&lt;ol class=&quot; list-paddingleft-2&quot; readability=&quot;1.5&quot;&gt;&lt;li&gt;
&lt;p&gt;收集更多的数据&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;增加正则化作用 (L2, L1 和 dropout)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;加入提前停止&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;减少特征数量&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;用更浅的模型 (减少层数) 或更小的模型 (减少每层的神经元)&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;通过在训练集上做误差分析&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;寻找更好的神经网络架构&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;小结一下：&lt;/p&gt;

&lt;ul class=&quot; list-paddingleft-2&quot; readability=&quot;3.5&quot;&gt;&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;方法 1 是最直接的，只要有足够处理大量数据的算力。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;方法 2 和 3 在减小方差时会增大偏差，一般不会单独使用。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;方法 4 在减小方差时会增大偏差，在数据很多时并不是很有效。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;方法 5 大神不推荐，除非算力是最值得顾虑的因素。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;方法 6 和 7 都是直接减小训练误差，因而会同时减少偏差和方差。注意的是方法 7 更好的神经网络架构通常很难找到。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;&lt;strong&gt;最有效的是方法 1：收集更多数据，唯一需要考虑的因素是算力。&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;section class=&quot;&quot; data-mpa-template-id=&quot;882500&quot; data-mpa-color=&quot;null&quot; data-mpa-category=&quot;fav&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;/&gt; &lt;section https:=&quot;&quot; inline-block=&quot;&quot; auto=&quot;&quot; no-repeat=&quot;&quot; top=&quot;&quot; rgb=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;&gt;&lt;p&gt;&lt;span&gt;4.5&lt;/span&gt;&lt;/p&gt;
&lt;/section&gt;&lt;section https:=&quot;&quot; inline-block=&quot;&quot; left=&quot;&quot; auto=&quot;&quot; no-repeat=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong mpa-from-tpl=&quot;t&quot;&gt;学习曲线&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;/section&gt;&lt;/section&gt;&lt;section https:=&quot;&quot; inline-block=&quot;&quot; left=&quot;&quot; auto=&quot;&quot; no-repeat=&quot;&quot; top=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section class=&quot;&quot; data-mpa-template-id=&quot;998729&quot; data-mpa-color=&quot;null&quot; data-mpa-category=&quot;fav&quot; readability=&quot;1&quot;&gt;&lt;section readability=&quot;2&quot;&gt;&lt;p&gt;&lt;strong&gt;要点：线永远比点表达的信息更多。&lt;/strong&gt;&lt;/p&gt;
&lt;/section&gt;&lt;/section&gt;
&lt;p&gt;在上一节，我们只在一个点 (固定数目的训练数据) 上比较训练误差和开发误差，进而推断到底该减小偏差或方差。诚然该方法是有效，但是能看出训练误差和开发误差随着训练数据数目的变化趋势不是更好么？如下图所示：&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;&quot; data-backh=&quot;223&quot; data-backw=&quot;558&quot; data-before-oversubscription-url=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/e4kxNicDVcCGshicI4aDsYYDUdv62Wlib5VcVibJAewvBpEstU1dnvia5ZuRjwJdGAXW6Fjiboibje4G5azJsibTNBqhGQ/0?wx_fmt=jpeg&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.4&quot; data-s=&quot;300,640&quot; data-type=&quot;jpeg&quot; data-w=&quot;1280&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/e4kxNicDVcCGshicI4aDsYYDUdv62Wlib5VcVibJAewvBpEstU1dnvia5ZuRjwJdGAXW6Fjiboibje4G5azJsibTNBqhGQ/640?&quot;/&gt;&lt;/p&gt;

&lt;p&gt;上右图就是学习曲线，它是将训练误差和开放误差作为训练数据数量的函数绘制的图表。直观来讲，随着训练集大小增加&lt;/p&gt;

&lt;ul class=&quot; list-paddingleft-2&quot; readability=&quot;0&quot;&gt;&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;&lt;span&gt;开发误差&lt;/span&gt;会越来越&lt;strong&gt;小&lt;/strong&gt;，数据越多模型泛化能力越强，因此在开发集表现会越好。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;&lt;span&gt;训练误差&lt;/span&gt;会越来越&lt;strong&gt;大&lt;/strong&gt;，数据少时模型可以记住达到零误差，数据多时喂不进模型了，因为模型复杂度有限因此误差增大。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;给定固定的训练集大小，&lt;span&gt;开发误差&lt;/span&gt;会比&lt;span&gt;训练误差&lt;/span&gt;大，因此&lt;span&gt;蓝线&lt;/span&gt;在&lt;span&gt;红线&lt;/span&gt;下面。&lt;/p&gt;

&lt;p&gt;接下来看看三幅图：&lt;/p&gt;

&lt;ul class=&quot; list-paddingleft-2&quot;&gt;&lt;li&gt;
&lt;p&gt;高偏差低方差&lt;br/&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;高方差低偏差&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;高偏差高方差&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr/&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-backh=&quot;343&quot; data-backw=&quot;558&quot; data-before-oversubscription-url=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/e4kxNicDVcCGshicI4aDsYYDUdv62Wlib5VDCLGCblgWSd1ocPD0L5VAhGMKXs2OuvhyEIyLFag6y8E2nGrSygnaw/0?wx_fmt=jpeg&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.6162162162162163&quot; data-s=&quot;300,640&quot; data-type=&quot;jpeg&quot; data-w=&quot;1110&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/e4kxNicDVcCGshicI4aDsYYDUdv62Wlib5VDCLGCblgWSd1ocPD0L5VAhGMKXs2OuvhyEIyLFag6y8E2nGrSygnaw/640?&quot;/&gt;&lt;/p&gt;

&lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;/&gt; &lt;p&gt;在&lt;strong&gt;高偏差低方差&lt;/strong&gt;情况下，增加训练数据只会&lt;br/&gt;&lt;/p&gt;


&lt;p&gt;这时候用更复杂的神经网络才是王道，增加训练数据只会浪费功夫。&lt;/p&gt;

&lt;hr/&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-backh=&quot;342&quot; data-backw=&quot;558&quot; data-before-oversubscription-url=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/e4kxNicDVcCGshicI4aDsYYDUdv62Wlib5VJrYaRKn7XuUia56lXC3HcvQnFgMBCLUaSZh6BicQcdibgTc7Mhtj4MNug/0?wx_fmt=jpeg&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.6140035906642729&quot; data-s=&quot;300,640&quot; data-type=&quot;jpeg&quot; data-w=&quot;1114&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/e4kxNicDVcCGshicI4aDsYYDUdv62Wlib5VJrYaRKn7XuUia56lXC3HcvQnFgMBCLUaSZh6BicQcdibgTc7Mhtj4MNug/640?&quot;/&gt;&lt;/p&gt;
&lt;p&gt;在&lt;strong&gt;高方差低偏差&lt;/strong&gt;情况下，增加训练数据&lt;br/&gt;&lt;/p&gt;


&lt;p&gt;这时候用更复杂的神经网络没用，因为偏差已经很小，模型不用继续复杂化。&lt;/p&gt;

&lt;hr/&gt;&lt;p&gt;&lt;img class=&quot;&quot; data-backh=&quot;361&quot; data-backw=&quot;558&quot; data-before-oversubscription-url=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/e4kxNicDVcCGshicI4aDsYYDUdv62Wlib5VHFYibBN1a287LD2KlDHIJAxdqYUib8xsIoyU7qK17n5QFsXdEtFrfSHw/0?wx_fmt=jpeg&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.6483412322274882&quot; data-s=&quot;300,640&quot; data-type=&quot;jpeg&quot; data-w=&quot;1055&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/e4kxNicDVcCGshicI4aDsYYDUdv62Wlib5VHFYibBN1a287LD2KlDHIJAxdqYUib8xsIoyU7qK17n5QFsXdEtFrfSHw/640?&quot;/&gt;&lt;/p&gt;
&lt;p&gt;在&lt;strong&gt;高偏差高方差&lt;/strong&gt;情况下，能做的事就多了，比如&lt;br/&gt;&lt;/p&gt;

&lt;ul class=&quot; list-paddingleft-2&quot; readability=&quot;1&quot;&gt;&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;用更复杂的神经网络，减小偏差&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;增加训练数据，减小方差&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;人工分析误差，减小两者&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;换更好的网络架构，减小两者&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;学习曲线可以帮助我们快速诊断出问题在哪，再对症下药。深度学习本来就是一半科学一半艺术，通过不断“炼丹”，最终目标就是下图，&lt;strong&gt;低偏差低方差&lt;/strong&gt;。&lt;br/&gt;&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;&quot; data-backh=&quot;384&quot; data-backw=&quot;558&quot; data-before-oversubscription-url=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/e4kxNicDVcCGshicI4aDsYYDUdv62Wlib5VJKzJ7VuJl6ibz3kWGAMVhJRLGdFw4ibx00a7zhpOhOYwU7Comx9hPmDQ/0?wx_fmt=jpeg&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.6884576098059244&quot; data-s=&quot;300,640&quot; data-type=&quot;jpeg&quot; data-w=&quot;979&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/e4kxNicDVcCGshicI4aDsYYDUdv62Wlib5VJKzJ7VuJl6ibz3kWGAMVhJRLGdFw4ibx00a7zhpOhOYwU7Comx9hPmDQ/640?&quot;/&gt;&lt;/p&gt;

&lt;hr/&gt;&lt;p&gt;在两种情况下绘制学习曲线会遇到问题。假设全集有 100 个数据，选取 10 个子集，分别包含 10, 20, 30 到 100 个数据点，在每个子集上训练模型，计算训练误差并画图。&lt;br/&gt;&lt;/p&gt;



&lt;p&gt;对这两个问题，大神也给了解决方案 (都是在取样上做文章)。&lt;/p&gt;



&lt;p&gt;当数据很多时而且类别比较平衡时，可以忽略上述两个问题。&lt;/p&gt;

&lt;p&gt;最后当数据很多时，绘制学习曲线会很耗时，因为会选取不同子集来训练模型。大神给的建议是不用等分数据来划分子集，比如有 10K 个数据，划分 2 比划分 1 好，而且也能清晰的看出趋势。&lt;/p&gt;

&lt;p&gt;    划分 1：1K, 2K, 3K, …, 10K&lt;/p&gt;
&lt;p&gt;    划分 2：1K, 2K, 4K, 6K, 10K&lt;/p&gt;


&lt;section class=&quot;&quot; data-mpa-template-id=&quot;882154&quot; data-mpa-color=&quot;null&quot; data-mpa-category=&quot;fav&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section class=&quot;&quot;&gt;5&lt;/section&gt;&lt;section&gt;性能对比&lt;/section&gt;&lt;section https:=&quot;&quot; left=&quot;&quot; no-repeat=&quot;&quot; rgb=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;/&gt;&lt;/section&gt;&lt;section/&gt;&lt;/section&gt;&lt;/section&gt;
&lt;p&gt;上章最后一节主要讲如何根据学习曲线来减小偏差或方差最终取得低偏差低方差 (低误差)，本章来分析如果误差低到逼近人类水平甚至超过人类水平会发生什么。&lt;/p&gt;

&lt;section class=&quot;&quot; data-mpa-template-id=&quot;882500&quot; data-mpa-color=&quot;null&quot; data-mpa-category=&quot;fav&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section https:=&quot;&quot; inline-block=&quot;&quot; auto=&quot;&quot; no-repeat=&quot;&quot; top=&quot;&quot; rgb=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;&gt;&lt;p&gt;&lt;span&gt;5.1&lt;/span&gt;&lt;/p&gt;
&lt;/section&gt;&lt;section https:=&quot;&quot; inline-block=&quot;&quot; left=&quot;&quot; auto=&quot;&quot; no-repeat=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong mpa-from-tpl=&quot;t&quot;&gt;人类表现&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;/section&gt;&lt;/section&gt;&lt;section https:=&quot;&quot; inline-block=&quot;&quot; left=&quot;&quot; auto=&quot;&quot; no-repeat=&quot;&quot; top=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section class=&quot;&quot; data-mpa-template-id=&quot;998729&quot; data-mpa-color=&quot;null&quot; data-mpa-category=&quot;fav&quot; readability=&quot;1&quot;&gt;&lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;/&gt; &lt;section readability=&quot;2&quot;&gt;&lt;p&gt;&lt;strong&gt;要点：对于人类擅长的任务，可用人类误差近似不可避免偏差。&lt;/strong&gt;&lt;/p&gt;
&lt;/section&gt;&lt;/section&gt;
&lt;p&gt;人们经常比较机器学习系统表现和人类表现，通常趋势如下图：&lt;br/&gt;&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;&quot; data-backh=&quot;381&quot; data-backw=&quot;558&quot; data-before-oversubscription-url=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/e4kxNicDVcCEFMSK7RFWcm9Exlfawn7iaZict2Wh7sxYgNmu74H7IzuMUXSE5OSkico5MsBpJNefI5ysKXXSVN6PTQ/0?wx_fmt=jpeg&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.6824324324324325&quot; data-s=&quot;300,640&quot; data-type=&quot;jpeg&quot; data-w=&quot;888&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/e4kxNicDVcCEFMSK7RFWcm9Exlfawn7iaZict2Wh7sxYgNmu74H7IzuMUXSE5OSkico5MsBpJNefI5ysKXXSVN6PTQ/640?&quot;/&gt;&lt;/p&gt;

&lt;p&gt;从上图可看出三点：&lt;/p&gt;

&lt;ol class=&quot; list-paddingleft-2&quot; readability=&quot;0&quot;&gt;&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;开始当模型没有人类水平好时，往人类水平进展的速度是很快的。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;一旦模型过了人类水平，其精度提升变得很慢了。原因有二：&lt;/p&gt;
&lt;ol class=&quot; list-paddingleft-2&quot; readability=&quot;-2&quot;&gt;&lt;li&gt;
&lt;p&gt;数据是人类标记的&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;错误分析是人类做的&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;最后我们都希望模型能达到理论上最佳水平，但就是无法超越。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;第 3 点里的理论上限就是 1 减去贝叶斯最优错误率 (Bayes optimal error rate)，姑且定义为贝叶斯水平吧。而贝叶斯最优错误率就是 1.3 小节提到的最优误差 (不可避免偏差），因此&lt;/p&gt;

&lt;p&gt;    贝叶斯水平 = 1 - 不可避免偏差&lt;/p&gt;

&lt;p&gt;人类擅长很多任务，比如图像识别和语音识别这类处理自然数据的任务，人类水平和贝叶斯水平相差不远，通常用人类水平来近似成贝叶斯水平，那么我们有&lt;/p&gt;

&lt;p&gt;    人类水平 ≈&lt;span&gt; &lt;/span&gt;贝叶斯水平&lt;/p&gt;
&lt;p&gt;    人类误差 ≈ 不可避免偏差&lt;/p&gt;

&lt;p&gt;假设下面两种分类情况，人类误差分别是 1% 和 7.5%，模型的训练误差是 8%，开发误差是 10%。&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;&quot; data-backh=&quot;87&quot; data-backw=&quot;558&quot; data-before-oversubscription-url=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/e4kxNicDVcCEFMSK7RFWcm9Exlfawn7iaZl4ickf0BRgWrp4kEibLRqUvXDsibybfj16H4ibWOtzm2vywbWm7xibYHF4w/0?wx_fmt=png&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.1551155115511551&quot; data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-w=&quot;606&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/e4kxNicDVcCEFMSK7RFWcm9Exlfawn7iaZl4ickf0BRgWrp4kEibLRqUvXDsibybfj16H4ibWOtzm2vywbWm7xibYHF4w/640?&quot;/&gt;&lt;/p&gt;

&lt;p&gt;很明显：&lt;/p&gt;

&lt;ul class=&quot; list-paddingleft-2&quot; readability=&quot;-0.5&quot;&gt;&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;情况 A：可避免偏差 7% &amp;gt; 方差 2%，偏差问题比较严重，应该使用更深的神经网络&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;情况 B：可避免偏差 0.5% &amp;lt; 方差 2%，方差问题比较严重，应该获取更多数据&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;接下来我们来研究如何定义人类误差，既不可避免偏差。如医学图像分类问题上，假设有下面几种分类的水平：&lt;/p&gt;


&lt;p&gt;问题：人类误差到底是 0.5%, 0.7%, 1% 还是 3%？&lt;/p&gt;
&lt;p&gt;答案：看机器学习系统表现而定，见下面三种情况。&lt;/p&gt;

&lt;p&gt;&lt;span&gt;情况 1：训练误差 5%，开发误差 6%，方差为 6% - 5% = 1%&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;&quot; data-backh=&quot;142&quot; data-backw=&quot;558&quot; data-before-oversubscription-url=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/e4kxNicDVcCEFMSK7RFWcm9Exlfawn7iaZX6qlKOWF6vV6of9J7ibnqJve28NVQa8oos4G7j0Obslpo0tooXznRdQ/0?wx_fmt=png&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.2539936102236422&quot; data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-w=&quot;626&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/e4kxNicDVcCEFMSK7RFWcm9Exlfawn7iaZX6qlKOWF6vV6of9J7ibnqJve28NVQa8oos4G7j0Obslpo0tooXznRdQ/640?&quot;/&gt;&lt;/p&gt;

&lt;p&gt;不管选哪个作为人类误差，所有结论都是偏差严重，专注于减小偏差。&lt;/p&gt;

&lt;p&gt;&lt;span&gt;情况 2：训练误差 1%，开发误差 5%，方差为 5% - 1% = 4%&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;&quot; data-backh=&quot;139&quot; data-backw=&quot;558&quot; data-before-oversubscription-url=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/e4kxNicDVcCEFMSK7RFWcm9Exlfawn7iaZgJ4CWSX0KBfYg6sQsX3hhF0yf6Vb8ndmNGt8hG0NMSNNYcHZrLhbog/0?wx_fmt=png&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.2496&quot; data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-w=&quot;625&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/e4kxNicDVcCEFMSK7RFWcm9Exlfawn7iaZgJ4CWSX0KBfYg6sQsX3hhF0yf6Vb8ndmNGt8hG0NMSNNYcHZrLhbog/640?&quot;/&gt;&lt;/p&gt;

&lt;p&gt;当训练误差到 1%这么小了，再选普通人 3% 作为人类误差已经无意义了。只有选等于或小于 1% 作为人类误差才能继续改进模型，比如选后三个 1%, 0.7% 和0.5%，得到结论都是方差严重，专注于减小方差。&lt;/p&gt;

&lt;p&gt;&lt;span&gt;情况 3：训练误差 0.7%，开发误差 0.8%，方差为 0.8% - 0.7% = 0.1%&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;&quot; data-backh=&quot;143&quot; data-backw=&quot;558&quot; data-before-oversubscription-url=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/e4kxNicDVcCEFMSK7RFWcm9Exlfawn7iaZcaGyic9Ig6BWg3psw1rVoJ7uY3KR53cPhPq31ImgTAX6NdjqofpMdvg/0?wx_fmt=png&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.256&quot; data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-w=&quot;625&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/e4kxNicDVcCEFMSK7RFWcm9Exlfawn7iaZcaGyic9Ig6BWg3psw1rVoJ7uY3KR53cPhPq31ImgTAX6NdjqofpMdvg/640?&quot;/&gt;&lt;/p&gt;

&lt;p&gt;当训练误差到 0.7% 时，选 0.7% 或 0.5% 作为人类误差可以得到相反的结论，到底是要减小偏差还是减小方差？模型表现越好时也越难继续优化，因为这时候人类误差是比较模糊难以准确定义的。&lt;/p&gt;

&lt;p&gt;这样看来，如果模型超过人类时，继续优化会更加困难！&lt;/p&gt;

&lt;section class=&quot;&quot; data-mpa-template-id=&quot;882500&quot; data-mpa-color=&quot;null&quot; data-mpa-category=&quot;fav&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section https:=&quot;&quot; inline-block=&quot;&quot; auto=&quot;&quot; no-repeat=&quot;&quot; top=&quot;&quot; rgb=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;&gt;&lt;p&gt;&lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;/&gt; &lt;span&gt;5.2&lt;/span&gt;&lt;/p&gt;
&lt;/section&gt;&lt;section https:=&quot;&quot; inline-block=&quot;&quot; left=&quot;&quot; auto=&quot;&quot; no-repeat=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong mpa-from-tpl=&quot;t&quot;&gt;超人表现&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;/section&gt;&lt;/section&gt;&lt;section https:=&quot;&quot; inline-block=&quot;&quot; left=&quot;&quot; auto=&quot;&quot; no-repeat=&quot;&quot; top=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section class=&quot;&quot; data-mpa-template-id=&quot;998729&quot; data-mpa-color=&quot;null&quot; data-mpa-category=&quot;fav&quot; readability=&quot;1.5&quot;&gt;&lt;section readability=&quot;3&quot;&gt;&lt;p&gt;&lt;strong&gt;要点：当机器学习系统表现超过人类表现，贝叶斯误差就很难估计，再从减少偏差或方差方面提升系统性能就很困难。&lt;/strong&gt;&lt;/p&gt;
&lt;/section&gt;&lt;/section&gt;
&lt;p&gt;对于自然感知类问题，机器学习的表现不及人类。但是在很多其它方面，机器学习模型的表现已经超过人类了，包括：&lt;strong&gt;产品推荐&lt;/strong&gt;，&lt;strong&gt;物流预测&lt;/strong&gt;和&lt;strong&gt;贷款审批&lt;/strong&gt;等。注意这些任务的数据都是结构化 (structured) 数据 (两维数据，每一行是一个示范，每一列是一个特征)，而不像感知类问题的非结构化 (unstructured) 数据 (一张图片，一段语音等)。&lt;/p&gt;

&lt;p&gt;当今，机器在处理结构化数据的表现远远超过了人类表现，此外，机器在某些语音识别和图像识别的任务中也超过了人类，因此想继续提升会非常困难。这也很正常，想想博尔特百米用时从 9.7 秒提升到 9.6 秒远比从 10.1 秒提升到 10 秒困难。&lt;/p&gt;

&lt;section class=&quot;&quot; data-mpa-template-id=&quot;882157&quot; data-mpa-color=&quot;null&quot; data-mpa-category=&quot;fav&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section class=&quot;&quot;&gt;6&lt;/section&gt;&lt;section&gt;总结&lt;/section&gt;&lt;section https:=&quot;&quot; left=&quot;&quot; no-repeat=&quot;&quot; rgb=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;/&gt;&lt;/section&gt;&lt;section/&gt;&lt;/section&gt;&lt;/section&gt;
&lt;p&gt;回答本帖要解决的问题：&lt;/p&gt;

&lt;hr/&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;问：用完机器学习后效果不好怎么办？&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;答：用正交策略模型在训练集、开发集、测试集和真实环境上的表现，对症下药。&lt;/p&gt;

&lt;hr/&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;问：在项目之前如何设定有效的目标？&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;答：&lt;/p&gt;
&lt;ol class=&quot; list-paddingleft-2&quot; readability=&quot;1.5&quot;&gt;&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;数据多时按 98/1/1 来划分训练集、开发集和测试集；&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;快速制定开发集和测试集，保证它们同分布&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;选择单值评估指标 (用函数综合或满意和优化指标)&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;发现以上开发集、测试集和评估指标和项目期望的方向不一致时，赶快换它们&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;hr/&gt;&lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;/&gt; &lt;p&gt;&lt;span&gt;&lt;strong&gt;问：如何有效的进行误差分析？&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;答:&lt;/p&gt;
&lt;ol class=&quot; list-paddingleft-2&quot; readability=&quot;0&quot;&gt;&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;手动分析误差，并行找出可改进它的原因，根据其占比分配精力去做&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;根据错误标记的特性，或者占比，来决定修正或忽略&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;对大开发集，将其分成两个子集，一个用来误差分析，一个用来调参&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;&lt;hr/&gt;
&lt;p&gt;最重要的是在做项目时记住下图：&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;&quot; data-backh=&quot;340&quot; data-backw=&quot;450&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.7555555555555555&quot; data-s=&quot;300,640&quot; data-type=&quot;jpeg&quot; data-w=&quot;450&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/e4kxNicDVcCH9EViaib3KEia4h875rFXoJiclwq7pXPPOt46k49HIyB7ur0mlXaEeylYsQoSaamm7UHgbsPfTEWMTAQ/640?wx_fmt=jpeg&quot;/&gt;&lt;/p&gt;

&lt;section class=&quot;&quot; data-mpa-template-id=&quot;882157&quot; data-mpa-color=&quot;null&quot; data-mpa-category=&quot;fav&quot; readability=&quot;6.1540785498489&quot;&gt;&lt;section readability=&quot;12.308157099698&quot;&gt;&lt;p&gt;明晰大神提出的几个定义：&lt;/p&gt;

&lt;ul class=&quot; list-paddingleft-2&quot; readability=&quot;0&quot;&gt;&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;不可避免偏差 ≈ 人类误差&lt;br/&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;可避免偏差 = 训练误差 - 不可避免偏差&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;方差 = 开发误差 - 训练误差&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;用学习曲线来判断误差主要来源是偏差还是方差&lt;/p&gt;

&lt;ul class=&quot; list-paddingleft-2&quot; readability=&quot;0&quot;&gt;&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;如果是偏差问题，可以用更大更深神经网络加正则化&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;如果是方差问题，可以增加训练数据&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;如果是两者，可以试着所有方法，能找到更好的网络架构最好&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;终极目标是让机器学习系统表现逼近人类表现并超越人类，但是进展越来越慢 (分析误差效率越来越低)，原因有三：&lt;/p&gt;

&lt;ol class=&quot; list-paddingleft-2&quot; readability=&quot;0.5&quot;&gt;&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;数据要靠人类标记的&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;错误分析是用人类的见解&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;贝叶斯误差定义越来越模糊，因此发现误差来源属于偏差或者方差这件事越来越困难&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;本文经授权转自微信公众号 王的机器，俩篇合为一篇发出，感谢作者的授权。&lt;/p&gt;

&lt;p&gt;更多阅读&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651383879&amp;amp;idx=1&amp;amp;sn=be6682d117cebc143f439796a11bbe4b&amp;amp;chksm=84f3c606b3844f10217b6886660d1f5ca18ed626f20c0cb0547f6714a6f5fd22493189737797&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-linktype=&quot;2&quot;&gt;机器学习是怎么巧妙揭开大脑工作原理的&lt;/a&gt;&lt;br/&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651383835&amp;amp;idx=1&amp;amp;sn=c937dbe49d0f6320fed53d727bf63071&amp;amp;chksm=84f3c65ab3844f4cbcc834b0d881069254a193a0f3799282f583c256920bb3582c173b29d863&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-linktype=&quot;2&quot;&gt;机器学习高维数据分析中那些一定可以避开的坑！&lt;/a&gt;&lt;br/&gt;&lt;/p&gt;
&lt;/section&gt;&lt;/section&gt;</description>
<pubDate>Tue, 08 Jan 2019 13:29:07 +0000</pubDate>
<dc:language>zh-CN</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.jintiankansha.me/t/bOuNks81mo</dc:identifier>
</item>
<item>
<title>[原创]正确阅读科学文献的九条建议</title>
<link>http://www.jintiankansha.me/t/DLeKi8Ev0E</link>
<guid isPermaLink="true" >http://www.jintiankansha.me/t/DLeKi8Ev0E</guid>
<description>&lt;p&gt;&lt;span data-offset-key=&quot;77jo8-0-0&quot;&gt;对于正在读博的博士， 还是刚刚进入科研圈的青椒，什么是最重要的问题呢？  如果你的答案是如何写论文， 说明你还没有入道， 事实上， 在能够正确写论文之前，正确读文献更加重要。 所谓熟读唐诗三百首， 不会吟诗也会吟， 这一点上说 ，读论文是写论文的基础。而又经常被忽略。 最近看到plos上一篇非常好的教人如何读论文的文章， 特此给大家分享。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;d2k02-0-0&quot;&gt;我们正在经历一个论文爆炸的时代， 面对这个信息过载的危机， 最好的应对方法是养成正确的阅读习惯：&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;span data-offset-key=&quot;b647f-0-0&quot;&gt;1，  正确阅读， 要做到每日一读。&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;span data-offset-key=&quot;9tq7t-0-0&quot;&gt;一旦意识到阅读文献对研究者的必要性， 你会懂得除非你的阅读成为一种日常习惯， 否则你的知识一定会很快过时， 根本无法和先锋研究者进行对话。 有的人有记录癖好， 把没读过的文章累计成一打， 这样的做法让你觉得暗自很爽但不过是一种幻影。 你要真正去读， 而且不能等到写文章时候再读 ， 而是日常阅读。 最好的办法是每天都设定一个固定的时间段来读， 即使是坐地铁这样的碎片化时间也很好！ 关键是， 要把它仪式化!&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;span data-offset-key=&quot;3846f-0-0&quot;&gt;2，  在你的研究生涯早期， 透彻了解你所有要了解的背景。&lt;/span&gt;&lt;/strong&gt; &lt;span data-offset-key=&quot;3846f-0-0&quot;&gt; &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span data-offset-key=&quot;dbsad-0-0&quot;&gt;不要以自己太忙没有时间为理由， 想象一下越是到了人生的后期， 工作， 家庭， 多少事物会让你无法阅读， 所以 ，在你的研究早期， 透彻的了解整个领域是核心重要的， 你后面更难抽出这个时间。  这些知识将如同你的知识地图， 为你后面更精细的课题研究引入航道。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;span data-offset-key=&quot;9ejch-0-0&quot;&gt;3， 不要忘记阅读领域经典论文&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;span data-offset-key=&quot;7gcs3-0-0&quot;&gt;如果你要达到前沿，最好的方法不是直接去看前沿， 而是从你的课题的诞生一刻开始追溯它的发展。 你必须找到那颗一点点达到领域前沿的知识树， 把每个核心概念串起来， 这个串联的过程， 就是把核心知识点通过一篇篇关键论文链接的过程。  有了这些关键论文组成的知识树， 你不再会重新造轮子， 或提出别人已经想过而没有显著意义的学术课题了。 &lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;span data-offset-key=&quot;cla5r-0-0&quot;&gt;4， 不要忽略学科发展史里的信息&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;span data-offset-key=&quot;1u07b-0-0&quot;&gt;如果你已经开始构建这颗知识树， 那么请你重视这些知识发展和形成的历史， 它经历过哪些戏剧性时刻？ 哪些概念的内涵和外延发生了变化？ 为什么出现了这些转变？ 这个变化的背景是什么？ 经过这些思考， 你会对你的整个学科有新的理解，注意这些论文背后的人， 以及它们之间的关系。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;span data-offset-key=&quot;5q7k4-0-0&quot;&gt;5， 不要思维狭隘，只关注本领域的知识&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;span data-offset-key=&quot;d659d-0-0&quot;&gt;有趣的知识点， 概念， 方法事实上很多来自其它学科的启迪。 虽然你不能成为达芬奇那样的全才 ，但是在“专”和“精”之间达到平衡， 却还是可以做到的。  一个窍门是寻找那些提供综述类文章的期刊，订阅它们，习惯性的阅读，这些综述性文章是高效的拓宽视野的好方法。  另外你还可以通过社交网络增加这类了解。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;span data-offset-key=&quot;4p3r3-0-0&quot;&gt;6， 制定一个最核心的阅读期刊列表&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;span data-offset-key=&quot;5fb5d-0-0&quot;&gt;关注核心期刊， 如果你关注的核心期刊少于20个， 说明你可能缺失一些关键信息。 在定位这些期刊的时候，你既要关心它们的影响因子，也要考虑那些影响因子较小但是内容非常新锐的期刊。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;span data-offset-key=&quot;1oasd-0-0&quot;&gt;7， 不要忘记教科书&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;span data-offset-key=&quot;ahadn-0-0&quot;&gt;经典教科书的信噪比永远高于论文，所以， 阅读教科书是高效的。一些最新的教科书可能在谷歌学术上找到。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;span data-offset-key=&quot;8ed1g-0-0&quot;&gt;8， 合理使用工作， 文献管理器来追踪管理你的文献阅读&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;span data-offset-key=&quot;863ap-0-0&quot;&gt;合理使用工具会事半功倍，但不要依赖工具， 认为把文章放入工具就够了。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;span data-offset-key=&quot;br3op-0-0&quot;&gt;9， 主动建立知识索引或综述&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;span data-offset-key=&quot;b6v4o-0-0&quot;&gt;好记性不如烂笔头， 把核心信息记下来， 自己给自己写综述！&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;延申阅读：&lt;/strong&gt; &lt;span&gt;How to keep up with the scientific literature  - science  这是一篇science上关于如何阅读文献的资料， 里面有很多知名科学家有意思的观点,  基本思想和此处是类似的。一个特别值得注意的点在于， 它特点提到了跟踪一些大牛的twitter。目前在深度学习这样的领域， 确实不少大牛直接在twitter上发布自己的新作， 甚至进行学术讨论。 另外文中指出很多年轻研究者的缺陷正是在于在研究初期下载几篇项目有关的文献，后面就基本放弃阅读了，这是一个经常陷入的陷阱， 需要警觉。 &lt;/span&gt;&lt;/p&gt;


&lt;p&gt;&lt;span data-offset-key=&quot;b6v4o-0-0&quot;&gt;常用的工具介绍： &lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;span data-offset-key=&quot;b6v4o-0-0&quot;&gt;1，  google scholar：&lt;/span&gt;&lt;/strong&gt;&lt;span data-offset-key=&quot;b6v4o-0-0&quot;&gt;  你的搜索装置也是你最好的文献管理器， 如何订阅喜欢的主题， 进行文献归档整理， 你可以搜索网上资料一大把。 学会利用索引按图索隐的把自己领域一网打尽。 &lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;span data-offset-key=&quot;b6v4o-0-0&quot;&gt;2，  Zoreto：&lt;/span&gt;&lt;/strong&gt; &lt;span data-offset-key=&quot;b6v4o-0-0&quot;&gt;极为方便灵活的免费工具。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;span data-offset-key=&quot;b6v4o-0-0&quot;&gt;3，  paper：&lt;/span&gt;&lt;/strong&gt; &lt;span data-offset-key=&quot;b6v4o-0-0&quot;&gt;mac用户可以用paper， 管理十分方便简洁。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;span data-offset-key=&quot;b6v4o-0-0&quot;&gt;4，  Mendeley&lt;/span&gt;&lt;/strong&gt;&lt;span data-offset-key=&quot;b6v4o-0-0&quot;&gt;： 可以将文献归档打标签搜索 。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;96l0u-0-0&quot;&gt;编后记：&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;6fndk-0-0&quot;&gt;巡洋舰希望在新的一年带领大家阅读人工智能， 复杂系统， 和神经科学的一些经典论文。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;6fndk-0-0&quot;&gt;参考文章源地址：&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1006467&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;2 How to keep up with the scientific literature&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;https://www.sciencemag.org/careers/2016/11/how-keep-scientific-literature&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;巡洋舰相关文章： &lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;6fndk-0-0&quot;&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=400566313&amp;amp;idx=1&amp;amp;sn=a6486939518fa90af2ab116c13142bec&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-linktype=&quot;2&quot;&gt;如何挑导师&lt;/a&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=402751373&amp;amp;idx=1&amp;amp;sn=66e33d02d7b034fbcdac43f078750b29&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-linktype=&quot;2&quot;&gt;科学的教你写论文&lt;/a&gt;&lt;br/&gt;&lt;/p&gt;





</description>
<pubDate>Mon, 07 Jan 2019 23:16:04 +0000</pubDate>
<dc:language>zh-CN</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.jintiankansha.me/t/DLeKi8Ev0E</dc:identifier>
</item>
</channel>
</rss>