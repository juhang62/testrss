<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="css/feed.xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/" xmlns:og="http://ogp.me/ns#">
<channel>
<atom:link rel="self" href="http://192.168.1.4/fivefilters/makefulltextfeed.php?url=feed43.com%2Fchaoscruiser-jtks.xml&amp;max=5&amp;links=preserve&amp;exc=1" />
<atom:link rel="alternate" title="Source URL" href="http://feed43.com/chaoscruiser-jtks.xml" />
<atom:link rel="related" title="Subscribe to feed" href="http://www.subtome.com/#/subscribe?feeds=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed43.com%252Fchaoscruiser-jtks.xml%26max%3D5%26links%3Dpreserve%26exc%3D1&amp;back=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed43.com%252Fchaoscruiser-jtks.xml%26max%3D5%26links%3Dpreserve%26exc%3D1" />
<title>混沌巡洋舰</title>
<link>http://www.jintiankansha.me/column/ultiWL8Axg</link>
<description>混沌巡洋舰 - 今天看啥</description>
<ttl>360</ttl>
<item>
<title>模拟人类大脑 ：人工智能的救赎之路 ？</title>
<link>http://www.jintiankansha.me/t/LwMQM6PYck</link>
<guid isPermaLink="true" >http://www.jintiankansha.me/t/LwMQM6PYck</guid>
<description>&lt;p&gt;&lt;span data-offset-key=&quot;7sdel-0-0&quot;&gt;这两年， 频频有专家警示深度学习即将进入寒冬。 而同时， 一个名叫“类脑智能”的词汇火起来， 这个概念说的是一种比目前深度学习更加接近人脑的智能。 这背后的故事是， 深度学习的大佬，目前已经注意到深度学习的原创性进展面临瓶颈，甚至呼吁全部重来。为了拯救这种趋势， 模拟人脑再次成为一种希望。 然而这一思路是否经得住深度推敲?  我本人做过多年计算神经科学和AI ， 做一个抛砖引玉的小结。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;7sdel-0-0&quot;&gt;&lt;img data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz/dcEP2tDMibcfyNibceeGvVKo0qCGicGJ9lQ9J5zzOIxmTUAE4OYfwx25QZ2J2KLUic1lWYkMwelC8Ld30RF0FsibAPQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; class=&quot;&quot; data-ratio=&quot;0.1671875&quot; data-w=&quot;640&quot; /&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;av90m-0-0&quot;&gt;AI发展的危机&lt;/span&gt;人工智能， 目前多被理解成一个领域领应用的工程学科，从自动安防系统到无人驾驶是它的疆土，而模式识别和计算机专家， 是这片陆地的原住民。 目前的人工智能事实上以工程思维为主， 从当下人工智能的主流深度学习来看， 打开任何一篇论文， 映入眼帘的是几个知名数据集的性能比较，无论是视觉分类的ImageNet，Pascal Vol， 还是强化学习的Atari game。各种各样的bench mark和曲线， 让我们感觉像是一个CPU或者数码相机的导购指南。   &lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;422j3-0-0&quot;&gt;那么， 是否这些在这些流行数据库跑分最高的“智能工具&quot;就更智能？ 这可能取决于对”智能“ 本身的定义。  如果你问一个认知专家“智能”是不是ImageNet的错误率， 那么他一定会觉得相当好笑。 一个人可能在识别图片的时候由于各种劳累和马虎， 在这个数据集的错误率高于机器。但是只要你去和它谈任何一个图片它所理解的东西， 比如一个苹果， 你都会震惊于其信息之丰富， 不仅包含了真实苹果的各种感官， 还包含了关于苹果的各种文学影视， 从夏娃的苹果， 到白雪公主的苹果。 &lt;strong&gt;应该说， 人类理解的苹果更加接近概念网络里的一个节点，和整个世界的所有其它概念相关联， 而非机器学习分类器眼里的n个互相分离的“高斯分布”。&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;1.2921875&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcePZySeD5xPZfjjWazKSPDh20hLgHcyEoib49ibJgElNU7u5P3FONvupkasJaZ4wGb1IklIsggAVvlA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;640&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;dmh2-0-0&quot;&gt;如果我们认为， ”智能“ 是解决某一类复杂问题的能力，是否我们就可以完全不care上述那种”理解“呢 ？&lt;/span&gt; &lt;span data-offset-key=&quot;dmh2-0-1&quot;&gt;这样的智能工具， 顶多是一些感官的外延， 而”感官“ 是否可以解决复杂问题呢？&lt;/span&gt; &lt;span data-offset-key=&quot;dmh2-0-2&quot;&gt;一个能够准确的识别1000种苹果的机器， 未必能有效的利用这样的信息去思考如何把它在圣诞节分作为礼品分发给公司的员工， 或者取悦你的女友。没有”理解“ 的智能， 将很快到达解决问题复杂度的上限。 缺少真正的理解， 甚至连做感官有时也会捉襟见肘， 你在图像里加入各种噪声， 会明显的干扰分类的准确性， 这点在人类里并不存在。比如下图的小狗和曲奇， 你可以分出来，AI很难。 &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.4375&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcdDoicV8Epgicfoh4Exr1IKsyibIzCic4k4QPnV11XG8t7H37pxibJK3KzWWayCbpXny7J1Qia5k0H5secg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;800&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;span data-offset-key=&quot;7iokk-0-0&quot;&gt;”语言“ 在人类的智能里享有独一无二的特殊性，而刚刚的”理解“问题， 背后的本质是目前深度学习对语言的捉襟见肘。  虽然我们可以用强大的LSTM生成诗歌(下图)， 再配上注意力机制和外显记忆与人类对话， 也不代表它能理解人类的这个语言系统。 目前机器对自然语言处理的能力远不及视觉（当下的图卷积网络或可以这个领域做出贡献）。&lt;/span&gt;&lt;br /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;Image FocusPlugin--unfocused Image--isBlock&quot; data-ratio=&quot;0.5277777777777778&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcfcibblDq1JfWD2ElpcKZN1xbAlDYb8GiaoeibGsNUJo93SQhBwjlDNcyzMLyl3MPJllFdZo2jNYhPmw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;720&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.3502906976744186&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcdDoicV8Epgicfoh4Exr1IKsyqljMrfZjdPk0TQX7MfxUKCqF0hZ0ForTA2R2iaRudsUnGZP9YwxvFicw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;2064&quot; /&gt;&lt;/p&gt;
&lt;p&gt;LSTM加上注意力机制，可以生成极为复杂的宋词， 却不真正理解人类的语言&lt;/p&gt;
&lt;p&gt;Chinese Song Iambics generation with neural attention-based model (Qinxi Wang 2016)&lt;/p&gt;
&lt;p&gt;&lt;span&gt;Zhang,&lt;/span&gt; &lt;span&gt;Xingxing&lt;/span&gt;&lt;span&gt;, and&lt;/span&gt; &lt;span&gt;Mirella&lt;/span&gt;&lt;span&gt;Lapata&lt;/span&gt;&lt;span&gt;. &quot;Chinese poetry generationwith recurrent neural networks.&quot; &lt;/span&gt;&lt;span&gt;Proceedings of the 2014 Conferenceon Empirical Methods in Natural Language Processing (EMNLP)&lt;/span&gt;&lt;span&gt;. 2014.&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;5fbqt-0-0&quot;&gt;更加糟糕的还有强化学习， 深度强化学习已经战胜了最强大的人类棋手。 但是强化学习却远非一种可靠的实用方法。 这里面最难的在于目前的强化学习还做不到可扩展， 也就是从一个游戏的问题扩展到真实的问题时候会十分糟糕。 一个已经学的很好的强化学习网络，可以在自己已经学到的领域所向披靡， 然而在游戏里稍微增加一点变化， 神经网络就不知所措。 我们可以想象成这是泛化能力的严重缺失， 在真实世界里，这恰恰一击致命。  &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;Image FocusPlugin--unfocused Image--isBlock&quot; data-ratio=&quot;0.3819444444444444&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcfcibblDq1JfWD2ElpcKZN1xMWfRsAe0fBGJrwOWXRRwnlY1ObT57PdQJwiaVBRiaficeHsdCz1EpMySA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;720&quot; /&gt;&lt;/p&gt;

&lt;p&gt;游戏里的王者不代表真实世界能用&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;4j1d4-0-0&quot;&gt;事实上在很长时间里，人工智能的过分依赖工科思维恰恰给它的危机埋下了伏笔，在人工数据上破记录， 并不代表我们就会在刚说的“理解”上做进步。 这更像是两个不同的进化方向。 其实， 关于智能的更深刻的理解， 早就是认知科学家，心理学家和神经科学家的核心任务。 如果我们需要让人工智能进步， 向他们取经就看起来很合理。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;4j1d4-0-0&quot;&gt;&lt;img data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz/dcEP2tDMibcfyNibceeGvVKo0qCGicGJ9lQ9J5zzOIxmTUAE4OYfwx25QZ2J2KLUic1lWYkMwelC8Ld30RF0FsibAPQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; class=&quot;&quot; data-ratio=&quot;0.1671875&quot; data-w=&quot;640&quot; /&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;7qifh-0-0&quot;&gt;脑科学与人工智能合作与分离的历史&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;da66p-0-0&quot;&gt;虽然看起来模拟生物大脑是达到更高层次人工智能的必由之路，但是从当下的人工智能学者的角度，这远非显然。 这里的渊源来自人工智能的早期发展史，应该说深度学习来自于对脑科学的直接取经， 然而它的壮大却是由于对这条道路的背离。 我们可以把这个历史概括为两次合作一次分离。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;a7vps-0-0&quot;&gt;第一次合作：&lt;/span&gt; &lt;span data-offset-key=&quot;a7vps-0-1&quot;&gt;深度学习的前身-感知机。模拟人类大脑的人工智能流派又称为连接主义，最早的连接主义尝试就是模拟大脑的单个神经元。 Warren McCulloch 和 WalterPitts在1943 提出而来神经元的模型， 这个模型类似于某种二极管或逻辑门电路。&lt;/span&gt;事实上， 人们很快发现感知机的学习有巨大的局限性，Minksky等一批AI早期大师发现感知机无法执行“抑或”这个非常基本的逻辑运算，从而让人们彻底放弃了用它得到人类智能的希望。  对感知机的失望导致连接主义机器学习的研究陷入低谷达15年， 直到一股新的力量的注入。&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;7l7o-0-0&quot;&gt;第二次合作：&lt;/span&gt; &lt;span data-offset-key=&quot;7l7o-0-1&quot;&gt; 这次风波， 来自一群好奇心极强的物理学家，在20世纪80年代，hopefiled提出了它的 Hopefield 网络模型，这个模型受到了物理里的Ising模型和自旋玻璃模型的启发， Hopefield发现，自旋玻璃和神经网络具有极大的相似性。每个神经元可以看作一个个微小的磁极， 它可以一种极为简单的方法影响周围的神经元，一个是兴奋（使得其他神经元和自己状态相同）， 一个是抑制（相反）。 如果我们用这个模型来表示神经网络， 那么我们会立刻得到一个心理学特有的现象： 关联记忆。 比如说你看到你奶奶的照片， 立刻想到是奶奶，再联想到和奶奶有关的很多事。 这里的观点是， 某种神经信息（比如奶奶）对应神经元的集体发放状态（好比操场上正步走的士兵）， 当奶奶的照片被输入进去， 它会召唤这个神经元的集体状态， 然后你就想到了奶奶。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;3sjvt-0-0&quot;&gt;由于这个模型可以模拟心理学的现象， 人们开始重新对模拟人脑的人工智能报以希望。 人们从不同领域开始涌入这个研究。 在这批人里，发生了一个有趣的分化。 有的人沿着这个路数去研究真实大脑是怎么思考的， 有的人则想直接用这个模型制造机器大脑，&lt;/span&gt; &lt;span data-offset-key=&quot;3sjvt-0-1&quot;&gt;前者派生出了计算神经科学， 后者则导致了联结主义机器学习的复兴，&lt;/span&gt; &lt;span data-offset-key=&quot;3sjvt-0-2&quot;&gt;你可以理解为前者对猫感兴趣，后者只对机器猫感兴趣，虽然两者都在那里写模型。 CNN和RNN分别在80年中后期被发现， 应该说， CNN的结构是直接借鉴了Husel和Wiesel 发现的视觉皮层处理信息的原理， 而RNN则是刚刚说到的Hopefield 网络的一个直接进化。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;&gt;&lt;/ins&gt; &lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.6521739130434783&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcfcibblDq1JfWD2ElpcKZN1xLhU8icbxc6bCFdW6L3UXFQVgribyp7FE6bS66MFy9GcfM7FOLwVFuI4w/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1242&quot; /&gt;&lt;/p&gt;
&lt;p&gt;一批人用模型研究真实大脑， 另一批研究机器大脑&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;d7fkb-0-0&quot;&gt;AI与脑科学的分离：&lt;/span&gt; &lt;span data-offset-key=&quot;d7fkb-0-1&quot;&gt;90年代后人工智能的主流是以支持向量机为代表的统计机器学习， 而非神经网络。 在漫长的联结主义低谷期， Hinton坚信神经网络既然作为生物智能的载体， 它一定会称为人工智能的救星， 在它的努力下， Hopefield网络很快演化称为新的更强大的模型玻尔兹曼机， 玻尔兹曼机演化为受限玻尔兹曼机， 自编码器， 堆叠自编码器，这已经很接近当下的深度网络。 而深度卷积网络CNN则连续打破视觉处理任务的记录，宣布深度学习时代开始。  &lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;8na4n-0-0&quot;&gt;然而， 如果你认为这一股AI兴起的风波的原因是我们对大脑的借鉴， 则一定会被机器学习专家diss，恰恰相反，这波深度学习的崛起来自于深度学习专家对脑科学的背离。  &lt;/span&gt;CNN虽然直接模拟了大脑视皮层结构的模拟， 利用了层级编码， 局部网络连接， 池化这样和生物直接相关的原理。但是， 网络的训练方法，却来自一种完全非生物的方法。  由于信息存储在无数神经元构成的网络连接里， 如何让它学进去， 也是最难的问题。很久以前，人们使用的学习方法是Hebian learning 的生物学习方法， 这种方法实用起来极为困难。 Hinton等人放弃这条道路而使用没有生物支撑但更加高效的反向传播算法， 使得最终训练成功。 从此数据犹如一颗颗子弹打造出神经网络的雏形 ，虽然每次只改一点点， 最终当数据的量特别巨大， 却发生一场质变。    &lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;bpke-0-0&quot;&gt;CNN能够在2012 年而不是2011或者2010年开始爆发是因为那一年人们提出了Alexnet。  而Alexnet比起之前的Lenet一个关键性的微小调整在于使用Relu，所谓线性整流单元替换了之前的Sigmoid作为激活函数。Simoid 函数才是更加具有生物基础的学习函数， 然而能够抛弃模拟大脑的想法使用Relu， 使得整个网络的信息流通通畅了很多。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;Image FocusPlugin--unfocused Image--isBlock&quot; data-ratio=&quot;0.5875&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcfcibblDq1JfWD2ElpcKZN1xkVSbabRGrVrBOcg5gvbbTtlbU8PzxMicTTicrr0WyohthGPdz8qDRKHg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;720&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;span data-offset-key=&quot;f8fr0-0-0&quot;&gt;深度学习另一条主线， 沿着让机器听懂人类的语言， 一种叫LSTM的神经网络， 模拟了人类最奇妙的记忆能力， 并却开始处理和自然语言有关的任务， LSTM框架的提出依然是没有遵循大脑的结构，而是直接在网络里引入类似逻辑门的结构控制信息。  &lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;d0b6l-0-0&quot;&gt;由此我们看到， &lt;strong&gt;神经网络虽然在诞生之初多次吸收了生物学的原理本质， 而其最终的成功却在于它大胆的脱离生物细节， 使用更加讲究效率的数理工科思维&lt;/strong&gt;。 生物的细节千千万， 有一些是进化的副产品， 或者由于生物经常挨饿做出的妥协， 却远非智能的必须， 因此对它们的抛弃极大的解放了人工智能的发展。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span data-offset-key=&quot;d0b6l-0-0&quot;&gt;&lt;br /&gt;&lt;img data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz/dcEP2tDMibcfyNibceeGvVKo0qCGicGJ9lQ9J5zzOIxmTUAE4OYfwx25QZ2J2KLUic1lWYkMwelC8Ld30RF0FsibAPQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; class=&quot;&quot; data-ratio=&quot;0.1671875&quot; data-w=&quot;640&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span data-offset-key=&quot;324r-0-0&quot;&gt;脑科学究竟能否开启深度学习时代的下个阶段  &lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;1b0ts-0-0&quot;&gt;那么生物神经网络究竟可不可以启发人工智能呢？&lt;/span&gt; &lt;span data-offset-key=&quot;1b0ts-0-1&quot;&gt;刚刚的分析我们看到生物的细节并不一定对人工智能有帮助， 而生物大脑计算的根本原理却始终在推动深度学习 。&lt;/span&gt; &lt;span data-offset-key=&quot;1b0ts-0-2&quot;&gt;正如CNN的发展直接使用了层级编码的原理， 然后根据自己计算的需求重新设定了细节， 无论如何变化， 生物视觉处理和CNN背后的数学核心却始终保持一致。  &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span data-offset-key=&quot;1b0ts-0-2&quot;&gt;  &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span data-offset-key=&quot;cipoj-0-0&quot;&gt;那么目前的深度学习工具用到了多少生物大脑计算的基本原理呢， 答案是， 冰山一角。 如果说人工智能要继续革命， 那么无疑还要继续深挖这些原理，然后根据这些原则重新设定细节。&lt;/span&gt; &lt;span data-offset-key=&quot;cipoj-0-1&quot;&gt;答案很简单， 宇宙的基本定律不会有很多， 比如相对论量子论这样的根本原理几乎统治物理世界。 如果生物大脑使用一套原理实现了智能， 那么很可能人工智能也不会差很远。即使细节差距很大， 那个根本的东西极有可能是一致的。  &lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;64a9g-0-0&quot;&gt;这样的数学原理应该不会有很多条， 因为人脑的结构一个惊人的特点就是虽然脑区非常不同， 但不同脑区的构造却极为相似， 这种相似性显示了大脑不同脑区使用类似的基本原理。&lt;/span&gt; &lt;span data-offset-key=&quot;64a9g-0-1&quot;&gt;我们目前的深度学习算法， 无论是CNN还是RNN，都只是发现了这个基本原理的某个局部。&lt;/span&gt;&lt;span data-offset-key=&quot;64a9g-0-2&quot;&gt;  &lt;/span&gt;发现这个基本原理， 恰恰是计算神经科学的使命。 对于智能这个上帝最杰出的作品， 我们能做的只有盲人摸象， 目前摸到的东西有一些已经被用到了人工智能里， 有些则没有，我们随便举几个看看。&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;9bu1f-0-0&quot;&gt;确定已经被应用的原理：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span data-offset-key=&quot;fgp2t-0-0&quot;&gt;1，  层级编码原理（Hierarchical coding)&lt;/span&gt;&lt;span data-offset-key=&quot;fgp2t-0-1&quot;&gt;： 生物神经网络最基本的结构特点是多层， 无论是视觉， 听觉， 我们说基本的神经回路都有层级结构， 而且经常是六层。这种纵深的层级， 对应的编码原理正是从具体特征到抽象特征的层级编码结构。 最有名的莫过于祖母细胞， 这一思路直接催生了以CNN为代表的深度学习。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;Image FocusPlugin--unfocused Image--isBlock&quot; data-ratio=&quot;0.8511705685618729&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcfcibblDq1JfWD2ElpcKZN1x6YszcyBAdiaIwianPMQyV5XRt0qgibwiaiauFia6LTqC4RE1xLLyAwnCFBXg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;598&quot; /&gt;&lt;/p&gt;

&lt;p&gt;皮层网络的构成往往是6层结构， 在不同的脑区反复出现&lt;/p&gt;


&lt;p&gt;&lt;img class=&quot;Image FocusPlugin--unfocused Image--isBlock&quot; data-ratio=&quot;0.44722222222222224&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcfcibblDq1JfWD2ElpcKZN1xXoL09eTW2ezXic4cCzWBFPjrwEcHRGQTzw4QFrTSbaGsZ8sjMO4tibvQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;720&quot; /&gt;&lt;/p&gt;

&lt;p&gt;层级编码假设&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;a0vog-0-0&quot;&gt;2， 集群编码原理 (Distributed coding)：&lt;/span&gt; &lt;span data-offset-key=&quot;a0vog-0-1&quot;&gt; 一个与层级编码相对应的生物神经编码假设是集群编码， 这里说的是一个抽象的概念， 并非对应某个具体的神经元， 而是被一群神经元所表述。 这种编码方法， 相比层级编码， 会更具备鲁棒性， 或更加反脆弱，因为删除一些细胞不会造成整体神经回路的瘫痪。 集群编码在深度学习里的一个直接体现就是词向量编码， word2vect，  词向量编码并没有采取我们最常想到的每个向量独立的独热编码， 而是每个向量里有大量非零的元素，  如此好比用一个神经集群表述一个单词， 带来的好处不仅是更加具有鲁棒性， 而且我们无形中引入了词语之间本来的互相关联，从而使得神经网络更好的吸收语义信息， 从而增加了泛化能力。 在此处， 每个词语概念都有多个神经元表达， 而同一个神经元，可以参与多个概念的描述。 这与之前说的每个概念比如祖母对应一个特定的神经元有比较大的区别。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;Image FocusPlugin--unfocused Image--isBlock&quot; data-ratio=&quot;0.4236111111111111&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcfcibblDq1JfWD2ElpcKZN1xlChl5rY4IAibvkGwicdm01YE4OfDYfBiaGy71PpcnoC1AJvCHdU5LsrvA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;720&quot; /&gt;&lt;/p&gt;



&lt;p&gt;&lt;span data-offset-key=&quot;7j9t0-0-0&quot;&gt;然而目前的深度学习依然缺乏对集群编码更深刻的应用， 这点上来看，计算神经科学走的更远，我们使用RNN内在的动力学特性， 可以编码很多属性。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;5m2cn-0-0&quot;&gt;局部被应用或没有被应用的原理：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span data-offset-key=&quot;f1phk-0-0&quot;&gt;1，cortical minicolumn：&lt;/span&gt;&lt;span data-offset-key=&quot;f1phk-0-1&quot;&gt;皮层内的神经元都采取簇状结构， 细胞之间不是独立的存在， 而是聚集成团簇， 犹如一个微型的柱状体。  这些柱状体成为信息传输的基本单元。  这种惊人一致的皮层内结构， 背后的认知原理是什么呢？  目前还没有定论。 但是Hinton已经把类似的结构用到了Capsule Network ， 在那里， 每个Capsule对应一个簇状体， 而它们有着非常明确的使命， 就是记录一个物体的不同属性， 由于一个Capsule有很多神经元构成，它也可以看作一个神经元向量， 如果它用来记录一组特征， 则可以对付向旋转不变性这种非常抽象的性质。&lt;/span&gt;&lt;/p&gt;
&lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;&gt;&lt;/ins&gt; &lt;p&gt;&lt;img class=&quot;Image FocusPlugin--unfocused Image--isBlock&quot; data-ratio=&quot;1.243781094527363&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcfcibblDq1JfWD2ElpcKZN1xQ71r2Quaupwib86LVuqmYsicR2sDO7Do1PFXj1waUBBVCC6tBmPibS3Rw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;201&quot; /&gt;&lt;/p&gt;

&lt;p&gt;神经簇细胞， 每个神经簇有80-120个神经元， 犹如大脑认知的基本单元， 你可以把某个组成神经簇的细胞集团看成矢量神经元&lt;/p&gt;


&lt;p&gt;&lt;img class=&quot;Image FocusPlugin--unfocused Image--isBlock&quot; data-ratio=&quot;0.3&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcfcibblDq1JfWD2ElpcKZN1xX5ia2DPZ0OJYcHUkqHphuWEyAwAOa2Of5I0uiaNSYMeFWYticfmDemw5Q/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;720&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Dynamic Routing Between CapsulesCapsule Network (Hinton)   每个Capsule取代之前的单个神经元， 能够同时感知物体的多个属性，如长度，宽度，角度，最终通过多个特征确定物体存在的概率， 因此比卷积网络具备表述更多不变性的能力， 比如旋转不变性&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;epot2-0-0&quot;&gt;2，兴奋抑制平衡：&lt;/span&gt; &lt;span data-offset-key=&quot;epot2-0-1&quot;&gt;生物神经系统的各个组成部分， 尤其是靠近深层的脑区， 都具有的一个性质是兴奋性和抑制性神经元的信号互相抵消，犹如两个队伍拔河， 两边势均力敌（最终和为零）。这使得每个神经元接受的信息输入都在零附近， 这带来的一个巨大的好处是神经元对新进入信号更加敏感， 具有更大的动态范围。  这个原理已经被深度学习悄悄的介入了， 它的直接体现就是极为实用的batch normalization， 输入信号被加上或减去一个值从而成为一个零附近的标准高斯分布（这和兴奋抑制平衡效果类似）， 从而大大提升了网络梯度传输的效率。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;1g07j-0-0&quot;&gt;3，动态网络连接：&lt;/span&gt; &lt;span data-offset-key=&quot;1g07j-0-1&quot;&gt;生物神经系统的神经元和神经元之间的连接-突触本身是随放电活动变化的。 当一个神经元经过放电， 它的活动将会引起细胞突触钙离子的浓度变化，从而引起两个神经元间的连接强度变化。这将导致神经网络的连接权重跟着它的工作状态变化，  计算神经科学认为动态连接的神经网络可以承载工作记忆， 而这点并没有被目前的深度学习系统很好利用 。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;Image FocusPlugin--unfocused Image--isBlock&quot; data-ratio=&quot;0.5513888888888889&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcfcibblDq1JfWD2ElpcKZN1xfiaDFEJJqGQKsia4XlV3DsVpPaiaYQcg4KzR1Nz4owhWVJTkjgC5iaAgeA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;720&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Synaptic Theory of Working Memory （Science）&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;f2pmd-0-0&quot;&gt;4   Top down processing:&lt;/span&gt; &lt;span data-offset-key=&quot;f2pmd-0-1&quot;&gt;  目前深度学习使用的网络以前向网络为主（bottom up）， 而事实上， 在生物大脑里， 不同脑区间反馈的连接数量超过前向的连接， 这些连接的作用是什么？ &lt;strong&gt; 一个主流的观点认为它们是从高级脑区向感官的反向调节（top down）， 如同我们所说的相由心生， 而不是相由眼生。&lt;/strong&gt; 同一个图片有美女拿着蛋糕， 可能一个你在饥肠辘辘的时候只看到蛋糕而吃饱了就只看到美女。 我们所看到的，很大程度上取决于我们想要看到什么，以及我们的心情 。这点对我们的生存无疑十分重要， 你显然不是在被动的认知和识别物体， 你的感知和认知显然是统一的。 你在主动的搜索对你的生存有利的物体， 而非被动的感觉外界存在。这一点目前深度学习还完全没有涉及。 一个引入相应的机制的方法是加入从深层神经网络返回输入层的连接，这样深层的神经活动就可以调控输出层的信息处理，  这可能对真正的“ 理解” 有着极为重大的意义。 &lt;/span&gt; &lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.5986111111111111&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcfcibblDq1JfWD2ElpcKZN1xjRcSy95BGPDSPfClJUtricON0YFziah0YIkB8JjaUEeszeVvLTQ242NQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;720&quot; /&gt;&lt;/p&gt;


&lt;p&gt;给卷积神经网络加入从输出端返回输入端的连接， 是一个深度学习未来的重要方向Deep Convolutional Neural Networks as Models of the Visual System&lt;/p&gt;


&lt;p&gt;&lt;span data-offset-key=&quot;7qff1-0-0&quot;&gt;7，Grid Cells：&lt;/span&gt; &lt;span data-offset-key=&quot;7qff1-0-1&quot;&gt; 海马栅格细胞是一组能够集群表征空间位置的细胞， 它们的原理类似于对物体所在的位置做了一个傅里叶变换， 形成一组表征物体空间位置的坐标基。为什么要对空间里物体的位置做一次傅里叶变换， 这里包含的原理是对任何环境中的物体形成通用的空间表示， 在新的环境里也可以灵活的学习物体的位置，而不是一下子成为路痴。 &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;Image FocusPlugin--unfocused Image--isBlock&quot; data-ratio=&quot;0.4875&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcfcibblDq1JfWD2ElpcKZN1xVVTuuT6IibaaA7VGtMls5n0EKX1LLiaUbaCauDSJsx9Az7GVtibdLWaLQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;720&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Grid Cell被用在强化学习里，使得我们可以得到更加强大的导航能力。&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;9nb9s-0-0&quot;&gt;我们对栅格细胞的认知可能只是更大的神经编码原则的一个局部，正如同傅里叶变换和量子力学之间存在着隐秘的联系。 虽然栅格网络，目前已经被Deepmind用于空间导航任务， 但是目前AI所应用的应该只是这一原理的冰山一角。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;dmpok-0-0&quot;&gt;8   Dale Principle&lt;/span&gt;&lt;span data-offset-key=&quot;dmpok-0-1&quot;&gt;： Dale Principle 说的是兴奋型和抑制型神经元 是完全分开的，犹如动物分雌雄。 兴奋性神经元只对周围神经元发放正向反馈（只分泌兴奋性递质， 如Glutamine），让其它神经元一起兴奋， 而抑制型神经元只发放负向反馈（只分泌抑制型递质， 如GABA），取消其它神经元的兴奋。 目前的深度学习网络不会对某个神经元的连接权重做如此限制 ，每个神经元均可向周围神经元发放正或负的信号。 这一原理到底对AI有没有作用目前未知。   &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span data-offset-key=&quot;dmpok-0-1&quot;&gt;&lt;img class=&quot;&quot; data-ratio=&quot;1.2466666666666666&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcfcibblDq1JfWD2ElpcKZN1xWwMurf9ic6mRXS39lZUx3IgibEOSj6dgpWkCn5RdmicLHibUTECdibsfVHw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;300&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span data-offset-key=&quot;450g1-0-0&quot;&gt;8  Routing by Inhibitory cells&lt;/span&gt; &lt;span data-offset-key=&quot;450g1-0-1&quot;&gt;：  生物神经系统包含种类丰富的抑制型神经元， 它们往往在生物神经网络起到调控功能，如同控制信息流动的路由器，在合适的时候开启或关闭某个信号。 当下的AI直接用attention的机制， 或者LSTM里的输入门来调控是否让某个输入进入网络， 其它一点类似路由器的作用， 但是种类和形式的多样性远不及生物系统。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;span data-offset-key=&quot;450g1-0-1&quot;&gt;9 临界： &lt;/span&gt;&lt;/strong&gt; &lt;span data-offset-key=&quot;450g1-0-1&quot;&gt;大脑的神经元组成一个巨大的喧闹的动力系统， 根据很多实验数据发现， 这个动力系统处于平衡和混沌的边缘， 被称为临界。 在临界状态， 神经元的活动是一种混乱和秩序的统一体， 看似混乱， 但是隐含着生机勃勃的秩序。 临界是不是也可以用于优化目前的深度学习系统， 是一个很大的课题。 &lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;span data-offset-key=&quot;450g1-0-1&quot;&gt;10 ，自由能假说&lt;/span&gt;&lt;/strong&gt;&lt;span data-offset-key=&quot;450g1-0-1&quot;&gt;：  这个假定认为&lt;/span&gt;&lt;span&gt;大脑是一台贝叶斯推断机器。 贝叶斯推断和决策的核心即由最新采纳的证据更新先验概率得到后验概率。 认知科学的核心（&lt;/span&gt;&lt;strong&gt;Perception&lt;/strong&gt;&lt;span&gt;）就是这样一个过程。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;这里再说两句认知，认知的过程用机器学习的语言说就是用大脑的内部变量来模拟外部世界， 并希望建立内部世界和外部的一个一一映射关系。 这里我们说认知的模型是一个概率模型，并且可以被一系列条件概率所描述。如果用一个形象的比喻来说， 你可以把你的大脑看成一个可以自由打隔断的巨大仓库， 你要把外部世界不同种类的货放进不同的隔断，你的大脑内部运作要有一种对外界真实变化的推测演绎能力， 即随时根据新的证据调整的能力， 你和外界世界的模型匹配的越好， 你的脑子就运转越有效率。 认知是对外部世界运动的一种编码， 你可以立刻联想到机器学习里的表征方法（&lt;strong&gt;representation&lt;/strong&gt; &lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;&gt;&lt;/ins&gt;  ）， 如果你熟悉RNN或CNN的embeding过程， 就会有一种豁然开朗的感觉。  这个假说的理论如果成立， 我们机器学习目前应当使用的只是冰山一角， 可以参考强化学习种的有模型学习。 更多内容见&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651383843&amp;amp;idx=1&amp;amp;sn=41e82163f76edfe5ffe31a8518d5bafa&amp;amp;chksm=84f3c662b3844f7430b27f82522dd9414d6c481f6e63822d99deb8baf281be8681ea5c4413a7&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-linktype=&quot;2&quot;&gt;大脑的自由能假说-兼论认知科学与机器学习&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;3do9v-0-0&quot;&gt;11  一些未被量化的心理学和认知科学领地，比如意识。&lt;/span&gt; &lt;span data-offset-key=&quot;3do9v-0-1&quot;&gt; 意识可以理解为自我对自我本身的感知。 关于意识的起源，已经成为一个重要的神经科学探索方向而非玄学， 最近的一些文章指出（The controversial correlates of consiousness - Science 2018），  意识与多个脑区协同的集体放电相关。 但是， 关于意识的一个重大疑团是它对认知和智能到底有什么作用， 还是一个进化的副产物。 如果它对智能有不可替代的作用， 那么毫无疑问， 我们需要让AI最终拥有意识。  一个假说指出意识与我们的社会属性相关， 因为我们需要预测它人的意图和行动， 就需要对它人的大脑建模， 从而派生了对自己本身大脑的感知和认知，从而有了意识。 那么我们究竟需要不需要让AI之间能够互相交流沟通形成组织呢？ 这就是一个更有趣的问题了。  &lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;img data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz/dcEP2tDMibcfyNibceeGvVKo0qCGicGJ9lQ9J5zzOIxmTUAE4OYfwx25QZ2J2KLUic1lWYkMwelC8Ld30RF0FsibAPQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; class=&quot;&quot; data-ratio=&quot;0.1671875&quot; data-w=&quot;640&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;1jp7m-0-0&quot;&gt;深度学习对脑科学的启发：&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;6577n-0-0&quot;&gt;反过来， 深度学习的某些发现也在反向启发脑科学， &lt;strong&gt;这点正好对应费曼所说的， 如果你要真正理解一个东西， 请你把它做出来。&lt;/strong&gt; 由于深度学习的BP算法太强大了， 它可以让我们在不care任何生物细节的情况下任意的改变网络权重， 这就好比给我们了一个巨大的检测各种理论假设的东西。 由于当下对大脑连接改变的方式我们也只理解了冰山一角， 我们可以先丢下细节， 直接去检验所有可能的选项。 这点上看， 用深度学习理解大脑甚至更加有趣。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;bbfml-0-0&quot;&gt;就那刚刚讲的兴奋抑制平衡来看， 最初人们对兴奋抑制平衡作用的理解更多停留在它通过对信号做一个信息增益， 而在深度学习兴起后 ， 我们越来越多的把它的功能和batch normalization 联系起来， 而batch normalization更大的作用在于对梯度消失问题的改进， 而且提高了泛化性能， 这无疑可以提示它的更多功能。 而最近的一篇文章甚至直接将它和LSTM的门调控机制联系起来。 抑制神经元可以通过有条件的发放对信息进行导流， 正如LSTM种的输入门， 输出门的作用， 而互相连接的兴奋神经元则作为信息的载体（对应LSTM中央的循环神经网络）&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;Image FocusPlugin--unfocused Image--isBlock&quot; data-ratio=&quot;0.5819444444444445&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcfcibblDq1JfWD2ElpcKZN1xczzp6hlib2cpsxgCglibMFw8JFHgTEN4EpW05ak19vfnmictiblJpsjYWQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;720&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Cortical Microcircuit as gated recurrent networks   DeepMind    LSTM 和 皮层通用回路具有极为密切的相关性&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;fm386-0-0&quot;&gt;&lt;img data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz/dcEP2tDMibcfyNibceeGvVKo0qCGicGJ9lQ9J5zzOIxmTUAE4OYfwx25QZ2J2KLUic1lWYkMwelC8Ld30RF0FsibAPQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; class=&quot;&quot; data-ratio=&quot;0.1671875&quot; data-w=&quot;640&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span data-offset-key=&quot;fm386-0-0&quot;&gt;我们距离通用人工智能可能还有多远？&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;1g49h-0-0&quot;&gt;其实人工智能的目标就是找寻那个通用人工智能，而类脑计算是实现它的一个重要途径 。 通用智能和当下的智能到底有什么实质性的区别， 作为本文结尾， 我们来看一下：&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;c78e7-0-0&quot;&gt;对数据的使用效率：&lt;/span&gt; &lt;span data-offset-key=&quot;c78e7-0-1&quot;&gt;比如大脑对数据的应用效率和AI算法并非一个等级， 你看到一个数据， 就可以充分的提取里面的信息，比如看到一个陌生人的脸， 你就记住他了， 但是对于目前的AI算法， 这是不可能的， 因为我们需要大量的照片输入让他掌握这件事。 我们可以轻松的在学完蛙泳的时候学习自由泳， 这对于AI，就是一个困难的问题， 也就是说，同样的效率， 人脑能够从中很快提取到信息， 形成新的技能， AI算法却差的远。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;c78e7-0-1&quot;&gt; &lt;/span&gt;&lt;span data-offset-key=&quot;c78e7-0-2&quot;&gt;这是为什呢？ 可能这里的挂件体现在一种被称为迁移学习的能力。虽然当下的深度学习算法也具备这一类举一反三的迁移学习能力， 但是往往集中在一些真正非常相近的任务里， 人的表现却灵活的多。&lt;/span&gt;&lt;span data-offset-key=&quot;c78e7-0-3&quot;&gt;这是为什么呢？ 也许， 目前的AI算法缺少一种元学习的能力。 和为元学习， 就是提取一大类问题里类似的本质， 我们人类非常容易干的一个事情。 到底什么造成了人工神经网络和人的神经网路的差距， 还是未知的， 而这个问题也构成一个非常主流的研究方向。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;2fu41-0-0&quot;&gt;能耗比：&lt;/span&gt;&lt;span data-offset-key=&quot;2fu41-0-1&quot;&gt;如果和人类相比， 人工智能系统完成同等任务的功耗是人的极多倍数（比如阿法狗是人脑消耗的三百倍， 3000MJ vs 10MJ 5小时比赛）。 如果耗能如此剧烈， 我们无法想象在能源紧张的地球可以很容易大量普及这样的智能。 那么这个问题有没有解呢？  当然有， 一种， 是我们本身对能量提取的能力大大增强， 比如小型可控核聚变实用化。 另一种， 依然要依靠算法的进步， 既然人脑可以做到的， 我们相信通过不断仿生机器也可以接近。 这一点上我们更多看到的信息是， 人工智能的能耗比和人相比， 还是有很大差距的。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;drpng-0-0&quot;&gt;不同数据整合&lt;/span&gt;&lt;span data-offset-key=&quot;drpng-0-1&quot;&gt;： 我们离终极算法相差甚远的另一个重要原因可能是&lt;/span&gt;&lt;span data-offset-key=&quot;drpng-0-2&quot;&gt;现实人类在解决的AI问题犹如一个个分离的孤岛&lt;/span&gt;&lt;span data-offset-key=&quot;drpng-0-3&quot;&gt;， 比如说视觉是视觉， 自然语言是自然语言， 这些孤岛并没有被打通。 相反，人类的智慧里， 从来就没有分离的视觉， 运动或自然语言， 这点上看， 我们还处在AI的初级阶段。 我们可以预想， 人类的智慧是不可能建立在一个个分离的认知孤岛上的， 我们的世界模型一定建立在把这些孤立的信息领域打通的基础上， 才可以做到真正对某个事物的认知， 无论是一个苹果， 还是一只狗。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;6pd07-0-0&quot;&gt;沟通与社会性&lt;/span&gt;&lt;span data-offset-key=&quot;6pd07-0-1&quot;&gt;： 另外，&lt;/span&gt; &lt;span data-offset-key=&quot;6pd07-0-2&quot;&gt;人类的智慧是建立在沟通之上的， 人与人相互沟通结成社会&lt;/span&gt;&lt;span data-offset-key=&quot;6pd07-0-3&quot;&gt;， 社会基础上才有文明， 目前的人工智能体还没有沟通， 但不代表以后是不能的， 这点， 也是一个目前的AI水平与强AI（超级算法）的距离所在。  &lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;aqaeq-0-1&quot;&gt;有的人认为， 我们可以直接通过模拟大脑的神经元，组成一个和大脑类似复杂度的复杂系统， 让它自我学习和进化， 从而实现强AI。 从我这个复杂系统专业的角度看， 这还是一个不太现实的事情。因为复杂系统里面最重要的是涌现，也就是说当组成一个集合的元素越来越多，相互作用越来越复杂， 这个集合在某个特殊条件下会出现一些特殊的总体属性，比如强AI，自我意识。 但是我们几乎不可能指望只要我们堆积了那么多元素， 这个现象（相变）就一定会发生。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;8uis4-0-0&quot;&gt;至于回到那个未来人工智能曲线发展展望的话题， 我们可以看到， 这些不确定的因素都会使得这条发展曲线变得不可确定&lt;/span&gt;&lt;span data-offset-key=&quot;8uis4-0-1&quot;&gt;。 然而有一点是肯定的， 就是正在有越来越多非常聪明的人， 开始迅速的进入到这个领域， 越来越多的投资也在进来。 这说明， AI已经是势不可挡的称为人类历史的增长极， 即使有一些不确定性， 它却不可能再进入到一个停滞不前的低谷了， 我们也许不会一天两天就接近终极算法， 但却一定会在细分领域取得一个又一个突破。无论是视觉， 自然语言， 还是运动控制。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;q2iu-0-0&quot;&gt;能否走向通用人工智能的确是人工智能未来发展最大的变数&lt;/span&gt;&lt;span data-offset-key=&quot;q2iu-0-1&quot;&gt;， 或许， 我们真正的沉下心来去和大脑取经还是可以或多或少的帮助我们。 因为本质上， 我们在人工智能的研究上所作的， 依然是在模拟人类大脑的奥秘。&lt;/span&gt; &lt;span data-offset-key=&quot;q2iu-0-2&quot;&gt;我们越接近人类智慧的终极算法， 就越能得到更好的人工智能算法。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;更多阅读&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651383852&amp;amp;idx=1&amp;amp;sn=09d90baeafb224ab6f4309e170dffe14&amp;amp;chksm=84f3c66db3844f7b196609bf0b68c8e42293df8aec12ecd53844a6871e1ab1830f8f722dc516&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-linktype=&quot;2&quot;&gt;复杂性思维应对不确定性&lt;/a&gt;&lt;br /&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651383842&amp;amp;idx=1&amp;amp;sn=b4196485b009ebd21e7e0d8db1e2cd61&amp;amp;chksm=84f3c663b3844f756cb7f0547b8f1acf03ac6aeff743d8a37c4d3024b0c30dec19afb8f2298e&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-linktype=&quot;2&quot;&gt;Alpha Zero登上Science封面- 听铁哥浅析阿尔法元&lt;/a&gt;&lt;br /&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651383841&amp;amp;idx=1&amp;amp;sn=dcaede7797236936bb76650a8434627b&amp;amp;chksm=84f3c660b3844f767a5f38f0093f94ae781eafaed9737b99e78e2da121b34b3b6ca8234a37ff&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-linktype=&quot;2&quot;&gt;人工智能vs人类智能小传&lt;/a&gt;&lt;br /&gt;&lt;/p&gt;
&lt;p&gt;&lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;&gt;&lt;/ins&gt; &lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651383350&amp;amp;idx=1&amp;amp;sn=f396de4fbaffd7dcf7af2af20b55bb2e&amp;amp;chksm=84f3c877b38441617cf9ecaea03d652f18ab2d159eccdc966107df071cca384e55618ce57671&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-linktype=&quot;2&quot;&gt;胶囊网络结构Capsule初探&lt;/a&gt;&lt;br /&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651383212&amp;amp;idx=1&amp;amp;sn=e6dbbda2acc5984c8d06e24ec9c84d09&amp;amp;chksm=84f3cbedb38442fb58f0aea635821fcf4ba3edaacef4685716c7eadb6191197ebfa70a6bf14b&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-linktype=&quot;2&quot;&gt;你所不能不知道的CNN&lt;/a&gt;&lt;br /&gt;&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; rgb=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;&gt;作者简介&lt;/p&gt;
&lt;pre contenteditable-directive=&quot;&quot; mm-paste=&quot;&quot; ng-blur=&quot;editAreaBlur($event)&quot; ng-model=&quot;editAreaCtn&quot; ng-click=&quot;editAreaClick($event)&quot; ng-keyup=&quot;editAreaKeyup($event)&quot; ng-keydown=&quot;editAreaKeydown($event)&quot; readability=&quot;4.5&quot;&gt;
&lt;br /&gt;&lt;span&gt;作者许铁，微信号：ironcruiser &lt;/span&gt;&lt;br /&gt;&lt;span&gt;法国&lt;/span&gt;&lt;strong&gt;巴黎高师&lt;/strong&gt;&lt;span&gt;物理硕士 ，&lt;/span&gt;&lt;strong&gt;以色列理工大学&lt;/strong&gt;&lt;span readability=&quot;3&quot;&gt;（以色列85%科技创业人才的摇篮, 计算机科学享誉全球）计算神经科学博士，巡洋舰科技有限公司创始人,   《机器学习与复杂系统》纸质书作者。曾在香港浸会大学非线性科学中心工作一年 ，万门童校长好战友。&lt;p&gt;&lt;strong&gt;铁哥更系统性的关于人脑智能和人工智能的比较分析可见目前在万门大学开设的新课： 模拟人类大脑-跟着许铁老师学人工智能&lt;br /&gt;&lt;/strong&gt;&lt;br /&gt;&lt;img data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibccvEGHcvx6vn7ibqucwWjTLJNQDiajMVL3arkx9IJnm10baZ1RjdLTN2KH6SKHZqnzyGO5K0G3dNOwg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; class=&quot;&quot; data-ratio=&quot;5.896&quot; data-w=&quot;750&quot; /&gt;&lt;/p&gt;&lt;/span&gt;
&lt;/pre&gt;

</description>
<pubDate>Tue, 01 Jan 2019 08:03:02 +0000</pubDate>
<dc:language>zh-CN</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.jintiankansha.me/t/LwMQM6PYck</dc:identifier>
</item>
<item>
<title>订阅，一种全新的商业模型-速读《Subscribe》</title>
<link>http://www.jintiankansha.me/t/KNAuitpAYw</link>
<guid isPermaLink="true" >http://www.jintiankansha.me/t/KNAuitpAYw</guid>
<description>&lt;p&gt;今天花五分钟介绍一本18年的商业类新书，也是经济学人杂志年度书单中商业类书籍的第一名，作者是Zuora（美国一家成功转型为订阅模式的IT服务企业0的高管。这本书分为俩部分，第一部分介绍了订阅模式是什么，以及在不同的领域（即包括2C，也包括2B）会有怎样的应用场景，第二部分介绍了为了转型为订阅模式，企业从金融，组织结构，营销，研发等方面所需做出的改变。本书的预期读者不止是企业管理人员，而是所有对未来的主流商业模式感兴趣的人，正如书中强调的，订阅模式在各行各业，都正在成为主流的模式。&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;1.5096286107290233&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcc9HBjjJcjicXEDkO2ouQbIEYm6Ajx0Frke3W54GlerMNE8ekvRlYdKEQcdDbC6KwY0XhFFxuktPnw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1454&quot; /&gt;&lt;/p&gt;

&lt;p&gt;说起订阅，最容易想起的是视频网站的会员，还有亚马逊的Prime/京东的Plus会员。除了这俩种（媒体，购物平台），还包括云服务，比如SaaS模式，例如你购买一个云服务器搭建网站，共享单车/汽车的月度会员，有些航空公司/旅店会对常客提供月度会员服务，购买软件时，也会有按年度收费的等。按照作者的统计，下图展示了12年到17年订阅模式的销售量和S&amp;amp;P 500公司销售量以及美国总零售额增长速率的对比，这种图想说明的是订阅模式的增长速度。而我们日常的经验也会让我们意识到订阅模式正在成为主流，你身边有越来越多的会员，需要你去续费，或者会直接从你信用卡你扣款。&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.718964204112719&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcc9HBjjJcjicXEDkO2ouQbIEqEvKC4KSVuibD9JcBEuOxYFgSRSxpFLktuGyibVeAEnQicLVvaDWGZB0w/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1313&quot; /&gt;&lt;/p&gt;

&lt;p&gt;为什么2C的订阅模式会流行，目前是归结于移动互联网带来的海量信息，&lt;strong&gt;只有当你可以和客户持续双向的互动的时候，购买的行为才不是一次性的&lt;/strong&gt;。在此之前，只有健身房这样少数人们需要切身参与的场景下才能让用户与商家有不止一次的交流，从而促成年度会员的模式。订阅模式的核心是&lt;strong&gt;商家&lt;/strong&gt;&lt;strong&gt;给顾客提供的是一种持续的服务，而顾客为了这份体验付出一笔固定的年金&lt;/strong&gt;。顾客不会由于付费额外拥有什么东西，只会获得对其有帮助的体验，为此这需要有移动互联网带来的普遍的个人信用体系及便捷的支付方式。&lt;/p&gt;

&lt;p&gt;对于娱乐业来说，订阅模式最成功的就是Netflex的网拍剧“纸牌屋”，凭借对订阅用户的大数据研究，精准的找出主题演员编剧的组合，打造爆款，而国内的视频网站爱奇艺和腾讯也有自拍的网剧，同样获得了成功。传媒领域，喜马拉雅/知乎的会员代表的是知识付费，财新/三联的付费新闻代表的更具有时效性的媒体。媒体和娱乐业都是反经济周期的，经济越不景气，人们越需要娱乐，越容易焦虑从而需要充电，而订阅模式的付费门槛低，并且能通过长尾效应给小众用户更多的选择，从而使用户有更好的体验，在未来势必会变得更为普及。&lt;/p&gt;

&lt;p&gt;会员模式不止限于线上。线下的超市，也可以通过类似Costco，以收取会员费而不是依靠价格差获得盈利；汽车的租赁，停车车位，地铁/公交这样的公共交通等，都可以转换为订阅模式。你的家具/电脑如果是租的，这还不算是订阅模式，但如果你租了小米的笔记本用起来觉得不好，可以立刻换一个苹果的，那么这才是正宗的订阅式服务。会员会有不同的等级，也会有不同类型的偏好。而像万门大学这样的终生VIP，也不算是订阅模式，订阅模式的起点是相对比购买要低的，依靠的是用户持续的（很多时候是默认为自动的）续费及会员升级来保证持续的盈利和增长。&lt;/p&gt;

&lt;p&gt;未来随着5G的到来以及物联网的普及，订阅模式最广泛的用途还是在2B的工业流水线上。比如智能电网的服务可以帮助用户节省电费，不管是个人还是企业，通过错峰用电，避免在电费高的时候收费。或者你的智能机器人或者一种算法能够降低生产成本，提高良品率，那么你也可以将其当成是一种订阅服务来销售。例如通过深度学习来帮助医院里放射科的医生提高效率，是2B，而直接在农户的手机上装上害虫识别的APP，从而帮助农户及早对症下药，则是2C的模式。由于物联网带来的对生产过程中的量化，不仅能够提高工业生产的效率，对于深耕其中的小微型企业，只要能够带来收益，能够通过订阅模式获得生计，并将服务扩展开来。&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.5475206611570248&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcc9HBjjJcjicXEDkO2ouQbIEpRzfFQrtUIgwoNuI2fQTaQpQJlzLUiaG3fibChR1I4liaicdLq5Epgz5jw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1452&quot; /&gt;&lt;/p&gt;

&lt;p&gt;和传统的树状商业模式不同，订阅模式是一个持续的循环，其没有明确的销售渠道。商家需要做的是持续的去通过创新来为用户去创建超过其心理预期的好的体验，从而留住用户，让用户升级会员的等级，或者购买其他的细分会员（例如从音乐平台导流到知识付费平台）并通过用户的分享带来新的用户。&lt;strong&gt;只有持续的全面的记录用户的使用行为，才能从这些数据中挖掘出用户的痛点，给会员做出个性化的推荐，让用户得到更好的体验，从而使的获得新会员带来的收益高于你的获客成本（该目标可以通过用户数增加摊平固定成本增加收益或通过社交化精准运营降低获客成本），从最终实现盈利。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;为了达成向订阅模式的转换，企业的管理层要转变任务/目标分解的方式，将会员量而不是销售收入看成是最重要的评价指标，要将之前的部门，例如营销，研发，公关等融合起来，让所有人共同围绕着用户体验的优化来展开工作，而不是各自完成自己的KPI。IT和财务也要做出相应的改变。本书的第二部分对其每个领域都给出了建议。但我看来这些建议只能做参考，各个不同的行业所采取的订阅模式会有细节的差异，从而导致所需的改变策略也都不同的，这里重要的信息是&lt;strong&gt;商业模式的改变必然导致系统性的对企业运营方式以及企业中每个人产生深远的影响，没有一场伤筋动骨范式革命就无法成功的转型。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;总结一下，订阅模式的应用场景广泛，发展迅速，前景光明。起源于移动互联网，兴盛于5G和人工智能大规模应用，不管是成熟的还是初创的企业，都应该逐步向该订阅模式转移。而对个人来说，订阅模式对我们和人交往也有所启示，你不要将和人与人的交往想象成一个一次性的交易，未来你的一举一动都被记录，你要将自己变成一个值得别人为你付年金的服务，当然这里的年金主要值得是时间和注意力。这句话可以理解为你要通过持续表现的有创意有幽默感有洞见，从而愿意让别人愿意在你身上花时间投资。&lt;/p&gt;

&lt;p&gt;更多阅读&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651383706&amp;amp;idx=1&amp;amp;sn=a1640b00320b0e43e769bff619cb78fc&amp;amp;chksm=84f3c9dbb38440cd0a807d9a8d72b9a4701191dd24af206c0703f2fa104ed1cae6b0758964f3&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-linktype=&quot;2&quot;&gt;机器与人-寻找人机之间的中间地带&lt;/a&gt;&lt;br /&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651383620&amp;amp;idx=1&amp;amp;sn=925e02ec639b33f4f88fd470d78b78bb&amp;amp;chksm=84f3c905b3844013bec20e1c5318c3135a3494dc2f1c7d02ac135f3925136bcebe42cf8ccc61&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-linktype=&quot;2&quot;&gt;一本带你读懂无形资产的书-《CAPITALISM WITHOUT CAPITAL》&lt;/a&gt;&lt;br /&gt;&lt;/p&gt;







</description>
<pubDate>Tue, 25 Dec 2018 15:10:27 +0000</pubDate>
<dc:language>zh-CN</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.jintiankansha.me/t/KNAuitpAYw</dc:identifier>
</item>
<item>
<title>复杂性思维应对不确定性</title>
<link>http://www.jintiankansha.me/t/M3u0s66sJC</link>
<guid isPermaLink="true" >http://www.jintiankansha.me/t/M3u0s66sJC</guid>
<description>&lt;p&gt;我在三年前写过一篇文章叫无常世界的生存圣经， 这篇文章是根据塔勒布的反脆弱引申到我自身的学科“复杂系统” 所得到的。 今天我就在之前很多思考基础上再谈谈这个主题。&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;6pb9j-0-0&quot;&gt;风险和不确定性来自于不可预测，如果一切容易预测， 何“险”之有？&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;8tigg-0-0&quot;&gt;那么一个很自然的问题就是这种不可预测性是否无可避免， 我么要走进它的根源， 也就是我们刚刚讲到的复杂性来认识它。 如果用一句话来总结复杂性， 我会说是“ 世界有网络组成， 网络带来的非线性作用， 毁灭了可预测性，却带来了世界的所有精彩， 从生命，到智能， 到我们的文明本身” 。  &lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;1deb6-0-0&quot;&gt;那么如何抵抗这种风险？ 这我也用一句话来总结，就是“即使没有预测的确定性， 我们可以英明决策，这套方法的本质恰是一套受复杂性启发的算法”&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span data-offset-key=&quot;edsv7-0-0&quot;&gt;那么我们就把两句话依次展开：&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;2vbf4-0-0&quot;&gt;复杂性导致预测失败的本质&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;k2ug-0-0&quot;&gt;预测是人类最古老的主题， 从一个人的命运生老病死， 到一个国家国势的兴衰。 这都包含在预测这个庞大的主题里。 想象一下，如果你能预测你的人生， 或者某个人能够预测一个国家甚至人类的兴衰， 那将是何等意义的事。&lt;/span&gt; &lt;span data-offset-key=&quot;k2ug-0-1&quot;&gt;阿西莫夫的小说基地里的故事说，&lt;/span&gt; &lt;span data-offset-key=&quot;k2ug-0-3&quot;&gt;一个叫哈里谢顿的人发明了一个叫心理史学的学问能够预测整个银河帝国的兴衰，&lt;/span&gt; &lt;span data-offset-key=&quot;k2ug-0-5&quot;&gt;便是这类故事的一种形式。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;5aq6j-0-0&quot;&gt;如果粗略把这个世界的东西分个类， 那一定会被分成两个大类，一类可以叫做”死物“ ， 比如宇宙里的星体， 固体， 液体， 各类分子原子， 亚原子 。  另一类就是”活物“  ， 包括所有和生命有关的东西，从各类生物学的细胞过程， 到我们大脑里的神经运动，再到社会经济。  &lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;fdq95-0-0&quot;&gt;对于第一类事物，人类已经无比成功的做到了预测， 而第二类事物则不是。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;7uef-0-0&quot;&gt;物理模型&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;d2ock-0-0&quot;&gt;物理预测的故事一类围绕那些确定性的， 周期性的事物， 如单摆或行星， 一类围绕那些微观的随机的不确定的东西， 而中间有一个叫统计物理的东西把它们连起来。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;fc3f3-0-0&quot;&gt;哪一类确定性的东西具经典的莫过于行星运动模型的进化史。 从托勒密 (Ptolemy) 的&lt;/span&gt;&lt;span data-offset-key=&quot;fc3f3-1-0&quot;&gt;&lt;span data-text=&quot;true&quot;&gt;宇宙&lt;/span&gt;&lt;/span&gt;&lt;span data-offset-key=&quot;fc3f3-2-0&quot;&gt;模型系统， 他的模型里说日月星辰的运动可以分解为一系列互相嵌套的圆周运动，到哥白尼的日心说， 直到开普勒把之前的圆形轨道变成椭圆轨道。 最终椭圆轨道起到了牛顿力学， 模糊被经典的微分方程抽象化， 我们也可以称之为定理。 它们可以预测各类事物的变化，而又可以通过实验检验。 从此苹果落地的抛物线，到日月星辰的运动， 被统一在一起。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;Image FocusPlugin--unfocused Image--isBlock&quot; data-ratio=&quot;0.5633333333333334&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibccy2aaFP2wGUsJjeD4oCJSDs7kjiaoT5Qv5JCc2r4KCF2UTSCZziaIf1L7UxDkFgxPHPIMmYuQMickrQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;600&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;fh9h1-0-0&quot;&gt;这种对现象进行分解，抽象出最一般性的因素的方法就是物理的思维。 很快， 这种思维开始进入微观世界。 这些微小的例子由于测不准原理具有根深蒂固的不确定性，却可以描述， 而之后被实验证实。  没错， 物理预测的力量正在与每一次我们都在实验发生前就知道了将要发生什么。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;611l2-0-0&quot;&gt;差不多同时，我们开始构建微观到宏观的桥梁。 如果原子是随机的， 那么它们组成了所有宏观物质，它们有温度，有软硬，有形状，有化学性质， 为什么却是确定的呢？我们能否从微观预测宏观？  我们又一次的成功了， 而这在常识里， 可以被看成不可能的任务。 这不得不归功于统计物理。 统计物理的最重要的观点是， 微观尺度上的大量粒子运动是随机的，通过统计的方法，我们在宏观尺度上得到的东西却可以如磁铁般稳固， 且可以预测的特性。 比如我们可以计算磁铁的磁性，水的沸点。 这种随机到宏观精确的可预测性背后的保证， 正是大数定律。 大数定律的关键观点是你有无数的随机且独立的变量不停加和， 你就会得到一个更大尺度上确定性的个体。  所谓多而不同。 一个典型的例子是掉入水里的花粉颗粒像一个醉汉一样做布朗运动， 而一个巨大的台球掉进去就是扑通一下从加速到减速的确定轨迹。 两者有何不同？体积也。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;76p67-0-0&quot;&gt;你可以看看下图的随着数据增加高斯分布的变化来理解。 数量极大， 整体可以由平均数替代。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;Image FocusPlugin--unfocused Image--isBlock&quot; data-ratio=&quot;0.5633333333333334&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibccy2aaFP2wGUsJjeD4oCJSDqFW83OfsHmJR9YYnPGQyEGiaffY5xRklsX60oibic16P5rA5CjOicoPFLg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;600&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;Image FocusPlugin--unfocused Image--isBlock&quot; data-ratio=&quot;0.5633333333333334&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibccy2aaFP2wGUsJjeD4oCJSDkibDj8NPAAToO4wP4Y68gKymjpfEiaRzF8IcX8AapIib1XkC19ywqmQ4w/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;600&quot; /&gt;&lt;/p&gt;


&lt;p&gt;&lt;span data-offset-key=&quot;80v9i-0-0&quot;&gt;社会与人类心理预测的失败&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;eet4g-0-0&quot;&gt;在20世纪以后， 在所有之前工业革命基础上出现了计算机， 以至于后面的互联网， 使得人类积累数据， 以及用数学来预测的能力又一次空前提高， 迎来了信息爆炸的时代。我们依然按照之前的思路继续建模，因循着这样的思路，人开始思考社会本身也存在类似牛顿原则一样的第一性原理，是否可以由统计物理来预测。 而在心理学领域，我们也开始认识到人类的心智也如同一台动力学机器， 在客观的受力法则下思考和运行。 对于这一类愿望的典型描述在阿西莫夫的基地里淋漓尽致， 它借哈里谢顿教授的口说出： 人类社会的每个成员如同气体里的分子，他们的运动可能是随机的不可预测， 但是其组成的人类社会确是高度可以预测的。因此它预测了整个“基地“ 的没落， 从而展开了整个它的改变人类历史的计划。 这简直就是对统计物理的观点重演，每个人随机的不可预测， 但是很多人加总在一起， 一个国家，一个民族的兴衰确是高度精确可测的。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;b7sqc-0-0&quot;&gt;但是这些幻想很快落空， 这条路走不下去了。 我们发现， 凡是跟社会和人类有关的领域，我们几乎输的精光。 你想应用大数定律， 你却总在失败。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span data-offset-key=&quot;ah9e1-0-0&quot;&gt;有一个有趣的实验说的是，  如果一个群里人数固定， 每个人起初都有100元，然后我们玩一个游戏， 每个人随机的给周围人1元 ， 这样接龙传递下去， 那么过上一段时间， 屋子里人的资金就会有一个分布 ， 这个分布会是一个什么形状呢？&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;Image FocusPlugin--unfocused Image--isBlock&quot; data-ratio=&quot;0.5633333333333334&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibccy2aaFP2wGUsJjeD4oCJSDwBYIWlTNzkcLl7rAssE3TlAnKkghOqPsCOR8cbMZp6oXDZpJicOwTcQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;600&quot; /&gt;&lt;/p&gt;

&lt;p&gt;图片来自知乎&lt;/p&gt;


&lt;p&gt;&lt;span data-offset-key=&quot;f5p22-0-0&quot;&gt;&lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;&gt;&lt;/ins&gt;  事实上， 这个方程非常接近物理里的扩散过程， 因此你得到一个经典的玻尔兹曼分布。 事实却并非如此， 事实的真相是， 这个分布比玻尔兹曼分布极端的多， 它呈现一个幂律分布。 为什么会是幂律分布？  它说的是一种比高斯，指数（玻尔兹曼）分布都更加不均匀的分布， 不是在最大， 就是在最小， 反脆弱书里说的极端斯坦， 平均数开始变得越来越没有意义。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;Image FocusPlugin--unfocused Image--isBlock&quot; data-ratio=&quot;0.5633333333333334&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibccy2aaFP2wGUsJjeD4oCJSDHW6ibSzWaBjtQnE9q0KhxvZm4UicHWcudFViauJTzBFTu8CB1Qq7tw5yQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;600&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;d0ipu-0-0&quot;&gt;另一个典型的预测失效的例子在于经济金融危机和股市，大家都想预测股票价格，一群最天才的数学物理加发现了black-scholes 方程， 我们想象股市的价格是大量的进入交易所买入和卖出的交易者决定的， 股市价格的本质是人们对公司未来总价值的预期， 如果这些交易者， 就像组成物质实体的粒子一样， 虽然随机， 统计上却可以预测， 市场总体会符合一个经典的随机微分方程。 然而事实逐步违背了天才们的初衷， 这么多的聪明人进入到股市交易搏杀， 却没有几个人能预测2009年的金融危机。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;Image FocusPlugin--unfocused Image--isBlock&quot; data-ratio=&quot;0.5633333333333334&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibccy2aaFP2wGUsJjeD4oCJSD0byD4Xia71cfPumttMJePv64KKDZx9Ag3DXjOv5kd9FlOA2ZXpXEIxw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;600&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;Image FocusPlugin--unfocused Image--isBlock&quot; data-ratio=&quot;0.5633333333333334&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibccy2aaFP2wGUsJjeD4oCJSDjWAWdQyS916aG1FkmpzA4CzbEuBnNLbibUkKxkQCicz4D2tQm9UpDbOQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;600&quot; /&gt;&lt;/p&gt;


&lt;p&gt;&lt;span data-offset-key=&quot;amrh0-0-0&quot;&gt;事实上金融市场的背后推手往往有社会层面的突发事件，这些事件更加难以预测。 比如特朗普的当选， 或者英国的脱欧。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;2khrh-0-0&quot;&gt;而另一个角度， 我们对自己的大脑的预测更是知之甚少， 比如目前几乎还没有什么仪器能够预测你老了会不会得老年痴呆，或者你今晚会不会失眠。我们并不能用受力分析的方法把人脑分解为细胞，然后找到一组方程， 或者用统计的方法， 解出心智运行的模型。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;5mdv9-0-0&quot;&gt;预测失败的元凶 – 网络&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;1hrpo-0-0&quot;&gt;到底是什么， 破坏了我们建造预测性的通天塔的目标？&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;d6ohe-0-0&quot;&gt;我们先前的理论一个根本缺陷是一个最重要的假设是不成立的， 它就是独立性假设。 当组成整体的每个个体之间的相互作用可忽略， 我们称为独立假设成立， 这时候，如果每一个个体的行为是随机的， 但是组成总体的特性确实可以确定的。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;2on11-0-0&quot;&gt;最致命的是， 人的大脑还是人类社会， 独立性假设不成立。 显然你的成长无法忽略周围的某些特定个体对你的影响， 同样的你的大脑里的某个神经元离开周围神经元的信号传递一无是处，几乎就是一个比较大的电阻电容电路而已。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;cu990-0-0&quot;&gt;所有这些问题的背后， 隐藏了一个新的问题范式 – 网络。 如果个体和个体不独立，意味着它们的互相影响无法忽略， 这个互相影响， 导致之前的预测范式无法很好的起作用， 有效的理解个体已经不再是理解总体的基础。 这个网络， 会引入如下几个效应：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;Image FocusPlugin--unfocused Image--isBlock&quot; data-ratio=&quot;0.5633333333333334&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibccy2aaFP2wGUsJjeD4oCJSDLIZ6TIx8pnsJtAUnDPhiaBP6VPWibAicgKVlSNawPLwiaB4IViaiaLgEIIKg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;600&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;ejoc6-0-0&quot;&gt;非线性：&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;4nm1-0-0&quot;&gt;整体不再是部分的加和我们管它叫非线性，这个整体的特性变得特别难以预测。  这个你可以理解当下的互联网使得个人的作用已经远远不是加法。 非线性的基本类型包含负反馈和正反馈 ，  它使得整体的相加的结果更大或者更小于部分之和。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;faiuq-0-0&quot;&gt;这样的例子在你身边也很多， 两个很优秀组成的家庭可能非常不幸福， 而一群乌合之众在某个清晰聪明的规则下， 可以其力断金。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;da50s-0-0&quot;&gt;非线性带来机会， 由于连续的正反馈， 一个单个节点有时可以改变整个网络， 你可以想象某个小人物有时候突然改变了历史的进程， 无论是遇雨失期的陈胜， 还是一战里那个艺术气质的失落士兵希特勒。非线性对应普通个体意味着机会。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;58q58-0-0&quot;&gt;混沌：&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;8qg8f-0-0&quot;&gt;气象预测一直以来是农业生产的重要课题，曾经有一段时间， 物理学家认为只要能够合理的解出气体运动的流体力学方程， 那么一个月后的天气无非是大量模拟可以解决。 然而气象学家试图对大气建模（当然是牛顿力学了）的过程里，发现了一个不可思议的现象，它们算出来的天气一会儿晴天一会儿下雨：完全相同的一份数据，多保留小数点后一位数，计算出来的就是晴天；少保留一位小数，计算出来的就是下雨。这是机器的问题吗，比如说这是程序员都遇见过的计算机浮点误差导致的？最后这为我们揭示了叫做混沌的物理现象。 有本书叫三体， 事实上牛顿力学里三体问题的时候就已经很难预测了， 三个物体之间只要有复杂的相互预测，在一定时间后， 得到的解都已经极不稳定， 假设计算机程序出那么一丁点的误差， 都会使得我们最终的解与之前完全不同。 这里的不确定性来自于我们无法控制所研究系统的所有信息，而每一丁点的不同都导致结果完全不同。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;55sjn-0-0&quot;&gt;只要个体数大于等于三， 系统内的非线性连接足够强， 就会发生混沌， 非线性网络大部分都处在混沌成立的条件区间，这使得确定性逐步远离了我们的视野。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;Image FocusPlugin--unfocused Image--isBlock&quot; data-ratio=&quot;0.5633333333333334&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibccy2aaFP2wGUsJjeD4oCJSDUIosoFYibbO3KQGoga32EvvVsgA04mTa88osI36LnlAECQXZh1GoYtw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;600&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;afgr-0-0&quot;&gt;相变与涌现：&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;4db6a-0-0&quot;&gt;混沌绝不仅是不可知的混乱， 它的另一面恰恰是我们说的秩序（order）。 我们说非线性网络中的正反馈达到一定程度， 会从比较稳定的结构过度到混沌， 这个混沌边缘的点或者说相变点。恰是所有复杂结构（秩序）诞生的基础， 比如智能的载体神经网络就是在这个混沌边缘的点工作的。  &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;Image FocusPlugin--unfocused Image--isBlock&quot; data-ratio=&quot;0.5633333333333334&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibccy2aaFP2wGUsJjeD4oCJSDfQNd4O5qeOQ7jL154endzM89zTH4IOKW7JCicbRsgTMAHeNWaUnJmUw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;600&quot; /&gt;&lt;/p&gt;


&lt;p&gt;&lt;span data-offset-key=&quot;dqn8i-0-0&quot;&gt;复杂网络间的耦合：&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;8nfle-0-0&quot;&gt;社会，历史，经济问题恰是两个不同尺度的复杂非线性网络的耦合， 一个是社会网络， 一个是大脑网络 。 两个网络都符合前面的所有特征。 而恰恰是两个网络纠缠在一起。 社会网络的节点， 其实是一个个超级复杂的脑网络， 它们的某个情绪风暴， 会引起下一级社会网络的一个革命风暴， 尤其是当两个网络都处于相变点， 这种级联效应更加可怕， 也使得它们构成的整体彻底的逃离了预测性的边界。&lt;/span&gt;&lt;/p&gt;


&lt;p&gt;&lt;span data-offset-key=&quot;f7vlh-0-0&quot;&gt;我们要意识到虽然非线性网络在毁灭预测性， 但来了世界的丰富多彩， 生命本身来自于这样的网络， 以至于智能物种的产生， 直道文明和社会， 直到你自己， 这些事情都是不可思议， 也非确定发生的， 它， 也是我们生活的所有滋味所在。&lt;/span&gt;&lt;/p&gt;


&lt;p&gt;&lt;span data-offset-key=&quot;c65pd-0-0&quot;&gt;我们既然存在于这张不确定的网中， 就要做到与它对抗， 而是共存。 因为在我们的生活， 还是创业中， 我们真正面临的不是精确的预测每个个体乃至社会的行为， 而是正确的决策， 即使无法预测， 依然可以英明决策。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span data-offset-key=&quot;c65pd-0-0&quot;&gt;&lt;img data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz/dcEP2tDMibcfyNibceeGvVKo0qCGicGJ9lQ9J5zzOIxmTUAE4OYfwx25QZ2J2KLUic1lWYkMwelC8Ld30RF0FsibAPQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; class=&quot;&quot; data-ratio=&quot;0.1671875&quot; data-w=&quot;640&quot; /&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;bkhed-0-0&quot;&gt;下面我们就来说一下有关决策应对不确定性的问题：&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;4aiuh-0-0&quot;&gt;一些系统的应对不确定性的思维方法可以称之为算法， 我们站在事物发展， 而非自身的层面去看问题。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;1um59-0-0&quot;&gt;进化算法：&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;b8gqt-0-0&quot;&gt;其实整个生命进化史， 就是一套自然应对不确定性的方法论。  你要看到，从远古生命到现在， 自然环境发生的沧海桑田的变化已经有多少次？ 也许有无数次， 你都可以假定生命已经毁灭了， 事实上发生的是， 生命没有被毁灭， 而是在这个过程里， 越来越复杂， 越来越高级。 这背后， 就是达尔文发生的进化论。 我想可以把这件事做如下总结：&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;span data-offset-key=&quot;26hgl-0-0&quot;&gt;1，&lt;/span&gt;&lt;/strong&gt; &lt;span data-offset-key=&quot;26hgl-0-0&quot;&gt;&lt;strong&gt;生命不能预测未来， 但是它可以生成一套在各种条件下的一组行为策略。&lt;/strong&gt;比如摄入什么样的物质， 向什么方向移动， 这组策略被一套叫DNA的大分子固定， 也就是我们常常说的遗传编码 ， 它通过一个复杂的化学反应， 制造RNA和特定的蛋白质，而一切生命现象都是由特定蛋白质实现的， 我们简单的说就是生命策略， 比如在外界环境出现如何变化时候如何反应。 你可以把DNA的编码看成一系列的if else语句， 就是在某种条件下， 触发某个蛋白质， 实现某一个功能。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;Image FocusPlugin--unfocused Image--isBlock&quot; data-ratio=&quot;0.5633333333333334&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibccy2aaFP2wGUsJjeD4oCJSDzr0mK6Bz8JhoRJW3sy9jOldkfXHnPXPsxzLcUEvYd8kZer4tfw7xqQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;600&quot; /&gt;&lt;/p&gt;


&lt;p&gt;&lt;strong&gt;&lt;span data-offset-key=&quot;146et-0-0&quot;&gt;2， 单组策略的存在时间有限， 它会以繁殖的形式得到一个和自己一样的策略， 但是这个过程不是完全精确的， 它会以一定的方式出错或者说变化。&lt;/span&gt;&lt;/strong&gt;&lt;span data-offset-key=&quot;146et-0-0&quot;&gt; 这恰恰使得下一代的策略可以轻微的偏离上一代， 从而在一段时间里， 形成越来越多的策略，我们叫做基因池。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;span data-offset-key=&quot;42tmn-0-0&quot;&gt;3， 有的时候不同的基因会发生交叉。&lt;/span&gt;&lt;/strong&gt;&lt;span data-offset-key=&quot;42tmn-0-0&quot;&gt; 也就是说把两组策略把各自的一部分给对方， 然后形成新的策略组合。 这种重组产生新的基因的速度会比变异快的多， 也就是我们说的交配。  &lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;4c7ds-0-0&quot;&gt;3， &lt;strong&gt;环境会评估某个策略（DNA） 是不是适合自己， 这个通常由一个叫适应度函数的东西表达。&lt;/strong&gt;  适应度越高， 基因就是越适应当下环境。&lt;/span&gt; 经过一段时间， 适应环境的策略会比不适应的环境的策略得到更多的个体，因为它自身存活的概率更高， 这样， 最终环境里数量最多的， 是最适应环境的策略。这样的策略不一定有一个。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;span data-offset-key=&quot;ej353-0-0&quot;&gt;4，  环境会变化。&lt;/span&gt;&lt;/strong&gt;&lt;span data-offset-key=&quot;ej353-0-0&quot;&gt;当环境变化， 最适宜的策略发生变化， 这个时候最适合的策略也发生变化， 导致新的物种和生态系统的生成。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;Image FocusPlugin--unfocused Image--isBlock&quot; data-ratio=&quot;0.5633333333333334&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibccy2aaFP2wGUsJjeD4oCJSD75ic4vnG7YqRotL4zqSb4HhicGgIjVF39RfNe5BJKTA1M0ZSunsRVBzA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;600&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;span data-offset-key=&quot;3srqu-0-0&quot;&gt;应该说， 这样的一个算法具有一种天然的反脆弱性， 基因的变化是随机的无目的的， 恰恰对应环境的变化是不可预测的无方向的， 生命通过死亡，竞争和繁殖的游戏， 使得群体总有某些个体能够适应环境而延续， 即使对于每个个体这足够残酷， 但是在总体水平上， 却使得基因能最有效的调整自己。  即便不做任何预测， 也可以很好存留。&lt;/span&gt;&lt;/p&gt;


&lt;p&gt;&lt;span data-offset-key=&quot;cit5-0-0&quot;&gt;一个日常生活中的进化选择算法例子&lt;/span&gt;&lt;span data-offset-key=&quot;cit5-2-0&quot;&gt;：  此处， 我们假定有100个随机排列的扇贝（三角形），它们的基因组就是每个扇贝的颜色和位置， 我们的环境适应函数是让它们组合起来接近一个火狐的形状， 越接近就是越相似。 我们每一次稍稍改变这组参数，  并且寻找一组最优的交换基因， 最终的结果大家见图 。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;Image FocusPlugin--unfocused Image--isBlock&quot; data-ratio=&quot;0.5633333333333334&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibccy2aaFP2wGUsJjeD4oCJSDOgHQrRibrRTIWPsXHFibPicrIzU8Pab1KZMLqiceuJ8I2Zm7YApvvpy6OQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;600&quot; /&gt;&lt;/p&gt;


&lt;p&gt;&lt;span data-offset-key=&quot;d5r0-0-0&quot;&gt;对于我们日常生活的启发性：&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;span data-offset-key=&quot;am898-0-0&quot;&gt;1， 试错而非设计的方法论&lt;/span&gt;&lt;/strong&gt;&lt;span data-offset-key=&quot;am898-0-0&quot;&gt;： 对不确定环境具有最高适应的策略 ， 是来自于自然进化和淘汰而非设计， 靠的是繁殖的速度能够跑赢环境变化。 因此， 对于产品设计， 最重要的是加快迭代速度， 远好于常开会。  &lt;/span&gt;&lt;/p&gt;


&lt;p&gt;&lt;strong&gt;&lt;span data-offset-key=&quot;7dpve-0-0&quot;&gt;2， 鲁棒性很重要&lt;/span&gt;&lt;/strong&gt;&lt;span data-offset-key=&quot;7dpve-0-0&quot;&gt;：  最好的东西不一定是目前看起来最优的， 而是在变化的环境中可以适应自己的。 这个特性通常称为鲁棒性， 所谓杀不死的是最好的， 也就是塔勒布的反脆弱。 也许一个方案特别完美， 但是条件一旦出现变化， 它就不成立了， 这还不如找一个没有那么完美， 但是适应性更好的方案， 往往迭代试错来的方案具有这个特点。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;emlqu-0-0&quot;&gt;由此我们也可以想一下最近基因编辑的那个事情。 你随意的改变人的基因， 这是基于设计而非进化来的东西， 也没有经过过各种环境的论证， 这样创造的人， 就是不具备自然选择赋予的鲁棒性，说不定在某个情况下会有灭顶之灾， 这也是基因编辑的科学问题的一个关键挑战。&lt;/span&gt;&lt;/p&gt;


&lt;p&gt;&lt;strong&gt;&lt;span data-offset-key=&quot;a2n9a-0-0&quot;&gt;3， 多备胎策略。&lt;/span&gt;&lt;/strong&gt; &lt;span data-offset-key=&quot;a2n9a-0-0&quot;&gt; 自然进化的特点是对待个体是残酷的， 而总体上获得进化的鲁棒性，  多子嗣，也就是多备胎。 对于产品设计， 或公司运营， 我们要考虑环境变化时候的备选方案。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;c65pd-0-0&quot;&gt;&lt;img data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz/dcEP2tDMibcfyNibceeGvVKo0qCGicGJ9lQ9J5zzOIxmTUAE4OYfwx25QZ2J2KLUic1lWYkMwelC8Ld30RF0FsibAPQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; class=&quot;&quot; data-ratio=&quot;0.1671875&quot; data-w=&quot;640&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span data-offset-key=&quot;4utc9-0-0&quot;&gt;智能算法：  &lt;/span&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;&gt;&lt;/ins&gt; &lt;span data-offset-key=&quot;6j7q7-0-0&quot;&gt;进化算法最重要的里程碑是动物神经系统的产生， 或者说我们的大脑。 也就是在这个阶段， 生存策略的生成出现了质的飞跃， 此时的策略， 不再是单向的在环境有水的时候就去喝水这种， 而是出现了所谓的学习策略，你可以把它看成一个生成策略的策略，通过一个叫神经网络的东西， 你可以超越基因编码新的策略。  这里最重要的就是强化学习的出现， 相比进化这种被动的随机的策略搜索， 强化学习更类似于一种主动有目标的调整， 从而使得策略更新的效率极大的加快。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;Image FocusPlugin--unfocused Image--isBlock&quot; data-ratio=&quot;0.5633333333333334&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibccy2aaFP2wGUsJjeD4oCJSDLlWHHlKz0Qk47C1TXPnIFoohrbB9zTSSr9ia0N62DPibX59IOSoVxxsQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;600&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;9ua8c-0-0&quot;&gt;那么，强化学习算法可以看作第二个更有效的面对不确定性的思维框架。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span data-offset-key=&quot;1q6vp-0-0&quot;&gt;强化学习里最核心的思想是有效的探索策略， 以及探索和收益的平衡。 它包含如下要点：&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;5ceof-0-0&quot;&gt;1， 强化学习分为几个要素， 个体， 环境， 行为， 奖励， 个体做出行动， 获得环境的奖励反馈，同时改变环境，个体为了让长期的奖励最大化， 需要调整自己的行为。 行为的规则的， 也就是不同环境条件下的该做什么行为， 也就是策略， 也就是我们学习的对象。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;Image FocusPlugin--unfocused Image--isBlock&quot; data-ratio=&quot;0.5633333333333334&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibccy2aaFP2wGUsJjeD4oCJSDsd3ZXOkoa332AUibiblWicBbOiccia8y0G0LGQtxpkqQtEOeV0L0DEV6DiaA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;600&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;59h11-0-0&quot;&gt;2， 未来是不确定的，但我们必须在此刻做出选择， 因此， 我们把未来所有可行的选项都考虑进去， 并给每个可行性估值， 它代表我所认为的潜在收益。 我们根据这个估值来做行动的决策， 我们倾向于选择那个估值最高的选项， 但是不要马上抛弃其它选项，而是给其它的选项一个较小的概率执行，这又称为探索。 最初的估值我们可以看作在初期更多就是凭直觉， 后面会迅速调整。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;8c4ih-0-0&quot;&gt;3， 每个行动会带来有关结果的新的信息，这个信息可能对结果有害或者有益， 这时候我们要迅速的调整估值。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;5igt5-0-0&quot;&gt;4， 根据新的估值决策。&lt;/span&gt;一个特别简单的例子是摇臂赌博机， 你去赌场玩的， 都知道这个机器的存在，  它的构造就是很多个长得一样的摇臂，每个对应不同的中奖概率， 你要玩N轮， 每次选择摇臂， 使得最终的收益最大。 聪明的你一定可以设计一个方案， 让自己的收益最大， 怎么做呢？&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;8i7va-0-0&quot;&gt;这里， 我们就到了一个点，就是探索与收益的平衡， 加入你开始就中了 ， 你会一直选择那个中奖的摇臂不放过吗？ 显然这可能是陷阱，因为还有收益更高的臂，或者只是这次的运气好。 反过来， 你会不停的随机试下去吗？显然不会， 因为存在收益比较高的臂。 所以， 你就需要设计一个策略， 在有效探索的同时加大在那个最有收益可能的臂的概率， 每次玩， 又都增加你的信息。  这就是一个极为典型的应对不确定的策略。 而且，  可以直接用到产品设计上， 我们也可以把它看成一个特别有方向性的试错， 比进化的随机试错要快的多。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;Image FocusPlugin--unfocused Image--isBlock&quot; data-ratio=&quot;0.5633333333333334&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibccy2aaFP2wGUsJjeD4oCJSDb9BKPLFazEbk2z08HLRfJamxSiaEcnZL1kfQfAB59wFBLibqKTujo13g/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;600&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;cmthd-0-0&quot;&gt;更高级的强化学习包含了一个世界模型的部分， 也就是说， 在行动之初， 你不仅要设定可行选项， 还要尽可能的在平行宇宙里将不同选项导致的未来展开， 先在思维里战上100轮，减少那些不好的选项， 这就比最初凭直觉估值好的多了， 虽然我们无法精确预测， 但是有一个模糊的世界模型依然可以大大加强我们决策正确的概率， 阿法狗就是凭类似的思想战胜李世石的。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;2v6lf-0-0&quot;&gt;强化学习给我们的启示：&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;span data-offset-key=&quot;cb7s8-0-0&quot;&gt;1，  未来不可预测， 但不等于我们可以没有清晰的目标：&lt;/span&gt;&lt;/strong&gt; &lt;span data-offset-key=&quot;cb7s8-0-0&quot;&gt; 强化学习成立的根据在于一开始就有一个自定义的收益函数，  这个函数必须是行为体已知的， 而不是之前进化算法里来自环境的适应度。 这里的收益， 就是目标， 一开始没有清晰的目标界定， 一切行动无从谈起。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;span data-offset-key=&quot;5ds99-0-0&quot;&gt;2，  只考虑可行边界之内的事， 无论目标有多宏大， 我们每一步只考虑可能做到的几个动作， 及这些动作对目标的影响。&lt;/span&gt;&lt;/strong&gt; &lt;span data-offset-key=&quot;5ds99-0-0&quot;&gt;这点的反面就是眼高手低， 很多人每天想来想去，事实上都在想自己的可行区间外的事情。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;span data-offset-key=&quot;2c7s8-0-0&quot;&gt;3，  探索与收益是随时间调整的。&lt;/span&gt;&lt;/strong&gt; &lt;span data-offset-key=&quot;2c7s8-0-0&quot;&gt;虽然我们始终要考虑探索与收益，但是强化学习过程里， 探索和收益的比值始终在不停减少。也就是说越到后期， 就越以收益为主， 探索，但一定要有限度，因为你的生命是有限的。 这里面直接的方法论就是我们年龄越大就越要保守，如果你20岁， 失败只是打一个喷嚏， 30岁， 还可以从头再来， 50岁， 就很难了， 褚时健毕竟是少数， 已经取得了一定资历的人， 一定要把成功换成更稳定的，可以向下一代传递的东西。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;span data-offset-key=&quot;941qu-0-0&quot;&gt;4， 无论任何时候， 尝试建立世界模型。&lt;/span&gt;&lt;/strong&gt; &lt;span data-offset-key=&quot;941qu-0-0&quot;&gt;虽然预测是困难的， 你要把不同方案导致的未来，以及它们的结果， 尽量的建立一个世界模型， 就好像一个平行宇宙的展开。这个展开的方式， 一方面来自由你的经验模板塑造的直觉， 另一方面是关于世界运行的原理。 如果你的平行宇宙展开的足够好， 你就得到了一个可能世界的合理分布。 阿法狗其实是面对不确定性的最聪明的算法， 虽然我们不是阿法狗， 但是可以学习它的套路。  有时候， 你做了这件事， 会淘汰一些直觉看起来正确， 但是错误的选项。&lt;/span&gt;&lt;/p&gt;


&lt;p&gt;&lt;span data-offset-key=&quot;b9l1k-0-0&quot;&gt;曾经的我， 思路更加接近于不断试错和迭代的进化算法， 而今天， 我的思维更接近强化学习的系统， 人生苦短， 试错有限，在结构目标非常清晰的时候， 极为高效的试错， 并且迅速的收敛于那个收益最高的解，再此基础上迭代， 是更有效的策略。  &lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;b9l1k-0-0&quot;&gt;&lt;img data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz/dcEP2tDMibcfyNibceeGvVKo0qCGicGJ9lQ9J5zzOIxmTUAE4OYfwx25QZ2J2KLUic1lWYkMwelC8Ld30RF0FsibAPQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; class=&quot;&quot; data-ratio=&quot;0.1671875&quot; data-w=&quot;640&quot; /&gt;&lt;/span&gt;&lt;/p&gt;


&lt;p&gt;&lt;span data-offset-key=&quot;d742j-0-0&quot;&gt;如何把这样的思维更精确的结合数据来使用我们会得到贝叶斯算法：&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;brgt4-0-0&quot;&gt;当下这个时代， 我们拥有越来越多帮助我们决策的数据， 谷歌，百度， 知乎， 都在帮助我们迅速的得到信息。 很多时候你会告诉我， 预测无非就是数数， 比如预测大选结果， 我可以做一个简单的假设， 在谷歌上被搜索更多的那位更有可能获胜 ， 然后你去查看谷歌的搜索结果， 你居然真的可以准确预测啊，请看下图。  &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;Image FocusPlugin--unfocused Image--isBlock&quot; data-ratio=&quot;0.5633333333333334&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibccy2aaFP2wGUsJjeD4oCJSDeS6xLAjIpJ03m1ibEMqf9mr2M8unib8HvlLmyEgh7Seu1JBfpzDeZ34g/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;600&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;2a7re-0-0&quot;&gt;但是这样的方法却不总是奏效， 几年前谷歌搞过一个预测流感的系统，它把流感出现的关键词，比如头痛，发烧，咳嗽， 呕吐都做成了特征。 这些关键词，构成了一组关键特征， 可以用来有效的预测流感是否发生， 只要我们搜索这些词汇， 应该就可以预测流感在一个地区是否会发生。 然而，这个问题虽然一开始的预测比较准确， 很快就完全的偏离了真实的数据， 问题出在什么地方？ 我们无法避免隐藏在数据里的大量噪声， 因为产生那些特征的原因非常多， 比如说头痛， 工作疲劳可以头痛， 失恋也可以头痛，感冒仅仅是原因之一。&lt;/span&gt;&lt;/p&gt;

&lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;&gt;&lt;/ins&gt; &lt;p&gt;&lt;img class=&quot;Image FocusPlugin--unfocused Image--isBlock&quot; data-ratio=&quot;0.5633333333333334&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibccy2aaFP2wGUsJjeD4oCJSDS1RJrE7jx5tLcPxrAQxvRiag1su8n6cC2lcPhwUkKWdeYhZyPQ4jtGw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;600&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;dereh-0-0&quot;&gt;而贝叶斯算法可以有效的剔除数据里的噪声，因为它可以通过加入先验信息， 把我们几千年积累的知识和大数据结合起来。贝叶斯算法其实是一种非常中庸的态度， 一方面， 我们要保持一套对世界的预测模型， 虽然我们知道它不准确， 另在不确定性面前， 我们最好的办法是保持一种理性的谦逊， 也就是赋予这种原始预测一个有限的概率， 然后我们设计实验收集数据， 如果这个数据支持这种模型假设， 我们就加强一点信息， 否则就减少一点， 这个根据数据调整信心（概率）的公式就是贝叶斯公式， 我更喜欢把它看成一个思维方法。 一个很好的例子是月亮和奶酪的估计， 你孩子看到月亮， 觉得那是个奶酪， 你不要马上告诉它那不是， 而是告诉它根据物理学家的理论，它是一个石头， 不过你的观测确实也作数， 因此你可以稍稍的动一下概率。   根据贝叶斯公式， 依然鼓励我们做出一个初始的模型预测， 比如说， 你去看未来的经济形势， 你可以根据各类的周期理论， 得到一个大致的上行或下行估计。 然后你可以根据周边人的状态调整这个概率。 这样的思维可以让你在不确定性面前最有效的调整自己。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;Image FocusPlugin--unfocused Image--isBlock&quot; data-ratio=&quot;0.5633333333333334&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibccy2aaFP2wGUsJjeD4oCJSD2Mial5XpAtXF1PoK0X2xWNaNt6e6kw8CSAYDOfKia4bVnjz5KbFT9z1g/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;600&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;16khl-0-0&quot;&gt;一个很好的运用贝叶斯的例子来自于对掉入海里的飞机的搜索， 比如之前的马航事件， 这几乎可以说是一个不确定性大到极点的例子，大海茫茫， 我们依据的信息确是非常稀少的。 但是并不需要特别担心， 因为我们有贝叶斯的框架。 首先， 一组专家会对可能找到黑匣子的区域做出限定， 然后， 搜救人员会出动进入这个区域， 它们所做的事情大致是这样的， 我们把区域分成无数的小方格， 首先搜索那些根据专家开始估计的概率最大的区域， 如果没有黑匣子， 就降低这个区域的概率，同时提高那些没有搜救的概率， 这样每搜索一个格子， 这个概率就会变化一次， 最终经过几轮之后， 我们就会得到越来越小和精确的搜救区域， 根据这样的方法， 即使是大海捞针，我们也可以胜利。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;Image FocusPlugin--unfocused Image--isBlock&quot; data-ratio=&quot;0.5633333333333334&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibccy2aaFP2wGUsJjeD4oCJSDcfdx43jDrpBNo2GTl2pGp2fKCFteNGuh8sNzjyr5aOoicCUJzBZ1Nzw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;600&quot; /&gt;&lt;/p&gt;



&lt;p&gt;&lt;span data-offset-key=&quot;e4h9u-0-0&quot;&gt;在不确定面前，我们能够做的最蠢的事情是直接把某些选项的概率降为0，  因为这样如果它们真的是成立的， 你就死无葬身之地了。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span data-offset-key=&quot;e4h9u-0-0&quot;&gt;&lt;img data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz/dcEP2tDMibcfyNibceeGvVKo0qCGicGJ9lQ9J5zzOIxmTUAE4OYfwx25QZ2J2KLUic1lWYkMwelC8Ld30RF0FsibAPQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; class=&quot;&quot; data-ratio=&quot;0.1671875&quot; data-w=&quot;640&quot; /&gt;&lt;/span&gt;&lt;/p&gt;


&lt;p&gt;&lt;span data-offset-key=&quot;fh12e-0-0&quot;&gt;应对非线性的一些策略启示&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;5h0se-0-0&quot;&gt;相变营销：&lt;/span&gt;&lt;span data-offset-key=&quot;5h0se-0-1&quot;&gt;这里记录一些没有那么成系统的思想， 我们知道非线性网络里相变的影响， 那么， 我们也可以利用这种思想来营销。 我们都想爆发式增长， 在互联网世界， 它就是你的客户网络里的一种相变， 如何能够达到这样的产品？ 首先是时机，第一个发布的产品在用户的心理永远更容易占据位置。 然后是速度， 因为非线性的原理告诉我们， 速度决定了网络里传播的密度， 最终将影响动力学的稳定点， 只有速度超过一个阈值，我们才能推动这个产品的传播达到一个更高的稳定点，也就是占领整个市场。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;4g1a0-0-0&quot;&gt;关于搜索策略：&lt;/span&gt; &lt;span data-offset-key=&quot;4g1a0-0-1&quot;&gt;鲨鱼在寻找事物时候实行一种l随机游走的姿势， 它时而在一个小范围里不停翻滚改变方向， 时而做一系列极长的不改变方向的行动以达到更远的点， 这个策略事实上是在时间有限希望能够快速探索整个空间的方法 。因为资源的分布是非线性的，要不是富集状态，要不一穷二白， 相对应的，当我们经过一个小的搜索得不到什么资源时候， 做个较大幅度的调整通常可以跳脱局部极小， 然后再进行比较密集的搜索。  这样往往可以更快的找到富矿。&lt;/span&gt;&lt;/p&gt;


&lt;p&gt;&lt;span data-offset-key=&quot;5csnb-0-0&quot;&gt;关于认知偏差&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;4ag5n-0-0&quot;&gt;一个很致命的影响我们应对不确定性的策略的因子是心态，　很多人在不确定性面前容易犯以下几个错误：&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;span data-offset-key=&quot;b3ip1-0-0&quot;&gt;1， 认知的锚定效应， 夸大或缩小一些可能， 而看不到真实的分布。&lt;/span&gt;&lt;/strong&gt; &lt;span data-offset-key=&quot;b3ip1-0-0&quot;&gt;我们通常喜欢那些容易认知的东西， 而夸大那些可能性。 比如你天天在新闻联播里看到以色列发生了恐怖袭击， 你就会觉得耶路撒冷天天都在发生炸弹爆炸。 比如你很容易想象阴谋论里说的非典是美国人制造的病毒这种事， 因为脑补这样的画面非常容易， 我给你将一个更抽象但是成立概率更高的可能性， 但是由于脑补不成故事画面， 你就不会重视那个可能。 这点在应对不确定性时候是致命的， 因为你对概率的估计能力决定了你策略的准确性。&lt;/span&gt;&lt;/p&gt;


&lt;p&gt;&lt;strong&gt;&lt;span data-offset-key=&quot;f2fce-0-0&quot;&gt;2，决策的后果不等于质量&lt;/span&gt;&lt;/strong&gt;&lt;span data-offset-key=&quot;f2fce-0-0&quot;&gt;： 很多人是根据决策的后果来思考是否决策正确， 比如当年没有投资马爸爸， 没有买北京房子， 说自己当时有什么什么人劝自己做那些事而没有做， 或者差一点做了， 然后特别后悔 。其实这是一个非常常见的误区。 因为我刚刚讲过的一点， 我们的信息永远是不足的， 所谓的最优决策就是在有限信息下的最优决策。 即使你当年有钱投资马爸爸， 但是那时候的你的信息完全不足以支撑你买，这才是事实。  而你不买也不一定不对。 因为你只是看到了所有可能的后果中的一种。  有多少创业成功的人认为自己回到过去还会成功？ 100个平行宇宙， 只有一个马爸爸是成为首富， 那99个世界没有投资的你可都做了正确的决定啊。 记住， 成功学鸡汤背后， 可能藏着的就是幸存者偏差。&lt;/span&gt;&lt;/p&gt;


&lt;p&gt;&lt;span data-offset-key=&quot;4q01q-0-0&quot;&gt;3， 关于现实扭曲力场：&lt;/span&gt;&lt;strong&gt;最牛的人， 往往做的事不是预测， 而是改变。&lt;/strong&gt; 虽然预测是不可能准确的， 但是如果你的行动足以改变它，那么世界就会向着你所预想的方向变化 。 也就是说， 正确的决策使得你所预想的未来成为现实， 那句鸡汤不是说， be the change you want to see 吗？  正是说， 预期无休止的预测， 不如让你的力量产生一个足够强大的现实扭曲力场。&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz/dcEP2tDMibcfyNibceeGvVKo0qCGicGJ9lQ9J5zzOIxmTUAE4OYfwx25QZ2J2KLUic1lWYkMwelC8Ld30RF0FsibAPQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; class=&quot;&quot; data-ratio=&quot;0.1671875&quot; data-w=&quot;640&quot; /&gt;&lt;/p&gt;
&lt;p&gt;本来是许铁在混沌大学讲座的记录，更多相关内容，请参考作者的科普书籍《机器学习与复杂系统》。作者简介：微信号：ironcruiser 法国巴黎高师物理硕士 ，以色列理工大学计算神经科学博士，巡洋舰科技有限公司创始人, 《机器学习与复杂系统》纸质书作者。曾在香港浸会大学非线性科学中心工作一年 ，万门童校长好战友。&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;9h0bm-0-0&quot;&gt;&lt;img data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibccvEGHcvx6vn7ibqucwWjTLJNQDiajMVL3arkx9IJnm10baZ1RjdLTN2KH6SKHZqnzyGO5K0G3dNOwg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; class=&quot;&quot; data-ratio=&quot;5.896&quot; data-w=&quot;750&quot; /&gt;&lt;/span&gt;&lt;br /&gt;&lt;/p&gt;


</description>
<pubDate>Tue, 18 Dec 2018 16:02:50 +0000</pubDate>
<dc:language>zh-CN</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.jintiankansha.me/t/M3u0s66sJC</dc:identifier>
</item>
</channel>
</rss>