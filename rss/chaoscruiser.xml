<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="css/feed.xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/" xmlns:og="http://ogp.me/ns#">
<channel>
<atom:link rel="self" href="http://192.168.1.4/fivefilters/makefulltextfeed.php?url=feed43.com%2Fchaoscruiser-jtks.xml&amp;max=5&amp;links=preserve&amp;exc=1" />
<atom:link rel="alternate" title="Source URL" href="http://feed43.com/chaoscruiser-jtks.xml" />
<atom:link rel="related" title="Subscribe to feed" href="http://www.subtome.com/#/subscribe?feeds=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed43.com%252Fchaoscruiser-jtks.xml%26max%3D5%26links%3Dpreserve%26exc%3D1&amp;back=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed43.com%252Fchaoscruiser-jtks.xml%26max%3D5%26links%3Dpreserve%26exc%3D1" />
<title>混沌巡洋舰</title>
<link>http://www.jintiankansha.me/column/ultiWL8Axg</link>
<description>混沌巡洋舰 - 今天看啥</description>
<ttl>360</ttl>
<item>
<title>强化学习书籍与课程推荐</title>
<link>http://www.jintiankansha.me/t/t3mDMe8GmF</link>
<guid isPermaLink="true" >http://www.jintiankansha.me/t/t3mDMe8GmF</guid>
<description>&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;人工智能有关决策的核心是强化学习。让机器来决策，首先体现在如何模仿人类的决策。对于决策这个问题， 对于人类是困难的， 对于机器就更难。而强化学习， 就是一套如何学习决策的方法论。当下的强化学习逐步过渡到深度强化学习主导的时代， 从打游戏，逐步向机器人，无人驾驶等领域扩散。&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;然而强化学习的入门门槛却比其它人工智能领域要高，其中一个原因是强化学习课程不像深度学习和机器学习一样琳琅满目， 铁哥在此给大家推荐几个经典的强化学习课程和书籍。&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;&lt;span&gt;经典书籍：&lt;/span&gt;&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;由于这是一个80年代才发展起来的新兴学科，其经典著作也非常稀少。如果硬要推一本， 那首推Rechard Sutton的强化学习经典书籍， 首先Rechard老爷子是强化学习的发明人， 这也就为Reinforcement Learning: An Introduction. 这本书从强化学习是什么开始引入，然后把内容分为表格化方法（Tabular method）, 近似方法（Apporximative method） 和 强化学习前沿（主要讲解强化学习和心理学的关系）三个方面。而Tabular method又是其中最大的一块。所谓的Tabular方法，指的是在任务的所有状态都已知的情况下，强化学习问题等同为一个把每个状态的未来收益都列出来的状态表， 唯一要做的就是把表里的每个数值都通过各种不同的经历都列出来。&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;这个写法的根基在于Sutton老人家的得意之作在于TD学习的方法， 这种利用迭代方法boostrap对未来收益的估计的方法特别好体现在表格方法里，后面的TD-lambda等高阶的TD方法也在这里一并讲出。表格化方法还有一个优点是容易引入动态规划（dynamic programming）的整体框架， 这是人工智能领域比较少见的非常优雅成系统的数学方法。&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;然而本书毕竟成书较早， 虽然理论功底十分扎实， 但是对强化学习当下的应用， 尤其是深度强化学习， 涉猎较少， 对于学以致用的中国学生显然无法满足要求。因此这本书只建议作为基础入门之选，可以让你从根上熟悉强化学习理论是怎么一步步生长出来的。&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;&lt;span&gt;以下推荐经典课程：&lt;/span&gt;&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;1， Deepmind 强化学习课程系列&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;Deepmind的课程高度尊重了Sutton书籍的经典性， 可谓是其书籍的现代版。这个课程偏向强化学习的理论框架搭建，应该说比较好的延续了Rechard Sutton偏向于值学习为基础的框架，甚至可以看作Sutton书籍的视频版 。本书从强化学习的基本概念入手，引入值函数， 引入TD学习 和蒙特卡洛抽样学习逐层引入强化学习的基本概念，因此课程的理论框架偏向于值函数学习这一套， 这也是和Sutton最初的框架一脉相承。&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;Deepmind采用这样的课程体系也不难理解， 因为Deepmind 在强化学习的第一桶金深度强化学习攻克Atari game就是DQN（深度Q学习）的巨大功劳， 值学习和值函数学习在状态给定清晰的游戏里也具有最高的效率。&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot;&gt;&lt;span&gt;课程优点是理论框架和数学&lt;/span&gt;推导&lt;span&gt;极为扎实，而且讲解和比喻非常清晰有趣， 缺点是实践性内容比较依然稀缺， 当然你可以去Deepmind的网页查找论文和对应的github。&lt;/span&gt;&lt;span&gt;DeepMind课程在Youtube上可以找到两个不同的品种，一个是David Silver亲自讲的，一个是更年轻的教授的较新版本，两个课程事实上非常相似。&lt;/span&gt;&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;Deepmind的课程缺少实践的内容本身也和其公司注重打游戏而非把算法用在工业实践有关， 而另一个课程则可以看成极好的对其补充。&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;2，Berkeley· deep RL 285&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;这个课程较少为人所知， 但是确是一个真正的干货满满的深度强化学习课程。它的内容一开始就跳开了Sutton老爷子的动态规划框架，而是从一个更接地气的角度模仿学习入手。一开始学生就可以接触到自动驾驶这样的非常实际的问题， 这和Berkeley在机器人领域功底深厚密不可分。因此如果你喜欢研究深度强化学习的偏实践问题， 那么我强烈推荐这个课程。&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;从理论上看有意思的是， 它的介绍角度偏向于policy gradient作为框架的基础。课程一开始以模仿学习引入， 然后指出模仿学习的不足， 无法轻易的泛化到人类经验之外，从而开始引入学习策略和策略梯度，以及最核心的Actor-Critic算法。而在所有其它教材里浓墨重彩的值学习方法， 却仅仅是作为Actor-Critic一个去掉Actor的特例讲解。这与工业控制领域更多依靠策略梯度而很难应用值函数法是密切相关的（因为工业领域一般面对较为连续的动作空间，比如机器手的移动）。同时这个课程最大的优势在于引入了元强化学习，分布式强化学习， 多任务学习， 生成式模型等领域前沿概念，仅仅看课表就可以感受到其内容之新颖。&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;这个课程的主讲人是Sergey Levine， 也是这个领域的前沿研究者。&lt;/p&gt;
&lt;img data-ratio=&quot;0.43333333333333335&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibceTw4J0RSWJyJb30T8XQw5OZzgoSZibmZco7zjzCZpApPf3kDwDfDCAlMyGOIsSiahLJfGp65ywcGOA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;720&quot; width=&quot;1305&quot;/&gt;&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;作为总结补上强化学习的学科地图。我们看到解决一般性的强化学习有两大不同的流派，一个叫做策略优化（左），旨在利用策略梯度直接优化行为，得到最后的奖励。一个叫做动态规划（右）， 旨在通过假定存在一个马尔可夫状态链，迭代式的求解每个状态下的未来收益，侧重先评估再改进行为。Deepmind的书籍课可以看作从右向左的过程， 而伯克利的课程则是从左向右。经典的理论注重从右向左， 当下强化学习实践注重从左向右， 此处就是其关键所在。&lt;/p&gt;
&lt;img data-ratio=&quot;0.37777777777777777&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibceTw4J0RSWJyJb30T8XQw5OqbSvA8YZG6p1BqicrF3CfCK093iaxNYdXL5IEJicj192fghBvEu7xn7Bw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;720&quot; width=&quot;720&quot;/&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;最后分享一个铁哥3月30号的 live 讲座 ICLR论文看脑科学如何助力人工智能：&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span data-text=&quot;true&quot;&gt;ICLR论文看脑科学如何助力人工智能&lt;/span&gt;&lt;span&gt;www.zhihu.com&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;img data-ratio=&quot;1&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibceTw4J0RSWJyJb30T8XQw5OgeSOJPWkos0l0lZBAKGMMtTkFq8YRJ7juo9W6iaBpvXic4xlYQZxwOKg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;100&quot;/&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;从中你可以了解如何用强化学习构建一个适应各种不同环境任务的导航系统，制造一个“聪明”的人工小鼠。&lt;/p&gt;

&lt;p&gt;更多阅读&lt;/p&gt;

&lt;p&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651385192&amp;amp;idx=2&amp;amp;sn=40df3b79609f6abe54b60e62148b1c9d&amp;amp;chksm=84f3c329b3844a3fff1c767d53a9934741df23b0b3b740313e09932f364a2fbd98dfd8db1a4b&amp;amp;scene=21#wechat_redirect&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;铁哥知乎live讲座-从导航看AI的未来&lt;/a&gt;&lt;br/&gt;&lt;/p&gt;
&lt;p&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651384652&amp;amp;idx=1&amp;amp;sn=6f9d524b432673822e4c5da4e188522e&amp;amp;chksm=84f3c50db3844c1bb4f6a29b280c517467933c203a4fbeec529f229173e311431944012adc4e&amp;amp;scene=21#wechat_redirect&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;站在AI与神经科学交叉点上的强化学习&lt;/a&gt;&lt;br/&gt;&lt;/p&gt;
&lt;p&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651384881&amp;amp;idx=1&amp;amp;sn=0faf30bbeb5e4f7b386c9ba08aab8ebb&amp;amp;chksm=84f3c270b3844b6636333248db8e75e3e348517bed5ba3ad53851f78e5dd9317a186294a499e&amp;amp;scene=21#wechat_redirect&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;多巴胺引领下的分布式强化学习&lt;/a&gt;&lt;br/&gt;&lt;/p&gt;
</description>
<pubDate>Tue, 24 Mar 2020 03:28:57 +0000</pubDate>
<dc:language>zh-CN</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.jintiankansha.me/t/t3mDMe8GmF</dc:identifier>
</item>
<item>
<title>[原创]不可能三角的种种类比</title>
<link>http://www.jintiankansha.me/t/3k0EpHBODi</link>
<guid isPermaLink="true" >http://www.jintiankansha.me/t/3k0EpHBODi</guid>
<description>&lt;p&gt;国际金融学中的不可能三角指：资本自由流动、汇率稳定和货币政策独立性三者只能选择俩者。&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-ratio=&quot;0.5625&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibceZgS4dszgOag9HQbbUnyg6RDJlicKOVblRoTH5CN0j7omHHGOniaPXfdN7Y0dLF4gC5tGL1OrpK64g/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;960&quot;/&gt;&lt;/p&gt;



&lt;p&gt;上图是好友Justin之前分享过关于管理的一种不可能三角的观点，本文讨论类似的，但更为基础的，也更为本质的不可能三角。&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-ratio=&quot;0.65625&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibceZgS4dszgOag9HQbbUnyg62IMr0mru8OibiaDqnSLOJXE4icMHIK0K1wicPMIO2NhVlwVYKqfc0iaXBWw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;512&quot;/&gt;&lt;/p&gt;
&lt;p&gt;下面是我提出的不可能三角，适合于任何基于预测的场景。&lt;br/&gt;&lt;/p&gt;

&lt;p&gt;1 吸烟导致肺癌，保险公司根据生活习惯就可以提高你的保费，但这是对肺癌成因不完全的解释。吸烟的人会嘴硬说某某没吸烟也得了肺癌，某某天天吸烟咋就没得肺癌，这个预测的问题是假阴性过高；而如果要完全解释肺癌在个体的成因，就需要采集全面的数据，例如基于对肺癌易感性的全基因组关联分析判定先天的肺癌风险，这时最上的那个角就难以满足了；而如果像养生公众号中，发给你各种清肺的菜单，那这样的预测虽然便宜且全面，但假阳性确实太高了。&lt;br/&gt;&lt;/p&gt;

&lt;p&gt;2 随着银行安检系统用上了人脸识别，这些算法的假阳性率都肯定很低，但时不时会发现为何认不出这是我，又叫我眨眼又叫我读数字的，这是目前算法的假阴性率偏高，而随着持续的投入，或者随着手机普遍配上了3D景深摄像头，算法的假阴性率下降，只是此时算法的开发成本，所需的设备成本都不低，不过由于使用人数的增加，对每个用户来说成本很低。&lt;/p&gt;

&lt;p&gt;3 微信群朋友圈会给你提供最及时的信息更新，只是这里的信息假阳性率太高，有不少最终证明是有误的；头条系的信息流推送会免费给你信息，如果你订阅的up主都是相对靠谱的，那信息的假阳性不会高，只是由于echo chamber的原因，你听到的信息都来自你想听到的，即假阴性过高。而若选择了诸如三联财新这样假阴假阳都相对低的信息来源，就不再免费了。&lt;br/&gt;&lt;/p&gt;

&lt;p&gt;4 基于大数据的相关性分析，可以做到很全面（假阴低），但相关不等于因果，因此有很多伪关联，导致假阳高；定向的进行因果性的分析，属于按图索骥，假阳低但假阴性高；而如果对复杂系统中的各个成因都进行因果性的分析，成本又会很高，这是对上述不可能三角的一种解释。&lt;br/&gt;&lt;/p&gt;

&lt;p&gt;5 了解预测领域的不可能三角，意味着所有要做以预测为核心卖点的产品经理，不能什么都要。你可以做高端的产品，又准又全，但相对成本偏高；你也可以做验孕棒一样的产品，很准但可能会漏检；还可以做心理测试型的，成本低且包罗万象，更关键的是即使不准也无关大局。&lt;br/&gt;&lt;/p&gt;

&lt;p&gt;6 对比上述的两个不可能三角，资本自由流动和运行效率高对应预测成本低；安全合规和汇率稳定对应假阳性低，即不会由于预测失效的概率和影响较低；灵活创新和货币政策独立性对应假阴性低，即能够及时的对未来进行预测及基于预测调整自身。&lt;br/&gt;&lt;/p&gt;

&lt;p&gt;7 引申来看，虽然是对真实情况的简化，但也多少反映了真实情况。国家治理中的不可能三角分别是社会平稳运行（预测成本低），贫富分化不造成社会撕裂（假阳性低），持续的创新（假阴性低）；中美欧三大经济体中，一个是维稳成本逐渐升高，一个是中产消失暴民越发激进，一个是缺少创新的旧贵族。&lt;br/&gt;&lt;/p&gt;

&lt;p&gt;8 打破不可能三角的是不去玩这个游戏，换一个新的玩法。例如之前是富人吃牛排，穷人吃红烧牛肉面，结果社会发展了，富人的牛排越来越大，穷人的牛肉面中肉越来越多，导致牛胃产生的甲烷造成全球变暖了（运行成本高），解法不是把富人的牛排店关掉，或者叫穷人重新去吃方便面；而是发明一种好吃健康且不会造成全球变暖的人造牛肉，让穷人富人都爱吃。&lt;/p&gt;

&lt;p&gt;9 从第一性的物理学原理上来讲，预测未来时，假阳性低且假阴性也低的那是拉普拉斯妖，理论上就不可能存在；之所以在相对低的成本，即观测精度低的时候，会出现假阳性（预测失败），是由于混沌系统中的蝴蝶效应；而为何会出现假阴性，则是由于索罗斯提出的反身性造成的，有些最初看起来不可能的事，会变成自我实现的预言，这些最初被我们忽略的可能性，就是在时间有限情况下产生的假阴性。&lt;br/&gt;&lt;/p&gt;

&lt;p&gt;更多阅读&lt;/p&gt;
&lt;p&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651385179&amp;amp;idx=2&amp;amp;sn=be4e6c94c9fc83bfbf7ae8102569eda2&amp;amp;chksm=84f3c31ab3844a0c6ba15bfc3c10fd66ef1383bba956152d454077c4ca1da8342858d11c3736&amp;amp;scene=21#wechat_redirect&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;关于当下时局的一些担心和思考&lt;/a&gt;&lt;br/&gt;&lt;/p&gt;
&lt;p&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651385166&amp;amp;idx=1&amp;amp;sn=760a1fcc8b318f997f24064bf12d35fc&amp;amp;chksm=84f3c30fb3844a19776a89559f5d77580e5a9fef2e04995d1c72bf4590d578d6e0d8719f1533&amp;amp;scene=21#wechat_redirect&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;由石头剪刀布展开的种种类比&lt;/a&gt;&lt;br/&gt;&lt;/p&gt;
&lt;p&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651385144&amp;amp;idx=1&amp;amp;sn=ffef7500b30c96032b6d5fe587735bd0&amp;amp;chksm=84f3c379b3844a6f9f7f3abd3f1c41b57c16b8f1ef3ff50c6ba25ed95c6905e04172ce6e9eaa&amp;amp;scene=21#wechat_redirect&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;樱花，气候，相关性与因果性&lt;/a&gt;&lt;br/&gt;&lt;/p&gt;







</description>
<pubDate>Sun, 22 Mar 2020 01:03:39 +0000</pubDate>
<dc:language>zh-CN</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.jintiankansha.me/t/3k0EpHBODi</dc:identifier>
</item>
<item>
<title>关于当下时局的一些担心和思考</title>
<link>http://www.jintiankansha.me/t/ieuyzUGlFS</link>
<guid isPermaLink="true" >http://www.jintiankansha.me/t/ieuyzUGlFS</guid>
<description>&lt;p&gt;笔者在米国读书三年，现在米国也有很多牵挂于心的好友。大统领的Chinese virus，是一个很危险的预示，第一次担心起在米国朋友的安全。这篇文说说为何我会担心。 &lt;/p&gt;

&lt;section/&gt;
&lt;p&gt;1 生存是文明的第一需要 文明不断发展，但宇宙的资源有限。这是三体中黑暗森林的两条初始公理。这同样适用于疫情，防疫物资有限，国与国之间对检测数据充满了怀疑（猜疑链）再加上疫病的指数级增长。这使得在缺少维持秩序的世界霸主时，国与国之间会按照丛林法则行事。&lt;/p&gt;

&lt;p&gt;2 很多人会想起权力的游戏中的名言：“混乱是阶梯”。但说这句话的小指头四处挑拨离间，最终却什么都没有拿到。决定如何分蛋糕的只是实力。在红方还没有做好准备的时候，全球的混乱会让每个参与者都受到伤害。&lt;/p&gt;

&lt;p&gt;3 疫情让人们面对历史上最大的不平等，即面对死亡的不平等。有钱人能够提早检测，更早的治疗，因此欧美名人检出的概率比国内要高。保护私人权利，再加上人人平等，就如同三体中拒绝逃亡主义那样，大家都不要走，听天由命。但如此谁就需要找一个假想敌，三体二中是ETO，当前就是海外华人。&lt;/p&gt;

&lt;p&gt;4 人类是通过类比和隐喻对事物归类的，具体参考侯士达的《表象与本质》。判断当下的情况，要多看动词，少看形容词，仔细审查名词的文本分析习惯，但预估未来，却最需要关注的形容词，通过将事物归于某个范畴，为将来的行动铺垫民意基础，使其合理化&lt;/p&gt;

&lt;p&gt;5 在一个阶层分化很严重的社会中，底层相比处在转型期的社会，更加被彻底的愚民政策变成巨婴.&lt;/p&gt;

&lt;p&gt;6 一个处在转型期的社会，才会需要英雄。大统领的出现，你可以将其看成是米国底层找到的拯救世界的超级英雄。&lt;br/&gt;&lt;/p&gt;

&lt;p&gt;7 恐惧。排外这种古老的情绪。其传播的速度和强度是指数级的，甚至是超越指数级的，只要有苗头，并且越过了临界点，就能够迅速升级，层层加码。所谓历史中的相变时刻，一去就难以回头。&lt;/p&gt;

&lt;p&gt;8 恐惧主要的来源是不确定性。避免恐惧的只有信息和公开，检测一百例，检出八十例相比检测十万例，检出一万例会激起更多的恐惧，即使暂时数字看起来吓人，但只要到了拐点，就会有希望。因此只要放开检测，才能避免恐惧的蔓延。这时帮助全球，尤其是帮欧美尽快控制住疫情，才能够避免我们这代人经历我们父辈甚至祖辈经历过的苦痛剧情。既然是战争状态，就要少些抱怨，多些节约。&lt;/p&gt;

&lt;p&gt;9 在面对未知情况时，没有人能避免类比。既然用了类比，在不同人看来，就会将其归于不同的范畴。从而形成双标。类比只是用来形成概念的，最终还要进行逻辑推演，就像这篇小文做的。逻辑推演的结论不等同立场，而是超越观点的事实。&lt;br/&gt;&lt;/p&gt;

&lt;p&gt;10 知道事实，尤其是关于未来可能发生什么的推演，但却无能为力去阻止，会让人很痛苦。面对人与人国与国之间的不信任，&lt;span helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; sans=&quot;&quot; gb=&quot;&quot; yahei=&quot;&quot; ui=&quot;&quot; arial=&quot;&quot; sans-serif=&quot;&quot; rgb=&quot;&quot;&gt;面对纳粹与民粹的热血诱惑&lt;/span&gt;，单纯的呼吁不要回答，多少于事无补。而通过游戏，艺术去让&lt;span helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; sans=&quot;&quot; gb=&quot;&quot; yahei=&quot;&quot; ui=&quot;&quot; arial=&quot;&quot; sans-serif=&quot;&quot; rgb=&quot;&quot;&gt;每个人重新注意到基本常识与文明底线，才是更好的解药。虽然这有些理想化，但却是治本之道。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;更多阅读&lt;br/&gt;&lt;/p&gt;

&lt;p&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651385144&amp;amp;idx=1&amp;amp;sn=ffef7500b30c96032b6d5fe587735bd0&amp;amp;chksm=84f3c379b3844a6f9f7f3abd3f1c41b57c16b8f1ef3ff50c6ba25ed95c6905e04172ce6e9eaa&amp;amp;scene=21#wechat_redirect&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;樱花，气候，相关性与因果性&lt;/a&gt;&lt;br/&gt;&lt;/p&gt;
&lt;p&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651384904&amp;amp;idx=1&amp;amp;sn=9179d9154ce0a915c9300fa798a6c068&amp;amp;chksm=84f3c209b3844b1f893da5fc2293cac60399c12702dec949553f2c0010eac0f59bf73056d8d6&amp;amp;scene=21#wechat_redirect&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;keep calm and carry on 共度国难应有的态度&lt;/a&gt;&lt;br/&gt;&lt;/p&gt;
&lt;p&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651384908&amp;amp;idx=1&amp;amp;sn=a86322895d71c94eaab7c60227cacccc&amp;amp;chksm=84f3c20db3844b1b00dfeffd1156209d56b40dd94d1adde2be151f5fdf202c0abfd88b559997&amp;amp;scene=21#wechat_redirect&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;抗疫期间的反思&lt;/a&gt;&lt;br/&gt;&lt;/p&gt;
</description>
<pubDate>Fri, 20 Mar 2020 05:03:05 +0000</pubDate>
<dc:language>zh-CN</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.jintiankansha.me/t/ieuyzUGlFS</dc:identifier>
</item>
</channel>
</rss>