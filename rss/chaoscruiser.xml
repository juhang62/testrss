<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="css/feed.xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/" xmlns:og="http://ogp.me/ns#">
<channel>
<atom:link rel="self" href="http://192.168.1.4/fivefilters/makefulltextfeed.php?url=feed43.com%2Fchaoscruiser-jtks.xml&amp;max=5&amp;links=preserve&amp;exc=1" />
<atom:link rel="alternate" title="Source URL" href="http://feed43.com/chaoscruiser-jtks.xml" />
<atom:link rel="related" title="Subscribe to feed" href="http://www.subtome.com/#/subscribe?feeds=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed43.com%252Fchaoscruiser-jtks.xml%26max%3D5%26links%3Dpreserve%26exc%3D1&amp;back=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed43.com%252Fchaoscruiser-jtks.xml%26max%3D5%26links%3Dpreserve%26exc%3D1" />
<title>混沌巡洋舰</title>
<link>http://www.jintiankansha.me/column/ultiWL8Axg</link>
<description>混沌巡洋舰 - 今天看啥</description>
<ttl>360</ttl>
<item>
<title>类脑计算背后的计算神经科学框架</title>
<link>http://www.jintiankansha.me/t/vxIBUoMiXU</link>
<guid isPermaLink="true" >http://www.jintiankansha.me/t/vxIBUoMiXU</guid>
<description>&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;类脑计算， 是一个新兴的名词， 其实换一个名字， 就是我之前研究的计算神经科学。&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;大家了解人工智能， 而不了解计算神经科学， 事实上两者的关系就是一颗硬币的两面。&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;这枚硬币就是智能算法本身。宇宙中产生智能的过程， 孕育了生物智能， 我们取其道行之， 得到人工智能。而从生物的神经系统取出这个算法的过程， 就是计算神经科学。&lt;/p&gt;
&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibccts2GdPDN5kPZiaKPh2I56p6fSCOUcXSn9B7KumHb0Cc8WKBCZSeC9cdn5xicSW9L9O4LJFmpN1KbA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;640&quot; width=&quot;640&quot;/&gt;&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;计算神经科学有两个使命，一个是直接解决生命智能有关的问题， 如困扰我们的心理疾病， 器质性的神经退行性疾病如老年痴呆。因为你只有懂得了算法出现问题的原因， 才能去修正它。&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;另一方面，计算神经科学得到的启发可以直接用于人工智能， 好比一个蓄水池， 它的水位足够高， 就可以流出一部分做人工智能算法的应用。当下的AI的核心重磅RNN和CNN，都和8，90年代这个算法的积累有关。&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;计算神经科学的算法和人工智能算法的本质不同在于计算神经科学考虑生物细节的影响，试图解释生物现象， 而人工智能把这条缰绳脱去了。而这条缰绳是否有意义也是计算神经科学的热点问题。&lt;/p&gt;
&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibccts2GdPDN5kPZiaKPh2I56p1icL6H5lWeZKfqhc3Y8LCIQJ0MrnwuyUjVhMnTCOfWrFibWPqqRiboqkQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;640&quot; width=&quot;640&quot;/&gt;&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;研究计算神经科学的方法我们可以总结一种层级型的思维方法。因为计算神经科学本质是一个桥梁学科。它连接了从最基本的生物物理层级， 到神经回路（网络）， 然后大尺度神经回路基础上涌现的动力系统，以及动力系统所carry的信息流， 而在信息尺度之上， 我们得到计算，或者算法本身， 在此基础上得到功能， 得到多种多样的心智现象， 这也就是最高层级。&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;&lt;span&gt;一 生物物理层次&lt;/span&gt;&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;最低层级的现象往往可以由生化实验所测量， 最高层级就是心理学或认知科学， 可以由心理实验测量。中间的那些层次生物神经科学家通过各种各种的成像记录间接获得。而这些层次间的联系就是计算神经科学。&lt;/p&gt;
&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibccts2GdPDN5kPZiaKPh2I56po3Mvq6XNocWFtLVamQ4DvRLCAfOToKx9NwgDLN7qpLeFRBM7XugLTQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;640&quot; width=&quot;640&quot;/&gt;&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;计算神经科学与人工智能的载体均是神经网络， 但是两者既有联系又有区别。这种区别主要体现在计算神经科学的神经网络试图用最简单的模型获取最多的生物真实性， 而AI的神经网络试图这种简化模型进一步工程化标准化最大化其功能。具体的区分度， 又在于神经元的细节， 连接懂得细节， 以及学习本身。&lt;/p&gt;
&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.737012987012987&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibccts2GdPDN5kPZiaKPh2I56pE5rrduLwkYFLND0bcvy6H0gzFZR8B3PsBkQjibhNFZ0qUanA074ZJAg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;616&quot; width=&quot;616&quot;/&gt;&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;生物神经细胞本身其实极为复杂， 一个细胞甚至堪比一个神经网络。树突收集信息， 胞体做出决策， 传递到轴突。&lt;/p&gt;
&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibccts2GdPDN5kPZiaKPh2I56pDRJ4FwpicCBYibjpVP3nicuydd2ddX0EgTA9AueVCT7icicWeNibn5kxcRaw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;640&quot; width=&quot;640&quot;/&gt;&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;Spike，神经元尖峰放电是生物神经网络的信息货币（bit），放电是一个典型的物理化学过程， 当输入超过某个阈值，细胞膜内外的钠离子和钾离子相继发放，引起一个由正反馈到负反馈主宰的过程， 由Hodykin Huxley 方程描述。&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;Häusser, Michael. &quot;The Hodgkin-Huxley theory of the action potential.&quot;&lt;em&gt;nature neuroscience&lt;/em&gt;3.11 (2000): 1165.&lt;/p&gt;
&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.48055555555555557&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibccts2GdPDN5kPZiaKPh2I56pgCTvCqEfX4E99JavBAILmsDkmr7E1FrIL88SNibUak7Yj4KvjHxepfA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;720&quot; width=&quot;822&quot;/&gt;&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;连续的尖峰放电把一个直流输入转化成脉冲输出 ， 这个脉冲频率由直流输入大小决定， 对外表现为脑电波。如我们数值的alpha或gamma波。&lt;/p&gt;
&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibccts2GdPDN5kPZiaKPh2I56poUJAq3Gcysuiagw4qicqgxUaY8R4ibY8vkRcKzrmw7Q92liaR8CpHW1GyA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;640&quot; width=&quot;640&quot;/&gt;&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;把脉冲神经元放在一起组成脉冲神经网络。&lt;/p&gt;
&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibccts2GdPDN5kPZiaKPh2I56pnKBJk0vJe1ZxxvVCUib2y6oWj5R7VS7NxNEhgwdjWOL7LJPdQeiaZ5Ag/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;640&quot; width=&quot;640&quot;/&gt;&lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;/&gt; &lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot;&gt;&lt;span&gt;这个步骤如何做一个大&lt;/span&gt;刀&lt;span&gt;阔斧的简化呢？&lt;/span&gt;&lt;span&gt;我们把单位时间窗口的输出spike个数简化为发放率， 刚刚说脉冲神经元的输入和输出是简单线性的， 那么这个线性关系被以上方程概括。&lt;/span&gt;&lt;span&gt;w描述每个神经树突对信息的敏感性。&lt;/span&gt;&lt;/p&gt;
&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibccts2GdPDN5kPZiaKPh2I56pMy1x1HqxycqTxuQQpxXVfLyDO5TjW05yCBnibl73RFRKJVggBTiazr6w/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;640&quot; width=&quot;640&quot;/&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;而神经脉冲那种输入超过阈值则引起正反馈的性质被一个非线性的门函数概括， 它可以是我们们熟悉的relu，sigmoid。&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;生物脉冲神经元和这种经过简化的实数神经元到底有何不同？　同样是前馈网络，脉冲神经元构成的网络，由于尖峰脉冲的时间结构， 它的发放可以携带和时间有关的信息，是当下的深度学习所使用的rate神经元不具备的。同时，不同尖峰脉冲神经元发放间的correlation 被认为可以编码信息。而脉冲神经元和rate数值神经元到底有无本质区别， 也成为各种学派的争论焦点。&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;&lt;span&gt;二 学习和网络架构层次&lt;/span&gt;&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;&lt;span&gt;1， 生物学习vs机器学习&lt;/span&gt;&lt;/p&gt;
&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibccts2GdPDN5kPZiaKPh2I56px8O4sqW3wCvxaUjjd6c2pA7g4U7ccs3LHHibsvXbLs9OTA001Ge64HQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;640&quot; width=&quot;640&quot;/&gt;&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;生物学习和机器学习的比较：同为学习， 生物学习和机器学习的本质相同而形式迥异。所谓本质相同， 它们都是输出导致的对自身的反馈， 且这种反馈的方向使得总体的信息增加而熵减少。&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;这就决定了，学习的过程需要的是输出的结果，被一个函数衡量， 作用到信息流动的载体，神经网络里， 使得新的输出向着某个确定方向变化 。&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;如果从一个较大的尺度看生物学习， 那么大部分的学习实质上是“进化” 。因为我们先天的已经具备大量的学习能力， 比如先验的语言能力（乔姆斯基）。而真正通过生物后天学习可以得到的， 反而是一小部分内容。&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;如果但看学习， 生物学习的关键词是Hebian学习， 神经可塑性和强化学习， 而机器学习是监督学习， 非监督学习和强化学习。&lt;/p&gt;
&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibccts2GdPDN5kPZiaKPh2I56pXw7s8gRWaeLKwEI7hBOF9JicRoe7RIIzicWtacw37GT0cQyAibGXyXzibA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;640&quot; width=&quot;640&quot;/&gt;&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;机器学习的基础是监督学习。这个对输出的度量由一个绝对真理的代表-导师提供，与它不匹配的时候， 一个错误信号向整个网络传递， 而最终网络结构向着减少这个错误的方向改变。&lt;/p&gt;
&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibccts2GdPDN5kPZiaKPh2I56pOxFia4qgOjHE12lO7cRa0XVoPRdzsAt9Z1VC7ia0ibbVJX1TysAvzWd3g/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;640&quot; width=&quot;640&quot;/&gt;&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot;&gt;&lt;span&gt;而生物学习的基础是无监督学习。它本质所&lt;/span&gt;做&lt;span&gt;的工作是相似度匹配。&lt;/span&gt;&lt;/p&gt;
&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibccts2GdPDN5kPZiaKPh2I56pqyiceDBCRib7RMmMy96EQ5sHy2Mrnmcs49FOlN5hE4jND1CKLqkibcdeA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;640&quot; width=&quot;640&quot;/&gt;&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;这种学习的基础正是著名的赫布法则， 它说的是当一个上游神经元可以引发下游神经元的放电， 它们的加强就会增强。&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;“Hebb suggested that such synaptic modification could produce neuronal&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;assemblies that reflect the relationships experienced during training.&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;For example, consider applying this rule to neurons that fire together during training&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;due to an association between a stimulus and a response. These neurons&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;would develop strong interconnections, and subsequent activation&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;of some of them by the stimulus could produce the synaptic drive needed&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;to activate the remaining neurons and generate the associated response.&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;赫布法则导致的一个直接结果是神经元集团的生成，对应一个经常一起发生的事件序列进行反应。这其实就是在挖掘事件间的相关性。把这种相关性学习直接写成数学公式， 我们会发现这种学习的效果类似PCA主成分分析，也就是通过学习神经元集团掌握了数据样例间的共同特征（oja's law），而不同的“相关特征组”就可能是概念形成的基础 。&lt;/p&gt;
&lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;/&gt; &lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibccts2GdPDN5kPZiaKPh2I56pCvBddAvwvVQiamicAIGg2KbWibibkUiaOlB9IEodpj3dQcX9v19GVev7j5Q/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;640&quot; width=&quot;640&quot;/&gt;&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibccts2GdPDN5kPZiaKPh2I56pcLydWv0thVj9vZqNgXR3esITyq0ibyyYFFJgkh7dUzt4XdtvCGhgkUA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;640&quot; width=&quot;640&quot;/&gt;&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;把上面的想法变成一个非常典型的例子， 通过无监督学习， 神经网络可以特征的共同出现（假设我们具有一组分别感受颜色和形状的细胞， 那么红色和圆形， 或者黄色和长形对应苹果和香蕉两个共同概念）来学习苹果和香蕉的概念。&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;那么通过这样的学习能否得到丰富复杂的生物大脑模型呢？答案是否定的， 因为生物的多样性建立在复杂的进化历程基础上， 这种长期与环境交互的“学习”被写在基因里 。这种进化的复杂性表现在神经元的种类， 网络的拓扑结构， 全脑连接等等因素上， 即使如此，我们可以发现不同神经网络的共性， 比如多层级结构(hierarchy structure)， 小世界网络(small world networks)， 兴奋抑制平衡(Dale Principle balanced network)等， 它们可能反应了神经网络的共同原则。同时我们可以通过这些原则给AI设计人工神经网络。&lt;/p&gt;
&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibccts2GdPDN5kPZiaKPh2I56p68KynrJMmTCBShy3HCtV7skecLA8dzBuk11tibEHvQibf3Kfnbe4PeoA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;640&quot; width=&quot;640&quot;/&gt;&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibccts2GdPDN5kPZiaKPh2I56ppJSAVwdMXMb2Nd18x2PyoibxnoibRHopbM6A4jTlHtItcm4uAWgF9Qyg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;640&quot; width=&quot;640&quot;/&gt;&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;目前我们对这些共同原则知之甚少， 比较程序的框架有efficient coding， sparse coding 或者 predictive coding。它们都处在我们下面要讲的编码层次。&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;&lt;span&gt;三 大脑信息编码层次&lt;/span&gt;&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;有了学习和通过进化与学习得到的结构，下一个level就是编码， 编码又分为大脑神经网络的编码和解码。这个层次的本质是信息的流动， 外界刺激需要通过编码被内在神经活动加载， 而后面内在神经活动需要通过解码等转化为肌肉的运动和语言等。&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;让我们来具体看几个生物计算系统的案例；　&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;１，　视网膜，　一个人们研究极为透彻的系统。　　&lt;/p&gt;
&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibccts2GdPDN5kPZiaKPh2I56pcvGvVXEVbR7cycfIyG7mqgTtvkbwmlhIsSxdlVcDQc1XibeNZHHhVQw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;640&quot; width=&quot;640&quot;/&gt;&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;视网膜看似如同照相机的ccd，　事实上确是一个非常核心的计算单元。视网膜其实是一个类似ＣＮＮ的典型多层神经网络。从最底层的感受色彩的像素，然后对物体的边缘进行对比度分析提出边缘，最终还可以对运动方向等一些信号进行处理（ganglia cells）。　视网膜是视觉神经编码的开始， 关于视网膜计算的根本编码原理被称为&lt;span&gt;efficient coding&lt;/span&gt;框架。这个框架说神经编码的根本在于maximize mutual information with input（增大神经活动与外部信号的互信息）， 的方向尽可能减少冗余的发放达到节能的目的。根据这个原则，我们可以理解视网膜编码对某些色彩或运动方向（如水平， 竖直方向）的编码精确度高于其它色彩或方向。&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;Barlow, Horace B. &quot;Possible principles underlying the transformation of sensory messages.&quot;&lt;em&gt;Sensory communication&lt;/em&gt;1 (1961): 217-234.&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;２，视觉皮层回路&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;视网膜之后， 主要的视觉运算在视皮层内进行， 与视网膜不同的是， 视皮层的运算需要涉及到视觉概念的处理。&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;不用多说， 视觉皮层回路的研究来是计算神经科学和人工智能的交叉点， 早期对视觉皮层的研究工作启发了CNN的工作（Witz）， 而当下的CNN则已经是计算神经科学经常用的工具。&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;CNN用到的大脑视觉编码处理原理称为层级编码， 用这个方法我们把可以把信息表征成从低级到高级的组合形式， 从而高效的表达概念， 如下图的桌子和祖母细胞的例子。&lt;/p&gt;
&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;http://img2.jintiankansha.me/get?&quot;/&gt;</description>
<pubDate>Thu, 17 Oct 2019 01:02:49 +0000</pubDate>
<dc:language>zh-CN</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.jintiankansha.me/t/vxIBUoMiXU</dc:identifier>
</item>
<item>
<title>那样的话，我们就会在宇宙中真正获得家的感觉-读《生命与新物理学》</title>
<link>http://www.jintiankansha.me/t/IlpqHDL4tz</link>
<guid isPermaLink="true" >http://www.jintiankansha.me/t/IlpqHDL4tz</guid>
<description>&lt;p&gt;&lt;br /&gt;Paul Davies是理论物理学家，也是一位极好的科普作家。读中学的时候，就被图书馆中霸气的书名《上帝和新物理学》吸引，翻看过这本书。而他在19年2月新出的书英文名叫“The demon in the machine”，中信的翻译版起名为《生命与新物理学》。这篇读书笔记的题目来自于该书的最后一句话，点名了全书的主旨。&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;1.45875&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcfcWKXE3rsMt3q6l8fxHPib0rZIj6qQ6nNPicIxrNeTOunYpQHhvLu4TCJkeMD9H6EAeEpAt5uetWzg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;800&quot; /&gt;&lt;/p&gt;

&lt;p&gt;生命能用物理学解释吗？现有的物理学能否用来解释生命，还是需要或者已经产生了新的物理学，用以解释生命？这是整本书都在回答的问题。也对应中文题目中的新物理学，而英文标题中的demon指的是热力学中的麦克斯韦妖，一个出现在思想实验中的对当下每个分子状态都知晓的，能够利用信息逆转时间箭头的怪物，通过英文的标题，作者点出连接物理学和生物学之间的桥梁在于信息。&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;在三体死神永生的后半部分，有一段读起来令人有些后怕的对话，来自小说中的物理学大神丁仪和他的学生，丁仪这段话的主旨是“生命对物理学是一种干扰”。他问学生“假设一切都是决定论的，知道初始条件就可以计算出以后任何时间断面的状态，假如有一个外星科学家，给它地球在几十亿年前的所有初始数据，它能通过计算预测出今天这片沙漠的存在吗？”学生对这个问题的答案是“当然不能，因为这沙漠的存在不是地球自然演化的结果，沙漠化是人类文明造成的，文明的行为很难用物理规律把握吧。”接下来的对话，导出的结论是无法仅仅通过物理学，来预测一个诞生了生命的宇宙会发生什么，生命的诞生会改变宇宙规律。而小说中接下来的情节，就是生命如何改造了宇宙规律（太阳系二维化）。&lt;/p&gt;

&lt;p&gt;将物理学和生物学的研究范围切开，如同笛卡尔时代认为身心是二元的。在这样的假设下，生命的出现就如同一个偶然，好比你不知怎么的中了彩票，栖身上流社会，但却无法从中找到家的感觉。但如果宇宙的规律预示着其有利于形成广泛的复杂信息处理系统，而生命真是这种系统的典型代表，那么就预示着生命的起源不具有特殊性，宇宙是生命友好的。这让我想起一句话“来了就是深圳人”。生命能否用物理学解释这个问题的回答，如果是肯定的，读者就不必担心三体中描述的末日场景，而可以安心的在这个宇宙间生活。&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;但不可否认的是，生命开辟了非生物系统无法进入的“可能性空间”。《生命和新物理学》这本书这样写道：生命的游戏必定会被视为一种规则随时间变化的主观体验性游戏。书中将生命比做一盘象棋，但其规则会改变，而物理学要做的是解释这些改变规则的规则（元规则）。而随状态函数改变的法则，是对自我指涉的一种概述。例如生物体内的DNA，在生命复制时，是硬件，是复杂用的模板，而在同时，又是软件，编码了如何让自身得以复制的信息，何时是软件，何时是硬件，这需要根据环境来决定。而随着系统的时间演变，复制的内容，与复制的方式都会改变。从计算机的角度来看，物理世界程序和数据是分开的，但在生物世界，程序和数据是不可分的。&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;从宏观来看，生命和非生命泾渭分明，但到了微观层面，俩者又都是由同样的基本粒子组成的，因此要解释生命，就需要在中尺度结构（meso-scale）展开，而这也是生物信息学，生物物理等新兴的交叉学科所关注的。把生命的运作看成是信息的交换，把生命的演化看成是环境如何改变生命复制自身的程序，从而影响被复制的数据。本书前4章集中讨论的是如何用信息的视角去研究生命现象，从而打破物理学解释和生物现象之间的鸿沟，主线是上述的逻辑，后三章分别讨论了量子现象在生命中的应用，生命的起源及意识和自由意志的问题。&lt;/p&gt;

&lt;p&gt;在讨论意识时，作者对朱利奥•托诺尼的Phi的解释给出了极为形象的类比，想象一个20名成员组成的委员会，负责评选年度的大奖。对外来看，这是一个黑箱，但如果从内部来看，如果成员是彼此独立且未经协商的，那么这个系统的Phi值就为0，但如果存在着派系，成员们的决策相互制约，那么就可以用Phi值来计算系统的集成度，当委员之间进行了广泛的内部交流，之后做出了一致的决定，那么这时系统的Phi值就最大，而如果某个成员只是速记员，那么委员会的Phi值就会降低，因为它不是完全集成的。Phi的大小，本来是用来衡量意识的，信息处理系统的集成度越高，Phi值越高，越具有意识。通读全书之后，我意识到Phi值计算背后的假设，也适用于生命的其他尺度上，对应的例子来自书中关于癌症的论述，也是令我印象深刻的一段。&lt;/p&gt;

&lt;p&gt;基因突变通常认为是随机发生的，但基因组上的有些区域，是更容易突变的，有些地方的突变，则不太可能在下一代出现。之所以会这样，是由于复杂的多细胞生物，像操作系统一样，需要一个安全模式，越是古老的，越要保留，从而在遭到危险时回到原初状态。而癌细胞，正是这样一种原始的细胞防御机制，这个观点和之前把癌细胞看成是逃逸了监管的突变细胞不同。前者指出癌症是在外界坏境触发下，引起的自我驱动走向细胞的默认状态，而后者则认为是外界的刺激带来了癌症。而当癌细胞从受控的状态变成如同单细胞生物一样，只“关心”如何增值的时候，就会导致整个系统的整合程度降低，类比对意识的度量Phi，癌细胞就是前文中提到的那个变成了速记员的评奖委员，没有参与对生物体整体的信息交流。&lt;/p&gt;

&lt;p&gt;对癌症起源的认识，对癌症的诊断和治疗都有意义。癌细胞特有的信息处理特征，有潜力让人们在细胞和组织形态的临床变化之前，提前发现；而意识到癌症本质上是多细胞生命诞生的逻辑必然，就应该通过维持避免让细胞陷入返祖的生活方式的物质条件来向癌症发起挑战，以期管理和控制，而不是完全消除癌症。&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;总结来看，本书（按原文书名）告诉读者，必须把信息这个要素带入生命研究当中，至于如何解开生命之谜，他提出的问题远比回答的问题要多。书中指出的方向（系统生物学）进展迅速，其中很多研究成果的影响不止停留在实验室中，还会如同进化论一般，对每个人的思考方式产生巨大影响（例如社会达尔文主义），而这本读起来轻松有趣的书，将带你了进入这个将会影响我们每个人的变革。&lt;/p&gt;

&lt;p&gt;更多阅读&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651384611&amp;amp;idx=1&amp;amp;sn=e38249770191c24a2beec48cf0161054&amp;amp;chksm=84f3c562b3844c7419a4859afaec690b3c0e1ea05b1ddc5d5d68db4f83835dc6a3449e48a3c5&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-itemshowtype=&quot;0&quot; data-linktype=&quot;2&quot;&gt;不同领域的相通的创新之道-读《Life finds a way》&lt;/a&gt;&lt;br /&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651383691&amp;amp;idx=1&amp;amp;sn=c3eec0a6581f4d995b2b720deefa3f05&amp;amp;chksm=84f3c9cab38440dc4322b5a9c9c1b4b608b1c1ee4437f6098e8b83a908a66940500a2d61ff5b&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-itemshowtype=&quot;0&quot; data-linktype=&quot;2&quot;&gt;进化如何可能-读《适者降临》&lt;/a&gt;&lt;/p&gt;

</description>
<pubDate>Thu, 17 Oct 2019 01:02:47 +0000</pubDate>
<dc:language>zh-CN</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.jintiankansha.me/t/IlpqHDL4tz</dc:identifier>
</item>
</channel>
</rss>