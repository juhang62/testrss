<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="css/feed.xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/" xmlns:og="http://ogp.me/ns#">
<channel>
<atom:link rel="self" href="http://192.168.1.4/fivefilters/makefulltextfeed.php?url=feed43.com%2Fchaoscruiser-jtks.xml&amp;max=5&amp;links=preserve&amp;exc=1" />
<atom:link rel="alternate" title="Source URL" href="http://feed43.com/chaoscruiser-jtks.xml" />
<atom:link rel="related" title="Subscribe to feed" href="http://www.subtome.com/#/subscribe?feeds=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed43.com%252Fchaoscruiser-jtks.xml%26max%3D5%26links%3Dpreserve%26exc%3D1&amp;back=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed43.com%252Fchaoscruiser-jtks.xml%26max%3D5%26links%3Dpreserve%26exc%3D1" />
<title>混沌巡洋舰</title>
<link>http://www.jintiankansha.me/column/ultiWL8Axg</link>
<description>混沌巡洋舰 - 今天看啥</description>
<ttl>360</ttl>
<item>
<title>大脑的自由能假说-兼论认知科学与机器学习</title>
<link>http://www.jintiankansha.me/t/94BvzOP4G6</link>
<guid isPermaLink="true" >http://www.jintiankansha.me/t/94BvzOP4G6</guid>
<description>&lt;p&gt;如果大脑如何运作的机理可以和热力学一样系统完整完美解释， 那这个理论将是物理学家的终究梦想。而有一篇神文险些胜利。这套理论可以叫自由能大法，如果你通读此文， 也会感觉到一种脑科学， 人工智能， 物理学， 甚至经济学都打通的感觉，然而， 估计99%的物理系读者都很难读通此文（The free-energy principle: a unified brain theory）&lt;/p&gt;

&lt;p&gt;什么是物理里的自由能法则？  一句话说就是：  &lt;strong&gt;任何处于平衡状态的自组织系统均趋于自由能极小的状态。&lt;/strong&gt; 这话是什么意思？ 自由能又是什么？  自由能和大脑有啥关系？&lt;/p&gt;

&lt;p&gt;自由能是什么？ 自由能的物理公司E-TS极为简洁，E是能量 ，S是熵。 统计物理说， 与外界具备能量交换的系统（一杯放在桌上的热水，底下放着一块冰糖）处于平衡状态下，则自由能最小（水温下降，冰糖扩散）， 指的是一个能量尽可能小熵尽可能大的状态。 当水温下降到室温， 冰糖均匀扩算， 此时水分子和外界环境的整体所能够取得的微观状态数最多， 也就是最大概然状态，或者说稳态。好比一个教室里没有老师，学生就逐渐的变得乱遭遭的，这个乱遭遭的状态就是稳态。 自由能最小是热力学第二定律下系统与外界环境相互作用的法则。&lt;/p&gt;

&lt;p&gt;生物系统呢？ 生物系统和水这种系统恰好相反，因为它们是开放的非平衡耗散系统，它们所遵守的法则是趋于有序和结构确定的状态， 相当于一个严厉的老师管制下的教室， 同学工作井井有条（这样的状态需要外界输送能量，如老师的工资）。所以我们经常说生物遵守反方向的热力学第二定律-即产生和维持秩序，而紧闭大多数自由状态。 如果某个时刻你开始控制不住自己， 那也就是衰老的起点。&lt;strong&gt;刚刚好，生物系统也可以被一个形式类型自由能最小的定律结合。表现在认知系统，就是学习过程！ 你读过之后就会立刻发现它和机器学习的联系。  &lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt; &lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;简单的看，你可以把你的脑子想成刚才说的那杯水，外部环境和这杯水具有一种能量交互关系，正好对应你的脑子通过眼睛和耳朵这样的东西采集外部的信息（感知）。这杯水会越来越趋于室温， 你的脑子像这杯水一样与外界交换能量和信息， &lt;strong&gt;只是， 这个过程中，你的脑子对外界的信息越来越丰富， 它不仅是被动的采纳，还要主动的预测和做出行为。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;那么看看我们通常说的大脑对外界信息处理过程包含以下几个方面，感知（sensation）决定计入哪些数据， &lt;strong&gt;cognition&lt;/strong&gt;（认知）对这些数据进行处理如分类， &lt;strong&gt;action&lt;/strong&gt;（行为）一个由&lt;strong&gt;cognition&lt;/strong&gt;的分类导致的决策， &lt;strong&gt;motion&lt;/strong&gt;（运动），一系列的行为组成motion。&lt;/p&gt;

&lt;p&gt;我们来看看这个过程是怎么发生的。 首先， 这一切行为的综治是为了&lt;strong&gt;最大化生存可能性&lt;/strong&gt;（maximize existence）， 外部世界充满危险， 如果把生物所有的行为可能性做成一个状态空间， 那么只有极少数是可以保证生存的， 生物越能够绑定在这极少数状态里， 生存机会就越大， 这也是生物需要抵抗热力学第二定律的理由。那么如何不跑偏呢？&lt;/p&gt;

&lt;p&gt;一方面我们有&lt;strong&gt;基因编码&lt;/strong&gt;（genetic encoding），使得我么的&lt;strong&gt;表现型&lt;/strong&gt;（phenotype）只能在一个有限的范围里（由一个条件概率函数P(pIg) 描述），这套编码已经在我们的祖辈自然选择里被遗传下来，去掉了大部分不适宜生存的可能， 比如长出三头六臂。&lt;/p&gt;

&lt;p&gt;另一方面，作为具有认知能力的动物，能够保证对生存最有利的状态的办法就是学习，整个对大脑外界信号的处理都可以通过&quot;学习”来认识， 请看下图（请始终想着&lt;strong&gt;机器学习&lt;/strong&gt;）。&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;origin_image zh-lightbox-thumb&quot; data-ratio=&quot;1.3583333333333334&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcdmt7U3YGvq0BYUCp5icmmgaRC6jiaibSE5gVBKV3TSImUHWkxAN9GdaZ04neoGN4IRibMN0W8JgEZycA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;600&quot; width=&quot;958&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;大脑的自由能最小定律说， 学习的状态就是使得 1，通过不断调整行为得到符合大脑预期的感知状态（Accuracy）  2， 大脑内部的状态能够更加准确的匹配外部世界的变化 ，不至于出现没有预期到的状况（Divergence）。&lt;/strong&gt; 两部分何在一起使得上图定义的大脑的自由能函数最小。这个原则的威力是巨大的， 它可以告诉你如此多你为什么要这么想， 这么看，尽管你平时从未知觉。 比如为什么你看到你想看的， 为什么你想到的东西又总在随时客观情景调整。&lt;/p&gt;

&lt;p&gt;注： 第一项D中p是已知生物的感知得到某种外部世界状态的概率， q是已知大脑内部状态生物猜测到某外部世界状态的概率 ， D是p和q两个概率分布函数的距离， 指的是大脑猜测的真实之间的距离。 第二项是对数项内的p是已知外部世界的变化得到某种感知状态的概率。&lt;/p&gt;

&lt;p&gt;外界的信息是无穷多的，我们的脑子就那么多， 选择哪些信息录入，就显得特别重要。 感知的过程， 就是一个数据采样的过程， 机器学习的同学都知道， 开始录入什么样的特征对机器学习是具有决定性的一步，而感知也一样， 生物要做到的是要取样哪些数据。 所以感知绝非被动的过程。&lt;/p&gt;

&lt;p&gt;这里的关键是要把&lt;strong&gt;感知&lt;/strong&gt;，认知和行为放在一个循环里理解。这里理解的框架就是&lt;strong&gt;贝叶斯决策&lt;/strong&gt;。贝叶斯公式把事物之间的联系表现为一系列的条件概率关系， 并根据新的证据不停调整条件概率，最终我们要优化我们想得到的结果， 比如此处的生存机会， 就是通常生物系统优化的量， 为了优化生存机会，我们只有少数几个想要达到的结果， 我们需要产生一个使得这一系列结果机会最大的决策机制（所谓我们不是为思考而思考，而是为生存而思考）， 这一切决定了感知和认知的过程。&lt;/p&gt;

&lt;p&gt;那么我们是如何通过学习来找到这个机制的呢？ 其实你会发现，这就是一个模型选择过程&lt;strong&gt;（model selection）&lt;/strong&gt;恰恰符合机器学习的本质。所谓认知，即找到一个预测性模型使得感知得到的信号可以预测出未来外界物体的运动， 从而趋利避害。 所谓感知，就是寻找最能够提供给这一模型预测效力的有用证据&lt;strong&gt;（feature engineering）&lt;/strong&gt;。一句话说，世界很大， 我只要最和我的游戏相关的。&lt;/p&gt;

&lt;p&gt;那么行为呢？ 我们的行为最终还是要归之于感官，所谓人生食色性也。行为如果带来香甜的巧克力或可爱的美女，则得到嘉奖，这是符合你的理想的生存预期的。一个非常有趣的例子说明认知模型：一个黑暗里摸索的人， 他不停猜测前面是什么， 它会主动伸手去摸索，证实他的想法，一般如果我们发现我们的证实与内心的想法不符，则不停探索，知道符合它的预期，这就是一个简单的认知模型。&lt;/p&gt;

&lt;p&gt;这里面我们看到认知模型包含两方面， 一个是感知和行为所获取的外部世界的状态， 一个是大脑内部认知过程的内部状态（模型）。 这个内部模型不停预测每个一个感官背后的动因， 和所蕴含的未来变化， 而行为本身则趋向于那些有利生存的结果。学习的目的就是让那么内部状态的模型更准确（预测精准），另一方面让行为决策获取更多对生存有利的证据。   如果模型的预测不正确， 则行为决策无法得到正确的结果。&lt;/p&gt;

&lt;p&gt;这一原则所得到的启示十分强大，可以直接打通认知科学和机器学习的诸多方面：&lt;/p&gt;

&lt;p&gt;1， &lt;strong&gt;贝叶斯大脑假设&lt;/strong&gt;： 如之前提到的， 大脑是部贝叶斯机器。 贝叶斯推断和决策的核心即由最新采纳的证据更新先验概率得到后验概率。 认知科学的核心（&lt;strong&gt;Perception&lt;/strong&gt;）就是这样一个过程。&lt;/p&gt;

&lt;p&gt;这里再说两句认知，认知的过程用机器学习的语言说就是用大脑的内部变量来模拟外部世界， 并希望建立内部世界和外部的一个一一映射关系。 这里我们说认知的模型是一个概率模型，并且可以被一系列条件概率所描述。如果用一个形象的比喻来说， 你可以把你的大脑看成一个可以自由打隔断的巨大仓库， 你要把外部世界不同种类的货放进不同的隔断，你的大脑内部运作要有一种对外界真实变化的推测演绎能力， 即随时根据新的证据调整的能力， 你和外界世界的模型匹配的越好， 你的脑子就运转越有效率。 认知是对外部世界运动的一种编码， 你可以立刻联想到机器学习里的表征方法（&lt;strong&gt;representation&lt;/strong&gt;）， 如果你熟悉RNN或CNN的embeding过程， 就会有一种豁然开朗的感觉， 虽然一时并不知有鸟用。&lt;/p&gt;

&lt;p&gt;更多阅读&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651381942&amp;amp;idx=1&amp;amp;sn=c29a10c721f319546c503c954c8e4f21&amp;amp;chksm=84f3cef7b38447e151560d9b2f80bf1f1bc912911842428a7cd8d6928114a0f47b05fe899188&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data_ue_src=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651381942&amp;amp;idx=1&amp;amp;sn=c29a10c721f319546c503c954c8e4f21&amp;amp;chksm=84f3cef7b38447e151560d9b2f80bf1f1bc912911842428a7cd8d6928114a0f47b05fe899188&amp;amp;scene=21#wechat_redirect&quot;&gt;如何向你奶奶解释机器学习是什么&lt;/a&gt;&lt;br /&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651381855&amp;amp;idx=1&amp;amp;sn=04aeb9e0fa6d5d0866a852a276f272cf&amp;amp;chksm=84f3ce1eb38447083dcbdd611ea13287148885612be48fdeae276e51b1503e6c7e2f6e0ba2bc&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data_ue_src=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651381855&amp;amp;idx=1&amp;amp;sn=04aeb9e0fa6d5d0866a852a276f272cf&amp;amp;chksm=84f3ce1eb38447083dcbdd611ea13287148885612be48fdeae276e51b1503e6c7e2f6e0ba2bc&amp;amp;scene=21#wechat_redirect&quot;&gt;what is Bifurcation&lt;/a&gt;&lt;br /&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651383823&amp;amp;idx=1&amp;amp;sn=68d85261e3f0cb1c680112a4cb034cc2&amp;amp;chksm=84f3c64eb3844f5842ec848d552ab20f9052a0a1908c8cc0a3d66ff0eaa44aa1a011858b3e37&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot;&gt;机器学习的本质： 理解泛化的新观点&lt;/a&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; rgb=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;&gt;作者简介&lt;/p&gt;
&lt;pre contenteditable-directive=&quot;&quot; mm-paste=&quot;&quot; ng-blur=&quot;editAreaBlur($event)&quot; ng-model=&quot;editAreaCtn&quot; ng-click=&quot;editAreaClick($event)&quot; ng-keyup=&quot;editAreaKeyup($event)&quot; ng-keydown=&quot;editAreaKeydown($event)&quot;&gt;
&lt;span&gt;作者许铁，微信号：ironcruiser &lt;/span&gt;&lt;br /&gt;&lt;span&gt;法国&lt;/span&gt;&lt;strong&gt;巴黎高师&lt;/strong&gt;&lt;span&gt;物理硕士 ，&lt;/span&gt;&lt;strong&gt;以色列理工大学&lt;/strong&gt;&lt;span&gt;（以色列85%科技创业人才的摇篮, 计算机科学享誉全球）计算神经科学博士，巡洋舰科技有限公司创始人,   《机器学习与复杂系统》纸质书作者。曾在香港浸会大学非线性科学中心工作一年 ，万门童校长好战友。&lt;br /&gt;&lt;/span&gt;
&lt;/pre&gt;






</description>
<pubDate>Mon, 10 Dec 2018 03:23:35 +0000</pubDate>
<dc:language>zh-CN</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.jintiankansha.me/t/94BvzOP4G6</dc:identifier>
</item>
<item>
<title>机器学习高维数据分析中那些一定可以避开的坑！</title>
<link>http://www.jintiankansha.me/t/pyTQCuYVcR</link>
<guid isPermaLink="true" >http://www.jintiankansha.me/t/pyTQCuYVcR</guid>
<description>&lt;p data-mpa-powered-by=&quot;yiban.io&quot; helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; sans=&quot;&quot; gb=&quot;&quot; yahei=&quot;&quot; ui=&quot;&quot; arial=&quot;&quot; sans-serif=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot; center=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.7311258278145696&quot; data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-w=&quot;755&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/wibWV1DB7tWINE7dHffUN1wQZG6icOIpZoycAWPNzQsu5CcQWJjv6zsVdGkD5qicgIo3Aqhspync7IxJx3ISqzr3A/640?&quot;/&gt;&lt;/p&gt;
&lt;section class=&quot;&quot; data-mpa-template-id=&quot;1258535&quot; data-mpa-color=&quot;null&quot; data-mpa-category=&quot;fav&quot; helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; sans=&quot;&quot; gb=&quot;&quot; yahei=&quot;&quot; ui=&quot;&quot; arial=&quot;&quot; sans-serif=&quot;&quot; justify=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;&gt;
&lt;section class=&quot;&quot; data-mpa-template-id=&quot;1172402&quot; data-mpa-color=&quot;null&quot; data-mpa-category=&quot;fav&quot;&gt;&lt;section&gt;&lt;span&gt;&lt;strong mpa-from-tpl=&quot;t&quot;&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;导语&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;section readability=&quot;4.2717815344603&quot;&gt;&lt;section readability=&quot;8.5435630689207&quot;&gt;&lt;p&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;《Nature》11月28日推出的一篇&lt;span class=&quot;&quot;&gt;comments&lt;/span&gt;文章指出了使用高维数据的机器学习中常见的“坑”，以及避免方法，从而帮助该领域的小白能够客观的评价他们结果是否靠谱。&lt;/span&gt;&lt;/p&gt;

&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; sans=&quot;&quot; gb=&quot;&quot; yahei=&quot;&quot; ui=&quot;&quot; arial=&quot;&quot; sans-serif=&quot;&quot; justify=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;由于和生物有关的&lt;/span&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzIzMjQyNzQ5MA==&amp;amp;mid=2247488566&amp;amp;idx=1&amp;amp;sn=5be07345c82c154d0bb69e8266d8c4bd&amp;amp;chksm=e8944ebbdfe3c7ad3da3d3759f83f7d95d89fb0bd417e8c7c9a68ce0897d1503c0a445cd2582&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot;&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;组学数据&lt;/span&gt;&lt;/a&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;都是典型的高维数据，例如蛋白组，脂质组，转录组（RNA），基因组（DNA）等，在这个&lt;/span&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzIzMjQyNzQ5MA==&amp;amp;mid=2247493647&amp;amp;idx=1&amp;amp;sn=4d75f9734f1562bd0d849a45261f2845&amp;amp;chksm=e897b282dfe03b942747ba35bc95b0bf7a1299066f747e86388443e5a8f05fd221a6c37389ab&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot;&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;人工智能和医疗结合&lt;/span&gt;&lt;/a&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;愈发深入的年代，基于高维数据的预测模型将会变得越来越重要。因此对于相关从业者，深入了解其中的方法论愈加不可或缺。另外，高维数据不止出现在生物相关的组学数据中，在材料，气象等领域也会有类似的数据集，故这篇“避坑指南”不仅仅适用于与生物相关的数据挖掘中&lt;/span&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;。&lt;/span&gt;&lt;/p&gt;
&lt;section class=&quot;&quot; data-mpa-template-id=&quot;1377480&quot; data-mpa-color=&quot;#ffffff&quot; data-mpa-category=&quot;title&quot; helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; sans=&quot;&quot; gb=&quot;&quot; yahei=&quot;&quot; ui=&quot;&quot; arial=&quot;&quot; sans-serif=&quot;&quot; justify=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;&gt;
&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;
&lt;/section&gt;&lt;blockquote helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; sans=&quot;&quot; gb=&quot;&quot; yahei=&quot;&quot; ui=&quot;&quot; arial=&quot;&quot; sans-serif=&quot;&quot; justify=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot; readability=&quot;5&quot;&gt;
&lt;p&gt;&lt;span&gt;论文题目：&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;论文地址：&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;https://www.nature.com/articles/s41563-018-0241-z&lt;/span&gt;&lt;/p&gt;
&lt;/blockquote&gt;



&lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;/&gt; &lt;section class=&quot;&quot; data-mpa-template-id=&quot;1377480&quot; data-mpa-color=&quot;#ffffff&quot; data-mpa-category=&quot;title&quot; helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; sans=&quot;&quot; gb=&quot;&quot; yahei=&quot;&quot; ui=&quot;&quot; arial=&quot;&quot; sans-serif=&quot;&quot; justify=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;&gt;&lt;section data-mid=&quot;t4&quot;&gt;&lt;section data-preserve-color=&quot;t&quot; data-mid=&quot;&quot;&gt;&lt;section data-mid=&quot;&quot;&gt;&lt;p&gt;&lt;strong mpa-from-tpl=&quot;t&quot;&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;&lt;strong mpa-from-tpl=&quot;t&quot; mpa-is-content=&quot;t&quot;&gt;过拟合与维度灾难&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;
&lt;/section&gt;&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; sans=&quot;&quot; gb=&quot;&quot; yahei=&quot;&quot; ui=&quot;&quot; arial=&quot;&quot; sans-serif=&quot;&quot; justify=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;文章背景&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; sans=&quot;&quot; gb=&quot;&quot; yahei=&quot;&quot; ui=&quot;&quot; arial=&quot;&quot; sans-serif=&quot;&quot; justify=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;&gt;&lt;span&gt;为了搞清楚那些因素影响我们的身体健康，人们对自身从多个角度进行了观测。随着测序成本的降低，从基因到转录出RNA再到合成蛋白质，积累了越来越多的数据。关于一个人的数据项，没有百万也有数十万，这其中的每一项数据，可以看成数据集的一个维度。而我们关心的是&lt;/span&gt;&lt;span&gt;这些分子层面的数据如何与宏观的表型通过统计模型关联起来&lt;/span&gt;&lt;span&gt;&lt;span&gt;，&lt;/span&gt;例如血压，血糖，尿酸等数据变化与人体的健康状况的联系。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;

&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; sans=&quot;&quot; gb=&quot;&quot; yahei=&quot;&quot; ui=&quot;&quot; arial=&quot;&quot; sans-serif=&quot;&quot; justify=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;&gt;&lt;span&gt;过拟合指的是将表型之间本来是随机的变化错视为统计显著的关联，错误地和某一个维度建立了联系，即假阳性。&lt;/span&gt;&lt;span&gt;假设有一百万维的数据，如果单独来看，那么就需要判定一百万次是否统计相关，而每次独立的判定假设有5%的几率将随机的误差当成是相关性的信号，&lt;/span&gt;&lt;span&gt;那一百万次的判定，不知会导致多少次假阳性。&lt;/span&gt;&lt;/p&gt;

&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; sans=&quot;&quot; gb=&quot;&quot; yahei=&quot;&quot; ui=&quot;&quot; arial=&quot;&quot; sans-serif=&quot;&quot; justify=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;&gt;&lt;span&gt;因此需要将P值的显著性判定值进行校正，最严格的就是&lt;/span&gt;&lt;span&gt;用0.05除以数据的维度&lt;/span&gt;&lt;span&gt;。但是由于不同数据间本身具有相关性，很多维度反映了身体相同的调控机制，所以简单地除以数据本身的维度，也会带来假阴性的问题。而且这些维度之间是有相互影响的。这两项原因，使得机器学习的方法逐渐流行起来。&lt;/span&gt;&lt;/p&gt;

&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; sans=&quot;&quot; gb=&quot;&quot; yahei=&quot;&quot; ui=&quot;&quot; arial=&quot;&quot; sans-serif=&quot;&quot; justify=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;&gt;&lt;span&gt;最近有文献指出，在&lt;/span&gt;&lt;span&gt;已发表的神经科学类论文中，有&lt;/span&gt;&lt;span&gt;50%&lt;/span&gt;&lt;span&gt;的文章统计学方法有疏漏[2]&lt;/span&gt;&lt;span&gt;，在其他的分子生物学领域也是类似的，毕竟该领域的数据暴增是最近十年间才发生的。&lt;/span&gt;&lt;/p&gt;

&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; sans=&quot;&quot; gb=&quot;&quot; yahei=&quot;&quot; ui=&quot;&quot; arial=&quot;&quot; sans-serif=&quot;&quot; justify=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;&gt;&lt;strong&gt;&lt;span&gt;高维度低样本数据的维度诅咒&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; sans=&quot;&quot; gb=&quot;&quot; yahei=&quot;&quot; ui=&quot;&quot; arial=&quot;&quot; sans-serif=&quot;&quot; justify=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;&gt;&lt;strong&gt;&lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;/&gt; &lt;span&gt;（&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;The curse of dimensionality&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; sans=&quot;&quot; gb=&quot;&quot; yahei=&quot;&quot; ui=&quot;&quot; arial=&quot;&quot; sans-serif=&quot;&quot; justify=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;&gt;&lt;span&gt;下图代表我们的数据集，其中有n个sample，比如有500个，但是每个人的基因数据，却可能有几万的维度，即p&amp;gt;&amp;gt;n，最上面的表型是不同颜色代表分类的标签，比如是否患某种疾病。但这里的基因数据是随机生成的高斯噪音。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; sans=&quot;&quot; gb=&quot;&quot; yahei=&quot;&quot; ui=&quot;&quot; arial=&quot;&quot; sans-serif=&quot;&quot; justify=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;&gt;&lt;span&gt;       &lt;/span&gt;&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; sans=&quot;&quot; gb=&quot;&quot; yahei=&quot;&quot; ui=&quot;&quot; arial=&quot;&quot; sans-serif=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot; center=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.6525547445255474&quot; data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-w=&quot;685&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/wibWV1DB7tWINE7dHffUN1wQZG6icOIpZoFaj2e4xdEkrckZ9bW9ngdpjiacS69iamIF3PTKOGZ6T1AJs4m0SibWGMg/640?&quot;/&gt;&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; sans=&quot;&quot; gb=&quot;&quot; yahei=&quot;&quot; ui=&quot;&quot; arial=&quot;&quot; sans-serif=&quot;&quot; justify=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;&gt;&lt;span&gt;       &lt;/span&gt;&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; sans=&quot;&quot; gb=&quot;&quot; yahei=&quot;&quot; ui=&quot;&quot; arial=&quot;&quot; sans-serif=&quot;&quot; justify=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;&gt;&lt;span&gt;但是当使用SVM分类器，将原始投影在三维平面上时，却可以几乎完美地分开，这就是高维度低样本数据的维度诅咒（The curse of dimensionality）。&lt;/span&gt;&lt;/p&gt;

&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; sans=&quot;&quot; gb=&quot;&quot; yahei=&quot;&quot; ui=&quot;&quot; arial=&quot;&quot; sans-serif=&quot;&quot; justify=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;&gt;&lt;strong&gt;&lt;span&gt;引入惩罚项的常规步骤&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; sans=&quot;&quot; gb=&quot;&quot; yahei=&quot;&quot; ui=&quot;&quot; arial=&quot;&quot; sans-serif=&quot;&quot; justify=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;&gt;&lt;span&gt;机器学习中面对过拟合的常见方法，是引入惩罚项，如果模型越来越复杂，就在要优化的损失函数中加上对应的惩罚，这样是不是就能够解决问题了？&lt;/span&gt;&lt;/p&gt;

&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; sans=&quot;&quot; gb=&quot;&quot; yahei=&quot;&quot; ui=&quot;&quot; arial=&quot;&quot; sans-serif=&quot;&quot; justify=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;&gt;&lt;span&gt;惩罚项也有很多种类，该加那一类惩罚项这个问题也需要通过数据才能回答。&lt;/span&gt;&lt;/p&gt;
&lt;ul class=&quot; list-paddingleft-2&quot; readability=&quot;2.5&quot;&gt;&lt;li readability=&quot;1&quot;&gt;
&lt;p&gt;&lt;span&gt;在理想情况下，有足够多的样本，能够将样本分成三部分，一个训练集，一个测试集，还有一个数据集用来确定模型的复杂度，这三个集合是完全隔离的；&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;&lt;span&gt;先在训练集上使用不同的方法和惩罚项的组合训练一组模型及进行特征选择（选出哪些数据项对预测任务更有效）；&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;&lt;span&gt;之后在橙色的模型选择集合上选择一个最优模型，即图中曲线的最低点；&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;&lt;span&gt;最后在测试集合上判定准确性。&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; sans=&quot;&quot; gb=&quot;&quot; yahei=&quot;&quot; ui=&quot;&quot; arial=&quot;&quot; sans-serif=&quot;&quot; justify=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;&gt;&lt;span&gt;       &lt;/span&gt;&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; sans=&quot;&quot; gb=&quot;&quot; yahei=&quot;&quot; ui=&quot;&quot; arial=&quot;&quot; sans-serif=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot; center=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.22927100723427934&quot; data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-w=&quot;1797&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/wibWV1DB7tWINE7dHffUN1wQZG6icOIpZooNAES2m0RTopMnZhXIxs6B7l1ckL7YVo9mBX3DL29PqzHeUO05V74g/640?&quot;/&gt;&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; sans=&quot;&quot; gb=&quot;&quot; yahei=&quot;&quot; ui=&quot;&quot; arial=&quot;&quot; sans-serif=&quot;&quot; justify=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;&gt;&lt;span&gt;       &lt;br/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; sans=&quot;&quot; gb=&quot;&quot; yahei=&quot;&quot; ui=&quot;&quot; arial=&quot;&quot; sans-serif=&quot;&quot; justify=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;&gt;&lt;span&gt;就像在下图中，先在测试数据集上训练了多个模型，之后在橙色的第三幅图中确定三次项的模型是最好的。最后再去测试数据集上看模型的泛化误差。&lt;/span&gt;&lt;/p&gt;
&lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;/&gt; &lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; sans=&quot;&quot; gb=&quot;&quot; yahei=&quot;&quot; ui=&quot;&quot; arial=&quot;&quot; sans-serif=&quot;&quot; justify=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;&gt;&lt;span&gt;       &lt;/span&gt;&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; sans=&quot;&quot; gb=&quot;&quot; yahei=&quot;&quot; ui=&quot;&quot; arial=&quot;&quot; sans-serif=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot; center=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.2932745314222712&quot; data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-w=&quot;1814&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/wibWV1DB7tWINE7dHffUN1wQZG6icOIpZoibvBFicW5QoDlOiaXhslicYjnsib0RIeoictyg2h2y0RJuLwg2PrTs11q6TQ/640?&quot;/&gt;&lt;/p&gt;

&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; sans=&quot;&quot; gb=&quot;&quot; yahei=&quot;&quot; ui=&quot;&quot; arial=&quot;&quot; sans-serif=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;非理想情况下的数据集分类：交叉验证&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; sans=&quot;&quot; gb=&quot;&quot; yahei=&quot;&quot; ui=&quot;&quot; arial=&quot;&quot; sans-serif=&quot;&quot; justify=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;&gt;&lt;span&gt;      &lt;br/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; sans=&quot;&quot; gb=&quot;&quot; yahei=&quot;&quot; ui=&quot;&quot; arial=&quot;&quot; sans-serif=&quot;&quot; justify=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;&gt;&lt;span&gt;可是真实情况下，组学的数据往往本身就不会有那么多样本，不同标签间的比例也不一定均一，所以不能像理想中那样将数据集分成三类。实际上的做法&lt;/span&gt;&lt;span&gt;类似下图的&lt;/span&gt;&lt;span&gt;交叉验证&lt;/span&gt;&lt;span&gt;，将数据分为N份，每次拿其中一份做测试集，剩下的做训练集。之后将每次实验验证集的误差汇总或取平均值，当做模型的泛化误差。由于每一份数据在都有机会被用做了验证集，因此对模型泛化误差的估计是无偏的。而模型选择的过程则是通过在不同模型上进行交叉验证完成的。&lt;/span&gt;&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; sans=&quot;&quot; gb=&quot;&quot; yahei=&quot;&quot; ui=&quot;&quot; arial=&quot;&quot; sans-serif=&quot;&quot; justify=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;&gt;&lt;span&gt;       &lt;/span&gt;&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; sans=&quot;&quot; gb=&quot;&quot; yahei=&quot;&quot; ui=&quot;&quot; arial=&quot;&quot; sans-serif=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot; center=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.3413705583756345&quot; data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-w=&quot;1576&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/wibWV1DB7tWINE7dHffUN1wQZG6icOIpZorhwtyXjUVjP1Awzr4nfH65L0TE82ghBs4aSEMCfkaK7ZvMvgwW9xtA/640?&quot;/&gt;&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; sans=&quot;&quot; gb=&quot;&quot; yahei=&quot;&quot; ui=&quot;&quot; arial=&quot;&quot; sans-serif=&quot;&quot; justify=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;&gt;&lt;span&gt;       &lt;br/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; sans=&quot;&quot; gb=&quot;&quot; yahei=&quot;&quot; ui=&quot;&quot; arial=&quot;&quot; sans-serif=&quot;&quot; justify=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;&gt;&lt;span&gt;极端情况下，n是数据集的样本个数（leave-one-out CV ），即只拿出一个样本来，剩下的都用来做训练集，从而保证模型有足够的样本量。那在做交叉验证的时候，需要注意什么了？&lt;/span&gt;&lt;/p&gt;

&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; sans=&quot;&quot; gb=&quot;&quot; yahei=&quot;&quot; ui=&quot;&quot; arial=&quot;&quot; sans-serif=&quot;&quot; justify=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;&gt;&lt;span&gt;交叉验证的目的是为了避免训练出的模型过拟合，因此可以训练一组模型，之后将这些模型给予不同数据维度的权重进行平均及排序，从中根据模型复杂度的惩罚项来选出多少项对预测结果影响最大的特征。或者通过选择不同数量的模型，确定一个最优的惩罚项，之后再用全部的数据来训练这个加上了预估的最优惩罚项的模型[3,4,5]。&lt;/span&gt;&lt;/p&gt;

&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; sans=&quot;&quot; gb=&quot;&quot; yahei=&quot;&quot; ui=&quot;&quot; arial=&quot;&quot; sans-serif=&quot;&quot; justify=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;&gt;&lt;span&gt;如果已经进行了特征选择，比如选出了我们关注的表型和这几百个基因最相关，那在做交叉验证的时候需要注意什么？&lt;/span&gt;&lt;/p&gt;

&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; sans=&quot;&quot; gb=&quot;&quot; yahei=&quot;&quot; ui=&quot;&quot; arial=&quot;&quot; sans-serif=&quot;&quot; justify=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;&gt;&lt;span&gt;要在全部的数据项上进行交叉验证。使用降维后的数据以及反复的特征选择，会带来偏差项的提高。因此要区分CV用来判定整个模型的泛化能力的交叉验证外层循环以及用来对具体这个模型参数调优的内部循环，从而将模型选择和模型优化分离，从而避免过拟合。&lt;/span&gt;&lt;/p&gt;
&lt;section class=&quot;&quot; data-mpa-template-id=&quot;1377480&quot; data-mpa-color=&quot;#ffffff&quot; data-mpa-category=&quot;title&quot; helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; sans=&quot;&quot; gb=&quot;&quot; yahei=&quot;&quot; ui=&quot;&quot; arial=&quot;&quot; sans-serif=&quot;&quot; justify=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;&gt;

&lt;section data-mid=&quot;t4&quot;&gt;&lt;section data-preserve-color=&quot;t&quot; data-mid=&quot;&quot;&gt;&lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;/&gt; &lt;section data-mid=&quot;&quot;&gt;&lt;p&gt;&lt;strong mpa-from-tpl=&quot;t&quot;&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;&lt;strong mpa-from-tpl=&quot;t&quot; mpa-is-content=&quot;t&quot;&gt;未知的混淆因素&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;
&lt;/section&gt;&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; sans=&quot;&quot; gb=&quot;&quot; yahei=&quot;&quot; ui=&quot;&quot; arial=&quot;&quot; sans-serif=&quot;&quot; justify=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;数据维度不足有什么不良后果？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; sans=&quot;&quot; gb=&quot;&quot; yahei=&quot;&quot; ui=&quot;&quot; arial=&quot;&quot; sans-serif=&quot;&quot; justify=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;&gt;&lt;span&gt;数据量不足之外，生物相关的数据还受制于数据本身的维度不足的影响，比如你收集的数据不包括生活习惯，或者做实验时用到的试剂的批次等，但这却会对这个人是否患病有显著的影响，或影响数据本身的分布。这种情况具体是怎样的？&lt;/span&gt;&lt;/p&gt;

&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; sans=&quot;&quot; gb=&quot;&quot; yahei=&quot;&quot; ui=&quot;&quot; arial=&quot;&quot; sans-serif=&quot;&quot; justify=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;&gt;&lt;span&gt;如下图所示，本来的数据集中一个没有被记录下的特征，将其称为X，如图中灰色和黑色的那一列，而在对应的表型上，这个X变量并不是均匀分布的，这导致在交叉验证时，不论在测试集还是验证集上，黑色对应的哪一列用肉眼就能看出其很特殊，这导致模型学到的&lt;/span&gt;&lt;span&gt;其实不是判定一个样本是红色还是蓝色这个预设的目标，反而“偷懒”去判定样本是灰色还是黑色&lt;/span&gt;&lt;span&gt;。&lt;/span&gt;&lt;/p&gt;

&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; sans=&quot;&quot; gb=&quot;&quot; yahei=&quot;&quot; ui=&quot;&quot; arial=&quot;&quot; sans-serif=&quot;&quot; justify=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;&gt;&lt;span&gt;这导致的结果是不管训练集本身的交叉验证还是测试集，其结果都不差，但到了完全不同的一份独立数据集上，模型的表现就差得和随机乱猜差不多了。见右下方的ROC曲线，ROC 接近0.5，就意味着模型完全没有预测效力。&lt;/span&gt;&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; sans=&quot;&quot; gb=&quot;&quot; yahei=&quot;&quot; ui=&quot;&quot; arial=&quot;&quot; sans-serif=&quot;&quot; justify=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;&gt;&lt;span&gt;       &lt;/span&gt;&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; sans=&quot;&quot; gb=&quot;&quot; yahei=&quot;&quot; ui=&quot;&quot; arial=&quot;&quot; sans-serif=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot; center=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.6510948905109489&quot; data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-w=&quot;685&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/wibWV1DB7tWINE7dHffUN1wQZG6icOIpZot2aFjKX7df7owpnibVcvIGWM77ibfy70hfIzGr0Ga1LTFDxOfe6FIHDA/640?&quot;/&gt;&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; sans=&quot;&quot; gb=&quot;&quot; yahei=&quot;&quot; ui=&quot;&quot; arial=&quot;&quot; sans-serif=&quot;&quot; justify=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;&gt;&lt;span&gt;     &lt;br/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; sans=&quot;&quot; gb=&quot;&quot; yahei=&quot;&quot; ui=&quot;&quot; arial=&quot;&quot; sans-serif=&quot;&quot; justify=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;&gt;&lt;span&gt;因此当前判定一个模型是否靠谱的金标准，都是将你模型在其他实验室使用相同的实验方法对相近或相同样本观测得出的独立数据集上跑一下。&lt;/span&gt;&lt;span&gt;通过一个独立的验证集，能够看到模型本身是不是受到未知的干扰因素的影响&lt;/span&gt;&lt;span&gt;。那如果发现了有未知因素的影响，又应该怎么办呢？&lt;/span&gt;&lt;/p&gt;

&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; sans=&quot;&quot; gb=&quot;&quot; yahei=&quot;&quot; ui=&quot;&quot; arial=&quot;&quot; sans-serif=&quot;&quot; justify=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;&gt;&lt;strong&gt;&lt;span&gt;对于未知混淆因素&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; sans=&quot;&quot; gb=&quot;&quot; yahei=&quot;&quot; ui=&quot;&quot; arial=&quot;&quot; sans-serif=&quot;&quot; justify=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;&gt;&lt;span&gt;有些好排除，例如人种，年龄之间的差异，可以通过统计上的校正解决，对于年龄，由于年老对身体的影响不一定是线性而可能是指数的，因此还会将年龄的平方项和立方项作为控制因素[6]。&lt;/span&gt;&lt;/p&gt;

&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; sans=&quot;&quot; gb=&quot;&quot; yahei=&quot;&quot; ui=&quot;&quot; arial=&quot;&quot; sans-serif=&quot;&quot; justify=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;&gt;&lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;/&gt; &lt;span&gt;但更多的混合因素则是未知的，例如那一天做的实验，用的那一台机器等。虽然目前已有相关的统计方法来解决这一问题，但这些模型都假设未知的因素满足相应的分布，但现实中却往往不是这样的，这导致即使校正后也有残余的未知因素影响。&lt;/span&gt;&lt;/p&gt;

&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; sans=&quot;&quot; gb=&quot;&quot; yahei=&quot;&quot; ui=&quot;&quot; arial=&quot;&quot; sans-serif=&quot;&quot; justify=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;&gt;&lt;span&gt;当你的模型在独立数据集上无法重复好结果的时候，也不应该当成是你的模型的末日审判，而应该去找可能的原因和解释。&lt;/span&gt;&lt;/p&gt;

&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; sans=&quot;&quot; gb=&quot;&quot; yahei=&quot;&quot; ui=&quot;&quot; arial=&quot;&quot; sans-serif=&quot;&quot; justify=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;&gt;&lt;span&gt;比如用于验证的独立数据测量的数据项不如原始的用于交叉验证的数据项丰富，或者用来验证的数据来自一个不同的人种，从而使得你的模型不适用。尤其在医疗领域，为了保护隐私及伦理要求，并不是所有的数据都是公开的。这使得评价用于验证的独立数据集是否恰当变得很困难。&lt;/span&gt;&lt;/p&gt;

&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; sans=&quot;&quot; gb=&quot;&quot; yahei=&quot;&quot; ui=&quot;&quot; arial=&quot;&quot; sans-serif=&quot;&quot; justify=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;&gt;&lt;span&gt;这个问题对于那些方法类的“虐前任”型创新尤其严重。很多文章宣称自己通过整合很多组学数据，提出了一种比之前所有模型更准确的预测模型。但由于有残留的未知因素，当你引入新的数据项的时候，模型不做改进，就有可能效果比前人的好，这并不代表着你做出了方法学上的改进与创新。因此现在严谨的做法是&lt;/span&gt;&lt;span&gt;如果你要证明你的方法有所长进，至少需要在五到六份的独立数据集上展示你的方法比前人的有显著提升。&lt;/span&gt;&lt;/p&gt;
&lt;section class=&quot;&quot; data-mpa-template-id=&quot;1377480&quot; data-mpa-color=&quot;#ffffff&quot; data-mpa-category=&quot;title&quot; helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; sans=&quot;&quot; gb=&quot;&quot; yahei=&quot;&quot; ui=&quot;&quot; arial=&quot;&quot; sans-serif=&quot;&quot; justify=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;&gt;

&lt;section data-mid=&quot;t4&quot;&gt;&lt;section data-preserve-color=&quot;t&quot; data-mid=&quot;&quot; readability=&quot;1&quot;&gt;&lt;section data-mid=&quot;&quot; readability=&quot;2&quot;&gt;&lt;p&gt;&lt;strong mpa-from-tpl=&quot;t&quot;&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;&lt;strong mpa-from-tpl=&quot;t&quot; mpa-is-content=&quot;t&quot;&gt;非监督学习中也有过拟合&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;
&lt;/section&gt;&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; sans=&quot;&quot; gb=&quot;&quot; yahei=&quot;&quot; ui=&quot;&quot; arial=&quot;&quot; sans-serif=&quot;&quot; justify=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;&gt;&lt;span&gt;在非监督学习中，也会也出现过拟合的现象呢？&lt;/span&gt;&lt;span&gt;例如在对特征进行聚类时，即使每一个数据项都和待研究的表型统计相关性并不显著，但它们之间的相关性却会使它们聚在一起，从而导致数据项聚成簇，但这样的结果却不能用于指导特征选择，否则就会导致过拟合。&lt;/span&gt;&lt;/p&gt;

&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; sans=&quot;&quot; gb=&quot;&quot; yahei=&quot;&quot; ui=&quot;&quot; arial=&quot;&quot; sans-serif=&quot;&quot; justify=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;&gt;&lt;span&gt;非监督学习的另一个常见应用是数据降维，这中间也会也导致过拟合。&lt;/span&gt;&lt;span&gt;这篇论文中举出了一个具体的例子，如下图。图中的红色和绿色是两个样本在不同基因区域上的对应特征，红色的是有病的，绿色的是没病的。在图a中，使用数据的均值作为降维后的特征，会导致对数据分类时效果变差，但使用数据的方差则不会。而在b图中，由于数据本身的分布不同，导致相反的结果，使用方差会导致分类时效果变差。&lt;/span&gt;&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; sans=&quot;&quot; gb=&quot;&quot; yahei=&quot;&quot; ui=&quot;&quot; arial=&quot;&quot; sans-serif=&quot;&quot; justify=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;&gt;&lt;span&gt;       &lt;/span&gt;&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; sans=&quot;&quot; gb=&quot;&quot; yahei=&quot;&quot; ui=&quot;&quot; arial=&quot;&quot; sans-serif=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot; center=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.4399776661083194&quot; data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-w=&quot;1791&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/wibWV1DB7tWINE7dHffUN1wQZG6icOIpZolN45063qwoicaPIa5Pj09jbC7cdia6h07YBSOBYMOVG2hfd1I82oGOvg/640?&quot;/&gt;&lt;span&gt;     &lt;/span&gt;&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; sans=&quot;&quot; gb=&quot;&quot; yahei=&quot;&quot; ui=&quot;&quot; arial=&quot;&quot; sans-serif=&quot;&quot; justify=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;&gt;&lt;span&gt;虽然取方差和取均值不是现实中用到的数据降维的方式，但上面的例子展示了如果只根据少量数据选择的降维模型不适合新的数据，即导致过拟合。这方面有一个工具可以用来评估，可以进一步学习。&lt;/span&gt;&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; sans=&quot;&quot; gb=&quot;&quot; yahei=&quot;&quot; ui=&quot;&quot; arial=&quot;&quot; sans-serif=&quot;&quot; justify=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;&gt;&lt;span&gt;       &lt;/span&gt;&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; sans=&quot;&quot; gb=&quot;&quot; yahei=&quot;&quot; ui=&quot;&quot; arial=&quot;&quot; sans-serif=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot; center=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;&gt;&lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;/&gt; &lt;img class=&quot;&quot; data-ratio=&quot;0.3487762237762238&quot; data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-w=&quot;1144&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/wibWV1DB7tWINE7dHffUN1wQZG6icOIpZogaWKRXC63s4ibqHlz8SiaXTAC89y1v4FjHE3RLF3ynSjFVzkjSNE2KicA/640?&quot;/&gt;&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; sans=&quot;&quot; gb=&quot;&quot; yahei=&quot;&quot; ui=&quot;&quot; arial=&quot;&quot; sans-serif=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot; center=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;&gt;&lt;strong&gt;&lt;span&gt;该方法借鉴了交叉验证，用来判定非监督模型是否过拟合。&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;blockquote helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; sans=&quot;&quot; gb=&quot;&quot; yahei=&quot;&quot; ui=&quot;&quot; arial=&quot;&quot; sans-serif=&quot;&quot; justify=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot; readability=&quot;7&quot;&gt;
&lt;p&gt;&lt;span&gt;论文题目：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;MOVIE: Multi-Omics VIsualization of Estimated contributions&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;论文地址：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;https://www.biorxiv.org/content/early/2018/07/29/379115&lt;/span&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; sans=&quot;&quot; gb=&quot;&quot; yahei=&quot;&quot; ui=&quot;&quot; arial=&quot;&quot; sans-serif=&quot;&quot; justify=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;&gt;&lt;span&gt;     &lt;br/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; sans=&quot;&quot; gb=&quot;&quot; yahei=&quot;&quot; ui=&quot;&quot; arial=&quot;&quot; sans-serif=&quot;&quot; justify=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;&gt;&lt;span&gt;例如下面的图片中，哪一个过拟合了？&lt;/span&gt;&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; sans=&quot;&quot; gb=&quot;&quot; yahei=&quot;&quot; ui=&quot;&quot; arial=&quot;&quot; sans-serif=&quot;&quot; justify=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;&gt;&lt;span&gt;      &lt;/span&gt;&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; sans=&quot;&quot; gb=&quot;&quot; yahei=&quot;&quot; ui=&quot;&quot; arial=&quot;&quot; sans-serif=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot; center=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;&gt;&lt;img class=&quot;&quot; data-ratio=&quot;1.0685805422647527&quot; data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-w=&quot;627&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/wibWV1DB7tWINE7dHffUN1wQZG6icOIpZoSmdMFM7JuicnJr0NZkQs6qJZ1QdU1ic3Okgwodf3xd6AtoqzzbtWoAicQ/640?&quot;/&gt;&lt;span&gt;   &lt;/span&gt;&lt;span&gt;  &lt;/span&gt;&lt;/p&gt;
&lt;section class=&quot;&quot; data-mpa-template-id=&quot;1377480&quot; data-mpa-color=&quot;#ffffff&quot; data-mpa-category=&quot;title&quot; helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; sans=&quot;&quot; gb=&quot;&quot; yahei=&quot;&quot; ui=&quot;&quot; arial=&quot;&quot; sans-serif=&quot;&quot; justify=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;&gt;

&lt;section data-mid=&quot;t4&quot;&gt;&lt;section data-preserve-color=&quot;t&quot; data-mid=&quot;&quot;&gt;&lt;section data-mid=&quot;&quot;&gt;&lt;p&gt;&lt;strong mpa-from-tpl=&quot;t&quot;&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;&lt;strong mpa-from-tpl=&quot;t&quot; mpa-is-content=&quot;t&quot;&gt;小结&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;
&lt;/section&gt;&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; sans=&quot;&quot; gb=&quot;&quot; yahei=&quot;&quot; ui=&quot;&quot; arial=&quot;&quot; sans-serif=&quot;&quot; justify=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;&gt;&lt;span&gt;这篇文章总结了高维数据的三个常见问题，一是没有用好交叉验证，导致预测模型过拟合。二是忽略了未知的干扰因素，导致模型在独立数据集上表现糟糕，三是在非监督学习中忽略了过拟合，导致特征选择时丢失关键信息，从而影响预测模型的效果。针对这三个问题，作者给出了当前行业内共识的常见解决建议，虽然这些问题都没有完全解决，但避免前人踩过的坑，是必不可少的。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;

&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; sans=&quot;&quot; gb=&quot;&quot; yahei=&quot;&quot; ui=&quot;&quot; arial=&quot;&quot; sans-serif=&quot;&quot; justify=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;&gt;&lt;strong&gt;&lt;span&gt;参考文献&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;ol class=&quot; list-paddingleft-2&quot; readability=&quot;10.5&quot;&gt;&lt;li readability=&quot;4&quot;&gt;
&lt;p&gt;&lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;/&gt; &lt;span&gt;Nieuwenhuis, S., Forstmann, B. U. &amp;amp; Wagenmakers, E. J. Nat. Neurosci. 14, 1105–1107 (2011)&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;6&quot;&gt;
&lt;p&gt;&lt;span&gt;Simon, R., Radmacher, M. D., Dobbin, K. &amp;amp; McShane, L. M. J. Natl Cancer Inst. 95, 14–18 (2003)&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;2&quot;&gt;
&lt;p&gt;&lt;span&gt;Varma, S. &amp;amp; Simon, R. BMC Bioinform. 7, 91 (2006).&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;1&quot;&gt;
&lt;p&gt;&lt;span&gt;Teschendorf, A. E. et al. Genome Biol. 7, R101 (2006)&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;&lt;span&gt;https://permalinks.23andme.com/pdf/23-12_predictivemodel_methodology_02oct2015.pdf&lt;/span&gt;&lt;/p&gt;

&lt;/li&gt;
&lt;/ol&gt;

&lt;blockquote helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; sans=&quot;&quot; gb=&quot;&quot; yahei=&quot;&quot; ui=&quot;&quot; arial=&quot;&quot; sans-serif=&quot;&quot; justify=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;&gt;
&lt;p&gt;&lt;span&gt;作者：郭瑞东&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;编辑：王怡蔺&lt;/span&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;section class=&quot;&quot; data-mpa-template-id=&quot;1377480&quot; data-mpa-color=&quot;#ffffff&quot; data-mpa-category=&quot;title&quot; helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; sans=&quot;&quot; gb=&quot;&quot; yahei=&quot;&quot; ui=&quot;&quot; arial=&quot;&quot; sans-serif=&quot;&quot; justify=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;&gt;
&lt;section data-mid=&quot;t4&quot;&gt;&lt;section data-preserve-color=&quot;t&quot; data-mid=&quot;&quot;&gt;&lt;section data-mid=&quot;&quot;&gt;&lt;p&gt;&lt;strong mpa-from-tpl=&quot;t&quot;&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;&lt;strong mpa-from-tpl=&quot;t&quot; mpa-is-content=&quot;t&quot;&gt;推荐阅读&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;
&lt;/section&gt;&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; sans=&quot;&quot; gb=&quot;&quot; yahei=&quot;&quot; ui=&quot;&quot; arial=&quot;&quot; sans-serif=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot; center=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzIzMjQyNzQ5MA==&amp;amp;mid=2247490693&amp;amp;idx=1&amp;amp;sn=171c4800ce8d7eb72e7b7e24d4fc6806&amp;amp;chksm=e8944608dfe3cf1eed89347b3227a7125887ab97132a31a22bc89b63844a0065da69de7e09de&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot;&gt;从拓扑数据分析到压缩感知&lt;/a&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; sans=&quot;&quot; gb=&quot;&quot; yahei=&quot;&quot; ui=&quot;&quot; arial=&quot;&quot; sans-serif=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot; center=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzIzMjQyNzQ5MA==&amp;amp;mid=2247488037&amp;amp;idx=1&amp;amp;sn=802627d033d5f724930938eff55df8f6&amp;amp;chksm=e89448a8dfe3c1be6babd37a031f8b265052a13bce6cfea294008d1980a01711ab5d29711670&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot;&gt;如何捕捉&lt;/a&gt;&lt;strong&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzIzMjQyNzQ5MA==&amp;amp;mid=2247488037&amp;amp;idx=1&amp;amp;sn=802627d033d5f724930938eff55df8f6&amp;amp;chksm=e89448a8dfe3c1be6babd37a031f8b265052a13bce6cfea294008d1980a01711ab5d29711670&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot;&gt;关系数据结构？&lt;/a&gt;&lt;/strong&gt;&lt;/span&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; sans=&quot;&quot; gb=&quot;&quot; yahei=&quot;&quot; ui=&quot;&quot; arial=&quot;&quot; sans-serif=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot; center=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;/&gt; &lt;span&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzIzMjQyNzQ5MA==&amp;amp;mid=2247490249&amp;amp;idx=1&amp;amp;sn=8f494f8da307913910f51523ea218482&amp;amp;chksm=e8944044dfe3c952c975ebfa26c36c827bb20d957ec693a928c929bf9dcfe1855cf8aa631adf&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot;&gt;混乱中的秩序 | Kolmogorov复杂度&lt;/a&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; sans=&quot;&quot; gb=&quot;&quot; yahei=&quot;&quot; ui=&quot;&quot; arial=&quot;&quot; sans-serif=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot; center=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzIzMjQyNzQ5MA==&amp;amp;mid=2247491991&amp;amp;idx=1&amp;amp;sn=b866da720abca815123eb2d6024b6cde&amp;amp;chksm=e897bb1adfe0320ca533cb6bca860148a61d538fd77122117001a830163b2f4399db3eaaea70&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot;&gt;大数据知道你更想和谁约会&lt;/a&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; sans=&quot;&quot; gb=&quot;&quot; yahei=&quot;&quot; ui=&quot;&quot; arial=&quot;&quot; sans-serif=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot; center=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzIzMjQyNzQ5MA==&amp;amp;mid=2247487778&amp;amp;idx=1&amp;amp;sn=c2e77ec93213c4c63f57a777ff10e368&amp;amp;chksm=e8944bafdfe3c2b9d66544dafe7403159473e8c94fd3bc513f5300c353bcec49c0c0b69797af&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;加入集智，一起复杂！&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/a&gt;&lt;br/&gt;&lt;/p&gt;
&lt;section class=&quot;&quot; data-mpa-template-id=&quot;1377480&quot; data-mpa-color=&quot;#ffffff&quot; data-mpa-category=&quot;title&quot; helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; sans=&quot;&quot; gb=&quot;&quot; yahei=&quot;&quot; ui=&quot;&quot; arial=&quot;&quot; sans-serif=&quot;&quot; justify=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;&gt;
&lt;section data-mid=&quot;t4&quot;&gt;&lt;section data-preserve-color=&quot;t&quot; data-mid=&quot;&quot;&gt;&lt;section data-mid=&quot;&quot;&gt;&lt;p&gt;&lt;strong mpa-from-tpl=&quot;t&quot;&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;&lt;strong mpa-from-tpl=&quot;t&quot; mpa-is-content=&quot;t&quot;&gt;推荐课程&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;
&lt;/section&gt;&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; sans=&quot;&quot; gb=&quot;&quot; yahei=&quot;&quot; ui=&quot;&quot; arial=&quot;&quot; sans-serif=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot; center=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;&gt;&lt;img class=&quot;&quot; data-croporisrc=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/wibWV1DB7tWLer16ibicMVplicymdJ2rLpaOIcZa3TWmowp7tWE4HematypZyuO7eMQLJFA4M82bf62EE3DwptH1iaw/0?wx_fmt=png&quot; data-cropx1=&quot;0&quot; data-cropx2=&quot;1280&quot; data-cropy1=&quot;0&quot; data-cropy2=&quot;580.3584229390681&quot; data-ratio=&quot;0.453125&quot; data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/wibWV1DB7tWINE7dHffUN1wQZG6icOIpZo217bHkjLXud50FYVCNwq6o7h6nG4erXgLbS6YQpboIysbjhc61xEgQ/640?&quot;/&gt;&lt;br/&gt;&lt;/p&gt;
&lt;section class=&quot;&quot; data-mpa-template-id=&quot;1398939&quot; data-mpa-color=&quot;null&quot; data-mpa-category=&quot;fav&quot; helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; sans=&quot;&quot; gb=&quot;&quot; yahei=&quot;&quot; ui=&quot;&quot; arial=&quot;&quot; sans-serif=&quot;&quot; justify=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot; readability=&quot;2&quot;&gt;&lt;p&gt;&lt;span&gt;PC观看地址：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;https://campus.swarma.org/gpac=10406&lt;/span&gt;&lt;/p&gt;
&lt;/section&gt;
</description>
<pubDate>Tue, 04 Dec 2018 09:43:00 +0000</pubDate>
<dc:language>zh-CN</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.jintiankansha.me/t/pyTQCuYVcR</dc:identifier>
</item>
</channel>
</rss>