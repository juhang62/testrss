<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="css/feed.xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/" xmlns:og="http://ogp.me/ns#">
<channel>
<atom:link rel="self" href="http://192.168.1.4/fivefilters/makefulltextfeed.php?url=feed43.com%2Fchaoscruiser-jtks.xml&amp;max=5&amp;links=preserve&amp;exc=1" />
<atom:link rel="alternate" title="Source URL" href="http://feed43.com/chaoscruiser-jtks.xml" />
<atom:link rel="related" title="Subscribe to feed" href="http://www.subtome.com/#/subscribe?feeds=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed43.com%252Fchaoscruiser-jtks.xml%26max%3D5%26links%3Dpreserve%26exc%3D1&amp;back=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed43.com%252Fchaoscruiser-jtks.xml%26max%3D5%26links%3Dpreserve%26exc%3D1" />
<title>混沌巡洋舰</title>
<link>http://www.jintiankansha.me/column/ultiWL8Axg</link>
<description>混沌巡洋舰 - 今天看啥</description>
<ttl>360</ttl>
<item>
<title>大脑的自由能假说-兼论认知科学与机器学习</title>
<link>http://www.jintiankansha.me/t/94BvzOP4G6</link>
<guid isPermaLink="true" >http://www.jintiankansha.me/t/94BvzOP4G6</guid>
<description>&lt;p&gt;如果大脑如何运作的机理可以和热力学一样系统完整完美解释， 那这个理论将是物理学家的终究梦想。而有一篇神文险些胜利。这套理论可以叫自由能大法，如果你通读此文， 也会感觉到一种脑科学， 人工智能， 物理学， 甚至经济学都打通的感觉，然而， 估计99%的物理系读者都很难读通此文（The free-energy principle: a unified brain theory）&lt;/p&gt;

&lt;p&gt;什么是物理里的自由能法则？  一句话说就是：  &lt;strong&gt;任何处于平衡状态的自组织系统均趋于自由能极小的状态。&lt;/strong&gt; 这话是什么意思？ 自由能又是什么？  自由能和大脑有啥关系？&lt;/p&gt;

&lt;p&gt;自由能是什么？ 自由能的物理公司E-TS极为简洁，E是能量 ，S是熵。 统计物理说， 与外界具备能量交换的系统（一杯放在桌上的热水，底下放着一块冰糖）处于平衡状态下，则自由能最小（水温下降，冰糖扩散）， 指的是一个能量尽可能小熵尽可能大的状态。 当水温下降到室温， 冰糖均匀扩算， 此时水分子和外界环境的整体所能够取得的微观状态数最多， 也就是最大概然状态，或者说稳态。好比一个教室里没有老师，学生就逐渐的变得乱遭遭的，这个乱遭遭的状态就是稳态。 自由能最小是热力学第二定律下系统与外界环境相互作用的法则。&lt;/p&gt;

&lt;p&gt;生物系统呢？ 生物系统和水这种系统恰好相反，因为它们是开放的非平衡耗散系统，它们所遵守的法则是趋于有序和结构确定的状态， 相当于一个严厉的老师管制下的教室， 同学工作井井有条（这样的状态需要外界输送能量，如老师的工资）。所以我们经常说生物遵守反方向的热力学第二定律-即产生和维持秩序，而紧闭大多数自由状态。 如果某个时刻你开始控制不住自己， 那也就是衰老的起点。&lt;strong&gt;刚刚好，生物系统也可以被一个形式类型自由能最小的定律结合。表现在认知系统，就是学习过程！ 你读过之后就会立刻发现它和机器学习的联系。  &lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt; &lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;简单的看，你可以把你的脑子想成刚才说的那杯水，外部环境和这杯水具有一种能量交互关系，正好对应你的脑子通过眼睛和耳朵这样的东西采集外部的信息（感知）。这杯水会越来越趋于室温， 你的脑子像这杯水一样与外界交换能量和信息， &lt;strong&gt;只是， 这个过程中，你的脑子对外界的信息越来越丰富， 它不仅是被动的采纳，还要主动的预测和做出行为。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;那么看看我们通常说的大脑对外界信息处理过程包含以下几个方面，感知（sensation）决定计入哪些数据， &lt;strong&gt;cognition&lt;/strong&gt;（认知）对这些数据进行处理如分类， &lt;strong&gt;action&lt;/strong&gt;（行为）一个由&lt;strong&gt;cognition&lt;/strong&gt;的分类导致的决策， &lt;strong&gt;motion&lt;/strong&gt;（运动），一系列的行为组成motion。&lt;/p&gt;

&lt;p&gt;我们来看看这个过程是怎么发生的。 首先， 这一切行为的综治是为了&lt;strong&gt;最大化生存可能性&lt;/strong&gt;（maximize existence）， 外部世界充满危险， 如果把生物所有的行为可能性做成一个状态空间， 那么只有极少数是可以保证生存的， 生物越能够绑定在这极少数状态里， 生存机会就越大， 这也是生物需要抵抗热力学第二定律的理由。那么如何不跑偏呢？&lt;/p&gt;

&lt;p&gt;一方面我们有&lt;strong&gt;基因编码&lt;/strong&gt;（genetic encoding），使得我么的&lt;strong&gt;表现型&lt;/strong&gt;（phenotype）只能在一个有限的范围里（由一个条件概率函数P(pIg) 描述），这套编码已经在我们的祖辈自然选择里被遗传下来，去掉了大部分不适宜生存的可能， 比如长出三头六臂。&lt;/p&gt;

&lt;p&gt;另一方面，作为具有认知能力的动物，能够保证对生存最有利的状态的办法就是学习，整个对大脑外界信号的处理都可以通过&quot;学习”来认识， 请看下图（请始终想着&lt;strong&gt;机器学习&lt;/strong&gt;）。&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;origin_image zh-lightbox-thumb&quot; data-ratio=&quot;1.3583333333333334&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcdmt7U3YGvq0BYUCp5icmmgaRC6jiaibSE5gVBKV3TSImUHWkxAN9GdaZ04neoGN4IRibMN0W8JgEZycA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;600&quot; width=&quot;958&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;大脑的自由能最小定律说， 学习的状态就是使得 1，通过不断调整行为得到符合大脑预期的感知状态（Accuracy）  2， 大脑内部的状态能够更加准确的匹配外部世界的变化 ，不至于出现没有预期到的状况（Divergence）。&lt;/strong&gt; 两部分何在一起使得上图定义的大脑的自由能函数最小。这个原则的威力是巨大的， 它可以告诉你如此多你为什么要这么想， 这么看，尽管你平时从未知觉。 比如为什么你看到你想看的， 为什么你想到的东西又总在随时客观情景调整。&lt;/p&gt;

&lt;p&gt;注： 第一项D中p是已知生物的感知得到某种外部世界状态的概率， q是已知大脑内部状态生物猜测到某外部世界状态的概率 ， D是p和q两个概率分布函数的距离， 指的是大脑猜测的真实之间的距离。 第二项是对数项内的p是已知外部世界的变化得到某种感知状态的概率。&lt;/p&gt;

&lt;p&gt;外界的信息是无穷多的，我们的脑子就那么多， 选择哪些信息录入，就显得特别重要。 感知的过程， 就是一个数据采样的过程， 机器学习的同学都知道， 开始录入什么样的特征对机器学习是具有决定性的一步，而感知也一样， 生物要做到的是要取样哪些数据。 所以感知绝非被动的过程。&lt;/p&gt;

&lt;p&gt;这里的关键是要把&lt;strong&gt;感知&lt;/strong&gt;，认知和行为放在一个循环里理解。这里理解的框架就是&lt;strong&gt;贝叶斯决策&lt;/strong&gt;。贝叶斯公式把事物之间的联系表现为一系列的条件概率关系， 并根据新的证据不停调整条件概率，最终我们要优化我们想得到的结果， 比如此处的生存机会， 就是通常生物系统优化的量， 为了优化生存机会，我们只有少数几个想要达到的结果， 我们需要产生一个使得这一系列结果机会最大的决策机制（所谓我们不是为思考而思考，而是为生存而思考）， 这一切决定了感知和认知的过程。&lt;/p&gt;

&lt;p&gt;那么我们是如何通过学习来找到这个机制的呢？ 其实你会发现，这就是一个模型选择过程&lt;strong&gt;（model selection）&lt;/strong&gt;恰恰符合机器学习的本质。所谓认知，即找到一个预测性模型使得感知得到的信号可以预测出未来外界物体的运动， 从而趋利避害。 所谓感知，就是寻找最能够提供给这一模型预测效力的有用证据&lt;strong&gt;（feature engineering）&lt;/strong&gt;。一句话说，世界很大， 我只要最和我的游戏相关的。&lt;/p&gt;

&lt;p&gt;那么行为呢？ 我们的行为最终还是要归之于感官，所谓人生食色性也。行为如果带来香甜的巧克力或可爱的美女，则得到嘉奖，这是符合你的理想的生存预期的。一个非常有趣的例子说明认知模型：一个黑暗里摸索的人， 他不停猜测前面是什么， 它会主动伸手去摸索，证实他的想法，一般如果我们发现我们的证实与内心的想法不符，则不停探索，知道符合它的预期，这就是一个简单的认知模型。&lt;/p&gt;

&lt;p&gt;这里面我们看到认知模型包含两方面， 一个是感知和行为所获取的外部世界的状态， 一个是大脑内部认知过程的内部状态（模型）。 这个内部模型不停预测每个一个感官背后的动因， 和所蕴含的未来变化， 而行为本身则趋向于那些有利生存的结果。学习的目的就是让那么内部状态的模型更准确（预测精准），另一方面让行为决策获取更多对生存有利的证据。   如果模型的预测不正确， 则行为决策无法得到正确的结果。&lt;/p&gt;

&lt;p&gt;这一原则所得到的启示十分强大，可以直接打通认知科学和机器学习的诸多方面：&lt;/p&gt;

&lt;p&gt;1， &lt;strong&gt;贝叶斯大脑假设&lt;/strong&gt;： 如之前提到的， 大脑是部贝叶斯机器。 贝叶斯推断和决策的核心即由最新采纳的证据更新先验概率得到后验概率。 认知科学的核心（&lt;strong&gt;Perception&lt;/strong&gt;）就是这样一个过程。&lt;/p&gt;

&lt;p&gt;这里再说两句认知，认知的过程用机器学习的语言说就是用大脑的内部变量来模拟外部世界， 并希望建立内部世界和外部的一个一一映射关系。 这里我们说认知的模型是一个概率模型，并且可以被一系列条件概率所描述。如果用一个形象的比喻来说， 你可以把你的大脑看成一个可以自由打隔断的巨大仓库， 你要把外部世界不同种类的货放进不同的隔断，你的大脑内部运作要有一种对外界真实变化的推测演绎能力， 即随时根据新的证据调整的能力， 你和外界世界的模型匹配的越好， 你的脑子就运转越有效率。 认知是对外部世界运动的一种编码， 你可以立刻联想到机器学习里的表征方法（&lt;strong&gt;representation&lt;/strong&gt;）， 如果你熟悉RNN或CNN的embeding过程， 就会有一种豁然开朗的感觉， 虽然一时并不知有鸟用。&lt;/p&gt;

&lt;p&gt;更多阅读&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651381942&amp;amp;idx=1&amp;amp;sn=c29a10c721f319546c503c954c8e4f21&amp;amp;chksm=84f3cef7b38447e151560d9b2f80bf1f1bc912911842428a7cd8d6928114a0f47b05fe899188&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data_ue_src=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651381942&amp;amp;idx=1&amp;amp;sn=c29a10c721f319546c503c954c8e4f21&amp;amp;chksm=84f3cef7b38447e151560d9b2f80bf1f1bc912911842428a7cd8d6928114a0f47b05fe899188&amp;amp;scene=21#wechat_redirect&quot;&gt;如何向你奶奶解释机器学习是什么&lt;/a&gt;&lt;br /&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651381855&amp;amp;idx=1&amp;amp;sn=04aeb9e0fa6d5d0866a852a276f272cf&amp;amp;chksm=84f3ce1eb38447083dcbdd611ea13287148885612be48fdeae276e51b1503e6c7e2f6e0ba2bc&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data_ue_src=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651381855&amp;amp;idx=1&amp;amp;sn=04aeb9e0fa6d5d0866a852a276f272cf&amp;amp;chksm=84f3ce1eb38447083dcbdd611ea13287148885612be48fdeae276e51b1503e6c7e2f6e0ba2bc&amp;amp;scene=21#wechat_redirect&quot;&gt;what is Bifurcation&lt;/a&gt;&lt;br /&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651383823&amp;amp;idx=1&amp;amp;sn=68d85261e3f0cb1c680112a4cb034cc2&amp;amp;chksm=84f3c64eb3844f5842ec848d552ab20f9052a0a1908c8cc0a3d66ff0eaa44aa1a011858b3e37&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot;&gt;机器学习的本质： 理解泛化的新观点&lt;/a&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; rgb=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;&gt;作者简介&lt;/p&gt;
&lt;pre contenteditable-directive=&quot;&quot; mm-paste=&quot;&quot; ng-blur=&quot;editAreaBlur($event)&quot; ng-model=&quot;editAreaCtn&quot; ng-click=&quot;editAreaClick($event)&quot; ng-keyup=&quot;editAreaKeyup($event)&quot; ng-keydown=&quot;editAreaKeydown($event)&quot;&gt;
&lt;span&gt;作者许铁，微信号：ironcruiser &lt;/span&gt;&lt;br /&gt;&lt;span&gt;法国&lt;/span&gt;&lt;strong&gt;巴黎高师&lt;/strong&gt;&lt;span&gt;物理硕士 ，&lt;/span&gt;&lt;strong&gt;以色列理工大学&lt;/strong&gt;&lt;span&gt;（以色列85%科技创业人才的摇篮, 计算机科学享誉全球）计算神经科学博士，巡洋舰科技有限公司创始人,   《机器学习与复杂系统》纸质书作者。曾在香港浸会大学非线性科学中心工作一年 ，万门童校长好战友。&lt;br /&gt;&lt;/span&gt;
&lt;/pre&gt;






</description>
<pubDate>Mon, 10 Dec 2018 03:23:35 +0000</pubDate>
<dc:language>zh-CN</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.jintiankansha.me/t/94BvzOP4G6</dc:identifier>
</item>
<item>
<title>Alpha Zero登上Science封面- 听铁哥浅析阿尔法元</title>
<link>http://www.jintiankansha.me/t/NNQW9Ngv1Z</link>
<guid isPermaLink="true" >http://www.jintiankansha.me/t/NNQW9Ngv1Z</guid>
<description>&lt;section helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; sans=&quot;&quot; gb=&quot;&quot; yahei=&quot;&quot; ui=&quot;&quot; arial=&quot;&quot; sans-serif=&quot;&quot; justify=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;&gt;&lt;span&gt;&lt;strong mpa-from-tpl=&quot;t&quot;&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;导语&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;section helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; sans=&quot;&quot; gb=&quot;&quot; yahei=&quot;&quot; ui=&quot;&quot; arial=&quot;&quot; sans-serif=&quot;&quot; justify=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot; solid=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;&gt;&lt;section readability=&quot;2.5&quot;&gt;&lt;section readability=&quot;5&quot;&gt;&lt;p&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;从1997年“深蓝”击败国际象棋冠军卡斯帕罗夫，到2017年AlphaGo击败围棋冠军柯洁，AI 在与人类对抗训练中不断提高，而脱胎于 AlphaGo 的 AlphaZero 则完全脱离了人类棋谱的束缚，通过自我博弈，成为多种棋类游戏的王者。在最新一期 Science 中，首次全方位揭示了 AlphaZero 背后的原理。&lt;/span&gt;&lt;/p&gt;
&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;
&lt;p&gt;&lt;img data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCy68f4biajmzchV6stRScXfF9pGthBXRAX51xOibqwd9XYlre3OqVF7SibDeicR71zoFUeJGKhpXSMibQ/640?&quot; class=&quot;&quot; data-ratio=&quot;1.2716763005780347&quot; data-w=&quot;346&quot;/&gt;&lt;/p&gt;

&lt;p&gt;阿尔法元超越自己的大哥-阿尔法狗。 这一代算法被deepmind命名为Alphago Zero， 中文阿尔法元，“元” 含有起点，创世之意。 总之，就是从零开始 ，其实这个元字用意很深， 一方面说， 这个算法是不需要人类数据指导，也不需要它哥哥（阿法狗）指导，就自己演化出来。 另一方面也可以理解为它可以开启新纪元。&lt;br/&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;dt5il-0-0&quot;&gt;当然， 同时谷歌也宣传了它的TPU， 只需要4台TPU运行几天的功夫就可以了。 那么， 这次的大新闻是不是一个谷歌精心策划的商业广告，还是真的隐藏天机。铁哥就来给大家解读一下阿法元和其背后的深度强化学习，看看这次的大新闻算不算得从零到一。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;8ibcs-0-0&quot;&gt;如果大家了解计算机学下棋的事情，就会了解到几十年前，我们就已经用穷举法来解决棋类问题了，在国际象棋这类游戏里， 计算机会以比人脑快的多的速度推演两军对峙的未来，在运用零和游戏里固有的减少风险策略， 在1996年就可以让人类棋手甘拜下风。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;acaae-0-0&quot;&gt;穷举法不适用围棋，因为跟其灿若宇宙星辰的可能性搜索空间（每一步19*19可能，若干步骤后就是天文数字，这种由于可能性爆炸导致的悲剧也称为维度灾难），被称为人工智能界的mission impossible。 而在2015年， 梦幻被粉碎，原因在于深度卷积网络的幽灵终于潜入到了棋类游戏领域。 深度学习最擅长把高维度的问题自动的降维，从而解决了刚说过的维度灾难，如宇宙星辰般的搜索空间瞬间被压榨到很小，在此时的机器算法面前， 围棋无非是一个当年的国际象棋。&lt;/span&gt;&lt;/p&gt;


&lt;p&gt;&lt;img class=&quot;Image FocusPlugin--unfocused Image--isBlock&quot; data-ratio=&quot;0.5&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibccPns0lxHhsOFyp82BuMcps0Xjicz0kQJbhFWNb3Dev590WibnD2QZA8JbS69KEBdNIGTlzLDicZu2fQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;600&quot; height=&quot;300&quot; width=&quot;600&quot;/&gt;&lt;/p&gt;


&lt;p&gt;&lt;span data-offset-key=&quot;7ufh3-0-0&quot;&gt;然而当时立下首要功勋的深度卷积网络，却需要学习三千万组人类数据进行训练， 而整个训练过程需要的能量据说要耗费几吨煤炭。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;19ekg-0-0&quot;&gt;人们说，你秒杀人类智商的阿法狗无非是比人类看棋谱的速度快，难道还真的懂围棋吗？ 你所作的顶多是模仿，里面的强化学习到底有多少作用， 真的不知道。  &lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;389o-0-0&quot;&gt;然而今天，阿法元却能够在不用那3000万数据的时候来个完胜阿法狗。从人工智能的技术角度看， 这是强化学习的胜利， 在不进行监督学习的情况下， 就可以达到一个高于人类的境地。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;cf1o3-0-0&quot;&gt;为什么强化学习如此重要？ 让我们先比较一下监督学习和强化学习的基本思想。 监督学习， 强化学习和无监督学习是机器学习的三大框架。 某一个意义说，监督学习是给定输入和输出，机器来学习输入和输出的关系，一个好的监督学习算法犹如一个预言家， 它能够根据自己之前见过的输入输出关系来预测未知的输入。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;2psih-0-0&quot;&gt;强化学习呢？ 强化学习的三元素是状态，行为和环境奖励。 强化学习条件下， 学习者每一步看到的是它决策的行为结果， 然后导致下一步行动，为了最终游戏的胜利。 一句话说：强化学习强在决策。 监督学习是预言家，强化学习是决策家。&lt;/span&gt;&lt;/p&gt;


&lt;p&gt;&lt;img class=&quot;Image FocusPlugin--unfocused Image--isBlock&quot; data-ratio=&quot;0.48833333333333334&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibccPns0lxHhsOFyp82BuMcpsV4Mu5XbPHGfej0xjDpj72EibTct0ibav9n1Zzn4icv4IWzBMoaWTpialRA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;600&quot; height=&quot;293&quot; width=&quot;600&quot;/&gt;&lt;/p&gt;


&lt;p&gt;&lt;span data-offset-key=&quot;cj562-0-0&quot;&gt;我们一比就明白， 强化学习更像是一个日常决策中的人。我们看到一个老虎，监督学习帮你识别出来它是老虎，那么你可能刚说出来就被它吃了。 而强化学习告诉你赶紧跑，你可能活下来。 &lt;strong&gt;监督学习让你成为复读机，而强化学习让你称之为生物。&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;


&lt;p&gt;&lt;img class=&quot;Image FocusPlugin--unfocused Image--isBlock&quot; data-ratio=&quot;0.29333333333333333&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibccPns0lxHhsOFyp82BuMcpsRxyf7PuFXI3NXVG0IB5N90pmc0QIdZBnEibf4yWCUwhichupUZgjtQkQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;600&quot; height=&quot;176&quot; width=&quot;600&quot;/&gt;&lt;/p&gt;


&lt;p&gt;&lt;span data-offset-key=&quot;bfpem-0-0&quot;&gt;再深一点想，其实学习是为了生存，是赢得game of life（想想那些不太读书就能过得很好生活的真是深谙强化学习的道理）。 强化学习赋予机器以灵魂。监督学习的那些任务反而是在这个宗旨之下产生的。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;80nhn-0-0&quot;&gt;回到围棋， 我们看看强化学习如何决策： 我们在好好理解一些一下“强化” 二字， 强化的意味是： 强化优势经历，反过来，就是弱化劣势经历。当你走了一部棋导致不好结果，之后被选入这一步棋的概率就降低， 而导致胜利的选择被不停的强化，直到你每次都延着最佳路径前进。这听起来很像进化， 而与进化的区别是，进化是严酷的客观环境对随机变化的生物的选择，而强化学习里的单元可以通过梯度下降主动调整策略。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;a1bc6-0-0&quot;&gt;既然强化学习那么牛， 为什么阿法狗还用监督学习这个拐棍呢？一句话说，强化学习太难了！&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;8s35-0-0&quot;&gt;&lt;span data-text=&quot;true&quot;&gt;强化学习有两大难题：&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;ev461-0-0&quot;&gt;1， 奖励时间的不确定性： 今天的努力，可能明天回报， 可能十年后才有回报, 今天带来奖励的事情，明天可能就导致悲剧（比如吸毒很爽未来地狱） 对于游戏里的每一次决策，　你都无法获得立即的反馈，相比监督学习时时可以得到对和错的答案，这个信息实在太弱了， 用来指导学习，那是慢慢的（如何利用这个或有或无的信息，强化学习的一系列方法围绕而来，比如Q-learn）。 　&lt;/span&gt;&lt;/p&gt;
&lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;/&gt; 
&lt;p&gt;&lt;span data-offset-key=&quot;2l540-0-0&quot;&gt;2， 探索与收益的平衡难以掌握： 有的人一辈子抱残守缺，７岁玩泥巴未来就永远玩泥巴。 有的人一辈子都在探索不同的方向，但是换来换去最终庸庸碌碌。而只有恰当把握探索收益平衡的，比如说27岁前读书去不同国家，27岁开始认准一个方向成为大佬，30岁前各种风流倜傥，30岁选个知书达理另一半从一而终。 强化学习始终面临是探索更多空间，还是开始用现在经验收益的矛盾。　&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;3cja1-0-0&quot;&gt;&lt;span data-text=&quot;true&quot;&gt;这两点放到围棋这个搜索空间犹如宇宙星辰的游戏里，估计学习时间也要用生物进化的尺度算， 然而阿尔法元所用的强化学习算法，号称解决了这个问题。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;ajql2-0-0&quot;&gt;仔细看它和它哥哥阿尔法狗的差别没那么大， 只不过这一次的神经网络完全由强化学习训练， 和蒙特卡罗树得融合可以算是完美。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;6716o-0-0&quot;&gt;之前的阿尔法狗有策略和估值网络（都是深度卷积网络），策略负责把棋盘现在的状态转化为可能的行为概率， 这个东西被称为策略（policy，是由每个可能的行为概率构成的向量，简称策略向量） ，估值则是输入目前的棋盘状态得到最终结果的概率。 这两个网络在这一次被合成一个巨大的深度残差网络（卷积网络的一种）。&lt;/span&gt;&lt;/p&gt;


&lt;p&gt;&lt;img class=&quot;Image FocusPlugin--unfocused Image--isBlock&quot; data-ratio=&quot;0.9314079422382672&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibccPns0lxHhsOFyp82BuMcpsoH0hA9BP2pujxMyw7ZHia69xRjmMAibl7JhVWWsiaCaE9FebZrEpP0NKg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;554&quot; height=&quot;516&quot; width=&quot;554&quot;/&gt;&lt;/p&gt;


&lt;p&gt;&lt;span data-offset-key=&quot;7nudg-0-0&quot;&gt;Nature图： 深度卷积网络计算概率&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;8uljh-0-0&quot;&gt;深度卷积网络擅长整体对图像信息进行编码， 我们可以把这个巨大的残差网络所作的事情看成白日梦者对未来的总体规划。 多层卷积本身的天性决定它擅长从这种19*19的格子图像总结出意思来，强化学习的信息一旦可以训练网络，就会产生意想不到的效果。而之后MCTS蒙特卡罗树则对这种初步的结论进行实践修正。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;d3a31-0-0&quot;&gt;在这里回顾一下蒙特卡洛树是怎么工作的，说到蒙特卡洛， 这是大名鼎鼎的随机抽样方法。所谓树，大家一定可以想到决策树，树的节点是某一刻的状态，而枝杈代表一个决策（行为），而这里的蒙特卡洛树即生成整个决策树的过程，通过大量的实验（犹如蒙特卡洛抽样的过程）得到每个决策行为取胜的概率。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;d3a31-0-0&quot;&gt;决策树从一个状态s出发，每个分支代表一个可能行为（a），而且有一个代表最终赢率的分数与之对应，我们选择分数最高的那个行为继续展开（下一次行动），得到新的状态，用相同的规则行动，直到游戏结束， 最终赢的走法加一分， 输的走法减一分，依次往复模拟无数次后，就会得到从s出发不同决策赢得比赛的概率。 这个过程酷似进化选择算法， 就是让那些有优势的选择有更高的繁殖子代概率， 最终胜出。虽说这仅仅是阿尔法元的一小步，却包含了著名的Q-learning和马尔科夫决策树的思想。  &lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;qrgk-0-0&quot;&gt;我们来看每一步决策神经网络和蒙特卡洛树是怎么结合的： &lt;/span&gt;&lt;span data-offset-key=&quot;qrgk-0-1&quot;&gt;&lt;span data-text=&quot;true&quot;&gt;决策分为搜索阶段和行为阶段&lt;/span&gt;&lt;/span&gt;&lt;span data-offset-key=&quot;qrgk-0-2&quot;&gt;。假定现在我处在状态s，在搜索阶段神经网络对我所能做的所有行为（a）进行根据对未来的猜测进行预判&lt;/span&gt;，生成赢棋的概率v和策略向量p（s，a）。 当然这个预判开始很不靠谱， 蒙特卡洛树在此基础通过无数次模拟实践展开来（注意均是在状态s上），来实践出靠谱的策略向量pi（s，a）。&lt;/p&gt;

&lt;p&gt;有了神经网络的帮助，蒙特卡罗树展开不是瞎展开， 也不是从零开始，每一个树的新分支上，我们都通过神经网络给它一个是正确步骤的先验概率（P）和初始的赢率（V），代表走它通向胜利的概率。在神经网络助攻下，蒙特卡洛树可以更快的更新策略向量（每个行为选择的概率）。此时搜索阶段结束， 我们从这个策略向量里通过抽样得到我们最终进行的行为，是为行为阶段。 这下一步棋还真不容易啊！&lt;/p&gt;


&lt;p&gt;&lt;img class=&quot;Image FocusPlugin--unfocused Image--isBlock&quot; data-ratio=&quot;0.26666666666666666&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibccPns0lxHhsOFyp82BuMcpsiajKyaOtibGwOv1hLBtLtjgNtSAAYibPBwNaiapFvJPyWb8FFcsTOWCkibg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;600&quot; height=&quot;160&quot; width=&quot;600&quot;/&gt;&lt;/p&gt;


&lt;p&gt;&lt;span data-offset-key=&quot;77j4h-0-0&quot;&gt;Nature图： 策略更新的方法&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;a1pa3-0-0&quot;&gt;最终当游戏结束的时候，神经网络的权重开始更新，这个更新的过程里，我们把整个游戏的过程分成很多小段， 比较神经网络预测的概率和蒙特卡洛树算出来的（策略向量之间的差异），以及预测结果与最终结果的差距进行梯度下降（梯度由如下公式得到，此处混合之前的策略和估值网络）。&lt;/span&gt;&lt;/p&gt;


&lt;p&gt;&lt;img class=&quot;Image FocusPlugin--unfocused Image--isBlock&quot; data-ratio=&quot;0.14333333333333334&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibccPns0lxHhsOFyp82BuMcpsWbnhR49iaFicbgX6lQ8jibSQyN8WvXlZ5cYhTkh1u7EibTbDcbDMWal7Dg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;600&quot; height=&quot;86&quot; width=&quot;600&quot;/&gt;&lt;/p&gt;



&lt;p&gt;&lt;span data-offset-key=&quot;9jrnd-0-0&quot;&gt;这样周而复始，我们可以推断，最终神经网络的预测将越来越靠谱，和蒙特卡洛树给出的分析越来越一致。 而围棋的套路也会被一一发明出来，所谓无师自通。&lt;/span&gt;&lt;/p&gt;



&lt;p&gt;&lt;img class=&quot;Image FocusPlugin--unfocused Image--isBlock&quot; data-ratio=&quot;0.8633333333333333&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibccPns0lxHhsOFyp82BuMcpsQTc3L6c3EdUyfKoVVa0CpgQciacvMYiaHYcdDGYFQaps8Q0NOrXqoJJQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;600&quot; height=&quot;518&quot; width=&quot;600&quot;/&gt;&lt;/p&gt;


&lt;p&gt;&lt;span data-offset-key=&quot;5ibte-0-0&quot;&gt;Nature图： 看看右下的图，是不是很像人类选手常用的招！  &lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;9c2ea-0-0&quot;&gt;为什么说阿尔法元敢叫元？ 如果从技术角度看，这一次的阿尔法元没有那么多新的东西，而是在之前基础上让强化学习进行的更彻底了，然而它所展示的深度强化学习的应用未来，却是十分诱人的。&lt;/span&gt;&lt;/p&gt;



&lt;p&gt;&lt;img class=&quot;Image FocusPlugin--unfocused Image--isBlock&quot; data-ratio=&quot;0.35&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibccPns0lxHhsOFyp82BuMcpsRGYzWDxqCfib19LOQ0gfBSD7qFIIaSQ3bAfbA6ibr02JT5uPI4Oic2wiaw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;600&quot; height=&quot;210&quot; width=&quot;600&quot;/&gt;&lt;/p&gt;


&lt;p&gt;&lt;span data-offset-key=&quot;fmjkn-0-0&quot;&gt;图： 强化学习的胜利（蓝）对比监督学习（紫）和监督+强化学习（虚线）&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;987es-0-0&quot;&gt;首先，我们看到， 并不是每一件机器学习的事情， 都需要和数据，尤其是需要大量人力的标注数据死磕， 而是可以通过恰当的设立模拟器（比如此处用到的蒙卡树） 来弥补。阿尔法元不是不需要数据，而是数据都是自己模拟产生的。 模拟+深度强化学习， &lt;strong&gt;在简单的游戏规则下，一些复杂的行为范式可以进化出来，而且可以比人类设计的还好&lt;/strong&gt;， 这， 你就可以大开脑洞了。&lt;/span&gt;&lt;/p&gt;
&lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;/&gt; 
&lt;p&gt;&lt;span data-offset-key=&quot;ckimk-0-0&quot;&gt;这件事在很多设计性的工作里实在是太诱人了。 无论是设计新材料，建筑，还是衣服，&lt;strong&gt;这些可变维度很高的事物，你都可以想象设立一个模拟仿真环境，再设立一个相应的神经网络去做各种尝试，最终设计出的结果有一个奖惩函数反馈，来让这个网络来学习。&lt;/strong&gt;这就打破了深度学习创业只和手里有大量数据的垄断者相关的梦魇。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;8k7da-0-0&quot;&gt;这里的深度强化技术， 也才只展示了冰山一角， 在一类被称为SLAM的技术上， 深度强化学习被证明了强大的控制能力， 它能够驱动机器人在非常复杂的空间里进行探索无需GPS，对于这一类深度学习任务， 有别于alphago的任务，因为围棋属于完全信息的博弈， 而真正的空间探索，是通过感知系统探测到的不完全信息， 通过记忆在时间尺度上的综合，这一点，只有搬出大名鼎鼎的LSTM来对付了。&lt;/span&gt;&lt;/p&gt;


&lt;p&gt;&lt;img class=&quot;Image FocusPlugin--unfocused Image--isBlock&quot; data-ratio=&quot;0.6333333333333333&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibccPns0lxHhsOFyp82BuMcpskhySEVQXKxWy56LKHsAJ0XXnA0hdiaAua0iaZrdWHaTzGDjdAO0xMQibQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;600&quot; height=&quot;380&quot; width=&quot;600&quot;/&gt;&lt;/p&gt;



&lt;p&gt;&lt;span data-offset-key=&quot;4nqss-0-0&quot;&gt;能够控制运动的深度强化学习，迟早会改变工业界，它不仅是无人车里的核心技术， 更是对话，推荐系统， 金融交易， 甚至是图像识别的利器，几乎各类需要监督学习的事情，说到底强化学习都有实力。 你如果制造一个聊天机器人， 你当然希望它能够揣测你的意图和你谈情说爱而不是背书。 你要一个推荐系统， 你当然不需要它天天给你推你刚看过的小黄片，而是带着你探索一段BBC-性的秘密。  所以， 强化学习， 是人工智能的大势所趋啊。&lt;/span&gt;&lt;/p&gt;


&lt;p&gt;&lt;img class=&quot;Image FocusPlugin--unfocused Image--isBlock&quot; data-ratio=&quot;0.66&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibccPns0lxHhsOFyp82BuMcpsjUU1ewb6V3XTQvWIy5IuR5tHXrIBWdnPzhAQcE4h8zY3CB0KJXVAOQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;600&quot; height=&quot;396&quot; width=&quot;600&quot;/&gt;&lt;/p&gt;

&lt;p&gt;图：强化学习下的装配空间&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;Image FocusPlugin--unfocused Image--isBlock&quot; data-ratio=&quot;0.5631970260223048&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibccPns0lxHhsOFyp82BuMcps8ic1kUm8dgUofdWt4AT4wib66t7NzYhTzVm1ribBxPmeFjgFB0jJhgjPA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;538&quot; height=&quot;303&quot; width=&quot;538&quot;/&gt;&lt;/p&gt;

&lt;p&gt;图： 强化学习下的物流车间&lt;/p&gt;





&lt;p&gt;&lt;span data-offset-key=&quot;evrgp-0-0&quot;&gt;更有甚者，我们可以设立一个具有类似地球的物理环境的地方，让配备了深度强化学习系统的虚拟生物进行各种活动，看它们能否利用这个环境发现和利用其中的物理定律。&lt;/span&gt;&lt;/p&gt;
&lt;pre contenteditable-directive=&quot;&quot; mm-paste=&quot;&quot; ng-blur=&quot;editAreaBlur($event)&quot; ng-model=&quot;editAreaCtn&quot; ng-click=&quot;editAreaClick($event)&quot; ng-keyup=&quot;editAreaKeyup($event)&quot; ng-keydown=&quot;editAreaKeydown($event)&quot;&gt;
&lt;span&gt;&lt;br/&gt;&lt;/span&gt;
&lt;/pre&gt;
&lt;pre contenteditable-directive=&quot;&quot; mm-paste=&quot;&quot; ng-blur=&quot;editAreaBlur($event)&quot; ng-model=&quot;editAreaCtn&quot; ng-click=&quot;editAreaClick($event)&quot; ng-keyup=&quot;editAreaKeyup($event)&quot; ng-keydown=&quot;editAreaKeydown($event)&quot;&gt;
&lt;img data-s=&quot;300,640&quot; data-type=&quot;jpeg&quot; data-ratio=&quot;0.10966542750929369&quot; data-w=&quot;538&quot; class=&quot;&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz/dcEP2tDMibccdYT8ViaXic1q1ibC3U0Ub0WhaaX0dxl5oRO3YicRx7fSozVkP7Z5UfiaQdwyaxxEM5AZaMAGHjY4yS4Q/640?wx_fmt=jpeg&quot;/&gt;&lt;/pre&gt;



&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; sans=&quot;&quot; gb=&quot;&quot; yahei=&quot;&quot; ui=&quot;&quot; arial=&quot;&quot; sans-serif=&quot;&quot; justify=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;&gt;&lt;span data-offset-key=&quot;4csh-0-0&quot;&gt;铁哥本人的研究目前涉及深度强化学习与RNN的结合， 因此参与课程也是与铁哥结盟， 共同进军未来的深度强化学习世界的机会。&lt;/span&gt;&lt;/p&gt;

&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; sans=&quot;&quot; gb=&quot;&quot; yahei=&quot;&quot; ui=&quot;&quot; arial=&quot;&quot; sans-serif=&quot;&quot; justify=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;&gt;&lt;img class=&quot;&quot; data-ratio=&quot;10.284953395472703&quot; data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-w=&quot;751&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcfqJgX6L51kcnJ07DHpdBzq4CdJ7Pj2yE9q9ZGjIpLAQSMrWe8ricgP18icaBWjc39YTLsPLCvWsJNQ/640?wx_fmt=png&quot;/&gt;&lt;/p&gt;










</description>
<pubDate>Sun, 09 Dec 2018 02:05:53 +0000</pubDate>
<dc:language>zh-CN</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.jintiankansha.me/t/NNQW9Ngv1Z</dc:identifier>
</item>
<item>
<title>人工智能vs人类智能小传</title>
<link>http://www.jintiankansha.me/t/QW8H2qTxdK</link>
<guid isPermaLink="true" >http://www.jintiankansha.me/t/QW8H2qTxdK</guid>
<description>&lt;p&gt; &lt;br /&gt;&lt;/p&gt;
&lt;p&gt;Alphago&lt;span&gt;代表的深度网络人工智能体现了&lt;/span&gt;AI&lt;span&gt;逐步进入未知领域的强大能力，&lt;/span&gt; &lt;span&gt;因此有人堪忧有人喜乐，&lt;/span&gt; &lt;span&gt;却极少有人戳中要害。说AI比人牛是因为它下围棋比人厉害？  &lt;/span&gt;&lt;span&gt; 说AI离真正的智能很遥远&lt;/span&gt;&lt;span&gt;是因为它不能创造吗？&lt;/span&gt;&lt;span&gt;  &lt;/span&gt;&lt;span&gt;是因为它只擅长形式逻辑？&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;是因为它没有自我意识？&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;而深度网络代表的这波人工智能风潮代表的是一种局部的演进，还是未来的一扇大门打开？ &lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;网络上各种似是而非的谣言其实了表现了我们连生物的智能都不了解。 &lt;/span&gt;&lt;span&gt;我们回顾一下神经科学和&lt;/span&gt;&lt;span&gt;AI&lt;/span&gt;&lt;span&gt;的历史，&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;从脑和智能的演进来看这个所谓的人工智能有多聪明。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;要谈这个问题，我们就需要从智能说起，&lt;/span&gt; &lt;span&gt;智能其实分为三个层次，对应丹内特对意识进化的三个分级：&lt;/span&gt; &lt;span&gt;达尔文式造物&lt;/span&gt; &lt;span&gt;，斯金纳式造物，&lt;/span&gt; &lt;span&gt;波普尔式造物&lt;/span&gt; &lt;span&gt;。&lt;/span&gt; &lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.16782334384858044&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz/dcEP2tDMibcfyNibceeGvVKo0qCGicGJ9lQ9J5zzOIxmTUAE4OYfwx25QZ2J2KLUic1lWYkMwelC8Ld30RF0FsibAPQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1585&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;span&gt;智能的第一个层次是进化（达尔文式）&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;，而不是自我意识这些高端装逼的东西。智能的起点是学习，学习即对环境变化做出相应对策。&lt;/span&gt; &lt;span&gt;整个生物进化过程，就是学习的过程。为什么呢&lt;/span&gt;?   &lt;span&gt;你一个小小的细菌，&lt;/span&gt; &lt;span&gt;也可以对环境做出趋利避害的反应，&lt;/span&gt; 并且&lt;span&gt;通过基因突变的方法有点盲目的适应环境，这其实就是用遍历法来选择针环境变化的最佳生存策略，然后通过遗传以及下一代继续试错，将某种策略强化。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt; 阿法狗的策略网络也是类似的道理， 通过对可选策略集合的分析进行局部最优的调整。  &lt;/span&gt;&lt;span&gt;细菌和十亿年的&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;的恶略环境下棋，&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;把对哪些化学物质该如何转化这个信息深深的埋藏在了它的&lt;/span&gt;&lt;span&gt;DNA&lt;/span&gt;&lt;span&gt;里，&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;因此才可以有如今如此从极地到大漠的如此伟大的适应性。&lt;/span&gt;&lt;span&gt; 大自然的这种学习方式可以看做智能1.0版， 缺陷是&lt;span&gt;速度慢和读取数据量小&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;。&lt;/span&gt;我们人类模仿进化的过程创造了进化选择算法， 作为人工智能一个非常基础的部分。 &lt;/span&gt;&lt;/p&gt;

&lt;p&gt; &lt;img class=&quot;&quot; data-ratio=&quot;0.9633333333333334&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz/dcEP2tDMibcdLHShRICbgZxBCicTxwkG5w6L0ey0TaP9JlhvTWCtCtbibA7HWkxicc08bibxZtoUnImDEO9BnhIvWHg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;600&quot; /&gt;&lt;br /&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;智能1.0 版 进化算法  - 遍历所有可能并加以选择，最终得到最适合环境的策略，被动但是在历史长河里极为有效 。  &lt;/span&gt;&lt;/p&gt;




&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.5558060879368658&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz/dcEP2tDMibcer8XuOIJic4IJsP9eJaKyQHp254Ed8xI8Ha2oeQibtzMdDCD4t53KHUb3dkgZiam1EQ0KAtlXhZLZkg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;887&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;达尔文智能主宰了漫长的生物进化史的大部分岁月， 使得单细胞生物逐步具有越来越复杂的性能。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt; &lt;img class=&quot;&quot; data-ratio=&quot;0.76875&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz/dcEP2tDMibcer8XuOIJic4IJsP9eJaKyQHHGQ1lBDhtxl1TdSCiamAoYQeR1j68SiaEex9fKKic8d1h4x30cawuxNiaQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;640&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;阿尔法狗的策略网络（蒙特卡洛树搜索）-- 细菌级别的智慧， 20年前的深蓝却使用它打败了人类国际象棋大师。&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;


&lt;p&gt;&lt;span&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.16782334384858044&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz/dcEP2tDMibcfyNibceeGvVKo0qCGicGJ9lQ9J5zzOIxmTUAE4OYfwx25QZ2J2KLUic1lWYkMwelC8Ld30RF0FsibAPQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1585&quot; /&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;span&gt;下面我想说的是第二阶段的智能，&lt;/span&gt; &lt;span&gt;斯金纳（伟大的行为心理学家）式造物。&lt;/span&gt; &lt;/strong&gt; &lt;strong&gt;斯金纳式造物说的是生物自己能够自主的去学习而非被动的靠基因变异适应环境。&lt;/strong&gt; 这项伟大的创举背后就是&lt;span&gt;大名鼎鼎的神经网络，&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;生物进化几十亿年的历史都是这种被动的适应环境，&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;直到神经网络的出现&lt;/span&gt;&lt;span&gt;一切才悄悄发生变化。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;&lt;span&gt;神经网络的作用简单来看，&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;就是一个分类器，&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;它可以把外界刺激分成好的和坏的，&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;并且趋利避害。拥有这个分类器， 动物终于可以在自然环境面前主动做决策，&lt;/span&gt;  &lt;/span&gt;&lt;span&gt;并且趋利避害。把狮子放在&lt;/span&gt;&lt;span&gt;要躲避的那一堆， 异性放在要接近的那一堆对于动物的生存意义之重大不言而喻。  &lt;/span&gt;&lt;span&gt;这个分类器最开始是储存一些先天的条件反射，&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;比如婴儿见到目前的乳头就要吸。&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;而后来就出现了后天习得的条件反射，&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;比如著名的巴甫洛夫的狗，听到铃声就会分泌口水。没错， 后天形成的条件反射-就是学习的2.0版。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;然而生物神经网络是如何实现这一调整的，却一直是个迷，直到&lt;/span&gt;&lt;span&gt;1940&lt;/span&gt;&lt;span&gt;年&lt;/span&gt;&lt;span&gt;Hebb&lt;/span&gt;&lt;span&gt;提出神经科学的牛顿定律&lt;/span&gt;&lt;span&gt;-Hebbian learning rule&lt;/span&gt;&lt;span&gt;，&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;人们开始了解神经网络是如何实现这一步骤。 &lt;/span&gt;&lt;span&gt;Hebb&lt;/span&gt;&lt;span&gt;&lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;&gt;&lt;/ins&gt;  说组成神经网络的神经元通过不停的调整之间的突触连接来改变对外界刺激的反应，这个变化法则就是同时放电的神经元连接加强（细节来看还与放电的顺序有关）。&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;这就使得被一起激活的神经元形成一个基团，&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;比如狗听到铃声以后被喂食，&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;那铃声这个刺激之前狗可能没有任何反应，而之后就被划分到午餐那一类， 从而形成对铃声的条件反射。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;阿尔法狗深度学习的基本原件人工神经网络也是一个人为敲定的分类器， 用于做决策。 人工神经网络的训练过程同样借鉴了生物神经网络的学习过程， 根据反馈调整神经元之间连接的权重关系， 来实现对外界信号分类方法的改变， 因此调整决策（reinforcement learning 强化学习）。 &lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;&lt;img data-ratio=&quot;1&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz/dcEP2tDMibcdLHShRICbgZxBCicTxwkG5w7UmsH80SxuJTUjfC1u1x3ibABdUsnzcbTgbh22ev0RMtAKKLA4XpmLA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;485&quot; /&gt;&lt;br /&gt;&lt;strong&gt;&lt;span&gt;生物形成新的条件反射，可以理解为一个决策的生成， 用二进制表述后成为分类问题。&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;


&lt;p&gt;&lt;span&gt;       &lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;&lt;img data-ratio=&quot;0.6594202898550725&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz/dcEP2tDMibcer8XuOIJic4IJsP9eJaKyQHveF4XfibTv9YNunAmTib6c4JZXLiakrzNFtgHwwhQibsnGOD5plczrycSA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;276&quot; /&gt;&lt;br /&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;分类问题可以由神经网络解决：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;上图的神经网络， 就是一个基本的卷积网络， 把输入的值乘以一定权重在加在一起， 再通过一个非线性的阶梯函数， 转化为0（有害），1（有利）的输出， 即决策过程。 &lt;/span&gt;&lt;br /&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;学习， 数学上叫调参：  改变w的数值即可改变分类的方法（界限）。&lt;/span&gt;&lt;/p&gt;



&lt;p&gt;&lt;span&gt;&lt;img data-ratio=&quot;1&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz/dcEP2tDMibcer8XuOIJic4IJsP9eJaKyQHqx4TqGyp07L8D8LqkSnTNsNuLicqicC3mzonteVia4rbt0VsFhOQasz5A/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;500&quot; /&gt;&lt;br /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;训练的过程， 图中为一个分类野生和家养动物的网络，随着数据量的加大分类越来越准确。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;br /&gt;神经网络的分类功能， 把输入的信息（环境变化）分为有利和有害的进行决策， 环境的变化越复杂， 越体现神经网络可以任意的通过改变连接强度来调整决策“界面”  的优势, 而不需要用进化的方法上下一辈来适应环境（学习的重要性）。 当然这个学习过程需要大量数据的训练。 &lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;span&gt;结论：  一个单层神经网络完全可以娴熟的应用斯金纳造物&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;       &lt;/span&gt;&lt;span&gt;从第二种智能方式我们依然可以看到， 生物智能的方式是如何启发了人工智能。 &lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.16782334384858044&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz/dcEP2tDMibcfyNibceeGvVKo0qCGicGJ9lQ9J5zzOIxmTUAE4OYfwx25QZ2J2KLUic1lWYkMwelC8Ld30RF0FsibAPQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1585&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;span&gt;智能的最高级形式波普尔造物，&lt;/span&gt; &lt;span&gt;对外部世界进行表征，&lt;/span&gt; &lt;span&gt;形成认知，信念和预期，则对应神经网络的更高级功能。&lt;/span&gt; &lt;/strong&gt;&lt;span&gt;如果仔细思考，&lt;/span&gt; &lt;span&gt;我们会发现这些很多包含在阿法狗使用的深度网络里。&lt;/span&gt; &lt;span&gt;首先，&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;深度网络最擅长的是对事物进行抽象（深度学习），&lt;/span&gt;&lt;span&gt; 在最靠近输入的层次上， 每个细胞就如同数码相机CCD上的像素，&lt;/span&gt;&lt;span&gt;之后的每一层次都比上级网络的感受野要大，&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;而最终得到的效果是最深层的神经元直接处理和图像的全貌相关的特征，比如照片上的人是谁。如果换到其他地方，就是&lt;/span&gt;&lt;span&gt;从抽象或全局&lt;/span&gt;&lt;span&gt;特征进行决策。   &lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;这个结构像极人类社会的结构， 越是高层， 越能把握和总控全局。&lt;/span&gt;&lt;span&gt;深度网络上的&lt;/span&gt;&lt;span&gt;“&lt;/span&gt;&lt;span&gt;抽象概念&lt;/span&gt;&lt;span&gt;”&lt;/span&gt;&lt;span&gt;这个认知武器，使得阿尔法狗有对全盘棋的趋势进行判断的能力，可以迅速舍弃一些错误的方向，减少搜索的深度，即价值网络。 &lt;/span&gt;&lt;span&gt;其实人脑所使用的算法和阿尔法狗差距没有那么大， &lt;/span&gt;&lt;span&gt;记得前些年有一篇著名的&lt;/span&gt;&lt;span&gt;science&lt;/span&gt;&lt;span&gt;文章说人类发现在高级脑区表现抽象概念&lt;/span&gt;&lt;span&gt;-&lt;/span&gt;&lt;span&gt;如人名的细胞，这是符合这种深度网络逐层抽象的概念。高级脑区正是对应人脑深层网络的最底层。 &lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;span&gt;阿尔法狗此次能够战胜代表棋牌巅峰智慧的围棋冠军这件事最大的意义，也在于深度网络赋予了AI自主判断局势和形成策略，而不是靠之前的仅靠人为给定的策略遍历所有可能。或者说深度网络打开了波普尔造物的大门&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;当然，深度网络算法只是提取了生物神经网络的一个主要特征 ， 而几亿年进化结晶的人脑， 由于计算机能够提取并用于学习的数据量巨大， 使得它能够在学习了人脑的一个雕虫小技之后通过迭代学习迅速在某个特定任务上超越人类。   &lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;span&gt;波普尔式的智能-深度网络&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;&lt;img data-ratio=&quot;0.6&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz/dcEP2tDMibcer8XuOIJic4IJsP9eJaKyQHwpHSjTJScnqs1HXHufNibDoicZQNofUGiaYvv08g4aMTzu8rfibkRJOTVA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;290&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.5143843498273878&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz/dcEP2tDMibcer8XuOIJic4IJsP9eJaKyQHEYPxQxJKtKLDVeiaic07VpW1u4xH5nmibKWeTo57QgSVl737oibE9actIw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;869&quot; /&gt;&lt;/p&gt;


&lt;p&gt;&lt;span&gt;就上面这个简单的历史陈述我们发现，AI说到底是一种仿生，但是这种仿生无疑会改变我们生活的方方面面， &lt;/span&gt;&lt;span&gt;目前网络对于阿法狗的大多数评论或者夸张或者贬低了&lt;/span&gt;&lt;span&gt;ai&lt;/span&gt;&lt;span&gt;的价值和深度，不仅是对AI的理解不清， 更是对我们自身的理解不清。&lt;/span&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;&lt;img data-ratio=&quot;0.3669724770642202&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz/dcEP2tDMibcer8XuOIJic4IJsP9eJaKyQHfViaDent1lq9U6QSpEib5Xiapbdes5MibKQJH5rKicEoiaOKM4X8Yng6tNibA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;545&quot; /&gt;&lt;br /&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;阿尔法狗的智慧是结合了古老的细菌智慧（策略网络）+高级哺乳动物的智慧（价值网络），可谓仿生物智慧杰作&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;&gt;&lt;/ins&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;一些常见问题：&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;1.&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt; &lt;strong&gt;&lt;span&gt;&lt;span&gt; &lt;/span&gt;AI&lt;/span&gt;&lt;span&gt;到取代人类大量劳动的时候了&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;AI&lt;span&gt;一定会逐步取代简单的人类劳动，&lt;/span&gt; &lt;span&gt;但是也会增加新的劳动出来，&lt;/span&gt; &lt;span&gt;比如&lt;/span&gt;AI&lt;span&gt;设计，&lt;/span&gt; AI纠错 ，  &lt;span&gt;以及如何利用&lt;/span&gt;AI&lt;span&gt;做出以往实践不能的事，  AI将使得人脑从简单劳动中解放， 可以爆发中不可预计的新产业。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;2&lt;span&gt;，&lt;/span&gt; &lt;/strong&gt; &lt;strong&gt;&lt;span&gt;AI&lt;/span&gt;&lt;span&gt;没有意识，&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;无法预测，没有创造力，&lt;/span&gt;&lt;span&gt; AI&lt;/span&gt;&lt;span&gt;几乎永远无法与人类智能望其相背。&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;        人类容易犯的错误之一， 就是用一些自己也无法严格定义的概念去套用机器。   “ 意识”  “  创造力”这些概念，  其实人类自身也不理解， 你站在人类的角度上， 去讨论ai有无意识这个问题， 是自己陷入了一个思维的陷阱。 因为究其根本， 我们对自己有没有意识这件事也没有一个掌控的时候， 整个这样的讨论流于空泛。     而对于这些概念的进一步掌握， 取决于神经科学的进步。虽然我比较怀疑很快强人工智能会出现， 但是即使出现， 它也不一定需要以我们人类能理解的方式产生意识， 达到目标。 说不定在另一个外星观测者看来， 我们也是无意识的， 意识不过是这个被称作“人”的东西所使用的多级神经网络里某个调节参数的辅助工具。 &lt;/p&gt;

&lt;p&gt;&lt;strong&gt;3，  &lt;/strong&gt;&lt;strong&gt;觉得AI的运转方式一定和人脑是天壤之别的&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt; 这也是犯了太骄傲的毛病。 因为你并不懂得人脑运算所采用的算法。  人脑这个东西， 即使是情感这些我们觉得很柔软的功能，背后也是以海量运算为背景的，而目前的科学论文证实的是， 在视皮层的运算， 很多与目前的深度网路运算是很接近的。 有的人说人是向前看的动物而机器只会向后看， 事实上呢， 人对未来的预测也来自于对过去数据的大量积累。 &lt;/p&gt;

&lt;p&gt;&lt;span&gt;&lt;strong&gt;我们并无太多证据受AI是否和我们的大脑有着相类似的运转方式， 但是有一点肯定的是， AI的发展源自我们对自身的模仿， 而对AI的探究反过来正在帮助我们理解我们自身 ，这也是生命最终的意义。 正如费曼所说， 只有你知道如何制造一个东西， 你才真正理解它。 &lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;8.917333333333334&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcfAJhIt9ib9SI5GEiaNXhxiaKKwiczJaXlqdcRiawey4yNMN8o9h1Dno56XyYdiaOw4eTRZWexUyazOPK7Q/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;750&quot; /&gt;&lt;/p&gt;




</description>
<pubDate>Sat, 08 Dec 2018 07:29:37 +0000</pubDate>
<dc:language>zh-CN</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.jintiankansha.me/t/QW8H2qTxdK</dc:identifier>
</item>
</channel>
</rss>