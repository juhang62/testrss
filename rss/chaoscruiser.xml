<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="css/feed.xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/" xmlns:og="http://ogp.me/ns#">
<channel>
<atom:link rel="self" href="http://192.168.1.4/fivefilters/makefulltextfeed.php?url=feed43.com%2Fchaoscruiser-jtks.xml&amp;max=5&amp;links=preserve&amp;exc=1" />
<atom:link rel="alternate" title="Source URL" href="http://feed43.com/chaoscruiser-jtks.xml" />
<atom:link rel="related" title="Subscribe to feed" href="http://www.subtome.com/#/subscribe?feeds=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed43.com%252Fchaoscruiser-jtks.xml%26max%3D5%26links%3Dpreserve%26exc%3D1&amp;back=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed43.com%252Fchaoscruiser-jtks.xml%26max%3D5%26links%3Dpreserve%26exc%3D1" />
<title>混沌巡洋舰</title>
<link>http://www.jintiankansha.me/column/ultiWL8Axg</link>
<description>混沌巡洋舰 - 今天看啥</description>
<ttl>360</ttl>
<item>
<title>铁哥脑科学改善人工智能-ICLR论文讲解</title>
<link>http://www.jintiankansha.me/t/KM8lKccZYz</link>
<guid isPermaLink="true" >http://www.jintiankansha.me/t/KM8lKccZYz</guid>
<description>&lt;p&gt;&lt;img data-ratio=&quot;0.5625&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcdOfhS5WM9zUnXwQJxgGdwQc3prFdLfgJRJS1oYxicPSF6fiamwsniacloYBUtMbOFjPWwpR5pAtuozQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;720&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;span data-offset-key=&quot;8emjl-0-0&quot;&gt;&lt;span data-text=&quot;true&quot;&gt;故事的起因，是当下的深度学习日子越来越不好过，自动驾驶，智能对话都在陷入一种人工智能不智能的怪圈， 即使最火的CV，其实也是需要大量数据填补的人工智障。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;b9hvp-0-0&quot;&gt;&lt;span data-text=&quot;true&quot;&gt;这些困难的根本，在于人工智能不具备人的智能的基础， 而只是模仿了人的思维能力的皮毛，也就是感知能力。我们来回顾这个人工智能进化的历史 。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span data-offset-key=&quot;e57q5-0-0&quot;&gt;&lt;span data-text=&quot;true&quot;&gt;首先， 人工智能经历过三个基本范式 ：符号主义， 统计学习， 连接主义。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;span data-offset-key=&quot;fdoa-0-0&quot;&gt;&lt;span data-text=&quot;true&quot;&gt;符号主义:&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt; &lt;span data-offset-key=&quot;fdoa-0-0&quot;&gt;&lt;span data-text=&quot;true&quot;&gt;  模拟人的逻辑， 如何把人的逻辑和知识用符号串起来 。符号主义的本质 = 符号的运算  &lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;span data-offset-key=&quot;fj8jk-0-0&quot;&gt;&lt;span data-text=&quot;true&quot;&gt;统计学习：&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span data-offset-key=&quot;fj8jk-0-0&quot;&gt;&lt;span data-text=&quot;true&quot;&gt;模拟人类统计学习的过程， 如何从大量的实践总结出有效的特征， 然后根据这些特征的先后重要性排列连接成决策树 。 &lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;span data-offset-key=&quot;cp2dg-0-0&quot;&gt;&lt;span data-text=&quot;true&quot;&gt;连接主义：&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span data-offset-key=&quot;cp2dg-0-0&quot;&gt;&lt;span data-text=&quot;true&quot;&gt;人类模拟自身大脑的结构，提炼出网络的结构。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img data-ratio=&quot;0.5625&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcdOfhS5WM9zUnXwQJxgGdwQVLynJIJGJslLsKY7nctm9MibRsqWrsicFfsM7YQMQfMF2ick2tbyw1DPw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;720&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;span data-offset-key=&quot;88lvk-0-0&quot;&gt;&lt;span data-text=&quot;true&quot;&gt;然后我们回顾连接主义发展的历史，连接主义的发展可谓三起三落， 所谓 起都是因为借鉴了对生物大脑的某个理解而进步， 而 衰 都是因为达不到人们的预期而衰。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;cnmg6-0-0&quot;&gt;&lt;span data-text=&quot;true&quot;&gt;1, 第一次合作：&lt;/span&gt;&lt;/span&gt;&lt;span data-offset-key=&quot;cnmg6-0-1&quot;&gt;&lt;span data-text=&quot;true&quot;&gt;深度学习的前身-感知机。Warren McCulloch 和 WalterPitts在1943 提出而来神经元的模型， 这个模型类似于某种二极管或逻辑门电路。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span data-offset-key=&quot;fejnp-0-0&quot;&gt;&lt;span data-text=&quot;true&quot;&gt;事实上， 人们很快发现感知机的学习有巨大的局限性， Minksky等一批AI早期大师发现感知机无法执行“抑或”这个非常基本的逻辑运算，从而让人们彻底放弃了用它得到人类智能的希望。对感知机的失望导致连接主义机器学习的研究陷入低谷达15年， 直到一股新的力量的注入。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;34nra-0-0&quot;&gt;&lt;span data-text=&quot;true&quot;&gt;2， 第二次合作：这次风波， 来自一群好奇心极强的物理学家，在20世纪80年代， hopefiled提出了它的 Hopefield 网络模型，这个模型受到了物理里的Ising模型和自旋玻璃模型的启发， Hopefield发现，自旋玻璃和神经网络具有极大的相似性。每个神经元可以看作一个个微小的磁极， 它可以一种极为简单的方法影响周围的神经元，一个是兴奋（使得其他人和自己状态相同）， 一个是抑制（相反）。 &lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;34nra-0-0&quot;&gt;&lt;span data-text=&quot;true&quot;&gt;如果我们用这个模型来表示神经网络， 那么我们会立刻得到一个心理学特有的现象：关联记忆。比如说你看到你奶奶的照片， 立刻想到是奶奶，再联想到和奶奶有关的很多事。hopefield模型的更大影响是引发了神经网络研究的一股旋风， 人们从不同领域开始涌入这个研究。有的人想用这个模型研究人脑， 有的人想用这个模型制造机器大脑，&lt;/span&gt;&lt;/span&gt; &lt;span data-offset-key=&quot;34nra-0-1&quot;&gt;&lt;span data-text=&quot;true&quot;&gt;前者派生出了计算神经科学，&lt;/span&gt;&lt;/span&gt; &lt;span data-offset-key=&quot;34nra-0-3&quot;&gt;&lt;span data-text=&quot;true&quot;&gt;后者则导致了联结主义机器学习的复兴，&lt;/span&gt;&lt;/span&gt; &lt;span data-offset-key=&quot;34nra-0-4&quot;&gt;&lt;span data-text=&quot;true&quot;&gt;你可以理解为前者对猫感兴趣，后者只对机器猫感兴趣，虽然两者都在那里写模型。 &lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;3jti1-0-0&quot;&gt;&lt;span data-text=&quot;true&quot;&gt;3，第三次合作：所谓深度学习革命，在漫长的联结主义低谷期， hinton坚信神经网络既然作为生物智能的载体，它一定会成为人工智能的救星，在它的努力下， Hopefield网络很快演化成为新的更强大的模型如玻尔兹曼机，玻尔兹曼机演化为受限玻尔兹曼机，自编码器，堆叠自编码器。算法的进步更多体现在学习方法的改进。信息存储在无数神经元构成的网络连接里，如何让它学进去，也就是最难的问题。一种叫反向传播的方法60年代就开始&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img data-ratio=&quot;0.5625&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcdOfhS5WM9zUnXwQJxgGdwQxYrMeiaCuuxIhicxApDbOGIazNKwLJIuvFoiaKFOUoT8bnsAOuIZ61BYA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;720&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;img data-ratio=&quot;0.5625&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcdOfhS5WM9zUnXwQJxgGdwQcV91IlHc0uucUVS8YWqyxsicpiapZdbMFNym5vyauibadUiapkRdNkjrMQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;720&quot;/&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;7aefq-0-0&quot;&gt;&lt;span data-text=&quot;true&quot;&gt;当下的AI与真正的人类的智能差距在哪里。但是当下的ai还不够智能 。我们从以下几个角度介绍原因 。在学习的目标上，由单任务vs多任务的区别 ， 在对数据的需求上小数据vs大数据， 在思维的本质上，有因果性vs相关性的区别， 在智能的层次上，有意识vs无意识的区别， 在语言的使用上， 真正的语言能力意味着蕴藏多个模态关联的符号集合， 在社会交互上，有社群性和个体性的区别。我们可以思考单任务和多任务， 因果性和相关性， 群体和单机的真正区别所在，是来源于哪里呢?&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img data-ratio=&quot;0.5625&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcdOfhS5WM9zUnXwQJxgGdwQthDbL9IDKkNXKFbYVSrSE2q9bqVUqZs8SX0vwfwnKW1tGqlBVHG8Sw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;720&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;span data-offset-key=&quot;11cd7-0-0&quot;&gt;&lt;span data-text=&quot;true&quot;&gt;我们来仔细思考这种区别的根基， 脑结构的区别， 大脑内的神经元采用尖峰脉冲放电，具有树突和轴突。从连接上看， 当下的AI以前馈为主， 而生物循环为主。从拓扑结构看， 目前的网络不太有先验支撑的拓扑， 而是单纯靠梯度下降学习。生物神经网络的每个模块带有不同的先验。从学习角度，端到端学习的能力十分有限。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img data-ratio=&quot;0.5625&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcdOfhS5WM9zUnXwQJxgGdwQdtibm1y16icVnTktHFCG7jWaI1dxtCZWBS1ynVahbVoBTag7dlfTFGyw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;720&quot;/&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;8pc97-0-0&quot;&gt;&lt;span data-text=&quot;true&quot;&gt;如何改善AI?  大家众说纷纭， 最激进的观点在于我们可以直接用大量的算力堆积， 让AI自己从超大的人工神经网络进化出来， 而更加温和的观点则认为理解和模拟我们大脑本身是绕不开的， 可以称之为仿生学派，这也是我自己的观点。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;img data-ratio=&quot;0.5625&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcdOfhS5WM9zUnXwQJxgGdwQRP8icjibPO4cmlv8iamqmCSJrYIzuBV14iaH1BKPyKycYqCLSEriaNk5ibmA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;720&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;span data-offset-key=&quot;e9quv-0-0&quot;&gt;&lt;span data-text=&quot;true&quot;&gt;要理解大脑，最重要的是理解大脑是个复杂动力学系统。何为动力学系统，事实上大脑不像电脑 ，拔掉电源就不再工作，仅有输入来有一个输出。而是一个不停演化的动力系统 。最简单的动力学系统是一个单摆系统，有简单的动力学方程确定。作为一个动力学系统，掌握其演化的微分，就掌握了整个系统的未来，而微分又是通过不同微小局部的相互作用形成。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;img data-ratio=&quot;0.5625&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcdOfhS5WM9zUnXwQJxgGdwQAhd6wtZOSu4LzricWc5zGcvqS0PPwyeZfWO5z4GolxcAIMTYUt7auQA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;720&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;span data-offset-key=&quot;3n4bm-0-0&quot;&gt;&lt;span data-text=&quot;true&quot;&gt;大脑的不同层级， 具有不同的动力系统特征。每个层次上展现的性质完全不同。神经元层次上我们看到经典的物理振子系统， 而哪怕最简单的神经回路也是一个小小的复杂网络。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;img data-ratio=&quot;0.5625&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcdOfhS5WM9zUnXwQJxgGdwQOD62GW1vq4C1Xw1GR8pTV1JnsGNaMf2sicxibxv0FogsoOZZB9fgjB9Q/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;720&quot;/&gt;&lt;/p&gt;


&lt;p&gt;&lt;span data-offset-key=&quot;9gqr3-0-0&quot;&gt;&lt;span data-text=&quot;true&quot;&gt;下一个问题， 如何研究脑内的动力学 ？一言以蔽之， 用机器学习研究人脑。如果用生物学一个个分解研究的思维是很困难的，那么一个很好的方法是以毒攻毒，以复杂攻克复杂，我们使用人工神经网络，来拟合脑，但目的不是拟合，而是找到脑功能动力学的关键。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;72cad-0-0&quot;&gt;&lt;span data-text=&quot;true&quot;&gt;这个机器学习工具是什么呢?  他就是RNN。方程-记忆-输入-输出。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;img data-ratio=&quot;0.5625&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcdOfhS5WM9zUnXwQJxgGdwQibMz1slYY0BkmoMoibcSPQIoI8rbUNicx4TAvmRaPrvnFjxtR5esDqqFA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;720&quot;/&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;bvo4r-0-0&quot;&gt;&lt;span data-text=&quot;true&quot;&gt;为什么用RNN可以帮助我们理解我们的大脑，因为RNN本身是一个复杂的动力学系统，只要给它数据，它就可以捕捉真实大脑的动力学， 而捕捉到脑动力学的RNN比大脑更容易分析， 因此它就是这个领域的神器 。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;img data-ratio=&quot;0.5625&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcdOfhS5WM9zUnXwQJxgGdwQcRhjCS7lj9ZBnHpjh8tsxqJPpIDzj8UkIykD3msicrvJ1yJozk7nW0Q/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;720&quot;/&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;71pfq-0-0&quot;&gt;&lt;span data-text=&quot;true&quot;&gt;用术语说，RNN可以看作是一个通用动力学逼近器，通过可以学习的动力学方程组学习任何representation。&lt;/span&gt;&lt;/span&gt;一种研究套路是用RNN建立脑回路特有的功能， 然后再研究这个RNN。&lt;/p&gt;

&lt;p&gt;能否构建一个任务，体现通用ai多任务，多先验，强泛化，而且从大脑中取经提高性能？文章的后面部分将用一个我自己ICLR论文的实例说明上面的道理。如何建立一个任务来说明这个问题，我们选择导航 。这是对生物非常重要的一个日常任务，导航和一般的视觉任务比，更加需要模型，比如规划路线。&lt;/p&gt;

</description>
<pubDate>Wed, 22 Apr 2020 01:02:47 +0000</pubDate>
<dc:language>zh-CN</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.jintiankansha.me/t/KM8lKccZYz</dc:identifier>
</item>
</channel>
</rss>