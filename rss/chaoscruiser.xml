<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="css/feed.xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/" xmlns:og="http://ogp.me/ns#">
<channel>
<atom:link rel="self" href="http://192.168.1.4/fivefilters/makefulltextfeed.php?url=feed43.com%2Fchaoscruiser-jtks.xml&amp;max=5&amp;links=preserve&amp;exc=1" />
<atom:link rel="alternate" title="Source URL" href="http://feed43.com/chaoscruiser-jtks.xml" />
<atom:link rel="related" title="Subscribe to feed" href="http://www.subtome.com/#/subscribe?feeds=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed43.com%252Fchaoscruiser-jtks.xml%26max%3D5%26links%3Dpreserve%26exc%3D1&amp;back=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed43.com%252Fchaoscruiser-jtks.xml%26max%3D5%26links%3Dpreserve%26exc%3D1" />
<title>混沌巡洋舰</title>
<link>http://www.jintiankansha.me/column/ultiWL8Axg</link>
<description>混沌巡洋舰 - 今天看啥</description>
<ttl>360</ttl>
<item>
<title>空间简史-人类认识空间的旅程与其对强化学习的启示</title>
<link>http://www.jintiankansha.me/t/9DKU2tIReQ</link>
<guid isPermaLink="true" >http://www.jintiankansha.me/t/9DKU2tIReQ</guid>
<description>&lt;p&gt;&lt;span data-offset-key=&quot;9nmgo-0-0&quot;&gt;本文是对okeefe 1978(栅格细胞发现者， 2014诺贝尔奖得主)的论文 cognitive map  的总结和延申。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;4mvhc-0-0&quot;&gt;一  空间的先验与后验之争&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;5fivr-0-0&quot;&gt;对于我们在其中生存和繁衍的空间， 是如何在我们的心理世界表达的， 这是一个争论了几百年， 也依然没有完全清楚的问题。 如果你不去仔细思考， 你可能觉得这是一个很简单的问题。 而一旦较真， 你就会发现几乎所有的哲学家， 物理学家， 心理学家所纠结过的那些问题。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;fut2f-0-0&quot;&gt;首先， 什么是空间？  最早探讨它的是物理学， 从亚里士多德到牛顿。 牛顿的物理学在&lt;strong&gt;绝对空间&lt;/strong&gt;基础上存在，所谓绝对空间， 可以简化为一个欧式直角坐标系， 世间的所有有行实体都可以在这个坐标系里寻找到一个坐标。有了空间和时间， 我们就可以相当准确的描述和预测发生在时空里的运动，并且进行大距离的迁徙（比如大航海）。 想象一下没有地图和坐标， 哥伦布即使偶然到达美洲也不可能回去了。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;Image FocusPlugin--unfocused Image--isBlock&quot; data-ratio=&quot;0.902542372881356&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcf6UicViaMRj6HicuSic8LUiajm5eoVMy7tN5ia4Gf32QqzbydCZP5h3zYLmY0j8BnBqfomuju42nfRvSibg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;236&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;Image FocusPlugin--unfocused Image--isBlock&quot; data-ratio=&quot;0.68&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcf6UicViaMRj6HicuSic8LUiajm5pqRgj6fWpib4icGP6F9cIQLjTXk4jibGmuGvW5HQiaW8Uo4SMBp3UibuCAw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;600&quot; /&gt;&lt;/p&gt;
&lt;p&gt;在古代， 星空是人类航海重要的坐标， 我们通过判断星辰间的指向， 知道茫茫大海自己的去向， “陪你一起看看星星” 绝非为了浪漫， 而是关乎生存。&lt;/p&gt;
&lt;p&gt;&lt;span data-offset-key=&quot;5df0s-0-0&quot;&gt;虽然物理学家从不怀疑真实空间的存在， 然而有一个问题确没法解决。 我们的感知是含糊的，柔软的，既缺乏像尺规一样的绝对空间度量， 也没有绝对的方向度量。 我们对距离的描述经常是或近或远这样的模糊语言，也不擅长想象一个超大空间的地图（受到训练之前）。 那么， 那个物理学家关心的刚性的欧式度量的空间是从哪里来的呢？ 我们为什么能够产生这样的概念？ 是什么使我们能够产生这样的概念？  &lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;9umse-0-0&quot;&gt;换句话说， 空间如果存在， 它到底在哪里？ 它是怎么在我们脑海里形成的？ 它是通过某种先天的“结构” 得来 ， 还是通过感知基础， 在后天的学习和思考基础上形成的?&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;6ren9-0-0&quot;&gt;应该说对这些问题的回答绝非容易， 我们一开始解决这些问题的方法是哲学， 而后面才从生物学的认知基础上讨论。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;eh1l2-0-0&quot;&gt;最早对这个问题进行阐述的人包括贝克莱和康德， 它们分别代表了两种截然不同的观点。贝克莱和我们熟悉的休谟和洛克一样是英国经验主义哲学的代表人物， 强调一切认知的基础， 无非是大量经验的总结， 它否定物理上的绝对空间，认为这是人的认知造成的一种幻觉。首先在空间认知的事情上，他认为存在等同于被感知， 而所谓的空间， 无非是我们被感知到的大量的触觉，视觉， 和肌肉运动之间的某种关联。 因而绝对空间这个东西， 根本就是子虚乌有。 大家想下大卫休谟的那句话：&lt;strong&gt;只要闭上眼睛就没有悬崖&lt;/strong&gt;， 就会理解他的观点的深刻含义。 感知所构成的大量经验集合是第一性的， 绝对的物理空间是第二性的， 是一种方便性的考量。  &lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;Image FocusPlugin--unfocused Image--isBlock&quot; data-ratio=&quot;1.3454545454545455&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcf6UicViaMRj6HicuSic8LUiajm5ia4BdTYBLNibv3hicicIUOiaS4QCKBkNRU8eTMqLphD0zfibupQiaCyXuWhyw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;220&quot; /&gt;&lt;/p&gt;
&lt;p&gt;具有经验主义传统的英国， 出产了贝克莱和休谟这样的哲学家。&lt;/p&gt;
&lt;p&gt;&lt;span data-offset-key=&quot;2i12a-0-0&quot;&gt;这样的对空间的认知， 与牛顿的物理学存在本质的冲突， 而另一个派别， 是结合了理性主义和经验主义的康德提出的理论， 他认为绝对空间存在，而它依赖的恰不是外部的物理世界， 而是人类先天的认知基础，一种与这种绝对空间相对应的脑组织，它是我们认知外部世界的基石。   &lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;2i12a-0-0&quot;&gt;康德的时空观是起纯粹理性批判的基础。康德的观点既不同于贝克莱也不同于牛顿。 首先他认同绝对欧式空间的存在， 其次他认为这个空间不存在于物理世界恰恰在我们的心理， 第三这个先验的结构是我们其它感知的基础。 &lt;strong&gt;我们的对物体的感知， 都要放到这个空间结构里得到认识。&lt;/strong&gt; 应该说这里的第一性和第二性的顺序与经验主义恰好相反。 康德的理念里， 没有了时空这样的先验， 经验毫无意义（联想以下当下 数据-经验 驱动的AI所遇到的缺乏逻辑推理能力的瓶颈， 我们无疑在某种程度回归康德的问题）。  &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;Image FocusPlugin--unfocused Image--isBlock&quot; data-ratio=&quot;1.4984984984984986&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcf6UicViaMRj6HicuSic8LUiajm5q2ydezSg0X819ribLFic7zSJUSbib4wv1CqpYu3pzEmAvXwmfREJAGM8w/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;333&quot; /&gt;&lt;/p&gt;
&lt;p&gt;康德认为经验的认知需要在先验存在的时间和空间之上， 这也是康德思想体系的基础之一。&lt;/p&gt;
&lt;p&gt;&lt;span data-offset-key=&quot;2s0ur-0-0&quot;&gt;在康德之后， 这两个派别分别发展出Empiricist（经验主义）,  和Natist （先天认知）两个基础流派，&lt;/span&gt;&lt;span data-offset-key=&quot;2s0ur-0-1&quot;&gt;经验主义者强调所有有关绝对空间的认知都是后天学习得到的大量感知之间的联系。 而先天主义者则认为需要有一个先验而非习得的空间结构，这个结构是后来学习的基础。  &lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;1sfen-0-0&quot;&gt;在后面的整个世纪里，两边各站着一批各自的哲学家，分别寻找证据阐述各自的理由。 一个比较标示性的任务是20世纪初的庞家莱。 这个时期的物理学发生了天翻地覆的变换。 爱因斯坦的相对时空开始取代牛顿的绝对时空。 而黎曼几何的出现代表我们之前深信不疑的欧式空间无非是受到了我们经验的局限。黎曼几何成为广义相对论的基础。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;1sfen-0-0&quot;&gt;而从电动力学和量子力学衍生的场论更是刷新了人们的三观 。庞家莱在这个基础回到了贝克莱的经验主义，就没有特别奇怪。庞家莱首先认为空间无非是无数经验的集合， 这些经验主要是由人在移动时候视觉的变换构成的。 我们对不同物体的距离的感知， 也无非是让一个虚拟的自己经历一个从A物体到B物体的过程而认识到的。大量 经验上学到的位移与视野变换的对应关系可以用平移算子和群表示。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;1sfen-0-0&quot;&gt; 而这样的群最大的特质是存在一个逆运算可以让当下的状态和先前的状态完全一致（联想一下时间就没有这样的对称性， 不存在一个时间平移逆运算让你回到时间的原点）。  位置的概念隐含在这种平移算子的对称性里 。庞家莱的理论不难找到同时代的相对论和场论的影子， 而他的思想标志了经验主义的新高度。&lt;/span&gt; &lt;span data-offset-key=&quot;1sfen-0-1&quot;&gt;我们在不停的变化的经验积累中得到了变化中的不变性（数学规则）， 而这些数学规则就是空间的本质。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;Image FocusPlugin--unfocused Image--isBlock&quot; data-ratio=&quot;0.6&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcf6UicViaMRj6HicuSic8LUiajm5HseU1MBGiaNOp3ptQ909N9utJQbyghIY3wc2mORoDKIO3tloIqrL0xQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;300&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;&gt;&lt;/ins&gt; &lt;img class=&quot;Image FocusPlugin--unfocused Image--isBlock&quot; data-ratio=&quot;0.5633333333333334&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcf6UicViaMRj6HicuSic8LUiajm5pblIushnqyL4lmicj1glPd1KhDWVbFEDP7AR175TbR1sEqyrLuiawebg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;600&quot; /&gt;&lt;/p&gt;
&lt;p&gt;黎曼几何， 打破了欧式直角坐标系，同样的也是对于日常经验的一个突破。 因为我们常见直线， 不说明它是真实的。事实上爱因斯坦的广义相对论指出光线被引力弯曲沿曲线传播。 黎曼几何成为广义相对论的数学基础。&lt;/p&gt;
&lt;p&gt;&lt;span data-offset-key=&quot;9g6ei-0-0&quot;&gt;注： 爱因斯坦的狭义相对论的建立过程体现了对牛顿绝对时空的突破。事实上正是爱因斯坦看到了牛顿的绝对时空是受到了我们经验的局限才能够打破它。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;Image FocusPlugin--unfocused Image--isBlock&quot; data-ratio=&quot;0.4033333333333333&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcf6UicViaMRj6HicuSic8LUiajm5otsAHscJQBT7jGhR0JbJkhYZWQzvuIOAxHASjMrTvKuL9PyKHEM37A/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;600&quot; /&gt;&lt;/p&gt;
&lt;p&gt;狭义相对论认为，我们的绝对时间的观点， 正是受制于我们自身的经验，因为我们从来不以接近光速运行。 而得到真实的物理规律， 事实上需要突破这种经验。 狭义相对论以光速（电磁学规律）为绝对不变， 而放弃时间的绝对流逝， 当物体的运动速度变换，其时钟也相对静止坐标系进行调整。&lt;/p&gt;
&lt;p&gt;&lt;span data-offset-key=&quot;egr3d-0-0&quot;&gt;而继续把场论的思维进行深化的，是Kohler等人提出的Gestalt（格式塔）理论。 Gestalt理论比庞家莱进一步的指向了空间感知的神经基础， 他把大量神经元的同时放电看做是一种场的形成， 不同的神经元组（网络）代表不同的场， 两种最基本的和空间导航有关的场一种叫做 地理场（geography field）， 一种叫做 行为场（behavior field）。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;egr3d-0-0&quot;&gt;地理场主要用来表征外部的物理世界-空间关系， 而行为场用于赋予各种外部刺激（感知）以意义，估值，和反射行为（这就是强化学习理论的预演，行为场可以看做强化学习的值函数），这两个场互相配合产生空间有关的概念和行为。 从外部的刺激通过神经组织合成出各种合适的“场”来表征外部特征的思想已经像极了今天的深度学习， 不难看出我们今天的科技和前人的思想的联系。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;a4jvn-0-0&quot;&gt;在此基础上， 1936年Lewin提出了空间拓扑结构和所谓行为场的关系， 使得Gestalt的理论变得更为坚实， 之前的行为场的一个问题是不知道它如何组织和形成， 而Lewin则提出了它的基础是各种各样的和行为有关的空间拓扑结构， 比如边界，连接， 等等。  也就是说你先建立一个空间的拓扑场， 后面可以就容易建立一个行为场。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;f780f-0-0&quot;&gt;二 来自动物行为的证据&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;fk4an-0-0&quot;&gt;好了，再fancy的问题 ，最终还要回到空间认知的本质是个生物问题 ，它需要特定的生物载体 。  那么研究动物对空间的认知就是一个几乎不可避开的问题。 动物是不会说话的，本质上了解动物的空间认知必须要从行为入手，与空间有关的行为就是导航。 像鸟类，小鼠， 蝙蝠都具有极为发达的空间导航能力（甚至比人还厉害），那么它们是怎么在复杂的空间里穿行，或者经过几千公里回到自己的家的呢？ 从观察这些行为入手， 我们也可以得到空间认知的本质。 我们说， 如果一个概念对行为和动物的生存并无意义 ，那也就是失去了任何行为的基础。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;Image FocusPlugin--unfocused Image--isBlock&quot; data-ratio=&quot;0.5387755102040817&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcf6UicViaMRj6HicuSic8LUiajm5CGFiauhV0R2yIqFLibFg6VprTlUia5m6RVBIck4N3Qbibtz5qj8MQRenbA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;490&quot; /&gt;&lt;/p&gt;
&lt;p&gt;经典的小鼠走迷宫任务。&lt;/p&gt;
&lt;p&gt;&lt;span data-offset-key=&quot;a92uh-0-0&quot;&gt;关于小鼠的导航问题的实验的问题，我们看到小鼠很容易在非常复杂的迷宫里找到食物，关于这个现象基本的假设解释， 一种是小鼠没有空间的概念，但是它可以记住一系列的动作 。这就好比一个很长的条件反射，比如左左右右左左右。 这就好比在现实生活中， 当你完成一个动作系列到达了星巴克， 你再执行另一个动作序列到达肯德基。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;aliv-0-0&quot;&gt;而另一个假设是小鼠有关于空间的概念 ，根据在大脑里生成的地图来决定每个时候的走向找到目标。 所谓地图，是指你和周围的物体（地标）以及周围的物体（地标）之间相对位置的几何。 在一个地图上， 所有的地标都获得了一个绝对的坐标， 即使你没有去过那个地方， 这个坐标依然告诉你它在什么位置。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;5ktiv-0-0&quot;&gt;为了研究相应的问题，我们可以把真实的空间去掉， 让小鼠在一个“时间迷宫”里（这个任务里缺乏固定的空间结构），单纯记住“左左右右左左右” 这样的动作序列来解决这个问题。 事实上小鼠这个时候已经很难完成这个任务。 这一系列的实验结果支持地图学说， 导致Tolman在1948年提出了Cognitive map的概念。 那就是 空间 或者 地图的概念在小鼠的大脑里是存在的， 成为其导航学习的基础。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;e3g3n-0-0&quot;&gt;对于同样的实验现象， Hull为代表的人提出了一套截然不同的解释，可以看作刚刚说的动作序列的高级版本，解决刚刚的矛盾 。 那就是看似复杂的空间导航，无非是一个多级的，组合式的条件反射。这就和我们日常大多数习惯的获得没有区别。 只是，在空间导航的学习里， 你学到的不是一个从起点到终点的方法， 而是一个系列的能够从起点到终点的动作系列（对应同一效果的不同的轨迹），这样也就不会受困于某个特定的行为序列。这个理论与庞家莱的群论的含义是一致的。 也就是我们学到的不是一个轨迹， 而是一个行为的集合， 具有同样的最终效果（一个群）， 这其实说的就是当今机器学习的泛化能力。  &lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;f5hiq-0-0&quot;&gt;多级条件反射和认知地图均能够解释现象， 但是背后的眼里却非常不同， 这也成为后面一系列的工作的起点。&lt;/span&gt;多级条件反射， 与心理学的一个重要的流派-行为主义流派不谋而合。它的主要代表人斯金纳用非常复杂的条件反射来解释语言和思考在内的所有认知现象（把语言符号也看作一种刺激），因此在那个年代也很占优势。&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;Image FocusPlugin--unfocused Image--isBlock&quot; data-ratio=&quot;0.7283333333333334&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcf6UicViaMRj6HicuSic8LUiajm5TWERwC5F7fF6lQib49o26DWyOMCVfOl8Il8icUEeusZjF1JvvEjjib8Eg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;600&quot; /&gt;&lt;/p&gt;
&lt;p&gt;斯金纳箱， 操作性条件反射的实验装置。 小鼠做出正确的动作后可以得到食物。 操作性条件反射在斯金纳的时代被认为是智能的基础。 也是强化学习理论的基础。通过多级条件反射， 小鼠不仅可以把当下的刺激和奖励联系起来， 还可以把之前的行为和刺激和当下的刺激联系起来&lt;/p&gt;
&lt;p&gt;&lt;span data-offset-key=&quot;7bdb1-0-0&quot;&gt;注： 稍微用心的研究者不难发现组合条件反射与深度强化学习的关系 ，我们一次又一次回归前人思想的轨迹。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;2rlgf-0-0&quot;&gt;而认知地图的支持者后来者居上， 一个重要的根据在动物导航行为的研究。 研究者发现在诸如鸟类这样的动物里 ，当你把鸟从一个地方移动到它所从未见过的地方， 它依然有能力找到到回家的路。 按照多级条件反射的说法， 鸟需要根据自己熟悉的地标， 记住一系列动作， 或者一个方向， 然后才能达到目的地。 而如果一个地方是完全陌生的， 那么鸟根本不可能能够根据习得的一套方案回巢（事实上这个逻辑并不严密）。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;Image FocusPlugin--unfocused Image--isBlock&quot; data-ratio=&quot;0.9383333333333334&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcf6UicViaMRj6HicuSic8LUiajm5f4WicAHicGB4f4RpRStXvTwiboEJb4LhMbXibeU2GIymibkn1a8GVCw5L0Q/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;600&quot; /&gt;&lt;/p&gt;
&lt;p&gt;鸟类天然擅长长途迁徙&lt;/p&gt;
&lt;p&gt;&lt;span data-offset-key=&quot;2r51e-0-0&quot;&gt;另一个重要的支持在于寻找捷径， 比如你回家的路上发现平时需要绕过的公园多了一条小路 你可能没有走过， 但是你依然可能会直接穿越回去到家。 寻找捷径的能力类似于强化学习里的有模型学习， 你需要建立一个最小的世界模型， 才能知道当下某个从没有见过的地标和你熟悉的地标（家）之间的联系。认知地图的支持者认为这个模型正是由认知地图提供的。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;ou86-0-0&quot;&gt;这些都成为认知地图作为一个先验结构早已存在于脑海中的实验支持， 不仅如此， 这个地图需要的样子是一个绝对的欧几里得坐标系，而不是你根据自己的位置为中心，设立的一张相对你而言周围物体分布的地图。 正是因为有这样一个绝对的欧式坐标系，你才知道周围物体相对周围物体， 门子相对窗子， 马路相对公园的位置， 你才能根据你的空间想象做出决策 ，不是走A路而是走B路，即使你从来没有见过A路，或者到了一个完全陌生的城市。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;2rids-0-0&quot;&gt;如何构建这样一个地图？ 你的大脑里的某个部位需要能够精确的进行路径积分， 并把每个看到的地标放置到这个精确积分的大脑平面图里。如果整个周围环境是固定的， 一旦出现一个新的物体， 你就很快可以想象出它和之前所有出现过的物体的相对位置， 在这个世界里， 每个物体的表示都是一个位置向量。 如果你想做一个能够行走的机器人， 不难想象也会构建一个类似的概念。&lt;/span&gt;这样的观点构成认知地图的基础， 我们通过大脑里的一个先验的绝对空间的概念载体， 而使得复杂的空间计划和导航学习成为可能。&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;a2m4q-0-0&quot;&gt;&lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;&gt;&lt;/ins&gt;  三 Place Cell 和 Grid Cell的发现&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;eete9-0-0&quot;&gt;这样的想法非常合理， 唯一的问题是我们的大脑里真有这样的结构吗？  这个观点在一组大名鼎鼎的细胞， grid cell和place cell之后可谓是登峰造极， 成为了科学的主流。 而它的发现者O'Keefe 和 Moser也获得了2014年的诺贝尔奖。  &lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;5dp4k-0-0&quot;&gt;这组细胞， 仿佛就是cognitive map的生物载体。所谓place cell的含义非常简单， 就是当你不停的经过某个同样的地点，同一个细胞会放电。  而所谓Grid cell， 其特征是其感受野对空间进行周期性的放电，它可以把一个二维平面表现成一个密集堆积的六边形结构， 不同的grid-cell具有不同的空间周期。 认知地图的支持者认为，这个Grid cell正是那个先验的大脑里的欧式坐标系的载体。如果你对空间里的一个狄拉克函数（一个空间质点的表示）做傅里叶变换你会得到一系列不同周期频率的波函数， 反过来， 这群函数或许可以作为一组表达不同物体位置的基函数。 而Grid cell如果是对应了这群函数， 那么它将可以非常灵活的表达生物体在一个绝对坐标系里的位置，即使生物体运动到了一个完全陌生的环境。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;Image FocusPlugin--unfocused Image--isBlock&quot; data-ratio=&quot;0.995&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcf6UicViaMRj6HicuSic8LUiajm5pmcLxcOm2D3WGCjia2RAPZePreTiaeWUbd0tiadOgibULxbEhKHl03icv3w/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;600&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;Image FocusPlugin--unfocused Image--isBlock&quot; data-ratio=&quot;0.4340175953079179&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcf6UicViaMRj6HicuSic8LUiajm5A7P7peaOS064K3TQjVAfjDe2fDqUSneiaceuDgDcApVYUpMXInCCuZw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;341&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;Image FocusPlugin--unfocused Image--isBlock&quot; data-ratio=&quot;0.555&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcf6UicViaMRj6HicuSic8LUiajm5npnXSEAguVVZ319icKVmAmCIE4DiaQs3TA9BWgl88lHggjicusq7wePGg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;600&quot; /&gt;&lt;/p&gt;
&lt;p&gt;不仅在小鼠， 蝙蝠的大脑里也存在Grid Cell， 与三维空间相对应, 参见 Grid cells without theta oscillations in the entorhinal cortex of bats Nature&lt;/p&gt;
&lt;p&gt;&lt;span data-offset-key=&quot;egu7f-0-0&quot;&gt;在Grid cell和Place cell发现之后，认知地图的理论奠定了统治地位，空间学习需要一个先验的神经空间坐标系成为了共识。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;a2nid-0-0&quot;&gt;四 人工智能时代的续篇&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;eciud-0-0&quot;&gt;在人工智能时代，我们越来越发现这些早期认知科学争论过的核心主题， 事实上对发展从狭义到通用的人工智能都非常重要。你要先理解智能，才能做出人工智能， 否则做出的东西只有“人工”没有“智能” 。  &lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;2rrte-0-0&quot;&gt;在DeepMind去年发表的一篇和空间导航有关的论文里， 它们也确实把这种和空间有关的结构- Grid Cell 引入到了它们的网络架构里，而非常有趣的是， 如同当年的认知科学家所阐述的， 这个空间坐标结构的引入， 使得导航出现了类似于直接利用捷径这样的行为。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;1pob1-0-0&quot;&gt;而与空间结构的先验学派不同的是，DeepMind的这个Grid Cell 结构， 事实上是从利用监督学习进行引导的。  DeepMind 让人工“小鼠” 在方格空间里乱跑并预测其位置，在这个过程里， 如果适当的引入dropout这样的条件，它们表明就可以出现类似于Grid的细胞结构。 而这个结构正是刚刚说的寻找捷径行为的基础。论证的方法也和生物实验相同， 就是去掉这些细胞观测， 寻找捷径的行为消失了。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;Image FocusPlugin--unfocused Image--isBlock&quot; data-ratio=&quot;0.6866666666666666&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcf6UicViaMRj6HicuSic8LUiajm5121JlNk1abM39bE8hurQ6uP0uVKoeKEia4xA2ibQwpdYvWydLIas8T6w/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;600&quot; /&gt;&lt;/p&gt;
&lt;p&gt;Vector-based navigation using grid-like representations in artificial agents  Nature&lt;/p&gt;
&lt;p&gt;&lt;span data-offset-key=&quot;ej61m-0-0&quot;&gt;这篇文章在专业圈子引起了很多批判，很多学者不认可这样形成的Grid Cell就是生物学的Grid Cell。&lt;/span&gt;另外一种可能是Grid Cell只是许多对空间探索有利的结构的一种，而这种结构恰恰是无论是自然训练还是人工训练都非常容易找到的一种， 可能对应某个自然界的最小作用原理（事实上六边形是周期性的布满一个二维空间的最经济方法）。因此DeepMind的这个作品也就没有那么神奇了。&lt;/p&gt;

&lt;p&gt;在思考这个问题的时候， 我个人依然觉得到庞加莱等人的经验主义思想具有极高的借鉴价值。 虽然用认知地图方便好用， 但是它是否是最基本的东西？  我们大脑里的那个空间概念最根本的东西究竟是什么？ 或许背后更本质的东西依然是几条抽象的数学规则，而我们大脑的神奇在于利用这个规则得到地图这类方便的概念。Deepmind按照人们已经预期设定的理论找到了同样的结果， 虽然促进了AI的进步， 但是对于我们理解这个问题却是有限的。&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;9md34-0-0&quot;&gt;五 关于空间任务之外的启示&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;9lp2a-0-0&quot;&gt;不管认知地图是否最终成立，生物学的研究，还是人工智能的研究，都在指向的一个共同点，就是我们学习需要预先存在的特定“结构”，而不是简单的多级条件反射可以得到， 虽然在深度强化学习时代，多级条件反射给我们展示的可能性比我们想的多很多。 而AI的研究在告诉我们， 这样的先验结构， 是可以通过大量的预训练得到的。 &lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;9lp2a-0-0&quot;&gt;如何预训练， 怎么设计预训练流程， 可能是未来的一个极为重要的方向。Karl Friston所说的预测误差最小，最新的大量关于好奇心的研究，甚至最近的语言模型Bert，可能都在提示我们怎样设计这样的流程。  同时，这样的研究或许也在启发我们如何更好的设计婴儿的早期教育 ，使得后期的学习效果更好。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;8il2h-0-0&quot;&gt;对于空间的思考本身， 对于非空间的很多任务也极有启发。 比如我们常说的语言。 我们知道，语言代表了我们使用和控制符号的能力，  而“符号” 和空间“位置”的关系是什么？ 是否存在一种隐喻， 正是由于我们发展出了对抽象的“空间” 和 “位置”的认知能力， 才引领我们走向了更广义的形成和使用“符号”的能力？ 在一个抽象的“符号” 地图里， 运动不再是欧式空间里从一点到另一点的轨迹， 而可能是一种逻辑思维的流动？  这些都将是未来人工智能极为需要回答的问题。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;Image FocusPlugin--unfocused Image--isBlock&quot; data-ratio=&quot;0.74&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcf6UicViaMRj6HicuSic8LUiajm5bKc1g86RibzW2OmNLVicH3kQMLTvr6iaGSrPTnt5iaB5kP7uYozTuzMgsQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;600&quot; /&gt;&lt;/p&gt;
&lt;p&gt;Organizing Conceptual Knowledge in Humans with a Grid-like Code  Science   一个惊人的实验， 在人类进行对不同形状的关联（把一种形状的鸟对应到另一个形状上）的时候， 类似的Grid的神经表示出现&lt;/p&gt;
&lt;p&gt;&lt;span&gt;参考文献&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;http://www.cognitivemap.net&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;http://www.cognitivemap.net/HCMpdf/HCMComplete.pdf&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;更多阅读&lt;br /&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651383872&amp;amp;idx=1&amp;amp;sn=07e6ad262787f89af6ea00eaeefb9df1&amp;amp;chksm=84f3c601b3844f170021e030a84c70f662c8f03f96db7eece0670a6a3de2d3a16cfc3370b2f5&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-itemshowtype=&quot;0&quot; data-linktype=&quot;2&quot;&gt;模拟人类大脑 ：人工智能的救赎之路 ？&lt;/a&gt;&lt;br /&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651383843&amp;amp;idx=1&amp;amp;sn=41e82163f76edfe5ffe31a8518d5bafa&amp;amp;chksm=84f3c662b3844f7430b27f82522dd9414d6c481f6e63822d99deb8baf281be8681ea5c4413a7&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-itemshowtype=&quot;0&quot; data-linktype=&quot;2&quot;&gt;大脑的自由能假说-兼论认知科学与机器学习&lt;/a&gt;&lt;br /&gt;&lt;/p&gt;
</description>
<pubDate>Wed, 13 Mar 2019 11:44:39 +0000</pubDate>
<dc:language>zh-CN</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.jintiankansha.me/t/9DKU2tIReQ</dc:identifier>
</item>
<item>
<title>读《Possible Mind》，看25位大咖谈AI</title>
<link>http://www.jintiankansha.me/t/mtbIgoi2zA</link>
<guid isPermaLink="true" >http://www.jintiankansha.me/t/mtbIgoi2zA</guid>
<description>&lt;p&gt;好久没写读书笔记了，最近还是读了不少书的，选取其中最值得分享的一本，简单的介绍下。&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;1.51875&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibceaCia3ppia3xp8PybpqCOpJCpvq0M7fIyD4YJafYz3MqV6kIyyx6NVrUb0QxRlFibfRfAxC7XlCBENA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;320&quot; /&gt;&lt;/p&gt;

&lt;p&gt;这本书是今年2月份出版的，编者是Edge网站的创始人John Brockman，之前Edge出的书，我都是一本不落下的都看过的，例如&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651382220&amp;amp;idx=1&amp;amp;sn=5d8f83d31878527f91e214bb929f8086&amp;amp;chksm=84f3cf8db384469b1d91d03041896b8c0c7b03e252e4e866d4bbd0ef218ee9d79251404f7ee0&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-itemshowtype=&quot;0&quot; data-linktype=&quot;2&quot;&gt;用还原论来回答一个问题-从Edge网站的年度问题说起&lt;/a&gt; 以及 &lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651382530&amp;amp;idx=1&amp;amp;sn=188560244e704449596c9807fc72ef5d&amp;amp;chksm=84f3cd43b3844455a4b76b01cbb778a1dfdd8f6e22f97247efd2e673e0738edc13eae0046122&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-itemshowtype=&quot;0&quot; data-linktype=&quot;2&quot;&gt;灯下暗影：关于那些“忧虑”的忧虑——评Edge2013《那些科学家们彻夜忧虑的问题》&lt;/a&gt;等。《Possible mind》这本书由25偏随笔性的议论文组成，书中的随笔的作者来自各个背景，既有有物理学，生物学这样的硬科学，也有艺术家和畅销书作家，其中不少是我曾读过其的作品，例如Max Tegmark，Steven Pinker，丹尼尔丹内特，这些人除了在本领域内做出了成绩，在对社会整体问题的讨论中，也保持这自己独特而深邃的见解。&lt;/p&gt;

&lt;p&gt;全书的话题虽然是围绕着人工智能对未来的影响这个热门话题谈起，但书中的每篇文，都在或直接，或间接的围绕着控制论创始人诺伯特·维纳在1950年出版的一本名为《人有人的用处-控制论与社会》展开（该书英文标题是“The human use of human being”），《Possible mind》仿佛是针对这本书，每位大咖写了一篇读后感，然后集结成册。正是由于拉开了近70年的时间差距，才让《Possible mind》这本书中的文字不局限于当下，而具有更长久的半衰期。&lt;/p&gt;

&lt;p&gt;全书中除了几篇艺术家写的文，每一篇的文我都读了俩遍，这不是一本容易读的书，书中每一篇都全没有一句废话，除了原样翻译，不知道该如何能用更精炼的语言加以概括或总结。全书可以看成是一场辩论比赛，正反俩方在讨论当下人工智能的发展有没有让我们变成我们制造的工具的奴隶，人工智能的终极天花板又在哪里，该不该对其有所限制。书中的观点不是像量子力学那样烧脑，但逻辑严丝合缝，你看到了截然不同的观点，看着每一篇都有道理，想将多篇整合成一个统一的东西，却感觉无比困难，这也是我不知该怎么来写这篇读书笔记的原因。&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;1.3824884792626728&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibceaCia3ppia3xp8PybpqCOpJChQn5zwxD7PvsolTgYgqg1mpJ4VUBTj5AKjwtTGsplsohZ4lw4mic5qQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;651&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;本书的25篇议论文的标题&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;我可以从书中选出几章来，分别用自己的话来概述大咖的观点，再加上点评及自己的观点，再结合国内的现状，写一个系列，但这毕竟不是一手的知识。即使这本书有了翻译版，由于该书的知识背景很广，翻译难度不低，我对翻译的质量表示担忧的，很多原作中的细微的地方，会由于翻译的原因，读起来不够流利，所以在这里奉上这本书的下载链接，&lt;strong&gt;如果读者对其中的那一章感兴趣，可以留言，我再接下来试着再针对这本书再多写一些文字&lt;/strong&gt;。我们需要更多人来了解AI这个正在从方方面面默不作声的塑造着我们日常生活的基础设施，不止是了解其中的原理。中世纪的时候，只有教士才会书写，而文艺复兴让越来越多的人掌握了文字，从而带来了历史进程的“寒武纪大爆发”，而当代只有程序猿才会编程或者懂AI，假设全球有1%的人能了解AI的原理和影响，那整个社会在面对新技术带来的冲击与机遇时，才会走的更快更稳。&lt;/p&gt;

&lt;p&gt;&lt;span&gt;链接：https://pan.baidu.com/s/1GH0SmsOXOmp3O6jsbOKmeg &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;提取码：78s0 &lt;/span&gt;&lt;/p&gt;

&lt;p&gt;在阅读《Possible Mind》这本书之前，请务必先读一下维纳的这本《人有人的用处》。该书1950年出版的时候，1954年再版时删除了其中部分激进的观点。一本近70年前的一百多页的小书，读起来却如同是在说当下。控制论的关键词是信息，反馈，通讯，维纳这本书用控制论的思路跨界分析社会问题。读完了《Possible mind》，我又读了这本书在书中被多次引用的《人有人的用处》，下面摘录书中的几段，没有读过这本经典之作的，可以借此了解该书的主旨。也许之后我会针对《人有人的用处》这本书认真写一篇读书后的思考长文，但值得分享的材料不应该等待太久，因此在这里先简单的和读者汇报一下。&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;1.43&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibceaCia3ppia3xp8PybpqCOpJCahuQVh1u0iaK6fDibOUp7JNwjA6alm9CPMvXe8CKMb00ywlO5a9yR20w/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;300&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;我们是如此彻底地改造了我们的环境，以致我们现在必须改造自己，才能在这个新环境中生存下去。我们再也不能生活在旧环境中了。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;新工业革命是一把双刃刀，它可以用来为人类造福，但是，仅当人类生存的时间足够长时，我们才有可能进入这个为人类造福的时期。新工业革命也可以毁灭人类，如果我们不去理智地利用它，它就有可能很快地发展到这个地步的。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;人是束缚在他自己的感官所能知觉到的世界中的。举凡他所收到的信息都得通过他的大脑和神经系统来进行调整，只在经过存储、校对和选择的特定过程之后，它才进入效应器，一般是他的肌肉。这些效应器又作用于外界，同时通过运动感觉器官末梢这类感受器再反作用于中枢神经系统，而运动感觉器官所收到的信息又和他过去存储的信息结合在一起去影响未来的行动&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;用任何方法传递消息或者从任何外部来干预它们，都会降低它们所含的信息量，除非利用新的感觉或原先处于信息系统以外的记忆输入新的信。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;更多阅读&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651383323&amp;amp;idx=1&amp;amp;sn=1b954794ff6ea866a19d420a517ccab3&amp;amp;chksm=84f3c85ab384414c1df772db5510441e30a3c4983923280528e6296b7fc82603d7e23ec8c12a&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-itemshowtype=&quot;0&quot; data-linktype=&quot;2&quot;&gt;黑镜书单-列一列那些反思互联网和人工智能的30本警世之书&lt;/a&gt;&lt;br /&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651383580&amp;amp;idx=1&amp;amp;sn=da0870102ecdc4a1802d28bb5db92574&amp;amp;chksm=84f3c95db384404bd330565babd688d50f11fac8a9cda914520f61f538c54eebf2f9466dd5c7&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-itemshowtype=&quot;0&quot; data-linktype=&quot;2&quot;&gt;生命3.0-在亿年的尺度下审视生命的演进&lt;/a&gt;&lt;br /&gt;&lt;/p&gt;

</description>
<pubDate>Mon, 11 Mar 2019 15:23:11 +0000</pubDate>
<dc:language>zh-CN</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.jintiankansha.me/t/mtbIgoi2zA</dc:identifier>
</item>
<item>
<title>让神经网络看懂图像</title>
<link>http://www.jintiankansha.me/t/C8XQvUfjg6</link>
<guid isPermaLink="true" >http://www.jintiankansha.me/t/C8XQvUfjg6</guid>
<description>&lt;p&gt;视觉的重要性毋庸置疑， 你可以想象，我们平时的生活， 从识图辨物， 到读书看电脑， 哪一个离不开视觉。 所谓的互联网信息大爆炸， 你看看我们手机空间里的大部分图片是什么， 一定是照片。 所以， 我们说视觉占领了我们信息的主体。这背后深层的原因是视觉相对听觉或触觉对真实世界的信息效率大的多， 一个图片可能包含很长一段文字的信息， 这点是其它渠道所不能比拟的。生物进化出视觉而有了寒武纪大爆发， 那么让机器拥有视觉能力， 一定是让它变得更聪明的第一步。  &lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.37558062375580625&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcf5diaEmI5SjKhUZmLUmaX4koFQJ0KyYo2twh0dBzVDic9bb8quJZRv5c5pBP6oEFiafTobNPhstZugw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1507&quot;/&gt;&lt;/p&gt;
&lt;p&gt; &lt;br/&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;人脑对图像的认知：&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;电脑记录下来的图像是由一个个像素构成的，每个像素又分为r，g，b三个通道（可以理解为垂直排列的三个像素），这三个通道起到复现整个光场的作用。而事实上物理里的真实的图象， 是一个由无数光子组成的电磁场， 这个电磁场在我们的视网膜上振动， 从而形成了我们对图象的感知。 因此， 归根到底 ，我们是用大脑， 而不是用双眼来感知图象的， 也许我们永远无法知道真实世界是什么样， 但是是我们的大脑赋予了它形象， 一个很好的例子就是你分不清猪的美丑， 但我想猪是可以的， 这正说明了所谓的相由心生， 你不关心， 就看不到。&lt;/p&gt;
&lt;p&gt; &lt;br/&gt;&lt;/p&gt;
&lt;p&gt;那么什么是我们大脑处理图象的神经基础呢？  多少代的科学家研究这个问题， 最终有了一个比较完备的答案。   一个眼睛正常的人不一定能够产生对视觉的知觉， 有一种叫视觉认知症的人： visual agnosia，   它们虽然可以看见物体， 却无法区分一个物体时什么， 课件， 看到， 不等于知道。 事实上， 大脑对视觉的感知主要时通过视觉回路实现的， 这个视觉回路的概念 ， 主要是通过视皮层V1-V4完成的。&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.5879120879120879&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcf5diaEmI5SjKhUZmLUmaX4kb3jh8KiboexvaqpcbeXAAWHYPVGfrYdGsW44hGIrAbGegiadpFme1RqQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;910&quot;/&gt;&lt;/p&gt;
&lt;p&gt; 这个v1到v4的视觉回路，  本质起到的作用是一级一级的筛选视觉特征。  我们之前讲过， 每个细胞都相当于一个小的特征检测器， 而我们事实上发现， 这些小的特征选择器所检测的目标是不同的， 有的对简单的特征敏感， 比如桌子的轮廓边角， 有些对复杂的特征敏感， 比如桌子的腿或边角， 一个重要的假设是复杂细胞形成的基础正是简单细胞的组合， 很多简单细胞的输入构成了复杂细胞。  而最“复杂”的一些细胞， 居然会对那些抽象的人名，物体概念敏感。  为了表达这种极端的特性， 我们把这类极为复杂的细胞称为“祖母细胞”就好像每个人的脑子里都有那么一个细胞对自己的祖母是反应的， 它就是祖母的代言。&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;1.0314465408805031&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcf5diaEmI5SjKhUZmLUmaX4kOlUDudCyB33jMJ5wnvGPibNKORj7lBVRqKJp2zNgicp8RBjwEIPibGia0Q/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;636&quot;/&gt;&lt;/p&gt;
&lt;p&gt; &lt;br/&gt;&lt;/p&gt;
&lt;p&gt;这种表面的“简单”， “复杂”其实可以被一个称为为层级编码假设的理论解释， 说的是比较底层的细胞先得到从视网膜传来的视觉信号（类似数码相机的图象）进行处理， 然后所谓的“复杂”细胞， 无非是把最底层的特征拼接组合起来， 得到比较了比较复杂的特征。而最终当我们得到的祖母的头， 鼻子， 或眼睛这些特征的时候， 在最后进行一次综合就得到了“祖母细胞”这种复杂概念的对应物。当然， 这只是粗浅版本的视觉编码机制。 很多人认为除了层级特征， 视觉编码还需要具有集群编码的特性， 也不一定存在那么一个特定的祖母细胞， 而是概念被一个细胞发放的集体模式所表达。 这些我们就不一一详述了。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;模拟人脑的CNN&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;如何把图象让机算计处理呢？ 我们可以在深度学习兴起以前， 这是一个超级超级难的问题。 我们就拿机器视觉最简单的例子： 图象分类来说。我们前两节课讲过应鸢尾花的识别， 在这个例子里， 我们看到的实际状况是花的照片来了， 然后我们的植物学家告诉我们花瓣的长度和宽度是重要的特征， 它可与把鸢尾花分为三类， 这样，我们的计算机就可以用前面讲过的KNN把花分成三类。这个方法里， 计算机事实上接受的一个表格数据， 也就是花的特征总结， 而得到一个分类的结论。 非常可惜的是， 这和真正的图象识别相差甚远。 因为真正的图象识别，意味着我们直接把图象，也就是我们看到的原始数据给计算机处理。 或者说， 计算机需要自己找出像花的长度和宽度这样的特征。&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.7663197729422895&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcf5diaEmI5SjKhUZmLUmaX4kKiadibV0TFibYrLIgxtiapoYGNARzgOMy6SiaiaTUa01jNaakulibgMCDo9bA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1057&quot;/&gt;&lt;/p&gt;

&lt;p&gt;刚刚说了， 计算机眼里的图象是一个巨大的矩阵， 首先图象由像素组成， 每个像素就是一个数字， 它代表我们对信息的采样。 像素组成的图象是黑白的， 然后我们需要对不同波段的光波分别形成这样一个黑白图， 然后把它们拼接在一起，得到我们最后的彩色照片，比如我们拿一个日常的3x256x256的图像看， 那个像素就是256x256个，然后有三个色彩通道。 如此组成了一张图片。最终这个图象这样的信息维度是巨大的。 远非机器学习的常见问题可以比拟。&lt;/p&gt;

&lt;p&gt;让机器来直接看图，这个在过去看似不可能的技术，被一个叫卷积网络的东西给解决掉了，在2012 ，它超过了所有的视觉算法， 并在随后几年在很大的数据集上赶超人类。这个卷积网络正是对刚说的生物神经网络的直接模拟。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt; &lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;什么是卷积&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;你要理解卷积， 只需要理解一个东西叫滤镜， 人类在处理图像问题的时候， 最有名的发明莫属photoshop了， 在ps里你可以把图片调整各种各样的色调，模糊，锐化， 这些东西统统是一个叫做滤镜的东西做出的。&lt;/p&gt;
&lt;p&gt; 滤镜这个玩应， 你可能想到镜头前的镜片，事实上，它所做的事情是把图像转化为 一个另一个图片。 它是怎么做到的呢？ 数学上的操作，正是今天讲的卷积。数学上， 这些操作对应的运算都有一个特点， 就是对局部的信息进行综合 ，得到一个新的信息。&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.5936352509179926&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcf5diaEmI5SjKhUZmLUmaX4kNMkicsrDnx2xgaJqavCTW5TiaicO92Sj5mIUn7SZ58zAFTs18pHkyicdPw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;817&quot;/&gt;&lt;/p&gt;

&lt;p&gt;看看卷积的数学操作，卷积，顾名思义， “卷”有席卷的意思，“积“ 有乘积的意思。 卷积实质上是用一个叫kernel的矩阵，从图像的小块上一一贴过去，一次和图像块的每一个像素乘积得到一个output值， 扫过之后就得到了一个新的图像。我们用一个3*3的卷积卷过一个4*4的图像。&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.6256627783669141&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcf5diaEmI5SjKhUZmLUmaX4kiafx1W2wMDMpcpjib6VfT1xRjogT5ptswDhOPM6X16H3TTcteENjmpcw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;943&quot;/&gt;&lt;/p&gt;
&lt;p&gt; &lt;br/&gt;&lt;/p&gt;
&lt;p&gt;卷积网络的基础正是这样的卷积， 我们说通过一个滤镜我们可以提取一个图象的特征， 那么为什么我们要采取看起来这么笨拙的一个方法呢？&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;图像识别与降维&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt; &lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;其实要让神经网络告诉某两个照片是香蕉还是苹果， 并不是那么难， 但是图像识别的根本目标是你要识别整个世界的香蕉或苹果， 这个问题背后的核心是我们之前讲的泛化。  也就是让它理解苹果这个概念。当然你可能会想到苹果是红色， 圆形这种具体的特征，这些特征变化了，它就不是苹果了。 但是我今天要说的是， 你要让计算机来学到这个东西， 你要想的是反过来， 那就是， 什么特征变化了， 它还是一个苹果？&lt;/p&gt;

&lt;p&gt;首先，我们想到的是， 一张图象是跟苹果还是香蕉， 首先一定不取决于它所处在图象中的位置。 这个东西叫位置不变性， 或者叫&lt;strong&gt;平移不变性&lt;/strong&gt;。我们把这个特性直接写到神经网络里， 就是卷积。 什么意思， 卷积就是拿着一个恒定不变的小型矩阵， 一行行的扫过整个图像， 这样得到一个特征图。 你的苹果无论出现在什么位置， 对应我的卷积扫描这个行为， 事实上得到的结果都是一样的， 数学上说， 就是你的图像如果移动了5个格， 它在特征图上也做同样的一个移动， 别的什么都不变。 能够满足这种条件的运算-就是卷积。&lt;/p&gt;
&lt;p&gt; &lt;img class=&quot;&quot; data-ratio=&quot;0.5&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcf5diaEmI5SjKhUZmLUmaX4kicEJJke9nugZB031A0zcCJglstLuNPuGjxZahlHk4qFzGDJ4aqSj2vw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;362&quot;/&gt;&lt;/p&gt;
&lt;p&gt;卷积被当成先验信息写入，每次卷积都对应一个神经元对图像的一个小块进行信息提取， 而每个神经元与输入的连接系数均是一致的，这个特性叫做&lt;strong&gt;权值共享&lt;/strong&gt;。不要小瞧这样一个简化，有了这样一个简化，我们的神经网络得到正确的解就好了很多。用一个术语就是， 我们把问题的维度减少了。 抓住一个不变性， 你就可以把需要解决问题的维度指数级别的减少。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;激活函数：&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;事实上完成局部特征检测这一步，我们还需要一个东西，就是激活函数， 这个我摸嗯上节课已经讲过了，一般这里用的激活函数是relu，它的作用是把一个信号里为负的部分变成0，你可以把这看成特征提取的实现，更本质的说，如果没有激活函数，我们的神经网络将是一个巨大的线性回归而已。&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.7770034843205574&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcf5diaEmI5SjKhUZmLUmaX4k3LIxRYO5HB5yXEjicsicJ68fOBCvKOMSqnqQBZFvuMW6LOyZV1a1mibJA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;287&quot;/&gt;&lt;/p&gt;

&lt;p&gt; &lt;span helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; start=&quot;&quot; rgb=&quot;&quot;&gt;ReLU函数是小于0是为0，大于0时为自身&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;什么是通道：&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;

&lt;p&gt;我们以一个手写数字的历程为例，讲讲我们还需要什么，首先我们说， 一层卷积对应一个特征， 但是，显然一个特征是不够识别的。 就以识别数字为例子降价给你这个问题， 比如你要识别10个数字，仅以1和7为例子。显然识别它们的核心方法就是条纹走向。横线是一个特征，竖线是一个特征。如果一个卷积对应一个特征，那么我们其实需要两个卷积，让一个卷积核可以识别横向条纹， 另一个卷积核识别纵向条纹， 这个操作就可以。&lt;/p&gt;

&lt;p&gt;这样的操作，使用如下的3x3卷积就可以了： -1，1， -1  ，  这样的算子具有和之前提取梯度的运算差不多的样子。只要两种卷积核可以做到这点， 然后，如果我们把这两个卷积核组成一个小组扫描一个特征， 那么我们就会知道每个图像小块上的横竖情况。&lt;/p&gt;

&lt;p&gt;比如这时候我们得到每个图像小块的一个特征编码，一共有四种情况 （0，0），（0，1），（1，0）（1，1），横线对应（1，0）竖线对应（0，1）， 你是不是可以把整个数表看成一个新的图像 ？ 而这个新的图像里的变化从（1，0）到（0，1）是否相当于一个角度呢？ 这就是比条纹走向更高级的一个特征。 怎么提取它？如果你的答案是再放入一层卷积， 恭喜你答对了。&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.4789272030651341&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcf5diaEmI5SjKhUZmLUmaX4kxd2XRKOic2My0D0qappe2qgI8L3KYvLk6khicEElAict1x1SKCCQWzXxg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1305&quot;/&gt;&lt;/p&gt;
&lt;p&gt;回顾整个过程，我们要做的无非是在第一卷积层的位置上， 放两个并行的卷积核， 一个核处理横向条纹，一个处理纵条纹， 得到两组不同的特征， 最终我们在前面的两个特征之上读取这组新生成的特征图之上的特征。 下一层卷积寻找的上一组卷积的特征组合。这个操作对应的是在两张并列的图层之上，在它们的同一位置识别信息， 如果两个警报器均响了，说明夹角存在，  我们依然可以用一个3x3卷积网络来完成这个操作，这个新的卷积建立在之前的纵横两组卷积之上，对原先的横纹和纵纹组成的特征空间进行操作（因为这里的维度是2x3x3，最单纯的情况我们也可以用一个2x1x1的一个矩阵综合两个特征）。  因为这个时候， 对之前平行卷积的结果做一个综合， 以及形成一个特征之特征， 即横向和竖线交叉的特征。&lt;/p&gt;

&lt;p&gt;这样的方法无论手写数字出现在什么位置，  我都给你找出来。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;从两层到多层：&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;我们刚刚说 kernel就是通过计算小区域内像素的关系来提取局部特征，而最常用的卷积核大小是3x3， 那么这里的一个问题是， 为什么要这么小， 为什么要提取一个局部信息？我们说因为图像这个东西里包含的信息具有以下特点： 最底层的信息，比如边角轮廓， 都存在于局部之中， 只有更上层的信息，比如物体的概念， 才会用到更多部分的信息， 而这种跨度又是逐步发生的。那么，如果实现这种跨度呢？  答案： 多层。局部特征，在更高层上被组合， 会变成整体特征。&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.42369186046511625&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcf5diaEmI5SjKhUZmLUmaX4kKqsX2xB7m1ZnmrTCNuF12RThK0PURyTC5mgzPrDDw2PZpEcS3SF0vw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1376&quot;/&gt;&lt;/p&gt;

&lt;p&gt;&lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;/&gt;  首先，我们把每个神经特征所提取的特征区域， 叫感受野，如果我们始终只能用的其实都是3x3这样的小卷积核， 我们能不能让感受野扩大呢？ 答案是， 可以。 这里的关键是一个叫池化的造作。&lt;/p&gt;

&lt;p&gt;最大池化所做的是事情，是把每四个相邻神经元得到的数值取一个最大的， 其它全部扔掉。每次卷积后如果经过这样一个操作，那么图像就会缩小到原先的四分之一，而再次之上的相邻四个像素， 对应了原始的16个像素， 从而使得感受野迅速扩大。&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.5582706766917294&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcf5diaEmI5SjKhUZmLUmaX4kA57IKwRcHrqUjq6SVb77Sd3ibgSvvcDxNOzRHgaBrmiazv7e1Yrb209g/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1064&quot;/&gt;&lt;br/&gt;&lt;/p&gt;

&lt;p&gt;Pooling的本质依然是降维，或者过滤冗余信息，这个就是pooling。背后能够这样做的理由是，局域特征特征是大量冗余的 ，经过条纹提取的数字一定在大量临近区域里的数值都一样。 冗余踢去后， 经过pooling， 上层细胞得到更大的感受野，也就抽取了更高层次的特征。&lt;/p&gt;
&lt;p&gt; &lt;br/&gt;&lt;/p&gt;
&lt;p&gt;卷积层 ，激活函数，pooling帮我完整的特征提取到剔除冗余的过程 ， 这可以称为卷积网络的三明治， 把这个结构不停迭代，我们可以构建一个很深的网络。&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.363479758828596&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcf5diaEmI5SjKhUZmLUmaX4kMARlAiaha7Tp0OAyibiclNr6c5R7PS7uCicOZjRjCkZP35apJUxgq2rJnw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1161&quot;/&gt;&lt;/p&gt;

&lt;p&gt;深度意味着什么？  我们想一下， 要正确的识别一个图像，你不可能只看边，也不可能只看角， 你要对图像的整体有认识才知道张三李四。 也就是说我们要从局部关联进化到全局关联， 真实的图像一定是有一个全局的，比如手我的脸， 只有我的眼镜，鼻子耳朵都被一起观察时候才称得上我的脸，一个只要局部，就什么都不是了。如何提取全局特征？ 从一个层次到另一个层次的递进， 通常是对上一层次做横向以及纵向的整合（图层间的组合或图层之内的组合或两者）。&lt;br/&gt;&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.4612005856515373&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcf5diaEmI5SjKhUZmLUmaX4kicPBaImgyWqzuJNtkEKMbrIrkzPSdp6UWZyq9NgShHPJb3P6MtCmibjQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1366&quot;/&gt;&lt;/p&gt;

&lt;p&gt;我们刚刚讲了CNN如何找到边角的过程， 但是它的下一层会是什么？再下一层会是什么？ 我们头脑中的想象力已经不够了。我们只能做让学习得到结构，然后去观测。我们可以把每组卷积网络看做一组基，我们在这组基上重构我们的信息， 就和线性代数里坐标变换相似，只不过非线性更复杂。 每一级别的网络都是一组新的基底，我们把刚刚的全局换一个词叫抽象。深度卷积赋予了神经网络以抽象能力。 这样的一级级向上卷积做基变换的过程，有人说叫搞基（深度学习就是搞基），深一点想叫表征， 和人的思维做个比喻就是抽象。 抽象是我在很深的层次把不同的东西联系起来，CNN教会了我们实现抽象的一种物理方法，  他也体现了在一个空间尺度上我们所能够达到的特征工程。&lt;br/&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;最终分类：&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;这里我们还差最后一步没讲， 整个CNN网络如同一个等级社会里，最上层的，就是君王。 而这个君王，与直接其下的一层（议会）的关系，事实上往往是全连接网络。为什么，因为这时候君王要做的是最终决策， 它不在“搞基”提取特征了。一个非常复杂的问题，已经在此时变成了线性可分的简单问题。 决策 – 就是做一个线性分类， 得到我最想要的结果。  我们要做的是返回一组最终可能结果的概率。如果得到可能结果的一组概率？ 我们搬出基于最大熵模型的softmax  gate ，这也是正是CNN网络做分类的最后一层。 至此，我们可以得到众多识别物体的抽象信息。 那个概率最大的，即使我想要的结果。&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.5389435989256938&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcf5diaEmI5SjKhUZmLUmaX4kF6KG6kGBVeH4Zwib3bCIeFwOrMQygTJ8ckUDyfZHkLTCEKfHmgbfSlQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1117&quot;/&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;总结：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.7400318979266348&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcf5diaEmI5SjKhUZmLUmaX4kByPbeQrjLRAFZMt2UBqXLDompmohkqQN7fjYMqSlaeWfxI0jZaQ2og/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;627&quot;/&gt;&lt;/p&gt;
&lt;p&gt;更多阅读&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651383212&amp;amp;idx=1&amp;amp;sn=e6dbbda2acc5984c8d06e24ec9c84d09&amp;amp;chksm=84f3cbedb38442fb58f0aea635821fcf4ba3edaacef4685716c7eadb6191197ebfa70a6bf14b&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-itemshowtype=&quot;0&quot; data-linktype=&quot;2&quot;&gt;你所不能不知道的CNN&lt;/a&gt;&lt;br/&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651381959&amp;amp;idx=1&amp;amp;sn=1b920dd476849d88b67a2ef1cf3ed8fc&amp;amp;chksm=84f3ce86b3844790627d2f15256aff0753be1f0b0623da64aaa7357d73e8ed14c415061acb27&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-itemshowtype=&quot;0&quot; data-linktype=&quot;2&quot;&gt;用CNN来识别鸟or飞机的图像&lt;/a&gt;&lt;br/&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;作者简介：微信号：ironcruiser 法国巴黎高师物理硕士 ，以色列理工大学计算神经科学博士，巡洋舰科技有限公司创始人, 《机器学习与复杂系统》纸质书作者。 &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;img data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibccvEGHcvx6vn7ibqucwWjTLJNQDiajMVL3arkx9IJnm10baZ1RjdLTN2KH6SKHZqnzyGO5K0G3dNOwg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; class=&quot;&quot; data-ratio=&quot;5.896&quot; data-w=&quot;750&quot;/&gt;&lt;/span&gt;&lt;/p&gt;
</description>
<pubDate>Sat, 02 Mar 2019 11:40:37 +0000</pubDate>
<dc:language>zh-CN</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.jintiankansha.me/t/C8XQvUfjg6</dc:identifier>
</item>
<item>
<title>基于一张“规则表”的人工智能</title>
<link>http://www.jintiankansha.me/t/WW3EirRLSj</link>
<guid isPermaLink="true" >http://www.jintiankansha.me/t/WW3EirRLSj</guid>
<description>&lt;p&gt;&lt;span data-offset-key=&quot;4ds8l-0-0&quot;&gt;我在过去对人工智能简史的描述中，把人工智能的整个历史描述成围绕一张规则表， 本文是基于这一想法的总结和扩展。我们说，早期的AI发展史围绕如何人为构建这样一个规则表解决复杂问题， 而当下的AI则围绕如何让它在复杂的现象中自己归纳出这个规则表。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;bkglj-0-0&quot;&gt;我们说，上帝通过制定规则从简单演绎出复杂。最初的原始人类在黑暗中摸索， 在众多的现象不知所措， 只能通过设立各色大神小神来缓解自己对不确定性的恐惧。 从多神宗教到一神宗教的跨度体现了一个从复杂中寻找简单的跨度， 这可能是基于一种隐隐的直觉，就是现象虽然多样， 但是背后的法则不应该如此复杂。 到了科学的时代， 这种思维在物理学里淋漓尽致起来，四大力学， 把分子原子间的作用力统一到电磁力， 把宏观物体的作用统一到引力和经典的动力方程， 已经是极致。 而后面的对这两者的统一构成了从广义相对论后的现代物理主线。  &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.5625&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibccd3W2SkazpguaDUmf1EWibibembXL81evOfRdy0cTz2qqulnss6iaFGmXLmdjuRu9GiayK86XIM1TVSg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;640&quot; /&gt;&lt;/p&gt;
&lt;p&gt;图: 简单规则生成复杂的极好例子， 元胞自动机， 每一步细胞的繁殖和扩散方法一定（左图黑格表述的， 从上一行到下一行的变化法则）， 它最后形成的图案就定了， 规则可以很简单， 图案可以很复杂。 &lt;/p&gt;

&lt;p&gt;&lt;strong&gt;早期的智能：  制定规则表 - 迭代&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz/dcEP2tDMibcfyNibceeGvVKo0qCGicGJ9lQ9J5zzOIxmTUAE4OYfwx25QZ2J2KLUic1lWYkMwelC8Ld30RF0FsibAPQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; class=&quot;&quot; data-ratio=&quot;0.1671875&quot; data-w=&quot;640&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;c1j7g-0-0&quot;&gt;另一方面，这样的思想从智能科学诞生之出，也贯穿出来。它在早期的可计算性中， 通过图灵机的构建。它认为存在这样的通用机器，能够和人类一样解决问题， 即使过程非常复杂， 你无非需要四个要素： &lt;strong&gt;1， 输入 2， 中间状态 3， 规则表 4， 输出。&lt;/strong&gt; 并在时间上进行大量迭代， 就可以实现这个过程。 通过这个过程， 我们可以把一个输入转化为一个想要的输出。 如果我们能够在在有限的步骤里将一个输入转化为一个输出，据此解决一个实际问题， 那么这个问题就是可计算的。&lt;/span&gt;&lt;/p&gt;


&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.6114081996434938&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibccd3W2SkazpguaDUmf1EWibibBnC8zkibScsiccAOwoSH4Ld9vdiamljakNVOX5TKF69ywm3Qq2ic3IdhUw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;561&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;图： 图灵纸袋， 一个在纸袋上根据一定规则表行走的机械昆虫， 机械昆虫具有一个内部状态， 并接受外部的输入，最终通过规则表找到对应的下一步输出。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;c00nl-0-0&quot;&gt;而冯诺依架构让它变成一个技术现实。 它通过可以存储程序的机器， 让人们通过把这些图灵规则表的指令变为计算机二极管的开合代码， 而让图灵纸袋的思想成为了一个每个工程师可以设计的现实，从此有了程序和程序员。 &lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;176de-0-0&quot;&gt;一个计算机程序， 最基本的部分包括一些简单的形式逻辑， 包括逻辑与或非， if else， for 循环这些。 其实本质上， if else 所描述的就是规则表， 规则里面通常涉及简单的逻辑， 最终通过for循环， 我们就可以得到我们要的东西。 比如一个中学生都会的排序算法， 我们无非需要做的是前面和后面的数比较大小， 然后一个if else进行换位， 最后一个for循环， 多长的序列都可以瞬间搞定。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;176de-0-0&quot;&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.40556900726392253&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibccd3W2SkazpguaDUmf1EWibibibEBCIwsAHiaGwDkFcYUeGLqHsuPP0ibBA7ibPX7OxPPq87Jr0NAtFjSibw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;826&quot; /&gt;&lt;/span&gt;&lt;/p&gt;


&lt;p&gt;&lt;span data-offset-key=&quot;b1ct2-0-0&quot;&gt;这就是用程序解决问题的核心思维， 给你一个再复杂手忙脚乱的问题， 只要这个问题可计算， 那么我们只需要设定好我们需要的规则表， 在有限的步骤里迭代， 最终机器总会给你解决。&lt;/span&gt;比如魔方问题， 一般的聪明小孩都很难在短时间解决问题， 但是， 事实上解决魔方问题有一套非常整齐的规则表（你想象打乱一个魔方其实比较容易的， 把它弄整齐是打乱的逆运算，但是破镜重圆总是难的）。 如果按照这个规则表执行若干步， 再困难的魔方也给你整出来。&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.75&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibccd3W2SkazpguaDUmf1EWibibz3zliaRoh4oEWf9QQOX3VMpbMFylumcHY7novvRnic1j7aN7R7pohRHQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;676&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;Image FocusPlugin--unfocused Image--isBlock&quot; data-ratio=&quot;0.44333333333333336&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibccd3W2SkazpguaDUmf1EWibibBqmPPsMKMLBUUyKWYnVsiaibg6hmZP9cADL9iak5yxuibvmosIG5ZUWbuw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;600&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;span data-offset-key=&quot;e13hv-0-0&quot;&gt;我们说规则表， 加上迭代等操作的思路可以解决大量的工程问题。我们曾经认为按照这样的思路我们可以解决整个智能的问题。 只是填入一张越来越大的表格。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;5g8h1-0-0&quot;&gt;但是它在通向智能的关键位置， 却停住了， 这个元凶 -就是- &lt;strong&gt;不确定性&lt;/strong&gt;。日常生活中很多东西无法轻易的总结出规则表来， 因为细小的规则实在太多了。 你可以想象我们有无数尺寸和规格各不相同的螺钉螺母。 每一种规格我们都要想一条if else，可悲的是这些螺钉和螺母几乎没有哪两对完全相同， 穷尽一个程序员一生也写不完这些程序。现实生活中的大部分问题属于这一类问题， 比如你无法轻易的写出一段程序来判断A男和B女是否合适结婚。 &lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;中期的智能： 让机器学会归纳规则表&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;5g8h1-0-0&quot;&gt;&lt;img data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz/dcEP2tDMibcfyNibceeGvVKo0qCGicGJ9lQ9J5zzOIxmTUAE4OYfwx25QZ2J2KLUic1lWYkMwelC8Ld30RF0FsibAPQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; class=&quot;&quot; data-ratio=&quot;0.1671875&quot; data-w=&quot;640&quot; /&gt;&lt;/span&gt;&lt;/p&gt;


&lt;p&gt;&lt;span data-offset-key=&quot;9mrot-0-0&quot;&gt;统计机器学习 - 机器判断规则&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;6pfmt-0-0&quot;&gt;这个问题的解决方法十分自然又十分了不起：  能不能让机器自己学会这个表格， 而不是认为设定它呢？  这就是整个智能问题的第二步 - 学习。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span data-offset-key=&quot;eeh10-0-0&quot;&gt;整个学习问题的基石其实是古希腊人提出的归纳法和演绎法。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;17gbk-0-0&quot;&gt;伟大的希腊哲学家早就对学习的本质展开过探讨，它们把学习分类为&lt;/span&gt;&lt;span data-offset-key=&quot;17gbk-0-1&quot;&gt;归纳法和演绎法&lt;/span&gt;&lt;span data-offset-key=&quot;17gbk-0-2&quot;&gt;。所谓演绎法， 就是从用一定规则进行推理的过程。 苏格拉底是人，人都是会死的， 因此苏格拉底会死。这就是三段论， 或者称为演绎法的根基。 而真正学习的过程，是这个演绎法的逆过程。我们先知道一个特例，然后通过特例，得到这个“人都是会死的” 知识，再指导自己的行动。 学习是知识在脑子或者机器里面形成的过程， 怎么形成？ 这个过程被称为归纳法，也就是根据搜集到的特例比如苏格拉底死了这个事情，来归纳更一般的知识。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.5625&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibccd3W2SkazpguaDUmf1EWibibmSX7rgCyJJfTKEhApOyARbIowfAnPvZVr0gFicQTQYD7WgfkLMcPbZw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;640&quot; /&gt;&lt;/p&gt;



&lt;p&gt;&lt;span data-offset-key=&quot;17gbk-0-2&quot;&gt;让机器实现归纳法， 我们来看我们需要提供给机器怎样的佐料来解决这个问题。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;6nhn2-0-0&quot;&gt;我们想象这样一台机器， 这个机器和之前说的规则机器类似， 唯一的区别是， 我们把大量的假设放在那里，让机器来连线。 我们要让它学习一个知识， 比如-什么人是否会死的。我们把人按照几个特征进行分类， 一个特征对应一个问题， 比如是否是哲学家， 是男还是女， 是白种人还是黄种人。 这些特征， 都对应会死或不会死这两个结论。 这样，你会得到多少个假设呢？ 组合数学告诉我们16种， 于是学习的任务就是给这16个假设和真或者假连接起来。 一旦一条线连起来， 我们就得到了一个新的知识，可以被用于在真实的世界做判断！ 就和之前说的规则机器一样。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.5625&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibccd3W2SkazpguaDUmf1EWibibeB6eia8YghicHCagGO02XX9WcmpmicrD1ya9UNmpAlIqbbygWzLKiarAVQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;640&quot; /&gt;&lt;/p&gt;


&lt;p&gt;&lt;span data-offset-key=&quot;1bdeq-0-0&quot;&gt;我们首先给这个机器灌入所有的可能性， 那16种假设。 然后我们让机器来收集案例！比如机器收集到一个苏格拉底死了， 那么苏格拉底是什么？ 男性，白种人， 哲学家， 于是机器得到男性， 白种人， 哲学家，会死。 于是机器给机器输入亚里士多德， 柏拉图， 大卫休谟，机器都会告诉你会死。然后我们继续收集样例， 比如居里夫人死了， 然后机器会得到女性，白种人， 非哲学家，死了。 这样它能够做的判断就又多了很多！ &lt;strong&gt;我们直接把规则转化为了可以学习的对象。输入样例，得到一个是非的知识， 这个样例我们换个词叫数据， 这个机器我们换个词– 叫做分类器。&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;&gt;&lt;/ins&gt; &lt;img class=&quot;&quot; data-ratio=&quot;0.5625&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibccd3W2SkazpguaDUmf1EWibibCChMBjNz3U3sMtU9kp7SpWibY4ocjf7OhopFnViaibcnR1aYIDpYKLaVg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;640&quot; /&gt;&lt;/p&gt;


&lt;p&gt;&lt;strong&gt;整个有关统计的机器学习， 都可以看成让机器学习有效归纳的方法， 从数据里得到规则表， 再用规则表进行判断。前面的过程叫训练， 后面的过程叫测试。 &lt;/strong&gt;&lt;span data-offset-key=&quot;9nnub-0-0&quot;&gt; 如果这些规则是有关一个是非的命题， 它就是一个分类器， 如果它是一个连续数值的预测， 就是回归。 但是规则表的本质是不变的， 它就是让你填表，表格的横排和竖排已经有了， 一个叫特征， 一个叫实例。 特征是人为归纳好的， 而实例是我们人为收集的， 表格中有些地方是空的，  就是我们想要判断的东西， 需要机器来填的部分。 比如给你一百幸福和不幸的人的案例， 让你判断第101个人的情况。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.7663197729422895&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibccd3W2SkazpguaDUmf1EWibibGeQKfN4oT43Gf7qPQGibnceOkVZRMtllFgcAHBwVIocWdibkMkFB9V1Q/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1057&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;图：机器从实例中学到分类的方法： 机器学习&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;81s85-0-0&quot;&gt;刚刚的那个例子你应该已经体会到， 这个命题验证过程其实是一个组合爆炸的问题。我们把关于这个世界的互相矛盾的假设都丢尽机器。即使最简单的问题也会有无穷多的情况要判断 （特征的n次方）这种假设的数量随着问题的复杂度急速指数上升的过程，我们称之为维度灾难。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.5625&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibccd3W2SkazpguaDUmf1EWibib6XNRA36VEFMtlPlZQ2RpPXtla5u66LIcDmhkLUQuPecqg0IVicuibIwA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;640&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;span data-offset-key=&quot;ajopm-0-0&quot;&gt;而机器学习的各个算法， 让我们通过加入更多的假设， 来偷懒解决这个问题， 此处没有比决策树更典型的， 它的高阶版本xgboost成为机器学习竞赛的杀手锏。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;a9isr-0-0&quot;&gt;而决策树得核心智慧就是优先级算法简化命题数量。 虽然特征很多， 但是并不是每个特征都一样重要， 我们如果先按照最重要得特征进行判断， 依此往下， 你可能不需要2得N次方个情况， 而是按照树结构做N次判定即可。 优先级， 也是人类智慧得核心。事实上， 我们永远在抓轻重缓急，在抓主要矛盾， 无论是有意的还是无意的，当然大部分人的轻重缓急是按照时间来的，时间比较近的就是比较重要的， 这也是为什么很多人有拖延症。 &lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;a9isr-0-0&quot;&gt;很多人说到优先级算法很想到相亲， 其实这也是一种人类思维自然使用的决策树， 比如女生找男朋友通常心理都有一个优先级构成的树， 首先， 对方的年龄多大？ 如果对方年龄大于50岁直接pass， 然后看工资，如果工资小于20万直接pass，工资在20和30万间看下学历， 学历小于本科直接pass。 这其实就是一个决策树的结构。 每次pass， 就减少掉了一半需要判定的命题。 通过这种预设的二叉树逻辑， 一个本来需要2的n次方的步骤解决的事情， 可能只要n步了。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.7453703703703703&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibccd3W2SkazpguaDUmf1EWibibq5oBakMtQKgHb2Akq4jNYicdNNniarAhbtJNpWaJ7qOkbJDDKpTTB9MQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;8dl0e-0-0&quot;&gt;具体如何来学，树的根部是你选择的第一个特征， 更好的角度是把特征看成一个问题，树的根部是你要问的第一个问题， 根据这个问题的回答， 数据会在左边右边分成两组。 然后在每个答案的基础上， 你继续问下一个问题， 所谓的决策树的分叉， 每个枝杈就是一个新的问题。 &lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;8dl0e-0-0&quot;&gt;如此，就会形成一个树的结构。构建这个树的主要难点， 在于要由机器决定哪个问题先问， 哪个问题后问， 如何选择这个优先顺序？我的要求就是， 每一次分化，我们都希望取得最多的信息，如分叉后一个树杈全是yes，一个全是no就是最好的效果， 如果达不到， 也让它尽可能接近这个效果。  这样一个一个问题问下去， 最终达到稳定后过程停止。  这样形成的决策树， 我们会形成任何一个情况下的优先级。 或许长的帅的人工资不重要。 或许学历高的人年龄不重要。 这种不同情况不停调整优先级的思维， 真的是被决策树利用到了极致！ 从原始数据里提炼的决策树， 可以对无限的新情况进行预测。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;fk0ce-0-0&quot;&gt;另一个得到这样的一个规则表的方法是线性假设。 线性分类器通过假定特征之间的相互独立， 使得命题的成立与否可以通过一个加权求和的关系表达， 即f=wx+b 。最后f如果大于0就是是， 小于0就是否。 线性分类器也是一种特别符合人认知习惯的模型：一般人在决策时候做的事情就是加权平均，比如你平时做分类（决策）， 你最想的一种状态是什么？你要把几个核心的要素放到一起， 按照他们的重要性加和，比如你今天要不要去看电影，可能取决于你的女朋友free否， 下不下雨和电影好不好看， 这个时候，我们可以把这些因素加权在一起， 在和一个我们给定的阈值做比较，大就去， 不大就不去， 这正权衡得失的做法， 就是线性分类器。线性分类器看上去是一个数学公式， 本质还是一个规则表， 只不过这里要学习的规则无非是每个特征给多少权重。最后在表格最后一列得到yes or no。 &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.9387096774193548&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibccd3W2SkazpguaDUmf1EWibibm99R31Z3g5uTib3k3mrK8kME4XDCicJ6HgXW6a31dQaFa9RABR3z7VHA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;620&quot; /&gt;&lt;/p&gt;
&lt;p&gt;图： 线性分类器， 一条直线代表一组权重， 把两组数据分的越开越好。 &lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;a0m7b-0-0&quot;&gt;具体学习的过程， 我们从实例里归纳出每个特征对应的权重参数，然后进行判断。 只要参数都确定了， 也就是一次解决了所有的问题。 线性分类器的高级版本SVM已经超越了线性假设。 也是小数据下生成有效规则的大杀器。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;span data-offset-key=&quot;a0m7b-0-0&quot;&gt;近期的智能： 让机器生成有效的规则 &lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;span data-offset-key=&quot;a0m7b-0-0&quot;&gt;&lt;img data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz/dcEP2tDMibcfyNibceeGvVKo0qCGicGJ9lQ9J5zzOIxmTUAE4OYfwx25QZ2J2KLUic1lWYkMwelC8Ld30RF0FsibAPQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; class=&quot;&quot; data-ratio=&quot;0.1671875&quot; data-w=&quot;640&quot; /&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;8te9f-0-0&quot;&gt;连接主义机器学习， 产生规则&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span data-offset-key=&quot;fk6j-0-0&quot;&gt;刚刚说的那一套， 有一个问题你有没有注意到？ 我们最先提出的问题是让机器产生一个规则表， 而刚刚说的统计机器学习里， 更多的是让机器根据定好的特征收集数据进行命题判断。 这其实离我们说的让机器自己得到规则表只进行了0.5步。&lt;strong&gt;大家想象下， 在真正的实践活动里， 你无法一开始就设定出一堆特征让它进行逻辑判断，在这个情况下如何得到我们所说的“规则”呢？ &lt;/strong&gt; 如何让机器自己生成战胜“复杂”的程序呢？ 连接主义机器学习在一定程度解决了这个问题。  因为， 人类认识事物，生成规则， 其实是通过“&lt;strong&gt;概念&lt;/strong&gt;”来的， “概念”是一个浓缩的信息载体， 通过它我们能够进行任何更复杂的推理。 那么“概念”是如何生成的呢？ 它的载体正是下面说的联结主义的代言人神经网络。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;a5gsn-0-0&quot;&gt;神经网络&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span data-offset-key=&quot;dijog-0-0&quot;&gt;首先，神经网络是由神经细胞组成的。  一个神经细胞就是一个最小的认知单元， 何为认知单元，就是把一定的数据组成起来，对它做出一个判断， 我们可以给它看成一个具有偏好的探测器。  联系机器学习，它就是刚刚说的线性分类器。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;cr2lq-0-0&quot;&gt;正确的分类，是认知的基础，我们对事物的感知比如色彩，物体的形状等，其实都是离散的，而物理信号是连续的，比如光波，声波。这里面的中间步骤就是模数转化，把连续的信号转化成离散的样子，这正是一个分类器干的事情。一个单个神经元可以执行一个简单的基于感知信号的if else语句。 先收集一下特征做个加和，if大于一个值我就放电，小于我就不放电，就这么简单。晶体管当然也在干这个事情。 神经细胞与晶体管和计算机的根本区别在于可塑性。或者更准确的说具有学习能力。从机器学习的角度看， 它实现的是一个可以学习的分类器，就和我们上次课讲的一样， 具有自己调整权重的能力， 也就是调整这个w1和w2.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.5625&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibccd3W2SkazpguaDUmf1EWibib2NvE4HCXevrTz3VAnXzfIxaOZibibe1YnYGN84NF1XWqyKpNdsISR2aA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;640&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;3f6fb-0-0&quot;&gt;我们这个简化出来的模型，正是所有人工神经网络的祖母－感知机。从名字可以看出，&lt;/span&gt;&lt;span data-offset-key=&quot;3f6fb-0-1&quot;&gt;感知机算是最早的把连接主义引入机器学习的尝试。&lt;/span&gt;&lt;span data-offset-key=&quot;3f6fb-0-2&quot;&gt; 它直接模拟Warren McCulloch 和 Walter Pitts 在1943 提出而来神经元的模型， 它的创始人 R 事实上制造了一台硬件装置的跟神经元器件装置。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;2b1gb-0-0&quot;&gt;单个的感知机并不能比传统的机器学习多做一丁点的事情， 还要差一些。 但是把很多个感知机比较聪明的联系起来，就发生了一个质变。&lt;/span&gt;首先， 每个线性分类器， 刚刚讲过都是一个小的特征检测器， 具有自己的偏好，这个偏好刚好用一个直线表示，左边是yes，右边是no， 那么多个神经元表达的是什么呢？ 很多条这样yes or no的直线！  最终的结果是什么呢？我们得到一个被一条条直线割的四分五裂的结构， 既混乱又没用！  这就好比每个信息收集者按照自己的偏好得到一个结论。所以， 多个神经之后，我们还要在头顶放一个神经元， 它就是最终的大法官， 它把每个人划分的方法， 做一个汇总。 大法官并不需要什么特殊的手段做汇总，&lt;strong&gt; 它所做到的，无非是逻辑运算， 所谓的“与”， “或”， “非”， 这个合并方法，把哪些被直线分开的四分五裂的块，就可以得到一个非常复杂的判决结果。 &lt;/strong&gt;你可以把大法官的工作看成是筛选， 我们要再空间里筛选出一个我们最终需要的形状来， 这有点像是小孩子玩的折纸游戏，每一次都这一条直线， 最终会得到一个边界非常复杂的图形。 其实这里面做的事情， 正是基础的逻辑运算， 一个简单的一层神经网络可以执行与或非这些基本的逻辑操作。事实上它的本质就是把简单的特征组合在一起形成一些原始的概念。&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.5758323057953144&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibccd3W2SkazpguaDUmf1EWibibuABrESypc6M08wlHD6dia0vL7GRLUKEQiby0Bicc47icreRupKWw5IHVVQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;811&quot; /&gt;&lt;/p&gt;
&lt;p&gt;它是怎么做到的呢？ 学习。 生物神经网络的学习， 是通过一种叫做hebbian可塑性的性质进行调节的。 这种调控的法则十分简单。说的是神经细胞之间的连接随着它们的活动而变化， 这个变化的方法是， 如果有两个上游的神经元同时给一个共同的下游神经元提供输入， 那么这个共同的输入将导致那个弱的神经元连接的增强， 或者说权重的增强。 这个原理导致的结果是， 我们会形成对共同出现的特征的一种相关性提取。 比如一个香蕉的特征是黄色和长形， 一个猴子经常看到香蕉， 那么一个连接到黄色和长形这两种底层特征的细胞就会越来越敏感， 形成一个对香蕉敏感的细胞，我们简称香蕉细胞。 也就是说我们通过底层特征的“共现” 形成了一个简单的“概念”。 上述过程被总结hebian学习的一个过程。  我们可想象，一个两层以上的神经网络， 就可以表述香蕉， 苹果， 菠萝这些水果了， 它们无非是底层特征颜色，形状的不同组合而已。 而这些不同水果的概念， 就可以帮助我们形成更加复杂的规则表 ，比如让它根据客户的信息帮它推荐一个水果拼盘。 由此可见， 神经网络通过与或非进行简单特征的组合 ，再通过if esle进行判断选择合适的特征得到概念， 再通过下一层迭代得到概念有关的命题。 就可以生成比之前的传统机器学习复杂的多的规则表。而且我们可以想象出来， 迭代的层数越多，它生成的“概念”和“规则”就越复杂。  &lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;48v3r-0-0&quot;&gt;当然真实训练中我们用到的不是模仿生物版本的hebbian学习， 而是强大的多的反向传播算法。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span data-offset-key=&quot;48v3r-0-0&quot;&gt;&lt;img data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/jrbyyXzrKkJqzpvQ60VcjgiacFu21XHHubic1vJveCSZ6PHEDDyJd1LZhn3z6ibqmBehPbx0icZx0ZXosoBaXWceQw/640?wx_fmt=png&quot; data-type=&quot;png&quot; class=&quot;&quot; data-ratio=&quot;1.6111111111111112&quot; data-w=&quot;360&quot; /&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;&gt;&lt;/ins&gt; &lt;span data-offset-key=&quot;dmb6s-0-0&quot;&gt;事实上为了让这种生成“概念”得到“规则”的方法更加有效， 我们会加入一些无比强大的先验假设。 其中最有名的一组，  就叫CNN，它所做的，其实是针对于图像这类巨大无比而局部特征不断重复的数据形式， 你可以写一个循环， 来让你的程序更有效。 循环里的每一步都对图像的局部特征进行提取， 由一个可以共用的卷积核实现。 卷积核一点点的卷过图像上的每个小块， 也就是循环的总体。 卷积核在每个图像局部做的， 事实上都是一个小的if esle 语句。 if像素之间符合某个关系，就是yes，否则No。这个结果， 最后被综合出来， 给下一层合成更复杂的图像特征。我们事实上通过学习的过程，让机器自动补全了循环每一步的这个if else语句。 &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.7298850574712644&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibccd3W2SkazpguaDUmf1EWibibJ7GaCXDzw2dMW8QiaAPh96svf1lqjLico2MoDlVUCfFZgIHkysrSaRibQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;870&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;4vk9r-0-0&quot;&gt;好了，到目前为止， 说的都是和时间无关的规则。 而一开始讲到的真实的图灵机， 是和时间有关的规则。 那么如何得到一个和时间有关的规则表呢？ 如果要处理和时间相关的信息， 你必须要引入记忆，引入内部状态， 而和刚刚说的一样， 这些含时间的规则要是可以学习的，用数学的语言说， 就是要有一个连续可微的载体， 这个东西就是RNN。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;72qm9-0-0&quot;&gt;def step&lt;/span&gt;&lt;span data-offset-key=&quot;72qm9-0-1&quot;&gt;(self, x):&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span data-offset-key=&quot;di032-0-0&quot;&gt;# update the hidden state&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span data-offset-key=&quot;4f218-0-0&quot;&gt;self.h = np.tanh(np.dot(self.W_hh, self.h) + np.dot(self.W_xh, x))&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span data-offset-key=&quot;243tl-0-0&quot;&gt;# compute the output vector&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span data-offset-key=&quot;591p4-0-0&quot;&gt;y = np.dot(self.W_hy, self.h)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span data-offset-key=&quot;a1b57-0-0&quot;&gt;return&lt;/span&gt;&lt;span data-offset-key=&quot;a1b57-0-1&quot;&gt; y&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;g9on-0-0&quot;&gt;以上是RNN的python程序定义。 它说的无非是你有一个刚刚说的线性分类器组成的单隐层神经网络，但是这一回，神经网络的输出，要作为输入，重新回到神经网络的隐层里， 这个关键的增加， 就使得它具有了处理复杂时间信息的能力。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;5qh71-0-0&quot;&gt;这个结构，非但优雅，而且有效。一个非常重要的点是， 你知道信息的传播是有损耗的， 如果把RNN展开， 它事实上相当于一个和历史长度一样长的深度网络， 信息随着每个时间步骤往深度传播， 这个传播的信息是有损耗的， 到一定程度我就记不住之前的信息了， 当然如果你的学习学的足够好， Wij还是可以学到应该学的记忆长度。  &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;Image FocusPlugin--unfocused Image--isBlock&quot; data-ratio=&quot;0.26161790017211706&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibccd3W2SkazpguaDUmf1EWibibPf1BYBmsfuHXyspOv0uwulVbuy0UibqOib2grXtp4XpvWU4b6Pj3402Q/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;581&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;2ot4h-0-0&quot;&gt;事实上叫做“循环神经网络”  循环的本质是什么呢？   它其实正是你的程序里的for循环啊！ RNN的本质是， 在每个时间步里进行同样的操作， 这个操作无非是， 当下的输入， 和神经网络的状态两部分特征的逻辑组合（与或非）然后， 这个组合的结构进行一个if else的逻辑判断， yes or no， 根据这个，生成一个输出的结果， 这个结果， 要回传给神经网络隐层， 生成下一个隐层状态。 大家看这其实就是图灵机的定义啊， 而RNN的本质， 就是一个可以通过微分方法学习的图灵机啊。 虽然每个步骤的规则和执行足够简单， 但是只要步数足够多， 却可以产生非常复杂的结果。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;2ot4h-0-0&quot;&gt;RNN学习的本质， 就是给你那个足够复杂的结果， 让你反演出那个足够简单的规则， 然后让它在新的环境下再去做预测与决策。 我们可以看到， 这已经非常接近智能的本质了。 那么RNN有没有可能学到真正类似人类的抽象思考能力， 具备人类类似的生成规则的能力呢？ 这可能才是后面真正的问题。 &lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;span data-offset-key=&quot;2ot4h-0-0&quot;&gt;让机器生成有关未来的规则-强化学习&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;span data-offset-key=&quot;2ot4h-0-0&quot;&gt;&lt;img data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz/dcEP2tDMibcfyNibceeGvVKo0qCGicGJ9lQ9J5zzOIxmTUAE4OYfwx25QZ2J2KLUic1lWYkMwelC8Ld30RF0FsibAPQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; class=&quot;&quot; data-ratio=&quot;0.1671875&quot; data-w=&quot;640&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;span data-offset-key=&quot;2ot4h-0-0&quot;&gt; &lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span data-offset-key=&quot;2ot4h-0-0&quot;&gt;强化学习&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; rgb=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;&gt;果说监督学习的基本框架已经是在生成用于判断（分类）的规则表， 那么强化学习， 就是生成一套直接用于行动的规则表， 这套语言的元素包括&lt;span&gt;状态， 行为， 观测， 奖励&lt;/span&gt;。 事实上， 强化学习所做的事情是从成功或失败的经历里去归纳行为的准则。 &lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; rgb=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;&gt;我开头讲的解魔方的问题， 如过让机器自己找到最短时间完成它的方法， 这就是强化学习所做的事情。 &lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; rgb=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;&gt;首先看&lt;span&gt;状态&lt;/span&gt;s， 状态是什么呢？ 它指的是智能体（agent）所在的环境里所有和游戏有关的信息， &lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; rgb=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;&gt;&lt;span&gt;再来看行为，所谓行为，是指智能体的&lt;/span&gt;&lt;span&gt;决策&lt;/span&gt;&lt;span&gt;，某种情况下我们可以认为它就是监督学习要求的那个y， 或者预测， 但一个决策与预测不同的是，我们并不能马上取得一个信号告诉我们这个决策对不对， 只有在游戏的最后 ，我们才能从整个游戏的收益反观当时的决策好坏。&lt;/span&gt;&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; rgb=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;&gt;寻找到从根据当下的状态s行动的一张规则表， 让我有最好的机会拿到奖励， 就是强化学习在做的事情。 &lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; rgb=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;&gt;而深度强化学习呢？  它就是把刚说的连接主义通过概念生成规则的方法，和此处的决策联系起来得到的框架。 &lt;/p&gt;


&lt;p&gt;&lt;strong&gt;&lt;span data-offset-key=&quot;2ot4h-0-0&quot;&gt;我们还差很远&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;span data-offset-key=&quot;2ot4h-0-0&quot;&gt;&lt;img data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz/dcEP2tDMibcfyNibceeGvVKo0qCGicGJ9lQ9J5zzOIxmTUAE4OYfwx25QZ2J2KLUic1lWYkMwelC8Ld30RF0FsibAPQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; class=&quot;&quot; data-ratio=&quot;0.1671875&quot; data-w=&quot;640&quot; /&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;说到所有上述的东西， 你会觉得我们已经无所不能， 既然机器能够自己填写程序， 自己生成规则表来适应多变的世界， 那我们还差什么呢？  我们说都是生成规则， 不同的规则效力差距万千，而目前的AI在此处也就是个小学生。 亚里士多德和牛顿都观测力学现象， 亚里士多德看到的是轻的气体向上飘，重的东西向下沉。 牛顿看到的是受力与加速度的关系。 这两种规则的归纳即使都能解释现象， 但是它们的泛化能力确是千差万别， 一个可以解释全宇宙， 另一个也就适应一些物体吧。 如同下图所示， 坏的规则总结只能解释数据实例周边一丁点的地方， 而好的规则呢， 它可以把点连城片！  &lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.7445945945945946&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibce3GnvDlNCSjsGosHtINzN4XExqvasWticuD9ehaBQuFeiazL5LEfoMicN72hz0eQJEZpp4IqichpMVAA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;740&quot; /&gt;&lt;/p&gt;
&lt;p&gt;我们说人类总结的规则解释力最强的地方是物理 ，因为物理里描述了客观实体间作用的因果联系，而非简单的相关性。 这恰恰是目前AI所不足的。 &lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;5j932-0-0&quot;&gt;有关物理的世界和智能的世界&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;di5qc-0-0&quot;&gt;上面的这些思考无疑开始让人们想象我们所说的包含了逻辑推理， 情感，甚至意识的问题与物理世界的关系到底是什么。 我们说物理的世界里， 主宰一切的是微分方程。 一切因果关系， 都由微分方程所承载。 你有了不同不同微观粒子电磁力的描述，把它们放入薛定谔和狄拉克方程， 你就可以推出原子的不同性质。  这其实可以说是因果推理的极致了。 它甚至导致了机械的宿命论思想。当一切初始的原因输入系统， 那么它就回归于一个必然的结果。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;dl784-0-0&quot;&gt;到了非线性动力学的时代看似这点被混沌打破了，亚马逊的蝴蝶引起北美的飓风， 让通俗科学爱好折重新燃起了不可知论的希望，事实上并没有。  所谓的混沌， 无非是一种确定性下的不确定， 或者已知中的未知。 混沌的系统依然在一个被方程高度确定的洛伦兹吸引子里。&lt;/span&gt;&lt;/p&gt;

&lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;&gt;&lt;/ins&gt; &lt;p&gt;&lt;span data-offset-key=&quot;af64u-0-0&quot;&gt;到此处， 我认为微分方程依然是描述因果关系最精密的所在， 它可以在输入很少信息的时候， 得到最多的预测产出。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;8i7lg-0-0&quot;&gt;在看刚刚的智能问题， 我们说， 整个智能问题， 到目前为止其实还是在围绕那张规则表， 只是我们的思路由制定规则表， 到了学习规则表。和物理比较， 目前的机器， 需要输入进去大量的数据， 才能生成一点十分简单的规则。 当然你可以举阿法狗下围棋的例子说明所生成的规则并没有那么简单， 可惜的是， 那些规则只适用于一些非常封闭而特定的领域。 而不像牛顿定律放之四海而皆准。  那么神经网络可不可以观测大量物体坠落的过程把万有引力定律给推出来呢？ 目前看是不能的。其实牛顿引力定律的得出是含有了大量的人类推理。 我们需要先知道物体运动改变和受力的关系， 然后通过观测物体的轨迹得到大量物体的受力情况，再在这些手里情况下得出某一种共同的作用力形式， 这是一个多么复杂的思维链条。 这对于目前统计的巨人， 而只懂得浅显的形式逻辑的神经网络，还是比较困难的。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;8i7lg-0-0&quot;&gt;如果我们可以用神经网络加上强化学习，诱导它掌握特别抽象而复杂的如受力，运动这样的概念，那将是不可想象的， 目前我们也并不清楚有没有那一天。 &lt;/span&gt;&lt;/p&gt;

&lt;p&gt;另一方面， 人类是通过符号组成的语言思考的， 目前AI总结和归纳符号的能力， 同人类的语言相比依然天差地别。 &lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;dsh1-0-0&quot;&gt;有关语言代表的符号世界&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span data-offset-key=&quot;8cbc-0-0&quot;&gt;讨论智能的问题离不开语言。从乔姆斯基开始，人们就开始研究不同语言背后的共同语法基础。 其实如果深究语言问题， 我们会看到它和刚刚说的程序的联系。 语言无非是对世界的符号化，类似于给每个刚刚说的概念赋予一个符号。而语言其实很像程序， 它就是对概念之间关系的表述。 当然数学也是一套伟大的符号系统。  语言和数学以及程序的区别可能在于语言更加模糊， 但是它对付不确定性的能力远远大于程序。  &lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;8cbc-0-0&quot;&gt;事实上， 人类语言很少有那种特征精确的关于几何关系和量值的描绘， 而似乎更多定性成分， 比如美丑，近， 远， 大，小。 我们可以想象在一个充满变化的世界那种特别精确的描述不一定十分有用。 恰恰因为这种模糊性，让它具备了更好的适应能力， 和泛化能力。 可以表述那些用程序难以描述的事情。 &lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;8cbc-0-0&quot;&gt;既然本质上语言无非是一个现有概念的符号体系，以往的深度学习NLP其实是走了一条南辕北辙的路，我们把不同的词汇和句子压缩成词向量， 句向量喂给神经网络学习， &lt;strong&gt;而事实上神经网络对这些符号背后的实体概念却一无所知。&lt;/strong&gt;虽然词向量也能稍微的带有一点不同词语之间的语义距离， 但是这和真实世界所含有的信息量，也依然是差异巨大。 目前用图卷积网络解决NLP的思路，算是一个进步， 因为它更好的涵盖了整个符号世界的信息。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;blfe1-0-0&quot;&gt;语言， 好比一个巨大的人类经验和逻辑的宝库， 这个符号世界几乎就是真实世界的最好压缩体， 如果一天神经网络真正被赋予了语言的power，也就是能够真正理解这个符号世界，或许离通用人工智能也就不远了。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;有关物理世界和语言世界的打通&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;blfe1-0-0&quot;&gt;刚刚说的精确的物理方程的世界， 和能够应付更多不确定性的模糊的语言， 之间又有哪些联系呢？  我的想法是， 物理的杀手锏微分方程， 当构成了一个非线性的动力学系统， 却可以通过它内在的定点， 极限环，吸引子等概念， 去接近那个模糊性的语言， 就好比在非线性动力学的世界里， 我们往往不再那么关于一个系统如何发展的暂态，很多不同的系统都归一于一个吸引子， 那么它们背后的逻辑可能就是类似的。 这或许会架起一座物理世界和语义世界的桥梁？  &lt;/span&gt;&lt;/p&gt;


&lt;p&gt;&lt;strong&gt;&lt;span data-offset-key=&quot;blfe1-0-0&quot;&gt;如何让机器学习符号&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;blfe1-0-0&quot;&gt;假定语言这样的高效符号系统是大脑产生的，那么我们是否可以根据脑科学的启发把这种能力赋予神经网络，来加强它的推理能力呢？ 如此可以延申的思考还很广很广。&lt;/span&gt;&lt;/p&gt;



&lt;p&gt;&lt;span data-offset-key=&quot;blfe1-0-0&quot;&gt;更多阅读&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651383991&amp;amp;idx=1&amp;amp;sn=26f543505499441e7f31cfb15177ff10&amp;amp;chksm=84f3c6f6b3844fe08f91bfec42c55b42d221f452c68d3820eb1612a6c09f39c06956d69f42ca&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-itemshowtype=&quot;0&quot; data-linktype=&quot;2&quot;&gt;当神经网络遇到神经科学-铁哥18年长文汇总&lt;/a&gt;&lt;br /&gt;&lt;/p&gt;

</description>
<pubDate>Tue, 26 Feb 2019 00:50:52 +0000</pubDate>
<dc:language>zh-CN</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.jintiankansha.me/t/WW3EirRLSj</dc:identifier>
</item>
</channel>
</rss>