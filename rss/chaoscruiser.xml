<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="css/feed.xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/" xmlns:og="http://ogp.me/ns#">
<channel>
<atom:link rel="self" href="http://192.168.1.4/fivefilters/makefulltextfeed.php?url=feed43.com%2Fchaoscruiser-jtks.xml&amp;max=5&amp;links=preserve&amp;exc=1" />
<atom:link rel="alternate" title="Source URL" href="http://feed43.com/chaoscruiser-jtks.xml" />
<atom:link rel="related" title="Subscribe to feed" href="http://www.subtome.com/#/subscribe?feeds=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed43.com%252Fchaoscruiser-jtks.xml%26max%3D5%26links%3Dpreserve%26exc%3D1&amp;back=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed43.com%252Fchaoscruiser-jtks.xml%26max%3D5%26links%3Dpreserve%26exc%3D1" />
<title>混沌巡洋舰</title>
<link>http://www.jintiankansha.me/column/ultiWL8Axg</link>
<description>混沌巡洋舰 - 今天看啥</description>
<ttl>360</ttl>
<item>
<title>如何让神经网络具有好奇心</title>
<link>http://www.jintiankansha.me/t/pB5uZcxwFe</link>
<guid isPermaLink="true" >http://www.jintiankansha.me/t/pB5uZcxwFe</guid>
<description>&lt;p&gt;&lt;strong&gt;一 为何强化学习要有好奇心&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;聪明人都珍视好奇心这个品质，好奇心驱使我们探索未知，从而带来了人类历史上所有重大的科学发现，从而带领人类走上了蓝星生态链的顶级。而对于那些需要在虚拟的游戏环境中称霸的AI来说，游戏环境越复杂，就越需要在强化学习中加入好奇心。&lt;/p&gt;

&lt;p&gt;&lt;img data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcenH9WLvLsrBZukiafEJwhkEjFBzNFcGulOr8XicbMINSzX2wtfdicyia9EQTbLasqdBicriaUg2uTtmNtA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; class=&quot;&quot; data-ratio=&quot;0.8597222222222223&quot; data-w=&quot;720&quot; /&gt;&lt;/p&gt;

&lt;p&gt;上图是强化学习的框架，AI要根据奖励和当下的情况来调查下一个阶段的行动，最终在最后的阶段能够让奖励最大化。但在最后的结算日之前，agent需要一个能够代表当前场上局势的估值函数，对于象棋军旗，人们还能根据场上的形式去确定这个函数大概章什么样子，例如象棋中当前的局势是当前你的车马炮各自的价值的加和，人们可以写出这样的函数应该具有的形式，由程序去学到该如何为函数中参数值赋值，但对于更加复杂的游戏，例如围棋，这样的方式就不可行，也就是说，手动确定奖励函数形式的方法，不具备可扩展性（scalable）。&lt;/p&gt;

&lt;p&gt;强化学习要解决的问题，要面临的另一个问题是激励来的太晚，比如智能体的最终目标赢得星际争霸的游戏，但为了让智能体在自我对弈中学会如到制胜的策略，需要一个函数来告诉智能体，是那些决策导致了获胜，而这对于很多策略类的游戏来说，开局的决定就能够影响最终获胜的概率。而这会让奖励函数在时间尺度上变的稀疏&lt;/p&gt;

&lt;p&gt;而有了好奇心之后，智能体就不需要由程序员来定义奖励函数了，而可以自己对自己之前的行为给予奖励，从而指导下一轮的行动。奖励函数对于强化学习中的智能体，可以类比为人的情绪，情绪告诉我们现在所处的情况对我们的生存是好是坏，在没有内在好奇心的时候，你的情绪全部由外人的批评或表扬决定，而有了好奇心这个机制，你就可以自己调控情绪，从而通过情绪的变化指导你调整自己的行为，让你更好的活下去。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;二 好奇心指的是什么&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;古龙对好奇心说过这样的话，“人们对他们不了解的人，总是会生出一种特别强烈的好奇心，这份好奇心，往往又会引起许多种别的感情。”，这句话反映出好奇心的原本是为了应对人际的互动中的陌生情况，如果陌生人和你的交往如你心里所想，那你会生出喜悦的情绪，而如果出乎意料，你也会在负面情绪的指导下调整自己的认知模型。&lt;/p&gt;

&lt;p&gt;将这句话中的道理用稍微数学一些的语言来表示，就得出了强化学习中的好奇心，即根据当前的形式，最小化对智能体的行为（action）的后果的预测误差，这等价于基于场上当前的局势及自己本回合的策略，预测未来一个回合的会发生什么。智能体在上述的“好奇心”的指导下，为了最小化预测误差，会主动采取那些会降低对未来不确定性有帮助的策略，例如智能体预测到下一回合敌人要进攻了，而这个行为会导致自己对未来的预测有很大的不确定性，于是本回合就会积极备战，从而降低不确定性。&lt;/p&gt;

&lt;p&gt;而智能体为了能进行上述的思考，就需要其对周围的环境构建出一个更抽象的表征，从而在类似的坏境下，也能用到之前的经验。而当一个模型具有了从环境中提取更精炼的表征（representation）的能力后，也能更容易的用同样的模型在不同的游戏中取得成功。这也是为什么说好奇心在各类强化学习任务中都有通用性的原因。&lt;/p&gt;

&lt;p&gt;既然是熟悉的预测任务，那就要面对过拟合的问题。在真实的而不是像围棋那样简化后情境下，智能体预测的环境中，既包含了会受到智能体行为影响的部分，也一定会包含和智能体行为毫无关系的部分，例如对于自动驾驶来说，要关注的不是路边的行道树，而是其他的车与行人，下图展示了对于自动驾驶程序，好奇心模块需要关注的部分。&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.7185501066098081&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcck4r46wZsTRCpQFI9K1Ivf3op5EdJWIiaADwNeyibBlz7Y9jJYDjjNf7mAGLyqXzP3AEBQicjDWMDuQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;469&quot; /&gt;&lt;/p&gt;

&lt;p&gt;上面的例子展示了强化学习中的好奇心应具有的一个普遍规律，即预测的目标不应该是环境本身，例如星际争霸游戏中屏幕上的每一个像素，而应该是对环境的映射（embedding），或者是环境中的一部分，这个映射应该维度足够的低，同时保留了全部受智能体影响及会影响智能体决策的特征，同时在短时间内保持相对的稳定，否则会导致模型难以瞄准一个变化幅度太大的目标。&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;三 好奇心的具体实现&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;好奇心是在2017年的一篇论文中第一次引入的，在今年，该组又此基础上发表了最新的结果。下面是好奇心模型已经征服的54种游戏中的截图&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.5729166666666666&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcck4r46wZsTRCpQFI9K1IvfW71aFpickcQz2Yr3QwicawYsPTRN4mbyUmnF0OdajptDLmzrmUb1icX3w/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;576&quot; /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;这个模型的缩写ICM，指的是Intrinstic Curiosity Model。引入好奇心之后，不需要由人来告诉程序目标是什么，也不需要指出什么条件下游戏结束或者胜利，仅仅通过好奇心，就可以让AI学会怎么通关超级马里奥。&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.7983870967741935&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcck4r46wZsTRCpQFI9K1IvffzSCByNarCBY7b8ISwHWZF4PSia1Yx06bWNnEviaT3jHOUQ0bKiciagbMg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;496&quot; /&gt;&lt;/p&gt;
&lt;p&gt;这里蓝色的部分是好奇心具体实现中的self-supervise模块，给定当前的状态St以及St+1，先从中提取那些和智能体有关的特征，通过神经网络，去最小化对行为at造成的影响的预测。&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.8236301369863014&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcck4r46wZsTRCpQFI9K1IvfuhnWOG0Yczt4FEWqCa1wOEfjJcRINAWxJ5JRcwY87xBLmfU7GeKYGQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;584&quot; /&gt;&lt;/p&gt;
&lt;p&gt;而模型中红色的前馈神经网络，则是利用前面的ICM提取出的特征，最终实现预测下一时刻的坏境的目标，这里的待优化函数类似图像领域常见的MSE误差，&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.7661870503597122&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcck4r46wZsTRCpQFI9K1IvfehJfRlZqTDOeO9n9iaXftJLQBjPicwQ2Il73Y6ytDBHgmLV8LyoUXYRA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.6868686868686869&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcck4r46wZsTRCpQFI9K1IvfGskBfdZv3O1ZKTmfsCVUrkJ1j6qPTKczTBTPRozQ17rVtutiaiczZllQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;495&quot; /&gt;&lt;/p&gt;
&lt;p&gt;有了前馈网络提供的对下一时间点的环境中特征的预测结果，就可以从导出好奇心用数学表达的形式，下图中的n类似折线系数，代表了模型有多看重对更遥远未来的预测准确性。&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.43548387096774194&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcck4r46wZsTRCpQFI9K1IvfZf7aiakBiaUPSSZr7MLQn7UmKeibCrHNHeSib0zl1vn8oerIhVHcXnTVpQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;558&quot; /&gt;&lt;/p&gt;
&lt;p&gt;最后要做的是用一个公式，将上文提到的俩个神经网络的预测目标结合起来，从而使得模型有动力去探索那些自己不熟悉的或者很复杂的环境，因为对未知的探索，哪怕只知道一点点，也能够极大的降低对未来的预测误差，同时要促使模型能够自主的学到那些特征是和智能体的行动有关系。&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.3830104321907601&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcck4r46wZsTRCpQFI9K1IvfzgSuBCpAMGypDCs9hiaaroDKL4yz3ic8mbwRfae7ubj3ic79eppdjcR6Q/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;671&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.3549222797927461&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcck4r46wZsTRCpQFI9K1Ivfv3N1VmcRMXdCjcXgu5uDdTAzxsn09dofvBriaXLYrczTJiadQibDDo8Lw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;772&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;四 总结&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Lecun一直以来推崇的半监督学习，就是根据视频的前一帧去预测下一帧，从而使得模型具有更强的表征抽取能力。而在强化学习中，由于要考虑智能体自身行为的影响，这个过程变得更为复杂，需要一个独立的模块来判断环境中的那些是与智能体的行动有关的（包括限制条件和对智能体的行为有效应的部分），从而避免随机噪音的影响。通过在强化学习中引入好奇心，可以使模型在面对噪音时的表现更加稳定（这在原论文中有细致的论述），还能使模型具有通用性，从而接近强人工智能所要达到的。好奇心的引入还使得数据标注不是必须，从而能够让更多的数据集得以被利用。&lt;/p&gt;

&lt;p&gt;更多阅读&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651383664&amp;amp;idx=1&amp;amp;sn=89f11f166582925c041b960035f10c37&amp;amp;chksm=84f3c931b3844027a5c484c7af41f73dada1cb15a87fe4aa776fe293e45b66c0ea96e2e20c77&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-itemshowtype=&quot;0&quot; data-linktype=&quot;2&quot;&gt;强化学习最小手册&lt;/a&gt;&lt;br /&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651384219&amp;amp;idx=1&amp;amp;sn=f396d027ea5a6074e0f0cda0aeb0cded&amp;amp;chksm=84f3c7dab3844ecc80be70e9b9e47cd12686624d71158caf69fb79de9b1067d1b548e31ee132&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-itemshowtype=&quot;0&quot; data-linktype=&quot;2&quot;&gt;空间简史-人类认识空间的旅程与其对强化学习的启示&lt;/a&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;参考资料&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;https://pathak22.github.io/large-scale-curiosity/&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;https://pathak22.github.io/noreward-rl/&lt;/span&gt;&lt;/p&gt;
</description>
<pubDate>Sun, 17 Mar 2019 14:37:23 +0000</pubDate>
<dc:language>zh-CN</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.jintiankansha.me/t/pB5uZcxwFe</dc:identifier>
</item>
<item>
<title>AI就能解决食品安全问题吗</title>
<link>http://www.jintiankansha.me/t/kigw41CD7S</link>
<guid isPermaLink="true" >http://www.jintiankansha.me/t/kigw41CD7S</guid>
<description>&lt;p&gt;十年之后，我们怀念过去的时候，就像我们如今回忆99年或者08年时，会怎样谈论这个三月了？也许会说起波音的事故是人类打响从AI抢回控制权的第一枪，在这场人机大战中，人类飞行员无法战胜一个有bug的程序。站在十年的角度来看，能够多少让我们更多的看到制度的问题。但我今天不想说这个话题，有一件让人心寒到骨子里的事，不吐不快。&lt;/p&gt;

&lt;p&gt;在一个信奉民以食为天的国度，成都七中的食堂被曝光出现了显而易见的食品安全问题。受害者不是幼儿园，而是小学生。小学校园中有六年级的孩子，所以我本以为是孩子们参与了真相的曝光，但看了报道，才知道并没有。小学的时候看小鬼当家这个电影，看完我想美国的孩子真厉害，能自己动手来解决问题，而在9012年，遇到坏人，我们的家长还只是习惯性的跪下来。这是何等的悲哀。&lt;/p&gt;

&lt;p&gt;问了几个朋友，为何不就成都七中的事情写点东西，回答都是累了，觉得写了也没用，食品安全喊了这么久，只能靠跑路解决问题。但米国已经选择了America first，老欧洲则更加封闭和民粹，等过几年大概率的成了gdp第一，担起普世价值的大旗，不想承担也躲不开。再说真要学欧美那样，工业化的食品精加工，高盐高脂高糖，未来还不满街的超重人群。&lt;/p&gt;

&lt;p&gt;接着有朋友说AI未来能解决这个问题，AI是不会被阿伦特的平庸之恶困扰的，现实中那么多做饭的洗碗的买菜的，他们在这件事被曝光后可以说自己上有老，下有小只是为了混口饭吃，自己不用承担什么责任。在创客展上，我见过机器人厨师做的三明治，汉堡，也吃过无人售卖机卖的面，它们的确不会罔顾良心，而做这些机器人的公司，也会爱惜羽毛，不要机器人做出违背阿西莫夫三原则的事情来。过不了几年，也许私立小学的食堂会引入机器人，然后这里会成为家长们参观的必要打卡地，会成为孩子们科学实践课的场所。&lt;/p&gt;

&lt;p&gt;或者不需要等未来的机器人技术成熟，现在只要有人能找到足够多霉变食物做的菜的图片，用图像识别就能够做一个分类器，以后每天手机扫一扫，就能知道自己吃的饭是否卫生了，这目前已是很成熟的技术了。但我们真的要依靠AI来解决人类自己作的恶吗？过度的依赖技术，就会像波音的飞机那样，陷入人机大战中。做饭机器人可能会被供货商黑掉其用来做食物指控的模块，而通过图像来识别食品是否卫生，也会让某种食物更容易被误判的。人类自身的问题，需要自身的制度建设来解决。&lt;/p&gt;

&lt;p&gt;判断一个学校的食堂好不好，就看老师或校长是不是也在这里吃饭，判断一个单位的食堂好不好，就看大老板是不是也会食堂吃饭或招待客户，街边的苍蝇馆子是否干净，就看这家店的伙计是不是各个都吃的胖胖的，这就算所谓的skin in the game，要让做这件事的人来承担因这件事做错带来的损失，一定要具体到个人，这次成都七中的事情，要想杜绝下一次类似事情的重演，就要追究到个人，所有在这个时间段，在该小学食堂工作的人，不管是帮厨还是掌勺，通通很长的一段时间，按老赖处理，限制坐飞机上高铁，派出所重点照顾，芝麻信用分什么的通通清零，良心上欠了债，不在脸上打上终身的红字，就已经是社会进步的红利了。&lt;/p&gt;

&lt;p&gt;除了寄希望事后的惩罚，还不如用好事前的开放，有一个方法，可以不需要立法的改变，就能避免未来再出现类似的事。现在直播这么普遍，为何不能要求每个学校的食堂开一个直播间，将手机固定起来，从买来的食物原材料，到最后的上菜，每一步都直播出来，有了这样的直播间，家长那怕给直播平台交流量费，也肯定会看的。类似的，外卖平台也可以要求加盟商户直播自家的厨房。这不需要新的立法，不需要新的技术，只需要有人用现有的技术，只需要有人愿意去做，愿意去用脚投票。&lt;/p&gt;

&lt;p&gt;最后的最后，本想放一首歌，周云蓬的中国孩子，但加上了，这篇文多半会404的，想听的百度就能找到。我既不想写会404的文，更不想写十万加的文，会刻意的避免那些会让文章火起来的元素，这篇也不例外。真正持久的改革，不是靠几篇十万加就促成的，只要少数的人从心理认定了一件事坚持下去，就足够了。昨天看美剧The good doctor中的一句台词，深深的打动了我，”Whenever people want you to do something they think is wrong, they say it's reality&quot;,世上有那么多的学校，那么多的食堂，总有一所会有一些害群之马，就像飞机的代码那么多，总会有些bug，这就是现实。从统计来看，飞机是安全的，食物的无害的，只是我们说起这样的现实的时候，是低着头的，而当说起我们改变了的现实的时候，肯定会自豪的扬着头的。&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.9571428571428572&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcchv3KUuweZXe6fsWE5ibGU1ia4EK7z4k4428aicv80iaX9TmDgibur2w2ibe7KjtWmGMFjbHsNibFbe3XDA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;420&quot; /&gt;&lt;/p&gt;

&lt;p&gt;ps 最后放一张图，很喜欢这句话，也很应和这篇的主题，希望通过AI来解决社会自身的问题，就是年轻和幼稚的表现，通过发明或者应用一个黑科技，立刻见到立竿见影的成果，但人的问题，应该由人来解决。机器不应该为人的平庸之恶买单，机器只会以指数级的效率，去放大人的平庸之恶，甚至是人无心做的恶，只要自己先做的端正，才能避免ai把我们带到反乌托邦。&lt;/p&gt;


&lt;p&gt;更多阅读&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651383677&amp;amp;idx=1&amp;amp;sn=b1aa1ab4453286c02b7fedcc28a9b391&amp;amp;chksm=84f3c93cb384402ae4482f878a696616f168f13e9f1a6a74481f892b0265ef087de6f7d1901a&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-itemshowtype=&quot;0&quot; data-linktype=&quot;2&quot;&gt;当你年近九十，是否还有心气，向人类史上最困难的百万美金发起挑战？&lt;/a&gt;&lt;br /&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651383412&amp;amp;idx=1&amp;amp;sn=b3d8537651bb02abd3ebfa759e5e1db3&amp;amp;chksm=84f3c835b38441239a0cc7412f1e0873a8ff7dfdff3f7044c4a998c9706f444a43cbaf55fbcd&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-itemshowtype=&quot;0&quot; data-linktype=&quot;2&quot;&gt;《Skin In The Game》塔勒布由风险管理引出的一碗毒鸡汤&lt;/a&gt;&lt;br /&gt;&lt;/p&gt;





</description>
<pubDate>Fri, 15 Mar 2019 14:53:24 +0000</pubDate>
<dc:language>zh-CN</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.jintiankansha.me/t/kigw41CD7S</dc:identifier>
</item>
</channel>
</rss>