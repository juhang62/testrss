<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="css/feed.xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/" xmlns:og="http://ogp.me/ns#">
<channel>
<atom:link rel="self" href="http://192.168.1.4/fivefilters/makefulltextfeed.php?url=feed43.com%2Fchaoscruiser-jtks.xml&amp;max=5&amp;links=preserve&amp;exc=1" />
<atom:link rel="alternate" title="Source URL" href="http://feed43.com/chaoscruiser-jtks.xml" />
<atom:link rel="related" title="Subscribe to feed" href="http://www.subtome.com/#/subscribe?feeds=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed43.com%252Fchaoscruiser-jtks.xml%26max%3D5%26links%3Dpreserve%26exc%3D1&amp;back=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed43.com%252Fchaoscruiser-jtks.xml%26max%3D5%26links%3Dpreserve%26exc%3D1" />
<title>混沌巡洋舰</title>
<link>http://www.jintiankansha.me/column/ultiWL8Axg</link>
<description>混沌巡洋舰 - 今天看啥</description>
<ttl>360</ttl>
<item>
<title>类脑计算背后的计算神经科学框架</title>
<link>http://www.jintiankansha.me/t/vxIBUoMiXU</link>
<guid isPermaLink="true" >http://www.jintiankansha.me/t/vxIBUoMiXU</guid>
<description>&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;类脑计算， 是一个新兴的名词， 其实换一个名字， 就是我之前研究的计算神经科学。&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;大家了解人工智能， 而不了解计算神经科学， 事实上两者的关系就是一颗硬币的两面。&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;这枚硬币就是智能算法本身。宇宙中产生智能的过程， 孕育了生物智能， 我们取其道行之， 得到人工智能。而从生物的神经系统取出这个算法的过程， 就是计算神经科学。&lt;/p&gt;
&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibccts2GdPDN5kPZiaKPh2I56p6fSCOUcXSn9B7KumHb0Cc8WKBCZSeC9cdn5xicSW9L9O4LJFmpN1KbA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;640&quot; width=&quot;640&quot;/&gt;&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;计算神经科学有两个使命，一个是直接解决生命智能有关的问题， 如困扰我们的心理疾病， 器质性的神经退行性疾病如老年痴呆。因为你只有懂得了算法出现问题的原因， 才能去修正它。&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;另一方面，计算神经科学得到的启发可以直接用于人工智能， 好比一个蓄水池， 它的水位足够高， 就可以流出一部分做人工智能算法的应用。当下的AI的核心重磅RNN和CNN，都和8，90年代这个算法的积累有关。&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;计算神经科学的算法和人工智能算法的本质不同在于计算神经科学考虑生物细节的影响，试图解释生物现象， 而人工智能把这条缰绳脱去了。而这条缰绳是否有意义也是计算神经科学的热点问题。&lt;/p&gt;
&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibccts2GdPDN5kPZiaKPh2I56p1icL6H5lWeZKfqhc3Y8LCIQJ0MrnwuyUjVhMnTCOfWrFibWPqqRiboqkQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;640&quot; width=&quot;640&quot;/&gt;&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;研究计算神经科学的方法我们可以总结一种层级型的思维方法。因为计算神经科学本质是一个桥梁学科。它连接了从最基本的生物物理层级， 到神经回路（网络）， 然后大尺度神经回路基础上涌现的动力系统，以及动力系统所carry的信息流， 而在信息尺度之上， 我们得到计算，或者算法本身， 在此基础上得到功能， 得到多种多样的心智现象， 这也就是最高层级。&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;&lt;span&gt;一 生物物理层次&lt;/span&gt;&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;最低层级的现象往往可以由生化实验所测量， 最高层级就是心理学或认知科学， 可以由心理实验测量。中间的那些层次生物神经科学家通过各种各种的成像记录间接获得。而这些层次间的联系就是计算神经科学。&lt;/p&gt;
&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibccts2GdPDN5kPZiaKPh2I56po3Mvq6XNocWFtLVamQ4DvRLCAfOToKx9NwgDLN7qpLeFRBM7XugLTQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;640&quot; width=&quot;640&quot;/&gt;&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;计算神经科学与人工智能的载体均是神经网络， 但是两者既有联系又有区别。这种区别主要体现在计算神经科学的神经网络试图用最简单的模型获取最多的生物真实性， 而AI的神经网络试图这种简化模型进一步工程化标准化最大化其功能。具体的区分度， 又在于神经元的细节， 连接懂得细节， 以及学习本身。&lt;/p&gt;
&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.737012987012987&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibccts2GdPDN5kPZiaKPh2I56pE5rrduLwkYFLND0bcvy6H0gzFZR8B3PsBkQjibhNFZ0qUanA074ZJAg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;616&quot; width=&quot;616&quot;/&gt;&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;生物神经细胞本身其实极为复杂， 一个细胞甚至堪比一个神经网络。树突收集信息， 胞体做出决策， 传递到轴突。&lt;/p&gt;
&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibccts2GdPDN5kPZiaKPh2I56pDRJ4FwpicCBYibjpVP3nicuydd2ddX0EgTA9AueVCT7icicWeNibn5kxcRaw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;640&quot; width=&quot;640&quot;/&gt;&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;Spike，神经元尖峰放电是生物神经网络的信息货币（bit），放电是一个典型的物理化学过程， 当输入超过某个阈值，细胞膜内外的钠离子和钾离子相继发放，引起一个由正反馈到负反馈主宰的过程， 由Hodykin Huxley 方程描述。&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;Häusser, Michael. &quot;The Hodgkin-Huxley theory of the action potential.&quot;&lt;em&gt;nature neuroscience&lt;/em&gt;3.11 (2000): 1165.&lt;/p&gt;
&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.48055555555555557&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibccts2GdPDN5kPZiaKPh2I56pgCTvCqEfX4E99JavBAILmsDkmr7E1FrIL88SNibUak7Yj4KvjHxepfA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;720&quot; width=&quot;822&quot;/&gt;&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;连续的尖峰放电把一个直流输入转化成脉冲输出 ， 这个脉冲频率由直流输入大小决定， 对外表现为脑电波。如我们数值的alpha或gamma波。&lt;/p&gt;
&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibccts2GdPDN5kPZiaKPh2I56poUJAq3Gcysuiagw4qicqgxUaY8R4ibY8vkRcKzrmw7Q92liaR8CpHW1GyA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;640&quot; width=&quot;640&quot;/&gt;&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;把脉冲神经元放在一起组成脉冲神经网络。&lt;/p&gt;
&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibccts2GdPDN5kPZiaKPh2I56pnKBJk0vJe1ZxxvVCUib2y6oWj5R7VS7NxNEhgwdjWOL7LJPdQeiaZ5Ag/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;640&quot; width=&quot;640&quot;/&gt;&lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;/&gt; &lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot;&gt;&lt;span&gt;这个步骤如何做一个大&lt;/span&gt;刀&lt;span&gt;阔斧的简化呢？&lt;/span&gt;&lt;span&gt;我们把单位时间窗口的输出spike个数简化为发放率， 刚刚说脉冲神经元的输入和输出是简单线性的， 那么这个线性关系被以上方程概括。&lt;/span&gt;&lt;span&gt;w描述每个神经树突对信息的敏感性。&lt;/span&gt;&lt;/p&gt;
&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibccts2GdPDN5kPZiaKPh2I56pMy1x1HqxycqTxuQQpxXVfLyDO5TjW05yCBnibl73RFRKJVggBTiazr6w/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;640&quot; width=&quot;640&quot;/&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;而神经脉冲那种输入超过阈值则引起正反馈的性质被一个非线性的门函数概括， 它可以是我们们熟悉的relu，sigmoid。&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;生物脉冲神经元和这种经过简化的实数神经元到底有何不同？　同样是前馈网络，脉冲神经元构成的网络，由于尖峰脉冲的时间结构， 它的发放可以携带和时间有关的信息，是当下的深度学习所使用的rate神经元不具备的。同时，不同尖峰脉冲神经元发放间的correlation 被认为可以编码信息。而脉冲神经元和rate数值神经元到底有无本质区别， 也成为各种学派的争论焦点。&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;&lt;span&gt;二 学习和网络架构层次&lt;/span&gt;&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;&lt;span&gt;1， 生物学习vs机器学习&lt;/span&gt;&lt;/p&gt;
&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibccts2GdPDN5kPZiaKPh2I56px8O4sqW3wCvxaUjjd6c2pA7g4U7ccs3LHHibsvXbLs9OTA001Ge64HQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;640&quot; width=&quot;640&quot;/&gt;&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;生物学习和机器学习的比较：同为学习， 生物学习和机器学习的本质相同而形式迥异。所谓本质相同， 它们都是输出导致的对自身的反馈， 且这种反馈的方向使得总体的信息增加而熵减少。&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;这就决定了，学习的过程需要的是输出的结果，被一个函数衡量， 作用到信息流动的载体，神经网络里， 使得新的输出向着某个确定方向变化 。&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;如果从一个较大的尺度看生物学习， 那么大部分的学习实质上是“进化” 。因为我们先天的已经具备大量的学习能力， 比如先验的语言能力（乔姆斯基）。而真正通过生物后天学习可以得到的， 反而是一小部分内容。&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;如果但看学习， 生物学习的关键词是Hebian学习， 神经可塑性和强化学习， 而机器学习是监督学习， 非监督学习和强化学习。&lt;/p&gt;
&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibccts2GdPDN5kPZiaKPh2I56pXw7s8gRWaeLKwEI7hBOF9JicRoe7RIIzicWtacw37GT0cQyAibGXyXzibA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;640&quot; width=&quot;640&quot;/&gt;&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;机器学习的基础是监督学习。这个对输出的度量由一个绝对真理的代表-导师提供，与它不匹配的时候， 一个错误信号向整个网络传递， 而最终网络结构向着减少这个错误的方向改变。&lt;/p&gt;
&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibccts2GdPDN5kPZiaKPh2I56pOxFia4qgOjHE12lO7cRa0XVoPRdzsAt9Z1VC7ia0ibbVJX1TysAvzWd3g/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;640&quot; width=&quot;640&quot;/&gt;&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot;&gt;&lt;span&gt;而生物学习的基础是无监督学习。它本质所&lt;/span&gt;做&lt;span&gt;的工作是相似度匹配。&lt;/span&gt;&lt;/p&gt;
&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibccts2GdPDN5kPZiaKPh2I56pqyiceDBCRib7RMmMy96EQ5sHy2Mrnmcs49FOlN5hE4jND1CKLqkibcdeA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;640&quot; width=&quot;640&quot;/&gt;&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;这种学习的基础正是著名的赫布法则， 它说的是当一个上游神经元可以引发下游神经元的放电， 它们的加强就会增强。&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;“Hebb suggested that such synaptic modification could produce neuronal&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;assemblies that reflect the relationships experienced during training.&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;For example, consider applying this rule to neurons that fire together during training&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;due to an association between a stimulus and a response. These neurons&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;would develop strong interconnections, and subsequent activation&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;of some of them by the stimulus could produce the synaptic drive needed&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;to activate the remaining neurons and generate the associated response.&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;赫布法则导致的一个直接结果是神经元集团的生成，对应一个经常一起发生的事件序列进行反应。这其实就是在挖掘事件间的相关性。把这种相关性学习直接写成数学公式， 我们会发现这种学习的效果类似PCA主成分分析，也就是通过学习神经元集团掌握了数据样例间的共同特征（oja's law），而不同的“相关特征组”就可能是概念形成的基础 。&lt;/p&gt;
&lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;/&gt; &lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibccts2GdPDN5kPZiaKPh2I56pCvBddAvwvVQiamicAIGg2KbWibibkUiaOlB9IEodpj3dQcX9v19GVev7j5Q/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;640&quot; width=&quot;640&quot;/&gt;&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibccts2GdPDN5kPZiaKPh2I56pcLydWv0thVj9vZqNgXR3esITyq0ibyyYFFJgkh7dUzt4XdtvCGhgkUA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;640&quot; width=&quot;640&quot;/&gt;&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;把上面的想法变成一个非常典型的例子， 通过无监督学习， 神经网络可以特征的共同出现（假设我们具有一组分别感受颜色和形状的细胞， 那么红色和圆形， 或者黄色和长形对应苹果和香蕉两个共同概念）来学习苹果和香蕉的概念。&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;那么通过这样的学习能否得到丰富复杂的生物大脑模型呢？答案是否定的， 因为生物的多样性建立在复杂的进化历程基础上， 这种长期与环境交互的“学习”被写在基因里 。这种进化的复杂性表现在神经元的种类， 网络的拓扑结构， 全脑连接等等因素上， 即使如此，我们可以发现不同神经网络的共性， 比如多层级结构(hierarchy structure)， 小世界网络(small world networks)， 兴奋抑制平衡(Dale Principle balanced network)等， 它们可能反应了神经网络的共同原则。同时我们可以通过这些原则给AI设计人工神经网络。&lt;/p&gt;
&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibccts2GdPDN5kPZiaKPh2I56p68KynrJMmTCBShy3HCtV7skecLA8dzBuk11tibEHvQibf3Kfnbe4PeoA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;640&quot; width=&quot;640&quot;/&gt;&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibccts2GdPDN5kPZiaKPh2I56ppJSAVwdMXMb2Nd18x2PyoibxnoibRHopbM6A4jTlHtItcm4uAWgF9Qyg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;640&quot; width=&quot;640&quot;/&gt;&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;目前我们对这些共同原则知之甚少， 比较程序的框架有efficient coding， sparse coding 或者 predictive coding。它们都处在我们下面要讲的编码层次。&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;&lt;span&gt;三 大脑信息编码层次&lt;/span&gt;&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;有了学习和通过进化与学习得到的结构，下一个level就是编码， 编码又分为大脑神经网络的编码和解码。这个层次的本质是信息的流动， 外界刺激需要通过编码被内在神经活动加载， 而后面内在神经活动需要通过解码等转化为肌肉的运动和语言等。&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;让我们来具体看几个生物计算系统的案例；　&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;１，　视网膜，　一个人们研究极为透彻的系统。　　&lt;/p&gt;
&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibccts2GdPDN5kPZiaKPh2I56pcvGvVXEVbR7cycfIyG7mqgTtvkbwmlhIsSxdlVcDQc1XibeNZHHhVQw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;640&quot; width=&quot;640&quot;/&gt;&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;视网膜看似如同照相机的ccd，　事实上确是一个非常核心的计算单元。视网膜其实是一个类似ＣＮＮ的典型多层神经网络。从最底层的感受色彩的像素，然后对物体的边缘进行对比度分析提出边缘，最终还可以对运动方向等一些信号进行处理（ganglia cells）。　视网膜是视觉神经编码的开始， 关于视网膜计算的根本编码原理被称为&lt;span&gt;efficient coding&lt;/span&gt;框架。这个框架说神经编码的根本在于maximize mutual information with input（增大神经活动与外部信号的互信息）， 的方向尽可能减少冗余的发放达到节能的目的。根据这个原则，我们可以理解视网膜编码对某些色彩或运动方向（如水平， 竖直方向）的编码精确度高于其它色彩或方向。&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;Barlow, Horace B. &quot;Possible principles underlying the transformation of sensory messages.&quot;&lt;em&gt;Sensory communication&lt;/em&gt;1 (1961): 217-234.&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;２，视觉皮层回路&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;视网膜之后， 主要的视觉运算在视皮层内进行， 与视网膜不同的是， 视皮层的运算需要涉及到视觉概念的处理。&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;不用多说， 视觉皮层回路的研究来是计算神经科学和人工智能的交叉点， 早期对视觉皮层的研究工作启发了CNN的工作（Witz）， 而当下的CNN则已经是计算神经科学经常用的工具。&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;CNN用到的大脑视觉编码处理原理称为层级编码， 用这个方法我们把可以把信息表征成从低级到高级的组合形式， 从而高效的表达概念， 如下图的桌子和祖母细胞的例子。&lt;/p&gt;
&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibccts2GdPDN5kPZiaKPh2I56pNzqZ890wiahjibj1Ycoia1mRQeLj9x2EaQg6Hzws4WI4ibXOHBWX0myDwA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;640&quot; width=&quot;640&quot;/&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; yahei=&quot;&quot; han=&quot;&quot; sans=&quot;&quot; cjk=&quot;&quot; micro=&quot;&quot; hei=&quot;&quot; sans-serif=&quot;&quot; medium=&quot;&quot; start=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot;&gt;视觉问题是激发表征学习进步的核心。关于视觉表征一个非常基本的原理称为&lt;span&gt;sparse coding&lt;/span&gt;， sparse coding的基本假设是视觉信息的编码虽然看似高维繁复， 但是实质上常见的物体就那么多， 因此从有效的角度， 视觉回路完全由更智慧的方法用最小的神经元来编码它们。具体怎么做？你可以做一个字典， 这个字典里包含我们万千日常可见事物， 这些事物被称作引发神经元发放的隐变量， 事实上视皮层的神经元很大部分就是参与这些隐变量的表征。但是我用一个先�&lt;/p&gt;
</description>
<pubDate>Sat, 12 Oct 2019 01:02:55 +0000</pubDate>
<dc:language>zh-CN</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.jintiankansha.me/t/vxIBUoMiXU</dc:identifier>
</item>
<item>
<title>哥白尼原理的是非-读《如果，哥白尼错了》</title>
<link>http://www.jintiankansha.me/t/Idr23V0v6X</link>
<guid isPermaLink="true" >http://www.jintiankansha.me/t/Idr23V0v6X</guid>
<description>&lt;p&gt;&lt;br /&gt;机器学习中的最大熵原则，在科学界有一个类似的描述，叫做哥白尼原理，在阅读这本书之前，我对其很是推崇，曾在公众号写过相关的文，例如&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651381462&amp;amp;idx=1&amp;amp;sn=4fe09a232805b60ea0ae04424e25345e&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-itemshowtype=&quot;0&quot; data-linktype=&quot;2&quot;&gt;从不拒绝自命不凡，说到柏林墙的终结&lt;/a&gt;，介绍相关的应用。但在读了湛庐新出的《如果，哥白尼错了》（原标题The Copernicus Complex）这本书之后，觉得有必要对这个话题重新说说。&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;1&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcdJHJyDZ0CFyBQhVEKkPib1obumh6UcLOaibwFBanEuxmY7CMQzmWl4VQQbfcI3iarrNG16s310xAvOQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;350&quot; /&gt;&lt;/p&gt;
&lt;p&gt;这本书的作者是哥伦比亚大学的天体生物学系主任，天体生物学就是寻找外星人的学科，或者说解释为何还没有找到外星人的学科。这个问题更为人熟知的名字是费米悖论，而其中的一个解释叫人择原理。具体来说，天体物理学家发现，这个宇宙的很多基本常数，哪怕发生一点点的改变，那么不要说人类这样的高等生物，那怕是原子这种基本结构，都会不复存在的。仿佛这个宇宙是被精准的调节到一个恰好的状态，使得生命得以存活。与之相对的哥白尼原理则指出，人，作为观测者，没有道理处在一个最特殊的位置上。&lt;/p&gt;

&lt;p&gt;在无法对多重宇宙进行观测之前，无论是哥白尼原理还是人择原理，都是不可证伪的。俩者各自都可以拿出诸多证据。The Copernicus Complex这本书原文的副标题是“在一个充满行星和概率的宇宙中找到在宇宙中的意义”。这里点出了这本书的俩个核心词，本文先逐个展开简述，再来说说自己对这个问题的看法。&lt;/p&gt;

&lt;p&gt;寻找地外生物，主流的方法还是按图索骥，根据地球上生命所需的环境，找地外星系中和地球环境类似的行星，然而根据人类的观察，哥白尼原理似乎不适合了，我们的太阳系和其他恒星系统比起来很特殊，按照哥白尼原理，太阳的寿命，应该在所有恒星中属于中间值，地球的大小，距离恒星的距离的也没错，都是属于中间的。但若是合起来看，那太阳系就很特殊了。但生命的诞生，需要的是太多复杂的巧合，而不是一次次的，从可能孕育生命的恒星系中减去一长串数字背后的0（例如电影“超时空接触”中所演的）。天体物理学的发现，让我们发现大部分恒星系都不是类似太阳系的，但这不应该成为反驳哥白尼原理的证据，单个属性来看，我们所在的位置并不特殊，但若是按照复杂系统的视角，同时考虑系统的演化路径，那么生命就是独一无二的，或者说，生命存活在所有看上去很怪异的地方。&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;生命的演化是一个需要大量时间的过程，而这其中就涉及到概率问题。三体问题不可解，这看似和太阳系无关。但将哪怕一个初始的不那么大的物体，由于蝴蝶效应的影响，在概率的层面上，也可以看成是三体问题，例如下图所示的，大部分球都会往同一个方向反弹，但不时有一个例外会使球弹向别处。这本书中讲到用计算机模拟行星间的引力相互作用，结果显示，在多次模拟中，类地行星的轨道是不稳定的。&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-ratio=&quot;0.57&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcdJHJyDZ0CFyBQhVEKkPib1orQhFdLDIiaUyva0iamIR9DHpH1okY9ncobf4esRwyPCg4XlpSSNTLHyg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;500&quot; /&gt;&lt;/p&gt;
&lt;p&gt;也就是说，太阳系初始时即使只多出一粒尘埃，理论上，地球也会因此而掉入太阳。书中讲到，根据对未来太阳系的模拟，有1%的概率，太阳系中水星在未来33亿年之后掉入太阳，下图展示的对太阳系模拟的多种可能的轨迹。这个例子的关键信息是用当下的情况来推断未来时，并没有机械化的可预测性，而是令人不安的数学可能性与不确定性。而这应和本书副标题中的概率。虽然通往最终状态的路径不可预测，但并不意味着最终状态不可预测。&lt;br /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-ratio=&quot;0.454&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcdJHJyDZ0CFyBQhVEKkPib1or0s0AKnticTvNEZFfJBorc72jdpJldnxtuN9EPaM1HbmCtWt7TWtnDA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;500&quot; /&gt;&lt;/p&gt;

&lt;p&gt;综合上述的俩点，在省略了一长串的论证之后，(自己看书去)本书最终的结论是：&lt;strong&gt;生命的状态是一种突发性现象，生命产生于一系列不断变化的物理环境的边界处。&lt;/strong&gt;&lt;strong&gt;而人在宇宙中的地位即是特殊但非别有深意的，是独特但非异常的。&lt;/strong&gt;&lt;strong&gt;哥白尼定理即是正确的，也是错误的。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;关于这个不怎么好理解的结论，我是认同的，用其类比人的一生，小孩时你觉得自己是世界的中心，所有人都围着你转，长大后遇见越来越多各种各样的人，发现自己很普通，就如同哥白尼原理所说的，而若你取得了成功后回首往事，会发觉哪怕环境只要有一点变化，就无法让自己成为了当下的样子，而这正是人择原理。但再成熟一些，就会发现真正让自己特殊的正是偶然性带来的轨迹。童话“小王子”中遇到了五千颗玫瑰之后的落寞，对应着人类一步步发现自己所在的行星不过是万千宇宙中很平常的一颗，而意识到复杂性带来的路径依赖和混沌现象中的不可预测性之后，人类意识到我们存在于一个对人类很特殊的地方，而正是生命几十亿年对地球的改造，使得地球变得对人类如此特殊。&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;更多阅读&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651384638&amp;amp;idx=1&amp;amp;sn=94d0fea265492161a2cbacdc58483b14&amp;amp;chksm=84f3c57fb3844c6959289f419cd90922d177266153ab443fbba1aebdcd471a0b1e90f9229de7&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-itemshowtype=&quot;0&quot; data-linktype=&quot;2&quot;&gt;那样的话，我们就会在宇宙中真正获得家的感觉-读《生命与新物理学》&lt;/a&gt;&lt;br /&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651384626&amp;amp;idx=1&amp;amp;sn=60d7a08d0dbb9a56e02113937326832c&amp;amp;chksm=84f3c573b3844c65067a18f2534af36f52ff670347d4125f8ce40ee9720315b52903713a1b2a&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-itemshowtype=&quot;0&quot; data-linktype=&quot;2&quot;&gt;《反常识》读书笔记-一旦知道了答案，凡事都是显而易见的&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;该书购买链接：https://item.m.jd.com/product/12571227.html? 或点击原文&lt;/p&gt;
</description>
<pubDate>Sat, 12 Oct 2019 01:02:54 +0000</pubDate>
<dc:language>zh-CN</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.jintiankansha.me/t/Idr23V0v6X</dc:identifier>
</item>
</channel>
</rss>