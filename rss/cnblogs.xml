<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="css/feed.xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/" xmlns:og="http://ogp.me/ns#">
<channel>
<atom:link rel="self" href="http://192.168.1.4/fivefilters/makefulltextfeed.php?url=feed.cnblogs.com%2Fblog%2Fsitehome%2Frss&amp;max=10&amp;links=preserve&amp;exc=" />
<atom:link rel="alternate" title="Source URL" href="http://feed.cnblogs.com/blog/sitehome/rss" />
<atom:link rel="related" title="Subscribe to feed" href="http://www.subtome.com/#/subscribe?feeds=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed.cnblogs.com%252Fblog%252Fsitehome%252Frss%26max%3D10%26links%3Dpreserve%26exc%3D&amp;back=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed.cnblogs.com%252Fblog%252Fsitehome%252Frss%26max%3D10%26links%3Dpreserve%26exc%3D" />
<title>博客园_首页</title>
<link></link>
<description>代码改变世界</description>
<item>
<title>创建 SysV 风格的 linux daemon 程序 - sparkdev</title>
<link>http://www.cnblogs.com/sparkdev/p/12714790.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/sparkdev/p/12714790.html</guid>
<description>&lt;p&gt;&lt;span&gt;本文介绍如何使用 C 语言创建 Linux 系统中 SysV 风格的 daemon 程序。注意：这是一种旧式的 daemon 程序写法，进入 systemd 时代后是不需要通过这样的方式创建 daemon 程序的。 本文的演示环境为 ubuntu 18.04。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;通过前文《&lt;a href=&quot;https://www.cnblogs.com/sparkdev/p/12146305.html&quot; target=&quot;_blank&quot;&gt;Linux session(会话)&lt;/a&gt;》我们了解到，如果要让程序运行在后台，必须处理好进程的 session。所以在创建 daemon 程序的过程中处理 session 问题是很重要的一步，当然除此之外还需要其它的步骤。下面是在 Linux 系统中创建一个 SysV 风格的 daemon 的基本流程：&lt;/span&gt;&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;&lt;span&gt;从父进程 fork 出一个子进程&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span&gt;为子进程创建新的 session ID&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span&gt;在子进程中再 fork 一次&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span&gt;修改 umask&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span&gt;修改进程的当前工作目录&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span&gt;关闭进程中的文件描述符&lt;/span&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;&lt;span&gt;接下来我们通过代码来介绍这些操作的含义。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;span&gt;从父进程 fork 出一个子进程&lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;&lt;span&gt;创建一个子进程，如果成功就让父进程退出，此时的子进程已经成为了 init 进程的子进程：&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;32&quot;&gt;
&lt;pre&gt;
&lt;span&gt;pid_t pid;

pid &lt;/span&gt;=&lt;span&gt; fork();
&lt;/span&gt;&lt;span&gt;if&lt;/span&gt; (pid &amp;lt; &lt;span&gt;0&lt;/span&gt;&lt;span&gt;)
    exit(EXIT_FAILURE);
&lt;/span&gt;&lt;span&gt;if&lt;/span&gt; (pid &amp;gt; &lt;span&gt;0&lt;/span&gt;&lt;span&gt;)
    exit(EXIT_SUCCESS);&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;&lt;span&gt;为子进程创建新的 session ID&lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;&lt;span&gt;运行在后台的进程需要摆脱 session 终端的束缚，通过 setsid() 函数为进程设置新的 session ID 可以做到这一点：&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;33&quot;&gt;
&lt;pre&gt;
&lt;span&gt;pid_t pid;

pid &lt;/span&gt;=&lt;span&gt; fork();
&lt;/span&gt;&lt;span&gt;if&lt;/span&gt; (pid &amp;lt; &lt;span&gt;0&lt;/span&gt;&lt;span&gt;)
    exit(EXIT_FAILURE);
&lt;/span&gt;&lt;span&gt;if&lt;/span&gt; (pid &amp;gt; &lt;span&gt;0&lt;/span&gt;&lt;span&gt;)
    exit(EXIT_SUCCESS);

&lt;/span&gt;&lt;span&gt;&lt;strong&gt;if (setsid() &amp;lt; 0)
    exit(EXIT_FAILURE);&lt;/strong&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span&gt;********************************&lt;/span&gt;&lt;br/&gt;&lt;span&gt;执行到这里时，PID==PGID==SID&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/952033/202004/952033-20200416180606227-684161729.png&quot; alt=&quot;&quot;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;********************************&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;span&gt;在子进程中再 fork 一次&lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;&lt;span&gt;这次 fork 的目的是防止进程再次获得终端。因为只有 session leader 才能获得终端，而这次 fork 使子进程变成了非 session leader：&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;34&quot;&gt;
&lt;pre&gt;
&lt;span&gt;pid_t pid;

pid &lt;/span&gt;=&lt;span&gt; fork();
&lt;/span&gt;&lt;span&gt;if&lt;/span&gt; (pid &amp;lt; &lt;span&gt;0&lt;/span&gt;&lt;span&gt;)
    exit(EXIT_FAILURE);
&lt;/span&gt;&lt;span&gt;if&lt;/span&gt; (pid &amp;gt; &lt;span&gt;0&lt;/span&gt;&lt;span&gt;)
    exit(EXIT_SUCCESS);

&lt;/span&gt;&lt;span&gt;if&lt;/span&gt; (setsid() &amp;lt; &lt;span&gt;0&lt;/span&gt;&lt;span&gt;)
    exit(EXIT_FAILURE);
    
&lt;/span&gt;&lt;span&gt;&lt;strong&gt;/* 第二次 fork */
pid = fork();
if (pid &amp;lt; 0)
    exit(EXIT_FAILURE);

if (pid &amp;gt; 0)
    exit(EXIT_SUCCESS);&lt;/strong&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span&gt;********************************&lt;/span&gt;&lt;br/&gt;&lt;span&gt;执行到这里时，PGID==SID 但是已经不等于 PID 了，说明进程已经不是 session leader&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/952033/202004/952033-20200416180704116-1295386313.png&quot; alt=&quot;&quot;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;********************************&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;span&gt;修改 umask&lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;&lt;span&gt;为了能够向 daemon 进程创建的任何文件中写入内容(包括日志)，必须重置 umask(file mode mask, umask)，以确保能够正确地写入或读取这些文件：&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;span&gt;修改进程的当前工作目录&lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;&lt;span&gt;必须保证进程的当前工作目录是存在的。因为众多的 Linux 发行版中很多都没有完全遵守标准的文件目录结构，所以最好是把进程的当前工作目录设置为 /，这样可以避免因设置了某个目录而导致它无法被 unmount：&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot;&gt;
&lt;pre&gt;
&lt;strong&gt;&lt;span&gt;chdir(&quot;/&quot;);&lt;/span&gt;&lt;/strong&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;&lt;span&gt;关闭进程中的文件描述符&lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;&lt;span&gt;关闭进程中所有打开的文件描述符：&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;32&quot;&gt;
&lt;pre&gt;
&lt;span&gt;&lt;strong&gt;int x;
for (x = sysconf(_SC_OPEN_MAX); x&amp;gt;=0; x--)
{
    close (x);
}&lt;/strong&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;br/&gt;&lt;strong&gt;&lt;span&gt;把日志写入 syslog&lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;&lt;span&gt;Daemon 程序的日志非常重要，我们可以通过 openlog、syslog 和 closelog 三个函数把日志内容写入到 syslog  中：&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;38&quot;&gt;
&lt;pre&gt;
openlog (&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;daemondemo&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;, LOG_PID, LOG_DAEMON);
syslog (LOG_NOTICE, &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;Daemon demo is running, number: %d&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;, count);
closelog();&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span&gt;本文 demo 输出的日志如下所示：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/952033/202004/952033-20200416180841012-418428751.png&quot; alt=&quot;&quot;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;span&gt;完整的代码&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;44&quot;&gt;
&lt;pre&gt;
#include &amp;lt;stdio.h&amp;gt;&lt;span&gt;
#include &lt;/span&gt;&amp;lt;stdlib.h&amp;gt;&lt;span&gt;
#include &lt;/span&gt;&amp;lt;unistd.h&amp;gt;&lt;span&gt;
#include &lt;/span&gt;&amp;lt;signal.h&amp;gt;&lt;span&gt;
#include &lt;/span&gt;&amp;lt;sys/types.h&amp;gt;&lt;span&gt;
#include &lt;/span&gt;&amp;lt;sys/stat.h&amp;gt;&lt;span&gt;
#include &lt;/span&gt;&amp;lt;syslog.h&amp;gt;

&lt;span&gt;static&lt;/span&gt; &lt;span&gt;void&lt;/span&gt;&lt;span&gt; demo_daemon()
{
    pid_t pid;

    &lt;/span&gt;&lt;span&gt;/*&lt;/span&gt;&lt;span&gt; Fork off the parent process &lt;/span&gt;&lt;span&gt;*/&lt;/span&gt;&lt;span&gt;
    pid &lt;/span&gt;=&lt;span&gt; fork();

    &lt;/span&gt;&lt;span&gt;/*&lt;/span&gt;&lt;span&gt; An error occurred &lt;/span&gt;&lt;span&gt;*/&lt;/span&gt;
    &lt;span&gt;if&lt;/span&gt; (pid &amp;lt; &lt;span&gt;0&lt;/span&gt;&lt;span&gt;)
        exit(EXIT_FAILURE);

    &lt;/span&gt;&lt;span&gt;/*&lt;/span&gt;&lt;span&gt; Success: Let the parent terminate &lt;/span&gt;&lt;span&gt;*/&lt;/span&gt;
    &lt;span&gt;if&lt;/span&gt; (pid &amp;gt; &lt;span&gt;0&lt;/span&gt;&lt;span&gt;)
        exit(EXIT_SUCCESS);

    &lt;/span&gt;&lt;span&gt;/*&lt;/span&gt;&lt;span&gt; On success: The child process becomes session leader &lt;/span&gt;&lt;span&gt;*/&lt;/span&gt;
    &lt;span&gt;if&lt;/span&gt; (setsid() &amp;lt; &lt;span&gt;0&lt;/span&gt;&lt;span&gt;)
        exit(EXIT_FAILURE);

    &lt;/span&gt;&lt;span&gt;/*&lt;/span&gt;&lt;span&gt; Catch, ignore and handle signals &lt;/span&gt;&lt;span&gt;*/&lt;/span&gt;
    &lt;span&gt;//&lt;/span&gt;&lt;span&gt;TODO: Implement a working signal handler */
    &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;signal(SIGCHLD, SIG_IGN);
    &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;signal(SIGHUP, SIG_IGN);&lt;/span&gt;

    &lt;span&gt;/*&lt;/span&gt;&lt;span&gt; Fork off for the second time&lt;/span&gt;&lt;span&gt;*/&lt;/span&gt;&lt;span&gt;
    pid &lt;/span&gt;=&lt;span&gt; fork();

    &lt;/span&gt;&lt;span&gt;/*&lt;/span&gt;&lt;span&gt; An error occurred &lt;/span&gt;&lt;span&gt;*/&lt;/span&gt;
    &lt;span&gt;if&lt;/span&gt; (pid &amp;lt; &lt;span&gt;0&lt;/span&gt;&lt;span&gt;)
        exit(EXIT_FAILURE);

    &lt;/span&gt;&lt;span&gt;/*&lt;/span&gt;&lt;span&gt; Success: Let the parent terminate &lt;/span&gt;&lt;span&gt;*/&lt;/span&gt;
    &lt;span&gt;if&lt;/span&gt; (pid &amp;gt; &lt;span&gt;0&lt;/span&gt;&lt;span&gt;)
        exit(EXIT_SUCCESS);

    &lt;/span&gt;&lt;span&gt;/*&lt;/span&gt;&lt;span&gt; Set new file permissions &lt;/span&gt;&lt;span&gt;*/&lt;/span&gt;&lt;span&gt;
    umask(&lt;/span&gt;&lt;span&gt;0&lt;/span&gt;&lt;span&gt;);

    &lt;/span&gt;&lt;span&gt;/*&lt;/span&gt;&lt;span&gt; Change the working directory to the root directory &lt;/span&gt;&lt;span&gt;*/&lt;/span&gt;
    &lt;span&gt;/*&lt;/span&gt;&lt;span&gt; or another appropriated directory &lt;/span&gt;&lt;span&gt;*/&lt;/span&gt;&lt;span&gt;
    chdir(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;/&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;);

    &lt;/span&gt;&lt;span&gt;/*&lt;/span&gt;&lt;span&gt; Close all open file descriptors &lt;/span&gt;&lt;span&gt;*/&lt;/span&gt;
    &lt;span&gt;int&lt;/span&gt;&lt;span&gt; x;
    &lt;/span&gt;&lt;span&gt;for&lt;/span&gt; (x = sysconf(_SC_OPEN_MAX); x&amp;gt;=&lt;span&gt;0&lt;/span&gt;; x--&lt;span&gt;)
    {
        close (x);
    }

    &lt;/span&gt;&lt;span&gt;/*&lt;/span&gt;&lt;span&gt; Open the log file &lt;/span&gt;&lt;span&gt;*/&lt;/span&gt;&lt;span&gt;
    openlog (&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;daemondemo&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;, LOG_PID, LOG_DAEMON);
}

&lt;/span&gt;&lt;span&gt;int&lt;/span&gt;&lt;span&gt; main()
{
    &lt;/span&gt;&lt;span&gt;int&lt;/span&gt; count = &lt;span&gt;0&lt;/span&gt;&lt;span&gt;;
    demo_daemon();

    &lt;/span&gt;&lt;span&gt;while&lt;/span&gt; (&lt;span&gt;1&lt;/span&gt;&lt;span&gt;)
    {
        &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;TODO: Insert daemon code here.&lt;/span&gt;
        count ++&lt;span&gt;;
        syslog (LOG_NOTICE, &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;Daemon demo is running, number: %d&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;, count);
        sleep (&lt;/span&gt;&lt;span&gt;5&lt;/span&gt;&lt;span&gt;);
        &lt;/span&gt;&lt;span&gt;if&lt;/span&gt;(count &amp;gt; &lt;span&gt;5&lt;/span&gt;&lt;span&gt;)
        {
            &lt;/span&gt;&lt;span&gt;break&lt;/span&gt;&lt;span&gt;;
        }
    }

    syslog (LOG_NOTICE, &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;Daemon demo terminated.&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;);
    closelog();

    &lt;/span&gt;&lt;span&gt;return&lt;/span&gt;&lt;span&gt; EXIT_SUCCESS;
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span&gt;把上面的代码保存到文件 daemondemo.c 中(也可以从&lt;a href=&quot;https://github.com/sparkdevo/daemondemo/blob/master/daemondemo.c&quot; target=&quot;_blank&quot;&gt;这里&lt;/a&gt;下代码)，然后执行下面的命令进行编译就可以得到可执行文件 daemondemo：&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;32&quot;&gt;
&lt;pre&gt;
$ &lt;span&gt;gcc&lt;/span&gt; -Wall daemondemo.c -o daemondemo
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;span&gt;这是一个很有意思的话题，有人说需要 fork 两次，有人说第二次是可选的，究竟该如何做呢？当我们理解了第二次 fork 的用途后就可以自行决定是否需要第二次 fork 了。&lt;/span&gt;&lt;br/&gt;&lt;span&gt;这还需要从 session 的控制终端说起。控制终端是进程的一个属性，通过 fork 系统调用创建的子进程会从父进程那里继承控制终端。这样，session 中的所有进程都从 session 领头进程那里继承控制终端。前面已经说过了，要把程序变成 daemon，就得让进程摆脱 session 的终端。而这些在第一次 fork 后调用 setsid() 函数就搞定了。那么如果接下来不小心再给进程添加了终端该怎么办？答案是不让你添加！这就是第二次 fork 的作用。只有 session leader 才能获得终端，而第二次 fork 使子进程变成了非 session leader，你想犯错也不给你机会了。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;像 nginx 和 gblic 的 daemon 函数的实现都是 fork 一次，所以说第二次 fork 是可选的，你可以根据自己的实际情况来决定。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;span&gt;参考：&lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;&lt;a href=&quot;http://www.netzmafia.de/skripten/unix/linux-daemon-howto.html&quot; target=&quot;_blank&quot;&gt;&lt;span&gt;Linux Daemon Writing HOWTO&lt;/span&gt;&lt;/a&gt;&lt;br/&gt;&lt;a href=&quot;https://stackoverflow.com/questions/17954432/creating-a-daemon-in-linux&quot; target=&quot;_blank&quot;&gt;&lt;span&gt;Creating a daemon in Linux&lt;/span&gt;&lt;/a&gt;&lt;br/&gt;&lt;a href=&quot;https://www.freedesktop.org/software/systemd/man/daemon.html&quot; target=&quot;_blank&quot;&gt;&lt;span&gt;daemon man page&lt;/span&gt;&lt;/a&gt;&lt;br/&gt;&lt;a href=&quot;http://man7.org/linux/man-pages/man3/daemon.3.html&quot; target=&quot;_blank&quot;&gt;&lt;span&gt;daemon 函数&lt;/span&gt;&lt;/a&gt;&lt;br/&gt;&lt;a href=&quot;http://www.enderunix.org/docs/eng/daemon.php&quot; target=&quot;_blank&quot;&gt;&lt;span&gt;Unix Daemon Server Programming&lt;/span&gt;&lt;/a&gt;&lt;br/&gt;&lt;a href=&quot;https://github.com/lattera/glibc/blob/master/misc/daemon.c&quot; target=&quot;_blank&quot;&gt;&lt;span&gt;glibc daemon.c&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;
</description>
<pubDate>Fri, 17 Apr 2020 00:32:00 +0000</pubDate>
<dc:creator>sparkdev</dc:creator>
<og:description>本文介绍如何使用 C 语言创建 Linux 系统中 SysV 风格的 daemon 程序。注意：这是一种旧式的 daemon 程序写法，进入 systemd 时代后是不需要通过这样的方式创建 daem</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/sparkdev/p/12714790.html</dc:identifier>
</item>
<item>
<title>Docker命名空间 - 刘新元</title>
<link>http://www.cnblogs.com/precipitation/p/12717442.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/precipitation/p/12717442.html</guid>
<description>&lt;h2 id=&quot;命名空间&quot;&gt;命名空间&lt;/h2&gt;
&lt;p&gt;命名空间（ namespace ）是 Linux 内核的一个强大特性，为容器虚拟化的实现带来极大便利，利用这 特性，每个容器都可以拥有自己单独的命名空间，运行在其中的应用都像是在独立的操作系统环境中一样 命名 间机制保证了容器之间彼此互不影响。&lt;br/&gt;在操作系统中，包括内核、文件系统、网络、进程号（ Process ID, PID ）、用户号（ UserID, UID 进程间通信（ Inter Process Communication, IPC ）等资源，所有的资源都是应用进程直接共享的 要想实现虚拟化，除了要实现对内存、 CPU 、网络 IO 、硬盘 IO 、存储空间等的限制外，还要实现文件系统、网络、 PID UID IPC 等的相互隔离 前者相对容易实现一些，后者则需要宿主主机系统的深入支持。&lt;br/&gt;随着 Linux 系统对于命名空间功能的逐步完善，现在已经可以实现这些需求，让进程在彼此隔离的命名空间中运行 虽然这些进程仍在共用同 个内核和某些运行时环境(runtime ，例如一些系统命令和系统库），但是彼此是不可见的，并且认为自己是独占系统的&lt;br/&gt;Docker 容器每次启动时候，通过调用 func setNamespaces(daemon *Daemon, s *specs. Spec, c *container.Container) error 方法来完成对各个命名 间的配置&lt;/p&gt;
&lt;h3 id=&quot;进程命名空间&quot;&gt;进程命名空间&lt;/h3&gt;
&lt;p&gt;Linux 通过进程命名 理进程号，对于同 进程（同 task struct ），在不同的命名空间中，看到的进程号不相同 个进程命名 间有一套 自己的进程号管理方法 进程命名空间是一个父子关系的结构，子空间中的进程对于父 间是可见的 fork 出的 个进程，在父命名空间和子命名空间将分别对应不同的进程号 例如，查看 Docker 服务主进程( dockerd ）的进程号是 3393 ，它作为父进程启动了 docker containerd 进程，进程号为 3398,&lt;br/&gt;代码如下所示：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-python&quot;&gt;$ ps - ef lgrep docker 
root 3393 1 0 Jan18 ? 00 43 02 /usr/bin/dockerd - H fd : // -H tcp:// 
127 . 0 . 0 . 1 : 2375 -H unix:///var/run/docker.sock 
root 3398 3393 0 Jan18 ? 00 : 34 : 31 docker containerd config /var/ru口／
docker /conta nerd/conta nerd toml

&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;新建一个 Ubuntu 容器，执行 sleep 命令 此时 docker containerd 进程作为父进程，会为每个容器启动一个 docker containerd shim 程，作为该容器内所有进程的根进程&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-python&quot;&gt;$ docker ru --name test d ubuntu :l6 . 04 sleep 9999
$ ps -ef lgrep docker
root 21535 3398 0 06 : 57 ? 00 : 00 : 00 docker-containerd-shim
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;从宿主机上查看新建容器的进程的父进程 ，正是 docker-containerd shim 进程：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-python&quot;&gt;$ ps -e f lgrep sleep
root 21569 21535 0 06 : 57 ? 00 : 00 : 00 sleep 9999
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;而在容器内的进程空 间中 则把 docker containerd-shim 进程作为 号根进程（类似宿主系统 号根进程 idle), while 进程的进程号则变为 （类似宿主系统中 号初始化进程/sbin/init 容器内只能看到 docker containerd iim 程往下的子进程空间，而无法获知宿主机上的进程信息：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-python&quot;&gt;$ docker exec -it 3a bash c ’ ps ef ’ 
UID PID PPID C STIME TTY TI ME CMD 
root 1 0 0 06 : 57 ? 00 : 00 : 00 sleep 9999
&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;ipc-命名空间&quot;&gt;IPC 命名空间&lt;/h3&gt;
&lt;p&gt;容器中的进程交互还是采用了 Linux 常见的进程间交互方法（ Interprocess Communication, IPC ），包括信号 、消息队列和共 内存等方式PID 命名 间和 IPC 命名空间可以组合起来使用，同 IPC 命名 间内的进程可以彼此可见，允许进行交互；不同 间的进程则无法交互&lt;/p&gt;
&lt;h3 id=&quot;网络命名空间&quot;&gt;网络命名空间&lt;/h3&gt;
&lt;p&gt;有了进程命名空间后，不同命名空间中的进 17-2 宿主机与容器内进程空间的关系 程号可以相互隔离，但是网络端口还是共享本地&lt;br/&gt;系统的端口&lt;br/&gt;通过网络命名空间，可以 现网络隔离。一个网络命名空间为进程提供了一个完全独立的网络协议校的视图 包括网络设备接口 1Pv4 1Pv6 协议械 IP路由 表、 防火墙规则 sockets 等， 这样 容器的网络就能隔离开来&lt;br/&gt;Docker 采用虚拟网络设备（Virtual Network Device, VND ）的方式，将不同命名 间的网络设备连接到一起，默认情况下， Docker 在宿 机上创建多个虚机网桥（如 认的网桥 dockerO)容器中的虚拟网卡通过网桥进行连接。&lt;br/&gt;使用 docker network ls 令可以查看 当前系统中的网桥：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-python&quot;&gt;$ docker network ls
NETWORK ID NAME DRIVER SCOPE 
337120b7e82e lO_ default bridge local 
7b0bc9cdc8a0 bridge bridge local 
8f57993d438b host host local 
6d9342f43ffc none null local
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;使用 brctl 工具（需要 bridge utils 工具包 ，还可以 到连 到网桥 拟网口的信息 默认分配一个网桥上的虚拟网口， 并将 dockerO IP 地址设 默认的网关， 容器发起的网络流 通过宿主机的 iptab es 规则进行转发&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-python&quot;&gt;$ brctl show
&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;挂载命名空间&quot;&gt;挂载命名空间&lt;/h3&gt;
&lt;p&gt;类似于 cbro 挂载 Mount MNT 空间可以将一个进 的根文件系 限制到&lt;br/&gt;个特定的目录下&lt;br/&gt;挂载命名 间允许不同命名空 间的进程 到的 位于宿主机中不同路 ，每&lt;br/&gt;个命名 间中的进程所看到的文件目 彼此是隔离的 例如， 同命名空间中的进程， 都认为自己独占了 个完 的根文件系统（ rootfs 际上，不同命名空间中的文件彼此不受任何影响，同时也无法 响宿主机文件系统中的 他路径&lt;/p&gt;
&lt;h3 id=&quot;uts-命名空间&quot;&gt;UTS 命名空间&lt;/h3&gt;
&lt;p&gt;UTS (UNIX T im e -sh aring System 命名 间允许 容器 有独立的主机 和域 ，从而可以虚拟出一个有独 主机 和网络空间的环境 就跟网 台独 的主机一样&lt;br/&gt;如果没有于动指定主机名称 Docker 器的主机名就是返回的容器 ID 的前 节前缀，否则为指定的用户名：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-python&quot;&gt;$docker run - -name testl -d ubuntu : l6 . 04 /bin/sh -c ”while t rue ; do echo h e llo
worl d ; sl eep l ; done &quot; 
alb7bdc9609ad52c6ca7cd39dl69d55ae32f8523lee22da063la20c94d7aa8db 
$docker [contai ner] inspect -f {{ &quot;. Config . Hostname ” }} testl 
alb7bdc9609a 
$ docker run --hostname test2 --name test2 -d ubuntu: 16 . 04 /bin/sh c ” while 
true ; do echo hello world; sleep l; done ” 
140573f8582584d8e 331368288a96a8838f4a7ed0ff7ee50824f8lbc0459677a 
$docker [contai ner] inspect -f {{ .Config.Hostn ne ” }} test2 
test2
&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;用户命名空间&quot;&gt;用户命名空间&lt;/h3&gt;
&lt;p&gt;每个容器可以有不同的用户和组 id 也就是说 可以在 器内使用特定的内部用户执行程序，而非本地系统上存在的用户&lt;br/&gt;每个容器内部都可以有 高权限的 root 帐号，但跟宿主主机不在一个命名 通过使用隔离的用户命名 可以提高安全 ，避 容器内的进程获取 外的权限；同时通过使用不同用户也可以进一步在容器内控制权限&lt;br/&gt;例如，下面的命令在容器内创建了 test 用户，只有普通权限，无法访问更高权限的资源：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-python&quot;&gt;$ docker run --rm --it ubuntu :l6 . 04 bash 
root@6da1370b22a0: /# cat /pro c/1/enviro
PATH=/usr/local/sbin : /usr/local/bin: /usr/sbin: /usr/bin : /sb工口： lb nHOSTNAME=6dal37
Ob22a0TERM=xtermHOME=/root 
root@6da1370b22a0 : /# useradd ms /bin/bash test 
root@6da13 70b22a0 : /# su test 
test@6da1370b22a0 : /$ cat /proc/1/environ 
cat: /proc/1/environ: Pe ssion denied
&lt;/code&gt;
&lt;/pre&gt;</description>
<pubDate>Fri, 17 Apr 2020 00:32:00 +0000</pubDate>
<dc:creator>刘新元</dc:creator>
<og:description>命名空间 命名空间（ namespace ）是 Linux 内核的一个强大特性，为容器虚拟化的实现带来极大便利，利用这 特性，每个容器都可以拥有自己单独的命名空间，运行在其中的应用都像是在独立的操作系</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/precipitation/p/12717442.html</dc:identifier>
</item>
<item>
<title>来说说Java中String 类的那些事情 - IT女一枚</title>
<link>http://www.cnblogs.com/xiao666/p/12717146.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/xiao666/p/12717146.html</guid>
<description>&lt;blockquote&gt;
&lt;h6 id=&quot;今天正好学校那边的任务不多，我就打算把stirng-的有关知识点都总结在一起了，这样有利于知识的系统性，要不然学多了就会越来越杂，最主要的是总会忘记，记忆的时间太短了，通过这种方式，把它归纳在一起，写一下博客，这样我认为会好一点，也可以帮助有需要的人，一举两得，嘻嘻，废话不多说继续干，奥里给。&quot;&gt;今天正好学校那边的任务不多，我就打算把Stirng 的有关知识点都总结在一起了，这样有利于知识的系统性，要不然学多了就会越来越杂，最主要的是总会忘记，记忆的时间太短了，通过这种方式，把它归纳在一起，写一下博客，这样我认为会好一点，也可以帮助有需要的人，一举两得，嘻嘻，废话不多说继续干，奥里给。&lt;/h6&gt;
&lt;/blockquote&gt;
&lt;p&gt;首先咱们从最开始的源头来说，刚开始接触JAVA的时候，我们学过java的基本的数据类型&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;[ 1 ] 基本类型&lt;/li&gt;
&lt;/ul&gt;&lt;ol&gt;&lt;li&gt;
&lt;p&gt;数值类型&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;boolean&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;&lt;ul&gt;&lt;li&gt;[ 2 ] 引用类型&lt;/li&gt;
&lt;/ul&gt;&lt;pre&gt;
&lt;code&gt;
引用类型--&amp;gt;引用
&lt;/code&gt;
&lt;/pre&gt;
&lt;h6 id=&quot;那么好，我们就先说说引用数据类型，先了解一下，java一个有四种引用类型分别是类类型，接口类型，数组类型，枚举类型&quot;&gt;那么好，我们就先说说引用数据类型，先了解一下，JAVA一个有四种引用类型分别是类类型，接口类型，数组类型，枚举类型&lt;/h6&gt;
&lt;p&gt;1.&lt;strong&gt;String&lt;/strong&gt; 可以通过new和构造方法来创建一个对象，用s来引用它（也就是相当于把asdf这个字符串赋值给s&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;String s = new String(&quot;asdf&quot;);
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;那么什么是引用呢？打个比方：就好比是你的学号，那么对象就是你，那就需要你（对象）来找到的学号，那怎吗可以找到你的学号呢？就需要学号来引用你（对象），那么你就可以知道你的学号是什么了，这个比方就可以解释什么是引用了&lt;/p&gt;
&lt;p&gt;2.String(字符串)可以和数字相互转换&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;[1] 字符串转换成数字（三种）（前提是数字型）&lt;/li&gt;
&lt;/ul&gt;&lt;pre&gt;
&lt;code&gt;String a = &quot;123&quot;;
int num1 = Integer.parselnt(a);
Integer num2 = Integer.valuOf(a);
Integer num3 = new Integer(a);
&lt;/code&gt;
&lt;/pre&gt;
&lt;ul&gt;&lt;li&gt;[2] 数字转换成字符串&lt;/li&gt;
&lt;/ul&gt;&lt;pre&gt;
&lt;code&gt;int a = 10;
String s = Integer.toString(a);
String s1 = String.valueOf(a);
String s2 = &quot; &quot; + a;
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;3.字符串中String类和StringBuffer类（StringBuilder类)&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;[1] String 对象是不可变的，他的内容是不可以变得&lt;/li&gt;
&lt;/ul&gt;&lt;pre&gt;
&lt;code&gt;String s = &quot;JAVA&quot;;
Stystem.out.println(&quot;s= &quot; + s);
S = &quot;Html&quot;;
System.out.println(&quot;s = &quot; + s);
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;输出结果：&lt;/p&gt;
&lt;p&gt;s=JAVA&lt;/p&gt;
&lt;p&gt;s=Html&lt;/p&gt;
&lt;p&gt;新手有的小白一定会好奇，它的值不是改变了吗，但是为什么说它是不可的呢？这个第一天语句创建一个内容为JAVA的String对象,第二个是创建一个内容为Html类的对象 并将其引用赋值给s，赋值后第一个对象&lt;br/&gt;仍然存在但是却不能进行访问了，因为s现在已经指向了一个新的对象，那么原来那个对象就会成为他的垃圾内存，在莫以特定时刻有JAVA虚拟机回收，如果你要想存放的String可以调整大小的话，而不是通过创建新的内存来存放新的对象。&lt;/p&gt;
&lt;p&gt;String s = &quot;JAVA&quot;;,执行之后如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;graph LR
S--&amp;gt;JAVA
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;String s = &quot;Html&quot;;执行之后如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;graph LR
S--&amp;gt;JAVA
&lt;/code&gt;
&lt;/pre&gt;
&lt;pre&gt;
&lt;code&gt;graph LR
S--&amp;gt;Html
&lt;/code&gt;
&lt;/pre&gt;
&lt;h6 id=&quot;这里由于我技术水平的问题图我只能这样画但是其实它是指向下一个html那个的，请大家谅解&quot;&gt;这里由于我技术水平的问题图我只能这样画但是其实它是指向下一个Html那个的，请大家谅解&lt;/h6&gt;
&lt;ul&gt;&lt;li&gt;[2] StringBuffer类和Stringbuilder类&lt;br/&gt;StringButter类/StringBuilder类要比Stirng要灵活，他们可以随意的插入，添加，或者追加新的内容，可以这么说，StringButter类和Sttringbuilder类基本是相同的，可以视为一致&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;修改StringBuilder常用的方法：&lt;br/&gt;appand(char[])//追加一个字符数组到构造器中&lt;/p&gt;
&lt;p&gt;reverse()//翻转构造器中的字符&lt;/p&gt;
&lt;p&gt;setCharAt(o,'a')//将构造器中的索引值换做成字符型&lt;/p&gt;
&lt;h6 id=&quot;我只说了其中的一小部分种的一小部分，也是很常用的，剩下的大家可以查阅api文档来看哒！&quot;&gt;我只说了其中的一小部分种的一小部分，也是很常用的，剩下的大家可以查阅API文档来看哒！&lt;/h6&gt;
&lt;p&gt;4.String类中to String()方法&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;[1] toString()方法在object类中定义的，其返回值是String类型&lt;/li&gt;
&lt;li&gt;[2] 在进行String 类与其他类型的连接操作时，自动调用toString方法，demo如下;&lt;/li&gt;
&lt;/ul&gt;&lt;pre&gt;
&lt;code&gt;Data now = new DateData();
System.out.println(&quot;now= &quot; + now);//相当于下一行代码
System.out.println(&quot;now=&quot;+ now.toString());
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;在阅读javadoc时ToString()&lt;br/&gt;是这样说的 The toString method for class Object return a string consisting of the name of the class of which theobject is an instance, the at-sign character `@', andthe unsigned hexadecimal representation of the hash code of theobject. In other words, this method returns a string equal to thevalue of:&lt;/p&gt;
&lt;p&gt;getClass().getName() + '@' + Integer.toHexString(hashCode())&lt;/p&gt;
&lt;p&gt;它的注释是这么说的，翻译过来大致意思就是：类对象这个方法返回一个字符串，这个字符串是一个实例，@字符和无符号十六进制的表示形式，也就是说此方法返回一个等于值的字符串&lt;br/&gt;因为它是object类已经有的方法m，而所有的类都继承Object，所以&quot;所有对象都有这个方法”，他就是为了方便输出，如果输出的不是String类型的话，系统就会自动调用toString()放法（其实他也就是起到个补充的作用&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;public class A{
    public String toString(){
        return&quot;this is A&quot;;
    }
    public static void main(String[] args){
        A obj = new A();
        System.out.println(obj);
    }
    输出结果是：this is A
    
&lt;/code&gt;
&lt;/pre&gt;
&lt;pre&gt;
&lt;code&gt;public class A{
    public String getString(){
        return&quot;this is A&quot;;
    }
    public static void main(String[] args){
        A obj = new A();
        System.out.println(obj.getString());
    }
    输出结果是：A@279f2327
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;看到好处了吗？就是这个toString()方法只要遇到println等一些输出的方法时，他就会自动调用，不用显示打出来。&lt;/p&gt;
&lt;p&gt;5.String类型&lt;/p&gt;
&lt;p&gt;常见的方法我简单的给你们说道说道，可能只是片面，又没说到的建议大家多多的去查阅API文档，差多了自然就记住了，就好比是背单词似的也是要一点一点地积累的&lt;/p&gt;
&lt;p&gt;length()//返回字符串中的字符数&lt;/p&gt;
&lt;p&gt;charAt(index)//返回字符串ss中指定位置的字符&lt;/p&gt;
&lt;p&gt;tuUpperCase()//返回一个新的字符串，其中所有字母大写&lt;/p&gt;
&lt;p&gt;toLoverCase()返回一个新的字符串，其中所有字母小写&lt;/p&gt;
&lt;p&gt;concat(s1)//将本字符串和s1字符串连接起来返回一个新的字符串&lt;/p&gt;
&lt;p&gt;给你们举个例子具体这些方法是怎么用的，因为总是有很多刚刚学还没入门的小伙伴，不会用，就是理论和实践不能很完全的结合。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;String message = &quot;welcome to JAVA!&quot;;
System.out.println(&quot;The length of &quot; + message + &quot;is&quot;+ message.length());
输出结果：The length of welcome to JAVA! is 16
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;这只是代码中的一小部分，但却也是核心地方。&lt;/p&gt;
&lt;p&gt;6.String类的静态format()方法&lt;br/&gt;它和printf很是相似只不过printf是显示一个格式化字符串，而format()则是返回一个格式化字符串，这个就是二者的区别，这个还是很简单个，也很好理解我还是继续说一个例子吧！加深理解。&lt;/p&gt;
&lt;p&gt;语法一：format(String format,object....args)&lt;br/&gt;其中format为格式化字符串，args为由格式字符串中由格式说明符引用的参数，参数的数目是可变的，也可以为0.&lt;/p&gt;
&lt;h6 id=&quot;转换符-说--明-示--例&quot;&gt;转换符 说 明 示 &lt;strong&gt;&lt;strong&gt;例&lt;/strong&gt;&lt;/strong&gt;&lt;/h6&gt;
&lt;p&gt;%b、%B 格式化为布尔类型 false&lt;/p&gt;
&lt;p&gt;%h、%H 格式化为散列码 A05A5198&lt;/p&gt;
&lt;p&gt;%s、%S 格式化为字符串类型 &quot;abc&quot;&lt;/p&gt;
&lt;p&gt;%c、%C 格式化为字符类型 'w'&lt;/p&gt;
&lt;p&gt;%d 格式化为十进制数 26&lt;/p&gt;
&lt;p&gt;%0 格式化为八进制整数 12&lt;/p&gt;
&lt;p&gt;%x、%X 格式化为十六进制整数 4b 1&lt;/p&gt;
&lt;p&gt;%e 格式化为用计算机科学计数法表示的十进制数&lt;br/&gt;1.700000e+01&lt;/p&gt;
&lt;p&gt;%a 格式化为带有效位数和指数的十六进制浮点值 0X1.C000000000001P4&lt;/p&gt;
&lt;p&gt;%n 结果为特定于平台的行分隔符&lt;/p&gt;
&lt;p&gt;%% 结果为字面值％&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;Sttring str = String.format(&quot;%d&quot;,400/2);
String str2 = String.format(&quot;b&quot;,3&amp;gt;5);
输出结果：
200
false

&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;语法二：format(Loacate l,String format,Object...args)&lt;br/&gt;该方法可以作为常用的日期和时间的格式转换符&lt;/p&gt;
&lt;p&gt;下面这个表是我在书上看到的，所以记录了下来，也同时可以为大家作为参考。&lt;/p&gt;
&lt;h6 id=&quot;表2-常见的日期和时间转换符&quot;&gt;表2 &lt;strong&gt;常见的日期和时间转换符&lt;/strong&gt;&lt;/h6&gt;
&lt;p&gt;转换 说明 示 例&lt;/p&gt;
&lt;p&gt;%te 一个月中的某一天（1〜31） 12&lt;/p&gt;
&lt;p&gt;%tb 指定语言环境的月份简称 Jan （英文）、一月（中文）&lt;/p&gt;
&lt;p&gt;%tB 指定语言环境的月份全称 February&lt;br/&gt;（英文）、二月（中文）&lt;/p&gt;
&lt;p&gt;%tA 指定语言环境的星期几全称 Monday （英文）、星期一（中文）&lt;/p&gt;
&lt;p&gt;%ta 指定语言环境的星期几简称 Mon （英文）、星期一（中文）&lt;/p&gt;
&lt;p&gt;%tc 包括全部日期和时间信息 星期三 十月 25 13:37:22 CST 2008&lt;/p&gt;
&lt;p&gt;%tY 4位年份 2008&lt;/p&gt;
&lt;p&gt;%tj 一年中的第几天（001〜366） 060&lt;/p&gt;
&lt;p&gt;%tm 月份 05&lt;/p&gt;
&lt;p&gt;%td 一个月中的第几天（01〜31） 07&lt;/p&gt;
&lt;p&gt;%ty 两位年份 08&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;public  static void main(String[] args){
    Date date new Date();//定义Data类对象
    Locale dorm = Locale.Us;
    String month = String.format(form,&quot;%tY&quot;,date);//将当前年份初始格式化String data = String.format(form.&quot;%td&quot;,date);//将当前日期s初始化
    System.out.println(&quot;今年是:&quot; + year +)；
    System.out.println(&quot;今天是:&quot; + date + &quot;号&quot;)；
}
运行结果：
今年是：2022年
现在是: April
今天是：17号
&lt;/code&gt;
&lt;/pre&gt;
&lt;h6 id=&quot;又是一个通宵终于把它总结完了，string-的知识点总结完了，说多倒也不多，但是说少他也不少啊，也有一些硬骨头得需要啃一会的对于小白来说&quot;&gt;又是一个通宵终于把它总结完了，String 的知识点总结完了，说多倒也不多，但是说少他也不少啊，也有一些硬骨头得需要啃一会的对于小白来说&lt;/h6&gt;
&lt;h6 id=&quot;打个哈欠，满满的成就感，感觉看着电脑时间久了眼睛都花了-，总结了好久，哈哈哈哈，都是一些干货，觉得好可以，或者对你有帮助，点个赞，鼓励我一下子哦！嘿嘿，希望可以帮助有需要的人，我们可以一起进步！！这个点写完了估计发不到首页了，等到明天早上的吧！明早在发布吧。明天继续加油！奥里给！你们也是哦&quot;&gt;打个哈欠，满满的成就感，感觉看着电脑时间久了眼睛都花了 ，总结了好久，哈哈哈哈，都是一些干货，觉得好可以，或者对你有帮助，点个赞，鼓励我一下子哦！嘿嘿，希望可以帮助有需要的人，我们可以一起进步！！这个点写完了估计发不到首页了，等到明天早上的吧！明早在发布吧。明天继续加油！奥里给！你们也是哦&lt;/h6&gt;
</description>
<pubDate>Fri, 17 Apr 2020 00:22:00 +0000</pubDate>
<dc:creator>IT女一枚</dc:creator>
<og:description>今天正好学校那边的任务不多，我就打算把Stirng 的有关知识点都总结在一起了，这样有利于知识的系统性，要不然学多了就会越来越杂，最主要的是总会忘记，记忆的时间太短了，通过这种方式，把它归纳在一起，写</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/xiao666/p/12717146.html</dc:identifier>
</item>
<item>
<title>Elasticsearch系列---聚合查询原理 - 清茶豆奶</title>
<link>http://www.cnblogs.com/huangying2124/p/12717369.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/huangying2124/p/12717369.html</guid>
<description>&lt;p&gt;介绍聚合查询的内部原理，正排索引是如何建立的和优化的，fielddata的使用，最后简单介绍了聚合分析时如何选用深度优先和广度优先&lt;/p&gt;&lt;div id=&quot;cnblogs_post_body&quot; readability=&quot;261&quot;&gt;
&lt;h3 id=&quot;概要&quot;&gt;概要&lt;/h3&gt;
&lt;p&gt;本篇主要介绍聚合查询的内部原理，正排索引是如何建立的和优化的，fielddata的使用，最后简单介绍了聚合分析时如何选用深度优先和广度优先。&lt;/p&gt;
&lt;h3 id=&quot;正排索引&quot;&gt;正排索引&lt;/h3&gt;
&lt;p&gt;聚合查询的内部原理是什么，Elastichsearch是用什么样的数据结构去执行聚合的？用倒排索引吗？&lt;/p&gt;
&lt;h4 id=&quot;工作原理&quot;&gt;工作原理&lt;/h4&gt;
&lt;p&gt;我们了解到倒排索引对搜索是非常高效的，但是在排序或聚合操作方面，倒排索引就显得力不从心，例如我们举个实际案例，假设我们有两个文档：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;I have a friend who loves smile&lt;/li&gt;
&lt;li&gt;love me, I love you&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;为了建立倒排索引，我们先按最简单的用空格把每个单词分开，可以得到如下结果：&lt;br/&gt;*表示该列文档中有这个词条，为空表示没有该词条&lt;/p&gt;
&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;Term&lt;/th&gt;
&lt;th&gt;doc1&lt;/th&gt;
&lt;th&gt;doc2&lt;/th&gt;
&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;I&lt;/td&gt;
&lt;td&gt;*&lt;/td&gt;
&lt;td&gt;*&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;have&lt;/td&gt;
&lt;td&gt;*&lt;/td&gt;
&lt;td/&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;a&lt;/td&gt;
&lt;td&gt;*&lt;/td&gt;
&lt;td/&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;friend&lt;/td&gt;
&lt;td&gt;*&lt;/td&gt;
&lt;td/&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;who&lt;/td&gt;
&lt;td&gt;*&lt;/td&gt;
&lt;td/&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;loves&lt;/td&gt;
&lt;td&gt;*&lt;/td&gt;
&lt;td/&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;smile&lt;/td&gt;
&lt;td&gt;*&lt;/td&gt;
&lt;td/&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;love&lt;/td&gt;
&lt;td/&gt;
&lt;td&gt;*&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;me&lt;/td&gt;
&lt;td/&gt;
&lt;td&gt;*&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;you&lt;/td&gt;
&lt;td/&gt;
&lt;td&gt;*&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;如果我们要搜索love you，我们只需要查找包含每个词条的文档：&lt;/p&gt;
&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;Term&lt;/th&gt;
&lt;th&gt;doc1&lt;/th&gt;
&lt;th&gt;doc2&lt;/th&gt;
&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;love&lt;/td&gt;
&lt;td/&gt;
&lt;td&gt;*&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;you&lt;/td&gt;
&lt;td/&gt;
&lt;td&gt;*&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;搜索是非常高效的，倒排索引根据词条来排序，我们首先在词条列表中打到love，然后扫描所有的列，可以快速看到doc2包含这个关键词。&lt;/p&gt;
&lt;p&gt;但聚合操作呢？我们需要找到doc2里所有唯一的词条，用倒排索引来完成，代价就非常高了，需要迭代索引的每个词条，看一下有没有doc2，有就把这个词条收录起来，没有就检查下一个词条，直到整个倒排索引全部搜索完成。很慢而且难以扩展，并且 会随着数据量的增加而增加。&lt;/p&gt;
&lt;p&gt;聚合查询肯定不能用倒排索引了，那就用正排索引，建立的数据结构将变成这样：&lt;/p&gt;
&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;Doc&lt;/th&gt;
&lt;th&gt;terms&lt;/th&gt;
&lt;/tr&gt;&lt;/thead&gt;&lt;tbody readability=&quot;4&quot;&gt;&lt;tr readability=&quot;8&quot;&gt;&lt;td&gt;doc1&lt;/td&gt;
&lt;td&gt;I, have, a, friend, who, loves, smile&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;doc2&lt;/td&gt;
&lt;td&gt;love, me, I, you&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;这样的数据结构，我们要搜索doc2包含多少个词条就非常容易了。&lt;/p&gt;
&lt;p&gt;倒排索引+正排索引结合的优势&lt;/p&gt;
&lt;p&gt;如果聚合查询里有带过滤条件或检索条件，先由倒排索引完成搜索，确定文档范围，再由正排索引提取field，最后做聚合计算。&lt;/p&gt;
&lt;p&gt;这样才是最高效的&lt;/p&gt;
&lt;h5 id=&quot;帮助理解两个索引结构&quot;&gt;帮助理解两个索引结构&lt;/h5&gt;
&lt;p&gt;倒排索引，类似JAVA中Map的k-v结构，k是分词后的关键词，v是doc文档编号，检索关键字特别容易，但要找到aggs的value值，必须全部搜索v才能得到，性能比较低。&lt;/p&gt;
&lt;p&gt;正排索引，也类似JAVA中Map的k-v结构，k是doc文档编号，v是doc文档内容，只要有doc编号作参数，提取相应的v即可，搜索范围小得多，性能比较高。&lt;/p&gt;
&lt;h4 id=&quot;底层原理&quot;&gt;底层原理&lt;/h4&gt;
&lt;h5 id=&quot;基本原理&quot;&gt;基本原理&lt;/h5&gt;
&lt;ol&gt;&lt;li&gt;正排索引也是索引时生成(index-time)，倒排索引也是index-time。&lt;/li&gt;
&lt;li&gt;核心写入原理与倒排索引类似，同样基于不变原理设计，也写os cache，磁盘等，os cache要存放所有的doc value，存不下时放磁盘。&lt;/li&gt;
&lt;li&gt;性能问题，jvm内存少用点，os cache搞大一些，如64G内存的机器，jvm设置为16G，os cache内存给个32G左右，os cache够大才能提升正排索引的缓存和查询效率。&lt;/li&gt;
&lt;/ol&gt;&lt;h5 id=&quot;column压缩&quot;&gt;column压缩&lt;/h5&gt;
&lt;p&gt;正排索引本质上是一个序列化的链表，里面的数据类型都是一致的（不一致说明索引建立不规范），压缩时可以大大减少磁盘空间、提高访问速度，如以下几种压缩技巧：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;如果所有的数值各不相同（或缺失），设置一个标记并记录这些值&lt;/li&gt;
&lt;li&gt;如果这些值小于 256，将使用一个简单的编码表&lt;/li&gt;
&lt;li&gt;如果这些值大于 256，检测是否存在一个最大公约数&lt;/li&gt;
&lt;li&gt;如果没有存在最大公约数，从最小的数值开始，统一计算偏移量进行编码&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;例如：&lt;br/&gt;doc1: 550&lt;br/&gt;doc2: 600&lt;br/&gt;doc3: 500&lt;/p&gt;
&lt;p&gt;最大公约数50，压缩后的结果可能是这样：&lt;br/&gt;doc1: 11&lt;br/&gt;doc2: 12&lt;br/&gt;doc3: 10&lt;/p&gt;
&lt;p&gt;同时最大公约数50也会保存起来。&lt;/p&gt;
&lt;h4 id=&quot;禁用正排索引&quot;&gt;禁用正排索引&lt;/h4&gt;
&lt;p&gt;正排索引默认对所有字段启用，除了analyzed text。也就是说所有的数字、地理坐标、日期和不分析(not_analyzed)字符类型都会默认开启。针对某些字段，可以不存正排索引，减少磁盘空间占用（生产不建议使用，毕竟无法预知需求的变化），示例如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;# 对字段sessionId取消正排索引
PUT music
{
  &quot;mappings&quot;: {
    &quot;_doc&quot;: {
      &quot;properties&quot;: {
        &quot;sessionId&quot;: {
          &quot;type&quot;:   &quot;keyword&quot;,
          &quot;doc_values&quot;: false
        }
      }
    }
  }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;同样的，我们对倒排索引也可以取消，让一个字段可以被聚合，但是不能被正常检索，示例如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;PUT music
{
  &quot;mappings&quot;: {
    &quot;_doc&quot;: {
      &quot;properties&quot;: {
        &quot;sessionId&quot;: {
          &quot;type&quot;:   &quot;keyword&quot;,
          &quot;doc_values&quot;: true,
          &quot;index&quot;: false
        }
      }
    }
  }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;fielddata原理&quot;&gt;fielddata原理&lt;/h3&gt;
&lt;p&gt;上一小节我们提到，正排索引对分词的字段是不启用的，如果我们尝试对一个分词的字段进行聚合操作，如music索引的author字段，将得到如下提示：&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Fielddata is disabled on text fields by default. Set fielddata=true on [author] in order to load fielddata in memory by uninverting the inverted index. Note that this can however use significant memory. Alternatively use a keyword field instead.&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;这段提示告诉我们，如果分词的字段要支持聚合查询，必须设置fielddata=true，然后把正排索引的数据加载到内存中，这会消耗大量的内存。&lt;/p&gt;
&lt;p&gt;解决办法：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;设置fielddata=true&lt;/li&gt;
&lt;li&gt;使用author.keyword字段，建立mapping时有内置字段的设置。&lt;/li&gt;
&lt;/ol&gt;&lt;h4 id=&quot;内部原理&quot;&gt;内部原理&lt;/h4&gt;
&lt;p&gt;analyzed字符串的字段，字段分词后占用空间很大，正排索引不能很有效的表示多值字符串，所以正排索引不支持此类字段。&lt;/p&gt;
&lt;p&gt;fielddata结构与正排索引类似，是另外一份数据，构建和管理100%在内存中，并常驻于JVM内存堆，极易引起OOM问题。&lt;/p&gt;
&lt;h5 id=&quot;加载过程&quot;&gt;加载过程&lt;/h5&gt;
&lt;p&gt;fielddata加载到内存的过程是lazy加载的，对一个analzyed field执行聚合时，才会加载，而且是针对该索引下所有的文档进行field-level加载的，而不是匹配查询条件的文档，这对JVM是极大的考验。&lt;/p&gt;
&lt;p&gt;fielddata是query-time创建，动态填充数据，而不是不是index-time创建，&lt;/p&gt;
&lt;h5 id=&quot;内存限制&quot;&gt;内存限制&lt;/h5&gt;
&lt;p&gt;indices.fielddata.cache.size 控制为fielddata分配的堆空间大小。 当你发起一个查询，分析字符串的聚合将会被加载到fielddata，如果这些字符串之前没有被加载过。如果结果中fielddata大小超过了指定大小，其他的值将会被回收从而获得空间(使用LRU算法执行回收)。&lt;/p&gt;
&lt;p&gt;默认无限制，限制内存使用，但是会导致频繁evict和reload，大量IO性能损耗，以及内存碎片和gc，这个参数是一个安全卫士，必须要设置：&lt;/p&gt;
&lt;p&gt;&lt;code&gt;indices.fielddata.cache.size: 20%&lt;/code&gt;&lt;/p&gt;
&lt;h5 id=&quot;监控fielddata内存使用&quot;&gt;监控fielddata内存使用&lt;/h5&gt;
&lt;p&gt;Elasticsearch提供了监控监控fielddata内存使用的命令，我们在上面可以看到内存使用和替换的次数，过高的evictions值（回收替换次数）预示着内存不够用的问题和性能不佳的原因：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;# 按索引使用 indices-stats API
GET /_stats/fielddata?fields=*

# 按节点使用 nodes-stats API
GET /_nodes/stats/indices/fielddata?fields=*

# 按索引节点
GET /_nodes/stats/indices/fielddata?level=indices&amp;amp;fields=*
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;fields=*表示所有的字段，也可以指定具体的字段名称。&lt;/p&gt;
&lt;h5 id=&quot;熔断器&quot;&gt;熔断器&lt;/h5&gt;
&lt;p&gt;indices.fielddata.cache.size的作用范围是当前查询完成后，发现内存不够用了才执行回收过程，如果当前查询的数据比内存设置的fielddata 的总量还大，如果没有做控制，可能就直接OOM了。&lt;/p&gt;
&lt;p&gt;熔断器的功能就是阻止OOM的现象发生，在执行查询时，会预算内存要求，如果超过限制，直接掐断请求，返回查询失败，这样保护Elasticsearch不出现OOM错误。&lt;/p&gt;
&lt;p&gt;常用的配置如下：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;indices.breaker.fielddata.limit：fielddata的内存限制，默认60%&lt;/li&gt;
&lt;li&gt;indices.breaker.request.limit：执行聚合的内存限制，默认40%&lt;/li&gt;
&lt;li&gt;indices.breaker.total.limit：综合上面两个，限制在70%以内&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;最好为熔断器设置一个相对保守点的值。fielddata需要与request断路器共享堆内存、索引缓冲内存和过滤器缓存，并且熔断器是根据总堆内存大小估算查询大小的，而不是实际堆内存的使用情况，如果堆内有太多等待回收的fielddata，也有可能会导致OOM发生。&lt;/p&gt;
&lt;h4 id=&quot;ngram对fielddata的影响&quot;&gt;ngram对fielddata的影响&lt;/h4&gt;
&lt;p&gt;前缀搜索一章节我们介绍了ngram，ngram会生成大量的词条，如果这个字段同时设置fielddata=true的话，那么会消耗大量的内存，这里一定要谨慎。&lt;/p&gt;
&lt;h3 id=&quot;fielddata精细化控制&quot;&gt;fielddata精细化控制&lt;/h3&gt;
&lt;h4 id=&quot;fielddata过滤&quot;&gt;fielddata过滤&lt;/h4&gt;
&lt;p&gt;过滤的主要目的是去掉长尾数据，我们可以加一些限制条件，如下请求：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;PUT /music/_mapping/children
{
  &quot;properties&quot;: {
    &quot;tags&quot;: {
      &quot;type&quot;: &quot;text&quot;,
      &quot;fielddata&quot;: true,
      &quot;fielddata_frequency_filter&quot;: {
        &quot;min&quot;: 0.001,
        &quot;max&quot;: 0.1,
        &quot;min_segment_size&quot;: 500
      }
    }
  }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;fielddata_frequency_filter过滤器会基于以下条件进行过滤：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;出现频率介绍0.1%和10%之间&lt;/li&gt;
&lt;li&gt;忽略文档个数小于500的段文件&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;fidelddata是按段来加载的，所以出现频率是基于某个段计算得来的，如果一个段内只有少量文档，统计词频意义不大，等段合并到大的段当中，超过500个文档这个限制，就会纳入计算。&lt;/p&gt;
&lt;p&gt;fielddata数据对内存的占用是显而易见的，对fielddata过滤长尾是一种权衡。&lt;/p&gt;
&lt;h4 id=&quot;序号标记预加载&quot;&gt;序号标记预加载&lt;/h4&gt;
&lt;p&gt;假设我们的文档用来标记状态有几种字符串：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;SUCCESS&lt;/li&gt;
&lt;li&gt;FAILED&lt;/li&gt;
&lt;li&gt;PENDING&lt;/li&gt;
&lt;li&gt;WAIT_PAY&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;状态这类的字段，系统设计时肯定是可以穷举的，如果我们存储到Elasticsearch中也用的是字符串类型，需要的存储空间就会多一些，如果我们换成1，2，3，4这种Byte类型的，就可以节省很多空间。&lt;/p&gt;
&lt;p&gt;&quot;序号标记&quot;做的就是这种优化，如果文档特别多（PB级别），那节省的空间就非常可观，我们可以对这类可以穷举的字段设置序号标记，如下请求：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;PUT /music/_mapping/children
{
  &quot;properties&quot;: {
    &quot;tags&quot;: {
      &quot;type&quot;: &quot;text&quot;,
      &quot;fielddata&quot;: true,
      &quot;eager_global_ordinals&quot;: true
    }
  }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;h4 id=&quot;深度优先vs广度优先&quot;&gt;深度优先VS广度优先&lt;/h4&gt;
&lt;p&gt;Elasticsearch的聚合查询时，如果数据量较多且涉及多个条件聚合，会产生大量的bucket，并且需要从这些bucket中挑出符合条件的，那该怎么对这些bucket进行挑选是一个值得考虑的问题，挑选方式好，事半功倍，效率非常高，挑选方式不好，可能OOM，我们拿深度优先和广度优先这两个方式来讲解。&lt;/p&gt;
&lt;p&gt;我们举个电影与演员的例子，一部电影由多名演员参与，我们搜索的需求：出演电影最多的10名演员以及他们合作最多的5名演员。&lt;/p&gt;
&lt;p&gt;如果是深度优先，示例图如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://imgkr.cn-bj.ufileos.com/a247ce0e-e4d3-44de-81ca-5d238f91c473.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;这种查询方式需要构建完整的数据，会消耗大量的内存。假设我们每部电影有10位演员（1主9配），有10万部电影，那么第一层的数据就有10万条，第二层为9*10万=90万条，共100万条数据。&lt;/p&gt;
&lt;p&gt;我们对这100万条数据进行排序后，取主角出演次数最多的10个，即10条数据，裁掉99加上与主角合作最多的5名演员，共50条数据。&lt;/p&gt;
&lt;p&gt;构建了100万条数据，最终只取50条，内存是不是有点浪费？&lt;/p&gt;
&lt;p&gt;如果是广度优先，示例图如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://imgkr.cn-bj.ufileos.com/0dad84bd-ac0b-4d5e-b722-100343d0baca.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;这种查询方式先查询电影主角，取前面10条，第一层就只有10条数据，裁掉其他不要的，然后找出跟主角有关联的配角人员，与合作最多的5名，共50条数据。&lt;/p&gt;
&lt;p&gt;聚合查询默认是深度优先，设置广度优先只需要设置collect_mode参数为breadth_first，示例：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;GET /music/children/_search
{
  &quot;size&quot;: 0,
  &quot;aggs&quot;: {
    &quot;lang&quot;: {
      &quot;terms&quot;: {
        &quot;field&quot;: &quot;language&quot;,
        &quot;collect_mode&quot; : &quot;breadth_first&quot; 
      },
      &quot;aggs&quot;: {
        &quot;length_avg&quot;: {
          &quot;avg&quot;: {
            &quot;field&quot;: &quot;length&quot;
          }
        }
      }
    }
  }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;h5 id=&quot;注意&quot;&gt;注意&lt;/h5&gt;
&lt;p&gt;使用深度优先还是广度优先，要考虑实际的情况，广度优先仅适用于每个组的聚合数量远远小于当前总组数的情况，比如上面的例子，我只取10位主角，但每部电影都有一位主角，聚合的10位主角组数远远小于总组数，所以是适用的。&lt;/p&gt;
&lt;p&gt;另外一组按月统计的柱状图数据，总组数固定只有12个月，但每个月下的数据量特别大，广度优先就不适合了。&lt;/p&gt;
&lt;p&gt;所以说，使用哪种方式要看具体的需求。&lt;/p&gt;
&lt;h3 id=&quot;小结&quot;&gt;小结&lt;/h3&gt;
&lt;p&gt;本篇讲解的聚合查询原理，可以根据实际案例做一些演示，加深一下印象，多阅读一下官网文档，实际工作中这块用到的地方还是比较多的，谢谢。&lt;/p&gt;
&lt;p&gt;专注Java高并发、分布式架构，更多技术干货分享与心得，请关注公众号：Java架构社区&lt;br/&gt;可以扫左边二维码添加好友，邀请你加入Java架构社区微信群共同探讨技术&lt;br/&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1834889/202003/1834889-20200303074927076-1724862603.jpg&quot; alt=&quot;Java架构社区&quot;/&gt;&lt;/p&gt;
&lt;/div&gt;</description>
<pubDate>Fri, 17 Apr 2020 00:07:00 +0000</pubDate>
<dc:creator>清茶豆奶</dc:creator>
<og:description>介绍聚合查询的内部原理，正排索引是如何建立的和优化的，fielddata的使用，最后简单介绍了聚合分析时如何选用深度优先和广度优先</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/huangying2124/p/12717369.html</dc:identifier>
</item>
<item>
<title>架构设计基础：单服务.集群.分布式，基本区别和联系 - 知了一笑</title>
<link>http://www.cnblogs.com/cicada-smile/p/12716752.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/cicada-smile/p/12716752.html</guid>
<description>&lt;h2 id=&quot;1、架构简介&quot;&gt;1、架构简介&lt;/h2&gt;
&lt;p&gt;现在的互联网，几乎常见的复杂系统都会使用分布式架构，如果在不清楚概念之前，刚接触分布式架构这个名词会感觉十分的高大上，其实在对比单服务，集群服务之后，你就会发现本质上都是一样的。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;絮叨一句&lt;/code&gt;：所谓Java架构师，基本就是看被单服务，集群，分布式不断暴打的频率，架构师因为被虐频率高，自然做出来的系统架构坑少，新手不能做架构的原因，所以你该懂的。&lt;/p&gt;
&lt;p&gt;言归正传，分布式架构对于Java开发来说基本算是分水岭，能不能从开发层面跳出来，就看你工作个三五年之后，对分布式系统理解到什么程度。单服务应用，基于单服务做集群化部署，这种操作运维可以自行搭建环境，所以基本对能力要求不算高。但是如何设计出弹性、配置化、分布化、高性能、高容错、安全的分布式系统，的确是一件很有挑战的事情。&lt;/p&gt;
&lt;h2 id=&quot;2、集群和分布式&quot;&gt;2、集群和分布式&lt;/h2&gt;
&lt;p&gt;首先需要理清楚单服务，集群，分布式这几种不同架构的区别。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;单服务和集群&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;一张图，你品，你细品：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1691717/202004/1691717-20200416232250220-692236823.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;业务体量小，所有服务和应用部署在一台服务上，节省成本，这是单服务结构。当业务量逐渐增大，把一台服务进行水平扩展，做一个服务群，每台服务称为集群的一个节点，到这就是集群服务。集群服务要面对的一个问题就是：请求分配，自然需要一个调度组件来均衡服务器压力，这也被称为负载均衡。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;code&gt;补刀一句&lt;/code&gt;&lt;/strong&gt;：做到集群模式的应用，在程序员面试的时候已经会被拿来做高格调的自吹自擂了，其实单服务和集群的本质区别就是：在处理请求的时候多了一个分配服务的过程，现在你还觉得跟人吹集群很高端吗？&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;分布式&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;一张图，你品，你细品：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1691717/202004/1691717-20200416232303510-603848356.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;这个概念解释起来就不容易了，单服务到集群，是部署上的改变，在代码层面改动极小，集群模式会加入更多的服务监控，为了快速的判断哪个服务宕机。&lt;/p&gt;
&lt;p&gt;首先要解释一下上图：常见的电商系统架构(部分业务)，订单，仓储，物流。&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;用户在订单服务下单，自然需要校验库存；&lt;/li&gt;
&lt;li&gt;下单成功之后，需要追踪订单物流；&lt;/li&gt;
&lt;li&gt;商家需要仓储服务管理上架商品，发货等；&lt;/li&gt;
&lt;li&gt;如果订单服务出现高并发，可以水平扩展，做订单服务的集群化；&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;这是一个基础的业务场景，特点：多应用服务，多数据库存储，且服务之间有通信行为，在个别服务压力大的情况下可以水平扩展集群化部署。&lt;/p&gt;
&lt;p&gt;分布式结构就是按照业务系统的功能，拆分成独立的子服务，可以独立运行，且服务之间通信和交互。带来的好处也是非常的多，例如：降低业务间的耦合度，方便开发维护，水平扩展，复用性高等等。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;code&gt;补刀一句&lt;/code&gt;&lt;/strong&gt;：不要出现思维上的错觉，认为分布式系统的边界大于集群，如果把一个分布式整体看做一个服务，针对这个分布式服务做集群化部署，逻辑上是说的通的，只是这样违背分布式系统的初衷，比如后台服务，没有那么大的高并发，自然不用浪费资源。&lt;/p&gt;
&lt;h2 id=&quot;3、一句总结&quot;&gt;3、一句总结&lt;/h2&gt;
&lt;p&gt;分布式和集群模式磨刀霍霍的根本原因，都是为了解决两个问题：提高系统吞吐量和高可用性，只是两种模式站在的角度和业务场景不同，例如业务单调的高并发场景，业务复杂但不具备并发的场景，当然也有这两种业务场景同时具备的。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;code&gt;补刀一句&lt;/code&gt;&lt;/strong&gt;：针对系统架构和选型，各大公司也确实没有统一的标准，但是都强调写代码的规范和逻辑，这样做的根本原因就是方便后续的系统架构更改。&lt;/p&gt;

&lt;p&gt;上面聊完了基本概念，现在聊聊分布式系统中的技术体系。这个话题依旧有点飘逸。分布式是一种架构思维和模式，并不一定非要使用特定的框架，现在很火的几个框架，SpringCloud,Dubbo，AliCloud等等，这些的出现都是给架构提供了更多的选择。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;code&gt;补刀一句&lt;/code&gt;&lt;/strong&gt;：架构体系和框架，一定是可以分的开概念，框架更多是方便架构快速落地和实现。&lt;/p&gt;
&lt;h2 id=&quot;1、服务架构&quot;&gt;1、服务架构&lt;/h2&gt;
&lt;p&gt;作为开发人员，分布式系统要处理的问题非常多，但是主流的模块有下面几个：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;网关控制&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;网关主要涉及到请求校验，聚合API，路由配置，鉴权管理，安全，灰度发布等等。常用的Zuul组件。&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;配置中心&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;动态资源配置加载，例如运行时流量管理，环境切换，静态资源管理等。常用Nacos和config组件。&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;服务管理&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;分布式中最难管理的模块，也最容易出错，首先多服务运行情况下，需要保证服务间的交互正常，避免请求在链路的某个服务上积压，出现异常还要及时熔断，进行服务降级，高并发到峰值时，要配置限流策略，还有最难处理的分布式事务。这里也被称为服务容错设计，常用Eureka、Hystrix、Sentinel、Dubbo等组件。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;code&gt;补刀一句&lt;/code&gt;&lt;/strong&gt;：分布式系统中真正的核心内容，即使一个很牛的架构师，搭建的分布式环境也是在业务发展中不断优化的，不会一成不变。&lt;/p&gt;
&lt;h2 id=&quot;2、容器化运维&quot;&gt;2、容器化运维&lt;/h2&gt;
&lt;p&gt;作为运维人员：部署分布式系统的确是一件极其繁杂的事情，这时就应景诞生了容器化运维。&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;部署环境&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;有的服务需要部署公有云(就是常说的几家大公司云服务)，有的要部署私有云（自己公司搭建，只服务自己业务的云服务），混合云就是上述两种环境都需要部署服务。总之，现在不这么说，会显得自己很低调。&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;容器化技术&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;将服务打包部署在Docker容器中，如果需要临时扩展，把Docker容器镜像快速部署到多个服务器上即可，如果对这个概念比较懵，就好比自己电脑里面多个虚拟机，可以基于一个虚拟机镜像文件，快速复制多个。Docker一大特色就是：搭建一次，到处运行。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;code&gt;补刀一句&lt;/code&gt;&lt;/strong&gt;：此处必须要感叹一句，Java一直火那么久是有原因的，后续的很多技术出现都在参考这个基本理念。&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;环境监控&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;分布式系统的应用非常复杂，所以要对监控做的非常到位，这里不仅仅要对服务监控，硬件环境同样重要。快速扩展，定位宕机服务。&lt;/p&gt;

&lt;p&gt;上面一直没有提到这个超大模块，意识必须清楚，任何系统最复杂的逻辑莫过于数据存储，从开发层面看：一个架构的核心价值就是在于数据的管理。&lt;/p&gt;
&lt;h2 id=&quot;1、基础描述&quot;&gt;1、基础描述&lt;/h2&gt;
&lt;p&gt;基于上面分布式的概念，数据库的理解方式也是同样。分布式数据库可以解决单个数据库存储的IO或CPU瓶颈而诞生的。常用的模式如下：&lt;/p&gt;
&lt;p&gt;应用集成一个数据库代理的中间件，把数据基于特定策略路由到不同的数据库表中，取数据的时候在以同样的逻辑查询。很经典的sharding-jdbc组件，分库分表的模式。&lt;/p&gt;
&lt;p&gt;上面关系数据库的分库分表处理，是比较显式且刻意的，在分布式数据库中，天然的支持，且具有良好的水平扩展能力。例如：Hbase、mongodb、Greenplum分布式数仓等等。&lt;/p&gt;
&lt;h2 id=&quot;2、数据库选型&quot;&gt;2、数据库选型&lt;/h2&gt;
&lt;p&gt;分布式系统架构和分布式数据存储相辅相成，不管架构选型还是存储选型，都没有可建议的标准，这里只能用一句很有用的废话来描述：基于自己的技术认知范围，和业务场景综合考量。&lt;/p&gt;

&lt;p&gt;如何架构分布式系统，这说不好，但是如何判断分布式架构是否好，这很好说：服务良好的扩展性，高可用性，例如高并发业务随时扩展，提高系统可用性，处理能力，这是必须具备的基础特性。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1691717/201908/1691717-20190823075428183-1996768914.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
</description>
<pubDate>Thu, 16 Apr 2020 23:52:00 +0000</pubDate>
<dc:creator>知了一笑</dc:creator>
<og:description>一、分布式简介 1、架构简介 现在的互联网，几乎常见的复杂系统都会使用分布式架构，如果在不清楚概念之前，刚接触分布式架构这个名词会感觉十分的高大上，其实在对比单服务，集群服务之后，你就会发现本质上都是</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/cicada-smile/p/12716752.html</dc:identifier>
</item>
<item>
<title>Blazor WebAssembly 3.2.0 Preview 4 如期发布 - 张善友</title>
<link>http://www.cnblogs.com/shanyou/p/12717318.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/shanyou/p/12717318.html</guid>
<description>&lt;p&gt;ASP.NET团队如期3.16在官方博客发布了 Blazor WebAssembly 3.2.0 Preview 4：&lt;a href=&quot;https://devblogs.microsoft.com/aspnet/blazor-webassembly-3-2-0-preview-4-release-now-available/&quot;&gt;https://devblogs.microsoft.com/aspnet/blazor-webassembly-3-2-0-preview-4-release-now-available/&lt;/a&gt; ，同时在twitter上发了一条信息带上了下面这张图，这张图很形象的说明了Blazor Webassembly 正在进行最后的准备发射，按照开发计划，将在下周4.23 发布Blazor WebAssembly 3.2.0 Preview 5， 完成功能特性的开发，接下来就是5月初发布Blazor WebAssembly 3.2.0 RC了，将在5.19 的微软Build大会正式发射升空，进入使用C#进行前端开发旅程。&lt;/p&gt;
&lt;p&gt;&lt;img width=&quot;573&quot; height=&quot;369&quot; src=&quot;https://pbs.twimg.com/card_img/1250271384535592962/AZRVW8H6?format=png&amp;amp;name=240x240&quot;/&gt;&lt;/p&gt;
&lt;p&gt;Blazor WebAssembly 3.2.0 Preview 4新增功能：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;启动期间访问主机环境：在&lt;code&gt;WebAssemblyHostBuilder通过&lt;/code&gt;&lt;code&gt;IWebAssemblyHostEnvironment的&lt;/code&gt;&lt;code&gt;HostEnvironment&lt;/code&gt;属性公开，在应用环境中的启动过程中区分（开发，分期，生产等）的细节。如果该应用程序托管在ASP.NET Core应用程序中，则该环境将反映ASP.NET Core环境，因此ASP.NET Core肯定是最佳开发环境，毕竟是亲儿子，当然也很乐意成为其他环境下的干儿子，不管你是使用Java，PHP，NodeJs还是go，Blazor可以作为前后端分离的前端框架让你使用C#写前端逻辑。&lt;/li&gt;
&lt;li&gt;日志改进：在&lt;code&gt;WebAssemblyHostBuilder&lt;/code&gt;现在公开一个&lt;code&gt;Logging&lt;/code&gt;类型的属性&lt;code&gt;ILoggingBuilder&lt;/code&gt;，可以用于配置日志记录应用程序，类似于你会如何配置&lt;a href=&quot;https://docs.microsoft.com/aspnet/core/fundamentals/logging&quot;&gt;在ASP.NET Core 应用记录&lt;/a&gt;在服务器上，也就是把Microsoft.Extensions.Logging 带给了前端，还剩一个中的配置框架要等到下周发布Preview 5了&lt;/li&gt;
&lt;li&gt;Brotli 预压缩： 当发布Blazor WebAssembly应用程序时，已使用最高级别的Brotli预压缩，以进一步减小应用程序的大小并消除对运行时压缩的需求。ASP.NET Core托管的应用程序已经无缝地利用了这些预压缩的文件。对于独立应用程序，您可以配置主机服务器以将请求重定向到预压缩文件。使用预压缩的文件，已发布的Blazor WebAssembly现在为1.8MB，低于之前预览中的2MB。没有Bootstrap CSS的最小应用程序减小到1.6MB。&lt;/li&gt;
&lt;li&gt;并行加载程序集和运行时：Blazor WebAssembly应用程序现在可以并行加载程序集和运行时，从而节省了应用程序加载时间的宝贵时间。&lt;/li&gt;
&lt;li&gt;简化应用程序的IL链接器配置：Blazor WebAssembly应用程序&lt;a href=&quot;https://docs.microsoft.com/aspnet/core/host-and-deploy/blazor/configure-linker?#control-linking-with-a-configuration-file&quot;&gt;提供.NET IL链接器配置文件&lt;/a&gt;，以自定义链接器的行为&lt;/li&gt;
&lt;li&gt;本地化支持：Blazor WebAssembly应用程序现在支持使用.NET资源文件（.resx）和附属程序集进行本地化。&lt;/li&gt;
&lt;li&gt;智能提示中的获得各种Blazor WebAssembly 的API文档&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;目前Blazor 存在的主要问题就是调试支持，虽然目前对调试的支持有一些进展，但是在Visual Studio和Visual Studio Code中的当前调试经验仍然存在许多限制。我们可以在Mono的Webassembly的开发问题列表里看到大量的都是Debugger支持问题&lt;a href=&quot;https://github.com/mono/mono/milestone/17&quot;&gt;https://github.com/mono/mono/milestone/17&lt;/a&gt;：&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://img2020.cnblogs.com/blog/510/202004/510-20200417072729298-8741050.png&quot;&gt;&lt;img width=&quot;599&quot; height=&quot;386&quot; title=&quot;image&quot; alt=&quot;image&quot; src=&quot;https://img2020.cnblogs.com/blog/510/202004/510-20200417072729956-1586513910.png&quot; border=&quot;0&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;为什么会出现Blazor？&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;现代浏览器都支持WebAssembly，WebAssembly是一种新的编码方式，可以在现代的网络浏览器中运行二进制格式文件，以接近原生的性能运行。Blazor 尝试使用WebAssembly和Mono将.NET带回到浏览器。除了用C#来开发之外，还可以让C#运行在浏览器（使用WebAssembly）上，这样dotnet的众多api我们都可以在浏览器使用了。&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://img2020.cnblogs.com/blog/510/202004/510-20200417072730386-972196954.png&quot;&gt;&lt;img width=&quot;616&quot; height=&quot;445&quot; title=&quot;image&quot; alt=&quot;image&quot; src=&quot;https://img2020.cnblogs.com/blog/510/202004/510-20200417072730906-663649928.png&quot; border=&quot;0&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Blazor文档相对齐全：&lt;a href=&quot;https://docs.microsoft.com/zh-cn/aspnet/core/blazor/get-started&quot;&gt;https://docs.microsoft.com/zh-cn/aspnet/core/blazor/get-started&lt;/a&gt; ，官方团队正在加强这文档，在github 有个issue 在追踪 &lt;a href=&quot;https://github.com/dotnet/aspnetcore/issues/20890&quot;&gt;https://github.com/dotnet/aspnetcore/issues/20890&lt;/a&gt;，欢迎大家参与。&lt;/p&gt;
&lt;p&gt;目前我们在开发一个开源项目 ant-design-blazor，目标是成为Ant Design官方认可的Blazor实现，并丰富Blazor生态。现在刚起步，需要有兴趣的同学一起参与。&lt;/p&gt;
&lt;p&gt;Github：&lt;a href=&quot;https://github.com/ElderJames/ant-design-blazor&quot;&gt;https://github.com/ElderJames/ant-design-blazor&lt;/a&gt;&lt;br/&gt;Demo：&lt;br/&gt;&lt;a href=&quot;https://ant-design-blazor.gitee.io&quot;&gt;https://ant-design-blazor.gitee.io&lt;/a&gt;&lt;br/&gt;开发文档：&lt;br/&gt;&lt;a href=&quot;https://github.com/ElderJames/ant-design-blazor/wiki&quot;&gt;https://github.com/ElderJames/ant-design-blazor/wiki&lt;/a&gt;&lt;br/&gt;Blazor文档：&lt;a href=&quot;https://docs.microsoft.com/zh-cn/aspnet/core/blazor/?view=aspnetcore-3.1&quot;&gt;https://docs.microsoft.com/zh-cn/aspnet/core/blazor/?view=aspnetcore-3.1&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;欢迎任何形式的issue和PR&lt;/p&gt;
</description>
<pubDate>Thu, 16 Apr 2020 23:28:00 +0000</pubDate>
<dc:creator>张善友</dc:creator>
<og:description>ASP.NET团队如期3.16在官方博客发布了 Blazor WebAssembly 3.2.0 Preview 4：https://devblogs.microsoft.com/aspnet/bla</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/shanyou/p/12717318.html</dc:identifier>
</item>
<item>
<title>数据库里账号的密码，需要怎样安全的存放？—— 密码哈希（Password Hash） - 小蒋不素小蒋</title>
<link>http://www.cnblogs.com/xjnotxj/p/12716981.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/xjnotxj/p/12716981.html</guid>
<description>&lt;p&gt;最早在大学的时候，只知道用 MD5 来存用户的账号的密码，但其实这非常不安全，而所用到的哈希函数，深入挖掘，也发现并不简单……&lt;/p&gt;

&lt;hr/&gt;&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;哈希（散列）函数是什么就不赘述了。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&quot;1、不推荐&quot;&gt;1、不推荐&lt;/h3&gt;
&lt;p&gt;RC4, MD4, MD5, SHA-0, SHA-1, DES, 2DES 等&lt;/p&gt;
&lt;h3 id=&quot;2、推荐&quot;&gt;2、推荐&lt;/h3&gt;
&lt;p&gt;SHA-2(SHA-256, SHA-384, SHA-512)、SHA-3、Blake2 等&lt;/p&gt;
&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;美国国家标准和技术协会（NIST）宣布，2010 年后开始逐步取消 SHA-1 作为安全哈希算法的资格，取而代之的是其更强大的变异算法：SHA-224、SHA-256、SHA-384 和 SHA-512。无论是否遵循 NIST 的标准，至少使用 SHA-256 算法加密密码总是好的。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;hr/&gt;&lt;p&gt;就像攻与矛的互相增强，哈希函数哪怕用到 SHA-3 以上，都还是有被轻易破解的风险。于是我们有其他额外的办法来解决这个问题。&lt;/p&gt;
&lt;h3 id=&quot;1、加盐（salt）&quot;&gt;1、加盐（salt）&lt;/h3&gt;
&lt;p&gt;加盐就是对目标字段哈希前，拼接上另一个字段（salt）。&lt;/p&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;注：盐值加到字段之前较为普遍。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;加盐对防彩虹表很有效。&lt;/p&gt;
&lt;p&gt;注意点：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;盐不能太短&lt;/li&gt;
&lt;li&gt;盐不能重复使用（否则一破解，所有的都遭殃）&lt;/li&gt;
&lt;li&gt;盐随机变化（例如，虽用户名不重复，但用户名不能拿来当盐）&lt;/li&gt;
&lt;/ul&gt;&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;盐的本质是将&lt;code&gt;无差别攻击&lt;/code&gt;转化为&lt;code&gt;针对性攻击&lt;/code&gt;。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&quot;11、【拓展】针对-salt-的另一种做法--hmac&quot;&gt;1.1、【拓展】针对 salt 的另一种做法 —— HMAC&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;HMAC&lt;/code&gt;（Keyed-Hashing for Message Authentication）其实也是一种特殊的加盐，只是这个 salt 用更安全的&lt;strong&gt;密钥&lt;/strong&gt;代替了。&lt;/p&gt;
&lt;p&gt;具体介绍可以看我之前一篇：&lt;a href=&quot;https://www.cnblogs.com/xjnotxj/p/11934756.html&quot;&gt;《破解另一家网站的反爬机制 &amp;amp; HMAC 算法》&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&quot;2、慢哈希&quot;&gt;2、慢哈希&lt;/h3&gt;
&lt;p&gt;高端的显卡（GPU）和定制的硬件可以每秒进行数十亿次哈希计算，因此这类攻击依然可以很高效。为了降低攻击者的效率，我们可以使用慢哈希，即迭代进行&lt;strong&gt;很多次哈希运算&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;那么迭代&lt;strong&gt;多少次&lt;/strong&gt;比较安全呢？来自 NIST 官方的建议：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;2000 年 9 月，建议迭代一千次&lt;/li&gt;
&lt;li&gt;2015 年 - 2018年，建议迭代一万次&lt;/li&gt;
&lt;li&gt;2017 年 6 月，建议迭代&lt;strong&gt;十万次&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr/&gt;&lt;p&gt;&lt;code&gt;密码哈希函数（Password Hash）&lt;/code&gt;可以用来应对普通哈希容易被破解的问题（也用到了上面所提到的两个策略）。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;下面列举的顺序是按照时间顺序，安全程度和推荐指数也逐级递增。&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&quot;1、pbkdf2&quot;&gt;1、PBKDF2&lt;/h3&gt;
&lt;p&gt;比较老，很少有人用了，略。&lt;/p&gt;
&lt;h3 id=&quot;2、bcrypt&quot;&gt;2、Bcrypt&lt;/h3&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;这是我司目前用的。（不过有过时的隐患，建议换掉）&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h5 id=&quot;（1）介绍&quot;&gt;（1）介绍&lt;/h5&gt;
&lt;p&gt;bcrypt 是由 Niels Provos 和 DavidMazières 基于 Blowfish 密码设计的密码哈希函数，于 1999 年在 USENIX 上提出。&lt;/p&gt;
&lt;p&gt;bcrypt 函数是 OpenBSD 和其他系统（包括某些 Linux 发行版，例如 SUSE Linux）的默认密码哈希算法。&lt;/p&gt;
&lt;h5 id=&quot;（2）使用（nodejs）&quot;&gt;（2）使用（Node.js）&lt;/h5&gt;
&lt;p&gt;安装：&lt;code&gt;npm i bcryptjs&lt;/code&gt;&lt;/p&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;&lt;code&gt;bcryptjs&lt;/code&gt; 跟 C++ 的 bcrypt 兼容，但因为是&lt;strong&gt;纯 JavaScript 编写&lt;/strong&gt;的，因此速度较慢（约 30％）。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;用法：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;Sync 方法（Async 方法略）：

const bcryptjs = require('bcryptjs');

// 1、生成 安全因子
const salt = bcrypt.genSaltSync(10);
// 2、执行 哈希函数
const password = bcryptjs.hashSync(plainPassword, bcryptjs.genSaltSync(salt));

// 另一种方法：快速执行
const SALT_FACTOR = 10;
const password = bcryptjs.hashSync(plainPassword, bcryptjs.genSaltSync(SALT_FACTOR));

// 3、比较是否相等
bcryptjs.compareSync(plainPassword, password);
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;注：代码里出现的&lt;code&gt;安全因子&lt;/code&gt;，值的大小决定了哈希函数会有多慢。（即慢哈希）&lt;/p&gt;
&lt;h3 id=&quot;3、scrypt&quot;&gt;3、Scrypt&lt;/h3&gt;
&lt;p&gt;没用过，略。&lt;/p&gt;
&lt;h3 id=&quot;4、argon2&quot;&gt;4、Argon2&lt;/h3&gt;
&lt;h5 id=&quot;（1）介绍-2&quot;&gt;（1）介绍&lt;/h5&gt;
&lt;p&gt;2013 年 NIST（美国国家标准与技术研究院）邀请了一些密码学家一起，举办了&lt;code&gt;密码哈希竞赛 PHC（Password Hashing Competition）&lt;/code&gt;。Argon2 在 2015 年 7 月赢得了冠军。&lt;/p&gt;
&lt;p&gt;大赛列出了参赛算法可能面临的攻击手段：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;哈希算法破解（原值还原、哈希碰撞等）；&lt;/li&gt;
&lt;li&gt;查询表/彩虹表攻击；&lt;/li&gt;
&lt;li&gt;CPU 优化攻击；&lt;/li&gt;
&lt;li&gt;GPU、FPGA、ASIC 等专用硬件攻击；&lt;/li&gt;
&lt;li&gt;旁路攻击；&lt;/li&gt;
&lt;/ul&gt;&lt;h5 id=&quot;（2）使用（nodejs）-2&quot;&gt;（2）使用（Node.js）&lt;/h5&gt;
&lt;p&gt;1、准备&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;You can skip this section if the prebuilt binaries work for you.

You MUST have a node-gyp global install before proceeding with install, along with GCC &amp;gt;= 5 / Clang &amp;gt;= 3.3. On Windows, you must compile under Visual Studio 2015 or newer.

node-argon2 works only and is tested against Node &amp;gt;=10.0.0.

--- 

OSX
To install GCC &amp;gt;= 5 on OSX, use homebrew:

$ brew install gcc
Once you've got GCC installed and ready to run, you then need to install node-gyp, you must do this globally:

$ npm install -g node-gyp
Finally, once node-gyp is installed and ready to go, you can install this library, specifying the GCC or Clang binary to use:

$ CXX=g++-6 npm install argon2
NOTE: If your GCC or Clang binary is named something different than g++-6, you'll need to specify that in the command.
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;2、安装&lt;/p&gt;
&lt;p&gt;&lt;code&gt;npm i argon2&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;3、使用&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;const argon2 = require('argon2');

(async () =&amp;gt; {
    try {
        // const hash = await argon2.hash(&quot;password&quot;);
        // 更多选项（以下都是默认值）
        const hash = await argon2.hash(&quot;password&quot;, {
            type: argon2.argon2i,
            hashLength: 32, // 哈希函数输出的字节长度(请注意，生成的哈希是使用Base64编码的，因此长度将增加约1/3)
            timeCost : 3, // 时间成本是哈希函数使用的通过次数（迭代次数）
            memoryCost: 2 ** 16, // 默认 4096（单位 KB，即 4MB）
            parallelism :1, //用于计算哈希值的线程数量。每个线程都有一个具有memoryCost大小的内存池
        })
        console.log(&quot;hash&quot;, hash)
        const is = await argon2.verify(hash, &quot;password&quot;)
        console.log(&quot;is&quot;, is) // true
    } catch (err) {
        console.error(&quot;err&quot;, err)
    }
})()
&lt;/code&gt;
&lt;/pre&gt;
&lt;h5 id=&quot;（3）参数&quot;&gt;（3）参数&lt;/h5&gt;
&lt;p&gt;1、type：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;code&gt;argon2d&lt;/code&gt; 更快且对GPU攻击具有高度抵抗力，这对于加密货币很有用&lt;/li&gt;
&lt;li&gt;&lt;code&gt;argon2i&lt;/code&gt; 速度较慢且可以抵御权衡攻击，因此首选用于密码哈希和密钥派生&lt;/li&gt;
&lt;li&gt;&lt;code&gt;argon2id&lt;/code&gt; 是上述内容的混合组合，可以抵抗GPU和权衡攻击&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;因为我们是用于密码的 hash，用默认的 argon2i 即可。&lt;/p&gt;
&lt;p&gt;2、（慢）哈希相关参数&lt;/p&gt;
&lt;p&gt;① &lt;code&gt;memoryCost&lt;/code&gt; 内存开销，它定义了内存的使用情况&lt;/p&gt;
&lt;p&gt;好的起点是 0.75 *（RAM / number_of_users) 起步。&lt;/p&gt;
&lt;p&gt;② &lt;code&gt;parallelism&lt;/code&gt; 并行程度，它定义了线程的数量&lt;/p&gt;
&lt;p&gt;最佳起点是内核数。&lt;/p&gt;
&lt;p&gt;③ &lt;code&gt;timeCost&lt;/code&gt; 时间开销，它定义了执行的时间&lt;/p&gt;
&lt;p&gt;建议在系统上运行它，并确定与内存和处理器使用时间限制相匹配的最大参数。&lt;/p&gt;
&lt;hr/&gt;&lt;p&gt;如前所述，本质是&lt;strong&gt;在安全性和可用性之间取得平衡&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;3、其他参数&lt;/p&gt;
&lt;p&gt;salt：默认值是未设置，将生成加密安全的随机盐。&lt;br/&gt;saltLength：默认16。&lt;/p&gt;
&lt;p&gt;version：您不应更改此设置，因为最新版本更强大。&lt;/p&gt;
&lt;h3 id=&quot;5、密码哈希是如何解决普通哈希容易被破解的问题&quot;&gt;5、密码哈希是如何解决普通哈希容易被破解的问题&lt;/h3&gt;
&lt;p&gt;上面介绍了 &lt;em&gt;二、应对普通哈希容易被破解的策略&lt;/em&gt; ，我们可以看看密码哈希是如何运用并符合这些策略的。&lt;/p&gt;
&lt;h5 id=&quot;（1）针对-salt&quot;&gt;（1）针对 salt&lt;/h5&gt;
&lt;p&gt;密码哈希使用 &lt;code&gt;CSPRNG（Cryptographically Secure Pseudo-Random Number Generator）密码学安全伪随机数生成器&lt;/code&gt;生成盐。&lt;/p&gt;
&lt;p&gt;CSPRNG 是&lt;code&gt;加密安全（Cryptographically Secure）&lt;/code&gt;的，（加密安全的意思即）意味着用它产生的随机数&lt;strong&gt;更加随机&lt;/strong&gt;，且不可预测。&lt;/p&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;普通的计算机随机数算法并不是很随机。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;注：&lt;strong&gt;盐值本身就在存在于哈希后的字符串中（其实还可能包括版本、慢哈希迭代次数等），当调用跟明文比对的方法时，模块内部会提取出盐值进行验证。&lt;/strong&gt;&lt;/p&gt;
&lt;h5 id=&quot;（2）针对-慢哈希&quot;&gt;（2）针对 慢哈希&lt;/h5&gt;
&lt;p&gt;Bcryoy 的&lt;strong&gt;安全因子&lt;/strong&gt;和 Argon2的 &lt;strong&gt;timeCost&lt;/strong&gt; 参数，都是针对慢哈希的配置。&lt;/p&gt;
&lt;h3 id=&quot;6、结论&quot;&gt;6、结论&lt;/h3&gt;
&lt;p&gt;我司使用的 Bcrypt 其实在今年（2020年），已经不安全了，&lt;strong&gt;推荐至少使用 Scrypt，有条件上 Argon2&lt;/strong&gt;。&lt;/p&gt;

&lt;hr/&gt;&lt;p&gt;问1：我用我自己实现哈希算法，不用公开现成的，越古怪越好，坏人不就猜不到了吗？&lt;/p&gt;
&lt;p&gt;答：不建议。&lt;/p&gt;
&lt;p&gt;首先介绍下密码学上的&lt;code&gt;柯克霍夫原则&lt;/code&gt;（Kerckhoffs's principle，也称为柯克霍夫假说、公理、或定律），由奥古斯特·柯克霍夫在 19 世纪提出：&lt;strong&gt;即使密码系统的任何细节已为人悉知，只要密匙（key，又称密钥或秘钥）未泄漏，它也应是安全的。&lt;/strong&gt;信息论的发明者克劳德·香农则改成说：“敌人了解系统”，这样的说法则称为&lt;code&gt;香农箴言&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;基于这个原则：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;1、你自己实现的再古怪，毕竟你不是密码专家，很难确保不被坏人破解（可能自己实现后看似复杂，实际更容易破解了）。&lt;/li&gt;
&lt;li&gt;2、如果自己包含哈希算法的代码泄露，它很脆弱，难保不会被坏人破解。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;问2：既然现在都是 https，前端传给后端的明文密码，就懒得加哈希了，可以吗？&lt;/p&gt;
&lt;p&gt;还是建议前端也进行哈希（虽然前端的哈希算法容易暴露）。不要漏掉任何一个环节。&lt;/p&gt;

&lt;hr/&gt;&lt;p&gt;Dropbox 公司曾公开分享过自己对用户账号的密码加密的策略，使用了&lt;strong&gt;三层加密&lt;/strong&gt;：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/896608/202004/896608-20200416141959818-873499930.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;h3 id=&quot;1、password&quot;&gt;1、password&lt;/h3&gt;
&lt;p&gt;即明文密码。&lt;/p&gt;
&lt;h3 id=&quot;2、sha512&quot;&gt;2、SHA512&lt;/h3&gt;
&lt;p&gt;在 bcrypt 前做 SHA512，是因为有些 bcrypt 实现会把散列值长度截至 72 字节，从而降低了密码的熵值，而有的则允许变长密码，这样容易受到 DoS 攻击。使用 SHA512 散列可以得到固定长度的 512 字节散列值，避免了上述的两个问题。&lt;/p&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;&lt;em&gt;”而有的则允许变长密码，这样容易受到 DoS 攻击“&lt;/em&gt;，这句话我不是很理解，待写。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&quot;3、bcrypt&quot;&gt;3、bcrypt&lt;/h3&gt;
&lt;p&gt;上面说过，不赘述了。&lt;/p&gt;
&lt;h3 id=&quot;4、aes256&quot;&gt;4、AES256&lt;/h3&gt;
&lt;p&gt;AES256 会用到&lt;strong&gt;密钥&lt;/strong&gt;，俗称&lt;strong&gt;胡椒粉（pepper）&lt;/strong&gt;。密钥需要被&lt;strong&gt;单独存储&lt;/strong&gt;，最好存储在外部系统：如物理上隔离的服务端、甚至特殊的硬件设备（如 YubiHSM） 。&lt;/p&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;这里的 AES256 也可以用 HMAC 代替。不过前者安全性更好些。&lt;/p&gt;
&lt;/blockquote&gt;
</description>
<pubDate>Thu, 16 Apr 2020 16:16:00 +0000</pubDate>
<dc:creator>小蒋不素小蒋</dc:creator>
<og:description>最早在大学的时候，只知道用 MD5 来存用户的账号的密码，但其实这非常不安全，而所用到的哈希函数，深入挖掘，也发现并不简单…… 一、普通的 Hash 函数 哈希（散列）函数是什么就不赘述了。 1、不推</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/xjnotxj/p/12716981.html</dc:identifier>
</item>
<item>
<title>十九种Elasticsearch字符串搜索方式终极介绍 - 佛西先森</title>
<link>http://www.cnblogs.com/sunshuyi/p/12716828.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/sunshuyi/p/12716828.html</guid>
<description>&lt;p&gt;刚开始接触Elasticsearch的时候被Elasticsearch的搜索功能搞得晕头转向，每次想在Kibana里面查询某个字段的时候，查出来的结果经常不是自己想要的，然而又不知道问题出在了哪里。出现这个问题归根结底是因为对于Elasticsearch的底层索引原理以及各个查询搜索方式的不了解，在Elasticsearch中仅仅字符串相关的查询就有19个之多，如果不弄清楚查询语句的工作方式，应用可能就不会按照我们预想的方式运作。这篇文章就详细介绍了Elasticsearch的19种搜索方式及其原理，老板再也不用担心我用错搜索语句啦！&lt;/p&gt;&lt;div id=&quot;cnblogs_post_body&quot; readability=&quot;489.99219988857&quot;&gt;
&lt;h2 id=&quot;前言&quot;&gt;前言&lt;/h2&gt;
&lt;p&gt;刚开始接触Elasticsearch的时候被Elasticsearch的搜索功能搞得晕头转向，每次想在Kibana里面查询某个字段的时候，查出来的结果经常不是自己想要的，然而又不知道问题出在了哪里。出现这个问题归根结底是因为对于Elasticsearch的底层索引原理以及各个查询搜索方式的不了解，在Elasticsearch中仅仅字符串相关的查询就有19个之多，如果不弄清楚查询语句的工作方式，应用可能就不会按照我们预想的方式运作。这篇文章就详细介绍了Elasticsearch的19种搜索方式及其原理，老板再也不用担心我用错搜索语句啦！&lt;/p&gt;
&lt;h2 id=&quot;简介&quot;&gt;简介&lt;/h2&gt;
&lt;p&gt;Elasticsearch为所有类型的数据提供实时搜索和分析，不管数据是结构化文本还是非结构化文本、数字数据或地理空间数据，都能保证在支持快速搜索的前提下对数据进行高效的存储和索引。用户不仅可以进行简单的数据检索，还可以聚合信息来发现数据中的趋势和模式。&lt;/p&gt;
&lt;p&gt;搜索是Elasticsearch系统中最重要的一个功能，它支持结构化查询、全文查询以及结合二者的复杂查询。结构化查询有点像SQL查询，可以对特定的字段进行筛选，然后按照特定的字段进行排序得到结果。全文查询会根据查询字符串寻找相关的文档，并且按照相关性排序。&lt;/p&gt;
&lt;p&gt;Elasticsearch内包含很多种查询类型，下面介绍是其中最重要的19种。如果你的app想要添加一个搜索框，为用户提供搜索操作，并且数据量很大用MySQL会造成慢查询想改用Elasticsearch，那么我相信这篇文章会给你带来很大的帮助。&lt;/p&gt;
&lt;h2 id=&quot;query和filter区别&quot;&gt;query和filter区别&lt;/h2&gt;
&lt;p&gt;在正式进入到搜索部分之前，我们需要区分&lt;strong&gt;query&lt;/strong&gt;（查询）和&lt;strong&gt;filter&lt;/strong&gt;（过滤）的区别。&lt;/p&gt;
&lt;p&gt;在进行&lt;strong&gt;query&lt;/strong&gt;的时候，除了完成匹配的过程，我们实际上在问“&lt;em&gt;这个结果到底有多匹配我们的搜索关键词&lt;/em&gt;”。在所有的返回结果的后面都会有一个&lt;code&gt;_score&lt;/code&gt;字段表示这个结果的匹配程度，也就是&lt;strong&gt;相关性&lt;/strong&gt;。相关性越高的结果就越排在前面，相关性越低就越靠后。当两个文档的相关性相同的时候，会根据lucene内部的&lt;code&gt;doc_id&lt;/code&gt;字段来排序，这个字段对于用户是不可见的也不能控制。&lt;/p&gt;
&lt;p&gt;而在进行&lt;strong&gt;filter&lt;/strong&gt;的时候，仅仅是在问“&lt;em&gt;这个文档符不符合要求&lt;/em&gt;”，这仅仅是一个过滤的操作判断文档是否满足我们的筛选要求，不会计算任何的相关性。比如&lt;code&gt;timestamp&lt;/code&gt;的范围是否在2019和2020之间，&lt;code&gt;status&lt;/code&gt;状态是否是1等等。&lt;/p&gt;
&lt;p&gt;在一个查询语句里面可以同时存在&lt;code&gt;query&lt;/code&gt;和&lt;code&gt;filter&lt;/code&gt;，只不过只有&lt;code&gt;query&lt;/code&gt;的查询字段会进行相关性&lt;code&gt;_score&lt;/code&gt;的计算，而&lt;code&gt;filter&lt;/code&gt;仅仅用来筛选。比如在下面的查询语句里面，只有&lt;code&gt;title&lt;/code&gt;字段会进行相关性的计算，而下面的&lt;code&gt;status&lt;/code&gt;只是为了筛选并不会计算相关性。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-sh&quot;&gt;GET /_search
{
  &quot;query&quot;: {
    &quot;bool&quot;: {
      &quot;must&quot;: [
        {&quot;match&quot;: {&quot;title&quot;: &quot;Search&quot;}}
      ],
      &quot;filter&quot;: [
        {&quot;term&quot;: {&quot;state&quot;: 1}}
      ]
    }
  }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;对于在实际应用中应该用&lt;code&gt;query&lt;/code&gt;还是用&lt;code&gt;filter&lt;/code&gt;需要根据实际的业务场景来看。如果你的产品的搜索只是需要筛选得到最后的搜索结果并不需要Elasticsearch的相关性排序（你可能自定义了其他的排序规则），那么使用&lt;code&gt;filter&lt;/code&gt;就完全能够满足要求并且能够有更好的性能（&lt;code&gt;filter&lt;/code&gt;不需要计算相关性而且会缓存结果）；如果需要考虑文档和搜索词的相关性，那么使用&lt;code&gt;query&lt;/code&gt;就是最好的选择。&lt;/p&gt;
&lt;h2 id=&quot;相关性&quot;&gt;相关性&lt;/h2&gt;
&lt;p&gt;上面讲到了在使用&lt;code&gt;query&lt;/code&gt;查询的时候会计算相关性并且进行排序，很多人都会好奇相关性是怎么计算的？&lt;/p&gt;
&lt;p&gt;相关性的计算是比较复杂的，详细的文档可以看这两篇博客——&lt;a href=&quot;https://www.elastic.co/guide/cn/elasticsearch/guide/current/relevance-intro.html#relevance-intro&quot;&gt;什么是相关性&lt;/a&gt;和&lt;a href=&quot;https://blog.csdn.net/paditang/article/details/79098830&quot;&gt;ElasticSearch 使用教程之_score(评分)介绍&lt;/a&gt;，我这里只是做一个简单的介绍。&lt;/p&gt;
&lt;p&gt;Elasticsearch的相似度计算主要是利用了全文检索领域的计算标准——&lt;strong&gt;TF/IDF&lt;/strong&gt;（Term Frequency/Inverted Document Frequency）也就是&lt;strong&gt;检索词频率&lt;/strong&gt;和&lt;strong&gt;反向文档频率&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;&lt;strong&gt;TF&lt;/strong&gt;（检索词频率）：检索词在这个字段里面出现的频率越高，相关性越高。比如搜索词出现5次肯定比出现1次的文档相关性更高。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;IDF&lt;/strong&gt;（反向文档频率）：包含检索词的文档的频率越高，这个检索词的相关性比重越低。如果一个检索词在所有的文档里面都出现了，比如中文的&lt;code&gt;的&lt;/code&gt;，那么这个检索词肯定就不重要，相对应的根据这个检索词匹配的文档的相关性权重应该下降。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;字段长度&lt;/strong&gt;：注意这个字段是文档的里面被搜索的字段，不是检索词。如果这个字段的长度越长，相关性就越低。这个主要是因为这个检索词在字段内的重要性降低了，文档就相对来说不那么匹配了。&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;在复合查询里面，比如&lt;code&gt;bool&lt;/code&gt;查询，每个子查询计算出来的评分会根据特定的公式合并到综合评分里面，最后根据这个综合评分来排序。当我们想要修改不同的查询语句的在综合评分里面的比重的时候，可以在查询字段里面添加&lt;code&gt;boost&lt;/code&gt;参数，这个值是相对于&lt;code&gt;1&lt;/code&gt;来说的。如果大于&lt;code&gt;1&lt;/code&gt;则这个查询参数的权重会提高；如果小于&lt;code&gt;1&lt;/code&gt;，权重就下降。&lt;/p&gt;
&lt;p&gt;这个评分系统一般是系统默认的，我们可以根据需要定制化我们自己的相关性计算方法，比如通过脚本自定义评分。&lt;/p&gt;
&lt;h2 id=&quot;分析器&quot;&gt;分析器&lt;/h2&gt;
&lt;p&gt;分析器是针对&lt;code&gt;text&lt;/code&gt;字段进行文本分析的工具。文本分析是把非结构化的数据（比如产品描述或者邮件内容）转化成结构化的格式从而提高搜索效率的过程，通常在搜索引擎里面应用的比较多。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;text&lt;/code&gt;格式的数据和&lt;code&gt;keyword&lt;/code&gt;格式的数据在存储和索引的时候差别比较大。&lt;code&gt;keyword&lt;/code&gt;会直接被当成整个字符串保存在文档里面，而&lt;code&gt;text&lt;/code&gt;格式数据，需要经过分析器解析之后，转化成结构化的文档再保存起来。比如对于&lt;code&gt;the quick fox&lt;/code&gt;字符串，如果使用&lt;code&gt;keyword&lt;/code&gt;类型，保存直接就是&lt;code&gt;the quick fox&lt;/code&gt;，使用&lt;code&gt;the quick fox&lt;/code&gt;作为关键词可以直接匹配，但是使用&lt;code&gt;the&lt;/code&gt;或者&lt;code&gt;quick&lt;/code&gt;就不能匹配；但是如果使用&lt;code&gt;text&lt;/code&gt;保存，那么分析器会把这句话解析成&lt;code&gt;the&lt;/code&gt;、&lt;code&gt;quick&lt;/code&gt;、&lt;code&gt;fox&lt;/code&gt;三个token进行保存，使用&lt;code&gt;the quick fox&lt;/code&gt;就无法匹配，但是单独用&lt;code&gt;the&lt;/code&gt;、&lt;code&gt;quick&lt;/code&gt;、&lt;code&gt;fox&lt;/code&gt;三个字符串就可以匹配。所以对于&lt;code&gt;text&lt;/code&gt;类型的数据的搜索需要格外注意，如果你的搜索词得不到想要的结果，很有可能是你的搜索语句有问题。&lt;/p&gt;
&lt;p&gt;分析器的工作过程大概分成两步：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;&lt;strong&gt;分词&lt;/strong&gt;（Tokenization）：根据&lt;strong&gt;停止词&lt;/strong&gt;把文本分割成很多的小的token，比如&lt;code&gt;the quick fox&lt;/code&gt;会被分成&lt;code&gt;the&lt;/code&gt;、&lt;code&gt;quick&lt;/code&gt;、&lt;code&gt;fox&lt;/code&gt;，其中的停止词就是空格，还有很多其他的停止词比如&lt;code&gt;&amp;amp;&lt;/code&gt;或者&lt;code&gt;#&lt;/code&gt;，大多数的标点符号都是停止词&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;归一化&lt;/strong&gt;（Normalization）：把分隔的token变成统一的形式方便匹配，比如下面几种
&lt;ul&gt;&lt;li&gt;把单词变成小写，&lt;code&gt;Quick&lt;/code&gt;会变成&lt;code&gt;quick&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;提取词干，&lt;code&gt;foxes&lt;/code&gt;变成&lt;code&gt;fox&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;合并同义词，&lt;code&gt;jump&lt;/code&gt;和&lt;code&gt;leap&lt;/code&gt;是同义词，会被统一索引成&lt;code&gt;jump&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;Elasticsearch自带了一个分析器，是系统默认的标准分析器，使用&lt;a href=&quot;http://unicode.org/reports/tr29/&quot;&gt;标准分词器&lt;/a&gt;，大多数情况下都能够有不错的分析效果。用户也可以定义自己的分析器，用于满足不同的业务需求。&lt;/p&gt;
&lt;p&gt;想要知道某个解析器的分析结果，可以直接在ES里面进行分析，执行下面的语句就行了：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-sh&quot;&gt;POST /_analyze
{
  &quot;analyzer&quot;: &quot;standard&quot;,
  &quot;text&quot;: &quot;1 Fire's foxes&quot;
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;返回的结果是：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-sh&quot;&gt;{
  &quot;tokens&quot; : [
    {
      &quot;token&quot; : &quot;1&quot;,
      &quot;start_offset&quot; : 0,
      &quot;end_offset&quot; : 1,
      &quot;type&quot; : &quot;&amp;lt;NUM&amp;gt;&quot;,
      &quot;position&quot; : 0
    },
    {
      &quot;token&quot; : &quot;fire's&quot;,
      &quot;start_offset&quot; : 2,
      &quot;end_offset&quot; : 8,
      &quot;type&quot; : &quot;&amp;lt;ALPHANUM&amp;gt;&quot;,
      &quot;position&quot; : 1
    },
    {
      &quot;token&quot; : &quot;fox&quot;,
      &quot;start_offset&quot; : 9,
      &quot;end_offset&quot; : 12,
      &quot;type&quot; : &quot;&amp;lt;ALPHANUM&amp;gt;&quot;,
      &quot;position&quot; : 2
    }
  ]
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;返回的&lt;code&gt;tokens&lt;/code&gt;内部就是所有的解析结果，&lt;code&gt;token&lt;/code&gt;表示解析的词语部分，&lt;code&gt;start_offset&lt;/code&gt;和&lt;code&gt;end_offset&lt;/code&gt;分别表示token在原text内的起始和终止位置，&lt;code&gt;type&lt;/code&gt;表示类型，&lt;code&gt;position&lt;/code&gt;表示这个token在整个tokens列表里面的位置。&lt;/p&gt;
&lt;p&gt;OK！有了上面的基础知识，就可以进行下面的搜索的介绍了。&lt;/p&gt;
&lt;h2 id=&quot;term搜索&quot;&gt;term搜索&lt;/h2&gt;
&lt;p&gt;term搜索不仅仅可以对&lt;code&gt;keyword&lt;/code&gt;类型的字段使用，也可以对&lt;code&gt;text&lt;/code&gt;类型的数据使用，前提是使用的搜索词必须要预先处理一下——不包含停止词并且都是小写（标准解析器），因为文档里面保存的&lt;code&gt;text&lt;/code&gt;字段分词后的结果，用term是可以匹配的。&lt;/p&gt;
&lt;h3 id=&quot;exists&quot;&gt;exists&lt;/h3&gt;
&lt;p&gt;返回所有指定字段不为空的文档，比如这个字段对应的值是&lt;code&gt;null&lt;/code&gt;或者&lt;code&gt;[]&lt;/code&gt;或者没有为这个字段建立索引。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-sh&quot;&gt;GET /_search
{
  &quot;query&quot;: {
    &quot;exists&quot;: {
      &quot;field&quot;: &quot;user&quot;
    }
  }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;如果字段是空字符串&lt;code&gt;&quot;&quot;&lt;/code&gt;或者包含&lt;code&gt;null&lt;/code&gt;的数组&lt;code&gt;[null,&quot;foo&quot;]&lt;/code&gt;，都会被当作字段存在。&lt;/p&gt;
&lt;p&gt;这个方法可以用来搜索没有被索引的值或者不存在的值。&lt;/p&gt;
&lt;h3 id=&quot;fuzzy&quot;&gt;fuzzy&lt;/h3&gt;
&lt;p&gt;fuzzy查询是一种模糊查询，会根据检索词和检索字段的&lt;strong&gt;编辑距离&lt;/strong&gt;（Levenshtein Distance）来判断是否匹配。一个编辑距离就是对单词进行一个字符的修改，这种修改可能是&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;修改一个字符，比如&lt;code&gt;box&lt;/code&gt;到&lt;code&gt;fox&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;删除一个字符，比如&lt;code&gt;black&lt;/code&gt;到&lt;code&gt;lack&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;插入一个字符，比如&lt;code&gt;sic&lt;/code&gt;到&lt;code&gt;sick&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;交换两个相邻的字符的位置，比如&lt;code&gt;act&lt;/code&gt;到&lt;code&gt;cat&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;在进行fuzzy搜索的时候，ES会生成一系列的在特定编辑距离内的变形，然后返回这些变形的准确匹配。默认情况下，当检索词的长度在&lt;code&gt;0..2&lt;/code&gt;中间时，必须准确匹配；长度在&lt;code&gt;3..5&lt;/code&gt;之间的时候，编辑距离最大为&lt;strong&gt;1&lt;/strong&gt;；长度大于&lt;code&gt;5&lt;/code&gt;的时候，最多允许编辑距离为&lt;strong&gt;2&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;可以通过配置&lt;code&gt;fuzziness&lt;/code&gt;修改最大编辑距离，&lt;code&gt;max_expansions&lt;/code&gt;修改最多的变形的token的数量&lt;/p&gt;
&lt;p&gt;比如搜索是以下条件的时候：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-sh&quot;&gt;GET /_search
{
  &quot;query&quot;: {
    &quot;fuzzy&quot;: {
      &quot;name&quot;: &quot;Accha&quot;
    }
  }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;返回结果有&lt;code&gt;Iccha&lt;/code&gt;、&lt;code&gt;AccHa&lt;/code&gt;、&lt;code&gt;accha&lt;/code&gt;还有&lt;code&gt;ccha&lt;/code&gt;&lt;/p&gt;
&lt;h3 id=&quot;ids&quot;&gt;ids&lt;/h3&gt;
&lt;p&gt;根据文档的&lt;code&gt;_id&lt;/code&gt;数组返回对应的文档信息&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-sh&quot;&gt;GET /_search
{
  &quot;query&quot;: {
    &quot;ids&quot;: {
      &quot;values&quot;: [&quot;1&quot;,&quot;4&quot;,&quot;100&quot;]
    }
  }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;prefix&quot;&gt;prefix&lt;/h3&gt;
&lt;p&gt;返回所有包含以检索词为前缀的字段的文档。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-sh&quot;&gt;GET /_search
{
  &quot;query&quot;: {
    &quot;prefix&quot;: {
      &quot;name&quot;: &quot;ac&quot;
    }
  }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;返回所有以&lt;code&gt;ac&lt;/code&gt;开头的字段，比如&lt;code&gt;acchu&lt;/code&gt;、&lt;code&gt;achu&lt;/code&gt;、&lt;code&gt;achar&lt;/code&gt;等等&lt;/p&gt;
&lt;p&gt;在某些场景下面比如搜索框里面，需要用户在输入内容的同时也要实时展示与输入内容前缀匹配的搜索结果，就可以使用prefix查询。为了加速prefix查询，还可以在设置字段映射的时候，使用&lt;code&gt;index_prefixes&lt;/code&gt;映射。ES会额外建立一个长度在2和5之间索引，在进行前缀匹配的时候效率会有很大的提高。&lt;/p&gt;
&lt;h3 id=&quot;range&quot;&gt;range&lt;/h3&gt;
&lt;p&gt;对字段进行范围的匹配。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-sh&quot;&gt;GET /_search
{
  &quot;query&quot;: {
    &quot;range&quot;: {
      &quot;age&quot;: {
        &quot;gte&quot;: 10,
        &quot;lte&quot;: 20
      }
    }
  }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;搜索年龄在10（包含）和20（包含）之间的结果&lt;/p&gt;
&lt;h3 id=&quot;regexp&quot;&gt;regexp&lt;/h3&gt;
&lt;p&gt;正则表达式匹配。通过正则表达式来寻找匹配的字段，&lt;code&gt;lucene&lt;/code&gt;会在搜索的时候生成&lt;strong&gt;有限状态机&lt;/strong&gt;，其中包含很多的&lt;strong&gt;状态&lt;/strong&gt;，默认的最多状态数量是10000&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-sh&quot;&gt;GET /_search
{
  &quot;query&quot;: {
    &quot;regexp&quot;: {
      &quot;name&quot;: &quot;ac.*ha&quot;
    }
  }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;这个搜索会匹配&lt;code&gt;achha&lt;/code&gt;、&lt;code&gt;achintha&lt;/code&gt;还有&lt;code&gt;achutha&lt;/code&gt;&lt;/p&gt;
&lt;h3 id=&quot;term&quot;&gt;term&lt;/h3&gt;
&lt;p&gt;根据检索词来准确匹配字段。官方文档建议不要用term去搜索&lt;code&gt;text&lt;/code&gt;类型的字段，因为分析器的原因很有可能不会出现你想要的结果。但是直接使用term去搜索&lt;code&gt;text&lt;/code&gt;字段还是可以工作的，前提是明白为什么会返回这些数据。比如通过下面的搜索：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-sh&quot;&gt;GET /_search
{
  &quot;query&quot;: {
    &quot;term&quot;: {
      &quot;name&quot;: {
        &quot;value&quot;: &quot;accha&quot;
      }
    }
  }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;如果&lt;code&gt;name&lt;/code&gt;字段是&lt;code&gt;keyword&lt;/code&gt;类型的，没有进行解析，那么只会匹配所有&lt;code&gt;name&lt;/code&gt;是&lt;code&gt;accha&lt;/code&gt;的文档。&lt;/p&gt;
&lt;p&gt;如果&lt;code&gt;name&lt;/code&gt;字段是&lt;code&gt;text&lt;/code&gt;类型的，原字段经过分词、小写化处理之后，只能匹配到解析之后的单独token，比如使用标准解析器，这个搜索会匹配&lt;code&gt;Accha Baccha&lt;/code&gt;、&lt;code&gt;so cute accha baccha&lt;/code&gt;或者&lt;code&gt;Accha Baccha Shivam&lt;/code&gt;等字段。&lt;/p&gt;
&lt;h3 id=&quot;terms&quot;&gt;terms&lt;/h3&gt;
&lt;p&gt;根据检索词列表来批量搜索文档，每个检索词在搜索的时候相当于&lt;code&gt;or&lt;/code&gt;的关系，只要一个匹配就行了。Elasticsearch最多允许65,536个term同时查询。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-sh&quot;&gt;GET /_search
{
  &quot;query&quot;: {
    &quot;terms&quot;: {
      &quot;name&quot;: [
        &quot;accha&quot;,
        &quot;ghazali&quot;
      ]
    }
  }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;上面的查询会匹配&lt;code&gt;name&lt;/code&gt;字段为&lt;code&gt;accha&lt;/code&gt;和&lt;code&gt;ghazali&lt;/code&gt;的文档。&lt;/p&gt;
&lt;p&gt;除了直接指定查询的term列表，还可以使用&lt;strong&gt;Terms lookUp&lt;/strong&gt;功能，也就是指定某一个存在的文档的某一个字段（可能是数字、字符串或者列表）来作为搜索条件，进行terms搜索。&lt;/p&gt;
&lt;p&gt;比如有一个文件&lt;code&gt;index&lt;/code&gt;是&lt;code&gt;my_doc&lt;/code&gt;，&lt;code&gt;id&lt;/code&gt;是&lt;code&gt;10&lt;/code&gt;，&lt;code&gt;name&lt;/code&gt;字段是&lt;code&gt;term&lt;/code&gt;并且值为&lt;code&gt;accha&lt;/code&gt;，搜索可以这样写：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-sh&quot;&gt;{
  &quot;query&quot;: {
    &quot;terms&quot;: {
      &quot;name&quot;: {
        &quot;index&quot;: &quot;my_doc&quot;,
        &quot;id&quot;: &quot;10&quot;,
        &quot;path&quot;: &quot;name&quot;
      }
    }
  }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;这样就可以返回所有&lt;code&gt;name&lt;/code&gt;字段值是&lt;code&gt;accha&lt;/code&gt;的文档里，这个通常可以用来查询所有和某个文档某个字段重复的文档并且不需要提前知道这个字段的值是什么。&lt;/p&gt;
&lt;h3 id=&quot;terms_set&quot;&gt;terms_set&lt;/h3&gt;
&lt;p&gt;terms_set和terms十分类似，只不过是多了一个最少需要匹配数量&lt;code&gt;minimum_should_match_field&lt;/code&gt;参数。当进行匹配的时候，只有至少包含了这么多的terms中的term的时候，才会返回对应的结果。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-sh&quot;&gt;GET /_search
{
  &quot;query&quot;: {
    &quot;terms_set&quot;: {
      &quot;programming_languages&quot;: {
        &quot;terms&quot;: [&quot;c++&quot;,&quot;java&quot;,&quot;php&quot;],
        &quot;minimum_should_match_field&quot;: &quot;required_match&quot;
      }
    }
  }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;pre&gt;
&lt;code class=&quot;language-sh&quot;&gt;{
    &quot;name&quot;:&quot;Jane Smith&quot;,
    &quot;programming_languages&quot;:[
        &quot;c++&quot;,
        &quot;java&quot;
    ],
    &quot;required_matches&quot;:2
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;那么只有&lt;code&gt;programming_languages&lt;/code&gt;列表里面至少包含&lt;code&gt;[&quot;c++&quot;, &quot;java&quot;, &quot;php&quot;]&lt;/code&gt;其中的2项才能满足条件&lt;/p&gt;
&lt;p&gt;还可以使用&lt;code&gt;minimum_should_match_script&lt;/code&gt;脚本来配置动态查询&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-sh&quot;&gt;{
  &quot;query&quot;: {
    &quot;terms_set&quot;: {
      &quot;programming_languages&quot;: {
        &quot;terms&quot;: [&quot;c++&quot;,&quot;java&quot;,&quot;php&quot;],
        &quot;minimum_should_match_script&quot;: {
          &quot;source&quot;: &quot;Math.min(params.num_terms, doc['required_matches'].value)&quot;
        }
      }
    }
  }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;其中&lt;code&gt;params.num_terms&lt;/code&gt;是在&lt;code&gt;terms&lt;/code&gt;字段中的元素的个数&lt;/p&gt;
&lt;h3 id=&quot;wildcard&quot;&gt;wildcard&lt;/h3&gt;
&lt;p&gt;通配符匹配，返回匹配包含通配符的检索词的结果。&lt;/p&gt;
&lt;p&gt;目前只支持两种通配符：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;code&gt;?&lt;/code&gt;：匹配任何单一的字符&lt;/li&gt;
&lt;li&gt;&lt;code&gt;*&lt;/code&gt;：匹配0个或者多个字符&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;在进行wildcard搜索的时候最好避免在检索词的开头使用&lt;code&gt;*&lt;/code&gt;或者&lt;code&gt;?&lt;/code&gt;，这会降低搜索性能。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-sh&quot;&gt;GET /_search
{
  &quot;query&quot;: {
    &quot;wildcard&quot;: {
      &quot;name&quot;: {
        &quot;value&quot;: &quot;acc*&quot;
      }
    }
  }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;这个搜索会匹配&lt;code&gt;acchu&lt;/code&gt;、&lt;code&gt;acche&lt;/code&gt;或者&lt;code&gt;accio父&lt;/code&gt;&lt;/p&gt;
&lt;h2 id=&quot;text搜索&quot;&gt;text搜索&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;text&lt;/code&gt;搜索实际上是针对被定义为&lt;code&gt;text&lt;/code&gt;类型的字段的搜索，通常搜索的时候不能根据输入的字符串的整体来理解，而是要预先处理一下，把搜索词变成小的token，再来查看每个token的匹配。&lt;/p&gt;
&lt;h3 id=&quot;interval&quot;&gt;interval&lt;/h3&gt;
&lt;p&gt;返回按照检索词的特定排列顺序排列的文档。这个查询比较复杂，这里只是简单的介绍，详细的介绍可以看&lt;a href=&quot;https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-intervals-query.html&quot;&gt;官方文档&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;比如我们想查询同时包含&lt;code&gt;raj&lt;/code&gt;和&lt;code&gt;nayaka&lt;/code&gt;的字段并且&lt;code&gt;ray&lt;/code&gt;正好在&lt;code&gt;nayaka&lt;/code&gt;前面，查询语句如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-sh&quot;&gt;POST /_search
{
  &quot;query&quot;: {
    &quot;intervals&quot;: {
      &quot;name&quot;: {
        &quot;match&quot;: {
          &quot;query&quot;: &quot;raj nayaka&quot;,
          &quot;max_gaps&quot;: 0,
          &quot;ordered&quot;: true
        }
      }
    }
  }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;上面的查询会匹配&lt;code&gt;Raj Nayaka Acchu Valmiki&lt;/code&gt;和&lt;code&gt;Yateesh Raj Nayaka&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;如果把&lt;code&gt;ordered:true&lt;/code&gt;去掉，就会匹配&lt;code&gt;nayaka raj&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;如果把&lt;code&gt;max_gaps:0&lt;/code&gt;去掉，系统会用默认值&lt;code&gt;-1&lt;/code&gt;也就是没有距离要求，就会匹配&lt;code&gt;Raj Raja nayaka&lt;/code&gt;或者&lt;code&gt;Raj Kumar Nayaka&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;其中有两个关键词&lt;code&gt;ordered&lt;/code&gt;和&lt;code&gt;max_gaps&lt;/code&gt;分别用来控制这个筛选条件是否需要排序以及两个token之间的最大间隔&lt;/p&gt;
&lt;h3 id=&quot;match&quot;&gt;match&lt;/h3&gt;
&lt;p&gt;查找和检索词短语匹配的文档，这些检索词在进行搜索之前会先被分析器解析，检索词可以是文本、数字、日期或者布尔值。match检索也可以进行模糊匹配。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-sh&quot;&gt;GET /_search
{
  &quot;query&quot;: {
    &quot;match&quot;: {
      &quot;name&quot;: &quot;nagesh acchu&quot;
    }
  }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;以上的查询会匹配&lt;code&gt;NaGesh Acchu&lt;/code&gt;、&lt;code&gt;Acchu Acchu&lt;/code&gt;和&lt;code&gt;acchu&lt;/code&gt;。系统默认是在分词后匹配任何一个token都可以完成匹配，如果修改&lt;code&gt;operator&lt;/code&gt;为&lt;code&gt;AND&lt;/code&gt;，则会匹配同时包含&lt;code&gt;nagesh&lt;/code&gt;和&lt;code&gt;acchu&lt;/code&gt;的字段。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-sh&quot;&gt;GET /_search
{
  &quot;query&quot;: {
    &quot;match&quot;: {
      &quot;name&quot;: {
        &quot;query&quot;: &quot;nagesh acchu&quot;,
        &quot;operator&quot;: &quot;and&quot;
      }
    }
  }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;上面这个查询就只会返回&lt;code&gt;NaGesh Acchu&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;查询的时候也可以使用模糊查询，修改&lt;code&gt;fuzziness&lt;/code&gt;参数&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-sh&quot;&gt;GET /_search
{
  &quot;query&quot;: {
    &quot;match&quot;: {
      &quot;name&quot;: {
        &quot;query&quot;: &quot;nagesh acchu&quot;,
        &quot;operator&quot;: &quot;and&quot;,
        &quot;fuzziness&quot;: 1
      }
    }
  }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;上面的语句会匹配&lt;code&gt;NaGesh Acchu&lt;/code&gt;还有&lt;code&gt;Nagesh Bacchu&lt;/code&gt;&lt;/p&gt;
&lt;h3 id=&quot;match_bool_prefix&quot;&gt;match_bool_prefix&lt;/h3&gt;
&lt;p&gt;match_bool_prefix会解析检索词，然后生成一个bool复合检索语句。如果检索词由很多个token构成，除了最后一个会进行prefix匹配，其他的会进行term匹配。&lt;/p&gt;
&lt;p&gt;比如使用&lt;code&gt;nagesh ac&lt;/code&gt;进行match_bool_prefix搜索&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-sh&quot;&gt;GET /_search
{
  &quot;query&quot;: {
    &quot;match_bool_prefix&quot;: {
      &quot;name&quot;: &quot;nagesh ac&quot;
    }
  }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;上面的查询会匹配&lt;code&gt;Nagesh Nagesh&lt;/code&gt;、&lt;code&gt;Rakshith Achar&lt;/code&gt;或者&lt;code&gt;ACoco&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;实际查询等价于&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-sh&quot;&gt;GET /_search
{
  &quot;query&quot;: {
    &quot;bool&quot;: {
      &quot;should&quot;: [
        {
          &quot;term&quot;: {
            &quot;name&quot;: {
              &quot;value&quot;: &quot;nagesh&quot;
            }
          }
        },
        {
          &quot;prefix&quot;: {
            &quot;name&quot;: {
              &quot;value&quot;: &quot;ac&quot;
            }
          }
        }
      ]
    }
  }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;match_phrase&quot;&gt;match_phrase&lt;/h3&gt;
&lt;p&gt;词组匹配会先解析检索词，并且标注出每个的token相对位置，搜索匹配的字段的必须包含所有的检索词的token，并且他们的相对位置也要和检索词里面相同。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-sh&quot;&gt;GET /_search
{
  &quot;query&quot;: {
    &quot;match_phrase&quot;: {
      &quot;name&quot;: &quot;Bade Acche&quot;
    }
  }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;这个搜索会匹配&lt;code&gt;Bade Acche Lagte&lt;/code&gt;，但是不会匹配&lt;code&gt;Acche Bade Lagte&lt;/code&gt;或者&lt;code&gt;Bade Lagte Acche&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;如果我们不要求这两个单词相邻，希望放松一点条件，可以添加&lt;code&gt;slop&lt;/code&gt;参数，比如设置成&lt;code&gt;1&lt;/code&gt;，代表两个token之间相隔的最多的距离（最多需要移动多少次才能相邻）。下面的查询语句会匹配&lt;code&gt;Bade Lagte Acche&lt;/code&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-sh&quot;&gt;GET /_search
{
  &quot;query&quot;: {
    &quot;match_phrase&quot;: {
      &quot;name&quot;: {
        &quot;query&quot;: &quot;Bade Acche&quot;,
        &quot;slop&quot;: 1
      }
    }
  }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;match_phrase_prefix&quot;&gt;match_phrase_prefix&lt;/h3&gt;
&lt;p&gt;match_phrase_prefix相当于是结合了match_bool_prefix和match_phrase。ES会先解析检索词，分成很多个token，然后除去最后一个token，对其他的token进行match_phrase的匹配，即全部都要匹配并且相对位置相同；对于最后一个token，需要进行前缀匹配并且匹配的这个单词在前面的match_phrase匹配的结果的后面。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-sh&quot;&gt;GET /_search
{
  &quot;query&quot;: {
    &quot;match_phrase_prefix&quot;: {
      &quot;name&quot;: &quot;acchu ac&quot;
    }
  }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;上面的查询能够匹配&lt;code&gt;Acchu Acchu1&lt;/code&gt;和&lt;code&gt;Acchu Acchu Papu&lt;/code&gt;，但是不能匹配&lt;code&gt;acc acchu&lt;/code&gt;或者&lt;code&gt;acchu pa&lt;/code&gt;&lt;/p&gt;
&lt;h3 id=&quot;multi_match&quot;&gt;multi_match&lt;/h3&gt;
&lt;p&gt;multi_match可以同时对多个字段进行查询匹配，ES支持很多种不同的查询类型比如&lt;code&gt;best_fields&lt;/code&gt;（任何字段match检索词都表示匹配成功）、&lt;code&gt;phrase&lt;/code&gt;（用&lt;code&gt;match_phrase&lt;/code&gt;代替&lt;code&gt;match&lt;/code&gt;）还有&lt;code&gt;cross_field&lt;/code&gt;（交叉匹配，通常用在所有的token必须在至少一个字段中出现）等等&lt;/p&gt;
&lt;p&gt;下面是普通的&lt;code&gt;best_fields&lt;/code&gt;的匹配&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-sh&quot;&gt;GET /_search
{
  &quot;query&quot;: {
    &quot;multi_match&quot;: {
      &quot;query&quot;: &quot;acchu&quot;,
      &quot;fields&quot;: [
        &quot;name&quot;,
        &quot;intro&quot;
      ]
    }
  }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;只要&lt;code&gt;name&lt;/code&gt;或者&lt;code&gt;intro&lt;/code&gt;字段任何一个包含&lt;code&gt;acchu&lt;/code&gt;都会完成匹配。&lt;/p&gt;
&lt;p&gt;如果使用&lt;code&gt;cross_fields&lt;/code&gt;匹配如下&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-sh&quot;&gt;GET /_search
{
  &quot;query&quot;: {
    &quot;multi_match&quot;: {
      &quot;query&quot;: &quot;call acchu&quot;,
      &quot;type&quot;: &quot;cross_fields&quot;,
      &quot;fields&quot;: [
        &quot;name&quot;,
        &quot;intro&quot;
      ],
      &quot;operator&quot;: &quot;and&quot;
    }
  }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;上面的匹配需要同时满足下面两个条件:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;code&gt;name&lt;/code&gt;中出现&lt;code&gt;call&lt;/code&gt;或&lt;code&gt;intro&lt;/code&gt;中出现&lt;code&gt;call&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;name&lt;/code&gt;中出现&lt;code&gt;acchu&lt;/code&gt;或&lt;code&gt;intro&lt;/code&gt;中出现&lt;code&gt;acchu&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;所以这个查询能够匹配&lt;code&gt;name&lt;/code&gt;包含&lt;code&gt;acchu&lt;/code&gt;和&lt;code&gt;intro&lt;/code&gt;包含&lt;code&gt;call&lt;/code&gt;的文档，或者匹配&lt;code&gt;name&lt;/code&gt;同时包含&lt;code&gt;call&lt;/code&gt;和&lt;code&gt;acchu&lt;/code&gt;的文档。&lt;/p&gt;
&lt;h3 id=&quot;common&quot;&gt;common&lt;/h3&gt;
&lt;p&gt;common查询会把查询语句分成两个部分，较为重要的分为一个部分（这个部分的token通常在文章中出现频率比较低），不那么重要的为一个部分（出现频率比较高，以前可能被当作停止词），然后分别用&lt;code&gt;low_freq_operator&lt;/code&gt;、&lt;code&gt;high_freq_operator&lt;/code&gt;以及&lt;code&gt;minimum_should_match&lt;/code&gt;来控制这些语句的表现。&lt;/p&gt;
&lt;p&gt;在进行查询之前需要指定一个区分高频和低频词的分界点，也就是&lt;code&gt;cutoff_frequency&lt;/code&gt;，它既可以是小数比如&lt;code&gt;0.001&lt;/code&gt;代表该字段所有的token的集合里面出现的频率也可以是大于&lt;code&gt;1&lt;/code&gt;的整数代表这个词出现的次数。当token的频率高于这一个阈值的时候，他就会被当作高频词。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-sh&quot;&gt;GET /_search
{
  &quot;query&quot;: {
    &quot;common&quot;: {
      &quot;body&quot;: {
        &quot;query&quot;: &quot;nelly the elephant as a cartoon&quot;,
        &quot;cutoff_frequency&quot;: 0.001,
        &quot;low_freq_operator&quot;: &quot;and&quot;
      }
    }
  }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;其中高频词是&lt;code&gt;the&lt;/code&gt;、&lt;code&gt;a&lt;/code&gt;和&lt;code&gt;as&lt;/code&gt;，低频词是&lt;code&gt;nelly&lt;/code&gt;、&lt;code&gt;elephant&lt;/code&gt;和&lt;code&gt;cartoon&lt;/code&gt;，上面的搜索大致等价于下面的查询&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-sh&quot;&gt;GET /_search
{
  &quot;query&quot;: {
    &quot;bool&quot;: {
      &quot;must&quot;: [
        {&quot;term&quot;: {&quot;body&quot;: &quot;nelly&quot;}},
        {&quot;term&quot;: {&quot;body&quot;: &quot;elephant&quot;}},
        {&quot;term&quot;: {&quot;body&quot;: &quot;cartoon&quot;}}
      ],
      &quot;should&quot;: [
        {&quot;term&quot;: {&quot;body&quot;: &quot;the&quot;}},
        {&quot;term&quot;: {&quot;body&quot;: &quot;as&quot;}},
        {&quot;term&quot;: {&quot;body&quot;: &quot;a&quot;}}
      ]
    }
  }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;但是第一个查询的效率要优于第二个，因为common语句有性能上的优化，只有重要的token匹配之后的文档，才会在不重要的文档的查询时候计算&lt;code&gt;_score&lt;/code&gt;；不重要的token在查询的时候不会计算&lt;code&gt;_score&lt;/code&gt;&lt;/p&gt;
&lt;h3 id=&quot;query_string&quot;&gt;query_string&lt;/h3&gt;
&lt;p&gt;输入一个查询语句，返回和这个查询语句匹配的所有的文档。&lt;/p&gt;
&lt;p&gt;这个查询语句不是简单的检索词，而是包含特定语法的的搜索语句，里面包含操作符比如&lt;code&gt;AND&lt;/code&gt;和&lt;code&gt;OR&lt;/code&gt;，在进行查询之前会被一个语法解析器解析，转化成可以执行的搜索语句进行搜索。用户可以生成一个特别复杂的查询语句，里面可能包含通配符、多字段匹配等等。在搜索之前ES会检查查询语句的语法，如果有语法错误会直接报错。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-sh&quot;&gt;GET /_search
{
  &quot;query&quot;: {
    &quot;query_string&quot;: {
      &quot;default_field&quot;: &quot;name&quot;,
      &quot;query&quot;: &quot;acchu AND nagesh&quot;
    }
  }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;上面的查询会匹配所有的同时包含&lt;code&gt;acchu&lt;/code&gt;和&lt;code&gt;nagesh&lt;/code&gt;的结果。简化一下可以这样写：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-sh&quot;&gt;GET /_search
{
  &quot;query&quot;: {
    &quot;query_string&quot;: {
      &quot;query&quot;: &quot;name: acchu AND nagesh&quot;
    }
  }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;query_string里面还支持更加复杂的写法：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;code&gt;name: acchu nagesh&lt;/code&gt;：查询&lt;code&gt;name&lt;/code&gt;包含&lt;code&gt;acchu&lt;/code&gt;和&lt;code&gt;nagesh&lt;/code&gt;其中的任意一个&lt;/li&gt;
&lt;li&gt;&lt;code&gt;book.\*:(quick OR brown)&lt;/code&gt;：&lt;code&gt;book&lt;/code&gt;的任何子字段比如&lt;code&gt;book.title&lt;/code&gt;和&lt;code&gt;book.content&lt;/code&gt;，包含&lt;code&gt;quick&lt;/code&gt;或者&lt;code&gt;brown&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;_exists_: title&lt;/code&gt;：&lt;code&gt;title&lt;/code&gt;字段包含非&lt;code&gt;null&lt;/code&gt;值&lt;/li&gt;
&lt;li&gt;&lt;code&gt;name: acch*&lt;/code&gt;：通配符，匹配任何&lt;code&gt;acch&lt;/code&gt;开头的字段&lt;/li&gt;
&lt;li&gt;&lt;code&gt;name:/joh?n(ath[oa]n)/&lt;/code&gt;：正则表达式，需要把内容放到两个斜杠&lt;code&gt;/&lt;/code&gt;中间&lt;/li&gt;
&lt;li&gt;&lt;code&gt;name: acch~&lt;/code&gt;：模糊匹配，默认编辑距离为2，不过80%的情况编辑距离为1就能解决问题&lt;code&gt;name: acch~1&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;count:[1 TO 5]&lt;/code&gt;：范围查询，或者&lt;code&gt;count: &amp;gt;10&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;下面的查询允许匹配多个字段，字段之间时&lt;code&gt;OR&lt;/code&gt;的关系&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-sh&quot;&gt;GET /_search
{
  &quot;query&quot;: {
    &quot;query_string&quot;: {
      &quot;fields&quot;: [
        &quot;name&quot;,
        &quot;intro&quot;
      ],
      &quot;query&quot;: &quot;nagesh&quot;
    }
  }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;simple_query_string&quot;&gt;simple_query_string&lt;/h3&gt;
&lt;p&gt;和上面的query_string类似，但是使用了更加简单的语法。使用了下面的操作符：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;code&gt;+&lt;/code&gt;表示&lt;code&gt;AND&lt;/code&gt;操作&lt;/li&gt;
&lt;li&gt;&lt;code&gt;|&lt;/code&gt;表示&lt;code&gt;OR&lt;/code&gt;操作&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-&lt;/code&gt;表示否定&lt;/li&gt;
&lt;li&gt;&lt;code&gt;&quot;&lt;/code&gt;用于圈定一个短语&lt;/li&gt;
&lt;li&gt;&lt;code&gt;*&lt;/code&gt;放在token的后面表示前缀匹配&lt;/li&gt;
&lt;li&gt;&lt;code&gt;()&lt;/code&gt;表示优先级&lt;/li&gt;
&lt;li&gt;&lt;code&gt;~N&lt;/code&gt;放在token后面表示模糊查询的最大编辑距离&lt;code&gt;fuzziness&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;~N&lt;/code&gt;放在phrase后面表示模糊匹配短语的&lt;code&gt;slop&lt;/code&gt;值&lt;/li&gt;
&lt;/ul&gt;&lt;pre&gt;
&lt;code class=&quot;language-sh&quot;&gt;GET /_search
{
  &quot;query&quot;: {
    &quot;simple_query_string&quot;: {
      &quot;query&quot;: &quot;acch* + foll~2 + -Karen&quot;,
      &quot;fields&quot;: [
        &quot;intro&quot;
      ]
    }
  }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;上面的搜索相当于搜索包含前缀为&lt;code&gt;acch&lt;/code&gt;的、和&lt;code&gt;foll&lt;/code&gt;编辑距离最大是2的并且不包含&lt;code&gt;Karen&lt;/code&gt;的字段，这样的语句会匹配&lt;code&gt;call me acchu&lt;/code&gt;或者&lt;code&gt;acchu follow me&lt;/code&gt;&lt;/p&gt;
&lt;h2 id=&quot;总结&quot;&gt;总结&lt;/h2&gt;
&lt;p&gt;Elasticsearch提供了强大的搜索功能，使用query匹配可以进行相关性的计算排序但是filter可能更加适用于大多数的过滤查询的情况，如果用户对于标准解析器不太满意可以自定义解析器或者第三方解析器比如支持中文的&lt;strong&gt;IK解析器&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;在进行搜索的时候一定要注意搜索&lt;strong&gt;keyword&lt;/strong&gt;和&lt;strong&gt;text&lt;/strong&gt;字段时候的区别，使用term相关的查询只能匹配单个的token但是使用text相关的搜索可以利用前面的term搜索进行组合查询，text搜索更加灵活强大，但是性能相对差一点。&lt;/p&gt;
&lt;h2 id=&quot;参考&quot;&gt;参考&lt;/h2&gt;
&lt;blockquote readability=&quot;0&quot;&gt;
&lt;p&gt;&lt;a href=&quot;https://www.elastic.co/guide/cn/elasticsearch/guide/current/relevance-intro.html&quot;&gt;什么是相关性？&lt;/a&gt;&lt;br/&gt;&lt;a href=&quot;https://blog.csdn.net/paditang/article/details/79098830&quot;&gt;ElasticSearch 使用教程之_score(评分)介绍&lt;/a&gt;&lt;br/&gt;&lt;a href=&quot;https://www.elastic.co/guide/en/elasticsearch/reference/current/full-text-queries.html&quot;&gt;Full text queries&lt;/a&gt;&lt;br/&gt;&lt;a href=&quot;https://www.elastic.co/guide/en/elasticsearch/reference/current/term-level-queries.html&quot;&gt;Term-level queries&lt;/a&gt;&lt;br/&gt;&lt;a href=&quot;https://discuss.elastic.co/t/elasticsearch-query-performance-using-filter-query/109889&quot;&gt;Elasticsearch query performance using filter query&lt;/a&gt;&lt;br/&gt;&lt;a href=&quot;http://unicode.org/reports/tr29/&quot;&gt;Unicode Text Segmentation&lt;/a&gt;&lt;br/&gt;&lt;a href=&quot;https://www.elastic.co/guide/cn/elasticsearch/guide/current/phrase-matching.html&quot;&gt;短词匹配&lt;/a&gt;&lt;br/&gt;&lt;a href=&quot;https://discuss.elastic.co/t/top-hits-query-with-same-score/107018&quot;&gt;Top hits query with same score?&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;更多精彩内容请看我的&lt;/strong&gt;&lt;a href=&quot;http://sunshuyi.vip?hmsr=cnblog&amp;amp;hmpl=es%2Dquery&amp;amp;hmcu=home&amp;amp;hmkw=home&amp;amp;hmci=none&quot;&gt;&lt;strong&gt;个人博客&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;</description>
<pubDate>Thu, 16 Apr 2020 15:39:00 +0000</pubDate>
<dc:creator>佛西先森</dc:creator>
<og:description>刚开始接触Elasticsearch的时候被Elasticsearch的搜索功能搞得晕头转向，每次想在Kibana里面查询某个字段的时候，查出来的结果经常不是自己想要的，然而又不知道问题出在了哪里。出</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/sunshuyi/p/12716828.html</dc:identifier>
</item>
<item>
<title>coding++：Spring 中的 AOP 原理 - coding++</title>
<link>http://www.cnblogs.com/codingmode/p/12716824.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/codingmode/p/12716824.html</guid>
<description>&lt;p&gt;&lt;span&gt;&lt;strong&gt;为什么使用 AOP 如下场景：&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;现在有一个情景：&lt;/p&gt;
&lt;p&gt;我们要把大象放进冰箱，步骤为：打开冰箱-&amp;gt;放入大象-&amp;gt;关闭冰箱&lt;/p&gt;
&lt;p&gt;如果再把大象拿出来，步骤为：打开冰箱-&amp;gt;拿出大象-&amp;gt;关闭冰箱&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;代码如下：&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;34&quot;&gt;
&lt;pre&gt;
 &lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt;&lt;span&gt; put() {
        System.out.println(&lt;/span&gt;&quot;打开冰箱...&quot;&lt;span&gt;);
        System.out.println(&lt;/span&gt;&quot;放入大象...&quot;&lt;span&gt;);
        System.out.println(&lt;/span&gt;&quot;关闭冰箱...&quot;&lt;span&gt;);
    }
 
    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt;&lt;span&gt; get() {
        System.out.println(&lt;/span&gt;&quot;打开冰箱...&quot;&lt;span&gt;);
        System.out.println(&lt;/span&gt;&quot;拿出大象...&quot;&lt;span&gt;);
        System.out.println(&lt;/span&gt;&quot;关闭冰箱...&quot;&lt;span&gt;);
    }&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;我们需要在每一个拿进拿出操作前后都要进行打开冰箱和关闭冰箱的操作，造成了代码重复。&lt;/p&gt;
&lt;p&gt;而如果要拿进拿出其他动物，那么每一个动物的操作都需要加入打开冰箱关闭冰箱的操作，十分繁琐混乱。&lt;/p&gt;
&lt;p&gt;解决方法就是AOP，将这些打开冰箱和关闭冰箱的操作单独抽取出来，做成一个切面，之后调用任何方法，都插入到方法前后即可。&lt;/p&gt;
&lt;p&gt;先来看一些基本概念再来解决这个问题。&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;基本概念：&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;AOP &lt;/strong&gt;  即Aspect Oriented Program，&lt;strong&gt;面向切面编程&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;使用AOP技术，可以将一些系统性相关的编程工作，独立提取出来，独立实现，然后通过切面切入进系统。&lt;/p&gt;
&lt;p&gt;从而避免了在业务逻辑的代码中混入很多的系统相关的逻辑——比如权限管理，事物管理，日志记录等等。&lt;/p&gt;
&lt;p&gt;这些系统性的编程工作都可以独立编码实现，然后通过AOP技术切入进系统即可。从而达到了 将不同的关注点分离出来的效果。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;切面（Aspect）：&lt;/strong&gt;其实就是共有功能的实现。&lt;/p&gt;
&lt;p&gt;　　　　　　　　  如日志切面、权限切面、事务切面等。&lt;/p&gt;
&lt;p&gt;　　　　　　　　   在实际应用中通常是一个存放共有功能实现的普通Java类，之所以能被AOP容器识别成切面，是在配置中指定的。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;通知/增强（Advice）：&lt;/strong&gt;是切面的具体实现。以目标方法为参照点，根据放置的地方不同，可分为前置通知（Before）、后置通知（AfterReturning）、异常通知（AfterThrowing）、最终通知（After）与环绕通知（Around）5种。&lt;/p&gt;
&lt;p&gt;　　　　　　　　　　  在实际应用中通常是切面类中的一个方法，具体属于哪类通知，同样是在配置中指定的。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;连接点（Joinpoint）：&lt;/strong&gt;就是程序在运行过程中能够插入切面的地点。&lt;/p&gt;
&lt;p&gt;　　　　　　　　　　  例如，方法调用、异常抛出或字段修改等，但Spring只支持方法级的连接点。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;切入点（Pointcut）：&lt;/strong&gt;用于定义通知应该切入到哪些连接点上。&lt;/p&gt;
&lt;p&gt;　　　　　　　　　　不同的通知通常需要切入到不同的连接点上，这种精准的匹配是由切入点的正则表达式来定义的。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;目标对象（Target）：&lt;/strong&gt;就是那些即将切入切面的对象，也就是那些被通知的对象。&lt;/p&gt;
&lt;p&gt;　　　　　　              这些对象中已经只剩下干干净净的核心业务逻辑代码了，所有的共有功能代码等待AOP容器的切入。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;代理对象（Proxy）：&lt;/strong&gt;将通知应用到目标对象之后被动态创建的对象。&lt;/p&gt;
&lt;p&gt;　　　　　　　　　　可以简单地理解为，代理对象的功能等于目标对象的核心业务逻辑功能加上共有功能。&lt;/p&gt;
&lt;p&gt;　　　　　　　　　　 代理对象对于使用者而言是透明的，是程序运行过程中的产物。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;织入（Weaving）：&lt;/strong&gt;将切面应用到目标对象从而创建一个新的代理对象的过程。&lt;/p&gt;
&lt;p&gt;　　　　　　　　　这个过程可以发生在编译期、类装载期及运行期，当然不同的发生点有着不同的前提条件。&lt;/p&gt;
&lt;p&gt;　　　　　　　　　譬如发生在编译期的话，就要求有一个支持这种AOP实现的特殊编译器；发生在类装载期，就要求有一个支持AOP实现的特殊类装载器；只有发生在运行期，则可直接通过Java语言的反射机制与动态代理机制来动态实现。&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;AOP 原理：&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;AOP 代理可分为静态代理和动态代理两大类，&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;静态代理：&lt;/strong&gt;使用 AOP 框架提供的命令进行编译，从而在编译阶段就可生成 AOP 代理类，因此也称为编译时增强；&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;动态代理：&lt;/strong&gt;在运行时借助于 JDK 动态代理、CGLIB（code generate libary）字节码生成技术 等在内存中“临时”生成 AOP 动态代理类，因此也被称为运行时增强&lt;/p&gt;
&lt;p&gt;Spring AOP采用的是动态代理，在运行期间对业务方法进行增强，所以不会生成新类。&lt;/p&gt;
&lt;p&gt;对于动态代理技术，Spring AOP提供了对JDK动态代理的支持以及CGLib的支持。&lt;/p&gt;
&lt;p&gt;前者是基于反射技术的实现，后者是基于继承的机制实现。&lt;/p&gt;
&lt;p&gt;如果目标对象有实现接口，使用jdk代理。&lt;/p&gt;
&lt;p&gt;如果目标对象没有实现接口，则使用Cglib代理。&lt;/p&gt;

&lt;p&gt;&lt;span&gt;&lt;strong&gt;JDK：动态代理：&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;JDK动态代理需要获得被目标类的接口信息（应用Java的反射），生成一个实现了代理接口的动态代理类（字节码），再通过反射机制获得动态代理类的构造函数，利用构造函数生成动态代理类的实例对象，在调用具体方法前调用&lt;/p&gt;
&lt;p&gt;invokeHandler方法来处理。&lt;/p&gt;
&lt;p&gt;主要使用到 InvocationHandler 接口和 Proxy.newProxyInstance() 方法。&lt;/p&gt;
&lt;p&gt;JDK动态代理要求被代理的类实现一个接口，只有接口中的方法才能够被代理 。&lt;/p&gt;
&lt;p&gt;其方法是将被代理对象注入到一个中间对象，而中间对象实现InvocationHandler接口，在实现该接口时，可以在被代理对象调用它的方法时，在调用的前后插入一些代码。&lt;/p&gt;
&lt;p&gt;而 Proxy.newProxyInstance() 能够利用中间对象来生产代理对象。&lt;/p&gt;
&lt;p&gt;插入的代码就是切面代码。所以使用JDK动态代理可以实现AOP。&lt;/p&gt;
&lt;p&gt;现在演示一下如何使用JDK动态代理实现开头的情景&lt;/p&gt;
&lt;p&gt;JDK动态代理需要被代理类实现一个接口，先写一个接口。&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;32&quot;&gt;
&lt;pre&gt;
&lt;span&gt;public&lt;/span&gt; &lt;span&gt;interface&lt;/span&gt;&lt;span&gt; AnimalOperation {
    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt;&lt;span&gt; put();
    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt;&lt;span&gt; get();
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;再写一个类（要被代理的类），实现这个接口&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;33&quot;&gt;
&lt;pre&gt;
&lt;span&gt;public&lt;/span&gt; &lt;span&gt;class&lt;/span&gt; ElephantOperation &lt;span&gt;implements&lt;/span&gt;&lt;span&gt; AnimalOperation{
 
    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt;&lt;span&gt; put() {
        System.out.println(&lt;/span&gt;&quot;放入大象...&quot;&lt;span&gt;);
    }
 
    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt;&lt;span&gt; get() {
        System.out.println(&lt;/span&gt;&quot;拿出大象...&quot;&lt;span&gt;);
    }
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;然后写一个类来实现InvocationHandler接口，在该类中对被代理类的方法做增强，并编写生成代理对象的方法&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;42&quot;&gt;
&lt;pre&gt;
&lt;span&gt;public&lt;/span&gt; &lt;span&gt;class&lt;/span&gt; FridgeJDKProxy &lt;span&gt;implements&lt;/span&gt;&lt;span&gt; InvocationHandler{
    &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;被代理的对象,之后用反射调用被代理方法的时候需要被代理对象的引用&lt;/span&gt;
    &lt;span&gt;private&lt;/span&gt;&lt;span&gt; Object target;
 
    &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;InvocationHandler接口的方法,
    &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; proxy是代理对象，method是被代理的方法，args是被代理方法的参数，返回值是原方法的返回&lt;/span&gt;
    &lt;span&gt;public&lt;/span&gt; Object invoke(Object proxy, Method method, Object[] args) &lt;span&gt;throws&lt;/span&gt;&lt;span&gt; Throwable {
        openDoor();&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;调用被代理方法做一些操作&lt;/span&gt;
        Object result = method.invoke(target, args);&lt;span&gt;//&lt;/span&gt;&lt;span&gt;执行被代理对象的方法，如果方法有返回值则赋值给result&lt;/span&gt;
        closeDoor();&lt;span&gt;//&lt;/span&gt;&lt;span&gt;调用被代理方法后做一些操作&lt;/span&gt;
        &lt;span&gt;return&lt;/span&gt;&lt;span&gt; result;
    }
    &lt;/span&gt;&lt;span&gt;private&lt;/span&gt; &lt;span&gt;void&lt;/span&gt;&lt;span&gt; openDoor(){
        System.out.println(&lt;/span&gt;&quot;打开冰箱...&quot;&lt;span&gt;);
    }
    &lt;/span&gt;&lt;span&gt;private&lt;/span&gt; &lt;span&gt;void&lt;/span&gt;&lt;span&gt; closeDoor(){
        System.out.println(&lt;/span&gt;&quot;关闭冰箱...&quot;&lt;span&gt;);
    }
    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt;&lt;span&gt; Object getProxy(Object target){
        &lt;/span&gt;&lt;span&gt;this&lt;/span&gt;.target=&lt;span&gt;target;
        &lt;/span&gt;&lt;span&gt;return&lt;/span&gt; Proxy.newProxyInstance(target.getClass().getClassLoader(),target.getClass().getInterfaces(),&lt;span&gt;this&lt;/span&gt;&lt;span&gt;);
    }
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;其中Proxy.newProxyInstance()方法需要的参数分别为，类加载器ClassLoader loader,接口数组Class&amp;lt;?&amp;gt;[] interfaces，与 InvocationHandler &lt;/p&gt;
&lt;p&gt;测试代码为：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;34&quot;&gt;
&lt;pre&gt;
  &lt;span&gt;public&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; &lt;span&gt;void&lt;/span&gt;&lt;span&gt; main(String args[]) {
      AnimalOperation elephantOperation &lt;/span&gt;=(AnimalOperation) &lt;span&gt;new&lt;/span&gt; FridgeJDKProxy().getProxy(&lt;span&gt;new&lt;/span&gt;&lt;span&gt; ElephantOperation());
      elephantOperation.put();
      elephantOperation.get();
  }&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;打印结果：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1652134/202004/1652134-20200416233102474-1653210809.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p id=&quot;2.2%20CGLIB%20%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86&quot;&gt;&lt;span&gt;&lt;strong&gt;CGLIB 动态代理：&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;字节码生成技术实现AOP，其实就是继承被代理对象，然后Override需要被代理的方法，在覆盖该方法时，自然是可以插入我们自己的代码的。&lt;/p&gt;
&lt;p&gt;CGLib动态代理需要依赖asm包，把被代理对象类的class文件加载进来，修改其字节码生成子类。&lt;/p&gt;
&lt;p&gt;因为需要Override被代理对象的方法，所以自然CGLIB技术实现AOP时，就 必须要求需要被代理的方法不能是final方法，因为final方法不能被子类覆盖 。&lt;/p&gt;
&lt;p&gt;现在演示一下如何使用CGLIB动态代理实现开头的情景&lt;/p&gt;
&lt;p&gt;CGLIB动态代理不要求被代理类实现接口，先写一个被代理类。&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;33&quot;&gt;
&lt;pre&gt;
&lt;span&gt;public&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;&lt;span&gt; MonkeyOperation {
    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt;&lt;span&gt; put() {
        System.out.println(&lt;/span&gt;&quot;放入猴子...&quot;&lt;span&gt;);
    }
 
    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt;&lt;span&gt; get() {
        System.out.println(&lt;/span&gt;&quot;拿出猴子...&quot;&lt;span&gt;);
    }
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;在写一个类实现MethodInterceptor接口，并在接口方法intercept（）里对被代理对象的方法做增强，并编写生成代理对象的方法&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;39&quot;&gt;
&lt;pre&gt;
&lt;span&gt;public&lt;/span&gt; &lt;span&gt;class&lt;/span&gt; FridgeCGLibProxy &lt;span&gt;implements&lt;/span&gt;&lt;span&gt; MethodInterceptor {
 
    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; String name=&quot;hahaha&quot;&lt;span&gt;;
    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; Object intercept(Object proxy, Method method, Object[] args, MethodProxy methodProxy) &lt;span&gt;throws&lt;/span&gt;&lt;span&gt; Throwable {
        openDoor();&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;调用被代理方法做一些操作&lt;/span&gt;
        Object result = methodProxy.invokeSuper(proxy,args);&lt;span&gt;//&lt;/span&gt;&lt;span&gt;执行被代理对象的方法，如果方法有返回值则赋值给result&lt;/span&gt;
        closeDoor();&lt;span&gt;//&lt;/span&gt;&lt;span&gt;调用被代理方法后做一些操作&lt;/span&gt;
        &lt;span&gt;return&lt;/span&gt;&lt;span&gt; result;
    }
    &lt;/span&gt;&lt;span&gt;private&lt;/span&gt; &lt;span&gt;void&lt;/span&gt;&lt;span&gt; openDoor(){
        System.out.println(&lt;/span&gt;&quot;打开冰箱...&quot;&lt;span&gt;);
    }
    &lt;/span&gt;&lt;span&gt;private&lt;/span&gt; &lt;span&gt;void&lt;/span&gt;&lt;span&gt; closeDoor(){
        System.out.println(&lt;/span&gt;&quot;关闭冰箱...&quot;&lt;span&gt;);
    }
    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; Object getProxy(Class cls){&lt;span&gt;//&lt;/span&gt;&lt;span&gt;参数为被代理的类对象&lt;/span&gt;
        Enhancer enhancer = &lt;span&gt;new&lt;/span&gt; Enhancer();&lt;span&gt;//&lt;/span&gt;&lt;span&gt;创建增强器，用来创建动态代理类&lt;/span&gt;
        enhancer.setSuperclass(cls);&lt;span&gt;//&lt;/span&gt;&lt;span&gt;设置父类，即被代理的类对象&lt;/span&gt;
        enhancer.setCallback(&lt;span&gt;this&lt;/span&gt;);&lt;span&gt;//&lt;/span&gt;&lt;span&gt;设置回调，指定为当前对象&lt;/span&gt;
        &lt;span&gt;return&lt;/span&gt; enhancer.create();&lt;span&gt;//&lt;/span&gt;&lt;span&gt;返回生成的代理类&lt;/span&gt;
&lt;span&gt;    }
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;测试代码：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;33&quot;&gt;
&lt;pre&gt;
  &lt;span&gt;public&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; &lt;span&gt;void&lt;/span&gt;&lt;span&gt; main(String args[]) {
      MonkeyOperation monkeyOperation &lt;/span&gt;=(MonkeyOperation)&lt;span&gt;new&lt;/span&gt; FridgeCGLibProxy().getProxy(MonkeyOperation.&lt;span&gt;class&lt;/span&gt;&lt;span&gt;);
      monkeyOperation.put();
      monkeyOperation.get();
  }&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;打印结果：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1652134/202004/1652134-20200416233312447-332474219.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;spring实现AOP，如果被代理对象实现了接口，那么就使用JDK的动态代理技术，反之则使用CGLIB来实现AOP，所以 Spring默认是使用JDK的动态代理技术实现AOP的 。&lt;/p&gt;

</description>
<pubDate>Thu, 16 Apr 2020 15:35:00 +0000</pubDate>
<dc:creator>coding++</dc:creator>
<og:description>为什么使用 AOP 如下场景： 现在有一个情景： 我们要把大象放进冰箱，步骤为：打开冰箱-&amp;gt;放入大象-&amp;gt;关闭冰箱 如果再把大象拿出来，步骤为：打开冰箱-&amp;gt;拿出大象-&amp;gt;关闭冰箱</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/codingmode/p/12716824.html</dc:identifier>
</item>
<item>
<title>C# 基础知识系列- 9 字符串的更多用法（二） - 月影西下</title>
<link>http://www.cnblogs.com/c7jie/p/12716596.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/c7jie/p/12716596.html</guid>
<description>&lt;p&gt;上一篇文章介绍了字符串自身的一些方法，就是对象方法。在字符串体系中，还有一些是&lt;code&gt;string&lt;/code&gt;类提供的静态方法。这两部分构成了字符串体系，当然还有一些三方库为字符串提供了扩展方法。&lt;br/&gt;这里简单的介绍一下&lt;code&gt;string&lt;/code&gt;类的静态方法。&lt;/p&gt;

&lt;h2 id=&quot;11-create一个字符串&quot;&gt;1.1 Create一个字符串&lt;/h2&gt;
&lt;p&gt;通过调用&lt;code&gt;string.Create&lt;/code&gt;方法可以生成一个字符串。该方法的声明是&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-c#&quot;&gt;public static string Create&amp;lt;TState&amp;gt; (int length, TState state, System.Buffers.SpanAction&amp;lt;char,TState&amp;gt; action);
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;简单的来讲就是生成一个长度为&lt;code&gt;length&lt;/code&gt;的字符串，基本元素是 &lt;code&gt;TState&lt;/code&gt;类型的&lt;code&gt;state&lt;/code&gt;，具体的填充过程交由&lt;code&gt;action&lt;/code&gt;来进行处理。值得注意的是action是一个委托，也就是它可以用lambda表达式直接使用，具体声明如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-c#&quot;&gt;public delegate void SpanAction&amp;lt;T,in TArg&amp;gt;(Span&amp;lt;T&amp;gt; span, TArg arg);
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;因为方法中指定了&lt;code&gt;Span&lt;/code&gt;参数为&lt;code&gt;char&lt;/code&gt;，那么 action 的写法应该如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-c#&quot;&gt;(span, state)=&amp;gt;//span 的类型是 Span&amp;lt;char&amp;gt;，state的类型是 TState
{
// 注意，没有返回值
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;示例：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-c#&quot;&gt;string str = &quot;12320kz,zxcqweqwkuqwiqewpqwwe&quot;;
Console.WriteLine(string.Create(10,str, (span, c) =&amp;gt;
{
    span.Fill(c[0]);
}));
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;span&lt;/code&gt;的方法&lt;code&gt;Fill&lt;/code&gt;的参数是&lt;code&gt;char&lt;/code&gt;，所以这个方法就是按照一定逻辑将 state参数转换成char然后填充给字符串，在action中多次调用Fill只会生效最后一次填充。&lt;/p&gt;
&lt;h2 id=&quot;12-连接多个元素&quot;&gt;1.2 连接多个元素&lt;/h2&gt;
&lt;p&gt;字符串的连接有两个方法，一个是&lt;code&gt;string.Concat&lt;/code&gt;，一个是&lt;code&gt;string.Join&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;首先介绍&lt;code&gt;Concat&lt;/code&gt;，这个方法最基本的功能就是将多个字符串收尾连接成一个字符串，继续引申，连接任意个对象形成一个字符串，最后将一个集合的元素拼接成字符串。所以，这个方法的声明就有以下内容：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-c#&quot;&gt;public static string Concat (string str0, string str1);
public static string Concat (object arg0, object arg1);
public static string Concat (params string[] values);
public static string Concat (params object[] args);
public static string Concat (System.Collections.Generic.IEnumerable&amp;lt;string&amp;gt; values);
public static string Concat&amp;lt;T&amp;gt; (System.Collections.Generic.IEnumerable&amp;lt;T&amp;gt; values);
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;以上只是几个具有代表性的方法，介绍到这里有没有觉得它的实现很眼熟？&lt;/p&gt;
&lt;p&gt;没错，字符串的‘加法’运算就是基于这个方法实现的。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Join&lt;/code&gt;在行为上与&lt;code&gt;Concat&lt;/code&gt;很相似，但是这个方法是用一个分割符（可以是字符串）将一组对象连接起来，所以它的声明就是如下内容：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-c#&quot;&gt;public static string Join (char separator, params object[] values);
public static string Join&amp;lt;T&amp;gt; (char separator, System.Collections.Generic.IEnumerable&amp;lt;T&amp;gt; values);
public static string Join (string separator, params object[] values);
public static string Join&amp;lt;T&amp;gt; (string separator, System.Collections.Generic.IEnumerable&amp;lt;T&amp;gt; values);
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;这两个方法出镜率非常高，不过&lt;code&gt;Concat&lt;/code&gt;更多的是用‘加法’形式，而&lt;code&gt;Join&lt;/code&gt;在多个元素快速生成字符串中非常常见。&lt;/p&gt;
&lt;p&gt;这里简单介绍一下&lt;code&gt;Join&lt;/code&gt;的使用：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-c#&quot;&gt;var list = new List&amp;lt;int&amp;gt;();
for (var i = 0; i &amp;lt; 10; i++)
{
    list.Add(i);// 生成一个列表，元素是0到9这十个数字
}
string str = string.Join(&quot;,&quot;, list);//0,1,2,3,4,5,6,7,8,9
&lt;/code&gt;
&lt;/pre&gt;

&lt;h2 id=&quot;21-我们是不是同一个&quot;&gt;2.1 我们是不是同一个&lt;/h2&gt;
&lt;p&gt;因为字符串机制的问题，所以一般字符串的相等性比较分为了两种，字面相等性和引用相等性。在C#中默认的相等性比较是字面值相等性。示例：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-c#&quot;&gt;string str1 = &quot;123&quot;;
string str2 = &quot;123&quot;;
string str3 = new string(&quot;123&quot;);
bool eq1 = str1 == str2;// true
bool eq2 = str2 == str3;// true
bool eq3 = str1 == str3;// true
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;那么如何判断是否是同一个引用呢？通过&lt;code&gt;object.ReferenceEquals&lt;/code&gt;来判断是否是同一个引用。继续上面的例子：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-c#&quot;&gt;bool req1 = object.ReferenceEquals(str1, str2);// true
bool req1 = object.ReferenceEquals(str2, str3);// false
bool req3 = object.ReferenceEquals(str1, str3);// false
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;在C#中，编译器会将一样字面值的字符串指向同一个地址，这个地址是在字符串的常量池中。而使用new等方法创建的字符串，是在程序运行后才会确认字符串具体的值，所以这个地址是后分配的。所以上述两种判断方式会出现不同的结果。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;string&lt;/code&gt;类提供了一个静态方法&lt;code&gt;Equals&lt;/code&gt;，方法声明如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-c#&quot;&gt;public static bool Equals (string a, string b);
public static bool Equals (string a, string b, StringComparison comparisonType);
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;该方法返回两个字符串是否是相等的，也就是与字符串默认的&lt;code&gt;==&lt;/code&gt;判断是一致的。&lt;/p&gt;
&lt;h2 id=&quot;22-来比一比高矮&quot;&gt;2.2 来比一比高矮&lt;/h2&gt;
&lt;p&gt;在我们开发的过程中经常会遇到对字符串进行排序的需求，那么字符串排序的逻辑是什么呢？&lt;/p&gt;
&lt;p&gt;对于数字、字母来说是按照ASCII码进行排序的，也就是数字、小写、大写字母这样进行排序。当加入中文后，中文排最后，同种字符按字典顺序进行排序。对于一些跨语言的排序会因为语言不同而导致排序结果不一样。这里有兴趣的可以查看一下微软的官方文档。&lt;/p&gt;
&lt;p&gt;介绍一下字符串排序的基本方法：&lt;code&gt;Compare&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;这个方法有一个对象的相似方法是&lt;code&gt;CompareTo&lt;/code&gt;，这个方法是&lt;code&gt;IComparable&lt;/code&gt;接口定义的方法，与这个方法行为一致。该方法常用的有如下几个定义：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-c#&quot;&gt;public static int Compare (string strA, string strB);
public static int Compare (string strA, string strB, StringComparison comparisonType);
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;这个方法返回一个整型，可以理解为两个字符串之间的距离，正的表示A在B的后面，负的表示A在B的前面。值的绝对值越大，两个字符串之间的距离也越大，但是值本身不具备意义。如果值为0，则表示这两个字符串相等。&lt;/p&gt;
&lt;p&gt;有一个重载版本里有个参数类型是&lt;code&gt;StringComparison&lt;/code&gt;，这是一个枚举类型，用来定义在比较两个字符串时的一些行为，后续有机会详细介绍这一部分。&lt;/p&gt;
&lt;p&gt;示例：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-c#&quot;&gt;string str1 = &quot;123a&quot;;
string str2 = &quot;132a&quot;;
int position1 = string.Compare(str1, str2);// -1
str1 = &quot;你好&quot;;
str2 = &quot;我们&quot;;
int position2 = string.Compare(str1, str2);// -1
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;可以明显看出，排序规则基本就是字典顺序。&lt;/p&gt;

&lt;p&gt;补充三个上一篇文章遗漏的方法，插入、删除、获取一个子串。&lt;/p&gt;
&lt;h2 id=&quot;31-插入到某个位置&quot;&gt;3.1 插入到某个位置&lt;/h2&gt;
&lt;pre&gt;
&lt;code class=&quot;language-c#&quot;&gt;public string Insert (int startIndex, string value);
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;在源字符串指定的位置插入一个字符串并返回插入的结果。&lt;/p&gt;
&lt;h2 id=&quot;32-删除&quot;&gt;3.2 删除&lt;/h2&gt;
&lt;pre&gt;
&lt;code class=&quot;language-c#&quot;&gt;//从startIndex开始，后面的所有元素都删除，包括startIndex，返回剩下的字符
public string Remove (int startIndex);
//从startIndex开始，删除 count个元素，返回剩下的字符
public string Remove (int startIndex, int count);
&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;33-获取一个子串&quot;&gt;3.3 获取一个子串&lt;/h2&gt;
&lt;pre&gt;
&lt;code class=&quot;language-c#&quot;&gt;// 返回从startIndex开始，剩下的的元素，包括startIndex
public string Substring (int startIndex);
// 返回从startIndex开始，一共count个元素的字符串，包括startIndex
public string Substring (int startIndex, int length);
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;这一部分的方法比较简单，就不做示例演示了。不过需要注意的是 所有参数都应该是大于0的，且不能大于字符串的长度，包括 startIndex+count。&lt;/p&gt;

&lt;p&gt;目前为止，字符串的常规使用已经完成了，但是字符串的使用却并没有结束，后续会继续介绍C#其他内容，其中有几个内容是与字符串有很大的关联的，这里先容我卖个关子。&lt;/p&gt;
&lt;blockquote readability=&quot;3.3333333333333&quot;&gt;
&lt;p&gt;更多内容烦请关注&lt;a href=&quot;https://blogs.attachie.club&quot;&gt;我的博客&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/1266612/202004/1266612-20200416230344932-1019239872.png&quot; alt=&quot;file&quot;/&gt;&lt;/p&gt;
</description>
<pubDate>Thu, 16 Apr 2020 15:04:00 +0000</pubDate>
<dc:creator>月影西下</dc:creator>
<og:description>0. 前言 上一篇文章介绍了字符串自身的一些方法，就是对象方法。在字符串体系中，还有一些是 类提供的静态方法。这两部分构成了字符串体系，当然还有一些三方库为字符串提供了扩展方法。 这里简单的介绍一下</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/c7jie/p/12716596.html</dc:identifier>
</item>
</channel>
</rss>