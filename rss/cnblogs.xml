<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="css/feed.xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/" xmlns:og="http://ogp.me/ns#">
<channel>
<atom:link rel="self" href="http://192.168.1.4/fivefilters/makefulltextfeed.php?url=feed.cnblogs.com%2Fblog%2Fsitehome%2Frss&amp;max=10&amp;links=preserve&amp;exc=" />
<atom:link rel="alternate" title="Source URL" href="http://feed.cnblogs.com/blog/sitehome/rss" />
<atom:link rel="related" title="Subscribe to feed" href="http://www.subtome.com/#/subscribe?feeds=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed.cnblogs.com%252Fblog%252Fsitehome%252Frss%26max%3D10%26links%3Dpreserve%26exc%3D&amp;back=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed.cnblogs.com%252Fblog%252Fsitehome%252Frss%26max%3D10%26links%3Dpreserve%26exc%3D" />
<title>博客园_首页</title>
<link></link>
<description>代码改变世界</description>
<item>
<title>关于Oracle的44951事件 - AlfredZhao</title>
<link>http://www.cnblogs.com/jyzhao/p/10340237.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/jyzhao/p/10340237.html</guid>
<description>&lt;p&gt;最近有同事遇到某客户数据库产生大量阻塞，等待事件为：enq HW - contention，最开始采用不断杀会话的方式，效果不好，问题一直高频反复。进一步确认SQL是大量的insert，且插入的表中含有LOB字段，根据经验最终采用设置44951 event缓解了该问题。&lt;/p&gt;
&lt;p&gt;具体关于Oracle的44951事件，可参考Maclean的文章：&lt;/p&gt;
&lt;p&gt;这篇文章中采用的设置方法是：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;alter system set events '44951 trace name context forever, level 1024';&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;需要注意的是，这种设置方法在重启数据库后就会失效，若需要重启后永久生效，需设置event：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;alter system set event='44951 trace name context forever, level 1024' scope=spfile;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;但说到这里就需要深入了解下event和events的区别，这里大概测试总结有如下区别：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;1.events立即生效，重启数据库后消失&lt;/li&gt;
&lt;li&gt;2.events无法直接通过show parameter event查看&lt;/li&gt;
&lt;li&gt;3.event后面必须有等号，重启数据库后生效，可通过show parameter event查看&lt;/li&gt;
&lt;li&gt;4.event需要注意不要覆盖掉之前的event设置，如果这个知识点不理解很容易产生误操作，需要特别注意&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;补充说明：&lt;/strong&gt;&lt;br/&gt;比如在11g的最佳实践中，通常已经设置10949和28401event：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;alter system set event='28401 trace name context forever,level 1','10949 trace name context forever,level 1' sid='*' scope=spfile;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;所以如果有需求额外设置44951 event，就需要将之前的也写上（否则就会覆盖）：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;alter system set event='28401 trace name context forever,level 1','10949 trace name context forever,level 1','44951 trace name context forever,level 1024' sid='*' scope=spfile;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;events设置的值如何查看？使用下面的脚本（注意循环的范围要包含要查询的events）：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;set serveroutput on

declare
event_level number;
begin
for i in 10000..50000 loop
sys.dbms_system.read_ev(i,event_level);
if (event_level &amp;gt; 0) then
dbms_output.put_line('Event '||to_char(i)||' set at level '||
to_char(event_level));
end if;
end loop;
end;
/&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;查询结果类似如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;Event 10949 set at level 1
Event 28401 set at level 1
Event 44951 set at level 1024&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;附:Maclean使用的测试用例：&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;create user maclean identified by maclean;
grant resource, connect, dba to maclean;
conn maclean/maclean

CREATE TABLE &quot;MACLEAN_LOB&quot; ( &quot;T1&quot; VARCHAR2(200) NOT NULL , &quot;T2&quot; CLOB, &quot;T3&quot; CLOB)  tablespace users
    LOB (&quot;T2&quot;) 
    STORE AS  ( TABLESPACE &quot;USERS&quot; CHUNK 16K PCTVERSION 50 CACHE ) 
    LOB (&quot;T3&quot;) 
    STORE AS  ( TABLESPACE &quot;USERS&quot; CHUNK 16K PCTVERSION 50 CACHE );

select segment_space_management from dba_tablespaces where tablespace_name='USERS';

exec dbms_workload_repository.create_snapshot;

--开3个进程并发插入LOB表
begin
for i in 1..10000 loop
 insert into maclean.maclean_lob values ('ABC',rpad('Z',32000,'L'),rpad('Z',32000,'L'));
 end loop;
 commit;
 end;
 /

exec dbms_workload_repository.create_snapshot;
select bytes/1024,segment_name from dba_segments where segment_name in (select segment_name from dba_lobs where table_name='MACLEAN_LOB' and owner='MACLEAN');
truncate table maclean.maclean_lob;
select bytes/1024,segment_name from dba_segments where segment_name in (select segment_name from dba_lobs where table_name='MACLEAN_LOB' and owner='MACLEAN');

alter system flush buffer_cache;
alter system flush shared_pool;

alter system set events '44951 trace name context forever, level 1024';

exec dbms_workload_repository.create_snapshot;

--开3个进程并发插入LOB表
begin
for i in 1..10000 loop
 insert into maclean.maclean_lob values ('ABC',rpad('Z',32000,'L'),rpad('Z',32000,'L'));
 end loop;
 commit;
 end;
 /  

exec dbms_workload_repository.create_snapshot;

select bytes/1024,segment_name from dba_segments where segment_name in (select segment_name from dba_lobs where table_name='MACLEAN_LOB' and owner='MACLEAN');

以上可以看到虽然设置了44951 level 1024，但并不会因为单次bump hwm的chunks数增加而导致大量空间的浪费。 

对比AWR可以发现设置44961 level 1024后 enq HW - contention消耗的DB TIME明显减少：
此外在10.2.0.3之前还有一种方案即设置LOB的PCTVERSION 为0/100，但是该方案会导致LOB占用的SPACE大幅上升，所以不推荐，你有大量的理由至少升级DB到10.2.0.5.9。 &lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;通过这个测试用例实验效果，确实设置前后的效果明显：&lt;br/&gt;&lt;img src=&quot;https://www.cnblogs.com/images/cnblogs_com/jyzhao/846011/o_44951event_effect.png&quot;/&gt;&lt;br/&gt;&lt;img src=&quot;https://www.cnblogs.com/images/cnblogs_com/jyzhao/846011/o_44951event_effect2.png&quot;/&gt;&lt;br/&gt;&lt;strong&gt;注意：&lt;/strong&gt;这里主要看enq HW - contention的优化效果，其他event也有调整优化空间，但不在本文讨论范围。&lt;/p&gt;
</description>
<pubDate>Wed, 30 Jan 2019 23:39:00 +0000</pubDate>
<dc:creator>AlfredZhao</dc:creator>
<og:description>最近有同事遇到某客户数据库产生大量阻塞，等待事件为：enq HW contention，最开始采用不断杀会话的方式，效果不好，问题一直高频反复。进一步确认SQL是大量的insert，且插入的表中含有L</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/jyzhao/p/10340237.html</dc:identifier>
</item>
<item>
<title>asp.net core microservices 架构之分布式自动计算（三）-kafka日志同步至elasticsearch和kibana展示 - 无为有道</title>
<link>http://www.cnblogs.com/ck0074451665/p/10340387.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/ck0074451665/p/10340387.html</guid>
<description>
&lt;p&gt;&lt;span&gt;一 kafka consumer准备                       &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;　　前面的章节进行了分布式job的自动计算的概念讲解以及实践。上次分布式日志说过日志写进kafka，是需要进行处理，以便合理的进行展示，分布式日志的量和我们对日志的重视程度，决定了我们必须要有一个大数据检索，和友好展示的需求。那么自然就是elasticsearch和kibana，elasticsearch是可以检索TB级别数据的一个分布式NOSQL数据库，而kibana，不仅仅可以展示详情，而且有针对不同展示需求的功能，并且定制了很多很多日志格式的模板和采集数据的插件，这里不多介绍了，我自己感觉是比percona的pmm强大很多。&lt;/p&gt;
&lt;p&gt;　　书归正传，我们这一节是要做同步前的准备工作。第一，对kafka的consumer进行封装。第二,读取kafka数据是需要一个后台程序去处理，但是不需要job，我们上次做的框架是基于zookeeper的分布式job，而kafka的分布式是在服务器端的，当然将job分布式设计方案用在轮询或者阻塞方式的后台程序，也是可以的，但是这次就不讲解了。下面我们就将kafka分布式的原理分析下，kafka的客户端有一个组的概念，borker端有一个topic的概念，product在发送消息的时候，会有一个key值。因为kafka存数据就是以key-value的方式存储数据的，所以broker就是用product传递过来的这个key进行运算，合理的将数据存储到某个topic的某个分区。而consumer端订阅topic，可以订阅多个topic,它的分派是这样的，每一个topic下的分区会有多个consuer，但是这些consumer必须属于不同的组，而每一个consumer可以订阅多个topic下的分区，但是不能重复。下面看图吧，以我们这次实际的日志为例，在kafka中mylog topic有5个分区。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/46403/201901/46403-20190131013327062-1247547222.png&quot; alt=&quot;&quot; width=&quot;1235&quot; height=&quot;763&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　那么如果我们有三个程序需要用这个mylog topic怎么办？而且我们需要很快的处理完这个数据，所以有可能这三个程序每一个程序都要两台服务器。想着都很头大，对吧？当然如果有我们前面讲解的分布式job也可以处理，但是要把分布式的功能迁移到这个后台程序，避免不了又大动干戈，开发，调试，测试，修改bug，直到程序稳定，那又是一场苦功。但是在kafka这里，不用担心，三个程序，比如订单，库存，顾客，我们为这三个程序的kafka客户端对应的设置为三个组，每一个组中consumer数量只要不超过5个，假如订单需要用到名为mylog的topic的消息，只要订单处理这个topic的实例数量，必须不能超过5个，当然可以少于5个，也可以等于0个。而同时一个consumer又可以去订阅多个topic，这也是kafka可以媲美rabbit的重要的一个原因，先天支持并发和扩展。我们看图：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/46403/201901/46403-20190131020029215-2124566158.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;如果一个组的consumer数量没有topic的分区多，kafka会自动分派给这个组的consumer，如果某一个consumer失败，kafka也会自动的将这个consumer的offset记录并且分派给另外一个consumer。&lt;/p&gt;
&lt;p&gt;下面看看我们封装的kafka客户端方法：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;44&quot;&gt;
&lt;pre&gt;
&lt;span&gt;using&lt;/span&gt;&lt;span&gt; System;
&lt;/span&gt;&lt;span&gt;using&lt;/span&gt;&lt;span&gt; System.Collections.Generic;
&lt;/span&gt;&lt;span&gt;using&lt;/span&gt;&lt;span&gt; System.Threading.Tasks;
&lt;/span&gt;&lt;span&gt;using&lt;/span&gt;&lt;span&gt; Confluent.Kafka;
&lt;/span&gt;&lt;span&gt;using&lt;/span&gt;&lt;span&gt; Microsoft.Extensions.Options;

&lt;/span&gt;&lt;span&gt;namespace&lt;/span&gt;&lt;span&gt;  Walt.Framework.Service.Kafka
{
    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;&lt;span&gt; KafkaService : IKafkaService
    {

        &lt;/span&gt;&lt;span&gt;private&lt;/span&gt;&lt;span&gt; KafkaOptions _kafkaOptions;
        &lt;/span&gt;&lt;span&gt;private&lt;/span&gt;&lt;span&gt; Producer _producer;
        &lt;/span&gt;&lt;span&gt;private&lt;/span&gt;&lt;span&gt; Consumer _consumer;

        &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; Action&amp;lt;Message&amp;gt; GetMessageDele{ &lt;span&gt;get&lt;/span&gt;; &lt;span&gt;set&lt;/span&gt;&lt;span&gt;; }

        &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; Action&amp;lt;Error&amp;gt; ErrorDele{ &lt;span&gt;get&lt;/span&gt;; &lt;span&gt;set&lt;/span&gt;&lt;span&gt;; }

        &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; Action&amp;lt;LogMessage&amp;gt; LogDele{ &lt;span&gt;get&lt;/span&gt;; &lt;span&gt;set&lt;/span&gt;&lt;span&gt;; }

        &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; KafkaService(IOptionsMonitor&amp;lt;KafkaOptions&amp;gt;&lt;span&gt;  kafkaOptions)
        {
            _kafkaOptions&lt;/span&gt;=&lt;span&gt;kafkaOptions.CurrentValue; 
            kafkaOptions.OnChange((kafkaOpt,s)&lt;/span&gt;=&amp;gt;&lt;span&gt;{
                _kafkaOptions&lt;/span&gt;=&lt;span&gt;kafkaOpt; 
                    System.Diagnostics.Debug
                    .WriteLine(Newtonsoft.Json.JsonConvert.SerializeObject(kafkaOpt)&lt;/span&gt;+&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;---&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;+&lt;span&gt;s);
            });
             _producer&lt;/span&gt;=&lt;span&gt;new&lt;/span&gt;&lt;span&gt; Producer(_kafkaOptions.Properties);

            _consumer&lt;/span&gt;=&lt;span&gt;new&lt;/span&gt;&lt;span&gt; Consumer(_kafkaOptions.Properties);
        }

        &lt;/span&gt;&lt;span&gt;private&lt;/span&gt; &lt;span&gt;byte&lt;/span&gt;[] ConvertToByte(&lt;span&gt;string&lt;/span&gt;&lt;span&gt; str)
        {
            &lt;/span&gt;&lt;span&gt;return&lt;/span&gt;&lt;span&gt; System.Text.Encoding.Default.GetBytes(str);
        }
 
        &lt;/span&gt;&lt;span&gt;public&lt;/span&gt;  &lt;span&gt;async&lt;/span&gt; Task&amp;lt;Message&amp;gt; Producer&amp;lt;T&amp;gt;(&lt;span&gt;string&lt;/span&gt; topic,&lt;span&gt;string&lt;/span&gt;&lt;span&gt; key,T t)
        {  
            &lt;/span&gt;&lt;span&gt;if&lt;/span&gt;(&lt;span&gt;string&lt;/span&gt;&lt;span&gt;.IsNullOrEmpty(topic)
            &lt;/span&gt;|| t==&lt;span&gt;null&lt;/span&gt;&lt;span&gt;)
            {
                &lt;/span&gt;&lt;span&gt;throw&lt;/span&gt; &lt;span&gt;new&lt;/span&gt; ArgumentNullException(&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;topic或者value不能为null.&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;);
            }
            &lt;/span&gt;&lt;span&gt;string&lt;/span&gt; data =&lt;span&gt; Newtonsoft.Json.JsonConvert.SerializeObject(t);
            &lt;/span&gt;&lt;span&gt;var&lt;/span&gt; task=  &lt;span&gt;await&lt;/span&gt;&lt;span&gt; _producer.ProduceAsync(topic,ConvertToByte(key),ConvertToByte(data)); 
           &lt;/span&gt;&lt;span&gt;return&lt;/span&gt;&lt;span&gt; task;
        }


        &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt;&lt;span&gt; AddProductEvent()
        {
            _producer.OnError&lt;/span&gt;+=&lt;span&gt;new&lt;/span&gt; EventHandler&amp;lt;Error&amp;gt;&lt;span&gt;(Error);
            _producer.OnLog&lt;/span&gt;+=&lt;span&gt;new&lt;/span&gt; EventHandler&amp;lt;LogMessage&amp;gt;&lt;span&gt;(Log);
        }
　　　　&lt;span&gt;　　///以事件的方式获取message
        &lt;/span&gt;&lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; AddConsumerEvent(IEnumerable&amp;lt;&lt;span&gt;string&lt;/span&gt;&amp;gt;&lt;span&gt; topics)
        {
            _consumer.Subscribe(topics);
            _consumer.OnMessage &lt;/span&gt;+= &lt;span&gt;new&lt;/span&gt; EventHandler&amp;lt;Message&amp;gt;&lt;span&gt;(GetMessage);
            _consumer.OnError &lt;/span&gt;+= &lt;span&gt;new&lt;/span&gt; EventHandler&amp;lt;Error&amp;gt;&lt;span&gt;(Error);
            _consumer.OnLog &lt;/span&gt;+= &lt;span&gt;new&lt;/span&gt; EventHandler&amp;lt;LogMessage&amp;gt;&lt;span&gt;(Log);
        }

        &lt;/span&gt;&lt;span&gt;private&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; GetMessage(&lt;span&gt;object&lt;/span&gt;&lt;span&gt; sender, Message mess)
        {
            &lt;/span&gt;&lt;span&gt;if&lt;/span&gt;(GetMessageDele!=&lt;span&gt;null&lt;/span&gt;&lt;span&gt;)
            {
                GetMessageDele(mess);
            }
        }

        &lt;/span&gt;&lt;span&gt;private&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; Error(&lt;span&gt;object&lt;/span&gt;&lt;span&gt; sender, Error mess)
        {
            &lt;/span&gt;&lt;span&gt;if&lt;/span&gt;(ErrorDele!=&lt;span&gt;null&lt;/span&gt;&lt;span&gt;)
            {
                ErrorDele(mess);
            }
        }

        &lt;/span&gt;&lt;span&gt;private&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; Log(&lt;span&gt;object&lt;/span&gt;&lt;span&gt; sender, LogMessage mess)
        {
            &lt;/span&gt;&lt;span&gt;if&lt;/span&gt;(LogDele!=&lt;span&gt;null&lt;/span&gt;&lt;span&gt;)
            {
                LogDele(mess);
            }
        }
　　　　　&lt;span&gt;//以轮询的方式获取message
        &lt;/span&gt;&lt;/span&gt;&lt;span&gt;public&lt;/span&gt; Message Poll(&lt;span&gt;int&lt;/span&gt;&lt;span&gt; timeoutMilliseconds)
        {
            Message message &lt;/span&gt;=&lt;span&gt;default&lt;/span&gt;&lt;span&gt;(Message);
            _consumer.Consume(&lt;/span&gt;&lt;span&gt;out&lt;/span&gt;&lt;span&gt; message, timeoutMilliseconds);
            &lt;/span&gt;&lt;span&gt;return&lt;/span&gt;&lt;span&gt; message;
        }
    }
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;以事件激发的方式，因为是线程安全的方式调用，而本实例是后台方式执行，少不了多线程，所以还是以轮询的方式。以轮询的方式，这样的程序需要放那块尼？就是我们的后台程序框架。&lt;/p&gt;

&lt;p&gt;&lt;span&gt;&lt;span&gt;二 后台程序管理框架开发                                            &lt;/span&gt;      &lt;/span&gt;  &lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/46403/201901/46403-20190131020901311-184945455.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;他的原理和job几乎差不多，比job要简单多了。看入口程序：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;59&quot;&gt;
&lt;pre&gt;
&lt;span&gt;using&lt;/span&gt;&lt;span&gt; System;
&lt;/span&gt;&lt;span&gt;using&lt;/span&gt;&lt;span&gt; System.Collections.Generic;
&lt;/span&gt;&lt;span&gt;using&lt;/span&gt;&lt;span&gt; System.Collections.ObjectModel;
&lt;/span&gt;&lt;span&gt;using&lt;/span&gt;&lt;span&gt; System.IO;
&lt;/span&gt;&lt;span&gt;using&lt;/span&gt;&lt;span&gt; System.Linq;
&lt;/span&gt;&lt;span&gt;using&lt;/span&gt;&lt;span&gt; System.Reflection;
&lt;/span&gt;&lt;span&gt;using&lt;/span&gt;&lt;span&gt; System.Threading.Tasks;
&lt;/span&gt;&lt;span&gt;using&lt;/span&gt;&lt;span&gt; Microsoft.AspNetCore;
&lt;/span&gt;&lt;span&gt;using&lt;/span&gt;&lt;span&gt; Microsoft.AspNetCore.Hosting;
&lt;/span&gt;&lt;span&gt;using&lt;/span&gt;&lt;span&gt; Microsoft.Extensions.Configuration;
&lt;/span&gt;&lt;span&gt;using&lt;/span&gt;&lt;span&gt; Microsoft.Extensions.DependencyInjection;
&lt;/span&gt;&lt;span&gt;using&lt;/span&gt;&lt;span&gt; Microsoft.Extensions.Hosting;
&lt;/span&gt;&lt;span&gt;using&lt;/span&gt;&lt;span&gt; Microsoft.Extensions.Logging;
&lt;/span&gt;&lt;span&gt;using&lt;/span&gt; EnvironmentName =&lt;span&gt; Microsoft.Extensions.Hosting.EnvironmentName;
&lt;/span&gt;&lt;span&gt;using&lt;/span&gt;&lt;span&gt; Walt.Framework.Log;
&lt;/span&gt;&lt;span&gt;using&lt;/span&gt;&lt;span&gt; Walt.Framework.Service;
&lt;/span&gt;&lt;span&gt;using&lt;/span&gt;&lt;span&gt; Walt.Framework.Service.Kafka;
&lt;/span&gt;&lt;span&gt;using&lt;/span&gt;&lt;span&gt; Walt.Framework.Configuration;
&lt;/span&gt;&lt;span&gt;using&lt;/span&gt;&lt;span&gt; MySql.Data.EntityFrameworkCore;
&lt;/span&gt;&lt;span&gt;using&lt;/span&gt;&lt;span&gt; Microsoft.EntityFrameworkCore;
&lt;/span&gt;&lt;span&gt;using&lt;/span&gt;&lt;span&gt; System.Threading;
&lt;/span&gt;&lt;span&gt;using&lt;/span&gt; IApplicationLife =&lt;span&gt;Microsoft.Extensions.Hosting;
&lt;/span&gt;&lt;span&gt;using&lt;/span&gt; IApplicationLifetime =&lt;span&gt; Microsoft.Extensions.Hosting.IApplicationLifetime;

&lt;/span&gt;&lt;span&gt;namespace&lt;/span&gt;&lt;span&gt; Walt.Framework.Console
{
    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;&lt;span&gt; Program
    {
        &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; Main(&lt;span&gt;string&lt;/span&gt;&lt;span&gt;[] args)
        {
            &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;这里获取程序及和工作线程配置信息&lt;/span&gt;
            Dictionary&amp;lt;&lt;span&gt;string&lt;/span&gt;, Assembly&amp;gt; assmblyColl = &lt;span&gt;new&lt;/span&gt; Dictionary&amp;lt;&lt;span&gt;string&lt;/span&gt;, Assembly&amp;gt;&lt;span&gt;();
            &lt;/span&gt;&lt;span&gt;var&lt;/span&gt; host = &lt;span&gt;new&lt;/span&gt;&lt;span&gt; HostBuilder()
                    .UseEnvironment(EnvironmentName.Development)
                
                    .ConfigureAppConfiguration((hostContext, configApp) &lt;/span&gt;=&amp;gt;&lt;span&gt;
                    {
                        &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;这里netcore支持多数据源，所以可以扩展到数据库或者redis，集中进行配置。
                        &lt;/span&gt;&lt;span&gt;//
&lt;/span&gt;&lt;span&gt;                        configApp.SetBasePath(Directory.GetCurrentDirectory());
                        configApp.AddJsonFile(
                              $&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;appsettings.{hostContext.HostingEnvironment.EnvironmentName}.json&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;,
                                 optional: &lt;/span&gt;&lt;span&gt;true&lt;/span&gt;&lt;span&gt;);
                        configApp.AddEnvironmentVariables(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;PREFIX_&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;);
                        configApp.AddCommandLine(args);
                    }).ConfigureLogging((hostContext, configBuild) &lt;/span&gt;=&amp;gt;&lt;span&gt;
                    {
                        configBuild.AddConfiguration(hostContext.Configuration.GetSection(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;Logging&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;));
                        configBuild.AddConsole();
                        configBuild.AddCustomizationLogger();
                    })
                    .ConfigureServices((hostContext, service) &lt;/span&gt;=&amp;gt;&lt;span&gt;
                    {
                        service.Configure&lt;/span&gt;&amp;lt;HostOptions&amp;gt;(option =&amp;gt;&lt;span&gt;
                        {
                            option.ShutdownTimeout &lt;/span&gt;= System.TimeSpan.FromSeconds(&lt;span&gt;10&lt;/span&gt;&lt;span&gt;);
                        });

                        service.AddKafka(KafkaBuilder &lt;/span&gt;=&amp;gt;&lt;span&gt;
                        {
                            KafkaBuilder.AddConfiguration(hostContext.Configuration.GetSection(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;KafkaService&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;));
                        });
                        service.AddElasticsearchClient(config&lt;/span&gt;=&amp;gt;&lt;span&gt;{
                            config.AddConfiguration(hostContext.Configuration.GetSection(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;ElasticsearchService&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;));
                        });

                        service.AddDbContext&lt;/span&gt;&amp;lt;ConsoleDbContext&amp;gt;(option =&amp;gt;&lt;span&gt;
                        option.UseMySQL(hostContext.Configuration.GetConnectionString(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;ConsoleDatabase&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;)), ServiceLifetime.Transient, ServiceLifetime.Transient);
                        &lt;/span&gt;&lt;span&gt;///&lt;/span&gt;&lt;span&gt;TODO 待实现从数据库中pull数据，再将任务添加进DI&lt;/span&gt;
                        service.AddSingleton&amp;lt;IConsole,KafkaToElasticsearch&amp;gt;&lt;span&gt;();
                    })
                    .Build();
             CancellationTokenSource source &lt;/span&gt;= &lt;span&gt;new&lt;/span&gt;&lt;span&gt; CancellationTokenSource();
            CancellationToken token &lt;/span&gt;=&lt;span&gt; source.Token;
            &lt;/span&gt;&lt;span&gt;var&lt;/span&gt; task=Task.Run(&lt;span&gt;async&lt;/span&gt; () =&amp;gt;&lt;span&gt;{
                IConsole console &lt;/span&gt;= host.Services.GetService&amp;lt;IConsole&amp;gt;&lt;span&gt;();
                &lt;/span&gt;&lt;span&gt;await&lt;/span&gt;&lt;span&gt; console.AsyncExcute(source.Token);
            },source.Token);
            Dictionary&lt;/span&gt;&amp;lt;&lt;span&gt;string&lt;/span&gt;, Task&amp;gt; dictTask = &lt;span&gt;new&lt;/span&gt; Dictionary&amp;lt;&lt;span&gt;string&lt;/span&gt;, Task&amp;gt;&lt;span&gt;();
            dictTask.Add(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;kafkatoelasticsearch&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;, task);

            &lt;/span&gt;&lt;span&gt;int&lt;/span&gt; recordRunCount = &lt;span&gt;0&lt;/span&gt;&lt;span&gt;;
            &lt;/span&gt;&lt;span&gt;var&lt;/span&gt; fact = host.Services.GetService&amp;lt;ILoggerFactory&amp;gt;&lt;span&gt;();
            &lt;/span&gt;&lt;span&gt;var&lt;/span&gt; log = fact.CreateLogger&amp;lt;Program&amp;gt;&lt;span&gt;();
            &lt;/span&gt;&lt;span&gt;var&lt;/span&gt; disp = Task.Run(() =&amp;gt;&lt;span&gt;
            {
                &lt;/span&gt;&lt;span&gt;while&lt;/span&gt; (&lt;span&gt;true&lt;/span&gt;&lt;span&gt;)
                {
                    &lt;/span&gt;&lt;span&gt;if&lt;/span&gt; (!&lt;span&gt;token.IsCancellationRequested)
                    {
                        &lt;/span&gt;++&lt;span&gt;recordRunCount;
                        &lt;/span&gt;&lt;span&gt;foreach&lt;/span&gt; (KeyValuePair&amp;lt;&lt;span&gt;string&lt;/span&gt;, Task&amp;gt; item &lt;span&gt;in&lt;/span&gt;&lt;span&gt; dictTask)
                        {
                            &lt;/span&gt;&lt;span&gt;if&lt;/span&gt;&lt;span&gt; (item.Value.IsCanceled
                            &lt;/span&gt;||&lt;span&gt; item.Value.IsCompleted
                            &lt;/span&gt;||&lt;span&gt; item.Value.IsCompletedSuccessfully
                            &lt;/span&gt;||&lt;span&gt; item.Value.IsFaulted)
                            {
                                log.LogWarning(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;console任务：{0}，参数：{1}，执行异常,task状态：{2}&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;, item.Key, &lt;span&gt;&quot;&quot;&lt;/span&gt;&lt;span&gt;, item.Value.Status);
                                &lt;/span&gt;&lt;span&gt;if&lt;/span&gt; (item.Value.Exception != &lt;span&gt;null&lt;/span&gt;&lt;span&gt;)
                                {
                                    log.LogError(item.Value.Exception, &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;task:{0},参数：{1}，执行错误.&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;, item.Key, &lt;span&gt;&quot;&quot;&lt;/span&gt;&lt;span&gt;);
                                    &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;TODO 根据参数更新数据库状态，以便被监控到。&lt;/span&gt;
&lt;span&gt;                                }
                                &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;更新数据库状态。&lt;/span&gt;
&lt;span&gt;                            }
                        }
                    }
                    System.Threading.Thread.Sleep(&lt;/span&gt;&lt;span&gt;2000&lt;/span&gt;&lt;span&gt;);
                    log.LogInformation(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;循环：{0}次，接下来等待2秒。&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;, recordRunCount);
                }
            },source.Token);
            
            IApplicationLifetime appLiftTime &lt;/span&gt;= host.Services.GetService&amp;lt;IApplicationLifetime&amp;gt;&lt;span&gt;();
            appLiftTime.ApplicationStopping.Register(()&lt;/span&gt;=&amp;gt;&lt;span&gt;{
                log.LogInformation(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;程序停止中。&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;);
                source.Cancel();
                log.LogInformation(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;程序停止完成。&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;);
            });
            host.RunAsync().GetAwaiter().GetResult();
        }
    }
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;因为分布式job有quartz，是有自己的设计理念，但是这个console后台框架不需要，是自己开发，所以完全和Host通用主机兼容，所有的部件都可以DI。设计原理就是以数据库的配置，构造Task，然后使用&lt;/p&gt;
&lt;pre&gt;
&lt;span&gt;CancellationTokenSource和TaskCompletionSource去管理Task。运行结果根据状态去更新数据库，以便监控。当然咱们这个例子功能没实现全，后面可以完善&lt;br/&gt;，感兴趣的可以去我的github上pull代码。咱们看任务中的例子代码：&lt;br/&gt;&lt;/span&gt;
&lt;/pre&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;61&quot;&gt;
&lt;pre readability=&quot;5&quot;&gt;
&lt;span&gt;using&lt;/span&gt;&lt;span&gt; System.Collections.Generic;
&lt;/span&gt;&lt;span&gt;using&lt;/span&gt;&lt;span&gt; System.Threading;
&lt;/span&gt;&lt;span&gt;using&lt;/span&gt;&lt;span&gt; System.Threading.Tasks;
&lt;/span&gt;&lt;span&gt;using&lt;/span&gt;&lt;span&gt; Confluent.Kafka;
&lt;/span&gt;&lt;span&gt;using&lt;/span&gt;&lt;span&gt; Microsoft.Extensions.Configuration;
&lt;/span&gt;&lt;span&gt;using&lt;/span&gt;&lt;span&gt; Microsoft.Extensions.Logging;
&lt;/span&gt;&lt;span&gt;using&lt;/span&gt;&lt;span&gt; Nest;
&lt;/span&gt;&lt;span&gt;using&lt;/span&gt;&lt;span&gt; Walt.Framework.Log;
&lt;/span&gt;&lt;span&gt;using&lt;/span&gt;&lt;span&gt; Walt.Framework.Service.Elasticsearch;
&lt;/span&gt;&lt;span&gt;using&lt;/span&gt;&lt;span&gt; Walt.Framework.Service.Kafka;

&lt;/span&gt;&lt;span&gt;namespace&lt;/span&gt;&lt;span&gt; Walt.Framework.Console
{
    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;&lt;span&gt; KafkaToElasticsearch : IConsole
    {
        ILoggerFactory _logFact;

        IConfiguration _config;

        IElasticsearchService _elasticsearch;

        IKafkaService _kafkaService;

        &lt;/span&gt;&lt;span&gt;public&lt;/span&gt;&lt;span&gt; KafkaToElasticsearch(ILoggerFactory logFact,IConfiguration config
        ,IElasticsearchService elasticsearch
        ,IKafkaService kafkaService)
        {
            _logFact &lt;/span&gt;=&lt;span&gt; logFact;
            _config &lt;/span&gt;=&lt;span&gt; config;
            _elasticsearch &lt;/span&gt;=&lt;span&gt; elasticsearch;
            _kafkaService &lt;/span&gt;=&lt;span&gt; kafkaService;
        }
        &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;async&lt;/span&gt; Task AsyncExcute(CancellationToken cancel=&lt;span&gt;default&lt;/span&gt;&lt;span&gt;(CancellationToken))
        {
            &lt;/span&gt;&lt;span&gt;var&lt;/span&gt; log = _logFact.CreateLogger&amp;lt;KafkaToElasticsearch&amp;gt;&lt;span&gt;();
            _kafkaService.AddConsumerEvent(&lt;/span&gt;&lt;span&gt;new&lt;/span&gt; List&amp;lt;&lt;span&gt;string&lt;/span&gt;&amp;gt;(){&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;mylog&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span readability=&quot;2&quot;&gt;});&lt;p&gt;　　　　　　　　&lt;span&gt;//以事件方式获取message不工作，因为跨线程
            &lt;/span&gt;&lt;/p&gt;&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; _kafkaService.GetMessageDele = (message) =&amp;gt; {
            &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;     var id = message.Key;
            &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;     var offset = string.Format(&quot;{0}---{2}&quot;,message.Offset.IsSpecial,message.Offset.Value);
            &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;     var topic = message.Topic;
            &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;     var topicPartition = message.TopicPartition.Partition.ToString();
            &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;     var topicPartitionOffsetValue = message.TopicPartitionOffset.Offset.Value;
            &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;     &lt;span&gt;//&lt;/span&gt;&lt;span&gt; log.LogInformation(&quot;id:{0},offset:{1},topic:{2},topicpatiton:{3},topicPartitionOffsetValue:{4}&quot;
            &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;     &lt;span&gt;//&lt;/span&gt;&lt;span&gt; ,id,offset,topic,topicPartition,topicPartitionOffsetValue);
            &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; };
            &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;  _kafkaService.ErrorDele = (message) =&amp;gt; {
            &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;      log.LogError(message.ToString());
            &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;  };
            &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;  _kafkaService.LogDele = (message) =&amp;gt; { 
            &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;      log.LogInformation(message.ToString());
            &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; };
            &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; log.LogInformation(&quot;事件添加完毕&quot;);
            &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; var waitForStop = 
            &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; new TaskCompletionSource&amp;lt;object&amp;gt;(TaskCreationOptions.RunContinuationsAsynchronously);
            &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; cancel.Register(()=&amp;gt;{
            &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;     log.LogInformation(&quot;task执行被取消回掉函数&quot;);
            &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;     waitForStop.SetResult(null);
            &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; });
            &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; waitForStop.Task.Wait();
            &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; log.LogInformation(&quot;任务已经被取消。&quot;);&lt;/span&gt;
&lt;br/&gt;　　　　　　　&lt;span&gt;　//下面以轮询方式。&lt;/span&gt;
            &lt;span&gt;if&lt;/span&gt;(!&lt;span&gt;cancel.IsCancellationRequested)
            {
                &lt;/span&gt;&lt;span&gt;while&lt;/span&gt; (&lt;span&gt;true&lt;/span&gt;&lt;span&gt;)
                {
                    Message message &lt;/span&gt;= _kafkaService.Poll(&lt;span&gt;2000&lt;/span&gt;&lt;span&gt;);
                    &lt;/span&gt;&lt;span&gt;if&lt;/span&gt; (message != &lt;span&gt;null&lt;/span&gt;&lt;span&gt;)
                    {
                        &lt;/span&gt;&lt;span&gt;if&lt;/span&gt;(message.Error!=&lt;span&gt;null&lt;/span&gt;&amp;amp;&amp;amp;message.Error.Code!=&lt;span&gt;ErrorCode.NoError)
                        {
                            &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;log.LogError(&quot;consumer获取message出错,详细信息：{0}&quot;,message.Error);&lt;/span&gt;
                            System.Console.WriteLine(&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;consumer获取message出错,详细信息：{0}&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;,message.Error);
                            System.Threading.Thread.Sleep(&lt;/span&gt;&lt;span&gt;200&lt;/span&gt;&lt;span&gt;);
                            &lt;/span&gt;&lt;span&gt;continue&lt;/span&gt;&lt;span&gt;;
                        }
                        &lt;/span&gt;&lt;span&gt;var&lt;/span&gt; id =message.Key==&lt;span&gt;null&lt;/span&gt;?&lt;span&gt;&quot;&quot;&lt;/span&gt;&lt;span&gt;:System.Text.Encoding.Default.GetString(message.Key);
                        &lt;/span&gt;&lt;span&gt;var&lt;/span&gt; offset = &lt;span&gt;string&lt;/span&gt;.Format(&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;{0}---{1}&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;, message.Offset.IsSpecial, message.Offset.Value);
                        &lt;/span&gt;&lt;span&gt;var&lt;/span&gt; topic =&lt;span&gt; message.Topic;
                        &lt;/span&gt;&lt;span&gt;var&lt;/span&gt; topicPartition =&lt;span&gt; message.TopicPartition.Partition.ToString();
                        &lt;/span&gt;&lt;span&gt;var&lt;/span&gt; topicPartitionOffsetValue =&lt;span&gt; message.TopicPartitionOffset.Offset.Value;
                        &lt;/span&gt;&lt;span&gt;var&lt;/span&gt; val =&lt;span&gt;System.Text.Encoding.Default.GetString( message.Value);
                        EntityMessages entityMess &lt;/span&gt;=&lt;span&gt; 
                        Newtonsoft.Json.JsonConvert.DeserializeObject&lt;/span&gt;&amp;lt;EntityMessages&amp;gt;&lt;span&gt;(val);
                        &lt;/span&gt;&lt;span&gt;await&lt;/span&gt;  _elasticsearch.CreateIndexIfNoExists&amp;lt;LogElasticsearch&amp;gt;(&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;mylog&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;+&lt;span&gt;entityMess.OtherFlag);
                        &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; _elasticsearch.CreateMappingIfNoExists&amp;lt;LogElasticsearch&amp;gt;(&quot;mylog&quot;+entityMess.OtherFlag
                        &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span readability=&quot;2&quot;&gt;                 ,&quot;mylog&quot;+entityMess.OtherFlag+&quot;type&quot;,null);&lt;p&gt;　　　　　　　　　　　　　　&lt;span&gt;//为elasticsearch添加document&lt;/span&gt;&lt;/p&gt;&lt;/span&gt;
                        &lt;span&gt;var&lt;/span&gt; addDocumentResponse = &lt;span&gt;await&lt;/span&gt; _elasticsearch.CreateDocument&amp;lt;LogElasticsearch&amp;gt;(&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;mylog&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; +&lt;span&gt; entityMess.OtherFlag
                                , &lt;/span&gt;&lt;span&gt;new&lt;/span&gt;&lt;span&gt; LogElasticsearch()
                                {
                                    Id &lt;/span&gt;=&lt;span&gt; entityMess.Id,
                                    Time &lt;/span&gt;=&lt;span&gt; entityMess.DateTime,
                                    LogLevel &lt;/span&gt;=&lt;span&gt; entityMess.LogLevel,
                                    Exception &lt;/span&gt;=&lt;span&gt; entityMess.Message
                                }
                        );
                        &lt;/span&gt;&lt;span&gt;if&lt;/span&gt; (addDocumentResponse != &lt;span&gt;null&lt;/span&gt;&lt;span&gt;)
                        {
                            &lt;/span&gt;&lt;span&gt;if&lt;/span&gt; (!&lt;span&gt;addDocumentResponse.ApiCall.Success)
                            {

                            }
                        }
                    }
                }
            }
            &lt;/span&gt;&lt;span&gt;return&lt;/span&gt;&lt;span&gt; ;
        }
    }
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;pre&gt;
&lt;span&gt; &lt;/span&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;span&gt; 三 elasticsearch 服务开发                             &lt;/span&gt;            &lt;/p&gt;
&lt;p&gt;　　服务已经开发很多了，主要就是构建和配置的设计，还有就是对组件的封装，看程序结构：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/46403/201901/46403-20190131022131227-2106150948.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;配置：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;47&quot;&gt;
&lt;pre&gt;
&lt;span&gt;{
  &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;Logging&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;: {
    &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;LogLevel&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;: {
      &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;Default&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;Information&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;,
      &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;System&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;Information&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;,
      &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;Microsoft&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;Information&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;
    },
    &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;KafkaLog&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;:{
      &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;Prix&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;:&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;console&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;, &lt;span&gt;//目前这个属性，可以放程序类别，比如用户中心，商品等。
      &lt;/span&gt;&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;LogStoreTopic&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;:&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;mylog&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;
    }
  },
  &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;KafkaService&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;:{
    &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;Properties&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;:{
      &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;bootstrap.servers&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;:&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;192.168.249.106:9092&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;,
      &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;group.id&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;:&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;group2&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;
    }
  },
  &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;ConnectionStrings&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;: {
    &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;ConsoleDatabase&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;:&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;Server=192.168.249.106;Database=quartz;Uid=quartz;Pwd=quartz&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;
  },
  &lt;/span&gt;&lt;span&gt;&quot;ElasticsearchService&quot;:{
    &quot;Host&quot;:[&quot;http://192.168.249.105:9200&quot;,&quot;http://localhost:9200&quot;],
    &quot;TimeOut&quot;:&quot;10000&quot;,
    &quot;User&quot;:&quot;&quot;,
    &quot;Pass&quot;:&quot;&quot;&lt;/span&gt;&lt;span&gt;&lt;span&gt;
  }&lt;/span&gt;
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;服务类：这里有必要说下，elasticsearch是基于api的接口，最底层就是http请求，在接口上，实现了一个高级的接口和一个低级别的接口，当然低级别的接口需要熟悉elasticsearch的协议，&lt;/p&gt;
&lt;p&gt;而高级别的api，使用强类型去使用，对开发很有帮助。下面是封装elasticsearch的服务类：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;52&quot;&gt;
&lt;pre&gt;
&lt;span&gt;using&lt;/span&gt;&lt;span&gt; System;
&lt;/span&gt;&lt;span&gt;using&lt;/span&gt;&lt;span&gt; System.Net.Http;
&lt;/span&gt;&lt;span&gt;using&lt;/span&gt;&lt;span&gt; Elasticsearch.Net;
&lt;/span&gt;&lt;span&gt;using&lt;/span&gt;&lt;span&gt; Microsoft.Extensions.Options;
&lt;/span&gt;&lt;span&gt;using&lt;/span&gt;&lt;span&gt; System.Threading.Tasks;
&lt;/span&gt;&lt;span&gt;using&lt;/span&gt;&lt;span&gt; Microsoft.Extensions.Logging;
&lt;/span&gt;&lt;span&gt;using&lt;/span&gt;&lt;span&gt; Nest;

&lt;/span&gt;&lt;span&gt;namespace&lt;/span&gt;&lt;span&gt; Walt.Framework.Service.Elasticsearch
{
    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;&lt;span&gt; ElasticsearchService:IElasticsearchService
    {

        &lt;/span&gt;&lt;span&gt;private&lt;/span&gt;  ElasticsearchOptions _elasticsearchOptions=&lt;span&gt;null&lt;/span&gt;&lt;span&gt;;

        &lt;/span&gt;&lt;span&gt;private&lt;/span&gt; ElasticClient _elasticClient = &lt;span&gt;null&lt;/span&gt;&lt;span&gt;;

        &lt;/span&gt;&lt;span&gt;private&lt;/span&gt;&lt;span&gt; ILoggerFactory _loggerFac;

        &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; ElasticsearchService(IOptionsMonitor&amp;lt;ElasticsearchOptions&amp;gt;&lt;span&gt;  options
        ,ILoggerFactory loggerFac)
        {
            _elasticsearchOptions &lt;/span&gt;=&lt;span&gt; options.CurrentValue;
             options.OnChange((elasticsearchOpt,s)&lt;/span&gt;=&amp;gt;&lt;span&gt;{
                _elasticsearchOptions&lt;/span&gt;=&lt;span&gt;elasticsearchOpt; 
                    System.Diagnostics.Debug
                    .WriteLine(Newtonsoft.Json.JsonConvert.SerializeObject(elasticsearchOpt)&lt;/span&gt;+&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;---&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;+&lt;span&gt;s);
            });
　　　　　　　&lt;span&gt;//连接客户端需，支持多个节点，防止单点故障
            &lt;/span&gt;&lt;/span&gt;&lt;span&gt;var&lt;/span&gt; lowlevelClient = &lt;span&gt;new&lt;/span&gt;&lt;span&gt; ElasticLowLevelClient();
            &lt;/span&gt;&lt;span&gt;var&lt;/span&gt; urlColl = &lt;span&gt;new&lt;/span&gt;&lt;span&gt; Uri[_elasticsearchOptions.Host.Length];
            &lt;/span&gt;&lt;span&gt;for&lt;/span&gt; (&lt;span&gt;int&lt;/span&gt; i = &lt;span&gt;0&lt;/span&gt;; i &amp;lt; _elasticsearchOptions.Host.Length;i++&lt;span&gt;)
            {
                urlColl[i] &lt;/span&gt;= &lt;span&gt;new&lt;/span&gt;&lt;span&gt; Uri(_elasticsearchOptions.Host[i]);
            }
            _loggerFac &lt;/span&gt;=&lt;span&gt; loggerFac;
            &lt;/span&gt;&lt;span&gt;var&lt;/span&gt; connectionPool = &lt;span&gt;new&lt;/span&gt;&lt;span&gt; SniffingConnectionPool(urlColl);
            &lt;/span&gt;&lt;span&gt;var&lt;/span&gt; settings = &lt;span&gt;new&lt;/span&gt;&lt;span&gt; ConnectionSettings(connectionPool)
            .RequestTimeout(TimeSpan.FromMinutes(_elasticsearchOptions.TimeOut))
            .DefaultIndex(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;mylogjob&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;);&lt;span&gt;//设置默认的index&lt;/span&gt;
            _elasticClient &lt;/span&gt;= &lt;span&gt;new&lt;/span&gt;&lt;span&gt; ElasticClient(settings);
        }&lt;br/&gt;　　　　　&lt;span&gt;//如果index存在，则返回，如果不存在，则创建，type的创建方式是为文档类型打标签&lt;/span&gt;&lt;/span&gt;&lt;span&gt;ElasticsearchTypeAttribute&lt;/span&gt;
&lt;/pre&gt;
&lt;pre&gt;
&lt;span&gt;public&lt;/span&gt; &lt;span&gt;async&lt;/span&gt; Task&amp;lt;&lt;span&gt;bool&lt;/span&gt;&amp;gt; CreateIndexIfNoExists&amp;lt;T&amp;gt;(&lt;span&gt;string&lt;/span&gt; indexName) &lt;span&gt;where&lt;/span&gt; T : &lt;span&gt;class&lt;/span&gt;&lt;span&gt;
        {

            &lt;/span&gt;&lt;span&gt;var&lt;/span&gt; log = _loggerFac.CreateLogger&amp;lt;ElasticsearchService&amp;gt;&lt;span&gt;();
            &lt;/span&gt;&lt;span&gt;var&lt;/span&gt; exists = &lt;span&gt;await&lt;/span&gt;&lt;span&gt; _elasticClient.IndexExistsAsync(Indices.Index(indexName));
            &lt;/span&gt;&lt;span&gt;if&lt;/span&gt;&lt;span&gt; (exists.Exists)
            {
                log.LogWarning(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;index:{0}已经存在&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;, indexName.ToString());
                &lt;/span&gt;&lt;span&gt;return&lt;/span&gt; &lt;span&gt;await&lt;/span&gt; Task.FromResult(&lt;span&gt;true&lt;/span&gt;&lt;span&gt;);
            }
            &lt;/span&gt;&lt;span&gt;var&lt;/span&gt; response = &lt;span&gt;await&lt;/span&gt;&lt;span&gt; _elasticClient.CreateIndexAsync(indexName
                ,c&lt;/span&gt;=&amp;gt;c.Mappings(mm=&amp;gt;mm.Map&amp;lt;T&amp;gt;(m=&amp;gt;&lt;span&gt;m.AutoMap())));&lt;span&gt;//将类型的属性自动映射到index的type上，也可以打标签控制那个可以映射，那些不可以&lt;/span&gt;
            log.LogInformation(response.DebugInformation);
            &lt;/span&gt;&lt;span&gt;if&lt;/span&gt;&lt;span&gt; (response.Acknowledged)
            {
                log.LogInformation(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;index:{0},创建成功&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;, indexName.ToString());
                &lt;/span&gt;&lt;span&gt;return&lt;/span&gt; &lt;span&gt;await&lt;/span&gt; Task.FromResult(&lt;span&gt;false&lt;/span&gt;&lt;span&gt;);
            }
            &lt;/span&gt;&lt;span&gt;else&lt;/span&gt;&lt;span&gt;
            {
                log.LogError(response.ServerError.ToString());
                log.LogError(response.OriginalException.ToString());
                &lt;/span&gt;&lt;span&gt;return&lt;/span&gt; &lt;span&gt;await&lt;/span&gt; Task.FromResult(&lt;span&gt;false&lt;/span&gt;&lt;span&gt;);
            }
        }

&lt;/span&gt;

　　　　　&lt;span&gt;//创建document&lt;/span&gt;
        &lt;span&gt;public&lt;/span&gt; &lt;span&gt;async&lt;/span&gt; Task&amp;lt;ICreateResponse&amp;gt; CreateDocument&amp;lt;T&amp;gt;(&lt;span&gt;string&lt;/span&gt; indexName,T  t) &lt;span&gt;where&lt;/span&gt; T:&lt;span&gt;class&lt;/span&gt;&lt;span&gt;
        {
            &lt;/span&gt;&lt;span&gt;var&lt;/span&gt; log=_loggerFac.CreateLogger&amp;lt;ElasticsearchService&amp;gt;&lt;span&gt;(); 
            &lt;/span&gt;&lt;span&gt;if&lt;/span&gt;(t==&lt;span&gt;null&lt;/span&gt;&lt;span&gt;)
            {
                log.LogError(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;bulk 参数不能为空。&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;);
                &lt;/span&gt;&lt;span&gt;return&lt;/span&gt; &lt;span&gt;null&lt;/span&gt;&lt;span&gt;;
            }
            IndexRequest&lt;/span&gt;&amp;lt;T&amp;gt; request = &lt;span&gt;new&lt;/span&gt; IndexRequest&amp;lt;T&amp;gt;(indexName, TypeName.From&amp;lt;T&amp;gt;()) { Document =&lt;span&gt; t };
             
             &lt;/span&gt;&lt;span&gt;var&lt;/span&gt; createResponse = &lt;span&gt;await&lt;/span&gt; _elasticClient.CreateDocumentAsync&amp;lt;T&amp;gt;&lt;span&gt;(t);
             log.LogInformation(createResponse.DebugInformation);
            &lt;/span&gt;&lt;span&gt;if&lt;/span&gt;&lt;span&gt; (createResponse.ApiCall.Success)
            {
                log.LogInformation(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;index:{0},type:{1},创建成功&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;, createResponse.Index, createResponse.Type);
                &lt;/span&gt;&lt;span&gt;return&lt;/span&gt;&lt;span&gt; createResponse;
            }
            &lt;/span&gt;&lt;span&gt;else&lt;/span&gt;&lt;span&gt;
            {
                log.LogError(createResponse.ServerError.ToString());
                log.LogError(createResponse.OriginalException.ToString());
                &lt;/span&gt;&lt;span&gt;return&lt;/span&gt; &lt;span&gt;null&lt;/span&gt;&lt;span&gt;;
            }
        }
    }
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;poco类型，这个类会和index的typ相关联的：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;35&quot;&gt;
&lt;pre&gt;
&lt;span&gt;using&lt;/span&gt;&lt;span&gt; System;
&lt;/span&gt;&lt;span&gt;using&lt;/span&gt;&lt;span&gt; Nest;

&lt;/span&gt;&lt;span&gt;namespace&lt;/span&gt;&lt;span&gt; Walt.Framework.Console
{
    [ElasticsearchTypeAttribute(Name&lt;/span&gt;=&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;LogElasticsearchDefaultType&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;)] &lt;span&gt;//可以使用类型生成和查找type
    &lt;/span&gt;&lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;&lt;span&gt; LogElasticsearch
    {
        &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;string&lt;/span&gt; Id { &lt;span&gt;get&lt;/span&gt;; &lt;span&gt;set&lt;/span&gt;&lt;span&gt;; }

        &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; DateTime Time { &lt;span&gt;get&lt;/span&gt;; &lt;span&gt;set&lt;/span&gt;&lt;span&gt;; }

        &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;string&lt;/span&gt; LogLevel{ &lt;span&gt;get&lt;/span&gt;; &lt;span&gt;set&lt;/span&gt;&lt;span&gt;; }

        &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;string&lt;/span&gt; Exception{ &lt;span&gt;get&lt;/span&gt;; &lt;span&gt;set&lt;/span&gt;&lt;span&gt;; }

        &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;string&lt;/span&gt; Mess{ &lt;span&gt;get&lt;/span&gt;; &lt;span&gt;set&lt;/span&gt;&lt;span&gt;; }
    }
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;然后就是执行我们console后台程序，就可以在kibana看到日志被同步的情况：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/46403/201901/46403-20190131023110418-1625994217.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt; 所有程序都提交到github，如果调试代码，再看这篇文章，或许理解能更快。&lt;/p&gt;

</description>
<pubDate>Wed, 30 Jan 2019 18:33:00 +0000</pubDate>
<dc:creator>无为有道</dc:creator>
<og:description>一 kafka consumer准备 前面的章节进行了分布式job的自动计算的概念讲解以及实践。上次分布式日志说过日志写进kafka，是需要进行处理，以便合理的进行展示，分布式日志的量和我们对日志的重</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/ck0074451665/p/10340387.html</dc:identifier>
</item>
<item>
<title>[IOT] 自制蓝牙工牌办公室定位系统 （二）—— 基于ESP32的蓝牙信号扫描系统 - beautifulzzzz</title>
<link>http://www.cnblogs.com/zjutlitao/p/10328544.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/zjutlitao/p/10328544.html</guid>
<description>&lt;p&gt; &lt;br/&gt;&lt;strong&gt;前面章节：&lt;/strong&gt;&lt;/p&gt;

&lt;hr/&gt;&lt;p&gt; &lt;br/&gt;&lt;strong&gt;目录：&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;1、蓝牙广播简介&lt;/li&gt;
&lt;li&gt;2、蓝牙扫描简介&lt;/li&gt;
&lt;li&gt;3、基于蓝牙广播和蓝牙扫描常见应用&lt;/li&gt;
&lt;li&gt;4、ESP32简介&lt;/li&gt;
&lt;li&gt;5、ESP32开发环境搭建&lt;/li&gt;
&lt;li&gt;6、基于ESP32的蓝牙扫描实现&lt;/li&gt;
&lt;li&gt;7、效果展示&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt; &lt;br/&gt;&lt;strong&gt;前言：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;我们整个基于蓝牙beacon的办公室定位系统主要有两部分组成：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;1）蓝牙信号扫描器（蓝牙扫描+数据上云）&lt;/li&gt;
&lt;li&gt;2）基于beacon的低功耗工牌&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;上一节我们讲解了如何将数据通过ESP32上传到云端，本节主要讲如何用ESP32扫描周边蓝牙设备。&lt;/p&gt;

&lt;h4 id=&quot;蓝牙广播简介&quot;&gt;1、蓝牙广播简介&lt;/h4&gt;
&lt;p&gt;蓝牙就在我们身边：电子信标引导消防员穿过建筑物; 可穿戴医疗设备将患者的生物数据发送给医生的平板电脑; 40万平方英尺仓库的设备监控等。蓝牙技术正在蓬勃发展，预计到2021年将有超过480亿的安装基数（per ABI Internet of Everything Market Tracker）。&lt;/p&gt;
&lt;p&gt;那么蓝牙是如何工作的呢？BLE（蓝牙低功耗） 在2.4GHz的ISM频段中有40个物理信道，每个信道之间相隔2MHz。蓝牙定义了两种传输类型：数据传输和广播传输。因此，这40个频道中有3个专门用于广播，37个专门用于数据。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://tuchuang.beautifulzzzz.com:3000/?path=/0f/aecb22c8e8f062276aedd17339ebaa.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt; &lt;br/&gt;广播主要会涉及下面几个参数：&lt;/p&gt;
&lt;table&gt;&lt;thead/&gt;&lt;tbody readability=&quot;4.5&quot;&gt;&lt;tr class=&quot;odd&quot; readability=&quot;2&quot;&gt;&lt;td&gt;Advertising Interval&lt;/td&gt;
&lt;td&gt;Time between the start of two consecutive advertising events&lt;/td&gt;
&lt;td&gt;20ms to 10.24s&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;even&quot; readability=&quot;2&quot;&gt;&lt;td&gt;Advertising Types&lt;/td&gt;
&lt;td&gt;Different PDUs are sent for different types of advertising&lt;/td&gt;
&lt;td&gt;See following&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;odd&quot; readability=&quot;5&quot;&gt;&lt;td&gt;Advertising Channels&lt;/td&gt;
&lt;td&gt;Legacy advertising packets are sent on three channels&lt;/td&gt;
&lt;td&gt;Different combinations of channels 37, 38 and 39.&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt; &lt;br/&gt;一般情况下，广播信道有channel 37 (2402 MHz), channel 38 (2426 MHz), and channel 39 (2480 MHz)。设备可以在其中一个、两个或三个上进行广播，下图展示了在所有三个频道上进行广播的事件：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://tuchuang.beautifulzzzz.com:3000/?path=/2f/e258048ae0c7aa6d360cbc7affe271.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt; &lt;br/&gt;注意，上列中是在所有通道上都发送了相同的数据（ADV_IND）。由于数据包非常小（广播数据不超过31字节），发送它所需的时间不到10毫秒。设备可以修改为仅在选定的频道上进行广播。在较少的频道上进行广播将节省电力，但是使用更多的频道将增加对等设备接收数据包的可能性。用户可以根据应用程序用例配置广播间隔。例如，如果门锁以较慢的间隔进行广播，则对等设备连接到门锁将需要更长的时间，这将对用户体验产生不利影响。&lt;/p&gt;
&lt;p&gt; &lt;br/&gt;无论是beacon（传输位置、天气或其他数据）还是与主机（平板电脑或手机）建立长期连接的健身手表，所有外围设备，至少在最初都是以广播模式开始的。&lt;/p&gt;
&lt;p&gt;Advertising允许设备去广播有意图的信息。&lt;/p&gt;
&lt;p&gt;那么，蓝牙的广播是怎样的呢？&lt;/p&gt;
&lt;p&gt;为了便于使用，蓝牙为广播和数据传输定义了一种单一的数据包格式。这个包由四个部分组成：前导码（1字节）、访问地址（4字节）、协议数据单元（2-257字节）和循环冗余校验（3字节）；见下图：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://tuchuang.beautifulzzzz.com:3000/?path=/b2/79dad0c57d2544ab863fd654eb356a.jpg&quot;/&gt;&lt;/p&gt;
&lt;p&gt; &lt;br/&gt;PDU部分比较重要，因为它定义了该数据包是广播包还是数据包。在我们解析来的讨论中，将重点讨论广播PUD包。&lt;/p&gt;
&lt;p&gt;广播PUD包包含16 bits 的头和不定长度的payload：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://tuchuang.beautifulzzzz.com:3000/?path=/ae/2d698cce777a49dd4821576e9dd644.jpg&quot;/&gt;&lt;/p&gt;
&lt;p&gt;广播的头部包含6部分，我们主要关注Length和PUD Type两部分。Length长6bits，定义了payload的长度。Length的取值范围是6-27字节（取决于PUD Type）。&lt;/p&gt;
&lt;p&gt;OK，现在我们知道了广播的时候会有几字节的16进制数据在payload中，但是为什么广播呢？这就要提到PUD Type了。在蓝牙低功耗中，有两个原因需要广播：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;在设备（如智能手表和电话）之间建立双向连接。&lt;/li&gt;
&lt;li&gt;或者在不与其他设备连接的情况下广播信息，例如在博物馆里一个信标发送数据，告诉你身后5英尺处有一具500年前的木乃伊尸体。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt; &lt;br/&gt;因此，无论是智能手表还是木乃伊都在争夺关注，我们开发人员则需要关注4种PDU类型：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;ADV_IND
&lt;ul&gt;&lt;li&gt;广播指示：设备请求连接中心设备（不是针对特殊的指定的中心设备）&lt;/li&gt;
&lt;li&gt;例如：智能手表请求连接任何中心设备&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;ADV_DIRECT_IND
&lt;ul&gt;&lt;li&gt;类似ADV_IND，只是是针对特殊中心设备&lt;/li&gt;
&lt;li&gt;例如：智能手表请求连接特殊中心设备&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;ADV_NONCONN_IND
&lt;ul&gt;&lt;li&gt;不可连接的设备，广播信息到任何收听设备&lt;/li&gt;
&lt;li&gt;例如：博物馆的信标定义了临近的特定展品的信息&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;ADV_SCAN_IND
&lt;ul&gt;&lt;li&gt;类似ADV_SCAN_IND，是响应扫描的附加可选信息&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt; &lt;br/&gt;所以，当需要维持长期连接时，PDU的类型应设置为ADV_IND或ADV_DIRECT_IND；当只是广播一些信息，不需要维持长期连接时，ADV_NONCONN_IND和ADV_SCAN_IND将会被用上，beacon常用ADV_NONCONN_IND，当需要广播更多信息的时候，可以把信息放在scan回复中，选用ADV_SCAN_IND。&lt;/p&gt;
&lt;p&gt;无论是请求长期连接还是作为beacon，这一切都始于广播。&lt;/p&gt;

&lt;h4 id=&quot;蓝牙扫描简介&quot;&gt;2、蓝牙扫描简介&lt;/h4&gt;
&lt;p&gt;当BLE设备未被连接时，可以通过发送广播包来宣传它们的存在，或者扫描附近正在广播的设备。扫描设备的过程被成为设备发现。扫描有两种类型：主动扫描和被动扫描。区别在于：主动扫描器可以主动发送一个扫描请求，请求广播设备进行广播回复；而被动扫描器只能被动扫描广播信息。下图显示了扫描器在广播事件期间向广广播客户发送扫描请求的时序：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://tuchuang.beautifulzzzz.com:3000/?path=/cd/f9e46d0a55a8f5c878ab80e27ff2af.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;当涉及到扫描时间时，您需要熟悉一些参数。每个参数都有一个由蓝牙核心规范指定的范围。帧间时隙（T_IFS）是同一信道上两个连续数据包之间的时间间隔，由BLE规范设置为150us。&lt;/p&gt;
&lt;table&gt;&lt;thead/&gt;&lt;tbody readability=&quot;3&quot;&gt;&lt;tr class=&quot;odd&quot; readability=&quot;2&quot;&gt;&lt;td&gt;Scan Interval&lt;/td&gt;
&lt;td&gt;The interval between the start of two consecutive scan windows&lt;/td&gt;
&lt;td&gt;10ms to 10.24s&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;even&quot; readability=&quot;2&quot;&gt;&lt;td&gt;Scan Window&lt;/td&gt;
&lt;td&gt;The duration in which the Link Layer scans on one channel&lt;/td&gt;
&lt;td&gt;10ms to 10.24s&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;odd&quot; readability=&quot;2&quot;&gt;&lt;td&gt;Scan Duration&lt;/td&gt;
&lt;td&gt;The duration in which the device stays in the scanning state&lt;/td&gt;
&lt;td&gt;10ms to infinity&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt; &lt;br/&gt;下图展示了这些参数的关系：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://tuchuang.beautifulzzzz.com:3000/?path=/7b/b876b75ab85ac26275f2bfcd12e76a.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;请注意，扫描通道的顺序是固定的。设备将分别在通道37（2402MHz）、通道38（2426MHz）和通道39（2480MHz）上进行扫描，并按照扫描窗口定义的时间长度在每个扫描间隔上进行扫描。&lt;/p&gt;
&lt;p&gt;二级广播信道上的可扫描广播包也可以引发扫描请求和扫描响应。这些被称为AUX_SCAN_REQ and AUX_SCAN_RSP。下表总结了所有与扫描相关的数据包：&lt;/p&gt;
&lt;table&gt;&lt;thead/&gt;&lt;tbody readability=&quot;4&quot;&gt;&lt;tr class=&quot;odd&quot; readability=&quot;2&quot;&gt;&lt;td&gt;SCAN_REQ&lt;/td&gt;
&lt;td&gt;Scanner&lt;/td&gt;
&lt;td&gt;Scanner's address + advertiser's address&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;even&quot; readability=&quot;2&quot;&gt;&lt;td&gt;SCAN_RSP&lt;/td&gt;
&lt;td&gt;Advertiser&lt;/td&gt;
&lt;td&gt;Advertiser's address + 0-31 bytes scan response data&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;odd&quot; readability=&quot;2&quot;&gt;&lt;td&gt;AUX_SCAN_REQ&lt;/td&gt;
&lt;td&gt;Scanner&lt;/td&gt;
&lt;td&gt;Scanner's address + advertiser's address&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;even&quot; readability=&quot;2&quot;&gt;&lt;td&gt;AUX_SCAN_RSP&lt;/td&gt;
&lt;td&gt;Advertiser&lt;/td&gt;
&lt;td&gt;Header + 0-254 bytes data&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;h4 id=&quot;基于蓝牙广播和蓝牙扫描常见应用&quot;&gt;3、基于蓝牙广播和蓝牙扫描常见应用&lt;/h4&gt;
&lt;p&gt;蓝牙广播常见的应用有：beacon、室内定位、靠近开门、广播小数据信息等，维基百科&lt;sup&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Bluetooth_advertising&quot;&gt;[3]&lt;/a&gt;&lt;/sup&gt;上的总结有如下场景：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;Broadcast location-based coupons.&lt;/li&gt;
&lt;li&gt;Contextual advertising.&lt;/li&gt;
&lt;li&gt;Localized information.&lt;/li&gt;
&lt;li&gt;Gaming and music.&lt;/li&gt;
&lt;li&gt;Content on demand.&lt;/li&gt;
&lt;li&gt;Specific and targeted campaign.&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;注：蓝牙5的定位、广播将更具诱人特性。&lt;/p&gt;

&lt;h4 id=&quot;esp32简介&quot;&gt;4、ESP32简介&lt;/h4&gt;
&lt;p&gt;ESP32是一款2.4 GHz Wi-Fi和蓝牙组合芯片，采用TSMC超低功耗40纳米技术设计。它的设计是为了获得最佳的功率和射频性能，在各种应用和电源方案中显示出鲁棒性、通用性和可靠性。&lt;/p&gt;
&lt;p&gt;ESP32 系列芯片包括：ESP32-D0WDQ6, ESP32-D0WD, ESP32-D2WD, and ESP32-S0WD。其架构图如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://tuchuang.beautifulzzzz.com:3000/?path=/7b/a358d52270490fbae356fbc5180899.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt; &lt;br/&gt;我们实验用了乐鑫官方的一个开发板：ESP32-WROOM-32。该开发板是一款功能强大的通用Wi-Fi+BT+BLE MCU模块，面向各种应用，从低功耗传感器网络到最苛刻的任务，如语音编码、音乐流和MP3解码。&lt;/p&gt;
&lt;p&gt;该模块采用EP32-D0WDQ6芯片，该芯片是双核芯片、可独立控制，时钟频率可以从80MHz ~ 240MHz。用户还可以关闭CPU电源，并利用低功耗协处理器持续监控外围设备的变化或是否超过阈值。ESP32集成了一套丰富的外围设备，包括电容式触摸传感器、霍尔传感器、SD卡接口、以太网、高速SPI、UART、I2s和I2c。&lt;/p&gt;
&lt;p&gt;集成了蓝牙、BLE和Wi-Fi，代表着未来：使用WIFI可通过路由器连接到互联网，而使用蓝牙则方便用户连接到手机和低功耗。ESP32芯片的休眠电流小于5uA，因此适用于电池供电和可穿戴电子设备应用。ESP32支持高达150 Mbps的数据速率和20.5 dBm的输出功率，以确保最宽的物理范围。因此，该芯片确实为电子集成、范围、功耗和连接性提供了行业领先的规格和最佳性能。&lt;/p&gt;
&lt;p&gt;ESP32可选的操作系统是freeRTOS with LwIP + TLS 1.2 + 硬件内部加速 + 加密的OTA技术。下表是ESP32-WROOM-32的资源总览：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://tuchuang.beautifulzzzz.com:3000/?path=/ea/54217a64d7ad0a0fc1ee0d084fc113.png&quot;/&gt;&lt;/p&gt;

&lt;h4 id=&quot;esp32开发环境搭建&quot;&gt;5、ESP32开发环境搭建&lt;/h4&gt;
&lt;p&gt;通过下面两个资料，大家可以自行搭建环境：&lt;/p&gt;
&lt;p&gt; &lt;br/&gt;&lt;strong&gt;不过！&lt;/strong&gt;作为系统洁癖和拒绝重复造轮子的博主，已经写了一个全自动构建环境的脚本、并把该工具在github上开源了：esp32_linux_tool &lt;sup&gt;&lt;a href=&quot;https://github.com/nbtool/esp32_linux_tool&quot;&gt;[13]&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;&lt;sub&gt;&lt;strong&gt;注：&lt;/strong&gt;nbtool是博主专门放自己造的或收集到的牛逼轮子的github组&lt;/sub&gt;&lt;/p&gt;
&lt;p&gt; &lt;br/&gt;博主造的这个轮子比较好用，基于&lt;strong&gt;all-in-one思想&lt;/strong&gt;(所有相关文件在一个文件夹下；所有相关环境变量不需要额外配置）：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;#!/bin/bash

set -e

PROJECT_ROOT=..
TOOLS_PATH=$PROJECT_ROOT/tool
SDK_PATH=$PROJECT_ROOT/sdk
APP_PATH=$PROJECT_ROOT/app

XTENSA_ESP32_ELF_PATH=$TOOLS_PATH/xtensa-esp32-elf
ESP_IDF_PATH=$SDK_PATH/esp-idf

XTENSA_ESP32_ELF_LINK=https://dl.espressif.com/dl/xtensa-esp32-elf-linux64-1.22.0-80-g6c4433a-5.2.0.tar.gz
ESP_IDF_LINK=https://github.com/espressif/esp-idf.git   

#--------------------------------------------------------------------------
function install_tool_chain(){
    echo &quot;&amp;gt; install tool chain ...&quot;
    echo &quot;&amp;gt; web page: https://docs.espressif.com/projects/esp-idf/zh_CN/v3.1.1/get-started/linux-setup.html&quot;
    if [ ! -d $XTENSA_ESP32_ELF_PATH ]; then
        wget $XTENSA_ESP32_ELF_LINK 
        tar -xzf xtensa-esp32-elf*.tar.gz
        rm xtensa-esp32-elf*.tar.gz
    fi
}

function install_esp_idf(){
    echo &quot;&amp;gt; install esp idf ...&quot;
    echo &quot;&amp;gt; web page: https://github.com/espressif/esp-idf&quot;
    if [ ! -d $ESP_IDF_PATH ]; then
        git clone $ESP_IDF_LINK 
        mv esp-idf $SDK_PATH/
    fi
}

function create_project(){
    if [ &quot;$1&quot; == &quot;&quot; ] || [ &quot;$2&quot; == &quot;&quot; ]; then
        echo &quot;input error&quot;
    elif [ -d $1 ] &amp;amp;&amp;amp; [ ! -d &quot;$APP_PATH/$2&quot; ]; then
        cp -r $1 $APP_PATH/$2
       

        file=$APP_PATH/$2/run.sh
        the_sdk_path=`cd $ESP_IDF_PATH; pwd`
        the_tool_chain_path=`cd $XTENSA_ESP32_ELF_PATH/bin; pwd`

cat &amp;gt; $file &amp;lt;&amp;lt;EOF
#!/bin/bash
#I don't like to set environment variables in the system, 
#so I put the environment variables in run.sh.
#Every time I use run.sh, the enviroment variables will be set, after use that will be unsetted.
PROJECT_ROOT=../..
TOOLS_PATH=\$PROJECT_ROOT/tool
SDK_PATH=\$PROJECT_ROOT/sdk
APP_PATH=\$PROJECT_ROOT/app
XTENSA_ESP32_ELF_PATH=\$TOOLS_PATH/xtensa-esp32-elf
ESP_IDF_PATH=\$SDK_PATH/esp-idf
the_sdk_path=\`cd \$ESP_IDF_PATH; pwd\`
the_tool_chain_path=\`cd \$XTENSA_ESP32_ELF_PATH/bin; pwd\`
export PATH=&quot;\$PATH:\$the_tool_chain_path&quot;
export IDF_PATH=&quot;\$the_sdk_path&quot;
if [ &quot;\$1&quot; == &quot;config&quot; ]; then
    make menuconfig
elif [ &quot;\$1&quot; == &quot;build&quot; ]; then
    make all
elif [ &quot;\$1&quot; == &quot;flash&quot; ]; then
    make flash   
elif [ &quot;\$1&quot; == &quot;build-app&quot; ]; then
    make app   
elif [ &quot;\$1&quot; == &quot;flash-app&quot; ]; then
    make app-flash
elif [ &quot;\$1&quot; == &quot;monitor&quot; ]; then
    make monitor   
elif [ &quot;\$1&quot; == &quot;clean&quot; ]; then
    make clean
elif [ &quot;\$1&quot; == &quot;help&quot; ]; then
    echo &quot;bash run.sh config&quot;
    echo &quot;      |- basic configuration by GUI, if we use -j4 to build and flash, we must first config then build or flash!!!&quot;
    echo &quot;bash run.sh build&quot;
    echo &quot;      |- build all&quot;
    echo &quot;bash run.sh flash&quot;
    echo &quot;      |- build all and flash the program&quot;
    echo &quot;bash run.sh build-app&quot;
    echo &quot;      |- just build app, not build bootloader and partition table&quot;
    echo &quot;bash run.sh flash-app&quot;
    echo &quot;      |- just flash app, when bootloader and partition table have not changed, no need to flash&quot;
    echo &quot;      |- more infomation:https://docs.espressif.com/projects/esp-idf/zh_CN/v3.1.1/get-started/make-project.html&quot;
    echo &quot;bash run.sh monitor&quot;
    echo &quot;      |- monitor the program, 'Ctrl+]' to stop&quot;
    echo &quot;      |- IDF Monitor:https://docs.espressif.com/projects/esp-idf/zh_CN/v3.1.1/get-started/idf-monitor.html&quot;
else
    echo &quot;error, try bash run.sh help&quot;
fi
EOF

        chmod +x $file
        ls -all $APP_PATH/$2
    fi
}
#--------------------------------------------------------------------------

function tool(){
    if [ ! -d $SDK_PATH ]; then
        mkdir $SDK_PATH
    fi
    if [ ! -d $APP_PATH ]; then
        mkdir $APP_PATH
    fi

    install_tool_chain
    install_esp_idf
}

function clean(){
    echo &quot;cleaning ....&quot;
    rm -rf $XTENSA_ESP32_ELF_PATH
    rm -rf $ESP_IDF_PATH
    rm -rf $SDK_PATH
}

if [ &quot;$1&quot; == &quot;clean&quot; ]; then
    clean
elif [ &quot;$1&quot; == &quot;tool&quot; ]; then
    tool
elif [ &quot;$1&quot; == &quot;create&quot; ]; then
    create_project $2 $3
elif [ &quot;$1&quot; == &quot;help&quot; ]; then
    echo &quot;bash run.sh tool&quot;
    echo &quot;      |- create the build enviroment, including sdk and tool chain&quot;
    echo &quot;bash run.sh clean&quot;
    echo &quot;      |- clean all the sdk and tools, thats download form web-page when 'bash run.sh tool'&quot;
    echo &quot;bash run.sh create path_of_example_in_sdk new_name_project&quot;
    echo &quot;      |- copy the example in the sdk to app directory, and rename it new_name_project&quot;
else
    echo &quot;error, try bash run.sh help&quot;
fi&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt; &lt;br/&gt;上面的run.sh脚本就是完成开发环境构建、工程创建、编译、烧写、跟踪LOG等复杂功能，大家可以慢慢理解。下面先谈谈如何用该开源项目：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;#克隆项目到本地
&amp;gt; git clone git@github.com:nbtool/esp32_linux_tool.git

#构建esp32开发环境
&amp;gt; cd ./esp32_linux_tool/tool
&amp;gt; ./run.sh help
&amp;gt; ./run.sh tool

#从SDK的example中复制一个DEMO到APP层(例如:hello_world)
&amp;gt; bash run.sh create ../sdk/esp-idf/examples/get-started/hello_world hello_world
&amp;gt; cd ../app/hello_world
&amp;gt; ./run.sh help

#烧写固件
&amp;gt; ./run.sh flash

#查看LOG
&amp;gt; ./run.sh monitor

#清空工程
&amp;gt; ./run.sh clean&lt;/code&gt;
&lt;/pre&gt;

&lt;h4 id=&quot;基于esp32的蓝牙扫描实现&quot;&gt;6、基于ESP32的蓝牙扫描实现&lt;/h4&gt;
&lt;p&gt;由于ESP32的IDF中已经有蓝牙扫描的DEMO，因此我们用下面命令直接从DEMO创建工程：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;bash run.sh create ../sdk/esp-idf/examples/bluetooth/bt_discovery bt_discovery&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt; &lt;br/&gt;之后将 ./app/bt_discovery/main/bt_discovery.c 修改为：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;#include &amp;lt;stdint.h&amp;gt;
#include &amp;lt;string.h&amp;gt;
#include &quot;freertos/FreeRTOS.h&quot;
#include &quot;freertos/task.h&quot;
#include &quot;nvs.h&quot;
#include &quot;nvs_flash.h&quot;
#include &quot;esp_system.h&quot;
#include &quot;esp_log.h&quot;
#include &quot;esp_bt.h&quot;
#include &quot;esp_bt_main.h&quot;
#include &quot;esp_bt_device.h&quot;
#include &quot;esp_gap_bt_api.h&quot;

#define GAP_TAG          &quot;GAP&quot;

typedef enum {
    APP_GAP_STATE_IDLE = 0,
    APP_GAP_STATE_DEVICE_DISCOVERING,
    APP_GAP_STATE_DEVICE_DISCOVER_COMPLETE,
} app_gap_state_t;

typedef struct {
    bool dev_found;
    uint8_t bdname_len;
    uint8_t eir_len;
    uint8_t rssi;
    uint32_t cod;
    uint8_t eir[ESP_BT_GAP_EIR_DATA_LEN];
    uint8_t bdname[ESP_BT_GAP_MAX_BDNAME_LEN + 1];
    esp_bd_addr_t bda;
    app_gap_state_t state;
} app_gap_cb_t;

static app_gap_cb_t m_dev_info;

static char *bda2str(esp_bd_addr_t bda, char *str, size_t size)
{
    if (bda == NULL || str == NULL || size &amp;lt; 18) {
        return NULL;
    }

    uint8_t *p = bda;
    sprintf(str, &quot;%02x:%02x:%02x:%02x:%02x:%02x&quot;,
            p[0], p[1], p[2], p[3], p[4], p[5]);
    return str;
}

static void update_device_info(esp_bt_gap_cb_param_t *param)
{
    char bda_str[18];
    uint32_t cod = 0;
    int32_t rssi = -129; /* invalid value */
    esp_bt_gap_dev_prop_t *p;

    ESP_LOGI(GAP_TAG, &quot;Device found: %s&quot;, bda2str(param-&amp;gt;disc_res.bda, bda_str, 18));
    for (int i = 0; i &amp;lt; param-&amp;gt;disc_res.num_prop; i++) {
        p = param-&amp;gt;disc_res.prop + i;
        switch (p-&amp;gt;type) {
        case ESP_BT_GAP_DEV_PROP_COD:
            cod = *(uint32_t *)(p-&amp;gt;val);
            ESP_LOGI(GAP_TAG, &quot;--Class of Device: 0x%x&quot;, cod);
            break;
        case ESP_BT_GAP_DEV_PROP_RSSI:
            rssi = *(int8_t *)(p-&amp;gt;val);
            ESP_LOGI(GAP_TAG, &quot;--RSSI: %d&quot;, rssi);
            break;
        case ESP_BT_GAP_DEV_PROP_BDNAME:
        default:
            break;
        }
    }

    /* search for device with MAJOR service class as &quot;rendering&quot; in COD */
    app_gap_cb_t *p_dev = &amp;amp;m_dev_info;
    if (p_dev-&amp;gt;dev_found &amp;amp;&amp;amp; 0 != memcmp(param-&amp;gt;disc_res.bda, p_dev-&amp;gt;bda, ESP_BD_ADDR_LEN)) {
        return;
    }

    if (!esp_bt_gap_is_valid_cod(cod) ||
            !(esp_bt_gap_get_cod_major_dev(cod) == ESP_BT_COD_MAJOR_DEV_PHONE)) {
        return;
    }

    memcpy(p_dev-&amp;gt;bda, param-&amp;gt;disc_res.bda, ESP_BD_ADDR_LEN);
    p_dev-&amp;gt;dev_found = true;
    for (int i = 0; i &amp;lt; param-&amp;gt;disc_res.num_prop; i++) {
        p = param-&amp;gt;disc_res.prop + i;
        switch (p-&amp;gt;type) {
        case ESP_BT_GAP_DEV_PROP_COD:
            p_dev-&amp;gt;cod = *(uint32_t *)(p-&amp;gt;val);
            break;
        case ESP_BT_GAP_DEV_PROP_RSSI:
            p_dev-&amp;gt;rssi = *(int8_t *)(p-&amp;gt;val);
            break;
        case ESP_BT_GAP_DEV_PROP_BDNAME: {
            uint8_t len = (p-&amp;gt;len &amp;gt; ESP_BT_GAP_MAX_BDNAME_LEN) ? ESP_BT_GAP_MAX_BDNAME_LEN :
                          (uint8_t)p-&amp;gt;len;
            memcpy(p_dev-&amp;gt;bdname, (uint8_t *)(p-&amp;gt;val), len);
            p_dev-&amp;gt;bdname[len] = '\0';
            p_dev-&amp;gt;bdname_len = len;
            break;
        }
        case ESP_BT_GAP_DEV_PROP_EIR: {
            memcpy(p_dev-&amp;gt;eir, (uint8_t *)(p-&amp;gt;val), p-&amp;gt;len);
            p_dev-&amp;gt;eir_len = p-&amp;gt;len;
            break;
        }
        default:
            break;
        }
    }
}

void bt_app_gap_init(void)
{
    app_gap_cb_t *p_dev = &amp;amp;m_dev_info;
    memset(p_dev, 0, sizeof(app_gap_cb_t));
}

void bt_app_gap_cb(esp_bt_gap_cb_event_t event, esp_bt_gap_cb_param_t *param)
{
    app_gap_cb_t *p_dev = &amp;amp;m_dev_info;
    switch (event) {
    case ESP_BT_GAP_DISC_RES_EVT: {
        update_device_info(param);
        break;
    }
    case ESP_BT_GAP_DISC_STATE_CHANGED_EVT: {
        ESP_LOGE(GAP_TAG, &quot;%d&quot;, p_dev-&amp;gt;state);
        if(p_dev-&amp;gt;state == APP_GAP_STATE_IDLE){
            ESP_LOGE(GAP_TAG, &quot;discovery start ...&quot;);
            p_dev-&amp;gt;state = APP_GAP_STATE_DEVICE_DISCOVERING; 
        }else if(p_dev-&amp;gt;state == APP_GAP_STATE_DEVICE_DISCOVERING){
            ESP_LOGE(GAP_TAG, &quot;discovery timeout ...&quot;);
            p_dev-&amp;gt;state = APP_GAP_STATE_DEVICE_DISCOVER_COMPLETE;
            esp_bt_gap_start_discovery(ESP_BT_INQ_MODE_GENERAL_INQUIRY, 10, 0);
        }else{
            ESP_LOGE(GAP_TAG, &quot;discovery again ...&quot;);
            p_dev-&amp;gt;state = APP_GAP_STATE_IDLE;
        }
        break;
    }
    case ESP_BT_GAP_RMT_SRVCS_EVT: {
        break;
    }
    case ESP_BT_GAP_RMT_SRVC_REC_EVT:
    default: {
        break;
    }
    }
    return;
}

void bt_app_gap_start_up(void)
{
    char *dev_name = &quot;ESP_GAP_INQRUIY&quot;;
    esp_bt_dev_set_device_name(dev_name);

    /* set discoverable and connectable mode, wait to be connected */
    esp_bt_gap_set_scan_mode(ESP_BT_SCAN_MODE_CONNECTABLE_DISCOVERABLE);

    /* register GAP callback function */
    esp_bt_gap_register_callback(bt_app_gap_cb);

    /* inititialize device information and status */
    app_gap_cb_t *p_dev = &amp;amp;m_dev_info;
    memset(p_dev, 0, sizeof(app_gap_cb_t));

    /* start to discover nearby Bluetooth devices */
    p_dev-&amp;gt;state = APP_GAP_STATE_IDLE;
    esp_bt_gap_start_discovery(ESP_BT_INQ_MODE_GENERAL_INQUIRY, 10, 0);
}

void app_main()
{
    /* Initialize NVS — it is used to store PHY calibration data */
    esp_err_t ret = nvs_flash_init();
    if (ret == ESP_ERR_NVS_NO_FREE_PAGES || ret == ESP_ERR_NVS_NEW_VERSION_FOUND) {
        ESP_ERROR_CHECK(nvs_flash_erase());
        ret = nvs_flash_init();
    }
    ESP_ERROR_CHECK( ret );

    ESP_ERROR_CHECK(esp_bt_controller_mem_release(ESP_BT_MODE_BLE));

    esp_bt_controller_config_t bt_cfg = BT_CONTROLLER_INIT_CONFIG_DEFAULT();
    if ((ret = esp_bt_controller_init(&amp;amp;bt_cfg)) != ESP_OK) {
        ESP_LOGE(GAP_TAG, &quot;%s initialize controller failed: %s\n&quot;, __func__, esp_err_to_name(ret));
        return;
    }

    if ((ret = esp_bt_controller_enable(ESP_BT_MODE_CLASSIC_BT)) != ESP_OK) {
        ESP_LOGE(GAP_TAG, &quot;%s enable controller failed: %s\n&quot;, __func__, esp_err_to_name(ret));
        return;
    }

    if ((ret = esp_bluedroid_init()) != ESP_OK) {
        ESP_LOGE(GAP_TAG, &quot;%s initialize bluedroid failed: %s\n&quot;, __func__, esp_err_to_name(ret));
        return;
    }

    if ((ret = esp_bluedroid_enable()) != ESP_OK) {
        ESP_LOGE(GAP_TAG, &quot;%s enable bluedroid failed: %s\n&quot;, __func__, esp_err_to_name(ret));
        return;
    }

    bt_app_gap_start_up();
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt; &lt;br/&gt;逐层调用关系：&lt;/p&gt;
&lt;table&gt;&lt;thead/&gt;&lt;tbody readability=&quot;4.5&quot;&gt;&lt;tr class=&quot;odd&quot; readability=&quot;2&quot;&gt;&lt;td&gt;app_main&lt;/td&gt;
&lt;td&gt;-&amp;gt;&lt;/td&gt;
&lt;td&gt;各种初始化，最后调用 bt_app_gap_start_up&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;even&quot; readability=&quot;2&quot;&gt;&lt;td&gt;bt_app_gap_start_up&lt;/td&gt;
&lt;td&gt;-o&lt;/td&gt;
&lt;td&gt;初始化蓝牙并启动搜索，超时10S，回调事件会被 bt_app_gap_cb 捕捉&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;odd&quot; readability=&quot;3&quot;&gt;&lt;td&gt;bt_app_gap_cb&lt;/td&gt;
&lt;td&gt;o-&amp;gt;&lt;/td&gt;
&lt;td&gt;开始搜索/搜索超时/再次搜索+搜索到设备事件，超时会再次启动10S搜索，搜到设备会调用update_device_info 打印&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;even&quot; readability=&quot;2&quot;&gt;&lt;td&gt;update_device_info&lt;/td&gt;
&lt;td&gt;-o&lt;/td&gt;
&lt;td&gt;将搜索结果打印下来&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;&lt;sub&gt;&lt;strong&gt;注：&lt;/strong&gt;-&amp;gt; 会继续调用其他函数；-o 停止调用其他函数；o-&amp;gt; 回调函数；&lt;/sub&gt;&lt;/p&gt;

&lt;h4 id=&quot;效果展示&quot;&gt;7、效果展示&lt;/h4&gt;
&lt;p&gt;&lt;img src=&quot;http://tuchuang.beautifulzzzz.com:3000/?path=/91/9e7b0638f90f70ba43dfcfb61db895.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;sub&gt;&lt;strong&gt;注：&lt;/strong&gt;周期性扫描，10S超时后继续扫描，扫到之后打印MAC和RSSI&lt;/sub&gt;&lt;/p&gt;
&lt;p&gt;: &lt;span&gt;&lt;strong&gt;完～&lt;/strong&gt;&lt;/span&gt;&lt;br/&gt;: &lt;span&gt;&lt;strong&gt;大家觉得不错，可以点推荐给更多人～&lt;/strong&gt;&lt;/span&gt;&lt;br/&gt;: &lt;span&gt;&lt;strong&gt;最近一段时间准备将这个系列写完，做一套可演示的系统（笑）～&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;

&lt;h3 id=&quot;links&quot;&gt;LINKS&lt;/h3&gt;
&lt;p&gt;&lt;a href=&quot;https://www.cnblogs.com/zjutlitao/p/10269835.html&quot;&gt;[1]. BLOG - 自制蓝牙工牌办公室定位系统 （一）&lt;/a&gt;&lt;br/&gt;&lt;a href=&quot;https://www.bluetooth.com/specifications/bluetooth-core-specification&quot;&gt;[2]. SIG - Bluetooth core specification&lt;/a&gt;&lt;br/&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Bluetooth_advertising&quot;&gt;[3]. WiKi - Bluetooth advertising&lt;/a&gt;&lt;br/&gt;&lt;a href=&quot;https://blog.bluetooth.com/bluetooth-low-energy-it-starts-with-advertising&quot;&gt;[4]. SIG - Bluetooth Low Energy - It starts with Advertising&lt;/a&gt;&lt;br/&gt;&lt;a href=&quot;http://dev.ti.com/tirex/content/simplelink_academy_cc26x2sdk_1_15_03_10/modules/ble5stack/ble_scan_adv_basic/ble_scan_adv_basic.html&quot;&gt;[5]. TI - Bluetooth Low Energy Scanning and Advertising&lt;/a&gt;&lt;br/&gt;&lt;a href=&quot;http://dev.ti.com/tirex/content/simplelink_academy_cc2640r2sdk_1_12_01_16/modules/ble_scan_adv_basic/ble_scan_adv_basic.html&quot;&gt;[6]. TI - Bluetooth Low Energy Scanning and Advertising&lt;/a&gt;&lt;br/&gt;&lt;a href=&quot;https://source.android.com/devices/bluetooth/ble_advertising&quot;&gt;[7]. Android - Bluetooth Low Energy Advertising&lt;/a&gt;&lt;br/&gt;&lt;a href=&quot;https://sites.google.com/a/gclue.jp/ble-docs/advertising-1/advertising&quot;&gt;[8]. BLOG - Advertising(解説)&lt;/a&gt;&lt;br/&gt;&lt;a href=&quot;https://www.espressif.com/sites/default/files/documentation/esp32_datasheet_en.pdf&quot;&gt;[9]. PDF - ESP32 datasheet&lt;/a&gt;&lt;br/&gt;&lt;a href=&quot;https://www.mouser.com/ds/2/891/esp-wroom-32_datasheet_en-1223836.pdf&quot;&gt;[10]. PDF - ESP32-WROOM-32 datasheet&lt;/a&gt;&lt;br/&gt;&lt;a href=&quot;https://github.com/espressif/esp-idf&quot;&gt;[11]. ESP32-IDF GITHUB地址&lt;/a&gt;&lt;br/&gt;&lt;a href=&quot;https://docs.espressif.com/projects/esp-idf/en/v3.1.1/index.html&quot;&gt;[12]. ESP-IDF Program Guide&lt;/a&gt;&lt;br/&gt;&lt;a href=&quot;https://github.com/nbtool/esp32_linux_tool&quot;&gt;[13]. esp32_linux_tool GITHUB地址&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;
&lt;code&gt;@beautifulzzzz
以蓝牙技术为基础的的末梢无线网络系统架构及创新型应用探索！
领域：智能硬件、物联网、自动化、前沿软硬件
博客：https://www.cnblogs.com/zjutlitao/
园友交流群|微信交流群：414948975|园友交流群&lt;/code&gt;
&lt;/pre&gt;</description>
<pubDate>Wed, 30 Jan 2019 17:38:00 +0000</pubDate>
<dc:creator>beautifulzzzz</dc:creator>
<og:description>  前面章节： [自制蓝牙工牌办公室定位系统 （一）—— 阿里物联网平台概览及打通端到云（硬核·干货）][ 1]   目录： 1、蓝牙广播简介 2、蓝牙扫描简介 3、基于蓝牙广播和</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/zjutlitao/p/10328544.html</dc:identifier>
</item>
<item>
<title>Kernel 内核调试 - int80</title>
<link>http://www.cnblogs.com/int80/p/10340282.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/int80/p/10340282.html</guid>
<description>&lt;p&gt;本机环境 Win7 + VMware 14 Pro&lt;/p&gt;
&lt;p&gt;1.安装Qemu，Ubuntu包管理器中的二进制版本比较老了，这里选择源码安装&lt;a href=&quot;https://download.qemu.org/qemu-2.12.0.tar.xz&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;2.12.0版本&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;具体的安装教程可以参考这篇文章《&lt;a href=&quot;https://blog.csdn.net/candcplusplus/article/details/78320602&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;QEMU 2.10.1 编译安装&lt;/a&gt;》，写的非常详细。&lt;/p&gt;
&lt;p&gt;2.下载、编译目标的内核版本&lt;/p&gt;
&lt;p&gt;这里下载的是4.4.1版本的Linux内核  &lt;a href=&quot;https://mirrors.edge.kernel.org/pub/linux/kernel/v4.x/linux-4.4.1.tar.xz&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;linux-4.4.1.tar.xz&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;解压 编译&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;32&quot;&gt;
&lt;pre&gt;
xz - d   linux-&lt;span&gt;4.4&lt;/span&gt;.&lt;span&gt;1&lt;/span&gt;.&lt;span&gt;tar&lt;/span&gt;&lt;span&gt;.xz

&lt;/span&gt;&lt;span&gt;tar&lt;/span&gt; -xvf  linux-&lt;span&gt;4.4&lt;/span&gt;.&lt;span&gt;1&lt;/span&gt;.&lt;span&gt;tar&lt;/span&gt;&lt;span&gt;

cd linux&lt;/span&gt;-&lt;span&gt;4.4&lt;/span&gt;.&lt;span&gt;1&lt;/span&gt;

&lt;span&gt;make&lt;/span&gt; menuconfig
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt; 确保以下三个选项是勾选上的：&lt;/p&gt;
&lt;div readability=&quot;7&quot;&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;34&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
kernel hacking –&amp;gt; Kernel debugging
kernel hacking –&amp;gt; Compile-time checks and compiler options –&amp;gt; compile the kernel with debug info
kernel hacking –&amp;gt; Compile-time checks and compiler options -&amp;gt; compile the kernel with frame pointers
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt; 在多核平台上使用-j 参数来加快编译&lt;/p&gt;

&lt;p&gt;3.制作根文件系统&lt;/p&gt;
&lt;p&gt;先了解以下几个文件的区别，参考这篇&lt;a href=&quot;https://blog.csdn.net/geekcome/article/details/6558754&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;文章&lt;/a&gt;&lt;/p&gt;
&lt;div readability=&quot;10&quot;&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;34&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
vmlinux 是ELF文件，即编译出来的最原始的文件。 

vmlinuz 应该是由ELF文件vmlinux经过OBJCOPY后，并经过压缩后的文件 

zImage 是vmlinuz经过gzip压缩后的文件，适用于小内核

bzImage 是vmlinuz经过gzip压缩后的文件，适用于大内核
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;新建一个目录用于存放生成的内核文件,以及根文件系统：&lt;/p&gt;
&lt;/div&gt;
&lt;div readability=&quot;10.252268602541&quot;&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;35&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
mkdir ~/Desktop/kernel-debug

cp   ./arch/x86/boot/bzImage  ~/Desktop/kernel-debug

cd  ~/Desktop/kernel-debug

dd if=/dev/zero of=rootfs.img bs=1M count=20  #新建一个20M的文件

mkfs -t ext3 rootfs.img #将其格式化为ext3文件系统格式

#将其mount 到新创建到目录rootfs上 

mkdir rootfs 

sudo mount -t ext3 -o loop rootfs.img rootfs 

#将挂载后的根文件系统中建立基本的目录结构

sudo mkdir rootfs/dev rootfs/proc rootfs/sys
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;给系统安装基本的命令行工具，比如ls，这里选择了BusyBox，下载的&lt;a href=&quot;https://busybox.net/downloads/busybox-1.28.3.tar.bz2&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;BusyBox源码&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div readability=&quot;7.5&quot;&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;35&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
cd ~/Desktop/kernel-debug&lt;br/&gt;tar -jxvf busybox-1.28.3.tar.bz2&lt;br/&gt;cd busybox-1.28.3&lt;br/&gt;#进行配置，注意这里选择静态连接的方式生成可执行文件，避免对外部lib有依赖
make menuconfig&lt;br/&gt;#勾选Settings-&amp;gt;Build Busybox as a static binary
make -j
#编译完成后，安装到目标的根文件系统中去，然后unmount掉根文件系统
make install CONFIG_PREFIX=~/Desktop/kernel-debug/rootfs&lt;br/&gt;sudo umount ~/Desktop/kernel-debug/rootfs
&lt;/pre&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;p&gt;4.启动Qemu虚拟机&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;33&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
sudo qemu-system-x86_64  -S -kernel ~/Desktop/kernel-debug/bzImage -hda ~/Desktop/kernel-debug/rootfs.img -append &quot;root=/dev/sda init=/bin/ash&quot;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;此时启动的Qemu处于Pasued状态，单机黑色区域，让Qemu接收输入，按下ctrl+ alt + 2，切换到控制台。&lt;/p&gt;
&lt;p&gt;注意之后可以通过ctrl + alt + G 来让qemu释放鼠标以及键盘输入。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/771012/201901/771012-20190131000421499-1290927327.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;启动gdbserver，监听到8888端口，便于用GDB来远程调试。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/771012/201901/771012-20190131000437591-1215807349.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;5.使用GDB连接到gdbserver进行调试&lt;/p&gt;
&lt;p&gt;由于GDB用的不太熟悉，这里使用图形化的调试工具DDD，可以通过以下命令安装：&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;33&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
sudo apt-get install ddd
#切换到之前linux编译的目录
cd linux-4.4.1
#选择未压缩的内核文件，读入符号表
ddd vmlinux
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;在GDB命令处，连接到Qemu中的GDB server：target remote 127.0.0.1:8888，这个时候Qemu中的Linux系统是处于Paused状态的。&lt;/p&gt;
&lt;p&gt;连接之后可以在菜单栏Status--&amp;gt;BackTrace...中看到堆栈信息。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/771012/201901/771012-20190131000524449-2075547412.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;输入continue，让Qemu中的Linux系统运行起来，可以在Qemu中按下ctrl+Alt+1,切换到虚拟机的命令行界面，可以看到这个时候虚拟机已经正常运行起来了。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/771012/201901/771012-20190131000558399-875489922.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;这里对Linux创建进程的系统调用下断点，观察调用栈：&lt;/p&gt;
&lt;p&gt;在fork.c文件中的_do_fork函数处下断点：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/771012/201901/771012-20190131000611975-1106182526.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;切换到Qemu，使用ctrl+Alt+1回到Linux的控制台，运行ls，这时候shell会创建ls进程，这个时候ddd就会断下来了：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/771012/201901/771012-20190131000640200-1780637066.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

</description>
<pubDate>Wed, 30 Jan 2019 16:00:00 +0000</pubDate>
<dc:creator>int80</dc:creator>
<og:description>本文总结了在Ubuntu16.04上通过GDB+Qemu双击调试Linux 4.4.1内核的方法。</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/int80/p/10340282.html</dc:identifier>
</item>
<item>
<title>你不知道的 docker 命令的奇淫怪巧 - WeihanLi</title>
<link>http://www.cnblogs.com/weihanli/p/docker-tricks.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/weihanli/p/docker-tricks.html</guid>
<description>&lt;h2 id=&quot;intro&quot;&gt;Intro&lt;/h2&gt;
&lt;p&gt;介绍并收录一些可能会用到的一些简单实用却很少有人用的 docker 命令&lt;/p&gt;
&lt;h2 id=&quot;dangling-images&quot;&gt;dangling images&lt;/h2&gt;
&lt;p&gt;build 自己的 docker 镜像的时候，有时会遇到用一个甚至多个中间层镜像，这会一定程度上减少最终打包出来 docker 镜像的大小，但是会产生一些tag 为 none 的无用镜像，也称为悬挂镜像 (&lt;code&gt;dangling images&lt;/code&gt;)&lt;/p&gt;
&lt;p&gt;列出所有的 dangling images:&lt;/p&gt;
&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;docker images -f &quot;dangling=true&quot;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;删除所有的 dangling images：&lt;/p&gt;
&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;docker rmi $(docker images -f &quot;dangling=true&quot; -q)&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;批量操作&quot;&gt;批量操作&lt;/h2&gt;
&lt;p&gt;当服务器重启或者因故关机时，docker 容器可能需要全部重新启动，启动所有 docker 容器&lt;/p&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;注：如果有依赖关系，如 link 等，应该先启动这些被依赖的容器&lt;/p&gt;
&lt;/blockquote&gt;
&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;docker start $(docker ps -aq)&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;停止所有 docker 容器&lt;/p&gt;
&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;docker stop $(docker ps -aq)&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;删除所有 docker 容器&lt;/p&gt;
&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;docker rm $(docker ps -aq)&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;删除所有 docker 镜像&lt;/p&gt;
&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;docker rmi $(docker images -q)&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;docker-资源清理&quot;&gt;docker 资源清理&lt;/h2&gt;
&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;docker container prune # 删除所有退出状态的容器
docker volume prune # 删除未被使用的数据卷
docker image prune # 删除 dangling 或所有未被使用的镜像

docker system prune #删除已停止的容器、dangling 镜像、未被容器引用的 network 和构建过程中的 cache
# 安全起见，这个命令默认不会删除那些未被任何容器引用的数据卷，如果需要同时删除这些数据卷，你需要显式的指定 --volumns 参数
docker system prune --all --force --volumns #这次不仅会删除数据卷，而且连确认的过程都没有了！注意，使用 --all 参数后会删除所有未被引用的镜像而不仅仅是 dangling 镜像&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;reference&quot;&gt;Reference&lt;/h2&gt;
</description>
<pubDate>Wed, 30 Jan 2019 15:54:00 +0000</pubDate>
<dc:creator>WeihanLi</dc:creator>
<og:description>你不知道的 docker 命令的奇淫怪巧 Intro 介绍并收录一些可能会用到的一些简单实用却很少有人用的 docker 命令 dangling images build 自己的 docker 镜像的</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/weihanli/p/docker-tricks.html</dc:identifier>
</item>
<item>
<title>Jmeter干货 不常用却极其有用的几个地方 - 夏天里的Jasmine</title>
<link>http://www.cnblogs.com/qianjinyan/p/10340269.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/qianjinyan/p/10340269.html</guid>
<description>&lt;p&gt;&lt;strong&gt;1. Jmeter测试计划下Run Thread Groups consecutively 表示序列化执行测试计划下所有线程组中的各个请求&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;如下图配置，新建的测试计划中，不默认勾选此项，&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;而享用Jmeter做接口自动化测试的同学们，会发现一个问题是，可能多个接口使用的变量是同一个，同个接口一起执行，会影响数据检查和断言，导致自动化误报。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1064427/201901/1064427-20190130233910622-1394520070.png&quot; alt=&quot;&quot;/&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;2. Jmeter的HTTP请求中，设置响应时间超过N，将请求标记为失败，不再继续等待&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;如下图配置，HTTP请求中点击高级Advance项，在Timeouts下填写设置的响应超时时间，注意单位是毫秒&lt;/strong&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1064427/201901/1064427-20190130234445065-1294206036.png&quot; alt=&quot;&quot;/&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;3. Jmeter的快捷键&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1064427/201901/1064427-20190130235253878-558704726.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;


&lt;p&gt;&lt;span&gt;欢迎各位亲们进行补充~~~&lt;/span&gt;&lt;/p&gt;
</description>
<pubDate>Wed, 30 Jan 2019 15:53:00 +0000</pubDate>
<dc:creator>夏天里的Jasmine</dc:creator>
<og:description>1. Jmeter测试计划下Run Thread Groups consecutively 表示序列化执行测试计划下所有线程组中的各个请求 如下图配置，新建的测试计划中，不默认勾选此项， 而享用Jme</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/qianjinyan/p/10340269.html</dc:identifier>
</item>
<item>
<title>【原创】谈谈服务雪崩、降级与熔断 - 孤独烟</title>
<link>http://www.cnblogs.com/rjzheng/p/10340176.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/rjzheng/p/10340176.html</guid>
<description>&lt;h2 id=&quot;引言&quot;&gt;引言&lt;/h2&gt;
&lt;p&gt;首先，之所以谈这个话题呢，是发现现在很多人对微服务的设计缺乏认识，所以写一篇扫盲文。当然，考虑到目前大多微服务的文章都是口水文，烟哥争取将实现方式讲透，点清楚，让大家有所收获！&lt;br/&gt;OK，我要先说明一下，我有很长一段时间将&lt;strong&gt;服务降级&lt;/strong&gt;和&lt;strong&gt;服务熔断&lt;/strong&gt;混在一起，认为是一回事！&lt;br/&gt;为什么我会有这样的误解呢？&lt;br/&gt;针对下面的情形，如图所示&lt;br/&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/725429/201901/725429-20190130225813653-676264554.png&quot;/&gt;&lt;br/&gt;当&lt;code&gt;Service A&lt;/code&gt;调用&lt;code&gt;Service B&lt;/code&gt;，失败多次达到一定阀值，&lt;code&gt;Service A&lt;/code&gt;不会再去调&lt;code&gt;Service B&lt;/code&gt;，而会去执行本地的降级方法！&lt;br/&gt;对于这么一套机制:在Spring cloud中结合Hystrix,将其称为熔断降级!&lt;/p&gt;
&lt;p&gt;所以我当时就以为是一回事了，毕竟熔断和降级是一起发生的，而且这二者的概念太相近了！后面接触了多了，发现自己理解的还是太狭隘了，因此本文中带着点我自己的见解，大家如果有不同意见，请轻喷！毕竟还有很多人认为两者是一致的！&lt;/p&gt;
&lt;h2 id=&quot;正文&quot;&gt;正文&lt;/h2&gt;
&lt;h3 id=&quot;服务雪崩&quot;&gt;服务雪崩&lt;/h3&gt;
&lt;p&gt;OK，我们从服务雪崩开始讲起！假设存在如下调用链&lt;br/&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/725429/201901/725429-20190130225819816-259073605.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;而此时，&lt;code&gt;Service A&lt;/code&gt;的流量波动很大，流量经常会突然性增加！那么在这种情况下，就算&lt;code&gt;Service A&lt;/code&gt;能扛得住请求，&lt;code&gt;Service B&lt;/code&gt;和&lt;code&gt;Service C&lt;/code&gt;未必能扛得住这突发的请求。&lt;br/&gt;此时，如果&lt;code&gt;Service C&lt;/code&gt;因为抗不住请求，变得不可用。那么&lt;code&gt;Service B&lt;/code&gt;的请求也会阻塞，慢慢耗尽&lt;code&gt;Service B&lt;/code&gt;的线程资源，&lt;code&gt;Service B&lt;/code&gt;就会变得不可用。紧接着，&lt;code&gt;Service A&lt;/code&gt;也会不可用，这一过程如下图所示&lt;br/&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/725429/201901/725429-20190130225824355-156743654.jpg&quot;/&gt;&lt;/p&gt;
&lt;p&gt;如上图所示，一个服务失败，导致整条链路的服务都失败的情形，我们称之为服务雪崩。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;ps：&lt;/code&gt;谁发明的这个词，真是面试装13必备！&lt;/p&gt;
&lt;p&gt;那么，服务熔断和服务降级就可以视为解决服务雪崩的手段之一。&lt;/p&gt;
&lt;h3 id=&quot;服务熔断&quot;&gt;服务熔断&lt;/h3&gt;
&lt;p&gt;那么，什么是服务熔断呢？&lt;br/&gt;服务熔断：当下游的服务因为某种原因突然&lt;strong&gt;变得不可用&lt;/strong&gt;或&lt;strong&gt;响应过慢&lt;/strong&gt;，上游服务为了保证自己整体服务的可用性，不再继续调用目标服务，直接返回，快速释放资源。如果目标服务情况好转则恢复调用。&lt;br/&gt;需要说明的是熔断其实是一个框架级的处理，那么这套熔断机制的设计，基本上业内用的是&lt;code&gt;断路器模式&lt;/code&gt;，如&lt;code&gt;Martin Fowler&lt;/code&gt;提供的状态转换图如下所示&lt;br/&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/725429/201901/725429-20190130230717121-435467568.jpg&quot;/&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;最开始处于&lt;code&gt;closed&lt;/code&gt;状态，一旦检测到错误到达一定阈值，便转为&lt;code&gt;open&lt;/code&gt;状态；&lt;/li&gt;
&lt;li&gt;这时候会有个 reset timeout，到了这个时间了，会转移到&lt;code&gt;half open&lt;/code&gt;状态；&lt;/li&gt;
&lt;li&gt;尝试放行一部分请求到后端，一旦检测成功便回归到&lt;code&gt;closed&lt;/code&gt;状态，即恢复服务；&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;业内目前流行的熔断器很多，例如阿里出的Sentinel,以及最多人使用的Hystrix&lt;br/&gt;在Hystrix中，对应配置如下&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;//滑动窗口的大小，默认为20
circuitBreaker.requestVolumeThreshold 
//过多长时间，熔断器再次检测是否开启，默认为5000，即5s钟
circuitBreaker.sleepWindowInMilliseconds 
//错误率，默认50%
circuitBreaker.errorThresholdPercentage&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;每当20个请求中，有50%失败时，熔断器就会打开，此时再调用此服务，将会直接返回失败，不再调远程服务。直到5s钟之后，重新检测该触发条件，判断是否把熔断器关闭，或者继续打开。&lt;/p&gt;
&lt;p&gt;这些属于框架层级的实现，我们只要实现对应接口就好！&lt;/p&gt;
&lt;h3 id=&quot;服务降级&quot;&gt;服务降级&lt;/h3&gt;
&lt;p&gt;那么，什么是服务降级呢？&lt;br/&gt;这里有两种场景:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;当下游的服务因为某种原因&lt;strong&gt;响应过慢&lt;/strong&gt;，下游服务主动停掉一些不太重要的业务，释放出服务器资源，增加响应速度！&lt;/li&gt;
&lt;li&gt;当下游的服务因为某种原因&lt;strong&gt;不可用&lt;/strong&gt;，上游主动调用本地的一些降级逻辑，避免卡顿，迅速返回给用户！&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;其实乍看之下，很多人还是不懂熔断和降级的区别!&lt;/p&gt;
&lt;p&gt;其实应该要这么理解:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;服务降级有很多种降级方式！如开关降级、限流降级、熔断降级!&lt;/li&gt;
&lt;li&gt;服务熔断属于降级方式的一种！&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;可能有的人不服，觉得熔断是熔断、降级是降级，分明是两回事啊！其实不然，因为从实现上来说，熔断和降级必定是一起出现。因为当发生&lt;strong&gt;下游服务不可用&lt;/strong&gt;的情况，这个时候为了对最终用户负责，就需要&lt;strong&gt;进入上游的降级逻辑&lt;/strong&gt;了。因此，将熔断降级视为降级方式的一种，也是可以说的通的！&lt;/p&gt;
&lt;p&gt;我撇开框架，以最简单的代码来说明！上游代码如下&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;try{
    //调用下游的helloWorld服务
    xxRpc.helloWorld();
}catch(Exception e){
    //因为熔断，所以调不通
    doSomething();
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;注意看，下游的helloWorld服务因为熔断而调不通。此时上游服务就会进入catch里头的代码块，那么catch里头执行的逻辑，你就可以理解为降级逻辑!&lt;br/&gt;&lt;strong&gt;什么，你跟我说你不捕捉异常，直接丢页面？&lt;/strong&gt;&lt;br/&gt;OK，那我甘拜下风，当我理解错误!&lt;/p&gt;
&lt;p&gt;服务降级大多是属于一种业务级别的处理，&lt;br/&gt;当然，我这里要讲的是另一种降级方式，也就是&lt;em&gt;&lt;span&gt;开关降级&lt;/span&gt;&lt;/em&gt;!这也是我们生产上常用的另一种降级方式！&lt;/p&gt;
&lt;p&gt;做法很简单，做个开关，然后将开关放配置中心！在配置中心更改开关，决定哪些服务进行降级。至于配置变动后，应用怎么监控到配置发生了变动，这就不是本文该讨论的范围。&lt;br/&gt;那么，在应用程序中部下开关的这个过程，业内也有一个名词，称为&lt;strong&gt;埋点&lt;/strong&gt;！&lt;/p&gt;
&lt;p&gt;那接下来最关键的一个问题，哪些业务需要埋点？&lt;br/&gt;一般有以下方法&lt;br/&gt;&lt;strong&gt;(1)简化执行流程&lt;/strong&gt;&lt;br/&gt;自己梳理出核心业务流程和非核心业务流程。然后在非核心业务流程上加上开关，一旦发现系统扛不住，关掉开关，结束这些次要流程。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;(2)关闭次要功能&lt;/strong&gt;&lt;br/&gt;一个微服务下肯定有很多功能，那自己区分出主要功能和次要功能。然后次要功能加上开关，需要降级的时候，把次要功能关了吧！&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;(3)降低一致性&lt;/strong&gt;&lt;br/&gt;假设，你在业务上发现执行流程没法简化了，愁啊！也没啥次要功能可以关了，桑心啊！那只能降低一致性了，即将核心业务流程的同步改异步，将强一致性改最终一致性！&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;可是这些都是手动降级，有办法自动降级么？&lt;/strong&gt;&lt;br/&gt;这里我摸着良心说，我们在生产上没弄自动降级！因为一般需要降级的场景，都是可以预见的，例如某某活动。假设，平时真的有突发事件，流量异常，也有监控系统发邮件通知，提醒我们去降级！&lt;br/&gt;当然，这并不代表自动降级不能做，因此以下内容可以认为我在胡说八道，因为我在生产上没实践过，只是头脑大概想了下，如果让我来做自动降级我会怎么实现：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;(1)自己设一个阈值，例如几秒内失败多少次，就启动降级&lt;/li&gt;
&lt;li&gt;(2)自己做接口监控(有兴趣的可以了解一下Rxjava)，达到阈值就走推送逻辑。怎么推呢？比如你配置是放在git上，就用jgit去改配置中心的配置。如果配置放数据库，就用jdbc去改。&lt;/li&gt;
&lt;li&gt;(3)改完配置中心的配置后，应用就可以自动检测到配置的变化，进行降级！(这句不了解的，了解一下配置中心的热刷新功能)&lt;/li&gt;
&lt;/ul&gt;</description>
<pubDate>Wed, 30 Jan 2019 15:51:00 +0000</pubDate>
<dc:creator>孤独烟</dc:creator>
<og:description>引言 首先，之所以谈这个话题呢，是发现现在很多人对微服务的设计缺乏认识，所以写一篇扫盲文。当然，考虑到目前大多微服务的文章都是口水文，烟哥争取将实现方式讲透，点清楚，让大家有所收获！ OK，我要先说明</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/rjzheng/p/10340176.html</dc:identifier>
</item>
<item>
<title>意识科学初步：David Chalmers的简单问题与困难问题 - 毛利小九郎</title>
<link>http://www.cnblogs.com/morikokyuro/p/10335713.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/morikokyuro/p/10335713.html</guid>
<description>&lt;p&gt;这是第一篇关于意识科学的内容。主要谈一下阅读大卫查莫斯的几篇论文的一些观点和思考。&lt;/p&gt;
&lt;p&gt;论文作者简介（摘自wiki）：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;David John Chalmers&lt;/strong&gt; (&lt;span class=&quot;nowrap&quot;/&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1517558/201901/1517558-20190130225829182-171317834.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;个人主页：http://consc.net/&lt;/p&gt;

&lt;p&gt;意识作为一个和人类生存息息相关的问题古已有之，但是一直只是哲学讨论的对象。而近代以来，随着神经科学和脑科学，包括心理学和认知科学等领域的发展，人们开始逐渐将意识的机理的研究纳入到科学的范畴之中来。但是，Chalmers认为，现在的认知科学与神经科学所研究的问题，和我们真正关心的&lt;strong&gt;意识问题&lt;/strong&gt;其实并没有太大的联系。Chalmers在这些文章中的的主要任务是，先为意识科学的研究者们划清研究的界限，即哪些问题是意识科学本身应该重点关注的，而哪些研究对于最根本的意识问题没有太大助益。下面简单介绍一下Chalmers的一些基本论点。&lt;/p&gt;
&lt;p&gt;他的第一个论点就是区分&lt;strong&gt;困难问题&lt;/strong&gt;和&lt;strong&gt;简单问题。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;&lt;strong&gt;简单问题（the easy problem）&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;比如，我们的人类主体是如何判别感官刺激并且对此做出反应？我们的大脑是如何整合信息，并且控制行为的？主体是如何通过语言表达它的内在状态的？&lt;/p&gt;
&lt;p&gt;这些问题在chalmers看来，属于简单问题。这里的简单是相对的，只是为了和真正困难的意识问题区分开。这些问题的共同点在于，它们关心的是mechanism of cognitive system，也就是认知系统的机制，或者简单来说，就是机械性的那些原理。&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;困难问题（the hard problem）&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;而困难问题则不一样。困难问题说的是：为什么我们的大脑的反应的这些物理的过程，也就是前面说的那些种过程，总会产生或者说伴随着一个意识主体的&lt;strong&gt;意识体验（conscious experience，subjective experience，在后面一般直接就写成experience了）。&lt;/strong&gt;这是我们最关心的意识问题中的重点，而 chalmers认为现在的人做的工作还没有真正触及这个问题。&lt;/p&gt;
&lt;p&gt;也就是说，我们更关注&lt;strong&gt;体验&lt;/strong&gt;这种主观的意识现象，而不是认知机制等等。chalmers认为，简单问题通过神经生物学，脑科学，心理学等等这些学科的发展总能够得到解决，也就是研究方式是正确的，最终结果只是时间问题。而困难问题则不一样，人们还没有进入这个领域，因此也没有一个统一的理论框架，或者研究范式。chalmers的目的就是为困难问题设定一个可能的理论框架。&lt;/p&gt;
&lt;p&gt;为了说明困难问题，我们可以举几个栗子：&lt;/p&gt;

&lt;p&gt;&lt;span&gt;&lt;strong&gt;玛丽黑白屋问题（isolated neuroscientist in a black-and-white room）&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;这个问题是由澳大利亚的哲学家 &lt;strong&gt;Frank Jackson&lt;/strong&gt; 提出来的，实际上是一个思想实验。imagine 在23世纪又一个神经科学家Mary， 玛丽是世界上一流的脑科学专家，她非常了解大脑对于颜色视觉的处理机制。但是，玛丽一生都生活在一个黑白屋里，在这里她从来没有看到过任何除了黑白以外的颜色。那么我们可以说，玛丽知道很多关于颜色视觉的知识，比方说，我们的视觉系统如何接收刺激，如何传递信息，整合信息，大脑如何处理，如何做出反应，以及不同颜色在频谱中各自占据哪些范围等等。但是我们说，玛丽的知识中仍然有一个重要的缺陷，也就是，她不知道什么是&lt;strong&gt;红色的体验&lt;/strong&gt;（experience of red）。她可以说，红色是多少纳米的波长范围，红色被视觉系统中的视锥细胞的哪些物理过程所捕获，然后通过哪些神经传到大脑进行处理，最终让我们判断它是红色，等等。但是她没有对于红色的体验。打个比方，这一点就像我们现在的正常人对于红外光的感受，我们知道它是怎么一回事，但是我们仍然无法体验到红外光，或者另一个例子，我们可以讨论高维空间为何物，里面的距离如何计算，里面的几何体有什么性质，物理现象遵从什么规律，等等。但是我们无法想象出高维空间，就像这个没见过红色的神经科学家没法体验到红色一样。&lt;/p&gt;
&lt;p&gt;这个思想实验其实就是将困难问题和简单问题剥离开，玛丽缺少的那部分知识，就是我们需要在困难问题中解决的。&lt;/p&gt;

&lt;p&gt; &lt;img src=&quot;https://img2018.cnblogs.com/blog/1517558/201901/1517558-20190130225927282-685388642.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;


&lt;p&gt;&lt;span&gt;&lt;strong&gt;解释鸿沟（explanatory gap）&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;这个概念由Joseph Levine提出。 指的是物理过程和意识之间的巨大差异。简言之，chalmers认为，现有的物理的理论无法解释的一个重要的意识问题是：为什么物理过程必须要伴随着意识？ &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;这个问题是很重要的，因为我们知道，如果一个人，按照生物物理学的或者生物化学的机械形式，是可以完全完成从【接受刺激-进行处理-做出反应】这个过程的，这样看起来意识似乎是可有可无的。因为一个automaton，机器人，或者称为自动机，就可以完成很多人所能完成的内容。那么为何这样的过程还有给主体投射一个体验或者说印象呢？&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;物理的方式其实更多的是机械论的方式，是将过程解释成具体的process，但是意识是不能被这样解释出来的，这就是物理理论对于意识的解释鸿沟。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;也就是说，如果意识科学要是可能的话，那么必有又一种新的理论来解决。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;span&gt;Dancing Qualia in a Synthetic Brain&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;systems with the same organization will embody the same information。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;上面这个是一个假设，这个假设可以通过一个思想实验来证明，也就是所谓的dancing qualia。 qualia指的是感受质。这个思想实验如图所示：&lt;/span&gt;&lt;/p&gt;

&lt;p&gt; &lt;img src=&quot;https://img2018.cnblogs.com/blog/1517558/201901/1517558-20190130230002065-493726593.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;对上面的解释简单介绍一下。作者是如何证明相同的结构的系统会有相同的意识体验呢？这里作者采用反证法（归谬法），先假设如果不成立，也就是说，相同结构的不同系统具有不同的意识体验。那么，我们设想一个硅基系统，里面的芯片都是按照大脑中神经元的组织结构和功能做成的，那么，我们将大脑中的某个区域的神经元换成硅基系统中的一些同等结构的芯片，也就是说，比如我们用芯片替代了我们的视觉皮层（visual cortex），那么我们仍然能够视觉，但是，按照假设，我们的原先的体验和改变后的意识体验应当是不同的，比如对于红色，本来我们的体验是红色，现在变成了紫色的体验。那么，如果我们有一个开关，这个开关可以控制我们用芯片的大脑还是原本的大脑，那么，由于我们的意识体验不同，那么我们的qualia就会dancing between两种不同的意识体验。然而，又因为我们的脑组织结构没有改变，那么我们的判断是不变的，也就是说，即使两种颜色在眼前dancing，我们仍然会认为无事发生，没有任何改变。这个是不合理的。这也就说明我们的假设不合理，通过反证法得到结论。&lt;/p&gt;
&lt;p&gt;可能这个说明还是不够具体，我们进一步来说明。假设我很喜欢红色，那么当开关在两种意识体验（红色和紫色）之间来回交替的时候，我仍然会对别人说，这个就是我喜欢的颜色，并且是没有变化的。但是我们假设了意识体验是不同的，但是我们却对它产生了同样的领悟和理解，以及处理方式，那么这种现象就不合理。或者说，抛开归谬法，我们想象，如果这个东西对我们来说意味着完全一样的东西，那么他们对我们来说，没有理由不认为它门对我们有着相同的意识体验。这个思想实验的关键在于，把【相同还是不同】这个比较难解的问题转化成了【变化还是不变】这样一个更加直观和易于判别的问题，并从中得出结论。&lt;/p&gt;

&lt;p&gt;这是我们介绍的两个思想实验。以及一些概念。最重要的是困难问题的理解。在之后我们再整理chalmers的其他文章，他在有些文章里对现有的意识研究的模型和路线提出了一些质疑，并表示他们都是在解决简单问题。并且给出了如果要解决困难问题的话，需要遵循的一些原则。&lt;/p&gt;

&lt;p&gt;参考文献：&lt;/p&gt;
&lt;p&gt;Chalmers D J . The puzzle of conscious experience.[J]. Scientific American, 1995, 273(6):80.&lt;/p&gt;


</description>
<pubDate>Wed, 30 Jan 2019 15:19:00 +0000</pubDate>
<dc:creator>毛利小九郎</dc:creator>
<og:description>意识作为一个和人类生存息息相关的问题古已有之，但是一直只是哲学讨论的对象。而近代以来，随着神经科学和脑科学，包括心理学和认知科学等领域的发展，人们开始逐渐将意识的机理的研究纳入到科学的范畴之中来。但是</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/morikokyuro/p/10335713.html</dc:identifier>
</item>
<item>
<title>使用Kazoo操作ZooKeeper服务治理 - Harvard_Fly</title>
<link>http://www.cnblogs.com/FG123/p/10261682.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/FG123/p/10261682.html</guid>
<description>&lt;p&gt;&lt;span&gt;单机服务的可靠性及可扩展性有限，某台服务宕机可能会影响整个系统的正常使用；分布式服务能够有效地解决这一问题，但同时分布式服务也会带来一些新的问题，如：服务发现(新增或者删除了服务如何确保能让客户端知道)，容灾(某些服务出现故障如何让客户端只访问正常的服务)；ZooKeeper的提出主要是为了解决分布式服务的治理问题，它在分布式环境中协调和管理服务。&lt;/span&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;Zookeeper协调管理服务的过程如下图：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/739231/201901/739231-20190123095338887-1408365925.png&quot; alt=&quot;&quot;/&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;服务端：每台服务器都要向注册中心Zookeeper进行注册登记，并且保持与Zookeeper的连接，如果服务器与Zookeeper断开了连接，Zookeeper将删除该服务器的地址。&lt;/span&gt;&lt;br/&gt;&lt;span&gt;客户端：需要服务的时候先向Zookeeper订阅服务器的地址信息，Zookeeper返回给客户端已注册的服务器信息列表，客户端从服务器信息列表中选择服务器进行服务调用，如果Zookeeper记录的服务器信息发生了变更，服务器会通知客户端变更事件，客户端可以获取最新的服务器信息。&lt;/span&gt;&lt;br/&gt;&lt;span&gt;ZooKeeper文件系统的数据结构是个树状结构，它的每个节点(znode)由一个名称标识，并用路径/分割：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/739231/201901/739231-20190129202950561-1373842958.png&quot; alt=&quot;&quot;/&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt; ZooKeeper的节点类型有：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;  1. 持久节点(ZooKeeper默认的节点类型，创建该节点的客户端断开连接后，持久节点仍然存在)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;  2. 顺序节点(将10位的序列号附加到原始名称来设置节点的路径，如：/server0000000001)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;  3. 临时节点(当客户端与ZooKeeper断开连接时，临时节点会自动删除)&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;RPC服务注册到ZooKeeper&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;服务端：&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;54&quot;&gt;
&lt;pre&gt;
&lt;span&gt; 1&lt;/span&gt; &lt;span&gt;import&lt;/span&gt;&lt;span&gt; threading
&lt;/span&gt;&lt;span&gt; 2&lt;/span&gt; &lt;span&gt;import&lt;/span&gt;&lt;span&gt; json
&lt;/span&gt;&lt;span&gt; 3&lt;/span&gt; &lt;span&gt;import&lt;/span&gt;&lt;span&gt; socket
&lt;/span&gt;&lt;span&gt; 4&lt;/span&gt; &lt;span&gt;import&lt;/span&gt;&lt;span&gt; sys
&lt;/span&gt;&lt;span&gt; 5&lt;/span&gt; &lt;span&gt;from&lt;/span&gt; kazoo.client &lt;span&gt;import&lt;/span&gt;&lt;span&gt; KazooClient
&lt;/span&gt;&lt;span&gt; 6&lt;/span&gt; &lt;span&gt;from&lt;/span&gt; divide_rpc &lt;span&gt;import&lt;/span&gt;&lt;span&gt; ServerStub
&lt;/span&gt;&lt;span&gt; 7&lt;/span&gt; &lt;span&gt;from&lt;/span&gt; divide_rpc &lt;span&gt;import&lt;/span&gt;&lt;span&gt; InvalidOperation
&lt;/span&gt;&lt;span&gt; 8&lt;/span&gt; 
&lt;span&gt; 9&lt;/span&gt; 
&lt;span&gt;10&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;&lt;span&gt; ThreadServer(object):
&lt;/span&gt;&lt;span&gt;11&lt;/span&gt;     &lt;span&gt;def&lt;/span&gt; &lt;span&gt;__init__&lt;/span&gt;&lt;span&gt;(self, host, port, handlers):
&lt;/span&gt;&lt;span&gt;12&lt;/span&gt;         self.sock =&lt;span&gt; socket.socket(socket.AF_INET, socket.SOCK_STREAM)
&lt;/span&gt;&lt;span&gt;13&lt;/span&gt;         self.sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1&lt;span&gt;)
&lt;/span&gt;&lt;span&gt;14&lt;/span&gt;         self.host =&lt;span&gt; host
&lt;/span&gt;&lt;span&gt;15&lt;/span&gt;         self.port =&lt;span&gt; port
&lt;/span&gt;&lt;span&gt;16&lt;/span&gt; &lt;span&gt;        self.sock.bind((host, port))
&lt;/span&gt;&lt;span&gt;17&lt;/span&gt;         self.handlers =&lt;span&gt; handlers
&lt;/span&gt;&lt;span&gt;18&lt;/span&gt; 
&lt;span&gt;19&lt;/span&gt;     &lt;span&gt;def&lt;/span&gt;&lt;span&gt; serve(self):
&lt;/span&gt;&lt;span&gt;20&lt;/span&gt;         &lt;span&gt;&quot;&quot;&quot;&lt;/span&gt;
&lt;span&gt;21&lt;/span&gt; &lt;span&gt;        开始服务
&lt;/span&gt;&lt;span&gt;22&lt;/span&gt;         &lt;span&gt;&quot;&quot;&quot;&lt;/span&gt;
&lt;span&gt;23&lt;/span&gt;         self.sock.listen(128&lt;span&gt;)
&lt;/span&gt;&lt;span&gt;24&lt;/span&gt; &lt;span&gt;        self.register_zk()
&lt;/span&gt;&lt;span&gt;25&lt;/span&gt;         &lt;span&gt;print&lt;/span&gt;(&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;开始监听&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;)
&lt;/span&gt;&lt;span&gt;26&lt;/span&gt;         &lt;span&gt;while&lt;/span&gt;&lt;span&gt; True:
&lt;/span&gt;&lt;span&gt;27&lt;/span&gt;             conn, addr =&lt;span&gt; self.sock.accept()
&lt;/span&gt;&lt;span&gt;28&lt;/span&gt;             &lt;span&gt;print&lt;/span&gt;(&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;建立链接%s&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; %&lt;span&gt; str(addr))
&lt;/span&gt;&lt;span&gt;29&lt;/span&gt;             t = threading.Thread(target=self.handle, args=&lt;span&gt;(conn,))
&lt;/span&gt;&lt;span&gt;30&lt;/span&gt; &lt;span&gt;            t.start()
&lt;/span&gt;&lt;span&gt;31&lt;/span&gt; 
&lt;span&gt;32&lt;/span&gt;     &lt;span&gt;def&lt;/span&gt;&lt;span&gt; handle(self, client):
&lt;/span&gt;&lt;span&gt;33&lt;/span&gt;         stub =&lt;span&gt; ServerStub(client, self.handlers)
&lt;/span&gt;&lt;span&gt;34&lt;/span&gt;         &lt;span&gt;try&lt;/span&gt;&lt;span&gt;:
&lt;/span&gt;&lt;span&gt;35&lt;/span&gt;             &lt;span&gt;while&lt;/span&gt;&lt;span&gt; True:
&lt;/span&gt;&lt;span&gt;36&lt;/span&gt; &lt;span&gt;                stub.process()
&lt;/span&gt;&lt;span&gt;37&lt;/span&gt;         &lt;span&gt;except&lt;/span&gt;&lt;span&gt; EOFError:
&lt;/span&gt;&lt;span&gt;38&lt;/span&gt;             &lt;span&gt;print&lt;/span&gt;(&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;客户端关闭连接&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;)
&lt;/span&gt;&lt;span&gt;39&lt;/span&gt; 
&lt;span&gt;40&lt;/span&gt; &lt;span&gt;        client.close()
&lt;/span&gt;&lt;span&gt;41&lt;/span&gt; 
&lt;span&gt;42&lt;/span&gt;     &lt;span&gt;def&lt;/span&gt;&lt;span&gt; register_zk(self):
&lt;/span&gt;&lt;span&gt;43&lt;/span&gt;         &lt;span&gt;&quot;&quot;&quot;&lt;/span&gt;
&lt;span&gt;44&lt;/span&gt; &lt;span&gt;        注册到zookeeper
&lt;/span&gt;&lt;span&gt;45&lt;/span&gt;         &lt;span&gt;&quot;&quot;&quot;&lt;/span&gt;
&lt;span&gt;46&lt;/span&gt;         self.zk = KazooClient(hosts=&lt;span&gt;'&lt;/span&gt;&lt;span&gt;127.0.0.1:2181&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;)
&lt;/span&gt;&lt;span&gt;47&lt;/span&gt; &lt;span&gt;        self.zk.start()
&lt;/span&gt;&lt;span&gt;48&lt;/span&gt;         self.zk.ensure_path(&lt;span&gt;'&lt;/span&gt;&lt;span&gt;/rpc&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;)  &lt;span&gt;#&lt;/span&gt;&lt;span&gt; 创建根节点&lt;/span&gt;
&lt;span&gt;49&lt;/span&gt;         value = json.dumps({&lt;span&gt;'&lt;/span&gt;&lt;span&gt;host&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;: self.host, &lt;span&gt;'&lt;/span&gt;&lt;span&gt;port&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;: self.port})
&lt;/span&gt;&lt;span&gt;50&lt;/span&gt;         &lt;span&gt;#&lt;/span&gt;&lt;span&gt; 创建服务子节点&lt;/span&gt;
&lt;span&gt;51&lt;/span&gt;         self.zk.create(&lt;span&gt;'&lt;/span&gt;&lt;span&gt;/rpc/server&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;, value.encode(), ephemeral=True, sequence=&lt;span&gt;True)
&lt;/span&gt;&lt;span&gt;52&lt;/span&gt; 
&lt;span&gt;53&lt;/span&gt; 
&lt;span&gt;54&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;&lt;span&gt; Handlers:
&lt;/span&gt;&lt;span&gt;55&lt;/span&gt; &lt;span&gt;    @staticmethod
&lt;/span&gt;&lt;span&gt;56&lt;/span&gt;     &lt;span&gt;def&lt;/span&gt; divide(num1, num2=1&lt;span&gt;):
&lt;/span&gt;&lt;span&gt;57&lt;/span&gt;         &lt;span&gt;&quot;&quot;&quot;&lt;/span&gt;
&lt;span&gt;58&lt;/span&gt; &lt;span&gt;        除法
&lt;/span&gt;&lt;span&gt;59&lt;/span&gt; &lt;span&gt;        :param num1:
&lt;/span&gt;&lt;span&gt;60&lt;/span&gt; &lt;span&gt;        :param num2:
&lt;/span&gt;&lt;span&gt;61&lt;/span&gt; &lt;span&gt;        :return:
&lt;/span&gt;&lt;span&gt;62&lt;/span&gt;         &lt;span&gt;&quot;&quot;&quot;&lt;/span&gt;
&lt;span&gt;63&lt;/span&gt;         &lt;span&gt;if&lt;/span&gt; num2 ==&lt;span&gt; 0:
&lt;/span&gt;&lt;span&gt;64&lt;/span&gt;             &lt;span&gt;raise&lt;/span&gt;&lt;span&gt; InvalidOperation()
&lt;/span&gt;&lt;span&gt;65&lt;/span&gt;         val = num1 /&lt;span&gt; num2
&lt;/span&gt;&lt;span&gt;66&lt;/span&gt;         &lt;span&gt;return&lt;/span&gt;&lt;span&gt; val
&lt;/span&gt;&lt;span&gt;67&lt;/span&gt; 
&lt;span&gt;68&lt;/span&gt; 
&lt;span&gt;69&lt;/span&gt; &lt;span&gt;if&lt;/span&gt; &lt;span&gt;__name__&lt;/span&gt; == &lt;span&gt;'&lt;/span&gt;&lt;span&gt;__main__&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;:
&lt;/span&gt;&lt;span&gt;70&lt;/span&gt;     &lt;span&gt;if&lt;/span&gt; len(sys.argv) &amp;lt; 3&lt;span&gt;:
&lt;/span&gt;&lt;span&gt;71&lt;/span&gt;         &lt;span&gt;print&lt;/span&gt;(&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;usage:python server.py [host] [port]&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;)
&lt;/span&gt;&lt;span&gt;72&lt;/span&gt;         exit(1&lt;span&gt;)
&lt;/span&gt;&lt;span&gt;73&lt;/span&gt;     host = sys.argv[1&lt;span&gt;]
&lt;/span&gt;&lt;span&gt;74&lt;/span&gt;     port = sys.argv[2&lt;span&gt;]
&lt;/span&gt;&lt;span&gt;75&lt;/span&gt;     server =&lt;span&gt; ThreadServer(host, int(port), Handlers)
&lt;/span&gt;&lt;span&gt;76&lt;/span&gt;     server.serve()
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span&gt;服务端通过kazoo连接zookeeper，依次创建根节点和服务的子节点，当启动多线程服务器的时候，会根据ip和端口创建不同的节点，依次启动两个server(8001、8002)，查看zookeeper的节点信息：&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;35&quot;&gt;
&lt;pre&gt;
&lt;span&gt;1&lt;/span&gt; &amp;gt;&amp;gt;&amp;gt; &lt;span&gt;from&lt;/span&gt; kazoo.client &lt;span&gt;import&lt;/span&gt;&lt;span&gt; KazooClient
&lt;/span&gt;&lt;span&gt;2&lt;/span&gt; &amp;gt;&amp;gt;&amp;gt; zk = KazooClient(hosts=&lt;span&gt;'&lt;/span&gt;&lt;span&gt;127.0.0.1:2181&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;)
&lt;/span&gt;&lt;span&gt;3&lt;/span&gt; &amp;gt;&amp;gt;&amp;gt;&lt;span&gt; zk.start() 
&lt;/span&gt;&lt;span&gt;4&lt;/span&gt; &amp;gt;&amp;gt;&amp;gt; children = zk.get_children(&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;/rpc&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;)
&lt;/span&gt;&lt;span&gt;5&lt;/span&gt; &amp;gt;&amp;gt;&amp;gt; &lt;span&gt;print&lt;/span&gt;&lt;span&gt;(children)
&lt;/span&gt;&lt;span&gt;6&lt;/span&gt; [&lt;span&gt;'&lt;/span&gt;&lt;span&gt;server0000000001&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;, &lt;span&gt;'&lt;/span&gt;&lt;span&gt;server0000000000&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;]
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;span&gt;客户端：&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;40&quot;&gt;
&lt;pre&gt;
&lt;span&gt; 1&lt;/span&gt; &lt;span&gt;import&lt;/span&gt;&lt;span&gt; random
&lt;/span&gt;&lt;span&gt; 2&lt;/span&gt; &lt;span&gt;import&lt;/span&gt;&lt;span&gt; time
&lt;/span&gt;&lt;span&gt; 3&lt;/span&gt; &lt;span&gt;import&lt;/span&gt;&lt;span&gt; json
&lt;/span&gt;&lt;span&gt; 4&lt;/span&gt; &lt;span&gt;import&lt;/span&gt;&lt;span&gt; socket
&lt;/span&gt;&lt;span&gt; 5&lt;/span&gt; &lt;span&gt;from&lt;/span&gt; divide_rpc &lt;span&gt;import&lt;/span&gt;&lt;span&gt; (
&lt;/span&gt;&lt;span&gt; 6&lt;/span&gt; &lt;span&gt;    ClientStub, InvalidOperation
&lt;/span&gt;&lt;span&gt; 7&lt;/span&gt; &lt;span&gt;)
&lt;/span&gt;&lt;span&gt; 8&lt;/span&gt; &lt;span&gt;from&lt;/span&gt; kazoo.client &lt;span&gt;import&lt;/span&gt;&lt;span&gt; KazooClient
&lt;/span&gt;&lt;span&gt; 9&lt;/span&gt; 
&lt;span&gt;10&lt;/span&gt; 
&lt;span&gt;11&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;&lt;span&gt; DistributedChannel(object):
&lt;/span&gt;&lt;span&gt;12&lt;/span&gt;     &lt;span&gt;def&lt;/span&gt; &lt;span&gt;__init__&lt;/span&gt;&lt;span&gt;(self):
&lt;/span&gt;&lt;span&gt;13&lt;/span&gt;         self._zk = KazooClient(hosts=&lt;span&gt;'&lt;/span&gt;&lt;span&gt;127.0.0.1:2181&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;)
&lt;/span&gt;&lt;span&gt;14&lt;/span&gt; &lt;span&gt;        self._zk.start()
&lt;/span&gt;&lt;span&gt;15&lt;/span&gt; &lt;span&gt;        self._get_servers()
&lt;/span&gt;&lt;span&gt;16&lt;/span&gt; 
&lt;span&gt;17&lt;/span&gt;     &lt;span&gt;def&lt;/span&gt; _get_servers(self, event=&lt;span&gt;None):
&lt;/span&gt;&lt;span&gt;18&lt;/span&gt;         &lt;span&gt;&quot;&quot;&quot;&lt;/span&gt;
&lt;span&gt;19&lt;/span&gt; &lt;span&gt;        从zookeeper获取服务器地址信息列表
&lt;/span&gt;&lt;span&gt;20&lt;/span&gt;         &lt;span&gt;&quot;&quot;&quot;&lt;/span&gt;
&lt;span&gt;21&lt;/span&gt;         servers = self._zk.get_children(&lt;span&gt;'&lt;/span&gt;&lt;span&gt;/rpc&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;, watch=&lt;span&gt;self._get_servers)
&lt;/span&gt;&lt;span&gt;22&lt;/span&gt;         &lt;span&gt;print&lt;/span&gt;&lt;span&gt;(servers)
&lt;/span&gt;&lt;span&gt;23&lt;/span&gt;         self._servers =&lt;span&gt; []
&lt;/span&gt;&lt;span&gt;24&lt;/span&gt;         &lt;span&gt;for&lt;/span&gt; server &lt;span&gt;in&lt;/span&gt;&lt;span&gt; servers:
&lt;/span&gt;&lt;span&gt;25&lt;/span&gt;             data = self._zk.get(&lt;span&gt;'&lt;/span&gt;&lt;span&gt;/rpc/&lt;/span&gt;&lt;span&gt;'&lt;/span&gt; +&lt;span&gt; server)[0]
&lt;/span&gt;&lt;span&gt;26&lt;/span&gt;             &lt;span&gt;if&lt;/span&gt;&lt;span&gt; data:
&lt;/span&gt;&lt;span&gt;27&lt;/span&gt;                 addr =&lt;span&gt; json.loads(data.decode())
&lt;/span&gt;&lt;span&gt;28&lt;/span&gt; &lt;span&gt;                self._servers.append(addr)
&lt;/span&gt;&lt;span&gt;29&lt;/span&gt; 
&lt;span&gt;30&lt;/span&gt;     &lt;span&gt;def&lt;/span&gt;&lt;span&gt; _get_server(self):
&lt;/span&gt;&lt;span&gt;31&lt;/span&gt;         &lt;span&gt;&quot;&quot;&quot;&lt;/span&gt;
&lt;span&gt;32&lt;/span&gt; &lt;span&gt;        随机选出一个可用的服务器
&lt;/span&gt;&lt;span&gt;33&lt;/span&gt;         &lt;span&gt;&quot;&quot;&quot;&lt;/span&gt;
&lt;span&gt;34&lt;/span&gt;         &lt;span&gt;return&lt;/span&gt;&lt;span&gt; random.choice(self._servers)
&lt;/span&gt;&lt;span&gt;35&lt;/span&gt; 
&lt;span&gt;36&lt;/span&gt;     &lt;span&gt;def&lt;/span&gt;&lt;span&gt; get_connection(self):
&lt;/span&gt;&lt;span&gt;37&lt;/span&gt;         &lt;span&gt;&quot;&quot;&quot;&lt;/span&gt;
&lt;span&gt;38&lt;/span&gt; &lt;span&gt;        提供一个可用的tcp连接
&lt;/span&gt;&lt;span&gt;39&lt;/span&gt;         &lt;span&gt;&quot;&quot;&quot;&lt;/span&gt;
&lt;span&gt;40&lt;/span&gt;         &lt;span&gt;while&lt;/span&gt;&lt;span&gt; True:
&lt;/span&gt;&lt;span&gt;41&lt;/span&gt;             server =&lt;span&gt; self._get_server()
&lt;/span&gt;&lt;span&gt;42&lt;/span&gt;             &lt;span&gt;print&lt;/span&gt;&lt;span&gt;(server)
&lt;/span&gt;&lt;span&gt;43&lt;/span&gt;             &lt;span&gt;try&lt;/span&gt;&lt;span&gt;:
&lt;/span&gt;&lt;span&gt;44&lt;/span&gt;                 sock =&lt;span&gt; socket.socket(socket.AF_INET, socket.SOCK_STREAM)
&lt;/span&gt;&lt;span&gt;45&lt;/span&gt;                 sock.connect((server[&lt;span&gt;'&lt;/span&gt;&lt;span&gt;host&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;], server[&lt;span&gt;'&lt;/span&gt;&lt;span&gt;port&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;]))
&lt;/span&gt;&lt;span&gt;46&lt;/span&gt;             &lt;span&gt;except&lt;/span&gt;&lt;span&gt; ConnectionRefusedError:
&lt;/span&gt;&lt;span&gt;47&lt;/span&gt;                 time.sleep(1&lt;span&gt;)
&lt;/span&gt;&lt;span&gt;48&lt;/span&gt;                 &lt;span&gt;continue&lt;/span&gt;
&lt;span&gt;49&lt;/span&gt;             &lt;span&gt;else&lt;/span&gt;&lt;span&gt;:
&lt;/span&gt;&lt;span&gt;50&lt;/span&gt;                 &lt;span&gt;break&lt;/span&gt;
&lt;span&gt;51&lt;/span&gt;         &lt;span&gt;return&lt;/span&gt;&lt;span&gt; sock
&lt;/span&gt;&lt;span&gt;52&lt;/span&gt; 
&lt;span&gt;53&lt;/span&gt; 
&lt;span&gt;54&lt;/span&gt; channel =&lt;span&gt; DistributedChannel()
&lt;/span&gt;&lt;span&gt;55&lt;/span&gt; 
&lt;span&gt;56&lt;/span&gt; &lt;span&gt;for&lt;/span&gt; i &lt;span&gt;in&lt;/span&gt; range(50&lt;span&gt;):
&lt;/span&gt;&lt;span&gt;57&lt;/span&gt;     &lt;span&gt;try&lt;/span&gt;&lt;span&gt;:
&lt;/span&gt;&lt;span&gt;58&lt;/span&gt;         stub =&lt;span&gt; ClientStub(channel)
&lt;/span&gt;&lt;span&gt;59&lt;/span&gt;         val =&lt;span&gt; stub.divide(i)
&lt;/span&gt;&lt;span&gt;60&lt;/span&gt;     &lt;span&gt;except&lt;/span&gt;&lt;span&gt; InvalidOperation as e:
&lt;/span&gt;&lt;span&gt;61&lt;/span&gt;         &lt;span&gt;print&lt;/span&gt;&lt;span&gt;(e.message)
&lt;/span&gt;&lt;span&gt;62&lt;/span&gt;     &lt;span&gt;else&lt;/span&gt;&lt;span&gt;:
&lt;/span&gt;&lt;span&gt;63&lt;/span&gt;         &lt;span&gt;print&lt;/span&gt;&lt;span&gt;(val)
&lt;/span&gt;&lt;span&gt;64&lt;/span&gt;     time.sleep(1)
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;span&gt;客户端连接zookeeper，通过get_children来获取服务器信息，并watch监听服务器的变化情况，启动客户端会发现它会调用8001端口的server和8002端口的server：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/739231/201901/739231-20190130225706063-2097430521.png&quot; alt=&quot;&quot;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;此时服务端新增加一个结点，8003，客户端变化情况：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/739231/201901/739231-20190130230024050-57962967.png&quot; alt=&quot;&quot;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;可以看出zookeeper总共有三个节点了，前面调用的server都是8001和8002,当8003加入后，zookeeper会发现并调用它&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;此时服务端断开一个server，8001，客户端变化情况：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/739231/201901/739231-20190130230408534-789067832.png&quot; alt=&quot;&quot;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;断开server前客户端会调用8001、8002、8003这三个服务，当断开server 8001以后，zookeeper只会调用8002和8003这两个server了&lt;/span&gt;&lt;/p&gt;
</description>
<pubDate>Wed, 30 Jan 2019 15:09:00 +0000</pubDate>
<dc:creator>Harvard_Fly</dc:creator>
<og:description>单机服务的可靠性及可扩展性有限，某台服务宕机可能会影响整个系统的正常使用；分布式服务能够有效地解决这一问题，但同时分布式服务也会带来一些新的问题，如：服务发现(新增或者删除了服务如何确保能让客户端知道</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/FG123/p/10261682.html</dc:identifier>
</item>
<item>
<title>Windows-删除Windows Server backup卷影副本 - Wenzhongxiang</title>
<link>http://www.cnblogs.com/wenzhongxiang/p/10340173.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/wenzhongxiang/p/10340173.html</guid>
<description>&lt;p&gt;现有环境中有一台Windows Server做过定期备份计划，时间太久未做清理操作，收到磁盘报警邮件后需要及时释放该空间，具体操作步骤如下：&lt;/p&gt;
&lt;p&gt;当前备份计划信息如下：&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://img2018.cnblogs.com/blog/1328979/201901/1328979-20190130230555041-252858939.png&quot;&gt;&lt;img width=&quot;640&quot; height=&quot;444&quot; title=&quot;image&quot; alt=&quot;image&quot; src=&quot;https://img2018.cnblogs.com/blog/1328979/201901/1328979-20190130230555723-1911764410.png&quot; border=&quot;0&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;清理步骤如下：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;1.以管理身份运行CMD或者Powershell:&lt;/p&gt;
&lt;p&gt;2.在命令行模式下输入：diskshadow 进入diskshadow 模式&lt;/p&gt;
&lt;p&gt;DiskShadow.exe是一种公开卷影复制服务（VSS）提供的功能的工具。默认情况下，DiskShadow使用类似于DiskRAID或DiskPart的交互式命令解释器。DiskShadow还包括可编写脚本的模式。&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://img2018.cnblogs.com/blog/1328979/201901/1328979-20190130230556182-17497502.png&quot;&gt;&lt;img width=&quot;640&quot; height=&quot;94&quot; title=&quot;image&quot; alt=&quot;image&quot; src=&quot;https://img2018.cnblogs.com/blog/1328979/201901/1328979-20190130230556622-259685255.png&quot; border=&quot;0&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;有关diskshadow命令行的具体帮助信息如下：&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://img2018.cnblogs.com/blog/1328979/201901/1328979-20190130230557232-1223395034.png&quot;&gt;&lt;img width=&quot;638&quot; height=&quot;728&quot; title=&quot;image&quot; alt=&quot;image&quot; src=&quot;https://img2018.cnblogs.com/blog/1328979/201901/1328979-20190130230557861-1341726369.png&quot; border=&quot;0&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;3.列出当前所有备份卷信息：List shadows all&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://img2018.cnblogs.com/blog/1328979/201901/1328979-20190130230558282-872304562.png&quot;&gt;&lt;img width=&quot;640&quot; height=&quot;385&quot; title=&quot;image&quot; alt=&quot;image&quot; src=&quot;https://img2018.cnblogs.com/blog/1328979/201901/1328979-20190130230558801-1837961395.png&quot; border=&quot;0&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://img2018.cnblogs.com/blog/1328979/201901/1328979-20190130230559163-1844590794.png&quot;&gt;&lt;img width=&quot;640&quot; height=&quot;193&quot; title=&quot;image&quot; alt=&quot;image&quot; src=&quot;https://img2018.cnblogs.com/blog/1328979/201901/1328979-20190130230559605-1390063228.png&quot; border=&quot;0&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;4.删除目标路径下旧的备份，或删除指定ID卷影副本：&lt;/p&gt;
&lt;pre class=&quot;brush: bash;html-script: false;quick-code: true;smart-tabs: true;auto-links: false;toolbar: false;gutter; true;light: false;ruler: false;pad-line-numbers: 2;collapse: false;tab-size: 4;first-line: 1;&quot;&gt;
delete shadows oldest \\?\Volume{df31d105-2303-11e6-b55e-6c92bf0e506c}\
delete shadows ID {10860cfa-be0d-4b80-a1c4-b12b4ecec5c1}
&lt;/pre&gt;
&lt;p&gt;DELETE SHADOWS { ALL | VOLUME &amp;lt;volume&amp;gt; | OLDEST &amp;lt;volume&amp;gt; | SET &amp;lt;setID&amp;gt; | ID &amp;lt;shadowID&amp;gt; | EXPOSED &amp;lt;drive letter, mountPoint or share&amp;gt; }&lt;/p&gt;
&lt;p&gt;删除持久和非持久的卷影副本&lt;/p&gt;
&lt;p&gt;ALL 所有卷影副本。&lt;/p&gt;
&lt;p&gt;VOLUME &amp;lt;volume&amp;gt; 删除给定卷的所有卷影副本。&lt;/p&gt;
&lt;p&gt;OLDEST &amp;lt;volume&amp;gt;   删除给定卷的最旧卷影副本。&lt;/p&gt;
&lt;p&gt;SET &amp;lt;setID&amp;gt; 删除由 setId 参数指定的卷影副本集中的卷影副本。&lt;/p&gt;
&lt;p&gt;ID &amp;lt;shadowID&amp;gt; 删除由 shadowId 参数指定的卷影副本。&lt;/p&gt;
&lt;p&gt;EXPOSED &amp;lt;exposeName&amp;gt; 删除在指定的驱动器号、装入点或共享暴露的卷影副&lt;/p&gt;
&lt;p&gt;示例:&lt;/p&gt;
&lt;p&gt;DELETE SHADOWS ALL&lt;/p&gt;
&lt;p&gt;DELETE SHADOWS EXPOSED p:&lt;/p&gt;
&lt;p&gt;DELETE SHADOWS EXPOSED ShareName&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://img2018.cnblogs.com/blog/1328979/201901/1328979-20190130230600168-468827723.png&quot;&gt;&lt;img width=&quot;640&quot; height=&quot;149&quot; title=&quot;image&quot; alt=&quot;image&quot; src=&quot;https://img2018.cnblogs.com/blog/1328979/201901/1328979-20190130230600645-1402947255.png&quot; border=&quot;0&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;删除所有卷影副本：&lt;/p&gt;
&lt;pre class=&quot;brush: bash;html-script: false;quick-code: true;smart-tabs: true;auto-links: false;toolbar: false;gutter; true;light: false;ruler: false;pad-line-numbers: 2;collapse: false;tab-size: 4;first-line: 1;&quot;&gt;
delete shadows all
&lt;/pre&gt;
&lt;p&gt;&lt;a href=&quot;https://img2018.cnblogs.com/blog/1328979/201901/1328979-20190130230601356-2105830343.png&quot;&gt;&lt;img width=&quot;640&quot; height=&quot;127&quot; title=&quot;image&quot; alt=&quot;image&quot; src=&quot;https://img2018.cnblogs.com/blog/1328979/201901/1328979-20190130230601992-1795731203.png&quot; border=&quot;0&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;5.再次查询当前所有备份卷信息：&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://img2018.cnblogs.com/blog/1328979/201901/1328979-20190130230602561-52319406.png&quot;&gt;&lt;img width=&quot;640&quot; height=&quot;133&quot; title=&quot;image&quot; alt=&quot;image&quot; src=&quot;https://img2018.cnblogs.com/blog/1328979/201901/1328979-20190130230603285-1816576840.png&quot; border=&quot;0&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;6.或者我们可以只保留最近3个副本：&lt;/p&gt;
&lt;pre class=&quot;brush: bash;html-script: false;quick-code: true;smart-tabs: true;auto-links: false;toolbar: false;gutter; true;light: false;ruler: false;pad-line-numbers: 2;collapse: false;tab-size: 4;first-line: 1;&quot;&gt;
wbadmin delete systemstatebackup -keepVersions:3
&lt;/pre&gt;
&lt;p&gt;&lt;a href=&quot;https://img2018.cnblogs.com/blog/1328979/201901/1328979-20190130230603912-1534677852.png&quot;&gt;&lt;img width=&quot;640&quot; height=&quot;170&quot; title=&quot;image&quot; alt=&quot;image&quot; src=&quot;https://img2018.cnblogs.com/blog/1328979/201901/1328979-20190130230604611-993947230.png&quot; border=&quot;0&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://img2018.cnblogs.com/blog/1328979/201901/1328979-20190130230605282-1176059043.png&quot;&gt;&lt;img width=&quot;640&quot; height=&quot;53&quot; title=&quot;image&quot; alt=&quot;image&quot; src=&quot;https://img2018.cnblogs.com/blog/1328979/201901/1328979-20190130230606061-1122670169.png&quot; border=&quot;0&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
</description>
<pubDate>Wed, 30 Jan 2019 15:06:00 +0000</pubDate>
<dc:creator>Wenzhongxiang</dc:creator>
<og:description>现有环境中有一台Windows Server做过定期备份计划，时间太久未做清理操作，收到磁盘报警邮件后需要及时释放该空间，具体操作步骤如下：当前备份计划信息如下：清理步骤如下：1.以管理身份运行CMD</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/wenzhongxiang/p/10340173.html</dc:identifier>
</item>
</channel>
</rss>