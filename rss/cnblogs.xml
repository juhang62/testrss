<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="css/feed.xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/" xmlns:og="http://ogp.me/ns#">
<channel>
<atom:link rel="self" href="http://192.168.1.4/fivefilters/makefulltextfeed.php?url=feed.cnblogs.com%2Fblog%2Fsitehome%2Frss&amp;max=10&amp;links=preserve&amp;exc=" />
<atom:link rel="alternate" title="Source URL" href="http://feed.cnblogs.com/blog/sitehome/rss" />
<atom:link rel="related" title="Subscribe to feed" href="http://www.subtome.com/#/subscribe?feeds=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed.cnblogs.com%252Fblog%252Fsitehome%252Frss%26max%3D10%26links%3Dpreserve%26exc%3D&amp;back=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed.cnblogs.com%252Fblog%252Fsitehome%252Frss%26max%3D10%26links%3Dpreserve%26exc%3D" />
<title>博客园_首页</title>
<link></link>
<description>代码改变世界</description>
<item>
<title>.NET ORM 分表分库【到底】怎么做？ - nicye</title>
<link>http://www.cnblogs.com/kellynic/p/13584095.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/kellynic/p/13584095.html</guid>
<description>&lt;h2 id=&quot;理论知识&quot;&gt;理论知识&lt;/h2&gt;
&lt;p&gt;分表 - 从表面意思上看呢，就是把一张表分成N多个小表，每一个小表都是完正的一张表。分表后数据都是存放在分表里，总表只是一个外壳，存取数据发生在一个一个的分表里面。分表后单表的并发能力提高了，磁盘I/O性能也提高了。并发能力为什么提高了呢，因为查寻一次所花的时间变短了，如果出现高并发的话，总表可以根据不同 的查询，将并发压力分到不同的小表里面。&lt;/p&gt;
&lt;p&gt;分库 - 把原本存储于一个库的数据分块存储到多个库上，把原本存储于一个表的数据分块存储到多个表上。数据库中的数据量不一定是可控的，在未进行分表分库的情况下，随着时间和业务的发展，库中的表会越来越多，表中的数据量也会越来越大，相应地，数据操作，增删改查的开销也会越来越大；另外，一台服务器的资源（CPU、磁盘、内存、IO等）是有限的，最终数据库所能承载的数据量、数据处理能力都将遭遇瓶颈。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/31407/202008/31407-20200828032759646-1618203847.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h2 id=&quot;情怀满满&quot;&gt;情怀满满&lt;/h2&gt;
&lt;p&gt;分表、分库在 .NET 下可谓是老大难题，简单点可以使用类似 mycat 中间件，但是就 .NET 平台的自身生态，很缺乏类似 sharding-jdbc 这样强大的轮子。&lt;/p&gt;
&lt;p&gt;本人就自身有限的技术水平和经验，对分表、分库进行分析，实现出自成一套的使用方法，虽然不极 sharding-jdbc 强大，但是还算比较通用、简单。但愿有朝一日出现一批真正 .NET 大神，造出伟大的开源项目，实现你我心中的抱负。&lt;/p&gt;
&lt;p&gt;这套分表、分库方法是建立在 .NET ORM FreeSql 之上做的，内容可能比较抽象，敬请谅解！后续会详解各种租户设计方案，除了按字段区分租户，还包括分库、分表的方案，敬请关注！&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/31407/202008/31407-20200828032759646-1618203847.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h2 id=&quot;入戏准备&quot;&gt;入戏准备&lt;/h2&gt;
&lt;p&gt;FreeSql 是 .Net ORM，能支持 .NetFramework4.0+、.NetCore、Xamarin、XAUI、Blazor、以及还有说不出来的运行平台，因为代码绿色无依赖，支持新平台非常简单。目前单元测试数量：5000+，Nuget下载数量：180K+，源码几乎每天都有提交。值得高兴的是 FreeSql 加入了 ncc 开源社区：&lt;a href=&quot;https://github.com/dotnetcore/FreeSql&quot;&gt;https://github.com/dotnetcore/FreeSql&lt;/a&gt;，加入组织之后社区责任感更大，需要更努力做好品质，为开源社区出一份力。&lt;/p&gt;
&lt;p&gt;QQ群：4336577(已满)、8578575(在线)、52508226(在线)&lt;/p&gt;
&lt;p&gt;为什么要重复造轮子？&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/31407/202005/31407-20200525013907903-1470982538.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;blockquote readability=&quot;7&quot;&gt;
&lt;p&gt;FreeSql 主要优势在于易用性上，基本是开箱即用，在不同数据库之间切换兼容性比较好。作者花了大量的时间精力在这个项目，肯请您花半小时了解下项目，谢谢。功能特性如下：&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;&lt;li&gt;支持 CodeFirst 对比结构变化迁移；&lt;/li&gt;
&lt;li&gt;支持 DbFirst 从数据库导入实体类；&lt;/li&gt;
&lt;li&gt;支持 丰富的表达式函数，自定义解析；&lt;/li&gt;
&lt;li&gt;支持 批量添加、批量更新、BulkCopy；&lt;/li&gt;
&lt;li&gt;支持 导航属性，贪婪加载、延时加载、级联保存；&lt;/li&gt;
&lt;li&gt;支持 读写分离、分表分库，租户设计；&lt;/li&gt;
&lt;li&gt;支持 MySql/SqlServer/PostgreSQL/Oracle/Sqlite/达梦/神通/人大金仓/MsAccess；&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;FreeSql 使用非常简单，【单机数据库】只需要定义一个 IFreeSql 对象即可：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-csharp&quot;&gt;static IFreeSql fsql = new FreeSql.FreeSqlBuilder()
    .UseConnectionString(FreeSql.DataType.MySql, connectionString)
    .UseAutoSyncStructure(true) //自动同步实体结构到数据库
    .Build(); //请务必定义成 Singleton 单例模式
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/31407/202008/31407-20200828032759646-1618203847.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h2 id=&quot;分表&quot;&gt;分表&lt;/h2&gt;
&lt;p&gt;既然是分表，那就大胆认为他是操作【单机数据库】，只需要对实体类进行动态映射表名即可实现，FreeSql 原生用法、FreeSql.Repository 仓储用法 都提供了 AsTable 方法对分表进行 CRUD 操作，例如：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-c#&quot;&gt;var repo = fsql.GetRepository&amp;lt;Log&amp;gt;();
repo.AsTable(oldname =&amp;gt; $&quot;{oldname}_201903&quot;);
//对 Log_201903 表 CRUD

repo.Insert(new Log { ... });
repo.Update(...);
repo.Delete(...);
repo.Select...;
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;AsTable 动态设置实体映射的表名，达到对分表的操作目的。除了 CRUD 操作，还提供了创建分表的功能：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;如果开启了自动同步结构功能 UseAutoSyncStructure(true)，则 AsTable 会自动创建对应分表；&lt;/li&gt;
&lt;li&gt;可以使用 fsql.CodeFirst.SyncStructure(typeof(实体类), &quot;分表名&quot;) 进行手工建表；&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;多数情况，我们都建议提前创建好分表，如果按月分表，手工创建一年的分表。&lt;/p&gt;
&lt;p&gt;目前这种算是比较简单入门的方案，远不及 mycat、sharding-jdbc 那么智能，比如：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;不能利用分表字段自动进行分表映射；&lt;/li&gt;
&lt;li&gt;不能在查询时根据 where 条件自动映射分表，甚至跨多个分表的联合查询；&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/31407/202008/31407-20200828032759646-1618203847.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h2 id=&quot;分库（单机）&quot;&gt;分库（单机）&lt;/h2&gt;
&lt;p&gt;分库，但是在同一个数据库服务器实例下。这种情况也可以使用 AsTable 方式进行操作，如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-c#&quot;&gt;var repo = fsql.GetRepository&amp;lt;Log&amp;gt;();
repo.AsTable(oldname =&amp;gt; $&quot;{201903}.dbo.{oldname}&quot;);
//对 [201903].dbo.Log CRUD
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;分库之后，老大难题是事务，如果使用 SqlServer 可以利用 TransactionScope 做简单的跨库事务，如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-c#&quot;&gt;var repoLog = fsql.GetRepository&amp;lt;Log&amp;gt;();
var repoComment = fsql.GetRepository&amp;lt;Comment&amp;gt;();
repoLog.AsTable(oldname =&amp;gt; $&quot;{201903}.dbo.{oldname}&quot;);
repoComment.AsTable(oldname =&amp;gt; $&quot;{201903}.dbo.{oldname}&quot;);

using (TransactionScope ts = new TransactionScope())
{
    repoComment.Insert(new Comment { ... });
    repoLog.Insert(new Log { ... });
    ts.Complete();
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/31407/202008/31407-20200828032759646-1618203847.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h2 id=&quot;分库（跨服务器）&quot;&gt;分库（跨服务器）&lt;/h2&gt;
&lt;p&gt;前面提到：【单机数据库】只需要定义一个 IFreeSql 对象即可。那分库是不是要定义很多个 IFreeSql 对象？答案是的。&lt;/p&gt;
&lt;p&gt;一般思路可以定义 static ConcurrentDictionary&amp;lt;string, IFreeSql&amp;gt; 存储所有 IFreeSql 对象（key = ConnectionString），当进行 CRUD 时获取到对应的 IFreeSql 即可。由于 IFreeSql 是静态单例设计长驻内存，分库数量太多的时候会浪费资源，因为不是所有分库都一直一直在访问。例如租户分库 10000 个，定义 10000 个 static IFreeSql？&lt;/p&gt;
&lt;p&gt;更好的办法可以使用 IdleBus 空闲对象管理容器，有效组织对象重复利用，自动创建、销毁，解决【实例】过多且长时间占用的问题。有时候想做一个单例对象重复使用提升性能，但是定义多了，有的又可能一直空闲着占用资源。专门解决：又想重复利用，又想少占资源的场景。&lt;a href=&quot;https://github.com/2881099/IdleBus&quot;&gt;https://github.com/2881099/IdleBus&lt;/a&gt;&lt;/p&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;dotnet add package IdleBus&lt;/p&gt;
&lt;/blockquote&gt;
&lt;pre&gt;
&lt;code class=&quot;language-csharp&quot;&gt;static IdleBus&amp;lt;IFreeSql&amp;gt; ib = new IdleBus&amp;lt;IFreeSql&amp;gt;(TimeSpan.FromMinutes(10));

ib.Register(&quot;db1&quot;, () =&amp;gt; new FreeSqlBuilder().UseConnectionString(DataType.MySql, &quot;str1&quot;).Build());
ib.Register(&quot;db2&quot;, () =&amp;gt; new FreeSqlBuilder().UseConnectionString(DataType.MySql, &quot;str2&quot;).Build());
ib.Register(&quot;db3&quot;, () =&amp;gt; new FreeSqlBuilder().UseConnectionString(DataType.SqlServer, &quot;str3&quot;).Build());
//...注册很多个

ib.Get(&quot;db1&quot;).Select&amp;lt;T&amp;gt;().Limit(10).ToList();
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;IdleBus 也是【单例】设计！主要的两个方法，注册，获取。idlebus 注册不是创建 IFreeSql，首次 Get 时才创建，后面会一直用已经创建的。还有一个超时机制，如果 10 分钟该 IFreeSql 未使用会被 Dispose，然后下一次又会创建新的 IFreeSql，如此反复。从而解决了 10000 个 IFreeSql 长驻内存的问题。&lt;/p&gt;
&lt;p&gt;还利用 AsyncLocal 特性扩展使用起来更加方便：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-c#&quot;&gt;public static class IdleBusExtesions
{
    static AsyncLocal&amp;lt;string&amp;gt; asyncDb = new AsyncLocal&amp;lt;string&amp;gt;();
    public static IdleBus&amp;lt;IFreeSql&amp;gt; ChangeDatabase(this IdleBus&amp;lt;IFreeSql&amp;gt; ib, string db)
    {
        asyncDb.Value = db;
        return ib;
    }
    public static IFreeSql Get(this IdleBus&amp;lt;IFreeSql&amp;gt; ib) =&amp;gt; ib.Get(asyncDb.Value ?? &quot;db1&quot;);
    public static IBaseRepository&amp;lt;T&amp;gt; GetRepository&amp;lt;T&amp;gt;(this IdleBus&amp;lt;IFreeSql&amp;gt; ib) where T : class 
        =&amp;gt; ib.Get().GetRepository&amp;lt;T&amp;gt;();
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;ul&gt;&lt;li&gt;使用 ChangeDatabase 切换 db；&lt;/li&gt;
&lt;li&gt;使用 Get() 获取当前 IFreeSql，省略每次都传递 db 参数；&lt;/li&gt;
&lt;li&gt;使用 GetRepository 获取当前 IFreeSql 对应的仓储类；&lt;/li&gt;
&lt;/ul&gt;&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;注意：使用 IdleBus 需要弱化 IFreeSql 的存在，每次都使用 ib.Get 获取 IFreeSql 对象；&lt;/p&gt;
&lt;/blockquote&gt;
&lt;pre&gt;
&lt;code class=&quot;language-c#&quot;&gt;IdleBus&amp;lt;IFreeSql&amp;gt; ib = ...; //单例注入

var fsql = ib.Get(); //获取当前租户对应的 IFreeSql

var fsql00102 = ib.ChangeDatabase(&quot;db2&quot;).Get(); //切换租户，后面的操作都是针对 db2

var songRepository = ib.GetRepository&amp;lt;Song&amp;gt;();
var detailRepository = ib.GetRepository&amp;lt;Detail&amp;gt;();
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;目前这种算是比较简单入门的方案，远不及 mycat、sharding-jdbc 那么智能，比如：没有实现跨库事务。&lt;/p&gt;
&lt;h2 id=&quot;写在最后&quot;&gt;写在最后&lt;/h2&gt;
&lt;p&gt;.NET 生态还处于较弱的状态，呼吁大家支持、踊跃参与开源项目，为下一个 .NET 开源社区五年计划做贡献。&lt;/p&gt;
&lt;p&gt;希望正在使用的、善良的您能动一动小手指，把文章转发一下，让更多人知道 .NET 有这样一个好用的 ORM 存在。谢谢了！！&lt;/p&gt;
&lt;p&gt;FreeSql 开源协议 MIT &lt;a href=&quot;https://github.com/dotnetcore/FreeSql&quot;&gt;https://github.com/dotnetcore/FreeSql&lt;/a&gt;，可以商用，文档齐全。QQ群：4336577(已满)、8578575(在线)、52508226(在线)&lt;/p&gt;
&lt;p&gt;如果你有好的 ORM 实现想法，欢迎给作者留言讨论，谢谢观看！&lt;/p&gt;
</description>
<pubDate>Sat, 29 Aug 2020 17:18:00 +0000</pubDate>
<dc:creator>nicye</dc:creator>
<og:description>理论知识 分表 - 从表面意思上看呢，就是把一张表分成N多个小表，每一个小表都是完正的一张表。分表后数据都是存放在分表里，总表只是一个外壳，存取数据发生在一个一个的分表里面。分表后单表的并发能力提高了</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/kellynic/p/13584095.html</dc:identifier>
</item>
<item>
<title>测试必须学spring RESTful Service（上） - 东方er</title>
<link>http://www.cnblogs.com/df888/p/13584047.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/df888/p/13584047.html</guid>
<description>&lt;p&gt;文末我会说说为什么测试必须学spring。&lt;/p&gt;

&lt;p&gt;REST，是指REpresentational State Transfer，有个精辟的解释什么是RESTful，&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;看url就知道要什么&lt;/li&gt;
&lt;li&gt;看method就知道干什么&lt;/li&gt;
&lt;li&gt;看status code就知道结果如何&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;实际上，RESTful API已经成为构建微服务的标准了，因为RESTful API容易build和consume。&lt;/p&gt;
&lt;p&gt;为什么选择REST？REST信奉web的规则，包括架构、效益和其他一切。这并非偶然，因为spring的作者Roy Fielding参与了十几项web规则的定义，这些规则决定了web怎么运行。&lt;/p&gt;
&lt;p&gt;效益是什么？web和它的核心协议，HTTP，提供了一系列特性，&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;适当的actions (&lt;code&gt;GET&lt;/code&gt;, &lt;code&gt;POST&lt;/code&gt;, &lt;code&gt;PUT&lt;/code&gt;, &lt;code&gt;DELETE&lt;/code&gt;, …)&lt;/li&gt;
&lt;li&gt;缓存&lt;/li&gt;
&lt;li&gt;重定向和转发&lt;/li&gt;
&lt;li&gt;安全（加密和鉴权）&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;这些都是创建可伸缩性services的关键因素。但也不是全部。&lt;/p&gt;
&lt;p&gt;web是由大量细小的规则构成的，所以不会存在什么“标准之争”，因此就能轻松的发展。&lt;/p&gt;
&lt;p&gt;开发们（Javaer）可以使用第三方工具来实现这些不同的规则，在指尖就可以立即拥有client和server的技术。&lt;/p&gt;
&lt;p&gt;所以建立在HTTP之上的REST APIs提供了创建灵活APIs的方法，&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;支持向后兼容&lt;/li&gt;
&lt;li&gt;可扩展的API&lt;/li&gt;
&lt;li&gt;可伸缩性的services&lt;/li&gt;
&lt;li&gt;安全性的services&lt;/li&gt;
&lt;li&gt;无状态到有状态的services&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;但是，REST并不是一个普遍的标准，而是一个方法，一个style，一系列架构上的约束，来帮你创建web-scale的系统，区别这一点很重要。&lt;/p&gt;

&lt;p&gt;到&lt;a href=&quot;https://start.spring.io/&quot;&gt;Spring Initializr&lt;/a&gt;这个网址选择，&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;Web&lt;/li&gt;
&lt;li&gt;JPA&lt;/li&gt;
&lt;li&gt;H2&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;然后生成项目。下载&lt;code&gt;.zip&lt;/code&gt;文件。解压。就有了一个基于Maven的示例项目，包括一个&lt;code&gt;pom.xml&lt;/code&gt;文件。&lt;/p&gt;
&lt;p&gt;Spirng Boot可以用任何IDE，包括Eclipse、IntelliJ IDEA、Netbeans等。&lt;/p&gt;
&lt;p&gt;Eclipse可以使用一个工具STS(The Spring Tool Suite)。&lt;/p&gt;

&lt;p&gt;我们先以最简单的示例开始。先抛弃REST的概念，后面再添加REST，在示例中感受到不同之处。&lt;/p&gt;
&lt;p&gt;示例建模了一个简单的工资单service，管理公司employees。简言之，需要存储employee objects到一个H2内存数据库（Java编写的嵌入式数据库引擎），然后通过JPA（Java Persistence API，把实体对象持久化到数据库，是一种ORM规范，Hibernate是具体实现的框架）访问。它会被封装到Spring MVC layer进行远程访问。&lt;/p&gt;
&lt;p&gt;nonrest/src/main/java/payroll/Employee.java&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;package payroll;

import java.util.Objects;

import javax.persistence.Entity;
import javax.persistence.GeneratedValue;
import javax.persistence.Id;

@Entity
class Employee {

  private @Id @GeneratedValue Long id;
  private String name;
  private String role;

  Employee() {}

  Employee(String name, String role) {

    this.name = name;
    this.role = role;
  }

  public Long getId() {
    return this.id;
  }

  public String getName() {
    return this.name;
  }

  public String getRole() {
    return this.role;
  }

  public void setId(Long id) {
    this.id = id;
  }

  public void setName(String name) {
    this.name = name;
  }

  public void setRole(String role) {
    this.role = role;
  }

  @Override
  public boolean equals(Object o) {

    if (this == o)
      return true;
    if (!(o instanceof Employee))
      return false;
    Employee employee = (Employee) o;
    return Objects.equals(this.id, employee.id) &amp;amp;&amp;amp; Objects.equals(this.name, employee.name)
        &amp;amp;&amp;amp; Objects.equals(this.role, employee.role);
  }

  @Override
  public int hashCode() {
    return Objects.hash(this.id, this.name, this.role);
  }

  @Override
  public String toString() {
    return &quot;Employee{&quot; + &quot;id=&quot; + this.id + &quot;, name='&quot; + this.name + '\'' + &quot;, role='&quot; + this.role + '\'' + '}';
  }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;代码不多，这个Java class包含了，&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;code&gt;@Entity&lt;/code&gt; 是JPA注解，标记这个object是存储在基于JPA的数据库的。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;id&lt;/code&gt;, &lt;code&gt;name&lt;/code&gt;, 和 &lt;code&gt;role&lt;/code&gt; 是domain object的属性，第一个被多个JPA注解标记的，是主键，通过JPA provider实现了自增。&lt;/li&gt;
&lt;li&gt;当创建新实例的时候，就会创建custom constructor，但是还没有id。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;domain object定义好以后，就可以用&lt;a href=&quot;https://spring.io/guides/gs/accessing-data-jpa/&quot;&gt;Spring Data JPA&lt;/a&gt;来处理冗长的数据库交互。Spring Data repositories是一些接口，可以对后端数据库进行reading, updating, deleting, 和 creating记录。一些repositories也支持适当的data paging和sorting。Spring Data基于接口中的methods的命名约定来合成实现。&lt;/p&gt;
&lt;p&gt;Spring Data JPA是Spring Data家族成员之一，只需要写repository接口，包括custom finder methods，Spring会自动提供实现。除了JPA之外，还有多种repository实现，如Spring Data MongoDB, Spring Data GemFire, Spring Data Cassandra等。&lt;/p&gt;
&lt;p&gt;nonrest/src/main/java/payroll/EmployeeRepository.java&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;package payroll;

import org.springframework.data.jpa.repository.JpaRepository;

interface EmployeeRepository extends JpaRepository&amp;lt;Employee, Long&amp;gt; {

}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;接口继承了Spring Data JPA的&lt;code&gt;JpaRepository&lt;/code&gt;，定义domain type为&lt;code&gt;Employee&lt;/code&gt;，id type为&lt;code&gt;Long&lt;/code&gt;。这个接口表面上是空的，但是支持，&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;Creating new instances&lt;/li&gt;
&lt;li&gt;Updating existing ones&lt;/li&gt;
&lt;li&gt;Deleting&lt;/li&gt;
&lt;li&gt;Finding (one, all, by simple or complex properties)&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;Spring Data的&lt;a href=&quot;https://docs.spring.io/spring-data/jpa/docs/current/reference/html/#repositories&quot;&gt;repository solution&lt;/a&gt;可以避开数据存储细节，使用domain-specific术语来解决大部分问题。&lt;/p&gt;
&lt;p&gt;不管你信不信，反正我信了！现在已经足够来启动一个应用了！Spring Boot应用至少有一个&lt;code&gt;public static void main&lt;/code&gt; entry-point，和&lt;code&gt;@SpringBootApplication&lt;/code&gt;注解。&lt;/p&gt;
&lt;p&gt;nonrest/src/main/java/payroll/PayrollApplication.java&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;package payroll;

import org.springframework.boot.SpringApplication;
import org.springframework.boot.autoconfigure.SpringBootApplication;

@SpringBootApplication
public class PayrollApplication {

  public static void main(String... args) {
    SpringApplication.run(PayrollApplication.class, args);
  }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;@SpringBootApplication&lt;/code&gt;是元注解，引入了&lt;strong&gt;component scanning&lt;/strong&gt;, &lt;strong&gt;autoconfiguration&lt;/strong&gt;, 和&lt;strong&gt;property support&lt;/strong&gt;。Spring Boot会启动一个servlet container，并为我们的service服务。&lt;/p&gt;
&lt;p&gt;然而，没有数据的应用有点搞笑，先添点数据。下面这个类会由Spring自动加载，&lt;/p&gt;
&lt;p&gt;nonrest/src/main/java/payroll/LoadDatabase.java&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;package payroll;

import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import org.springframework.boot.CommandLineRunner;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;

@Configuration
class LoadDatabase {

  private static final Logger log = LoggerFactory.getLogger(LoadDatabase.class);

  @Bean
  CommandLineRunner initDatabase(EmployeeRepository repository) {

    return args -&amp;gt; {
      log.info(&quot;Preloading &quot; + repository.save(new Employee(&quot;Bilbo Baggins&quot;, &quot;burglar&quot;)));
      log.info(&quot;Preloading &quot; + repository.save(new Employee(&quot;Frodo Baggins&quot;, &quot;thief&quot;)));
    };
  }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;Spring加载这个类的时候会发生什么？&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;一旦应用上下文加载后，Spring Boot就会运行所有的&lt;code&gt;CommandLineRunner&lt;/code&gt; beans&lt;/li&gt;
&lt;li&gt;runner会请求刚才创建的&lt;code&gt;EmployeeRepository&lt;/code&gt;的copy&lt;/li&gt;
&lt;li&gt;然后创建2个对象，并存储&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;右键&lt;strong&gt;Run&lt;/strong&gt; &lt;code&gt;PayRollApplication&lt;/code&gt;，&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-shell&quot;&gt;...
2018-08-09 11:36:26.169  INFO 74611 --- [main] payroll.LoadDatabase : Preloading Employee(id=1, name=Bilbo Baggins, role=burglar)
2018-08-09 11:36:26.174  INFO 74611 --- [main] payroll.LoadDatabase : Preloading Employee(id=2, name=Frodo Baggins, role=thief)
...
&lt;/code&gt;
&lt;/pre&gt;

&lt;p&gt;为了用web layer封装repository，必须转Spring MVC。Spring Boot简化了这部分工作，基础代码只有一点点，从而把编码重心放到actions，&lt;/p&gt;
&lt;p&gt;nonrest/src/main/java/payroll/EmployeeController.java&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;package payroll;

import java.util.List;

import org.springframework.web.bind.annotation.DeleteMapping;
import org.springframework.web.bind.annotation.GetMapping;
import org.springframework.web.bind.annotation.PathVariable;
import org.springframework.web.bind.annotation.PostMapping;
import org.springframework.web.bind.annotation.PutMapping;
import org.springframework.web.bind.annotation.RequestBody;
import org.springframework.web.bind.annotation.RestController;

@RestController
class EmployeeController {

  private final EmployeeRepository repository;

  EmployeeController(EmployeeRepository repository) {
    this.repository = repository;
  }

  // Aggregate root

  @GetMapping(&quot;/employees&quot;)
  List&amp;lt;Employee&amp;gt; all() {
    return repository.findAll();
  }

  @PostMapping(&quot;/employees&quot;)
  Employee newEmployee(@RequestBody Employee newEmployee) {
    return repository.save(newEmployee);
  }

  // Single item

  @GetMapping(&quot;/employees/{id}&quot;)
  Employee one(@PathVariable Long id) {

    return repository.findById(id)
      .orElseThrow(() -&amp;gt; new EmployeeNotFoundException(id));
  }

  @PutMapping(&quot;/employees/{id}&quot;)
  Employee replaceEmployee(@RequestBody Employee newEmployee, @PathVariable Long id) {

    return repository.findById(id)
      .map(employee -&amp;gt; {
        employee.setName(newEmployee.getName());
        employee.setRole(newEmployee.getRole());
        return repository.save(employee);
      })
      .orElseGet(() -&amp;gt; {
        newEmployee.setId(id);
        return repository.save(newEmployee);
      });
  }

  @DeleteMapping(&quot;/employees/{id}&quot;)
  void deleteEmployee(@PathVariable Long id) {
    repository.deleteById(id);
  }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;ul&gt;&lt;li&gt;&lt;code&gt;@RestController&lt;/code&gt; 表明了每个方法返回的数据会直接写入到响应的body里面，而不是render一个template。&lt;/li&gt;
&lt;li&gt;constructor注入了一个&lt;code&gt;EmployeeRepository&lt;/code&gt; 到controller（依赖注入）。&lt;/li&gt;
&lt;li&gt;每个operations的路由 (&lt;code&gt;@GetMapping&lt;/code&gt;, &lt;code&gt;@PostMapping&lt;/code&gt;, &lt;code&gt;@PutMapping&lt;/code&gt; 和 &lt;code&gt;@DeleteMapping&lt;/code&gt;, 对应HTTP &lt;code&gt;GET&lt;/code&gt;, &lt;code&gt;POST&lt;/code&gt;, &lt;code&gt;PUT&lt;/code&gt;, 和 &lt;code&gt;DELETE&lt;/code&gt; )。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;EmployeeNotFoundException&lt;/code&gt; 是当employee找不到时抛出的异常。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;nonrest/src/main/java/payroll/EmployeeNotFoundException.java&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;package payroll;

class EmployeeNotFoundException extends RuntimeException {

  EmployeeNotFoundException(Long id) {
    super(&quot;Could not find employee &quot; + id);
  }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;当抛出&lt;code&gt;EmployeeNotFoundException&lt;/code&gt;，Spring MVC configuration会render一个&lt;code&gt;HTTP 404&lt;/code&gt;，&lt;/p&gt;
&lt;p&gt;nonrest/src/main/java/payroll/EmployeeNotFoundAdvice.java&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;package payroll;

import org.springframework.http.HttpStatus;
import org.springframework.web.bind.annotation.ControllerAdvice;
import org.springframework.web.bind.annotation.ExceptionHandler;
import org.springframework.web.bind.annotation.ResponseBody;
import org.springframework.web.bind.annotation.ResponseStatus;

@ControllerAdvice
class EmployeeNotFoundAdvice {

  @ResponseBody
  @ExceptionHandler(EmployeeNotFoundException.class)
  @ResponseStatus(HttpStatus.NOT_FOUND)
  String employeeNotFoundHandler(EmployeeNotFoundException ex) {
    return ex.getMessage();
  }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;ul&gt;&lt;li&gt;&lt;code&gt;@ResponseBody&lt;/code&gt; 表示advice会直接render到response body。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;@ExceptionHandler&lt;/code&gt; 配置了只有抛&lt;code&gt;EmployeeNotFoundException&lt;/code&gt; 异常的时候，advice才会响应。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;@ResponseStatus&lt;/code&gt; 表示发出 &lt;code&gt;HttpStatus.NOT_FOUND&lt;/code&gt;, 比如 &lt;strong&gt;HTTP 404&lt;/strong&gt;。&lt;/li&gt;
&lt;li&gt;advice的body生成具体内容。示例中，返回了异常的message。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;运行应用有多种方式，可以右键&lt;code&gt;PayRollApplication&lt;/code&gt;中的&lt;code&gt;public static void main&lt;/code&gt;，然后选择IDE的&lt;strong&gt;Run&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;如果是Spring Initializr，可以输入命令行，&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-shell&quot;&gt;$ ./mvnw clean spring-boot:run
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;如果是本地安装了maven，可以输入命令行，&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-shell&quot;&gt;$ mvn clean spring-boot:run
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;一旦应用启动了，可以查看http通信，&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-shell&quot;&gt;$ curl -v localhost:8080/employees
&lt;/code&gt;
&lt;/pre&gt;
&lt;pre&gt;
&lt;code class=&quot;language-shell&quot;&gt;*   Trying ::1...
* TCP_NODELAY set
* Connected to localhost (::1) port 8080 (#0)
&amp;gt; GET /employees HTTP/1.1
&amp;gt; Host: localhost:8080
&amp;gt; User-Agent: curl/7.54.0
&amp;gt; Accept: */*
&amp;gt;
&amp;lt; HTTP/1.1 200
&amp;lt; Content-Type: application/json;charset=UTF-8
&amp;lt; Transfer-Encoding: chunked
&amp;lt; Date: Thu, 09 Aug 2018 17:58:00 GMT
&amp;lt;
* Connection #0 to host localhost left intact
[{&quot;id&quot;:1,&quot;name&quot;:&quot;Bilbo Baggins&quot;,&quot;role&quot;:&quot;burglar&quot;},{&quot;id&quot;:2,&quot;name&quot;:&quot;Frodo Baggins&quot;,&quot;role&quot;:&quot;thief&quot;}]
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;能看到预加载的数据。&lt;/p&gt;
&lt;p&gt;如果请求一个不存在的employee，&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-shell&quot;&gt;$ curl -v localhost:8080/employees/99
&lt;/code&gt;
&lt;/pre&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;*   Trying ::1...
* TCP_NODELAY set
* Connected to localhost (::1) port 8080 (#0)
&amp;gt; GET /employees/99 HTTP/1.1
&amp;gt; Host: localhost:8080
&amp;gt; User-Agent: curl/7.54.0
&amp;gt; Accept: */*
&amp;gt;
&amp;lt; HTTP/1.1 404
&amp;lt; Content-Type: text/plain;charset=UTF-8
&amp;lt; Content-Length: 26
&amp;lt; Date: Thu, 09 Aug 2018 18:00:56 GMT
&amp;lt;
* Connection #0 to host localhost left intact
Could not find employee 99
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;HTTP 404&lt;/strong&gt; error，并打印了message，&lt;strong&gt;Could not find employee 99&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;使用&lt;code&gt;-X&lt;/code&gt;发个POST请求，创建新的&lt;code&gt;Employee&lt;/code&gt;，&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-shell&quot;&gt;$ curl -X POST localhost:8080/employees -H 'Content-type:application/json' -d '{&quot;name&quot;: &quot;Samwise Gamgee&quot;, &quot;role&quot;: &quot;gardener&quot;}'
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;使用&lt;code&gt;PUT&lt;/code&gt;更新，&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-shell&quot;&gt;$ curl -X PUT localhost:8080/employees/3 -H 'Content-type:application/json' -d '{&quot;name&quot;: &quot;Samwise Gamgee&quot;, &quot;role&quot;: &quot;ring bearer&quot;}'
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;使用&lt;code&gt;Delete&lt;/code&gt;删除，&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-shell&quot;&gt;$ curl -X DELETE localhost:8080/employees/3
$ curl localhost:8080/employees/3
Could not find employee 3
&lt;/code&gt;
&lt;/pre&gt;

&lt;p&gt;现在已经实现了基于web的service，但是是非REST的，&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;像&lt;code&gt;/employees/3&lt;/code&gt;这种漂亮的URLs，不一定是REST&lt;/li&gt;
&lt;li&gt;只用了 &lt;code&gt;GET&lt;/code&gt;, &lt;code&gt;POST&lt;/code&gt; 等，不一定是REST&lt;/li&gt;
&lt;li&gt;实现了所有CRUD操作，不一定是REST&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;那到底怎么样才算REST？&lt;/p&gt;
&lt;p&gt;实际上现在创建的这个应该叫做&lt;strong&gt;RPC&lt;/strong&gt; (&lt;strong&gt;Remote Procedure Call&lt;/strong&gt; 远程过程调用)。因为并不知道以何种方式来和这个service交互。如果发布这个代码，还必须写个文档或者搞个开发门户网站，来把所有细节描述清楚。&lt;/p&gt;
&lt;p&gt;看看Roy Fielding的这段话，是如何区别&lt;strong&gt;REST&lt;/strong&gt; 和&lt;strong&gt;RPC&lt;/strong&gt;的，&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;I am getting frustrated by the number of people calling any HTTP-based interface a REST API. Today’s example is the SocialSite REST API. That is RPC. It screams RPC. There is so much coupling on display that it should be given an X rating.

What needs to be done to make the REST architectural style clear on the notion that hypertext is a constraint? In other words, if the engine of application state (and hence the API) is not being driven by hypertext, then it cannot be RESTful and cannot be a REST API. Period. Is there some broken manual somewhere that needs to be fixed?

— Roy Fielding
https://roy.gbiv.com/untangled/2008/rest-apis-must-be-hypertext-driven
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;大概意思就是，应用状态引擎（API）不是超文本驱动的（我的理解是，像超文本一样携带一个地址，可以寻址定位信息，如超文本的link和id属性），就不是RESTful。&lt;/p&gt;
&lt;p&gt;不包括hypermedia的坏处，就是clients必须硬编码URIs来导航API。这导致了电子商务兴起之前同样的脆弱特性。JSON output需要优化。&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://spring.io/projects/spring-hateoas&quot;&gt;Spring HATEOAS&lt;/a&gt;，是一个spring项目，旨在帮你写hypermedia-driven outputs。&lt;/p&gt;
&lt;p&gt;接下来RESTful开搞，先添加Spring HATEOAS到pom.xml，&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-xml&quot;&gt;&amp;lt;dependency&amp;gt;
        &amp;lt;groupId&amp;gt;org.springframework.boot&amp;lt;/groupId&amp;gt;
        &amp;lt;artifactId&amp;gt;spring-boot-starter-hateoas&amp;lt;/artifactId&amp;gt;
&amp;lt;/dependency&amp;gt;
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;这个小library会提供定义RESTful service的constructs，然后以可接受的格式render，以便client消费。&lt;/p&gt;
&lt;p&gt;对任何RESTful service来说，一个关键的要素，是给相关的操作添加&lt;a href=&quot;https://tools.ietf.org/html/rfc8288&quot;&gt;links&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;Getting a single item resource&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;@GetMapping(&quot;/employees/{id}&quot;)
EntityModel&amp;lt;Employee&amp;gt; one(@PathVariable Long id) {

  Employee employee = repository.findById(id) //
      .orElseThrow(() -&amp;gt; new EmployeeNotFoundException(id));

  return EntityModel.of(employee, //
      linkTo(methodOn(EmployeeController.class).one(id)).withSelfRel(),
      linkTo(methodOn(EmployeeController.class).all()).withRel(&quot;employees&quot;));
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;跟之前非REST有些类似，但也有不同，&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;方法的返回值从 &lt;code&gt;Employee&lt;/code&gt; 变成了 &lt;code&gt;EntityModel&amp;lt;Employee&amp;gt;&lt;/code&gt;。&lt;code&gt;EntityModel&amp;lt;T&amp;gt;&lt;/code&gt; 是Spring HATEOAS的通用container，不仅包含data，也包含links集合。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;linkTo(methodOn(EmployeeController.class).one(id)).withSelfRel()&lt;/code&gt; 让Spring HATEOAS创建link到 &lt;code&gt;EmployeeController&lt;/code&gt; 's &lt;code&gt;one()&lt;/code&gt; 方法，并标记为&lt;a href=&quot;https://www.iana.org/assignments/link-relations/link-relations.xhtml&quot;&gt;self&lt;/a&gt; link。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;linkTo(methodOn(EmployeeController.class).all()).withRel(&quot;employees&quot;)&lt;/code&gt; 让Spring HATEOAS创建link到aggregate root（聚合根）， &lt;code&gt;all()&lt;/code&gt;，叫做&quot;employees&quot;。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;创建link是什么意思？Spring HATEOAS的核心types之一就是&lt;code&gt;Link&lt;/code&gt;，包括一个 &lt;strong&gt;URI&lt;/strong&gt; 和 一个 &lt;strong&gt;rel&lt;/strong&gt; (relation)。正是Links改变了web。&lt;/p&gt;
&lt;p&gt;在World Wide Web之前，其他的document systems会render information or links，但正是带有这种关系metadata的documents link把web连在了一起。&lt;/p&gt;
&lt;p&gt;Roy Fielding鼓励使用相同的技术来创建APIs，links便是其中之一。&lt;/p&gt;
&lt;p&gt;如果重启应用，查询employee &lt;em&gt;Bilbo&lt;/em&gt;，会有一些不同，&lt;/p&gt;
&lt;p&gt;RESTful representation of a single employee&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-json&quot;&gt;{
  &quot;id&quot;: 1,
  &quot;name&quot;: &quot;Bilbo Baggins&quot;,
  &quot;role&quot;: &quot;burglar&quot;,
  &quot;_links&quot;: {
    &quot;self&quot;: {
      &quot;href&quot;: &quot;http://localhost:8080/employees/1&quot;
    },
    &quot;employees&quot;: {
      &quot;href&quot;: &quot;http://localhost:8080/employees&quot;
    }
  }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;不只有&lt;code&gt;id&lt;/code&gt;, &lt;code&gt;name&lt;/code&gt; and &lt;code&gt;role&lt;/code&gt;，还有 &lt;code&gt;_links&lt;/code&gt;，包括2个URLs。整个文档是采用&lt;a href=&quot;http://stateless.co/hal_specification.html&quot;&gt;HAL&lt;/a&gt;格式化的。&lt;/p&gt;
&lt;p&gt;HAL是一个轻量的&lt;a href=&quot;https://tools.ietf.org/html/draft-kelly-json-hal-08&quot;&gt;mediatype&lt;/a&gt;，不仅允许encoding data，也能hypermedia controls，提醒consumers到能导航到的API的其他部分。在本示例中，就是&quot;self&quot;（类似于代码里的&lt;code&gt;this&lt;/code&gt;） link和能返回到&lt;strong&gt;aggregate root&lt;/strong&gt;的link。&lt;/p&gt;
&lt;p&gt;为了让aggregate root也更RESTful，那么会希望包含top level links，和包含其他RESTful components，&lt;/p&gt;
&lt;p&gt;Getting an aggregate root resource&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;@GetMapping(&quot;/employees&quot;)
CollectionModel&amp;lt;EntityModel&amp;lt;Employee&amp;gt;&amp;gt; all() {

  List&amp;lt;EntityModel&amp;lt;Employee&amp;gt;&amp;gt; employees = repository.findAll().stream()
      .map(employee -&amp;gt; EntityModel.of(employee,
          linkTo(methodOn(EmployeeController.class).one(employee.getId())).withSelfRel(),
          linkTo(methodOn(EmployeeController.class).all()).withRel(&quot;employees&quot;)))
      .collect(Collectors.toList());

  return CollectionModel.of(employees, linkTo(methodOn(EmployeeController.class).all()).withSelfRel());
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;我擦！之前只有一个方法&lt;code&gt;repository.findAll()&lt;/code&gt;！现在多了这么多代码！看不懂！不慌！排着队一个一个来！&lt;/p&gt;
&lt;p&gt;&lt;code&gt;CollectionModel&amp;lt;&amp;gt;&lt;/code&gt;是Spring HATEOAS的另外一个container，用于封装集合，以及links。&lt;/p&gt;
&lt;p&gt;封装集合？employees集合？&lt;/p&gt;
&lt;p&gt;不完全是。&lt;/p&gt;
&lt;p&gt;既然已经在说REST了，那么封装的是&lt;strong&gt;employee resources&lt;/strong&gt;的集合。&lt;/p&gt;
&lt;p&gt;这就是为什么获取了所有employees后，还需要转换为&lt;code&gt;EntityModel&amp;lt;Employee&amp;gt;&lt;/code&gt;的list。&lt;/p&gt;
&lt;p&gt;重启之后，获取aggregate root，&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-json&quot;&gt;{
  &quot;_embedded&quot;: {
    &quot;employeeList&quot;: [
      {
        &quot;id&quot;: 1,
        &quot;name&quot;: &quot;Bilbo Baggins&quot;,
        &quot;role&quot;: &quot;burglar&quot;,
        &quot;_links&quot;: {
          &quot;self&quot;: {
            &quot;href&quot;: &quot;http://localhost:8080/employees/1&quot;
          },
          &quot;employees&quot;: {
            &quot;href&quot;: &quot;http://localhost:8080/employees&quot;
          }
        }
      },
      {
        &quot;id&quot;: 2,
        &quot;name&quot;: &quot;Frodo Baggins&quot;,
        &quot;role&quot;: &quot;thief&quot;,
        &quot;_links&quot;: {
          &quot;self&quot;: {
            &quot;href&quot;: &quot;http://localhost:8080/employees/2&quot;
          },
          &quot;employees&quot;: {
            &quot;href&quot;: &quot;http://localhost:8080/employees&quot;
          }
        }
      }
    ]
  },
  &quot;_links&quot;: {
    &quot;self&quot;: {
      &quot;href&quot;: &quot;http://localhost:8080/employees&quot;
    }
  }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;这个aggregate root，提供了employee resources的集合，有一个top-level &lt;strong&gt;&quot;self&quot;&lt;/strong&gt; link。 &lt;strong&gt;&quot;collection&quot;&lt;/strong&gt;列在&lt;strong&gt;&quot;_embedded&quot;&lt;/strong&gt;下面。这就是HAL怎么表示集合。&lt;/p&gt;
&lt;p&gt;集合中每个独立的成员，都有information和关联的links。&lt;/p&gt;
&lt;p&gt;添加links到底有什么意义？它使得随着时间的推移发展REST services成为可能。已存在的links能保留，新的links在未来被添加。新的clients可能用新的links，同时遗留clients仍然能用老的links。如果services需要重定位和移动，那这就会非常有用。只要link结构保留，clients就仍然能查找和交互。&lt;/p&gt;
&lt;p&gt;&lt;em&gt;后续内容请等待《测试必须学spring RESTful Service（下）》&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;参考资料&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://spring.io/guides/tutorials/rest/&quot;&gt;https://spring.io/guides/tutorials/rest/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;高级测试，需要懂架构，需要懂开发，需要能和开发在同一个Level交流。除了公司项目以外，业务时间是很少有合适的方式去学习一些开发技术的。尤其是对于我这种对代码不太敏感，对技术反应有些迟钝的。光靠自己零零散散的学习，是很难真正提升的。那么有一个比较好的方式，就是去看一些成熟的成体系的东西。对于Web来说，没有任何一个框架比得上Java Spring成熟。在spring里面可以了解到很多开发的技术点，这对了解整个技术栈是很有效的方式。虽然我平时写Python比较多（毕竟生产力很强大），但仍然喜欢学Java，这样才能接触到更完整的生态。让自己的测试眼界更宽广。&lt;/p&gt;
&lt;p&gt;&lt;span&gt;版权申明：本文为博主原创文章，转载请保留原文链接及作者。&lt;/span&gt;&lt;/p&gt;
&lt;hr/&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1629545/202008/1629545-20200829190437010-1052781058.png&quot;/&gt;</description>
<pubDate>Sat, 29 Aug 2020 16:11:00 +0000</pubDate>
<dc:creator>东方er</dc:creator>
<og:description>文末我会说说为什么测试必须学spring。 REST REST，是指REpresentational State Transfer，有个精辟的解释什么是RESTful， 看url就知道要什么 看met</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/df888/p/13584047.html</dc:identifier>
</item>
<item>
<title>【原创】Linux虚拟化KVM-Qemu分析（二）之ARMv8虚拟化 - LoyenWang</title>
<link>http://www.cnblogs.com/LoyenWang/p/13584020.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/LoyenWang/p/13584020.html</guid>
<description>&lt;ul&gt;&lt;li&gt;&lt;code&gt;Read the fucking source code!&lt;/code&gt; --By 鲁迅&lt;/li&gt;
&lt;li&gt;&lt;code&gt;A picture is worth a thousand words.&lt;/code&gt; --By 高尔基&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;说明：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;KVM版本：5.9.1&lt;/li&gt;
&lt;li&gt;QEMU版本：5.0.0&lt;/li&gt;
&lt;li&gt;工具：Source Insight 3.5， Visio&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1771657/202008/1771657-20200829232438753-619940029.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;KVM虚拟化离不开底层硬件的支持，本文将介绍ARMv8架构处理器对虚拟化的支持，包括内存虚拟化、中断虚拟化、I/O虚拟化等内容；&lt;/li&gt;
&lt;li&gt;ARM处理器主要用于移动终端领域，近年也逐渐往服务器领域靠拢，对虚拟化也有了较为完善的支持；&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Hypervisor&lt;/code&gt;软件，涵盖的功能包括：内存管理、设备模拟、设备分配、异常处理、指令捕获、虚拟异常管理、中断控制器管理、调度、上下文切换、内存转换、多个虚拟地址空间管理等；&lt;/li&gt;
&lt;li&gt;本文描述的ARMv8虚拟化支持，对于理解&lt;code&gt;arch/arm64/kvm&lt;/code&gt;下的代码很重要，脱离硬件去看Architecture-Specific代码，那是耍流氓；&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;开始旅程！&lt;/p&gt;

&lt;h2 id=&quot;21-exception-level&quot;&gt;2.1 Exception Level&lt;/h2&gt;
&lt;ul&gt;&lt;li&gt;ARMv7之前的架构，定义了一个处理器的异常处理模式，比如&lt;code&gt;USR, FIQ, IRQ, SVC, ABT, UND, SYS, HYP, MON&lt;/code&gt;等，各个异常模式所处的特权级不一样，比如&lt;code&gt;USR&lt;/code&gt;模式的特权级就为&lt;code&gt;PL0&lt;/code&gt;，对应为用户态程序运行；&lt;/li&gt;
&lt;li&gt;处理器的异常模式可以在特权级软件控制下进行主动切换，比如修改&lt;code&gt;CPSR&lt;/code&gt;寄存器，也可以被动进行异常模式切换，典型的比如中断来临时切换到&lt;code&gt;IRQ模式&lt;/code&gt;；&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;ARMv7处理器的异常模式如下表所示：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1771657/202008/1771657-20200829232458451-1431013725.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;然鹅，到了ARMv8，&lt;code&gt;Exception Level(EL)&lt;/code&gt;取代了特权级，其中处理器的异常模式与&lt;code&gt;Exception Level&lt;/code&gt;的映射关系如下图：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1771657/202008/1771657-20200829232734015-1125516073.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;当异常发生时，处理器将改变&lt;code&gt;Exception Level&lt;/code&gt;（相当于ARMv7中的处理器模式切换），来处理异常类型；&lt;/li&gt;
&lt;li&gt;图中可以看出&lt;code&gt;Hypervisor&lt;/code&gt;运行在&lt;code&gt;EL2&lt;/code&gt;，而&lt;code&gt;Guest OS&lt;/code&gt;运行在&lt;code&gt;EL1&lt;/code&gt;，可以通过&lt;code&gt;HVC (Hypervisor Call)&lt;/code&gt;指令向&lt;code&gt;Hypervisor&lt;/code&gt;请求服务，响应虚拟化请求时就涉及到了&lt;code&gt;Exception Level&lt;/code&gt;的切换；&lt;/li&gt;
&lt;/ul&gt;&lt;h2 id=&quot;22-stage-2-translation&quot;&gt;2.2 Stage 2 translation&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;Stage 2转换&lt;/code&gt;与内存虚拟化息息相关，这部分内容不仅包括常规的内存映射访问，还包含了基于内存映射的I/O(&lt;code&gt;MMIO&lt;/code&gt;)访问，以及系统内存管理单元(&lt;code&gt;SMMUs&lt;/code&gt;)控制下的内存访问。&lt;/p&gt;
&lt;h3 id=&quot;221-内存映射&quot;&gt;2.2.1 内存映射&lt;/h3&gt;
&lt;p&gt;OS在访问物理内存前，需要先建立页表来维护虚拟地址到物理地址的映射关系，看过之前内存管理分析的同学应该熟悉下边这张图，这个可以认为是&lt;code&gt;Stage 1转换&lt;/code&gt;：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1771657/202008/1771657-20200829232749769-1606100875.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;当有了虚拟机时，情况就不太一样了，比如Qemu运行在Linux系统之上时，它只是Linux系统的一个用户进程，&lt;code&gt;Guest OS&lt;/code&gt;所认为自己访问的物理地址，其实是Linux的用户进程虚拟地址，到最终的物理地址还需要进一步的映射；&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Hypervisor&lt;/code&gt;可以通过&lt;code&gt;Stage 2转换&lt;/code&gt;来控制虚拟机的内存视图，控制虚拟机是否可以访问某块物理内存，进而达到隔离的目的；&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1771657/202008/1771657-20200829232831670-243204921.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;ul readability=&quot;6&quot;&gt;&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;整个地址的映射分成了两个阶段：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;&lt;code&gt;Stage 1: VA(Virutal Address) -&amp;gt; IPA(Intermediate Physical Address)&lt;/code&gt;，操作系统控制&lt;code&gt;Stage 1转换&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Stage 2: IPA(Intermediate Physical Address) -&amp;gt; PA(Physical Address)&lt;/code&gt;，&lt;code&gt;Hypervisor&lt;/code&gt;控制&lt;code&gt;Stage 2转换&lt;/code&gt;;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;li readability=&quot;1&quot;&gt;
&lt;p&gt;&lt;code&gt;Stage 2转换&lt;/code&gt;与&lt;code&gt;Stage 1&lt;/code&gt;转换机制很类似，不同点在于&lt;code&gt;Stage 2转换&lt;/code&gt;时判断内存类型是normal还是device时，是存放进页表信息里了，而不是通过&lt;code&gt;MAIR_ELx&lt;/code&gt;寄存器来判断；&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;每个虚拟机（VM，Virtual Machine）都会分配一个&lt;code&gt;VMID&lt;/code&gt;，用于标识&lt;code&gt;TLB entry&lt;/code&gt;所属的VM，允许在TLB中同时存在多个不同VM的转换；&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;2&quot;&gt;
&lt;p&gt;操作系统会给应用程序分配一个&lt;code&gt;ASID(Address Space Identifier)&lt;/code&gt;，也可以用于标识&lt;code&gt;TLB entry&lt;/code&gt;，属于同一个应用程序的&lt;code&gt;TLB entry&lt;/code&gt;都有相同的&lt;code&gt;ASID&lt;/code&gt;，不同的应用程序可以共享同一块&lt;code&gt;TLB缓存&lt;/code&gt;。每个VM都有自己的&lt;code&gt;ASID&lt;/code&gt;空间，通常会结合&lt;code&gt;VMID&lt;/code&gt;和&lt;code&gt;ASID&lt;/code&gt;来同时使用；&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;1&quot;&gt;
&lt;p&gt;&lt;code&gt;Stage 1&lt;/code&gt;和&lt;code&gt;Stage 2&lt;/code&gt;的转换页表中，都包含了属性的相关设备，比如访问权限，存储类型等，在两级转换的过程中，&lt;code&gt;MMU&lt;/code&gt;会整合成一个最终的也有效值，选择限制更严格的属性，如下图：&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1771657/202008/1771657-20200829232932829-1993666529.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;图中的&lt;code&gt;Device&lt;/code&gt;属性限制更严格，则选择&lt;code&gt;Device&lt;/code&gt;类型；&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Hypervisor&lt;/code&gt;如果想要改变默认整合行为，可以通过寄存器&lt;code&gt;HCR_EL2（Hypervisor Configuration Register）&lt;/code&gt;来配置，比如设置&lt;code&gt;Non-cacheable&lt;/code&gt;， &lt;code&gt;Write-Back Cacheable&lt;/code&gt;等特性；&lt;/li&gt;
&lt;/ul&gt;&lt;h3 id=&quot;222-mmiomemory-mapped-inputoutput&quot;&gt;2.2.2 &lt;code&gt;MMIO(Memory-Mapped Input/Output)&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;Guest OS&lt;/code&gt;认为的物理地址空间，实际是&lt;code&gt;IPA&lt;/code&gt;地址空间，就像真实物理机中一样，&lt;code&gt;IPA&lt;/code&gt;的地址空间，也分成内存地址空间和&lt;code&gt;I/O&lt;/code&gt;地址空间：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1771657/202008/1771657-20200829232949035-1560977763.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;访问外设有两种情况：1）直通访问真实的外设；2）触发&lt;code&gt;fault&lt;/code&gt;，&lt;code&gt;Hypervisor&lt;/code&gt;通过软件来模拟；&lt;/li&gt;
&lt;li&gt;&lt;code&gt;VTTBR_EL2&lt;/code&gt;：&lt;code&gt;Virtualization Translation Table Base Register&lt;/code&gt;，虚拟转换表基地址寄存器，存放&lt;code&gt;Stage 2转换&lt;/code&gt;的页表；&lt;/li&gt;
&lt;li&gt;为了模拟外设，&lt;code&gt;Hypervisor&lt;/code&gt;需要知道访问的是哪个外设以及访问的寄存器，读访问还是写访问，访问长度是多少，使用哪些寄存器来传送数据等。&lt;code&gt;Stage 2转换&lt;/code&gt;有一个专门的&lt;code&gt;Hypervisor IPA Fault Address Register, EL2（HPFAR_EL2）&lt;/code&gt;寄存器，用于捕获&lt;code&gt;Stage 2转换&lt;/code&gt;过程中的fault；&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;软件模拟外设的示例流程如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1771657/202008/1771657-20200829233001772-1160277084.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;1）虚拟机VM中的软件尝试访问串口设备；&lt;/li&gt;
&lt;li&gt;2）访问时&lt;code&gt;Stage 2转换&lt;/code&gt;被block住，并触发abort异常路由到&lt;code&gt;EL2&lt;/code&gt;。异常处理程序查询&lt;code&gt;ESR_EL2(Exception Syndrome Register)&lt;/code&gt;寄存器关于异常的信息，如访问长度、目标寄存器，Load/Store操作等，异常处理程序还会查询&lt;code&gt;HPFAR_EL2&lt;/code&gt;寄存器，获取abort的IPA地址；&lt;/li&gt;
&lt;li&gt;3）&lt;code&gt;Hypervisor&lt;/code&gt;通过&lt;code&gt;ESR_EL2&lt;/code&gt;和&lt;code&gt;HPFAR_EL2&lt;/code&gt;里的相关信息对相关虚拟外围设备进行模拟，完成后通过&lt;code&gt;ERET&lt;/code&gt;指令返回给&lt;code&gt;vCPU&lt;/code&gt;，从发生异常的下一条指令继续运行；&lt;/li&gt;
&lt;/ul&gt;&lt;h3 id=&quot;223-smmussystem-memory-management-units&quot;&gt;2.2.3 &lt;code&gt;SMMUs(System Memory Management Units)&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;访问内存的另外一种case就是DMA控制器。&lt;/p&gt;
&lt;p&gt;非虚拟化下DMA控制器的工作情况如下：&lt;br/&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1771657/202008/1771657-20200829233027257-538027833.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;DMA控制器由内核的驱动程序来控制，能确保操作系统层面的内存的保护不会被破坏，用户程序无法通过DMA去访问被限制的区域；&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;虚拟化下DMA控制器，VM中的驱动直接与DMA控制器交互会出现什么问题呢？如下图：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1771657/202008/1771657-20200829233042445-1554003389.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;DMA控制器不受&lt;code&gt;Stage 2转换&lt;/code&gt;的约束，会破坏VM的隔离性；&lt;/li&gt;
&lt;li&gt;Guest OS以为的物理地址是IPA地址，而DMA看到的地址是真实的物理地址，两者的视角不一致，为了解决这个问题，需要捕获每次VM与DMA控制器的交互，并提供转换，当内存出现碎片化时，这个处理低效且容易引入问题；&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;code&gt;SMMUs&lt;/code&gt;可以用于解决这个问题：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1771657/202008/1771657-20200829233058320-1717242981.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;code&gt;SMMU&lt;/code&gt;也叫&lt;code&gt;IOMMU&lt;/code&gt;，对IO部件提供MMU功能，虚拟化只是SMMU的一个应用；&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Hypervisor&lt;/code&gt;可以负责对&lt;code&gt;SMMU&lt;/code&gt;进行编程，以便让上层的控制器和虚拟机VM以同一个视角对待内存，同时也保持了隔离性；&lt;/li&gt;
&lt;/ul&gt;&lt;h2 id=&quot;23-trapping-and-emulation-of-instructions&quot;&gt;2.3 Trapping and emulation of Instructions&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;Hypervisor&lt;/code&gt;也需要具备捕获（&lt;code&gt;trap&lt;/code&gt;）和模拟指令的能力，比如当VM中的软件需要配置底层处理器来进行功耗管理或者缓存一致性操作时，为了不破坏隔离性，&lt;code&gt;Hypervisor&lt;/code&gt;就需要捕获操作并进行模拟，以便不影响其他的VM。如果设置了捕获某个操作时，当该操作被执行时会向更高一级的&lt;code&gt;Exception Level&lt;/code&gt;触发异常（比如&lt;code&gt;Hypervisor&lt;/code&gt;为EL2），从而在相应的异常处理中完成模拟。&lt;/p&gt;
&lt;p&gt;例子来了：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1771657/202008/1771657-20200829233146348-464186261.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;在ARM处理器中执行&lt;code&gt;WFI（wait for interrupt）&lt;/code&gt;命令，可以让CPU处于一个低功耗的状态；&lt;/li&gt;
&lt;li&gt;&lt;code&gt;HCR_EL2（Hypervisor Control Register）&lt;/code&gt;，当该寄存器的&lt;code&gt;TWI==1&lt;/code&gt;时，vCPU执行&lt;code&gt;WFI&lt;/code&gt;指令会触发EL2异常，从而&lt;code&gt;Hypervisor&lt;/code&gt;可以对其进行模拟，将任务调度到另外一个vCPU即可；&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;捕获（&lt;code&gt;traps&lt;/code&gt;）的另一个作用是可以用于向Guest OS呈现寄存器的虚拟值，如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1771657/202008/1771657-20200829233202178-1880863710.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;code&gt;ID_AA64MMFR0_EL1&lt;/code&gt;寄存器用于查询处理器对内存系统相关特性的支持，系统可能在启动阶段会读取该寄存器，&lt;code&gt;Hypervisor&lt;/code&gt;可以向Guest OS呈现一个不同的虚拟值；&lt;/li&gt;
&lt;li&gt;当vCPU读取该寄存器时，触发异常，&lt;code&gt;Hypervisor&lt;/code&gt;在&lt;code&gt;trap_handler&lt;/code&gt;中进行处理，设置一个虚拟值，并最终返回给vCPU；&lt;/li&gt;
&lt;li&gt;通过&lt;code&gt;trap&lt;/code&gt;来虚拟化一个操作需要大量的计算，包括触发异常、捕获，模拟、返回等一系列操作，像&lt;code&gt;ID_AA64MMFR0_EL1&lt;/code&gt;寄存器访问并不频繁，这种方式问题不大。但是当需要频繁访问的寄存器，比如&lt;code&gt;MIDR_EL1&lt;/code&gt;和&lt;code&gt;MPIDR_EL1&lt;/code&gt;等，出于性能的考虑，应该避免陷入到&lt;code&gt;Hypervisor&lt;/code&gt;中进行模拟处理，可以通过其他机制，比如提供&lt;code&gt;VPIDR_EL2&lt;/code&gt;和&lt;code&gt;VMIDR_EL2&lt;/code&gt;寄存器，在进入VM前就设置好该值，当读取&lt;code&gt;MIDR_EL1&lt;/code&gt;和&lt;code&gt;MPIDR_EL1&lt;/code&gt;时，硬件就返回&lt;code&gt;VPIDR_EL2&lt;/code&gt;和&lt;code&gt;VMIDR_EL2&lt;/code&gt;的值，避免了陷入处理；&lt;/li&gt;
&lt;/ul&gt;&lt;h2 id=&quot;24-virtualizing-exceptions&quot;&gt;2.4 Virtualizing exceptions&lt;/h2&gt;
&lt;ul&gt;&lt;li&gt;&lt;code&gt;Hypervisor&lt;/code&gt;对虚拟中断的处理比较复杂，&lt;code&gt;Hypervisor&lt;/code&gt;本身需要机制来在EL2处理中断，还需要机制来将外设的中断信号发送到目标虚拟机VM（或vCPU）上，为了使能这些机制，ARM体系架构包含了对虚拟中断的支持（vIRQs，vFIQs，vSErrors）；&lt;/li&gt;
&lt;li&gt;处理器只有在EL0/EL1执行状态下，才能收到虚拟中断，在EL2/EL3状态下不能收到虚拟中断；&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Hypervisor&lt;/code&gt;通过设置&lt;code&gt;HCR_EL2&lt;/code&gt;寄存器来控制向EL0/EL1发送虚拟中断，比如为了使能vIRQ，需要设置&lt;code&gt;HCR_EL2.IMO&lt;/code&gt;，设置后便会将物理中断发送至EL2，然后使能将虚拟中断发送至EL1；&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;有两种方式可以产生虚拟中断：1）在处理器内部控制&lt;code&gt;HCR_EL2&lt;/code&gt;寄存器；2）通过GIC中断控制器（v2版本以上）；其中方式一使用比较简单，但是它只提供了产生中断的方式，需要&lt;code&gt;Hypervisor&lt;/code&gt;来模拟VM中的中断控制器，通过捕获然后模拟的方式，会带来overhead，当然不是一个最优解。&lt;/p&gt;
&lt;p&gt;让我们来看看&lt;code&gt;GIC&lt;/code&gt;吧，看过之前中断子系统系列文章的同学，应该见过下图：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1771657/202008/1771657-20200829233259504-1725365094.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;code&gt;Hypervisor&lt;/code&gt;可以将GIC中的&lt;code&gt;Virtual CPU Interface&lt;/code&gt;映射到VM中，从而允许VM中的软件直接与GIC进行通信，&lt;code&gt;Hypervisor&lt;/code&gt;只需要进行配置即可，这样可以减少虚拟中断的overhead；&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;来个虚拟中断的例子吧：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1771657/202008/1771657-20200829233333557-1792763750.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;外设触发中断信号到GIC；&lt;/li&gt;
&lt;li&gt;GIC产生物理中断&lt;code&gt;IRQ&lt;/code&gt;或者&lt;code&gt;FIQ&lt;/code&gt;信号，如果设置了&lt;code&gt;HCR_EL2.IMO/FMO&lt;/code&gt;，中断信号将被路由到&lt;code&gt;Hypervisor&lt;/code&gt;，&lt;code&gt;Hypervisor&lt;/code&gt;会检查中断信号转发给哪个&lt;code&gt;vCPU&lt;/code&gt;；&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Hypervisor&lt;/code&gt;设置GIC，将该物理中断信号以虚拟中断的形式发送给某个&lt;code&gt;vCPU&lt;/code&gt;，如果此时处理器运行在EL2，中断信号会被忽略；&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Hypervisor&lt;/code&gt;将控制权返回给&lt;code&gt;vCPU&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;处理器运行在EL0/EL1时，虚拟中断会被接受和处理&lt;/li&gt;
&lt;/ol&gt;&lt;ul&gt;&lt;li&gt;ARMv8处理器中断屏蔽由&lt;code&gt;PSTATE&lt;/code&gt;中的比特位来控制（比如&lt;code&gt;PSTATE.I&lt;/code&gt;），虚拟化时比特位的作用有些不一样，比如设置&lt;code&gt;HCR_EL2.IMO&lt;/code&gt;时，表明物理IRQ路由到EL2，并且对EL0/EL1开启&lt;code&gt;vIRQs&lt;/code&gt;，因此，当运行在EL0/EL1时，&lt;code&gt;PSTATE.I&lt;/code&gt;比特位针对的是虚拟&lt;code&gt;vIRQs&lt;/code&gt;而不是物理的&lt;code&gt;pIRQs&lt;/code&gt;。&lt;/li&gt;
&lt;/ul&gt;&lt;h2 id=&quot;25-virtualizing-the-generic-timers&quot;&gt;2.5 Virtualizing the Generic Timers&lt;/h2&gt;
&lt;p&gt;先来看一下SoC的内部：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1771657/202008/1771657-20200829233343231-187249989.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;简化之后是这样的：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1771657/202008/1771657-20200829233351132-1430832040.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;ARM体系架构每个处理器都包含了一组通用定时器，从图中可以看到两个模块：&lt;code&gt;Comparators&lt;/code&gt;和&lt;code&gt;Counter Module&lt;/code&gt;，当&lt;code&gt;Comparators&lt;/code&gt;的值小于等于系统的count值时便会产生中断，我们都知道在操作系统中&lt;code&gt;timer&lt;/code&gt;的中断就是系统的脉搏了；&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;下图展示虚拟化系统中运行的&lt;code&gt;vCPU&lt;/code&gt;的时序：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1771657/202008/1771657-20200829233408771-223266346.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;物理时间4ms，每个&lt;code&gt;vCPU&lt;/code&gt;运行2ms，如果设置&lt;code&gt;vCPU0&lt;/code&gt;在&lt;code&gt;T=0&lt;/code&gt;之后的3ms后产生中断，那希望是物理时间的3ms后（也就是&lt;code&gt;vCPU0&lt;/code&gt;的虚拟时间2ms）产生中断，还是虚拟时间3ms后产生中断？ARM体系结构支持这两种设置；&lt;/li&gt;
&lt;li&gt;运行在&lt;code&gt;vCPU&lt;/code&gt;上的软件可以同时访问两种时钟：&lt;code&gt;EL1物理时钟&lt;/code&gt;和&lt;code&gt;EL1虚拟时钟&lt;/code&gt;；&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;code&gt;EL1物理时钟&lt;/code&gt;和&lt;code&gt;EL1虚拟时钟&lt;/code&gt;：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1771657/202008/1771657-20200829233415764-710020648.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;code&gt;EL1物理时钟&lt;/code&gt;与系统计数器模块直接比较，使用的是&lt;code&gt;wall-clock&lt;/code&gt;时间；&lt;/li&gt;
&lt;li&gt;&lt;code&gt;EL1虚拟时钟&lt;/code&gt;与虚拟计数器比较，而虚拟计数器是在物理计数器上减去一个偏移；&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Hypervisor&lt;/code&gt;负责为当前调度运行的&lt;code&gt;vCPU&lt;/code&gt;指定对应的偏移，这种方式使得虚拟时间只会覆盖&lt;code&gt;vCPU&lt;/code&gt;实际运行的那部分时间；&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;来一张示例图：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1771657/202008/1771657-20200829233422824-60522162.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;6ms的时间段里，每个&lt;code&gt;vCPU&lt;/code&gt;运行3ms，&lt;code&gt;Hypervisor&lt;/code&gt;可以使用偏移寄存器来将&lt;code&gt;vCPU&lt;/code&gt;的时间调整为其实际的运行时间；&lt;/li&gt;
&lt;/ul&gt;&lt;h2 id=&quot;26-virtualization-host-extensions（vhe）&quot;&gt;2.6 Virtualization Host Extensions（VHE）&lt;/h2&gt;
&lt;ul&gt;&lt;li&gt;先抛出一个问题：通常&lt;code&gt;Host OS&lt;/code&gt;的内核都运行在EL1，而控制虚拟化的代码运行在EL2，这就意味着传统的上下文切换，这个显然是比较低效的；&lt;/li&gt;
&lt;li&gt;&lt;code&gt;VHE&lt;/code&gt;用于支持&lt;code&gt;type-2&lt;/code&gt;的&lt;code&gt;Hypervisor&lt;/code&gt;，这种扩展可以让内核直接跑在EL2，减少host和guest之间共享的系统寄存器数量，同时也减少虚拟化的overhead；&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;code&gt;VHE&lt;/code&gt;由系统寄存器&lt;code&gt;HCR_EL2&lt;/code&gt;的&lt;code&gt;E2H&lt;/code&gt;和&lt;code&gt;TGE&lt;/code&gt;两个比特位来控制，如下图：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1771657/202008/1771657-20200829233435229-1455157188.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;VHE&lt;/code&gt;的引入，需要考虑虚拟地址空间的问题，如下图：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1771657/202008/1771657-20200829233442416-1824423239.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;我们在内存子系统分析时提到过虚拟地址空间的问题，分为用户地址空间（&lt;code&gt;EL0&lt;/code&gt;）和内核地址空间（&lt;code&gt;EL1&lt;/code&gt;），两者的区域不一致，而在&lt;code&gt;EL2&lt;/code&gt;只有一个虚拟地址空间区域，这是因为&lt;code&gt;Hypervisor&lt;/code&gt;不支持应用程序，因此也就不需要分成内核空间和用户空间了；&lt;/li&gt;
&lt;li&gt;&lt;code&gt;EL0/EL1&lt;/code&gt;虚拟地址空间也同时支持&lt;code&gt;ASID(Address Space Identifiers)&lt;/code&gt;，而&lt;code&gt;EL2&lt;/code&gt;不支持，原因也是&lt;code&gt;Hypervisor&lt;/code&gt;不需要支持应用程序；&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;从上两点可以看出，为了支持&lt;code&gt;Host OS&lt;/code&gt;能运行在&lt;code&gt;EL2&lt;/code&gt;，需要添加一个地址空间区域，以及支持&lt;code&gt;ASID&lt;/code&gt;，设置&lt;code&gt;HCR_EL2.E2H&lt;/code&gt;的寄存器位可以解决这个问题，如下图：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1771657/202008/1771657-20200829233529711-813181793.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Host OS&lt;/code&gt;运行在&lt;code&gt;EL2&lt;/code&gt;需要解决的另一个问题就是寄存器访问重定向，在内核中需要访问&lt;code&gt;EL1&lt;/code&gt;的寄存器，比如&lt;code&gt;TTBR0_EL1&lt;/code&gt;，而当内核运行在&lt;code&gt;EL2&lt;/code&gt;时，不需要修改内核代码，可以通过寄存器的设置来控制访问流，如下图：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1771657/202008/1771657-20200829233538193-425961869.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;重定向访问寄存器引入一个新的问题，&lt;code&gt;Hypervisor&lt;/code&gt;在某些情况下需要访问真正的&lt;code&gt;EL1&lt;/code&gt;寄存器，ARM架构引入了一套新的别名机制，以&lt;code&gt;_EL12/_EL02&lt;/code&gt;结尾，如下图，可以在&lt;code&gt;ECH==1&lt;/code&gt;的&lt;code&gt;EL2&lt;/code&gt;访问&lt;code&gt;TTBR0_EL1&lt;/code&gt;：&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1771657/202008/1771657-20200829233544630-856509126.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Host OS&lt;/code&gt;运行在&lt;code&gt;EL2&lt;/code&gt;还需要考虑异常处理的问题，前边提到过&lt;code&gt;HCR_EL2.IMO/FMO/AMO&lt;/code&gt;的比特位可以用来控制物理异常路由到&lt;code&gt;EL1/EL2&lt;/code&gt;。当运行在&lt;code&gt;EL0&lt;/code&gt;且&lt;code&gt;TGE==1&lt;/code&gt;时，所有物理异常都会被路由到&lt;code&gt;EL2&lt;/code&gt;（除了SCR_EL3控制的），这是因为&lt;code&gt;Host Apps&lt;/code&gt;运行在&lt;code&gt;EL0&lt;/code&gt;，而&lt;code&gt;Host OS&lt;/code&gt;运行在&lt;code&gt;EL2&lt;/code&gt;。&lt;/p&gt;
&lt;h2 id=&quot;27-总结&quot;&gt;2.7 总结&lt;/h2&gt;
&lt;ul&gt;&lt;li&gt;本文涉及到内存虚拟化（stage 2转换），I/O虚拟化（包含了SMMU，中断等），中断虚拟化，以及指令&lt;code&gt;trap and emulation&lt;/code&gt;等内容；&lt;/li&gt;
&lt;li&gt;基本的套路就是请求虚拟化服务时，路由到&lt;code&gt;EL2&lt;/code&gt;去处理，如果有硬件支持的则硬件负责处理，否则可以通过软件进行模拟；&lt;/li&gt;
&lt;li&gt;尽管本文还没涉及到代码分析，但是已经大概扫了一遍了，大体的轮廓已经了然于胸了，说了可能不信，我现在都有点小兴奋了；&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;code&gt;《ArmV8-A virtualization.pdf》&lt;/code&gt;&lt;br/&gt;&lt;code&gt;《vm-support-ARM-may6-2019.pdf》&lt;/code&gt;&lt;br/&gt;&lt;code&gt;《aarch64_virtualization_100942_0100_en.pdf》&lt;/code&gt;&lt;br/&gt;&lt;code&gt;《ARM Cortex-A Series Programmer's Guide for ARMv8-A》&lt;/code&gt;&lt;br/&gt;&lt;a href=&quot;https://lwn.net/Articles/650524/&quot;&gt;arm64: Virtualization Host Extension support&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;欢迎关注个人公众号，不定期更新技术文章。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1771657/202008/1771657-20200829233610911-651763717.jpg&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
</description>
<pubDate>Sat, 29 Aug 2020 15:42:00 +0000</pubDate>
<dc:creator>LoyenWang</dc:creator>
<og:description>背景 Read the fucking source code! --By 鲁迅 A picture is worth a thousand words. --By 高尔基 说明： KVM版本：5.9</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/LoyenWang/p/13584020.html</dc:identifier>
</item>
<item>
<title>OpenSIPS 2.4.2 高并发下，日志丢失怎么办 - 玉修</title>
<link>http://www.cnblogs.com/initialjiang/p/13567796.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/initialjiang/p/13567796.html</guid>
<description>
&lt;p&gt;问题年年有，今年特别多。最近公司对呼叫中心平台做了大幅度重构，基于OpenSIPS实现的会话管理服务，在高并发压测过程中，发现OpenSIPS的日志居然出现丢失的情况，简直让我食不知味，困惑不已。&lt;/p&gt;
&lt;p&gt;最终虽解决了问题，但内部个中原理性尚未彻底弄明白，今日先记录在此，供同道中人参考，更希望有识之士能一解玉修心中之惑……&lt;/p&gt;

&lt;p&gt;闲话不多说，来、来、来，翠花，上酸菜！！！！！！&lt;/p&gt;
&lt;div&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/773260/202008/773260-20200829230509577-330865088.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/div&gt;

&lt;p&gt;&lt;span&gt;&lt;strong&gt;1、运行环境配置&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;div&gt;
&lt;ul&gt;&lt;li&gt;
&lt;p&gt;CentOS      7.4&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Rsyslogd    8.24.0&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;OpenSIPS  2.4.2&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;/div&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;1.1 OpenSIPS日志参数配置如下：&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;div readability=&quot;6.5&quot;&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;33&quot;&gt;
&lt;pre&gt;
log_level=&lt;span&gt;3&lt;/span&gt;&lt;span&gt;
log_stderror&lt;/span&gt;=&lt;span&gt;no
log_facility&lt;/span&gt;=&lt;span&gt;LOG_LOCAL0
log_name&lt;/span&gt;=&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;/usr/local/opensips/sbin/opensips&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;
xlog_buf_size&lt;/span&gt;=&lt;span&gt;409600&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;div readability=&quot;14.754725323312&quot;&gt;
&lt;div readability=&quot;13.5&quot;&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;1.2 rsyslog.conf 自定义日志配置如下：&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;    将设施为local0的所有级别的日志，都输出到指定文件&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;32&quot;&gt;
&lt;pre&gt;
local0.* /var/log/opensips/opensips.log
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;&lt;span&gt;1.3 OpenSIPS日志输出方式：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;33&quot;&gt;
&lt;pre&gt;
xlog(&lt;span&gt;&quot;&lt;/span&gt;&lt;strong&gt;&lt;span&gt;L_INFO&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&quot;&lt;/span&gt;, &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;[$fU-&amp;gt;$rU] Route to user [$tu] [ci:$ci] [xcid:$hdr(X-CID)]&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;);
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;&lt;span&gt;2、问题现象：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;ul readability=&quot;0.5&quot;&gt;&lt;li readability=&quot;1&quot;&gt;
&lt;p&gt;在低并发测试场景，按上述方式使用L_INFO级别输出日志时，都能在 &lt;span&gt;/var/log/opensips/opensips.log 中&lt;/span&gt;正常打印日志，但是在高并发（20 CPS、1500并发）下，使用L_INFO级别输出的日志，经常会丢失。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;高并发下，opensips的日志文件，经常出现输出一次后，会等30秒才输出后续的日志。&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;高并发下 /var/log/message 文件偶尔输出提示因日志输出速率超标，而强制丢弃部分日志的信息。如下所示：&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;/div&gt;
&lt;div readability=&quot;22.456554878049&quot;&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;34&quot;&gt;
&lt;pre&gt;
Aug &lt;span&gt;19&lt;/span&gt; &lt;span&gt;21&lt;/span&gt;:&lt;span&gt;42&lt;/span&gt;:&lt;span&gt;55&lt;/span&gt; uat16599 rsyslogd: imjournal: &lt;span&gt;4188&lt;/span&gt; messages lost due to rate-&lt;span&gt;limiting
Aug &lt;/span&gt;&lt;span&gt;19&lt;/span&gt; &lt;span&gt;21&lt;/span&gt;:&lt;span&gt;52&lt;/span&gt;:&lt;span&gt;56&lt;/span&gt; uat16599 rsyslogd: imjournal: &lt;span&gt;5108&lt;/span&gt; messages lost due to rate-&lt;span&gt;limiting
Aug &lt;/span&gt;&lt;span&gt;19&lt;/span&gt; &lt;span&gt;22&lt;/span&gt;:&lt;span&gt;02&lt;/span&gt;:&lt;span&gt;57&lt;/span&gt; uat16599 rsyslogd: imjournal: &lt;span&gt;5073&lt;/span&gt; messages lost due to rate-limiting
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;span&gt;&lt;strong&gt;3、原因分析：&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;div readability=&quot;40.401835253948&quot;&gt; 
&lt;p&gt;    OpenSIPS默认情况下日志内容是直接输出到Linux rsyslogd 服务的日志文件 /etc/message 中的，但可以通过修改rsyslogd服务的规则配置，将OpenSIPS的日志输出到指定文件（比如上面提到的在rsyslog.conf 中增加 local0.*的规则）。&lt;/p&gt;
&lt;p&gt;    通过分析OpenSIPS源码我们可以得知：OpenSIPS先调用 xlog.c  的 int xlog_2(struct sip_msg* msg, char* lev, char* frm) ，然后在dprint.h文件中调用rsyslogd守护进程的 void syslog(int priority, const char *format, ...) 方法进行输出日志。&lt;span&gt;从源码上看，OpenSIPS并没有控制日志输出的速率，而且没有当日志量达到某个阈值而直接丢弃日志的功能&lt;/span&gt;&lt;span&gt;。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt; &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;   &lt;/span&gt; &lt;span&gt;因此，我有理由怀疑，日志丢失是Rsyslogd服务在作祟。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;    那还等什么，我们去探究一下Rsyslogd的到底是怎么回事……&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt; &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;    从rsyslogd从5.7.1版本开始(我的系统采用的rsyslogd是8.24.0)，新增了输出速率限制功能，默认情况下，如果一个PID在5秒内不能输出超过200条日志，否则超过200条之后的消息将被丢弃，所以会报 rate-limiting 记录。&lt;/p&gt;
&lt;p&gt;    另外，CentOS7 的Rsyslogd已经默认采用 Systemd Journal来处理本地日志文件(从/etc/rsyslog.conf文件中下面几行配置可得知)&lt;/p&gt;
&lt;div readability=&quot;12&quot;&gt;
&lt;div readability=&quot;6.5&quot;&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;33&quot;&gt;
&lt;pre&gt;
&lt;span&gt;# Turn off message reception via local log socket;
# local messages are retrieved through imjournal now.
$OmitLocalLogging on&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
    然而Systemd Journal 默认情况下，&lt;strong&gt;30秒&lt;/strong&gt;内只允许记录1000条日志文件，并且每&lt;strong&gt;10分钟&lt;/strong&gt;累计最大处理20000条日志，这显然不够用啊。所以我们可以通过修改 Systemd Journal 的配置/etc/systemd/journald.conf来解决该问题。&lt;/div&gt;
&lt;p&gt;    Systemd Journal 是采用异步存储日志的，而老的rsyslog则是采用同步模式。&lt;/p&gt;


&lt;p&gt;    OpenSIPS的xlog 默认的日志级别是 -1(ERR级别)，如果输出日志时指定的级别大于-1, 那么就有丢失的风险。从源码上看，OpenSIPS是直接调用 syslog函数打印日志，按理不会因日志级别不同，而导致日志丢失的问题。这一点在下着实没能弄明白，要是有读者查明具体原由，烦请留言告知我，玉修在此谢过了(抱拳)。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/773260/202008/773260-20200826204310426-1558973675.png&quot; alt=&quot;&quot; width=&quot;227&quot; height=&quot;288&quot; loading=&quot;lazy&quot;/&gt;&lt;/div&gt;
&lt;div readability=&quot;14.5&quot;&gt;
&lt;p&gt;&lt;strong&gt;&lt;span&gt;4、解决办法：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;首先我们解决Linux 系统层面 &lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;span&gt;4.1 解决使用“L_INFO”级别输出日志，高压下INFO级别日志容易丢失的问题&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;span&gt;&lt;strong&gt;方式一、去掉第一个参数“L_INFO”（将采用&lt;/strong&gt;默认的&lt;/span&gt; L_ERR级别），高压下打印也都正常&lt;/li&gt;
&lt;/ul&gt;&lt;div readability=&quot;6&quot;&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;32&quot;&gt;
&lt;pre&gt;
xlog(&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;[$fU-&amp;gt;$rU] Route to user [$tu] [ci:$ci] [xcid:$hdr(X-CID)]&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;);
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;ul&gt;&lt;li&gt;&lt;span&gt;&lt;strong&gt;方式二、指定OpenSIPS的默认日志级别：xlog_default_level=3或4, 这样高并发下基本正常，偶尔依旧会丢失部分日志&lt;/strong&gt;&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;div readability=&quot;7&quot;&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;34&quot;&gt;
&lt;pre&gt;
&lt;strong&gt;xlog_default_level=&lt;span&gt;3&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;
 
xlog(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;L_INFO&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;, &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;[$fU-&amp;gt;$rU] Route to user [$tu] [ci:$ci] xcid:$hdr(X-CID)]&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;);
xlog(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;[$fU-&amp;gt;$rU] Route to user [$tu] [ci:$ci] [xcid:$hdr(X-CID)]&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;);
&lt;/pre&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;4.2 解决日志输出速率达到rsyslog阈值的问题&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;div readability=&quot;12&quot;&gt;
&lt;p&gt;     通过调整rsyslog和Systemd Journal日志输出速率相关的配置。&lt;/p&gt;
&lt;p&gt;     调整后需要重启相关服务 : sudo service rsyslog restrat 、sudo systemctl restart systemd-journald&lt;/p&gt;
&lt;p&gt;     目前想到下面三种解决方案，其中后两种方法下$OmitLocalLogging=on&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div readability=&quot;7&quot;&gt;
&lt;div&gt;

&lt;ul readability=&quot;0.5&quot;&gt;&lt;li&gt;&lt;span&gt;&lt;strong&gt;方式二、关闭ystemd Journal的速率限制【野蛮暴力】&lt;/strong&gt;&lt;/span&gt;&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;调整Systemd Journal的配置文件/etc/systemd/journald.conf (CentOS6没有)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;RateLimitInterval=0&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;RateLimitBurst=0&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;

&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;同时修改/etc/rsyslog.conf文件，增加下面几行(CentOS6下没有Journal，只需增加下面的最后两项)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;$imjournalRatelimitInterval 0        (CentOS7必选)&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;$SystemLogRateLimitInterval 0   (CentOS7可选)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;$IMUXSockRateLimitInterval 0    (CentOS7可选)&lt;/li&gt;
&lt;/ul&gt;
&lt;ul readability=&quot;1&quot;&gt;&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;方式三、增大速率限制上限【温文尔雅】&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;调整Systemd Journal的配置文件/etc/systemd/journald.conf (CentOS6没有)&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;RateLimitInterval=5s      (默认值30s)&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;RateLimitBurst=20000   (默认值200)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;同时修改/etc/rsyslog.conf文件，增加下面几行(CentOS6下没有Journal，只需增加下面的前两项)&lt;/li&gt;
&lt;li&gt;$SystemLogRateLimitInterval 5       (默认值5，      CentOS7可选)&lt;/li&gt;
&lt;li&gt;$SystemLogRateLimitBurst 20000  (默认值200，   CentOS7可选)&lt;/li&gt;
&lt;li&gt;$imjournalRatelimitInterval 5           (默认值600，   CentOS7必选：不配置时，输出部分日志后，需要等10分钟才能再写入)&lt;/li&gt;
&lt;li&gt;$imjournalRatelimitBurst 20000      (默认值20000，CentOS7必选：貌似修改该值不起作用)&lt;/li&gt;
&lt;/ul&gt;&lt;/div&gt;

&lt;p&gt;&lt;span&gt;&lt;strong&gt;5、知识拓展&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;&lt;strong&gt;5.1 OpenSIPS 日志相关的参数介绍&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div&gt; 
&lt;table&gt;&lt;colgroup&gt;&lt;col/&gt;&lt;col/&gt;&lt;col/&gt;&lt;/colgroup&gt;&lt;tbody readability=&quot;7.5&quot;&gt;&lt;tr&gt;&lt;td&gt;
&lt;p&gt;&lt;strong&gt;&lt;span&gt;参数&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;p&gt;&lt;strong&gt;&lt;span&gt;说明&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;p&gt;&lt;strong&gt;&lt;span&gt;默认值&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;log_level&lt;/td&gt;
&lt;td&gt;OpenSIPS输出的日志详细程度，值越大，代表输出日志越详细&lt;/td&gt;
&lt;td&gt;[-3, 4]&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;xlog_default_level&lt;/td&gt;
&lt;td&gt;是否需要将日志输出到启动OpenSIPS的控制台&lt;/td&gt;
&lt;td&gt;-1&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;log_stderror&lt;/td&gt;
&lt;td&gt;是否需要将日志输出到启动OpenSIPS的控制台&lt;/td&gt;
&lt;td&gt;no&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;3&quot;&gt;&lt;td&gt;log_name&lt;/td&gt;
&lt;td&gt;以守护进程方式运行OpenSIPS时，输出日志的进程名称，如默认是启动OpenSIPS的命令名 /usr/local/opensips/sbin/opensips&lt;/td&gt;
&lt;td&gt;argv[0]&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;3&quot;&gt;&lt;td&gt;log_facility&lt;/td&gt;
&lt;td&gt;指定使用rsyslogd 的facility 输出日志，默认会将日志输出到 /var/log/messages 文件中&lt;/td&gt;
&lt;td&gt;LOG_DAEMON&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;3&quot;&gt;&lt;td&gt;xlog_buf_size&lt;/td&gt;
&lt;td&gt;用于缓存单行日志的空间大小，如果待输出的日志超过该阈值，OpenSIPS将丢弃，并输出一个 buffer overflow 的错误&lt;/td&gt;
&lt;td&gt;4096&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/div&gt;

&lt;div readability=&quot;8&quot;&gt;
&lt;h4&gt;&lt;span&gt;5.2 xlog函数介绍&lt;/span&gt;&lt;/h4&gt;
&lt;h4&gt;&lt;span&gt;    函数：xlog([log_level, ]format_string)&lt;/span&gt;&lt;/h4&gt;
&lt;p&gt;&lt;span&gt;    支持将format_string中的将伪变量(pseudo-variable)经过计算后打印出来。支持的日志级别参照syslog服务中的级别，具体可选值如下：&lt;/span&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;L_ALERT (-3)&lt;/li&gt;
&lt;li&gt;L_CRIT (-2)&lt;/li&gt;
&lt;li&gt;L_ERR (-1) - 如果不填写log_level，则默认选这个&lt;/li&gt;
&lt;li&gt;L_WARN (1)&lt;/li&gt;
&lt;li&gt;L_NOTICE (2)&lt;/li&gt;
&lt;li&gt;L_INFO (3)&lt;/li&gt;
&lt;li&gt;L_DBG (4)&lt;/li&gt;
&lt;/ul&gt;&lt;/div&gt;
&lt;div readability=&quot;7&quot;&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;34&quot;&gt;
&lt;pre&gt;
&lt;span&gt;样例：
  xlog(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;Received $rm from $fu (callid: $ci)\n&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;);
  xlog(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;L_ERR&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;, &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;key $var(username) not found in cache!\n&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;);
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;span&gt;&lt;strong&gt;5.3 syslog 功能测试&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div&gt;
&lt;div readability=&quot;6&quot;&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;32&quot;&gt;
&lt;pre&gt;
logger -p local1.&lt;span&gt;info&lt;/span&gt; &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;hello world&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div readability=&quot;21.5&quot;&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;55&quot;&gt;
&lt;pre&gt;
#include&amp;lt;stdio.h&amp;gt;&lt;span&gt;
#include&lt;/span&gt;&amp;lt;stdlib.h&amp;gt;&lt;span&gt;
#include &lt;/span&gt;&amp;lt;syslog.h&amp;gt;&lt;span&gt;
#include &lt;/span&gt;&amp;lt;unistd.h&amp;gt;

&lt;span&gt;void&lt;/span&gt; Info(&lt;span&gt;void&lt;/span&gt;&lt;span&gt;)
{
    &lt;/span&gt;&lt;span&gt;int&lt;/span&gt;&lt;span&gt; i;    
    &lt;/span&gt;&lt;span&gt;int&lt;/span&gt;&lt;span&gt; j;    
    openlog(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;info&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;,LOG_PID,LOG_LOCAL1);&lt;span&gt;/*&lt;/span&gt;&lt;span&gt;注意这里的数字1要跟 /etc/rsyslog.conf中的配置一致 local1.*  /home/admin/z_test_rsyslog.log &lt;/span&gt;&lt;span&gt;*/&lt;/span&gt;&lt;span&gt;
    syslog(LOG_INFO, &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;hello %s&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;,&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;info log test&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;);
    &lt;/span&gt;&lt;span&gt;for&lt;/span&gt;(j = &lt;span&gt;0&lt;/span&gt;; j &amp;lt; &lt;span&gt;100000&lt;/span&gt;; j++&lt;span&gt;) {
        &lt;/span&gt;&lt;span&gt;for&lt;/span&gt;(i = &lt;span&gt;0&lt;/span&gt;; i &amp;lt; &lt;span&gt;35&lt;/span&gt;; i++&lt;span&gt; ) {
            syslog(LOG_INFO&lt;/span&gt;|LOG_LOCAL1, &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;hello not execute openlog for specify progress name : %s, loop=%d, index=%d&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;, &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;info log test&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;, j, i);
            syslog(LOG_ERR&lt;/span&gt;|LOG_LOCAL1, &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;hello not execute openlog for specify progress name : %s, loop=%d, index=%d&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;, &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;ERROR log test&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;, j, i);
        }
        sleep(&lt;/span&gt;&lt;span&gt;1&lt;/span&gt;&lt;span&gt;);
    }
}

&lt;/span&gt;&lt;span&gt;void&lt;/span&gt; Woring(&lt;span&gt;void&lt;/span&gt;&lt;span&gt;)
{
    openlog(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;woring&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;,LOG_PID,LOG_LOCAL1);
    syslog(LOG_WARNING, &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;hello %s&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;,&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;warning log test&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;);
}

&lt;/span&gt;&lt;span&gt;int&lt;/span&gt;&lt;span&gt; main()
{
    Woring();
    Info();
    closelog();
    &lt;/span&gt;&lt;span&gt;return&lt;/span&gt; &lt;span&gt;0&lt;/span&gt;&lt;span&gt;;
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;编译运行：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;gcc -o ztest_rsyslog_bin ztest_rsyslog.c &lt;/p&gt;
&lt;p&gt;./ztest_rsyslog_bin&lt;/p&gt;
&lt;p&gt;在/home/admin/z_test_rsyslog.log 文件中就会输出下面日志了&lt;/p&gt;
&lt;/div&gt;
&lt;div readability=&quot;9.5&quot;&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;39&quot;&gt;
&lt;pre&gt;
Aug &lt;span&gt;26&lt;/span&gt; &lt;span&gt;10&lt;/span&gt;:&lt;span&gt;58&lt;/span&gt;:&lt;span&gt;37&lt;/span&gt; LPT0570 progress-name-&lt;span&gt;info&lt;/span&gt;[&lt;span&gt;30326&lt;/span&gt;]: hello &lt;span&gt;info&lt;/span&gt;&lt;span&gt; log test
Aug &lt;/span&gt;&lt;span&gt;26&lt;/span&gt; &lt;span&gt;10&lt;/span&gt;:&lt;span&gt;58&lt;/span&gt;:&lt;span&gt;37&lt;/span&gt; LPT0570 progress-name-woring[&lt;span&gt;30326&lt;/span&gt;&lt;span&gt;]: hello warning log test
Aug &lt;/span&gt;&lt;span&gt;26&lt;/span&gt; &lt;span&gt;18&lt;/span&gt;:&lt;span&gt;59&lt;/span&gt;:&lt;span&gt;36&lt;/span&gt; LPT0570 ztest_rsyslog_bin: hello not execute openlog &lt;span&gt;for&lt;/span&gt; specify progress name : &lt;span&gt;info&lt;/span&gt; log test, loop=&lt;span&gt;0&lt;/span&gt;, index=&lt;span&gt;0&lt;/span&gt;&lt;span&gt;
Aug &lt;/span&gt;&lt;span&gt;26&lt;/span&gt; &lt;span&gt;18&lt;/span&gt;:&lt;span&gt;59&lt;/span&gt;:&lt;span&gt;36&lt;/span&gt; LPT0570 ztest_rsyslog_bin: hello not execute openlog &lt;span&gt;for&lt;/span&gt; specify progress name : ERROR log test, loop=&lt;span&gt;0&lt;/span&gt;, index=&lt;span&gt;0&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;p&gt;&lt;strong&gt; 相关文档：&lt;/strong&gt;&lt;/p&gt;



&lt;/div&gt;
</description>
<pubDate>Sat, 29 Aug 2020 15:18:00 +0000</pubDate>
<dc:creator>玉修</dc:creator>
<og:description>问题年年有，今年特别多。最近公司对呼叫中心平台做了大幅度重构，基于OpenSIPS实现的会话管理服务，在高并发压测过程中，发现OpenSIPS的日志居然出现丢失的情况，简直让我食不知味，困惑不已。 最</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/initialjiang/p/13567796.html</dc:identifier>
</item>
<item>
<title>Orleans 知多少 | Orleans 中文文档上线 - 「圣杰」</title>
<link>http://www.cnblogs.com/sheng-jie/p/Chinese-Orleans-Docs-Online.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/sheng-jie/p/Chinese-Orleans-Docs-Online.html</guid>
<description>&lt;p&gt;&lt;img src=&quot;https://upload-images.jianshu.io/upload_images/2799767-a72c3e286c5ed8b7.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Orleans是一个跨平台框架，用于构建健壮，可扩展的分布式应用程序&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Orleans建立在.NET开发人员生产力的基础上，并将其带入了分布式应用程序的世界，例如云服务。 Orleans可从单个本地服务器扩展到云中全局分布的高可用性应用程序。&lt;/p&gt;
&lt;p&gt;Orleans采用了对象，接口，async/await和try/catch等熟悉的概念，并将其扩展到多服务器环境。这样，它可以帮助具有单服务器应用程序经验的开发人员过渡到构建弹性，可扩展的云服务和其他分布式应用程序。因此，Orleans通常被称为“分布式.NET”。&lt;/p&gt;
&lt;p&gt;它是由&lt;a href=&quot;http://research.microsoft.com/projects/orleans/&quot;&gt;Microsoft Research&lt;/a&gt; 创建的，并介绍了&lt;a href=&quot;http://research.microsoft.com/apps/pubs/default.aspx?id=210931&quot;&gt;Virtual Actor Model&lt;/a&gt;作为一种新方法来构建面向云时代的新一代分布式系统。 Orleans的核心贡献是它的编程模型，它在不限制功能，以及对开发人员施加繁重约束的情况下，降低了高并发分布式系统固有的复杂性。&lt;/p&gt;

&lt;p&gt;2019年10月，我在Orleans官网提了一个Issue，希望开展Orleans文档本地化的工作，一年时间过去了，是时候该给自己，给社区一个交代了，目前Orleans中文文档已部署上线，文档地址：&lt;a href=&quot;https://orleans.azurewebsites.net&quot;&gt;https://orleans.azurewebsites.net&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;目前文档仍旧在完善当中，期望更多读者能参与到校对工作中为.NET生态建设添砖加瓦。&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;Orleans中文文档，是通过机器翻译，加上人工校对而成，因为个人精力有限，校对工作目前只做了一部分，但会继续利用闲暇时间做下去，也欢迎各位读者积极参与进来。&lt;/li&gt;
&lt;li&gt;中文文档目前位于个人仓库&lt;a href=&quot;https://github.com/sheng-jie/orleans/tree/docs/zh-cn&quot;&gt;sheng-jie/orleans docs分支的zh-cn目录下&lt;/a&gt;，其中1.5下的文件夹未翻译。&lt;/li&gt;
&lt;li&gt;一些专业术语因无合适翻译予以保留，例如：Orleans，Silo，Grain，Actor 等等。&lt;/li&gt;
&lt;li&gt;计划是在维护一段时间后，文档翻译通顺后再提PR合并到Orlans官方仓库下。[doc] Multiple language support](&lt;a href=&quot;https://github.com/dotnet/orleans/issues/6075&quot;&gt;https://github.com/dotnet/orleans/issues/6075&lt;/a&gt;)。&lt;/li&gt;
&lt;/ul&gt;</description>
<pubDate>Sat, 29 Aug 2020 14:51:00 +0000</pubDate>
<dc:creator>「圣杰」</dc:creator>
<og:description>Orleans 中文文档上线</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/sheng-jie/p/Chinese-Orleans-Docs-Online.html</dc:identifier>
</item>
<item>
<title> 8.深入k8s：资源控制Qos和eviction及其源码分析 - luozhiyun</title>
<link>http://www.cnblogs.com/luozhiyun/p/13583772.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/luozhiyun/p/13583772.html</guid>
<description>&lt;blockquote readability=&quot;4.5128205128205&quot;&gt;
&lt;p&gt;转载请声明出处哦~，本篇文章发布于luozhiyun的博客：&lt;a href=&quot;https://www.luozhiyun.com&quot;&gt;https://www.luozhiyun.com&lt;/a&gt;，源码版本是&lt;a href=&quot;https://github.com/kubernetes/kubernetes/tree/release-1.19&quot;&gt;1.19&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&quot;https://img.luozhiyun.com/20200829221848.jpg&quot; alt=&quot;83980769_p0_master1200&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;又是一个周末，可以愉快的坐下来静静的品味一段源码，这一篇涉及到资源的回收，工作量是很大的，篇幅会比较长，我们可以看到k8s在资源不够时会怎么做的，k8s在回收资源的时候有哪些考虑，我们的pod为什么会无端端的被干掉等等。&lt;/p&gt;
&lt;h2 id=&quot;limitrequest&quot;&gt;limit&amp;amp;request&lt;/h2&gt;
&lt;p&gt;在k8s中，CPU和内存的资源主要是通过这limit&amp;amp;request来进行限制的，在yaml文件中的定义如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;spec.containers[].resources.limits.cpu
spec.containers[].resources.limits.memory
spec.containers[].resources.requests.cpu
spec.containers[].resources.requests.memory
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;在调度的时候，kube-scheduler 只会按照 requests 的值进行计算，而真正限制资源使用的是limit。&lt;/p&gt;
&lt;p&gt;下面我引用一个官方的例子：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-yaml&quot;&gt;apiVersion: v1
kind: Pod
metadata:
  name: cpu-demo
  namespace: cpu-example
spec:
  containers:
  - name: cpu-demo-ctr
    image: vish/stress
    resources:
      limits:
        cpu: &quot;1&quot;
      requests:
        cpu: &quot;0.5&quot;
    args:
    - -cpus
    - &quot;2&quot;
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;在这个例子中，args参数给的是cpus等于2，表示这个container可以使用2个cpu进行压测。但是我们的limits是1，以及requests是0.5。&lt;/p&gt;
&lt;p&gt;当我们创建好这个pod之后，然后使用kubectl top去查看资源使用情况的时候会发现cpu使用并不会超过1：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;NAME                        CPU(cores)   MEMORY(bytes)
cpu-demo                    974m         &amp;lt;something&amp;gt;
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;这说明这个pod的cpu资源被限制在了1个cpu，即使container想使用，也是没有办法的。&lt;/p&gt;
&lt;p&gt;在容器没有指定 request 的时候，request 的值和 limit 默认相等。&lt;/p&gt;
&lt;h2 id=&quot;qos-模型与eviction&quot;&gt;QoS 模型与Eviction&lt;/h2&gt;
&lt;p&gt;下面说一下由不同的 requests 和 limits 的设置方式引出的不同的 QoS 级别。&lt;/p&gt;
&lt;p&gt;kubernetes 中有三种 Qos，分别为：&lt;/p&gt;
&lt;ol readability=&quot;0.5&quot;&gt;&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;&lt;code&gt;Guaranteed&lt;/code&gt;：Pod中所有Container的所有Resource的&lt;code&gt;limit&lt;/code&gt;和&lt;code&gt;request&lt;/code&gt;都相等且不为0；&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;&lt;code&gt;Burstable&lt;/code&gt;：pod不满足Guaranteed条件，但是其中至少有一个container设置了requests或limits ；&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;&lt;code&gt;BestEffort&lt;/code&gt;：pod的 requests 与 limits 均没有设置；&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;当宿主机资源紧张的时候，kubelet 对 Pod 进行 Eviction（即资源回收）时会按照Qos的顺序进行回收，回收顺序是：BestEffort&amp;gt;Burstable&amp;gt;Guaranteed&lt;/p&gt;
&lt;p&gt;Eviction有两种模式，分为 Soft 和 Hard。Soft Eviction 允许你为 Eviction 过程设置grace period，然后等待一个用户配置的grace period之后，再执行Eviction，而Hard则立即执行。&lt;/p&gt;
&lt;p&gt;那么什么时候会发生Eviction呢？我们可以为Eviction 设置threshold，比如设置设定内存的 eviction hard threshold 为 100M，那么当这台机器的内存可用资源不足 100M 时，kubelet 就会根据这台机器上面所有 pod 的 QoS 级别以及他们的内存使用情况，进行一个综合排名，把排名最靠前的 pod 进行迁移，从而释放出足够的内存资源。&lt;/p&gt;
&lt;p&gt;thresholds定义方式为&lt;code&gt;[eviction-signal][operator][quantity]&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;eviction-signal&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;eviction-signal按照官方文档的说法分为如下几种：&lt;/p&gt;
&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;Eviction Signal&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;&lt;/thead&gt;&lt;tbody readability=&quot;5&quot;&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;memory.available&lt;/td&gt;
&lt;td&gt;memory.available := node.status.capacity[memory] - node.stats.memory.workingSet&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;nodefs.available&lt;/td&gt;
&lt;td&gt;nodefs.available := node.stats.fs.available&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;nodefs.inodesFree&lt;/td&gt;
&lt;td&gt;nodefs.inodesFree := node.stats.fs.inodesFree&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;imagefs.available&lt;/td&gt;
&lt;td&gt;imagefs.available := node.stats.runtime.imagefs.available&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;imagefs.inodesFree&lt;/td&gt;
&lt;td&gt;imagefs.inodesFree := node.stats.runtime.imagefs.inodesFree&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;nodefs和imagefs表示两种文件系统分区：&lt;/p&gt;
&lt;p&gt;nodefs：文件系统，kubelet 将其用于卷和守护程序日志等。&lt;/p&gt;
&lt;p&gt;imagefs：文件系统，容器运行时用于保存镜像和容器可写层。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;operator&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;就是所需的关系运算符，如&quot;&amp;lt;&quot;。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;quantity&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;是阈值的大小，可以容量大小，如：1Gi；也可以用百分比来表示：10%。&lt;/p&gt;
&lt;p&gt;如果kubelet在节点经历系统 OOM 之前无法回收内存，那么oom_killer将基于它在节点上 使用的内存百分比算出一个oom_score，然后结束得分最高的容器。&lt;/p&gt;
&lt;h2 id=&quot;qos源码分析&quot;&gt;Qos源码分析&lt;/h2&gt;
&lt;p&gt;qos的代码位于pkg\apis\core\v1\helper\qos\包下面：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;qos#GetPodQOS&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-go&quot;&gt;//pkg\apis\core\v1\helper\qos\qos.go
func GetPodQOS(pod *v1.Pod) v1.PodQOSClass {
        requests := v1.ResourceList{}
        limits := v1.ResourceList{}
        zeroQuantity := resource.MustParse(&quot;0&quot;)
        isGuaranteed := true
        allContainers := []v1.Container{}
        //追加所有的初始化容器
        allContainers = append(allContainers, pod.Spec.Containers...)
        allContainers = append(allContainers, pod.Spec.InitContainers...)
        //遍历container
        for _, container := range allContainers {
                // process requests
                //遍历request 里面的cpu、memory 获取其中的值
                for name, quantity := range container.Resources.Requests {
                        if !isSupportedQoSComputeResource(name) {
                                continue
                        }
                        if quantity.Cmp(zeroQuantity) == 1 {
                                delta := quantity.DeepCopy()
                                if _, exists := requests[name]; !exists {
                                        requests[name] = delta
                                } else {
                                        delta.Add(requests[name])
                                        requests[name] = delta
                                }
                        }
                }
                // process limits
                qosLimitsFound := sets.NewString()
                //遍历 limit 里面的cpu、memory 获取其中的值
                for name, quantity := range container.Resources.Limits {
                        if !isSupportedQoSComputeResource(name) {
                                continue
                        }
                        if quantity.Cmp(zeroQuantity) == 1 {
                                qosLimitsFound.Insert(string(name))
                                delta := quantity.DeepCopy()
                                if _, exists := limits[name]; !exists {
                                        limits[name] = delta
                                } else {
                                        delta.Add(limits[name])
                                        limits[name] = delta
                                }
                        }
                }
                //如果limits 没有同时设置cpu 、Memory，那么就不是Guaranteed
                if !qosLimitsFound.HasAll(string(v1.ResourceMemory), string(v1.ResourceCPU)) {
                        isGuaranteed = false
                }
        }
        //如果requests 和 limits都没有设置，那么为BestEffort
        if len(requests) == 0 &amp;amp;&amp;amp; len(limits) == 0 {
                return v1.PodQOSBestEffort
        }
        // Check is requests match limits for all resources.
        if isGuaranteed {
                for name, req := range requests {
                        if lim, exists := limits[name]; !exists || lim.Cmp(req) != 0 {
                                isGuaranteed = false
                                break
                        }
                }
        }
        // 都设置了limits 和 requests，则是Guaranteed
        if isGuaranteed &amp;amp;&amp;amp;
                len(requests) == len(limits) {
                return v1.PodQOSGuaranteed
        }
        return v1.PodQOSBurstable
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;上面有注释我就不过多介绍，非常的简单。&lt;/p&gt;
&lt;p&gt;下面这里是QOS OOM打分机制，通过给不同的pod打分来判断，哪些pod可以被优先kill掉，分数越高的越容易被kill。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;policy&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-go&quot;&gt;//\pkg\kubelet\qos\policy.go
// 分值越高越容易被kill
const (
        // KubeletOOMScoreAdj is the OOM score adjustment for Kubelet
        KubeletOOMScoreAdj int = -999
        // KubeProxyOOMScoreAdj is the OOM score adjustment for kube-proxy
        KubeProxyOOMScoreAdj  int = -999
        guaranteedOOMScoreAdj int = -998
        besteffortOOMScoreAdj int = 1000
)
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;policy#GetContainerOOMScoreAdjust&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-go&quot;&gt;//\pkg\kubelet\qos\policy.go
func GetContainerOOMScoreAdjust(pod *v1.Pod, container *v1.Container, memoryCapacity int64) int {
        //静态Pod、镜像Pod和高优先级Pod，直接可以是guaranteedOOMScoreAdj
        if types.IsCriticalPod(pod) {
                // Critical pods should be the last to get killed.
                return guaranteedOOMScoreAdj
        }
        //获取pod的qos等级，这里只处理Guaranteed与BestEffort
        switch v1qos.GetPodQOS(pod) {
        case v1.PodQOSGuaranteed:
                // Guaranteed containers should be the last to get killed.
                return guaranteedOOMScoreAdj
        case v1.PodQOSBestEffort:
                return besteffortOOMScoreAdj
        } 
        memoryRequest := container.Resources.Requests.Memory().Value()
        //如果我们占用的内存越少，则打分就越高
        oomScoreAdjust := 1000 - (1000*memoryRequest)/memoryCapacity
         
        //这里是为了保证burstable能有个更高的 OOM score
        if int(oomScoreAdjust) &amp;lt; (1000 + guaranteedOOMScoreAdj) {
                return (1000 + guaranteedOOMScoreAdj)
        }
         
        if int(oomScoreAdjust) == besteffortOOMScoreAdj {
                return int(oomScoreAdjust - 1)
        }
        return int(oomScoreAdjust)
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;这个方法里面给不同的pod进行打分，静态Pod、镜像Pod和高优先级Pod，QOS直接被设置成为guaranteed；&lt;/p&gt;
&lt;p&gt;然后调用qos的GetPodQOS方法获取一个pod的评分，但是如果一个pod是burstable，那么需要根据其直接使用的内存来进行评分，占用的内存越少，则打分就越高，如果分数小于1000 + guaranteedOOMScoreAdj，也就是2分，那么被直接设置成2分，避免分数过低。&lt;/p&gt;
&lt;h2 id=&quot;eviction-manager源码分析&quot;&gt;Eviction Manager源码分析&lt;/h2&gt;
&lt;p&gt;kubelet在实例化一个kubelet对象的时候，调用&lt;code&gt;eviction.NewManager&lt;/code&gt;新建了一个evictionManager对象。然后kubelet再Run方法开始工作的时候，创建一个goroutine，每5s执行一次updateRuntimeUp。&lt;/p&gt;
&lt;p&gt;在updateRuntimeUp中，待确认runtime启动成功后，会调用initializeRuntimeDependentModules完成runtime依赖模块的初始化工作。&lt;/p&gt;
&lt;p&gt;然后在initializeRuntimeDependentModules中会调用evictionManager的start方法进行启动。&lt;/p&gt;
&lt;p&gt;代码如下，具体的kubelet流程我们留到以后慢慢分析：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-go&quot;&gt;func NewMainKubelet(...){
        ...
        evictionManager, evictionAdmitHandler := eviction.NewManager(klet.resourceAnalyzer, evictionConfig, killPodNow(klet.podWorkers, kubeDeps.Recorder), klet.podManager.GetMirrorPodByPod, klet.imageManager, klet.containerGC, kubeDeps.Recorder, nodeRef, klet.clock, etcHostsPathFunc)

        klet.evictionManager = evictionManager
    ...
}

func (kl *Kubelet) Run(updates &amp;lt;-chan kubetypes.PodUpdate) {
    ...
    go wait.Until(kl.updateRuntimeUp, 5*time.Second, wait.NeverStop)
    ...
}

func (kl *Kubelet) updateRuntimeUp() {
    ...
    kl.oneTimeInitializer.Do(kl.initializeRuntimeDependentModules)
    ...
}


func (kl *Kubelet) initializeRuntimeDependentModules() {
    ...
    kl.evictionManager.Start(kl.StatsProvider, kl.GetActivePods, kl.podResourcesAreReclaimed, evictionMonitoringPeriod)
    ...
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;下面我们来到\pkg\kubelet\eviction\eviction_manager.go去看一下Start方法怎么实现eviction的。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;managerImp#Start&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-go&quot;&gt;// 开启一个控制循环去监视和响应资源过低的情况
func (m *managerImpl) Start(diskInfoProvider DiskInfoProvider, podFunc ActivePodsFunc, podCleanedUpFunc PodCleanedUpFunc, monitoringInterval time.Duration) {
        thresholdHandler := func(message string) {
                klog.Infof(message)
                m.synchronize(diskInfoProvider, podFunc)
        }
        //是否要利用kernel memcg notification
        if m.config.KernelMemcgNotification {
                for _, threshold := range m.config.Thresholds {
                        if threshold.Signal == evictionapi.SignalMemoryAvailable || threshold.Signal == evictionapi.SignalAllocatableMemoryAvailable {
                                notifier, err := NewMemoryThresholdNotifier(threshold, m.config.PodCgroupRoot, &amp;amp;CgroupNotifierFactory{}, thresholdHandler)
                                if err != nil {
                                        klog.Warningf(&quot;eviction manager: failed to create memory threshold notifier: %v&quot;, err)
                                } else {
                                        go notifier.Start()
                                        m.thresholdNotifiers = append(m.thresholdNotifiers, notifier)
                                }
                        }
                }
        }
        // start the eviction manager monitoring
        // 启动一个goroutine，for循环里每隔monitoringInterval（10s）执行一次synchronize
        go func() {
                for { 
                        //synchronize是主要的eviction控制循环，返回被kill的pod，或返回nill
                        if evictedPods := m.synchronize(diskInfoProvider, podFunc); evictedPods != nil {
                                klog.Infof(&quot;eviction manager: pods %s evicted, waiting for pod to be cleaned up&quot;, format.Pods(evictedPods))
                                m.waitForPodsCleanup(podCleanedUpFunc, evictedPods)
                        } else {
                                time.Sleep(monitoringInterval)
                        }
                }
        }()
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;下面的synchronize方法会很长，需要点耐心：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;managerImpl#synchronize&lt;/strong&gt;&lt;/p&gt;
&lt;ol readability=&quot;121.16432393864&quot;&gt;&lt;li readability=&quot;40&quot;&gt;
&lt;p&gt;根据上面介绍的不同的eviction signal会有不同的排序方法，以及设置节点资源回收方法&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-go&quot;&gt;func (m *managerImpl) synchronize(diskInfoProvider DiskInfoProvider, podFunc ActivePodsFunc) []*v1.Pod {
        ...
        if m.dedicatedImageFs == nil {
                hasImageFs, ok := diskInfoProvider.HasDedicatedImageFs()
                if ok != nil {
                        return nil
                }
                m.dedicatedImageFs = &amp;amp;hasImageFs
                //注册各个eviction signal所对应的资源排序方法
                m.signalToRankFunc = buildSignalToRankFunc(hasImageFs)
                // 注册节点资源回收方法，例如imagefs.avaliable对应的是删除无用容器和无用镜像
                m.signalToNodeReclaimFuncs = buildSignalToNodeReclaimFuncs(m.imageGC, m.containerGC, hasImageFs)
        }
        ...
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;看一下buildSignalToRankFunc方法的实现：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-go&quot;&gt;func buildSignalToRankFunc(withImageFs bool) map[evictionapi.Signal]rankFunc {
        signalToRankFunc := map[evictionapi.Signal]rankFunc{
                evictionapi.SignalMemoryAvailable:            rankMemoryPressure,
                evictionapi.SignalAllocatableMemoryAvailable: rankMemoryPressure,
                evictionapi.SignalPIDAvailable:               rankPIDPressure,
        } 
        if withImageFs { 
                signalToRankFunc[evictionapi.SignalNodeFsAvailable] = rankDiskPressureFunc([]fsStatsType{fsStatsLogs, fsStatsLocalVolumeSource}, v1.ResourceEphemeralStorage)
                signalToRankFunc[evictionapi.SignalNodeFsInodesFree] = rankDiskPressureFunc([]fsStatsType{fsStatsLogs, fsStatsLocalVolumeSource}, resourceInodes) 
                signalToRankFunc[evictionapi.SignalImageFsAvailable] = rankDiskPressureFunc([]fsStatsType{fsStatsRoot}, v1.ResourceEphemeralStorage)
                signalToRankFunc[evictionapi.SignalImageFsInodesFree] = rankDiskPressureFunc([]fsStatsType{fsStatsRoot}, resourceInodes)
        } else { 
                signalToRankFunc[evictionapi.SignalNodeFsAvailable] = rankDiskPressureFunc([]fsStatsType{fsStatsRoot, fsStatsLogs, fsStatsLocalVolumeSource}, v1.ResourceEphemeralStorage)
                signalToRankFunc[evictionapi.SignalNodeFsInodesFree] = rankDiskPressureFunc([]fsStatsType{fsStatsRoot, fsStatsLogs, fsStatsLocalVolumeSource}, resourceInodes)
                signalToRankFunc[evictionapi.SignalImageFsAvailable] = rankDiskPressureFunc([]fsStatsType{fsStatsRoot, fsStatsLogs, fsStatsLocalVolumeSource}, v1.ResourceEphemeralStorage)
                signalToRankFunc[evictionapi.SignalImageFsInodesFree] = rankDiskPressureFunc([]fsStatsType{fsStatsRoot, fsStatsLogs, fsStatsLocalVolumeSource}, resourceInodes)
        }
        return signalToRankFunc
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;这个方法里面会将各个eviction signal的排序方法放入到一个map中返回，如MemoryAvailable、NodeFsAvailable、ImageFsAvailable等。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;10&quot;&gt;
&lt;p&gt;获取所有的活跃的pod，以及整体的stat信息&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-go&quot;&gt;func (m *managerImpl) synchronize(diskInfoProvider DiskInfoProvider, podFunc ActivePodsFunc) []*v1.Pod {
        ...
        //获取当前active的pods
        activePods := podFunc()
        updateStats := true
        //获取节点的整体概况，即nodeStsts和podStats
        summary, err := m.summaryProvider.Get(updateStats)
        if err != nil {
                klog.Errorf(&quot;eviction manager: failed to get summary stats: %v&quot;, err)
                return nil
        }
        //如果Notifiers有超过10s没有刷新，那么更新Notifiers
        if m.clock.Since(m.thresholdsLastUpdated) &amp;gt; notifierRefreshInterval {
                m.thresholdsLastUpdated = m.clock.Now()
                for _, notifier := range m.thresholdNotifiers {
                        if err := notifier.UpdateThreshold(summary); err != nil {
                                klog.Warningf(&quot;eviction manager: failed to update %s: %v&quot;, notifier.Description(), err)
                        }
                }
        }
        ...
}
&lt;/code&gt;
&lt;/pre&gt;&lt;/li&gt;
&lt;li readability=&quot;22&quot;&gt;
&lt;p&gt;根据summary信息创建相应的统计信息到observations对象中&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-go&quot;&gt;func (m *managerImpl) synchronize(diskInfoProvider DiskInfoProvider, podFunc ActivePodsFunc) []*v1.Pod {
        ...
        //根据summary信息创建相应的统计信息到observations对象中，如SignalMemoryAvailable、SignalNodeFsAvailable等。
        observations, statsFunc := makeSignalObservations(summary)
        ...
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;下面抽取部分代码&lt;strong&gt;makeSignalObservations&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-go&quot;&gt;func makeSignalObservations(summary *statsapi.Summary) (signalObservations, statsFunc) { 
        ...
        if memory := summary.Node.Memory; memory != nil &amp;amp;&amp;amp; memory.AvailableBytes != nil &amp;amp;&amp;amp; memory.WorkingSetBytes != nil {
                result[evictionapi.SignalMemoryAvailable] = signalObservation{
                        available: resource.NewQuantity(int64(*memory.AvailableBytes), resource.BinarySI),
                        capacity:  resource.NewQuantity(int64(*memory.AvailableBytes+*memory.WorkingSetBytes), resource.BinarySI),
                        time:      memory.Time,
                }
        }
        ... 
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;这个方法主要是将summary里面的资源利用情况根据不同的eviction signal封装到result里面返回。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;32.654575432811&quot;&gt;
&lt;p&gt;根据获取的observations判断是否已到达阈值的thresholds&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-go&quot;&gt;func (m *managerImpl) synchronize(diskInfoProvider DiskInfoProvider, podFunc ActivePodsFunc) []*v1.Pod {
        ...
    //根据获取的observations判断是否已到达阈值的thresholds，然后返回
        thresholds = thresholdsMet(thresholds, observations, false)
        
    if len(m.thresholdsMet) &amp;gt; 0 {
                //Minimum eviction reclaim 策略
                thresholdsNotYetResolved := thresholdsMet(m.thresholdsMet, observations, true)
                thresholds = mergeThresholds(thresholds, thresholdsNotYetResolved)
        }
        ...
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;thresholdsMet&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-go&quot;&gt;func thresholdsMet(thresholds []evictionapi.Threshold, observations signalObservations, enforceMinReclaim bool) []evictionapi.Threshold {
        results := []evictionapi.Threshold{}
        for i := range thresholds {
                threshold := thresholds[i]
                observed, found := observations[threshold.Signal]
                if !found {
                        klog.Warningf(&quot;eviction manager: no observation found for eviction signal %v&quot;, threshold.Signal)
                        continue
                } 
                thresholdMet := false
        // 根据资源容量获取阈值的资源大小
                quantity := evictionapi.GetThresholdQuantity(threshold.Value, observed.capacity) 
                //Minimum eviction reclaim 策略，具体看：https://kubernetes.io/docs/tasks/administer-cluster/out-of-resource/#minimum-eviction-reclaim
                if enforceMinReclaim &amp;amp;&amp;amp; threshold.MinReclaim != nil {
                        quantity.Add(*evictionapi.GetThresholdQuantity(*threshold.MinReclaim, observed.capacity))
                }
                //如果observed.available比quantity大，那么返回1
                thresholdResult := quantity.Cmp(*observed.available)
                //检查Operator标识符
                switch threshold.Operator {
                //如果是小于号&quot;&amp;lt;&quot;,当thresholdResult大于0，返回true
                case evictionapi.OpLessThan:
                        thresholdMet = thresholdResult &amp;gt; 0
                }
                //如果append到results，表示已经到达阈值
                if thresholdMet {
                        results = append(results, threshold)
                }
        }
        return results
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;thresholdsMet会遍历整个thresholds，然后从observations里面获取eviction signal对应的资源情况。因为我们上面讲了设置的threshold可以是1Gi，也可以是百分比，所以需要调用GetThresholdQuantity方法换算一下，得到quantity；&lt;/p&gt;
&lt;p&gt;然后根据Minimum eviction reclaim 策略判断一下是否还需要提高这个需要eviction的资源，具体的信息查看文档：&lt;a href=&quot;https://kubernetes.io/docs/tasks/administer-cluster/out-of-resource/#minimum-eviction-reclaim%EF%BC%9B&quot;&gt;https://kubernetes.io/docs/tasks/administer-cluster/out-of-resource/#minimum-eviction-reclaim；&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;然后用quantity和available比较一下，如果已达阈值，那么加入到results集合中返回。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;28&quot;&gt;
&lt;p&gt;记录eviction signal 第一次的时间，并将Eviction Signals映射到对应的Node Conditions&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-go&quot;&gt;func (m *managerImpl) synchronize(diskInfoProvider DiskInfoProvider, podFunc ActivePodsFunc) []*v1.Pod {
        ...
        now := m.clock.Now()
        //主要用来记录 eviction signal 第一次的时间，没有则设置 now 时间
        thresholdsFirstObservedAt := thresholdsFirstObservedAt(thresholds, m.thresholdsFirstObservedAt, now)

        // the set of node conditions that are triggered by currently observed thresholds
        // Kubelet会将对应的Eviction Signals映射到对应的Node Conditions
        nodeConditions := nodeConditions(thresholds)
        if len(nodeConditions) &amp;gt; 0 {
                klog.V(3).Infof(&quot;eviction manager: node conditions - observed: %v&quot;, nodeConditions)
        }
        ...
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;nodeConditions&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-go&quot;&gt;func nodeConditions(thresholds []evictionapi.Threshold) []v1.NodeConditionType {
        results := []v1.NodeConditionType{}
        for _, threshold := range thresholds {
                if nodeCondition, found := signalToNodeCondition[threshold.Signal]; found {
                        //检查results里是否已有nodeCondition
                        if !hasNodeCondition(results, nodeCondition) {
                                results = append(results, nodeCondition)
                        }
                }
        }
        return results
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;nodeConditions方法主要就是根据signalToNodeCondition来映射对应的nodeCondition，其中nodeCondition如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-go&quot;&gt; signalToNodeCondition = map[evictionapi.Signal]v1.NodeConditionType{}
        signalToNodeCondition[evictionapi.SignalMemoryAvailable] = v1.NodeMemoryPressure
        signalToNodeCondition[evictionapi.SignalAllocatableMemoryAvailable] = v1.NodeMemoryPressure
        signalToNodeCondition[evictionapi.SignalImageFsAvailable] = v1.NodeDiskPressure
        signalToNodeCondition[evictionapi.SignalNodeFsAvailable] = v1.NodeDiskPressure
        signalToNodeCondition[evictionapi.SignalImageFsInodesFree] = v1.NodeDiskPressure
        signalToNodeCondition[evictionapi.SignalNodeFsInodesFree] = v1.NodeDiskPressure
        signalToNodeCondition[evictionapi.SignalPIDAvailable] = v1.NodePIDPressure
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;也就是将Eviction Signals分别映射成了MemoryPressure或DiskPressure，整理出来的表格如下：&lt;/p&gt;
&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;Node Condition&lt;/th&gt;
&lt;th&gt;Eviction Signal&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;&lt;/thead&gt;&lt;tbody readability=&quot;5&quot;&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;MemoryPressure&lt;/td&gt;
&lt;td&gt;memory.available&lt;/td&gt;
&lt;td&gt;Available memory on the node has satisfied an eviction threshold&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;8&quot;&gt;&lt;td&gt;DiskPressure&lt;/td&gt;
&lt;td&gt;nodefs.available, nodefs.inodesFree, imagefs.available, or imagefs.inodesFree&lt;/td&gt;
&lt;td&gt;Available disk space and inodes on either the node's root filesystem or image filesystem has satisfied an eviction threshold&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/li&gt;
&lt;li readability=&quot;7&quot;&gt;
&lt;p&gt;本轮 node condition 与上次的observed合并，以最新的为准&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-go&quot;&gt;func (m *managerImpl) synchronize(diskInfoProvider DiskInfoProvider, podFunc ActivePodsFunc) []*v1.Pod {
        ...
        //本轮 node condition 与上次的observed合并，以最新的为准
        nodeConditionsLastObservedAt := nodeConditionsLastObservedAt(nodeConditions, m.nodeConditionsLastObservedAt, now)
        ...
}
&lt;/code&gt;
&lt;/pre&gt;&lt;/li&gt;
&lt;li readability=&quot;21&quot;&gt;
&lt;p&gt;防止Node的资源不断在阈值附近波动，从而不断变动Node Condition值&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-go&quot;&gt;func (m *managerImpl) synchronize(diskInfoProvider DiskInfoProvider, podFunc ActivePodsFunc) []*v1.Pod {
        ...
        //PressureTransitionPeriod参数默认为5分钟
        //防止Node的资源不断在阈值附近波动，从而不断变动Node Condition值
        //具体查看文档：https://kubernetes.io/docs/tasks/administer-cluster/out-of-resource/#oscillation-of-node-conditions
        nodeConditions = nodeConditionsObservedSince(nodeConditionsLastObservedAt, m.config.PressureTransitionPeriod, now)
        if len(nodeConditions) &amp;gt; 0 {
                klog.V(3).Infof(&quot;eviction manager: node conditions - transition period not met: %v&quot;, nodeConditions)
        }
        ...
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;nodeConditionsObservedSince&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-go&quot;&gt;func nodeConditionsObservedSince(observedAt nodeConditionsObservedAt, period time.Duration, now time.Time) []v1.NodeConditionType {
        results := []v1.NodeConditionType{}
        for nodeCondition, at := range observedAt {
                duration := now.Sub(at)
                if duration &amp;lt; period {
                        results = append(results, nodeCondition)
                }
        }
        return results
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;如果已经超过了5分钟，那么需要排除。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;16&quot;&gt;
&lt;p&gt;对eviction-soft做判断&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-go&quot;&gt;func (m *managerImpl) synchronize(diskInfoProvider DiskInfoProvider, podFunc ActivePodsFunc) []*v1.Pod {
        ...
        //设置 eviction-soft-grace-period，默认为90秒，超过该值加入阈值集合
        thresholds = thresholdsMetGracePeriod(thresholdsFirstObservedAt, now)
        ...
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;thresholdsMetGracePeriod&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-go&quot;&gt;func thresholdsMetGracePeriod(observedAt thresholdsObservedAt, now time.Time) []evictionapi.Threshold {
        results := []evictionapi.Threshold{}
        for threshold, at := range observedAt {
                duration := now.Sub(at)
                //Soft Eviction Thresholds，必须要等一段时间之后才能进行trigger
                if duration &amp;lt; threshold.GracePeriod {
                        klog.V(2).Infof(&quot;eviction manager: eviction criteria not yet met for %v, duration: %v&quot;, formatThreshold(threshold), duration)
                        continue
                }
                results = append(results, threshold)
        }
        return results
}
&lt;/code&gt;
&lt;/pre&gt;&lt;/li&gt;
&lt;li readability=&quot;9&quot;&gt;
&lt;p&gt;设值，然后比较更新&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-go&quot;&gt;func (m *managerImpl) synchronize(diskInfoProvider DiskInfoProvider, podFunc ActivePodsFunc) []*v1.Pod {
        ...
        // update internal state
        m.Lock()
        m.nodeConditions = nodeConditions
        m.thresholdsFirstObservedAt = thresholdsFirstObservedAt
        m.nodeConditionsLastObservedAt = nodeConditionsLastObservedAt
        m.thresholdsMet = thresholds
 
        // 阈值集合跟上次比较是否需要更新
        thresholds = thresholdsUpdatedStats(thresholds, observations, m.lastObservations)
        debugLogThresholdsWithObservation(&quot;thresholds - updated stats&quot;, thresholds, observations)

        //将本次的信息设置为上次信息
        m.lastObservations = observations
        m.Unlock()
        ...
}
&lt;/code&gt;
&lt;/pre&gt;&lt;/li&gt;
&lt;li readability=&quot;31&quot;&gt;
&lt;p&gt;排序之后找到第一个需要释放的threshold，以及对应的resource&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-go&quot;&gt;func (m *managerImpl) synchronize(diskInfoProvider DiskInfoProvider, podFunc ActivePodsFunc) []*v1.Pod {
        ...
        //如果没有 eviction signal 集合则本轮结束流程
        if len(thresholds) == 0 {
                klog.V(3).Infof(&quot;eviction manager: no resources are starved&quot;)
                return nil
        }
 
        //排序之后获取thresholds集合中的第一个元素
        sort.Sort(byEvictionPriority(thresholds))
        thresholdToReclaim, resourceToReclaim, foundAny := getReclaimableThreshold(thresholds)
        if !foundAny {
                return nil
        }
        ...
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;getReclaimableThreshold&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-go&quot;&gt;func getReclaimableThreshold(thresholds []evictionapi.Threshold) (evictionapi.Threshold, v1.ResourceName, bool) {
        //遍历thresholds，然后根据对应的Eviction Signals找到对应的resource
        for _, thresholdToReclaim := range thresholds {
                if resourceToReclaim, ok := signalToResource[thresholdToReclaim.Signal]; ok {
                        return thresholdToReclaim, resourceToReclaim, true
                }
                klog.V(3).Infof(&quot;eviction manager: threshold %s was crossed, but reclaim is not implemented for this threshold.&quot;, thresholdToReclaim.Signal)
        }
        return evictionapi.Threshold{}, &quot;&quot;, false
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;下面我们看一下signalToResource的定义：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-go&quot;&gt; signalToResource = map[evictionapi.Signal]v1.ResourceName{}
        signalToResource[evictionapi.SignalMemoryAvailable] = v1.ResourceMemory
        signalToResource[evictionapi.SignalAllocatableMemoryAvailable] = v1.ResourceMemory
        signalToResource[evictionapi.SignalImageFsAvailable] = v1.ResourceEphemeralStorage
        signalToResource[evictionapi.SignalImageFsInodesFree] = resourceInodes
        signalToResource[evictionapi.SignalNodeFsAvailable] = v1.ResourceEphemeralStorage
        signalToResource[evictionapi.SignalNodeFsInodesFree] = resourceInodes
        signalToResource[evictionapi.SignalPIDAvailable] = resourcePids
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;signalToResource将Eviction Signals分成了memory、ephemeral-storage、inodes、pids几类。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;回收节点级别的资源&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;&lt;pre&gt;
&lt;code&gt;```go
func (m *managerImpl) synchronize(diskInfoProvider DiskInfoProvider, podFunc ActivePodsFunc) []*v1.Pod {
        ...
        //回收节点级别的资源
        if m.reclaimNodeLevelResources(thresholdToReclaim.Signal, resourceToReclaim) {
                klog.Infof(&quot;eviction manager: able to reduce %v pressure without evicting pods.&quot;, resourceToReclaim)
                return nil
        }
        ...
}
```

**reclaimNodeLevelResources**

```go
func (m *managerImpl) reclaimNodeLevelResources(signalToReclaim evictionapi.Signal, resourceToReclaim v1.ResourceName) bool {
        //调用buildSignalToNodeReclaimFuncs中设置的方法
        nodeReclaimFuncs := m.signalToNodeReclaimFuncs[signalToReclaim]
        for _, nodeReclaimFunc := range nodeReclaimFuncs { 
                // 删除没用使用到的images或 删除已经是dead状态的Pod 和 container
                if err := nodeReclaimFunc(); err != nil {
                        klog.Warningf(&quot;eviction manager: unexpected error when attempting to reduce %v pressure: %v&quot;, resourceToReclaim, err)
                }

        }
        //回收之后再检查一下资源占用情况，如果没有达到阈值，那么直接结束
        if len(nodeReclaimFuncs) &amp;gt; 0 {
                summary, err := m.summaryProvider.Get(true)
                if err != nil {
                        klog.Errorf(&quot;eviction manager: failed to get summary stats after resource reclaim: %v&quot;, err)
                        return false
                }
 
                observations, _ := makeSignalObservations(summary)
                debugLogObservations(&quot;observations after resource reclaim&quot;, observations)
 
                thresholds := thresholdsMet(m.config.Thresholds, observations, false)
                debugLogThresholdsWithObservation(&quot;thresholds after resource reclaim - ignoring grace period&quot;, thresholds, observations)

                if len(thresholds) == 0 {
                        return true
                }
        }
        return false
}
```

首先根据需要释放的signal从signalToNodeReclaimFuncs中找到对应的释放资源的方法，这个方法在上面buildSignalToNodeReclaimFuncs中设置的，如：

```
nodeReclaimFuncs{containerGC.DeleteAllUnusedContainers, imageGC.DeleteUnusedImages}
```

这个方法会调用相应的GC方法，删除无用的container以及无用的images来释放资源。

然后会检查释放完资源之后是否依然超过阈值，如果没有的话就直接结束了。
&lt;/code&gt;
&lt;/pre&gt;
&lt;ol start=&quot;12&quot; readability=&quot;11&quot;&gt;&lt;li readability=&quot;9&quot;&gt;
&lt;p&gt;获取相应的排序函数并进行排序&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-go&quot;&gt;func (m *managerImpl) synchronize(diskInfoProvider DiskInfoProvider, podFunc ActivePodsFunc) []*v1.Pod {
        ... 
        //得到上面的eviction signal 排序函数，在buildSignalToRankFunc方法中设置
        rank, ok := m.signalToRankFunc[thresholdToReclaim.Signal]
        if !ok {
                klog.Errorf(&quot;eviction manager: no ranking function for signal %s&quot;, thresholdToReclaim.Signal)
                return nil
        }

        //如果没有 active pod 直接返回
        if len(activePods) == 0 {
                klog.Errorf(&quot;eviction manager: eviction thresholds have been met, but no pods are active to evict&quot;)
                return nil
        }
 
        //将pod按照特定资源排序
        rank(activePods, statsFunc)
        ...
}
&lt;/code&gt;
&lt;/pre&gt;&lt;/li&gt;
&lt;li readability=&quot;13&quot;&gt;
&lt;p&gt;将排好序的pod删除，并返回&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-go&quot;&gt;func (m *managerImpl) synchronize(diskInfoProvider DiskInfoProvider, podFunc ActivePodsFunc) []*v1.Pod {
        ... 
        for i := range activePods {
                pod := activePods[i]
                gracePeriodOverride := int64(0)
                if !isHardEvictionThreshold(thresholdToReclaim) {
                        gracePeriodOverride = m.config.MaxPodGracePeriodSeconds
                }
                message, annotations := evictionMessage(resourceToReclaim, pod, statsFunc)
                //kill pod
                if m.evictPod(pod, gracePeriodOverride, message, annotations) {
                        metrics.Evictions.WithLabelValues(string(thresholdToReclaim.Signal)).Inc()
                        return []*v1.Pod{pod}
                }
        }
        ...
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;只要有一个pod被删除了，那么就返回~&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;到这里eviction manager就分析完了~&lt;/p&gt;
&lt;h2 id=&quot;总结&quot;&gt;总结&lt;/h2&gt;
&lt;p&gt;这一篇讲解了其中资源控制是怎么做的，理解了通过limit和request的设置会影响到pod被删除的优先级，所以我们在设置pod的时候尽量设置合理的limit和request可以不那么容易被kill掉；然后通过分析了源码知道了limit和request会影响到QOS的评分，从而影响到pod被kill掉的优先级。&lt;/p&gt;
&lt;p&gt;接下来通过源码分析了k8s中对阈值的设定是怎样的，当资源不够的时候pod是根据什么条件被kill掉的，这一部分花了很大的篇幅来介绍。通过源码也可以知道在eviction发生的时候k8s也是做了很多的考虑，比如说对于节点状态振荡应该怎么处理、首先应该回收什么类型的资源、minimum-reclaim最小回收资源在源码里是怎么做到的等等。&lt;/p&gt;
&lt;h2 id=&quot;reference&quot;&gt;Reference&lt;/h2&gt;
&lt;p&gt;&lt;a href=&quot;https://kubernetes.io/docs/tasks/configure-pod-container/assign-cpu-resource/&quot;&gt;https://kubernetes.io/docs/tasks/configure-pod-container/assign-cpu-resource/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://kubernetes.io/docs/tasks/configure-pod-container/assign-memory-resource/&quot;&gt;https://kubernetes.io/docs/tasks/configure-pod-container/assign-memory-resource/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://kubernetes.io/docs/tasks/configure-pod-container/quality-service-pod/&quot;&gt;https://kubernetes.io/docs/tasks/configure-pod-container/quality-service-pod/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://kubernetes.io/docs/tasks/administer-cluster/out-of-resource/&quot;&gt;https://kubernetes.io/docs/tasks/administer-cluster/out-of-resource/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/38359775&quot;&gt;https://zhuanlan.zhihu.com/p/38359775&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://cloud.tencent.com/developer/article/1097431&quot;&gt;https://cloud.tencent.com/developer/article/1097431&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://developer.aliyun.com/article/679216&quot;&gt;https://developer.aliyun.com/article/679216&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://my.oschina.net/jxcdwangtao/blog/841937&quot;&gt;https://my.oschina.net/jxcdwangtao/blog/841937&lt;/a&gt;&lt;/p&gt;
</description>
<pubDate>Sat, 29 Aug 2020 14:22:00 +0000</pubDate>
<dc:creator>luozhiyun</dc:creator>
<og:description>转载请声明出处哦~，本篇文章发布于luozhiyun的博客：https://www.luozhiyun.com，源码版本是1.19 又是一个周末，可以愉快的坐下来静静的品味一段源码，这一篇涉及到资源的</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/luozhiyun/p/13583772.html</dc:identifier>
</item>
<item>
<title>数据结构与算法之常用数据结构 - 平酱</title>
<link>http://www.cnblogs.com/p1ng/p/13583714.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/p1ng/p/13583714.html</guid>
<description>&lt;ul&gt;&lt;li&gt;
&lt;p&gt;数组、字符串&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;链表&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;栈&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;队列&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;双端队列&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;树&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;h2 id=&quot;数组、字符串（array--string）&quot;&gt;数组、字符串（Array &amp;amp; String）&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;字符串转化&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;数组和字符串是最基本的数据结构，在很多编程语言中都有着十分相似的性质，而围绕着它们的算法面试题也是最多的。&lt;/p&gt;
&lt;p&gt;很多时候，在分析字符串相关面试题的过程中，我们往往要针对字符串当中的每一个字符进行分析和处理，甚至有时候我们得先把给定的字符串转换成字符数组之后再进行分析和处理。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;举例&lt;/strong&gt;：反转字符串&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1898410/202008/1898410-20200829212103070-377022279.gif&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;解法&lt;/strong&gt;：用两个指针，一个指向字符串的第一个字符 a，一个指向它的最后一个字符 m，然后互相交换。交换之后，两个指针向中央一步步地靠拢并相互交换字符，直到两个指针相遇。这是一种比较快速和直观的方法。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;实现代码&lt;/strong&gt;：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;    public static String reverseString(String str) {
        if(str == null || str.length() &amp;lt; 0) {
            return null;
        }
        char[] result = str.toCharArray();
        int startIndex = 0;
        int endIndex = result.length - 1;
        char temp;
        for (; endIndex &amp;gt; startIndex; startIndex++, endIndex--) {
            temp = result[startIndex];
            result[startIndex] = result[endIndex];
            result[endIndex] = temp;
        }
        return new String(result);
    }
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;数组的优缺点&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;优点
&lt;ul&gt;&lt;li&gt;构建非常简单&lt;/li&gt;
&lt;li&gt;能在 O(1) 的时间里根据数组的下标（index）查询某个元素&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;缺点
&lt;ul&gt;&lt;li&gt;构建时必须分配一段连续的空间&lt;/li&gt;
&lt;li&gt;查询某个元素是否存在时需要遍历整个数组，耗费 O(n) 的时间（其中，n 是元素的个数）&lt;/li&gt;
&lt;li&gt;删除和添加某个元素时，同样需要耗费 O(n) 的时间&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;例题分析&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;LeetCode 第 242 题：给定两个字符串 s 和 t，编写一个函数来判断 t 是否是 s 的字母异位词。&lt;/p&gt;
&lt;p&gt;说明：你可以假设字符串只包含小写字母。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;示例 1
输入: s = &quot;anagram&quot;, t = &quot;nagaram&quot;
输出: true

示例 2
输入: s = &quot;rat&quot;, t = &quot;car&quot;
输出: false
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;字母异位词，也就是两个字符串中的相同字符的数量要对应相等。例如，s 等于 “anagram”，t 等于 “nagaram”，s 和 t 就互为字母异位词。因为它们都包含有三个字符 a，一个字符 g，一个字符 m，一个字符 n，以及一个字符 r。而当 s 为 “rat”，t 为 “car”的时候，s 和 t 不互为字母异位词。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;解题思路&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;解题思路&lt;/p&gt;
&lt;p&gt;一个重要的前提“假设两个字符串只包含小写字母”，小写字母一共也就 26 个，因此：&lt;/p&gt;
&lt;ol readability=&quot;0.5&quot;&gt;&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;可以利用两个长度都为 26 的字符数组来统计每个字符串中小写字母出现的次数，然后再对比是否相等；&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;1&quot;&gt;
&lt;p&gt;可以只利用一个长度为 26 的字符数组，将出现在字符串 s 里的字符个数加 1，而出现在字符串 t 里的字符个数减 1，最后判断每个小写字母的个数是否都为 0。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;按上述操作，可得出结论：s 和 t 互为字母异位词。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;实现代码&lt;/strong&gt;：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;       //方法2 时间复杂度：O(n) 空间复杂度：O(1)
        public boolean isAnagram(String s, String t) {
        int[] judge = new int[26];
        int lens = s.length(), lent = t.length();
        if(lens != lent) {
            return false;
        }else{
            for(int i = 0; i &amp;lt; lens; i++) {
               judge[s.charAt(i)-'a']++;
               judge[t.charAt(i)-'a']--; 
            }
            for(int i = 0; i &amp;lt; judge.length; i++) {
                if(judge[i] != 0) {
                    return false;
                }
            }
            return true;
        }
    }
&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;链表（linkedlist）&quot;&gt;链表（LinkedList）&lt;/h2&gt;
&lt;p&gt;单链表：链表中的每个元素实际上是一个单独的对象，而所有对象都通过每个元素中的引用字段链接在一起。&lt;/p&gt;
&lt;p&gt;双链表：与单链表不同的是，双链表的每个结点中都含有两个引用字段。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;链表的优缺点&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;优点
&lt;ul&gt;&lt;li&gt;链表能灵活地分配内存空间；&lt;/li&gt;
&lt;li&gt;能在 O(1) 时间内删除或者添加元素，前提是该元素的前一个元素已知，当然也取决于是单链表还是双链表，在双链表中，如果已知该元素的后一个元素，同样可以在 O(1) 时间内删除或者添加该元素。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;缺点
&lt;ul&gt;&lt;li&gt;不像数组能通过下标迅速读取元素，每次都要从链表头开始一个一个读取；&lt;/li&gt;
&lt;li&gt;查询第 k 个元素需要 O(k) 时间。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;应用场景&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;如果要解决的问题里面需要很多快速查询，链表可能并不适合；如果遇到的问题中，数据的元素个数不确定，而且需要经常进行数据的添加和删除，那么链表会比较合适。而如果数据元素大小确定，删除插入的操作并不多，那么数组可能更适合。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;经典解法&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;链表是实现很多复杂数据结构的基础，经典解法如下。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;1.利用快慢指针（有时候需要用到三个指针）&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;典型题目例如：链表的翻转，寻找倒数第 k 个元素，寻找链表中间位置的元素，判断链表是否有环等等。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2. 构建一个虚假的链表头&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;一般用在要返回新的链表的题目中，比如，给定两个排好序的链表，要求将它们整合在一起并排好序。又比如，将一个链表中的奇数和偶数按照原定的顺序分开后重新组合成一个新的链表，链表的头一半是奇数，后一半是偶数。&lt;/p&gt;
&lt;p&gt;在这类问题里，如果不用一个虚假的链表头，那么在创建新链表的第一个元素时，我们都得要判断一下链表的头指针是否为空，也就是要多写一条 if else 语句。比较简洁的写法是创建一个空的链表头，直接往其后面添加元素即可，最后返回这个空的链表头的下一个节点即可。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;建议&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;在解决链表的题目时，可以在纸上或者白板上画出节点之间的相互关系，然后画出修改的方法，既可以帮助你分析问题，又可以在面试的时候，帮助面试官清楚地看到你的思路。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;例题分析&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;LeetCode 第 25 题：给你一个链表，每 k 个节点一组进行翻转，请你返回翻转后的链表。k 是一个正整数，它的值小于或等于链表的长度。如果节点总数不是 k 的整数倍，那么请将最后剩余的节点保持原有顺序。&lt;/p&gt;
&lt;p&gt;说明：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;你的算法只能使用常数的额外空间。&lt;/li&gt;
&lt;li&gt;你不能只是单纯的改变节点内部的值，而是需要实际的进行节点交换。&lt;/li&gt;
&lt;/ul&gt;&lt;pre&gt;
&lt;code&gt;示例：
给定这个链表：1-&amp;gt;2-&amp;gt;3-&amp;gt;4-&amp;gt;5
当 k=2 时，应当返回：2-&amp;gt;1-&amp;gt;4-&amp;gt;3-&amp;gt;5
当 k=3 时，应当返回：3-&amp;gt;2-&amp;gt;1-&amp;gt;4-&amp;gt;5
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1898410/202008/1898410-20200829212137774-1482919131.gif&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;ol readability=&quot;1.5&quot;&gt;&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;将 curr 指向的下一节点保存到 next 指针；&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;curr 指向 prev，一起前进一步；&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;重复之前步骤，直到 k 个元素翻转完毕；&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;当完成了局部的翻转后，prev 就是最终的新的链表头，curr 指向了下一个要被处理的局部，而原来的头指针 head 成为了链表的尾巴。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;实现代码：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;/**
 * Definition for singly-linked list.
 * public class ListNode {
 *     int val;
 *     ListNode next;
 *     ListNode(int x) { val = x; }
 * }
 */
class Solution {
    public ListNode reverseKGroup(ListNode head, int k) {
        ListNode prev = null, curr = head, next = null;
        ListNode check = head;
        int canProceed = 0, count = 0;
        //检查链表长度是否满足翻转
        while(canProceed &amp;lt; k &amp;amp;&amp;amp; check != null) {
            check = check.next;
            canProceed++;
        }
        //满足条件进行翻转
        if(canProceed == k) {
            while(count &amp;lt; k &amp;amp;&amp;amp; curr != null) {
                next = curr.next;
                curr.next = prev;
                prev = curr;
                curr = next;
                count++;
            }
            if(next != null) {
                //head为链表翻转后的尾节点
                head.next = reverseKGroup(next, k);
            }
            //prev为链表翻转后的头节点
            return prev;
        } else {
            //不满足翻转条件直接返回head即可
            return head;
        }
    }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;栈（stack）&quot;&gt;栈（Stack）&lt;/h2&gt;
&lt;p&gt;特点：栈的最大特点就是后进先出（LIFO）。对于栈中的数据来说，所有操作都是在栈的顶部完成的，只可以查看栈顶部的元素，只能够向栈的顶部压⼊数据，也只能从栈的顶部弹出数据。&lt;/p&gt;
&lt;p&gt;实现：利用一个单链表来实现栈的数据结构。而且，因为我们都只针对栈顶元素进行操作，所以借用单链表的头就能让所有栈的操作在 O(1) 的时间内完成。&lt;/p&gt;
&lt;p&gt;应用场景：在解决某个问题的时候，只要求关心最近一次的操作，并且在操作完成了之后，需要向前查找到更前一次的操作。&lt;/p&gt;
&lt;p&gt;如果打算用一个数组外加一个指针来实现相似的效果，那么，一旦数组的长度发生了改变，哪怕只是在最后添加一个新的元素，时间复杂度都不再是 O(1)，而且，空间复杂度也得不到优化。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;例题分析一&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;LeetCode 第 20 题：给定一个只包括 '('，')'，'{'，'}'，'['，']' 的字符串，判断字符串是否有效。&lt;/p&gt;
&lt;p&gt;有效字符串需满足：&lt;/p&gt;
&lt;ol readability=&quot;-1&quot;&gt;&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;左括号必须用相同类型的右括号闭合。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;左括号必须以正确的顺序闭合。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;注意：空字符串可被认为是有效字符串。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;示例 1
输入: &quot;()&quot;
输出: true

示例 2
输入: &quot;(]&quot;
输出: false

&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;解题思路&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;将给定字符串转换成字符数组进行遍历，利用一个栈，遇到左括号时将对应的右括号压入栈中，如果遇到栈为空或者右括号不等于弹栈元素（括号不匹配的情况）直接返回false，最后返回栈是否为空即可。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;class Solution {
    public boolean isValid(String s) {
        Stack&amp;lt;Character&amp;gt; stack = new Stack&amp;lt;Character&amp;gt;();
        for(char c: s.toCharArray()) {
            if(c == '('){
                stack.push(')');
            }else if(c == '['){
                stack.push(']');
            }else if(c == '{'){
                stack.push('}');
            }else if(stack.isEmpty() || c != stack.pop()){
                return false;
            }
        }
        return stack.isEmpty();
    }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;例题分析二&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;LeetCode 第 739 题：根据每日气温列表，请重新生成一个列表，对应位置的输入是你需要再等待多久温度才会升高超过该日的天数。如果之后都不会升高，请在该位置用 0 来代替。&lt;/p&gt;
&lt;p&gt;提示：气温列表 temperatures 长度的范围是 [1, 30000]。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;示例：给定一个数组 T 代表了未来几天里每天的温度值，要求返回一个新的数组 D，D 中的每个元素表示需要经过多少天才能等来温度的升高。
给定 T：[23, 25, 21, 19, 22, 26, 23]
返回 D:  [  1,   4,   2,   1,   1,   0,   0]
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;解题思路&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;第一个温度值是 23 摄氏度，它要经过 1 天才能等到温度的升高，也就是在第二天的时候，温度升高到 24 摄氏度，所以对应的结果是 1。接下来，从 25 度到下一次温度的升高需要等待 4 天的时间，那时温度会变为 26 度。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;思路1&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;最直观的做法就是针对每个温度值向后进行依次搜索，找到比当前温度更高的值，这样的计算复杂度就是 O(n2)。&lt;/p&gt;
&lt;p&gt;但是，在这样的搜索过程中，产生了很多重复的对比。例如，从 25 度开始往后面寻找一个比 25 度更高的温度的过程中，经历了 21 度、19 度和 22 度，而这是一个温度由低到高的过程，也就是说在这个过程中已经找到了 19 度以及 21 度的答案，它就是 22 度。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;思路2&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;可以运用一个堆栈 stack 来快速地知道需要经过多少天就能等到温度升高。从头到尾扫描一遍给定的数组 T，如果当天的温度比堆栈 stack 顶端所记录的那天温度还要高，那么就能得到结果。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1898410/202008/1898410-20200829212156951-1251135184.gif&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;ol readability=&quot;7&quot;&gt;&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;对第一个温度 23 度，堆栈为空，把它的下标压入堆栈；&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;下一个温度 24 度，高于 23 度高，因此 23 度温度升高只需 1 天时间，把 23 度下标从堆栈里弹出，把 24 度下标压入；&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;同样，从 24 度只需要 1 天时间升高到 25 度；&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;21 度低于 25 度，直接把 21 度下标压入堆栈；&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;19 度低于 21 度，压入堆栈；&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;22 度高于 19 度，从 19 度升温只需 1 天，从 21 度升温需要 2 天；&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;由于堆栈里保存的是下标，能很快计算天数；&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;22 度低于 25 度，意味着尚未找到 25 度之后的升温，直接把 22 度下标压入堆栈顶端；&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;后面的温度与此同理。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;该方法只需要对数组进行一次遍历，每个元素最多被压入和弹出堆栈一次，算法复杂度是 O(n)。&lt;/p&gt;
&lt;p&gt;实现代码：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;class Solution {
    public int[] dailyTemperatures(int[] T) {
        Stack&amp;lt;Integer&amp;gt; stack = new Stack&amp;lt;Integer&amp;gt;();
        int[] res = new int[T.length];
        for(int i = 0; i &amp;lt; T.length; i++) {
            while(!stack.isEmpty() &amp;amp;&amp;amp; T[i] &amp;gt; T[stack.peek()]) {
                int temp = stack.pop();
                res[temp] = i - temp;
            }
            stack.push(i);
        }
        return res;
    }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;blockquote readability=&quot;7&quot;&gt;
&lt;p&gt;tip：官方的API文档中的建议：“Deque接口及其实现提供了更完整和一致的LIFO堆栈操作集，这些接口应优先于此类。”，且拥有一定的速度提升。所以可以将上述实现代码的栈Stack改成Deque，执行速度会有一定的提升。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;利用堆栈，还可以解决如下常见问题：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;求解算术表达式的结果（LeetCode 224、227、772、770)&lt;/li&gt;
&lt;li&gt;求解直方图里最大的矩形区域（LeetCode 84）&lt;/li&gt;
&lt;/ul&gt;&lt;h2 id=&quot;队列（queue）&quot;&gt;队列（Queue）&lt;/h2&gt;
&lt;p&gt;特点：和栈不同，队列的最大特点是先进先出（FIFO），就好像按顺序排队一样。对于队列的数据来说，我们只允许在队尾查看和添加数据，在队头查看和删除数据。&lt;/p&gt;
&lt;p&gt;实现：可以借助双链表来实现队列。双链表的头指针允许在队头查看和删除数据，而双链表的尾指针允许我们在队尾查看和添加数据。&lt;/p&gt;
&lt;p&gt;应用场景：直观来看，当我们需要按照一定的顺序来处理数据，而该数据的数据量在不断地变化的时候，则需要队列来帮助解题。在算法面试题当中，广度优先搜索（Breadth-First Search）是运用队列最多的地方。&lt;/p&gt;
&lt;h2 id=&quot;双端队列（deque）&quot;&gt;双端队列（Deque）&lt;/h2&gt;
&lt;p&gt;特点：双端队列和普通队列最大的不同在于，它允许我们在队列的头尾两端都能在 O(1) 的时间内进行数据的查看、添加和删除。&lt;/p&gt;
&lt;p&gt;实现：与队列相似，我们可以利用一个双链表实现双端队列。&lt;/p&gt;
&lt;p&gt;应用场景：双端队列最常用的地方就是实现一个长度动态变化的窗口或者连续区间，而动态窗口这种数据结构在很多题目里都有运用。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;例题分析&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;LeetCode 第 239 题：给定一个数组 nums，有一个大小为 k 的滑动窗口从数组的最左侧移动到数组的最右侧。你只可以看到在滑动窗口 k 内的数字，滑动窗口每次只向右移动一位。返回滑动窗口最大值。&lt;/p&gt;
&lt;p&gt;注意：你可以假设 k 总是有效的，1 ≤ k ≤ 输入数组的大小，且输入数组不为空。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;示例：给定一个数组以及一个窗口的长度 k，现在移动这个窗口，要求打印出一个数组，数组里的每个元素是当前窗口当中最大的那个数。
输入：nums = [1, 3, -1, -3, 5, 3, 6, 7]，k = 3
输出：[3, 3, 5, 5, 6, 7]
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;解题思路&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;思路1&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;移动窗口，扫描，获得最大值。假设数组里有 n 个元素，算法复杂度就是 O(n)。这是最直观的做法。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;思路2&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;利用一个双端队列来保存当前窗口中最大那个数在数组里的下标，双端队列新的头就是当前窗口中最大的那个数。通过该下标，可以很快地知道新的窗口是否仍包含原来那个最大的数。如果不再包含，我们就把旧的数从双端队列的头删除。&lt;/p&gt;
&lt;p&gt;因为双端队列能让上面的这两种操作都能在 O(1) 的时间里完成，所以整个算法的复杂度能控制在 O(n)。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1898410/202008/1898410-20200829212232786-1209017975.gif&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;ol readability=&quot;8.5&quot;&gt;&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;初始化窗口 k=3，包含 1，3，-1，把 1 的下标压入双端队列的尾部；&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;把 3 和双端队列的队尾的数据逐个比较，3 &amp;gt;1，把 1 的下标弹出，把 3 的下标压入队尾；&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;-1&amp;lt;3，-1 压入双端队列队尾保留到下一窗口进行比较；&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;3 为当前窗口的最大值；&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;窗口移动，-3 与队尾数据逐个比较，-3&amp;lt;-1，-3 压入双端队列队尾保留；&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;3 为当前窗口的最大值；&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;窗口继续移动，5&amp;gt;-3，-3 从双端队列队尾弹出；&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;5&amp;gt;-1，-1 从队尾弹出；&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;3 超出当前窗口，从队列头部弹出；&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;5 压入队列头部，成为当前窗口最大值；&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;继续移动窗口，操作与上述同理。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;实现代码&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;class Solution {
    public int[] maxSlidingWindow(int[] nums, int k) {
        if(nums == null || nums.length &amp;lt; 2) {
            return nums;
        }
        Deque&amp;lt;Integer&amp;gt; deque = new ArrayDeque&amp;lt;&amp;gt;();
        int[] res = new int[nums.length-k+1];
        for(int i = 0; i &amp;lt; nums.length; i++) {
            while(!deque.isEmpty() &amp;amp;&amp;amp; nums[deque.peekLast()] &amp;lt;= nums[i]) {
                deque.pollLast();
            }
            deque.addLast(i);
            if(deque.peek() &amp;lt;= i-k) {
                deque.poll();
            }
            if(i+1 &amp;gt;= k) {
                res[i+1-k] = nums[deque.peek()]; 
            }
        }
        return res;
    }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;树（tree）&quot;&gt;树（Tree）&lt;/h2&gt;
&lt;p&gt;树的结构十分直观，而树的很多概念定义都有一个相同的特点：递归，也就是说，一棵树要满足某种性质，往往要求每个节点都必须满足。例如，在定义一棵二叉搜索树时，每个节点也都必须是一棵二叉搜索树。&lt;/p&gt;
&lt;p&gt;正因为树有这样的性质，大部分关于树的面试题都与递归有关，换句话说，面试官希望通过一道关于树的问题来考察你对于递归算法掌握的熟练程度。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;树的形状&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;在面试中常考的树的形状有：普通二叉树、平衡二叉树、完全二叉树、二叉搜索树、四叉树（Quadtree）、多叉树（N-ary Tree）。&lt;/p&gt;
&lt;p&gt;对于一些特殊的树，例如红黑树（Red-Black Tree）、自平衡二叉搜索树（AVL Tree），一般在面试中不会被问到，除非你所涉及的研究领域跟它们相关或者你十分感兴趣，否则不需要特别着重准备。&lt;/p&gt;
&lt;p&gt;关于树的考题，无非就是要考查树的遍历以及序列化（serialization)。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;树的遍历&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;1. 前序遍历（Preorder Traversal&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;方法：先访问根节点，然后访问左子树，最后访问右子树。在访问左、右子树的时候，同样，先访问子树的根节点，再访问子树根节点的左子树和右子树，这是一个不断递归的过程。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1898410/202008/1898410-20200829212249285-1765845271.gif&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;应用场景：运用最多的场合包括在树里进行搜索以及创建一棵新的树。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2. 中序遍历（Inorder Traversal）&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;方法：先访问左子树，然后访问根节点，最后访问右子树，在访问左、右子树的时候，同样，先访问子树的左边，再访问子树的根节点，最后再访问子树的右边。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1898410/202008/1898410-20200829220202254-1120224651.gif&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;应用场景：最常见的是二叉搜索树，由于二叉搜索树的性质就是左孩子小于根节点，根节点小于右孩子，对二叉搜索树进行中序遍历的时候，被访问到的节点大小是按顺序进行的。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;3. 后序遍历（Postorder Traversal）&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;方法：先访问左子树，然后访问右子树，最后访问根节点。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1898410/202008/1898410-20200829220223534-82840562.gif&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;应用场景：在对某个节点进行分析的时候，需要来自左子树和右子树的信息。收集信息的操作是从树的底部不断地往上进行，好比你在修剪一棵树的叶子，修剪的方法是从外面不断地往根部将叶子一片片地修剪掉。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;注意&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;掌握好这三种遍历的递归写法和非递归写法是非常重要的，懂得分析各种写法的时间复杂度和空间复杂度同样重要。&lt;/li&gt;
&lt;li&gt;无论是前端工程师，还是后端工程师，在准备面试的时候，树这个数据结构都是最应该花时间学习的，既能证明你对递归有很好的认识，又能帮助你学习图论。树的许多性质都是面试的热门考点，尤其是二叉搜索树（BST）。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;例题分析&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;LeetCode 第 230 题：给定一个二叉搜索树，编写一个函数 kthSmallest 来查找其中第 k 个最小的元素。&lt;/p&gt;
&lt;p&gt;说明：你可以假设 k 总是有效的，1 ≤ k ≤ 二叉搜索树元素个数。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;解题思路&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;这道题考察了两个知识点：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;二叉搜索树的性质&lt;/li&gt;
&lt;li&gt;二叉搜索树的遍历&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;二叉搜索树的性质：对于每个节点来说，该节点的值比左孩子大，比右孩子小，而且一般来说，二叉搜索树里不出现重复的值。&lt;/p&gt;
&lt;p&gt;二叉搜索树的中序遍历是高频考察点，节点被遍历到的顺序是按照节点数值大小的顺序排列好的。即，中序遍历当中遇到的元素都是按照从小到大的顺序出现。&lt;/p&gt;
&lt;p&gt;因此，我们只需要对这棵树进行中序遍历的操作，当访问到第 k 个元素的时候返回结果就好。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://www.cnblogs.com/p1ng/p/CgoB5l2IRaOAag5tAHlWAofWh6A551.gif&quot; alt=&quot;img&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;实现代码：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;/**
 * Definition for a binary tree node.
 * public class TreeNode {
 *     int val;
 *     TreeNode left;
 *     TreeNode right;
 *     TreeNode() {}
 *     TreeNode(int val) { this.val = val; }
 *     TreeNode(int val, TreeNode left, TreeNode right) {
 *         this.val = val;
 *         this.left = left;
 *         this.right = right;
 *     }
 * }
 */
class Solution {
    int flag,res;
    public void inOrder(TreeNode node) {
        if(node == null || flag == 0) {
            return;
        }
        inOrder(node.left);
        if(--flag == 0) {
            res = node.val;
        }
        inOrder(node.right);
    }

    public int kthSmallest(TreeNode root, int k) {
        flag = k;
        inOrder(root);
        return res; 
    }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;注意：这道题可以变成求解第 K 大的元素，方法就是对这个二叉搜索树进行反向的中序遍历，那么数据的被访问顺序就是由大到小了。&lt;/p&gt;
&lt;p&gt;第K大元素实现代码：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;/**
 * Definition for a binary tree node.
 * public class TreeNode {
 *     int val;
 *     TreeNode left;
 *     TreeNode right;
 *     TreeNode(int x) { val = x; }
 * }
 */
class Solution {
    int flag,res;
    public void reinOrder(TreeNode node) {
        if(node == null || flag == 0) {
            return;
        }
        reinOrder(node.right);
        if(--flag == 0) {
            res = node.val;
        }
        reinOrder(node.left);
    }

    public int kthLargest(TreeNode root, int k) {
        flag = k;
        reinOrder(root);
        return res;
    }
}
&lt;/code&gt;
&lt;/pre&gt;</description>
<pubDate>Sat, 29 Aug 2020 14:03:00 +0000</pubDate>
<dc:creator>平酱</dc:creator>
<og:description>常用数据结构 数组、字符串 链表 栈 队列 双端队列 树 数组、字符串（Array &amp;amp;amp; String） 字符串转化 数组和字符串是最基本的数据结构，在很多编程语言中都有着十分相似的性质</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/p1ng/p/13583714.html</dc:identifier>
</item>
<item>
<title>04.简单了解一下Redis企业级数据备份方案 - MrMirror</title>
<link>http://www.cnblogs.com/mrmirror/p/13583225.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/mrmirror/p/13583225.html</guid>
<description>&lt;h3 id=&quot;一、企业级的持久化的配置策略&quot;&gt;一、企业级的持久化的配置策略&lt;/h3&gt;
&lt;hr/&gt;&lt;p&gt;（1）每隔1分钟去检查如果超过10000个可以变更，则生成一个快照。RDB最多丢1分钟的数据。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;save 60 10000
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;（2）AOF一定要打开，fsync，everysec&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-properties&quot;&gt;#就是当前AOF大小膨胀到超过上次100%，上次的两倍
auto-aof-rewrite-percentage 100
#最小触发size
auto-aof-rewrite-min-size 64mb
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt; &lt;br/&gt; &lt;/p&gt;
&lt;h3 id=&quot;二、企业级的数据备份方案&quot;&gt;二、企业级的数据备份方案&lt;/h3&gt;
&lt;hr/&gt;&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;RDB非常适合做冷备，每次生成之后，就不会再有修改了&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h5 id=&quot;数据备份方案&quot;&gt;数据备份方案&lt;/h5&gt;
&lt;p&gt;（1）写一个linux服务器的crontab命令定时调度脚本去做数据备份&lt;br/&gt;（2）每小时都copy一份rdb的备份，到一个目录中去，仅仅保留最近48小时的备份&lt;br/&gt;（3）每天都保留一份当日的rdb的备份，到一个目录中去，仅仅保留最近1个月的备份&lt;br/&gt;（4）每次copy备份的时候，都把太旧的备份给删了&lt;br/&gt;（5）每天晚上将当前服务器上所有的数据备份，发送一份到远程的云服务上去&lt;/p&gt;

&lt;ul&gt;&lt;li&gt;每小时copy一次备份，删除48小时前的数据&lt;/li&gt;
&lt;/ul&gt;&lt;pre&gt;
&lt;code&gt;crontab -e

0 * * * * sh /usr/local/redis/copy/redis_rdb_copy_hourly.sh

redis_rdb_copy_hourly.sh

#!/bin/sh

cur_date=`date +%Y%m%d%k`
rm -rf /usr/local/redis/snapshotting/$cur_date
mkdir /usr/local/redis/snapshotting/$cur_date
cp /var/redis/6379/dump.rdb /usr/local/redis/snapshotting/$cur_date

del_date=`date -d -48hour +%Y%m%d%k`
rm -rf /usr/local/redis/snapshotting/$del_date
&lt;/code&gt;
&lt;/pre&gt;

&lt;ul&gt;&lt;li&gt;每天copy一次备份&lt;/li&gt;
&lt;/ul&gt;&lt;pre&gt;
&lt;code&gt;crontab -e

0 0 * * * sh /usr/local/redis/copy/redis_rdb_copy_daily.sh

redis_rdb_copy_daily.sh

#!/bin/sh

cur_date=`date +%Y%m%d`
rm -rf /usr/local/redis/snapshotting/$cur_date
mkdir /usr/local/redis/snapshotting/$cur_date
cp /var/redis/6379/dump.rdb /usr/local/redis/snapshotting/$cur_date

del_date=`date -d -1month +%Y%m%d`
rm -rf /usr/local/redis/snapshotting/$del_date
&lt;/code&gt;
&lt;/pre&gt;

&lt;ul&gt;&lt;li&gt;每天一次将所有数据上传一次到远程的云服务器上去&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt; &lt;br/&gt; &lt;/p&gt;
&lt;h3 id=&quot;三、数据恢复方案&quot;&gt;三、数据恢复方案&lt;/h3&gt;
&lt;hr/&gt;&lt;p&gt;（1）如果是redis进程挂掉，那么重启redis进程即可，直接基于AOF日志文件恢复数据&lt;br/&gt;（2）如果是redis进程所在机器挂掉，那么重启机器后，尝试重启redis进程，尝试直接基于AOF日志文件进行数据恢复&lt;br/&gt;AOF append-only，顺序写入，如果AOF文件破损，那么用redis-check-aof fix&lt;br/&gt;（3）如果redis当前最新的AOF和RDB文件出现了丢失/损坏，那么可以尝试基于该机器上当前的某个最新的RDB数据副本进行数据恢复&lt;br/&gt;（4）如果当前机器上的所有RDB文件全部损坏，那么从远程的云服务上拉取最新的RDB快照回来恢复数据&lt;br/&gt;（5）如果是发现有重大的数据错误，比如某个小时上线的程序一下子将数据全部污染了，数据全错了，那么可以选择某个更早的时间点，对数据进行恢复&lt;/p&gt;
&lt;p&gt;&lt;em&gt;举个例子，12点上线了代码，发现代码有bug，导致代码生成的所有的缓存数据，写入redis，全部错了&lt;br/&gt;找到一份11点的rdb的冷备，然后按照上面的步骤，去恢复到11点的数据，不就可以了吗&lt;/em&gt;&lt;/p&gt;
&lt;p&gt; &lt;br/&gt; &lt;/p&gt;
&lt;h3 id=&quot;四、容灾演练&quot;&gt;四、容灾演练&lt;/h3&gt;
&lt;hr/&gt;&lt;p&gt;我们希望redis数据恢复到某一个时间点，所以选择那个时间点的RDB文件进行恢复，我们拷贝RDB到服务器中。把原来的aof文件删掉。&lt;br/&gt;&lt;em&gt;注意：我们此时使用的是混合持久化机制。会优先用AOF文件去恢复数据，但是我们发现redis自动生成的appendonly.aof是没有数据的，而我们拷贝的dump.rdb是有数据的。&lt;/em&gt;&lt;/p&gt;

&lt;ul&gt;&lt;li&gt;&lt;strong&gt;错误操作&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;edis启动，会自动生成一个空的AOF文件，并使用这个空的AOF恢复数据，又自动重新基于内存的数据生成了一份最新的空的rdb快照，覆盖掉了我们有数据的拷贝过去的那份dump.rdb&lt;/p&gt;

&lt;ul&gt;&lt;li&gt;&lt;strong&gt;原因分析&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;虽然你删除了appendonly.aof，但是因为打开了aof持久化，redis启动就一定会优先基于aof去恢复，即使文件不在，那就创建一个新的空的aof文件，导致redis恢复后又是空的，又生成了一个空的RDB文件，结果数据恢复失败了。&lt;/p&gt;

&lt;ul&gt;&lt;li&gt;&lt;strong&gt;调整操作&lt;/strong&gt;：&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;停止redis，应该先暂时在配置中关闭aof，然后拷贝一份rdb过来，再重启redis，数据就会使用RDB进行数据恢复，可以恢复过来，这一步是对的&lt;br/&gt;如果此时脑子一热，再关掉redis，手动修改配置文件，打开aof，再重启redis，数据又没了，空的aof文件，所有数据又没了。&lt;img src=&quot;https://img-blog.csdnimg.cn/20200826112807976.png#pic_center&quot; alt=&quot;在这里插入图片描述&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;

&lt;ul&gt;&lt;li&gt;&lt;strong&gt;最终正确操作&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;在数据安全丢失的情况下，基于rdb冷备如何完美的恢复数据，同时还保持aof和rdb的双开&lt;br/&gt;（1）停止redis，配置关闭aof，拷贝rdb备份，重启redis，确认数据恢复，直接在命令行热修改redis配置，打开aof，这个redis就会将内存中的数据对应的日志，写入aof文件中。此时aof和rdb两份数据文件的数据就同步了&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;#使用命令打开AOF
redis-cli config set appendonly yes
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;（2）redis config set热修改配置参数，可是配置文件中的实际的参数没有被持久化的修改，再次停止redis，手动修改配置文件，打开aof的命令，再次重启redis，完美！&lt;/p&gt;
&lt;p&gt; &lt;br/&gt; &lt;/p&gt;
&lt;hr/&gt;&lt;blockquote readability=&quot;7&quot;&gt;
&lt;p&gt;hi~我是Mirror，一个为了自由安逸的未来而不断前进的的程序员。&lt;br/&gt;如果你觉得文章对你有一点点帮助，一个小小赞，便是对我的认可，如果有不足之处，也欢迎各位指正。&lt;/p&gt;
&lt;/blockquote&gt;
</description>
<pubDate>Sat, 29 Aug 2020 11:34:00 +0000</pubDate>
<dc:creator>MrMirror</dc:creator>
<og:description>一、企业级的持久化的配置策略 （1）每隔1分钟去检查如果超过10000个可以变更，则生成一个快照。RDB最多丢1分钟的数据。 save 60 10000 （2）AOF一定要打开，fsync，every</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/mrmirror/p/13583225.html</dc:identifier>
</item>
<item>
<title>【原创】探索云计算容器底层之Namespace - lightinglei</title>
<link>http://www.cnblogs.com/gdut1425/p/13579460.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/gdut1425/p/13579460.html</guid>
<description>&lt;p&gt;&lt;span&gt;&lt;strong&gt;一、先谈谈进程&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;在正式介绍Namespace之前，先介绍下进程，因为容器本质上是进程，但是在介绍进程之前，先理清下“程序”和“进程”的关系，这是IT从业人员在日常工作中经常碰到的两个词汇，举个通俗点的例子帮助大家理解，“程序”可以看成是一张机械图，图上的内容都是手工画上去的，相当于是计算机的输入，在机械图未正式设计出产品的时候，它是静态的，而当工程师按照机械图正式设计各个零部件、组合、啮合到最后产品成型的整个动态过程，可看成是一个进程，因此进程可认为是程序运行起来后的计算机执行环境的总和，是静态程序的具体实现。&lt;/p&gt;

&lt;p&gt;&lt;span&gt;&lt;strong&gt;二、容器的namespace&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;在上节中介绍了什么是进程，可通过ps命名查看当前宿主机正在运行的进程，如下图所示&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;33&quot;&gt;
&lt;pre&gt;
[root@k8s-&lt;span&gt;master James]# ps
   PID TTY          TIME CMD
&lt;/span&gt;&lt;span&gt;101614&lt;/span&gt; pts/&lt;span&gt;1&lt;/span&gt;    &lt;span&gt;00&lt;/span&gt;:&lt;span&gt;00&lt;/span&gt;:&lt;span&gt;00&lt;/span&gt;&lt;span&gt; su
&lt;/span&gt;&lt;span&gt;101657&lt;/span&gt; pts/&lt;span&gt;1&lt;/span&gt;    &lt;span&gt;00&lt;/span&gt;:&lt;span&gt;00&lt;/span&gt;:&lt;span&gt;00&lt;/span&gt;&lt;span&gt; bash
&lt;/span&gt;&lt;span&gt;103878&lt;/span&gt; pts/&lt;span&gt;1&lt;/span&gt;    &lt;span&gt;00&lt;/span&gt;:&lt;span&gt;00&lt;/span&gt;:&lt;span&gt;00&lt;/span&gt; ps
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;容器本质上对于Linux操作系统来说，和上述进程一样，但是会在进程上加入了很多namespace来实现进程、挂载点、网络、用户信息之间的隔离，这样容器看上去就像一个沙箱，在沙箱内部只能看到和操作限定namespace下的系统资源，以PID namespace为例，我们先创建1个容器&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;36&quot;&gt;
&lt;p&gt;[root@k8s-master James]# docker run -it -d busybox /bin/sh&lt;br/&gt;01a0fd62d2110e54b0c3635b2897e7c18e6b78f026fa57b4214d7662dd3b38ba&lt;/p&gt;
&lt;p&gt;[root@k8s-master James]# docker exec -it 01a0fd62d2110e54b0c3635b2897e7c18e6b78f026fa57b4214d7662dd3b38ba /bin/sh&lt;br/&gt;/ # ps&lt;br/&gt;PID USER TIME COMMAND&lt;br/&gt;1 root 0:00 /bin/sh&lt;br/&gt;6 root 0:00 /bin/sh&lt;br/&gt;11 root 0:00 ps&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;这条命名的意思是我想启动一个容器执行/bin/bash命令，并分配一个伪终端的交互窗口和容器进行交互，docker run是创建和启动容器的意思，-it表示就是分配一个伪终端的输入和输出交互窗口，busybox是镜像，/bin/bash是操作程序。当创建成功后，输入ps可查看容器中正在运行的进程，可以看到有2个进程，PID代表进程的唯一编号，可以看到1号PID的操作程序为/bin/bash，之前谈到容器也是一种进程，回到宿主机查看下此容器的进程&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;33&quot;&gt;
&lt;pre&gt;
[root@k8s-&lt;span&gt;master James]# docker container top 01a0fd62d2110e54b0c3635b2897e7c18e6b78f026fa57b4214d7662dd3b38ba
UID                 PID                 PPID                C                   STIME               TTY                 TIME                CMD
root                &lt;/span&gt;&lt;span&gt;24691&lt;/span&gt;               &lt;span&gt;24668&lt;/span&gt;               &lt;span&gt;0&lt;/span&gt;                   &lt;span&gt;18&lt;/span&gt;:&lt;span&gt;34&lt;/span&gt;               pts/&lt;span&gt;0&lt;/span&gt;               &lt;span&gt;00&lt;/span&gt;:&lt;span&gt;00&lt;/span&gt;:&lt;span&gt;00&lt;/span&gt;            /bin/&lt;span&gt;sh&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;其PID为24691了，此PID在容器中不存在，也就是说容器中只能看到自己程序执行后的进程，而看不到其他容器和宿主机上的进程，且容器里面的进程编号PID也做了障眼法般的处理，与宿主机上的PID不一致，而实现这个技术的就是PID namespace，而容器类似的还有NET、IPC、MNT、UTS、USER的namespace，其对应隔离的内容如下表所示：&lt;/p&gt;
&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;namespace&lt;/th&gt;
&lt;th&gt;隔离的内容&lt;/th&gt;
&lt;/tr&gt;&lt;/thead&gt;&lt;tbody readability=&quot;2&quot;&gt;&lt;tr&gt;&lt;td&gt;PID&lt;/td&gt;
&lt;td&gt;进程&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;IPC&lt;/td&gt;
&lt;td&gt;信号量、消息队列和共享内容&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;UTS　　&lt;/td&gt;
&lt;td&gt;主机名、域名&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;NET&lt;/td&gt;
&lt;td&gt;网络设备、网络栈、端口&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;MNT&lt;/td&gt;
&lt;td&gt;文件系统&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;User&lt;/td&gt;
&lt;td&gt;用户和用户组&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;








&lt;p&gt;网络相对比较复杂，我们再详细深入看下，从上表可以看出不同的网络命名空间可以隔离网络设备、网络栈、端口等，为了达到这个目标，LINUX系统就需要支持虚拟化网络协议栈的多个实例，且这些独立的协议栈可处于不同的网络命名空间来进行隔离，达到彼此无法进行通信隔离的效果，如果想要不同的网络命名空间设备进行通信，应如何操作呢？答案是：&lt;strong&gt;veth设备对&lt;/strong&gt;，什么是veth设备对，你可以认为是一根管道，一端连接一个网络命名空间的协议栈，另外一端连接另外一个网络命名空间的协议栈来实现通信，那如何建立veth设备对呢？接下来一起操作下&lt;/p&gt;
&lt;p&gt;在root用户下，先创建一个网络命名空间&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;33&quot;&gt;
&lt;pre&gt;
[root@k8s-&lt;span&gt;master zhanglei]# ip netns add net_test1
[root@k8s&lt;/span&gt;-&lt;span&gt;master zhanglei]# ip netns list
net_test1&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;再创建一个设备对veth：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;36&quot;&gt;
&lt;pre&gt;
[root@k8s-&lt;span&gt;master zhanglei]# ip link add veth0 type veth peer name veth1
[root@k8s&lt;/span&gt;-&lt;span&gt;master zhanglei]# ip link show
&lt;/span&gt;&lt;span&gt;60&lt;/span&gt;: veth0@veth1: &amp;lt;BROADCAST,MULTICAST,M-DOWN&amp;gt; mtu &lt;span&gt;1500&lt;/span&gt; qdisc noop state DOWN mode DEFAULT group default qlen &lt;span&gt;1000&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;可以看到veth0和veth1的设备对已经生成，veth的设备支持在不同的网络命名空间进行转移，将veth0设备住转移到net_test1命名空间&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;32&quot;&gt;
&lt;pre&gt;
[root@k8s-master zhanglei]# ip link set veth0 netns net_test1
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;此时在宿主机上ip link show，因不同的网络命名空间设备是隔离的，且veth0设备已经被移动到net_test1网络命名空间，因此将无法在宿主机网络命名空间再次找到veth0&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;36&quot;&gt;
&lt;pre&gt;
[root@k8s-&lt;span&gt;master zhanglei]# ip netns exec net_test1 ip link show
&lt;/span&gt;&lt;span&gt;1&lt;/span&gt;: lo: &amp;lt;LOOPBACK&amp;gt; mtu &lt;span&gt;65536&lt;/span&gt; qdisc noop state DOWN mode DEFAULT group default qlen &lt;span&gt;1000&lt;/span&gt;&lt;span&gt;
    link&lt;/span&gt;/loopback &lt;span&gt;00&lt;/span&gt;:&lt;span&gt;00&lt;/span&gt;:&lt;span&gt;00&lt;/span&gt;:&lt;span&gt;00&lt;/span&gt;:&lt;span&gt;00&lt;/span&gt;:&lt;span&gt;00&lt;/span&gt; brd &lt;span&gt;00&lt;/span&gt;:&lt;span&gt;00&lt;/span&gt;:&lt;span&gt;00&lt;/span&gt;:&lt;span&gt;00&lt;/span&gt;:&lt;span&gt;00&lt;/span&gt;:&lt;span&gt;00&lt;/span&gt;
&lt;span&gt;2&lt;/span&gt;: tunl0@NONE: &amp;lt;NOARP&amp;gt; mtu &lt;span&gt;1480&lt;/span&gt; qdisc noop state DOWN mode DEFAULT group default qlen &lt;span&gt;1000&lt;/span&gt;&lt;span&gt;
    link&lt;/span&gt;/ipip &lt;span&gt;0.0&lt;/span&gt;.&lt;span&gt;0.0&lt;/span&gt; brd &lt;span&gt;0.0&lt;/span&gt;.&lt;span&gt;0.0&lt;/span&gt;
&lt;span&gt;60&lt;/span&gt;: veth0@if59: &amp;lt;BROADCAST,MULTICAST&amp;gt; mtu &lt;span&gt;1500&lt;/span&gt; qdisc noop state DOWN mode DEFAULT group default qlen &lt;span&gt;1000&lt;/span&gt;&lt;span&gt;
    link&lt;/span&gt;/ether &lt;span&gt;26&lt;/span&gt;:c0:&lt;span&gt;29&lt;/span&gt;:4d:&lt;span&gt;77&lt;/span&gt;:&lt;span&gt;28&lt;/span&gt; brd ff:ff:ff:ff:ff:ff link-netnsid &lt;span&gt;0&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;同时我们将另veth1设置到命名空间net_test2里面&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;33&quot;&gt;
&lt;pre&gt;
[root@k8s-&lt;span&gt;master zhanglei]# ip netns add net_test2
[root@k8s&lt;/span&gt;-&lt;span&gt;master zhanglei]# ip netns show
net_test2
net_test1 (&lt;/span&gt;&lt;span&gt;id&lt;/span&gt;: &lt;span&gt;24&lt;/span&gt;)
&lt;/pre&gt;&lt;/div&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;36&quot;&gt;
&lt;pre&gt;
[root@k8s-&lt;span&gt;master zhanglei]#  ip link set veth1 netns net_test2
[root@k8s&lt;/span&gt;-&lt;span&gt;master zhanglei]# ip netns exec net_test2 ip link show
&lt;/span&gt;&lt;span&gt;1&lt;/span&gt;: lo: &amp;lt;LOOPBACK&amp;gt; mtu &lt;span&gt;65536&lt;/span&gt; qdisc noop state DOWN mode DEFAULT group default qlen &lt;span&gt;1000&lt;/span&gt;&lt;span&gt;
    link&lt;/span&gt;/loopback &lt;span&gt;00&lt;/span&gt;:&lt;span&gt;00&lt;/span&gt;:&lt;span&gt;00&lt;/span&gt;:&lt;span&gt;00&lt;/span&gt;:&lt;span&gt;00&lt;/span&gt;:&lt;span&gt;00&lt;/span&gt; brd &lt;span&gt;00&lt;/span&gt;:&lt;span&gt;00&lt;/span&gt;:&lt;span&gt;00&lt;/span&gt;:&lt;span&gt;00&lt;/span&gt;:&lt;span&gt;00&lt;/span&gt;:&lt;span&gt;00&lt;/span&gt;
&lt;span&gt;2&lt;/span&gt;: tunl0@NONE: &amp;lt;NOARP&amp;gt; mtu &lt;span&gt;1480&lt;/span&gt; qdisc noop state DOWN mode DEFAULT group default qlen &lt;span&gt;1000&lt;/span&gt;&lt;span&gt;
    link&lt;/span&gt;/ipip &lt;span&gt;0.0&lt;/span&gt;.&lt;span&gt;0.0&lt;/span&gt; brd &lt;span&gt;0.0&lt;/span&gt;.&lt;span&gt;0.0&lt;/span&gt;
&lt;span&gt;59&lt;/span&gt;: veth1@if60: &amp;lt;BROADCAST,MULTICAST&amp;gt; mtu &lt;span&gt;1500&lt;/span&gt; qdisc noop state DOWN mode DEFAULT group default qlen &lt;span&gt;1000&lt;/span&gt;&lt;span&gt;
    link&lt;/span&gt;/ether 7e:&lt;span&gt;06&lt;/span&gt;:da:3a:&lt;span&gt;09&lt;/span&gt;:&lt;span&gt;44&lt;/span&gt; brd ff:ff:ff:ff:ff:ff link-netns net_test1
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;到这里，veth0和veth1这个设备对已经配置在不同的网络命名空间了，但是此时还不能通信，就像电线已经搭好，但是还未通电，谁来扮演通电的角色呢？答案就是：&lt;strong&gt;IP&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;40&quot;&gt;
&lt;pre&gt;
[root@k8s-master zhanglei]# ip netns exec net_test1 ip addr add &lt;span&gt;10.1&lt;/span&gt;.&lt;span&gt;1.1&lt;/span&gt;/&lt;span&gt;24&lt;/span&gt;&lt;span&gt; dev veth0
[root@k8s&lt;/span&gt;-master zhanglei]# ip netns exec net_test2 ip addr add &lt;span&gt;10.1&lt;/span&gt;.&lt;span&gt;1.2&lt;/span&gt;/&lt;span&gt;24&lt;/span&gt;&lt;span&gt; dev veth1
[root@k8s&lt;/span&gt;-&lt;span&gt;master zhanglei]# ip netns exec net_test1 ip link set dev veth0 up
[root@k8s&lt;/span&gt;-&lt;span&gt;master zhanglei]# ip netns exec net_test2 ip link set dev veth1 up
[root@k8s&lt;/span&gt;-master zhanglei]# ip netns exec net_test1 &lt;span&gt;ping&lt;/span&gt; &lt;span&gt;10.1&lt;/span&gt;.&lt;span&gt;1.2&lt;/span&gt;&lt;span&gt;
PING &lt;/span&gt;&lt;span&gt;10.1&lt;/span&gt;.&lt;span&gt;1.2&lt;/span&gt; (&lt;span&gt;10.1&lt;/span&gt;.&lt;span&gt;1.2&lt;/span&gt;) &lt;span&gt;56&lt;/span&gt;(&lt;span&gt;84&lt;/span&gt;&lt;span&gt;) bytes of data.
&lt;/span&gt;&lt;span&gt;64&lt;/span&gt; bytes from &lt;span&gt;10.1&lt;/span&gt;.&lt;span&gt;1.2&lt;/span&gt;: icmp_seq=&lt;span&gt;1&lt;/span&gt; ttl=&lt;span&gt;64&lt;/span&gt; &lt;span&gt;time&lt;/span&gt;=&lt;span&gt;0.097&lt;/span&gt;&lt;span&gt; ms
&lt;/span&gt;&lt;span&gt;64&lt;/span&gt; bytes from &lt;span&gt;10.1&lt;/span&gt;.&lt;span&gt;1.2&lt;/span&gt;: icmp_seq=&lt;span&gt;2&lt;/span&gt; ttl=&lt;span&gt;64&lt;/span&gt; &lt;span&gt;time&lt;/span&gt;=&lt;span&gt;0.061&lt;/span&gt;&lt;span&gt; ms
&lt;/span&gt;&lt;span&gt;64&lt;/span&gt; bytes from &lt;span&gt;10.1&lt;/span&gt;.&lt;span&gt;1.2&lt;/span&gt;: icmp_seq=&lt;span&gt;3&lt;/span&gt; ttl=&lt;span&gt;64&lt;/span&gt; &lt;span&gt;time&lt;/span&gt;=&lt;span&gt;0.032&lt;/span&gt;&lt;span&gt; ms
&lt;/span&gt;&lt;span&gt;64&lt;/span&gt; bytes from &lt;span&gt;10.1&lt;/span&gt;.&lt;span&gt;1.2&lt;/span&gt;: icmp_seq=&lt;span&gt;4&lt;/span&gt; ttl=&lt;span&gt;64&lt;/span&gt; &lt;span&gt;time&lt;/span&gt;=&lt;span&gt;0.024&lt;/span&gt; ms
&lt;/pre&gt;
&lt;p&gt;[root@k8s-master zhanglei]# ip netns exec net_test2 ping 10.1.1.1&lt;br/&gt;PING 10.1.1.1 (10.1.1.1) 56(84) bytes of data.&lt;br/&gt;64 bytes from 10.1.1.1: icmp_seq=1 ttl=64 time=0.030 ms&lt;br/&gt;64 bytes from 10.1.1.1: icmp_seq=2 ttl=64 time=0.090 ms&lt;br/&gt;64 bytes from 10.1.1.1: icmp_seq=3 ttl=64 time=0.032 ms&lt;br/&gt;64 bytes from 10.1.1.1: icmp_seq=4 ttl=64 time=0.033 ms&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;35&quot;&gt;
&lt;pre&gt;
[root@k8s-master zhanglei]# ip netns exec net_test2 &lt;span&gt;ping&lt;/span&gt; &lt;span&gt;10.1&lt;/span&gt;.&lt;span&gt;1.1&lt;/span&gt;&lt;span&gt;
PING &lt;/span&gt;&lt;span&gt;10.1&lt;/span&gt;.&lt;span&gt;1.1&lt;/span&gt; (&lt;span&gt;10.1&lt;/span&gt;.&lt;span&gt;1.1&lt;/span&gt;) &lt;span&gt;56&lt;/span&gt;(&lt;span&gt;84&lt;/span&gt;&lt;span&gt;) bytes of data.
&lt;/span&gt;&lt;span&gt;64&lt;/span&gt; bytes from &lt;span&gt;10.1&lt;/span&gt;.&lt;span&gt;1.1&lt;/span&gt;: icmp_seq=&lt;span&gt;1&lt;/span&gt; ttl=&lt;span&gt;64&lt;/span&gt; &lt;span&gt;time&lt;/span&gt;=&lt;span&gt;0.030&lt;/span&gt;&lt;span&gt; ms
&lt;/span&gt;&lt;span&gt;64&lt;/span&gt; bytes from &lt;span&gt;10.1&lt;/span&gt;.&lt;span&gt;1.1&lt;/span&gt;: icmp_seq=&lt;span&gt;2&lt;/span&gt; ttl=&lt;span&gt;64&lt;/span&gt; &lt;span&gt;time&lt;/span&gt;=&lt;span&gt;0.090&lt;/span&gt;&lt;span&gt; ms
&lt;/span&gt;&lt;span&gt;64&lt;/span&gt; bytes from &lt;span&gt;10.1&lt;/span&gt;.&lt;span&gt;1.1&lt;/span&gt;: icmp_seq=&lt;span&gt;3&lt;/span&gt; ttl=&lt;span&gt;64&lt;/span&gt; &lt;span&gt;time&lt;/span&gt;=&lt;span&gt;0.032&lt;/span&gt;&lt;span&gt; ms
&lt;/span&gt;&lt;span&gt;64&lt;/span&gt; bytes from &lt;span&gt;10.1&lt;/span&gt;.&lt;span&gt;1.1&lt;/span&gt;: icmp_seq=&lt;span&gt;4&lt;/span&gt; ttl=&lt;span&gt;64&lt;/span&gt; &lt;span&gt;time&lt;/span&gt;=&lt;span&gt;0.033&lt;/span&gt; ms
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;如上，给每个设备配备1个ip地址，配备成功后再启动设备，然后就可以进行相互的通信了，前面提到每个容器拥有自己单独的网络命名空间，而网络命名空间之间的通信是通过设备对，而上面演示的就是命名空间通过设备对进行通信的全过程，&lt;/p&gt;
&lt;p&gt;事实上容器之间、容器与宿主机之间都是通过设备对的方式进行通信的，当然实际上容器网络命名空间的创建、设备对的创建、IP的分配并不是手动进行的，都是容器在创建的时候会自动完成，对用户来说是无感知的，这里是方便展示内部原理，采用的手动的形式。&lt;/p&gt;

&lt;p&gt;&lt;span&gt;&lt;strong&gt;三、总结&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;本文主要重点介绍了容器PID和NET 命名空间（namespace）的隔离原理，其他namespace的隔离原理类似，容器本质上一种特殊的进程，它虽然提供了隔离技术，但与虚拟机的隔离技术要区别开来，虚拟机是在宿主机上通过Hypervisor虚拟了一个独立的GuestOS，它的隔离是彻底的，虚拟机上的进程在宿主机上无法查看；而容器本质上是宿主机上的进程，它的隔离机制是通过在进程上加入不同的namespace参数来实现资源、文件、设备、状态，或者配置的隔离，两者隔离的本质是有差异的，你或许有个疑问，既然容器是宿主机上的一个进程，而不同的进程可以相互共享宿主机的内核，一旦一个容器的应用逃逸入侵宿主机，是不是会有可能会影响宿主机或者其他容器应用呢，事实上，Docker容器的确存在这样的安全隐患，由此看来，Docker容器的隔离性并不像虚拟机般隔离的彻底，细心的读者，可能发现在这里为什么特意加入Docker，这是因为有其他类型的容器既可以提供虚拟机级般的隔离能力同时又拥有容器的高性能，这就是Kata容器，什么是Kata容器？这里先卖个关子，后续专文介绍下，感谢您的阅读！&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者简介：云计算容器\Docker\K8s\Serverless方向产品经理，学点技术，为更好地设计产品。&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
</description>
<pubDate>Sat, 29 Aug 2020 10:12:00 +0000</pubDate>
<dc:creator>lightinglei</dc:creator>
<og:description>一、先谈谈进程 在正式介绍Namespace之前，先介绍下进程，因为容器本质上是进程，但是在介绍进程之前，先理清下“程序”和“进程”的关系，这是IT从业人员在日常工作中经常碰到的两个词汇，举个通俗点的</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/gdut1425/p/13579460.html</dc:identifier>
</item>
<item>
<title>Combine 框架，从0到1  —— 3.使用 Subscriber 控制发布速度 - Ficow</title>
<link>http://www.cnblogs.com/ficow/p/13582587.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/ficow/p/13582587.html</guid>
<description>
&lt;p&gt;本文首发于 &lt;a href=&quot;https://ficowshen.com&quot;&gt;Ficow Shen's Blog&lt;/a&gt;，原文地址： &lt;a href=&quot;https://blog.ficowshen.com/page/post/14&quot;&gt;Combine 框架，从0到1 —— 3.使用 Subscriber 控制发布速度&lt;/a&gt;。&lt;/p&gt;

&lt;h2 id=&quot;内容概览&quot;&gt;内容概览&lt;/h2&gt;
&lt;ul&gt;&lt;li&gt;前言&lt;/li&gt;
&lt;li&gt;在发布者生产元素时消耗它们&lt;/li&gt;
&lt;li&gt;使用自定义的订阅者施加背压(back pressure)&lt;/li&gt;
&lt;li&gt;使用背压操作符管理无限需求(Unlimited Demand)&lt;/li&gt;
&lt;li&gt;总结&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;前言&quot;&gt;前言&lt;/h2&gt;

&lt;p&gt;对于大多数响应式编程场景而言，订阅者不需要对发布过程进行过多的控制。当发布者发布元素时，订阅者只需要无条件地接收即可。但是，&lt;code&gt;如果发布者发布的速度过快，而订阅者接收的速度又太慢&lt;/code&gt;，我们该怎么解决这个问题呢？&lt;code&gt;Combine&lt;/code&gt; 已经为我们制定了稳健的解决方案！现在，让我们来了解如何&lt;code&gt;施加背压(back pressure，也可以叫反压)以精确控制发布者何时生成元素&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;在 &lt;code&gt;Combine&lt;/code&gt; 中，发布者生成元素，而订阅者对其接收的元素进行操作。不过，发布者会在订阅者连接和获取元素时才发送元素。订阅者通过 &lt;code&gt;Subscribers.Demand&lt;/code&gt; 类型来表明自己可以接收多少个元素，以此来控制发布者发送元素的速率。&lt;/p&gt;
&lt;p&gt;订阅者可以通过两种方式来表明需求(&lt;code&gt;Demand&lt;/code&gt;)：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;调用 &lt;code&gt;Subscription&lt;/code&gt; 实例（由发布者在订阅者进行第一次订阅时提供）的 &lt;code&gt;request(_:)&lt;/code&gt; 方法；&lt;/li&gt;
&lt;li&gt;在发布者调用订阅者的 &lt;code&gt;receive(_:)&lt;/code&gt; 方法来发送元素时，返回一个新的 &lt;code&gt;Subscribers.Demand&lt;/code&gt; 实例；&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;code&gt;Demand&lt;/code&gt; 是可以累加的。如果订阅者已经请求了两个元素，然后请求 &lt;code&gt;Subscribers.Demand(.max(3))&lt;/code&gt;，则现在发布者不满足的需求是五个元素。如果发布者随后发送元素，则未满足的需求将减少到四个。&lt;/p&gt;

&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;发布元素是减少未满足需求的数量的唯一方法，订阅者不能请求负需求。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;很多应用会使用 &lt;code&gt;sink(receiveValue:)&lt;/code&gt; 和 &lt;code&gt;assign(to:on:)&lt;/code&gt; 来创建便捷的订阅者类型，分别为：&lt;code&gt;Subscribers.Sink&lt;/code&gt; 和 &lt;code&gt;Subscribers.Assign&lt;/code&gt;。这两种订阅者在第一次连接到发布者时，会发送一个 &lt;code&gt;unlimited&lt;/code&gt; 的 &lt;code&gt;Demand&lt;/code&gt;，这时候订阅者会一直不停地接收发布者发来的内容。&lt;/p&gt;

&lt;h2 id=&quot;在发布者生产元素时消耗它们&quot;&gt;在发布者生产元素时消耗它们&lt;/h2&gt;

&lt;p&gt;当发布者的需求很高或不受限制时，它发送元素的速度可能比订阅者处理元素的速度快很多。这种情况可能导致元素丢失，或者在元素等待被缓存时迅速增加内存的压力。&lt;/p&gt;
&lt;p&gt;如果您使用便捷的订阅者，则会发生这种情况，因为它们的需求(&lt;code&gt;Demand&lt;/code&gt;) 是无限数量 (&lt;code&gt;unlimited&lt;/code&gt;) 的元素。确保您提供给 &lt;code&gt;sink(receiveValue:)&lt;/code&gt; 的闭包和 &lt;code&gt;assign(to:on:)&lt;/code&gt; 的副作用(执行效果)遵循以下特征：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;不会阻塞发布者；&lt;/li&gt;
&lt;li&gt;不会因为缓存元素而消耗过多的内存；&lt;/li&gt;
&lt;li&gt;不会不知所措并且不能处理元素;&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;庆幸的是，许多常用的发布者（例如与用户界面元素相关联的发布者）都会以可控的速度进行发布。其他常见的发布者仅仅生成一个元素，例如：&lt;code&gt;URL&lt;/code&gt; 加载系统的 &lt;code&gt;URLSession.DataTaskPublisher&lt;/code&gt;。配合这些发布者，使用 &lt;code&gt;sink(receiveValue:)&lt;/code&gt; 和 &lt;code&gt;assign(to:on:)&lt;/code&gt; 订阅者是绝对安全的。&lt;/p&gt;

&lt;h2 id=&quot;使用自定义的订阅者施加背压back-pressure&quot;&gt;使用自定义的订阅者施加背压(back pressure)&lt;/h2&gt;

&lt;p&gt;想要控制发布者向订阅者发送元素的速率，可以创建订阅者协议的自定义实现。使用你的自定义实现来指定你的订阅者可以适应的需求。当订阅者接收元素时，它可以通过返回新的需求值给 &lt;code&gt;receive(_:)&lt;/code&gt; 方法，或通过在订阅上调用 &lt;code&gt;request(_:)&lt;/code&gt; 来请求更多内容。无论使用哪种方法，你自定义的订阅者都可以在任何给定时间微调发布者可以发送的元素数量。&lt;/p&gt;

&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;通过发信号来表明订阅者已准备好接收元素来控制流量的概念称为&lt;code&gt;背压&lt;/code&gt;。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;每个发布者都跟踪其当前未满足的需求，也就是：订阅者已请求多少个元素。甚至，像 &lt;code&gt;Foundation&lt;/code&gt; 框架中的 &lt;code&gt;Timer.TimerPublisher&lt;/code&gt; 这样的自动化资源，也只会在有未满足的需求时才产生元素。&lt;/p&gt;
&lt;p&gt;下面的示例代码说明了这个行为：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-swift&quot;&gt;// 发布者: 使用一个定时器来每秒发送一个日期对象
let timerPub = Timer.publish(every: 1, on: .main, in: .default)
    .autoconnect()


// 订阅者: 在订阅以后，等待5秒，然后请求最多3个值
class MySubscriber: Subscriber {
    typealias Input = Date
    typealias Failure = Never
    var subscription: Subscription?
    
    func receive(subscription: Subscription) {
        print(&quot;published                             received&quot;)
        self.subscription = subscription
        DispatchQueue.main.asyncAfter(deadline: .now() + 5) {
            subscription.request(.max(3))
        }
    }
    
    func receive(_ input: Date) -&amp;gt; Subscribers.Demand {
        print(&quot;\(input)             \(Date())&quot;)
        return Subscribers.Demand.none
    }
    
    func receive(completion: Subscribers.Completion&amp;lt;Never&amp;gt;) {
        print (&quot;--done--&quot;)
    }
}

// 订阅 timerPub
let mySub = MySubscriber()
print (&quot;Subscribing at \(Date())&quot;)
timerPub.subscribe(mySub)
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;订阅者的 &lt;code&gt;receive(subscription:)&lt;/code&gt; 实现在请求发布者的任何元素之前执行了五秒钟的延迟。在此期间，发布者存在并具有有效的订阅者，但需求为零，因此不会产生任何元素。它仅在延迟到期且订阅者给它一个非零需求 &lt;code&gt;subscription.request(.max(3))&lt;/code&gt; 之后才开始发布元素，如以下输出所示：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;Subscribing at 2019-12-09 18:57:06 +0000
published                             received
2019-12-09 18:57:11 +0000             2019-12-09 18:57:11 +0000
2019-12-09 18:57:12 +0000             2019-12-09 18:57:12 +0000
2019-12-09 18:57:13 +0000             2019-12-09 18:57:13 +0000
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;这个示例只请求了三个元素，在五秒钟的延迟到期后发出需求。最后，发布者在第三个元素之后不再发送其他元素，但是也不会通过发送完成(&lt;code&gt;.finished&lt;/code&gt;) 的值来完成发布，因为发布者只是在等待更多需求。为了继续接收元素，订阅者可以存储订阅并定期请求更多元素。它还可以在 &lt;code&gt;receive(_:)&lt;/code&gt; 方法中返回新需求的值。&lt;/p&gt;

&lt;h2 id=&quot;使用背压操作符管理无限需求unlimited-demand&quot;&gt;使用背压操作符管理无限需求(Unlimited Demand)&lt;/h2&gt;

&lt;p&gt;即使没有自定义的订阅者，你也可以通过一些操作符来实施背压：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;code&gt;buffer(size:prefetch:whenFull:)&lt;/code&gt; ，保留来自上游发布者的固定数量的项目。缓冲满了之后，缓冲区会丢弃元素或抛出错误；&lt;/li&gt;
&lt;li&gt;&lt;code&gt;debounce(for:scheduler:options:)&lt;/code&gt;，只在上游发布者在指定的时间间隔内停止发布时才发布；&lt;/li&gt;
&lt;li&gt;&lt;code&gt;throttle(for:scheduler:latest:)&lt;/code&gt;，以给定的最大速率生成元素。如果在一个间隔内接收到多个元素，则仅发送最新的或最早的元素;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;collect(_:)&lt;/code&gt; 和 &lt;code&gt;collect(_:options:)&lt;/code&gt; 聚集元素，直到它们超过给定的数量或时间间隔，然后向订阅者发送元素数组。如果订阅者可以同时处理多个元素，这个操作符将是很好的选择。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;由于这些操作符可以控制订阅者接收的元素数量，因此可以放心地连接无限需求的订阅者，例如：&lt;code&gt;sink(receiveValue:)&lt;/code&gt; 和 &lt;code&gt;assign(to:on:)&lt;/code&gt;。&lt;/p&gt;

&lt;h2 id=&quot;总结&quot;&gt;总结&lt;/h2&gt;

&lt;p&gt;通过实施背压，我们可以灵活地调控发布过程。背压操作符可以帮助我们应对大多数场景，这些操作符可以大幅提升我们的开发效率。&lt;/p&gt;
&lt;p&gt;比如这种常见的场景：当搜索输入框的内容发生变动时，应用需要去查找用户输入内容对应的结果，但是这个查找操作的频率需要有一定的控制。如果用户按住一个键不放开，输入框的内容就会一直变化，此时就会触发多次查找操作。这时候，我们可以从容地使用背压操作符解决这种问题。&lt;/p&gt;
&lt;p&gt;如果你需要处理的场景非常复杂，通过自定义订阅者来实施&lt;code&gt;精确的背压&lt;/code&gt;将会是一个更好的选择。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;本文内容来源：&lt;/strong&gt; &lt;a href=&quot;https://developer.apple.com/documentation/combine/processing-published-elements-with-subscribers&quot;&gt;Processing Published Elements with Subscribers&lt;/a&gt;，转载请&lt;a href=&quot;https://blog.ficowshen.com&quot;&gt;注明出处&lt;/a&gt;。&lt;/p&gt;

</description>
<pubDate>Sat, 29 Aug 2020 08:26:00 +0000</pubDate>
<dc:creator>Ficow</dc:creator>
<og:description>本文首发于 Ficow Shen&amp;amp;#39;s Blog，原文地址： Combine 框架，从0到1 —— 3.使用 Subscriber 控制发布速度。 内容概览 前言 在发布者生产元素时消耗</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/ficow/p/13582587.html</dc:identifier>
</item>
</channel>
</rss>