<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="css/feed.xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/" xmlns:og="http://ogp.me/ns#">
<channel>
<atom:link rel="self" href="http://192.168.1.4/fivefilters/makefulltextfeed.php?url=feed.cnblogs.com%2Fblog%2Fsitehome%2Frss&amp;max=10&amp;links=preserve&amp;exc=" />
<atom:link rel="alternate" title="Source URL" href="http://feed.cnblogs.com/blog/sitehome/rss" />
<atom:link rel="related" title="Subscribe to feed" href="http://www.subtome.com/#/subscribe?feeds=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed.cnblogs.com%252Fblog%252Fsitehome%252Frss%26max%3D10%26links%3Dpreserve%26exc%3D&amp;back=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed.cnblogs.com%252Fblog%252Fsitehome%252Frss%26max%3D10%26links%3Dpreserve%26exc%3D" />
<title>博客园_首页</title>
<link></link>
<description>代码改变世界</description>
<item>
<title>Delphi - 互斥对象下实现系统的单例模式 - Jeremy.Wu</title>
<link>http://www.cnblogs.com/jeremywucnblog/p/11450919.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/jeremywucnblog/p/11450919.html</guid>
<description>&lt;p&gt;&lt;strong&gt;使用CreateMutex函数创建互斥对象&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;利用Windows系统函数CreateMutex()，找出当前系统是否已经存在指定进程的实例，如果没有则创建一个互斥体。&lt;/p&gt;
&lt;p&gt;CreateMutex函数原型如下:&lt;/p&gt;
&lt;p&gt;function CreateMutex(lpMutexAttributes: PSecurityAttributes; bInitialOwner: BOOL; lpName: PChar): THandle; &lt;/p&gt;
&lt;p&gt;function CreateMutex(lpMutexAttributes: PSecurityAttributes; bInitialOwner: BOOL; lpName: PChar): THandle;&lt;/p&gt;
&lt;p&gt;其中参数：&lt;/p&gt;
&lt;p&gt;lpMutexAttributes ：SECURITY_ATTRIBUTES 结构类型指针，可以为NULL。&lt;/p&gt;
&lt;p&gt;bInitialOwner ：是否初始化互斥体。&lt;/p&gt;
&lt;p&gt;lpName ：互斥体对象的名称，一般是工程的名称。&lt;/p&gt;
&lt;p&gt;最终，函数返回一个互斥体句柄。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Delphi WinFrm利用互斥对象实现单例模式&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;单击Project，View Source；&lt;/p&gt;
&lt;p&gt;uses 中添加Windows；&lt;/p&gt;
&lt;p&gt;Begin和End之间添加如下代码。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1335881/201909/1335881-20190903084110505-931764581.png&quot; alt=&quot;&quot;/&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1335881/201909/1335881-20190903084705540-406291193.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;


&lt;div class=&quot;cnblogs_code&quot; readability=&quot;39&quot;&gt;
&lt;pre&gt;
  &lt;span&gt;//&lt;/span&gt;&lt;span&gt;*****************************单例模式********************************&lt;/span&gt;
  CreateMutex(&lt;span&gt;nil&lt;/span&gt;, False, &lt;span&gt;'&lt;/span&gt;&lt;span&gt;Application Name&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;);
  &lt;/span&gt;&lt;span&gt;if&lt;/span&gt; GetLastError = ERROR_ALREADY_EXISTS &lt;span&gt;then&lt;/span&gt;
  &lt;span&gt;begin&lt;/span&gt;&lt;span&gt;
    Application.MessageBox(&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;系统已经开启了，请确认下！&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;, &lt;span&gt;'&lt;/span&gt;&lt;span&gt;提示&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;, MB_OK);
    Halt(&lt;/span&gt;&lt;span&gt;0&lt;/span&gt;&lt;span&gt;);
  &lt;/span&gt;&lt;span&gt;end&lt;/span&gt;&lt;span&gt;;
    &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;*****************************单例模式********************************&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

</description>
<pubDate>Tue, 03 Sep 2019 00:49:00 +0000</pubDate>
<dc:creator>Jeremy.Wu</dc:creator>
<og:description>使用CreateMutex函数创建互斥对象 利用Windows系统函数CreateMutex()，找出当前系统是否已经存在指定进程的实例，如果没有则创建一个互斥体。 CreateMutex函数原型如下</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/jeremywucnblog/p/11450919.html</dc:identifier>
</item>
<item>
<title>从SpringBoot构建十万博文聊聊限流特技 - 小柒2012</title>
<link>http://www.cnblogs.com/smallSevens/p/11450911.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/smallSevens/p/11450911.html</guid>
<description>&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/109211/201909/109211-20190903084539542-1926323390.png&quot;/&gt;&lt;/p&gt;
&lt;h2 id=&quot;前言&quot;&gt;前言&lt;/h2&gt;
&lt;p&gt;在开发十万博客系统的的过程中，前面主要分享了爬虫、缓存穿透以及文章阅读量计数等等。爬虫的目的就是解决十万+问题；缓存穿透是为了保护后端数据库查询服务；计数服务解决了接近真实阅读数以及数据库服务的压力。&lt;/p&gt;
&lt;h2 id=&quot;架构图&quot;&gt;架构图&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/109211/201909/109211-20190903084548770-1297124532.png&quot;/&gt;&lt;/p&gt;
&lt;h2 id=&quot;限流&quot;&gt;限流&lt;/h2&gt;
&lt;p&gt;就拿十万博客来说，如果存在热点文章，可能会有数十万级别的并发用户参与阅读。如果想让这些用户正常访问，无非就是加机器横向扩展各种服务，但凡事都有一个利益平衡点，有时候只需要少量的机器保证大部分用户在大部分时间可以正常访问即可。&lt;/p&gt;
&lt;p&gt;亦或是，如果存在大量爬虫或者恶意攻击，我们必须采取一定的措施来保证服务的正常运行。这时候我们就要考虑限流来保证服务的可用性，以防止非预期的请求对系统压力过大而引起的系统瘫痪。通常的策略就是拒绝多余的访问，或者让多余的访问排队等待服务。&lt;/p&gt;
&lt;h2 id=&quot;限流算法&quot;&gt;限流算法&lt;/h2&gt;
&lt;p&gt;任何限流都不是漫无目的的，也不是一个开关就可以解决的问题，常用的限流算法有：令牌桶，漏桶。&lt;/p&gt;
&lt;h4 id=&quot;令牌桶&quot;&gt;令牌桶&lt;/h4&gt;
&lt;p&gt;令牌桶算法是网络流量整形（Traffic Shaping）和速率限制（Rate Limiting）中最常使用的一种算法。典型情况下，令牌桶算法用来控制发送到网络上的数据的数目，并允许突发数据的发送(百科)。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/109211/201909/109211-20190903084558458-1937770210.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;用户的请求速率是不固定的，这里我们假定为10r/s，令牌按照5个每秒的速率放入令牌桶，桶中最多存放20个令牌。仔细想想，是不是总有那么一部分请求被丢弃。&lt;/p&gt;
&lt;h4 id=&quot;漏桶&quot;&gt;漏桶&lt;/h4&gt;
&lt;p&gt;漏桶算法的主要目的是控制数据注入到网络的速率，平滑网络上的突发流量。漏桶算法提供了一种机制，通过它，突发流量可以被整形以便为网络提供一个稳定的流量(百科)。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/109211/201909/109211-20190903084606050-1929585770.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;令牌桶是无论你流入速率多大，我都按照既定的速率去处理，如果桶满则拒绝服务。&lt;/p&gt;
&lt;h2 id=&quot;应用限流&quot;&gt;应用限流&lt;/h2&gt;
&lt;h4 id=&quot;tomcat&quot;&gt;Tomcat&lt;/h4&gt;
&lt;p&gt;在Tomcat容器中，我们可以通过自定义线程池，配置最大连接数，请求处理队列等参数来达到限流的目的。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/109211/201909/109211-20190903084615771-1856054415.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;Tomcat默认使用自带的连接池，这里我们也可以自定义实现，打开/conf/server.xml文件，在Connector之前配置一个线程池：&lt;/p&gt;
&lt;pre class=&quot;xml&quot;&gt;
&lt;code&gt;&amp;lt;Executor name=&quot;tomcatThreadPool&quot;
        namePrefix=&quot;tomcatThreadPool-&quot;
        maxThreads=&quot;1000&quot;
        maxIdleTime=&quot;300000&quot;
        minSpareThreads=&quot;200&quot;/&amp;gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;ul&gt;&lt;li&gt;name：共享线程池的名字。这是Connector为了共享线程池要引用的名字，该名字必须唯一。默认值：None；&lt;/li&gt;
&lt;li&gt;namePrefix:在JVM上，每个运行线程都可以有一个name 字符串。这一属性为线程池中每个线程的name字符串设置了一个前缀，Tomcat将把线程号追加到这一前缀的后面。默认值：tomcat-exec-；&lt;/li&gt;
&lt;li&gt;maxThreads：该线程池可以容纳的最大线程数。默认值：200；&lt;/li&gt;
&lt;li&gt;maxIdleTime：在Tomcat关闭一个空闲线程之前，允许空闲线程持续的时间(以毫秒为单位)。只有当前活跃的线程数大于minSpareThread的值，才会关闭空闲线程。默认值：60000(一分钟)。&lt;/li&gt;
&lt;li&gt;minSpareThreads：Tomcat应该始终打开的最小不活跃线程数。默认值：25。&lt;/li&gt;
&lt;/ul&gt;&lt;h5 id=&quot;配置connector&quot;&gt;配置Connector&lt;/h5&gt;
&lt;pre class=&quot;xml&quot;&gt;
&lt;code&gt;&amp;lt;Connector executor=&quot;tomcatThreadPool&quot;
           port=&quot;8080&quot; protocol=&quot;HTTP/1.1&quot;
           connectionTimeout=&quot;20000&quot;
           redirectPort=&quot;8443&quot;
           minProcessors=&quot;5&quot;
           maxProcessors=&quot;75&quot;
           acceptCount=&quot;1000&quot;/&amp;gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;ul&gt;&lt;li&gt;executor：表示使用该参数值对应的线程池；&lt;/li&gt;
&lt;li&gt;minProcessors：服务器启动时创建的处理请求的线程数；&lt;/li&gt;
&lt;li&gt;maxProcessors：最大可以创建的处理请求的线程数；&lt;/li&gt;
&lt;li&gt;acceptCount：指定当所有可以使用的处理请求的线程数都被使用时，可以放到处理队列中的请求数，超过这个数的请求将不予处理。&lt;/li&gt;
&lt;/ul&gt;&lt;h3 id=&quot;api限流&quot;&gt;API限流&lt;/h3&gt;
&lt;p&gt;这里我们采用开源工具包guava提供的限流工具类RateLimiter进行API限流，该类基于&quot;令牌桶算法&quot;，开箱即用。&lt;/p&gt;
&lt;p&gt;自定义定义注解&lt;/p&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;/**
 * 自定义注解  限流
 * 创建者  爪洼笔记
 * 博客 https://blog.52itstyle.vip
 * 创建时间 2019年8月15日
 */
@Target({ElementType.PARAMETER, ElementType.METHOD})
@Retention(RetentionPolicy.RUNTIME)
@Documented
public  @interface ServiceLimit {
    /**
     * 描述
     */
    String description()  default &quot;&quot;;

    /**
     * key
     */
    String key() default &quot;&quot;;

    /**
     * 类型
     */
    LimitType limitType() default LimitType.CUSTOMER;

    enum LimitType {
        /**
         * 自定义key
         */
        CUSTOMER,
        /**
         * 根据请求者IP
         */
        IP
    }
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;自定义切面&lt;/p&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;/**
 * 限流 AOP
 * 创建者  爪洼笔记
 * 博客 https://blog.52itstyle.vip
 * 创建时间 2019年8月15日
 */
@Aspect
@Configuration
@Order(1)
public class LimitAspect{

    //根据IP分不同的令牌桶, 每天自动清理缓存
    private static LoadingCache&amp;lt;String, RateLimiter&amp;gt; caches = CacheBuilder.newBuilder()
            .maximumSize(1000)
            .expireAfterWrite(1, TimeUnit.DAYS)
            .build(new CacheLoader&amp;lt;String, RateLimiter&amp;gt;() {
                @Override
                public RateLimiter load(String key){
                    // 新的IP初始化 每秒只发出5个令牌
                    return RateLimiter.create(5);
                }
            });

    //Service层切点  限流
    @Pointcut(&quot;@annotation(com.itstyle.blog.common.limit.ServiceLimit)&quot;)
    public void ServiceAspect() {

    }

    @Around(&quot;ServiceAspect()&quot;)
    public  Object around(ProceedingJoinPoint joinPoint) {
        MethodSignature signature = (MethodSignature) joinPoint.getSignature();
        Method method = signature.getMethod();
        ServiceLimit limitAnnotation = method.getAnnotation(ServiceLimit.class);
        ServiceLimit.LimitType limitType = limitAnnotation.limitType();
        String key = limitAnnotation.key();
        Object obj;
        try {
            if(limitType.equals(ServiceLimit.LimitType.IP)){
                key = IPUtils.getIpAddr();
            }
            RateLimiter rateLimiter = caches.get(key);
            Boolean flag = rateLimiter.tryAcquire();
            if(flag){
                obj = joinPoint.proceed();
            }else{
                throw new RrException(&quot;小同志，你访问的太频繁了&quot;);
            }
        } catch (Throwable e) {
            throw new RrException(&quot;小同志，你访问的太频繁了&quot;);
        }
        return obj;
    }
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;业务实现：&lt;/p&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;   /**
     * 执行顺序
     * 1）限流
     * 2）布隆
     * 3）计数
     * 4) 缓存
     * @param id
     * @return
     */
    @Override
    @ServiceLimit(limitType= ServiceLimit.LimitType.IP)
    @BloomLimit
    @HyperLogLimit
    @Cacheable(cacheNames =&quot;blog&quot;)
    public Blog getById(Long id) {
        String nativeSql = &quot;SELECT * FROM blog WHERE id=?&quot;;
        return dynamicQuery.nativeQuerySingleResult(Blog.class,nativeSql,new Object[]{id});
    }
&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;分布式限流&quot;&gt;分布式限流&lt;/h2&gt;
&lt;h3 id=&quot;nginx&quot;&gt;Nginx&lt;/h3&gt;
&lt;p&gt;如何使用Nginx实现基本的限流，比如单个IP限制每秒访问50次。通过Nginx限流模块，我们可以设置一旦并发连接数超过我们的设置，将返回503错误给客户端。&lt;/p&gt;
&lt;h4 id=&quot;配置nginx.conf&quot;&gt;配置nginx.conf&lt;/h4&gt;
&lt;pre&gt;
&lt;code&gt;#统一在http域中进行配置
#限制请求
limit_req_zone $binary_remote_addr $uri zone=api_read:20m rate=50r/s;
#按ip配置一个连接 zone
limit_conn_zone $binary_remote_addr zone=perip_conn:10m;
#按server配置一个连接 zone
limit_conn_zone $server_name zone=perserver_conn:100m;
server {
        listen       80;
        server_name  blog.52itstyle.top;
        index index.jsp;
        location / {
              #请求限流排队通过 burst默认是0
              limit_req zone=api_read burst=5;
              #连接数限制,每个IP并发请求为2
              limit_conn perip_conn 2;
              #服务所限制的连接数(即限制了该server并发连接数量)
              limit_conn perserver_conn 1000;
              #连接限速
              limit_rate 100k;
              proxy_pass      http://seckill;
        }
}
upstream seckill {
        fair;
        server  172.16.1.120:8080 weight=1  max_fails=2 fail_timeout=30s;
        server  172.16.1.130:8080 weight=1  max_fails=2 fail_timeout=30s;
}&lt;/code&gt;
&lt;/pre&gt;
&lt;h4 id=&quot;配置说明&quot;&gt;配置说明&lt;/h4&gt;
&lt;p&gt;imit_conn_zone&lt;/p&gt;
&lt;p&gt;是针对每个IP定义一个存储session状态的容器。这个示例中定义了一个100m的容器，按照32bytes/session，可以处理3200000个session。&lt;/p&gt;
&lt;p&gt;limit_rate 300k;&lt;/p&gt;
&lt;p&gt;对每个连接限速300k. 注意，这里是对连接限速，而不是对IP限速。如果一个IP允许两个并发连接，那么这个IP就是限速limit_rate×2。&lt;/p&gt;
&lt;p&gt;burst=5；&lt;/p&gt;
&lt;p&gt;这相当于桶的大小，如果某个请求超过了系统处理速度，会被放入桶中，等待被处理。如果桶满了，那么抱歉，请求直接返回503，客户端得到一个服务器忙的响应。如果系统处理请求的速度比较慢，桶里的请求也不能一直待在里面，如果超过一定时间，也是会被直接退回，返回服务器忙的响应。&lt;/p&gt;
&lt;h3 id=&quot;openresty&quot;&gt;OpenResty&lt;/h3&gt;
&lt;p&gt;这里我们使用 OpenResty 开源的限流方案，测试案例使用OpenResty1.15.8.1最新版本，自带lua-resty-limit-traffic模块以及案例 ，实现起来更为方便。&lt;/p&gt;
&lt;h4 id=&quot;限制接口总并发数请求数&quot;&gt;限制接口总并发数/请求数&lt;/h4&gt;
&lt;p&gt;热点博文，由于突发流量暴增，有可能会影响整个系统的稳定性从而造成崩溃，这时候我们就要限制热点博文的总并发数/请求数。&lt;/p&gt;
&lt;p&gt;这里我们采用 lua-resty-limit-traffic中的resty.limit.count模块实现：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;-- 限制接口总并发数/请求数
local limit_count = require &quot;resty.limit.count&quot;

-- 这里我们使用AB测试,-n访问10000次, -c并发1200个 
-- ab -n 10000 -c 1200 http://121.42.155.213/ ,第一次测试数据：1000个请求会有差不多8801请求失败，符合以下配置说明
-- 限制 一分钟内只能调用 1200 次 接口（允许在时间段开始的时候一次性放过1200个请求）
local lim, err = limit_count.new(&quot;my_limit_count_store&quot;, 1200, 60)
if not lim then
    ngx.log(ngx.ERR, &quot;failed to instantiate a resty.limit.count object: &quot;, err)
    return ngx.exit(500)
end

-- use the Authorization header as the limiting key
local key = ngx.req.get_headers()[&quot;Authorization&quot;] or &quot;public&quot;
local delay, err = lim:incoming(key, true)

if not delay then
    if err == &quot;rejected&quot; then
        ngx.header[&quot;X-RateLimit-Limit&quot;] = &quot;5000&quot;
        ngx.header[&quot;X-RateLimit-Remaining&quot;] = 0
        return ngx.exit(503)
    end
    ngx.log(ngx.ERR, &quot;failed to limit count: &quot;, err)
    return ngx.exit(500)
end

-- the 2nd return value holds the current remaining number
-- of requests for the specified key.
local remaining = err

ngx.header[&quot;X-RateLimit-Limit&quot;] = &quot;5000&quot;
ngx.header[&quot;X-RateLimit-Remaining&quot;] = remaining&lt;/code&gt;
&lt;/pre&gt;
&lt;h4 id=&quot;限制接口时间窗请求数&quot;&gt;限制接口时间窗请求数&lt;/h4&gt;
&lt;p&gt;现在网络爬虫泛滥，有时候并不是人为的去点击，亦或是存在恶意攻击的情况。此时我们就要对客户端单位时间内的请求数进行限制，以至于黑客不是那么猖獗。当然了道高一尺魔高一丈，攻击者总是会有办法绕开你的防线，从另一方面讲也促进了技术的进步。&lt;/p&gt;
&lt;p&gt;这里我们采用 lua-resty-limit-traffic中的resty.limit.conn模块实现：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;-- well, we could put the require() and new() calls in our own Lua
-- modules to save overhead. here we put them below just for
-- convenience.

local limit_conn = require &quot;resty.limit.conn&quot;
-- 这里我们使用AB测试,-n访问1000次, -c并发100个 
-- ab -n 1000 -c 100 http://121.42.155.213/ ,这里1000个请求将会有700个失败
-- 相同IP段的人将不能被访问，不影响其它IP 

-- 限制 IP 总请求数
-- 限制单个 ip 客户端最大 200 req/sec 并且允许100 req/sec的突发请求
-- 就是说我们会把200以上300一下的请求请求给延迟， 超过300的请求将会被拒绝
-- 最后一个参数其实是你要预估这些并发（或者说单个请求）要处理多久,可以通过的log_by_lua中的leaving（）调用进行动态调整
local lim, err = limit_conn.new(&quot;my_limit_conn_store&quot;, 200, 100, 0.5)
if not lim then
    ngx.log(ngx.ERR,
            &quot;failed to instantiate a resty.limit.conn object: &quot;, err)
    return ngx.exit(500)
end

-- the following call must be per-request.
-- here we use the remote (IP) address as the limiting key
-- commit 为true 代表要更新shared dict中key的值，
-- false 代表只是查看当前请求要处理的延时情况和前面还未被处理的请求数
local key = ngx.var.binary_remote_addr
local delay, err = lim:incoming(key, true)
if not delay then
    if err == &quot;rejected&quot; then
        return ngx.exit(503)
    end
    ngx.log(ngx.ERR, &quot;failed to limit req: &quot;, err)
    return ngx.exit(500)
end

if lim:is_committed() then
    local ctx = ngx.ctx
    ctx.limit_conn = lim
    ctx.limit_conn_key = key
    ctx.limit_conn_delay = delay
end

-- the 2nd return value holds the current concurrency level
-- for the specified key.
local conn = err

if delay &amp;gt;= 0.001 then
    -- 其实这里的 delay 肯定是上面说的并发处理时间的整数倍，
    -- 举个例子，每秒处理100并发，桶容量200个，当时同时来500个并发，则200个拒掉
    -- 100个在被处理，然后200个进入桶中暂存，被暂存的这200个连接中，0-100个连接其实应该延后0.5秒处理，
    -- 101-200个则应该延后0.5*2=1秒处理（0.5是上面预估的并发处理时间）
    -- the request exceeding the 200 connections ratio but below
    -- 300 connections, so
    -- we intentionally delay it here a bit to conform to the
    -- 200 connection limit.
    -- ngx.log(ngx.WARN, &quot;delaying&quot;)
    ngx.sleep(delay)
end
&lt;/code&gt;
&lt;/pre&gt;
&lt;h4 id=&quot;平滑限制接口请求数&quot;&gt;平滑限制接口请求数&lt;/h4&gt;
&lt;p&gt;之前的限流方式允许突发流量，也就是说瞬时流量都会被允许。突然流量如果不加以限制会影响整个系统的稳定性，因此在秒杀场景中需要对请求整形为平均速率处理，即20r/s。&lt;/p&gt;
&lt;p&gt;这里我们采用 lua-resty-limit-traffic 中的resty.limit.req 模块实现漏桶限流和令牌桶限流。&lt;/p&gt;
&lt;p&gt;其实漏桶和令牌桶根本的区别就是，如何处理超过请求速率的请求。漏桶会把请求放入队列中去等待均速处理，队列满则拒绝服务；令牌桶在桶容量允许的情况下直接处理这些突发请求。&lt;/p&gt;
&lt;h5 id=&quot;漏桶-1&quot;&gt;漏桶&lt;/h5&gt;
&lt;p&gt;桶容量大于零，并且是延迟模式。如果桶没满，则进入请求队列以固定速率等待处理，否则请求被拒绝。&lt;/p&gt;
&lt;h5 id=&quot;令牌桶-1&quot;&gt;令牌桶&lt;/h5&gt;
&lt;p&gt;桶容量大于零，并且是非延迟模式。如果桶中存在令牌，则允许突发流量，否则请求被拒绝。&lt;/p&gt;
&lt;h2 id=&quot;压测&quot;&gt;压测&lt;/h2&gt;
&lt;p&gt;为了测试以上配置效果，我们采用AB压测，Linux下执行以下命令即可：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;# 安装
yum -y install httpd-tools
# 查看ab版本
ab -v
# 查看帮助
ab --help&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;测试命令：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;ab -n 1000 -c 100 http://127.0.0.1/&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;测试结果：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;Server Software:        openresty/1.15.8.1  #服务器软件
Server Hostname:        127.0.0.1     #IP
Server Port:            80            #请求端口号

Document Path:          /             #文件路径
Document Length:        12 bytes      #页面字节数

Concurrency Level:      100           #请求的并发数
Time taken for tests:   4.999 seconds #总访问时间
Complete requests:      1000          #总请求树
Failed requests:        0             #请求失败数量
Write errors:           0
Total transferred:      140000 bytes  #请求总数据大小
HTML transferred:       12000 bytes   #html页面实际总字节数
Requests per second:    200.06 [#/sec] (mean) #每秒多少请求，这个是非常重要的参数数值，服务器的吞吐量
Time per request:       499.857 [ms] (mean) #用户平均请求等待时间 
Time per request:       4.999 [ms] (mean, across all concurrent requests)  # 服务器平均处理时间，也就是服务器吞吐量的倒数 
Transfer rate:          27.35 [Kbytes/sec] received #每秒获取的数据长度

Connection Times (ms)
              min  mean[+/-sd] median   max
Connect:        0    0   0.8      0       4
Processing:     5  474  89.1    500     501
Waiting:        2  474  89.2    500     501
Total:          9  475  88.4    500     501

Percentage of the requests served within a certain time (ms)
  50%    500
  66%    500
  75%    500
  80%    500
  90%    501
  95%    501
  98%    501
  99%    501
 100%    501 (longest request)&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;源码&quot;&gt;源码&lt;/h2&gt;
&lt;p&gt;&lt;a href=&quot;https://gitee.com/52itstyle/spring-boot-blog&quot; title=&quot;SpringBoot开发案例之打造十万博文Web篇&quot;&gt;SpringBoot开发案例之打造十万博文Web篇&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;总结&quot;&gt;总结&lt;/h2&gt;
&lt;p&gt;以上限流方案，只是针对此次十万博文做一个简单的小结，大家也不要刻意区分那种方案的好坏，只要适合业务场景就是最好的。&lt;/p&gt;
</description>
<pubDate>Tue, 03 Sep 2019 00:48:00 +0000</pubDate>
<dc:creator>小柒2012</dc:creator>
<og:description>前言 在开发十万博客系统的的过程中，前面主要分享了爬虫、缓存穿透以及文章阅读量计数等等。爬虫的目的就是解决十万+问题；缓存穿透是为了保护后端数据库查询服务；计数服务解决了接近真实阅读数以及数据库服务的</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/smallSevens/p/11450911.html</dc:identifier>
</item>
<item>
<title>Docker swarm 获取service的container信息 - JadePeng</title>
<link>http://www.cnblogs.com/xiaoqi/p/docker-service-container.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/xiaoqi/p/docker-service-container.html</guid>
<description>&lt;p&gt;我们可以通过&lt;code&gt;docker service create&lt;/code&gt;创建服务，例如：&lt;/p&gt;
&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;docker service create --name mysql mysql:latest&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;服务创建好后，如何来获取该service包含的容器信息呢？比如获取刚才创建的mysql服务的容器。我们可以通过docker service ps命令来获取，&lt;/p&gt;
&lt;h2 id=&quot;命令行方式&quot;&gt;命令行方式&lt;/h2&gt;
&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;~# docker service ps mysql
ID                  NAME                IMAGE               NODE                DESIRED STATE       CURRENT STATE        ERROR               PORTS
lvskmv1lkhz6        mysql.1             mysql:latest        docker86-9          Running             Running 3 days ago &lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;遗憾的是返回的数据不包含containerId，只有serviceId, 可以通过&lt;code&gt;docker inspect来获取service详情&lt;/code&gt;&lt;/p&gt;
&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;
~# docker inspect lvskmv1lkhz6
[
    {
        &quot;ID&quot;: &quot;lvskmv1lkhz6bvynfuxa0jqgn&quot;,
        &quot;Version&quot;: {
            &quot;Index&quot;: 21
        },
        &quot;CreatedAt&quot;: &quot;2019-08-30T08:04:18.382831966Z&quot;,
        &quot;UpdatedAt&quot;: &quot;2019-08-30T08:09:43.613636037Z&quot;,
        &quot;Labels&quot;: {},
        &quot;Spec&quot;: {
            &quot;ContainerSpec&quot;: {
                &quot;Image&quot;: &quot;mysql:latest@sha256:01cf53f2538aa805bda591d83f107c394adca8d31f98eacd3654e282dada3193&quot;,
                &quot;Env&quot;: [
                    &quot;MYSQL_ROOT_PASSWORD=aimind@mysql2019\&quot;&quot;
                ],
                &quot;Isolation&quot;: &quot;default&quot;
            },
            &quot;Resources&quot;: {
                &quot;Limits&quot;: {},
                &quot;Reservations&quot;: {}
            },
            &quot;RestartPolicy&quot;: {
                &quot;Condition&quot;: &quot;any&quot;,
                &quot;Delay&quot;: 5000000000,
                &quot;MaxAttempts&quot;: 0,
                &quot;Window&quot;: 0
            },
            &quot;Placement&quot;: {},
            &quot;ForceUpdate&quot;: 0
        },
        &quot;ServiceID&quot;: &quot;uporil7xf4rwffa0rhg1j5htw&quot;,
        &quot;Slot&quot;: 1,
        &quot;NodeID&quot;: &quot;sixp62dhqe702b69pm6v8m9rh&quot;,
        &quot;Status&quot;: {
            &quot;Timestamp&quot;: &quot;2019-08-30T08:09:43.554514932Z&quot;,
            &quot;State&quot;: &quot;running&quot;,
            &quot;Message&quot;: &quot;started&quot;,
            &quot;ContainerStatus&quot;: {
                &quot;ContainerID&quot;: &quot;2cf128f77797f08419f50a057973388f15753efb16134ed05370ded495d0ac08&quot;,
                &quot;PID&quot;: 14884,
                &quot;ExitCode&quot;: 0
            },
            &quot;PortStatus&quot;: {}
        },
        &quot;DesiredState&quot;: &quot;running&quot;,
        &quot;NetworksAttachments&quot;: [
            {
                &quot;Network&quot;: {
                    &quot;ID&quot;: &quot;emypqxzjggws7uicersyz6uag&quot;,
                    &quot;Version&quot;: {
                        &quot;Index&quot;: 12
                    },
                    &quot;CreatedAt&quot;: &quot;2019-08-30T08:02:57.254494392Z&quot;,
                    &quot;UpdatedAt&quot;: &quot;2019-08-30T08:02:57.271216394Z&quot;,
                    &quot;Spec&quot;: {
                        &quot;Name&quot;: &quot;aimind-overlay&quot;,
                        &quot;Labels&quot;: {},
                        &quot;DriverConfiguration&quot;: {
                            &quot;Name&quot;: &quot;overlay&quot;
                        },
                        &quot;IPAMOptions&quot;: {
                            &quot;Driver&quot;: {
                                &quot;Name&quot;: &quot;default&quot;
                            }
                        },
                        &quot;Scope&quot;: &quot;swarm&quot;
                    },
                    &quot;DriverState&quot;: {
                        &quot;Name&quot;: &quot;overlay&quot;,
                        &quot;Options&quot;: {
                            &quot;com.docker.network.driver.overlay.vxlanid_list&quot;: &quot;4097&quot;
                        }
                    },
                    &quot;IPAMOptions&quot;: {
                        &quot;Driver&quot;: {
                            &quot;Name&quot;: &quot;default&quot;
                        },
                        &quot;Configs&quot;: [
                            {
                                &quot;Subnet&quot;: &quot;10.0.0.0/24&quot;,
                                &quot;Gateway&quot;: &quot;10.0.0.1&quot;
                            }
                        ]
                    }
                },
                &quot;Addresses&quot;: [
                    &quot;10.0.0.4/24&quot;
                ]
            }
        ]
    }
]
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;返回的json中，&lt;code&gt;NodeID&lt;/code&gt;是所在节点ID，&lt;code&gt;Status.ContainerStatus&lt;/code&gt; 是容器的状态信息，&lt;code&gt;.Status.ContainerStatus.ContainerID&lt;/code&gt; 是容器ID，比如这里的是&lt;code&gt;2cf128f77797f08419f50a057973388f15753efb16134ed05370ded495d0ac08&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;拿到容器ID就能获取容器详情了，也可以获取container的统计信息：&lt;/p&gt;
&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;docker inspect 2cf128f77797f08419f50a057973388f15753efb16134ed05370ded495d0ac08
[
    {
        &quot;Id&quot;: &quot;2cf128f77797f08419f50a057973388f15753efb16134ed05370ded495d0ac08&quot;,
        &quot;Created&quot;: &quot;2019-08-30T08:09:41.827551223Z&quot;,
        &quot;Path&quot;: &quot;docker-entrypoint.sh&quot;,
        &quot;Args&quot;: [
            &quot;mysqld&quot;
        ],
        &quot;State&quot;: {
            &quot;Status&quot;: &quot;running&quot;,
            &quot;Running&quot;: true,
            &quot;Paused&quot;: false,
            &quot;Restarting&quot;: false,
            &quot;OOMKilled&quot;: false,
            &quot;Dead&quot;: false,
            &quot;Pid&quot;: 14884,
            &quot;ExitCode&quot;: 0,
            &quot;Error&quot;: &quot;&quot;,
            &quot;StartedAt&quot;: &quot;2019-08-30T08:09:43.402630785Z&quot;,
            &quot;FinishedAt&quot;: &quot;0001-01-01T00:00:00Z&quot;
        },
        &quot;Image&quot;: &quot;sha256:62a9f311b99c24c0fde0a772abc6030bc48e5acc7d7416b8eeb72d3da1b4eb6c&quot;,
        &quot;ResolvConfPath&quot;: &quot;/data/docker/containers/2cf128f77797f08419f50a057973388f15753efb16134ed05370ded495d0ac08/resolv.conf&quot;,
        &quot;HostnamePath&quot;: &quot;/data/docker/containers/2cf128f77797f08419f50a057973388f15753efb16134ed05370ded495d0ac08/hostname&quot;,
        &quot;HostsPath&quot;: &quot;/data/docker/containers/2cf128f77797f08419f50a057973388f15753efb16134ed05370ded495d0ac08/hosts&quot;,
        &quot;LogPath&quot;: &quot;/data/docker/containers/2cf128f77797f08419f50a057973388f15753efb16134ed05370ded495d0ac08/2cf128f77797f08419f50a057973388f15753efb16134ed05370ded495d0ac08-json.log&quot;,
        &quot;Name&quot;: &quot;/mysql.1.lvskmv1lkhz6bvynfuxa0jqgn&quot;,
        &quot;RestartCount&quot;: 0,
        &quot;Driver&quot;: &quot;overlay2&quot;,
        &quot;Platform&quot;: &quot;linux&quot;,
        &quot;MountLabel&quot;: &quot;&quot;,
        &quot;ProcessLabel&quot;: &quot;&quot;,
        &quot;AppArmorProfile&quot;: &quot;docker-default&quot;,
        &quot;ExecIDs&quot;: null,
        &quot;HostConfig&quot;: {
            &quot;Binds&quot;: null,
            &quot;ContainerIDFile&quot;: &quot;&quot;,
            &quot;LogConfig&quot;: {
                &quot;Type&quot;: &quot;json-file&quot;,
                &quot;Config&quot;: {
                    &quot;max-file&quot;: &quot;3&quot;,
                    &quot;max-size&quot;: &quot;10m&quot;
                }
            },
            &quot;NetworkMode&quot;: &quot;default&quot;,
            &quot;PortBindings&quot;: {},
            &quot;RestartPolicy&quot;: {
                &quot;Name&quot;: &quot;&quot;,
                &quot;MaximumRetryCount&quot;: 0
            },
            &quot;AutoRemove&quot;: false,
            &quot;VolumeDriver&quot;: &quot;&quot;,
            &quot;VolumesFrom&quot;: null,
            &quot;CapAdd&quot;: null,
            &quot;CapDrop&quot;: null,
            &quot;Dns&quot;: null,
            &quot;DnsOptions&quot;: null,
            &quot;DnsSearch&quot;: null,
            &quot;ExtraHosts&quot;: null,
            &quot;GroupAdd&quot;: null,
            &quot;IpcMode&quot;: &quot;shareable&quot;,
            &quot;Cgroup&quot;: &quot;&quot;,
            &quot;Links&quot;: null,
            &quot;OomScoreAdj&quot;: 0,
            &quot;PidMode&quot;: &quot;&quot;,
            &quot;Privileged&quot;: false,
            &quot;PublishAllPorts&quot;: false,
            &quot;ReadonlyRootfs&quot;: false,
            &quot;SecurityOpt&quot;: null,
            &quot;UTSMode&quot;: &quot;&quot;,
            &quot;UsernsMode&quot;: &quot;&quot;,
            &quot;ShmSize&quot;: 67108864,
            &quot;Runtime&quot;: &quot;runc&quot;,
            &quot;ConsoleSize&quot;: [
                0,
                0
            ],
            &quot;Isolation&quot;: &quot;default&quot;,
            &quot;CpuShares&quot;: 0,
            &quot;Memory&quot;: 0,
            &quot;NanoCpus&quot;: 0,
            &quot;CgroupParent&quot;: &quot;&quot;,
            &quot;BlkioWeight&quot;: 0,
            &quot;BlkioWeightDevice&quot;: null,
            &quot;BlkioDeviceReadBps&quot;: null,
            &quot;BlkioDeviceWriteBps&quot;: null,
            &quot;BlkioDeviceReadIOps&quot;: null,
            &quot;BlkioDeviceWriteIOps&quot;: null,
            &quot;CpuPeriod&quot;: 0,
            &quot;CpuQuota&quot;: 0,
            &quot;CpuRealtimePeriod&quot;: 0,
            &quot;CpuRealtimeRuntime&quot;: 0,
            &quot;CpusetCpus&quot;: &quot;&quot;,
            &quot;CpusetMems&quot;: &quot;&quot;,
            &quot;Devices&quot;: null,
            &quot;DeviceCgroupRules&quot;: null,
            &quot;DiskQuota&quot;: 0,
            &quot;KernelMemory&quot;: 0,
            &quot;MemoryReservation&quot;: 0,
            &quot;MemorySwap&quot;: 0,
            &quot;MemorySwappiness&quot;: null,
            &quot;OomKillDisable&quot;: false,
            &quot;PidsLimit&quot;: 0,
            &quot;Ulimits&quot;: null,
            &quot;CpuCount&quot;: 0,
            &quot;CpuPercent&quot;: 0,
            &quot;IOMaximumIOps&quot;: 0,
            &quot;IOMaximumBandwidth&quot;: 0,
            &quot;MaskedPaths&quot;: [
                &quot;/proc/acpi&quot;,
                &quot;/proc/kcore&quot;,
                &quot;/proc/keys&quot;,
                &quot;/proc/latency_stats&quot;,
                &quot;/proc/timer_list&quot;,
                &quot;/proc/timer_stats&quot;,
                &quot;/proc/sched_debug&quot;,
                &quot;/proc/scsi&quot;,
                &quot;/sys/firmware&quot;
            ],
            &quot;ReadonlyPaths&quot;: [
                &quot;/proc/asound&quot;,
                &quot;/proc/bus&quot;,
                &quot;/proc/fs&quot;,
                &quot;/proc/irq&quot;,
                &quot;/proc/sys&quot;,
                &quot;/proc/sysrq-trigger&quot;
            ]
        },
        &quot;GraphDriver&quot;: {
            &quot;Data&quot;: {
                &quot;LowerDir&quot;: &quot;/data/docker/overlay2/f0184a2c979eef7a135726a49f5651e16b568ecfd47606e20e504e28ea311f25-init/diff:/data/docker/overlay2/644c4c905af78d3320559b9f388631151dcf5c19ab8f2c91999d4d59c8409784/diff:/data/docker/overlay2/7ed834798bd5eeef1b75d012a27bb01cd8a0a5e71048db72a8743980481bb74b/diff:/data/docker/overlay2/56e3eac1c86a9ae29b3251025824f93b78e43151a36eb973407feb1075d8db1c/diff:/data/docker/overlay2/40161cfa334a118eaa09c04dc7d864d00e3544f77e6979584298478f68566bc5/diff:/data/docker/overlay2/e884a3df3e827368a468a4afc8850de4fa6336a78ca9a922406237e3ab75a97e/diff:/data/docker/overlay2/a04e8776674f902eaa0e15467ad0678f03baf2a1b8a568b034ad4b4c1ddb1a23/diff:/data/docker/overlay2/7745739e901232d6b702b599844157583d02a34fa4aca10c888e0e9c44075433/diff:/data/docker/overlay2/f423b8f55475ec902cea1ea5c54897ed6a24da3cc0acd64a79e022e887d83e77/diff:/data/docker/overlay2/231e63e7fbb5084facc93c89ed23d366d915f9a2edd4f85735df5d45bc87cafa/diff:/data/docker/overlay2/c11047327e6f47e49d1abee4df8acbaba51ac6b92e59801ac613331c5bad3bc1/diff:/data/docker/overlay2/f893602043c1b5ad9d2839ec0ab8f17da7e0eaf073788f6c3d35138dfe6c06b8/diff:/data/docker/overlay2/3443517fc9e882df67d9730a9aa7530dc3c541b6872aaf05290c5e7ec588e0fb/diff&quot;,
                &quot;MergedDir&quot;: &quot;/data/docker/overlay2/f0184a2c979eef7a135726a49f5651e16b568ecfd47606e20e504e28ea311f25/merged&quot;,
                &quot;UpperDir&quot;: &quot;/data/docker/overlay2/f0184a2c979eef7a135726a49f5651e16b568ecfd47606e20e504e28ea311f25/diff&quot;,
                &quot;WorkDir&quot;: &quot;/data/docker/overlay2/f0184a2c979eef7a135726a49f5651e16b568ecfd47606e20e504e28ea311f25/work&quot;
            },
            &quot;Name&quot;: &quot;overlay2&quot;
        },
        &quot;Mounts&quot;: [
            {
                &quot;Type&quot;: &quot;volume&quot;,
                &quot;Name&quot;: &quot;c2128d05001b8fec1712807f381e2c72d42ce8a83ae97f6b038f51c0d48446f1&quot;,
                &quot;Source&quot;: &quot;/data/docker/volumes/c2128d05001b8fec1712807f381e2c72d42ce8a83ae97f6b038f51c0d48446f1/_data&quot;,
                &quot;Destination&quot;: &quot;/var/lib/mysql&quot;,
                &quot;Driver&quot;: &quot;local&quot;,
                &quot;Mode&quot;: &quot;&quot;,
                &quot;RW&quot;: true,
                &quot;Propagation&quot;: &quot;&quot;
            }
        ],
        &quot;Config&quot;: {
            &quot;Hostname&quot;: &quot;2cf128f77797&quot;,
            &quot;Domainname&quot;: &quot;&quot;,
            &quot;User&quot;: &quot;&quot;,
            &quot;AttachStdin&quot;: false,
            &quot;AttachStdout&quot;: false,
            &quot;AttachStderr&quot;: false,
            &quot;ExposedPorts&quot;: {
                &quot;3306/tcp&quot;: {},
                &quot;33060/tcp&quot;: {}
            },
            &quot;Tty&quot;: false,
            &quot;OpenStdin&quot;: false,
            &quot;StdinOnce&quot;: false,
            &quot;Env&quot;: [
                &quot;MYSQL_ROOT_PASSWORD=aimind@mysql2019\&quot;&quot;,
                &quot;PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin&quot;,
                &quot;GOSU_VERSION=1.7&quot;,
                &quot;MYSQL_MAJOR=8.0&quot;,
                &quot;MYSQL_VERSION=8.0.17-1debian9&quot;
            ],
            &quot;Cmd&quot;: [
                &quot;mysqld&quot;
            ],
            &quot;ArgsEscaped&quot;: true,
            &quot;Image&quot;: &quot;mysql:latest@sha256:01cf53f2538aa805bda591d83f107c394adca8d31f98eacd3654e282dada3193&quot;,
            &quot;Volumes&quot;: {
                &quot;/var/lib/mysql&quot;: {}
            },
            &quot;WorkingDir&quot;: &quot;&quot;,
            &quot;Entrypoint&quot;: [
                &quot;docker-entrypoint.sh&quot;
            ],
            &quot;OnBuild&quot;: null,
            &quot;Labels&quot;: {
                &quot;com.docker.swarm.node.id&quot;: &quot;sixp62dhqe702b69pm6v8m9rh&quot;,
                &quot;com.docker.swarm.service.id&quot;: &quot;uporil7xf4rwffa0rhg1j5htw&quot;,
                &quot;com.docker.swarm.service.name&quot;: &quot;mysql&quot;,
                &quot;com.docker.swarm.task&quot;: &quot;&quot;,
                &quot;com.docker.swarm.task.id&quot;: &quot;lvskmv1lkhz6bvynfuxa0jqgn&quot;,
                &quot;com.docker.swarm.task.name&quot;: &quot;mysql.1.lvskmv1lkhz6bvynfuxa0jqgn&quot;
            }
        },
        &quot;NetworkSettings&quot;: {
            &quot;Bridge&quot;: &quot;&quot;,
            &quot;SandboxID&quot;: &quot;459ab4b83580513da251182d08dc217d0079613d10952df00ffcca6e2537958b&quot;,
            &quot;HairpinMode&quot;: false,
            &quot;LinkLocalIPv6Address&quot;: &quot;&quot;,
            &quot;LinkLocalIPv6PrefixLen&quot;: 0,
            &quot;Ports&quot;: {
                &quot;3306/tcp&quot;: null,
                &quot;33060/tcp&quot;: null
            },
            &quot;SandboxKey&quot;: &quot;/var/run/docker/netns/459ab4b83580&quot;,
            &quot;SecondaryIPAddresses&quot;: null,
            &quot;SecondaryIPv6Addresses&quot;: null,
            &quot;EndpointID&quot;: &quot;&quot;,
            &quot;Gateway&quot;: &quot;&quot;,
            &quot;GlobalIPv6Address&quot;: &quot;&quot;,
            &quot;GlobalIPv6PrefixLen&quot;: 0,
            &quot;IPAddress&quot;: &quot;&quot;,
            &quot;IPPrefixLen&quot;: 0,
            &quot;IPv6Gateway&quot;: &quot;&quot;,
            &quot;MacAddress&quot;: &quot;&quot;,
            &quot;Networks&quot;: {
                &quot;aimind-overlay&quot;: {
                    &quot;IPAMConfig&quot;: {
                        &quot;IPv4Address&quot;: &quot;10.0.0.4&quot;
                    },
                    &quot;Links&quot;: null,
                    &quot;Aliases&quot;: [
                        &quot;2cf128f77797&quot;
                    ],
                    &quot;NetworkID&quot;: &quot;emypqxzjggws7uicersyz6uag&quot;,
                    &quot;EndpointID&quot;: &quot;56a78b2527a6dcf83fd3dc2794c514aaa325457d9c8a21bd236d3ea3c22c8fa9&quot;,
                    &quot;Gateway&quot;: &quot;&quot;,
                    &quot;IPAddress&quot;: &quot;10.0.0.4&quot;,
                    &quot;IPPrefixLen&quot;: 24,
                    &quot;IPv6Gateway&quot;: &quot;&quot;,
                    &quot;GlobalIPv6Address&quot;: &quot;&quot;,
                    &quot;GlobalIPv6PrefixLen&quot;: 0,
                    &quot;MacAddress&quot;: &quot;02:42:0a:00:00:04&quot;,
                    &quot;DriverOpts&quot;: null
                }
            }
        }
    }
]
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;然后就可以通过stats来获取资源占用情况：&lt;/p&gt;
&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;~#docker stats 2cf128f77797f08419f50a057973388f15753efb16134ed05370ded495d0ac08 --all --no-stream 
CONTAINER ID        NAME                                CPU %               MEM USAGE / LIMIT     MEM %               NET I/O             BLOCK I/O           PIDS
2cf128f77797        mysql.1.lvskmv1lkhz6bvynfuxa0jqgn   0.33%               374.4MiB / 188.8GiB   0.19%               230kB / 0B          8.19kB / 1.26GB     38&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;coding方式&quot;&gt;coding方式&lt;/h2&gt;
&lt;p&gt;除了命令行，我们还可以通过docker api来获取，可以参见 &lt;a href=&quot;https://www.cnblogs.com/xiaoqi/p/docker-java.html&quot;&gt;docker-java Docker的java API&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&quot;获取containerid&quot;&gt;获取containerID&lt;/h3&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;System.out.println(client.listTasksCmd().withNameFilter(&quot;mysql&quot;).exec());&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;结果：&lt;/p&gt;
&lt;pre class=&quot;javascript&quot;&gt;
&lt;code&gt;[class Task {
    ID: lvskmv1lkhz6bvynfuxa0jqgn
    version: 21
    createdAt: 2019-08-30T08:04:18.382831966Z
    updatedAt: 2019-08-30T08:09:43.613636037Z
    name: null
    labels: {}
    spec: TaskSpec[containerSpec=ContainerSpec[image=mysql:latest@sha256:01cf53f2538aa805bda591d83f107c394adca8d31f98eacd3654e282dada3193,labels=&amp;lt;null&amp;gt;,command=&amp;lt;null&amp;gt;,args=&amp;lt;null&amp;gt;,env=[MYSQL_ROOT_PASSWORD=aimind@mysql2019&quot;],dir=&amp;lt;null&amp;gt;,user=&amp;lt;null&amp;gt;,groups=&amp;lt;null&amp;gt;,tty=&amp;lt;null&amp;gt;,mounts=&amp;lt;null&amp;gt;,duration=&amp;lt;null&amp;gt;,stopGracePeriod=&amp;lt;null&amp;gt;,dnsConfig=&amp;lt;null&amp;gt;,openStdin=&amp;lt;null&amp;gt;,readOnly=&amp;lt;null&amp;gt;,hosts=&amp;lt;null&amp;gt;,hostname=&amp;lt;null&amp;gt;,secrets=&amp;lt;null&amp;gt;,healthCheck=&amp;lt;null&amp;gt;,stopSignal=&amp;lt;null&amp;gt;,privileges=&amp;lt;null&amp;gt;,configs=&amp;lt;null&amp;gt;],resources=ResourceRequirements[limits=ResourceSpecs[memoryBytes=&amp;lt;null&amp;gt;,nanoCPUs=&amp;lt;null&amp;gt;],reservations=ResourceSpecs[memoryBytes=&amp;lt;null&amp;gt;,nanoCPUs=&amp;lt;null&amp;gt;]],restartPolicy=ServiceRestartPolicy[condition=ANY,delay=5000000000,maxAttempts=0,window=0],placement=ServicePlacement[constraints=&amp;lt;null&amp;gt;,platforms=&amp;lt;null&amp;gt;],logDriver=&amp;lt;null&amp;gt;,forceUpdate=0,networks=&amp;lt;null&amp;gt;,runtime=&amp;lt;null&amp;gt;]
    serviceId: uporil7xf4rwffa0rhg1j5htw
    slot: 1
    nodeId: sixp62dhqe702b69pm6v8m9rh
    assignedGenericResources: null
    status: TaskStatus[timestamp=2019-08-30T08:09:43.554514932Z,state=running,message=started,err=&amp;lt;null&amp;gt;,containerStatus=TaskStatusContainerStatus[containerID=2cf128f77797f08419f50a057973388f15753efb16134ed05370ded495d0ac08,pid=14884,exitCode=0]]
    desiredState: running
}]&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;可以看到containerID：&lt;code&gt;2cf128f77797f08419f50a057973388f15753efb16134ed05370ded495d0ac08&lt;/code&gt; 和命令行一直。&lt;/p&gt;
&lt;p&gt;然后获取容器详情：&lt;/p&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt; System.out.println(client.inspectContainerCmd(&quot;2cf128f77797f08419f50a057973388f15753efb16134ed05370ded495d0ac08&quot;).exec());&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;获取容器统计信息：&lt;/p&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;        System.out.println(client.statsCmd(&quot;2cf128f77797f08419f50a057973388f15753efb16134ed05370ded495d0ac08&quot;).exec(new InvocationBuilder.AsyncResultCallback&amp;lt;&amp;gt;()).awaitResult());
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;对应的结果：&lt;/p&gt;
&lt;pre class=&quot;javascript&quot;&gt;
&lt;code&gt;InspectContainerResponse[args={mysqld},config=com.github.dockerjava.api.model.ContainerConfig@3e15bb06[attachStderr=false,attachStdin=false,attachStdout=false,cmd={mysqld},domainName=,entrypoint={docker-entrypoint.sh},env={MYSQL_ROOT_PASSWORD=aimind@mysql2019&quot;,PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin,GOSU_VERSION=1.7,MYSQL_MAJOR=8.0,MYSQL_VERSION=8.0.17-1debian9},exposedPorts=com.github.dockerjava.api.model.ExposedPorts@6778aea6,hostName=2cf128f77797,image=mysql:latest@sha256:01cf53f2538aa805bda591d83f107c394adca8d31f98eacd3654e282dada3193,labels={com.docker.swarm.node.id=sixp62dhqe702b69pm6v8m9rh, com.docker.swarm.service.id=uporil7xf4rwffa0rhg1j5htw, com.docker.swarm.service.name=mysql, com.docker.swarm.task=, com.docker.swarm.task.id=lvskmv1lkhz6bvynfuxa0jqgn, com.docker.swarm.task.name=mysql.1.lvskmv1lkhz6bvynfuxa0jqgn},macAddress=&amp;lt;null&amp;gt;,networkDisabled=&amp;lt;null&amp;gt;,onBuild=&amp;lt;null&amp;gt;,stdinOpen=false,portSpecs=&amp;lt;null&amp;gt;,stdInOnce=false,tty=false,user=,volumes={/var/lib/mysql={}},workingDir=,healthCheck=&amp;lt;null&amp;gt;],created=2019-08-30T08:09:41.827551223Z,driver=overlay2,execDriver=&amp;lt;null&amp;gt;,hostConfig=com.github.dockerjava.api.model.HostConfig@5853495b[binds=&amp;lt;null&amp;gt;,blkioWeight=0,blkioWeightDevice=&amp;lt;null&amp;gt;,blkioDeviceReadBps=&amp;lt;null&amp;gt;,blkioDeviceWriteBps=&amp;lt;null&amp;gt;,blkioDeviceReadIOps=&amp;lt;null&amp;gt;,blkioDeviceWriteIOps=&amp;lt;null&amp;gt;,memorySwappiness=&amp;lt;null&amp;gt;,nanoCPUs=&amp;lt;null&amp;gt;,capAdd=&amp;lt;null&amp;gt;,capDrop=&amp;lt;null&amp;gt;,containerIDFile=,cpuPeriod=0,cpuRealtimePeriod=0,cpuRealtimeRuntime=0,cpuShares=0,cpuQuota=0,cpusetCpus=,cpusetMems=,devices=&amp;lt;null&amp;gt;,deviceCgroupRules=&amp;lt;null&amp;gt;,diskQuota=0,dns=&amp;lt;null&amp;gt;,dnsOptions=&amp;lt;null&amp;gt;,dnsSearch=&amp;lt;null&amp;gt;,extraHosts=&amp;lt;null&amp;gt;,groupAdd=&amp;lt;null&amp;gt;,ipcMode=shareable,cgroup=,links=&amp;lt;null&amp;gt;,logConfig=com.github.dockerjava.api.model.LogConfig@524a2ffb,lxcConf=&amp;lt;null&amp;gt;,memory=0,memorySwap=0,memoryReservation=0,kernelMemory=0,networkMode=default,oomKillDisable=false,init=&amp;lt;null&amp;gt;,autoRemove=false,oomScoreAdj=0,portBindings={},privileged=false,publishAllPorts=false,readonlyRootfs=false,restartPolicy=no,ulimits=&amp;lt;null&amp;gt;,cpuCount=0,cpuPercent=0,ioMaximumIOps=0,ioMaximumBandwidth=0,volumesFrom=&amp;lt;null&amp;gt;,mounts=&amp;lt;null&amp;gt;,pidMode=,isolation=default,securityOpts=&amp;lt;null&amp;gt;,storageOpt=&amp;lt;null&amp;gt;,cgroupParent=,volumeDriver=,shmSize=67108864,pidsLimit=0,runtime=runc,tmpFs=&amp;lt;null&amp;gt;,utSMode=,usernsMode=,sysctls=&amp;lt;null&amp;gt;,consoleSize=[0, 0]],hostnamePath=/data/docker/containers/2cf128f77797f08419f50a057973388f15753efb16134ed05370ded495d0ac08/hostname,hostsPath=/data/docker/containers/2cf128f77797f08419f50a057973388f15753efb16134ed05370ded495d0ac08/hosts,logPath=/data/docker/containers/2cf128f77797f08419f50a057973388f15753efb16134ed05370ded495d0ac08/2cf128f77797f08419f50a057973388f15753efb16134ed05370ded495d0ac08-json.log,id=2cf128f77797f08419f50a057973388f15753efb16134ed05370ded495d0ac08,sizeRootFs=&amp;lt;null&amp;gt;,imageId=sha256:62a9f311b99c24c0fde0a772abc6030bc48e5acc7d7416b8eeb72d3da1b4eb6c,mountLabel=,name=/mysql.1.lvskmv1lkhz6bvynfuxa0jqgn,restartCount=0,networkSettings=com.github.dockerjava.api.model.NetworkSettings@7173ae5b[bridge=,sandboxId=459ab4b83580513da251182d08dc217d0079613d10952df00ffcca6e2537958b,hairpinMode=false,linkLocalIPv6Address=,linkLocalIPv6PrefixLen=0,ports={3306/tcp=null, 33060/tcp=null},sandboxKey=/var/run/docker/netns/459ab4b83580,secondaryIPAddresses=&amp;lt;null&amp;gt;,secondaryIPv6Addresses=&amp;lt;null&amp;gt;,endpointID=,gateway=,portMapping=&amp;lt;null&amp;gt;,globalIPv6Address=,globalIPv6PrefixLen=0,ipAddress=,ipPrefixLen=0,ipV6Gateway=,macAddress=,networks={aimind-overlay=com.github.dockerjava.api.model.ContainerNetwork@53a9fcfd[ipamConfig=com.github.dockerjava.api.model.ContainerNetwork$Ipam@21f459fc,links=&amp;lt;null&amp;gt;,aliases=[2cf128f77797],networkID=emypqxzjggws7uicersyz6uag,endpointId=56a78b2527a6dcf83fd3dc2794c514aaa325457d9c8a21bd236d3ea3c22c8fa9,gateway=,ipAddress=10.0.0.4,ipPrefixLen=24,ipV6Gateway=,globalIPv6Address=,globalIPv6PrefixLen=0,macAddress=02:42:0a:00:00:04]}],path=docker-entrypoint.sh,processLabel=,resolvConfPath=/data/docker/containers/2cf128f77797f08419f50a057973388f15753efb16134ed05370ded495d0ac08/resolv.conf,execIds=&amp;lt;null&amp;gt;,state=com.github.dockerjava.api.command.InspectContainerResponse$ContainerState@4d192aef[status=running,running=true,paused=false,restarting=false,oomKilled=false,dead=false,pid=14884,exitCode=0,error=,startedAt=2019-08-30T08:09:43.402630785Z,finishedAt=0001-01-01T00:00:00Z,health=&amp;lt;null&amp;gt;],volumes=&amp;lt;null&amp;gt;,volumesRW=&amp;lt;null&amp;gt;,node=&amp;lt;null&amp;gt;,mounts=[com.github.dockerjava.api.command.InspectContainerResponse$Mount@1416cf9f[name=c2128d05001b8fec1712807f381e2c72d42ce8a83ae97f6b038f51c0d48446f1,source=/data/docker/volumes/c2128d05001b8fec1712807f381e2c72d42ce8a83ae97f6b038f51c0d48446f1/_data,destination=/var/lib/mysql,driver=local,mode=,rw=true]],graphDriver=com.github.dockerjava.api.command.GraphDriver@84487f4[name=overlay2,data=com.github.dockerjava.api.command.GraphData@bfc14b9[rootDir=&amp;lt;null&amp;gt;,deviceId=&amp;lt;null&amp;gt;,deviceName=&amp;lt;null&amp;gt;,deviceSize=&amp;lt;null&amp;gt;,dir=&amp;lt;null&amp;gt;]],platform=linux]
Disconnected from the target VM, address: '127.0.0.1:60730', transport: 'socket'
com.github.dockerjava.api.model.Statistics@55a88417[read=2019-09-02T12:20:14.534216408Z,networks={eth0=com.github.dockerjava.api.model.StatisticNetworksConfig@18acfe88[rxBytes=0,rxDropped=0,rxErrors=0,rxPackets=0,txBytes=0,txDropped=0,txErrors=0,txPackets=0], eth1=com.github.dockerjava.api.model.StatisticNetworksConfig@8a2a6a[rxBytes=197752,rxDropped=0,rxErrors=0,rxPackets=836,txBytes=0,txDropped=0,txErrors=0,txPackets=0]},network=&amp;lt;null&amp;gt;,memoryStats=com.github.dockerjava.api.model.MemoryStatsConfig@772861aa,blkioStats=BlkioStatsConfig[ioServiceBytesRecursive=[BlkioStatEntry[major=8,minor=0,op=Read,value=8192], BlkioStatEntry[major=8,minor=0,op=Write,value=1259921408], BlkioStatEntry[major=8,minor=0,op=Sync,value=1258987520], BlkioStatEntry[major=8,minor=0,op=Async,value=942080], BlkioStatEntry[major=8,minor=0,op=Total,value=1259929600]],ioServicedRecursive=[BlkioStatEntry[major=8,minor=0,op=Read,value=2], BlkioStatEntry[major=8,minor=0,op=Write,value=4066], BlkioStatEntry[major=8,minor=0,op=Sync,value=4009], BlkioStatEntry[major=8,minor=0,op=Async,value=59], BlkioStatEntry[major=8,minor=0,op=Total,value=4068]],ioQueueRecursive=[],ioServiceTimeRecursive=[],ioWaitTimeRecursive=[],ioMergedRecursive=[],ioTimeRecursive=[],sectorsRecursive=[]],cpuStats=com.github.dockerjava.api.model.CpuStatsConfig@4cb40e3b,preCpuStats=com.github.dockerjava.api.model.CpuStatsConfig@41b1f51e,pidsStats=com.github.dockerjava.api.model.PidsStatsConfig@3a543f31]&lt;/code&gt;
&lt;/pre&gt;
&lt;hr/&gt;&lt;blockquote readability=&quot;7.3156342182891&quot;&gt;
&lt;p&gt;作者：Jadepeng&lt;br/&gt;出处：jqpeng的技术记事本--&lt;a href=&quot;http://www.cnblogs.com/xiaoqi&quot; class=&quot;uri&quot;&gt;http://www.cnblogs.com/xiaoqi&lt;/a&gt;&lt;br/&gt;您的支持是对博主最大的鼓励，感谢您的认真阅读。&lt;br/&gt;本文版权归作者所有，欢迎转载，但未经作者同意必须保留此段声明，且在文章页面明显位置给出原文连接，否则保留追究法律责任的权利。&lt;/p&gt;
&lt;/blockquote&gt;
</description>
<pubDate>Tue, 03 Sep 2019 00:48:00 +0000</pubDate>
<dc:creator>JadePeng</dc:creator>
<og:description>我们可以通过`docker service create`创建服务，但是服务创建好后，如何来获取该service包含的容器信息呢？比如获取刚才创建的mysql服务的容器。我们可以通过docker se</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/xiaoqi/p/docker-service-container.html</dc:identifier>
</item>
<item>
<title>session一致性的解决方案 - 全菜工程师小辉</title>
<link>http://www.cnblogs.com/mseddl/p/11450917.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/mseddl/p/11450917.html</guid>
<description>&lt;p&gt;更多内容，欢迎关注微信公众号：全菜工程师小辉。公众号回复关键词，领取免费学习资料。&lt;/p&gt;

&lt;p&gt;服务器为每个用户创建一个会话，存储用户的相关信息，以便多次请求能够定位到同一个上下文，这个相关信息就是session。这样，当用户在应用程序的Web页之间跳转时，存储在session对象中的变量将不会丢失，而是在整个用户会话中一直存在下去。&lt;/p&gt;
&lt;p&gt;session是对http无状态协议的补充，达到状态保持的目的&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1327889/201909/1327889-20190903084822752-282084013.png&quot; alt=&quot;session一致性问题&quot;/&gt;&lt;/p&gt;
&lt;p&gt;假设用户包含登录信息的session都记录在第一台server上，反向代理如果将请求路由到另一台server上，可能就找不到相关信息，而导致用户需要重新登录。&lt;/p&gt;

&lt;h2 id=&quot;客户端保存cookie&quot;&gt;1. 客户端保存cookie&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1327889/201909/1327889-20190903084822977-1692429687.png&quot; alt=&quot;基于cookie的会话管理&quot;/&gt;&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;服务端不需要存储&lt;/li&gt;
&lt;/ol&gt;&lt;ol&gt;&lt;li&gt;每次http请求都携带session，占网络带宽&lt;/li&gt;
&lt;li&gt;数据存储在客户端上，并在网络传输，存在泄漏、篡改等安全隐患&lt;/li&gt;
&lt;li&gt;session存储的数据大小受cookie限制&lt;/li&gt;
&lt;/ol&gt;&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;由于技术不断演进，客户端保存cookie出现了信息全量cookie，cookie存储sessionId和JWT三种方式，他们优缺点各异，可以点击笔者的另一篇博客查看相关介绍&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;a href=&quot;https://www.jianshu.com/p/750eff92d932&quot;&gt;快速了解会话管理三剑客cookie、session和JWT&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;session复制方法&quot;&gt;2. session复制方法&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1327889/201909/1327889-20190903084823166-733553527.png&quot; alt=&quot;session复制方法&quot;/&gt;&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;只需要设定配置，应用程序不需要修改代码&lt;/li&gt;
&lt;/ol&gt;&lt;ol&gt;&lt;li&gt;session的同步需要数据传输，占内网带宽，有延时&lt;/li&gt;
&lt;li&gt;所有server都包含所有session数据，数据量受最小内存的sever限制，水平拓展能力差&lt;/li&gt;
&lt;/ol&gt;&lt;h2 id=&quot;session中心存储&quot;&gt;3. session中心存储&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1327889/201909/1327889-20190903084823346-1301644452.png&quot; alt=&quot;session中心存储&quot;/&gt;&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;没有安全隐患&lt;/li&gt;
&lt;li&gt;可以水平扩展，支持缓存集群或横向拓展&lt;/li&gt;
&lt;/ol&gt;&lt;ol&gt;&lt;li&gt;增加了一次网络调用&lt;/li&gt;
&lt;li&gt;需要修改应用代码&lt;/li&gt;
&lt;/ol&gt;&lt;h2 id=&quot;session会话粘连&quot;&gt;4. session会话粘连&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1327889/201909/1327889-20190903084823767-702218849.png&quot; alt=&quot;session会话粘连&quot;/&gt;&lt;/p&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;session会话粘连：英文原词为&quot;Sticky Sessions&quot;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul readability=&quot;1.5&quot;&gt;&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;思路：&lt;br/&gt;反向代理层让同一个用户的请求保证落在一台server上呢？&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;方法一：四层代理hash。反向代理层使用用户ip来做hash，以保证同一个ip的请求落在同一个server上（更推荐，保证传输层不引入业务层的逻辑）&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;1&quot;&gt;
&lt;p&gt;方法二：七层代理hash。反向代理使用http协议中的某些业务属性来做hash，例如sid，city_id，user_id等，能够更加灵活的实施hash策略，以保证同一个浏览器用户的请求落在同一个server上&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;优点：&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;ol&gt;&lt;li&gt;只需要改nginx配置，不需要修改应用代码&lt;/li&gt;
&lt;li&gt;可以支持server水平扩展&lt;/li&gt;
&lt;/ol&gt;&lt;ol&gt;&lt;li&gt;server水平扩展，rehash后session重新分布，会有一部分用户路由不到正确的session&lt;/li&gt;
&lt;li&gt;即使hash散列均匀，也不能保证server的负载均匀&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;更多内容，欢迎关注微信公众号：全菜工程师小辉。公众号回复关键词，领取免费学习资料。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1327889/201909/1327889-20190903084823943-1103558960.gif&quot; alt=&quot;哎呀，如果我的名片丢了。微信搜索“全菜工程师小辉”，依然可以找到我&quot;/&gt;&lt;/p&gt;
</description>
<pubDate>Tue, 03 Sep 2019 00:48:00 +0000</pubDate>
<dc:creator>全菜工程师小辉</dc:creator>
<og:description>更多内容，欢迎关注微信公众号：全菜工程师小辉。公众号回复关键词，领取免费学习资料。 什么是session？ 服务器为每个用户创建一个会话，存储用户的相关信息，以便多次请求能够定位到同一个上下文，这个相</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/mseddl/p/11450917.html</dc:identifier>
</item>
<item>
<title>Spring Cloud Alibaba | Nacos动态网关路由 - 极客挖掘机</title>
<link>http://www.cnblogs.com/babycomeon/p/11450899.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/babycomeon/p/11450899.html</guid>
<description>&lt;blockquote readability=&quot;9&quot;&gt;
&lt;p&gt;本篇实战所使用Spring有关版本：&lt;/p&gt;
&lt;p&gt;SpringBoot:2.1.7.RELEASE&lt;/p&gt;
&lt;p&gt;Spring Cloud:Greenwich.SR2&lt;/p&gt;
&lt;p&gt;Spring CLoud Alibaba:2.1.0.RELEASE&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;前面几篇文章我们介绍了&lt;a href=&quot;http://www.geekdigging.com/2019/08/31/nacos-fu-wu-zhu-ce-yu-fa-xian/&quot;&gt;《Nacos服务注册与发现》&lt;/a&gt;和&lt;a href=&quot;http://www.geekdigging.com/2019/08/31/nacos-pei-zhi-guan-li/&quot;&gt;《Nacos配置管理》&lt;/a&gt;，还没看过的小伙伴们快去看一下，本篇文章是建立在这两篇文章基础上的一次实战。&lt;/p&gt;
&lt;h2 id=&quot;背景介绍&quot;&gt;背景介绍&lt;/h2&gt;
&lt;p&gt;在Spring Cloud微服务体系下，常用的服务网关有Netflix公司开源的Zuul，还有Spring Cloud团队自己开源的Spring Cloud Gateway，其中NetFlix公司开源的Zuul版本已经迭代至2.x，但是Spring Cloud并未集成，目前Spring Cloud集成的Spring Cloud Zuul还是Zuul1.x，这一版的Zuul是基于&lt;code&gt;Servlet&lt;/code&gt;构建的，采用的方案是阻塞式的多线程方案，即一个线程处理一次连接请求，这种方式在内部延迟严重、设备故障较多情况下会引起存活的连接增多和线程增加的情况发生。Spring Cloud自己开源的Spring Cloud Gateway则是基于&lt;code&gt;Spring Webflux&lt;/code&gt;来构建的，&lt;code&gt;Spring Webflux&lt;/code&gt;有一个全新的非堵塞的函数式 &lt;code&gt;Reactive Web&lt;/code&gt; 框架，可以用来构建异步的、非堵塞的、事件驱动的服务，在伸缩性方面表现非常好。使用非阻塞API， Websockets得到支持，并且由于它与Spring紧密集成，将会得到更好的开发体验。&lt;/p&gt;
&lt;p&gt;本文将基于Gateway服务网关来介绍如何使用Nacos的配置功能来实现服务网关动态路由。&lt;/p&gt;
&lt;h2 id=&quot;实现方案&quot;&gt;实现方案&lt;/h2&gt;
&lt;p&gt;在开始之前我们先介绍一下具体实现方式：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;路由信息不再配置在配置文件中，将路由信息配置在Nacos的配置中。&lt;/li&gt;
&lt;li&gt;在服务网关Spring Cloud Gateway中开启监听，监听Nacos配置文件的修改。&lt;/li&gt;
&lt;li&gt;Nacos配置文件一旦发生改变，则Spring Cloud Gateway重新刷新自己的路由信息。&lt;/li&gt;
&lt;/ol&gt;&lt;h2 id=&quot;环境准备&quot;&gt;环境准备&lt;/h2&gt;
&lt;p&gt;首先，需要准备一个Nacos服务，我这里的版本是使用的Nacos v1.1.3，如果不会配置Nacos服务的同学，请参考之前的文章&lt;a href=&quot;http://www.geekdigging.com/2019/08/31/nacos-fu-wu-zhong-xin-chu-tan/&quot;&gt;《Nacos服务中心初探》&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;工程实战&quot;&gt;工程实战&lt;/h2&gt;
&lt;p&gt;创建工程gateway-nacos-config，工程依赖pom.xml如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;&amp;lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&amp;gt;
&amp;lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;
         xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&amp;gt;
    &amp;lt;modelVersion&amp;gt;4.0.0&amp;lt;/modelVersion&amp;gt;
    &amp;lt;parent&amp;gt;
        &amp;lt;groupId&amp;gt;org.springframework.boot&amp;lt;/groupId&amp;gt;
        &amp;lt;artifactId&amp;gt;spring-boot-starter-parent&amp;lt;/artifactId&amp;gt;
        &amp;lt;version&amp;gt;2.1.7.RELEASE&amp;lt;/version&amp;gt;
        &amp;lt;relativePath/&amp;gt; &amp;lt;!-- lookup parent from repository --&amp;gt;
    &amp;lt;/parent&amp;gt;
    &amp;lt;groupId&amp;gt;com.springcloud.alibaba&amp;lt;/groupId&amp;gt;
    &amp;lt;artifactId&amp;gt;gateway-nacos-config&amp;lt;/artifactId&amp;gt;
    &amp;lt;version&amp;gt;0.0.1-SNAPSHOT&amp;lt;/version&amp;gt;
    &amp;lt;name&amp;gt;gateway-nacos-config&amp;lt;/name&amp;gt;
    &amp;lt;description&amp;gt;gateway-nacos-config&amp;lt;/description&amp;gt;

    &amp;lt;properties&amp;gt;
        &amp;lt;project.build.sourceEncoding&amp;gt;UTF-8&amp;lt;/project.build.sourceEncoding&amp;gt;
        &amp;lt;project.reporting.outputEncoding&amp;gt;UTF-8&amp;lt;/project.reporting.outputEncoding&amp;gt;
        &amp;lt;java.version&amp;gt;1.8&amp;lt;/java.version&amp;gt;
        &amp;lt;spring-cloud.version&amp;gt;Greenwich.SR2&amp;lt;/spring-cloud.version&amp;gt;
        &amp;lt;spring-cloud-alibaba.version&amp;gt;2.1.0.RELEASE&amp;lt;/spring-cloud-alibaba.version&amp;gt;
    &amp;lt;/properties&amp;gt;

    &amp;lt;dependencies&amp;gt;
        &amp;lt;dependency&amp;gt;
            &amp;lt;groupId&amp;gt;org.springframework.boot&amp;lt;/groupId&amp;gt;
            &amp;lt;artifactId&amp;gt;spring-boot-starter-actuator&amp;lt;/artifactId&amp;gt;
        &amp;lt;/dependency&amp;gt;
        &amp;lt;dependency&amp;gt;
            &amp;lt;groupId&amp;gt;org.springframework.boot&amp;lt;/groupId&amp;gt;
            &amp;lt;artifactId&amp;gt;spring-boot-starter-webflux&amp;lt;/artifactId&amp;gt;
        &amp;lt;/dependency&amp;gt;
        &amp;lt;dependency&amp;gt;
            &amp;lt;groupId&amp;gt;org.springframework.cloud&amp;lt;/groupId&amp;gt;
            &amp;lt;artifactId&amp;gt;spring-cloud-starter-gateway&amp;lt;/artifactId&amp;gt;
        &amp;lt;/dependency&amp;gt;
        &amp;lt;dependency&amp;gt;
            &amp;lt;groupId&amp;gt;com.alibaba.cloud&amp;lt;/groupId&amp;gt;
            &amp;lt;artifactId&amp;gt;spring-cloud-starter-alibaba-nacos-discovery&amp;lt;/artifactId&amp;gt;
        &amp;lt;/dependency&amp;gt;

        &amp;lt;dependency&amp;gt;
            &amp;lt;groupId&amp;gt;org.projectlombok&amp;lt;/groupId&amp;gt;
            &amp;lt;artifactId&amp;gt;lombok&amp;lt;/artifactId&amp;gt;
            &amp;lt;optional&amp;gt;true&amp;lt;/optional&amp;gt;
        &amp;lt;/dependency&amp;gt;
        &amp;lt;dependency&amp;gt;
            &amp;lt;groupId&amp;gt;org.springframework.boot&amp;lt;/groupId&amp;gt;
            &amp;lt;artifactId&amp;gt;spring-boot-starter-test&amp;lt;/artifactId&amp;gt;
            &amp;lt;scope&amp;gt;test&amp;lt;/scope&amp;gt;
        &amp;lt;/dependency&amp;gt;
        &amp;lt;dependency&amp;gt;
            &amp;lt;groupId&amp;gt;io.projectreactor&amp;lt;/groupId&amp;gt;
            &amp;lt;artifactId&amp;gt;reactor-test&amp;lt;/artifactId&amp;gt;
            &amp;lt;scope&amp;gt;test&amp;lt;/scope&amp;gt;
        &amp;lt;/dependency&amp;gt;
    &amp;lt;/dependencies&amp;gt;

    &amp;lt;dependencyManagement&amp;gt;
        &amp;lt;dependencies&amp;gt;
            &amp;lt;dependency&amp;gt;
                &amp;lt;groupId&amp;gt;org.springframework.cloud&amp;lt;/groupId&amp;gt;
                &amp;lt;artifactId&amp;gt;spring-cloud-dependencies&amp;lt;/artifactId&amp;gt;
                &amp;lt;version&amp;gt;${spring-cloud.version}&amp;lt;/version&amp;gt;
                &amp;lt;type&amp;gt;pom&amp;lt;/type&amp;gt;
                &amp;lt;scope&amp;gt;import&amp;lt;/scope&amp;gt;
            &amp;lt;/dependency&amp;gt;
            &amp;lt;dependency&amp;gt;
                &amp;lt;groupId&amp;gt;com.alibaba.cloud&amp;lt;/groupId&amp;gt;
                &amp;lt;artifactId&amp;gt;spring-cloud-alibaba-dependencies&amp;lt;/artifactId&amp;gt;
                &amp;lt;version&amp;gt;${spring-cloud-alibaba.version}&amp;lt;/version&amp;gt;
                &amp;lt;type&amp;gt;pom&amp;lt;/type&amp;gt;
                &amp;lt;scope&amp;gt;import&amp;lt;/scope&amp;gt;
            &amp;lt;/dependency&amp;gt;
        &amp;lt;/dependencies&amp;gt;
    &amp;lt;/dependencyManagement&amp;gt;

    &amp;lt;repositories&amp;gt;
        &amp;lt;repository&amp;gt;
            &amp;lt;id&amp;gt;spring-milestones&amp;lt;/id&amp;gt;
            &amp;lt;name&amp;gt;Spring Milestones&amp;lt;/name&amp;gt;
            &amp;lt;url&amp;gt;https://repo.spring.io/libs-milestone&amp;lt;/url&amp;gt;
            &amp;lt;snapshots&amp;gt;
                &amp;lt;enabled&amp;gt;false&amp;lt;/enabled&amp;gt;
            &amp;lt;/snapshots&amp;gt;
        &amp;lt;/repository&amp;gt;
    &amp;lt;/repositories&amp;gt;

    &amp;lt;build&amp;gt;
        &amp;lt;plugins&amp;gt;
            &amp;lt;plugin&amp;gt;
                &amp;lt;groupId&amp;gt;org.springframework.boot&amp;lt;/groupId&amp;gt;
                &amp;lt;artifactId&amp;gt;spring-boot-maven-plugin&amp;lt;/artifactId&amp;gt;
            &amp;lt;/plugin&amp;gt;
        &amp;lt;/plugins&amp;gt;
    &amp;lt;/build&amp;gt;

&amp;lt;/project&amp;gt;
&lt;/code&gt;
&lt;/pre&gt;
&lt;ul&gt;&lt;li&gt;在使用Spring Cloud Alibaba组件的时候，在&lt;code&gt;&amp;lt;dependencyManagement&amp;gt;&lt;/code&gt;中需配置&lt;code&gt;spring-cloud-alibaba-dependencies&lt;/code&gt;，它管理了Spring Cloud Alibaba组件的版本依赖。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;配置文件application.yml如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;server:
  port: 8080
spring:
  application:
    name: spring-cloud-gateway-server
  cloud:
    nacos:
      discovery:
        server-addr: 192.168.44.129:8848
management:
  endpoints:
    web:
      exposure:
        include: '*'&lt;/code&gt;
&lt;/pre&gt;
&lt;ul&gt;&lt;li&gt;&lt;code&gt;spring.cloud.nacos.discovery.server-addr&lt;/code&gt;：配置为Nacos服务地址，格式为ip:port&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;接下来进入核心部分，配置Spring Cloud Gateway动态路由，这里需要实现一个Spring提供的事件推送接口&lt;code&gt;ApplicationEventPublisherAware&lt;/code&gt;，代码如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;@Component
public class DynamicRoutingConfig implements ApplicationEventPublisherAware {

    private final Logger logger = LoggerFactory.getLogger(DynamicRoutingConfig.class);

    private static final String DATA_ID = &quot;zuul-refresh-dev.json&quot;;
    private static final String Group = &quot;DEFAULT_GROUP&quot;;

    @Autowired
    private RouteDefinitionWriter routeDefinitionWriter;

    private ApplicationEventPublisher applicationEventPublisher;

    @Bean
    public void refreshRouting() throws NacosException {
        Properties properties = new Properties();
        properties.put(PropertyKeyConst.SERVER_ADDR, &quot;192.168.44.129:8848&quot;);
        properties.put(PropertyKeyConst.NAMESPACE, &quot;8282c713-da90-486a-8438-2a5a212ef44f&quot;);
        ConfigService configService = NacosFactory.createConfigService(properties);
        configService.addListener(DATA_ID, Group, new Listener() {
            @Override
            public Executor getExecutor() {
                return null;
            }

            @Override
            public void receiveConfigInfo(String configInfo) {
                logger.info(configInfo);

                boolean refreshGatewayRoute = JSONObject.parseObject(configInfo).getBoolean(&quot;refreshGatewayRoute&quot;);

                if (refreshGatewayRoute) {
                    List&amp;lt;RouteEntity&amp;gt; list = JSON.parseArray(JSONObject.parseObject(configInfo).getString(&quot;routeList&quot;)).toJavaList(RouteEntity.class);

                    for (RouteEntity route : list) {
                        update(assembleRouteDefinition(route));
                    }
                } else {
                    logger.info(&quot;路由未发生变更&quot;);
                }


            }
        });
    }

    @Override
    public void setApplicationEventPublisher(ApplicationEventPublisher applicationEventPublisher) {
        this.applicationEventPublisher = applicationEventPublisher;
    }

    /**
     * 路由更新
     * @param routeDefinition
     * @return
     */
    public void update(RouteDefinition routeDefinition){

        try {
            this.routeDefinitionWriter.delete(Mono.just(routeDefinition.getId()));
            logger.info(&quot;路由更新成功&quot;);
        }catch (Exception e){
            logger.error(e.getMessage(), e);
        }

        try {
            routeDefinitionWriter.save(Mono.just(routeDefinition)).subscribe();
            this.applicationEventPublisher.publishEvent(new RefreshRoutesEvent(this));
            logger.info(&quot;路由更新成功&quot;);
        }catch (Exception e){
            logger.error(e.getMessage(), e);
        }
    }

    public RouteDefinition assembleRouteDefinition(RouteEntity routeEntity) {

        RouteDefinition definition = new RouteDefinition();

        // ID
        definition.setId(routeEntity.getId());

        // Predicates
        List&amp;lt;PredicateDefinition&amp;gt; pdList = new ArrayList&amp;lt;&amp;gt;();
        for (PredicateEntity predicateEntity: routeEntity.getPredicates()) {
            PredicateDefinition predicateDefinition = new PredicateDefinition();
            predicateDefinition.setArgs(predicateEntity.getArgs());
            predicateDefinition.setName(predicateEntity.getName());
            pdList.add(predicateDefinition);
        }
        definition.setPredicates(pdList);

        // Filters
        List&amp;lt;FilterDefinition&amp;gt; fdList = new ArrayList&amp;lt;&amp;gt;();
        for (FilterEntity filterEntity: routeEntity.getFilters()) {
            FilterDefinition filterDefinition = new FilterDefinition();
            filterDefinition.setArgs(filterEntity.getArgs());
            filterDefinition.setName(filterEntity.getName());
            fdList.add(filterDefinition);
        }
        definition.setFilters(fdList);

        // URI
        URI uri = UriComponentsBuilder.fromUriString(routeEntity.getUri()).build().toUri();
        definition.setUri(uri);

        return definition;
    }
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;这里主要介绍一下&lt;code&gt;refreshRouting()&lt;/code&gt;这个方法，这个方法主要负责监听Nacos的配置变化，这里先使用参数构建一个&lt;code&gt;ConfigService&lt;/code&gt;，再使用&lt;code&gt;ConfigService&lt;/code&gt;开启一个监听，并且在监听的方法中刷新路由信息。&lt;/p&gt;
&lt;p&gt;Nacos配置如图：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/908359/201909/908359-20190903084402428-840675255.png&quot; alt=&quot;Nacos配置&quot;/&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;{
    &quot;refreshGatewayRoute&quot;:false,
    &quot;routeList&quot;:[
        {
            &quot;id&quot;:&quot;github_route&quot;,
            &quot;predicates&quot;:[
                {
                    &quot;name&quot;:&quot;Path&quot;,
                    &quot;args&quot;:{
                        &quot;_genkey_0&quot;:&quot;/meteor1993&quot;
                    }
                }
            ],
            &quot;filters&quot;:[

            ],
            &quot;uri&quot;:&quot;https://github.com&quot;,
            &quot;order&quot;:0
        }
    ]
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;配置格式选择JSON，Data ID和Group与程序中的配置保持一致，注意，我这里的程序配置了namespace，如果使用默认namespace，可以不用配置。&lt;/p&gt;
&lt;p&gt;这里配置了一个路由&lt;code&gt;/meteor1993&lt;/code&gt;，直接访问这个路由会访问到作者的Github仓库。&lt;/p&gt;
&lt;p&gt;剩余部分的代码这里就不一一展示了，已经上传至代码仓库，有需要的同学可以自行取用。&lt;/p&gt;
&lt;h2 id=&quot;测试&quot;&gt;测试&lt;/h2&gt;
&lt;p&gt;启动工程，这时是没有任何路由信息的，打开浏览器访问：http://localhost:8080/meteor1993 ，页面返回404报错信息，如图：&lt;/p&gt;
&lt;p&gt;同时，也可以访问链接：http://localhost:8080/actuator/gateway/routes ，可以看到如下打印：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;[]&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;打开在Nacos Server端的UI界面，选择监听查询，选择namespace为&lt;code&gt;springclouddev&lt;/code&gt;的栏目，输入DATA_ID为&lt;code&gt;zuul-refresh-dev.json&lt;/code&gt;和Group为&lt;code&gt;DEFAULT_GROUP&lt;/code&gt;，点击查询，可以看到我们启动的工程gateway-nacos-config正在监听Nacos Server端，如图：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/908359/201909/908359-20190903084402655-469185357.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;笔者这里的本地ip为：192.168.44.1。监听正常，这时，我们修改刚才创建的配置，将里面的&lt;code&gt;refreshGatewayRoute&lt;/code&gt;修改为&lt;code&gt;true&lt;/code&gt;，如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;{&quot;refreshGatewayRoute&quot;: true, &quot;routeList&quot;:[{&quot;id&quot;:&quot;github_route&quot;,&quot;predicates&quot;:[{&quot;name&quot;:&quot;Path&quot;,&quot;args&quot;:{&quot;_genkey_0&quot;:&quot;/meteor1993&quot;}}],&quot;filters&quot;:[],&quot;uri&quot;:&quot;https://github.com&quot;,&quot;order&quot;:0}]}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;点击发布，可以看到工程gateway-nacos-config的控制台打印日志如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;2019-09-02 22:09:49.254  INFO 8056 --- [38-2a5a212ef44f] c.s.a.g.config.DynamicRoutingConfig      : {
    &quot;refreshGatewayRoute&quot;:true,
    &quot;routeList&quot;:[
        {
            &quot;id&quot;:&quot;github_route&quot;,
            &quot;predicates&quot;:[
                {
                    &quot;name&quot;:&quot;Path&quot;,
                    &quot;args&quot;:{
                        &quot;_genkey_0&quot;:&quot;/meteor1993&quot;
                    }
                }
            ],
            &quot;filters&quot;:[

            ],
            &quot;uri&quot;:&quot;https://github.com&quot;,
            &quot;order&quot;:0
        }
    ]
}
2019-09-02 22:09:49.268  INFO 8056 --- [38-2a5a212ef44f] c.s.a.g.config.DynamicRoutingConfig      : 路由更新成功&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;这时，我们的工程gateway-nacos-config的路由已经更新成功，访问路径：http://localhost:8080/actuator/gateway/routes ，可以看到如下打印：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;[{&quot;route_id&quot;:&quot;github_route&quot;,&quot;route_definition&quot;:{&quot;id&quot;:&quot;github_route&quot;,&quot;predicates&quot;:[{&quot;name&quot;:&quot;Path&quot;,&quot;args&quot;:{&quot;_genkey_0&quot;:&quot;/meteor1993&quot;}}],&quot;filters&quot;:[],&quot;uri&quot;:&quot;https://github.com&quot;,&quot;order&quot;:0},&quot;order&quot;:0}]&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;我们再次在浏览器中访问链接：http://localhost:8080/meteor1993 ，可以看到页面正常路由到Github仓库，如图：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/908359/201909/908359-20190903084403326-1905296067.png&quot;/&gt;&lt;/p&gt;
&lt;h2 id=&quot;总结&quot;&gt;总结&lt;/h2&gt;
&lt;p&gt;至此，Nacos动态网关路由就介绍完了，主要运用了服务网关端监听Nacos配置改变的功能，实现服务网关路由配置动态刷新，同理，我们也可以使用服务网关Zuul来实现基于Nacos的动态路由功能。&lt;/p&gt;
&lt;p&gt;基于这个思路，我们可以使用配置中心来实现网关的动态路由，而不是使用服务网关本身自带的配置文件，这样每次路由信息变更，无需修改配置文件而后重启服务。&lt;/p&gt;
&lt;p&gt;目前市面上使用比较多的配置中心有携程开源的Apollo，服务网关还有Spring Cloud Zuul，下一篇文章我们介绍如何使用Apollo来实现Spring Cloud Zuul的动态路由。&lt;/p&gt;
&lt;h2 id=&quot;示例代码&quot;&gt;示例代码&lt;/h2&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/meteor1993/SpringCloudLearning/tree/master/Alibaba/gateway-nacos-config&quot;&gt;Github-示例代码&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://gitee.com/inwsy/SpringCloudLearning/tree/master/Alibaba/gateway-nacos-config&quot;&gt;Gitee-示例代码&lt;/a&gt;&lt;/p&gt;
</description>
<pubDate>Tue, 03 Sep 2019 00:44:00 +0000</pubDate>
<dc:creator>极客挖掘机</dc:creator>
<og:description>Spring Cloud Alibaba | Gateway基于Nacos动态网关路由 本篇实战所使用Spring有关版本： SpringBoot:2.1.7.RELEASE Spring Cloud</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/babycomeon/p/11450899.html</dc:identifier>
</item>
<item>
<title>学并发编程，透彻理解这三个核心是关键 - tan日拱一兵</title>
<link>http://www.cnblogs.com/FraserYu/p/11450892.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/FraserYu/p/11450892.html</guid>
<description>&lt;h2 id=&quot;写在前面&quot;&gt;写在前面&lt;/h2&gt;
&lt;p&gt;上一篇文章&lt;a href=&quot;https://mp.weixin.qq.com/s/I53l5W_Wl-lMc-_FAeJ6WQ&quot;&gt;这次走进并发的世界，请不要错过&lt;/a&gt; 给大家带了并发编程的开胃菜，接下来我们逐步上正餐，在吃正餐之前，我还要引用那首诗词: 「横看成岭侧成峰，远近高低各不同」，远看看轮廓，近看看细节，不断切换思维或视角来学习&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1583165/201909/1583165-20190903083929900-772639219.jpg&quot;/&gt;&lt;/p&gt;
&lt;p&gt;远看并发，&lt;strong&gt;并发编程可以抽象成三个核心问题: 分工、同步/协作、互斥&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;如果你已经工作了，那么你一定听说过或者正在应用敏捷开发模式来交付日常的工作任务，我们就用你熟悉的流程来解释这三个核心问题&lt;/p&gt;
&lt;h2 id=&quot;分工&quot;&gt;分工&lt;/h2&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;将当前 Sprint 的 Story 拆分成「合适」大小的 Task，并且安排给「合适」的 Team Member 去完成&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;这里面用了两个「合适」，将 Story 拆分成大小适中，可完成的 Task 是非常重要的。拆分的粒度太粗，导致这个任务完成难度变高，耗时长，不易与其他人配合；拆分的粒度太细，又导致任务太多，不好管理与追踪，浪费精力和资源。(&lt;strong&gt;合适的线程才能更好的完成整块工作，当然一个线程可以轻松搞定的就没必要多线程&lt;/strong&gt;)；安排给合适的人员去完成同样重要，UX-UE 问题交给后端人员处理，很显然是有问题的 (&lt;strong&gt;主线程应该做的事交给子线程显然是解决不了问题的，每个线程做正确的事才能发挥作用&lt;/strong&gt;)&lt;/p&gt;
&lt;p&gt;关于分工，常见的 Executor，生产者-消费者模式，Fork/Join 等，这都是分工思想的体现&lt;/p&gt;
&lt;h2 id=&quot;同步协作&quot;&gt;同步/协作&lt;/h2&gt;
&lt;p&gt;任务拆分完毕，我要等张三的任务，张三要等李四的任务，也就是说任务之间存在依赖关系，前面的任务执行完毕，后面的任务才可以执行，人高级在可以通过沟通反复确认，确保自己的任务可以开始执行。&lt;strong&gt;但面对程序，我们需要了解程序的沟通方式，一个线程执行完任务，如何通知后续线程执行&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;所有的同步/协作关系我们都可以用你最熟悉的 If-then-else 来表示:&lt;/p&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;if(前序任务完成){
    execute();
}else{
    wait();
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;上面的代码就是说:&lt;strong&gt;当某个条件不满足时，线程需要等待；当某个条件满足时，线程需要被唤醒执行&lt;/strong&gt;，线程之间的协作可能是主线程与子线程的协作，可能是子线程与子线程的合作， Java SDK 中 CountDownLatch 和 CyclicBarrier 就是用来解决线程协作问题的&lt;/p&gt;
&lt;h2 id=&quot;互斥&quot;&gt;互斥&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;分工和同步强调的是性能，但是互斥是强调正确性&lt;/strong&gt;，就是我们常常提到的「线程安全」，当多个线程&lt;strong&gt;同时&lt;/strong&gt;访问一个共享变量/成员变量时，就可能发生不确定性，造成不确定性主要是有&lt;code&gt;可见性&lt;/code&gt;、&lt;code&gt;原子性&lt;/code&gt;、&lt;code&gt;有序性&lt;/code&gt;这三大问题，而解决这些问题的核心就是互斥&lt;/p&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;h3 id=&quot;互斥-1&quot;&gt;互斥&lt;/h3&gt;
&lt;p&gt;同一时刻，只允许一个线程访问共享变量&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;来看下图，主干路就是共享变量，进入主干路一次只能有一辆车，这样你是否理解了呢？「&lt;strong&gt;天下大事，分久必合&lt;/strong&gt;」&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1583165/201909/1583165-20190903083931407-1735364083.gif&quot;/&gt;&lt;/p&gt;
&lt;p&gt;同样 Java SDK 也有很多互斥的解决方案，比如你马上就能想到 synchronized 关键字，Lock，ThreadLocal 等就是互斥的解决方案&lt;/p&gt;
&lt;h2 id=&quot;总结&quot;&gt;总结&lt;/h2&gt;
&lt;p&gt;资本家疯狂榨取劳动工人的剩余价值，获得最大收益。当你面对 CPU，内存，IO 这些劳动工人时，你就是那个资本家，你要思考如何&lt;code&gt;充分榨取&lt;/code&gt;它们的价值&lt;/p&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;当一个工人能干的活，绝不让两个人来干(单线程能满足就没必要为了多线程)&lt;br/&gt;当多个工人干活时，就要让他们分工明确，合作顺畅，没矛盾&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;当任务很大时，由于 IO 干活慢，CPU 干活快，就没必要让 CPU 死等当前的 IO，转而去执行其他指令，这就是&lt;code&gt;榨取剩余价值&lt;/code&gt;，如何最大限度的榨取其价值，这就涉及到后续的调优问题，比如多少线程合适等&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;分工是设计，同步和互斥是实现&lt;/strong&gt;，没有好的设计也就没有好的实现，所以在分工阶段，强烈建议大家勾划草图，了解瓶颈所在，这样才会有更好的实现，后续章节的内容，我也会带领大家画草图，分析问题，逐步养成这个习惯&lt;/p&gt;
&lt;p&gt;本章内容可以用下面的图来简单概括，叶子结点的内容我们会逐步点亮，现阶段不用过分关注(如果你上来就啃 JDK 源码，也许你会痛苦的迷失，并最终放弃你的进阶之路的)&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1583165/201909/1583165-20190903083934220-756106057.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;理解三大核心问题，你要充分结合生活中的实际，程序中的并发问题，基本上都能在实际生活中找得到原型&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;下一篇文章的内容，我们就要聊聊，引起线程安全的三个问题:「可见性，原子性，有序性」，这涉及到 JMM 的一点内容，可以提前了解一下的，这样我们才能更好的碰撞&lt;/p&gt;
&lt;h2 id=&quot;灵魂追问&quot;&gt;灵魂追问&lt;/h2&gt;
&lt;ol&gt;&lt;li&gt;工作中多线程编程的场景多吗？&lt;/li&gt;
&lt;li&gt;想到多线程，只会想到 synchronized 吗？&lt;/li&gt;
&lt;li&gt;Java 并发包各个类，你有了解底层实现和设计理念吗？&lt;/li&gt;
&lt;/ol&gt;&lt;h2 id=&quot;提高效率工具&quot;&gt;提高效率工具&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1583165/201909/1583165-20190903083934764-383093853.png&quot;/&gt;&lt;/p&gt;
&lt;hr/&gt;&lt;h2 id=&quot;推荐阅读&quot;&gt;推荐阅读&lt;/h2&gt;
&lt;hr/&gt;&lt;blockquote&gt;
&lt;h3 id=&quot;欢迎持续关注公众号日拱一兵&quot;&gt;欢迎持续关注公众号：「日拱一兵」&lt;/h3&gt;
&lt;ul&gt;&lt;li&gt;前沿 Java 技术干货分享&lt;/li&gt;
&lt;li&gt;高效工具汇总 | 回复「工具」&lt;/li&gt;
&lt;li&gt;面试问题分析与解答&lt;/li&gt;
&lt;li&gt;技术资料领取 | 回复「资料」&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;blockquote readability=&quot;7&quot;&gt;
&lt;p&gt;以读侦探小说思维轻松趣味学习 Java 技术栈相关知识，本着将复杂问题简单化，抽象问题具体化和图形化原则逐步分解技术问题，技术持续更新，请持续关注......&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1583165/201909/1583165-20190903083936095-587875761.png&quot;/&gt;&lt;/p&gt;
</description>
<pubDate>Tue, 03 Sep 2019 00:40:00 +0000</pubDate>
<dc:creator>tan日拱一兵</dc:creator>
<og:description>写在前面 上一篇文章 '这次走进并发的世界，请不要错过' 给大家带了并发编程的开胃菜，接下来我们逐步上正餐，在吃正餐之前，我还要引用那首诗词: 「横看成岭侧成峰，远近高低各不同」，远看看轮廓，近看看细</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/FraserYu/p/11450892.html</dc:identifier>
</item>
<item>
<title>持续集成高级篇之Jenkins cli与Jenkins ssh - 周国通</title>
<link>http://www.cnblogs.com/tylerzhou/p/11450853.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/tylerzhou/p/11450853.html</guid>
<description>&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&quot;https://www.cnblogs.com/tylerzhou/p/11204826.html&quot;&gt;系列目录&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Jenkins Cli为Jenkins提供的一个cli工具,此工具功能非常强大,可以完成诸如重启jenkins,创建/删除job,查看job控制台输出,添加/删除节点等功能.但是实际工作中,像创建任务这样的配置显然cli非常吃力,不如直接在web管理界面操作,但是对于重启Jenkins,查看诊断信息等,执行一个手动构建任务等,则直接使用cli比进入web管理界面操作更加方便.因此什么时候web管理界面,什么时候使用cli,要看是否有利于提升生产力,是否有利于提升个人能力,是否有利于提升团队的自动化作业水平这些指标,不要以为使用cli就代表水平高而盲目使用cli从而导致效率下降或者问题增多.&lt;/p&gt;
&lt;p&gt;jenkins cli可以通过jenkins提供的jar包来创建一个cli环境或者使用ssh客户端来执行cli,本节也会分别介绍它们.&lt;/p&gt;
&lt;h2 id=&quot;使用jenkins自身客户端来执行cli&quot;&gt;使用jenkins自身客户端来执行cli&lt;/h2&gt;
&lt;p&gt;我们打开jenkins的安装目录,进入到&lt;code&gt;war\WEB-INF&lt;/code&gt;目录,此目录下面有一个&lt;code&gt;jenkins-cli.jar&lt;/code&gt;文件,它便是用来创建jenkins cli环境的.我们在这个目录下打开命令行工具,然后执行&lt;code&gt;java -jar jenkins-cli.jar help&lt;/code&gt;便可以看到它的输出帮助信息&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/811801/201909/811801-20190903080649968-958024111.png&quot; alt=&quot;img&quot;/&gt;&lt;/p&gt;
&lt;p&gt;可以看到-s选项可以指定一个url,这个url就是jenkins web管理界面的url,现在是测试环境,url为&lt;code&gt;http://localhost:8080&lt;/code&gt;,当然想要执行cli,还需要输入你的用户名和密码,这里通过 -auth选项指定用户名密码.&lt;/p&gt;
&lt;p&gt;我们把上以信息综合起来,组成以下命令&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;java -jar jenkins-cli.jar -s http://localhost:8080 -auth tylerzhou:密码 help&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;以上语句中,help为要执行的命令.&lt;/p&gt;
&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;需要注意的是,这里执行的命令直接是命令名称,不能加像其它命令行工具&lt;code&gt;- -- 或/&lt;/code&gt;标识&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;如果你找不到Jenkins-cli.jar,可以通过在浏览器输入&lt;code&gt;http://localhost:8080/jnlpJars/jenkins-cli.jar&lt;/code&gt;进行下载保存,注意把以上地址替换为您的实际地址&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;点击回车,可以看到所有Jenkins cli可执行的命令和命令的简短描述.下面介绍几个可能比较常用的命令&lt;/p&gt;
&lt;p&gt;1) list-jobs,可以列出Jenkins里所有的job,就像打开jenkins web管理界面首页看到的那样.&lt;/p&gt;
&lt;p&gt;命令如下&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;java -jar jenkins-cli.jar -s http://localhost:8080 -auth 您的账户:您的密码 list-jobs&lt;/code&gt;
&lt;/pre&gt;
&lt;blockquote readability=&quot;9&quot;&gt;
&lt;p&gt;需要注意的是,Jenkins cli需要每次执行命令的时候都带上&lt;code&gt;java -jar jenkins-cli.jar -s http://localhost:8080 -auth 您的账户:您的密码&lt;/code&gt;+要执行的命令,而不是进入一个环境后只输入命令就行了.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;2) build+要构建的job名,即可通过cli来触发一次构建.&lt;/p&gt;
&lt;p&gt;构建成功后,我们打开web管理界面便可以看到多一次构建.&lt;/p&gt;
&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;cli构建命令是一个非常实用的命令,虽然我们的大部分任务都是基于git的一个自动化流程.但是有些时候也需要手动执行一些脚本来完成工作中的一些自动化操作.如果每次打开web管理界面手动执行显然不如通过cli来执行效率高.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;3) restart/safe-restart 可以重启jenkins服务,通过它们的名称可以看到safe-restart为安全重启,它会等到所有的操作都完成然后执行重启&lt;/p&gt;
&lt;p&gt;4) clear-queue 清除构建队列.没有实际jenkins使用经验的朋友可能不知道,由于Jenkins自身原因或者我们脚本测试不够充分导致的bug,有时候会造成Jenkins构建阻塞,一直处于构建状态无法完成,这时候通过web管理界面点击取消构建也无法取消掉.此时呆以尝试这个命令.当然也可能仍然无法终止,此时需要使用restart命令暴力重启服务.&lt;/p&gt;
&lt;h2 id=&quot;使用api-token登陆&quot;&gt;使用api token登陆&lt;/h2&gt;
&lt;p&gt;以上我们都是通过用户名:密码的方式来登陆cli,这样把明文密码暴露出来是不可取的,其实Jenkins cli还可以通过&lt;code&gt;用户名:apitoken&lt;/code&gt;的方式来实现登陆cli.下面我们介绍五如何设置api token.&lt;/p&gt;
&lt;p&gt;我们打开jenkins web管理界面,点击左侧的&lt;code&gt;People&lt;/code&gt;按钮,在出现的界面中会列出可能不止一个用户,此时点击自身登陆jenkins的用户名,在进入的界面中点击&lt;code&gt;configure&lt;/code&gt;按钮,在出现的界面中找到&lt;code&gt;Api token&lt;/code&gt;栏&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/811801/201909/811801-20190903080644362-827727163.png&quot; alt=&quot;img&quot;/&gt;&lt;/p&gt;
&lt;p&gt;点击&lt;code&gt;Add new token&lt;/code&gt;便会出现一个生成token的小界面,输入token的名称,可以是任意名称,然后点击generate,这时候就会生成一个token&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/811801/201909/811801-20190903080638510-1383143290.png&quot; alt=&quot;img&quot;/&gt;&lt;/p&gt;
&lt;blockquote readability=&quot;7&quot;&gt;
&lt;p&gt;注意一定要把这个token复制下来然后保存到其它地方,下次再找开的时候就看不到它了.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;完成后点击保存.&lt;/p&gt;
&lt;p&gt;此时我们在cli中输入以下命令&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;java -jar jenkins-cli.jar -s http://localhost:8080 -auth tylerzhou:11f52cef1324556a41d966083ffcf0ac1b&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;其中tylerhzou为用户名,后面就是我们刚才创建的token&lt;/p&gt;
&lt;p&gt;如果执行成功,以上命令就输出jenkins cli的所有命令.&lt;/p&gt;
&lt;h3 id=&quot;把命令信息保存到单独文件&quot;&gt;把命令信息保存到单独文件&lt;/h3&gt;
&lt;p&gt;我们可以看到,使用token的方式登陆会导致命令行非常长,严重影响命令可读性,其实我们可以把auth信息保存到一个文件文件里.我在&lt;code&gt;Jenkins安装目录/war/WEB-INF&lt;/code&gt;目录下创建了一个名为&lt;code&gt;password.txt&lt;/code&gt;的文本文件,内容如下&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;tylerzhou:11f52cef1324556a41d966083ffcf0ac1b&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;也即上面auth里输入的用户名:apitoken&lt;/p&gt;
&lt;p&gt;这时我们在-auth选项里 通过指定@文件名方式指定包含用户名(密码或token)的文件来实现登陆.&lt;/p&gt;
&lt;p&gt;代码如下&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;java -jar jenkins-cli.jar -s http://localhost:8080 -auth @password.txt&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;以上@后面的password.txt即为我们创建的密码文件&lt;/p&gt;
&lt;h2 id=&quot;ssh方式登陆jenkins执行cli&quot;&gt;SSH方式登陆Jenkins执行cli&lt;/h2&gt;
&lt;p&gt;使用SSH方式登陆Jenkins需要进行配置,默认情况下jenkins SSHD port使用的是一个随机端口号,这样显然不利于ssh登陆,使用ssh登陆我们需要显式知道端口号是多少.我们打开&lt;code&gt;Manage jenkins&amp;gt;Configure Global Security&lt;/code&gt;找到&lt;code&gt;SSH Server&lt;/code&gt;栏,把默认random选项切为&lt;code&gt;fixed&lt;/code&gt;然后输入一个同用端口号,我使用的是&lt;code&gt;16022&lt;/code&gt;配置完成后点击保存.端口配置好了,我们还需要添加公钥到当前用户配置项,请参照上面&lt;code&gt;使用api token登陆&lt;/code&gt;一节,进入到当前用户设置界面,这次我们不配置apitoken,而是往下拉找到&lt;code&gt;SSH Public Keys&lt;/code&gt;选项,把我们生成的ssh公钥复制到这里.关于生成ssh key请参阅其它资料或者前面章节,这里不再赘述.&lt;/p&gt;
&lt;p&gt;完成以后,我们就可以通过ssh方式执行命令了.&lt;/p&gt;
&lt;p&gt;输入以下命令&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;ssh -l tylerzhou -p 16022 localhost help&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;其中-l指定的用户为我们登陆jenkins时的账户.&lt;br/&gt;如果配置成功,以上命令就会列出所有的Jenkins 命令和简短介绍.&lt;/p&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;ssh执行的命令和上面通过&lt;code&gt;jenkins-cli.jar&lt;/code&gt;执行的命令是一样,可以互相参照.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;对jenkins-cli进行简单封装&quot;&gt;对jenkins cli进行简单封装&lt;/h2&gt;
&lt;h3 id=&quot;使用bat简单封装&quot;&gt;使用bat简单封装&lt;/h3&gt;
&lt;p&gt;可以看到,以上执行cli不论是通过工具还是ssh,每次都需要带上一些固定的登陆信息,非常烦,我们可以进行一下简单的封装,这样每次只需要输入命令,不再需要每次重复输入固定内容&lt;/p&gt;
&lt;p&gt;我们把它封装成个bat命令,命令如下&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;@echo off
cls
:start
set /p arg=&quot;请输入您的命令: &quot;
java -jar jenkins-cli.jar -s http://localhost:8080 -auth @password.txt %arg%
goto start&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;以上命令产首先创建一个start标签,然后提示用户输入命令,输入以后传到的jenkins cli工具里,然后执行goto语句跳到start标签.以上命令会重复执行,想要终止需要按下ctrl+c来终止&lt;/p&gt;
&lt;h3 id=&quot;使用powershell脚本进行封装&quot;&gt;使用powershell脚本进行封装&lt;/h3&gt;
&lt;p&gt;由于笔者对bat不是很熟练,因此写起复杂脚本感觉比较费劲,这里使用powershell进行一下封装,支持清屏,查看执行状态和退出选项,脚本内容如下&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;[System.Console]::ForegroundColor=[System.ConsoleColor]::Green
 $writeout= 
  &quot;  退出请按1或者输入exit
  清屏请按2或者输入cls或者clear
  查看执行状态请按3
  查看帮助请输入help
  查看提示信息请按4&quot;
  Write-Host $writeout
[System.Console]::ForegroundColor=[System.ConsoleColor]::White

while ($true) {
$myvar=Read-Host &quot;请输入命令 &quot;
if(($myvar -eq 1)-or($myvar -eq &quot;exit&quot;)){break}
elseif (($myval -eq 2) -or ($myvar -eq &quot;cls&quot;) -or($myvar -eq &quot;clear&quot;)) {
    Clear-Host
}
elseif ($myvar -eq 3) {
    if($LASTEXITCODE -eq 0){
      Write-Host &quot;执行成功&quot;
    }else{
        [System.Console]::ForegroundColor=[System.ConsoleColor]::Red
        Write-Host &quot;执行失败&quot;
        [System.Console]::ForegroundColor=[System.ConsoleColor]::White
    }
}
elseif($myvar -eq 4){
[System.Console]::ForegroundColor=[System.ConsoleColor]::Green
Write-Host $writeout
[System.Console]::ForegroundColor=[System.ConsoleColor]::White
}
else {
   java -jar jenkins-cli.jar -s http://localhost:8080 -ssh -user tylerzhou $myvar.split(&quot; &quot;)
}
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;大家创建一个ps1文件,把以上内容复制进去然后按提示操作,便可以执行脚本了.&lt;/p&gt;
&lt;h2 id=&quot;windows-没有ssh客户端的问题&quot;&gt;windows 没有ssh客户端的问题&lt;/h2&gt;
&lt;p&gt;有些童鞋在跟着做上面的ssh方式登陆时,可能在命令行输入ssh会提示找不到命令,这是因为只有最新版本的windows 10(不是所有的版本都有).幸运的是,&lt;code&gt;Jenkins-cli.jar&lt;/code&gt;也提供了ssh登陆方式.我们输入以下命令&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;java -jar jenkins-cli.jar -s http://localhost:8080 -ssh -user tylerzhou help&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;通过以上方式指定ssh方式登陆,并指定-user,不需要指定端口,便可以使用ssh方式连接了.我们可以使用上面讲到的封闭方法简单的封闭一下,这样就不用每次都输入重复的,固定的内容了.&lt;/p&gt;
</description>
<pubDate>Tue, 03 Sep 2019 00:09:00 +0000</pubDate>
<dc:creator>周国通</dc:creator>
<og:description>'系列目录' Jenkins Cli介绍 Jenkins Cli为Jenkins提供的一个cli工具,此工具功能非常强大,可以完成诸如重启jenkins,创建/删除job,查看job控制台输出,添加/</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/tylerzhou/p/11450853.html</dc:identifier>
</item>
<item>
<title>你为什么成为一名程序员？ - 沉默王二</title>
<link>http://www.cnblogs.com/qing-gee/p/11450851.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/qing-gee/p/11450851.html</guid>
<description>&lt;p&gt;兄弟姐妹们，还记得自己成为一名程序员的初心吗？遥想公瑾当年，不，遥想我当年，似乎是“命中注定”走上这条路的。因为不在计划之内嘛，所以走了很多弯弯路。&lt;/p&gt;
&lt;p&gt;路漫漫其修远兮，我们就来上下求索一下，权当是一次复盘吧。我先来说道说道自己在程序员这条路上的点点滴滴，也许能够给颓丧或者迷茫中的你一些启发和感悟。&lt;strong&gt;在人生的不同阶段里，我们都需要和过去的自己认真地说一声“拜拜”，然后才能思索出未来前进的方向&lt;/strong&gt;。&lt;/p&gt;
&lt;h3 id=&quot;h01&quot;&gt;01、带疙瘩的电视&lt;/h3&gt;
&lt;p&gt;记得高四（复读）的时候，同桌阿联经常嘲笑我说：“电脑都不知道，真服你，不就是‘带疙瘩的电视嘛！’”阿联说的“疙瘩”，指的就是键盘了。确实啊，那时候电脑和电视差不了多少，笨重得很，真的是只多了一个键盘（不对，还有主机）。&lt;/p&gt;
&lt;p&gt;那时候用电脑干的最多的一件事，就是下载电影到 MP4 里。然后趁晚上自习的时候，带上耳机偷偷地看。因为陪课的老师上了一天的课也比较累，就经常呆坐在讲台上，不知道在干些什么，反正没精力盯着我们不放了。&lt;/p&gt;
&lt;p&gt;当时名不见经传的汤唯出演了一部很牛逼的电影——《色戒》（完了，要暴露年龄了），我们男同学算是被福利了。当时还不怀好意地推荐给了几个女同学看，等她们还我 MP4 的时候，我能从她脸上瞥出一副略带喜悦的表情，尽管她们已经极力掩饰了。&lt;/p&gt;
&lt;p&gt;复读了一年，高考成绩仍然不尽人意。阿联给我推荐了几个学校，我就漫不经心地填了志愿，并且服从调剂（&lt;strong&gt;我为什么命中注定成为一名程序员，正源于此&lt;/strong&gt;）。他已经是第三年复读了，报考经验比我多一些，但成绩比我还差。接二连三的复读，他的心态已经崩了，高三的时候还在“宏志班”呢。“宏志班”，你们懂吧，那可都是学霸啊，但复读一次又一次地摧毁了阿联的信心，逼迫他成了和我一样的学渣。&lt;/p&gt;
&lt;p&gt;在此，我必须警告一下&lt;strong&gt;各位年轻的学弟学妹们，心态不够强大的千万别复读&lt;/strong&gt;，早一点步入社会没准是更好的选择。阿联现在赋闲在家，半年前去平顶山参加婚礼的时候顺带到他家里坐了坐，他竟然问我编程好学不好学，要我教教他。我都惊呆了好不好。&lt;/p&gt;
&lt;p&gt;我们关系很铁，尽管多年不曾谋面，但聊起来还是颇有年轻时候的意气风发。甚至再次聊起了《色戒》。&lt;/p&gt;
&lt;h3 id=&quot;h02&quot;&gt;02、计算机网络专业&lt;/h3&gt;
&lt;p&gt;高考填报的专业是一所专科学校的“电力工程”——阿联推荐的，据说是学校最热门的专业（没有之一），很多子弟们挤破头要进的专业。&lt;/p&gt;
&lt;p&gt;庆幸的是，我不是子弟，自然没挤上这么好的专业。我被调剂到了“计算机网络”专业，学校最差劲的专业（没有之一）。据说，学校前身始建于 1933 年，老大不小了，但“计算机网络”专业只有两年不到的岁数（我们这届是第二年），算是个呱呱坠地的小娃娃吧。&lt;/p&gt;
&lt;p&gt;那时候，只觉得“计算机网络”专业是最差的，自己也是学校最差的学生之一。我们专业一百多名学生，几乎没有人对未来充满过信心。大家心心念的就是，通过半个学期一个学期的努力，转到电力系去。就算是转系无望，毕业后也没打算要成为一名正儿八经的程序员。&lt;/p&gt;
&lt;p&gt;我上大专的两年，一副破罐子破摔的模样。上课带着笔记本打游戏（单机的，比如忍者神龟、天龙八部、极品飞车等等），下课的时候仍然在打。都不舍得花一点时间去买饭，都是宿友帮带的。吃饭打游戏，全凭下面这张小桌子。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1117051/201909/1117051-20190903080341819-1343412328.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;站在现在的高度回头去看的话，真的是想捶了那个时候自暴自弃的自己&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;由于写作的原因，认识不少年轻人（98 年以后的），大一就开始写作了。除了写作，还搞公众号、卖课等等，各种知识付费是玩的六六六啊。&lt;/p&gt;
&lt;p&gt;假如我现在有一台时光机，我一定会从大一就开始写作，然后折腾一些开源项目。你可能已经忍不住想抽我几个耳光子了——醒醒吧，大哥，还在做梦呢？&lt;/p&gt;
&lt;p&gt;可惜我没有时光机。但我想年轻人要引我为戒啊，尤其是身在福中不知福的（自认为专业很差劲，其实很牛逼的），&lt;strong&gt;千万不要轻易地自暴自弃啊&lt;/strong&gt;。当年被我们看不起的计算机网络专业，尤其是学了 Java 编程语言的，在一线城市，可是很吃香的啊。&lt;/p&gt;
&lt;p&gt;可惜那时候老师们没给我们任何的指点（他们也觉得自己不受学校的重视，升迁无望），还特么鼓励我们转去电力专业。而我们这群傻瓜，整天除了打游游戏，就剩下无所事事了。&lt;/p&gt;
&lt;p&gt;顺带说一句，当年转去电力系的同学，现在大多就职于某个小城市的电力局，升迁基本无望，因为要等资格更老的退休或者转行啊。&lt;/p&gt;
&lt;h3 id=&quot;h03&quot;&gt;03、要不要培训&lt;/h3&gt;
&lt;p&gt;浑浑噩噩地度过了两年的大学生活，自觉毕业后就业无望，就和二十几个同学南下去了苏州一家软件园培训了（https://www.jianshu.com/p/7f8272fc8c11）。两个月后，找到了一份工作，起始工资一个月只有 1200 元，除了每月还 800 元的培训费，剩下那点钱勉强能糊口。&lt;/p&gt;
&lt;p&gt;现在回头来看的话，当时完全没必要去培训的。我们毕竟学了两年的 Java 编程了，SQL Server 也学了，计算机底层的网络架构也学了，网页三剑客也入门了，完全有能力去一线城市找一份工作的。&lt;/p&gt;
&lt;p&gt;只可惜那时候比较无知，自己把自己看扁了。&lt;strong&gt;我认识一些互联网大咖，早年都是拼命地从别的专业转到计算机专业的&lt;/strong&gt;。这就是差距啊！&lt;/p&gt;
&lt;p&gt;如果那时候能够遇到一个像我现在这样的人，给指点一下迷津，甚至不用指点，只需要说一句鼓励的话：“年轻人，去北漂吧，去深漂吧，未来是属于你们的”，那人生就可能完全不一样了。&lt;/p&gt;
&lt;p&gt;认知真的太重要了。如果了解当下的经济环境、产业环境、行业环境、技术环境，就能够做出更优的决策。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1117051/201909/1117051-20190903080327801-2113465084.png&quot; alt=&quot;&quot;/&gt;当然了，不管怎么说，还是要感谢一下 IT 行业的包容性！俗话说得好：“白猫黑猫，逮住老鼠的都是好猫。”那些科班出身的，大有作为的比比皆是；那些培训出身的，干出一番大事业的也不在少数。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;如果你觉得自己无路可走，培训应该算是一个很明智的选择，它能够让你快速地投入战斗的状态，在实战当中学习、进步，然后身经百战后成为一颗参天大树&lt;/strong&gt;。在三国时代，有“千里走单骑”的关公，在解放时代，有“敢横刀立马”的彭大将军。总之，在实战中成为英雄的不胜枚举。&lt;/p&gt;
&lt;p&gt;如果你的自学能力比较强，也完全没有必要去培训，网络上学习编程的资料有很多，我都可以提供一些给你。&lt;/p&gt;
&lt;h3 id=&quot;h04&quot;&gt;04、最后&lt;/h3&gt;
&lt;p&gt;我成为一名程序员，说得好听点是因为“命中注定”，不好听点就是“误打误撞”。你呢？&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1117051/201909/1117051-20190903080310426-1106981591.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;A：因为走投无路&lt;br/&gt;B：我也不知道为啥&lt;br/&gt;C：因为穷&lt;br/&gt;D：因为命中注定&lt;br/&gt;E：因为喜欢敲代码&lt;br/&gt;F：因为追求高薪&lt;br/&gt;G：因为要改变世界&lt;/p&gt;
&lt;p&gt;但无论初心是什么，我都希望你以“程序员”为傲，也只有这样，你才能走得更坚定，更长远。&lt;/p&gt;

</description>
<pubDate>Tue, 03 Sep 2019 00:06:00 +0000</pubDate>
<dc:creator>沉默王二</dc:creator>
<og:description>兄弟姐妹们，还记得自己成为一名程序员的初心吗？遥想公瑾当年，不，遥想我当年，似乎是“命中注定”走上这条路的。因为不在计划之内嘛，所以走了很多弯弯路。 路漫漫其修远兮，我们就来上下求索一下，权当是一次复</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/qing-gee/p/11450851.html</dc:identifier>
</item>
<item>
<title>边缘缓存模式(Cache-Aside Pattern) - MeteorSeed</title>
<link>http://www.cnblogs.com/MeteorSeed/p/11433455.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/MeteorSeed/p/11433455.html</guid>
<description>&lt;h2&gt;2.1 缓存数据的选择&lt;/h2&gt;
&lt;p&gt;　　对于相对静态的数据或频繁读取的数据，缓存是最有效的。&lt;/p&gt;
&lt;h2&gt;2.2 缓存数据的生命周期&lt;/h2&gt;
&lt;p&gt;　　过期时间短，会导致频繁查询数据源而失去缓存的意义；设置时间过长，可能发生缓存的数据过时不同步的情况。&lt;/p&gt;
&lt;h2&gt;2.3 缓存过期策略的选择&lt;/h2&gt;
&lt;p&gt;　　一般缓存产品都有自己内置的缓存过期策略，最长使用的是“最近最不常使用”算法，需要在使用时，了解产品的默认配置和可配置项，根据实际需求选择。&lt;/p&gt;
&lt;h2&gt;2.4 本地缓存与分布式缓存的选择&lt;/h2&gt;
&lt;p&gt;　　本地缓存的查询速度更快，但在一个分布式环境中，需要保证不同机器的本地缓存统一，这需要我们在程序中处理；分布式缓存性能不如本地缓存，但大多数时候，分布式缓存更适合大型项目，分布式缓存产品家族自带的管理和诊断工具十分适合运维和性能监控。&lt;/p&gt;
&lt;h2&gt;2.5 一致性问题&lt;/h2&gt;
&lt;p&gt;　　实现边缘缓存模式不能保证数据存储和缓存之间的实时一致性。数据存储中的某个项可能随时被外部进程更改，并且此更改可能在下次将项加载到缓存中之前不会反映在缓存中。&lt;/p&gt;

&lt;h2 id=&quot;7210-1567046506219&quot;&gt;3.1 淘汰还是更新缓存&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;淘汰缓存&lt;/strong&gt;：数据写入数据存储，并从缓存删除&lt;/p&gt;
&lt;p&gt;优点：简单&lt;/p&gt;
&lt;p&gt;缺点：缓存增加一次miss，需要重新加载数据到缓存&lt;/p&gt;
&lt;p&gt;　　&lt;strong&gt;更新缓存&lt;/strong&gt;：数据写入数据存储，并更新缓存&lt;/p&gt;
&lt;p&gt;　　优点：缓存不会增加一次miss，命中率高&lt;/p&gt;
&lt;p&gt;　　缺点：更新缓存比淘汰缓存复杂&lt;/p&gt;
&lt;p&gt;　　&lt;strong&gt;淘汰还是更新缓存主要取决于——更新缓存的复杂度，数据查询时间以及更新频率。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;　　&lt;strong&gt;如果更新缓存复杂度低，从数据存储查询查询数据有比较耗时，更新频率又高，则为了保证缓存命中率，更新缓存比较适合。此外大大多数情景，都可以用淘汰缓存，来满足需求。&lt;/strong&gt;&lt;/p&gt;
&lt;h2&gt;3.2 操作顺序&lt;/h2&gt;
&lt;p&gt;　　先操作数据存储，再操作缓存&lt;/p&gt;
&lt;p&gt;　　先操作缓存，再操作数据存储&lt;/p&gt;
&lt;h2 id=&quot;5997-1567056260906&quot;&gt;3.3 一致性问题&lt;/h2&gt;
&lt;h3&gt;非并发场景——场景为Application修改数据（考虑操作失败的影响）&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;先操作缓存，再操作数据存储&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/270073/201908/270073-20190830103434529-979408484.png&quot; alt=&quot;&quot; width=&quot;337&quot; height=&quot;150&quot;/&gt;&lt;/p&gt;
&lt;div&gt;&lt;img src=&quot;file:///C:/Users/Seed/youdao/weixinobU7VjiS94WjaGf-siiibhF7ZeaM/3609c5639c174109902e7d9110d0ea27/clipboard.png&quot; alt=&quot;&quot; data-attr-org-src-id=&quot;0631E61FC85A476DA4B1A36483E7BB2A&quot; data-media-type=&quot;image&quot;/&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;淘汰缓存时：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;step 1:淘汰缓存成功&lt;/p&gt;
&lt;p&gt;step 2:更新数据存储失败&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;结果：数据存储未修改，缓存已失效&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;修改缓存时：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;step 1:修改缓存成功&lt;/p&gt;
&lt;p&gt;step 2:更新数据存储失败&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;结果：数据不一致&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;先操作数据存储，再操作缓存&lt;/strong&gt;&lt;/p&gt;
&lt;div&gt;&lt;strong&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/270073/201908/270073-20190830103814329-1420672295.png&quot; alt=&quot;&quot; width=&quot;353&quot; height=&quot;167&quot;/&gt;&lt;/strong&gt;&lt;/div&gt;
&lt;div&gt;&lt;img src=&quot;file:///C:/Users/Seed/youdao/weixinobU7VjiS94WjaGf-siiibhF7ZeaM/a03155aeb9c6437e8adf7c89874eeaa6/clipboard.png&quot; alt=&quot;&quot; data-attr-org-src-id=&quot;9108F6CEB27540EEB90693EE0E6D9476&quot; data-media-type=&quot;image&quot;/&gt;&lt;/div&gt;
&lt;p&gt;　&lt;strong&gt;　淘汰缓存时：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;step 1:更新数据存储成功&lt;/p&gt;
&lt;p&gt;step 2:淘汰缓存失败&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;结果：数据不一致&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;　&lt;strong&gt;　修改缓存时：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;step 1:更新数据存储成功&lt;/p&gt;
&lt;p&gt;step 2:修改缓存失败&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;结果：数据不一致&lt;/strong&gt;&lt;/p&gt;
&lt;h3&gt;并发场景——场景位Application1修改数据，Application2读取数据，（不考虑操作失败的影响，仅考虑执行顺序的影响）&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;先操作缓存，再操作数据存储&lt;/strong&gt;&lt;/p&gt;
&lt;div&gt;&lt;strong&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/270073/201908/270073-20190830104145997-188124195.png&quot; alt=&quot;&quot; width=&quot;351&quot; height=&quot;207&quot;/&gt;&lt;/strong&gt;&lt;/div&gt;
&lt;div&gt;&lt;img src=&quot;file:///C:/Users/Seed/youdao/weixinobU7VjiS94WjaGf-siiibhF7ZeaM/30b4ea7f5ad443c199508456257e3eea/clipboard.png&quot; alt=&quot;&quot; data-attr-org-src-id=&quot;51F872F58A4B403A9779424F4F159DDF&quot; data-media-type=&quot;image&quot;/&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;　　淘汰缓存时：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;step 1:Application1先淘汰缓存&lt;/p&gt;
&lt;p&gt;step 2:Application2从缓存读取数据，但是没有命中缓存&lt;/p&gt;
&lt;p&gt;step 3:Application2从数据存储读取旧数据&lt;/p&gt;
&lt;p&gt;step 4:Application1完成数据存储的更新&lt;/p&gt;
&lt;p&gt;step 5:Application2把旧数据写入缓存，造成缓存与数据存储不一致&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;结果：数据不一致&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;　　&lt;strong&gt;更新缓存时：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;step 1:Application1先更新缓存&lt;/p&gt;
&lt;p&gt;step 2:Application2从缓存读取到新数据&lt;/p&gt;
&lt;p&gt;&lt;span&gt;step 3:Application2&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;step 4:Application1更新数据存储成功&lt;/p&gt;
&lt;p&gt;&lt;span&gt;step 5:Application2&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;结果：数据一致&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;先操作数据存储，再操作存储&lt;/strong&gt;&lt;/p&gt;
&lt;div&gt;&lt;strong&gt;　　&lt;img src=&quot;https://img2018.cnblogs.com/blog/270073/201908/270073-20190830104306680-1132181825.png&quot; alt=&quot;&quot; width=&quot;367&quot; height=&quot;203&quot;/&gt;&lt;/strong&gt;&lt;/div&gt;
&lt;div&gt;&lt;img src=&quot;file:///C:/Users/Seed/youdao/weixinobU7VjiS94WjaGf-siiibhF7ZeaM/5443d05a239c40029ac696a6865f692e/clipboard.png&quot; alt=&quot;&quot; data-attr-org-src-id=&quot;4A41B3C98E574444990034F15858366F&quot; data-media-type=&quot;image&quot;/&gt;　　&lt;strong&gt;淘汰缓存时：&lt;/strong&gt;&lt;/div&gt;
&lt;p&gt;step 1:Application1更新数据存储完成&lt;/p&gt;
&lt;p&gt;step 2:Application2从缓存读取数据，查询到旧数据&lt;/p&gt;
&lt;p&gt;step 3:Application1从缓存中删除数据&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;结果：缓存已淘汰，下次加载新数据&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;　　更新缓存时：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;step 1:Application1更新数据存储完成&lt;/p&gt;
&lt;p&gt;step 2:Application2从缓存读取数据，查询到旧数据&lt;/p&gt;
&lt;p&gt;step 3:Application1从更新缓存数据&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;结果：数据一致&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;　　&lt;strong&gt;由此可见，不管我们如何组织，都可能完全杜绝不一致问题，而影响一致性的两个关键因素是——“操作失败”和“时序”。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;　　对于“淘汰还是更新缓存”、“先缓存还是先数据存储”的选择，不应该脱离具体需求和业务场景而一概而论。我们把关注点重新回到“操作失败”和“时序”问题上来.&lt;/p&gt;
&lt;p&gt;　　对于“操作失败”，首先要从程序层面提高稳定性，比如“弹性编程”，“防御式编程”等技巧，其次，要设计补偿机制，在操作失败后要做到保存足够的信息（包括补偿操作需要的数据，异常信息等），并进行补偿操作（清洗异常数据，回滚数据到操作前的状态），通过补偿操作，实现最终一致性。&lt;/p&gt;
&lt;p&gt;　　对于“时序”问题，需要根据程序结构，梳理出潜在的时序问题。本文例子中，不设计补偿操作，如果引入的话，操作组合的时序图可能会更加复杂。解决的思路就是对于单个用户来说操作应该是“原子的”在分布式环境中，多个用户的操作应该是“串行”的。最简单的思路，就是使用分布式锁，来保证操作的串行化。当然，我们也可以通过队列来进行异步落库，实现最终一致性。&lt;/p&gt;

&lt;h2&gt;4.1 缓存穿透&lt;/h2&gt;
&lt;p&gt;　　缓存穿透是指用户频繁查询数据存储中不存在的数据，这类数据，查不到数据所以也不会写入缓存，所以每次都会查询数据存储，导致数据存储压力过大。&lt;/p&gt;
&lt;p&gt;　　解决方案：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;
&lt;ul&gt;&lt;li&gt;增加数据校验&lt;/li&gt;
&lt;li&gt;查询不到时，缓存空对象&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;h2&gt;4.2 缓存击穿&lt;/h2&gt;
&lt;p&gt;　　高并发下，当某个缓存失效时，可能出现多个进程同时查询数据存储，导致数据存储压力过大。&lt;/p&gt;
&lt;p&gt;　　解决方案：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;
&lt;ul&gt;&lt;li&gt;
&lt;ul&gt;&lt;li&gt;使用二级缓存&lt;/li&gt;
&lt;li&gt;通过加锁或者队列降低查询数据库存储的并发数量&lt;/li&gt;
&lt;li&gt;考虑延长部分数据是过期时间，或者设置为永不过期&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;h2&gt;4.3 缓存雪崩&lt;/h2&gt;
&lt;p&gt;　　高并发下，大量缓存同时失效，导致大量请求同时查询数据存储，导致数据存储压力过大。&lt;/p&gt;
&lt;p&gt;　　解决方案：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;
&lt;ul&gt;&lt;li&gt;
&lt;ul&gt;&lt;li&gt;使用二级缓存&lt;/li&gt;
&lt;li&gt;通过加锁或者队列降低查询数据库存储的并发数量&lt;/li&gt;
&lt;li&gt;根据数据的变化频率，设置不同的过期时间，避免在同一时间大量失效&lt;/li&gt;
&lt;li&gt;考虑延长部分数据是过期时间，或者设置为永不过期&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;　　&lt;strong&gt;总之，设计不能脱离具体需求和业务场景而存在，这里没有最优的组合方式，以上对该模式涉及问题的讨论，旨在发掘潜在的问题，以便合理应对。&lt;/strong&gt;&lt;/p&gt;
</description>
<pubDate>Tue, 03 Sep 2019 00:06:00 +0000</pubDate>
<dc:creator>MeteorSeed</dc:creator>
<og:description>边缘缓存模式(Cache-Aside Pattern)，即按需将数据从数据存储加载到缓存中。此模式最大的作用就是提高性能减少不必要的查询。 1 模式 &amp;lt;!--5f39ae17-8c62-4a45</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/MeteorSeed/p/11433455.html</dc:identifier>
</item>
<item>
<title>Storm 系列（二）—— Storm 核心概念详解 - 黑白影</title>
<link>http://www.cnblogs.com/heibaiying/p/11450830.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/heibaiying/p/11450830.html</guid>
<description>&lt;h2 id=&quot;一storm核心概念&quot;&gt;一、Storm核心概念&lt;/h2&gt;
&lt;div align=&quot;center&quot;&gt;&lt;img src=&quot;https://raw.githubusercontent.com/heibaiying/BigData-Notes/master/pictures/spout-bolt.png&quot;/&gt;&lt;/div&gt;
&lt;h3 id=&quot;topologies拓扑&quot;&gt;1.1 Topologies（拓扑）&lt;/h3&gt;
&lt;p&gt;一个完整的 Storm 流处理程序被称为 Storm topology(拓扑)。它是一个是由 &lt;code&gt;Spouts&lt;/code&gt; 和 &lt;code&gt;Bolts&lt;/code&gt; 通过 &lt;code&gt;Stream&lt;/code&gt; 连接起来的有向无环图，Storm 会保持每个提交到集群的 topology 持续地运行，从而处理源源不断的数据流，直到你将主动其杀死 (kill) 为止。&lt;/p&gt;
&lt;h3 id=&quot;streams流&quot;&gt;1.2 Streams（流）&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;Stream&lt;/code&gt; 是 Storm 中的核心概念。一个 &lt;code&gt;Stream&lt;/code&gt; 是一个无界的、以分布式方式并行创建和处理的 &lt;code&gt;Tuple&lt;/code&gt; 序列。Tuple 可以包含大多数基本类型以及自定义类型的数据。简单来说，Tuple 就是流数据的实际载体，而 Stream 就是一系列 Tuple。&lt;/p&gt;
&lt;h3 id=&quot;spouts&quot;&gt;1.3 Spouts&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;Spouts&lt;/code&gt; 是流数据的源头，一个 Spout 可以向不止一个 &lt;code&gt;Streams&lt;/code&gt; 中发送数据。&lt;code&gt;Spout&lt;/code&gt; 通常分为&lt;strong&gt;可靠&lt;/strong&gt;和&lt;strong&gt;不可靠&lt;/strong&gt;两种：可靠的 &lt;code&gt;Spout&lt;/code&gt; 能够在失败时重新发送 Tuple, 不可靠的 &lt;code&gt;Spout&lt;/code&gt; 一旦把 Tuple 发送出去就置之不理了。&lt;/p&gt;
&lt;h3 id=&quot;bolts&quot;&gt;1.4 Bolts&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;Bolts&lt;/code&gt; 是流数据的处理单元，它可以从一个或者多个 &lt;code&gt;Streams&lt;/code&gt; 中接收数据，处理完成后再发射到新的 &lt;code&gt;Streams&lt;/code&gt; 中。&lt;code&gt;Bolts&lt;/code&gt; 可以执行过滤 (filtering)，聚合 (aggregations)，连接 (joins) 等操作，并能与文件系统或数据库进行交互。&lt;/p&gt;
&lt;h3 id=&quot;stream-groupings分组策略&quot;&gt;1.5 Stream groupings（分组策略）&lt;/h3&gt;
&lt;div align=&quot;center&quot;&gt;&lt;img width=&quot;400px&quot; src=&quot;https://raw.githubusercontent.com/heibaiying/BigData-Notes/master/pictures/topology-tasks.png&quot;/&gt;&lt;/div&gt;
&lt;p&gt;&lt;code&gt;spouts&lt;/code&gt; 和 &lt;code&gt;bolts&lt;/code&gt; 在集群上执行任务时，是由多个 Task 并行执行 (如上图，每一个圆圈代表一个 Task)。当一个 Tuple 需要从 Bolt A 发送给 Bolt B 执行的时候，程序如何知道应该发送给 Bolt B 的哪一个 Task 执行呢？&lt;/p&gt;
&lt;p&gt;这是由 Stream groupings 分组策略来决定的，Storm 中一共有如下 8 个内置的 Stream Grouping。当然你也可以通过实现 &lt;code&gt;CustomStreamGrouping&lt;/code&gt; 接口来实现自定义 Stream 分组策略。&lt;/p&gt;
&lt;ol readability=&quot;9.5&quot;&gt;&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;&lt;strong&gt;Shuffle grouping&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Tuples 随机的分发到每个 Bolt 的每个 Task 上，每个 Bolt 获取到等量的 Tuples。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;&lt;strong&gt;Fields grouping&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Streams 通过 grouping 指定的字段 (field) 来分组。假设通过 &lt;code&gt;user-id&lt;/code&gt; 字段进行分区，那么具有相同 &lt;code&gt;user-id&lt;/code&gt; 的 Tuples 就会发送到同一个 Task。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;1&quot;&gt;
&lt;p&gt;&lt;strong&gt;Partial Key grouping&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Streams 通过 grouping 中指定的字段 (field) 来分组，与 &lt;code&gt;Fields Grouping&lt;/code&gt; 相似。但是对于两个下游的 Bolt 来说是负载均衡的，可以在输入数据不平均的情况下提供更好的优化。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;&lt;strong&gt;All grouping&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Streams 会被所有的 Bolt 的 Tasks 进行复制。由于存在数据重复处理，所以需要谨慎使用。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;&lt;strong&gt;Global grouping&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;整个 Streams 会进入 Bolt 的其中一个 Task，通常会进入 id 最小的 Task。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;&lt;strong&gt;None grouping&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;当前 None grouping 和 Shuffle grouping 等价，都是进行随机分发。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;&lt;strong&gt;Direct grouping&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Direct grouping 只能被用于 direct streams 。使用这种方式需要由 Tuple 的生产者直接指定由哪个 Task 进行处理。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;3&quot;&gt;
&lt;p&gt;&lt;strong&gt;Local or shuffle grouping&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;如果目标 Bolt 有 Tasks 和当前 Bolt 的 Tasks 处在同一个 Worker 进程中，那么则优先将 Tuple Shuffled 到处于同一个进程的目标 Bolt 的 Tasks 上，这样可以最大限度地减少网络传输。否则，就和普通的 &lt;code&gt;Shuffle Grouping&lt;/code&gt; 行为一致。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;&lt;h2 id=&quot;二storm架构详解&quot;&gt;二、Storm架构详解&lt;/h2&gt;
&lt;div align=&quot;center&quot;&gt;&lt;img src=&quot;https://raw.githubusercontent.com/heibaiying/BigData-Notes/master/pictures/Internal-Working-of-Apache-Storm.png&quot;/&gt;&lt;/div&gt;
&lt;h3 id=&quot;nimbus进程&quot;&gt;2.1 Nimbus进程&lt;/h3&gt;
&lt;p&gt;也叫做 Master Node，是 Storm 集群工作的全局指挥官。主要功能如下：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;通过 Thrift 接口，监听并接收 Client 提交的 Topology；&lt;/li&gt;
&lt;li&gt;根据集群 Workers 的资源情况，将 Client 提交的 Topology 进行任务分配，分配结果写入 Zookeeper;&lt;/li&gt;
&lt;li&gt;通过 Thrift 接口，监听 Supervisor 的下载 Topology 代码的请求，并提供下载 ;&lt;/li&gt;
&lt;li&gt;通过 Thrift 接口，监听 UI 对统计信息的读取，从 Zookeeper 上读取统计信息，返回给 UI;&lt;/li&gt;
&lt;li&gt;若进程退出后，立即在本机重启，则不影响集群运行。&lt;/li&gt;
&lt;/ol&gt;&lt;h3 id=&quot;supervisor进程&quot;&gt;2.2 Supervisor进程&lt;/h3&gt;
&lt;p&gt;也叫做 Worker Node , 是 Storm 集群的资源管理者，按需启动 Worker 进程。主要功能如下：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;定时从 Zookeeper 检查是否有新 Topology 代码未下载到本地 ，并定时删除旧 Topology 代码 ;&lt;/li&gt;
&lt;li&gt;根据 Nimbus 的任务分配计划，在本机按需启动 1 个或多个 Worker 进程，并监控所有的 Worker 进程的情况；&lt;/li&gt;
&lt;li&gt;若进程退出，立即在本机重启，则不影响集群运行。&lt;/li&gt;
&lt;/ol&gt;&lt;h3 id=&quot;zookeeper的作用&quot;&gt;2.3 zookeeper的作用&lt;/h3&gt;
&lt;p&gt;Nimbus 和 Supervisor 进程都被设计为&lt;strong&gt;快速失败&lt;/strong&gt;（遇到任何意外情况时进程自毁）和&lt;strong&gt;无状态&lt;/strong&gt;（所有状态保存在 Zookeeper 或磁盘上）。 这样设计的好处就是如果它们的进程被意外销毁，那么在重新启动后，就只需要从 Zookeeper 上获取之前的状态数据即可，并不会造成任何数据丢失。&lt;/p&gt;
&lt;h3 id=&quot;worker进程&quot;&gt;2.4 Worker进程&lt;/h3&gt;
&lt;p&gt;Storm 集群的任务构造者 ，构造 Spoult 或 Bolt 的 Task 实例，启动 Executor 线程。主要功能如下：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;根据 Zookeeper 上分配的 Task，在本进程中启动 1 个或多个 Executor 线程，将构造好的 Task 实例交给 Executor 去运行；&lt;/li&gt;
&lt;li&gt;向 Zookeeper 写入心跳 ；&lt;/li&gt;
&lt;li&gt;维持传输队列，发送 Tuple 到其他的 Worker ；&lt;/li&gt;
&lt;li&gt;若进程退出，立即在本机重启，则不影响集群运行。&lt;/li&gt;
&lt;/ol&gt;&lt;h3 id=&quot;executor线程&quot;&gt;2.5 Executor线程&lt;/h3&gt;
&lt;p&gt;Storm 集群的任务执行者 ，循环执行 Task 代码。主要功能如下：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;执行 1 个或多个 Task；&lt;/li&gt;
&lt;li&gt;执行 Acker 机制，负责发送 Task 处理状态给对应 Spout 所在的 worker。&lt;/li&gt;
&lt;/ol&gt;&lt;h3 id=&quot;并行度&quot;&gt;2.6 并行度&lt;/h3&gt;
&lt;div align=&quot;center&quot;&gt;&lt;img src=&quot;https://raw.githubusercontent.com/heibaiying/BigData-Notes/master/pictures/relationships-worker-processes-executors-tasks.png&quot;/&gt;&lt;/div&gt;
&lt;p&gt;1 个 Worker 进程执行的是 1 个 Topology 的子集，不会出现 1 个 Worker 为多个 Topology 服务的情况，因此 1 个运行中的 Topology 就是由集群中多台物理机上的多个 Worker 进程组成的。1 个 Worker 进程会启动 1 个或多个 Executor 线程来执行 1 个 Topology 的 Component(组件，即 Spout 或 Bolt)。&lt;/p&gt;
&lt;p&gt;Executor 是 1 个被 Worker 进程启动的单独线程。每个 Executor 会运行 1 个 Component 中的一个或者多个 Task。&lt;/p&gt;
&lt;p&gt;Task 是组成 Component 的代码单元。Topology 启动后，1 个 Component 的 Task 数目是固定不变的，但该 Component 使用的 Executor 线程数可以动态调整（例如：1 个 Executor 线程可以执行该 Component 的 1 个或多个 Task 实例）。这意味着，对于 1 个 Component 来说，&lt;code&gt;#threads&amp;lt;=#tasks&lt;/code&gt;（线程数小于等于 Task 数目）这样的情况是存在的。默认情况下 Task 的数目等于 Executor 线程数，即 1 个 Executor 线程只运行 1 个 Task。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;总结如下：&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;一个运行中的 Topology 由集群中的多个 Worker 进程组成的；&lt;/li&gt;
&lt;li&gt;在默认情况下，每个 Worker 进程默认启动一个 Executor 线程；&lt;/li&gt;
&lt;li&gt;在默认情况下，每个 Executor 默认启动一个 Task 线程；&lt;/li&gt;
&lt;li&gt;Task 是组成 Component 的代码单元。&lt;/li&gt;
&lt;/ul&gt;&lt;h2 id=&quot;参考资料&quot;&gt;参考资料&lt;/h2&gt;
&lt;ol readability=&quot;-0.019736842105263&quot;&gt;&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;&lt;a href=&quot;http://storm.apache.org/releases/1.2.2/Concepts.html&quot;&gt;storm documentation -&amp;gt; Concepts&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://www.spritle.com/blogs/2016/04/04/apache-storm/&quot;&gt;Internal Working of Apache Storm&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://storm.apache.org/releases/1.2.2/Understanding-the-parallelism-of-a-Storm-topology.html&quot;&gt;Understanding the Parallelism of a Storm Topology&lt;/a&gt;&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;&lt;a href=&quot;https://blog.csdn.net/daiyutage/article/details/52049519&quot;&gt;Storm nimbus 单节点宕机的处理&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;&lt;blockquote readability=&quot;3.75&quot;&gt;
&lt;p&gt;&lt;strong&gt;更多大数据系列文章可以参见 GitHub 开源项目&lt;/strong&gt;： &lt;a href=&quot;https://github.com/heibaiying/BigData-Notes&quot;&gt;&lt;strong&gt;大数据入门指南&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
</description>
<pubDate>Mon, 02 Sep 2019 23:38:00 +0000</pubDate>
<dc:creator>黑白影</dc:creator>
<og:description>一、Storm核心概念 1.1 Topologies（拓扑） 一个完整的 Storm 流处理程序被称为 Storm topology(拓扑)。它是一个是由 和 通过 连接起来的有向无环图，Storm</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/heibaiying/p/11450830.html</dc:identifier>
</item>
</channel>
</rss>