<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="css/feed.xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/" xmlns:og="http://ogp.me/ns#">
<channel>
<atom:link rel="self" href="http://192.168.1.4/fivefilters/makefulltextfeed.php?url=feed.cnblogs.com%2Fblog%2Fsitehome%2Frss&amp;max=10&amp;links=preserve&amp;exc=" />
<atom:link rel="alternate" title="Source URL" href="http://feed.cnblogs.com/blog/sitehome/rss" />
<atom:link rel="related" title="Subscribe to feed" href="http://www.subtome.com/#/subscribe?feeds=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed.cnblogs.com%252Fblog%252Fsitehome%252Frss%26max%3D10%26links%3Dpreserve%26exc%3D&amp;back=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed.cnblogs.com%252Fblog%252Fsitehome%252Frss%26max%3D10%26links%3Dpreserve%26exc%3D" />
<title>博客园_首页</title>
<link></link>
<description>代码改变世界</description>
<item>
<title>C/C++多参数函数参数的计算顺序与压栈顺序 - _程序兔</title>
<link>http://www.cnblogs.com/GuoYuying/p/12990751.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/GuoYuying/p/12990751.html</guid>
<description>&lt;p&gt;&lt;strong&gt;一、前言&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;　　今天在看Thinking in C++这本书时，书中的一个例子引起了我的注意，具体是使用了下面这句&lt;/p&gt;
&lt;p&gt;　　&lt;img src=&quot;https://img2020.cnblogs.com/blog/1696980/202005/1696980-20200530081725371-1937481953.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;单看这条语句的语义会发现仅仅是使用一个简单的string的substr函数将所得子串push_back到strings。但是在阅读时我却对于substr的参数传递产生了疑惑，到底是先执行了++current，还是先执行了last-current？&lt;/p&gt;
&lt;p&gt;经过查阅资料，发现了两个相关知识点----参数的计算顺序与压栈顺序。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;二、参数压栈顺序&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;　　&lt;strong&gt;C/C++中规定了函数参数的压栈顺序是从右至左&lt;/strong&gt;，对于含有不定参数的printf函数，其原型是printf（const char* format,…）；其中format确定了printf的参数（通过format的%个数判断）。假设是从左至右压栈，那么先入栈的是format（这里我们简化理解为参数个数），然后依次入栈未知参数，此时想要知道参数个数，就必须找到format，而要找到format，就必须知道参数个数，陷入一个逻辑矛盾。因此C/C++中规定参数压栈为从右至左，这样对于不定参数，最后入栈的是参数个数，只需要取栈顶就可以得到。可以通过下面的程序验证：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;45&quot;&gt;
&lt;pre&gt;
#include &amp;lt;stdio.h&amp;gt;
&lt;span&gt;void&lt;/span&gt; foo(&lt;span&gt;int&lt;/span&gt; x, &lt;span&gt;int&lt;/span&gt; y, &lt;span&gt;int&lt;/span&gt;&lt;span&gt; z)
{
        printf(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;x = %d at [%X]\n&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;, x, &amp;amp;&lt;span&gt;x);
        printf(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;y = %d at [%X]\n&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;, y, &amp;amp;&lt;span&gt;y);
        printf(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;z = %d at [%X]\n&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;, z, &amp;amp;&lt;span&gt;z);
}
&lt;/span&gt;&lt;span&gt;int&lt;/span&gt; main(&lt;span&gt;int&lt;/span&gt; argc, &lt;span&gt;char&lt;/span&gt; *&lt;span&gt;argv[])
{
        foo(&lt;/span&gt;&lt;span&gt;100&lt;/span&gt;, &lt;span&gt;200&lt;/span&gt;, &lt;span&gt;300&lt;/span&gt;&lt;span&gt;);
        &lt;/span&gt;&lt;span&gt;return&lt;/span&gt; &lt;span&gt;0&lt;/span&gt;&lt;span&gt;;
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1696980/202005/1696980-20200530083219622-848085403.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;通过输出结果可以看到x,y,z的栈内地址依次是 x &amp;lt; y &amp;lt; z；而栈的生长方向是从高到低，也就是先入栈的占高地址，因此z先入栈，其次是y，最后是x，即压栈顺序从右至左。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;三、参数计算顺序&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;　　知道参数压栈顺序从右至左，是不是可以得出结论strings.push_back( s.substr(++current, last-current)); 先执行last-current，再执行++current呢？其实不然，先执行哪个参数和参数的计算顺序有关，而&lt;strong&gt;C/C++中没有规定函数参数的计算顺序，即计算顺序依照编译器&lt;/strong&gt;，编译器规定从右至左计算就先执行last-current，规定从左至右就先执行++current，笔者试过codeblocks与vscode的计算顺序都是从右至左。&lt;/p&gt;
&lt;p&gt;　　也正因为函数参数的计算顺序依照编译器的实现，因此，C/C++的代码编写中并不支持编写诸如 func(++x, x+y)这种的程序，在不同编译器下可能产生不同的结果，所以上述代码应该分开写为：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;33&quot;&gt;
&lt;pre&gt;
        &lt;span&gt;int&lt;/span&gt; len = last -&lt;span&gt; current;
        &lt;/span&gt;++&lt;span&gt;current;
        strings.push_back(
            s.substr(current, len));&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

</description>
<pubDate>Sat, 30 May 2020 00:43:00 +0000</pubDate>
<dc:creator>_程序兔</dc:creator>
<og:description>一、前言 今天在看Thinking in C++这本书时，书中的一个例子引起了我的注意，具体是使用了下面这句 单看这条语句的语义会发现仅仅是使用一个简单的string的substr函数将所得子串pus</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/GuoYuying/p/12990751.html</dc:identifier>
</item>
<item>
<title>搭建Nexus Repository包管理系统 - 维晟</title>
<link>http://www.cnblogs.com/bluersw/p/12990744.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/bluersw/p/12990744.html</guid>
<description>&lt;h2 id=&quot;下载安装程序&quot;&gt;下载安装程序&lt;/h2&gt;
&lt;p&gt;&lt;a href=&quot;https://www.sonatype.com/download-oss-sonatype&quot;&gt;下载Nexus Repository最新版本&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://help.sonatype.com/repomanager3&quot;&gt;配置说明&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;将下载后的文件传输到服务器上&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-shell&quot;&gt;#修改配置文件
vi  /etc/security/limits.conf

#添加
* soft nofile 65536

#修改服务配置
vi /etc/systemd/system.conf

#修改
DefaultLimitNOFILE=65536

#重启
reboot

#查看结果
ulimit -n

#将当前目标下的文件上传到目标服务器的指定路径
scp nexus-3.23.0-03-unix.tar root@192.168.0.5:/opt/

#解压
tar -xvf nexus-3.23.0-03-unix.tar

#做一个软链接方便访问和更新
ln -s /opt/nexus-3.23.0-03/ /nexus

#修改运行用户
vi /nexus/bin/nexus.rc

#修改运行用户，除非自己个人使用否则不要用root用户
run_as_user=&quot;root&quot;

ln -s /nexus/bin/nexus /etc/init.d/nexus

#init.d设置
cd /etc/init.d
chkconfig --add nexus
chkconfig --levels 345 nexus on
service nexus start

#创建Nexus服务
vi /etc/systemd/system/nexus.service
&lt;/code&gt;
&lt;/pre&gt;
&lt;pre&gt;
&lt;code class=&quot;language-conf&quot;&gt;[Unit]
Description=nexus service
After=network.target
  
[Service]
Type=forking
LimitNOFILE=65536
ExecStart=/nexus/bin/nexus start
ExecStop=/nexus/bin/nexus stop
User=root
Restart=on-abort
TimeoutSec=600
  
[Install]
WantedBy=multi-user.target
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;如果没有安装JAVA，请看：&lt;br/&gt;&lt;a href=&quot;https://www.cnblogs.com/bluersw/p/Install-Java-18.md&quot;&gt;安装Java1.8&lt;/a&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-shell&quot;&gt;#重新加载服务
systemctl daemon-reload

#开机启动
systemctl enable nexus.service

#运行服务
systemctl start nexus.service

#查看日志
tail -f /opt/sonatype-work/nexus3/log/nexus.log
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;访问http://192.168.0.5:8081 进入管理界面。&lt;/p&gt;
&lt;h2 id=&quot;创建yum仓库&quot;&gt;创建YUM仓库&lt;/h2&gt;
&lt;p&gt;&lt;a href=&quot;https://help.sonatype.com/repomanager3/formats/yum-repositories&quot;&gt;创建YUM代理仓库官方说明&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Nexus服务器域名和端口：repo.bluersw.com：8081&lt;/p&gt;
&lt;p&gt;Proxy仓库：&lt;/p&gt;
&lt;p&gt;Group仓库：&lt;/p&gt;
&lt;p&gt;客户端配置：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-shell&quot;&gt;#备份
cd /etc/yum.repos.d/
mkdir bak
cp *.repo bak/

vi /etc/yum.repos.d/CentOS-Base.repo
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;修改CentOS-Base文件内容：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-conf&quot;&gt;[base]
name=CentOS-$releasever - Base
#mirrorlist=http://mirrorlist.centos.org/?release=$releasever&amp;amp;arch=$basearch&amp;amp;repo=os&amp;amp;infra=$infra
#baseurl=http://mirror.centos.org/centos/$releasever/os/$basearch/
baseurl=http://repo.bluersw.com:8081/repository/repo-bluersw/$releasever/os/$basearch/
gpgcheck=1
gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-7

#released updates
[updates]
name=CentOS-$releasever - Updates
#mirrorlist=http://mirrorlist.centos.org/?release=$releasever&amp;amp;arch=$basearch&amp;amp;repo=updates&amp;amp;infra=$infra
#baseurl=http://mirror.centos.org/centos/$releasever/updates/$basearch/
baseurl=http://repo.bluersw.com:8081/repository/repo-bluersw/$releasever/updates/$basearch/
gpgcheck=1
gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-7

#additional packages that may be useful
[extras]
name=CentOS-$releasever - Extras
#mirrorlist=http://mirrorlist.centos.org/?release=$releasever&amp;amp;arch=$basearch&amp;amp;repo=extras&amp;amp;infra=$infra
#baseurl=http://mirror.centos.org/centos/$releasever/extras/$basearch/
baseurl=http://repo.bluersw.com:8081/repository/repo-bluersw/$releasever/extras/$basearch/
gpgcheck=1
gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-7

#additional packages that extend functionality of existing packages
[centosplus]
name=CentOS-$releasever - Plus
#mirrorlist=http://mirrorlist.centos.org/?release=$releasever&amp;amp;arch=$basearch&amp;amp;repo=centosplus&amp;amp;infra=$infra
#baseurl=http://mirror.centos.org/centos/$releasever/centosplus/$basearch/
baseurl=http://repo.bluersw.com:8081/repository/repo-bluersw/$releasever/centosplus/$basearch/
gpgcheck=1
enabled=0
gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-7
&lt;/code&gt;
&lt;/pre&gt;
&lt;pre&gt;
&lt;code class=&quot;language-shell&quot;&gt;yum clean all
yum makecache

#更新系统第一次会比较慢
yum update -y
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;下载的RPM包都存储在Nexus服务器上，以后其他服务器照此配置就不用从外网下载了。&lt;/p&gt;
&lt;h2 id=&quot;创建docker仓库&quot;&gt;创建Docker仓库&lt;/h2&gt;
&lt;p&gt;&lt;a href=&quot;https://help.sonatype.com/repomanager3/formats/docker-registry&quot;&gt;创建Docker仓库官方说明&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Proxy仓库：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;仓库名称：hub-docker-proxy&lt;/li&gt;
&lt;li&gt;仓库类型：proxy&lt;/li&gt;
&lt;li&gt;远程仓库地址：&lt;a href=&quot;https://registry-1.docker.io&quot;&gt;https://registry-1.docker.io&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Repository Connectors：不创建（由Group仓库负责）&lt;/li&gt;
&lt;li&gt;Allow anonymous docker pull ( Docker Bearer Token Realm required )：true（勾选）&lt;/li&gt;
&lt;li&gt;Enable Docker V1 API：勾选&lt;/li&gt;
&lt;li&gt;Docker Index：Use Docker Hub&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;Hosted仓库：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;仓库名称：my-docker-host&lt;/li&gt;
&lt;li&gt;仓库类型：hosted&lt;/li&gt;
&lt;li&gt;Repository Connectors：HTTP 8082端口（负责Push Image）&lt;/li&gt;
&lt;li&gt;Allow anonymous docker pull ( Docker Bearer Token Realm required )：true（勾选）&lt;/li&gt;
&lt;li&gt;Enable Docker V1 API：勾选&lt;/li&gt;
&lt;li&gt;对外地址：&lt;a href=&quot;http://repo.bluersw.com:8082&quot;&gt;http://repo.bluersw.com:8082&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;Group仓库：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;仓库名称：docker-bluersw（含hub-docker-proxy和my-docker-host）&lt;/li&gt;
&lt;li&gt;仓库类型：group&lt;/li&gt;
&lt;li&gt;Repository Connectors：HTTP 8083端口（负责Pull Image）&lt;/li&gt;
&lt;li&gt;
&lt;ul&gt;&lt;li&gt;Allow anonymous docker pull ( Docker Bearer Token Realm required )：true（勾选）&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;对外地址：&lt;a href=&quot;http://repo.bluersw.com:8083&quot;&gt;http://repo.bluersw.com:8083&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;group类型的Docker仓库只能pull不能push。&lt;/p&gt;
&lt;p&gt;在Security中打开Realms界面，激活Docker Bearer Token Realm 选项。&lt;/p&gt;
&lt;p&gt;客户端配置：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-shell&quot;&gt;vi /etc/docker/daemon.json
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;修改Docker的daemon配置文件，添加上述两个Docker私服地址。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-json&quot;&gt;{
&quot;insecure-registries&quot;: [&quot;http://repo.bluersw.com:8082&quot;,&quot;http://repo.bluersw.com:8083&quot;]
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;pre&gt;
&lt;code class=&quot;language-shell&quot;&gt;#重启服务
systemctl restart docker

#登录
docker login http://repo.bluersw.com:8082
docker login http://repo.bluersw.com:8083

#使用代理服务器下载镜像，镜像会存在代理服务器上供其他人下载
docker pull repo.bluersw.com:8083/hello-world

[root@ops docker]# docker images
REPOSITORY                           TAG                 IMAGE ID            CREATED             SIZE
repo.bluersw.com:8083/hello-world   latest              bf756fb1ae65        4 months ago        13.3kB

#改名
docker tag repo.bluersw.com:8083/hello-world repo.bluersw.com:8082/hello-world

#上传到Docker私有仓库
docker push repo.bluersw.com:8082/hello-world
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;a href=&quot;https://www.cnblogs.com/bluersw/p/www.bluersw.com&quot;&gt;www.bluersw.com&lt;/a&gt;&lt;/p&gt;
</description>
<pubDate>Sat, 30 May 2020 00:40:00 +0000</pubDate>
<dc:creator>维晟</dc:creator>
<og:description>搭建Nexus Repository包管理系统 下载安装程序 下载Nexus Repository最新版本 配置说明 将下载后的文件传输到服务器上 #修改配置文件 vi /etc/security/l</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/bluersw/p/12990744.html</dc:identifier>
</item>
<item>
<title>看了这篇，我确定你已经彻底搞懂Java的继承了 - 沉默王二</title>
<link>http://www.cnblogs.com/qing-gee/p/12990735.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/qing-gee/p/12990735.html</guid>
<description>&lt;p&gt;遇到认真的读者是作者的一种幸运，真的，上一篇&lt;a href=&quot;https://mp.weixin.qq.com/s/06d5Fk_ho4yafR83mfbWag&quot;&gt;接口&lt;/a&gt;推送后，有好几个读者留言说，“二哥，你有一处内容需要修正，应该是接口中不能有 private 和 protected 修饰的方法。”说实话，看到这样的留言，我内心是非常欣慰的，因为你投出去的一块石头在水面上激起了一串美丽的涟漪。&lt;/p&gt;
&lt;p&gt;在 Java 中，一个类可以继承另外一个类或者实现多个接口，我想这一点，大部分的读者应该都知道了。还有一点，我不确定大家是否知道，就是一个接口也可以继承另外一个接口，就像下面这样：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;java language-java hljs&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;hljs-class&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;interface&lt;/span&gt; &lt;span class=&quot;hljs-title&quot;&gt;OneInterface&lt;/span&gt; &lt;span class=&quot;hljs-keyword&quot;&gt;extends&lt;/span&gt; &lt;span class=&quot;hljs-title&quot;&gt;Cloneable&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;这样做有什么好处呢？我想有一部分读者应该已经猜出来了，就是实现了 OneInterface 接口的类，也可以使用 &lt;code&gt;Object.clone()&lt;/code&gt; 方法了。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;java language-java hljs&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;hljs-class&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;hljs-title&quot;&gt;TestInterface&lt;/span&gt; &lt;span class=&quot;hljs-keyword&quot;&gt;implements&lt;/span&gt; &lt;span class=&quot;hljs-title&quot;&gt;OneInterface&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;&lt;span class=&quot;hljs-function&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;hljs-keyword&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;hljs-keyword&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;hljs-title&quot;&gt;main&lt;/span&gt;&lt;span class=&quot;hljs-params&quot;&gt;(String[] args)&lt;/span&gt; &lt;span class=&quot;hljs-keyword&quot;&gt;throws&lt;/span&gt; CloneNotSupportedException &lt;/span&gt;{&lt;br/&gt;TestInterface c1 = &lt;span class=&quot;hljs-keyword&quot;&gt;new&lt;/span&gt; TestInterface();&lt;br/&gt;TestInterface c2 = (TestInterface) c1.clone();&lt;br/&gt;}&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;除此之外，我们还可以在 OneInterface 接口中定义其他一些抽象方法（比如说深拷贝），使该接口拥有 Cloneable 所不具有的功能。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;java language-java hljs&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;hljs-class&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;interface&lt;/span&gt; &lt;span class=&quot;hljs-title&quot;&gt;OneInterface&lt;/span&gt; &lt;span class=&quot;hljs-keyword&quot;&gt;extends&lt;/span&gt; &lt;span class=&quot;hljs-title&quot;&gt;Cloneable&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;&lt;span class=&quot;hljs-function&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;hljs-title&quot;&gt;deepClone&lt;/span&gt;&lt;span class=&quot;hljs-params&quot;&gt;()&lt;/span&gt;&lt;/span&gt;;&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;看到了吧？这就是继承的好处：&lt;strong&gt;子接口拥有了父接口的方法，使得子接口具有了父接口相同的行为；同时，子接口还可以在此基础上自由发挥，添加属于自己的行为&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;以上，把“接口”换成“类”，结论同样成立。让我们来定义一个普通的父类 Wanger：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;java language-java hljs&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;hljs-class&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;hljs-title&quot;&gt;Wanger&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;int&lt;/span&gt; age;&lt;br/&gt;String name;&lt;br/&gt;&lt;span class=&quot;hljs-function&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;hljs-title&quot;&gt;write&lt;/span&gt;&lt;span class=&quot;hljs-params&quot;&gt;()&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;System.out.println(&lt;span class=&quot;hljs-string&quot;&gt;&quot;我写了本《基督山伯爵》&quot;&lt;/span&gt;);&lt;br/&gt;}&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;然后，我们再来定义一个子类 Wangxiaoer，使用关键字 &lt;code&gt;extends&lt;/code&gt; 来继承父类 Wanger：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;java language-java hljs&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;hljs-class&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;hljs-title&quot;&gt;Wangxiaoer&lt;/span&gt; &lt;span class=&quot;hljs-keyword&quot;&gt;extends&lt;/span&gt; &lt;span class=&quot;hljs-title&quot;&gt;Wanger&lt;/span&gt;&lt;/span&gt;{&lt;br/&gt;&lt;span class=&quot;hljs-meta&quot;&gt;@Override&lt;/span&gt;&lt;br/&gt;&lt;span class=&quot;hljs-function&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;hljs-title&quot;&gt;write&lt;/span&gt;&lt;span class=&quot;hljs-params&quot;&gt;()&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;System.out.println(&lt;span class=&quot;hljs-string&quot;&gt;&quot;我写了本《茶花女》&quot;&lt;/span&gt;);&lt;br/&gt;}&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;我们可以将通用的方法和成员变量放在父类中，达到代码复用的目的；然后将特殊的方法和成员变量放在子类中，除此之外，子类还可以覆盖父类的方法（比如&lt;code&gt;write()&lt;/code&gt; 方法）。这样，子类也就焕发出了新的生命力。&lt;/p&gt;
&lt;p&gt;Java 只支持单一继承，这一点，我在上一篇&lt;a href=&quot;https://mp.weixin.qq.com/s/06d5Fk_ho4yafR83mfbWag&quot;&gt;接口&lt;/a&gt;的文章中已经提到过了。如果一个类在定义的时候没有使用 &lt;code&gt;extends&lt;/code&gt; 关键字，那么它隐式地继承了 &lt;code&gt;java.lang.Object&lt;/code&gt; 类——在我看来，这恐怕就是 Java 号称万物皆对象的真正原因了。&lt;/p&gt;
&lt;p&gt;那究竟子类继承了父类的什么呢？&lt;/p&gt;
&lt;p&gt;子类可以继承父类的非 private 成员变量，为了验证这一点，我们来看下面这个示例。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;java language-java hljs&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;hljs-class&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;hljs-title&quot;&gt;Wanger&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;String defaultName;&lt;br/&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;private&lt;/span&gt; String privateName;&lt;br/&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;public&lt;/span&gt; String publicName;&lt;br/&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;protected&lt;/span&gt; String protectedName;&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;父类 Wanger 定义了四种类型的成员变量，缺省的 defaultName、私有的 privateName、共有的 publicName、受保护的 protectedName。&lt;/p&gt;
&lt;p&gt;在子类 Wangxiaoer 中定义一个测试方法 &lt;code&gt;testVariable()&lt;/code&gt;：&lt;/p&gt;
&lt;img src=&quot;http://www.itwanger.com/assets/images/2020/05/java-extends-01.png&quot; alt=&quot;&quot; title=&quot;&quot;/&gt;&lt;p&gt;可以确认，除了私有的 privateName，其他三种类型的成员变量都可以继承到。&lt;/p&gt;
&lt;p&gt;同理，子类可以继承父类的非 private 方法，为了验证这一点，我们来看下面这个示例。&lt;/p&gt;
&lt;pre readability=&quot;6&quot;&gt;
&lt;code class=&quot;java language-java hljs&quot; readability=&quot;6&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;hljs-class&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;hljs-title&quot;&gt;Wanger&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;&lt;span class=&quot;hljs-function&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;hljs-title&quot;&gt;write&lt;/span&gt;&lt;span class=&quot;hljs-params&quot;&gt;()&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;}&lt;p&gt;&lt;span class=&quot;hljs-function&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;hljs-keyword&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;hljs-title&quot;&gt;privateWrite&lt;/span&gt;&lt;span class=&quot;hljs-params&quot;&gt;()&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;}&lt;/p&gt;&lt;p&gt;&lt;span class=&quot;hljs-function&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;hljs-keyword&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;hljs-title&quot;&gt;publicWrite&lt;/span&gt;&lt;span class=&quot;hljs-params&quot;&gt;()&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;}&lt;/p&gt;&lt;p&gt;&lt;span class=&quot;hljs-function&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;protected&lt;/span&gt; &lt;span class=&quot;hljs-keyword&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;hljs-title&quot;&gt;protectedWrite&lt;/span&gt;&lt;span class=&quot;hljs-params&quot;&gt;()&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;}&lt;br/&gt;}&lt;br/&gt;&lt;/p&gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;父类 Wanger 定义了四种类型的方法，缺省的 write、私有的 privateWrite()、共有的 publicWrite()、受保护的 protectedWrite()。&lt;/p&gt;
&lt;p&gt;在子类 Wangxiaoer 中定义一个 main 方法，并使用 new 关键字新建一个子类对象：&lt;/p&gt;
&lt;img src=&quot;http://www.itwanger.com/assets/images/2020/05/java-extends-02.png&quot; alt=&quot;&quot; title=&quot;&quot;/&gt;&lt;p&gt;可以确认，除了私有的 privateWrite()，其他三种类型的方法都可以继承到。&lt;/p&gt;
&lt;p&gt;不过，子类无法继承父类的构造方法。如果父类的构造方法是带有参数的，代码如下所示：&lt;/p&gt;
&lt;pre readability=&quot;4.5&quot;&gt;
&lt;code class=&quot;java language-java hljs&quot; readability=&quot;3&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;hljs-class&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;hljs-title&quot;&gt;Wanger&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;int&lt;/span&gt; age;&lt;br/&gt;String name;&lt;p&gt;&lt;span class=&quot;hljs-function&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;hljs-title&quot;&gt;Wanger&lt;/span&gt;&lt;span class=&quot;hljs-params&quot;&gt;(&lt;span class=&quot;hljs-keyword&quot;&gt;int&lt;/span&gt; age, String name)&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;this&lt;/span&gt;.age = age;&lt;br/&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;this&lt;/span&gt;.name = name;&lt;br/&gt;}&lt;br/&gt;}&lt;br/&gt;&lt;/p&gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;则必须在子类的构造器中显式地通过 super 关键字进行调用，否则编译器将提示以下错误：&lt;/p&gt;
&lt;img src=&quot;http://www.itwanger.com/assets/images/2020/05/java-extends-03.png&quot; alt=&quot;&quot; title=&quot;&quot;/&gt;&lt;p&gt;修复后的代码如下所示：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;java language-java hljs&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;hljs-class&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;hljs-title&quot;&gt;Wangxiaoer&lt;/span&gt; &lt;span class=&quot;hljs-keyword&quot;&gt;extends&lt;/span&gt; &lt;span class=&quot;hljs-title&quot;&gt;Wanger&lt;/span&gt;&lt;/span&gt;{&lt;br/&gt;&lt;span class=&quot;hljs-function&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;hljs-title&quot;&gt;Wangxiaoer&lt;/span&gt;&lt;span class=&quot;hljs-params&quot;&gt;(&lt;span class=&quot;hljs-keyword&quot;&gt;int&lt;/span&gt; age, String name)&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;super&lt;/span&gt;(age, name);&lt;br/&gt;}&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;is-a 是继承的一个明显特征，就是说子类的对象引用类型可以是一个父类类型。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;java language-java hljs&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;hljs-class&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;hljs-title&quot;&gt;Wangxiaoer&lt;/span&gt; &lt;span class=&quot;hljs-keyword&quot;&gt;extends&lt;/span&gt; &lt;span class=&quot;hljs-title&quot;&gt;Wanger&lt;/span&gt;&lt;/span&gt;{&lt;br/&gt;&lt;span class=&quot;hljs-function&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;hljs-keyword&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;hljs-keyword&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;hljs-title&quot;&gt;main&lt;/span&gt;&lt;span class=&quot;hljs-params&quot;&gt;(String[] args)&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;Wanger wangxiaoer = &lt;span class=&quot;hljs-keyword&quot;&gt;new&lt;/span&gt; Wangxiaoer();&lt;br/&gt;}&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;同理，子接口的实现类的对象引用类型也可以是一个父接口类型。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;java language-java hljs&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;hljs-class&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;interface&lt;/span&gt; &lt;span class=&quot;hljs-title&quot;&gt;OneInterface&lt;/span&gt; &lt;span class=&quot;hljs-keyword&quot;&gt;extends&lt;/span&gt; &lt;span class=&quot;hljs-title&quot;&gt;Cloneable&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;}&lt;br/&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;hljs-class&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;hljs-title&quot;&gt;TestInterface&lt;/span&gt; &lt;span class=&quot;hljs-keyword&quot;&gt;implements&lt;/span&gt; &lt;span class=&quot;hljs-title&quot;&gt;OneInterface&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;&lt;span class=&quot;hljs-function&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;hljs-keyword&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;hljs-keyword&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;hljs-title&quot;&gt;main&lt;/span&gt;&lt;span class=&quot;hljs-params&quot;&gt;(String[] args)&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;Cloneable c1 = &lt;span class=&quot;hljs-keyword&quot;&gt;new&lt;/span&gt; TestInterface();&lt;br/&gt;}&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;尽管一个类只能继承一个类，但一个类却可以实现多个接口，这一点，我在&lt;a href=&quot;https://mp.weixin.qq.com/s/06d5Fk_ho4yafR83mfbWag&quot;&gt;上一篇文章&lt;/a&gt;也提到过了。另外，还有一点我也提到了，就是 Java 8 之后，接口中可以定义 default 方法，这很方便，但也带来了新的问题：&lt;/p&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;如果一个类实现了多个接口，而这些接口中定义了相同签名的 default 方法，那么这个类就要重写该方法，否则编译无法通过。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;FlyInterface 是一个会飞的接口，里面有一个签名为 &lt;code&gt;sleep()&lt;/code&gt; 的默认方法：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;java language-java hljs&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;hljs-class&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;interface&lt;/span&gt; &lt;span class=&quot;hljs-title&quot;&gt;FlyInterface&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;&lt;span class=&quot;hljs-function&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;hljs-title&quot;&gt;fly&lt;/span&gt;&lt;span class=&quot;hljs-params&quot;&gt;()&lt;/span&gt;&lt;/span&gt;;&lt;br/&gt;&lt;span class=&quot;hljs-function&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;default&lt;/span&gt; &lt;span class=&quot;hljs-keyword&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;hljs-title&quot;&gt;sleep&lt;/span&gt;&lt;span class=&quot;hljs-params&quot;&gt;()&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;System.out.println(&lt;span class=&quot;hljs-string&quot;&gt;&quot;睡着飞&quot;&lt;/span&gt;);&lt;br/&gt;}&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;RunInterface 是一个会跑的接口，里面也有一个签名为 &lt;code&gt;sleep()&lt;/code&gt; 的默认方法：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;java language-java hljs&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;hljs-class&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;interface&lt;/span&gt; &lt;span class=&quot;hljs-title&quot;&gt;RunInterface&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;&lt;span class=&quot;hljs-function&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;hljs-title&quot;&gt;run&lt;/span&gt;&lt;span class=&quot;hljs-params&quot;&gt;()&lt;/span&gt;&lt;/span&gt;;&lt;br/&gt;&lt;span class=&quot;hljs-function&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;default&lt;/span&gt; &lt;span class=&quot;hljs-keyword&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;hljs-title&quot;&gt;sleep&lt;/span&gt;&lt;span class=&quot;hljs-params&quot;&gt;()&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;System.out.println(&lt;span class=&quot;hljs-string&quot;&gt;&quot;睡着跑&quot;&lt;/span&gt;);&lt;br/&gt;}&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;Pig 类实现了 FlyInterface 和 RunInterface 两个接口，但这时候编译出错了。&lt;/p&gt;
&lt;img src=&quot;http://www.itwanger.com/assets/images/2020/05/java-extends-04.png&quot; alt=&quot;&quot; title=&quot;&quot;/&gt;&lt;p&gt;原本，default 方法就是为实现该接口而不覆盖该方法的类提供默认实现的，现在，相同方法签名的 &lt;code&gt;sleep()&lt;/code&gt; 方法把编译器搞懵逼了，只能重写了。&lt;/p&gt;
&lt;pre readability=&quot;6&quot;&gt;
&lt;code class=&quot;java language-java hljs&quot; readability=&quot;6&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;hljs-class&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;hljs-title&quot;&gt;Pig&lt;/span&gt; &lt;span class=&quot;hljs-keyword&quot;&gt;implements&lt;/span&gt; &lt;span class=&quot;hljs-title&quot;&gt;FlyInterface&lt;/span&gt;, &lt;span class=&quot;hljs-title&quot;&gt;RunInterface&lt;/span&gt; &lt;/span&gt;{&lt;p&gt;&lt;span class=&quot;hljs-meta&quot;&gt;@Override&lt;/span&gt;&lt;br/&gt;&lt;span class=&quot;hljs-function&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;hljs-keyword&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;hljs-title&quot;&gt;fly&lt;/span&gt;&lt;span class=&quot;hljs-params&quot;&gt;()&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;System.out.println(&lt;span class=&quot;hljs-string&quot;&gt;&quot;会飞的猪&quot;&lt;/span&gt;);&lt;br/&gt;}&lt;/p&gt;&lt;p&gt;&lt;span class=&quot;hljs-meta&quot;&gt;@Override&lt;/span&gt;&lt;br/&gt;&lt;span class=&quot;hljs-function&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;hljs-keyword&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;hljs-title&quot;&gt;sleep&lt;/span&gt;&lt;span class=&quot;hljs-params&quot;&gt;()&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;System.out.println(&lt;span class=&quot;hljs-string&quot;&gt;&quot;只能重写了&quot;&lt;/span&gt;);&lt;br/&gt;}&lt;/p&gt;&lt;p&gt;&lt;span class=&quot;hljs-meta&quot;&gt;@Override&lt;/span&gt;&lt;br/&gt;&lt;span class=&quot;hljs-function&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;hljs-keyword&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;hljs-title&quot;&gt;run&lt;/span&gt;&lt;span class=&quot;hljs-params&quot;&gt;()&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;System.out.println(&lt;span class=&quot;hljs-string&quot;&gt;&quot;会跑的猪&quot;&lt;/span&gt;);&lt;br/&gt;}&lt;br/&gt;}&lt;br/&gt;&lt;/p&gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;类虽然不能继承多个类，但接口却可以继承多个接口，这一点，我不知道有没有触及到一些读者的知识盲区。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;java language-java hljs&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;hljs-class&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;interface&lt;/span&gt; &lt;span class=&quot;hljs-title&quot;&gt;WalkInterface&lt;/span&gt; &lt;span class=&quot;hljs-keyword&quot;&gt;extends&lt;/span&gt; &lt;span class=&quot;hljs-title&quot;&gt;FlyInterface&lt;/span&gt;,&lt;span class=&quot;hljs-title&quot;&gt;RunInterface&lt;/span&gt;&lt;/span&gt;{&lt;br/&gt;&lt;span class=&quot;hljs-function&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;hljs-title&quot;&gt;walk&lt;/span&gt;&lt;span class=&quot;hljs-params&quot;&gt;()&lt;/span&gt;&lt;/span&gt;;&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;学到了吧？学到就是赚到。&lt;/p&gt;
&lt;p&gt;我是沉默王二，一枚有趣的程序员。如果觉得文章对你有点帮助，请微信搜索「 &lt;strong&gt;沉默王二&lt;/strong&gt; 」第一时间阅读，回复【&lt;strong&gt;666&lt;/strong&gt;】更有我为你精心准备的 500G 高清教学视频（已分门别类）。&lt;/p&gt;
&lt;blockquote readability=&quot;4.5890410958904&quot;&gt;
&lt;p&gt;本文 &lt;a href=&quot;https://github.com/qinggee/itwanger.github.io&quot;&gt;GitHub&lt;/a&gt; 已经收录，有大厂面试完整考点，欢迎 Star。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;原创不易，莫要白票，请你为本文点个赞吧&lt;/strong&gt;，这将是我写作更多优质文章的最强动力。&lt;/p&gt;
</description>
<pubDate>Sat, 30 May 2020 00:33:00 +0000</pubDate>
<dc:creator>沉默王二</dc:creator>
<og:description>遇到认真的读者是作者的一种幸运，真的，上一篇接口推送后，有好几个读者留言说，“二哥，你有一处内容需要修正，应该是接口中不能有 private 和 protected 修饰的方法。”说实话，看到这样的留</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/qing-gee/p/12990735.html</dc:identifier>
</item>
<item>
<title>突发！HashiCorp禁止在中国使用企业版VAULT软件 - flydean</title>
<link>http://www.cnblogs.com/flydean/p/hashicorp-terms-of-vault.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/flydean/p/hashicorp-terms-of-vault.html</guid>
<description>&lt;p&gt;昨天HashiCorp突然发布一则消息，禁止在中国使用Vault软件的企业版本，官方申明是这样的：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20200530071025939.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_0,text_aHR0cDovL3d3dy5mbHlkZWFuLmNvbQ==,size_35,color_8F8F8F,t_70&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;HashiCorp的解释是因为中国的出口管制的原因导致无法出售HASHICORP软件或者使用企业版的Vault。所以在没有取得HashiCorp书面协议的前提下，不得在中国境内使用，部署和安装HashiCorp的Vault企业版本软件。&lt;/p&gt;
&lt;blockquote readability=&quot;7&quot;&gt;
&lt;p&gt;注意，这里只是禁止使用企业版本的Vault软件，个人版本和HashiCorp公司的其他软件并不在此限制之内。大家不要被网络上面的谣言所迷惑，一定要勇于探索真理。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;那么这个影响到底对我们有多大呢？我们先看下HashiCorp公司的成长史。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20200530071841736.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_0,text_aHR0cDovL3d3dy5mbHlkZWFuLmNvbQ==,size_35,color_8F8F8F,t_70&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;HashiCorp于2012年成立，由Mitchell Hashimoto和Armon Dadgar创办，并陆续推出了Vagrant、Packer 、 Terraform、Consul , Vault 和 Nomad以满足不同的需求。&lt;/p&gt;
&lt;p&gt;更多精彩内容且看：&lt;/p&gt;
&lt;p&gt;HashiCorp专注于提供DevOps基础设施自动化工具，集开发、运营和安全性于一体，可以帮助开发者编写和部署应用程序，加速应用程序分发，助力企业提升开发效率。公司还推出了一个商业平台Atlas，为公共云服务供应商和私人云技术公司等提供支持。&lt;/p&gt;
&lt;p&gt;HashiCorp于2014年获得了1000万美元A轮融资。并在最近，也就是2020-03-18月E轮融资获得了1.75亿美元。主要投资方包括：GGV纪源资本，红点投资，Mayfield Fund，IVP (Institutional Venture Partners)等知名机构。&lt;/p&gt;
&lt;p&gt;HashiCorp采用开源的方式和云厂商合作，为云的使用提供了一套通用的工作流程。合作方包括2000多家上市公司。&lt;/p&gt;
&lt;p&gt;在2019 胡润研究院发布《2019胡润全球独角兽榜》，HashiCorp排名第138位。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20200530072905179.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_0,text_aHR0cDovL3d3dy5mbHlkZWFuLmNvbQ==,size_35,color_8F8F8F,t_70&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;HashiCor提供了一整套的技术服务，涵盖了云服务的每一层，帮助企业轻松在云环境中操作，每个产品都是为特定的云基础设置自动化来服务的。&lt;/p&gt;
&lt;p&gt;区分下来，可以分为Provision，Secure，Connect和Run四个部分。&lt;/p&gt;
&lt;h2 id=&quot;provision&quot;&gt;Provision&lt;/h2&gt;
&lt;p&gt;Provision的意思就是安装。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20200530073418681.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_0,text_aHR0cDovL3d3dy5mbHlkZWFuLmNvbQ==,size_35,color_8F8F8F,t_70&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;Terraform可以实现用代码的形式来安装cloud或者infrastructure。基础结构即代码，使用 Terraform 配置语言可以轻松跨整个工作流实现资源管理自动化。&lt;/p&gt;
&lt;p&gt;基本上大部分的公有云都支持使用Terraform。&lt;/p&gt;
&lt;h2 id=&quot;secure&quot;&gt;Secure&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20200530073817808.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_0,text_aHR0cDovL3d3dy5mbHlkZWFuLmNvbQ==,size_35,color_8F8F8F,t_70&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;安装好基础组件之后，那么就需要保证他们使用的安全性。那么就需要用到Vault。也就是今天被禁止使用的Vault。&lt;/p&gt;
&lt;p&gt;Vault是一款企业级私密信息管理工具。&lt;/p&gt;
&lt;p&gt;在企业级应用开发过程中，我们每时每刻都在使用到私密信息，包括密码，密钥，token等等。那么如果在公司内部的开发者之间共享这些密码，密钥，token就是一个很实在的问题。&lt;/p&gt;
&lt;p&gt;而Vault就是这样的一套统一的管理私密信息的接口。&lt;/p&gt;
&lt;p&gt;难道被禁的原因是Vault的安全性协议？&lt;/p&gt;
&lt;h2 id=&quot;connect&quot;&gt;Connect&lt;/h2&gt;
&lt;p&gt;安全性也保证了，那么接下来就是连接服务了。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20200530074218900.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_0,text_aHR0cDovL3d3dy5mbHlkZWFuLmNvbQ==,size_35,color_8F8F8F,t_70&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;Consul是一个支持多数据中心分布式高可用的服务发现和配置共享的服务软件。在国内有大量的使用案例。&lt;/p&gt;
&lt;h2 id=&quot;run&quot;&gt;Run&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20200530074416100.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_0,text_aHR0cDovL3d3dy5mbHlkZWFuLmNvbQ==,size_35,color_8F8F8F,t_70&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;最后就是运行了，Nomad可以用来对容器进行管理和调度。从而更加快捷的部署和更加方便的管理线上资源。&lt;/p&gt;

&lt;p&gt;虽然目前被禁用的只是Vault的企业版本，但是还是让人感到深深的危机感，中国的企业什么时候能够做出世界级的软件平台，让我们拭目以待！&lt;/p&gt;
&lt;blockquote readability=&quot;8.4117647058824&quot;&gt;
&lt;p&gt;本文作者：flydean程序那些事&lt;/p&gt;
&lt;p&gt;本文链接：&lt;a href=&quot;http://www.flydean.com/hashicorp-terms-of-vault/&quot;&gt;http://www.flydean.com/hashicorp-terms-of-vault/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;本文来源：flydean的博客&lt;/p&gt;
&lt;p&gt;欢迎关注我的公众号:程序那些事，更多精彩等着您！&lt;/p&gt;
&lt;/blockquote&gt;
</description>
<pubDate>Sat, 30 May 2020 00:28:00 +0000</pubDate>
<dc:creator>flydean</dc:creator>
<og:description>前言 昨天HashiCorp突然发布一则消息，禁止在中国使用Vault软件的企业版本，官方申明是这样的： HashiCorp的解释是因为中国的出口管制的原因导致无法出售HASHICORP软件或者使用企</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/flydean/p/hashicorp-terms-of-vault.html</dc:identifier>
</item>
<item>
<title>Elasticsearch系列---生产集群部署(上) - 清茶豆奶</title>
<link>http://www.cnblogs.com/huangying2124/p/12990693.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/huangying2124/p/12990693.html</guid>
<description>&lt;h3 id=&quot;概要&quot;&gt;概要&lt;/h3&gt;
&lt;p&gt;本篇开始介绍Elasticsearch生产集群的搭建及相关参数的配置。&lt;/p&gt;
&lt;h3 id=&quot;es集群的硬件特性&quot;&gt;ES集群的硬件特性&lt;/h3&gt;
&lt;p&gt;我们从开始编程就接触过各种各样的组件，而每种功能的组件，对硬件要求的特性都不太相同，有的需要很强的CPU计算能力，有的对内存需求量大，有的对网卡要求高等待，下面我们讨论一下ES集群对几种硬件的特性需求。&lt;/p&gt;
&lt;h4 id=&quot;cpu&quot;&gt;CPU&lt;/h4&gt;
&lt;p&gt;ES集群对CPU的要求相对低一些，毕竟纯计算的比重要小一些，选用主流的CPU，2核到8核的都可以。&lt;/p&gt;
&lt;p&gt;如果有两种CPU可以挑选，一种是主频高但核数少的CPU，另一种是主频一般核数多的CPU，肯定选后一种，因为多核的CPU可以提供更多的并发处理能力，远比单核高性能带来的效益要高。&lt;/p&gt;
&lt;h4 id=&quot;内存&quot;&gt;内存&lt;/h4&gt;
&lt;p&gt;ES集群对内存的要求很高，部署ES集群时，要把大部分资源投入到内存当中。内存分配主要有两部分，JVM heap内存（堆内存）和OS Cache内存。&lt;/p&gt;
&lt;p&gt;JVM heap内存用得不多，主要是OS Cache，我们知道，ES建立的倒排索引，正排索引，过滤器缓存，都是优先放在内存当中的，OS Cache的大小直接决定搜索的性能，如果OS Cache不够，ES搜索等操作只有被迫读硬盘，延时就会从毫秒级升到秒级。&lt;/p&gt;
&lt;p&gt;OS Cache具体在多大才算够，取决于数据量，如果是百万级别的数据，16GB左右应该可以接受，如果是亿级，一般单节点都是64GB内存。生产环境最低要求内存应不低于8GB。&lt;/p&gt;
&lt;h4 id=&quot;硬盘&quot;&gt;硬盘&lt;/h4&gt;
&lt;p&gt;硬盘成本本身比较便宜，能用SSD就用SSD，访问速度肯定比机械硬盘快，预估好数据量后就尽可能多规划一些容量。&lt;/p&gt;
&lt;p&gt;另外尽量使用本地存储，网络存储还依赖于网络传输，这个容易造成一些延迟。&lt;/p&gt;
&lt;h4 id=&quot;网络&quot;&gt;网络&lt;/h4&gt;
&lt;p&gt;对ES集群这种分布式系统来说，快速并且可靠的网络还是比较重要的，shard的分配和rebalance都需要占用大量的带宽，集群最好部署在同一个局域网内，异地容灾等跨数据中心的部署方案，要考虑到网络故障带来的影响。&lt;/p&gt;
&lt;h4 id=&quot;jvm选择&quot;&gt;JVM选择&lt;/h4&gt;
&lt;p&gt;使用ES官网推荐的JDK版本，服务端和客户端尽量使用同一个版本的JDK。&lt;/p&gt;
&lt;p&gt;涉及到ES服务端的JVM调优设置，保持原样不要轻易改动，毕竟ES已经花了大量人力物力验证过的，随意调整jvm参数可能适得其反。&lt;/p&gt;
&lt;h4 id=&quot;容量规划&quot;&gt;容量规划&lt;/h4&gt;
&lt;p&gt;规划集群里，要规划好投入几台服务器，数据量上限是多少，业务模型数据读写的比例是多少，历史数据的迁移方案等，一般来说，百万到10亿内的数据量，使用ES集群还是能够支撑下来的，ES节点数建议不要超过100个。&lt;/p&gt;
&lt;p&gt;举个例子：数据量10亿以内，部署5台服务器，8核64GB内存，是能够支撑的。&lt;/p&gt;
&lt;h3 id=&quot;生产案例模拟&quot;&gt;生产案例模拟&lt;/h3&gt;
&lt;h4 id=&quot;linux操作系统搭建&quot;&gt;Linux操作系统搭建&lt;/h4&gt;
&lt;p&gt;我们使用Linux虚拟机来演示一个生产ES集群的搭建。我们创建4台虚拟机，每台2核CPU，4GB内存，操作系统为CentOS 7 64bit。&lt;/p&gt;
&lt;p&gt;虚拟机我用的是VMware workstation，有用virtual box也行，CentOS 7、JDK的安装不赘述。记得把CentOS的防火墙关了。&lt;/p&gt;
&lt;p&gt;修改每台机器的hostname信息，命令&lt;br/&gt;&lt;code&gt;vi /etc/hostname&lt;/code&gt;，修改文件，保存即可，建议修改成elasticsearch01，elasticsearch02，elasticsearch03，elasticsearch04。&lt;/p&gt;
&lt;p&gt;假定我们4台虚拟机的域名和IP是这样分配的：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;192.168.17.138 elasticsearch01
192.168.17.137 elasticsearch02
192.168.17.132 elasticsearch03
192.168.17.139 elasticsearch04
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;把这段配置放在 &lt;code&gt;/etc/hosts&lt;/code&gt;文件末尾，4台机器做相同的配置。&lt;/p&gt;
&lt;p&gt;这4台机器之间，可以配置免密登录，如在elasticsearch01机器上，我们执行以下操作：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;生成公钥文件，命令：&lt;/li&gt;
&lt;/ol&gt;&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;ssh-keygen -t rsa
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;一直输入回车，不要设置密码默认会将公钥放在/root/.ssh目录下生成id_rsa.pub和id_rsa两个文件&lt;/p&gt;
&lt;ol start=&quot;2&quot;&gt;&lt;li&gt;拷贝公钥文件&lt;/li&gt;
&lt;/ol&gt;&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;cp id_rsa.pub authorized_keys
&lt;/code&gt;
&lt;/pre&gt;
&lt;ol start=&quot;3&quot;&gt;&lt;li&gt;将公钥文件拷贝到另外三台机器&lt;/li&gt;
&lt;/ol&gt;&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;ssh-copy-id -i elasticsearch02
ssh-copy-id -i elasticsearch03
ssh-copy-id -i elasticsearch03
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;拷贝完成后，可以在目标机器上&lt;code&gt;/root/.ssh/&lt;/code&gt;目录下看到多了一个authorized_keys文件。&lt;/p&gt;
&lt;ol start=&quot;4&quot;&gt;&lt;li&gt;尝试免密登录，在elasticsearch01机器上输入&lt;code&gt;ssh elasticsearch02&lt;/code&gt;，如果不需要输入密码就能登录到elasticsearch02，说明配置成功，其他机器类似。&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;这4台机器也可以相互做ssh免密设置。&lt;/p&gt;
&lt;p&gt;这里补充一点免密登录的方向性问题，上面的案例是在elasticsearch01机器生成的公钥，并且发送给了elasticsearch02等三台机器，那么我从elasticsearch01跳到elasticsearch02是不需要密码的，反过来从elasticsearch02登录到elasticsearch01，还是需要密码的。&lt;/p&gt;
&lt;p&gt;最后补充几个常用检查命令：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;检查NetManager的状态：systemctl status NetworkManager.service&lt;/li&gt;
&lt;li&gt;检查NetManager管理的网络接口：nmcli dev status&lt;/li&gt;
&lt;li&gt;检查NetManager管理的网络连接：nmcli connection show&lt;/li&gt;
&lt;/ul&gt;&lt;h4 id=&quot;elasticsearch服务端&quot;&gt;Elasticsearch服务端&lt;/h4&gt;
&lt;p&gt;这里选用的JDK版本为1.8.0_211，Elasticsearch版本为6.3.1，自行安装不赘述。&lt;/p&gt;
&lt;p&gt;ES解压后的目录结构：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;# 用 &quot;tree -L 1&quot; 命令得到的树状结构
.
├── bin
├── config
├── lib
├── LICENSE.txt
├── logs
├── modules
├── NOTICE.txt
├── plugins
└── README.textile
&lt;/code&gt;
&lt;/pre&gt;
&lt;ul&gt;&lt;li&gt;bin：存放es的一些可执行脚本，比如用于启动进程的elasticsearch命令，以及用于安装插件的elasticsearch-plugin插件&lt;/li&gt;
&lt;li&gt;config：用于存放es的配置文件，比如elasticsearch.yml&lt;/li&gt;
&lt;li&gt;logs：用于存放es的日志文件&lt;/li&gt;
&lt;li&gt;plugins：用于存放es的插件&lt;/li&gt;
&lt;li&gt;data：用于存放es的数据文件的默认目录，就是每个索引的shard的数据文件，一般会另外指定一个目录。&lt;/li&gt;
&lt;/ul&gt;&lt;h3 id=&quot;elasticsearch参数设置&quot;&gt;Elasticsearch参数设置&lt;/h3&gt;
&lt;p&gt;在config目录下的文件，包含了ES的基本配置信息：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;.
├── elasticsearch.yml
├── jvm.options
├── log4j2.properties
├── role_mapping.yml
├── roles.yml
├── users
└── users_roles

&lt;/code&gt;
&lt;/pre&gt;
&lt;h4 id=&quot;默认参数&quot;&gt;默认参数&lt;/h4&gt;
&lt;p&gt;Elasticsearch的配置项比较丰富并且默认配置已经非常优秀了，基本上我们需要改动的是跟服务器环境相关的配置，如IP地址，集群名称，数据存储位置，日志存储位置等外围参数，涉及到内部机制及JVM参数的，一般不干预，不恰当的JVM参数调整反而会导致集群出现性能故障，如果没有充足的理由或数据验证结果，不要轻易尝试修改。&lt;/p&gt;
&lt;h4 id=&quot;集群和节点名称&quot;&gt;集群和节点名称&lt;/h4&gt;
&lt;p&gt;在elasticsearch.yml文件里这项配置表示集群名称，配置项默认是注释掉的，集群名称默认为elasticsearch。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;#cluster.name: my-application&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;这个配置项强烈建议打开，用项目约定的命名规范进行重命名，并且将研发环境、测试环境、STG准生产环境、生产环境分别命名，如elasticsearch_music_app_dev表示研发环境，elasticsearch_music_app_sit表示测试环境，elasticsearch_music_app_pro表示生产环境等。避免开发测试环境连错环境，无意中加入集群导致数据问题。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;cluster.name: elasticsearch_music_app_pro&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;节点名称的配置项&lt;/p&gt;
&lt;p&gt;&lt;code&gt;#node.name: node-1&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;默认也是注释掉的，ES启动时会分配一个随机的名称，建议还是自行分配一个名称，这样容易记住是哪台机器，如&lt;/p&gt;
&lt;p&gt;&lt;code&gt;node.name: es_node_001_data&lt;/code&gt;&lt;/p&gt;
&lt;h4 id=&quot;文件路径&quot;&gt;文件路径&lt;/h4&gt;
&lt;p&gt;涉及到文件路径的几个参数，主要有数据、日志、插件等，默认这几个地址都是在Elasticsearch安装的根目录下，但Elasticsearch升级时，有些目录可能会有影响，安全起见，可以单独设置目录。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;#
# ----------------------------------- Paths ------------------------------------
#
# Path to directory where to store the data (separate multiple locations by comma):
#
#path.data: /path/to/data
#
# Path to log files:
#
#path.logs: /path/to/logs
#
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;例如我们可以在&lt;code&gt;/var&lt;/code&gt;目录下创建相应的文件夹，并且赋予相应的读写权限，如：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;path.data: /var/es/data
path.logs: /var/es/logs
&lt;/code&gt;
&lt;/pre&gt;
&lt;h4 id=&quot;日志文件配置&quot;&gt;日志文件配置&lt;/h4&gt;
&lt;p&gt;log4j2.properties文件，ES日志框架选用的是log4j2，也就是log4j的进化版本，对Java技术栈熟悉的童鞋，看到这个配置文件会非常熟悉，默认的日志输入配置、格式均能满足日常的故障定位和分析，也不需要什么改动。&lt;/p&gt;
&lt;p&gt;默认是一天生成一个日期文件，如果ES承载的数据量特别大，可以调整日志文件产生频率和每个日志文件的大小，以及ES最多存储日志的大小、数量。&lt;/p&gt;
&lt;h3 id=&quot;elasticsearch集群发现机制&quot;&gt;Elasticsearch集群发现机制&lt;/h3&gt;
&lt;h4 id=&quot;配置参数&quot;&gt;配置参数&lt;/h4&gt;
&lt;p&gt;Zen Discovery是Elasticsearch集群发现机制的默认实现，底层通信依赖transport组件，我们完成Elasticsearch集群的配置主要有下面几个参数：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;cluster.name 指定集群的名称。&lt;/li&gt;
&lt;li&gt;node.name 节点名称。&lt;/li&gt;
&lt;li&gt;network.host 节点绑定的IP。&lt;/li&gt;
&lt;li&gt;node.master 可选值为true/false，决定该节点类型为master eligible或data node。&lt;/li&gt;
&lt;li&gt;discovery.zen.ping.unicast.hosts gossip路由服务的IP地址，即集群发现协议通信的公共节点，可以写多个，有节点启动时会向里面的IP发送消息，获取集群其他节点的信息，最后加入集群。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;Elasticsearch集群是点对点(P2P)的分布式系统架构，数据索引、搜索操作是node之间直接通信的，没有中心式的master节点，但Elasticsearch集群内的节点也分成master node和data node两种角色。&lt;/p&gt;
&lt;p&gt;正常情况下，Elasticsearch集群只有一个master节点，它负责维护整个集群的状态信息，集群的元数据信息，有新的node加入或集群内node宕机下线时，重新分配shard，并同步node的状态信息给所有的node节点，这样所有的node节点都有一份完整的cluster state信息。&lt;/p&gt;
&lt;p&gt;集群发现的一般步骤如下：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;节点配置network.host绑定内网地址，配置各自的node.name信息，cluster.name设置为相同的值。&lt;/li&gt;
&lt;li&gt;discovery.zen.ping.unicast.hosts配置了几个gossip路由的node。&lt;/li&gt;
&lt;li&gt;所有node都可以发送ping消息到路由node，再从路由node获取cluster state回来。&lt;/li&gt;
&lt;li&gt;所有node执行master选举。&lt;/li&gt;
&lt;li&gt;所有node都会跟master进行通信，然后加入master的集群。&lt;/li&gt;
&lt;/ol&gt;&lt;h4 id=&quot;master选举&quot;&gt;master选举&lt;/h4&gt;
&lt;p&gt;node.master设置为true的，将成为master eligible node，也叫master候选节点，只有master eligible node才能被选举成master node。如果是个小集群，那么所有节点都可以是master eligible node，10个节点以上的集群，可以考虑拆分master node和data node，一般建议master eligible node给3个即可。&lt;/p&gt;
&lt;p&gt;master选举过程是自动完成的，有几个参数可以影响选举的过程：&lt;/p&gt;
&lt;ul readability=&quot;4.5&quot;&gt;&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;discovery.zen.ping_timeout: 选举超时时间，默认3秒，网络状况不好时可以增加超时时间。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;discovery.zen.join_timeout: 有新的node加入集群时，会发送一个join request到master node，同样因为网络原因可以调大，如果一次超时，默认最多重试20次。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;1&quot;&gt;
&lt;p&gt;discovery.zen.master_election.ignore_non_master_pings：如果master node意外宕机了，集群进行重新选举，如果此值为true，那么只有master eligible node才有资格被选为master。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;2&quot;&gt;
&lt;p&gt;discovery.zen.minimum_master_nodes: 新选举master时，要求必须有多少个 master eligible node去连接那个新选举的master。而且还用于设置一个集群中必须拥有的master eligible node。如果这些要求没有被满足，那么master node就会被停止，然后会重新选举一个新的master。这个参数必须设置为我们的master eligible node的quorum数量。一般避免说只有两个master eligible node，因为2的quorum还是2。如果在那个情况下，任何一个master候选节点宕机了，集群就无法正常运作了。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;h4 id=&quot;集群故障探查&quot;&gt;集群故障探查&lt;/h4&gt;
&lt;p&gt;有两种集群故障探查机制&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;master主动对集群中所有的其他node发起ping命令，判断它们是否是存活着的。&lt;/li&gt;
&lt;li&gt;每个node向master node发送ping请求，判断master node是否存活，否则就会发起一个选举过程。&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;有下面三个参数用来配置集群故障的探查过程：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;ping_interval：ping一次node的间隔时间，默认是1s&lt;/li&gt;
&lt;li&gt;ping_timeout：每次ping的timeout等待时长，默认是30s&lt;/li&gt;
&lt;li&gt;ping_retries：对node的ping请求失败了，重试次数，默认3次。&lt;/li&gt;
&lt;/ul&gt;&lt;h4 id=&quot;集群状态更新&quot;&gt;集群状态更新&lt;/h4&gt;
&lt;p&gt;master node是集群中唯一可以对cluster state进行更新的node。更新的步骤如下：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;master node收到更新事件，如shard移动，可能会有多条事件，但master node一次只处理一个集群状态的更新事件。&lt;/li&gt;
&lt;li&gt;master node将事件更新到本地，并发布publish message到集群所有的node上。&lt;/li&gt;
&lt;li&gt;node接收publish message后，对这个message返回ack响应，但是不会立即更新。&lt;/li&gt;
&lt;li&gt;如果master没有在指定的时间内（discovery.zen.commit_timeout配置项，默认是30s），从至少N个节点（discovery.zen.minimum_master_nodes配置项）获取ack响应，那么这次cluster state change事件就会被reject，最终不会被提交。&lt;/li&gt;
&lt;li&gt;如果在指定时间内，指定数量的node都返回了ack消息，那么cluster state就会被commit，然后master node把 commit message发送给所有的node。所有的node接收到那个commit message之后，接着才会将之前接收到的集群状态应用到自己本地的状态副本中去。&lt;/li&gt;
&lt;li&gt;master会等待所有node的commit message 的ack消息，在一个等待超时时长内，如果接收到了响应，表示状态更新成功，master node继续处理内存queue中保存的下一个更新事件。&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;discovery.zen.publish_timeout默认是30s，这个超时等待时长是从plublish cluster state开始计算的。&lt;/p&gt;
&lt;p&gt;我们可以参照此图：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://imgkr.cn-bj.ufileos.com/b296199f-a391-4304-a2b4-2ed4ea09680b.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;h4 id=&quot;master-node宕机问题&quot;&gt;master node宕机问题&lt;/h4&gt;
&lt;p&gt;Elasticsearch集群中，master node扮演着非常重要的角色，如果master node宕机了，那岂不是群龙无首了？虽然有master选举，但这个也是要时间的，没有master node那段空档期集群该怎么办？&lt;/p&gt;
&lt;p&gt;说了一半，基本上是完了，但我们也可以设置，群龙无首时哪些操作可以做，哪些操作不能做。&lt;/p&gt;
&lt;p&gt;discovery.zen.no_master_block配置项可以控制在群龙无首时的策略：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;all: 一旦master宕机，那么所有的操作都会被拒绝。&lt;/li&gt;
&lt;li&gt;write：默认的选项，所有写操作都会被拒绝，但是读操作是被允许的。&lt;/li&gt;
&lt;/ul&gt;&lt;h4 id=&quot;split-brain脑分裂问题&quot;&gt;split-brain(脑分裂问题)&lt;/h4&gt;
&lt;p&gt;在Elasticsearch集群中，master node非常重要，并且只有一个，相当于整个集群的大脑，控制将整个集群状态的更新，如果Elasticsearch集群节点之间出现区域性的网络中断，比如10个节点的Elasticsearch集群，4台node部署在机房A区，6台node部署在机房B区，如果A区与B区的交换机故障，导致两个区隔离开来了，那么没有master node的那个区，会触发master选举，如果选举了新的master，那么整个集群就会出现两个master node，这种现象叫做脑分裂。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://imgkr.cn-bj.ufileos.com/d4baf564-2f42-4b25-ba96-51d98edac4b3.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;这样现象很严重，会破坏集群的数据，该如何避免呢？&lt;/p&gt;
&lt;p&gt;回到我们前面提到的&lt;code&gt;discovery.zen.minimum_master_nodes&lt;/code&gt;参数，这个值的正确设置，可以避免上述的脑分裂问题。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;discovery.zen.minimum_master_nodes&lt;/code&gt;参数表示至少需要多少个master eligible node，才可以成功地选举出master，否则不进行选举。&lt;/p&gt;
&lt;p&gt;足够的master eligible node计算公式：&lt;/p&gt;
&lt;p&gt;&lt;code&gt;quorum = master_eligible_nodes / 2 + 1&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;如上图我们10个node的集群，如果全部是master eligible node，那么quorum = 10/2 + 1 = 6。&lt;/p&gt;
&lt;p&gt;如果我们有3个master eligible node，7个data node，那么quorum = 3/2 + 1 = 2。&lt;/p&gt;
&lt;p&gt;如果集群只有2个节点，并且全是master eligible node，那么quorum = 2/2 + 1 = 2，问题就来了，如果随便一个node宕机，在只剩下一个node情况下，无法满足quorum的值，master永远选举不成功，集群就彻底无法写入了，所以只能设置成1，后果是只要这两个node之间网络断了，就会发生脑分裂的现象。&lt;/p&gt;
&lt;p&gt;所以一个Elasticsearch集群至少得有3个node，全部为master eligible node的话，quorum = 3/2 + 1 = 2。如果我们设置minimum_master_nodes=2，分析一下会不会出现脑分裂的问题。&lt;/p&gt;
&lt;p&gt;场景一：A区一个node，为master，B区两个node，为master eligible node&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://imgkr.cn-bj.ufileos.com/80cdc4b1-07f3-4627-8d29-7fa4df226ac9.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;A区因为只剩下一个node，无法满足quorum的条件，此时master取消当前的master角色，且无法选举成功。&lt;/p&gt;
&lt;p&gt;B区两个master eligible node，满足quorum条件，成功选举出master。&lt;/p&gt;
&lt;p&gt;此时集群还是只有一个master，待网络故障恢复后，集群数据正常。&lt;/p&gt;
&lt;p&gt;场景二：A区一个node，为master eligible node，B区2个node，其中一个是master&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://imgkr.cn-bj.ufileos.com/e217630d-6cd7-451d-a46d-fc77d684f202.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;A区只有一个master eligible node，不满足quorum的条件，无法进行选举。&lt;/p&gt;
&lt;p&gt;B区原本的master存在，不需要进行选举，并且满quorum的条件，master角色可以保留。&lt;/p&gt;
&lt;p&gt;此时集群还是一个master，正常。&lt;/p&gt;
&lt;p&gt;综上所述：3个节点的集群，全部为master eligible node，配置discovery.zen.minimum_master_nodes: 2，就可以避免脑裂问题的产生。&lt;/p&gt;
&lt;h5 id=&quot;minimum_master_nodes动态修改&quot;&gt;minimum_master_nodes动态修改&lt;/h5&gt;
&lt;p&gt;因为集群是可以动态增加和下线节点的，quorum的值也会跟着改变。minimum_master_nodes参数值需要通过api随时修改的，特别是在节点上线和下线的时候，都需要作出对应的修改。而且一旦修改过后，这个配置就会持久化保存下来。&lt;/p&gt;
&lt;p&gt;修改api请求如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;PUT /_cluster/settings
{
    &quot;persistent&quot; : {
        &quot;discovery.zen.minimum_master_nodes&quot; : 2
    }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;响应报文：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;{
  &quot;acknowledged&quot;: true,
  &quot;persistent&quot;: {
    &quot;discovery&quot;: {
      &quot;zen&quot;: {
        &quot;minimum_master_nodes&quot;: &quot;2&quot;
      }
    }
  },
  &quot;transient&quot;: {}
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;也可以通过命令查询当前的配置：&lt;/p&gt;
&lt;p&gt;&lt;code&gt;GET /_cluster/settings&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;响应结果如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;{
  &quot;persistent&quot;: {
    &quot;discovery&quot;: {
      &quot;zen&quot;: {
        &quot;minimum_master_nodes&quot;: &quot;1&quot;
      }
    }
  },
  &quot;transient&quot;: {}
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;h5 id=&quot;留一个问题&quot;&gt;留一个问题&lt;/h5&gt;
&lt;p&gt;上图10个节点的集群，假设全是master eligible node，按照上述的网络故障，会不会出现脑分裂现象 ？配置项minimum_master_nodes最低要配置成多少，才不会出现脑分裂的问题？&lt;/p&gt;
&lt;h3 id=&quot;小结&quot;&gt;小结&lt;/h3&gt;
&lt;p&gt;本篇主要介绍了Elasticsearch集群的部署和参数设置等知识，大部分都不需要人工干预，默认值已经是最优选，集群发现机制和master选举机制了解一下就OK。&lt;/p&gt;
&lt;p&gt;专注Java高并发、分布式架构，更多技术干货分享与心得，请关注公众号：Java架构社区&lt;br/&gt;可以扫左边二维码添加好友，邀请你加入Java架构社区微信群共同探讨技术&lt;br/&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1834889/202003/1834889-20200303074927076-1724862603.jpg&quot; alt=&quot;Java架构社区&quot;/&gt;&lt;/p&gt;
</description>
<pubDate>Fri, 29 May 2020 23:38:00 +0000</pubDate>
<dc:creator>清茶豆奶</dc:creator>
<og:description>本篇开始介绍Elasticsearch生产集群的搭建及相关参数的配置</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/huangying2124/p/12990693.html</dc:identifier>
</item>
<item>
<title>NetCore项目实战篇08---Docker挂载mysql并连接.netCoreWeb - zhengwei_cq</title>
<link>http://www.cnblogs.com/zhengwei-cq/p/12917965.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/zhengwei-cq/p/12917965.html</guid>
<description>&lt;p&gt;我们的项目之前在直接连接的mysql,今天我们将通过docker挂载mysql 并与我们开发的webapi项目连接。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;1、&lt;/strong&gt; &lt;strong&gt;安装docker&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;下载地址：&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://download.docker.com/win/stable/Docker%20for%20Windows%20Installer.exe&quot;&gt;https://download.docker.com/win/stable/Docker%20for%20Windows%20Installer.exe&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;下载后直接点下一步就可完成安装，或参见：&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.cnblogs.com/stilldream/p/10627831.html&quot;&gt;https://www.cnblogs.com/stilldream/p/10627831.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2、&lt;/strong&gt; &lt;strong&gt;安装完成后查看版本：docker –version&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1109435/202005/1109435-20200519163846830-1265698703.png&quot; alt=&quot;&quot;/&gt;&lt;/strong&gt;&lt;/p&gt;


&lt;p&gt;&lt;strong&gt;3、&lt;/strong&gt; &lt;strong&gt;设置一下镜像仓库吧，点击桌面右下角下的docer&lt;/strong&gt;&lt;strong&gt;小图标，右键settings&lt;/strong&gt;&lt;strong&gt;进入：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;加入&lt;a href=&quot;http://hub-mirror.c.163.com/&quot;&gt;http://hub-mirror.c.163.com&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1109435/202005/1109435-20200519163918795-1829818473.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;


&lt;p&gt;4、  下载mysql 镜像。&lt;/p&gt;
&lt;p&gt;进入cmd 输入命令：docker pull  mysql&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1109435/202005/1109435-20200519163946333-930368560.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;


&lt;p&gt;&lt;strong&gt;5、等待所有的都下载完成后启动mysql&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;docker run -d -p 3306:3306 --name mysql01 mysql/mysql-server&lt;/p&gt;
&lt;p&gt;启动后可以用命令：docker ps  查看到运行的容器。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;6、获取root初始密码：docker logs mysql01&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;复制密码：UP0jkovbOtj3mxEJLyvJeRasIL#&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1109435/202005/1109435-20200519164018356-1093428972.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;


&lt;p&gt;&lt;strong&gt;7、进入docker中的mysql&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Docker exec –it mysql01 bash&lt;/p&gt;
&lt;p&gt;如果报错：OCI runtime exec failed:xxx&lt;/p&gt;
&lt;p&gt;可用：Docker exec -it mysql01 /bin/sh 命令进入&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1109435/202005/1109435-20200519164049577-986138093.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;


&lt;p&gt;&lt;strong&gt;8、再输入：mysql –uroot –p&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;会提示我们修改密码：将之前复制的密码右键就可粘贴，回车，会要我们修改密码&lt;/p&gt;
&lt;p&gt;使用：SET  PASSWORD  FOR 'root'@'localhost'=PASSWORD('1230');&lt;/p&gt;
&lt;p&gt;如果不行可能是版本问题，mysql8.0以上就用命令：alter user 'root'@'localhost' identified by '1230';&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;9、修改成功后我们最好不要用root用户，来创建一个自己的用户吧：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Create user 'zhengwei'@'localhost' identified by '1230';&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1109435/202005/1109435-20200519164148646-1677397890.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;


&lt;p&gt;&lt;strong&gt;10、查看用户是否创建成功：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;select user,host from user  或者用  select user,host from mysql.user&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1109435/202005/1109435-20200519164220459-2104911288.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;


&lt;p&gt;11、改成任意主机都可以访问的吧：&lt;/p&gt;
&lt;p&gt;update user set host='%' where user = 'zhengwei';&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1109435/202005/1109435-20200519164231657-1791201109.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;


&lt;p&gt;12、同样我的是mysql8.0以上，用以下的sql给用户赋予所有权限:&lt;/p&gt;
&lt;p&gt;grant all privileges on *.* to 'zhengwei'@'%' with grant option;&lt;/p&gt;
&lt;p&gt;13、使用navicat连接一下我们的mysql，由于我本机之前是装了mysql，为了防止冲突，使用exit退出后，执行net stop mysql&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1109435/202005/1109435-20200519164243070-498720889.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;


&lt;p&gt;连接时会报错：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1109435/202005/1109435-20200519164256411-612169670.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;


&lt;p&gt;14、是权限的问题，再次进入mysql 如何再将进去，请看上面吧，然后刷新权限：刷新权限：FLUSH PRIVILEGES，再次连接 ，还是报错：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1109435/202005/1109435-20200519164309485-1189397575.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;


&lt;p&gt;&lt;strong&gt;原因：&lt;/strong&gt;mysql 8.0 默认使用 caching_sha2_password 身份验证机制；客户端不支持新的加密方式。&lt;/p&gt;
&lt;p&gt;修改用户（zhengwei）的加密方式：&lt;/p&gt;
&lt;p&gt;先查看所有用户的加密方式：&lt;/p&gt;
&lt;p&gt;select host,user,plugin,authentication_string from mysql.user&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1109435/202005/1109435-20200519164330835-1455439450.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;


&lt;p&gt;将zhengwei的加密方式修改为mysql_native_password&lt;/p&gt;
&lt;p&gt;ALTER USER 'zhengwei'@'%' IDENTIFIED WITH mysql_native_password BY '1230';&lt;/p&gt;
&lt;p&gt;再次连接，终于完美解决，爽：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1109435/202005/1109435-20200519164344291-798352446.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;


&lt;p&gt;15、docker中已安装好了mysql,那就用我们之前开发的webapi连接这个mysql吧。&lt;/p&gt;
&lt;p&gt;16、打开之前创建的.netcore webapi项目(&lt;a href=&quot;https://www.cnblogs.com/zhengwei-cq/p/12810754.html&quot; target=&quot;_blank&quot;&gt;NetCore项目实战篇01---EFCore CodeFirst For Mysql 数据库初始化&lt;/a&gt;)，修改mysql连接&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1109435/202005/1109435-20200519164401428-361217577.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;


&lt;p&gt;17、VS中选择工具-&amp;gt;NuGet包管理器-&amp;gt;程序包管理器控制台。&lt;/p&gt;
&lt;p&gt;输入命令：Update-Database&lt;/p&gt;
&lt;p&gt;记得默认项目要选zhengwei.Use.Api&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1109435/202005/1109435-20200519164413442-1708024379.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt; 执行完成后我们用&lt;span lang=&quot;EN-US&quot;&gt;navicat看看数据库中也生成成功了。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1109435/202005/1109435-20200519164425921-956922154.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;


&lt;p&gt;如果在执行时失败，可能是因为用户的权限问题，我们要回到命令行停止当前的mysql:&lt;/p&gt;
&lt;p&gt;命令：docker stop mysql01   再删除：docker rm mysql01&lt;/p&gt;
&lt;p&gt;通过在启动时加环境变量，因为我们前面已创建了zhengwei这个用户就直接用这个用户启动：&lt;/p&gt;
&lt;p&gt;docker run -d -p 3306:3306 -e MYSQL_USER=&quot;zhengwei&quot; -e MYSQL_PASSWORD=&quot;1230&quot; -e MYSQL_ROOT_PASSWORD=&quot;1230&quot;  --name mysql01 mysql/mysql-server --character-set-server=utf8 --collation-server=utf8_general_ci&lt;/p&gt;

&lt;p&gt;然后再给用户授所有的权，都按上面的顺序来就可以了。&lt;/p&gt;
&lt;p&gt;18、打开&lt;span lang=&quot;EN-US&quot;&gt;postman访问我们的&lt;span lang=&quot;EN-US&quot;&gt;webapi也是成功的，&lt;/span&gt;&lt;/span&gt;此时我们连接的&lt;span lang=&quot;EN-US&quot;&gt;mysql是&lt;span lang=&quot;EN-US&quot;&gt;docker容器中运行的&lt;span lang=&quot;EN-US&quot;&gt;mysql&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span lang=&quot;EN-US&quot;&gt;&lt;span lang=&quot;EN-US&quot;&gt;，如下图：&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1109435/202005/1109435-20200519211816769-76201247.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

</description>
<pubDate>Fri, 29 May 2020 22:55:00 +0000</pubDate>
<dc:creator>zhengwei_cq</dc:creator>
<og:description>我们的项目之前在直接连接的mysql,今天我们将通过docker挂载mysql 并与我们开发的webapi项目连接。 1、 安装docker 下载地址： https://download.docker</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/zhengwei-cq/p/12917965.html</dc:identifier>
</item>
<item>
<title>Alink漫谈(五) : 迭代计算和Superstep - 罗西的思考</title>
<link>http://www.cnblogs.com/rossiXYZ/p/12990632.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/rossiXYZ/p/12990632.html</guid>
<description>&lt;p&gt;Alink 是阿里巴巴基于实时计算引擎 Flink 研发的新一代机器学习算法平台，是业界首个同时支持批式算法、流式算法的机器学习平台。迭代算法在很多数据分析领域会用到，比如机器学习或者图计算。本文将通过Superstep入手看看Alink是如何利用Flink迭代API来实现具体算法。&lt;/p&gt;&lt;div id=&quot;cnblogs_post_body&quot; readability=&quot;501.43276422764&quot;&gt;


&lt;h2 id=&quot;0x00-摘要&quot;&gt;0x00 摘要&lt;/h2&gt;
&lt;p&gt;Alink 是阿里巴巴基于实时计算引擎 Flink 研发的新一代机器学习算法平台，是业界首个同时支持批式算法、流式算法的机器学习平台。迭代算法在很多数据分析领域会用到，比如机器学习或者图计算。本文将通过Superstep入手看看Alink是如何利用Flink迭代API来实现具体算法。&lt;/p&gt;
&lt;p&gt;因为Alink的公开资料太少，所以以下均为自行揣测，肯定会有疏漏错误，希望大家指出，我会随时更新。&lt;/p&gt;
&lt;h2 id=&quot;0x01-缘由&quot;&gt;0x01 缘由&lt;/h2&gt;
&lt;p&gt;为什么提到 Superstep 这个概念，是因为在撸KMeans代码的时候，发现几个很奇怪的地方，比如以下三个步骤中，都用到了context.getStepNo()，而且会根据其数值的不同进行不同业务操作：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;public class KMeansPreallocateCentroid extends ComputeFunction {
    public void calc(ComContext context) {
        LOG.info(&quot;liuhao  KMeansPreallocateCentroid &quot;);
        if (context.getStepNo() == 1) {
          /** 具体业务逻辑代码
           * Allocate memory for pre-round centers and current centers.
           */        
        }
    }
}  

public class KMeansAssignCluster extends ComputeFunction {
    public void calc(ComContext context) {
        ......
        if (context.getStepNo() % 2 == 0) {
            stepNumCentroids = context.getObj(KMeansTrainBatchOp.CENTROID1);
        } else {
            stepNumCentroids = context.getObj(KMeansTrainBatchOp.CENTROID2);
        }
      /** 具体业务逻辑代码
       * Find the closest cluster for every point and calculate the sums of the points belonging to the same cluster.
       */
    }
}

public class KMeansUpdateCentroids extends ComputeFunction {
    public void calc(ComContext context) {
        if (context.getStepNo() % 2 == 0) {
            stepNumCentroids = context.getObj(KMeansTrainBatchOp.CENTROID2);
        } else {
            stepNumCentroids = context.getObj(KMeansTrainBatchOp.CENTROID1);
        }
      /** 具体业务逻辑代码
       * Update the centroids based on the sum of points and point number belonging to the same cluster.
       */
    }
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;查看ComContext的源码，发现stepNo的来源居然是&lt;code&gt;runtimeContext.getSuperstepNumber()&lt;/code&gt;。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;public class ComContext {
   private final int taskId;
   private final int numTask;
   private final int stepNo; // 对，就是这里
   private final int sessionId;
        public ComContext(int sessionId, IterationRuntimeContext runtimeContext) {
                this.sessionId = sessionId;
                this.numTask = runtimeContext.getNumberOfParallelSubtasks();
                this.taskId = runtimeContext.getIndexOfThisSubtask();
                this.stepNo = runtimeContext.getSuperstepNumber(); // 这里进行了变量初始化
        }  
        /**
         * Get current iteration step number, the same as {@link IterationRuntimeContext#getSuperstepNumber()}.
         * @return iteration step number.
         */
        public int getStepNo() {
                return stepNo; // 这里是使用
        }  
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;看到这里有的兄弟可能会虎躯一震，&lt;u&gt;&lt;em&gt;这不是BSP模型的概念嘛。我就是想写个KMeans算法，怎么除了MPI模型，还要考虑BSP模型&lt;/em&gt;&lt;/u&gt;。下面就让我们一步一步挖掘究竟Alink都做了什么工作。&lt;/p&gt;
&lt;h2 id=&quot;0x02-背景概念&quot;&gt;0x02 背景概念&lt;/h2&gt;
&lt;h3 id=&quot;21-四层执行图&quot;&gt;2.1 四层执行图&lt;/h3&gt;
&lt;p&gt;在 Flink 中的执行图可以分为四层：StreamGraph -&amp;gt; JobGraph -&amp;gt; ExecutionGraph -&amp;gt; 物理执行图&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;StreamGraph：Stream API 编写的代码生成的最初的图。用来表示程序的拓扑结构。&lt;/li&gt;
&lt;li&gt;JobGraph：StreamGraph 经过优化后生成了 JobGraph， JobGraph是提交给 JobManager 的数据结构。主要的优化为，将多个符合条件的节点 chain 在一起作为一个节点，这样可以减少数据在节点之间流动所需要的序列化/反序列化/传输消耗。JobGraph是唯一被Flink的数据流引擎所识别的表述作业的数据结构，也正是这一共同的抽象体现了流处理和批处理在运行时的统一。&lt;/li&gt;
&lt;li&gt;ExecutionGraph：JobManager 根据 JobGraph 生成 ExecutionGraph。ExecutionGraph 是 JobGraph 的并行化版本，是调度层最核心的数据结构。&lt;/li&gt;
&lt;li&gt;物理执行图：JobManager 根据 ExecutionGraph 对 Job 进行调度后，在各个TaskManager 上部署 Task 后形成的“图”，并不是一个具体的数据结构。&lt;/li&gt;
&lt;/ul&gt;&lt;h3 id=&quot;22-task和subtask&quot;&gt;2.2 Task和SubTask&lt;/h3&gt;
&lt;p&gt;因为某种原因，Flink内部对这两个概念的使用本身就有些混乱：在Task Manager里这个subtask的概念由一个叫Task的类来实现。Task Manager里谈论的Task对象实际上对应的是ExecutionGraph里的一个subtask。&lt;/p&gt;
&lt;p&gt;所以这两个概念需要理清楚。&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;Task(任务) ：Task对应JobGraph的一个节点，是一个算子Operator。Task 是一个阶段多个功能相同 subTask 的集合，类似于 Spark 中的 TaskSet。&lt;/li&gt;
&lt;li&gt;subTask(子任务) ：subTask 是 Flink 中任务最小执行单元，是一个 Java 类的实例，这个 Java 类中有属性和方法，完成具体的计算逻辑。在ExecutionGraph里Task被分解为多个并行执行的subtask 。每个subtask作为一个excution分配到Task Manager里执行。&lt;/li&gt;
&lt;li&gt;Operator Chains(算子链) ：没有 shuffle 的多个算子合并在一个 subTask 中，就形成了 Operator Chains，类似于 Spark 中的 Pipeline。Operator subTask 的数量指的就是算子的并行度。同一程序的不同算子也可能具有不同的并行度（因为可以通过 setParallelism() 方法来修改并行度）。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;Flink 中的程序本质上是并行的。在执行期间，每一个算子 Operator (Transformation)都有一个或多个算子subTask（Operator SubTask），每个算子的 subTask 之间都是彼此独立，并在不同的线程中执行，并且可能在不同的机器或容器上执行。&lt;/p&gt;
&lt;p&gt;Task（ SubTask） 是一个Runnable 对象， Task Manager接受到TDD 后会用它实例化成一个Task对象， 并启动一个线程执行Task的Run方法。&lt;/p&gt;
&lt;p&gt;TaskDeploymentDescriptor(TDD) : 是Task Manager在submitTask是提交给TM的数据结构。 他包含了关于Task的所有描述信息。比如：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;TaskInfo : 包含该Task 执行的java 类，该类是某个 AbstractInvokable的实现类 ， 当然也是某个operator的实现类 （比如DataSourceTask, DataSinkTask, BatchTask,StreamTask 等）。&lt;/li&gt;
&lt;li&gt;IG描述 ：通常包含一个或两个InputGateDeploymentDescriptor（IGD)。&lt;/li&gt;
&lt;li&gt;目标RP的描述: ParitionId, PartitionType, RS个数等等。&lt;/li&gt;
&lt;/ul&gt;&lt;h3 id=&quot;23-如何划分-task-的依据&quot;&gt;2.3 如何划分 Task 的依据&lt;/h3&gt;
&lt;p&gt;在以下情况下会重新划分task&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;并行度发生变化时&lt;/li&gt;
&lt;li&gt;keyBy() /window()/apply() 等发生 Rebalance 重新分配;&lt;/li&gt;
&lt;li&gt;调用 startNewChain() 方法，开启一个新的算子链；&lt;/li&gt;
&lt;li&gt;调用 diableChaining()方法，即：告诉当前算子操作不使用 算子链 操作。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;比如有如下操作&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-scala&quot;&gt;DataStream&amp;lt;String&amp;gt; text = env.socketTextStream(hostname, port);

DataStream counts = text
    .filter(new FilterClass())
    .map(new LineSplitter())
    .keyBy(0)
    .timeWindow(Time.seconds(10))
    .sum(2)
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;那么StreamGraph的转换流是：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt; Source --&amp;gt; Filter --&amp;gt; Map --&amp;gt; Timestamps/Watermarks --&amp;gt; Window(SumAggregator) --&amp;gt; Sink
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;其task是四个：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;Source --&amp;gt; Filter --&amp;gt; Map&lt;/li&gt;
&lt;li&gt;keyBy&lt;/li&gt;
&lt;li&gt;timeWindow&lt;/li&gt;
&lt;li&gt;Sink&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;其中每个task又会被分成分若干subtask。在执行时，一个Task会被并行化成若干个subTask实例进行执行，一个subTask对应一个执行线程。&lt;/p&gt;
&lt;h3 id=&quot;24-jobgraph&quot;&gt;2.4 JobGraph&lt;/h3&gt;
&lt;p&gt;以上说了这么多，就是要说jobGraph和subtask，&lt;u&gt;因为本文中我们在分析源码和调试时候，主要是从jobGraph这里开始入手来看subtask&lt;/u&gt;。&lt;/p&gt;
&lt;p&gt;JobGraph是在StreamGraph的基础之上，对StreamNode进行了关联合并的操作，比如对于source -&amp;gt; flatMap -&amp;gt; reduce -&amp;gt; sink 这样一个数据处理链，当source和flatMap满足链接的条件时，可以可以将两个操作符的操作放到一个线程并行执行，这样可以减少网络中的数据传输，由于在source和flatMap之间的传输的数据也不用序列化和反序列化，所以也提高了程序的执行效率。&lt;/p&gt;
&lt;p&gt;相比流图（StreamGraph）以及批处理优化计划（OptimizedPlan），JobGraph发生了一些变化，已经不完全是“静态”的数据结构了，因为它加入了中间结果集（IntermediateDataSet）这一“动态”概念。&lt;/p&gt;
&lt;p&gt;作业顶点（JobVertex）、中间数据集（IntermediateDataSet）、作业边（JobEdge）是组成JobGraph的基本元素。这三个对象彼此之间互为依赖：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;一个JobVertex关联着若干个JobEdge作为输入端以及若干个IntermediateDataSet作为其生产的结果集；每个JobVertex都有诸如并行度和执行代码等属性。&lt;/li&gt;
&lt;li&gt;一个IntermediateDataSet关联着一个JobVertex作为生产者以及若干个JobEdge作为消费者；&lt;/li&gt;
&lt;li&gt;一个JobEdge关联着一个IntermediateDataSet可认为是源以及一个JobVertex可认为是目标消费者；&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;那么JobGraph是怎么组织并存储这些元素的呢？其实JobGraph只以Map的形式存储了所有的JobVertex，键是JobVertexID：&lt;/p&gt;
&lt;p&gt;&lt;code&gt;private final Map&amp;lt;JobVertexID, JobVertex&amp;gt; taskVertices = new LinkedHashMap&amp;lt;JobVertexID, JobVertex&amp;gt;();&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;至于其它的元素，通过JobVertex都可以根据关系找寻到。需要注意的是，用于迭代的反馈边（feedback edge）当前并不体现在JobGraph中，而是被内嵌在特殊的JobVertex中通过反馈信道（feedback channel）在它们之间建立关系。&lt;/p&gt;
&lt;h3 id=&quot;25-bsp模型和superstep&quot;&gt;2.5 BSP模型和Superstep&lt;/h3&gt;
&lt;h4 id=&quot;bsp模型&quot;&gt;BSP模型&lt;/h4&gt;
&lt;p&gt;BSP模型是并行计算模型的一种。并行计算模型通常指从并行算法的设计和分析出发，将各种并行计算机（至少某一类并行计算机）的基本特征抽象出来，形成一个抽象的计算模型。&lt;/p&gt;
&lt;p&gt;BSP模型是一种异步MIMD-DM模型（DM: distributed memory，SM: shared memory），BSP模型支持消息传递系统，&lt;u&gt;块内异步并行，块间显式同步&lt;/u&gt;，该模型基于一个master协调，所有的worker同步(lock-step)执行, 数据从输入的队列中读取。&lt;/p&gt;
&lt;p&gt;BSP计算模型不仅是一种体系结构模型，也是设计并行程序的一种方法。BSP程序设计准则是整体同步(bulk synchrony)，其独特之处在于超步(superstep)概念的引入。一个BSP程序同时具有水平和垂直两个方面的结构。从垂直上看,一个BSP程序由一系列串行的超步(superstep)组成。&lt;/p&gt;
&lt;h4 id=&quot;bsp模型的实现&quot;&gt;BSP模型的实现&lt;/h4&gt;
&lt;p&gt;BSP模型的实现大概举例如下：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Pregel&lt;/strong&gt; ：Google的大规模图计算框架，首次提出了将BSP模型应用于图计算，具体请看Pregel——大规模图处理系统，不过至今未开源。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Apache Giraph&lt;/strong&gt; ：ASF社区的Incubator项目，由Yahoo!贡献，是BSP的java实现，专注于迭代图计算（如pagerank，最短连接等），每一个job就是一个没有reducer过程的hadoop job。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Apache Hama&lt;/strong&gt; ：也是ASF社区的Incubator项目，与Giraph不同的是它是一个纯粹的BSP模型的java实现，并且不单单是用于图计算，意在提供一个通用的BSP模型的应用框架。&lt;/li&gt;
&lt;/ul&gt;&lt;h4 id=&quot;flink-gelly&quot;&gt;Flink-Gelly&lt;/h4&gt;
&lt;p&gt;Flink-Gelly利用Flink的高效迭代算子来支持海量数据的迭代式图处理。目前，Flink Gelly提供了“Vertex-Centric”，“Scatter-Gather”以及“Gather-Sum-Apply”等计算模型的实现。&lt;/p&gt;
&lt;p&gt;“Vertex-Centric”迭代模型也就是我们经常听到的“Pregel”，是一种从Vertex角度出发的图计算方式。其中，同步地迭代计算的步骤称之为“superstep”。在每个“superstep”中，每个顶点都执行一个用户自定义的函数，且顶点之间通过消息进行通信，当一个顶点知道图中其他任意顶点的唯一ID时，该顶点就可以向其发送一条消息。&lt;/p&gt;
&lt;p&gt;但是实际上，&lt;u&gt;KMeans不是图处理，Alink也没有基于Flink-Gelly来构建。也许只是借鉴了其概念。所以我们还需要再探寻。&lt;/u&gt;&lt;/p&gt;
&lt;h2 id=&quot;0x03-flink的迭代算法（superstep-based）&quot;&gt;0x03 Flink的迭代算法（superstep-based）&lt;/h2&gt;
&lt;p&gt;迭代算法在很多数据分析领域会用到，比如机器学习或者图计算。为了从大数据中抽取有用信息，这个时候往往会需要在处理的过程中用到迭代计算。&lt;/p&gt;
&lt;p&gt;所谓迭代运算，就是给定一个初值，用所给的算法公式计算初值得到一个中间结果，然后将中间结果作为输入参数进行反复计算，在满足一定条件的时候得到计算结果。&lt;/p&gt;
&lt;p&gt;大数据处理框架很多，比如spark，mr。实际上这些实现迭代计算都是很困难的。&lt;/p&gt;
&lt;p&gt;Flink直接支持迭代计算。Flink实现迭代的思路也是很简单，就是实现一个step函数，然后将其嵌入到迭代算子中去。有两种迭代操作算子: Iterate和Delta Iterate。两个操作算子都是在未收到终止迭代信号之前一直调用step函数。&lt;/p&gt;
&lt;h3 id=&quot;31-bulk-iterate&quot;&gt;3.1 Bulk Iterate&lt;/h3&gt;
&lt;p&gt;这种迭代方式称为全量迭代，它会将整个数据输入，经过一定的迭代次数，最终得到你想要的结果。&lt;/p&gt;
&lt;p&gt;迭代操作算子包括了简单的迭代形式：每次迭代，step函数会消费全量数据(本次输入和上次迭代的结果)，然后计算得到下轮迭代的输出(例如，map，reduce，join等)&lt;/p&gt;
&lt;p&gt;迭代过程主要分为以下几步：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;Iteration Input（迭代输入）：是初始输入值或者上一次迭代计算的结果。&lt;/li&gt;
&lt;li&gt;Step Function（step函数）：每次迭代都会执行step函数。它迭代计算DataSet，由一系列的operator组成，比如map，flatMap，join等，取决于具体的业务逻辑。&lt;/li&gt;
&lt;li&gt;Next Partial Solution（中间结果）：每一次迭代计算的结果，被发送到下一次迭代计算中。&lt;/li&gt;
&lt;li&gt;Iteration Result（迭代结果）：最后一次迭代输出的结果，被输出到datasink或者发送到下游处理。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;它迭代的结束条件是：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;达到最大迭代次数&lt;/li&gt;
&lt;li&gt;自定义收敛聚合函数&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;编程的时候，需要调用iterate(int),该函数返回的是一个IterativeDataSet，当然我们可以对它进行一些操作，比如map等。Iterate函数唯一的参数是代表最大迭代次数。&lt;/p&gt;
&lt;p&gt;迭代是一个环。我们需要进行闭环操作，那么这时候就要用到closeWith(Dataset)操作了，参数就是需要循环迭代的dataset。也可以可选的指定一个终止标准，操作closeWith(DataSet, DataSet)，可以通过判断第二个dataset是否为空，来终止迭代。如果不指定终止迭代条件，迭代就会在迭代了最大迭代次数后终止。&lt;/p&gt;
&lt;h3 id=&quot;32-迭代机制&quot;&gt;3.2 迭代机制&lt;/h3&gt;
&lt;p&gt;DataSet API引进了独特的同步迭代机制（superstep-based），仅限于用在有界的流。&lt;/p&gt;
&lt;p&gt;我们将迭代操作算子的每个步骤函数的执行称为单个迭代。在并行设置中，在迭代状态的不同分区上并行计算step函数的多个实例。在许多设置中，对所有并行实例上的step函数的一次评估形成了所谓的superstep，这也是同步的粒度。因此，迭代的所有并行任务都需要在初始化下一个superstep之前完成superstep。终止准则也将被评估为superstep&lt;em&gt;同步&lt;/em&gt;屏障。&lt;/p&gt;
&lt;p&gt;下面是Apache原文&lt;/p&gt;
&lt;blockquote readability=&quot;13&quot;&gt;
&lt;p&gt;We referred to each execution of the step function of an iteration operator as &lt;em&gt;a single iteration&lt;/em&gt;. In parallel setups, &lt;strong&gt;multiple instances of the step function are evaluated in parallel&lt;/strong&gt; on different partitions of the iteration state. In many settings, one evaluation of the step function on all parallel instances forms a so called &lt;strong&gt;superstep&lt;/strong&gt;, which is also the granularity of synchronization. Therefore, &lt;em&gt;all&lt;/em&gt; parallel tasks of an iteration need to complete the superstep, before a next superstep will be initialized. &lt;strong&gt;Termination criteria&lt;/strong&gt; will also be evaluated at superstep barriers.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;下面是apache原图&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://ci.apache.org/projects/flink/flink-docs-release-1.10/fig/iterations_supersteps.png&quot; alt=&quot;Supersteps&quot;/&gt;&lt;/p&gt;
&lt;p&gt;概括如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;每次迭代都是一个superstep
    每次迭代中有若干subtask在不同的partition上分别执行step
         每个step有一个HeadTask，若干IntermediateTask，一个TailTask
    每个superstep有一个SynchronizationSinkTask 同步，因为迭代的所有并行任务需要在下一个迭代前完成
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;u&gt;由此我们可以知道，superstep这是Flink DataSet API的概念，但是你从这里能够看到BSP模型的影子&lt;/u&gt;，比如：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;在传统的BSP模型中，一个superstep被分为3步： 本地的计算， 消息的传递， 同步的barrier.&lt;/li&gt;
&lt;li&gt;Barrier Synchronization又叫障碍同步或栅栏同步。每一次同步也是一个超步的完成和下一个超步的开始；&lt;/li&gt;
&lt;li&gt;Superstep超步 是一次计算迭代，从起始每往前步进一层对应一个超步。&lt;/li&gt;
&lt;li&gt;程序该什么时候结束是程序自己控制&lt;/li&gt;
&lt;/ul&gt;&lt;h2 id=&quot;0x04-alink如何使用迭代&quot;&gt;0x04 Alink如何使用迭代&lt;/h2&gt;
&lt;p&gt;KMeansTrainBatchOp.iterateICQ函数中，生成了一个IterativeComQueue，而IterativeComQueue之中就用到了superstep-based迭代。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;return new IterativeComQueue()
   .initWithPartitionedData(TRAIN_DATA, data)
   .initWithBroadcastData(INIT_CENTROID, initCentroid)
   .initWithBroadcastData(KMEANS_STATISTICS, statistics)
   .add(new KMeansPreallocateCentroid())
   .add(new KMeansAssignCluster(distance))
   .add(new AllReduce(CENTROID_ALL_REDUCE))
   .add(new KMeansUpdateCentroids(distance))
   .setCompareCriterionOfNode0(new KMeansIterTermination(distance, tol)) // 终止条件
   .closeWith(new KMeansOutputModel(distanceType, vectorColName, latitudeColName, longitudeColName)) 
   .setMaxIter(maxIter) // 迭代最大次数
   .exec();
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;而BaseComQueue.exec函数中则有：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;public DataSet&amp;lt;Row&amp;gt; exec() {
   IterativeDataSet&amp;lt;byte[]&amp;gt; loop // Flink 迭代API
      = loopStartDataSet(executionEnvironment)
      .iterate(maxIter);
     // 后续操作能看出来，之前添加在queue上的比如KMeansPreallocateCentroid，都是在loop之上运行的。
                if (null == compareCriterion) {
        loopEnd = loop.closeWith...
        } else {     
        // compare Criterion.
        DataSet&amp;lt;Boolean&amp;gt; criterion = input ... compareCriterion
        loopEnd = loop.closeWith( ... criterion ... )
      }   
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;再仔细研究代码，我们可以看出：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;superstep&lt;/strong&gt;包括：&lt;/p&gt;
&lt;p&gt;.add(new KMeansPreallocateCentroid())&lt;br/&gt;.add(new KMeansAssignCluster(distance))&lt;br/&gt;.add(new AllReduce(CENTROID_ALL_REDUCE))&lt;br/&gt;.add(new KMeansUpdateCentroids(distance))&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;终止标准&lt;/strong&gt;就是&lt;/p&gt;
&lt;p&gt;利用KMeansIterTermination构建了一个RichMapPartitionFunction作为终止标准。最后结束时候调用 KMeansOutputModel完成业务操作。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;最大循环&lt;/strong&gt;就是&lt;/p&gt;
&lt;p&gt;.setMaxIter(maxIter)&lt;/p&gt;
&lt;p&gt;于是我们可以得出结论，&lt;em&gt;&lt;u&gt;&lt;strong&gt;superstep-based Bulk Iterate 迭代算子是用来实现整体KMeans算法，KMeans算法就是一个superstep进行迭代。但是在superstep内容如果需要通讯或者栅栏同步，则采用了MPI的allReduce。&lt;/strong&gt;&lt;/u&gt;&lt;/em&gt;&lt;/p&gt;
&lt;h2 id=&quot;0x05-深入flink源码和runtime来验证&quot;&gt;0x05 深入Flink源码和runtime来验证&lt;/h2&gt;
&lt;p&gt;我们需要深入到Flink内部去挖掘验证，如果大家有兴趣，可以参见下面调用栈，自己添加断点来研究。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;execute:56, LocalExecutor (org.apache.flink.client.deployment.executors)
executeAsync:944, ExecutionEnvironment (org.apache.flink.api.java)
execute:860, ExecutionEnvironment (org.apache.flink.api.java)
execute:844, ExecutionEnvironment (org.apache.flink.api.java)
collect:413, DataSet (org.apache.flink.api.java)
sinkFrom:44, PrintBatchOp (com.alibaba.alink.operator.batch.utils)
sinkFrom:20, PrintBatchOp (com.alibaba.alink.operator.batch.utils)
linkFrom:31, BaseSinkBatchOp (com.alibaba.alink.operator.batch.sink)
linkFrom:17, BaseSinkBatchOp (com.alibaba.alink.operator.batch.sink)
link:89, BatchOperator (com.alibaba.alink.operator.batch)
linkTo:239, BatchOperator (com.alibaba.alink.operator.batch)
print:337, BatchOperator (com.alibaba.alink.operator.batch)
main:35, KMeansExample (com.alibaba.alink)
&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;51-向flink提交job&quot;&gt;5.1 向Flink提交Job&lt;/h3&gt;
&lt;p&gt;Alink和Flink构建联系，是在print调用中完成的。因为是本地调试，Flink会启动一个miniCluster，然后会做如下操作。&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;首先生成执行计划Plan。Plan以数据流形式来表示批处理程序，但它只是批处理程序最初的表示，然后计划会被优化以生成更高效的方案OptimizedPlan。&lt;/li&gt;
&lt;li&gt;然后，计划被编译生成JobGraph。这个图是要交给flink去生成task的图。&lt;/li&gt;
&lt;li&gt;生成一系列配置。&lt;/li&gt;
&lt;li&gt;将JobGraph和配置交给flink集群去运行。如果不是本地运行的话，还会把jar文件通过网络发给其他节点。&lt;/li&gt;
&lt;li&gt;以本地模式运行的话，可以看到启动过程，如启动性能度量、web模块、JobManager、ResourceManager、taskManager等等。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;当我们看到了&lt;code&gt;submitJob&lt;/code&gt;调用，就知道&lt;u&gt;KMeans代码已经和Flink构建了联系&lt;/u&gt;。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;@Internal
public class LocalExecutor implements PipelineExecutor {

   public static final String NAME = &quot;local&quot;;

   @Override
   public CompletableFuture&amp;lt;JobClient&amp;gt; execute(Pipeline pipeline, Configuration configuration) throws Exception {

      // we only support attached execution with the local executor.
      checkState(configuration.getBoolean(DeploymentOptions.ATTACHED));

      final JobGraph jobGraph = getJobGraph(pipeline, configuration);
      final MiniCluster miniCluster = startMiniCluster(jobGraph, configuration);
      final MiniClusterClient clusterClient = new MiniClusterClient(configuration, miniCluster);

      CompletableFuture&amp;lt;JobID&amp;gt; jobIdFuture = clusterClient.submitJob(jobGraph);

      jobIdFuture
            .thenCompose(clusterClient::requestJobResult)
            .thenAccept((jobResult) -&amp;gt; clusterClient.shutDownCluster());

      return jobIdFuture.thenApply(jobID -&amp;gt;
            new ClusterClientJobClientAdapter&amp;lt;&amp;gt;(() -&amp;gt; clusterClient, jobID));
   }
&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;52-生成jobgraph&quot;&gt;5.2 生成JobGraph&lt;/h3&gt;
&lt;p&gt;生成jobGraph的具体流程是：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;IterativeDataSet.closeWith会生成一个BulkIterationResultSet。&lt;/li&gt;
&lt;li&gt;PrintBatchOp.sinkFrom中会调用到ExecutionEnvironment.executeAsync&lt;/li&gt;
&lt;li&gt;调用createProgramPlan构建一个Plan&lt;/li&gt;
&lt;li&gt;OperatorTranslation.translate函数发现&lt;code&gt;if (dataSet instanceof BulkIterationResultSet)&lt;/code&gt;，则调用&lt;code&gt;translateBulkIteration(bulkIterationResultSet);&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;这时候生成了执行计划Plan&lt;/li&gt;
&lt;li&gt;ExecutionEnvironment.executeAsync调用LocalExecutor.execute&lt;/li&gt;
&lt;li&gt;然后调用FlinkPipelineTranslationUtil.getJobGraph来生成jobGraph&lt;/li&gt;
&lt;li&gt;GraphCreatingVisitor.preVisit中会判断 &lt;code&gt;if (c instanceof BulkIterationBase)&lt;/code&gt;，以生成BulkIterationNode&lt;/li&gt;
&lt;li&gt;PlanTranslator.translateToJobGraph会调用到JobGraphGenerator.compileJobGraph，最终调用到createBulkIterationHead就生成了迭代处理的Head。&lt;/li&gt;
&lt;li&gt;最后将jobGraph提交给Cluster ,jobGraph 变形为 ExceutionGraph在JM和TM上执行。&lt;/li&gt;
&lt;/ul&gt;&lt;h3 id=&quot;53-迭代对应的task&quot;&gt;5.3 迭代对应的Task&lt;/h3&gt;
&lt;p&gt;前面代码中，getJobGraph函数作用是生成了job graph。&lt;/p&gt;
&lt;p&gt;然后 JobManager 根据 JobGraph 生成 ExecutionGraph。ExecutionGraph 是 JobGraph 的并行化版本，是调度层最核心的数据结构。&lt;/p&gt;
&lt;p&gt;最后 JobManager 根据 ExecutionGraph 对 Job 进行调度后，在各个TaskManager 上部署 Task。&lt;/p&gt;
&lt;p&gt;所以我们需要看看最终运行时候，迭代API对应着哪些Task。&lt;/p&gt;
&lt;p&gt;针对IterativeDataSet，即superstep-based Bulk Iterate，Flink生成了如下的task。&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;IterationHeadTask&lt;/li&gt;
&lt;li&gt;IterationIntermediateTask&lt;/li&gt;
&lt;li&gt;IterationTailTask&lt;/li&gt;
&lt;li&gt;IterationSynchronizationSinkTask&lt;/li&gt;
&lt;/ul&gt;&lt;h4 id=&quot;531-iterationheadtask&quot;&gt;5.3.1 IterationHeadTask&lt;/h4&gt;
&lt;p&gt;IterationHeadTask主要作用是协调一次迭代。&lt;/p&gt;
&lt;p&gt;它会读取初始输入，和迭代Tail建立一个BlockingBackChannel。在成功处理输入之后，它会发送EndOfSuperstep事件给自己的输出。它在每次superstep之后会联系 synchronization task，等到自己收到一个用来同步的AllWorkersDoneEvent。AllWorkersDoneEvent表示所有其他的heads已经完成了自己的迭代。&lt;/p&gt;
&lt;p&gt;下一次迭代时候，上一次迭代中tail的输出就经由backchannel传输，形成了head的输入。何时进入到下一个迭代，是由HeadTask完成的。一旦迭代完成，head将发送TerminationEvent给所有和它关联的task，告诉他们shutdown。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;                               barrier.waitForOtherWorkers();

                                if (barrier.terminationSignaled()) {
                                        requestTermination();
                                        nextStepKickoff.signalTermination();
                                } else {
                                        incrementIterationCounter();
                                        String[] globalAggregateNames = barrier.getAggregatorNames();
                                        Value[] globalAggregates = barrier.getAggregates();
                                        aggregatorRegistry.updateGlobalAggregatesAndReset(globalAggregateNames, globalAggregates);
          // 在这里发起下一次Superstep。
                                        nextStepKickoff.triggerNextSuperstep();
                                }
                        }
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;IterationHeadTask是在JobGraphGenerator.createBulkIterationHead中构建的。其例子如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;&quot;PartialSolution (Bulk Iteration) (org.apache.flink.runtime.iterative.task.IterationHeadTask)&quot;
&lt;/code&gt;
&lt;/pre&gt;
&lt;h4 id=&quot;532-iterationintermediatetask&quot;&gt;5.3.2 IterationIntermediateTask&lt;/h4&gt;
&lt;p&gt;IterationIntermediateTask是superstep中间段的task，其将传输EndOfSuperstepEvent和TerminationEvent给所有和它关联的tasks。此外，IterationIntermediateTask能更新the workset或者the solution set的迭代状态。&lt;/p&gt;
&lt;p&gt;如果迭代状态被更新，本task的输出将传送回IterationHeadTask，在这种情况下，本task将作为head再次被安排。&lt;/p&gt;
&lt;p&gt;IterationIntermediateTask的例子如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt; &quot;MapPartition (computation@KMeansUpdateCentroids) (org.apache.flink.runtime.iterative.task.IterationIntermediateTask)&quot;
   
 &quot;Combine (SUM(0), at kMeansPlusPlusInit(KMeansInitCentroids.java:135) (org.apache.flink.runtime.iterative.task.IterationIntermediateTask)&quot;
   
 &quot;MapPartition (AllReduceSend) (org.apache.flink.runtime.iterative.task.IterationIntermediateTask)&quot;
   
&quot;Filter (Filter at kMeansPlusPlusInit(KMeansInitCentroids.java:130)) (org.apache.flink.runtime.iterative.task.IterationIntermediateTask)&quot;
   
&lt;/code&gt;
&lt;/pre&gt;
&lt;h4 id=&quot;533-iterationtailtask&quot;&gt;5.3.3 IterationTailTask&lt;/h4&gt;
&lt;p&gt;IterationTailTask是迭代的最末尾。如果迭代状态被更新，本task的输出将通过BlockingBackChannel传送回IterationHeadTask，反馈给迭代头就意味着一个迭代完整逻辑的完成，那么就可以关闭这个迭代闭合环了。这种情况下，本task将在head所在的实例上重新被调度。&lt;/p&gt;
&lt;p&gt;这里有几个关键点需要注意：&lt;/p&gt;
&lt;h5 id=&quot;如何和head建立联系&quot;&gt;如何和Head建立联系&lt;/h5&gt;
&lt;p&gt;Flink有一个BlockingQueueBroker类，这是一个阻塞式的队列代理，它的作用是对迭代并发进行控制。Broker是单例的，迭代头任务和尾任务会生成同样的broker ID，所以头尾在同一个JVM中会基于相同的dataChannel进行通信。dataChannel由迭代头创建。&lt;/p&gt;
&lt;p&gt;IterationHeadTask中会生成BlockingBackChannel，这是一个容量为1的阻塞队列。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;// 生成channel
BlockingBackChannel backChannel = new BlockingBackChannel(new SerializedUpdateBuffer(segments, segmentSize, this.getIOManager())); 

// 然后block在这里，等待Tail
superstepResult = backChannel.getReadEndAfterSuperstepEnded();
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;IterationTailTask则是如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;// 在基类得到channel，因为是单例，所以会得到同一个
worksetBackChannel = BlockingBackChannelBroker.instance().getAndRemove(brokerKey());

// notify iteration head if responsible for workset update 在这里通知Head
worksetBackChannel.notifyOfEndOfSuperstep();
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;而两者都是利用如下办法来建立联系，在同一个subtask中会使用同一个brokerKey，这样首尾就联系起来了。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;public String brokerKey() {
    if (this.brokerKey == null) {
        int iterationId = this.config.getIterationId();
        this.brokerKey = this.getEnvironment().getJobID().toString() + '#' + iterationId + '#' + this.getEnvironment().getTaskInfo().getIndexOfThisSubtask();
    }

    return this.brokerKey;
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;h5 id=&quot;如何把用户返回的数值传给head&quot;&gt;如何把用户返回的数值传给Head&lt;/h5&gt;
&lt;p&gt;这是通过output.collect来完成的。&lt;/p&gt;
&lt;p&gt;首先，在Tail初始化时候，会生成一个outputCollector，这个outputCollector会被设置为本task的输出outputCollector。这样就保证了用户函数的输出都会转流到outputCollector。&lt;/p&gt;
&lt;p&gt;而outputCollector的输出就是worksetBackChannel的输出，这里设置为同一个instance。这样用户输出就输出到backChannel中。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;       @Override
        protected void initialize() throws Exception {
                super.initialize();
    
                // set the last output collector of this task to reflect the iteration tail state update:
                // a) workset update,
                // b) solution set update, or
                // c) merged workset and solution set update

                Collector&amp;lt;OT&amp;gt; outputCollector = null;
                if (isWorksetUpdate) {
      // 生成一个outputCollector
                        outputCollector = createWorksetUpdateOutputCollector();

                        // we need the WorksetUpdateOutputCollector separately to count the collected elements
                        if (isWorksetIteration) {
                                worksetUpdateOutputCollector = (WorksetUpdateOutputCollector&amp;lt;OT&amp;gt;) outputCollector;
                        }
                }
    
    ......
    // 把outputCollector设置为本task的输出
                setLastOutputCollector(outputCollector);
        }
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;outputCollector的输出就是worksetBackChannel的输出buffer，这里设置为同一个instance。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;       protected Collector&amp;lt;OT&amp;gt; createWorksetUpdateOutputCollector(Collector&amp;lt;OT&amp;gt; delegate) {
                DataOutputView outputView = worksetBackChannel.getWriteEnd();
                TypeSerializer&amp;lt;OT&amp;gt; serializer = getOutputSerializer();
                return new WorksetUpdateOutputCollector&amp;lt;OT&amp;gt;(outputView, serializer, delegate);
        }
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;运行时候如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;       @Override
        public void run() throws Exception {

                SuperstepKickoffLatch nextSuperStepLatch = SuperstepKickoffLatchBroker.instance().get(brokerKey());

                while (this.running &amp;amp;&amp;amp; !terminationRequested()) {

      // 用户在这里输出，最后会输出到output.collect，也就是worksetBackChannel的输出buffer。
                        super.run();

      // 这时候以及输出到channel完毕，只是通知head进行读取。
                        if (isWorksetUpdate) {
                                // notify iteration head if responsible for workset update
                                worksetBackChannel.notifyOfEndOfSuperstep();
                        } else if (isSolutionSetUpdate) {
                                // notify iteration head if responsible for solution set update
                                solutionSetUpdateBarrier.notifySolutionSetUpdate();
                        }

      ...
        }
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;IterationTailTask例子如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;&quot;Pipe (org.apache.flink.runtime.iterative.task.IterationTailTask)&quot;
&lt;/code&gt;
&lt;/pre&gt;
&lt;h4 id=&quot;534-iterationsynchronizationsinktask&quot;&gt;5.3.4 IterationSynchronizationSinkTask&lt;/h4&gt;
&lt;p&gt;IterationSynchronizationSinkTask作用是同步所有的iteration heads，IterationSynchronizationSinkTask被是实现成一个 output task。其只是用来协调，不处理任何数据。&lt;/p&gt;
&lt;p&gt;在每一次superstep，IterationSynchronizationSinkTask只是等待直到它从每一个head都收到一个WorkerDoneEvent。这表示下一次superstep可以开始了。&lt;/p&gt;
&lt;p&gt;&lt;u&gt;这里需要注意的是 SynchronizationSinkTask 如何等待各个并行度的headTask&lt;/u&gt;。比如Flink的并行度是5，那么SynchronizationSinkTask怎么做到等待这5个headTask。&lt;/p&gt;
&lt;p&gt;在IterationSynchronizationSinkTask中，注册了SyncEventHandler来等待head的WorkerDoneEvent。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;this.eventHandler = new SyncEventHandler(numEventsTillEndOfSuperstep, this.aggregators, this.getEnvironment().getUserClassLoader());
this.headEventReader.registerTaskEventListener(this.eventHandler, WorkerDoneEvent.class);
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;在SyncEventHandler中，我们可以看到，在构建时候，numberOfEventsUntilEndOfSuperstep就被设置为并行度，每次收到一个WorkerDoneEvent，workerDoneEventCounter就递增，当等于numberOfEventsUntilEndOfSuperstep，即并行度时候，就说明本次superstep中，所有headtask都成功了。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;    private void onWorkerDoneEvent(WorkerDoneEvent workerDoneEvent) {
        if (this.endOfSuperstep) {
            throw new RuntimeException(&quot;Encountered WorderDoneEvent when still in End-of-Superstep status.&quot;);
        } else {
          // 每次递增
            ++this.workerDoneEventCounter;
            String[] aggNames = workerDoneEvent.getAggregatorNames();
            Value[] aggregates = workerDoneEvent.getAggregates(this.userCodeClassLoader);
            if (aggNames.length != aggregates.length) {
                throw new RuntimeException(&quot;Inconsistent WorkerDoneEvent received!&quot;);
            } else {
                for(int i = 0; i &amp;lt; aggNames.length; ++i) {
                    Aggregator&amp;lt;Value&amp;gt; aggregator = (Aggregator)this.aggregators.get(aggNames[i]);
                    aggregator.aggregate(aggregates[i]);
                }

              // numberOfEventsUntilEndOfSuperstep就是并行度，等于并行度时候就说明所有head都成功了。
                if (this.workerDoneEventCounter % this.numberOfEventsUntilEndOfSuperstep == 0) {
                    this.endOfSuperstep = true;
                    Thread.currentThread().interrupt();
                }
            }
        }
    }
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;IterationSynchronizationSinkTask的例子如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;&quot;Sync (BulkIteration (Bulk Iteration)) (org.apache.flink.runtime.iterative.task.IterationSynchronizationSinkTask)&quot;
&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;54-superstep&quot;&gt;5.4 superstep&lt;/h3&gt;
&lt;p&gt;综上所述，我们最终得到superstep如下:&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;***** 文字描述如下 *****
  
每次迭代都是一个superstep
  每次迭代中有若干subtask在不同的partition上分别执行step
     每个step有一个HeadTask，若干IntermediateTask，一个TailTask
  每个superstep有一个SynchronizationSinkTask
  
***** 伪代码大致如下 *****
  
for maxIter ：
  begin superstep
      for maxSubTask ：
         begin step
           IterationHeadTask
           IterationIntermediateTask
           IterationIntermediateTask
           ...
           IterationIntermediateTask
           IterationIntermediateTask
           IterationTailTask
         end step
    IterationSynchronizationSinkTask
  end superstep
&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;0x06-结合kmeans代码看superset&quot;&gt;0x06 结合KMeans代码看superset&lt;/h2&gt;
&lt;h3 id=&quot;61-k-means算法概要&quot;&gt;6.1 K-means算法概要&lt;/h3&gt;
&lt;p&gt;K-means算法的过程，为了尽量不用数学符号，所以描述的不是很严谨，大概就是这个意思，“物以类聚、人以群分”：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;首先输入k的值，即我们希望将数据集经过聚类得到k个分组。&lt;/li&gt;
&lt;li&gt;从数据集中随机选择k个数据点作为初始大哥（质心，Centroid）&lt;/li&gt;
&lt;li&gt;对集合中每一个小弟，计算与每一个大哥的距离（距离的含义后面会讲），离哪个大哥距离近，就跟定哪个大哥。&lt;/li&gt;
&lt;li&gt;这时每一个大哥手下都聚集了一票小弟，这时候召开人民代表大会，每一群选出新的大哥（其实是通过算法选出新的质心）。&lt;/li&gt;
&lt;li&gt;如果新大哥和老大哥之间的距离小于某一个设置的阈值（表示重新计算的质心的位置变化不大，趋于稳定，或者说收敛），可以认为我们进行的聚类已经达到期望的结果，算法终止。&lt;/li&gt;
&lt;li&gt;如果新大哥和老大哥距离变化很大，需要迭代3~5步骤。&lt;/li&gt;
&lt;/ol&gt;&lt;h3 id=&quot;62-kmeanspreallocatecentroid&quot;&gt;6.2 KMeansPreallocateCentroid&lt;/h3&gt;
&lt;p&gt;KMeansPreallocateCentroid也是superstep一员，但是只有&lt;code&gt;context.getStepNo() == 1&lt;/code&gt;的时候，才会进入实际业务逻辑，预分配Centroid。当superstep为大于1的时候，本task会执行，但不会进入具体业务代码。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;public class KMeansPreallocateCentroid extends ComputeFunction {
    private static final Logger LOG = LoggerFactory.getLogger(KMeansPreallocateCentroid.class);

    @Override
    public void calc(ComContext context) {
        // 每次superstep都会进到这里
        LOG.info(&quot;  KMeansPreallocateCentroid 我每次都会进的呀   &quot;);
        if (context.getStepNo() == 1) {
          // 实际预分配业务只进入一次
        }
    }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;63-kmeansassigncluster-和-kmeansupdatecentroids&quot;&gt;6.3 KMeansAssignCluster 和 KMeansUpdateCentroids&lt;/h3&gt;
&lt;p&gt;KMeansAssignCluster 作用是为每个点(point)计算最近的聚类中心，为每个聚类中心的点坐标的计数和求和。&lt;/p&gt;
&lt;p&gt;KMeansUpdateCentroids 作用是基于计算出来的点计数和坐标，计算新的聚类中心。&lt;/p&gt;
&lt;p&gt;Alink在整个计算过程中维护一个特殊节点来记住待求中心点当前的结果。&lt;/p&gt;
&lt;p&gt;这就是为啥迭代时候需要区分奇数次和偶数次的原因了。奇数次就表示老大哥，偶数次就表示新大哥。每次superstep只会计算一批大哥，留下另外一批大哥做距离比对。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;另外要注意的一点是&lt;/strong&gt;：普通的迭代计算，是通过Tail给Head回传用户数据，但是KMeans这里的实现并没有采用这个办法，而是把计算出来的中心点都存在共享变量中，在各个intermediate之间互相交互。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;public class KMeansAssignCluster extends ComputeFunction {
    public void calc(ComContext context) {
        ......
        if (context.getStepNo() % 2 == 0) {
            stepNumCentroids = context.getObj(KMeansTrainBatchOp.CENTROID1);
        } else {
            stepNumCentroids = context.getObj(KMeansTrainBatchOp.CENTROID2);
        }
      /** 具体业务逻辑代码
       * Find the closest cluster for every point and calculate the sums of the points belonging to the same cluster.
       */
    }
}

public class KMeansUpdateCentroids extends ComputeFunction {
    public void calc(ComContext context) {
        if (context.getStepNo() % 2 == 0) {
            stepNumCentroids = context.getObj(KMeansTrainBatchOp.CENTROID2);
        } else {
            stepNumCentroids = context.getObj(KMeansTrainBatchOp.CENTROID1);
        }
      /** 具体业务逻辑代码
       * Update the centroids based on the sum of points and point number belonging to the same cluster.
       */
    }
&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;64-kmeansoutputmodel&quot;&gt;6.4 KMeansOutputModel&lt;/h3&gt;
&lt;p&gt;这里要特殊说明，因为KMeansOutputModel是最终输出模型，而KMeans算法的实现是：所有subtask都拥有所有中心点，就是说所有subtask都会有相同的模型，就没有必要全部输出，所以这里限定了第一个subtask才能输出，其他的都不输出。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;       @Override
        public List &amp;lt;Row&amp;gt; calc(ComContext context) {
    // 只有第一个subtask才输出模型数据。
                if (context.getTaskId() != 0) {
                        return null;
                }

    ....
      
                modelData.params = new KMeansTrainModelData.ParamSummary();
                modelData.params.k = k;
                modelData.params.vectorColName = vectorColName;
                modelData.params.distanceType = distanceType;
                modelData.params.vectorSize = vectorSize;
                modelData.params.latitudeColName = latitudeColName;
                modelData.params.longtitudeColName = longtitudeColName;

                RowCollector collector = new RowCollector();
                new KMeansModelDataConverter().save(modelData, collector);
                return collector.getRows();
        }
&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;0x07-参考&quot;&gt;0x07 参考&lt;/h2&gt;
&lt;p&gt;&lt;a href=&quot;https://blog.csdn.net/qq100440110/article/details/51657842&quot;&gt;几种并行计算模型的区别(BSP LogP PRAM)&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://ci.apache.org/projects/flink/flink-docs-release-1.10/dev/batch/iterations.html&quot;&gt;https://ci.apache.org/projects/flink/flink-docs-release-1.10/dev/batch/iterations.html&lt;/a&gt;&lt;br/&gt;&lt;a href=&quot;https://www.jianshu.com/p/fc91fed8c77b&quot;&gt;聚类、K-Means、例子、细节&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.jianshu.com/p/e70e90d9d2cd&quot;&gt;Flink-Gelly：Iterative Graph Processing&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://www.mamicode.com/info-detail-947492.html&quot;&gt;从BSP模型到Apache Hama&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://blog.csdn.net/qq_37142346/article/details/90315229&quot;&gt;Flink DataSet迭代运算&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://blog.csdn.net/qq100440110/article/details/51657842&quot;&gt;几种并行计算模型的区别(BSP LogP PRAM)&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.cnblogs.com/nightbreeze/p/10942536.html&quot;&gt;Flink架构，源码及debug&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://blog.csdn.net/lzb348110175/article/details/104248577&quot;&gt;Flink 之 Dataflow、Task、subTask、Operator Chains、Slot 介绍&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.jianshu.com/p/72fe9f2959e4&quot;&gt;Flink 任务和调度&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://blog.csdn.net/yanghua_kobe/article/details/56321793&quot;&gt;Flink运行时之生成作业图&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;</description>
<pubDate>Fri, 29 May 2020 20:12:00 +0000</pubDate>
<dc:creator>罗西的思考</dc:creator>
<og:description>Alink 是阿里巴巴基于实时计算引擎 Flink 研发的新一代机器学习算法平台，是业界首个同时支持批式算法、流式算法的机器学习平台。迭代算法在很多数据分析领域会用到，比如机器学习或者图计算。本文将通</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/rossiXYZ/p/12990632.html</dc:identifier>
</item>
<item>
<title>聊聊二分算法 - Yrion</title>
<link>http://www.cnblogs.com/wyq178/p/12953128.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/wyq178/p/12953128.html</guid>
<description>&lt;p&gt;&lt;strong&gt;前言:   &lt;/strong&gt;二分查找作为很常见的一种算法,基本思想是定义头和尾双指针,计算中间的index指针,每次去和数组的中间值和目标值进行比较,如果相同就直接返回，如果目标值小于中间值就将尾指针重新赋值为中间值-1，头指针不变,相当于从左边区域去找；如果目标值大于中间值就将头指针赋值为中间值+1,尾巴指针不变,相当于从右边区间去找元素.依次循环这个过程,将区间一层层的压缩,最终就可以得到最终的目标值的index.&lt;/p&gt;




&lt;h5&gt;&lt;strong&gt;四：总结&lt;/strong&gt;&lt;/h5&gt;

&lt;p&gt;&lt;strong&gt;正文&lt;/strong&gt;&lt;/p&gt;
&lt;h2&gt;&lt;strong&gt;一：二分的使用条件和时间复杂度&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;1.1：①必须是单调递增或者递减数组&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;     注意这里是单调递增或者递减,而不是全部递增或者递减，这点很重要。如果是完全乱序的数组，那么二分算法就会完全失效。二分的本质就是借助于单调性然后比较中间节点的值来达到缩小范围去查询元素的目的。如果是乱序的,那么就无法比对中间值来达到缩减区间的目的&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;     ②必须是线性结构&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;    对于像图二叉树等结构，二分是不合适的，因为没办法去用二分，这是由结构决定的&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;1.2：二分的时间复杂度&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;    二分查找的时间复杂度是o(logn)，关于二分的时间复杂度是怎么计算出来的呢？假如数组的长度是n，每次进行二分查找的时候是n/2，下次是n/4，再一次是n/8。在最坏的情况下，每次都找不到目标值，那么就有可以设查找的次数为T，（n/2）^T=1；则T=logn,底数是2，时间复杂度为O（logn）&lt;/p&gt;
&lt;h2&gt;&lt;strong&gt;二:二分的基本写法&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;2.1：图解二分&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1066538/202005/1066538-20200530021223933-1201275247.png&quot; alt=&quot;&quot;/&gt; &lt;/p&gt;
&lt;p&gt;    上述的例子是在{1,3,5,6,12,14,19}这个数组中寻找target=3这个元素,因为数组的长度是7,中点的index=3,值为6,发现3小于6，所以最终值肯定在中点的左半区域里,因此右指针左移动=2,接下来是0、1、 2这三个元素中查找，找到中点3,发现3=target,因此直接返回最终index=1。分析其过程,发现一共用了三次，就完成了元素的查找，总体来说效率还是很高的。&lt;/p&gt;
&lt;p&gt;2.2:二分查找的标准写法&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;36&quot;&gt;
&lt;pre&gt;
&lt;span&gt; 1&lt;/span&gt;     &lt;span&gt;/**&lt;/span&gt;
&lt;span&gt; 2&lt;/span&gt; &lt;span&gt;     * 二分查找
&lt;/span&gt;&lt;span&gt; 3&lt;/span&gt; &lt;span&gt;     *
&lt;/span&gt;&lt;span&gt; 4&lt;/span&gt; &lt;span&gt;     * &lt;/span&gt;&lt;span&gt;@param&lt;/span&gt;&lt;span&gt; nums
&lt;/span&gt;&lt;span&gt; 5&lt;/span&gt; &lt;span&gt;     * &lt;/span&gt;&lt;span&gt;@param&lt;/span&gt;&lt;span&gt; target
&lt;/span&gt;&lt;span&gt; 6&lt;/span&gt; &lt;span&gt;     * &lt;/span&gt;&lt;span&gt;@return&lt;/span&gt;
&lt;span&gt; 7&lt;/span&gt;      &lt;span&gt;*/&lt;/span&gt;
&lt;span&gt; 8&lt;/span&gt;     &lt;span&gt;public&lt;/span&gt; &lt;span&gt;int&lt;/span&gt; binarySearch(&lt;span&gt;int&lt;/span&gt;[] nums, &lt;span&gt;int&lt;/span&gt;&lt;span&gt; target) {
&lt;/span&gt;&lt;span&gt; 9&lt;/span&gt; 
&lt;span&gt;10&lt;/span&gt;         &lt;span&gt;int lo&lt;/span&gt; = 0&lt;span&gt;;
&lt;/span&gt;&lt;span&gt;11&lt;/span&gt;         &lt;span&gt;int&lt;/span&gt; hi = nums.length - 1&lt;span&gt;;
&lt;/span&gt;&lt;span&gt;12&lt;/span&gt;         &lt;span&gt;while&lt;/span&gt; (lo &amp;lt;&lt;span&gt; hi) {
&lt;/span&gt;&lt;span&gt;13&lt;/span&gt;             &lt;span&gt;int&lt;/span&gt; middle = (low + hi) / 2&lt;span&gt;;
&lt;/span&gt;&lt;span&gt;14&lt;/span&gt;             &lt;span&gt;if&lt;/span&gt; (nums[middle] &amp;lt;&lt;span&gt; target) {
&lt;/span&gt;&lt;span&gt;15&lt;/span&gt;                 lo = middle + 1&lt;span&gt;;
&lt;/span&gt;&lt;span&gt;16&lt;/span&gt;             } &lt;span&gt;else&lt;/span&gt; &lt;span&gt;if&lt;/span&gt; (nums[middle] &amp;gt;&lt;span&gt; target) {
&lt;/span&gt;&lt;span&gt;17&lt;/span&gt;                 hi = middle - 1&lt;span&gt;;
&lt;/span&gt;&lt;span&gt;18&lt;/span&gt;             } &lt;span&gt;else&lt;/span&gt;&lt;span&gt; {
&lt;/span&gt;&lt;span&gt;19&lt;/span&gt;                 &lt;span&gt;return&lt;/span&gt;&lt;span&gt; middle;
&lt;/span&gt;&lt;span&gt;20&lt;/span&gt; &lt;span&gt;            }
&lt;/span&gt;&lt;span&gt;21&lt;/span&gt; &lt;span&gt;        }
&lt;/span&gt;&lt;span&gt;22&lt;/span&gt;         &lt;span&gt;return&lt;/span&gt; -1&lt;span&gt;;
&lt;/span&gt;&lt;span&gt;23&lt;/span&gt;     }
&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;&lt;strong&gt;三：二分变种问题&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;3.1：找出有重复数据的数组元素的第一个值&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;在1.1里谈了二分的适用条件,但是需要注意的一点是，并没有排除到数组没有重复的元素,在有重复元素的情况下二分可能会存在一个问题：查找出来的元素并不是第一次出现的，假如我们要求必须查找出来第一次出现的元素,那二分又怎么写呢？&lt;/p&gt;
&lt;p&gt;首先思考一点：找出重复数组的第一个值，那么这个值肯定是第一个找出数字的index&lt;strong&gt;左侧，当中间值等于目标值的时候我们不能立刻返回，因为此时它并不一定是第一次出现的(当然它也有可能就是第一次出现),之后我们需要将它继续划分,直到left&amp;gt;right的值后,返回当前的left左边的值就是它第一次出现的位置(如果元素确实存在的话)。&lt;/strong&gt;&lt;strong&gt;每次去查找元素的时候,我们寻找目标值的时候就需要一直向左侧逼近，当发现在这个值等于目标值的时候不能立刻返回，必须再次移动区间，直到逼近目标值的index再返回&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;36&quot;&gt;
&lt;pre&gt;
&lt;span&gt; 1&lt;/span&gt;  &lt;span&gt;/**&lt;/span&gt;
&lt;span&gt; 2&lt;/span&gt; &lt;span&gt;     * 找到重复元素出现的第一个值
&lt;/span&gt;&lt;span&gt; 3&lt;/span&gt; &lt;span&gt;     *
&lt;/span&gt;&lt;span&gt; 4&lt;/span&gt; &lt;span&gt;     * &lt;/span&gt;&lt;span&gt;@param&lt;/span&gt;&lt;span&gt; array
&lt;/span&gt;&lt;span&gt; 5&lt;/span&gt; &lt;span&gt;     * &lt;/span&gt;&lt;span&gt;@param&lt;/span&gt;&lt;span&gt; target
&lt;/span&gt;&lt;span&gt; 6&lt;/span&gt; &lt;span&gt;     * &lt;/span&gt;&lt;span&gt;@return&lt;/span&gt;
&lt;span&gt; 7&lt;/span&gt;      &lt;span&gt;*/&lt;/span&gt;
&lt;span&gt; 8&lt;/span&gt;     &lt;span&gt;public&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; &lt;span&gt;int&lt;/span&gt; findFirstBinarySearch(&lt;span&gt;int&lt;/span&gt;[] array, &lt;span&gt;int&lt;/span&gt;&lt;span&gt; target) {
&lt;/span&gt;&lt;span&gt; 9&lt;/span&gt;         &lt;span&gt;int&lt;/span&gt; lo = 0&lt;span&gt;;
&lt;/span&gt;&lt;span&gt;10&lt;/span&gt;         &lt;span&gt;int&lt;/span&gt; hi = array.length - 1&lt;span&gt;;
&lt;/span&gt;&lt;span&gt;11&lt;/span&gt; 
&lt;span&gt;12&lt;/span&gt;         &lt;span&gt;while&lt;/span&gt; (lo &amp;lt;=&lt;span&gt; hi) {
&lt;/span&gt;&lt;span&gt;13&lt;/span&gt;             &lt;span&gt;int&lt;/span&gt; mid = (lo + hi) / 2&lt;span&gt;;
&lt;/span&gt;&lt;span&gt;14&lt;/span&gt;             &lt;span&gt;//&lt;/span&gt;&lt;span&gt;注意这里不再有array[mid]=target return mid;&lt;/span&gt;
&lt;span&gt;15&lt;/span&gt;             &lt;span&gt;if&lt;/span&gt; (array[mid] &amp;gt;=&lt;span&gt; target) {
&lt;/span&gt;&lt;span&gt;16&lt;/span&gt;                 hi = mid - 1&lt;span&gt;;
&lt;/span&gt;&lt;span&gt;17&lt;/span&gt;             } &lt;span&gt;else&lt;/span&gt;&lt;span&gt; {
&lt;/span&gt;&lt;span&gt;18&lt;/span&gt;                 lo = mid + 1&lt;span&gt;;
&lt;/span&gt;&lt;span&gt;19&lt;/span&gt; &lt;span&gt;            }
&lt;/span&gt;&lt;span&gt;20&lt;/span&gt; &lt;span&gt;        }
&lt;/span&gt;&lt;span&gt;21&lt;/span&gt;         &lt;span&gt;//&lt;/span&gt;&lt;span&gt;防止lo越界 并且判断lo的值&lt;/span&gt;
&lt;span&gt;22&lt;/span&gt;         &lt;span&gt;if&lt;/span&gt; (lo &amp;lt; array.length &amp;amp;&amp;amp; array[lo] ==&lt;span&gt; target) {
&lt;/span&gt;&lt;span&gt;23&lt;/span&gt;             &lt;span&gt;return&lt;/span&gt;&lt;span&gt; lo;
&lt;/span&gt;&lt;span&gt;24&lt;/span&gt; &lt;span&gt;        }
&lt;/span&gt;&lt;span&gt;25&lt;/span&gt; 
&lt;span&gt;26&lt;/span&gt;         &lt;span&gt;return&lt;/span&gt; -1&lt;span&gt;;
&lt;/span&gt;&lt;span&gt;27&lt;/span&gt;     }
&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;&lt;strong&gt;3.1：找出有重复数据的数组元素的最后一个值&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt; 找到最后一个元素,那么它出现的值肯定在找出的第一个值的右侧,同样在找到middle值等于目标值的时候不能立刻返回,指针还需要继续移动.因此就需要将值进行向右逼近,直到找到middle等于目标值的最后一个，此时返回的index一定是目标值的最后一个(假如存在目标值的话)，最终&lt;/strong&gt;取right索引,因为在条件不成立的时候,目标的索引值肯定在最终肯定是在middle的右边&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;36&quot;&gt;
&lt;pre&gt;
  &lt;span&gt;/**&lt;/span&gt;&lt;span&gt;
     * 找出数组中最后一个重复的数字
     * &lt;/span&gt;&lt;span&gt;@param&lt;/span&gt;&lt;span&gt; array
     * &lt;/span&gt;&lt;span&gt;@param&lt;/span&gt;&lt;span&gt; key
     * &lt;/span&gt;&lt;span&gt;@return&lt;/span&gt;
     &lt;span&gt;*/&lt;/span&gt;
    &lt;span&gt;static&lt;/span&gt; &lt;span&gt;int&lt;/span&gt; findLastBinarySearch(&lt;span&gt;int&lt;/span&gt;[] array, &lt;span&gt;int&lt;/span&gt;&lt;span&gt; key) {
        &lt;/span&gt;&lt;span&gt;int&lt;/span&gt; lo = 0&lt;span&gt;;
        &lt;/span&gt;&lt;span&gt;int&lt;/span&gt; hi = array.length - 1&lt;span&gt;;

        &lt;/span&gt;&lt;span&gt;while&lt;/span&gt; (lo &amp;lt;=&lt;span&gt; hi) {
            &lt;/span&gt;&lt;span&gt;int&lt;/span&gt; mid = (lo + hi) / 2&lt;span&gt;;
            &lt;/span&gt;&lt;span&gt;if&lt;/span&gt; (array[mid] &amp;lt;=&lt;span&gt; key) {
                &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;尽可能在右半区域里找&lt;/span&gt;
                lo = mid + 1&lt;span&gt;;
            }
            &lt;/span&gt;&lt;span&gt;else&lt;/span&gt;&lt;span&gt; {
                hi &lt;/span&gt;= mid - 1&lt;span&gt;;
            }
        }&lt;br/&gt;//
        &lt;/span&gt;&lt;span&gt;if&lt;/span&gt; (hi &amp;gt;= 0 &amp;amp;&amp;amp; array[hi] ==&lt;span&gt; key) {
            &lt;/span&gt;&lt;span&gt;return&lt;/span&gt;&lt;span&gt; hi;
        }

        &lt;/span&gt;&lt;span&gt;return&lt;/span&gt; -1&lt;span&gt;;
    }&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;&lt;strong&gt; 3.3:求一个数的平方根&lt;/strong&gt;&lt;/h2&gt;
&lt;h2&gt;&lt;strong&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1066538/202005/1066538-20200528014029765-163959335.png&quot; alt=&quot;&quot;/&gt;&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;   初步看这道题，很难想到用二分去做。但是仔细一想,二分可以解决这个问题的,假如数字是8，那么我们可以分为一个数组为[1,2,3,4,5,6,7,8];这个数组属于单调递增的,完全满足二分的使用条件，题目要求返回的是整数部分,因此8的平方根肯定在这个数组中的某一个数字,每个数的平方也是单调自增的，因此完全可以用二分查找来解决这个问题：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;35&quot;&gt;
&lt;pre&gt;
  &lt;span&gt;public&lt;/span&gt; &lt;span&gt;int&lt;/span&gt; sqrt(&lt;span&gt;int&lt;/span&gt;&lt;span&gt; n) {
        &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;0和1返回它本身&lt;/span&gt;
        &lt;span&gt;if&lt;/span&gt; (n==0||n==1&lt;span&gt;){
            &lt;/span&gt;&lt;span&gt;return&lt;/span&gt;&lt;span&gt; n;
        }
        &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;左指针&lt;/span&gt;
        &lt;span&gt;int&lt;/span&gt; lo = 0&lt;span&gt;;
        &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;右指针 一个数的平方根肯定小于这个数的一半&lt;/span&gt;
        &lt;span&gt;int&lt;/span&gt; hi = n / 2&lt;span&gt;;
        &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;存储结果值 默认-1&lt;/span&gt;
        &lt;span&gt;int&lt;/span&gt; res = -1&lt;span&gt;;
        &lt;/span&gt;&lt;span&gt;while&lt;/span&gt; (lo &amp;lt;=&lt;span&gt; hi) {
            &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;取中间值&lt;/span&gt;
            &lt;span&gt;int&lt;/span&gt; mid = lo + (hi - lo) / 2&lt;span&gt;;
            &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;计算平方&lt;/span&gt;
            &lt;span&gt;int&lt;/span&gt; square = mid *&lt;span&gt; mid;
            &lt;/span&gt;&lt;span&gt;if&lt;/span&gt; (square ==&lt;span&gt; n) {
                &lt;/span&gt;&lt;span&gt;return&lt;/span&gt;&lt;span&gt; mid;
            } &lt;/span&gt;&lt;span&gt;else&lt;/span&gt; &lt;span&gt;if&lt;/span&gt; (square &amp;lt;&lt;span&gt; n) {
                &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;对于非完全平方根 结果肯定是在左区间&lt;/span&gt;
                res =&lt;span&gt; mid;
                lo &lt;/span&gt;= mid + 1&lt;span&gt;;
            } &lt;/span&gt;&lt;span&gt;else&lt;/span&gt;&lt;span&gt; {
                hi &lt;/span&gt;= mid - 1&lt;span&gt;;
            }
        }
        &lt;/span&gt;&lt;span&gt;return&lt;/span&gt;&lt;span&gt; res;

    }&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;h2&gt;3.4:旋转数组的最小数字&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1066538/202005/1066538-20200529143436946-1282629044.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;


&lt;p&gt;   在1.1中讨论过二分的使用条件,是单调递增,注意是单调递增，并不是全部递增。在旋转数组的最小数字这个问题中，它的整体数组并不是全量递增或者递减的，但是它依然适用于二分,不过此时需要将原二分进行改造一下：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;35&quot;&gt;
&lt;pre&gt;
 &lt;span&gt;public&lt;/span&gt; &lt;span&gt;int&lt;/span&gt; minarrayinRotationArray(&lt;span&gt;int&lt;/span&gt;&lt;span&gt;[] numbers) {
        &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;左边指针&lt;/span&gt;
        &lt;span&gt;int&lt;/span&gt; lo = 0&lt;span&gt;;
        &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;右边指针&lt;/span&gt;
        &lt;span&gt;int&lt;/span&gt; hi = numbers.length - 1&lt;span&gt;;
        &lt;/span&gt;&lt;span&gt;while&lt;/span&gt; (lo &amp;lt;&lt;span&gt; hi) {
            &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;中间指针&lt;/span&gt;
            &lt;span&gt;int&lt;/span&gt; middle = (lo + hi) / 2&lt;span&gt;;
            &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;中间值大于右边指针值 说明寻找的旋转点一定在右区间&lt;/span&gt;
            &lt;span&gt;if&lt;/span&gt; (numbers[middle] &amp;gt;&lt;span&gt; numbers[hi]) {
                lo &lt;/span&gt;= middle + 1&lt;span&gt;;
            &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;中间值小于右边指针值 说明旋转点一定在左区间&lt;/span&gt;
            } &lt;span&gt;else&lt;/span&gt; &lt;span&gt;if&lt;/span&gt; (numbers[middle] &amp;lt;&lt;span&gt; numbers[hi]) {
                hi &lt;/span&gt;=&lt;span&gt; middle;
            &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;如果中间值等于右边指针值 无法确定旋转点在哪 右指针减一 缩小区间&lt;/span&gt;
            } &lt;span&gt;else&lt;/span&gt;&lt;span&gt; {
                hi&lt;/span&gt;--&lt;span&gt;;
            }
        }
        &lt;/span&gt;&lt;span&gt;return&lt;/span&gt;&lt;span&gt; numbers[lo];
    }&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;      本篇博客介绍了常见二分方法的思想以及时间复杂度的由来,还有二分的基本变形题,在找第一个出现的目标值和最后一个目标值的时候如何用二分去找。以及二分不太容易想到的寻找一个数的平方根和旋转数组的最小值,解决这两个问题能够帮助更加深刻的理解二分法。二分作为一种常见的算法,能够知道普通的二分还是不够的，灵活掌握并运用二分并解决实际中出现的问题，是值得我们思考的。&lt;/p&gt;
</description>
<pubDate>Fri, 29 May 2020 18:15:00 +0000</pubDate>
<dc:creator>Yrion</dc:creator>
<og:description>前言: 二分查找作为很常见的一种算法,基本思想是定义头和尾双指针,计算中间的index指针,每次去和数组的中间值和目标值进行比较,如果相同就直接返回，如果目标值小于中间值就将尾指针重新赋值为中间值-1</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/wyq178/p/12953128.html</dc:identifier>
</item>
<item>
<title>DQN（Deep Q-learning）入门教程（四）之Q-learning Play Flappy Bird - 段小辉</title>
<link>http://www.cnblogs.com/xiaohuiduan/p/12990510.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/xiaohuiduan/p/12990510.html</guid>
<description>&lt;p&gt;在上一篇&lt;a href=&quot;https://www.cnblogs.com/xiaohuiduan/p/12977830.html&quot;&gt;博客&lt;/a&gt;中，我们详细的对Q-learning的算法流程进行了介绍。同时我们使用了&lt;span class=&quot;math inline&quot;&gt;\(\epsilon-贪婪法\)&lt;/span&gt;防止陷入局部最优。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1439869/202005/1439869-20200530014805803-238391864.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;那么我们可以想一下，最后我们得到的结果是什么样的呢？因为我们考虑到了所有的（&lt;span class=&quot;math inline&quot;&gt;\(\epsilon-贪婪法\)&lt;/span&gt;导致的）情况，因此最终我们将会得到一张如下的&lt;strong&gt;Q-Table&lt;/strong&gt;表。&lt;/p&gt;
&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;Q-Table&lt;/th&gt;
&lt;th&gt;&lt;span class=&quot;math inline&quot;&gt;\(a_1\)&lt;/span&gt;&lt;/th&gt;
&lt;th&gt;&lt;span class=&quot;math inline&quot;&gt;\(a_2\)&lt;/span&gt;&lt;/th&gt;
&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;span class=&quot;math inline&quot;&gt;\(s_1\)&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;&lt;span class=&quot;math inline&quot;&gt;\(q(s_1,a_1)\)&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;&lt;span class=&quot;math inline&quot;&gt;\(q(s_1,a_2)\)&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;span class=&quot;math inline&quot;&gt;\(s_2\)&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;&lt;span class=&quot;math inline&quot;&gt;\(q(s_2,a_1)\)&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;&lt;span class=&quot;math inline&quot;&gt;\(q(s_2,a_2)\)&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;span class=&quot;math inline&quot;&gt;\(s_3\)&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;&lt;span class=&quot;math inline&quot;&gt;\(q(s_3,a_1)\)&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;&lt;span class=&quot;math inline&quot;&gt;\(q(s_3,a_2)\)&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;当agent运行到某一个场景&lt;span class=&quot;math inline&quot;&gt;\(s\)&lt;/span&gt;时，会去查询已经训练好的Q-Table，然后从中选择一个最大的&lt;span class=&quot;math inline&quot;&gt;\(q\)&lt;/span&gt;对应的action。&lt;/p&gt;
&lt;h2 id=&quot;训练内容&quot;&gt;训练内容&lt;/h2&gt;
&lt;p&gt;这一次，我们将对Flappy-bird游戏进行训练。这个游戏的介绍我就不多说了，可以看一下&lt;a href=&quot;https://zh.wikipedia.org/wiki/Flappy_Bird&quot;&gt;维基百科&lt;/a&gt;的介绍。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1439869/202005/1439869-20200530014806480-858317041.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;游戏就是控制一只🐦穿越管道，然后可以获得分数，对于小鸟来说，他只有两个动作，跳or不跳，而我们的目标就是使小鸟穿越管道获得更多的分数。&lt;/p&gt;
&lt;h2 id=&quot;前置准备&quot;&gt;前置准备&lt;/h2&gt;
&lt;p&gt;因为我们的目标是来学习“强化学习”的，所以我们不可能说自己去弄一个Flappy-bird（当然自己弄也可以），这里我们直接使用一个已经写好的Flappy-bird。&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/ntasfi/PyGame-Learning-Environment&quot;&gt;PyGame-Learning-Environment&lt;/a&gt;，是一个Python的强化学习环境，简称PLE，下面时他Github上面的介绍：&lt;/p&gt;
&lt;blockquote readability=&quot;10.14161849711&quot;&gt;
&lt;p&gt;&lt;strong&gt;PyGame Learning Environment (PLE)&lt;/strong&gt; is a learning environment, mimicking the &lt;a href=&quot;https://github.com/mgbellemare/Arcade-Learning-Environment&quot;&gt;Arcade Learning Environment&lt;/a&gt; interface, allowing a quick start to Reinforcement Learning in Python. The goal of PLE is &lt;strong&gt;allow practitioners to focus design of models and experiments instead of environment design.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;PLE hopes to eventually build an expansive library of games.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;然后关于FlappyBird的文档介绍在&lt;a href=&quot;https://pygame-learning-environment.readthedocs.io/en/latest/user/games/flappybird.html&quot;&gt;这里&lt;/a&gt;，文档的介绍还是蛮清楚的。安装步骤如下所示，推荐在Pipenv的环境下安装，不过你也可以直接clone&lt;a href=&quot;https://github.com/xiaohuiduan/flappy-bird-q-learning&quot;&gt;我的代码&lt;/a&gt;然后然后根据reademe的步骤进行使用。&lt;/p&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;pre&gt;
&lt;code&gt;git clone https://github.com/ntasfi/PyGame-Learning-Environment.git
cd PyGame-Learning-Environment/
pip install -e .
&lt;/code&gt;
&lt;/pre&gt;&lt;/blockquote&gt;
&lt;p&gt;需要的库如下：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;pygame&lt;/li&gt;
&lt;li&gt;numpy&lt;/li&gt;
&lt;li&gt;pillow&lt;/li&gt;
&lt;/ul&gt;&lt;h3 id=&quot;函数说明&quot;&gt;函数说明&lt;/h3&gt;
&lt;p&gt;在&lt;a href=&quot;https://pygame-learning-environment.readthedocs.io/en/latest/user/games/flappybird.html&quot;&gt;官方文档&lt;/a&gt;有几个的函数在这里说下，因为等下我们需要用到。&lt;/p&gt;
&lt;ul readability=&quot;3&quot;&gt;&lt;li readability=&quot;1&quot;&gt;
&lt;p&gt;&lt;code&gt;getGameState()&lt;/code&gt;：获得游戏当前的状态，返回值为一个字典：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;player y position.&lt;/li&gt;
&lt;li&gt;players velocity.&lt;/li&gt;
&lt;li&gt;next pipe distance to player&lt;/li&gt;
&lt;li&gt;next pipe top y position&lt;/li&gt;
&lt;li&gt;next pipe bottom y position&lt;/li&gt;
&lt;li&gt;next next pipe distance to player&lt;/li&gt;
&lt;li&gt;next next pipe top y position&lt;/li&gt;
&lt;li&gt;next next pipe bottom y position&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;部分数据表示如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1439869/202005/1439869-20200530014806749-233334266.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;&lt;code&gt;reset_game()&lt;/code&gt;：重新开始游戏&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;&lt;code&gt;act(action)&lt;/code&gt;：在游戏中执行一个动作，参数为动作，返回执行后的分数。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;&lt;code&gt;game_over()&lt;/code&gt;：假如游戏结束，则返回True，否者返回False。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;&lt;code&gt;getActionSet()&lt;/code&gt;：获得游戏的动作集合。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;我们的窗体大小默认是288*512，其中鸟的速度在-20到10之间（最小速度我并不知道，但是经过观察，并没有小于-20的情况，而最大的速度在源代码里面已经说明好了为10）&lt;/p&gt;
&lt;h2 id=&quot;coding-time&quot;&gt;Coding Time&lt;/h2&gt;
&lt;p&gt;在前面我们说，通过&lt;code&gt;getGameState()&lt;/code&gt;函数，我们可以获得几个关于环境的数据，在这里我们选择如下的数据：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;next_pipe_dist_to_player：&lt;/li&gt;
&lt;li&gt;player_y与next_pipe_top_y的差值&lt;/li&gt;
&lt;li&gt;🐦的速度&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;但是我们可以想一想，next_pipe_dist_to_player一共会有多少种的取值：因为窗体大小为288*512，则取值的范围大约是0~288，也就是说它大约有288个取值，而关于player_y与next_pipe_top_y的差值，则大概有1024个取值。这样很难让模型收敛，因此我们将数值进行简化。其中简化的思路来自：&lt;a href=&quot;https://github.com/BujuNB/Flappy-Brid-RL&quot;&gt;GitHub&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;首先我们创建一个Agent类，然后逐渐向里面添加功能。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-python&quot;&gt;class Agent():

    def __init__(self, action_space):
        # 获得游戏支持的动作集合
        self.action_set = action_space

        # 创建q-table
        self.q_table = np.zeros((6, 6, 6, 2))

        # 学习率
        self.alpha = 0.7
        # 励衰减因子
        self.gamma = 0.8
        # 贪婪率
        self.greedy = 0.8
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;至于为什么q-table的大小是(6,6,6,2)，其中的3个6分别代表&lt;strong&gt;next_pipe_dist_to_player&lt;/strong&gt;，&lt;strong&gt;player_y与next_pipe_top_y的差值&lt;/strong&gt;，&lt;strong&gt;🐦的速度&lt;/strong&gt;，其中的2代表动作的个数。也就是说，表格中的state一共有$6 \times6 \times 6 $种，表格的大小为&lt;span class=&quot;math inline&quot;&gt;\(6 \times6 \times 6 \times 2\)&lt;/span&gt;。&lt;/p&gt;
&lt;h3 id=&quot;缩小状态值的范围&quot;&gt;缩小状态值的范围&lt;/h3&gt;
&lt;p&gt;我们定义一个函数&lt;code&gt;get_state(s)&lt;/code&gt;，这个函数专门提取游戏中的状态，然后返回进行简化的状态数据：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-python&quot;&gt;    def get_state(self, state):
        &quot;&quot;&quot;
        提取游戏state中我们需要的数据
        :param state: 游戏state
        :return: 返回提取好的数据
        &quot;&quot;&quot;
        return_state = np.zeros((3,), dtype=int)
        dist_to_pipe_horz = state[&quot;next_pipe_dist_to_player&quot;]
        dist_to_pipe_bottom = state[&quot;player_y&quot;] - state[&quot;next_pipe_top_y&quot;]
        velocity = state['player_vel']
        if velocity &amp;lt; -15:
            velocity_category = 0
        elif velocity &amp;lt; -10:
            velocity_category = 1
        elif velocity &amp;lt; -5:
            velocity_category = 2
        elif velocity &amp;lt; 0:
            velocity_category = 3
        elif velocity &amp;lt; 5:
            velocity_category = 4
        else:
            velocity_category = 5

        if dist_to_pipe_bottom &amp;lt; 8:  # very close or less than 0
            height_category = 0
        elif dist_to_pipe_bottom &amp;lt; 20:  # close
            height_category = 1
        elif dist_to_pipe_bottom &amp;lt; 50:  # not close
            height_category = 2
        elif dist_to_pipe_bottom &amp;lt; 125:  # mid
            height_category = 3
        elif dist_to_pipe_bottom &amp;lt; 250:  # far
            height_category = 4
        else:
            height_category = 5

        # make a distance category
        if dist_to_pipe_horz &amp;lt; 8:  # very close
            dist_category = 0
        elif dist_to_pipe_horz &amp;lt; 20:  # close
            dist_category = 1
        elif dist_to_pipe_horz &amp;lt; 50:  # not close
            dist_category = 2
        elif dist_to_pipe_horz &amp;lt; 125:  # mid
            dist_category = 3
        elif dist_to_pipe_horz &amp;lt; 250:  # far
            dist_category = 4
        else:
            dist_category = 5

        return_state[0] = height_category
        return_state[1] = dist_category
        return_state[2] = velocity_category
        return return_state
&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;更新q-table&quot;&gt;更新Q-table&lt;/h3&gt;
&lt;p&gt;更新的数学公式如下：&lt;/p&gt;
&lt;p&gt;\[{\displaystyle Q^{new}(s_{t},a_{t})\leftarrow \underbrace {Q(s_{t},a_{t})} _{\text{旧的值}}+\underbrace {\alpha } _{\text{学习率}}\cdot \overbrace {{\bigg (}\underbrace {\underbrace {r_{t}} _{\text{奖励}}+\underbrace {\gamma } _{\text{奖励衰减因子}}\cdot \underbrace {\max _{a}Q(s_{t+1},a)} _{\text{estimate of optimal future value}}} _{\text{new value (temporal difference target)}}-\underbrace {Q(s_{t},a_{t})} _{\text{旧的值}}{\bigg )}} ^{\text{temporal difference}}} \]&lt;/p&gt;
&lt;p&gt;下面是更新Q-table的函数代码：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-python&quot;&gt;def update_q_table(self, old_state, current_action, next_state, r):
    &quot;&quot;&quot;

    :param old_state: 执行动作前的状态
    :param current_action: 执行的动作
    :param next_state: 执行动作后的状态
    :param r: 奖励
    :return:
    &quot;&quot;&quot;
    next_max_value = np.max(self.q_table[next_state[0], next_state[1], next_state[2]])

    self.q_table[old_state[0], old_state[1], old_state[2], current_action] = (1 - self.alpha) * self.q_table[
        old_state[0], old_state[1], old_state[2], current_action] + self.alpha * (r + next_max_value)
&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;选择最佳的动作&quot;&gt;选择最佳的动作&lt;/h3&gt;
&lt;p&gt;然后我们就是根据q-table对应的Q值选择最大的那一个，其中第一个代表（也就是0）跳跃，第2个代表不执行任何操作。&lt;/p&gt;
&lt;p&gt;选择的示意图如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1439869/202005/1439869-20200530014807034-1323519259.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;代码如下所示：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-python&quot;&gt;def get_best_action(self, state, greedy=False):
    &quot;&quot;&quot;
    获得最佳的动作
    :param state: 状态
    :是否使用ϵ-贪婪法
    :return: 最佳动作
    &quot;&quot;&quot;
        
    # 获得q值
    jump = self.q_table[state[0], state[1], state[2], 0]
    no_jump = self.q_table[state[0], state[1], state[2], 1]
    # 是否执行策略
    if greedy:
        if np.random.rand(1) &amp;lt; self.greedy:
            return np.random.choice([0, 1])
        else:
            if jump &amp;gt; no_jump:
                return 0
            else:
                return 1
    else:
        if jump &amp;gt; no_jump:
            return 0
        else:
            return 1
&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;更新值&quot;&gt;更新&lt;span class=&quot;math inline&quot;&gt;\(\epsilon\)&lt;/span&gt;值&lt;/h3&gt;
&lt;p&gt;这个比较简单，从前面的博客中，我们知道&lt;span class=&quot;math inline&quot;&gt;\(\epsilon\)&lt;/span&gt;是随着训练次数的增加而减少的，有很多种策略可以选择，这里乘以&lt;span class=&quot;math inline&quot;&gt;\(0.95\)&lt;/span&gt;吧。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-python&quot;&gt;def update_greedy(self):
    self.greedy *= 0.95
&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;执行动作&quot;&gt;执行动作&lt;/h3&gt;
&lt;p&gt;在官方文档中，如果小鸟没有死亡奖励为0，越过一个管道，奖励为1，死亡奖励为-1，我们稍微的对其进行改变：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-python&quot;&gt;def act(self, p, action):
    &quot;&quot;&quot;
    执行动作
    :param p: 通过p来向游戏发出动作命令
    :param action: 动作
    :return: 奖励
    &quot;&quot;&quot;
    # action_set表示游戏动作集(119，None)，其中119代表跳跃
    r = p.act(self.action_set[action])
    if r == 0:
        r = 1
    if r == 1:
        r = 10
    else:
        r = -1000
    return r
&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;main函数&quot;&gt;main函数&lt;/h3&gt;
&lt;p&gt;最后我们就可以执行main函数了。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-python&quot;&gt;if __name__ == &quot;__main__&quot;:
    # 训练次数
    episodes = 2000_000000
    # 实例化游戏对象
    game = FlappyBird()
    # 类似游戏的一个接口，可以为我们提供一些功能
    p = PLE(game, fps=30, display_screen=False)
    # 初始化
    p.init()
    # 实例化Agent，将动作集传进去
    agent = Agent(p.getActionSet())
    max_score = 0
        
    for episode in range(episodes):
        # 重置游戏
        p.reset_game()
        # 获得状态
        state = agent.get_state(game.getGameState())
        agent.update_greedy()
        while True:
            # 获得最佳动作
            action = agent.get_best_action(state)
            # 然后执行动作获得奖励
            reward = agent.act(p, action)
            # 获得执行动作之后的状态
            next_state = agent.get_state(game.getGameState())
            # 更新q-table
            agent.update_q_table(state, action, next_state, reward)
            # 获得当前分数
            current_score = p.score()
            state = next_state
            if p.game_over():
                max_score = max(current_score, max_score)
                print('Episodes: %s, Current score: %s, Max score: %s' % (episode, current_score, max_score))
                # 保存q-table
                if current_score &amp;gt; 300:
                    np.save(&quot;{}_{}.npy&quot;.format(current_score, episode), agent.q_table)
                break
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;部分的训练的结果如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1439869/202005/1439869-20200530014807411-1604207571.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;h2 id=&quot;总结&quot;&gt;总结&lt;/h2&gt;
&lt;p&gt;emm，说实话，我也不知道结果会怎么样，因为训练的时间比较长，我不想放在我的电脑上面跑，然后我就放在树莓派上面跑，但是树莓派性能比较低，导致训练的速度比较慢。但是，我还是觉得我的方法有点问题，&lt;code&gt;get_state()&lt;/code&gt;函数中简化的方法，我感觉不是特别的合理，如果各位有好的看法，可以在评论区留言哦，然后共同学习。&lt;/p&gt;
&lt;p&gt;项目地址：&lt;a href=&quot;https://github.com/xiaohuiduan/flappy-bird-q-learning&quot;&gt;https://github.com/xiaohuiduan/flappy-bird-q-learning&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&quot;参考&quot;&gt;参考&lt;/h3&gt;
</description>
<pubDate>Fri, 29 May 2020 17:51:00 +0000</pubDate>
<dc:creator>段小辉</dc:creator>
<og:description>在上一篇博客中，我们详细的对Q-learning的算法流程进行了介绍。同时我们使用了$\epsilon-贪婪法$防止陷入局部最优。 那么我们可以想一下，最后我们得到的结果是什么样的呢？因为我们考虑到了</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/xiaohuiduan/p/12990510.html</dc:identifier>
</item>
<item>
<title>容器技术之Docker常用命令说明 - Linux-1874</title>
<link>http://www.cnblogs.com/qiuhom-1874/p/12990424.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/qiuhom-1874/p/12990424.html</guid>
<description>&lt;p&gt;　　前面我们聊了docker的基本概念、架构、镜像、网络、数据卷，回顾请参考&lt;a href=&quot;https://www.cnblogs.com/qiuhom-1874/category/1766327.html&quot; target=&quot;_blank&quot;&gt;https://www.cnblogs.com/qiuhom-1874/category/1766327.html&lt;/a&gt;；今天这篇博客主要是对前面博客中的常用命令做一个总结补充说明；&lt;/p&gt;
&lt;p&gt;　　在前面的博客中我们说过docker是基于LXC之上封装来实现容器的，其核心就是利用内核的资源名称空间和Cgroup实现资源的管控和隔离；这里要补充一点的是docker容器把资源抽象成对象；作为客户端，docker这个命令其实就是在对这些抽象出来的资源对象做增删查改的操作；docker的API是RESTful风格的API，所以它支持类似像http协议里的GET、POST、PUT、DELETE等操作；RESTful风格的API有这样的特点；1、每一个URI代表1种资源；2、支持类似http里的GET、POST、PUT、DELETE；GET用来获取资源，POST用来新建资源（也可以用于更新资源），PUT用来更新资源，DELETE用来删除资源；3、通过操作资源的表现形式来操作资源；4、资源的表现形式是XML或者HTML；5、客户端与服务端之间的交互在请求之间是无状态的，从客户端到服务端的每个请求都必须包含理解请求所必需的信息。这也是docker客户端和服务端使用http或https协议通信的原因吧！！&lt;/p&gt;
&lt;p&gt;　　了解了上面docker的API风格，我们接下来再说说docker的对象；docker的对象大概有这样几个，1、镜像（image），2、容器（container），3、网络（network），4、卷（volumes）,5、插件（plugins）；除上5种还有就是其他对象；其中最为核心的就image，container，network；对于docker来说运行一容器的最最基础的是需要一镜像，其次就是网络，对于容器来讲，我们运行容器的目的就是为了提供服务，而绝大部分服务都是基于网络的，所以真正产生价值的是把服务通过网络提供给客户；所以网络是必不可少的资源；&lt;/p&gt;
&lt;p&gt;　　镜像相关操作&lt;/p&gt;
&lt;p&gt;　　镜像搜索&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;38&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
[root@node1 ~]# docker search nginx
NAME                               DESCRIPTION                                     STARS               OFFICIAL            AUTOMATED
nginx                              Official build of Nginx.                        13255               [OK]                
jwilder/nginx-proxy                Automated Nginx reverse proxy for docker con…   1812                                    [OK]
richarvey/nginx-php-fpm            Container running Nginx + PHP-FPM capable of…   775                                     [OK]
linuxserver/nginx                  An Nginx container, brought to you by LinuxS…   113                                     
bitnami/nginx                      Bitnami nginx Docker Image                      83                                      [OK]
tiangolo/nginx-rtmp                Docker image with Nginx using the nginx-rtmp…   74                                      [OK]
alfg/nginx-rtmp                    NGINX, nginx-rtmp-module and FFmpeg from sou…   64                                      [OK]
jc21/nginx-proxy-manager           Docker container for managing Nginx proxy ho…   61                                      
nginxdemos/hello                   NGINX webserver that serves a simple page co…   50                                      [OK]
jlesage/nginx-proxy-manager        Docker container for Nginx Proxy Manager        44                                      [OK]
nginx/nginx-ingress                NGINX Ingress Controller for Kubernetes         32                                      
privatebin/nginx-fpm-alpine        PrivateBin running on an Nginx, php-fpm &amp;amp; Al…   25                                      [OK]
schmunk42/nginx-redirect           A very simple container to redirect HTTP tra…   18                                      [OK]
nginxinc/nginx-unprivileged        Unprivileged NGINX Dockerfiles                  16                                      
centos/nginx-112-centos7           Platform for running nginx 1.12 or building …   13                                      
blacklabelops/nginx                Dockerized Nginx Reverse Proxy Server.          13                                      [OK]
centos/nginx-18-centos7            Platform for running nginx 1.8 or building n…   13                                      
raulr/nginx-wordpress              Nginx front-end for the official wordpress:f…   12                                      [OK]
nginx/nginx-prometheus-exporter    NGINX Prometheus Exporter                       12                                      
mailu/nginx                        Mailu nginx frontend                            7                                       [OK]
sophos/nginx-vts-exporter          Simple server that scrapes Nginx vts stats a…   7                                       [OK]
bitnami/nginx-ingress-controller   Bitnami Docker Image for NGINX Ingress Contr…   5                                       [OK]
ansibleplaybookbundle/nginx-apb    An APB to deploy NGINX                          1                                       [OK]
wodby/nginx                        Generic nginx                                   1                                       [OK]
centos/nginx-110-centos7           Platform for running nginx 1.10 or building …   0                                       
[root@node1 ~]#
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　提示：docker search 命令是从dockerhub中检索对应镜像的命令；该命令有个-s选项，是用于指定镜像的星级；通过使用-s选项可以筛选出我们指定星级以上的镜像；&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;37&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
[root@node1 ~]# docker search -s 5000 nginx
Flag --stars has been deprecated, use --filter=stars=3 instead
NAME                DESCRIPTION                STARS               OFFICIAL            AUTOMATED
nginx               Official build of Nginx.   13255               [OK]                
[root@node1 ~]# docker search -s 500 nginx 
Flag --stars has been deprecated, use --filter=stars=3 instead
NAME                      DESCRIPTION                                     STARS               OFFICIAL            AUTOMATED
nginx                     Official build of Nginx.                        13255               [OK]                
jwilder/nginx-proxy       Automated Nginx reverse proxy for docker con…   1812                                    [OK]
richarvey/nginx-php-fpm   Container running Nginx + PHP-FPM capable of…   775                                     [OK]
[root@node1 ~]# 
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　镜像下载&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;35&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
[root@node1 ~]# docker pull nginx
Using default tag: latest
latest: Pulling from library/nginx
afb6ec6fdc1c: Pull complete 
b90c53a0b692: Pull complete 
11fa52a0fdc0: Pull complete 
Digest: sha256:30dfa439718a17baafefadf16c5e7c9d0a1cde97b4fd84f63b69e13513be7097
Status: Downloaded newer image for nginx:latest
docker.io/library/nginx:latest
[root@node1 ~]# docker image pull centos:7
7: Pulling from library/centos
524b0c1e57f8: Pull complete 
Digest: sha256:e9ce0b76f29f942502facd849f3e468232492b259b9d9f076f71b392293f1582
Status: Downloaded newer image for centos:7
docker.io/library/centos:7
[root@node1 ~]#
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　提示：docker pull和docker image pull两个命令都是从dockerhub仓库中下载指定镜像；这里需要提示一下，docker的镜像是镜像名+版本组成的；如果我们只指定了镜像名称没有指定版本，默认是latest版本（最新版）；&lt;/p&gt;
&lt;p&gt;　　查看镜像列表&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;35&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
[root@node1 ~]# docker image ls
REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE
nginx               latest              9beeba249f3e        13 days ago         127MB
centos              7                   b5b4d78bc90c        3 weeks ago         203MB
[root@node1 ~]# docker images
REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE
nginx               latest              9beeba249f3e        13 days ago         127MB
centos              7                   b5b4d78bc90c        3 weeks ago         203MB
[root@node1 ~]#
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　提示：docker image ls 等同docker images 这两个命令都是用来查看本地仓库所有镜像列表；&lt;/p&gt;
&lt;p&gt;　　除了上面的两种操作外，还有其他操作，我们可以通过docker image --help 来查看对镜像的命令帮助；如下&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;35&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
[root@node1 ~]# docker image --help

Usage:  docker image COMMAND

Manage images

Commands:
  build       Build an image from a Dockerfile
  history     Show the history of an image
  import      Import the contents from a tarball to create a filesystem image
  inspect     Display detailed information on one or more images
  load        Load an image from a tar archive or STDIN
  ls          List images
  prune       Remove unused images
  pull        Pull an image or a repository from a registry
  push        Push an image or a repository to a registry
  rm          Remove one or more images
  save        Save one or more images to a tar archive (streamed to STDOUT by default)
  tag         Create a tag TARGET_IMAGE that refers to SOURCE_IMAGE

Run 'docker image COMMAND --help' for more information on a command.
[root@node1 ~]# 
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　提示：build子命令是基于dockerfile来构建镜像；history：显示镜像的历史制作过程；import：从tarball导入内容以创建文件系统镜像；inspect：显示镜像的详细信息；load：指定本地一个tar包格式的文件从标准输入导入镜像；prune：移除未使用的镜像；push：把指定镜像推送到仓库；rm：删除一个或多个镜像；save：导出一个或多个镜像到本地指定tar文件中；默认是从标准输出导出；tag：对指定镜像新建一个标签；&lt;/p&gt;
&lt;p&gt;　　查看镜像历史&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;35&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
[root@node1 ~]# docker image history   nginx              
IMAGE               CREATED             CREATED BY                                      SIZE                COMMENT
9beeba249f3e        13 days ago         /bin/sh -c #(nop)  CMD [&quot;nginx&quot; &quot;-g&quot; &quot;daemon…   0B                  
&amp;lt;missing&amp;gt;           13 days ago         /bin/sh -c #(nop)  STOPSIGNAL SIGTERM           0B                  
&amp;lt;missing&amp;gt;           13 days ago         /bin/sh -c #(nop)  EXPOSE 80                    0B                  
&amp;lt;missing&amp;gt;           13 days ago         /bin/sh -c ln -sf /dev/stdout /var/log/nginx…   22B                 
&amp;lt;missing&amp;gt;           13 days ago         /bin/sh -c set -x     &amp;amp;&amp;amp; addgroup --system -…   57.6MB              
&amp;lt;missing&amp;gt;           13 days ago         /bin/sh -c #(nop)  ENV PKG_RELEASE=1~buster     0B                  
&amp;lt;missing&amp;gt;           13 days ago         /bin/sh -c #(nop)  ENV NJS_VERSION=0.3.9        0B                  
&amp;lt;missing&amp;gt;           13 days ago         /bin/sh -c #(nop)  ENV NGINX_VERSION=1.17.10    0B                  
&amp;lt;missing&amp;gt;           13 days ago         /bin/sh -c #(nop)  LABEL maintainer=NGINX Do…   0B                  
&amp;lt;missing&amp;gt;           2 weeks ago         /bin/sh -c #(nop)  CMD [&quot;bash&quot;]                 0B                  
&amp;lt;missing&amp;gt;           2 weeks ago         /bin/sh -c #(nop) ADD file:7780c81c33e6cc5b6…   69.2MB              
[root@node1 ~]# 
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　提示：以上默认是显示部分命令，如果要显示命令全部可以使用 --no-trunc选项；&lt;/p&gt;
&lt;p&gt;　　查看镜像详细信息&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;108&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
[root@node1 ~]# docker image inspect nginx
[
    {
        &quot;Id&quot;: &quot;sha256:9beeba249f3ee158d3e495a6ac25c5667ae2de8a43ac2a8bfd2bf687a58c06c9&quot;,
        &quot;RepoTags&quot;: [
            &quot;nginx:latest&quot;
        ],
        &quot;RepoDigests&quot;: [
            &quot;nginx@sha256:30dfa439718a17baafefadf16c5e7c9d0a1cde97b4fd84f63b69e13513be7097&quot;
        ],
        &quot;Parent&quot;: &quot;&quot;,
        &quot;Comment&quot;: &quot;&quot;,
        &quot;Created&quot;: &quot;2020-05-15T20:15:52.366876108Z&quot;,
        &quot;Container&quot;: &quot;ed0a25109c2acf3dcb0b4926cad00692e01717b8417d36e50928aa6f03a711ca&quot;,
        &quot;ContainerConfig&quot;: {
            &quot;Hostname&quot;: &quot;ed0a25109c2a&quot;,
            &quot;Domainname&quot;: &quot;&quot;,
            &quot;User&quot;: &quot;&quot;,
            &quot;AttachStdin&quot;: false,
            &quot;AttachStdout&quot;: false,
            &quot;AttachStderr&quot;: false,
            &quot;ExposedPorts&quot;: {
                &quot;80/tcp&quot;: {}
            },
            &quot;Tty&quot;: false,
            &quot;OpenStdin&quot;: false,
            &quot;StdinOnce&quot;: false,
            &quot;Env&quot;: [
                &quot;PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin&quot;,
                &quot;NGINX_VERSION=1.17.10&quot;,
                &quot;NJS_VERSION=0.3.9&quot;,
                &quot;PKG_RELEASE=1~buster&quot;
            ],
            &quot;Cmd&quot;: [
                &quot;/bin/sh&quot;,
                &quot;-c&quot;,
                &quot;#(nop) &quot;,
                &quot;CMD [\&quot;nginx\&quot; \&quot;-g\&quot; \&quot;daemon off;\&quot;]&quot;
            ],
            &quot;ArgsEscaped&quot;: true,
            &quot;Image&quot;: &quot;sha256:23edbb1066877bcc22193518edb32ee3a50a18d52787c4f45f9a8bca95d329eb&quot;,
            &quot;Volumes&quot;: null,
            &quot;WorkingDir&quot;: &quot;&quot;,
            &quot;Entrypoint&quot;: null,
            &quot;OnBuild&quot;: null,
            &quot;Labels&quot;: {
                &quot;maintainer&quot;: &quot;NGINX Docker Maintainers &amp;lt;docker-maint@nginx.com&amp;gt;&quot;
            },
            &quot;StopSignal&quot;: &quot;SIGTERM&quot;
        },
        &quot;DockerVersion&quot;: &quot;18.09.7&quot;,
        &quot;Author&quot;: &quot;&quot;,
        &quot;Config&quot;: {
            &quot;Hostname&quot;: &quot;&quot;,
            &quot;Domainname&quot;: &quot;&quot;,
            &quot;User&quot;: &quot;&quot;,
            &quot;AttachStdin&quot;: false,
            &quot;AttachStdout&quot;: false,
            &quot;AttachStderr&quot;: false,
            &quot;ExposedPorts&quot;: {
                &quot;80/tcp&quot;: {}
            },
            &quot;Tty&quot;: false,
            &quot;OpenStdin&quot;: false,
            &quot;StdinOnce&quot;: false,
            &quot;Env&quot;: [
                &quot;PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin&quot;,
                &quot;NGINX_VERSION=1.17.10&quot;,
                &quot;NJS_VERSION=0.3.9&quot;,
                &quot;PKG_RELEASE=1~buster&quot;
            ],
            &quot;Cmd&quot;: [
                &quot;nginx&quot;,
                &quot;-g&quot;,
                &quot;daemon off;&quot;
            ],
            &quot;ArgsEscaped&quot;: true,
            &quot;Image&quot;: &quot;sha256:23edbb1066877bcc22193518edb32ee3a50a18d52787c4f45f9a8bca95d329eb&quot;,
            &quot;Volumes&quot;: null,
            &quot;WorkingDir&quot;: &quot;&quot;,
            &quot;Entrypoint&quot;: null,
            &quot;OnBuild&quot;: null,
            &quot;Labels&quot;: {
                &quot;maintainer&quot;: &quot;NGINX Docker Maintainers &amp;lt;docker-maint@nginx.com&amp;gt;&quot;
            },
            &quot;StopSignal&quot;: &quot;SIGTERM&quot;
        },
        &quot;Architecture&quot;: &quot;amd64&quot;,
        &quot;Os&quot;: &quot;linux&quot;,
        &quot;Size&quot;: 126773960,
        &quot;VirtualSize&quot;: 126773960,
        &quot;GraphDriver&quot;: {
            &quot;Data&quot;: {
                &quot;LowerDir&quot;: &quot;/var/lib/docker/overlay2/4728ce1723abfab65d8065858c616360f45e258d53e7573be8e0f7bbe338be5d/diff:/var/lib/docker/overlay2/e998de0cd64ffe2b0410fb4595cbc3358b1b28626c8d356c6c6ac0ef97234a31/diff&quot;,
                &quot;MergedDir&quot;: &quot;/var/lib/docker/overlay2/d9c40ef0bb9226e6a84b720b9c6ce18ed46b4f61caab567b5ee13a801dbc7ef5/merged&quot;,
                &quot;UpperDir&quot;: &quot;/var/lib/docker/overlay2/d9c40ef0bb9226e6a84b720b9c6ce18ed46b4f61caab567b5ee13a801dbc7ef5/diff&quot;,
                &quot;WorkDir&quot;: &quot;/var/lib/docker/overlay2/d9c40ef0bb9226e6a84b720b9c6ce18ed46b4f61caab567b5ee13a801dbc7ef5/work&quot;
            },
            &quot;Name&quot;: &quot;overlay2&quot;
        },
        &quot;RootFS&quot;: {
            &quot;Type&quot;: &quot;layers&quot;,
            &quot;Layers&quot;: [
                &quot;sha256:ffc9b21953f4cd7956cdf532a5db04ff0a2daa7475ad796f1bad58cfbaf77a07&quot;,
                &quot;sha256:2f4accd375d93db49e5a47c9bebe4e0dd3cef35f765f5cd36840a986435affc9&quot;,
                &quot;sha256:6c7de695ede33d90077f01d60ec29e6a51552a3e350757018ff1b1ecd6cee0bf&quot;
            ]
        },
        &quot;Metadata&quot;: {
            &quot;LastTagTime&quot;: &quot;0001-01-01T00:00:00Z&quot;
        }
    }
]
[root@node1 ~]# 
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　提示：docker image inspect 是显示指定镜像的详细信息；其中-f选项可以只显示指定字段；起着过滤功能&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;35&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
[root@node1 ~]# docker image inspect -f {{.RootFS}} nginx        
{layers [sha256:ffc9b21953f4cd7956cdf532a5db04ff0a2daa7475ad796f1bad58cfbaf77a07 sha256:2f4accd375d93db49e5a47c9bebe4e0dd3cef35f765f5cd36840a986435affc9 sha256:6c7de695ede33d90077f01d60ec29e6a51552a3e350757018ff1b1ecd6cee0bf] }
[root@node1 ~]# docker image inspect -f {{.RootFS.Type}} nginx 
layers
[root@node1 ~]# docker image inspect -f {{.RootFS.Layers}} nginx    
[sha256:ffc9b21953f4cd7956cdf532a5db04ff0a2daa7475ad796f1bad58cfbaf77a07 sha256:2f4accd375d93db49e5a47c9bebe4e0dd3cef35f765f5cd36840a986435affc9 sha256:6c7de695ede33d90077f01d60ec29e6a51552a3e350757018ff1b1ecd6cee0bf]
[root@node1 ~]# 
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　提示：-f指定字段必须从“.”开始且需要用双大括号把字段括起来；如果一级字段是下还有二级字段，可以使用“.”加二级字段名称来表示显示二级字段的值；以此类推；&lt;/p&gt;
&lt;p&gt;　　删除镜像&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;35&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
[root@node1 ~]# docker pull busybox
Using default tag: latest
latest: Pulling from library/busybox
d9cbbca60e5f: Pull complete 
Digest: sha256:836945da1f3afe2cfff376d379852bbb82e0237cb2925d53a13f53d6e8a8c48c
Status: Downloaded newer image for busybox:latest
docker.io/library/busybox:latest
[root@node1 ~]# docker pull alpine
Using default tag: latest
latest: Pulling from library/alpine
cbdbe7a5bc2a: Pull complete 
Digest: sha256:9a839e63dad54c3a6d1834e29692c8492d93f90c59c978c1ed79109ea4fb9a54
Status: Downloaded newer image for alpine:latest
docker.io/library/alpine:latest
[root@node1 ~]# docker images
REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE
nginx               latest              9beeba249f3e        13 days ago         127MB
busybox             latest              78096d0a5478        2 weeks ago         1.22MB
centos              7                   b5b4d78bc90c        3 weeks ago         203MB
alpine              latest              f70734b6a266        5 weeks ago         5.61MB
[root@node1 ~]# docker image rm centos:7
Untagged: centos:7
Untagged: centos@sha256:e9ce0b76f29f942502facd849f3e468232492b259b9d9f076f71b392293f1582
Deleted: sha256:b5b4d78bc90ccd15806443fb881e35b5ddba924e2f475c1071a38a3094c3081d
Deleted: sha256:edf3aa290fb3c255a84fe836109093fbfeef65c08544f655fad8d6afb53868ba
[root@node1 ~]# docker images
REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE
nginx               latest              9beeba249f3e        13 days ago         127MB
busybox             latest              78096d0a5478        2 weeks ago         1.22MB
alpine              latest              f70734b6a266        5 weeks ago         5.61MB
[root@node1 ~]#
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　提示：删除镜像的前提是该镜像没有运行成容器；docker image rm 等同docker rmi命令；如果需要强行删除已经运行为容器的镜像，可以使用-f选项来指定；&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;35&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
[root@node1 ~]# docker images
REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE
alpine              latest              f70734b6a266        5 weeks ago         5.61MB
[root@node1 ~]# docker run --name a1 -d alpine
d0abe1efe7138dfb409574a785e77b4941a50534a23740d6f7d2f1af36d05589
[root@node1 ~]# docker ps -a
CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS                     PORTS               NAMES
d0abe1efe713        alpine              &quot;/bin/sh&quot;           4 seconds ago       Exited (0) 2 seconds ago                       a1
[root@node1 ~]# docker image rm alpine
Error response from daemon: conflict: unable to remove repository reference &quot;alpine&quot; (must force) - container d0abe1efe713 is using its referenced image f70734b6a266
[root@node1 ~]# docker rmi alpine
Error response from daemon: conflict: unable to remove repository reference &quot;alpine&quot; (must force) - container d0abe1efe713 is using its referenced image f70734b6a266
[root@node1 ~]# docker image rm -f alpine
Untagged: alpine:latest
Untagged: alpine@sha256:9a839e63dad54c3a6d1834e29692c8492d93f90c59c978c1ed79109ea4fb9a54
Deleted: sha256:f70734b6a266dcb5f44c383274821207885b549b75c8e119404917a61335981a
[root@node1 ~]# docker images
REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE
[root@node1 ~]# 
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　提示：只要运行为容器，不管容器是否是运行状态，删除镜像都需要先删除容器在删除镜像，否则就需要用-f来指定强制删除镜像；通常不建议这么干；&lt;/p&gt;
&lt;p&gt;　　给镜像打标签&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;35&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
[root@node1 ~]# docker images
REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE
alpine              latest              f70734b6a266        5 weeks ago         5.61MB
[root@node1 ~]# docker image tag alpine:latest alpine:v1
[root@node1 ~]# docker image tag alpine:latest alpine:v2
[root@node1 ~]# docker images
REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE
alpine              latest              f70734b6a266        5 weeks ago         5.61MB
alpine              v1                  f70734b6a266        5 weeks ago         5.61MB
alpine              v2                  f70734b6a266        5 weeks ago         5.61MB
[root@node1 ~]# docker tag alpine alpine:v3 
[root@node1 ~]# docker images
REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE
alpine              latest              f70734b6a266        5 weeks ago         5.61MB
alpine              v1                  f70734b6a266        5 weeks ago         5.61MB
alpine              v2                  f70734b6a266        5 weeks ago         5.61MB
alpine              v3                  f70734b6a266        5 weeks ago         5.61MB
[root@node1 ~]# 
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　提示：docker image tag 和docker tag 等同；都是用于给镜像打标签；打标签的意思类似给镜像取别名的意思；&lt;/p&gt;
&lt;p&gt;　　移除未使用的镜像&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;35&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
[root@node1 ~]# docker images
REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE
nginx               latest              9beeba249f3e        13 days ago         127MB
alpine              latest              f70734b6a266        5 weeks ago         5.61MB
alpine              v1                  f70734b6a266        5 weeks ago         5.61MB
alpine              v2                  f70734b6a266        5 weeks ago         5.61MB
alpine              v3                  f70734b6a266        5 weeks ago         5.61MB
[root@node1 ~]# docker ps -a
CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS                      PORTS               NAMES
d0abe1efe713        alpine              &quot;/bin/sh&quot;           11 minutes ago      Exited (0) 11 minutes ago                       a1
[root@node1 ~]# docker image prune -a
WARNING! This will remove all images without at least one container associated to them.
Are you sure you want to continue? [y/N] y
Deleted Images:
untagged: alpine:latest
untagged: alpine:v1
untagged: alpine:v2
untagged: nginx:latest
untagged: nginx@sha256:30dfa439718a17baafefadf16c5e7c9d0a1cde97b4fd84f63b69e13513be7097
deleted: sha256:9beeba249f3ee158d3e495a6ac25c5667ae2de8a43ac2a8bfd2bf687a58c06c9
deleted: sha256:8fb6373b4cca3383756d7fd7843dd92f95827e5f2913609e09a9621dcddb3752
deleted: sha256:8b09841626797a03a9fe5e73aa38aeacf9ff0ce85a3004236ff35234eec3b35c
deleted: sha256:ffc9b21953f4cd7956cdf532a5db04ff0a2daa7475ad796f1bad58cfbaf77a07

Total reclaimed space: 126.8MB
[root@node1 ~]# docker images
REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE
alpine              v3                  f70734b6a266        5 weeks ago         5.61MB
[root@node1 ~]# 
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　提示：-a表示移除全部未使用的镜像；如果不想交互式确认可以使用-f选项，-f表示强制删除，不询问；&lt;/p&gt;
&lt;p&gt;　　把指定镜像推送到仓库&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;35&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
[root@node1 ~]# docker images
REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE
linux1874/myimg     latest              e408b1c6e04f        6 days ago          1.22MB
linux1874/myimg     v0.1                e408b1c6e04f        6 days ago          1.22MB
alpine              v3                  f70734b6a266        5 weeks ago         5.61MB
[root@node1 ~]# docker image push linux1874/myimg
The push refers to repository [docker.io/linux1874/myimg]
Get https://registry-1.docker.io/v2/: net/http: request canceled (Client.Timeout exceeded while awaiting headers)
[root@node1 ~]# docker image push linux1874/myimg
The push refers to repository [docker.io/linux1874/myimg]
4d567d38fed1: Layer already exists 
1079c30efc82: Layer already exists 
latest: digest: sha256:6c2f6b7a0df5ca0a46cd46d858e9fd564169471e6715c0155027ac77672508f6 size: 734
4d567d38fed1: Layer already exists 
1079c30efc82: Layer already exists 
v0.1: digest: sha256:6c2f6b7a0df5ca0a46cd46d858e9fd564169471e6715c0155027ac77672508f6 size: 734
[root@node1 ~]# 
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　提示：如果是往自己私有仓库里推送镜像，需要先登录，然后在推镜像；这里需要注意一点镜像的命名需要同仓库一样；如果是顶级仓库则没有“/”分割；如果推送镜像没有指定版本，默认会把本地指定镜像的所有版本的推送到仓库；&lt;/p&gt;
&lt;p&gt;　　镜像导出&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;35&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
[root@node1 ~]# docker images
REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE
linux1874/myimg     latest              e408b1c6e04f        6 days ago          1.22MB
linux1874/myimg     v0.1                e408b1c6e04f        6 days ago          1.22MB
alpine              v3                  f70734b6a266        5 weeks ago         5.61MB
[root@node1 ~]# docker save alpine &amp;gt; alpine.tar.gz
[root@node1 ~]# ls
alpine.tar.gz
[root@node1 ~]# 
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　提示：docker save默认是把镜像输出到标准输出，所以我们导出时需要用重定向的方式存储到某个文件中，通常这个文件是tar格式的文件；&lt;/p&gt;
&lt;p&gt;　　镜像导入&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;35&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
[root@node1 ~]# scp alpine.tar.gz 192.168.0.22:/root
The authenticity of host '192.168.0.22 (192.168.0.22)' can't be established.
ECDSA key fingerprint is SHA256:EG9nua4JJuUeofheXlgQeL9hX5H53JynOqf2vf53mII.
ECDSA key fingerprint is MD5:57:83:e6:46:2c:4b:bb:33:13:56:17:f7:fd:76:71:cc.
Are you sure you want to continue connecting (yes/no)? yes
Warning: Permanently added '192.168.0.22' (ECDSA) to the list of known hosts.
alpine.tar.gz                                                   100% 5750KB  31.9MB/s   00:00    
[root@node1 ~]# 
&lt;/pre&gt;&lt;/div&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;38&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
[root@docker_node1 ~]# ip a s ens33
2: ens33: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; mtu 1500 qdisc pfifo_fast state UP qlen 1000
    link/ether 00:0c:29:22:36:7f brd ff:ff:ff:ff:ff:ff
    inet 192.168.0.22/24 brd 192.168.0.255 scope global ens33
       valid_lft forever preferred_lft forever
    inet6 fe80::20c:29ff:fe22:367f/64 scope link 
       valid_lft forever preferred_lft forever
[root@docker_node1 ~]# ls
alpine.tar.gz  
[root@docker_node1 ~]# docker images
WARNING: Error loading config file: /root/.docker/config.json: EOF
REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE
linux1874/myimg     v0.1                e408b1c6e04f        6 days ago          1.22MB
wordpress           latest              c3fa1c8546fb        4 weeks ago         540MB
mysql               5.7                 f965319e89de        4 weeks ago         448MB
httpd               2.4.37-alpine       dfd436f9a5d8        17 months ago       91.8MB
[root@docker_node1 ~]# docker load -i alpine.tar.gz 
WARNING: Error loading config file: /root/.docker/config.json: EOF
3e207b409db3: Loading layer  5.879MB/5.879MB
Loaded image: alpine:v3
[root@docker_node1 ~]# docker images
WARNING: Error loading config file: /root/.docker/config.json: EOF
REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE
linux1874/myimg     v0.1                e408b1c6e04f        6 days ago          1.22MB
wordpress           latest              c3fa1c8546fb        4 weeks ago         540MB
mysql               5.7                 f965319e89de        4 weeks ago         448MB
alpine              v3                  f70734b6a266        5 weeks ago         5.61MB
httpd               2.4.37-alpine       dfd436f9a5d8        17 months ago       91.8MB
[root@docker_node1 ~]#
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　有关容器的操作&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;38&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
[root@node1 ~]# docker container --help
WARNING: Error loading config file: /root/.docker/config.json: EOF

Usage:  docker container COMMAND

Manage containers

Commands:
  attach      Attach local standard input, output, and error streams to a running container
  commit      Create a new image from a container's changes
  cp          Copy files/folders between a container and the local filesystem
  create      Create a new container
  diff        Inspect changes to files or directories on a container's filesystem
  exec        Run a command in a running container
  export      Export a container's filesystem as a tar archive
  inspect     Display detailed information on one or more containers
  kill        Kill one or more running containers
  logs        Fetch the logs of a container
  ls          List containers
  pause       Pause all processes within one or more containers
  port        List port mappings or a specific mapping for the container
  prune       Remove all stopped containers
  rename      Rename a container
  restart     Restart one or more containers
  rm          Remove one or more containers
  run         Run a command in a new container
  start       Start one or more stopped containers
  stats       Display a live stream of container(s) resource usage statistics
  stop        Stop one or more running containers
  top         Display the running processes of a container
  unpause     Unpause all processes within one or more containers
  update      Update configuration of one or more containers
  wait        Block until one or more containers stop, then print their exit codes

Run 'docker container COMMAND --help' for more information on a command.
[root@node1 ~]# 
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　提示：docker container 操作大概有这么多；其中run ,exec,kill,port,logs,inspect用的比较多；其余命令其实我们看子命令就大概知道什么意思；如果需要查看某个子命令的具体用法和选项，我们可以加上子命令 然后用--help来查看帮助即可；如下&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;37&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
[root@node1 ~]# docker container logs --help
WARNING: Error loading config file: /root/.docker/config.json: EOF

Usage:  docker container logs [OPTIONS] CONTAINER

Fetch the logs of a container

Options:
      --details        Show extra details provided to logs
  -f, --follow         Follow log output
      --since string   Show logs since timestamp (e.g. 2013-01-02T13:23:37) or relative
                       (e.g. 42m for 42 minutes)
      --tail string    Number of lines to show from the end of the logs (default &quot;all&quot;)
  -t, --timestamps     Show timestamps
      --until string   Show logs before a timestamp (e.g. 2013-01-02T13:23:37) or relative
                       (e.g. 42m for 42 minutes)
[root@node1 ~]# 
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　提示：以上就是查看logs指明的用法和选项说明；&lt;/p&gt;
&lt;p&gt;　　创建容器&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;35&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
[root@node1 ~]# docker images
REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE
linux1874/myimg     latest              e408b1c6e04f        6 days ago          1.22MB
linux1874/myimg     v0.1                e408b1c6e04f        6 days ago          1.22MB
alpine              v3                  f70734b6a266        5 weeks ago         5.61MB
[root@node1 ~]# docker container create alpine
Unable to find image 'alpine:latest' locally
latest: Pulling from library/alpine
Digest: sha256:9a839e63dad54c3a6d1834e29692c8492d93f90c59c978c1ed79109ea4fb9a54
Status: Downloaded newer image for alpine:latest
13bcdb5067a31389acd75b8218f73c9d759590b81e178084de3c8110af330d0b
[root@node1 ~]# docker container ls
CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES
[root@node1 ~]# docker container ls -a
CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS                      PORTS               NAMES
13bcdb5067a3        alpine              &quot;/bin/sh&quot;           17 seconds ago      Created                                         tender_grothendieck
d0abe1efe713        alpine              &quot;/bin/sh&quot;           49 minutes ago      Exited (0) 49 minutes ago                       a1
[root@node1 ~]# docker ps 
CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES
[root@node1 ~]# docker ps -a
CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS                      PORTS               NAMES
13bcdb5067a3        alpine              &quot;/bin/sh&quot;           3 minutes ago       Created                                         tender_grothendieck
d0abe1efe713        alpine              &quot;/bin/sh&quot;           53 minutes ago      Exited (0) 53 minutes ago                       a1
[root@node1 ~]# 
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　提示：用create命令创建容器，容器不会自动运行；查看容器用ls命令，其中ls不加选项表示查看运行状态的容器列表，-a表示查看所有状态容器列表；docker container ls 就等同docker ps 都用于查看运行态容器列表； &lt;/p&gt;
&lt;p&gt;　　创建并运行容器&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;35&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
[root@node1 ~]# docker ps -a
CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES
[root@node1 ~]# docker images 
REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE
linux1874/myimg     latest              e408b1c6e04f        6 days ago          1.22MB
linux1874/myimg     v0.1                e408b1c6e04f        6 days ago          1.22MB
alpine              latest              f70734b6a266        5 weeks ago         5.61MB
alpine              v3                  f70734b6a266        5 weeks ago         5.61MB
[root@node1 ~]# docker run --name a1 -d linux1874/myimg
6be4be4e54690bc10fb07b12cc00c3173636ed95bd456f04ed2cca6cb8cc93e9
[root@node1 ~]# docker ps -a
CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS               NAMES
6be4be4e5469        linux1874/myimg     &quot;/bin/sh -c '/bin/ht…&quot;   4 seconds ago       Up 2 seconds                            a1
[root@node1 ~]# 
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　提示：docker run 等同docker container run；其中--name表示指定容器的的名称；-d表示后台运行，不占据现有终端；用run命令表示运行一容器，如果本地没有镜像，它默认会从dockerhub上去拖镜像，然后直接创建并运行容器；如果有镜像，则直接创建并运行为容器；&lt;/p&gt;
&lt;p&gt;　　停止、启动、重启容器&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;35&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
[root@node1 ~]# docker ps -a
CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS               NAMES
6be4be4e5469        linux1874/myimg     &quot;/bin/sh -c '/bin/ht…&quot;   4 minutes ago       Up 4 minutes                            a1
[root@node1 ~]# docker stop a1
a1
[root@node1 ~]# docker ps -a
CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS                       PORTS               NAMES
6be4be4e5469        linux1874/myimg     &quot;/bin/sh -c '/bin/ht…&quot;   4 minutes ago       Exited (137) 5 seconds ago                       a1
[root@node1 ~]# docker start a1
a1
[root@node1 ~]# docker ps -a
CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS               NAMES
6be4be4e5469        linux1874/myimg     &quot;/bin/sh -c '/bin/ht…&quot;   4 minutes ago       Up 3 seconds                            a1
[root@node1 ~]# docker restart a1
a1
[root@node1 ~]# docker ps -a
CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS               NAMES
6be4be4e5469        linux1874/myimg     &quot;/bin/sh -c '/bin/ht…&quot;   5 minutes ago       Up 6 seconds                            a1
[root@node1 ~]#
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　提示：以上命令都支持后面跟多个容器，表示同时操作多个容器；docker start;docker stop ;docker restart;这三个命令等同docker contaier start,docker container stop ,docker container restart；停止容器除了正常用stop停止外，还可以使用kill命令停止容器；两者不同的是一个是给docker进程发送15号信号，正常停止容器，一个是发送9号信号，强杀容器；如下&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1503305/202005/1503305-20200530003334546-1776953249.gif&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　提示：--rm选项表示启动一次性容器，容器停止后，自动删除容器；&lt;/p&gt;
&lt;p&gt;　　查看容器日志&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;40&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
[root@node1 ~]# docker ps -a
CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES
[root@node1 ~]# docker images
REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE
linux1874/myimg     latest              e408b1c6e04f        6 days ago          1.22MB
linux1874/myimg     v0.1                e408b1c6e04f        6 days ago          1.22MB
nginx               stable-alpine       ab94f84cc474        5 weeks ago         21.3MB
alpine              latest              f70734b6a266        5 weeks ago         5.61MB
alpine              v3                  f70734b6a266        5 weeks ago         5.61MB
[root@node1 ~]# docker run --name n1 -d nginx:stable-alpine
a859fda7c6021a1e5398f744826d5a62257eb1d272b622ea32dac39f83009fc9
[root@node1 ~]# docker ps -a
CONTAINER ID        IMAGE                 COMMAND                  CREATED             STATUS              PORTS               NAMES
a859fda7c602        nginx:stable-alpine   &quot;nginx -g 'daemon of…&quot;   3 seconds ago       Up 2 seconds        80/tcp              n1
[root@node1 ~]# docker container inspect -f {{.NetworkSettings.Networks.bridge.IPAddress}} n1
172.17.0.2
[root@node1 ~]# curl http://172.17.0.2
&amp;lt;!DOCTYPE html&amp;gt;
&amp;lt;html&amp;gt;
&amp;lt;head&amp;gt;
&amp;lt;title&amp;gt;Welcome to nginx!&amp;lt;/title&amp;gt;
&amp;lt;style&amp;gt;
    body {
        width: 35em;
        margin: 0 auto;
        font-family: Tahoma, Verdana, Arial, sans-serif;
    }
&amp;lt;/style&amp;gt;
&amp;lt;/head&amp;gt;
&amp;lt;body&amp;gt;
&amp;lt;h1&amp;gt;Welcome to nginx!&amp;lt;/h1&amp;gt;
&amp;lt;p&amp;gt;If you see this page, the nginx web server is successfully installed and
working. Further configuration is required.&amp;lt;/p&amp;gt;

&amp;lt;p&amp;gt;For online documentation and support please refer to
&amp;lt;a href=&quot;http://nginx.org/&quot;&amp;gt;nginx.org&amp;lt;/a&amp;gt;.&amp;lt;br/&amp;gt;
Commercial support is available at
&amp;lt;a href=&quot;http://nginx.com/&quot;&amp;gt;nginx.com&amp;lt;/a&amp;gt;.&amp;lt;/p&amp;gt;

&amp;lt;p&amp;gt;&amp;lt;em&amp;gt;Thank you for using nginx.&amp;lt;/em&amp;gt;&amp;lt;/p&amp;gt;
&amp;lt;/body&amp;gt;
&amp;lt;/html&amp;gt;
[root@node1 ~]# elinks -dump http://172.17.0.2
                               Welcome to nginx!

   If you see this page, the nginx web server is successfully installed and
   working. Further configuration is required.

   For online documentation and support please refer to [1]nginx.org.
   Commercial support is available at [2]nginx.com.

   Thank you for using nginx.

References

   Visible links
   1. http://nginx.org/
   2. http://nginx.com/
[root@node1 ~]# docker logs n1
172.17.0.1 - - [29/May/2020:16:20:15 +0000] &quot;GET / HTTP/1.1&quot; 200 612 &quot;-&quot; &quot;curl/7.29.0&quot; &quot;-&quot;
172.17.0.1 - - [29/May/2020:16:20:27 +0000] &quot;GET / HTTP/1.1&quot; 200 612 &quot;-&quot; &quot;ELinks/0.12pre6 (textmode; Linux; -)&quot; &quot;-&quot;
[root@node1 ~]# docker container logs n1
172.17.0.1 - - [29/May/2020:16:20:15 +0000] &quot;GET / HTTP/1.1&quot; 200 612 &quot;-&quot; &quot;curl/7.29.0&quot; &quot;-&quot;
172.17.0.1 - - [29/May/2020:16:20:27 +0000] &quot;GET / HTTP/1.1&quot; 200 612 &quot;-&quot; &quot;ELinks/0.12pre6 (textmode; Linux; -)&quot; &quot;-&quot;
[root@node1 ~]# 
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　提示：docker container logs等同docker logs命令，用于查看指定容器的日志信息；跟踪某个容器的日志信息可以使用-f选项；该选项同tail -f选项一样；&lt;/p&gt;
&lt;p&gt;　　删除容器&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;35&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
[root@node1 ~]# docker ps -a
CONTAINER ID        IMAGE                 COMMAND                  CREATED             STATUS              PORTS               NAMES
d6bd7c0a29bb        nginx:stable-alpine   &quot;nginx -g 'daemon of…&quot;   3 seconds ago       Up 3 seconds        80/tcp              n1
[root@node1 ~]# docker container rm n1
Error response from daemon: You cannot remove a running container d6bd7c0a29bb4ea4cb60266727bd534fa086c8a70831dfea00791034bb2a84c4. Stop the container before attempting removal or force remove
[root@node1 ~]# docker container rm -f n1
n1
[root@node1 ~]# 
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　提示：删除容器必须得是停止状态的容器才可正常删除；如果删除正在运行的容器需要用到-f选项；docker rm 等同docker container rm 用于删除容器；&lt;/p&gt;
&lt;p&gt;　　附加到现运行的容器终端&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1503305/202005/1503305-20200530004254442-166967125.gif&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　提示：容器运行服务和传统系统上运行服务端方式有点不同，传统运行服务都是把服务运行到后台，而容器运行服务通常是把服务运行为前台；所以我们进入到容器内部终端是可以直接看到nginx访问日志的输出的；docker attach命令等同docker container attach；&lt;/p&gt;
&lt;p&gt;　　通过上面对镜像和容器的一些基本操作，总结为一点docker客户端命令就是对docker的资源对象做增删查改操作，每个资源对象后面都有一些子命令支持对该资源的操作；我们可以使用docker +资源对象+--help 来查看该资源对象支持那些操作，每个子命令的用法可以使用docker + 资源对象 + 子命令 + --help来查看具体资源对象子命令的操作命令用法和选项的说明；有关网络和卷的操作我这里就不多去演示；有兴趣的朋友可以试试docker + 资源对象 + --help去了解每个资源对象的用法吧；&lt;/p&gt;
</description>
<pubDate>Fri, 29 May 2020 17:13:00 +0000</pubDate>
<dc:creator>Linux-1874</dc:creator>
<og:description>前面我们聊了docker的基本概念、架构、镜像、网络、数据卷，回顾请参考https://www.cnblogs.com/qiuhom-1874/category/1766327.html；今天这篇博客</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/qiuhom-1874/p/12990424.html</dc:identifier>
</item>
</channel>
</rss>