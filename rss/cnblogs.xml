<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="css/feed.xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/" xmlns:og="http://ogp.me/ns#">
<channel>
<atom:link rel="self" href="http://192.168.1.4/fivefilters/makefulltextfeed.php?url=feed.cnblogs.com%2Fblog%2Fsitehome%2Frss&amp;max=10&amp;links=preserve&amp;exc=" />
<atom:link rel="alternate" title="Source URL" href="http://feed.cnblogs.com/blog/sitehome/rss" />
<atom:link rel="related" title="Subscribe to feed" href="http://www.subtome.com/#/subscribe?feeds=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed.cnblogs.com%252Fblog%252Fsitehome%252Frss%26max%3D10%26links%3Dpreserve%26exc%3D&amp;back=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed.cnblogs.com%252Fblog%252Fsitehome%252Frss%26max%3D10%26links%3Dpreserve%26exc%3D" />
<title>博客园_首页</title>
<link></link>
<description>代码改变世界</description>
<item>
<title>RabbitMQ指南之一：&quot;Hello World!&quot; - 无恨之都</title>
<link>http://www.cnblogs.com/wuhenzhidu/p/10781101.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/wuhenzhidu/p/10781101.html</guid>
<description>&lt;p&gt;　　为什么要使用MQ消息中间件？它解决了什么问题？关于为什么要使用消息中间件？消息中间件是如何做到同步变异步、流量削锋、应用解耦的？网上已经有很多说明，我这里就不再说明了，读者可以参考（&lt;a href=&quot;https://www.jianshu.com/p/2820561158c4&quot;&gt;https://www.jianshu.com/p/2820561158c4&lt;/a&gt;）。我在接下来的RabbitMq系列博客里会将官方的讲解翻译过来，同时加以自己的理解整理成博客，希望能和大家共同交流，一起进步。&lt;/p&gt;
&lt;p&gt;　　&lt;img src=&quot;https://img2018.cnblogs.com/blog/1651332/201904/1651332-20190427212439914-531768886.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1651332/201904/1651332-20190427212446396-827073077.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　　　　　　　　　　　　　　　　　RabbitMq原理图&lt;/p&gt;

&lt;p&gt;　　RabbitMq是一个消息中间件：它接收消息、转发消息。你可以把它理解为一个邮局：当你向邮箱里寄出一封信后，邮递员们就能最终将信送到收信人手中。类似的，RabbitMq就好比是一个邮箱、邮局和邮递员。RabbitMq和邮局最大的区别是：RabbitMq接收、转发的都是二进制数据块--消息，而不是纸质的数据文件。&lt;/p&gt;
&lt;p&gt;　　&lt;strong&gt;RabbitMq、消息相关术语如下：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;　　&lt;strong&gt;生产者：&lt;/strong&gt;生产者只发送消息，发送消息的程序即为生产者：&lt;/p&gt;
&lt;p&gt;　　&lt;img src=&quot;https://img2018.cnblogs.com/blog/1651332/201904/1651332-20190427203239150-48128011.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　&lt;strong&gt;消息队列：&lt;/strong&gt;消息队列就相当于RabbitMq中的邮箱名称。尽管消息在你的程序和RabbitMq中流动，但它只能存储在消息队列中。队列本质上是一个大的消息缓存，它能存多少消息，取决于主机的内存和磁盘限制。多个生产者可以往同一个消息队列中发送消息；多个消费者可以从同一个队列中获取数据。我们以下列图形来表示一个消息队列：&lt;/p&gt;
&lt;p&gt;　　&lt;img src=&quot;https://img2018.cnblogs.com/blog/1651332/201904/1651332-20190427203711746-2033345305.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　&lt;strong&gt;消费者：&lt;/strong&gt;消费者是一个等待接收消息的程序：&lt;/p&gt;
&lt;p&gt;　　&lt;img src=&quot;https://img2018.cnblogs.com/blog/1651332/201904/1651332-20190427203841623-1080666304.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　注意：生产者、消费者和RabbitMq可以在不同的机器上；在很多的应用中，一个生产者同时也可能是消费者。&lt;/p&gt;

&lt;p&gt; 　　在这小节里，我们将写一个消息生产者用来发送消息、一个消息消费者来消费消息（接收消息并打印出来）。&lt;/p&gt;
&lt;p&gt;　　在下面图形中，“P”是我们的生产者，“C”是我们的消费者，中间的红框是我们的消息队列，保存了从生产者那里接收到的准备转发到消费方的消息。&lt;/p&gt;
&lt;p&gt;　　&lt;img src=&quot;https://img2018.cnblogs.com/blog/1651332/201904/1651332-20190427204807658-1007898875.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;h4&gt;　　Java客户端类库说明：&lt;/h4&gt;
&lt;p&gt;　　RabbitMq使用多种协议，本指南使用AMQP 0-9-1协议，该协议是一个开源的、通用的消息协议。RabbitMq有多种语言的客户端，这里我们使用JAVA语言的客户端做实验。通过以下地址下载RabbitMq客户端jar包和依赖包：&lt;/p&gt;
&lt;p&gt;　　&lt;a href=&quot;http://central.maven.org/maven2/com/rabbitmq/amqp-client/5.5.1/amqp-client-5.5.1.jar&quot; target=&quot;_blank&quot;&gt;amqp-client-5.5.1.jar&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;　　&lt;a href=&quot;http://central.maven.org/maven2/org/slf4j/slf4j-api/1.7.25/slf4j-api-1.7.25.jar&quot; target=&quot;_blank&quot;&gt;slf4j-api-1.7.25.jar&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;　　&lt;a href=&quot;http://central.maven.org/maven2/org/slf4j/slf4j-simple/1.7.25/slf4j-simple-1.7.25.jar&quot; target=&quot;_blank&quot;&gt;slf4j-simple-1.7.25.jar&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;　　把这三个jar包拷贝到你的工作目录，包括后面教程要新建的java文件。&lt;/p&gt;
&lt;h2&gt;2.1 发送消息&lt;/h2&gt;
&lt;p&gt;　　生产者连接RabbitMq,发送一条简单的消息”Hello World!“后就退出。&lt;/p&gt;
&lt;p&gt;　　在Send.java类中，需要引入以下依赖包：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;33&quot;&gt;
&lt;pre&gt;
&lt;span&gt;1&lt;/span&gt; &lt;span&gt;import&lt;/span&gt;&lt;span&gt; com.rabbitmq.client.ConnectionFactory;
&lt;/span&gt;&lt;span&gt;2&lt;/span&gt; &lt;span&gt;import&lt;/span&gt;&lt;span&gt; com.rabbitmq.client.Connection;
&lt;/span&gt;&lt;span&gt;3&lt;/span&gt; &lt;span&gt;import&lt;/span&gt; com.rabbitmq.client.Channel;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　给队列起个名字：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;33&quot;&gt;
&lt;pre&gt;
&lt;span&gt;1&lt;/span&gt; &lt;span&gt;public&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;&lt;span&gt; Send {
&lt;/span&gt;&lt;span&gt;2&lt;/span&gt;   &lt;span&gt;private&lt;/span&gt; &lt;span&gt;final&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; String QUEUE_NAME = &quot;hello&quot;&lt;span&gt;;
&lt;/span&gt;&lt;span&gt;3&lt;/span&gt;   &lt;span&gt;public&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; main(String[] argv) &lt;span&gt;throws&lt;/span&gt;&lt;span&gt; Exception {
&lt;/span&gt;&lt;span&gt;4&lt;/span&gt; &lt;span&gt;      ...
&lt;/span&gt;&lt;span&gt;5&lt;/span&gt; &lt;span&gt;  }
&lt;/span&gt;&lt;span&gt;6&lt;/span&gt; }
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　创建连接到服务器的连接Collection：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;33&quot;&gt;
&lt;pre&gt;
&lt;span&gt;1&lt;/span&gt; onnectionFactory factory = &lt;span&gt;new&lt;/span&gt;&lt;span&gt; ConnectionFactory();
&lt;/span&gt;&lt;span&gt;2&lt;/span&gt; factory.setHost(&quot;localhost&quot;&lt;span&gt;);
&lt;/span&gt;&lt;span&gt;3&lt;/span&gt; &lt;span&gt;try&lt;/span&gt; (Connection connection =&lt;span&gt; factory.newConnection();
&lt;/span&gt;&lt;span&gt;4&lt;/span&gt;      Channel channel =&lt;span&gt; connection.createChannel()) {
&lt;/span&gt;&lt;span&gt;5&lt;/span&gt; 
&lt;span&gt;6&lt;/span&gt; }
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　这个连接即套接字连接，为我们处理协议版本协商和身份验证等。这里我们连接一个本地的RabbitMq：因此是localhost，如果你想要连接一个远程机器上的RabbitMq，只需要把localhst改成那台机器的计算机名或是IP地址。&lt;/p&gt;
&lt;p&gt;　　创建完连接之后，我们继续创建一个信道：Channel。我们需要使用try-with-resource表达式，因为Connection和Channel都实现了JAVA接口Closeable，属于资源，需要关闭，这样我们就不需要显示地在我们的代码中进行关闭了。（关于信道，请参考文章最顶部的RabbitMq原理图，是TCP里面的虚拟链接，例如：电缆相当于一个TCP，信道就是里面的一个独立光纤，一条TCP上面创建多条信道是没有问题的；TCP一旦打开就分创建AMQP信道；无论是发布消息、接收消息、订阅队列，这些动作都是通过信道完成的）。&lt;/p&gt;
&lt;p&gt;　　为了发送消息，我们还必须要定义一个需要发送到的消息队列，这些都要使用try-with-resource表达式：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;41&quot;&gt;
&lt;pre&gt;
&lt;span&gt;1&lt;/span&gt; channel.queueDeclare(QUEUE_NAME, &lt;span&gt;false&lt;/span&gt;, &lt;span&gt;false&lt;/span&gt;, &lt;span&gt;false&lt;/span&gt;, &lt;span&gt;null&lt;/span&gt;&lt;span&gt;);
&lt;/span&gt;&lt;span&gt;2&lt;/span&gt; String message = &quot;Hello World!&quot;&lt;span&gt;;
&lt;/span&gt;&lt;span&gt;3&lt;/span&gt; channel.basicPublish(&quot;&quot;, QUEUE_NAME, &lt;span&gt;null&lt;/span&gt;&lt;span&gt;, message.getBytes());
&lt;/span&gt;&lt;span&gt;4&lt;/span&gt; System.out.println(&quot; [x] Sent '&quot; + message + &quot;'&quot;);
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　定义一个消息队列是幂等的：只有该队列不存在的时候才能被创建，消息是二进制数组，因此你可以根据需要指定编码。&lt;/p&gt;
&lt;p&gt;　　完成的Send.java如下：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;42&quot;&gt;
&lt;pre&gt;
&lt;span&gt; 1&lt;/span&gt; &lt;span&gt;import&lt;/span&gt;&lt;span&gt; com.rabbitmq.client.Channel;
&lt;/span&gt;&lt;span&gt; 2&lt;/span&gt; &lt;span&gt;import&lt;/span&gt;&lt;span&gt; com.rabbitmq.client.Connection;
&lt;/span&gt;&lt;span&gt; 3&lt;/span&gt; &lt;span&gt;import&lt;/span&gt;&lt;span&gt; com.rabbitmq.client.ConnectionFactory;
&lt;/span&gt;&lt;span&gt; 4&lt;/span&gt; 
&lt;span&gt; 5&lt;/span&gt; &lt;span&gt;public&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;&lt;span&gt; Send {
&lt;/span&gt;&lt;span&gt; 6&lt;/span&gt; 
&lt;span&gt; 7&lt;/span&gt;     &lt;span&gt;private&lt;/span&gt; &lt;span&gt;final&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; String QUEUE_NAME = &quot;hello&quot;&lt;span&gt;;
&lt;/span&gt;&lt;span&gt; 8&lt;/span&gt; 
&lt;span&gt; 9&lt;/span&gt;     &lt;span&gt;public&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; main(String[] argv) &lt;span&gt;throws&lt;/span&gt;&lt;span&gt; Exception {
&lt;/span&gt;&lt;span&gt;10&lt;/span&gt;         ConnectionFactory factory = &lt;span&gt;new&lt;/span&gt;&lt;span&gt; ConnectionFactory();
&lt;/span&gt;&lt;span&gt;11&lt;/span&gt;         factory.setHost(&quot;localhost&quot;&lt;span&gt;);
&lt;/span&gt;&lt;span&gt;12&lt;/span&gt;         &lt;span&gt;try&lt;/span&gt; (Connection connection =&lt;span&gt; factory.newConnection();
&lt;/span&gt;&lt;span&gt;13&lt;/span&gt;              Channel channel =&lt;span&gt; connection.createChannel()) {
&lt;/span&gt;&lt;span&gt;14&lt;/span&gt;             channel.queueDeclare(QUEUE_NAME, &lt;span&gt;false&lt;/span&gt;, &lt;span&gt;false&lt;/span&gt;, &lt;span&gt;false&lt;/span&gt;, &lt;span&gt;null&lt;/span&gt;&lt;span&gt;);
&lt;/span&gt;&lt;span&gt;15&lt;/span&gt;             String message = &quot;Hello World!&quot;&lt;span&gt;;
&lt;/span&gt;&lt;span&gt;16&lt;/span&gt;             channel.basicPublish(&quot;&quot;, QUEUE_NAME, &lt;span&gt;null&lt;/span&gt;, message.getBytes(&quot;UTF-8&quot;&lt;span&gt;));
&lt;/span&gt;&lt;span&gt;17&lt;/span&gt;             System.out.println(&quot; [x] Sent '&quot; + message + &quot;'&quot;&lt;span&gt;);
&lt;/span&gt;&lt;span&gt;18&lt;/span&gt; &lt;span&gt;        }
&lt;/span&gt;&lt;span&gt;19&lt;/span&gt; &lt;span&gt;    }
&lt;/span&gt;&lt;span&gt;20&lt;/span&gt; }
&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;2.2 接收消息&lt;/h2&gt;
&lt;p&gt;　　消费者监听RabbitMq中的消息，因此与生产者发送一条消息就退出不同，消费者要保持运行状态来接收消息并打印出来。&lt;/p&gt;
&lt;p&gt;　　Recv.java同样需要导入以下依赖包：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;33&quot;&gt;
&lt;pre&gt;
&lt;span&gt;1&lt;/span&gt; &lt;span&gt;import&lt;/span&gt;&lt;span&gt; com.rabbitmq.client.Channel;
&lt;/span&gt;&lt;span&gt;2&lt;/span&gt; &lt;span&gt;import&lt;/span&gt;&lt;span&gt; com.rabbitmq.client.Connection;
&lt;/span&gt;&lt;span&gt;3&lt;/span&gt; &lt;span&gt;import&lt;/span&gt;&lt;span&gt; com.rabbitmq.client.ConnectionFactory;
&lt;/span&gt;&lt;span&gt;4&lt;/span&gt; &lt;span&gt;import&lt;/span&gt; com.rabbitmq.client.DeliverCallback;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　与生产者相同，我们需要创建Connetcion和Channel、定义队列（需要监听并接收消息的队列）：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;39&quot;&gt;
&lt;pre&gt;
&lt;span&gt; 1&lt;/span&gt; &lt;span&gt;public&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;&lt;span&gt; Recv {
&lt;/span&gt;&lt;span&gt; 2&lt;/span&gt; 
&lt;span&gt; 3&lt;/span&gt;   &lt;span&gt;private&lt;/span&gt; &lt;span&gt;final&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; String QUEUE_NAME = &quot;hello&quot;&lt;span&gt;;
&lt;/span&gt;&lt;span&gt; 4&lt;/span&gt; 
&lt;span&gt; 5&lt;/span&gt;   &lt;span&gt;public&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; main(String[] argv) &lt;span&gt;throws&lt;/span&gt;&lt;span&gt; Exception {
&lt;/span&gt;&lt;span&gt; 6&lt;/span&gt;     ConnectionFactory factory = &lt;span&gt;new&lt;/span&gt;&lt;span&gt; ConnectionFactory();
&lt;/span&gt;&lt;span&gt; 7&lt;/span&gt;     factory.setHost(&quot;localhost&quot;&lt;span&gt;);
&lt;/span&gt;&lt;span&gt; 8&lt;/span&gt;     Connection connection =&lt;span&gt; factory.newConnection();
&lt;/span&gt;&lt;span&gt; 9&lt;/span&gt;     Channel channel =&lt;span&gt; connection.createChannel();
&lt;/span&gt;&lt;span&gt;10&lt;/span&gt; 
&lt;span&gt;11&lt;/span&gt;     channel.queueDeclare(QUEUE_NAME, &lt;span&gt;false&lt;/span&gt;, &lt;span&gt;false&lt;/span&gt;, &lt;span&gt;false&lt;/span&gt;, &lt;span&gt;null&lt;/span&gt;&lt;span&gt;);
&lt;/span&gt;&lt;span&gt;12&lt;/span&gt;     System.out.println(&quot; [*] Waiting for messages. To exit press CTRL+C&quot;&lt;span&gt;);
&lt;/span&gt;&lt;span&gt;13&lt;/span&gt; 
&lt;span&gt;14&lt;/span&gt; &lt;span&gt;  }
&lt;/span&gt;&lt;span&gt;15&lt;/span&gt; }
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　注意我们也在这里声明队列，因为我们可能在生产者之前启动消费者，我们想要确保在我们尝试消费消息的时候队列就已经存在了。&lt;/p&gt;
&lt;p&gt;　　这里我们为什么不使用try-with-resource表达式自动关闭channl和connection？通过这样，我们就可以使我们的程序一直保持运行状态，如果把这些关了，程序也就停止了。这就尴尬了，因为我们需要保持消费者一直处于异步监听消息过来的状态。&lt;/p&gt;
&lt;p&gt;　　RabbitMq会将队列中的消息异步地推送过来，我们需要提供一个回调函数来缓存消息直到我们需要用到这些消息：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;39&quot;&gt;
&lt;pre&gt;
&lt;span&gt;1&lt;/span&gt; DeliverCallback deliverCallback = (consumerTag, delivery) -&amp;gt;&lt;span&gt; {
&lt;/span&gt;&lt;span&gt;2&lt;/span&gt;     String message = &lt;span&gt;new&lt;/span&gt; String(delivery.getBody(), &quot;UTF-8&quot;&lt;span&gt;);
&lt;/span&gt;&lt;span&gt;3&lt;/span&gt;     System.out.println(&quot; [x] Received '&quot; + message + &quot;'&quot;&lt;span&gt;);
&lt;/span&gt;&lt;span&gt;4&lt;/span&gt; &lt;span&gt;};
&lt;/span&gt;&lt;span&gt;5&lt;/span&gt; channel.basicConsume(QUEUE_NAME, &lt;span&gt;true&lt;/span&gt;, deliverCallback, consumerTag -&amp;gt; { });
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　Rec.java完整代码：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;44&quot;&gt;
&lt;pre&gt;
&lt;span&gt;import&lt;/span&gt;&lt;span&gt; com.rabbitmq.client.Channel;
&lt;/span&gt;&lt;span&gt;import&lt;/span&gt;&lt;span&gt; com.rabbitmq.client.Connection;
&lt;/span&gt;&lt;span&gt;import&lt;/span&gt;&lt;span&gt; com.rabbitmq.client.ConnectionFactory;
&lt;/span&gt;&lt;span&gt;import&lt;/span&gt;&lt;span&gt; com.rabbitmq.client.DeliverCallback;

&lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;&lt;span&gt; Recv {

    &lt;/span&gt;&lt;span&gt;private&lt;/span&gt; &lt;span&gt;final&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; String QUEUE_NAME = &quot;hello&quot;&lt;span&gt;;

    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; main(String[] argv) &lt;span&gt;throws&lt;/span&gt;&lt;span&gt; Exception {
        ConnectionFactory factory &lt;/span&gt;= &lt;span&gt;new&lt;/span&gt;&lt;span&gt; ConnectionFactory();
        factory.setHost(&lt;/span&gt;&quot;localhost&quot;&lt;span&gt;);
        Connection connection &lt;/span&gt;=&lt;span&gt; factory.newConnection();
        Channel channel &lt;/span&gt;=&lt;span&gt; connection.createChannel();

        channel.queueDeclare(QUEUE_NAME, &lt;/span&gt;&lt;span&gt;false&lt;/span&gt;, &lt;span&gt;false&lt;/span&gt;, &lt;span&gt;false&lt;/span&gt;, &lt;span&gt;null&lt;/span&gt;&lt;span&gt;);
        System.out.println(&lt;/span&gt;&quot; [*] Waiting for messages. To exit press CTRL+C&quot;&lt;span&gt;);

        DeliverCallback deliverCallback &lt;/span&gt;= (consumerTag, delivery) -&amp;gt;&lt;span&gt; {
            String message &lt;/span&gt;= &lt;span&gt;new&lt;/span&gt; String(delivery.getBody(), &quot;UTF-8&quot;&lt;span&gt;);
            System.out.println(&lt;/span&gt;&quot; [x] Received '&quot; + message + &quot;'&quot;&lt;span&gt;);
        };
        channel.basicConsume(QUEUE_NAME, &lt;/span&gt;&lt;span&gt;true&lt;/span&gt;, deliverCallback, consumerTag -&amp;gt;&lt;span&gt; { });
    }
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;　　在官方手册中，测试部分他们是将客户端jar和依赖jar添加到classpath路径，然后在cmd终端来运行的，我觉得麻烦，因此，我这里放到IDEA中来运行，效果是一样的。&lt;/p&gt;
&lt;p&gt;　　&lt;img src=&quot;https://img2018.cnblogs.com/blog/1651332/201904/1651332-20190427222055375-489515340.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　&lt;strong&gt;第一步：首先运行Send.java:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;　　输出结果：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot;&gt;
&lt;pre&gt;
[x] Sent 'Hello World!'
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　查看RabbitMq控制台：&lt;/p&gt;
&lt;p&gt;　　&lt;img src=&quot;https://img2018.cnblogs.com/blog/1651332/201904/1651332-20190427222425053-1550169729.png&quot; alt=&quot;&quot; width=&quot;667&quot; height=&quot;220&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1651332/201904/1651332-20190427222437934-902849612.png&quot; alt=&quot;&quot; width=&quot;716&quot; height=&quot;92&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　说明消息已经发送成功。&lt;/p&gt;
&lt;p&gt; 　  &lt;strong&gt;第二步：启动消费者Recv.java:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;　　输出结果：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;32&quot;&gt;
&lt;pre&gt;
[x] Received 'Hello World!'
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　说明消息已经消费成功了，此时再查看控制台：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1651332/201904/1651332-20190427222702602-1265746330.png&quot; alt=&quot;&quot; width=&quot;599&quot; height=&quot;197&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1651332/201904/1651332-20190427222738082-1689153081.png&quot; alt=&quot;&quot; width=&quot;644&quot; height=&quot;104&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　消息依然存在在队列中，但是区别是，在第一张图中Ready由1变成了0，Unacknowledged由0变成了1；第二张图中Ready也由1变成0，Unacked由0变成了1。为什么会这样？按道理，消息消费了之后就应该删除掉，否则可能造成重复消费。关于这方面知识，将会在后面的章节中再介绍（Ack机制）。&lt;/p&gt;

&lt;p&gt;　　上面虽然实现了功能，但在实际工作中，我们更多的可能是使用SpringBoot、SpringCloud等成熟的框架来实现。本小节就通过SpringBoot来实现以上功能。&lt;/p&gt;
&lt;p&gt;　　工程目录如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1651332/201904/1651332-20190427232111614-1475605362.png&quot; alt=&quot;&quot; width=&quot;287&quot; height=&quot;413&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　Provider和Consumer的配置文件相同,IP请替换成你自己的：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;33&quot;&gt;
&lt;pre&gt;
&lt;span&gt;1&lt;/span&gt; &lt;span&gt;#RabbitMq
&lt;/span&gt;&lt;span&gt;2&lt;/span&gt; spring.rabbitmq.host=192.168.xx.xx  
&lt;span&gt;3&lt;/span&gt; spring.rabbitmq.username=&lt;span&gt;rabbitmq
&lt;/span&gt;&lt;span&gt;4&lt;/span&gt; spring.rabbitmq.password=123456
&lt;span&gt;5&lt;/span&gt; 
&lt;span&gt;6&lt;/span&gt; hello_world.queue=hello
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　为方便让系统启动时就往队列发送消息，所以写了一个SenderRunner类：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;34&quot;&gt;
&lt;pre&gt;
&lt;span&gt; 1&lt;/span&gt; &lt;span&gt;@Component
&lt;/span&gt;&lt;span&gt; 2&lt;/span&gt; &lt;span&gt;public&lt;/span&gt; &lt;span&gt;class&lt;/span&gt; SenderRunner &lt;span&gt;implements&lt;/span&gt;&lt;span&gt; ApplicationRunner {
&lt;/span&gt;&lt;span&gt; 3&lt;/span&gt; 
&lt;span&gt; 4&lt;/span&gt; &lt;span&gt;    @Autowired
&lt;/span&gt;&lt;span&gt; 5&lt;/span&gt;     &lt;span&gt;private&lt;/span&gt;&lt;span&gt; Send send;
&lt;/span&gt;&lt;span&gt; 6&lt;/span&gt; 
&lt;span&gt; 7&lt;/span&gt; &lt;span&gt;    @Override
&lt;/span&gt;&lt;span&gt; 8&lt;/span&gt;     &lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; run(ApplicationArguments args) &lt;span&gt;throws&lt;/span&gt;&lt;span&gt; Exception {
&lt;/span&gt;&lt;span&gt; 9&lt;/span&gt;         send.doSender(&quot;Hello RabbitMq&quot;&lt;span&gt;);
&lt;/span&gt;&lt;span&gt;10&lt;/span&gt; &lt;span&gt;    }
&lt;/span&gt;&lt;span&gt;11&lt;/span&gt; }
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　Send.java&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;35&quot;&gt;
&lt;pre&gt;
&lt;span&gt; 1&lt;/span&gt; &lt;span&gt;@Component
&lt;/span&gt;&lt;span&gt; 2&lt;/span&gt; &lt;span&gt;public&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;&lt;span&gt; Send {
&lt;/span&gt;&lt;span&gt; 3&lt;/span&gt; 
&lt;span&gt; 4&lt;/span&gt;     @Value(&quot;${hello_world.queue}&quot;&lt;span&gt;)
&lt;/span&gt;&lt;span&gt; 5&lt;/span&gt;     &lt;span&gt;private&lt;/span&gt;&lt;span&gt; String queueName;
&lt;/span&gt;&lt;span&gt; 6&lt;/span&gt; 
&lt;span&gt; 7&lt;/span&gt; &lt;span&gt;    @Autowired
&lt;/span&gt;&lt;span&gt; 8&lt;/span&gt;     &lt;span&gt;private&lt;/span&gt;&lt;span&gt; AmqpTemplate amqpTemplate;
&lt;/span&gt;&lt;span&gt; 9&lt;/span&gt; 
&lt;span&gt;10&lt;/span&gt;     &lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt;&lt;span&gt; doSender(String msg) {
&lt;/span&gt;&lt;span&gt;11&lt;/span&gt; 
&lt;span&gt;12&lt;/span&gt; &lt;span&gt;        amqpTemplate.convertAndSend(queueName,msg);
&lt;/span&gt;&lt;span&gt;13&lt;/span&gt;         System.out.println(&quot;发送消息：&quot; +&lt;span&gt; msg);
&lt;/span&gt;&lt;span&gt;14&lt;/span&gt; &lt;span&gt;    }
&lt;/span&gt;&lt;span&gt;15&lt;/span&gt; }
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　启动类：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;34&quot;&gt;
&lt;pre&gt;
&lt;span&gt;1&lt;/span&gt; &lt;span&gt;@SpringBootApplication
&lt;/span&gt;&lt;span&gt;2&lt;/span&gt; &lt;span&gt;public&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;&lt;span&gt; ProviderApplication {
&lt;/span&gt;&lt;span&gt;3&lt;/span&gt;     &lt;span&gt;public&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; &lt;span&gt;void&lt;/span&gt;&lt;span&gt; main(String[] args) {
&lt;/span&gt;&lt;span&gt;4&lt;/span&gt;         SpringApplication.run(ProviderApplication.&lt;span&gt;class&lt;/span&gt;&lt;span&gt;, args);
&lt;/span&gt;&lt;span&gt;5&lt;/span&gt; &lt;span&gt;    }
&lt;/span&gt;&lt;span&gt;6&lt;/span&gt; }
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　Recv.java&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;33&quot;&gt;
&lt;pre&gt;
&lt;span&gt;@Component
&lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;&lt;span&gt; Recv {

    @RabbitListener(queues &lt;/span&gt;= &quot;${hello_world.queue}&quot;&lt;span&gt;)
    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt;&lt;span&gt; receive(String msg) {
        System.out.println(&lt;/span&gt;&quot;接收到消息：&quot; +&lt;span&gt; msg);
    }
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　&lt;strong&gt;启动Provider:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1651332/201904/1651332-20190427232542563-367428738.png&quot; alt=&quot;&quot; width=&quot;1222&quot; height=&quot;50&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　查看控制台：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1651332/201904/1651332-20190427232719748-185323471.png&quot; alt=&quot;&quot; width=&quot;620&quot; height=&quot;85&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　&lt;strong&gt;启动Consumer:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;　&lt;img src=&quot;https://img2018.cnblogs.com/blog/1651332/201904/1651332-20190427232929472-290654375.png&quot; alt=&quot;&quot; width=&quot;595&quot; height=&quot;130&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　可见，SpringBoot为我们做了很多封装，隐藏了很多底层的细节，使用起来简单多了。&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;　&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;　　PS：关于SpringBoot的实现涉及到很多的配置，我将在系统的最后专门用一章来讲解SpringBoot的实现&lt;/strong&gt;&lt;/span&gt;。&lt;/p&gt;
</description>
<pubDate>Sat, 27 Apr 2019 15:40:00 +0000</pubDate>
<dc:creator>无恨之都</dc:creator>
<og:description>为什么要使用MQ消息中间件？它解决了什么问题？关于为什么要使用消息中间件？消息中间件是如何做到同步变异步、流量削锋、应用解耦的？网上已经有很多说明，我这里就不再说明了，读者可以参考（https://w</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/wuhenzhidu/p/10781101.html</dc:identifier>
</item>
<item>
<title>es6学习笔记-proxy对象 - 热爱前端的17号诶</title>
<link>http://www.cnblogs.com/sqh17/p/10755165.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/sqh17/p/10755165.html</guid>
<description>&lt;p&gt;尤大大的vue3.0即将到来，虽然学不动了，但是还要学的啊，据说vue3.0是基于proxy来进行对值进行拦截并操作，所以es6的proxy也是要学习一下的。&lt;/p&gt;

&lt;p&gt;Proxy 对象用于定义基本操作的自定义行为（如属性查找，赋值，枚举，函数调用等） --摘自MDN&lt;br/&gt;Proxy 用于修改某些操作的默认行为，等同于在语言层面做出修改，所以属于一种“元编程”（meta programming），即对编程语言进行编程。 --摘自阮一峰的ES6入门&lt;br/&gt;Proxy 这个词的原意是代理，用在这里表示由它来“代理”某些操作，可以译为“代理器”。&lt;br/&gt;Proxy 也可以理解成，在目标对象之前架设一层“拦截”，外界对该对象的访问，都必须先通过这层拦截，因此提供了一种机制，可以对外界的访问进行过滤和改写。&lt;br/&gt;总结来说：Proxy对象就是要在目标对象上设置自定义的规则和方法，让它按照自己定义的规则去实行某些操作。&lt;/p&gt;

&lt;p&gt;ES6 原生提供 Proxy 构造函数，用来生成 Proxy 实例，所以可以按照构造函数创建对象的形式去实例化一个Proxy对象。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;var proxy = new Proxy({},{})
console.log(proxy) // Proxy{}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;注意点：&lt;br/&gt;1 实例化一个Proxy对象时，必须要传两个参数对象,否则会报错：Uncaught TypeError: Cannot create proxy with a non-object as target or handler,不能创建没有对象的proxy对象。&lt;br/&gt;2 传两个空对象时，默认的是简单声明了一个Proxy实例，（好像没啥卵用……）&lt;/p&gt;
&lt;p&gt;参数对象解释：&lt;/p&gt;
&lt;ul readability=&quot;3.390625&quot;&gt;&lt;li readability=&quot;6&quot;&gt;
&lt;p&gt;第一个参数：target，目标对象，是你要代理的对象.它可以是JavaScript中的任何合法对象.如: (数组, 对象, 函数等等)&lt;br/&gt;tip:&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;var arr = []
var obj = {}
var Person = class{}
var foo = function (){}
console.log(Person instanceof Object) // true
console.log(foo instanceof Object)  // true
console.log(arr instanceof Object)  // true
console.log(obj instanceof Object)  // true&lt;/code&gt;
&lt;/pre&gt;&lt;/li&gt;
&lt;li readability=&quot;0.92250922509225&quot;&gt;
&lt;p&gt;第二个参数：handler，配置对象，用来定制拦截行为，对于每一个被代理的操作，需要提供一个对应的处理函数，该函数将拦截对应的操作。&lt;br/&gt;Proxy支持的拦截操作，有13种，使用方法可以参考 &lt;a href=&quot;http://es6.ruanyifeng.com/#docs/proxy&quot;&gt;阮一峰的ES6入门&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;当目标对象为空时&quot;&gt;3.1 当目标对象为空时&lt;/h2&gt;
&lt;p&gt;var proxy = new Proxy({},handler)&lt;br/&gt;这样直接代表着，拦截的对象是空的，所以直接对proxy对象进行操控。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;var target = {};
var handler = {
  get(target,propKey,receiver){
    return 'peter'
  }
};
var proxy = new Proxy(target, handler);
proxy.name = 'tom';
console.log(proxy.name) // tom
console.log(target.name) // undefined&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;上面的代码说明了：target是个空对象，但是操作了proxy，也影响不了target&lt;br/&gt;ps：要使得Proxy起作用，必须针对Proxy实例进行操作，而不是针对目标对象进行操作&lt;/p&gt;
&lt;h2 id=&quot;当拦截对象为空时&quot;&gt;3.2 当拦截对象为空时&lt;/h2&gt;
&lt;p&gt;var proxy = new Proxy(target,{})&lt;br/&gt;handler没有设置任何拦截，那就等同于直接通向原对象。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;var target = {};
var handler = {};
var proxy = new Proxy(target, handler);
proxy.name = 'peter';
console.log(proxy.name) // peter
console.log(target.name) // peter&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;上面的代码说明了：handler是一个空对象，没有任何拦截效果，访问proxy就等同于访问target&lt;/p&gt;

&lt;p&gt;Proxy实例化的对象默认带有get和set方法。也可以在这些基础上进行拦截操作，其他的13种方法也是如此。&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;get() 用于拦截某个属性的读取（read）操作，换句话讲，就是在读取目标对象的属性之前，操作该属性。&lt;br/&gt;参数解释：
&lt;ul readability=&quot;3&quot;&gt;&lt;li&gt;target：目标对象&lt;/li&gt;
&lt;li&gt;property：属性名&lt;/li&gt;
&lt;li readability=&quot;9&quot;&gt;
&lt;p&gt;receiver：proxy实例&lt;br/&gt;例子：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;var person = {
  name: &quot;张三&quot;
};

var proxy = new Proxy(person, {
  get: function(target, property) {
    if (property in target) {
      return target[property];
    } else {
      throw new ReferenceError(&quot;Property \&quot;&quot; + property + &quot;\&quot; does not exist.&quot;);
    }
  }
});

proxy.name // &quot;张三&quot;
proxy.age // Property &quot;age&quot; does not exist.&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;参考阮一峰的例子，上述说明了，如果输入目标函数不存在的属性，就直接报错。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;set() 用来拦截目标对象的赋值（write）操作&lt;br/&gt;参数解释：
&lt;ul readability=&quot;4&quot;&gt;&lt;li&gt;target：目标对象&lt;/li&gt;
&lt;li&gt;propertyName：属性名&lt;/li&gt;
&lt;li&gt;propertyValue：属性值&lt;/li&gt;
&lt;li readability=&quot;11&quot;&gt;
&lt;p&gt;receiver：Proxy实例本身&lt;br/&gt;例子：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;var target = {}
var handler = {
  set(target, propKey, value, receiver) {
    if (typeof value !== 'string') {
      target[propKey] = String(value);
    }else{
      target[propKey] = value;
    }
  }
}
var proxy = new Proxy(target, handler)
proxy.name = 'peter'
proxy.age = 25
console.log(typeof proxy.name) // string
console.log(typeof proxy.age) // string&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;上面例子就是拦截对象是不是字符串，不是字符串的话会强制转化为字符串。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;apply() 用来拦截函数的调用、call和apply操作&lt;br/&gt;参数解释：
&lt;ul readability=&quot;6&quot;&gt;&lt;li&gt;target：目标对象&lt;/li&gt;
&lt;li&gt;context：目标对象的上下文对象(this）&lt;/li&gt;
&lt;li readability=&quot;15&quot;&gt;
&lt;p&gt;arguments：目标对象的参数数组&lt;br/&gt;例子：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;var target = function(a,b){
  return 10 + a + b
}
var handler = {
  apply(target,context,arguments){
    arguments[0] = 10
    arguments[1] = 20
    return arguments.reduce(function(prev, curr, idx, arr){
        return prev + curr;
    });
  }
}
var proxy = new Proxy(target,handler)
console.log(proxy(1,2)) // 30&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;上面的例子，就是目标函数是要传两个参数，并且返回之和，拦截目标做的就是改变目标对象的参数，并且求和，所以这样写触发了apply方法，返回30，而不是13&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;has() 用来拦截hasProperty操作，即判断对象是否具有某个属性时，这个方法会生效。典型的操作就是in运算符。&lt;br/&gt;参数解释：
&lt;ul readability=&quot;3.5&quot;&gt;&lt;li&gt;target：目标对象&lt;/li&gt;
&lt;li readability=&quot;10&quot;&gt;
&lt;p&gt;key： 需查询的属性名,是一个字符串！！！！！&lt;br/&gt;例子：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;var target = {
  name: 'peter',
  age:25
}
var handler = {
  has(target,key){
    return key in target;
  }

}
var proxy = new Proxy(target,handler)
console.log('age' in proxy) // true
console.log('colors' in proxy) // false&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;上面的例子是典型的has的方法，判断所要查询的属性名是不是在目标对象上的属性名，返回布尔值。&lt;br/&gt;ps：has拦截对for...in循环不生效。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;construct() 用于拦截new命令，要返回是一个对象，否则会报错&lt;br/&gt;参数解释：
&lt;ul readability=&quot;2&quot;&gt;&lt;li&gt;target：目标对象&lt;/li&gt;
&lt;li&gt;args：构造函数的参数对象&lt;/li&gt;
&lt;li readability=&quot;7&quot;&gt;
&lt;p&gt;newTarget：创造实例对象时，new命令作用的构造函数&lt;br/&gt;例子：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;var p = new Proxy(function () {}, {
  construct: function(target, args) {
    console.log('called: ' + args.join(', '));
    return { value: args[0] * 10 };
  }
});

(new p(1)).value
// &quot;called: 1&quot;
// 10&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;由此可见，是针对构造函数而言的，对目标对象的构造函数进行拦截。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;defineProperty() 拦截了Object.defineProperty操作，在声明时进行拦截，设置的是一个布尔值
&lt;ul readability=&quot;13&quot;&gt;&lt;li&gt;参数解释：
&lt;ul&gt;&lt;li&gt;target：目标对象&lt;/li&gt;
&lt;li&gt;key：要定义或修改的属性的名称&lt;/li&gt;
&lt;li&gt;descriptor： 将被定义或修改的属性描述符,是一个对象&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li readability=&quot;8&quot;&gt;
&lt;p&gt;拓展：&lt;br/&gt;Object.defineProperty(),声明对象的属性，参数说明和上述一样&lt;br/&gt;例子：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;var obj = {}
Object.defineProperty(obj, &quot;key&quot;, {
  enumerable: false,
  configurable: false,
  writable: false,
  value: &quot;static&quot;
});&lt;/code&gt;
&lt;/pre&gt;&lt;/li&gt;
&lt;li readability=&quot;18&quot;&gt;
&lt;p&gt;例子：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;var target = {
  name: 'peter',
  age:25
}
var handler = {
  defineProperty(target,key,descriptor){
    if(key === 'color'){
      throw new Error('不能定义颜色')
    }
    Object.defineProperty(target, key, descriptor)
    // return true
  }
}
var proxy = new Proxy(target,handler)
var descriptor = {
  writable : true,
  enumerable : true,
  configurable : true
}
descriptor.value = 'sport'
Object.defineProperty(proxy, 'favor', descriptor)
console.log(proxy.favor) // sport
descriptor.value = 'red'
Object.defineProperty(proxy, 'color', descriptor)  // 不能定义颜色
console.log(proxy.color)&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;如果目标对象不可扩展（non-extensible），则defineProperty不能增加目标对象上不存在的属性，否则会报错。另外，如果目标对象的某个属性不可写（writable）或不可配置（configurable），则defineProperty方法不得改变这两个设置。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;deleteProperty() 用于拦截delete操作，如果这个方法抛出错误或者返回false，当前属性就无法被delete命令删除。
&lt;ul readability=&quot;2.5&quot;&gt;&lt;li&gt;参数解释：
&lt;ul&gt;&lt;li&gt;target：目标对象&lt;/li&gt;
&lt;li&gt;key：要删除的属性名&lt;br/&gt;(delete是关键字，目前用到的就是删除对象的某个属性)&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li readability=&quot;8&quot;&gt;
&lt;p&gt;例子：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;var target = { _prop: 'foo' };
var handler = {
  deleteProperty (target, key) {
    if (key[0] === '_') {
      throw new Error(`Invalid attempt to ${target} private &quot;${key}&quot; property`);
    }
    delete target[key];
    return true;
  }
};
var proxy = new Proxy(target, handler);
delete proxy._prop // Error: Invalid attempt to delete private &quot;_prop&quot; property&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;上面代码中，deleteProperty方法拦截了delete操作符，删除第一个字符为下划线的属性会报错。&lt;br/&gt;注意，目标对象自身的不可配置（configurable）的属性，不能被deleteProperty方法删除，否则报错。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;getOwnPropertyDescriptor() 拦截Object.getOwnPropertyDescriptor()，返回一个属性描述对象或者undefined。
&lt;ul readability=&quot;5.5&quot;&gt;&lt;li&gt;参数解释：
&lt;ul&gt;&lt;li&gt;target：目标对象&lt;/li&gt;
&lt;li&gt;key： 属性名&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;拓展：&lt;br/&gt;Object.getOwnPropertyDescriptor(obj,prop) 返回指定对象上一个自有属性对应的属性描述符
&lt;ul readability=&quot;0.5&quot;&gt;&lt;li&gt;参数解释：
&lt;ul&gt;&lt;li&gt;obj：需要查找的目标对象&lt;/li&gt;
&lt;li&gt;prop: 目标对象内属性名称&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;返回值：&lt;br/&gt;如果指定的属性存在于对象上，则返回其属性描述符对象（property descriptor），否则返回 undefined。&lt;/li&gt;
&lt;li readability=&quot;4&quot;&gt;
&lt;p&gt;例子：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;o = { bar: 42 };
d = Object.getOwnPropertyDescriptor(o, &quot;bar&quot;);
console.log(d)
// d {
//   configurable: true,
//   enumerable: true,
//   value: 42,
//   writable: true
// }&lt;/code&gt;
&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li readability=&quot;14&quot;&gt;
&lt;p&gt;例子：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;var target = { _foo: 'bar', baz: 'tar' };
var handler = {
  getOwnPropertyDescriptor (target, key) {
    if (key[0] === '_') {
      return;
    }
    return Object.getOwnPropertyDescriptor(target, key);
  }
};
var proxy = new Proxy(target, handler);
Object.getOwnPropertyDescriptor(proxy, 'wat')
// undefined
Object.getOwnPropertyDescriptor(proxy, '_foo')
// undefined
Object.getOwnPropertyDescriptor(proxy, 'baz')
// { value: 'tar', writable: true, enumerable: true, configurable: true }&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;上述说明：对于第一个字符为下划线的属性名会返回undefined。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;getPrototypeOf() 用来拦截获取对象原型,主要拦截以下操作：
&lt;/li&gt;
&lt;li&gt;isExtensible() 拦截Object.isExtensible()操作
&lt;ul readability=&quot;0.5&quot;&gt;&lt;li&gt;Object.isExtensible() 判断是否可以为对象添加新的属性&lt;br/&gt;参数：
&lt;ul readability=&quot;-0.5&quot;&gt;&lt;li&gt;object 要进行判断的对象&lt;br/&gt;返回值：&lt;/li&gt;
&lt;li readability=&quot;2&quot;&gt;
&lt;p&gt;是个布尔值，true是可以添加，false不可以添加&lt;br/&gt;例子：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;let obj = { 
  name: 'peter',
  age:25
}
console.log(Object.isExtensible(obj)) // true&lt;/code&gt;
&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;
对象默认情况下是可以添加新的属性的。&lt;/li&gt;
&lt;li readability=&quot;4&quot;&gt;
&lt;p&gt;例子：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;var p = new Proxy({}, {
  isExtensible: function(target) {
    console.log(&quot;called&quot;);
    return true;
  }
});
Object.isExtensible(p) // called&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;这个方法有一个强限制，它的返回值必须与目标对象的isExtensible属性保持一致，否则就会抛出错误。&lt;br/&gt;即：Object.isExtensible(proxy) === Object.isExtensible(target)&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;preventExtensions() 拦截Object.preventExtensions()操作
&lt;ul&gt;&lt;li&gt;Object.preventExtensions(object) 不能再为此对象添加新的属性或者方法
&lt;/li&gt;
&lt;li&gt;例子&lt;br/&gt;————————————&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;setPrototypeOf() 拦截Object.setPrototypeOf方法
&lt;ul readability=&quot;0.5&quot;&gt;&lt;li&gt;Object.setPrototypeOf(obj,proto) 设置对象的原型&lt;br/&gt;此方法修改的是对象实例的内部属性[[Prototype]]，也就是__proto__属性所指向的对象，它只是修改了特定对象上的原型对象，对于构造函数的prototype指向的原型对象没有影响
&lt;ul&gt;&lt;li&gt;参数：
&lt;ul&gt;&lt;li&gt;obj 对其设置原型的对象&lt;/li&gt;
&lt;li&gt;proto 新的原型对象&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;例子：&lt;/p&gt;
let proto = {&lt;br/&gt;color: red&lt;br/&gt;};&lt;br/&gt;let obj = {&lt;br/&gt;name: 'peter'&lt;br/&gt;age: 26&lt;br/&gt;};&lt;br/&gt;Object.setPrototypeOf(obj, proto);&lt;br/&gt;console.log(obj.color); // red&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li readability=&quot;4&quot;&gt;
&lt;p&gt;例子&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;var handler = {
  setPrototypeOf (target, proto) {
    throw new Error('Changing the prototype is forbidden');
  }
};
var proto = {};
var target = function () {};
var proxy = new Proxy(target, handler);
Object.setPrototypeOf(proxy, proto);
// Error: Changing the prototype is forbidden&lt;/code&gt;
&lt;/pre&gt;
上面代码中，只要修改target的原型对象，就会报错。&lt;/li&gt;
&lt;li&gt;ps
&lt;ol&gt;&lt;li&gt;该方法只能返回布尔值，否则会被自动转为布尔值&lt;/li&gt;
&lt;li&gt;如果目标对象不可扩展（non-extensible），setPrototypeOf方法不得改变目标对象的原型&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;ownKeys() 用来拦截对象自身属性的读取操作
&lt;ul readability=&quot;1&quot;&gt;&lt;li&gt;如下：
&lt;ul&gt;&lt;li&gt;Object.getOwnPropertyNames(obj) 获取对象的属性名称，并存储在数组中。
&lt;/li&gt;
&lt;li&gt;Object.getOwnPropertySymbols(obj) 返回一个给定对象自身的所有 Symbol 属性的数组
&lt;ul readability=&quot;-0.5&quot;&gt;&lt;li&gt;参数解释： obj 要返回 Symbol 属性的对象&lt;/li&gt;
&lt;li&gt;返回值： 在给定对象自身上找到的所有 Symbol 属性的数组。&lt;/li&gt;
&lt;li readability=&quot;2&quot;&gt;
&lt;p&gt;例子：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;var obj = {};
var a = Symbol(&quot;a&quot;);
var b = Symbol.for(&quot;b&quot;);

obj[a] = &quot;localSymbol&quot;;
obj[b] = &quot;globalSymbol&quot;;

var objectSymbols = Object.getOwnPropertySymbols(obj);

console.log(objectSymbols.length); // 2
console.log(objectSymbols)         // [Symbol(a), Symbol(b)]
console.log(objectSymbols[0])      // Symbol(a)&lt;/code&gt;
&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Object.keys() 返回一个由一个给定对象的自身可枚举属性组成的数组，数组中属性名的排列顺序和使用 for...in 循环遍历该对象时返回的顺序一致
&lt;ul readability=&quot;0&quot;&gt;&lt;li&gt;参数：obj 要返回其枚举自身属性的对象&lt;/li&gt;
&lt;li&gt;返回值： 一个表示给定对象的所有可枚举属性的字符串数组&lt;/li&gt;
&lt;li readability=&quot;3&quot;&gt;
&lt;p&gt;例子：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;var obj = { 0: 'a', 1: 'b', 2: 'c' };
console.log(Object.keys(obj)); // ['0', '1', '2']&lt;/code&gt;
&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;for...in循环&lt;br/&gt;————————————&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li readability=&quot;5&quot;&gt;
&lt;p&gt;例子之一：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;var p = new Proxy({}, {
  ownKeys: function(target) {
    return ['a', 'b', 'c'];
  }
});

Object.getOwnPropertyNames(p)
// [ 'a', 'b', 'c' ]&lt;/code&gt;
&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;返回一个可取消的 Proxy 实例&lt;/p&gt;
&lt;ul readability=&quot;0.5&quot;&gt;&lt;li&gt;参数解释：
&lt;ul&gt;&lt;li&gt;target 用Proxy包装的目标对象（可以是任何类型的对象，包括原生数组，函数，甚至另一个代理）。&lt;/li&gt;
&lt;li&gt;handler 拦截对象，其属性是当执行一个操作时定义代理的行为的函数。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;返回值&lt;br/&gt;返回一个包含了所生成的代理对象本身以及该代理对象的撤销方法的对象&lt;br/&gt;其结构为： {&quot;proxy&quot;: proxy, &quot;revoke&quot;: revoke}，其中：
&lt;ul&gt;&lt;li&gt;proxy&lt;br/&gt;表示新生成的代理对象本身，和用一般方式 new Proxy(target, handler) 创建的代理对象没什么不同，只是它可以被撤销掉&lt;/li&gt;
&lt;li&gt;revoke&lt;br/&gt;撤销方法，调用的时候不需要加任何参数，就可以撤销掉和它一起生成的那个代理对象&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li readability=&quot;4&quot;&gt;
&lt;p&gt;例子：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;var revocable = Proxy.revocable({}, {
  get(target, propKey) {
    return propKey + '啦啦啦';
  }
});
var proxy = revocable.proxy;
console.log(proxy.foo) // foo啦啦啦
revocable.revoke(); // 执行撤销方法
console.log(proxy.foo); // Uncaught TypeError: Cannot perform 'get' on a proxy that has been revoked&lt;/code&gt;
&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;刚开始学proxy时，都是懵逼的状态，阮一峰ES6入门一开始看代码有点难度，所以我一边看一边查资料，里面关于Object对象的方法居多，也顺便学习了一下，知识很多，需要日常回顾加深理解，经过查阅，对于代理模式 Proxy 的作用主要体现在三个方面:1拦截和监视外部对对象的访问，2降低函数或类的复杂度，3在复杂操作前对操作进行校验或对所需资源进行管理，目前还没有大量运用，最常见的应该是拦截和监听对象的变化吧。&lt;br/&gt;我把笔记放到&lt;a href=&quot;https://github.com/sqh17/notes/blob/master/ways/proxy.md&quot;&gt;GitHub&lt;/a&gt;里了，如需要可以去看看，有什么不对的地方，欢迎指正，大家一起进步加油。&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://es6.ruanyifeng.com/#docs/proxy&quot;&gt;阮一峰ES6入门&lt;/a&gt;&lt;br/&gt;&lt;a href=&quot;https://www.jb51.net/article/132373.htm&quot;&gt;详解ES6中的代理模式——Proxy&lt;/a&gt;&lt;br/&gt;&lt;a href=&quot;https://developer.mozilla.org/zh-CN/docs/Web/JavaScript/Reference/Global_Objects/Proxy&quot;&gt;MDN&lt;/a&gt;&lt;br/&gt;&lt;a href=&quot;https://segmentfault.com/a/1190000006035363&quot;&gt;[译] 实例解析 ES6 Proxy 使用场景&lt;/a&gt;&lt;/p&gt;
</description>
<pubDate>Sat, 27 Apr 2019 15:36:00 +0000</pubDate>
<dc:creator>热爱前端的17号诶</dc:creator>
<og:description>前提摘要 尤大大的vue3.0即将到来，虽然学不动了，但是还要学的啊，据说vue3.0是基于proxy来进行对值进行拦截并操作，所以es6的proxy也是要学习一下的。 一 什么是proxy Prox</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/sqh17/p/10755165.html</dc:identifier>
</item>
<item>
<title>SpringBoot进阶教程(三十)整合Redis之Sentinel哨兵模式 - 请叫我头头哥</title>
<link>http://www.cnblogs.com/toutou/p/sentinel.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/toutou/p/sentinel.html</guid>
<description>&lt;pre&gt;
&lt;span&gt;##redis配置详解

# Redis configuration file example.
#
# Note that in order to read the configuration file, Redis must be
# started with the file path as first argument:
#
# ./redis-server /path/to/redis.conf

# Note on units: when memory size is needed, it is possible to specify
# it in the usual form of 1k 5GB 4M and so forth:
#
# 1k =&amp;gt; 1000 bytes
# 1kb =&amp;gt; 1024 bytes
# 1m =&amp;gt; 1000000 bytes
# 1mb =&amp;gt; 1024*1024 bytes
# 1g =&amp;gt; 1000000000 bytes
# 1gb =&amp;gt; 1024*1024*1024 bytes
#
# units are case insensitive so 1GB 1Gb 1gB are all the same.

################################## INCLUDES ###################################
################################## 包含     ###################################

# Include one or more other config files here.  This is useful if you
# have a standard template that goes to all Redis servers but also need
# to customize a few per-server settings.  Include files can include
# other files, so use this wisely.
#
# Notice option &quot;include&quot; won't be rewritten by command &quot;CONFIG REWRITE&quot;
# from admin or Redis Sentinel. Since Redis always uses the last processed
# line as value of a configuration directive, you'd better put includes
# at the beginning of this file to avoid overwriting config change at runtime.
#
# If instead you are interested in using includes to override configuration
# options, it is better to use include as the last line.
#
# 假如说你有一个可用于所有的 redis server 的标准配置模板，
# 但针对某些 server 又需要一些个性化的设置，
# 你可以使用 include 来包含一些其他的配置文件，这对你来说是非常有用的。
#
# 但是要注意哦，include 是不能被 config rewrite 命令改写的
# 由于 redis 总是以最后的加工线作为一个配置指令值，所以你最好是把 include 放在这个文件的最前面，
# 以避免在运行时覆盖配置的改变，相反，你就把它放在后面
# include /path/to/local.conf
# include /path/to/other.conf

################################ GENERAL  #####################################
################################ 常用     #####################################

# By default Redis does not run as a daemon. Use 'yes' if you need it.
# Note that Redis will write a pid file in /var/run/redis.pid when daemonized.
# 默认情况下 redis 不是作为守护进程运行的，如果你想让它在后台运行，你就把它改成 yes。
# 当redis作为守护进程运行的时候，它会写一个 pid 到 /var/run/redis.pid 文件里面。
daemonize yes

# When running daemonized, Redis writes a pid file in /var/run/redis.pid by
# default. You can specify a custom pid file location here.
# 当 Redis 以守护进程的方式运行的时候，Redis 默认会把 pid 文件放在/var/run/redis.pid
# 可配置到其他地址，当运行多个 redis 服务时，需要指定不同的 pid 文件和端口
# 指定存储Redis进程号的文件路径
pidfile /var/run/redis.pid

# Accept connections on the specified port, default is 6379.
# If port 0 is specified Redis will not listen on a TCP socket.
# 端口，默认端口是6379，生产环境中建议更改端口号，安全性更高
# 如果你设为 0 ，redis 将不在 socket 上监听任何客户端连接。
port 9966

# TCP listen() backlog.
#
# In high requests-per-second environments you need an high backlog in order
# to avoid slow clients connections issues. Note that the Linux kernel
# will silently truncate it to the value of /proc/sys/net/core/somaxconn so
# make sure to raise both the value of somaxconn and tcp_max_syn_backlog
# in order to get the desired effect.
# TCP 监听的最大容纳数量
# 此参数确定了TCP连接中已完成队列(完成三次握手之后)的长度，
# 当系统并发量大并且客户端速度缓慢的时候，你需要把这个值调高以避免客户端连接缓慢的问题。
# Linux 内核会一声不响的把这个值缩小成 /proc/sys/net/core/somaxconn 对应的值，默认是511，而Linux的默认参数值是128。
# 所以可以将这二个参数一起参考设定，你以便达到你的预期。
#  
tcp-backlog 511

# By default Redis listens for connections from all the network interfaces
# available on the server. It is possible to listen to just one or multiple
# interfaces using the &quot;bind&quot; configuration directive, followed by one or
# more IP addresses.
#
# Examples:
#
# bind 192.168.1.100 10.0.0.1
# 有时候为了安全起见，redis一般都是监听127.0.0.1 但是有时候又有同网段能连接的需求，当然可以绑定0.0.0.0 用iptables来控制访问权限，或者设置redis访问密码来保证数据安全

# 不设置将处理所有请求,建议生产环境中设置，有个误区：bind是用来限制外网IP访问的，其实不是，限制外网ip访问可以通过iptables；如：-A INPUT -s 10.10.1.0/24 -p tcp -m state --state NEW -m tcp --dport 9966 -j ACCEPT ；
# 实际上，bind ip 绑定的是redis所在服务器网卡的ip，当然127.0.0.1也是可以的
#如果绑定一个外网ip，就会报错：Creating Server TCP listening socket xxx.xxx.xxx.xxx:9966: bind: Cannot assign requested address

# bind 127.0.0.1
bind 127.0.0.1 10.10.1.3

# 假设绑定是以上ip，使用 netstat -anp|grep 9966 会发现，这两个ip被bind，其中10.10.1.3是服务器网卡的ip
# tcp        0      0 10.10.1.3:9966         0.0.0.0:*                   LISTEN      11188/redis-server  
# tcp        0      0 127.0.0.1:9966         0.0.0.0:*                   LISTEN      11188/redis-server 


# Specify the path for the Unix socket that will be used to listen for
# incoming connections. There is no default, so Redis will not listen
# on a unix socket when not specified.
#
# unixsocket /tmp/redis.sock
# unixsocketperm 700

# Close the connection after a client is idle for N seconds (0 to disable)
# 客户端和Redis服务端的连接超时时间，默认是0，表示永不超时。
timeout 0

# TCP keepalive.
#
# If non-zero, use SO_KEEPALIVE to send TCP ACKs to clients in absence
# of communication. This is useful for two reasons:
#
# 1) Detect dead peers.
# 2) Take the connection alive from the point of view of network
#    equipment in the middle.
#
# On Linux, the specified value (in seconds) is the period used to send ACKs.
# Note that to close the connection the double of the time is needed.
# On other kernels the period depends on the kernel configuration.
#
# A reasonable value for this option is 60 seconds.

# tcp 心跳包。
#
# 如果设置为非零，则在与客户端缺乏通讯的时候使用 SO_KEEPALIVE 发送 tcp acks 给客户端。
# 这个之所有有用，主要由两个原因：
#
# 1) 防止死的 peers
# 2) Take the connection alive from the point of view of network
#    equipment in the middle.
#
# 推荐一个合理的值就是60秒
tcp-keepalive 0

# Specify the server verbosity level.
# This can be one of:
# debug (a lot of information, useful for development/testing)
# verbose (many rarely useful info, but not a mess like the debug level)
# notice (moderately verbose, what you want in production probably)
# warning (only very important / critical messages are logged)
# 日志记录等级，4个可选值debug,verbose,notice,warning
# 可以是下面的这些值：
# debug (适用于开发或测试阶段)
# verbose (many rarely useful info, but not a mess like the debug level)
# notice (适用于生产环境)
# warning (仅仅一些重要的消息被记录)
loglevel notice

# Specify the log file name. Also the empty string can be used to force
# Redis to log on the standard output. Note that if you use standard
# output for logging but daemonize, logs will be sent to /dev/null
#配置 log 文件地址,默认打印在命令行终端的窗口上，也可设为/dev/null屏蔽日志、
logfile &quot;/data/logs/redis/redis.log&quot;

# To enable logging to the system logger, just set 'syslog-enabled' to yes,
# and optionally update the other syslog parameters to suit your needs.
# 要想把日志记录到系统日志，就把它改成 yes，
# 也可以可选择性的更新其他的syslog 参数以达到你的要求
# syslog-enabled no

# Specify the syslog identity.
# 设置 syslog 的 identity。
# syslog-ident redis

# Specify the syslog facility. Must be USER or between LOCAL0-LOCAL7.
# syslog-facility local0

# Set the number of databases. The default database is DB 0, you can select
# a different one on a per-connection basis using SELECT &lt;/span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;dbid&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;span&gt; where
# dbid is a number between 0 and 'databases'-1
# 可用的数据库数，默认值为16，默认数据库为0，数据库范围在0-（database-1）之间
databases 16

################################ SNAPSHOTTING  ################################
################################ 快照          ################################
#
# Save the DB on disk:
#
#   save &lt;/span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;seconds&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;changes&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;span&gt;
#
#   Will save the DB if both the given number of seconds and the given
#   number of write operations against the DB occurred.
#
#   In the example below the behaviour will be to save:
#   after 900 sec (15 min) if at least 1 key changed
#   after 300 sec (5 min) if at least 10 keys changed
#   after 60 sec if at least 10000 keys changed
#
#   Note: you can disable saving completely by commenting out all &quot;save&quot; lines.
#
#   It is also possible to remove all the previously configured save
#   points by adding a save directive with a single empty string argument
#   like in the following example:
#
#   save &quot;&quot;
# 在 900 秒内最少有 1 个 key 被改动，或者 300 秒内最少有 10 个 key 被改动，又或者 60 秒内最少有 1000 个 key 被改动，以上三个条件随便满足一个，就触发一次保存操作。

#    if(在60秒之内有10000个keys发生变化时){
#      进行镜像备份
#    }else if(在300秒之内有10个keys发生了变化){
#      进行镜像备份
#    }else if(在900秒之内有1个keys发生了变化){
#      进行镜像备份
#    }

save 900 1
save 300 10
save 60 10000

# By default Redis will stop accepting writes if RDB snapshots are enabled
# (at least one save point) and the latest background save failed.
# This will make the user aware (in a hard way) that data is not persisting
# on disk properly, otherwise chances are that no one will notice and some
#:/ disaster will happen.
#
# If the background saving process will start working again Redis will
# automatically allow writes again.
#
# However if you have setup your proper monitoring of the Redis server
# and persistence, you may want to disable this feature so that Redis will
# continue to work as usual even if there are problems with disk,
# permissions, and so forth.
# 默认情况下，如果 redis 最后一次的后台保存失败，redis 将停止接受写操作，
# 这样以一种强硬的方式让用户知道数据不能正确的持久化到磁盘，
# 否则就会没人注意到灾难的发生。
#
# 如果后台保存进程重新启动工作了，redis 也将自动的允许写操作。
#
# 然而你要是安装了靠谱的监控，你可能不希望 redis 这样做，那你就改成 no 好
stop-writes-on-bgsave-error yes

# Compress string objects using LZF when dump .rdb databases?
# For default that's set to 'yes' as it's almost always a win.
# If you want to save some CPU in the saving child set it to 'no' but
# the dataset will likely be bigger if you have compressible values or keys.
# 在进行备份时,是否进行压缩
# 是否在 dump .rdb 数据库的时候使用 LZF 压缩字符串
# 默认都设为 yes
# 如果你希望保存子进程节省点 cpu ，你就设置它为 no ，
# 不过这个数据集可能就会比较大
rdbcompression yes

# Since version 5 of RDB a CRC64 checksum is placed at the end of the file.
# This makes the format more resistant to corruption but there is a performance
# hit to pay (around 10%) when saving and loading RDB files, so you can disable it
# for maximum performances.
#
# RDB files created with checksum disabled have a checksum of zero that will
# tell the loading code to skip the check.    
# 读取和写入的时候是否支持CRC64校验，默认是开启的
rdbchecksum yes

# The filename where to dump the DB
# 备份文件的文件名
dbfilename dump.rdb

# The working directory.
#
# The DB will be written inside this directory, with the filename specified
# above using the 'dbfilename' configuration directive.
#
# The Append Only File will also be created inside this directory.
#
# Note that you must specify a directory here, not a file name.
# 数据库备份的文件放置的路径
# 路径跟文件名分开配置是因为 Redis 备份时，先会将当前数据库的状态写入到一个临时文件
# 等备份完成时，再把该临时文件替换为上面所指定的文件
# 而临时文件和上面所配置的备份文件都会放在这个指定的路径当中
# 默认值为 ./
dir /data/data/redis/

################################# REPLICATION #################################
################################# 主从复制    #################################
# Master-Slave replication. Use slaveof to make a Redis instance a copy of
# another Redis server. A few things to understand ASAP about Redis replication.
#
# 1) Redis replication is asynchronous, but you can configure a master to
#    stop accepting writes if it appears to be not connected with at least
#    a given number of slaves.
# 2) Redis slaves are able to perform a partial resynchronization with the
#    master if the replication link is lost for a relatively small amount of
#    time. You may want to configure the replication backlog size (see the next
#    sections of this file) with a sensible value depending on your needs.
# 3) Replication is automatic and does not need user intervention. After a
#    network partition slaves automatically try to reconnect to masters
#    and resynchronize with them.
#
# 设置该数据库为其他数据库的从数据库
# slaveof &lt;/span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;masterip&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;masterport&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;span&gt; 当本机为从服务时，设置主服务的IP及端口
# slaveof &lt;/span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;masterip&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;masterport&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;span&gt;

# If the master is password protected (using the &quot;requirepass&quot; configuration
# directive below) it is possible to tell the slave to authenticate before
# starting the replication synchronization process, otherwise the master will
# refuse the slave request.
#
# 指定与主数据库连接时需要的密码验证
# masterauth &lt;/span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;master-password&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;span&gt; 当本机为从服务时，设置访问master服务器的密码
# masterauth &lt;/span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;master-password&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;span&gt;

# When a slave loses its connection with the master, or when the replication
# is still in progress, the slave can act in two different ways:
#
# 1) if slave-serve-stale-data is set to 'yes' (the default) the slave will
#    still reply to client requests, possibly with out of date data, or the
#    data set may just be empty if this is the first synchronization.
#
# 2) if slave-serve-stale-data is set to 'no' the slave will reply with
#    an error &quot;SYNC with master in progress&quot; to all the kind of commands
#    but to INFO and SLAVEOF.
#
# 当slave服务器和master服务器失去连接后，或者当数据正在复制传输的时候，如果此参数值设置“yes”，slave服务器可以继续接受客户端的请求，否则，会返回给请求的客户端如下信息“SYNC with master in progress”,除了INFO，SLAVEOF这两个命令
slave-serve-stale-data yes

# You can configure a slave instance to accept writes or not. Writing against
# a slave instance may be useful to store some ephemeral data (because data
# written on a slave will be easily deleted after resync with the master) but
# may also cause problems if clients are writing to it because of a
# misconfiguration.
#
# Since Redis 2.6 by default slaves are read-only.
#
# Note: read only slaves are not designed to be exposed to untrusted clients
# on the internet. It's just a protection layer against misuse of the instance.
# Still a read only slave exports by default all the administrative commands
# such as CONFIG, DEBUG, and so forth. To a limited extent you can improve
# security of read only slaves using 'rename-command' to shadow all the
# administrative / dangerous commands.
# 是否允许slave服务器节点只提供读服务
slave-read-only yes

# Replication SYNC strategy: disk or socket.
#
# -------------------------------------------------------
# WARNING: DISKLESS REPLICATION IS EXPERIMENTAL CURRENTLY
# -------------------------------------------------------
#
# New slaves and reconnecting slaves that are not able to continue the replication
# process just receiving differences, need to do what is called a &quot;full
# synchronization&quot;. An RDB file is transmitted from the master to the slaves.
# The transmission can happen in two different ways:
#
# 1) Disk-backed: The Redis master creates a new process that writes the RDB
#                 file on disk. Later the file is transferred by the parent
#                 process to the slaves incrementally.
# 2) Diskless: The Redis master creates a new process that directly writes the
#              RDB file to slave sockets, without touching the disk at all.
#
# With disk-backed replication, while the RDB file is generated, more slaves
# can be queued and served with the RDB file as soon as the current child producing
# the RDB file finishes its work. With diskless replication instead once
# the transfer starts, new slaves arriving will be queued and a new transfer
# will start when the current one terminates.
#
# When diskless replication is used, the master waits a configurable amount of
# time (in seconds) before starting the transfer in the hope that multiple slaves
# will arrive and the transfer can be parallelized.
#
# With slow disks and fast (large bandwidth) networks, diskless replication
# works better.
repl-diskless-sync no

# When diskless replication is enabled, it is possible to configure the delay
# the server waits in order to spawn the child that transfers the RDB via socket
# to the slaves.
#
# This is important since once the transfer starts, it is not possible to serve
# new slaves arriving, that will be queued for the next RDB transfer, so the server
# waits a delay in order to let more slaves arrive.
#
# The delay is specified in seconds, and by default is 5 seconds. To disable
# it entirely just set it to 0 seconds and the transfer will start ASAP.
repl-diskless-sync-delay 5

# Slaves send PINGs to server in a predefined interval. It's possible to change
# this interval with the repl_ping_slave_period option. The default value is 10
# seconds.
#
# Slaves 在一个预定义的时间间隔内发送 ping 命令到 server 。
# 你可以改变这个时间间隔。默认为 10 秒。
# repl-ping-slave-period 10

# The following option sets the replication timeout for:
#
# 1) Bulk transfer I/O during SYNC, from the point of view of slave.
# 2) Master timeout from the point of view of slaves (data, pings).
# 3) Slave timeout from the point of view of masters (REPLCONF ACK pings).
#
# It is important to make sure that this value is greater than the value
# specified for repl-ping-slave-period otherwise a timeout will be detected
# every time there is low traffic between the master and the slave.
#
# 设置主从复制过期时间
# 这个值一定要比 repl-ping-slave-period 大
# repl-timeout 60

# Disable TCP_NODELAY on the slave socket after SYNC?
#
# If you select &quot;yes&quot; Redis will use a smaller number of TCP packets and
# less bandwidth to send data to slaves. But this can add a delay for
# the data to appear on the slave side, up to 40 milliseconds with
# Linux kernels using a default configuration.
#
# If you select &quot;no&quot; the delay for data to appear on the slave side will
# be reduced but more bandwidth will be used for replication.
#
# By default we optimize for low latency, but in very high traffic conditions
# or when the master and slaves are many hops away, turning this to &quot;yes&quot; may
# be a good idea.
# 指定向slave同步数据时，是否禁用socket的NO_DELAY选 项。若配置为“yes”，则禁用NO_DELAY，则TCP协议栈会合并小包统一发送，这样可以减少主从节点间的包数量并节省带宽，但会增加数据同步到 slave的时间。若配置为“no”，表明启用NO_DELAY，则TCP协议栈不会延迟小包的发送时机，这样数据同步的延时会减少，但需要更大的带宽。 通常情况下，应该配置为no以降低同步延时，但在主从节点间网络负载已经很高的情况下，可以配置为yes。
repl-disable-tcp-nodelay no

# Set the replication backlog size. The backlog is a buffer that accumulates
# slave data when slaves are disconnected for some time, so that when a slave
# wants to reconnect again, often a full resync is not needed, but a partial
# resync is enough, just passing the portion of data the slave missed while
# disconnected.
#
# The bigger the replication backlog, the longer the time the slave can be
# disconnected and later be able to perform a partial resynchronization.
#
# The backlog is only allocated once there is at least a slave connected.
#
# 设置主从复制容量大小。这个 backlog 是一个用来在 slaves 被断开连接时
# 存放 slave 数据的 buffer，所以当一个 slave 想要重新连接，通常不希望全部重新同步，
# 只是部分同步就够了，仅仅传递 slave 在断开连接时丢失的这部分数据。
#
# The biggest the replication backlog, the longer the time the slave can be
# disconnected and later be able to perform a partial resynchronization.
# 这个值越大，salve 可以断开连接的时间就越长。

# repl-backlog-size 1mb

# After a master has no longer connected slaves for some time, the backlog
# will be freed. The following option configures the amount of seconds that
# need to elapse, starting from the time the last slave disconnected, for
# the backlog buffer to be freed.
#
# A value of 0 means to never release the backlog.
#
# 在某些时候，master 不再连接 slaves，backlog 将被释放。
# 如果设置为 0 ，意味着绝不释放 backlog 。
# repl-backlog-ttl 3600

# The slave priority is an integer number published by Redis in the INFO output.
# It is used by Redis Sentinel in order to select a slave to promote into a
# master if the master is no longer working correctly.
#
# A slave with a low priority number is considered better for promotion, so
# for instance if there are three slaves with priority 10, 100, 25 Sentinel will
# pick the one with priority 10, that is the lowest.
#
# However a special priority of 0 marks the slave as not able to perform the
# role of master, so a slave with priority of 0 will never be selected by
# Redis Sentinel for promotion.
#
# By default the priority is 100.
# 指定slave的优先级。在不只1个slave存在的部署环境下，当master宕机时，Redis
# Sentinel会将priority值最小的slave提升为master。
# 这个值越小，就越会被优先选中，需要注意的是，
# 若该配置项为0，则对应的slave永远不会自动提升为master。
slave-priority 100

# It is possible for a master to stop accepting writes if there are less than
# N slaves connected, having a lag less or equal than M seconds.
#
# The N slaves need to be in &quot;online&quot; state.
#
# The lag in seconds, that must be &lt;/span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;= the &lt;/span&gt;&lt;span&gt;specified value, is calculated from
# the last ping received from the slave, that is usually sent every second.
#
# This option does not GUARANTEE that N replicas will accept the write, but
# will limit the window of exposure for lost writes in case not enough slaves
# are available, to the specified number of seconds
#
# For example to require at least 3 slaves with a lag &amp;lt;&lt;/span&gt;&lt;span&gt;= 10 &lt;/span&gt;&lt;span&gt;seconds use:
#
# min-slaves-to-write 3
# min-slaves-max-lag 10
#
# Setting one or the other to 0 disables the feature.
#
# By default min-slaves-to-write is set to 0 (feature disabled) and
# min-slaves-max-lag is set to 10.

################################## SECURITY ###################################
################################## 安全     ###################################

# Require clients to issue AUTH &amp;lt;PASSWORD&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;span&gt; before processing any other
# commands.  This might be useful in environments in which you do not trust
# others with access to the host running redis-server.
#
# This should stay commented out for backward compatibility and because most
# people do not need auth (e.g. they run their own servers).
#
# Warning: since Redis is pretty fast an outside user can try up to
# 150k passwords per second against a good box. This means that you should
# use a very strong password otherwise it will be very easy to break.
#
# 设置连接redis的密码
# redis速度相当快，一个外部用户在一秒钟进行150K次密码尝试，需指定强大的密码来防止暴力破解
requirepass set_enough_strong_passwd

# Command renaming.
#
# It is possible to change the name of dangerous commands in a shared
# environment. For instance the CONFIG command may be renamed into something
# hard to guess so that it will still be available for internal-use tools
# but not available for general clients.
#
# Example:
#
# rename-command CONFIG b840fc02d524045429941cc15f59e41cb7be6c52
#
# It is also possible to completely kill a command by renaming it into
# an empty string:
#
# rename-command CONFIG &quot;&quot;
#
# Please note that changing the name of commands that are logged into the
# AOF file or transmitted to slaves may cause problems.
# 重命名一些高危命令，用来禁止高危命令
rename-command FLUSHALL ZYzv6FOBdwflW2nX
rename-command CONFIG aI7zwm1GDzMMrEi
rename-command EVAL S9UHPKEpSvUJMM
rename-command FLUSHDB D60FPVDJuip7gy6l

################################### LIMITS ####################################
################################### 限制   ####################################

# Set the max number of connected clients at the same time. By default
# this limit is set to 10000 clients, however if the Redis server is not
# able to configure the process file limit to allow for the specified limit
# the max number of allowed clients is set to the current file limit
# minus 32 (as Redis reserves a few file descriptors for internal uses).
#
# Once the limit is reached Redis will close all the new connections sending
# an error 'max number of clients reached'.
#
# 限制同时连接的客户数量,默认是10000
# 当连接数超过这个值时，redis 将不再接收其他连接请求，客户端尝试连接时将收到 error 信息
# maxclients 10000

# Don't use more memory than the specified amount of bytes.
# When the memory limit is reached Redis will try to remove keys
# according to the eviction policy selected (see maxmemory-policy).
#
# If Redis can't remove keys according to the policy, or if the policy is
# set to 'noeviction', Redis will start to reply with errors to commands
# that would use more memory, like SET, LPUSH, and so on, and will continue
# to reply to read-only commands like GET.
#
# This option is usually useful when using Redis as an LRU cache, or to set
# a hard memory limit for an instance (using the 'noeviction' policy).
#
# WARNING: If you have slaves attached to an instance with maxmemory on,
# the size of the output buffers needed to feed the slaves are subtracted
# from the used memory count, so that network problems / resyncs will
# not trigger a loop where keys are evicted, and in turn the output
# buffer of slaves is full with DELs of keys evicted triggering the deletion
# of more keys, and so forth until the database is completely emptied.
#
# In short... if you have slaves attached it is suggested that you set a lower
# limit for maxmemory so that there is some free RAM on the system for slave
# output buffers (but this is not needed if the policy is 'noeviction').
#
# 设置redis能够使用的最大内存。
# 达到最大内存设置后，Redis会先尝试清除已到期或即将到期的Key（设置过expire信息的key）
# 在删除时,按照过期时间进行删除，最早将要被过期的key将最先被删除
# 如果已到期或即将到期的key删光，仍进行set操作，那么将返回错误
# 此时redis将不再接收写请求,只接收get请求。
# maxmemory的设置比较适合于把redis当作于类似memcached 的缓存来使用
# maxmemory &lt;/span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;bytes&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;span&gt;

# MAXMEMORY POLICY: how Redis will select what to remove when maxmemory
# is reached. You can select among five behaviors:
#
# volatile-lru -&amp;gt; remove the key with an expire set using an LRU algorithm
# allkeys-lru -&amp;gt; remove any key according to the LRU algorithm
# volatile-random -&amp;gt; remove a random key with an expire set
# allkeys-random -&amp;gt; remove a random key, any key
# volatile-ttl -&amp;gt; remove the key with the nearest expire time (minor TTL)
# noeviction -&amp;gt; don't expire at all, just return an error on write operations
#
# Note: with any of the above policies, Redis will return an error on write
#       operations, when there are no suitable keys for eviction.
#
#       At the date of writing these commands are: set setnx setex append
#       incr decr rpush lpush rpushx lpushx linsert lset rpoplpush sadd
#       sinter sinterstore sunion sunionstore sdiff sdiffstore zadd zincrby
#       zunionstore zinterstore hset hsetnx hmset hincrby incrby decrby
#       getset mset msetnx exec sort
#
# The default is:
#
# maxmemory-policy noeviction

# LRU and minimal TTL algorithms are not precise algorithms but approximated
# algorithms (in order to save memory), so you can tune it for speed or
# accuracy. For default Redis will check five keys and pick the one that was
# used less recently, you can change the sample size using the following
# configuration directive.
#
# The default of 5 produces good enough results. 10 Approximates very closely
# true LRU but costs a bit more CPU. 3 is very fast but not very accurate.
#
# maxmemory-samples 5

############################## APPEND ONLY MODE ###############################

# By default Redis asynchronously dumps the dataset on disk. This mode is
# good enough in many applications, but an issue with the Redis process or
# a power outage may result into a few minutes of writes lost (depending on
# the configured save points).
#
# The Append Only File is an alternative persistence mode that provides
# much better durability. For instance using the default data fsync policy
# (see later in the config file) Redis can lose just one second of writes in a
# dramatic event like a server power outage, or a single write if something
# wrong with the Redis process itself happens, but the operating system is
# still running correctly.
#
# AOF and RDB persistence can be enabled at the same time without problems.
# If the AOF is enabled on startup Redis will load the AOF, that is the file
# with the better durability guarantees.
#
# Please check http://redis.io/topics/persistence for more information.

# redis 默认每次更新操作后会在后台异步的把数据库镜像备份到磁盘，但该备份非常耗时，且备份不宜太频繁
# redis 同步数据文件是按上面save条件来同步的
# 如果发生诸如拉闸限电、拔插头等状况,那么将造成比较大范围的数据丢失
# 所以redis提供了另外一种更加高效的数据库备份及灾难恢复方式
# 开启append only 模式后,redis 将每一次写操作请求都追加到appendonly.aof 文件中
# redis重新启动时,会从该文件恢复出之前的状态。
# 但可能会造成 appendonly.aof 文件过大，所以redis支持BGREWRITEAOF 指令，对appendonly.aof重新整理,默认是不开启的。

appendonly no

# The name of the append only file (default: &quot;appendonly.aof&quot;)
# 默认为appendonly.aof。
appendfilename &quot;appendonly.aof&quot;

# The fsync() call tells the Operating System to actually write data on disk
# instead of waiting for more data in the output buffer. Some OS will really flush
# data on disk, some other OS will just try to do it ASAP.
#
# Redis supports three different modes:
#
# no: don't fsync, just let the OS flush the data when it wants. Faster.
# always: fsync after every write to the append only log. Slow, Safest.
# everysec: fsync only one time every second. Compromise.
#
# The default is &quot;everysec&quot;, as that's usually the right compromise between
# speed and data safety. It's up to you to understand if you can relax this to
# &quot;no&quot; that will let the operating system flush the output buffer when
# it wants, for better performances (but if you can live with the idea of
# some data loss consider the default persistence mode that's snapshotting),
# or on the contrary, use &quot;always&quot; that's very slow but a bit safer than
# everysec.
#
# More details please check the following article:
# http://antirez.com/post/redis-persistence-demystified.html
#
# If unsure, use &quot;everysec&quot;.

# 设置对 appendonly.aof 文件进行同步的频率,有三种选择always、everysec、no，默认是everysec表示每秒同步一次。
# always 表示每次有写操作都进行同步,everysec 表示对写操作进行累积,每秒同步一次。
# no表示等操作系统进行数据缓存同步到磁盘，都进行同步,everysec 表示对写操作进行累积,每秒同步一次
# appendfsync always
# appendfsync everysec
# appendfsync no

# When the AOF fsync policy is set to always or everysec, and a background
# saving process (a background save or AOF log background rewriting) is
# performing a lot of I/O against the disk, in some Linux configurations
# Redis may block too long on the fsync() call. Note that there is no fix for
# this currently, as even performing fsync in a different thread will block
# our synchronous write(2) call.
#
# In order to mitigate this problem it's possible to use the following option
# that will prevent fsync() from being called in the main process while a
# BGSAVE or BGREWRITEAOF is in progress.
#
# This means that while another child is saving, the durability of Redis is
# the same as &quot;appendfsync none&quot;. In practical terms, this means that it is
# possible to lose up to 30 seconds of log in the worst scenario (with the
# default Linux settings).
#
# If you have latency problems turn this to &quot;yes&quot;. Otherwise leave it as
# &quot;no&quot; that is the safest pick from the point of view of durability.
# 指定是否在后台aof文件rewrite期间调用fsync，默认为no，表示要调用fsync（无论后台是否有子进程在刷盘）。Redis在后台写RDB文件或重写afo文件期间会存在大量磁盘IO，此时，在某些linux系统中，调用fsync可能会阻塞。
no-appendfsync-on-rewrite yes

# Automatic rewrite of the append only file.
# Redis is able to automatically rewrite the log file implicitly calling
# BGREWRITEAOF when the AOF log size grows by the specified percentage.
#
# This is how it works: Redis remembers the size of the AOF file after the
# latest rewrite (if no rewrite has happened since the restart, the size of
# the AOF at startup is used).
#
# This base size is compared to the current size. If the current size is
# bigger than the specified percentage, the rewrite is triggered. Also
# you need to specify a minimal size for the AOF file to be rewritten, this
# is useful to avoid rewriting the AOF file even if the percentage increase
# is reached but it is still pretty small.
#
# Specify a percentage of zero in order to disable the automatic AOF
# rewrite feature.
# 指定Redis重写aof文件的条件，默认为100，表示与上次rewrite的aof文件大小相比，当前aof文件增长量超过上次afo文件大小的100%时，就会触发background rewrite。若配置为0，则会禁用自动rewrite
auto-aof-rewrite-percentage 100

# 指定触发rewrite的aof文件大小。若aof文件小于该值，即使当前文件的增量比例达到auto-aof-rewrite-percentage的配置值，也不会触发自动rewrite。即这两个配置项同时满足时，才会触发rewrite。
auto-aof-rewrite-min-size 64mb

# An AOF file may be found to be truncated at the end during the Redis
# startup process, when the AOF data gets loaded back into memory.
# This may happen when the system where Redis is running
# crashes, especially when an ext4 filesystem is mounted without the
# data=ordered option (however this can't happen when Redis itself
# crashes or aborts but the operating system still works correctly).
#
# Redis can either exit with an error when this happens, or load as much
# data as possible (the default now) and start if the AOF file is found
# to be truncated at the end. The following option controls this behavior.
#
# If aof-load-truncated is set to yes, a truncated AOF file is loaded and
# the Redis server starts emitting a log to inform the user of the event.
# Otherwise if the option is set to no, the server aborts with an error
# and refuses to start. When the option is set to no, the user requires
# to fix the AOF file using the &quot;redis-check-aof&quot; utility before to restart
# the server.
#
# Note that if the AOF file will be found to be corrupted in the middle
# the server will still exit with an error. This option only applies when
# Redis will try to read more data from the AOF file but not enough bytes
# will be found.
aof-load-truncated yes

################################ LUA SCRIPTING  ###############################

# Max execution time of a Lua script in milliseconds.
#
# If the maximum execution time is reached Redis will log that a script is
# still in execution after the maximum allowed time and will start to
# reply to queries with an error.
#
# When a long running script exceeds the maximum execution time only the
# SCRIPT KILL and SHUTDOWN NOSAVE commands are available. The first can be
# used to stop a script that did not yet called write commands. The second
# is the only way to shut down the server in the case a write command was
# already issued by the script but the user doesn't want to wait for the natural
# termination of the script.
#
# Set it to 0 or a negative value for unlimited execution without warnings.
# 一个Lua脚本最长的执行时间，单位为毫秒，如果为0或负数表示无限执行时间，默认为5000
lua-time-limit 5000

################################ REDIS CLUSTER  ###############################
#
# ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
# WARNING EXPERIMENTAL: Redis Cluster is considered to be stable code, however
# in order to mark it as &quot;mature&quot; we need to wait for a non trivial percentage
# of users to deploy it in production.
# ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
#
# Normal Redis instances can't be part of a Redis Cluster; only nodes that are
# started as cluster nodes can. In order to start a Redis instance as a
# cluster node enable the cluster support uncommenting the following:
#
# cluster-enabled yes

# Every cluster node has a cluster configuration file. This file is not
# intended to be edited by hand. It is created and updated by Redis nodes.
# Every Redis Cluster node requires a different cluster configuration file.
# Make sure that instances running in the same system do not have
# overlapping cluster configuration file names.
#
# cluster-config-file nodes-6379.conf

# Cluster node timeout is the amount of milliseconds a node must be unreachable
# for it to be considered in failure state.
# Most other internal time limits are multiple of the node timeout.
#
# cluster-node-timeout 15000

# A slave of a failing master will avoid to start a failover if its data
# looks too old.
#
# There is no simple way for a slave to actually have a exact measure of
# its &quot;data age&quot;, so the following two checks are performed:
#
# 1) If there are multiple slaves able to failover, they exchange messages
#    in order to try to give an advantage to the slave with the best
#    replication offset (more data from the master processed).
#    Slaves will try to get their rank by offset, and apply to the start
#    of the failover a delay proportional to their rank.
#
# 2) Every single slave computes the time of the last interaction with
#    its master. This can be the last ping or command received (if the master
#    is still in the &quot;connected&quot; state), or the time that elapsed since the
#    disconnection with the master (if the replication link is currently down).
#    If the last interaction is too old, the slave will not try to failover
#    at all.
#
# The point &quot;2&quot; can be tuned by user. Specifically a slave will not perform
# the failover if, since the last interaction with the master, the time
# elapsed is greater than:
#
#   (node-timeout * slave-validity-factor) + repl-ping-slave-period
#
# So for example if node-timeout is 30 seconds, and the slave-validity-factor
# is 10, and assuming a default repl-ping-slave-period of 10 seconds, the
# slave will not try to failover if it was not able to talk with the master
# for longer than 310 seconds.
#
# A large slave-validity-factor may allow slaves with too old data to failover
# a master, while a too small value may prevent the cluster from being able to
# elect a slave at all.
#
# For maximum availability, it is possible to set the slave-validity-factor
# to a value of 0, which means, that slaves will always try to failover the
# master regardless of the last time they interacted with the master.
# (However they'll always try to apply a delay proportional to their
# offset rank).
#
# Zero is the only value able to guarantee that when all the partitions heal
# the cluster will always be able to continue.
#
# cluster-slave-validity-factor 10

# Cluster slaves are able to migrate to orphaned masters, that are masters
# that are left without working slaves. This improves the cluster ability
# to resist to failures as otherwise an orphaned master can't be failed over
# in case of failure if it has no working slaves.
#
# Slaves migrate to orphaned masters only if there are still at least a
# given number of other working slaves for their old master. This number
# is the &quot;migration barrier&quot;. A migration barrier of 1 means that a slave
# will migrate only if there is at least 1 other working slave for its master
# and so forth. It usually reflects the number of slaves you want for every
# master in your cluster.
#
# Default is 1 (slaves migrate only if their masters remain with at least
# one slave). To disable migration just set it to a very large value.
# A value of 0 can be set but is useful only for debugging and dangerous
# in production.
#
# cluster-migration-barrier 1

# By default Redis Cluster nodes stop accepting queries if they detect there
# is at least an hash slot uncovered (no available node is serving it).
# This way if the cluster is partially down (for example a range of hash slots
# are no longer covered) all the cluster becomes, eventually, unavailable.
# It automatically returns available as soon as all the slots are covered again.
#
# However sometimes you want the subset of the cluster which is working,
# to continue to accept queries for the part of the key space that is still
# covered. In order to do so, just set the cluster-require-full-coverage
# option to no.
#
# cluster-require-full-coverage yes

# In order to setup your cluster make sure to read the documentation
# available at http://redis.io web site.

################################## SLOW LOG ###################################

# The Redis Slow Log is a system to log queries that exceeded a specified
# execution time. The execution time does not include the I/O operations
# like talking with the client, sending the reply and so forth,
# but just the time needed to actually execute the command (this is the only
# stage of command execution where the thread is blocked and can not serve
# other requests in the meantime).
#
# You can configure the slow log with two parameters: one tells Redis
# what is the execution time, in microseconds, to exceed in order for the
# command to get logged, and the other parameter is the length of the
# slow log. When a new command is logged the oldest one is removed from the
# queue of logged commands.

# The following time is expressed in microseconds, so 1000000 is equivalent
# to one second. Note that a negative number disables the slow log, while
# a value of zero forces the logging of every command.
slowlog-log-slower-than 10000

# There is no limit to this length. Just be aware that it will consume memory.
# You can reclaim memory used by the slow log with SLOWLOG RESET.
slowlog-max-len 128

################################ LATENCY MONITOR ##############################

# The Redis latency monitoring subsystem samples different operations
# at runtime in order to collect data related to possible sources of
# latency of a Redis instance.
#
# Via the LATENCY command this information is available to the user that can
# print graphs and obtain reports.
#
# The system only logs operations that were performed in a time equal or
# greater than the amount of milliseconds specified via the
# latency-monitor-threshold configuration directive. When its value is set
# to zero, the latency monitor is turned off.
#
# By default latency monitoring is disabled since it is mostly not needed
# if you don't have latency issues, and collecting data has a performance
# impact, that while very small, can be measured under big load. Latency
# monitoring can easily be enabled at runtime using the command
# &quot;CONFIG SET latency-monitor-threshold &lt;/span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;milliseconds&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;span&gt;&quot; if needed.
latency-monitor-threshold 0

############################# EVENT NOTIFICATION ##############################

# Redis can notify Pub/Sub clients about events happening in the key space.
# This feature is documented at http://redis.io/topics/notifications
#
# For instance if keyspace events notification is enabled, and a client
# performs a DEL operation on key &quot;foo&quot; stored in the Database 0, two
# messages will be published via Pub/Sub:
#
# PUBLISH __keyspace@0__:foo del
# PUBLISH __keyevent@0__:del foo
#
# It is possible to select the events that Redis will notify among a set
# of classes. Every class is identified by a single character:
#
#  K     Keyspace events, published with __keyspace@&lt;/span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;db&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;span&gt;__ prefix.
#  E     Keyevent events, published with __keyevent@&lt;/span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;db&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;span&gt;__ prefix.
#  g     Generic commands (non-type specific) like DEL, EXPIRE, RENAME, ...
#  $     String commands
#  l     List commands
#  s     Set commands
#  h     Hash commands
#  z     Sorted set commands
#  x     Expired events (events generated every time a key expires)
#  e     Evicted events (events generated when a key is evicted for maxmemory)
#  A     Alias for g$lshzxe, so that the &quot;AKE&quot; string means all the events.
#
#  The &quot;notify-keyspace-events&quot; takes as argument a string that is composed
#  of zero or multiple characters. The empty string means that notifications
#  are disabled.
#
#  Example: to enable list and generic events, from the point of view of the
#           event name, use:
#
#  notify-keyspace-events Elg
#
#  Example 2: to get the stream of the expired keys subscribing to channel
#             name __keyevent@0__:expired use:
#
#  notify-keyspace-events Ex
#
#  By default all notifications are disabled because most users don't need
#  this feature and the feature has some overhead. Note that if you don't
#  specify at least one of K or E, no events will be delivered.
notify-keyspace-events &quot;&quot;

############################### ADVANCED CONFIG ###############################

# Hashes are encoded using a memory efficient data structure when they have a
# small number of entries, and the biggest entry does not exceed a given
# threshold. These thresholds can be configured using the following directives.
# 当hash中包含超过指定元素个数并且最大的元素没有超过临界时，
# hash将以一种特殊的编码方式（大大减少内存使用）来存储，这里可以设置这两个临界值
hash-max-ziplist-entries 512
hash-max-ziplist-value 64

# Similarly to hashes, small lists are also encoded in a special way in order
# to save a lot of space. The special representation is only used when
# you are under the following limits:
# list数据类型多少节点以下会采用去指针的紧凑存储格式。
# list数据类型节点值大小小于多少字节会采用紧凑存储格式。
list-max-ziplist-entries 512
list-max-ziplist-value 64

# Sets have a special encoding in just one case: when a set is composed
# of just strings that happen to be integers in radix 10 in the range
# of 64 bit signed integers.
# The following configuration setting sets the limit in the size of the
# set in order to use this special memory saving encoding.
# set数据类型内部数据如果全部是数值型，且包含多少节点以下会采用紧凑格式存储。
set-max-intset-entries 512

# Similarly to hashes and lists, sorted sets are also specially encoded in
# order to save a lot of space. This encoding is only used when the length and
# elements of a sorted set are below the following limits:

# zsort数据类型多少节点以下会采用去指针的紧凑存储格式。
# zsort数据类型节点值大小小于多少字节会采用紧凑存储格式。
zset-max-ziplist-entries 128
zset-max-ziplist-value 64

# HyperLogLog sparse representation bytes limit. The limit includes the
# 16 bytes header. When an HyperLogLog using the sparse representation crosses
# this limit, it is converted into the dense representation.
#
# A value greater than 16000 is totally useless, since at that point the
# dense representation is more memory efficient.
#
# The suggested value is ~ 3000 in order to have the benefits of
# the space efficient encoding without slowing down too much PFADD,
# which is O(N) with the sparse encoding. The value can be raised to
# ~ 10000 when CPU is not a concern, but space is, and the data set is
# composed of many HyperLogLogs with cardinality in the 0 - 15000 range.
hll-sparse-max-bytes 3000

# Active rehashing uses 1 millisecond every 100 milliseconds of CPU time in
# order to help rehashing the main Redis hash table (the one mapping top-level
# keys to values). The hash table implementation Redis uses (see dict.c)
# performs a lazy rehashing: the more operation you run into a hash table
# that is rehashing, the more rehashing &quot;steps&quot; are performed, so if the
# server is idle the rehashing is never complete and some more memory is used
# by the hash table.
#
# The default is to use this millisecond 10 times every second in order to
# actively rehash the main dictionaries, freeing memory when possible.
#
# If unsure:
# use &quot;activerehashing no&quot; if you have hard latency requirements and it is
# not a good thing in your environment that Redis can reply from time to time
# to queries with 2 milliseconds delay.
#
# use &quot;activerehashing yes&quot; if you don't have such hard requirements but
# want to free memory asap when possible.

# Redis将在每100毫秒时使用1毫秒的CPU时间来对redis的hash表进行重新hash，可以降低内存的使用
# 当你的使用场景中，有非常严格的实时性需要，不能够接受Redis时不时的对请求有2毫秒的延迟的话，把这项配置为no。
# 如果没有这么严格的实时性要求，可以设置为yes，以便能够尽可能快的释放内存
activerehashing yes

# The client output buffer limits can be used to force disconnection of clients
# that are not reading data from the server fast enough for some reason (a
# common reason is that a Pub/Sub client can't consume messages as fast as the
# publisher can produce them).
#
# The limit can be set differently for the three different classes of clients:
#
# normal -&amp;gt; normal clients including MONITOR clients
# slave  -&amp;gt; slave clients
# pubsub -&amp;gt; clients subscribed to at least one pubsub channel or pattern
#
# The syntax of every client-output-buffer-limit directive is the following:
#
# client-output-buffer-limit &lt;/span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;class&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;hard &lt;/span&gt;&lt;span&gt;limit&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;soft &lt;/span&gt;&lt;span&gt;limit&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;soft &lt;/span&gt;&lt;span&gt;seconds&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;span&gt;
#
# A client is immediately disconnected once the hard limit is reached, or if
# the soft limit is reached and remains reached for the specified number of
# seconds (continuously).
# So for instance if the hard limit is 32 megabytes and the soft limit is
# 16 megabytes / 10 seconds, the client will get disconnected immediately
# if the size of the output buffers reach 32 megabytes, but will also get
# disconnected if the client reaches 16 megabytes and continuously overcomes
# the limit for 10 seconds.
#
# By default normal clients are not limited because they don't receive data
# without asking (in a push way), but just after a request, so only
# asynchronous clients may create a scenario where data is requested faster
# than it can read.
#
# Instead there is a default limit for pubsub and slave clients, since
# subscribers and slaves receive data in a push fashion.
#
# Both the hard or the soft limit can be disabled by setting them to zero.
client-output-buffer-limit normal 0 0 0
client-output-buffer-limit slave 256mb 64mb 60
client-output-buffer-limit pubsub 32mb 8mb 60

# Redis calls an internal function to perform many background tasks, like
# closing connections of clients in timeout, purging expired keys that are
# never requested, and so forth.
#
# Not all tasks are performed with the same frequency, but Redis checks for
# tasks to perform according to the specified &quot;hz&quot; value.
#
# By default &quot;hz&quot; is set to 10. Raising the value will use more CPU when
# Redis is idle, but at the same time will make Redis more responsive when
# there are many keys expiring at the same time, and timeouts may be
# handled with more precision.
#
# The range is between 1 and 500, however a value over 100 is usually not
# a good idea. Most users should use the default of 10 and raise this up to
# 100 only in environments where very low latency is required.
hz 10

# When a child rewrites the AOF file, if the following option is enabled
# the file will be fsync-ed every 32 MB of data generated. This is useful
# in order to commit the file to the disk more incrementally and avoid
# big latency spikes.
# aof rewrite过程中,是否采取增量文件同步策略,默认为“yes”。 rewrite过程中,每32M数据进行一次文件同步,这样可以减少aof大文件写入对磁盘的操作次数
aof-rewrite-incremental-fsync yes


# redis数据存储
redis的存储分为内存存储、磁盘存储和log文件三部分，配置文件中有三个参数对其进行配置。
save seconds updates，save配置，指出在多长时间内，有多少次更新操作，就将数据同步到数据文件。可多个条件配合，默认配置了三个条件。
appendonly yes/no ，appendonly配置，指出是否在每次更新操作后进行日志记录，如果不开启，可能会在断电时导致一段时间内的数据丢失。因为redis本身同步数据文件是按上面的save条件来同步的，所以有的数据会在一段时间内只存在于内存中。
appendfsync no/always/everysec ，appendfsync配置，no表示等操作系统进行数据缓存同步到磁盘，always表示每次更新操作后手动调用fsync()将数据写到磁盘，everysec表示每秒同步一次。&lt;/span&gt;
&lt;/pre&gt;</description>
<pubDate>Sat, 27 Apr 2019 15:05:00 +0000</pubDate>
<dc:creator>请叫我头头哥</dc:creator>
<og:description>Redis-Sentinel是官方推荐的高可用解决方案，当redis在做master-slave的高可用方案时，假如master宕机了，redis本身（以及其很多客户端）都没有实现自动进行主备切换，而</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/toutou/p/sentinel.html</dc:identifier>
</item>
<item>
<title>Android缓存机制——LruCache - Ivo-oo</title>
<link>http://www.cnblogs.com/ivoo/p/10744558.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/ivoo/p/10744558.html</guid>
<description>&lt;h2&gt;概述&lt;/h2&gt;
&lt;p&gt;LruCache的核心原理就是对LinkedHashMap的有效利用，它的内部存在一个LinkedHashMap成员变量，值得注意的4个方法：构造方法、get、put、trimToSize&lt;/p&gt;
&lt;p&gt;LRU(Least Recently Used)缓存算法便应运而生，LRU是最近最少使用的算法，它的核心思想是当缓存满时，会优先淘汰那些最近最少使用的缓存对象。采用LRU算法的缓存有两种：LrhCache和DisLruCache，分别用于实现内存缓存和硬盘缓存，其核心思想都是LRU缓存算法。&lt;/p&gt;

&lt;h2&gt;LRU原理&lt;/h2&gt;
&lt;p&gt;LruCache的核心思想很好理解，就是要维护一个缓存对象列表，其中对象列表的排列方式是按照访问顺序实现的，即一直没访问的对象，将放在队尾，即将被淘汰。而最近访问的对象将放在队头，最后被淘汰。&lt;/p&gt;
&lt;p&gt;LruCache 其实使用了 LinkedHashMap 双向链表结构，现在分析下 LinkedHashMap 使用方法。&lt;/p&gt;
&lt;h3&gt;1.构造方法：&lt;/h3&gt;

&lt;div class=&quot;cnblogs_code&quot; readability=&quot;36&quot;&gt;
&lt;pre&gt;
&lt;span&gt;public&lt;/span&gt; LinkedHashMap(&lt;span&gt;int&lt;/span&gt;&lt;span&gt; initialCapacity,
    &lt;/span&gt;&lt;span&gt;float&lt;/span&gt;&lt;span&gt; loadFactor,
    &lt;/span&gt;&lt;span&gt;boolean&lt;/span&gt;&lt;span&gt; accessOrder) {
    &lt;/span&gt;&lt;span&gt;super&lt;/span&gt;&lt;span&gt;(initialCapacity, loadFactor);
    &lt;/span&gt;&lt;span&gt;this&lt;/span&gt;.accessOrder =&lt;span&gt; accessOrder;
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt; 当 accessOrder 为 true 时，这个集合的元素顺序就会是访问顺序，也就是访问了之后就会将这个元素放到集合的最后面。&lt;/p&gt;
&lt;p&gt; 例如：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;42&quot;&gt;
&lt;pre&gt;
LinkedHashMap &amp;lt; Integer, Integer &amp;gt; map = &lt;span&gt;new&lt;/span&gt; LinkedHashMap &amp;lt; &amp;gt; (0, 0.75f, &lt;span&gt;true&lt;/span&gt;&lt;span&gt;);
map.put(&lt;/span&gt;0, 0&lt;span&gt;);
map.put(&lt;/span&gt;1, 1&lt;span&gt;);
map.put(&lt;/span&gt;2, 2&lt;span&gt;);
map.put(&lt;/span&gt;3, 3&lt;span&gt;);
map.get(&lt;/span&gt;1&lt;span&gt;);
map.get(&lt;/span&gt;2&lt;span&gt;);

&lt;/span&gt;&lt;span&gt;for&lt;/span&gt; (Map.Entry &amp;lt; Integer, Integer &amp;gt;&lt;span&gt; entry: map.entrySet()) {
    System.out.println(entry.getKey() &lt;/span&gt;+ &quot;:&quot; +&lt;span&gt; entry.getValue());

}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;输出结果：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot;&gt;
&lt;pre&gt;
0:0
3:3
1:1
2:2
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;下面我们在LruCache源码中具体看看，怎么应用LinkedHashMap来实现缓存的添加，获得和删除的：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;40&quot;&gt;
&lt;pre&gt;
&lt;span&gt;/**&lt;/span&gt;&lt;span&gt;
     * &lt;/span&gt;&lt;span&gt;@param&lt;/span&gt;&lt;span&gt; maxSize for caches that do not override {&lt;/span&gt;&lt;span&gt;@link&lt;/span&gt;&lt;span&gt; #sizeOf}, this is
     *     the maximum number of entries in the cache. For all other caches,
     *     this is the maximum sum of the sizes of the entries in this cache.
     &lt;/span&gt;&lt;span&gt;*/&lt;/span&gt;
    &lt;span&gt;public&lt;/span&gt; LruCache(&lt;span&gt;int&lt;/span&gt;&lt;span&gt; maxSize) {
        &lt;/span&gt;&lt;span&gt;if&lt;/span&gt; (maxSize &amp;lt;= 0&lt;span&gt;) {
            &lt;/span&gt;&lt;span&gt;throw&lt;/span&gt; &lt;span&gt;new&lt;/span&gt; IllegalArgumentException(&quot;maxSize &amp;lt;= 0&quot;&lt;span&gt;);
        }
        &lt;/span&gt;&lt;span&gt;this&lt;/span&gt;.maxSize =&lt;span&gt; maxSize;
        &lt;/span&gt;&lt;span&gt;this&lt;/span&gt;.map = &lt;span&gt;new&lt;/span&gt; LinkedHashMap&amp;lt;K, V&amp;gt;(0, 0.75f, &lt;span&gt;true&lt;/span&gt;&lt;span&gt;);//accessOrder被设置为true
    }&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;从LruCache的构造函数中可以看到正是用了LinkedHashMap的访问顺序。&lt;/p&gt;
&lt;h3&gt;&lt;strong&gt;2.put()方法&lt;/strong&gt;&lt;/h3&gt;

&lt;div class=&quot;cnblogs_code&quot; readability=&quot;42&quot;&gt;
&lt;pre&gt;
&lt;span&gt;/**&lt;/span&gt;&lt;span&gt;
     * Caches {&lt;/span&gt;&lt;span&gt;@code&lt;/span&gt;&lt;span&gt; value} for {&lt;/span&gt;&lt;span&gt;@code&lt;/span&gt;&lt;span&gt; key}. The value is moved to the head of
     * the queue.
     *
     * &lt;/span&gt;&lt;span&gt;@return&lt;/span&gt;&lt;span&gt; the previous value mapped by {&lt;/span&gt;&lt;span&gt;@code&lt;/span&gt;&lt;span&gt; key}.
     &lt;/span&gt;&lt;span&gt;*/&lt;/span&gt;
    &lt;span&gt;public&lt;/span&gt; &lt;span&gt;final&lt;/span&gt;&lt;span&gt; V put(K key, V value) {
        &lt;/span&gt;&lt;span&gt;if&lt;/span&gt; (key == &lt;span&gt;null&lt;/span&gt; || value == &lt;span&gt;null&lt;/span&gt;&lt;span&gt;) {//判空，不可为空
            &lt;/span&gt;&lt;span&gt;throw&lt;/span&gt; &lt;span&gt;new&lt;/span&gt; NullPointerException(&quot;key == null || value == null&quot;&lt;span&gt;);
        }

        V previous;
        &lt;/span&gt;&lt;span&gt;synchronized&lt;/span&gt; (&lt;span&gt;this&lt;/span&gt;&lt;span&gt;) {
            putCount&lt;/span&gt;++&lt;span&gt;;//插入缓存对象加1
            size &lt;/span&gt;+=&lt;span&gt; safeSizeOf(key, value);//增加已有缓存的大小
            previous &lt;/span&gt;=&lt;span&gt; map.put(key, value);//向map中加入缓存对象
            &lt;/span&gt;&lt;span&gt;if&lt;/span&gt; (previous != &lt;span&gt;null&lt;/span&gt;&lt;span&gt;) {//如果已有缓存对象，则缓存大小恢复到之前
                size &lt;/span&gt;-=&lt;span&gt; safeSizeOf(key, previous);
            }
        }

        &lt;/span&gt;&lt;span&gt;if&lt;/span&gt; (previous != &lt;span&gt;null&lt;/span&gt;&lt;span&gt;) {//entryRemoved()是个空方法，可以自行实现
            entryRemoved(&lt;/span&gt;&lt;span&gt;false&lt;/span&gt;&lt;span&gt;, key, previous, value);
        }

        trimToSize(maxSize);//调整缓存大小(关键方法)
        &lt;/span&gt;&lt;span&gt;return&lt;/span&gt;&lt;span&gt; previous;
    }&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt; 可以看到put()方法重要的就是在添加过缓存对象后，调用 trimToSize()方法来保证内存不超过maxSize&lt;/p&gt;
&lt;h3&gt;3.trimToSize方法&lt;/h3&gt;
&lt;p&gt;再看一下trimToSize()方法：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;40&quot;&gt;
&lt;pre&gt;
 &lt;span&gt;/**&lt;/span&gt;&lt;span&gt;
     * Remove the eldest entries until the total of remaining entries is at or
     * below the requested size.
     *
     * &lt;/span&gt;&lt;span&gt;@param&lt;/span&gt;&lt;span&gt; maxSize the maximum size of the cache before returning. May be -1
     *            to evict even 0-sized elements.
     &lt;/span&gt;&lt;span&gt;*/&lt;/span&gt;
    &lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; trimToSize(&lt;span&gt;int&lt;/span&gt;&lt;span&gt; maxSize) {
        &lt;/span&gt;&lt;span&gt;while&lt;/span&gt; (&lt;span&gt;true&lt;/span&gt;&lt;span&gt;) {//死循环
            K key;
            V value;
            &lt;/span&gt;&lt;span&gt;synchronized&lt;/span&gt; (&lt;span&gt;this&lt;/span&gt;&lt;span&gt;) {&lt;br/&gt;　　　　　　　　   //如果map为空并且缓存size不等于0或者缓存size小于0，抛出异常
                &lt;/span&gt;&lt;span&gt;if&lt;/span&gt; (size &amp;lt; 0 || (map.isEmpty() &amp;amp;&amp;amp; size != 0&lt;span&gt;)) {
                    &lt;/span&gt;&lt;span&gt;throw&lt;/span&gt; &lt;span&gt;new&lt;/span&gt;&lt;span&gt; IllegalStateException(getClass().getName()
                            &lt;/span&gt;+ &quot;.sizeOf() is reporting inconsistent results!&quot;&lt;span&gt;);
                }
　　　　　　　　　　//如果缓存大小size小于最大缓存，或者map为空，不需要再删除缓存对象，跳出循环
                &lt;/span&gt;&lt;span&gt;if&lt;/span&gt; (size &amp;lt;=&lt;span&gt; maxSize) {
                    &lt;/span&gt;&lt;span&gt;break&lt;/span&gt;&lt;span&gt;;
                }
　　　　　　　　　　// 取出 map 中最老的映射
                Map.Entry&lt;/span&gt;&amp;lt;K, V&amp;gt; toEvict =&lt;span&gt; map.eldest();
                &lt;/span&gt;&lt;span&gt;if&lt;/span&gt; (toEvict == &lt;span&gt;null&lt;/span&gt;&lt;span&gt;) {
                    &lt;/span&gt;&lt;span&gt;break&lt;/span&gt;&lt;span&gt;;
                }

                key &lt;/span&gt;=&lt;span&gt; toEvict.getKey();
                value &lt;/span&gt;=&lt;span&gt; toEvict.getValue();
                map.remove(key);
                size &lt;/span&gt;-=&lt;span&gt; safeSizeOf(key, value);
                evictionCount&lt;/span&gt;++&lt;span&gt;;
            }

            entryRemoved(&lt;/span&gt;&lt;span&gt;true&lt;/span&gt;, key, value, &lt;span&gt;null&lt;/span&gt;&lt;span&gt;);
        }
    }&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;trimToSize()方法不断地删除LinkedHashMap中队头的元素，即近期最少访问的，直到缓存大小小于最大值。&lt;/p&gt;
&lt;h3&gt;4. get方法&lt;/h3&gt;
&lt;p&gt;当调用LruCache的get()方法获取集合中的缓存对象时，就代表访问了一次该元素，将会更新队列，保持整个队列是按照访问顺序排序。这个更新过程就是在LinkedHashMap中的get()方法中完成的。&lt;/p&gt;
&lt;p&gt;接着看LruCache的get()方法&lt;/p&gt;

&lt;div class=&quot;cnblogs_code&quot; readability=&quot;36&quot;&gt;
&lt;pre&gt;
 &lt;span&gt;/**&lt;/span&gt;&lt;span&gt;
     * Returns the value for {&lt;/span&gt;&lt;span&gt;@code&lt;/span&gt;&lt;span&gt; key} if it exists in the cache or can be
     * created by {&lt;/span&gt;&lt;span&gt;@code&lt;/span&gt;&lt;span&gt; #create}. If a value was returned, it is moved to the
     * head of the queue. This returns null if a value is not cached and cannot
     * be created.
     &lt;/span&gt;&lt;span&gt;*/&lt;/span&gt;
    &lt;span&gt;public&lt;/span&gt; &lt;span&gt;final&lt;/span&gt;&lt;span&gt; V get(K key) {
        &lt;/span&gt;&lt;span&gt;if&lt;/span&gt; (key == &lt;span&gt;null&lt;/span&gt;&lt;span&gt;) {//key不能为空
            &lt;/span&gt;&lt;span&gt;throw&lt;/span&gt; &lt;span&gt;new&lt;/span&gt; NullPointerException(&quot;key == null&quot;&lt;span&gt;);
        }

        V mapValue;
        &lt;/span&gt;&lt;span&gt;synchronized&lt;/span&gt; (&lt;span&gt;this&lt;/span&gt;&lt;span&gt;) {&lt;br/&gt;　　　　　　　　/获取对应的缓存对象 
            mapValue &lt;/span&gt;=&lt;span&gt; map.get(key);
            &lt;/span&gt;&lt;span&gt;if&lt;/span&gt; (mapValue != &lt;span&gt;null&lt;/span&gt;&lt;span&gt;) {
                hitCount&lt;/span&gt;++&lt;span&gt;;
                &lt;/span&gt;&lt;span&gt;return&lt;/span&gt;&lt;span&gt; mapValue;
            }
            missCount&lt;/span&gt;++&lt;span&gt;;
        }&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt; 看到LruCache的get方法实际是调用了LinkedHashMap的get方法：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;35&quot;&gt;
&lt;pre&gt;
&lt;span&gt;public&lt;/span&gt;&lt;span&gt; V get(Object key) {
        LinkedHashMapEntry&lt;/span&gt;&amp;lt;K,V&amp;gt; e = (LinkedHashMapEntry&amp;lt;K,V&amp;gt;&lt;span&gt;)getEntry(key);
        &lt;/span&gt;&lt;span&gt;if&lt;/span&gt; (e == &lt;span&gt;null&lt;/span&gt;&lt;span&gt;)
            &lt;/span&gt;&lt;span&gt;return&lt;/span&gt; &lt;span&gt;null&lt;/span&gt;&lt;span&gt;;
        e.recordAccess(&lt;/span&gt;&lt;span&gt;this&lt;/span&gt;&lt;span&gt;);//实现排序的关键
        &lt;/span&gt;&lt;span&gt;return&lt;/span&gt;&lt;span&gt; e.value;
    }&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt; 再接着看LinkedHashMapEntry的recordAccess方法：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;40&quot;&gt;
&lt;pre&gt;
　　　　 &lt;span&gt;/**&lt;/span&gt;&lt;span&gt;
         * This method is invoked by the superclass whenever the value
         * of a pre-existing entry is read by Map.get or modified by Map.set.
         * If the enclosing Map is access-ordered, it moves the entry
         * to the end of the list; otherwise, it does nothing.
         &lt;/span&gt;&lt;span&gt;*/&lt;/span&gt;
        &lt;span&gt;void&lt;/span&gt; recordAccess(HashMap&amp;lt;K,V&amp;gt;&lt;span&gt; m) {
            LinkedHashMap&lt;/span&gt;&amp;lt;K,V&amp;gt; lm = (LinkedHashMap&amp;lt;K,V&amp;gt;&lt;span&gt;)m;
            &lt;/span&gt;&lt;span&gt;if&lt;/span&gt;&lt;span&gt; (lm.accessOrder) {//判断是否是访问顺序
                lm.modCount&lt;/span&gt;++&lt;span&gt;;
                remove();//删除此元素
                addBefore(lm.header);//将此元素移到队尾
            }
        }&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;recordAccess方法的作用是如果accessOrder为true，把已存在的entry在调用get读取或者set编辑后移到队尾，否则不做任何操作。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;也就是说： 这个方法的作用就是将刚访问过的元素放到集合的最后一位&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;strong&gt;5.总结：&lt;/strong&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;LruCache的核心原理就是对LinkedHashMap 对象的有效利用。在构造方法中设置maxSize并将accessOrder设为true，执行get后会将访问元素放到队列尾，put操作后则会调用trimToSize维护LinkedHashMap的大小不大于maxSize。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt; &lt;/strong&gt;&lt;/p&gt;
&lt;p&gt; 参考：&lt;a href=&quot;https://juejin.im/post/5b5d4e2d6fb9a04fc226c09f&quot;&gt;https://juejin.im/post/5b5d4e2d6fb9a04fc226c09f&lt;/a&gt;  ； &lt;a href=&quot;https://www.cnblogs.com/ganchuanpu/p/8908264.html&quot;&gt;https://www.cnblogs.com/ganchuanpu/p/8908264.html&lt;/a&gt;&lt;/p&gt;

</description>
<pubDate>Sat, 27 Apr 2019 15:03:00 +0000</pubDate>
<dc:creator>Ivo-oo</dc:creator>
<og:description>概述 LruCache的核心原理就是对LinkedHashMap的有效利用，它的内部存在一个LinkedHashMap成员变量，值得注意的4个方法：构造方法、get、put、trimToSize LR</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/ivoo/p/10744558.html</dc:identifier>
</item>
<item>
<title>promise原理—一步一步实现一个promise - 魑魅魍魉_killer</title>
<link>http://www.cnblogs.com/chenlei987/p/10780777.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/chenlei987/p/10780777.html</guid>
<description>&lt;p&gt;一个promise的当前状态只能是pending、fulfilled和rejected三种之一。状态改变只能是pending到fulfilled或者pending到rejected。状态改变不可逆。&lt;/p&gt;
&lt;p&gt;支持链式调用。&lt;/p&gt;
&lt;p&gt;(1) 原型方法&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;Promise.prototype.then = function() {}
Promise.prototype.catch = function() {}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;(2) 静态方法&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;Promise.resolve = function() {}
Promise.reject = function() {}
Promise.all = function() {}
Promise.race = function() {}
//...&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;Promise的优缺点&lt;br/&gt;优点：&lt;br/&gt;状态不可改变&lt;br/&gt;链式调用解决回调地狱问题，让代码更清晰，更易维护。&lt;br/&gt;缺点：&lt;br/&gt;不能在执行中中止&lt;br/&gt;在pending中不能查看异步到什么状态了。&lt;/p&gt;
&lt;p&gt;promise中止&lt;br/&gt;&lt;a href=&quot;https://segmentfault.com/a/1190000007598894&quot; class=&quot;uri&quot;&gt;https://segmentfault.com/a/1190000007598894&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;promise源码实现&lt;br/&gt;首先我们先看看我们怎么使用Promise的&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;new Promise(function (resolve, reject) {
    setTimeout(() =&amp;gt; {
        // resolve(&quot;异步成功拉&quot;);
        reject(&quot;异步失败啦&quot;);
    }, 1000);
}).then(
function (data) {
    console.log(data);

    /* then里面可以是同步的代码，也可以是异步的promise */
    // return new Promise(function (resolve, reject){
    //     setTimeout(() =&amp;gt; {
    //         resolve(&quot;第一个then里面的异步&quot;);
    //     }, 1000);
    // });

    return &quot;链式调用第一个then的返回值&quot;;
},
function (reason) {
    console.log(&quot;第一个then&quot; + reason);
    return &quot;第一个then reject 后的 失败 reason&quot;
}
)&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;于是我们来实现一个简单的Promise构造函数&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;function Promise(executor) {
    var _this = this;
    this.data = undefined;//数据
    this.status = &quot;pending&quot;;//状态

    this.onResolvedCallback = [] // Promise resolve时的回调函数集，因为在Promise结束之前有可能有多个回调添加到它上面
    this.onRejectedCallback = [] // Promise reject时的回调函数集，因为在Promise结束之前有可能有多个回调添加到它上面

   var resolve = function (data){
        if (_this.status === &quot;pending&quot;){
            _this.status = &quot;resolved&quot;;
            _this.data = data;
            for(var i = 0; i &amp;lt; _this.onResolvedCallback.length; i++) {
                _this.onResolvedCallback[i](data)
            }
        }
    }

    var reject = function (errReason) {
        if (_this.status === &quot;pending&quot;){
            _this.status = &quot;rejected&quot;;
            _this.data = errReason;
            for(var i = 0; i &amp;lt; _this.onRejectedCallback.length; i++) {
                _this.onRejectedCallback[i](errReason)
            }
        }
    }
    try{
        executor(resolve, reject);
    } catch(e){
        reject(e);
    }
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;由上面的代码可以看出 executor一般来说应该是一个异步，等待其执行完后 成功或者失败，然后执行其回调resolve或者reject。 然后在resolve或者reject里面执行then里面注册的回调函数。所以then函数应该是一个注册用户回调 到 onResolvedCallback或者onRejectedCallback里的过程。&lt;br/&gt;then的实现&lt;br/&gt;在实现的then函数之前，我们来明确一下then函数要做那几件事情。&lt;br/&gt;1、注册用户回调到 _this.onResolvedCallback 或者 _this.onRejectedCallback&lt;br/&gt;2、支持链式调用， 其实就是then函数执行完后应该返回一个promise对象，并且根据promise A+标准，这个promise应该是一个新的promise。&lt;br/&gt;3、处理三种状态， executor可能是一个同步的函数也有可能是一个异步的函数，所以在执行then的时候 _this.status 可能是pending（executor是异步的情况），_this.status 可能是resolve/reject （executor是同步的情况）&lt;br/&gt;而status是pending的情况下是一个注册的过程，也就是将回调存起来，等待status变成resolve或者reject再执行回调。&lt;br/&gt;而status是resolve/reject的情况下就直接执行对调了。&lt;br/&gt;上面这段解释建议边看下面的代码边理解上面这段话&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;
//onResolved  onRejected 为调用者传进来的 成功和失败的回掉
Promise.prototype.then = function (onResolved, onRejected){

    var _this = this
    var promise2;
    // 根据标准，如果then的参数不是function，则我们需要忽略它，此处以如下方式处理
    onResolved = typeof onResolved === 'function' ? onResolved : function(value) {}
    onRejected = typeof onRejected === 'function' ? onRejected : function(reason) {}

    //如果上面的executor是一个异步的，执行then的时候 status一定是pending
    if (this.status === &quot;pending&quot;){
        //生成一个新的promise
        promise2 = new Promise(function(resolve, reject) {
            //将调用者的回调包装后注册进promise的回调队列
            _this.onResolvedCallback.push(function (value){
                //这里的value是在onResolvedCallback里面的函数执行时传的
                try {
                    var x = onResolved(_this.data)
                    if (x instanceof Promise) {
                        //then里面的回调如果是异步的promise，则等待异步执行完后，再进入promise2的then中注册的回调
                        x.then(resolve, reject);
                    }
                    else{
                        //如果是同步的，直接进入promise2的then中注册的回调
                        resolve(x);
                    }
                } catch (e) {
                    reject(e)
                }
            });

            _this.onRejectedCallback.push(function (reason) {
                try {
                    var x = onRejected(_this.data)
                    if (x instanceof Promise) {
                      x.then(resolve, reject);
                    }
                    else{
                        reject(x);
                    }
                } catch (e) {
                    reject(e)
                }
            });
        })
        return promise2;
    }

    //如果executor是同步的， 则执行then的时候 status为 resolved或者rejected
    if (_this.status === 'resolved') {
        // 如果promise1(此处即为this/_this)的状态已经确定并且是resolved，我们调用onResolved
        // 因为考虑到有可能throw，所以我们将其包在try/catch块里
        return promise2 = new Promise(function(resolve, reject) {
          try {
            var x = onResolved(_this.data)
            if (x instanceof Promise) { // 如果onResolved的返回值是一个Promise对象，直接取它的结果做为promise2的结果
              x.then(resolve, reject)
            }
            resolve(x) // 否则，以它的返回值做为promise2的结果
          } catch (e) {
            reject(e) // 如果出错，以捕获到的错误做为promise2的结果
          }
        })
      }
    
      // 此处与前一个if块的逻辑几乎相同，区别在于所调用的是onRejected函数，就不再做过多解释
      if (_this.status === 'rejected') {
        return promise2 = new Promise(function(resolve, reject) {
          try {
            var x = onRejected(_this.data)
            if (x instanceof Promise) {
              x.then(resolve, reject)
            }
          } catch (e) {
            reject(e)
          }
        })
    }
}  &lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;看完代码后我继续来解释promise2中的处理过程,现在需要想的是如何在 promise2中如何执行完后如何将正确的数据交给下一个then。&lt;br/&gt;所以需要判断x（onResolved或者onRejected执行的结果）是一个什么值，如果是一个普通的值则直接调用promise2的resolve或者reject，但是如果x是一个promise对象，则我们需要等待这个promise对象状态变成reosolve或者reject，也就是等待这个promise处理完异步任务（需要用到promise，里面一般都是异步任务），所以调用x.then(resove,reject)，这里是直接将promise2的resolve/reject作为回调的。也就是等待x这个promise对象执行完后，交给promise2的then里面的回调，衔接整个链式的过程。&lt;/p&gt;
&lt;h3 id=&quot;catch的实现&quot;&gt;catch的实现&lt;/h3&gt;
&lt;pre&gt;
&lt;code&gt;Promise.prototype.catch = function (onRejected) {
    return this.then(null, onRejected)
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;到此，promise的整个原理就算大部分完成了，其实理解起来并不是那么难，对不对。&lt;/p&gt;
&lt;p&gt;确保x的处理，能与不同的promise进行交互&lt;br/&gt;根据promise A+规范，上面在promise2中处理x并将处理值交给 promise2.then的回调的整个过程并没有考虑到''不符合promise规范的对象并带有then方法的情况''，promise A+规范希望能以最保险的方式将x传递到promise2.then，即使x是一个不遵循promise规范，但是带有then的对象也能够完美的处理。&lt;br/&gt;所以需要对x更进一步的处理，然后将数据交给下一步&lt;/p&gt;
&lt;p&gt;/&lt;em&gt;即我们要把onResolved/onRejected的返回值，x，&lt;br/&gt;当成一个可能是Promise的对象，也即标准里所说的thenable，&lt;br/&gt;并以最保险的方式调用x上的then方法，如果大家都按照标准实现，&lt;br/&gt;那么不同的Promise之间就可以交互了。而标准为了保险起见，&lt;br/&gt;即使x返回了一个带有then属性但并不遵循Promise标准的对象&lt;/em&gt;/&lt;br/&gt;递归解决，只要x带有then方法，就会像剥洋葱一样层层的剥开，直到x是一个非类似promise的这种处理异步的对象，非thennable对象。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;function resolvePromise(promise2, x, resolve, reject) {
    var then
    var thenCalledOrThrow = false
  
    if (promise2 === x) { // 对应标准2.3.1节
      return reject(new TypeError('Chaining cycle detected for promise!'))
    }
  
    if (x instanceof Promise) { // 对应标准2.3.2节
      // 如果x的状态还没有确定，那么它是有可能被一个thenable决定最终状态和值的
      // 所以这里需要做一下处理，而不能一概的以为它会被一个“正常”的值resolve
      if (x.status === 'pending') {
        x.then(function(value) {
          resolvePromise(promise2, value, resolve, reject)
        }, reject)
      } else { // 但如果这个Promise的状态已经确定了，那么它肯定有一个“正常”的值，而不是一个thenable，所以这里直接取它的状态
        x.then(resolve, reject)
      }
      return
    }
  
    if ((x !== null) &amp;amp;&amp;amp; ((typeof x === 'object') || (typeof x === 'function'))) { // 2.3.3
      try {
  
        // 2.3.3.1 因为x.then有可能是一个getter，这种情况下多次读取就有可能产生副作用
        // 即要判断它的类型，又要调用它，这就是两次读取
        then = x.then 
        if (typeof then === 'function') { // 2.3.3.3
          then.call(x, function rs(y) { // 2.3.3.3.1
            if (thenCalledOrThrow) return // 2.3.3.3.3 即这三处谁选执行就以谁的结果为准
            thenCalledOrThrow = true
            return resolvePromise(promise2, y, resolve, reject) // 2.3.3.3.1
          }, function rj(r) { // 2.3.3.3.2
            if (thenCalledOrThrow) return // 2.3.3.3.3 即这三处谁选执行就以谁的结果为准
            thenCalledOrThrow = true
            return reject(r)
          })
        } else { // 2.3.3.4
          resolve(x)
        }
      } catch (e) { // 2.3.3.2
        if (thenCalledOrThrow) return // 2.3.3.3.3 即这三处谁选执行就以谁的结果为准
        thenCalledOrThrow = true
        return reject(e)
      }
    } else { // 2.3.4
      resolve(x)
    }
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;将promise2的处理过程改一下，三种情况都要改。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;promise2 = new Promise(function(resolve, reject) {
            //将调用者的回调包装后注册进promise的回调队列
            _this.onResolvedCallback.push(function (value){
                //这里的value是在onResolvedCallback里面的函数执行时传的
                try {
                    var x = onResolved(value);
                    //解决调用者定义的onResolved的返回值 x 是非规范的Promise对象且带有then方法的情况
                    resolvePromise(promise2, x, resolve, reject);
                } catch (e) {
                    reject(e)
                }
            });

            _this.onRejectedCallback.push(function (reason) {
                try {
                    var x = onRejected(reason)
                    resolvePromise(promise2, x, resolve, reject);
                } catch (e) {
                    reject(e)
                }
            });
        })
        return promise2;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;测试一下&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;//测试不遵守promise的对象，且带有then方法
var notPromise = function () {
    //
}

notPromise.prototype.then = function (onResolved, onRejected) {
    setTimeout(function () {
        onResolved(&quot;不遵守promise规范的对象&quot;)
    }, 1000)
}

//测试
new Promise(function (resolve, rejected) {
    setTimeout(function () {
        resolve(&quot;异步开始了&quot;);
    },1000)
}).then(function (data) {
    console.log(data);
    //下面的返回可以是 promise  也可以是普通的值， 还可以是不准寻promise规范的对象但带有then方法（在resolve都给与了支持）
    //普通值和promise就不测试了。
    //测试一下遵循promise的对象， 且带有then方法
    return new notPromise();
}).then(function (data) {
    //在then里面 会把上一个传递下来的值（new notPromise()）不断的调它的then方法，知道确定没有then可以调用了，就递交到下一个then
    console.log(data); // 这里的 data 不是 （new notPromise()）而是它的then方法返回的。
})&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;值穿透问题&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;new Promise(resolve=&amp;gt;resolve(8))
  .then()
  .catch()
  .then(function(value) {
    alert(value)
  })&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;跟下面这段代码的行为是一样的&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;new Promise(resolve=&amp;gt;resolve(8))
  .then(function(value){
    return value
  })
  .catch(function(reason){
    throw reason
  })
  .then(function(value) {
    alert(value)
  })&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;不传回调，则使用默认回调，所以在默认回调上改改，让它将值传递下去&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;onResolved = typeof onResolved === 'function' ? onResolved : function(value) {return value}
onRejected = typeof onRejected === 'function' ? onRejected : function(reason) {throw reason}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;promise中止问题（面试题哦）&lt;br/&gt;在一些场景下，我们可能会遇到一个较长的Promise链式调用，在某一步中出现的错误让我们完全没有必要去运行链式调用后面所有的代码，类似下面这样（此处略去了then/catch里的函数）：&lt;br/&gt;先给出结果&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;Promise.cancel = Promise.stop = function() {
    return new Promise(function(){})
}
//下面我们来尝试一下，如果遇到错误，则不会执行alert(1)
new Promise(function(resolve, reject) {
    resolve(42)
  })
    .then(function(value) {
        var isErr = true;  //尝试更改成 true 或者 false  看alert(1);是否执行
        if (isErr){
            // &quot;Big ERROR!!!&quot;
            return Promise.stop()
        }
      
    })
    //值的穿透
    .catch()
    .then()
    .then()
    .catch()
    .then(function () {
        alert(1);
    })&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;return new Promise(function(){})这段话就意味着x是一个promise对象， 则一定会走 x。then(resolve,reject) 交给promise2的then。但是这里new Promise(function(){}根本就没有resolve或者reject，所以它的状态一直为pending， 所以永远不会执行 x.then(resolve,reject)里面的resolve/reject，那么状态就传递不下去，链式就算是断开了。&lt;/p&gt;
&lt;p&gt;promise链上没有catch等错误处理回调，怎么看到错误&lt;br/&gt;没有错误处理函数，就给个默认的错误处理&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;function reject(reason) {
        setTimeout(function() {
          if (_this.status === 'pending') {
            _this.status = 'rejected'
            _this.data = reason
            if (_this.onRejectedCallback.length === 0) {
              console.error(reason)//默认的错误处理
            }
            for (var i = 0; i &amp;lt; _this.rejectedFn.length; i++) {
              _this.rejectedFn[i](reason)
            }
          }
        })
    }&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;Promise静态方法的实现&lt;br/&gt;列几个比较常用，很好理解，看代码基本就能明白，特别是Promise.all Promise.race的实现哦，面试常考原理。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;Promise.all = function(promises) {
    return new Promise(function(resolve, reject) {
      var resolvedCounter = 0
      var promiseNum = promises.length
      var resolvedValues = new Array(promiseNum)
      for (var i = 0; i &amp;lt; promiseNum; i++) {
        (function(i) {
          Promise.resolve(promises[i]).then(function(value) {
            resolvedCounter++
            resolvedValues[i] = value
            if (resolvedCounter == promiseNum) {
              return resolve(resolvedValues)
            }
          }, function(reason) {
            return reject(reason)
          })
        })(i)
      }
    })
  }

  Promise.race = function(promises) {
    return new Promise(function(resolve, reject) {
      for (var i = 0; i &amp;lt; promises.length; i++) {
        Promise.resolve(promises[i]).then(function(value) {
          return resolve(value)
        }, function(reason) {
          return reject(reason)
        })
      }
    })
  }

  Promise.resolve = function(value) {
    var promise = new Promise(function(resolve, reject) {
      resolvePromise(promise, value, resolve, reject)
    })
    return promise
  }

  Promise.reject = function(reason) {
    return new Promise(function(resolve, reject) {
      reject(reason)
    })
  }&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;然后给一个完整版的代码&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;try {
    module.exports = Promise
  } catch (e) {}
  
  function Promise(executor) {
    var self = this
  
    self.status = 'pending'
    self.onResolvedCallback = []
    self.onRejectedCallback = []
  
    function resolve(value) {
      if (value instanceof Promise) {
        return value.then(resolve, reject)
      }
      setTimeout(function() { // 异步执行所有的回调函数
        if (self.status === 'pending') {
          self.status = 'resolved'
          self.data = value
          for (var i = 0; i &amp;lt; self.onResolvedCallback.length; i++) {
            self.onResolvedCallback[i](value)
          }
        }
      })
    }
  
    function reject(reason) {
      setTimeout(function() { // 异步执行所有的回调函数
        if (self.status === 'pending') {
          self.status = 'rejected'
          self.data = reason
          for (var i = 0; i &amp;lt; self.onRejectedCallback.length; i++) {
            self.onRejectedCallback[i](reason)
          }
        }
      })
    }
  
    try {
      executor(resolve, reject)
    } catch (reason) {
      reject(reason)
    }
  }
  
  function resolvePromise(promise2, x, resolve, reject) {
    var then
    var thenCalledOrThrow = false
  
    if (promise2 === x) {
      return reject(new TypeError('Chaining cycle detected for promise!'))
    }
  
    if (x instanceof Promise) {
      if (x.status === 'pending') { //because x could resolved by a Promise Object
        x.then(function(v) {
          resolvePromise(promise2, v, resolve, reject)
        }, reject)
      } else { //but if it is resolved, it will never resolved by a Promise Object but a static value;
        x.then(resolve, reject)
      }
      return
    }
  
    if ((x !== null) &amp;amp;&amp;amp; ((typeof x === 'object') || (typeof x === 'function'))) {
      try {
        then = x.then //because x.then could be a getter
        if (typeof then === 'function') {
          then.call(x, function rs(y) {
            if (thenCalledOrThrow) return
            thenCalledOrThrow = true
            return resolvePromise(promise2, y, resolve, reject)
          }, function rj(r) {
            if (thenCalledOrThrow) return
            thenCalledOrThrow = true
            return reject(r)
          })
        } else {
          resolve(x)
        }
      } catch (e) {
        if (thenCalledOrThrow) return
        thenCalledOrThrow = true
        return reject(e)
      }
    } else {
      resolve(x)
    }
  }
  
  Promise.prototype.then = function(onResolved, onRejected) {
    var self = this
    var promise2
    onResolved = typeof onResolved === 'function' ? onResolved : function(v) {
      return v
    }
    onRejected = typeof onRejected === 'function' ? onRejected : function(r) {
      throw r
    }
  
    if (self.status === 'resolved') {
      return promise2 = new Promise(function(resolve, reject) {
        setTimeout(function() { // 异步执行onResolved
          try {
            var x = onResolved(self.data)
            resolvePromise(promise2, x, resolve, reject)
          } catch (reason) {
            reject(reason)
          }
        })
      })
    }
  
    if (self.status === 'rejected') {
      return promise2 = new Promise(function(resolve, reject) {
        setTimeout(function() { // 异步执行onRejected
          try {
            var x = onRejected(self.data)
            resolvePromise(promise2, x, resolve, reject)
          } catch (reason) {
            reject(reason)
          }
        })
      })
    }
  
    if (self.status === 'pending') {
      // 这里之所以没有异步执行，是因为这些函数必然会被resolve或reject调用，而resolve或reject函数里的内容已是异步执行，构造函数里的定义
      return promise2 = new Promise(function(resolve, reject) {
        self.onResolvedCallback.push(function(value) {
          try {
            var x = onResolved(value)
            resolvePromise(promise2, x, resolve, reject)
          } catch (r) {
            reject(r)
          }
        })
  
        self.onRejectedCallback.push(function(reason) {
            try {
              var x = onRejected(reason)
              resolvePromise(promise2, x, resolve, reject)
            } catch (r) {
              reject(r)
            }
          })
      })
    }
  }
  
  Promise.prototype.catch = function(onRejected) {
    return this.then(null, onRejected)
  }
  
  Promise.deferred = Promise.defer = function() {
    var dfd = {}
    dfd.promise = new Promise(function(resolve, reject) {
      dfd.resolve = resolve
      dfd.reject = reject
    })
    return dfd
  }&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;其他静态方法代码参考&lt;br/&gt;&lt;a href=&quot;https://github.com/ab164287643/Promise3/blob/master/Promise3.js&quot; class=&quot;uri&quot;&gt;https://github.com/ab164287643/Promise3/blob/master/Promise3.js&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;本文参考&lt;br/&gt;&lt;a href=&quot;https://github.com/xieranmaya/blog/issues/3&quot; class=&quot;uri&quot;&gt;https://github.com/xieranmaya/blog/issues/3&lt;/a&gt;&lt;/p&gt;
</description>
<pubDate>Sat, 27 Apr 2019 14:24:00 +0000</pubDate>
<dc:creator>魑魅魍魉_killer</dc:creator>
<og:description>一个promise的当前状态只能是pending、fulfilled和rejected三种之一。状态改变只能是pending到fulfilled或者pending到rejected，状态改变不可逆，支</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/chenlei987/p/10780777.html</dc:identifier>
</item>
<item>
<title>《HelloGitHub》第 37 期 - 削微寒</title>
<link>http://www.cnblogs.com/xueweihan/p/10780584.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/xueweihan/p/10780584.html</guid>
<description>&lt;p&gt;欢迎熟悉 C# 热爱开源的小伙伴加入我们，&lt;a href=&quot;mailto:595666367@qq.com&quot;&gt;点此联系我&lt;/a&gt;&lt;/p&gt;

&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;兴趣是最好的老师，&lt;strong&gt;HelloGitHub&lt;/strong&gt; 就是帮你找到兴趣！&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/759200/201904/759200-20190427214358062-1592005660.jpg&quot;/&gt;&lt;/p&gt;
&lt;h2 id=&quot;简介&quot;&gt;简介&lt;/h2&gt;
&lt;p&gt;分享 GitHub 上有趣、入门级的开源项目。&lt;/p&gt;
&lt;p&gt;这是一个面向&lt;strong&gt;编程新手&lt;/strong&gt;、&lt;strong&gt;热爱编程&lt;/strong&gt;、&lt;strong&gt;对开源社区感兴趣&lt;/strong&gt; 人群的月刊，月刊的内容包括：&lt;strong&gt;各种编程语言的项目&lt;/strong&gt;、&lt;strong&gt;让生活变得更美好的工具&lt;/strong&gt;、&lt;strong&gt;书籍、学习笔记、教程等&lt;/strong&gt;，这些开源项目大多都是非常容易上手，而且非常 Cool。主要是希望大家能动手用起来，加入到&lt;strong&gt;开源社区&lt;/strong&gt;中。&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;会编程的可以贡献代码&lt;/li&gt;
&lt;li&gt;不会编程的可以反馈使用这些工具中的 Bug&lt;/li&gt;
&lt;li&gt;帮着宣传你觉得优秀的项目&lt;/li&gt;
&lt;li&gt;Star 项目⭐️&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;在浏览、参与这些项目的过程中，你将学习到&lt;strong&gt;更多编程知识&lt;/strong&gt;、&lt;strong&gt;提高编程技巧&lt;/strong&gt;、&lt;strong&gt;找到编程的乐趣&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;🎉 最后 &lt;a href=&quot;https://hellogithub.com&quot;&gt;HelloGitHub&lt;/a&gt; 这个项目就诞生了 🎉&lt;/p&gt;
&lt;hr/&gt;&lt;blockquote readability=&quot;3.5882352941176&quot;&gt;
&lt;p&gt;&lt;strong&gt;以下为本期内容&lt;/strong&gt;｜每个月 &lt;strong&gt;28&lt;/strong&gt; 号发布最新一期｜&lt;a href=&quot;https://github.com/521xueweihan/HelloGitHub#%E5%86%85%E5%AE%B9&quot;&gt;点击查看往期内容&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4 id=&quot;c-项目&quot;&gt;C# 项目&lt;/h4&gt;
&lt;p&gt;1、&lt;a href=&quot;https://github.com/xunki/RemoteDesktopManage&quot;&gt;RemoteDesktopManage&lt;/a&gt;：基于 MSTSC 连接 Windows 远程桌面，并对其进行封装实现管理多个远程桌面配置的小工具。更加方便地管理多个远程桌面，实现同时远程、互相切换。相当于把多个 MSTSC 集合在一个软件里，并进行分组打标试用&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/759200/201904/759200-20190427214414425-1410058721.png&quot;/&gt;&lt;/p&gt;
&lt;h4 id=&quot;c-项目-1&quot;&gt;C++ 项目&lt;/h4&gt;
&lt;p&gt;2、&lt;a href=&quot;https://github.com/taylorconor/tinytetris&quot;&gt;tinytetris&lt;/a&gt;：一个用 C++ 编写的终端版俄罗斯方块游戏。提供了两个版本的源码，分为注释版和库版，注释较多易于理解和学习&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/759200/201904/759200-20190427214432765-1394825847.gif&quot;/&gt;&lt;/p&gt;
&lt;h4 id=&quot;go-项目&quot;&gt;Go 项目&lt;/h4&gt;
&lt;p&gt;3、&lt;a href=&quot;https://github.com/bilibili/overlord&quot;&gt;overlord&lt;/a&gt;：基于 Go 语言编写的 memcache 和 redis&amp;amp;cluster 的代理及集群管理平台。致力于提供自动化高可用的缓存服务解决方案。自带图形界面的缓存集群管理程序，&lt;a href=&quot;https://github.com/bilibili/overlord/blob/master/doc/wiki-cn/platform-deploy.md&quot;&gt;安装步骤&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/759200/201904/759200-20190427214444463-713961453.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;4、&lt;a href=&quot;https://github.com/bilibili/kratos&quot;&gt;kratos&lt;/a&gt;：哔哩哔哩开源的一套 Go 微服务框架，包含大量微服务相关框架及工具。解决了 gin 在微服务场景下的一些适配和微服务本身的一系列生态，&lt;a href=&quot;https://github.com/bilibili/kratos/blob/master/doc/wiki-cn/quickstart.md&quot;&gt;快速开始&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/521xueweihan/img/master/hellogithub/37/img/kratos.gif&quot;/&gt;&lt;/p&gt;
&lt;p&gt;5、&lt;a href=&quot;https://github.com/docker-slim/docker-slim&quot;&gt;docker-slim&lt;/a&gt;：自动缩减 docker 镜像的体积的工具。大幅度缩减 docker 镜像的体积，方便分发，使用命令 &lt;code&gt;docker-slim build --http-probe your-name/your-app&lt;/code&gt;。比如 Node.js 镜像缩减后的对比：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;from ubuntu:14.04 - 432MB =&amp;gt; 14MB (缩减了 30.85 倍)

from debian:jessie - 406MB =&amp;gt; 25.1MB (缩减了 16.21 倍)

from node:alpine - 66.7MB =&amp;gt; 34.7MB (缩减了 1.92 倍)&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;6、&lt;a href=&quot;https://github.com/eBay/beam&quot;&gt;beam&lt;/a&gt;：eBay 开源的分布式图数据库，少数依然支持 SparQL 的图数据库&lt;/p&gt;
&lt;h4 id=&quot;java-项目&quot;&gt;Java 项目&lt;/h4&gt;
&lt;p&gt;7、&lt;a href=&quot;https://github.com/guolindev/giffun&quot;&gt;giffun&lt;/a&gt;：Android 端开源的 GIF 浏览和分享 App。该应用界面基于 Material Design 标准设计，围绕 GIF 为主题，建立了一个小型的社交系统。支持：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;查看热门搞笑的 GIF 图&lt;/li&gt;
&lt;li&gt;关注你喜欢的人，他的有趣分享尽收眼底&lt;/li&gt;
&lt;li&gt;一键发布你自己的 GIF 趣图&lt;/li&gt;
&lt;li&gt;对你感兴趣的内容点赞、点评&lt;/li&gt;
&lt;li&gt;喜欢的内容轻松转发至主流社交软件，传递你的快乐&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/759200/201904/759200-20190427214455458-10679535.gif&quot;/&gt;&lt;/p&gt;
&lt;p&gt;8、&lt;a href=&quot;https://github.com/crossoverJie/cim&quot;&gt;cim&lt;/a&gt;：一款面向开发者的 IM 即时通讯系统。命令行通讯工具，对开发者友好。提供了一些组件让开发者易于扩展和定制功能。架构图如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/759200/201904/759200-20190427214507501-767136615.jpg&quot;/&gt;&lt;/p&gt;
&lt;p&gt;9、&lt;a href=&quot;https://github.com/wuyouzhuguli/SpringAll&quot;&gt;SpringAll&lt;/a&gt;：Spring 系列源码教程，包含 Spring Boot、Spring Boot、Spring Cloud 等。Spring 是 Java 目前生命力最强的框架之一，通过资料与源码的配合，容易学习和上手&lt;/p&gt;
&lt;p&gt;10、&lt;a href=&quot;https://github.com/seata/seata&quot;&gt;seata&lt;/a&gt;：一套一站式分布式事务解决方案。让分布式事务的使用像本地事务的使用一样，简单和高效，并逐步解决开发者们遇到的分布式事务方面的所有难题。分布式事务提出了很多年，但是一直没有很好的解决方案，要不就收费很贵。蚂蚁金服开源的 seata，将让分布式事务不在束之高阁，任何需要的人都可以使用它，推荐学习和使用。工作流程图如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/759200/201904/759200-20190427214519729-903962322.png&quot;/&gt;&lt;/p&gt;
&lt;h4 id=&quot;javascript-项目&quot;&gt;JavaScript 项目&lt;/h4&gt;
&lt;p&gt;11、&lt;a href=&quot;https://github.com/bytedance/xgplayer&quot;&gt;xgplayer&lt;/a&gt;：由字节跳动西瓜视频开源的带解析器、能节省流量的 HTML5 视频播放器。可以作为 H5 组件、Vue、React 组件单独使用。它根据组件化的原则设计了一个独立的、可分离的 UI 组件。更重要的是，它不仅在 UI 层具有灵活性，而且在功能上也很大胆：它摆脱了视频加载、缓冲和格式支持。在播放器端加载视频、解析视频、转换格式，让不支持分段播放的 MP4 动态支持，这样就无须转换源视频的格式，服务器端也无其他开销。&lt;a href=&quot;http://h5player.bytedance.com/&quot;&gt;官网&lt;/a&gt;，示例代码：&lt;/p&gt;
&lt;pre class=&quot;javascript&quot;&gt;
&lt;code&gt;//  安装：$ npm install xgplayer
// 第一步：&amp;lt;div id=&quot;vs&quot;&amp;gt;&amp;lt;/div&amp;gt;
// 第二步：
import Player from 'xgplayer';

const player = new Player({
    id: 'vs',
    url: 'http://s2.pstatp.com/cdn/expire-1-M/byted-player-videos/1.0.0/xgplayer-demo.mp4'
})&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;12、&lt;a href=&quot;https://github.com/zhui-team/zhui&quot;&gt;zhui&lt;/a&gt;：这是一款国风的组件库。好用的组件库千千万，有趣的创意万里挑一&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/759200/201904/759200-20190427214530892-1298617641.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;13、&lt;a href=&quot;https://github.com/muan/emoji-minesweeper&quot;&gt;emoji-minesweeper&lt;/a&gt;：Emoji 符号的扫雷游戏。代码很简短，游戏创意很酷。寥寥 300+ 行代码实现该游戏，简短易于初学者学习&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/759200/201904/759200-20190427214544504-1596807387.gif&quot;/&gt;&lt;/p&gt;
&lt;p&gt;14、&lt;a href=&quot;https://github.com/GoogleChromeLabs/squoosh&quot;&gt;squoosh&lt;/a&gt;：谷歌开源的图片压缩工具。在保证图片质量的情况下快速压缩图片，支持多种图片格式。6.63M 的图片压缩后为 2.92M，使用起来简单方便&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/759200/201904/759200-20190427214555919-1561060751.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;15、&lt;a href=&quot;https://github.com/azl397985856/leetcode&quot;&gt;leetcode&lt;/a&gt;：更加贴近前端的数据结构与算法的库。以 leetcode 作为切入点，详细讲解关于数据结构的方方面面， 并以JavaScript 语言作为解题语言。 后期会加入更多关于前端贴合的内容， 比如：&lt;code&gt;react fiber&lt;/code&gt; 的实现和链表、&lt;code&gt;react hooks&lt;/code&gt; 的实现和数组等等&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;第一部分：leetcode 经典题目的解析，包括思路、关键点和具体的代码实现&lt;/li&gt;
&lt;li&gt;第二部分：对于数据结构与算法的总结&lt;/li&gt;
&lt;li&gt;第三部分：anki 卡片， 将 leetcode 题目按照一定的方式记录在 anki 中，方便大家记忆&lt;/li&gt;
&lt;/ul&gt;&lt;h4 id=&quot;python-项目&quot;&gt;Python 项目&lt;/h4&gt;
&lt;p&gt;16、&lt;a href=&quot;https://github.com/kkroening/ffmpeg-python&quot;&gt;ffmpeg-python&lt;/a&gt;：FFmpeg 是一套可以用来记录、转换数字音频、视频，并能将其转化为流的开源计算机程序。这个是其 Python 的库，可以用该库操作、处理视频和音频。示例代码：&lt;/p&gt;
&lt;pre class=&quot;python&quot;&gt;
&lt;code&gt;# 水平翻转视频
import ffmpeg
stream = ffmpeg.input('input.mp4')
stream = ffmpeg.hflip(stream)
stream = ffmpeg.output(stream, 'output.mp4')
ffmpeg.run(stream)&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/759200/201904/759200-20190427214610876-1160824903.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;17、&lt;a href=&quot;https://github.com/Microsoft/pyright&quot;&gt;pyright&lt;/a&gt;：微软出品的 Python 静态类型检查工具。执行速度快，适合大型 Python 项目，引用一句话：动态语言一时爽，重构火葬场&lt;/p&gt;
&lt;p&gt;18、&lt;a href=&quot;https://github.com/kitao/pyxel&quot;&gt;pyxel&lt;/a&gt;：基于 Python 编程程语言实现的复古游戏引擎。示例代码：&lt;/p&gt;
&lt;pre class=&quot;python&quot;&gt;
&lt;code&gt;# 代码中导入 Pyxel 模块后
import pyxel
# 首先使用 init 函数指定窗口大小
pyxel.init(160, 120)

def update():
    if pyxel.btnp(pyxel.KEY_Q):
        pyxel.quit()

def draw():
    pyxel.cls(0)
    pyxel.rect(10, 10, 20, 20, 11)
# 最后然后使用 run 函数启动 Pyxel 应用程序
pyxel.run(update, draw)&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/759200/201904/759200-20190427214625870-1282833366.gif&quot;/&gt;&lt;/p&gt;
&lt;h4 id=&quot;ruby-项目&quot;&gt;Ruby 项目&lt;/h4&gt;
&lt;p&gt;19、&lt;a href=&quot;https://github.com/2016rshah/githubchart-api&quot;&gt;githubchart-api&lt;/a&gt;：根据 GitHub 账号的贡献记录生成对应图像。一行代码，可以在任何网站展示自己在 GitHub 上的贡献活跃图标。示例代码：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;&amp;lt;img src=&quot;http://ghchart.rshah.org/用户名&quot; alt=&quot;Github commit chart&quot; /&amp;gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/759200/201904/759200-20190427214636687-635699439.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;20、&lt;a href=&quot;https://github.com/thoughtbot/guides&quot;&gt;guides&lt;/a&gt;：Ruby 编程风格指南。统一的格式风格有利于代码的维护和迭代，对于 Ruby 使用者而言帮助极大&lt;/p&gt;
&lt;h4 id=&quot;swift-项目&quot;&gt;Swift 项目&lt;/h4&gt;
&lt;p&gt;21、&lt;a href=&quot;https://github.com/zixun/GodEye&quot;&gt;GodEye&lt;/a&gt;：一行代码自动显示日志、崩溃、网络、ANR、泄漏、CPU、文件夹等信息，就像上帝睁开眼睛一样&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/759200/201904/759200-20190427214648381-655652070.png&quot;/&gt;&lt;/p&gt;
&lt;h4 id=&quot;其它&quot;&gt;其它&lt;/h4&gt;
&lt;p&gt;22、&lt;a href=&quot;https://github.com/CyC2018/CS-Notes&quot;&gt;CS-Notes&lt;/a&gt;：该项目整理、聚集了技术面试必备的基础知识。省去了查找资料的时间，同时也是一份很好的学习资料&lt;/p&gt;
&lt;p&gt;23、&lt;a href=&quot;https://github.com/QSCTech/zju-icicles&quot;&gt;zju-icicles&lt;/a&gt;：浙江大学各种课程相关资源集合。包含：课程、作业、答案、复习资料、选课攻略等，是浙大在校生的必备资源，对于有考研想法的小伙伴而言也是很好的资源&lt;/p&gt;
&lt;p&gt;24、&lt;a href=&quot;https://github.com/binhnguyennus/awesome-scalability&quot;&gt;awesome-scalability&lt;/a&gt;：一个系统的阅读列表，描述了可扩展、高可用、高性能的大型系统背后的东西。每部分都是基于真实案例，讲述了如何搭建一个可扩展、高可用、高性能的大型系统，案例都是来自于经过数百万甚至数十亿用户实战检验的系统。对于所有工程师而言都是一个很好的学习资料，开卷有益&lt;/p&gt;
&lt;p&gt;25、&lt;a href=&quot;https://github.com/justjavac/awesome-wechat-weapp&quot;&gt;awesome-wechat-weapp&lt;/a&gt;：该项目收集了微信小程序开发过程中会使用到的资料、问题以及第三方组件库。随着微信小程序的市场越来越大，很多公司也专门以制作小程序为业，不论对感兴趣的人还是想自己动手做小程序的人而言，这份合集省去了不少查找资料的时间&lt;/p&gt;
&lt;p&gt;26、&lt;a href=&quot;https://github.com/PKUanonym/REKCARC-TSC-UHT&quot;&gt;REKCARC-TSC-UHT&lt;/a&gt;：清华大学计算机系课程相关资源集合。内容丰富，包含从大一到大四，跟着清华学子一起学习传说中高校的课程吧&lt;/p&gt;
&lt;h4 id=&quot;开源书籍&quot;&gt;开源书籍&lt;/h4&gt;
&lt;p&gt;27、&lt;a href=&quot;https://github.com/yunlzheng/prometheus-book&quot;&gt;prometheus-book&lt;/a&gt;：《Prometheus 操作指南》，&lt;a href=&quot;https://yunlzheng.gitbook.io/prometheus-book/parti-prometheus-ji-chu/quickstart/why-monitor&quot;&gt;在线阅读&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;28、&lt;a href=&quot;https://github.com/selfteaching/the-craft-of-selfteaching&quot;&gt;the-craft-of-selfteaching&lt;/a&gt;：《自学是门手艺》一个编程入门者的自学心得。如今学习资源很多，对于初学者入门而言，最难的是如何自学，阅读本书打开编程自学大门吧&lt;/p&gt;
&lt;h4 id=&quot;教程&quot;&gt;教程&lt;/h4&gt;
&lt;p&gt;29、&lt;a href=&quot;https://github.com/trimstray/nginx-quick-reference&quot;&gt;nginx-quick-reference&lt;/a&gt;：该项目描述了如何提高 Nginx 的性能、安全性等方面的步骤，让你的网站在 SSL Labs 的评级到达 A+&lt;/p&gt;
&lt;h4 id=&quot;机器学习&quot;&gt;机器学习&lt;/h4&gt;
&lt;p&gt;30、&lt;a href=&quot;https://github.com/CMU-Perceptual-Computing-Lab/openpose&quot;&gt;openpose&lt;/a&gt;：基于卷积神经网络和监督学习的开源库，可以实现人的面部、躯干和四肢甚至手指的跟踪。适用于多人，且标记准确，同时具有较好的鲁棒性&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/759200/201904/759200-20190427214704795-345714778.gif&quot;/&gt;&lt;/p&gt;
&lt;p&gt;31、&lt;a href=&quot;https://github.com/TencentYoutuResearch/FaceDetection-DSFD&quot;&gt;FaceDetection-DSFD&lt;/a&gt;：腾讯优图的双分支人脸检测器全新算法，该算法已经被计算机视觉顶级会议 CVPR 2019 接收。优图此次提出的 DSFD 人脸检测算法，主要有 3 点创新：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;新的特征增强模块（FEM：Feature Enhance Module）&lt;/li&gt;
&lt;li&gt;分层锚点渐进式的代价函数监督（PLA：Progressive Anchor Loss）&lt;/li&gt;
&lt;li&gt;改进的锚点匹配策略（Improved Anchor Matching Strategy）&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/759200/201904/759200-20190427214730884-275884271.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;32、&lt;a href=&quot;https://github.com/NVlabs/SPADE&quot;&gt;SPADE&lt;/a&gt;：英伟达（NVIDIA）新开源的绘图工具。利用生成对抗网络，根据几根简单的线条就能生成栩栩如生的图像&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/759200/201904/759200-20190427214742365-1791587169.gif&quot;/&gt;&lt;/p&gt;
&lt;p&gt;33、&lt;a href=&quot;https://github.com/hzwer/LearningToPaint&quot;&gt;LearningToPaint&lt;/a&gt;：一个深度强化学习项目，研究如何让机器用画笔画画。也可体验制作自己的绘画或根据一张图片生成一整个绘画过程&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/759200/201904/759200-20190427214753663-1278770772.gif&quot;/&gt;&lt;/p&gt;
&lt;hr/&gt;&lt;h2 id=&quot;换种方式阅读&quot;&gt;换种方式阅读&lt;/h2&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;网站：&lt;/strong&gt; https://hellogithub.com&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;GitBook：&lt;/strong&gt; https://gitbook.hellogithub.com&lt;/li&gt;
&lt;/ul&gt;&lt;h2 id=&quot;声明&quot;&gt;声明&lt;/h2&gt;
&lt;p&gt;如果你发现了好玩、有意义的开源项目 &lt;a href=&quot;https://github.com/521xueweihan/HelloGitHub/issues/new&quot;&gt;点击这里&lt;/a&gt; 分享你觉得有意思的项目。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;欢迎转载，请注明出处和作者，同时保留声明。&lt;/strong&gt;&lt;/p&gt;
</description>
<pubDate>Sat, 27 Apr 2019 14:11:00 +0000</pubDate>
<dc:creator>削微寒</dc:creator>
<og:description>公告 欢迎熟悉 C 热爱开源的小伙伴加入我们， '点此联系我' 《HelloGitHub》第 37 期 兴趣是最好的老师， HelloGitHub 就是帮你找到兴趣！ 简介 分享 GitHub 上有趣</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/xueweihan/p/10780584.html</dc:identifier>
</item>
<item>
<title>深度学习基础之线性回归学习 - 玄苦</title>
<link>http://www.cnblogs.com/xuanku/p/dl_linear.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/xuanku/p/dl_linear.html</guid>
<description>&lt;p&gt;线性回归最简单和最经典的机器学习模型之一。&lt;/p&gt;
&lt;p&gt;任何一个机器学习模型都会有如下4个要素：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;训练数据&lt;/li&gt;
&lt;li&gt;数学模型&lt;/li&gt;
&lt;li&gt;损失函数&lt;/li&gt;
&lt;li&gt;计算方法&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;下面先阐述一下训练数据的数学定义，假设我们训练数据中有 &lt;code&gt;m&lt;/code&gt; 个样本，每个输入样本中有 &lt;code&gt;n&lt;/code&gt; 个特征输入和一个标注的输出：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://cdn.nlark.com/yuque/__latex/c59dcd7152bbe7186ccd5a349fba2a19.svg#card=math&amp;amp;code=%5Cleft%5B%0A%5Cbegin%7Barray%7D%7Bcccc%7Cc%7D%0Ax_1%5E1%20%26%20x_2%5E1%20%26%20%5Ccdots%20%26%20x_n%5E1%20%26%20y%5E1%20%5C%5C%0Ax_1%5E2%20%26%20x_2%5E2%20%26%20%5Ccdots%20%26%20x_n%5E2%20%26%20y%5E2%20%5C%5C%0A%5Cvdots%20%26%20%5Cvdots%20%26%20%5Cvdots%20%26%20%5Cvdots%20%26%20%5Cvdots%20%5C%5C%0Ax_1%5Em%20%26%20x_2%5Em%20%26%20%5Ccdots%20%26%20x_n%5Em%20%26%20y%5Em%20%5C%5C%0A%5Cend%7Barray%7D%0A%5Cright%5D&amp;amp;height=109&amp;amp;width=207&quot;/&gt;&lt;/p&gt;
&lt;p&gt;第 &lt;code&gt;i&lt;/code&gt; 个样本，记作：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://cdn.nlark.com/yuque/__latex/9c304d562adf46f6ea8bb7e8a175c521.svg#card=math&amp;amp;code=%5B%20x_1%5Ei%5C%20x_2%5Ei%20%5C%20%5Ccdots%5C%20x_n%5Ei%20%7C%20y%5Ei%5D&amp;amp;height=25&amp;amp;width=115&quot;/&gt;&lt;/p&gt;
&lt;p&gt;一个模型的表现好坏，训练数据的构建往往是最重要的一步，我们在做模型的时候往往会所这样一句话：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Garbage In, Garbage Out&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;不过如何构造和优化训练数据往往跟要解决的业务问题领域以及人工标注的质量有关，且跟采用哪种机器学习模型无关，所以就不在本文中详细描述。&lt;/p&gt;
&lt;p&gt;而其他三个 &lt;code&gt;数学模型&lt;/code&gt;  &lt;code&gt;损失函数&lt;/code&gt; &lt;code&gt;计算方法&lt;/code&gt; 都是定义了某一种机器学习模型的关键，所以本文就详细介绍这几个点。&lt;/p&gt;


&lt;p&gt;线性回归的数学模型定义很简单，就是一维的线性方程：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://cdn.nlark.com/yuque/__latex/c5c71ed07d93da14952ec4ee00c481a0.svg#card=math&amp;amp;code=%5Chat%7By%7D%20%3D%20w_1x_1%20%2Bw_2x_2%20%2B%20%5Ccdots%20%2B%20w_nx_n%20%2B%20b&amp;amp;height=24&amp;amp;width=246&quot;/&gt;&lt;/p&gt;
&lt;p&gt;而训练数据中的第 &lt;code&gt;i&lt;/code&gt; 个样本，我们记作：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://cdn.nlark.com/yuque/__latex/d1454682cf1313b924ecf97e280ca923.svg#card=math&amp;amp;code=%5Chat%7By%7D%5Ei%20%3D%20w_1x_1%5Ei%20%2B%20w_2x_2%5Ei%20%2B%20%5Ccdots%20%2B%20w_nx_n%5Ei%20%2B%20b&amp;amp;height=25&amp;amp;width=251&quot;/&gt;&lt;/p&gt;
&lt;p&gt;从上可以看出线性回归的数学假设是，训练数据中所有输出和所有输入的特征之间是一个线性表达式的关系。&lt;/p&gt;
&lt;p&gt;您很有可能会问，那如果我输入的训练数据之间他本身不是一个线性关系的话，那这个线性回归不就完全失效了么？&lt;br/&gt;确实是这样的，很多情况下我们拿到的数据并不一定会是线性关系，针对这种情况，我们一般会采取两种办法来解决：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;调整数学模型，不用线性方程来表达，用二维，三维甚至更高维度的方程式来表达这个数学关系&lt;/li&gt;
&lt;li&gt;调整输入特征，将输入特征做各种函数变化，比如可以将 &lt;img src=&quot;https://cdn.nlark.com/yuque/__latex/cb83201fed202d375dd5cc5144741796.svg#card=math&amp;amp;code=%5Csqrt%7Bx_1%5E2%2Bx_2%5E2%7D&amp;amp;height=34&amp;amp;width=70&quot;/&gt;当成一个特征的话，我们就可以将一个二维模型才能表达的公式转换成一维方程就能表达了&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;在实际生产环境中，我们一般不会升高数学模型的维度，但是可能会做变化，比如我们之后会讲到的深度学习，就是将多个一维线性模型串联起来作为一个大的模型。&lt;/p&gt;
&lt;p&gt;但是不管采用什么样的模型，都是基于假设的，所以机器学习的领域不管怎么优化，都是会有一个准确率和召回率的指标的，因为有可能这个假设就是不对的，当然学习出来的模型也是由偏差的。&lt;/p&gt;
&lt;p&gt;说远了，让我们回到我们的线性回归的模型上来，在本文中，为了描述简单，我们假设 &lt;code&gt;n=2&lt;/code&gt; 来演示计算过程，比如我们要做一个房价预测系统，特征有两个，一个是房屋面积，一个是房屋年龄，那么我们的计算公式如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://cdn.nlark.com/yuque/__latex/fc9550ac11d9864a020c5a21a0965e31.svg#card=math&amp;amp;code=%5Chat%7By%7D%5Ei%20%3D%20w_1x_1%5Ei%20%2B%20w_2x_2%5Ei%20%2B%20b&amp;amp;height=25&amp;amp;width=154&quot;/&gt;&lt;/p&gt;
&lt;p&gt;那么我们的任务就变成了&lt;strong&gt;如何利用训练数据求解&lt;/strong&gt; &lt;code&gt;**[w1, w2, b]**&lt;/code&gt; &lt;strong&gt;这几个参数&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;在数据量比较少的情况下，我们可以通过初中学过的解方程的思想来求解这个参数，一般来说，只要有3个(即求解参数个数)样本，我们就能求解这个参数了，这个解，我们叫 &lt;code&gt;解析解&lt;/code&gt; 。&lt;/p&gt;
&lt;p&gt;但是在实际情况中，我们的数据量远远比3个要多，选不同的3个样本的时候求出来的解是不一样的，而最终又无法通过一个 &lt;code&gt;[w1, w2, b]&lt;/code&gt; 的参数值来满足所有训练数据集合，即通过解方程得到的结论是 &lt;code&gt;无解&lt;/code&gt; ，那么我们的任务就变成&lt;strong&gt;在所有解当中找到一个最优的近似解，我们称这个解为 &lt;code&gt;数值解&lt;/code&gt; &lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;下面两章我们就来介绍，我们如何寻找到最优的近似解。&lt;/p&gt;


&lt;p&gt;要找到最优解，我们就需要来衡量一个解相比于另一个解到底哪个解更好。怎么衡量呢，就是我们本节要讲的 &lt;code&gt;损失函数&lt;/code&gt; 了。&lt;/p&gt;
&lt;p&gt;以如上的房屋面积的例子来距离，假设我么有两组解：&lt;br/&gt;&lt;img src=&quot;https://cdn.nlark.com/yuque/__latex/2a7d5d97861846a93f9310d649f60130.svg#card=math&amp;amp;code=%5Cbegin%7Balign%7D%20%0A%26%20%5Ctextbf%7Bw%7D%20%3D%20%5Bw_1%2C%20w_2%2C%20b%5D%5ET%20%5C%5C%0A%26%20%5Ctextbf%7Bw%27%7D%20%3D%20%5Bw_1%27%2C%20w_2%27%2C%20b%27%5D%5ET%20%5C%0A%5Cend%7Balign%7D&amp;amp;height=46&amp;amp;width=133&quot;/&gt;&lt;/p&gt;
&lt;p&gt;然后我们用训练数据，分别用 &lt;code&gt;w&lt;/code&gt; 和 &lt;code&gt;w'&lt;/code&gt; 来计算出一个房屋价格的数组，分别为：&lt;br/&gt;&lt;img src=&quot;https://cdn.nlark.com/yuque/__latex/89ea46bf24fd13992fa734978842ec36.svg#card=math&amp;amp;code=%5Cbegin%7Balign%7D%0A%5Chat%7B%5Ctextbf%7By%7D%7D%20%3D%20%5B%7B%5Chat%7By_1%7D%2C%20%5Chat%7By_2%7D%2C%20%5Ccdots%2C%20%5Chat%7By_n%7D%7D%5D%5ET%20%5C%5C%0A%5Chat%7B%5Ctextbf%7By%27%7D%7D%20%3D%20%5B%7B%5Chat%7By_1%27%7D%2C%20%5Chat%7By_2%27%7D%2C%20%5Ccdots%2C%20%5Chat%7By_n%27%7D%7D%5D%5ET%20%5C%5C%0A%5Cend%7Balign%7D&amp;amp;height=48&amp;amp;width=151&quot;/&gt;&lt;/p&gt;
&lt;p&gt;而输入的训练样本的真实的房屋面积的数组为：&lt;br/&gt;&lt;img src=&quot;https://cdn.nlark.com/yuque/__latex/b3146e12ef9102e87f3ec0d99ca44a11.svg#card=math&amp;amp;code=%7B%5Ctextbf%7By%7D%7D%20%3D%20%5B%7B%7By_1%7D%2C%20%7By_2%7D%2C%20%5Ccdots%2C%20%7By_n%7D%7D%5D%5ET&amp;amp;height=24&amp;amp;width=141&quot;/&gt;&lt;/p&gt;
&lt;p&gt;那么我们就是比较 &lt;img src=&quot;https://cdn.nlark.com/yuque/__latex/e76dd42ff23ca26ea1fd711e23a7a048.svg#card=math&amp;amp;code=%5Chat%7B%5Ctextbf%7By%7D%7D&amp;amp;height=24&amp;amp;width=10&quot;/&gt; 和 &lt;img src=&quot;https://cdn.nlark.com/yuque/__latex/bd850e20fc2dc7f13cb9c43f8de8ea98.svg#card=math&amp;amp;code=%5Chat%7B%5Ctextbf%7By%7D%27%7D&amp;amp;height=26&amp;amp;width=14&quot;/&gt;哪个离我们的真实数据 &lt;img src=&quot;https://cdn.nlark.com/yuque/__latex/5ec2f11ab432ba7ee489759649c008a2.svg#card=math&amp;amp;code=%5Ctextbf%7By%7D&amp;amp;height=24&amp;amp;width=10&quot;/&gt;  更相近，哪个就更好，那么怎么定义呢，一般我们采用每个元素之差的平方和来定义，如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://cdn.nlark.com/yuque/__latex/f5b43f41a4079ec6dbe33f724d78114f.svg#card=math&amp;amp;code=%5Cbegin%7Balign%7D%0Aloss%28%5Chat%7By%7D%29%20%26%20%3D%20%7B%5Csum_%7Bi%3D0%7D%5E%7Bn%7D%28%5Chat%7By_i%7D-y_i%29%5E2%7D%20%5C%5C%0A%26%20%3D%20%7B%5Csum_%7Bi%3D0%7D%5En%28%7Bw_1x_1%5Ei%2Bw_2x_2%5Ei%2Bb-y%5Ei%7D%29%5E2%7D%0A%5Cend%7Balign%7D&amp;amp;height=99&amp;amp;width=272&quot;/&gt;&lt;/p&gt;
&lt;p&gt;这个函数，我们也就称之为&lt;strong&gt;损失函数&lt;/strong&gt;。如上两组参数哪个好，只需要比较 &lt;img src=&quot;https://cdn.nlark.com/yuque/__latex/e76dd42ff23ca26ea1fd711e23a7a048.svg#card=math&amp;amp;code=%5Chat%7B%5Ctextbf%7By%7D%7D&amp;amp;height=24&amp;amp;width=10&quot;/&gt; 和 &lt;img src=&quot;https://cdn.nlark.com/yuque/__latex/bd850e20fc2dc7f13cb9c43f8de8ea98.svg#card=math&amp;amp;code=%5Chat%7B%5Ctextbf%7By%7D%27%7D&amp;amp;height=26&amp;amp;width=14&quot;/&gt;对应的损失函数取得的值，哪个损失函数的值比较小，我们就选择哪一组参数。&lt;/p&gt;
&lt;p&gt;当然，损失函数也不一定要采用平方，用绝对值，用四次方都可以，用什么函数，就跟下一步求解过程有关了，针对线性回归问题，我们一般都采用的是平方和损失函数。&lt;/p&gt;
&lt;p&gt;那么到目前为止，我们的任务已经变成了，在所有可能的 &lt;code&gt;[w1, w2, b]&lt;/code&gt; 的组合中，找寻到一组解，&lt;strong&gt;使得 &lt;code&gt;loss(y)&lt;/code&gt; 损失函数的取值最小&lt;/strong&gt;。&lt;/p&gt;


&lt;p&gt;如上一节损失函数中描述，我们已经将我们的问题求解过程转换成了一个数学求解的任务，找到损失函数最小的参数解。&lt;/p&gt;
&lt;p&gt;这个求解过程，最广泛被使用的方法就是&lt;strong&gt;随机梯度下降&lt;/strong&gt;算法。该算法的指导思想也很简单，就是&lt;strong&gt;随机&lt;/strong&gt;选择一组参数值 &lt;strong&gt;&lt;code&gt;[w]&lt;/code&gt;&lt;/strong&gt;  作为初始值，然后执行N次循环，每次循环都根据优化算法改变一点点 &lt;strong&gt;&lt;code&gt;w&lt;/code&gt;&lt;/strong&gt;  的值，使得损失函数能&lt;strong&gt;下降&lt;/strong&gt;一点点，经过有限次循环之后，如果发现损失函数基本上不怎么变化了，就可以停止循环，将当前计算出来的 &lt;strong&gt;&lt;code&gt;w&lt;/code&gt;&lt;/strong&gt; 当成是近似最优解返回。&lt;/p&gt;
&lt;p&gt;那么您可能也看出来了，如上的描述中提到了随机，也提到了下降，但是名字中的梯度没提到，同时可能您也看出来了，上面描述中还有一个黑盒一般的描述：&lt;strong&gt;每次根据优化算法改变一点点&lt;/strong&gt; &lt;code&gt;**w**&lt;/code&gt; &lt;strong&gt;的值&lt;/strong&gt;。那其实这里的优化算法就是对损失函数求梯度，梯度是微积分上的一个数学定义，定义参考我们在&lt;a href=&quot;http://www.cnblogs.com/xuanku/p/math#214942d8&quot;&gt;数学基础&lt;/a&gt;一章中的描述。这里简单说一下，就是针对每个 &lt;code&gt;w&lt;/code&gt; 中的参数，我们针对损失函数求该参数的偏导数，然后将该参数沿着偏导数的方向往下走一小段，这样大概率下一次我们的损失函数是会下降的。&lt;/p&gt;
&lt;p&gt;以房价为例子，我们的优化算法的数学表达式如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://cdn.nlark.com/yuque/__latex/4fc05a454cd953197802fc9d125c0d1b.svg#card=math&amp;amp;code=next%28w_1%29%20%3D%20w_1%20-%20%7B%5Ceta%7D%5Csum_%7Bi%3D0%7D%5E%7Bm%7D%5Cfrac%7B%5Cpartial%7Bloss%5Ei%28w_1%2C%20w_2%2C%20b%29%7D%7D%7B%5Cpartial%28w_1%29%7D&amp;amp;height=49&amp;amp;width=282&quot;/&gt;&lt;/p&gt;
&lt;p&gt;那么我们根据如上定义的平方损失函数，针对&lt;strong&gt;w1&lt;/strong&gt;计算偏导数如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://cdn.nlark.com/yuque/__latex/2b459367f6f5430edb932cd53b9bfa58.svg#card=math&amp;amp;code=%5Cbegin%7Balign%7D%0Af%27%28w_1%29%20%26%20%3D%20%28%5Cfrac12%7B%5Csum_%7Bi%3D0%7D%5Em%28%7Bw_1x_1%5Ei%2Bw_2x_2%5Ei%2Bb-y%5Ei%7D%29%5E2%7D%29%27%20%5C%5C%0A%26%20%3D%20%5Csum_%7Bi%3D0%7D%5Em%28w_1x_1%5Ei%2Bw_2x_2%5Ei%2Bb-y%5Ei%29x_1%5Ei%0A%5Cend%7Balign%7D&amp;amp;height=99&amp;amp;width=299&quot;/&gt;&lt;/p&gt;
&lt;p&gt;注意我们在损失函数前面增加了一个 &lt;code&gt;1/2&lt;/code&gt; ，主要为了求导更方便。&lt;/p&gt;
&lt;p&gt;然后我们将偏导数代入上面的公式中，可以得到如下的公式：&lt;br/&gt;&lt;img src=&quot;https://cdn.nlark.com/yuque/__latex/936ce5255418a6825162c958e00b4702.svg#card=math&amp;amp;code=%5Cbegin%7Balign%7D%0Anext%28w_1%29%20%26%20%3D%20w_1%20-%20%7B%5Ceta%7D%5Csum_%7Bi%3D0%7D%5E%7Bm%7D%5Cfrac%7B%5Cpartial%7Bloss%5Ei%28w_1%2C%20w_2%2C%20b%29%7D%7D%7B%5Cpartial%28w_1%29%7D%20%5C%5C%0A%26%20%3D%20w_1%20-%20%5Ceta%5Csum_%7Bi%3D0%7D%5Em%28w_1x_1%5Ei%2Bw_2x_2%5Ei%2Bb-y%5Ei%29x_1%5Ei%20%5C%5C%0A%5Cend%7Balign%7D&amp;amp;height=98&amp;amp;width=346&quot;/&gt;&lt;/p&gt;
&lt;p&gt;如上公式中的 &lt;img src=&quot;https://cdn.nlark.com/yuque/__latex/ffe9f913124f345732e9f00fa258552e.svg#card=math&amp;amp;code=%5Ceta&amp;amp;height=24&amp;amp;width=8&quot;/&gt; 的定义为&lt;strong&gt;学习率&lt;/strong&gt;，即每次都将该参数的偏导数乘以一个系数再下降，如果学习率选得大，那么迭代次数会更少，学习得会更快，但是有可能会导致跳过最优解，甚至无法收敛，而最终有可能训练时间比更小的学习率的时间更长；如果学习率选得小，那么会增加循环迭代次数，增加模型训练的时间。而如何选择这个学习率，并不是自动的，而是靠经验主义，在训练模型之初人工设定的，像这种靠人工一开始输入而不是学习出来的参数，就叫&lt;strong&gt;超参数&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;在如上的更新参数的过程中，我们每次都全量计算了所有的训练数据集合，在实际应用场景中，为了提高模型训练效率，我们一般不会这样做，而是每次迭代只选择一小部分数据进行计算，那么怎么选取这一小部分呢，我们一般会将训练数据随机打乱，按照窗口大小从前往后遍历，每次都取一小部分数据进行计算，比如假设每次取100条数据，那么第一次我们会取1~100条，第二次回取101~200条，以此类推，直到将训练数据都遍历完。当遍历完了之后很有可能模型还是没有训练好的，那么就再次重新打乱所有训练数据，按照窗口从前往后取数据再进行第二轮训练。所以综上，我们的求最佳参数的过程都是 &lt;strong&gt;按轮 按次&lt;/strong&gt; 重复进行训练的。&lt;/p&gt;
&lt;p&gt;在增加了按轮按次进行了之后，我们的迭代计算公式就需要调整了，如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://cdn.nlark.com/yuque/__latex/a5bcb1b6cf20c48909940346f1a9f6a4.svg#card=math&amp;amp;code=%5Cbegin%7Balign%7D%0Anext%28w_1%29%20%26%20%3D%20w_1%20-%20%5Cfrac%7B%5Ceta%7D%7B%7CB%7C%7D%5Csum_%7Bi%5Cin%20B%7D%28w_1x_1%5Ei%2Bw_2x_2%5Ei%2Bb-y%5Ei%29x_1%5Ei%20%5C%5C%0Anext%28w_2%29%20%26%20%3D%20w_2%20-%20%5Cfrac%7B%5Ceta%7D%7B%7CB%7C%7D%5Csum_%7Bi%5Cin%20B%7D%28w_1x_1%5Ei%2Bw_2x_2%5Ei%2Bb-y%5Ei%29x_2%5Ei%20%5C%5C%0Anext%28b%29%20%26%20%3D%20b%20-%20%5Cfrac%7B%5Ceta%7D%7B%7CB%7C%7D%5Csum_%7Bi%5Cin%20B%7D%28w_1x_1%5Ei%2Bw_2x_2%5Ei%2Bb-y%5Ei%29%20%5C%5C%0A%5Cend%7Balign%7D&amp;amp;height=132&amp;amp;width=365&quot;/&gt;&lt;/p&gt;
&lt;p&gt;如上公式中的 &lt;strong&gt;B&lt;/strong&gt; ，就是对应轮次的选取的样本集合，并且我们将学习率除以了窗口大小，来保证学习率的经验数字不需要随着窗口选择大小而改变。&lt;/p&gt;
&lt;p&gt;最后我们来说一下如何判断模型训练是否结束，一般有两种方法：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;超参数指定训练的轮数和次数，到了次数就结束&lt;/li&gt;
&lt;li&gt;每轮次根据计算出来的损失函数的变化率来判断是否应该结束&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&quot;向量表示&quot;&gt;向量表示&lt;/h2&gt;
&lt;p&gt;我们计算机在执行运算的时候，对矩阵预算是比较友好的，尤其是GPU机器，所以我们在实现模型训练的代码的时候，尽量要用向量(矩阵)计算的方式，而不是用 &lt;code&gt;for&lt;/code&gt; 循环逐个计算。&lt;/p&gt;
&lt;pre class=&quot;python&quot;&gt;
&lt;code&gt;from mxnet import nd
from time import time

# 初始化几个数组
a = nd.ones(1000)
b = nd.ones(1000)
c = nd.zeros(1000)

# 普通操作，通过循环赋值的方式操作
start1 = time()
for i in range(1000):
    c[i] = a[i] + b[i]
end1 = time()

print(&quot;normal time: &quot;, end1-start1)

# 向量操作，利用API一次操作
start2 = time()
d = a + b
end2 = time()

print(&quot;vector oper time: &quot;, end2-start2)&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;该段代码的输出为：&lt;/p&gt;
&lt;pre class=&quot;shell&quot;&gt;
&lt;code&gt;normal time:  0.16321206092834473
vector oper time:  0.0009930133819580078&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;可以看出，普通操作是通过向量操作方式的 &lt;strong&gt;200倍！&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;所以，我们尽可能的将所有数学操作都通过向量表达式来操作，来提高模型训练效率。&lt;/p&gt;
&lt;p&gt;在线性回归的计算式当中，主要是有两个需要计算的数学公式，一个是计算损失函数，一个是计算损失函数的梯度。&lt;/p&gt;
&lt;p&gt;首先用向量来定义训练样本，定义如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://cdn.nlark.com/yuque/__latex/962e2e6189e7fdc677807db4500b93cb.svg#card=math&amp;amp;code=%5Cboldsymbol%20y%20%3D%20%5Cbegin%7Bbmatrix%7D%0Ay_1%20%5C%5C%0Ay_2%20%5C%5C%0A%5Cvdots%20%5C%5C%0Ay_m%20%5C%5C%0A%5Cend%7Bbmatrix%7D%0A%0A%0A%5Cquad%0A%0A%5Cboldsymbol%20X%20%3D%20%5Cbegin%7Bbmatrix%7D%0Ax_1%5E1%20%26%20x_2%5E1%20%26%201%20%5C%5C%0Ax_1%5E2%20%26%20x_2%5E2%20%26%201%20%5C%5C%0A%5Cvdots%20%26%20%5Cvdots%20%26%20%5Cvdots%20%5C%5C%0Ax_1%5Em%20%26%20x_2%5Em%20%26%201%20%5C%5C%0A%0A%5Cend%7Bbmatrix%7D&amp;amp;height=102&amp;amp;width=244&quot;/&gt;&lt;/p&gt;
&lt;p&gt;定义要学习的参数向量为：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://cdn.nlark.com/yuque/__latex/b39cc9d2ba2233f7b1ec82e82b206b06.svg#card=math&amp;amp;code=%5Cboldsymbol%20%5Ctheta%20%3D%20%5Cbegin%7Bbmatrix%7D%0Aw_1%20%5C%5C%0Aw_2%20%5C%5C%0Ab%20%5C%5C%0A%5Cend%7Bbmatrix%7D&amp;amp;height=64&amp;amp;width=77&quot;/&gt;&lt;/p&gt;
&lt;p&gt;那么给定当前参数，计算出来的输出数组的向量计算表达式看起来就很简单了，如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://cdn.nlark.com/yuque/__latex/796cac9f18d8fa1cb7d2871778eab416.svg#card=math&amp;amp;code=%5Chat%7B%5Cboldsymbol%20y%7D%20%3D%20%5Cboldsymbol%20X%20%5Cboldsymbol%20%5Ctheta&amp;amp;height=24&amp;amp;width=56&quot;/&gt;&lt;/p&gt;
&lt;p&gt;然后我们再来看如上线性回归定义的损失函数，原始定义如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://cdn.nlark.com/yuque/__latex/148eafd1902922a3aa175067085cbdc8.svg#card=math&amp;amp;code=%5Cbegin%7Balign%7D%0Aloss%28%5Chat%7By%7D%29%20%0A%26%20%3D%20%7B%5Csum_%7Bi%3D0%7D%5En%28%7Bw_1x_1%5Ei%2Bw_2x_2%5Ei%2Bb-y%5Ei%7D%29%5E2%7D%0A%5Cend%7Balign%7D&amp;amp;height=48&amp;amp;width=272&quot;/&gt;&lt;/p&gt;
&lt;p&gt;调整为向量表达式之后变成如下了：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://cdn.nlark.com/yuque/__latex/68a19bc3251724cd0c280fcdaeed070a.svg#card=math&amp;amp;code=loss%28%5Chat%7B%5Cboldsymbol%20y%7D%29%20%3D%20%28%5Chat%7B%5Cboldsymbol%20y%7D%20-%20%7B%5Cboldsymbol%20y%7D%29%5ET%28%5Chat%7B%5Cboldsymbol%20y%7D%20-%20%7B%5Cboldsymbol%20y%7D%29&amp;amp;height=24&amp;amp;width=186&quot;/&gt;&lt;/p&gt;
&lt;p&gt;然后参数的递归梯度下降的公式也可以用向量公式来替换，先回忆一下原始的定义：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://cdn.nlark.com/yuque/__latex/a5bcb1b6cf20c48909940346f1a9f6a4.svg#card=math&amp;amp;code=%5Cbegin%7Balign%7D%0Anext%28w_1%29%20%26%20%3D%20w_1%20-%20%5Cfrac%7B%5Ceta%7D%7B%7CB%7C%7D%5Csum_%7Bi%5Cin%20B%7D%28w_1x_1%5Ei%2Bw_2x_2%5Ei%2Bb-y%5Ei%29x_1%5Ei%20%5C%5C%0Anext%28w_2%29%20%26%20%3D%20w_2%20-%20%5Cfrac%7B%5Ceta%7D%7B%7CB%7C%7D%5Csum_%7Bi%5Cin%20B%7D%28w_1x_1%5Ei%2Bw_2x_2%5Ei%2Bb-y%5Ei%29x_2%5Ei%20%5C%5C%0Anext%28b%29%20%26%20%3D%20b%20-%20%5Cfrac%7B%5Ceta%7D%7B%7CB%7C%7D%5Csum_%7Bi%5Cin%20B%7D%28w_1x_1%5Ei%2Bw_2x_2%5Ei%2Bb-y%5Ei%29%20%5C%5C%0A%5Cend%7Balign%7D&amp;amp;height=132&amp;amp;width=365&quot;/&gt;&lt;/p&gt;
&lt;p&gt;然后再来看一下新的向量计算方式：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://cdn.nlark.com/yuque/__latex/eb17cd70c914392405752716f0de1376.svg#card=math&amp;amp;code=%5Cbegin%7Balign%7D%0Anext%28%5Cboldsymbol%20%5Ctheta%29%20%26%20%3D%20%5Cboldsymbol%20%5Ctheta%20-%20%5Cfrac%7B%5Ceta%7D%7B%7CB%7C%7D%20%5Cboldsymbol%20X%5ET%20%28%5Chat%7B%5Cboldsymbol%20y%7D%20-%20%7B%5Cboldsymbol%20y%7D%29%20%5C%5C%20%26%20%3D%20%5Cboldsymbol%20%5Ctheta%20-%20%5Cfrac%7B%5Ceta%7D%7B%7CB%7C%7D%20%5Cboldsymbol%20X%5ET%20%28%7B%5Cboldsymbol%20X%7D%7B%5Cboldsymbol%20%5Ctheta%7D%20-%20%7B%5Cboldsymbol%20y%7D%29%0A%5Cend%7Balign%7D&amp;amp;height=81&amp;amp;width=230&quot;/&gt;&lt;/p&gt;
&lt;p&gt;这样一来，可以看出，原本来起来还比较复杂的公式一下子看起来就很简单清晰了。&lt;/p&gt;
&lt;p&gt;下面我们就摩拳擦掌，开始来按照向量表示的方式自己从零实现一个线性回归的模型训练吧。&lt;/p&gt;



&lt;h2 id=&quot;构造训练数据&quot;&gt;构造训练数据&lt;/h2&gt;
&lt;p&gt;为了理解简单，我们在实现过程中，演示一个只有两个参数的例子，下面我们首先来构造一下训练数据，具体请参考注释：&lt;/p&gt;
&lt;pre class=&quot;python&quot;&gt;
&lt;code&gt;from mxnet import autograd, nd
import random

true_w = nd.array([[2,-3.4]])
true_b = 4.2
num_inputs = 2
num_examples = 1000

# 生成随机的特征数组
features = nd.random.normal(scale=1, shape=((num_examples, num_inputs)))
# 根据特征数组生成label数组
labels = nd.dot(features, true_w.T) + true_b
# 再给label数组加上一个随机的噪音
labels += nd.random.normal(scale=0.01, shape=labels.shape)&lt;/code&gt;
&lt;/pre&gt;

&lt;h2 id=&quot;定义遍历函数和超参数&quot;&gt;定义遍历函数和超参数&lt;/h2&gt;
&lt;pre class=&quot;python&quot;&gt;
&lt;code&gt;# 我们定义一个按轮按次轮询数据的函数                                                                          
def data_iter(batch_size, X, Y):                                                             
    # 定义一个下标数组并打印出来，并将下标做随机打乱                                                                
    num_inputs = len(X)                                                                      
    indices = list(range(num_inputs))                                                        
    random.shuffle(indices)                                                                  
    # 每次都从下标数组中取一个 batch_size 窗口大小的数据出来                                                      
    for i in range(0, num_inputs, batch_size):                                               
        cur_indices = nd.array(indices[i:min(i+batch_size, num_inputs)])                     
        yield X.take(cur_indices), Y.take(cur_indices)                                       
                                                                                             
# 定义超参数轮和每轮需要遍历的次                                                                            
# 对训练数据总共遍历多少轮                                                                               
loop_num = 3                                                                                 
# 每轮的小批量的窗口大小                                                                                
batch_size = 10                                                                              
# 梯度下降的学习率                                                                                   
learn_rate = 0.5                                                                             
                                                                                             
# 定义我们要学习的参数并做随机初始化, shape (3, 1)                                                            
W = nd.random.normal(scale=1, shape=(num_features+1, 1))                                     &lt;/code&gt;
&lt;/pre&gt;

&lt;h2 id=&quot;开始训练&quot;&gt;开始训练&lt;/h2&gt;
&lt;pre class=&quot;python&quot;&gt;
&lt;code&gt;start_time = time()
for epoch_num in range(loop_num):
    for batchX, batchY in data_iter(batch_size, X, Y):
        # 按照上面向量表示的梯度下降参数执行
        W[:] = W - (learn_rate / batch_size) * nd.dot(batchX.T, nd.dot(batchX, W) - batchY)
end_time = time()

# 打印最初的初始值和训练出来的值
print(&quot;train time: &quot;, end_time-start_time)
print(true_W, W)&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;到此为止，我们的线性回归实现就完成了，该脚本的实现输出为：&lt;/p&gt;
&lt;pre class=&quot;shell&quot;&gt;
&lt;code&gt;train time:  0.09574174880981445

[[2.1]
 [3.7]
 [1.2]]
&amp;lt;NDArray 3x1 @cpu(0)&amp;gt;
[[2.1006684]
 [3.6992905]
 [1.1961068]]
&amp;lt;NDArray 3x1 @cpu(0)&amp;gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;可以看到针对一个1000条数据的训练过程还是很快的，只需要不到 &lt;code&gt;0.1&lt;/code&gt; 秒就训练完了，同时训练出来的结果跟一开始构造数据的参数是几乎相同的。&lt;/p&gt;
&lt;p&gt;下面，我们引入mxnet的自动求梯度的机制，利用这个机制，我们甚至可以不用了解损失函数求导的过程，只需要通过 &lt;code&gt;mxnet&lt;/code&gt; 提供的API接口计算出损失函数，然后 &lt;code&gt;mxnet&lt;/code&gt; 就能自动推导出要计算的参数的梯度。&lt;/p&gt;
&lt;p&gt;虽然用在线性回归上是有点大材小用了，但是对一些比较复杂的数学模型（比如深度学习），这个机制就会显得非常有用了，大大提高了我们代码的编写效率。&lt;br/&gt; &lt;br/&gt;&lt;/p&gt;
&lt;h2 id=&quot;利用mxnet的自动求梯度&quot;&gt;利用mxnet的自动求梯度&lt;/h2&gt;
&lt;pre class=&quot;python&quot;&gt;
&lt;code&gt;# 我们按照mxnet自动求梯度的接口先调用attach_grad()函数对要求梯度的矩阵/向量进行标记
W.attach_grad()
start_time = time()
for epoch_num in range(loop_num):
    for batchX, batchY in data_iter(batch_size, X, Y):
        # 在这个标记片段内所有计算操作都会被记录下来并针对标记的参数求梯度
        with autograd.record():
            # 计算损失函数
            batchY_hat = nd.dot(batchX, W)
            loss = (batchY_hat - batchY)**2/2
        # 针对损失函数求梯度, 经过这个函数之后，后面就可以一共W.grad来获取此次计算针对W的梯度了
        loss.backward()
        # 然后将参数按照梯度进行下降
        W[:] = W - (learn_rate / batch_size) * W.grad

end_time = time()

# 打印最初的初始值和训练出来的值
print(&quot;train time: &quot;, end_time-start_time)
print(true_W, W)&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;这段代码的输出如下：&lt;/p&gt;
&lt;pre class=&quot;shell&quot;&gt;
&lt;code&gt;train time:  0.19647645950317383

[[2.1]
 [3.7]
 [1.2]]
&amp;lt;NDArray 3x1 @cpu(0)&amp;gt;
[[2.102761 ]
 [3.701326 ]
 [1.1980474]]
&amp;lt;NDArray 3x1 @cpu(0)&amp;gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;看起来代码要更复杂一些了，训练效率也要低一些了，下降了差不多一倍，训练参数的结果是差不多的，主要的好处是对将来的更复杂的模型打下了代码实现的基础。&lt;/p&gt;

&lt;h2 id=&quot;加上中间输出&quot;&gt;加上中间输出&lt;/h2&gt;
&lt;p&gt;我们在如下的代码中，加上了一些中间输出结果，来方便我们下一步来调试不同的超参数对模型训练过程的影响：&lt;/p&gt;
&lt;pre class=&quot;python&quot;&gt;
&lt;code&gt;#  求线性回归的损失函数
def get_loss(X, Y, W):
    YHat = nd.dot(X, W)
    return (YHat - Y)**2/2
  
# 我们按照mxnet自动求梯度的接口先调用attach_grad()函数对要求梯度的矩阵/向量进行标记
W.attach_grad()
start_time = time()
for epoch_num in range(loop_num):
    cur_batch_num = 0
    for batchX, batchY in data_iter(batch_size, X, Y):
        # 在这个标记片段内所有计算操作都会被记录下来并针对标记的参数求梯度
        with autograd.record():
            # 计算损失函数
            loss = get_loss(batchX, batchY, W)
        # 针对损失函数求梯度, 经过这个函数之后，后面就可以一共W.grad来获取此次计算针对W的梯度了
        loss.backward()
        # 然后将参数按照梯度进行下降
        W[:] = W - (learn_rate / batch_size) * W.grad

        cur_batch_num+=1
        loss = get_loss(batchX, batchY, W)
        if(cur_batch_num%50 == 0):
            print(&quot;epoch_num: %d, batch_num: %d, loss: %f&quot; %
                    (epoch_num, cur_batch_num, loss.mean().asnumpy()))
    # 打印一些训练过程中的信息
    cur_loss = get_loss(X, Y, W)
    print(&quot;## epoch_num: %d, loss: %f\n&quot; % (epoch_num, cur_loss.mean().asnumpy()))
end_time = time()

# 打印最初的初始值和训练出来的值
print(&quot;train time: &quot;, end_time-start_time)
print(true_W, W)&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;我们再来看看这个代码的输出：&lt;/p&gt;
&lt;pre class=&quot;shell&quot;&gt;
&lt;code&gt;epoch_num: 0, batch_num: 50, loss: 0.000046
epoch_num: 0, batch_num: 100, loss: 0.000050
## epoch_num: 0, loss: 0.000052

epoch_num: 1, batch_num: 50, loss: 0.000061
epoch_num: 1, batch_num: 100, loss: 0.000029
## epoch_num: 1, loss: 0.000062

epoch_num: 2, batch_num: 50, loss: 0.000052
epoch_num: 2, batch_num: 100, loss: 0.000022
## epoch_num: 2, loss: 0.000053

train time:  0.2802696228027344

[[2.1]
 [3.7]
 [1.2]]
&amp;lt;NDArray 3x1 @cpu(0)&amp;gt;
[[2.1014354]
 [3.6990693]
 [1.1987416]]
&amp;lt;NDArray 3x1 @cpu(0)&amp;gt;&lt;/code&gt;
&lt;/pre&gt;

&lt;h2 id=&quot;不同超参数对训练过程的影响&quot;&gt;不同超参数对训练过程的影响&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;学习率&lt;/strong&gt;&lt;br/&gt;固定 轮次：3， 小批量窗口 10&lt;br/&gt;我们来看不同的学习率对训练过程的影响，如下表：&lt;/p&gt;
&lt;table&gt;&lt;thead/&gt;&lt;tbody&gt;&lt;tr class=&quot;odd&quot;&gt;&lt;td&gt;0.01&lt;/td&gt;
&lt;td&gt;1.89&lt;/td&gt;
&lt;td&gt;0.26&lt;/td&gt;
&lt;td&gt;0.03&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;even&quot;&gt;&lt;td&gt;0.02&lt;/td&gt;
&lt;td&gt;0.156179&lt;/td&gt;
&lt;td&gt;0.003019&lt;/td&gt;
&lt;td&gt;0.000111&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;odd&quot;&gt;&lt;td&gt;0.03&lt;/td&gt;
&lt;td&gt;0.027368&lt;/td&gt;
&lt;td&gt;0.000096&lt;/td&gt;
&lt;td&gt;0.000049&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;even&quot;&gt;&lt;td&gt;0.05&lt;/td&gt;
&lt;td&gt;0.000423&lt;/td&gt;
&lt;td&gt;0.000045&lt;/td&gt;
&lt;td&gt;0.000045&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;odd&quot;&gt;&lt;td&gt;0.1&lt;/td&gt;
&lt;td&gt;0.000051&lt;/td&gt;
&lt;td&gt;0.000050&lt;/td&gt;
&lt;td&gt;0.000051&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;even&quot;&gt;&lt;td&gt;0.5&lt;/td&gt;
&lt;td&gt;0.000054&lt;/td&gt;
&lt;td&gt;0.000065&lt;/td&gt;
&lt;td&gt;0.000055&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;odd&quot;&gt;&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;0.000073&lt;/td&gt;
&lt;td&gt;0.000081&lt;/td&gt;
&lt;td&gt;0.000107&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;even&quot;&gt;&lt;td&gt;1.5&lt;/td&gt;
&lt;td&gt;0.000081&lt;/td&gt;
&lt;td&gt;0.000101&lt;/td&gt;
&lt;td&gt;0.000296&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;odd&quot;&gt;&lt;td&gt;1.8&lt;/td&gt;
&lt;td&gt;0.001779&lt;/td&gt;
&lt;td&gt;0.001116&lt;/td&gt;
&lt;td&gt;0.001254&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;even&quot;&gt;&lt;td&gt;1.9&lt;/td&gt;
&lt;td&gt;22.656252&lt;/td&gt;
&lt;td&gt;8493858816&lt;/td&gt;
&lt;td&gt;4272635665084055552&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;odd&quot;&gt;&lt;td&gt;2.0&lt;/td&gt;
&lt;td&gt;35379048448&lt;/td&gt;
&lt;td&gt;nan&lt;/td&gt;
&lt;td&gt;nan&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;从如上表我们可以得出如下的结论：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;在学习率数值较小的一段范围内，学习率越大，模型收敛得就越快，理论上最终模型的模拟效果会越好&lt;/li&gt;
&lt;li&gt;在学习率数值适中的一段范围内，最终学习效果都差不多&lt;/li&gt;
&lt;li&gt;当学习率数值较大的范围内，效果反而更不可控了，甚至到最后损失函数的值都超过了整数范围值&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;所以学习率千万不能设置得太大，设置太大之后不收敛了；设置太小模型还是能收敛只是训练时间要更长，最好是要选择得适中，比如在我们的实现例子中， &lt;code&gt;0.05&lt;/code&gt; 就是一个不错的case。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;小批量窗口&lt;/strong&gt;&lt;br/&gt;固定学习率0.05，选择不同的小批量窗口对应的结果如下：&lt;/p&gt;
&lt;table&gt;&lt;thead/&gt;&lt;tbody&gt;&lt;tr class=&quot;odd&quot;&gt;&lt;td&gt;10&lt;/td&gt;
&lt;td&gt;0.000288&lt;/td&gt;
&lt;td&gt;0.000047&lt;/td&gt;
&lt;td&gt;0.000047&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;even&quot;&gt;&lt;td&gt;20&lt;/td&gt;
&lt;td&gt;0.076830&lt;/td&gt;
&lt;td&gt;0.000432&lt;/td&gt;
&lt;td&gt;0.000048&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;odd&quot;&gt;&lt;td&gt;50&lt;/td&gt;
&lt;td&gt;0.759479&lt;/td&gt;
&lt;td&gt;0.098075&lt;/td&gt;
&lt;td&gt;0.012729&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;可以看到，在合适范围内，窗口值越小就收敛得越快。&lt;/p&gt;


&lt;p&gt;虽然我们在如上的代码中实现线性回归的逻辑已经很简单了，但是我们还是自己写了不少的一些函数，比如我们自己实现了数据遍历的函数，自己实现了损失计算函数，自己实现了梯度下降等逻辑。&lt;/p&gt;
&lt;p&gt;而实际上一些通用的深度学习基础库，比如 &lt;code&gt;mxnet&lt;/code&gt; 已经为我们预先实现了很多常用的函数库了，我们可以直接调用他们的服务来重新实现一个线性回归训练脚本。&lt;/p&gt;
&lt;p&gt;并且在这个实现中，我们会按照典型的训练模型的代码框架来实现线性回归的训练，按照这个代码框架，即使后面我们实现更复杂的深度学习的多层神经网络模型的时候，代码看起来都是类似的。&lt;/p&gt;
&lt;pre class=&quot;python&quot;&gt;
&lt;code&gt;from mxnet import autograd, nd
import random

# 构造数据
true_w = nd.array([[2,-3.4]])
true_b = 4.2
num_inputs = 2
num_examples = 1000

# 生成随机的特征数组
features = nd.random.normal(scale=1, shape=((num_examples, num_inputs)))
# 根据特征数组生成label数组
labels = nd.dot(features, true_w.T) + true_b
# 再给label数组加上一个随机的噪音
labels += nd.random.normal(scale=0.01, shape=labels.shape)

# 引入gluon的管理训练集的库
from mxnet.gluon import data as gdata

batch_size = 10
# 将样本的特征值和标签值都传入
dataset = gdata.ArrayDataset(features, labels)
# 利用gdata提供的数据抽取小批量遍历函数指针
data_iter = gdata.DataLoader(dataset, batch_size, shuffle=True)

# 接下来将是最主要的区别，在手动实现中，我们自己实现了线性函数和损失函数
# 而gluon当中提供了一系列默认的函数，可以快速的模型训练
# 第一步，搭建一个神经网络, 虽然我们现在的神经网络还很简单，只有一层
from mxnet.gluon import nn
net = nn.Sequential()
net.add(nn.Dense(1))

# 第二步，将参数矩阵给初始化好
from mxnet import init
net.initialize(init.Normal(sigma=0.01))

# 定义损失函数
from mxnet.gluon import loss as gloss
loss = gloss.L2Loss()

# 定义参数梯度下降的函数
from mxnet import gluon
trainer = gluon.Trainer(net.collect_params(), 'sgd', {'learning_rate': 0.03})

# 开始训练, 跟手动实现的就很相似了
num_epochs = 3
for epoch in range(1, num_epochs + 1):
    for X, y in data_iter:
        with autograd.record():
            l = loss(net(X), y)
        l.backward()
        trainer.step(batch_size)
    l = loss(net(features), labels)
    print('epoch %d, loss: %f' % (epoch, l.mean().asnumpy()))

# 对比训练出来的值的效果
dense = net[0]
print(true_w, dense.weight.data())
print(true_b, dense.bias.data())&lt;/code&gt;
&lt;/pre&gt;</description>
<pubDate>Sat, 27 Apr 2019 13:11:00 +0000</pubDate>
<dc:creator>玄苦</dc:creator>
<og:description>线性回归 理论 线性回归最简单和最经典的机器学习模型之一。 任何一个机器学习模型都会有如下4个要素： 1. 训练数据 1. 数学模型 1. 损失函数 1. 计算方法 训练数据 下面先阐述一下训练数据的</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/xuanku/p/dl_linear.html</dc:identifier>
</item>
<item>
<title>浅谈.Net异步编程的前世今生----APM篇 - Wackysoft</title>
<link>http://www.cnblogs.com/wackysoft/p/10777264.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/wackysoft/p/10777264.html</guid>
<description>&lt;p&gt;&lt;span&gt;&lt;strong&gt;前言&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;在.Net程序开发过程中，我们经常会遇到如下场景：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;编写WinForm程序客户端，需要查询数据库获取数据，于是我们根据需求写好了代码后，点击查询，发现界面卡死，无法响应。经过调试，发现查询数据库这一步执行了很久，在此过程中，UI被阻塞，无法响应任何操作。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;如何解决此问题？我们需要分析问题成因：在WinForm窗体运行时，只有一个主线程，即为UI线程，UI线程在此过程中既负责渲染界面，又负责查询数据，因此在大量耗时的操作中，UI线程无法及时响应导致出现问题。此时我们需要将耗时操作放入异步操作，使主线程继续响应用户的操作，这样可以大大提升用户体验。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;直接编写异步编程也许不是一件轻松的事，和同步编程不同的是，异步代码并不是始终按照写好的步骤执行，且如何在异步执行完通知前序步骤也是其中一个问题，因此会带来一系列的考验。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;幸运的是，在.Net Framework中，提供了多种异步编程模型以及相关的API，这些模型的存在使得编写异步程序变得容易上手。随着Framework的不断升级，相应的模型也在不断改进，下面我们一起来回顾一下.Net异步编程的前世今生。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;第一个异步编程模型：APM&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;概述&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;APM，全称Asynchronous Programing Model，顾名思义，它即为异步编程模型，最早出现于.Net Framework 1.x中。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;它使用IAsyncResult设计模式的异步操作，一般由BeginOperationName和EndOperationName两个方法实现，这两个方法分别用于开始和结束异步操作，例如FileStream类中提供了BeginRead和EndRead来对文件进行异步字节读取操作。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;使用&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;在程序运行过程中，直接调用BeginOperationName后，会将所包含的方法放入异步操作，并返回一个IAsyncResult结果，同时异步操作在另外一个线程中执行。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;每次在调用BeginOperationName方法后，还应调用EndOperationName方法，来获取异步执行的结果，下面我们一起来看一个示例：&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;36&quot;&gt;
&lt;pre&gt;
&lt;span&gt;using&lt;/span&gt;&lt;span&gt; System;
&lt;/span&gt;&lt;span&gt;using&lt;/span&gt;&lt;span&gt; System.Collections.Generic;
&lt;/span&gt;&lt;span&gt;using&lt;/span&gt;&lt;span&gt; System.Linq;
&lt;/span&gt;&lt;span&gt;using&lt;/span&gt;&lt;span&gt; System.Text;
&lt;/span&gt;&lt;span&gt;using&lt;/span&gt;&lt;span&gt; System.Threading;
&lt;/span&gt;&lt;span&gt;using&lt;/span&gt;&lt;span&gt; System.Threading.Tasks;

&lt;/span&gt;&lt;span&gt;namespace&lt;/span&gt;&lt;span&gt; APMTest
{
    &lt;/span&gt;&lt;span&gt;class&lt;/span&gt;&lt;span&gt; Program
    {
        &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;delegate&lt;/span&gt; &lt;span&gt;void&lt;/span&gt;&lt;span&gt; ConsoleDelegate();

        &lt;/span&gt;&lt;span&gt;static&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; Main(&lt;span&gt;string&lt;/span&gt;&lt;span&gt;[] args)
        {
            ConsoleDelegate consoleDelegate &lt;/span&gt;= &lt;span&gt;new&lt;/span&gt;&lt;span&gt; ConsoleDelegate(ConsoleToUI);
            Thread.CurrentThread.Name &lt;/span&gt;= &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;主线程Thread&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;;
            IAsyncResult ar &lt;/span&gt;= consoleDelegate.BeginInvoke(&lt;span&gt;null&lt;/span&gt;, &lt;span&gt;null&lt;/span&gt;&lt;span&gt;);
            consoleDelegate.EndInvoke(ar);
            Console.WriteLine(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;我是同步输出，我的名字是：&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; +&lt;span&gt; Thread.CurrentThread.Name);
            Console.Read();
        }

        &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; &lt;span&gt;void&lt;/span&gt;&lt;span&gt; ConsoleToUI()
        {
            &lt;/span&gt;&lt;span&gt;if&lt;/span&gt;&lt;span&gt; (Thread.CurrentThread.IsThreadPoolThread)
            {
                Thread.CurrentThread.Name &lt;/span&gt;= &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;线程池Thread&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;;
            }
            &lt;/span&gt;&lt;span&gt;else&lt;/span&gt;&lt;span&gt;
            {
                Thread.CurrentThread.Name &lt;/span&gt;= &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;普通Thread&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;;
            }
            Thread.Sleep(&lt;/span&gt;&lt;span&gt;3000&lt;/span&gt;); &lt;span&gt;//&lt;/span&gt;&lt;span&gt;模拟耗时操作&lt;/span&gt;
            Console.WriteLine(&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;我是异步输出，我的名字是：&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; +&lt;span&gt; Thread.CurrentThread.Name);
        }
    }
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span&gt;在这段示例中，我们定义了一个委托来使用其BeginInvoke/EndInvoke方法用于我们自定义方法的异步执行，同时将线程名称打印出来，用于区分主线程与异步线程。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;如代码中所示，在调用BeginInvoke之后，立即调用了EndInvoke获取结果，那么会发生什么呢？&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;如下图所示：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/443744/201904/443744-20190427203709979-1781108818.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;看到这里大家也许会比较诧异：为什么同步操作会在异步操作之后输出呢？这样不是和同步就一样了吗？&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;原因是这样的：EndInvoke方法会阻塞调用线程，直到异步调用结束，由于我们在异步操作中模拟了3s耗时操作，所以它会一直等待到3s结束后输出异步信息，此时才完成了异步操作，进而进行下一步的同步操作。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;同时在BeginInvoke返回的IAynscResult中，包含如下属性：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/443744/201904/443744-20190427200036444-1815701380.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;通过轮询IsCompleted属性或使用AsyncWaitHandle属性，均可以获取异步操作是否完成，从而进行下一步操作，相关代码如下所示：&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;36&quot;&gt;
&lt;pre&gt;
&lt;span&gt;using&lt;/span&gt;&lt;span&gt; System;
&lt;/span&gt;&lt;span&gt;using&lt;/span&gt;&lt;span&gt; System.Collections.Generic;
&lt;/span&gt;&lt;span&gt;using&lt;/span&gt;&lt;span&gt; System.Linq;
&lt;/span&gt;&lt;span&gt;using&lt;/span&gt;&lt;span&gt; System.Text;
&lt;/span&gt;&lt;span&gt;using&lt;/span&gt;&lt;span&gt; System.Threading;
&lt;/span&gt;&lt;span&gt;using&lt;/span&gt;&lt;span&gt; System.Threading.Tasks;

&lt;/span&gt;&lt;span&gt;namespace&lt;/span&gt;&lt;span&gt; APMTest
{
    &lt;/span&gt;&lt;span&gt;class&lt;/span&gt;&lt;span&gt; Program
    {
        &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;delegate&lt;/span&gt; &lt;span&gt;void&lt;/span&gt;&lt;span&gt; ConsoleDelegate();

        &lt;/span&gt;&lt;span&gt;static&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; Main(&lt;span&gt;string&lt;/span&gt;&lt;span&gt;[] args)
        {
            ConsoleDelegate consoleDelegate &lt;/span&gt;= &lt;span&gt;new&lt;/span&gt;&lt;span&gt; ConsoleDelegate(ConsoleToUI);
            Thread.CurrentThread.Name &lt;/span&gt;= &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;主线程Thread&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;;
            IAsyncResult ar &lt;/span&gt;= consoleDelegate.BeginInvoke(&lt;span&gt;null&lt;/span&gt;, &lt;span&gt;null&lt;/span&gt;&lt;span&gt;);
            &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;此处改为了轮询IsCompleted属性，AsyncWaitHandle属性同理&lt;/span&gt;
            &lt;span&gt;while&lt;/span&gt; (!&lt;span&gt;ar.IsCompleted)
            {
                Console.WriteLine(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;等待执行...&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;);
            }
            consoleDelegate.EndInvoke(ar);
            Console.WriteLine(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;我是同步输出，我的名字是：&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; +&lt;span&gt; Thread.CurrentThread.Name);
            Console.Read();
        }

        &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; &lt;span&gt;void&lt;/span&gt;&lt;span&gt; ConsoleToUI()
        {
            &lt;/span&gt;&lt;span&gt;if&lt;/span&gt;&lt;span&gt; (Thread.CurrentThread.IsThreadPoolThread)
            {
                Thread.CurrentThread.Name &lt;/span&gt;= &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;线程池Thread&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;;
            }
            &lt;/span&gt;&lt;span&gt;else&lt;/span&gt;&lt;span&gt;
            {
                Thread.CurrentThread.Name &lt;/span&gt;= &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;普通Thread&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;;
            }
            Thread.Sleep(&lt;/span&gt;&lt;span&gt;3000&lt;/span&gt;); &lt;span&gt;//&lt;/span&gt;&lt;span&gt;模拟耗时操作&lt;/span&gt;
            Console.WriteLine(&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;我是异步输出，我的名字是：&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; +&lt;span&gt; Thread.CurrentThread.Name);
        }
    }
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span&gt;运行后结果如下：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/443744/201904/443744-20190427203752109-1226594479.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;可以发现，在轮询属性时，程序仍然会等待异步操作完成，进而进行下一步的同步输出，无法达到我们需要的效果，那么究竟有没有办法解决呢？&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;此时我们需要引入一个新方法：使用回调。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;在之前的操作中，使用BeginInvoke方法，两个参数总传入的为null。若要使用回调机制，则需传入一个类型为AsyncCallback的回调函数，并在最后一个参数中，传入需要使用的参数，如以下代码所示：&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;37&quot;&gt;
&lt;pre&gt;
&lt;span&gt;using&lt;/span&gt;&lt;span&gt; System;
&lt;/span&gt;&lt;span&gt;using&lt;/span&gt;&lt;span&gt; System.Collections.Generic;
&lt;/span&gt;&lt;span&gt;using&lt;/span&gt;&lt;span&gt; System.Linq;
&lt;/span&gt;&lt;span&gt;using&lt;/span&gt;&lt;span&gt; System.Text;
&lt;/span&gt;&lt;span&gt;using&lt;/span&gt;&lt;span&gt; System.Threading;
&lt;/span&gt;&lt;span&gt;using&lt;/span&gt;&lt;span&gt; System.Threading.Tasks;

&lt;/span&gt;&lt;span&gt;namespace&lt;/span&gt;&lt;span&gt; APMTest
{
    &lt;/span&gt;&lt;span&gt;class&lt;/span&gt;&lt;span&gt; Program
    {
        &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;delegate&lt;/span&gt; &lt;span&gt;void&lt;/span&gt;&lt;span&gt; ConsoleDelegate();

        &lt;/span&gt;&lt;span&gt;static&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; Main(&lt;span&gt;string&lt;/span&gt;&lt;span&gt;[] args)
        {
            ConsoleDelegate consoleDelegate &lt;/span&gt;= &lt;span&gt;new&lt;/span&gt;&lt;span&gt; ConsoleDelegate(ConsoleToUI);
            Thread.CurrentThread.Name &lt;/span&gt;= &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;主线程Thread&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;;
            &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;此处传入AsyncCallback类型的回调函数，并传入需要使用的参数&lt;/span&gt;
&lt;span&gt;            consoleDelegate.BeginInvoke(CallBack, consoleDelegate);
            &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;IAsyncResult ar = consoleDelegate.BeginInvoke(null, null);&lt;/span&gt;
            &lt;span&gt;///&lt;/span&gt;&lt;span&gt;/此处改为了轮询IsCompleted属性，AsyncWaitHandle属性同理&lt;/span&gt;
            &lt;span&gt;//&lt;/span&gt;&lt;span&gt;while (!ar.IsCompleted)
            &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;{
            &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;    Console.WriteLine(&quot;等待执行...&quot;);
            &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;}
            &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;consoleDelegate.EndInvoke(ar);&lt;/span&gt;
            Console.WriteLine(&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;我是同步输出，我的名字是：&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; +&lt;span&gt; Thread.CurrentThread.Name);
            Console.Read();
        }

        &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; &lt;span&gt;void&lt;/span&gt;&lt;span&gt; ConsoleToUI()
        {
            &lt;/span&gt;&lt;span&gt;if&lt;/span&gt;&lt;span&gt; (Thread.CurrentThread.IsThreadPoolThread)
            {
                Thread.CurrentThread.Name &lt;/span&gt;= &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;线程池Thread&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;;
            }
            &lt;/span&gt;&lt;span&gt;else&lt;/span&gt;&lt;span&gt;
            {
                Thread.CurrentThread.Name &lt;/span&gt;= &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;普通Thread&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;;
            }
            Thread.Sleep(&lt;/span&gt;&lt;span&gt;3000&lt;/span&gt;); &lt;span&gt;//&lt;/span&gt;&lt;span&gt;模拟耗时操作&lt;/span&gt;
            Console.WriteLine(&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;我是异步输出，我的名字是：&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; +&lt;span&gt; Thread.CurrentThread.Name);
        }

        &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; &lt;span&gt;void&lt;/span&gt;&lt;span&gt; CallBack(IAsyncResult ar)
        {
            &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;使用IAsyncResult的AsyncState获取BeginInvoke中的参数，并用于执行EndInvoke&lt;/span&gt;
            ConsoleDelegate callBackDelegate = ar.AsyncState &lt;span&gt;as&lt;/span&gt;&lt;span&gt; ConsoleDelegate;
            callBackDelegate.EndInvoke(ar);
        }
    }
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span&gt;运行后结果如下：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/443744/201904/443744-20190427203841951-1187372289.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;此时可以看出，使用回调的方式已经实现了我们需要的效果。在同步执行时，将耗时操作放入异步操作，从而不影响同步操作的继续执行，在异步操作完成后，回调返回相应的结果。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;小结&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;APM模型的引入，使得编写异步程序变的如此简单，只需定义委托，将要执行的方法包含其中，并调用Begin/End方法对，即可实现异步编程。在一些基础类库中，也已经提供了异步操作的方法，直接调用即可。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;同时我们可以看到，BeginInvoke方法，实际上是调用了线程池中的线程进行操作，因此APM模型也应属于多线程程序，同时包含主线程与线程池线程。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;但是APM模型也存在一些缺点：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;1、若不使用回调机制，则需等待异步操作完成后才能继续执行，此时未达到异步操作的效果。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;2、在异步操作的过程中，无法取消，也无法得知操作进度。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;3、若编写GUI程序，异步操作内容与主线程未在同一线程，操作控件时会引起线程安全问题。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;为了解决这些缺陷，微软推出了其他的异步模式，预知后事如何，且听下回分解。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;下集预告&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;浅谈.Net异步编程的前世今生----EAP篇&lt;/span&gt;&lt;/p&gt;
</description>
<pubDate>Sat, 27 Apr 2019 12:58:00 +0000</pubDate>
<dc:creator>Wackysoft</dc:creator>
<og:description>前言 在.Net程序开发过程中，我们经常会遇到如下场景： 编写WinForm程序客户端，需要查询数据库获取数据，于是我们根据需求写好了代码后，点击查询，发现界面卡死，无法响应。经过调试，发现查询数据库</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/wackysoft/p/10777264.html</dc:identifier>
</item>
<item>
<title>大白话5分钟带你走进人工智能-第十四节过拟合解决手段L1和L2正则 - LHBlog</title>
<link>http://www.cnblogs.com/LHWorldBlog/p/10780266.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/LHWorldBlog/p/10780266.html</guid>
<description>&lt;p&gt;&lt;span&gt;&lt;strong&gt;                                                                                                  第十四节过拟合解决手段L1和L2正则&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;第十三节中，我们讲解了过拟合的情形，也就是过度的去拟合训练集上的结果了，反倒让你的模型太复杂。为了去解决这种现象，我们提出用L1，L2正则去解决这种问题。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;strong&gt;怎么把正则应用进去？&lt;/strong&gt;&lt;/strong&gt;我们重新审视目标函数，以前我们可以理解目标函数和损失函数是一个东西。&lt;strong&gt;而有正则的含义之后，目标函数就不再是损失函数了，而是损失函数加惩罚项&lt;/strong&gt;。而这个惩罚项听起来好像是一个Optionally，一个可选项，但并不是，通常一定要加惩罚项，否则你训练出来模型极有可能是过拟合的。所以通常惩罚项是一定要加的，以前总讲线性回归一定要回归，一定要把损失函数降到最低，到今天你应该深刻地烙印在脑子里，&lt;strong&gt;它要降到最低的不光是损失函数，而是目标函数&lt;/strong&gt;。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;首先我们回忆机器学习的流程，先建立一个目标函数（在线性回归里面怎么建立的目标函数？ 最大似然），然后找到使目标函数最小的一组W，就是我们要求的W。这一节以后我们目标函数变一变之前咱们说的线性回归的目标函数是：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;                                                       &lt;img class=&quot;mathcode&quot; src=&quot;https://private.codecogs.com/gif.latex?J%28%5Ctheta%29%3D%5Cfrac%7B1%7D%7B2%7D%20%5Csum_%7Bi%3D1%7D%5E%7Bm%7D%5Cleft%28h_%7B%5Ctheta%7D%5Cleft%28x%5E%7B%28i%29%7D%5Cright%29-y%5E%7B%28i%29%7D%5Cright%29%5E%7B2%7D&quot; alt=&quot;J(\theta)=\frac{1}{2} \sum_{i=1}^{m}\left(h_{\theta}\left(x^{(i)}\right)-y^{(i)}\right)^{2}&quot; data-cke-saved-src=&quot;https://private.codecogs.com/gif.latex?J%28%5Ctheta%29%3D%5Cfrac%7B1%7D%7B2%7D%20%5Csum_%7Bi%3D1%7D%5E%7Bm%7D%5Cleft%28h_%7B%5Ctheta%7D%5Cleft%28x%5E%7B%28i%29%7D%5Cright%29-y%5E%7B%28i%29%7D%5Cright%29%5E%7B2%7D&quot; data-cke-widget-data=&quot;{}&quot; data-cke-widget-upcasted=&quot;1&quot;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;其实这并不是完整版的目标函数，我们实际优化的也不光是它，而是变成了&lt;strong&gt;两项，损失项加上λ的正则项，&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;                                                                              &lt;img class=&quot;mathcode&quot; src=&quot;https://private.codecogs.com/gif.latex?%24%5Coperatorname%7BObj%7D%28%5Ctheta%29%3DL%28%5Ctheta%29&amp;amp;plus;%5Clambda%20%5COmega%28%5Ctheta%29%24&quot; alt=&quot;$\operatorname{Obj}(\theta)=L(\theta)+\lambda \Omega(\theta)$&quot; data-cke-saved-src=&quot;https://private.codecogs.com/gif.latex?%24%5Coperatorname%7BObj%7D%28%5Ctheta%29%3DL%28%5Ctheta%29&amp;amp;plus;%5Clambda%20%5COmega%28%5Ctheta%29%24&quot; data-cke-widget-data=&quot;{}&quot; data-cke-widget-upcasted=&quot;1&quot;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;这个λ跟刚才学习率λ是两个不同的超参数。我们&lt;strong&gt;损失项的意义是要让训练集上的误差尽量小，而正则项的意义是让模型尽量简单，防止过拟合&lt;/strong&gt;。&lt;strong&gt;目标函数其实就是损失函数和正则项线性相加&lt;/strong&gt;，之前讲的目标函数只讲了损失项，损失项指的是什么？指的是我们的损失函数，虽然到目前为止我们只讲了一个MSE损失函数，但实际上你应该举一反三，虽然你不知道其它损失函数长什么样，但你知道会有各种各样的损失函数，只要这个损失函数降到最低了，我们这会儿运算出来的模型，就是我这个算法得到的最终结果。接下来介绍什么叫正则项，我刚才说的防止它一味的去追求损失函数最低而导致模型变复杂了，我们看目标函数的这么一个形式，&lt;img class=&quot;mathcode&quot; src=&quot;https://private.codecogs.com/gif.latex?%24%5Coperatorname%7BObj%7D%28%5Ctheta%29%3DL%28%5Ctheta%29&amp;amp;plus;%5Clambda%20%5COmega%28%5Ctheta%29%24&quot; alt=&quot;$\operatorname{Obj}(\theta)=L(\theta)+\lambda \Omega(\theta)$&quot; data-cke-saved-src=&quot;https://private.codecogs.com/gif.latex?%24%5Coperatorname%7BObj%7D%28%5Ctheta%29%3DL%28%5Ctheta%29&amp;amp;plus;%5Clambda%20%5COmega%28%5Ctheta%29%24&quot; data-cke-widget-data=&quot;{}&quot; data-cke-widget-upcasted=&quot;1&quot;/&gt;，虽然这么花里胡哨，但最终还是要把它交给SGD的算法去最优化。我机器还是傻乎乎的，你让我最优化损失函数，我就最优化损失函数，你不想让我光追求最优化损失函数，那你交给我点其他的东西，我也会一起帮你优化。我们最终是想让损失函数相对较小的时候，模型也相对简单，所以我们就看着Ω（θ）它应该具有一个什么样的特征？&lt;strong&gt;模型越复杂的时候&lt;/strong&gt;Ω（θ）&lt;strong&gt;会越大，模型也简单的时候&lt;/strong&gt;Ω（θ）&lt;strong&gt;就越小。举个例子来理解相对概念，&lt;/strong&gt;比如当损失项函数的最小值是0.18，结果当0.18的那组θ带到模型评估的函数Ω（θ）里面，发现Ω（θ）值是20，此时是不是模型太复杂了？ 当你损失函数上升了一点，上升到0.19的时候，θ虽然它已经不是最优解了，但此时发现这组θ带入到Ω（θ）里面，20直接降到了5，此时机器会选择哪种模型？第一组θ还是第二组θ？应该是第二组θ，因为它达到了一个在损失函数尽量小的同时，你要让我的模型尽量的简单。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;λ是干嘛的？&lt;strong&gt;λ是评估你到底多看重模型的简单性的&lt;/strong&gt;。假如刚才这个例子，λ设成0.0000001，对它来说你虽然从20减到了5，但是你乘的系数很少，你的简单在它眼里看起来它并不在乎，比如你在公司你自我陶醉一般的做了很多工作，老板可能并不在乎。这就是说你这个模型到底有多看重模型复杂程度的惩罚的。为什么管它叫惩罚项，&lt;strong&gt;正则项也叫惩罚项&lt;/strong&gt;，它是一个惩罚系数，你追求到了损失函数是0.18，但是你把这个模型搞复杂了，我就要惩罚你一下，给你加上一个惩罚项Ω（θ）为20，假如你损失函数是0.19了，你的惩罚性Ω（θ）就变小了，总体的效果会变好，也就是说正则项实际上是达到了一个为了追求损失函数最小而把模型搞复杂了去惩罚的这种情况。 这种情况发生了，我就要惩罚你，我让你损失函数不再是最优的了，就不会最后出现模型给你选出来一个损失函数是最低的，但是复杂度一下上升了好多的这种情况。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;怎么样评估这个模型复不复杂？我们回忆下参数型模型的本质是什么？是不是就那一组W，所以也只能从这一组W上来评估，没别的东西了。所以我们现在来探索评判模型的复杂度的Ω（θ）到底是什么？其实它非常简单，&lt;strong&gt;对于线性模型如何评估复杂程度，通常通过L0范数L1范数和L2范数，范数的值越大，该模型越复杂。&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;咱们讲一下什么叫L0范数，L1范数和L2范数？&lt;strong&gt;L0范数，所有&lt;/strong&gt;&lt;strong&gt;参数&lt;/strong&gt;&lt;strong&gt;W中非零元素的个数&lt;/strong&gt;。比如100个维度里边有80个没有用，它是怎么判定没用的？是不是直接把W调成0了？ 那W里边的零越多，这个模型就越简单，所以非零元素的个数越多，代表模型越复杂，因此L0范数可以作为我刚才Ω（θ）的一个候选人。假如Ω（θ）是L0的话，你有一个W是0.1，你直接给它减成0了，发现损失函数就上升了一点点，但是你就直接少考虑了一个维度，所以能一定程度上阻止你的过拟合，因为这个维度，我彻底不考虑了，这个是L0范数的作用，但是&lt;strong&gt;L0范数不可导&lt;/strong&gt;，不能求导有什么麻烦？梯度下降没法工作。你要想做梯度下降，老得求负梯度，你一求负梯度就发现这个家伙求不了。梯度下降这个东西你用不上了，所以通常我们不用L0范数作为Ω（θ）项。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;         因此Ω（θ）我们改为用L1范数，&lt;strong&gt;L1范数是所有参数的绝对值之和&lt;/strong&gt;&lt;strong&gt;（也称L0的最佳凸近似）&lt;/strong&gt;。&lt;img class=&quot;mathcode&quot; src=&quot;https://private.codecogs.com/gif.latex?%24%5C%7Cw%5C%7C_%7B1%7D%3D%5Csum_%7Bi%3D1%7D%5E%7Bm%7D%5Cleft%7Cw_%7Bi%7D%5Cright%7C%24&quot; alt=&quot;$\|w\|_{1}=\sum_{i=1}^{m}\left|w_{i}\right|$&quot; data-cke-saved-src=&quot;https://private.codecogs.com/gif.latex?%24%5C%7Cw%5C%7C_%7B1%7D%3D%5Csum_%7Bi%3D1%7D%5E%7Bm%7D%5Cleft%7Cw_%7Bi%7D%5Cright%7C%24&quot; data-cke-widget-data=&quot;{}&quot; data-cke-widget-upcasted=&quot;1&quot;/&gt;，这个话理解成它是L0的方便计算的替代品，它能达到跟L0差不多的效果，让大多数没什么用的这些W变为零，但是它又可导，能交给梯度下降来做。 假如损失函数是MSE，加上L1正则后|,你再去优化交给SGD的东西，就不再是原来的MSE函数了，而是MSE+0.1*Σ|W让它一起去做优化，优化出来的结果会是什么样的？ &lt;strong&gt;优化出来的结果会有相当一部分的W变为了0&lt;/strong&gt;。所以通常分类任务也好，回归任务也好,我们说特征太多，这些特征好麻烦，我也不知道哪个有用，哪个没用,你就可以，你直接给他加一个L1范数跑一下，哪些W是零了，那些特征就直接去掉。能够筛选掉那些W为0的特征,一定是没有它也不会引起损失函数巨大上升的那些特征。比如我刚才举那个例子，张三家关没关窗户，对于下雨的影响，它一定本身不大。 你加了一把L1正则训练出来模型之后，就会发现张三家关没关窗户这一列的属性的权重变为了零，如果加了L1正则它还不是零，说明从数据集上来看，这一列就是对下雨影响很大。但是可能发生吗这种事？明显不可能，说明什么？说明你收集的数据绝对不够多。或者你收集的数据不是全部的数据，是张三给你的数据，他一收集就老要打开窗户看下雨，经常会有这种荒唐的事发生。比如你发现你怎么跑模型？ 这个模型效果都不好，很可能是你收集上的这些数据本身就已经被筛选过了。比如你拿你用户数据的时候，你发现有一列的值只有安卓手机能提供给你，iPhone提供不了，所以你的数据就是一个有偏斜的数据，经过一次预筛选了，像我刚才讲的故事，张三一看下雨他就把窗户打开了，因果反制，所以你收集的数据只收集到了他们家开窗户的时候的数据，数据本身是有问题的。&lt;strong&gt;因此我们加上L1正则后，发现一些明显跟你的最终结果不应该有关系的数据还有了关系，那说明这个数据本身有问题。&lt;/strong&gt;这也是一个检验数据的一种方式。&lt;strong&gt;所以通常L1范数是用来做特征选择的。&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;我们对比下L0和L1&lt;/strong&gt;：&lt;strong&gt;L0和L1&lt;/strong&gt;&lt;strong&gt;都可以使参数稀疏&lt;/strong&gt;。所谓稀疏化就是0比1多，假如你给了我200个数，我发现里边只有三个数不为零，你接记下这三个数的大小和三个数的位置就可以存下来了，而不用真把这200个数存下来，这其实是一个稀疏向量。所以&lt;strong&gt;使参数稀疏化，也就让不重要的那些维度的参数归为0，重要的会更偏向为1。&lt;/strong&gt;L1范数比L0范数有一个优点，它是可微可导的，功能又类似，所以只选择L1范数，而基本没有见过用L0范数的，&lt;strong&gt;L1想做的事是尽量的让没用的特征变成零，因此&lt;/strong&gt;&lt;strong&gt;L1的意义是特征选择，与此同时增强了模型的解释性&lt;/strong&gt;，模型解释性是非常重要的一个事儿。 比如有一个业务场景，有一天银行来找到你了，说我们想训练一个模型，做一个客户还款能力的预测，丢给你一堆数据，你最后确实做出来一个模型，我问你这个东西好用不好用，你心里也没底，你去交活的时候，你说我们这400多个特征全用上了，连客户今天穿没穿花衣服都有，你能跟客户交差，说你这模型真有用吗？不能够的，你一定要把参数的量减下来，给她去解释，为什么这个东西在里面，你看这个模型确实让人更放心，让客户也有信心，你权重是高是低还好，你最终八竿子打不着的东西都抄进来了，明显这个模型是有问题的，是有缺陷的。所以模型的解释性不是一个没有意义的事儿，他一定要能解释得通这个东西才敢上线去生产，一定不能跟你的常识都是违背的，如果你发现跟你常识违背的模型，你一定要去经过实验来看看是不是真的有用，如果真有用了，这个东西叫知识发现，代表你发现了一个新的相关的指数，代表你有一个新的知识发现，但大部分情况下八竿子打不着的那些特征，通常一定是没有用的，一定是哪里有错了。你应该去考虑，&lt;strong&gt;所以L1有特征选择和增强模型解释性的功能。&lt;/strong&gt;&lt;strong&gt;如果有些维度被你训练的时候，机器给它加了很大权重，但是只能让损失函数降低一点点，那么很有可能会产生了过拟合现象&lt;/strong&gt;，因此我们要惩罚那些带不来什么提高又浪费了好多资源的这种权重。举个例子，比如你们家本来吃饭空间就有限，一哥们不干活，天天还在你们家吃饭，占用了大量的资源，但最后他也没说没贡献，他每个月贡献给你一毛钱，你觉得这个容忍你还要吗？，你为了挣这一毛钱还不够我给你收拾碗筷的。这个也一样，你为了提升那一点点损失函数，还不够你给我模型增加复杂度的带来的过拟合风险，所以我选择不要这个维度了。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;我们再来讨论下&lt;strong&gt;L2正则，定义是L2范数的平方。&lt;/strong&gt;什么叫L2范数？假如有a，b，它俩的L2范数就是&lt;img class=&quot;mathcode&quot; src=&quot;https://private.codecogs.com/gif.latex?%24%5Csqrt%7Ba%5E%7B2%7D&amp;amp;plus;b%5E%7B2%7D%7D%24&quot; alt=&quot;$\sqrt{a^{2}+b^{2}}$&quot; data-cke-saved-src=&quot;https://private.codecogs.com/gif.latex?%24%5Csqrt%7Ba%5E%7B2%7D&amp;amp;plus;b%5E%7B2%7D%7D%24&quot; data-cke-widget-data=&quot;{}&quot; data-cke-widget-upcasted=&quot;1&quot;/&gt;。假如你有一组W，W的L2范数就是 &lt;img class=&quot;mathcode&quot; src=&quot;https://private.codecogs.com/gif.latex?%24%5Csqrt%7B%5Csum_%7Bi%3D1%7D%5E%7Bn%7D%20w_%7Bi%7D%5E%7B2%7D%7D%24&quot; alt=&quot;$\sqrt{\sum_{i=1}^{n} w_{i}^{2}}$&quot; data-cke-saved-src=&quot;https://private.codecogs.com/gif.latex?%24%5Csqrt%7B%5Csum_%7Bi%3D1%7D%5E%7Bn%7D%20w_%7Bi%7D%5E%7B2%7D%7D%24&quot; data-cke-widget-data=&quot;{}&quot; data-cke-widget-upcasted=&quot;1&quot;/&gt;，这个东西定义为L2范数，通常写作&lt;img class=&quot;mathcode&quot; src=&quot;https://private.codecogs.com/gif.latex?%24%5C%7Cw%5C%7C%24&quot; alt=&quot;$\|w\|$&quot; data-cke-saved-src=&quot;https://private.codecogs.com/gif.latex?%24%5C%7Cw%5C%7C%24&quot; data-cke-widget-data=&quot;{}&quot; data-cke-widget-upcasted=&quot;1&quot;/&gt;，这个就像一个运算符一样，代表了这种运算。那么L2范数的平方是我们的L2正则，因为又一次平凡，所以就把L2范数的根号给去掉，你就会看到，它实际上是把所有的W的平方给加合起来。也就是L2正则表达式：&lt;img class=&quot;mathcode&quot; src=&quot;https://private.codecogs.com/gif.latex?%24%5C%7Cw%5C%7C_%7B2%7D%5E%7B2%7D%3D%5Csum_%7Bi%3D1%7D%5E%7Bm%7D%20w_%7Bi%7D%5E%7B2%7D%24&quot; alt=&quot;$\|w\|_{2}^{2}=\sum_{i=1}^{m} w_{i}^{2}$&quot; data-cke-saved-src=&quot;https://private.codecogs.com/gif.latex?%24%5C%7Cw%5C%7C_%7B2%7D%5E%7B2%7D%3D%5Csum_%7Bi%3D1%7D%5E%7Bm%7D%20w_%7Bi%7D%5E%7B2%7D%24&quot; data-cke-widget-data=&quot;{}&quot; data-cke-widget-upcasted=&quot;1&quot;/&gt;，什么情况下这个值会大？ &lt;strong&gt;W普遍比较大的时候，这个情况会大，或者说W的绝对值比较大的时候，这个情况会大。&lt;/strong&gt; 当模型把好多的权重都认为比较重要的时候，这个东西是不是会变大？而且会越重要，大的越厉害，惩罚的越厉害。因此，把L2正则加上又会发生什么？它会想做到尽量的把W给压缩小一点，但是它不是每种W都压缩，它会优先压缩那些特别大的W优先，因为这些W对正则项带来的提升是越好的，让正则项变得越小，所以会优先压缩那些最大的W，然后真正特别重要的W，它权重也会很大，这种东西也被压缩了。 这是我们想要的结果吗？明显不是。你会发现我优化的时候不是单独用一个正则项，在前面还加着损失项，所以它一定会压缩那些又大又没什么用的那些W。所谓有用没用怎么评估？就是你W变一变损失函数根本没发生什么改变的情况下，这种W是不是又大又没用？他会优先的把这些又大又没用的W给尽量压小，防止模型去过拟合。因此L2正则。默认一定是要带上的，很明显不带任何惩罚项的损失函数根本就不能用。 它光追追求训练集上发热损失函数最小了，因为一丝不苟地只追求最小，它无论付出多大的代价，都要最小，因此一定会过拟合。所以在实际情况中一定会带上L2正则。&lt;strong&gt;因此我们的目标函数obj里面永远是两项，第一项是loss，第二项是L2，这个是防止过拟合的。我们总结下&lt;/strong&gt;L2范数的作用，它是会使所有的W的绝对值都相对变小，而不会变到零，让大家都小一些，特别重要的权重小的比较少，不太重要的权重往下减的多一点，它的作用就是抵抗过拟合。如果训练出来的权重代表这一个特征对最终结果影响的重要性，由于我们观察到的特征一定不是完备的，“强迫”算法用并不完备的观察特征尽全力去拟合训练集，一定会将一些训练集中的巧合作为规律习得，然而这些巧合并不一定在未来预测时也会出现，因此这就是过拟合现象。我们要把这种现象去掉或者减少，就是通过正则去抵抗过拟合。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;下一节中我们讨论L1正则和L2正则的区别。&lt;/span&gt;&lt;/p&gt;
</description>
<pubDate>Sat, 27 Apr 2019 12:48:00 +0000</pubDate>
<dc:creator>LHBlog</dc:creator>
<og:description>第十四节过拟合解决手段L1和L2正则 第十三节中，我们讲解了过拟合的情形，也就是过度的去拟合训练集上的结果了，反倒让你的模型太复杂。为了去解决这种现象，我们提出用L1，L2正则去解决这种问题。 怎么把</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/LHWorldBlog/p/10780266.html</dc:identifier>
</item>
<item>
<title>设计模式----观察者模式 - 守望阳光01</title>
<link>http://www.cnblogs.com/liuhuimh/p/10780035.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/liuhuimh/p/10780035.html</guid>
<description>&lt;p&gt;&lt;span&gt;        今天，我们来讲讲观察者模式。。所谓观察者模式就是一种观察者的模式（哈哈），其实观察者模式就一句话：对象和行为分离。。如果你理解了这句话，观察者模式你就学会了，怎么样，是不是特别简单。。额，如果不理解的话请看以下代码。。&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;32&quot;&gt;
&lt;pre&gt;
&lt;span&gt;abstract&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;&lt;span&gt; Observer
    {
        &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;abstract&lt;/span&gt; &lt;span&gt;void&lt;/span&gt;&lt;span&gt; Update();
    }&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span&gt;        首先，观察者模式，当然不能少了观察者，&lt;span&gt;Observer&lt;/span&gt;类就是我们抽象出来的观察者，它只有一个方法Update，然后呢，前面我们不是说了吗，观察者模式核心就是对象和行为分离，既然对象有了，那么行为也该出场了啊。。&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;34&quot;&gt;
&lt;pre&gt;
&lt;span&gt;abstract&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;&lt;span&gt; Subject
    {
        &lt;/span&gt;&lt;span&gt;private&lt;/span&gt; IList&amp;lt;Observer&amp;gt; observers = &lt;span&gt;new&lt;/span&gt; List&amp;lt;Observer&amp;gt;&lt;span&gt;();

        &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt;&lt;span&gt; Attach(Observer observer)
        {
            observers.Add(observer);
        }
        &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt;&lt;span&gt; Detach(Observer observer)
        {
            observers.Remove(observer);
        }
        &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt;&lt;span&gt; Notify()
        {
            &lt;/span&gt;&lt;span&gt;foreach&lt;/span&gt; (Observer o &lt;span&gt;in&lt;/span&gt;&lt;span&gt; observers)
            {
                o.Update();
            }
        }
    }&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span&gt;&lt;span&gt;         Subject&lt;/span&gt;类就是我们的通知者，也就是我们所说的被观察者，它有三个方法和一个list集合，Attach方法就是往集合中添加观察对象，Detach方法就是往集合中减除观察对象，而Notify方法是执行所有被观察对象的Update方法，也就是修改状态（这个就是行为，由被观察者来通知观察者并改变其状态）。这些做完之后，我们就要开始去实现真正的观察对象和通知对象了，请看代码&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;38&quot;&gt;
&lt;pre&gt;
&lt;span&gt;class&lt;/span&gt;&lt;span&gt; ConcreteObserver : Observer
    {
        &lt;/span&gt;&lt;span&gt;private&lt;/span&gt; &lt;span&gt;string&lt;/span&gt;&lt;span&gt; name;
        &lt;/span&gt;&lt;span&gt;private&lt;/span&gt; &lt;span&gt;string&lt;/span&gt;&lt;span&gt; observerState;
        &lt;/span&gt;&lt;span&gt;private&lt;/span&gt;&lt;span&gt; ConcreteSubject subject;

        &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; ConcreteObserver(ConcreteSubject subject, &lt;span&gt;string&lt;/span&gt;&lt;span&gt; name)
        {
            &lt;/span&gt;&lt;span&gt;this&lt;/span&gt;.subject =&lt;span&gt; subject;
            &lt;/span&gt;&lt;span&gt;this&lt;/span&gt;.name =&lt;span&gt; name;
        }

        &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;override&lt;/span&gt; &lt;span&gt;void&lt;/span&gt;&lt;span&gt; Update()
        {
            observerState &lt;/span&gt;=&lt;span&gt; subject.SubjectState;
            Console.WriteLine(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;观察者{0}的新状态是{1}&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;, name, observerState);
        }

        &lt;/span&gt;&lt;span&gt;public&lt;/span&gt;&lt;span&gt; ConcreteSubject Subject
        {
            &lt;/span&gt;&lt;span&gt;get&lt;/span&gt; { &lt;span&gt;return&lt;/span&gt;&lt;span&gt; subject; }
            &lt;/span&gt;&lt;span&gt;set&lt;/span&gt; { subject =&lt;span&gt; value; }
        }
    }



&lt;/span&gt;&lt;span&gt;class&lt;/span&gt;&lt;span&gt; ConcreteSubject : Subject
    {
        &lt;/span&gt;&lt;span&gt;private&lt;/span&gt; &lt;span&gt;string&lt;/span&gt;&lt;span&gt; subjectState;

        &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;具体被观察者状态&lt;/span&gt;
        &lt;span&gt;public&lt;/span&gt; &lt;span&gt;string&lt;/span&gt;&lt;span&gt; SubjectState
        {
            &lt;/span&gt;&lt;span&gt;get&lt;/span&gt; { &lt;span&gt;return&lt;/span&gt;&lt;span&gt; subjectState; }
            &lt;/span&gt;&lt;span&gt;set&lt;/span&gt; { subjectState =&lt;span&gt; value; }
        }
    }&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span&gt;        我们首先看&lt;span&gt;ConcreteObserver&lt;/span&gt;类，它继承&lt;span&gt;Observer&lt;/span&gt;类,所以它是具体观察者，然后我们看&lt;span&gt;ConcreteSubject&lt;/span&gt;类，它继承&lt;span&gt;Subject&lt;/span&gt;类，所以它是具体通知者。。我们接着看他们内部，首先是&lt;span&gt;ConcreteSubject&lt;/span&gt;类，它只有一个属性SubjectState，然后我们看&lt;span&gt;ConcreteObserver&lt;/span&gt;类，首先是构造函数，它注入了具体通知者和name，然后重写Update方法，修改修改自身状态。好了，观察者模式就写完了，现在，让我们来通过上层使用来全局看看是如何运转的&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;38&quot;&gt;
&lt;pre&gt;
 &lt;span&gt;class&lt;/span&gt;&lt;span&gt; Program
    {
        &lt;/span&gt;&lt;span&gt;static&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; Main(&lt;span&gt;string&lt;/span&gt;&lt;span&gt;[] args)
        {
            Console.WriteLine(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;***********观察者模式************&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;);
            ConcreteSubject s &lt;/span&gt;= &lt;span&gt;new&lt;/span&gt;&lt;span&gt; ConcreteSubject();
            s.Attach(&lt;/span&gt;&lt;span&gt;new&lt;/span&gt; ConcreteObserver(s, &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;x&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;));
            s.Attach(&lt;/span&gt;&lt;span&gt;new&lt;/span&gt; ConcreteObserver(s, &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;y&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;));
            s.Attach(&lt;/span&gt;&lt;span&gt;new&lt;/span&gt; ConcreteObserver(s, &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;z&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;));
            s.SubjectState &lt;/span&gt;= &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;ABC&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;;
            s.Notify();
        }
    }&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span&gt;        首先是new一个通知者，然后通知者添加观察对象（它得知道有多少人在偷看它对吧），所有观察者模式还有一个别名叫发布--订阅模式。&lt;span&gt;ConcreteSubject&lt;/span&gt;就是发布者，&lt;span&gt;ConcreteObserver&lt;/span&gt;就是订阅者，好，接下来我们就看看实现运行效果如何。。。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1184927/201904/1184927-20190427200738471-843520145.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;        这里我们可以看到当我们改变发布者状态的时候，所有的观察者状态都得到了改变。。这样我们的目的也就达到了，当我发布东西的时候，我需要通知所有订阅我的人我的状态。。。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;        对象和行为分离：所有的观察者和通知者之间没有必然的联系，观察者只负责观察（也就是订阅），改变行为通知观察者交给通知者统一管理。这就是我们今天的观察者模式了。。。&lt;/span&gt;&lt;/p&gt;

</description>
<pubDate>Sat, 27 Apr 2019 12:16:00 +0000</pubDate>
<dc:creator>守望阳光01</dc:creator>
<og:description>今天，我们来讲讲观察者模式。。所谓观察者模式就是一种观察者的模式（哈哈），其实观察者模式就一句话：对象和行为分离。。如果你理解了这句话，观察者模式你就学会了，怎么样，是不是特别简单。。额，如果不理解的</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/liuhuimh/p/10780035.html</dc:identifier>
</item>
</channel>
</rss>