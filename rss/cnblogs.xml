<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="css/feed.xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/" xmlns:og="http://ogp.me/ns#">
<channel>
<atom:link rel="self" href="http://192.168.1.4/fivefilters/makefulltextfeed.php?url=feed.cnblogs.com%2Fblog%2Fsitehome%2Frss&amp;max=10&amp;links=preserve&amp;exc=" />
<atom:link rel="alternate" title="Source URL" href="http://feed.cnblogs.com/blog/sitehome/rss" />
<atom:link rel="related" title="Subscribe to feed" href="http://www.subtome.com/#/subscribe?feeds=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed.cnblogs.com%252Fblog%252Fsitehome%252Frss%26max%3D10%26links%3Dpreserve%26exc%3D&amp;back=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed.cnblogs.com%252Fblog%252Fsitehome%252Frss%26max%3D10%26links%3Dpreserve%26exc%3D" />
<title>博客园_首页</title>
<link></link>
<description>代码改变世界</description>
<item>
<title>[不得不知道系列]Java线程面试你不得不知道的基础知识一 - 分布式编程</title>
<link>http://www.cnblogs.com/daichangya/p/12963278.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/daichangya/p/12963278.html</guid>
<description>&lt;ol&gt;&lt;li&gt;&lt;a href=&quot;https://zthinker.com/archives/java-memory-interview-1&quot;&gt;Java内存管理面试指南一&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://zthinker.com/archives/java-basic-interview-1&quot;&gt;Java基础面试指南一&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://zthinker.com/archives/java-basic-interview-2&quot;&gt;Java基础面试指南二&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://zthinker.com/archives/java-basic-interview-3&quot;&gt;Java基础面试指南三&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://zthinker.com/archives/java-basic-interview-4&quot;&gt;Java基础面试指南四&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://zthinker.com/archives/java-thread-interview-1&quot;&gt;Java线程面试指南一&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://zthinker.com/archives/java-thread-interview-2&quot;&gt;Java线程面试指南二&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://zthinker.com/archives/redis-interview-1&quot;&gt;Redis面试指南一&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://zthinker.com/archives/kafka-interview-1&quot;&gt;Kafka面试指南一&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://zthinker.com/archives/spring-interview-1&quot;&gt;Spring面试指南一&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://zthinker.com/archives/springboot-interview-1&quot;&gt;SpringBoot面试指南一&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://zthinker.com/archives/microservice-interview-1&quot;&gt;微服务面试指南一&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;Java支持单线程以及多线程操作。线程是程序的执行路径。今天编写的大多数程序都是作为单线程运行的,当需要同时发生多个事件或动作时会引起问题。单线程程序具有一个入口点(main()方法)和一个出口点。&lt;/p&gt;
&lt;p&gt;可以使用两种不同的机制来创建线程:&lt;/p&gt;
&lt;p&gt;扩展Thread类&lt;/p&gt;
&lt;p&gt;实现Runnable接口&lt;/p&gt;
&lt;h5 id=&quot;java中的线程是什么&quot;&gt;&lt;a href=&quot;https://www.cnblogs.com/daichangya/p/12963278.html#&quot;&gt;Java中的线程是什么?&lt;/a&gt;&lt;/h5&gt;
&lt;ul&gt;&lt;li&gt;线程以最佳方式消耗CPU,因此可以进行多处理。多线程减少了CPU的空闲时间,从而提高了应用程序的性能。&lt;/li&gt;
&lt;li&gt;线程是轻量级的过程。&lt;/li&gt;
&lt;li&gt;线程类属于java.lang包。&lt;/li&gt;
&lt;li&gt;即使我们不创建任何线程,我们也可以在Java中创建多个线程,至少一个线程确实存在,即主线程。&lt;/li&gt;
&lt;li&gt;多个线程在Java中并行运行。&lt;/li&gt;
&lt;li&gt;线程有自己的堆栈。&lt;/li&gt;
&lt;li&gt;线程的优点:假设一个线程需要10分钟才能完成某些任务,一次使用10个线程可以在1分钟内完成该任务,因为线程可以并行运行。&lt;/li&gt;
&lt;/ul&gt;&lt;h5 id=&quot;java中的process和thread有什么区别&quot;&gt;&lt;a href=&quot;https://www.cnblogs.com/daichangya/p/12963278.html#&quot;&gt;Java中的Process和Thread有什么区别?&lt;/a&gt;&lt;/h5&gt;
&lt;p&gt;一个进程可以有多个线程,&lt;/p&gt;
&lt;p&gt;线程是进程的细分。一个或多个线程在进程的上下文中运行。线程可以执行过程的任何部分。进程的同一部分可以由多个线程执行。&lt;/p&gt;
&lt;p&gt;进程具有其父进程的数据段的副本,而线程可以直接访问其进程的数据段。&lt;/p&gt;
&lt;p&gt;进程具有自己的地址,而线程共享创建它的进程的地址空间。&lt;/p&gt;
&lt;p&gt;流程创建需要完成很多工作,我们可能需要复制整个父流程,但是可以轻松创建线程。&lt;/p&gt;
&lt;p&gt;进程可以轻松地与子进程进行通信,但是进程间的通信很困难。同时,线程可以使用wait()和notify()方法轻松地与同一进程的其他线程通信。&lt;/p&gt;
&lt;p&gt;在处理过程中,所有线程共享系统资源(例如堆内存等),而线程具有其自己的堆栈。&lt;/p&gt;
&lt;p&gt;对进程所做的任何更改都不会影响子进程,但是对线程所做的任何更改都可能影响该进程其他线程的行为。&lt;/p&gt;
&lt;p&gt;查看在不同进程和相同进程上创建线程的位置的示例。&lt;/p&gt;
&lt;h5 id=&quot;如何在java中实现线程&quot;&gt;&lt;a href=&quot;https://www.cnblogs.com/daichangya/p/12963278.html#&quot;&gt;如何在Java中实现线程?&lt;/a&gt;&lt;/h5&gt;
&lt;p&gt;这是非常基本的线程问题。可以通过两种方法来创建线程:通过实现java.lang.Runnable接口或扩展java.lang.Thread类,然后扩展run方法。&lt;/p&gt;
&lt;p&gt;线程有其自己的变量和方法,它在堆上生存和死亡。但是执行线程是具有自己的调用堆栈的单个进程。线程是Java中的轻量级进程。&lt;/p&gt;
&lt;p&gt;通过实现java.lang.Runnable interface创建线程。&lt;/p&gt;
&lt;p&gt;我们将创建实现Runnable接口的类的对象:&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;MyRunnable runnable=new MyRunnable();

Thread thread=new Thread(runnable);
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;然后通过调用构造函数并传递Runnable接口的引用(即runnable object)来创建Thread对象:&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;Thread thread=new Thread(runnable);
&lt;/code&gt;
&lt;/pre&gt;
&lt;h5 id=&quot;线程是否实现自己的堆栈如果是如何实现&quot;&gt;&lt;a href=&quot;https://www.cnblogs.com/daichangya/p/12963278.html#&quot;&gt;线程是否实现自己的堆栈,如果是,如何实现?&lt;/a&gt;&lt;/h5&gt;
&lt;p&gt;是的,线程有自己的堆栈。这是一个非常有趣的问题,面试官倾向于检查您有关线程如何内部维护自己的堆栈的基本知识。&lt;/p&gt;
&lt;h5 id=&quot;我们应该实现runnable接口或扩展thread类。实现runnable和扩展thread有什么区别&quot;&gt;&lt;a href=&quot;https://www.cnblogs.com/daichangya/p/12963278.html#&quot;&gt;我们应该实现Runnable接口或扩展Thread类。实现Runnable和扩展Thread有什么区别?&lt;/a&gt;&lt;/h5&gt;
&lt;p&gt;很好的答案是,只有在您想要修改run()和其他方法时,才必须扩展Thread。如果只想修改实现Runnable的run()方法是最好的选择(Runnable接口只有一个抽象方法,即run())。&lt;/p&gt;
&lt;h5 id=&quot;实现runnable接口和扩展thread类之间有什么区别&quot;&gt;&lt;a href=&quot;https://www.cnblogs.com/daichangya/p/12963278.html#&quot;&gt;实现Runnable接口和扩展Thread类之间有什么区别?&lt;/a&gt;&lt;/h5&gt;
&lt;p&gt;java中不允许多重继承:当我们实现Runnable接口时,我们也可以扩展另一个类,但是如果我们扩展Thread类,则不能扩展任何其他类,因为Java不允许多重继承。因此,通过实现Runnable和扩展Thread可以完成相同的工作,但是在实现Runnable的情况下,我们仍然可以选择扩展其他类。因此,最好实现Runnable。&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;线程安全性:当我们实现Runnable接口时,同一对象在多个线程之间共享,但是当我们扩展Thread类时,每个线程都与新对象相关联。&lt;/li&gt;
&lt;li&gt;继承(实现Runnable是轻量级操作):当我们不必要地扩展Thread时,所有Thread类的功能都会被继承,但是当我们实现Runnable接口时,不会继承任何额外的功能,因为Runnable仅包含一个抽象方法,即run()方法。因此,实现Runnable是轻量级的操作。&lt;/li&gt;
&lt;li&gt;编码到接口:甚至java也建议编码到接口。因此,我们必须实现Runnable而不是扩展线程。另外,Thread类实现Runnable接口。&lt;/li&gt;
&lt;li&gt;除非要修改类的基本行为,否则不要扩展,Runnable接口只有一个抽象方法,即run():仅当您希望修改run()和其他方法时,才必须扩展Thread。如果只想修改实现Runnable的run()方法是最好的选择(Runnable接口只有一个抽象方法,即run())。除非我们要修改Thread类的基本行为,否则我们不能扩展Thread类。&lt;/li&gt;
&lt;li&gt;实现Runnable时代码的灵活性:当我们首先扩展Thread时,所有线程功能都被继承,并且我们的类成为Thread的直接子类,因此我们正在做的任何操作都在Thread类中。但是,当我们实现Runnable时,我们创建了一个新线程并将runnable对象作为参数传递,我们可以将runable对象传递给执行程序Service等等。因此,当我们实现Runnable时,我们有更多选择,并且代码变得更加灵活。&lt;/li&gt;
&lt;li&gt;Executor Service:如果我们实现Runnable,则可以使用Executor Service启动在可运行对象上创建的多个线程(因为我们可以使用新线程来启动Runnable对象),但是在扩展Thread的情况下则不会(因为线程只能启动一次) 。&lt;/li&gt;
&lt;/ul&gt;&lt;h5 id=&quot;怎么说线程的行为是不可预测的&quot;&gt;&lt;a href=&quot;https://www.cnblogs.com/daichangya/p/12963278.html#&quot;&gt;怎么说线程的行为是不可预测的?&lt;/a&gt;&lt;/h5&gt;
&lt;p&gt;问题的解决方案非常简单,线程行为是不可预测的,因为线程的执行取决于线程调度程序,线程调度程序在Windows,Unix等不同平台上的实现方式可能不同。即使在同一平台上,相同的线程程序在后续执行中也可能产生不同的输出。&lt;/p&gt;
&lt;p&gt;为了实现这一点,我们将在同一个Runnable对象上创建2个线程,在run()方法中创建for循环并启动两个线程。不能确定哪个线程将首先完成,两个线程都将在for循环中匿名输入。&lt;/p&gt;
&lt;h5 id=&quot;当线程不是java中的轻量级进程时&quot;&gt;&lt;a href=&quot;https://www.cnblogs.com/daichangya/p/12963278.html#&quot;&gt;当线程不是Java中的轻量级进程时?&lt;/a&gt;&lt;/h5&gt;
&lt;p&gt;仅当同一进程的线程同时执行时,线程才是轻量级进程。但是,如果不同进程的线程同时执行,那么线程就是重量级进程。&lt;/p&gt;
&lt;h5 id=&quot;如何确保从main开始的所有线程必须按它们开始的顺序结束并且main应该最后结束&quot;&gt;&lt;a href=&quot;https://www.cnblogs.com/daichangya/p/12963278.html#&quot;&gt;如何确保从main开始的所有线程必须按它们开始的顺序结束,并且main应该最后结束?&lt;/a&gt;&lt;/h5&gt;
&lt;p&gt;面试官倾向于了解面试者对Thread方法的了解。因此,现在该通过正确回答来证明您的观点了。我们可以使用join()方法来确保所有从main开始的线程必须按照它们开始的顺序结束,并且main也应该在最后结束。换句话说,等待该线程死亡。内部调用join()方法将调用join(0);&lt;/p&gt;
&lt;p&gt;详细说明:Join()方法–确保从main开始的所有线程必须按它们开始的顺序结束,并且main也应最后结束。具有程序的join()方法的类型-join的10个显着特征。&lt;/p&gt;
&lt;h5 id=&quot;使用run和start方法启动线程之间的区别是什么&quot;&gt;&lt;a href=&quot;https://www.cnblogs.com/daichangya/p/12963278.html#&quot;&gt;使用run()和start()方法启动线程之间的区别是什么?&lt;/a&gt;&lt;/h5&gt;
&lt;p&gt;这是一个非常有趣的问题,它可能会使您感到困惑,并且有时可能使您认为使用run()和start()方法启动线程之间确实存在任何区别。&lt;/p&gt;
&lt;p&gt;当您调用start()方法时,主线程在内部调用run()方法以启动新创建的线程,因此run()方法最终被新创建的线程调用。&lt;/p&gt;
&lt;p&gt;当您调用run()方法主线程而不是使用新线程启动run()方法,它将自行启动run()方法。&lt;/p&gt;
&lt;h5 id=&quot;使用volatile关键字有什么意义&quot;&gt;&lt;a href=&quot;https://www.cnblogs.com/daichangya/p/12963278.html#&quot;&gt;使用Volatile关键字有什么意义?&lt;/a&gt;&lt;/h5&gt;
&lt;p&gt;Java允许线程访问共享变量。通常,为确保一致地更新共享变量,线程应通过获取对这些共享变量强制执行互斥的锁来确保其专有使用此类变量。&lt;/p&gt;
&lt;p&gt;如果将字段声明为易失性,则在这种情况下,Java内存模型可确保所有线程看到的变量值均一致。&lt;/p&gt;
</description>
<pubDate>Tue, 26 May 2020 00:39:00 +0000</pubDate>
<dc:creator>分布式编程</dc:creator>
<og:description>Java内存管理面试指南一 Java基础面试指南一 Java基础面试指南二 Java基础面试指南三 Java基础面试指南四 Java线程面试指南一 Java线程面试指南二 Redis面试指南一 Kaf</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/daichangya/p/12963278.html</dc:identifier>
</item>
<item>
<title>用 CSS Grid 布局制作一个响应式柱状图 - 前端小蜜蜂</title>
<link>http://www.cnblogs.com/fehoney/p/12962264.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/fehoney/p/12962264.html</guid>
<description>&lt;p&gt;最新一段时间比较喜欢玩弄图表，出于好奇，我想找出比较好的用 CSS 制作图表的方案。开始学习网上开源图表库，它对我学习新的和不熟悉的前端技术很有帮助，比如这个：CSS Grid。&lt;/p&gt;
&lt;p&gt;今天和大家分享我学到的新知识：如何用 CSS Grid 布局制作一个普通的响应式柱状图。先上效果图：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://qa457e20e.bkt.clouddn.com/202005/26022652&quot; alt=&quot; &quot;/&gt;&lt;/p&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;这篇文章的示例只是一个试验，用来学习 CSS Grid 布局，加上本人也是现学现卖，所以本文出现的代码不具有太多的参照意义。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;第一个简单版本&quot;&gt;第一个简单版本&lt;/h2&gt;
&lt;p&gt;第一眼看上去可能会有点不知道怎么开始，因此我们先来关注如何创建一个简单的版本。首先，我们需要为图表编写 HTML 标签：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-html&quot;&gt;&amp;lt;div class=&quot;chart&quot;&amp;gt;
  &amp;lt;div class=&quot;bar-1&quot;&amp;gt;&amp;lt;/div&amp;gt;
  &amp;lt;div class=&quot;bar-2&quot;&amp;gt;&amp;lt;/div&amp;gt;
  &amp;lt;div class=&quot;bar-3&quot;&amp;gt;&amp;lt;/div&amp;gt;
  &amp;lt;div class=&quot;bar-4&quot;&amp;gt;&amp;lt;/div&amp;gt;
  &amp;lt;!-- 一直到 bar-12 --&amp;gt;
&amp;lt;/div&amp;gt;
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;这些 &lt;code&gt;bar-&lt;/code&gt; 开头的 div 标签将对应柱状图中的一条柱子，整篇文章所需要的 HTML 就这么多。&lt;/p&gt;
&lt;p&gt;现在按照我的步骤和简单的解说一步一步用 CSS 把柱状图大概的样式画出来，不用过多地担心下面出现的可能对你有些陌生的 CSS 语义，稍后我们将重点介绍关于 CSS Grid 的知识。&lt;/p&gt;
&lt;p&gt;好了，现在开始我们的 CSS 样式编写。我们先对父元素添加一些必要的样式：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-css&quot;&gt;* {
  box-sizing: border-box;
}

html,
body {
  margin: 0;
  background-color: #eee;
  display: flex;
  justify-content: center;
}

.chart {
  height: 100vh;
  width: 70vw;
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;我们需要在图表中有 12 个条形，中间有 5px 的间距，按此需求，我们可以对父类 &lt;code&gt;.chart&lt;/code&gt; 编写如下 Grid 相关的样式：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-css&quot;&gt;.chart {
  display: grid;
  grid-template-columns: repeat(12, 1fr);
  grid-template-rows: repeat(100, 1fr);
  grid-column-gap: 5px;
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;对于熟悉 Grid 布局的人来说，这是非常简单的。上面代码表达的是：“我想要 12 列，每个子元素具有相同的宽度(1fr = 1 fraction)，高度分为 100 等分，1 等分为一行（这样方便计算），它们之间有 5px 的间隔。”&lt;/p&gt;
&lt;p&gt;到这里，我们的图表仍然是空的，因为我们没有告诉我们的子元素如何去占用网格中的空间。我们使用 &lt;code&gt;grid-row-start&lt;/code&gt; 和 &lt;code&gt;grid-row-end&lt;/code&gt; 属性来填充网格中的垂直空间，后而我们将通过改变这两个属性来定义各个子元素自己的高度。为样式类为 &lt;code&gt;bar&lt;/code&gt; 开头子元素添加如下样：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-css&quot;&gt;[class*='bar'] {
  grid-row-start: 1;
  grid-row-end: 101;
  border-radius: 5px 5px 0 0;
  background-color: #ff4136;
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;现在可以得到这样的效果：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://qa457e20e.bkt.clouddn.com/202005/26022754&quot; alt=&quot; &quot;/&gt;&lt;/p&gt;
&lt;p&gt;我们告诉每个柱状图从网格的顶部(1)开始，然后在底部(101)结束。上面我们把网格划分了 100 行，为什么要使用 101 作为该属性的值呢？如果你被这些 Grid 属性搞蒙了，没关系！在我们继续之前，让我们对此进行一点探讨。&lt;/p&gt;
&lt;h2 id=&quot;理解网格线&quot;&gt;理解网格线&lt;/h2&gt;
&lt;p&gt;Grid 布局的一个特殊之处就是网格线的概念，这对理解这个新的布局工具非常重要。以下是网格线在四行四列网格中绘制的示意图:&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://qa457e20e.bkt.clouddn.com/202005/26022840&quot; alt=&quot; &quot;/&gt;&lt;/p&gt;
&lt;p&gt;这四行四列的对应的样式是这样的（特殊的黑色区域对应的样式类为 &lt;code&gt;special-col&lt;/code&gt;）：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-css&quot;&gt;.grid {
  grid-gap: 5px;
  grid-template-columns: repeat(4, 1fr);
  grid-template-rows: repeat(4, 1fr);
}

.special-col {
  grid-row: 2 / 4;
  background-color: #333;
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;grid-row&lt;/code&gt; 是 &lt;code&gt;grid-row-start&lt;/code&gt; 和 &lt;code&gt;grid-row-end&lt;/code&gt; 的简写属性，前者表示元素在网格中的开始位置，后者表示元素在网格中的结束位置。注意到没，黑色块是从第 2 条网格线开始的，并在第 4 条网格线结束（而不是在第 4 行）。如果我们想让那个黑盒子填满所有 4 行，那么我们需要在第 5 条网格线结束，即：1 / 5。理解这一点很重要。&lt;/p&gt;
&lt;p&gt;换句话说，我们不应该认为子元素在一个网格中占据整个行或列，而应该只跨越这些网格线的。我花了不少时间才从概念上理解并习惯了这一点，因为我最近深入研究了 Jen Simmons 关于这个问题的教程。&lt;/p&gt;
&lt;h2 id=&quot;回到示例&quot;&gt;回到示例&lt;/h2&gt;
&lt;p&gt;这就是为什么在我们上面的图表示例中，所有列都在 101 这个值结束，因为 101 代表的是第 101 条网络线，而不是第 100 行。&lt;/p&gt;
&lt;p&gt;现在，由于我们的 &lt;code&gt;.chart&lt;/code&gt; 使用了 vw/vh 单位，也就有了一个响应良好的图表，不需要再做其它的额外工作来支持响应式。如果你调整浏览器大小，你会发现它可以很好地压缩或延伸，它总是占据整个视窗。&lt;/p&gt;
&lt;p&gt;理解了网络线的概念，我们就可以很轻松地为柱子调整高度了，我们需要让各柱子高度参差不一。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-css&quot;&gt;.bar-1 {
  grid-row-start: 55;
}
.bar-2 {
  grid-row-start: 1;
}
...(略);
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;最后我们使寄偶数的柱子颜色不一样：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-css&quot;&gt;[class*='bar']:nth-child(odd) {
  background-color: #ff4136;
}

[class*='bar']:nth-child(even) {
  background-color: #0074d9;
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;效果：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://qa457e20e.bkt.clouddn.com/202005/26022900&quot; alt=&quot; &quot;/&gt;&lt;/p&gt;
&lt;p&gt;我们就这样制作完成了一个支持响应式的柱状图。当然，这个示例只是一个开始，距离要达到实际应用的效果还有很多事情要做。比如画标注和轴、通过 JS 来绑定真实的业务数据等。&lt;/p&gt;
</description>
<pubDate>Tue, 26 May 2020 00:25:00 +0000</pubDate>
<dc:creator>前端小蜜蜂</dc:creator>
<og:description>最新一段时间比较喜欢玩弄图表，出于好奇，我想找出比较好的用 CSS 制作图表的方案。开始学习网上开源图表库，它对我学习新的和不熟悉的前端技术很有帮助，比如这个：CSS Grid。 今天和大家分享我学到</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/fehoney/p/12962264.html</dc:identifier>
</item>
<item>
<title>Jmeter(三) - 从入门到精通 - 测试计划（Test Plan）的元件（详解教程） - 北京-宏哥</title>
<link>http://www.cnblogs.com/du-hong/p/12909175.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/du-hong/p/12909175.html</guid>
<description>&lt;h3&gt;&lt;strong&gt;1.简介&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;上一篇中宏哥已经教你如何通过JMeter来创建一个测试计划（Test Plan），那么这一篇我们就将JMeter启动起来，创建一个测试计划（Test plan），然后宏哥给大家介绍一下测试计划（Test Plan）有哪些元件组成的。&lt;/p&gt;
&lt;h3&gt;&lt;strong&gt;2.测试计划（Test Plan）要素&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;本节主要描述测试计划的不同部分要素。JMeter中一个脚本就是一个测试计划（Test Plan），也是一个管理单元。JMeter 的请求模拟与并发数(设置线程数，一个线程代表一个虚拟用户)设置都在脚本文件中一起设置。JMeter 不像 LoadRunner 把脚本与虚拟用户设置分开。&lt;/p&gt;
&lt;h4&gt;2.1测试计划要素如下：&lt;/h4&gt;
&lt;p&gt;（1）要素一：脚本中测试计划只能有一个&lt;br/&gt;　　1、Jmeter 测试计划类似 LoadRunner Controller 中的测试场景，同一时刻场景故然只能有一个，。&lt;br/&gt;　　2、JMeter 脚本在 GUI 中显示时是树型结构，测试计划是根节点，根节点当然只能有一个。&lt;br/&gt;（2）要素二：测试计划中至少要有一个线程组&lt;br/&gt;　　1、JMeter 负裁是通过线程组驱动的，所以计划中至少要出现一个线程组。&lt;br/&gt;　　2、JMeter 测试计划支持多个线程组。&lt;br/&gt;　　3、我们可以在计划下面建立多个线程组，类似 LoadRunner 中的 Group 方式的场景，我们可以把JMeter 计划理解成LoadRmmer 中的 Group 方式场景，把不相关联的业务分布在不同的线程组中( LoadRunner 中的不同 Group)。&lt;br/&gt;（3）要素三：至少要有一个取样器&lt;br/&gt;　　1、测试的目的就是要模拟用户请求，没有取样脚本就毫无意义。&lt;br/&gt;（4）要素四：至少要有一个监听器&lt;br/&gt;　　1、测试结果用来衡量系统性能，我们需要从结果中分析系统性能。&lt;/p&gt;
&lt;h3&gt;&lt;strong&gt;3.测试计划（Test Plan）元件&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;&lt;span&gt;打开&lt;/span&gt;Jmeter页面：包括测试计划+工作台。&lt;/p&gt;
&lt;p&gt;&lt;span&gt;注意：敲黑板，敲脑壳啦！！！最新版的jmeter去掉了工作台。不要大惊小怪的导出截图问，我的JMeter为什么没有工作台，我同事的有工作台，如果你是在想要就下载一个低版本的JMeter安装好启动以后，就可以看到你的JMeter也有工作台了。&lt;/span&gt;&lt;/p&gt;
&lt;h4&gt;&lt;strong&gt;3.1测试计划（Test Plan）&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;Test Plan (测试计划)：用来描述一个性能测试，包含与本次性能测试所有相关的功能。也就说本的性能测试的所有内容是于基于一个计划的。&lt;br/&gt;右键单击“测试计划”弹出菜单：&lt;br/&gt;它用来描述一个测试方案，包含与本次性能测试所有相关的功能。也就说本次测试的所有内容是于基于一个计划的。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1232840/202005/1232840-20200518145449735-400207624.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;注意：敲黑板，敲脑壳啦！！！&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;测试计划对象具有一个名为“ 函数测试模式 ” 的复选框。如果选择，它将使JMeter记录每个样本从服务器返回的数据。如果您在测试侦听器中选择了文件，则此数据将被写入文件。如果要进行少量运行以确保正确配置JMeter并确保服务器返回预期结果，这将很有用。结果是文件将快速增长，JMeter的性能将受到影响。如果要进行压力测试，则应禁用此选项（默认情况下处于禁用状态）。&lt;br/&gt;如果您没有将数据记录到文件中，则此选项没有区别。&lt;br/&gt;您还可以使用监听器上的“ 配置”按钮来确定要保存的字段。&lt;/p&gt;
&lt;h4&gt;&lt;strong&gt;&lt;span&gt;3.2线程组Threads （Users）&lt;/span&gt;&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;&lt;span&gt;&lt;span&gt;线程组元素是任何测试计划的起点。&lt;/span&gt;&lt;span&gt;所有控制器和采样器必须在线程组下。&lt;/span&gt;&lt;span&gt;其他元素（例如，侦听器）可以直接放置在测试计划下，在这种情况下，它们将应用于所有线程组。&lt;/span&gt;&lt;span&gt;顾名思义，线程组元素控制JMeter将用于执行测试的线程数。&lt;/span&gt;&lt;span&gt;线程组的控件使您可以：&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;span&gt;设置线程数&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span&gt;设置加速时间&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span&gt;设置执行测试的次数&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;每个线程将完整地执行测试计划，并且完全独立于其他测试线程。多个线程用于模拟与服务器应用程序的并发连接。&lt;br/&gt;加速期告诉JMeter将“加速”到所选线程的总数需要多长时间。如果使用了10个线程，并且启动周期为100秒，那么JMeter将花费100秒来启动和运行所有10个线程。每个线程将在上一个线程开始后10（100/10）秒开始。如果有30个线程，启动周期为120秒，则每个连续线程将延迟4秒。&lt;br/&gt;加速需要足够长的时间来避免在测试开始时工作量过大，并且还必须足够短以使最后一个线程在第一个线程完成之前开始运行（除非有人希望这种情况发生）。&lt;br/&gt;从“上升=线程数”开始，然后根据需要向上或向下调整。&lt;br/&gt;默认情况下，线程组配置为在其元素之间循环一次。&lt;br/&gt;线程组还提供了调度程序。单击“线程组”面板底部的复选框以启用/禁用其他字段，您可以在其中输入测试的持续时间，启动延迟，运行的开始和结束时间。您可以配置持续时间（秒）和启动延迟（秒）来控制每个线程组的持续时间以及启动后的秒数。当测试开始时，JMeter将在启动线程组的线程之前等待启动延迟（秒），然后运行配置的持续时间（秒）。请注意，这两个选项会覆盖“ 开始时间”和“ 结束时间”。&lt;br/&gt;另外，您也可以使用其他两个字段Start time和End time（尽管不建议这样做，因为它不太灵活）。测试开始时，如有必要，JMeter将等待直到达到启动时间。在每个周期的末尾，JMeter会检查是否已达到结束时间，如果已结束，则运行将停止，否则，将允许测试继续进行直到达到迭代限制。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;线程组的添加路径：【测试计划】-【THreads（Users）线程组】&lt;/strong&gt;&lt;/p&gt;
&lt;h5&gt;&lt;strong&gt;&lt;span class=&quot;code&quot;&gt;&lt;span class=&quot;code&quot;&gt;3.2.1添加线程组&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/h5&gt;
&lt;p&gt;&lt;span class=&quot;code&quot;&gt;&lt;span class=&quot;code&quot;&gt;选中要添加线程组的测试计划（Test Plan），右键点击“Add”，选中“Threads（Users）”，我们目前可以看到三个线程组。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;code&quot;&gt;&lt;span class=&quot;code&quot;&gt;&lt;span&gt;&lt;span&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1232840/202005/1232840-20200518150531282-924534528.png&quot; alt=&quot;&quot;/&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;虽然有三个添加线程组的选项，名字不一样， 创建之后，其界面是完全一样的。之前的版本只有一个线程组的名字。现在多一个setUp theread Group 与terDown Thread Group&lt;br/&gt;1) setup thread group&lt;br/&gt;一种特殊类型的ThreadGroup的，可用于执行预测试操作。这些线程的行为完全像一个正常的线程组元件。不同的是，这些类型的线程执行测试前进行定期线程组的执行。&lt;br/&gt;setUp Thread Group类似于lr的init.可用于执行预测试操作。&lt;br/&gt;2) teardown thread group.&lt;br/&gt;一种特殊类型的ThreadGroup的，可用于执行测试后动作。这些线程的行为完全像一个正常的线程组元件。不同的是，这些类型的线程执行测试结束后执行定期的线程组。&lt;br/&gt;tearDown Thread Group类似于lr的end.可用于执行测试后动作。&lt;br/&gt;3) thread group(线程组).&lt;br/&gt;这个就是我们通常添加运行的线程。通俗的讲一个线程组，可以看做一个虚拟用户组，线程组中的每个线程都可以理解为一个虚拟用户。线程组中包含的线程数量在测试执行过程中是不会发生改变的。&lt;/p&gt;
&lt;h5 class=&quot;p0&quot;&gt;&lt;strong&gt;3.2.2线程组界面介绍&lt;/strong&gt;&lt;/h5&gt;
&lt;p&gt;这个就是我们通常添加运行的线程。通俗的讲一个线程组,，可以看做一个虚拟用户组，线程组中的每个线程都可以理解为一个虚拟用户。&lt;br/&gt;Ramp-Up Period：单位是秒，默认时间是1秒。它指定了启动所有线程所花费的时间。如果你需要Jmeter立即启动所有线程，将此设定为0即可&lt;br/&gt;循环次数：表示每个线程执行多少次请求。&lt;/p&gt;
&lt;p class=&quot;p0&quot;&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1232840/202005/1232840-20200518151526423-749826641.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;名称：就如字面意思，起个有意义的名字就行&lt;br/&gt;注释：&lt;br/&gt;线程数：这里选择1&lt;br/&gt;Ramp-Up Period：单位是秒，默认时间是1秒。它指定了启动所有线程所花费的时间，比如，当前的设定表示“在5秒内启动5个线程，每个线程的间隔时间为1秒”。如果你需要Jmeter立即启动所有线程，将此设定为0即可&lt;br/&gt;循环次数：表示每个线程执行多少次请求。&lt;/p&gt;
&lt;h4&gt;&lt;strong&gt;3.3拓展&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;这个是关于阶梯加压线程组，后期关于这部分会详细介绍，这里先提一下，有兴趣的自己可以研究一下，很简单的需要给JMeter下载安装一个插件就可以了。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1232840/202005/1232840-20200518152440855-882966973.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;注意：Stepping Thread Group 可用于模拟阶梯加压！&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1232840/202005/1232840-20200518152419502-2330537.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;h4&gt;&lt;strong&gt;3.4&lt;/strong&gt;控制器(Controllers)&lt;/h4&gt;
&lt;p&gt;JMeter有两种类型的控制器：采样器和逻辑控制器。用这些元件来驱动测试的进行。&lt;br/&gt;采样器告诉JMeter将请求发送到服务器。例如，如果您希望JMeter发送HTTP请求，则添加一个HTTP Request Sampler。您还可以通过将一个或多个配置元素添加到采样器来自定义请求。有关更多信息，请参见 采样器。&lt;br/&gt;逻辑控制器使您可以自定义JMeter用于决定何时发送请求的逻辑。例如，您可以添加一个Interleave Logic Controller在两个HTTP Request Samplers之间交替。有关更多信息，请参见逻辑控制器。&lt;/p&gt;
&lt;h4&gt;&lt;strong&gt;3.5&lt;/strong&gt;采样器(Samplers)&lt;/h4&gt;
&lt;p&gt;采样器也可以翻译成取样器；用来模拟用户的操作，向服务器（被测系统）发出Http请求、WebService（SOAP/XML-RPC Request）请求或者Java请求等。我们可以把Http请求元件看成是一个没有界面的浏览器，它可以发送Http请求，接收服务器的响应数据。采样器（Sampler）是测试中向服务器发送请求，记录响应信息，记录响应时间的最小单元，JMeter 原生支持多种不同的sampler 。如 HTTP Request Sampler 、 FTP Request Sampler 、TCP Request Sampler 、JDBC Request Sampler 等。高版本的jmeter支持更丰富的Sampler。&lt;br/&gt;&lt;strong&gt;采样器的添加路径：【测试计划】-【线程组】-【采样器】。&lt;/strong&gt;&lt;br/&gt;采样器告诉JMeter将请求发送到服务器并等待响应。它们按照它们在树中出现的顺序进行处理。控制器可用于修改采样器的重复次数。&lt;br/&gt;JMeter采样器包括：&lt;br/&gt;FTP请求&lt;br/&gt;HTTP请求（也可用于SOAP或REST Web服务）&lt;br/&gt;JDBC请求&lt;br/&gt;Java对象请求&lt;br/&gt;JMS请求&lt;br/&gt;JUnit测试请求&lt;br/&gt;LDAP要求&lt;br/&gt;邮件要求&lt;br/&gt;操作系统进程请求&lt;br/&gt;TCP请求&lt;br/&gt;每个采样器都有几个可以设置的属性。您可以通过向测试计划中添加一个或多个配置元素来进一步自定义采样器。&lt;br/&gt;如果要将相同类型的多个请求（例如HTTP请求）发送到同一服务器，请考虑使用默认配置元素。每个控制器都有一个或多个Defaults元素（请参见下文）。&lt;br/&gt;切记在测试计划中添加一个侦听器，以查看和/或将请求结果存储到磁盘。&lt;br/&gt;如果您有兴趣让JMeter对请求的响应执行基本验证，请将Assertion添加到采样器。例如，在对Web应用程序进行压力测试时，服务器可能返回成功的“ HTTP响应”代码，但是页面上可能有错误或缺少部分。您可以添加断言来检查某些HTML标记，常见错误字符串等。JMeter允许您使用正则表达式创建这些断言。&lt;/p&gt;
&lt;h4&gt;&lt;strong&gt;3.6&lt;/strong&gt;逻辑控制器(Logic Controllers)&lt;/h4&gt;
&lt;p&gt;逻辑控制器使您可以自定义JMeter用于决定何时发送请求的逻辑。逻辑控制器可以更改来自其子元素的请求的顺序。他们可以自己修改请求，使JMeter重复请求，等等。&lt;br/&gt;&lt;strong&gt;逻辑控制器器的添加路径：【测试计划】-【线程组】-【逻辑控制器】。&lt;/strong&gt;&lt;br/&gt;要了解逻辑控制器对测试计划的影响，请看一下以下测试树：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1232840/202005/1232840-20200519095555369-1245615656.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Test Plan&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Thread Group&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Once Only Controller&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Login Request (an HTTP Request)&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Load Search Page (HTTP Sampler)&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Interleave Controller&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Search &quot;A&quot; (HTTP Sampler)&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Search &quot;B&quot; (HTTP Sampler)&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;HTTP default request (Configuration Element)&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;HTTP default request (Configuration Element)&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Cookie Manager (Configuration Element)&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;此测试的第一件事是，登录请求将仅在第一次执行。随后的迭代将跳过它。这是由于“ &lt;strong&gt;Once Only Controller&lt;/strong&gt;”的作用。&lt;br/&gt;登录后，下一个Sampler将加载搜索页面（我们可以想象一个测试场景：用户登录到Web应用程序，然后转到搜索页面进行搜索）。这只是一个简单的请求，不会通过任何逻辑控制器进行过滤。&lt;br/&gt;加载搜索页面后，我们要进行搜索。实际上，我们要进行两种不同的搜索。但是，我们希望在每次搜索之间重新加载搜索页面本身。我们可以通过具有4个简单的HTTP请求元素（加载搜索，搜索“ A”，加载搜索，搜索“ B”）来实现。相反，我们使用“&lt;strong&gt;Interleave Controller&lt;/strong&gt;”，该控制器每次通过测试都会传递一个子请求。它保持子元素的顺序（即，它不会随机传递，而是“记住”其位置）。交叉处理2个子请求可能会过多，但很容易会有8个或20个子请求。&lt;br/&gt;注意HTTP请求默认值属于Interleave Controller。想象一下，“搜索A”和“搜索B”共享相同的PATH信息（HTTP请求规范包括域，端口，方法，协议，路径和参数以及其他可选项）。这很有道理-都是搜索请求，都命中了相同的后端搜索引擎（例如servlet或cgi-script）。与其在PATH字段中为两个HTTP Samplers配置相同的信息，不如将这些信息抽象到单个Configuration Element中。当Interleave Controller“传递”来自“搜索A”或“搜索B”的请求时，它将使用&lt;strong&gt;HTTP default request&lt;/strong&gt;配置元件中的值填充空白。因此，对于这些请求，我们将PATH字段留空，并将该信息放入配置元素。在这种情况下，这充其量是次要的好处，但可以证明其功能。&lt;br/&gt;树中的下一个元素是另一个&lt;strong&gt;HTTP default request&lt;/strong&gt;，这次已添加到线程组本身。线程组具有内置的逻辑控制器，因此，它完全如上所述使用此配置元件。它填补了所有通过的请求的空白。因此在Web测试中，将所有HTTP Sampler元件中的DOMAIN字段保留为空白，然后将该信息放入HTTP默认请求元素（添加到线程组中）非常有用。这样，您只需更改测试计划中的一个字段即可在另一台服务器上测试应用程序。否则，您将必须编辑每个Sampler。&lt;br/&gt;最后一个元件是HTTP &lt;strong&gt;Cookie Manager&lt;/strong&gt;。&lt;strong&gt;Cookie Manager&lt;/strong&gt;应添加到所有Web测试中-否则JMeter将忽略cookie。通过在线程组级别添加它，我们确保所有HTTP请求将共享相同的cookie。&lt;br/&gt;逻辑控制器可以组合使用以获得各种结果。请参阅内置逻辑控制器列表。&lt;/p&gt;
&lt;h4&gt;&lt;strong&gt;3.7测试片段（Test Fragments）&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;测试片段元素是一种特殊类型的控制器，它与线程组元素位于同一级别的测试计划树上。它与线程组的区别在于，除非被模块控制器或Include_Controller引用，否则它不会执行。&lt;br/&gt;此元件仅用于测试计划中的代码重用。它是一个辅助的组件，在此节点下几乎可以放置任何JMeter测试元件，但它一般不会被运行，那么它的作用到底是什么了？&lt;br/&gt;（1）在脚本开发的过程中，可以用来备份元件。&lt;br/&gt;（2）可以被模块控制台调用，我们可以用它模块化请求（是不是有点似曾相识的感觉了，没错就是程序开发中的，将业务封装成一个方法供复用）供模块化控制器调用&lt;/p&gt;
&lt;h4&gt;&lt;strong&gt;3.8监听器(Listeners)&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;监听器提供对JMeter运行时JMeter收集的有关测试用例的信息的访问。图形结果听者曲线在曲线图上的响应时间。“查看结果树”侦听器显示采样器请求和响应的详细信息，并可以显示响应的基本HTML和XML表示形式。其他侦听器提供摘要或聚合信息。&lt;br/&gt;此外，监听器可以将数据定向到文件以供以后使用。JMeter中的每个监听器都提供一个字段来指示要将数据存储到的文件。还有一个“配置”按钮，可用于选择要保存的字段以及使用CSV还是XML格式。&lt;br/&gt;请注意，所有监听器都保存相同的数据。唯一的区别在于数据在屏幕上的显示方式。&lt;br/&gt;可以在测试中的任何位置（包括直接在测试计划下）添加监听器。他们将仅从其级别或以下级别的元素收集数据。&lt;br/&gt;JMeter附带了多个监听器。JMeter的测试结果需要添加监听器来收集。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;监听器的添加路径：【测试计划】-【监听器】&lt;/strong&gt;&lt;/p&gt;
&lt;h5&gt;&lt;strong&gt;3.8.1监听器的任务&lt;/strong&gt;&lt;/h5&gt;
&lt;p&gt;（1）添加监听结果，并且可以保存测试结果到文件中，这些测试结果可以供再次分析使用。&lt;br/&gt;（2）展示结果，JMeter可以以表格以及图形的形式展示测试结果，方便测试人员分析测试结果。我们在开发测试脚本的时候，不可避免需要调试，监听器也提供了辅助（例如：我们查看结果树，我们在其中可以看到请求与响应的数据）。&lt;/p&gt;
&lt;h4&gt;&lt;strong&gt;3.9&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;定时器（&lt;/span&gt;Timer）&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;默认情况下，JMeter线程按顺序执行采样器而不会暂停。我们建议您通过将可用计时器之一添加到线程组来指定延迟。如果不添加延迟，JMeter可能会在很短的时间内发出太多请求，从而使服务器不堪重负。这就是我们通常说的负载，为了足够真实的模拟用户负载，我们有时候会需要模拟这些请求在同一时刻发送，就好像把大家集合在同一起跑线上，然后扣动发令枪的扳机，同时向终点（被测试系统）冲去。&lt;br/&gt;计时器将导致JMeter 在其范围内的每个采样器之前延迟一定的时间。&lt;br/&gt;如果您选择在一个线程组中添加多个计时器，JMeter将使用计时器的总和，并在执行该计时器所适用的采样器之前暂停该时间。可以将计时器作为采样器或控制器的子级添加，以限制将它们应用到的采样器。&lt;br/&gt;要在测试计划中的单个位置提供暂停，可以使用Flow Control Action Sampler。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;定时器的添加路径：【测试计划】-【线程组】-【定时器】。&lt;/strong&gt;&lt;/p&gt;
&lt;h4&gt;&lt;strong&gt;3.10断言&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;说到断言对于我们一个测试来说应该很熟悉了吧。断言用来验证结果是否正确，说白了就是用一个预设的结果（期望值、表达式、时间长短等条件）与实际结果匹配，匹配到成功，反之失败。断言使您可以断言有关从被测试服务器收到的响应的事实。使用断言，您基本上可以“测试”您的应用程序正在返回期望的结果。&lt;br/&gt;例如，您可以断言对查询的响应将包含一些特定的文本。您指定的文本可以是Perl样式的正则表达式，并且可以指示响应包含文本，或者应与整个响应匹配。&lt;br/&gt;您可以将断言添加到任何采样器。例如，您可以将断言添加到HTTP请求中以检查文本“ &amp;lt;/ HTML&amp;gt; ”。然后，JMeter将检查该文本是否出现在HTTP响应中。如果JMeter找不到文本，则它将标记为失败的请求。&lt;br/&gt;请注意，断言适用于其范围内的所有采样器。要将声明限制为单个采样器，请将该声明添加为采样器的子代。&lt;br/&gt;要查看断言结果，请将“断言侦听器”添加到线程组。失败的断言还将显示在树视图和表侦听器中，并将计入错误百分比，例如在“汇总”和“摘要”报告中。&lt;/p&gt;
&lt;h4&gt;&lt;strong&gt;3.11配置元件&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;性能测试中为了模拟大量的用户操作系统，我们往往需要做参数化，JMeter的参数化可以通过配置元件来完成。例如：CSV Data Set Config，它可以帮助我们从文件中读取测试数据。另外JMeter也提供了众多函数（通过函数助手可以查看到，后续宏哥会讲到，这里只是简单的提一下）来帮助我们动态的生成数据。当然了配置元件的作用不仅于此，它还可以记录服务器的返回数据，例如：Http Cache Manager，自动记录服务器返回的Cache信息，简而言之就是它为取样器提供预备数据，然后由取样器发出请求。配置元素与采样器紧密配合。尽管它不发送请求（HTTP（S）测试脚本记录器除外），但是它可以添加或修改请求。&lt;br/&gt;配置元素只能从放置该元素的树枝内部访问。例如，如果您将HTTP Cookie Manager放置在简单逻辑控制器中，则您放置在Simple Logic Controller中的HTTP请求控制器将只能访问Cookie Manager（请参见图1）。Cookie管理器可用于HTTP请求“网页1”和“网页2”，但不能访问“网页3”。&lt;br/&gt;而且，树枝内部的配置元素比“父”分支中的相同元素具有更高的优先级。例如，我们定义了两个HTTP请求默认值元素：“ Web默认值1”和“ Web默认值2”。由于我们在循环控制器内放置了“ Web Defaults 1”，因此只有“ Web Page 2”可以访问它。其他HTTP请求将使用“ Web默认值2”，因为我们将其放置在线程组（所有其他分支的“父级”）中。&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://jmeter.apache.org/images/screenshots/http-config/http-config-example.png&quot;&gt;&lt;img src=&quot;https://jmeter.apache.org/images/screenshots/http-config/http-config-example.png&quot; alt=&quot;图1-显示配置元素可访问性的测试计划&quot; width=&quot;&quot; height=&quot;&quot;/&gt;&lt;/a&gt;&lt;span&gt;图1-显示配置元素可访问性的测试计划&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;在用户定义的变量配置元素是不同的。无论在何处放置，都将在测试开始时对其进行处理。为简单起见，建议将元素仅放置在线程组的开始处。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;配置元件的添加路径：【测试计划】-【配置元件】。&lt;/strong&gt;&lt;/p&gt;
&lt;h4&gt;&lt;strong&gt;3.12前置处理器&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;预处理器在发出“采样器请求”之前执行一些操作。如果将预处理器附加到Sampler元素，则它将在该Sampler元素运行之前执行。预处理器最常用于在样品请求运行前修改其设置，或更新未从响应文本中提取的变量。有关执行预处理器的更多详细信息，请参见作用域规则。这块宏哥举一个使用这个元件的测试场景：在测试脚本的开发过程中，我们在请求发送之前可能会做一些环境或者参数的准备工作，那么我们可以在前置处理器中来完成这些工作。例如：我们对数据库进行操作前需要建立一个数据库连接，那么前置处理器就可以完成这个功能。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;前置处理器的添加路径：【测试计划】-【前置处理器】。&lt;/strong&gt;&lt;/p&gt;
&lt;h4&gt;&lt;strong&gt;3.13后置处理器&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;后置处理器一般放在取样器之后，用来处理服务器的返回结果，例如：一个Web应用程序，我们登录之后会返回一个SessionID，这个SessionID在登录之后的业务操作过程中会作为验证条件，验证用户是否合法登录了之后才进行的业务操作。发出采样器请求后，后处理器将执行某些操作。如果将后处理器附加到Sampler元素，则它将在该Sampler元素运行之后立即执行。后处理器最常用于处理响应数据，经常从中提取值。有关执行后处理器的更多详细信息，请参见作用域规则。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;span&gt;到此，我们已经简单了解了&lt;/span&gt;jmeter的基本组成原件，我们后序的测试工作也就是使用这些元件来完成测试任务。&lt;/strong&gt;&lt;/p&gt;
&lt;h4&gt;&lt;strong&gt;3.14执行顺序&lt;/strong&gt;&lt;/h4&gt;
&lt;ol start=&quot;0&quot;&gt;&lt;li&gt;&lt;span&gt;配置元素&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span&gt;预处理器&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span&gt;计时器&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span&gt;取样器&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span&gt;后处理器（除非SampleResult为&lt;/span&gt;&lt;span class=&quot;code&quot;&gt;&lt;span&gt;&lt;span&gt;null&lt;/span&gt;&lt;/span&gt;&lt;span&gt;）&lt;/span&gt;&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span&gt;断言（除非SampleResult为&lt;/span&gt;&lt;span class=&quot;code&quot;&gt;&lt;span&gt;&lt;span&gt;null&lt;/span&gt;&lt;/span&gt;&lt;span&gt;）&lt;/span&gt;&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span&gt;监听器（除非SampleResult为&lt;/span&gt;&lt;span class=&quot;code&quot;&gt;&lt;span&gt;&lt;span&gt;null&lt;/span&gt;&lt;/span&gt;&lt;span&gt;）&lt;/span&gt;&lt;/span&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;请注意，计时器，断言，预处理器和后处理器只有在有适用的采样器时才被处理。&lt;/span&gt;&lt;span&gt;逻辑控制器和采样器按照它们在树中出现的顺序进行处理。&lt;/span&gt;&lt;span&gt;其他测试元素将根据其发现范围和测试元素的类型进行处理。&lt;/span&gt;&lt;span&gt;[在一种类型中，元素按照它们在树中出现的顺序进行处理]。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;例如，在以下测试计划中：&lt;/span&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;span&gt;控制器&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;
&lt;ul&gt;&lt;li&gt;&lt;span&gt;后处理器1&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span&gt;采样器1&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span&gt;采样器2&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span&gt;计时器1&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span&gt;断言1&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span&gt;预处理器1&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span&gt;计时器2&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span&gt;后处理器2&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;执行顺序为：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;33&quot;&gt;
&lt;pre&gt;
&lt;span&gt;预处理器1
计时器1
计时器2
采样器1
后处理器1
后处理器2
断言1

预处理器1
计时器1
计时器2
采样器2
后处理器1
后处理器2
断言1&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h4&gt;&lt;strong&gt;3.15范围鉴定规则&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;&lt;span&gt;&lt;span&gt;JMeter测试树包含分层和有序的元素。&lt;/span&gt;&lt;span&gt;测试树中的某些元素严格地是分层的（侦听器，配置元素，后处理器，预处理器，断言，计时器），而有些则主要是有序的（控制器，采样器）。&lt;/span&gt;&lt;span&gt;创建测试计划时，您将创建样本请求的有序列表（通过Samplers），该列表表示要执行的一组步骤。&lt;/span&gt;&lt;span&gt;这些请求通常在也已排序的控制器中组织。&lt;/span&gt;&lt;span&gt;给定以下测试树：&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://jmeter.apache.org/images/screenshots/scoping1.png&quot;&gt;&lt;img src=&quot;https://jmeter.apache.org/images/screenshots/scoping1.png&quot; alt=&quot;示例测试树&quot; width=&quot;&quot; height=&quot;&quot;/&gt;&lt;/a&gt;&lt;span&gt;示例测试树&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;请求的顺序将为一，二，三，四。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;某些控制器会影响其子元素的顺序，您可以在&lt;/span&gt;&lt;span&gt;组件参考中&lt;/span&gt;&lt;span&gt;&lt;span&gt;阅读有关这些特定控制器&lt;/span&gt;&lt;span&gt;的信息&lt;/span&gt;&lt;span&gt;。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;span&gt;其他元素是分层的。&lt;/span&gt;&lt;span&gt;例如，断言在测试树中是分层的。&lt;/span&gt;&lt;span&gt;如果其父项是一个请求，则将其应用于该请求。&lt;/span&gt;&lt;span&gt;如果其父级是Controller，则它将影响该Controller的所有后代请求。&lt;/span&gt;&lt;span&gt;在以下测试树中：&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://jmeter.apache.org/images/screenshots/scoping2.png&quot;&gt;&lt;img src=&quot;https://jmeter.apache.org/images/screenshots/scoping2.png&quot; alt=&quot;层次结构示例&quot; width=&quot;&quot; height=&quot;&quot;/&gt;&lt;/a&gt;&lt;span&gt;层次结构示例&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;断言1仅适用于请求1，而断言2仅适用于请求2和3。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;另一个示例，这次使用Timers：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://jmeter.apache.org/images/screenshots/scoping3.png&quot;&gt;&lt;img src=&quot;https://jmeter.apache.org/images/screenshots/scoping3.png&quot; alt=&quot;复杂的例子&quot; width=&quot;&quot; height=&quot;&quot;/&gt;&lt;/a&gt;&lt;span&gt;复杂的例子&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;span&gt;在此示例中，对请求进行命名以反映其执行顺序。&lt;/span&gt;&lt;span&gt;计时器＃1将应用于请求2、3和4（请注意顺序与分层元素无关）。&lt;/span&gt;&lt;span&gt;断言1仅适用于请求三。&lt;/span&gt;&lt;span&gt;计时器2将影响所有请求。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;span&gt;希望这些示例可以清楚说明如何应用配置（分层）元素。&lt;/span&gt;&lt;span&gt;如果您想象每个请求都在树枝上传递给它的父级，然后传递给它的父级的父级，等等，并且每次收集该父级的所有配置元素，那么您将了解它是如何工作的。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;span&gt;配置元素的标题管理器，Cookie管理器和授权管理器与配置默认元素的处理方式有所不同。&lt;/span&gt;&lt;span&gt;“配置默认值”元素中的设置被合并为采样器可以访问的一组值。&lt;/span&gt;&lt;span&gt;但是，管理器中的设置不会合并。&lt;/span&gt;&lt;span&gt;如果在一个采样器的范围内有多个Manager，则仅使用一个Manager，但是目前无法指定使用&lt;/span&gt;&lt;/span&gt;&lt;em&gt;哪个&lt;/em&gt;&lt;span&gt;&lt;span&gt; Manager &lt;/span&gt;&lt;span&gt;。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h4&gt;&lt;strong&gt;3.16属性和变量&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;JMeter 属性在&lt;span class=&quot;code&quot;&gt;&lt;span&gt;&lt;span&gt;jmeter.properties&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;中定义&lt;/span&gt;&lt;span&gt;（&lt;/span&gt;&lt;span&gt;有关更多详细信息，&lt;/span&gt;&lt;span&gt;请参见&lt;/span&gt;&lt;/span&gt;&lt;span&gt;入门-配置JMeter&lt;/span&gt;&lt;span&gt;）。&lt;/span&gt;&lt;br/&gt;&lt;span&gt;&lt;span&gt;属性对于jmeter是全局的，并且主要用于定义JMeter使用的某些默认值。&lt;/span&gt;&lt;span&gt;例如，属性&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;code&quot;&gt;&lt;span&gt;&lt;span&gt;remote_hosts&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;定义JMeter将尝试远程运行的服务器。&lt;/span&gt;&lt;span&gt;可以在测试计划中引用属性-请参阅&lt;/span&gt;&lt;/span&gt;&lt;span&gt;功能-读取属性&lt;/span&gt;&lt;span&gt; -但不能用于特定于线程的值。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;JMeter &lt;/span&gt;&lt;em&gt;变量&lt;/em&gt;&lt;span&gt;&lt;span&gt;是每个线程局部的。&lt;/span&gt;&lt;span&gt;每个线程的值可以相同，也可以不同。&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;&lt;span&gt;&lt;span&gt;如果某个变量由线程更新，则仅更改该变量的线程副本。&lt;/span&gt;&lt;span&gt;例如，&lt;/span&gt;&lt;/span&gt;&lt;span&gt;正则表达式提取器&lt;/span&gt;&lt;span&gt;&lt;span&gt;后处理器将根据其线程读取的样本设置其变量，这些变量稍后可在同一线程中使用。&lt;/span&gt;&lt;span&gt;有关如何引用变量和函数的详细信息，请参见&lt;/span&gt;&lt;/span&gt;&lt;span&gt;函数和变量&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;span&gt;请注意，&lt;/span&gt;&lt;span&gt;在启动时，&lt;/span&gt;&lt;span&gt;将使&lt;/span&gt;&lt;span&gt; “ &lt;/span&gt;&lt;/span&gt;&lt;span&gt;测试计划”&lt;/span&gt;&lt;span&gt; 和“ &lt;/span&gt;&lt;span&gt;用户定义的变量”&lt;/span&gt;&lt;span&gt;&lt;span&gt;配置元素&lt;/span&gt;&lt;span&gt;定义&lt;/span&gt;&lt;span&gt;的值&lt;/span&gt;&lt;span&gt;可用于整个测试计划。&lt;/span&gt;&lt;span&gt;如果同一变量由多个UDV元素定义，则最后一个变量生效。&lt;/span&gt;&lt;span&gt;线程启动后，会将初始变量集复制到每个线程。&lt;/span&gt;&lt;span&gt;其他元素（例如 &lt;/span&gt;&lt;/span&gt;&lt;span&gt;用户参数&lt;/span&gt;&lt;span&gt;预处理器或&lt;/span&gt;&lt;span&gt;正则表达式提取器&lt;/span&gt;&lt;span&gt;&lt;span&gt;后处理器）可用于重新定义相同的变量（或创建新变量）。&lt;/span&gt;&lt;span&gt;这些重新定义仅适用于当前线程。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;所述&lt;/span&gt;&lt;span&gt;的setProperty&lt;/span&gt;&lt;span&gt;&lt;span&gt;函数可以用来定义JMeter的属性。&lt;/span&gt;&lt;span&gt;这些对于测试计划是全局的，因此可以用于在线程之间传递信息-如果需要的话。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;变量和属性都区分大小写。&lt;/span&gt;&lt;/p&gt;
&lt;h4&gt;&lt;strong&gt;3.17使用变量对测试参数化&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;变量不必更改-可以定义一次，并且如果单独保留，则不会更改值。因此，您可以将它们用作测试计划中经常出现的表达式的简写形式。或对于在运行期间保持恒定但在运行之间可能有所不同的项目。例如，主机名或线程组中的线程数。&lt;br/&gt;在决定如何构建测试计划时，请记下哪些项目对于运行是恒定的，但在运行之间可能会改变。为此确定一些变量名称-也许使用命名约定，例如以C_或K_前缀，或仅使用大写字母将它们与测试期间需要更改的变量区分开。还应考虑哪些项需要在线程本地进行，例如使用正则表达式后处理程序提取的计数器或值。您可能希望对它们使用不同的命名约定。&lt;br/&gt;例如，您可以在测试计划中定义以下内容：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;32&quot;&gt;
&lt;pre&gt;
&lt;span&gt;主机www.example.com
底线10
圈数20&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;您可以在测试计划中将它们称为$ {HOST} $ {THREADS}等。如果以后要更改主机，只需更改HOST变量的值即可。这对于少量的测试工作正常，但是在测试许多不同的组合时变得乏味。一种解决方案是使用属性来定义变量的值，例如：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;33&quot;&gt;
&lt;pre&gt;
&lt;span&gt;主机$ {__ P（host，www.example.com）}
螺纹$ {__ P（threads，10）}
循环$ {__ P（loops，20）}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;然后，您可以在命令行上更改某些或所有值，如下所示：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;32&quot;&gt;
&lt;pre&gt;
jmeter…-Jhost = www3.example.org -Jloops = 13
&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;4.小结&lt;/h3&gt;
&lt;p&gt; 好了，今天有关测试计划（Test Plan）的元件就分享到这里，后边后对这些元件进行详细的介绍和说明，以及会涉及到部分元件的实际应用。灰常感谢您阅读到这里，如果您觉得不错，就帮忙点个推荐呗。&lt;/p&gt;
&lt;p&gt;&lt;span&gt;您的肯定就是我进步的动力。如果你感觉还不错，就请鼓励一下吧！记得随手点波&lt;strong&gt;  &lt;span&gt;推荐&lt;/span&gt;  &lt;/strong&gt;不要忘记哦！！！&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;别忘了点 &lt;strong&gt;&lt;span&gt;推荐&lt;/span&gt; &lt;/strong&gt;留下您来过的痕迹&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt; &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1232840/201908/1232840-20190816135641371-1314831001.gif&quot; alt=&quot;&quot;/&gt;&lt;/span&gt;&lt;/p&gt;
</description>
<pubDate>Tue, 26 May 2020 00:08:00 +0000</pubDate>
<dc:creator>北京-宏哥</dc:creator>
<og:description>1.简介 上一篇中宏哥已经教你如何通过JMeter来创建一个测试计划（Test Plan），那么这一篇我们就将JMeter启动起来，创建一个测试计划（Test plan），然后宏哥给大家介绍一下测试计</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/du-hong/p/12909175.html</dc:identifier>
</item>
<item>
<title>人工智能中小样本问题相关的系列模型演变及学习笔记（含元学习/小样本学习/生成对抗网络/迁移学习等） - FinTecher</title>
<link>http://www.cnblogs.com/zhengzhicong/p/12952354.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/zhengzhicong/p/12952354.html</guid>
<description>&lt;p&gt;一、Meta Learning 元学习综述 二、Few-shot Learning 小样本学习综述 三、生成对抗网络 GAN 综述 四、迁移学习综述 五、深度迁移学习综述 六、其他概念介绍：知识蒸馏、增量学习&lt;/p&gt;&lt;div id=&quot;cnblogs_post_body&quot; readability=&quot;752.22322344322&quot;&gt;
&lt;p&gt;【说在前面】本人博客新手一枚，象牙塔的老白，职业场的小白。以下内容仅为个人见解，欢迎批评指正，不喜勿喷！[握手][握手]&lt;/p&gt;
&lt;p&gt;【再啰嗦一下】本来只想记一下GAN的笔记，没想到发现了一个大宇宙，很多个人并不擅长，主要是整理归纳！&lt;/p&gt;
&lt;h2&gt;一、Meta Learning 元学习综述&lt;/h2&gt;
&lt;blockquote readability=&quot;13&quot;&gt;
&lt;p&gt;&lt;strong&gt;Meta Learning，又称为 learning to learn，已经成为继 Reinforcement Learning 之后又一个重要的研究分支。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;元学习区别于机器学习的是：机器学习通常是在拟合一个数据的分布，而元学习是在拟合一系列相似任务的分布。&lt;/p&gt;
&lt;p&gt;本节主要参考了大佬的知乎专栏：https://zhuanlan.zhihu.com/p/28639662&lt;/p&gt;
&lt;p&gt;推荐Stanford助理教授Chelsea Finn开设的CS330 multitask and meta learning课程&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;&lt;li&gt;在 Machine Learning 机器学习时代，对于复杂一点的分类问题，模型效果就不好了。&lt;/li&gt;
&lt;li&gt;Deep Learning 深度学习解决了一对一映射问题，但如果输出对下一个输入有影响，也就是sequential decision making问题，单一的深度学习就解决不了了。&lt;/li&gt;
&lt;li&gt;Deep Reinforcement Learning 深度强化学习对序列决策取得成效，但深度强化学习太依赖于巨量的训练，并且需要精确的Reward。&lt;/li&gt;
&lt;li&gt;人类之所以能够快速学习的关键是人类具备学会学习的能力，能够充分利用以往的知识经验来指导新任务的学习，因此 Meta Learning 成为新的攻克方向。&lt;/li&gt;
&lt;/ul&gt;&lt;h3&gt;1. 基本概念&lt;/h3&gt;
&lt;p&gt;元学习是要去学习任务中的特征表示，从而在新的任务上泛化。举个例子，以下图的图像分类来说，元学习的训练过程是在task1和task2上训练模型（更新模型参数），而在训练样本中的训练集一般称作support set，训练样本中的测试集一般叫做query set。测试过程是在测试任务上评估模型好坏，从图中可以看出，测试任务和训练任务内容完全不同。&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; src=&quot;https://pic4.zhimg.com/80/v2-72b4d5e746720ccd84bd0f54dc8915a3_720w.jpg&quot; alt=&quot;&quot; width=&quot;432&quot; height=&quot;299&quot; data-lazy-status=&quot;ok&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-72b4d5e746720ccd84bd0f54dc8915a3_b.jpg&quot; data-original=&quot;https://pic4.zhimg.com/v2-72b4d5e746720ccd84bd0f54dc8915a3_r.jpg&quot; data-rawheight=&quot;488&quot; data-rawwidth=&quot;706&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;元学习解决的是学习如何学习的问题，元学习的思想是学习「学习（训练）」过程。&lt;/strong&gt;元学习主要包括Zero-Shot/One-Shot/Few-Shot 学习、模型无关元学习(Model Agnostic Meta Learning)和元强化学习（Meta Reinforcement Learning）等。&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;Zero-shot Learing 就是训练样本里没有这个类别的样本，但是如果我们可以学到一个牛逼的映射，这个映射好到我们即使在训练的时候没看到这个类，但是我们在遇到的时候依然能通过这个映射得到这个新类的特征。&lt;/li&gt;
&lt;li&gt;One-shot Learing 就是类别下训练样本只有一个或者很少，我们依然可以进行分类。比如我们可以在一个更大的数据集上或者利用knowledge graph、domain-knowledge 等方法，学到一个一般化的映射，然后再到小数据集上进行更新升级映射。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Few-Shot Learing 的综述将在下一节重点整理，这里暂时不展开介绍。&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;元学习的主要方法包括基于记忆Memory的方法、基于预测梯度的方法、利用Attention注意力机制的方法、借鉴LSTM的方法、面向RL的Meta Learning方法、利用WaveNet的方法、预测Loss的方法等。&lt;/p&gt;
&lt;h3&gt;2. 基于记忆Memory的方法&lt;/h3&gt;
&lt;p&gt;基本思路：既然要通过以往的经验来学习，那么是不是可以通过在神经网络上添加Memory来实现呢？&lt;/p&gt;
&lt;p&gt;代表方法包括：&lt;strong&gt;Meta-learning with memory-augmented neural networks&lt;/strong&gt;、Meta Networks等。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1998154/202005/1998154-20200525011435806-176755909.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;可以看到，网络的输入把上一次的y label也作为输入，并且添加了external memory存储上一次的x输入，这使得下一次输入后进行反向传播时，可以让y label和x建立联系，使得之后的x能够通过外部记忆获取相关图像进行比对来实现更好的预测。&lt;/p&gt;
&lt;h3&gt;3. 基于预测梯度的方法&lt;/h3&gt;
&lt;p&gt;基本思路：既然Meta Learning的目的是实现快速学习，而快速学习的关键一点是神经网络的梯度下降要准，要快，那么是不是可以让神经网络利用以往的任务学习如何预测梯度，这样面对新的任务，只要梯度预测得准，那么学习得就会更快了？&lt;/p&gt;
&lt;p&gt;代表方法包括：&lt;strong&gt;Learning to learn by gradient descent by gradient descent&lt;/strong&gt; 等。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1998154/202005/1998154-20200525011727314-829247479.png&quot; alt=&quot;&quot; width=&quot;580&quot; height=&quot;245&quot;/&gt;&lt;/p&gt;
&lt;p&gt;该方法训练一个通用的神经网络来预测梯度，用一次二次方程的回归问题来训练，优化器效果比Adam、RMSProp好，显然就加快了训练。&lt;/p&gt;
&lt;h3&gt;4. 利用Attention注意力机制的方法&lt;/h3&gt;
&lt;p&gt;基本思路：人的注意力是可以利用以往的经验来实现提升的，比如&lt;strong&gt;我们看一个性感图片，我们会很自然的把注意力集中在关键位置&lt;/strong&gt;。那么，能不能利用以往的任务来训练一个Attention模型，从而面对新的任务，能够直接关注最重要的部分。&lt;/p&gt;
&lt;p&gt;代表方法包括：&lt;strong&gt;Matching networks for one shot learning&lt;/strong&gt; 等。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1998154/202005/1998154-20200525011931024-1544726286.png&quot; alt=&quot;&quot; width=&quot;377&quot; height=&quot;236&quot;/&gt;&lt;/p&gt;
&lt;p&gt;这篇文章构造一个attention机制，也就是最后的label判断是通过attention的叠加得到的：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Cbar%7By%7D+%3D+%5Csum_%7Bi%3D1%7D%5E%7Bk%7D%7Ba%28%5Cbar%7Bx%7D%2Cx_i%29%7Dy_i+&quot; alt=&quot;[公式]&quot; data-formula=&quot;\bar{y} = \sum_{i=1}^{k}{a(\bar{x},x_i)}y_i&quot;/&gt;&lt;/p&gt;
&lt;p&gt;attention a 则通过 g 和 f 得到。基本目的就是利用已有任务训练出一个好的attention model。&lt;/p&gt;
&lt;h3&gt;5. 借鉴LSTM的方法&lt;/h3&gt;
&lt;p&gt;基本思路：LSTM内部的更新非常类似于梯度下降的更新，那么，能否利用LSTM的结构训练出一个神经网络的更新机制，输入当前网络参数，直接输出新的更新参数？&lt;/p&gt;
&lt;p&gt;代表方法包括：&lt;strong&gt;Optimization as a model for few-shot learning&lt;/strong&gt; 等。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1998154/202005/1998154-20200525012127864-908202023.png&quot; alt=&quot;&quot; width=&quot;515&quot; height=&quot;184&quot;/&gt;&lt;/p&gt;
&lt;p&gt;这篇文章的核心思想是下面这一段：&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; src=&quot;https://pic4.zhimg.com/80/v2-1bb24f764fd47ad3903db7504a170243_720w.png&quot; alt=&quot;&quot; width=&quot;511&quot; height=&quot;153&quot; data-lazy-status=&quot;ok&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-1bb24f764fd47ad3903db7504a170243_b.png&quot; data-original=&quot;https://pic4.zhimg.com/v2-1bb24f764fd47ad3903db7504a170243_r.jpg&quot; data-rawheight=&quot;504&quot; data-rawwidth=&quot;1680&quot;/&gt;&lt;/p&gt;
&lt;p&gt;怎么把LSTM的更新和梯度下降联系起来才是更值得思考的问题吧。&lt;/p&gt;
&lt;h3&gt;6. 面向RL的Meta Learning方法&lt;/h3&gt;
&lt;p&gt;基本思路：Meta Learning可以用在监督学习，那么增强学习上怎么做呢？能否通过增加一些外部信息比如reward，之前的action来实现？&lt;/p&gt;
&lt;p&gt;代表方法包括：Learning to reinforcement learn、&lt;strong&gt;Rl2: Fast reinforcement learning via slow reinforcement learning&lt;/strong&gt; 等。&lt;/p&gt;
&lt;p&gt;两篇文章思路一致，就是额外增加reward和之前action的输入，从而强制让神经网络学习一些任务级别的信息：&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; src=&quot;https://pic2.zhimg.com/80/v2-b27c44264d6ab5537fe7a90529f6c2c1_720w.png&quot; alt=&quot;&quot; width=&quot;588&quot; height=&quot;250&quot; data-lazy-status=&quot;ok&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-b27c44264d6ab5537fe7a90529f6c2c1_b.png&quot; data-original=&quot;https://pic2.zhimg.com/v2-b27c44264d6ab5537fe7a90529f6c2c1_r.jpg&quot; data-rawheight=&quot;722&quot; data-rawwidth=&quot;1698&quot;/&gt;&lt;/p&gt;
&lt;h3&gt;7. 通过训练一个好的base model的方法，并且同时应用到监督学习和强化学习&lt;/h3&gt;
&lt;p&gt;基本思路：之前的方法都只能局限在监督学习或强化学习上，能搞个更通用的？是不是相比finetune学习一个更好的base model就能work？&lt;/p&gt;
&lt;p&gt;主要方法包括：&lt;strong&gt;Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks&lt;/strong&gt; 等。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1998154/202005/1998154-20200525012447421-1098722904.png&quot; alt=&quot;&quot; width=&quot;409&quot; height=&quot;183&quot;/&gt;&lt;/p&gt;
&lt;p&gt;这篇文章的基本思路是同时启动多个任务，然后获取不同任务学习的合成梯度方向来更新，从而学习一个共同的最佳base。&lt;/p&gt;
&lt;h3&gt;8. 利用WaveNet的方法&lt;/h3&gt;
&lt;p&gt;基本思路：WaveNet的网络每次都利用了之前的数据，是否可以照搬WaveNet的方式来实现Meta Learning呢？就是充分利用以往的数据呀？&lt;/p&gt;
&lt;p&gt;主要方法包括：&lt;strong&gt;Meta-Learning with Temporal Convolutions&lt;/strong&gt; 等。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1998154/202005/1998154-20200525012553515-736404638.png&quot; alt=&quot;&quot; width=&quot;575&quot; height=&quot;245&quot;/&gt;&lt;/p&gt;
&lt;p&gt;直接利用之前的历史数据，思路极其简单，效果极其之好，是目前omniglot，mini imagenet图像识别的state-of-the-art。&lt;/p&gt;
&lt;h3&gt;9. 预测Loss的方法&lt;/h3&gt;
&lt;p&gt;基本思路：要让学习的速度更快，除了更好的梯度，如果有更好的loss，那么学习的速度也会更快，因此，是不是可以构造一个模型利用以往的任务来学习如何预测Loss呢？&lt;/p&gt;
&lt;p&gt;主要方法包括：&lt;strong&gt;Learning to Learn: Meta-Critic Networks for Sample Efficient Learning&lt;/strong&gt; 等。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1998154/202005/1998154-20200525012700762-1838887075.png&quot; alt=&quot;&quot; width=&quot;581&quot; height=&quot;229&quot;/&gt;&lt;/p&gt;
&lt;p&gt;本文构造了一个Meta-Critic Network（包含Meta Value Network和Task-Actor Encoder）来学习预测Actor Network的Loss。对于Reinforcement Learning而言，这个Loss就是Q Value。&lt;/p&gt;
&lt;h3&gt;10. 小结&lt;/h3&gt;
&lt;p&gt;这是两年前的综述了，但是感觉质量很高。当然，后续又有了一些新进展。在应用上，元学习应用到了更广泛的问题上，例如小样本图像分类、视觉导航、机器翻译和语音识别等。在算法上，最值得一提的应该就是&lt;strong&gt;元强化学习&lt;/strong&gt;，因为这样的结合将有望使智能体能够更快速地学习新的任务，这个能力对于部署在复杂和不断变化的世界中的智能体来说是至关重要的。&lt;/p&gt;
&lt;p&gt;具体的，以上关于元学习的论文已经介绍了在策略梯度（policy gradient）和密集奖励（dense rewards）的有限环境中将元学习应用于强化学习的初步结果。此后，很多学者对这个方法产生了浓厚的兴趣，也有更多论文展示了将元学习理念应用到更广泛的环境中，比如：从人类演示中学习、模仿学习以及基于模型的强化学习。除了元学习模型参数外，还考虑了超参数和损失函数。为了解决稀疏奖励设置问题，也有了一种利用元学习来探索策略的方法。&lt;/p&gt;
&lt;p&gt;尽管取得了这些进展，样本效率仍然是一项挑战。当考虑将 meta-RL 应用于实际中更复杂的任务时，快速适应这些任务则需要更有效的探索策略。因此在实际学习任务中，需要考虑如何解决元训练样本效率低下的问题。因此，伯克利 AI 研究院基于这些问题进行了深入研究，并开发了一种旨在解决这两个问题的算法。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;最后分享看到的元学习 meta learning 的2020综述论文。提出了一个新的分类法，对元学习方法的空间进行了更全面的细分：[认真看图]&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote readability=&quot;7&quot;&gt;
&lt;p&gt;&lt;strong&gt;论文标题：Meta-Learning in Neural Networks: A Survey&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;论文链接：https://arxiv.org/abs/2004.05439&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1998154/202005/1998154-20200525020333962-127509809.png&quot; alt=&quot;&quot; width=&quot;775&quot; height=&quot;341&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1998154/202005/1998154-20200525020520835-669566881.png&quot; alt=&quot;&quot; width=&quot;776&quot; height=&quot;381&quot;/&gt;&lt;/p&gt;
&lt;h2&gt;二、Few-shot Learning 小样本学习综述&lt;/h2&gt;
&lt;blockquote readability=&quot;12&quot;&gt;
&lt;p&gt;&lt;strong&gt;Few-shot Learning 可以说是 元学习 Meta Learning 在监督学习领域的一个应用，当然也有它自己研究领域的东西。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;本节来自香港科技大学和第四范式的综述：Generalizing from a Few Examples： A Survey on Few-Shot Learning&lt;/p&gt;
&lt;p&gt;该综述已被 ACM Computing Surveys 接收，还建立了 GitHub repo，持续更新：https://github.com/tata1661/FewShotPapers&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3&gt;1. 基本概念&lt;/h3&gt;
&lt;p&gt;机器学习在数据密集型应用中非常成功，但当数据集很小时，它常常受到阻碍。为了解决这一问题，近年来提出了小样本学习(FSL)。利用先验知识，FSL可以快速地泛化到只包含少量有监督信息的样本的新任务中。&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;fontstyle0&quot;&gt;大多数人认为FSL就是 meta learning，其实不是。FSL可以是各种形式的学习（例如监督、半监督、强化学习、迁移学习等），本质上的定义取决于可用的数据。&lt;strong&gt;但现在大多数时候在解决FSL任务时，采用的都是 meta Learning 的一些方法。&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;基于各个方法利用先验知识处理核心问题的方式，该综述将 FSL 方法分为三大类：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;数据：利用先验知识增强监督信号&lt;/li&gt;
&lt;li&gt;模型：利用先验知识缩小假设空间的大小&lt;/li&gt;
&lt;li&gt;算法：利用先验知识更改给定假设空间中对最优假设的搜索&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/i-beta/1335117/202001/1335117-20200107184200179-1606317169.png&quot; alt=&quot;&quot; width=&quot;581&quot; height=&quot;252&quot;/&gt;&lt;/p&gt;
&lt;p&gt;基于此，该综述将现有的 FSL 方法纳入此框架，得到如下分类体系：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1998154/202005/1998154-20200524152212357-1153383732.png&quot; alt=&quot;&quot; width=&quot;583&quot; height=&quot;482&quot;/&gt;&lt;/p&gt;
&lt;h3&gt;&lt;strong&gt;2. DATA&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;数据增强的方式有很多种，平时也被使用的比较多，在这里作者将数据增强的方法概括成三类：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1998154/202005/1998154-20200524223654976-1163565810.png&quot; alt=&quot;&quot; width=&quot;584&quot; height=&quot;134&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1998154/202005/1998154-20200524223006857-1275695325.png&quot; alt=&quot;&quot; width=&quot;549&quot; height=&quot;323&quot;/&gt;&lt;/p&gt;
&lt;p&gt;总之，数据增强没有什么神秘感，可以是手动在数据上修改（例如图片的旋转、句子中的同义词替换等），也可以是复杂的生成模型（生成和真实数据相近的数据）。数据增强的方式有很多种，大量合适的增强一定程度上可以缓解FSL问题，但其能力还是有限的。&lt;/p&gt;
&lt;h3&gt;3. MODEL&lt;/h3&gt;
&lt;p&gt;和模型剪枝中的理念类似，你一开始给一个小的模型，这个模型空间离真实假设太远了。而你给一个大的模型空间，它离真实假设近的概率比较大，然后通过先验知识去掉哪些离真实假设远的假设。&lt;/p&gt;
&lt;p&gt;作者根据使用不同的先验知识将MODEL的方法分成4类：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1998154/202005/1998154-20200524223812323-1097791824.png&quot; alt=&quot;&quot; width=&quot;584&quot; height=&quot;139&quot;/&gt;&lt;/p&gt;
&lt;h4&gt;3.1 Multitask Learning&lt;/h4&gt;
&lt;p&gt;对于多个共享信息的任务（例如数据相同任务不同、数据和任务都不同等），都可以用&lt;strong&gt;多任务学习&lt;/strong&gt;来训练。&lt;/p&gt;
&lt;p&gt;多任务分为硬参数共享和软参数共享两种模式：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;硬参数共享认为任务之间的假设空间是有部分重叠的，体现在模型上就是有部分参数是共享的。而共享的参数可以是模型的前面一些层，表征任务的低阶信息。也可以是在嵌入层之后，不同的嵌入层将不同任务嵌入到同一不变任务空间，然后共享模型参数等。&lt;/li&gt;
&lt;li&gt;软参数共享不再显示的共享模型参数，而是让不同的任务的参数相似。这就可以通过不同任务的参数正则，或者通过损失来影响参数的相似，以此让不同任务的假设空间类似。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/i-beta/1335117/202001/1335117-20200107201451814-1465095916.png&quot; alt=&quot;&quot; width=&quot;656&quot; height=&quot;278&quot;/&gt;&lt;/p&gt;
&lt;p&gt;多任务通过多个任务来限制模型的假设空间：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;对于硬参数共享，多个任务会有一个共享的假设空间，然后每个任务还有自己特定的假设空间。&lt;/li&gt;
&lt;li&gt;对于软参数共享也类似，软参数更灵活，但也需要精心设计。&lt;/li&gt;
&lt;/ul&gt;&lt;h4&gt;3.2 Embedding Learning&lt;/h4&gt;
&lt;p&gt;嵌入学习很好理解，将训练集中所有的样本通过一个函数 f 嵌入到一个低维可分的空间Z，然后将测试集中的样本通过一个函数 g 嵌入到这个低维空间Z，然后计算测试样本和所有训练样本的相似度，选择相似度最高的样本的标签作为测试样本的标签。&lt;/p&gt;
&lt;p&gt;根据task-specific和task-invariant，以及两者的结合可以分为三种，嵌入学习如下：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;Task-specific是在任务自身的训练集上训练的，通过构造同类样本相同，不同类样本不同的样本对作为数据集，这样数据集会有一个爆炸式的扩充，可以提高样本的复杂度，然后可以用如&lt;strong&gt;siamese network&lt;/strong&gt;等来训练。&lt;/li&gt;
&lt;li&gt;Task-invariant是在一个大的且和任务相似的source数据集上训练一个嵌入模型，然后直接用于当前任务的训练集和测试集嵌入。&lt;/li&gt;
&lt;li&gt;实际上现在用的比较多的还是两者的结合，既可以利用大的通用数据集学习通用特征，又可以在特定任务上学习特定的特征，而现在常用的训练模式是meta learning中的metric-based的方式，此类常见的模型有&lt;strong&gt;match network、prototypical network、relation network&lt;/strong&gt;等。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/i-beta/1335117/202001/1335117-20200107203731133-1752571664.png&quot; alt=&quot;&quot; width=&quot;641&quot; height=&quot;293&quot;/&gt;&lt;/p&gt;
&lt;h4&gt;3.3 Learning with External Memory&lt;/h4&gt;
&lt;p&gt;具有外部存储机制的网络都可以用来处理这一类问题，其实本质上和&lt;strong&gt;迁移学习&lt;/strong&gt;一样。只不过这里不更新模型的参数，只更新外部记忆库。外部记忆库一般都是一个矩阵，如神经图灵机，其外部记忆库具有读写操作。&lt;/p&gt;
&lt;p&gt;在这里就是在一个用大量类似的数据训练的具有外部存储机制的网络上，用具体task的样本来更新外部记忆库。这类方法需要精心设计才能有好的效果，比如外部记忆库写入或更新的规则可能就影响模型能够在当前任务上的表现。具体的如下图所示：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/i-beta/1335117/202001/1335117-20200107210121222-1993622771.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;h4&gt;3.4 Generative Modeling&lt;/h4&gt;
&lt;p&gt;引入了&lt;strong&gt;生成式的模型&lt;/strong&gt;来解FSL问题。&lt;/p&gt;
&lt;h3&gt;4. &lt;span class=&quot;fontstyle0&quot;&gt;ALGORITHM&lt;br/&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;在机器学习中，通常使用SGD及其变体（例如ADAM、RMSProp等）来寻找最优参数。但是在FSL中，样本数量很少，这种方法就失效了。&lt;/p&gt;
&lt;p&gt;在这一节，我们不再限制假设空间。根据使用不同的先验知识，可以将ALGORITHM分为下面3类：&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1998154/202005/1998154-20200524224554794-715590654.png&quot; alt=&quot;&quot; width=&quot;591&quot; height=&quot;87&quot;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h4&gt;4.1 &lt;span class=&quot;fontstyle0&quot;&gt;Refine Existing Parameters&lt;span class=&quot;fontstyle2&quot;&gt;&lt;span class=&quot;fontstyle3&quot;&gt;&lt;br/&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h4&gt;
&lt;p&gt;本质就是&lt;strong&gt;pretrained + fine-tuning&lt;/strong&gt;的模式，最常见的就是直接在pre-trianed的模型上直接fine-tuning参数，还可以在一个新的网络上使用pre-trained的部分参数来初始化等。&lt;/p&gt;
&lt;h4&gt;&lt;span class=&quot;fontstyle0&quot;&gt;&lt;span class=&quot;fontstyle2&quot;&gt;&lt;span class=&quot;fontstyle3&quot;&gt;4.2 &lt;span class=&quot;fontstyle0&quot;&gt;Refine Meta-learned Parameters&lt;span class=&quot;fontstyle2&quot;&gt;&lt;br/&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h4&gt;
&lt;p&gt;该小节是基于 meta learning 的解决方法，利用元学习器学习一个好的初始化参数。之后在新的任务上，只要对这个初始化参数少量迭代更新就能很好的适应新的任务。这种方法最经典的模型就是&lt;strong&gt;MAML&lt;/strong&gt;，MAML的训练模式如下图所示：&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;fontstyle0&quot;&gt;&lt;span class=&quot;fontstyle2&quot;&gt;&lt;span class=&quot;fontstyle3&quot;&gt;&lt;span class=&quot;fontstyle0&quot;&gt;&lt;img src=&quot;https://img2018.cnblogs.com/i-beta/1335117/202001/1335117-20200108121829343-156739612.png&quot; alt=&quot;&quot; width=&quot;242&quot; height=&quot;210&quot;/&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;上面的参数是元学习器的参数，最后&lt;strong&gt;用多个任务的梯度矢量和来更新参数。&lt;/strong&gt;这样的方式也有一个问题，就是新的任务的特性必须要和元训练中的任务相近，这样值才能作为一个较好的初始化值，否则效果会很差。因此，也就有不少研究在根据新任务的数据集来动态的生成一个适合它的初始化参数。&lt;/p&gt;
&lt;h4&gt;4.3 Learn Search Steps&lt;/h4&gt;
&lt;p&gt;上一节使用元学习来获得一个较好的初始化参数，而本节旨在用元学习来学习一个参数更新的策略。&lt;span class=&quot;fontstyle0&quot;&gt;&lt;span class=&quot;fontstyle0&quot;&gt;针对每一个子任务能给定特定的优化方式实际上是提高性能的唯一方法，这里就是设计一个元优化器来为特定的任务提供特定的优化方法，具体的如下图所示：&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/i-beta/1335117/202001/1335117-20200108142814999-2118133424.png&quot; alt=&quot;&quot; width=&quot;356&quot; height=&quot;213&quot;/&gt;&lt;/p&gt;
&lt;p&gt;梯度的更新也可以写成：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/i-beta/1335117/202001/1335117-20200108142856951-125601714.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;在这里使用RNN来实现，因为RNN具有时序记忆功能，而梯度迭代的过程中正好是一个时序操作。具体的训练如下图所示：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/i-beta/1335117/202001/1335117-20200108145643020-198180851.png&quot; alt=&quot;&quot; width=&quot;534&quot; height=&quot;274&quot;/&gt;&lt;/p&gt;
&lt;p&gt;训练过程大致如下：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;对于每个任务，同样划分训练集和测试集，训练集经过meta-learner得到一系列的梯度，因为RNN每个时刻都有输出，因此每个时刻的梯度都去依次更新learner的参数ϕ。这样看就相当于一个batch的样本就更新了T次learner&lt;/li&gt;
&lt;li&gt;训练完一轮之后，用测试集在learner上的到的梯度来更新meta-learner的参数&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;这和上一节面临的问题一样，meta-learner 学到的更新策略是针对这一类任务的，一旦新任务和元训练中的任务偏差较大时，这种更新策略可能就失效了。&lt;/p&gt;
&lt;h3&gt;5. FUTURE WORKS&lt;/h3&gt;
&lt;p&gt;未来的方向可能有：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;从使用的先验数据：例如利用更多的先验知识、多模态的数据等&lt;/li&gt;
&lt;li&gt;从使用的模型方法：用新的网络结构去替换以前的，例如用transformer替换RNN&lt;/li&gt;
&lt;li&gt;从使用的场景：现在FSL在字符识别、图像识别、小样本分割等取得效果，在目标检测、目标跟踪、NLP中的各项任务上等值得尝试&lt;/li&gt;
&lt;li&gt;理论分析&lt;/li&gt;
&lt;li&gt;......&lt;/li&gt;
&lt;/ul&gt;&lt;h2&gt;三、生成对抗网络 GAN 综述&lt;/h2&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;说到小样本学习，就想说比较时髦的生成对抗网络GAN。别误会，生成对抗网络并不是只针对小样本生成，还有很多别的丰富应用。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3&gt;1. GAN&lt;/h3&gt;
&lt;p&gt;GANs是一种结构化的概率模型，由两个对立的模型组成：生成模型(G)用于捕获数据分布，判别模型(D)用于估计生成数据的概率，以确定生成的数据是来自真实数据分布，还是来自G的分布。D和G使用基于梯度的优化技术(同时梯度下降)玩一个极小极大零和博弈，直到纳什均衡。&lt;/p&gt;
&lt;p&gt;GANs在一些实际任务中表现良好，例如图像生成、视频生成、域自适应和图像超分辨率等。&lt;strong&gt;传统的GANs虽然在很多方面都取得了成功，但是由于D和G训练的不平衡，使得GANs在训练中非常不稳定。&lt;/strong&gt;D利用迅速饱和的逻辑损失。另外，如果D可以很容易的区分出真假图像，那么D的梯度就会消失，当D不能提供梯度时，G就会停止更新。&lt;/p&gt;
&lt;p&gt;近年来，对于模式崩溃问题的处理有了许多改进，因为G产生的样本基于少数模式，而不是整个数据空间。另一方面，引入了几个目标(损失)函数来最小化与传统GANs公式的差异。最后，提出了几种稳定训练的方法。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1998154/202005/1998154-20200524143307203-435456092.png&quot; alt=&quot;&quot; width=&quot;685&quot; height=&quot;256&quot;/&gt;&lt;/p&gt;
&lt;h3&gt;2. DCGAN&lt;/h3&gt;
&lt;p&gt;顾名思义，DCGAN主要讨论CNN与GAN如何结合使用并给出了一系列建议。另外还讨论了GAN特征的可视化、潜在空间插值等问题。&lt;/p&gt;
&lt;h3&gt;3. ImprovedGAN&lt;/h3&gt;
&lt;p&gt;Ian Goodfellow等人提供了诸多训练稳定GAN的建议，包括特征匹配、mini-batch识别、历史平均、单边标签平滑以及虚拟批标准化等技巧。讨论了GAN不稳定性的最佳假设。&lt;/p&gt;
&lt;h3&gt;4. PACGAN&lt;/h3&gt;
&lt;p&gt;PACGAN讨论的是的如何分析model collapse，以及提出了PAC判别器的方法用于解决model collapse。思想其实就是将判别器的输入改成多个样本，这样判别器可以同时看到多个样本可以从一定程度上防止model collapse。&lt;/p&gt;
&lt;h3&gt;5. WGAN&lt;/h3&gt;
&lt;p&gt;WGAN首先从理论上分析了原始GAN模型存在的训练不稳定、生成器和判别器的loss无法只是训练进程、生成样本缺乏多样性等问题，并通过改进算法流程针对性的给出了改进要点。&lt;/p&gt;
&lt;h3&gt;6. CycleGAN &lt;/h3&gt;
&lt;p&gt;CycleGAN讨论的是image2image的转换问题，提出了Cycle consistency loss来处理缺乏成对训练样本来做image2image的转换问题。Cycle Consistency Loss 背后的主要想法，图片A转化得到图片B，再从图片B转换得到图片A'，那么图片A和图片A'应该是图一张图片。&lt;/p&gt;
&lt;h3&gt;7. Vid2Vid&lt;/h3&gt;
&lt;p&gt;Vid2Vid在生成器中加入光流约束，判别器中加入光流信息及对前景和背景分别建模，重点解决视频转换过程中前后帧图像的不一致性。&lt;/p&gt;
&lt;h3&gt;8. PGGAN&lt;/h3&gt;
&lt;p&gt;PGGAN创造性地提出了以一种渐进增大（Progressive growing）的方式训练GAN，利用逐渐增大的PGGAN网络实现了效果令人惊叹的生成图像。“Progressive Growing” 指的是先训练 4x4 的网络，然后训练 8x8，不断增大，最终达到 1024x1024。这既加快了训练速度，又大大稳定了训练速度，并且生成的图像质量非常高。&lt;/p&gt;
&lt;h3&gt;9. StackGAN&lt;/h3&gt;
&lt;p&gt;StackGAN是由文本生成图像，StackGAN模型与PGGAN工作的原理很像，StackGAN 首先输出分辨率为64×64 的图像，然后将其作为先验信息生成一个 256×256 分辨率的图像。&lt;/p&gt;
&lt;h3&gt;10. BigGAN&lt;/h3&gt;
&lt;p&gt;BigGAN模型是基于 ImageNet 生成图像质量最高的模型之一。该模型很难在本地机器上实现，而且 有许多组件，如 Self-Attention、 Spectral Normalization 和带有投影鉴别器的 cGAN等。&lt;/p&gt;
&lt;h3&gt;11. StyleGAN &lt;/h3&gt;
&lt;p&gt;StyleGAN应该是截至目前最复杂的GAN模型，该模型借鉴了一种称为自适应实例标准化 (AdaIN) 的机制来控制潜在空间向量 z。虽然很难自己实现一个StyleGAN，但是它提供了很多有趣的想法。&lt;/p&gt;
&lt;h3&gt;12. 小结&lt;/h3&gt;
&lt;p&gt;当然前文有一些方法没有提到的，例如CGAN、自编码GAN等。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;说到这里，放一张大佬整理的GAN家族主要模型的概要图：&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;左边部分主要是改进模型解决例如图片转换、文本转图像、生成图片、视频转换等实际问题。&lt;/li&gt;
&lt;li&gt;右边部分主要是解决GAN框架本身存在的一些问题。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1998154/202005/1998154-20200524141044867-2016614142.png&quot; alt=&quot;&quot; width=&quot;539&quot; height=&quot;432&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;同时，再分享一下生成式对抗网络(GANs)最新2020综述，分类更全面更细致：[认真看图][认真看图]&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;主要包括基于重新设计的网络结构、新的目标函数和替代优化算法的技术三个大类&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1998154/202005/1998154-20200524144357943-52399409.png&quot; alt=&quot;&quot; width=&quot;656&quot; height=&quot;467&quot;/&gt;&lt;/p&gt;
&lt;p&gt;GAN 已经在一些特定应用上与其它机器学习算法相结合，例如半监督学习、迁移学习、强化学习和多模态学习等。GAN 在图像处理与计算机视觉（例如图像超分辨率、图像生成、目标检测和视频处理等）、自然语言处理（例如文本生成等）、音乐（例如歌词生成等）、语音与音频、医学以及数据科学中的典型应用（例如之前我的随笔里提到的数据补全、异常检测、时间序列预测等）。&lt;/p&gt;
&lt;p&gt;同时，GAN 被用于特征学习领域（例如特征选择、哈希和度量学习等）和其它机器学习任务（例如主动学习、在线学习 、零/小样本学习和多任务学习等）。可以说，计算机领域的很多研究分支中的算法模型都能够互相迁移、彼此融合，从而在不同领域有了拓展性的应用。&lt;/p&gt;
&lt;h2&gt;四、迁移学习综述&lt;/h2&gt;
&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;说到小样本学习，我也想再说说迁移学习。但是别误会，迁移学习也并不是只针对小样本学习，还有很多别的丰富应用。&lt;/p&gt;
&lt;p&gt;本文主要参考了一篇综述：A Survey on Transfer Learning&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3&gt;1. 基本概念&lt;/h3&gt;
&lt;p&gt;在许多机器学习和数据挖掘算法中，一个重要的假设就是目前的训练数据和将来的训练数据，一定要在相同的特征空间并且具有相同的分布。然而，在许多现实的应用案例中，这个假设可能不会成立。这种情况下，如果知识的迁移做得成功，我们将会通过避免花费大量昂贵的标记样本数据的代价，使得学习性能取得显著的提升。近年来，为了解决这类问题，迁移学习作为一个新的学习框架出现在人们面前。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;迁移学习主要有以下三个研究问题：1）迁移什么，2）如何迁移，3）何时迁移。&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;“迁移什么”提出了迁移哪部分知识的问题。 一些知识对单独的域或任务有用，一些知识对不同的领域是通用的，可以用来提高目标域或目标任务的性能。&lt;/li&gt;
&lt;li&gt;“何时迁移”提出了哪种情况下运用迁移学习。当源域和目标域无关时，强行迁移可能并不会提高目标域上算法的性能，甚至会损害性能。这种情况称为负迁移。&lt;/li&gt;
&lt;li&gt;当前大部分关于迁移学习的工作关注于“迁移什么”和“如何迁移”，隐含着一个假设：源域和目标域彼此相关。然而，&lt;strong&gt;如何避免负迁移是一个很重要的问题&lt;/strong&gt;。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;基于迁移学习的定义，我们归纳了传统机器学习方法和迁移学习的异同见下表：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20190612214007175.png&quot; alt=&quot;在这里插入图片描述&quot; width=&quot;786&quot; height=&quot;98&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1998154/202005/1998154-20200525174711073-1812213689.png&quot; alt=&quot;&quot; width=&quot;787&quot; height=&quot;162&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;（1）inductive transfer learning：推导迁移学习，也叫归纳迁移学习。&lt;/strong&gt;其目标任务和源任务不同，无论目标域与源域是否相同。这种情况下，要用目标域中的一些已标注数据生成一个客观预测模型以应用到目标域中。根据源域中已标注和未标注数据的不同情况，可以进一步将inductive transfer learning分为两种情况：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;源域中大量已标注数据可用。&lt;strong&gt;这种情况下推导迁移学习和多任务学习类似。&lt;/strong&gt;然而，推导迁移学习只关注于通过从源任务中迁移知识以便在目标任务中获得更高性能，然而多任务学习尝试同时学习源任务和目标任务。&lt;/li&gt;
&lt;li&gt;源域中无已标注数据可用。&lt;strong&gt;这种情况下推导迁移学习和自我学习相似。&lt;/strong&gt;自我学习中，源域和目标域间的标签空间可能不同，这意味着源域中的边缘信息不能直接使用。因此当源域中无已标注数据可用时这两种学习方法相似。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;transductive transfer learning：转导迁移学习，也叫直推式迁移学习。&lt;/strong&gt;其源任务和目标任务相同，源域和目标域不同。这种情况下，目标域中无已标注数据可用，源域中有大量已标注数据可用。根据源域和目标域中的不同状况，可以进一步将转导迁移学习分为两类：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;源域和目标域中的特征空间不同&lt;/li&gt;
&lt;li&gt;源域和目标域间的特征空间相同，但输入数据的边缘概率分布不同。这种情况与自适应学习相关，因为文本分类、样本选择偏差和协方差移位中的知识迁移都有相似的假设。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;（3）unsupervised transfer learning：无监督迁移学习。&lt;/strong&gt;与推导迁移学习相似，目标任务与源任务不同但相关。然而，无监督迁移学习专注于解决目标域中的无监督学习问题，例如聚类、降维、密度估计等。这种情况下，训练中源域和目标域都无已标注数据可用。&lt;/p&gt;
&lt;h3&gt;2. 迁移学习的分类&lt;/h3&gt;
&lt;p&gt;上述三种迁移学习可以基于“迁移什么”被分为四种情况：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1998154/202005/1998154-20200525175505687-679360828.png&quot; alt=&quot;&quot; width=&quot;786&quot; height=&quot;229&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;（1）Instance-based TL（样本迁移）：可以被称为基于实例的迁移学习&lt;/strong&gt;。尽管source domain数据不可以整个直接被用到target domain里，但是在source domain中还是找到一些可以重新被用到target domain中的数据。对它们调整权重，使它能与target domain中的数据匹配之后可以进行迁移。&lt;/p&gt;
&lt;p&gt;instance reweighting（样本重新调整权重）和importance sampling（重要性采样）是instance-based TL里主要用到的两项技术。&lt;/p&gt;
&lt;p&gt;例如在这个例子中就是找到例子3，然后加重它的权值，这样在预测的时候它所占权重较大，预测也可以更准确。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1998154/202005/1998154-20200525180006695-1487707581.png&quot; alt=&quot;&quot; width=&quot;533&quot; height=&quot;274&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;（2）Feature-representation-transfer（特征迁移）：可以被称为基于特征表示的迁移学习。&lt;/strong&gt;找到一些好的有代表性的特征，通过特征变换把source domain和target domain的特征变换到同样的空间，使得这个空间中source domain和target domain的数据具有相同的分布，然后进行传统的机器学习就可以了。&lt;/p&gt;
&lt;p&gt;特征变换这一块可以举个栗子：比如评论男生的时候，你会说“好帅！好有男人味！好有担当！”，评论女生的时候，你会说“好漂亮！好有女人味！好温柔！”可以看出共同的特征就是“好看”。把“好帅”映射到“好看”，把“好漂亮”映射到“好看”，“好看”便是它们的共同特征。&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;（3）Parameter-transfer（参数/模型迁移）：可以被称为基于参数的迁移学习。&lt;/strong&gt;假设source tasks和target tasks之间共享一些参数，或者共享模型hyperparameters（超参数）的先验分布。这样把原来的模型迁移到新的domain时，也可以达到不错的精度。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;（4）Relational-knowledge-transfer（关系迁移）：可以被称为基于&lt;/strong&gt;关系知识的迁移学习。把相似的关系进行迁移，比如生物病毒传播到计算机病毒传播的迁移，比如师生关系到上司下属关系的迁移。最近，统计关系学习技术主导了这一领域。&lt;/p&gt;
&lt;h3&gt;3. 小结&lt;/h3&gt;
&lt;p&gt;综合第1小节和第2小节的内容，下图展示了不同迁移学习分类中不同方法的使用情况：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1998154/202005/1998154-20200525180820324-152873175.png&quot; alt=&quot;&quot; width=&quot;792&quot; height=&quot;140&quot;/&gt;&lt;/p&gt;
&lt;p&gt;与生成对抗网络GAN一样，迁移学习同样可以在很多领域使用，同时，可以与很其他机器学习算法相结合，道理是相通的。&lt;/p&gt;
&lt;p&gt;说到这里，前面各种方法中的统计学习实现实在是太恐怖了，我只想接下来重点介绍一下&lt;strong&gt;深度迁移学习&lt;/strong&gt;的内容，即&lt;strong&gt;深度学习+迁移学习&lt;/strong&gt;！&lt;/p&gt;
&lt;h3&gt;4. “小王爱迁移”系列学习内容：含深度迁移学习！&lt;/h3&gt;
&lt;p&gt;本小节主要分享一下大佬的知乎专栏的学习内容，主要包括迁移学习领域经典的各大方法，用于辅助对上文的理解：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;（1）迁移成分分析(TCA)：Domain adaptation via transfer component analysis，2009-2011&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;主要思想是：&lt;strong&gt;属于基于特征的迁移学习方法。&lt;/strong&gt;PCA是一个大矩阵进去，一个小矩阵出来，TCA是两个大矩阵进去，两个小矩阵出来。从学术角度讲，TCA针对domain adaptation问题中，源域和目标域处于不同数据分布时，将两个领域的数据一起映射到一个高维的再生核希尔伯特空间。在此空间中，最小化源和目标的数据距离，同时最大程度地保留它们各自的内部属性。直观地理解就是，在现在这个维度上不好最小化它们的距离，那么就找个映射，在映射后的空间上让它们最接近，那么不就可以进行分类了吗？&lt;/p&gt;
&lt;p&gt;主要步骤为：输入是两个特征矩阵，首先计算L和H矩阵，然后选择一些常用的核函数进行映射（比如线性核、高斯核）计算K，接着求&lt;img src=&quot;https://www.zhihu.com/equation?tex=%28%7BK%7DL%7BK%7D%2B%5Cmu+I%29%5E%7B-1%7D%7BK%7DH%7BK%7D&quot; alt=&quot;[公式]&quot; data-formula=&quot;({K}L{K}+\mu I)^{-1}{K}H{K}&quot;/&gt;的前m个特征值。然后，得到的就是源域和目标域的降维后的数据，就可以在上面用传统机器学习方法了。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;（2）测地线流式核方法（GFK）：Geodesic flow kernel for unsupervised domain adaptation，2011-2012&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;SGF方法的主要思想：把source和target分别看成高维空间（&lt;strong&gt;Grassmann流形&lt;/strong&gt;）中的两个点，在这两个点的测地线距离上取d个中间点，然后依次连接起来。这样，由source和target就构成了一条测地线的路径。只需要找到合适的每一步的变换，就能从source变换到target了。&lt;/p&gt;
&lt;p&gt;SGF方法的主要贡献在于：提出了这种变换的计算及实现了相应的算法。但是它有很明显的缺点：到底需要找几个中间点？就是说这个参数d是没法估计的。&lt;/p&gt;
&lt;p&gt;GFK方法解决了SGF的问题：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;如何确定source和target路径上中间点的个数。&lt;/strong&gt;它通过提出一种kernel方法，利用路径上的所有点的积分，把这个问题解决了。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;当有多个source的时候，我们如何决定使用哪个source跟target进行迁移？&lt;/strong&gt;GFK提出Rank of Domain度量，度量出跟target最近的source来解决这个问题。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;GFK方法有以下几个步骤：选择最优的子空间维度进行变换、构建测地线、计算测地线流式核、以及构建分类器。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;（3）联合分布适配(JDA)：Transfer feature learning with joint distribution adaptation，2013&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;主要思想是：&lt;strong&gt;属于基于特征的迁移学习方法。&lt;/strong&gt;是一个概率分布适配的方法，而且适配的是联合概率。JDA方法同时适配两个分布，然后非常精巧地规到了一个优化目标里。用弱分类器迭代，最后达到了很好的效果。&lt;/p&gt;
&lt;p&gt;和TCA的主要区别有两点：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;1）TCA是无监督的（边缘分布适配不需要label），JDA需要源域有label。&lt;/li&gt;
&lt;li&gt;2）TCA不需要迭代，JDA需要迭代。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;-------------------------------------------------------------------------------------------&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;（4）在线迁移学习：A framework of online transfer learning，2010-2014&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;这是在线迁移学习研究的第一篇文章，作者分别对同构OTL和异构OTL提出了相应的方法，就是基于SVM以及集成学习进行组合。&lt;/p&gt;
&lt;p&gt;基本思想是：先针对可用的源域数据建立一个分类器，然后，每来一个目标域数据，就对这个新数据建立一个分类器，然后与在源域上建立的这个分类器进行组合。&lt;/p&gt;
&lt;p&gt;核心问题是：确定源域和新数据分类器各自应该以怎么样的权重进行组合。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;（5）负迁移：提出“传递迁移学习”的解决思路，2015-2017&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;如果两个领域之间基本不相似，那么就会大大损害迁移学习的效果。还是拿骑自行车来说，拿骑自行车的经验来学习开汽车，这显然是不太可能的。因为自行车和汽车之间基本不存在什么相似性。所以，这个任务基本上完不成。这时候，可以说出现了&lt;strong&gt;负迁移（negative transfer）&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;产生负迁移的原因主要有：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;源域和目标域压根不相似，谈何迁移？------数据问题&lt;/li&gt;
&lt;li&gt;源域和目标域是相似的，但是，迁移学习方法不够好，没找到可迁移的成分。 ------方法问题&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;因此，在实际应用中，找到&lt;strong&gt;合理的相似性&lt;/strong&gt;，并且选择或开发&lt;strong&gt;合理的迁移学习方法&lt;/strong&gt;，能够避免负迁移现象。&lt;/p&gt;
&lt;p&gt;随着研究的深入，已经有新的研究成果在逐渐克服负迁移的影响：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;杨强教授团队2015在数据挖掘领悟顶级会议KDD上发表了&lt;strong&gt;传递迁移学习&lt;/strong&gt;文章《Transitive transfer learning》，提出了传递迁移学习的思想。&lt;/li&gt;
&lt;li&gt;杨强教授团队在2017年人工智能领域顶级会议AAAI上发表了&lt;strong&gt;远领域迁移学习&lt;/strong&gt;文章《Distant domain transfer learning》，可以用人脸来识别飞机。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;这些研究的意义在于，&lt;strong&gt;传统迁移学习只有两个领域足够相似才可以完成，而当两个领域不相似时，传递迁移学习却可以利用处于这两个领域之间的若干领域，将知识传递式的完成迁移&lt;/strong&gt;。这个是很有意义的工作，可以视为解决负迁移的有效思想和方法。&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; src=&quot;https://pic3.zhimg.com/80/v2-318056f64b3a8c12d7f17ad94253d6a2_720w.jpg&quot; alt=&quot;&quot; width=&quot;403&quot; height=&quot;177&quot; data-lazy-status=&quot;ok&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-318056f64b3a8c12d7f17ad94253d6a2_b.jpg&quot; data-original=&quot;https://pic3.zhimg.com/v2-318056f64b3a8c12d7f17ad94253d6a2_r.jpg&quot; data-rawheight=&quot;316&quot; data-rawwidth=&quot;719&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;（6）开放集迁移学习：Open Set Domain Adaptation，2017&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;现有的domain adaptation都针对的是一个“封闭”的任务，就是说，source和target中的类别是完全一样的，source有几类，target就有几类。这些方法都只是理想状态下的domain adaptation。而真正的环境中，source和target往往只会共享一些类的信息，而不是全部。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1998154/202005/1998154-20200525220743314-1574359983.png&quot; alt=&quot;&quot; width=&quot;377&quot; height=&quot;182&quot;/&gt;&lt;/p&gt;
&lt;p&gt;整个文章的解决思路大致是这样的：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;利用source和target的关系，给target的样本打上标签&lt;/li&gt;
&lt;li&gt;并将source转换到和target同一个空间中&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;两者依次迭代，直到收敛。作者根据target domain是否有label，把问题分成了unsupervised和semi-supervised domain adaptation，然后分开解决。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;（7）张量迁移学习：When Unsupervised Domain Adaptation Meets Tensor Representations，2017&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;现有的那些domain adaptation方法都只是针对向量（vector）的。而这种表示所带来的问题就是，当把这些数据应用于高维度表示（如卷积）时，数据首先要经过向量化（vectorization）。此时，无法精准完备地保留一些统计属性。所以作者提出，&lt;strong&gt;不经过向量化&lt;/strong&gt;来进行domain adaptation的方法，很自然地用到了&lt;strong&gt;tensor（张量）&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;（8）从经验中学习迁移：Learning To Transfer，2018&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;提出了一个新颖的研究问题：类似于增量学习，如何最大限度地利用已有的迁移学习经验，使得其对新问题的泛化能力很好？同时也可以避免一出现新问题就从头进行学习。&lt;/p&gt;
&lt;p&gt;在解决问题的方法上，虽然用的都是老方法，但是能够想到新已有方法很好地应用于这个问题。&lt;strong&gt;引来的拓展思考：在深度网络中如何持续学习？&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;（9）探秘任务迁移：Taskonomy: Disentangling Task Transfer Learning，2018&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;诸如物体识别、深度估计、边缘检测等一些常见的计算机视觉任务，彼此之间都或多或少地有一些联系。比如，我们很清楚地知道曲面的法线和深度是相关的：它们是彼此的梯度。但与此同时，另一些任务我们却不清楚，例如，一个房间中的关键点检测和阴影是如何协同工作完成姿态估计的？&lt;/p&gt;
&lt;p&gt;已有的相关工作均忽略了这些任务的关联性，而是单独地对各个任务进行建模。不利用任务之间的相关性，无疑是十分耗时和复杂的。即使是要在不同的任务之间进行迁移，由于不同任务的不同任务空间之间的联系尚不清楚，也无法实现简单有效的任务迁移。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;（10）选择性对抗迁移学习：Partial Transfer Learning with Selective Adversarial Networks，2018&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;传统的迁移学习问题情境都是，源域和目标域的类别空间一样。在大数据时代，通常我们会有大量的源域数据。这些源域数据比目标域数据，在类别上通常都是丰富的。比如基于ImageNet训练的图像分类器，必然是针对几千个类别进行的分类。我们实际用的时候，目标域往往只是其中的一部分类别。&lt;/p&gt;
&lt;p&gt;因此，就要求相应的迁移学习方法能够对目标域，选择相似的源域样本(类别)，同时也要避免负迁移。但是目标域通常是没有标签的，不知道和源域中哪个类别更相似。作者指出这个问题叫做partial transfer learning（部分迁移学习）。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1998154/202005/1998154-20200525221228346-1245178769.png&quot; alt=&quot;&quot; width=&quot;605&quot; height=&quot;267&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;（11）联邦迁移学习：2018&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;事实上，Google在2017年的一篇论文里进行了去中心化的推荐系统建模研究。其核心是，手机在本地进行模型训练，然后仅将模型更新的部分加密上传到云端，并与其他用户的进行整合。一些研究者也提出了CryptoDL深度学习框架、可扩展的加密深度方法、针对于逻辑回归方法的隐私保护等。但是，它们或只能针对于特定模型，或无法处理不同分布数据。&lt;/p&gt;
&lt;p&gt;正是为了解决上述这些挑战，&lt;strong&gt;香港科技大学杨强教授和微众银行AI团队&lt;/strong&gt;，最近提出了&lt;strong&gt;联邦迁移学习 (Federated Transfer Learning, FTL)&lt;/strong&gt;。FTL将联邦学习的概念加以推广，强调在任何数据分布、任何实体上，均可以进行协同建模学习。&lt;/p&gt;
&lt;p&gt;这项工作在国内，是杨教授与微众银行AI团队主导，&lt;strong&gt;目的是建立数据联邦，以解决大数据无法聚合的问题。&lt;/strong&gt;在国外，目前是Google在进行相关的研究。二者的区别：微众银行AI团队的做法是，用户维度部分重叠，特征维度不重叠；而Google则是反过来：特征重叠，用户不重叠。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;联邦迁移学习 vs 迁移学习 vs 多任务学习&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;多任务学习和FTL都注重多个任务的协同学习，最终目标都是要把所有的模型变得更强。但是，多任务学习强调不同任务之间可以共享训练数据，破坏了隐私规则。而FTL则可以在不共享隐私数据的情况下，进行协同的训练。&lt;/li&gt;
&lt;li&gt;迁移学习注重知识从一个源领域到另一个目标领域的单向迁移。而这种单向的知识迁移，往往伴有一定的信息损失，因为通常只会关注迁移学习在目标领域上的效果，而忽略了在源领域上的效果。FTL则从目标上就很好地考虑了这一点，多个任务之间协同。&lt;/li&gt;
&lt;li&gt;迁移学习和多任务学习都可以解决模型和数据漂移的问题，这一点在FTL中也得到了继承。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;-------------------------------------------------------------------------------------------&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;（12）深度神经网络的可迁移性：How transferable are features in deep neural networks，2014&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;深度网络的一个事实：前面几层都学习到的是通用的特征（general feature），后面的网络更偏重于学习特定的特征（specific feature）。&lt;/p&gt;
&lt;p&gt;虽然该论文并没有提出一个创新方法，但是通过实验得到了以下几个结论，对以后的深度学习和深度迁移学习都有着非常高的指导意义：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;神经网络的前3层基本都是general feature，进行迁移的效果会比较好。&lt;/li&gt;
&lt;li&gt;深度迁移网络中加入fine-tune，效果会提升比较大，可能会比原网络效果还好。&lt;/li&gt;
&lt;li&gt;Fine-tune可以比较好地克服数据之间的差异性。&lt;/li&gt;
&lt;li&gt;深度迁移网络要比随机初始化权重效果好。&lt;/li&gt;
&lt;li&gt;网络层数的迁移可以加速网络的学习和优化。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;（13）深度迁移学习：&lt;/strong&gt;&lt;strong&gt;例如DaNN、DDC、DAN等，2014-2015&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;DaNN（Domain Adaptive Neural Network）的结构异常简单，它仅由两层神经元组成：特征层和分类器层。作者的创新工作在于，在特征层后加入了一项MMD适配层，用来计算源域和目标域的距离，并将其加入网络的损失中进行训练。所以，整个网络的优化目标也相应地由两部分构成：在有label的源域数据上的分类误差，以及对两个领域数据的判别误差。&lt;/p&gt;
&lt;p&gt;但是，由于网络太浅，表征能力有限，故无法很有效地解决domain adaptation问题（通俗点说就是精度不高）。因此，后续的研究者大多数都基于其思想进行扩充，例如将浅层网络改为更深层的AlexNet、ResNet、VGG等，例如将MMD换为多核的MMD等。&lt;/p&gt;
&lt;p&gt;DDC（Deep Domain Confusion）针对预训练的AlexNet（8层）网络，在第7层（也就是feature层，softmax的上一层）加入了MMD距离来减小source和target之间的差异。这个方法简称为DDC。下图是DDC的算法插图。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1998154/202005/1998154-20200525212246928-2126232159.png&quot; alt=&quot;&quot; width=&quot;318&quot; height=&quot;359&quot;/&gt;&lt;/p&gt;
&lt;p&gt;从上图可以很明显地看出，DDC的思想非常简单：在原有的AlexNet网络的基础上，对网络的fc7层（分类器前一层）后加一层适配层（adaptation layer）&lt;strong&gt;。&lt;/strong&gt;适配层的作用是，单独考察网络对源域和目标域的判别能力。如果这个判别能力很差，那么我们就认为，网络学到的特征不足以将两个领域数据区分开，因而有助于学习到对领域不敏感的特征表示。&lt;/p&gt;
&lt;p&gt;DAN（Deep Adaptation Network）是在DDC的基础上发展起来的，它很好地解决了DDC的两个问题：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;一是DDC只适配了一层网络，可能还是不够，因为Jason的工作中已经明确指出不同层都是可以迁移的，所以DAN就多适配几层。&lt;/li&gt;
&lt;li&gt;二是DDC是用了单一核的MMD，单一固定的核可能不是最优的核。DAN用了多核的MMD（MK-MMD），效果比DDC更好。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;DAN的创新点是多层适配和多核MMD。下图是DAN的网络结构示意图。&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; src=&quot;https://pic1.zhimg.com/80/v2-5166a679f33ebe8b240fdead168bd61c_720w.jpg&quot; alt=&quot;&quot; width=&quot;600&quot; data-lazy-status=&quot;ok&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-5166a679f33ebe8b240fdead168bd61c_b.jpg&quot; data-original=&quot;https://pic1.zhimg.com/v2-5166a679f33ebe8b240fdead168bd61c_r.jpg&quot; data-rawheight=&quot;215&quot; data-rawwidth=&quot;600&quot; data-size=&quot;normal&quot;/&gt;&lt;/p&gt;
&lt;p&gt;DDC和DAN作为深度迁移学习的代表性方法，充分利用了深度网络的可迁移特性，然后又把统计学习中的MK-MMD距离引入，取得了很好的效果。DAN的作者在2017年又进一步对其进行了延伸，做出了Joint Adaptation Network (JAN)，进一步把feature和label的联合概率分布考虑了进来，可以视作之前JDA（joint distribution adaptation）的深度版。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;（14）深度迁移学习文章解读：Simultaneous Deep Transfer Across Domains and Tasks，2015&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;针对情况：target的部分class有少量label，剩下的class无label。文章最大的创新点是：现有的方法都是domain classifier加上一个domain confusion，就是适配。作者提出这些是不够的，所以提出了还要再加一个soft label loss。意思就是在source和target进行适配的时候，也要根据source的类别分布情况来进行调整target的。其实本意和JDA差不多。&lt;/p&gt;
&lt;p&gt;网络结构如下图所示。网络由AlexNet修改而来，前面的几层都一样，区别只是在第fc7层后面加入了一个domain classifier，也就是进行domain adaptation的一层，在fc8后计算网络的loss和soft label的loss。就现在的研究成果看来，绝大多数也都是在深度网络后加一些相关的loss层，以之来提高网络的适配性。本质并没有很大的创新性。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1998154/202005/1998154-20200525220040479-1041018067.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;（15）深度迁移度量学习：Deep Transfer Metric Learning，2015&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;已有的metric learning研究大多数集中在传统方法和深度方法中，它们已经取得了长足的进步。但是这些单纯的度量研究，往往只是在数据分布一致的情况下有效。如果数据分布发生了变化，已有的研究则不能很好地进行处理。因此，迁移学习就可以作为一种工具，综合学习不同数据分布下的度量，使得度量更稳定。&lt;/p&gt;
&lt;p&gt;另一方面，已有的迁移学习工作大多都是基于固定的距离，例如MMD，因此无法学习到更好的距离表达。虽然近年来有一些迁移度量学习的工作，但它们都只考虑在数据层面将特征分布差异减小，而忽略了在源领域中的监督信息。因而，作者提出要在深度迁移网络中对度量进行学习，有效利用源领域中的监督信息，学习到更泛化的距离表达。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;（16）用于部分迁移学习的深度加权对抗网络：Importance Weighted Adversarial Nets for Partial Domain Adaptation，2018&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;作者提出了一个深度加权对抗网络，如下图所示。网络的主要部分是：分别作用于源域和目标域的两个特征提取器(分别叫做 &lt;img src=&quot;https://www.zhihu.com/equation?tex=F_s&quot; alt=&quot;[公式]&quot; data-formula=&quot;F_s&quot;/&gt;&lt;em&gt;和&lt;/em&gt; &lt;img src=&quot;https://www.zhihu.com/equation?tex=F_t&quot; alt=&quot;[公式]&quot; data-formula=&quot;F_t&quot;/&gt; )，以及两个领域分类器(分别叫做 &lt;img src=&quot;https://www.zhihu.com/equation?tex=D&quot; alt=&quot;[公式]&quot; data-formula=&quot;D&quot;/&gt; 和 &lt;img src=&quot;https://www.zhihu.com/equation?tex=D_0&quot; alt=&quot;[公式]&quot; data-formula=&quot;D_0&quot;/&gt; )。第一个领域分类器用来筛选出源域中与目标域相似的那部分样本（或者源域中与目标领域共享的那部分类别），第二个领域分类器进行正常的domain adaptation。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1998154/202005/1998154-20200525222927665-23522940.png&quot; alt=&quot;&quot; width=&quot;478&quot; height=&quot;352&quot;/&gt;&lt;/p&gt;
&lt;p&gt;本文核心创新点是，从任务出发，直观地构造出两阶段式对抗网络，对源域中与目标域共享的类别样本进行有效筛选。另一个与已有工作不同的地方是，作者分别对源域和目标域采用了不同的特征提取器。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;（17）基于条件对抗网络的领域自适应：Conditional Adversarial Domain Adaptation，2018&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Domain adaptation问题一直以来是迁移学习和计算机视觉领域等的研究热点。从传统方法，到深度方法，再到最近的对抗方法，都在尝试解决此问题。作者在本文中提出，现在的对抗方法面临两个挑战：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;一是当数据特征具有非常复杂的模态结构时，对抗方法无法捕获多模态的数据结构，容易造成负迁移。&lt;/li&gt;
&lt;li&gt;二是当上面的问题存在时，domain classifier就很容易出错，所以造成迁移效果不好。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;本文提出了基于条件对抗网络的领域自适应方法，主要由Condition + Adversarial + Adaptation这三部分构成。进行condition的时候，用到了一个叫做multilinear map的数学工具，主要是来刻画多个特征和类别之间的关系。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;（18）深度迁移学习用于时间序列分类：Transfer learning for time series classification，2018&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;基本方法与在图像上进行深度迁移一致，先在一个源领域上进行pre-train，然后在目标领域上进行fine-tune。&lt;/p&gt;
&lt;p&gt;网络的结构如下图所示。网络由3个卷积层、1个全局池化层、和1个全连接层构成。使用全连接层的好处是，在进行不同输入长度序列的fine-tune时，不需要再额外设计池内化层。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1998154/202005/1998154-20200525224739717-547048129.png&quot; alt=&quot;&quot; width=&quot;636&quot; height=&quot;204&quot;/&gt;&lt;/p&gt;
&lt;p&gt;与图像的区别就是，输入由图片换成了时间序列。注意到，图片往往具有一定的通道数（如常见的R、G、B三通道）。时间序列也有通道，即不同维的时间序列数据。最简单的即是1维序列，可以认为是1个通道。多维时间序列则可以认为是多个通道。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt; （19）最大分类器差异的领域自适应：Maximum Classifier Discrepancy for Unsupervised Domain Adaptation，2018&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;方法的主要思想非常简单：用源域训练的网络如果用到目标域上，肯定因为目标域与源域的不同，效果也会有所不同。效果好的我们就不管了，重点关注效果不好的，因为这才能体现出领域的差异性。为了找到这些效果差的样本，作者引入了&lt;strong&gt;两个&lt;/strong&gt;独立的分类器 &lt;img src=&quot;https://www.zhihu.com/equation?tex=F_1&quot; alt=&quot;[公式]&quot; data-formula=&quot;F_1&quot;/&gt; 和 &lt;img src=&quot;https://www.zhihu.com/equation?tex=F_2&quot; alt=&quot;[公式]&quot; data-formula=&quot;F_2&quot;/&gt; ，用二者的&lt;strong&gt;分歧&lt;/strong&gt;表示样本的置信度不高，需要重新训练。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1998154/202005/1998154-20200525225051859-1843632337.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt; （20）异构网络的迁移：Learn What-Where to Transfer，2019&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;本文另辟蹊径，从根源上研究&lt;strong&gt;不同架构的深度网络&lt;/strong&gt;如何进行迁移，并提供了行之有效的解决方案。&lt;/p&gt;
&lt;p&gt;深度网络都是对迁移学习最为友好的学习架构。从最简单的finetune（微调），到固定网络的特征提取层不变在倒数第二层加入可学习的距离，再到通过领域对抗的思想学习隐式分布距离，深度迁移学习方法大行其道。在诸多图像分类、分割检测等任务上取得了不错的效果。&lt;/p&gt;
&lt;p&gt;纵观这些方法的思路，大多均逃脱不开一个固有的模式：源域和目标域的网络架构完全相同，固定前若干层，微调高层或在高层中加入分布适配距离。然而，在迁移模型变得越来越臃肿、特定数据集精度不断攀升的同时，极少有人想过这样一个问题：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;这种固定+微调的模式是否是唯一的迁移方法？&lt;/li&gt;
&lt;li&gt;如果2个网络结构不同（比如），则上述模式直接失效，此时如何做迁移？&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;本文将这一思路具体表述为2点：&lt;strong&gt;What to transfer&lt;/strong&gt;和&lt;strong&gt;Where to transfer&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;What部分解决网络的可迁移性：源域中哪些层可以迁移到目标域哪些层？&lt;/li&gt;
&lt;li&gt;Where部分解决网络迁移多少：源域中哪些层的知识迁移多少给目标域的哪些层？&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;简单来说就是：学习源域网络中哪些层的知识可以迁移多少给目标域的哪些层。&lt;/p&gt;
&lt;h2&gt;五、深度迁移学习综述&lt;/h2&gt;
&lt;blockquote readability=&quot;13&quot;&gt;
&lt;p&gt;说到迁移学习，我想最时髦的就是深度迁移学习了。有了深度学习的加持，迁移学习在人工智能领域有着丰富的应用。&lt;/p&gt;
&lt;p&gt;上一节的内容其实已经包含了深度迁移学习的很多方法，包括非常多的idea，本节就作为辅助理解用吧！&lt;/p&gt;
&lt;p&gt;本文参考了一篇综述：A Survey on Deep Transfer Learning&lt;/p&gt;
&lt;p&gt;这里强推大佬的知乎专栏和guthub：https://github.com/jindongwang/transferlearning&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3&gt;1. 基本概念&lt;/h3&gt;
&lt;p&gt;深度迁移学习是通过深度神经网络研究如何利用其他领域的知识。随着深度神经网络在各个领域的广泛应用，大量的深度迁移学习方法被提出。包括离线/在线、增量学习、生成对抗、同构/异构等，可以说是非常丰富。&lt;/p&gt;
&lt;h3&gt;2. 深度迁移学习的分类&lt;/h3&gt;
&lt;p&gt;本文将深度迁移学习分为四类：基于实例的深度迁移学习、基于映射的深度迁移学习、基于网络的深度迁移学习和基于对抗的深度迁移学习。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1998154/202005/1998154-20200525183225572-170692498.png&quot; alt=&quot;&quot; width=&quot;597&quot; height=&quot;208&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;（1）基于实例的深度迁移学习。&lt;/strong&gt;与迁移学习分类中的第一类是一致的，这里不再赘述。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1998154/202005/1998154-20200525183526469-913754677.png&quot; alt=&quot;&quot; width=&quot;520&quot; height=&quot;161&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;（2）基于映射的深度迁移学习。&lt;/strong&gt;与迁移学习分类中的第二类是一致的，这里不再赘述。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1998154/202005/1998154-20200525183709195-2087118339.png&quot; alt=&quot;&quot; width=&quot;518&quot; height=&quot;240&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;（3）基于网络的深度迁移学习。&lt;/strong&gt;将原领域中预先训练好的部分网络，包括其网络结构和连接参数，重新利用，将其转化为用于目标领域的深度神经网络的一部分。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1998154/202005/1998154-20200525183808767-1004164351.png&quot; alt=&quot;&quot; width=&quot;516&quot; height=&quot;314&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;（4）基于对抗的深度迁移学习。&lt;/strong&gt;在生成对抗网络 GAN 的启发下，引入对抗性技术，寻找既适用于源域又适用于目标域的可迁移表达。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1998154/202005/1998154-20200525184000423-1045036332.png&quot; alt=&quot;&quot; width=&quot;536&quot; height=&quot;223&quot;/&gt;&lt;/p&gt;
&lt;p&gt;负迁移和可迁移性测度是传统迁移学习中的重要问题。如何利用深度神经网络在无监督或半监督学习中进行知识的迁移会受到越来越多的关注。&lt;/p&gt;

&lt;ul&gt;&lt;li&gt;元学习关注的是一组任务T~p(T)，元学习的目标是从T1，T2...中不断学习，从中学到更通用的知识，从而具有适应新任务Ti的能力，它关注的是任务T到Ti这个过程。&lt;/li&gt;
&lt;li&gt;迁移学习通常只有一个源域A（当然可以有多个），一个目标域B，目标是学习A到B的迁移，更关注的是A到B的这个过程。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;当然，两者有很多重叠之处，要结合着看，互相补充，互相学习。&lt;/p&gt;
&lt;h2&gt;六、其他概念介绍：知识蒸馏、增量学习&lt;/h2&gt;
&lt;h3&gt;1. 知识蒸馏&lt;/h3&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;&lt;strong&gt;知识蒸馏被广泛的用于模型压缩和迁移学习当中。&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;知识蒸馏可以将一个网络的知识转移到另一个网络，两个网络可以是同构或者异构。做法是先训练一个teacher网络，然后使用这个teacher网络的输出和数据的真实标签去训练student网络。&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;可以用来将网络从大网络转化成一个小网络，并保留接近于大网络的性能。&lt;/li&gt;
&lt;li&gt;可以将多个网络的学到的知识转移到一个网络中，使得单个网络的性能接近emsemble的结果。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; src=&quot;https://pic1.zhimg.com/80/v2-b75c5781323c5ec2b8ad9ee648712e34_720w.jpg&quot; alt=&quot;&quot; width=&quot;386&quot; height=&quot;239&quot; data-lazy-status=&quot;ok&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-b75c5781323c5ec2b8ad9ee648712e34_b.jpg&quot; data-original=&quot;https://pic1.zhimg.com/v2-b75c5781323c5ec2b8ad9ee648712e34_r.jpg&quot; data-rawheight=&quot;288&quot; data-rawwidth=&quot;465&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot;/&gt;&lt;/p&gt;
&lt;h3&gt;2. 增量学习&lt;/h3&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;主要关注的是灾难性遗忘，平衡新知识与旧知识之间的关系。即如何在学习新知识的情况下不忘记旧知识。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;引用Robipolikar对增量学习算法的定义，即一个增量学习算法应同时具有以下特点：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;可以从新数据中学习新知识&lt;/li&gt;
&lt;li&gt;以前已经处理过的数据不需要重复处理&lt;/li&gt;
&lt;li&gt;每次只有一个训练观测样本被看到和学习&lt;/li&gt;
&lt;li&gt;学习新知识的同时能保持以前学习到的大部分知识&lt;/li&gt;
&lt;li&gt;一旦学习完成后训练观测样本被丢弃&lt;/li&gt;
&lt;li&gt;学习系统没有关于整个训练样本的先验知识&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;在概念上，增量学习与迁移学习最大的区别就是对待旧知识的处理&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;增量学习在学习新知识的同时需要尽可能保持旧知识，不管它们类别相关还是不相关的。&lt;/li&gt;
&lt;li&gt;迁移学习只是借助旧知识来学习新知识，学习完成后只关注在新知识上的性能，不再考虑在旧知识上的性能。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;如果您对异常检测感兴趣，欢迎浏览我的另一篇博客：&lt;a class=&quot;postTitle2&quot; href=&quot;https://www.cnblogs.com/zhengzhicong/p/12922836.html&quot;&gt;异常检测算法演变及学习笔记&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;如果您对智能推荐感兴趣，欢迎浏览我的另一篇博客：&lt;a class=&quot;postTitle2&quot; href=&quot;https://www.cnblogs.com/zhengzhicong/p/12817941.html&quot;&gt;智能推荐算法演变及学习笔记&lt;/a&gt; 、&lt;a class=&quot;postTitle2&quot; href=&quot;https://www.cnblogs.com/zhengzhicong/p/12862816.html&quot;&gt;CTR预估模型演变及学习笔记&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;如果您对知识图谱感兴趣，欢迎浏览我的另一篇博客：&lt;a id=&quot;cb_post_title_url&quot; class=&quot;postTitle2&quot; href=&quot;https://www.cnblogs.com/zhengzhicong/p/12930401.html&quot;&gt;行业知识图谱的构建及应用&lt;/a&gt;、&lt;a class=&quot;postTitle2&quot; href=&quot;https://www.cnblogs.com/zhengzhicong/p/12850056.html&quot;&gt;基于图模型的智能推荐算法学习笔记&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;如果您对时间序列分析感兴趣，欢迎浏览我的另一篇博客：&lt;a class=&quot;postTitle2&quot; href=&quot;https://www.cnblogs.com/zhengzhicong/p/12916915.html&quot;&gt;时间序列分析中预测类问题下的建模方案&lt;/a&gt; 、&lt;a class=&quot;postTitle2&quot; href=&quot;https://www.cnblogs.com/zhengzhicong/p/12890660.html&quot;&gt;深度学习中的序列模型演变及学习笔记&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;如果您对数据挖掘感兴趣，欢迎浏览我的另一篇博客：&lt;a class=&quot;postTitle2&quot; href=&quot;https://www.cnblogs.com/zhengzhicong/p/12728491.html&quot;&gt;数据挖掘比赛/项目全流程介绍&lt;/a&gt; 、&lt;a class=&quot;postTitle2&quot; href=&quot;https://www.cnblogs.com/zhengzhicong/p/12895421.html&quot;&gt;机器学习中的聚类算法演变及学习笔记&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;如果您对人工智能算法感兴趣，欢迎浏览我的另一篇博客：&lt;a href=&quot;https://www.cnblogs.com/zhengzhicong/p/12670260.html&quot;&gt;人工智能新手入门学习路线和学习资源合集（含AI综述/python/机器学习/深度学习/tensorflow）&lt;/a&gt;、&lt;a href=&quot;https://www.cnblogs.com/zhengzhicong/p/12875348.html&quot;&gt;人工智能领域常用的开源框架和库（含机器学习/深度学习/强化学习/知识图谱/图神经网络）&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;如果你是计算机专业的应届毕业生，欢迎浏览我的另外一篇博客：&lt;a href=&quot;https://www.cnblogs.com/zhengzhicong/p/12650878.html&quot;&gt;如果你是一个计算机领域的应届生，你如何准备求职面试？&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;如果你是计算机专业的本科生，欢迎浏览我的另外一篇博客：&lt;a href=&quot;https://www.cnblogs.com/zhengzhicong/p/12650191.html&quot;&gt;如果你是一个计算机领域的本科生，你可以选择学习什么？&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;如果你是计算机专业的研究生，欢迎浏览我的另外一篇博客：&lt;a href=&quot;https://www.cnblogs.com/zhengzhicong/p/12650369.html&quot;&gt;如果你是一个计算机领域的研究生，你可以选择学习什么？&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;如果你对金融科技感兴趣，欢迎浏览我的另一篇博客：&lt;a href=&quot;https://www.cnblogs.com/zhengzhicong/p/12657428.html&quot;&gt;如果你想了解金融科技，不妨先了解金融科技有哪些可能？&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;之后博主将持续分享各大算法的学习思路和学习笔记：&lt;a href=&quot;https://www.cnblogs.com/zhengzhicong/p/12641421.html&quot;&gt;hello world: 我的博客写作思路&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;</description>
<pubDate>Mon, 25 May 2020 18:17:00 +0000</pubDate>
<dc:creator>FinTecher</dc:creator>
<og:description>一、Meta Learning 元学习综述 二、Few-shot Learning 小样本学习综述 三、生成对抗网络 GAN 综述 四、迁移学习综述 五、深度迁移学习综述 六、其他概念介绍：知识蒸馏、</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/zhengzhicong/p/12952354.html</dc:identifier>
</item>
<item>
<title>MySQL常见6个考题在实际工作中的运用 - 编程一生</title>
<link>http://www.cnblogs.com/xiexj/p/12952378.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/xiexj/p/12952378.html</guid>
<description>&lt;p&gt;&lt;strong&gt;题目一&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;MyISAM和InnoDB的区别，什么时候选择MyISAM&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;参考回答&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;InnoDB是目前MySQL主流版本(5.6、5.7、8.0)默认的存储引擎，支持事务、外键、行级锁，对于并发条件下要求数据的一致性，适用于对数据准确性要求高的场景。&lt;/p&gt;
&lt;p&gt;MyISAM只支持表级锁、数据排列是按照插入顺序，没有做规则排序。适合应用以查询和插入为主，只有很少量的更新和删除操作，对事务的完整性和并发性要求不是很高的场景。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;实际运用&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;看到很多人在选择存储引擎的时候会无脑的选择InnoDB，这个选择合理的一点是如果对数据准确性要求没有那么高，直接用NoSQL就好了。用MySQL就是为了可靠啊。&lt;/p&gt;
&lt;p&gt;但是实际工作中，我设计的数据库中通常都会有几张MyISAM的数据表，通常用来存储历史记录，与使用InnoDB存储实时记录信息的配合使用。&lt;/p&gt;
&lt;p&gt;举个例子：比如一条物流信息，在实时的表里存着目前物流的状态：比如配送中。这条物流在历史上经过了：正在通知快递公司取件、XXX已收揽等，这张记录表基本只有插入和查询，并且丢失一个中间状态不影响当前结果，这就很合适用MyISAM。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;题目二&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;简述MySQL的MVCC多版本并发控制&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;参考回答&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1112728/202005/1112728-20200524195308771-2133083743.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;MVCC是对于事务隔离级别的读已提交RC和可重复读RR，基于乐观锁的实现。在LBCC(基于锁的并发控制)RC、RR和串行化分别是通过加行锁、间隙锁和表锁来基于悲观锁实现。而乐观锁的原理就是在特定的时间点(RC是每次读时，RR是事务开始时)生成一个当前快照，读数据读取快照，只在提交时判断是否有冲突，类似于git的branch和commit。&lt;/p&gt;
&lt;p&gt;MVCC会在新开启一个事务时，给事务里包含的每行记录添加一个当前事务ID和回滚指针。并包含一个Read View，Read View里保存了当前活跃的事务列表，小于这些列表的最近的事务ID才是可见的。这样保证了读到的都是已提交的事务。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;实际运用&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;MVCC不仅可以用于数据库，也是很常见的一种并发控制手段。比如使用有限状态自动机来控制的订单状态，在更新订单状态的时候先查询当前状态，比如当前状态是订单未提交，则更新时update XXX set status='订单已提交' where status='订单未提交'，如果执行这条语句时，status已经发生了改变，这条语句就执行失败了。这样不通过数据库自身事务的MVCC，在业务逻辑里也实现了MVCC思想的乐观锁设计。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;题目三&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;分布式锁的实现方式&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;参考回答&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;主流有三种&lt;/p&gt;
&lt;p&gt;1&amp;gt;基于数据库&lt;/p&gt;
&lt;p&gt;1.1&amp;gt;基于数据库主键：插入一条数据，指定主键。如果有两条插入会主键冲突，并发执行失败&lt;/p&gt;
&lt;p&gt;1.2&amp;gt;基于数据库排他锁：提交一个update事务，如果这个事务不提交，其他也对锁定范围内执行update就会阻塞，解决并发问题&lt;/p&gt;
&lt;p&gt;2&amp;gt;基于缓存比如redis的setNX&lt;/p&gt;
&lt;p&gt;3&amp;gt;基于zookeeper&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;实际运用&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;相信很多人选择分布式锁都是选择第二种，第三种虽然并发性差一下，如果本来就引入了zk，而没有缓存，而分布式锁应用量又不那么大，为了减少引入新组件带来的风险和维护成本，也有可能选择zk。很多人大概认为自己没有用过基于数据库的分布式锁，实际上在不使用MVCC的时代并不是这样。&lt;/p&gt;
&lt;p&gt;在使用spring进行业务开发的时候，常见的一种场景就是使用spring配置事务。默认级别是Repeatable Read可重复读。在这里面如果使用的是LBCC，一进入事务就加入一个排他锁，比如insert、update、delete或者select XXX for update。然后做其他的，比如进行一个RPC调用。这时候一旦出现并发，只有一个能顺利执行，其他都会被阻塞。实际上就相当于使用了分布式锁。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;题目四&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;为什么采用B+树作为索引结构?&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;参考回答&lt;/strong&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;如果采用Hash表，范围查找需要全表扫描；如果采用二叉查找树，由于无法保证平衡，可能退化为链表；如果采用平衡二叉树，通过旋转解决了平衡的问题，但是旋转操作效率太低；如果采用红黑树，树太高，IO次数多；如果采用普通B树，节点要存数索引和数据，一个内存页可存储的数据还是少，另外范围查找也需要多次IO；&lt;/p&gt;
&lt;p&gt;而B+Tree有三个特性：&lt;/p&gt;
&lt;p&gt;1&amp;gt;非叶子节点不存储data，只存储索引(冗余)，可以放更多的索引&lt;/p&gt;
&lt;p&gt;2&amp;gt;叶子节点包含所有索引字段&lt;/p&gt;
&lt;p&gt;3&amp;gt;叶子节点用指针链接，提高范围查询的性能&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;实际运用&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;在分布式场景下，我们的业务ID都是全局唯一的字符串。如果单纯从业务上来考虑，用业务ID作为数据库的主键就足够了。可以DBA往往要求使用整型的自增主键作为数据库主键，而这个主键对业务来说就是个浪费，没有任何业务含义。&lt;/p&gt;
&lt;p&gt;如果了解了索引的底层结构就不难理解&lt;/p&gt;
&lt;p&gt;1&amp;gt;整型比字符串占用更少的空间&lt;/p&gt;
&lt;p&gt;2&amp;gt;同时大小比较也很快&lt;/p&gt;
&lt;p&gt;3&amp;gt;之所以要自增是每次插入新的记录，对于叶子节点来说：记录会顺序的添加到当前索引节点的后续位置，当一页写满，会自动开辟一个新的页。而如果使用非自增主键，就需要插入的时候移动数据，甚至目标页面可能已经被回写到磁盘上而从缓存中清掉，此时又要读回来。分页操作造成大量的碎片，必须通过优化操作重建表并优化填充页面。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;题目五&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;什么叫做覆盖索引？&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;参考回答&lt;/strong&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;只需要在一棵辅助索引树上就可以获取SQL所需要的所有列数据，不需要回表。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;实际运用&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;一些持久层框架比如mybatis的generator插件可以自动生成sql配置文件，这些配置文件往往效率很低。但是刚毕业的同学很多都不会去改这个文件，比如只需要个别列的时候会用java的lambda表达式等方式从逻辑上做处理。结果造成一些性能的问题。&lt;/p&gt;
&lt;p&gt;我在根据一些条件进行范围查找的时候，如果只需要返回ID或者个别列，会自己去改mybatis的generator自动生成的文件，原因是尽量使用覆盖索引，较回表速度快。&lt;/p&gt;
&lt;p&gt;想验证是否使用了覆盖索引，可以用explain执行计划，查看extra字段，如果只显示Using index说明正确使用了覆盖索引。如果extra为空或者除了using index还有filesort说明触发了回表。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;题目六&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;查询在什么时候不走索引&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;参考回答&lt;/strong&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;主要三种情况&lt;/p&gt;
&lt;p&gt;1&amp;gt;不满足走索引的条件，常见的情况有&lt;/p&gt;
&lt;p&gt;1.1&amp;gt;不满足最左匹配原则&lt;/p&gt;
&lt;p&gt;1.2&amp;gt;查询条件使用了函数&lt;/p&gt;
&lt;p&gt;1.3&amp;gt;or操作有一个字段没有索引&lt;/p&gt;
&lt;p&gt;1.4&amp;gt;使用like条件以%开头&lt;/p&gt;
&lt;p&gt;2&amp;gt;走索引效率低于全表扫描，常见的情况有&lt;/p&gt;
&lt;p&gt;2.1&amp;gt;查询条件对null做判断，而null的值很多&lt;/p&gt;
&lt;p&gt;2.2&amp;gt;一个字段区分度很小，比如性别、状态&lt;/p&gt;
&lt;p&gt;3&amp;gt;需要回表的查询结果集过大，超过了配置的范围&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;实际运用&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;使用索引是为了对查询做优化，要衡量优化效果需要数据说话。所以需要一些工具来衡量，常用的有：&lt;/p&gt;
&lt;p&gt;1&amp;gt;慢查询日志&lt;/p&gt;
&lt;p&gt;开启慢查询日志，可以针对慢SQL进行分析看看哪些可以用索引进行优化&lt;/p&gt;
&lt;p&gt;2&amp;gt;show processlist&lt;/p&gt;
&lt;p&gt;show processlist 语句可以查看当前正在执行的SQL，如果一些SQL执行慢，block了其他的SQL，这是个很好的工具&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1112728/202005/1112728-20200524195356574-440856369.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;rich_pages img_loading&quot; src=&quot;data:image/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVQImWNgYGBgAAAABQABh6FO1AAAAABJRU5ErkJggg==&quot; alt=&quot;&quot; data-ratio=&quot;0.69432918395574&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/2tk5ianItRlibDic3bxGcqFd8OJPIXyia3wW8icrtib6RpSXGUv8MAqFhMe0icS9lLkFRjSFlXtQU7iaIZQqzF99vzqjaQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1446&quot;/&gt;&lt;/p&gt;
&lt;p&gt;3&amp;gt;show profile分析SQL&lt;/p&gt;
&lt;p&gt;使用这个工具可以分析出时间究竟耗费在哪个阶段。先查询是否支持&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;rich_pages img_loading&quot; src=&quot;data:image/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVQImWNgYGBgAAAABQABh6FO1AAAAABJRU5ErkJggg==&quot; alt=&quot;&quot; data-ratio=&quot;1.106280193236715&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/2tk5ianItRlibDic3bxGcqFd8OJPIXyia3wW594WjMOlYNQicwBv83fS8gKotUqHKGN1d1YFxiciarEnvjS1q2cDuk36g/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;414&quot;/&gt;&lt;/p&gt;
&lt;p&gt;支持的话，可以用select @@profiling 查看是否开启，如果结果为0说明未开启。需要先set @@profiling=1;&lt;/p&gt;
&lt;p&gt;这时候就可以用show profiles查看每一条SQL语句耗费的时间&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1112728/202005/1112728-20200524195420434-356459007.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;


&lt;p&gt;show profile for query XXID 可以查看具体耗费在哪个阶段&lt;/p&gt;
&lt;p&gt;4&amp;gt;Trace分析优化器的执行计划&lt;/p&gt;
&lt;p&gt;使用set optimizer_trace='enabled=on',end_markers_in_json=on;可以打开trace分析，想查看具体的优化器执行计划，只要执行&lt;/p&gt;
&lt;p&gt;select * from `information_schema`.optimizer_trace即可&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1112728/202005/1112728-20200524195441091-1770961090.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;


&lt;p&gt;点击开每一步都有很详细的分析&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;总结&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;知识只要学透了都可以灵活运用。在运用的时候要注意衡量效果。一个常见的误区是开发人员无脑的在MySQL上层加缓存，用来提高效率。但是缓存只适用于读多写少的情况，比如在金融交易系统，数据读写比例1：1。数据总是查询出来下一刻就被更新了，这时候用缓存反而加重系统的负担和复杂性。&lt;/p&gt;
&lt;p&gt;这时候，我们可以先利用工具查询数据库的读写比例。比如show global status like 'Com_______' 这个SQL可以查看select、update、insert、delete都被执行了多少次。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1112728/202005/1112728-20200524195456974-344288895.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;或者show global status like 'Innodb_row_%' 除了查看Innodb的读写情况，还可以查看锁的情况。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1112728/202005/1112728-20200524195515203-1100389785.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;思考&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;请网上搜索一下「58Mysql军规」然后思考每条军规背后的理论支撑。&lt;/p&gt;
</description>
<pubDate>Mon, 25 May 2020 16:29:00 +0000</pubDate>
<dc:creator>编程一生</dc:creator>
<og:description>题目一 MyISAM和InnoDB的区别，什么时候选择MyISAM 参考回答 InnoDB是目前MySQL主流版本(5.6、5.7、8.0)默认的存储引擎，支持事务、外键、行级锁，对于并发条件下要求数</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/xiexj/p/12952378.html</dc:identifier>
</item>
<item>
<title>【Java8新特性】面试官问我：Java8中创建Stream流有哪几种方式？ - 冰河团队</title>
<link>http://www.cnblogs.com/binghe001/p/12961977.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/binghe001/p/12961977.html</guid>
<description>&lt;h2 id=&quot;写在前面&quot;&gt;写在前面&lt;/h2&gt;
&lt;blockquote readability=&quot;10&quot;&gt;
&lt;p&gt;先说点题外话：不少读者工作几年后，仍然在使用Java7之前版本的方法，对于Java8版本的新特性，甚至是Java7的新特性几乎没有接触过。真心想对这些读者说：你真的需要了解下Java8甚至以后版本的新特性了。&lt;/p&gt;

&lt;p&gt;今天，一名读者出去面试，面试官问他：说说Java8中创建Stream流有哪几种方式？他竟然没回答上来！！&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;stream概述&quot;&gt;Stream概述&lt;/h2&gt;
&lt;p&gt;Java8中有两大最为重要的改变。第一个是 Lambda 表达式；另外一个则是 Stream API(java.util.stream.*)。&lt;/p&gt;
&lt;p&gt;Stream 是 Java8 中处理集合的关键抽象概念，它可以指定你希望对集合进行的操作，可以执行非常复杂的查找、过滤和映射数据等操作。使用Stream API 对集合数据进行操作，就类似于使用 SQL 执行的数据库查询。也可以使用 Stream API 来并行执行操作。简而言之，Stream API 提供了一种高效且易于使用的处理数据的方式。&lt;/p&gt;
&lt;h2 id=&quot;何为stream&quot;&gt;何为Stream?&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;流(Stream) 到底是什么呢？&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;可以这么理解流：流就是数据渠道，用于操作数据源（集合、数组等）所生成的元素序列。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;“集合讲的是数据，流讲的是计算！ ”&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;注意：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;①Stream 自己不会存储元素。&lt;/p&gt;
&lt;p&gt;②Stream 不会改变源对象。相反，他们会返回一个持有结果的新Stream。&lt;/p&gt;
&lt;p&gt;③Stream 操作是延迟执行的。这意味着他们会等到需要结果的时候才执行。&lt;/p&gt;
&lt;h2 id=&quot;stream操作步骤&quot;&gt;Stream操作步骤&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;1.创建 Stream&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;一个数据源（如： 集合、数组）， 获取一个流。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2.中间操作&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;一个中间操作链，对数据源的数据进行处理。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;3.终止操作(终端操作)&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;一个终止操作，执行中间操作链，并产生结果 。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20200525225333187.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2wxMDI4Mzg2ODA0,size_16,color_FFFFFF,t_70#pic_center&quot; alt=&quot;在这里插入图片描述&quot;/&gt;&lt;/p&gt;
&lt;h2 id=&quot;如何创建stream流？&quot;&gt;如何创建Stream流？&lt;/h2&gt;
&lt;p&gt;这里，创建测试类TestStreamAPI1，所有的操作都是在TestStreamAPI1类中完成的。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;（1）通过Collection系列集合提供的stream()方法或者parallelStream()方法来创建Stream。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;在Java8中，Collection 接口被扩展，提供了两个获取流的默认方法，如下所示。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;default Stream&amp;lt;E&amp;gt; stream() {
    return StreamSupport.stream(spliterator(), false);
}
default Stream&amp;lt;E&amp;gt; parallelStream() {
    return StreamSupport.stream(spliterator(), true);
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;其中，stream()方法返回一个顺序流，parallelStream()方法返回一个并行流。&lt;/p&gt;
&lt;p&gt;我们可以使用如下代码方式来创建顺序流和并行流。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;List&amp;lt;String&amp;gt; list = new ArrayList&amp;lt;&amp;gt;();
list.stream();
list.parallelStream();
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;（2）通过Arrays中的静态方法stream()获取数组流。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Java8 中的 Arrays类的静态方法 stream() 可以获取数组流 ，如下所示。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;public static &amp;lt;T&amp;gt; Stream&amp;lt;T&amp;gt; stream(T[] array) {
    return stream(array, 0, array.length);
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;上述代码的的作用为：传入一个泛型数组，返回这个泛型的Stream流。&lt;/p&gt;
&lt;p&gt;除此之外，在Arrays类中还提供了stream()方法的如下重载形式。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;public static &amp;lt;T&amp;gt; Stream&amp;lt;T&amp;gt; stream(T[] array) {
    return stream(array, 0, array.length);
}

public static &amp;lt;T&amp;gt; Stream&amp;lt;T&amp;gt; stream(T[] array, int startInclusive, int endExclusive) {
    return StreamSupport.stream(spliterator(array, startInclusive, endExclusive), false);
}

public static IntStream stream(int[] array) {
    return stream(array, 0, array.length);
}

public static IntStream stream(int[] array, int startInclusive, int endExclusive) {
    return StreamSupport.intStream(spliterator(array, startInclusive, endExclusive), false);
}

public static LongStream stream(long[] array) {
    return stream(array, 0, array.length);
}

public static LongStream stream(long[] array, int startInclusive, int endExclusive) {
    return StreamSupport.longStream(spliterator(array, startInclusive, endExclusive), false);
}

public static DoubleStream stream(double[] array) {
    return stream(array, 0, array.length);
}

public static DoubleStream stream(double[] array, int startInclusive, int endExclusive) {
    return StreamSupport.doubleStream(spliterator(array, startInclusive, endExclusive), false);
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;基本上能够满足基本将基本类型的数组转化为Stream流的操作。&lt;/p&gt;
&lt;p&gt;我们可以通过下面的代码示例来使用Arrays类的stream()方法来创建Stream流。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;Integer[] nums = new Integer[]{1,2,3,4,5,6,7,8,9};
Stream&amp;lt;Integer&amp;gt; numStream = Arrays.stream(nums);
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;（3）通过Stream类的静态方法of()获取数组流。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;可以使用静态方法 Stream.of(), 通过显示值创建一个流。它可以接收任意数量的参数。&lt;/p&gt;
&lt;p&gt;我们先来看看Stream的of()方法，如下所示。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;public static&amp;lt;T&amp;gt; Stream&amp;lt;T&amp;gt; of(T t) {
    return StreamSupport.stream(new Streams.StreamBuilderImpl&amp;lt;&amp;gt;(t), false);
}
@SafeVarargs
@SuppressWarnings(&quot;varargs&quot;) 
public static&amp;lt;T&amp;gt; Stream&amp;lt;T&amp;gt; of(T... values) {
    return Arrays.stream(values);
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;可以看到，在Stream类中，提供了两个of()方法，一个只需要传入一个泛型参数，一个需要传入一个可变泛型参数。&lt;/p&gt;
&lt;p&gt;我们可以使用下面的代码示例来使用of方法创建一个Stream流。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;Stream&amp;lt;String&amp;gt; strStream = Stream.of(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;);
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;（4）创建无限流&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;可以使用静态方法 Stream.iterate() 和Stream.generate(), 创建无限流。&lt;/p&gt;
&lt;p&gt;先来看看Stream类中iterate()方法和generate()方法的源码，如下所示。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;public static&amp;lt;T&amp;gt; Stream&amp;lt;T&amp;gt; iterate(final T seed, final UnaryOperator&amp;lt;T&amp;gt; f) {
    Objects.requireNonNull(f);
    final Iterator&amp;lt;T&amp;gt; iterator = new Iterator&amp;lt;T&amp;gt;() {
        @SuppressWarnings(&quot;unchecked&quot;)
        T t = (T) Streams.NONE;

        @Override
        public boolean hasNext() {
            return true;
        }

        @Override
        public T next() {
            return t = (t == Streams.NONE) ? seed : f.apply(t);
        }
    };
    return StreamSupport.stream(Spliterators.spliteratorUnknownSize(
        iterator,
        Spliterator.ORDERED | Spliterator.IMMUTABLE), false);
}

public static&amp;lt;T&amp;gt; Stream&amp;lt;T&amp;gt; generate(Supplier&amp;lt;T&amp;gt; s) {
    Objects.requireNonNull(s);
    return StreamSupport.stream(
        new StreamSpliterators.InfiniteSupplyingSpliterator.OfRef&amp;lt;&amp;gt;(Long.MAX_VALUE, s), false);
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;通过源码可以看出，iterate()方法主要是使用“迭代”的方式生成无限流，而generate()方法主要是使用“生成”的方式生成无限流。我们可以使用下面的代码示例来使用这两个方法生成Stream流。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;Stream&amp;lt;Integer&amp;gt; intStream = Stream.iterate(0, (x) -&amp;gt; x + 2);
intStream.forEach(System.out::println);
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;运行上述代码，会在终端一直输出偶数，这种操作会一直持续下去。如果我们只需要输出10个偶数，该如何操作呢？其实也很简单，使用Stream对象的limit方法进行限制就可以了，如下所示。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;Stream&amp;lt;Integer&amp;gt; intStream = Stream.iterate(0, (x) -&amp;gt; x + 2);
intStream.limit(10).forEach(System.out::println);
&lt;/code&gt;
&lt;/pre&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;Stream.generate(() -&amp;gt; Math.random()).forEach(System.out::println);
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;上述代码同样会一直输出随机数，如果我们只需要输出5个随机数，则只需要使用limit()方法进行限制即可。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;Stream.generate(() -&amp;gt; Math.random()).limit(5).forEach(System.out::println);
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;（5）创建空流&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;在Stream类中提供了一个empty()方法，如下所示。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;public static&amp;lt;T&amp;gt; Stream&amp;lt;T&amp;gt; empty() {
    return StreamSupport.stream(Spliterators.&amp;lt;T&amp;gt;emptySpliterator(), false);
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;我们可以使用Stream类的empty()方法来创建一个空Stream流，如下所示。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;Stream&amp;lt;String&amp;gt; empty = Stream.empty();
&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;写在最后&quot;&gt;写在最后&lt;/h2&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;如果觉得文章对你有点帮助，请微信搜索并关注「 &lt;strong&gt;冰河技术&lt;/strong&gt; 」微信公众号，跟冰河学习Java8新特性。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;最后，附上Java8新特性核心知识图，祝大家在学习Java8新特性时少走弯路。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20200520003727787.jpg&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
</description>
<pubDate>Mon, 25 May 2020 16:15:00 +0000</pubDate>
<dc:creator>冰河团队</dc:creator>
<og:description>写在前面 先说点题外话：不少读者工作几年后，仍然在使用Java7之前版本的方法，对于Java8版本的新特性，甚至是Java7的新特性几乎没有接触过。真心想对这些读者说：你真的需要了解下Java8甚至以</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/binghe001/p/12961977.html</dc:identifier>
</item>
<item>
<title>COLA的扩展性使用和源码研究 - 李福春</title>
<link>http://www.cnblogs.com/snidget/p/12961700.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/snidget/p/12961700.html</guid>
<description>&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/268922/202005/268922-20200525232318763-1113531243.png&quot; alt=&quot;image.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;封装变化，可灵活应对程序的需求变化。&lt;/p&gt;

&lt;p&gt;步骤:&lt;/p&gt;
&lt;p&gt;定义扩展点接口，类型可以是校验器，转换器，实体； 必须以ExtPt结尾，表示一个扩展点。&lt;/p&gt;
&lt;p&gt;比如，我定义一个云枢的组织结构的扩展点接口，消息发送扩展点，二开扩展点，webapi的rest接口扩展点点。&lt;/p&gt;
&lt;h2 id=&quot;定义扩展点接口&quot;&gt;定义扩展点接口&lt;/h2&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;package com.authine.web.cola.domain.customer;

import com.alibaba.cola.extension.ExtensionPointI;
import com.authine.web.cola.dto.domainmodel.Department;

import java.util.List;

/**
 * @author carter
 * create_date  2020/5/25 14:25
 * description     定义扩展点接口，对组织机构的某些方法。
 */

public interface OrganizationExtPt extends ExtensionPointI {

    /**
     * 根据corpId查询企业下所有部门
     *
     * @param corpId        企业编号
     * @param includeDelete 是否包含删除的部门
     * @return 部门
     */
    List&amp;lt;Department&amp;gt; getDepartmentsByCorpId(String corpId, Boolean includeDelete);


}

&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;比如业务扩展分为钉钉，微信：&lt;/p&gt;
&lt;p&gt;这里基于扩展理论（x,y）;&lt;/p&gt;
&lt;p&gt;即通过 业务，用例，场景得到扩展点的key, 那后扩展类就是针对实际的业务场景的业务处理代码；&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/268922/202005/268922-20200525232319107-661561341.jpg&quot; alt=&quot;file&quot;/&gt;&lt;/p&gt;
&lt;h2 id=&quot;钉钉场景扩展点实现&quot;&gt;钉钉场景扩展点实现&lt;/h2&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;package com.authine.web.cola.domain.customer.extpt;

import com.alibaba.cola.extension.Extension;
import com.authine.web.cola.dto.domainmodel.Department;
import com.authine.web.cola.domain.customer.OrganizationExtPt;
import lombok.extern.slf4j.Slf4j;

import java.util.Collections;
import java.util.List;

/**
 * @author carter
 * create_date  2020/5/25 14:32
 * description     企业部门在通过corpId获取部门列表的场景下，钉钉的扩展
 */
@Extension(bizId = &quot;organize&quot;,useCase = &quot;getByCorpId&quot;,scenario = &quot;dingTalk&quot;)
@Slf4j
public class DingTalkOrganizationExt implements OrganizationExtPt {

    @Override
    public List&amp;lt;Department&amp;gt; getDepartmentsByCorpId(String corpId, Boolean includeDelete) {

        log.info(&quot;在组织结构业务，通过企业编号获取部门列表的用例，在钉钉的场景下业务的实现处理方式&quot;);

        log.info(&quot;通过钉钉的配置信息和API获取得到组织信息，并组装成云枢识别的部门信息&quot;);

        Department department = new Department();

        department.setName(&quot;dingTalk&quot;);
        department.setCorpId(corpId);

        return Collections.singletonList(department);
    }
}

&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;企业微信扩展点实现&quot;&gt;企业微信扩展点实现&lt;/h2&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;package com.authine.web.cola.domain.customer.extpt;

import com.alibaba.cola.extension.Extension;
import com.authine.web.cola.dto.domainmodel.Department;
import com.authine.web.cola.domain.customer.OrganizationExtPt;
import lombok.extern.slf4j.Slf4j;

import java.util.Collections;
import java.util.List;

/**
 * @author carter
 * create_date  2020/5/25 15:05
 * description     企业微信的扩展点实现
 */
@Extension(bizId = &quot;organize&quot;,useCase = &quot;getByCorpId&quot;,scenario = &quot;wechat&quot;)
@Slf4j
public class WechatOrganizationExt  implements OrganizationExtPt {
    @Override
    public List&amp;lt;Department&amp;gt; getDepartmentsByCorpId(String corpId, Boolean includeDelete) {

        log.info(&quot;业务：组织机构，用例：通过企业编号获取部门 , 场景：企业微信&quot;);

        log.info(&quot;通过企业微信的API获取组织的部门信息，然后包装为需要的部门列表&quot;);

        Department department = new Department();

        department.setName(&quot;wechat&quot;);
        department.setCorpId(corpId);

        return Collections.singletonList(department);
    }
}

&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;扩展点使用-2&quot;&gt;扩展点使用&lt;/h2&gt;
&lt;p&gt;在命令执行器中使用。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;package com.authine.web.cola.executor.query;

import com.alibaba.cola.command.Command;
import com.alibaba.cola.command.CommandExecutorI;
import com.alibaba.cola.dto.MultiResponse;
import com.alibaba.cola.extension.ExtensionExecutor;
import com.authine.web.cola.dto.domainmodel.Department;
import com.authine.web.cola.domain.customer.OrganizationExtPt;
import com.authine.web.cola.dto.OrgnizationQry;

import java.util.List;


/**
 * @author carter
 * create_date  2020/5/25 15:09
 * description     查询组织机构的指令执行
 */
@Command
public class OrgazationQueryExe implements CommandExecutorI&amp;lt;MultiResponse, OrgnizationQry&amp;gt; {


    private final ExtensionExecutor extensionExecutor;

    public OrgazationQueryExe(ExtensionExecutor extensionExecutor) {
        this.extensionExecutor = extensionExecutor;
    }


    @Override
    public MultiResponse execute(OrgnizationQry cmd) {

        String corpId = cmd.getCorpId();

        boolean includeDelete = cmd.isIncludeDelete();

        List&amp;lt;Department&amp;gt; departmentList = extensionExecutor.execute(OrganizationExtPt.class, cmd.getBizScenario(),
                ex -&amp;gt; ex.getDepartmentsByCorpId(corpId, includeDelete));


        return MultiResponse.ofWithoutTotal(departmentList);
    }
}

&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;测试扩展点的使用&quot;&gt;测试扩展点的使用&lt;/h2&gt;
&lt;p&gt;封装一个http接口来调用。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;package com.authine.web.cola.controller;

import com.alibaba.cola.dto.MultiResponse;
import com.alibaba.cola.extension.BizScenario;
import com.authine.web.cola.api.OrganizationServiceI;
import com.authine.web.cola.dto.OrgnizationQry;
import com.authine.web.cola.dto.domainmodel.Department;
import org.springframework.web.bind.annotation.GetMapping;
import org.springframework.web.bind.annotation.PathVariable;
import org.springframework.web.bind.annotation.RestController;

@RestController
public class OrganizationController {

    private final OrganizationServiceI organizationServiceI;

    public OrganizationController(OrganizationServiceI organizationServiceI) {
        this.organizationServiceI = organizationServiceI;
    }

    @GetMapping(value = &quot;/organization/getDepartmentsByCorpId/{corpId}/{scenario}&quot;)
    public MultiResponse&amp;lt;Department&amp;gt; listCustomerByName(@PathVariable(&quot;corpId&quot;) String corpId,@PathVariable(&quot;scenario&quot;) String scenario){

        OrgnizationQry qry = new OrgnizationQry();
        qry.setCorpId(corpId);
        qry.setIncludeDelete(true);
        qry.setBizScenario(BizScenario.valueOf(&quot;organize&quot;,&quot;getByCorpId&quot;,scenario));

        return organizationServiceI.getDepartmentsByCorpId(qry);
    }


}

&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;下面是使用接口进行测试的结果。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/268922/202005/268922-20200525232319662-184780044.png&quot; alt=&quot;image.png&quot;/&gt;&lt;/p&gt;
&lt;h2 id=&quot;小结&quot;&gt;小结&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/268922/202005/268922-20200525232320398-824295432.png&quot; alt=&quot;image.png&quot;/&gt;&lt;br/&gt;基于元数据的扩展点设计，可以灵活的应对 业务场景的多样性，以及灵活的支持版本升级。&lt;br/&gt;其它的扩展点（校验器，转换器）其它等，也可以轻松做到扩展。&lt;br/&gt;使用例子在框架的单元测试用例中。&lt;/p&gt;

&lt;h2 id=&quot;设计本质&quot;&gt;设计本质&lt;/h2&gt;
&lt;p&gt;设计理念。&lt;strong&gt;是一种基于数据的配置扩展。即基于注解上带上配置数据。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;@Extension 源码如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;package com.alibaba.cola.extension;

import com.alibaba.cola.common.ColaConstant;
import org.springframework.stereotype.Component;

import java.lang.annotation.*;


@Inherited
@Retention(RetentionPolicy.RUNTIME)
@Target({ElementType.TYPE})
@Component
public @interface Extension {
    String bizId()  default BizScenario.DEFAULT_BIZ_ID;
    String useCase() default BizScenario.DEFAULT_USE_CASE;
    String scenario() default BizScenario.DEFAULT_SCENARIO;
}

&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;图文说明如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/268922/202005/268922-20200525232320694-1715877803.png&quot; alt=&quot;image.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;下面深入源码进行研究。从使用的源码出发。&lt;/p&gt;
&lt;h2 id=&quot;extensionexecutor&quot;&gt;ExtensionExecutor&lt;/h2&gt;
&lt;p&gt;类图如下。&lt;/p&gt;
&lt;p&gt;首先，标注了Component,所以，在ioc中可以通过类型拿到实例。&lt;/p&gt;
&lt;p&gt;最后，执行函数是放在父类AbstractComponentExecutor中；&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/268922/202005/268922-20200525232322178-2018684822.png&quot; alt=&quot;image.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;重点分析一下它实现的功能：即通过坐标得到扩展实例；&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt; /**
     * if the bizScenarioUniqueIdentity is &quot;ali.tmall.supermarket&quot;
     *
     * the search path is as below:
     * 1、first try to get extension by &quot;ali.tmall.supermarket&quot;, if get, return it.
     * 2、loop try to get extension by &quot;ali.tmall&quot;, if get, return it.
     * 3、loop try to get extension by &quot;ali&quot;, if get, return it.
     * 4、if not found, try the default extension
     * @param targetClz
     */
    protected &amp;lt;Ext&amp;gt; Ext locateExtension(Class&amp;lt;Ext&amp;gt; targetClz, BizScenario bizScenario) {
        checkNull(bizScenario);

        Ext extension;
        String bizScenarioUniqueIdentity = bizScenario.getUniqueIdentity();
        logger.debug(&quot;BizScenario in locateExtension is : &quot; + bizScenarioUniqueIdentity);

        // first try
        extension = firstTry(targetClz, bizScenarioUniqueIdentity);
        if (extension != null) {
            return extension;
        }

        // loop try
        extension = loopTry(targetClz, bizScenarioUniqueIdentity);
        if (extension != null) {
            return extension;
        }

        throw new ColaException(&quot;Can not find extension with ExtensionPoint: &quot;+targetClz+&quot; BizScenario:&quot;+bizScenarioUniqueIdentity);
    }
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;实现步骤如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/268922/202005/268922-20200525232322694-1044144054.jpg&quot; alt=&quot;file&quot;/&gt;&lt;/p&gt;
&lt;h2 id=&quot;extensionrepository&quot;&gt;ExtensionRepository&lt;/h2&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;package com.alibaba.cola.extension;

import java.util.HashMap;
import java.util.Map;

import org.springframework.stereotype.Component;

import lombok.Getter;

/**
 * ExtensionRepository 
 * @author fulan.zjf 2017-11-05
 */
@Component
public class ExtensionRepository {

    @Getter
    private Map&amp;lt;ExtensionCoordinate, ExtensionPointI&amp;gt; extensionRepo = new HashMap&amp;lt;&amp;gt;();

}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;里面是一个空的map,主要还是看组装过程。看下面的ExtensionRegister;&lt;/p&gt;
&lt;h2 id=&quot;extensionregister&quot;&gt;ExtensionRegister&lt;/h2&gt;
&lt;p&gt;看名字，就是注册扩展的组件。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;/*
 * Copyright 2017 Alibaba.com All right reserved. This software is the
 * confidential and proprietary information of Alibaba.com (&quot;Confidential
 * Information&quot;). You shall not disclose such Confidential Information and shall
 * use it only in accordance with the terms of the license agreement you entered
 * into with Alibaba.com.
 */
package com.alibaba.cola.boot;

import com.alibaba.cola.common.ApplicationContextHelper;
import com.alibaba.cola.common.ColaConstant;
import com.alibaba.cola.exception.framework.ColaException;
import com.alibaba.cola.extension.*;
import org.apache.commons.lang3.ArrayUtils;
import org.apache.commons.lang3.StringUtils;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.stereotype.Component;

/**
 * ExtensionRegister 
 * @author fulan.zjf 2017-11-05
 */
@Component
public class ExtensionRegister implements RegisterI{

    @Autowired
    private ExtensionRepository extensionRepository;
    

    @Override
    public void doRegistration(Class&amp;lt;?&amp;gt; targetClz) {
        ExtensionPointI extension = (ExtensionPointI) ApplicationContextHelper.getBean(targetClz);
        Extension extensionAnn = targetClz.getDeclaredAnnotation(Extension.class);
        String extPtClassName = calculateExtensionPoint(targetClz);
        BizScenario bizScenario = BizScenario.valueOf(extensionAnn.bizId(), extensionAnn.useCase(), extensionAnn.scenario());
        ExtensionCoordinate extensionCoordinate = new ExtensionCoordinate(extPtClassName, bizScenario.getUniqueIdentity());
        ExtensionPointI preVal = extensionRepository.getExtensionRepo().put(extensionCoordinate, extension);
        if (preVal != null) {
            throw new ColaException(&quot;Duplicate registration is not allowed for :&quot; + extensionCoordinate);
        }
    }

    /**
     * @param targetClz
     * @return
     */
    private String calculateExtensionPoint(Class&amp;lt;?&amp;gt; targetClz) {
        Class[] interfaces = targetClz.getInterfaces();
        if (ArrayUtils.isEmpty(interfaces))
            throw new ColaException(&quot;Please assign a extension point interface for &quot;+targetClz);
        for (Class intf : interfaces) {
            String extensionPoint = intf.getSimpleName();
            if (StringUtils.contains(extensionPoint, ColaConstant.EXTENSION_EXTPT_NAMING))
                return intf.getName();
        }
        throw new ColaException(&quot;Your name of ExtensionPoint for &quot;+targetClz+&quot; is not valid, must be end of &quot;+ ColaConstant.EXTENSION_EXTPT_NAMING);
    }

}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;注册过程如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/268922/202005/268922-20200525232322996-1199838311.jpg&quot; alt=&quot;file&quot;/&gt;&lt;/p&gt;
&lt;p&gt;以上是扩展类注册到扩展仓库的过程。&lt;/p&gt;
&lt;p&gt;注册时机。启动的时刻通过包扫描进行注册。&lt;/p&gt;
&lt;h2 id=&quot;registerfactory&quot;&gt;RegisterFactory&lt;/h2&gt;
&lt;p&gt;把各种注册器放入到ioc中，通过一个统一的方法返回。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;/*
 * Copyright 2017 Alibaba.com All right reserved. This software is the
 * confidential and proprietary information of Alibaba.com (&quot;Confidential
 * Information&quot;). You shall not disclose such Confidential Information and shall
 * use it only in accordance with the terms of the license agreement you entered
 * into with Alibaba.com.
 */
package com.alibaba.cola.boot;

import com.alibaba.cola.command.Command;
import com.alibaba.cola.command.PostInterceptor;
import com.alibaba.cola.command.PreInterceptor;
import com.alibaba.cola.event.EventHandler;
import com.alibaba.cola.extension.Extension;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.stereotype.Component;

/**
 * RegisterFactory
 *
 * @author fulan.zjf 2017-11-04
 */
@Component
public class RegisterFactory{

    @Autowired
    private PreInterceptorRegister preInterceptorRegister;
    @Autowired
    private PostInterceptorRegister postInterceptorRegister;
    @Autowired
    private CommandRegister commandRegister;
    @Autowired
    private ExtensionRegister extensionRegister;
    @Autowired
    private EventRegister eventRegister;


    public RegisterI getRegister(Class&amp;lt;?&amp;gt; targetClz) {
        PreInterceptor preInterceptorAnn = targetClz.getDeclaredAnnotation(PreInterceptor.class);
        if (preInterceptorAnn != null) {
            return preInterceptorRegister;
        }
        PostInterceptor postInterceptorAnn = targetClz.getDeclaredAnnotation(PostInterceptor.class);
        if (postInterceptorAnn != null) {
            return postInterceptorRegister;
        }
        Command commandAnn = targetClz.getDeclaredAnnotation(Command.class);
        if (commandAnn != null) {
            return commandRegister;
        }
        Extension extensionAnn = targetClz.getDeclaredAnnotation(Extension.class);
        if (extensionAnn != null) {
            return extensionRegister;
        }
        EventHandler eventHandlerAnn = targetClz.getDeclaredAnnotation(EventHandler.class);
        if (eventHandlerAnn != null) {
            return eventRegister;
        }
        return null;
    }
}

&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;bootstrap&quot;&gt;BootStrap&lt;/h2&gt;
&lt;p&gt;扫描java的class,进行ioc组装；&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;/*
 * Copyright 2017 Alibaba.com All right reserved. This software is the
 * confidential and proprietary information of Alibaba.com (&quot;Confidential
 * Information&quot;). You shall not disclose such Confidential Information and shall
 * use it only in accordance with the terms of the license agreement you entered
 * into with Alibaba.com.
 */
package com.alibaba.cola.boot;

import java.util.List;
import java.util.Set;
import java.util.TreeSet;

import org.springframework.beans.factory.annotation.Autowired;

import com.alibaba.cola.exception.framework.ColaException;

import lombok.Getter;
import lombok.Setter;

/**
 * &amp;lt;B&amp;gt;应用的核心引导启动类&amp;lt;/B&amp;gt;
 * &amp;lt;p&amp;gt;
 * 负责扫描在applicationContext.xml中配置的packages. 获取到CommandExecutors, intercepters, extensions, validators等
 * 交给各个注册器进行注册。
 *
 * @author fulan.zjf 2017-11-04
 */
public class Bootstrap {
    @Getter
    @Setter
    private List&amp;lt;String&amp;gt; packages;
    private ClassPathScanHandler handler;

    @Autowired
    private RegisterFactory registerFactory;


    public void init() {
        Set&amp;lt;Class&amp;lt;?&amp;gt;&amp;gt; classSet = scanConfiguredPackages();
        registerBeans(classSet);
    }

    /**
     * @param classSet
     */
    private void registerBeans(Set&amp;lt;Class&amp;lt;?&amp;gt;&amp;gt; classSet) {
        for (Class&amp;lt;?&amp;gt; targetClz : classSet) {
            RegisterI register = registerFactory.getRegister(targetClz);
            if (null != register) {
                register.doRegistration(targetClz);
            }
        }

    }



&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;其它的核心组件的注册也在该代码中。&lt;/p&gt;
&lt;h2 id=&quot;abstractcomponentexecutor&quot;&gt;AbstractComponentExecutor&lt;/h2&gt;
&lt;p&gt;抽象的组件执行器，主要功能是定位到扩展类，然后执行接口的方法。&lt;/p&gt;
&lt;p&gt;源码如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;package com.alibaba.cola.boot;

import com.alibaba.cola.extension.BizScenario;
import com.alibaba.cola.extension.ExtensionCoordinate;

import java.util.function.Consumer;
import java.util.function.Function;

/**
 * @author fulan.zjf
 * @date 2017/12/21
 */
public abstract class AbstractComponentExecutor {

    /**
     * Execute extension with Response
     *
     * @param targetClz
     * @param bizScenario
     * @param exeFunction
     * @param &amp;lt;R&amp;gt; Response Type
     * @param &amp;lt;T&amp;gt; Parameter Type
     * @return
     */
    public &amp;lt;R, T&amp;gt; R execute(Class&amp;lt;T&amp;gt; targetClz, BizScenario bizScenario, Function&amp;lt;T, R&amp;gt; exeFunction) {
        T component = locateComponent(targetClz, bizScenario);
        return exeFunction.apply(component);
    }

    public &amp;lt;R, T&amp;gt; R execute(ExtensionCoordinate extensionCoordinate, Function&amp;lt;T, R&amp;gt; exeFunction){
        return execute((Class&amp;lt;T&amp;gt;) extensionCoordinate.getExtensionPointClass(), extensionCoordinate.getBizScenario(), exeFunction);
    }

    /**
     * Execute extension without Response
     *
     * @param targetClz
     * @param context
     * @param exeFunction
     * @param &amp;lt;T&amp;gt; Parameter Type
     */
    public &amp;lt;T&amp;gt; void executeVoid(Class&amp;lt;T&amp;gt; targetClz, BizScenario context, Consumer&amp;lt;T&amp;gt; exeFunction) {
        T component = locateComponent(targetClz, context);
        exeFunction.accept(component);
    }

    public &amp;lt;T&amp;gt; void executeVoid(ExtensionCoordinate extensionCoordinate, Consumer&amp;lt;T&amp;gt; exeFunction){
        executeVoid(extensionCoordinate.getExtensionPointClass(), extensionCoordinate.getBizScenario(), exeFunction);
    }

    protected abstract &amp;lt;C&amp;gt; C locateComponent(Class&amp;lt;C&amp;gt; targetClz, BizScenario context);
}

&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;主要用到了java8的函数式接口Function&amp;lt;T,R&amp;gt;.&lt;br/&gt;T:即系统中注册好的扩展类实例；&lt;br/&gt;R即调用T的使用类的方法，执行之后的返回值。&lt;/p&gt;
&lt;p&gt;把执行哪个方法的选择权交给了业务逻辑代码。&lt;/p&gt;
&lt;p&gt;提供了4种不同的重载方法。&lt;/p&gt;
&lt;h2 id=&quot;小结-2&quot;&gt;小结&lt;/h2&gt;
&lt;p&gt;通过key,value的方式进行扩展。&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/carterbrother/springbootpractice/tree/master/demo_cola/cola_web1&quot;&gt;代码点我获取！&lt;/a&gt;&lt;/p&gt;
&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;原创不易，关注诚可贵，转发价更高！转载请注明出处，让我们互通有无，共同进步，欢迎沟通交流。&lt;br/&gt;我会持续分享Java软件编程知识和程序员发展职业之路，欢迎关注，我整理了这些年编程学习的各种资源，关注公众号‘李福春持续输出’，发送'学习资料'分享给你！&lt;br/&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/268922/202005/268922-20200525232323248-1484112660.jpg&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;/blockquote&gt;
</description>
<pubDate>Mon, 25 May 2020 15:23:00 +0000</pubDate>
<dc:creator>李福春</dc:creator>
<og:description>cola扩展点使用和设计初探 封装变化，可灵活应对程序的需求变化。 扩展点使用 步骤: 定义扩展点接口，类型可以是校验器，转换器，实体； 必须以ExtPt结尾，表示一个扩展点。 比如，我定义一个云枢的</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/snidget/p/12961700.html</dc:identifier>
</item>
<item>
<title>Linux的运行等级与目标 - JF Zhu</title>
<link>http://www.cnblogs.com/jfzhu/p/12961694.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/jfzhu/p/12961694.html</guid>
<description>&lt;h3 align=&quot;center&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;运行级别 Run Level&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;

&lt;p align=&quot;justify&quot;&gt;&lt;span&gt;大家都知道 Windows 有安全模式，它是Windows的最小模式，和普通模式相比，安全模式可以让用户更好地进行系统检测以及错误修复。Linux 的运行级别是个类似的机制，不同的运行级别有不同的作用：&lt;/span&gt;&lt;/p&gt;

&lt;p align=&quot;justify&quot;&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/442200/202005/442200-20200525231923953-990956473.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p align=&quot;justify&quot;&gt;&lt;span&gt;我们通常用到的是级别 3 和 5，一般服务器不需要安装图形界面，并且需要支持用户远程连接，所以运行级别会选择 3；个人电脑一般需要 GUI，所以会选择运行级别 5。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;想查看当前系统的运行级别可以使用命令用到命令&lt;/span&gt;&lt;/p&gt;
&lt;p align=&quot;left&quot;&gt;#runlevel&lt;/p&gt;
&lt;p align=&quot;left&quot;&gt;N 5&lt;/p&gt;
&lt;p&gt;&lt;span&gt;上面的结果表示当前的运行级别是 5。在不同级别间切换可以使用命令&lt;/span&gt;&lt;/p&gt;
&lt;p align=&quot;left&quot;&gt;#init [运行级别]&lt;/p&gt;
&lt;p&gt;&lt;span&gt;比如当前运行在级别 3，是多用户字符界面，想要启动 GUI 图形界面，只需要输入 init 5 &lt;/span&gt;&lt;/p&gt;

&lt;p align=&quot;justify&quot;&gt;&lt;span&gt;虽然运行级别可以实时切换，如果想修改系统启动时默认的运行级别，在 CentOS 5 和 6 中也可以修改 /etc/inittab 文件来进行配置。&lt;/span&gt;&lt;/p&gt;


&lt;h3 align=&quot;center&quot;&gt;&lt;span&gt;&lt;strong&gt;系统初始化进程 systemd vs. init&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;h3&gt;&lt;br/&gt;&lt;/h3&gt;
&lt;p align=&quot;justify&quot;&gt;&lt;span&gt;在 CentOS 7 之前，系统的初始化进程是 init，它的 PID 是 1，初始化进程就是系统第一个被执行的程序，所有其他进程都是它的子进程，所以我们切换运行级别用到的命令是 init，系统启动默认运行级别的配置文件是 /etc/inittab。&lt;/span&gt;&lt;/p&gt;

&lt;p align=&quot;justify&quot;&gt;&lt;span&gt;从 CentOS 7 开始，系统初始化进程采用了全新的 systemd。从它的名字可以看出，它是一个服务，由系统自动在后台运行。和 init 相比，systemd 有一些明显的优势：&lt;/span&gt;&lt;/p&gt;

&lt;p align=&quot;justify&quot;&gt;&lt;span&gt;1） systemd 在系统启动时使用了并发的启动机制，而 init 是按顺序依次启动每项服务。实际上很多服务之间没有依赖关系，不需要依次等待。在 Linux 早期，计算机的CPU是单核的，一次只能处理一项任务，所以 init 的设计有它的合理性。但随着硬件技术发展，现在的服务器CPU大多是多核心的，可以同时处理多项任务，systemd 可以并发启动那些不相关的服务，所以系统启动速度得到了极大的提升。&lt;/span&gt;&lt;/p&gt;

&lt;p align=&quot;justify&quot;&gt;&lt;span&gt;2） systemd 是按需启动服务，而 init 是将所有后台服务统统启动，全部完成后才允许用户登录。init 的这种方式会使得系统启动比较慢，另外也会占用比较多的系统资源。systemd 采用的方式是只有某个服务被请求时才会启动它，使用完成后会动态将该服务关闭，所以不管是启动速度，还是系统资源的使用， systemd 都有很大的优势。&lt;/span&gt;&lt;/p&gt;

&lt;p align=&quot;justify&quot;&gt;&lt;span&gt;systemd 有两个核心的概念，单元（unit）和 目标（target）。systemd 进程对系统的管理就是通过一个个的单元来实现的。比如服务，每一个服务都有一个对应的单元，而且每个单元都有一个配置文件，配置文件通常以 .service 作为文件名后缀，像 sshd 服务，它的配置文件就是 /usr/lib/systemd/system/sshd.service&lt;/span&gt;&lt;/p&gt;

&lt;p align=&quot;justify&quot;&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/442200/202005/442200-20200525231933371-1270619842.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p align=&quot;justify&quot;&gt;&lt;span&gt;有一类比较重要的单元叫目标单元（target unit），或者简称目标（target），它们的配置文件名后缀为 .target。在 systemd 中，我们用 target 来模拟实现系统不同的运行级别。&lt;/span&gt;&lt;/p&gt;

&lt;h3 align=&quot;center&quot;&gt;&lt;span&gt;&lt;strong&gt;通过目标（Target）来实现运行级别&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;

&lt;p align=&quot;justify&quot;&gt;&lt;span&gt;上面提到，CentOS 7 将系统初始化进程从 init 改为了 systemd，init 的运行级别（runlevels）也改成了用目标（target）来实现，不同的运行级别和目标之间是什么对应关系呢，我们用下面这张图来做了一个总结：&lt;/span&gt;&lt;/p&gt;

&lt;p align=&quot;justify&quot;&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/442200/202005/442200-20200525231939144-1793236403.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p align=&quot;justify&quot;&gt;&lt;span&gt;常用的运行级别是 3 （多用户字符模式）和 5（多用户图形界面模式），它们分别对应的目标就是 multi-user.target 和 graphical.target。设置和切换不同的运行级别，CentOS 7 还是向前支持 init 命令，但是更建议我们使用 systemd 的管理工具 systemctl 来完成。&lt;/span&gt;&lt;/p&gt;

&lt;p align=&quot;justify&quot;&gt;&lt;strong&gt;&lt;span&gt;1） 查看当前系统默认运行&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;，可以使用 systemctl get-default 命令&lt;/span&gt;&lt;/p&gt;
&lt;p align=&quot;left&quot;&gt;#systemctl get-default&lt;/p&gt;
&lt;p align=&quot;left&quot;&gt;multi-user.target&lt;/p&gt;

&lt;p align=&quot;justify&quot;&gt;&lt;strong&gt;&lt;span&gt;2） 切换不同运行级别&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;，以管理员身份使用 systemctl [目标名称] 命令&lt;/span&gt;&lt;/p&gt;
&lt;p align=&quot;left&quot;&gt;#systemctl isolate graphical.target    &lt;span&gt;切换到图形界面&lt;/span&gt;&lt;/p&gt;

&lt;p align=&quot;justify&quot;&gt;&lt;strong&gt;&lt;span&gt;3） 设置系统启动默认运行级别&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p align=&quot;justify&quot;&gt;&lt;span&gt;在 CentOS 5 和 6 中，系统启动默认的运行级别可以在 /etc/inittab 文件中进行配置，但在 CentOS 7 中，我们打开这个配置文件看一下：&lt;/span&gt;&lt;/p&gt;
&lt;p align=&quot;justify&quot;&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/442200/202005/442200-20200525231945705-841032057.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p align=&quot;justify&quot;&gt;&lt;span&gt;从配置文件内容可以看到，&lt;em&gt;“在这里做任何的配置对系统都是没有作用的，systemd 用目标来取代运行级别。默认有两个主要的目标，multi-user.target 相当于运行级别 3，graphical.target 相当于运行级别 5。使用 systemctl get-default 来看当前使用目标，使用 systemctl set-default Target.target 来设置系统默认目标”。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p align=&quot;justify&quot;&gt;&lt;span&gt;所以我们用下面的命令来试一下，将系统启动目标设置为 graphical&lt;/span&gt;&lt;/p&gt;
&lt;p align=&quot;left&quot;&gt;#systemctl set-default graphical.target&lt;/p&gt;
&lt;p align=&quot;justify&quot;&gt;&lt;span&gt;设置成功后，重启电脑，发现果然进入了 GUI 图形界面模式。&lt;/span&gt;&lt;/p&gt;


&lt;h3 align=&quot;center&quot;&gt;&lt;span&gt;&lt;strong&gt;最后&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;

&lt;p align=&quot;justify&quot;&gt;&lt;span&gt;到这里，systemd 如何使用 target 来替换 init 的 runlevels 就介绍完了。可能很多老 Linux 用户还是比较习惯于用 init，但毕竟 systemd 是更一种更先进的技术和方式，大家还是应该更积极地去接受并学习它。&lt;/span&gt;&lt;/p&gt;



&lt;p align=&quot;justify&quot;&gt;&lt;span&gt;推荐阅读：&lt;/span&gt;&lt;/p&gt;
&lt;p align=&quot;justify&quot;&gt;&lt;a href=&quot;https://www.cnblogs.com/jfzhu/p/12945358.html&quot; target=&quot;_blank&quot; data-linktype=&quot;2&quot;&gt;&lt;span&gt;《软链接 vs. 硬链接》&lt;/span&gt;&lt;/a&gt;&lt;br/&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.cnblogs.com/jfzhu/p/12940175.html&quot; target=&quot;_blank&quot; data-linktype=&quot;2&quot;&gt;《Linux 目录详解》&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.cnblogs.com/jfzhu/p/12928138.html&quot; target=&quot;_blank&quot; data-linktype=&quot;2&quot;&gt;《虚拟机安装 Linux 最完整攻略》&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.cnblogs.com/jfzhu/p/12907248.html&quot; target=&quot;_blank&quot; data-linktype=&quot;2&quot;&gt;《Xshell 与 Xftp 的安装与使用》&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.cnblogs.com/jfzhu/p/12895692.html&quot; target=&quot;_blank&quot; data-linktype=&quot;2&quot;&gt;《Linux，Unix，GNU 到底有什么样的渊源？》&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/442200/202005/442200-20200525232115577-175126278.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;span&gt;- The End -&lt;/span&gt;&lt;/p&gt;


</description>
<pubDate>Mon, 25 May 2020 15:22:00 +0000</pubDate>
<dc:creator>JF Zhu</dc:creator>
<og:description>在老的 Linux 发行版本中，系统运行分成不同的运行级别（run level），不同的级别所启动的服务搭配有所不同。较新的 Linux 发行版本，比如 CentOS 7+，已经将运行级别替换成另一个</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/jfzhu/p/12961694.html</dc:identifier>
</item>
<item>
<title>是小厂全栈好，还是大厂专业工程师好？ - 溪源More</title>
<link>http://www.cnblogs.com/xiyuanMore/p/12961596.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/xiyuanMore/p/12961596.html</guid>
<description>&lt;p&gt;在博客园中使用小公司大公司进行搜索，列入的搜索记录长达50页。虽然完全命中关键词的文章也许并不多，但这或许也能体现出这个话题的热门程度。&lt;/p&gt;
&lt;p&gt;今天我的公众号好友中也有人问了我这个问题：&lt;/p&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;在小公司里面做全栈好，还是大公司里面做专业的前端或者后台好？&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;对于这个问题，我大概有一点点发言权。在我过去若干年的职业生涯中，各种类型的公司也算都经历过，小一点的公司，大概有四五十人，大一点的公司有大几百人。&lt;/p&gt;
&lt;p&gt;当然，与读者们的大厂比起来，都是小公司，着实不算大公司。但总体来说，也算是了解“专业工程师”和“全栈工程师”这两个名词背后的水深水浅。&lt;/p&gt;

&lt;p&gt;有时，当我们去跟一些人交流，会发现一个奇怪的现象，往往小公司的更喜欢称自己为“全栈工程师”，而大厂出来的，则反而不敢自称自己为“全栈工程师”。这究竟是为何呢？&lt;/p&gt;
&lt;p&gt;我们可以继续引述经典理论“达克效应”。&lt;/p&gt;
&lt;p&gt;1、不知道自己不知道。&lt;/p&gt;
&lt;p&gt;2、知道自己不知道。&lt;/p&gt;
&lt;p&gt;3、知道自己知道。&lt;/p&gt;
&lt;p&gt;4、不知道自己知道。&lt;/p&gt;
&lt;p&gt;这四个阶段其实无论在技术层面，还是职场发展过程中，都无处不在。&lt;br/&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/191302/202005/191302-20200525230808489-203493298.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;在我们每个人说起漫长，说起短暂的职业生涯中，总是会历经无穷次技术的发展，甚至变革，这些技术其实在给我们创造价值的同时，也一点点在我们的灵魂深处留下投影。&lt;/p&gt;
&lt;p&gt;有的技术或理论，会对我们的职业发展产生非常深刻的影响；有的则如雨后彩虹一般，突然出现，却有遽然消失。&lt;/p&gt;
&lt;p&gt;每一种技术或理论的产生总会有一套成体系的脉络，也许入门很容易，但要成为专家其实非常困难。达克效应表现的也是这样一种效应。&lt;/p&gt;
&lt;p&gt;那些看起来很容易就学会的东西，往往要深入或许更加困难。而许多大厂开发者深刻体会其中的不容易，所以若非经过最少几百小时的学习，其实不敢自称为专家，更遑论自称“全栈工程师”了。&lt;/p&gt;
&lt;p&gt;其实，有的人自称为“全栈工程师”，倒不如说是“全能工程师”---每种技术都或多或少懂一点，能够在很短的时间内完成任务，但一旦要有所深入，就略显不足，无法再进一步了。&lt;/p&gt;

&lt;p&gt;但，无法在技术层面有所深入，是一件难以启齿的事情么？&lt;/p&gt;
&lt;p&gt;也许并非如此。我深深的感觉，在IT行业，看起来风起云涌，浪潮迭起，但依然充满前途和光明，其主要原因在于：人们对基于互联网场景下的应用，需求从来就没有因为互联网技术的发展而有所降低，反而越来越细致，越来越具体，产生着越来越深远的影响。&lt;/p&gt;
&lt;p&gt;例如，很多年前就说美国互联网泡沫破灭，但今天互联网经济反而越来越重要了；移动互联网也有人唱衰，“说BAT才掌握船票，已经垄断中国经济，其他公司几乎毫无机会”。却莫名其妙间，又多出了头条、美团、小米、滴滴、京东、拼多多等数不尽的优秀互联网公司。&lt;/p&gt;
&lt;p&gt;再过十年IT产业会逐渐退潮么，IT人才将会毫无施展才华的土壤么。不得而知，而且也不重要。重要的是，即便在互联网技术飞速发展的今天，中国依然对优秀的IT工程师非常稀缺。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/191302/202005/191302-20200525230759314-1127830903.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;时至今日，软件实现过程并没有因为软件技术人才的增加而逐渐简化，反而依然非常复杂。我们其实都能看到，在IT行业，五年经验以下的开发者始终居于大多数，不管是十年前，还是今天，行业都几乎没有太大的变化。我们能指望现在的年轻开发者能够提前规避我们之前遇到过的那些问题么？&lt;/p&gt;
&lt;p&gt;历史告诉我们：人们走过的弯路，后人其实还是会再走一遍。看似大爆炸的互联网，知识满地都是。其实，知识过载和知识过乏没有任何区别。所以，我们写过的那些垃圾代码，我们以前遇到过的那些bug，依然有许多年轻人在沿着我们的步伐再走一遍。&lt;/p&gt;
&lt;p&gt;那些隐藏在软件界面的冰山之下，难道bug突然减少了？究竟会不会在哪天突然爆发？客户提出的需求，程序员们究竟是如何实现的？&lt;/p&gt;

&lt;p&gt;我始终认为，专业工程师依然非常匮乏，无论过去、今天，或未来。&lt;/p&gt;
&lt;p&gt;专业工程师或许不一定是某个领域的专家，也许是某些具备优秀跨职能能力的开发者。&lt;/p&gt;
&lt;p&gt;他们首先能够基于某些行业场景出发，以独特的视角发掘问题的本质，并快速的将业务问题转换为技术实现，还能抽丝剥茧，发现不同事物之间的关联关系，从而更好的将业务问题以软件的形式进行呈现，&lt;/p&gt;
&lt;p&gt;他们也能灵活的发现不同技术之间的优缺点，并使用合适的技术问题来进行适配，使得问题能够以最快的速度进行解决。&lt;/p&gt;
&lt;p&gt;他们还能从多个角度出发，而不仅仅是从【软件代码实现】这个维度出发来解决问题，他们所具备的良好的沟通能力和专业素养，使得客户/用户能够愿意倾听提出的建议，从而以最少的代价来解决问题。&lt;/p&gt;

&lt;p&gt;成为专业工程师，与选择“大厂”或选择“小厂”有非常明显的区别么？&lt;/p&gt;
&lt;p&gt;大公司和小公司都有不同的发展轨迹，不同的人适合不同的发展方向。无论怎么选，其实都是“小样本”。&lt;/p&gt;
&lt;p&gt;个体选择走【跨职能型人才路线】或走【专业人才】路线，对于偌大的中国来说，都其实不会对历史的车轮产生多大的影响，但我们的选择其实是在慢慢的改变我们的生活。&lt;/p&gt;
&lt;p&gt;有时，小厂在能够填补我们对于经济上的匮乏，又有时，选择了大厂会让我们以为未来的发展无忧。&lt;/p&gt;
&lt;p&gt;确实如此，有时一些小厂反而能够比大厂提供短期内更加诱人的薪资，这对一些经济条件不太好的人来说，犹如“久旱甘霖”；而大厂看似平滑的发展曲线，能够让我们只要沿着设定的方向走下去，肯定不会走错。&lt;/p&gt;
&lt;p&gt;但真的小厂就意味着“朝不保夕”，大厂就一定是“高枕无忧”么？谁也说不准。&lt;/p&gt;
&lt;p&gt;最重要的，也许依然是认清自己的定位，无论在大厂，还是小厂，使自己成为出色的“专业工程师”，更加全面的成长，或许更能让我们的职场利于不败之地。&lt;/p&gt;
</description>
<pubDate>Mon, 25 May 2020 15:08:00 +0000</pubDate>
<dc:creator>溪源More</dc:creator>
<og:description>一 在博客园中使用小公司大公司进行搜索，列入的搜索记录长达50页。虽然完全命中关键词的文章也许并不多，但这或许也能体现出这个话题的热门程度。 今天我的公众号好友中也有人问了我这个问题： 在小公司里面做</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/xiyuanMore/p/12961596.html</dc:identifier>
</item>
<item>
<title>【Elasticsearch学习】DSL搜索大全（持续更新中） - xiaohuoshan</title>
<link>http://www.cnblogs.com/sirhuoshan/p/12961351.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/sirhuoshan/p/12961351.html</guid>
<description>&lt;p&gt;&lt;span&gt;&lt;strong&gt;1.复合查询&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;　　&lt;/strong&gt;复合查询能够组合其他复合查询或者查询子句，同时也可以组合各个查询的查询结果及得分，也可以从Query查询转换为Filter过滤器查询。&lt;/p&gt;
&lt;p&gt;　　首先介绍一下Query Context和 Filter Context&lt;/p&gt;
&lt;p&gt;　　1）Query Context查询主要关注的是文档和查询条件的匹配度，Query查询会计算文档和查询条件的相关度评分。&lt;/p&gt;
&lt;p&gt;　　2）Filter Context过滤器主要关注文档是否匹配查询条件，并不关系文档和查询条件的匹配程度，也不会计算文档的相关度评分。过滤器查询速度比普通查询快，经常使用的过滤器将被ES自动缓存。&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;38&quot;&gt;
&lt;pre class=&quot;brush:java;gutter:true;&quot;&gt;
GET /kibana_sample_data_ecommerce/_search
{
  &quot;query&quot;: { //query context
    &quot;bool&quot;: { 
      &quot;must&quot;: [
        { &quot;match&quot;: { &quot;customer_first_name&quot;: &quot;Eddie&quot;}},
        { &quot;match&quot;: { &quot;customer_gender&quot;: &quot;MALE&quot; }}
      ],
      &quot;filter&quot;: [  // filter context
        { &quot;term&quot;:  { &quot;currency&quot;: &quot;EUR&quot; }},
        { &quot;range&quot;: { &quot;order_id&quot;: { &quot;gte&quot;: &quot;584679&quot; }}}
      ]
    }
  }
}
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;1.1.Boolean Query&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;　　Bool查询由一个或多个bool查询子句组成，允许组合任意数量的查询子句，bool查询共有4钟查询类型。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;　　1）must&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;　　如果查询子句为must，那么must子句中的所有查询条件都必须在匹配文档中出现。&lt;/p&gt;
&lt;p&gt;　&lt;strong&gt;　2）must_not&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;　　查询条件中的任何一部分不能在文档中出现。&lt;/p&gt;
&lt;p&gt;　　&lt;strong&gt;3）should&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;　　查询条件可以在匹配文档中出现也可以不出现，但是出现的数量至少要达到minimum_should_match参数所设置的数量，如果组合中使用了must子句，该值默认为0，如果没有使用该值默认为1.&lt;/p&gt;
&lt;p&gt;　　&lt;strong&gt;4）&lt;/strong&gt;filter&lt;/p&gt;
&lt;p&gt;　　查询条件必须出现在匹配的文档中，但是该查询子句对于文档的评分没有影响，仅对文档进行过滤。&lt;/p&gt;
&lt;p&gt;　　http://127.0.0.1:9200/kibana_sample_data_ecommerce/_search&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;34&quot;&gt;
&lt;pre class=&quot;brush:java;gutter:true;&quot;&gt;
{
  &quot;query&quot;: {
    &quot;bool&quot; : {
      &quot;must&quot; : [
        {
        　　&quot;term&quot; : { &quot;day_of_week&quot;: &quot;Monday&quot; }
        },
        {
        　　&quot;term&quot; : {&quot;customer_gender&quot;: &quot;FEMALE&quot;}
        }
      ]
    }
  }
}
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;1.2Boosting Query&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;　　Boosting Query返回和positive查询条件匹配的文档，减少与negative查询条件匹配的文档的分数。注意，只有匹配了positive查询条件的文档才会被返回，negative只是降低同时匹配positive条件和negative查询条件的文档的相关性评分。&lt;span class=&quot;term&quot;&gt;&lt;code class=&quot;literal&quot;&gt;negative_boost为介于0和1.0之间的浮点数，用于降低与negative查询条件匹配的文档相关性评分。&lt;/code&gt;&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;36&quot;&gt;
&lt;pre class=&quot;brush:java;gutter:true;&quot;&gt;
GET /kibana_sample_data_ecommerce/_search
{
    &quot;query&quot;: {
        &quot;boosting&quot; : {
            &quot;positive&quot; : {
                &quot;match&quot;: {
                    &quot;customer_first_name&quot; : &quot;Eddie&quot;
                }
            },
            &quot;negative&quot; : {
                  &quot;match&quot; : {
                    &quot;customer_last_name&quot; : &quot;Underwood&quot;
                }
            },
            &quot;negative_boost&quot; : 0.5
        }
    }
}
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;1.3Constant Score Query&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;　　&lt;/strong&gt;包装filter查询，返回所有匹配的文档，但是文档的相关度评分等于查询传入的boost值，默认值为1.0。&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;34&quot;&gt;
&lt;pre class=&quot;brush:java;gutter:true;&quot;&gt;
GET /kibana_sample_data_ecommerce/_search
{
    &quot;query&quot;: {
        &quot;constant_score&quot; : {
            &quot;filter&quot; : {
                &quot;match&quot; : { &quot;customer_first_name&quot; : &quot;Eddie&quot;}
            },
            &quot;boost&quot; : 1.2
        }
    }
}
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;1.4Disjunction Max Query&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;　　将与任何一个查询条件匹配的文档作为结果返回，但是采用单个字段上最匹配的评分作为最终评分返回。&lt;/p&gt;
&lt;p&gt;首先看一个不使用dis_max查询多查询字段匹配的例子，&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;34&quot;&gt;
&lt;pre&gt;
GET /test/&lt;span&gt;_search
{
    &lt;/span&gt;&quot;query&quot;&lt;span&gt;: {
        &lt;/span&gt;&quot;bool&quot;&lt;span&gt;: {
            &lt;/span&gt;&quot;should&quot;&lt;span&gt;: [
                { &lt;/span&gt;&quot;match&quot;: { &quot;title&quot;: &quot;Brown fox&quot;&lt;span&gt; }},
                { &lt;/span&gt;&quot;match&quot;: { &quot;body&quot;:  &quot;Brown fox&quot;&lt;span&gt; }}
            ]
        }
    }
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;返回：可以看到文档2的body字段更加匹配查询条件&quot;body&quot;: &quot;Brown fox&quot;，但是由于文档1的title字段和body字段都有&quot;brown&quot;所以其评分叠加起来比文档2的评分更高。&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;47&quot;&gt;
&lt;pre class=&quot;brush:java;gutter:true;&quot;&gt;
{
  &quot;hits&quot; : {
    &quot;max_score&quot; : 0.90425634,
    &quot;hits&quot; : [
      {
        &quot;_index&quot; : &quot;test&quot;,
        &quot;_type&quot; : &quot;_doc&quot;,
        &quot;_id&quot; : &quot;1&quot;,
        &quot;_score&quot; : 0.90425634,
        &quot;_source&quot; : {
          &quot;title&quot; : &quot;Quick brown rabbits&quot;,
          &quot;body&quot; : &quot;Brown rabbits are commonly seen.&quot;
        }
      },
      {
        &quot;_index&quot; : &quot;test&quot;,
        &quot;_type&quot; : &quot;_doc&quot;,
        &quot;_id&quot; : &quot;2&quot;,
        &quot;_score&quot; : 0.77041256,
        &quot;_source&quot; : {
          &quot;title&quot; : &quot;Keeping pets healthy&quot;,
          &quot;body&quot; : &quot;My quick brown fox eats rabbits on a regular basis.&quot;
        }
      }
    ]
  }
}
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　dis_max不会将查询条件各个字段评分做简单的相加，而是将与查询条件匹配得分最高的单个字段的评分作为文档的评分返回。如下例：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;34&quot;&gt;
&lt;pre&gt;
GET /test/&lt;span&gt;_search
{
    &lt;/span&gt;&quot;query&quot;&lt;span&gt;: {
        &lt;/span&gt;&quot;dis_max&quot;&lt;span&gt;: {
            &lt;/span&gt;&quot;queries&quot;&lt;span&gt;: [
                { &lt;/span&gt;&quot;match&quot;: { &quot;title&quot;: &quot;Brown fox&quot;&lt;span&gt; }},
                { &lt;/span&gt;&quot;match&quot;: { &quot;body&quot;:  &quot;Brown fox&quot;&lt;span&gt; }}
            ]
        }
    }
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;返回：可以看到使用dis_max后文档1的评分降低了。&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;47&quot;&gt;
&lt;pre class=&quot;brush:java;gutter:true;&quot;&gt;
{  &lt;br/&gt;　　&quot;hits&quot; : {
    &quot;max_score&quot; : 0.77041256,
    &quot;hits&quot; : [
      {
        &quot;_index&quot; : &quot;test&quot;,
        &quot;_type&quot; : &quot;_doc&quot;,
        &quot;_id&quot; : &quot;2&quot;,
        &quot;_score&quot; : 0.77041256,
        &quot;_source&quot; : {
          &quot;title&quot; : &quot;Keeping pets healthy&quot;,
          &quot;body&quot; : &quot;My quick brown fox eats rabbits on a regular basis.&quot;
        }
      },
      {
        &quot;_index&quot; : &quot;test&quot;,
        &quot;_type&quot; : &quot;_doc&quot;,
        &quot;_id&quot; : &quot;1&quot;,
        &quot;_score&quot; : 0.6931471,
        &quot;_source&quot; : {
          &quot;title&quot; : &quot;Quick brown rabbits&quot;,
          &quot;body&quot; : &quot;Brown rabbits are commonly seen.&quot;
        }
      }
    ]
  }
}
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　dis_max查询的tie_breaker参数，如果在查询的时候根据查询场景需要考虑到其他查询字段的得分，则可以使用tie_breaker参数[0.0,1.0]，使用tie_beaker之后，计算得分的过程将变为：&lt;/p&gt;
&lt;p&gt;　　1.取到与查询条件最匹配的单个字段的评分，2.将与其他查询条件匹配的得分乘以tie_beaker，3.将1中最高分和2中的得分相加作为文档的评分返回。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;1.5Function Score Query&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;　　&lt;/strong&gt;function score query可以在查询结束后，对每一个匹配的文档重新算分，根据新生成的分数进行排序。　　&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;45&quot;&gt;
&lt;pre class=&quot;brush:java;gutter:true;&quot;&gt;
GET /_search
{
    &quot;query&quot;: {
        &quot;function_score&quot;: {
          &quot;query&quot;: { &quot;match_all&quot;: {} },
          &quot;boost&quot;: &quot;5&quot;, 
          &quot;functions&quot;: [
              {
                  &quot;filter&quot;: { &quot;match&quot;: { &quot;test&quot;: &quot;bar&quot; } },
                  &quot;random_score&quot;: {}, 
                  &quot;weight&quot;: 23
              },
              {
                  &quot;filter&quot;: { &quot;match&quot;: { &quot;test&quot;: &quot;cat&quot; } },
                  &quot;weight&quot;: 42
              }
          ],
          &quot;max_boost&quot;: 42,
          &quot;score_mode&quot;: &quot;max&quot;,
          &quot;boost_mode&quot;: &quot;multiply&quot;,
          &quot;min_score&quot; : 42
        }
    }
}
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　  &lt;strong&gt;score_mode&lt;/strong&gt;：每一个文档将会被定义的函数打分，当有多个函数时由score_mode决定如何去组合各个函数的打分，score_mode的几个方法：multiply，各个得分相乘；sum，分数相加；avg，分数取平均；first，用第一个有match filter的函数的评分；max，选取分数的最大值；min，选取分数的最小值。&lt;/p&gt;
&lt;p&gt;　 &lt;strong&gt;weight&lt;/strong&gt;：因为各个函数的打分范围不同，例如衰减函数打分范围为[0,1]，而field_value_factor的打分值是任意的，而且有时候希望不同的函数对文档的分数有不同的影响，用户可以使用weight权重来调整各个函数的得分，在每个function中定义weight的数值，函数计算出文档的得分后将会和其定义的weight值。&lt;/p&gt;
&lt;p&gt;　 &lt;strong&gt;max_score&lt;/strong&gt;：用于限制得分，function算出的新得分会被限制在max_boost内，默认为FLT_MAX。&lt;/p&gt;
&lt;p&gt;　 &lt;strong&gt;boost_mode&lt;/strong&gt;：决定function算出的分和query的得分如何组合：multiply，function和query得分相乘；replace，使用function的得分替换query的得分；sum，两者得分相加；avg，取两者均值；max，取两者较大值；min，取两者较小值。　&lt;/p&gt;
&lt;p&gt;　&lt;strong&gt;min_score&lt;/strong&gt;：用于排除分值低于阈值的文档。&lt;/p&gt;
&lt;p&gt;　function score支持的几种改变分值的函数：&lt;/p&gt;
&lt;p&gt;　　&lt;strong&gt;1）script_score&lt;/strong&gt;：包装一个子查询，通过自定义脚本的方式完全自定义计算文档的得分。&lt;/p&gt;
&lt;p&gt;　　&lt;strong&gt;2）Weight&lt;/strong&gt;：为每个文档设置一个权重，将文档的得分乘以该权重，该参数和boost类似，boost对文档得分的提升不是线性的，文档得分在乘以boost值后会被归一化（nomalize）处理，所以当不想将得分归一化处理时即可使用Weight来提升文档的得分。&lt;/p&gt;
&lt;p&gt;　　&lt;strong&gt;3）random_score&lt;/strong&gt;：随机均匀的产生在[0,1)之间的得分，可以为该函数提供种子(seed)和计算得分的字段(filed)，这样来保证分数的可复制性。最后的得分将基于seed、filed以及salt（salt由索引名和分片id计算得来），所以有相同的值但是存储在不同索引中的文档会有不同的评分。但是在同一个分片中并具有相同字段值的文档将获得相同的分数，因此通常需要使用具有唯一值的字段来进行评分。&lt;/p&gt;
&lt;p&gt;　　&lt;strong&gt;4）field_value_factor&lt;/strong&gt;：可以使用文档中的字段来影响文档的得分&lt;/p&gt;
&lt;p&gt;　　　　参数：field，用来计算得分的字段；factor，得分的乘数；modifier，得分的计算公式，可以为&lt;code class=&quot;literal&quot;&gt;none(默认值)&lt;/code&gt;, &lt;code class=&quot;literal&quot;&gt;log&lt;/code&gt;, &lt;code class=&quot;literal&quot;&gt;log1p&lt;/code&gt;, &lt;code class=&quot;literal&quot;&gt;log2p&lt;/code&gt;, &lt;code class=&quot;literal&quot;&gt;ln&lt;/code&gt;, &lt;code class=&quot;literal&quot;&gt;ln1p&lt;/code&gt;, &lt;code class=&quot;literal&quot;&gt;ln2p&lt;/code&gt;, &lt;code class=&quot;literal&quot;&gt;square&lt;/code&gt;, &lt;code class=&quot;literal&quot;&gt;sqrt&lt;/code&gt;, &lt;code class=&quot;literal&quot;&gt;reciprocal；missing，如果指定的filed字段文档中没有，默认使用的值。如下计算公式为：&lt;/code&gt;&lt;code class=&quot;literal&quot;&gt;sqrt(1.2 * doc['likes'].value)&lt;/code&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;36&quot;&gt;
&lt;pre class=&quot;programlisting prettyprint lang-console prettyprinted&quot;&gt;
&lt;span class=&quot;str&quot;&gt;&quot;query&quot;&lt;span class=&quot;pun&quot;&gt;:&lt;span class=&quot;pln&quot;&gt; &lt;span class=&quot;pun&quot;&gt;{&lt;span class=&quot;pln&quot;&gt;
        &lt;span class=&quot;str&quot;&gt;&quot;function_score&quot;&lt;span class=&quot;pun&quot;&gt;:&lt;span class=&quot;pln&quot;&gt; &lt;span class=&quot;pun&quot;&gt;{&lt;span class=&quot;pln&quot;&gt;
            &lt;span class=&quot;str&quot;&gt;&quot;field_value_factor&quot;&lt;span class=&quot;pun&quot;&gt;:&lt;span class=&quot;pln&quot;&gt; &lt;span class=&quot;pun&quot;&gt;{&lt;span class=&quot;pln&quot;&gt;
                &lt;span class=&quot;str&quot;&gt;&quot;field&quot;&lt;span class=&quot;pun&quot;&gt;:&lt;span class=&quot;pln&quot;&gt; &lt;span class=&quot;str&quot;&gt;&quot;likes&quot;&lt;span class=&quot;pun&quot;&gt;,&lt;span class=&quot;pln&quot;&gt;
                &lt;span class=&quot;str&quot;&gt;&quot;factor&quot;&lt;span class=&quot;pun&quot;&gt;:&lt;span class=&quot;pln&quot;&gt; &lt;span class=&quot;lit&quot;&gt;1.2&lt;span class=&quot;pun&quot;&gt;,&lt;span class=&quot;pln&quot;&gt;
                &lt;span class=&quot;str&quot;&gt;&quot;modifier&quot;&lt;span class=&quot;pun&quot;&gt;:&lt;span class=&quot;pln&quot;&gt; &lt;span class=&quot;str&quot;&gt;&quot;sqrt&quot;&lt;span class=&quot;pun&quot;&gt;,&lt;span class=&quot;pln&quot;&gt;
                &lt;span class=&quot;str&quot;&gt;&quot;missing&quot;&lt;span class=&quot;pun&quot;&gt;:&lt;span class=&quot;pln&quot;&gt; &lt;span class=&quot;lit&quot;&gt;1&lt;span class=&quot;pln&quot;&gt;
            &lt;span class=&quot;pun&quot;&gt;}&lt;span class=&quot;pln&quot;&gt;
        &lt;span class=&quot;pun&quot;&gt;}&lt;span class=&quot;pln&quot;&gt;
    &lt;span class=&quot;pun&quot;&gt;}&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　&lt;strong&gt;5）Decay functions&lt;/strong&gt;：衰减函数，用户指定一个文档中的字段的值，衰减函数根据距离这个值的距离来进行打分；查询时需要为每个字段定义origin值和scale值，&lt;/p&gt;
&lt;p&gt;　　　　origin代表的是中心点，用以计算其他值到中心点的距离；&lt;br/&gt;　　　　scale代表衰减的范围，衰减的范围为[origin-offset-scale，origin-offset]，[origin+offset，origin+offset+scale]&lt;/p&gt;
&lt;p&gt;　　　　此外有两个可选值：offset、decay   &lt;/p&gt;
&lt;p&gt;　　　　offset表示衰减函数只计算到中心点距离大于offset的文档，即衰减函数计算的范围是[origin-offset-scale，origin-offset]，[origin+offset，origin+offset+scale]；&lt;/p&gt;
&lt;p&gt;　　　　decay表示衰减到两个边界上时origin-offset-scale，origin+offset+scale文档的得分，默认为0.5分。如图：&lt;/p&gt;
&lt;p&gt;　　　　&lt;img src=&quot;https://img2020.cnblogs.com/blog/476944/202005/476944-20200517215505229-1896199905.png&quot; alt=&quot;&quot;/&gt; &lt;/p&gt;
&lt;p&gt;　　　　举例说明各参数的作用：假设衰减函数的origin定义为100，scale定义为10，offset定义为10，decay为0.5，那么衰减函数只会计算文档[80，90]，[110，120]，即介于90与110之间的文档评分与origin得分一样，在[80，90]，[110，120]之间文档得分将会进行衰减，在80，120&lt;code&gt;边界上的文档得分是&lt;/code&gt;&lt;code&gt;decay：0.5。&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;如下例所示：&lt;code class=&quot;literal&quot;&gt;DECAY_FUNCTION可以是&lt;/code&gt;&lt;code class=&quot;literal&quot;&gt;linear（线性）、&lt;/code&gt;&lt;code class=&quot;literal&quot;&gt;exp（指数）、&lt;/code&gt;&lt;code class=&quot;literal&quot;&gt;gauss（高斯）这三种衰减函数，FILED_NAME即用来评分的字段必须为数值型、日期型或地理位置型。&lt;/code&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;37&quot;&gt;
&lt;pre&gt;
&quot;DECAY_FUNCTION&quot;&lt;span&gt;: { 
    &lt;/span&gt;&quot;FIELD_NAME&quot;&lt;span&gt;: { 
          &lt;/span&gt;&quot;origin&quot;: &quot;11, 12&quot;&lt;span&gt;,
          &lt;/span&gt;&quot;scale&quot;: &quot;2km&quot;&lt;span&gt;,
          &lt;/span&gt;&quot;offset&quot;: &quot;0km&quot;&lt;span&gt;,
          &lt;/span&gt;&quot;decay&quot;: 0.33&lt;span&gt;
    }
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;日期型衰减函数：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;36&quot;&gt;
&lt;pre&gt;
&quot;function_score&quot;&lt;span&gt;: {
            &lt;/span&gt;&quot;gauss&quot;&lt;span&gt;: {
                &lt;/span&gt;&quot;date&quot;&lt;span&gt;: {
                      &lt;/span&gt;&quot;origin&quot;: &quot;2013-09-17&quot;&lt;span&gt;, 
                      &lt;/span&gt;&quot;scale&quot;: &quot;10d&quot;&lt;span&gt;,
                      &lt;/span&gt;&quot;offset&quot;: &quot;5d&quot;&lt;span&gt;, 
                      &lt;/span&gt;&quot;decay&quot; : 0.5&lt;span&gt; 
                }
            }
        }&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　如果用于计算衰减的字段包含多个值，在默认情况下，将选择最接近原点的值来确定距离，可以通过设置multi_value_mode来改变这个方法：min：衰减距离使用多个字段距离中的最小值，max：衰减距离使用多个字段距离中的最大值，avg：衰减距离使用多个字段距离的平均值，sum衰减距离使用多个字段距离的和。&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;2.全文检索&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　全文检索使用户能够搜索分析过的文本，查询的关键字也会被文档索引时使用的分析器进行处理。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;span&gt;2.1Intervals Query&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;span&gt;　　&lt;/span&gt;&lt;/strong&gt;允许对匹配词项的顺序和邻近性进行细粒度控制。用户可以应用一个或多个规则集合在指定的字段上进行操作。　　&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;40&quot;&gt;
&lt;pre class=&quot;brush:java;gutter:true;&quot;&gt;
POST _search
{
  &quot;query&quot;: {
    &quot;intervals&quot; : {
      &quot;my_text&quot; : {
        &quot;all_of&quot; : {
          &quot;ordered&quot; : true,
          &quot;intervals&quot; : [
            {
              &quot;match&quot; : {
                &quot;query&quot; : &quot;my favorite food&quot;,
                &quot;max_gaps&quot; : 0,
                &quot;ordered&quot; : true
              }
            },
            {
              &quot;any_of&quot; : {
                &quot;intervals&quot; : [
                  { &quot;match&quot; : { &quot;query&quot; : &quot;hot water&quot; } },
                  { &quot;match&quot; : { &quot;query&quot; : &quot;cold porridge&quot; } }
                ]
              }
            }
          ]
        }
      }
    }
  }
}
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　interval查询顶层参数：&lt;/p&gt;
&lt;p&gt;　　Field，用户希望查询的字段，上例为my_text。Field的参数为一个基于词项匹配度、顺序、接近度规则的对象用于匹配文档，上例为{&quot;all_of&quot;:&quot;....&quot;}。&lt;/p&gt;
&lt;p&gt;　　有如下一些规则：&lt;/p&gt;
&lt;p&gt;　　&lt;strong&gt;1）match&lt;/strong&gt;：match规则匹配分析后的文本。参数：&lt;/p&gt;
&lt;p&gt;　　  query：希望在Field字段中匹配的内容。&lt;/p&gt;
&lt;p&gt;　　  max_gaps：匹配的词项之间间隔的最大词数，超过max_gaps的被视为不匹配，默认为-1，如果没有设定，则对词项之间的间隔没有限制；如果设置为0，那么匹配的词项之间必须仅仅相邻。&lt;/p&gt;
&lt;p&gt;　　  ordered：如果为true，那么匹配的词项出现的顺序必须和查询内容的顺序一致，默认为false。&lt;/p&gt;
&lt;p&gt;        analyzer：用于分析查询内容的分析器，默认和文档的分析器一致。&lt;/p&gt;
&lt;p&gt;　　  filter：intervals filter。&lt;/p&gt;
&lt;p&gt;　　  use_field：如果指定该字段，那么此规则将应用于该字段而不是顶层Field字段。　　&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;34&quot;&gt;
&lt;pre&gt;
POST /test/&lt;span&gt;_search
{
  &lt;/span&gt;&quot;query&quot;&lt;span&gt;: {
    &lt;/span&gt;&quot;intervals&quot;&lt;span&gt; : {
      &lt;/span&gt;&quot;body&quot;&lt;span&gt; : {
        &lt;/span&gt;&quot;match&quot;&lt;span&gt; : {
          &lt;/span&gt;&quot;query&quot; : &quot;quick rabbits&quot;&lt;span&gt;,
          &lt;/span&gt;&quot;max_gaps&quot; : 10&lt;span&gt;
        }
      }
    }
  }
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;     &lt;strong&gt;2）prefix&lt;/strong&gt;：前缀规则匹配以指定字符集开头的词项，prefix最多可以扩展到匹配128个字符，如果超过128个字符，ES将返回错误。参数：&lt;/p&gt;
&lt;p&gt;　　 prefix：希望顶层Field开头的字符。&lt;/p&gt;
&lt;p&gt;　　 analyzer：用以处理prefix的分析器。&lt;/p&gt;
&lt;p&gt;　　 use_field：如果指定该字段，那么此规则将应用于该字段而不是顶层Field字段。&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;34&quot;&gt;
&lt;pre&gt;
POST /test/&lt;span&gt;_search
{
  &lt;/span&gt;&quot;query&quot;&lt;span&gt;: {
    &lt;/span&gt;&quot;intervals&quot;&lt;span&gt; : {
      &lt;/span&gt;&quot;body&quot;&lt;span&gt; : {
        &lt;/span&gt;&quot;prefix&quot;&lt;span&gt; : {
          &lt;/span&gt;&quot;prefix&quot; : &quot;Keeping&quot;&lt;span&gt;,
          &lt;/span&gt;&quot;use_field&quot;:&quot;title&quot;&lt;span&gt;
        }
      }
    }
  }
}&lt;/span&gt;　
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　&lt;strong&gt;　3）wildcard：&lt;/strong&gt;wildcard使用通配符模式，最多能匹配128个词项。参数：&lt;/p&gt;
&lt;p&gt;　　pattern：通配符，支持*、？两种通配符。&lt;/p&gt;
&lt;p&gt;　　analyzer：同上。&lt;/p&gt;
&lt;p&gt;　　use_field：同上。&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;33&quot;&gt;
&lt;pre&gt;
POST /test/&lt;span&gt;_search
{
  &lt;/span&gt;&quot;query&quot;&lt;span&gt;: {
    &lt;/span&gt;&quot;intervals&quot;&lt;span&gt; : {
      &lt;/span&gt;&quot;body&quot;&lt;span&gt; : {
        &lt;/span&gt;&quot;wildcard&quot;&lt;span&gt; : {
          &lt;/span&gt;&quot;pattern&quot; : &quot;rab?i*&quot;&lt;span&gt;
        }
      }
    }
  }
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　&lt;strong&gt;　4）fuzzy&lt;/strong&gt;：模糊规则匹配与提供的term相似的词项。参数：&lt;/p&gt;
&lt;p&gt;　　term：需要匹配的词项。&lt;/p&gt;
&lt;p&gt;　　prefix_length：保持不变的前缀的数量。&lt;/p&gt;
&lt;p&gt;　　transpositions：模糊规则是否包含两个相邻字符的转换，默认为true。&lt;/p&gt;
&lt;p&gt;　　fuzziness：通常被解释为莱文斯坦距离也叫做Edit Distance，指的是一个词与另一个词匹配需要编辑的次数，编辑操作替换字符，插入字符，删除字符，需要编辑的次数越多，说明Edit Distance越大。fuzziness的参数：0，1，2表示最大的编辑次数，默认为AUTO参数，表示根据term的长度自动生成编辑次数。&lt;/p&gt;
&lt;p&gt;　　analyzer：同上。&lt;/p&gt;
&lt;p&gt;　　use_field：同上。&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;34&quot;&gt;
&lt;pre&gt;
POST /test/&lt;span&gt;_search
{
  &lt;/span&gt;&quot;query&quot;&lt;span&gt;: {
    &lt;/span&gt;&quot;intervals&quot;&lt;span&gt; : {
      &lt;/span&gt;&quot;body&quot;&lt;span&gt; : {
        &lt;/span&gt;&quot;fuzzy&quot;&lt;span&gt; : {
          &lt;/span&gt;&quot;term&quot; : &quot;rabibst&quot;,&lt;span&gt;//&lt;/span&gt;&lt;span&gt;需要移动两次&lt;/span&gt;
          &quot;fuzziness&quot;:2 &lt;span&gt;//&lt;/span&gt;&lt;span&gt;两次edit&lt;/span&gt;
&lt;span&gt;        }
      }
    }
  }
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　&lt;strong&gt;5）all_of&lt;/strong&gt;：综合其他的interval规则，返回的文档必须满足所有的intervals规则。参数：&lt;/p&gt;
&lt;p&gt;　　intervals：要组合的规则数组。&lt;/p&gt;
&lt;p&gt;　　max_gaps：&lt;/p&gt;
&lt;p&gt;　　ordered：决定各个规则产生的结果是否排序。&lt;/p&gt;
&lt;p&gt;　　filter：intervals filter。&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;35&quot;&gt;
&lt;pre class=&quot;brush:java;gutter:true;&quot;&gt;
POST /test/_search
{
  &quot;query&quot;: {
    &quot;intervals&quot; : {
      &quot;body&quot; : {
        &quot;all_of&quot; : {
          &quot;intervals&quot; : [//match、prefix规则均需满足
            {
              &quot;match&quot; : {
                &quot;query&quot; : &quot;quick&quot;
              }
            },
            {
              &quot;prefix&quot; : {
                &quot;prefix&quot;:&quot;My&quot;
              }
            }
           ]
        }
      }
    }
  }
}
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　&lt;strong&gt;6）any_of&lt;/strong&gt;：满足任一子规则的文档即可返回。&lt;/p&gt;
&lt;p&gt;　　intervals：匹配的规则数组。&lt;/p&gt;
&lt;p&gt;　　filter：intervals filter。&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;35&quot;&gt;
&lt;pre class=&quot;brush:java;gutter:true;&quot;&gt;
POST /test/_search
{
  &quot;query&quot;: {
    &quot;intervals&quot; : {
      &quot;body&quot; : {
        &quot;any_of&quot; : {
          &quot;intervals&quot; : [ //match、prefix规则满足其一即可
            {
              &quot;match&quot; : {
                &quot;query&quot; : &quot;commonly&quot;
              }
            },
            {
              &quot;prefix&quot; : {
                &quot;prefix&quot;:&quot;My&quot;
              }
            }
           ]
        }
      }
    }
  }
}　　
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　&lt;strong&gt;intervals filter参数：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;　　　　&lt;/strong&gt;after：匹配的词项在filter rule后。&lt;/p&gt;
&lt;p&gt;　　　　before：匹配的词项在filter rule前。&lt;/p&gt;
&lt;p&gt;　　　　contained_by：匹配的词项由filter rule包含。&lt;/p&gt;
&lt;p&gt;　　　　not_contained_by：匹配的词项不被filter rule包含。&lt;/p&gt;
&lt;p&gt;　　      not_containing：fiter rule不在匹配间隙之间出现。&lt;/p&gt;
&lt;p&gt;　　　　not_overlapping：匹配的词项和filter rule不重叠。&lt;/p&gt;
&lt;p&gt;　　　　overlapping：匹配的词项和filter rule有重叠。&lt;/p&gt;
&lt;p&gt;　　　　script：决定文档是否返回的自定义脚本。&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;35&quot;&gt;
&lt;pre class=&quot;brush:java;gutter:true;&quot;&gt;
POST /test/_search
{
  &quot;query&quot;: {
    &quot;intervals&quot; : {
      &quot;body&quot; : {
        &quot;match&quot; : {
          &quot;query&quot; : &quot;commonly&quot;,
          &quot;filter&quot;:{
            &quot;contained_by&quot; : {
              &quot;match&quot; : {
                &quot;query&quot; : &quot;Brown seen&quot; //brown seen 必须包含commonly词项
              }
            }
          }
        }
      }
    }
  }
}&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;　　　&lt;/strong&gt;&lt;/strong&gt;&lt;/strong&gt;&lt;/strong&gt;　　
&lt;/pre&gt;&lt;/div&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;36&quot;&gt;
&lt;pre class=&quot;brush:java;gutter:true;&quot;&gt;
POST /test/_search
{
  &quot;query&quot;: {
    &quot;intervals&quot; : {
      &quot;body&quot; : {
        &quot;match&quot; : {
          &quot;query&quot; : &quot;brown rabbits&quot;,
          &quot;max_gaps&quot; : 10,
          &quot;filter&quot;:{
            &quot;not_containing&quot; : {
              &quot;match&quot; : {
                &quot;query&quot; : &quot;fox&quot; //fox 不能出现在brown rabbits 之间
              }
            }
          }
        }
      }
    }
  }
}
&lt;/pre&gt;&lt;/div&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;35&quot;&gt;
&lt;pre class=&quot;brush:java;gutter:true;&quot;&gt;
POST /test/_search
{
  &quot;query&quot;: {
    &quot;intervals&quot; : {
      &quot;body&quot; : {
        &quot;match&quot; : {
          &quot;query&quot; : &quot;commonly&quot;,
          &quot;filter&quot;:{
            &quot;overlapping&quot; : {
              &quot;match&quot; : {
                &quot;query&quot; : &quot;Brown seen&quot; //match规则查出的结果文档为Brown rabbits are commonly seen 与commonly 有重叠的地方
              }
            }
          }
        }
      }
    }
  }
}
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;2.2Match Query&lt;/strong&gt;　　&lt;/p&gt;
&lt;p&gt;　　返回与提供的搜索文本相匹配的文档，搜索文本在匹配之前会被分析器进行分析。&lt;/p&gt;
&lt;p&gt;　　参数：&lt;/p&gt;
&lt;p&gt;　　顶层参数：Filed,表示想要搜索的字段。&lt;/p&gt;
&lt;p&gt;　　Field下的参数：&lt;/p&gt;
&lt;p&gt;　　&lt;strong&gt;1.query：&lt;/strong&gt;想要在Field字段中匹配到的内容，match查询在查询之前会对查询内容进行分析。&lt;/p&gt;
&lt;p&gt;　　&lt;strong&gt;2.analyzer：&lt;/strong&gt;分析器，如果field的mapping中有定义分析器，则使用field的分析器，如果没有，则使用索引默认的分析器。&lt;/p&gt;
&lt;p&gt;　　&lt;strong&gt;3.auto_generate_synonyms_phrase_query：&lt;/strong&gt;是否开启同义词匹配，默认为false。&lt;/p&gt;
&lt;p&gt;　　&lt;strong&gt;4.fuzziness：&lt;/strong&gt;模糊匹配，参数见interval query fuzzy。&lt;br/&gt;　　&lt;strong&gt;5.max_expansions：&lt;/strong&gt;控制模糊匹配fuzzy能扩展多少个模糊选项。如test在fuzziness为1的时候，能匹配很多模糊选项：tes，tets，etst等，使用max_expansions控制能匹配多少个模糊选项。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;　　6.prefix_length：&lt;/strong&gt;fuzzy匹配时，保持不变的字符前缀数，默认为0。&lt;/p&gt;
&lt;p&gt;　　&lt;strong&gt;7.transpositions：&lt;/strong&gt;如果true，那么fuzzy匹配允许字符交换位置，ab-&amp;gt;ba。&lt;br/&gt;　　&lt;strong&gt;8.fuzzy_rewrite：&lt;/strong&gt;重写查询的方法，&lt;/p&gt;
&lt;p&gt;　　&lt;strong&gt;9.lenient：&lt;/strong&gt;如果true，则忽略查询格式错误，例如为数值字段提供文本查询值。默认为false。&lt;/p&gt;
&lt;p&gt;　　&lt;strong&gt;10.operator：&lt;/strong&gt;用于解析查询值的bool逻辑。默认为OR，如果Query值为quick brown fox，则匹配规则为quick or brown or fox；此外还有AND值。&lt;/p&gt;
&lt;p&gt;　　&lt;strong&gt;11.minimum_should_match：&lt;/strong&gt;返回的文档必须匹配的子句数量。&lt;/p&gt;
&lt;p&gt;　&lt;strong&gt;　12.zero_terms_query：&lt;/strong&gt;决定当分析器移除所有的分词时是否返回文档，如当查询内容中都是停用词时，所有的分词被分析器的停用词过滤器过滤掉时，是否返回文档。默认为none，不返回任何文档，all，返回所有文档。　　&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;36&quot;&gt;
&lt;pre&gt;
&lt;span&gt;测试数据：
POST &lt;/span&gt;/test/_doc/3&lt;span&gt;
{
    &lt;/span&gt;&quot;title&quot;: &quot;tets healthy&quot;&lt;span&gt;,
    &lt;/span&gt;&quot;body&quot;:  &quot;My quick brown fox eats rabbits on a regular basis.&quot;&lt;span&gt;
}
POST &lt;/span&gt;/test/_doc/4&lt;span&gt;
{
    &lt;/span&gt;&quot;title&quot;: &quot;tes healthy&quot;&lt;span&gt;,
    &lt;/span&gt;&quot;body&quot;:  &quot;My quick brown fox eats rabbits on a regular basis.&quot;&lt;span&gt;
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;测试案例：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;35&quot;&gt;
&lt;pre&gt;
&lt;span&gt;POST /test/_search
{
    &lt;/span&gt;&quot;query&quot;&lt;span&gt;: {
        &lt;/span&gt;&quot;match&quot;&lt;span&gt; : {
            &lt;/span&gt;&quot;title&quot;&lt;span&gt;:{
              &lt;/span&gt;&quot;query&quot;:&quot;test&quot;&lt;span&gt;,
              &lt;/span&gt;&quot;fuzziness&quot;:1&lt;span&gt;,
              &lt;/span&gt;&quot;max_expansions&quot;: 1 //最大扩展数，test只允许有一个模糊选项，匹配的结果只有一个&lt;span&gt;
            }
        }
    }
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;2.3Match boolean prefix query&lt;/strong&gt;　　　　&lt;/p&gt;

&lt;p&gt; 　　match_bool_prefix分析查询内容，并将分词出来的各个词项组合成为一个bool查询，除了最后一个词项其他的词项都会被用在term query中，最后一个词项被用在prefix query中。&lt;/p&gt;
&lt;p&gt;例如：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;32&quot;&gt;
&lt;pre&gt;
&lt;span&gt;POST /test/_search
{
    &lt;/span&gt;&quot;query&quot;&lt;span&gt;: {
        &lt;/span&gt;&quot;match_bool_prefix&quot;&lt;span&gt; : {
            &lt;/span&gt;&quot;message&quot; : &quot;quick brown f&quot;&lt;span&gt;
        }
    }
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;这个查询类似于：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;35&quot;&gt;
&lt;pre&gt;
&lt;span&gt;POST /test/_search
{
    &lt;/span&gt;&quot;query&quot;&lt;span&gt;: {
        &lt;/span&gt;&quot;bool&quot;&lt;span&gt; : {
            &lt;/span&gt;&quot;should&quot;&lt;span&gt;: [
                { &lt;/span&gt;&quot;term&quot;: { &quot;message&quot;: &quot;quick&quot;&lt;span&gt; }},
                { &lt;/span&gt;&quot;term&quot;: { &quot;message&quot;: &quot;brown&quot;&lt;span&gt; }},
                { &lt;/span&gt;&quot;prefix&quot;: { &quot;message&quot;: &quot;f&quot;&lt;span&gt;}}
            ]
        }
    }
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　参数：&lt;/p&gt;
&lt;p&gt;　　顶层参数：Filed,表示想要搜索的字段。&lt;/p&gt;
&lt;p&gt;　　&lt;strong&gt;1.query：&lt;/strong&gt;想要在Field字段中匹配到的内容。&lt;/p&gt;
&lt;p&gt;　　&lt;strong&gt;2.analyzer：&lt;/strong&gt;分析器，默认使用字段mapping中的分析器。&lt;/p&gt;
&lt;p&gt;　　&lt;strong&gt;3.minimum_should_match：&lt;/strong&gt;返回的文档最少匹配查询条件的程度。&lt;/p&gt;

&lt;p&gt;　　&lt;strong&gt;4.operator：&lt;/strong&gt;使用AND还是OR去连接词项。&lt;/p&gt;
&lt;p&gt;　　5.模糊查询可以用于所有的分词起器分析出的词项，除了最后一个词项。&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;35&quot;&gt;
&lt;pre&gt;
POST /test/&lt;span&gt;_search
{
    &lt;/span&gt;&quot;query&quot;&lt;span&gt;: {
        &lt;/span&gt;&quot;match_bool_prefix&quot;&lt;span&gt; : {
            &lt;/span&gt;&quot;body&quot;&lt;span&gt;: {
                &lt;/span&gt;&quot;query&quot;: &quot;fox eats&quot;&lt;span&gt;,
                &lt;/span&gt;&quot;operator&quot;:&quot;AND&quot;&lt;span&gt;,
                &lt;/span&gt;&quot;fuzziness&quot;:1&lt;span&gt;
            }
        }
    }
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;2.4Match phrase query&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;　　match_phrase查询分析搜索内容并创建一个短语查询。&lt;/p&gt;
&lt;p&gt;　　match_phrase的词项之间的间隔为0，analyzer使用查询字段mapping字段定义，如果未定义则使用默认查询分析器。&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;34&quot;&gt;
&lt;pre class=&quot;brush:java;gutter:true;&quot;&gt;
GET /test/_search
{
    &quot;query&quot;: {
        &quot;match_phrase&quot; : {
            &quot;body&quot;: {
                &quot;query&quot;: &quot;quick brown fox&quot;,&lt;br/&gt;　　　　　　　　　 &quot;analyzer&quot;:&quot;whitespace&quot;
            }
        }
    }
}
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;2.5Match phrase prefix query&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;　　返回包含搜索内容的文档，与搜索内容提供的顺序一致。搜索内容的最后一个词项作为前缀匹配任何以前缀开始的词项。&lt;/p&gt;
&lt;p&gt;　　参数：&lt;/p&gt;
&lt;p&gt;　　顶层参数：Filed,表示想要搜索的字段。&lt;/p&gt;
&lt;p&gt;　　query：想要搜索的文本。&lt;/p&gt;
&lt;p&gt;　　analyzer：分析器。&lt;/p&gt;
&lt;p&gt;　　max_expansions：最后一个查询词作为前缀去匹配到的词项最多扩展数。&lt;/p&gt;
&lt;p&gt;　　slop：分词之间的最大间隔数，默认为0。&lt;/p&gt;
&lt;p&gt;　　zero_terms_query：见Match Query。&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;34&quot;&gt;
&lt;pre&gt;
GET /test/&lt;span&gt;_search
{
    &lt;/span&gt;&quot;query&quot;&lt;span&gt;: {
        &lt;/span&gt;&quot;match_phrase_prefix&quot;&lt;span&gt; : {
            &lt;/span&gt;&quot;body&quot;&lt;span&gt; : {
                &lt;/span&gt;&quot;query&quot; : &quot;quick brown f&quot;&lt;span&gt;,
                &lt;/span&gt;&quot;max_expansions&quot;: 2 //为2代表以f开头的词项只会返回两种&lt;span&gt;
            }
        }
    }
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;2.6Multi match query&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;　　&lt;/strong&gt;multi match query以match query为基础，构建多字段的match查询。&lt;/p&gt;
&lt;p&gt;　　参数：&lt;/p&gt;
&lt;p&gt;　　&lt;strong&gt;1.query：&lt;/strong&gt;查询文本。&lt;/p&gt;
&lt;p&gt;　　&lt;strong&gt;2.fields：&lt;/strong&gt;查询字段，支持多个字段，最多查询字段数由indices.query.bool.max_clause_count定义，默认为1024个。&lt;/p&gt;
&lt;p&gt;　　&lt;strong&gt;3.type：&lt;/strong&gt;查询的类型。&lt;/p&gt;
&lt;p&gt;　　　　best_fields：查找匹配任意field的文档，但是文档的得分来自最匹配的那个字段。&lt;/p&gt;
&lt;p&gt;　　　　most_fields：组合所有字段的得分，作为文档的评分。&lt;/p&gt;
&lt;p&gt;　　　　cross_fields：将多个字段组合成一个字段，在组合成的字段里去查询。&lt;/p&gt;
&lt;p&gt;　　　　phrase：每个字段以match_phrase方式查询，使用最匹配字段的得分作为文档的评分。&lt;/p&gt;
&lt;p&gt;　　　　phrase_prefix：每个字段以match_phrase_prefix方式查询，，使用最匹配字段的得分作为文档的评分。&lt;/p&gt;
&lt;p&gt;　　　　bool_prefix：每个字段以match_bool_prefix方式查询，组合所有字段的得分作为文档的评分。&lt;/p&gt;
&lt;p&gt;　&lt;strong&gt;　4.tie_breaker：&lt;/strong&gt;当使用tie_breaker时，best_field会根据tie_breaker定义的值的大小，决定除最佳匹配字段得分以外其他字段的得分。为tie_breaker * （其他字段_score）之和。&lt;/p&gt;
&lt;p&gt; &lt;strong&gt;　  5.其他参数：&lt;/strong&gt;analyzer, boost, operator, minimum_should_match, fuzziness, lenient, prefix_length, max_expansions, rewrite, zero_terms_query, cutoff_frequency, auto_generate_synonyms_phrase_query and fuzzy_transpositions。&lt;/p&gt;

&lt;div class=&quot;cnblogs_code&quot; readability=&quot;37&quot;&gt;
&lt;pre&gt;
GET /test/&lt;span&gt;_search
{
  &lt;/span&gt;&quot;explain&quot;: &lt;span&gt;true&lt;/span&gt;&lt;span&gt;, 
  &lt;/span&gt;&quot;query&quot;&lt;span&gt;: {
    &lt;/span&gt;&quot;multi_match&quot;&lt;span&gt; : {
      &lt;/span&gt;&quot;query&quot;:      &quot;brown fox&quot;&lt;span&gt;,
      &lt;/span&gt;&quot;type&quot;:       &quot;best_fields&quot;&lt;span&gt;,
      &lt;/span&gt;&quot;fields&quot;:     [ &quot;title&quot;, &quot;body&quot;&lt;span&gt; ]
    }
  }
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;41&quot;&gt;
&lt;pre&gt;
GET /&lt;span&gt;_search
{
  &lt;/span&gt;&quot;query&quot;&lt;span&gt;: {
    &lt;/span&gt;&quot;multi_match&quot;&lt;span&gt; : {
      &lt;/span&gt;&quot;query&quot;:      &quot;Will Smith&quot;&lt;span&gt;,
      &lt;/span&gt;&quot;type&quot;:       &quot;cross_fields&quot;&lt;span&gt;,
      &lt;/span&gt;&quot;fields&quot;:     [ &quot;first_name&quot;, &quot;last_name&quot;&lt;span&gt; ],
      &lt;/span&gt;&quot;operator&quot;:   &quot;and&quot;&lt;span&gt;
    }
  }
}&lt;p&gt;这个查询类似与：&lt;br/&gt;&lt;/p&gt;&lt;/span&gt;
&lt;/pre&gt;
&lt;pre class=&quot;literallayout&quot;&gt;
(+first_name:will +first_name:smith) | (+last_name:will  +last_name:smith)&lt;br/&gt;所有的搜索词项都必须在单独的字段（也可以是多个字段组合成的单个字段，如first_name+last_name）中出现。
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt; &lt;strong&gt;2.6Common Terms Query&lt;br/&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;　　&lt;/strong&gt;使用语法基于操作符如：AND OR来解析和分割查询字符串，然后用分析器对分割的部分就行分析，并与文档进行匹配。&lt;/p&gt;
&lt;p&gt;　　参数：&lt;/p&gt;
&lt;p&gt;　　&lt;strong&gt;1.query：&lt;/strong&gt;查询字符串。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;　　2.default_field：&lt;/strong&gt;当query_string没有指定查询字段时候，默认查询的字段。默认值为索引设定的&lt;code class=&quot;literal&quot;&gt;index.query.default_field值，&lt;code class=&quot;literal&quot;&gt;index.query.default_field默认值为*。&lt;/code&gt;&lt;/code&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;　　3.allow_leading_wildcard：&lt;/strong&gt;true的时候，通配符*，？可以被作为查询字符串的首个字符。默认为true。&lt;/p&gt;
&lt;p&gt;　　4.analyze_wildcard：true的时候，查询会分析查询字符串中的通配符。&lt;/p&gt;
&lt;p&gt;　　5.analyzer：用于分析查询字符串的分析器，默认为文档索引时候的分析器。&lt;/p&gt;
&lt;p&gt;　　6.auto_generate_synonyms_phrase_query：true的时候，自动创建多同义词查询。&lt;/p&gt;
&lt;p&gt;　　7.boost：浮点数用于增加或减少查询的相关度评分。&lt;/p&gt;
&lt;p&gt;　　8.default_operator：如果没有定义operator，默认被用作解析查询字符串的操作符。OR（默认）&lt;/p&gt;
&lt;p&gt;　　9.enable_position_increments：&lt;/p&gt;
&lt;p&gt;　　10.fields：希望查询的字段的集合。&lt;/p&gt;
&lt;p&gt;　　11.模糊匹配相关：fuzziness，fuzzy_max_expansions模糊匹配最大扩展数，fuzzy_prefix_length模糊匹配前缀数，fuzzy_transpositions，lenient。&lt;/p&gt;
&lt;p&gt;　　12.max_determinized_states：确定一个查询需要的最大的自动机的数量。解释：&lt;a href=&quot;https://www.jianshu.com/p/9edca9474663?utm_source=desktop&amp;amp;utm_medium=timeline&quot;&gt;https://www.jianshu.com/p/9edca9474663?utm_source=desktop&amp;amp;utm_medium=timeline&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;　　13.minimum_should_match：返回的文档最少匹配查询条件的程度。&lt;/p&gt;
&lt;p&gt;　　14.quote_analyzer：用于分析在引号中的查询文本。&lt;/p&gt;
&lt;p&gt;　　15.phrase_slop：匹配的两个分词之间间隔的最大词项数。&lt;/p&gt;
&lt;p&gt;　　16.quote_field_suffix：附加到引号查询文本的后缀。&lt;/p&gt;
&lt;p&gt;　　17.rewrite：用于重写查询的方法。&lt;/p&gt;
&lt;p&gt;　　18.time_zone：时区，用于转换日期参数。&lt;/p&gt;
&lt;p&gt;2.7Simple Query String&lt;/p&gt;
&lt;p&gt;　　返回匹配查询字符串的文档，使用有限制的但是容错的语法去解析查询字符串。该查询使用简单的语法基于操作符去解析和分割查询字符串，在查询之前分别分析各个词项。因为对语法有更多的限制，索引当有不合规的语法时不会返回错误，忽略查询字符串中不合法的部分。&lt;/p&gt;
&lt;p&gt;　　参数：&lt;/p&gt;
&lt;p&gt;　　1.Query：搜索内容。&lt;/p&gt;
&lt;p&gt;　　2.Fields：搜索的字段集合。&lt;/p&gt;
&lt;p&gt;　　3.default_operator：如果没有定义operator，默认被用作解析查询字符串的操作符。OR（默认）&lt;/p&gt;
&lt;p&gt;　　4.analyze_wildcard：true的时候，查询会分析查询字符串中的通配符。&lt;/p&gt;
&lt;p&gt;　　5.analyzer：用于分析查询字符串的分析器，默认为文档索引时候的分析器。&lt;/p&gt;
&lt;p&gt;　　6.auto_generate_synonyms_phrase_query：true的时候，自动创建多同义词查询。&lt;/p&gt;
&lt;p&gt;　　7.flags：查询操作可以使用的操作符列表。合法操作符：AND、ESCAPE、FUZZY、NEAR、NONE、NOT、OR、PHRASE、PRECEDENCE、PREFIX、SLOP、WHITESPACE。&lt;/p&gt;
&lt;p&gt;　　8.其他参数：fuzzy_max_expansions、fuzzy_prefix_length、fuzzy_transpositions、lenient、minimum_should_match、quote_field_suffix。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;　　&lt;/strong&gt;&lt;/p&gt;
</description>
<pubDate>Mon, 25 May 2020 14:32:00 +0000</pubDate>
<dc:creator>xiaohuoshan</dc:creator>
<og:description>Elasticsearch DSL 查询 组合查询 全文查询</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/sirhuoshan/p/12961351.html</dc:identifier>
</item>
</channel>
</rss>