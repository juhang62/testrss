<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="css/feed.xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/" xmlns:og="http://ogp.me/ns#">
<channel>
<atom:link rel="self" href="http://192.168.1.4/fivefilters/makefulltextfeed.php?url=feed.cnblogs.com%2Fblog%2Fsitehome%2Frss&amp;max=10&amp;links=preserve&amp;exc=" />
<atom:link rel="alternate" title="Source URL" href="http://feed.cnblogs.com/blog/sitehome/rss" />
<atom:link rel="related" title="Subscribe to feed" href="http://www.subtome.com/#/subscribe?feeds=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed.cnblogs.com%252Fblog%252Fsitehome%252Frss%26max%3D10%26links%3Dpreserve%26exc%3D&amp;back=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed.cnblogs.com%252Fblog%252Fsitehome%252Frss%26max%3D10%26links%3Dpreserve%26exc%3D" />
<title>博客园_首页</title>
<link></link>
<description>代码改变世界</description>
<item>
<title>redis 数据删除策略和逐出算法 - black_monkey</title>
<link>http://www.cnblogs.com/monkey-code/p/13097412.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/monkey-code/p/13097412.html</guid>
<description>&lt;h2 id=&quot;数据存储和有效期&quot;&gt;数据存储和有效期&lt;/h2&gt;
&lt;p&gt;在 &lt;code&gt;redis&lt;/code&gt; 工作流程中，过期的数据并不需要马上就要执行删除操作。因为这些删不删除只是一种状态表示，可以&lt;code&gt;异步&lt;/code&gt;的去处理，在不忙的时候去把这些不紧急的删除操作做了，从而保证 &lt;code&gt;redis&lt;/code&gt; 的高效&lt;/p&gt;
&lt;h3 id=&quot;数据的存储&quot;&gt;数据的存储&lt;/h3&gt;
&lt;p&gt;在redis中数据的存储不仅仅需要保存数据本身还要保存数据的生命周期，也就是过期时间。在redis 中 数据的存储结构如下图：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1440828/202006/1440828-20200612084449122-2007065585.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h3 id=&quot;获取有效期&quot;&gt;获取有效期&lt;/h3&gt;
&lt;p&gt;Redis是一种内存级数据库，所有数据均存放在内存中，内存中的数据可以通过TTL指令获取其状态&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1440828/202006/1440828-20200612084505170-2130559407.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h2 id=&quot;删除策略&quot;&gt;删除策略&lt;/h2&gt;
&lt;p&gt;在内存占用与CPU占用之间寻找一种平衡，顾此失彼都会造成整体redis性能的下降，甚至引发服务器宕机或内存泄漏。&lt;/p&gt;
&lt;h3 id=&quot;定时删除&quot;&gt;定时删除&lt;/h3&gt;
&lt;p&gt;创建一个定时器，当key设置过期时间，且过期时间到达时，由定时器任务立即执行对键的删除操作&lt;/p&gt;
&lt;h4 id=&quot;优点&quot;&gt;优点&lt;/h4&gt;
&lt;p&gt;节约内存，到时就删除，快速释放掉不必要的内存占用&lt;/p&gt;
&lt;h4 id=&quot;缺点&quot;&gt;缺点&lt;/h4&gt;
&lt;p&gt;CPU压力很大，无论CPU此时负载多高，均占用CPU，会影响redis服务器响应时间和指令吞吐量&lt;/p&gt;
&lt;h4 id=&quot;总结&quot;&gt;总结&lt;/h4&gt;
&lt;p&gt;用处理器性能换取存储空间&lt;/p&gt;
&lt;h3 id=&quot;惰性删除&quot;&gt;惰性删除&lt;/h3&gt;
&lt;p&gt;数据到达过期时间，不做处理。等下次访问该数据，如果未过期，返回数据。发现已经过期，删除，返回不存在。这样每次读写数据都需要检测数据是否已经到达过期时间。也就是惰性删除总是在数据的读写时发生的。&lt;/p&gt;
&lt;h4 id=&quot;expireifneeded函数&quot;&gt;expireIfNeeded函数&lt;/h4&gt;
&lt;p&gt;对所有的读写命令进行检查，检查操作的对象是否过期。过期就删除返回过期，不过期就什么也不做～。&lt;/p&gt;
&lt;p&gt;执行&lt;strong&gt;数据写入&lt;/strong&gt;过程中，首先通过expireIfNeeded函数对写入的key进行过期判断。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-c&quot;&gt;/*
 * 为执行写入操作而取出键 key 在数据库 db 中的值。
 *
 * 和 lookupKeyRead 不同，这个函数不会更新服务器的命中/不命中信息。
 *
 * 找到时返回值对象，没找到返回 NULL 。
 */
robj *lookupKeyWrite(redisDb *db, robj *key) {

    // 删除过期键
    expireIfNeeded(db,key);

    // 查找并返回 key 的值对象
    return lookupKey(db,key);
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;执行&lt;strong&gt;数据读取&lt;/strong&gt;过程中，首先通过expireIfNeeded函数对写入的key进行过期判断。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-c&quot;&gt;/*
 * 为执行读取操作而取出键 key 在数据库 db 中的值。
 *
 * 并根据是否成功找到值，更新服务器的命中/不命中信息。
 *
 * 找到时返回值对象，没找到返回 NULL 。
 */
robj *lookupKeyRead(redisDb *db, robj *key) {
    robj *val;

    // 检查 key 释放已经过期
    expireIfNeeded(db,key);

    // 从数据库中取出键的值
    val = lookupKey(db,key);

    // 更新命中/不命中信息
    if (val == NULL)
        server.stat_keyspace_misses++;
    else
        server.stat_keyspace_hits++;

    // 返回值
    return val;
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;执行&lt;strong&gt;过期动作expireIfNeeded&lt;/strong&gt;其实内部做了三件事情，分别是：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;查看key判断是否过期&lt;/li&gt;
&lt;li&gt;向slave节点传播执行过期key的动作并发送事件通知&lt;/li&gt;
&lt;li&gt;删除过期key&lt;/li&gt;
&lt;/ul&gt;&lt;pre&gt;
&lt;code class=&quot;language-c&quot;&gt;/*
 * 检查 key 是否已经过期，如果是的话，将它从数据库中删除。
 *
 * 返回 0 表示键没有过期时间，或者键未过期。
 *
 * 返回 1 表示键已经因为过期而被删除了。
 */
int expireIfNeeded(redisDb *db, robj *key) {

    // 取出键的过期时间
    mstime_t when = getExpire(db,key);
    mstime_t now;

    // 没有过期时间
    if (when &amp;lt; 0) return 0; /* No expire for this key */

    /* Don't expire anything while loading. It will be done later. */
    // 如果服务器正在进行载入，那么不进行任何过期检查
    if (server.loading) return 0;

    // 当服务器运行在 replication 模式时
    // 附属节点并不主动删除 key
    // 它只返回一个逻辑上正确的返回值
    // 真正的删除操作要等待主节点发来删除命令时才执行
    // 从而保证数据的同步
    if (server.masterhost != NULL) return now &amp;gt; when;

    // 运行到这里，表示键带有过期时间，并且服务器为主节点

    /* Return when this key has not expired */
    // 如果未过期，返回 0
    if (now &amp;lt;= when) return 0;

    /* Delete the key */
    server.stat_expiredkeys++;

    // 向 AOF 文件和附属节点传播过期信息
    propagateExpire(db,key);

    // 发送事件通知
    notifyKeyspaceEvent(REDIS_NOTIFY_EXPIRED,
        &quot;expired&quot;,key,db-&amp;gt;id);

    // 将过期键从数据库中删除
    return dbDelete(db,key);
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;判断key是否过期的数据结构是db-&amp;gt;expires，也就是通过expires的数据结构判断数据是否过期。&lt;br/&gt;内部获取过期时间并返回。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-c&quot;&gt;/*
 * 返回字典中包含键 key 的节点
 *
 * 找到返回节点，找不到返回 NULL
 *
 * T = O(1)
 */
dictEntry *dictFind(dict *d, const void *key)
{
    dictEntry *he;
    unsigned int h, idx, table;

    // 字典（的哈希表）为空
    if (d-&amp;gt;ht[0].size == 0) return NULL; /* We don't have a table at all */

    // 如果条件允许的话，进行单步 rehash
    if (dictIsRehashing(d)) _dictRehashStep(d);

    // 计算键的哈希值
    h = dictHashKey(d, key);
    // 在字典的哈希表中查找这个键
    // T = O(1)
    for (table = 0; table &amp;lt;= 1; table++) {

        // 计算索引值
        idx = h &amp;amp; d-&amp;gt;ht[table].sizemask;

        // 遍历给定索引上的链表的所有节点，查找 key
        he = d-&amp;gt;ht[table].table[idx];
        // T = O(1)
        while(he) {

            if (dictCompareKeys(d, key, he-&amp;gt;key))
                return he;

            he = he-&amp;gt;next;
        }

        // 如果程序遍历完 0 号哈希表，仍然没找到指定的键的节点
        // 那么程序会检查字典是否在进行 rehash ，
        // 然后才决定是直接返回 NULL ，还是继续查找 1 号哈希表
        if (!dictIsRehashing(d)) return NULL;
    }

    // 进行到这里时，说明两个哈希表都没找到
    return NULL;
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;h4 id=&quot;优点-2&quot;&gt;优点&lt;/h4&gt;
&lt;p&gt;节约CPU性能，发现必须删除的时候才删除。&lt;/p&gt;
&lt;h4 id=&quot;缺点-2&quot;&gt;缺点&lt;/h4&gt;
&lt;p&gt;内存压力很大，出现长期占用内存的数据。&lt;/p&gt;
&lt;h4 id=&quot;总结-2&quot;&gt;总结&lt;/h4&gt;
&lt;p&gt;用存储空间换取处理器性能&lt;/p&gt;
&lt;h3 id=&quot;定期删除&quot;&gt;定期删除&lt;/h3&gt;
&lt;p&gt;周期性轮询redis库中时效性数据，采用随机抽取的策略，利用过期数据占比的方式删除频度。&lt;/p&gt;
&lt;h4 id=&quot;优点-3&quot;&gt;优点&lt;/h4&gt;
&lt;p&gt;CPU性能占用设置有峰值，检测频度可自定义设置&lt;/p&gt;
&lt;p&gt;内存压力不是很大，长期占用内存的冷数据会被持续清理&lt;/p&gt;
&lt;h4 id=&quot;缺点-3&quot;&gt;缺点&lt;/h4&gt;
&lt;p&gt;需要周期性抽查存储空间&lt;/p&gt;
&lt;h3 id=&quot;定期删除详解&quot;&gt;定期删除详解&lt;/h3&gt;
&lt;p&gt;redis的定期删除是通过定时任务实现的，也就是定时任务会循环调用&lt;code&gt;serverCron&lt;/code&gt;方法。然后定时检查过期数据的方法是&lt;code&gt;databasesCron&lt;/code&gt;。定期删除的一大特点就是考虑了定时删除过期数据会占用cpu时间，所以每次执行&lt;code&gt;databasesCron&lt;/code&gt;的时候会限制cpu的占用不超过25%。真正执行删除的是 &lt;code&gt;activeExpireCycle&lt;/code&gt;方法。&lt;/p&gt;
&lt;h4 id=&quot;时间事件&quot;&gt;时间事件&lt;/h4&gt;
&lt;p&gt;对于持续运行的服务器来说， 服务器需要定期对自身的资源和状态进行必要的检查和整理， 从而让服务器维持在一个健康稳定的状态， 这类操作被统称为常规操作（&lt;strong&gt;cron job&lt;/strong&gt;）&lt;/p&gt;
&lt;p&gt;在 Redis 中， 常规操作由 &lt;code&gt;redis.c/serverCron()&lt;/code&gt; 实现， 它主要执行以下操作&lt;/p&gt;
&lt;p&gt;1 更新服务器的各类统计信息，比如时间、内存占用、数据库占用情况等。&lt;/p&gt;
&lt;p&gt;2 清理数据库中的过期键值对。&lt;/p&gt;
&lt;p&gt;3 对不合理的数据库进行大小调整。&lt;/p&gt;
&lt;p&gt;4 关闭和清理连接失效的客户端。&lt;/p&gt;
&lt;p&gt;5 尝试进行 AOF 或 RDB 持久化操作。&lt;/p&gt;
&lt;p&gt;6 如果服务器是主节点的话，对附属节点进行定期同步。&lt;/p&gt;
&lt;p&gt;7 如果处于集群模式的话，对集群进行定期同步和连接测试。&lt;/p&gt;
&lt;p&gt;因为 &lt;code&gt;serverCron()&lt;/code&gt; 需要在 Redis 服务器运行期间一直定期运行， 所以它是一个循环时间事件： &lt;code&gt;serverCron()&lt;/code&gt; 会一直定期执行，直到服务器关闭为止。&lt;/p&gt;
&lt;p&gt;在 Redis 2.6 版本中， 程序规定 &lt;code&gt;serverCron()&lt;/code&gt; 每秒运行 &lt;code&gt;10&lt;/code&gt; 次， 平均每 &lt;code&gt;100&lt;/code&gt; 毫秒运行一次。 从 Redis 2.8 开始， 用户可以通过修改 &lt;code&gt;hz&lt;/code&gt;选项来调整 &lt;code&gt;serverCron()&lt;/code&gt; 的每秒执行次数， 具体信息请参考 &lt;code&gt;redis.conf&lt;/code&gt; 文件中关于 &lt;code&gt;hz&lt;/code&gt; 选项的说明&lt;/p&gt;
&lt;h4 id=&quot;查看hz&quot;&gt;查看hz&lt;/h4&gt;
&lt;pre&gt;
&lt;code class=&quot;language-redis&quot;&gt;way1 : config get hz  # &quot;hz&quot; &quot;10&quot;
way2 : info server  # server.hz 10
&lt;/code&gt;
&lt;/pre&gt;
&lt;h4 id=&quot;servercron&quot;&gt;serverCron()&lt;/h4&gt;
&lt;p&gt;&lt;code&gt;serverCron()&lt;/code&gt;会定期的执行，在&lt;code&gt;serverCron()&lt;/code&gt;执行中会调用&lt;code&gt;databasesCron()&lt;/code&gt; 方法(&lt;code&gt;serverCron()&lt;/code&gt;还做了其他很多事情，但是现在不讨论，只谈删除策略)&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-C&quot;&gt;int serverCron(struct aeEventLoop *eventLoop, long long id, void *clientData) {
    // 略去多无关代码

    /* We need to do a few operations on clients asynchronously. */
    // 检查客户端，关闭超时客户端，并释放客户端多余的缓冲区
    clientsCron();

    /* Handle background operations on Redis databases. */
    // 对数据库执行各种操作
    databasesCron();   /* ！我们关注的方法！ */
&lt;/code&gt;
&lt;/pre&gt;
&lt;h4 id=&quot;databasescron&quot;&gt;databasesCron()&lt;/h4&gt;
&lt;p&gt;在 &lt;code&gt;databasesCron()&lt;/code&gt; 中 调用了 &lt;code&gt;activeExpireCycle()&lt;/code&gt;方法，来对过期的数据进行处理。(在这里还会做一些其他操作～ 调整数据库大小，主动和渐进式rehash)&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-c&quot;&gt;// 对数据库执行删除过期键，调整大小，以及主动和渐进式 rehash
void databasesCron(void) {

    // 判断是否是主服务器 如果是 执行主动过期键清除
    if (server.active_expire_enabled &amp;amp;&amp;amp; server.masterhost == NULL)
        // 清除模式为 CYCLE_SLOW ，这个模式会尽量多清除过期键
        activeExpireCycle(ACTIVE_EXPIRE_CYCLE_SLOW);

    // 在没有 BGSAVE 或者 BGREWRITEAOF 执行时，对哈希表进行 rehash
    if (server.rdb_child_pid == -1 &amp;amp;&amp;amp; server.aof_child_pid == -1) {
        static unsigned int resize_db = 0;
        static unsigned int rehash_db = 0;
        unsigned int dbs_per_call = REDIS_DBCRON_DBS_PER_CALL;
        unsigned int j;

        /* Don't test more DBs than we have. */
        // 设定要测试的数据库数量
        if (dbs_per_call &amp;gt; server.dbnum) dbs_per_call = server.dbnum;

        /* Resize */
        // 调整字典的大小
        for (j = 0; j &amp;lt; dbs_per_call; j++) {
            tryResizeHashTables(resize_db % server.dbnum);
            resize_db++;
        }

        /* Rehash */
        // 对字典进行渐进式 rehash
        if (server.activerehashing) {
            for (j = 0; j &amp;lt; dbs_per_call; j++) {
                int work_done = incrementallyRehash(rehash_db % server.dbnum);
                rehash_db++;
                if (work_done) {
                    /* If the function did some work, stop here, we'll do
                     * more at the next cron loop. */
                    break;
                }
            }
        }
    }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;h4 id=&quot;activeexpirecycle&quot;&gt;activeExpireCycle()&lt;/h4&gt;
&lt;p&gt;大致流程如下&lt;/p&gt;
&lt;p&gt;1 遍历指定个数的db（默认的 16 ）进行删除操作&lt;/p&gt;
&lt;p&gt;2 针对每个db随机获取过期数据每次遍历不超过指定数量（如20），发现过期数据并进行删除。&lt;/p&gt;
&lt;p&gt;3 如果有多于25%的keys过期，重复步骤 2&lt;/p&gt;
&lt;p&gt;除了主动淘汰的频率外，Redis对每次淘汰任务执行的最大时长也有一个限定，这样保证了每次主动淘汰不会过多阻塞应用请求，以下是这个限定计算公式：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;#define ACTIVE_EXPIRE_CYCLE_SLOW_TIME_PERC 25 /* CPU max % for keys collection */ ``... ``timelimit = 1000000*ACTIVE_EXPIRE_CYCLE_SLOW_TIME_PERC/server.hz/100;
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;也就是每次执行时间的25%用于过期数据删除。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-c&quot;&gt;void activeExpireCycle(int type) {
    // 静态变量，用来累积函数连续执行时的数据
    static unsigned int current_db = 0; /* Last DB tested. */
    static int timelimit_exit = 0;      /* Time limit hit in previous call? */
    static long long last_fast_cycle = 0; /* When last fast cycle ran. */

    unsigned int j, iteration = 0;
    // 默认每次处理的数据库数量
    unsigned int dbs_per_call = REDIS_DBCRON_DBS_PER_CALL;
    // 函数开始的时间
    long long start = ustime(), timelimit;

    // 快速模式
    if (type == ACTIVE_EXPIRE_CYCLE_FAST) {
        // 如果上次函数没有触发 timelimit_exit ，那么不执行处理
        if (!timelimit_exit) return;
        // 如果距离上次执行未够一定时间，那么不执行处理
        if (start &amp;lt; last_fast_cycle + ACTIVE_EXPIRE_CYCLE_FAST_DURATION*2) return;
        // 运行到这里，说明执行快速处理，记录当前时间
        last_fast_cycle = start;
    }

    /* 
     * 一般情况下，函数只处理 REDIS_DBCRON_DBS_PER_CALL 个数据库，
     * 除非：
     *
     * 1) 当前数据库的数量小于 REDIS_DBCRON_DBS_PER_CALL
     * 2) 如果上次处理遇到了时间上限，那么这次需要对所有数据库进行扫描，
     *     这可以避免过多的过期键占用空间
     */
    if (dbs_per_call &amp;gt; server.dbnum || timelimit_exit)
        dbs_per_call = server.dbnum;

    // 函数处理的微秒时间上限
    // ACTIVE_EXPIRE_CYCLE_SLOW_TIME_PERC 默认为 25 ，也即是 25 % 的 CPU 时间
    timelimit = 1000000*ACTIVE_EXPIRE_CYCLE_SLOW_TIME_PERC/server.hz/100;
    timelimit_exit = 0;
    if (timelimit &amp;lt;= 0) timelimit = 1;

    // 如果是运行在快速模式之下
    // 那么最多只能运行 FAST_DURATION 微秒 
    // 默认值为 1000 （微秒）
    if (type == ACTIVE_EXPIRE_CYCLE_FAST)
        timelimit = ACTIVE_EXPIRE_CYCLE_FAST_DURATION; /* in microseconds. */

    // 遍历数据库
    for (j = 0; j &amp;lt; dbs_per_call; j++) {
        int expired;
        // 指向要处理的数据库
        redisDb *db = server.db+(current_db % server.dbnum);

        // 为 DB 计数器加一，如果进入 do 循环之后因为超时而跳出
        // 那么下次会直接从下个 DB 开始处理
        current_db++;

        do {
            unsigned long num, slots;
            long long now, ttl_sum;
            int ttl_samples;

            /* If there is nothing to expire try next DB ASAP. */
            // 获取数据库中带过期时间的键的数量
            // 如果该数量为 0 ，直接跳过这个数据库
            if ((num = dictSize(db-&amp;gt;expires)) == 0) {
                db-&amp;gt;avg_ttl = 0;
                break;
            }
            // 获取数据库中键值对的数量
            slots = dictSlots(db-&amp;gt;expires);
            // 当前时间
            now = mstime();

            // 这个数据库的使用率低于 1% ，扫描起来太费力了（大部分都会 MISS）
            // 跳过，等待字典收缩程序运行
            if (num &amp;amp;&amp;amp; slots &amp;gt; DICT_HT_INITIAL_SIZE &amp;amp;&amp;amp;
                (num*100/slots &amp;lt; 1)) break;

            /* 
             * 样本计数器
             */
            // 已处理过期键计数器
            expired = 0;
            // 键的总 TTL 计数器
            ttl_sum = 0;
            // 总共处理的键计数器
            ttl_samples = 0;

            // 每次最多只能检查 LOOKUPS_PER_LOOP 个键
            if (num &amp;gt; ACTIVE_EXPIRE_CYCLE_LOOKUPS_PER_LOOP)
                num = ACTIVE_EXPIRE_CYCLE_LOOKUPS_PER_LOOP;

            // 开始遍历数据库
            while (num--) {
                dictEntry *de;
                long long ttl;

                // 从 expires 中随机取出一个带过期时间的键
                if ((de = dictGetRandomKey(db-&amp;gt;expires)) == NULL) break;
                // 计算 TTL
                ttl = dictGetSignedIntegerVal(de)-now;
                // 如果键已经过期，那么删除它，并将 expired 计数器增一
                if (activeExpireCycleTryExpire(db,de,now)) expired++;
                if (ttl &amp;lt; 0) ttl = 0;
                // 累积键的 TTL
                ttl_sum += ttl;
                // 累积处理键的个数
                ttl_samples++;
            }

            /* Update the average TTL stats for this database. */
            // 为这个数据库更新平均 TTL 统计数据
            if (ttl_samples) {
                // 计算当前平均值
                long long avg_ttl = ttl_sum/ttl_samples;
                
                // 如果这是第一次设置数据库平均 TTL ，那么进行初始化
                if (db-&amp;gt;avg_ttl == 0) db-&amp;gt;avg_ttl = avg_ttl;
                /* Smooth the value averaging with the previous one. */
                // 取数据库的上次平均 TTL 和今次平均 TTL 的平均值
                db-&amp;gt;avg_ttl = (db-&amp;gt;avg_ttl+avg_ttl)/2;
            }

            // 我们不能用太长时间处理过期键，
            // 所以这个函数执行一定时间之后就要返回

            // 更新遍历次数
            iteration++;

            // 每遍历 16 次执行一次
            if ((iteration &amp;amp; 0xf) == 0 &amp;amp;&amp;amp; /* check once every 16 iterations. */
                (ustime()-start) &amp;gt; timelimit)
            {
                // 如果遍历次数正好是 16 的倍数
                // 并且遍历的时间超过了 timelimit
                // 那么断开 timelimit_exit
                timelimit_exit = 1;
            }

            // 已经超时了，返回
            if (timelimit_exit) return;

            // 如果已删除的过期键占当前总数据库带过期时间的键数量的 25 %
            // 那么不再遍历
        } while (expired &amp;gt; ACTIVE_EXPIRE_CYCLE_LOOKUPS_PER_LOOP/4);
    }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;hz调大将会提高Redis主动淘汰的频率，如果你的Redis存储中包含很多冷数据占用内存过大的话，可以考虑将这个值调大，但Redis作者建议这个值不要超过100。我们实际线上将这个值调大到100，观察到CPU会增加2%左右，但对冷数据的内存释放速度确实有明显的提高（通过观察keyspace个数和used_memory大小）。&lt;/p&gt;
&lt;p&gt;可以看出timelimit和server.hz是一个倒数的关系，也就是说hz配置越大，timelimit就越小。换句话说是每秒钟期望的主动淘汰频率越高，则每次淘汰最长占用时间就越短。这里每秒钟的最长淘汰占用时间是固定的250ms（1000000*ACTIVE_EXPIRE_CYCLE_SLOW_TIME_PERC/100），而淘汰频率和每次淘汰的最长时间是通过hz参数控制的。&lt;/p&gt;
&lt;p&gt;因此当redis中的过期key比率没有超过25%之前，提高hz可以明显提高扫描key的最小个数。假设hz为10，则一秒内最少扫描200个key（一秒调用10次*每次最少随机取出20个key），如果hz改为100，则一秒内最少扫描2000个key；另一方面，如果过期key比率超过25%，则扫描key的个数无上限，但是cpu时间每秒钟最多占用250ms。&lt;/p&gt;
&lt;p&gt;当REDIS运行在主从模式时，只有主结点才会执行上述这两种过期删除策略，然后把删除操作”del key”同步到从结点。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-c&quot;&gt;if (server.active_expire_enabled &amp;amp;&amp;amp; server.masterhost == NULL)  // 判断是否是主节点 从节点不需要执行activeExpireCycle()函数。
        // 清除模式为 CYCLE_SLOW ，这个模式会尽量多清除过期键
        activeExpireCycle(ACTIVE_EXPIRE_CYCLE_SLOW);
&lt;/code&gt;
&lt;/pre&gt;
&lt;h4 id=&quot;随机个数&quot;&gt;随机个数&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;redis.config.ACTIVE_EXPIRE_CYCLE_LOOKUPS_PER_LOOP&lt;/strong&gt; 决定每次循环从数据库 expire中随机挑选值的个数&lt;/p&gt;
&lt;h2 id=&quot;逐出算法&quot;&gt;逐出算法&lt;/h2&gt;
&lt;p&gt;如果不限制 reids 对内存使用的限制，它将会使用全部的内存。可以通过 &lt;code&gt;config.memory&lt;/code&gt; 来指定redis 对内存的使用量 。&lt;/p&gt;
&lt;p&gt;下面是redis 配置文件中的说明&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-text&quot;&gt; 543 # Set a memory usage limit to the specified amount of bytes.
 544 # When the memory limit is reached Redis will try to remove keys
 545 # according to the eviction policy selected (see maxmemory-policy).
 546 #
 547 # If Redis can't remove keys according to the policy, or if the policy is
 548 # set to 'noeviction', Redis will start to reply with errors to commands
 549 # that would use more memory, like SET, LPUSH, and so on, and will continue
 550 # to reply to read-only commands like GET.
 551 #
 552 # This option is usually useful when using Redis as an LRU or LFU cache, or to
 553 # set a hard memory limit for an instance (using the 'noeviction' policy).
 554 #
 555 # WARNING: If you have replicas attached to an instance with maxmemory on,
 556 # the size of the output buffers needed to feed the replicas are subtracted
 557 # from the used memory count, so that network problems / resyncs will
 558 # not trigger a loop where keys are evicted, and in turn the output
 559 # buffer of replicas is full with DELs of keys evicted triggering the deletion
 560 # of more keys, and so forth until the database is completely emptied.
 561 #
 562 # In short... if you have replicas attached it is suggested that you set a lower
 563 # limit for maxmemory so that there is some free RAM on the system for replica
 564 # output buffers (but this is not needed if the policy is 'noeviction').
 
将内存使用限制设置为指定的字节。当已达到内存限制Redis将根据所选的逐出策略（请参阅maxmemory策略）尝试删除数据。

如果Redis无法根据逐出策略移除密钥，或者策略设置为“noeviction”，Redis将开始对使用更多内存的命令（如set、LPUSH等）进行错误回复，并将继续回复只读命令，如GET。

当将Redis用作LRU或LFU缓存或设置实例的硬内存限制（使用“noeviction”策略）时，此选项通常很有用。

警告：如果将副本附加到启用maxmemory的实例，则将从已用内存计数中减去馈送副本所需的输出缓冲区的大小，这样，网络问题/重新同步将不会触发收回密钥的循环，而副本的输出缓冲区将充满收回的密钥增量，从而触发删除更多键，依此类推，直到数据库完全清空。

简而言之。。。如果附加了副本，建议您设置maxmemory的下限，以便系统上有一些空闲RAM用于副本输出缓冲区（但如果策略为“noeviction”，则不需要此限制）。
&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;驱逐策略的配置&quot;&gt;驱逐策略的配置&lt;/h3&gt;
&lt;pre&gt;
&lt;code class=&quot;language-redis&quot;&gt;Maxmemery-policy volatile-lru
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;当前已用内存超过 &lt;code&gt;maxmemory&lt;/code&gt; 限定时，触发&lt;strong&gt;主动清理&lt;/strong&gt;策略&lt;/p&gt;
&lt;h3 id=&quot;易失数据清理&quot;&gt;易失数据清理&lt;/h3&gt;
&lt;p&gt;volatile-lru：只对设置了过期时间的key进行LRU（默认值）&lt;/p&gt;
&lt;p&gt;volatile-random：随机删除即将过期key&lt;/p&gt;
&lt;p&gt;volatile-ttl ： 删除即将过期的&lt;/p&gt;
&lt;p&gt;volatile-lfu：挑选最近使用次数最少的数据淘汰&lt;/p&gt;
&lt;h3 id=&quot;全部数据清理&quot;&gt;全部数据清理&lt;/h3&gt;
&lt;p&gt;allkeys-lru ： 删除lru算法的key&lt;/p&gt;
&lt;p&gt;allkeys-lfu：挑选最近使用次数最少的数据淘汰&lt;/p&gt;
&lt;p&gt;allkeys-random：随机删除&lt;/p&gt;
&lt;h3 id=&quot;禁止驱逐&quot;&gt;禁止驱逐&lt;/h3&gt;
&lt;p&gt;(Redis 4.0 默认策略)&lt;/p&gt;
&lt;p&gt;noeviction ： 永不过期，返回错误当mem_used内存已经超过maxmemory的设定，对于所有的读写请求都会触发&lt;code&gt;redis.c/freeMemoryIfNeeded(void)&lt;/code&gt;函数以清理超出的内存。注意这个清理过程是阻塞的，直到清理出足够的内存空间。所以如果在达到maxmemory并且调用方还在不断写入的情况下，可能会反复触发主动清理策略，导致请求会有一定的延迟。&lt;/p&gt;
&lt;p&gt;清理时会根据用户配置的maxmemory-policy来做适当的清理（一般是LRU或TTL），这里的LRU或TTL策略并不是针对redis的所有key，而是以配置文件中的maxmemory-samples个key作为样本池进行抽样清理。&lt;/p&gt;
&lt;p&gt;maxmemory-samples在redis-3.0.0中的默认配置为5，如果增加，会提高LRU或TTL的精准度，redis作者测试的结果是当这个配置为10时已经非常接近全量LRU的精准度了，并且增加maxmemory-samples会导致在主动清理时消耗更多的CPU时间，建议：&lt;/p&gt;
&lt;p&gt;1 尽量不要触发maxmemory，最好在mem_used内存占用达到maxmemory的一定比例后，需要考虑调大hz以加快淘汰，或者进行集群扩容。&lt;/p&gt;
&lt;p&gt;2 如果能够控制住内存，则可以不用修改maxmemory-samples配置；如果Redis本身就作为LRU cache服务（这种服务一般长时间处于maxmemory状态，由Redis自动做LRU淘汰），可以适当调大maxmemory-samples。&lt;/p&gt;
&lt;p&gt;这里提一句，实际上redis根本就不会准确的将整个数据库中最久未被使用的键删除，而是每次从数据库中随机取5个键并删除这5个键里最久未被使用的键。上面提到的所有的随机的操作实际上都是这样的，这个5可以用过redis的配置文件中的maxmemeory-samples参数配置。&lt;/p&gt;
&lt;h3 id=&quot;数据逐出策略配置依据&quot;&gt;数据逐出策略配置依据&lt;/h3&gt;
&lt;p&gt;使用INFO命令输出监控信息，查询缓存int和miss的次数，根据业务需求调优Redis配置。&lt;/p&gt;
</description>
<pubDate>Fri, 12 Jun 2020 00:47:00 +0000</pubDate>
<dc:creator>black_monkey</dc:creator>
<og:description>数据存储和有效期 在 redis 工作流程中，过期的数据并不需要马上就要执行删除操作。因为这些删不删除只是一种状态表示，可以异步的去处理，在不忙的时候去把这些不紧急的删除操作做了，从而保证 redis</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/monkey-code/p/13097412.html</dc:identifier>
</item>
<item>
<title>Accord.NET重启4.0 开发 - 张善友</title>
<link>http://www.cnblogs.com/shanyou/p/13097288.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/shanyou/p/13097288.html</guid>
<description>&lt;p&gt;Accord.NET Framework是在AForge.NET基础上封装和进一步开发来的。功能也很强大，因为AForge.NET更注重与一些底层和广度，而Accord.NET Framework更注重与机器学习这个专业，在其基础上提供了更多统计分析和处理函数，包括图像处理和计算机视觉算法，所以侧重点不同，但都非常有用。 &lt;strong&gt;官方网站&lt;/strong&gt;：&lt;a href=&quot;http://accord-framework.net/&quot;&gt;http://accord-framework.net/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;在项目中断2年时间之后，作者&lt;a href=&quot;https://github.com/cesarsouza&quot;&gt;&lt;strong&gt;cesarsouza&lt;/strong&gt;&lt;/a&gt; &lt;strong&gt;在2020年5月1日更新了项目状态，&lt;/strong&gt; 他在欧洲完成博士，虽然他的工作中主要使用Python完成他的工作，但是他喜欢C#/.NET，一直在考虑Accprd.NET的发展问题，5月15日重新设定了4.0 版本的路线图&lt;a title=&quot;https://github.com/accord-net/framework/issues/2123&quot; href=&quot;https://github.com/accord-net/framework/issues/2123&quot;&gt;https://github.com/accord-net/framework/issues/2123，&lt;/a&gt;  其中他写道：“我看到这个项目仍然被认为对许多人有用，我不认为让项目消亡符合任何人的利益。我最初认为这个项目将由ML.NET取代，但事实并非如此。我们可以转换框架，转而与它合作。”&lt;/p&gt;
&lt;p&gt;我们在ML.NET的最初宣布文章中有Accord.NET的影子：&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;POSTS&quot; src=&quot;https://neelbhatt40.files.wordpress.com/2018/05/posts.png?w=1100&quot;/&gt;&lt;/p&gt;
&lt;p&gt;CNTK 已经死了，目前只有 Tensoflow.NET在蓬勃发展，发展的情况很不错，随着Accord.NET的加入，这个生态又重新激活，期待大家一起加入，推动.NET机器学习生态的发展。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;（一）框架的三大功能模块&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Accord.NET框架主要有三个大的功能性模块。&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;分别为科学技术，&lt;/li&gt;
&lt;li&gt;信号与图像处理，&lt;/li&gt;
&lt;li&gt;支持组件。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;下面将对3个模型的命名空间和功能进行简单介绍。可以让大家更快的接触和了解其功能是否是自己想要的，下面是主要的命名空间介绍。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;（二） 科学计算&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Accord.Math&lt;/strong&gt;:包括矩阵扩展程序，以及一组矩阵数值计算和分解的方法，也包括一些约束和非约束问题的数值优化&lt;strong&gt;&lt;a href=&quot;http://lib.csdn.net/base/datastructure&quot;&gt;算法&lt;/a&gt;&lt;/strong&gt;，还有一些特殊函数以及其他一些辅助工具。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Accord.Statistics&lt;/strong&gt;:包含概率分布、假设检验、线性和逻辑回归等统计模型和方法,隐马尔科夫模型,(隐藏)条件随机域、主成分分析、偏最小二乘判别分析、内核方法和许多其他相关的技术。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Accord.MachineLearning&lt;/strong&gt;: 为&lt;strong&gt;&lt;a href=&quot;http://lib.csdn.net/base/machinelearning&quot;&gt;机器学习&lt;/a&gt;&lt;/strong&gt;应用程序提供包括支持向量机,决策树,朴素贝叶斯模型,k-means聚类算法,高斯混合模型和通用算法如Ransac,交叉验证和网格搜索等算法。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Accord.Neuro&lt;/strong&gt;:包括大量的神经网络学习算法,如Levenberg-Marquardt，Parallel Resilient Backpropagation,Nguyen-Widrow初始化算法,深层的信念网络和许多其他神经网络相关的算法。具体看参考帮助文档。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;（三）信号与图像处理&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Accord.Imaging&lt;/strong&gt;:包含特征点探测器(如Harris, SURF, FAST and  FREAK),图像过滤器、图像匹配和图像拼接方法,还有一些特征提取器。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Accord.Audio:&lt;/strong&gt;包含一些机器学习和统计应用程序说需要的处理、转换过滤器以及处理音频信号的方法。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Accord.Vision:&lt;/strong&gt;实时人脸检测和跟踪,以及对人流图像中的一般的检测、跟踪和转换方法，还有动态模板匹配追踪器。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;（四） 支持组件&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;主要是为上述一些组件提供数据显示，绘图的控件，分为以下几个命名空间：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Accord.Controls:&lt;/strong&gt;包括科学计算应用程序常见的柱状图、散点图和表格数据浏览。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Accord.Controls.Imaging:&lt;/strong&gt;包括用来显示和处理的图像的WinForm控件，包含一个方便快速显示图像的对话框。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Accord.Controls.Audio:&lt;/strong&gt;显示波形和音频相关性信息的WinForm控件。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Accord.Controls.Vision:&lt;/strong&gt;包括跟踪头部,脸部和手部运动以及其他计算机视觉相关的任务WinForm控件。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;（五） 支持的算法介绍&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;下面将Accord&lt;strong&gt;&lt;a href=&quot;http://lib.csdn.net/base/dotnet&quot;&gt;.NET&lt;/a&gt;&lt;/strong&gt;框架包括的主要功能算法按照类别进行介绍。来源主要是官网介绍，进行了简单的翻译和整理。&lt;/p&gt;
&lt;p&gt;1、分类(Classification)&lt;/p&gt;
&lt;p&gt;SVM(支持向量机，类SupportVectorMachine、类KernelSupportVectorMachine、类SequentialMinimalOptimization—序列最小优化算法)、&lt;/p&gt;
&lt;p&gt;K-NN邻近算法（类KNearestNeighbors）；&lt;/p&gt;
&lt;p&gt;Logistic Regression(逻辑回归)、&lt;/p&gt;
&lt;p&gt;Decision Trees(决策树，类DecisionTree、ID3Learning、C45Learning)、&lt;/p&gt;
&lt;p&gt;Neural Networks(神经网络)、&lt;/p&gt;
&lt;p&gt;Deep Learning(深度学习)&lt;/p&gt;
&lt;p&gt;(Deep Neural Networks深层神经网络)、&lt;/p&gt;
&lt;p&gt;Levenberg-Marquardt with Bayesian Regularization、&lt;/p&gt;
&lt;p&gt;Restricted Boltzmann Machines(限制玻耳兹曼机)、&lt;/p&gt;
&lt;p&gt;Sequence classification (序列分类),&lt;/p&gt;
&lt;p&gt;Hidden Markov Classifiers and Hidden Conditional Random Fields(隐马尔科夫分类器和隐藏条件随机域)。&lt;/p&gt;
&lt;p&gt;2、回归(Regression)&lt;/p&gt;
&lt;p&gt;Multiple linear regression(多元线性回归-单因变量多自变量)、&lt;/p&gt;
&lt;p&gt;SimpleLinearRegression（线性回归，类SimpleLinearRegression）、&lt;/p&gt;
&lt;p&gt;Multivariate linear regression(多元线性回归-多因变量多自变量)、polynomial regression (多项式回归)、logarithmic regression(对数回归)、Logistic regression(逻辑回归)、multinomial logistic regression(多项式逻辑回归)(softmax) and generalized linear models(广义线性模型)、L2-regularized L2-loss logistic regression , L2-regularized logistic regression , L1-regularized logistic regression , L2-regularized logistic regression in the dual form and regression support vector machines。&lt;/p&gt;
&lt;p&gt;3、聚类(Clustering)&lt;/p&gt;
&lt;p&gt;K-Means、K-Modes、Mean-Shift(均值漂移)、Gaussian Mixture Models(高斯混合模型)、Binary Split(二元分裂)、Deep Belief Networks(深层的信念网络)、 Restricted Boltzmann Machines(限制玻耳兹曼机)。聚类算法可以应用于任意数据,包括图像、数据表、视频和音频。&lt;/p&gt;
&lt;p&gt;4、概率分布(Distributions)&lt;/p&gt;
&lt;p&gt;包括40多个分布的参数和非参数估计。包括一些常见的分布如正态分布、柯西分布、超几何分布、泊松分布、伯努利；也包括一些特殊的分布如Kolmogorov-Smirnov , Nakagami、Weibull、and Von-Mises distributions。也包括多元分布如多元正态分布、Multinomial 、Independent 、Joint and Mixture distributions。&lt;/p&gt;
&lt;p&gt;5、假设检验(Hypothesis Tests)&lt;/p&gt;
&lt;p&gt;超过35统计假设测试,包括单向和双向方差分析测试、非参数测试如Kolmogorov-Smirnov测试和媒体中的信号测试。contingency table tests such as the Kappa test，with variations for multiple tables , as well as the Bhapkar and Bowker tests; and the more traditional Chi-Square , Z , F , T and Wald tests .&lt;/p&gt;
&lt;p&gt;6、核方法(Kernel Methods)&lt;/p&gt;
&lt;p&gt;内核支持向量机,多类和多标签向量机、序列最小优化、最小二乘学习、概率学习。Including special methods for linear machines such as LIBLINEAR's methods for Linear Coordinate Descent , Linear Newton Method , Probabilistic Coordinate Descent , Probabilistic Coordinate Descent in the Dual , Probabilistic Newton Method for L1 and L2 machines in both the dual and primal formulations .&lt;/p&gt;
&lt;p&gt;7、图像(Imaging)&lt;/p&gt;
&lt;p&gt;兴趣和特征点探测器如Harris,FREAK,SURF,FAST。灰度共生矩阵,Border following,Bag-of-Visual-Words (BoW),RANSAC-based homography estimation , integral images , haralick textural feature extraction , and dense descriptors such as histogram of oriented gradients (HOG) and Local Binary Pattern (LBP).Several image filters for image processing applications such as difference of Gaussians , Gabor , Niblack and Sauvola thresholding。还有几个图像处理中经常用到的图像过滤器。&lt;/p&gt;
&lt;p&gt;8、音频信号(Audio and Signal)&lt;/p&gt;
&lt;p&gt;音频信号的加载、解析、保存、过滤和转换,如在空间域和频域应用音频过滤器。WAV文件、音频捕捉、时域滤波器,高通,低通,波整流过滤器。Frequency-domain operators such as differential rectification filter and comb filter with Dirac's delta functions . Signal generators for Cosine , Impulse , Square signals.&lt;/p&gt;
&lt;p&gt;9、视觉(Vision)&lt;/p&gt;
&lt;p&gt;实时人脸检测和跟踪,以及图像流中检测、跟踪、转换的一般的检测方法。Contains cascade definitions , Camshift and Dynamic Template Matching trackers . Includes pre-created classifiers for human faces and some facial features such as noses。&lt;/p&gt;
&lt;p&gt;10、降维技术&lt;/p&gt;
&lt;p&gt;SVD奇异值分解（OctaveEnvironment.svd方法）;&lt;/p&gt;
&lt;p&gt;PCA主成分分析（类PrincipalComponent）;&lt;/p&gt;
&lt;p&gt;ICA独立成份分析(类IndependentComponetAnalysis)&lt;/p&gt;
&lt;p&gt;11、算法精度测算&lt;/p&gt;
&lt;p&gt;混淆矩阵(类ConfusionMatrix)；&lt;/p&gt;
&lt;p&gt;ROC曲线评估(类ReceiverOperatingCharacteristic);&lt;/p&gt;
&lt;p&gt;Bootstrap算法（自助算法；类(Bootstrap)）;&lt;/p&gt;
&lt;p&gt;CrossValidation算法(交叉检验;类(CrossValidation));&lt;/p&gt;
</description>
<pubDate>Thu, 11 Jun 2020 23:43:00 +0000</pubDate>
<dc:creator>张善友</dc:creator>
<og:description>Accord.NET Framework是在AForge.NET基础上封装和进一步开发来的。功能也很强大，因为AForge.NET更注重与一些底层和广度，而Accord.NET Framework更注</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/shanyou/p/13097288.html</dc:identifier>
</item>
<item>
<title>.Net Core微服务入门全纪录（一）——项目搭建 - xhznl</title>
<link>http://www.cnblogs.com/xhznl/p/13071260.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/xhznl/p/13071260.html</guid>
<description>&lt;p&gt;写这篇博客主要目的是记录一下自己的学习过程，只能是简单入门级别的，因为水平有限就写到哪算哪吧，写的不对之处欢迎指正。&lt;/p&gt;

&lt;p&gt;关于微服务的概念解释网上有很多...&lt;br/&gt;个人理解，微服务是一种系统架构模式，它和语言无关，和框架无关，和工具无关，和服务器环境无关...&lt;br/&gt;微服务思想是将传统的单体系统按照业务拆分成多个职责单一、且可独立运行的接口服务，各个服务之间不耦合。至于服务如何拆分，没有明确的定义。&lt;br/&gt;几乎任何后端语言都能做微服务开发。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/610959/202006/610959-20200610192945580-2076034628.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;br/&gt;一个客户端，一个产品服务，一个订单服务。3个项目都是asp.net core web应用程序。创建项目的时候记得启用一下Docker支持，或者后面添加也行。&lt;/p&gt;
&lt;p&gt;为产品、订单服务添加一些基础代码，就简单的返回一下 服务名称，当前时间，服务的ip、端口。&lt;br/&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/610959/202006/610959-20200610193747469-82298951.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/610959/202006/610959-20200610193823797-616818977.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;

&lt;p&gt;为了方便，我使用Docker来运行服务，不用Docker也行，关于docker的安装及基本使用就不介绍了。&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;build镜像：&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;在项目根目录打开PowerShell窗口执行：&lt;code&gt;docker build -t productapi -f ./Product.API/Dockerfile .&lt;/code&gt;&lt;br/&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/610959/202006/610959-20200610195822281-1017385594.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;br/&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/610959/202006/610959-20200610195900044-1677580339.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;br/&gt;Successfully代表build成功了。&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;运行容器:&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;执行：&lt;code&gt;docker run -d -p 9050:80 --name productservice productapi&lt;/code&gt;&lt;br/&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/610959/202006/610959-20200610200637039-238683468.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;执行：&lt;code&gt;docker ps&lt;/code&gt;查看运行的容器：&lt;br/&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/610959/202006/610959-20200610200822095-1488681309.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;没问题，使用浏览器访问一下接口：&lt;br/&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/610959/202006/610959-20200610201058997-1287537831.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;br/&gt;也没问题，其中的ip端口是Docker容器内部的ip端口，所以端口是80，这个无所谓。&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;产品服务部署好了，下面部署一下订单服务，也是同样的流程，就把指令简单贴一下吧：&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;build镜像：&lt;code&gt;docker build -t orderapi -f ./Order.API/Dockerfile .&lt;/code&gt;&lt;br/&gt;运行容器：&lt;code&gt;docker run -d -p 9060:80 --name orderservice orderapi&lt;/code&gt;&lt;br/&gt;浏览器访问一下：&lt;br/&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/610959/202006/610959-20200610202518942-2050251746.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;br/&gt;OK，订单服务也部署完成了。&lt;/p&gt;

&lt;p&gt;客户端我这里只做了一个web客户端，实际可能是各种业务系统、什么PC端、手机端、小程序。。。这个明白就好，为了简单就不搞那么多了。&lt;/p&gt;
&lt;p&gt;IServiceHelper.cs：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;    public interface IServiceHelper
    {
        /// &amp;lt;summary&amp;gt;
        /// 获取产品数据
        /// &amp;lt;/summary&amp;gt;
        /// &amp;lt;returns&amp;gt;&amp;lt;/returns&amp;gt;
        Task&amp;lt;string&amp;gt; GetProduct();

        /// &amp;lt;summary&amp;gt;
        /// 获取订单数据
        /// &amp;lt;/summary&amp;gt;
        /// &amp;lt;returns&amp;gt;&amp;lt;/returns&amp;gt;
        Task&amp;lt;string&amp;gt; GetOrder();
    }
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;ServiceHelper.cs：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;    public class ServiceHelper : IServiceHelper
    {
        public async Task&amp;lt;string&amp;gt; GetOrder()
        {
            string serviceUrl = &quot;http://localhost:9060&quot;;//订单服务的地址，可以放在配置文件或者数据库等等...

            var Client = new RestClient(serviceUrl);
            var request = new RestRequest(&quot;/orders&quot;, Method.GET);

            var response = await Client.ExecuteAsync(request);
            return response.Content;
        }

        public async Task&amp;lt;string&amp;gt; GetProduct()
        {
            string serviceUrl = &quot;http://localhost:9050&quot;;//产品服务的地址，可以放在配置文件或者数据库等等...

            var Client = new RestClient(serviceUrl);
            var request = new RestRequest(&quot;/products&quot;, Method.GET);

            var response = await Client.ExecuteAsync(request);
            return response.Content;
        }
    }
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;Startup.cs：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;    public class Startup
    {
        public Startup(IConfiguration configuration)
        {
            Configuration = configuration;
        }

        public IConfiguration Configuration { get; }

        // This method gets called by the runtime. Use this method to add services to the container.
        public void ConfigureServices(IServiceCollection services)
        {
            services.AddControllersWithViews();
            
            //注入IServiceHelper
            services.AddSingleton&amp;lt;IServiceHelper, ServiceHelper&amp;gt;();
        }

        // This method gets called by the runtime. Use this method to configure the HTTP request pipeline.
        public void Configure(IApplicationBuilder app, IWebHostEnvironment env)
        {
            if (env.IsDevelopment())
            {
                app.UseDeveloperExceptionPage();
            }
            else
            {
                app.UseExceptionHandler(&quot;/Home/Error&quot;);
            }
            app.UseStaticFiles();

            app.UseRouting();

            app.UseAuthorization();

            app.UseEndpoints(endpoints =&amp;gt;
            {
                endpoints.MapControllerRoute(
                    name: &quot;default&quot;,
                    pattern: &quot;{controller=Home}/{action=Index}/{id?}&quot;);
            });
        }
    }
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;HomeController.cs：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;    public class HomeController : Controller
    {
        private readonly ILogger&amp;lt;HomeController&amp;gt; _logger;
        private readonly IServiceHelper _serviceHelper;

        public HomeController(ILogger&amp;lt;HomeController&amp;gt; logger, IServiceHelper serviceHelper)
        {
            _logger = logger;
            _serviceHelper = serviceHelper;
        }

        public async Task&amp;lt;IActionResult&amp;gt; Index()
        {
            ViewBag.OrderData = await _serviceHelper.GetOrder();
            ViewBag.ProductData = await _serviceHelper.GetProduct();

            return View();
        }

        public IActionResult Privacy()
        {
            return View();
        }

        [ResponseCache(Duration = 0, Location = ResponseCacheLocation.None, NoStore = true)]
        public IActionResult Error()
        {
            return View(new ErrorViewModel { RequestId = Activity.Current?.Id ?? HttpContext.TraceIdentifier });
        }
    }
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;Index.cshtml：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;@{
    ViewData[&quot;Title&quot;] = &quot;Home Page&quot;;
}

&amp;lt;div class=&quot;text-center&quot;&amp;gt;
    &amp;lt;h1 class=&quot;display-4&quot;&amp;gt;Welcome&amp;lt;/h1&amp;gt;
    &amp;lt;p&amp;gt;
        @ViewBag.OrderData
    &amp;lt;/p&amp;gt;
    &amp;lt;p&amp;gt;
        @ViewBag.ProductData
    &amp;lt;/p&amp;gt;
&amp;lt;/div&amp;gt;
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;代码比较简单，这里就不用docker了，直接控制台启动，使用浏览器访问：&lt;br/&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/610959/202006/610959-20200610213634874-1478989961.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;一切正常。进行到这里，各个服务也独立运行了，客户端也能正常调用了，貌似算是完成一个简易的微服务了。但是，微服务架构最重要的原则就是——“高可用”。以上的做法明显不能满足高可用性，因为任何一个服务挂掉，所有依赖这个服务的业务系统都会受影响。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;停止一下订单服务：&lt;code&gt;docker stop orderservice&lt;/code&gt;&lt;br/&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/610959/202006/610959-20200610214936537-1512158022.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;br/&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/610959/202006/610959-20200610215045754-1970315793.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;br/&gt;订单服务停止，导致客户端业务系统无法获取订单数据。&lt;br/&gt;要解决这个问题，很容易想到：集群。&lt;/p&gt;

&lt;p&gt;既然单个服务实例有挂掉的风险，那么部署多个服务实例就好了嘛，只要大家不同时全挂就行。&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;使用docker运行多个服务实例：&lt;br/&gt;&lt;code&gt;docker run -d -p 9061:80 --name orderservice1 orderapi&lt;/code&gt;&lt;br/&gt;&lt;code&gt;docker run -d -p 9062:80 --name orderservice2 orderapi&lt;/code&gt;&lt;br/&gt;&lt;code&gt;docker run -d -p 9051:80 --name productservice1 productapi&lt;/code&gt;&lt;br/&gt;&lt;code&gt;docker run -d -p 9052:80 --name productservice2 productapi&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;现在订单服务和产品服务都增加到3个服务实例。&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;那么稍微改造一下客户端代码吧：&lt;br/&gt;ServiceHelper.cs：&lt;/li&gt;
&lt;/ul&gt;&lt;pre&gt;
&lt;code&gt;public class ServiceHelper : IServiceHelper
    {
        public async Task&amp;lt;string&amp;gt; GetOrder()
        {
            string[] serviceUrls = { &quot;http://localhost:9060&quot;, &quot;http://localhost:9061&quot;, &quot;http://localhost:9062&quot; };//订单服务的地址，可以放在配置文件或者数据库等等...

            //每次随机访问一个服务实例
            var Client = new RestClient(serviceUrls[new Random().Next(0, 3)]);
            var request = new RestRequest(&quot;/orders&quot;, Method.GET);

            var response = await Client.ExecuteAsync(request);
            return response.Content;
        }

        public async Task&amp;lt;string&amp;gt; GetProduct()
        {
            string[] serviceUrls = { &quot;http://localhost:9050&quot;, &quot;http://localhost:9051&quot;, &quot;http://localhost:9052&quot; };//产品服务的地址，可以放在配置文件或者数据库等等...

            //每次随机访问一个服务实例
            var Client = new RestClient(serviceUrls[new Random().Next(0, 3)]);
            var request = new RestRequest(&quot;/products&quot;, Method.GET);

            var response = await Client.ExecuteAsync(request);
            return response.Content;
        }
    }
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;当然拿到这些服务地址可以自己做复杂的负载均衡策略，比如轮询，随机，权重等等 都行，甚至在中间弄个nginx也可以。这些不是重点，所以就简单做一个随机吧，每次请求来了随便访问一个服务实例。&lt;/p&gt;
&lt;ul readability=&quot;0.5&quot;&gt;&lt;li readability=&quot;2&quot;&gt;
&lt;p&gt;浏览器测试一下：&lt;br/&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/610959/202006/610959-20200610223710329-1540627927.gif&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;br/&gt;可以看到请求被随机分配了。但是这种做法依然不安全，如果随机访问到的实例刚好挂掉，那么业务系统依然会出问题。&lt;br/&gt;简单处理思路是：&lt;br/&gt;1.如果某个地址请求失败了，那么换一个地址接着执行。&lt;br/&gt;2.如果某个地址的请求连续多次失败了，那么就移除这个地址，下次就不会访问到它了。&lt;br/&gt;。。。。。。&lt;br/&gt;业务系统实现以上逻辑，基本上风险就很低了，也算是大大增加了系统可用性了。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;然后思考另一个问题：&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;实际应用中，上层的业务系统可能非常多，为了保证可用性，每个业务系统都去考虑服务实例挂没挂掉吗？&lt;br/&gt;而且实际应用中服务实例的数量或者地址大多是不固定的，例如双十一来了，流量大了，增加了一堆服务实例，这时候每个业务系统再去配置文件里配置一下这些地址吗？双十一过了又去把配置删掉吗？显然是不现实的，服务必须要做到可灵活伸缩。&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;这时候就引入一个名词：服务注册与发现&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;未完待续...&lt;/p&gt;
</description>
<pubDate>Thu, 11 Jun 2020 23:43:00 +0000</pubDate>
<dc:creator>xhznl</dc:creator>
<og:description>前言 写这篇博客主要目的是记录一下自己的学习过程，只能是简单入门级别的，因为水平有限就写到哪算哪吧，写的不对之处欢迎指正。 什么是微服务？ 关于微服务的概念解释网上有很多... 个人理解，微服务是一种</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/xhznl/p/13071260.html</dc:identifier>
</item>
<item>
<title>Elasticsearch系列---生产数据备份恢复方案 - 清茶豆奶</title>
<link>http://www.cnblogs.com/huangying2124/p/13097269.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/huangying2124/p/13097269.html</guid>
<description>&lt;h3 id=&quot;前言&quot;&gt;前言&lt;/h3&gt;
&lt;p&gt;生产环境中运行的组件，只要有数据存储，定时备份、灾难恢复是必修课，mysql数据库的备份方案已经非常成熟，Elasticsearch也同样有成熟的数据备份、恢复方案，我们来了解一下。&lt;/p&gt;
&lt;h3 id=&quot;概要&quot;&gt;概要&lt;/h3&gt;
&lt;p&gt;本篇介绍Elasticsearch生产集群数据的数据备份、恢复和升级的常规操作。&lt;/p&gt;
&lt;h3 id=&quot;curl命令&quot;&gt;curl命令&lt;/h3&gt;
&lt;p&gt;curl是Linux操作的必备工具，Elasticsearch生产环境的搭建，不能保证都能使用kibana访问到，而Elasticsearch Restful API都可以使用curl工具来完成访问。&lt;/p&gt;
&lt;p&gt;使用curl还有一个好处：有些操作需要一连串的请求才能完成，我们可以使用shell脚本将这些关联的操作，封装到脚本里，后续使用起来就非常方便。&lt;/p&gt;
&lt;p&gt;如果有定时执行的命令，也是使用shell将一系列操作封装好，运用Linux自带的crontab进行触发。&lt;/p&gt;
&lt;p&gt;后续的一些操作命令，将会用curl来完成，并且只需要将完整的curl请求拷贝到kibana的dev tools上，kibana能够自动转化成我们之前常见的请求，非常方便。&lt;/p&gt;
&lt;p&gt;在Linux下的请求命令：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;[esuser@elasticsearch02 ~]$ curl -XGET 'http://elasticsearch02:9200/music/children/_search?pretty' -H 'Content-Type: application/json' -d '
{
  &quot;query&quot;: {
    &quot;match_all&quot;: {}
  }
}
'
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;完整的命令拷贝到dev tools里时，自动会变成：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;GET /music/children/_search
{

  &quot;query&quot;: {

    &quot;match_all&quot;: {}

  }

}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;这工具真是强大，不过反过来操作不行的，我已经试过了。&lt;/p&gt;
&lt;p&gt;curl命令，有Body体的，记得加上&lt;code&gt;-H 'Content-Type: application/json'&lt;/code&gt;，&lt;code&gt;?pretty参数可以让响应结果格式化输出&lt;/code&gt;。&lt;/p&gt;
&lt;h3 id=&quot;数据备份&quot;&gt;数据备份&lt;/h3&gt;
&lt;p&gt;我们知道Elasticsearch的索引拆分成多个shard进行存储在磁盘里，shard虽然分了primary shard和replica shard，可以保证集群的数据不丢失，数据访问不间断，但如果机房停电导致集群节点全部宕机这种重大事故时，我们就需要提前定期地对数据进行备份，以防万一。&lt;/p&gt;
&lt;p&gt;既然是磁盘文件存储，那存储介质的选择就有很多了：本地磁盘，NAS，文件存储服务器（如FastDFS、HDFS等），各种云存储（Amazon S3, 阿里云OSS）等&lt;/p&gt;
&lt;p&gt;同样的，Elasticsearch也提供snapshot api命令来完成数据备份操作，可以把集群当前的状态和数据全部存储到一个其他目录上，本地路径或网络路径均可，并且支持增量备份。可以根据数据量来决定备份的执行频率，增量备份的速度还是很快的。&lt;/p&gt;
&lt;h4 id=&quot;创建备份仓库&quot;&gt;创建备份仓库&lt;/h4&gt;
&lt;p&gt;我们把仓库地址暂定为本地磁盘的&lt;code&gt;/home/esuser/esbackup&lt;/code&gt;目录，&lt;/p&gt;
&lt;p&gt;首先，我们需要在&lt;code&gt;elasticsearch.yml&lt;/code&gt;配置文件中加上&lt;/p&gt;
&lt;p&gt;&lt;code&gt;path.repo: /home/esuser/esbackup&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;并重启Elasticsearch。&lt;/p&gt;
&lt;p&gt;启动成功后，发送创建仓库的请求：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;[esuser@elasticsearch02 ~]$ curl -XPUT 'http://elasticsearch02:9200/_snapshot/esbackup?pretty' -H 'Content-Type: application/json' -d '
{
    &quot;type&quot;: &quot;fs&quot;, 
    &quot;settings&quot;: {
        &quot;location&quot;: &quot;/home/esuser/esbackup&quot;,
        &quot;max_snapshot_bytes_per_sec&quot; : &quot;50mb&quot;, 
        &quot;max_restore_bytes_per_sec&quot; : &quot;50mb&quot;
    }
}
'
{&quot;acknowledged&quot;:true}
[esuser@elasticsearch02 ~]$ 
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;参数解释：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;type: 仓库的类型名称，请求里都是fs，表示file system。&lt;/li&gt;
&lt;li&gt;location: 仓库的地址，要与&lt;code&gt;elasticsearch.yml&lt;/code&gt;配置文件相同，否则会报错&lt;/li&gt;
&lt;li&gt;max_snapshot_bytes_per_sec: 指定数据从Elasticsearch到仓库（数据备份）的写入速度上限，默认是20mb/s&lt;/li&gt;
&lt;li&gt;max_restore_bytes_per_sec: 指定数据从仓库到Elasticsearch（数据恢复）的写入速度上限，默认也是20mb/s&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;用于限流的两个参数，需要根据实际的网络进行设置，如果备份目录在同一局域网内，可以设置得大一些，便于加快备份和恢复的速度。&lt;/p&gt;
&lt;p&gt;也有查询命令可以看仓库的信息：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;[esuser@elasticsearch02 ~]$ curl -XGET 'http://elasticsearch02:9200/_snapshot/esbackup?pretty'

{&quot;esbackup&quot;:{&quot;type&quot;:&quot;fs&quot;,&quot;settings&quot;:{&quot;location&quot;:&quot;/home/esuser/esbackup&quot;,&quot;max_restore_bytes_per_sec&quot;:&quot;50mb&quot;,&quot;max_snapshot_bytes_per_sec&quot;:&quot;50mb&quot;}}}

[esuser@elasticsearch02 ~]$
&lt;/code&gt;
&lt;/pre&gt;
&lt;h4 id=&quot;使用hdfs创建仓库&quot;&gt;使用hdfs创建仓库&lt;/h4&gt;
&lt;p&gt;大数据这块跟hadoop生态整合还是非常推荐的方案，数据备份这块可以用hadoop下的hdfs分布式文件存储系统，关于hadoop集群的搭建方法，需要自行完成，本篇末尾有补充说明，可供参考。&lt;/p&gt;
&lt;p&gt;对Elasticsearch来说，需要安装repository-hdfs的插件，我们的Elasticsearch版本是6.3.1，对应的插件则使用repository-hdfs-6.3.1.zip，hadoop则使用2.8.1版本的。&lt;/p&gt;
&lt;p&gt;插件下载安装命令：&lt;/p&gt;
&lt;p&gt;&lt;code&gt;./elasticsearch-plugin install https://artifacts.elastic.co/downloads/elasticsearch-plugins/repository-hdfs/repository-hdfs-6.3.1.zip&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;如果生产环境的服务器无法连接外网，可以先在其他机器上下载好，上传到生产服务器，解压到本地，再执行安装：&lt;/p&gt;
&lt;p&gt;&lt;code&gt;./elasticsearch-plugin install file:///opt/elasticsearch/repository-hdfs-6.3.1&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;安装完成后记得重启Elasticsearch节点。&lt;/p&gt;
&lt;p&gt;查看节点状态：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;[esuser@elasticsearch02 ~]$ curl -XGET elasticsearch02:9200/_cat/nodes?v

ip             heap.percent ram.percent cpu load_1m load_5m load_15m node.role master name
192.168.17.137           38          95   2    0.03    0.03     0.05 mdi       *      node-1
&lt;/code&gt;
&lt;/pre&gt;
&lt;h5 id=&quot;创建hdfs仓库&quot;&gt;创建hdfs仓库&lt;/h5&gt;
&lt;p&gt;先查看节点的shard信息&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;[esuser@elasticsearch02 ~]$ curl -XGET 'http://elasticsearch02:9200/_count?pretty' -H 'Content-Type: application/json' -d '
 {
     &quot;query&quot;: {
         &quot;match_all&quot;: {}
     }
}'


{
  &quot;count&quot; : 5392,
  &quot;_shards&quot; : {
    &quot;total&quot; : 108,
    &quot;successful&quot; : 108,
    &quot;skipped&quot; : 0,
    &quot;failed&quot; : 0
  }
}

&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;创建一个hdfs的仓库，名称为hdfsbackup&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;[esuser@elasticsearch02 ~]$ curl -XPUT  'http://elasticsearch02:9200/_snapshot/hdfsbackup?pretty' -H 'Content-Type: application/json' -d '
 {
   &quot;type&quot;: &quot;hdfs&quot;,
   &quot;settings&quot;: {
     &quot;uri&quot;: &quot;hdfs://elasticsearch02:9000/&quot;,
     &quot;path&quot;: &quot;/home/esuser/hdfsbackup&quot;,
   &quot;conf.dfs.client.read.shortcircuit&quot;: &quot;false&quot;,
   &quot;max_snapshot_bytes_per_sec&quot; : &quot;50mb&quot;, 
     &quot;max_restore_bytes_per_sec&quot; : &quot;50mb&quot;
   }
 }'

{
  &quot;acknowledged&quot; : true
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;h5 id=&quot;验证仓库&quot;&gt;验证仓库&lt;/h5&gt;
&lt;p&gt;仓库创建好了之后，可以用verify命令验证一下：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;[esuser@elasticsearch02 ~]$ curl -XPOST 'http://elasticsearch02:9200/_snapshot/hdfsbackup/_verify?pretty'
{
  &quot;nodes&quot; : {
    &quot;A1s1uus7TpuDSiT4xFLOoQ&quot; : {
      &quot;name&quot; : &quot;node-1&quot;
    }
  }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;h5 id=&quot;索引备份&quot;&gt;索引备份&lt;/h5&gt;
&lt;p&gt;仓库创建好并验证完成后，可以执行snapshot api对索引进行备份了，&lt;/p&gt;
&lt;p&gt;如果不指定索引名称，表示备份当前所有open状态的索引都备份，还有一个参数wait_for_completion，表示是否需要等待备份完成后才响应结果，默认是false，请求提交后会立即返回，然后备份操作在后台异步执行，如果设置为true，请求就变成同步方式，后台备份完成后，才会有响应。建议使用默认值即可，有时备份的整个过程会持续1-2小时。&lt;/p&gt;
&lt;p&gt;示例1：备份所有的索引，备份名称为snapshot_20200122&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;[esuser@elasticsearch02 ~]$ curl -XPUT 'http://elasticsearch02:9200/_snapshot/hdfsbackup/snapshot_20200122?pretty'
{
  &quot;accepted&quot; : true
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;示例2：备份索引music的数据，备份名称为snapshot_20200122_02，并指定wait_for_completion为true&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;[esuser@elasticsearch02 ~]$ curl -XPUT 'http://elasticsearch02:9200/_snapshot/hdfsbackup/snapshot_20200122_02?wait_for_completion=true&amp;amp;pretty' -H 'Content-Type: application/json' -d '
{
  &quot;indices&quot;: &quot;music&quot;,
  &quot;ignore_unavailable&quot;: true,
  &quot;include_global_state&quot;: false,
  &quot;partial&quot;: true
}'


{
  &quot;snapshot&quot; : {
    &quot;snapshot&quot; : &quot;snapshot_20200122_02&quot;,
    &quot;uuid&quot; : &quot;KRXnzc6XSWagCQO92EQx6A&quot;,
    &quot;version_id&quot; : 6030199,
    &quot;version&quot; : &quot;6.3.1&quot;,
    &quot;indices&quot; : [
      &quot;music&quot;
    ],
    &quot;include_global_state&quot; : false,
    &quot;state&quot; : &quot;SUCCESS&quot;,
    &quot;start_time&quot; : &quot;2020-01-22T07:11:06.594Z&quot;,
    &quot;start_time_in_millis&quot; : 1579677066594,
    &quot;end_time&quot; : &quot;2020-01-22T07:11:07.313Z&quot;,
    &quot;end_time_in_millis&quot; : 1579677067313,
    &quot;duration_in_millis&quot; : 719,
    &quot;failures&quot; : [ ],
    &quot;shards&quot; : {
      &quot;total&quot; : 5,
      &quot;failed&quot; : 0,
      &quot;successful&quot; : 5
    }
  }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;这条命令中几个参数介绍：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;indices：索引名称，允许写多个，用&quot;,&quot;分隔，支持通配符。&lt;/li&gt;
&lt;li&gt;ignore_unavailable：可选值true/false，如果为true，indices里不存在的index就可以忽略掉，备份操作正常执行，默认是false，如果某个index不存在，备份操作会提示失败。&lt;/li&gt;
&lt;li&gt;include_global_state：可选值true/false，含义是要不要备份集群的全局state数据。&lt;/li&gt;
&lt;li&gt;partial：可选值true/false，是否支持备份部分shard的数据。默认值为false，如果索引的部分primary shard不可用，partial为false时备份过程会提示失败。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;使用snapshot api对数据的备份是增量进行的，执行snapshotting的时候，Elasticsearch会分析已经存在于仓库中的snapshot对应的index file，在前一次snapshot基础上，仅备份创建的或者发生过修改的index files。这就允许多个snapshot在仓库中可以用一种紧凑的模式来存储，非常节省存储空间，并且snapshotting过程是不会阻塞所有的Elasticsearch读写操作的。&lt;/p&gt;
&lt;p&gt;同样的，snapshot作为数据快照，在它之后写入index中的数据，是不会反应到这次snapshot中的，snapshot数据的内容包含index的副本，也可以选择是否保存全局的cluster元数据，元数据里面包含了全局的cluster设置和template。&lt;/p&gt;
&lt;p&gt;每次只能执行一次snapshot操作，如果某个shard正在被snapshot备份，那么这个shard此时就不能被移动到其他node上去，这会影响shard rebalance的操作。只有在snapshot结束之后，这个shard才能够被移动到其他的node上去。&lt;/p&gt;
&lt;h5 id=&quot;查看snapshot备份列表&quot;&gt;查看snapshot备份列表&lt;/h5&gt;
&lt;ol&gt;&lt;li&gt;查看仓库内所有的备份列表&lt;/li&gt;
&lt;/ol&gt;&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;curl -XGET 'http://elasticsearch02:9200/_snapshot/hdfsbackup/_all?pretty'
&lt;/code&gt;
&lt;/pre&gt;
&lt;ol start=&quot;2&quot;&gt;&lt;li&gt;查看单个备份数据&lt;/li&gt;
&lt;/ol&gt;&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;[esuser@elasticsearch02 ~]$ curl -XGET 'http://elasticsearch02:9200/_snapshot/hdfsbackup/snapshot_20200122_02?pretty'
{
  &quot;snapshots&quot; : [
    {
      &quot;snapshot&quot; : &quot;snapshot_20200122_02&quot;,
      &quot;uuid&quot; : &quot;KRXnzc6XSWagCQO92EQx6A&quot;,
      &quot;version_id&quot; : 6030199,
      &quot;version&quot; : &quot;6.3.1&quot;,
      &quot;indices&quot; : [
        &quot;music&quot;
      ],
      &quot;include_global_state&quot; : false,
      &quot;state&quot; : &quot;SUCCESS&quot;,
      &quot;start_time&quot; : &quot;2020-01-22T07:11:06.594Z&quot;,
      &quot;start_time_in_millis&quot; : 1579677066594,
      &quot;end_time&quot; : &quot;2020-01-22T07:11:07.313Z&quot;,
      &quot;end_time_in_millis&quot; : 1579677067313,
      &quot;duration_in_millis&quot; : 719,
      &quot;failures&quot; : [ ],
      &quot;shards&quot; : {
        &quot;total&quot; : 5,
        &quot;failed&quot; : 0,
        &quot;successful&quot; : 5
      }
    }
  ]
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;h5 id=&quot;删除snapshot备份&quot;&gt;删除snapshot备份&lt;/h5&gt;
&lt;p&gt;如果需要删除某个snapshot备份快照，一定要使用delete命令，造成别自个跑到服务器目录下做rm操作，因为snapshot是增量备份的，里面有各种依赖关系，极可能损坏backup数据，记住不要上来就自己干文件，让人家标准的命令来执行，命令如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;[esuser@elasticsearch02 ~]$ curl -XDELETE 'http://elasticsearch02:9200/_snapshot/hdfsbackup/snapshot_20200122?pretty'
{
  &quot;acknowledged&quot; : true
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;h5 id=&quot;查看备份进度&quot;&gt;查看备份进度&lt;/h5&gt;
&lt;p&gt;备份过程长短视数据量而定，wait_for_completion设置为true虽然可以同步得到结果，但时间太长的话也不现实，我们是希望备份操作后台自己搞，我们时不时的看看进度就行，其实还是调用的snapshot的get操作命令，加上_status参数即可，备份过程中会显示什么时间开始的，有几个shard在备份等等信息：&lt;/p&gt;
&lt;p&gt;&lt;code&gt;curl -XGET 'http://elasticsearch02:9200/_snapshot/hdfsbackup/snapshot_20200122_02/_status?pretty'&lt;/code&gt;&lt;/p&gt;
&lt;h5 id=&quot;取消备份&quot;&gt;取消备份&lt;/h5&gt;
&lt;p&gt;正在备份的数据可以执行取消，使用的是delete命令：&lt;/p&gt;
&lt;p&gt;&lt;code&gt;curl -XDELETE 'http://elasticsearch02:9200/_snapshot/hdfsbackup/snapshot_20200122?pretty'&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;这个命令有两个作用：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;如果备份正在进行中，那么取消备份操作，并且删除备份了一半的数据。&lt;/li&gt;
&lt;li&gt;如果备份已经完成，直接删除备份数据。&lt;/li&gt;
&lt;/ol&gt;&lt;h3 id=&quot;数据恢复&quot;&gt;数据恢复&lt;/h3&gt;
&lt;p&gt;生产环境的备份操作，是定期执行的，执行的频率看实际的数据量，有1天执行1次的，有4小时一次的，简单的操作是使用shell脚本封装备份的命令，然后使用Linux的crontab定时执行。&lt;/p&gt;
&lt;p&gt;既然数据有备份，那如果数据出现异常，或者需要使用到备份数据时，恢复操作就能派上用场了。&lt;/p&gt;
&lt;h4 id=&quot;常规恢复&quot;&gt;常规恢复&lt;/h4&gt;
&lt;p&gt;数据恢复使用restore命令，示例如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;[esuser@elasticsearch02 ~]$ curl -XPOST 'http://elasticsearch02:9200/_snapshot/hdfsbackup/snapshot_20200122_02/_restore?pretty'
{
  &quot;accepted&quot; : true
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;注意一下被恢复的索引，必须全部是close状态的，否则会报错，关闭索引的命令：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;[esuser@elasticsearch02 ~]$ curl -XPOST  'http://elasticsearch02:9200/music/_close?pretty'
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;恢复完成后，索引自动还原成open状态。&lt;/p&gt;
&lt;p&gt;同样有些参数可以进行选择：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;[esuser@elasticsearch02 ~]$ curl -XPOST 'http://elasticsearch02:9200/_snapshot/hdfsbackup/snapshot_20200122_02/_restore
{
    &quot;indices&quot;: &quot;music&quot;, 
        &quot;ignore_unavailable&quot;: true,
        &quot;include_global_state&quot;: true
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;默认会把备份数据里的索引全部还原，我们可以使用indices参数指定需要恢复的索引名称。同样可以使用wait_for_completion参数，ignore_unavailable、partial和include_global_state与备份时效果相同，不赘述。&lt;/p&gt;
&lt;h4 id=&quot;监控restore的进度&quot;&gt;监控restore的进度&lt;/h4&gt;
&lt;p&gt;与备份类似，调用的recovery的get操作命令查看恢复的进度：&lt;/p&gt;
&lt;p&gt;&lt;code&gt;curl -XGET 'http://elasticsearch02:9200/music/_recovery?pretty'&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;music为索引名称。&lt;/p&gt;
&lt;h4 id=&quot;取消restore&quot;&gt;取消restore&lt;/h4&gt;
&lt;p&gt;与备份类似，delete正在恢复的索引可以取消恢复过程：&lt;/p&gt;
&lt;p&gt;&lt;code&gt;curl -XDELETE 'http://elasticsearch02:9200/music'&lt;/code&gt;&lt;/p&gt;
&lt;h3 id=&quot;集群升级&quot;&gt;集群升级&lt;/h3&gt;
&lt;p&gt;我们现在使用的版本是6.3.1，目前官网最新版本已经是7.5.2了，如果没有重大的变更或严重bug报告的情况下，一般是不需要做升级，毕竟升级有风险，发布要谨慎。&lt;/p&gt;
&lt;p&gt;这里就简单说一下通用的步骤，谨慎操作:&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;查看官网最新版本的文档，从当前版本到目标版本的升级，有哪些变化，新加入的功能和修复的bug。&lt;/li&gt;
&lt;li&gt;在开发环境或测试环境先执行升级，相应的插件也做一次匹配升级，稳定运行几个项目版本周期后，再考虑生产环境的升级事宜。&lt;/li&gt;
&lt;li&gt;升级前对数据进行全量的备份，万一升级失败，还有挽救的余地。&lt;/li&gt;
&lt;li&gt;申请生产环境升级的时间窗口，逐个node进行升级验证。&lt;/li&gt;
&lt;/ol&gt;&lt;h3 id=&quot;补充hadoop集群搭建&quot;&gt;补充hadoop集群搭建&lt;/h3&gt;
&lt;p&gt;Elasticsearch的数据备份，通常建议的实践方案是结合hadoop的hdfs文件存储，这里我们搭建一个hadoop的集群环境用作演示，hadoop相关的基础知识请自行了解，已经掌握的童鞋可以跳过。&lt;/p&gt;
&lt;p&gt;版本环境：&lt;br/&gt;hadoop 2.8.1&lt;/p&gt;
&lt;p&gt;虚拟机环境&lt;/p&gt;
&lt;p&gt;hadoop集群至少需要3个节点。我们选用elasticsearch02、elasticsearch03、elasticsearch04三台机器用于搭建。&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;下载解压&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;官网下载hadoop-2.8.1.tar.gz，解压至/opt/hadoop目录&lt;/p&gt;
&lt;ol start=&quot;2&quot;&gt;&lt;li&gt;设置环境变量&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;演示环境拥有root权限，就介绍一种最简单的设置方法，修改/etc/profile文件，添加变量后记得source一下该文件。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;
[root@elasticsearch02 ~]# vi /etc/profile

# 文件末尾添加
export HADOOP_HOME=/opt/hadoop/hadoop-2.8.1
export PATH=${HADOOP_HOME}/bin:$PATH

[root@elasticsearch02 ~]# source /etc/profile
&lt;/code&gt;
&lt;/pre&gt;
&lt;ol start=&quot;3&quot; readability=&quot;0&quot;&gt;&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;创建hadoop数据目录，启动hadoop时我们使用esuser账户，就在/home/esuser下创建目录，如 &lt;code&gt;/home/esuser/hadoopdata&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;修改hadoop的配置文件，在&lt;code&gt;/opt/hadoop/hadoop-2.8.1/etc/hadoop&lt;/code&gt;目录下，基本上是添加配置，涉及的配置文件：&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;&lt;ul&gt;&lt;li&gt;core-site.xml&lt;/li&gt;
&lt;li&gt;hdfs-site.xml&lt;/li&gt;
&lt;li&gt;yarn-site.xml&lt;/li&gt;
&lt;li&gt;mapred-site.xml&lt;/li&gt;
&lt;li&gt;slaves(注：我们选定elasticsearch02为master，其余两个为slave)&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;示例修改如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;core-site.xml

&amp;lt;property&amp;gt;
  &amp;lt;name&amp;gt;fs.defaultFS&amp;lt;/name&amp;gt;
  &amp;lt;value&amp;gt;hdfs://elasticsearch02:9000&amp;lt;/value&amp;gt;
&amp;lt;/property&amp;gt;

hdfs-site.xml

&amp;lt;property&amp;gt;
  &amp;lt;name&amp;gt;dfs.namenode.name.dir&amp;lt;/name&amp;gt;
  &amp;lt;value&amp;gt;/home/esuser/hadoopdata/namenode&amp;lt;/value&amp;gt;
&amp;lt;/property&amp;gt;
&amp;lt;property&amp;gt;
  &amp;lt;name&amp;gt;dfs.datanode.data.dir&amp;lt;/name&amp;gt;
  &amp;lt;value&amp;gt;/home/esuser/hadoopdata/datanode&amp;lt;/value&amp;gt;
&amp;lt;/property&amp;gt;

yarn-site.xml

&amp;lt;property&amp;gt;
  &amp;lt;name&amp;gt;yarn.resourcemanager.hostname&amp;lt;/name&amp;gt;
  &amp;lt;value&amp;gt;elasticsearch02&amp;lt;/value&amp;gt;
&amp;lt;/property&amp;gt;

mapred-site.xml

&amp;lt;property&amp;gt;
  &amp;lt;name&amp;gt;mapreduce.framework.name&amp;lt;/name&amp;gt;
  &amp;lt;value&amp;gt;yarn&amp;lt;/value&amp;gt;
&amp;lt;/property&amp;gt;

slaves

elasticsearch03
elasticsearch04
&lt;/code&gt;
&lt;/pre&gt;
&lt;ol start=&quot;5&quot;&gt;&lt;li&gt;拷贝设置后的文件到另外两台机器上&lt;/li&gt;
&lt;/ol&gt;&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;scp -r /opt/hadoop/hadoop-2.8.1 esuser@elasticsearch03:/opt/hadoop/hadoop-2.8.1
scp -r /opt/hadoop/hadoop-2.8.1 esuser@elasticsearch04:/opt/hadoop/hadoop-2.8.1
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;拷贝的文件有点大，需要等一会儿，拷贝完成后，在elasticsearch03、elasticsearch04再设置一次HADOOP_HOME环境变量&lt;/p&gt;
&lt;ol start=&quot;6&quot;&gt;&lt;li&gt;启动集群&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;格式化namenode，在hadoop master节点(elasticsearch02)，HADOOP_HOME/sbin目录下执行&lt;code&gt;hdfs namenode -format&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;执行启动命令：&lt;code&gt;start-dfs.sh&lt;/code&gt;&lt;br/&gt;这个启动过程会建立到elasticsearch03、elasticsearch04的ssh连接，输入esuser的密码即可，也可以提前建立好免密ssh连接。&lt;/p&gt;
&lt;p&gt;我们只需要用它的hdfs服务，其他的组件可以不启动。&lt;/p&gt;
&lt;p&gt;验证启动是否成功，三台机器分别输入jps，看下面的进程，如无意外理论上应该是这样：&lt;br/&gt;elasticsearch02：NameNode、SecondaryNameNode&lt;br/&gt;elasticsearch03：DataNode&lt;br/&gt;elasticsearch04：DataNode&lt;/p&gt;
&lt;p&gt;同时在浏览器上输入hadoop master的控制台地址：&lt;code&gt;http://192.168.17.137:50070/dfshealth.html#tab-overview&lt;/code&gt;，应该能看到这两个界面：&lt;br/&gt;&lt;img src=&quot;https://imgkr.cn-bj.ufileos.com/65c7a4ff-14af-4453-bfd7-a8b0ba1dadec.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://imgkr.cn-bj.ufileos.com/f08189cb-0012-45a2-a83c-c2b4d2ea1386.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;datanodes看到2个结点，表示集群启动成功，如果只能看到一个或一个都没有，可以查看相应的日志：&lt;code&gt;/opt/hadoop/hadoop-2.8.1/logs&lt;/code&gt;&lt;/p&gt;
&lt;h4 id=&quot;error-java_home-is-not-set-and-could-not-be-found-错误解决办法&quot;&gt;Error: JAVA_HOME is not set and could not be found 错误解决办法&lt;/h4&gt;
&lt;p&gt;这个明明已经设置了JAVA_HOME，并且&lt;code&gt;export&lt;/code&gt;命令也能看到，启动时死活就是不行，不跟他杠了，直接在&lt;code&gt;/opt/hadoop/hadoop-2.8.1/etc/hadoop/hadoop-env.sh&lt;/code&gt;文件加上&lt;/p&gt;
&lt;p&gt;&lt;code&gt;export JAVA_HOME=&quot;/opt/jdk1.8.0_211&quot;&lt;/code&gt;&lt;/p&gt;
&lt;h3 id=&quot;小结&quot;&gt;小结&lt;/h3&gt;
&lt;p&gt;本篇主要以hadoop分布式文件存储为背景，讲解了Elasticsearch数据的备份与恢复，可以了解一下。集群版本升级这类操作，实践起来比较复杂，受项目本身影响比较大，这里就简单提及要注意的地方，没有作详细的案例操作，真要有版本升级的操作，请各位慎重操作，多验证，确保测试环境充分测试后再上生产，记得数据要备份。&lt;/p&gt;
&lt;p&gt;专注Java高并发、分布式架构，更多技术干货分享与心得，请关注公众号：Java架构社区&lt;br/&gt;可以扫左边二维码添加好友，邀请你加入Java架构社区微信群共同探讨技术&lt;br/&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1834889/202003/1834889-20200303074927076-1724862603.jpg&quot; alt=&quot;Java架构社区&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
</description>
<pubDate>Thu, 11 Jun 2020 23:19:00 +0000</pubDate>
<dc:creator>清茶豆奶</dc:creator>
<og:description>前言 生产环境中运行的组件，只要有数据存储，定时备份、灾难恢复是必修课，mysql数据库的备份方案已经非常成熟，Elasticsearch也同样有成熟的数据备份、恢复方案，我们来了解一下。 概要 本篇</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/huangying2124/p/13097269.html</dc:identifier>
</item>
<item>
<title>C#9.0 终于来了，您还学的动吗？ 带上VS一起解读吧！（应该是全网第一篇） - 一线码农</title>
<link>http://www.cnblogs.com/huangxincheng/p/13097256.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/huangxincheng/p/13097256.html</guid>
<description>&lt;h2 id=&quot;一：背景&quot;&gt;一：背景&lt;/h2&gt;
&lt;h3 id=&quot;1-讲故事&quot;&gt;1. 讲故事&lt;/h3&gt;
&lt;p&gt;好消息，&lt;code&gt;.NET 5.0&lt;/code&gt; 终于在2020年6月10日发布了第五个预览版，眼尖的同学一定看到了在这个版本中终于支持了 &lt;code&gt;C# 9.0&lt;/code&gt;，此处有掌声，太好了！！！&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://dotnet.microsoft.com/download/dotnet/5.0&quot; title=&quot;.Net5官方下载&quot;&gt;.Net5官方链接&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/214741/202006/214741-20200612070018247-1479429254.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;可以看到目前的C#9还是预览版，实现了一部分新语法供开发者提前尝鲜，从github的roslyn仓库上可以看到目前准备实现 &lt;code&gt;17&lt;/code&gt;个新特性，现阶段已经实现了&lt;code&gt;8&lt;/code&gt;个，其中的 &lt;code&gt;In Progress&lt;/code&gt; 表示正在开发中。&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/dotnet/roslyn/blob/master/docs/Language%20Feature%20Status.md&quot; title=&quot;新特性预览&quot;&gt;新特性预览&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/214741/202006/214741-20200612070018792-950169146.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h3 id=&quot;2-安装必备&quot;&gt;2. 安装必备&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/214741/202006/214741-20200612070019061-1464422498.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;找好你自己的vs版本类型哦。。。&lt;/p&gt;
&lt;h2 id=&quot;二：新特性研究&quot;&gt;二：新特性研究&lt;/h2&gt;
&lt;h2 id=&quot;1-target-typed-new&quot;&gt;1. Target-typed new&lt;/h2&gt;
&lt;p&gt;这个取名一定要留给学易经的大师傅，没见过世面的我不敢造次，取得不佳影响时运，所谓 &lt;code&gt;运去金成铁, 时来铁似金&lt;/code&gt; ，不过大概意思就是说直接new你定义的局部变量的类型，用&lt;code&gt;issues&lt;/code&gt;中总结的话就是：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-C#&quot;&gt;
Summary: Allow Point p = new (x, y);
Shipped in preview in 16.7p1.

&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;接下来就是全部代码，看看&lt;code&gt;使用前&lt;/code&gt; 和 &lt;code&gt;使用后&lt;/code&gt; 的具体差别。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-C#&quot;&gt;
    class Program
    {
        static void Main(string[] args)
        {
            //老语法
            var person = new Person(&quot;mary&quot;, &quot;123456&quot;);

            //新语法
            Person person2 = new(&quot;mary&quot;, &quot;123456&quot;);

            Console.WriteLine($&quot;person={person}person2={person2}&quot;);
        }
    }

    public class Person
    {
        private string username;
        private string password;

        public Person(string username, string password)
        {
            this.username = username;
            this.password = password;
        }

        public override string ToString()
        {
            return $&quot;username={username},password={password} \n&quot;;
        }
    }

&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/214741/202006/214741-20200612070019237-2001282404.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;然后用ilspy去看看下面的il代码，是不是省略了Person，让自己心里踏实一点。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/214741/202006/214741-20200612070019408-1080363057.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;总的来说这语法还行吧，能起到延长键盘使用寿命的功效。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;2-lambda-discard-parameters&quot;&gt;2. Lambda discard parameters&lt;/h2&gt;
&lt;p&gt;从字面上看大概就是说可以在lambda上使用取消参数，听起来怪怪的，那本意是什么呢？有时候lambda上的匿名方法签名的参数是不需要的，但在以前必须实打实的定义，这样就会污染方法体，也就是可以在body中被访问，如下图：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/214741/202006/214741-20200612070019638-1352171258.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;但有时候因为客观原因必须使用&lt;code&gt;Func&amp;lt;int,int,int&amp;gt;&lt;/code&gt;这样的委托，而且还不想让方法签名的参数污染方法体，我猜测在函数式编程中有这样的场景吧，可能有点类似MVC中的&lt;code&gt;EmptyResult&lt;/code&gt;效果。&lt;/p&gt;
&lt;p&gt;好了，我想你大概知道啥意思了，接下来实操一把。。。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-C#&quot;&gt;
    Func&amp;lt;int, int, int&amp;gt; func = (_, _) =&amp;gt;
    {
        return 0;
    };

    var result = func(10, 20);

&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/214741/202006/214741-20200612070019807-1427219605.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;从图中可以看到，我在方法体中是找不到所谓的 &lt;code&gt;_&lt;/code&gt; 变量的，这就神奇了，怎么做到的呢？ 带着这个好奇心看看它的IL代码是个什么样子。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-C#&quot;&gt;
.method private hidebysig static 
        void Main (
                string[] args
        ) cil managed 
{
        // Method begins at RVA 0x2048
        // Code size 45 (0x2d)
        .maxstack 3
        .entrypoint
        .locals init (
                [0] class [System.Runtime]System.Func`3&amp;lt;int32, int32, int32&amp;gt; func,
                [1] int32 result
        )

        IL_0000: nop
        IL_0001: ldsfld class [System.Runtime]System.Func`3&amp;lt;int32, int32, int32&amp;gt; ConsoleApp1.Program/'&amp;lt;&amp;gt;c'::'&amp;lt;&amp;gt;9__0_0'
        IL_0006: dup
        IL_0007: brtrue.s IL_0020

        IL_0009: pop
        IL_000a: ldsfld class ConsoleApp1.Program/'&amp;lt;&amp;gt;c' ConsoleApp1.Program/'&amp;lt;&amp;gt;c'::'&amp;lt;&amp;gt;9'
        IL_000f: ldftn instance int32 ConsoleApp1.Program/'&amp;lt;&amp;gt;c'::'&amp;lt;Main&amp;gt;b__0_0'(int32, int32)
        IL_0015: newobj instance void class [System.Runtime]System.Func`3&amp;lt;int32, int32, int32&amp;gt;::.ctor(object, native int)
        IL_001a: dup
        IL_001b: stsfld class [System.Runtime]System.Func`3&amp;lt;int32, int32, int32&amp;gt; ConsoleApp1.Program/'&amp;lt;&amp;gt;c'::'&amp;lt;&amp;gt;9__0_0'

        IL_0020: stloc.0
        IL_0021: ldloc.0
        IL_0022: ldc.i4.s 10
        IL_0024: ldc.i4.s 20
        IL_0026: callvirt instance !2 class [System.Runtime]System.Func`3&amp;lt;int32, int32, int32&amp;gt;::Invoke(!0, !1)
        IL_002b: stloc.1
        IL_002c: ret
} // end of method Program::Main

&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;从上面的IL代码来看 匿名方法 变成了&lt;code&gt;&amp;lt;&amp;gt;c&lt;/code&gt;类的&lt;code&gt;&amp;lt;Main&amp;gt;b__0_0&lt;/code&gt;方法,完整签名： &lt;code&gt;ConsoleApp1.Program/'&amp;lt;&amp;gt;c'::'&amp;lt;Main&amp;gt;b__0_0'(int32, int32)&lt;/code&gt;，然后再找一下 &lt;code&gt;&amp;lt;Main&amp;gt;b__0_0&lt;/code&gt; 方法的定义。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-C#&quot;&gt;
.class nested private auto ansi sealed serializable beforefieldinit '&amp;lt;&amp;gt;c'
        extends [System.Runtime]System.Object
        .method assembly hidebysig 
                instance int32 '&amp;lt;Main&amp;gt;b__0_0' (
                        int32 _,
                        int32 _
                ) cil managed 
        {
                // Method begins at RVA 0x2100
                // Code size 7 (0x7)
                .maxstack 1
                .locals init (
                        [0] int32
                )

                IL_0000: nop
                IL_0001: ldc.i4.0
                IL_0002: stloc.0
                IL_0003: br.s IL_0005

                IL_0005: ldloc.0
                IL_0006: ret
        } // end of method '&amp;lt;&amp;gt;c'::'&amp;lt;Main&amp;gt;b__0_0'

&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;这说明什么呢？ 说明两个参数是真实存在的，但编译器捣了鬼，做了语法上的限制，不让你访问所谓的 &lt;code&gt;_&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;等等。。。有一个问题，IL中的方法签名怎么是这样的： &lt;code&gt;&amp;lt;Main&amp;gt;b__0_0 (int32 _,int32 _)&lt;/code&gt; , 大家应该知道方法签名中不可以出现重复的参数名，比如下面这样定义肯定是报错的。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/214741/202006/214741-20200612070020013-1557330187.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;这说明什么？ 说明这个语法糖不仅需要编译器支持，更需要底层的JIT支持，那怎么证明呢？我们用windbg去底层挖一挖。。。为了方便调试,修改如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-C#&quot;&gt;
        static void Main(string[] args)
        {
            Func&amp;lt;int, int, int&amp;gt; func = (_, _) =&amp;gt;
            {
                Console.WriteLine(&quot;进入方法体了！！！&quot;);
                Console.ReadLine();
                return 0;
            };

            var result = func(10, 20);
        }

0:000&amp;gt; !clrstack -p
OS Thread Id: 0x52e8 (0)
0000007035F7E5C0 00007ffaff362655 ConsoleApp1.Program+c.b__0_0(Int32, Int32) [C:\5\ConsoleApp1\ConsoleApp1\Program.cs @ 13]
    PARAMETERS:
        this (0x0000007035F7E600) = 0x000001968000cb48
        _ (0x0000007035F7E608) = 0x000000000000000a
        _ (0x0000007035F7E610) = 0x0000000000000014
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/214741/202006/214741-20200612070020266-971533924.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;从图中可以看到，虽然都是 &lt;code&gt;_&lt;/code&gt; ,但在线程栈上是完完全全的两个栈地址。 &lt;code&gt;0x0000007035F7E608&lt;/code&gt; 和 &lt;code&gt;0x0000007035F7E610&lt;/code&gt;。&lt;/p&gt;
&lt;h2 id=&quot;三：总结&quot;&gt;三：总结&lt;/h2&gt;
&lt;p&gt;总的来说，C#是越来越像函数式编程靠拢，越来越像Scala，就像Jquery的口号一样： Write less，do more。&lt;/p&gt;
&lt;p&gt;好了，先就说这两个吧，大家先安装好工具，明天继续解剖~~~&lt;/p&gt;
&lt;hr/&gt;&lt;h3 id=&quot;如您有更多问题与我互动，扫描下方进来吧&quot;&gt;如您有更多问题与我互动，扫描下方进来吧~&lt;/h3&gt;
&lt;hr/&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/214741/202005/214741-20200522143723695-575216767.png&quot; width=&quot;600&quot; height=&quot;200&quot; alt=&quot;图片名称&quot; align=&quot;center&quot;/&gt;</description>
<pubDate>Thu, 11 Jun 2020 23:00:00 +0000</pubDate>
<dc:creator>一线码农</dc:creator>
<og:description>一：背景 1. 讲故事 好消息，.NET 5.0 终于在2020年6月10日发布了第五个预览版，眼尖的同学一定看到了在这个版本中终于支持了 C# 9.0，此处有掌声，太好了！！！ .Net5官方链接</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/huangxincheng/p/13097256.html</dc:identifier>
</item>
<item>
<title>Java并发相关知识点梳理和研究 - 五岳</title>
<link>http://www.cnblogs.com/wuyuegb2312/p/12829280.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/wuyuegb2312/p/12829280.html</guid>
<description>&lt;p&gt;主要包括深入分析wait()/notify()/notifyAll()实现生产者消费者模式、线程数调优、并发容器、AQS、JMM五个大专题，七个小专题，leetCode并发题简介三个部分，基本对大多数Java并发领域的知识都有所涉及，也是经常容易提问的问题，整理下来便于以后review。&lt;/p&gt;&lt;div id=&quot;cnblogs_post_body&quot; readability=&quot;320.00018836649&quot;&gt;

&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/228024/202006/228024-20200612020830812-1689346827.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;(图比较大，可以右键在新窗口打开)&lt;/p&gt;

&lt;p&gt;注：本节代码和部分分析参考了&lt;a href=&quot;https://www.jianshu.com/p/25e243850bd2&quot;&gt;你真的懂wait、notify和notifyAll吗&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;看下面一段典型的wait()/notify()/notifyAll()代码，对于值得注意的细节，用注释标出。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;import java.util.ArrayList;
import java.util.List;

public class Something {
    private Buffer mBuf = new Buffer(); // 共享的池子

    public void produce() {
        synchronized (this) { // 注1、注2
            while (mBuf.isFull()) { // 注3
                try {
                    wait(); // 注4
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }
            }
            mBuf.add();
            notifyAll();  // 注5、注6
        }
    }

    public void consume() {
        synchronized (this) { // 见注1、注2
            while (mBuf.isEmpty()) { // 注3
                try {
                    wait(); // 注4
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }
            }
            mBuf.remove();
            notifyAll(); // 注5、注6
        }
    }

    private class Buffer {
        private static final int MAX_CAPACITY = 1;
        private List innerList = new ArrayList&amp;lt;&amp;gt;(MAX_CAPACITY);

        void add() {
            if (isFull()) {
                throw new IndexOutOfBoundsException();
            } else {
                innerList.add(new Object());
            }
            System.out.println(Thread.currentThread().toString() + &quot; add&quot;);

        }

        void remove() {
            if (isEmpty()) {
                throw new IndexOutOfBoundsException();
            } else {
                innerList.remove(MAX_CAPACITY - 1);
            }
            System.out.println(Thread.currentThread().toString() + &quot; remove&quot;);
        }

        boolean isEmpty() {
            return innerList.isEmpty();
        }

        boolean isFull() {
            return innerList.size() == MAX_CAPACITY;
        }
    }

    public static void main(String[] args) {
        Something sth = new Something();
        Runnable runProduce = new Runnable() {
            int count = 4;

            @Override
            public void run() {
                while (count-- &amp;gt; 0) {
                    sth.produce();
                }
            }
        };
        Runnable runConsume = new Runnable() {
            int count = 4;

            @Override
            public void run() {
                while (count-- &amp;gt; 0) {
                    sth.consume();
                }
            }
        };
        for (int i = 0; i &amp;lt; 2; i++) {
            new Thread(runConsume).start();
        }
        for (int i = 0; i &amp;lt; 2; i++) {
            new Thread(runProduce).start();
        }
    }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;ul&gt;&lt;li&gt;注1：wait()/notify()/notifyAll()必须在synchronized块中使用&lt;/li&gt;
&lt;li&gt;注2：使用synchronized(this)的原因是，这段代码的main()，是通过实例化Something的对象，并使用它的方法来进行生产/消费的，因此是一个指向this的对象锁。不同的场景，需要注意同步的对象的选择。&lt;/li&gt;
&lt;li&gt;注3：必须使用while循环来包裹wait()。设想一种场景：存在多个生产者或多个消费者消费者，以多个生成者为例，在缓冲区满的情况下，如果生产者通过notify()唤醒的线程仍是生产者，如果不使用while，那么获取锁的线程无法重新进入睡眠，锁也不能释放，造成死锁。&lt;/li&gt;
&lt;li&gt;注4：wait()会释放锁&lt;/li&gt;
&lt;li&gt;注5：notfiy()、notifyAll()会通知其他在wait的线程来获取锁，但是获取锁的真正时机是锁的原先持有者退出synchronized块的时候。&lt;/li&gt;
&lt;li&gt;注6：使用notifyAll()而不是notfiy()的原因是，仍考虑注3的场景，假如生产者唤醒的也是生产者，后者发现缓冲区满重新进入阻塞，此时没有办法再唤醒在等待的消费者线程了，也会造成死锁。&lt;/li&gt;
&lt;/ul&gt;&lt;h2 id=&quot;扩展知识点1：synchronized块的两个队列&quot;&gt;扩展知识点1：synchronized块的两个队列&lt;/h2&gt;
&lt;p&gt;synchronized入口是将线程放入同步队列，wait()是将线程放入阻塞队列。notify()/notifyAll()实际上是把线程从阻塞队列放入同步队列。&lt;a href=&quot;https://blog.csdn.net/qq_42029989/article/details/89709692&quot;&gt;wait/notify/notifyAll方法需不需要被包含在synchronized块中，为什么？&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;扩展知识点2：synchronized重入原理&quot;&gt;扩展知识点2：synchronized重入原理&lt;/h2&gt;
&lt;p&gt;synchronized是可重入的，原理是它内部包含了一个计数器，进入时+1，退出时-1。 &lt;a href=&quot;https://www.cnblogs.com/cielosun/p/6684775.html&quot;&gt;Java多线程：synchronized的可重入性&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;扩展知识点3：作用范围&quot;&gt;扩展知识点3：作用范围&lt;/h2&gt;
&lt;p&gt;synchronized支持三种用法：修饰静态方法、修饰实例方法、修饰代码块，前两种分别锁类对象、锁对象实例，最后一种根据传入的值来决定锁什么。&lt;br/&gt;synchronized是基于java的对象头实现的，从字节码可以看出包括了一对进入&amp;amp;退出的监视器。&lt;br/&gt;&lt;a href=&quot;https://blog.csdn.net/javazejian/article/details/72828483&quot;&gt;深入理解Java并发之synchronized实现原理&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;扩展知识点4：分布式环境synchronized的意义&quot;&gt;扩展知识点4：分布式环境synchronized的意义&lt;/h2&gt;
&lt;p&gt;单看应用所运行的的单个宿主机，仍然可能有多线程的处理模式，在这个前提下使用并发相关技术是必须的。&lt;/p&gt;
&lt;h2 id=&quot;扩展知识点5：哪些方法释放资源，释放锁&quot;&gt;扩展知识点5：哪些方法释放资源，释放锁&lt;/h2&gt;
&lt;p&gt;所谓资源，指的是系统资源。&lt;/p&gt;
&lt;p&gt;wait(): 线程进入阻塞状态，释放资源，释放锁，Object类final方法（notify/notifyAll一样，不可改写）。&lt;br/&gt;sleep(): 线程进入阻塞态，释放资源，（如果在synchronized中）不释放锁，进入阻塞状态，唤醒随机线程，Thread类静态native方法。&lt;br/&gt;yield(): 线程进入就绪态，释放资源，（如果在synchronized中）不释放锁，进入可执行状态，选择优先级高的线程执行，Thread类静态native方法。&lt;br/&gt;如果线程产生的异常没有被捕获，会释放锁。&lt;br/&gt;&lt;a href=&quot;https://blog.csdn.net/u012813201/article/details/73467831&quot;&gt;sleep和yield的比较&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;可以进一步地将阻塞划分为同步阻塞——进入synchronized时没获取到锁、等待阻塞——wait()、其他阻塞——sleep()/join()，可以参考&lt;a href=&quot;https://www.cnblogs.com/miniSimple/p/12269950.html&quot;&gt;线程的状态及sleep、wait等方法的区别&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;再进一步地，Java线程状态转移可以用下图表示（图源《Java 并发编程艺术》4.1.4 节）&lt;br/&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/228024/202006/228024-20200608023927712-1749255378.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;WAITING状态的线程是不会消耗CPU资源的。&lt;/p&gt;

&lt;h2 id=&quot;理论篇&quot;&gt;理论篇&lt;/h2&gt;
&lt;p&gt;本节参考了《Java并发编程实战》8.2节，也可以结合&lt;a href=&quot;https://www.jianshu.com/p/f30ee2346f9f&quot;&gt;面试问我，创建多少个线程合适？我该怎么说&lt;/a&gt;帮助理解，其中的计算题比较有价值。&lt;/p&gt;
&lt;h3 id=&quot;前置知识&quot;&gt;前置知识&lt;/h3&gt;
&lt;p&gt;I/O密集型任务：I/O任务执行时CPU空闲。&lt;br/&gt;CPU密集型任务：进行计算&lt;br/&gt;有的任务是二者兼备的。为了便于分析，不考虑。&lt;/p&gt;
&lt;h3 id=&quot;定性分析&quot;&gt;定性分析&lt;/h3&gt;
&lt;p&gt;场景：单核单线程/单核多线程/多核多线程。单核多线程+CPU密集型不能提升执行效率，多核+CPU密集型任务可以；单核多线程+I/O密集型可以提升执行效率。&lt;br/&gt;因此，I/O耗时越多，线程也倾向于变多来充分利用IO等待时间。&lt;/p&gt;
&lt;h3 id=&quot;定量分析&quot;&gt;定量分析&lt;/h3&gt;
&lt;p&gt;对于CPU密集型，那么&lt;code&gt;线程数量=CPU 核数（逻辑）&lt;/code&gt;即可。特别的，为了防止线程在程序运行异常时不空转，额外多设一个线程&lt;code&gt;线程数量 = CPU 核数（逻辑）+ 1&lt;/code&gt;&lt;br/&gt;对于I/O密集型，&lt;code&gt;最佳线程数 = CPU核数 * (1/CPU利用率) = CPU核数 * (1 + I/O耗时/CPU耗时)&lt;/code&gt;&lt;br/&gt;为什么&lt;code&gt;CPU利用率=1/(1+ I/O耗时/CPU耗时)&lt;/code&gt;？简单推导一下：&lt;/p&gt;
&lt;p&gt;&lt;code&gt;1/(1+ I/O耗时/CPU耗时) = 1/((CPU耗时+I/O耗时)/ CPU耗时) = CPU耗时/总耗时 = CPU利用率&lt;/code&gt;&lt;/p&gt;
&lt;h3 id=&quot;如何获取参数cpu利用率？&quot;&gt;如何获取参数——CPU利用率？&lt;/h3&gt;
&lt;p&gt;因为利用率不是一成不变的，需要通过全面的系统监控工具（如SkyWalking、CAT、zipkin），并长期进行调整观测。&lt;br/&gt;可以先取2N即2倍核数，此时即假设I/O耗时/CPU耗时=1:1，再进行调优。&lt;/p&gt;
&lt;h3 id=&quot;阿姆达尔定律&quot;&gt;阿姆达尔定律&lt;/h3&gt;
&lt;p&gt;CPU并发处理时性能提升上限。&lt;br/&gt;&lt;code&gt;S=1/(1-a+a/n)&lt;/code&gt;&lt;br/&gt;其中，a为并行计算部分所占比例，n为并行处理结点个数。&lt;br/&gt;&lt;a href=&quot;https://blog.csdn.net/u012558400/article/details/53419791&quot;&gt;简单粗暴理解【阿姆达尔定律】&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;java线程池篇&quot;&gt;Java线程池篇&lt;/h2&gt;
&lt;h3 id=&quot;基本属性&quot;&gt;基本属性&lt;/h3&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;/**
 * 使用给定的初始参数和默认线程工厂创建一个新的ThreadPoolExecutor ，并拒绝执行处理程序。 使用Executors工厂方法之一可能更方便，而不是这种通用构造函数。
参数
 *  corePoolSize - 即使空闲时仍保留在池中的线程数，除非设置 allowCoreThreadTimeOut
 *  maximumPoolSize - 池中允许的最大线程数
 *  keepAliveTime - 当线程数大于核心时，这是多余的空闲线程在终止之前等待新任务的最大时间。
 *  unit - keepAliveTime参数的时间单位
 *  workQueue - 在执行任务之前用于保存任务的队列。 该队列将仅保存execute方法提交的Runnable任务。
 * threadFactory - 执行程序创建新线程时使用的工厂
 */
public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&amp;lt;Runnable&amp;gt; workQueue, ThreadFactory threadFactory)

&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;常见线程池&quot;&gt;常见线程池&lt;/h3&gt;
&lt;p&gt;由java.util.concurrent.Executors创建的线程池比较常用，而不是使用ThreadPoolExecutor的构造方法。&lt;/p&gt;
&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;名称&lt;/th&gt;
&lt;th&gt;特性&lt;/th&gt;
&lt;/tr&gt;&lt;/thead&gt;&lt;tbody readability=&quot;4&quot;&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;newFixedThreadPool&lt;/td&gt;
&lt;td&gt;线程池大小为固定值&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;newSingleThreadExecutor&lt;/td&gt;
&lt;td&gt;线程池大小固定为1&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;newCachedThreadPool&lt;/td&gt;
&lt;td&gt;线程池大小初始为0，默认最大值为MAX INTEGER&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;newScheduledExecutor&lt;/td&gt;
&lt;td&gt;延迟执行任务或按周期重复执行任务&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;h3 id=&quot;线程工厂的作用&quot;&gt;线程工厂的作用&lt;/h3&gt;
&lt;p&gt;用来创建线程，统一在创建线程时设置一些参数，如是否守护线程。线程一些特性等，如优先级。&lt;br/&gt;可参考&lt;a href=&quot;https://www.cnblogs.com/bjlhx/p/7609100.html&quot;&gt;004-多线程-JUC线程池-ThreadFactory线程工厂&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;并发容器可以说是一个面试时的高频问题了，网络上也有很多介绍，这里就不重复解读，将相关的知识整理一下，边看源码边读文章效果会很好。&lt;br/&gt;先提一句，Vector是线程安全的，为啥现在不推荐用呢？看源码可以知道，它将大部分方法都加了synchronized，牺牲了性能换取线程安全，是不可取的。如果真的有需要线程安全的容器，可以用Collections.synchronizedList()来手动给list加synchronized。&lt;/p&gt;
&lt;h2 id=&quot;concurrenthashmap&quot;&gt;ConcurrentHashMap&lt;/h2&gt;
&lt;p&gt;先重点介绍Map的两个实现类HashMap和ConcurrentHashMap&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt; public final boolean equals(Object o) {
     if (o == this)
         return true;
     if (o instanceof Map.Entry) {
         Map.Entry&amp;lt;?,?&amp;gt; e = (Map.Entry&amp;lt;?,?&amp;gt;)o;
         if (Objects.equals(key, e.getKey()) &amp;amp;&amp;amp;
             Objects.equals(value, e.getValue()))
             return true;
     }
     return false;
 }
&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;concurrentlinkedqueue&quot;&gt;ConcurrentLinkedQueue&lt;/h2&gt;
&lt;p&gt;ConcurrentLinkedQueue使用CAS无锁操作，保证入队出队的线程安全，但不保证遍历时的线程安全。遍历要想线程安全需要单独加锁。&lt;br/&gt;由于算法的特性，这个容器的尾结点是有延迟的，tail不一定是尾节点，但p.next == null的节点一定是尾结点。&lt;br/&gt;入队出队操作很抽象，需要画图帮助理解源码，对应的源码分析可参考&lt;a href=&quot;https://www.jianshu.com/p/231caf90f30b&quot;&gt;并发容器-ConcurrentLinkedQueue详解&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;抽象队列同步器AbstractQueuedSynchronizer（AQS）是JUC中很多并发工具类的基础，用来抽象各种并发控制行为，如ReentranLock、Semaphore。&lt;br/&gt;之前试着直接读源码，效果不太好，还是建议结合质量较高的文章来读，这里推荐一篇：&lt;a href=&quot;https://www.cnblogs.com/waterystone/p/4920797.html&quot;&gt;Java并发之AQS详解&lt;/a&gt;，并且作者还在不断更新。&lt;br/&gt;这里简单记录一下总结的点。&lt;/p&gt;
&lt;h2 id=&quot;结构特点&quot;&gt;结构特点&lt;/h2&gt;
&lt;ul&gt;&lt;li&gt;volatile int state标记位，标识当前的同步状态。具体的用法和使用AQS的工具类有关。同时，在做CAS的时候，state的状态变更是通过计算该变量在对象的偏移量来设置的。&lt;/li&gt;
&lt;li&gt;CLH队列。CLH锁（Craig，Landin andHagersten）是一种在SMP（Symmetric Multi-Processor对称多处理器）架构下基于单链表的高性能的自旋锁，队列中每个节点代表一个自旋的线程，每个线程只需在代表前一个线程的节点上的布尔值locked自旋即可，如图&lt;br/&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/228024/202006/228024-20200609012131575-1801591266.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;br/&gt;图源和CLH的详解见算法：&lt;a href=&quot;https://blog.csdn.net/claram/article/details/83828768&quot;&gt;CLH锁的原理及实现&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;exclusiveOwnerThread独占模式的拥有者，记录现在是哪个线程占用这个AQS。&lt;/li&gt;
&lt;/ul&gt;&lt;h2 id=&quot;操作特点&quot;&gt;操作特点&lt;/h2&gt;
&lt;ul&gt;&lt;li&gt;对state使用&amp;gt;0和&amp;lt;0的判断，初看代码很难看懂，这么写的原因是&lt;code&gt;负值表示结点处于有效等待状态，而正值表示结点已被取消&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;大量的CAS：无论是获取锁、入队、获取锁失败后的自旋，全部是依赖CAS实现的。&lt;/li&gt;
&lt;li&gt;没有使用synchronized：不难理解，如果使用了同步块，那么其实现ReentranLock就没有和synchronized比较的价值了。不过这一点很少有文章专门提到。&lt;/li&gt;
&lt;li&gt;LockSupport类的unpark()/park()方法的使用：回忆上文提到的线程状态，如果线程获取不到AQS控制的资源，需要将线程置于waiting，对应可选的方法是wait()/join()/park()。在AQS这个场景下，显然一没有synchronized，二没有显式的在同一个代码块中用join处理多线程（借助队列来处理线程，线程相互之间不感知），那么只有park()才能达到目的。&lt;/li&gt;
&lt;/ul&gt;&lt;h2 id=&quot;处理流程&quot;&gt;处理流程&lt;/h2&gt;
&lt;h3 id=&quot;获取资源acquireint&quot;&gt;获取资源acquire(int)&lt;/h3&gt;
&lt;ol&gt;&lt;li&gt;尝试获取资源(改写state)，成功则返回&lt;/li&gt;
&lt;li&gt;CAS（失败则自旋）加入等待队列队尾&lt;/li&gt;
&lt;li&gt;在队列中自旋，尝试获取一次资源（前提：队头+ tryAcquire()成功），每次失败都会更改线程状态为waiting。自旋时会看看前驱有没有失效的节点（即不再请求资源的），如果有就插队到最前面并把前面无效节点清理掉便于gc&lt;/li&gt;
&lt;li&gt;waiting状态中不响应中断，获取资源后才会补一个自我中断selfInterrupt (调用Thread.currentThread().interrupt())&lt;/li&gt;
&lt;/ol&gt;&lt;h3 id=&quot;释放资源releaseint&quot;&gt;释放资源release(int)&lt;/h3&gt;
&lt;ol&gt;&lt;li&gt;尝试释放，成功则处理后续动作，失败直接返回false&lt;/li&gt;
&lt;li&gt;唤醒（unpark）等待队列的下一个线程。如果当前节点没找到后继，则从队尾tail从后往前找。&lt;/li&gt;
&lt;/ol&gt;&lt;h3 id=&quot;共享模式获取资源acquiresharedint&quot;&gt;共享模式获取资源acquireShared(int)&lt;/h3&gt;
&lt;p&gt;除了抽象方法tryAcquireShared()以外，基本和acquire(int)一致。&lt;br/&gt;在等待队列中获取资源后，会调用独有的setHeadAndPropagate()方法，将这个节点设为头结点的同时，检查后续节点是否可以获取资源。&lt;/p&gt;
&lt;h3 id=&quot;共享模式释放资源releaseshared&quot;&gt;共享模式释放资源releaseShared()&lt;/h3&gt;
&lt;p&gt;和release(int)区别在于，唤醒后继时，不要求当前线程节点状态为0。举例：当前线程A原先拥有5个资源，释放1个，后继的等待线程B刚好需要1个，那么此时A、B就可以并行了。&lt;/p&gt;
&lt;h2 id=&quot;未实现的方法&quot;&gt;未实现的方法&lt;/h2&gt;
&lt;p&gt;为了便于使用AQS的类更加个性化，AQS有一下方法直接抛UnsupportedOperationException。&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;isHeldExclusively()&lt;/li&gt;
&lt;li&gt;tryAcquire()&lt;/li&gt;
&lt;li&gt;tryRelease()&lt;/li&gt;
&lt;li&gt;tryAcquireShared()&lt;/li&gt;
&lt;li&gt;tryReleaseShared()&lt;br/&gt;不写成abstract方法的原因是，避免强迫不需要对应方法的类实现这些方法。比如要写一个独占的锁，那么就不需要实现共享模式的方法。&lt;/li&gt;
&lt;/ul&gt;&lt;h2 id=&quot;aqs小结&quot;&gt;AQS小结&lt;/h2&gt;
&lt;p&gt;读完源码总结一下，AQS是一个维护资源和请求资源的线程之间的关系的队列。对于资源（有序或无序的）获取和释放已经提取成了线程的出入队方法，这个队列同时维护上线程的自旋状态和管理线程间的睡眠唤醒。&lt;/p&gt;
&lt;h2 id=&quot;应用&quot;&gt;应用&lt;/h2&gt;
&lt;p&gt;本节可以看作为《JAVA并发变成实战》14.6的引申。&lt;/p&gt;
&lt;h3 id=&quot;reentrantlock&quot;&gt;ReentrantLock&lt;/h3&gt;
&lt;p&gt;用内部类Sync实现AQS，Sync实现ReentrantLock的行为。Sync又有FairSync和UnfairSync两种实现。FairSync，lock对应aquire(1)；UnfairSync，lock先CAS试着获取一次，不行再aquire(1)。&lt;br/&gt;实际上，ReentrantLock的公平/非公平锁只在首次lock时有区别，入队后唤醒仍是按顺序的。可以参考&lt;a href=&quot;https://blog.csdn.net/mazhen1991/article/details/90450790&quot;&gt;reentrantLock公平锁和非公平锁源码解析&lt;/a&gt;&lt;br/&gt;Sync只实现了独占模式。&lt;/p&gt;
&lt;p&gt;注意：CyclicBarrier直接用了ReentrantLock，没有直接用AQS。&lt;/p&gt;
&lt;h3 id=&quot;semaphore&quot;&gt;Semaphore&lt;/h3&gt;
&lt;p&gt;和ReentrantLock类似，Semaphore也有一个内部类Sync，但相反的是这个Sync只实现了共享模式的acquire()/release()。&lt;br/&gt;Semaphore在acquire()/release()时会计算资源余量并设置，其中unfair模式下的acquire会无条件自旋CAS，fair模式下只有在AQS里不存在排队中的后继的情况下才会CAS，否则自旋。&lt;/p&gt;
&lt;h3 id=&quot;countdownlatch&quot;&gt;CountDownLatch&lt;/h3&gt;
&lt;p&gt;同样有一个内部类Sync，但是不再区分fair/unfair，并且是共享模式的。&lt;br/&gt;await()调用的是acquireSharedInterruptibly()，自然也存在自旋的可能，只是编程时一般不这么用。countDown()时释放一个资源继续在releaseShared()里自旋直到全部释放。&lt;/p&gt;
&lt;h3 id=&quot;futuretask&quot;&gt;FutureTask&lt;/h3&gt;
&lt;p&gt;新版的FutureTask已经重写，不再使用AQS，这里就不再提了。&lt;/p&gt;
&lt;h3 id=&quot;reentrantreadwritelock&quot;&gt;ReentrantReadWriteLock&lt;/h3&gt;
&lt;p&gt;可重入读写锁，涉及到锁升级，这里没有研究的很透彻，有兴趣可以自行了解。&lt;br/&gt;注意到读锁和写锁是共用同一个Sync的。&lt;/p&gt;

&lt;blockquote readability=&quot;7.7333333333333&quot;&gt;
&lt;p&gt;The Java memory model specifies how the Java virtual machine works with the computer's memory (RAM)。&lt;br/&gt;—— &lt;a href=&quot;http://tutorials.jenkov.com/java-concurrency/java-memory-model.html&quot;&gt;Java Memory Model&lt;/a&gt;&lt;br/&gt;虽然被冠以”模型“，JMM实际上是定义JVM如何与计算机内存协同工作的规范，也可以理解为__指令__与其操作的__数据__的行为。这样，自然而然地引入了指令重排序、变量更改的可见性的探讨。&lt;br/&gt;JMM定义了一个偏序关系，称之为happens-before。不满足happens-before的两个操作可以由JVM进行重排序。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&quot;61-什么是偏序关系&quot;&gt;6.1 什么是偏序关系&lt;/h3&gt;
&lt;p&gt;假设 R 是集合 A 上的关系，如果R是自反的、反对称的和传递的，则称 R 是 A 上的一个偏序。&lt;a href=&quot;https://www.jianshu.com/p/b74a49d80b68&quot;&gt;偏序关系&lt;/a&gt;&lt;br/&gt;那么，自反的、反对称的和传递的，又是什么？下面粘贴了百度百科相关词条：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;自反关系：设 R是 A上的一个二元关系，若对于 A中的每一个元素 a， (a,a)都属于 R，则称 R为自反关系。&lt;/li&gt;
&lt;li&gt;反对称关系：集合 A 上的二元关系 R 是反对称的，当且仅当对于X里的任意元素a, b，若a R-关系于 b 且 b R-关系于 a，则a=b。&lt;/li&gt;
&lt;li&gt;传递关系：令R是A上的二元关系，对于A中任意的 ，若 ，且 ，则 ，则称R具有传递性(或称R是传递关系)。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;上面的反对称关系稍微不好理解，转换成逆否命题就好理解了：若a!=b，那么R中不能同存在aRb和bRa。&lt;/p&gt;
&lt;h3 id=&quot;62-偏序关系和jmm&quot;&gt;6.2 偏序关系和JMM&lt;/h3&gt;
&lt;p&gt;将R作为两个操作间的关系，集合A是所有操作的集合，那么就可以理解JMM为什么实际上是一套偏序关系了。&lt;/p&gt;
&lt;h3 id=&quot;63-happens-before规则&quot;&gt;6.3 happens-before规则&lt;/h3&gt;
&lt;p&gt;这部分的说明很多文章都是有差异，比如锁原则，JLS（Java Language Specification，Java语言规范）特指的是监视器锁，只不过显式锁和内置锁有相同的内存语义而已。这里直接摘录原文并配上说明。原文见&lt;a href=&quot;https://docs.oracle.com/javase/specs/jls/se8/html/jls-17.html#jls-17.4.5&quot;&gt;Chapter 17. Threads and Locks&lt;/a&gt;&lt;/p&gt;
&lt;blockquote readability=&quot;7&quot;&gt;
&lt;p&gt;If we have two actions x and y, we write hb(x, y) to indicate that x happens-before y.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote readability=&quot;7&quot;&gt;
&lt;p&gt;If x and y are actions of the same thread and x comes before y in program order, then hb(x, y).&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;There is a happens-before edge from the end of a constructor of an object to the start of a finalizer (§12.6) for that object.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote readability=&quot;7&quot;&gt;
&lt;p&gt;If an action x synchronizes-with a following action y, then we also have hb(x, y).&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote readability=&quot;9&quot;&gt;
&lt;p&gt;If hb(x, y) and hb(y, z), then hb(x, z).&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;The wait methods of class Object (§17.2.1) have lock and unlock actions associated with them; their happens-before relationships are defined by these associated actions.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;It should be noted that the presence of a happens-before relationship between two actions does not necessarily imply that they have to take place in that order in an implementation. If the reordering produces results consistent with a legal execution, it is not illegal.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;For example, the write of a default value to every field of an object constructed by a thread need not happen before the beginning of that thread, as long as no read ever observes that fact.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote readability=&quot;12&quot;&gt;
&lt;p&gt;More specifically, if two actions share a happens-before relationship, they do not necessarily have to appear to have happened in that order to any code with which they do not share a happens-before relationship. Writes in one thread that are in a data race with reads in another thread may, for example, appear to occur out of order to those reads.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;The happens-before relation defines when data races take place.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote readability=&quot;9&quot;&gt;
&lt;p&gt;A set of synchronization edges, S, is sufficient if it is the minimal set such that the transitive closure of S with the program order determines all of the happens-before edges in the execution. This set is unique.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;It follows from the above definitions that:&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;An unlock on a monitor happens-before every subsequent lock on that monitor.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;A write to a volatile field (§8.3.1.4) happens-before every subsequent read of that field.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;A call to start() on a thread happens-before any actions in the started thread.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;All actions in a thread happen-before any other thread successfully returns from a join() on that thread.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;The default initialization of any object happens-before any other actions (other than default-writes) of a program.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;试着翻译一下各项规则：&lt;br/&gt;先定义hb(x, y)表示操作x和操作y的happens-before关系。&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;同一个线程的操作x, y，代码中顺序为x, y，那么hb(x, y)&lt;/li&gt;
&lt;li&gt;对象构造方法要早于终结方法完成&lt;/li&gt;
&lt;li&gt;如果x synchronizes-with y那么hb(x,y)&lt;/li&gt;
&lt;li&gt;传递性，hb(x, y) 且hb(y,z)则hb(x,z)&lt;/li&gt;
&lt;li&gt;同一个监视器锁解锁需要hb所有加锁（注：该规则扩展到显式锁）&lt;/li&gt;
&lt;li&gt;volatile的读hb所有写（该规则扩展到原子操作）&lt;/li&gt;
&lt;li&gt;线程start() hb所有它的启动后的任何动作&lt;/li&gt;
&lt;li&gt;线程中所有操作hb 对它的join()&lt;/li&gt;
&lt;li&gt;对象默认构造器hb对它的读写&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;synchronizes-with又是啥？查阅了一下，表示”这个关系表示一个行为在发生时，它首先把要操作的那些对象同主存同步完毕之后才继续执行“。参考&lt;a href=&quot;https://www.iteye.com/blog/guibin-1172731&quot;&gt;JMM（Java内存模型）中的核心概念&lt;/a&gt;。&lt;br/&gt;JLS上对happens-before的解释翻译过来还是不太好理解，《Java并发编程实战》的解释和&lt;a href=&quot;https://javaedge.blog.csdn.net/article/details/106450450&quot;&gt;Happens-beofre 先行发生原则（JVM 规范）&lt;/a&gt;一样，可以参考下。&lt;/p&gt;
&lt;p&gt;最后可以发现，JMM只是一套规则，并没有提到具体的实现，程序员知道Java有这一重保证即可。&lt;/p&gt;

&lt;h2 id=&quot;71-threadlocal的用法总结&quot;&gt;7.1 ThreadLocal的用法总结&lt;/h2&gt;
&lt;p&gt;应用场景：在多线程下替代类的静态变量(static)，在多线程环境进行单个 &lt;strong&gt;类&lt;/strong&gt; 的数据隔离。&lt;/p&gt;
&lt;h2 id=&quot;为什么推荐使用static修饰threadlocal？&quot;&gt;为什么推荐使用static修饰ThreadLocal？&lt;/h2&gt;
&lt;p&gt;这时才能保证&quot;一个线程，一个ThreadLocal&quot;，否则便成了“一个线程，（多个对象实例时）多个ThreadLocal”。&lt;br/&gt;可能会有内存泄漏：ThreadLocalMap的key(Thread对象)是弱引用，但value不是，如果key被回收，value还在。解法是手动remove掉。&lt;br/&gt;（本节参考了《Java并发编程实战》）&lt;/p&gt;
&lt;h2 id=&quot;72-countdownlatch和cyclicbarrier区别&quot;&gt;7.2 CountDownLatch和CyclicBarrier区别&lt;/h2&gt;
&lt;p&gt;&lt;a href=&quot;https://blog.csdn.net/tolcf/article/details/50925145&quot;&gt;https://blog.csdn.net/tolcf/article/details/50925145&lt;/a&gt;&lt;br/&gt;CountDownLatch的子任务调用countDown后会继续执行直至该线程结束。&lt;br/&gt;CyclicBarrier的子任务await时会暂停执行；可重复使用，即await的数目达到设置的值时，唤醒所有await的线程进行下一轮。&lt;/p&gt;
&lt;h2 id=&quot;73-reentrantlock用了cas但为什么不是乐观锁？&quot;&gt;7.3 ReentrantLock用了CAS但为什么不是乐观锁？&lt;/h2&gt;
&lt;p&gt;&lt;a href=&quot;https://blog.csdn.net/qq_35688140/article/details/101223701&quot;&gt;https://blog.csdn.net/qq_35688140/article/details/101223701&lt;/a&gt;&lt;br/&gt;我的看法：因为仍有可能造成阻塞，而乐观锁更新失败则会直接返回（CAS允许自旋）。&lt;br/&gt;换一个角度，悲观锁是预先做最坏的设想——一定会有其他任务并发，那么就先占好坑再更新；乐观锁则是认为不一定有并发，更新时判断再是否有问题。这样看来ReentrantLock从使用方式上来说是悲观锁。&lt;/p&gt;
&lt;h2 id=&quot;74-双重检查加锁&quot;&gt;7.4 双重检查加锁&lt;/h2&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;public classDoubleCheckedLocking{ //1
      private static Instance instance; //2
      public staticI nstance getInstance(){ //3
            if(instance==null){ //4:第一次检查
                  synchronized(DoubleCheckedLocking.class){ //5:加锁
                        if(instance==null) //6:第二次检查
                              instance=newInstance(); //7:问题的根源出在这里
                  } //8
            }//9
            return instance;
      }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;问题&quot;&gt;问题&lt;/h3&gt;
&lt;p&gt;一个线程看到另一个线程初始化该类的部分构造的对象，即以上代码注释第4处这里读到非null但未完全初始化&lt;/p&gt;
&lt;h3 id=&quot;原因&quot;&gt;原因&lt;/h3&gt;
&lt;p&gt;注释第7处，创建对象实例的三步指令1.分配内存空间2.初始化3.引用指向分配的地址，2和3可能重排序&lt;/p&gt;
&lt;h3 id=&quot;解决&quot;&gt;解决&lt;/h3&gt;
&lt;p&gt;方案1，给instance加violatile&lt;br/&gt;方案2，使用占位类，在类初始化时初始化对象，如下&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;public class InstanceFactory {
      private static class InstanceHolder{
            public static Instance instance= newInstance();
      }
      public static Instance getInstance() {
            return InstanceHolder.instance;　　//这里将导致InstanceHolder类被初始化
      }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;75-futuretask&quot;&gt;7.5 FutureTask&lt;/h2&gt;
&lt;p&gt;FutureTask是Future的实现类，可以使用Future来接收线程池的submit()方法，也可以直接用FutureTask封装任务，作为submit()的参数。具体的用法可以参考&lt;a href=&quot;https://www.cnblogs.com/dolphin0520/p/3949310.html&quot;&gt;Java并发编程：Callable、Future和FutureTask&lt;/a&gt; 。&lt;br/&gt;新版的FutureTask不再使用AQS。&lt;br/&gt;FutureTask设置了当前工作线程，对于其任务维护了一个内部状态转换状态机，通过CAS做状态判断和转换。&lt;br/&gt;当其他线程来get()时，如果任务未完成则放入等待队列，自旋直到取到结果（for循环+LockSupport.park()），否则直接取结果。&lt;br/&gt;具体实现原理可以参考&lt;a href=&quot;https://www.jianshu.com/p/36f8f3b8ee55&quot;&gt;《线程池系列一》-FutureTask原理讲解与源码剖析&lt;/a&gt;。&lt;/p&gt;
&lt;h2 id=&quot;76-jdk16锁优化之轻量级锁和偏向锁&quot;&gt;7.6 JDK1.6锁优化之轻量级锁和偏向锁&lt;/h2&gt;
&lt;p&gt;实际上二者是有联系的，都是基于mark word实现。这个转换关系可以用《深入理解Java虚拟机》第十三章的插图表现&lt;br/&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/228024/202006/228024-20200611031552047-1877485354.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;br/&gt;但是这个图没有体现轻量级锁释放后，仍可恢复为可偏向的。&lt;/p&gt;
&lt;h2 id=&quot;77-问题排查三板斧&quot;&gt;7.7 问题排查三板斧&lt;/h2&gt;
&lt;ol&gt;&lt;li&gt;top查看内存占用率，-H可以看线程（不会完整展示），-p [pid]看指定进程的线程&lt;br/&gt;注意：linux线程和进程id都是在pid这一列展示的。&lt;/li&gt;
&lt;li&gt;pstack跟踪进程栈，strace查看进程的系统操作。多次执行pstack来观察进程是不是总是处于某种上下文中。&lt;/li&gt;
&lt;li&gt;jps直接获取java进程id，jstat看java进程情况。jstate可用不同的参数来查看不同纬度的信息：类加载情况、gc统计、堆内存统计、新生代/老年代内存统计等，具体可以参考&lt;a href=&quot;https://www.cnblogs.com/sxdcgaq8080/p/11089841.html&quot;&gt;【JVM】jstat命令详解---JVM的统计监测工具&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;jstack打印java线程堆栈，和pstack展示方式很像，是java纬度的&lt;/li&gt;
&lt;li&gt;jmap打印java内存情况，-dump可以生成dump文件&lt;/li&gt;
&lt;li&gt;分析dump文件，如MATt&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;原题目和详解参考&lt;a href=&quot;https://leetcode-cn.com/problemset/concurrency/&quot;&gt;Concurrency - 力扣&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;1114按序打印&quot;&gt;1114.按序打印&lt;/h2&gt;
&lt;p&gt;按照指定次序完成一系列动作，可以看做是buffer为1的1对1生产者消费者模型。&lt;/p&gt;
&lt;h2 id=&quot;1115交替打印foobar&quot;&gt;1115.交替打印FooBar&lt;/h2&gt;
&lt;p&gt;交替执行(不完全是生产者-消费者模型)某些动作。&lt;br/&gt;可用的解法：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;synchronized&lt;/li&gt;
&lt;li&gt;Semaphore&lt;/li&gt;
&lt;li&gt;CountDownLatch&lt;/li&gt;
&lt;li&gt;CyclicBarrier&lt;/li&gt;
&lt;li&gt;Lock&lt;/li&gt;
&lt;/ul&gt;&lt;h2 id=&quot;1116打印零与奇偶数0102&quot;&gt;1116.打印零与奇偶数:0102...&lt;/h2&gt;
&lt;p&gt;和1114类似&lt;/p&gt;
&lt;h2 id=&quot;1188-设计有限阻塞队列&quot;&gt;1188. 设计有限阻塞队列&lt;/h2&gt;
&lt;p&gt;注意: 使用synchronize解法时，wait()应置于while中循环判断.&lt;br/&gt;如果只用if，唤醒后不再次判断dequeue可能NPE&lt;br/&gt;本题可以加深理解为什么要用while&lt;/p&gt;
&lt;h2 id=&quot;1195-交替打印字符串&quot;&gt;1195. 交替打印字符串&lt;/h2&gt;
&lt;p&gt;根据AC的解法推断, 每个线程只调用对应方法一次，因此需要在方法内部循环&lt;br/&gt;不推荐只用synchronized,四个线程按顺序打印, 如果使用单一的锁很容易饥饿导致超时&lt;/p&gt;
&lt;p&gt;推荐解法：&lt;br/&gt;AtomicInteger无锁解法&lt;br/&gt;CylicBarrier高效解法&lt;br/&gt;Semaphore加锁&lt;/p&gt;
&lt;h2 id=&quot;1279-红绿灯路口&quot;&gt;1279. 红绿灯路口&lt;/h2&gt;
&lt;p&gt;题目难懂，暗含条件：车来时红绿灯不是绿的，则强制变绿通过。红绿灯本身的时间没有严格控制&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.jianshu.com/p/a1ebab8ce78a&quot;&gt;什么是分布式锁&lt;/a&gt;&lt;br/&gt;&lt;a href=&quot;https://www.jianshu.com/p/31d3de863ff7&quot;&gt;一文了解分布式锁&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.cnblogs.com/yanlong300/p/8986041.html&quot;&gt;并发研究之CPU缓存一致性协议(MESI)&lt;/a&gt;&lt;br/&gt;&lt;a href=&quot;https://blog.csdn.net/luanmousheng/article/details/77816412?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.nonecase&amp;amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.nonecase&quot;&gt;线程池原理（四）：ScheduledThreadPoolExecutor&lt;/a&gt;&lt;br/&gt;&lt;a href=&quot;https://www.jianshu.com/p/2d07e24efa37&quot;&gt;一半是天使一半是魔鬼的Unsafe类详解&lt;/a&gt; —— unsafe类都有什么？用偏移量直接访问、线程操作、内存管理和内存屏障、CAS&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.jianshu.com/p/ca98ca34b47e&quot;&gt;Java并发高频面试题&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;</description>
<pubDate>Thu, 11 Jun 2020 18:14:00 +0000</pubDate>
<dc:creator>五岳</dc:creator>
<og:description>主要包括深入分析wait()/notify()/notifyAll()实现生产者消费者模式、线程数调优、并发容器、AQS、JMM五个大专题，七个小专题，leetCode并发题简介三个部分，基本对大多数</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/wuyuegb2312/p/12829280.html</dc:identifier>
</item>
<item>
<title>Mybatis详解(二) sqlsession的创建过程 - TimothyRasinski</title>
<link>http://www.cnblogs.com/yanzezhong/p/13097082.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/yanzezhong/p/13097082.html</guid>
<description>&lt;h2 id=&quot;我们处于的位置&quot;&gt;我们处于的位置&lt;/h2&gt;
&lt;p&gt;我们要清楚现在的情况.&lt;/p&gt;
&lt;p&gt;现在我们已经调用了&lt;code&gt;SqlSessionFactoryBuilder&lt;/code&gt;的build方法生成了&lt;code&gt;SqlSessionFactory&lt;/code&gt; 对象.&lt;/p&gt;
&lt;p&gt;但是如标题所说,要想生成&lt;code&gt;sqlsession&lt;/code&gt;还要另一步&lt;code&gt;SqlSessionFactory&lt;/code&gt; 调用&lt;code&gt;openSession()&lt;/code&gt;方法生成&lt;code&gt;sqlsession&lt;/code&gt;;&lt;/p&gt;
&lt;p&gt;这就要从上一部分代码讲起&lt;/p&gt;
&lt;p&gt;上文讲到&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://imgconvert.csdnimg.cn/aHR0cDovL3VwbG9hZC1pbWFnZXMuamlhbnNodS5pby91cGxvYWRfaW1hZ2VzLzQyMzY1NTMtMTlkMzA5OTM5YjhiOGE5OC5wbmc?x-oss-process=image/format,png&quot; alt=&quot;img&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;我们创建的实际上是一个叫做&lt;code&gt;DefaultSqlSessionFactory&lt;/code&gt;的类,实际上他是一个&lt;code&gt;SqlSessionFactory&lt;/code&gt;接口(没错,这玩应是接口)的实现类.&lt;/p&gt;
&lt;p&gt;既然sqlsession是由opensession产生的,那我们就先看这个方法.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://imgconvert.csdnimg.cn/aHR0cDovL3VwbG9hZC1pbWFnZXMuamlhbnNodS5pby91cGxvYWRfaW1hZ2VzLzQyMzY1NTMtYzA3YWZkY2RhODY3NWI4MC5wbmc?x-oss-process=image/format,png&quot; alt=&quot;img&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;说一嘴题外话就是自动提交也是在这个部分设置的,下面是如果你设置了autocommit的情况.&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;public SqlSession openSession(boolean autoCommit) {
  //this.configuration.getDefaultExecutorType()值为 ExecutorType.SIMPLE;
    return this.openSessionFromDataSource(this.configuration.getDefaultExecutorType(), (TransactionIsolationLevel)null, autoCommit);
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;参数中 configuration 获取了默认的执行器 “SIMPLE”.&lt;/strong&gt;&lt;/p&gt;
&lt;hr/&gt;&lt;h2 id=&quot;defaultsqlsessionfactory类&quot;&gt;&lt;code&gt;DefaultSqlSessionFactory&lt;/code&gt;类&lt;/h2&gt;
&lt;p&gt;调用了一个同一个类中&lt;code&gt;openSessionFromDataSource&lt;/code&gt;方法.&lt;/p&gt;
&lt;p&gt;在这个类中是如下执行流程&lt;/p&gt;
&lt;p&gt;所要知道的一部分知识.&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.cnblogs.com/hellowhy/p/9674280.html&quot;&gt;environments运行环境&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://blog.csdn.net/javageektech/article/details/99518588&quot;&gt;MyBatis 核心配置综述之 Configuration详解&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;其实就是数据库连接那个部分.&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;private SqlSession openSessionFromDataSource(ExecutorType execType, TransactionIsolationLevel level, boolean autoCommit) {
  Transaction tx = null;
  try {
    //从configuration对象中得到环境配置的对象
    final Environment environment = configuration.getEnvironment();
    //这个对象被用来创建一个事务工厂-&amp;gt;一号分支
    final TransactionFactory transactionFactory = getTransactionFactoryFromEnvironment(environment);
  //事务工厂创建一个事务对象-&amp;gt;二号分支
    tx = transactionFactory.newTransaction(environment.getDataSource(), level, autoCommit);
    //而 configurationye 则会根据事务对象和执行器类型创建一个执行器。
    -&amp;gt;三号分支
    final Executor executor = configuration.newExecutor(tx, execType);
    //返回一个默认的DefaultSqlSession对象
    -&amp;gt;四号分支
    return new DefaultSqlSession(configuration, executor, autoCommit);
  } catch (Exception e) {
    closeTransaction(tx); // may have fetched a connection so lets call close()
    throw ExceptionFactory.wrapException(&quot;Error opening session.  Cause: &quot; + e, e);
  } finally {
    ErrorContext.instance().reset();
  }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;现在我们要从一号分支开始&lt;/p&gt;
&lt;hr/&gt;&lt;h2 id=&quot;一号分支&quot;&gt;一号分支&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;final TransactionFactory transactionFactory = getTransactionFactoryFromEnvironment(environment);&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;这个代码如下:&lt;/p&gt;
&lt;p&gt;我们发现有两种可能性.&lt;/p&gt;
&lt;p&gt;如果传进来的值没有设置标签那么他会执行&lt;code&gt;ManagedTransactionFactory()&lt;/code&gt;而反之则会执行&lt;code&gt;environment.getTransactionFactory()&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;这两者产生的对象都实现了 &lt;code&gt;TransactionFactory&lt;/code&gt;接口.&lt;/p&gt;
&lt;p&gt;这里&lt;code&gt;ManagedTransactionFactory()&lt;/code&gt;是没有标签时生成的对象.其核心就是一句&lt;/p&gt;
&lt;p&gt;&lt;code&gt;private boolean closeConnection = true;&lt;/code&gt;的属性.&lt;/p&gt;
&lt;p&gt;我们不必过于关注这个部分.&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;private TransactionFactory getTransactionFactoryFromEnvironment(Environment environment) {
  if (environment == null || environment.getTransactionFactory() == null) {
   //如果没有目标标签
    return new ManagedTransactionFactory();
  }
  //如果有目标标签
  return environment.getTransactionFactory();
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;environment.getTransactionFactory()&lt;/code&gt;产生的东西才是重点.&lt;/p&gt;
&lt;p&gt;调用环境对象的&lt;code&gt;getTransactionFactory&lt;/code&gt;方法，该方法和我们配置的一样返回了一个 &lt;code&gt;JdbcTransactionFactory&lt;/code&gt;，而实际上，&lt;code&gt;TransactionFactory&lt;/code&gt; 只有2个实现类，一个是 &lt;code&gt;ManagedTransactionFactory&lt;/code&gt; (没有标签时返回的)，一个是 &lt;code&gt;JdbcTransactionFactory&lt;/code&gt;(有标签时返回的)。&lt;/p&gt;
&lt;p&gt;至此一号分支结束,从此看来,一号分支实际上是将environment对象包装成一个工厂对象.&lt;/p&gt;
&lt;p&gt;请返回一号分支之前部分继续.&lt;/p&gt;
&lt;hr/&gt;&lt;h2 id=&quot;分支二&quot;&gt;分支二&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;tx = transactionFactory.newTransaction(environment.getDataSource(), level, autoCommit);&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;我们回到&lt;code&gt;openSessionFromDataSource&lt;/code&gt;方法，获取了 &lt;code&gt;JdbcTransactionFactory&lt;/code&gt; 后，调用 &lt;code&gt;JdbcTransactionFactory&lt;/code&gt; 的&lt;code&gt;newTransaction&lt;/code&gt;方法创建一个事务对象.&lt;/p&gt;
&lt;p&gt;当然因为代码中采用&lt;code&gt;TransactionFactory&lt;/code&gt; 接口作为声明对象.所以无论分之一传回来的是哪个工厂对象.在分支二中都可以执行.&lt;/p&gt;
&lt;p&gt;我们先讲 &lt;code&gt;JdbcTransactionFactory&lt;/code&gt;的情况.&lt;/p&gt;
&lt;p&gt;分支二中调用的是这个&lt;code&gt;newTransaction&lt;/code&gt;方法.(还有一个重载的)&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;public Transaction newTransaction(Connection conn) {
  return new JdbcTransaction(conn);
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;这就到了另一个类中&lt;code&gt;JdbcTransaction&lt;/code&gt;中.&lt;/p&gt;
&lt;h2 id=&quot;jdbctransaction&quot;&gt;JdbcTransaction&lt;/h2&gt;
&lt;p&gt;我删掉其中的实现代码&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;public class JdbcTransaction implements Transaction {

  private static final Log log = LogFactory.getLog(JdbcTransaction.class);

  protected Connection connection;
  protected DataSource dataSource;
  protected TransactionIsolationLevel level;
  protected boolean autoCommmit;

  public JdbcTransaction(DataSource ds, TransactionIsolationLevel desiredLevel, boolean desiredAutoCommit) {
    dataSource = ds;
    level = desiredLevel;
    autoCommmit = desiredAutoCommit;
  }

  public JdbcTransaction(Connection connection) {
    this.connection = connection;
  }

  public Connection getConnection() throws SQLException {
  
  }

  public void commit() throws SQLException {
   
  }

  public void rollback() throws SQLException {
    
  }

  public void close() throws SQLException {
    
  }

  protected void setDesiredAutoCommit(boolean desiredAutoCommit) {
   
  }

  protected void resetAutoCommit() {
    
  }

  protected void openConnection() throws SQLException {
   
  }

}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;其实只要看了代码你就会发现,这个类中的方法,和我们调用session的方法高度重合.比如commit,rollback等等.而且还能设置事务的隔离级别&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://imgconvert.csdnimg.cn/aHR0cDovL3VwbG9hZC1pbWFnZXMuamlhbnNodS5pby91cGxvYWRfaW1hZ2VzLzQyMzY1NTMtYzA5MjEyZGU2NDE2ZmY3Zi5wbmc?x-oss-process=image/format,png&quot; alt=&quot;img&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;所以我们有理由认为,这个类就是对jdbc连接部分的封装.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;总结&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;至此分支二结束,我们对于标签在xml中的存在情况,会返回两种截然不同对象.一种是作为jdbc连接封装的&lt;code&gt;JdbcTransaction&lt;/code&gt;对象.另一个则是&lt;code&gt;ManagedTransaction&lt;/code&gt;对象(这个没讲....)&lt;/p&gt;
&lt;hr/&gt;&lt;h2 id=&quot;分支三&quot;&gt;分支三&lt;/h2&gt;
&lt;p&gt;第三分支我们将回到&lt;code&gt;Configuration&lt;/code&gt;对象.&lt;/p&gt;
&lt;h2 id=&quot;configuration对象&quot;&gt;Configuration对象&lt;/h2&gt;
&lt;p&gt;法此时已经创建好事务对象。接下来将事务对象执行器作为参数执行 configuration 的 newExecutor 方法来获取一个 执行器类。我们看看该方法实现：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://imgconvert.csdnimg.cn/aHR0cDovL3VwbG9hZC1pbWFnZXMuamlhbnNodS5pby91cGxvYWRfaW1hZ2VzLzQyMzY1NTMtZjY3MjcyYmNjYzQzYmMwMi5wbmc?x-oss-process=image/format,png&quot; alt=&quot;img&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;首先第一句将判断是否传入了一个excutorType参数,如果没有就用默认的参数.&lt;/p&gt;
&lt;p&gt;也就是 ExecutorType.SIMPLE(前面出现过)，然后根据执行的类型来创建不同的执行器，默认是 SimpleExecutor 执行器.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Mybatis有三种基本的Executor执行器&lt;/strong&gt;:&lt;/p&gt;
&lt;ul readability=&quot;3.5&quot;&gt;&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;SimpleExecutor：每执行一次update或select，就开启一个Statement对象，用完立刻关闭Statement对象。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;2&quot;&gt;
&lt;p&gt;ReuseExecutor：执行update或select，以sql作为key查找Statement对象，存在就使用，不存在就创建，用完后，不关闭Statement对象，而是放置于Map&amp;lt;String, Statement&amp;gt;内，供下一次使用。简言之，就是重复使用Statement对象。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;2&quot;&gt;
&lt;p&gt;BatchExecutor：执行update（没有select，JDBC批处理不支持select），将所有sql都添加到批处理中（addBatch()），等待统一执行（executeBatch()），它缓存了多个Statement对象，每个Statement对象都是addBatch()完毕后，等待逐一执行executeBatch()批处理。与JDBC批处理相同。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;作用范围：Executor的这些特点，都严格限制在SqlSession生命周期范围内。&lt;/p&gt;
&lt;p&gt;然后我们看下一句部分&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;Executor executor;
//看看上文.这是根据传入的内容不同,最终结果是
if (ExecutorType.BATCH == executorType) {
  executor = new BatchExecutor(this, transaction);
} else if (ExecutorType.REUSE == executorType) {
  executor = new ReuseExecutor(this, transaction);
} else {
  executor = new SimpleExecutor(this, transaction);
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;我们先将 BatchExecutor执行器.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://imgconvert.csdnimg.cn/aHR0cDovL3VwbG9hZC1pbWFnZXMuamlhbnNodS5pby91cGxvYWRfaW1hZ2VzLzQyMzY1NTMtYjU4Njc5MDk5MmNlYTM0MC5wbmc?x-oss-process=image/format,png&quot; alt=&quot;img&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;该类包装了事务对象，延迟加载的队列，本地缓存，永久缓存，配置对象，还包装了自己。&lt;/p&gt;
&lt;blockquote readability=&quot;7&quot;&gt;
&lt;p&gt;传入的两个参数分别为存储了配置信息的Configuration对象,以及封装了jdbc中连接数据库部分代码的&lt;code&gt;JdbcTransaction&lt;/code&gt;对象.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;回到 newExecutor 方法，判断是否使用缓存，默认是true， 则将刚刚的执行器包装到新的 CachingExecutor 缓存执行器中。最后将执行器添加到所有的拦截器中（如果配置了话），我们这里没有配置。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://imgconvert.csdnimg.cn/aHR0cDovL3VwbG9hZC1pbWFnZXMuamlhbnNodS5pby91cGxvYWRfaW1hZ2VzLzQyMzY1NTMtNDdlMzg2NGY0YjMyN2YyYi5wbmc?x-oss-process=image/format,png&quot; alt=&quot;img&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;到此分支三结束&lt;/p&gt;
&lt;p&gt;总结:&lt;/p&gt;
&lt;p&gt;我们从用从分支二得到的对象,构建了一个执行器.这个执行对象,包括事务对象(即连jdbc连接部分的控制封装.&lt;code&gt;JdbcTransaction&lt;/code&gt;)，延迟加载的队列，本地缓存，永久缓存，配置对象(Configuration)，还包装了自己。&lt;/p&gt;
&lt;hr/&gt;&lt;h2 id=&quot;四号分支&quot;&gt;四号分支&lt;/h2&gt;
&lt;p&gt;我们已经有了执行器，此时创建 DefaultSqlSession 对象，携带 configuration, executor, autoCommit 三个参数，该构造器就是简单的赋值过程。我们有必要看看该类的结构：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://imgconvert.csdnimg.cn/aHR0cDovL3VwbG9hZC1pbWFnZXMuamlhbnNodS5pby91cGxvYWRfaW1hZ2VzLzQyMzY1NTMtMzBiNTc0NTUwODU2ZTkyYy5wbmc?x-oss-process=image/format,png&quot; alt=&quot;img&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;该类包含了常用的所有方法，包括事务方法，可以说，该类封装了执行器和事务类。而执行器才是具体的执行工作人员。&lt;/p&gt;
&lt;p&gt;至此，我们已经完成了 SqlSession 的创建过程。&lt;/p&gt;
</description>
<pubDate>Thu, 11 Jun 2020 17:17:00 +0000</pubDate>
<dc:creator>TimothyRasinski</dc:creator>
<og:description>我们处于的位置 我们要清楚现在的情况. 现在我们已经调用了SqlSessionFactoryBuilder的build方法生成了SqlSessionFactory 对象. 但是如标题所说,要想生成sq</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/yanzezhong/p/13097082.html</dc:identifier>
</item>
<item>
<title>【译】Introducing YARP Preview 1 - MeteorSeed</title>
<link>http://www.cnblogs.com/MeteorSeed/p/13090655.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/MeteorSeed/p/13090655.html</guid>
<description>[unable to retrieve full-text content]1 YARP YARP是一个项目，用于创建反向代理服务器。它开始于我们注意到来自微软内部团队的一系列问题。他们要么为其服务构建反向代理，要么询问 API 和用于构建 API 的技术。因此我们决定让他们聚在一起开发一个通用解决方案，该解决方案形成了YARP。 YARP是一个反向代理工具包，用于使用 A</description>
<pubDate>Thu, 11 Jun 2020 16:33:00 +0000</pubDate>
<dc:creator>MeteorSeed</dc:creator>
<dc:identifier>https://www.cnblogs.com/MeteorSeed/p/13090655.html</dc:identifier>
</item>
<item>
<title>Python3 源码阅读 - 垃圾回收机制 - JonPan</title>
<link>http://www.cnblogs.com/panlq/p/13096942.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/panlq/p/13096942.html</guid>
<description>&lt;p&gt;Python的垃圾回收机制包括了两大部分：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;引用计数&lt;/strong&gt;(大部分在 &lt;code&gt;Include/object.h&lt;/code&gt; 中定义)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;标记清除+隔代回收&lt;/strong&gt;(大部分在 &lt;code&gt;Modules/gcmodule.c&lt;/code&gt; 中定义)&lt;/li&gt;
&lt;/ul&gt;&lt;h2 id=&quot;1-引用计数机制&quot;&gt;1. 引用计数机制&lt;/h2&gt;
&lt;p&gt;python中万物皆对象，他的核心结构是：&lt;code&gt;PyObject&lt;/code&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-c++&quot;&gt;typedef __int64 ssize_t;

typedef ssize_t         Py_ssize_t;

typedef struct _object {
    _PyObject_HEAD_EXTRA
    Py_ssize_t ob_refcnt;   // Py_ssize_t __int64
    struct _typeobject *ob_type;
} PyObject;

typedef struct {
    PyObject ob_base;
    Py_ssize_t ob_size; /* Number of items in variable part */
} PyVarObject;
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;PyObject&lt;/code&gt;是每个对象的底层数据结构，其中&lt;code&gt;ob_refcnt&lt;/code&gt;就是作为引用计数。当一个对象有新的引用时, 它的&lt;code&gt;ob_refcnt&lt;/code&gt;就会增加，当引用它的对象被删除，它的&lt;code&gt;ob_refcnt&lt;/code&gt;就会减少,当引用技术为0时，该对象的生命结束了。&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;引用计数+1的情况
&lt;ul&gt;&lt;li&gt;对象被创建 eg: a=2&lt;/li&gt;
&lt;li&gt;对象被引用 eg: b=a&lt;/li&gt;
&lt;li&gt;对象被作为参数，传入到一个函数中，例如func(a)&lt;/li&gt;
&lt;li&gt;对象作为一个元素，存储在容器中，例如list1=[a, b]&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;引用计数-1的情况
&lt;ul&gt;&lt;li&gt;对象的别名被显示的销毁 eg: del a&lt;/li&gt;
&lt;li&gt;对象的别名被赋予新的对象 eg: a=34&lt;/li&gt;
&lt;li&gt;一个对象离开它的作用域， 例如f函数执行完毕时，func函数中的局部变量（全局变量不会）&lt;/li&gt;
&lt;li&gt;对象所在的容器被销毁，或者从容器中删除&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;&lt;strong&gt;如何查看对象的引用计数&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-python&quot;&gt;import sys
a = 'hello'
sys.getrefcount(a)   
// 注意: getrefcount(a) 传入a时, a的引用计数会加1
&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;11-什么时候触发回收&quot;&gt;1.1 什么时候触发回收&lt;/h3&gt;
&lt;p&gt;当一个对象的引用计数变为了 0, 会直接进入释放空间的流程&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-c++&quot;&gt;/* cpython/Include/object.h */
static inline void _Py_DECREF(const char *filename, int lineno,
                              PyObject *op)
{
    _Py_DEC_REFTOTAL;
    if (--op-&amp;gt;ob_refcnt != 0) {
#ifdef Py_REF_DEBUG
        if (op-&amp;gt;ob_refcnt &amp;lt; 0) {
            _Py_NegativeRefcount(filename, lineno, op);
        }
#endif
    }
    else {
        /* // _Py_Dealloc 会找到对应类型的 descructor, 并且调用这个 descructor
        destructor dealloc = Py_TYPE(op)-&amp;gt;tp_dealloc;
        (*dealloc)(op);
        */
        _Py_Dealloc(op);
    }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;2-常驻内存对象&quot;&gt;2. 常驻内存对象&lt;/h2&gt;
&lt;p&gt;引用计数机制所带来的维护引用计数的额外操作，与python运行中所进行的内存分配、释放、引用赋值的次数是成正比的，这一点，相对于主流的垃圾回收技术，比如标记--清除&lt;code&gt;(mark--sweep)&lt;/code&gt;、停止--复制&lt;code&gt;(stop--copy)&lt;/code&gt;等方法相比是一个弱点，因为它们带来额外操作只和内存数量有关，至于多少人引用了这块内存则不关心。因此为了与引用计数搭配、在内存的分配和释放上获得最高的效率，python设计了大量的内存池机制，比如&lt;strong&gt;小整数对象池、字符串的intern机制，列表的freelist缓冲池&lt;/strong&gt;等等，这些大量使用的面向特定对象的内存池机制正是为了弥补引用计数的软肋。&lt;/p&gt;
&lt;h3 id=&quot;21-小整数对象池&quot;&gt;2.1 小整数对象池&lt;/h3&gt;
&lt;pre&gt;
&lt;code class=&quot;language-c++&quot;&gt;#ifndef NSMALLPOSINTS
#define NSMALLPOSINTS           257
#endif
#ifndef NSMALLNEGINTS
#define NSMALLNEGINTS           5
#endif

#if NSMALLNEGINTS + NSMALLPOSINTS &amp;gt; 0
/* Small integers are preallocated in this array so that they
   can be shared.
   The integers that are preallocated are those in the range
   -NSMALLNEGINTS (inclusive) to NSMALLPOSINTS (not inclusive).
*/
static PyLongObject small_ints[NSMALLNEGINTS + NSMALLPOSINTS];

Py_INCREF(op)  增加对象引用计数

Py_DECREF(op)  减少对象引用计数, 如果计数位0, 调用_Py_Dealloc

_Py_Dealloc(op) 调用对应类型的 tp_dealloc 方法
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;小整数对象池就是一个&lt;code&gt;PyLongObject&lt;/code&gt; 数组, 大小=257+5=262, 范围是&lt;code&gt;[-5, 257)&lt;/code&gt; 注意左闭右开.&lt;/p&gt;
&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;python对小整数的定义是[-5, 257)， 这些整数对象是提前建立好的，不会被垃圾回收，在一个python程序中，所有位于这个范围内的整数使用的都是同一个对象&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&quot;22-大整数对象池&quot;&gt;2.2 大整数对象池&lt;/h3&gt;
&lt;p&gt;疑惑：《Python源码剖析》提到的整数对象池block_list应该已经不存在了（因为PyLongObject为变长对象）。&lt;code&gt;Python2&lt;/code&gt;中的&lt;code&gt;PyIntObject&lt;/code&gt;实际是对&lt;code&gt;c&lt;/code&gt;中的&lt;code&gt;long&lt;/code&gt;的包装。所以&lt;code&gt;Python2&lt;/code&gt;也提供了专门的缓存池，供大整数轮流使用，避免每次使用不断的&lt;code&gt;malloc&lt;/code&gt;分配内存带来的效率损耗，可参考&lt;a href=&quot;https://foofish.net/python_int_implement.html&quot;&gt;刘志军老师的讲解&lt;/a&gt;。既然没有池了，malloc/free会带来的不小性能损耗。Guido认为Py3.0有极大的优化空间，在字符串和整形操作上可以取得很好的优化结果。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-c&quot;&gt;/* Allocate a new int object with size digits.
   Return NULL and set exception if we run out of memory. */

#define MAX_LONG_DIGITS \
    ((PY_SSIZE_T_MAX - offsetof(PyLongObject, ob_digit))/sizeof(digit))

PyLongObject *
_PyLong_New(Py_ssize_t size)
{
    PyLongObject *result;
    /* Number of bytes needed is: offsetof(PyLongObject, ob_digit) +
       sizeof(digit)*size.  Previous incarnations of this code used
       sizeof(PyVarObject) instead of the offsetof, but this risks being
       incorrect in the presence of padding between the PyVarObject header
       and the digits. */
    if (size &amp;gt; (Py_ssize_t)MAX_LONG_DIGITS) {
        PyErr_SetString(PyExc_OverflowError,
                        &quot;too many digits in integer&quot;);
        return NULL;
    }
    result = PyObject_MALLOC(offsetof(PyLongObject, ob_digit) +
                             size*sizeof(digit));
    if (!result) {
        PyErr_NoMemory();
        return NULL;
    }
    return (PyLongObject*)PyObject_INIT_VAR(result, &amp;amp;PyLong_Type, size);
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;&lt;code&gt;result = PyObject_MALLOC(offsetof(PyLongObject, ob_digit) + size*sizeof(digit));&lt;/code&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;每一个大整数，均创建一个新的对象。id(num)均不同。&lt;/p&gt;
&lt;h3 id=&quot;24-字符串的intern机制&quot;&gt;2.4 字符串的intern机制&lt;/h3&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;pre&gt;
&lt;code&gt;Objects/unicodeobject.c
Objects/codeobject.c
&lt;/code&gt;
&lt;/pre&gt;&lt;/blockquote&gt;
&lt;blockquote readability=&quot;10&quot;&gt;
&lt;p&gt;&lt;code&gt;PyStringObject&lt;/code&gt;对象的intern机制之目的是：对于被intern之后的字符串，比如“Ruby”，在整个Python的运行期间，系统中都只有唯一的一个与字符串“Ruby”对应的&lt;code&gt;PyStringObject&lt;/code&gt;对象。这样当判断两个&lt;code&gt;PyStringObject&lt;/code&gt;对象是否相同时，如果它们都被intern了，那么只需要简单地检查它们对应的&lt;code&gt;PyObject*&lt;/code&gt;是否相同即可。这个机制既节省了空间，又简化了对&lt;code&gt;PyStringObject&lt;/code&gt;对象的比较，嗯，可谓是一箭双雕哇。&lt;/p&gt;
&lt;p&gt;摘自：《Python源码剖析》 — 陈儒&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Python3中&lt;code&gt;PyUnicodeObject&lt;/code&gt;对象的&lt;code&gt;intern&lt;/code&gt;机制和Python2的&lt;code&gt;PyStringObject&lt;/code&gt;对象&lt;code&gt;intern&lt;/code&gt;机制一样，主要为了节省内存的开销，利用字符串对象的不可变性，对存在的字符串对象重复利用&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-powershell&quot;&gt;In [50]: a = 'python'

In [51]: b = 'python'

In [52]: id(a)
Out[52]: 442782398256

In [53]: id(b)
Out[53]: 442782398256

In [54]: b = 'hello python'

In [55]: a = 'hello python'

In [56]: id(a)
Out[56]: 442808585520

In [57]: id(b)
Out[57]: 442726541488
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;什么样的字符串会使用&lt;code&gt;intern&lt;/code&gt;机制?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;intern机制跟编译时期有关，相关代码在&lt;code&gt;Objects/codeobject.c&lt;/code&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-c++&quot;&gt;/* Intern selected string constants */
static int
intern_string_constants(PyObject *tuple)
{
    int modified = 0;
    Py_ssize_t i;

    for (i = PyTuple_GET_SIZE(tuple); --i &amp;gt;= 0; ) {
        PyObject *v = PyTuple_GET_ITEM(tuple, i);
        if (PyUnicode_CheckExact(v)) {
            if (PyUnicode_READY(v) == -1) {
                PyErr_Clear();
                continue;
            }
            if (all_name_chars(v)) {
                PyObject *w = v;
                PyUnicode_InternInPlace(&amp;amp;v);
                if (w != v) {
                    PyTuple_SET_ITEM(tuple, i, v);
                    modified = 1;
                }
            }
        }
        /*....*/
}
    
/* all_name_chars(s): true iff s matches [a-zA-Z0-9_]* */
static int
all_name_chars(PyObject *o)
{
    const unsigned char *s, *e;

    if (!PyUnicode_IS_ASCII(o))
        return 0;

    s = PyUnicode_1BYTE_DATA(o);
    e = s + PyUnicode_GET_LENGTH(o);
    for (; s != e; s++) {
        if (!Py_ISALNUM(*s) &amp;amp;&amp;amp; *s != '_')
            return 0;
    }
    return 1;
}

&lt;/code&gt;
&lt;/pre&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;可见 all_name_chars 决定了是否会 intern，简单来说就是 ascii 字母，数字和下划线组成的字符串会被缓存。但是不仅如此。2.5还会说&lt;/p&gt;
&lt;/blockquote&gt;
&lt;pre&gt;
&lt;code class=&quot;language-c++&quot;&gt;/* This dictionary holds all interned unicode strings.  Note that references
   to strings in this dictionary are *not* counted in the string's ob_refcnt.
   When the interned string reaches a refcnt of 0 the string deallocation
   function will delete the reference from this dictionary.

   Another way to look at this is that to say that the actual reference
   count of a string is:  s-&amp;gt;ob_refcnt + (s-&amp;gt;state ? 2 : 0)
*/
static PyObject *interned = NULL;
/*省略*/
void
PyUnicode_InternInPlace(PyObject **p)
{
    PyObject *s = *p;
    PyObject *t;
#ifdef Py_DEBUG
    assert(s != NULL);
    assert(_PyUnicode_CHECK(s));
#else
    if (s == NULL || !PyUnicode_Check(s))
        return;
#endif
    /* If it's a subclass, we don't really know what putting
       it in the interned dict might do. */
    if (!PyUnicode_CheckExact(s))
        return;
    // [1]
    if (PyUnicode_CHECK_INTERNED(s))
        return;
    if (interned == NULL) {
        interned = PyDict_New();
        if (interned == NULL) {
            PyErr_Clear(); /* Don't leave an exception */
            return;
        }
    }
    Py_ALLOW_RECURSION
    // [2]
    t = PyDict_SetDefault(interned, s, s);
    Py_END_ALLOW_RECURSION
    if (t == NULL) {
        PyErr_Clear();
        return;
    }
    // [3]
    if (t != s) {
        Py_INCREF(t);
        Py_SETREF(*p, t);
        return;
    }
    // [4]
    /* The two references in interned are not counted by refcnt.
       The deallocator will take care of this */
    Py_REFCNT(s) -= 2;
    _PyUnicode_STATE(s).interned = SSTATE_INTERNED_MORTAL;
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;通过函数我们可以得知，python中维护这一个interned变量的指针，这个变量指向&lt;code&gt;PyDict_New&lt;/code&gt;创建的对象，而&lt;code&gt;PyDict_New&lt;/code&gt;实际上创建了一个&lt;code&gt;PyDictObject&lt;/code&gt;对象，是Python中&lt;code&gt;dict&lt;/code&gt;类型的对象。实际上intern机制就是维护一个字典，这个字典中记录着被intern机制处理过的字符串对象，&lt;code&gt;[1]&lt;/code&gt;处&lt;code&gt;PyUnicode_CHECK_INTERNED&lt;/code&gt;宏检查字符串对象的&lt;code&gt;state.interned&lt;/code&gt;是否被标记，&lt;/p&gt;
&lt;p&gt;如果字符串对象的&lt;code&gt;state.interned&lt;/code&gt;被标记了，就直接返回；&lt;code&gt;[2]&lt;/code&gt;处&lt;strong&gt;尝试&lt;/strong&gt;把没有被标记的&lt;code&gt;字符串对象s&lt;/code&gt;作为&lt;code&gt;key-value&lt;/code&gt;加入&lt;code&gt;interned&lt;/code&gt;字典中；&lt;code&gt;[3]&lt;/code&gt;处表示&lt;code&gt;字符串对象s&lt;/code&gt;已经在&lt;code&gt;interned&lt;/code&gt;字典中（对应的value值是&lt;code&gt;字符串对象t&lt;/code&gt;），（通过&lt;code&gt;Py_SETREF&lt;/code&gt;宏来改变p指针的指向），且原&lt;code&gt;字符串对象p&lt;/code&gt;会因引用计数为零被回收。&lt;code&gt;Py_SETREF&lt;/code&gt;宏在&lt;code&gt;Include/object.h&lt;/code&gt;定义着：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-c&quot;&gt;/* Safely decref `op` and set `op` to `op2`.
 *
 * As in case of Py_CLEAR &quot;the obvious&quot; code can be deadly:
 *
 *     Py_DECREF(op);
 *     op = op2;
 *
 * The safe way is:
 *
 *      Py_SETREF(op, op2);
 *
 * That arranges to set `op` to `op2` _before_ decref'ing, so that any code
 * triggered as a side-effect of `op` getting torn down no longer believes
 * `op` points to a valid object.
 *
 * Py_XSETREF is a variant of Py_SETREF that uses Py_XDECREF instead of
 * Py_DECREF.
 */

#define Py_SETREF(op, op2)                      \
    do {                                        \
        PyObject *_py_tmp = (PyObject *)(op);   \
        (op) = (op2);                           \
        Py_DECREF(_py_tmp);                     \
    } while (0)
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;[4]&lt;/code&gt;中把新加入&lt;code&gt;interned&lt;/code&gt;字典中的字符串对象做减引用操作，并把&lt;code&gt;state.interned&lt;/code&gt;标记成&lt;code&gt;SSTATE_INTERNED_MORTAL&lt;/code&gt;。&lt;code&gt;SSTATE_INTERNED_MORTAL&lt;/code&gt;表示字符串对象被intern机制处理，但会随着引用计数被回收；&lt;code&gt;interned&lt;/code&gt;标记还有另外一种&lt;code&gt;SSTATE_INTERNED_IMMORTAL&lt;/code&gt;，表示被intern机制处理但对象不可销毁，会与Python解释器同在。&lt;code&gt;PyUnicode_InternInPlace&lt;/code&gt;只能创建&lt;code&gt;SSTATE_INTERNED_MORTAL&lt;/code&gt;状态的字符串，要想创建&lt;code&gt;SSTATE_INTERNED_IMMORTAL&lt;/code&gt;状态的字符串需要通过另外一个接口，强制改变intern的状态&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-c++&quot;&gt;void
PyUnicode_InternImmortal(PyObject **p)
{
    PyUnicode_InternInPlace(p);
    if (PyUnicode_CHECK_INTERNED(*p) != SSTATE_INTERNED_IMMORTAL) {
        _PyUnicode_STATE(*p).interned = SSTATE_INTERNED_IMMORTAL;
        Py_INCREF(*p);
    }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;为什么引用&lt;code&gt;Py_REFCNT(s) -= 2;&lt;/code&gt;要-2呢？&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-c++&quot;&gt;PyDict_SetDefault(PyObject *d, PyObject *key, PyObject *defaultobj)
{
    PyDictObject *mp = (PyDictObject *)d;
    PyObject *value;
    Py_hash_t hash;

    /*...*/
    if (ix == DKIX_EMPTY) {
        /*...*/
        Py_ssize_t hashpos = find_empty_slot(mp-&amp;gt;ma_keys, hash);
        ep0 = DK_ENTRIES(mp-&amp;gt;ma_keys);
        ep = &amp;amp;ep0[mp-&amp;gt;ma_keys-&amp;gt;dk_nentries];
        dictkeys_set_index(mp-&amp;gt;ma_keys, hashpos, mp-&amp;gt;ma_keys-&amp;gt;dk_nentries);
        Py_INCREF(key);
        Py_INCREF(value);
        /*...*/
    return value;
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;对于被intern机制处理了的PyStringObject对象，Python采用了特殊的引用计数机制。在将一个PyStringObject对象a的PyObject指针&lt;strong&gt;作为key和value&lt;/strong&gt;添加到interned中时，PyDictObject对象会通过这两个指针对a的引用计数进行两次加1的操作。但是Python的设计者规定在interned中a的指针不能被视为对象a的有效引用，因为如果是有效引用的话，那么a的引用计数在Python结束之前永远都不可能为0，因为interned中至少有两个指针引用了a，那么删除a就永远不可能了，这显然是没有道理的。&lt;br/&gt;摘自：《Python源码剖析》 — 陈儒&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;注意：&lt;/strong&gt;实际上，即使Python会对一个字符串进行intern机制的处理，也会先创建一个&lt;code&gt;PyUnicodeObject&lt;/code&gt;对象，然后检查在&lt;code&gt;interned&lt;/code&gt;字典中是否有值和其相同，存在的话就将&lt;code&gt;interned&lt;/code&gt;字典保存的value值返回，之前临时创建的字符串对象会由于引用计数为零而回收。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;是否可以直接对C原生对象做intern的动作呢？不需要创建临时对象&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;事实上&lt;code&gt;CPython&lt;/code&gt;确实提供了以&lt;code&gt;char *&lt;/code&gt; 为参数的intern机制相关函数，但是，也是一样的创建temp在设置intern.&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-c++&quot;&gt;PyUnicode_InternImmortal(PyObject **p)
{
    PyUnicode_InternInPlace(p);
    if (PyUnicode_CHECK_INTERNED(*p) != SSTATE_INTERNED_IMMORTAL) {
        _PyUnicode_STATE(*p).interned = SSTATE_INTERNED_IMMORTAL;
        Py_INCREF(*p);
    }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;为什么需要临时对象？&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;因为PyDict_SetDefault() 操作的是PyDictObject对象，而该对象必须以PyObject*指针作为键&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&quot;25-字符缓冲池（单字符）&quot;&gt;2.5 字符缓冲池（单字符）&lt;/h3&gt;
&lt;p&gt;python为小整数对象准备了小整数对象池，当然对于常用的字符，python对应的也建了字符串缓冲池，因为 python3 中通过 &lt;code&gt;unicode_latin1[256]&lt;/code&gt; &lt;strong&gt;将长度为 1 的 ascii 的字符也缓存了&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-c&quot;&gt;/* Single character Unicode strings in the Latin-1 range are being
   shared as well. */
static PyObject *unicode_latin1[256] = {NULL};

unicode_decode_utf8(){
    /*省略*/
    /* ASCII is equivalent to the first 128 ordinals in Unicode. */
    if (size == 1 &amp;amp;&amp;amp; (unsigned char)s[0] &amp;lt; 128) {
        if (consumed)
            *consumed = 1;
        return get_latin1_char((unsigned char)s[0]);
    }
    /*省略*/
}


static PyObject*
get_latin1_char(unsigned char ch)
{
    PyObject *unicode = unicode_latin1[ch];
    if (!unicode) {
        unicode = PyUnicode_New(1, ch);
        if (!unicode)
            return NULL;
        PyUnicode_1BYTE_DATA(unicode)[0] = ch;
        assert(_PyUnicode_CheckConsistency(unicode, 1));
        unicode_latin1[ch] = unicode;
    }
    Py_INCREF(unicode);
    return unicode;
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;pre&gt;
&lt;code class=&quot;language-powershell&quot;&gt;In [46]: a = 'p'

In [47]: b = 'p'

In [48]: id(a)
Out[48]: 442757120384

In [49]: id(b)
Out[49]: 442757120384
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;当然单字符也包括空字符。&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-c++&quot;&gt;/* The empty Unicode object is shared to improve performance. */
static PyObject *unicode_empty = NULL;
&lt;/code&gt;
&lt;/pre&gt;
&lt;pre&gt;
&lt;code class=&quot;language-shell&quot;&gt;In [8]: a = 'hello' + 'python'

In [9]: b = 'hellopython'

In [10]: a is b
Out[10]: True

In [11]: a = 'hello ' + 'python'

In [12]: b = 'hello python'

In [13]: id(a)
Out[13]: 118388503536

In [14]: id(b)
Out[14]: 118387544240

In [15]: 'hello ' + 'python' is 'hello python'
Out[15]: False

In [16]: 'hello_' + 'python' is 'hello_python'
Out[16]: True
&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;26-小结：&quot;&gt;2.6 小结：&lt;/h3&gt;
&lt;ul readability=&quot;2.4648711943794&quot;&gt;&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;&lt;strong&gt;小整数[-5， 257)共用对象，常驻内存&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;&lt;strong&gt;单个字母，长度为 1 的 ascii 的字符&lt;a href=&quot;https://en.wikipedia.org/wiki/ISO/IEC_8859-1&quot;&gt;latin1&lt;/a&gt;会被interned， 包括空字符，共用对象，常驻内存&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;&lt;strong&gt;由字母、数字、下划线([a-zA-Z0-9_])组成的字符串，不可修改，默认开启intern机制，共用对象，引用计数为0时，销毁&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;字符串（含有空格），不可修改，没开启intern机制，不共用对象，引用计数为0，销毁&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;h2 id=&quot;3-标记清除分代回收&quot;&gt;3. 标记清除+分代回收&lt;/h2&gt;
&lt;p&gt;为了防止出现&lt;strong&gt;循环引用&lt;/strong&gt;的致命性问题，&lt;strong&gt;python采用的是引用计数机制为主，标记-清除和分代收集两种机制为辅的策略&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://i.loli.net/2020/06/11/2GI7nmWSPvNjpOR.png&quot; alt=&quot;image.png&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://i.loli.net/2020/06/11/iLS5ATeBo3W1sVr.png&quot; alt=&quot;image.png&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;我们设置 n1.next 指向 n2，同时设置 n2.prev 指回 n1，现在，我们的两个节点使用循环引用的方式构成了一个&lt;code&gt;双向链表&lt;/code&gt;，同时请注意到 ABC 以及 DEF 的引用计数值已经增加到了2，现在，假定我们的程序不再使用这两个节点了，我们将 n1 和 n2 都设置为None，Python会像往常一样将每个节点的引用计数减少到1。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://i.loli.net/2020/06/11/q6IpCneRGwt2iM3.png&quot; alt=&quot;image.png&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h3 id=&quot;31-在python中的零代generation-zero&quot;&gt;3.1 在python中的零代(Generation Zero)&lt;/h3&gt;
&lt;p&gt;Ruby使用一个链表(free_list)来持续追踪未使用的、自由的对象，Python使用一种不同的链表来持续追踪活跃的对象。而不将其称之为“活跃列表”，Python的内部C代码将其称为零代(Generation Zero)。每次当你创建一个对象或其他什么值的时候，Python会将其加入零代链表：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://i.loli.net/2020/06/11/Yp8UMNXmP4ORFDG.png&quot; alt=&quot;image.png&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;从上边可以看到当我们创建ABC节点的时候，Python将其加入零代链表。请注意到这并不是一个真正的列表，并不能直接在你的代码中访问，事实上这个链表是一个完全内部的Python运行时。&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;疑惑1：&lt;/strong&gt;&lt;/em&gt;&lt;strong&gt;对于容器对象(比如list、dict、class、instance等等)，是在什么时候绑定GC，放入第0链表呢？&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;相似的，当我们创建DEF节点的时候，Python将其加入同样的链表：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://i.loli.net/2020/06/11/giHxS7pYNKwT8kh.png&quot; alt=&quot;image.png&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;现在零代包含了两个节点对象。(他还将包含Python创建的每个其他值，与一些Python自己使用的内部值。)&lt;/p&gt;
&lt;h3 id=&quot;32-标记循环引用&quot;&gt;3.2 标记循环引用&lt;/h3&gt;
&lt;p&gt;当达到某个 阈值之后 解释器会循环遍历，循环遍历零代列表上的每个对象，检查列表中每个互相引用的对象，根据规则减掉其引用计数。在这个过程中，Python会一个接一个的统计内部引用的数量以防过早地释放对象。以下例子便于理解：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://i.loli.net/2020/06/11/Y1ORJmN2UxPnFg7.png&quot; alt=&quot;image.png&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;从上面可以看到 ABC 和 DEF 节点包含的引用数为1.有三个其他的对象同时存在于零代链表中，蓝色的箭头指示了有一些对象正在被零代链表之外的其他对象所引用。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://i.loli.net/2020/06/11/g1fsLIiYMZupBRo.png&quot; alt=&quot;image.png&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;通过识别内部引用，Python能够减少许多零代链表对象的引用计数。在上图的第一行中你能够看见ABC和DEF的引用计数已经变为零了，这意味着收集器可以释放它们并回收内存空间了。剩下的活跃的对象则被移动到一个新的链表：一代链表。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;疑惑2： 内部如何识别零代的循环引用计数，在什么阈值下会触发GC执行？&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&quot;33-在源码中摸索答案&quot;&gt;3.3 在源码中摸索答案&lt;/h3&gt;
&lt;p&gt;Python通过&lt;code&gt;PyGC_Head&lt;/code&gt;来跟踪container对象，&lt;code&gt;PyGC_Head&lt;/code&gt;信息位于&lt;code&gt;PyObject_HEAD&lt;/code&gt;之前，定义在&lt;code&gt;Include/objimpl.h&lt;/code&gt;中&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-c++&quot;&gt;typedef union _gc_head {
    struct {
        union _gc_head *gc_next;
        union _gc_head *gc_prev;
        Py_ssize_t gc_refs;
    } gc;
    double dummy;  /* force worst-case alignment */
} PyGC_Head;
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;表头数据结构&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-c++&quot;&gt;//Include/internal/mem.h
struct gc_generation {
      PyGC_Head head;
      int threshold; /* collection threshold */  // 阈值
      int count; /* count of allocations or collections of younger
                    generations */    // 实时个数
  };
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;Python中用于分代垃圾收集的三个“代”由&lt;code&gt;_gc_runtime_state.generations&lt;/code&gt;数组所表示着：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;解答疑惑2，三个代的阈值如下数组&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-c++&quot;&gt;/* If we change this, we need to cbhange the default value in the
   signature of gc.collect. */
#define NUM_GENERATIONS 3

_PyGC_Initialize(struct _gc_runtime_state *state)
{
    state-&amp;gt;enabled = 1; /* automatic collection enabled? */

#define _GEN_HEAD(n) (&amp;amp;state-&amp;gt;generations[n].head)
    struct gc_generation generations[NUM_GENERATIONS] = {
        /* PyGC_Head,                                 threshold,      count */
        {{{_GEN_HEAD(0), _GEN_HEAD(0), 0}},           700,            0},
        {{{_GEN_HEAD(1), _GEN_HEAD(1), 0}},           10,             0},
        {{{_GEN_HEAD(2), _GEN_HEAD(2), 0}},           10,             0},
    };
    for (int i = 0; i &amp;lt; NUM_GENERATIONS; i++) {
        state-&amp;gt;generations[i] = generations[i];
    };
    state-&amp;gt;generation0 = GEN_HEAD(0);
    struct gc_generation permanent_generation = {
          {{&amp;amp;state-&amp;gt;permanent_generation.head, &amp;amp;state-&amp;gt;permanent_generation.head, 0}}, 0, 0
    };
    state-&amp;gt;permanent_generation = permanent_generation;
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;img src=&quot;https://i.loli.net/2020/06/11/bkKPog8n3Cy1TOx.png&quot; alt=&quot;image.png&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;解答疑惑1：那container对象是什么时候加入第0“代”的container对象链表呢？&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;对于python内置对象的创建，container对象是通过&lt;code&gt;PyObject_GC_New&lt;/code&gt;函数来创建的，而非container对象是通过&lt;code&gt;PyObject_Malloc&lt;/code&gt;函数来创建的。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-c++&quot;&gt;// Include/objimpl.h
#define PyObject_GC_New(type, typeobj) \
                ( (type *) _PyObject_GC_New(typeobj) )


// 调用了Modules/gcmodule.c中的_PyObject_GC_New函数：
PyObject *
_PyObject_GC_New(PyTypeObject *tp)
{
    PyObject *op = _PyObject_GC_Malloc(_PyObject_SIZE(tp));
    if (op != NULL)
        op = PyObject_INIT(op, tp);
    return op;
}

static PyObject *
_PyObject_GC_Alloc(int use_calloc, size_t basicsize)
{
    PyObject *op;
    PyGC_Head *g;
    size_t size;
    if (basicsize &amp;gt; PY_SSIZE_T_MAX - sizeof(PyGC_Head))
        return PyErr_NoMemory();
    size = sizeof(PyGC_Head) + basicsize;
    // [1]  申请PyGC_Head和对象本身的内存
    if (use_calloc)
        g = (PyGC_Head *)PyObject_Calloc(1, size);
    else
        g = (PyGC_Head *)PyObject_Malloc(size);
    if (g == NULL)
        return PyErr_NoMemory();
    // [2] 设置gc_refs的值
    g-&amp;gt;gc.gc_refs = 0;
    _PyGCHead_SET_REFS(g, GC_UNTRACKED);
    // [3]
    generations[0].count++; /* number of allocated GC objects */
    if (generations[0].count &amp;gt; generations[0].threshold &amp;amp;&amp;amp;
        enabled &amp;amp;&amp;amp;
        generations[0].threshold &amp;amp;&amp;amp;
        !collecting &amp;amp;&amp;amp;
        !PyErr_Occurred()) {
        collecting = 1;
        collect_generations();
        collecting = 0;
    }
    // [4]  FROM_GC宏定义可以通过PyGC_Head地址转换PyObject_HEAD地址，逆运算是AS_GC宏定义。
    op = FROM_GC(g);
    return op;
}

PyObject *
_PyObject_GC_Malloc(size_t basicsize)
{
    return _PyObject_GC_Alloc(0, basicsize);
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;[4] &lt;code&gt;FROM_GC&lt;/code&gt;宏定义可以通过&lt;code&gt;PyGC_Head&lt;/code&gt;地址转换&lt;code&gt;PyObject_HEAD&lt;/code&gt;地址，逆运算是&lt;code&gt;AS_GC&lt;/code&gt;宏定义。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-c++&quot;&gt;/* Get an object's GC head */
#define AS_GC(o) ((PyGC_Head *)(o)-1)

/* Get the object given the GC head */
#define FROM_GC(g) ((PyObject *)(((PyGC_Head *)g)+1))
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;当触发阈值后，是如何进行GC回收的？&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;collect&lt;/code&gt;是垃圾回收的主入口函数。&lt;strong&gt;特别注意 finalizers 与 python 的&lt;code&gt;__del__&lt;/code&gt;绑定了&lt;/strong&gt;。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-c&quot;&gt;/* This is the main function.  Read this to understand how the
 * collection process works. */
static Py_ssize_t
collect(int generation, Py_ssize_t *n_collected, Py_ssize_t *n_uncollectable,
        int nofail)
{
    int i;
    Py_ssize_t m = 0; /* # objects collected */
    Py_ssize_t n = 0; /* # unreachable objects that couldn't be collected */
    PyGC_Head *young; /* the generation we are examining */
    PyGC_Head *old; /* next older generation */
    PyGC_Head unreachable; /* non-problematic unreachable trash */
    PyGC_Head finalizers;  /* objects with, &amp;amp; reachable from, __del__ */
    PyGC_Head *gc;
    _PyTime_t t1 = 0;   /* initialize to prevent a compiler warning */

    struct gc_generation_stats *stats = &amp;amp;_PyRuntime.gc.generation_stats[generation];
    
    ...

    // “标记-清除”前的准备
    
    // 垃圾标记

    // 垃圾清除
  
    ...

    /* Update stats */
    if (n_collected)
        *n_collected = m;
    if (n_uncollectable)
        *n_uncollectable = n;
    stats-&amp;gt;collections++;
    stats-&amp;gt;collected += m;
    stats-&amp;gt;uncollectable += n;

    if (PyDTrace_GC_DONE_ENABLED())
        PyDTrace_GC_DONE(n+m);

    return n+m;
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;331-标记-清除前的准备&quot;&gt;3.3.1 标记-清除前的准备&lt;/h3&gt;
&lt;pre&gt;
&lt;code class=&quot;language-c&quot;&gt;    // [1]
    /* update collection and allocation counters */
    if (generation+1 &amp;lt; NUM_GENERATIONS)
        _PyRuntime.gc.generations[generation+1].count += 1;
    for (i = 0; i &amp;lt;= generation; i++)
        _PyRuntime.gc.generations[i].count = 0;

    // [2]
    /* merge younger generations with one we are currently collecting */
    for (i = 0; i &amp;lt; generation; i++) {
        gc_list_merge(GEN_HEAD(i), GEN_HEAD(generation));
    }

    // [3]
    /* handy references */
    young = GEN_HEAD(generation);
    if (generation &amp;lt; NUM_GENERATIONS-1)
        old = GEN_HEAD(generation+1);
    else
        old = young;

    // [4]
    /* Using ob_refcnt and gc_refs, calculate which objects in the
     * container set are reachable from outside the set (i.e., have a
     * refcount greater than 0 when all the references within the
     * set are taken into account).
     */
    update_refs(young);
    subtract_refs(young);
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;[1] 先更新了将被回收的“代”以及老一“代”的count计数器。&lt;br/&gt;这边对老一“代”的count计数器增量1就可以看出来在第1“代”和第2“代”的count值其实表示的是该代垃圾回收的次数。&lt;br/&gt;[2] 通过&lt;code&gt;gc_list_merge&lt;/code&gt;函数将这些“代”合并成一个链表。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;/* append list `from` onto list `to`; `from` becomes an empty list */
static void
gc_list_merge(PyGC_Head *from, PyGC_Head *to)
{
    PyGC_Head *tail;
    assert(from != to);
    if (!gc_list_is_empty(from)) {
        tail = to-&amp;gt;gc.gc_prev;
        tail-&amp;gt;gc.gc_next = from-&amp;gt;gc.gc_next;
        tail-&amp;gt;gc.gc_next-&amp;gt;gc.gc_prev = tail;
        to-&amp;gt;gc.gc_prev = from-&amp;gt;gc.gc_prev;
        to-&amp;gt;gc.gc_prev-&amp;gt;gc.gc_next = to;
    }
    gc_list_init(from);
}

static void
gc_list_init(PyGC_Head *list)
{
    list-&amp;gt;gc.gc_prev = list;
    list-&amp;gt;gc.gc_next = list;
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;gc_list_merge&lt;/code&gt;函数将from链表链接到to链表末尾并把from链表置为空链表。&lt;/p&gt;
&lt;p&gt;[3] 经过合并操作之后，所有需要被进行垃圾回收的对象都链接到young“代”（满足超过阈值的最老“代”），并记录old“代”，后面需要将不可回收的对象移到old“代”。&lt;/p&gt;
&lt;p&gt;链表的合并操作：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://i.loli.net/2020/06/11/g4QiLXuzaD2eKEo.png&quot; alt=&quot;image.png&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;[4] 寻找root object集合&lt;/p&gt;
&lt;p&gt;要对合并的链表进行垃圾标记，首先需要寻找root object集合。&lt;br/&gt;所谓的root object即是一些全局引用和函数栈中的引用。这些引用所用的对象是不可被删除的。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-python&quot;&gt;list1 = []
list2 = []
list1.append(list2)
list2.append(list1)
a = list1
del list1
del list2
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;上面的Python中循环引用的代码，变量a所指向的对象就是root object。&lt;/p&gt;
&lt;p&gt;三色标记模型&lt;/p&gt;
&lt;h3 id=&quot;332-垃圾标记&quot;&gt;3.3.2 垃圾标记&lt;/h3&gt;
&lt;pre&gt;
&lt;code class=&quot;language-c&quot;&gt;// [1]
/* Leave everything reachable from outside young in young, and move
     * everything else (in young) to unreachable.
     * NOTE:  This used to move the reachable objects into a reachable
     * set instead.  But most things usually turn out to be reachable,
     * so it's more efficient to move the unreachable things.
     */
gc_list_init(&amp;amp;unreachable);
move_unreachable(young, &amp;amp;unreachable);

// [2]
/* Move reachable objects to next generation. */
if (young != old) {
    if (generation == NUM_GENERATIONS - 2) {
        _PyRuntime.gc.long_lived_pending += gc_list_size(young);
    }
    gc_list_merge(young, old);
}
else {
    /* We only untrack dicts in full collections, to avoid quadratic
           dict build-up. See issue #14775. */
    untrack_dicts(young);
    _PyRuntime.gc.long_lived_pending = 0;
    _PyRuntime.gc.long_lived_total = gc_list_size(young);
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;[1] 初始化不可达链表，调用&lt;code&gt;move_unreachable&lt;/code&gt;函数将循环引用的对象移动到不可达链表中：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-c&quot;&gt;/* Move the unreachable objects from young to unreachable.  After this,
 * all objects in young have gc_refs = GC_REACHABLE, and all objects in
 * unreachable have gc_refs = GC_TENTATIVELY_UNREACHABLE.  All tracked
 * gc objects not in young or unreachable still have gc_refs = GC_REACHABLE.
 * All objects in young after this are directly or indirectly reachable
 * from outside the original young; and all objects in unreachable are
 * not.
 */
static void
move_unreachable(PyGC_Head *young, PyGC_Head *unreachable)
{
    PyGC_Head *gc = young-&amp;gt;gc.gc_next;

    /* Invariants:  all objects &quot;to the left&quot; of us in young have gc_refs
     * = GC_REACHABLE, and are indeed reachable (directly or indirectly)
     * from outside the young list as it was at entry.  All other objects
     * from the original young &quot;to the left&quot; of us are in unreachable now,
     * and have gc_refs = GC_TENTATIVELY_UNREACHABLE.  All objects to the
     * left of us in 'young' now have been scanned, and no objects here
     * or to the right have been scanned yet.
     */

    while (gc != young) {
        PyGC_Head *next;

        if (_PyGCHead_REFS(gc)) {
            /* gc is definitely reachable from outside the
             * original 'young'.  Mark it as such, and traverse
             * its pointers to find any other objects that may
             * be directly reachable from it.  Note that the
             * call to tp_traverse may append objects to young,
             * so we have to wait until it returns to determine
             * the next object to visit.
             */
            PyObject *op = FROM_GC(gc);
            traverseproc traverse = Py_TYPE(op)-&amp;gt;tp_traverse;
            assert(_PyGCHead_REFS(gc) &amp;gt; 0);
            _PyGCHead_SET_REFS(gc, GC_REACHABLE);
            (void) traverse(op,
                            (visitproc)visit_reachable,
                            (void *)young);
            next = gc-&amp;gt;gc.gc_next;
            if (PyTuple_CheckExact(op)) {
                _PyTuple_MaybeUntrack(op);
            }
        }
        else {
            /* This *may* be unreachable.  To make progress,
             * assume it is.  gc isn't directly reachable from
             * any object we've already traversed, but may be
             * reachable from an object we haven't gotten to yet.
             * visit_reachable will eventually move gc back into
             * young if that's so, and we'll see it again.
             */
            next = gc-&amp;gt;gc.gc_next;
            gc_list_move(gc, unreachable);
            _PyGCHead_SET_REFS(gc, GC_TENTATIVELY_UNREACHABLE);
        }
        gc = next;
    }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;这边遍历young“代”的container对象链表，&lt;code&gt;_PyGCHead_REFS(gc)&lt;/code&gt;判断是不是root object或从某个root object能直接/间接引用的对象，由于root object集合中的对象是不能回收的，因此，被这些对象直接或间接引用的对象也是不能回收的。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;_PyGCHead_REFS(gc)&lt;/code&gt;为0并不能断定这个对象是可回收的，但是还是先移动到&lt;code&gt;unreachable&lt;/code&gt;链表中，设置了&lt;code&gt;GC_TENTATIVELY_UNREACHABLE&lt;/code&gt;标志表示暂且认为是不可达的，如果是存在被root object直接或间接引用的对象，这样的对象还会被移出&lt;code&gt;unreachable&lt;/code&gt;链表中。&lt;/p&gt;
&lt;p&gt;[2] 将可达的对象移到下一“代”。&lt;/p&gt;
&lt;h3 id=&quot;333-垃圾清除&quot;&gt;3.3.3 垃圾清除&lt;/h3&gt;
&lt;pre&gt;
&lt;code class=&quot;language-c&quot;&gt;// [1]
    /* All objects in unreachable are trash, but objects reachable from
     * legacy finalizers (e.g. tp_del) can't safely be deleted.
     */
    gc_list_init(&amp;amp;finalizers);
    move_legacy_finalizers(&amp;amp;unreachable, &amp;amp;finalizers);
    /* finalizers contains the unreachable objects with a legacy finalizer;
     * unreachable objects reachable *from* those are also uncollectable,
     * and we move those into the finalizers list too.
     */
    move_legacy_finalizer_reachable(&amp;amp;finalizers);

    // [2]
    /* Collect statistics on collectable objects found and print
     * debugging information.
     */
    for (gc = unreachable.gc.gc_next; gc != &amp;amp;unreachable;
                    gc = gc-&amp;gt;gc.gc_next) {
        m++;
    }

    // [3]
    /* Clear weakrefs and invoke callbacks as necessary. */
    m += handle_weakrefs(&amp;amp;unreachable, old);

    // [4]
    /* Call tp_finalize on objects which have one. */
    finalize_garbage(&amp;amp;unreachable);

    // [5]
    if (check_garbage(&amp;amp;unreachable)) {
        revive_garbage(&amp;amp;unreachable);
        gc_list_merge(&amp;amp;unreachable, old);
    }
    else {
        /* Call tp_clear on objects in the unreachable set.  This will cause
         * the reference cycles to be broken.  It may also cause some objects
         * in finalizers to be freed.
         */
        delete_garbage(&amp;amp;unreachable, old);
    }
    
    // [6]
    /* Collect statistics on uncollectable objects found and print
     * debugging information. */
    for (gc = finalizers.gc.gc_next;
         gc != &amp;amp;finalizers;
         gc = gc-&amp;gt;gc.gc_next) {
        n++;
    }
    
    ...

    // [7]
    /* Append instances in the uncollectable set to a Python
     * reachable list of garbage.  The programmer has to deal with
     * this if they insist on creating this type of structure.
     */
    (void)handle_legacy_finalizers(&amp;amp;finalizers, old);
    
    /* Clear free list only during the collection of the highest
     * generation */
    if (generation == NUM_GENERATIONS-1) {
        clear_freelists();
    }
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;[1] 处理&lt;code&gt;unreachable&lt;/code&gt;链表中有finalizer的对象。即python中 实现了&lt;code&gt;__del__&lt;/code&gt;魔法方法的对象&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-c&quot;&gt;/* Move the objects in unreachable with tp_del slots into `finalizers`.
 * Objects moved into `finalizers` have gc_refs set to GC_REACHABLE; the
 * objects remaining in unreachable are left at GC_TENTATIVELY_UNREACHABLE.
 */
static void
move_legacy_finalizers(PyGC_Head *unreachable, PyGC_Head *finalizers)
{
    PyGC_Head *gc;
    PyGC_Head *next;

    /* March over unreachable.  Move objects with finalizers into
     * `finalizers`.
     */
    for (gc = unreachable-&amp;gt;gc.gc_next; gc != unreachable; gc = next) {
        PyObject *op = FROM_GC(gc);

        assert(IS_TENTATIVELY_UNREACHABLE(op));
        next = gc-&amp;gt;gc.gc_next;

        if (has_legacy_finalizer(op)) {
            gc_list_move(gc, finalizers);
            _PyGCHead_SET_REFS(gc, GC_REACHABLE);
        }
    }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;遍历&lt;code&gt;unreachable&lt;/code&gt;链表，将拥有finalizer的实例对象移到&lt;code&gt;finalizers&lt;/code&gt;链表中，并标示为&lt;code&gt;GC_REACHABLE&lt;/code&gt;。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-c&quot;&gt;/* Return true if object has a pre-PEP 442 finalization method. */
static int
has_legacy_finalizer(PyObject *op)
{
    return op-&amp;gt;ob_type-&amp;gt;tp_del != NULL;
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;拥有finalizer的实例对象指的就是实现了&lt;code&gt;tp_del&lt;/code&gt;函数的对象。&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-c&quot;&gt;/* Move objects that are reachable from finalizers, from the unreachable set
 * into finalizers set.
 */
static void
move_legacy_finalizer_reachable(PyGC_Head *finalizers)
{
    traverseproc traverse;
    PyGC_Head *gc = finalizers-&amp;gt;gc.gc_next;
    for (; gc != finalizers; gc = gc-&amp;gt;gc.gc_next) {
        /* Note that the finalizers list may grow during this. */
        traverse = Py_TYPE(FROM_GC(gc))-&amp;gt;tp_traverse;
        (void) traverse(FROM_GC(gc),
                        (visitproc)visit_move,
                        (void *)finalizers);
    }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;对&lt;code&gt;finalizers&lt;/code&gt;链表中拥有finalizer的实例对象遍历其引用对象，调用&lt;code&gt;visit_move&lt;/code&gt;访问者，这些被引用的对象也不应该被释放。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-c&quot;&gt;/* A traversal callback for move_legacy_finalizer_reachable. */
static int
visit_move(PyObject *op, PyGC_Head *tolist)
{
    if (PyObject_IS_GC(op)) {
        if (IS_TENTATIVELY_UNREACHABLE(op)) {
            PyGC_Head *gc = AS_GC(op);
            gc_list_move(gc, tolist);
            _PyGCHead_SET_REFS(gc, GC_REACHABLE);
        }
    }
    return 0;
}

#define IS_TENTATIVELY_UNREACHABLE(o) ( \
    _PyGC_REFS(o) == GC_TENTATIVELY_UNREACHABLE)
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;visit_move&lt;/code&gt;函数将引用对象还在&lt;code&gt;unreachable&lt;/code&gt;链表的对象移到&lt;code&gt;finalizers&lt;/code&gt;链表中。&lt;/p&gt;
&lt;p&gt;[2] 统计&lt;code&gt;unreachable&lt;/code&gt;链表数量。&lt;br/&gt;[3] 处理弱引用。&lt;br/&gt;[4] [5] 开始清除垃圾对象，我们先只看&lt;code&gt;delete_garbage&lt;/code&gt;函数：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-c&quot;&gt;/* Break reference cycles by clearing the containers involved.  This is
 * tricky business as the lists can be changing and we don't know which
 * objects may be freed.  It is possible I screwed something up here.
 */
static void
delete_garbage(PyGC_Head *collectable, PyGC_Head *old)
{
    inquiry clear;

    while (!gc_list_is_empty(collectable)) {
        PyGC_Head *gc = collectable-&amp;gt;gc.gc_next;
        PyObject *op = FROM_GC(gc);

        if (_PyRuntime.gc.debug &amp;amp; DEBUG_SAVEALL) {
            PyList_Append(_PyRuntime.gc.garbage, op);
        }
        else {
            if ((clear = Py_TYPE(op)-&amp;gt;tp_clear) != NULL) {
                Py_INCREF(op);
                clear(op);
                Py_DECREF(op);
            }
        }
        if (collectable-&amp;gt;gc.gc_next == gc) {
            /* object is still alive, move it, it may die later */
            gc_list_move(gc, old);
            _PyGCHead_SET_REFS(gc, GC_REACHABLE);
        }
    }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;遍历&lt;code&gt;unreachable&lt;/code&gt;链表中的container对象，调用其类型对象的&lt;code&gt;tp_clear&lt;/code&gt;指针指向的函数，我们以list对象为例：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-c&quot;&gt;static int
_list_clear(PyListObject *a)
{
    Py_ssize_t i;
    PyObject **item = a-&amp;gt;ob_item;
    if (item != NULL) {
        /* Because XDECREF can recursively invoke operations on
           this list, we make it empty first. */
        i = Py_SIZE(a);
        Py_SIZE(a) = 0;
        a-&amp;gt;ob_item = NULL;
        a-&amp;gt;allocated = 0;
        while (--i &amp;gt;= 0) {
            Py_XDECREF(item[i]);
        }
        PyMem_FREE(item);
    }
    /* Never fails; the return value can be ignored.
       Note that there is no guarantee that the list is actually empty
       at this point, because XDECREF may have populated it again! */
    return 0;
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;_list_clear&lt;/code&gt;函数对container对象的每个元素进行引用数减量操作并释放container对象内存。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;delete_garbage&lt;/code&gt;在对container对象进行&lt;code&gt;clear&lt;/code&gt;操作之后，还会检查是否成功，如果该container对象没有从&lt;code&gt;unreachable&lt;/code&gt;链表上摘除，表示container对象还不能销毁，需要放回到老一“代”中，并标记&lt;code&gt;GC_REACHABLE&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;[6] 统计&lt;code&gt;finalizers&lt;/code&gt;链表数量。&lt;br/&gt;[7] 处理&lt;code&gt;finalizers&lt;/code&gt;链表的对象。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-c&quot;&gt;/* Handle uncollectable garbage (cycles with tp_del slots, and stuff reachable
 * only from such cycles).
 * If DEBUG_SAVEALL, all objects in finalizers are appended to the module
 * garbage list (a Python list), else only the objects in finalizers with
 * __del__ methods are appended to garbage.  All objects in finalizers are
 * merged into the old list regardless.
 * Returns 0 if all OK, &amp;lt;0 on error (out of memory to grow the garbage list).
 * The finalizers list is made empty on a successful return.
 */
static int
handle_legacy_finalizers(PyGC_Head *finalizers, PyGC_Head *old)
{
    PyGC_Head *gc = finalizers-&amp;gt;gc.gc_next;

    if (_PyRuntime.gc.garbage == NULL) {
        _PyRuntime.gc.garbage = PyList_New(0);
        if (_PyRuntime.gc.garbage == NULL)
            Py_FatalError(&quot;gc couldn't create gc.garbage list&quot;);
    }
    for (; gc != finalizers; gc = gc-&amp;gt;gc.gc_next) {
        PyObject *op = FROM_GC(gc);

        if ((_PyRuntime.gc.debug &amp;amp; DEBUG_SAVEALL) || has_legacy_finalizer(op)) {
            if (PyList_Append(_PyRuntime.gc.garbage, op) &amp;lt; 0)
                return -1;
        }
    }

    gc_list_merge(finalizers, old);
    return 0;
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;遍历&lt;code&gt;finalizers&lt;/code&gt;链表，将拥有finalizer的实例对象放到一个名为garbage的PyListObject对象中，可以通过gc模块查看。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-powershell&quot;&gt;&amp;gt;&amp;gt;&amp;gt; import gc
&amp;gt;&amp;gt;&amp;gt; gc.garbage
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;并把&lt;code&gt;finalizers&lt;/code&gt;链表晋升到老一“代”。&lt;/p&gt;
&lt;blockquote readability=&quot;7&quot;&gt;
&lt;p&gt;&lt;strong&gt;注意：&lt;code&gt;__del__&lt;/code&gt;给gc带来的影响, gc模块唯一处理不了的是循环引用的类都有&lt;code&gt;__del__&lt;/code&gt;方法，所以项目中要避免定义&lt;code&gt;__del__&lt;/code&gt;方法&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&quot;34-小结&quot;&gt;3.4 小结&lt;/h3&gt;
&lt;ol readability=&quot;2.5&quot;&gt;&lt;li readability=&quot;8&quot;&gt;
&lt;p&gt;GC的流程:&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;-&amp;gt; 发现超过阈值了
-&amp;gt; 触发垃圾回收
-&amp;gt; 将所有可达对象链表放到一起
-&amp;gt; 遍历, 计算有效引用计数
-&amp;gt; 分成 有效引用计数=0 和 有效引用计数 &amp;gt; 0 两个集合
-&amp;gt; 大于0的, 放入到更老一代
-&amp;gt; =0的, 执行回收
-&amp;gt; 回收遍历容器内的各个元素, 减掉对应元素引用计数(破掉循环引用)
-&amp;gt; 执行-1的逻辑, 若发现对象引用计数=0, 触发内存回收
-&amp;gt; 由python底层内存管理机制回收内存
&lt;/code&gt;
&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;触发GC的条件&lt;/p&gt;
&lt;ul readability=&quot;-0.5&quot;&gt;&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;主动调用&lt;code&gt;gc.collect(),&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;当gc模块的计数器达到阀值的时候&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;程序退出的时候&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;h2 id=&quot;4-gc阈值&quot;&gt;4. GC阈值&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;分代回收 以空间换时间&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote readability=&quot;11&quot;&gt;
&lt;p&gt;&lt;strong&gt;重要思想&lt;/strong&gt;：将系统中的所有内存块根据其存活的时间划分为不同的集合, 每个集合就成为一个”代”, 垃圾收集的频率随着”代”的存活时间的增大而减小(活得越长的对象, 就越不可能是垃圾, 就应该减少去收集的频率)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;弱代假说&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;分代垃圾回收算法的核心行为：垃圾回收器会更频繁的处理新对象。一个新的对象即是你的程序刚刚创建的，而一个来的对象则是经过了几个时间周期之后仍然存在的对象。Python会在当一个对象从零代移动到一代，或是从一代移动到二代的过程中提升&lt;code&gt;(promote)&lt;/code&gt;这个对象。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;为什么要这么做？&lt;/strong&gt;这种算法的根源来自于弱代假说(&lt;strong&gt;weak generational hypothesis&lt;/strong&gt;)。这个假说由两个观点构成：&lt;/p&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;首先是年亲的对象通常死得也快，而老对象则很有可能存活更长的时间。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;假定我们创建了一个Python创建：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-python&quot;&gt;n1 = Node(&quot;ABC&quot;)
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;根据假说，我的代码很可能仅仅会使用ABC很短的时间。这个对象也许仅仅只是一个方法中的中间结果，并且随着方法的返回这个对象就将变成垃圾了。大部分的新对象都是如此般地很快变成垃圾。然而，偶尔程序会创建一些很重要的，存活时间比较长的对象-例如web应用中的session变量或是配置项。&lt;/p&gt;
&lt;blockquote readability=&quot;7&quot;&gt;
&lt;p&gt;通过频繁的处理零代链表中的新对象，Python的垃圾收集器将把时间花在更有意义的地方：它处理那些很快就可能变成垃圾的新对象。同时只在很少的时候，当满足阈值的条件，收集器才回去处理那些老变量。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;5-python中的gc模块使用&quot;&gt;5. Python中的gc模块使用&lt;/h2&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;gc模块默认是开启自动回收垃圾的，&lt;code&gt;gc.isenabled()=True&lt;/code&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;常用函数:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;code&gt;gc.set_debug(flags)&lt;/code&gt; 设置gc的debug日志，一般设置为&lt;code&gt;gc.DEBUG_LEAK&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;pre&gt;
&lt;code class=&quot;language-python&quot;&gt;&quot;&quot;&quot;
DEBUG_STATS - 在垃圾收集过程中打印所有统计信息
DEBUG_COLLECTABLE - 打印发现的可收集对象
DEBUG_UNCOLLECTABLE - 打印unreachable对象(除了uncollectable对象)
DEBUG_SAVEALL - 将对象保存到gc.garbage(一个列表)里面，而不是释放它
DEBUG_LEAK - 对内存泄漏的程序进行debug (everything but STATS).
    
&quot;&quot;&quot;
&lt;/code&gt;
&lt;/pre&gt;
&lt;ul readability=&quot;8.5&quot;&gt;&lt;li readability=&quot;2&quot;&gt;
&lt;p&gt;&lt;code&gt;gc.collect([generation])&lt;/code&gt; 显式进行垃圾回收，可以输入参数，0代表只检查第一代的对象，1代表检查一，二代的对象，2代表检查一，二，三代的对象，如果不传参数，执行一个full collection，也就是等于传2。 返回不可达（unreachable objects）对象的数目&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;&lt;code&gt;gc.get_threshold()&lt;/code&gt; 获取的gc模块中自动执行垃圾回收的频率&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;&lt;code&gt;gc.get_stats()&lt;/code&gt;查看每一代的具体信息&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;1&quot;&gt;
&lt;p&gt;&lt;code&gt;gc.set_threshold(threshold0[, threshold1[, threshold2])&lt;/code&gt; 设置自动执行垃圾回收的频率&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;7&quot;&gt;
&lt;p&gt;&lt;code&gt;gc.get_count()&lt;/code&gt; 获取当前自动执行垃圾回收的计数器，返回一个长度为3的列表&lt;/p&gt;
&lt;p&gt;例如&lt;strong&gt;(488,3,0)&lt;/strong&gt;，其中488是指距离上一次一代垃圾检查，Python分配内存的数目减去释放内存的数目，注意是内存分配，而不是引用计数的增加。&lt;/p&gt;
&lt;p&gt;3是指距离上一次二代垃圾检查，一代垃圾检查的次数，同理，0是指距离上一次三代垃圾检查，二代垃圾检查的次数。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;计数器和阈值关系解释：&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-python&quot;&gt;当计数器从(699,3,0)增加到(700,3,0)，gc模块就会执行gc.collect(0),即检查一代对象的垃圾，并重置计数器为(0,4,0)
当计数器从(699,9,0)增加到(700,9,0)，gc模块就会执行gc.collect(1),即检查一、二代对象的垃圾，并重置计数器为(0,0,1)
当计数器从(699,9,9)增加到(700,9,9)，gc模块就会执行gc.collect(2),即检查一、二、三代对象的垃圾，并重置计数器为(0,0,0)
&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;6-工作中如何避免循环引用？&quot;&gt;6. 工作中如何避免循环引用？&lt;/h2&gt;
&lt;blockquote readability=&quot;9.72&quot;&gt;
&lt;p&gt;To avoid circular references in your code, you can use weak references, that are implemented in the &lt;code&gt;weakref&lt;/code&gt; module. Unlike the usual references, the &lt;code&gt;weakref.ref&lt;/code&gt; doesn't increase the reference count and returns &lt;code&gt;None&lt;/code&gt; if an object was destroyed. &lt;a href=&quot;https://rushter.com/blog/python-garbage-collector/&quot;&gt;rushter&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;pre&gt;
&lt;code class=&quot;language-python&quot;&gt;import weakref


class Node():
    def __init__(self, value):
        self.value = value
        self._parent = None
        self.children = []

    def __repr__(self):
        return 'Node({!r:})'.format(self.value)

    @property
    def parent(self):
        return None if self._parent is None else self._parent()

    @parent.setter
    def parent(self, node):
        self._parent = weakref.ref(node)

    def add_child(self, child):
        self.children.append(child)
        child.parent = self


if __name__ == '__main__':

    a = Data()
    del a

    a = Node()
    del a

    a = Node()
    a.add_child(Node())
    del a
&lt;/code&gt;
&lt;/pre&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;弱引用消除了引用循环的这个问题，本质来讲，&lt;strong&gt;弱引用就是一个对象指针，它不会增加它的引用计数&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;为了访问弱引用所引用的对象，你可以像函数一样去调用它即可。如果那个对象还存在就会返回它，否则就返回一个None。 由于原始对象的引用计数没有增加，那么就可以去删除它了&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;参考文章和书籍:&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;&lt;a href=&quot;http://patshaughnessy.net/2013/10/24/visualizing-garbage-collection-in-ruby-and-python&quot;&gt;visualizing garbage collection in ruby and python&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/Junnplus/blog/issues/19&quot;&gt;膜拜的大佬-Junnplus'blog&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://wklken.me/posts/2015/09/29/python-source-gc.html&quot;&gt;wklken前辈&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://pythoninternal.wordpress.com/2014/08/04/the-garbage-collector/&quot;&gt;The Garbage Collector&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://rushter.com/blog/python-garbage-collector/&quot;&gt;Garbage collection in Python: things you need to know&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://python3-cookbook.readthedocs.io/zh_CN/latest/c08/p23_managing_memory_in_cyclic_data_structures.html&quot;&gt;Python-CookBook-循环引用数据结构的内存管理&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;《python源码剖析》&lt;/li&gt;
&lt;li&gt;Python-3.8.3/Modules/gcmodule.c&lt;/li&gt;
&lt;/ol&gt;</description>
<pubDate>Thu, 11 Jun 2020 16:01:00 +0000</pubDate>
<dc:creator>JonPan</dc:creator>
<og:description>Python的垃圾回收机制包括了两大部分： 引用计数(大部分在 Include/object.h 中定义) 标记清除+隔代回收(大部分在 Modules/gcmodule.c 中定义) 1. 引用计数</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/panlq/p/13096942.html</dc:identifier>
</item>
<item>
<title>01 . Docker原理部署及常用操作命令 - you-men</title>
<link>http://www.cnblogs.com/you-men/p/13096875.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/you-men/p/13096875.html</guid>
<description>&lt;h4 id=&quot;docker的来源及构造&quot;&gt;Docker的来源及构造:&lt;/h4&gt;
&lt;blockquote readability=&quot;9&quot;&gt;
&lt;p&gt;容器是一种基础工具：泛指任何用于容纳其他物品的工具，可以部分或完全封闭，被用于容纳，储存，运输物品：　物品可以被放置在容器中，而容器可以保护内容物：&lt;/p&gt;
&lt;p&gt;人类使用容器的历史有十万年，甚至可能有数百万年的历史:&lt;/p&gt;
&lt;/blockquote&gt;
&lt;pre&gt;
&lt;code class=&quot;language-shell&quot;&gt;     #   容器类型：
     #     瓶，罐，箱，篮，桶，袋
&lt;/code&gt;
&lt;/pre&gt;
&lt;blockquote readability=&quot;106&quot;&gt;
&lt;p&gt;但我们重点在LXC这里；&lt;/p&gt;
&lt;p&gt;虚拟化和容器的关系:&lt;/p&gt;
&lt;p&gt;主机级虚拟化:虚拟化的是整个完整的物理硬件平台,比如VMware,KVM.里面跑的是与宿主机不一样的系统&lt;/p&gt;
&lt;p&gt;两种类型：&lt;br/&gt;类型一： 直接在硬件上装一个虚拟机管理器，不装宿主机，在虚拟机管理器上跑需要的操作系统：&lt;br/&gt;类型二：　Vmware,kvm&lt;br/&gt;&lt;strong&gt;完整意义的操作系统:&lt;/strong&gt; 我们自己在上面装一个内核，内核上面有一个用户空间，用户空间里面跑进程。&lt;/p&gt;
&lt;p&gt;但是运行内核并不是我们主要目的，内核核心作用在于资源分配和管理。&lt;/p&gt;
&lt;p&gt;就是说真正在应用空间跑的应用程序才是能产生生产力的，就好比我们跑一个web服务，内核其实很少提供服务。&lt;/p&gt;
&lt;p&gt;而出于通用目的的而设计的资源管理平台，操作系统管理内核。我们并不太需要：&lt;/p&gt;
&lt;p&gt;但是内核也不得不有，原因在于要想在一组硬件平台跑软件程序，而现在的软件都是针对于内核调用和系统调用，库调用研发的，而不安装这些没法运行程序，所以内核看上去没多大用，但是也必不可少；&lt;/p&gt;
&lt;p&gt;更何况，我们一旦有了用户空间后，里面运行很多进程，这些进程为了协调也需要内核。&lt;/p&gt;
&lt;p&gt;但假设我们创建一个虚拟机，只为了运行一个nginx,tomcat,却不得不去安装内核，用户空间，再去跑tomcat，代价就有点大了。&lt;/p&gt;
&lt;p&gt;而在这里如果我们用二级虚拟化来分析的话：&lt;/p&gt;
&lt;p&gt;如果为了运行一个进程，就要实现两级调度和资源分派。&lt;/p&gt;
&lt;p&gt;第一，自己虚拟机有一个内核，已经实现了一次内存虚拟化，cpu调度以及IO调度和io 管理。&lt;/p&gt;
&lt;p&gt;但是真正虚拟机也是被宿主机内核管理一次，这个中间浪费可以想一下。&lt;/p&gt;
&lt;p&gt;传统的主机虚拟化技术，确实能让我们一组硬件平台之上实现跨系统传进的隔离和试验，调试，资源高效利用。而带来的资源开销不容忽视的，而很多时候，我们创建虚拟机只是为了运行一个和几个附有生产责任的进程而已，为此；&lt;/p&gt;
&lt;p&gt;减少中间层就是一个好的办法，&lt;/p&gt;
&lt;p&gt;比如在二级虚拟化我们把虚拟机那一层给抽掉，只保留进程，但是我们加虚拟机就是为了环境隔离，比如说一台机器跑两个或者五个nginx，我们一台机器没有那么多套接字和80端口。&lt;/p&gt;
&lt;p&gt;而我们虚拟机就是为了资源隔离，就算把里面的nginx翻江倒海，坏的也是哪一个虚拟机。&lt;/p&gt;
&lt;p&gt;所以这里的隔离才是我们的目标，我们虽然想抽掉这一层内核，但是不能让他回到在一个锅里吃饭那个环境，所以要让每一个组进程互相不可干扰的，只不过共享一个底层资源而已。&lt;/p&gt;
&lt;p&gt;因此我们想要的环境就是：&lt;/p&gt;
&lt;p&gt;创建一个又一个隔离环境，我们要运行隔离的程序就让他跑在隔离环境中，内核提供的是内核空间，进程试运行在用户空间，而这里就能实现将用户空间隔离成多个用户空间，互不干扰，这里一般都有一个空间是有特权的，一般第一个。而这里众多用户空间运行的都是同一个内核，被同一个内核管理的。但是运行时候能看到的边界只能是当前用户空间的边界，虽然没有主机级虚拟化隔离那么彻底。&lt;/p&gt;
&lt;p&gt;更重要是，这个用户空间放进程,给进程提供运行环境,并且保护内部进程不被其他进程所干扰.叫做容器.&lt;/p&gt;
&lt;p&gt;虚拟的隔离环境管理器&lt;/p&gt;
&lt;p&gt;一层硬件平台容器不是什么新概念，最早出现在2000年，当年叫jail，监狱，监禁之意，里面就像一个沙箱，就算里面那个程序bug,有了故障，异常行为，也无法影响这个容器之外的程序运行，这也是jail初衷。&lt;/p&gt;
&lt;p&gt;容器并非起源于 Linux，但开源世界的最精彩之处就在于借鉴、修改和改进，容器也不例外.&lt;/p&gt;
&lt;p&gt;但这个概念非常有吸引力。&lt;/p&gt;
&lt;p&gt;2001 年，通过 Jacques Gélinas 的 [VServer 项目，]隔离环境的实施进入了 Linux 领域。正如 Gélinas 所说，这项工作的目的是“&lt;strong&gt;在高度独立且安全的单一环境中运行多个通用 Linux 服务器 [sic]。” 在完成了这项针对 Linux 中多个受控制用户空间的基础性工作后，Linux 容器开始逐渐成形并最终发展成了现在的模样。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;一般来讲，就算一个程序被远程劫持在里面搞起破坏，他的边界也仅仅是哪个容器的边界，最初只是为了应用的安全运行。&lt;/p&gt;
&lt;p&gt;后来有人把这个技术山寨到Linux平台上，叫Vserver（chroot），在一个子目录定义一个根，让里面的程序以为他就是根。&lt;/p&gt;
&lt;p&gt;chroot他能实现的你看上去的那层空间，底层还是同一个内核，进程运行是特权模式还是普通模式，表面很简单，真正实现起来涉及东西至少要有；&lt;/p&gt;
&lt;p&gt;在一个单独用户空间当中，它主要目的是隔离使用，要让里面进程以为他就运行在底层内核之上，有六点：&lt;/p&gt;
&lt;/blockquote&gt;
&lt;pre&gt;
&lt;code class=&quot;language-shell&quot;&gt;# 1. 主机名和域名：　UTS
# 2. 根文件系统 :           MOUNT
# 3. 应该有自己的IPC,进程间的专用通道，如果能让两个用户空间进程能互相通信，也没有意义了，共享内存，拒绝跨用户空间。 IPC
# 4. 给每个用户空间做一个假的init，只能有一个，pid,1,每个系统正常来说只有一个，为了隔离，给每个空间伪装一个。
# 5. 必须给每个用户伪装一个root，实现效果就是在真正系统只是普通用户，在他所属用户空间里面可以为所欲为，让进程看起来是root.
# 6. IP地址，互相通信，而在内核级别，tcp协议栈只有一个，
&lt;/code&gt;
&lt;/pre&gt;
&lt;blockquote readability=&quot;12&quot;&gt;
&lt;p&gt;为了容器机制的实现,Linux内核对着六种明成空间原生支持，namespaces。直接通过系统调用对外进行输出，&lt;/p&gt;
&lt;p&gt;直到今天，所谓的容器就是靠六个namespaces和chroot来实现的。&lt;/p&gt;
&lt;p&gt;听上去容易，这六种名成空间有一个是到内核3.8才实现的，所以要想完美使用容器，要内核版本3.8以上。centos6天然排除在外.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;namespace&lt;/th&gt;
&lt;th&gt;系统调用参数&lt;/th&gt;
&lt;th&gt;隔离内容&lt;/th&gt;
&lt;th&gt;内核版本&lt;/th&gt;
&lt;/tr&gt;&lt;/thead&gt;&lt;tbody readability=&quot;2&quot;&gt;&lt;tr&gt;&lt;td&gt;UTS&lt;/td&gt;
&lt;td&gt;clone_newuts&lt;/td&gt;
&lt;td&gt;主机名和域名&lt;/td&gt;
&lt;td&gt;2.6.19&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;IPC&lt;/td&gt;
&lt;td&gt;clone_newipc&lt;/td&gt;
&lt;td&gt;信号量、消息队列和共享内存&lt;/td&gt;
&lt;td&gt;2.6.19&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;PID&lt;/td&gt;
&lt;td&gt;clone_newpid&lt;/td&gt;
&lt;td&gt;进程编号&lt;/td&gt;
&lt;td&gt;2.6.24&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;Network&lt;/td&gt;
&lt;td&gt;clon_newnet&lt;/td&gt;
&lt;td&gt;网络设备、网络栈、端口等&lt;/td&gt;
&lt;td&gt;2..29&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Mount&lt;/td&gt;
&lt;td&gt;clone_newns&lt;/td&gt;
&lt;td&gt;挂载点(文件系统)&lt;/td&gt;
&lt;td&gt;2.4.19&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;User&lt;/td&gt;
&lt;td&gt;clone_newuser&lt;/td&gt;
&lt;td&gt;用户和用户组&lt;/td&gt;
&lt;td&gt;3.8&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;&lt;strong&gt;容器级虚拟化:&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote readability=&quot;13&quot;&gt;
&lt;p&gt;资源限制: 我们可以在整体资源做比例性分配，也可以在单一用户空间做核心绑定,你只能使用几个核;不然的话一个进程内存泄露整个系统都蹦了；或者一个进程占用了绝大部分CPU.&lt;/p&gt;
&lt;p&gt;内存是压缩不了的，多一点都不能，一给就收不回来了，因为内存是压缩不了的；&lt;/p&gt;
&lt;p&gt;实现这个Control Cgroups&lt;/p&gt;
&lt;/blockquote&gt;
&lt;pre&gt;
&lt;code class=&quot;language-shell&quot;&gt;blkio:                # 块设备IO
cpu:                    # CPU
cpuacct:                # CPU资源使用报告
cpuset:                 # 多处理器平台上的cpu集合
devices:                # 设备访问
freezer:                # 挂起或恢复任务
memory:                 # 内存用量及报告
perf_event:             # 对cgroup中的任务进行统一性能测试
net_cls:                # cgroup中的任务创建的数据报文的类别；        
&lt;/code&gt;
&lt;/pre&gt;
&lt;blockquote readability=&quot;44&quot;&gt;
&lt;p&gt;划分成组后，在不同组内进行资源分配，组还可以再分。&lt;/p&gt;
&lt;p&gt;即使有了chroot,nameespaces, control cgroups,容器的隔离能力比起主机级别虚拟化依然差很多，因为容器毕竟属于同一个内核，而主机级虚拟化那么好，因为内核本来就是天然的隔离，因此为了加强安全性，防止里面的进程通过漏洞绕过边界伸到别的用户空间，通过selinux各种安全机制加强容器的边界，为了支撑容器做的更加完善。&lt;/p&gt;
&lt;p&gt;容器实现就是靠chroot,nameespaces,cgroups核心技术实现，而这些在内核已经实现了。&lt;/p&gt;
&lt;p&gt;容器本来是靠jail启发有了vserver,后来为了让这种容器更加易用，&lt;/p&gt;
&lt;p&gt;因为创建容器要自己写代码，系统调用，克隆等来实现的，但麻烦程度很大。&lt;/p&gt;
&lt;p&gt;所以我们最好把实现容器的这种功能做成一种工具，极大的简化容器的使用，于是就有了LXC的解决方案，&lt;/p&gt;
&lt;p&gt;LXCx　container,最早一批真正把完整的容器技术用一组简易使用的工具和摸板来极大的简化了容器的使用方案。&lt;/p&gt;
&lt;p&gt;lxc-create : 创建一个容器，template,摸板一组脚本，&lt;/p&gt;
&lt;p&gt;创建一个明成空间后，这脚本自动执行后，自动实现安装过程，指向了你所打算创建哪一类明成空间的系统发行版所属的仓库，从仓库中镜像下载过来，安装，生成这个新的名成空间，就可以像虚拟机一样使用。&lt;/p&gt;
&lt;p&gt;所有的明成空间都这样实现，而lxc就靠这样这一组工具包快速实现创建空间，利用模板完成内部所需要各种文件的安装，同时还有些工具可以通过chroot切换来切换去，于是我们就可以愉快的使用了，跟虚拟机没多大区别；&lt;/p&gt;
&lt;p&gt;lxc在容器技术推广绝对功不可没，但依然有很高门槛：&lt;/p&gt;
&lt;/blockquote&gt;
&lt;pre&gt;
&lt;code class=&quot;language-shell&quot;&gt;# 1. 学好lxc命令
# 2. 必要时候需要定制模板，
# 3. 如果在里面运行Mysql，如果服务在里面出现故障，如何迁移数据；
# 4. 批量创建也不容易
&lt;/code&gt;
&lt;/pre&gt;
&lt;blockquote readability=&quot;121&quot;&gt;
&lt;p&gt;虽然极大的简化了容器使用，但是在复杂程度没有多大降低的，更何况他的隔离性没有虚拟机那么好，&lt;/p&gt;
&lt;p&gt;好处是性能资源方面的节约，让每一个进程直接使用宿主机的性能。&lt;/p&gt;
&lt;p&gt;于是后来出现了docker:&lt;/p&gt;
&lt;p&gt;lxc增强版，也不是容器，容器的一个易用前端工具。&lt;/p&gt;
&lt;p&gt;lxc批量创建挺难，docker就在这个上面找突破点，docker早期核心就是lxc，他是lxc的二次封装发行版。&lt;/p&gt;
&lt;p&gt;功能上利用lxc做容器管理引擎，创建容器时不再使用模板安装，而是使用一种镜像技术，&lt;/p&gt;
&lt;p&gt;我们尝试着把一个操作系统用户空间所需要用到的所需要所有组件事先准备编排好，编排好后整体打包成一个文件，叫做镜像文件，这个镜像文件是放在一个集中统一的仓库中的，我把大家都会用到的最小化centos,ubuntu分别放在仓库内；&lt;/p&gt;
&lt;p&gt;而在这里我们在这个最小化系统里面先装好源码nginx,再打包成一个镜像，也放入这个仓库中，当启动创建容器时候，需用镜像，把镜像拖到本地，基于镜像启动容器。所以docker极大的简化了容器使用程度；&lt;/p&gt;
&lt;p&gt;比如说你想跑一个tomcat,nginx直接docker run就完成了&lt;/p&gt;
&lt;p&gt;为了易于管理，docker还采用另外一种方式，在一个用户空间当中，我们尝试只运行一组进程或一个进程，我们目的就是为了运行一个有生产力的程序，比如我们在主机上要跑tomcat,nginx,nginx运行在nginx容器中，tomcat运行在tomcat容器中，二者用容器间通信逻辑进行通信，所以以后一个容器只运行一个进程，这也是docker的目的；&lt;/p&gt;
&lt;p&gt;lxc就是当虚拟机使用，到时候管理极为不便；&lt;/p&gt;
&lt;p&gt;而docker这里实现功能：&lt;/p&gt;
&lt;p&gt;不用容器，一个内核之上运行各种进程 ，大家属于同一个用户空间，共享同一组主机名，用户，ipc,pid,在同一个可视范围内，如果一个黑客劫持一个进程以他做跳板可以威胁到其他进程&lt;/p&gt;
&lt;p&gt;而docker,把他们给圈起来了，彼此间不可见，而且这个容器只为了这一个进程，最小化定义的；&lt;br/&gt;坏处，占用更多空间，如果服务坏了，调试工具只针对一个容器有效，而如果加上调试工具违反了唯一进程目的，&lt;/p&gt;
&lt;p&gt;所以带来问题：本来调试一个进程极为简单，可能没有工具：&lt;/p&gt;
&lt;p&gt;而要想调试得突破他的边界:&lt;/p&gt;
&lt;p&gt;好处；删除了不影响别人:&lt;/p&gt;
&lt;p&gt;给运维带来极大不便利，给开发带来巨大好处，分发容易了，一次编写到处运行。现在环境都是异构的，&lt;/p&gt;
&lt;p&gt;centos5,6,7/Ubuntu/deepin/suse/kali/redhat/AIX&lt;/p&gt;
&lt;p&gt;要开发一个软件，要开发每一种平台的软件，各自组织一个团队开发，只需要打包一个镜像，不管你是windows,linux,unix跟内核没关系，跟操作系统没关系，他有自己的明成空间&lt;/p&gt;
&lt;p&gt;跟java类似这种效果，但是java有很多版本，6,7,8&lt;/p&gt;
&lt;p&gt;以前部署需要发布，变更，故障处理&lt;/p&gt;
&lt;p&gt;有了镜像，直接one，就行了，但是还需要接路由器和调度器，如果有一个容器编排工具，之间run结束，甚至连run都不需要你手动执行；&lt;/p&gt;
&lt;p&gt;像以前的java容器只能支持java一种语言；&lt;/p&gt;
&lt;p&gt;而docker不会管你是什么语言；&lt;/p&gt;
&lt;p&gt;随之带来运维的问题，发布操作用编排工具来实现，docker必须要使用编排工具来管理，不用的话手动管理比我们直接管理应用程序更麻烦，增加我们运维环境复杂度；但确实是降低开发压力；&lt;/p&gt;
&lt;p&gt;运维工作就是维稳，以往调试很容易，而容器可能没有调试工具，这么一来就意味着，我以后做镜像需要为每一个镜像自带调试工具，这么一来意味着做镜像需要自带一些工具，以前能共享的，现在不能，但他们却是隔离的；&lt;/p&gt;
&lt;p&gt;docker还有一个好处：　批量创建，他创建容器采用&lt;/p&gt;
&lt;p&gt;分层构建，联合挂载；使得我们以后镜像分发没有那么庞大，比如说我在一个系统上运行三个容器，都是基于底层centos构建，在这里只用一个centos基础镜像，三个上层nginx,tomcat,mariadb，底层镜像是共享的，底层镜像是只读的，要想改，在每一层联合挂载镜像栈最顶层额外附加一个新层，这个层才是能读能写的；&lt;/p&gt;
&lt;p&gt;迁移很困难，如果要把容器迁移到其他地方，但这里是有状态的，真正在使用容器时，不会在本地存储有效数据，他会在文件系统上共享存储，而用户存储数据，这个服务不小心宕掉了，再找一个主机重新数据加载就行了，再访问数据还在，所以数据脱离宿主机，脱离容器而持久，容器可以丢到任何主机上；&lt;/p&gt;
&lt;p&gt;存储需要一个外置持久性存储，程序是由指令＋数据组成，&lt;/p&gt;
&lt;p&gt;把容器当进程使用，启动一个容器，就是为了运行一个进程，进程一终止，把容器删了，不要了，下次重新创建，重新挂载&lt;/p&gt;
&lt;p&gt;容器不需要持久，容器和进程一样有生命周期，从创建而开始，从停止到结束，跟我们主机都没多大关系，可以运行在任何主机上；&lt;/p&gt;
&lt;p&gt;在docker之上建设一个层次，看那个主机更闲，来个调度法则，如果需要持久数据，给个web存储空间，挂载上去存储数据，一旦任务结束直接容器一删，结束，这个组件能帮我们把要启动容器调度于整个底层集群环境中某一个docker主机之上，当要构建lnmp，谁先启动，docker就解决不来这种功能，我们需要一个docker基础之上，能够把这种应用程序依赖关系，从属关系，隶属关系反映在启动关闭时的次序和管理逻辑中，这种功能叫容器编排工具；&lt;/p&gt;
&lt;/blockquote&gt;
&lt;pre&gt;
&lt;code class=&quot;language-shell&quot;&gt;# 在docker之后出现了各种编排工具，
machine+swarm+compose:    # compose只能单机编排，
mesos:                    # 统一资源调度和分配的     + 实现编排需要加上  marathon
kubernetes  -- &amp;gt;  k8s
&lt;/code&gt;
&lt;/pre&gt;
&lt;blockquote readability=&quot;40&quot;&gt;
&lt;p&gt;google使用容器有十几年历史了，据说每一周销毁和新建容器多达几十亿。&lt;/p&gt;
&lt;p&gt;docker因缘巧合摸到了这个门道，并且做成开源软件，谷歌就坐不住了，自己本来做为独门武器，那小子居然找到一种办法还公开所有人使用，本来我最有话语权，秘而不宣藏起来，这样才能称为独门武器，必要时候必杀技；&lt;/p&gt;
&lt;p&gt;但是docker已然独霸话语权了，好在docker也不是铁板一块，后来出来出来另一个公司，谷歌就在后面大力扶植反对派，后来发现难以跟docker抗衡，上不来台面；&lt;/p&gt;
&lt;p&gt;容器编排工具在谷歌已经跑了十几年了，该踩的坑都踩的差不多了；&lt;/p&gt;
&lt;p&gt;docker三两年做不到；&lt;/p&gt;
&lt;p&gt;于是kubemetes横空出世，占据了百分八十的市场，成为市场的标准，还成立了CNCF 容器标准组织，docker有一个问题，docker在编排上没有经验，义无建树，技术没走好，没有吸引更多的土豪进来投资，上市做独角兽，虽然互联网上火的不要不要的，但是无法变现，决定，把开源版拆分为企业版和社区版，将社区改名，把docker流量引入企业版，后来改名叫moby,把所有docker引入企业版，&lt;/p&gt;
&lt;p&gt;之所以这样 docker是因为一家商业公司，谷歌在做k8s时候向大家表明我是没有任何意图的，于是把k8s源代码捐给了cncf,cncf是由很多组织联合成立的，主导权不再属于谷歌，属于IMB,微软等等，不会被人说想把k8s私有化，一年四个版本发布，go研发的&lt;/p&gt;
&lt;p&gt;后来docker研发了一个容器引擎，libcontainer，替换了lxc,docker已经被cncf挟持了，cncf自己玩，把docker排除在外，如果以后容器要走下去肯定要开源，标准化，谁来负责标准化，cncf就可以做，定义标准，但这样太欺负docker了，所以给docker个机会，你来定标准化，同时做一款开源软件。&lt;/p&gt;
&lt;p&gt;现在新的docker引擎已经是runC了，&lt;/p&gt;
&lt;p&gt;虽然k8s支持很多种容器，但常见的还是docker+k8s;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4 id=&quot;镜像管理基础&quot;&gt;镜像管理基础&lt;/h4&gt;
&lt;blockquote readability=&quot;21&quot;&gt;
&lt;p&gt;docker架构形式：只考虑单机之上，整体架构是这样的：&lt;/p&gt;
&lt;p&gt;整体是一个dockerhosts: docker server端&lt;/p&gt;
&lt;p&gt;dockerhost　就是运行有docker进程(守护进程)的主机，被称为docerhost,dockerserver;&lt;/p&gt;
&lt;p&gt;docker接收到创建和启动容器命令后，将在本地创建容器，一个dockerhost上可以启动多个容器，此处我们可能运行的分别不属于各种不同程序的容器，而容器取决于镜像来实现，如果本地没有,dockerdaemon自动链接到registries上，而后从中获得镜像后，先存储到本地一个能够专门存储所谓镜像存储空间中，要求得是特殊并且特殊的文件系统，overlay2,&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://www.cnblogs.com/Users/youmen/Documents/blog/z/docker/1.png&quot; alt=&quot;1&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;这里面可能有多个镜像文件，镜像本身是只读的，而且镜像在registries放的时候仓库名就是应用程序名，而后仓库内可以放多个镜像，而且这些镜像通常属于同一个应用程序不同版本，我们用标签来识别;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;docker镜像:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;含有启动容器所需要的文件系统及其内容，因此，其用于创建并启动docker容器:&lt;/p&gt;
&lt;p&gt;采用分层构建机制，大体分为两层，最底层为bootfs,其之为rootfs&lt;/p&gt;
&lt;p&gt;真正让用户拿来去构建用户空间并运行进程容器的是rootfs;&lt;/p&gt;
&lt;p&gt;bootfs: 用于系统引导的文件系统，包括bootloader和kernel ,容器启动完成后会被卸载以节约内存资源&lt;/p&gt;
&lt;p&gt;这里的kernel仅仅用于引导并启动一个用户空间，启动完之后就没有了以节约内存资源，毕竟很有可能我们用户空间跟底层内核还是有一点不同之处的，向上就是rootfs了;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://www.cnblogs.com/Users/youmen/Documents/blog/z/docker/2.png&quot; alt=&quot;2&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-shell&quot;&gt;# rootfs: 位于bootfs之上，表现为docker容器的根文件系统；
# rootfs:  位于bootfs之上，表现为docker容器的根文件系统
&lt;/code&gt;
&lt;/pre&gt;
&lt;blockquote readability=&quot;9&quot;&gt;
&lt;p&gt;传统模式中，系统启动时，内核挂载bootfs时会首先将其挂载为只读模式，完整性自检完成后将其重新挂载为读写模式；&lt;/p&gt;
&lt;p&gt;docker中，rootfs由内核挂载为“只读”模式，而后通过“联合挂载技术”额外挂载一个“可写层”；&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;code&gt;这里的分层构建&lt;/code&gt;&lt;/p&gt;
&lt;blockquote readability=&quot;72&quot;&gt;
&lt;p&gt;我们做一个apache镜像，运行httpd镜像，我们很有可能在一个底层的非常基础系统镜像之上一个纯净最小化centos版本，在他之上添加一个编辑器，相当于vim,除此之外添加一个httpd,每添加一个软件都是一个独立的层次，这里是三层，底下bootfs那一层在容器启动时，一旦被引导了完了rootfs时候再卸载并移除，不是删除文件，而是从内存中移除；&lt;/p&gt;
&lt;p&gt;而这时候底层只有三层，base image 用来构建一个系统基本组成，/bin；如果要用到额外一个工具，需要额外安装；&lt;/p&gt;
&lt;p&gt;但是对于我们镜像来讲，底层镜像是不会动的，额外安装一个vim 他会在里面额外生成一个vim 层，再装个nginx,生成个nginx层；叠加在一起挂载的，这三层都是只读的，因此，对于一个容器来讲，仅能在writoble上能写，而且如果删除容器，writable也会被删除；&lt;/p&gt;
&lt;p&gt;含有启动容器所需要的文件系统及其内容，因此，其用于创建并启动docker容器:&lt;/p&gt;
&lt;p&gt;采用分层构建机制，大体分为两层，最底层为bootfs,其之为rootfs&lt;/p&gt;
&lt;p&gt;真正让用户拿来去构建用户空间并运行进程容器的是rootfs;&lt;/p&gt;
&lt;p&gt;bootfs: 用于系统引导的文件系统，包括bootloader和kernel ,容器启动完成后会被卸载以节约内存资源&lt;/p&gt;
&lt;p&gt;这里的kernel仅仅用于引导并启动一个用户空间，启动完之后就没有了以节约内存资源，毕竟很有可能我们用户空间跟底层内核还是有一点不同之处的，向上就是rootfs了；&lt;/p&gt;
&lt;p&gt;镜像分层构建和联合挂载依赖于文件系统的支撑&lt;/p&gt;
&lt;p&gt;早起用到的是Aufs，高级多层统一文件系统:&lt;/p&gt;
&lt;p&gt;最早被docker拿来用于实现联合挂载的Linux文件系统，&lt;/p&gt;
&lt;p&gt;aufs是之前的unionfs重新实现，重写后依然很烂，三万行代码，一个ext4才四五千代码，这是要被整合进内核的，因此被申请时，次次被拒绝，一直到不申请，aufs一直都不是内核中自有的文件系统，想用需要向内核打补丁，centos不会干这种事情，因为他们以保守稳定为初衷，ubuntu是很早一批把aufs打包进内核，早些时候想要使用docker需使用ubuntu.&lt;/p&gt;
&lt;p&gt;aufs的竞争产品是overlayfs（）,后者自从3.18版本才开始被合并到linux内核；&lt;/p&gt;
&lt;p&gt;docker的分层镜像，除了aufs,ｄｏｃｋｅｒ还支持btrfs,devicemapper和vsf等；&lt;/p&gt;
&lt;p&gt;docker默认是aufs; centos7用的是devicemapper;在试用联合挂载很差，不稳定，因为它使用target driver;&lt;/p&gt;
&lt;p&gt;比较成熟的支持的文件系统必须要能够是docker info当中的overlay2,xfs,overlay2是一种抽象的二级文件系统，他需要建立在本地文件系统之上；&lt;/p&gt;
&lt;p&gt;构建镜像时，镜像做好之后，应该有一个统一存储的位置，叫做doceker registry&lt;/p&gt;
&lt;p&gt;启动容器时，docker daemon会试图从本地获取相关的镜像：　本地镜像不存在时，将其从registry中下载该镜像并保存到本地；&lt;/p&gt;
&lt;p&gt;如果我们没有特别指定，那么他就是registry,如果要指向别的registry我们必须在镜像的访问路径当中给明服务器地址；否则访问默认的registry，除非我们修改默认；&lt;br/&gt;&lt;img src=&quot;https://www.cnblogs.com/Users/youmen/Documents/blog/z/docker/3.png&quot; alt=&quot;3&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h5 id=&quot;docker-registry分类&quot;&gt;Docker Registry分类&lt;/h5&gt;
&lt;pre&gt;
&lt;code class=&quot;language-shell&quot;&gt;# Registry用于保存docker镜像，包括镜像的层次结构和元数据
# 用户可自建Registry，也可以使用官方的docker  hub
分类：
# Sponsor Registry   第三方的registry,供客户和docker社区使用           
# Mirror Registry        第三方的registry,只让客户使用            
# Vendor  Registry      由发布docker 镜像的供应商提供的registry提供给买了红帽系统使用
# Private Registry      #  通过设有防火墙和额外的安全层的私有实体提供的registry 不消耗互联网带宽，尤其是本地大规模容器自建本地registry;
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;OCI&lt;/code&gt;&lt;/p&gt;
&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;由linux基金会于２０１５年６月创立&lt;br/&gt;旨在围绕容器格式和运行时制定一个开放的工业化标准&lt;br/&gt;RunC: 无论是客户端还是服务端，都由docker一个程序提供，他有很多子程序，他可以监听在一个套件字之上；&lt;br/&gt;docker有三种类型套接字，&lt;br/&gt;docker启动容器就是基于镜像启动，在镜像基础之上，为一个容器创建一个专用可写层；&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote readability=&quot;35&quot;&gt;
&lt;p&gt;containers：容器，&lt;/p&gt;
&lt;p&gt;lmages: 镜像　 镜像来自于Registry,注册表，可以称为docker的镜像仓库，默认就是docker hub,默认本地是没有的，镜像是分层构建的，所以下载到本地后，可以共享多个上层镜像使用，因为镜像是只读的，所以启动容器就是基于镜像来启动，在镜像基础上为一个容器创建一个专用的可写层，从而来启动这个容器。&lt;/p&gt;
&lt;p&gt;所以这里镜像也需要在docker本地存储，因此这有专门的仓库来放镜像，而镜像拥有几十万之多，所以放到一个公共的仓库，需要时候拉取过来加载到本地，这里的协议是http/https,默认是加密的，需要明确定义成不安全才可以使用；&lt;/p&gt;
&lt;p&gt;docker的运行过程中尤其是创建容器时可能有一点慢，原因是他要下载一次镜像，取决于他的宽带；&lt;/p&gt;
&lt;p&gt;因为服务器在国外， 为了能使加速访问，docker在大陆这边做了一个docker镜像服务器，docker.cn,加速不太好，可以使用阿里，科大，所以要想使用docker，必须要能接入到互联网。&lt;/p&gt;
&lt;p&gt;docker镜像是分层构建的&lt;/p&gt;
&lt;p&gt;仓库：　　一个docker拥有两重功能，第一，他提供镜像提供的仓库，第二，他还提供用户来获取镜像时的认证等功能，还提供了当前服务器所有可用镜像的索引；&lt;/p&gt;
&lt;p&gt;所以镜像也会有应用到不同程序版本的镜像，为了让镜像跟应用程序版本有一定的关联，给镜像外面加了一个标签，仓库名＋标签才能唯一标识一个镜像。如果只给了仓库名，那就是默认最新版；一个镜像可以有多个标签，在仓库名＋标签外面加上 stable最新版，稳定版什么的；&lt;/p&gt;
&lt;p&gt;镜像是静态的；&lt;/p&gt;
&lt;/blockquote&gt;
&lt;pre&gt;
&lt;code class=&quot;language-shell&quot;&gt;#       容器: 动态，生命周期，类似于程序；
#任何images，networks,volumes,plugins可以支持增删改查的,因为他们都是对象；
#       依赖的基础环境：
#            64　bits CPU
#            Linux KERNEL  3.10+　　CentOS6也支持docker,2.6.32，打了补丁;
&lt;/code&gt;
&lt;/pre&gt;
&lt;blockquote readability=&quot;13&quot;&gt;
&lt;p&gt;如果我们要是 就使用docker,如果我们要使用在这的仓库就下载docker,区别EE和CE;&lt;/p&gt;
&lt;p&gt;Docker 从 1.13 版本之后采用时间线的方式作为版本号，分为社区版 CE 和企业版 EE，社区版是免费提供给个人开发者和小型团体使用的，企业版会提供额外的收费服务，比如经过官方测试认证过的基础设施、容器、插件等。&lt;br/&gt;社区版按照 stable 和 edge 两种方式发布，每个季度更新 stable 版本，如 17.06，17.09；每个月份更新 edge 版本，如17.09，17.10。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4 id=&quot;docker的部署&quot;&gt;Docker的部署&lt;/h4&gt;
&lt;h5 id=&quot;初始化环境&quot;&gt;初始化环境&lt;/h5&gt;
&lt;pre&gt;
&lt;code class=&quot;language-shell&quot;&gt;init_security() {
systemctl stop firewalld
systemctl disable firewalld &amp;amp;&amp;gt;/dev/null
setenforce 0
sed -i '/^SELINUX=/ s/enforcing/disabled/'  /etc/selinux/config
sed -i '/^GSSAPIAu/ s/yes/no/' /etc/ssh/sshd_config
sed -i '/^#UseDNS/ {s/^#//;s/yes/no/}' /etc/ssh/sshd_config
systemctl enable sshd crond &amp;amp;&amp;gt; /dev/null
rpm -e postfix --nodeps
echo -e &quot;\033[32m [安全配置] ==&amp;gt; OK \033[0m&quot;
}
init_security

init_yumsource() {
if [ ! -d /etc/yum.repos.d/backup ];then
    mkdir /etc/yum.repos.d/backup
fi
mv /etc/yum.repos.d/* /etc/yum.repos.d/backup 2&amp;gt;/dev/null
if ! ping -c2 www.baidu.com &amp;amp;&amp;gt;/dev/null    
then
    echo &quot;您无法上外网，不能配置yum源&quot;
    exit    
fi
    curl -o /etc/yum.repos.d/163.repo http://mirrors.163.com/.help/CentOS7-Base-163.repo &amp;amp;&amp;gt;/dev/null
    curl -o /etc/yum.repos.d/epel.repo http://mirrors.aliyun.com/repo/epel-7.repo &amp;amp;&amp;gt;/dev/null
    yum clean all
    timedatectl set-timezone Asia/Shanghai
    echo &quot;nameserver 114.114.114.114&quot; &amp;gt; /etc/resolv.conf
    echo &quot;nameserver 8.8.8.8&quot; &amp;gt;&amp;gt; /etc/resolv.conf
    chattr +i /etc/resolv.conf
    echo -e &quot;\033[32m [YUM　Source] ==&amp;gt; OK \033[0m&quot;
}
init_yumsource
&lt;/code&gt;
&lt;/pre&gt;
&lt;h5 id=&quot;安装必要系统工具和软件源&quot;&gt;安装必要系统工具和软件源&lt;/h5&gt;
&lt;pre&gt;
&lt;code class=&quot;language-shell&quot;&gt;# 安装一些必要的系统工具
sudo yum install -y yum-utils device-mapper-persistent-data lvm2
# 添加软件源信息
# docker 官方源
sudo yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo

# 阿里云源
sudo yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo
&lt;/code&gt;
&lt;/pre&gt;
&lt;h5 id=&quot;安装并启动docker-ce&quot;&gt;安装并启动Docker-ce&lt;/h5&gt;
&lt;pre&gt;
&lt;code class=&quot;language-shell&quot;&gt;# 安装前可以先更新 yum 缓存：
sudo yum makecache fast

# CentOS7安装 Docker-ce
yum -y install docker-ce        # CentOS 中安装
apt-get install docker-ce       # Ubuntu 中安装
pacman -S docker                # Arch 中安装
emerge --ask docker             # Gentoo 中安装

# 如果想安装特定版本的Docker-ce版本，先列出repo中可用版本，然后选择安装
yum list docker-ce --showduplicates |sort -r
Loading mirror speeds from cached hostfile
Loaded plugins: fastestmirror
Installed Packages
docker-ce.x86_64            3:19.03.4-3.el7                    docker-ce-stable
docker-ce.x86_64            3:19.03.4-3.el7                    @docker-ce-stable
docker-ce.x86_64            3:19.03.3-3.el7                    docker-ce-stable
docker-ce.x86_64            3:19.03.2-3.el7                    docker-ce-stable
docker-ce.x86_64            3:19.03.1-3.el7                    docker-ce-stable

yum install docker-ce-&amp;lt;VERSION STRING&amp;gt;
# 选择安装 docker-ce-18.06.1.ce
yum install docker-ce-18.06.1.ce

# Docker镜像加速
# 没有启动/etc/docker目录不存在，需要自己创建，docker启动也会自己创建
# 为了期望我们的镜像下载快一点，应该定义一个镜像加速器，加速器在国内
mkdir /etc/docker
vim /etc/docker/daemon.json
{
&quot;registry-mirrors&quot;: [&quot;https://registry.docker-cn.com&quot;]
}

# 启动Docker后台服务
systemctl start docker &amp;amp;&amp;amp; systemctl enable docker
systemctl daemon-reload                 # 守护进程重启

# 通过运行hello-world镜像，验证是否正确安装了docker，或者通过查看版本
docker run hello-world
docker version
Client: Docker Engine - Community
Version:           19.03.4
API version:       1.40
Go version:        go1.12.10
Git commit:        9013bf583a
Built:            Fri Oct 18 15:52:22 2019
OS/Arch:           linux/amd64
Experimental:      false
&lt;/code&gt;
&lt;/pre&gt;
&lt;h4 id=&quot;centosrhel的用户需要注意的事项&quot;&gt;CentOS/RHEL的用户需要注意的事项&lt;/h4&gt;
&lt;blockquote readability=&quot;13&quot;&gt;
&lt;p&gt;在 Ubuntu/Debian 上有 UnionFS 可以使用，如 aufs 或者 overlay2 ，而 CentOS 和 RHEL 的内核中没有相关驱动。因此对于这类系统，一般使用 devicemapper 驱动利用 LVM 的一些 机制来模拟分层存储。这样的做法除了性能比较差外，稳定性一般也不好，而且配置相对复 杂。Docker 安装在 CentOS/RHEL 上后，会默认选择 devicemapper ，但是为了简化配置， 其 devicemapper 是跑在一个稀疏文件模拟的块设备上，也被称为 loop-lvm 。这样的选择是 因为不需要额外配置就可以运行 Docker，这是自动配置唯一能做到的事情。但是 loop-lvm 的做法非常不好，其稳定性、性能更差，无论是日志还是 docker info 中都会看到警告信 息。官方文档有明确的文章讲解了如何配置块设备给 devicemapper 驱动做存储层的做法，这 类做法也被称为配置 direct-lvm 。&lt;/p&gt;
&lt;p&gt;除了前面说到的问题外， devicemapper + loop-lvm 还有一个缺陷，因为它是稀疏文件，所 以它会不断增长。用户在使用过程中会注意到 /var/lib/docker/devicemapper/devicemapper/data 不断增长，而且无法控制。很多人会希望删 除镜像或者可以解决这个问题，结果发现效果并不明显。原因就是这个稀疏文件的空间释放 后基本不进行垃圾回收的问题。因此往往会出现即使删除了文件内容，空间却无法回收，随 着使用这个稀疏文件一直在不断增长。 所以对于 CentOS/RHEL 的用户来说，在没有办法使用 UnionFS 的情况下，一定要配置 direct-lvm 给 devicemapper ，无论是为了性能、稳定性还是空间利用率。 或许有人注意到了 CentOS 7 中存在被 backports 回来的 overlay 驱动，不过 CentOS 里的 这个驱动达不到生产环境使用的稳定程度，所以不推荐使用。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4 id=&quot;标准化开发测试和生产环境&quot;&gt;标准化开发测试和生产环境&lt;/h4&gt;
&lt;blockquote readability=&quot;19&quot;&gt;
&lt;p&gt;对于大部分企业来说，搭建PaaS既没有那个精力，也没那个必要，用Docker做个人的sandbox用处又小了点。可以用Docker来标准化开发、测试、生产环境。&lt;/p&gt;
&lt;p&gt;Docker占用资源小，在一台E5128G内存的服务器上部署100个容器都绰绰有余，可以单独抽一个容器或者直接在宿主物理主机上部署samba，利用samba的home分享方案将每个用户的home目录映射到开发中心和测试部门的Windows机器上。&lt;/p&gt;
&lt;p&gt;针对某个项目组，由架构师搭建好一个标准的容器环境供项目组和测试部门使用，每个开发工程师可以拥有自己单独的容器，通过 docker run -v 将用户的home 目录映射到容器中。需要提交测试时，只需要将代码移交给测试部门，然后分配一个容器使用 -v加载测试部门的 home目录启动即可。这样，在公司内部的开发、测试基本就统一了，不会出现开发部门提交的代码，测试部门部署不了的问题。&lt;/p&gt;
&lt;p&gt;测试部门发布测试通过的报告后，架构师再次检测容器环境，就可以直接交由部署工程师将代码和容器分别部署到生产环境中了。这种方式的部署横向性能的扩展性也极好。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4 id=&quot;docker镜像使用&quot;&gt;Docker镜像使用&lt;/h4&gt;
&lt;h4 id=&quot;管理命令&quot;&gt;管理命令&lt;/h4&gt;
&lt;pre&gt;
&lt;code class=&quot;language-shell&quot;&gt;Docker  --help
  container   管理容器
  image       管理镜像
  network     管理网络
命令：
  attach      介入到一个正在运行的容器
  build       根据 Dockerfile 构建一个镜像
  commit      根据容器的更改创建一个新的镜像
  cp          在本地文件系统与容器中复制 文件/文件夹
  create      创建一个新容器
  exec        在容器中执行一条命令
  images      列出镜像
  kill        杀死一个或多个正在运行的容器    
  logs        取得容器的日志
  pause       暂停一个或多个容器的所有进程
  ps          列出所有容器
  pull        拉取一个镜像或仓库到 registry
  push        推送一个镜像或仓库到 registry
  rename      重命名一个容器
  restart     重新启动一个或多个容器
  rm          删除一个或多个容器
  rmi         删除一个或多个镜像
  run         在一个新的容器中执行一条命令
  search      在 Docker Hub 中搜索镜像
  start       启动一个或多个已经停止运行的容器
  stats       显示一个容器的实时资源占用
  stop        停止一个或多个正在运行的容器
  tag         为镜像创建一个新的标签
  top         显示一个容器内的所有进程
  unpause     恢复一个或多个容器内所有被暂停的进程
&lt;/code&gt;
&lt;/pre&gt;
&lt;h4 id=&quot;docker服务管理&quot;&gt;Docker服务管理&lt;/h4&gt;
&lt;pre&gt;
&lt;code class=&quot;language-shell&quot;&gt;service docker start       # 启动 docker 服务，守护进程
service docker stop        # 停止 docker 服务
service docker status      # 查看 docker 服务状态

chkconfig docker on        # 设置为开机启动
systemctl stop docker
systemctl start docker 
systemctl enable docker
systemctl daemon-reload    # 守护进程重启
&lt;/code&gt;
&lt;/pre&gt;
&lt;h4 id=&quot;镜像管理&quot;&gt;镜像管理&lt;/h4&gt;
&lt;h5 id=&quot;获取镜像&quot;&gt;获取镜像&lt;/h5&gt;
&lt;pre&gt;
&lt;code class=&quot;language-shell&quot;&gt;# 镜像可以看做我们平时装系统的镜像，里面就是一个运行环境
# Docker Hub上有大量的高质量镜像可以用，这里就说一下怎么获取这些镜像,
# 从镜像仓库获取镜像的命令是docker pull,其命令格式为:
docker pull [选项]  [Docker Registry 地址[:端口号]/]仓库名[:标签]

docker search centos                            # 搜索docker官方提供的centos镜像
docker search centos --filter=stars=100         # 查找stars数至少为100的镜像
docker pull centos                              # 默认从官网拉取
docker pull centos:7.7.1908                     # 默认拉取centos8，需要指定版本才能下载7.
docker pull daocloud.io/library/centos          # 从daocloud拉取
docker dao pull centos                          # 从daocloud拉取,国内仓库
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;注意&lt;/code&gt;&lt;/p&gt;
&lt;blockquote readability=&quot;14&quot;&gt;
&lt;p&gt;我们使用docker image ls时候会发现，镜像体积的所占用空间在Docker Hub上看到的镜像大小不同，比如nginx镜像在docker hub官网上是50多兆，而把他pull下来就变成一百多兆了，这是因为docker hub所显示大小是网络传输中更关心的流量大小，而docker image ls显示的是镜像下载到本地展开后的各层所占空间的综合，因为镜像下载到本地后，更关心的是磁盘空间占用的大小.&lt;/p&gt;
&lt;p&gt;另一个需要注意问题是，docker image ls列表中的镜像体积综合并非是所有镜像实际硬盘消耗，由于Docker镜像是多层存储结构，并且可以继承、复用，因此不同镜像可能因为使用相同的基础镜像，从而拥有共同的层，由于Docker使用UnionFS,相同的层只需要保存一份即可，因此实际占用硬盘空间很可能比这个列表镜像大小的总和小的多.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h5 id=&quot;查看镜像&quot;&gt;查看镜像&lt;/h5&gt;
&lt;pre&gt;
&lt;code class=&quot;language-shell&quot;&gt;docker system df                              # 查看镜像、容器、数据卷所占用的空间.
docker images                                   # 查看已下载的镜像
docker rm image_id                              # 删除镜像，指定镜像id
docker images                                   # 查看已下载的镜像
docker images -q                                # 只查看所有镜像的id
docker inspect imageID                          # 查看镜像详情
&lt;/code&gt;
&lt;/pre&gt;
&lt;h5 id=&quot;删除镜像&quot;&gt;删除镜像&lt;/h5&gt;
&lt;pre&gt;
&lt;code class=&quot;language-dockerfile&quot;&gt;docker rm image_id                              # 删除镜像，指定镜像id
docker rmi RepositoryName --force               
# 删除镜像，指定镜像名,&amp;lt;仓库名&amp;gt;:&amp;lt;标签&amp;gt; --force镜像在使用中强制删除
# 如果镜像正在被未运行的容器使用，则需要强制删除，但是如果正在被运行的容器使用，则强制删除也无法删除

docker image ls -a                      
# 这样会看到很多无标签的镜像,这些无标签镜像很多都是中间层镜像，
# 是其他镜像所需要依赖的镜像，这些无标签镜像不应该删除，否则会导致上层镜像因为缺失依赖而出错，
# 实际上也没必要删除，因为相同的层只会存一遍，而这些镜像是别的镜像的依赖，
# 因此并不会因为他们被列出来而多存了一份，无论如何你也会需要他们，
# 删除那些依赖他们的镜像，这些中间层镜像也会被连带删除.

# 删除所有仓库名为redis的镜像:
docker image rm $(docker image ls -q redis)

# 删除所有镜像
# none 默认为 docker.io
docker rmi $(docker images | grep none | awk '{print $3}' | sort -r)
docker rmi $(docker images -q)
&lt;/code&gt;
&lt;/pre&gt;
&lt;h4 id=&quot;容器管理&quot;&gt;容器管理&lt;/h4&gt;
&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;启动容器有两种方式，一种基于镜像新建一个容器并启动，另外一个是将在终止状态（stopped）的容器重新启动.&lt;/p&gt;
&lt;p&gt;因为docker的容器太轻量级了，很多时候用户都是随时删除和重建.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h5 id=&quot;创建容器&quot;&gt;创建容器&lt;/h5&gt;
&lt;pre&gt;
&lt;code class=&quot;language-shell&quot;&gt;# 容器就像是一个类的实例（比如一个基于CentOS7镜像启动的虚拟机）
# 连接进行进入命令行模式，exit命令退出。
docker run -t -i nginx:latest /bin/bash
-i                      # 交互式操作,让容器的标准输入保持打开.
-t                      # 让docker分配一个伪终端(pseudo-tty)并绑定到容器的标准输入上
nginx:latest            # 基于centos构建的nginx镜像
/bin/bash               # 放在镜像后的命令，这里我们希望有个交互式shell,因此用的是/bin/bash
# 当我们基于镜像启动一个实例的时候，此时他就是容器了.
# 就好比CentOS7.iso镜像和已经运行了的CentOS7虚拟机一样.

# 同一个镜像可以启动多个容器  
# 创建运行容器且连接到容器  
docker run -it --rm -d --cidfile=&quot;id.txt&quot; centos /bin/bash  
-i                            # 捕获标准输入输出，保持交互式的意思  
-t                            # 分配一个终端或控制台，每一个控制台都要伴随一个shell  
--rm  # 退出时就删除该容器，默认情况下，每个容器在退出时，他的文件系统会保存下来,这样一方面有利于调试,
# 因为可以通过查看日志等方式来确定最终状态；另一方面，也可以报错容器所产生的数据，  
# 如果仅仅需要短暂的运行一个容器，且不需要保存容器中的数据，
# 就可以在exit容器时自动清理掉容器及产生的数据，但此选项不能与-d共用  
/bin/bash                     # 容器运行起来之后运行的程序，也可以是任何的命令，/bin/echo  hello  
--cidfile                     # 指定容器运行之后container长id的存放文件位置
-d                            # 如果不使用-d参数运行容器,容器会把输出的结果(STDOUT)打印到宿主机上面，
# 如果使用了-d参数会返回一个id,也可以通过docker ps 查看容器信息.
# 要获取容器的输出信息，可以通过docker container logs命令查看
# 容器能否长久运行是和docker run指定的命令有关，和-d参数无关.
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;当利用docker run来创建容器时，Docker在后台运行的标准操作包括:&lt;/code&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-shell&quot;&gt;# 1. 检查本地是否有指定的镜像，不存在就从公有仓库下载
# 2. 利用镜像创建并启动一个容器
# 3. 分配一个文件系统，并在只读的镜像层外面挂载一层可读写层.
# 4. 从宿主主机配置的网桥接口中桥接一个虚拟接口道容器中去.
# 5. 从地址池中配置一个ip地址给容器.
# 6. 执行用户指定的应用程序.
# 7. 执行完毕后容器被终止.
&lt;/code&gt;
&lt;/pre&gt;
&lt;h5 id=&quot;docker容器服务管理&quot;&gt;Docker容器服务管理&lt;/h5&gt;
&lt;pre&gt;
&lt;code class=&quot;language-shell&quot;&gt;docker start my-nginx                       # 启动一个已经存在的容器  
docker restart my-nginx                     # 重启容器  
docker stop my-nginx                        # 停止运行一个容器  
docker kill my-nginx                        # 杀死一个运行中的容器  
docker rename my-nginx new-nginx            # 重命名容器  
docker rm new-nginx                         # 删除容器
docker stop $(docker ps -q) &amp;amp; docker rm $(docker ps -aq) # 停掉所有容器并删除
docker container prune                      # 删除所有处于终止状态的容器.
docker logs [containerID/Names]             # 查看日志
docker logs my-nginx                        # 查看 my-nginx 容器日志

# 使用docker exec命令进入一个已经在运行的容器
docker exec -it [containerID/Names] /bin/bash    # 进入容器
docker attach 7968b44369    # 会附加该容器的标准输出到当前命令行   
    
# 启动状态的容器，执行任务   
# 通过exec命令可以创建两种任务：后台型任务和交互型任务   
# 后台型任务：docker exec -it test /bin/bash   
# 交互型任务：docker attach 7968

docker run centos echo &quot;hello world&quot;             # 在docker容器中运行hello world!
docker run centos yum install -y wget            # 在docker容器中，安装wget软件
docker ps                                        # 列出包括未运行的容器
docker ps -a                                     # 查看所有容器(包括正在运行和已停止的)
docker ps -a -q                                  # 查看所有容器的ID
docker ps -s                                     # 查看容器使用了多少内存
docker ps -qf status=running                     # 查看某种状态的容器ID
docker ps -l                                     # 列出最近一次启动的容器
docker inspect  7657b3785bcf      
# 查看容器详细配置信息，包含容器名，环境变量，运行命令，主机配置，网络配置，数据卷配置等，json格式；
docker inspect -f {{.State.Pid}} 44fc0f0582d9    # 获取id为 44fc0f0582d9 的PID进程编号
docker inspect --format  '{{.Config.Image}}' 7657b3485    # 获取当前运行镜像版本
docker inspect --format='{{.NetworkSettings.IPAddress}}' 7657b3485    # 获取当前运行镜像的IP地址
&lt;/code&gt;
&lt;/pre&gt;
&lt;pre&gt;
&lt;code class=&quot;language-shell&quot;&gt;# 打印该容器输出
docker run -it -d --name test centos /bin/bash -c &quot;while true; do echo hello world;sleep 2;done&quot;
docker logs test
# 监控容器运行
docker logs container_id/container_name
--tail:            # 选项可以指定查看最后几条日志
-t:                # 选项则可以对日志条目附加时间戳
-f:                # 选项可以跟踪日志的输出，直到手动停止

# 运行远程机器上的容器
docker run -it -d -h 39.108.140.0 daocloud.io/centos:7

# 断开容器
# 断开与容器的连接，并且关闭容器
[root@7968b4436989 /]# exit
[root@7968b4436989 /]# docker stop 7968b443

# 只断开和容器的连接而不关闭容器
# 快捷键： ctrl+p+q

# 关闭运行中的容器
# 如果此时有其他终端正在对他进行交互会自动中断
# docker stop contrainer_id/name        //发送SIGTERM信号，可忽略，15信号
# docker kill contrainer_id/name        //发送SIGKILL信号，9信号
&lt;/code&gt;
&lt;/pre&gt;
&lt;h5 id=&quot;容器的导入导出&quot;&gt;容器的导入导出&lt;/h5&gt;
&lt;pre&gt;
&lt;code class=&quot;language-shell&quot;&gt;# 导出容器
# 镜像打包
# 方案一: export
#    利用export把正在运行的容器直接导出为tar包的镜像文件，可以用-o或&amp;gt;
docker run --name my-nginx -d -p 8080:80 some-centent-nginx:1.2
docker export my-nginx &amp;gt; youmen_nginx.tar  &amp;amp;&amp;amp;  docker export -o youmen_nginx.tar my-nginx
scp youmen_nginx.tar 120.77.248.31:
docker import youmen_nginx.tar
docker tag 121d8 mynginx:1                            # 设置镜像名字
docker import youmen_nginx.tar mynginx:1.1            # 导入时即设置镜像名字

方案二: 利用save直接把镜像打包出来
docker save -o suibian.tar library/centos:latest
scp suibian.tar 192.168.135.161:
docker load &amp;lt; suibian.tar                # 导入之后使用原名

# 导入也可以通过指定URL或者某个目录来导入
docker import http://example.com/exampleimage.tgz example/imagerepo

------------------------------------区别介绍-------------------------------------
# docker save:将一个镜像导出为文件，保存的是该镜像的所有历史记录；
# docker export:将一个容器导出为文件，保存的是容器当时的状态，即容器快照；
# docker load:将镜像存储文件导入到本地镜像库；
# docker import:导入一个容器快照到本地镜像库；

docker save和docker export之间的区别：
    1&amp;gt; docker save是将镜像保存为tar包，且会保存该镜像的父层、标签、所有历史等信息；
       docker export是将容器文件系统保存为tar包，仅仅保存的是容器当时的状态(快照)；
    2&amp;gt; docker save可以同时指定多个镜像名称；docker export只能指定一个容器名称；
    3&amp;gt; docker save保存的镜像文件tar包使用docker load命令加载还原；
       docker export保存的容器快照tar包使用docker import命令导入还原；
    4&amp;gt; docker save保存的tar包文件通常比docker export导出的文件要大；

docker load和docker import之间的区别：
    1）docker load将镜像存储文件导入到本地镜像库；docker import将容器快照文件导入到本地镜像库；
    2）docker load不能指定url；而docker import可以指定url来进行导入；
&lt;/code&gt;
&lt;/pre&gt;
&lt;h4 id=&quot;容器服务管理及开机启动设置&quot;&gt;容器服务管理及开机启动设置&lt;/h4&gt;
&lt;pre&gt;
&lt;code class=&quot;language-shell&quot;&gt;# Docker容器开机启动设置
sudo docker run --restart=always -it centos /bin/bash
--restart=always # 默认情况下docker重启之后所有容器会被关闭，这个选项的意思是容器随docker engine自启动
# 如果创建时候未指定--restart=always,可通过docker  update命令设置：
docker update --restart=always  7b5f30fe77c0    

# 注意Docker服务开启启动
# restart参数介绍
# no:容器退出时候，不重启容器
# on-failure: 只有在非0状态退出时才重新启动容器
# always:无论退出状态是如何，都重启容器
# unless-stopped: 在容器退出时总是重启容器，但是不考虑在Docker守护进程启动时就已经停止了的容器
# 在使用on-failure策略时，指定Docker将尝试重新启动容器的最大次数；
# 默认情况下，Docker将尝试永远重新启动容器
# sudo docker run --restart=on-failure:5  &amp;lt;image&amp;gt;
&lt;/code&gt;
&lt;/pre&gt;</description>
<pubDate>Thu, 11 Jun 2020 15:44:00 +0000</pubDate>
<dc:creator>you-men</dc:creator>
<og:description>Docker的来源及构造: 容器是一种基础工具：泛指任何用于容纳其他物品的工具，可以部分或完全封闭，被用于容纳，储存，运输物品：　物品可以被放置在容器中，而容器可以保护内容物： 人类使用容器的历史有十</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/you-men/p/13096875.html</dc:identifier>
</item>
</channel>
</rss>