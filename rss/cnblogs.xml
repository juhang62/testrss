<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="css/feed.xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/" xmlns:og="http://ogp.me/ns#">
<channel>
<atom:link rel="self" href="http://192.168.1.4/fivefilters/makefulltextfeed.php?url=feed.cnblogs.com%2Fblog%2Fsitehome%2Frss&amp;max=10&amp;links=preserve&amp;exc=" />
<atom:link rel="alternate" title="Source URL" href="http://feed.cnblogs.com/blog/sitehome/rss" />
<atom:link rel="related" title="Subscribe to feed" href="http://www.subtome.com/#/subscribe?feeds=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed.cnblogs.com%252Fblog%252Fsitehome%252Frss%26max%3D10%26links%3Dpreserve%26exc%3D&amp;back=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed.cnblogs.com%252Fblog%252Fsitehome%252Frss%26max%3D10%26links%3Dpreserve%26exc%3D" />
<title>博客园_首页</title>
<link></link>
<description>代码改变世界</description>
<item>
<title>kubernetes实战篇之Dashboard的访问权限限制 - 周国通</title>
<link>http://www.cnblogs.com/tylerzhou/p/11124194.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/tylerzhou/p/11124194.html</guid>
<description>&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&quot;https://www.cnblogs.com/tylerzhou/p/11100649.html&quot;&gt;系列目录&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;前面我们的示例中,我们创建的ServiceAccount是与cluster-admin 绑定的,这个用户默认有最高的权限,实际生产环境中,往往需要对不同运维人员赋预不同的权限.而根据实际情况也可能会赋予开发人员只读的权限.这一节我们将介绍如何创建不同权限的用户.&lt;/p&gt;
&lt;p&gt;在开始之前,我们先了解一些关于kubernetes RABA的一些基本概念.&lt;/p&gt;
&lt;p&gt;Role表示是一组规则权限，只能累加，Role可以定义在一个namespace中，只能用于授予对单个命名空间中的资源访问的权限。比如我们新建一个对默认命名空间中Pods具有访问权限的角色：&lt;/p&gt;
&lt;pre class=&quot;yml&quot;&gt;
&lt;code&gt;kind: Role
apiVersion: rbac.authorization.k8s.io/v1beta1
metadata:
  namespace: default
  name: pod-reader
rules:
- apiGroups: [&quot;&quot;] # &quot;&quot; indicates the core API group
  resources: [&quot;pods&quot;]
  verbs: [&quot;get&quot;, &quot;watch&quot;, &quot;list&quot;]&lt;/code&gt;
&lt;/pre&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;ClusterRole&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;ClusterRole具有与Role相同的权限角色控制能力，不同的是ClusterRole是集群级别的，可以用于:&lt;/p&gt;
&lt;ul readability=&quot;0&quot;&gt;&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;集群级别的资源控制(例如 node 访问权限)&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;非资源型 endpoints(例如 /healthz 访问)&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;所有命名空间资源控制(例如 pods)&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;比如我们要创建一个授权某个特定命名空间或全部命名空间(取决于绑定方式)访问secrets的集群角色：&lt;/p&gt;
&lt;pre class=&quot;yml&quot;&gt;
&lt;code&gt;kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1beta1
metadata:
  # &quot;namespace&quot; omitted since ClusterRoles are not namespaced
  name: secret-reader
rules:
- apiGroups: [&quot;&quot;]
  resources: [&quot;secrets&quot;]
  verbs: [&quot;get&quot;, &quot;watch&quot;, &quot;list&quot;]&lt;/code&gt;
&lt;/pre&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;RoleBinding&lt;/strong&gt;和&lt;strong&gt;ClusterRoleBinding&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;RoloBinding可以将角色中定义的权限授予用户或用户组，RoleBinding包含一组权限列表(subjects)，权限列表中包含有不同形式的待授予权限资源类型(users、groups、service accounts)，RoleBinding适用于某个命名空间内授权，而 ClusterRoleBinding适用于集群范围内的授权。&lt;/p&gt;
&lt;p&gt;比如我们将默认命名空间的pod-reader角色授予用户jane，这样以后该用户在默认命名空间中将具有pod-reader的权限：&lt;/p&gt;
&lt;pre class=&quot;yml&quot;&gt;
&lt;code&gt;# This role binding allows &quot;jane&quot; to read pods in the &quot;default&quot; namespace.
kind: RoleBinding
apiVersion: rbac.authorization.k8s.io/v1beta1
metadata:
  name: read-pods
  namespace: default
subjects:
- kind: User
  name: jane
  apiGroup: rbac.authorization.k8s.io
roleRef:
  kind: Role
  name: pod-reader
  apiGroup: rbac.authorization.k8s.io
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;RoleBinding同样可以引用ClusterRole来对当前 namespace 内用户、用户组或 ServiceAccount 进行授权，这种操作允许集群管理员在整个集群内定义一些通用的 ClusterRole，然后在不同的 namespace 中使用 RoleBinding 来引用&lt;/p&gt;
&lt;p&gt;例如，以下 RoleBinding 引用了一个 ClusterRole，这个 ClusterRole 具有整个集群内对 secrets 的访问权限；但是其授权用户 dave 只能访问 development 空间中的 secrets(因为 RoleBinding 定义在 development 命名空间)&lt;/p&gt;
&lt;pre class=&quot;yml&quot;&gt;
&lt;code&gt;# This role binding allows &quot;dave&quot; to read secrets in the &quot;development&quot; namespace.
kind: RoleBinding
apiVersion: rbac.authorization.k8s.io/v1beta1
metadata:
  name: read-secrets
  namespace: development # This only grants permissions within the &quot;development&quot; namespace.
subjects:
- kind: User
  name: dave
  apiGroup: rbac.authorization.k8s.io
roleRef:
  kind: ClusterRole
  name: secret-reader
  apiGroup: rbac.authorization.k8s.io&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;使用 ClusterRoleBinding 可以对整个集群中的所有命名空间资源权限进行授权；以下 ClusterRoleBinding 示例展示了授权 manager 组内所有用户在全部命名空间中对 secrets 进行访问&lt;/p&gt;
&lt;pre class=&quot;yml&quot;&gt;
&lt;code&gt;# This cluster role binding allows anyone in the &quot;manager&quot; group to read secrets in any namespace.
kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1beta1
metadata:
  name: read-secrets-global
subjects:
- kind: Group
  name: manager
  apiGroup: rbac.authorization.k8s.io
roleRef:
  kind: ClusterRole
  name: secret-reader
  apiGroup: rbac.authorization.k8s.io&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;限制dashboard-用户权限&quot;&gt;限制dashboard 用户权限&lt;/h2&gt;
&lt;p&gt;有了上面的理论基础，我们就可以来新建一个用户，为该用户指定特定的访问权限了，比如我们要实现以下功能:&lt;/p&gt;
&lt;ul readability=&quot;0.5&quot;&gt;&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;新增一个新的用户tyler(tyler.yml)&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;该用户只能对命名空间kube-system下面的pods和deployments进行管理&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;首先,我们先创建这个&lt;code&gt;ServiceAccount&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;kubectl create sa tyler -n kube-system&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;然后我们新建一个角色role-tyler(role-tyler.yml)&lt;/li&gt;
&lt;/ul&gt;&lt;pre class=&quot;yml&quot;&gt;
&lt;code&gt;kind: Role
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  namespace: kube-system
  name: role-tyler
rules:
- apiGroups: [&quot;&quot;]
  resources: [&quot;pods&quot;]
  verbs: [&quot;get&quot;, &quot;watch&quot;, &quot;list&quot;]
- apiGroups: [&quot;extensions&quot;, &quot;apps&quot;]
  resources: [&quot;deployments&quot;]
  verbs: [&quot;get&quot;, &quot;list&quot;, &quot;watch&quot;, &quot;create&quot;, &quot;update&quot;, &quot;patch&quot;, &quot;delete&quot;]
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;注意上面的rules规则：管理pods和deployments的权限。&lt;/p&gt;
&lt;p&gt;然后我们创建一个角色绑定，将tyler用户绑定到role-tyler角色,这样用户就拥有了角色的权限.&lt;/p&gt;
&lt;p&gt;执行命令创建文件&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;$ kubect create -f tyler.yml
$ kubect create -f role-tyler.yml&lt;/code&gt;
&lt;/pre&gt;
&lt;blockquote readability=&quot;10&quot;&gt;
&lt;p&gt;前面一节我们使用的是命令来创建角色和已有的role绑定,这做方法简单快捷,但是不便于像这里一样进行复杂的权限编排操作,也不便于版本管理.更为复杂的权限编排建议使用yml声明式的方式创建.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;使用创建的token登陆&lt;/p&gt;
&lt;p&gt;我们前面说过,某一用户的secret名称为&lt;code&gt;用户名-token-随机字符串&lt;/code&gt;格式.我们可以使用&lt;code&gt;kubectl describe secret secret名称 -n=kube-system&lt;/code&gt;的方式查看secret,然后把token复制到dashboard登陆页的token里就可以登陆了.&lt;/p&gt;
</description>
<pubDate>Wed, 03 Jul 2019 00:00:00 +0000</pubDate>
<dc:creator>周国通</dc:creator>
<og:description>'系列目录' 前面我们的示例中,我们创建的ServiceAccount是与cluster admin 绑定的,这个用户默认有最高的权限,实际生产环境中,往往需要对不同运维人员赋预不同的权限.而根据实际</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/tylerzhou/p/11124194.html</dc:identifier>
</item>
<item>
<title>跟我学SpringCloud | 第三篇：服务的提供与Feign调用 - 魔鬼还是天使</title>
<link>http://www.cnblogs.com/babycomeon/p/11117763.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/babycomeon/p/11117763.html</guid>
<description>&lt;p&gt;上一篇，我们介绍了注册中心的搭建，包括集群环境吓注册中心的搭建，这篇文章介绍一下如何使用注册中心，创建一个服务的提供者，使用一个简单的客户端去调用服务端提供的服务。&lt;/p&gt;
&lt;p&gt;本篇文章中需要三个角色，分别是服务的提供者，服务的消费者，还有一个是上一篇文章的主角——注册中心Eureka（使用单机版本即可，本篇的示例也会使用单机版本的Eureka）。&lt;/p&gt;
&lt;p&gt;整体流程为：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;先启动注册中心Eureka&lt;/li&gt;
&lt;li&gt;启动服务的提供者将提供服务，并将服务注册到注册中心Eureka上&lt;/li&gt;
&lt;li&gt;启动服务的消费者，在注册中心中找到服务并完成消费&lt;/li&gt;
&lt;/ol&gt;&lt;h2 id=&quot;服务提供者&quot;&gt;1. 服务提供者&lt;/h2&gt;
&lt;h4 id=&quot;pom.xml&quot;&gt;1. pom.xml&lt;/h4&gt;
&lt;pre&gt;
&lt;code&gt;&amp;lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&amp;gt;
&amp;lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;
    xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&amp;gt;
    &amp;lt;modelVersion&amp;gt;4.0.0&amp;lt;/modelVersion&amp;gt;
    &amp;lt;parent&amp;gt;
        &amp;lt;groupId&amp;gt;org.springframework.boot&amp;lt;/groupId&amp;gt;
        &amp;lt;artifactId&amp;gt;spring-boot-starter-parent&amp;lt;/artifactId&amp;gt;
        &amp;lt;version&amp;gt;2.1.6.RELEASE&amp;lt;/version&amp;gt;
        &amp;lt;relativePath/&amp;gt; &amp;lt;!-- lookup parent from repository --&amp;gt;
    &amp;lt;/parent&amp;gt;
    &amp;lt;groupId&amp;gt;com.springcloud&amp;lt;/groupId&amp;gt;
    &amp;lt;artifactId&amp;gt;producer&amp;lt;/artifactId&amp;gt;
    &amp;lt;version&amp;gt;0.0.1-SNAPSHOT&amp;lt;/version&amp;gt;
    &amp;lt;name&amp;gt;producer&amp;lt;/name&amp;gt;
    &amp;lt;description&amp;gt;Demo project for Spring Boot&amp;lt;/description&amp;gt;

    &amp;lt;properties&amp;gt;
        &amp;lt;java.version&amp;gt;1.8&amp;lt;/java.version&amp;gt;
        &amp;lt;spring-cloud.version&amp;gt;Greenwich.SR1&amp;lt;/spring-cloud.version&amp;gt;
    &amp;lt;/properties&amp;gt;

    &amp;lt;dependencies&amp;gt;
        &amp;lt;dependency&amp;gt;
            &amp;lt;groupId&amp;gt;org.springframework.boot&amp;lt;/groupId&amp;gt;
            &amp;lt;artifactId&amp;gt;spring-boot-starter-web&amp;lt;/artifactId&amp;gt;
        &amp;lt;/dependency&amp;gt;
        &amp;lt;dependency&amp;gt;
            &amp;lt;groupId&amp;gt;org.springframework.cloud&amp;lt;/groupId&amp;gt;
            &amp;lt;artifactId&amp;gt;spring-cloud-starter-netflix-eureka-client&amp;lt;/artifactId&amp;gt;
        &amp;lt;/dependency&amp;gt;

        &amp;lt;dependency&amp;gt;
            &amp;lt;groupId&amp;gt;org.springframework.boot&amp;lt;/groupId&amp;gt;
            &amp;lt;artifactId&amp;gt;spring-boot-starter-test&amp;lt;/artifactId&amp;gt;
            &amp;lt;scope&amp;gt;test&amp;lt;/scope&amp;gt;
        &amp;lt;/dependency&amp;gt;
    &amp;lt;/dependencies&amp;gt;

    &amp;lt;dependencyManagement&amp;gt;
        &amp;lt;dependencies&amp;gt;
            &amp;lt;dependency&amp;gt;
                &amp;lt;groupId&amp;gt;org.springframework.cloud&amp;lt;/groupId&amp;gt;
                &amp;lt;artifactId&amp;gt;spring-cloud-dependencies&amp;lt;/artifactId&amp;gt;
                &amp;lt;version&amp;gt;${spring-cloud.version}&amp;lt;/version&amp;gt;
                &amp;lt;type&amp;gt;pom&amp;lt;/type&amp;gt;
                &amp;lt;scope&amp;gt;import&amp;lt;/scope&amp;gt;
            &amp;lt;/dependency&amp;gt;
        &amp;lt;/dependencies&amp;gt;
    &amp;lt;/dependencyManagement&amp;gt;

    &amp;lt;build&amp;gt;
        &amp;lt;plugins&amp;gt;
            &amp;lt;plugin&amp;gt;
                &amp;lt;groupId&amp;gt;org.springframework.boot&amp;lt;/groupId&amp;gt;
                &amp;lt;artifactId&amp;gt;spring-boot-maven-plugin&amp;lt;/artifactId&amp;gt;
            &amp;lt;/plugin&amp;gt;
        &amp;lt;/plugins&amp;gt;
    &amp;lt;/build&amp;gt;

&amp;lt;/project&amp;gt;
&lt;/code&gt;
&lt;/pre&gt;
&lt;h4 id=&quot;配置文件application.yml&quot;&gt;2. 配置文件application.yml&lt;/h4&gt;
&lt;pre&gt;
&lt;code&gt;server:
  port: 8080
spring:
  application:
    name: spring-cloud-producer
eureka:
  client:
    service-url:
      defaultZone: http://localhost:8761/eureka/&lt;/code&gt;
&lt;/pre&gt;
&lt;h4 id=&quot;启动类producerapplication.java&quot;&gt;3. 启动类ProducerApplication.java&lt;/h4&gt;
&lt;p&gt;增加@EnableEurekaClient，如果是其他注册中心可以使用注解@EnableDiscoveryClient来进行服务的注册&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;package com.springcloud.producer;

import org.springframework.boot.SpringApplication;
import org.springframework.boot.autoconfigure.SpringBootApplication;
import org.springframework.cloud.netflix.eureka.EnableEurekaClient;

@SpringBootApplication
@EnableEurekaClient
public class ProducerApplication {

    public static void main(String[] args) {
        SpringApplication.run(ProducerApplication.class, args);
    }

}
&lt;/code&gt;
&lt;/pre&gt;
&lt;h4 id=&quot;controller&quot;&gt;4. Controller&lt;/h4&gt;
&lt;pre&gt;
&lt;code&gt;package com.springcloud.producer.controller;

import org.springframework.web.bind.annotation.RequestMapping;
import org.springframework.web.bind.annotation.RequestParam;
import org.springframework.web.bind.annotation.RestController;

/**
 * Created with IntelliJ IDEA.
 *
 * @Date: 2019/7/2
 * @Time: 0:02
 * @email: inwsy@hotmail.com
 * Description:
 */
@RestController
public class HelloController {
    @RequestMapping(&quot;/hello&quot;)
    public String hello(@RequestParam String name) {
        return &quot;hello &quot;+name+&quot;，producer is ready&quot;;
    }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;先在可以先启动上一篇当中单机版的Eureka，再启动我们刚写好的producer服务提供者，启动成功后，访问链接http://localhost:8761/，可以看到我们的的服务提供者producer已经成功注册在注册中心上了。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/meteor1993/image/master/springcloud/chapter3/eureka_1.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;至此，服务的提供者已经配置完成。&lt;/p&gt;
&lt;h2 id=&quot;服务消费者&quot;&gt;2. 服务消费者&lt;/h2&gt;
&lt;h4 id=&quot;pom.xml-1&quot;&gt;1. pom.xml&lt;/h4&gt;
&lt;pre&gt;
&lt;code&gt;&amp;lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&amp;gt;
&amp;lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;
    xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&amp;gt;
    &amp;lt;modelVersion&amp;gt;4.0.0&amp;lt;/modelVersion&amp;gt;
    &amp;lt;parent&amp;gt;
        &amp;lt;groupId&amp;gt;org.springframework.boot&amp;lt;/groupId&amp;gt;
        &amp;lt;artifactId&amp;gt;spring-boot-starter-parent&amp;lt;/artifactId&amp;gt;
        &amp;lt;version&amp;gt;2.1.6.RELEASE&amp;lt;/version&amp;gt;
        &amp;lt;relativePath/&amp;gt; &amp;lt;!-- lookup parent from repository --&amp;gt;
    &amp;lt;/parent&amp;gt;
    &amp;lt;groupId&amp;gt;com.springcloud&amp;lt;/groupId&amp;gt;
    &amp;lt;artifactId&amp;gt;consumers&amp;lt;/artifactId&amp;gt;
    &amp;lt;version&amp;gt;0.0.1-SNAPSHOT&amp;lt;/version&amp;gt;
    &amp;lt;name&amp;gt;consumers&amp;lt;/name&amp;gt;
    &amp;lt;description&amp;gt;Demo project for Spring Boot&amp;lt;/description&amp;gt;

    &amp;lt;properties&amp;gt;
        &amp;lt;java.version&amp;gt;1.8&amp;lt;/java.version&amp;gt;
        &amp;lt;spring-cloud.version&amp;gt;Greenwich.SR1&amp;lt;/spring-cloud.version&amp;gt;
    &amp;lt;/properties&amp;gt;

    &amp;lt;dependencies&amp;gt;
        &amp;lt;dependency&amp;gt;
            &amp;lt;groupId&amp;gt;org.springframework.cloud&amp;lt;/groupId&amp;gt;
            &amp;lt;artifactId&amp;gt;spring-cloud-starter-netflix-eureka-client&amp;lt;/artifactId&amp;gt;
        &amp;lt;/dependency&amp;gt;
        &amp;lt;dependency&amp;gt;
            &amp;lt;groupId&amp;gt;org.springframework.boot&amp;lt;/groupId&amp;gt;
            &amp;lt;artifactId&amp;gt;spring-boot-starter-web&amp;lt;/artifactId&amp;gt;
        &amp;lt;/dependency&amp;gt;
        &amp;lt;dependency&amp;gt;
            &amp;lt;groupId&amp;gt;org.springframework.cloud&amp;lt;/groupId&amp;gt;
            &amp;lt;artifactId&amp;gt;spring-cloud-starter-openfeign&amp;lt;/artifactId&amp;gt;
        &amp;lt;/dependency&amp;gt;

        &amp;lt;dependency&amp;gt;
            &amp;lt;groupId&amp;gt;org.springframework.boot&amp;lt;/groupId&amp;gt;
            &amp;lt;artifactId&amp;gt;spring-boot-starter-test&amp;lt;/artifactId&amp;gt;
            &amp;lt;scope&amp;gt;test&amp;lt;/scope&amp;gt;
        &amp;lt;/dependency&amp;gt;
    &amp;lt;/dependencies&amp;gt;

    &amp;lt;dependencyManagement&amp;gt;
        &amp;lt;dependencies&amp;gt;
            &amp;lt;dependency&amp;gt;
                &amp;lt;groupId&amp;gt;org.springframework.cloud&amp;lt;/groupId&amp;gt;
                &amp;lt;artifactId&amp;gt;spring-cloud-dependencies&amp;lt;/artifactId&amp;gt;
                &amp;lt;version&amp;gt;${spring-cloud.version}&amp;lt;/version&amp;gt;
                &amp;lt;type&amp;gt;pom&amp;lt;/type&amp;gt;
                &amp;lt;scope&amp;gt;import&amp;lt;/scope&amp;gt;
            &amp;lt;/dependency&amp;gt;
        &amp;lt;/dependencies&amp;gt;
    &amp;lt;/dependencyManagement&amp;gt;

    &amp;lt;build&amp;gt;
        &amp;lt;plugins&amp;gt;
            &amp;lt;plugin&amp;gt;
                &amp;lt;groupId&amp;gt;org.springframework.boot&amp;lt;/groupId&amp;gt;
                &amp;lt;artifactId&amp;gt;spring-boot-maven-plugin&amp;lt;/artifactId&amp;gt;
            &amp;lt;/plugin&amp;gt;
        &amp;lt;/plugins&amp;gt;
    &amp;lt;/build&amp;gt;

&amp;lt;/project&amp;gt;
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;spring-boot-starter-web：&lt;/strong&gt; 这个包是通用的web开发包，里面包含了spring-web、spring-webmvc等包&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;spring-cloud-starter-openfeign：&lt;/strong&gt; 这个包是springcloud对于Feign的封装，Feign是一个声明式的Web服务客户端。它支持Feign本身的注解、JAX-RS注解以及SpringMVC的注解。Spring Cloud集成Ribbon和Eureka以在使用Feign时提供负载均衡的http客户端。&lt;/p&gt;
&lt;h4 id=&quot;配置文件application.yml-1&quot;&gt;2. 配置文件application.yml&lt;/h4&gt;
&lt;pre&gt;
&lt;code&gt;server:
  port: 8081
spring:
  application:
    name: spring-cloud-consumers
eureka:
  client:
    service-url:
      defaultZone: http://localhost:8761/eureka/&lt;/code&gt;
&lt;/pre&gt;
&lt;h4 id=&quot;启动类consumersapplication.java&quot;&gt;3. 启动类ConsumersApplication.java&lt;/h4&gt;
&lt;p&gt;同上，增加@EnableEurekaClient，如果是其他注册中心可以使用注解@EnableDiscoveryClient来进行服务的注册&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;package com.springcloud.consumers;

import org.springframework.boot.SpringApplication;
import org.springframework.boot.autoconfigure.SpringBootApplication;
import org.springframework.cloud.netflix.eureka.EnableEurekaClient;
import org.springframework.cloud.openfeign.EnableFeignClients;

@SpringBootApplication
@EnableEurekaClient
@EnableFeignClients
public class ConsumersApplication {

    public static void main(String[] args) {
        SpringApplication.run(ConsumersApplication.class, args);
    }

}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;@EnableFeignClients：&lt;/strong&gt; 这个注解是通知SpringBoot在启动的时候，扫描被 &lt;strong&gt;@FeignClient&lt;/strong&gt; 修饰的类，@FeignClient这个注解在进行远程调用的时候会用到。&lt;/p&gt;
&lt;h4 id=&quot;feign远程调用&quot;&gt;4. Feign远程调用&lt;/h4&gt;
&lt;blockquote readability=&quot;9&quot;&gt;
&lt;p&gt;Feign是一个声明式Web Service客户端。使用Feign能让编写Web Service客户端更加简单, 它的使用方法是定义一个接口，然后在上面添加注解，同时也支持JAX-RS标准的注解。Feign也支持可拔插式的编码器和解码器。Spring Cloud对Feign进行了封装，使其支持了Spring MVC标准注解和HttpMessageConverters。Feign可以与Eureka和Ribbon组合使用以支持负载均衡。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;创建一个remote接口&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;package com.springcloud.consumers.remote;

import org.springframework.cloud.openfeign.FeignClient;
import org.springframework.web.bind.annotation.RequestMapping;
import org.springframework.web.bind.annotation.RequestParam;

/**
 * @Author: shiyao.wei
 * @Date: 2019/7/2 11:14
 * @Version: 1.0
 * @Desc:
 */
@FeignClient(name= &quot;spring-cloud-producer&quot;)
public interface HelloRemote {
    @RequestMapping(value = &quot;/hello&quot;)
    String hello(@RequestParam(value = &quot;name&quot;) String name);
}&lt;/code&gt;
&lt;/pre&gt;
&lt;ul&gt;&lt;li&gt;name：远程服务名，及spring.application.name配置的名称&lt;/li&gt;
&lt;li&gt;此类中的方法和远程服务中contoller中的方法名和参数需保持一致&lt;/li&gt;
&lt;/ul&gt;&lt;h4 id=&quot;web层调用远程接口-controller&quot;&gt;5. web层调用远程接口 Controller&lt;/h4&gt;
&lt;pre&gt;
&lt;code&gt;package com.springcloud.consumers.controller;

import com.springcloud.consumers.remote.HelloRemote;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.web.bind.annotation.PathVariable;
import org.springframework.web.bind.annotation.RequestMapping;
import org.springframework.web.bind.annotation.RestController;

/**
 * @Author: shiyao.wei
 * @Date: 2019/7/2 11:25
 * @Version: 1.0
 * @Desc:
 */
@RestController
public class HelloController {
    @Autowired
    HelloRemote helloRemote;

    @RequestMapping(&quot;/hello/{name}&quot;)
    public String index(@PathVariable(&quot;name&quot;) String name) {
        return helloRemote.hello(name);
    }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;现在，一个最简单的服务注册和调用的例子就完成了。&lt;/p&gt;
&lt;h2 id=&quot;测试&quot;&gt;3. 测试&lt;/h2&gt;
&lt;h4 id=&quot;简单调用&quot;&gt;简单调用&lt;/h4&gt;
&lt;p&gt;顺次启动eureka、producer、consumer三个项目&lt;/p&gt;
&lt;p&gt;启动成功后，先在浏览器输入http://localhost:8080/hello?name=springcloud&lt;/p&gt;
&lt;p&gt;可以看到页面显示：hello springcloud，producer is ready&lt;/p&gt;
&lt;p&gt;证明我们的producer已经正常启动，提供的服务也正常&lt;/p&gt;
&lt;p&gt;接下来，我们测试服务消费者，在浏览器中输入：http://localhost:8081/hello/spring&lt;/p&gt;
&lt;p&gt;可以看到页面显示：hello spring，producer is ready&lt;/p&gt;
&lt;p&gt;说明客户端已经成功的通过feign调用了远程服务hello，并且将结果返回到了浏览器。&lt;/p&gt;
&lt;h4 id=&quot;负载均衡&quot;&gt;负载均衡&lt;/h4&gt;
&lt;p&gt;将上面的producer复制一份，修改名称为producer2，修改pom.xml中的&amp;lt;name&amp;gt;&amp;lt;/name&amp;gt;为producer2，修改其中的Controller：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;package com.springcloud.producer.controller;

import org.springframework.web.bind.annotation.RequestMapping;
import org.springframework.web.bind.annotation.RequestParam;
import org.springframework.web.bind.annotation.RestController;

/**
 * Created with IntelliJ IDEA.
 *
 * @Date: 2019/7/2
 * @Time: 0:02
 * @email: inwsy@hotmail.com
 * Description:
 */
@RestController
public class HelloController {
    @RequestMapping(&quot;/hello&quot;)
    public String hello(@RequestParam String name) {
        return &quot;hello &quot;+name+&quot;，producer2 is ready&quot;;
    }
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;修改application.yml配置文件启动端口为8082&lt;/p&gt;
&lt;p&gt;启动我们刚复制好的producer2，这时可以看一下注册中心Eureka，我们现在已经有两个producer服务了。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/meteor1993/image/master/springcloud/chapter3/eureka_2.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;这时我们再去访问：http://localhost:8081/hello/spring&lt;/p&gt;
&lt;p&gt;第一次返回结果：hello spring，producer is ready&lt;/p&gt;
&lt;p&gt;第二次返回结果：hello spring，producer2 is ready&lt;/p&gt;
&lt;p&gt;连续刷新页面，两个结果会交替出现，说明注册中心提供了服务负载均衡功能。将服务数提高到N个，会发现测试结果一样，请求会自动轮询到每个服务端来处理。&lt;/p&gt;
&lt;p&gt;好了，现在可以将代码打包扔到Github上去了，欢迎大家前往Github骚扰：）&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/meteor1993/SpringCloudLearning/tree/master/chapter3&quot; title=&quot;示例代码-Github&quot;&gt;示例代码-Github&lt;/a&gt;&lt;/p&gt;
</description>
<pubDate>Tue, 02 Jul 2019 23:16:00 +0000</pubDate>
<dc:creator>魔鬼还是天使</dc:creator>
<og:description>跟我学SpringCloud | 第三篇：服务的提供与Feign调用 上一篇，我们介绍了注册中心的搭建，包括集群环境吓注册中心的搭建，这篇文章介绍一下如何使用注册中心，创建一个服务的提供者，使用一个简</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/babycomeon/p/11117763.html</dc:identifier>
</item>
<item>
<title>Netty源码分析--Channel注册（中）（六） - Diligent_Watermelon</title>
<link>http://www.cnblogs.com/huxipeng/p/11042918.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/huxipeng/p/11042918.html</guid>
<description>&lt;p&gt;        接上一篇，我们继续看&lt;/p&gt;
&lt;p&gt;    &lt;img src=&quot;https://img2018.cnblogs.com/blog/1143158/201906/1143158-20190619001036079-216313645.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;    不知道大家第一次看这段代码的时候有没有一脸懵逼，反正我是一脸懵，为什么这个if else 最终都是调用的register0方法，都是一样的。&lt;/p&gt;
&lt;p&gt;    其实这里就是为什么Netty是线程安全的根本原因。&lt;/p&gt;
&lt;p&gt;    我们先看下 eventLoop.inEventLoop() 方法&lt;/p&gt;
&lt;p&gt;    &lt;img src=&quot;https://img2018.cnblogs.com/blog/1143158/201906/1143158-20190619001307937-706852625.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;    &lt;img src=&quot;https://img2018.cnblogs.com/blog/1143158/201906/1143158-20190619001319569-949425320.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;      第一张图传入了 当前的 线程， 第二个图 判断了 当前这个NioEventLoop中的Thread 是不是和当前线程相等， 如果相等返回true, 相反就是false.&lt;/p&gt;
&lt;p&gt;      我们debug 看一下&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1143158/201906/1143158-20190619001609436-1764944015.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;    发现NioEventLoop中的Thread 当前并没有赋值, 值是null，所以返回false.&lt;/p&gt;
&lt;p&gt;   那么代码也就进入到了&lt;/p&gt;
&lt;p&gt;   &lt;img src=&quot;https://img2018.cnblogs.com/blog/1143158/201906/1143158-20190619001706803-2145618033.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;   这里其实也容易漏看，其实这里不只是启动一个子线程来执行register0, 其实在这之前还做了好多时间。&lt;/p&gt;
&lt;p&gt;   我们进入eventLoop的execute()方法，惊喜不。。。&lt;/p&gt;
&lt;p&gt;    &lt;img src=&quot;https://img2018.cnblogs.com/blog/1143158/201906/1143158-20190619002155832-846395855.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;    inEventLoop的值肯定是false,  然后执行addTask(task)，把当前这个任务（register0）加入到队列中，看下这个队列&lt;/p&gt;
&lt;p&gt;   &lt;img src=&quot;https://img2018.cnblogs.com/blog/1143158/201906/1143158-20190619002405448-2128629321.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;   &lt;img src=&quot;https://img2018.cnblogs.com/blog/1143158/201906/1143158-20190619002449559-866771858.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;   这个队列是一个LinkedBlockingQueue. &lt;/p&gt;
&lt;p&gt;   继续&lt;/p&gt;
&lt;p&gt;   &lt;img src=&quot;https://img2018.cnblogs.com/blog/1143158/201906/1143158-20190619002604482-1711955479.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;   &lt;img src=&quot;https://img2018.cnblogs.com/blog/1143158/201906/1143158-20190619002718491-1354504562.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;    这就是举世闻名的CAS无锁技术，当然不了解CAS的自行百度。这里我想说的是，大家可以学习一下Netty这种写法。&lt;/p&gt;
&lt;p&gt;    &lt;img src=&quot;https://img2018.cnblogs.com/blog/1143158/201906/1143158-20190619003116898-1570090794.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;         &lt;img src=&quot;https://img2018.cnblogs.com/blog/1143158/201906/1143158-20190619003130808-46200665.png&quot; alt=&quot;&quot;/&gt; &lt;/p&gt;
&lt;p&gt;       CAS方式原子性更新state字段的值，这里的state一定要使用volatile修饰，这个关键字不太了解的，也自行百度。&lt;/p&gt;
&lt;p&gt;       回到  startThread() 方法， 先检查一下Thread 是否已经启动， 如果没有启动，就把state原子性改成 启动状态 ，如果在启动过程中出现异常，则再次把state原子性改成 未启动状态。&lt;/p&gt;
&lt;p&gt;       继续进入 doStartThread() 方法&lt;/p&gt;
&lt;p&gt;       &lt;img src=&quot;https://img2018.cnblogs.com/blog/1143158/201906/1143158-20190619003611620-1919333099.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;       先是一个断言来保证thread一定是null， 然后启动一个子线程，并把当前这个子线程 赋值给了当前的 这个NioEventLoop 中的 thread 成员变量。 ok ，到现在为止，NioEventLoop 中的唯一线程确定。&lt;/p&gt;
&lt;p&gt;      &lt;img src=&quot;https://img2018.cnblogs.com/blog/1143158/201906/1143158-20190619004222063-394102071.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;      从这里我们进入run() 方法&lt;/p&gt;
&lt;p&gt;      &lt;img src=&quot;https://img2018.cnblogs.com/blog/1143158/201906/1143158-20190619004425328-1516916842.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;      我们发现进入到了一个死循环， 然后里面有一个switch分支，我们来看下里面的策略计算方法。&lt;/p&gt;
&lt;p&gt;      在说这个之前我们再来一起看一个NIO中多路复用器的API&lt;/p&gt;
&lt;p&gt;     &lt;img src=&quot;https://img2018.cnblogs.com/blog/1143158/201906/1143158-20190624004854313-2027190334.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;       &lt;span&gt;不会阻塞，不管什么通道就绪都立刻返回（&lt;em&gt;译者注：此方法执行非阻塞的选择操作。如果自从前一次选择操作后，没有通道变成可选择的，则此方法直接返回零。&lt;/em&gt;）&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;       &lt;span&gt;同时这个方法会清除wakeup()方法的效果。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;    &lt;img src=&quot;https://img2018.cnblogs.com/blog/1143158/201906/1143158-20190624004914533-1897666131.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;       &lt;span&gt;此方法执行阻塞的 selection operation 。 只有在选择了至少一个通道之后，才会返回此选择器的&lt;a&gt;&lt;span&gt;&lt;code&gt;wakeup&lt;/code&gt;&lt;/span&gt;&lt;/a&gt;方法，当前线程被中断，或给定的超时期限到期，以先到者为准。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;       此方法不提供实时保证：它调用超时，就像调用&lt;a&gt;&lt;span&gt;&lt;code&gt;Object.wait(long)&lt;/code&gt;&lt;/span&gt;&lt;/a&gt;方法一样。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;    &lt;img src=&quot;https://img2018.cnblogs.com/blog/1143158/201906/1143158-20190624004938629-903955463.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;     &lt;span&gt; 如果另一个线程在&lt;a&gt;&lt;span&gt;调用&lt;code&gt;select()&lt;/code&gt;&lt;/span&gt;&lt;/a&gt;或&lt;a&gt;&lt;span&gt;&lt;code&gt;select(long)&lt;/code&gt;&lt;/span&gt;&lt;/a&gt;方法时被阻止，则该调用将立即返回。 如果当前没有选择操作，则下一次调用这些方法之一将立即返回，除非在此期间调用&lt;a&gt;&lt;span&gt;&lt;code&gt;selectNow()&lt;/code&gt;&lt;/span&gt;&lt;/a&gt;方法。 无论如何，该调用返回的值可能不为零。 的后续调用&lt;a&gt;&lt;span&gt;&lt;code&gt;select()&lt;/code&gt;点&lt;/span&gt;&lt;/a&gt;或&lt;a&gt;&lt;span&gt;&lt;code&gt;select(long)&lt;/code&gt;&lt;/span&gt;&lt;/a&gt;除非此方法在此期间再次调用的方法将阻塞如常。 &lt;span&gt;在两次连续的选择操作之间多次调用此方法与调用它一样具有相同的效果&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;    好了，了解了这些我们继续看，&lt;/p&gt;
&lt;p&gt;    &lt;img src=&quot;https://img2018.cnblogs.com/blog/1143158/201906/1143158-20190624005522441-2029462869.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;    先检查是否有待处理的task，如果有那么就非阻塞的检查一下是否有新的channel被注册，然后返回channel注册的数量，可能是0， 如果没有task，则返回 - 1&lt;/p&gt;
&lt;p&gt;    我们发现如果有task，那么这么switch就直接跳出了。如果返回 - 1 ，就执行 select(wakenUp.getAndSet(false))&lt;/p&gt;
&lt;p&gt;    我们先看下没有task的情况吧。先大概读一下这一大段注释&lt;/p&gt;
&lt;p&gt;   &lt;img src=&quot;https://img2018.cnblogs.com/blog/1143158/201906/1143158-20190624010012286-318926756.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;   大概的意思是说：&lt;/p&gt;
&lt;p&gt;   在调用选择器唤醒方法，之前，先确定wakenUp的值，以减少唤醒负载，因为&lt;/p&gt;




&lt;p&gt;oldWakenUp = false&lt;/p&gt;
&lt;p&gt;   &lt;img src=&quot;https://img2018.cnblogs.com/blog/1143158/201906/1143158-20190624011839161-1920090643.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;    那么再假如当前是有task待处理的，那么也就是说  hasTasks() &amp;amp;&amp;amp; wakenUp.compareAndSet(false, true)  == true , 那么将执行selectNow(), 也就是当前时间到上一次select操作的期间内是否有channel注册进来。&lt;/p&gt;
&lt;p&gt;    然后break，接下来&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1143158/201906/1143158-20190624012035269-1720138526.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;   wakeUp 刚刚被CAS 成 true ，所以这里会执行wakeup操作，也就意味着下一次select操作将会被立即返回。&lt;/p&gt;
&lt;p&gt;   接下来就是去处理task 和 新接入的客户端或者读写操作了（一会再说这个）。 &lt;/p&gt;
&lt;p&gt;   因为是死循环，我们继续回来，又到了 &lt;/p&gt;
&lt;p&gt;   &lt;img src=&quot;https://img2018.cnblogs.com/blog/1143158/201906/1143158-20190624012338928-443298165.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;    这次的wakeUp 变成了true, 并且把状态置为false, 那么也就是说  oldWakenUp = true &lt;/p&gt;
&lt;p&gt;    &lt;img src=&quot;https://img2018.cnblogs.com/blog/1143158/201906/1143158-20190624012517173-896870253.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;      这里不管有没有任务，都会立即返回，因为我们之前执行了selector.wakeup()，这里我自己猜测可能是因为处理读写和任务用掉了很长时间，所以这里直接就检查当前是会有channel已经注册进来已经在等待了。&lt;/p&gt;
&lt;p&gt;      如果有的话，直接break.去执行。 &lt;/p&gt;
&lt;p&gt;      当然如果之前没有 selector.wakeup() 过，那么将会执行 1s 的时间，看着1s 内是否有新的channel进来。&lt;/p&gt;
&lt;p&gt;      &lt;img src=&quot;https://img2018.cnblogs.com/blog/1143158/201906/1143158-20190624013039754-1682956491.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;        &lt;img src=&quot;https://img2018.cnblogs.com/blog/1143158/201906/1143158-20190624013048285-890486200.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;       继续看，通过这两段我们发现如果循环超时了，那么将会break掉。&lt;/p&gt;
&lt;p&gt;      &lt;img src=&quot;https://img2018.cnblogs.com/blog/1143158/201906/1143158-20190624013202876-1640405706.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;    &lt;img src=&quot;https://img2018.cnblogs.com/blog/1143158/201906/1143158-20190624013217673-314206527.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;      通过这两段我们发现，当循环512次之后，那么将会重建Selector&lt;/p&gt;
&lt;p&gt;       &lt;img src=&quot;https://img2018.cnblogs.com/blog/1143158/201906/1143158-20190624013351948-1722747185.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;      这里其实是因为JDK的BUG导致的，会把CPU飚到100%&lt;/p&gt;
&lt;p&gt;      整个重建的过程其实就是，创建新的selector，把老的上面的 SelectionKey 都注册到新的selector上，然后将老的selector关闭掉，具体的内容就不一起看了。&lt;/p&gt;

</description>
<pubDate>Tue, 02 Jul 2019 15:58:00 +0000</pubDate>
<dc:creator>Diligent_Watermelon</dc:creator>
<og:description>接上一篇，我们继续看 不知道大家第一次看这段代码的时候有没有一脸懵逼，反正我是一脸懵，为什么这个if else 最终都是调用的register0方法，都是一样的。 其实这里就是为什么Netty是线程安</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/huxipeng/p/11042918.html</dc:identifier>
</item>
<item>
<title>Go语言之从0到1实现一个简单的Redis连接池 - jeferwang</title>
<link>http://www.cnblogs.com/wxjblog/p/11123806.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/wxjblog/p/11123806.html</guid>
<description>&lt;h2 id=&quot;前言&quot;&gt;前言&lt;/h2&gt;
&lt;p&gt;最近学习了一些Go语言开发相关内容，但是苦于手头没有可以练手的项目，学的时候理解不清楚，学过容易忘。&lt;/p&gt;
&lt;p&gt;结合之前组内分享时学到的Redis相关知识，以及Redis Protocol文档，就想着自己造个轮子练练手。&lt;/p&gt;
&lt;p&gt;这次我把目标放在了Redis client implemented with Go，使用原生Go语言和TCP实现一个简单的Redis连接池和协议解析，以此来让自己入门Go语言，并加深理解和记忆。（这样做直接导致的后果是，最近写JS时if语句总是忘带括号QAQ）。&lt;/p&gt;
&lt;p&gt;本文只能算是学习Go语言时的一个随笔，并不是真正要造一个线上环境可用的Go-Redis库~(︿(￣︶￣)︿摊手)&lt;/p&gt;
&lt;p&gt;顺便安利以下自己做的一个跨平台开源Redis管理软件：&lt;a href=&quot;https://arm.jeferwang.com/&quot;&gt;AwesomeRedisManager官网&lt;/a&gt;&lt;a href=&quot;https://github.com/JeferWang/AwesomeRedisManager&quot;&gt;AwesomeRedisManager源码&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Redis协议主要参考这篇文档&lt;a href=&quot;http://doc.redisfans.com/topic/protocol.html&quot;&gt;通信协议（protocol）&lt;/a&gt;，阅读后了解到，Redis Protocol并没有什么复杂之处，主要是使用TCP来传输一些固定格式的字符串数据达到发送命令和解析Response数据的目的。&lt;/p&gt;
&lt;h3 id=&quot;命令格式&quot;&gt;命令格式&lt;/h3&gt;
&lt;p&gt;根据文档了解到，Redis命令格式为（CR LF即\r\n）：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;*&amp;lt;参数数量N&amp;gt; CR LF
$&amp;lt;参数 1 的字节数量&amp;gt; CR LF
&amp;lt;参数 1 的数据&amp;gt; CR LF
...
$&amp;lt;参数 N 的字节数量&amp;gt; CR LF
&amp;lt;参数 N 的数据&amp;gt; CR LF&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;命令的每一行都使用CRLF结尾，在命令结构的开头就声明了命令的参数数量，每一条参数都带有长度标记，方便服务端解析。&lt;/p&gt;
&lt;p&gt;例如，发送一个SET命令&lt;code&gt;set name jeferwang&lt;/code&gt;：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;*3
$3
SET
$4
name
$9
jeferwang&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;响应格式&quot;&gt;响应格式&lt;/h3&gt;
&lt;p&gt;Redis的响应回复数据主要分为五种类型：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;状态回复：一行数据，使用&lt;code&gt;+&lt;/code&gt;开头（例如：OK、PONG等）&lt;/li&gt;
&lt;/ul&gt;&lt;pre&gt;
&lt;code&gt;+OK\r\n
+PONG\r\n&lt;/code&gt;
&lt;/pre&gt;
&lt;ul&gt;&lt;li&gt;错误回复：一行数据，使用&lt;code&gt;-&lt;/code&gt;开头（Redis执行命令时产生的错误）&lt;/li&gt;
&lt;/ul&gt;&lt;pre&gt;
&lt;code&gt;-ERR unknown command 'demo'\r\n&lt;/code&gt;
&lt;/pre&gt;
&lt;ul&gt;&lt;li&gt;整数回复：一行数据，使用&lt;code&gt;:&lt;/code&gt;开头（例如：llen返回的长度数值等）&lt;/li&gt;
&lt;/ul&gt;&lt;pre&gt;
&lt;code&gt;:100\r\n&lt;/code&gt;
&lt;/pre&gt;
&lt;ul&gt;&lt;li&gt;批量回复（可以理解为字符串）：两行数据，使用&lt;code&gt;$&lt;/code&gt;开头，第一行为内容长度，第二行为具体内容&lt;/li&gt;
&lt;/ul&gt;&lt;pre&gt;
&lt;code&gt;$5\r\n
abcde\r\n

特殊情况：$-1\r\n即为返回空数据，可以转化为nil&lt;/code&gt;
&lt;/pre&gt;
&lt;ul&gt;&lt;li&gt;多条批量回复：使用&lt;code&gt;*&lt;/code&gt;开头，第一行标识本次回复包含多少条批量回复，后面每两行为一个批量回复（lrange、hgetall等命令的返回数据）&lt;/li&gt;
&lt;/ul&gt;&lt;pre&gt;
&lt;code&gt;*2\r\n
$5\r\n
ABCDE\r\n
$2\r\n
FG\r\n&lt;/code&gt;
&lt;/pre&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;更详细的命令和回复格式可以从Redis Protocol文档了解到，本位只介绍一些基本的开发中需要用到的内容&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;以下为部分代码，完整代码见GitHub：&lt;a href=&quot;https://github.com/JeferWang/redis4go&quot;&gt;redis4go&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;实现流程&quot;&gt;实现流程&lt;/h2&gt;
&lt;ol&gt;&lt;li&gt;首先，我们根据官网文档了解到了Redis传输协议，即Redis使用TCP传输命令的格式和接收数据的格式，据此，我们可以使用Go实现对Redis协议的解析&lt;/li&gt;
&lt;li&gt;接下来，在可以建立Redis连接并进行数据传输的前提下，实现一个连接池。&lt;/li&gt;
&lt;li&gt;实现拼接Redis命令的方法，通过TCP发送到RedisServer&lt;/li&gt;
&lt;li&gt;读取RedisResponse，实现解析数据的方法&lt;/li&gt;
&lt;/ol&gt;&lt;h2 id=&quot;模块结构分析&quot;&gt;模块结构分析&lt;/h2&gt;
&lt;p&gt;简单分析Redis连接池的结构，可以先简单规划为5个部分：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;结构体定义&lt;code&gt;entity.go&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Redis连接和调用&lt;code&gt;redis_conn.go&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Redis数据类型解析&lt;code&gt;data_type.go&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;连接池实现&lt;code&gt;pool.go&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;共划分为上述四个部分&lt;/p&gt;
&lt;h2 id=&quot;对象结构定义&quot;&gt;对象结构定义&lt;/h2&gt;
&lt;p&gt;为了实现连接池及Redis数据库连接，我们需要如下结构：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;Redis服务器配置&lt;code&gt;RedisConfig&lt;/code&gt;：包含Host、Port等信息&lt;/li&gt;
&lt;li&gt;Redis连接池配置&lt;code&gt;PoolConfig&lt;/code&gt;：继承&lt;code&gt;RedisConfig&lt;/code&gt;，包含PoolSize等信息&lt;/li&gt;
&lt;li&gt;Redis连接池结构：包含连接队列、连接池配置等信息&lt;/li&gt;
&lt;li&gt;单个Redis连接：包含TCP连接Handler、是否处于空闲标记位、当前使用的数据库等信息&lt;/li&gt;
&lt;/ul&gt;&lt;pre class=&quot;go&quot;&gt;
&lt;code&gt;package redis4go

import (
    &quot;net&quot;
    &quot;sync&quot;
)

type RedisConfig struct {
    Host     string // RedisServer主机地址
    Port     int    // RedisServer主机端口
    Password string // RedisServer需要的Auth验证，不填则为空
}

// 连接池的配置数据
type PoolConfig struct {
    RedisConfig
    PoolSize int // 连接池的大小
}

// 连接池结构
type Pool struct {
    Config PoolConfig          // 建立连接池时的配置
    Queue  chan *RedisConn     // 连接池
    Store  map[*RedisConn]bool // 所有的连接
    mu     sync.Mutex          // 加锁
}

// 单个Redis连接的结构
type RedisConn struct {
    mu        sync.Mutex   // 加锁
    p         *Pool        // 所属的连接池
    IsRelease bool         // 是否处于释放状态
    IsClose   bool         // 是否已关闭
    TcpConn   *net.TCPConn // 建立起的到RedisServer的连接
    DBIndex   int          // 当前连接正在使用第几个Redis数据库
}

type RedisResp struct {
    rType byte     // 回复类型(+-:$*)
    rData [][]byte // 从TCP连接中读取的数据统一使用二维数组返回
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;根据之前的规划，定义好基本的结构之后，我们可以先实现一个简单的Pool对象池&lt;/p&gt;
&lt;h2 id=&quot;redis连接&quot;&gt;Redis连接&lt;/h2&gt;
&lt;h3 id=&quot;建立连接&quot;&gt;建立连接&lt;/h3&gt;
&lt;p&gt;首先我们需要实现一个建立Redis连接的方法&lt;/p&gt;
&lt;pre class=&quot;go&quot;&gt;
&lt;code&gt;// 创建一个RedisConn对象
func createRedisConn(config RedisConfig) (*RedisConn, error) {
    tcpAddr := &amp;amp;net.TCPAddr{IP: net.ParseIP(config.Host), Port: config.Port}
    tcpConn, err := net.DialTCP(&quot;tcp&quot;, nil, tcpAddr)
    if err != nil {
        return nil, err
    }
    return &amp;amp;RedisConn{
        IsRelease: true,
        IsClose:   false,
        TcpConn:   tcpConn,
        DBIndex:   0,
    }, nil
}&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;实现连接池&quot;&gt;实现连接池&lt;/h3&gt;
&lt;p&gt;在Go语言中，我们可以使用一个&lt;code&gt;chan&lt;/code&gt;来很轻易地实现一个指定容量的队列，来作为连接池使用，当池中没有连接时，申请获取连接时将会被阻塞，直到放入新的连接。&lt;/p&gt;
&lt;pre class=&quot;go&quot;&gt;
&lt;code&gt;package redis4go

func CreatePool(config PoolConfig) (*Pool, error) {
    pool := &amp;amp;Pool{
        Config: config,
        Queue:  make(chan *RedisConn, config.PoolSize),
        Store:  make(map[*RedisConn]bool, config.PoolSize),
    }
    for i := 0; i &amp;lt; config.PoolSize; i++ {
        redisConn, err := createRedisConn(config.RedisConfig)
        if err != nil {
            // todo 处理之前已经创建好的链接
            return nil, err
        }
        redisConn.p = pool
        pool.Queue &amp;lt;- redisConn
        pool.Store[redisConn] = true
    }
    return pool, nil
}

// 获取一个连接
func (pool *Pool) getConn() *RedisConn {
    pool.mu.Lock()
    // todo 超时机制
    conn := &amp;lt;-pool.Queue
    conn.IsRelease = false
    pool.mu.Unlock()
    return conn
}

// 关闭连接池
func (pool *Pool) Close() {
    for conn := range pool.Store {
        err := conn.Close()
        if err != nil {
            // todo 处理连接关闭的错误？
        }
    }
}&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;发送命令解析回复数据&quot;&gt;发送命令&amp;amp;解析回复数据&lt;/h2&gt;
&lt;p&gt;下面是向RedisServer发送命令，以及读取回复数据的简单实现&lt;/p&gt;
&lt;pre class=&quot;go&quot;&gt;
&lt;code&gt;func (conn *RedisConn) Call(params ...interface{}) (*RedisResp, error) {
    reqData, err := mergeParams(params...)
    if err != nil {
        return nil, err
    }
    conn.Lock()
    defer conn.Unlock()
    _, err = conn.TcpConn.Write(reqData)
    if err != nil {
        return nil, err
    }
    resp, err := conn.getReply()
    if err != nil {
        return nil, err
    }
    if resp.rType == '-' {
        return resp, resp.ParseError()
    }
    return resp, nil
}

func (conn *RedisConn) getReply() (*RedisResp, error) {
    b := make([]byte, 1)
    _, err := conn.TcpConn.Read(b)
    if err != nil {
        return nil, err
    }
    resp := new(RedisResp)
    resp.rType = b[0]
    switch b[0] {
    case '+':
        // 状态回复
        fallthrough
    case '-':
        // 错误回复
        fallthrough
    case ':':
        // 整数回复
        singleResp := make([]byte, 1)
        for {
            _, err := conn.TcpConn.Read(b)
            if err != nil {
                return nil, err
            }
            if b[0] != '\r' &amp;amp;&amp;amp; b[0] != '\n' {
                singleResp = append(singleResp, b[0])
            }
            if b[0] == '\n' {
                break
            }
        }
        resp.rData = append(resp.rData, singleResp)
    case '$':
        buck, err := conn.readBuck()
        if err != nil {
            return nil, err
        }
        resp.rData = append(resp.rData, buck)
    case '*':
        // 条目数量
        itemNum := 0
        for {
            _, err := conn.TcpConn.Read(b)
            if err != nil {
                return nil, err
            }
            if b[0] == '\r' {
                continue
            }
            if b[0] == '\n' {
                break
            }
            itemNum = itemNum*10 + int(b[0]-'0')
        }
        for i := 0; i &amp;lt; itemNum; i++ {
            buck, err := conn.readBuck()
            if err != nil {
                return nil, err
            }
            resp.rData = append(resp.rData, buck)
        }
    default:
        return nil, errors.New(&quot;错误的服务器回复&quot;)
    }
    return resp, nil
}

func (conn *RedisConn) readBuck() ([]byte, error) {
    b := make([]byte, 1)
    dataLen := 0
    for {
        _, err := conn.TcpConn.Read(b)
        if err != nil {
            return nil, err
        }
        if b[0] == '$' {
            continue
        }
        if b[0] == '\r' {
            break
        }
        dataLen = dataLen*10 + int(b[0]-'0')
    }
    bf := bytes.Buffer{}
    for i := 0; i &amp;lt; dataLen+3; i++ {
        _, err := conn.TcpConn.Read(b)
        if err != nil {
            return nil, err
        }
        bf.Write(b)
    }
    return bf.Bytes()[1 : bf.Len()-2], nil
}

func mergeParams(params ...interface{}) ([]byte, error) {
    count := len(params) // 参数数量
    bf := bytes.Buffer{}
    // 参数数量
    {
        bf.WriteString(&quot;*&quot;)
        bf.WriteString(strconv.Itoa(count))
        bf.Write([]byte{'\r', '\n'})
    }
    for _, p := range params {
        bf.Write([]byte{'$'})
        switch p.(type) {
        case string:
            str := p.(string)
            bf.WriteString(strconv.Itoa(len(str)))
            bf.Write([]byte{'\r', '\n'})
            bf.WriteString(str)
            break
        case int:
            str := strconv.Itoa(p.(int))
            bf.WriteString(strconv.Itoa(len(str)))
            bf.Write([]byte{'\r', '\n'})
            bf.WriteString(str)
            break
        case nil:
            bf.WriteString(&quot;-1&quot;)
            break
        default:
            // 不支持的参数类型
            return nil, errors.New(&quot;参数只能是String或Int&quot;)
        }
        bf.Write([]byte{'\r', '\n'})
    }
    return bf.Bytes(), nil
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;实现几个常用数据类型的解析&lt;/p&gt;
&lt;pre class=&quot;go&quot;&gt;
&lt;code&gt;package redis4go

import (
    &quot;errors&quot;
    &quot;strconv&quot;
)

func (resp *RedisResp) ParseError() error {
    if resp.rType != '-' {
        return nil
    }
    return errors.New(string(resp.rData[0]))
}

func (resp *RedisResp) ParseInt() (int, error) {
    switch resp.rType {
    case '-':
        return 0, resp.ParseError()
    case '$':
        fallthrough
    case ':':
        str, err := resp.ParseString()
        if err != nil {
            return 0, err
        }
        return strconv.Atoi(str)
    default:
        return 0, errors.New(&quot;错误的回复类型&quot;)
    }
}

func (resp *RedisResp) ParseString() (string, error) {
    switch resp.rType {
    case '-':
        return &quot;&quot;, resp.ParseError()
    case '+':
        fallthrough
    case ':':
        fallthrough
    case '$':
        return string(resp.rData[0]), nil
    default:
        return &quot;&quot;, errors.New(&quot;错误的回复类型&quot;)
    }
}
func (resp *RedisResp) ParseList() ([]string, error) {
    switch resp.rType {
    case '-':
        return nil, resp.ParseError()
    case '*':
        list := make([]string, 0, len(resp.rData))
        for _, data := range resp.rData {
            list = append(list, string(data))
        }
        return list, nil
    default:
        return nil, errors.New(&quot;错误的回复类型&quot;)
    }
}
func (resp *RedisResp) ParseMap() (map[string]string, error) {
    switch resp.rType {
    case '-':
        return nil, resp.ParseError()
    case '*':
        mp := make(map[string]string)
        for i := 0; i &amp;lt; len(resp.rData); i += 2 {
            mp[string(resp.rData[i])] = string(resp.rData[i+1])
        }
        return mp, nil
    default:
        return nil, errors.New(&quot;错误的回复类型&quot;)
    }
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;在开发的过程中，随手编写了几个零零散散的测试文件，经测试，一些简单的Redis命令以及能跑通了。&lt;/p&gt;
&lt;pre class=&quot;go&quot;&gt;
&lt;code&gt;package redis4go

import (
    &quot;testing&quot;
)

func getConn() (*RedisConn, error) {
    pool, err := CreatePool(PoolConfig{
        RedisConfig: RedisConfig{
            Host: &quot;127.0.0.1&quot;,
            Port: 6379,
        },
        PoolSize: 10,
    })
    if err != nil {
        return nil, err
    }
    conn := pool.getConn()
    return conn, nil
}

func TestRedisResp_ParseString(t *testing.T) {
    demoStr := string([]byte{'A', '\n', '\r', '\n', 'b', '1'})
    conn, _ := getConn()
    _, _ = conn.Call(&quot;del&quot;, &quot;name&quot;)
    _, _ = conn.Call(&quot;set&quot;, &quot;name&quot;, demoStr)
    resp, err := conn.Call(&quot;get&quot;, &quot;name&quot;)
    if err != nil {
        t.Fatal(&quot;Call Error:&quot;, err.Error())
    }
    str, err := resp.ParseString()
    if err != nil {
        t.Fatal(&quot;Parse Error:&quot;, err.Error())
    }
    if str != demoStr {
        t.Fatal(&quot;结果错误&quot;)
    }
}

func TestRedisResp_ParseList(t *testing.T) {
    conn, _ := getConn()
    _, _ = conn.Call(&quot;del&quot;, &quot;testList&quot;)
    _, _ = conn.Call(&quot;lpush&quot;, &quot;testList&quot;, 1, 2, 3, 4, 5)
    res, err := conn.Call(&quot;lrange&quot;, &quot;testList&quot;, 0, -1)
    if err != nil {
        t.Fatal(&quot;Call Error:&quot;, err.Error())
    }
    ls, err := res.ParseList()
    if err != nil {
        t.Fatal(&quot;Parse Error:&quot;, err.Error())
    }
    if len(ls) != 5 {
        t.Fatal(&quot;结果错误&quot;)
    }
}

func TestRedisResp_ParseMap(t *testing.T) {
    conn, _ := getConn()
    _, _ = conn.Call(&quot;del&quot;, &quot;testMap&quot;)
    _, err := conn.Call(&quot;hmset&quot;, &quot;testMap&quot;, 1, 2, 3, 4, 5, 6)
    if err != nil {
        t.Fatal(&quot;设置Value失败&quot;)
    }
    res, err := conn.Call(&quot;hgetall&quot;, &quot;testMap&quot;)
    if err != nil {
        t.Fatal(&quot;Call Error:&quot;, err.Error())
    }
    ls, err := res.ParseMap()
    if err != nil {
        t.Fatal(&quot;Parse Error:&quot;, err.Error())
    }
    if len(ls) != 3 || ls[&quot;1&quot;] != &quot;2&quot; {
        t.Fatal(&quot;结果错误&quot;)
    }
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;至此，已经算是达到了学习Go语言和学习Redis Protocol的目的，不过代码中也有很多地方需要优化和完善，性能方面考虑的也并不周全。轮子就不重复造了，毕竟有很多功能完善的库，从头造一个轮子需要消耗的精力太多啦并且没必要~&lt;/p&gt;
&lt;p&gt;下一次我将会学习官方推荐的&lt;code&gt;gomodule/redigo&lt;/code&gt;源码，并分享我的心得。&lt;/p&gt;
&lt;p&gt;--The End--&lt;/p&gt;
</description>
<pubDate>Tue, 02 Jul 2019 15:28:00 +0000</pubDate>
<dc:creator>jeferwang</dc:creator>
<og:description>Go语言之从0到1实现一个简单的Redis连接池 前言 最近学习了一些Go语言开发相关内容，但是苦于手头没有可以练手的项目，学的时候理解不清楚，学过容易忘。 结合之前组内分享时学到的Redis相关知识</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/wxjblog/p/11123806.html</dc:identifier>
</item>
<item>
<title>Binary classification - 聊聊评价指标的那些事儿【实战篇】 - 风雨中的小七</title>
<link>http://www.cnblogs.com/gogoSandy/p/11123688.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/gogoSandy/p/11123688.html</guid>
<description>&lt;p&gt;分类问题就像披着羊皮的狼，看起来天真无害用起来天雷滚滚。比如在建模前你思考过下面的问题么？&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;你的分类模型输出的概率只是用来做样本间的相对排序，还是概率本身？&lt;/li&gt;
&lt;li&gt;你的训练数据本身分布如何是否存在Imbalanced Sample？&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;要是您都想到了拜拜👋。要是有1各您感兴趣的问题，那就接着往下看吧。本来是想先回顾一下各个分类问题中可能用到的metric，但是又觉得读的人可能觉得无聊，就分成了两章。要是有的指标断片了就来这里回忆一下: &lt;a href=&quot;https://www.cnblogs.com/gogoSandy/p/11112459.html&quot;&gt;回忆篇&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;问题1-rank-or-probability&quot;&gt;问题1 Rank or Probability?&lt;/h2&gt;
&lt;p&gt;分类问题可以根据对输出形式的要求分成两类&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;一种我们只关心排序。比如电商场景下，用户是否会回购某商品，我们更关心用户回购商品A的概率是否高于用户回购商品B的概率，然后把回购概率更高的商品放在推荐列表前面。这时分类问题其实是用来排序的。&lt;strong&gt;--样本间的相对排序比较比绝对概率更重要&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;另一种我们关心概率。比如现在大家都在谈增长，我们想知道一个用户明天在app活跃的概率，只知道用户A比用户B活跃的概率高并不够，我们需要明确知道用户A活跃的概率，究竟是90%还是50%，这样才能对高/低于特定概率的用户进行一定（促活/唤醒）操作。这时分类问题是对真实概率的估计 &lt;strong&gt;--样本的绝对概率需要接近真实概率，并且天极稳定&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;有人会问，上述两种需求究竟对解决一个二分类问题有什么影响？ 答案是&lt;strong&gt;损失函数/评价指标&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;让我们来看一个直观的例子，下图我们尝试用LightGBM解决一个二分类问题,我们选择的拟合指标是最大化AUC。&lt;/p&gt;
&lt;p&gt;X轴是预测概率，Y轴是真实概率，蓝线是LGB的预测结果，绿线对应真实概率=预测概率。为什么模型的AUC高达98.93%(这里还有ImbalancedSample的影响，让我们先忽略这一点)，但是预测概率和真实概率却差到了姥姥家。&lt;/p&gt;
&lt;p&gt;让我们对预测概率再做一层处理，黄线可以简单理解为我们对LGB的预测结果做了一层映射 &lt;span class=&quot;math inline&quot;&gt;\(\hat{p} \to f(\hat{p})\)&lt;/span&gt;，这时校准后的预测概率和真实概率基本一致了。&lt;strong&gt;但是有趣的是校准后的预测概率AUC = 98.94%和原始预测基本没差别？！&lt;/strong&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;http://static.zybuluo.com/hongchenzimo/fvn2k5tjuzy6pp1wtdcupoyh/image_1ddrqv2luqki75uqnmgcs1tjk13.png&quot; width=&quot;400&quot; height=&quot;300&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Duang Duang Duang!敲黑板！AUC是对相对概率排序的检验！&lt;/strong&gt;其实只要用心（我学AUC的时候一定没用心&amp;gt;_&amp;lt;）看一下AUC的计算方式就会发现，AUC只关心给定各个阈值，把样本按照预测概率分成0/1，并计算正负样本预测的准确率。&lt;/p&gt;
&lt;p&gt;举个最夏天的例子，两个瓜一个甜一个不甜，我们训练一个西瓜模型来预测它们甜（1）/不甜（0）。&lt;br/&gt;模型1: 甜的瓜预测概率是0.8，不甜的瓜预测概率是0.1，&lt;br/&gt;模型2: 甜的瓜预测概率是0.51，不甜的瓜预测概率是0.49&lt;br/&gt;两个模型的AUC是相同的，因为它们都完美对两个瓜进行了分类。&lt;/p&gt;
&lt;p&gt;所以当使用最大化AUC作为损失函数时，当正负样本的预测准确率不再提高，模型就会停止学习。这时模型的预测概率并不是对真实概率的拟合。那如何才能得到对真实概率的预测？ 答案是logloss/cros-entropy&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;math display&quot;&gt;\[ \begin{align} L &amp;amp;= \sum_{i=1}^N y_i * log(p_i) + (1-y_i) *log(1-p_i)\\ \end{align} \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;我们可以从两个角度来理解为什么logloss是对真实概率的估计&lt;/p&gt;
&lt;ol readability=&quot;4.410199556541&quot;&gt;&lt;li readability=&quot;1&quot;&gt;
&lt;p&gt;从极大似然估计的角度&lt;br/&gt;logloss可以由极大似然函数取对数得到，最小化logloss对应的最大化似然函数。&lt;span class=&quot;math inline&quot;&gt;\(p_i\)&lt;/span&gt;是对&lt;span class=&quot;math inline&quot;&gt;\(p(y_i=1)\)&lt;/span&gt;的估计&lt;br/&gt;&lt;span class=&quot;math display&quot;&gt;\[ argmax_p \prod_{i=1}^N {p_i}^{y_i} * {(1-p_i)}^{1-y_i} \]&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;7.8081705150977&quot;&gt;
&lt;p&gt;从信息论的角度&lt;br/&gt;不熟悉信息论的同学看这里 &lt;a href=&quot;https://www.cnblogs.com/gogoSandy/p/9075664.html&quot;&gt;Intro to Information Theory&lt;/a&gt;&lt;br/&gt;logloss也叫cross-entropy(交叉熵),用来衡量两个分布的相似程度。&lt;br/&gt;交叉熵本身可以分解为P本身的信息熵+分布P和分布q之间的距离。这里P是样本的真实分布信息,信息熵一定。所以最小化交叉熵就变成了最小化分布p和q之间的距离，也就是样本分布和模型估计间的距离，如下&lt;br/&gt;&lt;span class=&quot;math display&quot;&gt;\[ \begin{align} crossentropy &amp;amp;= H(p,q)\\ &amp;amp;= -\sum_{c=1}^C p(c) * log(q(c))\\ &amp;amp; = - \sum_{c=1}^C p(c) * log(p(c)) + \sum_{c=1}^C p(c)[log(p(c) - log(q(c)))] \\ &amp;amp;= H(p) + KL(p||q)\\ \end{align} \]&lt;/span&gt;&lt;br/&gt;乍一看会觉得交叉熵和logloss长的不像一家人。因为在训练模型时分布p是从训练样本的分布中抽象得到的。二分类问题中C=2, 让我们把上述交叉熵再推一步&lt;br/&gt;&lt;span class=&quot;math display&quot;&gt;\[ \begin{align} H(p,q) &amp;amp;= p *log(q) + (1-p) *log(1-q) \\ p&amp;amp; = \sum_{i=1}^N I(y_i=1)/N \\ H(p,q) &amp;amp;= \frac{1}{N} \sum_i I(y_i=1) *log(q)+ I(y_i=0) *log(1-q) \\ \end{align} \]&lt;/span&gt;&lt;br/&gt;所以下次解决分类问题，如果你的目标是计算对真实概率的估计的话，别选错指标哟�&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;&lt;blockquote readability=&quot;9&quot;&gt;
&lt;p&gt;兴趣卡片- 预测概率校准&lt;br/&gt;其实黄线用了Isotonic Regression来校准预测概率。是一种事后将预测概率根据真实概率进行校准的方法。感兴趣的可以看一下Reference里面的材料1，2。原理并不复杂，但在分析特定算法，尤其是boosting,bagging类的集合算法为什么使用loggloss对概率估计依旧会有偏的部分蛮有趣的&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;问题2-imbalanced-sample&quot;&gt;问题2 Imbalanced Sample ？&lt;/h2&gt;
&lt;p&gt;正负样本分布不均大概是分类问题中最常遇到的问题。正确解决Imbalane问题需要注意的并不只是评价指标，往往还要注意采样和训练集测试集的划分。但这里我们只讨论在解决样本分布不均的问题时，我们应该选择什么指标来评价模型表现。让我们挨个来剔除不好用的指标。&lt;/p&gt;
&lt;p&gt;举个极端的例子，100个样本里只有1个正样本&lt;/p&gt;
&lt;h3 id=&quot;accuracy&quot;&gt;Accuracy&lt;/h3&gt;
&lt;p&gt;这种情况下即便我们全部预测为负，我们的准确率依旧高达99%。所以Accuracy只适用于正负样本均匀分布的情况，因为它把正负样本的预测准确率柔和在一起看了。&lt;/p&gt;
&lt;h3 id=&quot;auc&quot;&gt;AUC&lt;/h3&gt;
&lt;p&gt;AUC是fpr和tpr(recall)组成的ROC的曲线下面积。还记得我们在【回忆篇】里面说过fpr,tpr是分别衡量在正负样本上的准确率的。&lt;/p&gt;
&lt;p&gt;而fpr和tpr之间的trade-off,在正样本占比很小的情况下，这种trad-off会被样本量更大的一方主导。所以当正样本占比很小的时候，AUC往往会看起来过于优秀。&lt;/p&gt;
&lt;p&gt;但就像硬币的正反面一样，从另一个角度看这也是AUC的优点，就是AUC本身不会很大的受到样本实际分布的影响，相同的模型相同的样本，你把正样本downsample /upsample 1倍，AUC不会有很大的改变。&lt;/p&gt;
&lt;p&gt;下图来自An introduction to ROC analysis, 上面的AUC和PR是正负样本1:1的预测表现，下面是1:10的表现。我们会发现AUC基本没有变化，但是precision-recall发生了剧烈变化。&lt;br/&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;&lt;br/&gt;&lt;img src=&quot;http://static.zybuluo.com/hongchenzimo/jsts4vvx4bythbnjwqf21mr0/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-07-02%20%E4%B8%8B%E5%8D%8810.31.52.png&quot; width=&quot;400&quot; height=&quot;300&quot;/&gt;&lt;br/&gt;&lt;/p&gt;
&lt;h3 id=&quot;apaucpr&quot;&gt;AP/AUCPR&lt;/h3&gt;
&lt;p&gt;AP是recall和precision组成的PR的曲线下面积。这里recall和precision分别从真实分布和预测分布两个角度衡量了对正样本的预测准确率。说到这里已经有人反应过来了。是的这一对trade-off指标都是针对正样本的，在计算中没有用到True negative.所以当你的数据集存在Imbalance的时候，AP一般会是更好的选择。&lt;/p&gt;
&lt;h3 id=&quot;你还遇到过啥问题嘞欢迎留言&quot;&gt;...你还遇到过啥问题嘞？欢迎留言&lt;/h3&gt;
&lt;hr/&gt;&lt;p&gt;Reference&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;&lt;a href=&quot;https://www.kaggle.com/residentmaio/notes-on-classification-probability-calibration/&quot; class=&quot;uri&quot;&gt;https://www.kaggle.com/residentmaio/notes-on-classification-probability-calibration/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Pedro G. Fonseca and Hugo D. Lopes. Calibration of Machine Learning Classifiers for Probability of Default Modelling&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Confusion_matrix&quot; class=&quot;uri&quot;&gt;https://en.wikipedia.org/wiki/Confusion_matrix&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Tom Fawcett，An introduction to ROC analysis&lt;/li&gt;
&lt;/ol&gt;</description>
<pubDate>Tue, 02 Jul 2019 15:02:00 +0000</pubDate>
<dc:creator>风雨中的小七</dc:creator>
<og:description>分类问题就像披着羊皮的狼，看起来天真无害用起来天雷滚滚。比如在建模前你思考过下面的问题么？ 你的分类模型输出的概率只是用来做样本间的相对排序，还是概率本身？ 你的训练数据本身分布如何是否存在Imbal</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/gogoSandy/p/11123688.html</dc:identifier>
</item>
<item>
<title>补习系列(21)-SpringBoot初始化之7招式 - 美码师</title>
<link>http://www.cnblogs.com/littleatp/p/11123577.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/littleatp/p/11123577.html</guid>
<description>&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/242916/201907/242916-20190702223217392-1314641492.png&quot;/&gt;&lt;/p&gt;
&lt;h2 id=&quot;背景&quot;&gt;背景&lt;/h2&gt;
&lt;p&gt;在日常开发时，我们常常需要 在SpringBoot 应用启动时执行某一段逻辑，如下面的场景：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;获取一些当前环境的配置或变量&lt;/li&gt;
&lt;li&gt;向数据库写入一些初始数据&lt;/li&gt;
&lt;li&gt;连接某些第三方系统，确认对方可以工作..&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;在实现这些功能时，我们可能会遇到一些&quot;坑&quot;。 为了利用SpringBoot框架的便利性，我们不得不将整个应用的执行控制权交给容器，于是造成了大家对于细节是一无所知的。&lt;br/&gt;那么在实现初始化逻辑代码时就需要小心了，比如，我们并不能简单的将初始化逻辑在Bean类的构造方法中实现，类似下面的代码：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;@Component
public class InvalidInitExampleBean {
 
    @Autowired
    private Environment env;
 
    public InvalidInitExampleBean() {
        env.getActiveProfiles();
    }
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;这里，我们在InvalidInitExampleBean的构造方法中试图访问一个自动注入的env字段，当真正执行时，你一定会得到一个空指针异常(NullPointerException)。&lt;br/&gt;原因在于，当构造方法被调用时，Spring上下文中的Environment这个Bean很可能还没有被实例化，同时也仍未注入到当前对象，所以并不能这样进行调用。&lt;/p&gt;
&lt;p&gt;下面，我们来看看在SpringBoot中实现&quot;安全初始化&quot;的一些方法：&lt;/p&gt;
&lt;h2 id=&quot;postconstruct-注解&quot;&gt;1、 @PostConstruct 注解&lt;/h2&gt;
&lt;p&gt;@PostConstruct 注解其实是来自于 javax的扩展包中(大多数人的印象中是来自于Spring框架)，它的作用在于&lt;strong&gt;声明一个Bean对象初始化完成后执行的方法&lt;/strong&gt;。&lt;br/&gt;来看看它的原始定义：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;The PostConstruct annotation is used on a method that needs to be executed after dependency injection is done to perform any initialization.&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;也就是说，该方法会在所有依赖字段注入后才执行，当然这一动作也是由Spring框架执行的。&lt;/p&gt;
&lt;p&gt;下面的代码演示了使用@PostConstruct的例子：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;@Component
public class PostConstructExampleBean {
 
    private static final Logger LOG 
      = Logger.getLogger(PostConstructExampleBean.class);
 
    @Autowired
    private Environment environment;
 
    @PostConstruct
    public void init() {
        //environment 已经注入
        LOG.info(Arrays.asList(environment.getDefaultProfiles()));
    }
}&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;initializingbean-接口&quot;&gt;2、 InitializingBean 接口&lt;/h2&gt;
&lt;p&gt;InitializingBean 是由Spring框架提供的接口，其与@PostConstruct注解的工作原理非常类似。&lt;br/&gt;如果不使用注解的话，你需要让Bean实例继承 InitializingBean接口，并实现&lt;strong&gt;afterPropertiesSet()&lt;/strong&gt;这个方法。&lt;/p&gt;
&lt;p&gt;下面的代码，展示了这种用法：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;@Component
public class InitializingBeanExampleBean implements InitializingBean {
 
    private static final Logger LOG 
      = Logger.getLogger(InitializingBeanExampleBean.class);
 
    @Autowired
    private Environment environment;
 
    @Override
    public void afterPropertiesSet() throws Exception {
        //environment 已经注入
        LOG.info(Arrays.asList(environment.getDefaultProfiles()));
    }
}&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;bean-initmethod方法&quot;&gt;3、 @Bean initMethod方法&lt;/h2&gt;
&lt;p&gt;我们在声明一个Bean的时候，可以同时指定一个initMethod属性，该属性会指向Bean的一个方法，表示在初始化后执行。&lt;/p&gt;
&lt;p&gt;如下所示：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;@Bean(initMethod=&quot;init&quot;)
public InitMethodExampleBean exBean() {
    return new InitMethodExampleBean();
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;然后，这里将initMethod指向init方法，相应的我们也需要在Bean中实现这个方法：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;public class InitMethodExampleBean {
 
    private static final Logger LOG = Logger.getLogger(InitMethodExampleBean.class);
 
    @Autowired
    private Environment environment;
 
    public void init() {
        LOG.info(Arrays.asList(environment.getDefaultProfiles()));
    }
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;上面的代码是基于Java注解的方式，使用Xml配置也可以达到同样的效果：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;&amp;lt;bean id=&quot;initMethodExampleBean&quot;
  class=&quot;org.baeldung.startup.InitMethodExampleBean&quot;
  init-method=&quot;init&quot;&amp;gt;
&amp;lt;/bean&amp;gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;该方式在早期的 Spring版本中大量被使用&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;构造器注入&quot;&gt;4、 构造器注入&lt;/h2&gt;
&lt;p&gt;如果依赖的字段在Bean的构造方法中声明，那么Spring框架会先实例这些字段对应的Bean，再调用当前的构造方法。&lt;br/&gt;此时，构造方法中的一些操作也是安全的，如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;@Component
public class LogicInConstructorExampleBean {
 
    private static final Logger LOG 
      = Logger.getLogger(LogicInConstructorExampleBean.class);
 
    private final Environment environment;
 
    @Autowired
    public LogicInConstructorExampleBean(Environment environment) {
        //environment实例已初始化
        this.environment = environment;
        LOG.info(Arrays.asList(environment.getDefaultProfiles()));
    }
}&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;applicationlistener&quot;&gt;5、 ApplicationListener&lt;/h2&gt;
&lt;p&gt;ApplicationListener 是由 spring-context组件提供的一个接口，主要是用来监听 &quot;容器上下文的生命周期事件&quot;。&lt;br/&gt;它的定义如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;public interface ApplicationListener&amp;lt;E extends ApplicationEvent&amp;gt; extends EventListener {
    /**
     * Handle an application event.
     * @param event the event to respond to
     */
    void onApplicationEvent(E event);
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;这里的event可以是任何一个继承于ApplicationEvent的事件对象。 对于初始化工作来说，我们可以通过监听&lt;strong&gt;ContextRefreshedEvent&lt;/strong&gt;这个事件来捕捉上下文初始化的时机。&lt;br/&gt;如下面的代码：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;@Component
public class StartupApplicationListenerExample implements
  ApplicationListener&amp;lt;ContextRefreshedEvent&amp;gt; {
 
    private static final Logger LOG 
      = Logger.getLogger(StartupApplicationListenerExample.class);
 
    public static int counter;
 
    @Override public void onApplicationEvent(ContextRefreshedEvent event) {
        LOG.info(&quot;Increment counter&quot;);
        counter++;
    }
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;在Spring上下文初始化完成后，这里定义的方法将会被执行。&lt;br/&gt;与前面的InitializingBean不同的是，通过ApplicationListener监听的方式是全局性的，也就是当所有的Bean都初始化完成后才会执行方法。&lt;br/&gt;Spring 4.2 之后引入了新的 @EventListener注解，可以实现同样的效果：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;@Component
public class EventListenerExampleBean {
 
    private static final Logger LOG 
      = Logger.getLogger(EventListenerExampleBean.class);
 
    public static int counter;
 
    @EventListener
    public void onApplicationEvent(ContextRefreshedEvent event) {
        LOG.info(&quot;Increment counter&quot;);
        counter++;
    }
}&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;commandlinerunner&quot;&gt;6、 CommandLineRunner&lt;/h2&gt;
&lt;p&gt;SpringBoot 提供了一个CommanLineRunner接口，用来实现在应用启动后的逻辑控制，其定义如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;public interface CommandLineRunner {

    /**
     * Callback used to run the bean.
     * @param args incoming main method arguments
     * @throws Exception on error
     */
    void run(String... args) throws Exception;

}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;这里的run方法会在Spring 上下文初始化完成后执行，同时会传入应用的启动参数。&lt;br/&gt;如下面的代码：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;@Component
public class CommandLineAppStartupRunner implements CommandLineRunner {
    private static final Logger LOG =
      LoggerFactory.getLogger(CommandLineAppStartupRunner.class);
 
    public static int counter;
 
    @Override
    public void run(String...args) throws Exception {
        //上下文已初始化完成
        LOG.info(&quot;Increment counter&quot;);
        counter++;
    }
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;此外，对于多个CommandLineRunner的情况下可以使用@Order注解来控制它们的顺序。&lt;/p&gt;
&lt;h2 id=&quot;applicationrunner&quot;&gt;7、 ApplicationRunner&lt;/h2&gt;
&lt;p&gt;与 CommandLineRunner接口类似, Spring boot 还提供另一个ApplicationRunner 接口来实现初始化逻辑。&lt;br/&gt;不同的地方在于 ApplicationRunner.run()方法接受的是封装好的ApplicationArguments参数对象，而不是简单的字符串参数。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;@Component
public class AppStartupRunner implements ApplicationRunner {
    private static final Logger LOG =
      LoggerFactory.getLogger(AppStartupRunner.class);
 
    public static int counter;
 
    @Override
    public void run(ApplicationArguments args) throws Exception {
        LOG.info(&quot;Application started with option names : {}&quot;, 
          args.getOptionNames());
        LOG.info(&quot;Increment counter&quot;);
        counter++;
    }
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;ApplicationArguments对象提供了一些非常方便的方法，可以用来直接获取解析后的参数，比如：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;java -jar application.jar --debug --ip=xxxx&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;此时通过 ApplicationArguments的getOptionNames就会得到&lt;strong&gt;[&quot;debug&quot;,&quot;ip&quot;]&lt;/strong&gt;这样的值&lt;/p&gt;
&lt;h2 id=&quot;测试代码&quot;&gt;测试代码&lt;/h2&gt;
&lt;p&gt;下面，通过一个小测试来演示几种初始化方法的执行次序，按如下代码实现一个复合式的Bean：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;@Component
@Scope(value = &quot;prototype&quot;)
public class AllStrategiesExampleBean implements InitializingBean {
 
    private static final Logger LOG 
      = Logger.getLogger(AllStrategiesExampleBean.class);
 
    public AllStrategiesExampleBean() {
        LOG.info(&quot;Constructor&quot;);
    }
 
    @Override
    public void afterPropertiesSet() throws Exception {
        LOG.info(&quot;InitializingBean&quot;);
    }
 
    @PostConstruct
    public void postConstruct() {
        LOG.info(&quot;PostConstruct&quot;);
    }
 
    //在XML中定义为initMethod
    public void init() {
        LOG.info(&quot;init-method&quot;);
    }
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;执行这个Bean的初始化，会发现日志输出如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;[main] INFO o.b.startup.AllStrategiesExampleBean - Constructor
[main] INFO o.b.startup.AllStrategiesExampleBean - PostConstruct
[main] INFO o.b.startup.AllStrategiesExampleBean - InitializingBean
[main] INFO o.b.startup.AllStrategiesExampleBean - init-method&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;所以，这几种初始化的顺序为：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;构造器方法&lt;/li&gt;
&lt;li&gt;@PostConstruct 注解方法&lt;/li&gt;
&lt;li&gt;InitializingBean的afterPropertiesSet()&lt;/li&gt;
&lt;li&gt;Bean定义的initMethod属性方法&lt;/li&gt;
&lt;/ol&gt;&lt;h2 id=&quot;参考文档&quot;&gt;参考文档&lt;/h2&gt;
&lt;p&gt;https://www.baeldung.com/running-setup-logic-on-startup-in-spring&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.cnblogs.com/littleatp/p/10807130.html#springboot-%E8%A1%A5%E4%B9%A0%E7%B3%BB%E5%88%97&quot;&gt;美码师的 SpringBoot 补习系列&lt;/a&gt;&lt;/p&gt;
</description>
<pubDate>Tue, 02 Jul 2019 14:34:00 +0000</pubDate>
<dc:creator>美码师</dc:creator>
<og:description>[TOC] 背景 在日常开发时，我们常常需要 在SpringBoot 应用启动时执行某一段逻辑，如下面的场景： 获取一些当前环境的配置或变量 向数据库写入一些初始数据 连接某些第三方系统，确认对方可以</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/littleatp/p/11123577.html</dc:identifier>
</item>
<item>
<title>惊：FastThreadLocal吞吐量居然是ThreadLocal的3倍！！！ - 匠心零度</title>
<link>http://www.cnblogs.com/jiangxinlingdu/p/11123538.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/jiangxinlingdu/p/11123538.html</guid>
<description>&lt;h2 id=&quot;说明&quot;&gt;说明&lt;/h2&gt;
&lt;p&gt;接着上次&lt;a href=&quot;https://mp.weixin.qq.com/s/8Ql-5kaUtxiCWyHR6uPPBw&quot;&gt;手撕面试题ThreadLocal！！！&lt;/a&gt;面试官一听，哎呦不错哦！本文将继续上文的话题，来聊聊FastThreadLocal，&lt;strong&gt;目前关于FastThreadLocal的很多文章都有点老有点过时了（本文将澄清几个误区），很多文章关于FastThreadLocal介绍的也不全，希望本篇文章可以带你彻底理解FastThreadLocal！！！&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;FastThreadLocal是Netty提供的，在池化内存分配等都有涉及到！​&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;关于FastThreadLocal，零度准备从这几个方面进行讲解：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;FastThreadLocal的使用。&lt;/li&gt;
&lt;li&gt;FastThreadLocal并不是什么情况都快，你要用对才会快。&lt;/li&gt;
&lt;li&gt;FastThreadLocal利用字节填充来解决伪共享问题。&lt;/li&gt;
&lt;li&gt;FastThreadLocal比ThreadLocal快，并不是空间换时间。&lt;/li&gt;
&lt;li&gt;FastThreadLocal不在使用ObjectCleaner处理泄漏，必要的时候建议重写onRemoval方法。&lt;/li&gt;
&lt;li&gt;FastThreadLocal为什么快？&lt;/li&gt;
&lt;/ul&gt;&lt;h2 id=&quot;fastthreadlocal的使用&quot;&gt;FastThreadLocal的使用&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;FastThreadLocal用法上兼容ThreadLocal&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;FastThreadLocal使用示例代码：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;public class FastThreadLocalTest {
    private static FastThreadLocal&amp;lt;Integer&amp;gt; fastThreadLocal = new FastThreadLocal&amp;lt;&amp;gt;();

    public static void main(String[] args) {

        //if (thread instanceof FastThreadLocalThread) 使用FastThreadLocalThread更优，普通线程也可以
        new FastThreadLocalThread(() -&amp;gt; {
            for (int i = 0; i &amp;lt; 100; i++) {
                fastThreadLocal.set(i);
                System.out.println(Thread.currentThread().getName() + &quot;====&quot; + fastThreadLocal.get());
                try {
                    Thread.sleep(200);
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }
            }
        }, &quot;fastThreadLocal1&quot;).start();


        new FastThreadLocalThread(() -&amp;gt; {
            for (int i = 0; i &amp;lt; 100; i++) {
                System.out.println(Thread.currentThread().getName() + &quot;====&quot; + fastThreadLocal.get());
                try {
                    Thread.sleep(200);
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }
            }
        }, &quot;fastThreadLocal2&quot;).start();
    }
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;代码截图：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://www.jiangxinlingdu.com/assets/images/2019/2019070107512.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;代码运行结果：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://www.jiangxinlingdu.com/assets/images/2019/2019070160203.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;我们在回顾下之前的ThreadLocal的 &lt;strong&gt;最佳实践做法：&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;try {
    // 其它业务逻辑
} finally {
    threadLocal对象.remove();
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;img src=&quot;http://www.jiangxinlingdu.com/assets/images/2019/2019061910377.png&quot;/&gt;&lt;/p&gt;
&lt;blockquote readability=&quot;7&quot;&gt;
&lt;p&gt;&lt;strong&gt;备注：&lt;/strong&gt; 通过上面的例子，我们发现FastThreadLocal和ThreadLocal在用法上面基本差不多，没有什么特别区别，&lt;strong&gt;个人认为，这就是FastThreadLocal成功的地方，它就是要让用户用起来和ThreadLocal没啥区别，要兼容！&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;使用FastThreadLocal居然不用像ThreadLocal那样先try ………………… 之后finally进行threadLocal对象.remove();&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;由于构造FastThreadLocalThread的时候，通过FastThreadLocalRunnable对Runnable对象进行了包装：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;FastThreadLocalRunnable.wrap(target)从而构造了FastThreadLocalRunnable对象。&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;img src=&quot;http://www.jiangxinlingdu.com/assets/images/2019/2019070180856.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;FastThreadLocalRunnable在执行完之后都会调用FastThreadLocal.removeAll();&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://www.jiangxinlingdu.com/assets/images/2019/2019070108368.png&quot;/&gt;&lt;/p&gt;
&lt;blockquote readability=&quot;15&quot;&gt;
&lt;p&gt;&lt;strong&gt;备注：&lt;/strong&gt; FastThreadLocal不在使用ObjectCleaner处理泄漏，必要的时候建议重写onRemoval方法。关于这块将在本文后面进行介绍，这样是很多网上资料比较老的原因，这块已经去掉了。&lt;/p&gt;
&lt;p&gt;如果是普通线程，还是应该最佳实践：&lt;/p&gt;
&lt;p&gt;finally {&lt;br/&gt;fastThreadLocal对象.removeAll();&lt;br/&gt;}&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;注意：&lt;/strong&gt; 如果使用FastThreadLocal就不要使用普通线程，而应该构建FastThreadLocalThread，关于为什么这样，关于这块将在本文后面进行介绍：FastThreadLocal并不是什么情况都快，你要用对才会快。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;fastthreadlocal并不是什么情况都快你要用对才会快&quot;&gt;FastThreadLocal并不是什么情况都快，你要用对才会快&lt;/h2&gt;
&lt;p&gt;首先看看netty关于这块的测试用例：&lt;br/&gt;代码路径：&lt;a href=&quot;https://github.com/netty/netty/blob/4.1/microbench/src/main/java/io/netty/microbench/concurrent/FastThreadLocalFastPathBenchmark.java&quot; class=&quot;uri&quot;&gt;https://github.com/netty/netty/blob/4.1/microbench/src/main/java/io/netty/microbench/concurrent/FastThreadLocalFastPathBenchmark.java&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://www.jiangxinlingdu.com/assets/images/2019/2019061900601.png&quot;/&gt;&lt;/p&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;&lt;strong&gt;备注：&lt;/strong&gt; 在我本地进行测试，FastThreadLocal的吞吐量是jdkThreadLocal的3倍左右。机器不一样，可能效果也不一样，大家可以自己试试，反正就是快了不少。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;关于ThreadLocal，之前的这篇：&lt;a href=&quot;https://mp.weixin.qq.com/s/8Ql-5kaUtxiCWyHR6uPPBw&quot;&gt;手撕面试题ThreadLocal！！！&lt;/a&gt;已经详细介绍了。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;FastThreadLocal并不是什么情况都快，你要用对才会快！！！&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;注意：&lt;/strong&gt; 使用FastThreadLocalThread线程才会快，如果是普通线程还更慢！&lt;br/&gt;&lt;strong&gt;注意：&lt;/strong&gt; 使用FastThreadLocalThread线程才会快，如果是普通线程还更慢！&lt;br/&gt;&lt;strong&gt;注意：&lt;/strong&gt; 使用FastThreadLocalThread线程才会快，如果是普通线程还更慢！&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://www.jiangxinlingdu.com/assets/images/2019/2019070118578.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;netty的测试目录下面有2个类:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;FastThreadLocalFastPathBenchmark&lt;/li&gt;
&lt;li&gt;FastThreadLocalSlowPathBenchmark&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;路径：&lt;a href=&quot;https://github.com/netty/netty/blob/4.1/microbench/src/main/java/io/netty/microbench/concurrent/&quot; class=&quot;uri&quot;&gt;https://github.com/netty/netty/blob/4.1/microbench/src/main/java/io/netty/microbench/concurrent/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;FastThreadLocalFastPathBenchmark测试结果：&lt;/strong&gt; 是ThreadLocal的吞吐量的3倍左右。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://www.jiangxinlingdu.com/assets/images/2019/2019070115044.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;FastThreadLocalSlowPathBenchmark测试结果：&lt;/strong&gt; 比ThreadLocal的吞吐量还低。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://www.jiangxinlingdu.com/assets/images/2019/2019070112348.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;测试结论： 使用FastThreadLocalThread线程操作FastThreadLocal才会快，如果是普通线程还更慢！&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://www.jiangxinlingdu.com/assets/images/2019/2019070127951.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;注释里面给出了三点：&lt;/p&gt;
&lt;ul readability=&quot;2.5&quot;&gt;&lt;li readability=&quot;1&quot;&gt;
&lt;p&gt;FastThreadLocal操作元素的时候，使用常量下标在数组中进行定位元素来替代ThreadLocal通过哈希和哈希表，这个改动特别在频繁使用的时候，效果更加显著！&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;想要利用上面的特征，线程必须是FastThreadLocalThread或者其子类，默认DefaultThreadFactory都是使用FastThreadLocalThread的&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;1&quot;&gt;
&lt;p&gt;只用在FastThreadLocalThread或者子类的线程使用FastThreadLocal才会更快，因为FastThreadLocalThread 定义了属性threadLocalMap类型是InternalThreadLocalMap。如果普通线程会借助ThreadLocal。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;我们看看NioEventLoopGroup细节：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://www.jiangxinlingdu.com/assets/images/2019/2019070174431.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://www.jiangxinlingdu.com/assets/images/2019/2019070191285.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://www.jiangxinlingdu.com/assets/images/2019/2019070126620.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;看到这里，和刚刚我们看到的注释内容一致的，是使用FastThreadLocalThread的。&lt;/p&gt;
&lt;p&gt;netty里面使用FastThreadLocal的举例常用的：&lt;/p&gt;
&lt;p&gt;池化内存分配：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://www.jiangxinlingdu.com/assets/images/2019/2019070170556.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;会使用到Recycler&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://www.jiangxinlingdu.com/assets/images/2019/2019070184261.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;而Recycler也使用了FastThreadLocal&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://www.jiangxinlingdu.com/assets/images/2019/2019070153172.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;我们再看看看测试类：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://www.jiangxinlingdu.com/assets/images/2019/2019070127399.png&quot;/&gt;&lt;/p&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;&lt;strong&gt;备注：&lt;/strong&gt; 我们会发现FastThreadLocalFastPathBenchmark里面的线程是FastThreadLocal。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&quot;http://www.jiangxinlingdu.com/assets/images/2019/2019070107335.png&quot;/&gt;&lt;/p&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;&lt;strong&gt;备注：&lt;/strong&gt; 我们会发现FastThreadLocalSlowPathBenchmark里面的线程 &lt;strong&gt;不是FastThreadLocal&lt;/strong&gt;。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;FastThreadLocal只有被的线程是FastThreadLocalThread或者其子类使用的时候才会更快，吞吐量我这边测试的效果大概3倍左右，但是如果是普通线程操作FastThreadLocal其吞吐量比ThreadLocal还差！&lt;/strong&gt;&lt;/p&gt;
&lt;h2 id=&quot;fastthreadlocal利用字节填充来解决伪共享问题&quot;&gt;FastThreadLocal利用字节填充来解决伪共享问题&lt;/h2&gt;
&lt;p&gt;关于CPU 缓存 内容来源于美团：&lt;a href=&quot;https://tech.meituan.com/2016/11/18/disruptor.html&quot; class=&quot;uri&quot;&gt;https://tech.meituan.com/2016/11/18/disruptor.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;下图是计算的基本结构。L1、L2、L3分别表示一级缓存、二级缓存、三级缓存，越靠近CPU的缓存，速度越快，容量也越小。所以L1缓存很小但很快，并且紧靠着在使用它的CPU内核；L2大一些，也慢一些，并且仍然只能被一个单独的CPU核使用；L3更大、更慢，并且被单个插槽上的所有CPU核共享；最后是主存，由全部插槽上的所有CPU核共享。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://www.jiangxinlingdu.com/assets/images/2019/201907017c9d5.png&quot; alt=&quot;img&quot;/&gt;&lt;/p&gt;
&lt;p&gt;当CPU执行运算的时候，它先去L1查找所需的数据、再去L2、然后是L3，如果最后这些缓存中都没有，所需的数据就要去主内存拿。走得越远，运算耗费的时间就越长。所以如果你在做一些很频繁的事，你要尽量确保数据在L1缓存中。&lt;/p&gt;
&lt;p&gt;另外，线程之间共享一份数据的时候，需要一个线程把数据写回主存，而另一个线程访问主存中相应的数据。&lt;/p&gt;
&lt;p&gt;下面是从CPU访问不同层级数据的时间概念:&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://www.jiangxinlingdu.com/assets/images/2019/2019070187317.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;可见CPU读取主存中的数据会比从L1中读取慢了近2个数量级。&lt;/p&gt;
&lt;h3 id=&quot;缓存行&quot;&gt;缓存行&lt;/h3&gt;
&lt;p&gt;Cache是由很多个cache line组成的。每个cache line通常是64字节，并且它有效地引用主内存中的一块儿地址。一个Java的long类型变量是8字节，因此在一个缓存行中可以存8个long类型的变量。&lt;/p&gt;
&lt;p&gt;CPU每次从主存中拉取数据时，会把相邻的数据也存入同一个cache line。&lt;/p&gt;
&lt;p&gt;在访问一个long数组的时候，如果数组中的一个值被加载到缓存中，它会自动加载另外7个。因此你能非常快的遍历这个数组。事实上，你可以非常快速的遍历在连续内存块中分配的任意数据结构。&lt;/p&gt;
&lt;h3 id=&quot;伪共享&quot;&gt;伪共享&lt;/h3&gt;
&lt;p&gt;由于多个线程同时操作同一缓存行的不同变量，但是这些变量之间却没有啥关联，但是每次修改，都会导致缓存的数据变成无效，从而明明没有任何修改的内容，还是需要去主存中读（CPU读取主存中的数据会比从L1中读取慢了近2个数量级）但是其实这块内容并没有任何变化，由于缓存的最小单位是一个缓存行，这就是伪共享。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;如果让多线程频繁操作的并且没有关系的变量在不同的缓存行中&lt;/strong&gt;，那么就不会因为缓存行的问题导致没有关系的变量的修改去影响另外没有修改的变量去读主存了（那么从L1中取是从主存取快2个数量级的）那么性能就会好很多很多。&lt;/p&gt;
&lt;h3 id=&quot;有伪共享-和没有的情况的测试效果&quot;&gt;有伪共享 和没有的情况的测试效果&lt;/h3&gt;
&lt;p&gt;代码路径：&lt;a href=&quot;https://github.com/jiangxinlingdu/nettydemo&quot; class=&quot;uri&quot;&gt;https://github.com/jiangxinlingdu/nettydemo&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/jiangxinlingdu/nettydemo&quot;&gt;nettydemo&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://www.jiangxinlingdu.com/assets/images/2019/2019070126805.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://www.jiangxinlingdu.com/assets/images/2019/2019070104823.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;利用字节填充来解决伪共享，从而速度快了3倍左右。&lt;/p&gt;
&lt;h3 id=&quot;fastthreadlocal使用字节填充解决伪共享&quot;&gt;FastThreadLocal使用字节填充解决伪共享&lt;/h3&gt;
&lt;p&gt;之前介绍ThreadLocal的时候，说过ThreadLocal是用在多线程场景下，那么FastThreadLocal也是用在多线程场景，大家可以看下这篇：&lt;a href=&quot;https://mp.weixin.qq.com/s/8Ql-5kaUtxiCWyHR6uPPBw&quot;&gt;手撕面试题ThreadLocal！！！&lt;/a&gt;，所以FastThreadLocal需要解决伪共享问题，FastThreadLocal使用字节填充解决伪共享。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://www.jiangxinlingdu.com/assets/images/2019/2019070184865.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://www.jiangxinlingdu.com/assets/images/2019/2019070192422.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;这个是我自己手算的，通过手算太麻烦，推荐一个工具&lt;strong&gt;JOL&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://openjdk.java.net/projects/code-tools/jol/&quot; class=&quot;uri&quot;&gt;http://openjdk.java.net/projects/code-tools/jol/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://www.jiangxinlingdu.com/assets/images/2019/2019070135352.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;推荐IDEA插件：&lt;a href=&quot;https://plugins.jetbrains.com/plugin/10953-jol-java-object-layout&quot; class=&quot;uri&quot;&gt;https://plugins.jetbrains.com/plugin/10953-jol-java-object-layout&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://www.jiangxinlingdu.com/assets/images/2019/2019070165404.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;代码路径：&lt;a href=&quot;https://github.com/jiangxinlingdu/nettydemo&quot; class=&quot;uri&quot;&gt;https://github.com/jiangxinlingdu/nettydemo&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/jiangxinlingdu/nettydemo&quot;&gt;nettydemo&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://www.jiangxinlingdu.com/assets/images/2019/2019070150744.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;通过这个工具算起来就很容易了，如果以后有类似的需要看的，不用手一个一个算了。&lt;/p&gt;
&lt;h3 id=&quot;fastthreadlocal被fastthreadlocalthread进行读写的时候也可能利用到缓存行&quot;&gt;FastThreadLocal被FastThreadLocalThread进行读写的时候也可能利用到缓存行&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;http://www.jiangxinlingdu.com/assets/images/2019/2019070156965.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;并且由于当线程是FastThreadLocalThread的时候操作FastThreadLocal是通过indexedVariables数组进行存储数据的的，每个FastThreadLocal有一个常量下标，通过下标直接定位数组进行读写操作，当有很多FastThreadLocal的时候，也可以利用缓存行，比如一次indexedVariables数组第3个位置数据，由于缓存的最小单位是缓存行，顺便把后面的4、5、6等也缓存了，下次刚刚好另外FastThreadLocal下标就是5的时候，进行读取的时候就直接走缓存了，比走主存可能快2个数量级。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://www.jiangxinlingdu.com/assets/images/2019/2019070126136.png&quot;/&gt;&lt;/p&gt;
&lt;h3 id=&quot;一点疑惑&quot;&gt;一点疑惑&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;问题：&lt;/strong&gt;为什么这里填充了9个long值呢？？？&lt;/p&gt;
&lt;p&gt;我提了一个issue：&lt;a href=&quot;https://github.com/netty/netty/issues/9284&quot; class=&quot;uri&quot;&gt;https://github.com/netty/netty/issues/9284&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://www.jiangxinlingdu.com/assets/images/2019/2019070156671.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;虽然也有人回答，但是感觉不是自己想要的，说服不了自己！！！&lt;br/&gt;&lt;img src=&quot;http://www.jiangxinlingdu.com/assets/images/2019/2019070177173.png&quot;/&gt;&lt;/p&gt;
&lt;h2 id=&quot;fastthreadlocal比threadlocal快并不是空间换时间&quot;&gt;FastThreadLocal比ThreadLocal快，并不是空间换时间&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;http://www.jiangxinlingdu.com/assets/images/2019/2019070184541.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://www.jiangxinlingdu.com/assets/images/2019/2019070131474.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;现在清理已经去掉，本文下面会介绍，所以FastThreadLocal比ThreadLocal快，并不是空间换时间，FastThreadLocal并没有浪费空间！！！&lt;/p&gt;
&lt;h2 id=&quot;fastthreadlocal不在使用objectcleaner处理泄漏必要的时候建议重写onremoval方法&quot;&gt;FastThreadLocal不在使用ObjectCleaner处理泄漏，必要的时候建议重写onRemoval方法&lt;/h2&gt;
&lt;p&gt;最新的netty版本中已经不在使用ObjectCleaner处理泄漏：&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/netty/netty/commit/9b1a59df383559bc568b891d73c7cb040019aca6#diff-e0eb4e9a6ea15564e4ddd076c55978de&quot; class=&quot;uri&quot;&gt;https://github.com/netty/netty/commit/9b1a59df383559bc568b891d73c7cb040019aca6#diff-e0eb4e9a6ea15564e4ddd076c55978de&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/netty/netty/commit/5b1fe611a637c362a60b391079fff73b1a4ef912#diff-e0eb4e9a6ea15564e4ddd076c55978de&quot; class=&quot;uri&quot;&gt;https://github.com/netty/netty/commit/5b1fe611a637c362a60b391079fff73b1a4ef912#diff-e0eb4e9a6ea15564e4ddd076c55978de&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://www.jiangxinlingdu.com/assets/images/2019/2019070174864.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://www.jiangxinlingdu.com/assets/images/2019/2019070186403.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://www.jiangxinlingdu.com/assets/images/2019/2019070141424.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;去掉原因：&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/netty/netty/issues/8017&quot; class=&quot;uri&quot;&gt;https://github.com/netty/netty/issues/8017&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://www.jiangxinlingdu.com/assets/images/2019/2019070126579.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;我们看看FastThreadLocal的onRemoval&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://www.jiangxinlingdu.com/assets/images/2019/2019070132279.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;如果使用的是FastThreadLocalThread能保证调用的，重写onRemoval做一些收尾状态修改等等&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://www.jiangxinlingdu.com/assets/images/2019/2019070182126.png&quot;/&gt;&lt;br/&gt;&lt;img src=&quot;http://www.jiangxinlingdu.com/assets/images/2019/2019070107793.png&quot;/&gt;&lt;/p&gt;
&lt;h2 id=&quot;fastthreadlocal为什么快&quot;&gt;FastThreadLocal为什么快？&lt;/h2&gt;
&lt;p&gt;FastThreadLocal操作元素的时候，使用常量下标在数组中进行定位元素来替代ThreadLocal通过哈希和哈希表，这个改动特别在频繁使用的时候，效果更加显著！计算该ThreadLocal需要存储的位置是通过hash算法确定位置：&lt;br/&gt;int i = key.threadLocalHashCode &amp;amp; (len-1);而FastThreadLocal就是一个常量下标index，这个如果执行次数很多也是有影响的。&lt;/p&gt;
&lt;p&gt;并且FastThreadLocal利用缓存行的特性，FastThreadLocal是通过indexedVariables数组进行存储数据的，如果有多个FastThreadLocal的时候，也可以利用缓存行，比如一次indexedVariables数组第3个位置数据，由于缓存的最小单位是缓存行，顺便把后面的4、5、6等也缓存了，下次刚刚好改线程需要读取另外的FastThreadLocal，这个FastThreadLocal的下标就是5的时候，进行读取的时候就直接走缓存了，比走主存可能快2个数量级而ThreadLocal通过hash是分散的。&lt;/p&gt;
&lt;hr/&gt;&lt;p&gt;&lt;strong&gt;如果读完觉得有收获的话，欢迎点赞、关注、加公众号 [匠心零度] ，查阅更多精彩历史！！！&lt;/strong&gt;&lt;br/&gt;&lt;img src=&quot;http://www.jiangxinlingdu.com/assets/images/lingdu.gif&quot;/&gt;&lt;/p&gt;
</description>
<pubDate>Tue, 02 Jul 2019 14:26:00 +0000</pubDate>
<dc:creator>匠心零度</dc:creator>
<og:description>说明 接着上次 '手撕面试题ThreadLocal！！！' 面试官一听，哎呦不错哦！本文将继续上文的话题，来聊聊FastThreadLocal， 目前关于FastThreadLocal的很多文章都有点</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/jiangxinlingdu/p/11123538.html</dc:identifier>
</item>
<item>
<title>精通并发与 Netty （一）如何使用 - 当年明月123</title>
<link>http://www.cnblogs.com/paulwang92115/p/11123519.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/paulwang92115/p/11123519.html</guid>
<description>&lt;h3 id=&quot;精通并发与-netty&quot;&gt;精通并发与 Netty&lt;/h3&gt;
&lt;p&gt;Netty 是一个异步的，事件驱动的网络通信框架，用于高性能的基于协议的客户端和服务端的开发。&lt;/p&gt;
&lt;p&gt;异步指的是会立即返回，并不知道到底发送过去没有，成功没有，一般都会使用监听器来监听返回。&lt;/p&gt;
&lt;p&gt;事件驱动是指开发者只需要关注事件对应的回调方法即可，比如 channel active，inactive，read 等等。&lt;/p&gt;
&lt;p&gt;网络通信框架就不用解释了，很多你非常熟悉的组件都使用了 netty，比如 spark，dubbo 等等。&lt;/p&gt;
&lt;h3 id=&quot;初步了解-netty&quot;&gt;初步了解 Netty&lt;/h3&gt;
&lt;p&gt;第一个简单的例子，使用 Netty 实现一个 http 服务器，客户端调用一个没有参数的方法，服务端返回一个 hello world。&lt;/p&gt;
&lt;p&gt;Netty 里面大量的代码都是对线程的处理和 IO 的异步的操作。&lt;/p&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;package com.paul;

import io.netty.bootstrap.ServerBootstrap;
import io.netty.channel.ChannelFuture;
import io.netty.channel.EventLoopGroup;
import io.netty.channel.nio.NioEventLoopGroup;
import io.netty.channel.socket.nio.NioSocketChannel;

public class Server {

    public static void main(String[] args) throws InterruptedException {
        //定义两个线程组，事件循环组,可以类比与 Tomcat 就是死循环，不断接收客户端的连接
        // boss 线程组不断从客户端接受连接，但不处理，由 worker 线程组对连接进行真正的处理
        // 一个线程组其实也能完成，推荐使用两个
        EventLoopGroup bossGroup = new NioEventLoopGroup();
        EventLoopGroup workerGroup = new NioEventLoopGroup();
        try {
            // 服务端启动器，可以轻松的启动服务端的 channel
            ServerBootstrap serverBootstrap = new ServerBootstrap();
            //group 方法有两个，一个接收一个参数，另一个接收两个参数
            // childhandler 是我们自己写的请求处理器
            serverBootstrap.group(bossGroup, workerGroup).channel(NioSocketChannel.class)
                    .childHandler(new ServerInitializer());
            //绑定端口
            ChannelFuture future = serverBootstrap.bind(8011).sync();
            //channel 关闭的监听
            future.channel().closeFuture().sync();
        }finally {
            bossGroup.shutdownGracefully();
            workerGroup.shutdownGracefully();
        }

    }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;package com.paul;

import io.netty.channel.ChannelInitializer;
import io.netty.channel.ChannelPipeline;
import io.netty.channel.socket.SocketChannel;
import io.netty.handler.codec.http.HttpServerCodec;

public class ServerInitializer extends ChannelInitializer&amp;lt;SocketChannel&amp;gt; {
    @Override
    protected void initChannel(SocketChannel socketChannel) throws Exception {
        //管道，管道里面可以有很多 handler，一层层过滤的柑橘
        ChannelPipeline pipeline = socketChannel.pipeline();
        //HttpServerCodec 是 HttpRequestDecoder 和 HttpReponseEncoder 的组合，编码和解码的 h      handler
        pipeline.addLast(&quot;httpServerCodec&quot;, new HttpServerCodec());
        pipeline.addLast(&quot;handler&quot;, new ServerHandler());
    }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;package com.paul;

import io.netty.buffer.ByteBuf;
import io.netty.buffer.Unpooled;
import io.netty.channel.ChannelHandlerContext;
import io.netty.channel.SimpleChannelInboundHandler;
import io.netty.handler.codec.http.*;
import io.netty.util.CharsetUtil;

public class ServerHandler extends SimpleChannelInboundHandler&amp;lt;HttpObject&amp;gt; {
    @Override
    protected void channelRead0(ChannelHandlerContext channelHandlerContext, HttpObject httpObject) throws Exception {
        if(httpObject instanceof HttpRequest) {
            ByteBuf content = Unpooled.copiedBuffer(&quot;hello world&quot;, CharsetUtil.UTF_8);
            FullHttpResponse response = new DefaultFullHttpResponse(HttpVersion.HTTP_1_1, HttpResponseStatus.OK, content);
            response.headers().set(HttpHeaderNames.CONTENT_TYPE, &quot;text/plain&quot;);
            response.headers().set(HttpHeaderNames.CONTENT_LENGTH, content.readableBytes());
            //单纯的调用 write 只会放到缓存区，不会真的发送
            channelHandlerContext.writeAndFlush(response);
        }
    }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;我们在 SimpleChannelInboundHandler 里分析一下，先看它继承的 ChannelInboundHandlerAdapter 里面的事件回调方法，包括通道注册，解除注册，Active，InActive等等。&lt;/p&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;public void channelRegistered(ChannelHandlerContext ctx) throws Exception {
  ctx.fireChannelRegistered();
}

public void channelUnregistered(ChannelHandlerContext ctx) throws Exception {
  ctx.fireChannelUnregistered();
}

public void channelActive(ChannelHandlerContext ctx) throws Exception {
  ctx.fireChannelActive();
}

public void channelInactive(ChannelHandlerContext ctx) throws Exception {
  ctx.fireChannelInactive();
}

public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception {
  ctx.fireChannelRead(msg);
}

public void channelReadComplete(ChannelHandlerContext ctx) throws Exception {
  ctx.fireChannelReadComplete();
}

public void userEventTriggered(ChannelHandlerContext ctx, Object evt) throws Exception {
  ctx.fireUserEventTriggered(evt);
}

public void channelWritabilityChanged(ChannelHandlerContext ctx) throws Exception {
  ctx.fireChannelWritabilityChanged();
}

public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception {
  ctx.fireExceptionCaught(cause);
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;执行顺序为 handler added-&amp;gt;channel registered-&amp;gt;channel active-&amp;gt;channelRead0-&amp;gt;channel inactive-&amp;gt;channel unregistered。&lt;/p&gt;
&lt;p&gt;Netty 本身并不是遵循 servlet 规范的。Http 是基于请求和响应的无状态协议。Http 1.1 是有 keep-alived 参数的，如果3秒没有返回，则服务端主动关闭了解，Http 1.0 则是请求完成直接返回。&lt;/p&gt;
&lt;p&gt;Netty 的连接会被一直保持，我们需要自己去处理这个功能。&lt;/p&gt;
&lt;p&gt;在服务端发送完毕数据后，可以在服务端关闭 Channel。&lt;/p&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;ctx.channel.close();&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;netty-能做什么&quot;&gt;Netty 能做什么&lt;/h3&gt;
&lt;ol&gt;&lt;li&gt;可以当作一个 http 服务器，但是他并没有实现 servelt 规范。虽然 Tomcat 底层本身也使用 NIO，但是 Netty 本身的特点决定了它比 Tomcat 的吞吐量更高。相比于 SpringMVC 等框架，Netty 没提供路由等功能，这也契合和 Netty 的设计思路，它更贴近底层。&lt;/li&gt;
&lt;li&gt;Socket 开发，也是应用最为广泛的领域，底层传输的最基础框架，RPC 框架底层多数采用 Netty。直接采用 Http 当然也可以，但是效率就低了很多了。&lt;/li&gt;
&lt;li&gt;支持长连接的开发，消息推送，聊天，服务端向客户端推送等等都会采用 WebSocket 协议，就是长连接。&lt;/li&gt;
&lt;/ol&gt;&lt;h3 id=&quot;netty-对-socket-的实现&quot;&gt;Netty 对 Socket 的实现&lt;/h3&gt;
&lt;p&gt;对于 Http 编程来说，我们实现了服务端就可以了，客户端完全可以使用浏览器或者 CURL 工具来充当。但是对于 Socket 编程来说，客户端也得我们自己实现。&lt;/p&gt;
&lt;p&gt;服务器端：&lt;/p&gt;
&lt;p&gt;Server 类于上面 Http 服务器那个一样，在 ServerInitoalizer 有一些变化&lt;/p&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;public class ServerInitializer extends ChannelInitializer&amp;lt;SocketChannel&amp;gt; {
    @Override
    protected void initChannel(SocketChannel socketChannel) throws Exception {
        //管道，管道里面可以有很多 handler，一层层过滤的柑橘
        ChannelPipeline pipeline = socketChannel.pipeline();
        // TCP 粘包 拆包
        pipeline.addLast(new LengthFieldBasedFrameDecoder(Integer.MAX_VALUE,0,4,0,4));
        pipeline.addLast(new LengthFieldPrepender(4));
        // 字符串编码，解码
        pipeline.addLast(new StringDecoder(CharsetUtil.UTF_8));
        pipeline.addLast(new StringEncoder(CharsetUtil.UTF_8));
        pipeline.addLast(new ServerHandler());

    }
}&lt;/code&gt;
&lt;/pre&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;public class ServerHandler extends SimpleChannelInboundHandler&amp;lt;String&amp;gt; {
    @Override
    protected void channelRead0(ChannelHandlerContext ctx, String msg) throws Exception {
        System.out.println(ctx.channel().remoteAddress()+&quot;,&quot;+msg);
        ctx.channel().writeAndFlush(&quot;from server:&quot; + UUID.randomUUID());

    }

    @Override
    public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception {
        cause.printStackTrace();
        ctx.close();
    }
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;客户端：&lt;/p&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;public class Client {

    public static void main(String[] args) throws InterruptedException {
        //客户端不需要两个 group，只需要一个就够了，直接连接服务端发送数据就可以了
        EventLoopGroup eventLoopGroup = new NioEventLoopGroup();
        try{
            Bootstrap bootstrap = new Bootstrap();
            //服务器端既可以使用 handler 也可以使用 childhandler， 客户端一般使用 handler
            //对于 服务端，handler 是针对 bossgroup的，childhandler 是针对 workergorup 的
            bootstrap.group(eventLoopGroup).channel(NioSocketChannel.class)
                    .handler(new ClientInitializer());

            ChannelFuture channelFuture = bootstrap.connect(&quot;localhost&quot;,8899).sync();
            channelFuture.channel().closeFuture().sync();

        }finally {
            eventLoopGroup.shutdownGracefully();
        }
    }
}&lt;/code&gt;
&lt;/pre&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;public class ClientInitializer extends ChannelInitializer&amp;lt;SocketChannel&amp;gt; {
    @Override
    protected void initChannel(SocketChannel socketChannel) throws Exception {
        //管道，管道里面可以有很多 handler，一层层过滤的柑橘
        ChannelPipeline pipeline = socketChannel.pipeline();
        // TCP 粘包 拆包
        pipeline.addLast(new LengthFieldBasedFrameDecoder(Integer.MAX_VALUE,0,4,0,4));
        pipeline.addLast(new LengthFieldPrepender(4));
        // 字符串编码，解码
        pipeline.addLast(new StringDecoder(CharsetUtil.UTF_8));
        pipeline.addLast(new StringEncoder(CharsetUtil.UTF_8));
        pipeline.addLast(new ClientHandler());

    }
}&lt;/code&gt;
&lt;/pre&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;public class ClientHandler extends SimpleChannelInboundHandler&amp;lt;String&amp;gt; {
    @Override
    protected void channelRead0(ChannelHandlerContext ctx, String msg) throws Exception {
        System.out.println(ctx.channel().remoteAddress()+&quot;,&quot;+msg);
        System.out.println(&quot;client output:&quot;+ msg);

    }

    @Override
    public void channelActive(ChannelHandlerContext ctx) throws Exception {
        ctx.channel().writeAndFlush(&quot;23123&quot;);
    }

    @Override
    public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception {
        cause.printStackTrace();
        ctx.close();
    }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;netty-长连接实现一个聊天室&quot;&gt;Netty 长连接实现一个聊天室&lt;/h3&gt;
&lt;p&gt;Server 端：&lt;/p&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;public class ServerHandler extends SimpleChannelInboundHandler&amp;lt;String&amp;gt; {

    //定义 channel group 来管理所有 channel
    private static ChannelGroup channelGroup = new DefaultChannelGroup(GlobalEventExecutor.INSTANCE);

    @Override
    protected void channelRead0(ChannelHandlerContext ctx, String msg) throws Exception {


    }

    @Override
    public void handlerAdded(ChannelHandlerContext ctx) throws Exception {
        Channel channel = ctx.channel();
        channelGroup.writeAndFlush(&quot;[服务器]-&quot; + channel.remoteAddress() + &quot;加入\n&quot;);
        channelGroup.add(channel);
    }

    @Override
    public void handlerRemoved(ChannelHandlerContext ctx) throws Exception {
        Channel channel = ctx.channel();
        channelGroup.writeAndFlush(&quot;[服务器]-&quot; + channel.remoteAddress() + &quot;离开\n&quot;);
        //这个 channel 会被自动从 channelGroup 里移除

    }

    @Override
    public void channelActive(ChannelHandlerContext ctx) throws Exception {
        Channel channel = ctx.channel();
        System.out.println(channel.remoteAddress() + &quot;上线&quot;);

    }

    @Override
    public void channelInactive(ChannelHandlerContext ctx) throws Exception {
        Channel channel = ctx.channel();
        System.out.println(channel.remoteAddress() + &quot;离开&quot;);
    }

    @Override
    public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception {
        cause.printStackTrace();
        ctx.close();
    }
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;Client 端：&lt;/p&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;BufferedReader br = new BufferedReader(new InputStreamReader(System.in));
for(;;){
  channel.writeAndFlush(br.readLine() + &quot;\r\n&quot;);
}&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;netty-心跳&quot;&gt;Netty 心跳&lt;/h3&gt;
&lt;p&gt;集群之间各个节点的通信，主从节点之间需要进行数据同步，每当主节点的数据发生变化时，通过异步的方式将数据同步到从节点，同步方式可以用日志等等，因此主从节点之间不是实时一致性而是最终一致性。&lt;/p&gt;
&lt;p&gt;节点与节点之间如何进行通信那？这种主从模式是需要互相之间有长连接的，这样来确定对方还活着，实现方式是互相之间定时发送心跳数据包。如果发送几次后对方还是没有响应的话，就可以认为对方已经挂掉了。&lt;/p&gt;
&lt;p&gt;回到客户端与服务端的模式，有人可能会想，客户端断开连接后服务端的 handlerRemoved 等方法不是能感知吗？还要心跳干什么哪？&lt;/p&gt;
&lt;p&gt;真实情况其实非常复杂，比如手机客户端和服务端进行一个长连接，客户端没有退出应用，客户端开了飞行模型，或者强制关机，此时双方是感知不到连接已经断掉了，或者说需要非常长的时间才能感知到，这是我们不想看到的，这时就需要心跳了。&lt;/p&gt;
&lt;p&gt;来看一个示例：&lt;/p&gt;
&lt;p&gt;其他的代码还是和上面的一样，我们就不列出来了，直接进入主题，看不同的地方：&lt;/p&gt;
&lt;p&gt;服务端&lt;/p&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;       // Netty 为了支持心跳的 IdleStateHandler,空闲状态监测处理器。
     pipeline.addLast(new IdleStateHandler(5，7，10，TimeUnit.SECONDS));&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;来看看 IdleStateHandler 的说明&lt;/p&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;/*
 * Triggers an IdleStateEvent when a Channel has not performed read, write, or both    
 * operation for a while
 * 当一个 channel 一断时间没有进行 read，write 就触发一个 IdleStateEvent
 */
public IdleStateHandler(int readerIdleTimeSeconds, int writerIdleTimeSeconds, int allIdleTimeSeconds) {
  this((long)readerIdleTimeSeconds, (long)writerIdleTimeSeconds, (long)allIdleTimeSeconds, TimeUnit.SECONDS);
  //三个参数分别为多长时间没进行读，写或者读写操作则触发 event。
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;触发 event 后我们编写这个 event 对应的处理器。&lt;/p&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;public class MyHandler extends ChannelInboundHandlerAdapter{
  //触发某个事件后这个方法就会被调用
  //一个 channelhandlerContext 上下文对象，另一个是事件
  @Override
  public void userEventTriggered(ChannelHandlerContext ctx, Object evt) throws Exception{
        if(evt instanceof IdleStateEvent){
        IdleStateEvent event = (IdleStateEvent)evt;
        String eventType = null;
        switch(event.state()){
          case READER_IDLE:
            eventType = &quot;读空闲&quot;;
          case WRITER_IDLE:
            eventType = &quot;写空闲&quot;;
          case ALL_IDLE:
            eventType = &quot;读写空闲&quot;;
        }
      }else{
        //继续将事件向下一个 handler 传递
        ctx.
      }
  }
}&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;websocket-实现与原理分析&quot;&gt;WebSocket 实现与原理分析&lt;/h3&gt;
&lt;p&gt;WebSocket 是一种规范，是 HTML5 规范的一部分，主要是解决 Http 协议本身存在的问题。可以实现浏览器和服务端的长连接，连接头信息只在建立连接时发送一次。是在 Http 协议之上构建的，比如请求连接其实是一个 Http 请求，只不过里面加了一些 WebSocket 信息。也可以用在非浏览器场合，比如 app 上。&lt;/p&gt;
&lt;p&gt;Http 是一种无状态的基于请求和响应的协议，意思是一定是客户端想服务端发送一个请求，服务端给客户端一个响应。Http 1.0 在服务端给客户端响应后连接就断了。Http 1.1 增加可 keep-alive，服务端可以和客户端在短时间之内保持一个连接，某个事件之内服务端和客户端可以复用这个链接。在这种情况下，网页聊天就是实现不了的，服务端的数据推送是无法实现的。&lt;/p&gt;
&lt;p&gt;以前有一些假的长连接技术，比如轮询，缺点和明显，这里就不细说了。&lt;/p&gt;
&lt;p&gt;Http 2.0 实现了长连接，但是这不在我们讨论范围之内。&lt;/p&gt;
&lt;p&gt;针对服务端，Tomcat 新版本，Spring，和 Netty 都实现了对 Websocket 的支持。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;使用 Netty 对 WebSocket 的支持来实现长连接&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;其他的部分还是一样的，先来看服务端的 WebSocketChannelInitializer。&lt;/p&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;public class WebSocketChannelInitializer extends ChannelInitializer&amp;lt;SocketChannel&amp;gt;{
   //需要支持 websocket，我们在 initChannel 是做一点改动
   @Override
   protected void initChannel(SocketChannel ch) throws Exception{
      ChannelPipeline pipeline = ch.pipeline();
      //因为 websocket 是基于 http 的，所以要加入 http 相应的编解码器
      pipeline.addLast(new HttpServerCodec());
      //以块的方式进行写的处理器
      pipeline.addLast(new ChunkedWriteHandler());
      // 进行 http 聚合的处理器，将 HttpMessage 和 HttpContent 聚合到 FullHttpRequest 或者 
      // FullHttpResponse
      //HttpObjectAggregator 在基于 netty 的 http 编程使用的非常多，粘包拆包。
      pipeline.addLast(new HttpObjectAggregator(8192));
      // 针对 websocket 的类,完成 websocket 构建的所有繁重工作，负责握手，以及心跳（close，ping， 
      // pong）的处理， websocket 通过 frame 帧来传递数据。
      // BinaryWebSocketFrame，CloseWebSocketFrame，ContinuationWebSocketFrame，
      // PingWebSocketFrame，PongWebSocketFrame，TextWebSocketFrame。
      // /ws 是 context_path，websocket 协议标准，ws://server:port/context_path
      pipeline.addLast(new WebSocketServerProcotolHandler(&quot;/ws&quot;));
      pipeline.addLast(new TextWebSocketFrameHandler());
   }
}&lt;/code&gt;
&lt;/pre&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;// websocket 协议需要用帧来传递参数
public class TextWebSocketFrameHandler extends SimpleChannelInboundHandler&amp;lt;TextWebSocketFrame&amp;gt;{
   @Override
   protected void channelRead0(ChannelHandlerContext ctx, TextWebSocketFrame msg) throws Exception{
     System.out.println(&quot;收到消息：&quot;+ msg.text());
     ctx.channel().writeAndFlush(new TextWebSocketFrame(&quot;服务器返回&quot;));
   }
   
   @Override
   public void handlerAdded(ChannelHandlerContext ctx) throws Exception{
     System.out.println(&quot;handlerAdded&quot; + ctx.channel().id.asLongText());
   }
  
   @Override
   public void handlerRemoved(ChannelHandlerContext ctx) throws Exception{
     System.out.println(&quot;handlerRemoved&quot; + ctx.channel().id.asLongText());
   }
  
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;客户端我们直接通过浏览器的原声 JS 来写&lt;/p&gt;
&lt;pre class=&quot;js&quot;&gt;
&lt;code&gt;&amp;lt;script type=&quot;text/javascript&quot;&amp;gt;
   var socket;
   if(window.WebSocket){
     socket = new WebSocket(&quot;ws://localhost:8899/ws&quot;);
     socket.onmessage = function(event){
       alert(event.data);
     }
     socket.onopen = function(event){
       alert(&quot;连接开启&quot;)；
     }
     socket.onclose = function(event){
       alert(&quot;连接关闭&quot;)；
     }
   }else{
     alert(&quot;浏览器不支持 WebSocket&quot;)；
   }

   function send(message){
     if(!window.WebSocket){
       return;
     }
     if(socket.readyState == WebSocket.OPEN){
       socket.send(message);
     }
   }
&amp;lt;/script&amp;gt;  &lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;我们在浏览器中通过 F12 看看 Http 协议升级为 WebSocket 协议的过程。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1712167/201907/1712167-20190702222040021-1233467456.png&quot;/&gt;&lt;/p&gt;
</description>
<pubDate>Tue, 02 Jul 2019 14:21:00 +0000</pubDate>
<dc:creator>当年明月123</dc:creator>
<og:description>精通并发与 Netty Netty 是一个异步的，事件驱动的网络通信框架，用于高性能的基于协议的客户端和服务端的开发。 异步指的是会立即返回，并不知道到底发送过去没有，成功没有，一般都会使用监听器来监</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/paulwang92115/p/11123519.html</dc:identifier>
</item>
<item>
<title>用一个宏实现求两个数中的最大数 - micro虾米</title>
<link>http://www.cnblogs.com/microxiami/p/11116903.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/microxiami/p/11116903.html</guid>
<description>&lt;h3 id=&quot;最常见的实现方法&quot;&gt;最常见的实现方法&lt;/h3&gt;
&lt;p&gt;  在面试或者笔试中，经常会碰到“用一个宏实现求两个数中的最大数”这个题目，大家看到这个问题，觉得很容易实现，认为这有什么难度呢，随手就是一个：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;#define MAX(x, y) \
        ((x) &amp;gt; (y) ? (x) : (y))&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;注：用括号将宏定义整个括起来，在任何时候，都是一个好习惯。&lt;br/&gt;  如果能写出上边这个宏，你这道题的考试就能交差了，然后觉得对自己来说就是随手一写的事儿，那可就大错特错了。因为以上写法的宏定义，虽然也能拿到分数，但是在面试者或者笔试阅卷者看来，你也不过如此，你也只是茫茫人海中平凡的一员。那么对于这道平淡无奇的题目来说，如何给考官一个眼前一亮，豁然开朗的印象，可以尝试下使用下边几种方法来实现。&lt;/p&gt;
&lt;p&gt;  上边那个宏定义，一般情况下，是可以满足需求的，但是对于一些参数具有副作用的情况，就很容易出现意想不到的结果了。比如：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;int a = 1;
int b = 10;
int max = MAX(a++, b++);
// 宏定义展开：
((a++) &amp;gt; (b++) ? (a++) : (b++));&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;  以上例子，结果会根据编译器的差异，产生一些意外的结果，这些绝对不会是程序开发者想要的结果，自己可以思考下...&lt;/p&gt;
&lt;h3 id=&quot;防止参数副作用的实现方法&quot;&gt;防止参数副作用的实现方法&lt;/h3&gt;
&lt;p&gt;  为了防止宏定义的两个参数存在副作用的情况，可以将传递给宏定义的参数，在对比之前，保留一份备份，用备份参数来进行对比，总不会错了吧，并且这样实现，参数的副作用仅计算一次，不会影响对比的结果，实现方式如下MAX_2：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;#define MAX_2(x, y) ({\
        int _x = (x); \
        int _y = (y); \
        _x &amp;gt; _y ? _x : _y; \
})&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;  然而，很快就发现，以上MAX_2宏定义，仅仅是用在对比两个int型参数时，实际情况可能对比的是unsigned char，或者其他的类型，那么这个宏定义也不能很好地实现预期效果。&lt;/p&gt;
&lt;h3 id=&quot;指定参数类型的实现方法&quot;&gt;指定参数类型的实现方法&lt;/h3&gt;
&lt;p&gt;  继续改进，将要对比的参数类型以一个参数的形式传递给宏定义，比如下面MAX_3：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;#define MAX_3(type, x, y) ({\
        type _x = (x); \
        type _y = (y); \
        _x &amp;gt; _y ? _x : _y; \
})&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;  这样，宏定义要对比的两个参数的参数类型，以参数的形式传递给宏定义，在宏定义中，type参数，将是宏定义中传递的那个参数类型，使用方法如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;unsigned char c = 'A';
unsigned char d = 'B'

MAX_3(unsigned char, c, d);&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;  MAX_3宏定义，很好地实现了对于不同类型的两个参数求最大值的功能，但是先不要太高兴，因为MAX_3还是存在些缺点的，比如，对于一些粗心大意，导致传递的两个参数，存在和第一个参数类型不一致的情况，如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;int a = 100;
unsigned char c = 'H';

MAX_3(unsigned char, a, c);&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;  以上情况，可能只是手误，但是这个意外确实存在了，而MAX_3宏定义也确实会正常执行，但是结果可能就不是实现者的本意，而在代码中也很难被查出来，大家应该都有花费大量时间查Bug，最后发现是一个小符号错误的情况，太无奈，不再多说...&lt;/p&gt;
&lt;h3 id=&quot;相对最安全的实现方法&quot;&gt;相对最安全的实现方法&lt;/h3&gt;
&lt;p&gt;  以上情况，也是有方法的，比如下面这个MAX_4宏定义：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;#define MAX_4(x, y) ({\
        typeof(x) _x = (x); \
        typeof(y) _y = (y); \
        (void)(&amp;amp;_x == &amp;amp;_y); \
        _x &amp;gt; _y ? _x : _y; \
})&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;  MAX_4宏定义，通过typeof关键字，来获取参数的类型，并保存参数的一份拷贝，防止参数副作用影响对比结果，再通过(void)(&amp;amp;_x == &amp;amp;_y);来对比两个参数类型，如果不是同一种类型，在编译阶段就会报出warning，引起开发者注意，提前消灭隐患。&lt;/p&gt;
&lt;h3 id=&quot;总结&quot;&gt;总结&lt;/h3&gt;
&lt;p&gt;  经过以上几种写法的对比，会发现最后一种MAX_4宏定义的使用还是很安全的。如果应试者能够在笔试中很快地写出MAX_4宏定义的实现方式，我相信绝对会给考官们眼前一亮，甚至是惊艳的效果。&lt;br/&gt;  如果以上四种方式都达不到你需要的效果，那么我也没办法了，因为MAX_4宏定义可以说是我的认知范围内，最安全的实现“宏定义求两个数中的最大值”的方法了。随时欢迎朋友们分享更好的实现方法来学习。&lt;/p&gt;
</description>
<pubDate>Tue, 02 Jul 2019 13:54:00 +0000</pubDate>
<dc:creator>micro虾米</dc:creator>
<og:description>在面试或者笔试中，经常会碰到“用一个宏实现求两个数中的最大数”这个题目，大家看到这个问题，觉得很容易实现，认为这有什么难度呢，随手就能写出一个，但是这写出来的宏定义有多少含金量呢，待考察。</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/microxiami/p/11116903.html</dc:identifier>
</item>
<item>
<title>论文研读Unet++ - 范中豪</title>
<link>http://www.cnblogs.com/zhhfan/p/11123393.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/zhhfan/p/11123393.html</guid>
<description>&lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1807.10165.pdf&quot;&gt;Unet++ 论文地址&lt;/a&gt;&lt;br/&gt;这里仅进行简要介绍，可供读者熟悉其结构与特点，若想更为深入的了解，可以阅读原论文和参考文献。&lt;br/&gt;在计算机视觉领域，全卷积网络（FCN）是比较有名的图像分割网络，在医学图像处理方向，U-net更是一个炙手可热的网络，基本上所有的分割问题，我们都会拿U-Net先看一下基本的结果，然后进行修改。和FCN相比，U-Net的第一个特点是完全对称，也就是左边和右边是很类似的，而FCN的decoder相对简单，只用了一个deconvolution的操作，之后并没有跟上卷积结构。第二个区别就是skip connection，FCN用的是加操作（summation），U-Net用的是叠操作（concatenation）。它们的结构总最为经典的思路就是都使用了编码和解码（encoder-decoder）。&lt;/p&gt;
&lt;p&gt;U-net中最为重要的三个部分就是 1. 下采样 2. 上采样 3. skip connection，其结构图如下：&lt;br/&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1503464/201907/1503464-20190702214924773-1537768185.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;该网络结构中使用下采样的理论意义是：它可以增加对输入图像的一些小扰动的鲁棒性，比如图像平移，旋转等，减少过拟合的风险，降低运算量，和增加感受野的大小。上采样的作用是：把抽象的特征再还原解码到原图的尺寸，最终得到分割结果。&lt;/p&gt;
&lt;p&gt;简言之就是：浅层结构可以抓取图像的一些简单的特征，比如边界，颜色；而深层结构因为感受野大了，而且经过的卷积操作多了，能抓取到图像的一些更为高层的抽象特征。&lt;/p&gt;
&lt;p&gt;而Unet++在原生的Unet基础上进行一些改进，主要针对了原结构中的skip connection部分。先放一张Unet++的结构图&lt;br/&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1503464/201907/1503464-20190702214913170-1241561892.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;相对于原来的Unet网络，Unet++把1～4层的U-Net全给连一起了。这个结构的好处就是我不管你哪个深度的特征有效，我干脆都给你用上，让网络自己去学习不同深度的特征的重要性。第二个好处是它共享了一个特征提取器，也就是你不需要训练一堆U-Net，而是只训练一个encoder，它的不同层次的特征由不同的decoder路径来还原。这个encoder依旧可以灵活的用各种不同的backbone来代替。&lt;/p&gt;
&lt;p&gt;Unet++主要改进就是将原来空心的U-Net填满了，优势是可以抓取不同层次的特征，将它们通过特征叠加的方式整合，不同层次的特征，或者说不同大小的感受野，对于大小不一的目标对象的敏感度是不同的，比如，感受野大的特征，可以很容易的识别出大物体的，但是在实际分割中，大物体边缘信息和小物体本身是很容易被深层网络一次次的降采样和一次次升采样给弄丢的，这个时候就可能需要感受野小的特征来帮助。&lt;/p&gt;
&lt;p&gt;除了skip connection做出的改变之外，为了能够让中间部分收到传递过来的梯度，Unet++使用了深监督(deep supervision)的方案。具体的操作就是将结构的&lt;span class=&quot;math inline&quot;&gt;\(x^{0,1}, x^{0,2}和x^{0,3}\)&lt;/span&gt;也直接连接到最后的输出。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;参考文献&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/44958351&quot;&gt;研习U-Net&lt;/a&gt;&lt;/p&gt;
</description>
<pubDate>Tue, 02 Jul 2019 13:51:00 +0000</pubDate>
<dc:creator>范中豪</dc:creator>
<og:description>Unet++</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/zhhfan/p/11123393.html</dc:identifier>
</item>
</channel>
</rss>