<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="css/feed.xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/" xmlns:og="http://ogp.me/ns#">
<channel>
<atom:link rel="self" href="http://192.168.1.4/fivefilters/makefulltextfeed.php?url=feed.cnblogs.com%2Fblog%2Fsitehome%2Frss&amp;max=10&amp;links=preserve&amp;exc=" />
<atom:link rel="alternate" title="Source URL" href="http://feed.cnblogs.com/blog/sitehome/rss" />
<atom:link rel="related" title="Subscribe to feed" href="http://www.subtome.com/#/subscribe?feeds=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed.cnblogs.com%252Fblog%252Fsitehome%252Frss%26max%3D10%26links%3Dpreserve%26exc%3D&amp;back=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed.cnblogs.com%252Fblog%252Fsitehome%252Frss%26max%3D10%26links%3Dpreserve%26exc%3D" />
<title>博客园_首页</title>
<link></link>
<description>代码改变世界</description>
<item>
<title>计算机网络之传输层 - Java伴我余生</title>
<link>http://www.cnblogs.com/reminis/p/13063815.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/reminis/p/13063815.html</guid>
<description>&lt;h2 id=&quot;传输层概述&quot;&gt;传输层概述&lt;/h2&gt;
&lt;p&gt;  从信息处理得角度上去看，传输层主要是给上面得应用层提供通信服务得。我们平时再对网络进行编程得时候，我们很多时候都是直接对接得传输层，也就是我们使用传输层所提供得接口来进行网络编程，所以我们常说传输层是用户功能得最底层，是面向通信部份得最高层。&lt;/p&gt;&lt;p&gt;  传输层负责将上层数据分段并提供端到端的、可靠的或不可靠的传输以及端到端的差错控制和流量控制问题；包含的主要协议：TCP协议（Transmission Control Protocol，传输控制协议）、UDP协议（User Datagram Protocol，用户数据报协议）。&lt;/p&gt;
&lt;h2 id=&quot;udp协议&quot;&gt;UDP协议&lt;/h2&gt;
&lt;p&gt;  UDP(User Datagram Protocol: 用户数据报协议)，是一个非常简单的协议，它对接收到的数据报不合并也不拆分，如下图：&lt;br/&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1975191/202006/1975191-20200610103232644-1262258335.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;br/&gt;UDP协议格式：&lt;/p&gt;
&lt;table border=&quot;1&quot; color=&quot;black&quot;&gt;&lt;tr&gt;&lt;td&gt;16位源端口号&lt;/td&gt;
&lt;td&gt;16位目的端口号&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;16位UDP长度&lt;/td&gt;
&lt;td&gt;16位UDP校验和&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td colspan=&quot;2&quot;&gt;UDP数据&lt;/td&gt;
&lt;/tr&gt;&lt;/table&gt;&lt;p&gt;  UDP协议的特点：UDP是无连接协议；UDP不能保证可靠的交付数据，即UDP协议不会感知网络是否拥塞，UDP协议不管网络是否拥塞，都会把数据交付出去，给这个网络就完了。无法保证数据在网络中是否丢失；UDP是面向报文传输的；UDP没有拥塞控制，而且UDP首部开销很小。&lt;/p&gt;
&lt;h2 id=&quot;tcp协议&quot;&gt;TCP协议&lt;/h2&gt;
&lt;p&gt;  TCP(Transmission Control Protocol: 传输控制协议)，是计算机网络中非常复杂的一个协议。&lt;/p&gt;&lt;p&gt;  TCP协议特点：TCP是&lt;span&gt;面向连接&lt;/span&gt;的协议；TCP的一个连接有两端（点对点通信）；TCP提供&lt;span&gt;可靠&lt;/span&gt;的传输服务；TCP协议提供&lt;span&gt;全双工&lt;/span&gt;的通信；TCP是&lt;span&gt;面向字节流&lt;/span&gt;的协议。&lt;br/&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1975191/202006/1975191-20200610104202458-79915700.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;br/&gt;TCP协议格式：&lt;/p&gt;
&lt;table&gt;&lt;tr&gt;&lt;td colspan=&quot;3&quot;&gt;16位源端口&lt;/td&gt;
&lt;td&gt;16位目的端口&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td colspan=&quot;6&quot;&gt;序号&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td colspan=&quot;6&quot;&gt;确认号&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;数据偏移&lt;/td&gt;
&lt;td&gt;保留字段&lt;/td&gt;
&lt;td&gt;TCP标记&lt;/td&gt;
&lt;td&gt;窗口&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td colspan=&quot;3&quot;&gt;校验和&lt;/td&gt;
&lt;td&gt;紧急指针&lt;/td&gt;
&lt;/tr&gt;&lt;/table&gt;&lt;table&gt;&lt;tr&gt;&lt;td&gt;TCP选项&lt;/td&gt;
&lt;td&gt;填充&lt;/td&gt;
&lt;/tr&gt;&lt;/table&gt;&lt;p&gt;&lt;strong&gt;序号&lt;/strong&gt;：0~&lt;span class=&quot;math inline&quot;&gt;\(2^{32}\)&lt;/span&gt;-1，一个字节一个序号， 数据首字节序号&lt;br/&gt;&lt;strong&gt;确认号&lt;/strong&gt;：0~&lt;span class=&quot;math inline&quot;&gt;\(2^{32}\)&lt;/span&gt;-1，一个字节一个序号， 期望收到数据的首字节序号。确认号为N：则表示N-1序号的数据都已经收到。&lt;br/&gt;&lt;strong&gt;数据偏移&lt;/strong&gt;：占4位：0~15，单位为：32位字，数据偏离首部的距离。&lt;br/&gt;&lt;strong&gt;TCP标记&lt;/strong&gt;：占6位，每位各有不同意义&lt;/p&gt;
&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;标记&lt;/th&gt;
&lt;th&gt;含义&lt;/th&gt;
&lt;/tr&gt;&lt;/thead&gt;&lt;tbody readability=&quot;6&quot;&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;URG&lt;/td&gt;
&lt;td&gt;Urgent: 紧急位，URG=1，表示紧急数据&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;ACK&lt;/td&gt;
&lt;td&gt;Acknowledgement: 确认位，ACK=1，确认号才生效&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;PSH&lt;/td&gt;
&lt;td&gt;Push: 推送位，PSH=1，尽快地把数据交付给应用层&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;RST&lt;/td&gt;
&lt;td&gt;Reset: 重置位，RST=1，重新建立连接&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;SYN&lt;/td&gt;
&lt;td&gt;Synchronization: 同步位，SYN=1 表示连接请求报文&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;FIN&lt;/td&gt;
&lt;td&gt;Finish: 终止位，FIN=1 表示释放连接&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;&lt;strong&gt;窗口&lt;/strong&gt;：占16位：0~&lt;span class=&quot;math inline&quot;&gt;\(2^{16}\)&lt;/span&gt;-1，窗口指明允许对方发送的数据量&lt;br/&gt;&lt;strong&gt;紧急指针&lt;/strong&gt;：紧急数据（URG=1），指定紧急数据在报文的位置&lt;br/&gt;&lt;strong&gt;TCP选项&lt;/strong&gt;：最多40字节，支持未来的拓展&lt;/p&gt;
&lt;h3 id=&quot;可靠传输的基本原理&quot;&gt;可靠传输的基本原理&lt;/h3&gt;
&lt;ul&gt;&lt;li&gt;停止等待协议：发送方生成新的消息，发送给接收方，并且此时不会产生新的消息，需要收到接受方的确认消息后，才会产生新的消息。超时重传：如果发送方的消息在传输的过程种丢失了，接收方没有收到消息，就会进行超时重传；如果接收方发送的确认消息，在传输的过程中丢失，也会进行超时重传，因此 每发送一个消息，都需要设置一个定时器。停止等待协议是最简单的可靠传输协议，但停止等待协议对信道的利用效率不高。&lt;/li&gt;
&lt;li&gt;连续ARQ协议：ARQ(Automatic Repeat reQuest：自动重传请求)，由于单个发送和确认效率低，我们可以通过批量发送和确认来提升效率。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;  TCP的可靠传输基于连续ARQ协议，TCP的滑动窗口以字节为单位，窗口滑动过程如下图：&lt;br/&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1975191/202006/1975191-20200612163541444-585702222.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;br/&gt;如果接收到的序号没有按序收到确认号，在超时时间内就会进行重新传送，如下图：&lt;br/&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1975191/202006/1975191-20200612164042195-619557208.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;br/&gt;为了避免对整个窗口中的字节进行重传，因此TCP协议使用了选择重传来提高传输效率。选择重传：重传的是一段字节流，而不是某个字节，在TCP选项里存储的是需要重传的字节流的边界。选择重传需要指定需要重传的字节，每一个字节都有唯一的32位序号。&lt;/p&gt;
&lt;h3 id=&quot;tcp协议的流量控制&quot;&gt;TCP协议的流量控制&lt;/h3&gt;
&lt;p&gt;   流量控制指让发送方发送速率不要太快，是使用滑动窗口来实现的，即通过窗口大小控制对方发送速率。当接收到窗口为0的消息，则启动坚持定时器,坚持定时器每隔一段时间发送一个窗口探测报文。&lt;br/&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1975191/202006/1975191-20200613071414294-454067827.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h3 id=&quot;tcp协议的拥塞控制&quot;&gt;TCP协议的拥塞控制&lt;/h3&gt;
&lt;p&gt;  一条数据链路经过非常多的设备，数据链路中各个部分都有可能成为网路传输的瓶颈。流量控制考虑点对点的通信量的控制，拥塞控制考虑整个网络，是全局性的考虑。如何判断是否发生了网络拥塞？根据报文超时来判断发生了拥塞是不成立的，如果我们在传输的过程中，把光纤或者网络断了，这个时候也会导致报文超时，但这是因为网络故障造成的&lt;br/&gt;  慢启动算法： 由小到大逐渐增加发送数据量，每收到一个报文确认，就加一。例如：发送的数据量以此为：1 2 4 8 16...，是指数增长的。当使用慢启动算法增长到慢启动阈值时，就会使用拥塞避免算法；拥塞避免算法：维护一个拥塞窗口的变量，只要网络不拥塞，就试探着拥塞窗口调大，如1 2 4 8 16 17 18 19。&lt;/p&gt;
&lt;h3 id=&quot;tcp连接的建立&quot;&gt;TCP连接的建立&lt;/h3&gt;
&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;标记&lt;/th&gt;
&lt;th&gt;含义&lt;/th&gt;
&lt;/tr&gt;&lt;/thead&gt;&lt;tbody readability=&quot;6&quot;&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;URG&lt;/td&gt;
&lt;td&gt;Urgent: 紧急位，URG=1，表示紧急数据&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;&lt;span&gt;ACK&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;&lt;span&gt;Acknowledgement: 确认位，ACK=1，确认号才生效&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;PSH&lt;/td&gt;
&lt;td&gt;Push: 推送位，PSH=1，尽快地把数据交付给应用层&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;RST&lt;/td&gt;
&lt;td&gt;Reset: 重置位，RST=1，重新建立连接&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;&lt;span&gt;SYN&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;&lt;span&gt;Synchronization: 同步位，SYN=1 表示连接请求报文&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;&lt;span&gt;FIN&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;&lt;span&gt;Finish: 终止位，FIN=1 表示释放连接&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1975191/202006/1975191-20200613082548397-471319884.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;TCP三次握手的过程：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;第一次握手：建立连接时，客户端（发送方）发送syn包（seq=j）到服务器，并进入SYN_SENT状态，等待服务器（接收方）确认；&lt;/li&gt;
&lt;li&gt;第二次握手：服务器收到syn包，必须确认客户的SYN（ack=j+1），同时自己也发送一个SYN包（seq=k），即SYN+ACK包，此时服务器进入SYN_RECV状态。&lt;/li&gt;
&lt;li&gt;第三次握手：客户端收到服务器的SYN+ACK包，向服务器发送确认包ACK(ack=k+1），此包发送完毕，客户端和服务器进入ESTABLISHED（TCP连接成功）状态，完成三次握手&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;  在客户端与服务器端传输的TCP报文中，双方的确认号Ack和序号Seq的值，都是在彼此Ack和Seq值的基础上进行计算的，这样做保证了TCP报文传输的连贯性。一旦出现某一方发出的TCP报文丢失，便无法继续&quot;握手&quot;，以此确保了&quot;三次握手&quot;的顺利完成。此后客户端和服务器端进行正常的数据传输。这就是“三次握手”的过程。&lt;/p&gt;
&lt;p&gt;为什么发送方要发出第三个确认报文呢？&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;为了避免已经失效的连接请求报文传送到对方，引起错误&lt;br/&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1975191/202006/1975191-20200613073550102-1992297657.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;h3 id=&quot;tcp连接的释放&quot;&gt;TCP连接的释放&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1975191/202006/1975191-20200613074906769-1962262167.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;TCP四次挥手的过程：TCP连接断开过程：假设Client端发起中断连接请求，也就是发送FIN报文。Server端接到FIN报文后，意思是说&quot;我Client端没有数据要发给你了&quot;，但是如果你还有数据没有发送完成，则不必急着关闭Socket，可以继续发送数据。所以你先发送ACK，&quot;告诉Client端，你的请求我收到了，但是我还没准备好，请继续你等我的消息&quot;。这个时候Client端就进入FIN_WAIT状态，继续等待Server端的FIN报文。当Server端确定数据已发送完成，则向Client端发送FIN报文，&quot;告诉Client端，好了，我这边数据发完了，准备好关闭连接了&quot;。Client端收到FIN报文后，&quot;就知道可以关闭连接了，但是他还是不相信网络，怕Server端不知道要关闭，所以发送ACK后进入TIME_WAIT状态，如果Server端没有收到ACK则可以重传。&quot;，Server端收到ACK后，&quot;就知道可以断开连接了&quot;。Client端等待了&lt;span&gt;2MSL&lt;/span&gt;后依然没有收到回复，则证明Server端已正常关闭，那好，我Client端也可以关闭连接了。Ok，TCP连接就这样关闭了！&lt;/p&gt;
&lt;p&gt;  MSL(Max Segment Lifetime): 最长报文段寿命，MSL建议设置为2分钟。为什么需要等待2MSL？其实在释放连接的过程中，客户端最后一次发送的报文，服务端是没有确认的，为了确保发送方的ACK可以达到接收方，如果2MSL时间内没有收到，则接收方会重发。这也是等待计时器的作用，主要是为了确保发送方发送的第四次挥手报文可以正确的到达接收方，如果没有到达的话，接收方就会重新放松第三次挥手的报文，以正确得到释放这次连接。等待计时器的另一个作用就是确保当前连接的所有报文都已经过期。&lt;/p&gt;
&lt;p&gt;为什么关闭连接需要四次挥手呢？&lt;br/&gt;  这是因为服务端的LISTEN状态下的SOCKET当收到SYN报文的建连请求后，它可以把ACK和SYN（ACK起应答作用，而SYN起同步作用）放在一个报文里来发送。但关闭连接时，当收到对方的FIN报文通知时，它仅仅表示对方没有数据发送给你了；但未必你所有的数据都全部发送给对方了，所以你可能未必会马上会关闭SOCKET,也即你可能还需要发送一些数据给对方之后，再发送FIN报文给对方来表示你同意现在可以关闭连接了，所以它这里的ACK报文和FIN报文多数情况下都是分开发送的。&lt;/p&gt;
&lt;p&gt;传输层总结：第一个端到端，即主机到主机的层次。传输层负责将上层数据分段并提供端到端的、可靠的或不可靠的传输。此外，传输层还要处理端到端的差错控制和流量控制问题。 传输层的任务是根据通信子网的特性，最佳的利用网络资源，为两个端系统的会话层之间，提供建立、维护和取消传输连接的功能，负责端到端的可靠数据传输。在这一层，信息传送的协议数据单元称为段或报文。 网络层只是根据网络地址将源结点发出的数据包传送到目的结点，而传输层则负责将数据可靠地传送到相应的端口。 有关网络层的重点：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;传输层负责将上层数据分段并提供端到端的、可靠的或不可靠的传输以及端到端的差错控制和流量控制问题；&lt;/li&gt;
&lt;li&gt;包含的主要协议：TCP协议（Transmission Control Protocol，传输控制协议）、UDP协议（User Datagram Protocol，用户数据报协议）；&lt;/li&gt;
&lt;li&gt;重要设备：网关。&lt;/li&gt;
&lt;/ul&gt;</description>
<pubDate>Sat, 13 Jun 2020 00:24:00 +0000</pubDate>
<dc:creator>Java伴我余生</dc:creator>
<og:description>传输层概述 从信息处理得角度上去看，传输层主要是给上面得应用层提供通信服务得。我们平时再对网络进行编程得时候，我们很多时候都是直接对接得传输层，也就是我们使用传输层所提供得接口来进行网络编程，所以我们</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/reminis/p/13063815.html</dc:identifier>
</item>
<item>
<title>小师妹学JavaIO之:NIO中那些奇怪的Buffer - flydean</title>
<link>http://www.cnblogs.com/flydean/p/java-io-nio-kinds-of-buffer.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/flydean/p/java-io-nio-kinds-of-buffer.html</guid>
<description>&lt;p&gt;妖魔鬼怪快快显形，今天F师兄帮助小师妹来斩妖除魔啦，什么BufferB，BufferL，BufferRB，BufferRL，BufferS，BufferU，BufferRS，BufferRU统统给你剖析个清清楚楚明明白白。&lt;/p&gt;

&lt;p&gt;小师妹：F师兄不都说JDK源码是最好的java老师吗？为程不识源码，就称牛人也枉然。但是我最近在学习NIO的时候竟然发现有些Buffer类居然没有注释，就那么突兀的写在哪里，让人好生心烦。&lt;/p&gt;
&lt;blockquote readability=&quot;2.9166666666667&quot;&gt;
&lt;p&gt;更多内容请访问&lt;a href=&quot;https://www.cnblogs.com/flydean/p/www.flydean.com&quot;&gt;www.flydean.com&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;居然还有这样的事情？快带F师兄去看看。&lt;/p&gt;
&lt;p&gt;小师妹：F师兄你看，以ShortBuffer为例，它的子类怎么后面都带一些奇奇怪怪的字符：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20200521231233790.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_0,text_aHR0cDovL3d3dy5mbHlkZWFuLmNvbQ==,size_35,color_8F8F8F,t_70&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;什么什么BufferB，BufferL，BufferRB，BufferRL，BufferS，BufferU，BufferRS，BufferRU都来了，点进去看他们的源码也没有说明这些类到底是做什么的。&lt;/p&gt;
&lt;p&gt;还真有这种事情，给我一个小时，让我仔细研究研究。&lt;/p&gt;
&lt;p&gt;一个小时后，小师妹，经过我一个小时的辛苦勘察，结果发现，确实没有官方文档介绍这几个类到底是什么含义，但是师兄我掐指一算，好像发现了这些类之间的小秘密，且听为兄娓娓道来。&lt;/p&gt;
&lt;p&gt;之前的文章，我们讲到Buffer根据类型可以分为ShortBuffer，LongBuffer，DoubleBuffer等等。&lt;/p&gt;
&lt;p&gt;但是根据本质和使用习惯，我们又可以分为三类，分别是：ByteBufferAsXXXBuffer，DirectXXXBuffer和HeapXXXBuffer。&lt;/p&gt;
&lt;p&gt;ByteBufferAsXXXBuffer主要将ByteBuffer转换成为特定类型的Buffer，比如CharBuffer，IntBuffer等等。&lt;/p&gt;
&lt;p&gt;而DirectXXXBuffer则是和虚拟内存映射打交道的Buffer。&lt;/p&gt;
&lt;p&gt;最后HeapXXXBuffer是在堆空间上面创建的Buffer。&lt;/p&gt;

&lt;p&gt;小师妹，F师兄，你刚刚讲的都不重要，我就想知道类后面的B，L，R，S，U是做什么的。&lt;/p&gt;
&lt;p&gt;好吧，在给你讲解这些内容之前，师兄我给你讲一个故事。&lt;/p&gt;
&lt;p&gt;话说在明末浙江才女吴绛雪写过一首诗：《春 景 诗》&lt;/p&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;莺啼岸柳弄春晴，&lt;br/&gt;柳弄春晴夜月明。&lt;br/&gt;明月夜晴春弄柳，&lt;br/&gt;晴春弄柳岸啼莺。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;小师妹，可有看出什么特异之处？最好是多读几遍，读出声来。&lt;/p&gt;
&lt;p&gt;小师妹：哇，F师兄，这首诗从头到尾和从尾到头读起来是一样的呀，又对称又有意境！&lt;/p&gt;
&lt;p&gt;不错，这就是中文的魅力啦，根据读的方式不同，得出的结果也不同，其实在计算机世界也存在这样的问题。&lt;/p&gt;
&lt;p&gt;我们知道在java中底层的最小存储单元是Byte，一个Byte是8bits，用16进制表示就是Ox00-OxFF。&lt;/p&gt;
&lt;p&gt;java中除了byte，boolean是占一个字节以外，好像其他的类型都会占用多个字节。&lt;/p&gt;
&lt;p&gt;如果以int来举例，int占用4个字节，其范围是从Ox00000000-OxFFFFFFFF,假如我们有一个int=Ox12345678，存到内存地址里面就有这样两种方式。&lt;/p&gt;
&lt;p&gt;第一种Big Endian将高位的字节存储在起始地址&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20200522145311810.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_0,text_aHR0cDovL3d3dy5mbHlkZWFuLmNvbQ==,size_35,color_8F8F8F,t_70&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;第二种Little Endian将地位的字节存储在起始地址&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20200522145506661.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_0,text_aHR0cDovL3d3dy5mbHlkZWFuLmNvbQ==,size_35,color_8F8F8F,t_70&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;其实Big Endian更加符合人类的读写习惯，而Little Endian更加符合机器的读写习惯。&lt;/p&gt;
&lt;p&gt;目前主流的两大CPU阵营中，PowerPC系列采用big endian方式存储数据，而x86系列则采用little endian方式存储数据。&lt;/p&gt;
&lt;p&gt;如果不同的CPU架构直接进行通信，就由可能因为读取顺序的不同而产生问题。&lt;/p&gt;
&lt;p&gt;java的设计初衷就是一次编写处处运行，所以自然也做了设计。&lt;/p&gt;
&lt;p&gt;所以BufferB表示的是Big Endian的buffer，BufferL表示的是Little endian的Buffer。&lt;/p&gt;
&lt;p&gt;而BufferRB，BufferRL表示的是两种只读Buffer。&lt;/p&gt;

&lt;p&gt;小师妹：F师兄，那这几个又是做什么用的呢？ BufferS，BufferU，BufferRS，BufferRU。&lt;/p&gt;
&lt;p&gt;在讲解这几个类之前，我们先要回顾一下JVM中对象的存储方式。&lt;/p&gt;
&lt;p&gt;还记得我们是怎么使用JOL来分析JVM的信息的吗？代码非常非常简单：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;log.info(&quot;{}&quot;, VM.current().details());
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;输出结果：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;# Running 64-bit HotSpot VM.
# Using compressed oop with 3-bit shift.
# Using compressed klass with 3-bit shift.
# WARNING | Compressed references base/shifts are guessed by the experiment!
# WARNING | Therefore, computed addresses are just guesses, and ARE NOT RELIABLE.
# WARNING | Make sure to attach Serviceability Agent to get the reliable addresses.
# Objects are 8 bytes aligned.
# Field sizes by type: 4, 1, 1, 2, 2, 4, 4, 8, 8 [bytes]
# Array element sizes: 4, 1, 1, 2, 2, 4, 4, 8, 8 [bytes]
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;上面的输出中，我们可以看到：Objects are 8 bytes aligned，这意味着所有的对象分配的字节都是8的整数倍。&lt;/p&gt;
&lt;p&gt;再注意上面输出的一个关键字aligned，确认过眼神，是对的那个人。&lt;/p&gt;
&lt;p&gt;aligned对齐的意思，表示JVM中的对象都是以8字节对齐的，如果对象本身占用的空间不足8字节或者不是8字节的倍数，则补齐。&lt;/p&gt;
&lt;p&gt;还是用JOL来分析String对象：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;[main] INFO com.flydean.JolUsage - java.lang.String object internals:
 OFFSET  SIZE      TYPE DESCRIPTION                               VALUE
      0    12           (object header)                           N/A
     12     4    byte[] String.value                              N/A
     16     4       int String.hash                               N/A
     20     1      byte String.coder                              N/A
     21     1   boolean String.hashIsZero                         N/A
     22     2           (loss due to the next object alignment)
Instance size: 24 bytes
Space losses: 0 bytes internal + 2 bytes external = 2 bytes total
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;可以看到一个String对象占用24字节，但是真正有意义的是22字节，有两个2字节是补齐用的。&lt;/p&gt;
&lt;p&gt;对齐的好处显而易见，就是CPU在读取数据的时候更加方便和快捷，因为CPU设定是一次读取多少字节来的，如果你存储是没有对齐的，则CPU读取起来效率会比较低。&lt;/p&gt;
&lt;p&gt;现在可以回答部分问题：BufferU表示是unaligned，BufferRU表示是只读的unaligned。&lt;/p&gt;
&lt;p&gt;小师妹：那BufferS和BufferRS呢？&lt;/p&gt;
&lt;p&gt;这个问题其实还是很难回答的，但是经过师兄我的不断研究和探索，终于找到了答案：&lt;/p&gt;
&lt;p&gt;先看下DirectShortBufferRU和DirectShortBufferRS的区别，两者的区别在两个地方，先看第一个Order：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;DirectShortBufferRU:

public ByteOrder order() {
        return ((ByteOrder.nativeOrder() != ByteOrder.BIG_ENDIAN)
                ? ByteOrder.LITTLE_ENDIAN : ByteOrder.BIG_ENDIAN);
    }
&lt;/code&gt;
&lt;/pre&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;DirectShortBufferRS：

public ByteOrder order() {
        return ((ByteOrder.nativeOrder() == ByteOrder.BIG_ENDIAN)
                ? ByteOrder.LITTLE_ENDIAN : ByteOrder.BIG_ENDIAN);
    }
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;可以看到DirectShortBufferRU的Order是跟nativeOrder是一致的。而DirectShortBufferRS的Order跟nativeOrder是相反的。&lt;/p&gt;
&lt;p&gt;为什么相反？再看两者get方法的不同：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;DirectShortBufferU：

public short get() {
        try {
            checkSegment();
            return ((UNSAFE.getShort(ix(nextGetIndex()))));
        } finally {
            Reference.reachabilityFence(this);
        }
    }
&lt;/code&gt;
&lt;/pre&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;DirectShortBufferS：

public short get() {
        try {
            checkSegment();
            return (Bits.swap(UNSAFE.getShort(ix(nextGetIndex()))));
        } finally {
            Reference.reachabilityFence(this);
        }
    }
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;区别出来了，DirectShortBufferS在返回的时候做了一个bits的swap操作。&lt;/p&gt;
&lt;p&gt;所以BufferS表示的是swap过后的Buffer，和BufferRS表示的是只读的swap过后的Buffer。&lt;/p&gt;

&lt;p&gt;不写注释实在是害死人啊！尤其是JDK自己也不写注释的情况下！&lt;/p&gt;
&lt;p&gt;更多精彩内容且看：&lt;/p&gt;
&lt;blockquote readability=&quot;8.2898550724638&quot;&gt;
&lt;p&gt;本文作者：flydean程序那些事&lt;/p&gt;
&lt;p&gt;本文链接：&lt;a href=&quot;http://www.flydean.com/java-io-nio-kinds-of-buffer/&quot;&gt;http://www.flydean.com/java-io-nio-kinds-of-buffer/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;本文来源：flydean的博客&lt;/p&gt;
&lt;p&gt;欢迎关注我的公众号:程序那些事，更多精彩等着您！&lt;/p&gt;
&lt;/blockquote&gt;
</description>
<pubDate>Sat, 13 Jun 2020 00:05:00 +0000</pubDate>
<dc:creator>flydean</dc:creator>
<og:description>简介 妖魔鬼怪快快显形，今天F师兄帮助小师妹来斩妖除魔啦，什么BufferB，BufferL，BufferRB，BufferRL，BufferS，BufferU，BufferRS，BufferRU统统</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/flydean/p/java-io-nio-kinds-of-buffer.html</dc:identifier>
</item>
<item>
<title>【JAVA进阶架构师指南】之五：JVM性能调优 - 悟空不败</title>
<link>http://www.cnblogs.com/wukongbubai/p/13111482.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/wukongbubai/p/13111482.html</guid>
<description>&lt;h2 id=&quot;前言&quot;&gt;前言&lt;/h2&gt;
&lt;p&gt;  首先给大家说声对不起,最近属实太忙了,白天上班,晚上加班,回家还要收拾家里,基本每天做完所有事儿都是凌晨一两点了,没有精力再搞其他的了.&lt;br/&gt;  好了,进入正题,让我们来聊聊JVM篇最后一个章节----JVM性能调优.童鞋们随便打开一个大厂的招聘岗位JD,应该都会有JVM调优相关的描述,其实招聘方不一定要求候选人真的对JVM调优有实际调优经验,但是至少得有思路,知道应该怎样进行JVM层面的性能调优,说实话,知道如何进行JVM层面的性能调优的人,在面试中确实是有加分的.&lt;br/&gt;  笔者在公司担任面试官的时候,经常会看到候选人简历描述有JVM性能调优经验,每当这个时候我都会问候选人一个问题,你是如何进行JVM性能调优的,很多童鞋的回答就是:噢,就是调整一下初始堆大小,新生代大小.这明显不是笔者想要的答案,因为这根本就不叫JVM性能调优.童鞋们对号入座一下,对JVM调优仅仅是我上述说的那样的,赶紧改一下简历,不要说自己会JVM性能调优.说实话,对JVM进行性能调优是对架构师的要求,甚至我敢说很多架构师都不一定有实际的JVM性能调优经验.话不多说,让我们进入正题,我们将从以下几点来讲解如何进行性能调优:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;JVM性能调优的前提&lt;/li&gt;
&lt;li&gt;JVM性能调优的预备知识&lt;/li&gt;
&lt;li&gt;STW现象--Stop-The-World&lt;/li&gt;
&lt;li&gt;垃圾回收器的种类&lt;/li&gt;
&lt;li&gt;性能调优的目的&lt;/li&gt;
&lt;li&gt;如何进行性能调优&lt;/li&gt;
&lt;/ul&gt;&lt;h2 id=&quot;jvm性能调优的前提&quot;&gt;JVM性能调优的前提&lt;/h2&gt;
&lt;p&gt;  所有有经验的架构师一定会有一个共识,JVM层面的性能调优一定是作为最后的调优手段,在此之前,一定要确保系统其它方面都已经做到了极致,无法再进行调优了,在这个前提下,才会考虑JVM性能调优.这里的其他方面包括从前端到架构到代码层面,我举一些例子&lt;br/&gt;从浏览器/APP角度可进行的优化有:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;减少HTTP请求次数.&lt;/li&gt;
&lt;li&gt;使用客户端缓存.&lt;/li&gt;
&lt;li&gt;浏览器启用压缩&lt;/li&gt;
&lt;li&gt;使用CDN加速&lt;/li&gt;
&lt;li&gt;动态资源和静态资源分离&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;从系统层面可进行的优化有:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;启用缓存,比如redis缓存数据&lt;/li&gt;
&lt;li&gt;使用集群&lt;/li&gt;
&lt;li&gt;异步处理,比如引入消息队列&lt;/li&gt;
&lt;li&gt;对代码的优化&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;  以上列出的每一点,都能单独拎出来讲很久,但是博文篇幅问题,就不细说了,有兴趣的童鞋可以自行下去了解,我们只着重说一下代码优化,相信大家都知道,业界比较公认的编码规范是阿里巴巴发布的&amp;lt;java开发手册&amp;gt;,里面的内容都是阿里集团多年来血的教训积累的精华,阿里集团内部有一个组织专门负责手册的编写和推广,并且在不断进行优化,最新版发布到泰山版了(我看的时候还是华山版,哈哈).如果有童鞋还不知道的,我建议去下载下来看一看.另外阿里云上有&amp;lt;java开发手册&amp;gt;的考试,如果通过了这个考试,说明你的编码规范还是不错的,有兴趣的童鞋可以去试一下.&lt;br/&gt;  除此之外,童鞋们还应该了解JVM本身为我们悄悄做的各种优化,其中最重要的是JIT编译器的优化.我举几个例子,比如:方法内联,逃逸分析等.默认情况下,这些都是开启的,如果不开启这些功能,JVM性能会下降50%以上.除此之外,还有一些比如:栈上分配,TLAB等优化.这些内容由于平时我们开发中不会用到,是JVM在背后悄悄为我们做了优化,因此可能很多童鞋都不知道,但是如果想成为一个合格的架构师,这些内容都是必须要知道的,毕竟架构师的知识广度和深度决定了架构师的高度.&lt;br/&gt;  除此之外,性能调优一定是基于性能测试的,空口说进行性能调优的都是耍流氓,只有在经过了实际的性能测试后,我们才知道系统的瓶颈在哪里,才知道那些方面需要进行调优,如何进行调优.常用的性能测试指标有TPS/QPS/吞吐量.并且默认所有的接口访问都遵循二八原则(接口每天80%的访问量集中在20%的时间内).&lt;/p&gt;
&lt;h2 id=&quot;jvm性能调优的预备知识&quot;&gt;JVM性能调优的预备知识&lt;/h2&gt;
&lt;p&gt;  在进行JVM性能调优之前,我们还得了解JVM,比如我前面的几篇有关JVM的博文,都是需要掌握的,比如JVM内存模型,垃圾回收机制等等.另外我们还需要掌握一些进行JVM分析的工具.其实在我们安装JDK的时候,JDK已经为我们准备了许多有用的性能调优监控工具,我们可以看一下JDK安装目录下的bin目录:&lt;br/&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/1924225/202006/1924225-20200613024907106-1130756876.jpg&quot; alt=&quot;file&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;jps: 主要用来输出JVM中运行的进程状态信息&lt;/li&gt;
&lt;li&gt;jstack: 主要用来查看某个Java进程内的线程堆栈信息&lt;/li&gt;
&lt;li&gt;jmap: 用来查看堆内存使用状况,一般结合jhat使用&lt;/li&gt;
&lt;li&gt;jstat: JVM统计监测工具&lt;/li&gt;
&lt;li&gt;jconsole: 图形化的统计工具&lt;/li&gt;
&lt;li&gt;jvisualvm: 比jconsole功能更强的图形化的监控工具&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;  另外我们需要知道,当JVM发生OOM异常时,可以使用命令生成一个.hprof后缀的dump文件,该文件是某个时间节点的heap的快照,我们可以使用VisualVM来查看,也可以用第三方提供的一些工具,比如eclipse的MAT来查看内存溢出的原因.&lt;/p&gt;
&lt;h2 id=&quot;stw现象&quot;&gt;STW现象&lt;/h2&gt;
&lt;p&gt;  所谓STW现象(Stop-The-World)是指在执行垃圾收集算法时,Java应用程序的其他所有线程(除了垃圾收集线程之外的线程)都被挂起.此时,系统只允许GC线程继续运行,其他线程全部暂停,等待GC线程执行完毕后才能继续执行.这些工作都是由虚拟机在后台自动发起和自动完成的,是在用户不可见的情况下把用户正常工作的线程全部停掉,举个例子,某个接口平时可能只需要50ms的RT,忽然某次调用花费了200ms.因此STW对实时性要求很高的系统来说是难以接受的.&lt;/p&gt;
&lt;h2 id=&quot;垃圾回收器的种类&quot;&gt;垃圾回收器的种类&lt;/h2&gt;
&lt;p&gt;  既然有STW现象,那么有没有解决方案呢?这就是我们接下来要讲的,垃圾回收器的种类,目前为止,JVM一共为我们提供了七种垃圾回收器,其中年轻代有三种,老年代有三种,另外还有一种特殊的G1:&lt;br/&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/1924225/202006/1924225-20200613024907548-1673576353.jpg&quot; alt=&quot;file&quot; loading=&quot;lazy&quot;/&gt;&lt;br/&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/1924225/202006/1924225-20200613024907942-1969212316.jpg&quot; alt=&quot;file&quot; loading=&quot;lazy&quot;/&gt;&lt;br/&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/1924225/202006/1924225-20200613024908361-1869098372.jpg&quot; alt=&quot;file&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;  当然,在更新版本的JDK中还有一种ZGC,为未来垃圾回收器提供了一种趋势,有兴趣的童鞋可以自行了解.&lt;/p&gt;
&lt;h2 id=&quot;性能调优的目的和具体过程&quot;&gt;性能调优的目的和具体过程&lt;/h2&gt;
&lt;p&gt;  有了前面的铺垫,终于来到了我们最重要的正题:如何进行JVM性能调优?在我看来JVM调优的具体步骤分为如下几步:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;确定调优的目的,选择合适的GC collector&lt;/li&gt;
&lt;li&gt;调整JVM heap的大小&lt;/li&gt;
&lt;li&gt;调整young generation在整个JVM heap中所占的比重.&lt;/li&gt;
&lt;/ul&gt;&lt;h3 id=&quot;确定调优的目的选择合适的gc-collector&quot;&gt;确定调优的目的,选择合适的GC collector&lt;/h3&gt;
&lt;p&gt;  由于每种垃圾回收器的特性并不相同,因此我们需要根据我们的调优目的选择合适的垃圾回收器,比如,我们需要降低STW的停顿时间,那我们就不能选用串行和并行的垃圾回收器,而应该选用并发的垃圾回收器,即CMS,与之搭配的新生代垃圾回收器就应该选用ParNew.目前一般主流互联网公司都是用CMS垃圾回收器.&lt;/p&gt;
&lt;h3 id=&quot;调整jvm-heap的大小&quot;&gt;调整JVM heap的大小&lt;/h3&gt;
&lt;p&gt;  确定了垃圾回收器的类型,就需要调整JVM heap的大小,在这一步的时候,首先我们需要了解JVM相关的一些指令,比如可以在启动java程序时加上&lt;br/&gt;-XX:+HeapDumpOnOutOfMemoryError,当发生OOM时,JVM会自动为我们生成DUMP文件&lt;br/&gt;-XX:+PrintGCDetails -Xloggc:D:\gclogger\gc.log -XX:+PrintGCDateStamps 生成GC日志&lt;br/&gt;-Xms2g -Xmx2g 当然,还应该要根据实际情况设置heap的最大最小值,童鞋们要知道,默认情况下,java程序启动的最小heap大小为1/64物理内存,最大值为1/4物理内存,一般要求我们最大最小值保持一致,避免JVM频繁扩容和缩容导致不必要的性能浪费.&lt;/p&gt;
&lt;h3 id=&quot;调整young-generation在整个jvm-heap中所占的比重&quot;&gt;调整young generation在整个JVM heap中所占的比重.&lt;/h3&gt;
&lt;p&gt;  确定了heap的大小,还需要确定新生代的比重&lt;br/&gt;–Xmn1500m -XX:MetaspaceSize=150M&lt;/p&gt;
&lt;p&gt;  当然,再厉害的架构师也不可能一次就调整得出最佳的JVM配置参数,而是应该多设置几组不同的值,放到生产环境(或者和生产环境一样的环境,比如阿里内部有预发环境,和生产环境保持一致)进行性能测试,通过对比结果得出最佳的JVM性能调优参数,完成JVM性能调优.&lt;/p&gt;
&lt;h2 id=&quot;总结&quot;&gt;总结&lt;/h2&gt;
&lt;p&gt;  读完了本篇文章,我相信童鞋们应该或多或少会有些收获.掌握JVM调整的核心步骤:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;确定调优的目的,选择合适的GC collector&lt;/li&gt;
&lt;li&gt;调整JVM heap的大小&lt;/li&gt;
&lt;li&gt;调整young generation在整个JVM heap中所占的比重.&lt;br/&gt;  不了解如何进行JVM的调优的人,把本文内容好好理解后,能让面试官刮目相看;了解JVM调优,但是条理不清晰的童鞋,可能会对JVM调优有更清晰的认识.总而言之,笔者认为本文是一篇满满的干货,网上许多讲JVM调优的博文,并没有这么系统的讲解过真正应该如何进行JVM调优.当然笔者能力有限,如文章有错误,欢迎指正,毕竟是人就会犯错.&lt;br/&gt;  PS:一入JVM深似海,从此再也出不来.对JVM有兴趣的童鞋,可以钻研,但是在经验不足之前,不建议太过深入了解JVM,否则会耽误自己.当然,立志要成为一名牛逼的架构师,这些都是必须要会的.&lt;br/&gt;  本文我们讲完了JVM,下一篇开始,让我们继续学习JAVA锁相关的内容.&lt;br/&gt;  如果觉得博主写的不错,欢迎关注博主微信公众号,博主会不定期分享技术干货!&lt;br/&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/1924225/202006/1924225-20200613024908788-477635036.jpg&quot; alt=&quot;file&quot; loading=&quot;lazy&quot;/&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;blockquote readability=&quot;4.1509433962264&quot;&gt;
&lt;p&gt;本文由博客一文多发平台 &lt;a href=&quot;https://openwrite.cn?from=article_bottom&quot;&gt;OpenWrite&lt;/a&gt; 发布！&lt;/p&gt;
&lt;/blockquote&gt;
</description>
<pubDate>Fri, 12 Jun 2020 18:49:00 +0000</pubDate>
<dc:creator>悟空不败</dc:creator>
<og:description>前言 首先给大家说声对不起,最近属实太忙了,白天上班,晚上加班,回家还要收拾家里,基本每天做完所有事儿都是凌晨一两点了,没有精力再搞其他的了. 好了,进入正题,让我们来聊聊JVM篇最后一个章节 JVM</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/wukongbubai/p/13111482.html</dc:identifier>
</item>
<item>
<title>TCP 三次握手的意义 - 烟草的香味</title>
<link>http://www.cnblogs.com/hujingnb/p/13111467.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/hujingnb/p/13111467.html</guid>
<description>&lt;p&gt;在网络的传输层协议中, 存在着两大悍将: &lt;code&gt;TCP&lt;/code&gt; 和 &lt;code&gt;UDP&lt;/code&gt; . 从前, 我傻傻的以为自己对他们虽谈不上精通, 但还是知道的, 但是, 我错了, 我被自己问住了, 我傻了. 啥也不是.&lt;/p&gt;

&lt;p&gt;(这里为了介绍简单, 就不提数据在传输过程中的失真(纠错码)等情况了. 简单介绍一下, &lt;code&gt;TCP&lt;/code&gt;才是今天的主角)&lt;/p&gt;
&lt;p&gt;UDP 就是, 我把数据发给你了, 我不管你有没有收到, 反正我发出去了, 任性. 就比如我要给我的女神表白, 但是我又不好意思, 所以我托我的好兄弟马六帮我给女神带句话, 但是这个马六也脸皮薄, 他又找周三转达, 就这样虽然历经波折, 但最后还是顺利的将话带到了女神那里. 在这个过程中我做了什么? 我只是将消息送出去了, 仅此而已. 最后我满心欢喜的等待着女神的回复, 可能换回一句: 我们还是做朋友吧. 但还有一种可能, 那就是最终根本就没有送到女神那里, 中间转到周三的时候, 他因为自己的事情, 把这事给忘了, 可怜的我还苦苦的等...&lt;/p&gt;
&lt;p&gt;&lt;code&gt;UDP&lt;/code&gt; 虽然省事, 高效, 但是却不可靠. 因为我仅仅是发出去了, 但是我不确定你有没有收到. 不可靠有什么问题么? 上面就是个例子. 再比如, 咱俩聊天, 我给你发了一段话: &lt;code&gt;123456&lt;/code&gt;, 结果中间4丢了, 你收到的信息是: &lt;code&gt;12356&lt;/code&gt;. 这种还好, 如果快过年了, 我发给你这样一段话: &lt;code&gt;明天把你的猪宰了吧&lt;/code&gt;, 哎, 中间 &lt;code&gt;的猪&lt;/code&gt; 丢了, 那估计免不了一番腥风血雨.&lt;/p&gt;
&lt;p&gt;那如此不可靠的&lt;code&gt;UDP&lt;/code&gt;协议, 有什么用呢? 还真有, 虽然不可靠, 但是他快啊. 在一些对数据的可靠性要求不高, 但是实时性很强的地方就有了用武之地, 比如视频电话(我也不知道底层是不是 UDP, 举个例子), 打视频电话的时候, 视频要保证其连续性, 而且中间如果丢了一帧也不会有什么影响.&lt;/p&gt;
&lt;p&gt;但是在大多数场景下, 数据的可靠性还是要有保证的, 你从网上下载一个程序的安装包, 如果中间丢了一个字节的数据, 那可能就导致一个200mb 的文件废了, 根本不能执行.&lt;/p&gt;

&lt;p&gt;为了保证传输数据的可靠性, &lt;code&gt;TCP&lt;/code&gt; 诞生了. 还记得刚才我给女神表白的时候, 问题出在哪里吗? 没错, 就是因为我到最后苦苦等待, 结果她悲剧的没有收到我的心意, 伤心. 怎么办呢? 这次我想通了, 求人不如求己, 我要鼓起勇气, 我到她面前当面告诉她, 即使我多了一个朋友(没办法, 咱就喜欢交朋友), 也好过她收不到消息的好. 这下可靠了, 我确信她收到了.&lt;/p&gt;
&lt;p&gt;区别在哪里? 不是我到他面前, 而是不管她是否愿意, 至少给爷们回句话吧. 没错, 就是回句话.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAABcIAAARiCAMAAACwO3S8AAAA+VBMVEX///8AAABmZmbS//9AAAACAD0AOJb//9c6Ojrb29v/24S2trZ53f+bMwDnjRr/s1QGAGug//9wAAD+/6xJt/8AkOEAZrzCYgAAOmmt3P9tOAD/2rHCYS1HuN87OWkuZbzitYqHt9/b3LJtNzkAOzrc2v9mZzPhtVeXZDC9j1//2do6OwCt3txbkLpnZZMsZpQnZ2fnjF1cj+EAkbq8jyG3teCXZGXitLVakZG2t4t33dzS/9iRj7m9jo+PkWD/s4mbMjeItf+FuIyGt7fR/63CYWS1t1l4Yrw8NpUAZ5TnjI5uJXhAADyPkSVFuLd33rOs3p3a3IVZkmIteb4uAAA9vElEQVR42uzBgQAAAACAoP2pF6kCAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGD24EAAAAAAAMj/tRFUVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVYU9OBAAAAAAAPJ/bQRVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVWEPDgQAAAAAgPxfG0FVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVdipAxsGghiGYX/7L9015IacQICDAAAAANe8tg8ALxwq3o6Putf2wd95Oz7qXtsHf+ft+Kh7bR/8nbfjo667U7cMvHAiujt1y+DAaW9U0t2pWwYHTnujku5O3TI4cNoblXR36pbBgdPeqKS7U7cMDpz2RiXdnbplcOC0Nyrp7tQtgwOnvVFJd6duGRw47Y1Kujt1y+DAaW9U0t2pWwYHTnujku5O3TI4cNoblXR36pbBgdPeqKS7U7cMDpz2RiXdnbplcOC0Nyrp7tQtgwOnvVFJd6duGRw47Y1Kujt1y+DAaW9U0t2pWwYHTnujku5O3TI4cNoblXR36pbBgdPeqKS7U7cMDpz2RiXdnbplcOC0Nyrp7tQtgwOnvVFJd6duGRw47Y1Kujt1y+DAaW9U0t2pWwYHTnujku5O3TI4cNoblXR36pbBgdPeqKS7U7cMDpz2RiXdnbplcOC0Nyrp7tQtgwOnvVFJd6duGRw47Y1Kujt1y+DH3pn1Ng1EUdg3dsgGNmkSO4GkgQKlBGhp2ZEQvABC8ML//zNk5s6Ckwac8DLL+STw2K6jI83R6dX1TBqBtf1QCdydJ3eVARCBtf1QCdydJ3eVARCBtQ9UWdDt4Y5bOU2S3fSz6SzZZHT08P760Ll1MUuAZ25yVxkAEVh7P5Wrk/dvutS+yRHemS/2jvCcbqTJJoX4SBHv6wPwzE3uKgMgAms3Vdl5ctrNSDHhCM/FSHIysJzRxcDyLKlTUZlsUYlcVwfgmZvcVQZABNZurLIi5vh80BMFs6zCSYVuRbso1+0RYkTqj45ofE0fRfwq4HvANze5qwyACKzdWOWn1rtB75WMbNvzyImmQ1Gj9yyv6GXPktYjvCB62DUcD/9srOfUftGynKMi98JN7ioDIAJr76cy34hw2Uv5Vy981ZPcE4V7rVzn5BYZX3IRvnkTeOAmd5UBEIG1D4zw0ZF683i5TFQMX0Ott12sz9YxfdXT3FK3C1IVfbtleYAI98RN7ioDIAJr/1eEWzpn3eu4kD/9NuVnS7WQ5e0glYU8jc3LTHWqwKtNj9zkrjIAIrB2U5WXLcEdXSmfZnTc0lz9K/dL3WCpqDTxX5kiXAz06WrwOsWrTZ/c5K4yACKwdlOVFe2EE7rf2kYktamvKxqLkY5wMdYtmBup6qbYV5vB9lGIKCw3uasMgAisvX8VzmQ0rVfhBW0hM1rlsQxu3TJp36wV4WLUz0qzOkXm+iQJEhIE5SZ3lQEQgbUP7IVvZ2xBZa9OJSJcLzmRK8nvnomHxGh9uDvjprp667lKbYSvz74EutWeJCG5yV1lAERg7cMi3O6yzKczE+FJHRnhppViHuWeif2h21/FHU0RbAeFISYgN7mrDIAIrH1ohOeqA57pK7sbKbxg8Kkp2wt5w44L01JZphzhj7MyCRViwnGTu8oAiMDa+0d45+Tj6VKOZBvk9tCEcbeOTGrTSrGld04i/m3triO8opKr8LC/74qYYNzkrjIAIrD2Xip7c5KYFd63bDD3W1fJ5U99NjpappctfWardY5q2ywZ/RiKCDfrxM3nhluG6wwPxU3uKgMgAms3VXny5kFGiu75B1koi9p6vKNVLkYGVa6bYe0xGeHqYY5w8X/AZbjO8EDc5K4yACKwdlOVOTHT+490a+TlLaKFPFkNmPd36LsczKn9XF17ZB4vzdvM062d9+rrClWEB16GJ4hwANzHD2s3VdnPjt+9TvNaO4RooUN4N2NVeXfJ7qf/VdtMX9jymw/hL0whSRhuclcZABFYe//XmWZIbZnDPVGF7+aRWjo4FP9Uy1v3WWyE80Jzm92jo1D39kiICcJN7ioDIAJrH7q15xWRCtmqvUh2YpcOiuwuRYuE92LSxN7d2mAf9A57CTEhuMldZQBEYO3DIvzuHf1VsqZ8zmkDk/EyvOVPyPqbvzBFJraNcNX8thHez4Iuw3WGB+Amd5UBEIG1D4nwzlzEs+yI2K+dzem4VecOTWqrUTqfr5I50URdE4/ZCD/jU9sEny/D/rJZYvx3k7vKAIjA2gds7XmSEU1nupLuZ7rzMb72z/foxeNqSEud2+ZqEdMGewsx3rvJXWUARGDtpirtcu9+Ru2Frq5nMtX/GuE5iTu6/bK0d9XH1CM8j+dPPRDju5vcVQZABNZurDKnh92nJPfAP09Nj5te6J51TlvoKlwcdPulvtJ8YSNcVvXdjIJeEF6HGM/d5K4yACKwdgOVNq/Nznh7TfZDdvfCLbahUq/SbYQXJJhG0kcREOO3m9xVBkAE1m6ssjNY83rz4r3W+YyHl13bSNFXrmrno29pUmPFh6J7kZo9ns+SmCDGaze5qwyACKzth8pgIcbneXJXGQARWNsPleGCCAfAUfywth8qA4YkHs+Tu8oAiMDafqgMGGL8nSd3lQEQgbX9UBkyxHg7T+4qAyACa/uhMmiI8XWe3FUGQATW9kNl2BDj6Ty5qwyACKzth8rAIcbPeXJXGQARWNsPlaFDjJfz5K4yACKwth8qg4cYH+fJXWUARGBtP1SGDzEezpO7ygCIwNp+qIyA3+zdYUqcQRgEYfv+lw465PuTEDSI2zVdzwkK3mYQWXZz8O7UWyYNTJtRuSAH7k69ZdLAtBmVE3zCpSaMaTMqN+QD7U69ZdLAtBmVG3LA7tRbJg1Mm1E5IgfrTr1l0sC08wdG951yoNbUWyYNTDuf5Vv/E3KQ1tRbJg1MO5/lW/8jcoDW1FsmDUw7bd7G5eCsqbdMGph2sN4ulQOzpt4yaWDaeXfTy85/63NQ1tRbJg1MO+8m/4rvfetzQNbUWyYNTPsflf7D5lVvfQ7GmnrLpIFp11XmIm//yydcejnGtBmVc299PiDu1FsmDUybUbn61hPu1FsmDUybUfl3A2894E69ZdLAtBmVXfKD+u/UWyYNTJtRCZVvUH+n3jJpYNqMytv5hEt1GNNmVA7yCZe+ZHTajMo9/i9c+prRaTMq1/iJFOnlGNNmVG7xc+FSAca0GZVTEr8jRXo9xrQZlUOS+E2FUgHGtBmVM5L4kw9SBca0GZUjkvjbmVIJxrQZlRuS+Av2UgvGtBmVC/Jg3am3TBqYNqPyfnnQ7tRbJg1Mm1F5vfzGu1NvmTQwbUbl5fIA3qm3TBqYNqPyankg79RbJg1Mm1F5sTygd+otkwamzai8Vx7UO/WWSQPTZlTeKg/unXrLpIFpMyrvlAf5Tr1l0sC0GZVXygN9p94yaWDajMoL5QG/U2+ZNDBtRuV18sDfqbdMv9ilAxOJoiiEodz+m15Y5r8aouZUEFANXDujss19CnbilkkD186o7HJPw07cMmng2hmVTe7p2IlbJg1cO6Oyxz0tO3HLpIFrZ1TWuKdmJ26ZNHDtjMoS9xTtxC2TBq6dUVnhnqqduGXSwLUzKhvcp2wnbpk0cO2Mynz3tO3ELZMGrp1Rme6evp24ZdLAtTMqs93TuBO3TBq4dkZltHsqd+KWSQPXzqgMdk/pTtwyaeDaGZW57lO7E7dMGrh2RmWu++ndiVsmDVw7ozLX/WveiVsmDVw7ozLY3XXvxC2TBq6dUSnuTtwyaeDaGZXi7sQtkwaunVEp7k7cMmng2hmV4u7ELZMGrp1RKe5O3DJp4NoZleLuxC2TBq6dUSnuTtwyaeDaGZXi7sQtkwaunVEp7k7cMmng2hmV4u7ELZMGrp1RKe5O3DJp4NoZleLuxC2TBq6dUSnuTtwyaeDaGZXi7sQtkwaunVEp7k7cMmng2hmV4u7ELZMGrp1RKe5O3DJp4NoZleLuxC2TBq6dUSnuTtwyaeDaGZXi7sQtkwaunVEp7k7cMmng2hmV4u7ELZMGrp1RKe5O3DJp4NoZleLuxC2TBq79x17drDQQRFEQ7iYqUcTxb+3gShBc+P4vZ+yFYHBj0oG6OfUtsgyVuYdJjUpx78QtkwKmXaNS3Dtxy6SAadeoFPdO3DIpYNo1KsW9E7dMCph2jUpx78QtkwKmXaNS3Dtxy6SAadeoFPdO3DIpYNo1KsW9E7dMCph2jUpx78QtkwKmXaNS3Dtxy6SAadeoFPdO3DIpYNoTKyv83LK4a+KWSQHTHpWwb1Klp8stkwKmPauy9xq/tyru0+WWSQHTnlTZfYX/Br1Ta0FlUsC0p1R23+D7kHf6FlQmBUx7VPoGx+M+X26ZFDDtUekLHI/7hLllUsC0R6VvcDzuI+aWSQHT/qk8+Qv8/brpDNfELZMCpn1E5dKv/vEGf3rsz22apd8/tD1vH5vdx/rXv8emHezu5XX3+bld27Bs14O+7Obi8vY818Qt0xd759qcNBCF4RxCTCBcFQhguUjrtbZaba2XcZzx8sFxnPH//xqXQ/ZlE4hZoCqh5/lCbuyewM6T7eEkFW7B0N5J4RrTzf51mOThDSr82ezdm4C82kLh/tHIMYiop0xJ3VULUy/n4pLG0G1EXTSR0Zb/JIh54Tr3jgNjDTS5zUwuggSdAo2m/Y1MEG7B0N4hStK02n8SYsdUeIMygBgz8J8+CsoU010ovEHwNTpocofTUsy56+htVbgVjNvZCkervAxzR9RZja1OMXfcRWtYAw18SkmwO4EoXBD+O8UY2ltHSZp6Ur/+m5LilLxSTI1zCLspnN25YHweVuZ5CZ6FQ5PL3Eqk/ItueFO8rVqmNK1Y4bCrqW1ki1xD4X4duxIKH1UU0zIrvPW8gjUQIVKDJlTfoBdhGD4te1/US10ULgj/n2IM7S2iZOmRhgW9eoAxPzYVfj9cQ91G4Z9Kb8PKJYsQbc5V3W/Do92464mehR9D0up9fhhzRN5ZyFy5uQrnPAoUzpeOdQrv8M5Y4W0Ha85RsICIgiTjWkLh3WXrkShcEP4/xRja2ymcNDzDLS05HyzEx+70r9tphQMzk0xElr8RNlIKRy4FW9TCg9UfPZs4DBPihLFflkwecVOw+TM1pb6kXkWh+jspMTVLhUeUBWf0eyo2Ubgg7CPFGNpbRUkapH4NL7GKqMNm6+UrfFom8mBdW4Vjonwx0WLmzu6HV2vrVqI+X1sQnN3PmezXr3eNzTByx1Lhs1DBKZKzMIUrCheEPaYYQ3uLKAmwe/QUdkgez8JNd1MnR+H+Eabg2yncEHMXByQUDjIm4cheg5lunM+Ek/tDnn2f/7rbej/Pcree2yVS/hyJKFwQ9phiDO3NoyTN3D1KzKw72BNpFCz8SeHTIVHfagp+gctEnOugcUnzinvPUzhcbx6SmQvHwT2jlpB1CzmbCh9zUGov0jK8lrhuiMIFoUgUY2hvGiVpFu5pkKHwHibWHfVSmYWXRD1T4TtMwSPKhvvIVTh0S3dmA8tZeEQJhft1bpCla11UiN9aReGCUCSKMbQ3jJI07WWeuIPaDZQ4nxrp40yF31dvRop6g1k4U6a+OQuPKFPhTZ3cRnQnZW9klQuvlpMKb/IeNq91UaFu6HVocuWKwgVhvynG0N4oStLcjSejl9T6SV0khE0jesG4dPbuLvXWKRxec51NgKExrUVTlgpXKwGdnBL3nFuREinbQ+HcKTfEvt0oF95YrUgXhQvCflOMob1JlKS5pxX+mLpsoEQC+Tp8XnH969Bld71wsxWOLbaY+fbYrf0BO/R7PTORgswId6livvOhTsZx947HOt2CDXFhjfd5qXA27E/qQLF2CkemxSuB4RqFe0EQnBKdqBe5O1MQ9oBiDO0NoiSNA4W71yxo6FIDo/sPHeemFQ6nchuxAN9nKRzBcOpGbWBlHhG1Bvn59251rvCLuCLl/Ge3SV3coWmrcI7yLa5wqNgxFP5PbrDH4yJv4zgXhAMd2ojSXuCOoXCkNDAtTld13LjC/dnHRxNe4kYXkXT9XIWzwb1aHPZjIm80n3AHWYxrzVabFR4h+8FehqRtFI4HpODzwYknFf66AjZMpKDVkzUf5/S05wB99bmF41wQDnRoI0prg6cUvpRp568rvHKEGhS2s3In93Lvh5urcO7PqyFsrmGZR5WFV7t35cQKH3GdSqvNZ84NZBYVVstGUaHezwEbxea8J50LB35lm++pgQ7SH7IoXBAOdmgjSmuBQ+EXbKKFm2FLfioI0rqKyc0ofPbmuEwxwfl7blS5EC3kK1zXP7IyuXuEnPlMb63wDk5aLbNuM4sKqwgToTRVmOxxY3VV4Tt9T7gwmKA2XxQuCIc6tBGlpcGh8NlQOypSr1pQvJqgdyMKR7K4/+ChNtbrOtHIsVT4+0hXMGISff8Y0+JxzVbhTXo5RNhLMT5AGaHKn5hFhZArThe3C3EoYXi5s8Jxe2rG9pEoXBAOdWgjSnuBs+sCTDP5sYTGX/G+vj3mAS+4OyocB4/fXrmGoSMiGNxmFl4tT1wHCgdQt5XC+TTS7+fmkf3m5rGGZ2zFj7xF+p5JP6kQTJ9bfk8W/1NiOliUCc15N9SPanFv2TgXhAMd2ojS1uBQz+SxllWDiC31b37OxCJ5/PaKZSKFgcJXW+WAgFdbr3AnSp0q9kDh6h1Ywy2d8cLg/tBQbXNe53IMhSdqYey/p+xb+KelmLMP9XSi/5aNc0E40KFNc+wFjtxvf8AuxDov3oDC/W+lVxYK9y9x1Yi80S4K58gmOqAT1KNkKDw124Ws9Svsi60N8x8XeWWsZefCUeJi/z1l/ce5BVwJzz+yluMXUbggHMbQRpTWBufqvIlrJpWHXKG3RuHARuFQUa7CuUfiZXb3tgqH6PISKVyRgkRKbyWqHqTN9sUaKtdxcuTFu6HwaulsK4WjySy82m/2znQ7aSiKwjkkMakDOFQoQ6EF7GAFxzqPP3Spy+X7P47hJGxjCpGu5Q1H2N+fFmxh4z18pCc393avKZ2ZwtNp+vMvVDghm1HaSLmiwEF+aoceXD70Lyp858W7qb9A4ZiZsXpLFwrPlse6q58A0HOZwjFzpaBwBNMdlcsUrmTTGMf4kMm1PSBtfQzc0ufGgx6fpSdkfz86/uKAwvGf9y8U7ik6eYcKJ2QjSxspVzY4aMCn6fy+cOLjjOaLL4GMIRIovHQiMyRdrvDoNNA+jp4exLoiJQq/08mf+dSj3uJkvJbIwC9ReDjfLbmXPGdd8GAQLqStAXAr1zqPVOCDnoiM9/2yTfbxmkrGqWz6N15GblY6FU7IZpY2Ul5O4FC4rvjdzprT4eCedxwHImAcT9teNDPWsUAyp7Xa22uvTkQKooKJS8/ZXQ20a5PO7WirtBcpHNvG3+modjEdMUcSLNIPAj2u778PZrNowIM/e+Hoa0PL+U+dKP3mDfLjwnl1c/ckmD1De94D6h/6xT8+JnjiYQevYoVxwistto9y/0SFE7KhpY2UlzE4HJXIBov+pW662xAlfpTsVuxDfIUFXxWIsLyFgF8ax2cqxMYEx7kij7StcUHhrTghEGnOD/YfB7KAXfRYjgMBuXTZGilZpp5kfXdExzOnr6mZqjT6qItVNbND8aH6W/ba2OdiRvipZMHb3RXHCb++dG9QbII3jjWUfuGMFEI2pLSR8rICzxabhZjUTbN9fJ5PzneKP6jcLdweP1naX1/W9FVBFu5TGxUVrkbVcIne1IfRaSwAze1cU2T4fhQrZ/jEyRSeyz3IrJ3L0e2E1+fzLP2eNDFpXffW7/pZzIdtDwxHes0T0HijGEzbl6ymBpwMneOWPlHESYWEbGRpI+XKBgeN+KH/+dDL8wLuyROteDEJTustfZDz4p0HulunKrB2mNv++L4+Zdo52bm4XF/G7Hh53yvj6miQT6fhsgUYwZ23uRvfb80vb8r9SG/v8ELwqf9vqgn9/EU6V3U36199NlIIqa600c10D1IW7+Mb0xYyY4WTmeijwOCyx0mFhFRS2veHr55rm1IVHvX2PbcgJQ1untIBgbWhcxg8PJJm0kz5RoUT4rC0o9OjOMBpNFV4uie7U5CSAjfP4iGBtfcOF/VU6hLu1mcLjf34SYUT4rK0W5LSn17byeYFRz1ctu4IpKTBzVM2JlE62Tw37TElUfeuzjjHYorD7AsVTsi/Le0PtWQOni47mrs4o66zGtyBlBS4ecpHRS93Cid+tpItuJcUEWekEFJRadcLCnfdS0FKGtw8GJZSideK21hA4VzmipDqFI4LXB4PPIcgJQVunr8PTHSMWfILFH7SRxNcb1HhhDhWuHuQkgY3zwoj0z2RGYN7RYVz70xCHJf249qMjoQ15SiQfm3OE88VSEmDm+evQ3O/JyJXTgOVOBVOSKWl3ZLlND1XICUFbp7lg4N1V3T1ryiTOBVOyHqOwpVA9qo8CqfBzVMyOtHBSGS+1i8k7lPhhKyrF16+5KoLhZP/Aa8AVrEVXNuDeeLhPhVOyBoUrrSkmd6DdQBzUOHbyuIVrkTGE78g9pHcvEWFE7IGheN9h30Xi1Dh24q3gIbuHnGBg/a8RxcPPBCd9KlwQlwqPBq+OxpkMr9ze8GKhVT49uJZxG4yQqot7Z2epDR1nSvsnOsOpKTD/ws8i9hNRkhlpT18PgokI56+1ivssSdYAb4BtxG742Q3GSGVlXZdFGzRm+j76Q3sCeYOpOS70Dh2RWk3GSGVlfbVoP/y3NcOeO5an8q2fODb0Dx2R8huMkLWcDoT30q4i40fXYGUhlutxLgo7SYjZF0Kj57JfJnZVujwWBwpLZ8uI7ZFaTcZIWtSeLcjIvq94+s0kZKH4daxOz52kxGyFoXr5dF3dRdb18vOIiUdbh27w2M3GSFrULguUjS7rL4l4fVsF01nICUdbh27o2M3GSEVl3YrUfjVQLT7rZdmttFbAa5Ssh1uG7uDYzcZIdWVdl3G8ZmuDd6YZM5OZC6PAqetcKSkw61jd2zsJiOkitKGrxPQNMF9bi+xR0o63Dp2h8ZuMkKqK+3oWsJ58c6D2rTtOQUp2Q63jd2hsZuMkC0o7TQlHW4duyNjNxkhW1DaaUo63Dp2B8ZuMkK2oLTnKdkOt43dcbGbjJAtKO00JR1uHbvDYjcZIVtQ2mlKOtw6dkfFbjJCtqC005R0uHXsDordZIRsQWkjJU9pmsbuoNhNRn6xZwc3cgQxEAT991qAiNZfv5ytCAtymwRxmGNgta/SDa/rzqRbBgOrfZVueF13JN0yGFjtV+lzeFt3It0yGFjtq3TD67oD6ZbBwGpfpRte151HtwwGVvtV+hze1p1HtwwGVvsq3fC67ji6ZTCw2lfphtd1p9Etg4HVfpU+h7d1h9Etg4HVvko3vK47i24ZDKz2Vbrhdd1RdMtgYLVfpc/hbd1RdMtgYLWv0g2v606iWwYDq32VbnhddxDdMhhY7Vfpc3hbdw7dMhhY7at0w+u6Y+iWwcBqX6UbXtedQrcMBlb7Vfoc3tadQrcMBlb7Kt3wuu4QumUwsNpX6YbXdWfQLYOB1X6VPoe3dUfQLYOB1b5KN7yuO4FuGQys9lW64XXdAXTLYGC1r9INr+u+f7cMBlb7X6V/aaZ1379bBgOrfZVueF33+btlMLDaV+mG13Vfv1sGA6v9Kn0Ob+s+frcMBlb7Kt3wuu7bd8tgYLWv0g2v6z59twwGVvtV+hze1n36bhkMrPZVuuF13ZfvlsHAal+lG17XffhuGQys9qv0Obyt++7dMhhY7av0Z3hd9927ZTCw2n8rf+5X/Z7uu3fLYGC1/7vyCz/qB3W3qVsGA6v9jUq6c+qWwcBqf6OS7py6ZTCw2t+opDunbhkMrPY3KunOqVsGA6v9h106oAEAgEEY5t/1bYy8VbAENirp7tQtgwfX3qiku1O3DB5ce6OS7k7dMnhw7Y1Kujt1y+DBtTcq6e7ULYMH196opLtTtwweXHujku5O3TJ4cO2NSro7dcvgwbU3Kunu1C2DB9feqKS7U7cMHlx7o5LuTt0yeHDtjUq6O3XL4MG1Nyrp7tQtgwfX3qiku1O3DB5ce6OS7k7dMnhw7Y1Kujt1y+DBtTcq6e7ULYMH196opLtTtwweXHujku5O3TJ4cO2NSro7dcvgwbU3Kunu1C2DB9feqKS7U7cMHlx7o5LuTt0yeHDtjUq6O3XL4MG1Nyrp7tQtgwfX3qiku1O3DB5ce6OS7k7dMnhw7Y1Kujt1y+DBtTcq6e7ULYMH196opLtTtwweXHujku5O3TJ4cO2NSro7dcvgwbU3Kunu1C2DB9feqKS7U7cMHlx7o5LuTt0yeHDtjUq6O3XL4MG1Nyrp7tQtgwfX3qiku1O3DB5ce6OS7k7dMnhw7Y1Kujt1y+DBtTcq6e7ULYMH196opLvTsUsHNAAAMAjD/Lu+jT20CpZAtwwGrv2jku5O3TIYuPaPSro7dctg4No/Kunu1C2DgWv/qKS7U7cMBq79o5LuTt0yGLj2j0q6O3XLYODaPyrp7tQtg4Fr/6iku1O3DAau/aOS7k7dMhi49o9Kujt1y2Dg2j8q6e7ULYOBa/+opLtTtwwGrv2jku5O3TIYuPaPSro7dctg4No/Kunu1C2DgWv/qKS7U7cMBq79o5LuTt0yGLj2j0q6O3XLYODaPyrp7tQtg4Fr/6iku1O3DAau/aOSY5cOTAAGgBAG8vsvXUo7RNTcBAHl7sQtkwaunVEp7k7cMmng2hmV4u7ELZMGrp1RKe5O3DJp4NoZleLuxC2TBq6dUSnuTtwyaeDaGZXi7sQtkwaunVFZ6O46duKWSQPXzqjsc6+Knbhl0sC1Myr73KdgJ26ZNHDtjMo+98vfiVumh12za04TiMLwvrAEEMWv2jgaP9uYxKZpbTuZ9qrTu/7/X9RZOBSBLCE6TNhwnrtVWd8Z33k8s8C0oNpmpHyDgDD+d2puMoZpQbWrpOxIpysqEeK9OJM+BkOR58yAbk+faz7ChS1eARCmt6m5yRimBdWuR+H7IOVaVGG//fXowenGCnevFoJwbz3iiy3GH7x0daz9kxXekWTwVwCE2W1qbjKGaUG1X6Bw99HS8WBnFd5HyjtRjnu38ySISazwEJik+o1Rqh2PQGTEG6prTlJ4X2J676dcx9tpUJvU4XCj29TcZAzTgmpDcey6onpJ4cqfOgbDrMI7VoKkfUq4RMzyIfDVl0VTeORoirRQcl3LSOGDez9ZHe9AqxcqvCjrC7tGhesdbnKbmpuMYVpQ7RKFl0/hM2B6NIVrBm+397zCf1s/A/8HWTj5shCYDo936JDC1Yu0EldeDAAvy7KbU/hEFJn3gI9eSqLwefAEvToULkAY3KbmJmOYFlQ7l3Lvx2xHeYXnGI+yhxcnK5wIcwqns5RyhV9Ch1NB4TcSziITQT/Mu7cAVvRuLRI3tk3NTcYwLai2JqUS6cEjPkXD6ip/+jHR3848Q+HjEen3sBLPKXwbRNxJ53OQw87+3xTDzmfAtJtdT4SGtQScjagFEKa2qbnJGKYF1c6nXP/5/2hfWHIQ3KeJtUaFE3qFlz+H2JHQQYftaqo+/I23UWsSepHkwzUBwtA2NTcZw7Sg2pQyY0MyqusTa+lsfN/O+pFEe77CD3S07lgRO4mllfBN7RCvd4gU7ny1klXhbmZ1hatrpptoPFeXujcS+K5z9HoG9eH6QIKRbWpuMob5x965PicNRFGca4KBoglVQghQ22KR+iq+6hNfHxwdv/j//zfO3hxyk8BOxBnNZnZ/H2wCa3Pa3jndntzdWFDapNjt3Ugo1vSFYxTe11l48udNhQnpGdc2FepvVvaFM59uVjoHg4G3XdjzQRn4JG1kCg4ItLGazFXmcFhQ2qQoT15HmDxrLByue1HOxqPyNFd8+ZBZOOPTRGbhdU2FkPxyUOS6ariRkqRd2kO6STY8Hvb+TyHQwmoyV5nDYUFpQ2VlmQw3Z3ee+6NdC0fD35TGneD1ud7C48OzcJlTH5SFh5oudSHR/iaZXbKBr3q9E53FI2H5xxBoXzWZq8zhsKC0obIcpcBQEzZDsXCxzOETNSohWqfl3CKhl5xUwMI16CycSRDGhJO01sIxgHgKD6Zi4TKiJyG98OihzwaushKNg+Ovkv8BgbZVk7nKHA4LSpsUO/NOngmr5HlcsXA4+DEb/dGUip3VS8nQ/97Ckadj85I6C8fAt3dEICsToP8XRgizTxyhrFPVTtg96W9pwMIBgZZVk7nKHA4LSnuPypCzCByNqhY+JxqmMMrgFSEphqvusfC7G+9PLTxYfHxwykeydKjewkPObcY6z0XHCkbISp0sAvd4hU+RUQMWDgi0q5rMVeZwWFDaVZVIJsY4YjstWHiQsINnFo4FMd2nXpaG77NwxOp19OeUMcZWhbcJ1yw1FR75laZCKIkwGpJ3XRgjitH9ZOMhDJcmRr8hCwe0pU3VZK4yh8OC0q6qhL/FcgQLlyWNxzBO6bmbpGLh68Fg8OQQC1+8vu8T6F2956sFt+Gl5aZCZahylkscQU5+WoIjfYwQ+tglsbTIfk4UNxSkAAItqiZzlTkcFpT2PpUJyRS4+6Jg4SufrRMWLibHNhipVxJMpWHhcPaaCIWQaixxTZXF8/1FSDjfthGq/ESaCst/KGzjFugCMHX5UGL1uNgxGGDTgGYsHBBoTzWZq8zhsKC096iMCpPcRx6y8MoiF1g4gmWOrUOKedEjt3PDwmse5AOTvPf22gvF6RMiOLgsuEf6HfEonJX+YkhIDUOCLmABpowocIa7scviJinNWTgg0JpqMleZw2FBaVdUog9lRXtWZ4bsePv6Pp5/RTNgbt0h5aE1xYd0pOA6ozzswB1MWDhfFWfQwW/zQTqbVm1aQnWx9zxC4V9IwZzfx76FzVu4mHhLqslcZQ6HBaVNit3oGFNWsXB2w5upvnWP42u2cPjllskxBny78aLWwtHlgnui3ROYdbnhBWfSM4Mrdv38rByOzNLy1lyQu06zEUPVWMiRihEW3iHQjmoyV5nDYUFpV1TCFCV+EAsHVQuXQViViQFvBhlPCgPiWgtnL6W8IzxGEAPTRoMhzqR5XDL50b7mmpU/TPGliU0ffV/mY4YPiLe5MsTCOwRaUU3mKnM4LCjtqsqIaIyP8UEWHtHNSxpOtTYtbX1aC0fcHivbRAqOaAamDSE4Q0oityZ3NjuZTdHHgghljiiozGefNFNwuQv6nyHQhmoyV5nDYUFpV1RK2JDcTA+y8ITG3P8X10Yl2nc5n56kuPPI7YjwcZg2PgXOCs+dCNjAT+dEdHGCIdJAI19VSIhPCpn4Yzi/RpeS0gAEzK8mc5U5HBaUNik0W/rhOWwL3DLUWbgEDuzh9zbX/QILzlIQi2jACsojvqOIO48pu3r2T5B5/Af5FFH2HtYXXfrquuk2hrl37vGr0kATsofD1el0uZ2lK//WGPjDGzc2g3eX/A1pAgLGV5O5yhwOC0obKjXz7Uj27a6xcF5TCYusMpLmwH2EdNF7zNeInnqSaz/zKc7zcBYR8jWCL/yk4jGm4gv2bwQh3Cmo6H5VSiQ1SfIEZpqZcn/wupeNPF1qVIG40wwETK8mc5U5HBaUdkXl2a19j75Ze1oLlxfi7cz2Qa/Mj2P9Eh+5yPC4+pqKMGZT5b0R8YR6jsdR5H0uMw8ji+HI4r6ye6Vwkoq8ZX40V1dCx0z3KtVH98zFi05T0Bazq8lcZQ6HBaWtVylJCltvXRb+piZvCLXT2YAf01B98ewG2+vdTUf4ydcI8OAdMJ+c7/zfK69uf62IelfXXsdsCBhdTeYqczgsKO12qLQVAib/nMxV5nBYUNrtUGktBAz+OZmrzPGbvTvGgRAGgiDo/f+nLziI2XDG3fWCljyyEAEIMO2OSrD5yz2n3DIJMO2OSjKvcGkDOu2OSjSvcGkBOu2OSjavcOkbdNodlXRe4dIX6LRHRU6g2DCJMO1Rk5MntUtCTHvU5ORJ7ZIQ0x41OXlSuyTEtEdFTqDYMIkw7Y5KtOwb3AXpVh3T7qgES38Id0G6Vce0Oyq54t+juCDdqmPaHZVU45cKpSXotDsqocbvhUtb0Gl3VDL54zVpDzrtjkqieYWfU26ZBJh2RyXQPOLPKbdMAky7oxJnXvnnlFsmAabdUUkzj4Zzyi2TANPuqGT5sUsHJhJFUQhDsf+ml2X+68FccyoIaB7ETr1l0sC1GZVT8jB26i2TBq7NqBySh7JTb5k0cG1G5Y48mJ16y6SBazMqZ+QD2qm3TBq4NqNyRB7STr1l0sC1GZUb8mHt1FsmDVybUbkgD2yn3jJp4NqMygH54HbqLZMGrs2oPC8Pb6feMmng2ozK6/IAd+otkwauzai8LQ9yp94yaeDajMrT8jB36i2TBq7NqLwsH+pOvWXSwLUZlXflwe7UWyYNXJtReVY+4J16y6SBazMqj8pD3qm3TBq4NqPypnzYO/WWSQPXZlRelAe+U2+ZNHBtRuVBeeg79ZZJA9dmVJ6Th79Tb5k0cG1G5TV5DuzUWyYNXJtReUw+J3bqLZMGrs2oPCXPjZ16y6SBazMqL8nnyk69ZdLAtRmVl+TnzE69ZdLAtRmVl+TfoZ16y6SBazMqT0lyaafeMmng2oxK9e7UWyYNXJtRqd6desukgWszKtW7U2+ZNHBtRqV6d+otkwauzahU7069ZdLAtRmV6t2pt0wauDajUr079ZZJA9dmVKp3p94yaeDajEr17tRbJg1cm1Gp3p16y6SBazMq1btTb5k0cG1GpXp36i2TBq7NqFTvTr1l0sC1GZXq3am3TH/s0gENAAAMwjD/rm9jD62CJcDAtX9U0t2pWwYD1/5RSXenbhkMXPtHJd2dumUwcO0flXR36pbBwLV/VNLdqVsGA9f+UUl3p24ZDFz7RyXdnbplMHDtH5V0d+qWwcC1f1TS3albBgPX/lFJd6duGQxc+0cl3Z26ZTBw7R+VdHfqlsHAtX9U0t2pWwYD1/5RSXenbhkMXPtHJd2dumUwcO0flXR36pbBwLV/VNLdqVsGA9f+UUl3p24ZDFz7RyXdnbplMHDtH5V0d+qWwcC1f1TS3albBgPX/lFJd6duGQxc+0cl3Z26ZTBw7R+VdHfqlsHAtX9U0t2pWwYD1/5RSXenbhkMXPtHJd2dumUwcO0flXR36pbBwLV/VNLdqVsGA9f+UUl3p24ZDFz7RyXdnbplMHDtH5V0d+qWwcC1f1TS3albBgPX/lFJd6duGQxc+0cl3Z26ZTBw7R+VdHfqlsHAtX9U0t2pWwYD1/5RSXenbhkMXPtHJd2dumUwcO0flXR36pbBwLV/VNLdqVsGA9c+9s50OW0gBsAW2HUIBHpwhoQSSHqE9L7vc9qZdqbt9P0fpit5F4Ft8OD2h9zV96PFsGvUseZjK7SmGlEqcq+T3MgUxYPUrkaUitzrJDcyRfEgtasRpSL3OsmNTFE8SO1qRKnIvU5yI1MUD1K7GlEqcq+T3MgUxYPUrkaUitzrJDcyRfEgtasRpSL3OsmNTFE8SO1qRKnIvU5yI1MUD1K7GlEqcq+T3MgUxYPUrkaUitzrJDcyRfEgtasRpSL3OsmNTFE8SO1qRKnIvU5yI1MUD1L7L6Kswj/vv0FuNsmNTFE8SO3SUQIR/Cs6cKke7MR+eNrlo50mRq2gmKO9h4Ec5GaT3MgUxYPULhklWIJrVyGNFWRjFaPnuOm4CJC4MWverk2u5Cg8vrWXx701ybchY2KayYOvzXOndmhiIW3oBXE9EILcbJIbmaJ4kNqlogQoVvh+CCv0Vp/or87q5in8AHKwI3gMH2dm0mB6l+zUNly+Emwhnr2Zh1HLKDw+GI4CGcjNJrmRKYoHqV0iSmACo8k1H+ITVuG4BAY43TNYhUf3a4YF9J1ph7W7zVG+wo8bCY/hkX10k0fYj4geH6VnTkNS+OWLxvJoySDP/R1AopdHC0h4SArHzyMRyM0muZEpigepDUhpgW9QOAs1eTxIFG5G4ut4ENd5YK7Cu1zOSI3YUg7hmfukcIrNHmFxOwEA9taZtPB05pWoNSCTn9RtIWUAUTeQgNxskhuZoniQ2jtGCYwzNq2tmRvhdoV3gP5i1z9rIo9h+Ike1AsVzmvp3RQ+gE1EqPCeGRG14jOaZt8ZHa4Kr2pkiuJBagNSwuC86IY0WxROju3zcj1b93bPTWoJhzC0j+bsbK6j7KLwWZO4HUZ3minqS4UHASscA40bgQjkZpPcyBTFg9QGpJTACVdvZmbGzPxiRuHc0ccKn5Cgo5qBXt38dSbO37KW3qpwgv8bkCJf4XKQm01yI1MUD1IbkN1rKMTWWnj8FIsqkHyDyQpP6h9js/J9kayGX5F0bZkkPnAKf9RMuAX37KPHxQrn9fsNM5iLPHS0rQLDCqcPIfpUegz9BiJjGS43m+RGpigepDYgOwu8YBWeqbA4hZtnSdht9u7LjMKLa+Fk8m5qq05RUyGP6AUbFf4xhBRCelLkZpPcyBTFg9QGpITAC2vh8TO70DYcLBXeTmQ6paUxLtHvXuyscO7t5spIcVMhC59W+MyT+qrCTSvkImmFDG3jykQVXtHIFMWD1AaknMCLO1K4Ft5NFL78MpN3V8a7FVII6kzMrYwU18LbkILG5NTCO1oLr3hkiuJBagOyu8BZ4fPJlfQTmxUe3AToO9luVXgONIKbwjM6L1a4O3VUW3K4ReGXxGyvl5xNciNTFA9SG5BSAi+Gm06cwlGM0HMFjejT640Kn9TSzGHFw1mdFyvcve1z7pnhHsd8heOf10WIXG42yY1MUTxIbUBKr8D38qECMsuQFc71E7vRppev8Ft73cC2tYyWquZ7VfGXmVxHKVQ4F9EHpG0+U67Cz2hSfCCknCI3m+RGpigepDYgZQROrtvS4Lfvvhg0ACucpGjnRm8BehmFF9wXlq2d1XmqqdDMTjcV0rvTup2X81mFR78X0Kd420IaUgRnk9zIFMWD1AakbAkl17asVsYpnBtI2nDf1DPaAMfZ3ZkMzWH41MOTTE0l21TIISzHdDAU8jgfrik8fvZ0AUj/s4mP9oCKQG42yY1MUTxIbUDKCJylOWmlFe7uF/4ALmFX34wLKXYgrnR/GkUaaf44gIhb+EjhbdiA9Xl8BACnx67BpLsWTXTi2gixfsJNhSx8t3Knv/t5feHRvQs61aerQsookrNJbmSK4kFqA1Ja4KzurMLtHvV0LZx292Ap5DMqPB6lCilbFc7fZ94OAaI7dZZw+la3Rtr2nFwL5y9TBxC1KBIKiRWOG43uf7Ql9EHyoSEDudkkNzJF8SC1Adld4Axt1iFNpqohvBEyzqzCsYDhbHve4I07dEDwCVLvtCbxWsiS5f3+rPB+wAqn89Hw5MFofGgDze9ICdrG4FJ+8UFwNsmNTFE8SO2cKHcQOK1kr7sC9Sn3o/CS2P1NCnc9IUau2+4XnukX5DU9E98M07VzljX9PYAeP8tVFxt2FNKRxd0vnBVuDT/+ehYIQG42yY1MUTxIbUBKC5ysmFtIcbJeU/iNCbZ3o76/XylSOM1bezLpBWTGtwC5fpYt3ZC0afG/PKK/YLU/HKJu5ld7WOH4AZHcWlHEDh+52SQ3MkXxILUBKVFDYcvS2pUVni2DsMK/ADIkrxcpnCxrR/DpmPMjLI7fDtclPoDeUtocER7xflDk5oIiOeH3T37gzRVj8ONheAhdMfvs5WaT3MgUxYPUBqSMwLnDY2AkWs8onDfxUAmF/vx1wxRZTupBkcJd2wkPcF+DOqaHABAdm2EscT5nIm1XO+df7bF+j0ng15O+ljrXwrme/iXEsXSCtoy2QrnZJDcyRfEgtQEpKXD6ackWyRYmb0PTzsdcULNI/KbZbEwPyaUk8oRihZ8fhQDDEb1Jg/w8Plj2FE7nAElDisFJnA5IunHy4BWv2juJi6Gf1F9CjHdE1W5D8ply3hytNqMPhiN79xUhv7wmN5vkRqYoHqQ2ILsKnNfg5DeqG6fojbFjz4wgusEuCp+9DZ2iad7ynE7AXAPhPvHo2NVa2oD0k0p8/J52h/btUnyWTB+OeDFviD4ElndmNHe5tAEWQrZnys0muZEpigepDUgpgZPhjpfWne8RC9dWmBRW2tSgchLspPABC5zGscHt9svT5EVmPCftjg/xlB2gVfkR9Olky/L72P3oz70Rz5zNgQS/9ma9lUiE3K9QbjbJjUxRPEhtYHYOOH5/HGymkypA7NNtabN3peWbWPErz0cBc94g3EAqfGSYjmjm64D5lrSAm6ln/OSRXb4z8fRunQ/w9/RXhk9rd0QYXHA2yY1MUTxIbXBUI1xvkXt5/rBjxzaSBEEMBHf8d/qFwsh3r+UeIywgQKIa6G4yGJj28z/c+9+bWVM3GQxM+/kCH8Jr6iaDgWk/fMVb0c3XTQYD0374WeCt6K6pmwwGpv3wPT5F3WQwMO3n5fr3fYq6yWBg2u3z4K1wwuF3Rqcdvw8/GHsrPkXdZDAw7fqB+JuccMj7jmnnLwTxNXWTwcC0L6UbXtftp5sMBqZ9Kd3wum493WQwMO03pRPe1q2nmwwGpn0p3fC6bjvdZDAw7Uvphtd1y+kmg4Fpvyl9h7d1u+kmg4FpX0o3vK5bTTcZDEz7Urrhdd1muslgYNpvSt/hbd1muslgYNqX0g2v6xbTTQYD076Ubnhdt5duMhiY9pvSd3hbt5ZuMhiY9qV0w+u6rXSTwcC0L6UbXtctpZsMBqb9pvQd3tYtpZsMBqZ9Kd3wum4n3WQwMO1L6YbXdSvpJoOBab8pfYe3dRvpJoOBaV9KN7yuW0g3GQxM+1K64XXdPrrJYGDab0rf4W3dPrrJYGDal9INr+vW0U0GA9O+lG54XbeNbjIYmPab0nd4W7eMbjIYmPaldMPrul10k8HAtC+lG17XraKbDAam/ab0Hd7WraKbDAamfSnd8LpuE91kMDDtS+mG13WL6CaDgWm/KX2Ht3V76CaDgWlfSje8rltDNxn8Y8eOThuIgiAI4vyTNuahAPzXq6mKoHU7HOIGpv0qvcPrulfolsHAtD+VPoe3da/QLYOBab9K7/C67hG6ZTAw7VfpHV7XvUG3DAam/an0Obyte4JuGQxM+1V6h9d1L9Atg4Fpv0rv8LruAbplMDDtT6XP4W3dA3TLYGDar9I7vK77/LtlMDDtV+kdXtd9/N0yGJj2p9Ln8Lbu0++WwcC0X6W/4XXdp98tg4Fp//z5ot/zrbpPv1sGA9P+R+WFn/O1umvqlsHAtG9U0r1TtwwGpn2jku6dumUwMO0blXTv1C2DgWnfqKR7p24ZDEz7RiXdO3XLYGDaNyrp3qlbBgPTvlFJ907dMhiY9o1KunfqlsHAtG9U0r1TtwwGpn2jku6dumUwMO0blXTv1C2DgWnfqKR7p24ZDEz7RiXdO3XLYGDaNyrp3qlbBgPTvlFJ907dMhiY9o1KunfqlsHAtG9U0r1TtwwGpn2jku6dumUwMO0blXTv1C2DgWnfqKR7p24ZDEz7RiXdO3XLYGDaNyrp3qlbBgPTvlFJ907dMhiY9o1KunfqlsHAtG9U0r1TtwwGpn2jku6dumUwMO0blXTv1C2DgWnfqOSXXTogAhAAYhgG/k1jo+MTBb3bujt1y+DAtTcq6e7ULYMD196opLtTtwwOXHujku5O3TI4cO2NSro7dcvgwLU3Kunu1C2DA9feqKS7U7cMDlx7o5LuTt0yOHDtjUq6O3XL4MC1Nyrp7tQtgwPX3qiku1O3DA5ce6OS7k7dMjhw7Y1Kujt1y+DAtTcq6e7ULYMD196opLtTtwwOXHujku5O3TI4cO2NSro7dcvgwLU3Kunu1C2DA9feqKS7U7cMDlx7o5LuTt0yOHDtjUq6O3XL4MC1Nyrp7tQtgwPX3qiku1O3DA5ce6OS7k7dMjhw7Y1Kujt1y+DAtTcq6e7ULYMD196opLtTtwwOXHujku5O3TI4cO2NSro7dcvgwLU3Kunu1C2DA9feqKS7U7cMDlx7o5LuTt0yOHDtjUq6O3XL4MC1Nyrp7tQtgwPX3qiku1O3DA5ce6OS7k7dMjhw7Y1K3rYHfmfj2huVvG0P/M7GtTcqedse+J2Na29U8rY98Dsb196o5G174Hc2rr1RCXzs1jERAAAIxDDwbxoJzDyJiF5ZPPsmDwUg4QCB+o4CQMIBMvQdBQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAw7MGBAAAAAACQ/2sjqKqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqoKe3AgAAAAAADk/9oIqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqrCHhwIAAAAAAD5vzaCqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqwBwcCAAAAAED+r42gqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqirswYEAAAAAAJD/ayOoqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqgp7cCAAAAAAAOT/2giqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqtIeHAgAAAAACPK3nmCDCgAAAAAAVjDdtf4TJ1dWAAAAAElFTkSuQmCC&quot; alt=&quot;image-20200612230118536&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;如果有这样一种机制, 每次我发出去的数据, 如果对方收到了, 就给我回句话, 告诉我收到了, 那消息就变得可靠了. 我发出去的所有消息, 都可以确信对方已经收到了.&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;如果数据中间丢了, 对方没有收到怎么办? 没有等到对方回复, 我就重新发一遍就好啦.&lt;/li&gt;
&lt;li&gt;如果对方的回复丢了, 没有收到回复怎么办? 处理方式同上, 对方收到重复数据, 把重复的数据包丢弃再回复一条就好啦.&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;一个来自灵魂的提问, 现在的数据发送可靠吗? 我觉得是不可靠的, 现在仅仅能够保证一个数据包, 我百分百的确信对方已经收到了. 那什么样的连接才是可靠的呢?&lt;/p&gt;
&lt;p&gt;我要发你100个数据包, 那这100个数据包你每一个都要能够收到, 并且要按照顺序将他们再拼装起来, 我觉得这样的连接才能称得上可靠. 这里面涉及到了两个概念, &lt;code&gt;确保收到&lt;/code&gt; 和 &lt;code&gt;顺序&lt;/code&gt;. 确保收到我们已经做到了, 如何保证包的顺序呢? 我把要发的数据排排队, 一个一个发就行了? 天真, 如果有包1在网络中某个地方喝了杯茶, 睡了一觉, 结果接收方先收到了包2后收到包1, 顺序就乱了. 保证顺序的方式其实很简单, 在每一个包上, 都加上一个序号, 接收方按照序号从小到大把收到的包组装起来就好了.&lt;/p&gt;
&lt;p&gt;经过改造, 现在已经基本能够保证传输的可靠性了, 到这里, 有没有发现什么? 现在和&lt;code&gt;TCP&lt;/code&gt;的区别就是少了&lt;code&gt;三次握手&lt;/code&gt;和&lt;code&gt;四次挥手&lt;/code&gt;(不仅仅是). 那&lt;code&gt;三次握手&lt;/code&gt;的意义何在?&lt;/p&gt;

&lt;p&gt;今天在接收了身边大神的一些思想之后, 我还是没有太明白. 不过现在, 我貌似明白了些什么. 要想知道三次握手有什么用, 就需要知道三次握手都做了什么事情.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;1. 确保对方能够正常接收数据, 测试连接&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;还是上面的例子, 我去女神面前表白, 但不凑巧, 女神正在午休, 我站着旁边傻傻的表白, 还是没有用. 所以, 在开始之前, 我要先确保女神能够听到我说的话, 我得把她叫醒, 庄重的告诉她. 而这, 就是握手的意义.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2.建立系统开销&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;在发送 UDP 包的时候, 因为其不可靠性, 所以基本不会用其发送很大的文件, 因为将较大的数据拆分后发出, 中间丢了几个数据包就尴尬了. 而且 UDP 也不能够保证包的顺序, 还是一样的原因. 但是 TCP 就不一样了, 它是可靠的啊, 你可以将多个数据包分开发给我, 到我这里, 我再把他们按顺序排列好就行了. 而这个按顺序排列的操作就需要专门开辟内存空间来保存收到的数据包了, 当握手成功后, 我就会为你留下用于保存数据包的内存空间及其他一些系统资源.&lt;/p&gt;
&lt;p&gt;而如果没有三次握手呢? 客户端发送的数据包, 可能因为某些原因(比如路不好走), 在网络中待的久了一些, 客户端因为没有收到回复, 已经放弃连接了, 但这时候, 服务器收到了这个数据包, 开辟系统资源, 返回确认包, 然后就没有然后了. 客户端已经放弃了, 根本不搭理你的回复. 系统的相关资源就白白浪费了.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;3. 测试超时时间&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;上面说了, 当我长时间没有收到你的回复时, 我就认为你没有收到我发出的数据, 那我就需要重新发送了. 那这个&lt;em&gt;长时间&lt;/em&gt;是多久呢? 可以在握手期间进行测试, 测量请求包的往返时间,并依此计算重传的超时时间.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;4.安全性&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;这个确实是我没有想到的. 因为 TCP 会将数据拆分后发送, 为了保证数据的有序, 就要给每个数据包进行编号. 然后接收方根据编号的顺序对收到的包进行重组, 保证了数据的有序.&lt;/p&gt;
&lt;p&gt;如果只是简单的123456, 那大家都知道了, 我黑客小黑, 也给你发一个编号为1的数据包, 不就把你真实的数据包给偷偷替换了么? 为了防止序列号被猜到, 就要让每次发送数据的序列号不同, 在进行握手的时候会对数据的初始序列号进行交换. 客户端第一次发送握手信息的时候, 会连着自己的初始序列号一起发过去, 服务器收到之后, 返回第二个握手信息的时候, 除了返回握手确认, 也会连着自己的初始序列号一起发回来. 这在一定程度上保证了数据的安全传输. 当然这种防护措施很弱.&lt;/p&gt;
&lt;p&gt;这个随机的序列号其实还有另外一个作用, 我觉得这才是它最主要的作用. 如果我们上一次连接的其中一个数据包3, 在网络中傲游了一会, 连接已经断开了, 我们又开始了新的一次数据连接, 这个时候我收到了数据包3, 就会导致生成了错误的数据序列, 而随机序列号则避免了这个问题,&lt;/p&gt;

&lt;p&gt;&lt;code&gt;三次握手&lt;/code&gt;确实是有些作用, 那&lt;code&gt;四次挥手&lt;/code&gt;有什么用呢?&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;1.释放系统资源&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;在三次握手的时候, 为了接收数据并进行序列重组, 开辟了一些系统资源, 当数据发送完了, 就不用一直占着了, 早些释放, 留给别人.&lt;/p&gt;
&lt;p&gt;额, 应该还有其他作用吧...&lt;/p&gt;

&lt;p&gt;综上, 你说如果没有&lt;code&gt;握手&lt;/code&gt;和&lt;code&gt;挥手&lt;/code&gt;的过程, 能不能实现一个可靠的连接呢? 可以, 只不过会有问题. 个人简单将握手的作用总结为以下几点:&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;为了对数据进行顺序重组, 势必需要开辟系统资源. 如果没有握手的过程, 所有的请求, 都要占用资源. 而没有挥手的过程, 这些资源就不能及时释放.&lt;/li&gt;
&lt;li&gt;为了数据的高效传输, 选用一个合理的超时重传时间是十分有必要的. 时间短了, 会导致频繁重传, 浪费网络资源. 时间长了, 就会导致整体的数据传输时间变长.&lt;/li&gt;
&lt;li&gt;为了保证对方能够正常接收数据, 否则对方关机了, 我总不能在这一直超时重传吧.&lt;/li&gt;
&lt;li&gt;为了保证多次连接的数据包不会引发数据错误. 通过随机的序列号, 保证了两次连接的数据包不会互相影响.&lt;/li&gt;
&lt;/ol&gt;</description>
<pubDate>Fri, 12 Jun 2020 17:57:00 +0000</pubDate>
<dc:creator>烟草的香味</dc:creator>
<og:description>概述 在网络的传输层协议中, 存在着两大悍将: TCP 和 UDP . 从前, 我傻傻的以为自己对他们虽谈不上精通, 但还是知道的, 但是, 我错了, 我被自己问住了, 我傻了. 啥也不是. UDP</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/hujingnb/p/13111467.html</dc:identifier>
</item>
<item>
<title>redis 主从复制 - black_monkey</title>
<link>http://www.cnblogs.com/monkey-code/p/13111453.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/monkey-code/p/13111453.html</guid>
<description>&lt;h2 id=&quot;redis-主从复制&quot;&gt;redis 主从复制&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1440828/202006/1440828-20200613013105577-976452031.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;master&lt;/code&gt; 节点提供数据，也就是写。&lt;code&gt;slave&lt;/code&gt; 节点负责读。&lt;/p&gt;
&lt;p&gt;不是说master 分支不能读数据，也能只是我们希望将读写进行分离。&lt;/p&gt;
&lt;p&gt;slave 是不能写数据的，只能处理读请求&lt;/p&gt;
&lt;h2 id=&quot;主从实现&quot;&gt;主从实现&lt;/h2&gt;
&lt;p&gt;客户端 &lt;code&gt;127.0.0.1:6379&lt;/code&gt; 服务器 &lt;code&gt;212.64.89.173:6379&lt;/code&gt;&lt;/p&gt;
&lt;h3 id=&quot;方式一&quot;&gt;方式一&lt;/h3&gt;
&lt;p&gt;客户端发送请求同步命令&lt;/p&gt;
&lt;p&gt;&lt;code&gt;slaveof masterip masterport&lt;/code&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-redis&quot;&gt;slaveof 212.64.89.173 6379
&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;方式二&quot;&gt;方式二&lt;/h3&gt;
&lt;p&gt;客户端启动服务器参数&lt;/p&gt;
&lt;p&gt;&lt;code&gt;redis-server --slaveof masterip masterport&lt;/code&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-redis&quot;&gt;redis-server --slaveof 212.64.89.173 6379
&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;方式三&quot;&gt;方式三&lt;/h3&gt;
&lt;p&gt;在客户端的配置文件中写入 &lt;code&gt;slaveof&lt;/code&gt; 信息&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-C&quot;&gt;redis.conf

slaveof 212.64.89.173 6379
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;注意 断开主从链接方式：&lt;/strong&gt; 客户端执行 &lt;code&gt;slaveof no one&lt;/code&gt;&lt;/p&gt;
&lt;h3 id=&quot;设置链接密码&quot;&gt;设置链接密码&lt;/h3&gt;
&lt;h4 id=&quot;server-端&quot;&gt;server 端&lt;/h4&gt;
&lt;p&gt;服务启动后设置&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-redis&quot;&gt;config set requierpass &amp;lt;password&amp;gt;
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;配置文件添加密码&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-redis&quot;&gt;# redis.conf
requirepass &amp;lt;password&amp;gt;
&lt;/code&gt;
&lt;/pre&gt;
&lt;h4 id=&quot;client-端&quot;&gt;client 端&lt;/h4&gt;
&lt;p&gt;命令设置密码&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-redis&quot;&gt;auth &amp;lt;password&amp;gt;
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;配置文件设置密码&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-redis&quot;&gt;masterauth &amp;lt;password&amp;gt;
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;启动客户端设置密码&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-redis&quot;&gt;redis-cli -a &amp;lt;password&amp;gt;
&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;建立连接&quot;&gt;建立连接&lt;/h2&gt;
&lt;p&gt;建立链接的过程就是希望 &lt;code&gt;master&lt;/code&gt; 和 &lt;code&gt;slave&lt;/code&gt; 都保有对方的 &lt;code&gt;IP&lt;/code&gt; 和 &lt;code&gt;Port&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1440828/202006/1440828-20200613013143479-721802553.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h2 id=&quot;数据同步&quot;&gt;数据同步&lt;/h2&gt;
&lt;p&gt;数据的同步分两部分，全量同步和增量同步，在增量同步结束后，master 应当保存Slave 同步数据的位置。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1440828/202006/1440828-20200613013156405-1650153045.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h3 id=&quot;复制积压缓冲区&quot;&gt;复制(积压)缓冲区&lt;/h3&gt;
&lt;p&gt;它有两部分组成 &lt;code&gt;偏移量&lt;/code&gt; + &lt;code&gt;字节值&lt;/code&gt;&lt;/p&gt;
&lt;h4 id=&quot;结构&quot;&gt;结构&lt;/h4&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1440828/202006/1440828-20200613013215314-1831547129.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h4 id=&quot;创建&quot;&gt;创建&lt;/h4&gt;
&lt;p&gt;1 当启动&lt;code&gt;AOF&lt;/code&gt; 时就会创建 复制积压缓冲区&lt;/p&gt;
&lt;p&gt;2 当被选为 &lt;code&gt;master&lt;/code&gt; 节点，必须创建积压缓冲区&lt;/p&gt;
&lt;h4 id=&quot;作用&quot;&gt;作用&lt;/h4&gt;
&lt;p&gt;保存所有的对数据修改或数据库修改的指令，查询指令不会被记录。&lt;/p&gt;
&lt;h4 id=&quot;数据源&quot;&gt;数据源&lt;/h4&gt;
&lt;p&gt;所有的进入&lt;code&gt;master&lt;/code&gt; 的对数据修改或数据库修改的指令都会被填充到积压缓冲区中。&lt;/p&gt;
&lt;h4 id=&quot;偏移量&quot;&gt;偏移量&lt;/h4&gt;
&lt;p&gt;1 &lt;code&gt;Master&lt;/code&gt; 和 &lt;code&gt;Slave&lt;/code&gt; 都会记录 &lt;code&gt;offset&lt;/code&gt; 值， 每次复制都会对比&lt;code&gt;offset&lt;/code&gt; 是否一致。如果一致，&lt;code&gt;Master&lt;/code&gt;直接从 &lt;code&gt;offset&lt;/code&gt; 处开始传缓冲区数据，如果不一致，那么&lt;code&gt;Master&lt;/code&gt;将遵循 &lt;code&gt;Slave&lt;/code&gt; 的&lt;code&gt;offset&lt;/code&gt; 来传。当然会保证命令是完整的。&lt;/p&gt;
&lt;p&gt;2 &lt;code&gt;Master&lt;/code&gt; 保存有多个 &lt;code&gt;offset&lt;/code&gt; 而 &lt;code&gt;Slave&lt;/code&gt; 仅保存自己的。&lt;/p&gt;
&lt;p&gt;3 &lt;code&gt;Master&lt;/code&gt;发送一次，记录一次, &lt;code&gt;Slave&lt;/code&gt; 接受一次记录一次。&lt;/p&gt;
&lt;h4 id=&quot;关于master注意&quot;&gt;关于Master注意&lt;/h4&gt;
&lt;p&gt;1如果master 数据量过大，应该避免业务高峰期进行数据同步。避免造成 &lt;code&gt;master 阻塞&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;2 &lt;strong&gt;数据缓冲区满&lt;/strong&gt;， 此时将会丢弃最早的记录(FIFO)，如果全量复制的时间开销过大，则可能在开增量复制时候已经存在数据丢失，这会导致Master 和 Slave 数据不一致，为了保证一致性，必须开始新一轮的全量复制，完成后缓冲区又被填满并存在丢弃，则会让Slave进入死循环。&lt;/p&gt;
&lt;p&gt;因此数据缓冲区要设置的大小合适(依具体情况而定)。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-redis&quot;&gt;repl-backlog-size 1mb   # 默认的大小为 1MB
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;3 &lt;code&gt;master&lt;/code&gt; 单机内存不应该占用主机内存过多。一般的 50 ～ 70% 预留下 30% ～ 50%来进行&lt;code&gt;bgsave&lt;/code&gt; 、 &lt;code&gt;创建复制缓冲区&lt;/code&gt;、执行其他业务等。&lt;/p&gt;
&lt;h4 id=&quot;关于slave注意&quot;&gt;关于Slave注意&lt;/h4&gt;
&lt;p&gt;1 为避免&lt;code&gt;slave&lt;/code&gt;进行全量复制、部分复制时服务器响应阻塞或数据不同步，建议关闭此期间的对外服务。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-redis&quot;&gt;slave-server-stale-data yes|no
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;2 数据同步阶段，&lt;code&gt;master&lt;/code&gt; 发送给 &lt;code&gt;slave&lt;/code&gt; 信息可以理解 &lt;code&gt;master&lt;/code&gt; 是 &lt;code&gt;slave&lt;/code&gt; 的一个客户端，主动向slave发送命令。&lt;/p&gt;
&lt;p&gt;3 多个&lt;code&gt;slave&lt;/code&gt;同时对&lt;code&gt;master&lt;/code&gt;请求数据同步，&lt;code&gt;master&lt;/code&gt;发送的&lt;code&gt;RDB&lt;/code&gt;文件增多，会对带宽造成巨大冲击，如果&lt;code&gt;master&lt;/code&gt;宽带不足，因此数据同步需要根据业务需求，适量错峰。&lt;/p&gt;
&lt;p&gt;4 &lt;code&gt;slave&lt;/code&gt;过多时，应该对拓扑结构进行调整，由一主多从结构变为树状结构，中间结点即是master,也是slave。但是使用树状结构时，因为层级越深，数据同步时延越大，因此将强一致性的数据放在顶层节点，一致性稍弱的数据放在靠底层的节点。&lt;/p&gt;
&lt;h2 id=&quot;命令传播&quot;&gt;命令传播&lt;/h2&gt;
&lt;p&gt;当&lt;code&gt;master&lt;/code&gt;数据库状态被修改后，导致主从服务器数据库状态不一致，此时需要让主从数据同步到一致的状态，同步的动作成为命令传播&lt;br/&gt;&lt;code&gt;master&lt;/code&gt;将接受到的数据变更命令发送给&lt;code&gt;slave&lt;/code&gt;，&lt;code&gt;slave&lt;/code&gt;接受命令后执行命令。&lt;/p&gt;
&lt;p&gt;网络闪断闪连 忽略&lt;br/&gt;短时间网络中断 部分复制&lt;br/&gt;长时间网络中断 全量复制&lt;/p&gt;
&lt;h3 id=&quot;服务器运行idrunid&quot;&gt;服务器运行ID(runid)&lt;/h3&gt;
&lt;p&gt;每台服务器每次运行都会产生的身份识别码，同一个服务器多次运行产生的&lt;code&gt;runid&lt;/code&gt;是不一样的。&lt;/p&gt;
&lt;p&gt;形式：runid 由 40 个字符组成 一般是16进制的字符串&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-redis&quot;&gt;info server
run_id:409b6e9ea2e5c32958de8f365711598c98489f13
&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;心跳机制&quot;&gt;心跳机制&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;master&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;指令 &lt;strong&gt;PING&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;周期 &lt;code&gt;repl-ping-slave-period&lt;/code&gt; 默认是 10s&lt;/p&gt;
&lt;p&gt;作用 判断 &lt;code&gt;slave&lt;/code&gt; 是否在线&lt;/p&gt;
&lt;p&gt;查询 INFO replication 获取最后一次 &lt;code&gt;slave&lt;/code&gt; 连接时间间隔 lag = 0 / 1 属于正常&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;slave&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;指令 &lt;strong&gt;REPLCONF{offset}&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;周期: 1s&lt;/p&gt;
&lt;p&gt;作用1: 汇报自己的复制偏移量 获取最新的数据变更指令&lt;/p&gt;
&lt;p&gt;作用2: 判断 &lt;code&gt;master&lt;/code&gt; 是否存活&lt;/p&gt;
&lt;h3 id=&quot;心跳注意事项&quot;&gt;心跳注意事项&lt;/h3&gt;
&lt;p&gt;当 salve多数掉线 或者网络延时过高时，master 会拒绝所有的同步信息。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-redis&quot;&gt;min-slaves-to-write 2   # 最小的 slave 数量

min-slaves-max-lag 8  # 最长的
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;当 slave 的数量小于2 ，或者所有的时延都大于等于 8 时，会强 关闭 &lt;code&gt;master&lt;/code&gt; 的血功能来停止数据同步。&lt;/p&gt;
&lt;p&gt;Slave 的数量和延时由&lt;code&gt;REPLCONF{offset}&lt;/code&gt; 命令确认。&lt;/p&gt;
&lt;h2 id=&quot;完整的主从复制流程&quot;&gt;完整的主从复制流程&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1440828/202006/1440828-20200613013359570-784519716.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h3 id=&quot;读写分离&quot;&gt;读写分离&lt;/h3&gt;
&lt;p&gt;在redis主从架构中，Master节点负责处理写请求，Slave节点只处理读请求。对于写请求少，读请求多的场景，例如电商详情页，通过这种读写分离的操作可以大幅提高并发量，通过增加redis从节点的数量可以使得redis的QPS达到10W+。&lt;/p&gt;
&lt;h3 id=&quot;负载均衡&quot;&gt;负载均衡&lt;/h3&gt;
&lt;p&gt;基于主从结构，配合读写分离，由slave分担master负载，并根据需求的变化，改变slave的数量，通过多个从节点分担数据读取负载，大大提高Redis服务器并发量与数据吞吐量&lt;/p&gt;
&lt;h3 id=&quot;故障恢复&quot;&gt;故障恢复&lt;/h3&gt;
&lt;p&gt;当master出现问题时，由slave提供服务，实现快速的故障恢复&lt;/p&gt;
&lt;h3 id=&quot;数据冗余&quot;&gt;数据冗余&lt;/h3&gt;
&lt;p&gt;实现数据热备份，时持久化之外的一种数据冗余方式&lt;/p&gt;
&lt;h3 id=&quot;高可用基石&quot;&gt;高可用基石&lt;/h3&gt;
&lt;p&gt;基于主从复制，构建哨兵模式与集群，实现redis 的高可用方案。&lt;/p&gt;
</description>
<pubDate>Fri, 12 Jun 2020 17:34:00 +0000</pubDate>
<dc:creator>black_monkey</dc:creator>
<og:description>redis 主从复制 master 节点提供数据，也就是写。slave 节点负责读。 不是说master 分支不能读数据，也能只是我们希望将读写进行分离。 slave 是不能写数据的，只能处理读请求</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/monkey-code/p/13111453.html</dc:identifier>
</item>
<item>
<title>SSH原理常见应用升级及端口转发 - you-men</title>
<link>http://www.cnblogs.com/you-men/p/13111313.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/you-men/p/13111313.html</guid>
<description>&lt;h4 id=&quot;ssh介绍&quot;&gt;SSH介绍&lt;/h4&gt;
&lt;blockquote readability=&quot;19&quot;&gt;
&lt;p&gt;SSH是&lt;code&gt;Secure Shell Protocol&lt;/code&gt;的简写，由IETF网络工作小组（&lt;code&gt;Network working Group&lt;/code&gt;）指定；在进行数据传输之前，SSH先对联机数据包通过加密技术进行加密处理，加密后在进行数据传输。确保了传递的数据安全.&lt;/p&gt;
&lt;p&gt;SSH是专为&lt;code&gt;远程登录会话&lt;/code&gt;和其他网络服务提供的&lt;code&gt;安全性协议&lt;/code&gt;。利用SSH协议可以有效的放置远程管理过程中的信息泄露问题，在当前的生产环境运维工作中，绝大多数企业普遍采用SSH协议服务来代替传统的不安全的远程联机服务软件，如&lt;code&gt;telnet&lt;/code&gt;（23端口，非加密)&lt;/p&gt;
&lt;p&gt;在默认状态下，SSH服务主要提供了两个服务功能，一个是提供类似Telnet远程联机服务器的服务，即上面提到的SSH服务；另一个是类似FTP服务的&lt;code&gt;sftp-server&lt;/code&gt;，借助SSH协议来传输数据的，提供更安全的SFTP服务（&lt;code&gt;vsftp，proftp&lt;/code&gt;）&lt;/p&gt;
&lt;p&gt;ssh 客户端(ssh命令)还包含一个远程安全拷贝命令scp,也是通过ssh协议工作.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1871335/202006/1871335-20200613002012127-689307645.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;小结&lt;/code&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-shell&quot;&gt;# 1、SSH是安全的加密协议，用于远程连接linux服务器
# 2、SSH默认端口是22，安全协议版本SSH2，除了2之外还有SSH1（漏洞）
# 3、SSH服务端主要包含两个服务协议SSH远程连接，SFTP服务
# 4、Linux SSH客户端包含ssh远程连接命令，以及远程拷贝scp命令
&lt;/code&gt;
&lt;/pre&gt;
&lt;h4 id=&quot;ssh结构&quot;&gt;SSH结构&lt;/h4&gt;
&lt;pre&gt;
&lt;code class=&quot;language-shell&quot;&gt;# SSH服务由服务端软件OpenSSH （openssl）
# 客户端（常见的有SSH（linux），SecureCRT，Putty，Xshell）组成

# SSH服务默认使用22端口提供服务，它有两个不兼容的SSH协议版本分别是1.x和2.x

rpm -qa openssh
openssh-6.6.1p1-31.el7.x86_64           # 远程连接安装包

rpm -qa openssl
openssl-1.0.2k-19.el7.x86_64            # 加密安装包
&lt;/code&gt;
&lt;/pre&gt;
&lt;blockquote readability=&quot;19&quot;&gt;
&lt;p&gt;OpenSSH同时支持SSH &lt;code&gt;1.x&lt;/code&gt;和&lt;code&gt;2.x&lt;/code&gt; 用SSH 2.x的客户端程序不能链接到SSH1.x的服务程序上&lt;/p&gt;
&lt;p&gt;SSH服务是一个&lt;code&gt;守护进程&lt;/code&gt;（daemon），他在后台运行并响应来自客户端的连接请求，&lt;code&gt;SSH服务端的进程名为sshd&lt;/code&gt;，负责实时监听&lt;code&gt;远程&lt;/code&gt;SSH客户端的连接请求，并进行处理，一般包括公共密钥认证、密钥交换、对称密钥加密和非安全连接等。&lt;/p&gt;
&lt;p&gt;SSH客户端包含&lt;code&gt;ssh&lt;/code&gt;以及像&lt;code&gt;scp&lt;/code&gt;（远程拷贝）&lt;code&gt;slogin&lt;/code&gt;（远程登录）&lt;code&gt;sftp&lt;/code&gt;（安全FTP文件传输）等&lt;code&gt;应用程序&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;SSH&lt;/code&gt;的工作机制大致是本地的ssh客户端发送一个连接请求到远程的ssh服务器，服务器检查连接的客户端发送的数据包和ip地址，如果确认&lt;code&gt;合法&lt;/code&gt;，就会发送密钥给SSH的客户端，此时，客户端本地再将密钥发回给服务端，自己建立连接。SSH1.x和SSH2.x在&lt;code&gt;连接协议上有一些安全方面&lt;/code&gt;的差异&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4 id=&quot;ssh加密技术&quot;&gt;SSH加密技术&lt;/h4&gt;
&lt;blockquote readability=&quot;11&quot;&gt;
&lt;p&gt;SSH加密技术是将人类可以看得懂的数据，通过一定的特殊的程序算法，把这些数据变成杂乱的无意义的信息，然后，通过网络进行传输，二挡到了目的地后，在通过对应的解密算法，把传过来的加密的数据信息解密成加密前的可读取的正常数据。因此，当数据在互联网上传输时即使被有心的黑客监听窃取了，也很难获取到真正需要的数据&lt;/p&gt;
&lt;p&gt;网络上的数据包加密技术一般是通过所谓的一对&lt;code&gt;公钥&lt;/code&gt;和&lt;code&gt;私钥&lt;/code&gt;（Public key and Pivate key）组合撑的密钥对进行&lt;code&gt;加密&lt;/code&gt;与&lt;code&gt;解密&lt;/code&gt;操作。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1871335/202006/1871335-20200613002022900-1518557596.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h5 id=&quot;ssh-1x&quot;&gt;SSH 1.x&lt;/h5&gt;
&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;每一台SSH服务器主机都可以使用RSA加密方式来产生一个&lt;code&gt;1024-bit&lt;/code&gt;的RSA Key 这个RSA的加密方式就是用来产生公钥和私钥的算法之一。&lt;/p&gt;
&lt;p&gt;当服务&lt;code&gt;启&lt;/code&gt;动时，就会产生一个&lt;code&gt;768 bit的临时公钥存放在Server&lt;/code&gt;中&lt;/p&gt;
&lt;/blockquote&gt;
&lt;pre&gt;
&lt;code class=&quot;language-shell&quot;&gt;grep ServerKey /etc/ssh/sshd_config 
#ServerKeyBits 1024
&lt;/code&gt;
&lt;/pre&gt;
&lt;h5 id=&quot;ssh-2x&quot;&gt;SSH 2.x&lt;/h5&gt;
&lt;blockquote readability=&quot;22&quot;&gt;
&lt;p&gt;在&lt;code&gt;SSH 1.x&lt;/code&gt;的联机过程中，当Server接收&lt;code&gt;Clinet端&lt;/code&gt;的&lt;code&gt;Private Key&lt;/code&gt;后，就不再针对该次联机的Key pair进行检验。若此时有而已黑客对该联机&lt;code&gt;key pair&lt;/code&gt;插入而已的程序代码时，由于服务端你不会在检验联机的正确性，因此可能会接收该程序代码，从而导致系统被黑.&lt;/p&gt;
&lt;p&gt;为了改正这个缺点，SSH version2多加了一个确认联机&lt;code&gt;正确&lt;/code&gt;性的&lt;code&gt;Diffie-Hellman机制&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;在每次数据传输中，Server都会以该机制检查数据的来源是否正确，这样，可以避免联机过程中被插入而已程序代码的问题&lt;/p&gt;
&lt;p&gt;另外，SSH2同时支持&lt;code&gt;RSA&lt;/code&gt;和&lt;code&gt;DSA&lt;/code&gt;密钥，但是SSH1仅支持RSA密钥&lt;/p&gt;
&lt;p&gt;由于SSH1协议本身存在较大问题，建议使用SSH2的&lt;code&gt;联机模式&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;当Client端SSH联机请求传送过来时，Server就会将这个768-bit的公钥传给Client端&lt;/p&gt;
&lt;p&gt;此时Client会将此公钥与先前存储的公钥进行对比，看是否一致，判断标准是Client端联机用户目录下&lt;code&gt;~/.ssh/known_hosts&lt;/code&gt;文件的内容（&lt;code&gt;linux-客户端&lt;/code&gt;）&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1871335/202006/1871335-20200613002031569-1775998614.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;不加用户默认是&lt;/code&gt;root &lt;code&gt;不加&lt;/code&gt;-p &lt;code&gt;指定端口 默认是&lt;/code&gt;22`&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-shell&quot;&gt;ssh -p22222 root@39.108.140.0
The authenticity of host '39.108.140.0 (39.108.140.0)' can't be established.
ECDSA key fingerprint is 17:33:ef:9b:05:b3:69:d3:20:48:49:e1:28:9b:7c:c8.
Are you sure you want to continue connecting (yes/no)? 

# 连接密码文件存放路径
cat /root/.ssh/known_hosts 
121.36.43.223 ecdsa-sha2-nistp256 AAAAE2VjZHNhLXNoYTItbmlzdHAyNTYAAAAIbmlzdHAyNTYAAABBBDgQ7H6KDIPTzOklwMSOxgFI0Xc3rgvwPnCLIuXIuzaCfYQBouM6owCArpj2CXEyk40lSn96ktW1vETbP1JmjEY=

# 第一次SH连接的时候,本地会产生一个密钥文件~/.ssh/known_hosts
&lt;/code&gt;
&lt;/pre&gt;
&lt;h5 id=&quot;如何防止ssh登录入侵&quot;&gt;如何防止SSH登录入侵&lt;/h5&gt;
&lt;pre&gt;
&lt;code class=&quot;language-shell&quot;&gt;# 1、用密钥登录，不用密码登录
# 2、牤牛阵法：解决SSH安全问题
# 3、防火墙封闭SSH，指定源限制（局域网，信任公网）
# 4、开启SSH只监听本地内网IP（ListenAddress 10.0.0.8）
# 5、尽量不给服务器外网IP
&lt;/code&gt;
&lt;/pre&gt;
&lt;h4 id=&quot;ssh客户端附带的scp命令&quot;&gt;SSH客户端附带的scp命令&lt;/h4&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;scp的基本语法使用：&lt;code&gt;scp -sercure copy&lt;/code&gt; （&lt;code&gt;remote file copy program&lt;/code&gt;）&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;code&gt;推push&lt;/code&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-shell&quot;&gt;scp -P22 -rp /root/test.txt root@39.108.140.0:/root/
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;拉pull&lt;/code&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-shell&quot;&gt;scp -p22 -rp root@39.108.140.0:/root/test.txt ./

# -P 指定端口,默认22,可忽略
# -p 表示拷贝前后保持文件或目录属性
# -r 递归,表示拷贝目录
# -l 限制速度

# 小结
# 1、scp是加密的远程拷贝，而cp仅为本地拷贝
# 2、可以把数据从一台机器推送到另一台机器，也可以从其他服务器把数据拉回到本地执行命令的服务器
# 3、每次都是全量完成拷贝，因此效率不高，适合第一次拷贝用，如果需要增量拷贝，用rsync
&lt;/code&gt;
&lt;/pre&gt;
&lt;h5 id=&quot;ssh服务附带的sftp功能服务&quot;&gt;ssh服务附带的sftp功能服务&lt;/h5&gt;
&lt;pre&gt;
&lt;code class=&quot;language-shell&quot;&gt;# 1. rz,sz(lrzsz)
# 2. winscp WinSCP-v4.0.5 基于SSH，sftp
# 3. SFX(xshell) 4） SFTP 基于SSH加密传输
# 4. samba，http，ftp，nfs
# FTP工具：vsftp、proftpd、SFTP

# linux sftp客户端登录sftp服务方法
# 登录FTP的方法就是
sftp -oPort=22 root@39.108.140.0:
sftp&amp;gt; put test.txt
Uploading test.txt to /root/test.txt
test.txt                                          100%    0     0.0KB/s   00:00                                   
sftp&amp;gt; ls test.txt 
test.txt
&lt;/code&gt;
&lt;/pre&gt;
&lt;h4 id=&quot;ssh服务认证类型介绍&quot;&gt;SSH服务认证类型介绍&lt;/h4&gt;
&lt;h5 id=&quot;基于口令安全认证&quot;&gt;基于口令安全认证&lt;/h5&gt;
&lt;blockquote readability=&quot;7&quot;&gt;
&lt;p&gt;基于口令的安全验证的方式就是大家现在一直在用的，只要知道服务器的SSH&lt;code&gt;端口号&lt;/code&gt;和&lt;code&gt;口令&lt;/code&gt;，应服务器的&lt;code&gt;IP&lt;/code&gt;及开放的&lt;code&gt;端口&lt;/code&gt;，默认都为&lt;code&gt;22&lt;/code&gt;，就可以通过ssh客户端登录到主机，此时联机过程中所有传输都是&lt;code&gt;加密&lt;/code&gt;的&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h5 id=&quot;基于密钥的安全验证&quot;&gt;基于密钥的安全验证&lt;/h5&gt;
&lt;blockquote readability=&quot;12&quot;&gt;
&lt;p&gt;基于密钥的安全验证方式是指，需要依靠&lt;code&gt;密钥&lt;/code&gt;，也就是必须事先建立一对&lt;code&gt;密钥&lt;/code&gt;，然后把公用密钥（&lt;code&gt;Publickey&lt;/code&gt;）放在需要访问的目标服务器上，另外，个还需要把&lt;code&gt;私有密钥&lt;/code&gt;（Private key）放到SSH客户端或对应的客户端服务器上&lt;/p&gt;
&lt;p&gt;此时，如果要想连接到这个带有&lt;code&gt;公用密钥&lt;/code&gt;的SSH服务器，客户端SSH软件或者客户端端服务就会想SSH服务端发出请求，请求用联机用户密钥进行安全连接。SSH服务会在收到请求之后，会现在改SSH服务器上连接的用户的加密路下 放上去的对应用户密钥，然后把它和连接的SSH客户端发来进行密钥，如果两个密钥一直SSH服务就会用公用密钥加密“&lt;code&gt;质询&lt;/code&gt;”（challenge）并把它发送给&lt;code&gt;SSH客户端&lt;/code&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1871335/202006/1871335-20200613002042052-1012526183.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h5 id=&quot;更改ssh-默认登录配置&quot;&gt;更改ssh 默认登录配置&lt;/h5&gt;
&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;修改SSH服务的运行参数，是通过修改配置文件&lt;code&gt;/etc/ssh/sshd_config&lt;/code&gt;实现的&lt;/p&gt;
&lt;p&gt;一般来说SSH服务使用默认的配置已经够很好的工作，如果对安全要求不高，仅仅提供SSH服务的情况不需要修改任何配置&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;code&gt;sshd_config配置文件说明:&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1871335/202006/1871335-20200613002054678-490245468.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h5 id=&quot;优化ssh配置文件选项&quot;&gt;优化SSH配置文件选项&lt;/h5&gt;
&lt;pre&gt;
&lt;code class=&quot;language-shell&quot;&gt;cp /etc/ssh/sshd_config{,.bak}
vim /etc/ssh/sshd_config
Port 52113              # ssh连接端口默认为22，修改端口号可以提高级别
PermitRootLogin no      # 禁止root远程登录
PermitEmptyPasswords no # 禁止空密码的用户登录
UseDNS no               # 不使用DNS进行解析
GSSAPIAuthentication no # 会导致SSH连接慢

# ssh远程连接服务满解决方法
sed -ri '13 iPort 52113\nPermitRootLogin no\nPermitEmptyPasswords no\nUseDNS no\nGSSAPIAuthentication no' /etc/ssh/sshd_config
&lt;/code&gt;
&lt;/pre&gt;
&lt;h4 id=&quot;ssh优化&quot;&gt;SSH优化&lt;/h4&gt;
&lt;h5 id=&quot;优化sshd_config&quot;&gt;优化sshd_config&lt;/h5&gt;
&lt;pre&gt;
&lt;code class=&quot;language-shell&quot;&gt;sed -i '13 iPort 52113\nPermitRootLogin no   \n   禁止root登录
PermitEmptyPasswords no \n      #        禁止使用密码
UseDNS no\n                     # 禁用DNS
GSSAPIAuthentication no'        #        禁用GSSAPI
sshd_config
&lt;/code&gt;
&lt;/pre&gt;
&lt;h5 id=&quot;检查hosts解析&quot;&gt;检查hosts解析&lt;/h5&gt;
&lt;pre&gt;
&lt;code class=&quot;language-shell&quot;&gt;cat &amp;gt;&amp;gt;/etc/hosts &amp;lt;&amp;lt;EOF
39.108.140.0 blog
149.129.38.117 blog2
121.36.43.223 huawei 
49.233.69.195 tenxun 
116.196.83.113 jd 
EOF

useradd oldboy
echo &quot;123456&quot;|passwd --stdin youmen
su – youmen
ssh-keygen -t dsa   //非交互式创建密钥  

#ssh-keygen是生产密钥的工具 -t参数是指定密钥的类型，这里是建立dsa类型密钥
#也可以使用ssh-keygen -t rsa来建立rsa类型密钥

#RSA与DSA加密算法的区别
#RSA：是一种加密算法（PS：RSA也可以进行数字签名的）它的简写的来由是RonRivest、Adi Shamir和LeonAdleman 这三个姓氏加在一起就是RSA

#DSA就是数字签名算法的英文全称的简写，即Digital Sigenature Algorithm=DSA

# RSA既可以进行加密，也可以进行数字签名实现认证，而DSA只能用于数字签名
&lt;/code&gt;
&lt;/pre&gt;
&lt;h5 id=&quot;分发密钥&quot;&gt;分发密钥&lt;/h5&gt;
&lt;pre&gt;
&lt;code class=&quot;language-shell&quot;&gt;yum -y install sshpass
ssh-keygen -t rsa -P '' -f ~/.ssh/id_dsa &amp;amp;&amp;gt;/dev/null
sshpass -p youmen ssh -o StrictHostKeyChecking=no  root@192.168.43.159


# 一键生成密钥对
ssh-keygen -t dsa -P '' -f ~/.ssh/id_dsa &amp;gt;/dev/null 2&amp;gt;&amp;amp;1

ssh-copy-id -i /root/.ssh/id_dsa.pub root@192.168.43.159
# -i 代表要发送的文件

# ssh-copy-id 只能发公钥，不能发私钥

# 1 免密码登录是单向的，方向从私钥（钥匙）==》公钥（锁）
# 2 SSH免密码登录基于用户的，最好不要跨不同的用户
# 3 ssh连接慢的问题解决
&lt;/code&gt;
&lt;/pre&gt;
&lt;h5 id=&quot;ssh批量管理步骤&quot;&gt;ssh批量管理步骤&lt;/h5&gt;
&lt;pre&gt;
&lt;code class=&quot;language-shell&quot;&gt;# 1、ssh优化和hosts解析
# 2、创建用户
# 3、生成密钥对
# 4、分发公钥到所有服务器 ssh-copy-id
# 5、测试 远程连接ssh 远程执行命令ssh ifconfig
# 远程拷贝文件scp rsync-e隧道模式
&lt;/code&gt;
&lt;/pre&gt;
&lt;h4 id=&quot;ssh常见操作&quot;&gt;ssh常见操作&lt;/h4&gt;
&lt;h5 id=&quot;将本地hosts发送指定ip&quot;&gt;将本地hosts发送指定IP&lt;/h5&gt;
&lt;p&gt;&lt;code&gt;1. sudo提权实现没有权限用户拷贝&lt;/code&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-shell&quot;&gt;echo“youmenALL= NOPASSWD:/usr/bin/rsync ”&amp;gt;&amp;gt;/etc/sudoers

visudo -c 

scp -P52113 hosts oldboy@192.168.43.159：~       # 最好发送到家目录下，直接发送到/下是没有权限

ssh -p22 -t youmen@192.168.43.159 sudo rsync ~/hosts /etc/hosts
# 需要授权sudo权限
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;2. 使用suid实现没有权限用户拷贝&lt;/code&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-shell&quot;&gt;chmod u+s `which rsync`
scp -P22 hosts oldboy@192.168.43.159：~
ssh -p22 youmen@192.168.43.159 rsync ~/hosts  /etc/hosts
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;3. 使用root进行操作&lt;/code&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-shell&quot;&gt;# rsync使用
rsync -avz hosts -e ‘ssh -p 22’youmen@192.168.43.159:~
# 可以增量备份
&lt;/code&gt;
&lt;/pre&gt;
&lt;h5 id=&quot;查看hosts主机系统版本&quot;&gt;查看hosts主机系统版本&lt;/h5&gt;
&lt;pre&gt;
&lt;code class=&quot;language-shell&quot;&gt; cat view.sh 
#!/bin/sh
for n in blog2 tenxun jd huawei 
do
  echo -n &quot;====$n====&quot;        
  ssh -p 22 $n $1               
done
[root@nginx_test ~]# sh view.sh &quot;cat /etc/redhat-release&quot;
====blog2====CentOS Linux release 7.3.1611 (Core) 
====tenxun====CentOS Linux release 7.6.1810 (Core) 
====jd====CentOS Linux release 7.6.1810 (Core) 
====huawei====CentOS Linux release 7.4.1708 (Core) 
&lt;/code&gt;
&lt;/pre&gt;
&lt;h5 id=&quot;分发文件&quot;&gt;分发文件&lt;/h5&gt;
&lt;pre&gt;
&lt;code class=&quot;language-shell&quot;&gt;cat file.sh 
#!/bin/sh
. /etc/init.d/functions
if [ $# -ne 1 ];then 
    echo &quot;USAGE:/bin/sh $0 FILENAME&quot;  $
    exit 1    
fi
for n in blog2 tenxun jd huawei 
do
  echo -n &quot;====$n====&quot;        
  scp -P22 $1  $n: &amp;amp;&amp;gt;/dev/null
  if [ $? -eq 0 ];then
      action &quot;dis $1 to $n&quot; /bin/true
else
      action &quot;$n&quot; /bin/false
fi
done

sh file.sh /etc/hosts
====blog2====dis /etc/hosts to blog2                       [  OK  ]
====tenxun====dis /etc/hosts to tenxun                     [  OK  ]
====jd====dis /etc/hosts to jd                             [  OK  ]
====huawei====dis /etc/hosts to huawei                     [  OK  ]
&lt;/code&gt;
&lt;/pre&gt;
&lt;h4 id=&quot;ssh端口转发简介&quot;&gt;SSH端口转发简介&lt;/h4&gt;
&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;SSH会自动加密和解密所有SSH客户端与服务端之间的网络数据。但是，SSH还能够将其他TCP端口的网络数据通SSH链接来转发，并且自动提供了相应的加密及解密服务。这一过程也被叫做&quot;&lt;strong&gt;隧道&lt;/strong&gt;&quot;（tunneling），这是因为SSH为其他TCP链接提供了一个安全的通道来进行传输而得名。例如，Telnet ，SMTP ，LDAP这些TCP应用均能够从中得益，避免了用户名，密码以及隐私信息的明文传输。而与此同时，如果工作环境许中的防火墙限制了一些网络端口的使用，但是允许SSH的连接，也能够将通过将TCP用端口转发来使用SSH进行通讯。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h5 id=&quot;ssh端口转发两大功能&quot;&gt;SSH端口转发两大功能&lt;/h5&gt;
&lt;pre&gt;
&lt;code class=&quot;language-shell&quot;&gt;# 1. 加密SSH Client端至SSH Server端之间的通讯数据。
# 2. 突破防火墙的简直完成一些之前无法建立的TCP连接。
&lt;/code&gt;
&lt;/pre&gt;
&lt;h4 id=&quot;本地转发&quot;&gt;本地转发&lt;/h4&gt;
&lt;p&gt;&lt;code&gt;命令 -L localport:remotehost:remotehostport sshserver&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;说明&lt;/code&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-shell&quot;&gt;localport　　　　　　#  本机开启的端口号
remotehost　　　　　 #　最终连接机器的IP地址
remotehostport     #  转发机器的端口号
sshserver　　　　　　#  转发机器的IP地址

# -L 本机端口
# -f 后台启用，可以在本机直接执行命令，无需另开新终端
# -N 不打开远程shell，处于等待状态，不跳到远程主机，还在主机上，只是搭好了隧道，桥搭好，不ssh上去
# -g 启用网关功能
# -R 服务端口

# 举例:
ssh –L 9527:telnetsrv:23 -N sshsrv
telnet 127.0.0.1 9527
# 当访问本机的9527的端口时，被加密后转发到sshsrv的ssh服务，再解密被转发到telnetsrv:23
data &amp;lt; &amp;gt;localhost:9527 &amp;lt; &amp;gt; localhost:XXXXX &amp;lt; &amp;gt; sshsrv:22 &amp;lt; &amp;gt; sshrv:yyyyy &amp;lt; &amp;gt; telnetsrv:23
&lt;/code&gt;
&lt;/pre&gt;
&lt;h5 id=&quot;环境背景&quot;&gt;环境背景&lt;/h5&gt;
&lt;blockquote readability=&quot;17&quot;&gt;
&lt;p&gt;&lt;strong&gt;背景：&lt;/strong&gt;企业内部C服务器只允许telnet连接（23端口）访问，不允许外部直接访问，B服务器是一个ssh服务器；有一个用户需要从外部连接到企业内部的C服务器。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;前提：&lt;/strong&gt;防火墙允许22端口进来（或者企业内部有一个堡垒机，ssh -t通过堡垒机进去）。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;原理：&lt;/strong&gt; 数据一旦telnet以后，数据会发送到本机9527端口，再在本机开一个随机端口，充当ssh客户端，再把数据流量发送到22端口的ssh服务端，收到数据以后，解密数据，临时开一个随机端口充当客户端，再把流量发送到23端口telnet服务端&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;机器：&lt;/strong&gt; blogA用户，huawei模拟B机器，tenxun模拟C机器&lt;/p&gt;
&lt;/blockquote&gt;
&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;节点名&lt;/th&gt;
&lt;th&gt;IP&lt;/th&gt;
&lt;th&gt;软件版本&lt;/th&gt;
&lt;th&gt;硬件&lt;/th&gt;
&lt;th&gt;网络&lt;/th&gt;
&lt;th&gt;说明&lt;/th&gt;
&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;CentOS7-A&lt;/td&gt;
&lt;td&gt;39.108.140.0&lt;/td&gt;
&lt;td/&gt;
&lt;td&gt;1C2G&lt;/td&gt;
&lt;td&gt;公有云&lt;/td&gt;
&lt;td&gt;阿里云&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;CentOS6-B&lt;/td&gt;
&lt;td&gt;121.36.43.223&lt;/td&gt;
&lt;td/&gt;
&lt;td&gt;1C2G&lt;/td&gt;
&lt;td&gt;公有云&lt;/td&gt;
&lt;td&gt;华为云&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;CentOS6-C&lt;/td&gt;
&lt;td&gt;49.233.69.195&lt;/td&gt;
&lt;td/&gt;
&lt;td&gt;1C2G&lt;/td&gt;
&lt;td&gt;公有云&lt;/td&gt;
&lt;td&gt;腾讯云&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1871335/202006/1871335-20200613002109385-1677974260.jpg&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-shell&quot;&gt;# ssh协议里面封装了telnet，一旦A连接了B主机，立即使用telnet连接C主机，此过程可以突破防火墙的限制
# 实验
#　  A-&amp;gt;C    访问被限制
#    A-B-&amp;gt;C　　使用B主机作为跳板突破访问限制
&lt;/code&gt;
&lt;/pre&gt;
&lt;h5 id=&quot;配置步骤&quot;&gt;配置步骤&lt;/h5&gt;
&lt;p&gt;&lt;code&gt;C机器通过iptables拒绝A机器登录&lt;/code&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-shell&quot;&gt;[root@C ~]# iptables -A INPUT -s 39.108.140.0 -j REJECT
[root@C ~]# yum -y install telnet-server xinetd
[root@C ~]# systemctl start telnet.socket
[root@C ~]# systemctl start xinetd
[root@C ~]# ss -tnl |grep 23
LISTEN     0      128       [::]:23                    [::]:*   

# 此时我们A机器是直接连接不上C机器的
[root@A ~]# ssh 49.233.69.195
ssh: connect to host 49.233.69.195 port 22: Connection refused

# 开启端口转发(telnet隧道)
[root@A ~]# ssh -L 10000:49.233.69.195:23 -Nf 121.36.43.223
# 通过本地9527端口访问centos6-1服务器IP地址使用telnet协议23端口，跳板机ip地址

# 隧道已经搭建好了，此时A主机可以通过telnet访问C主机
telnet 127.0.0.1 10000
Trying 127.0.0.1...
Connected to 127.0.0.1.
Escape character is '^]'.

Kernel 3.10.0-1062.9.1.el7.x86_64 on an x86_64
c login: youmen
Password: 
Last login: Fri Jun 12 22:32:04 from centos-b
[root@C ~]$

# 如何需要删除这个连接使用killall ssh即可
killall ssh   # 删除搭建的桥
telnet 127.0.0.1 10000
Trying 127.0.0.1...
telnet: connect to address 127.0.0.1: Connection refused
&lt;/code&gt;
&lt;/pre&gt;
&lt;h4 id=&quot;远程转发&quot;&gt;远程转发&lt;/h4&gt;
&lt;p&gt;&lt;code&gt;远程转发机制&lt;/code&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-shell&quot;&gt;# -R sshserverport:remotehost:remotehostportsshserver

# 举例
ssh–R 9527:telnetsrv:23 –N sshsrv
# 让sshsrv侦听9527端口的访问，如有访问，就加密后通过ssh服务转发请求到本机ssh客户端，再由本机解密后转发到telnetsrv:23
Data &amp;lt; &amp;gt; sshsrv:9527 &amp;lt; &amp;gt; sshsrv:22 &amp;lt; &amp;gt; localhost:XXXXX &amp;lt; &amp;gt; localhost:YYYYY&amp;lt; &amp;gt;telnetsrv:23

# 需求:
# 在A(Centos7)上开启smtp服务（postfix)，B(Centos6)做跳板，C(Centos6-1)客户端给Centos7发送邮件

# 流程解释
C-x-&amp;gt;A    （拒绝访问）
C-B-&amp;gt;A      （通过远程代理，接受访问）  
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;环境依然是上面三台机器,只是C服务器换成116.196.83.113 (JD)这台服务器&lt;/code&gt;&lt;/p&gt;
&lt;h5 id=&quot;配置步骤-2&quot;&gt;配置步骤&lt;/h5&gt;
&lt;pre&gt;
&lt;code class=&quot;language-shell&quot;&gt;[root@A ~]# vim /etc/postfix/main.cf 
# inet_interfaces = localhost  # 注释此行,不让接口直接绑定在127.0.0.1上
[root@A ~]# systemctl restart postfix
[root@A ~]# ss -tnl |grep 25
LISTEN     0      100          *:25                       *:*                  
LISTEN     0      100         :::25                      :::*  

[root@A ~]# yum -y install telnet-server
[root@A ~]# systemctl start telnet.socket

# 如果B上面有一些影响的防火墙规则就将它删掉
[root@B ~]# iptables -nL --line-number
[root@B ~]# iptables -D INPUT 1

# 测试下C能不能telnet 25端口连接A
[root@C ~]# 39.108.140.0 25
Trying 39.108.140.0...
Connected to 39.108.140.0.
Escape character is '^]'.
220 nginx_test.localdomain ESMTP Postfix

# 设置防火墙策略,使A不接受C的一切请求
[root@A ~]# iptables -A INPUT -s 39.108.140.0 -j REJECT
[root@C ~]# telnet 39.108.140.0 25
Trying 39.108.140.0...
telnet: connect to address 39.108.140.0: Connection refused

# 使用B远程转发,发送邮件到
[root@B ~]# ssh-copy-id root@116.196.83.113:
# 使用B远程转发,发送邮件到A,最好免密,否则需要手动口令验证
[root@B ~]#  ssh -R 50000:39.108.140.0:25 -fN 121.36.43.223

# 此时可以到C跳板机看到已经有端口在监听了
[root@C ~]# ss -tnl |grep 50000
LISTEN     0      128    127.0.0.1:50000                    *:*                

[root@C ~]# telnet 127.0.0.1 5000
Trying 127.0.0.1...
telnet: connect to address 127.0.0.1: Connection refused
[root@zabbix ~]# telnet 127.0.0.1 50000
Trying 127.0.0.1...
Connected to 127.0.0.1.
Escape character is '^]'.
220 nginx_test.localdomain ESMTP Postfix
mail from:youmen@163.com      
250 2.1.0 Ok
&lt;/code&gt;
&lt;/pre&gt;
&lt;h4 id=&quot;openssh升级&quot;&gt;openssh升级&lt;/h4&gt;
&lt;p&gt;&lt;code&gt;下载地址&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://ftp.openbsd.org/pub/OpenBSD/OpenSSH/portable/&quot;&gt;http://ftp.openbsd.org/pub/OpenBSD/OpenSSH/portable/&lt;/a&gt;&lt;/p&gt;
&lt;h5 id=&quot;具体升级步骤&quot;&gt;具体升级步骤&lt;/h5&gt;
&lt;pre&gt;
&lt;code class=&quot;language-shell&quot;&gt;# 记录sshd.pid路径
find / -name sshd.pid

# 查看openssh现有版本
ssh -V

# 使用rpm删除现有的openssh
rpm -e --nodeps $(rpm -qa | grep openssh)

# 删除旧的配置文件
rm -rf /etc/ssh/*

# 安装openssl-devel
yum -y install openssl-devel

# 下载tar.gz包,配置编译,安装
wget http://ftp.openbsd.org/pub/OpenBSD/OpenSSH/portable/openssh-8.0p1.tar.gz

# 编译并安装
tar xvf openssh-8.0p1.tar.gz 
cd openssh-8.0p1
./configure --prefix=/usr/ --sysconfdir=/etc/ssh/ --with-ssl-dir=/etc/ssl --with-md5-passwords --mandir=/usr/share/man/
make &amp;amp;&amp;amp; make install

# 设置ssh服务开机自启动
# 复制启动文件至/etc/init.d/
cp -a contrib/redhat/sshd.init /etc/init.d/sshd
     
# 编辑/etc/init.d/sshd文件, 将PID_FILE改为之前记下的sshd.pid路径
    sed -i &quot;s/PID_FILE=\/var\/run\/sshd.pid/PID_FILE=\/run\/sshd.pid/&quot; /etc/init.d/sshd
     
# 设置开机启动sshd
    chkconfig sshd on
    chkconfig --list sshd
    
    
# 编辑/etc/ssh/sshd_config, 设置一些常用参数
sed -i &quot;s/#PermitRootLogin prohibit-password/PermitRootLogin yes/&quot; /etc/ssh/sshd_config
sed -i &quot;s/#PubkeyAuthentication yes/PubkeyAuthentication yes/&quot; /etc/ssh/sshd_config
sed -i &quot;s/#PasswordAuthentication yes/PasswordAuthentication yes/&quot; /etc/ssh/sshd_config
sed -i &quot;s/#AllowTcpForwarding yes/AllowTcpForwarding yes/&quot; /etc/ssh/sshd_config
sed -i &quot;s/#X11Forwarding no/X11Forwarding yes/&quot; /etc/ssh/sshd_config
sed -i &quot;s/#PidFile \/var\/run\/sshd.pid/PidFile \/run\/sshd.pid/&quot; /etc/ssh/sshd_config

# 加入系统服务
cat &amp;gt; /usr/lib/systemd/system/sshd.service  &amp;lt;&amp;lt; EOF
[Unit]
Description=OpenSSH server daemon
Documentation=man:sshd(8) man:sshd_config(5)
#After=network.target sshd-keygen.service
#Wants=sshd-keygen.service
After=network.target
[Service]
ExecStart=/usr/sbin/sshd
[Install]
WantedBy=multi-user.target
EOF

# 启用sshd服务
systemctl enable sshd
# 重启服务
systemctl restart sshd
# 查看服务状态
systemctl status sshd

# 验证
ssh -V
OpenSSH_8.0p1, OpenSSL 1.0.2k-fips  26 Jan 2017
&lt;/code&gt;
&lt;/pre&gt;
&lt;h4 id=&quot;ssh设置登录欢迎信息&quot;&gt;SSH设置登录欢迎信息&lt;/h4&gt;
&lt;p&gt;&lt;code&gt;到/etc/motd里面编写内容,看个人爱好&lt;/code&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-shell&quot;&gt;[root@nginx_test ~]# cat /etc/motd 
　　／＼／＼
　 (_人｜人_)
　　 ／‥＼
　 ミ(_Ｙ_)ミ
　　 ＞　＜
　　(／　＼)
　 _(　　　)_
　(＿＞―＜＿)

# 关闭当前会话再登录
　　／＼／＼
　 (_人｜人_)
　　 ／‥＼
　 ミ(_Ｙ_)ミ
　　 ＞　＜
　　(／　＼)
　 _(　　　)_
　(＿＞―＜＿)
[root@nginx_test ~]#
&lt;/code&gt;
&lt;/pre&gt;
&lt;h5 id=&quot;小熊图案&quot;&gt;小熊图案&lt;/h5&gt;
&lt;pre&gt;
&lt;code class=&quot;language-shell&quot;&gt;┴┬┴┬／￣＼＿／￣＼   
┬┴┬┴▏　　▏▔▔▔▔＼   
┴┬┴／＼　／　　　　　　﹨   
┬┴∕　　　　　　　／　　　）   
┴┬▏　　　　　　　　●　　▏   
┬┴▏　　　　　　　　　　　▔█　   
┴◢██◣　　　　　＼＿＿＿／   
┬█████◣　　　　　　　／　　   
┴█████████████◣   
◢██████████████▆▄   
█◤◢██◣◥█████████◤＼   
◥◢████　████████◤　　 ＼   
┴█████　██████◤　　　　　 ﹨   
┬│　　　│█████◤　　　　　　　　▏   
┴│　　　│　　　　　　　　　　　　　　▏   
┬ ∕　　　 ∕　　　　／▔▔▔＼　　　　 ∕   
┴/＿＿＿／﹨　　　∕　　　　　﹨　　／＼   
┬┴┬┴┬┴＼ 　　 ＼ 　　　　　﹨／　　 ﹨   
┴┬┴┬┴┬┴ ＼＿＿＿＼　　　　 ﹨／▔＼﹨ ▔＼   
▲△▲▲╓╥╥╥╥╥╥╥╥＼　　 ∕　 ／▔﹨／▔﹨   
　  ＊＊╠╬╬╬╬╬╬╬╬＊﹨　　／　　／／
&lt;/code&gt;
&lt;/pre&gt;</description>
<pubDate>Fri, 12 Jun 2020 16:12:00 +0000</pubDate>
<dc:creator>you-men</dc:creator>
<og:description>SSH介绍 SSH是Secure Shell Protocol的简写，由IETF网络工作小组（Network working Group）指定；在进行数据传输之前，SSH先对联机数据包通过加密技术进行</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/you-men/p/13111313.html</dc:identifier>
</item>
<item>
<title>ThreadLocal的使用场景分析 - 寻觅beyond</title>
<link>http://www.cnblogs.com/-beyond/p/13111015.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/-beyond/p/13111015.html</guid>
<description>&lt;h2&gt;目录&lt;/h2&gt;
&lt;p&gt;一.&lt;a href=&quot;https://www.cnblogs.com/-beyond/p/13111015.html#intro&quot; target=&quot;_blank&quot;&gt;ThreadLocal介绍&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;二.&lt;a href=&quot;https://www.cnblogs.com/-beyond/p/13111015.html#tx&quot; target=&quot;_blank&quot;&gt;使用场景1——数据库事务问题&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;　　2.1 &lt;a href=&quot;https://www.cnblogs.com/-beyond/p/13111015.html#problem&quot; target=&quot;_blank&quot;&gt;问题背景&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;　　2.2 &lt;a href=&quot;https://www.cnblogs.com/-beyond/p/13111015.html#change-api&quot; target=&quot;_blank&quot;&gt;方案1-修改接口传参&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;　　2.3 &lt;a href=&quot;https://www.cnblogs.com/-beyond/p/13111015.html#use-threadlocal&quot; target=&quot;_blank&quot;&gt;方案2-使用ThreadLocal&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;三.&lt;a href=&quot;https://www.cnblogs.com/-beyond/p/13111015.html#log-trace&quot; target=&quot;_blank&quot;&gt;使用场景2——日志追踪问题&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;四.&lt;a href=&quot;https://www.cnblogs.com/-beyond/p/13111015.html#other&quot; target=&quot;_blank&quot;&gt;其他使用场景&lt;/a&gt;&lt;/p&gt;


&lt;h2&gt;一.ThreadLocal介绍&lt;/h2&gt;
&lt;p&gt;　　我们知道，变量从作用域范围进行分类，可以分为“全局变量”、“局部变量”两种：&lt;/p&gt;
&lt;p&gt;　　1.全局变量（global variable），比如类的静态属性（加static关键字），在类的整个生命周期都有效；&lt;/p&gt;
&lt;p&gt;　　2.局部变量（local variable)，比如在一个方法中定义的变量，作用域只是在当前方法内，方法执行完毕后，变量就销毁（释放）了；&lt;/p&gt;
&lt;p&gt;　　使用全局变量，当多个线程同时修改静态属性，就容易出现并发问题，导致脏数据；而局部变量一般来说不会出现并发问题（在方法中开启多线程并发修改局部变量，仍可能引起并发问题）；&lt;/p&gt;
&lt;p&gt;　　再看ThreadLocal，从名称上就能知道，它可以用来保存局部变量，只不过这个“局部”是指“线程”作用域，也就是说，该变量在该线程的整个生命周期中有效。&lt;/p&gt;

&lt;h2&gt;二.使用场景1——数据库事务问题&lt;/h2&gt;
&lt;h3&gt;2.1问题背景&lt;/h3&gt;
&lt;p&gt;　　下面介绍示例，UserService调用UserDao删除用户信息，涉及到两张表的操作，所以用到了数据库事务:&lt;/p&gt;
&lt;p&gt;　　数据库封装类DbUtils&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;34&quot;&gt;
&lt;pre class=&quot;brush:java;gutter:true;&quot;&gt;
public class DbUtils {

    // 使用C3P0连接池
    private static ComboPooledDataSource dataSource = new ComboPooledDataSource(&quot;dev&quot;);

    public static Connection getConnectionFromPool() throws SQLException {
        return dataSource.getConnection();
    }

    // 省略其他方法.....
}
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　UserService代码如下：　　&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;37&quot;&gt;
&lt;pre class=&quot;brush:java;gutter:true;&quot;&gt;
public class UserService {

    private UserDao userDao;

    public void deleteUserInfo(Integer id, String operator) {
        Connection connection = null;
        try {
            // 从连接池中获取一个连接
            connection = DbUtils.getConnectionFromPool();
            // 因为涉及事务操作，所以需要关闭自动提交
            connection.setAutoCommit(false);

            // 事务涉及两步操作，删除用户表，增加操作日志
            userDao.deleteUserById(id);
            userDao.addOperateLog(id, operator);

            connection.commit();
        } catch (SQLException e) {
            // 回滚操作
            try {
                if (connection != null) {
                    connection.rollback();
                }
            } catch (SQLException ex) {
            }
        } finally {
            DbUtils.freeConnection(connection);
        }
    }
}
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　下面是UserDao，省略了部分代码：&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;36&quot;&gt;
&lt;pre class=&quot;brush:java;gutter:true;&quot;&gt;
package cn.ganlixin.dao;
import cn.ganlixin.util.DbUtils;
import java.sql.Connection;

/**
 * @author ganlixin
 * @create 2020-06-12
 */
public class UserDao {

    public void deleteUserById(Integer id) {
        // 从连接池中获取一个数据连接
        Connection connection = DbUtils.getConnectionFromPool();

        // 利用获取的数据库连接，执行sql...........删除用户表的一条数据

        // 归还连接给连接池
        DbUtils.freeConnection(connection);
    }

    public void addOperateLog(Integer id, String operator) {
        // 从连接池中获取一个数据连接
        Connection connection = DbUtils.getConnectionFromPool();

        // 利用获取的数据库连接，执行sql...........插入一条记录到操作日志表

        // 归还连接给连接池
        DbUtils.freeConnection(connection);
    }
}
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　上面的代码乍一看，好像没啥问题，但是仔细看，其实是存在问题的！！问题出在哪儿呢？就出在从数据库连接池获取连接哪个位置。&lt;/p&gt;
&lt;p&gt;　　1.UserService会从数据库连接池获取一个连接，关闭该连接的自动提交；&lt;/p&gt;
&lt;p&gt;　　2.UserService然后调用UserDao的两个接口进行数据库操作；&lt;/p&gt;
&lt;p&gt;　　3.UserDao的两个接口，都会从数据库连接池获取一个连接，然后执行sql；&lt;/p&gt;
&lt;p&gt;　　注意，第1步和第3步获得的连接不一定是同一个！！！！这才是关键。&lt;/p&gt;
&lt;p&gt;　　如果UserService和UserDao获取的数据库连接不是同一个，那么UserService中关闭自动提交的数据库连接，并不是UserDao接口中执行sql的数据库连接，当userService中捕获异常，即使执行rollback，userDao中的sql已经执行完了，并不会回滚，所以数据已经出现不一致！！！&lt;/p&gt;

&lt;h3&gt;2.2方案1-修改接口传参&lt;/h3&gt;
&lt;p&gt;　　上面的例子中，因为UserService和UserDao获取的连接不是同一个，所以并不能保证事务原子性；那么只要能够解决这个问题，就可以保证了&lt;/p&gt;
&lt;p&gt;　　可以修改userDao中的代码，不要每次在UserDao中从数据库连接池获取连接，而是增加一个参数，该参数就是数据库连接，有UserService传入，这样就能保证UserService和UserDao使用同一个数据库连接了&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;38&quot;&gt;
&lt;pre class=&quot;brush:java;gutter:true;&quot;&gt;
public class UserDao {

    public void deleteUserById(Connection connection, Integer id) {
        // 利用传入的数据库连接，执行sql...........删除用户表的一条数据
    }

    public void addOperateLog(Connection connection, Integer id, String operator) {
        // 利用传入的数据库连接，执行sql...........插入一条记录到操作日志表
    }
}
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　UserService调用接口时，传入数据库连接，修改代码后如下：&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;37&quot;&gt;
&lt;pre class=&quot;brush:java;gutter:true;&quot;&gt;
// 事务涉及两步操作，删除用户表，增加操作日志
// 新增参数传入数据库连接，保证UserService和UserDao使用同一个连接
userDao.deleteUserById(connection, id);
userDao.addOperateLog(connection, id, operator);
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　这样做，的确是能解决数据库事务的问题，但是并不推荐这样做，耦合度太高，不利于维护，修改起来也不方便；&lt;/p&gt;

&lt;h3&gt;2.3使用ThreadLocal解决&lt;/h3&gt;
&lt;p&gt;　　ThreadLocal可以保存当前线程有效的变量，正好适合解决这个问题，而且改动的点也特别小，只需要在DbUtils获取连接的时候，将获取到的连接存到ThreadLocal中即可：&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;35&quot;&gt;
&lt;pre class=&quot;brush:java;gutter:true;&quot;&gt;
public class DbUtils {

    // 使用C3P0连接池
    private static ComboPooledDataSource dataSource = new ComboPooledDataSource(&quot;dev&quot;);

    // 创建threadLocal对象，保存每个线程的数据库连接对象
    private static ThreadLocal&amp;lt;Connection&amp;gt; threadLocal = new ThreadLocal&amp;lt;&amp;gt;();

    public static Connection getConnectionFromPool() throws SQLException {
        if (threadLocal.get() == null) {
            threadLocal.set(dataSource.getConnection());
        }

        return threadLocal.get();
    }

    // 省略其他方法.....
}
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　然后UserService和UserDao中，恢复最初的版本，UserService和UserDao中都调用DbUtils获取数据库连接，此时他们获取到的连接则是同一个Connection对象，就可以解决数据库事务问题了。&lt;/p&gt;

&lt;h2&gt;三.使用场景2——日志追踪问题&lt;/h2&gt;
&lt;p&gt;　　如果理解了场景1的数据库事务问题，那么对于本小节的日志追踪，光看标题就知道是怎么回事了；&lt;/p&gt;
&lt;p&gt;　　开发过程时，会在项目中打很多的日志，一般来说，查看日志的时候，都是通过关键字去找日志，这就需要我们在打日志的时候明确的写入某些标识，比如用户ID、订单号、流水号...&lt;/p&gt;
&lt;p&gt;　　如果业务比较复杂，那么一个请求的处理流程就会比较长，如果将这么一长串的流程给串起来，也可以通过前面说的用户ID、订单号、流水号来串，但有个问题，某些接口没有用户ID或者订单号作为参数！！！！这个时候，当然可以像场景1中给接口增加用户ID或者订单号作为参数，但是这样实现起来，除非想被炒鱿鱼，否则就别这样做。&lt;/p&gt;
&lt;p&gt;　　此时可以就可以使用ThreadLocal，封装一个工具类，提供唯一标识（可以是用户ID、订单号、或者是分布式全局ID），示例如下：&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;36&quot;&gt;
&lt;pre class=&quot;brush:java;gutter:true;&quot;&gt;
package cn.ganlixin.util;

/**
 * 描述:
 * 日志追踪工具类，设置和获取traceId，
 * 此处的traceId使用snowFlake雪花数算法，详情可以参考：https://www.cnblogs.com/-beyond/p/12452632.html
 *
 * @author ganlixin
 * @create 2020-06-12
 */
public class TraceUtils {
    // 创建ThreadLocal静态属性，存Long类型的uuid
    private static final ThreadLocal&amp;lt;Long&amp;gt; threadLocal = new ThreadLocal&amp;lt;&amp;gt;();

    // 全局id生成器（雪花数算法）
    private static final SnowFlakeIdGenerator generator = new SnowFlakeIdGenerator(1, 1);

    public static void setUuid(String uuid) {
        // 雪花数算法
        threadLocal.set(generator.nextId());
    }

    public static Long getUuid() {
        if (threadLocal.get() == null) {
            threadLocal.set(generator.nextId());
        }
        return threadLocal.get();
    }
}
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;　　使用示例：&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;45&quot;&gt;
&lt;pre class=&quot;brush:java;gutter:true;&quot;&gt;
@Slf4j
public class UserService {

    private UserDao userDao;

    public void deleteUserInfo(Integer id, String operator) {
        log.info(&quot;traceId:{}, id:{}, operator:{}&quot;, TraceUtils.getUuid(), id, operator);
        
        //.....
    }
}

@Slf4j
public class UserDao {

    public void deleteUserById(Connection connection, Integer id) {
        log.info(&quot;traceId:{}, id:{}&quot;, TraceUtils.getUuid(), id);
    }
}
&lt;/pre&gt;&lt;/div&gt;

&lt;h2&gt; 四.其他场景&lt;/h2&gt;
&lt;p&gt;　　其他场景，其实就是利用ThreadLocal“线程私有且线程间互不影响”特性，除了上面的两个场景，常见的还有用来记录用户的登录状态（当然也可以用session或者cookie实现）。&lt;/p&gt;

&lt;p&gt;　　原文地址：&lt;a href=&quot;https://www.cnblogs.com/-beyond/p/13111015.html&quot;&gt;https://www.cnblogs.com/-beyond/p/13111015.html&lt;/a&gt; &lt;/p&gt;
</description>
<pubDate>Fri, 12 Jun 2020 15:19:00 +0000</pubDate>
<dc:creator>寻觅beyond</dc:creator>
<og:description>目录 一.ThreadLocal介绍 二.使用场景1——数据库事务问题 2.1 问题背景 2.2 方案1-修改接口传参 2.3 方案2-使用ThreadLocal 三.使用场景2——日志追踪问题 四.</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/-beyond/p/13111015.html</dc:identifier>
</item>
<item>
<title>附022.Kubernetes_v1.18.3高可用部署架构一 - 木二</title>
<link>http://www.cnblogs.com/itzgr/p/13111119.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/itzgr/p/13111119.html</guid>
<description>&lt;h3 id=&quot;kubeadm介绍&quot;&gt;kubeadm介绍&lt;/h3&gt;
&lt;h4 id=&quot;kubeadm概述&quot;&gt;kubeadm概述&lt;/h4&gt;
&lt;p&gt;参考&lt;a href=&quot;https://www.cnblogs.com/itzgr/p/11050543.html&quot;&gt;附003.Kubeadm部署Kubernetes&lt;/a&gt;。&lt;/p&gt;
&lt;h4 id=&quot;kubeadm功能&quot;&gt;kubeadm功能&lt;/h4&gt;
&lt;p&gt;参考&lt;a href=&quot;https://www.cnblogs.com/itzgr/p/11050543.html&quot;&gt;附003.Kubeadm部署Kubernetes&lt;/a&gt;。&lt;/p&gt;
&lt;h4 id=&quot;本方案描述&quot;&gt;本方案描述&lt;/h4&gt;
&lt;ul&gt;&lt;li&gt;本方案采用kubeadm部署Kubernetes 1.18.3版本；&lt;/li&gt;
&lt;li&gt;etcd采用混部方式；&lt;/li&gt;
&lt;li&gt;Keepalived：实现VIP高可用；&lt;/li&gt;
&lt;li&gt;Nginx：以Pod形式运行与Kubernetes之上，即in Kubernetes模式，提供反向代理至3个master 6443端口；&lt;/li&gt;
&lt;li&gt;其他主要部署组件包括：
&lt;ul&gt;&lt;li&gt;Metrics：度量；&lt;/li&gt;
&lt;li&gt;Dashboard：Kubernetes 图形UI界面；&lt;/li&gt;
&lt;li&gt;Helm：Kubernetes Helm包管理工具；&lt;/li&gt;
&lt;li&gt;Ingress：Kubernetes 服务暴露；&lt;/li&gt;
&lt;li&gt;Longhorn：Kubernetes 动态存储组件。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;h3 id=&quot;部署规划&quot;&gt;部署规划&lt;/h3&gt;
&lt;h4 id=&quot;节点规划&quot;&gt;节点规划&lt;/h4&gt;
&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;节点主机名&lt;/th&gt;
&lt;th&gt;IP&lt;/th&gt;
&lt;th&gt;类型&lt;/th&gt;
&lt;th&gt;运行服务&lt;/th&gt;
&lt;/tr&gt;&lt;/thead&gt;&lt;tbody readability=&quot;7.5&quot;&gt;&lt;tr readability=&quot;3&quot;&gt;&lt;td&gt;master01&lt;/td&gt;
&lt;td&gt;172.24.8.71&lt;/td&gt;
&lt;td&gt;Kubernetes master节点&lt;/td&gt;
&lt;td&gt;docker、etcd、kube-apiserver、kube-scheduler、kube-controller-manager、kubectl、kubelet、metrics、calico&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;3&quot;&gt;&lt;td&gt;master02&lt;/td&gt;
&lt;td&gt;172.24.8.72&lt;/td&gt;
&lt;td&gt;Kubernetes master节点&lt;/td&gt;
&lt;td&gt;docker、etcd、kube-apiserver、kube-scheduler、kube-controller-manager、kubectl、kubelet、metrics、calico&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;3&quot;&gt;&lt;td&gt;master03&lt;/td&gt;
&lt;td&gt;172.24.8.73&lt;/td&gt;
&lt;td&gt;Kubernetes master节点&lt;/td&gt;
&lt;td&gt;docker、etcd、kube-apiserver、kube-scheduler、kube-controller-manager、kubectl、kubelet、metrics、calico&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;worker01&lt;/td&gt;
&lt;td&gt;172.24.8.74&lt;/td&gt;
&lt;td&gt;Kubernetes worker节点&lt;/td&gt;
&lt;td&gt;docker、kubelet、proxy、calico&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;worker02&lt;/td&gt;
&lt;td&gt;172.24.8.75&lt;/td&gt;
&lt;td&gt;Kubernetes worker节点&lt;/td&gt;
&lt;td&gt;docker、kubelet、proxy、calico&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;worker03&lt;/td&gt;
&lt;td&gt;172.24.8.76&lt;/td&gt;
&lt;td&gt;Kubernetes worker节点&lt;/td&gt;
&lt;td&gt;docker、kubelet、proxy、calico&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;Kubernetes的高可用主要指的是控制平面的高可用，即指多套Master节点组件和Etcd组件，工作节点通过负载均衡连接到各Master。&lt;br/&gt;&lt;img src=&quot;https://bed01.oss-cn-hangzhou.aliyuncs.com/study/kubernetes/f022/001.png&quot; alt=&quot;架构图&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;Kubernetes高可用架构中etcd与Master节点组件混布方式特点：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;Etcd混布方式&lt;/li&gt;
&lt;li&gt;所需机器资源少&lt;/li&gt;
&lt;li&gt;部署简单，利于管理&lt;/li&gt;
&lt;li&gt;容易进行横向扩展&lt;/li&gt;
&lt;li&gt;风险大，一台宿主机挂了，master和etcd就都少了一套，集群冗余度受到的影响比较大。&lt;/li&gt;
&lt;/ul&gt;&lt;h4 id=&quot;初始准备&quot;&gt;初始准备&lt;/h4&gt;
&lt;p&gt;&lt;code&gt;[root@master01 ~]# hostnamectl set-hostname master01 #其他节点依次修改&lt;/code&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;[root@master01 ~]# cat &amp;gt;&amp;gt; /etc/hosts &amp;lt;&amp;lt; EOF
172.24.8.71 master01··
172.24.8.72 master02
172.24.8.73 master03
172.24.8.74 worker01
172.24.8.75 worker02
172.24.8.76 worker03
EOF
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;[root@master01 ~]# vi k8sinit.sh&lt;/code&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;#!/bin/sh
#****************************************************************#
# ScriptName: k8sinit.sh
# Author: xhy
# Create Date: 2020-05-30 16:30
# Modify Author: xhy
# Modify Date: 2020-05-30 16:30
# Version: 
#***************************************************************#
# Initialize the machine. This needs to be executed on every machine.

# Add docker user
useradd -m docker

# Disable the SELinux.
sed -i 's/^SELINUX=.*/SELINUX=disabled/' /etc/selinux/config

# Turn off and disable the firewalld.
systemctl stop firewalld
systemctl disable firewalld

# Modify related kernel parameters &amp;amp; Disable the swap.
cat &amp;gt; /etc/sysctl.d/k8s.conf &amp;lt;&amp;lt; EOF
net.ipv4.ip_forward = 1
net.bridge.bridge-nf-call-ip6tables = 1
net.bridge.bridge-nf-call-iptables = 1
net.ipv4.tcp_tw_recycle = 0
vm.swappiness = 0
vm.overcommit_memory = 1
vm.panic_on_oom = 0
net.ipv6.conf.all.disable_ipv6 = 1
EOF
sysctl -p /etc/sysctl.d/k8s.conf &amp;gt;&amp;amp;/dev/null
swapoff -a
sed -i '/ swap / s/^\(.*\)$/#\1/g' /etc/fstab
modprobe br_netfilter

# Add ipvs modules
cat &amp;gt; /etc/sysconfig/modules/ipvs.modules &amp;lt;&amp;lt;EOF
#!/bin/bash
modprobe -- ip_vs
modprobe -- ip_vs_rr
modprobe -- ip_vs_wrr
modprobe -- ip_vs_sh
modprobe -- nf_conntrack_ipv4
modprobe -- nf_conntrack
EOF

chmod 755 /etc/sysconfig/modules/ipvs.modules
bash /etc/sysconfig/modules/ipvs.modules

# Install rpm
yum install -y conntrack ntpdate ntp ipvsadm ipset jq iptables curl sysstat libseccomp wget

# Install Docker Compose
sudo curl -L &quot;http://down.linuxsb.com:8888/docker/compose/releases/download/1.25.4/docker-compose-$(uname -s)-$(uname -m)&quot; -o /usr/local/bin/docker-compose
sudo chmod +x /usr/local/bin/docker-compose

# Update kernel
rpm --import http://down.linuxsb.com:8888/RPM-GPG-KEY-elrepo.org
rpm -Uvh http://down.linuxsb.com:8888/elrepo-release-7.0-4.el7.elrepo.noarch.rpm
yum --disablerepo=&quot;*&quot; --enablerepo=&quot;elrepo-kernel&quot; install -y kernel-ml
sed -i 's/^GRUB_DEFAULT=.*/GRUB_DEFAULT=0/' /etc/default/grub
grub2-mkconfig -o /boot/grub2/grub.cfg
yum update -y

# Reboot the machine.
# reboot
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;提示：对于某些特性，可能需要升级内核，内核升级操作见《018.Linux升级内核》。4.19版及以上内核nf_conntrack_ipv4已经改为nf_conntrack。&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;
&lt;h4 id=&quot;互信配置&quot;&gt;互信配置&lt;/h4&gt;
&lt;p&gt;为了更方便远程分发文件和执行命令，本实验配置master节点到其它节点的 ssh 信任关系。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;[root@master01 ~]# ssh-keygen -f ~/.ssh/id_rsa -N ''
[root@master01 ~]# ssh-copy-id -i ~/.ssh/id_rsa.pub root@master01
[root@master01 ~]# ssh-copy-id -i ~/.ssh/id_rsa.pub root@master02
[root@master01 ~]# ssh-copy-id -i ~/.ssh/id_rsa.pub root@master03
[root@master01 ~]# ssh-copy-id -i ~/.ssh/id_rsa.pub root@worker01
[root@master01 ~]# ssh-copy-id -i ~/.ssh/id_rsa.pub root@worker02
[root@master01 ~]# ssh-copy-id -i ~/.ssh/id_rsa.pub root@worker03
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;提示：此操作仅需要在master节点操作。&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;
&lt;h4 id=&quot;其他准备&quot;&gt;其他准备&lt;/h4&gt;
&lt;p&gt;&lt;code&gt;[root@master01 ~]# vi environment.sh&lt;/code&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;#!/bin/sh
#****************************************************************#
# ScriptName: environment.sh
# Author: xhy
# Create Date: 2020-05-30 16:30
# Modify Author: xhy
# Modify Date: 2020-05-30 16:30
# Version: 
#***************************************************************#
# 集群 MASTER 机器 IP 数组
export MASTER_IPS=(172.24.8.71 172.24.8.72 172.24.8.73)

# 集群 MASTER IP 对应的主机名数组
export MASTER_NAMES=(master01 master02 master03)

# 集群 NODE 机器 IP 数组
export NODE_IPS=(172.24.8.74 172.24.8.75 172.24.8.76)

# 集群 NODE IP 对应的主机名数组
export NODE_NAMES=(worker01 worker02 worker03)

# 集群所有机器 IP 数组
export ALL_IPS=(172.24.8.71 172.24.8.72 172.24.8.73 172.24.8.74 172.24.8.75 172.24.8.76)

# 集群所有IP 对应的主机名数组
export ALL_NAMES=(master01 master02 master03 worker01 worker02 worker03)
&lt;/code&gt;
&lt;/pre&gt;
&lt;pre&gt;
&lt;code&gt;[root@master01 ~]# source environment.sh
[root@master01 ~]# chmod +x *.sh
[root@master01 ~]# for all_ip in ${ALL_IPS[@]}
  do
    echo &quot;&amp;gt;&amp;gt;&amp;gt; ${all_ip}&quot;
    scp -rp /etc/hosts root@${all_ip}:/etc/hosts
    scp -rp k8sinit.sh root@${all_ip}:/root/
    ssh root@${all_ip} &quot;bash /root/k8sinit.sh&quot;
  done
&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;集群部署&quot;&gt;集群部署&lt;/h3&gt;
&lt;h4 id=&quot;docker安装&quot;&gt;Docker安装&lt;/h4&gt;
&lt;pre&gt;
&lt;code&gt;[root@master01 ~]# for all_ip in ${ALL_IPS[@]}
  do
    echo &quot;&amp;gt;&amp;gt;&amp;gt; ${all_ip}&quot;
    ssh root@${all_ip} &quot;yum -y install yum-utils device-mapper-persistent-data lvm2&quot;
    ssh root@${all_ip} &quot;yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo&quot;
    ssh root@${all_ip} &quot;yum -y install docker-ce&quot;
    ssh root@${all_ip} &quot;mkdir /etc/docker&quot;
    ssh root@${all_ip} &quot;cat &amp;gt; /etc/docker/daemon.json &amp;lt;&amp;lt;EOF
{
  \&quot;registry-mirrors\&quot;: [\&quot;https://dbzucv6w.mirror.aliyuncs.com\&quot;],
  \&quot;exec-opts\&quot;: [\&quot;native.cgroupdriver=systemd\&quot;],
  \&quot;log-driver\&quot;: \&quot;json-file\&quot;,
  \&quot;log-opts\&quot;: {
    \&quot;max-size\&quot;: \&quot;100m\&quot;
  },
  \&quot;storage-driver\&quot;: \&quot;overlay2\&quot;,
  \&quot;storage-opts\&quot;: [
    \&quot;overlay2.override_kernel_check=true\&quot;
  ]
}
EOF&quot;
    ssh root@${all_ip} &quot;systemctl restart docker&quot;
    ssh root@${all_ip} &quot;systemctl enable docker&quot;
    ssh root@${all_ip} &quot;systemctl status docker&quot;
    ssh root@${all_ip} &quot;iptables -nvL&quot;
  done
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;提示：如上仅需Master01节点操作，从而实现所有节点自动化安装。&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;
&lt;h4 id=&quot;相关组件包&quot;&gt;相关组件包&lt;/h4&gt;
&lt;p&gt;需要在每台机器上都安装以下的软件包：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;kubeadm: 用来初始化集群的指令；&lt;/li&gt;
&lt;li&gt;kubelet: 在集群中的每个节点上用来启动 pod 和 container 等；&lt;/li&gt;
&lt;li&gt;kubectl: 用来与集群通信的命令行工具。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;&lt;strong&gt;kubeadm不能安装或管理 kubelet 或 kubectl ，所以得保证他们满足通过 kubeadm 安装的 Kubernetes控制层对版本的要求。如果版本没有满足要求，可能导致一些意外错误或问题。&lt;br/&gt;具体相关组件安装见；&lt;a href=&quot;https://www.cnblogs.com/itzgr/p/10258937.html&quot;&gt;附001.kubectl介绍及使用书&lt;/a&gt;&lt;/strong&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;提示：Kubernetes 1.18版本所有兼容相应组件的版本参考：&lt;a href=&quot;https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG/CHANGELOG-1.18.md%E3%80%82&quot;&gt;https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG/CHANGELOG-1.18.md。&lt;/a&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;
&lt;h4 id=&quot;正式安装&quot;&gt;正式安装&lt;/h4&gt;
&lt;pre&gt;
&lt;code&gt;[root@master01 ~]# for all_ip in ${ALL_IPS[@]}
  do
    echo &quot;&amp;gt;&amp;gt;&amp;gt; ${all_ip}&quot;
    ssh root@${all_ip} &quot;cat &amp;lt;&amp;lt;EOF &amp;gt; /etc/yum.repos.d/kubernetes.repo
[kubernetes]
name=Kubernetes
baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/
enabled=1
gpgcheck=1
repo_gpgcheck=1
gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg
EOF&quot;
    ssh root@${all_ip} &quot;yum install -y kubeadm-1.18.3-0.x86_64 kubelet-1.18.3-0.x86_64 kubectl-1.18.3-0.x86_64 --disableexcludes=kubernetes&quot;
    ssh root@${all_ip} &quot;systemctl enable kubelet&quot;
done
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;[root@master01 ~]# yum search -y kubelet --showduplicates #查看相应版本&lt;/code&gt;&lt;br/&gt;&lt;img src=&quot;https://bed01.oss-cn-hangzhou.aliyuncs.com/study/kubernetes/f022/002.png&quot; alt=&quot;002&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;提示：如上仅需Master01节点操作，从而实现所有节点自动化安装，同时此时不需要启动kubelet，初始化的过程中会自动启动的，如果此时启动了会出现报错，忽略即可。&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;说明：同时安装了cri-tools, kubernetes-cni, socat三个依赖：&lt;br/&gt;socat：kubelet的依赖；&lt;br/&gt;cri-tools：即CRI(Container Runtime Interface)容器运行时接口的命令行工具。&lt;/strong&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&quot;部署高可用组件i&quot;&gt;部署高可用组件I&lt;/h3&gt;
&lt;h4 id=&quot;keepalived安装&quot;&gt;Keepalived安装&lt;/h4&gt;
&lt;pre&gt;
&lt;code&gt;[root@master01 ~]# for master_ip in ${MASTER_IPS[@]}
  do
    echo &quot;&amp;gt;&amp;gt;&amp;gt; ${master_ip}&quot;
    ssh root@${master_ip} &quot;yum -y install gcc gcc-c++ make libnl libnl-devel libnfnetlink-devel openssl-devel&quot;
    ssh root@${master_ip} &quot;wget http://down.linuxsb.com:8888/software/keepalived-2.0.20.tar.gz&quot;
    ssh root@${master_ip} &quot;tar -zxvf keepalived-2.0.20.tar.gz&quot;
    ssh root@${master_ip} &quot;cd keepalived-2.0.20/ &amp;amp;&amp;amp; ./configure --sysconf=/etc --prefix=/usr/local/keepalived &amp;amp;&amp;amp; make &amp;amp;&amp;amp; make install&quot;
    ssh root@${master_ip} &quot;systemctl enable keepalived &amp;amp;&amp;amp; systemctl start keepalived&quot;
  done
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;提示：如上仅需Master01节点操作，从而实现所有节点自动化安装。&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;
&lt;h4 id=&quot;创建配置文件&quot;&gt;创建配置文件&lt;/h4&gt;
&lt;pre&gt;
&lt;code&gt;[root@master01 ~]# wget http://down.linuxsb.com:8888/ngkek8s.sh              #拉取自动部署脚本
[root@master01 ~]# chmod u+x ngkek8s.sh
&lt;/code&gt;
&lt;/pre&gt;
&lt;pre&gt;
&lt;code&gt;[root@master01 ~]# vi ngkek8s.sh
#!/bin/sh
#****************************************************************#
# ScriptName: k8s_ha.sh
# Author: xhy
# Create Date: 2020-05-13 16:32
# Modify Author: xhy
# Modify Date: 2020-06-12 12:53
# Version: v2
#***************************************************************#

#######################################
# set variables below to create the config files, all files will create at ./config directory
#######################################

# master keepalived virtual ip address
export K8SHA_VIP=172.24.8.100

# master01 ip address
export K8SHA_IP1=172.24.8.71

# master02 ip address
export K8SHA_IP2=172.24.8.72

# master03 ip address
export K8SHA_IP3=172.24.8.73

# master01 hostname
export K8SHA_HOST1=master01

# master02 hostname
export K8SHA_HOST2=master02

# master03 hostname
export K8SHA_HOST3=master03

# master01 network interface name
export K8SHA_NETINF1=eth0

# master02 network interface name
export K8SHA_NETINF2=eth0

# master03 network interface name
export K8SHA_NETINF3=eth0

# keepalived auth_pass config
export K8SHA_KEEPALIVED_AUTH=412f7dc3bfed32194d1600c483e10ad1d

# kubernetes CIDR pod subnet
export K8SHA_PODCIDR=10.10.0.0

# kubernetes CIDR svc subnet
export K8SHA_SVCCIDR=10.20.0.0
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;[root@master01 ~]# ./ngkek8s.sh&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;解释：如上仅需Master01节点操作。执行ngkek8s.sh脚本后，会自动生成以下配置文件：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;kubeadm-config.yaml：kubeadm初始化配置文件，位于当前目录&lt;/li&gt;
&lt;li&gt;keepalived：keepalived配置文件，位于各个master节点的/etc/keepalived目录&lt;/li&gt;
&lt;li&gt;nginx-lb：nginx-lb负载均衡配置文件，位于各个master节点的/etc/kubernetes/nginx-lb/目录&lt;/li&gt;
&lt;li&gt;calico.yaml：calico网络组件部署文件，位于config/calico/目录&lt;/li&gt;
&lt;/ul&gt;&lt;pre&gt;
&lt;code&gt;[root@master01 ~]# cat kubeadm-config.yaml           #检查集群初始化配置
apiVersion: kubeadm.k8s.io/v1beta2
kind: ClusterConfiguration
networking:
  serviceSubnet: &quot;10.20.0.0/16&quot;                               #设置svc网段
  podSubnet: &quot;10.10.0.0/16&quot;                           #设置Pod网段
  dnsDomain: &quot;cluster.local&quot;
kubernetesVersion: &quot;v1.18.3&quot;                          #设置安装版本
controlPlaneEndpoint: &quot;172.24.8.100:16443&quot;            #设置相关API VIP地址
apiServer:
  certSANs:
  - master01
  - master02
  - master03
  - 127.0.0.1
  - 172.24.8.71
  - 172.24.8.72
  - 172.24.8.73
  - 172.24.8.100
  timeoutForControlPlane: 4m0s
certificatesDir: &quot;/etc/kubernetes/pki&quot;
imageRepository: &quot;k8s.gcr.io&quot;
---
apiVersion: kubeproxy.config.k8s.io/v1alpha1
kind: KubeProxyConfiguration
featureGates:
  SupportIPVSProxyMode: true
mode: ipvs
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;提示：如上仅需Master01节点操作，更多config文件参考：&lt;a href=&quot;https://godoc.org/k8s.io/kubernetes/cmd/kubeadm/app/apis/kubeadm/v1beta2%E3%80%82&quot;&gt;https://godoc.org/k8s.io/kubernetes/cmd/kubeadm/app/apis/kubeadm/v1beta2。&lt;/a&gt;&lt;br/&gt;此kubeadm部署初始化配置更多参考：&lt;a href=&quot;https://pkg.go.dev/k8s.io/kubernetes/cmd/kubeadm/app/apis/kubeadm/v1beta2?tab=doc%E3%80%82&quot;&gt;https://pkg.go.dev/k8s.io/kubernetes/cmd/kubeadm/app/apis/kubeadm/v1beta2?tab=doc。&lt;/a&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;
&lt;h4 id=&quot;启动keepalived&quot;&gt;启动Keepalived&lt;/h4&gt;
&lt;pre&gt;
&lt;code class=&quot;language-[root@master01&quot;&gt;[root@master01 ~]# cat /etc/keepalived/check_apiserver.sh    #确认Keepalived配置
&lt;/code&gt;
&lt;/pre&gt;
&lt;pre&gt;
&lt;code&gt;[root@master01 ~]# for master_ip in ${MASTER_IPS[@]}
  do
    echo &quot;&amp;gt;&amp;gt;&amp;gt; ${master_ip}&quot;
    ssh root@${master_ip} &quot;systemctl start keepalived.service &amp;amp;&amp;amp; systemctl enable keepalived.service&quot;
    ssh root@${master_ip} &quot;systemctl status keepalived.service | grep Active&quot;
  done
&lt;/code&gt;
&lt;/pre&gt;
&lt;pre&gt;
&lt;code&gt;[root@master01 ~]# for all_ip in ${ALL_IPS[@]}
  do
    echo &quot;&amp;gt;&amp;gt;&amp;gt; ${all_ip}&quot;
    ssh root@${all_ip} &quot;ping -c1 172.24.8.100&quot;
  done                                                          #等待10s左右执行检查
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;提示：如上仅需Master01节点操作，从而实现所有节点自动启动服务。&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;
&lt;h4 id=&quot;启动nginx&quot;&gt;启动Nginx&lt;/h4&gt;
&lt;p&gt;执行ngkek8s.sh脚本后，nginx-lb的配置文件会自动复制到各个master的节点的/etc/kubernetes/nginx-lb目录。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;[root@master01 ~]# for master_ip in ${MASTER_IPS[@]}
  do
    echo &quot;&amp;gt;&amp;gt;&amp;gt; ${master_ip}&quot;
    ssh root@${master_ip} &quot;cd /etc/kubernetes/nginx-lb/ &amp;amp;&amp;amp; docker-compose up -d&quot;
    ssh root@${master_ip} &quot;docker-compose ps&quot;
  done
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;提示：如上仅需Master01节点操作，从而实现所有节点自动启动服务。&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;
&lt;h3 id=&quot;初始化集群-master&quot;&gt;初始化集群-Master&lt;/h3&gt;
&lt;h4 id=&quot;拉取镜像&quot;&gt;拉取镜像&lt;/h4&gt;
&lt;p&gt;&lt;code&gt;[root@master01 ~]# kubeadm --kubernetes-version=v1.18.3 config images list #列出所需镜像&lt;/code&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;[root@master01 ~]# cat config/downimage.sh                   #确认版本，提前下载镜像
#!/bin/sh
#****************************************************************#
# ScriptName: downimage.sh
# Author: xhy
# Create Date: 2020-05-29 19:55
# Modify Author: xhy
# Modify Date: 2020-05-30 16:07
# Version: v2
#***************************************************************#

KUBE_VERSION=v1.18.3
CALICO_VERSION=v3.14.1
CALICO_URL=calico
KUBE_PAUSE_VERSION=3.2
ETCD_VERSION=3.4.3-0
CORE_DNS_VERSION=1.6.7
GCR_URL=k8s.gcr.io
METRICS_SERVER_VERSION=v0.3.6
INGRESS_VERSION=0.32.0
CSI_PROVISIONER_VERSION=v1.4.0
CSI_NODE_DRIVER_VERSION=v1.2.0
CSI_ATTACHER_VERSION=v2.0.0
CSI_RESIZER_VERSION=v0.3.0 
ALIYUN_URL=registry.cn-hangzhou.aliyuncs.com/google_containers
UCLOUD_URL=uhub.service.ucloud.cn/uxhy
QUAY_URL=quay.io

kubeimages=(kube-proxy:${KUBE_VERSION}
kube-scheduler:${KUBE_VERSION}
kube-controller-manager:${KUBE_VERSION}
kube-apiserver:${KUBE_VERSION}
pause:${KUBE_PAUSE_VERSION}
etcd:${ETCD_VERSION}
coredns:${CORE_DNS_VERSION}
metrics-server-amd64:${METRICS_SERVER_VERSION}
)

for kubeimageName in ${kubeimages[@]} ; do
docker pull $UCLOUD_URL/$kubeimageName
docker tag $UCLOUD_URL/$kubeimageName $GCR_URL/$kubeimageName
docker rmi $UCLOUD_URL/$kubeimageName
done

calimages=(cni:${CALICO_VERSION}
pod2daemon-flexvol:${CALICO_VERSION}
node:${CALICO_VERSION}
kube-controllers:${CALICO_VERSION})

for calimageName in ${calimages[@]} ; do
docker pull $UCLOUD_URL/$calimageName
docker tag $UCLOUD_URL/$calimageName $CALICO_URL/$calimageName
docker rmi $UCLOUD_URL/$calimageName
done

ingressimages=(nginx-ingress-controller:${INGRESS_VERSION})

for ingressimageName in ${ingressimages[@]} ; do
docker pull $UCLOUD_URL/$ingressimageName
docker tag $UCLOUD_URL/$ingressimageName $QUAY_URL/kubernetes-ingress-controller/$ingressimageName
docker rmi $UCLOUD_URL/$ingressimageName
done

csiimages=(csi-provisioner:${CSI_PROVISIONER_VERSION}
csi-node-driver-registrar:${CSI_NODE_DRIVER_VERSION}
csi-attacher:${CSI_ATTACHER_VERSION}
csi-resizer:${CSI_RESIZER_VERSION}
)

for csiimageName in ${csiimages[@]} ; do
docker pull $UCLOUD_URL/$csiimageName
docker tag $UCLOUD_URL/$csiimageName $QUAY_URL/k8scsi/$csiimageName
docker rmi $UCLOUD_URL/$csiimageName
done
&lt;/code&gt;
&lt;/pre&gt;
&lt;pre&gt;
&lt;code&gt;[root@master01 ~]# for all_ip in ${ALL_IPS[@]}
  do
    echo &quot;&amp;gt;&amp;gt;&amp;gt; ${all_ip}&quot;
    scp -rp config/downimage.sh root@${all_ip}:/root/
    ssh root@${all_ip} &quot;bash downimage.sh &amp;amp;&quot;
  done
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;提示：如上仅需Master01节点操作，从而实现所有节点自动拉取镜像。&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;br/&gt;&lt;code&gt;[root@master01 ~]# docker images #确认验证&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://bed01.oss-cn-hangzhou.aliyuncs.com/study/kubernetes/f022/003.png&quot; alt=&quot;003&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h4 id=&quot;master上初始化&quot;&gt;Master上初始化&lt;/h4&gt;
&lt;pre&gt;
&lt;code&gt;[root@master01 ~]# kubeadm init --config=kubeadm-config.yaml --upload-certs  

保留如下命令用于后续节点添加：
You can now join any number of the control-plane node running the following command on each as root:

  kubeadm join 172.24.8.100:16443 --token xb9wda.v0yf7tlsgo8mdrhk \
    --discovery-token-ca-cert-hash sha256:249884d81a23bd821e38d3345866a99e6d55e443b545825c3c448f30f8e52c3b \
    --control-plane --certificate-key e30428776a47ed2c7e18c9e2951d9e40e068c9ecec5a4858457f1475f1a2a39a

Please note that the certificate-key gives access to cluster sensitive data, keep it secret!
As a safeguard, uploaded-certs will be deleted in two hours; If necessary, you can use
&quot;kubeadm init phase upload-certs --upload-certs&quot; to reload certs afterward.

Then you can join any number of worker nodes by running the following on each as root:

kubeadm join 172.24.8.100:16443 --token xb9wda.v0yf7tlsgo8mdrhk \
    --discovery-token-ca-cert-hash sha256:249884d81a23bd821e38d3345866a99e6d55e443b545825c3c448f30f8e52c3b
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;img src=&quot;https://bed01.oss-cn-hangzhou.aliyuncs.com/study/kubernetes/f022/004.png&quot; alt=&quot;004&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;注意：如上token具有默认24小时的有效期，token和hash值可通过如下方式获取：&lt;br/&gt;kubeadm token list&lt;br/&gt;如果 Token 过期以后，可以输入以下命令，生成新的 Token:&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;kubeadm token create
openssl x509 -pubkey -in /etc/kubernetes/pki/ca.crt | openssl rsa -pubin -outform der 2&amp;gt;/dev/null | openssl dgst -sha256 -hex | sed 's/^.* //'***
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;[root@master01 ~]# mkdir -p $HOME/.kube&lt;/code&gt;&lt;br/&gt;&lt;code&gt;[root@master01 ~]# sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config&lt;/code&gt;&lt;br/&gt;&lt;code&gt;[root@master01 ~]# sudo chown $(id -u):$(id -g) $HOME/.kube/config&lt;/code&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;[root@master01 ~]# cat &amp;lt;&amp;lt; EOF &amp;gt;&amp;gt; ~/.bashrc
export KUBECONFIG=$HOME/.kube/config
EOF                                                     #设置KUBECONFIG环境变量
&lt;/code&gt;
&lt;/pre&gt;
&lt;pre&gt;
&lt;code&gt;[root@master01 ~]# echo &quot;source &amp;lt;(kubectl completion bash)&quot; &amp;gt;&amp;gt; ~/.bashrc
[root@master01 ~]# source ~/.bashrc
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;附加：初始化过程大致步骤如下：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;[kubelet-start] 生成kubelet的配置文件”/var/lib/kubelet/config.yaml”&lt;/li&gt;
&lt;li&gt;[certificates]生成相关的各种证书&lt;/li&gt;
&lt;li&gt;[kubeconfig]生成相关的kubeconfig文件&lt;/li&gt;
&lt;li&gt;[bootstraptoken]生成token记录下来，后边使用kubeadm join往集群中添加节点时会用到&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;提示：初始化仅需要在master01上执行，若初始化异常可通过kubeadm reset &amp;amp;&amp;amp; rm -rf $HOME/.kube重置。&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;
&lt;h4 id=&quot;添加其他master节点&quot;&gt;添加其他master节点&lt;/h4&gt;
&lt;pre&gt;
&lt;code&gt;[root@master02 ~]# kubeadm join 172.24.8.100:16443 --token xb9wda.v0yf7tlsgo8mdrhk \
    --discovery-token-ca-cert-hash sha256:249884d81a23bd821e38d3345866a99e6d55e443b545825c3c448f30f8e52c3b \
    --control-plane --certificate-key e30428776a47ed2c7e18c9e2951d9e40e068c9ecec5a4858457f1475f1a2a39a
&lt;/code&gt;
&lt;/pre&gt;
&lt;pre&gt;
&lt;code&gt;[root@master02 ~]# mkdir -p $HOME/.kube
[root@master02 ~]# sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
[root@master02 ~]# sudo chown $(id -u):$(id -g) $HOME/.kube/config
 [root@master02 ~]# cat &amp;lt;&amp;lt; EOF &amp;gt;&amp;gt; ~/.bashrc`
export KUBECONFIG=$HOME/.kube/config
EOF                                                             #设置KUBECONFIG环境变量
[root@master02 ~]# echo &quot;source &amp;lt;(kubectl completion bash)&quot; &amp;gt;&amp;gt; ~/.bashrc
[root@master02 ~]# source ~/.bashrc
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;提示：master03也如上执行添加至集群的controlplane。&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;span&gt;&lt;br/&gt;&lt;em&gt;&lt;strong&gt;提示：若添加异常可通过kubeadm reset &amp;amp;&amp;amp; rm -rf $HOME/.kube重置。&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h3 id=&quot;安装nic插件&quot;&gt;安装NIC插件&lt;/h3&gt;
&lt;h4 id=&quot;nic插件介绍&quot;&gt;NIC插件介绍&lt;/h4&gt;
&lt;ul&gt;&lt;li&gt;Calico 是一个安全的 L3 网络和网络策略提供者。&lt;/li&gt;
&lt;li&gt;Canal 结合 Flannel 和 Calico， 提供网络和网络策略。&lt;/li&gt;
&lt;li&gt;Cilium 是一个 L3 网络和网络策略插件， 能够透明的实施 HTTP/API/L7 策略。 同时支持路由（routing）和叠加/封装（ overlay/encapsulation）模式。&lt;/li&gt;
&lt;li&gt;Contiv 为多种用例提供可配置网络（使用 BGP 的原生 L3，使用 vxlan 的 overlay，经典 L2 和 Cisco-SDN/ACI）和丰富的策略框架。Contiv 项目完全开源。安装工具同时提供基于和不基于 kubeadm 的安装选项。&lt;/li&gt;
&lt;li&gt;Flannel 是一个可以用于 Kubernetes 的 overlay 网络提供者。&lt;br/&gt;+Romana 是一个 pod 网络的层 3 解决方案，并且支持 NetworkPolicy API。Kubeadm add-on 安装细节可以在这里找到。&lt;/li&gt;
&lt;li&gt;Weave Net 提供了在网络分组两端参与工作的网络和网络策略，并且不需要额外的数据库。&lt;/li&gt;
&lt;li&gt;CNI-Genie 使 Kubernetes 无缝连接到一种 CNI 插件，例如：Flannel、Calico、Canal、Romana 或者 Weave。&lt;br/&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;提示：本方案使用Calico插件。&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;h4 id=&quot;设置标签&quot;&gt;设置标签&lt;/h4&gt;
&lt;p&gt;&lt;code&gt;[root@master01 ~]# kubectl taint nodes --all node-role.kubernetes.io/master- #允许master部署应用&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;提示：部署完内部应用后可使用kubectl taint node master01 node-role.kubernetes.io/master=&quot;&quot;:NoSchedule重新设置Master为Master Only 状态。&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;
&lt;h4 id=&quot;部署calico&quot;&gt;部署calico&lt;/h4&gt;
&lt;pre&gt;
&lt;code&gt;[root@master01 ~]# cat config/calico/calico.yaml     #检查配置
……
            - name: CALICO_IPV4POOL_CIDR
              value: &quot;10.10.0.0/16&quot;                   #检查Pod网段
……
            - name: IP_AUTODETECTION_METHOD
              value: &quot;interface=eth.*&quot;                        #检查节点之间的网卡
# Auto-detect the BGP IP address.
            - name: IP
              value: &quot;autodetect&quot;
……
&lt;/code&gt;
&lt;/pre&gt;
&lt;pre&gt;
&lt;code&gt;[root@master01 ~]# kubectl apply -f config/calico/calico.yaml
[root@master01 ~]# kubectl get pods --all-namespaces -o wide            #查看部署
[root@master01 ~]# kubectl get nodes
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;img src=&quot;https://bed01.oss-cn-hangzhou.aliyuncs.com/study/kubernetes/f022/005.png&quot; alt=&quot;005&quot; loading=&quot;lazy&quot;/&gt;&lt;br/&gt;&lt;img src=&quot;https://bed01.oss-cn-hangzhou.aliyuncs.com/study/kubernetes/f022/006.png&quot; alt=&quot;006&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h4 id=&quot;修改node端口范围&quot;&gt;修改node端口范围&lt;/h4&gt;
&lt;pre&gt;
&lt;code&gt;[root@master01 ~]# vi /etc/kubernetes/manifests/kube-apiserver.yaml
……
    - --service-node-port-range=1-65535
……
&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;部署高可用组件ii&quot;&gt;部署高可用组件II&lt;/h3&gt;
&lt;h4 id=&quot;高可用说明&quot;&gt;高可用说明&lt;/h4&gt;
&lt;p&gt;高可用kubernetes集群步骤三已完成配置，但是使用docker-compose方式启动nginx-lb由于无法提供kubernetes集群的健康检查和自动重启功能，nginx-lb作为高可用kubernetes集群的核心组件建议也作为kubernetes集群中的一个pod来进行管理。&lt;/p&gt;
&lt;h4 id=&quot;污点和标签&quot;&gt;污点和标签&lt;/h4&gt;
&lt;pre&gt;
&lt;code&gt;[root@master01 ~]# kubectl taint node master01 node-`role.kubernetes.io/master=&quot;&quot;:NoSchedule
[root@master01 ~]# kubectl taint node master02 node-role.kubernetes.io/master=&quot;&quot;:NoSchedule
[root@master01 ~]# kubectl taint node master03 node-role.kubernetes.io/master=&quot;&quot;:NoSchedule
[root@master01 ~]# kubectl label nodes master01 node-role.kubernetes.io/master=&quot;true&quot; --overwrite
[root@master01 ~]# kubectl label nodes master02 node-role.kubernetes.io/master=&quot;true&quot; --overwrite
[root@master01 ~]# kubectl label nodes master02 node-role.kubernetes.io/master=&quot;true&quot; --overwrite
&lt;/code&gt;
&lt;/pre&gt;
&lt;h4 id=&quot;容器化实现高可用&quot;&gt;容器化实现高可用&lt;/h4&gt;
&lt;pre&gt;
&lt;code&gt;[root@master01 ~]# for master_ip in ${MASTER_IPS[@]}
  do
    echo &quot;&amp;gt;&amp;gt;&amp;gt; ${master_ip}&quot;
    ssh root@${master_ip} &quot;systemctl stop kubelet&quot;
    ssh root@${master_ip} &quot;docker stop nginx-lb &amp;amp;&amp;amp; docker rm nginx-lb&quot;
    scp -rp /root/config/k8s-nginx-lb.yaml root@${master_ip}:/etc/kubernetes/manifests/
    ssh root@${master_ip} &quot;systemctl restart kubelet docker&quot;
  done
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;提示：如上仅需Master01节点操作，从而实现所有Master节点自动启动服务。&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;[root@master01 ~]# kubectl -n kube-system get pods -o wide | grep -E 'NAME|nginx'&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://bed01.oss-cn-hangzhou.aliyuncs.com/study/kubernetes/f022/007.png&quot; alt=&quot;007&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h3 id=&quot;添加worker节点&quot;&gt;添加Worker节点&lt;/h3&gt;
&lt;h4 id=&quot;添加worker节点-2&quot;&gt;添加Worker节点&lt;/h4&gt;
&lt;p&gt;&lt;code&gt;[root@master01 ~]# source environment.sh&lt;/code&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;[root@master01 ~]# for node_ip in ${NODE_IPS[@]}
  do
    echo &quot;&amp;gt;&amp;gt;&amp;gt; ${node_ip}&quot;
    ssh root@${node_ip} &quot;kubeadm join 172.24.8.100:16443 --token xb9wda.v0yf7tlsgo8mdrhk \
    --discovery-token-ca-cert-hash sha256:249884d81a23bd821e38d3345866a99e6d55e443b545825c3c448f30f8e52c3b&quot;
    ssh root@${node_ip} &quot;systemctl enable kubelet.service&quot;
  done
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;提示：如上仅需Master01节点操作，从而实现所有Worker节点添加至集群，若添加异常可通过如下方式重置：&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;[root@node01 ~]# kubeadm reset
[root@node01 ~]# ifconfig cni0 down
[root@node01 ~]# ip link delete cni0
[root@node01 ~]# ifconfig flannel.1 down
[root@node01 ~]# ip link delete flannel.1
[root@node01 ~]# rm -rf /var/lib/cni/
&lt;/code&gt;
&lt;/pre&gt;
&lt;h4 id=&quot;确认验证&quot;&gt;确认验证&lt;/h4&gt;
&lt;pre&gt;
&lt;code&gt;[root@master01 ~]# kubectl get nodes                                 #节点状态
[root@master01 ~]# kubectl get cs                                       #组件状态
[root@master01 ~]# kubectl get serviceaccount                           #服务账户
[root@master01 ~]# kubectl cluster-info                                 #集群信息
[root@master01 ~]# kubectl get pod -n kube-system -o wide               #所有服务状态
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;img src=&quot;https://bed01.oss-cn-hangzhou.aliyuncs.com/study/kubernetes/f022/008.png&quot; alt=&quot;008&quot; loading=&quot;lazy&quot;/&gt;&lt;br/&gt;&lt;img src=&quot;https://bed01.oss-cn-hangzhou.aliyuncs.com/study/kubernetes/f022/009.png&quot; alt=&quot;009&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;提示：更多Kubetcl使用参考：&lt;a href=&quot;https://kubernetes.io/docs/reference/kubectl/kubectl/&quot;&gt;https://kubernetes.io/docs/reference/kubectl/kubectl/&lt;/a&gt;&lt;br/&gt;&lt;a href=&quot;https://kubernetes.io/docs/reference/kubectl/overview/&quot;&gt;https://kubernetes.io/docs/reference/kubectl/overview/&lt;/a&gt;&lt;br/&gt;更多kubeadm使用参考：&lt;a href=&quot;https://kubernetes.io/docs/reference/setup-tools/kubeadm/kubeadm/&quot;&gt;https://kubernetes.io/docs/reference/setup-tools/kubeadm/kubeadm/&lt;/a&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;
&lt;h3 id=&quot;metrics部署&quot;&gt;Metrics部署&lt;/h3&gt;
&lt;h4 id=&quot;metrics&quot;&gt;Metrics&lt;/h4&gt;
&lt;p&gt;Kubernetes的早期版本依靠Heapster来实现完整的性能数据采集和监控功能，Kubernetes从1.8版本开始，性能数据开始以Metrics API的方式提供标准化接口，并且从1.10版本开始将Heapster替换为Metrics Server。在Kubernetes新的监控体系中，Metrics Server用于提供核心指标（Core Metrics），包括Node、Pod的CPU和内存使用指标。&lt;br/&gt;对其他自定义指标（Custom Metrics）的监控则由Prometheus等组件来完成。&lt;/p&gt;
&lt;h4 id=&quot;开启聚合层&quot;&gt;开启聚合层&lt;/h4&gt;
&lt;p&gt;有关聚合层知识参考：&lt;a href=&quot;https://blog.csdn.net/liukuan73/article/details/81352637&quot;&gt;https://blog.csdn.net/liukuan73/article/details/81352637&lt;/a&gt;&lt;br/&gt;kubeadm方式部署默认已开启。&lt;/p&gt;
&lt;h4 id=&quot;获取部署文件&quot;&gt;获取部署文件&lt;/h4&gt;
&lt;pre&gt;
&lt;code&gt;[root@master01 ~]# mkdir metrics
[root@master01 ~]# cd metrics/
[root@master01 metrics]# wget https://github.com/kubernetes-sigs/metrics-server/releases/download/v0.3.6/components.yaml
&lt;/code&gt;
&lt;/pre&gt;
&lt;pre&gt;
&lt;code&gt;[root@master01 metrics]# vi components.yaml
……
apiVersion: apps/v1
kind: Deployment
……
spec:
  replicas: 3                                                           #根据集群规模调整副本数
……
    spec:
      hostNetwork: true
……
      - name: metrics-server
        image: k8s.gcr.io/metrics-server-amd64:v0.3.6
        imagePullPolicy: IfNotPresent
        args:
          - --cert-dir=/tmp
          - --secure-port=4443
          - --kubelet-insecure-tls                                      #追加此args
          - --kubelet-preferred-address-types=InternalIP,Hostname,InternalDNS,ExternalDNS,ExternalIP    #追加此args
……
&lt;/code&gt;
&lt;/pre&gt;
&lt;h4 id=&quot;正式部署&quot;&gt;正式部署&lt;/h4&gt;
&lt;pre&gt;
&lt;code&gt;[root@master01 metrics]# kubectl apply -f components.yaml
[root@master01 metrics]# kubectl -n kube-system get pods -l k8s-app=metrics-server
NAME                              READY   STATUS    RESTARTS   AGE
metrics-server-7b97647899-ghnxw   1/1     Running   0          11s
metrics-server-7b97647899-nqwvq   1/1     Running   0          10s
metrics-server-7b97647899-zkmxs   1/1     Running   0          10s
&lt;/code&gt;
&lt;/pre&gt;
&lt;h4 id=&quot;查看资源监控&quot;&gt;查看资源监控&lt;/h4&gt;
&lt;pre&gt;
&lt;code&gt;[root@k8smaster01 ~]# kubectl top nodes
[root@k8smaster01 ~]# kubectl top pods --all-namespaces
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;img src=&quot;https://bed01.oss-cn-hangzhou.aliyuncs.com/study/kubernetes/f022/010.png&quot; alt=&quot;010&quot; loading=&quot;lazy&quot;/&gt;&lt;br/&gt;&lt;img src=&quot;https://bed01.oss-cn-hangzhou.aliyuncs.com/study/kubernetes/f022/011.png&quot; alt=&quot;011&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;提示：Metrics Server提供的数据也可以供HPA控制器使用，以实现基于CPU使用率或内存使用值的Pod自动扩缩容功能。&lt;br/&gt;部署参考：&lt;a href=&quot;https://linux48.com/container/2019-11-13-metrics-server.html&quot;&gt;https://linux48.com/container/2019-11-13-metrics-server.html&lt;/a&gt;&lt;br/&gt;有关metrics更多部署参考：&lt;br/&gt;&lt;a href=&quot;https://kubernetes.io/docs/tasks/debug-application-cluster/resource-metrics-pipeline/&quot;&gt;https://kubernetes.io/docs/tasks/debug-application-cluster/resource-metrics-pipeline/&lt;/a&gt;&lt;br/&gt;开启开启API Aggregation参考：&lt;br/&gt;&lt;a href=&quot;https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/apiserver-aggregation/&quot;&gt;https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/apiserver-aggregation/&lt;/a&gt;&lt;br/&gt;API Aggregation介绍参考：&lt;br/&gt;&lt;a href=&quot;https://kubernetes.io/docs/tasks/access-kubernetes-api/configure-aggregation-layer/&quot;&gt;https://kubernetes.io/docs/tasks/access-kubernetes-api/configure-aggregation-layer/&lt;/a&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;
&lt;h3 id=&quot;nginx-ingress部署&quot;&gt;Nginx ingress部署&lt;/h3&gt;
&lt;p&gt;参考&lt;a href=&quot;https://www.cnblogs.com/itzgr/p/13030762.html&quot;&gt;附020.Nginx-ingress部署及使用&lt;/a&gt;，建议采用社区版。&lt;/p&gt;
&lt;h3 id=&quot;dashboard部署&quot;&gt;Dashboard部署&lt;/h3&gt;
&lt;h4 id=&quot;设置标签-2&quot;&gt;设置标签&lt;/h4&gt;
&lt;pre&gt;
&lt;code&gt;[root@master01 ~]# kubectl label nodes master01 dashboard=yes
[root@master01 ~]# kubectl label nodes master02 dashboard=yes
[root@master01 ~]# kubectl label nodes master03 dashboard=yes
&lt;/code&gt;
&lt;/pre&gt;
&lt;h4 id=&quot;创建证书&quot;&gt;创建证书&lt;/h4&gt;
&lt;p&gt;本实验已获取免费一年的证书，免费证书获取可参考：&lt;a href=&quot;https://freessl.cn&quot;&gt;https://freessl.cn&lt;/a&gt;。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;[root@master01 ~]# mkdir -p /root/dashboard/certs
[root@master01 ~]# cd /root/dashboard/certs
[root@master01 certs]# mv k8s.odocker.com tls.crt
[root@master01 certs]# mv k8s.odocker.com tls.crt
[root@master01 certs]# ll
total 8.0K
-rw-r--r-- 1 root root 1.9K Jun  8 11:46 tls.crt
-rw-r--r-- 1 root root 1.7K Jun  8 11:46 tls.ke
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;提示：也可手动如下操作创建自签证书：&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;[root@master01 ~]# openssl req -x509 -nodes -days 365 -newkey rsa:2048 -keyout tls.key -out tls.crt -subj &quot;/C=CN/ST=ZheJiang/L=HangZhou/O=Xianghy/OU=Xianghy/CN=k8s.odocker.com&quot;&lt;/code&gt;&lt;/p&gt;
&lt;h4 id=&quot;手动创建secret&quot;&gt;手动创建secret&lt;/h4&gt;
&lt;pre&gt;
&lt;code&gt;[root@master01 ~]# kubectl create ns kubernetes-dashboard    #v2版本dashboard独立ns
[root@master01 ~]# kubectl create secret generic kubernetes-dashboard-certs --from-file=$HOME/dashboard/certs/ -n kubernetes-dashboard
[root@master01 ~]# kubectl get secret kubernetes-dashboard-certs -n kubernetes-dashboard -o yaml                #查看新证书`
&lt;/code&gt;
&lt;/pre&gt;
&lt;h4 id=&quot;下载yaml&quot;&gt;下载yaml&lt;/h4&gt;
&lt;pre&gt;
&lt;code&gt;[root@master01 ~]# cd /root/dashboard
[root@master01 dashboard]# wget https://raw.githubusercontent.com/kubernetes/dashboard/v2.0.1/aio/deploy/recommended.yaml
&lt;/code&gt;
&lt;/pre&gt;
&lt;h4 id=&quot;修改yaml&quot;&gt;修改yaml&lt;/h4&gt;
&lt;pre&gt;
&lt;code&gt;[root@master01 dashboard]# vi recommended.yaml
……
kind: Service
apiVersion: v1
metadata:
  labels:
    k8s-app: kubernetes-dashboard
  name: kubernetes-dashboard
  namespace: kubernetes-dashboard
spec:
  type: NodePort                                #新增
  ports:
    - port: 443
      targetPort: 8443
      nodePort: 30001                           #新增
  selector:
    k8s-app: kubernetes-dashboard
---
……                                              #如下全部注释
#apiVersion: v1
#kind: Secret
#metadata:
#  labels:
#    k8s-app: kubernetes-dashboard
#  name: kubernetes-dashboard-certs
#  namespace: kubernetes-dashboard
#type: Opaque
……
kind: Deployment
……
  replicas: 3                                           #适当调整为3副本
……
          imagePullPolicy: IfNotPresent                 #修改镜像下载策略
          ports:
            - containerPort: 8443
              protocol: TCP
          args:
            - --auto-generate-certificates              #关闭自动创建证书
            - --namespace=kubernetes-dashboard
            - --tls-key-file=tls.key
            - --tls-cert-file=tls.crt
            - --token-ttl=3600                          #追加如上args
……
      nodeSelector:
        &quot;beta.kubernetes.io/os&quot;: linux
        &quot;dashboard&quot;: &quot;yes&quot;                          #部署在master节点
……
kind: Service
apiVersion: v1
metadata:
  labels:
    k8s-app: dashboard-metrics-scraper
  name: dashboard-metrics-scraper
  namespace: kubernetes-dashboard
spec:
  type: NodePort                                        #新增
  ports:
    - port: 8000
      nodePort: 30000                                   #新增
      targetPort: 8000
  selector:                                                                                  
    k8s-app: dashboard-metrics-scraper
……
   replicas: 3                                          #适当调整为3副本
……
      nodeSelector:
        &quot;beta.kubernetes.io/os&quot;: linux
        &quot;dashboard&quot;: &quot;yes&quot;                          #部署在master节点
……
&lt;/code&gt;
&lt;/pre&gt;
&lt;h4 id=&quot;正式部署-2&quot;&gt;正式部署&lt;/h4&gt;
&lt;pre&gt;
&lt;code&gt;[root@master01 dashboard]# kubectl apply -f recommended.yaml
[root@master01 dashboard]# kubectl get deployment kubernetes-dashboard -n kubernetes-dashboard
[root@master01 dashboard]# kubectl get services -n kubernetes-dashboard
[root@master01 dashboard]# kubectl get pods -o wide -n kubernetes-dashboard
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;img src=&quot;https://bed01.oss-cn-hangzhou.aliyuncs.com/study/kubernetes/f022/012.png&quot; alt=&quot;012&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;提示：master01 NodePort 30001/TCP映射到 dashboard pod 443 端口。&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;
&lt;h4 id=&quot;创建管理员账户&quot;&gt;创建管理员账户&lt;/h4&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;提示：dashboard v2版本默认没有创建具有管理员权限的账户，可如下操作创建。&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;[root@master01 dashboard]# vi dashboard-admin.yaml
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: admin-user
  namespace: kubernetes-dashboard

---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: admin-user
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: cluster-admin
subjects:
- kind: ServiceAccount
  name: admin-user
  namespace: kubernetes-dashboard
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;[root@master01 dashboard]# kubectl apply -f dashboard-admin.yaml&lt;/code&gt;&lt;/p&gt;
&lt;h3 id=&quot;ingress暴露dashboard&quot;&gt;ingress暴露dashboard&lt;/h3&gt;
&lt;h4 id=&quot;创建ingress-tls&quot;&gt;创建ingress tls&lt;/h4&gt;
&lt;pre&gt;
&lt;code&gt;[root@master01 ~]# cd /root/dashboard/certs
[root@master01 certs]# kubectl -n kubernetes-dashboard create secret tls kubernetes-dashboard-tls --cert=tls.crt --key=tls.key
[root@master01 certs]# kubectl -n kubernetes-dashboard describe secrets kubernetes-dashboard-tls
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;img src=&quot;https://bed01.oss-cn-hangzhou.aliyuncs.com/study/kubernetes/f022/013.png&quot; alt=&quot;013&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h4 id=&quot;创建ingress策略&quot;&gt;创建ingress策略&lt;/h4&gt;
&lt;pre&gt;
&lt;code&gt;[root@master01 ~]# cd /root/dashboard/
[root@master01 dashboard]# vi dashboard-ingress.yaml
apiVersion: networking.k8s.io/v1beta1
kind: Ingress
metadata:
  name: kubernetes-dashboard-ingress
  namespace: kubernetes-dashboard
  annotations:
    kubernetes.io/ingress.class: &quot;nginx&quot;
    nginx.ingress.kubernetes.io/use-regex: &quot;true&quot;
    nginx.ingress.kubernetes.io/ssl-passthrough: &quot;true&quot;
    nginx.ingress.kubernetes.io/rewrite-target: /
    nginx.ingress.kubernetes.io/ssl-redirect: &quot;true&quot;
    #nginx.ingress.kubernetes.io/secure-backends: &quot;true&quot;
    nginx.ingress.kubernetes.io/backend-protocol: &quot;HTTPS&quot;
    nginx.ingress.kubernetes.io/proxy-connect-timeout: &quot;600&quot;
    nginx.ingress.kubernetes.io/proxy-read-timeout: &quot;600&quot;
    nginx.ingress.kubernetes.io/proxy-send-timeout: &quot;600&quot;
    nginx.ingress.kubernetes.io/configuration-snippet: |
      proxy_ssl_session_reuse off;
spec:
  rules:
  - host: k8s.odocker.com
    http:
      paths:
      - path: /
        backend:
          serviceName: kubernetes-dashboard
          servicePort: 443
  tls:
  - hosts:
    - k8s.odocker.com
    secretName: kubernetes-dashboard-tls
&lt;/code&gt;
&lt;/pre&gt;
&lt;pre&gt;
&lt;code&gt;[root@master01 dashboard]# kubectl apply -f dashboard-ingress.yaml
[root@master01 dashboard]# kubectl -n kubernetes-dashboard get ingress
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;img src=&quot;https://bed01.oss-cn-hangzhou.aliyuncs.com/study/kubernetes/f022/014.png&quot; alt=&quot;014&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h3 id=&quot;访问dashboard&quot;&gt;访问dashboard&lt;/h3&gt;
&lt;h4 id=&quot;导入证书&quot;&gt;导入证书&lt;/h4&gt;
&lt;p&gt;将k8s.odocker.com导入浏览器，并设置为信任，导入操作略。&lt;/p&gt;
&lt;h4 id=&quot;创建kubeconfig文件&quot;&gt;创建kubeconfig文件&lt;/h4&gt;
&lt;p&gt;使用token相对复杂，可将token添加至kubeconfig文件中，使用KubeConfig文件访问dashboard。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;[root@master01 dashboard]# ADMIN_SECRET=$(kubectl -n kubernetes-dashboard get secret | grep admin-user | awk '{print $1}') 
[root@master01 dashboard]# DASHBOARD_LOGIN_TOKEN=$(kubectl describe secret -n kubernetes-dashboard ${ADMIN_SECRET} | grep -E '^token' | awk '{print $2}') 
[root@master01 dashboard]# kubectl config set-cluster kubernetes \
  --certificate-authority=/etc/kubernetes/pki/ca.crt \
  --embed-certs=true \
  --server=172.24.8.100:16443 \
  --kubeconfig=local-ngkek8s-dashboard-admin.kubeconfig         # 设置集群参数
 [root@master01 dashboard]# kubectl config set-credentials dashboard_user \
  --token=${DASHBOARD_LOGIN_TOKEN} \
  --kubeconfig=local-ngkek8s-dashboard-admin.kubeconfig         # 设置客户端认证参数，使用上面创建的 Token
[root@master01 dashboard]# kubectl config set-context default \
  --cluster=kubernetes \
  --user=dashboard_user \
  --kubeconfig=local-ngkek8s-dashboard-admin.kubeconfig         # 设置上下文参数
[root@master01 dashboard]# kubectl config use-context default --kubeconfig=local-ngkek8s-dashboard-admin.kubeconfig             # 设置默认上下文
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;将local-ngkek8s-dashboard-admin.kubeconfig文件导入，以便于浏览器使用该文件登录。&lt;/p&gt;
&lt;h4 id=&quot;测试访问dashboard&quot;&gt;测试访问dashboard&lt;/h4&gt;
&lt;p&gt;本实验采用ingress所暴露的域名：&lt;a href=&quot;https://k8s.odocker.com&quot;&gt;https://k8s.odocker.com&lt;/a&gt; 方式访问。使用local-ngkek8s-dashboard-admin.kubeconfig文件访问。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://bed01.oss-cn-hangzhou.aliyuncs.com/study/kubernetes/f022/015.png&quot; alt=&quot;015&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;提示：&lt;br/&gt;更多dashboard访问方式及认证可参考&lt;a href=&quot;https://www.cnblogs.com/itzgr/p/11082342.html&quot;&gt;附004.Kubernetes Dashboard简介及使用&lt;/a&gt;。&lt;br/&gt;dashboard登录整个流程可参考：&lt;a href=&quot;https://www.cnadn.net/post/2613.html&quot;&gt;https://www.cnadn.net/post/2613.html&lt;/a&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;
&lt;h3 id=&quot;longhorn存储部署&quot;&gt;Longhorn存储部署&lt;/h3&gt;
&lt;h4 id=&quot;longhorn概述&quot;&gt;Longhorn概述&lt;/h4&gt;
&lt;p&gt;Longhorn是用于Kubernetes的开源分布式块存储系统。&lt;br/&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;提示：更多介绍参考：&lt;a href=&quot;https://github.com/longhorn/longhorn%E3%80%82&quot;&gt;https://github.com/longhorn/longhorn。&lt;/a&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;
&lt;h4 id=&quot;longhorn部署&quot;&gt;Longhorn部署&lt;/h4&gt;
&lt;pre&gt;
&lt;code&gt;[root@master01 ~]# source environment.sh
[root@master01 ~]# for all_ip in ${ALL_IPS[@]}
  do
    echo &quot;&amp;gt;&amp;gt;&amp;gt; ${all_ip}&quot;
    ssh root@${all_ip} &quot;yum -y install iscsi-initiator-utils &amp;amp;&quot;
  done
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;提示：所有节点都需要安装。&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;[root@master01 ~]# mkdir longhorn
[root@master01 ~]# cd longhorn/
[root@master01 longhorn]# wget \
https://raw.githubusercontent.com/longhorn/longhorn/master/deploy/longhorn.yaml
&lt;/code&gt;
&lt;/pre&gt;
&lt;pre&gt;
&lt;code&gt;[root@master01 longhorn]# vi longhorn.yaml
#……
---
kind: Service
apiVersion: v1
metadata:
  labels:
    app: longhorn-ui
  name: longhorn-frontend
  namespace: longhorn-system
spec:
  type: NodePort                        #修改为nodeport
  selector:
    app: longhorn-ui
  ports:
  - port: 80
    targetPort: 8000
    nodePort: 30002
---
……
kind: DaemonSet
……
        imagePullPolicy: IfNotPresent
……
#……
&lt;/code&gt;
&lt;/pre&gt;
&lt;pre&gt;
&lt;code&gt;[root@master01 longhorn]# kubectl apply -f longhorn.yaml
[root@master01 longhorn]# kubectl -n longhorn-system get pods -o wide
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;img src=&quot;https://bed01.oss-cn-hangzhou.aliyuncs.com/study/kubernetes/f022/016.png&quot; alt=&quot;016&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;提示：若部署异常可删除重建，若出现无法删除namespace，可通过如下操作进行删除：&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;wget https://github.com/longhorn/longhorn/blob/master/uninstall/uninstall.yaml
rm -rf /var/lib/longhorn/
kubectl apply -f uninstall.yaml
kubectl delete -f longhorn.yaml
&lt;/code&gt;
&lt;/pre&gt;
&lt;h4 id=&quot;动态sc创建&quot;&gt;动态sc创建&lt;/h4&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;提示：默认longhorn部署完成已创建一个sc，也可通过如下手动编写yaml创建。&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt; [root@master01 longhorn]# kubectl get sc
NAME                   PROVISIONER             RECLAIMPOLICY   VOLUMEBINDINGMODE      ALLOWVOLUMEEXPANSION   AGE
……
longhorn               driver.longhorn.io      Delete          Immediate              true                   15m
&lt;/code&gt;
&lt;/pre&gt;
&lt;pre&gt;
&lt;code&gt;[root@master01 longhorn]# vi longhornsc.yaml
kind: StorageClass
apiVersion: storage.k8s.io/v1
metadata:
  name: longhornsc
provisioner: rancher.io/longhorn
parameters:
  numberOfReplicas: &quot;3&quot;
  staleReplicaTimeout: &quot;30&quot;
  fromBackup: &quot;&quot; 
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;[root@master01 longhorn]# kubectl create -f longhornsc.yaml&lt;/code&gt;&lt;/p&gt;
&lt;h4 id=&quot;测试pv及pvc&quot;&gt;测试PV及PVC&lt;/h4&gt;
&lt;pre&gt;
&lt;code&gt;[root@master01 longhorn]# vi longhornpod.yaml
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: longhorn-pvc
spec:
  accessModes:
    - ReadWriteOnce
  storageClassName: longhorn
  resources:
    requests:
      storage: 2Gi
---
apiVersion: v1
kind: Pod
metadata:
  name: longhorn-pod
  namespace: default
spec:
  containers:
  - name: volume-test
    image: nginx:stable-alpine
    imagePullPolicy: IfNotPresent
    volumeMounts:
    - name: volv
      mountPath: /data
    ports:
    - containerPort: 80
  volumes:
  - name: volv
    persistentVolumeClaim:
      claimName: longhorn-pvc
&lt;/code&gt;
&lt;/pre&gt;
&lt;pre&gt;
&lt;code&gt;[root@master01 longhorn]# kubectl apply -f longhornpod.yaml
[root@master01 longhorn]# kubectl get pods
[root@master01 longhorn]# kubectl get pvc
[root@master01 longhorn]# kubectl get pv
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;img src=&quot;https://bed01.oss-cn-hangzhou.aliyuncs.com/study/kubernetes/f022/017.png&quot; alt=&quot;017&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h4 id=&quot;创建ingress访问ui&quot;&gt;创建ingress访问UI&lt;/h4&gt;
&lt;pre&gt;
&lt;code&gt;[root@master01 longhorn]# yum -y install httpd-tools
[root@master01 longhorn]# htpasswd -c auth xhy                  #创建用户名和密码
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;&lt;span&gt;提示：也可通过如下命令创建：&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;br/&gt;&lt;code&gt;USER=xhy; PASSWORD=x120952576; echo &quot;${USER}:$(openssl passwd -stdin -apr1 &amp;lt;&amp;lt;&amp;lt; ${PASSWORD})&quot; &amp;gt;&amp;gt; auth&lt;/code&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;[root@master01 longhorn]# kubectl -n longhorn-system create secret generic longhorn-basic-auth --from-file=auth
&lt;/code&gt;
&lt;/pre&gt;
&lt;pre&gt;
&lt;code&gt;[root@master01 longhorn]# vi longhorn-ingress.yaml           #创建ingress规则
apiVersion: networking.k8s.io/v1beta1
kind: Ingress
metadata:
  name: longhorn-ingress
  namespace: longhorn-system
  annotations:
    nginx.ingress.kubernetes.io/auth-type: basic
    nginx.ingress.kubernetes.io/auth-secret: longhorn-basic-auth
    nginx.ingress.kubernetes.io/auth-realm: 'Authentication Required '
spec:
  rules:
  - host: longhorn.odocker.com
    http:
      paths:
      - path: /
        backend:
          serviceName: longhorn-frontend
          servicePort: 80
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;[root@master01 longhorn]# kubectl apply -f longhorn-ingress.yaml&lt;/code&gt;&lt;/p&gt;
&lt;h4 id=&quot;确认验证-2&quot;&gt;确认验证&lt;/h4&gt;
&lt;p&gt;浏览器访问：longhorn.odocker.com，并输入账号和密码。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://bed01.oss-cn-hangzhou.aliyuncs.com/study/kubernetes/f022/018.png&quot; alt=&quot;018&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;登录查看。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://bed01.oss-cn-hangzhou.aliyuncs.com/study/kubernetes/f022/019.png&quot; alt=&quot;019&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h3 id=&quot;helm安装&quot;&gt;Helm安装&lt;/h3&gt;
&lt;p&gt;参考&lt;a href=&quot;https://www.cnblogs.com/itzgr/p/12876009.html&quot;&gt;053.集群管理-Helm工具&lt;/a&gt;&lt;/p&gt;
</description>
<pubDate>Fri, 12 Jun 2020 15:19:00 +0000</pubDate>
<dc:creator>木二</dc:creator>
<og:description>kubeadm介绍 kubeadm概述 参考附003.Kubeadm部署Kubernetes。 kubeadm功能 参考附003.Kubeadm部署Kubernetes。 本方案描述 本方案采用kub</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/itzgr/p/13111119.html</dc:identifier>
</item>
<item>
<title>Redis学习笔记（二十） 发布订阅（下） - 温暖如太阳</title>
<link>http://www.cnblogs.com/xtt321/p/13111076.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/xtt321/p/13111076.html</guid>
<description>[unable to retrieve full-text content]当一个客户端执行SUBSCRIBE命令订阅某个或某些频道时，这个客户端与被订阅频道之间就建立起了一种订阅关系。 Redis将所有频道的订阅关系保存在服务器状态的pubsub_channels字典里面，这个字典的键是某个被订阅的频道，而键的值是一个链表，链表里面记录了所有订阅这个频道的客户端： str</description>
<pubDate>Fri, 12 Jun 2020 15:11:00 +0000</pubDate>
<dc:creator>温暖如太阳</dc:creator>
<dc:identifier>http://www.cnblogs.com/xtt321/p/13111076.html</dc:identifier>
</item>
<item>
<title>Alink漫谈(七) : 如何划分训练数据集和测试数据集 - 罗西的思考</title>
<link>http://www.cnblogs.com/rossiXYZ/p/13110960.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/rossiXYZ/p/13110960.html</guid>
<description>&lt;p&gt;Alink 是阿里巴巴基于实时计算引擎 Flink 研发的新一代机器学习算法平台，是业界首个同时支持批式算法、流式算法的机器学习平台。本文将为大家展现Alink如何划分训练数据集和测试数据集。&lt;/p&gt;&lt;div id=&quot;cnblogs_post_body&quot; readability=&quot;288.48162939297&quot;&gt;


&lt;h2 id=&quot;0x00-摘要&quot;&gt;0x00 摘要&lt;/h2&gt;
&lt;p&gt;Alink 是阿里巴巴基于实时计算引擎 Flink 研发的新一代机器学习算法平台，是业界首个同时支持批式算法、流式算法的机器学习平台。本文将为大家展现Alink如何划分训练数据集和测试数据集。&lt;/p&gt;
&lt;h2 id=&quot;0x01-训练数据集和测试数据集&quot;&gt;0x01 训练数据集和测试数据集&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;两分法&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;一般做预测分析时，会将数据分为两大部分。一部分是训练数据，用于构建模型，一部分是测试数据，用于检验模型。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;三分法&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;但有时候模型的构建过程中也需要检验模型/辅助模型构建，这时会将训练数据再分为两个部分：1）训练数据；2）验证数据（Validation Data）。所以这种情况下会把数据分为三部分。&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;训练数据（Train Data）：用于模型构建。&lt;/li&gt;
&lt;li&gt;验证数据（Validation Data）：可选，用于辅助模型构建，可以重复使用。&lt;/li&gt;
&lt;li&gt;测试数据（Test Data）：用于检测模型构建，此数据只在模型检验时使用，用于评估模型的准确率。绝对不允许用于模型构建过程，否则会导致过渡拟合。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;Training set是用来训练模型或确定模型参数的，如ANN中权值等；&lt;/p&gt;
&lt;p&gt;Validation set是用来做模型选择（model selection），即做模型的最终优化及确定，如ANN的结构；&lt;/p&gt;
&lt;p&gt;Test set则纯粹是为了测试已经训练好的模型的推广能力。当然test set并不能保证模型的正确性，他只是说相似的数据用此模型会得出相似的结果。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;实际应用&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;实际应用中，一般只将数据集分成两类，即training set 和test set，大多数文章并不涉及validation set。我们这里也不涉及。大家常用的sklearn的train_test_split函数就是将矩阵随机划分为训练子集和测试子集，并返回划分好的训练集测试集样本和训练集测试集标签。&lt;/p&gt;
&lt;h2 id=&quot;0x02-alink示例代码&quot;&gt;0x02 Alink示例代码&lt;/h2&gt;
&lt;p&gt;首先我们给出示例代码，然后会深入剖析：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;public class SplitExample {
  public static void main(String[] args) throws Exception {
    String url = &quot;iris.csv&quot;;
    String schema = &quot;sepal_length double, sepal_width double, petal_length double, petal_width double, category string&quot;;

    //这里是批处理
    BatchOperator data = new CsvSourceBatchOp().setFilePath(url).setSchemaStr(schema);
    SplitBatchOp spliter = new SplitBatchOp().setFraction(0.8);
    spliter.linkFrom(data);
    BatchOperator trainData = spliter;
    BatchOperator testData = spliter.getSideOutput(0);

    // 这里是流处理
    CsvSourceStreamOp dataS = new CsvSourceStreamOp().setFilePath(url).setSchemaStr(schema);
    SplitStreamOp spliterS = new SplitStreamOp().setFraction(0.4);
    spliterS.linkFrom(dataS);
    StreamOperator train_data = spliterS;
    StreamOperator test_data = spliterS.getSideOutput(0);
  }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;0x03-批处理&quot;&gt;0x03 批处理&lt;/h2&gt;
&lt;p&gt;SplitBatchOp是分割批处理的主要类，具体构建DAG的工作是在其linkFrom完成的。&lt;/p&gt;
&lt;p&gt;总体思路比较简单：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;假定有一个采样比例 fraction&lt;/li&gt;
&lt;li&gt;将数据集分区，并行计算每个分区上的记录数&lt;/li&gt;
&lt;li&gt;把每个分区上的记录数累积，得到所有记录总数 totCount&lt;/li&gt;
&lt;li&gt;&lt;u&gt;从上而下&lt;/u&gt;计算出一个采样总数：&lt;code&gt;numTarget = totCount * fraction&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;因为具体选择元素是在每个分区上做的，所以在每个分区上，分别计算出来这个分区应该采样的记录数，比如第n个分区上应采样记录数：&lt;code&gt;task_n_count * fraction&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;把这些分区 &quot;应该采样的记录数&quot; 累积，得出来&lt;u&gt;从下而上&lt;/u&gt;计算出的采样总数： &lt;code&gt;totSelect = task_1_count * fraction + task_2_count * fraction + ... task_n_count * fraction&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;numTarget 和 totSelect 可能不相等，所以随机决定把多出来的 &lt;code&gt;numTarget - totSelect&lt;/code&gt; 加入到某一个task中。&lt;/li&gt;
&lt;li&gt;在每个task上采样得到具体的记录。&lt;/li&gt;
&lt;/ol&gt;&lt;h3 id=&quot;31-得到记录数&quot;&gt;3.1 得到记录数&lt;/h3&gt;
&lt;p&gt;如果要分割数据，首先必须知道数据集的记录数。比如这个DataSet的记录是1万个？还是十万个？因为数据集可能会很大，所以这一步操作也使用了并行处理，即把数据分区，然后通过mapPartition操作得到每一个分区上元素的数目。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;DataSet&amp;lt;Tuple2&amp;lt;Integer, Long&amp;gt;&amp;gt; countsPerPartition = DataSetUtils.countElementsPerPartition(rows); //返回哪个task有哪些记录数

DataSet&amp;lt;long[]&amp;gt; numPickedPerPartition = countsPerPartition
    .mapPartition(new CountInPartition(fraction)) //计算总数
    .setParallelism(1)
    .name(&quot;decide_count_of_each_partition&quot;);
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;因为每个分区就对应了一个task，所以我们也可以认为，这是获取了每个task的记录数。&lt;/p&gt;
&lt;p&gt;具体工作是在 DataSetUtils.countElementsPerPartition 中完成的。返回类型是&amp;lt;index of this subtask, record count in this subtask&amp;gt;，比如3号task拥有30个记录。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;public static &amp;lt;T&amp;gt; DataSet&amp;lt;Tuple2&amp;lt;Integer, Long&amp;gt;&amp;gt; countElementsPerPartition(DataSet&amp;lt;T&amp;gt; input) {
   return input.mapPartition(new RichMapPartitionFunction&amp;lt;T, Tuple2&amp;lt;Integer, Long&amp;gt;&amp;gt;() {
      @Override
      public void mapPartition(Iterable&amp;lt;T&amp;gt; values, Collector&amp;lt;Tuple2&amp;lt;Integer, Long&amp;gt;&amp;gt; out) throws Exception {
         long counter = 0;
         for (T value : values) {
            counter++; //计算本task的记录总数
         }
         out.collect(new Tuple2&amp;lt;&amp;gt;(getRuntimeContext().getIndexOfThisSubtask(), counter));
      }
   });
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;计算总数的工作其实是在下一阶段算子中完成的。&lt;/p&gt;
&lt;h3 id=&quot;32-随机选取记录&quot;&gt;3.2 随机选取记录&lt;/h3&gt;
&lt;p&gt;接下来的工作主要是在 CountInPartition.mapPartition 完成的，其作用是随机决定每个task选择多少个记录。&lt;/p&gt;
&lt;p&gt;这时候就不需要并行了，所以 &lt;code&gt;.setParallelism(1)&lt;/code&gt;&lt;/p&gt;
&lt;h4 id=&quot;321-得到总记录数&quot;&gt;3.2.1 得到总记录数&lt;/h4&gt;
&lt;p&gt;得到了每个分区记录数之后，我们遍历每个task的记录数，然后累积得到总记录数 totCount（&lt;u&gt;就是从上而下计算出来的总数&lt;/u&gt;）。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;public void mapPartition(Iterable&amp;lt;Tuple2&amp;lt;Integer, Long&amp;gt;&amp;gt; values, Collector&amp;lt;long[]&amp;gt; out) throws Exception {
        long totCount = 0L;
        List&amp;lt;Tuple2&amp;lt;Integer, Long&amp;gt;&amp;gt; buffer = new ArrayList&amp;lt;&amp;gt;();
        for (Tuple2&amp;lt;Integer, Long&amp;gt; value : values) { //遍历输入的所有分区记录
    totCount += value.f1; //f1是Long类型的记录数
    buffer.add(value);
        }
  ...
  //后续代码在下面分析。  
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;h4 id=&quot;322-决定每个task选择记录数&quot;&gt;3.2.2 决定每个task选择记录数&lt;/h4&gt;
&lt;p&gt;然后CountInPartition.mapPartition函数中会随机决定每个task会选择的记录数。mapPartition的参数 Iterable&amp;lt;Tuple2&amp;lt;Integer, Long&amp;gt;&amp;gt; values 就是前一阶段的结果 ：一个元祖&amp;lt;task id, 每个task的记录数目&amp;gt;。&lt;/p&gt;
&lt;p&gt;把这些元祖结合在一起，记录在buffer这个列表中。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;buffer = {ArrayList@8972}  size = 4
 0 = {Tuple2@8975} &quot;(3,38)&quot; // 3号task，其对应的partition记录数是38个。
 1 = {Tuple2@8976} &quot;(2,0)&quot;
 2 = {Tuple2@8977} &quot;(0,38)&quot;
 3 = {Tuple2@8978} &quot;(1,74)&quot;
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;系统的task数目就是buffer大小。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;int npart = buffer.size(); // num tasks
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;然后，根据”记录总数“计算出来 “随机训练数据的个数numTarget”。比如总数1万，应该随机分配20%，于是numTarget就应该是2千。这个数字以后会用到。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;long numTarget = Math.round((totCount * fraction));
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;得到每个task的记录数目，比如是上面buffer中的 38，0，38，还是74，记录在 eachCount 中。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;for (Tuple2&amp;lt;Integer, Long&amp;gt; value : buffer) {
    eachCount[value.f0] = value.f1;
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;得到每个task中随机选中的训练记录数，记录在 eachSelect 中。就是每个task目前 “记录数字 * fraction”。比如3号task记录数是38个，应该选20%，则38*20%=8个。&lt;/p&gt;
&lt;p&gt;然后把这些task自己的“随机训练记录数”再累加起来得到 totSelect（&lt;u&gt;就是从下而上计算出来的总数&lt;/u&gt;）。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;long totSelect = 0L;
for (int i = 0; i &amp;lt; npart; i++) {
    eachSelect[i] = Math.round(Math.floor(eachCount[i] * fraction));
    totSelect += eachSelect[i];
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;请注意，这时候 totSelect 和 之前计算的numTarget就有具体细微出入了，&lt;u&gt;就是理论上的一个数字，但是我们 从上而下 计算 和 从下而上 计算，其结果可能不一样。&lt;/u&gt;通过下面我们可以看出来。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;numTarget = all count * fraction

totSelect = task_1_count * fraction + task_2_count * fraction + ...
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;所以我们下一步要处理这个细微出入，就得到remain，这是&quot;总体算出来的随机数目&quot; numTarget 和 &quot;从所有task选中的随机训练记录数累积&quot; totSelect 的差。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;if (totSelect &amp;lt; numTarget) {
    long remain = numTarget - totSelect;
    remain = Math.min(remain, totCount - totSelect);
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;如果刚好个数相等，则就正常分配。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;if (remain == totCount - totSelect) {
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;如果数目不等，随机决定把&quot;多出来的remain&quot;加入到eachSelect数组中的随便一个记录上。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;for (int i = 0; i &amp;lt; Math.min(remain, npart); i++) {
    int taskId = shuffle.get(i);
    while (eachSelect[taskId] &amp;gt;= eachCount[taskId]) {
          taskId = (taskId + 1) % npart;
    }
    eachSelect[taskId]++;
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;最后给出所有信息&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;long[] statistics = new long[npart * 2];
for (int i = 0; i &amp;lt; npart; i++) {
    statistics[i] = eachCount[i];
    statistics[i + npart] = eachSelect[i];
}
out.collect(statistics);

// 我们这里是4核，所以前面四项是eachCount，后面是eachSelect
statistics = {long[8]@9003} 
 0 = 38 //eachCount
 1 = 38
 2 = 36
 3 = 38
   
 4 = 31 //eachSelect
 5 = 31
 6 = 28
 7 = 30
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;这些信息是作为广播变量存储起来的，马上下面就会用到。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt; .withBroadcastSet(numPickedPerPartition, &quot;counts&quot;)
&lt;/code&gt;
&lt;/pre&gt;
&lt;h4 id=&quot;323-每个task选择记录&quot;&gt;3.2.3 每个task选择记录&lt;/h4&gt;
&lt;p&gt;CountInPartition.PickInPartition函数中会随机在每个task选择记录。&lt;/p&gt;
&lt;p&gt;首先得到task数目 和 之前存储的广播变量（就是之前刚刚存储的）。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;int npart = getRuntimeContext().getNumberOfParallelSubtasks();
List&amp;lt;long[]&amp;gt; bc = getRuntimeContext().getBroadcastVariable(&quot;counts&quot;);
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;分离count和select。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;long[] eachCount = Arrays.copyOfRange(bc.get(0), 0, npart);
long[] eachSelect = Arrays.copyOfRange(bc.get(0), npart, npart * 2);
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;得到总task数目&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;int taskId = getRuntimeContext().getIndexOfThisSubtask();
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;得到自己 task 对应的 count, select&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;long count = eachCount[taskId];
long select = eachSelect[taskId];
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;添加本task对应的记录，随机洗牌打乱顺序&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;for (int i = 0; i &amp;lt; count; i++) {
     shuffle.add(i); //就是把count内的数字加到数组
}
Collections.shuffle(shuffle, new Random(taskId)); //洗牌打乱顺序

// suffle举例
shuffle = {ArrayList@8987}  size = 38
 0 = {Integer@8994} 17
 1 = {Integer@8995} 8
 2 = {Integer@8996} 33
 3 = {Integer@8997} 34
 4 = {Integer@8998} 20
 5 = {Integer@8999} 0
 6 = {Integer@9000} 26
 7 = {Integer@9001} 27
 8 = {Integer@9002} 23
 9 = {Integer@9003} 28
 10 = {Integer@9004} 9
 11 = {Integer@9005} 16
 12 = {Integer@9006} 13
 13 = {Integer@9007} 2
 14 = {Integer@9008} 5
 15 = {Integer@9009} 31
 16 = {Integer@9010} 15
 17 = {Integer@9011} 22
 18 = {Integer@9012} 18
 19 = {Integer@9013} 35
 20 = {Integer@9014} 36
 21 = {Integer@9015} 12
 22 = {Integer@9016} 7
 23 = {Integer@9017} 21
 24 = {Integer@9018} 14
 25 = {Integer@9019} 1
 26 = {Integer@9020} 10
 27 = {Integer@9021} 30
 28 = {Integer@9022} 29
 29 = {Integer@9023} 19
 30 = {Integer@9024} 25
 31 = {Integer@9025} 32
 32 = {Integer@9026} 37
 33 = {Integer@9027} 4
 34 = {Integer@9028} 11
 35 = {Integer@9029} 6
 36 = {Integer@9030} 3
 37 = {Integer@9031} 24
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;随机选择，把选择后的再排序回来&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;for (int i = 0; i &amp;lt; select; i++) {
    selected[i] = shuffle.get(i); //这时候select看起来是按照顺序选择，但是实际上suffle里面已经是乱序
}
Arrays.sort(selected); //这次再排序

// selected举例，一共30个
selected = {int[30]@8991} 
 0 = 0
 1 = 1
 2 = 2
 3 = 5
 4 = 7
 5 = 8
 6 = 9
 7 = 10
 8 = 12
 9 = 13
 10 = 14
 11 = 15
 12 = 16
 13 = 17
 14 = 18
 15 = 19
 16 = 20
 17 = 21
 18 = 22
 19 = 23
 20 = 26
 21 = 27
 22 = 28
 23 = 29
 24 = 30
 25 = 31
 26 = 33
 27 = 34
 28 = 35
 29 = 36
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;发送选择的数据&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;if (numEmits &amp;lt; selected.length &amp;amp;&amp;amp; iRow == selected[numEmits]) {
    out.collect(row);
    numEmits++;
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;33-设置训练数据集和测试数据集&quot;&gt;3.3 设置训练数据集和测试数据集&lt;/h3&gt;
&lt;p&gt;output是训练数据集，SideOutput是测试数据集。因为这两个数据集在Alink内部都是Table类型，所以直接使用了SQL算子 &lt;code&gt;minusAll&lt;/code&gt; 来完成分割。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;this.setOutput(out, in.getSchema());
this.setSideOutputTables(new Table[]{in.getOutputTable().minusAll(this.getOutputTable())});
&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;0x04-流处理&quot;&gt;0x04 流处理&lt;/h2&gt;
&lt;p&gt;训练是在SplitStreamOp类完成的，其通过linkFrom完成了模型的构建。&lt;/p&gt;
&lt;p&gt;流处理依赖SplitStream 和 SelectTransformation 这两个类来完成分割流。&lt;u&gt;具体并没有建立一个物理操作，而只是影响了上游算子如何与下游算子联系，如何选择记录&lt;/u&gt;。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;SplitStream &amp;lt;Row&amp;gt; splited = in.getDataStream().split(new RandomSelectorOp(getFraction()));
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;首先，用RandomSelectorOp来随机决定输出时候选择哪个流。我们可以看到，这里就是随便起了&quot;a&quot;， &quot;b&quot; 这两个名字而已。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;class RandomSelectorOp implements OutputSelector &amp;lt;Row&amp;gt; {
   private double fraction;
   private Random random = null;
   @Override
   public Iterable &amp;lt;String&amp;gt; select(Row value) {
      if (null == random) {
         random = new Random(System.currentTimeMillis());
      }
      List &amp;lt;String&amp;gt; output = new ArrayList &amp;lt;String&amp;gt;(1);
      output.add((random.nextDouble() &amp;lt; fraction ? &quot;a&quot; : &quot;b&quot;)); //随机选取数字分配，随意起的名字
      return output;
   }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;其次，得到那两个随机生成的流。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;DataStream &amp;lt;Row&amp;gt; partA = splited.select(&quot;a&quot;);
DataStream &amp;lt;Row&amp;gt; partB = splited.select(&quot;b&quot;);
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;最后把这两个流分别设置为output和sideOutput。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;this.setOutput(partA, in.getSchema()); //训练集
this.setSideOutputTables(new Table[]{
DataStreamConversionUtil.toTable(getMLEnvironmentId(), partB, in.getSchema())}); //验证集
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;最后返回本身，这时候SplitStreamOp拥有两个成员变量：&lt;/p&gt;
&lt;p&gt;this.output就是训练集。&lt;/p&gt;
&lt;p&gt;this.sideOutPut就是验证集。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;return this;
&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;0x05-参考&quot;&gt;0x05 参考&lt;/h2&gt;
&lt;p&gt;&lt;a href=&quot;https://blog.csdn.net/baidu_29571167/article/details/83036225&quot;&gt;训练数据，验证数据和测试数据分析&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;</description>
<pubDate>Fri, 12 Jun 2020 14:45:00 +0000</pubDate>
<dc:creator>罗西的思考</dc:creator>
<og:description>Alink 是阿里巴巴基于实时计算引擎 Flink 研发的新一代机器学习算法平台，是业界首个同时支持批式算法、流式算法的机器学习平台。本文将为大家展现Alink如何划分训练数据集和测试数据集。</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/rossiXYZ/p/13110960.html</dc:identifier>
</item>
</channel>
</rss>