<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="css/feed.xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/" xmlns:og="http://ogp.me/ns#">
<channel>
<atom:link rel="self" href="http://192.168.1.4/fivefilters/makefulltextfeed.php?url=feed.cnblogs.com%2Fblog%2Fsitehome%2Frss&amp;max=10&amp;links=preserve&amp;exc=" />
<atom:link rel="alternate" title="Source URL" href="http://feed.cnblogs.com/blog/sitehome/rss" />
<atom:link rel="related" title="Subscribe to feed" href="http://www.subtome.com/#/subscribe?feeds=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed.cnblogs.com%252Fblog%252Fsitehome%252Frss%26max%3D10%26links%3Dpreserve%26exc%3D&amp;back=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed.cnblogs.com%252Fblog%252Fsitehome%252Frss%26max%3D10%26links%3Dpreserve%26exc%3D" />
<title>博客园_首页</title>
<link></link>
<description>代码改变世界</description>
<item>
<title>系统服务监控指标--load、CPU利用率、磁盘剩余空间、磁盘I/O、内存使用情况等 - 谁主沉浮oo7</title>
<link>http://www.cnblogs.com/feifuzeng/p/13638655.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/feifuzeng/p/13638655.html</guid>
<description>&lt;h2 id=&quot;介绍&quot;&gt;介绍&lt;/h2&gt;
&lt;p&gt;大型互联网企业的背后，依靠的是成千上万台服务器日夜不停的运转，以支撑其业务的运转。宕机对于互联网企业来说，代价是沉重的，轻则影响用户体验，重则直接影响交易，导致交易下跌，并且给企业声誉造成不可挽回的损失。对于这些机器对应的开发和运维人员来说，即便是每台机器登陆一次，登陆那么多台机器也够呛，何况还需要进行系统指标的检查。因此，依靠人力是不可能完成24小时不间断监控服务器的任务的。&lt;/p&gt;
&lt;p&gt;如今，互联网已经深入到人们生活的每个角落，可以想象一下，假如哪一天Google或者Baidu不能搜索，抑或是amazon或者taobao不能进行购物，这个世界将会如何？因此，成熟稳健的系统往往需要对集群运行时的各个指标进行收集，如系统的load、CPU利用率、I/O繁忙程度、网络traffic、内存利用率、应用心跳等，对这些信息进行实时监控，如发现异常情况，能够第一时间通知到相应的开发和运维人员进行处理，在用户还没有察觉之前处理完故障和异常，将损失降低到最低。&lt;/p&gt;
&lt;p&gt;下面来看一下，常见的系统监控指标。&lt;/p&gt;
&lt;h2 id=&quot;load：反映系统忙闲程度&quot;&gt;load：反映系统忙闲程度&lt;/h2&gt;
&lt;p&gt;在Linux系统中，可以通过top和uptime命令来查看系统的load值，那么什么是load呢？系统的load被定义为&lt;strong&gt;特定时间间隔内运行队列中的平均线程数&lt;/strong&gt;，如果一个线程满足以下条件，该线程就会处于运行队列中：&lt;/p&gt;
&lt;p&gt;没有处于I/O等待状态&lt;br/&gt;没有主动进入等待状态，也就是没有调用wait操作&lt;br/&gt;没有被终止当然load计算的算法较为复杂，因此，这种情况也不是绝对的。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;load值越大，也就意味着系统的CPU越繁忙，这样线程运行完以后等待操作系统分配下一个时间片段的时间也就越长&lt;/strong&gt;。假设：&lt;/p&gt;
&lt;p&gt;CPU1分钟内最多处理100个线程任务，load值为0.2，意味着这1分钟内CPU处理了20个任务&lt;br/&gt;CPU1分钟内最多处理100个线程任务，load值为1，意味着这1分钟内CPU刚好将这100个任务处理完&lt;br/&gt;CPU1分钟内最多处理100个线程任务，load值为1.7，意味着这1分钟内CPU除了处理了这100个任务外，还有70个任务等待处理&lt;br/&gt;当然，load的计算算法较为复杂，并不像上面说的这么简单，这么打比方只是为了简单说明问题。假设一般来说，只要load值不大于3，我们认为它的负载是正常的（考虑到多核CPU的系统），如果load值大于5，则表示当前系统的负载已经非常高了，需要采取相应的措施来降低系统的负载。&lt;/p&gt;
&lt;p&gt;w、top、uptime这三个命令都可以用来查看系统的load值，下面演示一下使用uptime命令查看系统的load：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/908629/202009/908629-20200914093934479-620095087.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;load average后面跟的三个值分别表示在过去1分钟、5分钟、15分钟内系统的load值。&lt;/p&gt;
&lt;h2 id=&quot;cpu利用率：反映cpu的使用和消耗情况&quot;&gt;CPU利用率：反映CPU的使用和消耗情况&lt;/h2&gt;
&lt;p&gt;在Linux系统中，CPU的时间消耗主要在这几个方面：用户进程、内核进程、中断处理、I/O等待、Nice时间、丢失时间、空闲等几个部分，而CPU的利用率则为这些时间所占用的总时间的百分比。通过CPU的利用率，能够反映出CPU的使用和消耗情况。&lt;/p&gt;
&lt;p&gt;可以通过top命令来查看Linux系统的CPU消耗情况：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/908629/202009/908629-20200914094115234-1108823338.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;上面一部分，也就是&quot;%Cpu(s)&quot;开头的内容是我们需要关注的，后面跟的列便是各种状态下CPU所消耗的时间比，看下每一列的意思：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;用户时间（User Time）即us所对应的列，表示CPU执行用户进程所占用的时间，通常情况下希望us的占比越高越好&lt;/li&gt;
&lt;li&gt;系统时间（System Time）即sy所对应该的列，表示CPU自内核态所花费的时间，sy占比比较高通常意味着系统在某些方面设计得不合理，比如频繁的系统调用导致的用户态和内核态的频繁切换&lt;/li&gt;
&lt;li&gt;Nice时间（Nice Time）即ni所对应的列，表示系统在调整进程优先级的时候所花费的时间&lt;/li&gt;
&lt;li&gt;空闲时间（Idle Time）即id所对应的列，表示系统处于空闲期，等待进程运行，这个过程所占用的时间。当然，我们希望id的占比越低越好&lt;/li&gt;
&lt;li&gt;等待时间（Waiting Time）即wa所对应的列，表示CPU在等待I/O操作所花费的时间，系统不应该花费大量的时间来进行等待，否则便表示可能有某个地方设计不合理&lt;/li&gt;
&lt;li&gt;硬件中断处理时间（Hard Irq Time）即hi对应的列，表示系统处理硬件中断所占用的时间&lt;/li&gt;
&lt;li&gt;软件中断处理时间（Soft Irq Time）即si对应的列，表示系统处理软件中断所占用的时间&lt;/li&gt;
&lt;li&gt;丢失时间（Steal Time）即st对应的列，实在硬件虚拟化开始流行后操作系统新增的一列，表示被强制等待虚拟CPU的时间&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;对于多个或多核CPU的情况，常常需要查看每个CPU的利用情况，此时可以按1，便可以查看到每个核的CPU利用率：&lt;br/&gt;若看到上面只出现了&quot;%Cpu0&quot;而不是&quot;%Cpu(s)&quot;，因为只有一个CPU，所以只展示Cpu0的CPU利用率&lt;/p&gt;
&lt;h2 id=&quot;磁盘剩余空间&quot;&gt;磁盘剩余空间&lt;/h2&gt;
&lt;p&gt;磁盘剩余空间也是一个非常关键的指标，如果磁盘没有足够的剩余空间，正常的日志写入以及系统I/O都将无法进行。&lt;/p&gt;
&lt;p&gt;通过df命令可以查看磁盘的剩余空间：&lt;br/&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/908629/202009/908629-20200914112607908-86380728.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;-h表示按单位格式化输出。该命令显示/dev/mapper/centos-root一共有148GB的空间，使用了38GB，剩余103GB可用。&lt;/p&gt;
&lt;p&gt;如果要查看具体目录所占用的内存空间，分析大文件所处位置，可以使用du命令来进行查看：&lt;br/&gt;-d指定了递归深度为1层，表示只列出指定目录的下一级目录文件大小，-h用来表示格式化输出。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/908629/202009/908629-20200914112958985-494653767.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h2 id=&quot;磁盘io&quot;&gt;磁盘I/O&lt;/h2&gt;
&lt;p&gt;磁盘I/O的繁忙程度也是一个重要的系统指标，对于I/O密集型的应用来说，比如数据库应用和分布式文件系统，I/O的繁忙程度也一定程度上反映了系统的负载情况，容易成为应用程序性能的瓶颈。可以使用iostat来查看系统的I/O状况：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/908629/202009/908629-20200914113419129-1205712352.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;-d表示查看磁盘使用状况，-k表示以KB为单位显示。各个列中，Device表示设备名称、tps表示每秒处理的I/O请求数、kB_read/s表示每秒从设备读取的数据量、kB_wrtn/s表示每秒向设备写入的数据量、kB_read表示读取的数据总量、kB_wrtn表示写入的数据总量。&lt;/p&gt;
&lt;h2 id=&quot;内存使用情况&quot;&gt;内存使用情况&lt;/h2&gt;
&lt;p&gt;程序运行时的数据加载、线程并发、I/O缓冲等，都依赖于内存，可用内存的大小决定了程序是否能正常运行以及运行的性能。&lt;/p&gt;
&lt;p&gt;通过free命令能够查看到系统的内存使用情况，加上-m参数表示以MB为单位：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/908629/202009/908629-20200914113556895-1362609115.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;Linux的内存包括物理内存Mem和虚拟内存Swap，下面介绍每一列的含义：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;total----内存总共的大小&lt;/li&gt;
&lt;li&gt;used----已使用的内存大小&lt;/li&gt;
&lt;li&gt;free----可使用的内存大小&lt;/li&gt;
&lt;li&gt;shared----多个进程共享的内存大小&lt;/li&gt;
&lt;li&gt;buffers----缓冲区的大小&lt;/li&gt;
&lt;li&gt;cached----缓存的大小&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;Linux系统的内存管理机制与Windows系统有所不同，其中有一个思想便是内存利用率最大化，内核会将剩余的内存申请为cached，而cached不属于free范畴。因此，当系统运行时间较长时，会发现cached这块区域比较大，对于有频繁文件读/写操作的系统，这种现象更为明显。&lt;/p&gt;
&lt;p&gt;但是，free的内存小，并不代表可用小，当程序需要申请更大的内存时，如果free内存不够，系统会将剩余部分cached会buffers内存回收，回收的内存再分配给应用程序。因此，Linux可用于分配的内存不仅仅只有free的内存。可看free命令显示的第三行，也就是&quot;-/+ buffers/cache&quot;对应的行，这一行将内存进行了重新计算，used减去buffers和cached占用的内存，而free则加上了buffers和cached对应的内存。&lt;/p&gt;
&lt;p&gt;对于应用来说，更值得关注的应该是虚拟内存Swap的消耗，Swap内存使用过多，表示物理内存已经不够用了，操作系统将本应该物理内存存储的一部分内存页调度到磁盘上，以腾出足够的空间给当前的进程使用。当其他进程需要运行时，再从磁盘将内存的页调度到物理内存当中，以恢复进程的运行。而这个调度的过程中，会产生Swap I/O，如果Swap I/O较为频繁，将严重地影响系统的性能。&lt;/p&gt;
&lt;p&gt;通过vmstat命令，可以查看到Swap I/O的情况：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/908629/202009/908629-20200914113706412-307443887.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;其中，swap列的si表示每秒从磁盘交换到内存的数据量，单位是KB/s，so表示每秒从内存交换到磁盘的数据量，单位也是KB/s。&lt;/p&gt;
&lt;h2 id=&quot;参考&quot;&gt;参考&lt;/h2&gt;
&lt;p&gt;&lt;a href=&quot;https://www.cnblogs.com/xrq730/p/5171463.html&quot;&gt;https://www.cnblogs.com/xrq730/p/5171463.html&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;结语&quot;&gt;结语&lt;/h2&gt;
&lt;p&gt;欢迎关注微信公众号『码仔zonE』，专注于分享Java、云计算相关内容，包括SpringBoot、SpringCloud、微服务、Docker、Kubernetes、Python等领域相关技术干货，期待与您相遇！&lt;br/&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/908629/202008/908629-20200819141402537-1758432824.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
</description>
<pubDate>Tue, 15 Sep 2020 00:49:00 +0000</pubDate>
<dc:creator>谁主沉浮oo7</dc:creator>
<og:description>介绍 大型互联网企业的背后，依靠的是成千上万台服务器日夜不停的运转，以支撑其业务的运转。宕机对于互联网企业来说，代价是沉重的，轻则影响用户体验，重则直接影响交易，导致交易下跌，并且给企业声誉造成不可挽</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/feifuzeng/p/13638655.html</dc:identifier>
</item>
<item>
<title>C#类库推荐  拼多多.Net SDK，开源免费！ - MSDev_NilTor</title>
<link>http://www.cnblogs.com/msdeveloper/p/open-pdd-net-sdk.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/msdeveloper/p/open-pdd-net-sdk.html</guid>
<description>&lt;p&gt;近两年拼多多的发展非常迅速，即便口碑一般，也没有网页端，奈何我们已经全面小康，6亿月收入1000以下，9亿月收入2000以下，所以因为价格原因使用拼多多的用户也越来越多了。同样的，拼多多也开放了部分API接口，提供给开发者使用，开放平台也是一如既往的拼多多，没法跟淘宝、京东等相比，至今没有测试环境，官方也只提供了Java版本的SDK，C#及.Net在国内的存量用户还是有一些的，虽然整体上目前还是不乐观，但我想有脑子的都知道，像C#这么优秀的语言和日益精进的.Net Core，未来一定会有越来越多的人采用的，在此背景下，通过官方提供的API文档，我编写了拼多多开放平台.Net SDK。&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://dev.azure.com/msdev-zpty/pdd-open-net-sdk/_build/latest?definitionId=1&quot;&gt;&lt;img src=&quot;https://dev.azure.com/msdev-zpty/pdd-open-net-sdk/_apis/build/status/pdd-open-net-sdk-CI&quot; alt=&quot;Build status&quot; loading=&quot;lazy&quot;/&gt;&lt;/a&gt; &lt;a href=&quot;https://www.nuget.org/packages/MSDev.PddOpenSdk.AspNetCore/&quot;&gt;&lt;img src=&quot;https://img.shields.io/nuget/v/MSDev.PddOpenSdk.AspNetCore.svg?style=flat-square&amp;amp;label=nuget&quot; alt=&quot;NuGet&quot; loading=&quot;lazy&quot;/&gt;&lt;/a&gt; &lt;a href=&quot;https://www.nuget.org/packages/MSDev.PddOpenSdk.AspNetCore/&quot;&gt;&lt;img src=&quot;https://img.shields.io/nuget/dt/MSDev.PddOpenSdk.AspNetCore.svg&quot; alt=&quot;NuGet&quot; loading=&quot;lazy&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;地址&quot;&gt;地址&lt;/h2&gt;
&lt;h2 id=&quot;概要&quot;&gt;概要&lt;/h2&gt;
&lt;p&gt;支持基于 NETStandardv2.0 的项目，支持 .NetFramework 4.5.2+，C#8.0。&lt;br/&gt;ASP.NET Core 项目请使用 Nuget 包 MSDev.PddOpenSdk.AspNetCore，可直接通过注入服务的方式使用。&lt;br/&gt;其他类型使用 Nuget 包 MSDev.PddOpenSdk&lt;/p&gt;
&lt;h2 id=&quot;源码项目说明&quot;&gt;源码项目说明&lt;/h2&gt;
&lt;h3 id=&quot;console项目&quot;&gt;Console项目&lt;/h3&gt;
&lt;p&gt;该项目是通过官方接口获取并自动生成所有请求模型类、返回模型类以及请求服务类，生成后部分类名会有重名,更改成不同的类名即可。&lt;/p&gt;
&lt;p&gt;执行方法，打开Console目录，然后执行&lt;code&gt;dotnet run&lt;/code&gt;命令即可。&lt;/p&gt;
&lt;p&gt;执行成功后，可使用Visual Studio自带的代码清理，对所有文件进行代码格式化操作。&lt;/p&gt;
&lt;h3 id=&quot;pddopensdk-核心类库使用&quot;&gt;PddOpenSdk 核心类库使用&lt;/h3&gt;
&lt;p&gt;支持 &lt;code&gt;.Net Framework4.5.2&lt;/code&gt;及&lt;code&gt;Net Standard 2.0&lt;/code&gt; ，安装 Nuget 包 &lt;code&gt;MSDev.PddOpenSdk&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;使用示例:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;基本请求及错误信息&lt;/li&gt;
&lt;/ul&gt;&lt;pre&gt;
&lt;code class=&quot;language-csharp&quot;&gt;class Program
{
    static async Task Main(string[] args)
    {
        // 设置ClientId与ClientSecret
        PddCommonApi.ClientId = &quot;ID&quot;;
        PddCommonApi.ClientSecret = &quot;Secret&quot;;
        // 先使用code换取token
        string code = &quot;&quot;;
        var authApi = new AuthApi();
        await authApi.GetAccessTokenAsync(code);
    
        // 构造请求内容
        var model = new GenDdkWeappQrcodeUrlRequestModel
        {
            PId = &quot;123133&quot;,
            GoodsIdList = new System.Collections.Generic.List&amp;lt;long&amp;gt; { 1122, 331323 }
        };
        var api = new DdkApi();
        var result = await api.GenDdkWeappQrcodeUrlAsync(model);

        // 获取Pdd官方返回的错误信息
        var errorResponse = _pdd.DdkApi.ErrorResponse.Value;
        Console.WriteLine(errorResponse.Error_msg);

    }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;ul&gt;&lt;li&gt;图片上传示例&lt;/li&gt;
&lt;/ul&gt;&lt;pre&gt;
&lt;code class=&quot;language-csharp&quot;&gt;    var filePath = Path.Combine(&quot;images&quot;, &quot;logo.png&quot;);
    byte[] bytes = System.IO.File.ReadAllBytes(filePath);

    // 构造图片上传内容
    string base64 = &quot;data:image/png;base64,&quot; + Convert.ToBase64String(bytes);
    var model = new UploadGoodsImageRequestModel
    {
        Image = base64
    };
    var result = await _pdd.GoodsApi.UploadGoodsImageAsync(model)
&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;aspnet-core-项目使用&quot;&gt;ASP.NET Core 项目使用&lt;/h3&gt;
&lt;p&gt;先安装Nuget 包 &lt;code&gt;MSDev.PddOpenSdk.AspNetCore&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;更多 &lt;a href=&quot;https://github.com/niltor/open-pdd-net-sdk/tree/dev/PddOpenSdk/Sample&quot;&gt;示例代码&lt;/a&gt;。&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;在 Startup.cs 中注入服务&lt;/li&gt;
&lt;/ul&gt;&lt;pre&gt;
&lt;code class=&quot;language-csharp&quot;&gt;services.AddPdd(options =&amp;gt;
{
    // 使用appsettings 配置你的ClientId等参数
    options.ClientId = Configuration.GetSection(&quot;Pdd&quot;)[&quot;ClientId&quot;];
    options.CallbackUrl = Configuration.GetSection(&quot;Pdd&quot;)[&quot;RedirectUri&quot;];
    options.ClientSecret = Configuration.GetSection(&quot;Pdd&quot;)[&quot;ClientSecret&quot;];
});
&lt;/code&gt;
&lt;/pre&gt;
&lt;ul&gt;&lt;li&gt;然后在控制器使用注入服务&lt;/li&gt;
&lt;/ul&gt;&lt;pre&gt;
&lt;code class=&quot;language-csharp&quot;&gt;readonly PddService _pdd;
public YourController(PddService pdd)
{
    _pdd = pdd;
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;ul&gt;&lt;li&gt;获取 AccessToken&lt;/li&gt;
&lt;/ul&gt;&lt;pre&gt;
&lt;code class=&quot;language-csharp&quot;&gt;/// &amp;lt;summary&amp;gt;
/// 测试获取token
/// &amp;lt;/summary&amp;gt;
/// &amp;lt;param name=&quot;code&quot;&amp;gt;&amp;lt;/param&amp;gt;
/// &amp;lt;returns&amp;gt;&amp;lt;/returns&amp;gt;
public async Task&amp;lt;IActionResult&amp;gt; Callback(string code)
{
    var token = await _pdd.AuthApi.GetAccessTokenAsync(code);
    // 自行维护Token过期时间
    return Content(token.AccessToken);
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;pre&gt;
&lt;code class=&quot;language-csharp&quot;&gt;public async Task&amp;lt;ActionResult&amp;gt; Test()
{
    // 构造请求模型
    var requestModel = new SearchDdkGoodsRequestModel
    {
        SortType = 0,
        WithCoupon = false
    };
    // 调用相应接口方法
    var result = await _pdd.DdkApi.SearchDdkGoodsAsync(requestModel);
    return Content(JsonConvert.SerializeObject(result));
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;所有方法名与官方文档保持一致，并有中文注释提醒，只是更改了命名规范，非常容易查找使用。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;欢迎通过以下方式反馈问题:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;提交 GitHub Issues&lt;/li&gt;
&lt;li&gt;Email： zpty@outlook.com（优先处理）&lt;/li&gt;
&lt;li&gt;QQ 群：737822525&lt;/li&gt;
&lt;/ul&gt;</description>
<pubDate>Tue, 15 Sep 2020 00:46:00 +0000</pubDate>
<dc:creator>MSDev_NilTor</dc:creator>
<og:description>拼多多开放平台 .net c# 版 sdk。</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/msdeveloper/p/open-pdd-net-sdk.html</dc:identifier>
</item>
<item>
<title>终于有人把MYSQL索引讲清楚了 - 知识追寻者</title>
<link>http://www.cnblogs.com/zszxz/p/13670986.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/zszxz/p/13670986.html</guid>
<description>&lt;p&gt;索引在MYSQL中也可以称为键，其是存储引擎用于快速查找记录的一种数据结构；这样听起来有点生涩，你可能难以理解；如果给你一本书，你如何能够精确的查找到书中某个章节的具体位置呢？我们肯定是先看目录，再找内容。你可以理解索引就像书的目录一样；当数据库的数据量大的时候，索引的性能对数据库非常重要，索引分为很多种，所以要学习好索引的相关知识，甚至比查询优化更重要。&lt;/p&gt;

&lt;h2 id=&quot;21b-tree树&quot;&gt;2.1B-tree树&lt;/h2&gt;
&lt;p&gt;学习B-树之前读者肯定要有二叉树的基础知识，（没学过的看这篇&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://blog.csdn.net/youku1327/article/details/105159762%EF%BC%89&quot;&gt;https://blog.csdn.net/youku1327/article/details/105159762）&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;MYSQL中的数据结构实际上是B+tree，而非Btree；所以我们先要了解一下什么是Btree，再了解下一下什么是B+tree; 要得出的结论是为什么MYSQL要使用B+tree, 而非 Btree；&lt;/p&gt;
&lt;p&gt;M阶B-tree的特征如下&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;根节点至少有两个子女.&lt;/li&gt;
&lt;li&gt;每个节点包含k-1个元素和k个孩子,其中m/2 &amp;lt;= k &amp;lt;= m.&lt;/li&gt;
&lt;li&gt;每一个叶子节点都包含k-1个元素,其中m/2 &amp;lt;= k &amp;lt;= m.&lt;/li&gt;
&lt;li&gt;所有的叶子节点位于同一层.&lt;/li&gt;
&lt;li&gt;每个节点中的元素从小到大排列,那么k-1个元素正好是k个孩子包含的值域的划分&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;如果没学过数据结构的读者看到这边肯定一头雾水，知识追寻者还是做个简单的说明；如下图3阶B-树所示；&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;根节点9包含两个子节点，（3，7）一个节点，12 一个节点；&lt;/li&gt;
&lt;li&gt;(m/2=1) &amp;lt;= k &amp;lt;= (m=3); 所以节点包含1至3个都正确，故 （3，7）和 12 满足要求；&lt;/li&gt;
&lt;li&gt;再看 2 小于 3 位于 3左侧，（4，5）大于3小于7位于（3，7）中间，8大于7位于7右侧；&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;img src=&quot;https://gitee.com/lsc180/images/raw/master/img/20200914092448.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;树的高度决定了磁盘的IO能力，一棵3阶的B-磁盘IO能力为3，与二叉树IO能力相同；数据库加载索引的时候是加载磁盘页（默认4K大小），而非整个索引，每个磁盘页都对应索引的记录，故B-树并不能带来高效磁盘IO；&lt;/p&gt;
&lt;p&gt;从树的形态上B-树比二叉树更加的胖，原因也很简单，B-树的节点可能包含多个元素；&lt;/p&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;注：B树就是B-树，面试的时候别说B减树；&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;22btree树&quot;&gt;2.2B+tree树&lt;/h2&gt;
&lt;p&gt;B+树是B-树的基础上进行升级，B+树的特征如下&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;每个中间节点不保存数据，用来保存索引，叶子节点存放数据；&lt;/li&gt;
&lt;li&gt;中间节点都存在于叶子节点，为最大值或者最小值，所以会出现重复的现象；&lt;/li&gt;
&lt;li&gt;叶子节点之间根据自身的顺序进行了链接；&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;img src=&quot;https://gitee.com/lsc180/images/raw/master/img/20200914101432.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;对B+树也做个简单说明：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;中间节点 （2，5，8）和（11，16）都没有存放数据，并且都是叶子节点存放数据；&lt;/li&gt;
&lt;li&gt;8，16同时存在于中间节点，叶子节点；同理（2，5，8）这个节点的元素都存在于叶子节点；&lt;/li&gt;
&lt;/ul&gt;&lt;h2 id=&quot;23b比b-优势&quot;&gt;2.3B+比B-优势&lt;/h2&gt;
&lt;p&gt;B+比B-的优势在哪里，面试经常问道；&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;B+树的中间节点不存放数据，磁盘页可以存放更多的节点元素；&lt;/li&gt;
&lt;li&gt;B+Tree非叶子节点不存储数据，所有的数据都要查询至叶子节点，而叶子节点的高度都是相同的，因此所有数据的查询速度都一样；而B-树根据精确的匹配查找，查找数据不稳定；&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;31-非聚集索引和聚集索引&quot;&gt;3.1 非聚集索引和聚集索引&lt;/h2&gt;
&lt;p&gt;MySQL中最常见的两种存储引擎分别是MyISAM和InnoDB，分别实现了&lt;strong&gt;非聚集索引（普通索引）&lt;/strong&gt;和&lt;strong&gt;聚集索引&lt;/strong&gt;；&lt;/p&gt;
&lt;p&gt;聚集索引:&lt;strong&gt;聚集索引的顺序就决定了数据行的物理存储顺序&lt;/strong&gt;；所以我们创建的主键索引其实就是聚集索引，如果未定义主键，MYSQL会默认选择非空的唯一索引当作主键，否则会默认生成一个主键&lt;/p&gt;
&lt;p&gt;非聚集索引：&lt;strong&gt;索引顺序与数据行物理排列顺序无关&lt;/strong&gt;；&lt;/p&gt;
&lt;p&gt;看下&lt;strong&gt;普通索引如何创建，其作用就是加快查询速度&lt;/strong&gt;；&lt;/p&gt;
&lt;p&gt;语法格式如下&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-sql&quot;&gt;alter table 表名 add index 索引名称(索引字段)
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;如果创建表的时候语法格式如下&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-sql&quot;&gt;CREATE INDEX 索引名称 ON 表名 (索引字段)
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;知识追寻者手头有一张用户表，模拟10万数据；&lt;/p&gt;
&lt;p&gt;未创建索引查询速度&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-sql&quot;&gt;select * from sys_user where first_name = 'ijklmnopqrs'
&amp;gt; OK
&amp;gt; 时间: 0.059s
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;创建索引&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-sql&quot;&gt;alter table sys_user add index select_username(first_name)
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;创建索引后查询速度&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-sql&quot;&gt;select * from sys_user where first_name = 'ijklmnopqrs'
&amp;gt; OK
&amp;gt; 时间: 0.049s
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;删除索引&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-sql&quot;&gt;DROP INDEX [索引名称] ON 表名; 
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;查看索引&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-sql&quot;&gt;SHOW INDEX FROM 表名;
&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;32索引的分类&quot;&gt;3.2索引的分类&lt;/h2&gt;
&lt;p&gt;Mysql中索引的种类也不是很多，不同类型的索引有不同的作用，索引的作用相互之间也存在交叉关系，Mysql中索引主要分为以下几类：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;&lt;strong&gt;主键索引&lt;/strong&gt;（&lt;code&gt;PRIMARY KEY&lt;/code&gt;）：主键索引一般都是在创建表的时候进行指定，&lt;strong&gt;一个表只有一个主键索引&lt;/strong&gt;，特点是&lt;strong&gt;唯一、非空&lt;/strong&gt;。MYSQL常用就是 自增主键；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;唯一索引&lt;/strong&gt;（&lt;code&gt;UNIQUE&lt;/code&gt;）：唯一索引具有的特点就是唯一性，即指定列不能出现重复数据；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;前缀索引&lt;/strong&gt;（&lt;code&gt;prefix INDEX&lt;/code&gt;）：前缀索引建立的基础就指定列数据有很多的共同前缀；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;联合索引&lt;/strong&gt;：联合索引又称符合索引，是在表中两个或者两个列以上的基础上创建索引；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;覆盖索引&lt;/strong&gt;：当一个索引包含(或者说是覆盖)需要查询的所有字段的值时,我们称之为覆盖索引；&lt;/li&gt;
&lt;/ol&gt;&lt;h2 id=&quot;33-主键索引和唯一索引&quot;&gt;3.3 主键索引和唯一索引&lt;/h2&gt;
&lt;p&gt;主键索引我们通常不默认，经常使用，一张表中仅允许有一个主键，可以由一个或者多字段组成；主键索引满足如下特征：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;主键必须唯一；&lt;/li&gt;
&lt;li&gt;主键不能包含NULL值；&lt;/li&gt;
&lt;li&gt;主键必须自增；&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;创建主键语法格式&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;alter table 表名 add primary key (字段名称)
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;创建唯一索引语法格式：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;alter table 表名 add unique (字段名称)
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;如果是创建表时添加约束语法格式&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;CREATE UNIQUE INDEX 索引名称 ON 表名(字段(字段长度));
&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;34-前缀索引&quot;&gt;3.4 前缀索引&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;前缀索引&lt;/strong&gt;: 当对字符串进行索引时,如果数据库中该字段有许多的前缀重复就可以使用前缀索引，,这样可以大大的节约索引空间,从而提高索引效率；但其&lt;strong&gt;缺点也很明显，不能在 order by 和 group by 中使用&lt;/strong&gt;；&lt;/p&gt;
&lt;p&gt;前缀索引经常使用在地名，比如 xx省xx市xx县这种情形，有一个统一的前缀 xx省xx市；&lt;/p&gt;
&lt;p&gt;创建语法&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;alter table 表名 add key (字段名称(前缀长度)) 
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;示例&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;alter table sys_user add key (first_name(8)) 
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;查询的时候使用指定前缀的长度性能更加&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;select * from sys_user where first_name = 'ijklmnop'
&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;35-覆盖索引&quot;&gt;3.5 覆盖索引&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;回表查询&lt;/strong&gt;：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;MYSQL 如果只通过索引就可以返回查询所需要的数据，就是不是回表查询，否则查到索引数据后还需要回到表中查询数据就是回表查询&lt;/strong&gt;；&lt;/p&gt;
&lt;p&gt;我们来看个简单的示例&lt;/p&gt;
&lt;p&gt;先去除前缀索引&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;drop index first_name on sys_user
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;然后加上普通索引&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;alter table sys_user add index select_username(first_name)
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;实行MYSQL执行计划&lt;/p&gt;
&lt;p&gt;（没学过MYSQL执行计划看这篇 &lt;a href=&quot;https://blog.csdn.net/youku1327/article/details/107336500%EF%BC%89&quot;&gt;https://blog.csdn.net/youku1327/article/details/107336500）&lt;/a&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;explain select id from sys_user where first_name = 'ijklmnop'
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;输出结果表示 使用using index ， 由于 id 和 first_name 都是索引；所以&lt;strong&gt;不需要回表查询就是覆盖索引&lt;/strong&gt;；&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://gitee.com/lsc180/images/raw/master/img/20200914113427.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;如果我们使用如下语句则需要回表查询，原因是查询到字段id, first_name后还需要回表查询其它字段，这就是为什么 s&lt;code&gt;elect *&lt;/code&gt; 如此慢的原因；&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;explain select * from sys_user where first_name = 'ijklmnop'
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;输出结果如下&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://gitee.com/lsc180/images/raw/master/img/20200914113848.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h2 id=&quot;36-联合索引&quot;&gt;3.6 联合索引&lt;/h2&gt;
&lt;p&gt;联合索引是在表中用2个或者2个以上的字段创建索引，其创建索引方式与普通索引相同；其能减小检索范围；&lt;/p&gt;
&lt;p&gt;语法格式&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;alter table 表名 add index 索引名称(字段1，字段2...)
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;最左前缀匹配原则&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;使用联合索引有一个非常重要的因素就是所有的索引列只可以进行最左前缀匹配原则&lt;/strong&gt;；&lt;/p&gt;
&lt;p&gt;比如&lt;/p&gt;
&lt;p&gt;联合索引 first_name和 last_name&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;alter table sys_user add index select_username(first_name,last_name)
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;根据最左匹配原则情形如下会命中索引&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;first_name,last_name&lt;/li&gt;
&lt;li&gt;first_name&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;转换为查询语句命中索引示例如下&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;select * from sys_user where first_name = 'ijklmnop';

select * from sys_user where first_name ='ijklmnop' and last_name ='ijklmnop';

select * from sys_user where first_name ='ijklmnop' and last_name in (ijklmnop');

select * from sys_user order by first_name,last_name

select * from sys_userwhere first_name ='ijklmnop'order by last_name
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;如下情形不会命中索引&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;select * from sys_user where last_name = 'ijklmnop';
select * from sys_userwhere last_name ='ijklmnop'order by first_name
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;索引下推&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Mysql5.6&lt;/code&gt;版本发布了索引下推的原则，&lt;strong&gt;主要用于like关键字的查询优化&lt;/strong&gt; ；&lt;/p&gt;
&lt;p&gt;比如联合索引（last_name,age）&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;select * from sys_user where last_name = 'ijklmnop' and age&amp;gt;'20';
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;命中可能性如下&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;命中last_name联合索引，查询所有满足last_name以&quot;ijklmnop&quot;开头的数据， 然后回表查询所有满足的行。&lt;/li&gt;
&lt;li&gt;命中last_name联合索引，查询所有满足last_name以&quot;ijklmnop&quot;开头的数据，然后再筛出age&amp;gt;20的索引，再回表查询全行数据。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;第二种方式的磁盘IO会更少，查询效率会更高，这就是下推索引；&lt;/p&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;除此之外还有全文索引和hash索引，简单了解一下即可；&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;41索引的优点&quot;&gt;4.1索引的优点&lt;/h2&gt;
&lt;ul&gt;&lt;li&gt;提高查询效率&lt;/li&gt;
&lt;li&gt;提高聚合函数查询效率&lt;/li&gt;
&lt;li&gt;提高排序查询效率&lt;/li&gt;
&lt;li&gt;使用覆盖索引避免回表&lt;/li&gt;
&lt;/ul&gt;&lt;h2 id=&quot;42创建索引的策略&quot;&gt;4.2创建索引的策略&lt;/h2&gt;
&lt;ul&gt;&lt;li&gt;不要在NULL值列上使用索引，尽量使用NOT NULL约束列上使用索引&lt;/li&gt;
&lt;li&gt;很少查询的字段不要使用索引&lt;/li&gt;
&lt;li&gt;大数据类型字段不创建索引&lt;/li&gt;
&lt;/ul&gt;&lt;h2 id=&quot;43-使用索引时的注意事项&quot;&gt;4.3 使用索引时的注意事项&lt;/h2&gt;
&lt;ul&gt;&lt;li&gt;不要在条件NOT IN、&amp;lt;&amp;gt;、!= 等范围查询中使用索引&lt;/li&gt;
&lt;li&gt;模糊查询时不要使用 %开头（ 如 '%xxx' , '%xxx%'）&lt;/li&gt;
&lt;li&gt;查询索引的字段不要函数计算&lt;/li&gt;
&lt;li&gt;联合索引查询时遵循最左原则&lt;/li&gt;
&lt;li&gt;全部扫描超过30%不会走优化器；&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;听说关注公众号 知识追寻者 的男孩子都找到了漂亮的女朋友，女孩子都找到了白马王子&lt;/strong&gt;；当然索引并非查询优化的最佳原则，但在大多数情况下就已经足够使用；在大数据情况下通常要考虑分库分表；&lt;br/&gt;&lt;img src=&quot;https://gitee.com/lsc180/images/raw/master/img/zszxz.jpg&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
</description>
<pubDate>Tue, 15 Sep 2020 00:40:00 +0000</pubDate>
<dc:creator>知识追寻者</dc:creator>
<og:description>一什么是索引 索引在MYSQL中也可以称为键，其是存储引擎用于快速查找记录的一种数据结构；这样听起来有点生涩，你可能难以理解；如果给你一本书，你如何能够精确的查找到书中某个章节的具体位置呢？我们肯定是</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/zszxz/p/13670986.html</dc:identifier>
</item>
<item>
<title>一条 SQL 引发的事故，同事直接被开除！！ - Java技术栈</title>
<link>http://www.cnblogs.com/javastack/p/13670978.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/javastack/p/13670978.html</guid>
<description>&lt;h3 id=&quot;前言&quot;&gt;前言&lt;/h3&gt;
&lt;p&gt;Insert into select请慎用。&lt;/p&gt;
&lt;p&gt;这天xxx接到一个需求，需要将表A的数据迁移到表B中去做一个备份。本想通过程序先查询查出来然后批量插入。但xxx觉得这样有点慢，需要耗费大量的网络I/O，决定采取别的方法进行实现。&lt;/p&gt;
&lt;p&gt;通过在Baidu的海洋里遨游，他发现了可以使用&lt;code&gt;insert into select&lt;/code&gt;实现，这样就可以避免使用网络I/O，直接使用SQL依靠数据库I/O完成，这样简直不要太棒了。&lt;/p&gt;
&lt;p&gt;然后他就被开除了。&lt;/p&gt;
&lt;h3 id=&quot;事故发生的经过。&quot;&gt;事故发生的经过。&lt;/h3&gt;
&lt;p&gt;由于数据数据库中&lt;strong&gt;order_today&lt;/strong&gt;数据量过大，当时好像有700W了并且每天在以30W的速度增加。&lt;/p&gt;
&lt;p&gt;所以上司命令xxx将&lt;strong&gt;order_today&lt;/strong&gt;内的部分数据迁移到&lt;strong&gt;order_record&lt;/strong&gt;中，并将&lt;strong&gt;order_today&lt;/strong&gt;中的数据删除。&lt;/p&gt;
&lt;p&gt;这样来降低&lt;strong&gt;order_today&lt;/strong&gt;表中的数据量。&lt;/p&gt;
&lt;p&gt;由于考虑到会占用数据库I/O，为了不影响业务，计划是9:00以后开始迁移，但是xxx在8:00的时候，尝试迁移了少部分数据(1000条)，觉得没啥问题，就开始考虑大批量迁移。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/1218593/202009/1218593-20200915083544491-1479585821.webp&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;在迁移的过程中，应急群是先反应有小部分用户出现支付失败，随后反应大批用户出现支付失败的情况，以及初始化订单失败的情况，同时腾讯也开始报警。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/1218593/202009/1218593-20200915083544987-862364827.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;然后xxx就慌了，立即停止了迁移。&lt;/p&gt;
&lt;p&gt;本以为停止迁移就就可以恢复了，但是并没有。后面发生的你们可以脑补一下。&lt;/p&gt;
&lt;h3 id=&quot;事故还原&quot;&gt;事故还原&lt;/h3&gt;
&lt;p&gt;在本地建立一个精简版的数据库，并生成了100w的数据。模拟线上发生的情况。&lt;/p&gt;
&lt;h4 id=&quot;建立表结构&quot;&gt;建立表结构&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;订单表&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;CREATE TABLE `order_today` (
  `id` varchar(32) NOT NULL COMMENT '主键',
  `merchant_id` varchar(32) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL COMMENT '商户编号',
  `amount` decimal(15,2) NOT NULL COMMENT '订单金额',
  `pay_success_time` datetime NOT NULL COMMENT '支付成功时间',
  `order_status` varchar(10) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL COMMENT '支付状态  S：支付成功、F：订单支付失败',
  `remark` varchar(100) CHARACTER SET utf8 COLLATE utf8_general_ci DEFAULT NULL COMMENT '备注',
  `create_time` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '创建时间',
  `update_time` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '修改时间 -- 修改时自动更新',
  PRIMARY KEY (`id`) USING BTREE,
  KEY `idx_merchant_id` (`merchant_id`) USING BTREE COMMENT '商户编号'
) ENGINE=InnoDB DEFAULT CHARSET=utf8;
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;订单记录表&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;CREATE TABLE order_record like order_today;
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;今日订单表数据&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/1218593/202009/1218593-20200915083545361-1294136519.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h4 id=&quot;模拟迁移&quot;&gt;模拟迁移&lt;/h4&gt;
&lt;p&gt;把8号之前的数据都迁移到&lt;code&gt;order_record&lt;/code&gt;表中去。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;INSERT INTO order_record SELECT
    *
FROM
    order_today
WHERE
    pay_success_time &amp;lt; '2020-03-08 00:00:00';
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;在navicat中运行迁移的sql,同时开另个一个窗口插入数据，模拟下单。这篇《&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzI3ODcxMzQzMw==&amp;amp;mid=2247491649&amp;amp;idx=2&amp;amp;sn=863bcc162fd63d3b3ad4a36e20e15fd5&amp;amp;chksm=eb506577dc27ec61583ea582e74ea4b77978ac07e745c9938f93ee76aeabb27f4a6a2dcb1f23&amp;amp;scene=21#wechat_redirect&quot;&gt;如何快速安全的插入千万条数据？》&lt;/a&gt;推荐看下。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/1218593/202009/1218593-20200915083545854-2116190048.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/1218593/202009/1218593-20200915083546653-2147278532.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;从上面可以发现一开始能正常插入，但是后面突然就卡住了，并且耗费了23s才成功，然后才能继续插入。这个时候已经迁移成功了，所以能正常插入了。&lt;/p&gt;
&lt;h3 id=&quot;出现的原因&quot;&gt;出现的原因&lt;/h3&gt;
&lt;p&gt;在默认的事务隔离级别下：&lt;code&gt;insert into order_record select * from order_today&lt;/code&gt; 加锁规则是：&lt;code&gt;order_record&lt;/code&gt;表锁，&lt;code&gt;order_today&lt;/code&gt;逐步锁（扫描一个锁一个）。&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzI3ODcxMzQzMw==&amp;amp;mid=2247489236&amp;amp;idx=1&amp;amp;sn=5067c4dffc609d0be9fb01405199cfea&amp;amp;chksm=eb5393e2dc241af47d98ad9a947996c1824daa789fd384b8c0dd8a2fea5cd4faa756c4e8b918&amp;amp;scene=21#wechat_redirect&quot;&gt;MySQL 四种隔离级别，&lt;/a&gt;推荐看下。&lt;/p&gt;
&lt;p&gt;分析执行过程。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/1218593/202009/1218593-20200915083546889-1115571679.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;通过观察&lt;strong&gt;迁移sql&lt;/strong&gt;的执行情况你会发现&lt;code&gt;order_today&lt;/code&gt;是全表扫描，也就意味着在执行&lt;code&gt;insert into select from&lt;/code&gt; 语句时，mysql会从上到下扫描&lt;code&gt;order_today&lt;/code&gt;内的记录并且加锁，这样一来不就和直接锁表是一样了。&lt;/p&gt;
&lt;p&gt;这也就可以解释，为什么一开始只有少量用户出现支付失败，后续大量用户出现支付失败，初始化订单失败等情况，因为一开始只锁定了少部分数据，没有被锁定的数据还是可以正常被修改为正常状态。&lt;/p&gt;
&lt;p&gt;由于锁定的数据越来越多，就导致出现了大量支付失败。最后全部锁住，导致无法插入订单，而出现初始化订单失败。&lt;/p&gt;
&lt;h3 id=&quot;解决方案&quot;&gt;解决方案&lt;/h3&gt;
&lt;p&gt;由于查询条件会导致&lt;code&gt;order_today&lt;/code&gt;全表扫描，什么能避免全表扫描呢，很简单嘛，给&lt;code&gt;pay_success_time&lt;/code&gt;字段添加一个&lt;code&gt;idx_pay_suc_time&lt;/code&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzI3ODcxMzQzMw==&amp;amp;mid=2247493930&amp;amp;idx=2&amp;amp;sn=e3fe720755de690d7780ca3c82fc36fc&amp;amp;chksm=eb506c1cdc27e50af1df2f509c53af5b2e087aab6a44ccdd852c1314e8647bf5e4d6704e2915&amp;amp;scene=21#wechat_redirect&quot;&gt;&lt;strong&gt;索引&lt;/strong&gt;&lt;/a&gt;就可以了，由于走索引查询，就不会出现扫描全表的情况而锁表了，只会锁定符合条件的记录。&lt;/p&gt;
&lt;p&gt;关于 MySQL 索引的详细用法有实战，大家可以关注公众号Java技术栈在后台回复mysql获取系列干货文章。&lt;/p&gt;
&lt;h4 id=&quot;最终的sql&quot;&gt;最终的sql&lt;/h4&gt;
&lt;pre&gt;
&lt;code&gt;INSERT INTO order_record SELECT
    *
FROM
    order_today FORCE INDEX (idx_pay_suc_time)
WHERE
    pay_success_time &amp;lt;= '2020-03-08 00:00:00';
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;执行过程&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/1218593/202009/1218593-20200915083547170-968722366.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h3 id=&quot;总结&quot;&gt;总结&lt;/h3&gt;
&lt;p&gt;使用&lt;code&gt;insert into tablA select * from tableB&lt;/code&gt;语句时，一定要确保&lt;code&gt;tableB&lt;/code&gt;后面的&lt;code&gt;where&lt;/code&gt;，&lt;code&gt;order&lt;/code&gt;或者其他条件，都需要有对应的&lt;strong&gt;索引&lt;/strong&gt;，来避免出现&lt;code&gt;tableB&lt;/code&gt;全部记录被锁定的情况。&lt;/p&gt;
&lt;h3 id=&quot;参考文章&quot;&gt;参考文章&lt;/h3&gt;
&lt;p&gt;insert into … select 由于SELECT表引起的死锁情况分析：&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://blog.csdn.net/asdfsadfasdfsa/article/details/83030011&quot;&gt;https://blog.csdn.net/asdfsadfasdfsa/article/details/83030011&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&quot;结尾&quot;&gt;结尾&lt;/h3&gt;
&lt;p&gt;如果觉得对你有帮助，可以多多评论，多多点赞哦，谢谢。&lt;/p&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;作者：不一样的科技宅&lt;br/&gt;来源：juejin.im/post/6844904086173646862&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;近期热文推荐：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;1.&lt;a href=&quot;http://www.javastack.cn/article/2020/intellij-idea-by-open-source-project/&quot;&gt;终于靠开源项目弄到 IntelliJ IDEA 激活码了，真香！&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;2.&lt;a href=&quot;http://www.javastack.cn/article/2020/java-8-optional-map-do-you-know/&quot;&gt;我用 Java 8 写了一段逻辑，同事直呼看不懂，你试试看。。&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;3.&lt;a href=&quot;http://www.javastack.cn/article/2020/undertow-introduce-with-spring-boot/&quot;&gt;吊打 Tomcat ，Undertow 性能很炸！！&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;4.&lt;a href=&quot;http://www.javastack.cn/article/2020/another-redis-desktop-manager/&quot;&gt;国人开源了一款超好用的 Redis 客户端，真香！！&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;5.&lt;a href=&quot;http://www.javastack.cn/article/2020/alibaba-release-java-develop-rules-songshan/&quot;&gt;《Java开发手册（嵩山版）》最新发布，速速下载！&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;觉得不错，别忘了随手点赞+转发哦！&lt;/p&gt;
</description>
<pubDate>Tue, 15 Sep 2020 00:36:00 +0000</pubDate>
<dc:creator>Java技术栈</dc:creator>
<og:description>前言 Insert into select请慎用。 这天xxx接到一个需求，需要将表A的数据迁移到表B中去做一个备份。本想通过程序先查询查出来然后批量插入。但xxx觉得这样有点慢，需要耗费大量的网络I</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/javastack/p/13670978.html</dc:identifier>
</item>
<item>
<title>【小白学PyTorch】11 MobileNet详解及PyTorch实现 - 忽逢桃林</title>
<link>http://www.cnblogs.com/PythonLearner/p/13670971.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/PythonLearner/p/13670971.html</guid>
<description>&lt;p&gt;文章来自微信公众号【机器学习炼丹术】。我是炼丹兄，欢迎加我微信好友交流学习：cyx645016617。&lt;/p&gt;
&lt;p&gt;@&lt;/p&gt;

&lt;br/&gt;本来计划是想在今天讲EfficientNet PyTorch的，但是发现EfficientNet是依赖于SENet和MobileNet两个网络结构，所以本着本系列是给“小白”初学者学习的，所以这一课先讲解MobileNet，然后下一课讲解SENet，然后再下一课讲解EfficientNet，当然，每一节课都是由PyTorch实现的。
&lt;h2 id=&quot;1-背景&quot;&gt;1 背景&lt;/h2&gt;
&lt;p&gt;Mobile是移动、手机的概念，MobileNet是Google在2017年提出的轻量级深度神经网络，专门用于移动端、嵌入式这种计算力不高、要求速度、实时性的设备。&lt;/p&gt;
&lt;h2 id=&quot;2-深度可分离卷积&quot;&gt;2 深度可分离卷积&lt;/h2&gt;
&lt;p&gt;主要应用了深度可分离卷积来代替传统的卷积操作，并且放弃pooling层。把标准卷积分解成：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;深度卷积(depthwise convolution)&lt;/li&gt;
&lt;li&gt;逐点卷积(pointwise convolution)。&lt;br/&gt;这么做的好处是可以&lt;strong&gt;大幅度降低参数量和计算量。&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;h3 id=&quot;22-一般卷积计算量&quot;&gt;2.2 一般卷积计算量&lt;/h3&gt;
&lt;p&gt;我们先来回顾一下什么是一般的卷积：&lt;br/&gt;&lt;img src=&quot;https://img-service.csdnimg.cn/img_convert/a224db09f91adce058ef775d4bc7e9d2.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;br/&gt;先说一下题目：&lt;strong&gt;特征图尺寸是H（高）和W（宽），尺寸（边长）为K，M是输入特征图的通道数，N是输出特征图的通道数。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;现在简化问题，如上图所示，&lt;strong&gt;输入单通道特征图，输出特征图也是单通道的，&lt;/strong&gt; 我们知道每一个卷积结果为一个标量，从输出特征图来看，总共进行了9次卷积。每一次卷积计算了9次，因为每一次卷积都需要让卷积核上的每一个数字与原来特征图上对应的数字相乘（这里只算乘法不用考虑加法）。所以图6.18所示，总共计算了：&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;math inline&quot;&gt;\(9*9=3*3*3*3=81\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;如果&lt;strong&gt;输入特征图是一个2通道的&lt;/strong&gt; ，那么意味着卷积核也是要2通道的卷积核才行，此时输出特征图还是单通道的。这样计算量就变成：&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;math inline&quot;&gt;\(9*9*2=3*3*3*3*2=162\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;原本单通道特征图每一次卷积只用计算9次乘法，现在因为输入通道数变成2，要计算18次乘法才能得到输出中的1个数字。现在假设&lt;strong&gt;输出特征图要输出3通道的特征图。&lt;/strong&gt; 那么就要准备3个不同的卷积核，重复上述全部操作3次才能拿的到3个特征图。所以计算量就是：&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;math inline&quot;&gt;\(9*9*2*3=3*3*3*3*2*3=486\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;现在解决原来的问题：&lt;strong&gt;特征图尺寸是H（高）和W（宽），卷积核是正方形的，尺寸（边长）为K，M是输入特征图的通道数，N是输出特征图的通道数。&lt;/strong&gt; 那么这样卷积的计算量为：&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;math inline&quot;&gt;\(H*W*K*K*M*N\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;这个就是卷积的计算量的公式。&lt;/p&gt;
&lt;h3 id=&quot;22-深度可分离卷积计算量&quot;&gt;2.2 深度可分离卷积计算量&lt;/h3&gt;
&lt;ul&gt;&lt;li&gt;深度可分离卷积（Depthwise Separable Convolution，DSC）&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;假设在一次一般的卷积中，需要将一个输入特征图64×7×7，经过3×3的卷积核，变成128×7×7的输出特征图。计算一下这个过程需要多少的计算量：&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;math inline&quot;&gt;\(7*7*3*3*64*128=3612672\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;如果&lt;strong&gt;用了深度可分离卷积，就是把这个卷积变成两个步骤：&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;Depthwise：先用64×7×7经过3×3的卷积核得到一个64×7×7的特征图。注意注意！这里是64×7×7的特征图经过3×3的卷积核，不是64×3×3的卷积核！这里将64×7×7的特征图看成64张7×7的图片，然后依次与3×3的卷积核进行卷积；&lt;/li&gt;
&lt;li&gt;Pointwise：在Depthwise的操作中，不难发现，这样的计算根本无法整合不同通道的信息，因为上一步把所有通道都拆开了，所以在这一步要用64×1×1的卷积核去整合不同通道上的信息，用128个64×1×1的卷积核，产生128×7×7的特征图。&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;最后的计算量就是：&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;math inline&quot;&gt;\(7*7*3*3*64+7*7*1*1*64*128=429632\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;计算量减少了百分之80以上。&lt;/p&gt;
&lt;p&gt;分解过程示意图如下：&lt;br/&gt;&lt;img src=&quot;https://img-service.csdnimg.cn/img_convert/e6099868c3ad99e7414a28355c756b08.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;在图中可以看到：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;(a)表示一般卷积过程，&lt;/strong&gt; 卷积核都是M个通道，然后总共有N和卷积核，意味着输入特征图有M个通道，然后输出特征图有N个通道。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;(b)表示depthwise过程&lt;/strong&gt;， 总共有M个卷积核，这里是对输入特征图的M个通道分别做一个卷积，输出的特征图也是M个通道的；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;(c)表示pointwise过程&lt;/strong&gt;，总共有N个&lt;span class=&quot;math inline&quot;&gt;\(1 \times 1\)&lt;/span&gt;的卷积核，这样来整合不同通道的信息，输出特征图有N个通道数。&lt;/li&gt;
&lt;/ul&gt;&lt;h3 id=&quot;23-网络结构&quot;&gt;2.3 网络结构&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;https://img-service.csdnimg.cn/img_convert/947bb64b2c1f314722e18931fb853da3.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;br/&gt;左图表示的是一般卷积过程，卷积之后跟上BN和ReLU激活层，因为DBC将分成了两个卷积过程，所以就变成了图右这种结构，Depthwise之后加上BN和ReLU，然后Pointwise之后再加上Bn和ReLU。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img-service.csdnimg.cn/img_convert/7e4ae1fb295b0832271c1c797a2046ae.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;br/&gt;从整个网络结构可以看出来：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;除了第一层为标准的卷积层之外，其他的层都为深度可分离卷积。&lt;/li&gt;
&lt;li&gt;整个网络没有使用Pooling层。&lt;/li&gt;
&lt;/ul&gt;&lt;h2 id=&quot;3-pytorch实现&quot;&gt;3 PyTorch实现&lt;/h2&gt;
&lt;pre&gt;
&lt;code class=&quot;language-python&quot;&gt;import torch
import torch.nn as nn
import torch.nn.functional as F


class Block(nn.Module):
    '''Depthwise conv + Pointwise conv'''
    def __init__(self, in_planes, out_planes, stride=1):
        super(Block, self).__init__()
        self.conv1 = nn.Conv2d\
            (in_planes, in_planes, kernel_size=3, stride=stride, 
             padding=1, groups=in_planes, bias=False)
        self.bn1 = nn.BatchNorm2d(in_planes)
        self.conv2 = nn.Conv2d\
            (in_planes, out_planes, kernel_size=1, 
            stride=1, padding=0, bias=False)
        self.bn2 = nn.BatchNorm2d(out_planes)

    def forward(self, x):
        out = F.relu(self.bn1(self.conv1(x)))
        out = F.relu(self.bn2(self.conv2(out)))
        return out


class MobileNet(nn.Module):
    # (128,2) means conv planes=128, conv stride=2, 
    # by default conv stride=1
    cfg = [64, (128,2), 128, (256,2), 256, (512,2), 
           512, 512, 512, 512, 512, (1024,2), 1024]

    def __init__(self, num_classes=10):
        super(MobileNet, self).__init__()
        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, 
                stride=1, padding=1, bias=False)
        self.bn1 = nn.BatchNorm2d(32)
        self.layers = self._make_layers(in_planes=32)
        self.linear = nn.Linear(1024, num_classes)

    def _make_layers(self, in_planes):
        layers = []
        for x in self.cfg:
            out_planes = x if isinstance(x, int) else x[0]
            stride = 1 if isinstance(x, int) else x[1]
            layers.append(Block(in_planes, out_planes, stride))
            in_planes = out_planes
        return nn.Sequential(*layers)

    def forward(self, x):
        out = F.relu(self.bn1(self.conv1(x)))
        out = self.layers(out)
        out = F.avg_pool2d(out, 2)
        out = out.view(out.size(0), -1)
        out = self.linear(out)
        return out

net = MobileNet()
x = torch.randn(1,3,32,32)
y = net(x)
print(y.size())
&amp;gt; torch.Size([1, 10])
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;正常情况下这个预训练模型都会输出1024个线性节点，然后这里我自己加上了一个1024-&amp;gt;10的一个全连接层。&lt;/p&gt;
&lt;p&gt;我们来看一下这个网络结构：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-python&quot;&gt;print(net)
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;输出结果：&lt;br/&gt;&lt;img src=&quot;https://img-service.csdnimg.cn/img_convert/9274669a7abda4f2736e1d6098d58621.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;然后代码中：&lt;br/&gt;&lt;img src=&quot;https://img-service.csdnimg.cn/img_convert/b0893ee50483fed9056bfd52f6f00033.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;关于模型通道数的设置部分：&lt;br/&gt;&lt;img src=&quot;https://img-service.csdnimg.cn/img_convert/06b983a82183fee6f37b5589b06aa2ae.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;MobileNet就差不多完事了，下一节课为SENet的PyTorch实现和详解。&lt;/p&gt;
&lt;p&gt;文章来自微信公众号【机器学习炼丹术】。我是炼丹兄，欢迎加我微信好友交流学习：cyx645016617。&lt;/p&gt;
</description>
<pubDate>Tue, 15 Sep 2020 00:33:00 +0000</pubDate>
<dc:creator>忽逢桃林</dc:creator>
<og:description>文章来自微信公众号【机器学习炼丹术】。我是炼丹兄，欢迎加我微信好友交流学习：cyx645016617。 @ 本来计划是想在今天讲EfficientNet PyTorch的，但是发现EfficientN</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/PythonLearner/p/13670971.html</dc:identifier>
</item>
<item>
<title>有关 HashMap 面试会问的一切 - 码农田小齐</title>
<link>http://www.cnblogs.com/nycsde/p/13670936.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/nycsde/p/13670936.html</guid>
<description>&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span class=&quot;content&quot;&gt;前言&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;大家好，本篇文章是《齐姐说数据结构》系列的第三篇，更多数据结构和算法的文章已经整理在我的 Github 上了：https://github.com/xiaoqi6666/NYCSDE&lt;/p&gt;
&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;HashMap 是无论在工作还是面试中都非常常见常考的数据结构。&lt;/p&gt;
&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;比如 Leetcode 第一题 Two Sum 的某种变种的最优解就是需要用到 HashMap 的，高频考题 LRU Cache 是需要用到 LinkedHashMap 的。&lt;/p&gt;
&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;HashMap 用起来很简单，底层实现也不复杂，先来看几道常见的面试题吧。相信大家多多少少都能回答上来一点，不清楚的地方就仔细阅读本文啦～这篇文章带你深挖到 HashMap 的老祖宗，保证吊打面试官:smirk:&lt;/p&gt;
&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;
&lt;ul&gt;&lt;li&gt;
&lt;section&gt;== 和 equals() 的区别？&lt;/section&gt;&lt;/li&gt;
&lt;li&gt;
&lt;section&gt;为什么重写 equals() 就必须要重写 hashCode()？&lt;/section&gt;&lt;/li&gt;
&lt;li&gt;
&lt;section&gt;Hashtable, HashSet 和 HashMap 的区别和联系&lt;/section&gt;&lt;/li&gt;
&lt;li&gt;
&lt;section&gt;处理 hash 冲突有哪些方法？Java 中用的哪一种？为什么？另一种方法你在工作中用过吗？在什么情况下用得多？&lt;/section&gt;&lt;/li&gt;
&lt;li&gt;
&lt;section&gt;徒手实现一个 HashMap 吧&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;本文分以下章节：&lt;/p&gt;
&lt;ul data-tool=&quot;mdnice编辑器&quot;&gt;&lt;li&gt;
&lt;section&gt;Set 和 Map 家族简介&lt;/section&gt;&lt;/li&gt;
&lt;li&gt;
&lt;section&gt;HashMap 实现原理&lt;/section&gt;&lt;/li&gt;
&lt;li&gt;
&lt;section&gt;哈希冲突详解&lt;/section&gt;&lt;/li&gt;
&lt;li&gt;
&lt;section&gt;HashMap 基本操作&lt;/section&gt;&lt;/li&gt;
&lt;li&gt;
&lt;section&gt;习题 Two Sum&lt;/section&gt;&lt;/li&gt;
&lt;li&gt;
&lt;section&gt;习题 LRU&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span class=&quot;content&quot;&gt;Set 家族&lt;/span&gt;&lt;/h2&gt;
&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在讲 Map 之前，我们先来看看 Set。&lt;/p&gt;
&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;集合的概念我们初中数学就学过了，就是里面不能有重复元素，这里也是一样。&lt;/p&gt;
&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Set 在 Java 中是一个接口，可以看到它是 java.util 包中的一个集合框架类，具体的实现类有很多：&lt;/p&gt;
&lt;img src=&quot;https://tva1.sinaimg.cn/large/007S8ZIlgy1giqpz9036wj314u0gemzf.jpg&quot; alt=&quot;&quot;/&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;其中比较常用的有三种：&lt;/p&gt;
&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;HashSet&lt;/strong&gt;: 采用 Hashmap 的 key 来储存元素，主要特点是无序的，基本操作都是 O(1) 的时间复杂度，很快。&lt;/p&gt;
&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;LinkedHashSet&lt;/strong&gt;: 这个是一个 HashSet + LinkedList 的结构，特点就是既拥有了 O(1) 的时间复杂度，又能够保留插入的顺序。&lt;/p&gt;
&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;TreeSet&lt;/strong&gt;: 采用红黑树结构，特点是可以有序，可以用自然排序或者自定义比较器来排序；缺点就是查询速度没有 HashSet 快。&lt;/p&gt;
&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span class=&quot;content&quot;&gt;Map 家族&lt;/span&gt;&lt;/h2&gt;
&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Map 是一个键值对 (Key - Value pairs)，其中 key 是不可以重复的，毕竟 set 中的 key 要存在这里面。&lt;/p&gt;
&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;那么与 Set 相对应的，Map 也有这三个实现类：&lt;/p&gt;
&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;HashMap&lt;/strong&gt;: 与 HashSet 对应，也是无序的，O(1)。&lt;/p&gt;
&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;LinkedHashMap&lt;/strong&gt;: 这是一个「HashMap + 双向链表」的结构，落脚点是 HashMap，所以既拥有 HashMap 的所有特性还能有顺序。&lt;/p&gt;
&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;TreeMap&lt;/strong&gt;: 是有序的，本质是用二叉搜索树来实现的。&lt;/p&gt;
&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span class=&quot;content&quot;&gt;HashMap 实现原理&lt;/span&gt;&lt;/h2&gt;
&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;对于 HashMap 中的每个 key，首先通过 hash function 计算出一个 hash 值，这个hash值就代表了在 buckets 里的编号，而 buckets 实际上是用数组来实现的，所以把这个数值模上数组的长度得到它在数组的 index，就这样把它放在了数组里。&lt;/p&gt;
&lt;img src=&quot;https://tva1.sinaimg.cn/large/007S8ZIlgy1giqq1ge5qfj30hi0cswet.jpg&quot; alt=&quot;&quot;/&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;那么这里有几个问题：&lt;/p&gt;
&lt;blockquote data-tool=&quot;mdnice编辑器&quot; readability=&quot;5&quot;&gt;
&lt;p&gt;如果不同的元素算出了相同的哈希值，那么该怎么存放呢？&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;答：这就是&lt;strong&gt;哈希碰撞&lt;/strong&gt;，即多个 key 对应了同一个桶。&lt;/p&gt;
&lt;blockquote data-tool=&quot;mdnice编辑器&quot; readability=&quot;6&quot;&gt;
&lt;p&gt;HashMap 中是如何保证元素的唯一性的呢？即相同的元素会不会算出不同的哈希值呢？&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;答：通过 &lt;strong&gt;hashCode()&lt;/strong&gt; 和 &lt;strong&gt;equals()&lt;/strong&gt; 方法来保证元素的唯一性。&lt;/p&gt;
&lt;blockquote data-tool=&quot;mdnice编辑器&quot; readability=&quot;5&quot;&gt;
&lt;p&gt;如果 pairs 太多，buckets 太少怎么破？&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;答：&lt;strong&gt;Rehasing&lt;/strong&gt;. 也就是碰撞太多的时候，会把数组扩容至两倍（默认）。所以这样虽然 hash 值没有变，但是因为数组的长度变了，所以算出来的 index 就变了，就会被分配到不同的位置上了，就不用挤在一起了，小伙伴们我们江湖再见～&lt;/p&gt;
&lt;blockquote data-tool=&quot;mdnice编辑器&quot; readability=&quot;6&quot;&gt;
&lt;p&gt;那什么时候会 rehashing 呢？也就是怎么衡量桶里是不是足够&lt;strong&gt;拥挤&lt;/strong&gt;要扩容了呢？&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;答：&lt;strong&gt;load factor&lt;/strong&gt;. 即用 pair 的数量除以 buckets 的数量，也就是&lt;strong&gt;平均每个桶里装几对&lt;/strong&gt;。Java 中默认值是 &lt;strong&gt;0.75f&lt;/strong&gt;，如果超过了这个值就会 &lt;strong&gt;rehashing&lt;/strong&gt;.&lt;/p&gt;
&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span class=&quot;content&quot;&gt;关于 hashCode() 和 equals()&lt;/span&gt;&lt;/h3&gt;
&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果 key 的 hashCode() 值相同，那么有可能是要发生 hash collision 了，也有可能是真的遇到了另一个自己。那么如何判断呢？继续用 equals() 来比较。&lt;/p&gt;
&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;也就是说，&lt;/p&gt;
&lt;blockquote data-tool=&quot;mdnice编辑器&quot; readability=&quot;5&quot;&gt;
&lt;p&gt;hashCode() 决定了 key 放在这个桶里的编号，也就是在数组里的 index；&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote data-tool=&quot;mdnice编辑器&quot; readability=&quot;5&quot;&gt;
&lt;p&gt;equals() 是用来比较两个 object 是否相同的。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;那么该如何回答这道&lt;span&gt;经典面试题&lt;/span&gt;：&lt;/p&gt;
&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;为什么重写 equals() 方法，一定要重写 hashCode() 呢？&lt;/span&gt;&lt;/p&gt;
&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;答：首先我们有一个假设：任何两个 object 的 hashCode 都是不同的。&lt;/p&gt;
&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;那么在这个条件下，有两个 object 是相等的，那如果不重写 hashCode()，算出来的哈希值都不一样，就会去到不同的 buckets 了，就迷失在茫茫人海中了，再也无法相认，就和 equals() 条件矛盾了，证毕。&lt;/p&gt;
&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;撒花～～🎉🎉🎉&lt;/p&gt;
&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;接下来我们再对这两个方法一探究竟：&lt;/p&gt;
&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;其实 hashCode() 和 equals() 方法都是在 Object class 这个老祖宗里定义的，Object 是所有 Java 中的 class 的鼻祖，默认都是有的，甩不掉的。&lt;/p&gt;
&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;那既然是白给的，我们先来看看大礼包里有什么，谷歌 Object 的 Oracle 文档：&lt;/p&gt;
&lt;img src=&quot;https://tva1.sinaimg.cn/large/007S8ZIlgy1giqq1tg1pfj31s60tc10j.jpg&quot; alt=&quot;&quot;/&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;所以这些方法都是可以直接拿来用的呢～&lt;/p&gt;
&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;回到 hashCode() 和 equals()，那么如果这个新的 class 里没有重写 (override) 这两个方法，就是默认继承 Object class 里的定义了。&lt;/p&gt;
&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;那我们点进去来看看 equals() 是怎么定义的：&lt;/p&gt;
&lt;img src=&quot;https://tva1.sinaimg.cn/large/007S8ZIlgy1giqq27js14j32i20nkzs4.jpg&quot; alt=&quot;&quot;/&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;记笔记：&lt;/p&gt;
&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;equals()&lt;/code&gt; 方法就是比较这两个 references 是否指向了同一个 object.&lt;/p&gt;
&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;嗯？？？你在逗我吗？？那岂不是和 &lt;code&gt;==&lt;/code&gt; 一样了？？&lt;/p&gt;
&lt;blockquote data-tool=&quot;mdnice编辑器&quot; readability=&quot;7&quot;&gt;
&lt;p&gt;补充：&lt;br/&gt;我们常用的比较大小的符号之 &lt;code&gt;==&lt;/code&gt;&lt;br/&gt;如果是 primitive type，那么 == 就是比较数值的大小；&lt;br/&gt;如果是 reference type，那么就比较的是这两个 reference 是否指向了同一个 object。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote data-tool=&quot;mdnice编辑器&quot; readability=&quot;14&quot;&gt;
&lt;p&gt;再补充：&lt;br/&gt;Java 的数据类型可以分为两种：&lt;br/&gt;Primitive type 有且仅有8种：byte, short, int, long, float, double, char, boolean.&lt;br/&gt;其他都是 Reference type.&lt;br/&gt;所以虽然 Java 声称 “Everything is object”，但是还是有非 object 数据类型的存在的。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我不信，我要去源码里看看它是怎么实现的。&lt;/p&gt;
&lt;img src=&quot;https://tva1.sinaimg.cn/large/007S8ZIlgy1giqq2j26rqj30fr0orq6c.jpg&quot; alt=&quot;&quot;/&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;​&lt;/p&gt;
&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;哈，还真是的，绕了这么半天，&lt;code&gt;equals()&lt;/code&gt; 就是用 &lt;code&gt;==&lt;/code&gt; 来实现的！&lt;/p&gt;
&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;那为什么还弄出来这么个方法呢？&lt;/p&gt;
&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;答：为了让你 override～&lt;/span&gt;&lt;/p&gt;
&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;比如一般来说我们比较字符串就是想比较这两个字符串的内容的，那么：&lt;/p&gt;
&lt;pre class=&quot;custom&quot; data-tool=&quot;mdnice编辑器&quot; readability=&quot;4&quot;&gt;
&lt;code class=&quot;hljs&quot; readability=&quot;2&quot;&gt;str1 = “tianxiaoqi”;&lt;br/&gt;str2 =  &lt;span class=&quot;hljs-keyword&quot;&gt;new&lt;/span&gt; String(“tianxiaoqi”);&lt;p&gt;str1 == str2; &lt;br/&gt;str1.equals(str2); &lt;br/&gt;&lt;/p&gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;因为 String 里是重写了 equals() 方法的：&lt;/p&gt;
&lt;img src=&quot;https://tva1.sinaimg.cn/large/007S8ZIlgy1giqq37zor0j30gk0ilabv.jpg&quot; alt=&quot;&quot;/&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;老祖宗留给你就是让你自己用的，如果你不用，那人家也提供了默认的方法，也是够意思了。&lt;/p&gt;
&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;好了，我们再去看 hashCode() 的介绍：&lt;/p&gt;
&lt;img src=&quot;https://tva1.sinaimg.cn/large/007S8ZIlgy1giqq3ostfoj32i40k245r.jpg&quot; alt=&quot;&quot;/&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;那至于 hashCode() 返回的究竟是什么，和本文关联不太大，有兴趣的同学可以看参考，结论就是：&lt;/p&gt;
&lt;blockquote data-tool=&quot;mdnice编辑器&quot; readability=&quot;6&quot;&gt;
&lt;p&gt;返回的并不一定是对象的（虚拟）内存地址，具体取决于运行时库和JVM的具体实现。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;但无论是怎么实现的，都需要遵循文档上的约定，也就是对不同的 object 会返回&lt;strong&gt;唯一的哈希值&lt;/strong&gt;。&lt;/p&gt;
&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span class=&quot;content&quot;&gt;哈希冲突详解&lt;/span&gt;&lt;/h3&gt;
&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;一般来说哈希冲突有两大类&lt;/p&gt;
&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;
&lt;ol&gt;&lt;li&gt;
&lt;section&gt;Separate chaining&lt;/section&gt;&lt;/li&gt;
&lt;li&gt;
&lt;section&gt;Open addressing&lt;/section&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/blockquote&gt;
&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Java 中采用的是第一种 &lt;code&gt;Separate chaining&lt;/code&gt;，即在发生碰撞的那个桶后面再加一条“链”来存储，那么这个“链”使用的具体是什么数据结构，不同的版本稍有不同：&lt;/p&gt;
&lt;blockquote data-tool=&quot;mdnice编辑器&quot; readability=&quot;6&quot;&gt;
&lt;p&gt;在 JDK1.6 和 1.7 中，是用&lt;strong&gt;链表&lt;/strong&gt;存储的，这样如果碰撞很多的话，就变成了在链表上的查找，worst case 就是 O(n)；&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote data-tool=&quot;mdnice编辑器&quot; readability=&quot;6&quot;&gt;
&lt;p&gt;在 JDK 1.8 进行了优化，当链表长度较大时（超过 8），会采用&lt;strong&gt;红黑树&lt;/strong&gt;来存储，这样大大提高了查找效率。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;（话说，这个还真的喜欢考，已经在多次面试中被问过了，还有面试官问为什么是超过“8”才用红黑树🤔）&lt;/p&gt;
&lt;img src=&quot;https://tva1.sinaimg.cn/large/007S8ZIlgy1giqq4abk69j30rs0dwaaz.jpg&quot; alt=&quot;&quot;/&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;第二种方法 &lt;code&gt;open addressing&lt;/code&gt; 也是非常重要的思想，因为在真实的分布式系统里，有很多地方会用到 hash 的思想但又不适合用 &lt;code&gt;seprate chaining&lt;/code&gt;。&lt;/p&gt;
&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这种方法是顺序查找，如果这个桶里已经被占了，那就按照“&lt;strong&gt;某种方式&lt;/strong&gt;”继续找下一个没有被占的桶，直到找到第一个的。&lt;/p&gt;
&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img src=&quot;https://tva1.sinaimg.cn/large/007S8ZIlgy1giqq4rnqohj30l40ict9w.jpg&quot; alt=&quot;&quot;/&gt;空的&lt;/p&gt;
&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如图所示，John Smith 和 Sandra Dee 发生了哈希冲突，都被计算到 152 号桶，于是 Sandra 就去了下一个空位 - 153 号桶，当然也会对之后的 key 发生影响：Ted Baker 计算结果本应是放在 153 号的，但鉴于已经被 Sandra 占了，就只能再去下一个空位了，所以到了 154 号。&lt;/p&gt;
&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这种方式叫做 &lt;code&gt;Linear probing&lt;/code&gt; 线性探查，就像上图所示，一个个的顺着找下一个空位。当然还有其他的方式，比如去找平方数，或者 Double hashing.&lt;/p&gt;
&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span class=&quot;content&quot;&gt;HashMap 基本操作&lt;/span&gt;&lt;/h2&gt;
&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;每种数据结构的基本操作都无外乎&lt;span&gt;增删改查&lt;/span&gt;这四种，具体到 HashMap 来说，&lt;/p&gt;
&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;
&lt;ul&gt;&lt;li&gt;
&lt;section&gt;增：put(K key, V value)&lt;/section&gt;&lt;/li&gt;
&lt;li&gt;
&lt;section&gt;删：remove(Object key)&lt;/section&gt;&lt;/li&gt;
&lt;li&gt;
&lt;section&gt;改：还是用的 put(K key, V value)&lt;/section&gt;&lt;/li&gt;
&lt;li&gt;
&lt;section&gt;查：get(Object key) / containsKey(Object key)&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;细心的同学可能发现了，为什么有些 key 的类型是 Object，有些是 K 呢？这还不是因为 equals()...&lt;/p&gt;
&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这是因为，在 get/remove 的时候，不一定是用的同一个 object。&lt;/p&gt;
&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;还记得那个 str1 和 str2 都是田小齐的例子吗？那比如我先 put(str1, value)，然后用 get(str2) 的时候，也是想要到 tianxiaoqi 对应的 value 呀！不能因为我换了身衣服就不认得我了呀！所以在 get/remove 的时候并没有很限制 key 的类型，方便另一个自己相认。&lt;/p&gt;
&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;其实这些 API 的操作流程大同小异，我们以最复杂的 put(K key, V value) 来讲：&lt;/p&gt;
&lt;ol data-tool=&quot;mdnice编辑器&quot;&gt;&lt;li&gt;
&lt;section&gt;首先要拿到 array 中要放的位置的 index&lt;/section&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot;&gt;&lt;li&gt;
&lt;section&gt;怎么找 index 呢，这里我们可以单独用 getIndex() method 来做这件事；&lt;/section&gt;&lt;/li&gt;
&lt;li&gt;
&lt;section&gt;具体怎么做，就是通过 hash function 算出来的值，模上数组的长度；&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;ol start=&quot;2&quot; data-tool=&quot;mdnice编辑器&quot;&gt;&lt;li&gt;
&lt;section&gt;那拿到了这个位置的 Node，我们开始 traverse 这个 LinkedList，这就是在链表上的操作了，&lt;/section&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot;&gt;&lt;li&gt;
&lt;section&gt;如果找的到，就更新一下 value；&lt;/section&gt;&lt;/li&gt;
&lt;li&gt;
&lt;section&gt;如果没找到，就把它放在链表上，可以放头上，也可以放尾上，一般我喜欢放头上，因为新加入的元素用到的概率总是大一些，但并不影响时间复杂度。&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;代码如下：&lt;/p&gt;
&lt;pre class=&quot;custom&quot; data-tool=&quot;mdnice编辑器&quot;&gt;
&lt;code class=&quot;hljs&quot;&gt;  &lt;span class=&quot;hljs-function&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;public&lt;/span&gt; V &lt;span class=&quot;hljs-title&quot;&gt;put&lt;/span&gt;&lt;span class=&quot;hljs-params&quot;&gt;(K key, V value)&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;int&lt;/span&gt; index = getIndex(key);&lt;br/&gt;Node&amp;lt;K, V&amp;gt; node = array[index];&lt;br/&gt;Node&amp;lt;K, V&amp;gt; head = node; &lt;br/&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;while&lt;/span&gt; (node != &lt;span class=&quot;hljs-keyword&quot;&gt;null&lt;/span&gt;) {&lt;br/&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;if&lt;/span&gt; (checkEquals(key, node)) {&lt;br/&gt;V preValue = node.value;&lt;br/&gt;node.value = value;&lt;br/&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;return&lt;/span&gt; preValue;&lt;br/&gt;}&lt;br/&gt;node = node.next;&lt;br/&gt;}&lt;br/&gt;Node&amp;lt;K, V&amp;gt; newNode = &lt;span class=&quot;hljs-keyword&quot;&gt;new&lt;/span&gt; Node(key, value); &lt;br/&gt;newNode.next = head;&lt;br/&gt;array[index] = newNode;&lt;br/&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;hljs-keyword&quot;&gt;null&lt;/span&gt;;&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;至于更多的细节比如加一些 rehashing 啊，load factor 啊，大家可以参考源码。&lt;/p&gt;
&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;读完源码大家可以做做 Leetcode 706 题练手，so easy~&lt;/p&gt;
&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span class=&quot;content&quot;&gt;与 Hashtable 的区别&lt;/span&gt;&lt;/h3&gt;
&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这是一个年龄暴露贴，HashMap 与 Hashtable 的关系，就像 ArrayList 与 Vector，以及 StringBuilder 与 StringBuffer。&lt;/p&gt;
&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Hashtable 是早期 JDK 提供的接口，HashMap 是新版的； 它们之间最显著的区别，就是 Hashtable 是线程安全的，HashMap 并非线程安全。&lt;/p&gt;
&lt;blockquote data-tool=&quot;mdnice编辑器&quot; readability=&quot;7&quot;&gt;
&lt;p&gt;这是因为 Java 5.0 之后允许数据结构不考虑线程安全的问题，因为实际工作中我们发现没有必要在数据结构的层面上上锁，加锁和放锁在系统中是有开销的，内部锁有时候会成为程序的瓶颈。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;所以 HashMap, ArrayList, StringBuilder 不再考虑线程安全的问题，性能提升了很多，当然，线程安全问题也就转移给我们程序员了。&lt;/p&gt;
&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;另外一个区别就是：HashMap 允许 key 中有 null 值，Hashtable 是不允许的。这样的好处就是可以给一个默认值。&lt;/p&gt;
&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在算法面试中，有关 HashMap 的算法题也很常见，比如有名的 Top K 问题，还有 LRU Cache 问题，这两道题都是非常高频的考题，之后也会讲到，还请大家继续关注我吧！&lt;/p&gt;
&lt;hr data-tool=&quot;mdnice编辑器&quot;/&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果你喜欢这篇文章，记得给我点赞留言哦～你们的支持和认可，就是我创作的最大动力，我们下篇文章见！&lt;/p&gt;
&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;我是小齐，纽约程序媛，终生学习者，每天晚上 9 点，云自习室里不见不散！&lt;/strong&gt;&lt;/p&gt;
&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;更多干货文章见我的 Github: https://github.com/xiaoqi6666/NYCSDE&lt;/strong&gt;&lt;/p&gt;

</description>
<pubDate>Mon, 14 Sep 2020 23:40:00 +0000</pubDate>
<dc:creator>码农田小齐</dc:creator>
<og:description>前言 大家好，本篇文章是《齐姐说数据结构》系列的第三篇，更多数据结构和算法的文章已经整理在我的 Github 上了：https://github.com/xiaoqi6666/NYCSDE HashM</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/nycsde/p/13670936.html</dc:identifier>
</item>
<item>
<title>golang开发:CSP-WaitGroup Mutex - 飞翔码农</title>
<link>http://www.cnblogs.com/feixiangmanon/p/13670927.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/feixiangmanon/p/13670927.html</guid>
<description>&lt;blockquote readability=&quot;7&quot;&gt;
&lt;p&gt;CSP 是 Communicating Sequential Process 的简称，中文可以叫做通信顺序进程，是一种并发编程模型，最初于Tony Hoare的1977年的论文中被描述，影响了许多编程语言的设计。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&quot;golang-csp模型&quot;&gt;golang CSP模型&lt;/h3&gt;
&lt;p&gt;golang语言并没有完全实现了CSP模型的所有理论，仅仅是借用了 process和channel这两个概念。process是在golang语言上的表现就是 goroutine, 是实际并发执行的实体，每个实体之间是通过channel通讯来实现数据共享。&lt;br/&gt;最经典的数据通信共享理论&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;以通信的方式来共享内存&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;Do not communicate by sharing memory; instead, share memory by communicating
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;不要以共享内存的方式来通信，相反，要通过通信来共享内存。&lt;/strong&gt;&lt;br/&gt;这是golang实现高并发的基础通信理论。&lt;br/&gt;在golang语言上面，就是通过channel实现多个goroutine的数据通信。&lt;/p&gt;
&lt;h3 id=&quot;syncwaitgroup使用&quot;&gt;sync.WaitGroup使用&lt;/h3&gt;
&lt;p&gt;如果需要让多个goroutine都执行完成，就是用使用time.sleep，延迟几秒保证每个goroutine都能执行到。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;func testPrint(i int) {
        fmt.Println(i)
}
func main() {
        for i:=0;i&amp;lt;5;i++ {
                go testPrint(i)
        }
        time.Sleep(time.Second)
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;但是在生产项目里面就没法这么写了，延迟1S有可能所有goroutine没执行完成，延迟1000S可能1毫秒就执行完了，其他999S都是等待，延长了程序执行时间。&lt;br/&gt;所以就有sync.WaitGroup&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;func testPrint(wg *sync.WaitGroup, i int) {
        fmt.Println(i)
        wg.Done()
}
func main() {
        var wg = new(sync.WaitGroup)
        for i:=0;i&amp;lt;5;i++ {
                wg.Add(1)
                go testPrint(wg,i)
        }
        wg.Wait()
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;WaitGroup比较容易理解，其实就是一个内部计数器，在执行goroutine行为之前执行 wg.Add(1)，给计数器+1，执行完之后，执行wg.Done()，表示这个goroutine执行完成，计数器内部-1，wg.Wait()会阻塞代码的运行，等待所有的添加进WaitGroup的goroutine全部执行完毕(计数器减为0)，再退出程序。&lt;br/&gt;非常完美的解决了等待所有goroutine执行完毕的需要。&lt;/p&gt;
&lt;h3 id=&quot;syncmutex&quot;&gt;sync.Mutex&lt;/h3&gt;
&lt;p&gt;sync.Mutex，互斥锁排它锁。&lt;br/&gt;我们需要维护一个变量，保证每个goroutine都能成功的修改它，如果没有互斥锁可能就是下面的代码&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;func testPrint(wg *sync.WaitGroup, i int) {
        count++
        fmt.Println(i)
        wg.Done()
}
var count int
func main() {
        count = 0
        var wg = new(sync.WaitGroup)
        for i:=0;i&amp;lt;500;i++ {
                wg.Add(1)
                go testPrint(wg,i)
        }
        wg.Wait()
        fmt.Printf(&quot;count:%d&quot;,count)
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;预期应该是特定的值，500，其实经常性的不是500.就是因为多个goroutine同时去修改count值了，加上互斥锁试一下。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;func testPrint(wg *sync.WaitGroup, i int) {
        defer func() {
                mu.Unlock()
        }()
        mu.Lock()
        count++
        fmt.Println(i)
        wg.Done()
}
var count int
var mu *sync.Mutex
func main() {
        count = 0
        mu = new(sync.Mutex)
        var wg = new(sync.WaitGroup)
        for i:=0;i&amp;lt;500;i++ {
                wg.Add(1)
                go testPrint(wg,i)
        }
        wg.Wait()
        fmt.Printf(&quot;count:%d&quot;,count)
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;结果是定值500，跟预想的一致。&lt;/p&gt;
</description>
<pubDate>Mon, 14 Sep 2020 23:23:00 +0000</pubDate>
<dc:creator>飞翔码农</dc:creator>
<og:description>CSP 是 Communicating Sequential Process 的简称，中文可以叫做通信顺序进程，是一种并发编程模型，最初于Tony Hoare的1977年的论文中被描述，影响了许多编程</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/feixiangmanon/p/13670927.html</dc:identifier>
</item>
<item>
<title>Spring Batch远程分区的本地Jar包模式 - 南瓜慢说</title>
<link>http://www.cnblogs.com/larrydpk/p/13670453.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/larrydpk/p/13670453.html</guid>
<description>&lt;blockquote readability=&quot;2.9545454545455&quot;&gt;
&lt;p&gt;欢迎访问&lt;a href=&quot;https://www.pkslow.com/&quot;&gt;南瓜慢说 www.pkslow.com&lt;/a&gt;获取更多精彩文章！&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;code&gt;Spring相关文章：&lt;/code&gt;&lt;a href=&quot;https://www.pkslow.com/categories/springboot&quot;&gt;Springboot-Cloud&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Spring Batch&lt;/code&gt;远程分区对于大量数据的处理非常擅长，它的实现有多种方式，如&lt;code&gt;本地Jar包模式&lt;/code&gt;、&lt;code&gt;MQ模式&lt;/code&gt;、&lt;code&gt;Kubernetes模式&lt;/code&gt;。这三种模式的如下：&lt;/p&gt;
&lt;p&gt;（1）&lt;code&gt;本地Jar包模式&lt;/code&gt;：分区处理的&lt;code&gt;worker&lt;/code&gt;为一个&lt;code&gt;Java进程&lt;/code&gt;，从&lt;code&gt;jar&lt;/code&gt;包启动，通过&lt;code&gt;jvm&lt;/code&gt;参数和数据库传递参数；官方提供示例代码。&lt;/p&gt;
&lt;p&gt;（2）&lt;code&gt;MQ模式&lt;/code&gt;：&lt;code&gt;worker&lt;/code&gt;是一个常驻进程，&lt;code&gt;Manager&lt;/code&gt;和&lt;code&gt;Worker&lt;/code&gt;通过消息队列来传递参数；网上有不少相关示例代码。&lt;/p&gt;
&lt;p&gt;（3）&lt;code&gt;Kubernetes模式&lt;/code&gt;：&lt;code&gt;worker&lt;/code&gt;为&lt;code&gt;K8s&lt;/code&gt;中的&lt;code&gt;Pod&lt;/code&gt;，&lt;code&gt;Manager&lt;/code&gt;直接启动&lt;code&gt;Pod&lt;/code&gt;来处理；网上并没有找到任何示例代码。&lt;/p&gt;
&lt;p&gt;本文将通过代码来讲解第一种模式（&lt;code&gt;本地Jar包模式&lt;/code&gt;），其它后续再介绍。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/946674/202009/946674-20200915005855106-1877776910.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;建议先看下面文章了解一下：&lt;/p&gt;
&lt;p&gt;Spring Batch入门：&lt;a href=&quot;https://www.pkslow.com/archives/spring-batch-introduction&quot;&gt;通过例子讲解Spring Batch入门，优秀的批处理框架&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Spring Batch并行处理介绍：&lt;a href=&quot;https://www.pkslow.com/archives/spring-batch-scaling&quot;&gt;大量数据也不在话下，Spring Batch并行处理四种模式初探&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;本文代码中，&lt;code&gt;Manager&lt;/code&gt;和&lt;code&gt;Worker&lt;/code&gt;是放在一起的，在同一个项目里，也只会打一个&lt;code&gt;jar&lt;/code&gt;包而已；我们通过&lt;code&gt;profile&lt;/code&gt;来区别是&lt;code&gt;manager&lt;/code&gt;还是&lt;code&gt;worker&lt;/code&gt;，也就是通过&lt;code&gt;Spring Profile&lt;/code&gt;实现一份代码，两份逻辑。实际上也可以拆成两份代码，但放一起更方便测试，而且代码量不大，就没有必要了。&lt;/p&gt;
&lt;h2 id=&quot;21-项目准备&quot;&gt;2.1 项目准备&lt;/h2&gt;
&lt;h3 id=&quot;211-数据库&quot;&gt;2.1.1 数据库&lt;/h3&gt;
&lt;p&gt;首先我们需要准备一个数据库，因为&lt;code&gt;Manager&lt;/code&gt;和&lt;code&gt;Worker&lt;/code&gt;都需要同步状态到&lt;code&gt;DB&lt;/code&gt;上，不能直接使用嵌入式的内存数据库了，需要一个外部可共同访问的数据库。这里我使用的是&lt;code&gt;H2 Database&lt;/code&gt;，安装可参考：&lt;a href=&quot;https://www.pkslow.com/archives/kubernetes-h2-database&quot;&gt;把H2数据库从jar包部署到Kubernetes，并解决Ingress不支持TCP的问题&lt;/a&gt;。&lt;/p&gt;
&lt;h3 id=&quot;212-引入依赖&quot;&gt;2.1.2 引入依赖&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;maven&lt;/code&gt;引入依赖如下所示：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-xml&quot;&gt;&amp;lt;dependency&amp;gt;
  &amp;lt;groupId&amp;gt;org.springframework.boot&amp;lt;/groupId&amp;gt;
  &amp;lt;artifactId&amp;gt;spring-boot-starter-batch&amp;lt;/artifactId&amp;gt;
&amp;lt;/dependency&amp;gt;
&amp;lt;dependency&amp;gt;
  &amp;lt;groupId&amp;gt;org.springframework.cloud&amp;lt;/groupId&amp;gt;
  &amp;lt;artifactId&amp;gt;spring-cloud-starter-task&amp;lt;/artifactId&amp;gt;
&amp;lt;/dependency&amp;gt;
&amp;lt;dependency&amp;gt;
  &amp;lt;groupId&amp;gt;com.h2database&amp;lt;/groupId&amp;gt;
  &amp;lt;artifactId&amp;gt;h2&amp;lt;/artifactId&amp;gt;
  &amp;lt;scope&amp;gt;runtime&amp;lt;/scope&amp;gt;
&amp;lt;/dependency&amp;gt;

&amp;lt;dependency&amp;gt;
  &amp;lt;groupId&amp;gt;org.springframework.cloud&amp;lt;/groupId&amp;gt;
  &amp;lt;artifactId&amp;gt;spring-cloud-deployer-local&amp;lt;/artifactId&amp;gt;
  &amp;lt;version&amp;gt;2.4.1&amp;lt;/version&amp;gt;
&amp;lt;/dependency&amp;gt;

&amp;lt;dependency&amp;gt;
  &amp;lt;groupId&amp;gt;org.springframework.batch&amp;lt;/groupId&amp;gt;
  &amp;lt;artifactId&amp;gt;spring-batch-integration&amp;lt;/artifactId&amp;gt;
&amp;lt;/dependency&amp;gt;
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;spring-cloud-deployer-local&lt;/code&gt;用于部署和启动&lt;code&gt;worker&lt;/code&gt;，非常关键；其它就是&lt;code&gt;Spring Batch&lt;/code&gt;和&lt;code&gt;Task&lt;/code&gt;相关的依赖；以及数据库连接。&lt;/p&gt;
&lt;h3 id=&quot;213-主类入口&quot;&gt;2.1.3 主类入口&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;Springboot&lt;/code&gt;的主类入口如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;@EnableTask
@SpringBootApplication
@EnableBatchProcessing
public class PkslowRemotePartitionJar {
    public static void main(String[] args) {
        SpringApplication.run(PkslowRemotePartitionJar.class, args);
    }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;在&lt;code&gt;Springboot&lt;/code&gt;的基础上，添加了&lt;code&gt;Spring Batch&lt;/code&gt;和&lt;code&gt;Spring Cloud Task&lt;/code&gt;的支持。&lt;/p&gt;
&lt;h2 id=&quot;22-关键代码编写&quot;&gt;2.2 关键代码编写&lt;/h2&gt;
&lt;p&gt;前面的数据库搭建和其它代码没有太多可讲的，接下来就开始关键代码的编写。&lt;/p&gt;
&lt;h3 id=&quot;221-分区管理partitioner&quot;&gt;2.2.1 分区管理Partitioner&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;Partitioner&lt;/code&gt;是远程分区中的核心&lt;code&gt;bean&lt;/code&gt;，它定义了分成多少个区、怎么分区，要把什么变量传递给&lt;code&gt;worker&lt;/code&gt;。它会返回一组&amp;lt;分区名，执行上下文&amp;gt;的键值对，即返回&lt;code&gt;Map&amp;lt;String, ExecutionContext&amp;gt;&lt;/code&gt;。把要传递给&lt;code&gt;worker&lt;/code&gt;的变量放在&lt;code&gt;ExecutionContext&lt;/code&gt;中去，支持多种类型的变量，如&lt;code&gt;String&lt;/code&gt;、&lt;code&gt;int&lt;/code&gt;、&lt;code&gt;long&lt;/code&gt;等。实际上，我们不建议通过&lt;code&gt;ExecutionContext&lt;/code&gt;来传递太多数据；可以传递一些标识或主键，然后&lt;code&gt;worker&lt;/code&gt;自己去拿数据即可。&lt;/p&gt;
&lt;p&gt;具体代码如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;private static final int GRID_SIZE = 4;
@Bean
public Partitioner partitioner() {
  return new Partitioner() {
    @Override
    public Map&amp;lt;String, ExecutionContext&amp;gt; partition(int gridSize) {

      Map&amp;lt;String, ExecutionContext&amp;gt; partitions = new HashMap&amp;lt;&amp;gt;(gridSize);

      for (int i = 0; i &amp;lt; GRID_SIZE; i++) {
        ExecutionContext executionContext = new ExecutionContext();
        executionContext.put(&quot;partitionNumber&quot;, i);
        partitions.put(&quot;partition&quot; + i, executionContext);
      }

      return partitions;
    }
  };
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;上面分成4个区，程序会启动4个&lt;code&gt;worker&lt;/code&gt;来处理；给&lt;code&gt;worker&lt;/code&gt;传递的参数是&lt;code&gt;partitionNumber&lt;/code&gt;。&lt;/p&gt;
&lt;h3 id=&quot;222-分区处理器partitionhandler&quot;&gt;2.2.2 分区处理器PartitionHandler&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;PartitionHandler&lt;/code&gt;也是核心的&lt;code&gt;bean&lt;/code&gt;，它决定了怎么去启动&lt;code&gt;worker&lt;/code&gt;，给它们传递什么&lt;code&gt;jvm&lt;/code&gt;参数（跟之前的&lt;code&gt;ExecutionContext&lt;/code&gt;传递不一样）。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;@Bean
public PartitionHandler partitionHandler(TaskLauncher taskLauncher, JobExplorer jobExplorer, TaskRepository taskRepository) throws Exception {

  Resource resource = this.resourceLoader.getResource(workerResource);

  DeployerPartitionHandler partitionHandler =
    new DeployerPartitionHandler(taskLauncher, jobExplorer, resource, &quot;workerStep&quot;, taskRepository);

  List&amp;lt;String&amp;gt; commandLineArgs = new ArrayList&amp;lt;&amp;gt;(3);
  commandLineArgs.add(&quot;--spring.profiles.active=worker&quot;);
  commandLineArgs.add(&quot;--spring.cloud.task.initialize-enabled=false&quot;);
  commandLineArgs.add(&quot;--spring.batch.initializer.enabled=false&quot;);

  partitionHandler
    .setCommandLineArgsProvider(new PassThroughCommandLineArgsProvider(commandLineArgs));
  partitionHandler
    .setEnvironmentVariablesProvider(new SimpleEnvironmentVariablesProvider(this.environment));
  partitionHandler.setMaxWorkers(2);
  partitionHandler.setApplicationName(&quot;PkslowWorkerJob&quot;);

  return partitionHandler;
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;上面代码中：&lt;/p&gt;
&lt;p&gt;&lt;code&gt;resource&lt;/code&gt;是&lt;code&gt;worker&lt;/code&gt;的&lt;code&gt;jar&lt;/code&gt;包地址，表示将启动该程序；&lt;/p&gt;
&lt;p&gt;&lt;code&gt;workerStep&lt;/code&gt;是&lt;code&gt;worker&lt;/code&gt;将要执行的&lt;code&gt;step&lt;/code&gt;；&lt;/p&gt;
&lt;p&gt;&lt;code&gt;commandLineArgs&lt;/code&gt;定义了启动&lt;code&gt;worker&lt;/code&gt;的&lt;code&gt;jvm&lt;/code&gt;参数，如&lt;code&gt;--spring.profiles.active=worker&lt;/code&gt;；&lt;/p&gt;
&lt;p&gt;&lt;code&gt;environment&lt;/code&gt;是&lt;code&gt;manager&lt;/code&gt;的系统环境变量，可以传递给&lt;code&gt;worker&lt;/code&gt;，当然也可以选择不传递；&lt;/p&gt;
&lt;p&gt;&lt;code&gt;MaxWorkers&lt;/code&gt;是最多能同时启动多少个&lt;code&gt;worker&lt;/code&gt;，类似于线程池大小；设置为2，表示最多同时有2个&lt;code&gt;worker&lt;/code&gt;来处理4个分区。&lt;/p&gt;
&lt;h3 id=&quot;223-manager和worker的batch定义&quot;&gt;2.2.3 Manager和Worker的Batch定义&lt;/h3&gt;
&lt;p&gt;完成了分区相关的代码，剩下的就只是如何定义&lt;code&gt;Manager&lt;/code&gt;和&lt;code&gt;Worker&lt;/code&gt;的业务代码了。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Manager&lt;/code&gt;作为管理者，不用太多业务逻辑，代码如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;@Bean
@Profile(&quot;!worker&quot;)
public Job partitionedJob(PartitionHandler partitionHandler) throws Exception {
  Random random = new Random();
  return this.jobBuilderFactory.get(&quot;partitionedJob&quot; + random.nextInt())
    .start(step1(partitionHandler))
    .build();
}

@Bean
public Step step1(PartitionHandler partitionHandler) throws Exception {
  return this.stepBuilderFactory.get(&quot;step1&quot;)
    .partitioner(workerStep().getName(), partitioner())
    .step(workerStep())
    .partitionHandler(partitionHandler)
    .build();
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;Worker&lt;/code&gt;主要作用是处理数据，是我们的业务代码，这里就演示一下如何获取&lt;code&gt;Manager&lt;/code&gt;传递过来的&lt;code&gt;partitionNumber&lt;/code&gt;：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;@Bean
public Step workerStep() {
  return this.stepBuilderFactory.get(&quot;workerStep&quot;)
    .tasklet(workerTasklet(null, null))
    .build();
}

@Bean
@StepScope
public Tasklet workerTasklet(final @Value(&quot;#{stepExecutionContext['partitionNumber']}&quot;) Integer partitionNumber) {
  return new Tasklet() {
    @Override
    public RepeatStatus execute(StepContribution contribution, ChunkContext chunkContext) throws Exception {
      Thread.sleep(6000); //增加延时，查看效果，通过jps：在jar情况下会新起java进程
      System.out.println(&quot;This tasklet ran partition: &quot; + partitionNumber);
     
      return RepeatStatus.FINISHED;
    }
  };
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;通过表达式&lt;code&gt;@Value(&quot;#{stepExecutionContext['partitionNumber']}&quot;)&lt;/code&gt; 获取&lt;code&gt;Manager&lt;/code&gt;传递过来的变量；注意要加注解&lt;code&gt;@StepScope&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;因为我们分为&lt;code&gt;Manager&lt;/code&gt;和&lt;code&gt;Worker&lt;/code&gt;，但都是同一份代码，所以我们先打包一个&lt;code&gt;jar&lt;/code&gt;出来，不然&lt;code&gt;manager&lt;/code&gt;无法启动。配置数据库和&lt;code&gt;Worker&lt;/code&gt;的&lt;code&gt;jar&lt;/code&gt;包地址如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-properties&quot;&gt;spring.datasource.url=jdbc:h2:tcp://localhost:9092/test
spring.datasource.username=pkslow
spring.datasource.password=pkslow
spring.datasource.driver-class-name=org.h2.Driver

pkslow.worker.resource=file://pkslow/target/remote-partitioning-jar-1.0-SNAPSHOT.jar
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;执行程序如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/946674/202009/946674-20200915005857301-862146195.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;可以看到启动了4次&lt;code&gt;Java&lt;/code&gt;程序，还给出日志路径。&lt;/p&gt;
&lt;p&gt;通过&lt;code&gt;jps&lt;/code&gt;命令查看，能看到一个&lt;code&gt;Manager&lt;/code&gt;进程，还有两个&lt;code&gt;worker&lt;/code&gt;进程：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/946674/202009/946674-20200915005857795-649729332.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;

&lt;p&gt;前面讲了&lt;code&gt;Manager&lt;/code&gt;可以通过&lt;code&gt;ExecutionContext&lt;/code&gt;传递变量，如简单的&lt;code&gt;String&lt;/code&gt;、&lt;code&gt;long&lt;/code&gt;等。但其实它也是可以传递复杂的&lt;code&gt;Java&lt;/code&gt;对象的，但对应的类需要可序列化，如：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;import java.io.Serializable;

public class Person implements Serializable {
    private Integer age;
    private String name;
    private String webSite;
  //getter and setter
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;Manager&lt;/code&gt;传递：&lt;/p&gt;
&lt;p&gt;&lt;code&gt;executionContext.put(&quot;person&quot;, new Person(0, &quot;pkslow&quot;, &quot;www.pkslow.com&quot;));&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Worker&lt;/code&gt;接收：&lt;/p&gt;
&lt;p&gt;&lt;code&gt;@Value(&quot;#{stepExecutionContext['person']}&quot;) Person person&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;本文介绍了&lt;code&gt;Spring Batch&lt;/code&gt;远程分区的&lt;code&gt;本地Jar包模式&lt;/code&gt;，只能在一台机器上运行，所以也是无法真正发挥出远程分区的作用。但它对我们后续理解更复杂的模式是有很大帮助的；同时，我们也可以使用本地模式进行开发测试，毕竟它只需要一个数据库就行了，依赖很少。&lt;/p&gt;
&lt;hr/&gt;&lt;p&gt;欢迎关注微信公众号&amp;lt;&lt;strong&gt;南瓜慢说&lt;/strong&gt;&amp;gt;，将持续为你更新...&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/946674/202009/946674-20200915005858308-584240189.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;多读书，多分享；多写作，多整理。&lt;/strong&gt;&lt;/p&gt;
</description>
<pubDate>Mon, 14 Sep 2020 16:59:00 +0000</pubDate>
<dc:creator>南瓜慢说</dc:creator>
<og:description>1 前言 欢迎访问南瓜慢说 www.pkslow.com获取更多精彩文章！ Spring相关文章：Springboot-Cloud Spring Batch远程分区对于大量数据的处理非常擅长，它的实现</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/larrydpk/p/13670453.html</dc:identifier>
</item>
<item>
<title>源码解读 TDengine 中线程池的实现 - Jack47</title>
<link>http://www.cnblogs.com/Jack47/p/threadpool-in-tdengine.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/Jack47/p/threadpool-in-tdengine.html</guid>
<description>&lt;p&gt;这篇&lt;a href=&quot;https://mp.weixin.qq.com/s/mZJO1quxyV7HMfW_KIUgfA&quot;&gt;文章&lt;/a&gt;中提到了 tsched 的源码可以一读，所以去阅读了一下，总共220来行。&lt;/p&gt;
&lt;h2 id=&quot;1-阅读前工作&quot;&gt;1. 阅读前工作&lt;/h2&gt;
&lt;p&gt;通过&lt;a href=&quot;https://mp.weixin.qq.com/s/mZJO1quxyV7HMfW_KIUgfA&quot;&gt;上文&lt;/a&gt;了解到这段程序实现的是一个任务队列，同时带有线程池。这段程序是计算机操作系统里经典的consumer-producer (生产者-消费者)问题的实现。凡是学过操作系统这门课的，都应该知道这个问题，做过习题。在阅读源码之前可以先尝试用伪代码实现上述生产者-消费者问题。&lt;/p&gt;
&lt;h2 id=&quot;2-如何阅读？&quot;&gt;2. 如何阅读？&lt;/h2&gt;
&lt;h3 id=&quot;了解清楚使用场景&quot;&gt;了解清楚使用场景&lt;/h3&gt;
&lt;p&gt;这是一个线程池，客户端可以提交任务，线程池按照顺序调度执行任务。通过&lt;a href=&quot;https://github.com/taosdata/TDengine/blob/develop/src/util/inc/tsched.h&quot;&gt;阅读 tsched.h 头文件&lt;/a&gt;，知道主要有三个函数：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;初始化命名的调度器、线程池：taosInitScheduler&lt;/li&gt;
&lt;li&gt;生产者提交某个任务：taosScheduleTask&lt;/li&gt;
&lt;li&gt;程序结束时的清理工作：taosCleanUpScheduler&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;通过搜索上述三个函数的调用， 知道初始化了两个调度器，有三个地方会提交任务。&lt;/p&gt;
&lt;h3 id=&quot;两个线程池&quot;&gt;两个线程池&lt;/h3&gt;
&lt;ol&gt;&lt;li&gt;定时器里的 &lt;a href=&quot;https://github.com/taosdata/TDengine/blob/develop/src/util/src/ttimer.c#L527&quot;&gt;tmr 线程池&lt;/a&gt; : 队列长度一万，只有一个线程服务。此线程会执行&lt;a href=&quot;https://github.com/taosdata/TDengine/blob/develop/src/util/src/ttimer.c#L257&quot;&gt;到期的 timer&lt;/a&gt; 的&lt;a href=&quot;https://github.com/taosdata/TDengine/blob/develop/src/util/src/ttimer.c#L265&quot;&gt;回调函数&lt;/a&gt;。&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/taosdata/TDengine/blob/develop/src/client/src/tscSystem.c#L132&quot;&gt;tsc 线程池&lt;/a&gt;：队列长度一万，线程数量为所在机器 CPU 核心数的一半。&lt;a href=&quot;https://github.com/taosdata/TDengine/search?q=tscQhandle&amp;amp;unscoped_q=tscQhandle&quot;&gt;这些线程负责&lt;/a&gt;：异步操作&lt;a href=&quot;https://github.com/taosdata/TDengine/blob/develop/src/client/src/tscAsync.c#L384&quot;&gt;如执行语句&lt;/a&gt;，&lt;a href=&quot;https://github.com/taosdata/TDengine/blob/develop/src/client/src/tscStream.c#L159&quot;&gt;固定大小滑动窗口流式数据处理&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;h3 id=&quot;两个生产者&quot;&gt;两个生产者&lt;/h3&gt;
&lt;p&gt;上面提到了，有三个生产者会提交任务给线程池：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;&lt;a href=&quot;https://github.com/taosdata/TDengine/blob/develop/src/util/src/ttimer.c#L257&quot;&gt;timer&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/taosdata/TDengine/blob/develop/src/client/src/tscStream.c#L159&quot;&gt;stream&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;了解了清楚使用方、使用场景后，就容易读懂逻辑了。这里是一个标准的操作系统中生产者消费者的问题，用的也是标准解法：使用一个互斥量，两个信号量。线程池使用 &lt;a href=&quot;https://zh.wikipedia.org/zh-hans/POSIX%E7%BA%BF%E7%A8%8B&quot;&gt;pthread&lt;/a&gt; 来创建。&lt;/p&gt;
&lt;h3 id=&quot;关键的数据结构&quot;&gt;关键的数据结构&lt;/h3&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/taosdata/TDengine/blob/develop/src/util/src/tsched.c#L25&quot;&gt;SSchedQueue&lt;/a&gt; 里面就是上述问题中的核心数据结构，除了放置上述提到的互斥量，信号量，还需要一个队列来存储要具体执行的任务。&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/taosdata/TDengine/blob/develop/src/util/inc/tsched.h#L23&quot;&gt;SSchedMsg&lt;/a&gt; 结构来表示线程池任务，包含要执行的具体函数及所需参数。&lt;/p&gt;
&lt;p&gt;源码里注释并不多，只能通过看具体实现来了解上述支持的执行模式。看到支持&lt;a href=&quot;https://github.com/taosdata/TDengine/blob/develop/src/util/src/tsched.c#L145&quot;&gt;两种模式&lt;/a&gt;：执行fp，或者执行 tfp(ahandle, thandle)。&lt;/p&gt;
&lt;h3 id=&quot;核心调度逻辑&quot;&gt;核心调度逻辑&lt;/h3&gt;
&lt;p&gt;上面提到了生产者，一直没有提到消费者。接着读 sched.c 里的源码，可以看到消费者就是线程池里每个线程的主框架逻辑： taosProcessSchedQueue。平常这些线程处于阻塞状态，等待任务。一旦生产者提交任务后，就会通知到消费者。消费者拿到提交的任务及参数，去执行。执行完之后继续进入上述阻塞的状态，这样周而复始。&lt;/p&gt;
&lt;p&gt;这里有个疑问，消费者和生产者之间是异步的。消费完之后，总得有办法通知消费者，这一步在哪里做呢？读到这里可以花点时间翻翻源码，找找答案。&lt;/p&gt;
&lt;p&gt;其实秘密也藏在当时提交任务的数据结构里。TDengine 里有样例代码，翻了翻，找到了这个 &lt;a href=&quot;https://github.com/taosdata/TDengine/blob/develop/tests/examples/c/asyncdemo.c#L116&quot;&gt;async demo&lt;/a&gt;。可以看到 taos_query_a 就是一个异步的query函数，里面带了 query语句异步执行完成后的回调函数：taos_insert_call_back)。&lt;/p&gt;
&lt;h2 id=&quot;3-一些思考&quot;&gt;3. 一些思考&lt;/h2&gt;
&lt;p&gt;看的时候内心不断在思考、对比，比如优势、劣势是什么？我会怎么实现&lt;/p&gt;
&lt;h3 id=&quot;优势&quot;&gt;优势&lt;/h3&gt;
&lt;p&gt;为何使用线程池？&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;通过固定线程池大小来固定资源开销，而且是程序初始化时申请资源，这在嵌入式设备里是非常重要的，如果资源不够用，那就快速失败，在程序一开始启动时就报错。&lt;/li&gt;
&lt;li&gt;复用了线程，因为创建、销毁线程都是有开销的。这样在频繁创建、销毁线程情况下，可以节省开销，复用之前的线程。&lt;/li&gt;
&lt;li&gt;任务和线程解耦：需要使用多线程的地方，只管提交任务就好了。线程的初始化、运行、状态切换由线程池来负责。&lt;/li&gt;
&lt;/ol&gt;&lt;h3 id=&quot;劣势&quot;&gt;劣势&lt;/h3&gt;
&lt;ol&gt;&lt;li&gt;操作异步化，对程序员的心智要求更高。需要使用回调函数，需要存储上下文。但是在上述场景里还好， 都是一些固定的逻辑。&lt;/li&gt;
&lt;li&gt;调试较麻烦，不是直来直去的逻辑。需要通过分析上下文及回调函数里的日志来分析问题。&lt;/li&gt;
&lt;/ol&gt;&lt;h3 id=&quot;有没有其他实现方式？&quot;&gt;有没有其他实现方式？&lt;/h3&gt;
&lt;p&gt;如果用 Go 语言实现，会很简单。使用 channel 来做任务分发，本身就是线程安全的。&lt;/p&gt;
&lt;p&gt;使用 C 来写，个人觉得会限制 TDengine 的开源参与方。因为现在市场上会 C 的人比较少，而且主要集中在嵌入式领域。而且 C 的生态一般，语言的轮子比较少，所以很多工作都需要自己做，比如 http server，rpc 等。如果让我来设计实现 TDengine，我可能会优先考虑 Rust，既能精准控制内存，又有比较完善的社区，而且语言处于上升期，容易成为其中的明星项目，会有推广优势，比如能吸引一些本身对数据库不怎么关注，但是对 Rust 感兴趣的程序员。&lt;/p&gt;
&lt;h2 id=&quot;4-一个思考题&quot;&gt;4. 一个思考题&lt;/h2&gt;
&lt;p&gt;通过搜索 &lt;a href=&quot;https://github.com/taosdata/TDengine/search?p=5&amp;amp;q=pthread_create&amp;amp;unscoped_q=pthread_create&quot;&gt;pthread_create&lt;/a&gt; 可以发现系统中还有其他创建线程的地方，并没有用到上述的线程池，比如 &lt;a href=&quot;https://github.com/taosdata/TDengine/blob/develop/src/dnode/src/dnodeMWrite.c#L98&quot;&gt;dnodeMWrite&lt;/a&gt;, &lt;a href=&quot;https://github.com/taosdata/TDengine/blob/develop/src/sync/src/taosTcpPool.c#L78&quot;&gt;TcpPool&lt;/a&gt;，&lt;a href=&quot;https://github.com/taosdata/TDengine/blob/develop/src/util/src/tcache.c&quot;&gt;cache&lt;/a&gt;，&lt;a href=&quot;https://github.com/taosdata/TDengine/blob/develop/src/sync/src/syncMain.c#L774&quot;&gt;sync&lt;/a&gt;等。这些地方为什么没有使用线程池呢？&lt;/p&gt;
&lt;h2 id=&quot;欢迎关注我的微信公众账号，会在第一时间更新，博客园上只有部分文章会发布&quot;&gt;欢迎关注我的微信公众账号，会在第一时间更新，博客园上只有部分文章会发布&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;http://img2.tbcdn.cn/L1/461/1/5a0eff69de17d58383b72c9a78b3c28cd74b9d39&quot; alt=&quot;code&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
</description>
<pubDate>Mon, 14 Sep 2020 15:41:00 +0000</pubDate>
<dc:creator>Jack47</dc:creator>
<og:description>这篇文章中提到了 tsched 的源码可以一读，所以去阅读了一下，总共220来行。 1. 阅读前工作 通过上文了解到这段程序实现的是一个任务队列，同时带有线程池。这段程序是计算机操作系统里经典的con</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/Jack47/p/threadpool-in-tdengine.html</dc:identifier>
</item>
<item>
<title>程序员你如何检查参数的合法性？ - 李福春</title>
<link>http://www.cnblogs.com/snidget/p/13670176.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/snidget/p/13670176.html</guid>
<description>&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/268922/202009/268922-20200914233437656-1165059278.png&quot; alt=&quot;image.png&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;作为程序员的你，代码中最多的就是各种方法了，你是如何对参数进行校验的呢？&lt;/p&gt;

&lt;p&gt;大部分的方法和构造函数对传入的参数值有一些限制，比如：常见的索引值必须是非负数，对象引用不能为空。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;你应该使用清晰的文档来标注所有的这些限制，然后在方法体开始的地方强制他们检查。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;应该在错误发生的时候尽快的检查出来&lt;/strong&gt;，这是基本原则。&lt;/p&gt;
&lt;p&gt;如果你不这么做，当错误发生的时候，错误将不会被检测出来，这让定位错误的源头变得更困难。&lt;/p&gt;
&lt;p&gt;如果一个非法参数传递到一个方法中，在方法执行前进行了参数检查。它将会快速失败，并给出清晰的异常信息。&lt;/p&gt;
&lt;p&gt;如果方法没有检查参数，下面这些事情会发生。&lt;/p&gt;
&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;程度&lt;/th&gt;
&lt;th&gt;说明&lt;/th&gt;
&lt;/tr&gt;&lt;/thead&gt;&lt;tbody readability=&quot;3.5&quot;&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;糟糕&lt;/td&gt;
&lt;td&gt;方法会在执行过程中失败然后抛出一个不明确的异常；&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;更糟糕&lt;/td&gt;
&lt;td&gt;方法会正常返回，但是悄悄的计算了一个错误的值。&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;3&quot;&gt;&lt;td&gt;最糟糕&lt;/td&gt;
&lt;td&gt;方法正常返回，但是一些对象处在一个不正确的状态，未来一个不确定的时间点在某些无关联的点会造成一个错误。&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;一句话总结：参数不校验会导致&lt;strong&gt;原子性失败&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;对公共和保护方法，使用java文档的@throws标签来标注参数值不合法将抛出的异常。&lt;/p&gt;
&lt;p&gt;常见的参数校验的异常类型如下：&lt;/p&gt;
&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;异常名称&lt;/th&gt;
&lt;th&gt;说明&lt;/th&gt;
&lt;/tr&gt;&lt;/thead&gt;&lt;tbody readability=&quot;1&quot;&gt;&lt;tr&gt;&lt;td&gt;IllegalArgumentException&lt;/td&gt;
&lt;td&gt;非法参数&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;IndexOutOfBoundsException&lt;/td&gt;
&lt;td&gt;数组越界&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;NullPointerException&lt;/td&gt;
&lt;td&gt;空指针&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;只要你已经已经在文档中标注了方法参数的限制和违反限制会抛出的异常，限制将是一个简单的事情，下面是一个典型的例子。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;/**
*@param m 必须是正整数
*@throws ArithmeticException 如果m&amp;lt;=0
**/
public BigInteger mod(BigInteger m){
        if(m&amp;lt;=0){
        throw new ArithmeticException(&quot;modulus &amp;lt;=0: &quot;+ m);
    }
    //todo 其它代码
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;注意：&lt;/p&gt;
&lt;p&gt;文档注释并没有说， 如果m是空，mod将抛出NullPointException， 尽管这个方法确实会这样。调用m.signum()的时候这个异常被标注在类级别BigInteger的文档注释上，类级别的注释适用于所有的公共方法的参数，这是一个避免在每个方法单独的文档化标注NullPointException这种混乱的好方法。&lt;/p&gt;
&lt;p&gt;也许可以结合@Nullable或者类似的注解来指明特殊参数可以为空，但是这个实践并不是标准的，并且有很多注解可以用来达到这个目的。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Objects.requireNonNull方法&lt;/strong&gt;，在Java7中添加的，非常的灵活和方便，所以没有理由手动的执行空指针检查。 &lt;strong&gt;你也可以指定异常的详细信息，这个方法返回自己的输入，所以你可以在使用该值的时候执行一个空指针检查。&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;//一行代码使用java的空指针检查
this.strategy = Objects.requireNonNull(strategy,&quot;strategy&quot;)
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;如果你可以忽略返回值，你也可以根据你的需要使用Objects.requireNonNull作为独立的空指针检查。&lt;br/&gt;在Java9中，一个范围检查的方法被添加到了java.util.Objects中，包含了3个方法：&lt;/p&gt;
&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;方法&lt;/th&gt;
&lt;th&gt;说明&lt;/th&gt;
&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;checkFromIndexSize&lt;/td&gt;
&lt;td/&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;checkFromToIndex&lt;/td&gt;
&lt;td/&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;checkIndex&lt;/td&gt;
&lt;td/&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;这3个方法没有空指针检查方法灵活，它无法让你指定自己的异常详细信息，它被设计用在List和Array的索引检查上。&lt;br/&gt;它也无法处理闭区间，但是只要你需要，这就是一个小便利。&lt;/p&gt;

&lt;p&gt;对一个不开放的方法，你作为包的作者，控制着方法的调用状况，你必须保证只有合法的参数值传递进去了。所以，对非公开的方法，你可以使用断言来进行参数检查，如下所示：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;//私有帮助排序函数
private static void sort(long a[] , int offset, int length){
        assert a != null ;
    //更多代码
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;本质上来讲，断言申明条件一定是true , 忽略客户端如何使用对应的包。&lt;br/&gt;跟一般的合法性检查不同，断言失败的时候抛出AssertError；&lt;br/&gt;跟一般的合法性检查不同，除非你启用他们否则断言对你没有任何影响和消耗。&lt;br/&gt;在java命令行启用指令：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-shell&quot;&gt;-ea
或者
-enableassertions
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;更多断言的信息，查看java手册的Asserts;&lt;/p&gt;
&lt;p&gt;检查参数的合法性非常重要，即使你的方法中没有用到，但是存储起来了，后面会用到。&lt;/p&gt;
&lt;p&gt;举个例子： 静态工厂方法： 输入一个 int数组 ，返回一个array的 list视图， 如果客户端传入 null, 这个方法会抛出NPE, 因为方法会有一个直接检查，调用了Objects.requireNonNull。&lt;br/&gt;如果忽略检查，方法会返回一个引用新创建的List的实例；&lt;/p&gt;
&lt;p&gt;而客户端尝试使用的时候回抛出NPE; 这个时候，原始的List实例很难决定，很大可能会复杂到变成一个调试任务。&lt;/p&gt;
&lt;p&gt;构造函数代表了一个特殊例子的原则： 你应该检查即将存储稍后会用到的参数的合法性。&lt;/p&gt;
&lt;p&gt;检查构造函数参数的合法性非常重要，它可以防止构造一个违反类的不变性的对象。&lt;/p&gt;

&lt;p&gt;在执行方法计算之前，你应该检查方法参数 。 这个规则也有异常情况。&lt;/p&gt;
&lt;p&gt;一个重要的异常情况是：合法性检查代价非常高并且重要， 并且检查是在执行计算的过程中执行的。&lt;br/&gt;举个例子：有一个方法对一个对象list排序，比如 Collectios.sort(list),所有的list中的对象必须是可互相比较的。在处理list比较的时候,每个对象将会跟其它的对象进行比较，&lt;/p&gt;
&lt;p&gt;如果对象不能互相比较，其中一个或多个比较会抛出ClassCastException，这是排序方法应该做的。&lt;/p&gt;
&lt;p&gt;所以：这里有一个小店，在开始的时候检查列表中的元素应该是可以互相比较的，注意：修改合法性检查会丧失&lt;strong&gt;原子失败&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;偶尔，一个计算执行了一个需要的合法性检查，但是当执行检查失败的时候，抛出了一个错误的异常。换句话说，计算常常会抛出参数合法性检查的异常，并不会匹配方法在文档中申明的异常。这种场景下，你应该使用异常翻译成语。 转换自然异常为正确的异常。&lt;/p&gt;
&lt;p&gt;这个原则并不是说武断的限制参数是一件好事,而是说：你应该设计通用实际的方法。&lt;br/&gt;假设你的方法接受所有的参数组合而可以做一些合理事情，你的参数限制越少越好，然而，一些限制本质上在抽象类中已经被实现了。&lt;/p&gt;

&lt;p&gt;如果看完之后你只能记住一句话：&lt;strong&gt;每次你写一个方法或者一个构造函数，你应该思考参数的限制是否存在，你应该把限制写在文档中，并在方法体的开始部分确保进行了检查&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;养成这个习惯很重要，适当的工作会在第一次合法性检查失败的时候回馈你。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/268922/202009/268922-20200914233438322-1829925368.png&quot; alt=&quot;检查参数的合法性.png&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;原创不易，关注诚可贵，转发价更高！转载请注明出处，让我们互通有无，共同进步，欢迎沟通交流。&lt;/p&gt;
&lt;/blockquote&gt;
</description>
<pubDate>Mon, 14 Sep 2020 15:35:00 +0000</pubDate>
<dc:creator>李福春</dc:creator>
<og:description>作为程序员的你，代码中最多的就是各种方法了，你是如何对参数进行校验的呢？ 背景 大部分的方法和构造函数对传入的参数值有一些限制，比如：常见的索引值必须是非负数，对象引用不能为空。 你应该使用清晰的文档</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/snidget/p/13670176.html</dc:identifier>
</item>
</channel>
</rss>