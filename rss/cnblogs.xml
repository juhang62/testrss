<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="css/feed.xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/" xmlns:og="http://ogp.me/ns#">
<channel>
<atom:link rel="self" href="http://192.168.1.4/fivefilters/makefulltextfeed.php?url=feed.cnblogs.com%2Fblog%2Fsitehome%2Frss&amp;max=10&amp;links=preserve&amp;exc=" />
<atom:link rel="alternate" title="Source URL" href="http://feed.cnblogs.com/blog/sitehome/rss" />
<atom:link rel="related" title="Subscribe to feed" href="http://www.subtome.com/#/subscribe?feeds=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed.cnblogs.com%252Fblog%252Fsitehome%252Frss%26max%3D10%26links%3Dpreserve%26exc%3D&amp;back=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed.cnblogs.com%252Fblog%252Fsitehome%252Frss%26max%3D10%26links%3Dpreserve%26exc%3D" />
<title>博客园_首页</title>
<link></link>
<description>代码改变世界</description>
<item>
<title>TensorFlow读取数据的三种方法 - 凌逆战</title>
<link>http://www.cnblogs.com/LXP-Never/p/11460000.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/LXP-Never/p/11460000.html</guid>
<description>&lt;ol&gt;&lt;li&gt;placehold feed_dict：从内存中读取数据，占位符填充数据&lt;/li&gt;
&lt;li&gt;queue队列：从硬盘读取数据&lt;/li&gt;
&lt;li&gt;Dataset：同时支持内存和硬盘读取数据&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;　　先用placehold 占位数据，在Graph中读取数据，数据直接内嵌到Graph中，然后当Graph传入Session是，用feed_dict喂补数据。当数据量比较大的时候，Graph的传输会遇到效率底下问题，特别是数据转换。&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;37&quot;&gt;
&lt;pre&gt;
&lt;span&gt;import&lt;/span&gt;&lt;span&gt; tensorflow as tf
&lt;/span&gt;&lt;span&gt;import&lt;/span&gt;&lt;span&gt; librosa

&lt;/span&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt; 把数据加载在Graph中&lt;/span&gt;
x1 = librosa.load(&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;temp_1.wav&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;, sr=16000&lt;span&gt;)
x2 &lt;/span&gt;= librosa.load(&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;temp_2.wav&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;, sr=16000&lt;span&gt;)
y &lt;/span&gt;=&lt;span&gt; tf.add(x1, x2)

with tf.Session() as sess:
    &lt;/span&gt;&lt;span&gt;print&lt;/span&gt;(sess.run(y))
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;　　如果我们的数据读取算法没有设计多线程的话（即单线程），由于读取数据和处理数据在同一个进程是有先后关系的，意味着数据处理完后必须花时间读取数据，然后才能进行计算处理。这样的一来GPU并没有高效的专一做一件事情，从而大大的降低的效率，queue创建多线程彻底的解决了这个问题。&lt;/p&gt;
&lt;p&gt;　　tensorflow中为了充分的利用时间，减少GPU等待的空闲时间，使用了两个线程（&lt;span&gt;&lt;strong&gt;文件名队列&lt;/strong&gt;&lt;/span&gt;和&lt;span&gt;&lt;strong&gt;内存队列&lt;/strong&gt;&lt;/span&gt;）分别执行数据读入和数据计算。文件名队列源源不断的将硬盘中的图片数据，内存队列负责给GPU送数据，所需数据直接从内存队列中获取。两个线程之间互不干扰，同时运行。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1433301/201909/1433301-20190915162848656-655663948.png&quot; alt=&quot;&quot; width=&quot;479&quot; height=&quot;233&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　因此 tensorflow 在内存队列之前，还要使用tf.train.slice_input_producer函数，创建一个文件名队列，文件名队列存放的是参与训练的文件名，要训练N个epoch，则文件名队列中就含有N个批次的所有文件名。&lt;/p&gt;
&lt;h2&gt;tf.train.slice_in put_producer()&lt;/h2&gt;
&lt;p&gt;　　使用到 tf.train.slice_input_producer 函数创建文件名队列。在N个epoch的文件名最后是一个结束标志，当tf读到这个结束标志的时候，会抛出一个&lt;em&gt;OutofRange&lt;/em&gt; 的异常，外部捕获到这个异常之后就可以结束程序了。&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;39&quot;&gt;
&lt;pre&gt;
&lt;span&gt;slice_input_producer(tensor_list, 
                    num_epochs&lt;/span&gt;=&lt;span&gt;None, 
                    shuffle&lt;/span&gt;=&lt;span&gt;True, 
                    seed&lt;/span&gt;=&lt;span&gt;None,
                    capacity&lt;/span&gt;=32&lt;span&gt;, 
                    shared_name&lt;/span&gt;=&lt;span&gt;None, 
                    name&lt;/span&gt;=None)
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span&gt;返回tensor生成器，作用是按照设定，每次从一个tensor_list中按顺序或者随机抽取出&lt;strong&gt;一个tensor&lt;/strong&gt;放入文件名队列。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;参数：&lt;/span&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;span&gt;tensor_list：tensor的列表，表中tensor的第一维度的值必须相等，即个数必须相等，有多少个图像，就应该有多少个对应的标签&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span&gt;num_epochs: 迭代的次数，num_epochs=None,生成器可以无限次遍历tensor列表；num_epochs=N，生成器只能遍历tensor列表N次&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span&gt;shuffle： bool，是否打乱样本的顺序。一般情况下，如果shuffle=True，生成的样本顺序就被打乱了，在批处理的时候不需要再次打乱样本，使用 tf.train.batch函数就可以了;如果shuffle=False,就需要在批处理时候使用 tf.train.shuffle_batch函数打乱样本&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span&gt;seed: 生成随机数的种子，shuffle=True的情况下才有用&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span&gt;capacity：队列容量的大小，为整数&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span&gt;shared_name：可选参数，如果设置一个&quot;shared_name&quot;，则在不同的上下文Session中可以通过这个名字共享生成的tensor&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span&gt;name：设置操作的名称&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;span&gt;如果tensor_list=[data, lable]，其中data.shape=(4000,10)，label.shape=[4000,2]，则生成器生成的第一个队列&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;input_quenue[0].shape=(10,)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;input_quenue[1].shape=(2,)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;要真正将文件放入文件名队列，还需要调用&lt;strong&gt;&lt;span&gt;tf.train.start_queue_runners&lt;/span&gt;&lt;/strong&gt; 函数来启动执行文件名队列填充的线程，之后计算单元才可以把数据读出来，否则文件名队列为空的，计算单元就会处于一直等待状态，导致系统阻塞。&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;57&quot;&gt;
&lt;pre&gt;
&lt;span&gt;import&lt;/span&gt;&lt;span&gt; tensorflow as tf

images &lt;/span&gt;= [&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;img1&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;, &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;img2&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;, &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;img3&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;, &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;img4&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;, &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;img5&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;]
labels &lt;/span&gt;= [1, 2, 3, 4, 5&lt;span&gt;]

epoch_num &lt;/span&gt;= 8
&lt;span&gt;#&lt;/span&gt;&lt;span&gt; 文件名队列&lt;/span&gt;
input_queue = tf.train.slice_input_producer([images, labels], num_epochs=None, shuffle=&lt;span&gt;False)

with tf.Session() as sess:
    sess.run(tf.global_variables_initializer())
    coord &lt;/span&gt;= tf.train.Coordinator()  &lt;span&gt;#&lt;/span&gt;&lt;span&gt; 创建一个协调器，管理线程&lt;/span&gt;
    &lt;span&gt;#&lt;/span&gt;&lt;span&gt; 启动QueueRunner, 执行文件名队列的填充&lt;/span&gt;
    threads = tf.train.start_queue_runners(sess=sess, coord=&lt;span&gt;coord)
    &lt;/span&gt;&lt;span&gt;for&lt;/span&gt; i &lt;span&gt;in&lt;/span&gt;&lt;span&gt; range(epoch_num):
        k &lt;/span&gt;=&lt;span&gt; sess.run(input_queue)
        &lt;/span&gt;&lt;span&gt;print&lt;/span&gt;&lt;span&gt;(i, k)
        &lt;/span&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt; 0[b'img1', 1]&lt;/span&gt;
        &lt;span&gt;#&lt;/span&gt;&lt;span&gt; 1[b'img2', 2]&lt;/span&gt;
        &lt;span&gt;#&lt;/span&gt;&lt;span&gt; 2[b'img3', 3]&lt;/span&gt;
        &lt;span&gt;#&lt;/span&gt;&lt;span&gt; 3[b'img4', 4]&lt;/span&gt;
        &lt;span&gt;#&lt;/span&gt;&lt;span&gt; 4[b'img5', 5]&lt;/span&gt;
        &lt;span&gt;#&lt;/span&gt;&lt;span&gt; 5[b'img1', 1]&lt;/span&gt;
        &lt;span&gt;#&lt;/span&gt;&lt;span&gt; 6[b'img2', 2]&lt;/span&gt;
        &lt;span&gt;#&lt;/span&gt;&lt;span&gt; 7[b'img3', 3]&lt;/span&gt;
&lt;span&gt;
    coord.request_stop()
    coord.join(threads)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;tf.train.batch &amp;amp; tf.train.shuffle_batch()&lt;/h2&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;42&quot;&gt;
&lt;pre&gt;
&lt;span&gt;tf.train.batch(
    tensors_list,
    batch_size,
    num_threads&lt;/span&gt;=1&lt;span&gt;,
    capacity&lt;/span&gt;=32&lt;span&gt;,
    enqueue_many&lt;/span&gt;=&lt;span&gt;False,
    shapes&lt;/span&gt;=&lt;span&gt;None,
    dynamic_pad&lt;/span&gt;=&lt;span&gt;False,
    allow_smaller_final_batch&lt;/span&gt;=&lt;span&gt;False,
    shared_name&lt;/span&gt;=&lt;span&gt;None,
    name&lt;/span&gt;=&lt;span&gt;None
)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;&lt;span&gt;tf.train.batch &amp;amp; tf.train.shuffle_batch()这两个函数的参数是一样的&lt;/span&gt;&lt;/strong&gt;，下面我以tf.train.batch讲解为例&lt;/p&gt;
&lt;p&gt;&lt;span&gt;tf.train.batch是一个tensor队列生成器，作用是按照给定的tensor顺序，把batch_size个tensor推送到&lt;span&gt;文件队列&lt;/span&gt;，作为训练一个batch的数据，等待tensor出队执行计算。&lt;/span&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;span&gt;&lt;strong&gt;tensors&lt;/strong&gt;：一个列表或字典的tensor用来进行入队&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span&gt;&lt;strong&gt;batch_size&lt;/strong&gt;: 每次从队列中获取出队数据的数量&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span&gt;&lt;strong&gt;num_threads&lt;/strong&gt;：用来控制&lt;strong&gt;入队tensors线程的数量&lt;/strong&gt;，如果num_threads大于1，则batch操作将是非确定性的，输出的batch可能会乱序&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span&gt;&lt;strong&gt;capacity&lt;/strong&gt;： 设置队列中元素的最大数量&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span&gt;&lt;strong&gt;enqueue_many&lt;/strong&gt;： 在第一个参数tensors中的tensor是否是单个样本&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span&gt;&lt;strong&gt;shapes&lt;/strong&gt;： 可选，每个样本的shape，默认是tensors的shape&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span&gt;&lt;strong&gt;dynamic_pad&lt;/strong&gt;： Boolean值；允许输入变量的shape，出队后会自动填补维度，来保持与batch内的shapes相同&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span&gt;&lt;strong&gt;allow_smaller_final_batch&lt;/strong&gt;： 设置为True，表示在tensor队列中剩下的tensor数量不够一个batch_size的情况下，允许最后一个batch的数量少于batch_size进行出队， 设置为False，小于batch_size的样本不会做出队处理&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span&gt;&lt;strong&gt;shared_name&lt;/strong&gt;： 可选参数，设置生成的tensor序列在不同的Session中的共享名称;&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span&gt;&lt;strong&gt;name&lt;/strong&gt;： 操作的名称;&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;span&gt;以下举例： 一共有5个样本，设置迭代次数是2次，每个batch中含有3个样本，不打乱样本顺序：&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;74&quot;&gt;
&lt;pre&gt;
&lt;span&gt;import&lt;/span&gt;&lt;span&gt; tensorflow as tf
&lt;/span&gt;&lt;span&gt;import&lt;/span&gt;&lt;span&gt; numpy as np

sample_num &lt;/span&gt;= 5  &lt;span&gt;#&lt;/span&gt;&lt;span&gt; 样本个数&lt;/span&gt;
epoch_num = 2  &lt;span&gt;#&lt;/span&gt;&lt;span&gt; 设置迭代次数&lt;/span&gt;
batch_size = 3  &lt;span&gt;#&lt;/span&gt;&lt;span&gt; 设置一个批次中包含样本个数&lt;/span&gt;
batch_total = int(sample_num / batch_size) + 1  &lt;span&gt;#&lt;/span&gt;&lt;span&gt; 计算每一轮epoch中含有的batch个数&lt;/span&gt;


&lt;span&gt;#&lt;/span&gt;&lt;span&gt; 生成4个数据和标签&lt;/span&gt;
&lt;span&gt;def&lt;/span&gt; generate_data(sample_num=&lt;span&gt;sample_num):
    labels &lt;/span&gt;=&lt;span&gt; np.asarray(range(0, sample_num))
    images &lt;/span&gt;= np.random.random([sample_num, 224, 224, 3&lt;span&gt;])
    &lt;/span&gt;&lt;span&gt;print&lt;/span&gt;(&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;image size {}, label size: {}&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;.format(images.shape, labels.shape))
    &lt;/span&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt; image size (5, 224, 224, 3), label size: (5,)&lt;/span&gt;
    &lt;span&gt;return&lt;/span&gt;&lt;span&gt; images, labels


&lt;/span&gt;&lt;span&gt;def&lt;/span&gt; get_batch_data(batch_size=&lt;span&gt;batch_size):
    images, label &lt;/span&gt;=&lt;span&gt; generate_data()
    images &lt;/span&gt;= tf.cast(images, tf.float32)  &lt;span&gt;#&lt;/span&gt;&lt;span&gt; 数据类型转换为tf.float32&lt;/span&gt;
    label = tf.cast(label, tf.int32)  &lt;span&gt;#&lt;/span&gt;&lt;span&gt; 数据类型转换为tf.int32&lt;/span&gt;

    &lt;span&gt;#&lt;/span&gt;&lt;span&gt; 从tensor列表中按顺序或随机抽取一个tensor，&lt;span&gt;&lt;strong&gt;主要代码&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;
    input_queue = tf.train.slice_input_producer([images, label], shuffle=&lt;span&gt;False)

    image_batch, label_batch &lt;/span&gt;= tf.train.batch(input_queue, batch_size=&lt;span&gt;batch_size,
                                              num_threads&lt;/span&gt;=1, capacity=64&lt;span&gt;)
    &lt;/span&gt;&lt;span&gt;return&lt;/span&gt;&lt;span&gt; image_batch, label_batch


image_batch, label_batch &lt;/span&gt;= get_batch_data(batch_size=&lt;span&gt;batch_size)

with tf.Session() as sess:
    coord &lt;/span&gt;=&lt;span&gt; tf.train.Coordinator()
    threads &lt;/span&gt;=&lt;span&gt; tf.train.start_queue_runners(sess, coord)
    &lt;/span&gt;&lt;span&gt;try&lt;/span&gt;&lt;span&gt;:
        &lt;/span&gt;&lt;span&gt;for&lt;/span&gt; i &lt;span&gt;in&lt;/span&gt; range(epoch_num):  &lt;span&gt;#&lt;/span&gt;&lt;span&gt; 每一轮迭代&lt;/span&gt;
            &lt;span&gt;print&lt;/span&gt;(&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt; ** ** ** ** ** ** &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;)
            &lt;/span&gt;&lt;span&gt;for&lt;/span&gt; j &lt;span&gt;in&lt;/span&gt; range(batch_total):  &lt;span&gt;#&lt;/span&gt;&lt;span&gt; 遍历每一个batch&lt;/span&gt;
                &lt;span&gt;#&lt;/span&gt;&lt;span&gt; 获取每一个batch中batch_size个样本和标签&lt;/span&gt;
                image_batch_v, label_batch_v =&lt;span&gt; sess.run([image_batch, label_batch])
                &lt;/span&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt; for k in&lt;/span&gt;
                &lt;span&gt;print&lt;/span&gt;&lt;span&gt;(image_batch_v.shape, label_batch_v)
                &lt;/span&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt; ** ** ** ** ** **&lt;/span&gt;
                &lt;span&gt;#&lt;/span&gt;&lt;span&gt; (3, 224, 224, 3) [0 1 2]&lt;/span&gt;
                &lt;span&gt;#&lt;/span&gt;&lt;span&gt; (3, 224, 224, 3) [3 4 0]&lt;/span&gt;
                &lt;span&gt;#&lt;/span&gt;&lt;span&gt; ** ** ** ** ** **&lt;/span&gt;
                &lt;span&gt;#&lt;/span&gt;&lt;span&gt; (3, 224, 224, 3) [1 2 3]&lt;/span&gt;
                &lt;span&gt;#&lt;/span&gt;&lt;span&gt; (3, 224, 224, 3) [4 0 1]&lt;/span&gt;
    &lt;span&gt;except&lt;/span&gt;&lt;span&gt; tf.errors.OutOfRangeError:
        &lt;/span&gt;&lt;span&gt;print&lt;/span&gt;(&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;done&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;)
    &lt;/span&gt;&lt;span&gt;finally&lt;/span&gt;&lt;span&gt;:
        coord.request_stop()
    coord.join(threads)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;与tf.train.batch函数相对的还有一个tf.train.shuffle_batch函数，两个函数作用一样，都是生成一定数量的tensor，组成训练一个batch需要的数据集，区别是tf.train.shuffle_batch会打乱样本顺序。&lt;/p&gt;
&lt;p&gt;下面这段代码和上面想表达的相同，但是如果tf.train.slice_input_producer中设置了epoch，则后面训练的时候，不需要for循环epoch，只需要设置coord.should_stop。&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;59&quot;&gt;
&lt;pre&gt;
&lt;span&gt;import&lt;/span&gt;&lt;span&gt; numpy as np
&lt;/span&gt;&lt;span&gt;import&lt;/span&gt;&lt;span&gt; tensorflow as tf


&lt;/span&gt;&lt;span&gt;def&lt;/span&gt;&lt;span&gt; next_batch():
    datasets &lt;/span&gt;= np.asarray(range(0, 20&lt;span&gt;))
    input_queue &lt;/span&gt;= tf.train.slice_input_producer([datasets], shuffle=False, num_epochs=1&lt;span&gt;)
    data_batchs &lt;/span&gt;= tf.train.batch(input_queue, batch_size=5, num_threads=1&lt;span&gt;,
                                 capacity&lt;/span&gt;=20, allow_smaller_final_batch=&lt;span&gt;False)
    &lt;/span&gt;&lt;span&gt;return&lt;/span&gt;&lt;span&gt; data_batchs


&lt;/span&gt;&lt;span&gt;if&lt;/span&gt; &lt;span&gt;__name__&lt;/span&gt; == &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;__main__&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;:
    data_batchs &lt;/span&gt;=&lt;span&gt; next_batch()
    sess &lt;/span&gt;=&lt;span&gt; tf.Session()
    sess.run(tf.initialize_local_variables())
    coord &lt;/span&gt;= tf.train.Coordinator()  &lt;span&gt;#&lt;/span&gt;&lt;span&gt; 创建一个协调器，管理线程&lt;/span&gt;
    threads = tf.train.start_queue_runners(sess, coord)  &lt;span&gt;#&lt;/span&gt;&lt;span&gt; 启动线程&lt;/span&gt;
    &lt;span&gt;try&lt;/span&gt;&lt;span&gt;:
        &lt;/span&gt;&lt;span&gt;while&lt;/span&gt; &lt;span&gt;not&lt;/span&gt;&lt;span&gt; coord.should_stop():
            data &lt;/span&gt;=&lt;span&gt; sess.run([data_batchs])
            &lt;/span&gt;&lt;span&gt;print&lt;/span&gt;&lt;span&gt;(data)
            &lt;/span&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt; [array([0, 1, 2, 3, 4])]&lt;/span&gt;
            &lt;span&gt;#&lt;/span&gt;&lt;span&gt; [array([5, 6, 7, 8, 9])]&lt;/span&gt;
            &lt;span&gt;#&lt;/span&gt;&lt;span&gt; [array([10, 11, 12, 13, 14])]&lt;/span&gt;
            &lt;span&gt;#&lt;/span&gt;&lt;span&gt; [array([15, 16, 17, 18, 19])]&lt;/span&gt;
            &lt;span&gt;#&lt;/span&gt;&lt;span&gt; complete&lt;/span&gt;
    &lt;span&gt;except&lt;/span&gt;&lt;span&gt; tf.errors.OutOfRangeError:
        &lt;/span&gt;&lt;span&gt;print&lt;/span&gt;(&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;complete&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;)
    &lt;/span&gt;&lt;span&gt;finally&lt;/span&gt;&lt;span&gt;:
        coord.request_stop()
    coord.join(threads)
    sess.close()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span&gt;注意：tf.train.batch这个函数的实现是使用queue，需要使用tf.initialize_local_variables()，如果使用tf.global_varialbes_initialize()时，会报： Attempting to use uninitialized value 。并不是tf.initialize_local_variables()替换了tf.global_varialbes_initialize()，而是他们有不同的功能，并要的时候都要使用&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;batch的使用方法，实现感知机。&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; onclick=&quot;cnblogs_code_show('45c31ab1-03d4-4695-95ec-13abeba8e6cc')&quot; readability=&quot;53&quot;&gt;&lt;img id=&quot;code_img_closed_45c31ab1-03d4-4695-95ec-13abeba8e6cc&quot; class=&quot;code_img_closed&quot; src=&quot;https://images.cnblogs.com/OutliningIndicators/ContractedBlock.gif&quot; alt=&quot;&quot;/&gt;&lt;img id=&quot;code_img_opened_45c31ab1-03d4-4695-95ec-13abeba8e6cc&quot; class=&quot;code_img_opened&quot; onclick=&quot;cnblogs_code_hide('45c31ab1-03d4-4695-95ec-13abeba8e6cc',event)&quot; src=&quot;https://images.cnblogs.com/OutliningIndicators/ExpandedBlockStart.gif&quot; alt=&quot;&quot;/&gt;&lt;div id=&quot;cnblogs_code_open_45c31ab1-03d4-4695-95ec-13abeba8e6cc&quot; class=&quot;cnblogs_code_hide&quot; readability=&quot;101&quot;&gt;
&lt;pre&gt;
&lt;span&gt;import&lt;/span&gt;&lt;span&gt; tensorflow as tf
&lt;/span&gt;&lt;span&gt;import&lt;/span&gt;&lt;span&gt; scipy.io as sio


&lt;/span&gt;&lt;span&gt;def&lt;/span&gt;&lt;span&gt; get_Batch(data, label, batch_size):
    &lt;/span&gt;&lt;span&gt;print&lt;/span&gt;&lt;span&gt;(data.shape, label.shape)
    input_queue &lt;/span&gt;= tf.train.slice_input_producer([data, label], num_epochs=1, shuffle=True, capacity=32&lt;span&gt;)
    x_batch, y_batch &lt;/span&gt;= tf.train.batch(input_queue, batch_size=batch_size, num_threads=1, capacity=32&lt;span&gt;,
                                      allow_smaller_final_batch&lt;/span&gt;=&lt;span&gt;False)
    &lt;/span&gt;&lt;span&gt;return&lt;/span&gt;&lt;span&gt; x_batch, y_batch


data &lt;/span&gt;= sio.loadmat(&lt;span&gt;'&lt;/span&gt;&lt;span&gt;data.mat&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;)
train_x &lt;/span&gt;= data[&lt;span&gt;'&lt;/span&gt;&lt;span&gt;train_x&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;]
train_y &lt;/span&gt;= data[&lt;span&gt;'&lt;/span&gt;&lt;span&gt;train_y&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;]
test_x &lt;/span&gt;= data[&lt;span&gt;'&lt;/span&gt;&lt;span&gt;test_x&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;]
test_y &lt;/span&gt;= data[&lt;span&gt;'&lt;/span&gt;&lt;span&gt;test_y&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;]

x &lt;/span&gt;= tf.placeholder(tf.float32, [None, 10&lt;span&gt;])
y &lt;/span&gt;= tf.placeholder(tf.float32, [None, 2&lt;span&gt;])

w &lt;/span&gt;= tf.Variable(tf.truncated_normal([10, 2], stddev=0.1&lt;span&gt;))
b &lt;/span&gt;= tf.Variable(tf.truncated_normal([2], stddev=0.1&lt;span&gt;))
pred &lt;/span&gt;= tf.nn.softmax(tf.matmul(x, w) +&lt;span&gt; b)

loss &lt;/span&gt;= tf.reduce_mean(-tf.reduce_sum(y * tf.log(pred), reduction_indices=[1&lt;span&gt;]))
optimizer &lt;/span&gt;= tf.train.AdamOptimizer(2e-5&lt;span&gt;).minimize(loss)
correct_prediction &lt;/span&gt;= tf.equal(tf.argmax(y, 1), tf.argmax(pred, 1&lt;span&gt;))
accuracy &lt;/span&gt;= tf.reduce_mean(tf.cast(correct_prediction, tf.float32), name=&lt;span&gt;'&lt;/span&gt;&lt;span&gt;evaluation&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;)

x_batch, y_batch &lt;/span&gt;= get_Batch(train_x, train_y, 1000&lt;span&gt;)
&lt;/span&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt; 训练&lt;/span&gt;
&lt;span&gt;with tf.Session() as sess:
    &lt;/span&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt; 初始化参数&lt;/span&gt;
&lt;span&gt;    sess.run(tf.global_variables_initializer())
    sess.run(tf.local_variables_initializer())
    &lt;/span&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt; 开启协调器&lt;/span&gt;
    coord =&lt;span&gt; tf.train.Coordinator()
    &lt;/span&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt; 使用start_queue_runners 启动队列填充&lt;/span&gt;
    threads =&lt;span&gt; tf.train.start_queue_runners(sess, coord)
    epoch &lt;/span&gt;=&lt;span&gt; 0
    &lt;/span&gt;&lt;span&gt;try&lt;/span&gt;&lt;span&gt;:
        &lt;/span&gt;&lt;span&gt;while&lt;/span&gt; &lt;span&gt;not&lt;/span&gt;&lt;span&gt; coord.should_stop():
            &lt;/span&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt; 获取训练用的每一个batch中batch_size个样本和标签&lt;/span&gt;
            data, label =&lt;span&gt; sess.run([x_batch, y_batch])
            sess.run(optimizer, feed_dict&lt;/span&gt;=&lt;span&gt;{x: data, y: label})
            train_accuracy &lt;/span&gt;=&lt;span&gt; accuracy.eval({x: data, y: label})
            test_accuracy &lt;/span&gt;=&lt;span&gt; accuracy.eval({x: test_x, y: test_y})
            &lt;/span&gt;&lt;span&gt;print&lt;/span&gt;(&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;Epoch %d, Training accuracy %g, Testing accuracy %g&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; %&lt;span&gt; (epoch, train_accuracy, test_accuracy))
            epoch &lt;/span&gt;= epoch + 1
    &lt;span&gt;except&lt;/span&gt; tf.errors.OutOfRangeError:  &lt;span&gt;#&lt;/span&gt;&lt;span&gt; num_epochs 次数用完会抛出此异常&lt;/span&gt;
        &lt;span&gt;print&lt;/span&gt;(&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;---Train end---&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;)
    &lt;/span&gt;&lt;span&gt;finally&lt;/span&gt;&lt;span&gt;:
        &lt;/span&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt; 协调器coord发出所有线程终止信号&lt;/span&gt;
&lt;span&gt;        coord.request_stop()
        &lt;/span&gt;&lt;span&gt;print&lt;/span&gt;(&lt;span&gt;'&lt;/span&gt;&lt;span&gt;---Programm end---&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;)
    coord.join(threads)  &lt;/span&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt; 把开启的线程加入主线程，等待threads结束&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;span class=&quot;cnblogs_code_collapse&quot;&gt;View Code&lt;/span&gt;&lt;/div&gt;


&lt;p&gt;&lt;span&gt;官方推荐用tf.data.Dateset，看到这个是不是有点心累，哈哈哈。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;Tensorflow中之前主要用的数据读取方式主要有&lt;/strong&gt;：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;1、建立placeholder，然后使用feed_dict将数据feed进placeholder进行使用。使用这种方法十分灵活，可以一下子将所有数据读入内存，然后分batch进行feed；也可以建立一个Python的generator，一个batch一个batch的将数据读入，并将其feed进placeholder。这种方法很直观，用起来也比较方便灵活jian，但是这种方法的效率较低，难以满足高速计算的需求。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;2、使用TensorFlow的QueueRunner，通过一系列的Tensor操作，将磁盘上的数据分批次读入并送入模型进行使用。这种方法效率很高，但因为其牵涉到Tensor操作，不够直观，也不方便调试，所有有时候会显得比较困难。使用这种方法时，常用的一些操作包括tf.TextLineReader，tf.FixedLengthRecordReader以及tf.decode_raw等等。如果需要循环，条件操作，还需要使用TensorFlow的tf.while_loop，tf.case等操作。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;3、上面的方法我觉得已经要被tensorflow放弃了，现在官方推荐用tf.data.Dataset模块，使其数据读入的操作变得更为方便，而支持多线程（进程）的操作，也在效率上获得了一定程度的提高。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1433301/201909/1433301-20190905005310365-1766627881.png&quot; alt=&quot;&quot;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h2&gt;&lt;span&gt;tf.data.Dataset.from_tensor_slices&lt;/span&gt;&lt;/h2&gt;
&lt;p&gt;&lt;span&gt;创建了一个dataset，这个dataset中含有5个元素&lt;/span&gt;&lt;code class=&quot;language-python3&quot;&gt;&lt;span class=&quot;p&quot;&gt;[&lt;span class=&quot;mf&quot;&gt;1.0&lt;span class=&quot;p&quot;&gt;, &lt;span class=&quot;mf&quot;&gt;2.0&lt;span class=&quot;p&quot;&gt;, &lt;span class=&quot;mf&quot;&gt;3.0&lt;span class=&quot;p&quot;&gt;, &lt;span class=&quot;mf&quot;&gt;4.0&lt;span class=&quot;p&quot;&gt;, &lt;span class=&quot;mf&quot;&gt;5.0&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;span&gt;，为了将5个元素取出，方法是从Dataset中示例化一个iterator，然后对iterator进行迭代。&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;40&quot;&gt;
&lt;pre&gt;
&lt;span&gt;import&lt;/span&gt;&lt;span&gt; tensorflow as tf
&lt;/span&gt;&lt;span&gt;import&lt;/span&gt;&lt;span&gt; numpy as np

dataset &lt;/span&gt;= tf.data.Dataset.from_tensor_slices(np.array([1.0, 2.0, 3.0, 4.0, 5.0&lt;span&gt;]))
iterator &lt;/span&gt;= dataset.make_one_shot_iterator()  &lt;span&gt;#&lt;/span&gt;&lt;span&gt; 从dataset中实例化一个iterator，只能从头到尾取一次,指名了顺序&lt;/span&gt;
one_element = iterator.get_next()  &lt;span&gt;#&lt;/span&gt;&lt;span&gt; 从iterator中取一个元素&lt;/span&gt;
&lt;span&gt;with tf.Session() as sess:
    &lt;/span&gt;&lt;span&gt;try&lt;/span&gt;&lt;span&gt;:
        &lt;/span&gt;&lt;span&gt;for&lt;/span&gt; i &lt;span&gt;in&lt;/span&gt; range(5&lt;span&gt;):
            &lt;/span&gt;&lt;span&gt;print&lt;/span&gt;&lt;span&gt;(sess.run(one_element))
    &lt;/span&gt;&lt;span&gt;except&lt;/span&gt; tf.errors.OutOfRangeError:   &lt;span&gt;#&lt;/span&gt;&lt;span&gt; iterator迭代完会抛出此异常&lt;/span&gt;
        &lt;span&gt;print&lt;/span&gt;(&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;数据迭代完了&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;)
&lt;/pre&gt;&lt;/div&gt;

&lt;div class=&quot;cnblogs_code&quot; readability=&quot;33&quot;&gt;
&lt;pre&gt;
dataset = tf.data.Dataset.from_tensor_slices(np.random.uniform(size=(5, 2)))
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;数据的第一维度是个数，这个函数会切分第一维度，最后生成的dataset中含有5个元素，每个元素的形状是（2，）&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;39&quot;&gt;
&lt;pre&gt;
dataset =&lt;span&gt; tf.data.Dataset.from_tensor_slices(
    {
        &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;a&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: np.array([1.0, 2.0, 3.0, 4.0, 5.0&lt;span&gt;]),                                       
        &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;b&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: np.random.uniform(size=(5, 2&lt;span&gt;))
    })&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span&gt;tf.data.Dataset.from_tensor_slices的参数，可以是列表也可以是字典，{&quot;image&quot;: &quot;image_tensor&quot;, &quot;label&quot;: &quot;label_tensor&quot;}&lt;/span&gt;&lt;/p&gt;
&lt;h2&gt;&lt;span&gt;Trainformation&lt;/span&gt;&lt;/h2&gt;
&lt;p&gt;&lt;span&gt;　　Dataset支持一类特殊的操作Trainformation，即一个Dataset通过Trainformation变成一个新的Dataset，可以理解为数据变换，对Dataset中的元素做变换（打乱、生成epoch...等操作）。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;常用的Trainformation有：&lt;/span&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;map&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span&gt;batch&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span&gt;shuffle&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span&gt;repeat&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;span&gt;1、&lt;span&gt;&lt;strong&gt;dataset.map&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　这个函数很重要也经常用到，他接收一个函数，Dataset中的每一个元素都会被当做这个函数的输入，并将函数返回值作为新的Dataset，&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;例如：对dataset中每一个元素的值加1&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;41&quot;&gt;
&lt;pre&gt;
dataset = tf.data.Dataset.from_tensor_slices(np.array([1.0, 2.0, 3.0, 4.0, 5.0&lt;span&gt;]))
dataset &lt;/span&gt;= dataset.map(&lt;span&gt;lambda&lt;/span&gt; x: x + 1) &lt;span&gt;#&lt;/span&gt;&lt;span&gt; 2.0, 3.0, 4.0, 5.0, 6.0&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span&gt;2、&lt;strong&gt;dataset.batch &lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　batch就是将多个元素组合成batch，如下面的程序将dataset中的每个元素组成了大小为6的batch:&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;34&quot;&gt;
&lt;pre&gt;
&lt;span&gt;#&lt;/span&gt;&lt;span&gt; 创建0-10的数据集，每个6个数取一个batch。&lt;/span&gt;
dataset = tf.data.Dataset.range(10).&lt;span&gt;batch&lt;/span&gt;(6&lt;span&gt;)
iterator &lt;/span&gt;=&lt;span&gt; dataset.make_one_shot_iterator()
next_element &lt;/span&gt;=&lt;span&gt; iterator.get_next()

with tf.Session() as sess:
    &lt;/span&gt;&lt;span&gt;for&lt;/span&gt; i &lt;span&gt;in&lt;/span&gt; range(2&lt;span&gt;):
        value &lt;/span&gt;=&lt;span&gt; sess.run(next_element)
        &lt;/span&gt;&lt;span&gt;print&lt;/span&gt;&lt;span&gt;(value)
&lt;/span&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt; [0 1 2 3 4 5]&lt;/span&gt;&lt;span&gt;
#&lt;/span&gt;&lt;span&gt; [6 7 8 9]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span&gt;tensorflow很好的帮我们自动处理最后的一个batch，但是，上面的for循环次数超过2，会报错，超过范围了，没值可取。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;4、&lt;strong&gt;datasets.repeat &lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　repeat的功能就是将整个序列重复多次，主要用来处理机器学习中的epoch，假设原先的数据是一个epoch，使用repeat(5)就可以将之变成5个epoch，当for循环取值超过一个epoch的时候，会开始下一个epoch。&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;34&quot;&gt;
&lt;pre&gt;
dataset = tf.data.Dataset.range(10).batch(6&lt;span&gt;)
dataset &lt;/span&gt;= dataset.&lt;span&gt;repeat&lt;/span&gt;(2&lt;span&gt;)
iterator &lt;/span&gt;=&lt;span&gt; dataset.make_one_shot_iterator()
next_element &lt;/span&gt;=&lt;span&gt; iterator.get_next()

with tf.Session() as sess:
    &lt;/span&gt;&lt;span&gt;for&lt;/span&gt; i &lt;span&gt;in&lt;/span&gt; range(4&lt;span&gt;):
        value &lt;/span&gt;=&lt;span&gt; sess.run(next_element)
        &lt;/span&gt;&lt;span&gt;print&lt;/span&gt;&lt;span&gt;(value)
&lt;/span&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt; [0 1 2 3 4 5]&lt;/span&gt;&lt;span&gt;
#&lt;/span&gt;&lt;span&gt; [6 7 8 9]&lt;/span&gt;&lt;span&gt;
#&lt;/span&gt;&lt;span&gt; [0 1 2 3 4 5]&lt;/span&gt;&lt;span&gt;
#&lt;/span&gt;&lt;span&gt; [6 7 8 9]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span&gt;repeat只是将数据集重复了指定的次数，但是如果for循环大于4还是会报错，所以简单的方法是repeat不设次数，生成的序列就会无限重复下去，没有结束，因此也不会抛出tf.errors.OutOfRangeError异常：&lt;/span&gt;&lt;code&gt;dataset = dataset.repeat()&lt;/code&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;35&quot;&gt;
&lt;pre&gt;
dataset = tf.data.Dataset.range(10).batch(6&lt;span&gt;)
dataset &lt;/span&gt;=&lt;span&gt; dataset.repeat()
iterator &lt;/span&gt;=&lt;span&gt; dataset.make_one_shot_iterator()
next_element &lt;/span&gt;=&lt;span&gt; iterator.get_next()

with tf.Session() as sess:
    &lt;/span&gt;&lt;span&gt;for&lt;/span&gt; i &lt;span&gt;in&lt;/span&gt; range(6&lt;span&gt;):
        value &lt;/span&gt;=&lt;span&gt; sess.run(next_element)
        &lt;/span&gt;&lt;span&gt;print&lt;/span&gt;&lt;span&gt;(value)
&lt;/span&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt; [0 1 2 3 4 5]&lt;/span&gt;&lt;span&gt;
#&lt;/span&gt;&lt;span&gt; [6 7 8 9]&lt;/span&gt;&lt;span&gt;
#&lt;/span&gt;&lt;span&gt; [0 1 2 3 4 5]&lt;/span&gt;&lt;span&gt;
#&lt;/span&gt;&lt;span&gt; [6 7 8 9]&lt;/span&gt;&lt;span&gt;
#&lt;/span&gt;&lt;span&gt; [0 1 2 3 4 5]&lt;/span&gt;&lt;span&gt;
#&lt;/span&gt;&lt;span&gt; [6 7 8 9]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;3、&lt;strong&gt;dataset.shuffle &lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;　　打乱dataset中的元素，它有一个参数buffer_size表示打乱顺序，buffer_size=1表示不打乱顺序，buffer_size越大，打乱程度越大，不设置会报错：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;32&quot;&gt;
&lt;pre&gt;
dataset = dataset.shuffle(buffer_size=10000)
&lt;/pre&gt;&lt;/div&gt;
&lt;p class=&quot;prettyprint&quot;&gt;shuffle打乱顺序很重要，建议先打乱顺序，再batch取值，因为如果是先执行batch操作的话，那么此时就只是对batch进行shuffle，而batch里面的数据顺序依旧是有序的，那么随机程度会减弱。&lt;/p&gt;
&lt;p class=&quot;prettyprint&quot;&gt;&lt;span&gt;　　建议：dataset = tf.data.Dataset.range(10).&lt;span&gt;shuffle(10).batch(6)&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h2 id=&quot;读入磁盘图片与对应label&quot;&gt;&lt;span&gt;读入磁盘图片与对应label&lt;/span&gt;&lt;/h2&gt;
&lt;p&gt;&lt;span&gt;我们可以来考虑一个简单，但同时也非常常用的例子：读入磁盘中的图片和图片相应的label，并将其打乱，组成batch_size=32的训练样本。在训练时重复10个epoch。 &lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;48&quot;&gt;
&lt;pre&gt;
&lt;span&gt;#&lt;/span&gt;&lt;span&gt; 函数的功能时将filename对应的图片文件读进来，并缩放到统一的大小&lt;/span&gt;
&lt;span&gt;def&lt;/span&gt;&lt;span&gt; _parse_function(filename, label):
    image_string &lt;/span&gt;=&lt;span&gt; tf.read_file(filename)
    image_decoded &lt;/span&gt;=&lt;span&gt; tf.image.decode_image(image_string)
    image_resized &lt;/span&gt;= tf.image.resize_images(image_decoded, [28, 28&lt;span&gt;])
    &lt;/span&gt;&lt;span&gt;return&lt;/span&gt;&lt;span&gt; image_resized, label


&lt;/span&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt; 图片文件的列表&lt;/span&gt;
filenames = tf.constant([&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;/var/data/image1.jpg&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;, &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;/var/data/image2.jpg&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;, ...])
&lt;/span&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt; label[i]就是图片filenames[i]的label&lt;/span&gt;
labels = tf.constant([0, 37&lt;span&gt;, ...])

&lt;/span&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt; filename是图片的文件名，label是图片对应的标签&lt;/span&gt;
dataset =&lt;span&gt; tf.data.Dataset.from_tensor_slices((filenames, labels))

&lt;/span&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt; 将filename对应的图片读入，并缩放为28x28的大小，&lt;/span&gt;
dataset =&lt;span&gt; dataset.map(_parse_function)

&lt;/span&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt; 在每个epoch内将图片打乱组成大小为32的batch，并重复10次。&lt;/span&gt;&lt;span&gt;
#&lt;/span&gt;&lt;span&gt; image_resized_batch(32, 28, 28, 3)，label_batch(32, )&lt;/span&gt;
dataset = dataset.shuffle(buffer_size=1000).batch(32).repeat(10)
&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id=&quot;dataset的其他创建方法&quot;&gt;&lt;span&gt;Dataset的其他创建方法&lt;/span&gt;&lt;/h2&gt;
&lt;p&gt;&lt;span&gt;除了tf.data.Dataset.from_tensor_slices外，目前Dataset API还提供了另外三种创建Dataset的方式：&lt;/span&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;span&gt;&lt;strong&gt;tf.data.TextLineDataset()&lt;/strong&gt;：这个函数的输入是一个文件的列表，输出是一个dataset。dataset中的每一个元素就对应了文件中的一行。可以使用这个函数来读入CSV文件。&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span&gt;&lt;strong&gt;tf.data.FixedLengthRecordDataset()&lt;/strong&gt;：这个函数的输入是一个文件的列表和一个record_bytes，之后dataset的每一个元素就是文件中固定字节数record_bytes的内容。通常用来读取以二进制形式保存的文件，如CIFAR10数据集就是这种形式。&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span&gt;&lt;strong&gt;tf.data.TFRecordDataset()&lt;/strong&gt;：顾名思义，这个函数是用来读TFRecord文件的，dataset中的每一个元素就是一个TFExample。&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;h2 id=&quot;更多类型的iterator&quot;&gt;&lt;span&gt;iterator&lt;/span&gt;&lt;/h2&gt;
&lt;p&gt;&lt;span&gt;在非Eager模式下，最简单的创建Iterator的方法就是通过dataset.make_one_shot_iterator()来创建一个one_shot_&lt;strong&gt;iterator&lt;/strong&gt;。除了这种iterator外，还有三个更复杂的Iterator，即：&lt;/span&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;span&gt;make_initializable_iterator&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span&gt;make_reinitializable_iterator&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span&gt;make_feedable_iterator &lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;span&gt;initializable_iterator必须要在使用前通过sess.run()来初始化。使用initializable iterator，可以将placeholder-feed_dict代入Iterator中，这可以方便我们通过参数快速定义新的Iterator。一个简单的initializable_iterator使用示例:&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;38&quot;&gt;
&lt;pre&gt;
limit = tf.placeholder(dtype=tf.int32, shape=&lt;span&gt;[])
&lt;/span&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt; 此时的limit相当于一个“可变参数”，它规定了Dataset中数的“上限”。&lt;/span&gt;
dataset = tf.data.Dataset.from_tensor_slices(tf.range(start=0, limit=&lt;span&gt;limit))
iterator &lt;/span&gt;=&lt;span&gt; dataset.make_initializable_iterator()
next_element &lt;/span&gt;=&lt;span&gt; iterator.get_next()

with tf.Session() as sess:
    &lt;/span&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt; 初始化并feed initializable_iterator&lt;/span&gt;
    sess.run(iterator.initializer, feed_dict={limit: 10&lt;span&gt;})
    &lt;/span&gt;&lt;span&gt;for&lt;/span&gt; i &lt;span&gt;in&lt;/span&gt; range(10&lt;span&gt;):
      value &lt;/span&gt;=&lt;span&gt; sess.run(next_element)
      &lt;/span&gt;&lt;span&gt;assert&lt;/span&gt; i == value
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span&gt;initializable_iterator还有一个功能：读入较大的数组。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;在使用tf.data.Dataset.from_tensor_slices(array)时，实际上发生的事情是将array作为一个tf.constants保存到了计算图中。当array很大时，会导致计算图变得很大，给传输、保存带来不便。这时，我们可以用一个placeholder取代这里的array，并使用initializable_iterator，只在需要时将array传进去，这样就可以避免把大数组保存在图里，示例代码为（来自官方例程）：&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;43&quot;&gt;
&lt;pre&gt;
&lt;span&gt;#&lt;/span&gt;&lt;span&gt; 读取numpy数据&lt;/span&gt;
with np.load(&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;/var/data/training_data.npy&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;) as data:
  features &lt;/span&gt;= data[&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;features&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;]
  labels &lt;/span&gt;= data[&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;labels&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;]

&lt;/span&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt; 查看图像和标签维度是否保持一致&lt;/span&gt;
&lt;span&gt;assert&lt;/span&gt; features.shape[0] ==&lt;span&gt; labels.shape[0]

&lt;/span&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt; 创建placeholder&lt;/span&gt;
features_placeholder =&lt;span&gt; tf.placeholder(features.dtype, features.shape)
labels_placeholder &lt;/span&gt;=&lt;span&gt; tf.placeholder(labels.dtype, labels.shape)

&lt;/span&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt; 创建dataset&lt;/span&gt;
dataset =&lt;span&gt; tf.data.Dataset.from_tensor_slices((features_placeholder, labels_placeholder))

&lt;/span&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt; 批量读取,打散数据,repeat()&lt;/span&gt;
dataset = dataset.shuffle(20).batch(5&lt;span&gt;).repeat()

&lt;/span&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt; [Other transformations on `dataset`...]&lt;/span&gt;
dataset_other =&lt;span&gt; ...

iterator &lt;/span&gt;=&lt;span&gt; dataset.make_initializable_iterator()
data_element &lt;/span&gt;=&lt;span&gt; iterator.get_nex()

sess &lt;/span&gt;=&lt;span&gt; tf.Session()
&lt;/span&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt; 注意迭代器要在循环语句之前初始化&lt;/span&gt;
sess.run(iterator.initializer, feed_dict=&lt;span&gt;{features_placeholder: features,
                                          labels_placeholder: labels})

&lt;/span&gt;&lt;span&gt;for&lt;/span&gt; e &lt;span&gt;in&lt;/span&gt;&lt;span&gt; range(EPOCHS):
    &lt;/span&gt;&lt;span&gt;for&lt;/span&gt; step &lt;span&gt;in&lt;/span&gt;&lt;span&gt; range(num_batches):
        x_batch, y_batch &lt;/span&gt;=&lt;span&gt; sess.run(data_element)
        y_pred &lt;/span&gt;=&lt;span&gt; model(x_batch)
        ...
...

sess.close()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;上面几种方法，都是官方可调用的方法，如果大家想自定义可以参考我的代码，这段代码是从tensorflow教程中偷来的。代码太长我的折叠起来了哈，这段代码大家可以直接拿去用（亲测可用）。&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; onclick=&quot;cnblogs_code_show('4e334de8-8549-4ff2-adca-de5e9c4d9055')&quot; readability=&quot;44&quot;&gt;&lt;img id=&quot;code_img_closed_4e334de8-8549-4ff2-adca-de5e9c4d9055&quot; class=&quot;code_img_closed&quot; src=&quot;https://images.cnblogs.com/OutliningIndicators/ContractedBlock.gif&quot; alt=&quot;&quot;/&gt;&lt;img id=&quot;code_img_opened_4e334de8-8549-4ff2-adca-de5e9c4d9055&quot; class=&quot;code_img_opened&quot; onclick=&quot;cnblogs_code_hide('4e334de8-8549-4ff2-adca-de5e9c4d9055',event)&quot; src=&quot;https://images.cnblogs.com/OutliningIndicators/ExpandedBlockStart.gif&quot; alt=&quot;&quot;/&gt;&lt;div id=&quot;cnblogs_code_open_4e334de8-8549-4ff2-adca-de5e9c4d9055&quot; class=&quot;cnblogs_code_hide&quot; readability=&quot;83&quot;&gt;
&lt;pre&gt;
&lt;span&gt;import&lt;/span&gt;&lt;span&gt; numpy as np
&lt;/span&gt;&lt;span&gt;from&lt;/span&gt; tensorflow.contrib.learn.python.learn.datasets &lt;span&gt;import&lt;/span&gt;&lt;span&gt; base
&lt;/span&gt;&lt;span&gt;from&lt;/span&gt; tensorflow.python.framework &lt;span&gt;import&lt;/span&gt;&lt;span&gt; dtypes


&lt;/span&gt;&lt;span&gt;class&lt;/span&gt;&lt;span&gt; DataSet(object):

    &lt;/span&gt;&lt;span&gt;def&lt;/span&gt; &lt;span&gt;__init__&lt;/span&gt;&lt;span&gt;(self,
                 datapoints,
                 labels,
                 fake_data&lt;/span&gt;=&lt;span&gt;False,
                 one_hot&lt;/span&gt;=&lt;span&gt;False,
                 dtype&lt;/span&gt;=&lt;span&gt;dtypes.float32):
        &lt;/span&gt;&lt;span&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span&gt;Construct a DataSet.
        one_hot arg is used only if fake_data is true.  `dtype` can be either
        `uint8` to leave the input as `[0, 255]`, or `float32` to rescale into
        `[0, 1]`.
        &lt;/span&gt;&lt;span&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span&gt;
        dtype &lt;/span&gt;=&lt;span&gt; dtypes.as_dtype(dtype).base_dtype
        &lt;/span&gt;&lt;span&gt;if&lt;/span&gt; dtype &lt;span&gt;not&lt;/span&gt; &lt;span&gt;in&lt;/span&gt;&lt;span&gt; (dtypes.uint8, dtypes.float32):
            &lt;/span&gt;&lt;span&gt;raise&lt;/span&gt; TypeError(&lt;span&gt;'&lt;/span&gt;&lt;span&gt;Invalid image dtype %r, expected uint8 or float32&lt;/span&gt;&lt;span&gt;'&lt;/span&gt; %&lt;span&gt;
                            dtype)

        &lt;/span&gt;&lt;span&gt;if&lt;/span&gt; labels &lt;span&gt;is&lt;/span&gt;&lt;span&gt; None:
            labels &lt;/span&gt;=&lt;span&gt; np.zeros((len(datapoints),))

        &lt;/span&gt;&lt;span&gt;if&lt;/span&gt;&lt;span&gt; fake_data:
            self._num_examples &lt;/span&gt;= 10000&lt;span&gt;
            self.one_hot &lt;/span&gt;=&lt;span&gt; one_hot
        &lt;/span&gt;&lt;span&gt;else&lt;/span&gt;&lt;span&gt;:
            &lt;/span&gt;&lt;span&gt;assert&lt;/span&gt; datapoints.shape[0] ==&lt;span&gt; labels.shape[0], (
                    &lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;datapoints.shape: %s labels.shape: %s&lt;/span&gt;&lt;span&gt;'&lt;/span&gt; %&lt;span&gt; (datapoints.shape, labels.shape))
            self._num_examples &lt;/span&gt;=&lt;span&gt; datapoints.shape[0]

        self._datapoints &lt;/span&gt;=&lt;span&gt; datapoints
        self._labels &lt;/span&gt;=&lt;span&gt; labels
        self._epochs_completed &lt;/span&gt;=&lt;span&gt; 0
        self._index_in_epoch &lt;/span&gt;=&lt;span&gt; 0

    @property
    &lt;/span&gt;&lt;span&gt;def&lt;/span&gt;&lt;span&gt; datapoints(self):
        &lt;/span&gt;&lt;span&gt;return&lt;/span&gt;&lt;span&gt; self._datapoints

    @property
    &lt;/span&gt;&lt;span&gt;def&lt;/span&gt;&lt;span&gt; labels(self):
        &lt;/span&gt;&lt;span&gt;return&lt;/span&gt;&lt;span&gt; self._labels

    @property
    &lt;/span&gt;&lt;span&gt;def&lt;/span&gt;&lt;span&gt; num_examples(self):
        &lt;/span&gt;&lt;span&gt;return&lt;/span&gt;&lt;span&gt; self._num_examples

    @property
    &lt;/span&gt;&lt;span&gt;def&lt;/span&gt;&lt;span&gt; epochs_completed(self):
        &lt;/span&gt;&lt;span&gt;return&lt;/span&gt;&lt;span&gt; self._epochs_completed

    &lt;/span&gt;&lt;span&gt;def&lt;/span&gt; next_batch(self, batch_size, fake_data=False, shuffle=&lt;span&gt;True):
        &lt;/span&gt;&lt;span&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span&gt;Return the next `batch_size` examples from this data set.&lt;/span&gt;&lt;span&gt;&quot;&quot;&quot;&lt;/span&gt;
        &lt;span&gt;if&lt;/span&gt;&lt;span&gt; fake_data:
            fake_image &lt;/span&gt;= [1] * 784
            &lt;span&gt;if&lt;/span&gt;&lt;span&gt; self.one_hot:
                fake_label &lt;/span&gt;= [1] + [0] * 9
            &lt;span&gt;else&lt;/span&gt;&lt;span&gt;:
                fake_label &lt;/span&gt;=&lt;span&gt; 0
            &lt;/span&gt;&lt;span&gt;return&lt;/span&gt; [fake_image &lt;span&gt;for&lt;/span&gt; _ &lt;span&gt;in&lt;/span&gt;&lt;span&gt; range(batch_size)], [
                fake_label &lt;/span&gt;&lt;span&gt;for&lt;/span&gt; _ &lt;span&gt;in&lt;/span&gt;&lt;span&gt; range(batch_size)
            ]
        start &lt;/span&gt;=&lt;span&gt; self._index_in_epoch
        &lt;/span&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt; Shuffle for the first epoch&lt;/span&gt;
        &lt;span&gt;if&lt;/span&gt; self._epochs_completed == 0 &lt;span&gt;and&lt;/span&gt; start == 0 &lt;span&gt;and&lt;/span&gt;&lt;span&gt; shuffle:
            perm0 &lt;/span&gt;=&lt;span&gt; np.arange(self._num_examples)
            np.random.shuffle(perm0)
            self._datapoints &lt;/span&gt;=&lt;span&gt; self.datapoints[perm0]
            self._labels &lt;/span&gt;=&lt;span&gt; self.labels[perm0]
        &lt;/span&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt; Go to the next epoch&lt;/span&gt;
        &lt;span&gt;if&lt;/span&gt; start + batch_size &amp;gt; self._num_examples:     &lt;span&gt;#&lt;/span&gt;&lt;span&gt; 如果初始epoch+batch_size(0+128)&amp;gt;样本总数&lt;/span&gt;
            &lt;span&gt;#&lt;/span&gt;&lt;span&gt; Finished epoch&lt;/span&gt;
            self._epochs_completed += 1
            &lt;span&gt;#&lt;/span&gt;&lt;span&gt; Get the rest examples in this epoch&lt;/span&gt;
            rest_num_examples = self._num_examples -&lt;span&gt; start
            datapoints_rest_part &lt;/span&gt;=&lt;span&gt; self._datapoints[start:self._num_examples]
            labels_rest_part &lt;/span&gt;=&lt;span&gt; self._labels[start:self._num_examples]
            &lt;/span&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt; Shuffle the data&lt;/span&gt;
            &lt;span&gt;if&lt;/span&gt;&lt;span&gt; shuffle:
                perm &lt;/span&gt;=&lt;span&gt; np.arange(self._num_examples)
                np.random.shuffle(perm)
                self._datapoints &lt;/span&gt;=&lt;span&gt; self.datapoints[perm]
                self._labels &lt;/span&gt;=&lt;span&gt; self.labels[perm]
            &lt;/span&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt; Start next epoch&lt;/span&gt;
            start =&lt;span&gt; 0
            self._index_in_epoch &lt;/span&gt;= batch_size -&lt;span&gt; rest_num_examples
            end &lt;/span&gt;=&lt;span&gt; self._index_in_epoch
            datapoints_new_part &lt;/span&gt;=&lt;span&gt; self._datapoints[start:end]
            labels_new_part &lt;/span&gt;=&lt;span&gt; self._labels[start:end]
            &lt;/span&gt;&lt;span&gt;return&lt;/span&gt; np.concatenate((datapoints_rest_part, datapoints_new_part), axis=&lt;span&gt;0), np.concatenate(
                (labels_rest_part, labels_new_part), axis&lt;/span&gt;=&lt;span&gt;0)
        &lt;/span&gt;&lt;span&gt;else&lt;/span&gt;&lt;span&gt;:
            self._index_in_epoch &lt;/span&gt;+=&lt;span&gt; batch_size
            end &lt;/span&gt;=&lt;span&gt; self._index_in_epoch
            &lt;/span&gt;&lt;span&gt;return&lt;/span&gt; self._datapoints[start:end], self._labels[start:end]
&lt;/pre&gt;&lt;/div&gt;
&lt;span class=&quot;cnblogs_code_collapse&quot;&gt;View Code&lt;/span&gt;&lt;/div&gt;
&lt;p&gt;想要真正弄懂建议自己写一个，虽然上面那个已经写的非常完美了。&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;要求1：每一个epoch之后都要shuff数据，&lt;/li&gt;
&lt;li&gt;要求2：训练数据集不用去batch_size的整数。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt; 打乱顺序&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;41&quot;&gt;
&lt;pre&gt;
&lt;span&gt;def&lt;/span&gt;&lt;span&gt; shuffle_set(train_image, train_label, test_image, test_label):
    train_row &lt;/span&gt;=&lt;span&gt; range(len(train_label))
    random.shuffle(train_row)
    train_image &lt;/span&gt;=&lt;span&gt; train_image[train_row]
    train_label &lt;/span&gt;=&lt;span&gt; train_label[train_row]
    
    test_row &lt;/span&gt;=&lt;span&gt; range(len(test_label))
    random.shuffle(test_row)
    test_image &lt;/span&gt;=&lt;span&gt; test_image[test_row]
    test_label &lt;/span&gt;=&lt;span&gt; test_label[test_row]
    &lt;/span&gt;&lt;span&gt;return&lt;/span&gt; train_image, train_label, test_image, test_label
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt; 取下一个batch&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;40&quot;&gt;
&lt;pre&gt;
&lt;span&gt;def&lt;/span&gt;&lt;span&gt; get_batch(image, label, batch_size, now_batch, total_batch):
    &lt;/span&gt;&lt;span&gt;if&lt;/span&gt; now_batch &amp;lt; total_batch-1&lt;span&gt;:
        image_batch &lt;/span&gt;= image[now_batch*batch_size:(now_batch+1)*&lt;span&gt;batch_size]
        label_batch &lt;/span&gt;= label[now_batch*batch_size:(now_batch+1)*&lt;span&gt;batch_size]
    &lt;/span&gt;&lt;span&gt;else&lt;/span&gt;&lt;span&gt;:
        image_batch &lt;/span&gt;= image[now_batch*&lt;span&gt;batch_size:]
        label_batch &lt;/span&gt;= label[now_batch*&lt;span&gt;batch_size:]
    &lt;/span&gt;&lt;span&gt;return&lt;/span&gt; image_batch, label_batch
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;epoch、 iteration和batchsize的区别：epoch是周期的意思，代表要重复训练epoch次，每个epoch包括样本数/batch个iteration&lt;/p&gt;

&lt;p&gt;本文主要介绍了tensortlfow三种读取数据方式的，placehold-feed_dict，queue队列还介绍了Dataset API的基本架构：Dataset类和Iterator类，以及它们的基础使用方法。 &lt;/p&gt;
&lt;p&gt;在非Eager模式下，Dataset中读出的一个元素一般对应一个batch的Tensor，我们可以使用这个Tensor在计算图中构建模型。 &lt;br/&gt;在Eager模式下，Dataset建立Iterator的方式有所不同，此时通过读出的数据就是含有值的Tensor，方便调试。&lt;/p&gt;

&lt;p class=&quot;title-article&quot;&gt;&lt;a href=&quot;https://blog.csdn.net/sinat_35821976/article/details/82668555&quot; target=&quot;_blank&quot;&gt;Tensorflow将自己的数据分割成batch训练&lt;/a&gt;&lt;/p&gt;
&lt;p class=&quot;title-article&quot;&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/30751039&quot; target=&quot;_blank&quot;&gt;何之源的知乎文章：Dataset API入门教程&lt;/a&gt;&lt;/p&gt;
</description>
<pubDate>Mon, 16 Sep 2019 00:55:00 +0000</pubDate>
<dc:creator>凌逆战</dc:creator>
<og:description>tensortlfow数据读取有三种方式 placehold feed_dict：从内存中读取数据，占位符填充数据 queue队列：从硬盘读取数据 Dataset：同时支持内存和硬盘读取数据 plac</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/LXP-Never/p/11460000.html</dc:identifier>
</item>
<item>
<title>使用Quarkus在Openshift上构建微服务的快速指南 - 锅外的大佬</title>
<link>http://www.cnblogs.com/liululee/p/11525469.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/liululee/p/11525469.html</guid>
<description>&lt;p&gt;在我的博客上，您有机会阅读了许多关于使用Spring Boot或Micronaut之类框架构建微服务的文章。这里将介绍另一个非常有趣的框架专门用于微服务体系结构，它越来越受到大家的关注– &lt;a href=&quot;https://quarkus.io/&quot;&gt;&lt;strong&gt;Quarkus&lt;/strong&gt;&lt;/a&gt;。它是作为下一代Kubernetes/Openshift原生Java框架引入的。它构建在著名的Java标准之上，如CDI、JAX-RS和Eclipse MicroProfile，这些标准将它与Spring Boot区别开来。&lt;/p&gt;
&lt;p&gt;其他一些可能说服您使用Quarkus的特性包括非常快的启动时间、为在容器中运行而优化的最小内存占用，以及较短的首次请求时间。此外，尽管它是一个相对较新的框架(当前版本是0.21)，但它有很多扩展，包括Hibernate、Kafka、RabbitMQ、Openapi和Vert.x等等。&lt;/p&gt;
&lt;p&gt;在本文中，我将指导您使用Quarkus构建微服务，并在OpenShift(通过Minishift)上运行它们。我们将讨论以下主题:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;构建基于rest的且包含输入校验的应用程序&lt;/li&gt;
&lt;li&gt;微服务与RestClient之间的通信&lt;/li&gt;
&lt;li&gt;开放健康检查(liveness, readiness)&lt;/li&gt;
&lt;li&gt;开放OpenAPI /Swagger 文档&lt;/li&gt;
&lt;li&gt;使用Quarkus Maven插件在本地机器上运行应用程序&lt;/li&gt;
&lt;li&gt;使用JUnit和RestAssured进行测试&lt;/li&gt;
&lt;li&gt;使用source-2镜像在Minishift上部署和运行Quarkus应用程序&lt;/li&gt;
&lt;/ul&gt;&lt;h3 id=&quot;创建应用程序---依赖项&quot;&gt;1. 创建应用程序 - 依赖项&lt;/h3&gt;
&lt;p&gt;在创建新应用程序时，你可以执行一个Maven命令，该命令使用&lt;code&gt;quarkus-maven-plugin&lt;/code&gt;。依赖项应该在参数&lt;code&gt;-Dextensions&lt;/code&gt;中声明。&lt;/p&gt;
&lt;pre class=&quot;shell&quot;&gt;
&lt;code&gt;mvn io.quarkus:quarkus-maven-plugin:0.21.1:create \
    -DprojectGroupId=pl.piomin.services \
    -DprojectArtifactId=employee-service \
    -DclassName=&quot;pl.piomin.services.employee.controller.EmployeeController&quot; \
    -Dpath=&quot;/employees&quot; \
    -Dextensions=&quot;resteasy-jackson, hibernate-validator&quot;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;下面是我们&lt;code&gt;pom.xml&lt;/code&gt;的结构:&lt;/p&gt;
&lt;pre class=&quot;xml&quot;&gt;
&lt;code&gt;&amp;lt;properties&amp;gt;
    &amp;lt;quarkus.version&amp;gt;0.21.1&amp;lt;/quarkus.version&amp;gt;
    &amp;lt;project.build.sourceEncoding&amp;gt;UTF-8&amp;lt;/project.build.sourceEncoding&amp;gt;
    &amp;lt;maven.compiler.source&amp;gt;11&amp;lt;/maven.compiler.source&amp;gt;
    &amp;lt;maven.compiler.target&amp;gt;11&amp;lt;/maven.compiler.target&amp;gt;
&amp;lt;/properties&amp;gt;
&amp;lt;dependencyManagement&amp;gt;
    &amp;lt;dependencies&amp;gt;
        &amp;lt;dependency&amp;gt;
            &amp;lt;groupId&amp;gt;io.quarkus&amp;lt;/groupId&amp;gt;
            &amp;lt;artifactId&amp;gt;quarkus-bom&amp;lt;/artifactId&amp;gt;
            &amp;lt;version&amp;gt;${quarkus.version}&amp;lt;/version&amp;gt;
            &amp;lt;type&amp;gt;pom&amp;lt;/type&amp;gt;
            &amp;lt;scope&amp;gt;import&amp;lt;/scope&amp;gt;
        &amp;lt;/dependency&amp;gt;
    &amp;lt;/dependencies&amp;gt;
&amp;lt;/dependencyManagement&amp;gt;
&amp;lt;build&amp;gt;
    &amp;lt;plugins&amp;gt;
        &amp;lt;plugin&amp;gt;
            &amp;lt;groupId&amp;gt;io.quarkus&amp;lt;/groupId&amp;gt;
            &amp;lt;artifactId&amp;gt;quarkus-maven-plugin&amp;lt;/artifactId&amp;gt;
            &amp;lt;version&amp;gt;${quarkus.version}&amp;lt;/version&amp;gt;
            &amp;lt;executions&amp;gt;
                &amp;lt;execution&amp;gt;
                    &amp;lt;goals&amp;gt;
                        &amp;lt;goal&amp;gt;build&amp;lt;/goal&amp;gt;
                    &amp;lt;/goals&amp;gt;
                &amp;lt;/execution&amp;gt;
            &amp;lt;/executions&amp;gt;
        &amp;lt;/plugin&amp;gt;
    &amp;lt;/plugins&amp;gt;
&amp;lt;/build&amp;gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;对于使用输入验证构建简单的REST应用程序，我们不需要太多模块。您可能已经注意到，我只声明了两个扩展，这与下面&lt;code&gt;pom.xml&lt;/code&gt;中的依赖项列表相同:&lt;/p&gt;
&lt;pre class=&quot;xml&quot;&gt;
&lt;code&gt;&amp;lt;dependency&amp;gt;
    &amp;lt;groupId&amp;gt;io.quarkus&amp;lt;/groupId&amp;gt;
    &amp;lt;artifactId&amp;gt;quarkus-resteasy-jackson&amp;lt;/artifactId&amp;gt;
&amp;lt;/dependency&amp;gt;
&amp;lt;dependency&amp;gt;
    &amp;lt;groupId&amp;gt;io.quarkus&amp;lt;/groupId&amp;gt;
    &amp;lt;artifactId&amp;gt;quarkus-hibernate-validator&amp;lt;/artifactId&amp;gt;
&amp;lt;/dependency&amp;gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;创建应用程序---代码&quot;&gt;2. 创建应用程序 - 代码&lt;/h3&gt;
&lt;p&gt;对于Spring Boot或Micronaut用户来说，可能有点奇怪的是，没有使用静态代码main方法的主运行类。resource/controller类实际上就是主类。Quarkus的resource/controller类和方法应该使用&lt;code&gt;javax.ws.rs&lt;/code&gt;库中的注解进行标记。&lt;/p&gt;
&lt;p&gt;下面是employee-service的REST controller 的实现:&lt;/p&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;@Path(&quot;/employees&quot;)
@Produces(MediaType.APPLICATION_JSON)
public class EmployeeController {

    private static final Logger LOGGER = LoggerFactory.getLogger(EmployeeController.class);

    @Inject
    EmployeeRepository repository;

    @POST
    public Employee add(@Valid Employee employee) {
        LOGGER.info(&quot;Employee add: {}&quot;, employee);
        return repository.add(employee);
    }

    @Path(&quot;/{id}&quot;)
    @GET
    public Employee findById(@PathParam(&quot;id&quot;) Long id) {
        LOGGER.info(&quot;Employee find: id={}&quot;, id);
        return repository.findById(id);
    }

    @GET
    public Set&amp;lt;Employee&amp;gt; findAll() {
        LOGGER.info(&quot;Employee find&quot;);
        return repository.findAll();
    }

    @Path(&quot;/department/{departmentId}&quot;)
    @GET
    public Set&amp;lt;Employee&amp;gt; findByDepartment(@PathParam(&quot;departmentId&quot;) Long departmentId) {
        LOGGER.info(&quot;Employee find: departmentId={}&quot;, departmentId);
        return repository.findByDepartment(departmentId);
    }

    @Path(&quot;/organization/{organizationId}&quot;)
    @GET
    public Set&amp;lt;Employee&amp;gt; findByOrganization(@PathParam(&quot;organizationId&quot;) Long organizationId) {
        LOGGER.info(&quot;Employee find: organizationId={}&quot;, organizationId);
        return repository.findByOrganization(organizationId);
    }

}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;我们使用CDI进行依赖注入，使用SLF4J进行日志记录。 Controller类使用内存存储库bean存储和检索数据。Repository bean使用CDI &lt;code&gt;@ApplicationScoped&lt;/code&gt;注解，并注入controller:&lt;/p&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;@ApplicationScoped
public class EmployeeRepository {

    private Set&amp;lt;Employee&amp;gt; employees = new HashSet&amp;lt;&amp;gt;();

    public EmployeeRepository() {
        add(new Employee(1L, 1L, &quot;John Smith&quot;, 30, &quot;Developer&quot;));
        add(new Employee(1L, 1L, &quot;Paul Walker&quot;, 40, &quot;Architect&quot;));
    }

    public Employee add(Employee employee) {
        employee.setId((long) (employees.size()+1));
        employees.add(employee);
        return employee;
    }

    public Employee findById(Long id) {
        Optional&amp;lt;Employee&amp;gt; employee = employees.stream().filter(a -&amp;gt; a.getId().equals(id)).findFirst();
        if (employee.isPresent())
            return employee.get();
        else
            return null;
    }

    public Set&amp;lt;Employee&amp;gt; findAll() {
        return employees;
    }

    public Set&amp;lt;Employee&amp;gt; findByDepartment(Long departmentId) {
        return employees.stream().filter(a -&amp;gt; a.getDepartmentId().equals(departmentId)).collect(Collectors.toSet());
    }

    public Set&amp;lt;Employee&amp;gt; findByOrganization(Long organizationId) {
        return employees.stream().filter(a -&amp;gt; a.getOrganizationId().equals(organizationId)).collect(Collectors.toSet());
    }

}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;最后一个组件是带验证的实体类:&lt;/p&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;public class Employee {

    private Long id;
    @NotNull
    private Long organizationId;
    @NotNull
    private Long departmentId;
    @NotBlank
    private String name;
    @Min(1)
    @Max(100)
    private int age;
    @NotBlank
    private String position;

    // ... GETTERS AND SETTERS

}&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;单元测试&quot;&gt;3. 单元测试&lt;/h3&gt;
&lt;p&gt;对于大多数流行的Java框架，使用Quarkus进行单元测试非常简单。如果您正在测试基于REST的web应用程序，您应该在&lt;code&gt;pom.xml&lt;/code&gt;中包含以下依赖项:&lt;/p&gt;
&lt;pre class=&quot;xml&quot;&gt;
&lt;code&gt;&amp;lt;dependency&amp;gt;
    &amp;lt;groupId&amp;gt;io.quarkus&amp;lt;/groupId&amp;gt;
    &amp;lt;artifactId&amp;gt;quarkus-junit5&amp;lt;/artifactId&amp;gt;
    &amp;lt;scope&amp;gt;test&amp;lt;/scope&amp;gt;
&amp;lt;/dependency&amp;gt;
&amp;lt;dependency&amp;gt;
    &amp;lt;groupId&amp;gt;io.rest-assured&amp;lt;/groupId&amp;gt;
    &amp;lt;artifactId&amp;gt;rest-assured&amp;lt;/artifactId&amp;gt;
    &amp;lt;scope&amp;gt;test&amp;lt;/scope&amp;gt;
&amp;lt;/dependency&amp;gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;让我们分析一下来自organization-service(我们的另一个微服务，以及employee-service和department-service)的测试类。测试类应该用&lt;code&gt;@QuarkusTest&lt;/code&gt;注释。我们可以通过&lt;code&gt;@Inject&lt;/code&gt;注解注入其他bean。其余部分是典型的JUnit和RestAssured—我们正在测试controller公开的API方法。因为我们使用内存存储库，所以除了服务间通信之外，我们不需要模拟任何东西(我们将在本文后面讨论)。对于GET、POST方法，我们有一些积极的场景，还有一个不通过输入验证的消极场景(&lt;code&gt;testInvalidAdd&lt;/code&gt;)。&lt;/p&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;@QuarkusTest
public class OrganizationControllerTests {

    @Inject
    OrganizationRepository repository;

    @Test
    public void testFindAll() {
        given().when().get(&quot;/organizations&quot;).then().statusCode(200).body(notNullValue());
    }

    @Test
    public void testFindById() {
        Organization organization = new Organization(&quot;Test3&quot;, &quot;Address3&quot;);
        organization = repository.add(organization);
        given().when().get(&quot;/organizations/{id}&quot;, organization.getId()).then().statusCode(200)
                .body(&quot;id&quot;, equalTo(organization.getId().intValue()))
                .body(&quot;name&quot;, equalTo(organization.getName()));
    }

    @Test
    public void testFindByIdWithDepartments() {
        given().when().get(&quot;/organizations/{id}/with-departments&quot;, 1L).then().statusCode(200)
                .body(notNullValue())
                .body(&quot;departments.size()&quot;, is(1));
    }

    @Test
    public void testAdd() {
        Organization organization = new Organization(&quot;Test5&quot;, &quot;Address5&quot;);
        given().contentType(&quot;application/json&quot;).body(organization)
                .when().post(&quot;/organizations&quot;).then().statusCode(200)
                .body(&quot;id&quot;, notNullValue())
                .body(&quot;name&quot;, equalTo(organization.getName()));
    }

    @Test
    public void testInvalidAdd() {
        Organization organization = new Organization();
        given().contentType(&quot;application/json&quot;).body(organization).when().post(&quot;/organizations&quot;).then().statusCode(400);
    }

}&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;服务间通信&quot;&gt;4. 服务间通信&lt;/h3&gt;
&lt;p&gt;由于Quarkus的目标是在Kubernetes上运行，因此它不提供任何对第三方服务发现(例如通过Consul 或Netflix Eureka)和与此发现集成的HTTP客户机的内置支持。然而，Quarkus为REST通信提供了专用的客户端支持。要使用它，我们首先需要包括以下依赖性:&lt;/p&gt;
&lt;pre class=&quot;xml&quot;&gt;
&lt;code&gt;&amp;lt;dependency&amp;gt;
    &amp;lt;groupId&amp;gt;io.quarkus&amp;lt;/groupId&amp;gt;
    &amp;lt;artifactId&amp;gt;quarkus-rest-client&amp;lt;/artifactId&amp;gt;
&amp;lt;/dependency&amp;gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;Quarkus基于MicroProfile REST客户机提供声明性REST客户机。您需要创建一个带有所需方法的接口，并使用&lt;code&gt;@RegisterRestClient&lt;/code&gt;对其进行注解。其他注解与服务器端非常相似。因为您使用&lt;code&gt;@RegisterRestClient&lt;/code&gt;来标记Quarkus，所以应该知道这个接口作为REST客户机可用于CDI注入。&lt;/p&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;@Path(&quot;/departments&quot;)
@RegisterRestClient
public interface DepartmentClient {

    @GET
    @Path(&quot;/organization/{organizationId}&quot;)
    @Produces(MediaType.APPLICATION_JSON)
    List&amp;lt;Department&amp;gt; findByOrganization(@PathParam(&quot;organizationId&quot;) Long organizationId);

    @GET
    @Path(&quot;/organization/{organizationId}/with-employees&quot;)
    @Produces(MediaType.APPLICATION_JSON)
    List&amp;lt;Department&amp;gt; findByOrganizationWithEmployees(@PathParam(&quot;organizationId&quot;) Long organizationId);

}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;现在，让我们看一下organization-service内的controller类。与&lt;code&gt;@Inject&lt;/code&gt;一起，我们需要使用&lt;code&gt;@RestClient&lt;/code&gt;注解来正确地注入REST客户机bean。之后，您可以使用接口方法来调用其他公开的服务&lt;/p&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;@Path(&quot;/organizations&quot;)
@Produces(MediaType.APPLICATION_JSON)
public class OrganizationController {

    private static final Logger LOGGER = LoggerFactory.getLogger(OrganizationController.class);

    @Inject
    OrganizationRepository repository;
    @Inject
    @RestClient
    DepartmentClient departmentClient;
    @Inject
    @RestClient
    EmployeeClient employeeClient;

    // ... OTHER FIND METHODS

    @Path(&quot;/{id}/with-departments&quot;)
    @GET
    public Organization findByIdWithDepartments(@PathParam(&quot;id&quot;) Long id) {
        LOGGER.info(&quot;Organization find: id={}&quot;, id);
        Organization organization = repository.findById(id);
        organization.setDepartments(departmentClient.findByOrganization(organization.getId()));
        return organization;
    }

    @Path(&quot;/{id}/with-departments-and-employees&quot;)
    @GET
    public Organization findByIdWithDepartmentsAndEmployees(@PathParam(&quot;id&quot;) Long id) {
        LOGGER.info(&quot;Organization find: id={}&quot;, id);
        Organization organization = repository.findById(id);
        organization.setDepartments(departmentClient.findByOrganizationWithEmployees(organization.getId()));
        return organization;
    }

    @Path(&quot;/{id}/with-employees&quot;)
    @GET
    public Organization findByIdWithEmployees(@PathParam(&quot;id&quot;) Long id) {
        LOGGER.info(&quot;Organization find: id={}&quot;, id);
        Organization organization = repository.findById(id);
        organization.setEmployees(employeeClient.findByOrganization(organization.getId()));
        return organization;
    }

}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;通信中缺少的最后一个东西是目标服务的地址。我们可以使用&lt;code&gt;@RegisterRestClient&lt;/code&gt;注解的字段&lt;code&gt;baseUri&lt;/code&gt; 来提供它们。然而，更好的解决方案似乎是将它们放在&lt;code&gt;application.properties&lt;/code&gt;中。属性名需要包含客户端接口的完全限定名和后缀&lt;code&gt;mp-rest/url&lt;/code&gt;。&lt;/p&gt;
&lt;pre class=&quot;properties&quot;&gt;
&lt;code&gt;pl.piomin.services.organization.client.DepartmentClient/mp-rest/url=http://localhost:8090
pl.piomin.services.organization.client.EmployeeClient/mp-rest/url=http://localhost:8080&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;在前一节中，我已经提到了单元测试和服务间通信。要测试与其他应用程序通信的API方法，我们需要模拟REST客户机。下面是为模拟示例创建了&lt;code&gt;DepartmentClient&lt;/code&gt;。它应该只在测试期间可见，所以我们必须将它放在&lt;code&gt;src/test/java&lt;/code&gt;中。如果我们用&lt;code&gt;@Mock&lt;/code&gt; 和&lt;code&gt;@RestClient&lt;/code&gt;注释它，那么默认情况下将自动使用这个bean，而不是在&lt;code&gt;src/main/java&lt;/code&gt;中定义的声明性REST客户机。&lt;/p&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;@Mock
@ApplicationScoped
@RestClient
public class MockDepartmentClient implements DepartmentClient {

    @Override
    public List&amp;lt;Department&amp;gt; findByOrganization(Long organizationId) {
        return Collections.singletonList(new Department(&quot;Test1&quot;));
    }

    @Override
    public List&amp;lt;Department&amp;gt; findByOrganizationWithEmployees(Long organizationId) {
        return null;
    }

}&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;监测和记录&quot;&gt;5. 监测和记录&lt;/h3&gt;
&lt;p&gt;我们可以轻松地使用Quarkus公开健康检查或API文档。API文档是使用OpenAPI/Swagger构建的。Quarkus利用了 &lt;a href=&quot;https://smallrye.io/projects/&quot;&gt;SmallRye&lt;/a&gt;项目中可用的库。我们应该在&lt;code&gt;pom.xml&lt;/code&gt;中包含以下依赖项:&lt;/p&gt;
&lt;pre class=&quot;xml&quot;&gt;
&lt;code&gt;&amp;lt;dependency&amp;gt;
    &amp;lt;groupId&amp;gt;io.quarkus&amp;lt;/groupId&amp;gt;
    &amp;lt;artifactId&amp;gt;quarkus-smallrye-openapi&amp;lt;/artifactId&amp;gt;
&amp;lt;/dependency&amp;gt;
&amp;lt;dependency&amp;gt;
    &amp;lt;groupId&amp;gt;io.quarkus&amp;lt;/groupId&amp;gt;
    &amp;lt;artifactId&amp;gt;quarkus-smallrye-health&amp;lt;/artifactId&amp;gt;
&amp;lt;/dependency&amp;gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;我们可以定义两种类型的健康检查:readiness 和liveness。有&lt;code&gt;/health/ready&lt;/code&gt; 和&lt;code&gt;/health/live&lt;/code&gt;上下文路径。要将它们公开到应用程序之外，我们需要定义一个实现MicroProfile &lt;code&gt;HealthCheck&lt;/code&gt; 接口的bean。Readiness 端应该用&lt;code&gt;@Readiness&lt;/code&gt;标注，而liveness 端应该用&lt;code&gt;@Liveness&lt;/code&gt;标注。&lt;/p&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;@ApplicationScoped
@Readiness
public class ReadinessHealthcheck implements HealthCheck {

    @Override
    public HealthCheckResponse call() {
        return HealthCheckResponse.named(&quot;Employee Health Check&quot;).up().build();
    }

}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;为了启用Swagger文档，我们只需要添加一个依赖项即可。Quarkus还为Swagger提供了内置UI。默认情况下，它是在开发模式下启用的，所以如果您愿意在生产环境中使用它，您应该添加&lt;code&gt;quarkus.swagger-ui.always-include=true&lt;/code&gt;到您的&lt;code&gt;application.properties&lt;/code&gt;文件。现在，如果通过执行Maven命令&lt;code&gt;mvn compile quarkus:dev&lt;/code&gt;在本地以开发模式运行应用程序employee-service，您可以在URLhttp://localhost:8080/swagger-ui下查看可用的API规范。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1692986/201909/1692986-20190916085339310-1373259925.png&quot; alt=&quot;quarkus-swagger&quot;/&gt;&lt;/p&gt;
&lt;p&gt;这是我从应用程序启动时的日志。它打印监听端口和加载的扩展列表。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1692986/201909/1692986-20190916085339677-2088779193.png&quot; alt=&quot;quarkus-startup&quot;/&gt;&lt;/p&gt;
&lt;h3 id=&quot;在本地机器上运行微服务&quot;&gt;6. 在本地机器上运行微服务&lt;/h3&gt;
&lt;p&gt;因为我们希望在同一台机器上运行多个应用程序，所以需要覆盖它们的默认HTTP监听端口。虽然employee-service仍然在默认的&lt;code&gt;8080&lt;/code&gt; 端口上运行，但是其他微服务使用不同的端口，如下所示。&lt;/p&gt;
&lt;p&gt;department-service:&lt;br/&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1692986/201909/1692986-20190916085339972-327819432.png&quot; alt=&quot;quarkus-port-department&quot;/&gt;&lt;/p&gt;
&lt;p&gt;organization-service:&lt;br/&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1692986/201909/1692986-20190916085340251-1259455244.png&quot; alt=&quot;quarkus-port-organization&quot;/&gt;&lt;/p&gt;
&lt;p&gt;让我们测试一下Swagger UI中的服务间通信。我调用了&lt;code&gt;GET /organizations/{id}/with-departments&lt;/code&gt;，它调用由department-service公开的端点GET &lt;code&gt;GET /departments/organization/{organizationId}&lt;/code&gt;。结果如下图所示。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1692986/201909/1692986-20190916085340692-292208386.png&quot; alt=&quot;quarkus-communication&quot;/&gt;&lt;/p&gt;
&lt;h3 id=&quot;在openshift上运行微服务&quot;&gt;7. 在OpenShift上运行微服务&lt;/h3&gt;
&lt;p&gt;我们已经完成了示例微服务体系结构的实现，并在本地机器上运行它们。现在，我们可以进行最后一步，并尝试在 Minishift上部署这些应用程序。在OpenShift上部署Quarkus应用程序时，我们有一些不同的方法。今天，我将向您展示如何利用S2I为此构建的机制。&lt;/p&gt;
&lt;p&gt;我们将使用Quarkus &lt;strong&gt;GraalVM Native S2I Builder&lt;/strong&gt;。可以在 quai.io的 &lt;code&gt;quarkus/ubi-quarkus-native-s2i&lt;/code&gt;找到。当然，在部署应用程序之前，我们需要先启动Minishift。根据Quarkus的文档，基于GraalVM的本机构建占用了大量内存和CPU，所以我决定为Minishift设置6GB和4个内核。&lt;/p&gt;
&lt;pre class=&quot;shell&quot;&gt;
&lt;code&gt;$ minishift start --vm-driver=virtualbox --memor&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;此外，我们还需要稍微修改一下应用程序的源代码。您可能还记得，我们使用JDK 11在本地运行它们。Quarkus S2I builder只支持JDK 8，所以我们需要在&lt;code&gt;pom.xml&lt;/code&gt;中更改它。我们还需要包括一个声明的&lt;code&gt;本机&lt;/code&gt;配置文件如下:&lt;/p&gt;
&lt;pre class=&quot;xml&quot;&gt;
&lt;code&gt;&amp;lt;properties&amp;gt;
    &amp;lt;quarkus.version&amp;gt;0.21.1&amp;lt;/quarkus.version&amp;gt;
    &amp;lt;project.build.sourceEncoding&amp;gt;UTF-8&amp;lt;/project.build.sourceEncoding&amp;gt;
    &amp;lt;maven.compiler.source&amp;gt;1.8&amp;lt;/maven.compiler.source&amp;gt;
    &amp;lt;maven.compiler.target&amp;gt;1.8&amp;lt;/maven.compiler.target&amp;gt;
&amp;lt;/properties&amp;gt;
...
&amp;lt;profiles&amp;gt;
    &amp;lt;profile&amp;gt;
        &amp;lt;id&amp;gt;native&amp;lt;/id&amp;gt;
        &amp;lt;activation&amp;gt;
            &amp;lt;property&amp;gt;
                &amp;lt;name&amp;gt;native&amp;lt;/name&amp;gt;
            &amp;lt;/property&amp;gt;
        &amp;lt;/activation&amp;gt;
        &amp;lt;build&amp;gt;
            &amp;lt;plugins&amp;gt;
                &amp;lt;plugin&amp;gt;
                    &amp;lt;groupId&amp;gt;io.quarkus&amp;lt;/groupId&amp;gt;
                    &amp;lt;artifactId&amp;gt;quarkus-maven-plugin&amp;lt;/artifactId&amp;gt;
                    &amp;lt;version&amp;gt;${quarkus.version}&amp;lt;/version&amp;gt;
                    &amp;lt;executions&amp;gt;
                        &amp;lt;execution&amp;gt;
                            &amp;lt;goals&amp;gt;
                                &amp;lt;goal&amp;gt;native-image&amp;lt;/goal&amp;gt;
                            &amp;lt;/goals&amp;gt;
                            &amp;lt;configuration&amp;gt;
                                &amp;lt;enableHttpUrlHandler&amp;gt;true&amp;lt;/enableHttpUrlHandler&amp;gt;
                            &amp;lt;/configuration&amp;gt;
                        &amp;lt;/execution&amp;gt;
                    &amp;lt;/executions&amp;gt;
                &amp;lt;/plugin&amp;gt;
                &amp;lt;plugin&amp;gt;
                    &amp;lt;artifactId&amp;gt;maven-failsafe-plugin&amp;lt;/artifactId&amp;gt;
                    &amp;lt;version&amp;gt;2.22.1&amp;lt;/version&amp;gt;
                    &amp;lt;executions&amp;gt;
                        &amp;lt;execution&amp;gt;
                            &amp;lt;goals&amp;gt;
                                &amp;lt;goal&amp;gt;integration-test&amp;lt;/goal&amp;gt;
                                &amp;lt;goal&amp;gt;verify&amp;lt;/goal&amp;gt;
                            &amp;lt;/goals&amp;gt;
                            &amp;lt;configuration&amp;gt;
                                &amp;lt;systemProperties&amp;gt;
                                    &amp;lt;native.image.path&amp;gt;${project.build.directory}/${project.build.finalName}-runner&amp;lt;/native.image.path&amp;gt;
                                &amp;lt;/systemProperties&amp;gt;
                            &amp;lt;/configuration&amp;gt;
                        &amp;lt;/execution&amp;gt;
                    &amp;lt;/executions&amp;gt;
                &amp;lt;/plugin&amp;gt;
            &amp;lt;/plugins&amp;gt;
        &amp;lt;/build&amp;gt;
    &amp;lt;/profile&amp;gt;
&amp;lt;/profiles&amp;gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;另外在&lt;code&gt;application.properties&lt;/code&gt;文件需要修改两处。我们不需要覆盖端口号，因为 Minishift动态地为每个pod分配虚拟IP。服务间的通信是通过OpenShift发现实现的，所以我们只需要设置服务的名称而不是localhost。&lt;/p&gt;
&lt;pre class=&quot;properties&quot;&gt;
&lt;code&gt;quarkus.swagger-ui.always-include=true
pl.piomin.services.organization.client.DepartmentClient/mp-rest/url=http://department:8080
pl.piomin.services.organization.client.EmployeeClient/mp-rest/url=http://employee:8080&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;最后，我们可以将我们的应用程序部署到Minishift上。为此，你应使用&lt;code&gt;oc&lt;/code&gt;客户端执行以下命令:&lt;/p&gt;
&lt;pre class=&quot;shell&quot;&gt;
&lt;code&gt;$ oc new-app quay.io/quarkus/ubi-quarkus-native-s2i:19.1.1~https://github.com/piomin/sample-quarkus-microservices.git#openshift --context-dir=employee --name=employee
$ oc new-app quay.io/quarkus/ubi-quarkus-native-s2i:19.1.1~https://github.com/piomin/sample-quarkus-microservices.git#openshift --context-dir=department --name=department
$ oc new-app quay.io/quarkus/ubi-quarkus-native-s2i:19.1.1~https://github.com/piomin/sample-quarkus-microservices.git#openshift --context-dir=organization --name=organization&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;正如您所看到的，可以在我的GitHub帐户上找到找到程序源代码，地址是https://github.com/piomin/sample-quarkus-microservices.git。在Minishift 上运行的版本已经在分支&lt;strong&gt;openshift&lt;/strong&gt;中共享。在本地机器上运行的版本在&lt;strong&gt;主分支&lt;/strong&gt;上可用。因为所有的应用程序都存储在一个库中，所以我们需要为每个部署定义一个参数&lt;code&gt;context-dir&lt;/code&gt; 。&lt;/p&gt;
&lt;p&gt;我很失望。虽然为minishift 设置更多的内存和CPU花费了我很长的时间——大约25分钟。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1692986/201909/1692986-20190916085341072-1191079264.png&quot; alt=&quot;quarkus-builds&quot;/&gt;&lt;/p&gt;
&lt;p&gt;然而，经过长时间的等待，我的所有应用程序终于都部署好了。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1692986/201909/1692986-20190916085341587-2054572558.png&quot; alt=&quot;quarkus-openshift-overview&quot;/&gt;&lt;/p&gt;
&lt;p&gt;我通过执行下面可见的命令将它们公开在Minishift 外。可以使用DNS &lt;code&gt;http://${APP_NAME}-myproject.192.168.99.100.nip.io&lt;/code&gt;下的OpenShift路由测试它们。&lt;/p&gt;
&lt;pre class=&quot;shell&quot;&gt;
&lt;code&gt;$ oc expose svc employee
$ oc expose svc department
$ oc expose svc organization&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;此外，您还可以在OpenShift上启用readiness 和liveness 健康检查，因为它们在默认情况下是禁用的。&lt;/p&gt;
&lt;h2 id=&quot;quarkus-health&quot;&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1692986/201909/1692986-20190916085342093-1911312907.png&quot; alt=&quot;quarkus-health&quot;/&gt;&lt;/h2&gt;
&lt;p&gt;9月福利，关注公众号&lt;br/&gt;​&lt;br/&gt;后台回复：004，领取8月翻译集锦!&lt;br/&gt;​&lt;br/&gt;往期福利回复：001，002, 003即可领取！&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1692986/201909/1692986-20190916085343962-1673398687.jpg&quot; alt=&quot;img&quot;/&gt;&lt;/p&gt;
</description>
<pubDate>Mon, 16 Sep 2019 00:54:00 +0000</pubDate>
<dc:creator>锅外的大佬</dc:creator>
<og:description>在我的博客上，您有机会阅读了许多关于使用Spring Boot或Micronaut之类框架构建微服务的文章。这里将介绍另一个非常有趣的框架专门用于微服务体系结构，它越来越受到大家的关注– ' Quar</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/liululee/p/11525469.html</dc:identifier>
</item>
<item>
<title>Spring Cloud同步场景分布式事务怎样做？试试Seata - zlt2000</title>
<link>http://www.cnblogs.com/zlt2000/p/11525417.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/zlt2000/p/11525417.html</guid>
<description>&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1769816/201909/1769816-20190916083303992-259461945.jpg&quot; alt=&quot;file&quot;/&gt;&lt;/p&gt;
&lt;h2 id=&quot;一概述&quot;&gt;一、概述&lt;/h2&gt;
&lt;p&gt;在微服务架构下，虽然我们会尽量避免分布式事务，但是只要业务复杂的情况下这是一个绕不开的问题，如何保证业务数据一致性呢？本文主要介绍同步场景下使用&lt;code&gt;Seata&lt;/code&gt;的&lt;code&gt;AT模式&lt;/code&gt;来解决一致性问题。&lt;/p&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;&lt;code&gt;Seata&lt;/code&gt;是 &lt;strong&gt;阿里巴巴&lt;/strong&gt; 开源的 &lt;strong&gt;一站式分布式事务解决方案&lt;/strong&gt; 中间件，以 &lt;strong&gt;高效&lt;/strong&gt; 并且对业务 &lt;strong&gt;0 侵入&lt;/strong&gt; 的方式，解决 &lt;strong&gt;微服务&lt;/strong&gt; 场景下面临的分布式事务问题&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;二seata介绍&quot;&gt;二、Seata介绍&lt;/h2&gt;
&lt;p&gt;整体事务逻辑是基于 &lt;strong&gt;两阶段提交&lt;/strong&gt; 的模型，核心概念包括以下3个角色：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;TM&lt;/strong&gt;：事务的发起者。用来告诉 TC，全局事务的开始，提交，回滚。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;RM&lt;/strong&gt;：具体的事务资源，每一个 RM 都会作为一个分支事务注册在 TC。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;TC&lt;/strong&gt;：事务的协调者seata-server，用于接收我们的事务的注册，提交和回滚。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;目前的&lt;code&gt;Seata&lt;/code&gt;有两种模式可使用分别对应不同业务场景&lt;/p&gt;
&lt;h3 id=&quot;at模式&quot;&gt;2.1. AT模式&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;该模式适合的场景：&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;基于支持本地 &lt;code&gt;ACID&lt;/code&gt; 事务的关系型数据库。&lt;/li&gt;
&lt;li&gt;Java 应用，通过 &lt;code&gt;JDBC&lt;/code&gt; 访问数据库。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1769816/201909/1769816-20190916083304314-715995967.jpg&quot; alt=&quot;file&quot;/&gt;&lt;/p&gt;
&lt;p&gt; &lt;br/&gt;&lt;strong&gt;一个典型的分布式事务过程：&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;&lt;code&gt;TM&lt;/code&gt; 向 &lt;code&gt;TC&lt;/code&gt; 申请开启一个全局事务，全局事务创建成功并生成一个全局唯一的 &lt;code&gt;XID&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;XID&lt;/code&gt; 在微服务调用链路的上下文中传播。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;RM&lt;/code&gt; 向 &lt;code&gt;TC&lt;/code&gt; 注册分支事务，将其纳入 XID 对应全局事务的管辖。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;TM&lt;/code&gt; 向 &lt;code&gt;TC&lt;/code&gt; 发起针对 &lt;code&gt;XID&lt;/code&gt; 的全局提交或回滚决议。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;TC&lt;/code&gt; 调度 &lt;code&gt;XID&lt;/code&gt; 下管辖的全部分支事务完成提交或回滚请求。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&quot;mt模式&quot;&gt;2.2. MT模式&lt;/h3&gt;
&lt;p&gt;该模式逻辑类似&lt;code&gt;TCC&lt;/code&gt;，需要 &lt;strong&gt;自定义实现&lt;/strong&gt; &lt;code&gt;prepare&lt;/code&gt;、&lt;code&gt;commit&lt;/code&gt;和&lt;code&gt;rollback&lt;/code&gt;的逻辑，适合 &lt;strong&gt;非关系型数据库&lt;/strong&gt; 的场景&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1769816/201909/1769816-20190916083304608-323600104.jpg&quot; alt=&quot;file&quot;/&gt;&lt;/p&gt;

&lt;h2 id=&quot;三seata场景样例&quot;&gt;三、Seata场景样例&lt;/h2&gt;
&lt;p&gt;模拟一个简单的用户下单场景，4个子工程分别是 &lt;strong&gt;Bussiness(事务发起者)&lt;/strong&gt;、&lt;strong&gt;Order(创建订单)&lt;/strong&gt;、&lt;strong&gt;Storage(扣减库存)&lt;/strong&gt; 和 &lt;strong&gt;Account(扣减账户余额)&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1769816/201909/1769816-20190916083304877-2102171627.jpg&quot; alt=&quot;file&quot;/&gt;&lt;/p&gt;
&lt;h3 id=&quot;部署seata的server端&quot;&gt;3.1. 部署Seata的Server端&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1769816/201909/1769816-20190916083305131-1681048296.jpg&quot; alt=&quot;file&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Discover&lt;/code&gt;注册、&lt;code&gt;Config&lt;/code&gt;配置和&lt;code&gt;Store&lt;/code&gt;存储模块默认都是使用&lt;code&gt;file&lt;/code&gt;只能适用于单机，我们安装的时候分别改成使用&lt;code&gt;nacos&lt;/code&gt;和&lt;code&gt;Mysql&lt;/code&gt;以支持server端集群&lt;/p&gt;
&lt;h4 id=&quot;下载最新版本并解压&quot;&gt;3.1.1. 下载最新版本并解压&lt;/h4&gt;
&lt;p&gt;https://github.com/seata/seata/releases&lt;/p&gt;

&lt;h4 id=&quot;修改-confregistry.conf-配置&quot;&gt;3.1.2. 修改 conf/registry.conf 配置&lt;/h4&gt;
&lt;p&gt;注册中心和配置中心默认是&lt;code&gt;file&lt;/code&gt;这里改为&lt;code&gt;nacos&lt;/code&gt;；设置 &lt;strong&gt;registry&lt;/strong&gt; 和 &lt;strong&gt;config&lt;/strong&gt; 节点中的&lt;code&gt;type&lt;/code&gt;为&lt;code&gt;nacos&lt;/code&gt;，修改&lt;code&gt;serverAddr&lt;/code&gt;为你的&lt;code&gt;nacos&lt;/code&gt;节点地址。&lt;/p&gt;
&lt;pre class=&quot;json&quot;&gt;
&lt;code&gt;registry {
  type = &quot;nacos&quot;

  nacos {
    serverAddr = &quot;192.168.28.130&quot;
    namespace = &quot;public&quot;
    cluster = &quot;default&quot;
  }
}

config {
  type = &quot;nacos&quot;

  nacos {
    serverAddr = &quot;192.168.28.130&quot;
    namespace = &quot;public&quot;
    cluster = &quot;default&quot;
  }
}&lt;/code&gt;
&lt;/pre&gt;

&lt;h4 id=&quot;修改-confnacos-config.txt配置&quot;&gt;3.1.3. 修改 conf/nacos-config.txt配置&lt;/h4&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1769816/201909/1769816-20190916083305457-809564838.jpg&quot; alt=&quot;file&quot;/&gt;&lt;/p&gt;
&lt;ul readability=&quot;-0.5&quot;&gt;&lt;li readability=&quot;1.5&quot;&gt;
&lt;p&gt;修改 &lt;strong&gt;service.vgroup_mapping&lt;/strong&gt; 为自己应用对应的名称；如果有多个服务，添加相应的配置&lt;/p&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;默认组名为&lt;code&gt;${spring.application.name}-fescar-service-group&lt;/code&gt;，可通过&lt;code&gt;spring.cloud.alibaba.seata.tx-service-group&lt;/code&gt;配置修改&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;修改 &lt;strong&gt;store.mode&lt;/strong&gt; 为&lt;code&gt;db&lt;/code&gt;，并修改数据库相关配置&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&quot;初始化seata的nacos配置&quot;&gt;3.1.4. 初始化seata的nacos配置&lt;/h4&gt;
&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;cd conf
sh nacos-config.sh 192.168.28.130&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;成功后在&lt;code&gt;nacos&lt;/code&gt;的配置列表中能看到&lt;code&gt;seata&lt;/code&gt;的相关配置&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1769816/201909/1769816-20190916083305785-1588215788.jpg&quot; alt=&quot;file&quot;/&gt;&lt;/p&gt;

&lt;h4 id=&quot;初始化数据库&quot;&gt;3.1.5. 初始化数据库&lt;/h4&gt;
&lt;p&gt;执行&lt;code&gt;conf/db_store.sql&lt;/code&gt;中的脚本&lt;/p&gt;

&lt;h4 id=&quot;启动seata-server&quot;&gt;3.1.6. 启动seata-server&lt;/h4&gt;
&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;sh bin/seata-server.sh -p 8091 -h 192.168.28.130&lt;/code&gt;
&lt;/pre&gt;

&lt;h3 id=&quot;应用配置&quot;&gt;3.2. 应用配置&lt;/h3&gt;
&lt;h4 id=&quot;初始化数据库-1&quot;&gt;3.2.1. 初始化数据库&lt;/h4&gt;
&lt;p&gt;执行脚本 &lt;a href=&quot;https://gitee.com/zlt2000/microservices-platform/blob/master/zlt-demo/seata-demo/seata-demo.sql&quot;&gt;seata-demo.sql&lt;/a&gt;&lt;/p&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;需在业务相关的数据库中添加 &lt;strong&gt;undo_log&lt;/strong&gt; 表，用于保存需要回滚的数据&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h4 id=&quot;添加registry.conf配置&quot;&gt;3.2.2. 添加registry.conf配置&lt;/h4&gt;
&lt;p&gt;直接把 &lt;strong&gt;seata-server&lt;/strong&gt; 中的&lt;code&gt;registry.conf&lt;/code&gt;复制到每个服务中去即可，不需要修改&lt;br/&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1769816/201909/1769816-20190916083306011-165490002.jpg&quot; alt=&quot;file&quot;/&gt;&lt;/p&gt;

&lt;h4 id=&quot;修改配置&quot;&gt;3.2.3. 修改配置&lt;/h4&gt;
&lt;p&gt;demo中的每个服务各自修改配置文件&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;bootstrap.yml&lt;/strong&gt; 修改nacos地址&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;application.yml&lt;/strong&gt; 修改数据库配置&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&quot;配置数据源代理&quot;&gt;3.2.4. 配置数据源代理&lt;/h4&gt;
&lt;p&gt;&lt;code&gt;Seata&lt;/code&gt;是通过代理数据源实现分布式事务，所以需要配置&lt;code&gt;io.seata.rm.datasource.DataSourceProxy&lt;/code&gt;的&lt;code&gt;Bean&lt;/code&gt;，且是&lt;code&gt;@Primary&lt;/code&gt;默认的数据源，否则事务不会回滚，无法实现分布式事务&lt;/p&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;public class DataSourceProxyConfig {
    @Bean
    @ConfigurationProperties(prefix = &quot;spring.datasource&quot;)
    public DruidDataSource druidDataSource() {
        return new DruidDataSource();
    }

    @Primary
    @Bean
    public DataSourceProxy dataSourceProxy(DruidDataSource druidDataSource) {
        return new DataSourceProxy(druidDataSource);
    }
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;因为使用了mybatis的starter所以需要排除&lt;code&gt;DataSourceAutoConfiguration&lt;/code&gt;，不然会产生循环依赖&lt;/p&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;@SpringBootApplication(exclude = {DataSourceAutoConfiguration.class})&lt;/code&gt;
&lt;/pre&gt;

&lt;h4 id=&quot;事务发起者添加全局事务注解&quot;&gt;3.2.5. 事务发起者添加全局事务注解&lt;/h4&gt;
&lt;p&gt;事务发起者 &lt;code&gt;business-service&lt;/code&gt; 添加 &lt;code&gt;@GlobalTransactional&lt;/code&gt; 注解&lt;/p&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;@GlobalTransactional
public void placeOrder(String userId) {
    ......
}&lt;/code&gt;
&lt;/pre&gt;

&lt;h3 id=&quot;测试&quot;&gt;3.3. 测试&lt;/h3&gt;
&lt;p&gt;提供两个接口测试&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;事务成功：扣除库存成功 &amp;gt; 创建订单成功 &amp;gt; 扣减账户余额成功&lt;br/&gt;http://localhost:9090/placeOrder&lt;/li&gt;
&lt;li&gt;事务失败：扣除库存成功 &amp;gt; 创建订单成功 &amp;gt; 扣减账户余额失败，事务回滚&lt;br/&gt;http://localhost:9090/placeOrderFallBack&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&quot;demo下载地址&quot;&gt;3.4. demo下载地址&lt;/h3&gt;
&lt;p&gt;&lt;a href=&quot;https://gitee.com/zlt2000/microservices-platform/tree/master/zlt-demo/seata-demo&quot; class=&quot;uri&quot;&gt;https://gitee.com/zlt2000/microservices-platform/tree/master/zlt-demo/seata-demo&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;推荐阅读&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt; &lt;br/&gt;扫码关注有惊喜！&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1769816/201909/1769816-20190916083306371-157355283.png&quot; alt=&quot;file&quot;/&gt;&lt;/p&gt;
</description>
<pubDate>Mon, 16 Sep 2019 00:33:00 +0000</pubDate>
<dc:creator>zlt2000</dc:creator>
<og:description>一、概述 在微服务架构下，虽然我们会尽量避免分布式事务，但是只要业务复杂的情况下这是一个绕不开的问题，如何保证业务数据一致性呢？本文主要介绍同步场景下使用 的`AT模式`来解决一致性问题。 是 阿里巴</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/zlt2000/p/11525417.html</dc:identifier>
</item>
<item>
<title>快速了解TCP的流量控制与拥塞控制 - 全菜工程师小辉</title>
<link>http://www.cnblogs.com/mseddl/p/11525411.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/mseddl/p/11525411.html</guid>
<description>&lt;p&gt;有关TCP你不能不知道的三次握手和四次挥手问题，&lt;a href=&quot;https://www.jianshu.com/p/11add30ee652&quot;&gt;点我跳转&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;滑动窗口&quot;&gt;1. 滑动窗口&lt;/h2&gt;
&lt;p&gt;数据的传送过程中很可能出现接收方来不及接收的情况，这时就需要对发送方进行控制以免数据丢失。利用滑动窗口机制可以很方便地在TCP连接上对发送方的流量进行控制。TCP的窗口单位是字节，不是报文段，发送方的发送窗口不能超过接收方给出的接收窗口的数值。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1327889/201909/1327889-20190916082957814-2134939345.jpg&quot; alt=&quot;TCP滑动窗口&quot;/&gt;&lt;/p&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;TCP规定，即使设置为零窗口，也必须接收以下几种报文段：&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;&lt;li&gt;零窗口探测报文段&lt;/li&gt;
&lt;li&gt;确认报文段&lt;/li&gt;
&lt;li&gt;携带紧急数据的报文段&lt;/li&gt;
&lt;/ul&gt;&lt;h3 id=&quot;确认丢失和确认迟到&quot;&gt;确认丢失和确认迟到&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1327889/201909/1327889-20190916082958921-197691449.png&quot; alt=&quot;确认丢失和确认迟到&quot;/&gt;&lt;/p&gt;
&lt;h3 id=&quot;持续计时器&quot;&gt;持续计时器&lt;/h3&gt;
&lt;p&gt;存在这样一种情况：发送方接收到零窗口报文之后将发送窗口设置为0，停止发送数据。但等到接收方有足够缓存，发送了非零窗口大小的报文，但是这个报文中途丢失，那么发送方的发送窗口就一直为0导致死锁。&lt;br/&gt;为此，TCP为每一个连接设有一个持续计时器(Persistence Timer)：当TCP连接的一方收到对方的零窗口通知时就启动持续计时器。若持续计时器时间到期，就发送一个零窗口探测报文段(携有1字节的数据)，那么收到这个报文段的一方就在确认这个探测报文段时给出了现在的窗口值。若窗口仍然是零，则收到这个报文段的一方就重新设置持续计时器；若窗口不是零，则死锁的僵局就可以打破了。&lt;/p&gt;
&lt;h2 id=&quot;延迟ack&quot;&gt;2. 延迟ACK&lt;/h2&gt;
&lt;p&gt;如果TCP对每个数据包都发送一个ACK确认，那么只是一个单独的数据包为了发送一个ACK代价比较高，所以TCP会延迟一段时间，如果这段时间内有数据发送到对端，则捎带发送ACK，如果在延迟ACK定时器触发时候，发现ACK尚未发送，则立即单独发送；&lt;/p&gt;
&lt;p&gt;延迟ACK好处：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;避免糊涂窗口综合症。&lt;/li&gt;
&lt;li&gt;发送数据的时候将ACK捎带发送，不必单独发送ACK。如果延迟时间内有多个数据段到达，那么允许协议栈发送一个ACK确认多个报文段。减少流量消耗。&lt;/li&gt;
&lt;/ol&gt;&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;糊涂窗口综合症：TCP接收方的缓存已满，而交互式的应用进程一次只从接收缓存中读取1字节（这样就使接收缓存空间仅腾出1字节），然后向发送方发送确认，并把窗口设置为1个字节（但发送的数据报为40字节的的话）。当发送方又发来1个字节的数据（发送方的IP数据报是41字节），接收方发回确认，仍然将窗口设置为1个字节。这样，网络的效率很低。要解决这个问题，可让接收方等待一段时间，使得或者接收缓存已有足够空间容纳一个最长的报文段或者等到接收方缓存已有一半的空闲空间。只要出现这两种情况，接收方就发回确认报文，并向发送方通知当前的窗口大小。此外，发送方也不要发送太小的报文段，而是把数据报积累成足够大的报文段，或达到接收方缓存的空间的一半大小。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;拥塞控制与流量控制的区别 :&lt;br/&gt;拥塞控制是防止过多的数据注入到网络中，可以使网络中的路由器或链路不致过载，是一个全局性的过程。&lt;br/&gt;流量控制是点对点通信量的控制，是一个端到端的问题，主要就是抑制发送端发送数据的速率，以便接收端来得及接收。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;拥塞控制的作用&quot;&gt;拥塞控制的作用&lt;/h2&gt;
&lt;p&gt;拥塞控制是为了防止过多的数据注入到网络中，这样可以使网络中的路由器或者链路不至于过载。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1327889/201909/1327889-20190916082959136-2075329289.png&quot; alt=&quot;拥塞控制的作用&quot;/&gt;&lt;/p&gt;
&lt;h2 id=&quot;拥塞控制的算法&quot;&gt;拥塞控制的算法&lt;/h2&gt;
&lt;p&gt;我们假定:&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;数据单方向传送，而另外一个方向只传送确认。&lt;/li&gt;
&lt;li&gt;接收方总是有足够大的缓存空间，因为发送窗口的大小由网络的拥塞程度来决定。&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;发送方的发送窗口的上限值应当取为接收方窗口rwnd和拥塞窗口cwnd这两个变量中较小的一个，即发送窗口的上限值为Min[rwnd, cwnd]&lt;/p&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;当rwnd &amp;lt; cwnd时，是接收方的接收能力限制发送窗口的最大值&lt;br/&gt;当cwnd &amp;lt; rwnd时，则是网络的拥塞限制发送窗口的最大值&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;拥塞控制的过程一共涉及了4种算法:&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;慢启动&lt;/li&gt;
&lt;li&gt;拥塞避免&lt;/li&gt;
&lt;li&gt;快重传&lt;/li&gt;
&lt;li&gt;快恢复&lt;/li&gt;
&lt;/ol&gt;&lt;h3 id=&quot;慢启动&quot;&gt;1. 慢启动&lt;/h3&gt;
&lt;p&gt;发送方维护一个拥塞窗口cwnd的状态变量，拥塞窗口的大小取决于网络的拥塞程度，动态变化。通过逐渐增加cwnd的大小来探测可用的网络容量，防止连接开始时采用不合适的发送量导致网络拥塞。&lt;/p&gt;
&lt;p&gt;当主机开始发送数据时，如果通过较大的发送窗口立即将全部数据字节都注入到网络中，由于不清楚网络状况，有可能引起网络拥塞。较好的方法是试探，从小到大逐渐增大发送端拥塞窗口的cwnd数值。&lt;/p&gt;
&lt;p&gt;例如：开始发送方先设置cwnd=1，发送第一个报文段M1，接收方接收到M1后，ACK返回给发送端，发送端将cwnd增加到2，接着发送方发送M2，再次接受到ACK后将cwnd增加到4...慢启动算法每经过一个传输轮次，拥塞窗口cwnd就加倍。&lt;/p&gt;
&lt;p&gt;当rwnd足够大时，为防止拥塞窗口cwind的增长引起网络拥塞，还需要另外一个变量，慢开始门限ssthresh&lt;/p&gt;
&lt;p&gt;当cwnd＜ssthresh，使用慢开始算法&lt;br/&gt;当cwnd=ssthresh，既可使用慢开始算法，也可以使用拥塞避免算法&lt;br/&gt;当cwnd＞ssthresh，使用拥塞避免算法&lt;/p&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;首次慢启动的ssthresh值，可以参阅网上的各种讨论，限于篇幅，本文不作介绍~&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&quot;拥塞避免&quot;&gt;2.拥塞避免&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1327889/201909/1327889-20190916082959326-710433143.jpg&quot; alt=&quot;TCP拥塞控制&quot;/&gt;&lt;/p&gt;
&lt;p&gt;控制过程:&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;TCP连接初始化，将拥塞窗口cwnd设置为1个报文段，即cwnd=1&lt;/li&gt;
&lt;li&gt;执行慢开始算法，cwnd按指数规律增长，直到cwnd == ssthresh时，开始拥塞避免算法，cwnd按线性规律增长&lt;/li&gt;
&lt;li&gt;当网络发生阻塞，把ssthresh值更新为拥塞前cwnd的一半(12=24/2)，cwnd重新设置为1，再按照(2)执行&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;让拥塞窗口cwnd缓慢地增大，每经过一个往返时间RTT就把发送方的拥塞窗口cwnd+1，而不是加倍。这样拥塞窗口cwnd线性缓慢增长，比慢开始算法的拥塞窗口增长速率缓慢地多。&lt;/p&gt;
&lt;p&gt;无论慢启动开始阶段还是在拥塞避免阶段，只要发送方判断网络出现拥塞(没收到ACK)，就把慢启动门限ssthresh设置为出现拥塞时的cwnd的一半。然后把拥塞窗口cwnd重新设置为1，执行慢启动算法。这样做的目的是能迅速的减少主机向网络中传输数据，使发生拥塞的路由器能够把队列中堆积的分组处理完毕。拥塞窗口是按照线性的规律增长，比慢启动算法拥塞窗口增长快的多。&lt;/p&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;拥塞避免是由指数增长拉低到线性增长，降低出现拥塞的可能，并不是能完全避免网络拥塞&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&quot;快重传&quot;&gt;3.快重传&lt;/h3&gt;
&lt;p&gt;一条TCP连接有时会因等待重传计时器的超时而空闲较长的时间，慢开始和拥塞避免无法很好地解决这类问题，因此提出了快重传和快恢复的拥塞控制方法。&lt;/p&gt;
&lt;p&gt;为使发送方及早知道有报文没有达到对方，快重传算法首先要求接受方每收到一个报文段后就立即发出重复确认。快重传算法并非取消了重传机制，只是在某些情况下更早地重传丢失的报文段。即，当TCP源端收到3个相同的ACK确认时，即认为有数据包丢失，则源端重传丢失的数据包，而不必等待RTO(Retransmission Timeout)超时。由于发送方尽早重传未被确认的报文段。因此，采用快重传后可以使整个网络吞吐量提高20%&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1327889/201909/1327889-20190916083000011-1044274294.png&quot; alt=&quot;TCP快重传&quot;/&gt;&lt;/p&gt;
&lt;p&gt;快重传算法要求首先接收方收到一个失序的报文段后就立刻发出重复确认，而不要等待自己发送数据时才进行捎带确认。接收方成功的接受了发送方发送来的M1、M2并且分别给发送了ACK，现在接收方没有收到M3，而接收到了M4，显然接收方不能确认M4，因为M4是失序的报文段。如果根据可靠性传输原理接收方什么都不做，但是按照快速重传算法，在收到M4、M5等报文段的时候，不断重复的向发送方发送M2的ACK,如果接收方一连收到三个重复的ACK,那么发送方不必等待重传计时器到期，由于发送方尽早重传未被确认的报文段。&lt;/p&gt;
&lt;h3 id=&quot;快恢复&quot;&gt;4.快恢复&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1327889/201909/1327889-20190916083000596-1341037594.jpg&quot; alt=&quot;TCP快恢复&quot;/&gt;&lt;/p&gt;
&lt;p&gt;快恢复算法控制过程:&lt;br/&gt;当发送方连续收到3个重复确认时，发送方认为网络很可能没有发生拥塞，因此不执行慢启动。而是把cwnd值设为新的门限值，然后执行拥塞避免算法，cwnd值线性增大，避免了当网络拥塞不够严重时采用&quot;慢启动&quot;算法而造成过大地减小发送窗口尺寸的现象，这就是快恢复。&lt;/p&gt;
&lt;p&gt;最后，限于笔者经验水平有限，欢迎读者就文中的观点提出宝贵的建议和意见。如果想获得更多的学习资源或者想和更多的是技术爱好者一起交流，可以关注我的公众号『全菜工程师小辉』后台回复关键词领取学习资料、进入前后端技术交流群和程序员副业群。同时也可以加入程序员副业群Q群：735764906 一起交流。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1327889/201909/1327889-20190916083000771-1155843669.gif&quot; alt=&quot;哎呀，如果我的名片丢了。微信搜索“全菜工程师小辉”，依然可以找到我&quot;/&gt;&lt;/p&gt;
</description>
<pubDate>Mon, 16 Sep 2019 00:30:00 +0000</pubDate>
<dc:creator>全菜工程师小辉</dc:creator>
<og:description>有关TCP你不能不知道的三次握手和四次挥手问题， '点我跳转' 流量控制 1. 滑动窗口 数据的传送过程中很可能出现接收方来不及接收的情况，这时就需要对发送方进行控制以免数据丢失。利用滑动窗口机制可以</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/mseddl/p/11525411.html</dc:identifier>
</item>
<item>
<title>事务隔离级别中可重复读与幻读的恩恩怨怨 - 码农阿宇</title>
<link>http://www.cnblogs.com/CoderAyu/p/11525408.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/CoderAyu/p/11525408.html</guid>
<description>&lt;p&gt;中秋刚过,大家是不是还没充中秋的假日里缓过来?三天假期里,我深入窥探了Innodb中可重复读与幻读,非常有意思,分享给大家,作为大家工作前的开胃小菜,希望有所帮助.&lt;/p&gt;
&lt;p&gt;每次谈到数据库的事务隔离级别,大家一定会看到这张表.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/liuzhenyulive/GitDisk/blogs/resource/PhantomRead/%E4%BA%8B%E5%8A%A1%E9%9A%94%E7%A6%BB%E7%BA%A7%E5%88%AB.png&quot; alt=&quot;事务隔离级别&quot;/&gt;&lt;/p&gt;
&lt;p&gt;其中,&lt;code&gt;可重复读&lt;/code&gt;这个隔离级别,有效地防止了脏读和不可重复读,但仍然可能发生幻读,&lt;strong&gt;可能&lt;/strong&gt;发生幻读就表示&lt;code&gt;可重复读&lt;/code&gt;这个隔离级别防不住幻读吗?&lt;/p&gt;
&lt;p&gt;我不管从数据库方面的教科书还是一些网络教程上,经常看到RR级别是可以重复读的,但是无法解决幻读,只有可串行化(Serializable)才能解决幻读,这个说法是否正确呢?&lt;/p&gt;
&lt;p&gt;在这篇文章中,我将重点围绕MySQL中&lt;br/&gt;&lt;strong&gt;可重复读（Repeatable read）能防住幻读吗?&lt;/strong&gt;&lt;br/&gt;这一问题展开讨论,相信看完这篇文章后,你一定会对事务隔离级别有新的认识.&lt;/p&gt;
&lt;p&gt;我们的数据库中有如下结构和数据的&lt;code&gt;Users&lt;/code&gt;表,下文中我们将对这张表进行操作,&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/liuzhenyulive/GitDisk/blogs/resource/PhantomRead/users.png&quot; alt=&quot;users&quot;/&gt;&lt;/p&gt;
&lt;p&gt;长文预警,读完此篇文章,大概需要您二十至三十分钟.&lt;/p&gt;

&lt;p&gt;在说幻读之前,我们要先来了解脏读和不可重复读.&lt;/p&gt;
&lt;h2 id=&quot;脏读&quot;&gt;脏读&lt;/h2&gt;
&lt;p&gt;当一个事务读取到另外一个事务修改但未提交的数据时，就可能发生脏读。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/liuzhenyulive/GitDisk/blogs/resource/PhantomRead/%E8%84%8F%E8%AF%BB.png&quot; alt=&quot;脏读&quot;/&gt;&lt;/p&gt;
&lt;p&gt;在我们的例子中，事务2修改了一行，但是没有提交，事务1读了这个没有提交的数据。现在如果事务2回滚了刚才的修改或者做了另外的修改的话，事务1中查到的数据就是不正确的了,所以这条数据就是脏读。&lt;/p&gt;
&lt;h2 id=&quot;不可重复读&quot;&gt;不可重复读&lt;/h2&gt;
&lt;p&gt;“不可重复读”现象发生在当执行SELECT 操作时没有获得读锁或者SELECT操作执行完后马上释放了读锁； 另外一个事务对数据进行了更新,读到了不同的结果.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/liuzhenyulive/GitDisk/blogs/resource/PhantomRead/%E4%B8%8D%E5%8F%AF%E9%87%8D%E5%A4%8D%E8%AF%BB.png&quot; alt=&quot;不可重复读&quot;/&gt;&lt;/p&gt;
&lt;p&gt;在这个例子中，事务2提交成功，因此他对id为1的行的修改就对其他事务可见了。导致了事务1在此前读的age=1,第二次读的age=2,两次结果不一致,这就是不可重复读.&lt;/p&gt;
&lt;h2 id=&quot;幻读&quot;&gt;幻读&lt;/h2&gt;
&lt;p&gt;“幻读”又叫&quot;幻象读&quot;,是''不可重复读''的一种特殊场景：当事务1两次执行''SELECT ... WHERE''检索一定范围内数据的操作中间，事务2在这个表中创建了(如[[INSERT]])了一行新数据，这条新数据正好满足事务1的“WHERE”子句。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/liuzhenyulive/GitDisk/blogs/resource/PhantomRead/%E5%B9%BB%E8%AF%BB.png&quot; alt=&quot;幻读&quot;/&gt;&lt;/p&gt;
&lt;p&gt;如图事务1执行了两遍同样的查询语句,第二遍比第一遍多出了一条数据,这就是幻读。&lt;/p&gt;
&lt;h2 id=&quot;三者到底什么区别&quot;&gt;三者到底什么区别&lt;/h2&gt;
&lt;p&gt;三者的场景介绍完,但是一定仍然有很多同学搞不清楚,它们到底有什么区别,我总结一下.&lt;/p&gt;
&lt;p&gt;脏读:指读到了其他事务未提交的数据.&lt;br/&gt;不可重复读: 读到了其他事务已提交的数据(update).&lt;/p&gt;
&lt;p&gt;不可重复读与幻读都是读到其他事务已提交的数据,但是它们针对点不同.&lt;br/&gt;不可重复读:update.&lt;br/&gt;幻读:delete,insert.&lt;/p&gt;

&lt;h2 id=&quot;未提交读&quot;&gt;未提交读&lt;/h2&gt;
&lt;p&gt;未提交读（READ UNCOMMITTED）是最低的隔离级别,在这种隔离级别下,如果一个事务已经开始写数据，则另外一个事务则&lt;strong&gt;不允许同时进行写操作，但允许其他事务读此行数据&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;把脏读的图拿来分析分析,因为事务2更新id=1的数据后,仍然允许事务1读取该条数据,所以事务1第二次执行查询,读到了事务2更新的结果,产生了脏读.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/liuzhenyulive/GitDisk/blogs/resource/PhantomRead/%E8%84%8F%E8%AF%BB.png&quot; alt=&quot;脏读&quot;/&gt;&lt;/p&gt;
&lt;h2 id=&quot;已提交读&quot;&gt;已提交读&lt;/h2&gt;
&lt;p&gt;由于MySQL的InnoDB默认是使用的RR级别，所以我们先要将该session开启成RC级别，并且设置binlog的模式&lt;/p&gt;
&lt;pre class=&quot;sql&quot;&gt;
&lt;code&gt;SET session transaction isolation level read committed;
SET SESSION binlog_format = 'ROW';（或者是MIXED）&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;在已提交读（READ COMMITTED）级别中，读取数据的事务&lt;strong&gt;允许其他事务继续访问该行数据，但是未提交的写事务将会禁止其他事务访问该行,会对该写锁一直保持直到到事务提交&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;同样,我们来分析脏读,事务2更新id=1的数据后,在提交前,会对该对象写锁,所以事务1读取id=1的数据时,会一直等待事务2结束,处于阻塞状态,避免了产生脏读.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/liuzhenyulive/GitDisk/blogs/resource/PhantomRead/%E8%84%8F%E8%AF%BB.png&quot; alt=&quot;脏读&quot;/&gt;&lt;/p&gt;
&lt;p&gt;同样,来分析不可重复读,事务1读取id=1的数据后并没有锁住该数据,所以事务2能对这条数据进行更新,事务2对更新并提交后,该数据立即生效,所以事务1再次执行同样的查询,查询到的结果便与第一次查到的不同,所以已提交读防不了不可重复读.&lt;br/&gt;&lt;img src=&quot;https://raw.githubusercontent.com/liuzhenyulive/GitDisk/blogs/resource/PhantomRead/%E4%B8%8D%E5%8F%AF%E9%87%8D%E5%A4%8D%E8%AF%BB.png&quot; alt=&quot;不可重复读&quot;/&gt;&lt;/p&gt;
&lt;h2 id=&quot;可重复度&quot;&gt;可重复度&lt;/h2&gt;
&lt;p&gt;在可重复读（REPEATABLE READS）是介于已提交读和可串行化之间的一种隔离级别(废话😅),它是InnoDb的默认隔离级别,它是我这篇文章的重点讨论对象,所以在这里我先卖个关子,后面我会详细介绍.&lt;/p&gt;
&lt;h2 id=&quot;可串行化&quot;&gt;可串行化&lt;/h2&gt;
&lt;p&gt;可串行化（Serializable ）是高的隔离级别,它求在选定对象上的读锁和写锁保持直到事务结束后才能释放,所以能防住上诉所有问题,但因为是串行化的,所以效率较低.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/liuzhenyulive/GitDisk/blogs/resource/PhantomRead/%E8%AF%B4%E6%AD%A3%E4%BA%8B.jpg&quot; alt=&quot;说正事&quot; width=&quot;400&quot;/&gt;&lt;/p&gt;
&lt;p&gt;了解到了上诉的一些背景知识后,下面正式开始我们的议题.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;可重复读（Repeatable read）能防住幻读吗?&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;在讲可重复读之前,我们先在mysql的InnoDB下做下面的实验.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/liuzhenyulive/GitDisk/blogs/resource/PhantomRead/RR.png&quot; alt=&quot;幻读&quot;/&gt;&lt;br/&gt;可以看到,事务A既没有读到事务B更新的数据,也没有读到事务C添加的数据,所以在这个场景下,它既防住了不可重复读,也防住了幻读.&lt;/p&gt;
&lt;p&gt;到此为止,相信大家已经知道答案了,这是怎么做到的呢?&lt;/p&gt;
&lt;h2 id=&quot;悲观锁与乐观锁&quot;&gt;悲观锁与乐观锁&lt;/h2&gt;
&lt;p&gt;我们前面说的在对象上加锁,是一种悲观锁机制,有很多文章说&lt;code&gt;可重复读&lt;/code&gt;的隔离级别防不了幻读, 是认为可重复读会对读的行加锁,导致他事务修改不了这条数据,直到事务结束,但是这种方案只能锁住数据行,如果有新的数据进来,是阻止不了的,所以会产生幻读.&lt;/p&gt;
&lt;p&gt;可是MySQL、ORACLE、PostgreSQL等已经是非常成熟的数据库了,怎么会单纯地采用这种如此影响性能的方案呢?&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/liuzhenyulive/GitDisk/blogs/resource/PhantomRead/mysql.png&quot; alt=&quot;mysql&quot;/&gt;&lt;/p&gt;
&lt;p&gt;我来介绍一下悲观锁和乐观锁.&lt;/p&gt;
&lt;h3 id=&quot;悲观锁&quot;&gt;悲观锁&lt;/h3&gt;
&lt;p&gt;正如其名，它指的是对数据被外界（包括本系统当前的其他事务，以及来自外部系统的事务处理）修改持保守态度，因此，在整个数据处理过程中，将数据处于锁定状态。读取数据时给加锁，其它事务无法修改这些数据。修改删除数据时也要加锁，其它事务无法读取这些数据。&lt;/p&gt;
&lt;h3 id=&quot;乐观锁&quot;&gt;乐观锁&lt;/h3&gt;
&lt;p&gt;相对悲观锁而言，乐观锁机制采取了更加宽松的加锁机制。悲观锁大多数情况下依靠数据库的锁机制实现，以保证操作最大程度的独占性。但随之而来的就是数据库性能的大量开销，特别是对长事务而言，这样的开销往往无法承受。&lt;/p&gt;
&lt;p&gt;而乐观锁机制在一定程度上解决了这个问题。乐观锁，大多是基于数据版本（ Version ）记录机制实现。何谓数据版本？即为数据增加一个版本标识，在基于数据库表的版本解决方案中，一般是通过为数据库表增加一个 “version” 字段来实现。读取出数据时，将此版本号一同读出，之后更新时，对此版本号加一。此时，将提交数据的版本数据与数据库表对应记录的当前版本信息进行比对，如果提交的数据版本号大于数据库表当前版本号，则予以更新，否则认为是过期数据。&lt;/p&gt;
&lt;p&gt;MySQL、ORACLE、PostgreSQL等都是使用了以乐观锁为理论基础的MVCC（多版本并发控制）来避免不可重复读和幻读,MVCC的实现没有固定的规范，每个数据库都会有不同的实现方式，这里讨论的是InnoDB的MVCC。&lt;/p&gt;
&lt;h2 id=&quot;mvcc多版本并发控制&quot;&gt;MVCC(多版本并发控制)&lt;/h2&gt;
&lt;p&gt;在InnoDB中，会在每行数据后添加两个额外的隐藏的值来实现MVCC，这两个值一个记录这行数据何时被创建，另外一个记录这行数据何时过期（或者被删除）。 在实际操作中，存储的并不是时间，而是事务的版本号，每开启一个新事务，事务的版本号就会递增。 在可重读Repeatable reads事务隔离级别下：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;SELECT时，读取创建版本号&amp;lt;=当前事务版本号，删除版本号为空或&amp;gt;当前事务版本号。&lt;/li&gt;
&lt;li&gt;INSERT时，保存当前事务版本号为行的创建版本号&lt;/li&gt;
&lt;li&gt;DELETE时，保存当前事务版本号为行的删除版本号&lt;/li&gt;
&lt;li&gt;UPDATE时，插入一条新纪录，保存当前事务版本号为行创建版本号，同时保存当前事务版本号到原来删除的行&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/liuzhenyulive/GitDisk/blogs/resource/PhantomRead/mvcc.png&quot; alt=&quot;mvcc&quot;/&gt;&lt;/p&gt;
&lt;p&gt;通过MVCC,虽然每行记录都要额外的存储空间来记录version,需要更多的行检查工作以及一些额外的维护工作,但可以减少锁的使用,大多读操作都不用加锁,读取数据操作简单,性能好.&lt;/p&gt;
&lt;p&gt;细心的同学应该也看到了,通过MVCC读取出来的数据其实是历史数据,而不是最新数据,这在一些对于数据时效特别敏感的业务中,很可能出问题,这也是MVCC的短板之处,有办法解决吗? 当然有.&lt;/p&gt;
&lt;p&gt;MCVV这种读取历史数据的方式称为快照读(snapshot read),而读取数据库当前版本数据的方式,叫当前读(current read).&lt;/p&gt;
&lt;h3 id=&quot;快照读&quot;&gt;快照读&lt;/h3&gt;
&lt;p&gt;我们平时只用使用select就是快照读,这样可以减少加锁所带来的开销.&lt;/p&gt;
&lt;pre class=&quot;sql&quot;&gt;
&lt;code&gt;select * from table ....&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;当前读&quot;&gt;当前读&lt;/h3&gt;
&lt;p&gt;对于会对数据修改的操作(update、insert、delete)都是采用当前读的模式。在执行这几个操作时会读取最新的记录，即使是别的事务提交的数据也可以查询到。假设要update一条记录，但是在另一个事务中已经delete掉这条数据并且commit了，如果update就会产生冲突，所以在update的时候需要知道最新的数据。读取的是最新的数据，需要加锁。以下第一个语句需要加共享锁，其它都需要加排它锁。&lt;/p&gt;
&lt;pre class=&quot;sql&quot;&gt;
&lt;code&gt;select * from table where ? lock in share mode; 
select * from table where ? for update; 
insert; 
update; 
delete;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;我们再利用当前读来做试验.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/liuzhenyulive/GitDisk/blogs/resource/PhantomRead/nextkeytest.png&quot; alt=&quot;nextkeytest&quot;/&gt;&lt;/p&gt;
&lt;p&gt;可以看到在读提交的隔离级别中,事务1修改了所有class_id=1的数据,当时当事务2 insert后,事务A莫名奇妙地多了一行class_id=1的数据,而且没有被之前的update所修改,产生了读提交下的的幻读.&lt;/p&gt;
&lt;p&gt;而在可重复度的隔离级别下,情况就完全不同了.事务1在update后,对该数据加锁,事务B无法插入新的数据,这样事务A在update前后数据保持一致,避免了幻读,可以明确的是,update锁的肯定不只是已查询到的几条数据,因为这样无法阻止insert,有同学会说,那就是锁住了整张表呗.&lt;/p&gt;
&lt;p&gt;还是那句话, Mysql已经是个成熟的数据库了,怎么会采用如此低效的方法呢? 其实这里的锁,是通过next-key锁实现的.&lt;/p&gt;
&lt;h2 id=&quot;next-key锁&quot;&gt;Next-Key锁&lt;/h2&gt;
&lt;p&gt;在Users这张表里面,class_id是个非聚簇索引,数据库会通过B+树维护一个非聚簇索引与主键的关系,简单来说,我们先通过class_id=1找到这个索引所对应所有节点,这些节点存储着对应数据的主键信息,即id=1,我们再通过主键id=1找到我们要的数据,这个过程称为回表.&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.cnblogs.com/sujing/p/11110292.html&quot;&gt;不懂数据库索引的底层原理？那是因为你心里没点b树&lt;/a&gt;&lt;br/&gt;前往学习: &lt;a href=&quot;https://www.cnblogs.com/sujing/p/11110292.html&quot; class=&quot;uri&quot;&gt;https://www.cnblogs.com/sujing/p/11110292.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;我本想用我们文章中的例子来画一个B+树,可是画得太丑了,为了避免拉低此偏文章B格.所以我想引用上面那边文章中作者画的B+树来解释Next-key.&lt;/p&gt;
&lt;p&gt;假设我们上面用到的User表需要对&lt;code&gt;Name&lt;/code&gt;建立非聚簇索引,是怎么实现的呢？我们看下图：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/liuzhenyulive/GitDisk/blogs/resource/PhantomRead/btree.png&quot; alt=&quot;btree&quot;/&gt;&lt;/p&gt;
&lt;p&gt;B+树的特点是所有数据都存储在叶子节点上,以非聚簇索引的&lt;code&gt;秦寿生&lt;/code&gt;为例,在&lt;code&gt;秦寿生&lt;/code&gt;的右叶子节点存储着所有&lt;code&gt;秦寿生&lt;/code&gt;对应的Id,即图中的34,在我们对这条数据做了当前读后,就会对这条数据加行锁,对于行锁很好理解,能够防止其他事务对其进行&lt;code&gt;update&lt;/code&gt;或&lt;code&gt;delete&lt;/code&gt;,但为什么要加GAP锁呢?&lt;/p&gt;
&lt;p&gt;还是那句话,B+树的所有数据存储在叶子节点上,当有一个新的叫&lt;code&gt;秦寿生&lt;/code&gt;的数据进来,一定是排在在这条id=34的数据前面或者后面的,我们如果对前后这个范围进行加锁了,那当然新的&lt;code&gt;秦寿生&lt;/code&gt;就插不进来了.&lt;/p&gt;
&lt;p&gt;那如果有一个新的&lt;code&gt;范统&lt;/code&gt;要插进行呢? 因为&lt;code&gt;范统&lt;/code&gt;的前后并没有被锁住,是能成功插入的,这样就极大地提高了数据库的并发能力.&lt;/p&gt;

&lt;p&gt;上文中说了可重复读能防不可重复读,还能防幻读,它能防住所有的幻读吗?当然不是,也有马失前蹄的时候.&lt;/p&gt;
&lt;p&gt;比如如下的例子:&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/liuzhenyulive/GitDisk/blogs/resource/PhantomRead/specialcase.png&quot; alt=&quot;specialcase&quot;/&gt;&lt;/p&gt;
&lt;p&gt;1.a事务先select，b事务insert确实会加一个gap锁，但是如果b事务commit，这个gap锁就会释放（释放后a事务可以随意操作），&lt;br/&gt;2.a事务再select出来的结果在MVCC下还和第一次select一样，&lt;br/&gt;3.接着a事务不加条件地update，这个update会作用在所有行上（包括b事务新加的），&lt;br/&gt;4.a事务再次select就会出现b事务中的新行，并且这个新行已经被update修改了.&lt;/p&gt;
&lt;p&gt;Mysql官方给出的幻读解释是：只要在一个事务中，第二次select多出了row就算幻读, 所以这个场景下,算出现幻读了.&lt;/p&gt;
&lt;p&gt;那么文章最后留个问题,你知道为什么上诉例子会出现幻读吗?欢迎留言讨论.&lt;/p&gt;
&lt;p&gt;参考文章:&lt;br/&gt;&lt;a href=&quot;https://dev.mysql.com/doc/refman/5.6/en/set-transaction.html#isolevel_repeatable-read&quot;&gt;MySQL 5.6 Reference Manual&lt;/a&gt;&lt;br/&gt;&lt;a href=&quot;http://www.ovaistariq.net/597/understanding-innodb-transaction-isolation-levels/#.Vw8XJuJ96Uk&quot;&gt;understanding InnoDB transaction isolation levels&lt;/a&gt;&lt;br/&gt;&lt;a href=&quot;http://mysql.taobao.org/monthly/2017/06/07/&quot;&gt;MySQL · 源码分析 · InnoDB Repeatable Read隔离级别之大不同&lt;/a&gt;&lt;br/&gt;&lt;a href=&quot;https://www.cnblogs.com/sujing/p/11110292.html&quot;&gt;不懂数据库索引的底层原理？那是因为你心里没点b树&lt;/a&gt;&lt;br/&gt;&lt;a href=&quot;https://tech.meituan.com/2014/08/20/innodb-lock.html&quot;&gt;Innodb中的事务隔离级别和锁的关系&lt;/a&gt;&lt;br/&gt;&lt;a href=&quot;https://blog.csdn.net/tb3039450/article/details/66475638&quot;&gt;MySQL InnoDB中的行锁 Next-Key Lock消除幻读&lt;/a&gt;&lt;/p&gt;
</description>
<pubDate>Mon, 16 Sep 2019 00:29:00 +0000</pubDate>
<dc:creator>码农阿宇</dc:creator>
<og:description>前言 中秋刚过,大家是不是还没充中秋的假日里缓过来?三天假期里,我深入窥探了Innodb中可重复读与幻读,非常有意思,分享给大家,作为大家工作前的开胃小菜,希望有所帮助. 每次谈到数据库的事务隔离级别</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/CoderAyu/p/11525408.html</dc:identifier>
</item>
<item>
<title>go 学习笔记之学习函数式编程前不要忘了函数基础 - 雪之梦技术驿站</title>
<link>http://www.cnblogs.com/snowdreams1006/p/11525375.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/snowdreams1006/p/11525375.html</guid>
<description>&lt;p&gt;在编程世界中向来就没有一家独大的&lt;strong&gt;编程风格&lt;/strong&gt;,至少目前还是&lt;strong&gt;百家争鸣&lt;/strong&gt;的春秋战国,除了众所周知的&lt;strong&gt;面向对象编程&lt;/strong&gt;还有日渐流行的&lt;strong&gt;函数式编程&lt;/strong&gt;,当然这也是本系列文章的重点.&lt;/p&gt;
&lt;p&gt;越来越多的主流语言在设计的时候几乎无一例外都会参考&lt;strong&gt;函数式特性&lt;/strong&gt;( &lt;code&gt;lambda&lt;/code&gt; 表达式,原生支持 &lt;code&gt;map,reduce...&lt;/code&gt;）,就连面向对象语言的 &lt;code&gt;Java8&lt;/code&gt; 也慢慢开始支持函数式编程,所以再不学习函数式编程可能就晚了!&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://upload-images.jianshu.io/upload_images/16648241-dc2ceed42a0b1fc1.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240&quot; alt=&quot;go-functional-programming-about-function.jpg&quot;/&gt;&lt;/p&gt;
&lt;p&gt;但是在正式学习&lt;strong&gt;函数式编程&lt;/strong&gt;之前,不妨和早已熟悉的&lt;strong&gt;面向对象编程&lt;/strong&gt;心底里做下对比,通过对比学习的方式,相信你一定会收获满满,因此特地整理出来关于 &lt;code&gt;Go&lt;/code&gt; 语言的&lt;strong&gt;面向对象系列文章&lt;/strong&gt;,邀君共赏.&lt;/p&gt;
&lt;blockquote readability=&quot;10&quot;&gt;
&lt;p&gt;上述系列文章讲解了 &lt;code&gt;Go&lt;/code&gt; 语言&lt;strong&gt;面向对象&lt;/strong&gt;相关知识点,如果点击后没有&lt;strong&gt;自动跳转&lt;/strong&gt;,可以关注微信公众号「雪之梦技术驿站」查看历史文章,再次感谢你的阅读与关注.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;生物学家和数学家的立场不同&quot;&gt;生物学家和数学家的立场不同&lt;/h2&gt;
&lt;p&gt;虽然是同一个世界,但是不同的人站在各自立场看问题,结果自然会千人千面,各有不同.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;生物学家&lt;/strong&gt;会下意识对动植物进行分类归纳,&lt;strong&gt;面向对象编程&lt;/strong&gt;也是如此,用一系列的抽象模型去&lt;strong&gt;模拟&lt;/strong&gt;现实世界的行为规律.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://upload-images.jianshu.io/upload_images/16648241-08d3998a46a367bc.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240&quot; alt=&quot;go-functional-programming-about-biology.jpg&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;数学家&lt;/strong&gt;向来以严谨求学著称,作为最重要的基础科学,数学规律以及归纳演绎方法论对应的就是&lt;strong&gt;函数式编程&lt;/strong&gt;,不是模拟现实而是&lt;strong&gt;描述&lt;/strong&gt;规律更有可能创造规律.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://upload-images.jianshu.io/upload_images/16648241-c30d3988c199afea.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240&quot; alt=&quot;go-functional-programming-about-math.jpg&quot;/&gt;&lt;/p&gt;
&lt;p&gt;标准的函数式编程具有浓厚的&lt;strong&gt;数学色彩&lt;/strong&gt;,幸运的是,&lt;code&gt;Go&lt;/code&gt; 并不是函数式语言,所以也不必受限于&lt;strong&gt;近乎苛责&lt;/strong&gt;般的条条框框.&lt;/p&gt;
&lt;p&gt;简单来说,函数式编程具有以下特点:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;不可变性: 不用状态变量和可变对象&lt;/li&gt;
&lt;li&gt;函数只能有一个参数&lt;/li&gt;
&lt;li&gt;纯函数没有副作用&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;img src=&quot;https://upload-images.jianshu.io/upload_images/16648241-686da263d19117d6.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240&quot; alt=&quot;go-functional-programming-about-feature.jpg&quot;/&gt;&lt;/p&gt;
&lt;p&gt;摘自维基百科中关于函数式编程中有这么一段话:&lt;/p&gt;
&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;In computer science, functional programming is a programming paradigm—a style of building the structure and elements of computer programs—that treats computation as the evaluation of mathematical functions and avoids changing-state and mutable data.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;上述的英文的大致意思是说:&lt;strong&gt;函数式编程&lt;/strong&gt;将计算机程序看成是数学函数的&lt;strong&gt;推演&lt;/strong&gt;,不用状态变量也不用可变对象来表达数与数之间的关系.&lt;/p&gt;
&lt;blockquote readability=&quot;5.5607476635514&quot;&gt;
&lt;p&gt;如需了解详情,可点击访问维基百科关于&lt;strong&gt;函数式编程&lt;/strong&gt; &lt;a href=&quot;https://en.wikipedia.org/wiki/Functional_programming&quot;&gt;Functional programming&lt;/a&gt; 的相关介绍.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;函数式编程的&lt;strong&gt;立足点和出发点&lt;/strong&gt;是函数,&lt;strong&gt;复杂函数&lt;/strong&gt;是基本函数经过一定&lt;strong&gt;组合&lt;/strong&gt;规律形成的,所以描述复杂函数的过程就是如何&lt;strong&gt;拆解重组&lt;/strong&gt;的过程.&lt;/p&gt;
&lt;p&gt;所以接下来我们一边复习一边学习函数的基本特点,为接下来理解函数式编程打下基础,关于函数的基础语言可参考 &lt;a href=&quot;https://mp.weixin.qq.com/s/8Ijk3FGMo9fCSTNGbx8R3Q&quot;&gt;go 学习笔记之值得特别关注的基础语法有哪些&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;函数的基础语法和高级特性&quot;&gt;函数的基础语法和高级特性&lt;/h2&gt;
&lt;p&gt;下面以最基本&lt;strong&gt;四则运算&lt;/strong&gt;为例,贯穿全文讲解函数的基本语法和高级特性,力求做到知其然知其所以然.&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;code&gt;func&lt;/code&gt; 定义普通函数&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;code&gt;eval&lt;/code&gt; 函数定义了加减乘除基本运算规则,若不支持操作类型则抛出异常,终止程序.&lt;/p&gt;
&lt;pre class=&quot;go&quot;&gt;
&lt;code&gt;func eval(a, b int, op string) int {
    var result int
    switch op {
    case &quot;+&quot;:
        result = a + b
    case &quot;-&quot;:
        result = a - b
    case &quot;*&quot;:
        result = a * b
    case &quot;/&quot;:
        result = a / b
    default:
        panic(&quot;unsupported operator: &quot; + op)
    }
    return result
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;测试未定义操作取余 &lt;code&gt;%&lt;/code&gt; 运算时,则抛出异常,&lt;code&gt;unsupported operator: %&lt;/code&gt; ,说明仅仅支持加减乘除基本运算.&lt;/p&gt;
&lt;pre class=&quot;go&quot;&gt;
&lt;code&gt;func TestEval(t *testing.T) {
    // 3 -1 2 0 unsupported operator: %
    t.Log(
        eval(1, 2, &quot;+&quot;),
        eval(1, 2, &quot;-&quot;),
        eval(1, 2, &quot;*&quot;),
        eval(1, 2, &quot;/&quot;),
        eval(1, 2, &quot;%&quot;),
    )
}&lt;/code&gt;
&lt;/pre&gt;
&lt;ul&gt;&lt;li&gt;多返回值定义标准函数&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;code&gt;Go&lt;/code&gt; 语言和其他主流的编程语言明显不同的是,函数支持&lt;strong&gt;多返回值&lt;/strong&gt;,通常第一个返回值表示真正结果,第二个返回值表示&lt;strong&gt;是否错误&lt;/strong&gt;,这也是 &lt;code&gt;Go&lt;/code&gt; 关于异常错误设计的独特之处.&lt;/p&gt;
&lt;blockquote readability=&quot;12&quot;&gt;
&lt;p&gt;如果正常返回,则表示没有错误,那么第一个返回值是正常结果而第二个返回值则是空 &lt;code&gt;nil&lt;/code&gt;;如果异常返回,第一个返回值设计无意义的特殊值,第二个返回值是具体的错误信息,一般非 &lt;code&gt;nil&lt;/code&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;pre class=&quot;go&quot;&gt;
&lt;code&gt;func evalWithStandardStyle(a, b int, op string) (int, error) {
    switch op {
    case &quot;+&quot;:
        return a + b, nil
    case &quot;-&quot;:
        return a - b, nil
    case &quot;*&quot;:
        return a * b, nil
    case &quot;/&quot;:
        return a / b, nil
    default:
        return 0, fmt.Errorf(&quot;unsupported operator: %s&quot;, op)
    }
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;改造 &lt;code&gt;eval&lt;/code&gt; 函数以编写真正 &lt;code&gt;Go&lt;/code&gt; 程序,此时再次测试,结果显示遇到没有定义的操作符时不再抛出异常而是返回默认零值以及给出简短的错误描述信息.&lt;/p&gt;
&lt;pre class=&quot;go&quot;&gt;
&lt;code&gt;func TestEvalWithStandardStyle(t *testing.T) {
    // Success: 2
    if result, err := evalWithStandardStyle(5, 2, &quot;/&quot;); err != nil {
        t.Log(&quot;Error:&quot;, err)
    } else {
        t.Log(&quot;Success:&quot;, result)
    }

    // Error: unsupported operator: %
    if result, err := evalWithStandardStyle(5, 2, &quot;%&quot;); err != nil {
        t.Log(&quot;Error:&quot;, err)
    } else {
        t.Log(&quot;Success:&quot;, result)
    }
}&lt;/code&gt;
&lt;/pre&gt;
&lt;ul&gt;&lt;li&gt;其他函数作为参数传入&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;上例通过多返回值解决了遇到不支持的运算符会报错终止程序的问题,但是并没有真正解决问题,假如真的想要进行非预定义的运算时,同样是无能为力!&lt;/p&gt;
&lt;p&gt;谁让你只是使用者而不是设计者呢!&lt;/p&gt;
&lt;p&gt;那么舞台交给你,你就是主角,你想要怎么处理输入怎么输出就怎么处理,全部逻辑转移给使用者,这样就不存在无法满足需求的情况了.&lt;/p&gt;
&lt;pre class=&quot;go&quot;&gt;
&lt;code&gt;func evalWithApplyStyle(a, b int, op func(int, int) (int, error)) (int, error) {
    return op(a, b)
}&lt;/code&gt;
&lt;/pre&gt;
&lt;blockquote readability=&quot;10&quot;&gt;
&lt;p&gt;操作符由原来的字符串 &lt;code&gt;string&lt;/code&gt; 更改成函数 &lt;code&gt;func(int, int) (int, error)&lt;/code&gt;,舞台交给你,全靠自由发挥!&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;code&gt;evalWithApplyStyle&lt;/code&gt; 函数内部直接调用函数参数 &lt;code&gt;op&lt;/code&gt; 并返回该函数的处理结果,当前演示示例中函数的控制权完全转移给函数入参 &lt;code&gt;op&lt;/code&gt; 函数,实际情况可按照实际需求决定如何处理 &lt;code&gt;evalWithApplyStyle&lt;/code&gt; 逻辑.&lt;/p&gt;
&lt;pre class=&quot;go&quot;&gt;
&lt;code&gt;func divide(a, b int) (int, error) {
    return a / b, nil
}

func mod(a, b int) (int, error) {
    return a % b, nil
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;自己动手,丰衣足食,顺手定义除法 &lt;code&gt;divide&lt;/code&gt; 和取余 &lt;code&gt;mod&lt;/code&gt; 运算,接下来测试下实现效果.&lt;/p&gt;
&lt;pre class=&quot;go&quot;&gt;
&lt;code&gt;func TestEvalWithApplyStyle(t *testing.T) {
    // Success: 2
    if result, err := evalWithApplyStyle(5, 2, divide); err != nil {
        t.Log(&quot;Error:&quot;, err)
    } else {
        t.Log(&quot;Success:&quot;, result)
    }

    // Success: 1
    if result, err := evalWithApplyStyle(5, 2, mod); err != nil {
        t.Log(&quot;Error:&quot;, err)
    } else {
        t.Log(&quot;Success:&quot;, result)
    }
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;测试结果很理想,不仅实现了减加乘除等基本运算,还可以实现之前一直没法实现的取余运算!&lt;/p&gt;
&lt;p&gt;这说明了这种函数作为参数的做法充分调动劳动人民积极性,妈妈再也不用担心我无法实现复杂功能了呢!&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;匿名函数也可以作为参数&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;一般而言,调用函数时都是直接用函数名进行调用,单独的函数具有可复用性,但如果本就是一次性函数的话,其实是没必要定义带函数名形式的函数.&lt;/p&gt;
&lt;p&gt;依然是上述例子,这一次对两个数的运算规则不再是数学运算了,这一次我们来比较两个数的最大值,使用匿名函数的形式进行实现.&lt;/p&gt;
&lt;pre class=&quot;go&quot;&gt;
&lt;code&gt;func TestEvalWithApplyStyle(t *testing.T) {
    // Success: 5
    if result, err := evalWithApplyStyle(5, 2, func(a int, b int) (result int, e error) {
        if a &amp;gt; b {
            return a, nil
        }
        return b, nil
    }); err != nil {
        t.Log(&quot;Error:&quot;, err)
    } else {
        t.Log(&quot;Success:&quot;, result)
    }
}&lt;/code&gt;
&lt;/pre&gt;
&lt;ul&gt;&lt;li&gt;函数的返回值可以是函数&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;依然是上述示例,如果由于原因不需要&lt;strong&gt;立即返回&lt;/strong&gt;函数的计算结果而是&lt;strong&gt;等待使用者&lt;/strong&gt;自己觉得时机合适的时候再计算返回值,这时候函数返回值依然是函数就很有作用了,也就是所谓的&lt;strong&gt;惰性求值&lt;/strong&gt;.&lt;/p&gt;
&lt;pre class=&quot;go&quot;&gt;
&lt;code&gt;func evalWithFunctionalStyle(a, b int, op func(int, int) (int, error)) func() (int, error) {
    return func() (int, error) {
        return op(a, b)
    }
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;上述函数看起来可能有点难以理解,实际上相对于上例&lt;strong&gt;仅仅更改了返回值&lt;/strong&gt;,由原来的 &lt;code&gt;(int, error)&lt;/code&gt; 更改成 &lt;code&gt;func() (int, error)&lt;/code&gt; ,其余均保持不变哟!&lt;/p&gt;
&lt;p&gt;&lt;code&gt;evalWithFunctionalStyle&lt;/code&gt; 函数依然是&lt;strong&gt;使用者的主场&lt;/strong&gt;,和上例相比的唯一不同之处在于,你的主场你做主,&lt;strong&gt;什么时候裁判完全自己说了算&lt;/strong&gt;,并不是运行后就立马宣布结果.&lt;/p&gt;
&lt;pre class=&quot;go&quot;&gt;
&lt;code&gt;func pow(a, b int) (int, error) {
    return int(math.Pow(float64(a), float64(b))),nil
}

func TestEvalWithFunctionalStyle(t *testing.T) {
    ef := evalWithFunctionalStyle(5, 2, pow)

    time.Sleep(time.Second * 1)

    // Success: 25
    if result, err := ef(); err != nil {
        t.Log(&quot;Error:&quot;, err)
    } else {
        t.Log(&quot;Success:&quot;, result)
    }
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;time.Sleep(time.Second * 1)&lt;/code&gt; 演示代码代表执行 &lt;code&gt;evalWithFunctionalStyle&lt;/code&gt; 函数后可以&lt;strong&gt;不立即计算最终结果&lt;/strong&gt;,等待时机合适后由使用者再次调用 &lt;code&gt;ef()&lt;/code&gt; 函数进行惰性求值.&lt;/p&gt;
&lt;pre class=&quot;go&quot;&gt;
&lt;code&gt;// 1 1 2 3 5 8 13 21 34 55
//     a b
//       a b
func fibonacci() func() int {
    a, b := 0, 1
    return func() int {
        a, b = b, a+b
        return a
    }
}&lt;/code&gt;
&lt;/pre&gt;
&lt;ul&gt;&lt;li&gt;函数可以充当类型&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;上述示例中讲解了函数可以作为返回值,参数有函数,返回值也有参数,所以 &lt;code&gt;evalWithFunctionalStyle&lt;/code&gt; 函数看起来比较费劲,而 &lt;code&gt;Go&lt;/code&gt; 语言的类型别名就是为了简化而生的,更何况函数是 &lt;code&gt;Go&lt;/code&gt; 中的一等公民,当然也适合了.&lt;/p&gt;
&lt;pre class=&quot;go&quot;&gt;
&lt;code&gt;func evalWithFunctionalStyle(a, b int, op func(int, int) (int, error)) func() (int, error) {
    return func() (int, error) {
        return op(a, b)
    }
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;于是打算把入参函数 &lt;code&gt;func(int, int) (int, error)&lt;/code&gt; 和返回值函数 &lt;code&gt;func() (int, error)&lt;/code&gt; 进行统一,而入参函数和返回值函数唯一不同之处就是入参个数不同,所以顺理成章想到了 &lt;code&gt;Go&lt;/code&gt; 函数中的&lt;strong&gt;不定长参数&lt;/strong&gt;相关语法.&lt;/p&gt;
&lt;pre class=&quot;go&quot;&gt;
&lt;code&gt;type generateIntFunc func(base ...int) (int, error)&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;这样入参函数和出参函数都可以用 &lt;code&gt;generateIntFunc&lt;/code&gt; 类型函数进行替代,接着改造 &lt;code&gt;evalWithFunctionalStyle&lt;/code&gt; 函数.&lt;/p&gt;
&lt;pre class=&quot;go&quot;&gt;
&lt;code&gt;func evalWithObjectiveStyle(a, b int, op generateIntFunc) generateIntFunc {
    return func(base ...int) (i int, e error) {
        return op(a, b)
    }
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;改造后的 &lt;code&gt;evalWithObjectiveStyle&lt;/code&gt; 函数看起来比较简洁,花花架子中看是否中用还不好说,还是用测试用例说话吧!&lt;/p&gt;
&lt;pre class=&quot;go&quot;&gt;
&lt;code&gt;func TestEvalWithObjectiveStyle(t *testing.T) {
    ef := evalWithObjectiveStyle(5, 2, func(base ...int) (int,error) {
        result := 0
        for i := range base {
            result += base[i]
        }
        return result,nil
    })

    time.Sleep(time.Second * 1)

    // Success: 7
    if result, err := ef(); err != nil {
        t.Log(&quot;Error:&quot;, err)
    } else {
        t.Log(&quot;Success:&quot;, result)
    }
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;函数别名进行类型化后并不影响功能,依然是函数式编程,不过夹杂了些面向对象的味道.&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;类型化函数可以实现接口&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;函数通过&lt;strong&gt;别名&lt;/strong&gt;形式进行类型化后可以实现接口,某些程度上可以视为一种类型,因此实现接口也是顺理成章的事情.&lt;/p&gt;
&lt;pre class=&quot;go&quot;&gt;
&lt;code&gt;func (g generateIntFunc) String() string {
    r,_ := g()
    return fmt.Sprint(r)
}&lt;/code&gt;
&lt;/pre&gt;
&lt;blockquote readability=&quot;10&quot;&gt;
&lt;p&gt;此处示例代码中为类型化函数 &lt;code&gt;generateIntFunc&lt;/code&gt; 实现 &lt;code&gt;String&lt;/code&gt; 接口方法,可能并没有太大实际意义,仅仅是为了讲解这个知识点而硬凑上去的,实际情况肯定会有所不同.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;pre class=&quot;go&quot;&gt;
&lt;code&gt;func TestEvalWithInterfaceStyle(t *testing.T) {
    ef := evalWithObjectiveStyle(5, 2, func(base ...int) (int,error) {
        result := 0
        for i := range base {
            result += base[i]
        }
        return result,nil
    })

    time.Sleep(time.Second * 1)

    // String: 7
    t.Log(&quot;String:&quot;, ef.String())

    // Success: 7
    if result, err := ef(); err != nil {
        t.Log(&quot;Error:&quot;, err)
    } else {
        t.Log(&quot;Success:&quot;, result)
    }
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;惰性求值获取的函数变量 &lt;code&gt;ef&lt;/code&gt; 此时可以调用 &lt;code&gt;String&lt;/code&gt; 方法,也就是具备对象化能力,得到的最终结果竟然和直接运行该函数的值一样?&lt;/p&gt;
&lt;p&gt;有点神奇,目前还不理解这是什么操作,如果有 &lt;code&gt;Go&lt;/code&gt; 语言的大佬们不吝赐教的话,小弟感激不尽!&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;水到渠成的闭包&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;函数的参数,返回值都可以是另外的函数,函数也可以作为引用那样传递给变量,也存在匿名函数等简化形式,除此之外,类型化后的函数还可以用来实现接口等等特性应该足以阐释一等公民的高贵身份地位了吧?&lt;/p&gt;
&lt;p&gt;如此强大的函数特性,只要稍加组合使用就会拥有强大的能力,并且 &lt;code&gt;Go&lt;/code&gt; 语言并不是严格的函数式语言,没有太多语法层面的限制.&lt;/p&gt;
&lt;pre class=&quot;go&quot;&gt;
&lt;code&gt;// 1 1 2 3 5 8 13 21 34 55
//     a b
//       a b
func fibonacci() func() int {
    a, b := 0, 1
    return func() int {
        a, b = b, a+b
        return a
    }
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;斐波那契数列&lt;/strong&gt;函数 &lt;code&gt;fibonacci&lt;/code&gt; 的返回值是真正的生成器函数,每次调用都会生成新的斐波那契数字.&lt;/p&gt;
&lt;p&gt;这就是 &lt;code&gt;Go&lt;/code&gt; 语言实现闭包的一种简单示例,&lt;code&gt;fibonacci&lt;/code&gt; 函数本身的变量 &lt;code&gt;a,b&lt;/code&gt; 被内部匿名函数 &lt;code&gt;func() int&lt;/code&gt; 所引用,而这种引用最终被使用者不断调用就会导致最初的 &lt;code&gt;a,b&lt;/code&gt; 变量一直被占用着,只要继续调用这种生成器,裴波那契数列的数字就会一直递增.&lt;/p&gt;
&lt;pre class=&quot;go&quot;&gt;
&lt;code&gt;// 1 1 2 3 5 8 13 21 34 55
func TestFibonacci(t *testing.T) {
    f := fibonacci()
    for i := 0; i &amp;lt; 10; i++ {
        fmt.Print(f(), &quot; &quot;)
    }
    fmt.Println()
}&lt;/code&gt;
&lt;/pre&gt;
&lt;pre class=&quot;go&quot;&gt;
&lt;code&gt;func TestFibonacci(t *testing.T) {
    f := fibonacci()
    for i := 0; i &amp;lt; 10; i++ {
        fmt.Print(f(), &quot; &quot;)
    }
    fmt.Println()
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;img src=&quot;https://upload-images.jianshu.io/upload_images/16648241-96ca089aa09a8fbe.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240&quot; alt=&quot;go-functional-programming-about-fib.png&quot;/&gt;&lt;/p&gt;
&lt;h2 id=&quot;函数式编程入门函数总结&quot;&gt;函数式编程入门函数总结&lt;/h2&gt;
&lt;ul&gt;&lt;li&gt;函数是&lt;strong&gt;一等公民&lt;/strong&gt;,其中函数参数,变量,函数返回值都可以是函数.&lt;/li&gt;
&lt;li&gt;高阶函数是普通函数&lt;strong&gt;组合&lt;/strong&gt;而成,参数和返回值可以是另外的函数.&lt;/li&gt;
&lt;li&gt;函数是函数式编程的基础,&lt;strong&gt;支持函数式编程但并不是函数式语言&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;没有&lt;strong&gt;纯粹函数式编程&lt;/strong&gt;的条条框框,更加灵活自由,良好的可读性.&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;img src=&quot;https://upload-images.jianshu.io/upload_images/16648241-66cabcaa077446c2.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240&quot; alt=&quot;雪之梦技术驿站.png&quot;/&gt;&lt;/p&gt;
</description>
<pubDate>Sun, 15 Sep 2019 23:58:00 +0000</pubDate>
<dc:creator>雪之梦技术驿站</dc:creator>
<og:description>越来越多的主流语言在设计的时候几乎无一例外都会参考函数式特性( lambda 表达式,原生支持 map,reduce...）,就连面向对象语言的 Java8 也慢慢开始支持函数式编程,所以再不学习函数</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/snowdreams1006/p/11525375.html</dc:identifier>
</item>
<item>
<title>Django之使用内置函数和celery发邮件 - YifChan</title>
<link>http://www.cnblogs.com/yifchan/p/python-1-34.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/yifchan/p/python-1-34.html</guid>
<description>&lt;h2&gt;邮箱配置&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;开启stmp服务&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;以163邮箱为例，点击设置里面的stmp&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1618401/201909/1618401-20190915131415691-1551149228.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;开启客户端授权密码&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1618401/201909/1618401-20190915131646448-142730053.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt; 如上所示，因为我已经开启了，所以出现的是以上页面。&lt;/p&gt;
&lt;p&gt;这样，邮箱的准备就已经完成了。&lt;/p&gt;

&lt;h2&gt;使用Django内置函数发邮件&lt;/h2&gt;
&lt;p&gt;1.在settings文件中加入以下配置&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;35&quot;&gt;
&lt;pre&gt;
&lt;span&gt;#&lt;/span&gt;&lt;span&gt; 邮件设置&lt;/span&gt;
EMAIL_BACKEND = &lt;span&gt;'&lt;/span&gt;&lt;span&gt;django.core.mail.backends.smtp.EmailBackend&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;
EMAIL_HOST &lt;/span&gt;= &lt;span&gt;'&lt;/span&gt;&lt;span&gt;smtp.163.com&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;
EMAIL_PORT &lt;/span&gt;= 25
&lt;span&gt;#&lt;/span&gt;&lt;span&gt; 发送邮件的邮箱&lt;/span&gt;
EMAIL_HOST_USER = &lt;span&gt;'&lt;/span&gt;&lt;span&gt;发送邮件的邮箱&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;
&lt;span&gt;#&lt;/span&gt;&lt;span&gt; 在邮箱中设置的客户端授权密码&lt;/span&gt;
EMAIL_HOST_PASSWORD = &lt;span&gt;'&lt;/span&gt;&lt;span&gt;授权密码&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;
&lt;span&gt;#&lt;/span&gt;&lt;span&gt; 收件人看到的发件人&lt;/span&gt;
EMAIL_FROM = &lt;span&gt;'&lt;/span&gt;&lt;span&gt;绿色果园&amp;lt;发送邮件的邮箱&amp;gt;&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;2.编写发送邮件代码&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;46&quot;&gt;
&lt;pre&gt;
from django.shortcuts import render, redirect, HttpResponse&lt;br/&gt;from django.core.mail import send_mail&lt;br/&gt;from itsdangerous import TimedJSONWebSignatureSerializer as Serializer&lt;br/&gt;from django.conf import settings
&lt;/pre&gt;
&lt;pre&gt;
&lt;span&gt;&lt;br/&gt;def&lt;/span&gt;&lt;span&gt; emailtest(request):
    &lt;/span&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt; 发送激活邮件，包括激活链接：http://127.0.0.1:8000/user/active/3&lt;/span&gt;
    &lt;span&gt;#&lt;/span&gt;&lt;span&gt; 激活链接中需要包含用户的身份信息，并且要把身份信息进行加密&lt;/span&gt;
    &lt;span&gt;#&lt;/span&gt;&lt;span&gt; 加密用户的身份信息，生成激活token&lt;/span&gt;
    userid = 3&lt;span&gt;
    email &lt;/span&gt;= &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;接收邮件的邮箱账号&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;
    serializer &lt;/span&gt;= Serializer(settings.SECRET_KEY, 1800&lt;span&gt;)
    info &lt;/span&gt;= {&lt;span&gt;'&lt;/span&gt;&lt;span&gt;confirm&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;: userid}
    token &lt;/span&gt;=&lt;span&gt; serializer.dumps(info)
    token &lt;/span&gt;=&lt;span&gt; token.decode()
    &lt;/span&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt; 发邮件&lt;/span&gt;
    subject = &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;绿色果园欢迎信息&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;
    message &lt;/span&gt;= &lt;span&gt;&quot;&quot;&lt;/span&gt;&lt;span&gt;
    sender &lt;/span&gt;=&lt;span&gt; settings.EMAIL_FROM
    receiver &lt;/span&gt;=&lt;span&gt; [email]
    html_message &lt;/span&gt;= &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;&amp;lt;h2&amp;gt;欢迎你成为绿色果园注册会员&amp;lt;/h2&amp;gt;&amp;lt;/br&amp;gt;请点击以下链接激活账号&amp;lt;a href='http:127.0.0.1:8000/&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt; \
                   &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;user/active/%s'&amp;gt;http:127.0.0.1:8000/user/active/%s&amp;lt;/a&amp;gt;&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; %&lt;span&gt; (token, token)
    send_mail(subject, message, sender, receiver, html_message&lt;/span&gt;=&lt;span&gt;html_message)

    &lt;/span&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt; 返回应答，跳转到首页&lt;/span&gt;
    &lt;span&gt;return&lt;/span&gt; HttpResponse(&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;邮件发送成功，请注意接收&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;)
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;配套url&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;35&quot;&gt;
&lt;pre&gt;
urlpatterns =&lt;span&gt; [
    url(r&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;^emailtest/$&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;, views.emailtest, name=&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;emailtest&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;),  &lt;span&gt;#&lt;/span&gt;&lt;span&gt; 发邮件测试&lt;/span&gt;
]
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;3.在浏览器中输入如下地址，即可看到“邮件已发送”的提示信息&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;32&quot;&gt;
&lt;pre&gt;
http://127.0.0.1:8000/user/emailtest/
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;接收邮件如下图所示&lt;/p&gt;
&lt;p&gt;收到邮件&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1618401/201909/1618401-20190915135544253-101751992.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;邮件内容详情&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1618401/201909/1618401-20190915135723637-1507128398.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;h2&gt;使用celery发邮件&lt;/h2&gt;
&lt;p&gt;使用django内置的函数发送邮件时，django给stmp服务器发送邮件需要时间，stmp服务器发送邮件给用户也需要时间，而在发送邮件这段时间内，用户是在等服务端返回应答的，如果等待时间过长，那么无疑会大大的降低用户的体验。&lt;/p&gt;
&lt;p&gt;这个时候，我们可以使用celery来异步发送邮件，即Django服务端在celery发送邮件的同时，返回应答给用户。这里，我们使用sleep来模拟发送邮件的时常。&lt;/p&gt;

&lt;p&gt;1.&lt;strong&gt;安装celery&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot;&gt;
&lt;pre&gt;
pip install celery
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;2.&lt;strong&gt;配置settings文件&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;38&quot;&gt;
&lt;pre&gt;
&lt;span&gt;#&lt;/span&gt;&lt;span&gt; 邮件设置&lt;/span&gt;
EMAIL_BACKEND = &lt;span&gt;'&lt;/span&gt;&lt;span&gt;django.core.mail.backends.smtp.EmailBackend&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;
EMAIL_HOST &lt;/span&gt;= &lt;span&gt;'&lt;/span&gt;&lt;span&gt;smtp.163.com&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;
EMAIL_PORT &lt;/span&gt;= 25
&lt;span&gt;#&lt;/span&gt;&lt;span&gt; 发送邮件的邮箱&lt;/span&gt;
EMAIL_HOST_USER = &lt;span&gt;'&lt;/span&gt;&lt;span&gt;发送邮件的邮箱&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;
&lt;span&gt;#&lt;/span&gt;&lt;span&gt; 在邮箱中设置的客户端授权密码&lt;/span&gt;
EMAIL_HOST_PASSWORD = &lt;span&gt;'&lt;/span&gt;&lt;span&gt;客户端授权密码&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;
&lt;span&gt;#&lt;/span&gt;&lt;span&gt; 收件人看到的发件人&lt;/span&gt;
EMAIL_FROM = &lt;span&gt;'&lt;/span&gt;&lt;span&gt;绿色果园&amp;lt;发送邮件的邮箱&amp;gt;&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;

&lt;span&gt;#&lt;/span&gt;&lt;span&gt; diango的缓存配置&lt;/span&gt;
CACHES =&lt;span&gt; {
    &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;default&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;: {
        &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;BACKEND&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;django_redis.cache.RedisCache&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;,
        &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;LOCATION&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;redis://127.0.0.1:6379/9&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;,
        &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;OPTIONS&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;: {
            &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;CLIENT_CLASS&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;django_redis.client.DefaultClient&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;,
        }
    }
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;3.在项目下新建celery_tasks文件夹，在文件夹中新建tasks文件，&lt;strong&gt;编写tasks文件&lt;/strong&gt;；&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;45&quot;&gt;
&lt;pre&gt;
&lt;span&gt;from&lt;/span&gt; django.core.mail &lt;span&gt;import&lt;/span&gt;&lt;span&gt; send_mail
&lt;/span&gt;&lt;span&gt;from&lt;/span&gt; django.conf &lt;span&gt;import&lt;/span&gt;&lt;span&gt; settings
&lt;/span&gt;&lt;span&gt;from&lt;/span&gt; celery &lt;span&gt;import&lt;/span&gt;&lt;span&gt; Celery
&lt;/span&gt;&lt;span&gt;import&lt;/span&gt;&lt;span&gt; time

&lt;/span&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt; 在任务处理者一端时需要加这几句&lt;/span&gt;&lt;span&gt;
#&lt;/span&gt;&lt;span&gt; import os&lt;/span&gt;&lt;span&gt;
#&lt;/span&gt;&lt;span&gt; import django&lt;/span&gt;&lt;span&gt;
#&lt;/span&gt;&lt;span&gt; os.environ.setdefault(&quot;DJANGO_SETTINGS_MODULE&quot;, &quot;项目名.settings&quot;)&lt;/span&gt;&lt;span&gt;
#&lt;/span&gt;&lt;span&gt; django.setup()&lt;/span&gt;

&lt;span&gt;#&lt;/span&gt;&lt;span&gt; 创建一个Celery类的实例对象&lt;/span&gt;
app = Celery(&lt;span&gt;'&lt;/span&gt;&lt;span&gt;celery_tasks.tasks&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;, broker=&lt;span&gt;'&lt;/span&gt;&lt;span&gt;redis://127.0.0.1:6379/8&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;)


&lt;/span&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt; 定义任务函数&lt;/span&gt;
&lt;span&gt;@app.task
&lt;/span&gt;&lt;span&gt;def&lt;/span&gt;&lt;span&gt; send_register_active_email(to_email, username, token):
    &lt;/span&gt;&lt;span&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span&gt;发送激活邮件&lt;/span&gt;&lt;span&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span&gt;
    subject &lt;/span&gt;= &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;绿色果园欢迎信息&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;
    message &lt;/span&gt;= &lt;span&gt;&quot;&quot;&lt;/span&gt;&lt;span&gt;
    sender &lt;/span&gt;=&lt;span&gt; settings.EMAIL_FROM
    receiver &lt;/span&gt;=&lt;span&gt; [to_email]
    html_message &lt;/span&gt;= &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;&amp;lt;h2&amp;gt;%s， 欢迎你成为绿色果园注册会员&amp;lt;/h2&amp;gt;&amp;lt;/br&amp;gt;请点击以下链接激活账号&amp;lt;a href='http:127.0.0.1:8000/&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt; \
                   &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;user/active/%s'&amp;gt;http:127.0.0.1:8000/user/active/%s&amp;lt;/a&amp;gt;&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; %&lt;span&gt; (username, token, token)
    send_mail(subject, message, sender, receiver, html_message&lt;/span&gt;=&lt;span&gt;html_message)
    time.sleep(&lt;/span&gt;5)
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;4.在发送邮件的地方&lt;strong&gt;调用&lt;/strong&gt;celery_tasks下的tasks下的&lt;strong&gt;发送邮件函数&lt;/strong&gt;；&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;40&quot;&gt;
&lt;pre&gt;
&lt;span&gt;from&lt;/span&gt; django.shortcuts &lt;span&gt;import&lt;/span&gt;&lt;span&gt; render, redirect, HttpResponse
&lt;/span&gt;&lt;span&gt;from&lt;/span&gt; django.core.mail &lt;span&gt;import&lt;/span&gt;&lt;span&gt; send_mail
&lt;/span&gt;&lt;span&gt;from&lt;/span&gt; itsdangerous &lt;span&gt;import&lt;/span&gt;&lt;span&gt; TimedJSONWebSignatureSerializer as Serializer
&lt;/span&gt;&lt;span&gt;from&lt;/span&gt; django.conf &lt;span&gt;import&lt;/span&gt;&lt;span&gt; settings

&lt;/span&gt;&lt;span&gt;def&lt;/span&gt;&lt;span&gt; emailtest(request):
    &lt;/span&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt; 发送激活邮件，包括激活链接：http://127.0.0.1:8000/user/active/3&lt;/span&gt;
    &lt;span&gt;#&lt;/span&gt;&lt;span&gt; 激活链接中需要包含用户的身份信息，并且要把身份信息进行加密&lt;/span&gt;
    &lt;span&gt;#&lt;/span&gt;&lt;span&gt; 加密用户的身份信息，生成激活token&lt;/span&gt;
    userid = 3&lt;span&gt;
    username &lt;/span&gt;= &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;mumun&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;
    email &lt;/span&gt;= &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;收邮件的邮箱&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;
    serializer &lt;/span&gt;= Serializer(settings.SECRET_KEY, 1800&lt;span&gt;)
    info &lt;/span&gt;= {&lt;span&gt;'&lt;/span&gt;&lt;span&gt;confirm&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;: userid}
    token &lt;/span&gt;=&lt;span&gt; serializer.dumps(info)
    token &lt;/span&gt;=&lt;span&gt; token.decode()
    &lt;/span&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt; 使用celery发送邮件&lt;/span&gt;
&lt;span&gt;    send_register_active_email.delay(email, username, token)

    &lt;/span&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt; 返回应答，跳转到首页&lt;/span&gt;
    &lt;span&gt;return&lt;/span&gt; HttpResponse(&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;邮件发送成功，请注意接收&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;)
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;配套url&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;35&quot;&gt;
&lt;pre&gt;
urlpatterns =&lt;span&gt; [
    url(r'^emailtest/$', views.emailtest, name=&quot;emailtest&quot;),  # 发邮件测试
]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;5.&lt;strong&gt;开启redis服务&lt;/strong&gt;；&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;35&quot;&gt;
&lt;pre&gt;
E:\&amp;gt;cd E:\YifChanSoft\Database\Redis\RedisSoft\Redis-x64-3.2.100&lt;span&gt;

E:\YifChanSoft\Database\Redis\RedisSoft\Redis&lt;/span&gt;-x64-3.2.100&amp;gt;redis-server --service-install redis.windows-service.conf --&lt;span&gt;loglevel verbose&lt;/span&gt;&lt;span&gt;

E:\YifChanSoft\Database\Redis\RedisSoft\Redis&lt;/span&gt;-x64-3.2.100&amp;gt;redis-&lt;span&gt;cli
&lt;/span&gt;127.0.0.1:6379&amp;gt; select 8&lt;span&gt;
OK
&lt;/span&gt;127.0.0.1:6379[8]&amp;gt; keys *&lt;span&gt;
(empty list &lt;/span&gt;&lt;span&gt;or&lt;/span&gt;&lt;span&gt; set)
&lt;/span&gt;127.0.0.1:6379[8]&amp;gt; keys *
1) &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;_kombu.binding.celery&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;
2) &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;_kombu.binding.celery.pidbox&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;
3) &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;_kombu.binding.celeryev&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;开启redis服务截图&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1618401/201909/1618401-20190915233640332-731219418.png&quot; alt=&quot;&quot; width=&quot;1011&quot; height=&quot;278&quot;/&gt;&lt;/p&gt;

&lt;p&gt;6.将项目代码拷贝一份放在某处，进入该处，&lt;strong&gt;启动tasks的worker模式&lt;/strong&gt;，&lt;br/&gt;注意，用作worker的代码的tasks文件中应该有提前启动django的初始化的代码，不然worker没法调用conf信息；&lt;/p&gt;
&lt;p&gt;即应该有以下内容&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;34&quot;&gt;
&lt;pre&gt;
&lt;span&gt;#&lt;/span&gt;&lt;span&gt; 在任务处理者一端时需要加这几句&lt;/span&gt;
&lt;span&gt;import&lt;/span&gt;&lt;span&gt; os
&lt;/span&gt;&lt;span&gt;import&lt;/span&gt;&lt;span&gt; django
os.environ.setdefault(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;DJANGO_SETTINGS_MODULE&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;, &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;项目名.settings&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;)
django.setup()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;开启worker模式&lt;/strong&gt;：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;32&quot;&gt;
&lt;pre&gt;
celery -A celery_tasks.tasks worker -l info
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;出现问题&lt;/strong&gt;，报错如下&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;33&quot;&gt;
&lt;pre&gt;
ValueError: &lt;span&gt;not&lt;/span&gt; enough values to unpack (expected 3, got 0)
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;原因&lt;/strong&gt;&lt;br/&gt;win10上运行celery4.x就会出现这个问题&lt;br/&gt;&lt;strong&gt;解决&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot;&gt;
&lt;pre&gt;
pip install eventlet
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;并在开启worker模式时加入参数&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;32&quot;&gt;
&lt;pre&gt;
celery -A celery_tasks.tasks worker -l info -P eventlet
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;开启worker模式截图，后面还有内容，但因为太多了，就只截一半&lt;/p&gt;
&lt;p&gt; &lt;img src=&quot;https://img2018.cnblogs.com/blog/1618401/201909/1618401-20190915231242552-1241379960.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;7.在浏览器中输入如下地址，即可看到“邮件已发送”的提示信息&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;32&quot;&gt;
&lt;pre&gt;
http://127.0.0.1:8000/user/emailtest/
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;接收邮件如下&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1618401/201909/1618401-20190915231715472-2028517538.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

</description>
<pubDate>Sun, 15 Sep 2019 15:44:00 +0000</pubDate>
<dc:creator>YifChan</dc:creator>
<og:description>Django之使用内置函数和celery发邮件，内容包括 发送邮件前的邮箱配置，使用Django内置函数发邮件，使用celery发邮件。在开发项目时，特别是用户注册时，我们通常都要给用户发送邮件验证注</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/yifchan/p/python-1-34.html</dc:identifier>
</item>
<item>
<title>C# 表达式树Lambda扩展（四） - 园子的蜗牛</title>
<link>http://www.cnblogs.com/snailblog/p/11525118.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/snailblog/p/11525118.html</guid>
<description>&lt;h2&gt;一、前言&lt;/h2&gt;
&lt;p&gt;本来计算这篇文章在后面需要运用的时候写的，但是既然写到表达式的扩展呢，就一起写完吧。&lt;/p&gt;
&lt;p&gt;看到这个标题就有一种疑问，Lambda表达式本来就是表达式树，还需要怎么扩展？那就看看下面的内容，你就知道了。&lt;/p&gt;
&lt;p&gt;表达式系列目录&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.cnblogs.com/snailblog/p/11521043.html&quot; target=&quot;_blank&quot;&gt;C# 表达式树讲解（一）&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.cnblogs.com/snailblog/p/11521335.html&quot; target=&quot;_blank&quot;&gt;C# 表达式树遍历（二）&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.cnblogs.com/snailblog/p/11521359.html&quot; target=&quot;_blank&quot;&gt;C# 表达式树分页扩展（三）&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;C# 表达式树Lambda扩展（四）&lt;/p&gt;
&lt;h2&gt;二、Lambda扩展&lt;/h2&gt;
&lt;p&gt;这里先不忙解答上面的问题，我们先看下这样一个应用场景。&lt;/p&gt;
&lt;p&gt;一个页面的请求，里面带有一些条件查询，请求类如下&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;33&quot;&gt;
&lt;pre&gt;
&lt;span&gt;public&lt;/span&gt; &lt;span&gt;class&lt;/span&gt; ScoreRequest
{
    &lt;span&gt;public&lt;/span&gt; &lt;span&gt;string&lt;/span&gt; CourseName { &lt;span&gt;get&lt;/span&gt;; &lt;span&gt;set&lt;/span&gt;; }
    &lt;span&gt;public&lt;/span&gt; &lt;span&gt;string&lt;/span&gt; StudentName { &lt;span&gt;get&lt;/span&gt;; &lt;span&gt;set&lt;/span&gt;; }
}
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;要求查询与课程名称和学生名称匹配的数据&lt;/p&gt;
&lt;p&gt;数据源我们就以上一例子的数据源&lt;/p&gt;
&lt;p&gt;数据源类&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; onclick=&quot;cnblogs_code_show('7c1c5bab-2858-4ba0-b00f-285fde640fa8')&quot; readability=&quot;31.5&quot;&gt;&lt;img id=&quot;code_img_closed_7c1c5bab-2858-4ba0-b00f-285fde640fa8&quot; class=&quot;code_img_closed&quot; src=&quot;https://images.cnblogs.com/OutliningIndicators/ContractedBlock.gif&quot; alt=&quot;&quot;/&gt;&lt;img id=&quot;code_img_opened_7c1c5bab-2858-4ba0-b00f-285fde640fa8&quot; class=&quot;code_img_opened&quot; onclick=&quot;cnblogs_code_hide('7c1c5bab-2858-4ba0-b00f-285fde640fa8',event)&quot; src=&quot;https://images.cnblogs.com/OutliningIndicators/ExpandedBlockStart.gif&quot; alt=&quot;&quot;/&gt;&lt;div id=&quot;cnblogs_code_open_7c1c5bab-2858-4ba0-b00f-285fde640fa8&quot; class=&quot;cnblogs_code_hide&quot; readability=&quot;58&quot;&gt;
&lt;pre&gt;
&lt;span&gt;public&lt;/span&gt; &lt;span&gt;class&lt;/span&gt; ScoreClass
{
    &lt;span&gt;public&lt;/span&gt; &lt;span&gt;string&lt;/span&gt; CourseName { &lt;span&gt;get&lt;/span&gt;; &lt;span&gt;set&lt;/span&gt;; }
    &lt;span&gt;public&lt;/span&gt; &lt;span&gt;string&lt;/span&gt; StudentName { &lt;span&gt;get&lt;/span&gt;; &lt;span&gt;set&lt;/span&gt;; }
    &lt;span&gt;public&lt;/span&gt; &lt;span&gt;decimal&lt;/span&gt; Score { &lt;span&gt;get&lt;/span&gt;; &lt;span&gt;set&lt;/span&gt;; }
}
&lt;/pre&gt;&lt;/div&gt;
&lt;span class=&quot;cnblogs_code_collapse&quot;&gt;View Code&lt;/span&gt;&lt;/div&gt;
&lt;p&gt;添加数据&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; onclick=&quot;cnblogs_code_show('0202f065-a5f2-4a5d-996e-09abb4a3b60d')&quot; readability=&quot;41.5&quot;&gt;&lt;img id=&quot;code_img_closed_0202f065-a5f2-4a5d-996e-09abb4a3b60d&quot; class=&quot;code_img_closed&quot; src=&quot;https://images.cnblogs.com/OutliningIndicators/ContractedBlock.gif&quot; alt=&quot;&quot;/&gt;&lt;img id=&quot;code_img_opened_0202f065-a5f2-4a5d-996e-09abb4a3b60d&quot; class=&quot;code_img_opened&quot; onclick=&quot;cnblogs_code_hide('0202f065-a5f2-4a5d-996e-09abb4a3b60d',event)&quot; src=&quot;https://images.cnblogs.com/OutliningIndicators/ExpandedBlockStart.gif&quot; alt=&quot;&quot;/&gt;&lt;div id=&quot;cnblogs_code_open_0202f065-a5f2-4a5d-996e-09abb4a3b60d&quot; class=&quot;cnblogs_code_hide&quot; readability=&quot;78&quot;&gt;
&lt;pre&gt;
var datas = &lt;span&gt;new&lt;/span&gt; List&amp;lt;ScoreClass&amp;gt;();
datas.Add(&lt;span&gt;new&lt;/span&gt; ScoreClass
{
    CourseName = &quot;&lt;span&gt;数学&lt;/span&gt;&quot;,
    StudentName = &quot;&lt;span&gt;学生A&lt;/span&gt;&quot;,
    Score = 60
});
datas.Add(&lt;span&gt;new&lt;/span&gt; ScoreClass
{
    CourseName = &quot;&lt;span&gt;数学&lt;/span&gt;&quot;,
    StudentName = &quot;&lt;span&gt;学生B&lt;/span&gt;&quot;,
    Score = 65
});
datas.Add(&lt;span&gt;new&lt;/span&gt; ScoreClass
{
    CourseName = &quot;&lt;span&gt;数学&lt;/span&gt;&quot;,
    StudentName = &quot;&lt;span&gt;学生C&lt;/span&gt;&quot;,
    Score = 70
});
datas.Add(&lt;span&gt;new&lt;/span&gt; ScoreClass
{
    CourseName = &quot;&lt;span&gt;数学&lt;/span&gt;&quot;,
    StudentName = &quot;&lt;span&gt;学生D&lt;/span&gt;&quot;,
    Score = 75
});
datas.Add(&lt;span&gt;new&lt;/span&gt; ScoreClass
{
    CourseName = &quot;&lt;span&gt;数学&lt;/span&gt;&quot;,
    StudentName = &quot;&lt;span&gt;学生E&lt;/span&gt;&quot;,
    Score = 80
});
datas.Add(&lt;span&gt;new&lt;/span&gt; ScoreClass
{
    CourseName = &quot;&lt;span&gt;数学&lt;/span&gt;&quot;,
    StudentName = &quot;&lt;span&gt;学生F&lt;/span&gt;&quot;,
    Score = 81
});
datas.Add(&lt;span&gt;new&lt;/span&gt; ScoreClass
{
    CourseName = &quot;&lt;span&gt;数学&lt;/span&gt;&quot;,
    StudentName = &quot;&lt;span&gt;学生G&lt;/span&gt;&quot;,
    Score = 82
});
datas.Add(&lt;span&gt;new&lt;/span&gt; ScoreClass
{
    CourseName = &quot;&lt;span&gt;数学&lt;/span&gt;&quot;,
    StudentName = &quot;&lt;span&gt;学生H&lt;/span&gt;&quot;,
    Score = 83
});
datas.Add(&lt;span&gt;new&lt;/span&gt; ScoreClass
{
    CourseName = &quot;&lt;span&gt;数学&lt;/span&gt;&quot;,
    StudentName = &quot;&lt;span&gt;学生I&lt;/span&gt;&quot;,
    Score = 84
});
&lt;/pre&gt;&lt;/div&gt;
&lt;span class=&quot;cnblogs_code_collapse&quot;&gt;View Code&lt;/span&gt;&lt;/div&gt;
&lt;p&gt;好了现在我们就查询数据&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;35&quot;&gt;
&lt;pre&gt;
var request = &lt;span&gt;new&lt;/span&gt; ScoreRequest()
            {
                CourseName = &quot;&lt;span&gt;数&lt;/span&gt;&quot;,
                StudentName = &quot;&lt;span&gt;H&lt;/span&gt;&quot;
            };
            var resultDatas = datas.Where(e =&amp;gt; e.CourseName.Contains(request.CourseName) &amp;amp;&amp;amp; e.StudentName.Contains(request.StudentName))
                .ToList();
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;如果查询对象里面CourseName和StudentName字段都有值得话，这样写没问题。如果没值，那就最后的数据，就不准确了。&lt;/p&gt;
&lt;p&gt;如果是直接拼凑sql语句，我们可以用if(String.IsNullOrEmpty())来判断，但是现在判断了，怎么拼凑Lambda表达式呢？&lt;/p&gt;
&lt;p&gt;所以就需要我们对Lambda表达式进行扩展，让他支持这种情况。那上面的问题，就不用再专门回答了吧！！！！&lt;/p&gt;
&lt;p&gt;创建一个LambdaExtension的类，代码如下&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;63&quot;&gt;
&lt;pre&gt;
&lt;span&gt;public&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; &lt;span&gt;class&lt;/span&gt; LambdaExtension
{
    &lt;span&gt;public&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; Expression&amp;lt;Func&amp;lt;T, &lt;span&gt;bool&lt;/span&gt;&amp;gt;&amp;gt; True&amp;lt;T&amp;gt;() { &lt;span&gt;return&lt;/span&gt; param =&amp;gt; &lt;span&gt;true&lt;/span&gt;; }
    &lt;span&gt;public&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; Expression&amp;lt;Func&amp;lt;T, &lt;span&gt;bool&lt;/span&gt;&amp;gt;&amp;gt; False&amp;lt;T&amp;gt;() { &lt;span&gt;return&lt;/span&gt; param =&amp;gt; &lt;span&gt;false&lt;/span&gt;; }
    &lt;span&gt;public&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; Expression&amp;lt;Func&amp;lt;T, &lt;span&gt;bool&lt;/span&gt;&amp;gt;&amp;gt; And&amp;lt;T&amp;gt;(&lt;span&gt;this&lt;/span&gt; Expression&amp;lt;Func&amp;lt;T, &lt;span&gt;bool&lt;/span&gt;&amp;gt;&amp;gt; first, Expression&amp;lt;Func&amp;lt;T, &lt;span&gt;bool&lt;/span&gt;&amp;gt;&amp;gt; second)
    {
        &lt;span&gt;return&lt;/span&gt; first.Compose(second, Expression.AndAlso);
    }
    &lt;span&gt;public&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; Expression&amp;lt;Func&amp;lt;T, &lt;span&gt;bool&lt;/span&gt;&amp;gt;&amp;gt; Or&amp;lt;T&amp;gt;(&lt;span&gt;this&lt;/span&gt; Expression&amp;lt;Func&amp;lt;T, &lt;span&gt;bool&lt;/span&gt;&amp;gt;&amp;gt; first, Expression&amp;lt;Func&amp;lt;T, &lt;span&gt;bool&lt;/span&gt;&amp;gt;&amp;gt; second)
    {
        &lt;span&gt;return&lt;/span&gt; first.Compose(second, Expression.OrElse);
    }
    &lt;span&gt;private&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; Expression&amp;lt;T&amp;gt; Compose&amp;lt;T&amp;gt;(&lt;span&gt;this&lt;/span&gt; Expression&amp;lt;T&amp;gt; first, Expression&amp;lt;T&amp;gt; second, Func&amp;lt;Expression, Expression, Expression&amp;gt; merge)
    {
        var map = first.Parameters
            .Select((f, i) =&amp;gt; &lt;span&gt;new&lt;/span&gt; { f, s = second.Parameters[i] })
            .ToDictionary(p =&amp;gt; p.s, p =&amp;gt; p.f);
        var secondBody = PFTParameterExtension.ReplaceParameters(map, second.Body);
        &lt;span&gt;return&lt;/span&gt; Expression.Lambda&amp;lt;T&amp;gt;(merge(first.Body, secondBody), first.Parameters);
    }

    &lt;span&gt;private&lt;/span&gt; &lt;span&gt;class&lt;/span&gt; PFTParameterExtension : ExpressionVisitor
    {
        &lt;span&gt;private&lt;/span&gt; &lt;span&gt;readonly&lt;/span&gt; Dictionary&amp;lt;ParameterExpression, ParameterExpression&amp;gt; map;

        &lt;span&gt;public&lt;/span&gt; PFTParameterExtension()
        {

        }

        &lt;span&gt;public&lt;/span&gt; PFTParameterExtension(Dictionary&amp;lt;ParameterExpression, ParameterExpression&amp;gt; map)
        {
            &lt;span&gt;this&lt;/span&gt;.map = map ?? &lt;span&gt;new&lt;/span&gt; Dictionary&amp;lt;ParameterExpression, ParameterExpression&amp;gt;();
        }

        &lt;span&gt;/// &amp;lt;summary&amp;gt;&lt;/span&gt;
        &lt;span&gt;/// 替换参数&lt;/span&gt;
        &lt;span&gt;/// &amp;lt;/summary&amp;gt;&lt;/span&gt;
        &lt;span&gt;/// &amp;lt;param name=&quot;map&quot;&amp;gt;The map.&amp;lt;/param&amp;gt;&lt;/span&gt;
        &lt;span&gt;/// &amp;lt;param name=&quot;exp&quot;&amp;gt;The exp.&amp;lt;/param&amp;gt;&lt;/span&gt;
        &lt;span&gt;/// &amp;lt;returns&amp;gt;Expression&amp;lt;/returns&amp;gt;&lt;/span&gt;
        &lt;span&gt;public&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; Expression ReplaceParameters(Dictionary&amp;lt;ParameterExpression, ParameterExpression&amp;gt; map, Expression exp)
        {
            &lt;span&gt;return&lt;/span&gt; &lt;span&gt;new&lt;/span&gt; PFTParameterExtension(map).Visit(exp);
        }

        &lt;span&gt;protected&lt;/span&gt; &lt;span&gt;override&lt;/span&gt; Expression VisitParameter(ParameterExpression p)
        {
            ParameterExpression replacement;
            &lt;span&gt;if&lt;/span&gt; (map != &lt;span&gt;null&lt;/span&gt; &amp;amp;&amp;amp; map.Count &amp;gt; 0 &amp;amp;&amp;amp; map.TryGetValue(p, &lt;span&gt;out&lt;/span&gt; replacement))
            {
                p = replacement;
            }
            &lt;span&gt;return&lt;/span&gt; &lt;span&gt;base&lt;/span&gt;.VisitParameter(p);
        }

    }

}
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;这里面私有化了一个表达式树访问器，他的作用主要是用来同步Lambda表达式里面的参数。&lt;/p&gt;
&lt;p&gt;下面是调用方式&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;36&quot;&gt;
&lt;pre&gt;
            var expression = LambdaExtension.True&amp;lt;ScoreClass&amp;gt;();
            &lt;span&gt;if&lt;/span&gt; (!&lt;span&gt;string&lt;/span&gt;.IsNullOrWhiteSpace(request.CourseName))
                expression = expression.And(e =&amp;gt; e.CourseName.Contains(request.CourseName));
            &lt;span&gt;if&lt;/span&gt; (!&lt;span&gt;string&lt;/span&gt;.IsNullOrWhiteSpace(request.StudentName))
                expression = expression.And(et =&amp;gt; et.StudentName.Contains(request.StudentName));

            var resultDatas = datas.Where(expression.Compile())
                .ToList();
            Console.WriteLine($&quot;&lt;span&gt;查询结果：\n{string.Join(&lt;/span&gt;&quot;\n&quot;&lt;span&gt;, resultDatas.Select(e =&amp;gt; $&lt;/span&gt;&quot;{e.StudentName} {e.CourseName} {e.Score}&quot;&lt;span&gt;))}&lt;/span&gt;&quot;);
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;where条件里面只能带委托，而我们的expression是Lambda表达式，所以需要Compile进行委托编译。&lt;/p&gt;
&lt;p&gt;运行结果：&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://img2018.cnblogs.com/blog/1764554/201909/1764554-20190915233248551-1551453117.png&quot;&gt;&lt;img title=&quot;image&quot; src=&quot;https://img2018.cnblogs.com/blog/1764554/201909/1764554-20190915233249105-1678472774.png&quot; alt=&quot;image&quot; width=&quot;491&quot; height=&quot;179&quot; border=&quot;0&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;仔细看代码，第一个条件And里面的参数是“e”，第二个条件里面的参数是et，同一个Lambda表达式里面（这里只有一个参数），参数肯定是一致的，所以在LambdaExtension类中，在合并两个Lambda表达式的时候，就需要将参数合并成一个。&lt;/p&gt;
&lt;p&gt;经过这样的扩展，我们就可以根据我们的实际情况，拼凑好需要的表达式，得到我们想要的结果。&lt;/p&gt;
&lt;h2&gt;三、总结&lt;/h2&gt;
&lt;p&gt;表达式树方面的讲解，终于可以告一段落了。一直后没有这样的写文章，现在觉得写文章还是真的挺累的，今年中秋节的这三天，算是全部的给博客园了。不过这三天讲解的内容，基本上把后面Dapper的扩展需要用的技术都铺垫了，后面我们就继续对ORM的讲解了。其实没写一篇博文，蜗牛都会去罗列和梳理相关知识点，这也让蜗牛获益匪浅，也希望蜗牛的博客能帮助到园友，这就是所谓的“赠人玫瑰，手留余香”吧。&lt;/p&gt;
</description>
<pubDate>Sun, 15 Sep 2019 15:34:00 +0000</pubDate>
<dc:creator>园子的蜗牛</dc:creator>
<og:description>一、前言 本来计算这篇文章在后面需要运用的时候写的，但是既然写到表达式的扩展呢，就一起写完吧。 看到这个标题就有一种疑问，Lambda表达式本来就是表达式树，还需要怎么扩展？那就看看下面的内容，你就知</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/snailblog/p/11525118.html</dc:identifier>
</item>
<item>
<title>浅入浅出 Java 排序算法 - www.bysocket.com</title>
<link>http://www.cnblogs.com/Alandre/p/11524985.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/Alandre/p/11524985.html</guid>
<description>&lt;h2 id=&quot;一前言&quot;&gt;一、前言&lt;/h2&gt;
&lt;p&gt;Q：什么是选择问题？&lt;br/&gt;选择问题，是假设一组 N 个数，要确定其中第 K 个最大值者。比如 A 与 B 对象需要哪个更大？又比如：要考虑从一些数组中找出最大项？&lt;/p&gt;
&lt;p&gt;解决选择问题，需要对象有个能力，即比较任意两个对象，并确定哪个大，哪个小或者相等。找出最大项问题的解决方法，只要依次用对象的比较（Comparable）能力，循环对象列表，一次就能解决。&lt;/p&gt;
&lt;p&gt;那么 JDK 源码如何实现比较（Comparable）能力的呢？&lt;/p&gt;
&lt;h2 id=&quot;二java.lang.comparable-接口&quot;&gt;二、java.lang.Comparable 接口&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/509099/201909/509099-20190915225607070-103632971.png&quot; alt=&quot;file&quot;/&gt;&lt;/p&gt;
&lt;p&gt;Comparable 接口，从 JDK 1.2 版本就有了，历史算悠久。Comparable 接口强制了实现类对象列表的排序。其排序称为自然顺序，其 &lt;code&gt;compareTo&lt;/code&gt; 方法，称为自然比较法。&lt;/p&gt;
&lt;p&gt;该接口只有一个方法 &lt;code&gt;public int compareTo(T o);&lt;/code&gt; ，可以看出&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;入参 T o ：实现该接口类，传入对应的要被比较的对象&lt;/li&gt;
&lt;li&gt;返回值 int：正数、负数和 0 ，代表大于、小于和等于&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;对象的集合列表（Collection List）或者数组（arrays） ，也有对应的工具类可以方便的使用：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;java.util.Collections#sort(List) 列表排序&lt;/li&gt;
&lt;li&gt;java.util.Arrays#sort(Object[]) 数组排序&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;那 String 对象如何被比较的？&lt;/p&gt;
&lt;h2 id=&quot;三string-源码中的算法&quot;&gt;三、String 源码中的算法&lt;/h2&gt;
&lt;p&gt;String 源码中可以看到 String JDK 1.0 就有了。那么应该是 JDK 1.2 的时候，String 类实现了 Comparable 接口，并且传入需要被比较的对象是 String。对象如图：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/509099/201909/509099-20190915225608423-618866121.png&quot; alt=&quot;file&quot;/&gt;&lt;/p&gt;
&lt;p&gt;String 是一个 final 类，无法从 String 扩展新的类。从 114 行，可以看出字符串的存储结构是字符（Char）数组。先可以看看一个字符串比较案例，代码如下：&lt;/p&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;
/**
 * 字符串比较案例
 *
 * Created by bysocket on 19/5/10.
 */
public class StringComparisonDemo {
    
    public static void main(String[] args) {
        String foo = &quot;ABC&quot;;
        
        // 前面和后面每个字符完全一样，返回 0
        String bar01 = &quot;ABC&quot;;
        System.out.println(foo.compareTo(bar01));
        
        // 前面每个字符完全一样，返回：后面就是字符串长度差
        String bar02 = &quot;ABCD&quot;;
        String bar03 = &quot;ABCDE&quot;;
        System.out.println(foo.compareTo(bar02)); // -1 (前面相等,foo 长度小 1)
        System.out.println(foo.compareTo(bar03)); // -2 (前面相等,foo 长度小 2)
        
        // 前面每个字符不完全一样，返回：出现不一样的字符 ASCII 差
        String bar04 = &quot;ABD&quot;;
        String bar05 = &quot;aABCD&quot;;
        System.out.println(foo.compareTo(bar04)); // -1  (foo 的 'C' 字符 ASCII 码值为 67，bar04 的 'D' 字符 ASCII 码值为 68。返回 67 - 68 = -1)
        System.out.println(foo.compareTo(bar05)); // -32 (foo 的 'A' 字符 ASCII 码值为 65，bar04 的 'a' 字符 ASCII 码值为 97。返回 65 - 97 = -32)
        
        String bysocket01 = &quot;泥瓦匠&quot;;
        String bysocket02 = &quot;瓦匠&quot;;
        System.out.println(bysocket01.compareTo(bysocket02));// -2049 （泥 和 瓦的 Unicode 差值）
    }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;运行结果如下：&lt;/p&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;0
-1
-2
-1
-32
-2049
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;可以看出， &lt;code&gt;compareTo&lt;/code&gt; 方法是按字典顺序比较两个字符串。具体比较规则可以看代码注释。比较规则如下：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;字符串的每个字符完全一样，返回 0&lt;/li&gt;
&lt;li&gt;字符串前面部分的每个字符完全一样，返回：后面就是两个字符串长度差&lt;/li&gt;
&lt;li&gt;字符串前面部分的每个字符存在不一样，返回：出现不一样的字符 ASCII 码的差值
&lt;ul&gt;&lt;li&gt;中文比较返回对应的 Unicode 编码值（Unicode 包含 ASCII）&lt;/li&gt;
&lt;li&gt;foo 的 'C' 字符 ASCII 码值为 67&lt;/li&gt;
&lt;li&gt;bar04 的 'D' 字符 ASCII 码值为 68。&lt;/li&gt;
&lt;li&gt;foo.compareTo(bar04)，返回 67 - 68 = -1&lt;/li&gt;
&lt;li&gt;常见字符 ASCII 码，如图所示&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/509099/201909/509099-20190915225609588-1310659961.png&quot; alt=&quot;file&quot;/&gt;&lt;/p&gt;
&lt;p&gt;再看看 String 的 &lt;code&gt;compareTo&lt;/code&gt; 方法如何实现字典顺序的。源码如图：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/509099/201909/509099-20190915225612844-595559443.png&quot; alt=&quot;file&quot;/&gt;&lt;/p&gt;
&lt;p&gt;源码解析如下：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;第 1156 行：获取当前字符串和另一个字符串，长度较小的长度值 lim&lt;/li&gt;
&lt;li&gt;第 1161 行：如果 lim 大于 0 （较小的字符串非空），则开始比较&lt;/li&gt;
&lt;li&gt;第 1164 行：当前字符串和另一个字符串，依次字符比较。如果不相等，则返回两字符的 Unicode 编码值的差值&lt;/li&gt;
&lt;li&gt;第 1169 行：当前字符串和另一个字符串，依次字符比较。如果均相等，则返回两个字符串长度的差值&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;所以要排序，肯定先有比较能力，即实现 Comparable 接口。然后实现此接口的对象列表（和数组）可以通过 Collections.sort（和 Arrays.sort）进行排序。&lt;/p&gt;
&lt;p&gt;还有 TreeSet 使用树结构实现（红黑树），集合中的元素进行排序。其中排序就是实现 Comparable 此接口&lt;/p&gt;
&lt;p&gt;另外，如果没有实现 Comparable 接口，使用排序时，会抛出 java.lang.ClassCastException 异常。详细看《Java 集合：三、HashSet，TreeSet 和 LinkedHashSet比较》https://www.bysocket.com/archives/195&lt;/p&gt;
&lt;h2 id=&quot;四小结&quot;&gt;四、小结&lt;/h2&gt;
&lt;p&gt;上面也说到，这种比较其实有一定的弊端：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;默认 compareTo 不忽略字符大小写。如果需要忽略，则重新自定义 compareTo 方法&lt;/li&gt;
&lt;li&gt;无法进行二维的比较决策。比如判断 2 * 1 矩形和 3 * 3 矩形，哪个更大？&lt;/li&gt;
&lt;li&gt;比如有些类无法实现该接口。一个 final 类，也无法扩展新的类。其也有解决方案：函数对象（Function Object）&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;方法参数：定义一个没有数据只有方法的类，并传递该类的实例。一个函数通过将其放在一个对象内部而被传递。这种对象通常叫做函数对象（Funtion Object）&lt;/p&gt;
&lt;p&gt;在接口方法设计中， T execute(Callback callback) 参数中使用 callback 类似。比如在 Spring 源码中，可以看出很多设计是：聚合优先于继承或者实现。这样可以减少很多继承或者实现。类似 SpringJdbcTemplate 场景设计，可以考虑到这种 Callback 设计实现。&lt;/p&gt;

&lt;p&gt;文章工程：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;JDK 1.8&lt;/li&gt;
&lt;li&gt;工程名：algorithm-core-learning&lt;/li&gt;
&lt;li&gt;工程地址：https://github.com/JeffLi1993/algorithm-core-learning&lt;/li&gt;
&lt;/ul&gt;&lt;h2 id=&quot;一前言-1&quot;&gt;一、前言&lt;/h2&gt;
&lt;p&gt;上面 Java String 源码的排序算法，讲了什么是选择问题，什么是比较能力。&lt;/p&gt;
&lt;p&gt;选择问题，是假设一组 N 个数，要确定其中第 K 个最大值者。算法是为求解一个问题。&lt;/p&gt;
&lt;p&gt;那什么是算法？&lt;br/&gt;算法是某种集合，是简单指令的集合，是被指定的简单指令集合。确定该算法重要的指标：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;第一是否能解决问题；&lt;/li&gt;
&lt;li&gt;第二算法运行时间，即解决问题出结果需要多少时间；&lt;/li&gt;
&lt;li&gt;还有所需的空间资源，比如内存等。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;很多时候，写一个工作程序并不够。因为遇到大数据下，运行时间就是一个重要的问题。&lt;/p&gt;
&lt;p&gt;算法性能用大 O 标记法表示。大 O 标记法是标记相对增长率，精度是粗糙的。比如 2N 和 3N + 2 ，都是 O(N)。也就是常说的线性增长，还有常说的指数增长等&lt;/p&gt;
&lt;p&gt;典型的增长率&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/509099/201909/509099-20190915225613209-337708320.png&quot; alt=&quot;file&quot;/&gt;&lt;/p&gt;
&lt;p&gt;典型的提供性能做法是分治法，即分支 divide and conquer 策略：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;将问题分成两个大致相等的子问题，递归地对它们求解，这是分的部分；&lt;/li&gt;
&lt;li&gt;治阶段将两个子问题的解修补到一起，并可能再做些少量的附加工作，最后得到整个问题的解。&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/509099/201909/509099-20190915225613375-2011253907.jpg&quot; alt=&quot;file&quot;/&gt;&lt;/p&gt;
&lt;h2 id=&quot;二排序&quot;&gt;二、排序&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/509099/201909/509099-20190915225613552-730670126.jpg&quot; alt=&quot;file&quot;/&gt;&lt;/p&gt;
&lt;p&gt;排序问题，是古老，但一直流行的问题。从 ACM 接触到现在工作，每次涉及算法，或品读 JDK 源码中一些算法，经常会有排序的算法出现。&lt;/p&gt;
&lt;p&gt;排序算法是为了将一组数组（或序列）重新排列，排列后数据符合从大到小（或从小到大）的次序。这样数据从无序到有序，会有什么好处？&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;应用层面：解决问题。
&lt;ul&gt;&lt;li&gt;最简单的是可以找到最大值或者最小值&lt;/li&gt;
&lt;li&gt;解决&quot;一起性&quot;问题，即相同标志元素连在一起&lt;/li&gt;
&lt;li&gt;匹配在两个或者更多个文件中的项目&lt;/li&gt;
&lt;li&gt;通过键码值查找信息&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;系统层面：减少系统的熵值，增加系统的有序度&lt;br/&gt;（Donald Knuth 的经典之作《计算机程序设计艺术》(The Art of Computer Programming)的第三卷）&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;通过维基百科查阅资料得到：&lt;br/&gt;在主内存中完成的排序叫做，内部排序。那需要在磁盘等其他存储完成的排序，叫做外部排序 external sorting。资料地址：https://en.wikipedia.org/wiki/External_sorting&lt;/p&gt;
&lt;p&gt;上一篇《Java String 源码的排序算法》，讲到了 java.lang.Comparable 接口。那么接口是一个抽象类型，是抽象方法（compareTo）的集合，用 interface 来声明。因此被排序的对象属于 Comparable 类型，即实现 Comparable 接口，然后调用对象实现的 compareTo 方法进行比较后排序。&lt;/p&gt;
&lt;p&gt;在这些条件下的排序，叫作基于比较的排序（comparison-based sorting）&lt;/p&gt;
&lt;h2 id=&quot;三插入排序&quot;&gt;三、插入排序&lt;/h2&gt;
&lt;p&gt;白话文：熊大（一）、熊二、熊三... 按照身高从低到高排队（排序）。这时候熊 N 加入队伍，它从队伍尾巴开始比较。如果它比前面的熊身高低，则与被比较的交换位置，依次从尾巴到头部进行比较 &amp;amp; 交换位置。最终换到了应该熊 N 所在的位置。这就是插入排序的原理。&lt;/p&gt;
&lt;p&gt;插入排序（insertion sort）&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;最简单的排序之一。ps: 冒泡排序看看就好，不推荐学习&lt;/li&gt;
&lt;li&gt;由 N - 1 次排序过程组成。
&lt;ul&gt;&lt;li&gt;如果被排序的这样一个元素，就不需要排序。即 N =1 （1 - 1 = 0）&lt;/li&gt;
&lt;li&gt;每一次排序保证，从第一个位置到当前位置的元素为已排序状态。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;如图：每个元素往前进行比较，并终止于自己所在的位置&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/509099/201909/509099-20190915225617841-1527879630.gif&quot; alt=&quot;file&quot;/&gt;&lt;/p&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;/**
 * 插入排序案例
 * &amp;lt;p&amp;gt;
 * Created by 泥瓦匠@bysocket.com on 19/5/15.
 */
public class InsertionSortingDemo {
    
    /**
     * 插入排序
     *
     * @param arr 能比较的对象数组
     * @param &amp;lt;T&amp;gt; 已排序的对象数组
     */
    public static &amp;lt;T extends Comparable&amp;gt; void insertionSort(T[] arr) {
        int j;
        
        // 从数组第二个元素开始，向前比较
        for (int p = 1; p &amp;lt; arr.length; p++) {
            T tmp = arr[p];
            // 循环，向前依次比较
            // 如果比前面元素小，交换位置
            for (j = p; (j &amp;gt; 0) &amp;amp;&amp;amp; (tmp.compareTo(arr[j - 1]) &amp;lt; 0); j--) {
                arr[j] = arr[j - 1];
            }
            // 如果比前面元素大或者相等，那么这就是元素的位置，交换
            arr[j] = tmp;
        }
    }
    
    public static void main(String[] args) {
        Integer[] intArr = new Integer[] {2, 3, 1, 4, 3};
        
        System.out.println(Arrays.toString(intArr));
        insertionSort(intArr);
        System.out.println(Arrays.toString(intArr));
    }
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;代码解析如下：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;从数组的第二个元素，向前开始比较。比第一个元素小，则交换位置&lt;/li&gt;
&lt;li&gt;如果第二个元素比较完毕，那就第三个，第四个... 以此类推&lt;/li&gt;
&lt;li&gt;比较到最后一个元素时，完成排序&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;时间复杂度是 O(N^2)，最好情景的是排序已经排好的，那就是 O（N），因为满足不了循环的判断条件；最极端的是反序的数组，那就是 O(N^2)。所以该算法的时间复杂度为 O(N^2)&lt;/p&gt;
&lt;p&gt;运行 main 方法，结果如下：&lt;/p&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;[2, 3, 1, 4, 3]
[1, 2, 3, 3, 4]&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;再考虑考虑优化，会怎么优化呢？&lt;br/&gt;插入排序优化版 不是往前比较 。往前的一半比较，二分比较会更好。具体代码，可以自行试试&lt;/p&gt;
&lt;h2 id=&quot;四array.sort-源码中的插入排序&quot;&gt;四、Array.sort 源码中的插入排序&lt;/h2&gt;
&lt;p&gt;上面用自己实现的插入算法进行排序，其实 JDK 提供了 Array.sort 方法，方便排序。案例代码如下：&lt;/p&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;/**
 * Arrays.sort 排序案例
 * &amp;lt;p&amp;gt;
 * Created by 泥瓦匠@bysocket.com on 19/5/28.
 */
public class ArraysSortDemo {
    
    public static void main(String[] args) {
    
        Integer[] intArr = new Integer[] {2, 3, 1, 4, 3};
    
        System.out.println(Arrays.toString(intArr));
        Arrays.sort(intArr);
        System.out.println(Arrays.toString(intArr));
    }
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;运行 main 方法，结果如下：&lt;/p&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;[2, 3, 1, 4, 3]
[1, 2, 3, 3, 4]&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;那 Arrays.sort 是如何实现的呢？JDK 1.2 的时候有了 Arrays ，JDK 1.8 时优化了一版 sort 算法。大致如下：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;如果元素数量小于 47，使用插入排序&lt;/li&gt;
&lt;li&gt;如果元素数量小于 286，使用快速排序&lt;/li&gt;
&lt;li&gt;Timsort 算法整合了归并排序和插入排序&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/509099/201909/509099-20190915225618566-913920823.png&quot; alt=&quot;file&quot;/&gt;&lt;/p&gt;
&lt;p&gt;源码中我们看到了 mergeSort 里面整合了插入排序算法，跟上面实现的异曲同工。这边就不一行一行解释了。&lt;/p&gt;
&lt;h2 id=&quot;五小结&quot;&gt;五、小结&lt;/h2&gt;
&lt;p&gt;算法是解决问题的。所以不一定一个算法解决一个问题，可能多个算法一起解决一个问题。达到问题的最优解。插入排序，这样就这么简单&lt;/p&gt;
&lt;h3 id=&quot;代码示例&quot;&gt;代码示例&lt;/h3&gt;
&lt;p&gt;本文示例读者可以通过查看下面仓库的中: StringComparisonDemo 字符串比较案例案例：&lt;/p&gt;
&lt;h3 id=&quot;参考资料&quot;&gt;参考资料&lt;/h3&gt;
&lt;ul&gt;&lt;li&gt;《数据结构与算法分析：Java语言描述（原书第3版）》&lt;/li&gt;
&lt;li&gt;https://en.wikipedia.org/wiki/Unicode&lt;/li&gt;
&lt;li&gt;https://www.cnblogs.com/vamei/tag/%E7%AE%97%E6%B3%95/&lt;/li&gt;
&lt;li&gt;https://www.bysocket.com/archives/2314/algorithm&lt;/li&gt;
&lt;/ul&gt;</description>
<pubDate>Sun, 15 Sep 2019 14:56:00 +0000</pubDate>
<dc:creator>www.bysocket.com</dc:creator>
<og:description>Java String 源码的排序算法 一、前言 Q：什么是选择问题？ 选择问题，是假设一组 N 个数，要确定其中第 K 个最大值者。比如 A 与 B 对象需要哪个更大？又比如：要考虑从一些数组中找出</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/Alandre/p/11524985.html</dc:identifier>
</item>
<item>
<title>脚本代码混淆-Python篇-pyminifier（1） - 七夜的故事</title>
<link>http://www.cnblogs.com/qiyeboy/p/11524806.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/qiyeboy/p/11524806.html</guid>
<description>&lt;h2&gt;前言&lt;/h2&gt;
&lt;p&gt;最近研究了一下脚本语言的混淆方法，比如 &lt;code&gt;&lt;span&gt;python，javascript&lt;/span&gt;&lt;/code&gt;等。脚本语言属于动态语言，代码大多无法直接编译成二进制机器码，发行脚本基本上相当于暴露源码，这对于一些商业应用是无法接受的。因此对脚本代码进行加固，成为很多应用的首选。代码加固的一项措施是代码混淆，增加逆向人员阅读代码逻辑的难度，拖延被破解的时间。&lt;/p&gt;
&lt;p&gt;今天讲解一下Python代码的混淆方法，Python代码一般用作web，提供服务接口，但也有一些桌面的应用，这一部分就需要对代码进行混淆保护。以一个开源项目pyminifier (https://github.com/qiyeboy/pyminifier)来说明混淆的技巧方法，这个项目已经有4年没更新，有一些bug，但是依然值得我们学习和入门。&lt;/p&gt;
&lt;h2&gt;项目结构&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/899843/201909/899843-20190915221656935-353276217.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;框架详情：&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;34&quot;&gt;
&lt;pre class=&quot;brush:python;gutter:true;&quot;&gt;
analyze.py - 用于分析Python代码
compression.py - 使用压缩算法压缩代码
minification.py - 用于简化Python代码
obfuscate.py - 用于混淆Python 代码
token_utils.py - 用于收集Python Token
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;从项目代码中，可以看到pyminifier的混淆方法是基于Token的，即基于词法分析，假如大家之前做过混淆的话，这应该属于混淆的初级方案，因为这样的混淆并不会修改代码原有的逻辑结构。&lt;/p&gt;
&lt;h3&gt;提取Token&lt;/h3&gt;
&lt;p&gt;如何提取Python语言的Token呢？Python中提供了专门的包进行词法分析： &lt;code&gt;&lt;span&gt;tokenize&lt;/span&gt;&lt;/code&gt;。使用起来很简单，在token_utils.py中代码如下：&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;33&quot;&gt;
&lt;pre class=&quot;brush:python;gutter:true;&quot;&gt;
def listified_tokenizer(source):

&quot;&quot;&quot;Tokenizes *source* and returns the tokens as a list of lists.&quot;&quot;&quot;
     io_obj = io.StringIO(source)
     return [list(a) for a in tokenize.generate_tokens(io_obj.readline)]
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;首先读取源文件，然后通过tokenize.generate_tokens生成token列表。咱们就将这个提取token的函数保存起来，然后让他自己提取自己，看一下token列表的结构。&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;84&quot;&gt;
&lt;pre class=&quot;brush:python;gutter:true;&quot;&gt;
[[1, 'def', (1, 0), (1, 3), 'def listified_tokenizer(source):\n'],
[1, 'listified_tokenizer', (1, 4), (1, 23), 'def listified_tokenizer(source):\n'],
[53, '(', (1, 23), (1, 24), 'def listified_tokenizer(source):\n'],
[1, 'source', (1, 24), (1, 30), 'def listified_tokenizer(source):\n'],
[53, ')', (1, 30), (1, 31), 'def listified_tokenizer(source):\n'],
[53, ':', (1, 31), (1, 32), 'def listified_tokenizer(source):\n'],
[4, '\n', (1, 32), (1, 33), 'def listified_tokenizer(source):\n'],
......
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;每一个Token对应一个list，以第一行 &lt;code&gt;&lt;span&gt;[1,'def',(1,0),(1,3),'def listified_tokenizer(source):\n']&lt;/span&gt;&lt;/code&gt;为例子进行解释:&lt;/p&gt;
&lt;ol class=&quot;list-paddingleft-2&quot; readability=&quot;3&quot;&gt;&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;1代表的是token的类型&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;def是提取的token字符串&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;(1, 0)代表的是token字符串的起始行与列&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;(1, 3)代表的是token字符串的结束行与列&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;'def listified_tokenizer(source):\n' 代表所在的行&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;&lt;h3&gt;Token还原代码&lt;/h3&gt;
&lt;p&gt;能从源文件中提取token 列表,如何从token列表还原为源代码呢？其实很简单，因为提取token 列表里面有位置信息和字符串信息，所以进行字符串拼接即可。&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;38&quot;&gt;
&lt;pre class=&quot;brush:python;gutter:true;&quot;&gt;
def untokenize(tokens):
    &quot;&quot;&quot;
    Converts the output of tokenize.generate_tokens back into a human-readable
    string (that doesn't contain oddly-placed whitespace everywhere).
    .. note::

        Unlike :meth:`tokenize.untokenize`, this function requires the 3rd and
        4th items in each token tuple (though we can use lists *or* tuples).
    &quot;&quot;&quot;
    out = &quot;&quot;
    last_lineno = -1
    last_col = 0
    for tok in tokens:
        token_string = tok[1]
        start_line, start_col = tok[2]
        end_line, end_col = tok[3]
        # The following two conditionals preserve indentation:
        if start_line &amp;gt; last_lineno:
            last_col = 0
        if start_col &amp;gt; last_col and token_string != '\n':
            out += (&quot; &quot; * (start_col - last_col))
        out += token_string
        last_col = end_col
        last_lineno = end_line
    return out
&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;精简与压缩代码&lt;/h3&gt;
&lt;p&gt;在pyminifier中，有两个缩小Python代码的方法：一个是精简方式，另一个是使用压缩算法的方式。&lt;/p&gt;
&lt;h3&gt;精简&lt;/h3&gt;
&lt;p&gt;在minification.py中使用的是精简方式，具体代码如下：&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;40&quot;&gt;
&lt;pre class=&quot;brush:python;gutter:true;&quot;&gt;
def minify(tokens, options):
    &quot;&quot;&quot;
    Performs minification on *tokens* according to the values in *options*
    &quot;&quot;&quot;
    # Remove comments
    remove_comments(tokens)
    # Remove docstrings
    remove_docstrings(tokens)
    result = token_utils.untokenize(tokens)
    # Minify our input script
    result = multiline_indicator.sub('', result)
    result = fix_empty_methods(result)
    result = join_multiline_pairs(result)
    result = join_multiline_pairs(result, '[]')
    result = join_multiline_pairs(result, '{}')
    result = remove_blank_lines(result)
    result = reduce_operators(result)
    result = dedent(result, use_tabs=options.tabs)
    return result　
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;上面的代码总共使用了9种方法来缩小脚本的体积：&lt;/p&gt;
&lt;h4&gt;remove_comments&lt;/h4&gt;
&lt;p&gt;去掉代码中的注释，但是有两类要保留：1.脚本解释器路径 2. 脚本编码&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;32&quot;&gt;
&lt;pre class=&quot;brush:python;gutter:true;&quot;&gt;
#!/usr/bin/env python
# -*- coding: utf-8 -*-
&lt;/pre&gt;&lt;/div&gt;
&lt;h4&gt; &lt;/h4&gt;
&lt;h4&gt;remove_docstrings&lt;/h4&gt;
&lt;p&gt;去掉&lt;strong&gt;doc&lt;/strong&gt;所指定的内容，example:&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;32&quot;&gt;
&lt;pre class=&quot;brush:python;gutter:true;&quot;&gt;
__doc__ = &quot;&quot;&quot;\
Module for minification functions.

&quot;&quot;&quot;
&lt;/pre&gt;&lt;/div&gt;
&lt;h4&gt; &lt;/h4&gt;
&lt;h4&gt;fix_empty_methods&lt;/h4&gt;
&lt;p&gt;修改空函数变成pass&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;32&quot;&gt;
&lt;pre class=&quot;brush:python;gutter:true;&quot;&gt;
def myfunc():
'''This is just a placeholder function.'''
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;转化为：&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot;&gt;
&lt;pre class=&quot;brush:python;gutter:true;&quot;&gt;
def myfunc():pass
&lt;/pre&gt;&lt;/div&gt;
&lt;h4&gt; &lt;/h4&gt;
&lt;h4&gt;join_multiline_pairs&lt;/h4&gt;
&lt;p&gt;(1) 第一种情况：&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;32&quot;&gt;
&lt;pre class=&quot;brush:python;gutter:true;&quot;&gt;
test = (
&quot;This is inside a multi-line pair of parentheses&quot;
)
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;转化为：&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;32&quot;&gt;
&lt;pre class=&quot;brush:python;gutter:true;&quot;&gt;
test = ( &quot;This is inside a multi-line pair of parentheses&quot;)
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;code&gt;&lt;span&gt; &lt;/span&gt;&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;(2)第二种情况：&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;32&quot;&gt;
&lt;pre class=&quot;brush:python;gutter:true;&quot;&gt;
test = [
&quot;This is inside a multi-line pair of parentheses&quot;
]
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;转化为:&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;32&quot;&gt;
&lt;pre class=&quot;brush:python;gutter:true;&quot;&gt;
test = [ &quot;This is inside a multi-line pair of parentheses&quot;]
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;(3)第三种情况：&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;32&quot;&gt;
&lt;pre class=&quot;brush:python;gutter:true;&quot;&gt;
test = {


&quot;parentheses&quot;:&quot;This is inside a multi-line pair of parentheses&quot;


}
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;转化为：&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;32&quot;&gt;
&lt;pre class=&quot;brush:python;gutter:true;&quot;&gt;
test = { &quot;parentheses&quot;:&quot;This is inside a multi-line pair of parentheses&quot;}
&lt;/pre&gt;&lt;/div&gt;
&lt;h4&gt; &lt;/h4&gt;
&lt;h4&gt;remove_blank_lines&lt;/h4&gt;
&lt;p&gt;移除空白行。&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;32&quot;&gt;
&lt;pre class=&quot;brush:python;gutter:true;&quot;&gt;
test = &quot;foo&quot;

 

test2 = &quot;bar&quot;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;转化为：&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;32&quot;&gt;
&lt;pre class=&quot;brush:python;gutter:true;&quot;&gt;
test = &quot;foo&quot;
test2 = &quot;bar&quot;
&lt;/pre&gt;&lt;/div&gt;
&lt;h4&gt; &lt;/h4&gt;
&lt;h4&gt;reduce_operators&lt;/h4&gt;
&lt;p&gt;移除操作符之间的空格。&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;34&quot;&gt;
&lt;pre class=&quot;brush:python;gutter:true;&quot;&gt;
def foo(foo, bar, blah):
    test = &quot;This is a %s&quot; % foo
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;修改为：&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;34&quot;&gt;
&lt;pre class=&quot;brush:python;gutter:true;&quot;&gt;
def foo(foo,bar,blah):
    test=&quot;This is a %s&quot;%foo
&lt;/pre&gt;&lt;/div&gt;

&lt;h4&gt;dedent&lt;/h4&gt;
&lt;p&gt;替换代码间的缩进，比如替换成单个空格&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;32&quot;&gt;
&lt;pre class=&quot;brush:python;gutter:true;&quot;&gt;
def foo(bar):

    test = &quot;This is a test&quot;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;修改为：&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;32&quot;&gt;
&lt;pre class=&quot;brush:python;gutter:true;&quot;&gt;
def foo(bar):

 test = &quot;This is a test&quot;
&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt; &lt;/h3&gt;
&lt;h3&gt;压缩&lt;/h3&gt;
&lt;p&gt;在这个项目中的compression.py，提供了4种代码压缩的方法，其中3个原理是一样，只不过使用的压缩算法不一样。&lt;/p&gt;
&lt;h4&gt;bz2,gz,lzma 压缩执行原理&lt;/h4&gt;
&lt;p&gt;假如新建一个1.py，并保存如下内容:&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;32&quot;&gt;
&lt;pre class=&quot;brush:python;gutter:true;&quot;&gt;
if __name__==&quot;__main__&quot;:

    print(__name__)
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;以bz2为例子，首先使用bz2算法压缩代码，然后转化成base64编码。&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;34&quot;&gt;
&lt;pre class=&quot;brush:python;gutter:true;&quot;&gt;
code='''


if __name__==&quot;__main__&quot;:


    print(__name__)


'''

import bz2,base64
compressed_source = bz2.compress(code.encode(&quot;utf-8&quot;))
print(base64.b64encode(compressed_source).decode('utf-8'))
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;输出：&lt;/p&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;&lt;code&gt;QlpoOTFBWSZTWdfQmoEAAAHbgEAQUGAAEgAAoyNUACAAIam1NNGgaaFNMjExMQ2Za0TTvJepAjgXb2pDBBGoliFIT04+LuSKcKEhr6E1Ag==&lt;/code&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;代码压缩完成后，如何执行呢？其实就用到了exec这个函数/关键字。将编码好的内容，先base64解码，再使用bz2算法解压缩，最后获得真实的代码，并使用exec执行&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;34&quot;&gt;
&lt;pre class=&quot;brush:python;gutter:true;&quot;&gt;
import bz2, base64
exec(bz2.decompress(base64.b64decode(&quot;QlpoOTFBWSZTWdfQmoEAAAHbgEAQUGAAEgAAoyNUACAAIam1NNGgaaFNMjExMQ2Za0TTvJepAjgXb2pDBBGoliFIT04+LuSKcKEhr6E1Ag==&quot;)))
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;这段代码就代表了最原始的代码，而使用gz,lzma压缩方式，将bz2包换成zlib 或者lzma即可。&lt;/p&gt;
&lt;h4&gt;zip执行原理&lt;/h4&gt;
&lt;p&gt;可能很多朋友不知道，Python是可以直接运行zip文件的(特别的)，主要是为了方便开发者管理和发布项目。Python能直接执行一个包含 __&lt;strong&gt;main__&lt;/strong&gt;.py的目录或者zip文件。&lt;/p&gt;
&lt;p&gt;举个例子：&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;32&quot;&gt;
&lt;pre class=&quot;brush:python;gutter:true;&quot;&gt;
|—— ABC/

|—— A.py

|—— __main__.py
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;示例代码：&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;32&quot;&gt;
&lt;pre class=&quot;brush:python;gutter:true;&quot;&gt;
# A.py
def echo():

    print('ABC!')

# __main__.py
if __name == '__main__':

    import A
    A.echo()
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;可以直接将多个文件压缩成一个zip文件，直接运行zip文件就可以。目录结构：&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;32&quot;&gt;
&lt;pre class=&quot;brush:python;gutter:true;&quot;&gt;
|—— ABC.zip/

|—— A.py

|—— __main__.py
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;运行情况：&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot;&gt;
&lt;pre class=&quot;brush:python;gutter:true;&quot;&gt;
$ python ABC.zip

ABC!
&lt;/pre&gt;&lt;/div&gt;

&lt;div id=&quot;cnblogs_post_body&quot; class=&quot;blogpost-body&quot; readability=&quot;57&quot;&gt;
&lt;h2 id=&quot;最后&quot;&gt;最后&lt;/h2&gt;
&lt;p&gt;关注公众号：&lt;strong&gt;七夜安全博客&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2015.cnblogs.com/blog/899843/201604/899843-20160412112303145-1979448153.jpg&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;回复【1】：领取 Python数据分析 教程大礼包&lt;/li&gt;
&lt;li&gt;回复【2】：领取 Python Flask 全套教程&lt;/li&gt;
&lt;li&gt;回复【3】：领取 某学院 机器学习 教程&lt;/li&gt;
&lt;li&gt;回复【4】：领取 爬虫 教程&lt;/li&gt;
&lt;li&gt;回复【5】：领取 编译原理 教程 &lt;/li&gt;
&lt;li&gt;回复【6】：领取 渗透测试 教程 &lt;/li&gt;
&lt;li&gt;回复【7】：领取 人工智能数学基础 教程&lt;/li&gt;
&lt;/ul&gt;&lt;/div&gt;
&lt;p&gt;本文章属于原创作品,欢迎大家转载分享，禁止修改文章的内容。尊重原创,转载请注明来自:七夜的故事 http://www.cnblogs.com/qiyeboy/&lt;/p&gt;

</description>
<pubDate>Sun, 15 Sep 2019 14:32:00 +0000</pubDate>
<dc:creator>七夜的故事</dc:creator>
<og:description>前言 最近研究了一下脚本语言的混淆方法，比如&amp;#160;python，javascript等。脚本语言属于动态语言，代码大多无法直接编译成二进制机器码，发行脚本基本上相当于暴露源码，这对于一些商业应用</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/qiyeboy/p/11524806.html</dc:identifier>
</item>
</channel>
</rss>