<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="css/feed.xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/" xmlns:og="http://ogp.me/ns#">
<channel>
<atom:link rel="self" href="http://192.168.1.4/fivefilters/makefulltextfeed.php?url=feed.cnblogs.com%2Fblog%2Fsitehome%2Frss&amp;max=10&amp;links=preserve&amp;exc=" />
<atom:link rel="alternate" title="Source URL" href="http://feed.cnblogs.com/blog/sitehome/rss" />
<atom:link rel="related" title="Subscribe to feed" href="http://www.subtome.com/#/subscribe?feeds=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed.cnblogs.com%252Fblog%252Fsitehome%252Frss%26max%3D10%26links%3Dpreserve%26exc%3D&amp;back=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed.cnblogs.com%252Fblog%252Fsitehome%252Frss%26max%3D10%26links%3Dpreserve%26exc%3D" />
<title>博客园_首页</title>
<link></link>
<description>代码改变世界</description>
<item>
<title>helm部署的服务如何修改配置 - 程序员欣宸</title>
<link>http://www.cnblogs.com/bolingcavalry/p/13766378.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/bolingcavalry/p/13766378.html</guid>
<description>&lt;h3 id=&quot;关于helm部署服务&quot;&gt;关于helm部署服务&lt;/h3&gt;
&lt;p&gt;在Kubernetes上进行容器化部署时，使用helm可以简化操作，以部署Jenkins为例，只需要以下命令即可完成部署：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-shell&quot;&gt;helm install --namespace helm-jenkins --name my-jenkins stable/jenkins
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;注意：关于helm部署的体验Jenkins的详情，请参考《》&lt;/p&gt;
&lt;h3 id=&quot;面临的问题&quot;&gt;面临的问题&lt;/h3&gt;
&lt;p&gt;上述命令部署的Jenkins服务，参数都是默认的，例如CPU和内存，如果您已装了metrics-server，用命令&lt;span&gt;kubectl top pod --all-namespaces&lt;/span&gt;可以看到Jenkins所占内存仅有515兆，如下图：&lt;br/&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/485422/202010/485422-20201004082446115-758151142.png&quot; alt=&quot;在这里插入图片描述&quot; loading=&quot;lazy&quot;/&gt;&lt;br/&gt;Jenkins服务Java应用，如果内存不足会导致频繁的垃圾回收，下图是通过docker exec在Jenkin容器中执行jstat命令看到的JVM状况，可见YGC频繁，还有FGC出现：&lt;br/&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/485422/202010/485422-20201004082447318-919023752.png&quot; alt=&quot;在这里插入图片描述&quot; loading=&quot;lazy&quot;/&gt;&lt;br/&gt;因此，helm部署的应用，有时默认参数是不能满足我们需求的，有必要修改；&lt;/p&gt;
&lt;h3 id=&quot;环境信息&quot;&gt;环境信息&lt;/h3&gt;
&lt;p&gt;本次操作在以下环境进行：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;kubernetes：1.15&lt;/li&gt;
&lt;li&gt;jenkins：2.190.2&lt;/li&gt;
&lt;/ol&gt;&lt;h3 id=&quot;第一种修改方式：kubectl-edit&quot;&gt;第一种修改方式：kubectl edit&lt;/h3&gt;
&lt;p&gt;如果应用已经通过helm部署好了，用命令&lt;span&gt;kubectl edit&lt;/span&gt;来修改最直接有效：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;执行命令&lt;span&gt;kubectl edit deployment my-jenkins -n helm-jenkins&lt;/span&gt;，即可在线编辑名为my-jenkins的deployment，操作方法和vi编辑文本文件一样，如下图所示，红框中是本次新增的内容，在java应用的启动参数中指定内存信息：&lt;br/&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/485422/202010/485422-20201004082448038-509413568.png&quot; alt=&quot;在这里插入图片描述&quot; loading=&quot;lazy&quot;/&gt;&lt;/li&gt;
&lt;li&gt;编辑完后，保存退出会立即生效，如下图，可见旧pod正在被销毁，新pod启动中：&lt;br/&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/485422/202010/485422-20201004082448513-983357182.png&quot; alt=&quot;在这里插入图片描述&quot; loading=&quot;lazy&quot;/&gt;&lt;/li&gt;
&lt;li&gt;等pod创建和启动成功后再次查看，如下图，新pod内存果然增加了：&lt;br/&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/485422/202010/485422-20201004082449111-323183550.png&quot; alt=&quot;在这里插入图片描述&quot; loading=&quot;lazy&quot;/&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;h3 id=&quot;第二种修改方式：改helm的配置文件&quot;&gt;第二种修改方式：改helm的配置文件&lt;/h3&gt;
&lt;p&gt;如果服务还没部署，可改用以下步骤部署：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;执行命令&lt;span&gt;helm fetch stable/jenkins&lt;/span&gt;，执行完毕后当前目录新增名为&lt;span&gt;jenkins-0.13.5.tgz&lt;/span&gt;的文件；&lt;/li&gt;
&lt;li&gt;解压&lt;span&gt;jenkins-0.13.5.tgz&lt;/span&gt;文件：&lt;/li&gt;
&lt;/ol&gt;&lt;pre&gt;
&lt;code class=&quot;language-shell&quot;&gt;tar -zxvf jenkins-0.13.5.tgz
&lt;/code&gt;
&lt;/pre&gt;
&lt;ol start=&quot;3&quot;&gt;&lt;li&gt;解压后得到名为jenkins的文件夹，进去发现如下内容：&lt;/li&gt;
&lt;/ol&gt;&lt;pre&gt;
&lt;code class=&quot;language-shell&quot;&gt;[root@node1 jenkins]# ls
Chart.yaml  OWNERS  README.md  templates  values.yaml
&lt;/code&gt;
&lt;/pre&gt;
&lt;ol start=&quot;4&quot;&gt;&lt;li&gt;打开&amp;lt;font color=&quot;blue&amp;gt;&quot;jenkins-0.13.5.tgz文件，如下图，里面有丰富的配置项，注意红框位置是我们要调整的：&lt;br/&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/485422/202010/485422-20201004082449666-1849421042.png&quot; alt=&quot;在这里插入图片描述&quot; loading=&quot;lazy&quot;/&gt;&lt;/li&gt;
&lt;li&gt;修改上图红框中的值，这里改为1024，如下图所示，注意要将最左边的&quot;#&quot;删除：&lt;br/&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/485422/202010/485422-20201004082450166-1066258202.png&quot; alt=&quot;在这里插入图片描述&quot; loading=&quot;lazy&quot;/&gt;&lt;/li&gt;
&lt;li&gt;在values.yaml文件所在目录执行以下命令，开始部署Jenkins：&lt;/li&gt;
&lt;/ol&gt;&lt;pre&gt;
&lt;code class=&quot;language-shell&quot;&gt;helm install --name-template my-jenkins -f values.yaml . --namespace helm-jenkins
&lt;/code&gt;
&lt;/pre&gt;
&lt;ol start=&quot;7&quot;&gt;&lt;li&gt;部署完成后，执行命令&lt;span&gt;kubectl edit deployment my-jenkins -n helm-jenkins&lt;/span&gt;查看当前deployment状态，如下图红框所示，Jenkins服务的内存参数和前一种方法设置的效果是一样的：&lt;br/&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/485422/202010/485422-20201004082450726-1365385577.png&quot; alt=&quot;在这里插入图片描述&quot; loading=&quot;lazy&quot;/&gt;&lt;/li&gt;
&lt;li&gt;再看看pod的实际内存情况，如下图，配置已生效：&lt;br/&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/485422/202010/485422-20201004082451330-80671634.png&quot; alt=&quot;在这里插入图片描述&quot; loading=&quot;lazy&quot;/&gt;&lt;br/&gt;以上就是helm部署的服务的设置方式，希望能给您提供参考。&lt;/li&gt;
&lt;/ol&gt;&lt;h3 id=&quot;欢迎关注我的公众号：程序员欣宸&quot;&gt;欢迎关注我的公众号：程序员欣宸&lt;/h3&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/zq2599/blog_demos&quot;&gt;https://github.com/zq2599/blog_demos&lt;/a&gt;&lt;/p&gt;
</description>
<pubDate>Sun, 04 Oct 2020 00:25:00 +0000</pubDate>
<dc:creator>程序员欣宸</dc:creator>
<og:description>关于helm部署服务 在Kubernetes上进行容器化部署时，使用helm可以简化操作，以部署Jenkins为例，只需要以下命令即可完成部署： helm install --namespace he</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/bolingcavalry/p/13766378.html</dc:identifier>
</item>
<item>
<title>模式串 从 0 开始的KMP算法 - Blithe-Chiang</title>
<link>http://www.cnblogs.com/Blithe-Chiang/p/13766368.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/Blithe-Chiang/p/13766368.html</guid>
<description>&lt;pre&gt;
&lt;code class=&quot;language-c&quot;&gt;
/**
 *  看了 b站视频 BV1jb411V78H 对KMP有了一点理解，然后我写了这个代码
 *  这个代码和视频里面的有一点不同，字符串是从 0 开始的，而不是从1 开始的
 *  希望能够帮到学习KMP的人
 */


#include &amp;lt;stdbool.h&amp;gt;
#include &amp;lt;malloc.h&amp;gt;
#include &quot;KMP.h&quot;

// KMP.h 内容
/*
#define MAXSIZE (255)

typedef struct {
    char ch[MAXSIZE + 1];
    int length;
}SString;

void Next(SString const *t);
extern int *next;
int IndexOf_KMP(SString const *s, SString const *t);
*/

int *next;      // 计算 next数组

/**
 * 计算 0-based 模式串t的next数组
 * @param t 模式串
 */
void Next(SString const *t) {
    //  模式串 0 开始
    int length = t-&amp;gt;length;

    // 分配 next数组 所需要的空间
    next = (int *)malloc(sizeof(int) * length);
    for (int *p = next; p &amp;lt; next + length; p++)
    {
        *p = 0;
    }

    for (int i = 0; i &amp;lt; length; i++)
    {
        if (i &amp;lt;= 1)     // 前两个next[i]置为-1
        {
            next[i] = -1;
            continue;
        }

        // 执行下面的语句的时候， 一定有 i &amp;gt;= 2



        int maxlen = 0;         // 存储最长公共前后缀的长度

        /**
         *  // len 表示前缀或后缀的最大长度, 可取的值是 [1..i-1]      // i 为(模式串或next数组)的访问下标
         *  这里主要是 对 模式串在i位置 求 它的最大公共前后缀的长度
         *  从 1 开始 到 i-1 一个一个去试 
         *  
         */
        for (int len = 1; len &amp;lt; i; len++)
        {
            int val = 0;
            bool flag = false;

            for (int j = 0, k = i - len; j &amp;lt; len; j++, k++)
            {
                if (t-&amp;gt;ch[j] == t-&amp;gt;ch[k])
                {
                }
                else
                {
                    flag = true;        // len 长度的公共前后缀匹配失败
                    break;
                }
            }

            if (flag == false)          //  公共前后缀长度为len
                val = len;
            if (val &amp;gt; maxlen)           // 这个比较不是必须的，因为找公共前后缀的长度的时候， len 从 1 到 i-1
                maxlen = val;           // maxlen 就是 next[i]的值了
        }
        next[i] = maxlen;
    }
}

// 调用这个函数之前，一定要调用 Next函数，为模式串构建 next数组
int IndexOf_KMP(SString const *s, SString const *t)
{
    // 开始匹配

    int i = 0, j = 0;       // i 表示主串的下标， j 表示模式串的下标
    while (i &amp;lt; s-&amp;gt;length)
    {
        if (j == -1 || s-&amp;gt;ch[i] == t-&amp;gt;ch[j])
        {
            i++;
            j++;
        }
        else
        {
            j = next[j];
        }

        // 匹配成功
        if (j == t-&amp;gt;length)
        {
            return i - t-&amp;gt;length;
        }
    }

    // 匹配失败
    return -1;
}


&lt;/code&gt;
&lt;/pre&gt;</description>
<pubDate>Sun, 04 Oct 2020 00:14:00 +0000</pubDate>
<dc:creator>Blithe-Chiang</dc:creator>
<og:description>/** * 看了 b站视频 BV1jb411V78H 对KMP有了一点理解，然后我写了这个代码 * 这个代码和视频里面的有一点不同，字符串是从 0 开始的，而不是从1 开始的 * 希望能够帮到学习KM</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/Blithe-Chiang/p/13766368.html</dc:identifier>
</item>
<item>
<title>移动机器人相机模型：从相机移动到二维图像 - 科西嘉人</title>
<link>http://www.cnblogs.com/IaCorse/p/13766127.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/IaCorse/p/13766127.html</guid>
<description>&lt;p&gt;​ 如果只是希望获取图像上的一些信息（例如特征提取、拟合等），那么我们不会对三维空间中相机的位置有所要求。但如果希望通过二维的图像去理解三维空间中摄像机的信息，或者是图像中物体在三维空间中的信息，那么就不得不考虑成像过程中三维变化为二维时的具体过程。而摄像机模型就是三维到二维的一种映射。本文简要总结了&lt;strong&gt;单目相机&lt;/strong&gt;的成像过程，以便于读者将相机模型作为一种基础的工具理解更深层次的内容。&lt;/p&gt;
&lt;p&gt;​ 本文通过讲解三维世界坐标系下某一点是如何被映射到二维图像上的一点的完整流程来讲解，以下为整体流程：&lt;/p&gt;
&lt;p&gt;\[World\ \to Camera\ \to Retinal\ \to Pixel\ \]&lt;/p&gt;
&lt;p&gt;（世界坐标系——相机坐标系——成像平面坐标系——图像坐标系）&lt;/p&gt;
&lt;p&gt;下面对这四个坐标系作出一个简要的介绍：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;世界坐标系 &lt;code&gt;P_w&lt;/code&gt;：通常是三维空间中人为选择的一个参考坐标系。单位为物理单位，例如m。&lt;/li&gt;
&lt;li&gt;相机坐标系 &lt;code&gt;P_c&lt;/code&gt;：三维空间中，通常以摄像机的光心作为原点，光轴作为z轴的一个坐标系。可以通过世界坐标系的平移和旋转来获得。单位为物理单位，例如m。&lt;/li&gt;
&lt;li&gt;成像平面坐标系 &lt;code&gt;P&lt;/code&gt;：通过相机模型映射得到的一个二维坐标系。单位为物理单位，例如m。&lt;/li&gt;
&lt;li&gt;图像坐标系 &lt;code&gt;P_uv&lt;/code&gt;：通过所成像转换获得的在计算机内部可以存储的矩阵图像上的坐标系。单位为像素。&lt;/li&gt;
&lt;/ul&gt;&lt;h2 id=&quot;1-world---camera&quot;&gt;1. World -&amp;gt; Camera&lt;/h2&gt;
&lt;p&gt;​ &lt;strong&gt;假如摄像头固定不动，那么世界坐标系和相机坐标系可以直接重合。但如果我们要把摄像头放在一个能够移动的机器人身上，那么就有必要令一个固定的坐标系和一个跟着机器人走的相机坐标系。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;​ 如果上述这句话你不太理解，那就说明你确实有必要阅读这篇文章，等到阅读结束后再回过头来思考这个问题。而现在，你只需要知道，我们在这里考虑的是后面这种情况，即&lt;strong&gt;摄像头置于移动机器人上&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;​ 作为一个移动机器人，它必然有所处位置坐标和一个朝向，我们把机器人的位置和朝向称为&lt;strong&gt;位姿&lt;/strong&gt;。如果它还没开始运动，我们不妨将该位置作为世界坐标系原点，而相机朝向作为Z轴：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1653121/202010/1653121-20201004005915049-298441355.png&quot; alt=&quot;1&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;​ 机器人在空间中会进行移动和转向，于是我们可以按照同样方式定义一个跟随着机器人进行移动的坐标系，称为相机坐标系。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1653121/202010/1653121-20201004005931026-855493292.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;​ 为了表示出这种移动和转向，我们需要知道机器人相对于原来位置移动了多少，旋转了多少。&lt;/p&gt;
&lt;p&gt;​ 很自然的，我们可以通过当前机器人在世界坐标系下的坐标，来表示机器人是如何从世界坐标系原点移动到当前位置。于是把该坐标，称为&lt;strong&gt;平移向量&lt;/strong&gt;：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1653121/202010/1653121-20201004005944652-1376391509.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;​ 而对于&lt;strong&gt;旋转&lt;/strong&gt;，通常使用旋转矩阵R进行描述。对于如何理解旋转矩阵，我这里推荐看&lt;a href=&quot;https://www.bilibili.com/video/BV1v4411H7ez?p=4&quot;&gt;台大的机器人学视频P4&lt;/a&gt;（通过列空间变换和投影的方式去理解）。我这里直接使用单位正交基的方式进行描述，意思是一致的。总之，下式表示是&lt;strong&gt;在A看来B坐标系的姿态&lt;/strong&gt;，或者可以把在B坐标系下的坐标表示通过左乘下列R转换成A坐标系下的坐标表示。&lt;/p&gt;
&lt;p&gt;\[R_{AB}=\begin{bmatrix} |&amp;amp;|&amp;amp;|\\\hat X_B^A &amp;amp; \hat Y_B^A &amp;amp; \hat Z_B^A\\ |&amp;amp;|&amp;amp;|\\\end{bmatrix}=\begin{bmatrix}e_1^Ae_1^B &amp;amp; e_2^Ae_1^B &amp;amp; e_3^Ae_1^B\\ e_1^Ae_2^B &amp;amp; e_2^Ae_2^B &amp;amp; e_3^Ae_2^B\\e_1^Ae_3^B &amp;amp; e_2^Ae_3^B &amp;amp; e_3^Ae_3^B\\ \end{bmatrix} \]&lt;/p&gt;
&lt;p&gt;​ 也就是说，旋转矩阵R除了表示在A看来B坐标系的姿态，也可以&lt;strong&gt;用来转换空间中某一点的坐标表示&lt;/strong&gt;（而这正是我们的相机模型最需要的）。即有：&lt;/p&gt;
&lt;p&gt;\[P^A=R_{AB}P^B \]&lt;/p&gt;
&lt;p&gt;​ 此外在机器人学中比较重要的一点是，R能够用来描述物体的旋转。例如下式就表示的是在A坐标系下点1通过一个R旋转至点2。&lt;/p&gt;
&lt;p&gt;\[P_2^A=RP_1^A \]&lt;/p&gt;
&lt;p&gt;​ 回到我们的机器人上来。假定现在机器人在世界坐标系初始位置时看到了一点 &lt;code&gt;P_W&lt;/code&gt;，然后经过一次旋转和平移，此时看到了同一个点，坐标为 &lt;code&gt;P_C&lt;/code&gt;。通过上面的定义，我们能够很自然的得到一个等式：&lt;/p&gt;
&lt;p&gt;\[P_c=R_{cw}P_w+t_{cw} \]&lt;/p&gt;
&lt;p&gt;​ 我们通常把这里的 &lt;code&gt;R&lt;/code&gt;和 &lt;code&gt;t&lt;/code&gt;称为&lt;strong&gt;相机的外参&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;​ 为了矩阵运算上的便利，上式同时也可以表现成下面这样（注意使用的是齐次坐标的形式）：&lt;/p&gt;
&lt;p&gt;\[\begin{bmatrix} x_w\\y_w\\z_w\\1 \end{bmatrix} = \begin{bmatrix} R &amp;amp; t \\ 0^t &amp;amp; 1 \end{bmatrix} \begin{bmatrix} x_c\\y_c\\z_c\\1 \end{bmatrix} \]&lt;/p&gt;
&lt;p&gt;​ 常将中间由R和t组成的矩阵写作变换矩阵T，于是可以表示成下列形式：&lt;/p&gt;
&lt;p&gt;\[P_c=T_{cw}P_w \ldots\ldots0 \]&lt;/p&gt;
&lt;p&gt;​ 此式子即为世界坐标系转换为相机坐标系的变换式。它揭示了两个很简单的道理：1. 知道 &lt;code&gt;R_cw&lt;/code&gt;和 &lt;code&gt;t_cw&lt;/code&gt;，那就能够将点在两个坐标系下进行转换。2. 如果知道多个点在两个坐标系下的坐标表示，那就可以求解获得 &lt;code&gt;R_cw&lt;/code&gt;和 &lt;code&gt;t_cw&lt;/code&gt;。&lt;/p&gt;
&lt;h2 id=&quot;2-camera---retinal&quot;&gt;2. Camera -&amp;gt; Retinal&lt;/h2&gt;
&lt;p&gt;​ 好了，现在我们已经能够知道如何把世界坐标系下的点转换成相机坐标系下的点了，现在我们要考虑的是三位空间下的点是如何转换到二维平面上。此刻我们考虑的几何模型才是真正的相机模型。&lt;/p&gt;
&lt;p&gt;​ 相机模型通常会考虑两种：&lt;strong&gt;针孔模型&lt;/strong&gt;和&lt;strong&gt;透镜模型。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;​ 一般来说，考虑针孔模型就够了，因为透镜模型不过是将针孔模型的焦距f进行修改。&lt;/p&gt;
&lt;p&gt;​ 首先先考虑针孔模型（&lt;a href=&quot;https://raw.githubusercontent.com/CV-xueba/A01_cvclass_basic/master/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E5%9F%BA%E7%A1%80_%E8%AF%BE%E4%BB%B6/12_%E6%91%84%E5%83%8F%E6%9C%BA%E5%87%A0%E4%BD%95.pdf&quot;&gt;图源&lt;/a&gt;）：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1653121/202010/1653121-20201004010004600-877868238.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;​ 如上图所示，针孔模型可以简单看作，位于三维空间中的某一点P经过相机坐标系的中心点O映射至像平面坐标系上的P'的一个过程。于是乎，我们可以把这一模型视作一个相似三角形模型：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1653121/202010/1653121-20201004010015449-1296745030.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;​ 很容易看出来左边X成像是倒的，对于坐标系来说这样的倒会引入负号，因此我们在O点右侧也画一个X‘，这样就能消除这个负号。而对于引入的橙色X’所在平面，我们称为归一化成像平面。于是成像过程就有如下式子：&lt;/p&gt;
&lt;p&gt;\[X' = f \cfrac {X_c} {Z_c} \ldots \ldots 1 \]&lt;/p&gt;
&lt;p&gt;\[Y' = f \cfrac {Y_c} {Z_c}\ldots\ldots 2 \]&lt;/p&gt;
&lt;h2 id=&quot;3-retinal---pixel&quot;&gt;3. Retinal -&amp;gt; Pixel&lt;/h2&gt;
&lt;p&gt;​ 由上面的推导，我们很清楚，它们都是在物理层面进行转换的，因此单位都是m。而真正拿到我们手中的是一张张由像素点构成的矩阵图像。因此在成像平面坐标系到图像坐标系还需要进行采样和量化。而同时我们也清楚，图像坐标的原点通常在图像左上角，x轴朝向图像右边，y轴竖直向下。而成像平面坐标系的原点则是在像的中间。因此要把成像平面坐标系转换至像素坐标系，需要&lt;strong&gt;进行一次缩放和原点平移&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;​ 因此，成像平面坐标系的坐标P’到像素坐标[u,v]有如下关系：&lt;/p&gt;
&lt;p&gt;\[u = aX'+c_x\ldots\ldots3 \]&lt;/p&gt;
&lt;p&gt;\[v = aY'+c_y\ldots\ldots4 \]&lt;/p&gt;
&lt;p&gt;​&lt;/p&gt;
&lt;hr/&gt;&lt;p&gt;​ 至此，我们已经完成了每一个局部过程的推导。但是，我们不可能每次都这样一次一次进行部分运算，如果我们希望直接把相机坐标系下的点转换到像素坐标系下，该怎么转换？又或者，我们希望从世界坐标系下的点开始转换呢？下面就会对这样的过程进行讲解。&lt;/p&gt;
&lt;h2 id=&quot;camera---pixel&quot;&gt;Camera -&amp;gt; Pixel&lt;/h2&gt;
&lt;p&gt;​ 在上面，我们已经获得了 &lt;code&gt;Camera -&amp;gt; Retinal&lt;/code&gt;和 &lt;code&gt;Retinal -&amp;gt; Pixel&lt;/code&gt;的式子，因此可以将 &lt;code&gt;X',Y'&lt;/code&gt;消去(即把1和2带入3和4)，得到下列式子：&lt;/p&gt;
&lt;p&gt;\[u = af \cfrac {X_c} {Z_c}+c_x \]&lt;/p&gt;
&lt;p&gt;\[v = bf \cfrac {Y_c} {Z_c}+c_y \]&lt;/p&gt;
&lt;p&gt;​ 通常地，我们会令 &lt;code&gt;f_x = af&lt;/code&gt;和&lt;code&gt;f_y = bf&lt;/code&gt;(这是由于a的单位为pixel/m,而f的单位为m，相乘从而将量纲统一到pixel)：&lt;/p&gt;
&lt;p&gt;\[u = f_x \cfrac {X_c} {Z_c}+c_x \]&lt;/p&gt;
&lt;p&gt;\[v = f_y \cfrac {Y_c} {Z_c}+c_y \]&lt;/p&gt;
&lt;p&gt;​ 将上式化作矩阵形式：&lt;/p&gt;
&lt;p&gt;\[\begin{bmatrix} u\\v\\1 \end{bmatrix} = \frac 1 {Z_c} \begin{bmatrix} f_x &amp;amp; 0 &amp;amp; c_x \\ 0 &amp;amp; f_x &amp;amp; c_y \\ 0 &amp;amp; 0 &amp;amp; 1 \end{bmatrix} \begin{bmatrix} X_c\\Y_c\\Z_c \end{bmatrix}\ldots\ldots5 \]&lt;/p&gt;
&lt;p&gt;​ 通常我们会将中间的3*3矩阵作为&lt;strong&gt;内参矩阵K&lt;/strong&gt;，我们很清楚，前面的f是固定的，a是采样过程固定的，因此f_x也是固定的，也就是说内参矩阵K也是从出厂开始就是固定的：&lt;/p&gt;
&lt;p&gt;\[K = \begin{bmatrix} f_x &amp;amp; 0 &amp;amp; c_x \\ 0 &amp;amp; f_x &amp;amp; c_y \\ 0 &amp;amp; 0 &amp;amp; 1 \end{bmatrix} \]&lt;/p&gt;
&lt;p&gt;​ 5式通常又可以写作下列形式：&lt;/p&gt;
&lt;p&gt;​&lt;/p&gt;
&lt;p&gt;\[ZP_{uv} = KP_c\ldots\ldots6 \]&lt;/p&gt;
&lt;h2 id=&quot;world---pixel&quot;&gt;World -&amp;gt; Pixel&lt;/h2&gt;
&lt;p&gt;​ 由于我们的机器人的运动，导致相机也不断在运动，因此我们可以把0式代入到6式中：&lt;/p&gt;
&lt;p&gt;\[ZP_{uv}=KT_{cw}P_w \]&lt;/p&gt;
&lt;p&gt;​ 至此，我们已经完成了整个过程的推导。&lt;/p&gt;
</description>
<pubDate>Sat, 03 Oct 2020 17:01:00 +0000</pubDate>
<dc:creator>科西嘉人</dc:creator>
<og:description>端到端地推导相机模型</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/IaCorse/p/13766127.html</dc:identifier>
</item>
<item>
<title>spring-boot-route（三）实现多文件上传 - Java旅途</title>
<link>http://www.cnblogs.com/zhixie/p/13765959.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/zhixie/p/13765959.html</guid>
<description>&lt;p&gt;Spring Boot默认上传的单个文件大小&lt;code&gt;1MB&lt;/code&gt;，一次上传的总文件大小为&lt;code&gt;10MB&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;单个文件上传使用MultipartFile参数来接收文件，多文件使用MultipartFile[]数组来接收，然后遍历它，当成单文件来处理。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;问题一&lt;/strong&gt;：如何配置上传文件大小限制？&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;@Configuration
public class FileConfig implements WebMvcConfigurer {
    @Bean
    public MultipartConfigElement multipartConfigElement(){
        MultipartConfigFactory factory = new MultipartConfigFactory();
        // 单个文件大小
        factory.setMaxFileSize(DataSize.parse(&quot;10240MB&quot;));
        // 上传的总文件大小
        factory.setMaxRequestSize(DataSize.parse(&quot;20480MB&quot;));
        return factory.createMultipartConfig();
    }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;思考&lt;/strong&gt;：SpringBoot项目推荐使用jar包的方式来运行项目，而实际应用中我们也发现jar包运行项目更加方便。但是当打完jar包后，这个jar的大小就固定好了，上传的文件肯定传不到jar包里面了。SpringBoot提供了一种方式，将文件上传到服务器物理路径下，然后做个映射关系，让图片可以正常被访问，具体操作如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;@Configuration
public class FileConfig implements WebMvcConfigurer {

    @Override
    public void addResourceHandlers(ResourceHandlerRegistry registry) {        registry.addResourceHandler(&quot;/static/**&quot;).addResourceLocations(&quot;file:&quot;+&quot;D://uploadfile/&quot;);
    }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;addResourceHandler(&quot;/static/**&quot;)表示访问路径为/static/文件名，addResourceLocations(&quot;file:&quot;+&quot;D://uploadfile/&quot;)表示文件存储的物理路径，&quot;file:&quot;为固定写法。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&quot;文件上传后台实现&quot;&gt;文件上传后台实现&lt;/h3&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;@RestController
@Slf4j
public class FileUpload {

    @PostMapping(&quot;uploadFile&quot;)
    public List uploadFile(@RequestParam(&quot;files&quot;) MultipartFile[] files) {

        // 存储上传成功的文件名，响应给客户端
        List&amp;lt;String&amp;gt; list = new ArrayList&amp;lt;&amp;gt;();
        // 判断文件数组长度
        if(files.length &amp;lt;= 0){
            list.add(&quot;请选择文件&quot;);
            return list;
        }
        for(MultipartFile file : files){
            // 源文件名
            String originalFilename = file.getOriginalFilename();
            // 文件格式
            String suffix = originalFilename.substring(originalFilename.lastIndexOf(&quot;.&quot;));
            // 新文件名，避免文件名重复，造成文件替换问题
            String fileName = UUID.randomUUID()+&quot;.&quot;+suffix;
            // 文件存储路径
            String filePath = &quot;D:/uploadFile/&quot;;
            // 文件全路径
            File targetFile = new File(filePath+fileName);

            // 判断文件存储目录是否存在，不存在则新建目录
            if(!targetFile.getParentFile().exists()){
                targetFile.getParentFile().mkdir();
            }
            try {
                // 将图片保存
                file.transferTo(targetFile);
                list.add(originalFilename);
            } catch (IOException e) {
                log.info(&quot;文件上传异常={}&quot;,e);
            }
        }
        return list;
    }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;静态资源问题&quot;&gt;静态资源问题&lt;/h3&gt;
&lt;p&gt;SpringBoot静态资源默认路径为：&lt;code&gt;classpath:/META-INF/resources/&lt;/code&gt; ，&lt;code&gt;classpath:/resources/&lt;/code&gt;，&lt;code&gt;classpath:/static/&lt;/code&gt;，&lt;code&gt;classpath:/public/&lt;/code&gt;。也就是说如果想访问静态资源，则需要将静态资源 文件放在这四个路径下面。&lt;/p&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;注：classpath 指的是 SpringBoot项目resources&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;如果想自定义静态资源路径有两种方式，&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;application.yml中指定&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-yml&quot;&gt;spring:
  resources:
    static-locations: classpath:/templates/
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;代码实现WebMvcConfigurer&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;@Configuration
public class FileConfig implements WebMvcConfigurer {

    @Override
    public void addResourceHandlers(ResourceHandlerRegistry registry) {
        registry.addResourceHandler(&quot;/**&quot;).addResourceLocations(&quot;classpath:/templates/&quot;);
    }
&lt;/code&gt;
&lt;/pre&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;注：当配置了自定义静态资源路径后，其默认配置将失效&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&quot;文件上传前端实现&quot;&gt;文件上传前端实现&lt;/h3&gt;
&lt;p&gt;在静态资源路径下，新建file.html文件，浏览器访问ip:port/file.html，进入file页面&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-html&quot;&gt;&amp;lt;form enctype=&quot;multipart/form-data&quot; method=&quot;post&quot; action=&quot;/uploadFile&quot;&amp;gt;
    文件：&amp;lt;input type=&quot;file&quot; name=&quot;files&quot;/&amp;gt;
    &amp;lt;input type=&quot;submit&quot; value=&quot;上传&quot;/&amp;gt;
&amp;lt;/form&amp;gt;
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;这里需要注意的是文件上传表单的enctype为&lt;strong&gt;multipart/form-data&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;此是spring-boot-route系列的第三篇文章，这个系列的文章都比较简单，主要目的就是为了帮助初次接触Spring Boot 的同学有一个系统的认识。本文已收录至我的&lt;a href=&quot;https://github.com/binzh303/spring-boot-route&quot;&gt;github&lt;/a&gt;，欢迎各位小伙伴&lt;code&gt;star&lt;/code&gt;！&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;github&lt;/strong&gt;：&lt;a href=&quot;https://github.com/binzh303/spring-boot-route&quot;&gt;https://github.com/binzh303/spring-boot-route&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;点关注、不迷路&quot;&gt;点关注、不迷路&lt;/h2&gt;
&lt;p&gt;如果觉得文章不错，欢迎&lt;strong&gt;关注&lt;/strong&gt;、&lt;strong&gt;点赞&lt;/strong&gt;、&lt;strong&gt;收藏&lt;/strong&gt;，你们的支持是我创作的动力，感谢大家。&lt;/p&gt;
&lt;p&gt;如果文章写的有问题，请不要吝啬，欢迎留言指出，我会及时核查修改。&lt;/p&gt;
&lt;p&gt;如果你还想更加深入的了解我，可以微信搜索「&lt;strong&gt;Java旅途&lt;/strong&gt;」进行关注。回复「&lt;strong&gt;1024&lt;/strong&gt;」即可获得学习视频及精美电子书。每天7:30准时推送技术文章，让你的上班路不在孤独，而且每月还有送书活动，助你提升硬实力！&lt;/p&gt;
</description>
<pubDate>Sat, 03 Oct 2020 15:36:00 +0000</pubDate>
<dc:creator>Java旅途</dc:creator>
<og:description>Spring Boot默认上传的单个文件大小1MB，一次上传的总文件大小为10MB。 单个文件上传使用MultipartFile参数来接收文件，多文件使用MultipartFile[]数组来接收，然后</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/zhixie/p/13765959.html</dc:identifier>
</item>
<item>
<title>使用模拟退火算法优化 Hash 函数 - buttercup</title>
<link>http://www.cnblogs.com/buttercup/p/13721957.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/buttercup/p/13721957.html</guid>
<description>&lt;p&gt;现有个处理股票行情消息的系统，其架构如下：&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;https://images.cnblogs.com/cnblogs_com/buttercup/1857394/o_201001045427symbol_count.png&quot; width=&quot;500&quot;/&gt;&lt;/p&gt;
&lt;p&gt;由于数据量巨大，系统中启动了 15 个线程来消费行情消息。消息分配的策略较为简单：对 symbol 的 hashCode 取模，将消息分配给其中一个线程进行处理。 经过验证，每个线程分配到的 symbol 数量较为均匀，于是系统愉快地上线了。&lt;/p&gt;
&lt;p&gt;运行一段时间后，突然收到了系统的告警，但此时并非消息峰值时间段。经过排查后，发现问题出现在 hash 函数上：&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;https://images.cnblogs.com/cnblogs_com/buttercup/1857394/o_201001045431symbol_count_2.png&quot; width=&quot;500&quot;/&gt;&lt;/p&gt;
&lt;p&gt;虽然每个线程被分配到的 symbol 数量较为均衡，但是部分热门 symbol 的报价消息量会更多，如果热门 symbol 集中到特定线程上，就会造成线程负载不均衡，使得系统整体的吞吐量大打折扣。&lt;/p&gt;
&lt;p&gt;为提高系统的吞吐量，有必要消息分发逻辑进行一些改造，避免出现热点线程。为此，系统需要记录下某天内每个 symbol 的消息量，然后在第二天使用这些数据，对分发逻辑进行调整。具体的改造的方案可以分为两种：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;放弃使用 hash 函数&lt;/li&gt;
&lt;li&gt;对 hash 函数进行优化&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;问题可以抽象为：&lt;/p&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;将 5000 个非负整数分配至 15 个桶&lt;code&gt;(bucket)&lt;/code&gt;中，并尽可能保证每个桶中的元素之和接近（每个桶中的元素个数无限制）。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;每个整数元素可能的放置方法有 15 种，这个问题总共可能的解有 15&lt;sup&gt;5000&lt;/sup&gt;种，暴力求解的可能性微乎其微。作为工程问题，最优解不是必要的，可以退而求其次寻找一个可接受的次优解：&lt;/p&gt;
&lt;div class=&quot;paper&quot;&gt;
&lt;ol&gt;&lt;li&gt;根据所有 symbol 的消息总数计算一个期望的分布均值&lt;code&gt;(expectation)&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;将每个 symbol 的消息数按照 symbol 的顺序进行排列，最后将这组数组划分为 15 个区间，并且尽可能使得每个区间元素之和与 expection 接近。&lt;/li&gt;
&lt;li&gt;使用一个有序查找表记录每个区间的首个 symbol，后续就可以按照这个表对数据进行划分。&lt;/li&gt;
&lt;/ol&gt;&lt;/div&gt;
&lt;pre&gt;
&lt;code&gt;public class FindBestDistribution {

    static final int NUM_OF_SYMBOLS = 5000;
    static final int NUM_OF_BUCKETS = 15;

    public static void main(String[] args) {
        // 生成样本
        IntStream ints = ThreadLocalRandom.current().ints(0, 1000);
        PrimitiveIterator.OfInt iterator = ints.iterator();
        
        Map&amp;lt;String,Integer&amp;gt; symbolAndCount = new TreeMap&amp;lt;&amp;gt;();
        for (int i=0; i&amp;lt;NUM_OF_SYMBOLS; i++) {
            symbolAndCount.put(Integer.toHexString(i).toUpperCase(), iterator.next());
        }

        // 按照 symbol 划分每个桶的数量
        TreeMap&amp;lt;String, Integer&amp;gt; distribution = findBestDistribution(symbolAndCount);

        // 测试效果
        int[] buckets = new int[NUM_OF_BUCKETS];
        for (Map.Entry&amp;lt;String, Integer&amp;gt; entry : symbolAndCount.entrySet()) {
            Map.Entry&amp;lt;String, Integer&amp;gt; floor = distribution.floorEntry(entry.getKey());
            int bucketIndex = floor == null ? 0 : floor.getValue();
            buckets[bucketIndex] += entry.getValue();
        }

        System.out.printf(&quot;buckets: %s\n&quot;, Arrays.toString(buckets));
    }

    public static TreeMap&amp;lt;String, Integer&amp;gt; findBestDistribution(Map&amp;lt;String,Integer&amp;gt; symbolAndCount) {

        // 每个桶均匀分布的情况（最优情况）
        int avg = symbolAndCount.values().stream().mapToInt(Integer::intValue).sum() / NUM_OF_BUCKETS;

        // 尝试将 symbol 放入不同的桶
        int bucketIdx = 0;
        int[] buckets = new int[NUM_OF_BUCKETS];
        String[] bulkheads = new String[NUM_OF_BUCKETS-1];
        for (Map.Entry&amp;lt;String, Integer&amp;gt; entry : symbolAndCount.entrySet()) {

            // 如果首个 symbol 数据量过大，则分配给其一个独立的桶
            int count = entry.getValue();
            if (count / 2 &amp;gt; avg &amp;amp;&amp;amp; bucketIdx == 0 &amp;amp;&amp;amp; buckets[0] == 0) {
                buckets[bucketIdx] += count;
                continue;
            }

            // 评估将 symbol 放入桶后的效果
            // 1. 如果桶中的数量更接近期望，则将其放入当前桶中
            // 2. 如果桶中的数量更远离期望，则将其放入下个桶中
            double before = Math.abs(buckets[bucketIdx] - avg);
            double after = Math.abs(buckets[bucketIdx] + count - avg);
            if (after &amp;gt; before &amp;amp;&amp;amp; bucketIdx &amp;lt; buckets.length - 1) {
                bulkheads[bucketIdx++] = entry.getKey();
            }

            buckets[bucketIdx] += count;
        }

        System.out.printf(&quot;expectation: %d\n&quot;, avg);
        System.out.printf(&quot;bulkheads: %s\n&quot;, Arrays.toString(bulkheads));

        TreeMap&amp;lt;String,Integer&amp;gt; distribution = new TreeMap&amp;lt;&amp;gt;();
        for (int i=0; i&amp;lt;bulkheads.length; i++) {
            distribution.put(bulkheads[i], i+1);
        }
        return distribution;
    }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;该方法存在的问题：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;分配策略并不是最优解，且无法对其分片效果进行直观的评估。&lt;/li&gt;
&lt;li&gt;当区间数量较多时，查找表本身可能成为一个潜在的性能瓶颈。&lt;/li&gt;
&lt;li&gt;可能的组合受到 key 的顺序限制，极大地限制了可能的解空间。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;换个角度来看，造成分布不均匀的原因不是数据，而是 hash 函数本身。&lt;/p&gt;
&lt;p&gt;项目中使用的 hash 函数是 JDK String 中的原生实现。经过查阅资料，发现该实现其实是 BKDRHash 的 seed = 31 的特殊情况。这样意味着：&lt;strong&gt;通过调整 seed 的值，可以改变 hash 函数的特性并使其适配特定的数据分布&lt;/strong&gt;。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;int BKDRHash(char[] value, int seed) {
    int hash = 0;
    for (int i = 0; i &amp;lt; value.length; i++) {
        hash = hash * seed + value[i];
    }
    return hash &amp;amp; 0x7fffffff;
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;那么问题来了，应该如何评估某个 seed 的分布的优劣？&lt;/p&gt;
&lt;h2 id=&quot;评价函数&quot;&gt;评价函数&lt;/h2&gt;
&lt;p&gt;一种可行的方法是计算每个 seed 对应的 bucket 分布的标准差，标准差越小则分布越均匀，则该 seed 越优。&lt;/p&gt;
&lt;p&gt;然而这一做法只考虑了每个 bucket 与均值之间的误差，无法量化不同 bucket 之间的误差。为了能够直观的量化 bucket 之间分布差异的情况，考虑使用下面的评估函数：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;double calculateDivergence(long[] bucket, long expectation) {
    long divergence = 0;
    for (int i=0; i&amp;lt;bucket.length; i++) {
        final long a = bucket[i];
        final long b = (a - expectation) * (a - expectation);
        for (int j=i+1; j&amp;lt;bucket.length; j++) {
            long c = (a - bucket[j]) * (a - bucket[j]);
            divergence += Math.max(b, c);
        }
    }
    return divergence; // the less the better
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;该数值越小，则证明 seed 对应的分布越均匀，其对应的 hash 函数越优。&lt;/p&gt;
&lt;h2 id=&quot;训练策略&quot;&gt;训练策略&lt;/h2&gt;
&lt;p&gt;seed 是一个 32bit 的无符号整数，其取值范围为 0 ～ 2&lt;sup&gt;32&lt;/sup&gt;-1。在 5000 个 symbol 的情况下，单线程尝试遍历所有 seed 的时间约为 25 小时。&lt;/p&gt;
&lt;p&gt;通常情况下 symbol 的数量会超过 5000，因此实际的搜索时间会大于这个值。此外，受限于计算资源限制，无法进行大规模的并行搜索，因此穷举法的耗时是不可接受的。&lt;/p&gt;
&lt;p&gt;幸好本例并不要求最优解，可以引入启发式搜索算法，加快训练速度。由于本人在这方面并不熟悉，为了降低编程难度，最终选择了模拟退火&lt;code&gt;(simulated annealing)&lt;/code&gt;算法。它模拟固体退火过程的热平衡问题与随机搜索寻优问题的相似性来达到寻找全局最优或近似全局最优的目的。&lt;br/&gt;相较于最简单的爬山法，模拟退火算法通以一定的概率接受较差的解，从而扩大搜索范围，保证解近似最优。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;/**
 * Basic framework of simulated annealing algorithm
 * @param &amp;lt;X&amp;gt; the solution of given problem
 */
public abstract class SimulatedAnnealing&amp;lt;X&amp;gt; {

    protected final int numberOfIterations;    // stopping condition for simulations

    protected final double coolingRate;        // the percentage by which we reduce the temperature of the system
    protected final double initialTemperature; // the starting energy of the system
    protected final double minimumTemperature; // optional stopping condition

    protected final long simulationTime;       // optional stopping condition
    protected final int detectionInterval;     // optional stopping condition

    protected SimulatedAnnealing(int numberOfIterations, double coolingRate) {
        this(numberOfIterations, coolingRate, 10000000, 1, 0, 0);
    }

    protected SimulatedAnnealing(int numberOfIterations, double coolingRate, double initialTemperature, double minimumTemperature, long simulationTime, int detectionInterval) {
        this.numberOfIterations = numberOfIterations;
        this.coolingRate = coolingRate;
        this.initialTemperature = initialTemperature;
        this.minimumTemperature = minimumTemperature;
        this.simulationTime = simulationTime;
        this.detectionInterval = detectionInterval;
    }

    protected abstract double score(X currentSolution);

    protected abstract X neighbourSolution(X currentSolution);

    public X simulateAnnealing(X currentSolution) {

        final long startTime = System.currentTimeMillis();

        // Initialize searching
        X bestSolution = currentSolution;
        double bestScore = score(bestSolution);
        double currentScore = bestScore;

        double t = initialTemperature;
        for (int i = 0; i &amp;lt; numberOfIterations; i++) {
            if (currentScore &amp;lt; bestScore) {
                // If the new solution is better, accept it unconditionally
                bestScore = currentScore;
                bestSolution = currentSolution;
            } else {
                // If the new solution is worse, calculate an acceptance probability for the worse solution
                // At high temperatures, the system is more likely to accept the solutions that are worse
                boolean rejectWorse = Math.exp((bestScore - currentScore) / t) &amp;lt; Math.random();
                if (rejectWorse || currentScore == bestScore) {
                    currentSolution = neighbourSolution(currentSolution);
                    currentScore = score(currentSolution);
                }
            }

            // Stop searching when the temperature is too low
            if ((t *= coolingRate) &amp;lt; minimumTemperature) {
                break;
            }

            // Stop searching when simulation time runs out
            if (simulationTime &amp;gt; 0 &amp;amp;&amp;amp; (i+1) % detectionInterval == 0) {
                if (System.currentTimeMillis() - startTime &amp;gt; simulationTime)
                    break;
            }
        }

        return bestSolution;
    }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;pre&gt;
&lt;code&gt;
/**
 * Search best hash seed for given key distribution and number of buckets with simulated annealing algorithm
 */
@Data
public class SimulatedAnnealingHashing extends SimulatedAnnealing&amp;lt;HashingSolution&amp;gt; {

    private static final int DISTRIBUTION_BATCH = 100;
    static final int SEARCH_BATCH = 200;

    private final int[] hashCodes = new int[SEARCH_BATCH];
    private final long[][] buckets = new long[SEARCH_BATCH][];

    @Data
    public class HashingSolution {

        private final int begin, range; // the begin and range for searching
        private int bestSeed;     // the best seed found in this search
        private long bestScore;   // the score corresponding to bestSeed

        private long calculateDivergence(long[] bucket) {
            long divergence = 0;
            for (int i=0; i&amp;lt;bucket.length; i++) {
                final long a = bucket[i];
                final long b = (a - expectation) * (a - expectation);
                for (int j=i+1; j&amp;lt;bucket.length; j++) {
                    long c = (a - bucket[j]) * (a - bucket[j]);
                    divergence += Math.max(b, c);
                }
            }
            return divergence; // the less the better
        }

        private HashingSolution solve() {

            if (range != hashCodes.length) {
                throw new IllegalStateException();
            }

            for (int i=0; i&amp;lt;range; i++) {
                Arrays.fill(buckets[i], hashCodes[i] = 0);
            }

            for (KeyDistribution[] bucket : distributions) {
                for (KeyDistribution distribution : bucket) {
                    Hashing.BKDRHash(distribution.getKey(), begin, hashCodes);
                    for (int k = 0; k&amp;lt; hashCodes.length; k++) {
                        int n = hashCodes[k] % buckets[k].length;
                        buckets[k][n] += distribution.getCount();
                    }
                }
            }

            int best = -1;
            long bestScore = Integer.MAX_VALUE;
            for (int i = 0; i&amp;lt; buckets.length; i++) {
                long score = calculateDivergence(buckets[i]);
                if (i == 0 || score &amp;lt; bestScore) {
                    bestScore = score;
                    best = i;
                }
            }

            if (best &amp;lt; 0) {
                throw new IllegalStateException();
            }

            this.bestScore = bestScore;
            this.bestSeed = begin + best;
            return this;
        }

        @Override
        public String toString() {
            return String.format(&quot;(seed:%d, score:%d)&quot;, bestSeed, bestScore);
        }
    }

    private final KeyDistribution[][] distributions; // key and its count（2-dimensional array for better performance）
    private final long expectation;  // the expectation count of each bucket
    private final int searchOutset;
    private int searchMin, searchMax;

    /**
     * SimulatedAnnealingHashing Prototype
     * @param keyAndCounts keys for hashing and count for each key
     * @param numOfBuckets number of buckets
     */
    public SimulatedAnnealingHashing(Map&amp;lt;String, Integer&amp;gt; keyAndCounts, int numOfBuckets) {
        super(100000000, .9999);
        distributions = buildDistribution(keyAndCounts);
        long sum = 0;
        for (KeyDistribution[] batch : distributions) {
            for (KeyDistribution distribution : batch) {
                sum += distribution.getCount();
            }
        }
        this.expectation = sum / numOfBuckets;
        this.searchOutset = 0;
        for (int i = 0; i&amp;lt; buckets.length; i++) {
            buckets[i] = new long[numOfBuckets];
        }
    }

    /**
     * SimulatedAnnealingHashing Derivative
     * @param prototype prototype simulation
     * @param searchOutset the outset for searching
     * @param simulationTime the expect time consuming for simulation
     */
    private SimulatedAnnealingHashing(SimulatedAnnealingHashing prototype, int searchOutset, long simulationTime) {
        super(prototype.numberOfIterations, prototype.coolingRate, prototype.initialTemperature, prototype.minimumTemperature,
                simulationTime, 10000);
        distributions = prototype.distributions;
        expectation = prototype.expectation;
        for (int i = 0; i&amp;lt; buckets.length; i++) {
            buckets[i] = new long[prototype.buckets[i].length];
        }
        this.searchOutset = searchOutset;
        this.searchMax = searchMin = searchOutset;
    }

    @Override
    public String toString() {
        return String.format(&quot;expectation: %d, outset:%d, search(min:%d, max:%d)&quot;, expectation, searchOutset, searchMin, searchMax);
    }

    private KeyDistribution[][] buildDistribution(Map&amp;lt;String, Integer&amp;gt; symbolCounts) {
        int bucketNum = symbolCounts.size() / DISTRIBUTION_BATCH + Integer.signum(symbolCounts.size() % DISTRIBUTION_BATCH);
        KeyDistribution[][] distributions = new KeyDistribution[bucketNum][];

        int bucketIndex = 0;
        List&amp;lt;KeyDistribution&amp;gt; batch = new ArrayList&amp;lt;&amp;gt;(DISTRIBUTION_BATCH);
        for (Map.Entry&amp;lt;String, Integer&amp;gt; entry : symbolCounts.entrySet()) {
            batch.add(new KeyDistribution(entry.getKey().toCharArray(), entry.getValue()));
            if (batch.size() == DISTRIBUTION_BATCH) {
                distributions[bucketIndex++] = batch.toArray(new KeyDistribution[0]);
                batch.clear();
            }
        }
        if (batch.size() &amp;gt; 0) {
            distributions[bucketIndex] = batch.toArray(new KeyDistribution[0]);
            batch.clear();
        }
        return distributions;
    }

    @Override
    protected double score(HashingSolution currentSolution) {
        return currentSolution.solve().bestScore;
    }

    @Override
    protected HashingSolution neighbourSolution(HashingSolution currentSolution) {
        // The default range of neighbourhood is [-100, 100]
        int rand = ThreadLocalRandom.current().nextInt(-100, 101);
        int next = currentSolution.begin + rand;
        searchMin = Math.min(next, searchMin);
        searchMax = Math.max(next, searchMax);
        return new HashingSolution(next, currentSolution.range);
    }

    public HashingSolution solve() {
        searchMin = searchMax = searchOutset;
        HashingSolution initialSolution = new HashingSolution(searchOutset, SEARCH_BATCH);
        return simulateAnnealing(initialSolution);
    }

    public SimulatedAnnealingHashing derive(int searchOutset, long simulationTime) {
        return new SimulatedAnnealingHashing(this, searchOutset, simulationTime);
    }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;forkjoin-框架&quot;&gt;ForkJoin 框架&lt;/h2&gt;
&lt;p&gt;为了达到更好的搜索效果，可以将整个搜索区域递归地划分为两两相邻的区域，然后在这些区域上执行并发的搜索，并递归地合并相邻区域的搜索结果。&lt;/p&gt;
&lt;p&gt;使用 JDK 提供的 ForkJoinPool 与 RecursiveTask 能很好地完成以上任务。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;@Data
@Slf4j
public class HashingSeedCalculator {

    /**
     * Recursive search task
     */
    private class HashingSeedCalculatorSearchTask extends RecursiveTask&amp;lt;HashingSolution&amp;gt; {

        private SimulatedAnnealingHashing simulation;
        private final int level;
        private final int center, range;

        private HashingSeedCalculatorSearchTask() {
            this.center = 0;
            this.range = Integer.MAX_VALUE / SimulatedAnnealingHashing.SEARCH_BATCH;
            this.level = traversalDepth;
            this.simulation = hashingSimulation;
        }

        private HashingSeedCalculatorSearchTask(HashingSeedCalculatorSearchTask parent, int center, int range) {
            this.center = center;
            this.range = range;
            this.level = parent.level - 1;
            this.simulation = parent.simulation;
        }

        @Override
        protected HashingSolution compute() {
            if (level == 0) {
                long actualCenter = center * SimulatedAnnealingHashing.SEARCH_BATCH;
                log.info(&quot;Searching around center {}&quot;, actualCenter);
                HashingSolution solution = simulation.derive(center, perShardRunningMills).solve();
                log.info(&quot;Searching around center {} found {}&quot;, actualCenter, solution);
                return solution;
            } else {
                int halfRange = range / 2;
                int leftCenter = center - halfRange, rightCenter = center + halfRange;
                ForkJoinTask&amp;lt;HashingSolution&amp;gt; leftTask = new HashingSeedCalculatorSearchTask(this, leftCenter, halfRange).fork();
                ForkJoinTask&amp;lt;HashingSolution&amp;gt; rightTask = new HashingSeedCalculatorSearchTask(this, rightCenter, halfRange).fork();
                HashingSolution left = leftTask.join();
                HashingSolution right = rightTask.join();
                return left.getBestScore() &amp;lt; right.getBestScore() ? left : right;
            }
        }
    }

    private final int poolParallelism;
    private final int traversalDepth;
    private final long perShardRunningMills;
    private final SimulatedAnnealingHashing hashingSimulation;

    /**
     * HashingSeedCalculator
     * @param numberOfShards the shard of the whole search range [Integer.MIN_VALUE, Integer.MAX_VALUE]
     * @param totalRunningHours the expect total time consuming for searching
     * @param symbolCounts the key and it`s distribution
     * @param numOfBuckets the number of buckets
     */
    public HashingSeedCalculator(int numberOfShards, int totalRunningHours, Map&amp;lt;String, Integer&amp;gt; symbolCounts, int numOfBuckets) {
        int n = (int) (Math.log(numberOfShards) / Math.log(2));
        if (Math.pow(2, n) != numberOfShards) {
            throw new IllegalArgumentException();
        }
        this.traversalDepth = n;
        this.poolParallelism = Math.max(ForkJoinPool.getCommonPoolParallelism() / 3 * 2, 1); // conservative estimation for parallelism
        this.perShardRunningMills = TimeUnit.HOURS.toMillis(totalRunningHours * poolParallelism) / numberOfShards;
        this.hashingSimulation = new SimulatedAnnealingHashing(symbolCounts, numOfBuckets);
    }

    @Override
    public String toString() {
        int numberOfShards = (int) Math.pow(2, traversalDepth);
        int totalRunningHours = (int) TimeUnit.MILLISECONDS.toHours(perShardRunningMills * numberOfShards) / poolParallelism;
        return &quot;HashingSeedCalculator(&quot; +
                &quot;numberOfShards: &quot; + numberOfShards +
                &quot;, perShardRunningMinutes: &quot; + TimeUnit.MILLISECONDS.toMinutes(perShardRunningMills) +
                &quot;, totalRunningHours: &quot; + totalRunningHours +
                &quot;, poolParallelism: &quot; + poolParallelism +
                &quot;, traversalDepth: &quot; + traversalDepth + &quot;)&quot;;
    }

    public synchronized HashingSolution searchBestSeed() {
        long now = System.currentTimeMillis();
        log.info(&quot;SearchBestSeed start&quot;);
        ForkJoinTask&amp;lt;HashingSolution&amp;gt; root = new HashingSeedCalculatorSearchTask().fork();
        HashingSolution initSolution = hashingSimulation.derive(0, perShardRunningMills).solve();
        HashingSolution bestSolution = root.join();
        log.info(&quot;Found init solution {}&quot;, initSolution);
        log.info(&quot;Found best solution {}&quot;, bestSolution);
        if (initSolution.getBestScore() &amp;lt; bestSolution.getBestScore()) {
            bestSolution = initSolution;
        }
        long cost = System.currentTimeMillis() - now;
        log.info(&quot;SearchBestSeed finish (cost:{}ms)&quot;, cost);
        return bestSolution;
    }

}
&lt;/code&gt;
&lt;/pre&gt;

&lt;p&gt;将改造后的代码部署到测试环境后，某日训练日志：&lt;/p&gt;
&lt;blockquote readability=&quot;39&quot;&gt;
&lt;p&gt;12:49:15.227 85172866 INFO hash.HashingSeedCalculator - Found init solution (seed:15231, score:930685828341164)&lt;br/&gt;12:49:15.227 85172866 INFO hash.HashingSeedCalculator - Found best solution (seed:362333, score:793386389726926)&lt;br/&gt;12:49:15.227 85172866 INFO hash.HashingSeedCalculator - SearchBestSeed finish (cost:10154898ms)&lt;br/&gt;12:49:15.227 85172866 INFO hash.TrainingService -&lt;br/&gt; &lt;br/&gt;Training result: (seed:362333, score:793386389726926)&lt;br/&gt; &lt;br/&gt;Buckets: 15&lt;br/&gt; &lt;br/&gt;Expectation: 44045697&lt;br/&gt; &lt;br/&gt;Result of Hashing.HashCode(seed=362333): 21327108 [42512742, 40479608, 43915771, 47211553, 45354264, 43209190, 43196570, 44725786, 41999747, 46450288, 46079231, 45116615, 44004021, 43896194, 42533877]&lt;br/&gt; &lt;br/&gt;Result of Hashing.HashCode(seed=31): 66929172 [39723630, 48721463, 43365391, 46301448, 43931616, 44678194, 39064877, 45922454, 43171141, 40715060, 33964547, 49709090, 58869949, 34964729, 47581868]&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;当晚使用 &lt;code&gt;BKDRHash(seed=31)&lt;/code&gt; 对新的交易日数据的进行分片：&lt;/p&gt;
&lt;blockquote readability=&quot;37&quot;&gt;
&lt;p&gt;04:00:59.001 partition messages per minute [45171, 68641, 62001, 80016, 55977, 61916, 55102, 49322, 55982, 57081, 51100, 70437, 135992, 37823, 58552] , messages total [39654953, 48666261, 43310578, 46146841, 43834832, 44577454, 38990331, 45871075, 43106710, 40600708, 33781629, 49752592, 58584246, 34928991, 47545369]&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;当晚使用 &lt;code&gt;BKDRHash(seed=362333)&lt;/code&gt; 对新的交易日数据的进行分片：&lt;/p&gt;
&lt;blockquote readability=&quot;37&quot;&gt;
&lt;p&gt;04:00:59.001 partition messages per minute [62424, 82048, 64184, 47000, 57206, 69439, 64430, 60096, 46986, 58182, 54557, 41523, 64310, 72402, 100326] , messages total [44985772, 48329212, 39995385, 43675702, 45216341, 45524616, 41335804, 44917938, 44605376, 44054821, 43371892, 42068637, 44000817, 42617562, 44652695]&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;对比日志发现 hash 经过优化后，分区的均匀程度有了显著的上升，并且热点分片也被消除了，基本达到当初设想的优化效果。&lt;/p&gt;
</description>
<pubDate>Sat, 03 Oct 2020 14:25:00 +0000</pubDate>
<dc:creator>buttercup</dc:creator>
<og:description>背景 现有个处理股票行情消息的系统，其架构如下： 由于数据量巨大，系统中启动了 15 个线程来消费行情消息。消息分配的策略较为简单：对 symbol 的 hashCode 取模，将消息分配给其中一个线</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/buttercup/p/13721957.html</dc:identifier>
</item>
<item>
<title>使用Maven那么久了，你对企业级Maven的核心配置了解多少？ - 冰河团队</title>
<link>http://www.cnblogs.com/binghe001/p/13765690.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/binghe001/p/13765690.html</guid>
<description>&lt;h2 id=&quot;写在前面&quot;&gt;写在前面&lt;/h2&gt;
&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;相信从事Java工作的小伙伴们多多少少都会接触到Maven。使用Maven来搭建项目，能够极大的方便我们构建项目的依赖关系，对于项目中需要依赖的Jar包，也只是简单的在pom.xml中进行配置即可。可以说，Maven能够极大的提高我们的开发效率和项目的维护效率，能够统一项目的依赖环境，提高团队的协作效率。然而，尽管使用Maven的小伙伴很多，但真正掌握了Maven核心配置的又有多少呢？&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;项目依赖&quot;&gt;项目依赖&lt;/h2&gt;
&lt;p&gt;项目依赖是指Maven 通过依赖传播、依赖优先原则、可选依赖、排除依赖、依赖范围等特性来管理项目classpath。&lt;/p&gt;
&lt;h3 id=&quot;依赖传播特性&quot;&gt;依赖传播特性&lt;/h3&gt;
&lt;p&gt;我们的项目通常需要依赖第三方组件，而第三方组件又会依赖其它组件遇到这种情况Maven会将依赖网络中的所有节点都会加入classpath当中，这就是Maven的依赖传播特性。&lt;/p&gt;
&lt;p&gt;例如下面的配置&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-xml&quot;&gt;&amp;lt;!-- 添加spring mvc依赖--&amp;gt;
&amp;lt;dependency&amp;gt;
  &amp;lt;groupId&amp;gt;org.springframework&amp;lt;/groupId&amp;gt;
  &amp;lt;artifactId&amp;gt;spring-webmvc&amp;lt;/artifactId&amp;gt;
  &amp;lt;version&amp;gt;5.2.9.RELEASE&amp;lt;/version&amp;gt;
&amp;lt;/dependency&amp;gt;
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;项目直接依赖了spring-webmvc 叫直接依赖，而对commons-logging 依赖是通过webmvc传递的所以叫间接依赖。&lt;/p&gt;
&lt;h3 id=&quot;依赖优先原则&quot;&gt;依赖优先原则&lt;/h3&gt;
&lt;p&gt;基于依赖传播特性，导致整个依赖网络会很复杂，难免会出现相同组件不同版本的情况。Maven此时会基于依赖优先原则选择其中一个版本。&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;第一原则：最短路径优先。&lt;/li&gt;
&lt;li&gt;第二原则：相同路径下配置在前的优先。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;第一原则示例&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-xml&quot;&gt;&amp;lt;!-- 直接添加commons-logging --&amp;gt;
&amp;lt;dependency&amp;gt;
  &amp;lt;groupId&amp;gt;commons-logging&amp;lt;/groupId&amp;gt;
  &amp;lt;artifactId&amp;gt;commons-logging&amp;lt;/artifactId&amp;gt;
  &amp;lt;version&amp;gt;1.2&amp;lt;/version&amp;gt;
&amp;lt;/dependency&amp;gt;
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;上述例子中commons-logging 通过spring-webmvc 依赖了1.1.3，而项目中直接依赖了1.2，基于最短路径原则项目最终引入的是1.2 版本。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;第二原则示例&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;主要步骤如下所示：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;（1）添加一个新工程Project B&lt;/p&gt;
&lt;p&gt;（2） 配置Project B 依赖 spring-web.3.2.9-RELEASE&lt;/p&gt;
&lt;p&gt;（3）当前工程直接依赖 Project B&lt;/p&gt;
&lt;p&gt;配置完之后，当前工程 project A 有两条路径可以依赖 spring-web,选择哪一条 就取决于 对 webmvc 和 Project B的配置先后顺序。&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;Project A==&amp;gt; spring-webmvc 5.2.9-RELEASE ==&amp;gt; spring-web 5.2.9-RELEASE&lt;/li&gt;
&lt;li&gt;Project A==&amp;gt; Project B 1.0.SNAPSHOT ==&amp;gt;spring-web.3.2.9-RELEASE&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;注意：在同一pom文件，第二原则不在适应。如下配置，最终引用的是1.2 版本，而不是配置在前面的1.1.1版本。&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-xml&quot;&gt;&amp;lt;!-- 在1.2 之前添加 commons-logging --&amp;gt;
&amp;lt;dependency&amp;gt;
 &amp;lt;groupId&amp;gt;commons-logging&amp;lt;/groupId&amp;gt;
 &amp;lt;artifactId&amp;gt;commons-logging&amp;lt;/artifactId&amp;gt;
 &amp;lt;version&amp;gt;1.1.1&amp;lt;/version&amp;gt;
&amp;lt;/dependency&amp;gt;

&amp;lt;dependency&amp;gt;
 &amp;lt;groupId&amp;gt;commons-logging&amp;lt;/groupId&amp;gt;
 &amp;lt;artifactId&amp;gt;commons-logging&amp;lt;/artifactId&amp;gt;
 &amp;lt;version&amp;gt;1.2&amp;lt;/version&amp;gt;
&amp;lt;/dependency&amp;gt;
&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;可选依赖&quot;&gt;可选依赖&lt;/h3&gt;
&lt;p&gt;可选依赖表示这个依赖不是必须的。通过在&lt;code&gt;&amp;lt;dependency&amp;gt;&amp;lt;/dependency&amp;gt;&lt;/code&gt;中添 加&lt;code&gt;&amp;lt;optional&amp;gt;true&amp;lt;/optional&amp;gt;&lt;/code&gt; 表示，默认是不可选的。可选依赖不会被传递。&lt;/p&gt;
&lt;h3 id=&quot;排除依赖&quot;&gt;排除依赖&lt;/h3&gt;
&lt;p&gt;即排除指定的间接依赖。通过配置&lt;code&gt;&amp;lt;exclusions&amp;gt;&amp;lt;/exclusions&amp;gt;&lt;/code&gt;配置排除指定组件。&lt;/p&gt;
&lt;p&gt;例如，我们可以使用下面的配置来排除对于spring-web的依赖。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-xml&quot;&gt;&amp;lt;!-- 排除指定项目 --&amp;gt;
&amp;lt;exclusions&amp;gt;
  &amp;lt;exclusion&amp;gt;
   &amp;lt;groupId&amp;gt;org.springframework&amp;lt;/groupId&amp;gt;
   &amp;lt;artifactId&amp;gt;spring-web&amp;lt;/artifactId&amp;gt;
  &amp;lt;/exclusion&amp;gt;
&amp;lt;/exclusions&amp;gt;
&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;依赖范围&quot;&gt;依赖范围&lt;/h3&gt;
&lt;p&gt;像junit 这个组件 我们只有在运行测试用例的时候去要用到，这就没有必要在打包的时候把junit.jar 包过构建进去，可以通过Maven 的依赖范围配置&lt;code&gt;&amp;lt;scope&amp;gt;&amp;lt;/scope&amp;gt;&lt;/code&gt;来达到这种目的。Maven 总共支持以下四种依赖范围：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;compile(默认)&lt;/strong&gt;: 编译范围，编译和打包都会依赖。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;provided：&lt;/strong&gt; 提供范围，编译时依赖，但不会打包进去。如：servlet-api.jar&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;runtime：&lt;/strong&gt; 运行时范围，打包时依赖，编译不会。如：mysql-connector-java.jar&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;test：&lt;/strong&gt; 测试范围，编译运行测试用例依赖，不会打包进去。如：junit.jar&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;system：&lt;/strong&gt; 表示由系统中classpath指定。编译时依赖，不会打包进去。配合&lt;code&gt;&amp;lt;systemPath&amp;gt;&amp;lt;/systemPath&amp;gt;&lt;/code&gt; 一起使用。示例：java.home下的tool.jar&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;system 除了可以用于引入系统classpath 中包，也可以用于引入系统非maven 收录的第三方Jar，做法是将第三方Jar放置在 项目的 lib 目录下，然后配置 相对路径，但因system 不会打包进去所以需要配合 maven-dependency-plugin 插件配合使用。当然，我还是推荐小伙伴们通过 将第三方Jar手动install 到仓库。&lt;/p&gt;
&lt;p&gt;接下来，我们就列举几个简单的使用示例。&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;system 的通常使用方式&lt;/li&gt;
&lt;/ul&gt;&lt;pre&gt;
&lt;code class=&quot;language-xml&quot;&gt;&amp;lt;dependency&amp;gt;
     &amp;lt;groupId&amp;gt;com.sun&amp;lt;/groupId&amp;gt;
     &amp;lt;artifactId&amp;gt;tools&amp;lt;/artifactId&amp;gt;
     &amp;lt;version&amp;gt;${java.version}&amp;lt;/version&amp;gt;
     &amp;lt;scope&amp;gt;system&amp;lt;/scope&amp;gt;
     &amp;lt;optional&amp;gt;true&amp;lt;/optional&amp;gt;
     &amp;lt;systemPath&amp;gt;${java.home}/../lib/tools.jar&amp;lt;/systemPath&amp;gt;
&amp;lt;/dependency&amp;gt;
&lt;/code&gt;
&lt;/pre&gt;
&lt;ul&gt;&lt;li&gt;system 另外使用方式 ,将工程内的jar直接引入&lt;/li&gt;
&lt;/ul&gt;&lt;pre&gt;
&lt;code class=&quot;language-xml&quot;&gt;&amp;lt;dependency&amp;gt;
  &amp;lt;groupId&amp;gt;jsr&amp;lt;/groupId&amp;gt;
  &amp;lt;artifactId&amp;gt;jsr&amp;lt;/artifactId&amp;gt;
  &amp;lt;version&amp;gt;3.5&amp;lt;/version&amp;gt;
  &amp;lt;scope&amp;gt;system&amp;lt;/scope&amp;gt;
  &amp;lt;optional&amp;gt;true&amp;lt;/optional&amp;gt;
  &amp;lt;systemPath&amp;gt;${basedir}/lib/jsr305.jar&amp;lt;/systemPath&amp;gt;
&amp;lt;/dependency&amp;gt;
&lt;/code&gt;
&lt;/pre&gt;
&lt;ul&gt;&lt;li&gt;通过插件 将system 的jar 打包进去&lt;/li&gt;
&lt;/ul&gt;&lt;pre&gt;
&lt;code class=&quot;language-xml&quot;&gt;&amp;lt;plugin&amp;gt;
  &amp;lt;groupId&amp;gt;org.apache.maven.plugins&amp;lt;/groupId&amp;gt;\
  &amp;lt;artifactId&amp;gt;maven-dependency-plugin&amp;lt;/artifactId&amp;gt;
  &amp;lt;version&amp;gt;2.10&amp;lt;/version&amp;gt;
  &amp;lt;executions&amp;gt;
    &amp;lt;execution&amp;gt;
      &amp;lt;id&amp;gt;copy-dependencies&amp;lt;/id&amp;gt;
      &amp;lt;phase&amp;gt;compile&amp;lt;/phase&amp;gt;
      &amp;lt;goals&amp;gt;
        &amp;lt;goal&amp;gt;copy-dependencies&amp;lt;/goal&amp;gt;
      &amp;lt;/goals&amp;gt;
      &amp;lt;configuration&amp;gt;
&amp;lt;outputDirectory&amp;gt;${project.build.directory}/${project.build.finalName}/WEB-INF/lib&amp;lt;/outputDirectory&amp;gt;
        &amp;lt;includeScope&amp;gt;system&amp;lt;/includeScope&amp;gt;
        &amp;lt;excludeGroupIds&amp;gt;com.sun&amp;lt;/excludeGroupIds&amp;gt;
      &amp;lt;/configuration&amp;gt;
    &amp;lt;/execution&amp;gt;
  &amp;lt;/executions&amp;gt;
&amp;lt;/plugin&amp;gt;
&lt;/code&gt;
&lt;/pre&gt;
&lt;ul&gt;&lt;li&gt;手动加入本地仓库&lt;/li&gt;
&lt;/ul&gt;&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;mvn install:install-file -Dfile=mykit-transaction-message.jar -DgroupId=io.mykit -DartifactId=mykit-transaction-message -Dversion=1.0.0-RELEASE -Dpackaging=jar
&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;项目聚合与继承&quot;&gt;项目聚合与继承&lt;/h2&gt;
&lt;h3 id=&quot;聚合&quot;&gt;聚合&lt;/h3&gt;
&lt;p&gt;聚合是指将多个模块整合在一起，统一构建，避免一个一个的构建。聚合需要个父工程，然后使用 &lt;code&gt;&amp;lt;modules&amp;gt;&amp;lt;/modules&amp;gt;&lt;/code&gt; 进行配置其中对应的是子工程的相对路径。例如下面的配置。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-xml&quot;&gt;&amp;lt;modules&amp;gt;
  &amp;lt;module&amp;gt;mykit-dao&amp;lt;/module&amp;gt;
  &amp;lt;module&amp;gt;mykit-service&amp;lt;/module&amp;gt;
&amp;lt;/modules&amp;gt;
&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;继承&quot;&gt;继承&lt;/h3&gt;
&lt;p&gt;继承是指子工程直接继承父工程 当中的属性、依赖、插件等配置，避免重复配置。继承包括如下几种方式。&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;属性继承&lt;/li&gt;
&lt;li&gt;依赖继承&lt;/li&gt;
&lt;li&gt;插件继承&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;注意：上面的三个配置子工程都可以进行重写，重写之后以子工程的为准。&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&quot;依赖管理&quot;&gt;依赖管理&lt;/h3&gt;
&lt;p&gt;通过继承的特性，子工程是可以间接依赖父工程的依赖，但多个子工程依赖有时并不一至，这时就可以在父工程中加入&lt;code&gt;&amp;lt;dependencyManagement&amp;gt;&amp;lt;/dependencyManagement&amp;gt;&lt;/code&gt; 声明该工程需要的JAR包，然后在子工程中引入。例如下面的配置。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-xml&quot;&gt;&amp;lt;!-- 父工程中声明 junit 4.12 --&amp;gt;
&amp;lt;dependencyManagement&amp;gt;
  &amp;lt;dependencies&amp;gt;
    &amp;lt;dependency&amp;gt;
      &amp;lt;groupId&amp;gt;junit&amp;lt;/groupId&amp;gt;
      &amp;lt;artifactId&amp;gt;junit&amp;lt;/artifactId&amp;gt;
      &amp;lt;version&amp;gt;4.12&amp;lt;/version&amp;gt;
    &amp;lt;/dependency&amp;gt;
  &amp;lt;/dependencies&amp;gt;
&amp;lt;/dependencyManagement&amp;gt;
&amp;lt;!-- 子工程中引入 --&amp;gt;
&amp;lt;dependency&amp;gt;
  &amp;lt;groupId&amp;gt;junit&amp;lt;/groupId&amp;gt;
  &amp;lt;artifactId&amp;gt;junit&amp;lt;/artifactId&amp;gt;
&amp;lt;/dependency&amp;gt;
&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;项目属性&quot;&gt;项目属性&lt;/h3&gt;
&lt;p&gt;通过 &lt;code&gt;&amp;lt;properties&amp;gt;&amp;lt;/properties&amp;gt;&lt;/code&gt; 配置属性参数，可以简化配置。例如下面的配置。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-xml&quot;&gt;&amp;lt;!-- 配置proName属性 --&amp;gt;
&amp;lt;properties&amp;gt;
  &amp;lt;projectName&amp;gt;projectName&amp;lt;/projectName&amp;gt;
&amp;lt;/properties&amp;gt;
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;我们可以在pom.xml文件中使用下面的形式来引入配置的参数。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-xml&quot;&gt;${projectName}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;接下来，我们再来看几个Maven的默认属性，如下所示。&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;${basedir} 项目根目录&lt;/li&gt;
&lt;li&gt;${version}表示项目版本;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;${project.basedir}同${basedir};&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;${project.version}表示项目版本,与${version}相同;&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;${project.build.directory} 构建目录，缺省为target&lt;/li&gt;
&lt;li&gt;${project.build.sourceEncoding}表示主源码的编码格式;&lt;/li&gt;
&lt;li&gt;${project.build.sourceDirectory}表示主源码路径;&lt;/li&gt;
&lt;li&gt;${project.build.finalName}表示输出文件名称;&lt;/li&gt;
&lt;li&gt;${project.build.outputDirectory} 构建过程输出目录，缺省为target/classes&lt;/li&gt;
&lt;/ul&gt;&lt;h2 id=&quot;项目构建配置&quot;&gt;项目构建配置&lt;/h2&gt;
&lt;h3 id=&quot;构建资源配置&quot;&gt;构建资源配置&lt;/h3&gt;
&lt;p&gt;基本配置示例：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-xml&quot;&gt;&amp;lt;defaultGoal&amp;gt;package&amp;lt;/defaultGoal&amp;gt;
&amp;lt;directory&amp;gt;${basedir}/target2&amp;lt;/directory&amp;gt;
&amp;lt;finalName&amp;gt;${artifactId}-${version}&amp;lt;/finalName&amp;gt;
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;说明：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;defaultGoal：执行构建时默认的goal或phase，如jar:jar或者package等&lt;/li&gt;
&lt;li&gt;directory：构建的结果所在的路径，默认为${basedir}/target目录&lt;/li&gt;
&lt;li&gt;finalName：构建的最终结果的名字，该名字可能在其他plugin中被改变&lt;/li&gt;
&lt;/ul&gt;&lt;h3 id=&quot;resources-配置示例&quot;&gt;resources 配置示例&lt;/h3&gt;
&lt;pre&gt;
&lt;code class=&quot;language-xml&quot;&gt;&amp;lt;resources&amp;gt;
  &amp;lt;resource&amp;gt;
   &amp;lt;directory&amp;gt;src/main/java&amp;lt;/directory&amp;gt;
   &amp;lt;includes&amp;gt;
     &amp;lt;include&amp;gt;**/*.MF&amp;lt;/include&amp;gt;
     &amp;lt;include&amp;gt;**/*.xml&amp;lt;/include&amp;gt;
   &amp;lt;/includes&amp;gt;
   &amp;lt;filtering&amp;gt;true&amp;lt;/filtering&amp;gt;
  &amp;lt;/resource&amp;gt;
  &amp;lt;resource&amp;gt;
   &amp;lt;directory&amp;gt;src/main/resources&amp;lt;/directory&amp;gt;
   &amp;lt;includes&amp;gt;
     &amp;lt;include&amp;gt;**/*&amp;lt;/include&amp;gt;
     &amp;lt;include&amp;gt;*&amp;lt;/include&amp;gt;
   &amp;lt;/includes&amp;gt;
   &amp;lt;filtering&amp;gt;true&amp;lt;/filtering&amp;gt;
  &amp;lt;/resource&amp;gt;
 &amp;lt;/resources&amp;gt;
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;说明：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;resources：build过程中涉及的资源文件&lt;/li&gt;
&lt;li&gt;targetPath：资源文件的目标路径&lt;/li&gt;
&lt;li&gt;directory：资源文件的路径，默认位于${basedir}/src/main/resources/目录下&lt;/li&gt;
&lt;li&gt;includes：一组文件名的匹配模式，被匹配的资源文件将被构建过程处理&lt;/li&gt;
&lt;li&gt;excludes：一组文件名的匹配模式，被匹配的资源文件将被构建过程忽略。同时被includes和excludes匹配的资源文件，将被忽略。&lt;/li&gt;
&lt;li&gt;filtering：默认false ，true 表示 通过参数 对 资源文件中 的${key} 在编译时进行动态变更。替换源 -Dkey 和pom 中的 值 或 中指定的properties 文件。&lt;/li&gt;
&lt;/ul&gt;&lt;h2 id=&quot;重磅福利&quot;&gt;重磅福利&lt;/h2&gt;
&lt;p&gt;微信搜一搜【冰河技术】微信公众号，关注这个有深度的程序员，每天阅读超硬核技术干货，公众号内回复【PDF】有我准备的一线大厂面试资料和我原创的超硬核PDF技术文档，以及我为大家精心准备的多套简历模板（不断更新中），希望大家都能找到心仪的工作，学习是一条时而郁郁寡欢，时而开怀大笑的路，加油。如果你通过努力成功进入到了心仪的公司，一定不要懈怠放松，职场成长和新技术学习一样，不进则退。如果有幸我们江湖再见！&lt;/p&gt;
&lt;p&gt;另外，我开源的各个PDF，后续我都会持续更新和维护，感谢大家长期以来对冰河的支持！！&lt;/p&gt;
</description>
<pubDate>Sat, 03 Oct 2020 14:10:00 +0000</pubDate>
<dc:creator>冰河团队</dc:creator>
<og:description>写在前面 相信从事Java工作的小伙伴们多多少少都会接触到Maven。使用Maven来搭建项目，能够极大的方便我们构建项目的依赖关系，对于项目中需要依赖的Jar包，也只是简单的在pom.xml中进行配</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/binghe001/p/13765690.html</dc:identifier>
</item>
<item>
<title>初识 Istio - 服务网格管理工具 - freshchen</title>
<link>http://www.cnblogs.com/freshchen/p/13765650.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/freshchen/p/13765650.html</guid>
<description>&lt;h2 id=&quot;what-is-a-service-mesh（服务网格）&quot;&gt;What is a service mesh（服务网格）?&lt;/h2&gt;
&lt;p&gt;微服务在国内流行已经多年了，大多数公司选择了基于容器化技术（ Docker ）以及容器编排管理平台 （ Kubernetes ）落地微服务 ，然而这仅仅是个开始，微服务的发展没有停滞。&lt;/p&gt;
&lt;p&gt;相信在调研微服务开发框架的过程中，会发现成熟的框架如 Spring Cloud ，Dubbo，Microprofile，它们都提供了诸如服务发现、负载均衡、故障恢复、度量和监控等方面的解决方案，但是都不同程度的产生了很多业务无关的代码。运维层面，在 Kubernetes 平台上要实现一些常见需求很不容易，例如 A/B 测试、金丝雀发布、速率限制、访问控制和端到端认证等。&lt;/p&gt;
&lt;p&gt;2016 年开发 Linkerd 的 Buoyant 公司提出，要在开发和运维中间增加一层基础设施，提供对网络流量的洞察和操作控制的能力，包括服务注册发现、负载均衡、故障恢复、监控、权限控制等等，而这层基础设施就称作服务网格。&lt;/p&gt;
&lt;h2 id=&quot;what-is-istio&quot;&gt;What is Istio?&lt;/h2&gt;
&lt;p&gt;Istio 是谷歌对于服务网格的实现，支持 Kubernetes，Consul，VMs等多种环境，并作为透明的一层接入到现有的微服务应用程序里，提供了如下功能：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;为 HTTP、gRPC、WebSocket 和 TCP 流量自动负载均衡。&lt;/li&gt;
&lt;li&gt;通过丰富的路由规则、重试、故障转移和故障注入对流量行为进行细粒度控制。&lt;/li&gt;
&lt;li&gt;可插拔的策略层和配置 API，支持访问控制、速率限制和配额。&lt;/li&gt;
&lt;li&gt;集群内（包括集群的入口和出口）所有流量的自动化度量、日志记录和追踪。&lt;/li&gt;
&lt;li&gt;在具有强大的基于身份验证和授权的集群中实现安全的服务间通信。&lt;/li&gt;
&lt;/ul&gt;&lt;h2 id=&quot;how-istio-work？&quot;&gt;How istio work？&lt;/h2&gt;
&lt;p&gt;Istio 的架构图如下，istio 服务网格，分为控制面和数据面，所有流量都从 istio 的 ingress 进，从 egress出，以 Kubernetes 为例，上图的两个 Service 对应 Kubernetes 中的 Pod，istio 使用 sidecar 模式，给每个 Pod 加了一层代理，实际请求通通路由到代理，满足条件才路由给 Pod，至于控制面很简单，就是把路由规则同步给各个代理，并且完成一些管理，安全，遥测工作。可以发现网格中 Kubernetes 的网络完全被 istio 接管了，每个 Pod 和其代理构成了一个个对外零信任的高内聚的小格子。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://cdn.jsdelivr.net/gh/freshchen/resource@master/img/istio-arch.png&quot; alt=&quot;图1&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;插一句，Docker 提倡每个进程一个容器，Kubernetes 提倡每个容器一个 Pod，istio 又提倡给每个 Pod 一个格子，最小单元变的越来越大了，每个格子外面还会接着套么？&lt;/p&gt;
&lt;h2 id=&quot;探秘-istio-流量管理&quot;&gt;探秘 Istio 流量管理&lt;/h2&gt;
&lt;p&gt;流量管理无疑是 Istio 的核心，流量管理的核心又是 sidecar 代理，正是通过一个个 sidecar 代理，istio 能清晰的知道流量从哪来到哪去，从而很方便的实现，日志收集，遥测，追踪，监控，限流等功能。下面让我们一起近距离体验一下 Istio 的流量管理功能。&lt;/p&gt;
&lt;h3 id=&quot;安装&quot;&gt;安装&lt;/h3&gt;
&lt;p&gt;参照 &lt;a href=&quot;https://istio.io/latest/docs/setup/getting-started/&quot;&gt;官方教程&lt;/a&gt; 安装 Isito demo profile，如下所示 Istio 相关的服务全装到了 istio-system 的 namespace。其中 istiod 是 istio 的核心服务，Pilot（服务发现），Galley（配置管理），Citadel（证书管理）等服务被统一成了 istiod，istiod 中 跑着 discovery 进程，用于监听 Kubernetes 的 ApiServer 并且实时把配置跟新到各个 sidecar 代理中。istio-ingressgateway 以及 istio-egressgateway 是 demo 模式下默认安装，运行中 Pilot 的客户端，接受配置实时跟新规则，envoy 是类似 ngnix 的轻量级代理工具。istio-ingressgateway 和Kubernetes 平台中的 nginx-ingress 组建起相同作用，作为平台外部请求进入网格的入口。其他 grafana，jaeger，kiali，prometheus为 istio 集成的可观察性相关的组件。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;chenling@ChendeMacBook-Pro ~ % kubectl get pod -n istio-system
NAME                                    READY   STATUS    RESTARTS   AGE
grafana-767c5487d6-j5l92                1/1     Running   0          5d5h
istio-egressgateway-55856f9f8f-s78md    1/1     Running   0          5d21h
istio-ingressgateway-85fbcc77b8-8rsfk   1/1     Running   0          5d21h
istiod-6dc785c4b9-z8v9v                 1/1     Running   0          5d21h
jaeger-566c547fb9-zbhn7                 1/1     Running   0          5d5h
kiali-89fd7f87b-r64dw                   1/1     Running   0          5d21h
prometheus-788c945c9c-xn8mz             2/2     Running   0          5d5h
chenling@ChendeMacBook-Pro ~ % kubectl exec -it istiod-6dc785c4b9-z8v9v -n istio-system -- ps -ef              
UID        PID  PPID  C STIME TTY          TIME CMD
istio-p+     1     0  3 Sep27 ?        00:28:28 /usr/local/bin/pilot-discovery d
istio-p+    34     0  0 00:41 pts/0    00:00:00 sh
istio-p+   112     0  0 08:04 pts/1    00:00:00 ps -ef
chenling@ChendeMacBook-Pro ~ % kubectl exec -it istio-ingressgateway-85fbcc77b8-8rsfk -n istio-system -- ps -ef
UID        PID  PPID  C STIME TTY          TIME CMD
istio-p+     1     0  0 Sep27 ?        00:01:38 /usr/local/bin/pilot-agent proxy
istio-p+    14     1  1 Sep27 ?        00:08:48 /usr/local/bin/envoy -c etc/isti
istio-p+    65     0  0 08:04 pts/0    00:00:00 ps -ef
&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;注入&quot;&gt;注入&lt;/h3&gt;
&lt;p&gt;通过给 default namespace 打如下标签，pod 创建时会自动注入 sidecar&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;$ kubectl label namespace default istio-injection=enabled
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;当我们通过 Kubernetes 的客户端工具给 ApiServer 发送指令时，平台的 Scheduler 调度服务，会监听创建请求，并找到合适的机器，把相关信息传给 ApiServer 并把原数据写入 etcd，Isito 的 Pilot 采用类似机制监听ApiServer ，当 namespace 被打上自动注入标签，就会修改创建 pod 的原数据，增加 sidecar 代理容器到 pod 中，并且监听到 Istio 自定义的资源变动，通知到相关的 sidecar。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://cdn.jsdelivr.net/gh/freshchen/resource@master/img/istio-2.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;当然也可以手动注入 sidecar，手动注入会启动新的 pod&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;istioctl kube-inject -f deployment.yaml -o deployment-injected.yaml
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;书写 deployment 资源文件，注入完成之后如下所示，为啥 Pod 中有 2 个容器？&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;chenling@ChendeMacBook-Pro ~ % kubectl get pod
NAME                         READY   STATUS    RESTARTS   AGE
client-6b495f748b-tgt97      2/2     Running   2          23h
hello-bc8bb7cd6-pvvkv        2/2     Running   0          24h
hello-new-5b7cbf7df4-ksxtg   2/2     Running   0          24h
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;默认容器是我们声明的，运行着一个 httpd 服务&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;chenling@ChendeMacBook-Pro ~ % kubectl exec -it hello-bc8bb7cd6-pvvkv -- ps -ef
Defaulting container name to hello.
Use 'kubectl describe pod/hello-bc8bb7cd6-pvvkv -n default' to see all of the containers in this pod.
PID   USER     TIME  COMMAND
    1 root      0:00 httpd -f -p 8080 -h /var/www
  435 root      0:00 ps -ef
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;查看 pod 中另外一个容器，可以发现和 istio-gateway 一样，其实运行着一个 envoy 代理服务，通过 pilot-agent 接受控制面信息。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;chenling@ChendeMacBook-Pro ~ % kubectl exec -it hello-bc8bb7cd6-pvvkv -c istio-proxy -- ps -ef
UID        PID  PPID  C STIME TTY          TIME CMD
istio-p+     1     0  0 Sep27 ?        00:01:50 /usr/local/bin/pilot-agent proxy
istio-p+    15     1  1 Sep27 ?        00:05:24 /usr/local/bin/envoy -c etc/isti
istio-p+   140     0  0 08:13 pts/0    00:00:00 ps -ef
&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;注入流程&quot;&gt;注入流程&lt;/h3&gt;
&lt;p&gt;下面我们看看注入过程，首先被注入的pod中增加了名为 istio-init 的 initContainer，如下日志显示初始化过程，通过在容器 iptables nat 表中增加规则，把所有非 Istio 的入站流量重定向到 15006 端口，所有非 Istio 的出站流量定向到 15001 端口&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;chenling@ChendeMacBook-Pro ~ % kubectl logs --tail=32 hello-bc8bb7cd6-pvvkv -c istio-init
iptables-save 
# Generated by iptables-save v1.6.1 on Sun Sep 27 07:20:03 2020
*nat
:PREROUTING ACCEPT [0:0]
:INPUT ACCEPT [0:0]
:OUTPUT ACCEPT [0:0]
:POSTROUTING ACCEPT [0:0]
:ISTIO_INBOUND - [0:0]
:ISTIO_IN_REDIRECT - [0:0]
:ISTIO_OUTPUT - [0:0]
:ISTIO_REDIRECT - [0:0]
-A PREROUTING -p tcp -j ISTIO_INBOUND
-A OUTPUT -p tcp -j ISTIO_OUTPUT
-A ISTIO_INBOUND -p tcp -m tcp --dport 15008 -j RETURN
-A ISTIO_INBOUND -p tcp -m tcp --dport 22 -j RETURN
-A ISTIO_INBOUND -p tcp -m tcp --dport 15090 -j RETURN
-A ISTIO_INBOUND -p tcp -m tcp --dport 15021 -j RETURN
-A ISTIO_INBOUND -p tcp -m tcp --dport 15020 -j RETURN
-A ISTIO_INBOUND -p tcp -j ISTIO_IN_REDIRECT
-A ISTIO_IN_REDIRECT -p tcp -j REDIRECT --to-ports 15006
-A ISTIO_OUTPUT -s 127.0.0.6/32 -o lo -j RETURN
-A ISTIO_OUTPUT ! -d 127.0.0.1/32 -o lo -m owner --uid-owner 1337 -j ISTIO_IN_REDIRECT
-A ISTIO_OUTPUT -o lo -m owner ! --uid-owner 1337 -j RETURN
-A ISTIO_OUTPUT -m owner --uid-owner 1337 -j RETURN
-A ISTIO_OUTPUT ! -d 127.0.0.1/32 -o lo -m owner --gid-owner 1337 -j ISTIO_IN_REDIRECT
-A ISTIO_OUTPUT -o lo -m owner ! --gid-owner 1337 -j RETURN
-A ISTIO_OUTPUT -m owner --gid-owner 1337 -j RETURN
-A ISTIO_OUTPUT -d 127.0.0.1/32 -j RETURN
-A ISTIO_OUTPUT -j ISTIO_REDIRECT
-A ISTIO_REDIRECT -p tcp -j REDIRECT --to-ports 15001
COMMIT
# Completed on Sun Sep 27 07:20:03 2020
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;如下所示 ，15006 和 15001 端口都是 envoy 提供&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;chenling@ChendeMacBook-Pro ~ % kubectl exec -it hello-bc8bb7cd6-pvvkv -c istio-proxy -- netstat -nltp
Active Internet connections (only servers)
Proto Recv-Q Send-Q Local Address           Foreign Address         State       PID/Program name    
tcp        0      0 0.0.0.0:15021           0.0.0.0:*               LISTEN      15/envoy            
tcp        0      0 0.0.0.0:15090           0.0.0.0:*               LISTEN      15/envoy            
tcp        0      0 127.0.0.1:15000         0.0.0.0:*               LISTEN      15/envoy            
tcp        0      0 0.0.0.0:15001           0.0.0.0:*               LISTEN      15/envoy            
tcp        0      0 0.0.0.0:15006           0.0.0.0:*               LISTEN      15/envoy            
tcp6       0      0 :::15020                :::*                    LISTEN      1/pilot-agent       
tcp6       0      0 :::8080                 :::*                    LISTEN      -    
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;综上所述，istio流量管理的实现大致如下&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;通过自动注入，给 pod 增加 iptables，把所有进出流量指向 envoy&lt;/li&gt;
&lt;li&gt;控制面的 pilot 监控 istio 自定义资源变化，把规则发送给各个 sidecar&lt;/li&gt;
&lt;li&gt;sidecar 中的 pilot-agent 接受 pilot 的信息，热更新 envoy 代理规则，无需重启 pod即可改变流量路径&lt;/li&gt;
&lt;/ul&gt;&lt;h3 id=&quot;配置&quot;&gt;配置&lt;/h3&gt;
&lt;p&gt;实践一下配置网格行为&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;配置名为 xingren-gateway 的 Istio Gateway 接受所有 host为 xingren.upup 的外部流量&lt;/li&gt;
&lt;/ul&gt;&lt;pre&gt;
&lt;code class=&quot;language-yaml&quot;&gt;---
apiVersion: networking.istio.io/v1alpha3
kind: Gateway
metadata:
  name: xingren-gateway
spec:
  selector:
    istio: ingressgateway
  servers:
    - port:
        number: 80
        name: http
        protocol: HTTP
      hosts:
        - xingren.upup
&lt;/code&gt;
&lt;/pre&gt;
&lt;ul&gt;&lt;li&gt;配置 VirtualService 接受所有来自 ingren-gateway，host 为 xingren.upup 或者 hello 的流量&lt;/li&gt;
&lt;li&gt;如果 http header 中 version 字段为 new，流量转到 new 子集，并且设置了 5 秒的超时时间，并且以 10% 的比例，注入一个10秒的请求延迟，已验证服务的容错能力&lt;/li&gt;
&lt;li&gt;如果 http header 中 version 字段不存在，或者不是 new，则 70% 流量转到 latest 子集， 30% 流量转到 new 子集&lt;/li&gt;
&lt;li&gt;配置可复用的 DestinationRule，定义了 latest 子集和 new 子集，按照 version 标签匹配到 Kubernetes hello 服务下的真实pod，同时设置了并发请求不能大于1的熔断规则&lt;/li&gt;
&lt;/ul&gt;&lt;pre&gt;
&lt;code class=&quot;language-yaml&quot;&gt;---
apiVersion: networking.istio.io/v1alpha3
kind: VirtualService
metadata:
  name: hello-virtualservice
spec:
  hosts:
    - hello
    - xingren.upup
  gateways:
    - xingren-gateway
  http:
    - match:
        - headers:
            version:
              exact: new
      route:
        - destination:
            host: hello
            subset: new
      fault:
        delay:
          percentage:
            value: 10
          fixedDelay: 10s
      timeout: 5s
    - route:
        - destination:
            host: hello
            subset: latest
          weight: 70
        - destination:
            host: hello
            subset: new
          weight: 30

---
apiVersion: networking.istio.io/v1alpha3
kind: DestinationRule
metadata:
  name: hello-destinationrule
spec:
  host: hello
  trafficPolicy:
    connectionPool:
      http:
        http1MaxPendingRequests: 1
        maxRequestsPerConnection: 1
      tcp:
        maxConnections: 1
  subsets:
    - name: latest
      labels:
        version: latest
    - name: new
      labels:
        version: new
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;当然 istio 的功能远远不止这些，详见 &lt;a href=&quot;https://istio.io/latest/docs/tasks/traffic-management/&quot;&gt;官网案例&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&quot;可视化&quot;&gt;可视化&lt;/h3&gt;
&lt;p&gt;可以通过如下命令观察服务网格，当然也可以通过网关暴露出去&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;chenling@ChendeMacBook-Pro ~ % istioctl dashboard --help
Access to Istio web UIs

Usage:
  istioctl dashboard [flags]
  istioctl dashboard [command]

Aliases:
  dashboard, dash, d

Available Commands:
  controlz    Open ControlZ web UI
  envoy       Open Envoy admin web UI
  grafana     Open Grafana web UI
  jaeger      Open Jaeger web UI
  kiali       Open Kiali web UI
  prometheus  Open Prometheus web UI
  zipkin      Open Zipkin web UI
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;向服务中注入一些流量&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;chenling@ChendeMacBook-Pro ~ % for i in `seq 1000`; do wget -q -O - http://xingren.upup; sleep 0.2;done
 Hello World(new) 
 Hello World 
 Hello World 
 Hello World 
 Hello World 
 Hello World 
 Hello World(new) 
 Hello World 
 Hello World 
 Hello World 
 Hello World(new) 
 Hello World 
 Hello World 
 Hello World 
 Hello World(new) 
 Hello World 
 ...
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;观察 istio 的可视化界面 kiali，可以看到流量从外部通过 hello 虚拟服务进入 pod，并且权重 大致 7比3&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://cdn.jsdelivr.net/gh/freshchen/resource@master/img/istio-5.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h2 id=&quot;总结&quot;&gt;总结&lt;/h2&gt;
&lt;p&gt;Istio 出色的完成了服务网格该有的功能，且有很强的可扩展性，可以方便的整合 prometheus，jaeger 等工具，随着迭代易用性也有所提高。虽然 Istio 还没有被大规模用于生产环境 ，并且有质疑其占用了过多的资源，总的来说利大于弊，经实验，没有被 Istio 注入的 pod 访问被注入的资源，不会受到任何影响，会直接透传给真实pod，所以还是可以小范围尝鲜 Istio 的。&lt;/p&gt;
</description>
<pubDate>Sat, 03 Oct 2020 13:55:00 +0000</pubDate>
<dc:creator>freshchen</dc:creator>
<og:description>What is a service mesh（服务网格）? 微服务在国内流行已经多年了，大多数公司选择了基于容器化技术（ Docker ）以及容器编排管理平台 （ Kubernetes ）落地微服务</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/freshchen/p/13765650.html</dc:identifier>
</item>
<item>
<title>Python字符编码和二进制不得不说的故事 - 北门吹雪</title>
<link>http://www.cnblogs.com/2bjiujiu/p/13762909.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/2bjiujiu/p/13762909.html</guid>
<description>&lt;p&gt;&lt;strong&gt;&lt;span&gt;二进制&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;span&gt;核心思想：&lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;&lt;span&gt;　　&lt;strong&gt;冯诺依曼 + 图灵机&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　&lt;strong&gt;电如何表示状态&lt;/strong&gt;，才能稳定？&lt;/span&gt;&lt;br/&gt;&lt;span&gt;　　　　计算机开始设计的时候并不是考虑简单，而是考虑能自动完成任务与结果的可靠性，&lt;/span&gt;&lt;br/&gt;&lt;span&gt;　　　　简单始终是建立再稳定、可靠基础上&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　　　经过尝试10进制，但很难检查电流的状态差异并且很难稳定状态，最稳定的检查是&lt;/span&gt;&lt;br/&gt;&lt;span&gt;　　　　通电和不通电状态，共两种状态那就规定 通电为 1 不通电 为 0，1和0的状态逻&lt;/span&gt;&lt;br/&gt;&lt;span&gt;　　　　辑被称为比特 Bit&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　那么&lt;strong&gt;如何用 0 和 1 表示数字和字符&lt;/strong&gt;呢？&lt;/span&gt;&lt;br/&gt;&lt;span&gt;　　　　首先找出需要表示的字符，英文字符和数字字符才100多个，需要 7 个二进制位就&lt;/span&gt;&lt;br/&gt;&lt;span&gt;　　　　可以全部表示，但为了可扩展性，多出一位表示扩展，这就是ASCII码&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　　　因为一个字符只需要最多8个二进制位表示，所以规定8个字节作为存储单位，所有&lt;/span&gt;&lt;br/&gt;&lt;span&gt;　　　　&lt;strong&gt;8 Bit = 1 Byte&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　　　规定字符用数字表示，数字用二进制表示，也就是 &lt;strong&gt;字符 --&amp;gt; 数字 -- &amp;gt; 二进制&lt;/strong&gt;，&lt;/span&gt;&lt;br/&gt;&lt;span&gt;　　　　那么文本信息就可以通过计算机存储为二进制，计算机上存储的二进制数可以逆转&lt;/span&gt;&lt;br/&gt;&lt;span&gt;　　　　成文本信息&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　　　10 进制到二进制之间的关系转换是固定的，那么字符到数字之间的转换被我们称为&lt;/span&gt;&lt;br/&gt;&lt;span&gt;　　　　字符编码， ASCII码 Unicode UTF-8 都是存储字符与数字之间的映射关系&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;span&gt;弄清楚几个关系&lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;&lt;span&gt;　　1. &lt;strong&gt;字符与数字之间的关系为映射关系，人为规定的标准&lt;/strong&gt;&lt;/span&gt;&lt;br/&gt;&lt;span&gt;　　　   这种映射关系，生活中普遍存在，如&lt;/span&gt;&lt;br/&gt;&lt;span&gt;　　　　a. 身份证信息与身份证号码&lt;/span&gt;&lt;br/&gt;&lt;span&gt;　　　　b. 数据库id与该行信息&lt;/span&gt;&lt;br/&gt;&lt;span&gt;　　　　c. 订单信息与订单编号&lt;/span&gt;&lt;br/&gt;&lt;span&gt;　　　　d. 员工编号与员工&lt;/span&gt;&lt;br/&gt;&lt;span&gt;　　　　e. 字典的键与值&lt;/span&gt;&lt;br/&gt;&lt;span&gt;　　　　f. 内存地址与存储在该地址上的值&lt;/span&gt;&lt;br/&gt;&lt;span&gt;　　　　...&lt;/span&gt;&lt;br/&gt;&lt;span&gt;　　2. 数字到二进制之间的关系，这个如同数学或物理定律一样，固定转换方式，写死的&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　3. &lt;strong&gt;8进制 16 进制都是建立在2进制的基础上&lt;/strong&gt;，和10进制之间没有直接关系，主要为了&lt;/span&gt;&lt;br/&gt;&lt;span&gt;　　　可读性，二进制的两种表示形式&lt;/span&gt;&lt;br/&gt;&lt;span&gt;　　　如二进制 00000000 一个存储单位，八进制000 000 000 每 3 个二进制位转&lt;/span&gt;&lt;br/&gt;&lt;span&gt;　　　换位10进制表示，最小数为 0 最大数为 7，所以取值范围为 0 - 7&lt;/span&gt;&lt;br/&gt;&lt;span&gt;　　　十六进制 0000 0000 每 4个二进制位转换位10进制表示，最小位为0 最大为15，&lt;/span&gt;&lt;br/&gt;&lt;span&gt;　　　所有取值范围为 0 - 15，因为超出10机制表示范围所以用 abcdef表示 10 11&lt;/span&gt;&lt;br/&gt;&lt;span&gt;　　　12 13 14 15&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　  十六进制常用于 内存地址表示 IPv6地址 颜色表 mac地址 二进制数据\x前缀b/B&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　   IP地址(32位 点分十进制) x.x.x.x 每个x都是8个bit位表示的十进制数字&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;　　# 8进制 16进制是建立在二进制的基础之上&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;span&gt;Py进制转换函数&lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;&lt;strong&gt;&lt;span&gt;　　10进制转其他进制&lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;&lt;span&gt;　　　　转2进制 bin 前缀0b&lt;/span&gt;&lt;br/&gt;&lt;span&gt;　　　　转16进制 hex 前缀0x&lt;/span&gt;&lt;br/&gt;&lt;span&gt;　　　　转8进制 oct 前缀0o&lt;/span&gt;&lt;br/&gt;&lt;span&gt;　　　　# 二进制 八进制 十六进制都是通过带前缀的字符串形式&quot;0b/o/x...&quot;&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;39&quot;&gt;
&lt;pre class=&quot;brush:python;gutter:true;&quot;&gt;
# 10 进制转其他进制
number = 9999
print(&quot;10进制转其他进制&quot;.ljust(40, &quot;*&quot;))
# 10 进制转2进制
b_number = bin(number)
print(&quot;二进制:&quot;, b_number)
# 10进制转8进制
o_number = oct(number)
print(&quot;八进制:&quot;, o_number)
# 10进制转16进制
h_number = hex(number)
print(&quot;十六进制:&quot;, h_number)
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span&gt;　　&lt;strong&gt;其他进制转10进制&lt;/strong&gt; int(..., base) base指定进制&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;42&quot;&gt;
&lt;pre class=&quot;brush:python;gutter:true;&quot;&gt;
# 10 进制转其他进制
number = 9999
print(&quot;10进制转其他进制&quot;.ljust(40, &quot;*&quot;))
# 10 进制转2进制
b_number = bin(number)
print(&quot;二进制:&quot;, b_number)
# 10进制转8进制
o_number = oct(number)
print(&quot;八进制:&quot;, o_number)
# 10进制转16进制
h_number = hex(number)
print(&quot;十六进制:&quot;, h_number)

# 其他进制转10进制
# 2进制转10进制
num_b = int(b_number, base=2)
print(num_b)
# 8 进制转10进制
num_o = int(o_number, base=8)
print(num_o)
# 8 进制转16进制
num_h = int(h_number, base=16)
print(num_h)
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span&gt;　　&lt;strong&gt;字符串转二进制字符串&lt;/strong&gt;&lt;/span&gt;&lt;br/&gt;&lt;span&gt;　　　　bytes&lt;/span&gt;&lt;br/&gt;&lt;span&gt;　　　　encode&lt;/span&gt;&lt;br/&gt;&lt;span&gt;　　　　需要指定字符编码，结果前缀为 b/B&quot;...&quot;&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;35&quot;&gt;
&lt;pre class=&quot;brush:python;gutter:true;&quot;&gt;
# 字符串转二进制字符串
song = &quot;你骄傲的飞远，我栖息的夏天&quot;

byte_song = song.encode(encoding=&quot;utf-8&quot;)
print(byte_song)
# 等价于
eq_byte_song = bytes(song, encoding=&quot;utf-8&quot;)
print(eq_byte_song)
print(byte_song == eq_byte_song)
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span&gt;　　&lt;strong&gt;二进制转字符串&lt;/strong&gt;&lt;/span&gt;&lt;br/&gt;&lt;span&gt;　　　　decode&lt;/span&gt;&lt;br/&gt;&lt;span&gt;　　　　str&lt;/span&gt;&lt;br/&gt;&lt;span&gt;　　　　需要指定字符编码&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;37&quot;&gt;
&lt;pre class=&quot;brush:python;gutter:true;&quot;&gt;
# 二进制转字符串
song = &quot;你骄傲的飞远，我栖息的夏天&quot;
# 获得二进制数据
byte_song = song.encode(encoding=&quot;utf-8&quot;)
print(byte_song)

# 二进制字符串转文本字符串
print(&quot;二进制数据转字符串&quot;.rjust(40, &quot;_&quot;))
dec_song = byte_song.decode(encoding=&quot;utf-8&quot;)
print(dec_song)
# 等价于'
str_song = str(byte_song, encoding=&quot;utf-8&quot;)
print(str_song)
print(dec_song == str_song)
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span&gt;　　&lt;strong&gt;算术方法&lt;/strong&gt;&lt;/span&gt;&lt;br/&gt;&lt;span&gt;　　　　10进制转2 8 16进制，辗转除法取余数&lt;/span&gt;&lt;br/&gt;&lt;span&gt;　　　　其他进制转10进制是从右往左加上基数的指定次方然后求和&lt;/span&gt;&lt;br/&gt;&lt;span&gt;　　　　# 转换方式像公式定律，固定&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;span&gt;二进制表示&lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;&lt;span&gt;　　分为有符号和无符号类型，一般是 8 16 32 64 Bit 表示整数或浮点数&lt;/span&gt;&lt;br/&gt;&lt;span&gt;　　有符号最高位表示符号，就是最左边的比特位，0表示正1表示负数 正负下标位0和1&lt;/span&gt;&lt;br/&gt;&lt;span&gt;　　有符号位表示范围，因为要分成两半，一半表示正数一半表示负数，&lt;/span&gt;&lt;br/&gt;&lt;span&gt;　　说白了是去除一位表示符号位 -2**(n-1) - 2**n(n-1) -1, n = 8/16/32/64&lt;/span&gt;&lt;br/&gt;&lt;span&gt;　　无符号位表示 0到2**n -1&lt;/span&gt;&lt;br/&gt;&lt;span&gt;　　# 长度不一样，分为1/2/4/8字节&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;br/&gt;&lt;span&gt;Py字符对应ASCII数字函数&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　ord()&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;span&gt;字符编码&lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;&lt;span&gt;　　&lt;strong&gt;语言文字 ---&amp;gt; 数字 ---&amp;gt; 0 1二进制&lt;/strong&gt;&lt;/span&gt;&lt;br/&gt;&lt;span&gt;　　# 这个映射关系表被称为字符编码&lt;/span&gt;&lt;br/&gt;&lt;span&gt;　　# 字符编码解决的问题是字符与十进制之间映射关系，人为定义的&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　中国 gb2312 -&amp;gt; GBK 中文2字节，英文1个字节&lt;/span&gt;&lt;br/&gt;&lt;span&gt;　　国际 Unicode(2-4个字节) -&amp;gt; UTF-8(1-4个字节)&lt;/span&gt;&lt;br/&gt;&lt;span&gt;　　　　1. 支持全球语言字符&lt;/span&gt;&lt;br/&gt;&lt;span&gt;　　　　2. 包含全球字符编码映射&lt;/span&gt;&lt;br/&gt;&lt;span&gt;　　　　# 全球各国语言可以转成Unicode，Unicode可以转全球各个国家语言&lt;/span&gt;&lt;br/&gt;&lt;span&gt;　　　　3. 全球软/硬件都支持Unicode&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　主流 &lt;strong&gt;UTF-8&lt;/strong&gt;&lt;/span&gt;&lt;br/&gt;&lt;span&gt;　　　　因为Unicode表示一个字符需要至少2个字节，那么原来用ASCII只需要一个字节，&lt;/span&gt;&lt;br/&gt;&lt;span&gt;　　　　现在使用Unicode编码则存储与进行网络传输需要的存储空间直接翻倍，不可接受&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　　　UTF-8为了解决这个问题，于是走上了历史舞台，那好，网络传输和存储使用&lt;/span&gt;&lt;br/&gt;&lt;span&gt;　　　　UTF-8，操作系统支持Unicode，那么高效传输、存储和支持全球语言体系成为可能&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;span&gt;Python中编码&lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;&lt;span&gt;　　首先说说Python中编码到底是何方神圣？&lt;/span&gt;&lt;br/&gt;&lt;span&gt;　　我们看存储代码的文件和代码加载到内存然后被解释器处理的文件&lt;/span&gt;&lt;br/&gt;&lt;span&gt;　　我们敲的代码，其实本质上是文本数据&lt;/span&gt;&lt;br/&gt;&lt;span&gt;　　文本数据要通过某一编码表转换成二进制然后存储到硬盘上&lt;/span&gt;&lt;br/&gt;&lt;span&gt;　　存储在电脑上的二进制数据也需要编码表才能转换成文本数据&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;span&gt;Python中编码是怎么回事？&lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;&lt;span&gt;　　Py3中默认文件编码为UTF-8, 我们通过编辑器编辑文件的时候也会有个默认编码&lt;/span&gt;&lt;br/&gt;&lt;span&gt;　　一般默认为UTF-8，如果定义的文件中文本数据不是以UTF-8编码，则需要在Py文&lt;/span&gt;&lt;br/&gt;&lt;span&gt;　　件的头行告诉Py解释器这个文件是以何种编码。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　解释器读取的并不是我们看到的编辑器里面的文本数据，而是存储在硬盘上的01&lt;/span&gt;&lt;br/&gt;&lt;span&gt;　　一样的二进制数据，解释器尝试用默认UTF-8编码解码读取到硬盘中的二进制数&lt;/span&gt;&lt;br/&gt;&lt;span&gt;　　据，转换成文件数据，如果非默认utf-8则出现乱码，解释器对文本数据解析失败，&lt;/span&gt;&lt;br/&gt;&lt;span&gt;　　则需要在Py源文件开头指定当前文件的编码格式，告诉Py解释器如何去转换该文件&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　Py解释器默认编码是Unicode，解释器会把读取到的二进制数据通过字符编码转&lt;/span&gt;&lt;br/&gt;&lt;span&gt;　　换成文件数据然后再次转换为Unicode编码，只要操作系统支持Unicode，解释器&lt;/span&gt;&lt;br/&gt;&lt;span&gt;　　都能正常执行并输出结果&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　&lt;strong&gt;　解释器&lt;/strong&gt;&lt;/span&gt;&lt;br/&gt;&lt;span&gt;　　　　二进制数据 -&amp;gt; 查字符编码表 -&amp;gt; 文本数据 -&amp;gt; Unicode编码的文本数据&lt;/span&gt;&lt;br/&gt;&lt;span&gt;　　&lt;strong&gt;编辑器&lt;/strong&gt;&lt;/span&gt;&lt;br/&gt;&lt;span&gt;　　　　二进制数据 -&amp;gt; 查字符编码表 -&amp;gt; 对应编码表的文本数据&lt;/span&gt;&lt;br/&gt;&lt;span&gt;　　# 解释器和编辑器都是从文件的二进制数据开始的，通过编码转换成对应的文本&lt;/span&gt;&lt;br/&gt;&lt;span&gt;　　# 数据，不过解释器会会在文件数据的基础上解析文本数据成底层机器指令并执行&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;　　需要弄清楚的是Py源文件编码和Py解释器默认编码不一致&lt;/span&gt;&lt;br/&gt;&lt;span&gt;　　# Py源文件编码默认UTF-8,Py解释器默认编码为Unicode&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;span&gt;那么，产生乱码的解决问题的思路就很好解决了&lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;&lt;span&gt;　　# 乱码 - 字符编码指定错误，存储的二进制转换成文本文件选择的字符集错误&lt;/span&gt;&lt;br/&gt;&lt;span&gt;　　1. C/S 架构的软件，检查 Client 和 Server默认编码是否一致&lt;/span&gt;&lt;br/&gt;&lt;span&gt;　　2. Web后端，数据库默认编码、表的编码和各个语言连接数据库接口的编码是否一致&lt;/span&gt;&lt;br/&gt;&lt;span&gt;　　3. 文件，检查编辑器的默认编码是否和文件初始编码一致，什么编码就存什么编码读&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;span&gt;Python声明源文件字符编码的方式&lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;&lt;span&gt;　　1. # conding:utf-8&lt;/span&gt;&lt;br/&gt;&lt;span&gt;　　2. # -*- conding:utf-8 -*-&lt;/span&gt;&lt;br/&gt;&lt;span&gt;　　# 都是以 # 开头，写在源文件顶行&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;32&quot;&gt;
&lt;pre class=&quot;brush:python;gutter:true;&quot;&gt;
# -*- coding:utf-8 -*-
# coding: utf-8
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;span&gt; &lt;/span&gt;&lt;/p&gt;
</description>
<pubDate>Sat, 03 Oct 2020 13:41:00 +0000</pubDate>
<dc:creator>北门吹雪</dc:creator>
<og:description>二进制 核心思想： 冯诺依曼 + 图灵机 电如何表示状态，才能稳定？ 计算机开始设计的时候并不是考虑简单，而是考虑能自动完成任务与结果的可靠性， 简单始终是建立再稳定、可靠基础上 经过尝试10进制，但</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/2bjiujiu/p/13762909.html</dc:identifier>
</item>
<item>
<title>莫比乌斯反演学习笔记 - Vocanda</title>
<link>http://www.cnblogs.com/Vocanda/p/13765533.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/Vocanda/p/13765533.html</guid>
<description>&lt;h2 id=&quot;前置：整除分块&quot;&gt;前置：整除分块&lt;/h2&gt;
&lt;ul&gt;&lt;li&gt;主要形式就是：&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;\[\sum_{i=1}^{n}\lfloor\frac{n}{i}\rfloor \]&lt;/p&gt;
&lt;p&gt;这个式子正常是 &lt;span class=&quot;math inline&quot;&gt;\(\Theta(n)\)&lt;/span&gt; 的效率，但是我们还可以缩小成 &lt;span class=&quot;math inline&quot;&gt;\(\Theta(\sqrt{n})\)&lt;/span&gt;。&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;对于每一个 &lt;span class=&quot;math inline&quot;&gt;\(\lfloor\frac{n}{i}\rfloor\)&lt;/span&gt; ， 易得&lt;s&gt;（打表）&lt;/s&gt;有许多的 &lt;span class=&quot;math inline&quot;&gt;\(\lfloor\frac{n}{i}\rfloor\)&lt;/span&gt; 是一样的&lt;s&gt;（废话）&lt;/s&gt;。我们就可以根据它们的分布情况进行计算。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;可以发现，对于每个相同值的一块，最后一个数是 &lt;span class=&quot;math inline&quot;&gt;\(\frac{n}{\frac{n}{i}}\)&lt;/span&gt; ，然后就可以 &lt;span class=&quot;math inline&quot;&gt;\(\Theta(\sqrt{n})\)&lt;/span&gt; 处理了。&lt;/p&gt;
&lt;h3 id=&quot;代码&quot;&gt;代码&lt;/h3&gt;
&lt;pre&gt;
&lt;code class=&quot;language-cpp&quot;&gt;for(int l=1,r;l&amp;lt;=n;l=r+1){
        r=n/(n/l);
        ans+=(r-l+1)*(n/l);
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;拓展&quot;&gt;拓展&lt;/h3&gt;
&lt;ul&gt;&lt;li&gt;有时候，可能推出来的式子不一定就是一个很裸的整除分块，可能会与某些积性函数相乘，如： &lt;span class=&quot;math inline&quot;&gt;\(\mu,\phi\)&lt;/span&gt; ...... 这时候，每当我们使用整除分块跳过一个区间的时候，其所对应的函数值也跳过了一个区间。所以此时，就需要乘上那一个区间的函数值，利用前缀和记录即可。&lt;/li&gt;
&lt;/ul&gt;&lt;h2 id=&quot;莫比乌斯函数&quot;&gt;莫比乌斯函数&lt;/h2&gt;
&lt;h3 id=&quot;定义&quot;&gt;定义&lt;/h3&gt;
&lt;p&gt;&lt;span class=&quot;math inline&quot;&gt;\(\mu (d)\)&lt;/span&gt; 为莫比乌斯函数的函数名，是一个由容斥系数所构成的函数。其定义为：&lt;br/&gt;1、当 &lt;span class=&quot;math inline&quot;&gt;\(d = 1\)&lt;/span&gt; 时， &lt;span class=&quot;math inline&quot;&gt;\(\mu (d)=1\)&lt;/span&gt; 。&lt;br/&gt;2、当 &lt;span class=&quot;math inline&quot;&gt;\(d = \prod_{i-1}^k\ p_i\)&lt;/span&gt; ,并且所有的 &lt;span class=&quot;math inline&quot;&gt;\(p_i\)&lt;/span&gt; 为不同的素数的时候， &lt;span class=&quot;math inline&quot;&gt;\(\mu(d)=(-1)^k\)&lt;/span&gt; 。&lt;br/&gt;3、当 &lt;span class=&quot;math inline&quot;&gt;\(d\)&lt;/span&gt; 含有的任一质因子的幂大于 &lt;span class=&quot;math inline&quot;&gt;\(2\)&lt;/span&gt; 次，那么 &lt;span class=&quot;math inline&quot;&gt;\(\mu(d)=0\)&lt;/span&gt; 。&lt;/p&gt;
&lt;h3 id=&quot;性质&quot;&gt;性质&lt;/h3&gt;
&lt;p&gt;1、最常用：对于任意正整数 &lt;span class=&quot;math inline&quot;&gt;\(n\)&lt;/span&gt; ，&lt;span class=&quot;math inline&quot;&gt;\(\sum_{d|n}\mu(d)=[n=1]\)&lt;/span&gt; 。其中 &lt;span class=&quot;math inline&quot;&gt;\([\ ]\)&lt;/span&gt; 代表的是布尔型，即只有 &lt;span class=&quot;math inline&quot;&gt;\(n=1\)&lt;/span&gt; 成立的时候才为 &lt;span class=&quot;math inline&quot;&gt;\(1\)&lt;/span&gt; ，其他情况为 &lt;span class=&quot;math inline&quot;&gt;\(0\)&lt;/span&gt; 。（由 &lt;span class=&quot;math inline&quot;&gt;\(\mu\)&lt;/span&gt; 的容斥系数的性质可证明。PS:我不会。）&lt;/p&gt;
&lt;p&gt;2、对于任意正整数 &lt;span class=&quot;math inline&quot;&gt;\(n\)&lt;/span&gt; ,&lt;/p&gt;
&lt;p&gt;\[\sum_{d|n}\frac{\mu(d)}{d}=\frac{\phi(n)}{n} \]&lt;/p&gt;
&lt;p&gt;具体的证明见博客：&lt;a href=&quot;https://www.cnblogs.com/peng-ym/p/8647856.html&quot;&gt;莫比乌斯反演&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&quot;代码实现&quot;&gt;代码实现&lt;/h3&gt;
&lt;p&gt;任何函数在OI中都是需要用到值的，那么我们就需要一些筛法，其中 &lt;span class=&quot;math inline&quot;&gt;\(xxs\)&lt;/span&gt; （线性筛）是最简单的一种，在线性筛素数的基础上稍做修改即可。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-cpp&quot;&gt;void xxs(){
        mu[1] = 1;
        for(int i = 2;i &amp;lt;= n;++i){
                if(!noprime[i]){
                        prime[++prime[0]] = i;
                        mu[i] = -1;
                }
                for(int j = 1,k;j &amp;lt;= prime[0] &amp;amp;&amp;amp; (k = i * prime[j]) &amp;lt;= n;++j){
                        noprime[k] = 1;
                        if(i % prime[j] == 0)break;
                        else mu[k] = -mu[i];
                }
        }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;莫比乌斯反演&quot;&gt;莫比乌斯反演&lt;/h2&gt;
&lt;p&gt;有了 &lt;span class=&quot;math inline&quot;&gt;\(\mu\)&lt;/span&gt; 函数的基础，我们就可以看莫比乌斯&lt;s&gt;繁衍&lt;/s&gt;反演了。&lt;/p&gt;
&lt;h3 id=&quot;定理&quot;&gt;定理&lt;/h3&gt;
&lt;p&gt;定义 &lt;span class=&quot;math inline&quot;&gt;\(F(n)\)&lt;/span&gt; 和 &lt;span class=&quot;math inline&quot;&gt;\(f(n)\)&lt;/span&gt; 是定义在非负整数集合上的两个函数，并且满足条件：&lt;/p&gt;
&lt;p&gt;\[F(n)=\sum_{d|n}f(d) \]&lt;/p&gt;
&lt;p&gt;那么一定存在：&lt;/p&gt;
&lt;p&gt;\[f(n)=\sum_{d|n}\mu(d)F(\lfloor\frac{n}{d}\rfloor) \]&lt;/p&gt;
&lt;p&gt;此定理即为莫比乌斯定理。&lt;/p&gt;
&lt;h3 id=&quot;证明&quot;&gt;证明&lt;/h3&gt;
&lt;p&gt;通过定义证明：&lt;br/&gt;由 &lt;span class=&quot;math inline&quot;&gt;\(F(n)\)&lt;/span&gt; 和 &lt;span class=&quot;math inline&quot;&gt;\(f(n)\)&lt;/span&gt; 的定义可得：&lt;/p&gt;
&lt;p&gt;\[F(\left \lfloor \frac{n}{d} \right \rfloor) = \sum_{i|\left \lfloor \frac{n}{d} \right \rfloor}\ f(i) \]&lt;/p&gt;
&lt;p&gt;那么&lt;/p&gt;
&lt;p&gt;\[\sum_{d|n}\mu(d)F(\lfloor\frac{n}{d}\rfloor)=\sum_{d|n}\mu(d)\sum_{i|\lfloor\frac{n}{d}\rfloor}f(i) \]&lt;/p&gt;
&lt;p&gt;\[=\sum_{i|n}f(i)\sum_{d|\lfloor\frac{n}{i}\rfloor}\mu(d)=f(n) \]&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;另一个式子：&lt;br/&gt;当 &lt;span class=&quot;math inline&quot;&gt;\(F(n)\)&lt;/span&gt; 和 &lt;span class=&quot;math inline&quot;&gt;\(f(n)\)&lt;/span&gt; 满足：&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;\[F(n)=\sum_{n|d}f(d) \]&lt;/p&gt;
&lt;p&gt;得到：&lt;/p&gt;
&lt;p&gt;\[f(n)=\sum_{n|d}\mu(\frac{d}{n})F(d) \]&lt;/p&gt;
&lt;h2 id=&quot;例题1&quot;&gt;例题1&lt;/h2&gt;
&lt;h3 id=&quot;yy的gcd&quot;&gt;YY的GCD&lt;/h3&gt;
&lt;p&gt;&lt;a href=&quot;https://www.luogu.com.cn/problem/P2257&quot;&gt;题目链接&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;莫比乌斯反演的开始。&lt;/p&gt;
&lt;p&gt;首先记录一个套路：在 &lt;span class=&quot;math inline&quot;&gt;\(gcd\)&lt;/span&gt; 问题中，通常把反演中的 &lt;span class=&quot;math inline&quot;&gt;\(f(d)\)&lt;/span&gt; 设为 &lt;span class=&quot;math inline&quot;&gt;\(gcd(i,j)=d\)&lt;/span&gt;的个数， &lt;span class=&quot;math inline&quot;&gt;\(F(n)\)&lt;/span&gt; 设为 &lt;span class=&quot;math inline&quot;&gt;\(\sum_{base=1}^{d\times base \leqslant n} [gcd(i,j)=d\times base]\)&lt;/span&gt; ，即 &lt;span class=&quot;math inline&quot;&gt;\(gcd(i,j)=d\)&lt;/span&gt; 和 &lt;span class=&quot;math inline&quot;&gt;\(d\)&lt;/span&gt; 的倍数的个数。&lt;/p&gt;
&lt;p&gt;在这个题中，我们不这样定义（因为不好证），这道题要求的是&lt;/p&gt;
&lt;p&gt;\[\sum_{i=1}^{n}\sum_{j=1}^{m}\ gcd(i,j)\in prime \]&lt;/p&gt;
&lt;p&gt;所以朴素算法就是，我们可以枚举每一个质数，进行求和，也就是这样：&lt;/p&gt;
&lt;p&gt;\[\sum_{k\in prime}\sum_{i=1}^{n}\sum_{j=1}^{m}\ [gcd(i,j)=k] \]&lt;/p&gt;
&lt;p&gt;我们直接把 &lt;span class=&quot;math inline&quot;&gt;\(k\)&lt;/span&gt; 在后两个式子中除去，得到：&lt;/p&gt;
&lt;p&gt;\[\sum_{k\in prime}\sum_{i=1}^{\left \lfloor \frac{n}{k}\right \rfloor}\sum_{j=1}^{\left \lfloor \frac{m}{k}\right \rfloor}\ [gcd(i,j)=1] \]&lt;/p&gt;
&lt;p&gt;然后开始&lt;s&gt;繁衍&lt;/s&gt;反演。&lt;br/&gt;由于只有在 &lt;span class=&quot;math inline&quot;&gt;\(gcd(i,j)=1\)&lt;/span&gt; 时才有贡献，那么我们就可以根据第一个莫比乌斯函数的性质（忘了往上翻）把最后一个 &lt;span class=&quot;math inline&quot;&gt;\(gcd(i,j)=1\)&lt;/span&gt; 进行转换，变为：&lt;/p&gt;
&lt;p&gt;\[\sum_{k\in prime}\sum_{i=1}^{\left \lfloor \frac{n}{k}\right \rfloor}\sum_{j=1}^{\left \lfloor \frac{m}{k}\right \rfloor}\sum_{d|gcd(i,j)}\mu(d) \]&lt;/p&gt;
&lt;p&gt;那么在这里， &lt;span class=&quot;math inline&quot;&gt;\(d\)&lt;/span&gt; 一定是 &lt;span class=&quot;math inline&quot;&gt;\(gcd(i,j)\)&lt;/span&gt; 的倍数，所以我们就可以继续化简，在 &lt;span class=&quot;math inline&quot;&gt;\(i\)&lt;/span&gt;，&lt;span class=&quot;math inline&quot;&gt;\(j\)&lt;/span&gt; 的极限值上同时除以一个 &lt;span class=&quot;math inline&quot;&gt;\(d\)&lt;/span&gt; ，直接乘在式子里即可，然后枚举 &lt;span class=&quot;math inline&quot;&gt;\(d\)&lt;/span&gt;。得到：&lt;/p&gt;
&lt;p&gt;\[\sum_{k\in prime}\sum_{d=1}^{\left \lfloor \frac{n}{k} \right \rfloor}\mu(d)\times \left \lfloor \frac{m}{kd} \right \rfloor\times \left \lfloor \frac{n}{kd} \right \rfloor \]&lt;/p&gt;
&lt;p&gt;这样的时间复杂度还是不对的，因为最大的 &lt;span class=&quot;math inline&quot;&gt;\(n,m\)&lt;/span&gt; 是 &lt;span class=&quot;math inline&quot;&gt;\(10^7\)&lt;/span&gt;，所以我们就可以（不得不）继续化简。&lt;br/&gt;设 &lt;span class=&quot;math inline&quot;&gt;\(tmp=kd\)&lt;/span&gt; ，那么原式子就变成了：&lt;/p&gt;
&lt;p&gt;\[\sum_{k\in prime}\sum_{d=1}^{\left \lfloor \frac{n}{k} \right \rfloor}\mu(d)\times \left \lfloor \frac{m}{tmp} \right \rfloor\times \left \lfloor \frac{n}{tmp} \right \rfloor \]&lt;/p&gt;
&lt;p&gt;我们再对这个式子化简，把 &lt;span class=&quot;math inline&quot;&gt;\(tmp\)&lt;/span&gt; 提前枚举，那么我们就得到了最终的式子：&lt;/p&gt;
&lt;p&gt;\[\sum_{tmp=1}^{n}\times \left \lfloor \frac{m}{tmp} \right \rfloor\times \left \lfloor \frac{n}{tmp} \right \rfloor\times (\sum_{k|tmp\ \&amp;amp;\&amp;amp;\ k \in prime}\mu(\frac{tmp}{k})) \]&lt;/p&gt;
&lt;p&gt;最后这个式子我们可以在线性筛的时候用迪利克雷前缀和来搞一个前缀和，然后在下边只需要用整除分块的思想枚举 &lt;span class=&quot;math inline&quot;&gt;\(tmp\)&lt;/span&gt; ，每一块的和就能求出来了。&lt;/p&gt;
&lt;h3 id=&quot;代码-2&quot;&gt;代码&lt;/h3&gt;
&lt;pre&gt;
&lt;code class=&quot;language-cpp&quot;&gt;#include&amp;lt;bits/stdc++.h&amp;gt;
using namespace std;
const int maxn = 1e7+10;
int mu[maxn],noprime[maxn],prime[maxn];
int sum[maxn],f[maxn];
int n;
void xxs(){
        mu[1] = 1;
        noprime[1] = 1;
        for(int i = 2;i &amp;lt;= 10000000;++i){
                if(!noprime[i]){
                        prime[++prime[0]] = i;
                        mu[i] = -1;
                }
                for(int j = 1,k;j &amp;lt;= prime[0] &amp;amp;&amp;amp; (k = i * prime[j]) &amp;lt;= 10000000;++j){
                        noprime[k] = 1;
                        if(i % prime[j] == 0)break;
                        else mu[k] = -mu[i];
                }
        }
        for(int i = 1;i &amp;lt;= prime[0];++i){
                for(int j = 1;j * prime[i] &amp;lt;= 10000000;++j){
                        f[j * prime[i]] += mu[j];
                }
        }
        for(int i = 1;i &amp;lt;= 10000000;++i){
                sum[i] = sum[i-1] + f[i];
        }
}
#define ll long long
int main(){
        xxs();
        int T;
        scanf(&quot;%d&quot;,&amp;amp;T);
        while(T--){
                int n,m;
                scanf(&quot;%d%d&quot;,&amp;amp;n,&amp;amp;m);
                if(n &amp;gt; m)swap(n,m);
                long long ans = 0;
                for(int l = 1,r = 0;l &amp;lt;= n;l = r + 1){
                        r = min(n / (n / l),m / (m / l));
                        ans += (ll)(sum[r] - sum[l-1]) * (ll)(n / l) * (ll)(m / l);
                }
                printf(&quot;%lld\n&quot;,ans);
        }
        return 0;
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;莫比乌斯反演的一些知识就到这里，其考察的一些题都是一些推柿子，所以需要慢慢钻研。筛法以后可能会更新（那得看我会不会退役），持续更新（咕咕咕）。&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;math inline&quot;&gt;\(Never\ Give\ Up\)&lt;/span&gt;&lt;/p&gt;
</description>
<pubDate>Sat, 03 Oct 2020 13:12:00 +0000</pubDate>
<dc:creator>Vocanda</dc:creator>
<og:description>前置：整除分块 主要形式就是： \(\sum_{i=1}^{n}\lfloor\frac{n}{i}\rfloor\) 这个式子正常是 \(\Theta(n)\) 的效率，但是我们还可以缩小成 \(\</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/Vocanda/p/13765533.html</dc:identifier>
</item>
<item>
<title>日志分析平台ELK之日志收集器logstash常用插件配置 - Linux-1874</title>
<link>http://www.cnblogs.com/qiuhom-1874/p/13763026.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/qiuhom-1874/p/13763026.html</guid>
<description>&lt;p&gt;　　前文我们了解了logstash的工作流程以及基本的收集日志相关配置，回顾请参考&lt;a href=&quot;https://www.cnblogs.com/qiuhom-1874/p/13761906.html&quot; target=&quot;_blank&quot;&gt;https://www.cnblogs.com/qiuhom-1874/p/13761906.html&lt;/a&gt;；今天我们来了解下logstash的常用input插件和filter插件的相关配置；&lt;/p&gt;
&lt;p&gt;　　先说filter插件吧，继续上一篇博客的环境，我们配置logstash收集httpd的访问日志；&lt;/p&gt;
&lt;p&gt;　　示例：配置logstash收集日志的时间戳为日志生成时的时间戳&lt;/p&gt;
&lt;p&gt;　　未配置date过滤器规则时，输出的文档信息是&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1503305/202010/1503305-20201002225714474-1328975504.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　提示：未配置date过滤器规则时，生成的文档中的时间戳信息是不一样的；@timestamp是指收集日志时的时间，timestamp是日志生成时的时间；&lt;/p&gt;
&lt;p&gt;　　配置date过滤器规则，让生成日志的时间替换收集日志时的时间&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1503305/202010/1503305-20201002230103081-1964589029.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　提示：以上红框中的配置表示把timestamp字段的时间替换@timestamp字段的时间，时间格式为标准的格林威治时间；&lt;/p&gt;
&lt;p&gt;　　验证：启动logstash，看看输出的日志中的@timestamp字段的时间是否还是收集日志的时间呢？&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1503305/202010/1503305-20201002230729871-1129562719.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　提示：现在收集日志的时间就变成了日志生成时的时间了；只不过一个是格林威治标准时间，一个是东八区时间，两个时间相差8小时；这样配置以后，对于timestamp这个字段就显得多余，我们可以使用remove_field去删除timestamp字段即可；如下&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1503305/202010/1503305-20201002231428526-1180098904.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　示例：配置logstash收集httpd访问日志，基于clientip做地理位置分析&lt;/p&gt;
&lt;p&gt;　　下载GeoLite2-City数据库到本地，这个数据库可以去maxmind官方去下载即可，我这里已经提前下载好了，直接传到服务器上即可；&lt;img src=&quot;https://img2020.cnblogs.com/blog/1503305/202010/1503305-20201002232020611-2057733386.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　提示：以上主要把GeoLite2-City包上传到指定目录，然后解压，把GeoLite2-City.mmdb数据库文件在指定目录做了一个软连接；这样做的原因是日后方便更新数据库；&lt;/p&gt;
&lt;p&gt;　　配置logstash过滤规则，让其能够基于httpd的访问日志中的clientip做地理位置分析&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1503305/202010/1503305-20201002232546911-696044477.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　提示：以上配置表示使用geoip过滤器插件，其中source表示以那个字段的值作为ip地址分析，target表示分析后的结果保存在那个字段上，database表示用那个数据库文件；&lt;/p&gt;
&lt;p&gt;　　验证：启动logstash，看看现在输出的文档是否有geoip字段？里面是否记录了clientip的ip地址信息呢？&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1503305/202010/1503305-20201002233330369-23933725.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　提示：可以看到配置了geoip过滤器插件以后，对应的文档中的geoip字段就把对应的clientip的位置信息分析后，加入到文档中了；这样经过logstash分析以后，我们就可以在kibana中配置区域地图来查看访问我们网站的客户端分布在世界地图的那些位置；&lt;/p&gt;
&lt;p&gt;　　示例：修改字段名称&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1503305/202010/1503305-20201002234151378-38517446.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　提示：mutate这个过滤器插件，主要对字段做操作，支持对字段进行增删查改；比如对字段重命名，如上配置；&lt;/p&gt;
&lt;p&gt;　　验证：启动logstash，看看现在输出的文档中的geoip是否更改为clientipInfo了？&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1503305/202010/1503305-20201002234602346-212193540.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　提示：可以看到原来的geoip字段名称已经修改成clientipInfo了；对于这个插件的用法还有其他操作和配置，可以去参考官方文档中的说明进行配置；&lt;/p&gt;
&lt;p&gt;　　示例：将logstash收集的数据日志数据存入redis中&lt;/p&gt;
&lt;p&gt;　　准备redis服务器，然后配置redis登录认证&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;35&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
[root@node04 ~]# yum install redis -y
Loaded plugins: fastestmirror
base                                                                                          | 3.6 kB  00:00:00     
epel                                                                                          | 4.7 kB  00:00:00     
extras                                                                                        | 2.9 kB  00:00:00     
updates                                                                                       | 2.9 kB  00:00:00     
(1/2): epel/x86_64/updateinfo                                                                 | 1.0 MB  00:00:00     
(2/2): epel/x86_64/primary_db                                                                 | 6.9 MB  00:00:01     
Loading mirror speeds from cached hostfile
 * base: mirrors.aliyun.com
 * extras: mirrors.aliyun.com
 * updates: mirrors.aliyun.com
Resolving Dependencies
--&amp;gt; Running transaction check
---&amp;gt; Package redis.x86_64 0:3.2.12-2.el7 will be installed
--&amp;gt; Processing Dependency: libjemalloc.so.1()(64bit) for package: redis-3.2.12-2.el7.x86_64
--&amp;gt; Running transaction check
---&amp;gt; Package jemalloc.x86_64 0:3.6.0-1.el7 will be installed
--&amp;gt; Finished Dependency Resolution

Dependencies Resolved

=====================================================================================================================
 Package                     Arch                      Version                         Repository               Size
=====================================================================================================================
Installing:
 redis                       x86_64                    3.2.12-2.el7                    epel                    544 k
Installing for dependencies:
 jemalloc                    x86_64                    3.6.0-1.el7                     epel                    105 k

Transaction Summary
=====================================================================================================================
Install  1 Package (+1 Dependent package)

Total download size: 648 k
Installed size: 1.7 M
Downloading packages:
(1/2): jemalloc-3.6.0-1.el7.x86_64.rpm                                                        | 105 kB  00:00:00     
(2/2): redis-3.2.12-2.el7.x86_64.rpm                                                          | 544 kB  00:00:00     
---------------------------------------------------------------------------------------------------------------------
Total                                                                                1.3 MB/s | 648 kB  00:00:00     
Running transaction check
Running transaction test
Transaction test succeeded
Running transaction
  Installing : jemalloc-3.6.0-1.el7.x86_64                                                                       1/2 
  Installing : redis-3.2.12-2.el7.x86_64                                                                         2/2 
  Verifying  : redis-3.2.12-2.el7.x86_64                                                                         1/2 
  Verifying  : jemalloc-3.6.0-1.el7.x86_64                                                                       2/2 

Installed:
  redis.x86_64 0:3.2.12-2.el7                                                                                        

Dependency Installed:
  jemalloc.x86_64 0:3.6.0-1.el7                                                                                      

Complete!
[root@node04 ~]# 
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　配置redis监听在本机所有地址的6379端口，并给redis设置认证口令&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1503305/202010/1503305-20201003174156791-608123698.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　启动redis&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1503305/202010/1503305-20201003174252396-2031532027.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　提示：可以看到redis使用我们设置的密码是可以正常登录到redis服务器，到此redis就准备好了；&lt;/p&gt;
&lt;p&gt;　　配置logstash将收集的日志输出到redis的5号库中&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1503305/202010/1503305-20201003180126158-391942058.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　提示：将logstash收集的日志输出到redis，需要用到输出插件redis，其中我们必须指定redis的主机地址，端口，密码，数据库，以及key和data_type；data_type是指定存放到redis是一那种数据结构存储，list表示存储为列表；我们知道列表有一个属性就是从列表取出数据以后，列表里对应的数据就会消失，这样一来当有多个logstash在redis中取数据时不会取到重复数据；&lt;/p&gt;
&lt;p&gt;　　验证配置文件语法&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1503305/202010/1503305-20201003180214826-869767514.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　启动logstash，然后去redis中验证，看看5号库中是否有我们定义key生成，对应key中是否有日志数据？&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1503305/202010/1503305-20201003180439790-799087436.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　去redis上查看5号库的情况&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1503305/202010/1503305-20201003180634522-1776194368.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　提示：在redis的5号库中可以看到logstash上配置的key的名称，对应key里有数据；&lt;/p&gt;
&lt;p&gt;　　示例：配置logstash从redis中读数据&lt;/p&gt;
&lt;p&gt;　　redis环境还是上面的环境，我们重新开一个服务器，把logstash安装上，logstash的安装请参考上一篇博客&lt;a href=&quot;https://www.cnblogs.com/qiuhom-1874/p/13761906.html&quot; target=&quot;_blank&quot;&gt;https://www.cnblogs.com/qiuhom-1874/p/13761906.html&lt;/a&gt;；&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1503305/202010/1503305-20201003181648725-420818541.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　提示：以上配置我们需要在input里配置，用redis输入插件，并明确指定redis的主机，端口，密码，数据库，key,以及数据类型；上面在node05上配置logstash将从redis的5号库采集数据，然后将数据输出到/root/目录下的test.log中；&lt;/p&gt;
&lt;p&gt;　　验证配置文件语法&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1503305/202010/1503305-20201003182006731-761537477.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　启动logstash,然后去node05上看对应目录下的文件是否有数据产生？redis对应库里的数据是否有减少？&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1503305/202010/1503305-20201003182415343-775508895.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　提示：可以看到启动logstash,它启动了一个线程去redis中读数据，然后有启动了一个线程把数据写到/root/test.log中；&lt;/p&gt;
&lt;p&gt;　　验证：在node05上查看/root目录下是否有test.log生成？对应文件中是否有内容？&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1503305/202010/1503305-20201003182623118-1331025408.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　提示：可以看到node05的/root目录下有test.log生成，并且里面也有数据，数据也是从redis里拿的日志数据；&lt;/p&gt;
&lt;p&gt;　　验证：到node04上的redis中查看对应库中的数据是否在减少？&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1503305/202010/1503305-20201003182828388-1701739339.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　提示：在redis的5号库可以看到logstash在取数据，对应列表的数据在依次减少，最后当logstash把对应列表数据取完以后，对应的列表也就随之删除；&lt;/p&gt;
&lt;p&gt;　　示例：配置logstash收集haproxy发送给rsyslog的日志&lt;/p&gt;
&lt;p&gt;　　安装haproxy&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;35&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
[root@node03 ~]# yum install haproxy
Loaded plugins: fastestmirror
base                                                                                          | 3.6 kB  00:00:00     
epel                                                                                          | 4.7 kB  00:00:00     
extras                                                                                        | 2.9 kB  00:00:00     
updates                                                                                       | 2.9 kB  00:00:00     
Loading mirror speeds from cached hostfile
 * base: mirrors.aliyun.com
 * extras: mirrors.aliyun.com
 * updates: mirrors.aliyun.com
Resolving Dependencies
--&amp;gt; Running transaction check
---&amp;gt; Package haproxy.x86_64 0:1.5.18-9.el7 will be installed
--&amp;gt; Finished Dependency Resolution

Dependencies Resolved

=====================================================================================================================
 Package                    Arch                      Version                          Repository               Size
=====================================================================================================================
Installing:
 haproxy                    x86_64                    1.5.18-9.el7                     base                    834 k

Transaction Summary
=====================================================================================================================
Install  1 Package

Total download size: 834 k
Installed size: 2.6 M
Is this ok [y/d/N]: y
Downloading packages:
haproxy-1.5.18-9.el7.x86_64.rpm                                                               | 834 kB  00:00:00     
Running transaction check
Running transaction test
Transaction test succeeded
Running transaction
  Installing : haproxy-1.5.18-9.el7.x86_64                                                                       1/1 
  Verifying  : haproxy-1.5.18-9.el7.x86_64                                                                       1/1 

Installed:
  haproxy.x86_64 0:1.5.18-9.el7                                                                                      

Complete!
[root@node03 ~]# 
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　配置haproxy将日志发送给rsyslog&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1503305/202010/1503305-20201003184849778-1039524797.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　配置rsyslog把local2的日志发送给node05的517端口（这个端口是一个任意端口，只要在node05上不冲突就好）&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1503305/202010/1503305-20201003191827034-2018670333.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　重启rsylog和haproxy&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1503305/202010/1503305-20201003191937535-1284647096.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　配置node05上的logstash，使用输入插件rsyslog监听517端口&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1503305/202010/1503305-20201003185820721-313179620.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　验证配置文件语法&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1503305/202010/1503305-20201003192159633-2089834821.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　启动logstash&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1503305/202010/1503305-20201003192318704-1436031505.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　提示：可以看到logstash启动了两个线程监听了udp的517端口和tcp517端口&lt;/p&gt;
&lt;p&gt;　　访问haproxy&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1503305/202010/1503305-20201003192342757-394279881.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　看看对应的标准输出中是否会打印haproxy的日志呢？&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1503305/202010/1503305-20201003192508207-897212037.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　提示：可以看到在node05的标准输出上能够看到访问haproxy的日志打印；&lt;/p&gt;
&lt;p&gt;　　示例：配置logstash收集tcp某个端口的数据&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1503305/202010/1503305-20201003193315018-491151578.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　验证配置文件语法，没有问题就直接启动logstash&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1503305/202010/1503305-20201003193510043-233944717.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　验证：在其他主机上利用nc向node05的52113发送数据，看看node05上是否会打印我们发送到信息内容？&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1503305/202010/1503305-20201003193818037-2086639431.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　提示：如果没有nc命令，直接使用yum install nc 即可；&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1503305/202010/1503305-20201003193906619-132376691.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　提示：在node05上是能够看到从node01发送过来的消息；&lt;/p&gt;
&lt;p&gt;　　好了，以上是logstash的常用插件的配置，当然还有很多很多，用到那个不会可以去官方文档查找相关插件文档说明进行配置即可；官方文档&lt;a href=&quot;https://www.elastic.co/guide/en/logstash-versioned-plugins/current/index.html&quot; target=&quot;_blank&quot;&gt;https://www.elastic.co/guide/en/logstash-versioned-plugins/current/index.html&lt;/a&gt;；&lt;/p&gt;
</description>
<pubDate>Sat, 03 Oct 2020 11:54:00 +0000</pubDate>
<dc:creator>Linux-1874</dc:creator>
<og:description>前文我们了解了logstash的工作流程以及基本的收集日志相关配置，回顾请参考https://www.cnblogs.com/qiuhom-1874/p/13761906.html；今天我们来了解下l</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/qiuhom-1874/p/13763026.html</dc:identifier>
</item>
</channel>
</rss>