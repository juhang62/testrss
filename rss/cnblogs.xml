<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="css/feed.xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/" xmlns:og="http://ogp.me/ns#">
<channel>
<atom:link rel="self" href="http://192.168.1.4/fivefilters/makefulltextfeed.php?url=feed.cnblogs.com%2Fblog%2Fsitehome%2Frss&amp;max=10&amp;links=preserve&amp;exc=" />
<atom:link rel="alternate" title="Source URL" href="http://feed.cnblogs.com/blog/sitehome/rss" />
<atom:link rel="related" title="Subscribe to feed" href="http://www.subtome.com/#/subscribe?feeds=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed.cnblogs.com%252Fblog%252Fsitehome%252Frss%26max%3D10%26links%3Dpreserve%26exc%3D&amp;back=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed.cnblogs.com%252Fblog%252Fsitehome%252Frss%26max%3D10%26links%3Dpreserve%26exc%3D" />
<title>博客园_首页</title>
<link></link>
<description>代码改变世界</description>
<item>
<title>一文读懂MySQL的索引结构及查询优化 - 行无际</title>
<link>http://www.cnblogs.com/itwild/p/13703259.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/itwild/p/13703259.html</guid>
<description>&lt;p&gt;回顾前文: &lt;a href=&quot;https://www.cnblogs.com/itwild/p/13424113.html&quot;&gt;一文学会MySQL的explain工具&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;(同时再次强调，这几篇关于MySQL的探究都是基于&lt;code&gt;5.7&lt;/code&gt;版本，相关总结与结论&lt;code&gt;不一定适用&lt;/code&gt;于其他版本)&lt;/p&gt;
&lt;p&gt;MySQL官方文档中(&lt;code&gt;https://dev.mysql.com/doc/refman/5.7/en/optimization-indexes.html&lt;/code&gt;)有这样一段描述：&lt;/p&gt;
&lt;blockquote readability=&quot;10&quot;&gt;
&lt;p&gt;The best way to improve the performance of SELECT operations is to create indexes on one or more of the columns that are tested in the query. But unnecessary indexes waste space and waste time for MySQL to determine which indexes to use. Indexes also add to the cost of inserts, updates, and deletes because each index must be updated. You must find the right balance to achieve fast queries using the optimal set of indexes.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;就是说提高查询性能最直接有效的方法就是建立索引，但是不必要的索引会浪费空间，同时也增加了额外的时间成本去判断应该走哪个索引，此外，索引还会增加插入、更新、删除数据的成本，因为做这些操作的同时还要去维护(更新)索引树。因此，应该学会使用最佳索引集来优化查询。&lt;/p&gt;
&lt;h2 id=&quot;索引结构&quot;&gt;索引结构&lt;/h2&gt;
&lt;p&gt;参考：&lt;/p&gt;
&lt;ol readability=&quot;2.5&quot;&gt;&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;《MySQL索引背后的数据结构及算法原理》&lt;code&gt;http://blog.codinglabs.org/articles/theory-of-mysql-index.html&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;《Mysql BTree和B+Tree详解》&lt;code&gt;https://www.cnblogs.com/Transkai/p/11595405.html&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;《为什么MySQL使用B+树》&lt;code&gt;https://draveness.me/whys-the-design-mysql-b-plus-tree/&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;《浅入浅出MySQL和InnoDB》&lt;code&gt;https://draveness.me/mysql-innodb/&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;《漫画：什么是B树？》&lt;code&gt;https://mp.weixin.qq.com/s/rDCEFzoKHIjyHfI_bsz5Rw&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;&lt;h3 id=&quot;什么是索引&quot;&gt;什么是索引&lt;/h3&gt;
&lt;p&gt;在MySQL中，索引(&lt;code&gt;Index&lt;/code&gt;)是帮助高效获取数据的数据结构。这种数据结构MySQL中最常用的就是B+树(&lt;code&gt;B+Tree&lt;/code&gt;)。&lt;/p&gt;
&lt;blockquote readability=&quot;7&quot;&gt;
&lt;p&gt;Indexes are used to find rows with specific column values quickly. Without an index, MySQL must begin with the first row and then read through the entire table to find the relevant rows.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;就好比给你一本书和一篇文章标题，如果没有目录，让你找此标题对应的文章，可能需要从第一页翻到最后一页；如果有目录大纲，你可能只需要在目录页寻找此标题，然后迅速定位文章。&lt;/p&gt;
&lt;p&gt;这里我们可以把&lt;code&gt;书(book)&lt;/code&gt;看成是MySQL中的&lt;code&gt;table&lt;/code&gt;，把&lt;code&gt;文章(article)&lt;/code&gt;看成是&lt;code&gt;table&lt;/code&gt;中的一行记录，即&lt;code&gt;row&lt;/code&gt;，&lt;code&gt;文章标题(title)&lt;/code&gt;看成&lt;code&gt;row&lt;/code&gt;中的一列&lt;code&gt;column&lt;/code&gt;，&lt;code&gt;目录&lt;/code&gt;自然就是对&lt;code&gt;title&lt;/code&gt;列建立的索引&lt;code&gt;index&lt;/code&gt;了，这样&lt;code&gt;根据文章标题从书中检索文章&lt;/code&gt;就对应sql语句&lt;code&gt;select * from book where title = ?&lt;/code&gt;，相应的，书中每增加一篇文章(即&lt;code&gt;insert into book (title, ...) values ('华山论剑', ...)&lt;/code&gt;)，都需要维护一下&lt;code&gt;目录&lt;/code&gt;，这样才能从目录中找到新增的文章&lt;code&gt;华山论剑&lt;/code&gt;，这一操作对应的是MySQL中每插入(&lt;code&gt;insert&lt;/code&gt;)一条记录需要维护&lt;code&gt;title&lt;/code&gt;列的索引树(&lt;code&gt;B+Tree&lt;/code&gt;)。&lt;/p&gt;
&lt;h3 id=&quot;为什么使用btree&quot;&gt;为什么使用B+Tree&lt;/h3&gt;
&lt;p&gt;首先需要澄清的一点是，MySQL跟B+树没有直接的关系，真正与B+树有关系的是MySQL的默认存储引擎&lt;code&gt;InnoDB&lt;/code&gt;，MySQL中存储引擎的主要作用是&lt;code&gt;负责数据的存储和提取&lt;/code&gt;，除了&lt;code&gt;InnoDB&lt;/code&gt;之外，MySQL中也支持比如&lt;code&gt;MyISAM&lt;/code&gt;等其他存储引擎(详情见&lt;code&gt;https://dev.mysql.com/doc/refman/5.7/en/storage-engine-setting.html&lt;/code&gt;)作为表的底层存储引擎。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-sh&quot;&gt;mysql&amp;gt; show engines;
+--------------------+---------+----------------------------------------------------------------+--------------+------+------------+
| Engine             | Support | Comment                                                        | Transactions | XA   | Savepoints |
+--------------------+---------+----------------------------------------------------------------+--------------+------+------------+
| MRG_MYISAM         | YES     | Collection of identical MyISAM tables                          | NO           | NO   | NO         |
| CSV                | YES     | CSV storage engine                                             | NO           | NO   | NO         |
| PERFORMANCE_SCHEMA | YES     | Performance Schema                                             | NO           | NO   | NO         |
| BLACKHOLE          | YES     | /dev/null storage engine (anything you write to it disappears) | NO           | NO   | NO         |
| InnoDB             | DEFAULT | Supports transactions, row-level locking, and foreign keys     | YES          | YES  | YES        |
| MyISAM             | YES     | MyISAM storage engine                                          | NO           | NO   | NO         |
| ARCHIVE            | YES     | Archive storage engine                                         | NO           | NO   | NO         |
| MEMORY             | YES     | Hash based, stored in memory, useful for temporary tables      | NO           | NO   | NO         |
| FEDERATED          | NO      | Federated MySQL storage engine                                 | NULL         | NULL | NULL       |
+--------------------+---------+----------------------------------------------------------------+--------------+------+------------+
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;提到索引，我们可能会立马想到下面几种数据结构来实现。&lt;/p&gt;
&lt;p&gt;(1) 哈希表&lt;br/&gt;哈希虽然能够提供&lt;code&gt;O(1)&lt;/code&gt;的单数据行的查询性能，但是对于&lt;code&gt;范围查询&lt;/code&gt;和&lt;code&gt;排序&lt;/code&gt;却无法很好支持，需全表扫描。&lt;/p&gt;
&lt;p&gt;(2) 红黑树&lt;br/&gt;红黑树(&lt;code&gt;Red Black Tree&lt;/code&gt;)是一种自平衡二叉查找树，在进行插入和删除操作时通过特定操作保持二叉查找树的平衡，从而获得较高的查找性能。&lt;/p&gt;
&lt;p&gt;一般来说，索引本身也很大，往往不可能全部存储在内存中，因此索引往往以索引文件的形式存储的磁盘上。这样的话，索引查找过程中就要产生磁盘I/O消耗，相对于内存存取，I/O存取的消耗远远高于内存，所以评价一个数据结构作为索引的优劣最重要的指标就是查找过程中磁盘I/O次数。换句话说，&lt;code&gt;索引的结构组织要尽量减少查找过程中磁盘I/O的次数。&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;在这里，磁盘I/O的次数取决于树的高度，所以，在数据量较大时，&lt;code&gt;红黑树会因树的高度较大而造成磁盘IO较多&lt;/code&gt;，从而影响查询效率。&lt;/p&gt;
&lt;p&gt;(3) B-Tree&lt;br/&gt;B树中的B代表平衡(&lt;code&gt;Balance&lt;/code&gt;)，而不是二叉(&lt;code&gt;Binary&lt;/code&gt;)，B树是从平衡二叉树演化而来的。&lt;/p&gt;
&lt;p&gt;为了降低树的高度(也就是减少磁盘I/O次数)，把原来&lt;code&gt;瘦高&lt;/code&gt;的树结构变得&lt;code&gt;矮胖&lt;/code&gt;，B树会在&lt;code&gt;每个节点存储多个元素&lt;/code&gt;(红黑树每个节点只会存储一个元素)，并且节点中的元素从左到右递增排列。如下图所示：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1546632/202008/1546632-20200830195348368-1304078258.png&quot; alt=&quot;B-Tree结构图&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;B-Tree&lt;/code&gt;在查询的时候比较次数其实不比二叉查找树少，但在内存中的大小比较、二分查找的耗时相比磁盘IO耗时几乎可以忽略。 &lt;code&gt;B-Tree大大降低了树的高度&lt;/code&gt;，所以也就极大地提升了查找性能。&lt;/p&gt;
&lt;p&gt;(4) B+Tree&lt;br/&gt;&lt;code&gt;B+Tree&lt;/code&gt;是在&lt;code&gt;B-Tree&lt;/code&gt;基础上进一步优化，使其更适合实现存储索引结构。InnoDB存储引擎就是用&lt;code&gt;B+Tree&lt;/code&gt;实现其索引结构。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;B-Tree&lt;/code&gt;结构图中可以看到每个节点中不仅包含数据的&lt;code&gt;key&lt;/code&gt;值，还有&lt;code&gt;data&lt;/code&gt;值。而每一个节点的存储空间是有限的，如果&lt;code&gt;data&lt;/code&gt;值较大时将会导致每个节点能存储的&lt;code&gt;key&lt;/code&gt;的数量很小，这样会导致B-Tree的高度变大，增加了查询时的磁盘I/O次数，进而影响查询性能。在&lt;code&gt;B+Tree&lt;/code&gt;中，所有&lt;code&gt;data&lt;/code&gt;值都是按照键值大小顺序存放在同一层的叶子节点上，而&lt;code&gt;非叶子节点上只存储key值信息&lt;/code&gt;，这样可以增大每个非叶子节点存储的&lt;code&gt;key&lt;/code&gt;值数量，降低B+Tree的高度，提高效率。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1546632/202008/1546632-20200830201413134-394816073.png&quot; alt=&quot;B+Tree结构图&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;这里补充一点相关知识&lt;/strong&gt; 在计算机中，磁盘往往不是严格按需读取，而是每次都会预读，即使只需要一个字节，磁盘也会从这个位置开始，顺序向后读取一定长度的数据放入内存。这样做的理论依据是计算机科学中著名的&lt;code&gt;局部性原理&lt;/code&gt;：&lt;/p&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;当一个数据被用到时，其附近的数据也通常会马上被使用。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;由于磁盘顺序读取的效率很高（不需要寻道时间，只需很少的旋转时间），因此对于具有局部性的程序来说，预读可以提高I/O效率。预读的长度一般为页(&lt;code&gt;page&lt;/code&gt;)的整数倍。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;页&lt;/code&gt;是计算机管理存储器的逻辑块，硬件及操作系统往往将主存和磁盘存储区分割为连续的大小相等的块，每个存储块称为一页(许多操作系统的页默认大小为&lt;code&gt;4KB&lt;/code&gt;)，主存和磁盘以页为单位交换数据。当程序要读取的数据不在主存中时，会触发一个缺页异常，此时操作系统会向磁盘发出读盘信号，磁盘会找到数据的起始位置并向后连续读取一页或几页载入内存中，然后异常返回，程序继续运行。(如下命令可以查看操作系统的默认页大小)&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-sh&quot;&gt;$ getconf PAGE_SIZE
4096
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;数据库系统的设计者巧妙利用了磁盘预读原理，将一个节点的大小设为操作系统的页大小的整数倍，这样每个节点只需要一次I/O就可以完全载入。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;InnoDB&lt;/code&gt;存储引擎中也有页(&lt;code&gt;Page&lt;/code&gt;)的概念，页是其磁盘管理的最小单位。InnoDB存储引擎中默认每个页的大小为16KB。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-sh&quot;&gt;mysql&amp;gt; show variables like 'innodb_page_size';
+------------------+-------+
| Variable_name    | Value |
+------------------+-------+
| innodb_page_size | 16384 |
+------------------+-------+
1 row in set (0.01 sec)
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;一般表的主键类型为&lt;code&gt;INT&lt;/code&gt;（占4个字节）或&lt;code&gt;BIGINT&lt;/code&gt;（占8个字节），指针类型也一般为4或8个字节，也就是说一个页（B+Tree中的一个节点）中大概存储&lt;code&gt;16KB/(8B+8B)=1K&lt;/code&gt;个键值（因为是估值，为方便计算，这里的K取值为&lt;code&gt;10^3&lt;/code&gt;）。也就是说一个深度为3的B+Tree索引可以维护&lt;code&gt;10^3 * 10^3 * 10^3 = 10亿&lt;/code&gt;条记录。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;B+Tree&lt;/code&gt;的高度一般都在2到4层。mysql的InnoDB存储引擎在设计时是将根节点常驻内存的，也就是说查找某一键值的行记录时最多只需要1到3次磁盘I/O操作。&lt;/p&gt;
&lt;p&gt;随机I/O对于MySQL的查询性能影响会非常大，而顺序读取磁盘中的数据会很快，由此我们也应该尽量减少随机I/O的次数，这样才能提高性能。在&lt;code&gt;B-Tree&lt;/code&gt;中由于所有的节点都可能包含目标数据，我们总是要从根节点向下遍历子树查找满足条件的数据行，这会带来大量的随机I/O，而&lt;code&gt;B+Tree&lt;/code&gt;所有的数据行都存储在叶子节点中，而这些叶子节点通过&lt;code&gt;双向链表&lt;/code&gt;依次按顺序连接，当我们在B+树遍历数据(比如说&lt;code&gt;范围查询&lt;/code&gt;)时可以直接在多个叶子节点之间进行跳转，保证&lt;code&gt;顺序&lt;/code&gt;、&lt;code&gt;倒序&lt;/code&gt;遍历的性能。&lt;/p&gt;
&lt;p&gt;另外，对以上提到的数据结构不熟悉的朋友，这里推荐一个在线数据结构可视化演示工具，有助于快速理解这些数据结构的机制：&lt;code&gt;https://www.cs.usfca.edu/~galles/visualization/Algorithms.html&lt;/code&gt;&lt;/p&gt;
&lt;h3 id=&quot;主键索引&quot;&gt;主键索引&lt;/h3&gt;
&lt;p&gt;上面也有提及，在MySQL中，索引属于存储引擎级别的概念。不同存储引擎对索引的实现方式是不同的，这里主要看下&lt;code&gt;MyISAM&lt;/code&gt;和&lt;code&gt;InnoDB&lt;/code&gt;两种存储引擎的索引实现方式。&lt;/p&gt;
&lt;h4 id=&quot;myisam索引实现&quot;&gt;MyISAM索引实现&lt;/h4&gt;
&lt;p&gt;&lt;code&gt;MyISAM&lt;/code&gt;引擎使用&lt;code&gt;B+Tree&lt;/code&gt;作为索引结构时叶子节点的&lt;code&gt;data&lt;/code&gt;域存放的是数据记录的地址。如下图所示：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1546632/202009/1546632-20200919221036646-2109444544.png&quot; alt=&quot;MyISAM主键索引原理图&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;由上图可以看出：MyISAM索引文件和数据文件是分离的，索引文件仅保存数据记录的地址，因此MyISAM的索引方式也叫做&lt;code&gt;非聚集&lt;/code&gt;的，之所以这么称呼是为了与InnoDB的&lt;code&gt;聚集索引&lt;/code&gt;区分。&lt;/p&gt;
&lt;h4 id=&quot;innodb索引实现&quot;&gt;InnoDB索引实现&lt;/h4&gt;
&lt;p&gt;&lt;code&gt;InnoDB&lt;/code&gt;的&lt;code&gt;主键索引&lt;/code&gt;也使用&lt;code&gt;B+Tree&lt;/code&gt;作为索引结构时的实现方式却与MyISAM截然不同。&lt;code&gt;InnoDB的数据文件本身就是索引文件&lt;/code&gt;。在InnoDB中，表数据文件本身就是按&lt;code&gt;B+Tree&lt;/code&gt;组织的一个索引结构，这棵树的叶子节点&lt;code&gt;data&lt;/code&gt;域保存了完整的数据记录，这个索引的&lt;code&gt;key&lt;/code&gt;是数据表的主键，因此InnoDB表数据文件本身就是主索引。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1546632/202009/1546632-20200919222451055-995072120.png&quot; alt=&quot;InnoDB主键索引原理图&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;InnoDB&lt;/code&gt;存储引擎中的主键索引(&lt;code&gt;primary key&lt;/code&gt;)又叫做聚集索引(&lt;code&gt;clustered index&lt;/code&gt;)。因为InnoDB的数据文件本身要按主键聚集，所以InnoDB要求表必须有主键（MyISAM可以没有），如果没有显式指定，则MySQL系统会自动选择一个可以唯一标识数据记录的列作为主键，如果不存在这种列，则MySQL自动为InnoDB表生成一个隐含字段作为主键，这个字段长度为6个字节，类型为长整形。(详情见官方文档：&lt;code&gt;https://dev.mysql.com/doc/refman/5.7/en/innodb-index-types.html&lt;/code&gt;)&lt;/p&gt;
&lt;p&gt;聚集索引这种实现方式使得按主键搜索十分高效，直接能查出整行数据。&lt;/p&gt;
&lt;p&gt;在InnoDB中，用非单调递增的字段作为主键不是个好主意，因为InnoDB数据文件本身是一棵&lt;code&gt;B+Tree&lt;/code&gt;，非单增的主键会造成在插入新记录时数据文件为了&lt;code&gt;维持B+Tree的特性&lt;/code&gt;而频繁的分裂调整，十分低效，因而使用&lt;code&gt;递增&lt;/code&gt;字段作为主键则是一个很好的选择。&lt;/p&gt;
&lt;h3 id=&quot;非主键索引&quot;&gt;非主键索引&lt;/h3&gt;
&lt;h4 id=&quot;myisam索引实现-2&quot;&gt;MyISAM索引实现&lt;/h4&gt;
&lt;p&gt;MyISAM中，主键索引和非主键索引（&lt;code&gt;Secondary key&lt;/code&gt;，也有人叫做&lt;code&gt;辅助索引&lt;/code&gt;）在结构上没有任何区别，只是主键索引要求key是唯一的，而辅助索引的key可以重复。这里不再多加叙述。&lt;/p&gt;
&lt;h4 id=&quot;innodb索引实现-2&quot;&gt;InnoDB索引实现&lt;/h4&gt;
&lt;p&gt;InnoDB的非主键索引&lt;code&gt;data&lt;/code&gt;域存储相应记录&lt;code&gt;主键的值&lt;/code&gt;。换句话说，InnoDB的所有非主键索引都引用主键的值作为data域。如下图所示：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1546632/202009/1546632-20200919225813936-1490118290.png&quot; alt=&quot;InnoDB非主键索引原理图&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;由上图可知：使用非主键索引搜索时需要检索两遍索引，首先检索非主键索引获得主键(&lt;code&gt;primary key&lt;/code&gt;)，然后用主键到&lt;code&gt;主键索引树&lt;/code&gt;中检索获得完整记录。&lt;/p&gt;
&lt;p&gt;那么为什么非主键索引结构叶子节点存储的是主键值，而不像主键索引那样直接存储完整的一行数据，这样就能避免回表二次检索？显然，这样做一方面节省了大量的存储空间，另一方面多份冗余数据，更新数据的效率肯定低下，另外保证数据的一致性是个麻烦事。&lt;/p&gt;
&lt;p&gt;到了这里，也很容易明白为什么&lt;code&gt;不建议使用过长的字段作为主键&lt;/code&gt;，因为所有的非主键索引都引用主键值，过长的主键值会让非主键索引变得过大。&lt;/p&gt;
&lt;h3 id=&quot;联合索引&quot;&gt;联合索引&lt;/h3&gt;
&lt;p&gt;官方文档：&lt;code&gt;https://dev.mysql.com/doc/refman/5.7/en/multiple-column-indexes.html&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;比如&lt;code&gt;INDEX idx_book_id_hero_name (book_id, hero_name) USING BTREE&lt;/code&gt;，即对&lt;code&gt;book_id, hero_name&lt;/code&gt;两列建立了一个联合索引。&lt;/p&gt;
&lt;blockquote readability=&quot;7&quot;&gt;
&lt;p&gt;A multiple-column index can be considered a sorted array, the rows of which contain values that are created by concatenating the values of the indexed columns.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;联合索引是多列按照次序一列一列比较大小，拿&lt;code&gt;idx_book_id_hero_name&lt;/code&gt;这个联合索引来说，先比较&lt;code&gt;book_id&lt;/code&gt;，book_id小的排在左边，book_id大的排在右边，book_id相同时再比较&lt;code&gt;hero_name&lt;/code&gt;。如下图所示：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1546632/202009/1546632-20200920111026527-1672463564.png&quot; alt=&quot;InnoDB联合索引原理图&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;了解了联合索引的结构，就能引入&lt;code&gt;最左前缀法则&lt;/code&gt;：&lt;/p&gt;
&lt;blockquote readability=&quot;17&quot;&gt;
&lt;p&gt;If the table has a multiple-column index, any leftmost prefix of the index can be used by the optimizer to look up rows. For example, if you have a three-column index on (col1, col2, col3), you have indexed search capabilities on (col1), (col1, col2), and (col1, col2, col3).&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;就是说联合索引中的多列是按照列的次序排列的，如果查询的时候不能满足列的次序，比如说where条件中缺少&lt;code&gt;col1 = ?&lt;/code&gt;，直接就是&lt;code&gt;col2 = ? and col3 = ?&lt;/code&gt;，那么就走不了联合索引，从上面联合索引的结构图应该能明显看出，只有&lt;code&gt;col2&lt;/code&gt;列无法通过索引树检索符合条件的数据。&lt;/p&gt;
&lt;p&gt;根据最左前缀法则，我们知道对&lt;code&gt;INDEX idx_book_id_hero_name (book_id, hero_name)&lt;/code&gt;来说，&lt;code&gt;where book_id = ? and hero_name = ?&lt;/code&gt;的查询来说，肯定可以走索引，但是如果是&lt;code&gt;where hero_name = ? and book_id = ?&lt;/code&gt;呢，表面上看起来不符合最左前缀法则啊，但MySQL优化器会根据已有的索引，调整查询条件中这两列的顺序，让它符合最左前缀法则，走索引，这里也就回答了上篇《一文学会MySQL的explain工具》中为什么用&lt;code&gt;show warnings&lt;/code&gt;命令查看时，&lt;code&gt;where&lt;/code&gt;中的两个过滤条件&lt;code&gt;hero_name&lt;/code&gt;、&lt;code&gt;book_id&lt;/code&gt;先后顺序被调换了。&lt;/p&gt;
&lt;p&gt;至于对联合索引中的列进行范围查询等各种情况，都可以先想联合索引的结构是如何创建出来的，然后看过滤条件是否满足最左前缀法则。比如说范围查询时，范围列可以用到索引（必须是最左前缀），但是范围列后面的列无法用到索引。同时，索引最多用于一个范围列，因此如果查询条件中有两个范围列则无法全用到索引。&lt;/p&gt;
&lt;h2 id=&quot;优化建议&quot;&gt;优化建议&lt;/h2&gt;
&lt;h3 id=&quot;主键的选择&quot;&gt;主键的选择&lt;/h3&gt;
&lt;p&gt;在使用&lt;code&gt;InnoDB&lt;/code&gt;存储引擎时，如果没有特别的需要，尽量使用一个与业务无关的&lt;code&gt;递增字段&lt;/code&gt;作为主键，主键字段不宜过长。原因上面在讲索引结构时已提过。比如说常用雪花算法生成64bit大小的整数(占8个字节，用&lt;code&gt;BIGINT&lt;/code&gt;类型)作为主键就是一个不错的选择。&lt;/p&gt;
&lt;h3 id=&quot;索引的选择&quot;&gt;索引的选择&lt;/h3&gt;
&lt;p&gt;(1) 表记录比较少的时候，比如说只有几百条记录的表，对一些列建立索引的意义可能并不大，所以表记录不大时酌情考虑索引。但是业务上具有&lt;code&gt;唯一特性&lt;/code&gt;的字段，即使是多个字段的组合，也建议使用唯一索引(&lt;code&gt;UNIQUE KEY&lt;/code&gt;)。&lt;/p&gt;
&lt;p&gt;(2) 当索引的选择性非常低时，索引的意义可能也不大。所谓索引的选择性(&lt;code&gt;Selectivity&lt;/code&gt;)，是指不重复的索引值(也叫基数&lt;code&gt;Cardinality&lt;/code&gt;)与表记录数的比值，即&lt;code&gt;count(distinct 列名)/count(*)&lt;/code&gt;，常见的场景就是有一列&lt;code&gt;status&lt;/code&gt;标识数据行的状态，可能&lt;code&gt;status&lt;/code&gt;非0即1，总数据100万行有50万行&lt;code&gt;status&lt;/code&gt;为0，50万行&lt;code&gt;status&lt;/code&gt;为1，那么是否有必要对这一列单独建立索引呢？&lt;/p&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;An index is best used when you need to select a small number of rows in comparison to the total rows.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;这句话我摘自stackoverflow上《MySQL: low selectivity columns = how to index?》下面一个人的回答。(详情见：&lt;code&gt;https://stackoverflow.com/questions/2386852/mysql-low-cardinality-selectivity-columns-how-to-index&lt;/code&gt;)&lt;/p&gt;
&lt;p&gt;对于上面说的&lt;code&gt;status&lt;/code&gt;非0即1，而且这两种情况分布比较均匀的情况，索引可能并没有实际意义，实际查询时，MySQL优化器在计算全表扫描和索引树扫描代价后，可能会放弃走索引，因为先从&lt;code&gt;status&lt;/code&gt;索引树中遍历出来主键值，再去主键索引树中查最终数据，代价可能比全表扫描还高。&lt;/p&gt;
&lt;p&gt;但是如果对于&lt;code&gt;status&lt;/code&gt;为1的数据只有1万行，其他99万行数据&lt;code&gt;status&lt;/code&gt;为0的情况呢，你怎么看？欢迎有兴趣的朋友在文章下面留言讨论！&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;补充&lt;/strong&gt;: 关于MySQL如何选择走不走索引或者选择走哪个最佳索引，可以使用MySQL自带的trace工具一探究竟。具体使用见下面的官方文档。&lt;br/&gt;&lt;code&gt;https://dev.mysql.com/doc/internals/en/optimizer-tracing.html&lt;/code&gt;&lt;br/&gt;&lt;code&gt;https://dev.mysql.com/doc/refman/5.7/en/information-schema-optimizer-trace-table.html&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;使用方法：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-sh&quot;&gt;mysql&amp;gt; set session optimizer_trace=&quot;enabled=on&quot;,end_markers_in_json=on;
mysql&amp;gt; select * from tb_hero where hero_id = 1;
mysql&amp;gt; SELECT * FROM information_schema.OPTIMIZER_TRACE;
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;注意&lt;/code&gt;：开启trace工具会影响MySQL性能，所以只能临时分析sql使用，用完之后应当立即关闭&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-sh&quot;&gt;mysql&amp;gt; set session optimizer_trace=&quot;enabled=off&quot;;
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;(3) 在&lt;code&gt;varchar&lt;/code&gt;类型字段上建立索引时，建议指定&lt;code&gt;索引长度&lt;/code&gt;，有些时候可能没必要对全字段建立索引，根据实际文本区分度决定索引长度即可【说明：索引的长度与区分度是一对矛盾体，&lt;code&gt;一般对字符串类型数据，长度为20的索引，区分度会高达90%以上&lt;/code&gt;，可以使用&lt;code&gt;count(distinct left(列名, 索引长度))/count(*)&lt;/code&gt;来确定区分度】。&lt;/p&gt;
&lt;p&gt;这种指定索引长度的索引叫做&lt;code&gt;前缀索引&lt;/code&gt;(详情见&lt;code&gt;https://dev.mysql.com/doc/refman/5.7/en/column-indexes.html#column-indexes-prefix&lt;/code&gt;)。&lt;/p&gt;
&lt;blockquote readability=&quot;10&quot;&gt;
&lt;p&gt;With col_name(N) syntax in an index specification for a string column, you can create an index that uses only the first N characters of the column. Indexing only a prefix of column values in this way can make the index file much smaller. When you index a BLOB or TEXT column, you must specify a prefix length for the index.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;前缀索引语法如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-sh&quot;&gt;mysql&amp;gt; alter table tb_hero add index idx_hero_name_skill2 (hero_name, skill(2));
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;前缀索引兼顾索引大小和查询速度，但是其缺点是不能用于&lt;code&gt;group by&lt;/code&gt;和&lt;code&gt;order by&lt;/code&gt;操作，也不能用于&lt;code&gt;covering index&lt;/code&gt;（即当索引本身包含查询所需全部数据时，不再访问数据文件本身）。&lt;/p&gt;
&lt;p&gt;(4) 当查询语句的&lt;code&gt;where&lt;/code&gt;条件或&lt;code&gt;group by&lt;/code&gt;、&lt;code&gt;order by&lt;/code&gt;含多列时，可根据实际情况优先考虑联合索引(&lt;code&gt;multiple-column index&lt;/code&gt;)，这样可以减少单列索引(&lt;code&gt;single-column index)&lt;/code&gt;的个数，有助于高效查询。&lt;/p&gt;
&lt;blockquote readability=&quot;7&quot;&gt;
&lt;p&gt;If you specify the columns in the right order in the index definition, a single composite index can speed up several kinds of queries on the same table.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;建立联合索引时要特别注意&lt;code&gt;column&lt;/code&gt;的次序，应结合上面提到的&lt;code&gt;最左前缀法则&lt;/code&gt;以及实际的过滤、分组、排序需求。&lt;code&gt;区分度最高的建议放最左边&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;说明：&lt;/p&gt;
&lt;ul readability=&quot;2.5&quot;&gt;&lt;li readability=&quot;1&quot;&gt;
&lt;p&gt;&lt;code&gt;order by&lt;/code&gt;的字段可以作为联合索引的一部分，并且放在最后，避免出现&lt;code&gt;file_sort&lt;/code&gt;的情况，影响查询性能。正例：&lt;code&gt;where a=? and b=? order by c&lt;/code&gt;会走索引&lt;code&gt;idx_a_b_c&lt;/code&gt;，但是&lt;code&gt;WHERE a&amp;gt;10 order by b&lt;/code&gt;却无法完全使用上索引&lt;code&gt;idx_a_b&lt;/code&gt;，只会使用上联合索引的第一列a&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;1&quot;&gt;
&lt;p&gt;存在非等号和等号混合时，在建联合索引时，应该把等号条件的列前置。如：&lt;code&gt;where c&amp;gt;? and d=?&lt;/code&gt;那么即使c的区分度更高，也应该把d放在索引的最前列，即索引&lt;code&gt;idx_d_c&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;如果&lt;code&gt;where a=? and b=?&lt;/code&gt;，如果a列的几乎接近于唯一值，那么只需要建立单列索引&lt;code&gt;idx_a&lt;/code&gt;即可&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;h3 id=&quot;order-by与group-by&quot;&gt;order by与group by&lt;/h3&gt;
&lt;p&gt;尽量在索引列上完成分组、排序，遵循索引&lt;code&gt;最左前缀法则&lt;/code&gt;，如果&lt;code&gt;order by&lt;/code&gt;的条件不在索引列上，就会产生&lt;code&gt;Using filesort&lt;/code&gt;，降低查询性能。&lt;/p&gt;
&lt;h3 id=&quot;分页查询&quot;&gt;分页查询&lt;/h3&gt;
&lt;p&gt;MySQL分页查询大多数写法可能如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-sh&quot;&gt;mysql&amp;gt; select * from tb_hero limit offset,N;
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;MySQL并不是跳过&lt;code&gt;offset&lt;/code&gt;行，而是取&lt;code&gt;offset+N&lt;/code&gt;行，然后返回放弃前&lt;code&gt;offset&lt;/code&gt;行，返回&lt;code&gt;N&lt;/code&gt;行，那当&lt;code&gt;offset&lt;/code&gt;特别大的时候，效率就非常的低下。&lt;/p&gt;
&lt;p&gt;可以对超过特定阈值的页数进行SQL改写如下：&lt;/p&gt;
&lt;p&gt;先快速定位需要获取的id段，然后再关联&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-sh&quot;&gt;mysql&amp;gt; select a.* from tb_hero a, (select hero_id from tb_hero where 条件 limit 100000,20 ) b where a.hero_id = b.hero_id;
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;或者这种写法&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-sh&quot;&gt;mysql&amp;gt; select a.* from tb_hero a inner join (select hero_id from tb_hero where 条件 limit 100000,20) b on a.hero_id = b.hero_id;
&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;多表join&quot;&gt;多表join&lt;/h3&gt;
&lt;p&gt;(1) 需要join的字段，数据类型必须绝对一致；&lt;br/&gt;(2) 多表join时，保证被关联的字段有索引&lt;/p&gt;
&lt;h3 id=&quot;覆盖索引&quot;&gt;覆盖索引&lt;/h3&gt;
&lt;p&gt;利用覆盖索引(&lt;code&gt;covering index&lt;/code&gt;)来进行查询操作，避免回表，从而增加磁盘I/O。换句话说就是，尽可能避免&lt;code&gt;select *&lt;/code&gt;语句，只选择必要的列，去除无用的列。&lt;/p&gt;
&lt;blockquote readability=&quot;12&quot;&gt;
&lt;p&gt;An index that includes all the columns retrieved by a query. Instead of using the index values as pointers to find the full table rows, the query returns values from the index structure, saving disk I/O. InnoDB can apply this optimization technique to more indexes than MyISAM can, because InnoDB secondary indexes also include the primary key columns. InnoDB cannot apply this technique for queries against tables modified by a transaction, until that transaction ends.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote readability=&quot;7&quot;&gt;
&lt;p&gt;Any column index or composite index could act as a covering index, given the right query. Design your indexes and queries to take advantage of this optimization technique wherever possible.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;当索引本身包含查询所需全部列时，无需回表查询完整的行记录。对于&lt;code&gt;InnoDB&lt;/code&gt;来说，非主键索引中包含了&lt;code&gt;所有的索引列&lt;/code&gt;以及&lt;code&gt;主键值&lt;/code&gt;，查询的时候尽量用这种特性避免回表操作，数据量很大时，查询性能提升很明显。&lt;/p&gt;
&lt;h3 id=&quot;in和exsits&quot;&gt;in和exsits&lt;/h3&gt;
&lt;p&gt;原则：&lt;code&gt;小表驱动大表&lt;/code&gt;，即小的数据集驱动大的数据集&lt;/p&gt;
&lt;p&gt;(1) 当A表的数据集大于B表的数据集时，&lt;code&gt;in&lt;/code&gt;优于&lt;code&gt;exists&lt;/code&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-sh&quot;&gt;mysql&amp;gt; select * from A where id in (select id from B)
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;(2) 当A表的数据集小于B表的数据集时，&lt;code&gt;exists&lt;/code&gt;优于&lt;code&gt;in&lt;/code&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-sh&quot;&gt;mysql&amp;gt; select * from A where exists (select 1 from B where B.id = A.id)
&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;like&quot;&gt;like&lt;/h3&gt;
&lt;p&gt;索引文件具有&lt;code&gt;B+Tree&lt;/code&gt;最左前缀匹配特性，如果左边的值未确定，那么无法使用索引，所以应尽量避免左模糊(即&lt;code&gt;%xxx&lt;/code&gt;)或者全模糊(即&lt;code&gt;%xxx%&lt;/code&gt;)。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-sh&quot;&gt;mysql&amp;gt; select * from tb_hero where hero_name like '%无%';
+---------+-----------+--------------+---------+
| hero_id | hero_name | skill        | book_id |
+---------+-----------+--------------+---------+
|       3 | 张无忌    | 九阳神功     |       3 |
|       5 | 花无缺    | 移花接玉     |       5 |
+---------+-----------+--------------+---------+
2 rows in set (0.00 sec)

mysql&amp;gt; explain select * from tb_hero where hero_name like '%无%';
+----+-------------+---------+------------+------+---------------+------+---------+------+------+----------+-------------+
| id | select_type | table   | partitions | type | possible_keys | key  | key_len | ref  | rows | filtered | Extra       |
+----+-------------+---------+------------+------+---------------+------+---------+------+------+----------+-------------+
|  1 | SIMPLE      | tb_hero | NULL       | ALL  | NULL          | NULL | NULL    | NULL |    6 |    16.67 | Using where |
+----+-------------+---------+------------+------+---------------+------+---------+------+------+----------+-------------+
1 row in set, 1 warning (0.00 sec)
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;可以看出全模糊查询时全表扫了，这个时候使用&lt;code&gt;覆盖索引&lt;/code&gt;的特性，只选择索引字段可以有所优化。如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-sh&quot;&gt;mysql&amp;gt; explain select book_id, hero_name from tb_hero where hero_name like '%无%';
+----+-------------+---------+------------+-------+---------------+-----------------------+---------+------+------+----------+--------------------------+
| id | select_type | table   | partitions | type  | possible_keys | key                   | key_len | ref  | rows | filtered | Extra                    |
+----+-------------+---------+------------+-------+---------------+-----------------------+---------+------+------+----------+--------------------------+
|  1 | SIMPLE      | tb_hero | NULL       | index | NULL          | idx_book_id_hero_name | 136     | NULL |    6 |    16.67 | Using where; Using index |
+----+-------------+---------+------------+-------+---------------+-----------------------+---------+------+------+----------+--------------------------+
1 row in set, 1 warning (0.00 sec)
&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;count&quot;&gt;count(*)&lt;/h3&gt;
&lt;p&gt;阿里巴巴Java开发手册中有这样的规约：&lt;/p&gt;
&lt;blockquote readability=&quot;9&quot;&gt;
&lt;p&gt;不要使用&lt;code&gt;count(列名)&lt;/code&gt;或&lt;code&gt;count(常量)&lt;/code&gt;来替代&lt;code&gt;count(*)&lt;/code&gt;，&lt;code&gt;count(*)&lt;/code&gt;是SQL92定义的标准统计行数的语法，跟数据库无关，跟&lt;code&gt;NULL&lt;/code&gt;和&lt;code&gt;非NULL&lt;/code&gt;无关【说明：&lt;code&gt;count(*)&lt;/code&gt;会统计值为&lt;code&gt;NULL&lt;/code&gt;的行，而&lt;code&gt;count(列名)&lt;/code&gt;不会统计此列为&lt;code&gt;NULL&lt;/code&gt;值的行】。&lt;br/&gt;&lt;code&gt;count(distinct col)&lt;/code&gt;计算该列除&lt;code&gt;NULL&lt;/code&gt;之外的不重复行数，注意&lt;code&gt;count(distinct col1, col2)&lt;/code&gt;如果其中一列全为&lt;code&gt;NULL&lt;/code&gt;，那么即使另一列有不同的值，也返回为0&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;截取一段官方文档对&lt;code&gt;count&lt;/code&gt;的描述(具体见：&lt;code&gt;https://dev.mysql.com/doc/refman/5.7/en/aggregate-functions.html#function_count&lt;/code&gt;)&lt;/p&gt;
&lt;blockquote readability=&quot;7&quot;&gt;
&lt;p&gt;COUNT(expr): Returns a count of the number of non-NULL values of expr in the rows.The result is a BIGINT value.If there are no matching rows, COUNT(expr) returns 0.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote readability=&quot;7&quot;&gt;
&lt;p&gt;COUNT(*) is somewhat different in that it returns a count of the number of rows, whether or not they contain NULL values.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote readability=&quot;11&quot;&gt;
&lt;p&gt;Prior to MySQL 5.7.18, InnoDB processes SELECT &lt;code&gt;COUNT(*)&lt;/code&gt; statements by scanning the clustered index. As of MySQL 5.7.18, InnoDB processes SELECT COUNT(*) statements by traversing the smallest available secondary index unless an index or optimizer hint directs the optimizer to use a different index. If a secondary index is not present, the clustered index is scanned.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;可见&lt;code&gt;5.7.18&lt;/code&gt;之前，MySQL处理&lt;code&gt;count(*)&lt;/code&gt;会扫描主键索引，&lt;code&gt;5.7.18&lt;/code&gt;之后从非主键索引中选择较小的合适的索引扫描。可以用&lt;code&gt;explain&lt;/code&gt;看下执行计划。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-sh&quot;&gt;mysql&amp;gt; select version();
+-----------+
| version() |
+-----------+
| 5.7.18    |
+-----------+
1 row in set (0.00 sec)

mysql&amp;gt; explain select count(*) from tb_hero;
+----+-------------+---------+------------+-------+---------------+-----------+---------+------+------+----------+-------------+
| id | select_type | table   | partitions | type  | possible_keys | key       | key_len | ref  | rows | filtered | Extra       |
+----+-------------+---------+------------+-------+---------------+-----------+---------+------+------+----------+-------------+
|  1 | SIMPLE      | tb_hero | NULL       | index | NULL          | idx_skill | 15      | NULL |    6 |   100.00 | Using index |
+----+-------------+---------+------------+-------+---------------+-----------+---------+------+------+----------+-------------+
1 row in set, 1 warning (0.00 sec)

mysql&amp;gt; explain select count(1) from tb_hero;
+----+-------------+---------+------------+-------+---------------+-----------+---------+------+------+----------+-------------+
| id | select_type | table   | partitions | type  | possible_keys | key       | key_len | ref  | rows | filtered | Extra       |
+----+-------------+---------+------------+-------+---------------+-----------+---------+------+------+----------+-------------+
|  1 | SIMPLE      | tb_hero | NULL       | index | NULL          | idx_skill | 15      | NULL |    6 |   100.00 | Using index |
+----+-------------+---------+------------+-------+---------------+-----------+---------+------+------+----------+-------------+
1 row in set, 1 warning (0.00 sec)
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;有人纠结&lt;code&gt;count(*)&lt;/code&gt;、&lt;code&gt;count(1)&lt;/code&gt;到底哪种写法更高效，从上面的执行计划来看都一样，如果你还不放心的话，官方文档中也明确指明了&lt;code&gt;InnoDB&lt;/code&gt;对&lt;code&gt;count(*)&lt;/code&gt;、&lt;code&gt;count(1)&lt;/code&gt;的处理完全一致。&lt;/p&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;InnoDB handles SELECT COUNT(*) and SELECT COUNT(1) operations in the same way. There is no performance difference.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&quot;其他&quot;&gt;其他&lt;/h3&gt;
&lt;p&gt;索引列上做任何操作(&lt;code&gt;表达式&lt;/code&gt;、&lt;code&gt;函数计算&lt;/code&gt;、&lt;code&gt;类型转换&lt;/code&gt;等)时无法使用索引会导致全表扫描&lt;/p&gt;
&lt;h2 id=&quot;实战&quot;&gt;实战&lt;/h2&gt;
&lt;p&gt;前几周测试同事对公司的某产品进行压测，某单表写入了近2亿条数据，过程中发现配的报表有几个数据查询时间太长，所以重点看了几个慢查询SQL。避免敏感信息，这里对其提取简化做个记录。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-sh&quot;&gt;mysql&amp;gt; select count(*) from tb_alert;
+-----------+
| count(*)  |
+-----------+
| 198101877 |
+-----------+
&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;表join慢&quot;&gt;表join慢&lt;/h3&gt;
&lt;p&gt;表join后，取前10条数据就花了15秒，看了下SQL执行计划，如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-sh&quot;&gt;mysql&amp;gt; select * from tb_alert left join tb_situation_alert on tb_alert.alert_id = tb_situation_alert.alert_id limit 10;
10 rows in set (15.46 sec)

mysql&amp;gt; explain select * from tb_alert left join tb_situation_alert on tb_alert.alert_id = tb_situation_alert.alert_id limit 10;
+----+-------------+--------------------+------------+------+---------------+------+---------+------+-----------+----------+----------------------------------------------------+
| id | select_type | table              | partitions | type | possible_keys | key  | key_len | ref  | rows      | filtered | Extra                                              |
+----+-------------+--------------------+------------+------+---------------+------+---------+------+-----------+----------+----------------------------------------------------+
|  1 | SIMPLE      | tb_alert           | NULL       | ALL  | NULL          | NULL | NULL    | NULL | 190097118 |   100.00 | NULL                                               |
|  1 | SIMPLE      | tb_situation_alert | NULL       | ALL  | NULL          | NULL | NULL    | NULL |   8026988 |   100.00 | Using where; Using join buffer (Block Nested Loop) |
+----+-------------+--------------------+------------+------+---------------+------+---------+------+-----------+----------+----------------------------------------------------+
2 rows in set, 1 warning (0.00 sec)
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;可以看出join的时候没有用上索引，&lt;code&gt;tb_situation_alert&lt;/code&gt;表上&lt;code&gt;联合主键&lt;/code&gt;是这样的&lt;code&gt;PRIMARY KEY (situation_id, alert_id)&lt;/code&gt;，参与表join字段是&lt;code&gt;alert_id&lt;/code&gt;，原来是不符合联合索引的最左前缀法则，仅从这条sql看，解决方案有两种，一种是对&lt;code&gt;tb_situation_alert&lt;/code&gt;表上的&lt;code&gt;alert_id&lt;/code&gt;单独建立索引，另外一种是调换联合主键的列的次序，改为&lt;code&gt;PRIMARY KEY (alert_id, situation_id)&lt;/code&gt;。当然不能因为多配一张报表，就改其他产线的表的主键索引，这并不合理。在这里，应该对&lt;code&gt;alert_id&lt;/code&gt;列单独建立索引。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-sh&quot;&gt;mysql&amp;gt; create index idx_alert_id on tb_situation_alert (alert_id);

mysql&amp;gt; select * from tb_alert left join tb_situation_alert on tb_alert.alert_id = tb_situation_alert.alert_id limit 100;
100 rows in set (0.01 sec)

mysql&amp;gt; explain select * from tb_alert left join tb_situation_alert on tb_alert.alert_id = tb_situation_alert.alert_id limit 100;
+----+-------------+--------------------+------------+------+---------------+--------------+---------+---------------------------------+-----------+----------+-------+
| id | select_type | table              | partitions | type | possible_keys | key          | key_len | ref                             | rows      | filtered | Extra |
+----+-------------+--------------------+------------+------+---------------+--------------+---------+---------------------------------+-----------+----------+-------+
|  1 | SIMPLE      | tb_alert           | NULL       | ALL  | NULL          | NULL         | NULL    | NULL                            | 190097118 |   100.00 | NULL  |
|  1 | SIMPLE      | tb_situation_alert | NULL       | ref  | idx_alert_id  | idx_alert_id | 8       | tb_alert.alert_id |         2 |   100.00 | NULL  |
+----+-------------+--------------------+------------+------+---------------+--------------+---------+---------------------------------+-----------+----------+-------+
2 rows in set, 1 warning (0.00 sec)
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;优化后，执行计划可以看出join的时候走了索引，查询前100条0.01秒，和之前的取前10条数据就花了15秒天壤之别。&lt;/p&gt;
&lt;h3 id=&quot;分页查询慢&quot;&gt;分页查询慢&lt;/h3&gt;
&lt;p&gt;从第10000000条数据往后翻页时，25秒才能出结果，这里就能使用上面的分页查询优化技巧了。上面讲优化建议时，没看执行计划，这里正好看一下。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-sh&quot;&gt;mysql&amp;gt; select * from tb_alert limit 10000000, 10;
10 rows in set (25.23 sec)

mysql&amp;gt; explain select * from tb_alert limit 10000000, 10;
+----+-------------+----------+------------+------+---------------+------+---------+------+-----------+----------+-------+
| id | select_type | table    | partitions | type | possible_keys | key  | key_len | ref  | rows      | filtered | Extra |
+----+-------------+----------+------------+------+---------------+------+---------+------+-----------+----------+-------+
|  1 | SIMPLE      | tb_alert | NULL       | ALL  | NULL          | NULL | NULL    | NULL | 190097118 |   100.00 | NULL  |
+----+-------------+----------+------------+------+---------------+------+---------+------+-----------+----------+-------+
1 row in set, 1 warning (0.00 sec)
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;再看下使用上分页查询优化技巧的sql的执行计划&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-sh&quot;&gt;mysql&amp;gt; select * from tb_alert a inner join (select alert_id from tb_alert limit 10000000, 10) b on a.alert_id = b.alert_id;
10 rows in set (2.29 sec)

mysql&amp;gt; explain select * from tb_alert a inner join (select alert_id from tb_alert a2 limit 10000000, 10) b on a.alert_id = b.alert_id;
+----+-------------+------------+------------+--------+---------------+---------------+---------+-----------+-----------+----------+-------------+
| id | select_type | table      | partitions | type   | possible_keys | key           | key_len | ref       | rows      | filtered | Extra       |
+----+-------------+------------+------------+--------+---------------+---------------+---------+-----------+-----------+----------+-------------+
|  1 | PRIMARY     | &amp;lt;derived2&amp;gt; | NULL       | ALL    | NULL          | NULL          | NULL    | NULL      |  10000010 |   100.00 | NULL        |
|  1 | PRIMARY     | a          | NULL       | eq_ref | PRIMARY       | PRIMARY       | 8       | b.alert_id |         1 |   100.00 | NULL        |
|  2 | DERIVED     | a2         | NULL       | index  | NULL          | idx_processed | 5       | NULL      | 190097118 |   100.00 | Using index |
+----+-------------+------------+------------+--------+---------------+---------------+---------+-----------+-----------+----------+-------------+
3 rows in set, 1 warning (0.00 sec)
&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;分组聚合慢&quot;&gt;分组聚合慢&lt;/h3&gt;
&lt;p&gt;分析SQL后，发现根本上并非分组聚合慢，而是扫描联合索引后，回表导致性能低下，去除不必要的字段，使用覆盖索引。&lt;/p&gt;
&lt;p&gt;这里避免敏感信息，只演示分组聚合前的简化SQL，主要问题也是在这。&lt;br/&gt;表上有联合索引&lt;code&gt;KEY idx_alert_start_host_template_id ( alert_start, alert_host, template_id)&lt;/code&gt;，优化前的sql为&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-sh&quot;&gt;mysql&amp;gt; select alert_start, alert_host, template_id, alert_service from tb_alert where alert_start &amp;gt; {ts '2019-06-05 00:00:10.0'} limit 10000;
10000 rows in set (1 min 5.22 sec)
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;使用覆盖索引，去掉&lt;code&gt;template_id&lt;/code&gt;列，就能避免回表，查询时间从1min多变为0.03秒，如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-sh&quot;&gt;mysql&amp;gt; select alert_start, alert_host, template_id from tb_alert where alert_start &amp;gt; {ts '2019-06-05 00:00:10.0'} limit 10000;
10000 rows in set (0.03 sec)

mysql&amp;gt; explain select alert_start, alert_host, template_id from tb_alert where alert_start &amp;gt; {ts '2019-06-05 00:00:10.0'} limit 10000;
+----+-------------+----------+------------+-------+------------------------------------+------------------------------------+---------+------+----------+----------+--------------------------+
| id | select_type | table    | partitions | type  | possible_keys                      | key                                | key_len | ref  | rows     | filtered | Extra                    |
+----+-------------+----------+------------+-------+------------------------------------+------------------------------------+---------+------+----------+----------+--------------------------+
|  1 | SIMPLE      | tb_alert | NULL       | range | idx_alert_start_host_template_id   | idx_alert_start_host_template_id   | 9       | NULL | 95048559 |   100.00 | Using where; Using index |
+----+-------------+----------+------------+-------+------------------------------------+------------------------------------+---------+------+----------+----------+--------------------------+
1 row in set, 1 warning (0.01 sec)
&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;总结&quot;&gt;总结&lt;/h2&gt;
&lt;p&gt;任何不考虑应用场景的设计都不是最好的设计，就比如说表结构的设计、索引的创建，都应该权衡数据量大小、查询需求、数据更新频率等。&lt;br/&gt;另外正如&lt;code&gt;《阿里巴巴java开发手册》&lt;/code&gt;中提到的&lt;code&gt;索引规约&lt;/code&gt;(详情见：&lt;a href=&quot;https://www.cnblogs.com/itwild/p/12353164.html&quot;&gt;《Java开发手册》之&quot;异常处理、MySQL 数据库&quot;&lt;/a&gt;)： &lt;code&gt;创建索引时避免有如下极端误解:&lt;/code&gt;&lt;/p&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;1）宁滥勿缺。认为一个查询就需要建一个索引&lt;br/&gt;2）宁缺勿滥。认为索引会消耗空间、严重拖慢记录的更新以及行的新增速度&lt;/p&gt;
&lt;/blockquote&gt;
</description>
<pubDate>Mon, 21 Sep 2020 00:24:00 +0000</pubDate>
<dc:creator>行无际</dc:creator>
<og:description>回顾前文: 一文学会MySQL的explain工具 (同时再次强调，这几篇关于MySQL的探究都是基于5.7版本，相关总结与结论不一定适用于其他版本) MySQL官方文档中(https://dev.m</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/itwild/p/13703259.html</dc:identifier>
</item>
<item>
<title>人工智能顶级会议最佳论文里的“DaDianNao”是什么鬼？ - Jack47</title>
<link>http://www.cnblogs.com/Jack47/p/dadiannao-shidiannao-pudiannao-diannaoyu.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/Jack47/p/dadiannao-shidiannao-pudiannao-diannaoyu.html</guid>
<description>&lt;p&gt;最近对人工智能领域的 AI 加速芯片感兴趣，在翻阅 Google 的第一代 &lt;a href=&quot;https://arxiv.org/pdf/1704.04760&quot;&gt;TPU 论文&lt;/a&gt;时，在相关工作中看到了 DaDianNao，PuDianNao，ShiDianNao。看的我一脸懵逼，这是什么？汉语拼音吗？后来经过搜索，发现这是中科院计算所的一系列研究成果，后来直接催生了国内芯片独角兽 -- 寒武纪的诞生。&lt;/p&gt;
&lt;p&gt;故事得从20年前说起，当时江西南昌有俩亲兄弟，哥哥叫&lt;a href=&quot;http://novel.ict.ac.cn/ychen/index_cn.html&quot;&gt;陈云霁&lt;/a&gt;，弟弟&lt;a href=&quot;http://novel.ict.ac.cn/tchen/&quot;&gt;陈天石&lt;/a&gt;。他们分别于97、01 年先后考入中国科学大学少年班学习，后来攻读研究生时，哥哥在计算所跟胡伟武(龙芯之父)做芯片方面研究，弟弟在中科大跟着陈国良、姚新做人工智能算法方面研究。08年的时候，他俩想合起来做一些人工智能芯片方面的事情。&lt;/p&gt;
&lt;p&gt;2012年到2014年，俩兄弟和 当时任职于法国巴黎综合理工学院(Inria Saclay)的 &lt;a href=&quot;https://pages.saclay.inria.fr/olivier.temam/&quot;&gt;Olivier Temam&lt;/a&gt; 教授一起合作，做人工智能加速器的研究。最开始叫做 electric brain，是一个电子的大脑，但是外籍教授 Olivier 说起个中国的名字，这样别人会觉得外国的东西，很有意思，很先进。于是就有了 DianNao 这个汉语拼音的名字了。中科院有专门页面介绍&lt;a href=&quot;http://novel.ict.ac.cn/diannao/&quot;&gt;“DianNao”项目&lt;/a&gt;，项目的核心是提出了一系列定制的AI加速器的设计方案。&lt;/p&gt;
&lt;p&gt;当时他们研究领域想要解决的三大矛盾是：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;有限规模的硬件 vs 任意规模的算法：硬件出厂后就固定了，但是算法是研究员自己定义的，会是任意的&lt;/li&gt;
&lt;li&gt;结构固定的硬件 vs 千变万化的算法：算法有图像、语音、自然语言处理等领域，而硬件构造在生产之后就固定了&lt;/li&gt;
&lt;li&gt;能耗受限的硬件 vs 精度优先的算法：硬件功耗受制于场景是受限的，但是算法研究员希望精度越高越好&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;陈氏兄弟的解决之道：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;虚拟化：没有让硬件运算单元和算法神经元一一对应起来，而是采用了对小尺度神经网络分时复用的方法来支持任意规模的神经网络&lt;/li&gt;
&lt;li&gt;智能指令集：自动化抽取各种深度学习算法共性基本算子，设计首个深度学习指令集来高效处理算法。&lt;/li&gt;
&lt;li&gt;利用神经网络对于计算误差的容忍能力，进行稀疏化神经网络处理，这样降低了功耗，提高了精度。&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;他们设计出了第一个加速器 &lt;a href=&quot;https://www.cnblogs.com/Jack47/p/dadiannao-shidiannao-pudiannao-diannaoyu.html&quot;&gt;DianNao&lt;/a&gt;--电脑。第二个加速器叫&lt;a href=&quot;http://novel.ict.ac.cn/ychen/pdf/DaDianNao.pdf&quot;&gt;DaDiannao&lt;/a&gt; -- 大电脑。这个是 DianNao 的多核版本，通过多片设计，可以将较大的模型放在加速器（芯片）的内存上运行，提高效率。第三个加速器ShiDianNao -- 视电脑：将 AI 加速器与传感器直连，从而减少内存通讯的开销，是属于端/边侧摄像头上的 AI 加速器。电脑和大电脑只能做深度学习处理，还有很多其他的人工智能算法， 怎么去支持？于是就有了 PuDianNao -- 普电脑。它比较普世，能支持很多机器学习算法。PuDianNao 也是 DianNao 项目的最后一个工作。我大胆猜测是因为再接着做下去，围绕电脑起名很困难。后来16年时他们提出了国际首个神经网络通用指令集 &lt;a href=&quot;https://seal.ece.ucsb.edu/sites/seal.ece.ucsb.edu/files/publications/07551409.pdf&quot;&gt;DianNaoYu&lt;/a&gt; -- 电脑语。这些指令集相当于深度学习算法界的乐高积木，是算法研究员与加速器打交道的唯一接口。&lt;/p&gt;
&lt;p&gt;他们当时的 DianNao 论文获得了这个领域最重要的国际会议 -- ASPLOS 的最佳论文奖。这也是亚洲地区，第一次在计算机体系结构的这种顶尖的国际会议上拿奖。他们研究最大的创新点在于前人做的不是一个完备的处理器，只能说是一个神经网络功能部件，只适用于特定大小的神经网络。而他们的工作是一个真正意义上完备的处理器，能够支持任意规模的神经网络。打个比方，只能处理两个数相加，而不能处理10000甚至任意个数相加的硬件，只能叫加法器，而不能叫处理器。&lt;/p&gt;
&lt;p&gt;后来弟弟陈天石从中科院出来创办了寒武纪，哥哥也一起合伙。但半年之后，哥哥因为觉得还是喜欢搞科研，所以又回到了中科院。&lt;/p&gt;
&lt;p&gt;对上述内容感兴趣的朋友可以去看看 B 站上 陈云霁的&lt;a href=&quot;https://www.bilibili.com/video/BV1xK41177Pj?from=search&amp;amp;seid=14026507824534048204&quot;&gt;智能之芯&lt;/a&gt;视频。大佬演讲风趣幽默，着装朴实，让人印象深刻。有两篇陈天石的采访放到了文末，从文章来看很清楚自己的能力边界，他强调了多次，做好本职工作，好好搬砖，感觉就是对有志青年的淳淳教导。&lt;/p&gt;
&lt;h2 id=&quot;彩蛋&quot;&gt;彩蛋&lt;/h2&gt;
&lt;p&gt;2015 年，陈天石有一次&lt;a href=&quot;https://www.thepaper.cn/asktopic_detail_10001473&quot;&gt;“问我任何事”&lt;/a&gt;的活动，我翻看了里面的问题，有好几个问题非常有意思。比如有人会问中科大的神通、天才和普通人的区别，还有家长因为孩子无法成为神通而苦恼。对这些问题，他没有一贯我们看到的好为人师的印象，回答很有借鉴意义，能给现在焦虑的家长们一些启发，点击阅读原文可以查看。&lt;/p&gt;
&lt;h2 id=&quot;参考资料&quot;&gt;参考资料&lt;/h2&gt;
&lt;ol&gt;&lt;li&gt;&lt;a href=&quot;https://www.sohu.com/a/259181739_100016644&quot;&gt;甲小姐对话陈天石：AI芯片市场广阔，寒武纪朋友遍天下 | 甲子光年&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://t.qianzhan.com/daka/detail/200315-8c89acc6.html&quot;&gt;甲小姐对话陈天石：通往伟大芯片公司的赛程很长&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://www.bilibili.com/video/BV1xK41177Pj?from=search&amp;amp;seid=14026507824534048204&quot;&gt;智能之芯&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;h2 id=&quot;欢迎关注我的微信公众账号，会在第一时间更新，博客园上只有部分文章会发布&quot;&gt;欢迎关注我的微信公众账号，会在第一时间更新，博客园上只有部分文章会发布&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;http://img2.tbcdn.cn/L1/461/1/5a0eff69de17d58383b72c9a78b3c28cd74b9d39&quot; alt=&quot;code&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
</description>
<pubDate>Sun, 20 Sep 2020 23:41:00 +0000</pubDate>
<dc:creator>Jack47</dc:creator>
<og:description>最近对人工智能领域的 AI 加速芯片感兴趣，在翻阅 Google 的第一代 TPU 论文时，在相关工作中看到了 DaDianNao，PuDianNao，ShiDianNao。看的我一脸懵逼，这是什么？</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/Jack47/p/dadiannao-shidiannao-pudiannao-diannaoyu.html</dc:identifier>
</item>
<item>
<title>灵活使用 SQLAlchemy 中的 ORM 查询 - kevinbai_cn</title>
<link>http://www.cnblogs.com/kevinbai/p/13703574.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/kevinbai/p/13703574.html</guid>
<description>&lt;p&gt;之前做查询一直觉得直接拼 SQL 比较方便，用了 SQLAlchemy 的 ORM 查询之后，发现也还可以，还提高了可读性。&lt;/p&gt;
&lt;p&gt;这篇文章主要说说 SQLAlchemy 常用的 ORM 查询方式，偏实践。看了之后，对付开发中的查询需求，我觉得可以满足不少。&lt;/p&gt;
&lt;p&gt;为方便说明，假设有如下数据&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;图书表 books&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;+----+--------+--------------------------+-------+
| id | cat_id | name                     | price |
+----+--------+--------------------------+-------+
|  1 |      1 | 生死疲劳                 | 40.40 |
|  2 |      1 | 皮囊                     | 31.80 |
|  3 |      2 | 半小时漫画中国史         | 33.60 |
|  4 |      2 | 耶路撒冷三千年           | 55.60 |
|  5 |      2 | 国家宝藏                 | 52.80 |
|  6 |      3 | 时间简史                 | 31.10 |
|  7 |      3 | 宇宙简史                 | 22.10 |
|  8 |      3 | 自然史                   | 26.10 |
|  9 |      3 | 人类简史                 | 40.80 |
| 10 |      3 | 万物简史                 | 33.20 |
+----+--------+--------------------------+-------+
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;分类表 categories&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;+----+--------------+
| id | name         |
+----+--------------+
|  1 | 文学         |
|  2 | 人文社科     |
|  3 | 科技         |
+----+--------------+
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;ORM 对象定义如下&lt;/p&gt;
&lt;hr/&gt;&lt;p&gt;&lt;strong&gt;注意：本文 Python 代码在以下环境测试通过&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;Python 3.6.0&lt;/li&gt;
&lt;li&gt;PyMySQL 0.8.1&lt;/li&gt;
&lt;li&gt;SQLAlchemy 1.2.8&lt;/li&gt;
&lt;/ul&gt;&lt;hr/&gt;&lt;pre&gt;
&lt;code&gt;# coding=utf-8

from sqlalchemy import create_engine
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy import Column, Integer, String, Numeric
from sqlalchemy.orm import sessionmaker

Base = declarative_base()
engine = create_engine('mysql+pymysql://username:password'
                       '@127.0.0.1:3306/db_name?charset=utf8')
Session = sessionmaker(bind=engine)

session = Session()


def to_dict(self):
    return {c.name: getattr(self, c.name, None)
            for c in self.__table__.columns}
Base.to_dict = to_dict


class Book(Base):
    __tablename__ = 'books'

    id = Column(Integer, primary_key=True)
    cat_id = Column(Integer)
    name = Column('name', String(120))
    price = Column('price', Numeric)


class Category(Base):
    __tablename__ = 'categories'

    id = Column(Integer, primary_key=True)
    name = Column('name', String(30))
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;好了，下面进入正题。&lt;/p&gt;

&lt;p&gt;当我们获取图书的详情时，很容易用到。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;book_id = 1
book = session.query(Book).get(book_id)
print(book and book.to_dict())
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;直接 get(primary_key) 就得到结果&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;{'id': 1, 'cat_id': 1, 'name': '生死疲劳',
 'price': Decimal('40.40')}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;当然，这样也可以&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;book_id = 1
book = session.query(Book) \
    .filter(Book.id == book_id) \
    .first()
print(book and book.to_dict())
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;不过，还是前一种方式简洁一些。&lt;/p&gt;

&lt;p&gt;我们最常用到的就是这种查询，比如我要获取 &lt;code&gt;cat_id&lt;/code&gt; 为 1 且价格大于 35 的书&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;books = session.query(Book) \
    .filter(Book.cat_id == 1,
            Book.price &amp;gt; 35) \
    .all()
print([v.to_dict() for v in books])
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;执行后，得到结果&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;[{'id': 1, 'cat_id': 1, 'name': '生死疲劳',
  'price': Decimal('40.40')}]
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;filter() 里面的条件默认是使用 AND 进行连接，毕竟这最常用嘛。所以说，换成这样用也是没有问题的&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;from sqlalchemy import and_
books = session.query(Book) \
    .filter(and_(Book.cat_id == 1,
                 Book.price &amp;gt; 35)) \
    .all()
print([v.to_dict() for v in books])
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;不过，通常来说，如果条件全是用 AND 连接的话，没必要显式的去用 &lt;code&gt;and_&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;如果条件都是等值比较的话，可以使用 &lt;code&gt;filter_by()&lt;/code&gt; 方法，传入的是关键字参数。&lt;/p&gt;
&lt;p&gt;查询 &lt;code&gt;cat_id&lt;/code&gt; 等于 1 且价格等于 31.8 的图书，可以这样&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;books = session.query(Book) \
    .filter_by(cat_id=1, price=31.8) \
    .all()
print([v.to_dict() for v in books])
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;结果&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;[{'id': 2, 'cat_id': 1, 'name': '皮囊',
  'price': Decimal('31.80')}]
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;这种方式相对于 filter() 来说，书写要简洁一些，不过条件都限制在了等值比较。&lt;/p&gt;
&lt;p&gt;不同情况选择合适的就好。&lt;/p&gt;

&lt;p&gt;除了上面使用的 get()、first()、all() 外，还有下面的一些方法比较常用。&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;one() 只获取一条记录，如果找不到记录或者找到多条都会报错&lt;/li&gt;
&lt;/ul&gt;&lt;pre&gt;
&lt;code&gt;# 找不到记录会抛如下错误
# sqlalchemy.orm.exc.NoResultFound: No row was found for one()
book = session \
    .query(Book).filter(Book.id &amp;gt; 10) \
    .one()
print(book and book.to_dict())

# 找到多条记录会抛如下错误
# sqlalchemy.orm.exc.MultipleResultsFound: Multiple rows were found for one()
book = session \
    .query(Book).filter(Book.id &amp;lt; 10) \
    .one()
print(book and book.to_dict())

# 正常，得到如下结果
# {'id': 10, 'cat_id': 3, 'name': '万物简史',
#  'price': Decimal('33.20')}
book = session \
    .query(Book).filter(Book.id == 10) \
    .one()
print(book and book.to_dict())
&lt;/code&gt;
&lt;/pre&gt;
&lt;ul&gt;&lt;li&gt;count() 返回记录条数&lt;/li&gt;
&lt;/ul&gt;&lt;pre&gt;
&lt;code&gt;count = session \
    .query(Book) \
    .filter(Book.cat_id == 3) \
    .count()
print(count)
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;结果&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;5
&lt;/code&gt;
&lt;/pre&gt;
&lt;ul&gt;&lt;li&gt;limit() 限制返回的记录条数&lt;/li&gt;
&lt;/ul&gt;&lt;pre&gt;
&lt;code&gt;books = session \
    .query(Book) \
    .filter(Book.cat_id == 3) \
    .limit(3) \
    .all()
print([v.to_dict() for v in books])
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;结果&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;[{'id': 6, 'cat_id': 3, 'name': '时间简史',
  'price': Decimal('31.10')},
 {'id': 7, 'cat_id': 3, 'name': '宇宙简史',
  'price': Decimal('22.10')},
 {'id': 8, 'cat_id': 3, 'name': '自然史',
  'price': Decimal('26.10')}]
&lt;/code&gt;
&lt;/pre&gt;
&lt;ul&gt;&lt;li&gt;distinct() 与 SQL 的 distinct 语句行为一致&lt;/li&gt;
&lt;/ul&gt;&lt;pre&gt;
&lt;code&gt;books = session \
    .query(Book.cat_id) \
    .distinct(Book.cat_id) \
    .all()
print([dict(zip(v.keys(), v)) for v in books])
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;结果&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;[{'cat_id': 1}, {'cat_id': 2},
 {'cat_id': 3}]
&lt;/code&gt;
&lt;/pre&gt;
&lt;ul&gt;&lt;li&gt;&lt;code&gt;order_by()&lt;/code&gt; 将记录按照某个字段进行排序&lt;/li&gt;
&lt;/ul&gt;&lt;pre&gt;
&lt;code&gt;# 图书按 ID 降序排列
# 如果要升序排列，去掉 .desc() 即可
books = session \
    .query(Book.id, Book.name) \
    .filter(Book.id &amp;gt; 8) \
    .order_by(Book.id.desc()) \
    .all()
print([dict(zip(v.keys(), v)) for v in books])
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;结果&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;[{'id': 10, 'name': '万物简史'},
 {'id': 9, 'name': '人类简史'}]
&lt;/code&gt;
&lt;/pre&gt;
&lt;ul&gt;&lt;li&gt;scalar() 返回调用 one() 后得到的结果的第一列值&lt;/li&gt;
&lt;/ul&gt;&lt;pre&gt;
&lt;code&gt;book_name = session \
    .query(Book.name) \
    .filter(Book.id == 10)\
    .scalar()
print(book_name)
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;结果&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;万物简史
&lt;/code&gt;
&lt;/pre&gt;
&lt;ul&gt;&lt;li&gt;exist() 查看记录是否存在&lt;/li&gt;
&lt;/ul&gt;&lt;pre&gt;
&lt;code&gt;# 查看 ID 大于 10 的图书是否存在
from sqlalchemy.sql import exists
is_exist = session \
    .query(exists().where(Book.id &amp;gt; 10)) \
    .scalar()
print(is_exist)
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;结果&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;False
&lt;/code&gt;
&lt;/pre&gt;

&lt;p&gt;通过 OR 连接条件的情况也多，比如我要获取 &lt;code&gt;cat_id&lt;/code&gt; 等于 1 或者价格大于 35 的书&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;from sqlalchemy import or_
books = session.query(Book) \
    .filter(or_(Book.cat_id == 1,
                Book.price &amp;gt; 35)) \
    .all()
print([v.to_dict() for v in books])
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;执行，得到结果&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;[{'id': 1, 'cat_id': 1, 'name': '生死疲劳',
  'price': Decimal('40.40')},
 {'id': 2, 'cat_id': 1, 'name': '皮囊',
  'price': Decimal('31.80')},
 {'id': 4, 'cat_id': 2, 'name': '耶路撒冷三千年',
  'price': Decimal('55.60')},
 {'id': 5, 'cat_id': 2, 'name': '国家宝藏',
  'price': Decimal('52.80')},
 {'id': 9, 'cat_id': 3, 'name': '人类简史',
  'price': Decimal('40.80')}]
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;使用方式和 AND 查询类似，从 sqlalchemy 引入 &lt;code&gt;or_&lt;/code&gt;，然后将条件放入就 OK 了。&lt;/p&gt;

&lt;p&gt;现实情况下，我们很容易碰到 AND 和 OR 并存的查询。比如，我现在要查询价格大于 55 或者小于 25，同时 &lt;code&gt;cat_id&lt;/code&gt; 不等于 1 的图书&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;from sqlalchemy import or_
books = session.query(Book) \
    .filter(or_(Book.price &amp;gt; 55,
                Book.price &amp;lt; 25),
            Book.cat_id != 1) \
    .all()
print([v.to_dict() for v in books])
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;结果&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;[{'id': 4, 'cat_id': 2, 'name': '耶路撒冷三千年',
  'price': Decimal('55.60')},
 {'id': 7, 'cat_id': 3, 'name': '宇宙简史',
  'price': Decimal('22.10')}]
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;又如，查询图书的数量，图书满足两个要求中的一个即可：一是 &lt;code&gt;cat_id&lt;/code&gt; 大于 5；二是 &lt;code&gt;cat_id&lt;/code&gt; 小于 2 且价格大于 40。可以这样&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;from sqlalchemy import or_, and_
count = session.query(Book) \
    .filter(or_(Book.cat_id &amp;gt; 5,
                and_(Book.cat_id &amp;lt; 2,
                     Book.price &amp;gt; 40))) \
    .count()
print(count)
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;结果&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;1
&lt;/code&gt;
&lt;/pre&gt;

&lt;p&gt;开发中，我们经常会碰到根据传入的参数构造查询条件进行查询。比如&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;如果接收到非 0 的 &lt;code&gt;cat_id&lt;/code&gt;，需要限制 &lt;code&gt;cat_id&lt;/code&gt; 等于 0&lt;/li&gt;
&lt;li&gt;如果接收到非 0 的 price，需要限制 price 等于传入的 price&lt;/li&gt;
&lt;li&gt;如果接收到非 0 的 &lt;code&gt;min_price&lt;/code&gt;，需要限制 price 大于等于 &lt;code&gt;min_price&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;如果接收到非 0 的 &lt;code&gt;max_price&lt;/code&gt;，需要限制 price 小于等于 &lt;code&gt;max_price&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;我们就可以编写类似的代码&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;# 请求参数，这里只是占位，实际由用户提交的请求决定
params = {'cat_id': 1}

conditions = []
if params.get('cat_id', 0):
    conditions.append(Book.cat_id == params['cat_id'])
if params.get('price', 0):
    conditions.append(Book.price == params['price'])
if params.get('min_price', 0):
    conditions.append(Book.price &amp;gt;= params['min_price'])
if params.get('max_price', 0):
    conditions.append(Book.price &amp;lt;= params['max_price'])
books = session.query(Book).filter(*conditions).all()

print([v.to_dict() for v in books])
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;结果&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;[{'id': 1, 'cat_id': 1, 'name': '生死疲劳',
  'price': Decimal('40.40')},
 {'id': 2, 'cat_id': 1, 'name': '皮囊',
  'price': Decimal('31.80')}]
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;OR 查询类似，将列表解包传给 &lt;code&gt;or_()&lt;/code&gt; 即可。&lt;/p&gt;
&lt;p&gt;如果需求更复杂，AND 和 OR 都可能出现，这个时候根据情况多建几个列表实现。这里只向大家说明大致的思路，就不举具体的例子了。&lt;/p&gt;
&lt;p&gt;当然，如果都是等值查询的话，比如只有这两种情况&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;如果接收到非 0 的 &lt;code&gt;cat_id&lt;/code&gt;，需要限制 &lt;code&gt;cat_id&lt;/code&gt; 等于 0&lt;/li&gt;
&lt;li&gt;如果接收到非 0 的 price，需要限制 price 等于传入的 price&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;可以使用字典的解包给 &lt;code&gt;filter_by()&lt;/code&gt; 传参&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;# 请求参数，这里只是占位，实际由用户提交的请求决定
params = {'price': 31.1}

condition_dict = {}
if params.get('cat_id', 0):
    condition_dict['cat_id'] = params['cat_id']
if params.get('price', 0):
    condition_dict['price'] = params['price']
books = session.query(Book) \
    .filter_by(**condition_dict) \
    .all()

print([v.to_dict() for v in books])
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;结果&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;[{'id': 6, 'cat_id': 3, 'name': '时间简史',
  'price': Decimal('31.10')}]
&lt;/code&gt;
&lt;/pre&gt;

&lt;p&gt;除了上面看到的 ==、&amp;gt;、&amp;gt;=、&amp;lt;、&amp;lt;=、!= 之外，还有几个比较常用&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;# 查询 ID 在 1、3、5 中的记录
books = session.query(Book) \
        .filter(Book.id.in_([1, 3, 5])) \
        .all()
&lt;/code&gt;
&lt;/pre&gt;
&lt;pre&gt;
&lt;code&gt;# 查询名称包含「时间简史」的图书
books = session.query(Book) \
    .filter(Book.name.contains('时间简史')) \
    .all()
&lt;/code&gt;
&lt;/pre&gt;
&lt;ul&gt;&lt;li&gt;&lt;code&gt;FIN_IN_SET()&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;pre&gt;
&lt;code&gt;# 查询名称包含「时间简史」的图书
# 这里显然应该用 INSTR() 的用法
# FIND_IN_SET() 一般用于逗号分隔的 ID 串查找
# 这里使用 FIND_IN_SET()，旨在说明用法

from sqlalchemy import func
books = session.query(Book) \
    .filter(func.find_in_set('时间简史', Book.name)) \
    .all()
&lt;/code&gt;
&lt;/pre&gt;
&lt;pre&gt;
&lt;code&gt;# 查询名称以「简史」结尾的图书
books = session.query(Book) \
        .filter(Book.name.like('%简史')) \
        .all()
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;上面的 IN、INSTR、&lt;code&gt;FIN_IN_SET&lt;/code&gt;、LIKE 都可以使用 ~ 符号取反。比如&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;# 查询 ID 不在 1 到 9 之间的记录
books = session.query(Book) \
    .filter(~Book.id.in_(range(1, 10))) \
    .all()
&lt;/code&gt;
&lt;/pre&gt;

&lt;p&gt;查询名称包含「简史」的图书的 ID 和名称。如下&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;books = session.query(Book.id, Book.name) \
    .filter(Book.name.contains('简史')) \
    .all()
print([dict(zip(v.keys(), v)) for v in books])
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;结果&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;[{'id': 6, 'name': '时间简史'},
 {'id': 7, 'name': '宇宙简史'},
 {'id': 9, 'name': '人类简史'},
 {'id': 10, 'name': '万物简史'}]
&lt;/code&gt;
&lt;/pre&gt;

&lt;h2 id=&quot;91-内连接&quot;&gt;9.1 内连接&lt;/h2&gt;
&lt;p&gt;获取分类为「科技」，且价格大于 40 的图书&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;# 如果 ORM 对象中定义有外键关系
# 那么 join() 中可以不指定关联关系
# 否则，必须要        
books = session \
    .query(Book.id,
           Book.name.label('book_name'),
           Category.name.label('cat_name')) \
    .join(Category, Book.cat_id == Category.id) \
    .filter(Category.name == '科技',
            Book.price &amp;gt; 40) \
    .all()
print([dict(zip(v.keys(), v)) for v in books])
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;结果&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;[{'id': 9, 'book_name': '人类简史',
  'cat_name': '科技'}]
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;统计各个分类的图书的数量&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;from sqlalchemy import func
books = session \
    .query(Category.name.label('cat_name'),
           func.count(Book.id).label('book_num')) \
    .join(Book, Category.id == Book.cat_id) \
    .group_by(Category.id) \
    .all()
print([dict(zip(v.keys(), v)) for v in books])
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;结果&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;[{'cat_name': '文学', 'book_num': 2},
 {'cat_name': '人文社科', 'book_num': 3},
 {'cat_name': '科技', 'book_num': 5}]
&lt;/code&gt;
&lt;/pre&gt;

&lt;p&gt;为方便说明，我们仅在这一小节中向 books 表中加入如下数据&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;+----+--------+-----------------+-------+
| id | cat_id | name            | price |
+----+--------+-----------------+-------+
| 11 |      5 | 人性的弱点      | 54.40 |
+----+--------+-----------------+-------+
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;查看 ID 大于等于 9 的图书的分类信息&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;# outerjoin 默认是左连接
# 如果 ORM 对象中定义有外键关系
# 那么 outerjoin() 中可以不指定关联关系
# 否则，必须要
books = session \
    .query(Book.id.label('book_id'),
           Book.name.label('book_name'),
           Category.id.label('cat_id'),
           Category.name.label('cat_name')) \
    .outerjoin(Category, Book.cat_id == Category.id) \
    .filter(Book.id &amp;gt;= 9) \
    .all()
print([dict(zip(v.keys(), v)) for v in books])
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;结果&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;[{'book_id': 9, 'book_name': '人类简史',
  'cat_id': 3, 'cat_name': '科技'},
 {'book_id': 10, 'book_name': '万物简史',
  'cat_id': 3, 'cat_name': '科技'},
 {'book_id': 11, 'book_name': '人性的弱点',
  'cat_id': None, 'cat_name': None}]

&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;注意最后一条记录。&lt;/p&gt;

&lt;p&gt;当碰到复杂的查询，比如有 AND、有 OR、还有连接查询时，有时可能得不到预期的结果，这时我们可以打出最终的 SQL 帮助我们来查找错误。&lt;/p&gt;
&lt;p&gt;以上一节的外连接为例说下怎么打印最终 SQL&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;q = session \
    .query(Book.id.label('book_id'),
           Book.name.label('book_name'),
           Category.id.label('cat_id'),
           Category.name.label('cat_name')) \
    .outerjoin(Category, Book.cat_id == Category.id) \
    .filter(Book.id &amp;gt;= 9)

raw_sql = q.statement \
    .compile(compile_kwargs={&quot;literal_binds&quot;: True})
print(raw_sql)
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;其中，q 为 sqlalchemy.orm.query.Query 类的对象。&lt;/p&gt;
&lt;p&gt;结果&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;SELECT books.id AS book_id, books.name AS book_name, categories.id AS cat_id, categories.name AS cat_name 
FROM books LEFT OUTER JOIN categories ON books.cat_id = categories.id 
WHERE books.id &amp;gt;= 9
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;至此，SQLAlchemy ORM 常用的一些查询方法和技巧已介绍完毕，希望能帮助到有需要的朋友。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;原文链接：&lt;a href=&quot;http://www.kevinbai.com/articles/30.html&quot;&gt;http://www.kevinbai.com/articles/30.html&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;关注公众号「小小后端」获取最新文章推送！&lt;/strong&gt;&lt;/p&gt;
</description>
<pubDate>Sun, 20 Sep 2020 23:36:00 +0000</pubDate>
<dc:creator>kevinbai_cn</dc:creator>
<og:description>之前做查询一直觉得直接拼 SQL 比较方便，用了 SQLAlchemy 的 ORM 查询之后，发现也还可以，还提高了可读性。 这篇文章主要说说 SQLAlchemy 常用的 ORM 查询方式，偏实践。</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/kevinbai/p/13703574.html</dc:identifier>
</item>
<item>
<title>我告诉你一个 AtomicInteger 的惊天大秘密 - 程序员cxuan</title>
<link>http://www.cnblogs.com/cxuanBlog/p/13703563.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/cxuanBlog/p/13703563.html</guid>
<description>&lt;p&gt;i++ 不是线程安全的操作，因为它不是一个原子性操作。&lt;/p&gt;
&lt;p&gt;那么，如果我想要达到类似 i++ 的这种效果，我应该使用哪些集合或者说工具类呢？&lt;/p&gt;
&lt;p&gt;在 JDK1.5 之前，为了确保在多线程下对某&lt;code&gt;基本&lt;/code&gt;数据类型或者&lt;code&gt;引用&lt;/code&gt;数据类型运算的原子性，必须依赖于外部关键字 &lt;code&gt;synchronized&lt;/code&gt;，但是这种情况在 JDK1.5 之后发生了改观，当然你依然可以使用 synchronized 来保证原子性，我们这里所说的一种线程安全的方式是原子性的工具类，比如 &lt;strong&gt;AtomicInteger、AtomicBoolean&lt;/strong&gt; 等。这些原子类都是线程安全的工具类，他们同时也是 &lt;code&gt;Lock-Free&lt;/code&gt; 的。下面我们就来一起认识一下这些工具类以及 Lock - Free 是个什么概念。&lt;/p&gt;
&lt;h2 id=&quot;了解-atomicinteger&quot;&gt;了解 AtomicInteger&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;AtomicInteger&lt;/code&gt; 是 JDK 1.5 新添加的工具类，我们首先来看一下它的继承关系&lt;/p&gt;
&lt;img src=&quot;https://s1.ax1x.com/2020/09/20/wosPYV.png&quot; alt=&quot;AtomicInteger01&quot; border=&quot;0&quot;/&gt;&lt;p&gt;与 int 的包装类 Integer 一样，都是继承于 &lt;code&gt;Number&lt;/code&gt; 类的。&lt;/p&gt;
&lt;img src=&quot;https://s1.ax1x.com/2020/09/20/wos4pT.png&quot; alt=&quot;AtomicInteger02&quot; border=&quot;0&quot;/&gt;&lt;p&gt;这个 Number 类是基本数据类型的包装类，一般和数据类型有关的对象都会继承于 Number 类。&lt;/p&gt;
&lt;p&gt;它的继承体系很简单，下面我们来看一下它的基本属性和方法&lt;/p&gt;
&lt;h3 id=&quot;atomicinteger-的基本属性&quot;&gt;AtomicInteger 的基本属性&lt;/h3&gt;
&lt;p&gt;AtomicInteger 的基本属性有三个&lt;/p&gt;
&lt;img src=&quot;https://s1.ax1x.com/2020/09/20/wTiyJH.png&quot; alt=&quot;wTiyJH.png&quot; border=&quot;0&quot;/&gt;&lt;p&gt;&lt;code&gt;Unsafe&lt;/code&gt; 是 &lt;code&gt;sun.misc&lt;/code&gt; 包下面的类，AtomicInteger 主要是依赖于 sun.misc.Unsafe 提供的一些 native 方法保证操作的原子性。&lt;/p&gt;
&lt;p&gt;Unsafe 的 &lt;code&gt;objectFieldOffset&lt;/code&gt; 方法可以获取成员属性在内存中的地址相对于对象内存地址的偏移量。说得简单点就是找到这个变量在内存中的地址，便于后续通过内存地址直接进行操作，这个值就是 &lt;code&gt;value&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;这个我们后面会再细说&lt;/p&gt;
&lt;p&gt;&lt;code&gt;value&lt;/code&gt; 就是 AtomicIneger 的值。&lt;/p&gt;
&lt;h3 id=&quot;atomicinteger-的构造方法&quot;&gt;AtomicInteger 的构造方法&lt;/h3&gt;
&lt;p&gt;继续往下看，AtomicInteger 的构造方法只有两个，一个是无参数的构造方法，无参数的构造方法默认的 value 初始值是 0 ，带参数的构造方法可以指定初始值。&lt;/p&gt;
&lt;img src=&quot;https://s1.ax1x.com/2020/09/20/wosWt0.png&quot; alt=&quot;AtomicInteger04&quot; border=&quot;0&quot;/&gt;&lt;h3 id=&quot;atomicinteger-中的方法&quot;&gt;AtomicInteger 中的方法&lt;/h3&gt;
&lt;p&gt;下面我们就来聊一下 AtomicInteger 中的方法。&lt;/p&gt;
&lt;h4 id=&quot;get--和-set&quot;&gt;Get 和 Set&lt;/h4&gt;
&lt;p&gt;我们首先来看一下最简单的 get 、set 方法：&lt;/p&gt;
&lt;p&gt;&lt;code&gt;get()&lt;/code&gt; : 获取当前 AtomicInteger 的值&lt;/p&gt;
&lt;p&gt;&lt;code&gt;set()&lt;/code&gt; : 设置当前 AtomicInteger 的值&lt;/p&gt;
&lt;p&gt;get() 可以原子性的读取 AtomicInteger 中的数据，set() 可以原子性的设置当前的值，因为 get() 和 set() 最终都是作用于 value 变量，而 value 是由 &lt;code&gt;volatile&lt;/code&gt; 修饰的，所以 get 、set 相当于都是对内存进行读取和设置。如下图所示&lt;/p&gt;
&lt;img src=&quot;https://s1.ax1x.com/2020/09/20/wosRkq.png&quot; alt=&quot;AtomicInteger05&quot; border=&quot;0&quot;/&gt;&lt;p&gt;我们上面提到了 i++ 和 i++ 的非原子性操作，我们说可以使用 AtomicInteger 中的方法进行替换。&lt;/p&gt;
&lt;h4 id=&quot;incremental-操作&quot;&gt;Incremental 操作&lt;/h4&gt;
&lt;p&gt;AtomicInteger 中的 &lt;code&gt;Incremental&lt;/code&gt; 相关方法可以满足我们的需求&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;code&gt;getAndIncrement()&lt;/code&gt; : 原子性的增加当前的值，并把结果返回。相当于 &lt;code&gt;i++&lt;/code&gt; 的操作。&lt;/li&gt;
&lt;/ul&gt;&lt;img src=&quot;https://www.cnblogs.com/Users/mr.l/Library/Application%20Support/typora-user-images/image-20200911085857825.png&quot; alt=&quot;image-20200911085857825&quot;/&gt;&lt;p&gt;为了验证是不是线程安全的，我们用下面的例子进行测试&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;public class TAtomicTest implements Runnable{

    AtomicInteger atomicInteger = new AtomicInteger();

    @Override
    public void run() {
        for(int i = 0;i &amp;lt; 10000;i++){
            System.out.println(atomicInteger.getAndIncrement());
        }
    }
    public static void main(String[] args) {

        TAtomicTest tAtomicTest = new TAtomicTest();

        Thread t1 = new Thread(tAtomicTest);
        Thread t2 = new Thread(tAtomicTest);
        t1.start();
        t2.start();
    }

}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;通过输出结果你会发现它是一个线程安全的操作，你可以修改 i 的值，但是最后的结果仍然是 i - 1，因为先取值，然后再 + 1，它的示意图如下。&lt;/p&gt;
&lt;img src=&quot;https://s1.ax1x.com/2020/09/20/wosg7n.png&quot; alt=&quot;AtomicInteger06&quot; border=&quot;0&quot;/&gt;&lt;ul&gt;&lt;li&gt;&lt;code&gt;incrementAndGet&lt;/code&gt; 与此相反，首先执行 + 1 操作，然后返回自增后的结果，该操作方法能够确保对 value 的原子性操作。如下图所示&lt;/li&gt;
&lt;/ul&gt;&lt;img src=&quot;https://s1.ax1x.com/2020/09/20/wosc0s.png&quot; alt=&quot;AtomicInteger07&quot; border=&quot;0&quot;/&gt;&lt;h4 id=&quot;decremental-操作&quot;&gt;Decremental 操作&lt;/h4&gt;
&lt;p&gt;与此相对，x-- 或者 x = x - 1 这样的自减操作也是原子性的。我们仍然可以使用 AtomicInteger 中的方法来替换&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;code&gt;getAndDecrement&lt;/code&gt; : 返回当前类型的 int 值，然后对 value 的值进行自减运算。下面是测试代码&lt;/li&gt;
&lt;/ul&gt;&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;class TAtomicTestDecrement implements Runnable{

    AtomicInteger atomicInteger = new AtomicInteger(20000);

    @Override
    public void run() {
        for(int i = 0;i &amp;lt; 10000 ;i++){
            System.out.println(atomicInteger.getAndDecrement());
        }
    }

    public static void main(String[] args) {

        TAtomicTestDecrement tAtomicTest = new TAtomicTestDecrement();

        Thread t1 = new Thread(tAtomicTest);
        Thread t2 = new Thread(tAtomicTest);
        t1.start();
        t2.start();

    }

}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;下面是 getAndDecrement 的示意图&lt;/p&gt;
&lt;img src=&quot;https://s1.ax1x.com/2020/09/20/wos6mj.png&quot; alt=&quot;AtomicInteger08&quot; border=&quot;0&quot;/&gt;&lt;ul&gt;&lt;li&gt;&lt;code&gt;decrementAndGet&lt;/code&gt;：同样的，decrementAndGet 方法就是先执行递减操作，然后再获取 value 的值，示意图如下&lt;/li&gt;
&lt;/ul&gt;&lt;img src=&quot;https://s1.ax1x.com/2020/09/20/wossXQ.png&quot; alt=&quot;AtomicInteger09&quot; border=&quot;0&quot;/&gt;&lt;h4 id=&quot;lazyset-方法&quot;&gt;LazySet 方法&lt;/h4&gt;
&lt;p&gt;volatile 有内存屏障你知道吗？&lt;/p&gt;
&lt;p&gt;内存屏障是啥啊？&lt;/p&gt;
&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;内存屏障，也称&lt;code&gt;内存栅栏&lt;/code&gt;，内存栅障，屏障指令等， 是一类同步屏障指令，是 CPU 或编译器在对内存随机访问的操作中的一个同步点，使得此点之前的所有读写操作都执行后才可以开始执行此点之后的操作。也是一个让CPU 处理单元中的内存状态对其它处理单元可见的一项技术。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;CPU 使用了很多优化，使用缓存、指令重排等，其最终的目的都是为了性能，也就是说，当一个程序执行时，只要最终的结果是一样的，指令是否被重排并不重要。所以指令的执行时序并不是顺序执行的，而是乱序执行的，这就会带来很多问题，这也促使着内存屏障的出现。&lt;/p&gt;
&lt;p&gt;语义上，内存屏障之前的所有写操作都要写入内存；内存屏障之后的读操作都可以获得同步屏障之前的写操作的结果。因此，对于敏感的程序块，写操作之后、读操作之前可以插入内存屏障。&lt;/p&gt;
&lt;p&gt;内存屏障的开销非常轻量级，但是再小也是有开销的，LazySet 的作用正是如此，它会以普通变量的形式来读写变量。&lt;/p&gt;
&lt;p&gt;也可以说是：&lt;strong&gt;懒得设置屏障了&lt;/strong&gt;&lt;/p&gt;
&lt;img src=&quot;https://s1.ax1x.com/2020/09/20/wosD1S.png&quot; alt=&quot;AtomicInteger10&quot; border=&quot;0&quot;/&gt;&lt;h4 id=&quot;getandset-方法&quot;&gt;GetAndSet 方法&lt;/h4&gt;
&lt;p&gt;以原子方式设置为给定值并返回旧值。&lt;/p&gt;
&lt;p&gt;它的源码就是调用了一下 unsafe 中的 getAndSetInt 方法，如下所示&lt;/p&gt;
&lt;img src=&quot;https://s1.ax1x.com/2020/09/20/woswff.png&quot; alt=&quot;AtomicInteger11&quot; border=&quot;0&quot;/&gt;&lt;p&gt;就是先进行循环，然后调用 &lt;code&gt;getIntVolatile&lt;/code&gt; 方法，这个方法我在 cpp 中没有找到，找到的小伙伴们记得及时告诉让我学习一下。&lt;/p&gt;
&lt;p&gt;循环直到 compareAndSwapInt 返回 false，这就说明使用 CAS 并没有更新为新的值，所以 var5 返回的就是最新的内存值。&lt;/p&gt;
&lt;h4 id=&quot;cas-方法&quot;&gt;CAS 方法&lt;/h4&gt;
&lt;p&gt;我们一直常说的 CAS 其实就是 &lt;code&gt;CompareAndSet&lt;/code&gt; 方法，这个方法顾名思义，就是 &lt;strong&gt;比较并更新&lt;/strong&gt; 的意思，当然这是字面理解，字面理解有点偏差，其实人家的意思是先比较，如果满足那么再进行更新。&lt;/p&gt;
&lt;img src=&quot;https://s1.ax1x.com/2020/09/20/wosBp8.png&quot; alt=&quot;AtomicInteger12&quot; border=&quot;0&quot;/&gt;&lt;p&gt;上面给出了 CAS Java 层面的源码，JDK 官方给它的解释就是 &lt;strong&gt;如果当前值等于 expect 的值，那么就以原子性的方式将当前值设置为 update 给定值&lt;/strong&gt;，这个方法会返回一个 boolean 类型，如果是 true 就表示比较并更新成功，否则表示失败。&lt;/p&gt;
&lt;p&gt;CAS 同时也是一种无锁并发机制，也称为 &lt;code&gt;Lock Free&lt;/code&gt;，所以你觉得 Lock Free 很高大上吗？并没有。&lt;/p&gt;
&lt;p&gt;下面我们构建一个加锁解锁的 &lt;code&gt;CASLock&lt;/code&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;class CASLock {

    AtomicInteger atomicInteger = new AtomicInteger();
    Thread currentThread = null;

    public void tryLock() throws Exception{

        boolean isLock = atomicInteger.compareAndSet(0, 1);
        if(!isLock){
            throw new Exception(&quot;加锁失败&quot;);
        }

        currentThread = Thread.currentThread();
        System.out.println(currentThread + &quot; tryLock&quot;);

    }

    public void unlock() {

        int lockValue = atomicInteger.get();
        if(lockValue == 0){
            return;
        }
        if(currentThread == Thread.currentThread()){
            atomicInteger.compareAndSet(1,0);
            System.out.println(currentThread + &quot; unlock&quot;);
        }
    }

    public static void main(String[] args) {

        CASLock casLock = new CASLock();

        for(int i = 0;i &amp;lt; 5;i++){

            new Thread(() -&amp;gt; {
                try {
                    casLock.tryLock();
                    Thread.sleep(10000);
                } catch (Exception e) {
                    e.printStackTrace();
                }finally {
                    casLock.unlock();
                }
            }).start();
        }

    }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;在上面的代码中，我们构建了一个 CASLock，在 &lt;code&gt;tryLock&lt;/code&gt; 方法中，我们先使用 CAS 方法进行更新，如果更新不成功则抛出异常，并把当前线程设置为加锁线程。在 &lt;code&gt;unLock&lt;/code&gt; 方法中，我们先判断当前值是否为 0 ，如果是 0 就是我们愿意看到的结果，直接返回。否则是 1，则表示当前线程还在加锁，我们再来判断一下当前线程是否是加锁线程，如果是则执行解锁操作。&lt;/p&gt;
&lt;p&gt;那么我们上面提到的 compareAndSet，它其实可以解析为如下操作&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;// 伪代码

// 当前值
int v = 0;
int a = 0;
int b = 1;

if(compare(0,0) == true){
  set(0,1);
}
else{
  // 继续向下执行
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;也可以拿生活场景中的买票举例子，你去景区旅游肯定要持票才能进，如果你拿着是假票或者不符合景区的票肯定是能够被识别出来的，如果你没有拿票拿你也肯定进不去景区。&lt;/p&gt;
&lt;p&gt;废话少说，这就祭出来 compareAndSet 的示意图&lt;/p&gt;
&lt;img src=&quot;https://s1.ax1x.com/2020/09/20/wosNTI.png&quot; alt=&quot;AtomicInteger14&quot; border=&quot;0&quot;/&gt;&lt;ul&gt;&lt;li&gt;&lt;code&gt;weakCompareAndSet&lt;/code&gt;: 妈的非常认真看了好几遍，发现 JDK1.8 的这个方法和 compareAndSet 方法完全一摸一样啊，坑我。。。&lt;/li&gt;
&lt;/ul&gt;&lt;img src=&quot;https://s1.ax1x.com/2020/09/20/wosYmd.png&quot; alt=&quot;AtomicInteger15&quot; border=&quot;0&quot;/&gt;&lt;p&gt;但是真的是这样么？并不是，JDK 源码很博大精深，才不会设计一个重复的方法，你想想 JDK 团队也不是会犯这种低级团队，但是原因是什么呢？&lt;/p&gt;
&lt;p&gt;《Java 高并发详解》这本书给出了我们一个答案&lt;/p&gt;
&lt;img src=&quot;https://s1.ax1x.com/2020/09/20/wosr6g.png&quot; alt=&quot;AtomicInteger16&quot; border=&quot;0&quot;/&gt;&lt;h4 id=&quot;addandget&quot;&gt;AddAndGet&lt;/h4&gt;
&lt;p&gt;AddAndGet 和 getAndIncrement、getAndAdd、incrementAndGet 等等方法都是使用了 do ... while + CAS 操作，其实也就相当于是一个自旋锁，如果 CAS 修改成功就会一直循环，修改失败才会返回。示意图如下&lt;/p&gt;
&lt;img src=&quot;https://s1.ax1x.com/2020/09/20/wosGOH.png&quot; alt=&quot;AtomicInteger17&quot; border=&quot;0&quot;/&gt;&lt;h3 id=&quot;深入-atomicinteger&quot;&gt;深入 AtomicInteger&lt;/h3&gt;
&lt;p&gt;我们上面探讨了 AtomicInteger 的具体使用，同时我们知道 AtomicInteger 是依靠 volatile 和 CAS 来保证原子性的，那么我们下面就来分析一下为什么 CAS 能够保证原子性，它的底层是什么？AtomicInteger 与乐观锁又有什么关系呢？&lt;/p&gt;
&lt;h4 id=&quot;atomicinteger-的底层实现原理&quot;&gt;AtomicInteger 的底层实现原理&lt;/h4&gt;
&lt;p&gt;我们再来瞧瞧这个可爱的 &lt;code&gt;compareAndSetL(CAS)&lt;/code&gt; 方法，为什么就这两行代码就保证原子性了？&lt;/p&gt;
&lt;img src=&quot;https://s1.ax1x.com/2020/09/20/wos86e.png&quot; alt=&quot;AtomicInteger18&quot; border=&quot;0&quot;/&gt;&lt;p&gt;我们可以看到，这个 CAS 方法相当于是调用了 unsafe 中的 &lt;code&gt;compareAndSwapInt&lt;/code&gt; 方法，我们进到 unsafe 方能发中看一下具体实现。&lt;/p&gt;
&lt;img src=&quot;https://s1.ax1x.com/2020/09/20/wos3lD.png&quot; alt=&quot;AtomicInteger19&quot; border=&quot;0&quot;/&gt;&lt;p&gt;compareAndSwapInt 是 &lt;code&gt;sun.misc&lt;/code&gt; 中的方法，这个方法是一个 &lt;code&gt;native&lt;/code&gt; 方法，它的底层是 C/C++ 实现的，所以我们需要看 C/C++ 的源码。&lt;/p&gt;
&lt;p&gt;知道 C/C++ 的牛逼之处了么。使用 Java 就是玩应用和架构的，C/C++ 是玩服务器、底层的。&lt;/p&gt;
&lt;p&gt;compareAndSwapInt 的源码在 &lt;code&gt;jdk8u-dev/hotspot/src/share/vm/prims/unsafe.app&lt;/code&gt; 路径下，它的源码实现是&lt;/p&gt;
&lt;img src=&quot;https://s1.ax1x.com/2020/09/20/wosMY6.png&quot; alt=&quot;AtomicInteger20&quot; border=&quot;0&quot;/&gt;&lt;p&gt;也就是 &lt;code&gt;Unsafe_CompareAndSwapInt&lt;/code&gt; 方法，我们找到这个方法&lt;/p&gt;
&lt;img src=&quot;https://s1.ax1x.com/2020/09/20/wosKFx.png&quot; alt=&quot;AtomicInteger21&quot; border=&quot;0&quot;/&gt;&lt;p&gt;C/C++ 源码我也看不懂，但是这不妨碍我们找到关键代码 &lt;code&gt;Atomic::cmpxchg&lt;/code&gt; ，cmpxchg 是 x86 CPU 架构的汇编指令，它的主要作用就是比较并交换操作数。我们继续往下跟找一下这个指令的定义。&lt;/p&gt;
&lt;p&gt;我们会发现对应不同的 os，其底层实现方式不一样&lt;/p&gt;
&lt;img src=&quot;https://s1.ax1x.com/2020/09/20/wos1SO.png&quot; alt=&quot;AtomicInteger22&quot; border=&quot;0&quot;/&gt;&lt;p&gt;我们找到 Windows 的实现方式如下&lt;/p&gt;
&lt;img src=&quot;https://s1.ax1x.com/2020/09/20/wosQfK.png&quot; alt=&quot;AtomicInteger23&quot; border=&quot;0&quot;/&gt;&lt;p&gt;我们继续向下找，它其实定义的是第 216 行的代码，我们找进去&lt;/p&gt;
&lt;img src=&quot;https://s1.ax1x.com/2020/09/20/wosnT1.png&quot; alt=&quot;AtomicInteger24&quot; border=&quot;0&quot;/&gt;&lt;p&gt;此时就需要汇编指令和寄存器相关的知识了。&lt;/p&gt;
&lt;p&gt;上面的 &lt;code&gt;os::is-MP()&lt;/code&gt; 是多处理操作系统的接口，下面是 __asm ，它是 C/C++ 的关键字，用于调用内联汇编程序。&lt;/p&gt;
&lt;p&gt;__asm 中的代码是汇编程序，大致来说就是把 dest、exchange_value 、compare_value 的值都放在寄存器中，下面的 &lt;code&gt;LOCK_IF_MP&lt;/code&gt; 中代码的大致意思就是&lt;/p&gt;
&lt;img src=&quot;https://s1.ax1x.com/2020/09/20/wosmwR.png&quot; alt=&quot;AtomicInteger25&quot; border=&quot;0&quot;/&gt;&lt;p&gt;如果是多处理器的话就会执行 lock，然后进行比较操作。其中的 cmp 表示比较，mp 表示的就是 &lt;code&gt;MultiProcess&lt;/code&gt;，&lt;code&gt;je&lt;/code&gt; 表示相等跳转，L0 表示的是标识位。&lt;/p&gt;
&lt;p&gt;我们回到上面的汇编指令，我们可以看到，CAS 的底层就是 &lt;code&gt;cmpxchg&lt;/code&gt; 指令。&lt;/p&gt;
&lt;h4 id=&quot;乐观锁&quot;&gt;乐观锁&lt;/h4&gt;
&lt;p&gt;你有没有这个疑问，为什么 AtomicInteger 可以获取当前值，那为什么还会出现 &lt;code&gt;expectValue&lt;/code&gt; 和 &lt;code&gt;value&lt;/code&gt; 不一致的情况呢？&lt;/p&gt;
&lt;p&gt;因为 AtomicInteger 只是一个原子性的工具类，它不具有排他性，它不像是 &lt;code&gt;synchronized&lt;/code&gt; 或者是 &lt;code&gt;lock&lt;/code&gt; 一样具有互斥和排他性，还记得 AtomicInteger 中有两个方法 get 和 set 吗？它们只是用 &lt;code&gt;volatile&lt;/code&gt; 修饰了一下，而 volatile 不具有原子性，所以可能会存在 expectValue 和 value 的当前值不一致的情况，因此可能会出现重复修改。&lt;/p&gt;
&lt;p&gt;针对上面这种情况的解决办法有两种，一种是使用 &lt;code&gt;synchronized&lt;/code&gt; 和 &lt;code&gt;lock&lt;/code&gt; 等类似的加锁机制，这种锁具有独占性，也就是说同一时刻只能有一个线程来进行修改，这种方式能够保证原子性，但是相对开销比较大，这种锁也叫做悲观锁。另外一种解决办法是使用&lt;code&gt;版本号&lt;/code&gt;或者是 &lt;code&gt;CAS 方法&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;版本号&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;版本号机制是在数据表中加上一个 &lt;code&gt;version&lt;/code&gt; 字段来实现的，表示数据被修改的次数，当执行写操作并且写入成功后，version = version + 1，当线程 A 要更新数据时，在读取数据的同时也会读取 version 值，在提交更新时，若刚才读取到的 version 值为当前数据库中的 version 值相等时才更新，否则重试更新操作，直到更新成功。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;CAS 方法&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;还有一种方式就是 CAS 了，我们上面用了大量的篇幅来介绍 CAS 方法，那么我们认为你现在已经对其运行机制有一定的了解了，我们就不再阐述它的运行机制了。&lt;/p&gt;
&lt;p&gt;任何事情都是有利也有弊，软件行业没有完美的解决方案只有最优的解决方案，所以乐观锁也有它的弱点和缺陷，那就是 ABA 问题。&lt;/p&gt;
&lt;h4 id=&quot;aba-问题&quot;&gt;ABA 问题&lt;/h4&gt;
&lt;p&gt;ABA 问题说的是，如果一个变量第一次读取的值是 A，准备好需要对 A 进行写操作的时候，发现值还是 A，那么这种情况下，能认为 A 的值没有被改变过吗？可以是由 A -&amp;gt; B -&amp;gt; A 的这种情况，但是 AtomicInteger 却不会这么认为，它只相信它看到的，它看到的是什么就是什么。举个例子来说&lt;/p&gt;
&lt;p&gt;假如现在有一个单链表，如下图所示&lt;/p&gt;
&lt;img src=&quot;https://s1.ax1x.com/2020/09/20/wosem9.png&quot; alt=&quot;AtomicInteger26&quot; border=&quot;0&quot;/&gt;&lt;p&gt;A.next = B ，B.next = null，此时有两个线程 T1 和 T2 分别从单链表中取出 A ，由于一些特殊原因，T2 把 A 改为 B ，然后又改为 A ，此时 T1 执行 CAS 方法，发现单链表仍然是 A ，就会执行 CAS 方法，虽然结果没错，但是这种操作会造成一些潜在的问题。&lt;/p&gt;
&lt;img src=&quot;https://s1.ax1x.com/2020/09/20/wosEy4.png&quot; alt=&quot;AtomicInteger27&quot; border=&quot;0&quot;/&gt;&lt;p&gt;此时还是一个单链表，两个线程 T1 和 T2 分别从单链表中取出 A ，然后 T1 把链表改为 ACD 如下图所示&lt;/p&gt;
&lt;img src=&quot;https://s1.ax1x.com/2020/09/20/wosVOJ.png&quot; alt=&quot;AtomicInteger28&quot; border=&quot;0&quot;/&gt;&lt;p&gt;此时 T2，发现内存值还是 A ，就会把 A 的值尝试替换为 B ，因为 B 的引用是 null，此时就会造成 C、D 处于游离态&lt;/p&gt;
&lt;img src=&quot;https://s1.ax1x.com/2020/09/20/wosCF0.png&quot; alt=&quot;AtomicInteger29&quot; border=&quot;0&quot;/&gt;&lt;p&gt;JDK 1.5 以后的 &lt;code&gt;AtomicStampedReference&lt;/code&gt; 类就提供了此种能力，其中的 &lt;code&gt;compareAndSet&lt;/code&gt; 方法就是首先检查当前值是否等于预期值，判断的标准就是当前引用和邮戳分别和预期引用和邮戳相等，如果全部相等，则以原子方式设置为给定的更新值。&lt;/p&gt;
&lt;img src=&quot;https://s1.ax1x.com/2020/09/20/woskSU.png&quot; alt=&quot;AtomicInteger30&quot; border=&quot;0&quot;/&gt;&lt;p&gt;好了，上面就是 Java 代码流程了，看到 native 我们知道又要撸 cpp 了。开撸&lt;/p&gt;
&lt;img src=&quot;https://s1.ax1x.com/2020/09/20/wosiWT.png&quot; alt=&quot;AtomicInteger31&quot; border=&quot;0&quot;/&gt;&lt;p&gt;简单解释一下就是 &lt;code&gt;UnsafeWrapper&lt;/code&gt; 就是包装器，换个名字而已。然后经过一些 JNI 的处理，因为 compareAndSwapOject 比较的是引用，所以需要经过 C++ 面向对象的转换。最主要的方法是 &lt;code&gt;atomic_compare_exchange_oop&lt;/code&gt;&lt;/p&gt;
&lt;img src=&quot;https://s1.ax1x.com/2020/09/20/wosAlF.png&quot; alt=&quot;AtomicInteger32&quot; border=&quot;0&quot;/&gt;&lt;p&gt;可以看到，又出现了熟悉的词汇 &lt;code&gt;cmpxchg&lt;/code&gt; ，也就是说 compareAndSwapOject 使用的还是 cmpxchg 原子性指令，只是它经过了一系列转换。&lt;/p&gt;
&lt;h3 id=&quot;后记&quot;&gt;后记&lt;/h3&gt;
&lt;p&gt;抛出来一个问题，CAS 能保证变量之间的可见性么？为什么？&lt;/p&gt;
&lt;p&gt;还有一个问题，&lt;code&gt;getIntVolatile&lt;/code&gt; 方法的 cpp 源码在哪里？怎么找？&lt;/p&gt;
&lt;p&gt;如果上面大佬们对这两个问题有兴趣，欢迎交流。&lt;/p&gt;
&lt;p&gt;关注公众号 程序员cxuan 回复 cxuan 领取优质资料。&lt;/p&gt;
&lt;p&gt;我自己写了六本 PDF ，非常硬核，链接如下&lt;/p&gt;
&lt;p&gt;我自己写了六本 PDF ，非常硬核，链接如下&lt;/p&gt;
&lt;p&gt;我自己写了六本 PDF ，非常硬核，链接如下&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1515111/202009/1515111-20200921070449940-116454700.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzI0ODk2NDIyMQ==&amp;amp;mid=2247485329&amp;amp;idx=1&amp;amp;sn=673f306bb229e73e8f671443488b42d4&amp;amp;chksm=e999f283deee7b95a3cce247907b6557bf5f228c85434fc6cbadf42b2ec4c64443742a8bea7a&amp;amp;token=581641926&amp;amp;lang=zh_CN#rd&quot;&gt;cxuan 呕心沥血肝了四本 PDF。&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzU2NDg0OTgyMA==&amp;amp;mid=2247494165&amp;amp;idx=1&amp;amp;sn=4e0247006bef89701529d765e6ce32a4&amp;amp;chksm=fc4617e6cb319ef0991ff70c8a769b92f59cf92122f27785b848604493653fdcc206d6830a23&amp;amp;token=794467841&amp;amp;lang=zh_CN#rd&quot;&gt;cxuan 又肝了两本 PDF&lt;/a&gt;&lt;/p&gt;
</description>
<pubDate>Sun, 20 Sep 2020 23:06:00 +0000</pubDate>
<dc:creator>程序员cxuan</dc:creator>
<og:description>i++ 不是线程安全的操作，因为它不是一个原子性操作。 那么，如果我想要达到类似 i++ 的这种效果，我应该使用哪些集合或者说工具类呢？ 在 JDK1.5 之前，为了确保在多线程下对某基本数据类型或者</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/cxuanBlog/p/13703563.html</dc:identifier>
</item>
<item>
<title>Gradle系列之Android Gradle高级配置 - 躬行之</title>
<link>http://www.cnblogs.com/jzmanu/p/13703204.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/jzmanu/p/13703204.html</guid>
<description>&lt;p&gt;本篇文章主要在之前学习的基础上，从实际开发的角度学习如何对 Android Gradle 来进行自定义以满足不同的开发需求，下面是 Gradle 系列的几篇文章：&lt;/p&gt;
&lt;p&gt;下面是主要内容：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;修改生成的Apk文件名&lt;/li&gt;
&lt;li&gt;版本信息统一管理&lt;/li&gt;
&lt;li&gt;隐藏签名文件信息&lt;/li&gt;
&lt;li&gt;动态配置AndroidManifest文件&lt;/li&gt;
&lt;li&gt;自定义BuildConfig&lt;/li&gt;
&lt;li&gt;动态添加自定义资源&lt;/li&gt;
&lt;li&gt;Java编译选项&lt;/li&gt;
&lt;li&gt;adb操作选项配置&lt;/li&gt;
&lt;li&gt;DEX选项配置&lt;/li&gt;
&lt;li&gt;自动起立未使用的资源&lt;/li&gt;
&lt;li&gt;突破65535方法限制&lt;/li&gt;
&lt;/ol&gt;&lt;h4 id=&quot;修改生成的apk文件名&quot;&gt;修改生成的Apk文件名&lt;/h4&gt;
&lt;p&gt;修改打包输出的 Apk 的文件名主要用到三个属性：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;applicationVariants //Android应用Gradle插件
libraryVariants     //Android库Gradle插件
testVariants        //上述两种插件都适用
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;下面是修改打包生成的 Apk 文件名的代码，参考如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;android{
    //...
    
    /**
     * 修改打包生成的apk的文件名
     */
    applicationVariants.all { variant -&amp;gt;
        variant.outputs.all { output -&amp;gt;
            if (output.outputFile != null &amp;amp;&amp;amp; output.outputFile.name.endsWith('.apk') &amp;amp;&amp;amp;
                    'release' == variant.buildType.name) {
                //输出文件名
                outputFileName = &quot;AndroidGradleProject_v${variant.versionName}_${buildTime()}.apk&quot;
            }
        }
    }   
}
//当前时间
def static buildTime() {
    def date = new Date()
    return date.format(&quot;yyyMMdd&quot;)
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;此时，执行 release 模式构建 Apk 的任务，生成的 Apk 的名字就修改了，当然还可以配置在 debug 模式下生成对应的文件名等。&lt;/p&gt;
&lt;h4 id=&quot;版本信息统一管理&quot;&gt;版本信息统一管理&lt;/h4&gt;
&lt;p&gt;每个应用都有一个版本，版本一般由三部分组成：major.minor.patch，第一个是主版本号，第二个是副版本号，第三个是补丁号，如 1.0.0 这种格式的版本号，在 Android 开发中最原始的版本配置方式就是在 build.gradle 中在 defaultConfig 中配置对应的版本号和版本名称，参考如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;//最原始的版本配置方式
android{
    defaultConfig {
        versionCode 1
        versionName &quot;1.0&quot;
        //...
    }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;实际开发中一般将这种版本相关的信息单独定义在一个独立的版本管理文件中进行统一管理，定义 version.gradle 文件如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;ext{
    //应用版本号、版本名称
    appversionCode = 1
    appVersionName = &quot;1.0&quot;
    //其他版本号...
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;然后在 build.gradle 中使用 version.gradle 文件中定义的版本号、版本名称即可，参考如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;//引入version.gradle文件
apply from: &quot;version.gradle&quot;
android {
    //...
    defaultConfig {
        //使用version.gradle里定义的版本号
        versionCode appversionCode
        //使用version.gradle里定义的版本名称
        versionName appVersionName
        //...
    }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;当然不只是应用的版本号，还有使用到的一些第三方的库的版本也可以使用这样的方式来统一管理。&lt;/p&gt;
&lt;h4 id=&quot;隐藏签名文件信息&quot;&gt;隐藏签名文件信息&lt;/h4&gt;
&lt;p&gt;签名文件信息是非常重要的信息，如果将签名文件信息直接配置到项目中将是不安全的，那么签名文件如何能够安全呢，签名文件放在本地是不安全的，那么只能放在服务器上才是安全的，打包的时候从服务器上读取签名文件信息即可，当然这个服务器也可以是一台专门用于打包正式 Apk 的电脑，将签名文件和密钥信息配置成环境变量，打包是直接从环境变量中读取签名文件和密钥信息即可。&lt;/p&gt;
&lt;p&gt;配置四个环境变量 STORE_FILE、STORE_PASSWORD、KEY_ALIAS、KEY_PASSWORD 分别对应签名文件、签名文件密码、签名文件密钥别名、签名文件密钥密码，环境变量的配置就不具体说了，代码参考如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;android {
    //签名文件配置
    signingConfigs {
        //读取配置的与签名文件信息对应的环境变量
        def appStoreFile = System.getenv('STORE_FILE')
        def appStorePassword = System.getenv('STORE_PASSWORD')
        def appKeyAlias = System.getenv('KEY_ALIAS')
        def appKeyPassword = System.getenv('KEY_PASSWORD')
        //如果获取不到相关签名文件信息，则使用默认的签名文件
        if(!appStoreFile || !appStorePassword || !keyAlias || !keyPassword){
            appStoreFile = &quot;debug.keystore&quot;
            appStorePassword = &quot;android&quot;
            appKeyAlias = &quot;androiddebugkey&quot;
            appKeyPassword = &quot;android&quot;
        }
        release {
            storeFile file(appStoreFile)
            storePassword appStorePassword
            keyAlias appKeyAlias
            keyPassword appKeyPassword
        }
        debug {
            //默认情况下，debug模式下的签名已配置为Android SDK自动生成的debug签名文件证书
            //.android/debug.keystore
        }
    }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;注意一点，配置好环境变量后，如果不能读取到新配置的环境变量，重启电脑后就能读取到了,至于如何使用专用的服务器进行打包、读取签名文件信息实践后再来介绍。&lt;/p&gt;
&lt;h4 id=&quot;动态配置androidmanifest文件&quot;&gt;动态配置AndroidManifest文件&lt;/h4&gt;
&lt;p&gt;动态配置 AndroidManifest 配置就是动态的去修改 AndroidManifest 文件中的一些内容，如友盟等第三方统计平台分析统计的时候，一般会要求要在 AndroidManifest 文件中指定渠道名称，如下所示：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-xml&quot;&gt;&amp;lt;meta-data android:value=&quot;CHANNEL_ID&quot; android:name=&quot;CHANNEL&quot;/&amp;gt;
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;这里 CHANNEL_ID 要替换成不同渠道的名称，如 baidu、miui 等各个渠道名称，那么如何动态的修改这些变化的参数呢，这里需要用到 Manifest 占位符和 manifestPlaceholder，manifestPlaceholder 是 ProductFlavor 的一个属性，是一个 Map 类型，可以配置多个占位符，具体代码参考如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;android{
    //维度
    flavorDimensions &quot;channel&quot;
    productFlavors{
        miui{
            dimension &quot;channel&quot;
            manifestPlaceholders.put(&quot;CHANNEL&quot;,&quot;google&quot;)
        }
        baidu{
            dimension &quot;channel&quot;
            manifestPlaceholders.put(&quot;CHANNEL&quot;,&quot;baidu&quot;)
        }
    }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;上述代码中配置了 flavorDimensions 属性，这个属性可以理解为维度，比如 release 和 debug 是一个维度、不同的渠道是一个维度、免费版本还是付费版本又是一个维度，如果这三个维度都要考虑，那么生成 Apk 的格式就是 2 * 2 * 2 供 8 个不同的 Apk，从 Gradle 3.0 开始不管是一个维度还是多个维度，都必须使用 flavorDimensions 来约束，上面代码中定义了一个维度 channel，再加上 buildType 中的 debug 和 release ，故此时生成不同 Apk 的个数是 4 个，如下图所示：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://user-gold-cdn.xitu.io/2019/9/1/16ced1895e93009e?w=359&amp;amp;h=202&amp;amp;f=jpeg&amp;amp;s=8366&quot; alt=&quot;channel.jpg&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;当然，如果没有配置 flavorDimensions 则会出现如下错误，具体如下：&lt;/p&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;Error:All flavors must now belong to a named flavor dimension.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;实际开发中根据实际情况配置对应的 flavorDimensions 即可。&lt;/p&gt;
&lt;p&gt;然后，在 AndroidManifest 文件中使用占位符介绍打包时传递过来的参数，在 AndroidManifest 文件中添加 如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-xml&quot;&gt;&amp;lt;meta-data android:value=&quot;${CHANNEL}&quot; android:name=&quot;channel&quot;/&amp;gt;
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;最后，执行对应的渠道包任务，如执行 assembleBaiduRelease 将会将 AndroidManifest 中的渠道替换成 baidu，可使用命令执行也可使用 Android Studio 选择对应的 task 来执行，执行命令如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;gradle assembleBaiduRelease
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;如果使用 Android Studio ,打开右侧 Gradle 控制面板，找到对应的 task 来执行相应的任务，如下图所示：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://user-gold-cdn.xitu.io/2019/9/1/16ced1895e8e543b?w=396&amp;amp;h=318&amp;amp;f=png&amp;amp;s=16079&quot; alt=&quot;assembleBaiduRelease&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;选择对应的 task 执行就会生成对应的 Apk，使用 Android Killer 反编译打开生成的 Apk ，查看 AndroidManifest 文件如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-xml&quot;&gt;&amp;lt;?xml version=&quot;1.0&quot; encoding=&quot;utf-8&quot; standalone=&quot;no&quot;?&amp;gt;
&amp;lt;manifest xmlns:android=&quot;http://schemas.android.com/apk/res/android&quot; package=&quot;com.manu.androidgradleproject&quot;&amp;gt;
    &amp;lt;application android:allowBackup=&quot;true&quot; android:icon=&quot;@mipmap/ic_launcher&quot; android:label=&quot;@string/app_name&quot; android:supportsRtl=&quot;true&quot; android:theme=&quot;@style/AppTheme&quot; roundIcon=&quot;@mipmap/ic_launcher_round&quot;&amp;gt;
        &amp;lt;!--AndroidManifest文件修改成功--&amp;gt;
        &amp;lt;meta-data android:name=&quot;channel&quot; android:value=&quot;baidu&quot;/&amp;gt;
        &amp;lt;activity android:name=&quot;com.manu.androidgradleproject.MainActivity&quot;&amp;gt;
            &amp;lt;intent-filter&amp;gt;
                &amp;lt;action android:name=&quot;android.intent.action.MAIN&quot;/&amp;gt;
                &amp;lt;category android:name=&quot;android.intent.category.LAUNCHER&quot;/&amp;gt;
            &amp;lt;/intent-filter&amp;gt;
        &amp;lt;/activity&amp;gt;
        &amp;lt;meta-data android:name=&quot;android.support.VERSION&quot; android:value=&quot;26.1.0&quot;/&amp;gt;
        &amp;lt;meta-data android:name=&quot;android.arch.lifecycle.VERSION&quot; android:value=&quot;27.0.0-SNAPSHOT&quot;/&amp;gt;
    &amp;lt;/application&amp;gt;
&amp;lt;/manifest&amp;gt;

&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;上述案列中，渠道的名称是一致的，可以通过遍历很方便的完成渠道名称的替换，参考如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;productFlavors.all{ flavor -&amp;gt;
    manifestPlaceholders.put(&quot;CHANNEL&quot;,name)
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;这一小节重要的一点就是关于 manifestPlaceholders 占位符的使用。&lt;/p&gt;
&lt;h4 id=&quot;自定义buildconfig&quot;&gt;自定义BuildConfig&lt;/h4&gt;
&lt;p&gt;BuildConfig 是一个在 Android Gradle 构建脚本编译后生成的类，默认构建生成的 BuildConfig 内容如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;/**
 * Automatically generated file. DO NOT MODIFY
 */
package com.manu.androidgradleproject;

public final class BuildConfig {
  public static final boolean DEBUG = false;
  public static final String APPLICATION_ID = &quot;com.manu.androidgradleproject&quot;;
  public static final String BUILD_TYPE = &quot;release&quot;;
  public static final String FLAVOR = &quot;baidu&quot;;
  public static final int VERSION_CODE = 1;
  public static final String VERSION_NAME = &quot;1.0&quot;;
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;上面 BuildConfig 中的一些常量都是关于应用的一些关键信息，其中 DEBUG 在 debug 模式下为 true，release 模式下为 false，此外还有应用包名、构建类型、构建渠道、版本号及版本名称，所以如果开发中需要用到这些值可以在 BuildConfig 中直接获取，比如包名的获取一般是 context.getPackageName()，如果直接从 BuildConfig 中获取是不是不仅方便而且有利于应用性能提升，所以，可在构建时在该文件中添加一些额外的有用的信息，可以使用 buildConfigField 方法，具体如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;/**
 * type:生成字段的类型
 * name:生成字段的常量名称
 * value:生成字段的常量值
 */
public void buildConfigField(String type, String name, String value) {
    //...
}

&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;下面使用 buildConfigField 方法为每个渠道配置一个相关地址，参考如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;android{
    //维度
    flavorDimensions &quot;channel&quot;
    productFlavors{
        miui{
            dimension &quot;channel&quot;
            manifestPlaceholders.put(&quot;CHANNEL&quot;,&quot;miui&quot;)
            buildConfigField 'String' ,'URL','&quot;http://www.miui.com&quot;'
        }
        baidu{
            dimension &quot;channel&quot;
            manifestPlaceholders.put(&quot;CHANNEL&quot;,&quot;baidu&quot;)
            //buildConfigField方法参数value中的内容是单引号中的，如果value是String，则String的双引号不能省略
            buildConfigField 'String' ,'URL','&quot;http://www.baidu.com&quot;'
        }
    }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;再打包时就会自动生成添加的字段，构建完成后查看 BuildConfig 文件，生成了上面添加的字段，参考如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;/**
 * Automatically generated file. DO NOT MODIFY
 */
package com.manu.androidgradleproject;

public final class BuildConfig {
  public static final boolean DEBUG = false;
  public static final String APPLICATION_ID = &quot;com.manu.androidgradleproject&quot;;
  public static final String BUILD_TYPE = &quot;release&quot;;
  public static final String FLAVOR = &quot;baidu&quot;;
  public static final int VERSION_CODE = -1;
  public static final String VERSION_NAME = &quot;&quot;;
  // Fields from product flavor: baidu
  public static final String URL = &quot;http://www.baidu.com&quot;;
}

&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;至此，自定义 BuildConfig 的学习就到此为止，当然 buildConfigField 也可以使用到构建类型中，关键就是 buildConfigField 方法的使用。&lt;/p&gt;
&lt;h4 id=&quot;动态添加自定义资源&quot;&gt;动态添加自定义资源&lt;/h4&gt;
&lt;p&gt;Android 开发中资源文件都是放置在 res 目录下，还可以在 Android Gradle 中定义，自定义资源需要使用到 resValue 方法，该方法在 BuildType 和 ProductFlavor 对象中可以使用，使用 resValue 方法会生成相对应的资源，使用方式和在 res/values 文件中定义的一样&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;android{
    //...
    productFlavors {
        miui {
            //...
           /**
            * resValue(String type,String name,String value)
            * type:生成字段的类型(id、string、bool等)
            * name:生成字段的常量名称
            * value:生成字段的常量值
            */
            resValue 'string', 'welcome','miui'
        }

        baidu {
            //...
            resValue 'string', 'welcome','baidu'
        }
    }

}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;当生成不同的渠道包时，通过 R.string.welcome 获取的值是不相同的，如生成的百度的渠道包时 R.string.welcome 的值为 baidu、生成小米渠道包时 R.string.welcome 的值为 miui，构建时生成的资源的位置在 build/generated/res/resValues/baidu/... 下面的 generated.xml 文件中，文件内容参考如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-xml&quot;&gt;&amp;lt;?xml version=&quot;1.0&quot; encoding=&quot;utf-8&quot;?&amp;gt;
&amp;lt;resources&amp;gt;

    &amp;lt;!-- Automatically generated file. DO NOT MODIFY --&amp;gt;

    &amp;lt;!-- Values from product flavor: baidu --&amp;gt;
    &amp;lt;string name=&quot;welcome&quot; translatable=&quot;false&quot;&amp;gt;baidu&amp;lt;/string&amp;gt;

&amp;lt;/resources&amp;gt;

&lt;/code&gt;
&lt;/pre&gt;
&lt;h4 id=&quot;java编译选项&quot;&gt;Java编译选项&lt;/h4&gt;
&lt;p&gt;在 Android Gradle 中还可以配置 Java 源代码的编译版本，这里使用到 compileOptions 方法， compileOptions 可配置三个属性：encoding、sourceCompatibility 和 targetCompatibility，通过这些属性来配置 Java 相关的编译选项，具体参考如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;//配置Java编译选项
android {
    compileSdkVersion 26
    buildToolsVersion '26.0.2'
    compileOptions{
        //设置源文件的编码
        encoding = 'utf-8'
        //设置Java源代码的编译级别()
        sourceCompatibility = JavaVersion.VERSION_1_8
//        sourceCompatibility  &quot;1.8&quot;
//        sourceCompatibility  1.8
//        sourceCompatibility  &quot;Version_1_8&quot;
        //设置Java字节码的版本
        targetCompatibility = JavaVersion.VERSION_1_8
    }
}

&lt;/code&gt;
&lt;/pre&gt;
&lt;h4 id=&quot;adb操作选项设置&quot;&gt;adb操作选项设置&lt;/h4&gt;
&lt;p&gt;adb 的全称是 Android Debug Bridge，adb 主要用来连接手机来进行一些操作，比如调试 Apk、安装 Apk、复制文件等操作，在 Android Gradle 中可借助 adpOptions 来配置，可配置的有两个属性：installOptions 和 timeOutInMs，也可以通过相应的 setter 方法来设置，具体参考如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;android{
    //adb配置选项
    adbOptions{
        //设置执行adb命令的超时时间
        timeOutInMs = 5 * 1000
        /**
         * 设置adb install安装这个操作的设置项
         * -l:锁定应用程序
         * -r:替换已存在的应用程序
         * -t:允许测试包
         * -s:把应用程序安装到SD卡上
         * -d:允许应用程序降级安装
         * -g:为该应用授予所有运行时的权限
         */
        installOptions '-r', '-s'
    }    
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;installOptions 的配置对应 adb install [-lrtsdg] 命令，如果安装、运行或调试 Apk 的时候，如果出现 CommandRejectException 可以尝试设置 timeOutInMs 来解决，单位是毫秒。&lt;/p&gt;
&lt;h4 id=&quot;dex选项配置&quot;&gt;DEX选项配置&lt;/h4&gt;
&lt;p&gt;Android 中的源代码被编译成 class 字节码，在打包成 Apk 的时候又被 dx 命令优化成 Android 虚拟机可执行的 DEX 文件，DEX 格式的文件是专为 Android 虚拟机设计的，在一定程度上会提高其运行速度，默认情况下给 dx 分配的内存是 1024M，在 Android Gradle 中可以通过 dexOptions 的五个属性：incremental、javaMaxHeapSize、jumboMode、threadCount 和 preDexLibraries 来对 DEX 进行相关配置，具体参考如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;android{
    //DEX选项配置
    dexOptions{
        //设置是否启用dx增量模式
        incremental true
        //设置执行dx命令为其分配的最大堆内存
        javaMaxHeapSize '4g'
        //设置是否开启jumbo模式，如果项目方法数超过65535，需要开启jumbo模式才能构建成功
        jumboMode true
        //设置Android Gradle运行dx命令时使用的线程数量，可提高dx执行的效率
        threadCount 2
        /**
         * 设置是否执行dex Libraries库工程,开启后会提高增量构建的速度，会影响clean的速度，默认为true
         * 使用dx的--multi-dex选项生成多个dex,为避免和库工程冲突，可设置为false
         */
        preDexLibraries true
    }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;h4 id=&quot;自动清理未使用资源&quot;&gt;自动清理未使用资源&lt;/h4&gt;
&lt;p&gt;Android 开发中打包 Apk 总是希望在相同功能的情况下 Apk 体积尽量小，那就要在打包之前删除没有使用的资源文件或打包时不将无用的资源打包到 Apk 中，可以使用 Android Lint 检查未使用的资源，但是无法清除一些第三方库中的无用资源，还可以使用 Resource Shrinking，可在打包之前检查资源，如果没有使用则不会被打包到 Apk 中，具体参考如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;//自动清理未使用资源
android{
    buildTypes {
        release {
            //开启混淆，保证某些资源在代码中未被使用，以便于自动清理无用资源，两者配合使用
            minifyEnabled true
            /**
             * 打包时会检查所有资源，如果没有被引用，则不会被打包到Apk中，会处理第三方库不使用的资源
             * 默认不启用
             */
            shrinkResources true
            //开启zipalign优化
            proguardFiles getDefaultProguardFile('proguard-android.txt'), 'proguard-rules.pro'
        }
        debug{
        }
    }
    //...
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;为防止有用资源未被打包到 Apk 中，Android Gradle 提供了 keep 方法来配置那些资源不被清理，在 res/raw/ 下新建一个 xml 文件来使用 keep 方法，参考如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-xml&quot;&gt;&amp;lt;!--keep.xml文件--&amp;gt;
&amp;lt;?xml version=&quot;1.0&quot; encoding=&quot;utf-8&quot;?&amp;gt;
&amp;lt;resources xmlns:tools=&quot;http://schemas.android.com/tools&quot;
    tools:keep=&quot;@layout/l_used*_c,@layout/l_used_a,@layout/l_used_b*&quot;
    tools:discard=&quot;@layout/l_used&quot;
    tools:shrinkMode=&quot;safe&quot;/&amp;gt;
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;可配置的三个属性：keep 表示要保留的资源文件，可使用以(,)分割的资源列表，可使用(*)作为通配符，discard 表示要移除的资源，和 keep 类似，shrinkMode 用于设置自动清理资源的模式，一般设置为 safe 即可，如果设置为 strict 则有可能清除可能会使用的资源。&lt;/p&gt;
&lt;p&gt;此外，还可以使用 ProductFlavor 提供的方法 resConfigs 和 resConfig，可配置那些资源打包到 Apk 中，使用方式如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;android{
    defaultConfig{
       //参数可以是Android开发时的资源限定符
        resConfigs 'zh'
        //...
    }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;上述自动清理资源的方式只是不打包到 Apk 中，在实际的项目中并没有被清除，可通过日志查看哪些资源被清理了，然后决定要不要在项目中清除。&lt;/p&gt;
&lt;h4 id=&quot;突破65535方法限制&quot;&gt;突破65535方法限制&lt;/h4&gt;
&lt;p&gt;在 Android 开发中总会遇到方法数大于 65535 时出现异常，那为什么会有这个限制呢，因为 Java 源文件被打包成一个 DEX 文件，这个文件是优化过的、可在 Dalvik 虚拟机上可执行的文件，由于 Dalvik 在执行 DEX 文件的时候，使用了 short 来索引 DEX 文件中的方法，这就意味着单个 DEX 文件可被定义的方法最多只有 65535 个。解决办法自然是当方法数超过 65535 个的时候创建多个 DEX 文件。&lt;/p&gt;
&lt;p&gt;从 Android 5.0 开始的 Android 系统使用 ART 的运行方式，原生支持多个 DEX 文件，ART 在安装 App 的时候执行预编译，把多个 DEX 文件合并成一个 oat 文件执行，在 Android 5.0 之前，Dalvik 虚拟机只支持单个 DEX 文件，要想突破单个 DEX 方法数超过 65535 的限制，需使用 Multidex 库，这里就不在赘述了。&lt;/p&gt;
&lt;h4 id=&quot;总结&quot;&gt;总结&lt;/h4&gt;
&lt;p&gt;​本篇文章的很多内容都可以用到实际开发中，这篇文章也是在边学习边验证的情况下完成的，断断续续花了一周时间，距离上次更文已有一周时间，希望阅读此文能够对你有所帮助。&lt;/p&gt;
&lt;p&gt;可以关注公众号：零点小筑（jzman-blog），一起交流学习。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://user-gold-cdn.xitu.io/2019/9/1/16ced1a49b274b3f?w=600&amp;amp;h=472&amp;amp;f=jpeg&amp;amp;s=21120&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
</description>
<pubDate>Sun, 20 Sep 2020 17:00:00 +0000</pubDate>
<dc:creator>躬行之</dc:creator>
<og:description>本篇文章主要在之前学习的基础上，从实际开发的角度学习如何对 Android Gradle 来进行自定义以满足不同的开发需求，下面是 Gradle 系列的几篇文章： Gradle系列之初识Gradle</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/jzmanu/p/13703204.html</dc:identifier>
</item>
<item>
<title>你还在寻找Navicat的破解版本？你应该了解开源免费的DBeaver - 三升水</title>
<link>http://www.cnblogs.com/sanshengshui/p/13703174.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/sanshengshui/p/13703174.html</guid>
<description>&lt;p&gt;&lt;img src=&quot;https://james-1258744956.cos.ap-shanghai.myqcloud.com/dbeaver/pear.jpg&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h2 id=&quot;前言&quot;&gt;前言&lt;/h2&gt;
&lt;p&gt;你是否还在各个“免费绿色”的下载网站上寻找navicat的破解版本，或者已经通过某些方式破解了navicat的特定版本。你或者是在一家对安全和软件著作权比较看重的公司，明令禁止不允许使用破解或者盗版软件，因此只能拾起了每个数据库给用户提供的免费客户端软件，例如MySQL Workbench, PostgreSQL pgAdmin...。但是你又不得不安装上多个不同的客户端软件，增加了使用成本。&lt;/p&gt;
&lt;p&gt;你或者是Linux的狂热爱好者，正在使用Ubuntu, Linux Mint, CentOS等Linux发行版本,你正在寻找一个支持多平台的客户端软件。你或者是正在使用IDEA Ultimate版本的Java开发者，平时习惯于编辑器自带的数据库连接工具，但有时候也会对此有所烦恼，因为其对特定格式的数据显示不太好，也对数据表结构转换成ER图这些功能有所需求。&lt;/p&gt;
&lt;p&gt;上面这些问题在&lt;strong&gt;DBeaver&lt;/strong&gt;都会得到解决。&lt;/p&gt;
&lt;h2 id=&quot;关于dbeaver&quot;&gt;关于DBeaver&lt;/h2&gt;
&lt;p&gt;官网地址: &lt;a href=&quot;https://dbeaver.io/&quot;&gt;https://dbeaver.io/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;GitHub地址: &lt;a href=&quot;https://github.com/dbeaver/dbeaver&quot;&gt;https://github.com/dbeaver/dbeaver&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;我们从GitHub的1w5千多Star数就可以看出，DBeaver在众多开发者中已经得到了广泛的认可。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://james-1258744956.cos.ap-shanghai.myqcloud.com/dbeaver/beaver-head.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;DBeaver是一个为开发人员、SQL程序员、数据库管理员和分析人员提供免费的多平台数据库工具。支持任何具有JDBC驱动程序的数据库(基本上意味着——任何数据库)。EE版本也支持非jdbc数据源(MongoDB, Cassandra, Redis, DynamoDB等)。&lt;/p&gt;
&lt;ul readability=&quot;8.2264851485149&quot;&gt;&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;有很多&lt;a href=&quot;https://github.com/dbeaver/dbeaver/wiki&quot;&gt;特性&lt;/a&gt;，包括元数据编辑器，SQL编辑器，富数据编辑器，ERD，数据导出/导入/迁移，SQL执行计划，等等。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;基于&lt;a href=&quot;https://www.eclipse.org/&quot;&gt;Eclipse&lt;/a&gt;平台。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;17&quot;&gt;
&lt;p&gt;使用插件架构并为以下数据库提供额外的功能:MySQL/MariaDB, PostgreSQL, Greenplum, Oracle, DB2 LUW, Exasol, SQL Server, Sybase/SAP ASE, SQLite, Firebird, H2, HSQLDB, Derby, Teradata, Vertica, Netezza, Informix，等等。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;h2 id=&quot;安装&quot;&gt;安装&lt;/h2&gt;
&lt;p&gt;官网下载地址: &lt;a href=&quot;https://dbeaver.io/download/&quot;&gt;https://dbeaver.io/download/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://james-1258744956.cos.ap-shanghai.myqcloud.com/dbeaver/dbeaver-download.jpg?imageMogr2/thumbnail/!50p&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;从上图我们可以看到，其支持Windows、MacOS、Linux和Eclipse Plugin多个平台。满足了我最开始说的多平台支持的特性。接下来我们看下其免费版本的特性是否比navicat的旗舰版还要出色，让我们拭目以待。&lt;/p&gt;

&lt;p&gt;基本的数据操作和使用，Navicat Premium和DBeaver 都是具有这些功能和特性的，下面我针对他们的不同点和优秀的特性进行讲解和说明。&lt;/p&gt;
&lt;h3 id=&quot;整体页面呈现&quot;&gt;整体页面呈现&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;https://james-1258744956.cos.ap-shanghai.myqcloud.com/dbeaver/dbeaver_view.jpg&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://james-1258744956.cos.ap-shanghai.myqcloud.com/dbeaver/navicat_view.jpg&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;整体页面显示对比方面，我的体验如下:&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;DBeaver在表的相关信息呈现方面更具体和详细，而Navicat有些信息没有呈现的情况。例如索引和表权限的情况。&lt;/li&gt;
&lt;li&gt;DBeaver对表的信息呈现是分Tab页的方式进行处理的，分为属性、数据和ER图，而Navicat的属性和数据是分为2个页面的形式。我觉得DBeaver对表信息呈现方面更好，毕竟对于同一个表，我并不想另开个页面去查看。&lt;/li&gt;
&lt;li&gt;Navicat比DBeaver好的一点，我认为是其页面显示更扁平化和清爽些。&lt;/li&gt;
&lt;/ol&gt;&lt;h3 id=&quot;数据编辑器&quot;&gt;数据编辑器&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;https://james-1258744956.cos.ap-shanghai.myqcloud.com/dbeaver/Panels.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;仅当您打开四个面板之一时，才会显示此附加窗格：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;计算&lt;/li&gt;
&lt;li&gt;分组&lt;/li&gt;
&lt;li&gt;元数据&lt;/li&gt;
&lt;li&gt;值查看器（默认）&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;如果你是对SQL语法不太熟悉的同学，那计算和分组简直是你的福音啊！&lt;/p&gt;
&lt;p&gt;Calc面板对于获取几列和几行数据的基本统计信息非常有用：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://james-1258744956.cos.ap-shanghai.myqcloud.com/dbeaver/Aggregate-panel.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;“分组”面板提供了基于自定义SQL查询表计算统计信息的工具。它使用GROUP BY查询提取COUNT（默认值），SUM，AVG，MIN，MAX和其他分析功能的唯一值，并在专用列中显示结果。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://james-1258744956.cos.ap-shanghai.myqcloud.com/dbeaver/Grouping-Panel.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h3 id=&quot;仪表盘&quot;&gt;仪表盘&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;仪表板&lt;/strong&gt;工具允许DBA和程序员快速识别性能，磁盘空间问题，连接数以及与单个数据库连接相关的其他重要KPI。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://james-1258744956.cos.ap-shanghai.myqcloud.com/dbeaver/Open_Dashboard_Menu_Option.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h3 id=&quot;er图调教&quot;&gt;ER图调教&lt;/h3&gt;
&lt;p&gt;这个我就不得不给DBeaver称赞了，因为它在ER图这块做的实在是太棒了，对于我这种经常做表结构设计和画ER图的同学帮助很大。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://james-1258744956.cos.ap-shanghai.myqcloud.com/dbeaver/ER-Diagrams-Editor.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;ER图的空白背景和田子格背景的自由切换&lt;/li&gt;
&lt;li&gt;表实体之间的连线和备注更形象具体。&lt;/li&gt;
&lt;/ul&gt;&lt;h3 id=&quot;行或者数据类型着色&quot;&gt;行或者数据类型着色&lt;/h3&gt;
&lt;p&gt;在数据编辑器中，您可以为所有与特定列的特定单元格具有相同值的行上色。除了用值给行着色之外，还可以按数据类型给列中的值着色。进行颜色设置:&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://james-1258744956.cos.ap-shanghai.myqcloud.com/dbeaver/Colored_rows.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://james-1258744956.cos.ap-shanghai.myqcloud.com/dbeaver/Colored-Data-Types.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;更多的特性和基本使用请参照其wiki文档: &lt;a href=&quot;https://github.com/dbeaver/dbeaver/wiki&quot;&gt;https://github.com/dbeaver/dbeaver/wiki&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;总结&quot;&gt;总结&lt;/h2&gt;
&lt;p&gt;如此优秀的开源数据库客户度软件DBeaver，我相信所有用过的人都将爱不释手。盆友们，赶紧使用起来吧！&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://james-1258744956.cos.ap-shanghai.myqcloud.com/JWT-No-MySQL/%E5%85%AC%E4%BC%97%E5%8F%B7%E4%BF%A1%E6%81%AF.jpg&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
</description>
<pubDate>Sun, 20 Sep 2020 16:57:00 +0000</pubDate>
<dc:creator>三升水</dc:creator>
<og:description>前言 你是否还在各个“免费绿色”的下载网站上寻找navicat的破解版本，或者已经通过某些方式破解了navicat的特定版本。你或者是在一家对安全和软件著作权比较看重的公司，明令禁止不允许使用破解或者</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/sanshengshui/p/13703174.html</dc:identifier>
</item>
<item>
<title>【Java并发编程】synchronized相关面试题总结 - 天乔巴夏丶</title>
<link>http://www.cnblogs.com/summerday152/p/13703110.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/summerday152/p/13703110.html</guid>
<description>&lt;p&gt;synchronized关键字用于解决多个线程之间访问资源的同步性，&lt;strong&gt;synchronized关键字可以保证被它修饰的方法或者代码块在任意时刻只能有一个线程执行&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;值得注意的是，在Java早期，JDK1.6之前，synchronized属于重量级锁，效率低下。&lt;/p&gt;
&lt;p&gt;原因在于：&lt;/p&gt;
&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;监视器锁【monitor】依赖于底层操作系统的&lt;code&gt;Mutex Lock&lt;/code&gt;实现，Java的线程是映射到操作系统的原生线程之上的。如果要挂起或唤醒一个线程，都需要操作系统帮忙完成，而&lt;strong&gt;操作系统实现线程之间的切换时需要从用户态转化到内核态，需要消耗比较长的时间&lt;/strong&gt;。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;但是，JDK1.6之后，Java官方从JVM层面对synchronized关键字进行了较大的优化，效率不可同日而语。主要的优化有：自旋锁、适应性自旋锁、锁消除、锁粗化、偏向锁、轻量级锁等技术来减少锁操作的开销。&lt;/p&gt;

&lt;ol&gt;&lt;li&gt;&lt;strong&gt;修饰实例方法：&lt;/strong&gt;作用于当前对象实例加锁，进入同步代码前要获得 &lt;strong&gt;当前对象实例的锁&lt;/strong&gt;。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;修饰静态方法:&lt;/strong&gt; 也就是给当前类加锁，会作用于类的所有对象实例 ，进入同步代码前要获得 &lt;strong&gt;当前 class 的锁&lt;/strong&gt;。&lt;/li&gt;
&lt;/ol&gt;&lt;blockquote readability=&quot;10&quot;&gt;
&lt;p&gt;注意：静态成员不属于任何一个实例对象，是类成员！因此，一个线程A调用一个实例对象的非静态synchronized方法，一个线程B调用这个实例对象的所属类的静态synchronized方法，是被允许的。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;因为访问静态 &lt;code&gt;synchronized&lt;/code&gt; 方法占用的锁是当前类的锁，而访问非静态 &lt;code&gt;synchronized&lt;/code&gt; 方法占用的锁是当前实例对象锁&lt;/strong&gt;。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ol start=&quot;3&quot;&gt;&lt;li&gt;&lt;strong&gt;修饰代码块&lt;/strong&gt; ：给括号内配置的对象加锁。&lt;code&gt;synchronized(this|object)&lt;/code&gt; 表示进入同步代码库前要获得&lt;strong&gt;给定对象的锁&lt;/strong&gt;。&lt;code&gt;synchronized(类.class)&lt;/code&gt; 表示进入同步代码前要获得 &lt;strong&gt;当前 class 的锁&lt;/strong&gt;。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;通过对.class文件反编译可以发现：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;同步方法通过&lt;code&gt;ACC_SYNCHRONIZED&lt;/code&gt;修饰。&lt;/li&gt;
&lt;li&gt;代码块同步使用&lt;code&gt;monitorenter&lt;/code&gt;和&lt;code&gt;monitorexit&lt;/code&gt;两个指令实现。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;虽然两者实现细节不同，但其实本质上都是JVM基于&lt;strong&gt;进入和退出Monitor对象&lt;/strong&gt;来实现同步，JVM的要求如下：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;code&gt;monitorenter&lt;/code&gt;指令会在编译后插入到同步代码块的开始位置，而&lt;code&gt;monitorexit&lt;/code&gt;则会插入到方法结束和异常处。&lt;/li&gt;
&lt;li&gt;每个对象都有一个&lt;code&gt;monitor&lt;/code&gt;与之关联，且当一个&lt;code&gt;monitor&lt;/code&gt;被持有之后，他会处于锁定状态。&lt;/li&gt;
&lt;li&gt;线程执行到&lt;code&gt;monitorenter&lt;/code&gt;时，会尝试获取对象对应&lt;code&gt;monitor&lt;/code&gt;的所有权。&lt;/li&gt;
&lt;li&gt;在获取锁时，如果对象没被锁定，或者当前线程已经拥有了该对象的锁（可重进入，不会锁死自己），将锁计数器加一，执行&lt;code&gt;monitorexit&lt;/code&gt;时，锁计数器减一，计数为零则锁释放。&lt;/li&gt;
&lt;li&gt;获取对象锁失败，&lt;strong&gt;则当前线程陷入阻塞&lt;/strong&gt;，直到对象锁被另外一个线程释放。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a href=&quot;https://blog.csdn.net/qq_34337272/article/details/108498442&quot;&gt;https://blog.csdn.net/qq_34337272/article/details/108498442&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;优化：偏向锁，轻量级锁，自旋锁，适应性自旋锁，锁消除，锁粗化。&lt;/p&gt;
&lt;blockquote readability=&quot;7&quot;&gt;
&lt;p&gt;锁主要存在的四种状态，依次是：&lt;strong&gt;无锁状态、偏向锁状态、轻量级锁状态、重量级锁状态&lt;/strong&gt;，他们会随着竞争的激烈而逐渐升级。注意&lt;strong&gt;锁可以升级不可降级&lt;/strong&gt;，这种策略是为了提高获得锁和释放锁的效率。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;java对象头的组成&quot;&gt;Java对象头的组成&lt;/h2&gt;
&lt;p&gt;锁存在于Java对象头里，对象头的组成部分：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;Mark Word：存储对象的hashCode或锁信息等。&lt;/li&gt;
&lt;li&gt;Class Metadata Address：存储到对象类型数据的指针。&lt;/li&gt;
&lt;li&gt;Array length：数组的长度（如果当前对象是数组）&lt;/li&gt;
&lt;/ul&gt;&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;Java对象头又存在于Java堆中，堆内存分为三部分：&lt;strong&gt;对象头&lt;/strong&gt;，实例数据和对齐填充。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;markword的组成&quot;&gt;MarkWord的组成&lt;/h2&gt;
&lt;p&gt;Java对象头的MardWord中记录了对象和锁的相关信息，&lt;strong&gt;无锁状态下，Java对象头里的Mark Word里默认存储对象的HashCode、分代年龄和锁标记位&lt;/strong&gt;。在64位的JVM中，Mark Word为&lt;strong&gt;64 bit&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1771072/202009/1771072-20200921000025902-374721258.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;在运行期间Mark Word里存储的数据会随着锁标志位的变化而变化。锁升级的功能也主要靠MarkWord中&lt;strong&gt;锁标志位&lt;/strong&gt;和&lt;strong&gt;是否偏向锁标志&lt;/strong&gt;完成。&lt;/p&gt;
&lt;h2 id=&quot;锁升级的过程&quot;&gt;锁升级的过程&lt;/h2&gt;
&lt;p&gt;锁升级的过程：无锁，偏向锁，轻量级锁，重量级锁&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1771072/202009/1771072-20200921000031252-1656502189.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h2 id=&quot;偏向锁&quot;&gt;偏向锁&lt;/h2&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;HotSpot的作者经过研究发现，大多数情况下，锁不仅不存在多线程竞争，而且总是由同一线程多次获得，为了让线程获得锁的代价更低而引入了偏向锁。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&quot;偏向锁的适用场景&quot;&gt;偏向锁的适用场景&lt;/h3&gt;
&lt;p&gt;偏向锁主要用于优化：&lt;strong&gt;同一线程多次申请同一个锁的竞争&lt;/strong&gt;，在某些情况下，大部分时间都是同一个线程竞争锁资源的。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1771072/202009/1771072-20200921000043172-1308845615.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h3 id=&quot;偏向锁的加锁&quot;&gt;偏向锁的加锁&lt;/h3&gt;
&lt;p&gt;主要流程：当一个线程访问同步块并获取锁时，会在对象头和栈帧中的锁记录里&lt;strong&gt;存储锁偏向的线程ID&lt;/strong&gt;，以后该线程在进入和退出同步块时&lt;strong&gt;不需要进行CAS操作来加锁和解锁&lt;/strong&gt;，只需简单地&lt;strong&gt;测试一下对象头的Mark Word里是否存储着指向当前线程的偏向锁&lt;/strong&gt;。&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;如果测试成功，表示线程已经获得了锁。&lt;/li&gt;
&lt;li&gt;如果测试失败，则需要再测试一下Mark Word中偏向锁的标识是否设置成1（表示当前是偏向锁）：
&lt;ul&gt;&lt;li&gt;如果没有设置，则使用CAS竞争锁。&lt;/li&gt;
&lt;li&gt;如果设置了，则尝试使用CAS将对象头的偏向锁指向当前线程。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;h3 id=&quot;偏向锁的撤销&quot;&gt;偏向锁的撤销&lt;/h3&gt;
&lt;p&gt;一旦出现其他线程竞争锁资源时，偏向锁就会被&lt;strong&gt;撤销&lt;/strong&gt;。偏向锁的撤销&lt;strong&gt;可能需要&lt;/strong&gt;等待&lt;strong&gt;全局安全点&lt;/strong&gt;【在这个时间点上没有正在执行的字节码】。&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;首先&lt;strong&gt;暂停持有该锁的线程&lt;/strong&gt;，然后&lt;strong&gt;检查持有偏向锁的线程是否活着&lt;/strong&gt;，如果线程&lt;strong&gt;不处于活动状态&lt;/strong&gt;，则将对象头设置成无锁状态。&lt;/li&gt;
&lt;li&gt;如果持有偏向锁的线程仍然活着，拥有偏向锁的栈会被执行，遍历偏向对象的锁记录，栈中的锁记录和对象头的Mark Word要么重新偏向于其他线程，要么恢复到无锁或者标记对象不适合作为偏向锁，&lt;strong&gt;最后唤醒在暂停的线程&lt;/strong&gt;。&lt;/li&gt;
&lt;/ul&gt;&lt;h3 id=&quot;偏向锁的关闭&quot;&gt;偏向锁的关闭&lt;/h3&gt;
&lt;p&gt;偏向锁在Java 6和Java 7里是默认启用的，但是它在应用程序启动几秒钟之后才激活，如有必要可以使用JVM参数来关闭延迟：&lt;code&gt;-XX:BiasedLockingStartupDelay=0&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;如果锁通常处于竞争状态，可以通过&lt;code&gt;- XX:-UseBiasedLocking=false&lt;/code&gt;，进入轻量级锁状态。&lt;/p&gt;
&lt;h2 id=&quot;轻量级锁&quot;&gt;轻量级锁&lt;/h2&gt;
&lt;p&gt;如偏向锁存在，如有另一线程竞争锁，且对象头MarkWord中的线程ID与当前线程ID不同，则该线程将会&lt;strong&gt;尝试CAS操作获取锁，获取失败，代表锁存在竞争，偏向锁向轻量级锁升级&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1771072/202009/1771072-20200921000048826-1303823171.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h3 id=&quot;轻量级锁的加锁&quot;&gt;轻量级锁的加锁&lt;/h3&gt;
&lt;ul&gt;&lt;li&gt;线程在执行同步块之前，JVM会先在当前线程的栈桢中创建用于存储锁记录的空间【Displaced Mark Word】，并&lt;strong&gt;将对象头中的Mark Word复制到锁记录中&lt;/strong&gt;。&lt;/li&gt;
&lt;li&gt;然后线程尝试&lt;strong&gt;使用CAS将对象头中的Mark Word替换为指向锁记录的指针&lt;/strong&gt;。
&lt;ul&gt;&lt;li&gt;替换成功，则当前线程获得锁。&lt;/li&gt;
&lt;li&gt;替换失败，表示其他线程竞争锁，当前线程尝试使用自旋来获取锁。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;h3 id=&quot;轻量级锁的解锁&quot;&gt;轻量级锁的解锁&lt;/h3&gt;
&lt;ul&gt;&lt;li&gt;使用原子的CAS操作将【Displaced Mark Word】替换回对象头。
&lt;ul&gt;&lt;li&gt;替换成功，表示没有竞争发生。&lt;/li&gt;
&lt;li&gt;替换失败，表示当前锁存在竞争，锁就会膨胀成重量级锁。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;h3 id=&quot;轻量级锁的适用场景&quot;&gt;轻量级锁的适用场景&lt;/h3&gt;
&lt;p&gt;线程&lt;strong&gt;交替执行&lt;/strong&gt;同步块，&lt;strong&gt;绝大部分的锁在整个同步周期内都不存在长时间的竞争&lt;/strong&gt;。&lt;/p&gt;
&lt;h2 id=&quot;锁的优缺点对比&quot;&gt;锁的优缺点对比&lt;/h2&gt;
&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;锁&lt;/th&gt;
&lt;th&gt;优点&lt;/th&gt;
&lt;th&gt;缺点&lt;/th&gt;
&lt;th&gt;适用场景&lt;/th&gt;
&lt;/tr&gt;&lt;/thead&gt;&lt;tbody readability=&quot;9&quot;&gt;&lt;tr readability=&quot;6&quot;&gt;&lt;td&gt;偏向锁&lt;/td&gt;
&lt;td&gt;加锁和解锁不需要额外的消耗，和执行非同步方法比仅存在纳秒级的差距。&lt;/td&gt;
&lt;td&gt;如果线程间存在锁竞争，&lt;br/&gt;会带来额外的锁撤销的消耗。&lt;/td&gt;
&lt;td&gt;适用于只有一个线程访问同步块场景。&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;6&quot;&gt;&lt;td&gt;轻量级锁&lt;/td&gt;
&lt;td&gt;竞争的线程不会阻塞，提高了程序的响应速度。&lt;/td&gt;
&lt;td&gt;如果始终得不到锁竞争的线程使用自旋会消耗CPU。&lt;/td&gt;
&lt;td&gt;追求响应时间。同步块执行速度非常快。&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;6&quot;&gt;&lt;td&gt;重量级锁&lt;/td&gt;
&lt;td&gt;线程竞争不使用自旋，不会消耗CPU。&lt;/td&gt;
&lt;td&gt;线程阻塞，响应时间缓慢。&lt;/td&gt;
&lt;td&gt;追求吞吐量。同步块执行速度较长。&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;h2 id=&quot;总结&quot;&gt;总结&lt;/h2&gt;
&lt;ol&gt;&lt;li&gt;JVM在&lt;strong&gt;JDK 1.6&lt;/strong&gt;中引入了&lt;strong&gt;分级锁&lt;/strong&gt;机制来优化synchronized&lt;/li&gt;
&lt;li&gt;当一个线程获取锁时，首先对象锁成为一个偏向锁
&lt;ul&gt;&lt;li&gt;这是为了避免在&lt;strong&gt;同一线程重复获取同一把锁&lt;/strong&gt;时，&lt;strong&gt;用户态和内核态频繁切换&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;如果有多个线程竞争锁资源，锁将会升级为轻量级锁
&lt;ul&gt;&lt;li&gt;这适用于在&lt;strong&gt;短时间&lt;/strong&gt;内持有锁，且分锁&lt;strong&gt;交替切换&lt;/strong&gt;的场景&lt;/li&gt;
&lt;li&gt;轻量级锁还结合了&lt;strong&gt;自旋锁&lt;/strong&gt;来&lt;strong&gt;避免线程用户态与内核态的频繁切换&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;如果锁竞争太激烈（自旋锁失败），同步锁会升级为重量级锁&lt;/li&gt;
&lt;li&gt;优化synchronized同步锁的关键：&lt;strong&gt;减少锁竞争&lt;/strong&gt;
&lt;ul&gt;&lt;li&gt;应该尽量使synchronized同步锁处于&lt;strong&gt;轻量级锁&lt;/strong&gt;或&lt;strong&gt;偏向锁&lt;/strong&gt;，这样才能提高synchronized同步锁的性能&lt;/li&gt;
&lt;li&gt;常用手段
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;减少锁粒度&lt;/strong&gt;：降低锁竞争&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;减少锁的持有时间&lt;/strong&gt;，提高synchronized同步锁在自旋时获取锁资源的成功率，&lt;strong&gt;避免升级为重量级锁&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;在&lt;strong&gt;锁竞争激烈&lt;/strong&gt;时，可以考虑&lt;strong&gt;禁用偏向锁&lt;/strong&gt;和&lt;strong&gt;禁用自旋锁&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&quot;共同点&quot;&gt;共同点&lt;/h2&gt;
&lt;ul&gt;&lt;li&gt;都是可重入锁：自己可以再次获取自己的内部锁【避免一个线程获取锁之后，再次尝试获取锁时造成的死锁】。同一线程每次获取锁，计数器加一，释放锁，计数器减一，计数为0，代表完全释放该锁。&lt;/li&gt;
&lt;/ul&gt;&lt;h2 id=&quot;不同点&quot;&gt;不同点&lt;/h2&gt;

</description>
<pubDate>Sun, 20 Sep 2020 16:03:00 +0000</pubDate>
<dc:creator>天乔巴夏丶</dc:creator>
<og:description>说说自己对于synchronized关键字的了解 synchronized关键字用于解决多个线程之间访问资源的同步性，synchronized关键字可以保证被它修饰的方法或者代码块在任意时刻只能有一个</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/summerday152/p/13703110.html</dc:identifier>
</item>
<item>
<title>畅购商城(十三)：秒杀系统「上」 - Robod丶</title>
<link>http://www.cnblogs.com/robod/p/13703033.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/robod/p/13703033.html</guid>
<description>&lt;blockquote readability=&quot;6.5172413793103&quot;&gt;
&lt;p&gt;&lt;strong&gt;好好学习，天天向上&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;本文已收录至我的Github仓库&lt;a href=&quot;https://github.com/RobodLee/DayDayUP&quot;&gt;&lt;strong&gt;DayDayUP&lt;/strong&gt;&lt;/a&gt;：github.com/RobodLee/DayDayUP，欢迎Star&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;流程分析&quot;&gt;流程分析&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;https://gitee.com/RobodLee/image_store/raw/master/Java/%E7%95%85%E8%B4%AD%E5%95%86%E5%9F%8E13%EF%BC%9A%E7%A7%92%E6%9D%80%E7%B3%BB%E7%BB%9F%E4%B8%8A/%E7%A7%92%E6%9D%80%E6%B5%81%E7%A8%8B%E5%9B%BE.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;上面这张图是整个秒杀系统的流程。简单介绍一下：&lt;/p&gt;
&lt;p&gt;秒杀是一个并发量很大的系统，数据吞吐量都很大，MySQL的数据是保存在硬盘中的，数据吞吐的能力满足不了整个秒杀系统的需求。为了提高系统的访问速度，我们定时将秒杀商品从MySQL加载进Redis，因为Redis的数据是保存在内存中的，速度非常快，可以满足很高的吞吐量。&lt;/p&gt;
&lt;p&gt;用户访问秒杀系统，请求到了OpenResty，OpenResty从Redis中加载秒杀商品，然后用户来到了秒杀列表页。当用户点击某个秒杀商品时，OpenResty再从Redis中加载秒杀商品详情信息，接着用户就来到了秒杀商品详情页。&lt;/p&gt;
&lt;p&gt;当进入到商品详情页之后用户就可以点击下单了，点击下单的时候，OpenResty会检查商品是否还有库存，没有库存就下单失败。有库存的话还需要检查一下用户是否登录，没有登录的话再到OAuth2.0认证服务那边去登录，登录成功后再进入到秒杀微服务中，开始正式的下单流程。&lt;/p&gt;
&lt;p&gt;理论上这时候还要对用户进行一些合法性检测，比如账号是否异常等，但是这太耗时了，为了减少系统响应的时间，用户检测这一步先省略。直接让用户进行排队，排队就是将用户id和商品id存入Redis队列，成功排队后给用户返回一个 “正在排队”的信息。&lt;/p&gt;
&lt;p&gt;当排队成功后就开启多线程抢单，为每个排队的用户分配一个线程。在排队用户自己的线程中开始检测账号的状态是否正常，然后从Redis中检测库存时候足够，当所有条件都满足的时候，下单成功，将订单信息存入Redis。并将Redis中的排队信息从“排队中”改为“待支付”，这样前端在查询状态的时候就知道可以开始支付了，然后跳转到支付页面进行支付。当用户支付成功后，将抢单信息从Redis中删除，并同步到MySQL中。&lt;/p&gt;
&lt;p&gt;最后一个问题，有的用户成功抢单后并不去付款，所以我们需要定时去处理未支付的订单。方案和上一篇文章中提到的一样，使用RabbitMQ死信队列。在抢单成功后将订单id、用户id和商品id存到RabbitMQ的队列1，设置半个小时后过期，过期后将信息发送给队列2，我们去监听队列2。当监听到队列2中的消息的时候，说明半个小时已经到了，这时候我们再去Redis中查询订单的状态，如果已经支付了就不去管它；如果没有支付就向微信服务器发送请求关闭支付，然后回滚库存，并将Redis中的抢单信息删除。&lt;/p&gt;
&lt;p&gt;这样整个秒杀流程就结束了。&lt;/p&gt;
&lt;h2 id=&quot;定时任务&quot;&gt;定时任务&lt;/h2&gt;
&lt;p&gt;怎么搭建秒杀微服务就不记录了，没什么好说的，秒杀微服务名为&lt;strong&gt;changgou-service-seckill&lt;/strong&gt;。定时任务我也是第一次接触，所以在这里记录一下。&lt;/p&gt;
&lt;p&gt;首先在启动类上添加一个注解&lt;strong&gt;@EnableScheduling&lt;/strong&gt;去开始对定时任务的支持。然后创建一个类&lt;strong&gt;SeckillGoodsPushTask&lt;/strong&gt;，在这个类上添加@Component注解，将其注入Spring容器。然后再添加一个方法，加上&lt;strong&gt;@Scheduled&lt;/strong&gt;注解，声明这个方法是一个定时任务。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;/**
 * SeckillGoodsPushTask
 * 定时将秒杀商品加载到redis中
 */
@Scheduled(cron = &quot;0/5 * * * * ?&quot;)
public void loadGoodsPushRedis() {
    List&amp;lt;Date&amp;gt; dateMenu = DateUtil.getDateMenus();
    for (Date date : dateMenu) {
        date.setYear(2019-1900);    //2019-6-1 为了方便测试
        date.setMonth(6-1);
        date.setDate(1);
        String dateString = SystemConstants.SEC_KILL_GOODS_PREFIX +DateUtil.data2str(date,&quot;yyyyMMddHH&quot;);
        BoundHashOperations boundHashOperations = redisTemplate.boundHashOps(dateString);
        Set&amp;lt;Long&amp;gt; keys = boundHashOperations.keys();      //获取Redis中已有的商品的id集合
        List&amp;lt;SeckillGoods&amp;gt; seckillGoods;
        //将秒杀商品的信息从数据库中加载出来
        if (keys!=null &amp;amp;&amp;amp; keys.size()&amp;gt;0) {
            seckillGoods = mapper.findSeckillGoodsNotIn(date,keys);     
        } else {
             seckillGoods = mapper.findSeckillGoods(date);
        }
        //遍历秒杀商品集合，将商品依次放入Redis中
        for (SeckillGoods seckillGood : seckillGoods) {
            boundHashOperations.put(seckillGood.getId(),seckillGood);
        }
    }
}
----------------------------------------------------------------------------------------------------------------
@Repository(&quot;seckillGoodsMapper&quot;)
public interface SeckillGoodsMapper extends Mapper&amp;lt;SeckillGoods&amp;gt; {

    //查找符合条件的秒杀商品
    @Select(&quot;SELECT&quot; +
            &quot; * &quot; +
            &quot; FROM &quot; +
            &quot; tb_seckill_goods &quot; +
            &quot; WHERE &quot; +
            &quot; status = 1 &quot; +
            &quot; AND stock_count &amp;gt; 0 &quot; +
            &quot; AND start_time &amp;gt;= #{date} &quot; +
            &quot; AND end_time &amp;lt; DATE_ADD(#{date},INTERVAL 2 HOUR)&quot;)
    List&amp;lt;SeckillGoods&amp;gt; findSeckillGoods(@Param(&quot;date&quot;) Date date);

    //查询出符合条件的秒杀商品，排除之前已存入的
    @SelectProvider(type = SeckillGoodsMapper.SeckillProvider.class, method = &quot;findSeckillGoodsNotIn&quot;)
    List&amp;lt;SeckillGoods&amp;gt; findSeckillGoodsNotIn(@Param(&quot;date&quot;) Date date, @Param(&quot;keys&quot;) Set&amp;lt;Long&amp;gt; keys);

    class SeckillProvider {
        public String findSeckillGoodsNotIn(@Param(&quot;date&quot;) Date date, @Param(&quot;keys&quot;) Set&amp;lt;Long&amp;gt; keys) {
            StringBuilder sql = new StringBuilder(&quot;SELECT&quot; +
                    &quot; * &quot; +
                    &quot; FROM &quot; +
                    &quot; tb_seckill_goods &quot; +
                    &quot; WHERE &quot; +
                    &quot; status = 1 &quot; +
                    &quot; AND stock_count &amp;gt; 0 &quot; +
                    &quot; AND start_time &amp;gt;=  &quot;);
            sql.append(&quot;'&quot;).append(date.toLocaleString()).append(&quot;'&quot;)
                    .append(&quot; AND end_time &amp;lt; DATE_ADD(&quot;)
                    .append(&quot;'&quot;).append(date.toLocaleString()).append(&quot;'&quot;)
                    .append(&quot; ,INTERVAL 2 HOUR) &quot;)
                    .append(&quot; AND id NOT IN (&quot;);
            for (Long key : keys) {
                sql.append(key).append(&quot;,&quot;);
            }
            sql.deleteCharAt(sql.length() - 1).append(&quot;)&quot;);
            System.out.println(sql.toString());
            return sql.toString();
        }
    }

}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;(cron = &quot;0/5 * * * * ?&quot;)&lt;/code&gt;中几个参数分别代表秒-分-时-日-月-周-年。年可以省略，所以是6个。&lt;code&gt;*&lt;/code&gt;表示所有值，比如 “分” 是*就代表每分钟都执行。&lt;code&gt;?&lt;/code&gt;表示不需要关心这个值是多少。&lt;code&gt;/&lt;/code&gt;表示递增触发，0/5表示从0秒开始每5秒触发一次。所以这段代码配置的就是每5秒执行一次定时任务。&lt;/p&gt;
&lt;p&gt;上面这段代码的意思是：将MySQL中的秒杀商品放入Redis，为了避免添加重复的商品，先获取Redis中已有商品的id集合，然后在查询数据库的时候将已有的排除掉。redis中存入商品的键为秒杀开始的时间，例如 &quot;2020100110&quot;表示2020年10月1日10点，获取时间菜单用的是资料提供的一个工具类DateUtil。DateUtil的代码不难，我就不介绍了，开调试模式跟着走一遍就能看懂。为了方便测试，我将日期定在了2019年6月1日，实际开发中应该用当前日期。&lt;/p&gt;
&lt;h2 id=&quot;秒杀频道页&quot;&gt;秒杀频道页&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;https://gitee.com/RobodLee/image_store/raw/master/Java/%E7%95%85%E8%B4%AD%E5%95%86%E5%9F%8E13%EF%BC%9A%E7%A7%92%E6%9D%80%E7%B3%BB%E7%BB%9F%E4%B8%8A/%E7%A7%92%E6%9D%80%E9%A2%91%E9%81%93%E9%A1%B5.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;将商品加载到Redis中后就可以开始下单流程了，首先需要有个秒杀频道页，就是将对应时间段的秒杀商品加载到页面上展示出来。前端将当前时间的字符串(&lt;strong&gt;yyyyMMddHH&lt;/strong&gt;)传到后端，后端从Redis中查询出对应的商品返回到前端，前端进行展示。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;//   SeckillGoodsController
//根据时间段(2019090516) 查询该时间段的所有的秒杀的商品
@GetMapping(&quot;/list&quot;)
public Result&amp;lt;List&amp;lt;SeckillGoods&amp;gt;&amp;gt; list(@RequestParam(&quot;time&quot;) String time){
    List&amp;lt;SeckillGoods&amp;gt; list = seckillGoodsService.list(time);
    return new Result&amp;lt;&amp;gt;(true,StatusCode.OK,&quot;查询成功&quot;,list);
}
-----------------------------------------------------------------------------------
//  SeckillGoodsServiceImpl
@Override
public List&amp;lt;SeckillGoods&amp;gt; list(String time) {
    return redisTemplate.boundHashOps(SystemConstants.SEC_KILL_GOODS_PREFIX+time).values();
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;代码很简单，就是根据键将商品从Redis中查询出来。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://gitee.com/RobodLee/image_store/raw/master/Java/%E7%95%85%E8%B4%AD%E5%95%86%E5%9F%8E13%EF%BC%9A%E7%A7%92%E6%9D%80%E7%B3%BB%E7%BB%9F%E4%B8%8A/%E6%A0%B9%E6%8D%AE%E6%97%B6%E9%97%B4%E6%AE%B5%E6%9F%A5%E8%AF%A2%E7%A7%92%E6%9D%80%E5%95%86%E5%93%81.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h2 id=&quot;秒杀商品详情页&quot;&gt;秒杀商品详情页&lt;/h2&gt;
&lt;p&gt;当用户点击秒杀频道页的商品后，就会进入到秒杀商品详情页。前端将当前时间段和商品的id传到后端，后端从Redis中将商品信息查询出来，然后返回给前端进行展示。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;//   SeckillGoodsController
//根据时间段  和秒杀商品的ID 获取商品的数据
@GetMapping(&quot;/one&quot;)
public Result&amp;lt;SeckillGoods&amp;gt; one(String time,Long id){
    SeckillGoods seckillGoods = seckillGoodsService.one(time, id);
    return new Result&amp;lt;&amp;gt;(true,StatusCode.OK,&quot;查询商品数据成功&quot;,seckillGoods);
}
------------------------------------------------------------------------------------------
//  SeckillGoodsServiceImpl
@GetMapping(&quot;/one&quot;)
public Result&amp;lt;SeckillGoods&amp;gt; one(String time,Long id){
    SeckillGoods seckillGoods = seckillGoodsService.one(time, id);
    return new Result&amp;lt;&amp;gt;(true,StatusCode.OK,&quot;查询商品数据成功&quot;,seckillGoods);
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;img src=&quot;https://gitee.com/RobodLee/image_store/raw/master/Java/%E7%95%85%E8%B4%AD%E5%95%86%E5%9F%8E13%EF%BC%9A%E7%A7%92%E6%9D%80%E7%B3%BB%E7%BB%9F%E4%B8%8A/%E6%9F%A5%E8%AF%A2%E7%A7%92%E6%9D%80%E5%95%86%E5%93%81%E8%AF%A6%E6%83%85%E9%A1%B5%E6%B5%8B%E8%AF%95.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h2 id=&quot;多线程抢单&quot;&gt;多线程抢单&lt;/h2&gt;
&lt;p&gt;上面两个小节内容都不多，现在正式进入下单的流程。因为在秒杀环境中，并发量都很大，如果只开一个线程的话，用户不知道要等到猴年马月，所以为每个下单的用户分配一个线程去进行处理是比较妥当的。&lt;/p&gt;
&lt;p&gt;要在SpringBoot中开启多线程，首先在启动类上添加一个注解&lt;strong&gt;@EnableAsync&lt;/strong&gt;去开启对异步任务的支持。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;//SeckillOrderController
//下单
@RequestMapping(&quot;/add&quot;)
public Result&amp;lt;Boolean&amp;gt; add(String time,Long id){
    //1.获取当前登录的用户的名称
    String username =&quot;robod&quot;;//测试用写死
    boolean flag = seckillOrderService.add(id, time, username);
    return new Result(true,StatusCode.OK,&quot;排队中。。。&quot;,flag);
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;前端将时间段和商品的id传进来，用户名暂时写死，方便测试。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;//  SeckillOrderServiceImpl
@Override
public boolean add(Long id, String time, String username) {
    SeckillStatus seckillStatus = new SeckillStatus(username,LocalDateTime.now(),1,id,time);
    //将seckillStatus存入redis队列
    redisTemplate.boundListOps(SystemConstants.SEC_KILL_USER_QUEUE_KEY).leftPush(seckillStatus);
    redisTemplate.boundHashOps(SystemConstants.SEC_KILL_USER_STATUS_KEY).put(username,seckillStatus);
    multiThreadingCreateOrder.createOrder();
    return true;
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;在这段代码中，先根据已有的信息创建了一个SeckillStatus对象，这个类中存放了秒杀的一些状态信息。然后将seckillStatus放入redis队列中，如果及时地处理订单系统响应速度就会变慢，所以先创建一个SeckillStatus放入redis，然后调用&lt;strong&gt;multiThreadingCreateOrder.createOrder()&lt;/strong&gt;去开启一个线程处理订单。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://gitee.com/RobodLee/image_store/raw/master/Java/%E7%95%85%E8%B4%AD%E5%95%86%E5%9F%8E13%EF%BC%9A%E7%A7%92%E6%9D%80%E7%B3%BB%E7%BB%9F%E4%B8%8A/redis%E8%AE%A2%E5%8D%95%E9%98%9F%E5%88%97.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;@Component
public class MultiThreadingCreateOrder {
        …………
    //异步抢单
    @Async  //声明该方法是个异步任务，另开一个线程去运行
    public void createOrder() {
        //从redis队列中取出seckillStatus
        SeckillStatus seckillStatus = (SeckillStatus) 
            redisTemplate.boundListOps(SystemConstants.SEC_KILL_USER_QUEUE_KEY).rightPop();

        BoundHashOperations seckillGoodsBoundHashOps = 
            redisTemplate.boundHashOps(SystemConstants.SEC_KILL_GOODS_PREFIX + seckillStatus.getTime());
        //从redis中查询出秒杀商品
        SeckillGoods seckillGoods = (SeckillGoods)seckillGoodsBoundHashOps.get(seckillStatus.getGoodsId());   
        if (seckillGoods == null || seckillGoods.getStockCount() &amp;lt;=0 ) {
            throw new RuntimeException(&quot;已售罄&quot;);
        }
        //创建秒杀订单
        SeckillOrder seckillOrder = new SeckillOrder();
        seckillOrder.setSeckillId(seckillGoods.getId());
        seckillOrder.setMoney(seckillGoods.getCostPrice());
        seckillOrder.setUserId(seckillStatus.getUsername());
        seckillOrder.setCreateTime(LocalDateTime.now());
        seckillOrder.setStatus(&quot;0&quot;);
        //将秒杀订单存入redis，键为用户名，确保一个用户只有一个秒杀订单
        redisTemplate.boundHashOps(SystemConstants.SEC_KILL_ORDER_KEY)
            .put(seckillStatus.getUsername(),seckillOrder);

        //减库存，如果库存没了就从redis中删除，并将库存数据写到MySQL中
        seckillGoods.setStockCount(seckillGoods.getStockCount()-1);
        if (seckillGoods.getStockCount() &amp;lt;= 0) {
            seckillGoodsBoundHashOps.delete(seckillStatus.getGoodsId());
            seckillGoodsMapper.updateByPrimaryKeySelective(seckillGoods);
        } else {
            seckillGoodsBoundHashOps.put(seckillStatus.getGoodsId(),seckillGoods);
        }
        //下单成功，更改seckillstatus的状态，再存入redis中
        seckillStatus.setOrderId(seckillOrder.getId());
        seckillStatus.setMoney(Float.valueOf(seckillGoods.getCostPrice()));
        seckillStatus.setStatus(2);             //等待支付
        redisTemplate.boundHashOps(SystemConstants.SEC_KILL_USER_STATUS_KEY)
            .put(seckillStatus.getUsername(),seckillStatus);
    }

}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;在这个方法上添加了一个&lt;strong&gt;@Async&lt;/strong&gt;注解，说明该方法是个异步任务，每次执行该方法的时候都会另开一个线程去运行。之前不是将订单存入redis队列中了吗，现在从redis队列中取出。然后根据商品id查询出商品信息。接着进行库存判断，如果没有商品或者库存没了说明已经卖完了，抛出&lt;strong&gt;已售罄&lt;/strong&gt;的异常。如果有库存的话，就创建一个秒杀订单，将status置为0表示&lt;strong&gt;未支付&lt;/strong&gt;。 然后将订单存入redis中，这样订单就算创建完成了。成功创建订单后就应该减去相应的库存。如果减完库存后发现库存没了，说明最后一件商品已经卖完了，这时候就可以将redis中的该商品删除，并更新到MySQL中。&lt;/p&gt;
&lt;p&gt;最后修改seckillstatus的内容，并更新到redis中。之前没说把seckillstatus存入redis的作用，其实它的作用就是供前端查询订单状态。&lt;/p&gt;
&lt;p&gt;既然是查询订单状态，得提供一个接口吧👇&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;// SeckillOrderController
//查询当前登录的用户的抢单信息(状态)
@GetMapping(&quot;/query&quot;)
public Result&amp;lt;SeckillStatus&amp;gt; queryStatus(String username) {
    SeckillStatus seckillStatus = seckillOrderService.queryStatus(username);
    if (seckillStatus == null) {
        return new Result&amp;lt;&amp;gt;(false,StatusCode.NOT_FOUND_ERROR,&quot;未查询到订单信息&quot;);
    }
    return new Result&amp;lt;&amp;gt;(true,StatusCode.OK,&quot;订单查询成功&quot;,seckillStatus);
}
-------------------------------------------------------------------------------------------
//SeckillOrderServiceImpl
@Override
public SeckillStatus queryStatus(String username) {
  return (SeckillStatus) redisTemplate.boundHashOps(SystemConstants.SEC_KILL_USER_STATUS_KEY).get(username);
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;前端将用户名传入进来，然后查询订单状态，如果查询出来的状态是待支付的话，就可以进入支付流程了。&lt;/p&gt;
&lt;h2 id=&quot;总结&quot;&gt;总结&lt;/h2&gt;
&lt;p&gt;好了，这篇文章到这里就结束了，主要介绍了一下秒杀的流程，然后实现了定时任务，秒杀频道页，秒杀商品详情页和多线程抢单的功能。这个秒杀系统还没有结束，还存在很多问题，在下一篇文章中，将会修改现有的问题并继续完善秒杀的流程。让我们下期再见！&lt;/p&gt;
&lt;blockquote readability=&quot;4.75&quot;&gt;
&lt;p&gt;码字不易，可以的话，给我来个&lt;code&gt;点赞&lt;/code&gt;，&lt;code&gt;收藏&lt;/code&gt;，&lt;code&gt;关注&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;代码：&lt;a href=&quot;https://github.com/RobodLee/changgou&quot;&gt;https://github.com/RobodLee/changgou&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&quot;https://gitee.com/RobodLee/image_store/raw/master/QRcode2.0.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
</description>
<pubDate>Sun, 20 Sep 2020 15:39:00 +0000</pubDate>
<dc:creator>Robod丶</dc:creator>
<og:description>好好学习，天天向上 本文已收录至我的Github仓库DayDayUP：github.com/RobodLee/DayDayUP，欢迎Star 畅购商城(一)：环境搭建 畅购商城(二)：分布式文件系统F</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/robod/p/13703033.html</dc:identifier>
</item>
<item>
<title>最全总结 | 聊聊 Python 数据处理全家桶（Sqlite篇） - AirPython</title>
<link>http://www.cnblogs.com/xingag/p/13702975.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/xingag/p/13702975.html</guid>
<description>&lt;p&gt;&lt;img src=&quot;https://upload-images.jianshu.io/upload_images/1466987-2217b05aaf5dd9e2?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240&quot; alt=&quot;image&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h2 id=&quot;1-前言&quot;&gt;1. 前言&lt;/h2&gt;
&lt;p&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzU1OTI0NjI1NQ==&amp;amp;mid=2247486468&amp;amp;idx=2&amp;amp;sn=7c8cdfb478e5801496dad8b0ddf2061e&amp;amp;chksm=fc1b72c4cb6cfbd2e71861ddb8aa5d6c2ba3d4266ede047cfaf0558e6cd4e5b05a9ecca4dcdc&amp;amp;scene=21#wechat_redirect&quot;&gt;上篇文章&lt;/a&gt; 聊到 Python 处理 Mysql 数据库最常见的两种方式，本篇文章继续说另外一种比较常用的数据库：Sqlite&lt;/p&gt;
&lt;p&gt;Sqlite 是一种 嵌入式数据库，数据库就是一个文件，体积很小，底层由 C 语言编写，经常被集成到移动应用程序中&lt;/p&gt;
&lt;p&gt;事实上，Python 内置了 sqlite3 模块，不需要安装任何依赖，就可以直接操作 Sqlite 数据库&lt;/p&gt;
&lt;h2 id=&quot;2-准备&quot;&gt;2. 准备&lt;/h2&gt;
&lt;p&gt;和 Python 操作 Mysql 类似，操作 Sqlite 主要包含下面 2 种方式：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;
&lt;p&gt;sqlite3 + 原生 SQL&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;SQLAlchemy + ORM&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;h2 id=&quot;3-sqlite3--原生-sql&quot;&gt;3. sqlite3 + 原生 SQL&lt;/h2&gt;
&lt;p&gt;由于 Python 内置了 sqlite3 模块，这里直接导入就可以使用了&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;# 导入内置模块sqlite3
import sqlite3
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;首先，我们使用 sqlite3 的 connnect() 方法创建一个数据库连接对象，如果数据库不存在，就自动在对应目录下新建一个数据库文件&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;# 创建数据库连接对象，如果数据库不存在，就自动新建一个数据库文件
# 还可以指定其他参数，包含：超时时间
 self.conn = sqlite3.connect(self.path_db)
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;然后，通过数据库连接对象获取一个操作数据库的 游标实例&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;# 获取操作数据库的游标对象
self.cursor = self.conn.cursor()
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;接着，使用数据库连接对象执行创建表的 SQL 语句，在数据库内新建一张表&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;# 创建表
SQL_CREATE_TABLE = '''CREATE TABLE IF NOT EXISTS PEOPLE
       (ID INT PRIMARY KEY     NOT NULL,
       NAME           TEXT    NOT NULL,
       AGE            INT     NOT NULL);'''

def create_db_table(self):
    &quot;&quot;&quot;
    初始化表
    :return:
    &quot;&quot;&quot;
    self.conn.execute(SQL_CREATE_TABLE)
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;接下来，我们通过增删改查来操作数据表&lt;/p&gt;
&lt;p&gt;1、新增&lt;/p&gt;
&lt;p&gt;同样以新增单条数据和多条数据为例&lt;/p&gt;
&lt;p&gt;对于单条数据的插入，只需要编写一条插入的 SQL 语句，然后作为参数执行上面数据库连接对象的 execute(sql) 方法，最后使用数据库连接对象的 commit() 方法将数据提交到数据库中&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;# 插入一条数据
SQL_INSERT_ONE_DATA = &quot;INSERT INTO PEOPLE(id,name,age) VALUES(3,'xag',23);&quot;

def insert_one(self):
    &quot;&quot;&quot;新增一条数据&quot;&quot;&quot;
    try:
        self.conn.execute(SQL_INSERT_ONE_DATA)
        # 必须要提交，才能正确执行
        self.conn.commit()
    except Exception as e:
        self.conn.rollback()
        print('插入一条记录失败，回滚~')
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;需要注意的是，&lt;strong&gt;插入操作经常会因为主键原因导致新增异常，所以需要捕获异常，执行回滚操作&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;使用数据库连接对象的 executemany() 方法，传入插入的 SQL 语句及 位置变量列表，可以实现一次插入多条数据&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;# 插入多条数据（3个变量，包含：id、name、value）
SQL_INSERT_MANY_DATA = 'INSERT INTO PEOPLE (id,name,age) VALUES(?,?,?);'

# 待插入的数据
self.data = [(4, '张三', 11), (5, '李四', 12), (6, '王五', 13)]

def insert_many(self, data):
    &quot;&quot;&quot;新增多条数据&quot;&quot;&quot;
    try:
        self.conn.executemany(SQL_INSERT_MANY_DATA, data)
        self.conn.commit()
    except Exception as e:
        self.conn.rollback()
        print('插入多条记录失败，回滚~')
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;2、查询&lt;/p&gt;
&lt;p&gt;查询分为 2 步，分别是：&lt;/p&gt;
&lt;p&gt;比如：&lt;/p&gt;
&lt;p&gt;要获取所有数据，可以使用游标对象的 fetchall() 方法&lt;/p&gt;
&lt;p&gt;要获取第一条满足条件的数据，可以使用 fetchone() 方法&lt;/p&gt;
&lt;p&gt;另外，fetchmany(num) 可以查询固定数量的数据&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;# 查询的SQL语句
SQL_QUERY_ONE_DATA = &quot;SELECT * FROM PEOPLE WHERE id={}&quot;

def query_one(self, id):
    &quot;&quot;&quot;
    查询一条数据
    :param id:
    :return:
    &quot;&quot;&quot;
    self.cursor.execute(SQL_QUERY_ONE_DATA.format(id))

    # fetchone():查询第一条数据
    # fetchall()：查询所有数据
    # fetchmany(1):查询固定的数量的数据
    result = self.cursor.fetchall()
    print(type(result))
    print(result)
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;3、更新&lt;/p&gt;
&lt;p&gt;和 新增操作 类似，更新操作也是通过数据库连接对象去执行更新的 SQL 语句，最后执行提交操作，将数据真实更新到数据表中&lt;/p&gt;
&lt;p&gt;以更新某一条记录为例&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;# 更新数据
SQL_UPDATE_ONE_DATA = &quot;UPDATE PEOPLE SET NAME = '{}',AGE={} where id = {}&quot;

def update_one(self, id, name, age):
    &quot;&quot;&quot;
    修改一条记录
    :param id:
    :param name:
    :param age:
    :return:
    &quot;&quot;&quot;
    sql_update = SQL_UPDATE_ONE_DATA.format(name, age, id)
    print(sql_update)
    self.conn.execute(sql_update)
    self.conn.commit()
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;4、删除&lt;/p&gt;
&lt;p&gt;删除操作同查询、新增操作类似，只需要执行删除的 SQL 语句即可&lt;/p&gt;
&lt;p&gt;以删除某一条记录为例&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;# 删除数据
SQL_DEL_ONE_DATA = &quot;DELETE FROM PEOPLE where id ={}&quot;

def del_one(self, id):
    &quot;&quot;&quot;通过id去删除一条数据&quot;&quot;&quot;
    sql_del = SQL_DEL_ONE_DATA.format(id)
    self.conn.execute(sql_del)
    self.conn.commit()
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;最后，我们同样需要将游标对象和数据库连接对象，资源释放&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;def teardown(self):
    # 关闭游标和数据库连接，避免资源浪费
    self.cursor.close()
    self.conn.close()
&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;4-sqlalchemy--orm&quot;&gt;4. SQLAlchemy + ORM&lt;/h2&gt;
&lt;p&gt;使用 SQLAlchemy 操作 sqlite 数据库同样先需要安装依赖库&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;# 安装依赖包
pip3 install sqlalchemy
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;通过内置方法 declarative_base() 创建一个基础类 Base&lt;/p&gt;
&lt;p&gt;然后，自定义一个 Base 类的子类，内部通过定义静态变量指定表名、表的字段&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;from sqlalchemy import Column, Integer, String, create_engine
from sqlalchemy.ext.declarative import declarative_base

# 基础类
Base = declarative_base()


# 自定义的表
class People(Base):
    # 表名
    __tablename__ = 'people'

    # 定义字段
    id = Column(Integer, primary_key=True)
    name = Column(String)
    age = Column(Integer)

    def __repr__(self):
        &quot;&quot;&quot;
        便于打印结果
        :return:
        &quot;&quot;&quot;
        return &quot;&amp;lt;People(id:{},name:{},age:{})&quot;.format(self.id, self.name, self.age)
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;接着，通过 SQLAlchemy 的 create_engine(sqlite数据库路径) 方法中创建数据库连接对象&lt;/p&gt;
&lt;p&gt;格式为：sqlite:///数据库相对路径&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;# 创建数据库连接
engine = create_engine('sqlite:///./xh.db', echo=True)
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;最后，通过数据库引擎在数据库中创建表结构，并实例化一个 数据库会话对象&lt;/p&gt;
&lt;p&gt;PS：数据库会话对象内置的方法非常方便我们进行增删改查操作&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;# 创建表结构
# checkfirst：判断表是否存在，如果存在，就不重复创建
Base.metadata.create_all(engine, checkfirst=True)

# 实例化会话
self.session = sessionmaker(bind=engine)()
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;这样所有的准备工作已经完成，接下来可以进行增删改查操作了&lt;/p&gt;
&lt;p&gt;1、新增&lt;/p&gt;
&lt;p&gt;新增操作同样以新增一条和多条记录为例，它们分别对应会话对象的 add()、add_all() 方法&lt;/p&gt;
&lt;p&gt;对于一条记录的新增操作，只需要实例化一个 People 对象，执行上面的会话对象的 add(instance) 和 commit() 两个方法，即可以将数据插入到数据表中&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;def add_one_data(self):
    &quot;&quot;&quot;新增一条数据&quot;&quot;&quot;
    # 创建一个表的实例对象
    people = People(name='xag1', age=24)
    self.session.add(people)

    # 必须提交，才能更新到数据库中
    self.session.commit()
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;如果需要一次插入多条数据，只需要调用 add_all(列表数据) 即可&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;def add_datas(self, data):
    &quot;&quot;&quot;
    新增多条数据
    :return:
    &quot;&quot;&quot;
    self.session.add_all(data)
    self.session.commit()
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;2、查询&lt;/p&gt;
&lt;p&gt;查询数据表的操作对应会话对象的 query() 方法&lt;/p&gt;
&lt;p&gt;同时，还可以结合 all()、first()、filter_by(限制条件) 级联方法限制要查询的数据&lt;/p&gt;
&lt;p&gt;以查询所有记录和根据 id 查询一条记录为例&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;def query_one_data(self, id):
    &quot;&quot;&quot;
    通过id去查询一条数据
    :param id:
    :return:
    &quot;&quot;&quot;
    # 通过id去查询数据，取第一条
    people = self.session.query(People).filter_by(id=id).first()
    print(people)
    print(type(people))

def query_all(self):
    &quot;&quot;&quot;
    查询所有数据
    :return:
    &quot;&quot;&quot;
    peoples = self.session.query(People).all()
    print(peoples)
    print(type(peoples))
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;3、更新&lt;/p&gt;
&lt;p&gt;更新操作一般做法是：&lt;/p&gt;
&lt;ul readability=&quot;0&quot;&gt;&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;query 查询出待更新的对象&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;直接更新对象中的数据&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;使用会话对象提交修改，完成更新操作&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;pre&gt;
&lt;code&gt;def update1(self, id, name, age):
    &quot;&quot;&quot;
    更新记录
    :param id:
    :param name:
    :param age:
    :return:
    &quot;&quot;&quot;
    # 更新步骤：先查询、修改数据、然后确认修改
    people_temp = self.session.query(People).filter_by(id=id).first()

    # 修改数据
    people_temp.name = name
    people_temp.age = age

    # 确认提交修改
    self.session.commit()
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;需要指出的是，&lt;strong&gt;这里也可以使用内置方法 update() ，对上面的更新操作进行简写&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;def update2(self, id, name, age):
    &quot;&quot;&quot;
    更新记录方法2
    :param id:
    :param name:
    :param age:
    :return:
    &quot;&quot;&quot;
    self.session.query(People).filter_by(id=id).update({People.name: name, People.age: age})
    self.session.commit()
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;4、删除&lt;/p&gt;
&lt;p&gt;和更新操作一样，删除操作也有两种实现方式&lt;/p&gt;
&lt;p&gt;第一种方式的思路是，先查询，后删除，最后提交会话完成删除操作&lt;/p&gt;
&lt;p&gt;以按照 id 删除某一条记录为例：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;def del_one_data1(self, id):
    &quot;&quot;&quot;
    删除一条数据方法1
    :param id:
    :return:
    &quot;&quot;&quot;
    people_temp = self.session.query(People).filter_by(id=id).first()

    # 判断是否为空
    if people_temp is not None:
        self.session.delete(people_temp)
        self.session.commit()
    else:
        print('此条记录不存在，删除失败！')
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;需要注意的是，&lt;strong&gt;查询的结果必须判断是否为空，否则直接执行删除操作，可以会抛出异常&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;另外一种方式是，直接使用级联函数将上面的删除操作进行简写&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;def del_one_data2(self, id):
    &quot;&quot;&quot;
    删除一条数据方法2
    :param id:
    :return:
    &quot;&quot;&quot;
    try:
        self.session.query(People).filter_by(id=id).first().delete()
    except Exception as e:
        print('删除失败')
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;同样，这种删除操作需要捕获异常，避免查询的结果为空的情况&lt;/p&gt;
&lt;p&gt;最后，完成所有操作之后，我们需要结束会话、销毁数据库引擎&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;def teardown(self):
    &quot;&quot;&quot;
    释放资源
    :return:
    &quot;&quot;&quot;
    # 结束会话
    self.session.close()

    # 销毁引擎
    self.engine.dispose()
&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;5最后&quot;&gt;5.最后&lt;/h2&gt;
&lt;p&gt;本篇文章通过一张表的增删改查，详细讲解了 Python 操作 sqlite 的两种使用方式&lt;/p&gt;
&lt;p&gt;我已经将文中全部源码上传到后台，关注公众号「 &lt;strong&gt;AirPython&lt;/strong&gt; 」后回复「 &lt;strong&gt;dball&lt;/strong&gt; 」即可获得全部源码&lt;/p&gt;
&lt;p&gt;如果你觉得文章还不错，请大家 &lt;strong&gt;点赞、分享、留言&lt;/strong&gt;下，因为这将是我持续输出更多优质文章的最强动力！&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;推荐阅读&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzU1OTI0NjI1NQ==&amp;amp;mid=2247486468&amp;amp;idx=2&amp;amp;sn=7c8cdfb478e5801496dad8b0ddf2061e&amp;amp;chksm=fc1b72c4cb6cfbd2e71861ddb8aa5d6c2ba3d4266ede047cfaf0558e6cd4e5b05a9ecca4dcdc&amp;amp;scene=21#wechat_redirect&quot;&gt;聊聊 Python 数据处理全家桶（Mysql 篇）&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzU1OTI0NjI1NQ==&amp;amp;mid=2247486453&amp;amp;idx=1&amp;amp;sn=a3af1e7babc58512aa7ce09f3c1662fb&amp;amp;chksm=fc1b7535cb6cfc234c04e5304936ac4dd8225fa7b0c0c38f3b982333736b9aae42dcc25ca6d5&amp;amp;scene=21#wechat_redirect&quot;&gt;Python 如何使用 HttpRunner 做接口自动化测试&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzU1OTI0NjI1NQ==&amp;amp;mid=2247486205&amp;amp;idx=1&amp;amp;sn=33dd05fc416daf1cc041bc76b53b733a&amp;amp;chksm=fc1b743dcb6cfd2b3dd1f1585bf0c3a4175e39a6dfdc7fe8a5792a405c50da2d7569fb361454&amp;amp;scene=21#wechat_redirect&quot;&gt;Python 自动化，Helium 凭什么取代 Selenium？&lt;/a&gt;&lt;/p&gt;
</description>
<pubDate>Sun, 20 Sep 2020 15:22:00 +0000</pubDate>
<dc:creator>AirPython</dc:creator>
<og:description>1. 前言 上篇文章&amp;amp;#160;聊到 Python 处理 Mysql 数据库最常见的两种方式，本篇文章继续说另外一种比较常用的数据库：Sqlite Sqlite 是一种&amp;amp;#160;嵌入</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/xingag/p/13702975.html</dc:identifier>
</item>
<item>
<title>asp.net core 从 3.1 到 5.0 - WeihanLi</title>
<link>http://www.cnblogs.com/weihanli/p/migrate-to-net5-from-netcore3_1.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/weihanli/p/migrate-to-net5-from-netcore3_1.html</guid>
<description>&lt;h2 id=&quot;intro&quot;&gt;Intro&lt;/h2&gt;
&lt;p&gt;就在前几天，微软宣布了 .NET5 发布了 RC1 版本，这也意味着 .NET5 的开发基本稳定了，正式发布之前，不会再新增新的 Feature，只会专注于修复 BUG 提高稳定性。&lt;/p&gt;
&lt;p&gt;对于开发者来说，RC版本的发布也意味着功能的稳定，可以上手尝尝鲜了，正式版的 API 不会再发生变化了，即使后面迁移到正式版也会很简单&lt;/p&gt;
&lt;p&gt;于是尝试着把我之前练手的一个小项目 asp.net core webapi 的项目从 3.1 迁移到了 5.0，意想不到的顺利，要比 2.x 更新顺利的多&lt;/p&gt;
&lt;h2 id=&quot;项目文件更新&quot;&gt;项目文件更新&lt;/h2&gt;
&lt;p&gt;首先需要更新项目的 &lt;code&gt;TargetFramework&lt;/code&gt; 从原来的 &lt;code&gt;netcoreapp3.1&lt;/code&gt; 变更到 &lt;code&gt;net5.0&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/489462/202009/489462-20200920224938479-1239974240.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h2 id=&quot;包引用更新&quot;&gt;包引用更新&lt;/h2&gt;
&lt;p&gt;原来引用的 3.1.x 版本的 nuget 包更新成 5.0 的包&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/489462/202009/489462-20200920225035481-1231026871.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;这里有几个不是 asp.net core 的包也顺带更新了&lt;/p&gt;
&lt;p&gt;这里更新用的包版本我使用的不是具体的版本号，你也可以使用具体的版本号，都是可以的&lt;/p&gt;
&lt;h2 id=&quot;docker-镜像更新&quot;&gt;Docker 镜像更新&lt;/h2&gt;
&lt;p&gt;docker 镜像的更新分为两部分，一个是镜像名称，一个是镜像 tag&lt;/p&gt;
&lt;p&gt;镜像 tag 比较好说，要从 3.1 更新成 5.0&lt;/p&gt;
&lt;p&gt;镜像名称的变化是原来的镜像名称中有一个 &lt;code&gt;core&lt;/code&gt;，在 net 5.0 中移除了，不再突出区分 &lt;code&gt;core&lt;/code&gt; 了&lt;/p&gt;
&lt;p&gt;具体的如下：&lt;/p&gt;
&lt;p&gt;&lt;code&gt;mcr.microsoft.com/dotnet/core/sdk&lt;/code&gt; =&amp;gt; &lt;code&gt;mcr.microsoft.com/dotnet/sdk&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;mcr.microsoft.com/dotnet/core/aspnet&lt;/code&gt; =&amp;gt; &lt;code&gt;mcr.microsoft.com/dotnet/aspnet&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/489462/202009/489462-20200920225137146-484268095.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h2 id=&quot;more&quot;&gt;More&lt;/h2&gt;
&lt;p&gt;总体来说，更新还是相当顺利的，从 3.1 到 5.0，asp.net core 的 API 大多都是兼容的，没有特别大的变更(Blazor 除外，Blazor有一些大的变更)，&lt;br/&gt;只需要更新项目 Target 和包版本以及 dockerfile 中基本镜像的更新。&lt;/p&gt;
&lt;p&gt;docker 镜像需要注意一下，不仅仅是改一下 tag，从 3.1 改成 5.0，最近我就是这样改的，结果提示找不到 tag，导致 build 失败了，&lt;/p&gt;
&lt;p&gt;后来仔细看了一下，docker 镜像名称也发生了变化，移除了原来镜像名称中的 core，更好的体现了 target 的变化，无论是项目文件中的 &lt;code&gt;TargetFramework&lt;/code&gt; 还是 docker 镜像都移除了名称中的 core，也正是体现了微软对于 .net core 的发展路线&lt;/p&gt;
&lt;p&gt;后来突然想起来微软官方文档上应该有迁移文档，然后就赶紧去看一下，微软文档上已经有说明了 docker 镜像名称的变化（应该先看微软的官方文档才对。。。不要学我，要先看微软的文档）&lt;/p&gt;
&lt;h2 id=&quot;reference&quot;&gt;Reference&lt;/h2&gt;
</description>
<pubDate>Sun, 20 Sep 2020 14:56:00 +0000</pubDate>
<dc:creator>WeihanLi</dc:creator>
<og:description>从 asp.net core 3.1 迁移到 net 5</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/weihanli/p/migrate-to-net5-from-netcore3_1.html</dc:identifier>
</item>
</channel>
</rss>