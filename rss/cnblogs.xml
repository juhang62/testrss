<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="css/feed.xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/" xmlns:og="http://ogp.me/ns#">
<channel>
<atom:link rel="self" href="http://192.168.1.4/fivefilters/makefulltextfeed.php?url=feed.cnblogs.com%2Fblog%2Fsitehome%2Frss&amp;max=10&amp;links=preserve&amp;exc=" />
<atom:link rel="alternate" title="Source URL" href="http://feed.cnblogs.com/blog/sitehome/rss" />
<atom:link rel="related" title="Subscribe to feed" href="http://www.subtome.com/#/subscribe?feeds=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed.cnblogs.com%252Fblog%252Fsitehome%252Frss%26max%3D10%26links%3Dpreserve%26exc%3D&amp;back=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed.cnblogs.com%252Fblog%252Fsitehome%252Frss%26max%3D10%26links%3Dpreserve%26exc%3D" />
<title>博客园_首页</title>
<link></link>
<description>代码改变世界</description>
<item>
<title>Protoc Buffer 优化传输大小的一个细节 - 渡码</title>
<link>http://www.cnblogs.com/duma/p/11111427.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/duma/p/11111427.html</guid>
<description>&lt;p&gt;&lt;span&gt;Protoc Buffer 是我们比较常用的序列化框架，Protocol Buffer 序列化后的占空间小，传输高效，可以在不同编程语言以及平台之间传输。今天这篇文章主要介绍 Protocol Buffer 使用 VarInt32 减少序列化后的数据大小。&lt;/span&gt;&lt;/p&gt;
&lt;h2&gt;VarInt32 编码&lt;/h2&gt;
&lt;p&gt;&lt;span&gt; VarInt32 (vary int 32)，即：长度可变的 32 为整型类型。一般来说，int 类型的长度固定为 32 字节。但 VarInt32 类型的数据长度是不固定的，VarInt32 中每个字节的最高位有特殊的含义。如果最高位为 1 代表下一个字节也是该数字的一部分。因此，表示一个整型数字最少用 1 个字节，最多用 5 个字节表示。如果某个系统中大部分数字需要 &amp;gt;= 4 字节才能表示，那其实并不适合用 VarInt32 来编码。下面以一个例子解释 VarInt32 的编码方式：&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;35&quot;&gt;
&lt;pre&gt;
以 129 为例，它的二进制为 1000 0001 。&lt;br/&gt;由于每个字节最高位用于特殊标记，因此只能有 7 位存储数据。&lt;br/&gt;第一个字节存储最后 7 位 （000 0001），但并没有存下所有的比特，因此最高位置位 1，剩下的部分用后续字节表示。所以，第一个字节为：1000 0001&lt;br/&gt;第二个字节只存储一个比特位即可，因此最高位为 0 ，所以，第二个字节为：0000 0001&lt;br/&gt;这样，我们就不必用 4 字节的整型存储 129 ，可以节省存储空间
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span&gt;在 Protoc buffer 中，每一个 ProtoBuf 对象都有一个方法 &lt;span&gt;public void writeDelimitedTo(final OutputStream output)&lt;/span&gt;，该方法将 ProtoBuf 对象序列化后的长度以及序列化数据本身写入到输出流 output 中。多个对象调用该方法可以将序列化后的数据写入到同一个输出流。由于每次写入都有长度，所以反序列化时先解析长度，在读取对应长度的字节数据，即可解析出每个对象。该方法中对序列化后长度的编码便使用 VarInt32，因为一个 Protobuf 对象序列化后的长度不会太大，因此使用 VarInt32 编码能够有效的节省存储空间。接下来我们看下 Protoc Buffer 中如何实现 VarInt32 编码，跟进 writeDelimitedTo 方法，可以看到 VarInt32 编码的源码如下：&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;36&quot;&gt;
&lt;pre&gt;
  &lt;span&gt;/**&lt;/span&gt;&lt;span&gt;
   * Encode and write a varint.  {&lt;/span&gt;&lt;span&gt;@code&lt;/span&gt;&lt;span&gt; value} is treated as
   * unsigned, so it won't be sign-extended if negative.
   &lt;/span&gt;&lt;span&gt;*/&lt;/span&gt;
  &lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; writeRawVarint32(&lt;span&gt;int&lt;/span&gt; value) &lt;span&gt;throws&lt;/span&gt;&lt;span&gt; IOException {
    &lt;/span&gt;&lt;span&gt;while&lt;/span&gt; (&lt;span&gt;true&lt;/span&gt;&lt;span&gt;) {
      &lt;/span&gt;&lt;span&gt;if&lt;/span&gt; ((value &amp;amp; ~0x7F) == 0) {&lt;span&gt;//代表只有低7位有值，因此只需1个字节即可完成编码&lt;/span&gt;
&lt;span&gt;        writeRawByte(value);
        &lt;/span&gt;&lt;span&gt;return&lt;/span&gt;&lt;span&gt;;
      } &lt;/span&gt;&lt;span&gt;else&lt;/span&gt;&lt;span&gt; {
        writeRawByte((value &lt;/span&gt;&amp;amp; 0x7F) | 0x80);&lt;span&gt;//代表编码不止一个字节，value &amp;amp; 0x7f 只取低 7 位，与 0x80 进行按位或（|）运算为了将最高位置位 1 ，代表后续字节也是改数字的一部分
&lt;/span&gt;        value &amp;gt;&amp;gt;&amp;gt;= 7&lt;span&gt;;
      }
    }
  }&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span&gt;该方法对 int 类型的值进行 VarInt32 编码，可以验证最多 5 个字节即可完成编码。&lt;/span&gt;&lt;/p&gt;
&lt;h2&gt;VarInt32 解码&lt;/h2&gt;
&lt;p&gt;&lt;span&gt; 理解了编码后，解码就没什么可说的了。就是从输入字节流中，读取一个字节判断最高位，将真实数据位拼接成最终的数字即可。Hadoop RPC 中使用了 Protoc Buffer 作为数据序列化框架。其中，Hadoop 针对 writeDelimitedTo 方法实现了对 VarInt32 的解码。源码如下：&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;35&quot;&gt;
&lt;pre&gt;
&lt;span&gt;/**&lt;/span&gt;&lt;span&gt;
   * Read a variable length integer in the same format that ProtoBufs encodes.
   * &lt;/span&gt;&lt;span&gt;@param&lt;/span&gt;&lt;span&gt; in the input stream to read from
   * &lt;/span&gt;&lt;span&gt;@return&lt;/span&gt;&lt;span&gt; the integer
   * &lt;/span&gt;&lt;span&gt;@throws&lt;/span&gt;&lt;span&gt; IOException if it is malformed or EOF.
   &lt;/span&gt;&lt;span&gt;*/&lt;/span&gt;
  &lt;span&gt;public&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; &lt;span&gt;int&lt;/span&gt; readRawVarint32(DataInput in) &lt;span&gt;throws&lt;/span&gt;&lt;span&gt; IOException {
    &lt;/span&gt;&lt;span&gt;byte&lt;/span&gt; tmp =&lt;span&gt; in.readByte();
    &lt;/span&gt;&lt;span&gt;if&lt;/span&gt; (tmp &amp;gt;= 0&lt;span&gt;) {// tmp &amp;gt;= 0 代表最高位是 0 ，否则 tmp &amp;lt; 0 代表最高位是 1 ，需要继续往下读
      &lt;/span&gt;&lt;span&gt;return&lt;/span&gt;&lt;span&gt; tmp;
    }
    &lt;/span&gt;&lt;span&gt;int&lt;/span&gt; result = tmp &amp;amp; 0x7f&lt;span&gt;;
    &lt;/span&gt;&lt;span&gt;if&lt;/span&gt; ((tmp = in.readByte()) &amp;gt;= 0&lt;span&gt;) {
      result &lt;/span&gt;|= tmp &amp;lt;&amp;lt; 7&lt;span&gt;;
    } &lt;/span&gt;&lt;span&gt;else&lt;/span&gt;&lt;span&gt; {
      result &lt;/span&gt;|= (tmp &amp;amp; 0x7f) &amp;lt;&amp;lt; 7&lt;span&gt;;
      &lt;/span&gt;&lt;span&gt;if&lt;/span&gt; ((tmp = in.readByte()) &amp;gt;= 0&lt;span&gt;) {
        result &lt;/span&gt;|= tmp &amp;lt;&amp;lt; 14&lt;span&gt;;
      } &lt;/span&gt;&lt;span&gt;else&lt;/span&gt;&lt;span&gt; {
        result &lt;/span&gt;|= (tmp &amp;amp; 0x7f) &amp;lt;&amp;lt; 14&lt;span&gt;;
        &lt;/span&gt;&lt;span&gt;if&lt;/span&gt; ((tmp = in.readByte()) &amp;gt;= 0&lt;span&gt;) {
          result &lt;/span&gt;|= tmp &amp;lt;&amp;lt; 21&lt;span&gt;;
        } &lt;/span&gt;&lt;span&gt;else&lt;/span&gt;&lt;span&gt; {
          result &lt;/span&gt;|= (tmp &amp;amp; 0x7f) &amp;lt;&amp;lt; 21&lt;span&gt;;
          result &lt;/span&gt;|= (tmp = in.readByte()) &amp;lt;&amp;lt; 28&lt;span&gt;;
          &lt;/span&gt;&lt;span&gt;if&lt;/span&gt; (tmp &amp;lt; 0) {&lt;span&gt;//我们说 VarInt32 最多 5 个字节表示，当程序执行到这里，tmp &amp;lt; 0，说明，编码格式有问题&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; Discard upper 32 bits.&lt;/span&gt;
            &lt;span&gt;for&lt;/span&gt; (&lt;span&gt;int&lt;/span&gt; i = 0; i &amp;lt; 5; i++&lt;span&gt;) {
              &lt;/span&gt;&lt;span&gt;if&lt;/span&gt; (in.readByte() &amp;gt;= 0&lt;span&gt;) {
                &lt;/span&gt;&lt;span&gt;return&lt;/span&gt;&lt;span&gt; result;
              }
            }
            &lt;/span&gt;&lt;span&gt;throw&lt;/span&gt; &lt;span&gt;new&lt;/span&gt; IOException(&quot;Malformed varint&quot;&lt;span&gt;);
          }
        }
      }
    }
    &lt;/span&gt;&lt;span&gt;return&lt;/span&gt;&lt;span&gt; result;
  }&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span&gt;在 Hadoop 源码中并没有使用循环去解码，而是使用多个 if 条件判断，根据 tmp 的正负号来判断最高位是否是 1。如果读取的该数字用了 5 个字节编码，当读到了第 5 个字节，理论上 tmp 应该大于 0 。但是如果 tmp 小于 0 ，说明编码格式有问题。在 Hadoop 源码中程序会继续往下读，最多再向下读 5 个字节且丢掉最高位仍然 &amp;lt; 0 的字节。如果在该过程某个字节最高位为 0 ，便停止读取直接返回。这个处理逻辑在其他框架源码中也有出现。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;看完 Hadoop 的源码，我们在看看 Protoc Buffer 自己提供的解析源码：&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;37&quot;&gt;
&lt;pre&gt;
  &lt;span&gt;/**&lt;/span&gt;&lt;span&gt;
   * Like {&lt;/span&gt;&lt;span&gt;@link&lt;/span&gt;&lt;span&gt; #readRawVarint32(InputStream)}, but expects that the caller
   * has already read one byte.  This allows the caller to determine if EOF
   * has been reached before attempting to read.
   &lt;/span&gt;&lt;span&gt;*/&lt;/span&gt;
  &lt;span&gt;public&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; &lt;span&gt;int&lt;/span&gt;&lt;span&gt; readRawVarint32(
      &lt;/span&gt;&lt;span&gt;final&lt;/span&gt; &lt;span&gt;int&lt;/span&gt; firstByte, &lt;span&gt;final&lt;/span&gt; InputStream input) &lt;span&gt;throws&lt;/span&gt;&lt;span&gt; IOException {
    &lt;/span&gt;&lt;span&gt;if&lt;/span&gt; ((firstByte &amp;amp; 0x80) == 0&lt;span&gt;) {
      &lt;/span&gt;&lt;span&gt;return&lt;/span&gt;&lt;span&gt; firstByte;
    }

    &lt;/span&gt;&lt;span&gt;int&lt;/span&gt; result = firstByte &amp;amp; 0x7f&lt;span&gt;;
    &lt;/span&gt;&lt;span&gt;int&lt;/span&gt; offset = 7&lt;span&gt;;
    &lt;/span&gt;&lt;span&gt;for&lt;/span&gt; (; offset &amp;lt; 32; offset += 7&lt;span&gt;) {
      &lt;/span&gt;&lt;span&gt;final&lt;/span&gt; &lt;span&gt;int&lt;/span&gt; b =&lt;span&gt; input.read();
      &lt;/span&gt;&lt;span&gt;if&lt;/span&gt; (b == -1&lt;span&gt;) {
        &lt;/span&gt;&lt;span&gt;throw&lt;/span&gt;&lt;span&gt; InvalidProtocolBufferException.truncatedMessage();
      }
      result &lt;/span&gt;|= (b &amp;amp; 0x7f) &amp;lt;&amp;lt;&lt;span&gt; offset;
      &lt;/span&gt;&lt;span&gt;if&lt;/span&gt; ((b &amp;amp; 0x80) == 0&lt;span&gt;) {
        &lt;/span&gt;&lt;span&gt;return&lt;/span&gt;&lt;span&gt; result;
      }
    }
    &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; Keep reading up to 64 bits.&lt;/span&gt;
    &lt;span&gt;for&lt;/span&gt; (; offset &amp;lt; 64; offset += 7&lt;span&gt;) {
      &lt;/span&gt;&lt;span&gt;final&lt;/span&gt; &lt;span&gt;int&lt;/span&gt; b =&lt;span&gt; input.read();
      &lt;/span&gt;&lt;span&gt;if&lt;/span&gt; (b == -1&lt;span&gt;) {
        &lt;/span&gt;&lt;span&gt;throw&lt;/span&gt;&lt;span&gt; InvalidProtocolBufferException.truncatedMessage();
      }
      &lt;/span&gt;&lt;span&gt;if&lt;/span&gt; ((b &amp;amp; 0x80) == 0&lt;span&gt;) {
        &lt;/span&gt;&lt;span&gt;return&lt;/span&gt;&lt;span&gt; result;
      }
    }
    &lt;/span&gt;&lt;span&gt;throw&lt;/span&gt;&lt;span&gt; InvalidProtocolBufferException.malformedVarint();
  }&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span&gt;可以看到 Protoc Buffer 自己提供的解码方式与 Hadoop 是一样的，包括遇到错误的编码时候的异常处理方式也是一样的。&lt;/span&gt;&lt;/p&gt;
&lt;h2&gt;小结&lt;/h2&gt;
&lt;p&gt;&lt;span&gt;本篇文章主要介绍了 VarInt32 编解码，VarInt32 表示一个整型数字最少用 1 个字节， 最多用 5 个字节。所以在传输数字大部分都比较小的场景下适合使用。当然，我们也可以用 VarInt64 来表示长整型的数字。 在介绍 VarInt32 的同时我们也看到了 ProtoBuf 和 Hadoop 这样的框架在传输数据的优化上不放过任何一个细节，值得我们学习。&lt;/span&gt;&lt;/p&gt;
</description>
<pubDate>Tue, 02 Jul 2019 00:32:00 +0000</pubDate>
<dc:creator>渡码</dc:creator>
<og:description>Protoc Buffer 是我们比较常用的序列化框架，Protocol Buffer 序列化后的占空间小，传输高效，可以在不同编程语言以及平台之间传输。今天这篇文章主要介绍 Protocol Buf</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/duma/p/11111427.html</dc:identifier>
</item>
<item>
<title>爬虫到底违法吗？这位爬虫工程师给出了答案 - 猪哥66</title>
<link>http://www.cnblogs.com/pig66/p/11111763.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/pig66/p/11111763.html</guid>
<description>&lt;p&gt;&lt;a href=&quot;https://www.cnblogs.com/pig66/p/10995446.html&quot;&gt;六月分享主题：爬虫&lt;/a&gt;&lt;br/&gt;&lt;a href=&quot;https://www.cnblogs.com/pig66/p/11013289.html&quot;&gt;HTTP详解&lt;/a&gt;&lt;br/&gt;&lt;a href=&quot;https://www.cnblogs.com/pig66/p/11059146.html&quot;&gt;网页结构简介&lt;/a&gt;&lt;br/&gt;&lt;a href=&quot;https://www.cnblogs.com/pig66/p/11080757.html&quot;&gt;一文带你了解爬虫&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;大家好，本期将为大家来采访一位爬虫工程师，与他相识是在一个技术号主群中，只有他怼了我的文章，所以也算不打不相识！他便是&lt;strong&gt;小周码字&lt;/strong&gt;号主：Loco。&lt;br/&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20190630215224582.jpg?&quot; alt=&quot;在这里插入图片描述&quot;/&gt;&lt;br/&gt;文章主要分为三部分，第一部分为Loco自述：简单讲述一下他是如何从大学生一步一步走到现在。第二部分为提问解答：猪哥收集了近100个问题，然后由Loco大佬自行选择回答，快看看你有没有被翻牌吧！第三部分是猪哥从Loco回答中提取的一些关键字，希望能加深大家的记忆。&lt;/p&gt;
&lt;h2 id=&quot;-&quot;&gt;一、自述&lt;/h2&gt;
&lt;h3 id=&quot;1-&quot;&gt;1.关于大学&lt;/h3&gt;
&lt;p&gt;我读的大学是个野鸡学校，虽说是一个计算机专业，但实际的课程内容很杂。CAD、3DMAX、Office全家桶之类的都会有，所以在校期间对编程方面的成长并不大，当时也就只有写个批量改文件名的工具这种水平。&lt;/p&gt;
&lt;p&gt;毕业以后到目前为止也就在两家公司工作过，一家是上家公司，另一个是现在这家，总体路程还算顺利吧，没遇到过什么大的挫折，各种需求也能逼着自己成长。&lt;/p&gt;
&lt;h3 id=&quot;2-&quot;&gt;2.接触爬虫&lt;/h3&gt;
&lt;p&gt;我接触爬虫这方面的起因，其实是因为找实习，当时快毕业了嘛，要先找个实习锻炼锻炼。但是因为我认为我能做的方向比较多，也还没有想好到底往哪个方向发展比较好，&lt;strong&gt;所以就开始看知乎的相关回答&lt;/strong&gt;，然后发现数据相关的好像都不错，爬虫这个方向看起来也挺有意思的，就边学边开始海投简历。&lt;/p&gt;
&lt;p&gt;投着投着我就发现了一个问题，投简历这个事情太机械化了，能不能写个程序帮我自动投？我就可以腾出这部分时间来干点别的事情了，这样还能顺便练一练写爬虫的技术。&lt;/p&gt;
&lt;p&gt;万幸的是，当时的拉勾、智联、实习僧、58等招聘网站的反爬基本没有，对于一个初学爬虫的人来说还是可以轻松地自己解决：&lt;strong&gt;搜索-&amp;gt; 获取职位详情-&amp;gt;投递简历&lt;/strong&gt;这个操作的。&lt;/p&gt;
&lt;p&gt;于是，一个自动投简历的小工具就诞生了，虽然代码十分简陋，&lt;strong&gt;完全就是用requests库以一个流程化的方式写下来的&lt;/strong&gt;，但已经足够达到我想要的效果了。在那之后，我每天就只需要等待面试通知和电话面试，发现有合适的就去面试一下就好了，节省了大量的时间用在搞项目上。&lt;br/&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20190630225406220.jpg?&quot; alt=&quot;在这里插入图片描述&quot;/&gt;&lt;/p&gt;
&lt;h3 id=&quot;3-&quot;&gt;3.第一家公司&lt;/h3&gt;
&lt;p&gt;然后大概这么投了一个多星期吧，&lt;strong&gt;中间面了十多个公司&lt;/strong&gt;，有大有小，但都是要么不太满意、要么对应方向的技术深度还不够，直到碰到了上家公司。那是一家创业公司，可能因为创始人是做技术出身的关系吧，公司氛围很不错，跟老板聊起来也很舒服，然后公司本身也是专门做爬虫相关产品的，所以就去了这家公司。&lt;/p&gt;
&lt;p&gt;在这家公司的那段时间应该是我技术水平成长最快的时候了，因为每天做的事情就是写爬虫，&lt;strong&gt;当时我们团队将应用商店排名前100的所有APP都“弄”了&lt;/strong&gt;。什么乱七八糟的问题都有碰到过，&lt;strong&gt;然后因为团队里每个人有天赋的方向都不同，一边被需求逼着查各种资料、挑战自己，一边互相补充知识，成长速度就非常快了&lt;/strong&gt;。&lt;br/&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20190630225421807.gif&quot; alt=&quot;在这里插入图片描述&quot;/&gt;&lt;/p&gt;
&lt;h3 id=&quot;4-&quot;&gt;4.目前&lt;/h3&gt;
&lt;p&gt;从那离职以后我进了现在这家公司，目前做的主要就是区块链搜索引擎的数据收集。看似简单但实际还是很有挑战性的，因为区块链的特性会导致数据量非常大，而且区块链还不像传统互联网网站那样有个标准化的HTML，存在着各种麻烦的问题。所以对于我自己的技术水平增长速度也是有很大的影响的。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;总结一下其实还是那句话，需求逼的。&lt;/strong&gt;&lt;br/&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20190630225434464.jpg&quot; alt=&quot;在这里插入图片描述&quot;/&gt;&lt;/p&gt;
&lt;h2 id=&quot;-&quot;&gt;二、解答&lt;/h2&gt;
&lt;p&gt;在采访大佬的时候，我在朋友圈征集了大概100个问题，以下是大佬随机挑选的21个比较有代表性的问题进行解答。&lt;/p&gt;
&lt;p&gt;注：以下“爬虫”均指“垂直爬虫”&lt;/p&gt;
&lt;h3 id=&quot;1-&quot;&gt;1.非爬虫方向的技术转行做爬虫是否可行？&lt;/h3&gt;
&lt;p&gt;可行，而且有一定的基础会很容易上手，至于深入的部分就看自己了。&lt;/p&gt;
&lt;h3 id=&quot;2-&quot;&gt;2.非技术转行做爬虫是否可行？&lt;/h3&gt;
&lt;p&gt;可行，但我认为较难，因为爬虫做深了以后是需要你了解各种相关领域知识的，而你现在对这些领域的东西一无所知，甚至可能连编程都还不知道怎么开始，起点会比有基础的人低很多。&lt;/p&gt;
&lt;h3 id=&quot;3-&quot;&gt;3.爬虫工作日常如何？加班多不多？&lt;/h3&gt;
&lt;p&gt;这个得看公司的，有些公司搞得都是些天天更新反爬的平台（比如工商信息相关的），那基本就是得一直盯着看会不会出问题，一不小心就会要加班。&lt;/p&gt;
&lt;h3 id=&quot;4-&quot;&gt;4.爬虫对于学生党的用处体现在哪些地方？&lt;/h3&gt;
&lt;p&gt;这个问题看个人，因为爬虫技术可用的地方太多了，没法一个一个地都拿出来说。比如你想搞个自动签到的工具，这其实本质上就是爬虫；比如你想搞个自动回复设定内容的机器人，这其实本质上也是爬虫。&lt;/p&gt;
&lt;h4 id=&quot;5-&quot;&gt;5.学到什么程度才能入职爬虫工程师？&lt;/h4&gt;
&lt;p&gt;我觉得首先发请求不用说了吧？抓包工具的使用也不用说了吧？熟练掌握XPath、正则表达式这种解析工具也是基本的，然后JSON之类的传输格式至少要了解过长啥样吧，再就是JS逆向总得会一点吧（从只改变量名函数名混淆级别的代码中找出加密参数生成部分的程度）。差不多会这些以后，再自己做几个项目，应聘个初级爬虫工程师没啥问题。&lt;/p&gt;
&lt;h3 id=&quot;6-&quot;&gt;6.如何成为一名优秀的爬虫工程师？&lt;/h3&gt;
&lt;p&gt;垂直爬虫做到后面本质上就是逆向，你需要有良好的逆向思维方式，并且对一些安全领域的骚东西也有一定的了解，这样你才能游刃有余地处理高难度的反爬。&lt;/p&gt;
&lt;h3 id=&quot;7-&quot;&gt;7.学爬虫的学习路线？&lt;/h3&gt;
&lt;p&gt;上面的入职水平了解一下？然后就是可以关注一下我的公众号「&lt;strong&gt;小周码字&lt;/strong&gt;」（猪哥强力推荐）学习进阶内容，网上其他的教程绝对没有讲得这么细的。&lt;/p&gt;
&lt;h3 id=&quot;8-&quot;&gt;8.大约学习并从事爬虫几年才可以达到一个不错的高度？&lt;/h3&gt;
&lt;p&gt;这个问题也很看个人，我觉得主要看有没有需求逼迫成长吧。之前招人的时候，很多三年经验的也就比入门水平稍微好一点，他们在工作时所遇到的难点几乎全是依靠自动化测试工具，对逆向水平毫无增长。&lt;strong&gt;所以建议还是多依靠逆向手段去解决问题，成长速度会很快&lt;/strong&gt;。&lt;/p&gt;
&lt;h3 id=&quot;9-15k-&quot;&gt;9.薪资方面如何，在几年内可以达到15K？&lt;/h3&gt;
&lt;p&gt;同上，标15K及以上的招聘JD还是挺多的，看看招聘需求就知道大概到什么程度了。&lt;/p&gt;
&lt;h3 id=&quot;10-&quot;&gt;10.面试爬虫哪些技能点是加分项？&lt;/h3&gt;
&lt;p&gt;丰富且有深度的逆向经验、熟悉通信协议底层实现、做过骚东西等各种，但主要还是逆向经验。&lt;br/&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20190630225525447.jpg?&quot; alt=&quot;在这里插入图片描述&quot;/&gt;&lt;/p&gt;
&lt;h3 id=&quot;11-&quot;&gt;11.作为一名爬虫工程师，对该岗位的前景如何看待？&lt;/h3&gt;
&lt;p&gt;未来主要内容在APP上的平台应该会越来越多，难度也会越来越高，所以对于爬虫工程师的逆向水平要求会越来越高，只会简单逆向甚至不会逆向的人找工作会越来越难。&lt;/p&gt;
&lt;h3 id=&quot;12-&quot;&gt;12.爬虫和数据挖掘是一样的吗？&lt;/h3&gt;
&lt;p&gt;不一样，爬虫只是将数据取回来，具体怎么分析才是数据挖掘的事情。&lt;/p&gt;
&lt;h3 id=&quot;13-&quot;&gt;13.爬虫是否和黑客差不多？&lt;/h3&gt;
&lt;p&gt;差很多，与上个问题类似，只不过“黑客”这个词太宽泛了，黑客也是有具体方向的。&lt;/p&gt;
&lt;h3 id=&quot;14-&quot;&gt;14.千奇百怪的验证码只能对接打码平台吗？有啥其他办法？&lt;/h3&gt;
&lt;p&gt;自己破呗，逆向+机器学习。&lt;/p&gt;
&lt;h3 id=&quot;15-pyppeteer-selenium-&quot;&gt;15.现在有用pyppeteer吗？还是一直是selenium？&lt;/h3&gt;
&lt;p&gt;都不用，因为效率太低了。&lt;/p&gt;
&lt;h3 id=&quot;16-xx-&quot;&gt;16.如何爬xx平台？&lt;/h3&gt;
&lt;p&gt;涉及法律问题，这种针对某个平台的东西是不能细说的。&lt;/p&gt;
&lt;h3 id=&quot;17-&quot;&gt;17.爬虫违法吗？如何避免过线导致的违法？怎么规避法律风险？&lt;/h3&gt;
&lt;p&gt;算是擦边球吧，其实你即使遵守规则去爬别人的网站，只要人家想搞你，还是可以让你做的事情变成违法的。所以建议不要做太过分的事情，毕竟狗急了也会跳墙。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;还有就是不要为一些明显是做灰黑产的人/公司写代码，一旦他们出事了，你也会被牵连。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;知乎上之前那个很火的被抓了的人，从回答内容中来看其实就是做打码平台的那个微凉，他这一个平台据说赚了至少千万，主要应该是提供给做黑产的人使用了，这种其实被抓是迟早的事。最好的避免违法的办法就是明显觉得不太好的事情就不要去碰，基本就不会有啥问题。&lt;/p&gt;
&lt;h3 id=&quot;18-&quot;&gt;18.如何有目的地爬取到真正想要的数据？&lt;/h3&gt;
&lt;p&gt;让需要数据的人提需求，如果你自己就是那个需要数据的人，那就去做市场调研，看看你需要的数据在哪里能找到。&lt;br/&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20190630225456922.jpg?&quot; alt=&quot;在这里插入图片描述&quot;/&gt;&lt;/p&gt;
&lt;h3 id=&quot;19-&quot;&gt;19.反爬虫最先进的技术是什么？最有效的技术是什么？&lt;/h3&gt;
&lt;p&gt;最先进的技术其实就是使用在PC平台上已经玩烂的各种反破解技术将行为监测点（设备指纹、用户操作等）隐藏起来，然后传给服务端做行为识别，如果操作非人类或者缺少某些东西就触发风控。&lt;/p&gt;
&lt;p&gt;最有效的技术其实不是技术而是方法，这个方法就是账号收费，将你的数据变成需要花多少钱才能看到这样子的，就能做到啥高端技术都不用上、轻松提高爬虫方的获取数据成本的效果，当然这也需要结合良好的产品设计，否则普通用户的体验会很差。&lt;/p&gt;
&lt;h3 id=&quot;20-xx-&quot;&gt;20.请问在xx领域有哪些应用？&lt;/h3&gt;
&lt;p&gt;这个应该是对应领域的人自己思考一下自己拿到那些公开数据究竟可以做什么。&lt;/p&gt;
&lt;h3 id=&quot;21-&quot;&gt;21.需要大量账号的平台成本过高该怎么办？&lt;/h3&gt;
&lt;p&gt;人家就是依靠这种方式来提高你成本的，你如果觉得成本过高要么放弃要么换一条路线获取数据。&lt;/p&gt;
&lt;h2 id=&quot;-&quot;&gt;三、关键字&lt;/h2&gt;
&lt;h3 id=&quot;1-&quot;&gt;1.实践&lt;/h3&gt;
&lt;p&gt;Loco在投简历时直接使用爬虫进行投简历，实习就有这种骚操作，让我明白一个道理：实践是获得高薪的一个捷径！&lt;/p&gt;
&lt;h3 id=&quot;2-&quot;&gt;2.需求逼的&lt;/h3&gt;
&lt;p&gt;和Loco大佬深有同感，尤其在最开始工作的那几年，需求是推动学习成长最快的方法，不逼一把自己，怎么知道你的上限有多高？&lt;/p&gt;
&lt;h3 id=&quot;3-&quot;&gt;3.逆向&lt;/h3&gt;
&lt;p&gt;和多位爬虫工程师交流过，一致认为逆向是最重要的一项技能，后面猪哥也会多学习并写一些逆向方面的教程！&lt;/p&gt;
&lt;h4 id=&quot;4-&quot;&gt;4.法律意识&lt;/h4&gt;
&lt;p&gt;爬虫本身就是打法律的擦边球，所以作为技术人我们更应该守住底线，向灰黑色产业说不。如果有些东西你不能确认是不是违法，可以向身边朋友咨询或者百度，切莫存侥幸心理！&lt;/p&gt;
&lt;h2 id=&quot;-&quot;&gt;四、感谢&lt;/h2&gt;
&lt;p&gt;最后感谢Loco大佬在百忙中抽出时间接受猪哥的采访，猪哥也看过他的一些爬虫教程，目前很少有人会讲爬虫的逆向，而他是其中一位！&lt;/p&gt;
&lt;p&gt;对于那些没有被翻牌的或者还有其他问题想要咨询的同学，大家可以关注Loco大佬的公众号：&lt;strong&gt;小周码字&lt;/strong&gt;，直接向他提问吧！&lt;/p&gt;
&lt;p&gt;​&lt;/p&gt;
</description>
<pubDate>Tue, 02 Jul 2019 00:18:00 +0000</pubDate>
<dc:creator>猪哥66</dc:creator>
<og:description>六月分享主题：爬虫HTTP详解网页结构简介一文带你了解爬虫 大家好，本期将为大家来采访一位爬虫工程师，与他相识是在一个技术号主群中，只有他怼了我的文章，所以也算不打不相识！他便是小周码字号主：Loco</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/pig66/p/11111763.html</dc:identifier>
</item>
<item>
<title>kubernetes实战篇之dashboard搭建 - 周国通</title>
<link>http://www.cnblogs.com/tylerzhou/p/11117956.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/tylerzhou/p/11117956.html</guid>
<description>&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&quot;https://www.cnblogs.com/tylerzhou/p/11100649.html&quot;&gt;系列目录&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;kubernetes dashboard是kubernetes官方提供的web管理界面,通过dashboard可以很方便地查看集群的各种资源.以及修改资源编排文件,对集群进行扩容操作,查看日志等.功能非常强大.虽然dashboard是官方提供的web管理界面,但是并没有默认安装,需要额外安装.下面将介绍如何安装kubernetes dashboard以及如何访问.&lt;/p&gt;
&lt;h2 id=&quot;dashboard安装&quot;&gt;dashboard安装&lt;/h2&gt;
&lt;p&gt;使用如下命令:&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;wget https://raw.githubusercontent.com/kubernetes/dashboard/master/aio/deploy/recommended/kubernetes-dashboard.yaml&lt;/code&gt;
&lt;/pre&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;在windows平台在浏览器直接输入网址即可下载&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;把dashboard的yaml编排文件下载下来到本地,然后进入下载目录,修改刚下载的&lt;code&gt;kubernetes-dashboard.yaml&lt;/code&gt;文件,找到&lt;code&gt;image&lt;/code&gt;栏,删除它的值(不要把键删了,即删除image:后面的值,保留键),然后替换为:&lt;code&gt;registry.cn-hangzhou.aliyuncs.com/google_containers/kubernetes-dashboard-amd64:v1.10.0&lt;/code&gt;&lt;/p&gt;
&lt;blockquote readability=&quot;13&quot;&gt;
&lt;p&gt;注意,有些网上的教程直接使用kubernetes的官方提供的安装命令,即&lt;code&gt;kubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/master/aio/deploy/recommended/kubernetes-dashboard.yaml&lt;/code&gt;这是不科学的,因为这个yml文件使用的镜像存放在&lt;code&gt;gcr.io&lt;/code&gt;上,很多用户是无法访问的,因此需要修改镜像源.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;修改完yml文件后,我们在&lt;code&gt;kubernetes-dashboard.yaml&lt;/code&gt;所在目录执行&lt;code&gt;kubectl apply -f kubernetes-dashboard.yaml&lt;/code&gt;即可完成安装.&lt;/p&gt;
&lt;h2 id=&quot;使用proxy方式访问-dashboard&quot;&gt;使用proxy方式访问 dashboard&lt;/h2&gt;
&lt;p&gt;这里先介绍一个坑,就是很多互联网上的教程照般官网上的示例教程,即使用&lt;code&gt;kubectl proxy&lt;/code&gt;然后在浏览器输入&lt;code&gt;http://localhost:8001/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy/.&lt;/code&gt;,这种方式只能用在windows或者mac上的docker.而linux服务器往往是没有图形界面的,没法直接通过浏览器访问,机智的你可能马上会想到,把localhost换成对应主机的ip,即可以在局域网访问了.然而实际情况并没有这么美好,大家可以试一下改成ip后也是访问不了的.&lt;/p&gt;
&lt;p&gt;正确的姿势是执行以下命令:&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;kubectl proxy --address='0.0.0.0'  --accept-hosts='^*$'&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;这时候就可以通过其它主机访问dashboard了.(以上地址中localhost改为ip地址)&lt;/p&gt;
&lt;p&gt;如果没有登陆,则会默认定向到登陆页面,可以使用config或者token方式登陆.我们这里使用token方式登陆.&lt;/p&gt;
&lt;p&gt;一般情况下,登陆的token默认都以secret对象的形式存在&lt;code&gt;kube-system&lt;/code&gt;名称空间下,我们执行&lt;code&gt;kubectl get secret -n=kube-system&lt;/code&gt;&lt;/p&gt;
&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;attachdetach-controller-token-zzdbv              kubernetes.io/service-account-token   3      37d
bootstrap-signer-token-kn7mv                     kubernetes.io/service-account-token   3      37d
certificate-controller-token-ck4bp               kubernetes.io/service-account-token   3      37d
clusterrole-aggregation-controller-token-gd8sq   kubernetes.io/service-account-token   3      37d
coredns-token-tm8nw                              kubernetes.io/service-account-token   3      37d
cronjob-controller-token-4p64q                   kubernetes.io/service-account-token   3      37d
daemon-set-controller-token-dhl8h                kubernetes.io/service-account-token   3      37d
dashboard-admin-token-sg6bp                      kubernetes.io/service-account-token   3      23h
default-token-tl6cs                              kubernetes.io/service-account-token   3      37d
deployment-controller-token-bs8zp                kubernetes.io/service-account-token   3      37d
disruption-controller-token-snpvq                kubernetes.io/service-account-token   3      37d
endpoint-controller-token-4kgz8                  kubernetes.io/service-account-token   3      37d
expand-controller-token-6j57x                    kubernetes.io/service-account-token   3      37d
flannel-token-f857v                              kubernetes.io/service-account-token   3      37d
generic-garbage-collector-token-2j6zz            kubernetes.io/service-account-token   3      37d
horizontal-pod-autoscaler-token-l7gt5            kubernetes.io/service-account-token   3      37d
job-controller-token-57rtv                       kubernetes.io/service-account-token   3      37d
kube-proxy-token-bf969                           kubernetes.io/service-account-token   3      37d
kubernetes-dashboard                             Opaque                                0      36d
kubernetes-dashboard-key-holder                  Opaque                                2      36d
kubernetes-dashboard-token-8z4v2                 kubernetes.io/service-account-token   3      36d
namespace-controller-token-zp4vx                 kubernetes.io/service-account-token   3      37d
node-controller-token-9kbmx                      kubernetes.io/service-account-token   3      37d
persistent-volume-binder-token-knjs7             kubernetes.io/service-account-token   3      37d
pod-garbage-collector-token-p7xhk                kubernetes.io/service-account-token   3      37d
pv-protection-controller-token-9rsjc             kubernetes.io/service-account-token   3      37d
pvc-protection-controller-token-5z68z            kubernetes.io/service-account-token   3      37d
replicaset-controller-token-gsfhs                kubernetes.io/service-account-token   3      37d
replication-controller-token-pvgrh               kubernetes.io/service-account-token   3      37d
resourcequota-controller-token-pmtsh             kubernetes.io/service-account-token   3      37d
service-account-controller-token-6zvnc           kubernetes.io/service-account-token   3      37d
service-controller-token-dnw2d                   kubernetes.io/service-account-token   3      37d
statefulset-controller-token-zn6tn               kubernetes.io/service-account-token   3      37d
tiller-token-7lpwt                               kubernetes.io/service-account-token   3      10d
token-cleaner-token-df7n5                        kubernetes.io/service-account-token   3      37d
ttl-controller-token-kfsh5                       kubernetes.io/service-account-token   3      37d
[centos@k8s-master dashboard]$&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;这些secrets中的大部分都可以用来访问dashboard的,只有不同的账户权限不同,很多账户被限制不能进行操作.比如我们使用名称为&lt;code&gt;default-token-tl6cs&lt;/code&gt;的secret包含的token进行登陆&lt;/p&gt;
&lt;blockquote readability=&quot;7&quot;&gt;
&lt;p&gt;注意,不同的机器上secret的名称是不一样的,读者以自己实际情况为主.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;我们使用以下命令来查看这个secret包含的token的值&lt;/p&gt;
&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;[centos@k8s-master dashboard]$ kubectl describe secret -n=kube-system default-token-tl6cs
Name:         default-token-tl6cs
Namespace:    kube-system
Labels:       &amp;lt;none&amp;gt;
Annotations:  field.cattle.io/projectId: c-tms4q:p-5bmgn
              kubernetes.io/service-account.name: default
              kubernetes.io/service-account.uid: f760bf27-44ab-11e9-a5c4-0050568417a2

Type:  kubernetes.io/service-account-token

Data
====
ca.crt:     1025 bytes
namespace:  11 bytes
token:      eyJhbGciOiJSUzI1NiIsImtpZCI6IiJ9.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlLXN5c3RlbSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJkZWZhdWx0LXRva2VuLXRsNmNzIiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQubmFtZSI6ImRlZmF1bHQiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC51aWQiOiJmNzYwYmYyNy00NGFiLTExZTktYTVjNC0wMDUwNTY4NDE3YTIiLCJzdWIiOiJzeXN0ZW06c2VydmljZWFjY291bnQ6a3ViZS1zeXN0ZW06ZGVmYXVsdCJ9.yVU85i5naX14TimIlQL0jgTv0oFsEFix7l55Wo09_Q9KbTavL2cjpdu26fHF7OtMCgGAsqxO0R_vOy_vVaPav6AvRWmCBPUEBr_oG_AcJCzdWvmCQkClAGaoZjGNx_qAbuJ3ZD9CG7C_QzjIIqMtjN7DVWjop2vQbByZL2yqkavMchuatr_LYkb_EsaGSKXFAZfDlqt7IO9IqGULl5Ri99fojCD230ji9QRO7x5g75Z6nBT1xf1g7txSAOppEn9S_J90CJ30tt0c9pEAhQ1qisLWpw0sZTBjjq4XcTjAszKe2u3G-ed5XLwEe_0xylbubRhT68XKWKUgBYx8IaqxIA
[centos@k8s-master dashboard]$&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;我们复制以上token值,然后粘贴到登陆页面的token里,就可以登陆了.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/811801/201907/811801-20190702080900887-1057545845.png&quot; alt=&quot;img&quot;/&gt;&lt;/p&gt;
&lt;p&gt;可以看到已经登陆进来了,但是这个用户没有任何权限,甚至连查看权限都没有.&lt;/p&gt;
&lt;p&gt;我们使用一个叫作&lt;code&gt;replicaset-controller-token-gsfhs&lt;/code&gt;的secret里包含的token来登陆,根据名字可以大概可以知道它是用来管理replicaset用的.实际上也确实是的,我们用它的token登陆来看一下web界面展示的内容&lt;/p&gt;
&lt;blockquote readability=&quot;7&quot;&gt;
&lt;p&gt;这里仅展示内容,操作方法与以上一样,这里就略过了&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/811801/201907/811801-20190702080846865-864401196.png&quot; alt=&quot;img&quot;/&gt;&lt;/p&gt;
&lt;p&gt;下面展示的还有replicaset的信息,这里我就没有截这么多.&lt;/p&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;由于replicaset包含的是pod的集合,因此这里展示出的有pod的信息&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;初次接触的朋友可能并不知道以上是不是展示的全部信息,因为并没有见过完整信息是什么样子的,这里先展示一下一个拥有完整权限的用户登陆后展示的信息是什么样子的.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/811801/201907/811801-20190702080840612-1694043027.png&quot; alt=&quot;img&quot;/&gt;&lt;/p&gt;
&lt;p&gt;从图形概览上可以看到,展示的信息比以上多.&lt;/p&gt;
&lt;p&gt;下面我们来讲解如何配置一个拥有完整权限的token.&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;创建一个dashboard管理用户&lt;/li&gt;
&lt;/ul&gt;&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;kubectl create serviceaccount dashboard-admin -n kube-system&lt;/code&gt;
&lt;/pre&gt;
&lt;ul&gt;&lt;li&gt;绑定用户为集群管理用户&lt;/li&gt;
&lt;/ul&gt;&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;kubectl create clusterrolebinding dashboard-cluster-admin --clusterrole=cluster-admin --serviceaccount=kube-system:dashboard-admin&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;执行完以上操作后,由于管理用户的名称为&lt;code&gt;dashboard-admin&lt;/code&gt;,生成的对应的secret的值则为&lt;code&gt;dashboard-admin-token-随机字符串&lt;/code&gt;我的机器上完整名称为&lt;code&gt;dashboard-admin-token-sg6bp&lt;/code&gt;&lt;/p&gt;
&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;[centos@k8s-master dashboard]$ kubectl get secret -n=kube-system |grep dashboard-admin-token
dashboard-admin-token-sg6bp                      kubernetes.io/service-account-token   3      23h
[centos@k8s-master dashboard]$&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;可以看到这个secret的完整名称,或者不使用grep管道,列出所有的secrets,然后从中寻找需要的.&lt;/p&gt;
&lt;p&gt;通过上面介绍过的&lt;code&gt;kubectl describe secret&lt;/code&gt;命令查看token&lt;/p&gt;
&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;[centos@k8s-master dashboard]$ kubectl describe -n=kube-system  secret dashboard-admin-token-sg6bp
Name:         dashboard-admin-token-sg6bp
Namespace:    kube-system
Labels:       &amp;lt;none&amp;gt;
Annotations:  kubernetes.io/service-account.name: dashboard-admin
              kubernetes.io/service-account.uid: c60d2a65-619e-11e9-a627-0050568417a2

Type:  kubernetes.io/service-account-token

Data
====
ca.crt:     1025 bytes
namespace:  11 bytes
token:      eyJhbGciOiJSUzI1NiIsImtpZCI6IiJ9.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlLXN5c3RlbSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJkYXNoYm9hcmQtYWRtaW4tdG9rZW4tc2c2YnAiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC5uYW1lIjoiZGFzaGJvYXJkLWFkbWluIiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQudWlkIjoiYzYwZDJhNjUtNjE5ZS0xMWU5LWE2MjctMDA1MDU2ODQxN2EyIiwic3ViIjoic3lzdGVtOnNlcnZpY2VhY2NvdW50Omt1YmUtc3lzdGVtOmRhc2hib2FyZC1hZG1pbiJ9.Ai8UqLHNbwVFf4QRq1p0JdVVy-KuguSTrsJRYmh-TEArH-Bkp0yBWNPpsP8fKL8MRMwlZEyJml-GZEoWvEbInvrgLHtMgA0A6Xbq89fvXqnLQBWsjEnrdIBSHmksLk4v_ldvVrnr6XXK8LGB34TVWxeYvSfv8aF35hXAV_r5-p18t7m9GFxU0_z1Gq1Af9GMA4wotERaWd1hHqNIcrDF8UpgUw2952nIu_VxGSV6eCagPxlpjbyAPrcEjSBK7O7QACtKXnG0bW8MqNaNYiLksYpvtJS7f0GlTeTpDZoj--5gJqAcNanCy7eQU8LuF-fiUaZIfXe0ZaWH0M1mjcAskA
[centos@k8s-master dashboard]$&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;我们把以上token复制到登陆页面的token栏里,就可以登陆了.登陆以后就可以看到如上面最后展示的有完整信息的界面.&lt;/p&gt;
&lt;h2 id=&quot;使用kubeconfig文件访问&quot;&gt;使用kubeconfig文件访问&lt;/h2&gt;
&lt;p&gt;这里只记录下命令,不做详细介绍,在dashboard 1.10.1里尝试了数次以及按照官网设置&lt;code&gt;--authentication-mode=config&lt;/code&gt;也不行,这里就不再做详细介绍了.&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;DASH_TOCKEN=$(kubectl get secret -n kube-system dashboard-admin-token-sg6bp -o jsonpath={.data.token}|base64 -d)

kubectl config set-cluster kubernetes --server=192.168.124.59:6443 --kubeconfig=/root/dashbord-admin.conf

kubectl config set-credentials dashboard-admin --token=$DASH_TOCKEN --kubeconfig=/root/dashbord-admin.conf

kubectl config set-context dashboard-admin@kubernetes --cluster=kubernetes --user=dashboard-admin --kubeconfig=/root/dashbord-admin.conf

kubectl config user-context dashboard-admin@kubernets --kubeconfig=/root/dashbord-admin.conf

生成的dashbord-admin.conf即可用于登录dashboard
&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;开启跳过登陆&quot;&gt;开启&lt;code&gt;跳过&lt;/code&gt;登陆&lt;/h2&gt;
&lt;p&gt;根据使用的版本不同,可能有的版本包含&lt;code&gt;skip&lt;/code&gt;按钮,有的则不包含,在1.10.1里面默认不再显然skip按钮,其实dashboard安装有很多坑,如果有读者按照以上设置仍然不能正常成功登陆,但是仍然想要体验dashboard,可以开启默认关闭的&lt;code&gt;skip&lt;/code&gt;按钮,这样就可以进入到dashboard管理界面了.&lt;/p&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;注意,生产环境强烈不建议这样做.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;执行命令&lt;/p&gt;
&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;kubectl edit deploy -n=kube-system kubernetes-dashboard&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;在containers下面的args栏里输入&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;- --enable-skip-login&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;内容如下&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/811801/201907/811801-20190702080834576-988346545.png&quot; alt=&quot;img&quot;/&gt;&lt;/p&gt;
&lt;p&gt;然后保存即可.刷新web页面,登陆界面就会多出一个skip按钮.&lt;/p&gt;
</description>
<pubDate>Tue, 02 Jul 2019 00:11:00 +0000</pubDate>
<dc:creator>周国通</dc:creator>
<og:description>'系列目录' kubernetes dashboard是kubernetes官方提供的web管理界面,通过dashboard可以很方便地查看集群的各种资源.以及修改资源编排文件,对集群进行扩容操作,查</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/tylerzhou/p/11117956.html</dc:identifier>
</item>
<item>
<title>Spring Boot2(四)：使用Spring Boot多数据源实现读写分离 - 南屿北岛</title>
<link>http://www.cnblogs.com/niaobulashi/p/mybatis-mutls.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/niaobulashi/p/mybatis-mutls.html</guid>
<description>&lt;h2 id=&quot;前言&quot;&gt;前言&lt;/h2&gt;
&lt;p&gt;实际业务场景中，不可能只有一个库，所以就有了分库分表，多数据源的出现。实现了读写分离，主库负责增改删，从库负责查询。这篇文章将实现Spring Boot如何实现多数据源，动态数据源切换，读写分离等操作。&lt;/p&gt;
&lt;h2 id=&quot;代码部署&quot;&gt;代码部署&lt;/h2&gt;
&lt;p&gt;快速新建项目spring-boot项目&lt;/p&gt;
&lt;h3 id=&quot;添加maven依赖&quot;&gt;1、添加maven依赖&lt;/h3&gt;
&lt;pre class=&quot;xml&quot;&gt;
&lt;code&gt;&amp;lt;dependency&amp;gt;
    &amp;lt;groupId&amp;gt;org.springframework.boot&amp;lt;/groupId&amp;gt;
    &amp;lt;artifactId&amp;gt;spring-boot-starter-web&amp;lt;/artifactId&amp;gt;
&amp;lt;/dependency&amp;gt;

&amp;lt;dependency&amp;gt;
    &amp;lt;groupId&amp;gt;org.mybatis.spring.boot&amp;lt;/groupId&amp;gt;
    &amp;lt;artifactId&amp;gt;mybatis-spring-boot-starter&amp;lt;/artifactId&amp;gt;
    &amp;lt;version&amp;gt;2.0.1&amp;lt;/version&amp;gt;
&amp;lt;/dependency&amp;gt;

&amp;lt;dependency&amp;gt;
    &amp;lt;groupId&amp;gt;org.springframework.boot&amp;lt;/groupId&amp;gt;
    &amp;lt;artifactId&amp;gt;spring-boot-starter-test&amp;lt;/artifactId&amp;gt;
    &amp;lt;scope&amp;gt;test&amp;lt;/scope&amp;gt;
&amp;lt;/dependency&amp;gt;

&amp;lt;dependency&amp;gt;
    &amp;lt;groupId&amp;gt;org.springframework.boot&amp;lt;/groupId&amp;gt;
    &amp;lt;artifactId&amp;gt;spring-boot-starter&amp;lt;/artifactId&amp;gt;
&amp;lt;/dependency&amp;gt;

&amp;lt;dependency&amp;gt;
    &amp;lt;groupId&amp;gt;mysql&amp;lt;/groupId&amp;gt;
    &amp;lt;artifactId&amp;gt;mysql-connector-java&amp;lt;/artifactId&amp;gt;
    &amp;lt;scope&amp;gt;runtime&amp;lt;/scope&amp;gt;
&amp;lt;/dependency&amp;gt;

&amp;lt;dependency&amp;gt;
    &amp;lt;groupId&amp;gt;org.projectlombok&amp;lt;/groupId&amp;gt;
    &amp;lt;artifactId&amp;gt;lombok&amp;lt;/artifactId&amp;gt;
    &amp;lt;optional&amp;gt;true&amp;lt;/optional&amp;gt;
&amp;lt;/dependency&amp;gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;application配置多数据源读取配置&quot;&gt;2、application配置多数据源读取配置&lt;/h3&gt;
&lt;p&gt;和之前教程一样，首先配置application.yml&lt;/p&gt;
&lt;pre class=&quot;yml&quot;&gt;
&lt;code&gt;#指定配置文件为test
spring:
  profiles:
    active: test

#配置Mybatis
mybatis:
  configuration:
    # 开启驼峰命名转换，如：Table(create_time) -&amp;gt; Entity(createTime)。不需要我们关心怎么进行字段匹配，mybatis会自动识别`大写字母与下划线`
    map-underscore-to-camel-case: true

#打印SQL日志
logging:
  level:
    com.niaobulashi.mapper.*: DEBUG&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;其中打印SQL日志这块，因为是多数据源，在mapper包下面区分不同的数据库来源xml文件，所以用*表示。&lt;/p&gt;
&lt;p&gt;配置application-test.yml如下&lt;/p&gt;
&lt;pre class=&quot;xml&quot;&gt;
&lt;code&gt;spring:
  datasource:
    #主库
    master:
      jdbc-url: jdbc:mysql://127.0.0.1:3306/test?serverTimezone=UTC&amp;amp;useUnicode=true&amp;amp;characterEncoding=utf-8&amp;amp;useSSL=true
      username: root
      password: root
      driver-class-name: com.mysql.cj.jdbc.Driver
    #从库
    slave:
      jdbc-url: jdbc:mysql://127.0.0.1:3306/test2?serverTimezone=UTC&amp;amp;useUnicode=true&amp;amp;characterEncoding=utf-8&amp;amp;useSSL=true
      username: root
      password: root
      driver-class-name: com.mysql.cj.jdbc.Driver&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;从spring.datasource节点开始，区分主库master，从库slave。主库连接的数据库为test，从库连接的数据库为test2。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;注意&lt;/strong&gt;：这里需要注意的是，从Spring Boot2开始，在配置多数据源时有些配置发生了变化，网上许多教程使用的是&lt;code&gt;spring.datasource.url&lt;/code&gt;。会出现&lt;code&gt;jdbcUrl is required with driverClassName.&lt;/code&gt;的问题。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;解决方法&lt;/strong&gt;：配置多数据源时，将&lt;code&gt;spring.datasource.url&lt;/code&gt;配置改为&lt;code&gt;spring.datasource.jdbc-url&lt;/code&gt;&lt;/p&gt;
&lt;h3 id=&quot;添加主库配置信息&quot;&gt;3、添加主库配置信息&lt;/h3&gt;
&lt;p&gt;依据知名博主：纯洁的微笑，写的博文我们来分析一波&lt;/p&gt;
&lt;p&gt;首先看主库配置的代码：&lt;/p&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;@Configuration
@MapperScan(basePackages = &quot;com.niaobulashi.mapper.master&quot;, sqlSessionTemplateRef = &quot;masterSqlSessionTemplate&quot;)
public class DataSourceMasterConfig {

    /**
     * 是application-test.yml中的spring.datasource.master配置生效
     * @return
     */
    @Bean(name = &quot;masterDataSource&quot;)
    @ConfigurationProperties(prefix = &quot;spring.datasource.master&quot;)
    @Primary
    public DataSource masterDataSource() {
        return DataSourceBuilder.create().build();
    }

    /**
     * 将配置信息注入到SqlSessionFactoryBean中
     * @param dataSource    数据库连接信息
     * @return
     * @throws Exception
     */
    @Bean(name = &quot;masterSqlSessionFactory&quot;)
    @Primary
    public SqlSessionFactory masterSqlSessionFactory(@Qualifier(&quot;masterDataSource&quot;) DataSource dataSource) throws Exception {
        SqlSessionFactoryBean bean = new SqlSessionFactoryBean();
        bean.setDataSource(dataSource);
        bean.setMapperLocations(new PathMatchingResourcePatternResolver().getResources(&quot;classpath:mapper/master/*.xml&quot;));
        return bean.getObject();
    }

    /**
     * 事务管理器，在实例化时注入主库master
     * @param dataSource
     * @return
     */
    @Bean(name = &quot;masterTransactionManager&quot;)
    @Primary
    public DataSourceTransactionManager masterTransactionManager(@Qualifier(&quot;masterDataSource&quot;) DataSource dataSource) {
        return new DataSourceTransactionManager(dataSource);
    }

    /**
     * SqlSessionTemplate具有线程安全性
     * @param sqlSessionFactory
     * @return
     * @throws Exception
     */
    @Bean(name = &quot;masterSqlSessionTemplate&quot;)
    @Primary
    public SqlSessionTemplate masterSqlSessionTemplate(@Qualifier(&quot;masterSqlSessionFactory&quot;) SqlSessionFactory sqlSessionFactory) throws Exception {
        return new SqlSessionTemplate(sqlSessionFactory);
    }
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;问题&lt;/strong&gt;：看这块&lt;code&gt;masterSqlSessionFactory&lt;/code&gt;，&lt;code&gt;SqlSessionFactoryBean&lt;/code&gt;只获取了&lt;code&gt;spring.datasource.master&lt;/code&gt;数据库连接信息，并没有获取多数据库的配置信息&lt;code&gt;mybatis.configuration&lt;/code&gt;导致我们需要配置驼峰命名规则，配置信息并没有注入到&lt;code&gt;SqlSessionFactoryBean&lt;/code&gt;。这样就导致在查询是，遇到下划线无法解析相应字段user_id，dept_id，create_time&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://niaobulashi.github.io/assets/images/2019/springboot/mybatis-mutli-04-01.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://niaobulashi.github.io/assets/images/2019/springboot/mybatis-mutli-04-02.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;解决方法&lt;/strong&gt;：在配置中添加Configuration&lt;/p&gt;
&lt;p&gt;同时，将配置信息注入到SqlSessionFactoryBean&lt;/p&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;/**
 * 将配置信息注入到SqlSessionFactoryBean中
 * @param dataSource    数据库连接信息
 * @return
 * @throws Exception
 */
@Bean(name = &quot;slaveSqlSessionFactory&quot;)
public SqlSessionFactory slaveSqlSessionFactory(@Qualifier(&quot;slaveDataSource&quot;) DataSource dataSource) throws Exception {
    SqlSessionFactoryBean bean = new SqlSessionFactoryBean();
    // 使配置信息加载到类中，再注入到SqlSessionFactoryBean
    org.apache.ibatis.session.Configuration configuration = new org.apache.ibatis.session.Configuration();
    configuration.setMapUnderscoreToCamelCase(true);
    bean.setConfiguration(configuration);
    bean.setDataSource(dataSource);
    bean.setMapperLocations(new PathMatchingResourcePatternResolver().getResources(&quot;classpath:mapper/slave/*.xml&quot;));
    return bean.getObject();
}&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;添加从库配置信息&quot;&gt;4、添加从库配置信息&lt;/h3&gt;
&lt;p&gt;和添加主库配置信息一样，只不过不同的是，不需要添加&lt;code&gt;@Primary&lt;/code&gt;首选注解&lt;/p&gt;
&lt;p&gt;代码如下&lt;/p&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;@Configuration
@MapperScan(basePackages = &quot;com.niaobulashi.mapper.slave&quot;, sqlSessionTemplateRef = &quot;slaveSqlSessionTemplate&quot;)
public class DataSourceSlaveConfig {

    /**
     * 是application-test.yml中的spring.datasource.master配置生效
     * @return
     */
    @Bean(name = &quot;slaveDataSource&quot;)
    @ConfigurationProperties(prefix = &quot;spring.datasource.slave&quot;)
    public DataSource slaveDataSource() {
        return DataSourceBuilder.create().build();
    }

    /**
     * 将配置信息注入到SqlSessionFactoryBean中
     * @param dataSource    数据库连接信息
     * @return
     * @throws Exception
     */
    @Bean(name = &quot;slaveSqlSessionFactory&quot;)
    public SqlSessionFactory slaveSqlSessionFactory(@Qualifier(&quot;slaveDataSource&quot;) DataSource dataSource) throws Exception {
        SqlSessionFactoryBean bean = new SqlSessionFactoryBean();
        // 使配置信息加载到类中，再注入到SqlSessionFactoryBean
        org.apache.ibatis.session.Configuration configuration = new org.apache.ibatis.session.Configuration();
        configuration.setMapUnderscoreToCamelCase(true);
        bean.setConfiguration(configuration);
        bean.setDataSource(dataSource);
        bean.setMapperLocations(new PathMatchingResourcePatternResolver().getResources(&quot;classpath:mapper/slave/*.xml&quot;));
        return bean.getObject();
    }

    /**
     * 事务管理器，在实例化时注入主库master
     * @param dataSource
     * @return
     */
    @Bean(name = &quot;slaveTransactionManager&quot;)
    public DataSourceTransactionManager slaveTransactionManager(@Qualifier(&quot;slaveDataSource&quot;) DataSource dataSource) {
        return new DataSourceTransactionManager(dataSource);
    }

    /**
     * SqlSessionTemplate具有线程安全性
     * @param sqlSessionFactory
     * @return
     * @throws Exception
     */
    @Bean(name = &quot;slaveSqlSessionTemplate&quot;)
    public SqlSessionTemplate slaveSqlSessionTemplate(@Qualifier(&quot;slaveSqlSessionFactory&quot;) SqlSessionFactory sqlSessionFactory) throws Exception {
        return new SqlSessionTemplate(sqlSessionFactory);
    }
}&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;扩展配置方法会报错&quot;&gt;5、扩展配置方法会报错&lt;/h3&gt;
&lt;p&gt;在网上还看到这样一种配置，单独通过@ConfigurationProperties注解配置Mybatis的配置信息如下&lt;/p&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;/**
 * 试application.yml中的mybatis.configuration配置生效，如果不主动配置，由于@Order配置顺序不同，讲导致配置不能及时生效
 * 使配置信息加载到类中，再注入到SqlSessionFactoryBean
 * @return
 */
@Bean
@ConfigurationProperties(prefix = &quot;mybatis.configuration&quot;)
public org.apache.ibatis.session.Configuration configuration() {
    return new org.apache.ibatis.session.Configuration();
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;其中&lt;code&gt;prefix&lt;/code&gt;，在主库和从库中的id是一样的，必须保持不同，否则idea就会提示报错&lt;code&gt;Duplicate prefix&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;导致只有主库可以执行Mybatis的配置，从库无效。&lt;/p&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;@Bean(name = &quot;masterSqlSessionFactory&quot;)
    @Primary
    public SqlSessionFactory masterSqlSessionFactory(@Qualifier(&quot;masterDataSource&quot;) DataSource dataSource, org.apache.ibatis.session.Configuration configuration) throws Exception {
        SqlSessionFactoryBean bean = new SqlSessionFactoryBean();
        // 使配置信息加载到类中，再注入到SqlSessionFactoryBean
        bean.setConfiguration(configuration);
        bean.setDataSource(dataSource);
        bean.setMapperLocations(new PathMatchingResourcePatternResolver().getResources(&quot;classpath:mapper/master/*.xml&quot;));
        return bean.getObject();
    }&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;这块验证只有主库有效，从库的驼峰方法解析无效。后续再来研究下。。。&lt;/p&gt;
&lt;h3 id=&quot;数据层代码&quot;&gt;6、数据层代码&lt;/h3&gt;
&lt;p&gt;代码结构如下&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://niaobulashi.github.io/assets/images/2019/springboot/mybatis-mutli-04-03.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;其中SysUserMasterDao代码&lt;/p&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;public interface SysUserMasterDao {
    
    /**
     * 根据userId查询用户信息
     * @param userId  用户ID
     */
    List&amp;lt;SysUserEntity&amp;gt; queryUserInfo(Long userId);

    /**
     * 查询所有用户信息
     */
    List&amp;lt;SysUserEntity&amp;gt; queryUserAll();

    /**
     * 根据userId更新用户的邮箱和手机号
     * @return
     */
    int updateUserInfo(SysUserEntity user);

}&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;resource下数据执行语句&quot;&gt;7、resource下数据执行语句&lt;/h3&gt;
&lt;p&gt;SysCodeMasterDao.xml&lt;/p&gt;
&lt;pre class=&quot;xml&quot;&gt;
&lt;code&gt;&amp;lt;mapper namespace=&quot;com.niaobulashi.mapper.master.SysUserMasterDao&quot;&amp;gt;

    &amp;lt;!--查询所有用户信息--&amp;gt;
    &amp;lt;select id=&quot;queryUserAll&quot; resultType=&quot;com.niaobulashi.entity.SysUserEntity&quot;&amp;gt;
        SELECT
            ur.*
        FROM
            sys_user ur
        WHERE
            1 = 1
    &amp;lt;/select&amp;gt;

    &amp;lt;!--根据用户userId查询用户信息--&amp;gt;
    &amp;lt;select id=&quot;queryUserInfo&quot; resultType=&quot;com.niaobulashi.entity.SysUserEntity&quot;&amp;gt;
        SELECT
            ur.*
        FROM
            sys_user ur
        WHERE
            1 = 1
          AND ur.user_id = #{userId}
    &amp;lt;/select&amp;gt;

    &amp;lt;!-- 根据UserId，更新邮箱和手机号 --&amp;gt;
    &amp;lt;update id=&quot;updateUserInfo&quot; parameterType=&quot;com.niaobulashi.entity.SysUserEntity&quot;&amp;gt;
        UPDATE sys_user u
        &amp;lt;set&amp;gt;
            &amp;lt;if test=&quot;email != null&quot;&amp;gt;
                u.email = #{email},
            &amp;lt;/if&amp;gt;
            &amp;lt;if test=&quot;mobile != null&quot;&amp;gt;
                u.mobile = #{mobile},
            &amp;lt;/if&amp;gt;
        &amp;lt;/set&amp;gt;
        WHERE
        u.user_id = #{userId}
    &amp;lt;/update&amp;gt;

&amp;lt;/mapper&amp;gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;8、Controller层测试&lt;/p&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;@RestController
public class SysUserController {

    @Autowired
    private SysUserMasterDao sysUserMasterDao;

    @Autowired
    private SysUserSlaveDao sysUserSlaveDao;

    /**
     * 查询所有用户信息Master
     * @return
     */
    @RequestMapping(&quot;/getUserMasterAll&quot;)
    private List&amp;lt;SysUserEntity&amp;gt; getUserMaster() {
        System.out.println(&quot;查询主库&quot;);
        List&amp;lt;SysUserEntity&amp;gt; userList = sysUserMasterDao.queryUserAll();
        return userList;
    }

    /**
     * 查询所有用户信息Slave
     * @return
     */
    @RequestMapping(&quot;/getUserSlaveAll&quot;)
    private List&amp;lt;SysUserEntity&amp;gt; getUserSlave() {
        System.out.println(&quot;查询从库&quot;);
        List&amp;lt;SysUserEntity&amp;gt; userList = sysUserSlaveDao.queryUserAll();
        return userList;
    }

    /**
     * 根据userId查询用户信息Master
     * @return
     */
    @RequestMapping(&quot;/getUserMasterById&quot;)
    private List&amp;lt;SysUserEntity&amp;gt; getUserMasterById(@RequestParam(value = &quot;userId&quot;, required = false) Long userId) {
        List&amp;lt;SysUserEntity&amp;gt; userList = sysUserMasterDao.queryUserInfo(userId);
        return userList;
    }

    /**
     * 根据userId查询用户信息Slave
     * @return
     */
    @RequestMapping(&quot;/getUserSlaveById&quot;)
    private List&amp;lt;SysUserEntity&amp;gt; getUserSlaveById(@RequestParam(value = &quot;userId&quot;, required = false) Long userId) {
        List&amp;lt;SysUserEntity&amp;gt; userList = sysUserSlaveDao.queryUserInfo(userId);
        return userList;
    }

}&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;发送查询所有用户接口&quot;&gt;发送查询所有用户接口&lt;/h3&gt;
&lt;p&gt;主库：http://localhost:8080/getUserMasterAll&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://niaobulashi.github.io/assets/images/2019/springboot/mybatis-mutli-04-04.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;从库：http://localhost:8080/getUserSlaveAll&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://niaobulashi.github.io/assets/images/2019/springboot/mybatis-mutli-04-05.png&quot;/&gt;&lt;/p&gt;
&lt;h2 id=&quot;总结&quot;&gt;总结&lt;/h2&gt;
&lt;p&gt;1、通过多数据源方式实现数据库层面的读写分离&lt;/p&gt;
&lt;p&gt;2、多数据源链接数据库是，使用spring.datasource.jdbc-url&lt;/p&gt;
&lt;p&gt;3、多数据源的mybatis.configuration配置注意需要手动注入SqlSessionFactory&lt;/p&gt;

</description>
<pubDate>Mon, 01 Jul 2019 17:19:00 +0000</pubDate>
<dc:creator>南屿北岛</dc:creator>
<og:description>前言 实际业务场景中，不可能只有一个库，所以就有了分库分表，多数据源的出现。实现了读写分离，主库负责增改删，从库负责查询。这篇文章将实现Spring Boot如何实现多数据源，动态数据源切换，读写分离</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/niaobulashi/p/mybatis-mutls.html</dc:identifier>
</item>
<item>
<title>Netty源码分析--Channel注册（上）（五） - Diligent_Watermelon</title>
<link>http://www.cnblogs.com/huxipeng/p/10994455.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/huxipeng/p/10994455.html</guid>
<description>&lt;p&gt;        其实在将这一节之前，我们来分析一个东西，方便下面的工作好开展。&lt;/p&gt;
&lt;p&gt;        打开启动类，最开始的时候创建了一个NioEventLoopGroup 事件循环组，我们来跟一下这个。&lt;/p&gt;
&lt;p&gt;        &lt;img src=&quot;https://img2018.cnblogs.com/blog/1143158/201906/1143158-20190610124612931-1602486503.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;      这里bossGroup， 我传入了一个线程， workerGroup 没有入参，默认0， 也就是说父级我用一个线程来处理客户端的接入， 多个线程来处理客户端的读写操作&lt;/p&gt;
&lt;p&gt;      通过一连串的构造方法进入到&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1143158/201906/1143158-20190610125222094-896970618.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;     executor 是 null ， selectorProvider 用来创建一个多路复用器， 最后一个参数传入了 一个多路复用器的一个策略， 这个策略我们后面会讲到&lt;/p&gt;
&lt;p&gt;    &lt;img src=&quot;https://img2018.cnblogs.com/blog/1143158/201906/1143158-20190610125538125-379483749.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;     紧接着又传入了一个拒绝策略， 由于  NioEventLoopGroup 继承了 MultithreadEventLoopGroup，所以进入 MultithreadEventLoopGroup 的构造方法&lt;/p&gt;
&lt;p&gt;     &lt;img src=&quot;https://img2018.cnblogs.com/blog/1143158/201906/1143158-20190610125657193-1873062234.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;    这里的判断， bossGroup 传入了 1 ，所以nThreads = 1；  workerGroup 没有入参，默认是0 ，所以这里到了一个判断默认线程数的地方。&lt;/p&gt;
&lt;p&gt;   &lt;img src=&quot;https://img2018.cnblogs.com/blog/1143158/201906/1143158-20190610125917781-2105979426.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;     就是这了， NettyRuntime.availableProcessors() * 2  代表 CPU核心数 * 2(处理器超线程数) * 2的值  或  CPU数 * 2的值  &lt;/p&gt;
&lt;p&gt;     在cmd命令中输入“wmic”，然后在出现的新窗口中输入“cpu get *”。&lt;br/&gt;     NumberOfCores：表示CPU核心数&lt;br/&gt;     NumberOfLogicalProcessors：表示CPU线程数&lt;/p&gt;
&lt;p&gt;     &lt;img src=&quot;https://img2018.cnblogs.com/blog/1143158/201906/1143158-20190610131000668-1147823095.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;     所以我这里是 CPU核心数 是 2 ， CPU 线程数 是 4 ， 所以我的 NettyRuntime.availableProcessors() * 2 = 8， 然后这里Math.max(1,8) 取大的 就是 8 了&lt;/p&gt;
&lt;p&gt;     所以我的 workerGroup 线程数 是 8&lt;/p&gt;
&lt;p&gt;     好了，我们继续跟进去&lt;/p&gt;
&lt;p&gt;    &lt;img src=&quot;https://img2018.cnblogs.com/blog/1143158/201906/1143158-20190615204557486-1526987263.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;     这里创建了一个线程工厂，主要是为线程设置名字、是否守护进程、线程的优先级等等。然后创建一个任务执行器，把线程工厂传进去赋给成员变量&lt;/p&gt;
&lt;p&gt;     这个executor 后面在每个 事件执行器 创建子线程处理task来用&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1143158/201906/1143158-20190616011249023-1764963215.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1143158/201906/1143158-20190616011331745-30491547.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;    接下来创建一个长度是nThreads的 EventExecutor[]  ，对于 子事件循环组来说，这里其实是创建了一个长度为8 的NioEventLoop的数组， 即 EventExecutor[]  children = new NioEventLoop[8]&lt;/p&gt;
&lt;p&gt;    这个地方我纠结了一下，因为我语文太差了，我决定画个图来展示一下， 虽然我美术也不好。&lt;/p&gt;
&lt;p&gt;    &lt;img src=&quot;https://img2018.cnblogs.com/blog/1143158/201906/1143158-20190616013532899-1553788490.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;    大家看下这个代码层级结构， 其实就很显而易见了，这里我要说一下，SingleThreadEventExecutor 中有一个thread成员变量，说明每个都只有一个线程来处理，并且含有任务队列和任务的执行器。&lt;/p&gt;
&lt;p&gt;   另外每一个NioEventLoop都含有一个selector 多路复用器 。&lt;/p&gt;
&lt;p&gt;   继续看，这里通过默认的选择工厂来创建一个选择器。&lt;/p&gt;
&lt;p&gt;   &lt;img src=&quot;https://img2018.cnblogs.com/blog/1143158/201906/1143158-20190617230426044-814201931.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;   跟进去，我们看到下面的这段代码，不得不感叹Netty真的已经把性能发挥到了极致，能用位运算的绝不会用数学计算法，所以这里对选择器进行了区分&lt;/p&gt;
&lt;p&gt;  &lt;img src=&quot;https://img2018.cnblogs.com/blog/1143158/201906/1143158-20190617230513561-216209136.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;   &lt;img src=&quot;https://img2018.cnblogs.com/blog/1143158/201906/1143158-20190617231330949-718250494.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;    看这个判断方法，意思是 如果是 2的次方 ，那么创建一个 PowerOfTwoEventExecutorChooser 选择器&lt;/p&gt;
&lt;p&gt;    我特意去验证了一个这个算法&lt;/p&gt;
&lt;p&gt;    &lt;img src=&quot;https://img2018.cnblogs.com/blog/1143158/201906/1143158-20190617231518332-1212612157.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;   结果是：&lt;/p&gt;
&lt;p&gt;    &lt;img src=&quot;https://img2018.cnblogs.com/blog/1143158/201906/1143158-20190617231528465-1988897188.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;   好了，讲到这里我们可以重新开始讲注册了，仍然进入  initAndRegister()方法&lt;/p&gt;
&lt;p&gt;   &lt;img src=&quot;https://img2018.cnblogs.com/blog/1143158/201906/1143158-20190616014619195-685562822.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;    config().group() 这个获取到的 是 ServerBootStrap.group(), 那么也就是取到了 父级的事件循环组 也就是bossGroup&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1143158/201906/1143158-20190617225425566-176109987.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt; 根据我上上图的分析，那么注册方法进入的肯定是 MultithreadEventLoopGroup &lt;/p&gt;
&lt;p&gt;   &lt;img src=&quot;https://img2018.cnblogs.com/blog/1143158/201906/1143158-20190617225517385-2029091437.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;  这里有一个next()方法，用来选择一个NioEventLoop。由于我这里是1个线程的数组，所以进入&lt;/p&gt;
&lt;p&gt;  &lt;img src=&quot;https://img2018.cnblogs.com/blog/1143158/201906/1143158-20190617231748958-1513431337.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;  因此，对于bossGroup来说，就是 0 &amp;amp; 0 = 0   1 &amp;amp; 0 = 0  2 &amp;amp; 0 = 0 .....&lt;/p&gt;
&lt;p&gt;            对于workerGroup来说，就是 0 &amp;amp; 7 = 0 1 &amp;amp; 7 = 1  2 &amp;amp; 7 = 2 .... 8 &amp;amp; 7 = 0  9 &amp;amp; 7 = 1 ....&lt;/p&gt;
&lt;p&gt; 所以这里其实是一个轮询的算法。&lt;/p&gt;
&lt;p&gt; ok， 看到这里我们猜测是 从   new NioEventLoop[1]  中轮询一个 NioEventLoop， 然后把channel注册到上面的多路复用器上。&lt;/p&gt;
&lt;p&gt; 继续看， 根据那个流程图，可以推断出是进入到  SingleThreadEventLoop&lt;/p&gt;
&lt;p&gt; &lt;img src=&quot;https://img2018.cnblogs.com/blog/1143158/201906/1143158-20190617233058829-1738572091.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;    接着传入了一个 DefaultChannelPromise ，用来做注册结果的异步通知的。传入了channel 和 当前的这个 SingleThreadEventLoop ，当然具体怎么异步通知的，我们后面会讲到&lt;/p&gt;
&lt;p&gt;  &lt;img src=&quot;https://img2018.cnblogs.com/blog/1143158/201906/1143158-20190617234411295-830096622.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;   继续看&lt;/p&gt;
&lt;p&gt;  &lt;img src=&quot;https://img2018.cnblogs.com/blog/1143158/201906/1143158-20190617235156268-665945583.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;  这里把刚刚选择出来的 NioEventLoop 赋给 Channel 的 eventLoop 的成员变量， 这里也就意味着 ，这个NioEventLoop 也将一直伴随 这个channel 的所有的读写操作， 因为通过上面的那个流程图表明了 一个NioEventLoop 上面只有一个Thread ， 那么也可以得出 一个Channel 整个周期 内所有的读写操作，全部由同一个Thread来完成， 这也就说明了为什么Netty没有线程安全问题&lt;/span&gt;，当然随着后面的讲解，你将会对这个地方理解的更加的深刻。 &lt;/p&gt;
&lt;p&gt;       好了，注册的内容我们下一节接着说。&lt;/p&gt;
</description>
<pubDate>Mon, 01 Jul 2019 16:03:00 +0000</pubDate>
<dc:creator>Diligent_Watermelon</dc:creator>
<og:description>其实在将这一节之前，我们来分析一个东西，方便下面的工作好开展。 打开启动类，最开始的时候创建了一个NioEventLoopGroup 事件循环组，我们来跟一下这个。 这里bossGroup， 我传入了</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/huxipeng/p/10994455.html</dc:identifier>
</item>
<item>
<title>RocketMQ(5)---RocketMQ重试机制 - 雨点的名字</title>
<link>http://www.cnblogs.com/qdhxhz/p/11117379.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/qdhxhz/p/11117379.html</guid>
<description>&lt;center&gt;

&lt;/center&gt;
&lt;p&gt;消息重试分为两种：&lt;strong&gt;Producer发送消息的重试&lt;/strong&gt; 和 &lt;strong&gt;Consumer消息消费的重试&lt;/strong&gt;。&lt;/p&gt;
&lt;h2 id=&quot;一producer端重试&quot;&gt;&lt;span&gt;一、Producer端重试&lt;/span&gt;&lt;/h2&gt;
&lt;p&gt;Producer端重试是指: Producer往MQ上发消息没有发送成功，比如网络原因导致生产者发送消息到MQ失败。&lt;/p&gt;
&lt;p&gt;看一下代码：&lt;/p&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;@Slf4j
public class RocketMQTest {
    /**
     * 生产者组
     */
    private static String PRODUCE_RGROUP = &quot;test_producer&quot;;
  
    public static void main(String[] args) throws Exception {
        //1、创建生产者对象
        DefaultMQProducer producer = new DefaultMQProducer(PRODUCE_RGROUP);
        //设置重试次数(默认2次）
        producer.setRetryTimesWhenSendFailed(3000);
        //绑定name server
        producer.setNamesrvAddr(&quot;74.49.203.55:9876&quot;);
        producer.start();
        //创建消息
        Message message = new Message(&quot;topic_family&quot;, (&quot;小小今年3岁&quot; ).getBytes());
        //发送 这里填写超时时间是5毫秒 所以每次都会发送失败
        SendResult sendResult = producer.send(message,5);
        log.info(&quot;输出生产者信息={}&quot;,sendResult);
    }
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;超时重试&lt;/code&gt; 针对网上说的超时异常会重试的说法都是错误的，想想都觉得可怕，我查的所以文章都说超时异常都会重试，难道这么多人都没有去测试一下 或者去看个源码。&lt;/p&gt;
&lt;p&gt;我发现这个问题，是因为我上面超时时间设置为5毫秒 ，按照正常肯定会报超时异常，但我设置1次重试和3000次的重试，虽然最终都会报下面异常，但输出错误时间报&lt;/p&gt;
&lt;p&gt;显然不应该是一个级别。但测试发现无论我设置的多少次的重试次数，报异常的时间都差不多。&lt;/p&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;org.apache.rocketmq.remoting.exception.RemotingTooMuchRequestException: sendDefaultImpl call timeout&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;针对这个疑惑，我去看了源码之后，才恍然大悟。&lt;/p&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;   /**
     * 说明 抽取部分代码
     */
    private SendResult sendDefaultImpl(Message msg, final CommunicationMode communicationMode, final SendCallback sendCallback, final long timeout) {
        
        //1、获取当前时间
        long beginTimestampFirst = System.currentTimeMillis();
        long beginTimestampPrev ;
        //2、去服务器看下有没有主题消息
        TopicPublishInfo topicPublishInfo = this.tryToFindTopicPublishInfo(msg.getTopic());
        if (topicPublishInfo != null &amp;amp;&amp;amp; topicPublishInfo.ok()) {
            boolean callTimeout = false;
            //3、通过这里可以很明显看出 如果不是同步发送消息 那么消息重试只有1次
            int timesTotal = communicationMode == CommunicationMode.SYNC ? 1 + this.defaultMQProducer.getRetryTimesWhenSendFailed() : 1;
            //4、根据设置的重试次数，循环再去获取服务器主题消息
            for (times = 0; times &amp;lt; timesTotal; times++) {
                MessageQueue mqSelected = this.selectOneMessageQueue(topicPublishInfo, lastBrokerName);
                beginTimestampPrev = System.currentTimeMillis();
                long costTime = beginTimestampPrev - beginTimestampFirst;
                //5、前后时间对比 如果前后时间差 大于 设置的等待时间 那么直接跳出for循环了 这就说明连接超时是不进行多次连接重试的
                if (timeout &amp;lt; costTime) {
                    callTimeout = true;
                    break;

                }
                //6、如果超时直接报错
                if (callTimeout) {
                    throw new RemotingTooMuchRequestException(&quot;sendDefaultImpl call timeout&quot;);
                }
        }
    }&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;通过这段源码很明显可以看出以下几点&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;如果是&lt;code&gt;异步发送&lt;/code&gt; 那么重试次数只有1次&lt;/li&gt;
&lt;li&gt;对于同步而言，&lt;code&gt;超时异常也是不会再去重试&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;如果发生重试是在一个for 循环里去重试，所以它是立即重试而不是隔一段时间去重试。&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;真是实践出真知！！！&lt;/p&gt;

&lt;h2 id=&quot;二-consumer端重试&quot;&gt;&lt;span&gt;二、 Consumer端重试&lt;/span&gt;&lt;/h2&gt;
&lt;p&gt;消费端比较有意思，而且在实际开发过程中，我们也更应该考虑的是消费端的重试。&lt;/p&gt;
&lt;p&gt;消费者端的失败主要分为2种情况，&lt;code&gt;Exception&lt;/code&gt; 和 &lt;code&gt;Timeout&lt;/code&gt;。&lt;/p&gt;
&lt;h4 id=&quot;exception&quot;&gt;1、Exception&lt;/h4&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;@Slf4j
@Component
public class Consumer {
    /**
     * 消费者实体对象
     */
    private DefaultMQPushConsumer consumer;
    /**
     * 消费者组
     */
    public static final String CONSUMER_GROUP = &quot;test_consumer&quot;;
    /**
     * 通过构造函数 实例化对象
     */
    public Consumer() throws MQClientException {
        consumer = new DefaultMQPushConsumer(CONSUMER_GROUP);
        consumer.setNamesrvAddr(&quot;47.99.203.55:9876;47.99.203.55:9877&quot;);
        //订阅topic和 tags（ * 代表所有标签)下信息
        consumer.subscribe(&quot;topic_family&quot;, &quot;*&quot;);
        //注册消费的监听 并在此监听中消费信息，并返回消费的状态信息
        consumer.registerMessageListener((MessageListenerConcurrently) (msgs, context) -&amp;gt; {
            //1、获取消息
            Message msg = msgs.get(0);
            try {
                //2、消费者获取消息
                String body = new String(msg.getBody(), &quot;utf-8&quot;);
                //3、获取重试次数
                int count = ((MessageExt) msg).getReconsumeTimes();
                log.info(&quot;当前消费重试次数为 = {}&quot;, count);
                //4、这里设置重试大于3次 那么通过保存数据库 人工来兜底
                if (count &amp;gt;= 2) {
                    log.info(&quot;该消息已经重试3次,保存数据库。topic={},keys={},msg={}&quot;, msg.getTopic(), msg.getKeys(), body);
                    return ConsumeConcurrentlyStatus.CONSUME_SUCCESS;
                }
                //直接抛出异常
                throw new Exception(&quot;=======这里出错了============&quot;);
                //return ConsumeConcurrentlyStatus.CONSUME_SUCCESS;
            } catch (Exception e) {
                e.printStackTrace();
                return ConsumeConcurrentlyStatus.RECONSUME_LATER;
            }
        });
        //启动监听
        consumer.start();
    }
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;这里的代码意思很明显: 主动抛出一个异常，然后如果超过3次，那么就不继续重试下去，而是将该条记录保存到数据库由人工来兜底。&lt;/p&gt;
&lt;p&gt;看下运行结果&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1090617/201907/1090617-20190701225750881-908786877.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;注意&lt;/code&gt; 消费者和生产者的重试还是有区别的，主要有两点&lt;/p&gt;
&lt;p&gt;1、默认重试次数：&lt;strong&gt;Product默认是2次，而Consumer默认是16次&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;2、重试时间间隔：&lt;strong&gt;Product是立刻重试，而Consumer是有一定时间间隔的&lt;/strong&gt;。它照&lt;code&gt;1S,5S,10S,30S,1M,2M····2H&lt;/code&gt;进行重试。&lt;/p&gt;
&lt;h4 id=&quot;timeout&quot;&gt;2、Timeout&lt;/h4&gt;
&lt;p&gt;&lt;code&gt;说明&lt;/code&gt; 这里的超时异常并非真正意义上的超时，它指的是指获取消息后，因为某种原因没有给RocketMQ返回消费的状态，即没有&lt;code&gt;return ConsumeConcurrentlyStatus.CONSUME_SUCCESS&lt;/code&gt; 或 &lt;code&gt;return ConsumeConcurrentlyStatus.RECONSUME_LATER&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;那么 &lt;strong&gt;RocketMQ会认为该消息没有发送，会一直发送&lt;/strong&gt;。因为它会认为该消息根本就没有发送给消费者,所以肯定没消费。&lt;/p&gt;
&lt;p&gt;做这个测试很简单。&lt;/p&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;        //1、消费者获得消息
        String body = new String(msg.getBody(), &quot;utf-8&quot;);
        //2、获取重试次数
        int count = ((MessageExt) msg).getReconsumeTimes();
        log.info(&quot;当前消费重试次数为 = {}&quot;, count);
        //3、这里睡眠60秒
        Thread.sleep(60000);
       log.info(&quot;休眠60秒 看还能不能走到这里。topic={},keys={},msg={}&quot;, msg.getTopic(), msg.getKeys(), body);
        //返回成功
        return ConsumeConcurrentlyStatus.CONSUME_SUCCESS;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;当获得 &lt;strong&gt;当前消费重试次数为 = 0&lt;/strong&gt; 后 , &lt;strong&gt;关掉该进程&lt;/strong&gt;。再重新启动该进程，那么依然能够获取该条消息&lt;/p&gt;
&lt;pre class=&quot;properties&quot;&gt;
&lt;code&gt;consumer消费者  当前消费重试次数为 = 0
休眠60秒 看还能不能走到这里。topic=topic_family,keys=1a2b3c4d5f,msg=小小今年3岁&lt;/code&gt;
&lt;/pre&gt;

&lt;pre&gt;
&lt;code&gt;只要自己变优秀了，其他的事情才会跟着好起来（上将2）&lt;/code&gt;
&lt;/pre&gt;</description>
<pubDate>Mon, 01 Jul 2019 16:03:00 +0000</pubDate>
<dc:creator>雨点的名字</dc:creator>
<og:description>RocketMQ重试机制 消息重试分为两种： Producer发送消息的重试 和 Consumer消息消费的重试 。 一、Producer端重试 Producer端重试是指: Producer往MQ上</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/qdhxhz/p/11117379.html</dc:identifier>
</item>
<item>
<title>SpringBoot中资源初始化加载的几种方式（看这一片就够了） - 会炼钢的小白龙</title>
<link>http://www.cnblogs.com/baixianlong/p/11117665.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/baixianlong/p/11117665.html</guid>
<description>&lt;p&gt;&lt;span&gt;&lt;strong&gt;原创不易，如需转载，请注明出处&lt;a href=&quot;https://www.cnblogs.com/baixianlong/p/11117665.html&quot; class=&quot;uri&quot;&gt;https://www.cnblogs.com/baixianlong/p/11117665.html&lt;/a&gt;，谢谢支持哈！！！&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h2 id=&quot;一问题&quot;&gt;一、问题&lt;/h2&gt;
&lt;p&gt;　　在平时的业务模块开发过程中，难免会需要做一些全局的任务、缓存、线程等等的初始化工作，那么如何解决这个问题呢？方法有多种，但具体又要怎么选择呢？&lt;/p&gt;
&lt;h2 id=&quot;二资源初始化&quot;&gt;二、资源初始化&lt;/h2&gt;
&lt;h3 id=&quot;既然要做资源的初始化那么就需要了解一下springboot启动过程这里大体说下启动过程详细httpswww.cnblogs.comdennyzhangddp8028950.html&quot;&gt;1、既然要做资源的初始化，那么就需要了解一下springboot启动过程（这里大体说下启动过程,详细：&lt;a href=&quot;https://www.cnblogs.com/dennyzhangdd/p/8028950.html&quot; class=&quot;uri&quot;&gt;https://www.cnblogs.com/dennyzhangdd/p/8028950.html&lt;/a&gt;）&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;https://i.loli.net/2019/07/01/5d1a2d4b1642343291.png&quot; alt=&quot;spring容器启动.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;按照前面的分析，Spring-boot容器启动流程总体可划分为2部分：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;执行注解：扫描指定范围下的bean、载入自动配置类对应的bean加载到IOC容器。&lt;/li&gt;
&lt;li&gt;man方法中具体SpringAppliocation.run()，全流程贯穿SpringApplicationEvent(经典的spring事件驱动模型),有6个子类：
&lt;ol&gt;&lt;li&gt;ApplicationFailedEvent.class&lt;/li&gt;
&lt;li&gt;ApplicationPreparedEvent.class&lt;/li&gt;
&lt;li&gt;ApplicationReadyEvent.class&lt;/li&gt;
&lt;li&gt;ApplicationStartedEvent.class&lt;/li&gt;
&lt;li&gt;ApplicationStartingEvent.class&lt;/li&gt;
&lt;li&gt;SpringApplicationEvent.class&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;h3 id=&quot;commandlinerunner和applicationrunner&quot;&gt;2、CommandLineRunner和ApplicationRunner&lt;/h3&gt;
&lt;p&gt;　　由上可知，我们只要实现这两个中的任何一个接口便可以完成我们的资源初始化任务，可以看到它们的加载是在容器完全启动之前。它两的区别是：前者的run方法参数是String...args，直接传入字符串，后者的参数是ApplicationArguments，对参数进行了封装。功能上是一样的。同时也可以使用 @Order注解来实现资源加载的先后顺序，值越小，优先级越高。实例如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;@Component
@Order(1)
public class MyCommandLineRunner implements CommandLineRunner {

    @Override
    public void run(String... args) throws Exception {
        System.out.println(&quot;...init resources by implements CommandLineRunner&quot;);
    }
}

@Component
@Order(2)
public class MyApplicationRunner implements ApplicationRunner {

    @Override
    public void run(ApplicationArguments applicationArguments) throws Exception {
        System.out.println(&quot;...init resources by implements ApplicationRunner&quot;);
    }
}&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;postconstruct&quot;&gt;3、@PostConstruct&lt;/h3&gt;
&lt;p&gt;　　在具体Bean的实例化过程中执行，@PostConstruct注解的方法，会在构造方法之后执行，顺序为Constructor &amp;gt; @Autowired &amp;gt; @PostConstruct &amp;gt; 静态方法，所以这个注解就避免了一些需要在构造方法里使用依赖组件的尴尬（与之对应的还有@PreDestroy，在对象消亡之前执行，原理差不多）。使用特点如下：&lt;/p&gt;
&lt;ul readability=&quot;0&quot;&gt;&lt;li&gt;只有一个非静态方法能使用此注解&lt;/li&gt;
&lt;li&gt;被注解的方法不得有任何参数&lt;/li&gt;
&lt;li&gt;被注解的方法返回值必须为void&lt;/li&gt;
&lt;li&gt;被注解方法不得抛出已检查异常&lt;/li&gt;
&lt;li readability=&quot;3&quot;&gt;
&lt;p&gt;此方法只会被执行一次&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;＠Component
public Class AAA {    
    @Autowired    
    private BBB b;   

    public AAA() {        
        System.out.println(&quot;此时b还未被注入: b = &quot; + b);    
    }    
    @PostConstruct    
    private void init() {        
        System.out.println(&quot;此时b已经被注入: b = &quot; + b);    
    }
}&lt;/code&gt;
&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;h3 id=&quot;initializingbean&quot;&gt;4、InitializingBean&lt;/h3&gt;
&lt;p&gt;　　InitializingBean 是 Spring 提供的一个接口，只包含一个方法 afterPropertiesSet()。凡是实现了该接口的类，当其对应的 Bean 交由 Spring 管理后，当其必要的属性全部设置完成后，Spring 会调用该 Bean 的 afterPropertiesSet()。在Bean在实例化的过程中执执行顺序为：Constructor &amp;gt; @PostConstruct &amp;gt; InitializingBean &amp;gt; init-method&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;public class InitSequenceBean implements InitializingBean {   
    
    public InitSequenceBean() {   
       System.out.println(&quot;InitSequenceBean: constructor&quot;);   
    }   
      
    @PostConstruct  
    public void postConstruct() {   
       System.out.println(&quot;InitSequenceBean: postConstruct&quot;);   
    }   
      
    public void initMethod() {   
       System.out.println(&quot;InitSequenceBean: init-method&quot;);   
    }   
      
    @Override  
    public void afterPropertiesSet() throws Exception {   
       System.out.println(&quot;InitSequenceBean: afterPropertiesSet&quot;);   
    }   
}&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;applicationlistener&quot;&gt;5、ApplicationListener&lt;/h3&gt;
&lt;p&gt;　　ApplicationListener 就是spring的监听器，能够用来监听事件，典型的观察者模式。如果容器中有一个ApplicationListener Bean，每当ApplicationContext发布ApplicationEvent时，ApplicationListener Bean将自动被触发。这种事件机制都必须需要程序显示的触发。其中spring有一些内置的事件，当完成某种操作时会发出某些事件动作。比如监听ContextRefreshedEvent事件，当所有的bean都初始化完成并被成功装载后会触发该事件，实现ApplicationListener接口可以收到监听动作，然后可以写自己的逻辑。同样事件可以自定义、监听也可以自定义，完全根据自己的业务逻辑来处理。所以也能做到资源的初始化加载！&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;@Component
public class DataSourceInitListener implements ApplicationListener&amp;lt;ContextRefreshedEvent&amp;gt; {//ContextRefreshedEvent为启动事件
 
    private static final Logger LOGGER = LoggerFactory.getLogger(DataSourceInitListener.class);
 
    @Autowired
    private SystemConfigService systemConfigService;
    @Autowired
    private ItemService itemService;
    @Autowired
    private SystemResultService systemResultService;
 
    @Override
    public void onApplicationEvent(ContextRefreshedEvent event) {
        if(event.getApplicationContext().getParent() == null) {//判断是否执行过，执行过则不再执行
            LOGGER.info(&quot;初始化systemConfig数据&quot;);
            systemConfigService.initConfig();
            LOGGER.info(&quot;初始化返回消息数据&quot;);
            systemResultService.initResult();
            LOGGER.info(&quot;系统初始化结束...........&quot;);
        }
    }
 
}&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;三总结&quot;&gt;三、总结&lt;/h2&gt;
&lt;ul&gt;&lt;li&gt;到此一些资源初始化的方法就说的差不多了，其中不免有些错误的地方，或者理解有偏颇的地方欢迎大家提出来！&lt;/li&gt;
&lt;/ul&gt;&lt;blockquote&gt;
&lt;p&gt;个人博客地址：&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote readability=&quot;1.4651162790698&quot;&gt;
&lt;blockquote readability=&quot;0.65789473684211&quot;&gt;
&lt;p&gt;csdn:&lt;a href=&quot;https://blog.csdn.net/tiantuo6513&quot; class=&quot;uri&quot;&gt;https://blog.csdn.net/tiantuo6513&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote readability=&quot;0.93023255813953&quot;&gt;
&lt;p&gt;cnblogs:&lt;a href=&quot;https://www.cnblogs.com/baixianlong&quot; class=&quot;uri&quot;&gt;https://www.cnblogs.com/baixianlong&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote readability=&quot;1.2745098039216&quot;&gt;
&lt;p&gt;segmentfault:&lt;a href=&quot;https://segmentfault.com/u/baixianlong&quot; class=&quot;uri&quot;&gt;https://segmentfault.com/u/baixianlong&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote readability=&quot;0.94594594594595&quot;&gt;
&lt;p&gt;github:&lt;a href=&quot;https://github.com/xianlongbai&quot; class=&quot;uri&quot;&gt;https://github.com/xianlongbai&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/blockquote&gt;
</description>
<pubDate>Mon, 01 Jul 2019 15:55:00 +0000</pubDate>
<dc:creator>会炼钢的小白龙</dc:creator>
<og:description>原创不易，如需转载，请注明出处 'https://www.cnblogs.com/baixianlong/p/11117665.html' ，谢谢支持哈！！！ 一、问题 在平时的业务模块开发过程中，难</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/baixianlong/p/11117665.html</dc:identifier>
</item>
<item>
<title>深入认识二进制序列化--记一次生产事故的思考 - hkant</title>
<link>http://www.cnblogs.com/zhu-wj/p/11117541.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/zhu-wj/p/11117541.html</guid>
<description>&lt;h2 id=&quot;一-概要&quot;&gt;一 概要&lt;/h2&gt;
&lt;p&gt;二进制序列化是公司内部自研微服务框架的主要的数据传输处理方式，但是普通的开发人员对于二进制的学习和了解并不深入，容易导致使用过程中出现了问题却没有分析解决的思路。本文从一次生产环境的事故引入这个话题，通过对于事故的分析过程，探讨了平时没有关注到的一些技术要点。二进制序列化结果并不像Json序列化一样具备良好的可读性，对于序列化的结果大多数人并不了解，因此本文最后通过实际的例子，对照MSDN的文档对于序列化结果进行详细解析，并意图通过本次分析对于二进制序列化的结果有直观和深入的认识。&lt;/p&gt;
&lt;h2 id=&quot;二-事故描述&quot;&gt;二 事故描述&lt;/h2&gt;
&lt;p&gt;某天晚上突发了一批预警，当时的场景：&lt;/p&gt;
&lt;blockquote readability=&quot;16&quot;&gt;
&lt;p&gt;A：B，帮忙看下你们的服务，我这里预警了&lt;/p&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;B：我刚发布了一个补丁，跟我有关？&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;A：我这里没有发布，当然有关系了，赶紧回退！&lt;/p&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;B：我这里又没改你们用到的接口，为啥是我们回退？&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;A：那怪我喽，我这里又没发布过东西，赶紧回退！&lt;/p&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;B：这个接口很长时间没有改过，肯定是你们自己的问题。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;A：不管谁的问题，咱们先回退看看。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;B：行吧，稍等下&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;发布助手：回退中……（回退后预警消失）&lt;/p&gt;
&lt;p&gt;A：……&lt;/p&gt;
&lt;p&gt;B：……&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;三-事故问题分析&quot;&gt;三 事故问题分析&lt;/h2&gt;
&lt;p&gt;虽然事故发生后通过回退补丁解决了当时的问题，但是事后对于问题的分析一直进行到了深夜。&lt;/p&gt;
&lt;p&gt;因为这次事故虽然解决起来简单，但是直接挑战了我们对于服务的认识，如果不查找到根本原因，后续的工作难以放心的开展。&lt;/p&gt;
&lt;p&gt;以前我们对于服务的认识简单归纳为：&lt;/p&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;增加属性不会导致客户端反序列化的失败。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;但是，这个并非是官方的说法，只是开发人员在使用过程中通过实际使用总结出来的规律。经验的总结往往缺乏理论的支持，在遇到问题的时候便一筹莫展。&lt;/p&gt;
&lt;p&gt;发生问题时，客户端捕获到的异常堆栈是这样的：&lt;/p&gt;
&lt;pre class=&quot;c#&quot;&gt;
&lt;code&gt;System.Runtime.Serialization.SerializationException
  HResult=0x8013150C
  Message=ObjectManager 发现链接地址信息的数目无效。这通常表示格式化程序中有问题。
  Source=mscorlib
  StackTrace:
   在 System.Runtime.Serialization.ObjectManager.DoFixups()
   在 System.Runtime.Serialization.Formatters.Binary.ObjectReader.Deserialize(HeaderHandler handler, __BinaryParser serParser, Boolean fCheck, Boolean isCrossAppDomain, IMethodCallMessage methodCallMessage)
   在 System.Runtime.Serialization.Formatters.Binary.BinaryFormatter.Deserialize(Stream serializationStream, HeaderHandler handler, Boolean fCheck, Boolean isCrossAppDomain, IMethodCallMessage methodCallMessage)
   在 System.Runtime.Serialization.Formatters.Binary.BinaryFormatter.Deserialize(Stream serializationStream)&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;通过异常堆栈能够看出是在进行二进制反序列化时发生了异常。通过多方查阅资料，针对此问题的观点基本可以总结为两点：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;反序列化使用的客户端过旧，将反序列化使用的类替换为最新的类。&lt;/li&gt;
&lt;li&gt;出现该问题跟泛型集合有关，如果新增了泛型集合容易出现此类问题。&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;观点一对于解决当前问题毫无帮助，观点二倒是有些用处，经过了解，当日发布的补丁中涉及的微服务接口并未新增泛型集合属性，而是对于以前增加而未使用的一个泛型集合增加了赋值的逻辑。后来经过测试，确实是由此处改动造成的问题。由此也可以看出，开发人员在日常开发过程中所总结出来的经验有一些局限性，有必要深入的分析下二进制序列化在何种情况下会导致反序列化失败。&lt;/p&gt;
&lt;h2 id=&quot;四-二进制序列化与反序列化测试&quot;&gt;四 二进制序列化与反序列化测试&lt;/h2&gt;
&lt;p&gt;为了测试不同的数据类型对于反序列化的影响，针对常用数据类型编写测试方案。本次测试涉及到两个代码解决方案，序列化的程序（简称V1）和反序列化的程序（简称V2）。&lt;/p&gt;
&lt;p&gt;测试步骤：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;V1中声明类及属性；&lt;/li&gt;
&lt;li&gt;V1中将类对象进行二进制序列化并保存到文件中；&lt;/li&gt;
&lt;li&gt;修改V1中类的属性，去掉相关的属性的声明后重新编译DLL；&lt;/li&gt;
&lt;li&gt;V2中引用步骤3中生成的DLL，并读取步骤2中生成的数据进行反序列化；&lt;/li&gt;
&lt;/ol&gt;&lt;pre class=&quot;c#&quot;&gt;
&lt;code&gt;/// &amp;lt;summary&amp;gt;
/// V1测试过程用到的类
/// &amp;lt;/summary&amp;gt;
[Serializable]
public class ObjectItem
{
    public string TestStr { get; set; }
}
/// &amp;lt;summary&amp;gt;
/// V1测试过程用到的结构体
/// &amp;lt;/summary&amp;gt;
[Serializable]
public struct StructItem
{
    public string TestStr;
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;测试常用数据类型的结果：&lt;/p&gt;
&lt;table&gt;&lt;thead/&gt;&lt;tbody readability=&quot;6&quot;&gt;&lt;tr class=&quot;odd&quot;&gt;&lt;td&gt;int&lt;/td&gt;
&lt;td&gt;100&lt;/td&gt;
&lt;td&gt;成功&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;even&quot;&gt;&lt;td&gt;int[]&lt;/td&gt;
&lt;td&gt;{1,100}&lt;/td&gt;
&lt;td&gt;成功&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;odd&quot;&gt;&lt;td&gt;string&lt;/td&gt;
&lt;td&gt;&quot;test&quot;&lt;/td&gt;
&lt;td&gt;成功&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;even&quot;&gt;&lt;td&gt;string[]&lt;/td&gt;
&lt;td&gt;{&quot;a&quot;,&quot;1&quot;}&lt;/td&gt;
&lt;td&gt;成功&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;odd&quot;&gt;&lt;td&gt;double&lt;/td&gt;
&lt;td&gt;1d&lt;/td&gt;
&lt;td&gt;成功&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;even&quot;&gt;&lt;td&gt;double[]&lt;/td&gt;
&lt;td&gt;{1d,2d}&lt;/td&gt;
&lt;td&gt;成功&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;odd&quot;&gt;&lt;td&gt;bool&lt;/td&gt;
&lt;td&gt;true&lt;/td&gt;
&lt;td&gt;成功&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;even&quot;&gt;&lt;td&gt;bool[]&lt;/td&gt;
&lt;td&gt;{false,true}&lt;/td&gt;
&lt;td&gt;成功&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;odd&quot;&gt;&lt;td&gt;List&amp;lt;string&amp;gt;&lt;/td&gt;
&lt;td&gt;null&lt;/td&gt;
&lt;td&gt;成功&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;even&quot;&gt;&lt;td&gt;List&amp;lt;string&amp;gt;&lt;/td&gt;
&lt;td&gt;{}&lt;/td&gt;
&lt;td&gt;成功&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;odd&quot;&gt;&lt;td&gt;List&amp;lt;string&amp;gt;&lt;/td&gt;
&lt;td&gt;{&quot;1&quot;,&quot;a&quot;}&lt;/td&gt;
&lt;td&gt;成功&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;even&quot;&gt;&lt;td&gt;List&amp;lt;int&amp;gt;&lt;/td&gt;
&lt;td&gt;null&lt;/td&gt;
&lt;td&gt;成功&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;odd&quot;&gt;&lt;td&gt;List&amp;lt;int&amp;gt;&lt;/td&gt;
&lt;td&gt;{}&lt;/td&gt;
&lt;td&gt;成功&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;even&quot;&gt;&lt;td&gt;List&amp;lt;int&amp;gt;&lt;/td&gt;
&lt;td&gt;{1,100}&lt;/td&gt;
&lt;td&gt;成功&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;odd&quot;&gt;&lt;td&gt;List&amp;lt;double&amp;gt;&lt;/td&gt;
&lt;td&gt;null&lt;/td&gt;
&lt;td&gt;成功&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;even&quot;&gt;&lt;td&gt;List&amp;lt;double&amp;gt;&lt;/td&gt;
&lt;td&gt;{}&lt;/td&gt;
&lt;td&gt;成功&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;odd&quot;&gt;&lt;td&gt;List&amp;lt;double&amp;gt;&lt;/td&gt;
&lt;td&gt;{1d,100d}&lt;/td&gt;
&lt;td&gt;成功&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;even&quot;&gt;&lt;td&gt;List&amp;lt;bool&amp;gt;&lt;/td&gt;
&lt;td&gt;null&lt;/td&gt;
&lt;td&gt;成功&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;odd&quot;&gt;&lt;td&gt;List&amp;lt;bool&amp;gt;&lt;/td&gt;
&lt;td&gt;{}&lt;/td&gt;
&lt;td&gt;成功&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;even&quot;&gt;&lt;td&gt;List&amp;lt;bool&amp;gt;&lt;/td&gt;
&lt;td&gt;{true,false}&lt;/td&gt;
&lt;td&gt;成功&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;odd&quot;&gt;&lt;td&gt;ObjectItem&lt;/td&gt;
&lt;td&gt;null&lt;/td&gt;
&lt;td&gt;成功&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;even&quot;&gt;&lt;td&gt;ObjectItem&lt;/td&gt;
&lt;td&gt;new ObjectItem()&lt;/td&gt;
&lt;td&gt;成功&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;odd&quot;&gt;&lt;td&gt;ObjectItem[]&lt;/td&gt;
&lt;td&gt;{}&lt;/td&gt;
&lt;td&gt;成功&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;even&quot; readability=&quot;2&quot;&gt;&lt;td&gt;ObjectItem{}&lt;/td&gt;
&lt;td&gt;{new ObjectItem()}&lt;/td&gt;
&lt;td&gt;失败（当反序列化时客户端没有ObjectItem这个类）&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;odd&quot; readability=&quot;2&quot;&gt;&lt;td&gt;ObjectItem{}&lt;/td&gt;
&lt;td&gt;{new ObjectItem()}&lt;/td&gt;
&lt;td&gt;成功（当反序列化时客户端有ObjectItem这个类）&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;even&quot;&gt;&lt;td&gt;List&amp;lt;ObjectItem&amp;gt;&lt;/td&gt;
&lt;td&gt;null&lt;/td&gt;
&lt;td&gt;成功&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;odd&quot;&gt;&lt;td&gt;List&amp;lt;ObjectItem&amp;gt;&lt;/td&gt;
&lt;td&gt;{}&lt;/td&gt;
&lt;td&gt;成功&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;even&quot; readability=&quot;2&quot;&gt;&lt;td&gt;List&amp;lt;ObjectItem&amp;gt;&lt;/td&gt;
&lt;td&gt;{new ObjectItem()}&lt;/td&gt;
&lt;td&gt;失败（当反序列化时客户端没有ObjectItem这个类）&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;odd&quot; readability=&quot;2&quot;&gt;&lt;td&gt;List&amp;lt;ObjectItem&amp;gt;&lt;/td&gt;
&lt;td&gt;{new ObjectItem()}&lt;/td&gt;
&lt;td&gt;成功（当反序列化时客户端有ObjectItem这个类）&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;even&quot;&gt;&lt;td&gt;StructItem&lt;/td&gt;
&lt;td&gt;null&lt;/td&gt;
&lt;td&gt;成功&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;odd&quot;&gt;&lt;td&gt;StructItem&lt;/td&gt;
&lt;td&gt;new StructItem()&lt;/td&gt;
&lt;td&gt;成功&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;even&quot;&gt;&lt;td&gt;List&amp;lt;StructItem&amp;gt;&lt;/td&gt;
&lt;td&gt;null&lt;/td&gt;
&lt;td&gt;成功&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;odd&quot;&gt;&lt;td&gt;List&amp;lt;StructItem&amp;gt;&lt;/td&gt;
&lt;td&gt;{}&lt;/td&gt;
&lt;td&gt;成功&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;even&quot; readability=&quot;2&quot;&gt;&lt;td&gt;List&amp;lt;StructItem&amp;gt;&lt;/td&gt;
&lt;td&gt;{new StructItem()}&lt;/td&gt;
&lt;td&gt;成功（当反序列化时客户端没有ObjectItem这个类）&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;odd&quot; readability=&quot;2&quot;&gt;&lt;td&gt;List&amp;lt;StructItem&amp;gt;&lt;/td&gt;
&lt;td&gt;{new StructItem()}&lt;/td&gt;
&lt;td&gt;成功（当反序列化时客户端有ObjectItem这个类）&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;测试结果总结：二进制反序列化的时候会自动兼容处理序列化一方新增的数据。但是在个别情况下会出现反序列化的过程中遇到异常的情况。&lt;br/&gt;出现反序列化异常的数据类型：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;泛型集合&lt;/li&gt;
&lt;li&gt;数组&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;这两种数据结构并非是一定会导致二进制反序列化报错，而是有一定的条件。泛型集合出现反序列化异常的条件有三个：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;序列化的对象新增了泛型集合；&lt;/li&gt;
&lt;li&gt;泛型使用的是新增的类；&lt;/li&gt;
&lt;li&gt;新增的类在反序列化的时候不存在；&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;数组也是类似的，只有满足上述三个条件的时候，才会导致二进制反序列化失败。这也是为什么之前发布后一直没有问题而对于其中的泛型集合进行赋值后出现微服务客户端报错的原因。&lt;/p&gt;
&lt;p&gt;既然通过测试了解到了二进制反序列化确实会有自动的兼容处理机制，那么有必要深入了解下MSDN上对于二进制反序列化的容错机制的理论知识。&lt;/p&gt;
&lt;h2 id=&quot;五-二进制反序列化的容错机制&quot;&gt;五 二进制反序列化的容错机制&lt;/h2&gt;
&lt;p&gt;二进制反序列化过程中不可避免会遇到序列化与反序列化使用的程序集版本不同的情况，如果强行要求反序列化的一方（比如微服务的客户端）一定要跟序列化的一方（比如微服务的服务端）时时刻刻保持一致在实际应用过程是不现实的。从.NET2.0版本开始，.NET中针对二进制反序列化引入了版本容错机制(Version Tolerant Serialization，简称VTS)。&lt;/p&gt;
&lt;blockquote readability=&quot;7&quot;&gt;
&lt;p&gt;当使用 BinaryFormatter 时，将启用 VTS 功能。VTS 功能尤其是为应用了 SerializableAttribute 特性的类（包括泛型类型）而启用的。 VTS 允许向这些类添加新字段，而不破坏与该类型其他版本的兼容性。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;序列化与反序列化过程中如果遇到客户端与服务端程序集不同的情况下，.NET会尽量的进行兼容，所以平时使用过程中对此基本没有太大的感触，甚至有习以为常的感觉。&lt;/p&gt;
&lt;p&gt;要确保版本管理行为正确，修改类型版本时请遵循以下规则：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;切勿移除已序列化的字段。&lt;/li&gt;
&lt;li&gt;如果未在以前版本中将 NonSerializedAttribute 特性应用于某个字段，则切勿将该特性应用于该字段。&lt;/li&gt;
&lt;li&gt;切勿更改已序列化字段的名称或类型。&lt;/li&gt;
&lt;li&gt;添加新的已序列化字段时，请应用 OptionalFieldAttribute 特性。&lt;/li&gt;
&lt;li&gt;从字段（在以前版本中不可序列化）中移除 NonSerializedAttribute 特性时，请应用 OptionalFieldAttribute 特性。&lt;/li&gt;
&lt;li&gt;对于所有可选字段，除非可接受 0 或 null 作为默认值，否则请使用序列化回调设置有意义的默认值。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;要确保类型与将来的序列化引擎兼容，请遵循以下准则：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;始终正确设置 OptionalFieldAttribute 特性上的 VersionAdded 属性。&lt;/li&gt;
&lt;li&gt;避免版本管理分支。&lt;/li&gt;
&lt;/ul&gt;&lt;h2 id=&quot;六-二进制序列化数据的结构&quot;&gt;六 二进制序列化数据的结构&lt;/h2&gt;
&lt;p&gt;通过前文已经了解了二进制序列化以及版本兼容性的理论知识。接下来有必要对于平时所用的二进制序列化结果进行直观的学习，消除对于二进制序列化结果的陌生感。&lt;/p&gt;
&lt;h3 id=&quot;远程调用过程中发送的数据&quot;&gt;6.1 远程调用过程中发送的数据&lt;/h3&gt;
&lt;p&gt;目前我们所使用的.NET微服务框架所使用的正是二进制的数据序列化方式。当进行远程调用的过程中，客户端发给服务端的数据到底是什么样子的呢？&lt;/p&gt;
&lt;p&gt;引用文档中一个现成的例子(参考资料4)：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/441736/201907/441736-20190701232918035-1677248169.png&quot; alt=&quot;远程调用的例子&quot;/&gt;&lt;/p&gt;
&lt;p&gt;上图表示的是客户端远程调用服务端的SendAddress方法，并且发送的是名为Address的类对象，该类有四个属性：(Street = &quot;One Microsoft Way&quot;, City = &quot;Redmond&quot;, State = &quot;WA&quot; and Zip = &quot;98054&quot;) 。服务端回复的是一个字符串“Address Received”。&lt;/p&gt;
&lt;p&gt;客户端实际发送的数据如下：&lt;/p&gt;
&lt;pre class=&quot;text&quot;&gt;
&lt;code&gt;0000  00 01 00 00 00 FF FF FF FF 01 00 00 00 00 00 00 .....ÿÿÿÿ.......
0010  00 15 14 00 00 00 12 0B 53 65 6E 64 41 64 64 72 ........SendAddr
0020  65 73 73 12 6F 44 4F 4A 52 65 6D 6F 74 69 6E 67 ess.oDOJRemoting
0030  4D 65 74 61 64 61 74 61 2E 4D 79 53 65 72 76 65 Metadata.MyServe
0040  72 2C 20 44 4F 4A 52 65 6D 6F 74 69 6E 67 4D 65 r, DOJRemotingMe
0050  74 61 64 61 74 61 2C 20 56 65 72 73 69 6F 6E 3D tadata, Version=
0060  31 2E 30 2E 32 36 32 32 2E 33 31 33 32 36 2C 20 1.0.2622.31326,
0070  43 75 6C 74 75 72 65 3D 6E 65 75 74 72 61 6C 2C Culture=neutral,
0080  20 50 75 62 6C 69 63 4B 65 79 54 6F 6B 65 6E 3D PublicKeyToken=
0090  6E 75 6C 6C 10 01 00 00 00 01 00 00 00 09 02 00 null............
00A0  00 00 0C 03 00 00 00 51 44 4F 4A 52 65 6D 6F 74 .......QDOJRemot
00B0  69 6E 67 4D 65 74 61 64 61 74 61 2C 20 56 65 72 ingMetadata, Ver
00C0  73 69 6F 6E 3D 31 2E 30 2E 32 36 32 32 2E 33 31 sion=1.0.2622.31
00D0  33 32 36 2C 20 43 75 6C 74 75 72 65 3D 6E 65 75 326, Culture=neu
00E0  74 72 61 6C 2C 20 50 75 62 6C 69 63 4B 65 79 54 tral, PublicKeyT
00F0  6F 6B 65 6E 3D 6E 75 6C 6C 05 02 00 00 00 1B 44 oken=null......D
0100  4F 4A 52 65 6D 6F 74 69 6E 67 4D 65 74 61 64 61 OJRemotingMetada
0110  74 61 2E 41 64 64 72 65 73 73 04 00 00 00 06 53 ta.Address.....S
0120  74 72 65 65 74 04 43 69 74 79 05 53 74 61 74 65 treet.City.State
0130  03 5A 69 70 01 01 01 01 03 00 00 00 06 04 00 00 .Zip............
0140  00 11 4F 6E 65 20 4D 69 63 72 6F 73 6F 66 74 20 ..One Microsoft 
0150  57 61 79 06 05 00 00 00 07 52 65 64 6D 6F 6E 64 Way......Redmond
0160  06 06 00 00 00 02 57 41 06 07 00 00 00 05 39 38 ......WA......98
0170  30 35 34 0B                                     054.  &lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;上文的数据是二进制的，能看出来序列化后的结果中包含程序集信息，被调用的方法、使用的参数类、属性及各个属性的值等信息。对于上述的序列化后数据进行详细解读的分析可以参考资料4。&lt;/p&gt;
&lt;h3 id=&quot;类对象二进制序列化结果&quot;&gt;6.2 类对象二进制序列化结果&lt;/h3&gt;
&lt;p&gt;对于类对象进行序列化后的结果没有现成的例子，针对此专门设计了一个简单的场景，将序列化后的数据保存到本地文件中。&lt;/p&gt;
&lt;pre class=&quot;c#&quot;&gt;
&lt;code&gt;/// &amp;lt;summary&amp;gt;
/// 自定义序列化对象
/// &amp;lt;/summary&amp;gt;
[Serializable]
public class MyObject
{
    public bool BoolMember { get; set; }
    public int IntMember { get; set; }
}
/// &amp;lt;summary&amp;gt;
/// 程序入口
/// &amp;lt;/summary&amp;gt;
class Program
{
    static void Main(string[] args)
    {
        var obj = new MyObject();
        obj.BoolMember = true;
        obj.IntMember = 10000;

        IFormatter formatter = new BinaryFormatter();
        Stream stream = new FileStream(&quot;data.dat&quot;, FileMode.Create, FileAccess.Write, FileShare.None);

        formatter.Serialize(stream, obj);
        stream.Close();
    }
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;data.dat中的内容：&lt;/p&gt;
&lt;pre class=&quot;text&quot;&gt;
&lt;code&gt;0000: 00 01 00 00 00 ff ff ff ff 01 00 00 00 00 00 00  ................
0010: 00 0c 02 00 00 00 4e 42 69 6e 61 72 79 53 65 72  ......NBinarySer
0020: 69 61 6c 69 7a 65 50 72 61 63 74 69 73 65 2c 20  ializePractise, 
0030: 56 65 72 73 69 6f 6e 3d 31 2e 30 2e 30 2e 30 2c  Version=1.0.0.0,
0040: 20 43 75 6c 74 75 72 65 3d 6e 65 75 74 72 61 6c   Culture=neutral
0050: 2c 20 50 75 62 6c 69 63 4b 65 79 54 6f 6b 65 6e  , PublicKeyToken
0060: 3d 6e 75 6c 6c 05 01 00 00 00 20 42 69 6e 61 72  =null..... Binar
0070: 79 53 65 72 69 61 6c 69 7a 65 50 72 61 63 74 69  ySerializePracti
0080: 73 65 2e 4d 79 4f 62 6a 65 63 74 02 00 00 00 1b  se.MyObject.....
0090: 3c 42 6f 6f 6c 4d 65 6d 62 65 72 3e 6b 5f 5f 42  &amp;lt;BoolMember&amp;gt;k__B
00a0: 61 63 6b 69 6e 67 46 69 65 6c 64 1a 3c 49 6e 74  ackingField.&amp;lt;Int
00b0: 4d 65 6d 62 65 72 3e 6b 5f 5f 42 61 63 6b 69 6e  Member&amp;gt;k__Backin
00c0: 67 46 69 65 6c 64 00 00 01 08 02 00 00 00 01 10  gField..........
00d0: 27 00 00 0b                                      '...&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;对于类对象直接进行二进制序列化后的结果与远程调用场景二进制序列化的结构有所不同。&lt;/p&gt;
&lt;p&gt;按照[MS-NRBF]所言，序列化后的结果首先是序列化数据头，其中包含RecordTypeEnum、TopId、HeaderId、MajorVersion和MajorVersion。这之后就是被序列化的类的一些信息，包括程序集、类名、属性和属性对应的值。&lt;/p&gt;
&lt;pre class=&quot;text&quot;&gt;
&lt;code&gt;Binary Serialization Format
   SerializationHeaderRecord:
       RecordTypeEnum: SerializedStreamHeader (0x00)
       TopId: 1 (0x1)
       HeaderId: -1 (0xFFFFFFFF)
       MajorVersion: 1 (0x1)
       MinorVersion: 0 (0x0)
   Record Definition:
       RecordTypeEnum: SystemClassWithMembers (0x02)
       ClassInfo:
            ObjectId:  (0x4e000000)
            LengthPrefixedString:
                Length: 78 (0x4e)
                String: BinarySerializePractise, Version=1.0.0.0, Culture=neutral, PublicKeyToken=null
            ObjectId:  (0x00000001)
            LengthPrefixedString:
                Length: 32 (0x20)
                String: BinarySerializePractise.MyObject
            MemberCount: 2(0x00000002)
            LengthPrefixedString:
                Length: 27(0x1b)
                String: &amp;lt;BoolMember&amp;gt;k__BackingField
            LengthPrefixedString:
                Length: 26(0x1a)
                String: &amp;lt;IntMember&amp;gt;k__BackingField
            ObjectId：0x08010000
            Length：0x00000002
            Value:1(0x01)
            Value:10000(0x00002710)
    MessageEnd:
             RecordTypeEnum: MessageEnd (0x0b)&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;七-总结&quot;&gt;七 总结&lt;/h2&gt;
&lt;p&gt;二进制序列化和反序列化虽然是目前使用的微服务的主要数据处理方式，但是对于开发人员来说这部分内容比较神秘，对于序列化数据和反序列化机制不甚了解。本文中通过一次事故的分析过程，梳理总结了反序列化机制，反序列化兼容性，序列化数据结构等内容，希望通过本文的一些知识，能够消除对于二进制序列化的陌生感，增进对于二进制序列化的深入认识。&lt;/p&gt;
&lt;h2 id=&quot;八-参考资料&quot;&gt;八 参考资料&lt;/h2&gt;
&lt;ol&gt;&lt;li&gt;&lt;a href=&quot;https://riptutorial.com/csharp/example/25104/some-gotchas-in-backward-compatibility&quot;&gt;Some gotchas in backward compatibility&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://docs.microsoft.com/zh-cn/dotnet/standard/serialization/version-tolerant-serialization&quot;&gt;版本容错序列化&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://docs.microsoft.com/en-us/openspecs/windows_protocols/ms-nrbf/75b9fe09-be15-475f-85b8-ae7b7558cfe5&quot;&gt;[MS-NRBF]: .NET Remoting: Binary Format Data Structure&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://docs.microsoft.com/zh-cn/openspecs/windows_protocols/ms-nrbf/86fe94e6-c8f4-472a-b520-a9877a34fbbb&quot;&gt;[MS-NRBF]: 3 Structure Examples&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;</description>
<pubDate>Mon, 01 Jul 2019 15:33:00 +0000</pubDate>
<dc:creator>hkant</dc:creator>
<og:description>一 概要 二进制序列化是公司内部自研微服务框架的主要的数据传输处理方式，但是普通的开发人员对于二进制的学习和了解并不深入，容易导致使用过程中出现了问题却没有分析解决的思路。本文从一次生产环境的事故引入</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/zhu-wj/p/11117541.html</dc:identifier>
</item>
<item>
<title>关于CORS 应该注意的几点 - 潇湘待雨</title>
<link>http://www.cnblogs.com/pqjwyn/p/11117458.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/pqjwyn/p/11117458.html</guid>
<description>&lt;h2 id=&quot;前言&quot;&gt;前言&lt;/h2&gt;
&lt;p&gt;对于跨域，随着w3c的CORS的出现，相比较于有些年头的jsonp，CORS以其简单安全，支持post的优势越来越收到大家的欢迎。具体如何CORS的原理和实现，&lt;a href=&quot;http://www.ruanyifeng.com/blog/2016/04/cors.html&quot;&gt;直接推荐阮老师的文章&lt;/a&gt;,十分详细。本文主要关注CORS实现过程中的几个疑惑点。&lt;/p&gt;
&lt;h2 id=&quot;预检请求&quot;&gt;预检请求&lt;/h2&gt;
&lt;h3 id=&quot;背景&quot;&gt;背景&lt;/h3&gt;
&lt;p&gt;浏览器将CORS请求分成两类：简单请求（simple request）和非简单请求（not-so-simple request)。&lt;/p&gt;
&lt;h4 id=&quot;简单请求&quot;&gt;简单请求&lt;/h4&gt;
&lt;p&gt;同时满足一下条件的即是简单请求：&lt;/p&gt;
&lt;ol readability=&quot;1&quot;&gt;&lt;li&gt;请求方法是以下三种方法之一：&lt;br/&gt;HEAD、GET、POST&lt;/li&gt;
&lt;li readability=&quot;5&quot;&gt;
&lt;p&gt;HTTP的头信息不超出以下几种字段&lt;br/&gt;Accept&lt;br/&gt;Accept-Language&lt;br/&gt;Content-Language&lt;br/&gt;Last-Event-ID&lt;br/&gt;Content-Type：只限于三个值application/x-www-form、multipart/form-data、text/plain&lt;/p&gt;
&lt;h4 id=&quot;非简单请求&quot;&gt;非简单请求&lt;/h4&gt;
&lt;p&gt;显然，不同时满足则为非简单请求(可以认为是复杂请求)。两者的差别在于复杂请求在与服务端交互时多了一次options的预检请求，毕竟复杂请求一般就是HTTP请求头信息超出限制或者method为put、delete等操作行为，处于安全考虑，需要服务端先行验证来决定是否给予相关权限。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;如下所示（示例来自阮老师文章）:&lt;/p&gt;
&lt;pre class=&quot;js&quot;&gt;
&lt;code&gt;var url = 'http://api.alice.com/cors';
var xhr = new XMLHttpRequest();
// PUT method为复杂请求，要预检
xhr.open('PUT', url, true);
xhr.setRequestHeader('X-Custom-Header', 'value');
xhr.send();&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;非简单请求，浏览器自动发送otpios的预检请求，请求头如下：&lt;/p&gt;
&lt;pre class=&quot;js&quot;&gt;
&lt;code&gt;OPTIONS /cors HTTP/1.1
// 请求源
Origin: http://api.bob.com
// 必须字段，指明正式cors请求将会使用那些method
Access-Control-Request-Method: PUT
// 除简单头之外，额外的请求头
Access-Control-Request-Headers: X-Custom-Header
Host: api.alice.com
Accept-Language: en-US
Connection: keep-alive
User-Agent: Mozilla/5.0...&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;对于预检信息，服务端一般做了如下操作：&lt;/p&gt;
&lt;p&gt;1、检查origin、Access-Control-Request-Method和Access-Control-Request-Headers等字段，确认是否允许跨域，如果允许跨域作出回应：&lt;/p&gt;
&lt;pre class=&quot;js&quot;&gt;
&lt;code&gt;HTTP/1.1 200 OK
Date: Mon, 01 Dec 2008 01:15:39 GMT
Server: Apache/2.0.61 (Unix)
// 允许的源 
Access-Control-Allow-Origin: http://api.bob.com
// 允许的请求方式
Access-Control-Allow-Methods: GET, POST, PUT
// 允许额外header
Access-Control-Allow-Headers: X-Custom-Header
Content-Type: text/html; charset=utf-8
Content-Encoding: gzip
Content-Length: 0
Keep-Alive: timeout=2, max=100
Connection: Keep-Alive
Content-Type: text/plain&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;如果不允许跨域，依然响应该请求，不过不携带CORS相关的信息。浏览器则会认为服务器不允许跨域，触发错误。&lt;/p&gt;
&lt;pre class=&quot;js&quot;&gt;
&lt;code&gt;// 常见的跨域错误
XMLHttpRequest cannot load http://api.alice.com.
Origin http://api.bob.com is not allowed by Access-Control-Allow-Origin.&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;到这里一个流程结束，不过我们要关注的是options 预检请求之后 code 返回的问题&lt;/p&gt;
&lt;h3 id=&quot;options-成功之后返回code-200-还是-204&quot;&gt;options 成功之后，返回code 200 还是 204&lt;/h3&gt;
&lt;p&gt;常规预检的就是对于options的请求直接返回code 200的响应，表示校验通过。&lt;br/&gt;但是前两天发现有的返回为code204。两者之间的差别具体在哪呢。&lt;/p&gt;
&lt;h4 id=&quot;常见用法&quot;&gt;常见用法&lt;/h4&gt;
&lt;p&gt;1、针对特定接口支持CORS时，在代码里加判断对于options返回200&lt;/p&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;// 随便找了段java代码 
if (req.getMethod().equals(&quot;OPTIONS&quot;)) {
     res.setStatus(200);
 }&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;2、如果整个域名都支持CORS，可以再nginx侧直接配置，此时常见的是返回204.&lt;/p&gt;
&lt;pre class=&quot;shell&quot;&gt;
&lt;code&gt;if ($request_method = 'OPTIONS') { 
    add_header Access-Control-Allow-Origin *; 
    add_header Access-Control-Allow-Methods GET,POST,PUT,DELETE,OPTIONS;
    #****省略...
    return 204; 
}&lt;/code&gt;
&lt;/pre&gt;
&lt;h4 id=&quot;总结&quot;&gt;总结&lt;/h4&gt;
&lt;p&gt;两者之间的差别，首先可以参考下204和200 对应的含义（下面内容摘自MDN）。&lt;br/&gt;&lt;strong&gt;200&lt;/strong&gt;&lt;br/&gt;请求成功，成功的具体含义依据http method 的不同而有所差别。：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;GET: 资源已经被提取并在消息中文中传递&lt;/li&gt;
&lt;li&gt;POST: 描述动作结果的资源在消息体中传输&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;204&lt;/strong&gt;&lt;br/&gt;服务器成功处理了请求，但不需要返回任何实体内容，并且希望返回更新了的元信息。&lt;br/&gt;客户端是浏览器的haul，用户浏览器应保留发送了该请求的页面，而不产生任何文档视图上的变化。由于204响应被禁止包含任何消息体，因此它始终以消息头后的第一个空行结尾。&lt;/p&gt;
&lt;p&gt;简单总结，204返回表示请求成功，并且无消息体，优势在于节省网络请求。&lt;/p&gt;
&lt;h4 id=&quot;具体到options请求选用哪一个&quot;&gt;具体到options请求，选用哪一个。&lt;/h4&gt;
&lt;p&gt;贴切的来说，应该像其他options请求一样为预检optiosn请求返回相同的code状态码，相关规范不要求或者推荐其他内容。&lt;br/&gt;&lt;strong&gt;fecth请求&lt;/strong&gt;&lt;br/&gt;例如对于&lt;a href=&quot;https://fetch.spec.whatwg.org/&quot;&gt;Fetch 规范&lt;/a&gt; 要求CORS协议的status可以为200-209里面的任意值。&lt;/p&gt;
&lt;pre class=&quot;json&quot;&gt;
&lt;code&gt;If a CORS check for request and response returns success 
and response’s status is an ok status, 
run these substeps.&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;如果response为一个okstatus就可以继续执行&lt;/p&gt;
&lt;pre class=&quot;json&quot;&gt;
&lt;code&gt;An ok status is any status in the range 200 to 299, inclusive.&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;并不要求具体哪一个值。&lt;br/&gt;所以从fetch来看，两者均可选择。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;HTTP 1.1&lt;/strong&gt;&lt;br/&gt;对于http/1.1 规范来说，有一章节专门定义了各种响应code。对于&lt;a href=&quot;https://tools.ietf.org/html/rfc7231#section-6.3&quot;&gt;2开头的2-XXcode&lt;/a&gt;,分别描述如下：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;200&lt;/strong&gt;&lt;br/&gt;请求成功，成功的具体含义依据http method 的不同而有所差别。&lt;/li&gt;
&lt;li&gt;GET: 资源已经被提取并在消息中文中传递&lt;/li&gt;
&lt;li&gt;POST: 描述动作结果的资源在消息体中传输&lt;/li&gt;
&lt;li&gt;OPTIONS: communications options成功的表示&lt;br/&gt;由上可知，对于options预检请求的响应，需要包含下面两种情况：&lt;br/&gt;1、表明请求成功&lt;br/&gt;2、描述通信选项（这里包括， Access-Control-Allow-Methods 和 Access-Control-Allow-Headers这些响应头）&lt;br/&gt;看起来，上面就是200在http定义中的含义，显然满足，但是如果继续看204的含义，好像也可以满足需求。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;204&lt;/strong&gt;&lt;br/&gt;服务器成功处理了请求，但不需要返回任何实体内容，并且希望返回更新了的元信息。&lt;br/&gt;客户端是浏览器的话，用户浏览器应保留发送了该请求的页面，而不产生任何文档视图上的变化。由于204响应被禁止包含任何消息体，因此它始终以消息头后的第一个空行结尾。&lt;/p&gt;
&lt;h4 id=&quot;结论&quot;&gt;结论&lt;/h4&gt;
&lt;p&gt;首先两者都可以使用，对于200，从定义而言更符合场景和定义。但是204无消息体，优势在于节省网络请求。&lt;br/&gt;至于用哪个，大家自行做下判断。&lt;/p&gt;
&lt;h3 id=&quot;跨域-读取cookie&quot;&gt;跨域 读取cookie&lt;/h3&gt;
&lt;p&gt;作为常见的场景，cookie一般会存放一些，鉴权会话等信息。对于CORS跨域，默认的是不包含cookie的。&lt;/p&gt;
&lt;pre class=&quot;js&quot;&gt;
&lt;code&gt;A cross-origin request by default does not bring any credentials (cookies or HTTP authentication)&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;如果要操作cookie需要分别从服务端和客户端两个场景来看。&lt;/p&gt;
&lt;h4 id=&quot;客户端-request-携带cookie&quot;&gt;客户端 request 携带cookie&lt;/h4&gt;
&lt;p&gt;request如果要携带cookie，需要特定参数指明。可能看到过这个参数为credentials或者withCredentials，什么时候用两者呢。主要跟请求的实现有关：&lt;/p&gt;
&lt;ol readability=&quot;0&quot;&gt;&lt;li readability=&quot;3&quot;&gt;
&lt;p&gt;&lt;strong&gt;Fetch 使用credentials&lt;/strong&gt;&lt;br/&gt;直接使用原生Fetch的话，需要设置credentials。&lt;/p&gt;
&lt;p&gt;credentials 是Request接口的只读属性，用于表示用户代理是否应该在跨域请求的情况下从其他域发送cookies。这与XHR的withCredentials 标志相似，不同的是有三个可选值（后者是两个）：&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;&lt;ul&gt;&lt;li&gt;omit: 从不发送cookies.&lt;/li&gt;
&lt;li&gt;same-origin: 只有当URL与响应脚本同源才发送 cookies、 HTTP Basic authentication 等验证信息.(浏览器默认值,在旧版本浏览器，例如safari 11依旧是omit，safari 12已更改)&lt;/li&gt;
&lt;li&gt;include: 不论是不是跨域的请求,总是发送请求资源域在本地的 cookies、 HTTP Basic authentication 等验证信息.&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;CORS跨域的时候，只需要如下设置：&lt;/p&gt;
&lt;pre class=&quot;js&quot;&gt;
&lt;code&gt;fetch('http://another.com', {
  credentials: &quot;include&quot;
});&lt;/code&gt;
&lt;/pre&gt;
&lt;ol&gt;&lt;li&gt;&lt;strong&gt;XHR 使用withCredentials&lt;/strong&gt;&lt;br/&gt;基于XMLHttpRequest实现的请求使用withCredentials来允许携带cookie。&lt;br/&gt;该属性为boolean类型，所以只有true/false两个取值，默认为false。&lt;br/&gt;这样也很好理解，默认不携带是处于安全考虑。&lt;br/&gt;使用如下&lt;/li&gt;
&lt;/ol&gt;&lt;pre class=&quot;js&quot;&gt;
&lt;code&gt;var xhr = new XMLHttpRequest();
xhr.open('GET', 'http://example.com/', true);
xhr.withCredentials = true;
xhr.send(null);&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;适用框架：jquery的ajax，axios等。&lt;/p&gt;
&lt;h4 id=&quot;服务端-access-control-allow-credentials&quot;&gt;服务端 Access-Control-Allow-Credentials&lt;/h4&gt;
&lt;p&gt;当客户端设置了允许携带cookie之后，并不能完成该操作，毕竟是跨域，服务端也需要做响应设置，否则浏览器拿不到正确响应。&lt;/p&gt;
&lt;pre class=&quot;js&quot;&gt;
&lt;code&gt;Access-Control-Allow-Credentials:true&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;看MDN 的解释：&lt;/p&gt;
&lt;pre class=&quot;js&quot;&gt;
&lt;code&gt;
The Access-Control-Allow-Credentials response header tells browsers whether to expose the response to frontend JavaScript code when the request's credentials mode (Request.credentials) is &quot;include&quot;.  &lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;当 credentials为include的时候，通知浏览器是否将响应暴露给前端jscode，如果为false，js不能读取响应自然请求报错。&lt;br/&gt;只有Access-Control-Allow-Credentials为true时，才会将响应暴露给客户端。&lt;br/&gt;当作为预检请求响应头时，表明该实际请求(即后面的真正请求)是否可以使用credentials。&lt;/p&gt;
&lt;p&gt;不过对于简单请求，因为没有预检，如果服务端没有正确响应，浏览器会忽略该属性，并不会直接报错。&lt;br/&gt;需要与XMLHttpRequest.withCredentials属性或者Fetch 的credentials 配合使用。&lt;/p&gt;
&lt;h4 id=&quot;注意&quot;&gt;注意&lt;/h4&gt;
&lt;p&gt;如果要发送Cookie，Access-Control-Allow-Origin就不能设为星号，必须指定明确的、与请求网页一致的域名。&lt;br/&gt;同时，Cookie依然遵循同源政策，只有用服务器域名设置的Cookie才会上传，其他域名的Cookie并不会上传。&lt;br/&gt;且（跨源）原网页代码中的document.cookie也无法读取服务器域名下的Cookie。&lt;/p&gt;
&lt;p&gt;毕竟cookie是有path来保证封闭性的，如果可以随便读取不管从安全还是性能上都是一种隐患。&lt;/p&gt;
&lt;h3 id=&quot;多域名跨域&quot;&gt;多域名跨域&lt;/h3&gt;
&lt;p&gt;对于多域名跨域，方法比较多。&lt;/p&gt;
&lt;h4 id=&quot;access-control-allow-origin-允许任意域名跨域显然支持多域名不过从安全性和cookie的使用的角度来看并不推荐&quot;&gt;1、Access-Control-Allow-Origin：*&lt;br/&gt;允许任意域名跨域，显然支持多域名。不过从安全性和cookie的使用的角度来看并不推荐。&lt;/h4&gt;
&lt;h4 id=&quot;动态匹配域名&quot;&gt;2、动态匹配域名&lt;/h4&gt;
&lt;p&gt;这种实现方式比较多，原理就是声明允许的多域名配置，可以是数组或者是正则，根据当前请求的域名，来判断是否在适用返回内，在的话则设置Access-Control-Allow-Origin为当前域名。&lt;/p&gt;
&lt;p&gt;具体实现这里就不写了。&lt;/p&gt;
&lt;h3 id=&quot;结束语&quot;&gt;结束语&lt;/h3&gt;
&lt;h4 id=&quot;参考文章&quot;&gt;参考文章&lt;/h4&gt;
&lt;p&gt;&lt;a href=&quot;http://www.ruanyifeng.com/blog/2016/04/cors.html&quot; class=&quot;uri&quot;&gt;http://www.ruanyifeng.com/blog/2016/04/cors.html&lt;/a&gt;&lt;br/&gt;&lt;a href=&quot;https://fetch.spec.whatwg.org/#cors-protocol-and-credentials&quot; class=&quot;uri&quot;&gt;https://fetch.spec.whatwg.org/#cors-protocol-and-credentials&lt;/a&gt;&lt;br/&gt;&lt;a href=&quot;http://www.yunweipai.com/archives/9381.html&quot; class=&quot;uri&quot;&gt;http://www.yunweipai.com/archives/9381.html&lt;/a&gt;&lt;br/&gt;以上是在工作中偶然发现的几点疑惑，解决之后深究了下具体原理。希望能对其他同学有所帮助，抛砖引玉，一起努力。&lt;/p&gt;
</description>
<pubDate>Mon, 01 Jul 2019 15:12:00 +0000</pubDate>
<dc:creator>潇湘待雨</dc:creator>
<og:description>前言 对于跨域，随着w3c的CORS的出现，相比较于有些年头的jsonp，CORS以其简单安全，支持post的优势越来越收到大家的欢迎。具体如何CORS的原理和实现， '直接推荐阮老师的文章' ,十分</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/pqjwyn/p/11117458.html</dc:identifier>
</item>
<item>
<title>kubernetes client-go解析 - charlieroro</title>
<link>http://www.cnblogs.com/charlieroro/p/10330390.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/charlieroro/p/10330390.html</guid>
<description>&lt;pre&gt;
&lt;span&gt;注：本次使用的client-go版本为：&lt;/span&gt;&lt;strong&gt;client-go 11.0&lt;/strong&gt;&lt;span&gt;，主要参考CSDN上的&lt;/span&gt;&lt;a href=&quot;https://so.csdn.net/so/search/s.do?q=%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BAkubernetes%E4%B9%8Bclient-go&amp;amp;t=blog&amp;amp;u=weixin_42663840&quot; target=&quot;_blank&quot;&gt;深入浅出kubernetes之client-go&lt;/a&gt;&lt;span&gt;系列，建议看本文前先参考该文档。本文档为CSDN文档的深挖和补充。&lt;br/&gt;本文中的visio可以从&lt;a href=&quot;https://files.cnblogs.com/files/charlieroro/client-go.rar&quot; target=&quot;_blank&quot;&gt;这里&lt;/a&gt;获取&lt;/span&gt;
&lt;/pre&gt;
&lt;p&gt;下图为来自&lt;a href=&quot;https://github.com/kubernetes/sample-controller/blob/master/docs/images/client-go-controller-interaction.jpeg&quot; target=&quot;_blank&quot;&gt;官方&lt;/a&gt;的Client-go架构图&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1334952/201906/1334952-20190627145621377-2135908448.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;图1.&lt;/p&gt;
&lt;p&gt;下图也可以作为参考&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1334952/201906/1334952-20190619205327657-121618547.png&quot; alt=&quot;&quot; width=&quot;788&quot; height=&quot;350&quot;/&gt;&lt;/p&gt;
&lt;p&gt;图2.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Indexer&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Indexer提供了对底层存储的操作，给出了存储对象以及索引对象的框架。Indexer的接口定义如下，它继承了Store接口，Store中定义了对对象的增删改查等方法。&lt;/p&gt;
&lt;p&gt;Indexer保存了来自apiServer的资源，使用listWatch方式来维护资源的增量变化。通过这种方式可以减小对apiServer的访问，减轻apiServer端的压力&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;42&quot;&gt;
&lt;pre&gt;
&lt;span&gt;&lt;em&gt;// client-go/tools/cache/index.go&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;type Indexer &lt;span&gt;interface&lt;/span&gt;&lt;span&gt; {
    Store
    &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; Retrieve list of objects that match on the named indexing function&lt;/span&gt;
    Index(indexName &lt;span&gt;string&lt;/span&gt;, obj &lt;span&gt;interface&lt;/span&gt;{}) ([]&lt;span&gt;interface&lt;/span&gt;&lt;span&gt;{}, error)
    &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; IndexKeys returns the set of keys that match on the named indexing function.&lt;/span&gt;
    IndexKeys(indexName, indexKey &lt;span&gt;string&lt;/span&gt;) ([]&lt;span&gt;string&lt;/span&gt;&lt;span&gt;, error)
    &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; ListIndexFuncValues returns the list of generated values of an Index func&lt;/span&gt;
    ListIndexFuncValues(indexName &lt;span&gt;string&lt;/span&gt;) []&lt;span&gt;string&lt;/span&gt;
    &lt;span&gt;//&lt;/span&gt;&lt;span&gt; ByIndex lists object that match on the named indexing function with the exact key&lt;/span&gt;
    ByIndex(indexName, indexKey &lt;span&gt;string&lt;/span&gt;) ([]&lt;span&gt;interface&lt;/span&gt;&lt;span&gt;{}, error)
    &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; GetIndexer return the indexers&lt;/span&gt;
&lt;span&gt;    GetIndexers() Indexers

    &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; AddIndexers adds more indexers to this store.  If you call this after you already have data
    &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; in the store, the results are undefined.&lt;/span&gt;
&lt;span&gt;    AddIndexers(newIndexers Indexers) error
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;42&quot;&gt;
&lt;pre&gt;
&lt;em&gt;&lt;span&gt;// client-go/tools/cache/store.go&lt;/span&gt;&lt;/em&gt;&lt;br/&gt;type Store &lt;span&gt;interface&lt;/span&gt;&lt;span&gt; {
    Add(obj &lt;/span&gt;&lt;span&gt;interface&lt;/span&gt;&lt;span&gt;{}) error
    Update(obj &lt;/span&gt;&lt;span&gt;interface&lt;/span&gt;&lt;span&gt;{}) error
    Delete(obj &lt;/span&gt;&lt;span&gt;interface&lt;/span&gt;&lt;span&gt;{}) error
    List() []&lt;/span&gt;&lt;span&gt;interface&lt;/span&gt;&lt;span&gt;{}
    ListKeys() []&lt;/span&gt;&lt;span&gt;string&lt;/span&gt;&lt;span&gt;
    Get(obj &lt;/span&gt;&lt;span&gt;interface&lt;/span&gt;{}) (item &lt;span&gt;interface&lt;/span&gt;{}, exists &lt;span&gt;bool&lt;/span&gt;&lt;span&gt;, err error)
    GetByKey(key &lt;/span&gt;&lt;span&gt;string&lt;/span&gt;) (item &lt;span&gt;interface&lt;/span&gt;{}, exists &lt;span&gt;bool&lt;/span&gt;&lt;span&gt;, err error)

    &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; Replace will delete the contents of the store, using instead the
    &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; given list. Store takes ownership of the list, you should not reference
    &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; it after calling this function.&lt;/span&gt;
    Replace([]&lt;span&gt;interface&lt;/span&gt;{}, &lt;span&gt;string&lt;/span&gt;&lt;span&gt;) error
    Resync() error
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;cache实现了Indexer和Store接口，同时也实现了ThreadSafeStore接口(可以看到ThreadSafeStore基本包含了Indexer接口的所有方法)，但cache是包内私有的(首字母小写)，只能通过包内封装的函数进行调用。&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;35&quot;&gt;
&lt;pre&gt;
&lt;span&gt;&lt;em&gt;// client-go/tools/cache/store.go&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;type cache &lt;span&gt;struct&lt;/span&gt;&lt;span&gt; {
    &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; cacheStorage bears the burden of thread safety for the cache&lt;/span&gt;
&lt;span&gt;    cacheStorage ThreadSafeStore
    &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; keyFunc is used to make the key for objects stored in and retrieved from items, and
    &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; should be deterministic.&lt;/span&gt;
&lt;span&gt;    keyFunc KeyFunc
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;46&quot;&gt;
&lt;pre&gt;
&lt;em&gt;&lt;span&gt;// client-&lt;/span&gt;&lt;/em&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;go/tools/cache/thread_safe_store.go&lt;/span&gt;&lt;/em&gt;
type ThreadSafeStore &lt;/span&gt;&lt;span&gt;interface&lt;/span&gt;&lt;span&gt; {
    Add(key &lt;/span&gt;&lt;span&gt;string&lt;/span&gt;, obj &lt;span&gt;interface&lt;/span&gt;&lt;span&gt;{})
    Update(key &lt;/span&gt;&lt;span&gt;string&lt;/span&gt;, obj &lt;span&gt;interface&lt;/span&gt;&lt;span&gt;{})
    Delete(key &lt;/span&gt;&lt;span&gt;string&lt;/span&gt;&lt;span&gt;)
    Get(key &lt;/span&gt;&lt;span&gt;string&lt;/span&gt;) (item &lt;span&gt;interface&lt;/span&gt;{}, exists &lt;span&gt;bool&lt;/span&gt;&lt;span&gt;)
    List() []&lt;/span&gt;&lt;span&gt;interface&lt;/span&gt;&lt;span&gt;{}
    ListKeys() []&lt;/span&gt;&lt;span&gt;string&lt;/span&gt;&lt;span&gt;
    Replace(map[&lt;/span&gt;&lt;span&gt;string&lt;/span&gt;]&lt;span&gt;interface&lt;/span&gt;{}, &lt;span&gt;string&lt;/span&gt;&lt;span&gt;)
    Index(indexName &lt;/span&gt;&lt;span&gt;string&lt;/span&gt;, obj &lt;span&gt;interface&lt;/span&gt;{}) ([]&lt;span&gt;interface&lt;/span&gt;&lt;span&gt;{}, error)
    IndexKeys(indexName, indexKey &lt;/span&gt;&lt;span&gt;string&lt;/span&gt;) ([]&lt;span&gt;string&lt;/span&gt;&lt;span&gt;, error)
    ListIndexFuncValues(name &lt;/span&gt;&lt;span&gt;string&lt;/span&gt;) []&lt;span&gt;string&lt;/span&gt;&lt;span&gt;
    ByIndex(indexName, indexKey &lt;/span&gt;&lt;span&gt;string&lt;/span&gt;) ([]&lt;span&gt;interface&lt;/span&gt;&lt;span&gt;{}, error)
    GetIndexers() Indexers

    &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; AddIndexers adds more indexers to this store.  If you call this after you already have data
    &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; in the store, the results are undefined.&lt;/span&gt;
&lt;span&gt;    AddIndexers(newIndexers Indexers) error
    Resync() error
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;例如可以通过函数NewStore和NewIndexer初始化cache来返回一个Store或Indexer指针(cache实现了Store和Indexer接口)。NewStore和NewIndexer返回的Store和Indexer接口的数据载体为threadSafeMap，threadSafeMap通过NewThreadSafeStore函数进行初始化。&lt;/p&gt;
&lt;p&gt;&lt;em&gt;注：运行go语言接口中的方法即运行该方法的实现。以&lt;/em&gt;threadSafeMap为例，在运行cache.Add函数中的“c.cacheStorage.Add(key, obj)”时，实际是在运行”(&amp;amp;threadSafeMap{items:map[string]interface{}{}, indexers: indexers, indices:  indices}).&lt;em&gt;Add&lt;/em&gt;(key, obj)“&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;36&quot;&gt;
&lt;pre&gt;
&lt;em&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; client-go/tools/cache/store.go&lt;/span&gt;
func (c *cache) Add(obj &lt;span&gt;interface&lt;/span&gt;&lt;span&gt;{}) error {
    key, err :&lt;/span&gt;=&lt;span&gt; c.keyFunc(obj)
    &lt;/span&gt;&lt;span&gt;if&lt;/span&gt; err !=&lt;span&gt; nil {
        &lt;/span&gt;&lt;span&gt;return&lt;/span&gt;&lt;span&gt; KeyError{obj, err}
    }
  &lt;span&gt;&lt;strong&gt;  c.cacheStorage.Add(key, obj)
    &lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;return&lt;/span&gt;&lt;span&gt; nil
}&lt;/span&gt;&lt;/em&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;42&quot;&gt;
&lt;pre&gt;
&lt;span&gt;// &lt;em&gt;&lt;span&gt;client-go/tools/cache/store.go&lt;/span&gt;&lt;/em&gt;&lt;br/&gt;//&lt;/span&gt;&lt;span&gt; NewStore returns a Store implemented simply with a map and a lock.&lt;/span&gt;
&lt;span&gt;func NewStore(keyFunc KeyFunc) Store {
    &lt;/span&gt;&lt;span&gt;return&lt;/span&gt; &amp;amp;&lt;span&gt;cache{
        cacheStorage: &lt;span&gt;&lt;strong&gt;NewThreadSafeStore&lt;/strong&gt;&lt;/span&gt;(Indexers{}, Indices{}),
        keyFunc:      keyFunc,
    }
}

&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; NewIndexer returns an Indexer implemented simply with a map and a lock.&lt;/span&gt;
&lt;span&gt;func NewIndexer(keyFunc KeyFunc, indexers Indexers) Indexer {
    &lt;/span&gt;&lt;span&gt;return&lt;/span&gt; &amp;amp;&lt;span&gt;cache{
        cacheStorage: &lt;span&gt;&lt;strong&gt;NewThreadSafeStore&lt;/strong&gt;&lt;/span&gt;(indexers, Indices{}),
        keyFunc:      keyFunc,
    }
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;可以通过下图理解threadSafeMap中各种索引之间的关系&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1334952/201906/1334952-20190621164852496-1708305355.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;indexer实际的对象存储在threadSafeMap结构中&lt;/li&gt;
&lt;li&gt;indexers划分了不同的索引类型(indexName，如namespace)，并按照索引类型进行索引(indexFunc，如MetaNamespaceIndexFunc)，得出符合该对象的索引键(indexKey，如namespaces)，一个对象在一个索引类型中可能有多个索引键。&lt;/li&gt;
&lt;li&gt;indices按照索引类型保存了索引(index，如包含所有namespaces下面的obj)，进而可以按照索引键找出特定的对象键(keys，如某个namespace下面的对象键)，indices用于快速查找对象&lt;/li&gt;
&lt;li&gt;items按照对象键保存了实际的对象&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;默认的indexFunc如下，根据对象的namespace进行分类&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;39&quot;&gt;
&lt;pre&gt;
&lt;em&gt;&lt;span&gt;// client-go/tools/cache/index.go&lt;/span&gt;&lt;/em&gt;&lt;br/&gt;func MetaNamespaceIndexFunc(obj &lt;span&gt;interface&lt;/span&gt;{}) ([]&lt;span&gt;string&lt;/span&gt;&lt;span&gt;, error) {
    meta, err :&lt;/span&gt;=&lt;span&gt; meta.Accessor(obj)
    &lt;/span&gt;&lt;span&gt;if&lt;/span&gt; err !=&lt;span&gt; nil {
        &lt;/span&gt;&lt;span&gt;return&lt;/span&gt; []&lt;span&gt;string&lt;/span&gt;{&lt;span&gt;&quot;&quot;&lt;/span&gt;}, fmt.Errorf(&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;object has no meta: %v&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;, err)
    }
    &lt;/span&gt;&lt;span&gt;return&lt;/span&gt; []&lt;span&gt;string&lt;/span&gt;&lt;span&gt;{meta.GetNamespace()}, nil
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;cache结构中的keyFunc用于生成objectKey，下面是默认的keyFunc。&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;43&quot;&gt;
&lt;pre&gt;
&lt;span&gt;//client-go/tools/cache/thread_safe_store.go&lt;/span&gt;&lt;br/&gt;func MetaNamespaceKeyFunc(obj &lt;span&gt;interface&lt;/span&gt;{}) (&lt;span&gt;string&lt;/span&gt;&lt;span&gt;, error) {
    &lt;/span&gt;&lt;span&gt;if&lt;/span&gt; key, ok :=&lt;span&gt; obj.(ExplicitKey); ok {
        &lt;/span&gt;&lt;span&gt;return&lt;/span&gt; &lt;span&gt;string&lt;/span&gt;&lt;span&gt;(key), nil
    }
    meta, err :&lt;/span&gt;=&lt;span&gt; meta.Accessor(obj)
    &lt;/span&gt;&lt;span&gt;if&lt;/span&gt; err !=&lt;span&gt; nil {
        &lt;/span&gt;&lt;span&gt;return&lt;/span&gt; &lt;span&gt;&quot;&quot;&lt;/span&gt;, fmt.Errorf(&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;object has no meta: %v&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;, err)
    }
    &lt;/span&gt;&lt;span&gt;if&lt;/span&gt; len(meta.GetNamespace()) &amp;gt; &lt;span&gt;0&lt;/span&gt;&lt;span&gt; {
        &lt;/span&gt;&lt;span&gt;return&lt;/span&gt; meta.GetNamespace() + &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;/&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; +&lt;span&gt; meta.GetName(), nil
    }
    &lt;/span&gt;&lt;span&gt;return&lt;/span&gt;&lt;span&gt; meta.GetName(), nil
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt; DeltaFIFO&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;DeltaFIFO的源码注释写的比较清楚，它是一个生产者-消费者队列，生产者为Reflector，消费者为Pop()函数，从架构图中可以看出DeltaFIFO的数据来源为Reflector，通过Pop操作消费数据，将数据存储到localstore中。需要注意的是，Pop的单位是一个Deltas，而不是Delta。&lt;/p&gt;
&lt;p&gt;DeltaFIFO同时实现了Queue和Store接口。DeltaFIFO使用Deltas保存了对象状态的变更(Add/Delete/Update)信息(如Pod的删除添加等)，Deltas缓存了针对相同对象的多个状态变更信息。最老的状态变更信息为Newest()，最新的状态变更信息为Oldest()，使用中获取DeltaFIFO中对象的key以及获取DeltaFIFO都以最新状态为准。&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;35&quot;&gt;
&lt;pre&gt;
&lt;span&gt;&lt;em&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;client-go/tools/cache/delta_fifo.go&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;
type Delta &lt;span&gt;struct&lt;/span&gt;&lt;span&gt; {
    Type   DeltaType
    Object &lt;/span&gt;&lt;span&gt;interface&lt;/span&gt;&lt;span&gt;{}
}

&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; Deltas is a list of one or more 'Delta's to an individual object.
&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; The oldest delta is at index 0, the newest delta is the last one.&lt;/span&gt;
&lt;strong&gt;&lt;span&gt;type Deltas []Delta&lt;/span&gt;&lt;/strong&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;DeltaFIFO结构中比较难以理解的是knownObjects，它的结构如下。其接口中的方法ListKeys和GetByKey也是Store接口中的方法，因此knownObjects能够被赋值为实现了Store的类型指针；同样地，由于Indexer继承了Store方法，因此knownObjects能够被赋值为实现了Indexer的类型指针。&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;39&quot;&gt;
&lt;pre&gt;
&lt;span&gt;&lt;em&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;client-go/tools/cache/delta_fifo.go&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;
type DeltaFIFO &lt;span&gt;struct&lt;/span&gt;&lt;span&gt; {
    &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; lock/cond protects access to 'items' and 'queue'.&lt;/span&gt;
    &lt;span&gt;lock&lt;/span&gt;&lt;span&gt; sync.RWMutex
    cond sync.Cond

    &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; We depend on the property that items in the set are in
    &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; the queue and vice versa, and that all Deltas in this
    &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; map have at least one Delta.&lt;/span&gt;
&lt;strong&gt;&lt;span&gt;    items map[string&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;]Deltas&lt;/span&gt;&lt;/strong&gt;
    queue []&lt;/span&gt;&lt;span&gt;string&lt;/span&gt;

    &lt;span&gt;//&lt;/span&gt;&lt;span&gt; populated is true if the first batch of items inserted by Replace() has been populated
    &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; or Delete/Add/Update was called first.&lt;/span&gt;
    populated &lt;span&gt;bool&lt;/span&gt;
    &lt;span&gt;//&lt;/span&gt;&lt;span&gt; initialPopulationCount is the number of items inserted by the first call of Replace()&lt;/span&gt;
    initialPopulationCount &lt;span&gt;int&lt;/span&gt;

    &lt;span&gt;//&lt;/span&gt;&lt;span&gt; keyFunc is used to make the key used for queued item
    &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; insertion and retrieval, and should be deterministic.&lt;/span&gt;
&lt;span&gt;    keyFunc KeyFunc

    &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; knownObjects list keys that are &quot;known&quot;, for the
    &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; purpose of figuring out which items have been deleted
    &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; when Replace() or Delete() is called.&lt;/span&gt;
&lt;strong&gt;&lt;span&gt;    knownObjects KeyListerGetter

    &lt;/span&gt;&lt;/strong&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; Indication the queue is closed.
    &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; Used to indicate a queue is closed so a control loop can exit when a queue is empty.
    &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; Currently, not used to gate any of CRED operations.&lt;/span&gt;
    closed     &lt;span&gt;bool&lt;/span&gt;&lt;span&gt;
    closedLock sync.Mutex
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;37&quot;&gt;
&lt;pre&gt;
// A KeyListerGetter is anything that knows how to list its keys and look up by key.
type KeyListerGetter interface&lt;span&gt; {
    KeyLister
    KeyGetter
}

// A KeyLister is anything that knows how to list its keys.
type KeyLister interface&lt;span&gt; {
    ListKeys() []string&lt;span&gt;
}

// A KeyGetter is anything that knows how to get the value stored under a given key.
type KeyGetter interface&lt;span&gt; {
    GetByKey(key string) (interface{}, bool&lt;span&gt;, error)
}&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;在NewSharedIndexInformer(&lt;span&gt;&lt;em&gt;&lt;span&gt;client-go/tools/cache/shared_informer.go&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;)函数中使用下面进行初始化一个sharedIndexInformer，即使用函数DeletionHandlingMetaNamespaceKeyFunc初始化indexer，并在sharedIndexInformer.Run中将该indexer作为knownObjects入参，最终初始化为一个DeltaFIFO。&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;33&quot;&gt;
&lt;pre&gt;
NewIndexer(DeletionHandlingMetaNamespaceKeyFunc, indexers) &lt;span&gt;//&lt;/span&gt;&lt;span&gt;NewDeltaFIFO&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;33&quot;&gt;
&lt;pre&gt;
fifo := NewDeltaFIFO(MetaNamespaceKeyFunc, s.indexer) &lt;span&gt;//&lt;/span&gt;&lt;span&gt;sharedIndexInformer.Run&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;DeltaFIFO实现了Queue接口。可以看到Queue接口同时&lt;strong&gt;也&lt;/strong&gt;(Indexer继承了Store)继承了Store接口。&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;36&quot;&gt;
&lt;pre&gt;
&lt;span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;client-go/tools/cache/delta_fifo.go&lt;/span&gt;&lt;/span&gt;
type Queue &lt;span&gt;interface&lt;/span&gt;&lt;span&gt; {
    Store

    &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; Pop blocks until it has something to process.
    &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; It returns the object that was process and the result of processing.
    &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; The PopProcessFunc may return an ErrRequeue{...} to indicate the item
    &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; should be requeued before releasing the lock on the queue.&lt;/span&gt;
    Pop(PopProcessFunc) (&lt;span&gt;interface&lt;/span&gt;&lt;span&gt;{}, error)

    &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; AddIfNotPresent adds a value previously
    &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; returned by Pop back into the queue as long
    &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; as nothing else (presumably more recent)
    &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; has since been added.&lt;/span&gt;
    AddIfNotPresent(&lt;span&gt;interface&lt;/span&gt;&lt;span&gt;{}) error

    &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; HasSynced returns true if the first batch of items has been popped&lt;/span&gt;
    HasSynced() &lt;span&gt;bool&lt;/span&gt;

    &lt;span&gt;//&lt;/span&gt;&lt;span&gt; Close queue&lt;/span&gt;
&lt;span&gt;    Close()
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;knownObjects实际使用时为Indexer，它对应图2中的localStore，DeltaFIFO根据其保存的对象状态变更消息处理(增/删/改/同步)knownObjects中相应的对象。其中同步(Sync)操作对Detals中即将被删除的对象是没有意义的(参见willObjectBeDeletedLocked函数)。&lt;/p&gt;
&lt;p&gt;Replace(&lt;span&gt;&lt;em&gt;client-go/tools/cache/delta_fifo.go&lt;/em&gt;)&lt;/span&gt;函数中会对DeltaFIFO进行全量更新，包括3个步骤：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;Sync所有的输入对象；&lt;/li&gt;
&lt;li&gt;如果knownObjects为空，则删除原有DeltaFIFO中不存在于输入对象的对象；&lt;/li&gt;
&lt;li&gt;如果knownObjects非空，则删除knownObjects中不存在于输入对象的对象；&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;由于全量更新的最终目的是为了更新knownObjects中的对象，故第三步中直接使用knownObjects而非DeltaFIFO进行比对删除。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1334952/201906/1334952-20190626102106132-822156429.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;ListWatch&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Lister用于获取某个资源(如Pod)的全量，Watcher用于获取某个资源的增量变化。实际使用中Lister和Watcher都从apiServer获取资源信息，Lister一般用于首次获取某资源的全量信息，而Watcher用于持续获取该资源的增量变化信息。Lister和Watcher的接口定义如下，使用NewListWatchFromClient函数来初始化ListerWatcher&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;38&quot;&gt;
&lt;pre&gt;
&lt;span&gt;&lt;em&gt;&lt;span&gt;// c&lt;/span&gt;&lt;span&gt;lient-go/tools/cache/listwatch.go&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;
type Lister &lt;span&gt;interface&lt;/span&gt;&lt;span&gt; {
    &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; List should return a list type object; the Items field will be extracted, and the
    &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; ResourceVersion field will be used to start the watch in the right place.&lt;/span&gt;
&lt;span&gt;    List(options metav1.ListOptions) (runtime.Object, error)
}

&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; Watcher is any object that knows how to start a watch on a resource.&lt;/span&gt;
type Watcher &lt;span&gt;interface&lt;/span&gt;&lt;span&gt; {
    &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; Watch should begin a watch at the specified version.&lt;/span&gt;
&lt;span&gt;    Watch(options metav1.ListOptions) (watch.Interface, error)
}

&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; ListerWatcher is any object that knows how to perform an initial list and start a watch on a resource.&lt;/span&gt;
type ListerWatcher &lt;span&gt;interface&lt;/span&gt;&lt;span&gt; {
    Lister
    Watcher
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;在workqueue的例子中可以看到调用NewListWatchFromClient的地方，该例子会从clientset.CoreV1().RESTClient()获取&quot;pods&quot;的相关信息。&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;36&quot;&gt;
&lt;pre&gt;
&lt;em&gt;&lt;span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; client-go/examples/workqueue/main.go
&lt;/span&gt;&lt;/span&gt;&lt;/em&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; create the pod watcher&lt;/span&gt;
podListWatcher := cache.NewListWatchFromClient(&lt;span&gt;&lt;strong&gt;clientset.CoreV1().&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;&lt;strong&gt;RES&lt;/strong&gt;&lt;strong&gt;TClien&lt;/strong&gt;&lt;strong&gt;t()&lt;/strong&gt;&lt;/span&gt;, &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;pods&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;, v1.NamespaceDefault, fields.Everything())
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;除了可以从CoreV1版本的API group获取RESTClient信息外，还可以从下面Clientset结构体定义的API group中获取信息&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;35&quot;&gt;
&lt;pre&gt;
&lt;em&gt;&lt;span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; client-go/kubernetes/clientset.go&lt;/span&gt;&lt;/span&gt;&lt;/em&gt;
type Clientset &lt;span&gt;struct&lt;/span&gt;&lt;span&gt; {
    &lt;/span&gt;*&lt;span&gt;discovery.DiscoveryClient
    admissionregistrationV1beta1 &lt;/span&gt;*&lt;span&gt;admissionregistrationv1beta1.AdmissionregistrationV1beta1Client
    appsV1                       &lt;/span&gt;*&lt;span&gt;appsv1.AppsV1Client
    appsV1beta1                  &lt;/span&gt;*&lt;span&gt;appsv1beta1.AppsV1beta1Client
    appsV1beta2                  &lt;/span&gt;*&lt;span&gt;appsv1beta2.AppsV1beta2Client
    auditregistrationV1alpha1    &lt;/span&gt;*&lt;span&gt;auditregistrationv1alpha1.AuditregistrationV1alpha1Client
    authenticationV1             &lt;/span&gt;*&lt;span&gt;authenticationv1.AuthenticationV1Client
    authenticationV1beta1        &lt;/span&gt;*&lt;span&gt;authenticationv1beta1.AuthenticationV1beta1Client
    authorizationV1              &lt;/span&gt;*&lt;span&gt;authorizationv1.AuthorizationV1Client
    authorizationV1beta1         &lt;/span&gt;*&lt;span&gt;authorizationv1beta1.AuthorizationV1beta1Client
    autoscalingV1                &lt;/span&gt;*&lt;span&gt;autoscalingv1.AutoscalingV1Client
    autoscalingV2beta1           &lt;/span&gt;*&lt;span&gt;autoscalingv2beta1.AutoscalingV2beta1Client
    autoscalingV2beta2           &lt;/span&gt;*&lt;span&gt;autoscalingv2beta2.AutoscalingV2beta2Client
    batchV1                      &lt;/span&gt;*&lt;span&gt;batchv1.BatchV1Client
    batchV1beta1                 &lt;/span&gt;*&lt;span&gt;batchv1beta1.BatchV1beta1Client
    batchV2alpha1                &lt;/span&gt;*&lt;span&gt;batchv2alpha1.BatchV2alpha1Client
    certificatesV1beta1          &lt;/span&gt;*&lt;span&gt;certificatesv1beta1.CertificatesV1beta1Client
    coordinationV1beta1          &lt;/span&gt;*&lt;span&gt;coordinationv1beta1.CoordinationV1beta1Client
    coordinationV1               &lt;/span&gt;*&lt;span&gt;coordinationv1.CoordinationV1Client
    coreV1                       &lt;/span&gt;*&lt;span&gt;corev1.CoreV1Client
    eventsV1beta1                &lt;/span&gt;*&lt;span&gt;eventsv1beta1.EventsV1beta1Client
    extensionsV1beta1            &lt;/span&gt;*&lt;span&gt;extensionsv1beta1.ExtensionsV1beta1Client
    networkingV1                 &lt;/span&gt;*&lt;span&gt;networkingv1.NetworkingV1Client
    networkingV1beta1            &lt;/span&gt;*&lt;span&gt;networkingv1beta1.NetworkingV1beta1Client
    nodeV1alpha1                 &lt;/span&gt;*&lt;span&gt;nodev1alpha1.NodeV1alpha1Client
    nodeV1beta1                  &lt;/span&gt;*&lt;span&gt;nodev1beta1.NodeV1beta1Client
    policyV1beta1                &lt;/span&gt;*&lt;span&gt;policyv1beta1.PolicyV1beta1Client
    rbacV1                       &lt;/span&gt;*&lt;span&gt;rbacv1.RbacV1Client
    rbacV1beta1                  &lt;/span&gt;*&lt;span&gt;rbacv1beta1.RbacV1beta1Client
    rbacV1alpha1                 &lt;/span&gt;*&lt;span&gt;rbacv1alpha1.RbacV1alpha1Client
    schedulingV1alpha1           &lt;/span&gt;*&lt;span&gt;schedulingv1alpha1.SchedulingV1alpha1Client
    schedulingV1beta1            &lt;/span&gt;*&lt;span&gt;schedulingv1beta1.SchedulingV1beta1Client
    schedulingV1                 &lt;/span&gt;*&lt;span&gt;schedulingv1.SchedulingV1Client
    settingsV1alpha1             &lt;/span&gt;*&lt;span&gt;settingsv1alpha1.SettingsV1alpha1Client
    storageV1beta1               &lt;/span&gt;*&lt;span&gt;storagev1beta1.StorageV1beta1Client
    storageV1                    &lt;/span&gt;*&lt;span&gt;storagev1.StorageV1Client
    storageV1alpha1              &lt;/span&gt;*&lt;span&gt;storagev1alpha1.StorageV1alpha1Client
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;RESTClient()的返回值为Interface接口类型，该类型中包含如下对资源的操作方法，如Get()就封装了HTTP的Get方法。NewListWatchFromClient初始化ListWatch的时候使用了Get方法&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;34&quot;&gt;
&lt;pre&gt;
&lt;span&gt;//&lt;/span&gt;&lt;span&gt; client-go/rest/client.go&lt;/span&gt;
type Interface &lt;span&gt;interface&lt;/span&gt;&lt;span&gt; {
    GetRateLimiter() flowcontrol.RateLimiter
    Verb(verb &lt;/span&gt;&lt;span&gt;string&lt;/span&gt;) *&lt;span&gt;Request
    Post() &lt;/span&gt;*&lt;span&gt;Request
    Put() &lt;/span&gt;*&lt;span&gt;Request
    Patch(pt types.PatchType) &lt;/span&gt;*&lt;span&gt;Request
    Get() &lt;/span&gt;*&lt;span&gt;Request
    Delete() &lt;/span&gt;*&lt;span&gt;Request
    APIVersion() schema.GroupVersion
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Reflector&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;reflector使用listerWatcher获取资源，并将其保存在store中，此处的store就是DeltaFIFO，Reflector核心处理函数为ListAndWatch(&lt;em&gt;&lt;span&gt;client-go/tools/cache/reflector.go&lt;/span&gt;&lt;/em&gt;)&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;36&quot;&gt;
&lt;pre&gt;
&lt;span&gt;&lt;em&gt;&lt;span&gt;// client-go/tools/cache/reflector.go
&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;type Reflector &lt;span&gt;struct&lt;/span&gt;&lt;span&gt; {
    &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; name identifies this reflector. By default it will be a file:line if possible.&lt;/span&gt;
    name &lt;span&gt;string&lt;/span&gt;
    &lt;span&gt;//&lt;/span&gt;&lt;span&gt; metrics tracks basic metric information about the reflector&lt;/span&gt;
    metrics *&lt;span&gt;reflectorMetrics

    &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; The type of object we expect to place in the store.&lt;/span&gt;
&lt;span&gt;    expectedType reflect.Type
    &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; The destination to sync up with the watch source&lt;/span&gt;
&lt;strong&gt;&lt;span&gt;    store Store
    &lt;/span&gt;&lt;/strong&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; listerWatcher is used to perform lists and watches.&lt;/span&gt;
&lt;span&gt;&lt;strong&gt;    listerWatcher ListerWatcher
    &lt;/strong&gt;&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; period controls timing between one watch ending and
    &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; the beginning of the next one.&lt;/span&gt;
&lt;span&gt;    period       time.Duration
    resyncPeriod time.Duration
    ShouldResync func() &lt;/span&gt;&lt;span&gt;bool&lt;/span&gt;
    &lt;span&gt;//&lt;/span&gt;&lt;span&gt; clock allows tests to manipulate time&lt;/span&gt;
&lt;span&gt;    clock clock.Clock
    &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; lastSyncResourceVersion is the resource version token last
    &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; observed when doing a sync with the underlying store
    &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; it is thread safe, but not synchronized with the underlying store&lt;/span&gt;
    lastSyncResourceVersion &lt;span&gt;string&lt;/span&gt;
    &lt;span&gt;//&lt;/span&gt;&lt;span&gt; lastSyncResourceVersionMutex guards read/write access to lastSyncResourceVersion&lt;/span&gt;
&lt;span&gt;    lastSyncResourceVersionMutex sync.RWMutex
    &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; WatchListPageSize is the requested chunk size of initial and resync watch lists.
    &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; Defaults to pager.PageSize.&lt;/span&gt;
&lt;span&gt;    WatchListPageSize int64
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt; ListAndWatch在Reflector.Run函数中启动，并以Reflector.period周期性进行调度。ListAndWatch使用resourceVersion来获取资源的增量变化：在List时会获取资源的首个resourceVersion值，在Watch的时候会使用List获取的resourceVersion来获取资源的增量变化，然后将获取到的资源的resourceVersion保存起来，最后下一次Watch的基线。&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;40&quot;&gt;
&lt;pre&gt;
&lt;span&gt;&lt;em&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; client-go/tools/cache/reflector.go&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;
func (r *Reflector) Run(stopCh &amp;lt;-chan &lt;span&gt;struct&lt;/span&gt;&lt;span&gt;{}) {
    klog.V(&lt;/span&gt;&lt;span&gt;3&lt;/span&gt;).Infof(&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;Starting reflector %v (%s) from %s&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;, r.expectedType, r.resyncPeriod, r.name)
    wait.Until(func() {
        &lt;/span&gt;&lt;span&gt;if&lt;/span&gt; err := r.&lt;span&gt;&lt;strong&gt;ListAndWatch&lt;/strong&gt;&lt;/span&gt;(stopCh); err !=&lt;span&gt; nil {
            utilruntime.HandleError(err)
        }
    }, r.period, stopCh)
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;如可以使用如下命令获取Pod的resourceVersion&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;32&quot;&gt;
&lt;pre&gt;
# oc &lt;span&gt;get&lt;/span&gt; pod $PodName -oyaml|&lt;span&gt;grep resourceVersion:
resourceVersion: &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;4993804&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1334952/201906/1334952-20190626105745204-742982785.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt; &lt;strong&gt;Controller&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;controller的结构如下，其包含一个配置变量config，在注释中可以看到Config.Queue就是DeltaFIFO。controller定义了如何调度Reflector。&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;33&quot;&gt;
&lt;pre&gt;
&lt;em&gt;&lt;span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; client-go/tools/cache/controller.go&lt;/span&gt;&lt;/span&gt;&lt;/em&gt;
type controller &lt;span&gt;struct&lt;/span&gt;&lt;span&gt; {
    &lt;span&gt;&lt;strong&gt;config         Config&lt;/strong&gt;&lt;/span&gt;
    reflector      &lt;/span&gt;*&lt;span&gt;Reflector
    reflectorMutex sync.RWMutex
    clock          clock.Clock
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;43&quot;&gt;
&lt;pre&gt;
&lt;span&gt;&lt;em&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; client-go/tools/cache/controller.go&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;
type Config &lt;span&gt;struct&lt;/span&gt;&lt;span&gt; {
    &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; The queue for your objects - &lt;strong&gt;has to be a DeltaFIFO&lt;/strong&gt; due to
    &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; assumptions in the implementation. Your Process() function
    &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; should accept the output of this Queue's Pop() method.&lt;/span&gt;
&lt;span&gt;    Queue

    &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; Something that can list and watch your objects.&lt;/span&gt;
&lt;span&gt;    ListerWatcher

    &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; Something that can process your objects.&lt;/span&gt;
&lt;span&gt;    Process ProcessFunc

    &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; The type of your objects.&lt;/span&gt;
&lt;span&gt;    ObjectType runtime.Object

    &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; Reprocess everything at least this often.
    &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; Note that if it takes longer for you to clear the queue than this
    &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; period, you will end up processing items in the order determined
    &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; by FIFO.Replace(). Currently, this is random. If this is a
    &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; problem, we can change that replacement policy to append new
    &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; things to the end of the queue instead of replacing the entire
    &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; queue.&lt;/span&gt;
&lt;span&gt;    FullResyncPeriod time.Duration

    &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; ShouldResync, if specified, is invoked when the controller's reflector determines the next
    &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; periodic sync should occur. If this returns true, it means the reflector should proceed with
    &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; the resync.&lt;/span&gt;
&lt;span&gt;    ShouldResync ShouldResyncFunc

    &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; If true, when Process() returns an error, re-enqueue the object.
    &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; TODO: add interface to let you inject a delay/backoff or drop
    &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;       the object completely if desired. Pass the object in
    &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;       question to this interface as a parameter.&lt;/span&gt;
    RetryOnError &lt;span&gt;bool&lt;/span&gt;&lt;span&gt;
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;controller的框架比较简单它使用wg.StartWithChannel启动Reflector.Run，相当于启动了一个DeltaFIFO的生产者(&lt;em&gt;wg.StartWithChannel(stopCh, r.Run)表示可以将r.Run放在独立的协程运行，并可以使用stopCh来停止r.Run&lt;/em&gt;)；使用wait.Until来启动一个消费者(&lt;em&gt;wait.Until(c.processLoop, time.Second, stopCh)表示每秒会触发一次&lt;/em&gt;c.processLoop，但如果&lt;em&gt;c.processLoop在1秒之内没有结束，则运行&lt;/em&gt;c.processLoop继续运行，不会结束其运行状态)&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;42&quot;&gt;
&lt;pre&gt;
&lt;em&gt;&lt;span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; client-go/tools/cache/controller.go&lt;/span&gt;&lt;/span&gt;&lt;/em&gt;
func (c *controller) Run(stopCh &amp;lt;-chan &lt;span&gt;struct&lt;/span&gt;&lt;span&gt;{}) {
    defer utilruntime.HandleCrash()
    go func() {
        &lt;/span&gt;&amp;lt;-&lt;span&gt;stopCh
        c.config.Queue.Close()
    }()
    r :&lt;/span&gt;=&lt;span&gt; NewReflector(
        c.config.ListerWatcher,
        c.config.ObjectType,
        c.config.Queue,
        c.config.FullResyncPeriod,
    )
    r.ShouldResync &lt;/span&gt;=&lt;span&gt; c.config.ShouldResync
    r.clock &lt;/span&gt;=&lt;span&gt; c.clock

    c.reflectorMutex.Lock()
    c.reflector &lt;/span&gt;=&lt;span&gt; r
    c.reflectorMutex.Unlock()

    &lt;/span&gt;&lt;span&gt;var&lt;/span&gt;&lt;span&gt; wg wait.Group
    defer wg.Wait()

&lt;strong&gt;&lt;span&gt;    wg.StartWithChannel(stopCh, r.Run)&lt;/span&gt;

&lt;span&gt;    wait.Until(c.processLoop, time.Second, stopCh)&lt;/span&gt;&lt;/strong&gt;
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;processLoop的框架也很简单，它运行了DeltaFIFO.Pop函数，用于消费DeltaFIFO中的对象，并在DeltaFIFO.Pop运行失败后可能重新处理该对象(AddIfNotPresent)&lt;/p&gt;
&lt;p&gt;&lt;em&gt;注：c.config.RetryOnError在目前版本中初始化为False&lt;/em&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;36&quot;&gt;
&lt;pre&gt;
&lt;span&gt;//&lt;/span&gt;&lt;span&gt; client-go/tools/cache/controller.go&lt;/span&gt;
func (c *&lt;span&gt;controller) processLoop() {
    &lt;/span&gt;&lt;span&gt;for&lt;/span&gt;&lt;span&gt; {
     &lt;span&gt;&lt;strong&gt;   obj, err :&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;strong&gt;= c.config.Queue.Pop(PopProcessFunc(c.config.Process))
        &lt;/strong&gt;&lt;/span&gt;&lt;span&gt;if&lt;/span&gt; err !=&lt;span&gt; nil {
            &lt;/span&gt;&lt;span&gt;if&lt;/span&gt; err ==&lt;span&gt; FIFOClosedError {
                &lt;/span&gt;&lt;span&gt;return&lt;/span&gt;&lt;span&gt;
            }
            &lt;/span&gt;&lt;span&gt;if&lt;/span&gt;&lt;span&gt; c.config.RetryOnError {
                &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; This is the safe way to re-enqueue.&lt;/span&gt;
&lt;span&gt;&lt;strong&gt;&lt;span&gt;                c.config.Queue.AddIfNotPresent(obj)&lt;/span&gt;&lt;/strong&gt;
            }
        }
    }
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;43&quot;&gt;
&lt;pre&gt;
&lt;em&gt;//client-go/tools/cache/shared_informer.go
func (s *sharedIndexInformer) Run(stopCh &amp;lt;-chan struct&lt;span&gt;{}) {
    defer utilruntime.HandleCrash()

    fifo :=&lt;span&gt; NewDeltaFIFO(MetaNamespaceKeyFunc, s.indexer)

    cfg := &amp;amp;&lt;span&gt;Config{
        Queue:            fifo,
        ListerWatcher:    s.listerWatcher,
        ObjectType:       s.objectType,
        FullResyncPeriod: s.resyncCheckPeriod,
 &lt;strong&gt;       RetryOnError:     &lt;/strong&gt;&lt;strong&gt;false&lt;/strong&gt;&lt;span&gt;&lt;strong&gt;,&lt;/strong&gt;
        ShouldResync:     s.processor.shouldResync,

        Process: s.HandleDeltas,
    }&lt;br/&gt;...&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/em&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;em&gt;&lt;span&gt; &lt;/span&gt;&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;ShareInformer&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;下图为SharedInformer的运行图。可以看出SharedInformer启动了controller，reflector，并将其与Indexer结合起来。&lt;/p&gt;
&lt;p&gt;&lt;em&gt;注：不同颜色表示不同的chan，相同颜色表示在同一个chan中的处理&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1334952/201906/1334952-20190627111643378-1818944456.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;SharedInformer.Run启动了两个chan，s.c.Run为controller的入口，s.c.Run函数中会Pop DeltaFIFO中的元素，并根据DeltaFIFO的元素的类型(Sync/Added/Updated/Deleted)进两类处理，一类会使用indexer.Update,indexer,Add,indexer.Delete对保存的在Store中的数据进行处理；另一类会根据DeltaFIFO的元素的类型将其封装为sharedInformer内部类型updateNotification，addNotification，deleteNotification，传递给s.processor.Listeners.addCh，后续给注册的pl.handler处理。&lt;/p&gt;
&lt;p&gt;s.processor.run主要用于处理注册的handler，processorListener.run函数接受processorListener.nextCh中的值，将其作为参数传递给handler进行处理。而processorListener.pop负责将processorListener.addCh中的元素缓存到p.pendingNotifications，并读取p.pendingNotifications中的元素，将其传递到processorListener.nextCh。即processorListener.pop负责管理数据，processorListener.run负责使用processorListener.pop管理的数据进行处理。&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;34&quot;&gt;
&lt;pre&gt;
&lt;span&gt;&lt;em&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; client-go/tools/cache/controller.go&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;
type ResourceEventHandler &lt;span&gt;interface&lt;/span&gt;&lt;span&gt; {
    OnAdd(obj &lt;/span&gt;&lt;span&gt;interface&lt;/span&gt;&lt;span&gt;{})
    OnUpdate(oldObj, newObj &lt;/span&gt;&lt;span&gt;interface&lt;/span&gt;&lt;span&gt;{})
    OnDelete(obj &lt;/span&gt;&lt;span&gt;interface&lt;/span&gt;&lt;span&gt;{})
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt; sharedIndexInformer有3个状态：启动前，启动后，停止后，由started, stopped两个bool值表示。&lt;/p&gt;
&lt;p&gt;stopped=true表示inforer不再运作且不能添加新的handler(因为即使添加了也不会运行)&lt;/p&gt;
&lt;p&gt;informer启动前和停止后允许添加新的indexer(sharedIndexInformer.AddIndexers)，但不能在informer运行时添加，因为此时需要通过watchlist以及handler等一系列处理来操作sharedIndexInformer.inxder。如果允许同时使用sharedIndexInformer.AddIndexers，可能会造成数据不一致。&lt;/p&gt;
&lt;p&gt;还有一个状态sharedProcessor.listenersStarted，用于表示是否所有的s.processor.Listeners都已经启动，如果已经启动，则在添加新的processorListener时，需要运行新添加的processorListener，否则仅仅添加即可(添加后同样会被sharedProcessor.run调度)&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;36&quot;&gt;
&lt;pre&gt;
&lt;span&gt;&lt;em&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; client-go/tools/cache/shared_informer.go&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;
type sharedIndexInformer &lt;span&gt;struct&lt;/span&gt;&lt;span&gt; {
    indexer    Indexer
    controller Controller

    processor             &lt;/span&gt;*&lt;span&gt;sharedProcessor
    cacheMutationDetector CacheMutationDetector

    &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; This block is tracked to handle late initialization of the controller&lt;/span&gt;
&lt;span&gt;    listerWatcher ListerWatcher
    objectType    runtime.Object

    &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; resyncCheckPeriod is how often we want the reflector's resync timer to fire so it can call
    &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; shouldResync to check if any of our listeners need a resync.&lt;/span&gt;
&lt;span&gt;    resyncCheckPeriod time.Duration
    &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; defaultEventHandlerResyncPeriod is the default resync period for any handlers added via
    &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; AddEventHandler (i.e. they don't specify one and just want to use the shared informer's default
    &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; value).&lt;/span&gt;
&lt;span&gt;    defaultEventHandlerResyncPeriod time.Duration
    &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; clock allows for testability&lt;/span&gt;
&lt;span&gt;    clock clock.Clock

 &lt;span&gt;&lt;strong&gt;   started, stopped &lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;strong&gt;bool&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;
    startedLock      sync.Mutex

    &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; blockDeltas gives a way to stop all event distribution so that a late event handler
    &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; can safely join the shared informer.&lt;/span&gt;
&lt;span&gt;    blockDeltas sync.Mutex
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;SharedInformerFactory&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;sharedInformerFactory接口的内容如下，它按照group和version对informer进行了分类。&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;36&quot;&gt;
&lt;pre&gt;
&lt;em&gt;&lt;span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; client-go/informers&lt;/span&gt;&lt;span&gt;/&lt;/span&gt;&lt;span&gt;factory.go&lt;/span&gt;&lt;/span&gt;&lt;/em&gt;
type SharedInformerFactory &lt;span&gt;interface&lt;/span&gt;&lt;span&gt; {
    internalinterfaces.SharedInformerFactory
    ForResource(resource schema.GroupVersionResource) (GenericInformer, error)
    WaitForCacheSync(stopCh &lt;/span&gt;&amp;lt;-chan &lt;span&gt;struct&lt;/span&gt;{}) map[reflect.Type]&lt;span&gt;bool&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;

    Admissionregistration() admissionregistration.Interface
    Apps() apps.Interface
    Auditregistration() auditregistration.Interface
    Autoscaling() autoscaling.Interface
    Batch() batch.Interface
    Certificates() certificates.Interface
    Coordination() coordination.Interface
    Core() core.Interface
    Events() events.Interface
    Extensions() extensions.Interface
    Networking() networking.Interface
    Node() node.Interface
    Policy() policy.Interface
    Rbac() rbac.Interface
    Scheduling() scheduling.Interface
    Settings() settings.Interface
    Storage() storage.Interface&lt;/strong&gt;&lt;/span&gt;
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;注：&lt;em&gt;下图来自&lt;a href=&quot;https://blog.csdn.net/weixin_42663840/article/details/81980022&quot;&gt;https://blog.csdn.net/weixin_42663840/article/details/81980022&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1334952/201906/1334952-20190627172151572-1714649693.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;sharedInformerFactory负责在不同的chan中启动不同的informer(或shared_informer)&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;35&quot;&gt;
&lt;pre&gt;
&lt;span&gt;&lt;em&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; client-go/informers/factory.go&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;
func (f *sharedInformerFactory) Start(stopCh &amp;lt;-chan &lt;span&gt;struct&lt;/span&gt;&lt;span&gt;{}) {
    f.&lt;/span&gt;&lt;span&gt;lock&lt;/span&gt;&lt;span&gt;.Lock()
    defer f.&lt;/span&gt;&lt;span&gt;lock&lt;/span&gt;&lt;span&gt;.Unlock()

    &lt;/span&gt;&lt;span&gt;for&lt;/span&gt; informerType, informer :=&lt;span&gt; range f.informers {
        &lt;/span&gt;&lt;span&gt;if&lt;/span&gt; !&lt;span&gt;f.startedInformers[informerType] {
            go informer.Run(stopCh)
            f.startedInformers[informerType] &lt;/span&gt;= &lt;span&gt;true&lt;/span&gt;&lt;span&gt;
        }
    }
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;那sharedInformerFactory启动的informer又是怎么注册到sharedInformerFactory.informers中的呢？informer的注册函数统一为InformerFor，代码如下，所有类型的informer都会调用该函数注册到sharedInformerFactory&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;41&quot;&gt;
&lt;pre&gt;
&lt;span&gt;&lt;span&gt;&lt;em&gt;// client-go/informers/factory.go&lt;/em&gt;&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;
&lt;pre&gt;
func (f *&lt;span&gt;sharedInformerFactory) InformerFor(obj runtime.Object, newFunc internalinterfaces.NewInformerFunc) cache.SharedIndexInformer {
    f.&lt;/span&gt;&lt;span&gt;lock&lt;/span&gt;&lt;span&gt;.Lock()
    defer f.&lt;/span&gt;&lt;span&gt;lock&lt;/span&gt;&lt;span&gt;.Unlock()

    informerType :&lt;/span&gt;=&lt;span&gt; reflect.TypeOf(obj)
    informer, exists :&lt;/span&gt;=&lt;span&gt; f.informers[informerType]
    &lt;/span&gt;&lt;span&gt;if&lt;/span&gt;&lt;span&gt; exists {
        &lt;/span&gt;&lt;span&gt;return&lt;/span&gt;&lt;span&gt; informer
    }

    resyncPeriod, exists :&lt;/span&gt;=&lt;span&gt; f.customResync[informerType]
    &lt;/span&gt;&lt;span&gt;if&lt;/span&gt; !&lt;span&gt;exists {
        resyncPeriod &lt;/span&gt;=&lt;span&gt; f.defaultResync
    }

    informer &lt;/span&gt;=&lt;span&gt; newFunc(f.client, resyncPeriod)
    f.informers[informerType] &lt;/span&gt;=&lt;span&gt; informer

    &lt;/span&gt;&lt;span&gt;return&lt;/span&gt;&lt;span&gt; informer
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;下面以(Core，v1，podInformer)为例结合client-go中提供的代码进行讲解。代码如下，在调用informers.Core().V1().Pods().Informer()的时候会同时调用informers.InformerFor注册到sharedInformerFactory，后续直接调用informers.Start启动注册的informer。&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;41&quot;&gt;
&lt;pre&gt;
&lt;span&gt;//&lt;/span&gt;&lt;span&gt; client-go/examples/fake-client/main_test.go&lt;/span&gt;
func TestFakeClient(t *&lt;span&gt;testing.T) {
    ctx, cancel :&lt;/span&gt;=&lt;span&gt; context.WithCancel(context.Background())
    defer cancel()

    &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; Create the fake client.&lt;/span&gt;
    client :=&lt;span&gt; fake.NewSimpleClientset()

    &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; We will create an informer that writes added pods to a channel.&lt;/span&gt;
    pods := make(chan *v1.Pod, &lt;span&gt;1&lt;/span&gt;&lt;span&gt;)
    informers :&lt;/span&gt;= informers.NewSharedInformerFactory(client, &lt;span&gt;0&lt;/span&gt;&lt;span&gt;)    //创建一个新的shareInformerFactory
    podInformer :&lt;/span&gt;=&lt;span&gt; informers.Core().V1().Pods().Informer()        //创建一个podInformer，并调用InformerFor函数进行注册
    podInformer.AddEventHandler(&lt;/span&gt;&amp;amp;&lt;span&gt;cache.ResourceEventHandlerFuncs{
        AddFunc: func(obj &lt;/span&gt;&lt;span&gt;interface&lt;/span&gt;&lt;span&gt;{}) {
            pod :&lt;/span&gt;= obj.(*&lt;span&gt;v1.Pod)
            t.Logf(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;pod added: %s/%s&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;, pod.Namespace, pod.Name)
            pods &lt;/span&gt;&amp;lt;-&lt;span&gt; pod
        },
    })

    &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; Make sure informers are running.&lt;/span&gt;
    informers.Start(ctx.Done())                                   //启动所有的informer&lt;br/&gt;...
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;workqueue&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt; indexer用于保存apiserver的资源信息，而workqueue用于保存informer中的handler处理之后的数据。workqueue的接口定义如下： &lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;34&quot;&gt;
&lt;pre&gt;
&lt;span&gt;&lt;em&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; client-go/util/workqueue/queue.go&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;
type Interface &lt;span&gt;interface&lt;/span&gt;&lt;span&gt; {
    Add(item &lt;/span&gt;&lt;span&gt;interface&lt;/span&gt;&lt;span&gt;{})
    Len() &lt;/span&gt;&lt;span&gt;int&lt;/span&gt;&lt;span&gt;
    Get() (item &lt;/span&gt;&lt;span&gt;interface&lt;/span&gt;{}, shutdown &lt;span&gt;bool&lt;/span&gt;&lt;span&gt;)
    Done(item &lt;/span&gt;&lt;span&gt;interface&lt;/span&gt;&lt;span&gt;{})
    ShutDown()
    ShuttingDown() &lt;/span&gt;&lt;span&gt;bool&lt;/span&gt;&lt;span&gt;
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1334952/201906/1334952-20190629094933929-1831494800.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;参见上图可以看到真正处理的元素来自queue，dirty和queue中的元素可能不一致，不一致点来自于当Get一个元素后且Done执行前，此时Get操作会删除dirty中的该元素，如果此时发生了Add正在处理的元素的操作，由于此时dirty中没有该元素且processing中存在该元素，会发生dirty中的元素大于queue中元素的情况。但对某一元素的不一致会在Done完成后消除，即Done函数中会判断该元素是否在dirty中，如果存在则会将该元素append到queue中。总之，dirty中的数据都会被append到queue中，后续queue中的数据会insert到processing中进行处理()&lt;/p&gt;
&lt;p&gt;dType实现了Interface接口。包含下面几个变量：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;queue：使用数组顺序存储了待处理的元素&lt;/li&gt;
&lt;li&gt;dirty：使用哈希表存储了需要处理的元素，它包含了queue中的所有元素，用于快速查找元素，dirty中可能包含queue中不存在的元素&lt;/li&gt;
&lt;li&gt;processing：使用哈希表保存了正在处理的元素，它不包含queue中的元素，但可能包含dirty中的元素&lt;/li&gt;
&lt;/ul&gt;&lt;div class=&quot;cnblogs_code&quot; readability=&quot;38&quot;&gt;
&lt;pre&gt;
&lt;em&gt;&lt;span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; client-go/util/workqueue/queue.go
&lt;/span&gt;&lt;/span&gt;&lt;/em&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; Type is a work queue (see the package comment).&lt;/span&gt;
type Type &lt;span&gt;struct&lt;/span&gt;&lt;span&gt; {
    &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; queue defines the order in which we will work on items. Every
    &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; element of queue should be in the dirty set and not in the
    &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; processing set.&lt;/span&gt;
&lt;span&gt;&lt;strong&gt;    queue []t

    &lt;/strong&gt;&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; dirty defines all of the items that need to be processed.&lt;/span&gt;
   &lt;strong&gt;&lt;span&gt; dirty set&lt;/span&gt;&lt;/strong&gt;

    &lt;span&gt;//&lt;/span&gt;&lt;span&gt; Things that are currently being processed are in the processing set.
    &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; These things may be simultaneously in the dirty set. When we finish
    &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; processing something and remove it from this set, we'll check if
    &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; it's in the dirty set, and if so, add it to the queue.&lt;/span&gt;
&lt;strong&gt;&lt;span&gt;    processing set&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;

    cond &lt;/span&gt;*&lt;span&gt;sync.Cond

    shuttingDown &lt;/span&gt;&lt;span&gt;bool&lt;/span&gt;&lt;span&gt;

    metrics queueMetrics

    unfinishedWorkUpdatePeriod time.Duration
    clock                      clock.Clock
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt; workqueue的使用例子可以参见client-go/util/workqueue/queue_test.go&lt;a href=&quot;http://client-go/util/workqueue/&quot;&gt;&lt;br/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;延时队列&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;延时队列接口继承了queue的Interface接口，仅新增了一个AddAfter方法，它用于在duration时间之后将元素添加到queue中。&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;35&quot;&gt;
&lt;pre&gt;
&lt;em&gt;&lt;span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; client-go/util/workqueue/delaying_queue.go&lt;/span&gt;&lt;/span&gt;&lt;/em&gt;
type DelayingInterface &lt;span&gt;interface&lt;/span&gt;&lt;span&gt; {
    Interface
    &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; AddAfter adds an item to the workqueue after the indicated duration has passed&lt;/span&gt;
    AddAfter(item &lt;span&gt;interface&lt;/span&gt;&lt;span&gt;{}, duration time.Duration)
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;delayingType实现了DelayingInterface接口使用waitingForAddCh来传递需要添加到queue的元素，&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;35&quot;&gt;
&lt;pre&gt;
&lt;em&gt;&lt;span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; client-go/util/workqueue/delaying_queue.go&lt;/span&gt;&lt;/span&gt;&lt;/em&gt;
type delayingType &lt;span&gt;struct&lt;/span&gt;&lt;span&gt; {
    Interface

    &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; clock tracks time for delayed firing&lt;/span&gt;
&lt;span&gt;    clock clock.Clock

    &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; stopCh lets us signal a shutdown to the waiting loop&lt;/span&gt;
    stopCh chan &lt;span&gt;struct&lt;/span&gt;&lt;span&gt;{}
    &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; stopOnce guarantees we only signal shutdown a single time&lt;/span&gt;
&lt;span&gt;    stopOnce sync.Once

    &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; heartbeat ensures we wait no more than maxWait before firing&lt;/span&gt;
&lt;span&gt;    heartbeat clock.Ticker

    &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; waitingForAddCh is a buffered channel that feeds waitingForAdd&lt;/span&gt;
    &lt;span&gt;&lt;strong&gt;waitingForAddCh chan *waitFor

    &lt;/strong&gt;&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; metrics counts the number of retries&lt;/span&gt;
&lt;span&gt;    metrics           retryMetrics
    deprecatedMetrics retryMetrics
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;delayingType.waitingForAddCh中的元素如果没有超过延时时间会添加到waitForPriorityQueue中，否则直接加入queue中。&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;32&quot;&gt;
&lt;pre&gt;
&lt;span&gt;&lt;em&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; client-go/util/workqueue/delaying_queue.go&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;
type waitForPriorityQueue []*waitFor
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;延时队列实现逻辑比较简单，需要注意的是waitingForQueue是以heap方式实现的队列，队列的pop和push等操作使用的是heap.pop和heap.push&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1334952/201906/1334952-20190630230640524-1185949639.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;限速队列&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;限速队列实现了3个接口，When用于返回元素的重试时间，Forget用于清除元素的重试记录，NumRequeues返回元素的重试次数&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;36&quot;&gt;
&lt;pre&gt;
&lt;span&gt;&lt;em&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;client-go/util/workqueue/default_rate_limiter.go&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;
type RateLimiter &lt;span&gt;interface&lt;/span&gt;&lt;span&gt; {
    &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; When gets an item and gets to decide how long that item should wait&lt;/span&gt;
    When(item &lt;span&gt;interface&lt;/span&gt;&lt;span&gt;{}) time.Duration
    &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; Forget indicates that an item is finished being retried.  Doesn't matter whether its for perm failing
    &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; or for success, we'll stop tracking it&lt;/span&gt;
    Forget(item &lt;span&gt;interface&lt;/span&gt;&lt;span&gt;{})
    &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; NumRequeues returns back how many failures the item has had&lt;/span&gt;
    NumRequeues(item &lt;span&gt;interface&lt;/span&gt;{}) &lt;span&gt;int&lt;/span&gt;&lt;span&gt;
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;ItemExponentialFailureRateLimiter对使用指数退避的方式进行失败重试，当failures增加时，下次重试的时间就变为了&lt;em&gt;baseDelay.Nanoseconds()) * math.Pow(2, float64(exp)&lt;/em&gt;，maxDelay用于限制重试时间的最大值，当计算的重试时间超过maxDelay时则采用maxDelay&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;34&quot;&gt;
&lt;pre&gt;
&lt;em&gt;&lt;span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; client-go/util/workqueue/default_rate_limiters.go&lt;/span&gt;&lt;/span&gt;&lt;/em&gt;
type ItemExponentialFailureRateLimiter &lt;span&gt;struct&lt;/span&gt;&lt;span&gt; {
    failuresLock sync.Mutex
    &lt;span&gt;&lt;strong&gt;failures&lt;/strong&gt;&lt;/span&gt;     map[&lt;/span&gt;&lt;span&gt;interface&lt;/span&gt;{}]&lt;span&gt;int&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;

    baseDelay&lt;/strong&gt; &lt;/span&gt;time.Duration
    &lt;span&gt;&lt;strong&gt;maxDelay &lt;/strong&gt; &lt;/span&gt;time.Duration
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;ItemFastSlowRateLimiter针对失败次数采用不同的重试时间。当重试次数小于maxFastAttempts时，重试时间为fastDelay，否则我为slowDelay。&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;34&quot;&gt;
&lt;pre&gt;
&lt;span&gt;&lt;em&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; client-go/util/workqueue/default_rate_limiters.go&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;
type ItemFastSlowRateLimiter &lt;span&gt;struct&lt;/span&gt;&lt;span&gt; {
    failuresLock sync.Mutex
    failures     map[&lt;/span&gt;&lt;span&gt;interface&lt;/span&gt;{}]&lt;span&gt;int&lt;/span&gt;&lt;span&gt;&lt;strong&gt;

    maxFastAttempts&lt;/strong&gt; &lt;/span&gt;&lt;span&gt;int&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;
    fastDelay      &lt;/strong&gt; &lt;/span&gt;time.Duration
    &lt;strong&gt;&lt;span&gt;slowDelay      &lt;/span&gt; &lt;/strong&gt;time.Duration
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;MaxOfRateLimiter为一个限速队列列表，它的实现中返回列表中重试时间最长的限速队列的值。&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;33&quot;&gt;
&lt;pre&gt;
&lt;em&gt;&lt;span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; client-go/util/workqueue/default_rate_limiters.go&lt;/span&gt;&lt;/span&gt;&lt;/em&gt;
type MaxOfRateLimiter &lt;span&gt;struct&lt;/span&gt;&lt;span&gt; {
    limiters []RateLimiter
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;34&quot;&gt;
&lt;pre&gt;
func (r *MaxOfRateLimiter) When(item &lt;span&gt;interface&lt;/span&gt;&lt;span&gt;{}) time.Duration {
    ret :&lt;/span&gt;= time.Duration(&lt;span&gt;0&lt;/span&gt;&lt;span&gt;)
    &lt;/span&gt;&lt;span&gt;for&lt;/span&gt; _, limiter :=&lt;span&gt; range r.limiters {
        curr :&lt;/span&gt;=&lt;span&gt; limiter.When(item)
        &lt;/span&gt;&lt;span&gt;if&lt;/span&gt; curr &amp;gt;&lt;span&gt; ret {
            ret &lt;/span&gt;=&lt;span&gt; curr
        }
    }

    &lt;/span&gt;&lt;span&gt;return&lt;/span&gt;&lt;span&gt; ret
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;BucketRateLimiter&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;使用令牌桶实现一个固定速率的限速器&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;33&quot;&gt;
&lt;pre&gt;
&lt;span&gt;&lt;em&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; client-go/util/workqueue/default_rate_limiters.go&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;
type BucketRateLimiter &lt;span&gt;struct&lt;/span&gt;&lt;span&gt; {
    &lt;/span&gt;*&lt;span&gt;rate.Limiter
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;限速队列的调用&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;所有的限速队列实际上就是根据不同的需求，最终提供一个延时时间，在延时时间到后通过AddAfter函数将元素添加添加到队列中。在queue.go中给出了workqueue的基本框架，delaying_queue.go扩展了workqueue的功能，提供了限速的功能，而default_rate_limiters.go提供了多种限速队列，用于给delaying_queue.go中的AddAfter提供延时参数，最后rate_limiting_queue.go给出了使用使用限速队列的入口。&lt;/p&gt;
&lt;p&gt;RateLimitingInterface为限速队列入口，AddRateLimited&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;37&quot;&gt;
&lt;pre&gt;
&lt;span&gt;//&lt;/span&gt;&lt;span&gt; client-g0/util/workqueue/rate_limiting_queue.go&lt;/span&gt;
type RateLimitingInterface &lt;span&gt;interface&lt;/span&gt;&lt;span&gt; {
    DelayingInterface

    &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; AddRateLimited adds an item to the workqueue after the rate limiter says it's ok&lt;/span&gt;
    AddRateLimited(item &lt;span&gt;interface&lt;/span&gt;&lt;span&gt;{})

    &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; Forget indicates that an item is finished being retried.  Doesn't matter whether it's for perm failing
    &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; or for success, we'll stop the rate limiter from tracking it.  This only clears the `rateLimiter`, you
    &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; still have to call `Done` on the queue.&lt;/span&gt;
    Forget(item &lt;span&gt;interface&lt;/span&gt;&lt;span&gt;{})

    &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; NumRequeues returns back how many times the item was requeued&lt;/span&gt;
    NumRequeues(item &lt;span&gt;interface&lt;/span&gt;{}) &lt;span&gt;int&lt;/span&gt;&lt;span&gt;
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;rateLimitingType实现了RateLimitingInterface接口，第二个参数就时限速队列接口。&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;33&quot;&gt;
&lt;pre&gt;
&lt;em&gt;&lt;span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; client-g0/util/workqueue/rate_limiting_queue.go&lt;/span&gt;&lt;/span&gt;&lt;/em&gt;
type rateLimitingType &lt;span&gt;struct&lt;/span&gt;&lt;span&gt; {
    DelayingInterface

    rateLimiter RateLimiter
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;下面是限速队列的使用：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;使用NewItemExponentialFailureRateLimiter初始化一个限速器&lt;/li&gt;
&lt;li&gt;使用NewRateLimitingQueue新建一个限速队列，并使用上一步的限速器进行初始化&lt;/li&gt;
&lt;li&gt;后续就可以使用AddRateLimited添加元素&lt;/li&gt;
&lt;/ul&gt;&lt;div class=&quot;cnblogs_code&quot; readability=&quot;54&quot;&gt;
&lt;pre&gt;
&lt;em&gt;&lt;span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; client-go/util/workqueue/rate_limiting_queue_test.go&lt;/span&gt;&lt;/span&gt;&lt;/em&gt;
func TestRateLimitingQueue(t *&lt;span&gt;testing.T) {
    limiter :&lt;/span&gt;= NewItemExponentialFailureRateLimiter(&lt;span&gt;1&lt;/span&gt;*time.Millisecond, &lt;span&gt;1&lt;/span&gt;*&lt;span&gt;time.Second)
    queue :&lt;/span&gt;= NewRateLimitingQueue(limiter).(*&lt;span&gt;rateLimitingType)
    fakeClock :&lt;/span&gt;=&lt;span&gt; clock.NewFakeClock(time.Now())
    delayingQueue :&lt;/span&gt;= &amp;amp;&lt;span&gt;delayingType{
        Interface:         New(),
        clock:             fakeClock,
        heartbeat:         fakeClock.NewTicker(maxWait),
        stopCh:            make(chan &lt;/span&gt;&lt;span&gt;struct&lt;/span&gt;&lt;span&gt;{}),
        waitingForAddCh:   make(chan &lt;/span&gt;*waitFor, &lt;span&gt;1000&lt;/span&gt;&lt;span&gt;),
        metrics:           newRetryMetrics(&lt;/span&gt;&lt;span&gt;&quot;&quot;&lt;/span&gt;&lt;span&gt;),
        deprecatedMetrics: newDeprecatedRetryMetrics(&lt;/span&gt;&lt;span&gt;&quot;&quot;&lt;/span&gt;&lt;span&gt;),
    }
    queue.DelayingInterface &lt;/span&gt;=&lt;span&gt; delayingQueue

    queue.AddRateLimited(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;one&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;)
    waitEntry :&lt;/span&gt;= &amp;lt;-&lt;span&gt;delayingQueue.waitingForAddCh
    &lt;/span&gt;&lt;span&gt;if&lt;/span&gt; e, a := &lt;span&gt;1&lt;/span&gt;*time.Millisecond, waitEntry.readyAt.Sub(fakeClock.Now()); e !=&lt;span&gt; a {
        t.Errorf(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;expected %v, got %v&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;, e, a)
    }

    queue.Forget(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;one&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;)
    &lt;/span&gt;&lt;span&gt;if&lt;/span&gt; e, a := &lt;span&gt;0&lt;/span&gt;, queue.NumRequeues(&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;one&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;); e !=&lt;span&gt; a {
        t.Errorf(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;expected %v, got %v&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;, e, a)
    }
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;
&lt;br/&gt;&lt;em&gt;&lt;span&gt;PS：后续会使用client-go编写简单程序&lt;/span&gt;&lt;/em&gt;
&lt;/pre&gt;
&lt;p&gt; TIPS：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;使用Client-go编写程序时，需要注意client-go的版本需要与对接的kubernetes相匹配，对应关系参见&lt;a href=&quot;https://github.com/kubernetes/client-go&quot; target=&quot;_blank&quot;&gt;github&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;参考:&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.huweihuang.com/kubernetes-notes/code-analysis/kube-controller-manager/sharedIndexInformer.html&quot;&gt;https://www.huweihuang.com/kubernetes-notes/code-analysis/kube-controller-manager/sharedIndexInformer.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://rancher.com/using-kubernetes-api-go-kubecon-2017-session-recap/&quot;&gt;https://rancher.com/using-kubernetes-api-go-kubecon-2017-session-recap/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://kubernetes.io/docs/tasks/access-kubernetes-api/custom-resources/custom-resource-definitions/&quot;&gt;https://kubernetes.io/docs/tasks/access-kubernetes-api/custom-resources/custom-resource-definitions/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources/&quot;&gt;https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.jianshu.com/p/d17f70369c35&quot;&gt;https://www.jianshu.com/p/d17f70369c35&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/kubernetes/community/blob/master/contributors/devel/sig-api-machinery/controllers.md&quot;&gt;https://github.com/kubernetes/community/blob/master/contributors/devel/sig-api-machinery/controllers.md&lt;/a&gt;&lt;/p&gt;
</description>
<pubDate>Mon, 01 Jul 2019 15:01:00 +0000</pubDate>
<dc:creator>charlieroro</dc:creator>
<og:description>下图为来自官方的Client-go架构图 图1. 下图也可以作为参考 图2. Indexer Indexer提供了对底层存储的操作，给出了存储对象以及索引对象的框架。Indexer的接口定义如下，它继</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/charlieroro/p/10330390.html</dc:identifier>
</item>
</channel>
</rss>