<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="css/feed.xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/" xmlns:og="http://ogp.me/ns#">
<channel>
<atom:link rel="self" href="http://192.168.1.4/fivefilters/makefulltextfeed.php?url=feed.cnblogs.com%2Fblog%2Fsitehome%2Frss&amp;max=10&amp;links=preserve&amp;exc=" />
<atom:link rel="alternate" title="Source URL" href="http://feed.cnblogs.com/blog/sitehome/rss" />
<atom:link rel="related" title="Subscribe to feed" href="http://www.subtome.com/#/subscribe?feeds=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed.cnblogs.com%252Fblog%252Fsitehome%252Frss%26max%3D10%26links%3Dpreserve%26exc%3D&amp;back=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed.cnblogs.com%252Fblog%252Fsitehome%252Frss%26max%3D10%26links%3Dpreserve%26exc%3D" />
<title>博客园_首页</title>
<link></link>
<description>代码改变世界</description>
<item>
<title>FLV协议5分钟入门浅析 - 程序猿小卡</title>
<link>http://www.cnblogs.com/chyingp/p/flv-getting-started.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/chyingp/p/flv-getting-started.html</guid>
<description>&lt;h2 id=&quot;flv协议简介&quot;&gt;FLV协议简介&lt;/h2&gt;
&lt;p&gt;FLV（Flash Video）是一种流媒体格式，因其体积小、协议相对简单，很快便流行开来，并得到广泛的支持。&lt;/p&gt;
&lt;p&gt;常见的HTTP-FLV直播协议，就是使用HTTP流式传输通过FLV封装的音视频数据。对想要了解HTTP-FLV的同学来说，了解FLV协议很有必要。&lt;/p&gt;
&lt;p&gt;概括地说，FLV 由 FLV header 跟 FLV file body 两部分组成，而 FLV file body 又由多个 FLV tag组成。&lt;/p&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;FLV = FLV header + FLV file body&lt;br/&gt;FLV file body = PreviousTagSize0 + Tag1 + PreviousTagSize1 + Tag2 + ... + PreviousTagSizeN-1 + TagN&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;FLV tag又分为3种类型：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;Video Tag：存放视频相关数据；&lt;/li&gt;
&lt;li&gt;Audio Tag：存放音频相关数据；&lt;/li&gt;
&lt;li&gt;Script Tag：存放音视频元数据；&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;在实际讲解FLV协议前，首先对单位进行约定：&lt;/p&gt;
&lt;table&gt;&lt;thead/&gt;&lt;tbody readability=&quot;2.5&quot;&gt;&lt;tr class=&quot;odd&quot;&gt;&lt;td&gt;0x...&lt;/td&gt;
&lt;td&gt;16进制数据&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;even&quot;&gt;&lt;td&gt;SI8&lt;/td&gt;
&lt;td&gt;有符号8位整数&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;odd&quot;&gt;&lt;td&gt;SI16&lt;/td&gt;
&lt;td&gt;有符号16位整数&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;even&quot;&gt;&lt;td&gt;SI24&lt;/td&gt;
&lt;td&gt;有符号24位整数&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;odd&quot;&gt;&lt;td&gt;SI32&lt;/td&gt;
&lt;td&gt;有符号32位整数&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;even&quot; readability=&quot;3&quot;&gt;&lt;td&gt;STRING&lt;/td&gt;
&lt;td&gt;Sequence of Unicode 8-bit characters (UTF-8), terminated with 0x00 (unless otherwise specified)&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;odd&quot;&gt;&lt;td&gt;UI8&lt;/td&gt;
&lt;td&gt;无符号8位整数&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;even&quot;&gt;&lt;td&gt;UI16&lt;/td&gt;
&lt;td&gt;无符号16位整数&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;odd&quot;&gt;&lt;td&gt;UI24&lt;/td&gt;
&lt;td&gt;无符号24位整数&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;even&quot;&gt;&lt;td&gt;UI32&lt;/td&gt;
&lt;td&gt;无符号32位整数&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;odd&quot;&gt;&lt;td&gt;xxx [ ]&lt;/td&gt;
&lt;td&gt;类型为xxx的数组&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;even&quot; readability=&quot;2&quot;&gt;&lt;td&gt;xxx [n]&lt;/td&gt;
&lt;td&gt;类型为xxx的数组，数组长度为n&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;p&gt;FLV header由如下字段组成，其中：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;前三个字节内容固定是&lt;strong&gt;FLV&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;最后4个字节内容固定是9（对FLV版本1来说）&lt;/li&gt;
&lt;/ol&gt;&lt;table&gt;&lt;thead/&gt;&lt;tbody readability=&quot;7&quot;&gt;&lt;tr class=&quot;odd&quot; readability=&quot;2&quot;&gt;&lt;td&gt;Signature&lt;/td&gt;
&lt;td&gt;UI8&lt;/td&gt;
&lt;td&gt;签名，固定为'F' (0x46)&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;even&quot; readability=&quot;2&quot;&gt;&lt;td&gt;Signature&lt;/td&gt;
&lt;td&gt;UI8&lt;/td&gt;
&lt;td&gt;签名，固定为'L' (0x4c)&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;odd&quot; readability=&quot;2&quot;&gt;&lt;td&gt;Signature&lt;/td&gt;
&lt;td&gt;UI8&lt;/td&gt;
&lt;td&gt;签名，固定为'V' (0x56)&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;even&quot; readability=&quot;2&quot;&gt;&lt;td&gt;Version&lt;/td&gt;
&lt;td&gt;UI8&lt;/td&gt;
&lt;td&gt;版本，比如 0x01 表示 FLV 版本 1&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;odd&quot;&gt;&lt;td&gt;TypeFlagsReserved&lt;/td&gt;
&lt;td&gt;UB[5]&lt;/td&gt;
&lt;td&gt;全为0&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;even&quot; readability=&quot;2&quot;&gt;&lt;td&gt;TypeFlagsAudio&lt;/td&gt;
&lt;td&gt;UB[1]&lt;/td&gt;
&lt;td&gt;1表示有audio tag，0表示没有&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;odd&quot;&gt;&lt;td&gt;TypeFlagsReserved&lt;/td&gt;
&lt;td&gt;UB[1]&lt;/td&gt;
&lt;td&gt;全为0&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;even&quot; readability=&quot;2&quot;&gt;&lt;td&gt;TypeFlagsVideo&lt;/td&gt;
&lt;td&gt;UB[1]&lt;/td&gt;
&lt;td&gt;1表示有video tag，0表示没有&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;odd&quot; readability=&quot;2&quot;&gt;&lt;td&gt;DataOffset&lt;/td&gt;
&lt;td&gt;UI32&lt;/td&gt;
&lt;td&gt;FLV header的大小，单位是字节&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;h2 id=&quot;flv-file-body&quot;&gt;FLV file body&lt;/h2&gt;
&lt;p&gt;FLV file body很有规律，由一系列的TagSize和Tag组成，其中：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;PreviousTagSize0 总是为0；&lt;/li&gt;
&lt;li&gt;tag 由tag header、tag body组成；&lt;/li&gt;
&lt;li&gt;对FLV版本1，tag header固定为11个字节，因此，PreviousTagSize（除第1个）的值为 11 + 前一个tag 的 tag body的大小；&lt;/li&gt;
&lt;/ol&gt;&lt;table&gt;&lt;thead/&gt;&lt;tbody readability=&quot;2&quot;&gt;&lt;tr class=&quot;odd&quot;&gt;&lt;td&gt;PreviousTagSize0&lt;/td&gt;
&lt;td&gt;UI32&lt;/td&gt;
&lt;td&gt;总是0&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;even&quot;&gt;&lt;td&gt;Tag1&lt;/td&gt;
&lt;td&gt;FLVTAG&lt;/td&gt;
&lt;td&gt;第1个tag&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;odd&quot; readability=&quot;2&quot;&gt;&lt;td&gt;PreviousTagSize1&lt;/td&gt;
&lt;td&gt;UI32&lt;/td&gt;
&lt;td&gt;前一个tag的大小，包括tag header&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;even&quot;&gt;&lt;td&gt;Tag2&lt;/td&gt;
&lt;td&gt;FLVTAG&lt;/td&gt;
&lt;td&gt;第2个tag&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;odd&quot;&gt;&lt;td&gt;...&lt;/td&gt;
&lt;td&gt;...&lt;/td&gt;
&lt;td&gt;...&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;even&quot;&gt;&lt;td&gt;PreviousTagSizeN-1&lt;/td&gt;
&lt;td&gt;UI32&lt;/td&gt;
&lt;td&gt;第N-1个tag的大小&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;odd&quot;&gt;&lt;td&gt;TagN&lt;/td&gt;
&lt;td&gt;FLVTAG&lt;/td&gt;
&lt;td&gt;第N个tag&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;even&quot; readability=&quot;2&quot;&gt;&lt;td&gt;PreviousTagSizeN&lt;/td&gt;
&lt;td&gt;UI32&lt;/td&gt;
&lt;td&gt;第N个tag的大小，包含tag header&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;p&gt;FLV tag由 tag header + tag body组成。&lt;/p&gt;
&lt;p&gt;tag header如下，总共占据11个字节：&lt;/p&gt;
&lt;table&gt;&lt;thead/&gt;&lt;tbody readability=&quot;4.5&quot;&gt;&lt;tr class=&quot;odd&quot; readability=&quot;2&quot;&gt;&lt;td&gt;TagType&lt;/td&gt;
&lt;td&gt;UI8&lt;/td&gt;
&lt;td&gt;tag类型&lt;br/&gt;8：audio&lt;br/&gt;9：video&lt;br/&gt;18：script data&lt;br/&gt;其他：保留&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;even&quot;&gt;&lt;td&gt;DataSize&lt;/td&gt;
&lt;td&gt;UI24&lt;/td&gt;
&lt;td&gt;tag body的大小&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;odd&quot; readability=&quot;2&quot;&gt;&lt;td&gt;Timestamp&lt;/td&gt;
&lt;td&gt;UI24&lt;/td&gt;
&lt;td&gt;相对于第一个tag的时间戳（单位是毫秒）&lt;br/&gt;第一个tag的Timestamp为0&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;even&quot; readability=&quot;3&quot;&gt;&lt;td&gt;TimestampExtended&lt;/td&gt;
&lt;td&gt;UI8&lt;/td&gt;
&lt;td&gt;时间戳的扩展字段，当 Timestamp 3个字节不够时，会启用这个字段，代表高8位&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;odd&quot;&gt;&lt;td&gt;StreamID&lt;/td&gt;
&lt;td&gt;UI24&lt;/td&gt;
&lt;td&gt;总是0&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;even&quot; readability=&quot;2&quot;&gt;&lt;td&gt;Data&lt;/td&gt;
&lt;td&gt;取决于根据TagType&lt;/td&gt;
&lt;td&gt;TagType=8，则为AUDIODATA&lt;br/&gt;TagType=9，则为VIDEODATA&lt;br/&gt;TagType=18，则为SCRIPTDATAOBJECT&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;blockquote readability=&quot;7&quot;&gt;
&lt;p&gt;In playback, the time sequencing of FLV tags depends on the FLV timestamps only. Any timing mechanisms built into the payload data format are ignored.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;定义如下所示：&lt;/p&gt;
&lt;table&gt;&lt;thead/&gt;&lt;tbody readability=&quot;8&quot;&gt;&lt;tr class=&quot;odd&quot; readability=&quot;7&quot;&gt;&lt;td&gt;SoundFormat&lt;/td&gt;
&lt;td&gt;UB[4]&lt;/td&gt;
&lt;td&gt;音频格式，重点关注 &lt;strong&gt;10 = AAC&lt;/strong&gt;&lt;br/&gt;0 = Linear PCM, platform endian&lt;br/&gt;1 = ADPCM&lt;br/&gt;2 = MP3&lt;br/&gt;3 = Linear PCM, little endian&lt;br/&gt;4 = Nellymoser 16-kHz mono&lt;br/&gt;5 = Nellymoser 8-kHz mono&lt;br/&gt;6 = Nellymoser&lt;br/&gt;7 = G.711 A-law logarithmic PCM 8 = G.711 mu-law logarithmic PCM 9 = reserved&lt;br/&gt;10 = AAC&lt;br/&gt;11 = Speex&lt;br/&gt;14 = MP3 8-Khz&lt;br/&gt;15 = Device-specific sound&lt;br/&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;even&quot; readability=&quot;2&quot;&gt;&lt;td&gt;SoundRate&lt;/td&gt;
&lt;td&gt;UB[2]&lt;/td&gt;
&lt;td&gt;采样率，对AAC来说，永远等于3&lt;br/&gt;0 = 5.5-kHz&lt;br/&gt;1 = 11-kHz&lt;br/&gt;2 = 22-kHz&lt;br/&gt;3 = 44-kHz&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;odd&quot; readability=&quot;2&quot;&gt;&lt;td&gt;SoundSize&lt;/td&gt;
&lt;td&gt;UB[1]&lt;/td&gt;
&lt;td&gt;采样精度，对于压缩过的音频，永远是16位&lt;br/&gt;0 = snd8Bit&lt;br/&gt;1 = snd16Bit&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;even&quot; readability=&quot;3&quot;&gt;&lt;td&gt;SoundType&lt;/td&gt;
&lt;td&gt;UB[1]&lt;/td&gt;
&lt;td&gt;声道类型，对Nellymoser来说，永远是单声道；对AAC来说，永远是双声道；&lt;br/&gt;0 = sndMono 单声道&lt;br/&gt;1 = sndStereo 双声道&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;odd&quot; readability=&quot;2&quot;&gt;&lt;td&gt;SoundData&lt;/td&gt;
&lt;td&gt;UI8[size of sound data]&lt;/td&gt;
&lt;td&gt;如果是AAC，则为 AACAUDIODATA；&lt;br/&gt;其他请参考规范；&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;备注：&lt;/p&gt;
&lt;blockquote readability=&quot;12&quot;&gt;
&lt;p&gt;If the SoundFormat indicates AAC, the SoundType should be set to 1 (stereo) and the SoundRate should be set to 3 (44 kHz). However, this does not mean that AAC audio in FLV is always stereo, 44 kHz data. Instead, the Flash Player ignores these values and extracts the channel and sample rate data is encoded in the AAC bitstream.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&quot;aacaudiodata&quot;&gt;AACAUDIODATA&lt;/h3&gt;
&lt;p&gt;当 SoundFormat 为10时，表示音频采AAC进行编码，此时，SoundData的定义如下：&lt;/p&gt;
&lt;table&gt;&lt;thead/&gt;&lt;tbody readability=&quot;2&quot;&gt;&lt;tr class=&quot;odd&quot; readability=&quot;2&quot;&gt;&lt;td&gt;AACPacketType&lt;/td&gt;
&lt;td&gt;UI8&lt;/td&gt;
&lt;td&gt;0: AAC sequence header&lt;br/&gt;1: AAC raw&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;even&quot; readability=&quot;2&quot;&gt;&lt;td&gt;Data&lt;/td&gt;
&lt;td&gt;UI8[n]&lt;/td&gt;
&lt;td&gt;如果AACPacketType为0，则为AudioSpecificConfig&lt;br/&gt;如果AACPacketType为1，则为AAC帧数据&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;The AudioSpecificConfig is explained in ISO 14496-3. Note that it is not the same as the contents of the esds box from an MP4/F4V file. This structure is more deeply embedded.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&quot;关于audiospecificconfig&quot;&gt;关于AudioSpecificConfig&lt;/h3&gt;
&lt;p&gt;伪代码如下：参考&lt;a href=&quot;https://wiki.multimedia.cx/index.php/MPEG-4_Audio#Audio_Specific_Config&quot;&gt;这里&lt;/a&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;5 bits: object type
if (object type == 31)
    6 bits + 32: object type
4 bits: frequency index
if (frequency index == 15)
    24 bits: frequency
4 bits: channel configuration
var bits: AOT Specific Config&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;定义如下：&lt;/p&gt;
&lt;table&gt;&lt;thead/&gt;&lt;tbody readability=&quot;4.5&quot;&gt;&lt;tr class=&quot;odd&quot; readability=&quot;2&quot;&gt;&lt;td&gt;AudioObjectType&lt;/td&gt;
&lt;td&gt;UB[5]&lt;/td&gt;
&lt;td&gt;编码器类型，比如2表示AAC-LC&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;even&quot; readability=&quot;2&quot;&gt;&lt;td&gt;SamplingFrequencyIndex&lt;/td&gt;
&lt;td&gt;UB[4]&lt;/td&gt;
&lt;td&gt;采样率索引值，比如4表示44100&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;odd&quot; readability=&quot;2&quot;&gt;&lt;td&gt;SamplingFrequencyIndex&lt;/td&gt;
&lt;td&gt;UB[4]&lt;/td&gt;
&lt;td&gt;采样率索引值，比如4表示44100&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;even&quot; readability=&quot;3&quot;&gt;&lt;td&gt;ChannelConfiguration&lt;/td&gt;
&lt;td&gt;UB[4]&lt;/td&gt;
&lt;td&gt;声道配置，比如2代表双声道，front-left, front-right&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;p&gt;定义如下：&lt;/p&gt;
&lt;table&gt;&lt;thead/&gt;&lt;tbody readability=&quot;6&quot;&gt;&lt;tr class=&quot;odd&quot; readability=&quot;6&quot;&gt;&lt;td&gt;FrameType&lt;/td&gt;
&lt;td&gt;UB[4]&lt;/td&gt;
&lt;td&gt;重点关注1、2：&lt;br/&gt;1: keyframe (for AVC, a seekable frame) —— 即H.264的IDR帧；&lt;br/&gt;2: inter frame (for AVC, a non- seekable frame) —— H.264的普通I帧；&lt;br/&gt;3: disposable inter frame (H.263 only)&lt;br/&gt;4: generated keyframe (reserved for server use only)&lt;br/&gt;5: video info/command frame&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;even&quot; readability=&quot;3&quot;&gt;&lt;td&gt;CodecID&lt;/td&gt;
&lt;td&gt;UB[4]&lt;/td&gt;
&lt;td&gt;编解码器，主要关注 7（AVC）&lt;br/&gt;1: JPEG (currently unused)&lt;br/&gt;2: Sorenson H.263&lt;br/&gt;3: Screen video&lt;br/&gt;4: On2 VP6&lt;br/&gt;5: On2 VP6 with alpha channel 6: Screen video version 2&lt;br/&gt;&lt;strong&gt;7: AVC&lt;/strong&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;odd&quot; readability=&quot;3&quot;&gt;&lt;td&gt;VideoData&lt;/td&gt;
&lt;td&gt;取决于CodecID&lt;/td&gt;
&lt;td&gt;实际的媒体类型，主要关注 7:AVCVIDEOPACKE&lt;br/&gt;2: H263VIDEOPACKET&lt;br/&gt;3: SCREENVIDEOPACKET&lt;br/&gt;4: VP6FLVVIDEOPACKET&lt;br/&gt;5: VP6FLVALPHAVIDEOPACKET&lt;br/&gt;6: SCREENV2VIDEOPACKET&lt;br/&gt;&lt;strong&gt;7: AVCVIDEOPACKE&lt;/strong&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;h3 id=&quot;avcvideopacke&quot;&gt;AVCVIDEOPACKE&lt;/h3&gt;
&lt;p&gt;当 CodecID 为 7 时，VideoData 为 AVCVIDEOPACKE，也即 H.264媒体数据。&lt;/p&gt;
&lt;p&gt;AVCVIDEOPACKE 的定义如下：&lt;/p&gt;
&lt;table&gt;&lt;thead/&gt;&lt;tbody readability=&quot;3.5&quot;&gt;&lt;tr class=&quot;odd&quot; readability=&quot;2&quot;&gt;&lt;td&gt;AVCPacketType&lt;/td&gt;
&lt;td&gt;UI8&lt;/td&gt;
&lt;td&gt;0: AVC sequence header&lt;br/&gt;1: AVC NALU&lt;br/&gt;2: AVC end of sequence&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;even&quot; readability=&quot;2&quot;&gt;&lt;td&gt;CompositionTime&lt;/td&gt;
&lt;td&gt;SI24&lt;/td&gt;
&lt;td&gt;如果AVCPacketType=1，则为时间cts偏移量；否则，为0&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;odd&quot; readability=&quot;3&quot;&gt;&lt;td&gt;Data&lt;/td&gt;
&lt;td&gt;UI8[n]&lt;/td&gt;
&lt;td&gt;1、如果如果AVCPacketType=1，则为AVCDecoderConfigurationRecord&lt;br/&gt;2、如果AVCPacketType=1=2，则为NALU（一个或多个）&lt;br/&gt;3、如果AVCPacketType=2，则为空&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;这里有几点稍微解释下：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;NALU：H.264中，将&lt;strong&gt;数据&lt;/strong&gt;按照特定规则格式化后得到的抽象逻辑单元，称为NALU。这里的数据既包括了编码后的视频数据，也包括视频解码需要用到的参数集（PPS、SPS）。&lt;/li&gt;
&lt;li&gt;AVCDecoderConfigurationRecord：H.264 视频解码所需要的参数集（SPS、PPS）&lt;/li&gt;
&lt;li&gt;CTS：当B帧的存在时，视频解码呈现过程中，dts、pts可能不同，cts的计算公式为 pts - dts/90，单位为毫秒；如果B帧不存在，则cts固定为0；&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;PPS、SPS这里先不展开。&lt;/p&gt;

&lt;p&gt;Script Data Tags通常用来存放跟FLV中音视频相关的元数据信息（onMetaData），比如时长、长度、宽度等。它的定义相对复杂些，采用AMF（Action Message Format）封装了一系列数据类型，比如字符串、数值、数组等。&lt;/p&gt;
&lt;table&gt;&lt;thead/&gt;&lt;tbody readability=&quot;2&quot;&gt;&lt;tr class=&quot;odd&quot; readability=&quot;2&quot;&gt;&lt;td&gt;Objects&lt;/td&gt;
&lt;td&gt;SCRIPTDATAOBJECT[]&lt;/td&gt;
&lt;td&gt;任意数目的 SCRIPTDATAOBJECT&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;even&quot; readability=&quot;2&quot;&gt;&lt;td&gt;SCRIPTDATAOBJECTEND&lt;/td&gt;
&lt;td&gt;UI24&lt;/td&gt;
&lt;td&gt;永远是9，标识着Script Data的结束&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;SCRIPTDATAOBJECT 定义如下：&lt;/p&gt;
&lt;table&gt;&lt;thead/&gt;&lt;tbody&gt;&lt;tr class=&quot;odd&quot;&gt;&lt;td&gt;ObjectName&lt;/td&gt;
&lt;td&gt;SCRIPTDATASTRING&lt;/td&gt;
&lt;td&gt;对象的名字&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;even&quot;&gt;&lt;td&gt;ObjectData&lt;/td&gt;
&lt;td&gt;SCRIPTDATAVALUE&lt;/td&gt;
&lt;td&gt;对象的值&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;SCRIPTDATAVALUE 的定义如下：&lt;/p&gt;
&lt;table&gt;&lt;thead/&gt;&lt;tbody readability=&quot;7.5&quot;&gt;&lt;tr class=&quot;odd&quot; readability=&quot;4&quot;&gt;&lt;td&gt;Type&lt;/td&gt;
&lt;td&gt;SCRIPTDATASTRING&lt;/td&gt;
&lt;td&gt;变量类型：&lt;br/&gt;0 = Number type&lt;br/&gt;1 = Boolean type&lt;br/&gt;2 = String type&lt;br/&gt;3 = Object type&lt;br/&gt;4 = MovieClip type&lt;br/&gt;5 = Null type&lt;br/&gt;6 = Undefined type&lt;br/&gt;7 = Reference type 8 = ECMA array type 10 = Strict array type 11 = Date type&lt;br/&gt;12 = Long string type&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;even&quot; readability=&quot;2&quot;&gt;&lt;td&gt;ECMAArrayLength&lt;/td&gt;
&lt;td&gt;如果Type为8（数组），则为UI32&lt;/td&gt;
&lt;td&gt;数组长度&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;odd&quot; readability=&quot;3&quot;&gt;&lt;td&gt;ScriptDataValue&lt;/td&gt;
&lt;td&gt;If Type == 0 DOUBLE&lt;br/&gt;If Type == 1 UI8&lt;br/&gt;If Type == 2 SCRIPTDATASTRING&lt;br/&gt;...（有点长，可以参考规范）&lt;/td&gt;
&lt;td&gt;变量的值&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;even&quot; readability=&quot;6&quot;&gt;&lt;td&gt;ScriptDataValueTerminator&lt;/td&gt;
&lt;td&gt;如果Type==3，则为SCRIPTDATAOBJECTEND&lt;br/&gt;如果 Type==8，则为SCRIPTDATAVARIABLEEND&lt;/td&gt;
&lt;td&gt;Object、Array的结束符&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;可以看到，Script Data Tag 的定义相对复杂，下面通过onMetaData进行进一步讲解。&lt;/p&gt;
&lt;h3 id=&quot;onmetadata&quot;&gt;onMetaData&lt;/h3&gt;
&lt;p&gt;onMetaData中包含了音视频相关的元数据，封装在Script Data Tag中，它包含了两个AMF。&lt;/p&gt;
&lt;p&gt;第一个AMF：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;第1个字节：0x02，表示字符串类型&lt;/li&gt;
&lt;li&gt;第2-3个字节：UI16类型，值为0x000A，表示字符串的长度为10（onMetaData的长度）；&lt;/li&gt;
&lt;li&gt;第4-13个字节：字符串onMetaData对应的16进制数字（0x6F 0x6E 0x4D 0x65 0x74 0x61 0x44 0x61 0x74 0x61）；&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;第二个AMF：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;第1个字节：0x08，表示数组类型；&lt;/li&gt;
&lt;li&gt;第2-5个字节：UI32类型，表示数组的长度，onMetaData中具体包含哪些属性是不固定的。&lt;/li&gt;
&lt;li&gt;第6个字节+：比如duration，则：
&lt;ul&gt;&lt;li&gt;第6-9个字节：0x0008，表示长度为8个字节；&lt;/li&gt;
&lt;li&gt;第10-17个字节：0x6475 7261 7469，表示 duration 这个字符串；&lt;/li&gt;
&lt;li&gt;第18个字节：0x00，表示为数值类型；&lt;/li&gt;
&lt;li&gt;第19-26个字节：0x...，表示具体的时长；&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;更多onMetaData字段的定义：&lt;/p&gt;
&lt;table&gt;&lt;thead/&gt;&lt;tbody readability=&quot;5&quot;&gt;&lt;tr class=&quot;odd&quot;&gt;&lt;td&gt;duration&lt;/td&gt;
&lt;td&gt;DOUBLE&lt;/td&gt;
&lt;td&gt;文件的时长&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;even&quot;&gt;&lt;td&gt;width&lt;/td&gt;
&lt;td&gt;DOUBLE&lt;/td&gt;
&lt;td&gt;视频宽度（px）&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;odd&quot;&gt;&lt;td&gt;height&lt;/td&gt;
&lt;td&gt;DOUBLE&lt;/td&gt;
&lt;td&gt;视频高度（px）&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;even&quot; readability=&quot;2&quot;&gt;&lt;td&gt;videodatarate&lt;/td&gt;
&lt;td&gt;DOUBLE&lt;/td&gt;
&lt;td&gt;视频比特率（kb/s）&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;odd&quot;&gt;&lt;td&gt;framerate&lt;/td&gt;
&lt;td&gt;DOUBLE&lt;/td&gt;
&lt;td&gt;视频帧率（帧/s）&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;even&quot; readability=&quot;2&quot;&gt;&lt;td&gt;videocodecid&lt;/td&gt;
&lt;td&gt;DOUBLE&lt;/td&gt;
&lt;td&gt;视频编解码器ID（参考Video Tag）&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;odd&quot;&gt;&lt;td&gt;audiosamplerate&lt;/td&gt;
&lt;td&gt;DOUBLE&lt;/td&gt;
&lt;td&gt;音频采样率&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;even&quot; readability=&quot;2&quot;&gt;&lt;td&gt;audiosamplesize&lt;/td&gt;
&lt;td&gt;DOUBLE&lt;/td&gt;
&lt;td&gt;音频采样精度（参考Audio Tag）&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;odd&quot;&gt;&lt;td&gt;stereo&lt;/td&gt;
&lt;td&gt;BOOL&lt;/td&gt;
&lt;td&gt;是否立体声&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;even&quot; readability=&quot;2&quot;&gt;&lt;td&gt;audiocodecid&lt;/td&gt;
&lt;td&gt;DOUBLE&lt;/td&gt;
&lt;td&gt;音频编解码器ID（参考Audio Tag）&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;odd&quot; readability=&quot;2&quot;&gt;&lt;td&gt;filesize&lt;/td&gt;
&lt;td&gt;DOUBLE&lt;/td&gt;
&lt;td&gt;文件总得大小（字节）&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;h2 id=&quot;写在后面&quot;&gt;写在后面&lt;/h2&gt;
&lt;p&gt;FLV协议本身不算复杂，理解上的困难，更多时候来自音视频编解码相关的知识，比如H.264、AAC相关知识，建议不懂的时候自行查下。此外，FLV的字节序为大端序，在做协议解析的时候一定要注意。&lt;/p&gt;
&lt;p&gt;本文为讲解方便，部分内容可能不够严谨，如有错漏敬请指出。&lt;/p&gt;
&lt;h2 id=&quot;相关链接&quot;&gt;相关链接&lt;/h2&gt;
&lt;p&gt;video_file_format_spec_v10.pdf&lt;br/&gt;&lt;a href=&quot;https://www.adobe.com/content/dam/acom/en/devnet/flv/video_file_format_spec_v10.pdf&quot; class=&quot;uri&quot;&gt;https://www.adobe.com/content/dam/acom/en/devnet/flv/video_file_format_spec_v10.pdf&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;MPEG-4 Part 3&lt;br/&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/MPEG-4_Part_3#Audio_Profiles&quot; class=&quot;uri&quot;&gt;https://en.wikipedia.org/wiki/MPEG-4_Part_3#Audio_Profiles&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;flv文件分析&lt;br/&gt;&lt;a href=&quot;https://www.jianshu.com/p/e290dca02979&quot; class=&quot;uri&quot;&gt;https://www.jianshu.com/p/e290dca02979&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;H.264再学习 -- 详解 H.264 NALU语法结构&lt;br/&gt;&lt;a href=&quot;https://blog.csdn.net/qq_29350001/article/details/78226286&quot; class=&quot;uri&quot;&gt;https://blog.csdn.net/qq_29350001/article/details/78226286&lt;/a&gt;&lt;/p&gt;
</description>
<pubDate>Mon, 12 Aug 2019 00:43:00 +0000</pubDate>
<dc:creator>程序猿小卡</dc:creator>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/chyingp/p/flv-getting-started.html</dc:identifier>
</item>
<item>
<title>简洁实用Socket框架DotNettySocket - 寒空飞箭</title>
<link>http://www.cnblogs.com/coldairarrow/p/11336771.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/coldairarrow/p/11336771.html</guid>
<description>&lt;p&gt;DotNettySocket是一个.NET跨平台Socket框架（支持.NET4.5+及.NET Standard2.0+），同时支持TcpSocket、WebSocket和UdpSocket，其基于微软强大的DotNetty框架，力求为Socket通讯提供&lt;strong&gt;简单&lt;/strong&gt;、&lt;strong&gt;高效&lt;/strong&gt;、&lt;strong&gt;优雅&lt;/strong&gt;的操作方式。&lt;/p&gt;
&lt;p&gt;安装方式：Nuget安装&lt;strong&gt;DotNettySocket&lt;/strong&gt;即可&lt;/p&gt;
&lt;p&gt;项目地址：&lt;a href=&quot;https://github.com/Coldairarrow/DotNettySocket&quot; class=&quot;uri&quot;&gt;https://github.com/Coldairarrow/DotNettySocket&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;两年前最开始接触物联网的时候，需要用到Tcp及Udp通讯，为了方便使用，将原始的Socket进行了简单的封装，基本满足了需求，并将框架开源。但是由于精力及实力有限，没有进一步优化原框架。后来发现了强大的DotNetty框架，DotNetty是微软Azure团队开源基于Java Netty框架的移植版，其性能优异、维护团队强大，许多.NET强大的框架都使用它。DotNetty功能强大，但是用起来还是不够简洁（或许是个人感觉），刚好最近项目需要用到WebSocket，因此鄙人抽时间基于DotNetty进行简单封装了下，撸出一个力求&lt;strong&gt;简单、高效、优雅&lt;/strong&gt;的Socket框架。&lt;/p&gt;

&lt;h2 id=&quot;tcpsocket&quot;&gt;TcpSocket&lt;/h2&gt;
&lt;p&gt;Tcp是面向连接的，所以服务端对连接的管理就至关重要，框架支持各种事件的处理、给连接设置连接名（身份标识）、通过连接名找到特定连接、连接收发数据、分包、粘包处理。&lt;/p&gt;
&lt;pre class=&quot;c#&quot;&gt;
&lt;code&gt;using Coldairarrow.DotNettySocket;
using System;
using System.Text;
using System.Threading.Tasks;

namespace TcpSocket.Server
{
    class Program
    {
        static async Task Main(string[] args)
        {
            var theServer = await SocketBuilderFactory.GetTcpSocketServerBuilder(6001)
                .SetLengthFieldEncoder(2)
                .SetLengthFieldDecoder(ushort.MaxValue, 0, 2, 0, 2)
                .OnConnectionClose((server, connection) =&amp;gt;
                {
                    Console.WriteLine($&quot;连接关闭,连接名[{connection.ConnectionName}],当前连接数:{server.GetConnectionCount()}&quot;);
                })
                .OnException(ex =&amp;gt;
                {
                    Console.WriteLine($&quot;服务端异常:{ex.Message}&quot;);
                })
                .OnNewConnection((server, connection) =&amp;gt;
                {
                    connection.ConnectionName = $&quot;名字{connection.ConnectionId}&quot;;
                    Console.WriteLine($&quot;新的连接:{connection.ConnectionName},当前连接数:{server.GetConnectionCount()}&quot;);
                })
                .OnRecieve((server, connection, bytes) =&amp;gt;
                {
                    Console.WriteLine($&quot;服务端:数据{Encoding.UTF8.GetString(bytes)}&quot;);
                    connection.Send(bytes);
                })
                .OnSend((server, connection, bytes) =&amp;gt;
                {
                    Console.WriteLine($&quot;向连接名[{connection.ConnectionName}]发送数据:{Encoding.UTF8.GetString(bytes)}&quot;);
                })
                .OnServerStarted(server =&amp;gt;
                {
                    Console.WriteLine($&quot;服务启动&quot;);
                }).BuildAsync();

            Console.ReadLine();
        }
    }
}&lt;/code&gt;
&lt;/pre&gt;
&lt;pre class=&quot;c#&quot;&gt;
&lt;code&gt;using Coldairarrow.DotNettySocket;
using System;
using System.Net;
using System.Text;
using System.Threading.Tasks;

namespace UdpSocket.Client
{
    class Program
    {
        static async Task Main(string[] args)
        {
            var theClient = await SocketBuilderFactory.GetUdpSocketBuilder()
                .OnClose(server =&amp;gt;
                {
                    Console.WriteLine($&quot;客户端关闭&quot;);
                })
                .OnException(ex =&amp;gt;
                {
                    Console.WriteLine($&quot;客户端异常:{ex.Message}&quot;);
                })
                .OnRecieve((server, point, bytes) =&amp;gt;
                {
                    Console.WriteLine($&quot;客户端:收到来自[{point.ToString()}]数据:{Encoding.UTF8.GetString(bytes)}&quot;);
                })
                .OnSend((server, point, bytes) =&amp;gt;
                {
                    Console.WriteLine($&quot;客户端发送数据:目标[{point.ToString()}]数据:{Encoding.UTF8.GetString(bytes)}&quot;);
                })
                .OnStarted(server =&amp;gt;
                {
                    Console.WriteLine($&quot;客户端启动&quot;);
                }).BuildAsync();

            while (true)
            {
                await theClient.Send(Guid.NewGuid().ToString(), new IPEndPoint(IPAddress.Parse(&quot;127.0.0.1&quot;), 6003));
                await Task.Delay(1000);
            }
        }
    }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;websocket&quot;&gt;WebSocket&lt;/h2&gt;
&lt;p&gt;WebSocket与TcpSocket接口基本保持一致，仅有的区别就是TcpSocket支持字节的收发并且需要自行处理分包粘包。而WebSocket直接收发字符串（UTF-8）编码，并且无需考虑分包粘包。框架目前没有支持WSS，建议解决方案是使用Nginx转发即可（相关资料一搜便有）&lt;/p&gt;
&lt;pre class=&quot;c#&quot;&gt;
&lt;code&gt;using Coldairarrow.DotNettySocket;
using System;
using System.Threading.Tasks;

namespace WebSocket.Server
{
    class Program
    {
        static async Task Main(string[] args)
        {
            var theServer = await SocketBuilderFactory.GetWebSocketServerBuilder(6002)
                .OnConnectionClose((server, connection) =&amp;gt;
                {
                    Console.WriteLine($&quot;连接关闭,连接名[{connection.ConnectionName}],当前连接数:{server.GetConnectionCount()}&quot;);
                })
                .OnException(ex =&amp;gt;
                {
                    Console.WriteLine($&quot;服务端异常:{ex.Message}&quot;);
                })
                .OnNewConnection((server, connection) =&amp;gt;
                {
                    connection.ConnectionName = $&quot;名字{connection.ConnectionId}&quot;;
                    Console.WriteLine($&quot;新的连接:{connection.ConnectionName},当前连接数:{server.GetConnectionCount()}&quot;);
                })
                .OnRecieve((server, connection, msg) =&amp;gt;
                {
                    Console.WriteLine($&quot;服务端:数据{msg}&quot;);
                    connection.Send(msg);
                })
                .OnSend((server, connection, msg) =&amp;gt;
                {
                    Console.WriteLine($&quot;向连接名[{connection.ConnectionName}]发送数据:{msg}&quot;);
                })
                .OnServerStarted(server =&amp;gt;
                {
                    Console.WriteLine($&quot;服务启动&quot;);
                }).BuildAsync();

            Console.ReadLine();
        }
    }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;ul&gt;&lt;li&gt;控制台客户端&lt;/li&gt;
&lt;/ul&gt;&lt;pre class=&quot;c#&quot;&gt;
&lt;code&gt;using Coldairarrow.DotNettySocket;
using System;
using System.Threading.Tasks;

namespace WebSocket.ConsoleClient
{
    class Program
    {
        static async Task Main(string[] args)
        {
            var theClient = await SocketBuilderFactory.GetWebSocketClientBuilder(&quot;127.0.0.1&quot;, 6002)
                .OnClientStarted(client =&amp;gt;
                {
                    Console.WriteLine($&quot;客户端启动&quot;);
                })
                .OnClientClose(client =&amp;gt;
                {
                    Console.WriteLine($&quot;客户端关闭&quot;);
                })
                .OnException(ex =&amp;gt;
                {
                    Console.WriteLine($&quot;异常:{ex.Message}&quot;);
                })
                .OnRecieve((client, msg) =&amp;gt;
                {
                    Console.WriteLine($&quot;客户端:收到数据:{msg}&quot;);
                })
                .OnSend((client, msg) =&amp;gt;
                {
                    Console.WriteLine($&quot;客户端:发送数据:{msg}&quot;);
                })
                .BuildAsync();

            while (true)
            {
                await theClient.Send(Guid.NewGuid().ToString());

                await Task.Delay(1000);
            }
        }
    }
}&lt;/code&gt;
&lt;/pre&gt;
&lt;ul&gt;&lt;li&gt;网页客户端&lt;/li&gt;
&lt;/ul&gt;&lt;pre class=&quot;javascript&quot;&gt;
&lt;code&gt;&amp;lt;!DOCTYPE HTML&amp;gt;
&amp;lt;html&amp;gt;
&amp;lt;head&amp;gt;
    &amp;lt;meta charset=&quot;utf-8&quot;&amp;gt;
    &amp;lt;title&amp;gt;菜鸟教程(runoob.com)&amp;lt;/title&amp;gt;

    &amp;lt;script type=&quot;text/javascript&quot;&amp;gt;
        function WebSocketTest() {
            if (&quot;WebSocket&quot; in window) {
                var ws = new WebSocket(&quot;ws://127.0.0.1:6002&quot;);

                ws.onopen = function () {
                    console.log('连上服务端');
                    setInterval(function () {
                        ws.send(&quot;111111&quot;);
                    }, 1000);
                };

                ws.onmessage = function (evt) {
                    var received_msg = evt.data;
                    console.log('收到' + received_msg);
                };

                ws.onclose = function () {
                    console.log(&quot;连接已关闭...&quot;);
                };
            }

            else {
                alert(&quot;您的浏览器不支持 WebSocket!&quot;);
            }
        }
    &amp;lt;/script&amp;gt;

&amp;lt;/head&amp;gt;
&amp;lt;body&amp;gt;
    &amp;lt;div id=&quot;sse&quot;&amp;gt;
        &amp;lt;a href=&quot;javascript:WebSocketTest()&quot;&amp;gt;运行 WebSocket&amp;lt;/a&amp;gt;
    &amp;lt;/div&amp;gt;
&amp;lt;/body&amp;gt;
&amp;lt;/html&amp;gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;udpsocket&quot;&gt;UdpSocket&lt;/h2&gt;
&lt;p&gt;Udp天生便是收发一体的，以下分为服务端与客户端仅仅是为了方便理解&lt;/p&gt;
&lt;pre class=&quot;c#&quot;&gt;
&lt;code&gt;using Coldairarrow.DotNettySocket;
using System;
using System.Text;
using System.Threading.Tasks;

namespace UdpSocket.Server
{
    class Program
    {
        static async Task Main(string[] args)
        {
            var theServer = await SocketBuilderFactory.GetUdpSocketBuilder(6003)
                .OnClose(server =&amp;gt;
                {
                    Console.WriteLine($&quot;服务端关闭&quot;);
                })
                .OnException(ex =&amp;gt;
                {
                    Console.WriteLine($&quot;服务端异常:{ex.Message}&quot;);
                })
                .OnRecieve((server, point, bytes) =&amp;gt;
                {
                    Console.WriteLine($&quot;服务端:收到来自[{point.ToString()}]数据:{Encoding.UTF8.GetString(bytes)}&quot;);
                    server.Send(bytes, point);
                })
                .OnSend((server, point, bytes) =&amp;gt;
                {
                    Console.WriteLine($&quot;服务端发送数据:目标[{point.ToString()}]数据:{Encoding.UTF8.GetString(bytes)}&quot;);
                })
                .OnStarted(server =&amp;gt;
                {
                    Console.WriteLine($&quot;服务端启动&quot;);
                }).BuildAsync();

            Console.ReadLine();
        }
    }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;pre class=&quot;c#&quot;&gt;
&lt;code&gt;using Coldairarrow.DotNettySocket;
using System;
using System.Net;
using System.Text;
using System.Threading.Tasks;

namespace UdpSocket.Client
{
    class Program
    {
        static async Task Main(string[] args)
        {
            var theClient = await SocketBuilderFactory.GetUdpSocketBuilder()
                .OnClose(server =&amp;gt;
                {
                    Console.WriteLine($&quot;客户端关闭&quot;);
                })
                .OnException(ex =&amp;gt;
                {
                    Console.WriteLine($&quot;客户端异常:{ex.Message}&quot;);
                })
                .OnRecieve((server, point, bytes) =&amp;gt;
                {
                    Console.WriteLine($&quot;客户端:收到来自[{point.ToString()}]数据:{Encoding.UTF8.GetString(bytes)}&quot;);
                })
                .OnSend((server, point, bytes) =&amp;gt;
                {
                    Console.WriteLine($&quot;客户端发送数据:目标[{point.ToString()}]数据:{Encoding.UTF8.GetString(bytes)}&quot;);
                })
                .OnStarted(server =&amp;gt;
                {
                    Console.WriteLine($&quot;客户端启动&quot;);
                }).BuildAsync();

            while (true)
            {
                await theClient.Send(Guid.NewGuid().ToString(), new IPEndPoint(IPAddress.Parse(&quot;127.0.0.1&quot;), 6003));
                await Task.Delay(1000);
            }
        }
    }
}
&lt;/code&gt;
&lt;/pre&gt;

&lt;p&gt;以上所有示例在源码中都有，若觉得不错请点赞加星星，希望能够帮助到大家。&lt;/p&gt;
&lt;p&gt;有任何问题请及时反馈或加群交流&lt;/p&gt;
&lt;p&gt;QQ群1:（已满）&lt;/p&gt;
&lt;p&gt;QQ群2:579202910&lt;/p&gt;
</description>
<pubDate>Mon, 12 Aug 2019 00:28:00 +0000</pubDate>
<dc:creator>寒空飞箭</dc:creator>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/coldairarrow/p/11336771.html</dc:identifier>
</item>
<item>
<title>Caddy 源码全解析 - abser</title>
<link>http://www.cnblogs.com/abser/p/11337662.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/abser/p/11337662.html</guid>
<description>&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1596023/201908/1596023-20190812081951311-770122693.png&quot;/&gt;&lt;/p&gt;




&lt;h2 id=&quot;preface&quot;&gt;Preface&lt;/h2&gt;
&lt;p&gt;Caddy 是 Go 语言构建的轻量配置化服务器。同时代码结构由于 Go 语言的轻便简洁，比较易读，推荐学弟学妹学习 Go 的时候也去查看追一下它的源码。不用怕相信这篇文章能给你很大的信心。&lt;/p&gt;
&lt;p&gt;可能会有点多，建议多看几遍。&lt;/p&gt;

&lt;h2 id=&quot;overview-caddymain&quot;&gt;Overview-CaddyMain&lt;/h2&gt;
&lt;p&gt;当然，建议看这篇文章的时候，查看上手一下 Caddy 的实际配置操作应用，对理解源码会有好处，如果没有操作过也没有关系。&lt;/p&gt;

&lt;h3 id=&quot;package&quot;&gt;Package&lt;/h3&gt;
&lt;p&gt;这是 caddy 包的结构&lt;br/&gt;&lt;img src=&quot;https://cdn.nlark.com/yuque/0/2019/png/176280/1564935806700-8ad7793d-4f04-4a6f-8660-cc6ec9fb8cfb.png#align=left&amp;amp;display=inline&amp;amp;height=640&amp;amp;originHeight=640&amp;amp;originWidth=279&amp;amp;size=0&amp;amp;status=done&amp;amp;width=279&quot;/&gt;&lt;img src=&quot;https://cdn.nlark.com/yuque/0/2019/png/176280/1564935806739-ae970f4e-21af-4e2e-aee0-194ef2fc8dd2.png#align=left&amp;amp;display=inline&amp;amp;height=478&amp;amp;originHeight=478&amp;amp;originWidth=266&amp;amp;size=0&amp;amp;status=done&amp;amp;width=266&quot;/&gt;&lt;/p&gt;
&lt;p&gt;首先我们从一切的开始讲起，即平时我们程序运行的 main.go 函数。&lt;br/&gt;这是 上图 caddy 文件夹下的目录结构。&lt;br/&gt;&lt;img src=&quot;https://cdn.nlark.com/yuque/0/2019/png/176280/1564935806855-13f9688d-d8fd-43a4-a65d-bc12f944e45a.png#align=left&amp;amp;display=inline&amp;amp;height=195&amp;amp;originHeight=195&amp;amp;originWidth=370&amp;amp;size=0&amp;amp;status=done&amp;amp;width=370&quot;/&gt;&lt;br/&gt;在 caddy 文件夹中的 main 函数启动 caddy 服务器。实际运行的是 run.go 中的文件，这是方便测试使用&lt;br/&gt;看 &lt;a href=&quot;https://sourcegraph.com/github.com/caddyserver/caddy/-/blob/caddy/main.go#L24:11&quot;&gt;main.go&lt;/a&gt;的代码&lt;br/&gt;&lt;img src=&quot;https://cdn.nlark.com/yuque/0/2019/png/176280/1564935806997-93107fac-42a9-45ad-ade7-32a1b0de0fd1.png#align=left&amp;amp;display=inline&amp;amp;height=103&amp;amp;originHeight=103&amp;amp;originWidth=366&amp;amp;size=0&amp;amp;status=done&amp;amp;width=366&quot;/&gt;&lt;br/&gt;通过改变 run 变量的值来方便测试，可以学习一下。&lt;/p&gt;

&lt;h4 id=&quot;启动流程&quot;&gt;启动流程&lt;/h4&gt;
&lt;p&gt;启动 caddy 的流程画了张图&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://cdn.nlark.com/yuque/0/2019/png/176280/1564935807366-70aa7b43-da65-4340-9d4f-bdedd5c4f727.png#align=left&amp;amp;display=inline&amp;amp;height=774&amp;amp;originHeight=774&amp;amp;originWidth=1240&amp;amp;size=0&amp;amp;status=done&amp;amp;width=1240&quot;/&gt;&lt;br/&gt;见到不认识的不用担心，查看上文的目录结构可以找到他们大概的位置，下文会详细讲解。&lt;/p&gt;
&lt;p&gt;可以在此图中看到几个重要的点 &lt;code&gt;caddyfileLoader&lt;/code&gt;这是加载 caddyfile 配置来启动服务器的。&lt;br/&gt;如果配置使用过 caddy ，配置的 caddyfile 就是在这里被 &lt;code&gt;Loader&lt;/code&gt; 读取后实例化服务器的。如果没有使用过，大致说一下流程，使用 caddy 非常简单，只需配置上文所说的 caddyfile 文件，按行配置选项，然后使用 caddy 运行读取该配置文件即可。简单示例就是以下的文本。&lt;br/&gt;&lt;img src=&quot;https://cdn.nlark.com/yuque/0/2019/png/176280/1564935806821-8e0088dd-7630-426d-84d9-196454d18011.png#align=left&amp;amp;display=inline&amp;amp;height=166&amp;amp;originHeight=166&amp;amp;originWidth=325&amp;amp;size=0&amp;amp;status=done&amp;amp;width=325&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Instance&lt;/code&gt; 是运行操作的实例，可以看到几个主要的操作都是在他身上&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Server&lt;/code&gt; 可以看到拥有 &lt;code&gt;TCP&lt;/code&gt; &lt;code&gt;UDP&lt;/code&gt; 两个 Server 的接口。&lt;/p&gt;
&lt;p&gt;我们首先关心的是 &lt;code&gt;Start()&lt;/code&gt; 启动服务器。&lt;/p&gt;

&lt;h3 id=&quot;启动服务器&quot;&gt;启动服务器&lt;/h3&gt;
&lt;p&gt;发送 StartupEvent, 参照下文中 &lt;a href=&quot;https://www.cnblogs.com/abser/p/11337662.html#Js2Dd&quot;&gt;Event&lt;/a&gt; 理解&lt;/p&gt;
&lt;pre class=&quot;go&quot;&gt;
&lt;code&gt;// Executes Startup events
caddy.EmitEvent(caddy.StartupEvent, nil)&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;读取配置文件：&lt;/p&gt;
&lt;pre class=&quot;go&quot;&gt;
&lt;code&gt;caddyfileinput, err := caddy.LoadCaddyfile(serverType)&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;启动：&lt;/p&gt;
&lt;pre class=&quot;go&quot;&gt;
&lt;code&gt;instance, err := caddy.Start(caddyfileinput)&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;发送 InstanceStartupEvent&lt;/p&gt;
&lt;pre class=&quot;go&quot;&gt;
&lt;code&gt;caddy.EmitEvent(caddy.InstanceStartupEvent, instance&lt;/code&gt;
&lt;/pre&gt;

&lt;h4 id=&quot;caddy.start&quot;&gt;caddy.Start()&lt;/h4&gt;
&lt;p&gt;阅读完代码，画一张图帮助理解&lt;br/&gt;&lt;img src=&quot;https://cdn.nlark.com/yuque/0/2019/png/176280/1564935806862-1d77b3d1-900b-4ee5-8b27-e725e5b7e3fb.png#align=left&amp;amp;display=inline&amp;amp;height=858&amp;amp;originHeight=858&amp;amp;originWidth=652&amp;amp;size=0&amp;amp;status=done&amp;amp;width=652&quot;/&gt;&lt;br/&gt;是不是很简单，来一点更详细的交互&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://cdn.nlark.com/yuque/0/2019/png/176280/1564935806965-993cc208-7980-4cf4-be3e-505ec16d67c3.png#align=left&amp;amp;display=inline&amp;amp;height=847&amp;amp;originHeight=847&amp;amp;originWidth=861&amp;amp;size=0&amp;amp;status=done&amp;amp;width=861&quot;/&gt;&lt;/p&gt;
&lt;p&gt;这里除了 &lt;code&gt;Instance&lt;/code&gt; 之外还有两个新名词&lt;br/&gt; &lt;code&gt;Controller&lt;/code&gt;：它是用来帮助 &lt;code&gt;Directives&lt;/code&gt; 设置它自身的，通过读取 &lt;code&gt;Token&lt;/code&gt;，这里的 &lt;code&gt;Directives&lt;/code&gt; 实际上对应的就是上文所说的 caddyfile 中的配置文件选项。这一点请参照下文中 Loader 下的 &lt;a href=&quot;https://www.cnblogs.com/abser/p/11337662.html#qGe2M&quot;&gt;&lt;code&gt;excuteDirective&lt;/code&gt;&lt;/a&gt; 理解。&lt;br/&gt; &lt;code&gt;Token&lt;/code&gt; ：是 caddy 自己的 词法分析器 解析 caddyfile 配置文件出的选项的标记。这一点请参照下文中 &lt;a href=&quot;https://www.cnblogs.com/abser/p/11337662.html#xFQKc&quot;&gt;Loader&lt;/a&gt; 中的 &lt;a href=&quot;https://www.cnblogs.com/abser/p/11337662.html#vNLTs&quot;&gt;Parser&lt;/a&gt; 理解&lt;/p&gt;
&lt;p&gt;如果不理解，首先记住 caddy 是配置化的服务器，&lt;br/&gt;通过 caddyfile 配置 -&amp;gt;&lt;br/&gt;那么肯定要读取它啦 -&amp;gt;&lt;br/&gt;然后要解析它配置的到底是那些东西 -&amp;gt;&lt;br/&gt;之后呢，就要让配置的目标做到 caddyfile 中声明的更改。&lt;br/&gt;记住这个流程继续看几遍就能理解了。&lt;/p&gt;

&lt;h2 id=&quot;server&quot;&gt;Server&lt;/h2&gt;
&lt;p&gt;在 caddy.go 中定义着 &lt;code&gt;Server&lt;/code&gt; 的接口，同时实现了优雅的退出。我们首先看图了解组织结构&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://cdn.nlark.com/yuque/0/2019/png/176280/1564935807413-c28b60c6-7905-4333-9eab-dc19e0aff7ca.png#align=left&amp;amp;display=inline&amp;amp;height=386&amp;amp;originHeight=386&amp;amp;originWidth=766&amp;amp;size=0&amp;amp;status=done&amp;amp;width=766&quot;/&gt;&lt;/p&gt;
&lt;p&gt;简单看一下 &lt;code&gt;Stopper&lt;/code&gt; 的接口&lt;/p&gt;
&lt;pre class=&quot;go&quot;&gt;
&lt;code&gt;// Stopper is a type that can stop serving. The stop
// does not necessarily have to be graceful.
type Stopper interface {
    // Stop stops the server. It blocks until the
    // server is completely stopped.
    Stop() error
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;a href=&quot;https://sourcegraph.com/github.com/caddyserver/caddy/-/blob/caddy.go#L345:6&quot;&gt;&lt;code&gt;GracefulServer&lt;/code&gt;&lt;/a&gt; 包含 &lt;code&gt;Stopper&lt;/code&gt; 的接口实现了优雅退出，这是拦截了 系统 signal 的信号之后执行的结果，意在意外中断的时候保存好需要保存的东西。&lt;/p&gt;
&lt;p&gt;它同时包含着 WrapListener 函数。可以看出，他用来做中间件。&lt;/p&gt;
&lt;pre class=&quot;go&quot;&gt;
&lt;code&gt;// WrapListener wraps a listener with the
    // listener middlewares configured for this
    // server, if any.
    WrapListener(net.Listener) net.Listener&lt;/code&gt;
&lt;/pre&gt;

&lt;h4 id=&quot;servertype&quot;&gt;ServerType&lt;/h4&gt;
&lt;p&gt;最后看到不同 serverType 生成不同的 server&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://cdn.nlark.com/yuque/0/2019/png/176280/1564935806965-54874cc5-d9fc-4eee-a8b8-edcb20d1bf0c.png#align=left&amp;amp;display=inline&amp;amp;height=715&amp;amp;originHeight=715&amp;amp;originWidth=944&amp;amp;size=0&amp;amp;status=done&amp;amp;width=944&quot;/&gt;&lt;/p&gt;
&lt;p&gt;另外可以看到 这里最重要的 &lt;code&gt;Instance&lt;/code&gt; 下面我们进一步查看 &lt;code&gt;Instance&lt;/code&gt; 的代码&lt;/p&gt;

&lt;h2 id=&quot;instance&quot;&gt;Instance&lt;/h2&gt;
&lt;p&gt;instance 是 Server 用来执行操作的实体。首先来看他的结构。它的代码在 主文件夹中的 &lt;a href=&quot;https://sourcegraph.com/github.com/caddyserver/caddy/-/blob/caddy.go&quot;&gt;caddy.go&lt;/a&gt; 中&lt;/p&gt;
&lt;p&gt;首先我们看一下 它的结构了解下它可能有的功能&lt;/p&gt;

&lt;h4 id=&quot;struct&quot;&gt;&lt;a href=&quot;https://sourcegraph.com/github.com/caddyserver/caddy/-/blob/caddy.go#L93&quot;&gt;struct&lt;/a&gt;&lt;/h4&gt;
&lt;pre class=&quot;go&quot;&gt;
&lt;code&gt;type Instance struct {
    serverType string
    caddyfileInput Input
    wg *sync.WaitGroup
    context Context
    servers []ServerListener
    OnFirstStartup  []func() error // starting, not as part of a restart
    OnStartup       []func() error // starting, even as part of a restart
    OnRestart       []func() error // before restart commences
    OnRestartFailed []func() error // if restart failed
    OnShutdown      []func() error // stopping, even as part of a restart
    OnFinalShutdown []func() error // stopping, not as part of a restart
    Storage   map[interface{}]interface{}
    StorageMu sync.RWMutex
}&lt;/code&gt;
&lt;/pre&gt;

&lt;h5 id=&quot;servertype-代表这个实例的服务器类型通常是-http&quot;&gt;&lt;code&gt;serverType&lt;/code&gt; 代表这个实例的服务器类型，通常是 HTTP&lt;/h5&gt;

&lt;h5 id=&quot;caddyfileinput-是-input-类型通常我们配置-caddy-服务器的时候就是通过编辑-caddyfileinput-的文本实现的修改配置行动值得注意的是生成-instance-的参数同样是-caddyfile这里的-caddyfile-在程序中是一个接口一会儿继续讲解&quot;&gt;&lt;code&gt;caddyfileInput&lt;/code&gt; 是 &lt;code&gt;Input&lt;/code&gt; 类型，通常我们配置 caddy 服务器的时候，就是通过编辑 caddyfileInput 的文本实现的修改配置行动。值得注意的是，生成 &lt;code&gt;Instance&lt;/code&gt; 的参数同样是 caddyfile，这里的 caddyfile 在程序中是一个接口，一会儿继续讲解&lt;/h5&gt;

&lt;h5 id=&quot;wg-是用来等待所有-servers-执行他们操作的信号量&quot;&gt;&lt;code&gt;wg&lt;/code&gt; 是用来等待所有 &lt;code&gt;servers&lt;/code&gt; 执行他们操作的信号量。&lt;/h5&gt;

&lt;h5 id=&quot;context-是实例instance的上下文其中包含-servertype-信息和服务器配置管理状态的信息&quot;&gt;&lt;code&gt;context&lt;/code&gt; 是实例 &lt;code&gt;Instance&lt;/code&gt;的上下文，其中包含 &lt;code&gt;serverType&lt;/code&gt; 信息和服务器配置管理状态的信息。&lt;/h5&gt;

&lt;h5 id=&quot;servers-是一组-server-和-他们的-listeners两种-server-tcpudp即servertype两种不同的servertype会对应不同的caddyfile中的选项&quot;&gt;&lt;code&gt;servers&lt;/code&gt; 是一组 &lt;code&gt;server&lt;/code&gt; 和 他们的 &lt;code&gt;listeners&lt;/code&gt;，两种 Server TCP/UDP，即 &lt;code&gt;serverType&lt;/code&gt; ，两种不同的 &lt;code&gt;serverType&lt;/code&gt; 会对应不同的 &lt;code&gt;caddyfile&lt;/code&gt;中的选项。&lt;/h5&gt;

&lt;h5 id=&quot;onxxx-等-6-个函数是一系列回调函数通过名字能够看出在什么时候回调触发&quot;&gt;&lt;code&gt;OnXXX&lt;/code&gt; 等 6 个函数是一系列回调函数，通过名字能够看出在什么时候回调触发。&lt;/h5&gt;

&lt;h5 id=&quot;storage-是存储数据的地方本来可以设计在-全局状态中但是设计在这里更好考虑到垃圾回收机制进程中重新加载时旧的-instance-be-destroyed-之后会变成垃圾收集这和-12-factor-中的-第九条-disposability-相符合意思是每一次重载实例-instance-即使是在进程中重载也不会出现数据相互影响到情况保持幂等&quot;&gt;&lt;code&gt;Storage&lt;/code&gt; 是存储数据的地方，本来可以设计在 全局状态中，但是设计在这里更好，考虑到垃圾回收机制，进程中重新加载时，旧的 Instance be destroyed 之后，会变成垃圾，收集。这和 &lt;a href=&quot;https://12factor.net/disposability&quot;&gt;12-factor 中的 第九条 Disposability&lt;/a&gt; 相符合。意思是每一次重载实例 Instance 即使是在进程中重载，也不会出现数据相互影响到情况，保持&lt;a href=&quot;https://www.google.com/search?q=%E4%BB%80%E4%B9%88%E6%98%AF%E5%B9%82%E7%AD%89&amp;amp;oq=%E4%BB%80%E4%B9%88%E6%98%AF%E5%B9%82%E7%AD%89&amp;amp;aqs=chrome..69i57.3848j0j7&amp;amp;sourceid=chrome&amp;amp;ie=UTF-8&quot;&gt;幂等&lt;/a&gt;。&lt;/h5&gt;
&lt;p&gt;&lt;img src=&quot;https://cdn.nlark.com/yuque/0/2019/png/176280/1564935807263-da368524-5c69-4f0f-9883-123fb7d5d768.png#align=left&amp;amp;display=inline&amp;amp;height=689&amp;amp;originHeight=689&amp;amp;originWidth=1240&amp;amp;size=0&amp;amp;status=done&amp;amp;width=1240&quot;/&gt;&lt;br/&gt;虽然 Instance 操作着众多操作，但是我们却不能从它讲起，从农村包围城市，渐渐了解 Instance 能调用的函数，自然 Instance 的功能就清晰了。&lt;/p&gt;

&lt;h2 id=&quot;event&quot;&gt;Event&lt;/h2&gt;
&lt;p&gt;首先上图：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://cdn.nlark.com/yuque/0/2019/png/176280/1564935807042-3654ae3a-d231-4190-92f4-e8f17816e309.png#align=left&amp;amp;display=inline&amp;amp;height=438&amp;amp;originHeight=438&amp;amp;originWidth=905&amp;amp;size=0&amp;amp;status=done&amp;amp;width=905&quot;/&gt;&lt;/p&gt;
&lt;p&gt;首先我们看到的是 eventHooks 这个结构，实际上他是存储 &lt;code&gt;key：name value：EventHook&lt;/code&gt; 这样的一个 &lt;code&gt;map[string]EventHook&lt;/code&gt; 的结构，只是从 sync 包中引入保证并发安全。&lt;/p&gt;
&lt;pre class=&quot;go&quot;&gt;
&lt;code&gt;eventHooks = &amp;amp;sync.Map{}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;然后是重要的 &lt;code&gt;caddy.EventHook&lt;/code&gt; 结构。&lt;/p&gt;
&lt;pre class=&quot;go&quot;&gt;
&lt;code&gt;type EventHook func(eventType EventName, eventInfo interface{}) error&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;然后我们关注到如何注册，和图中的 &lt;code&gt;caddy.EmitEvent&lt;/code&gt; &lt;/p&gt;

&lt;h3 id=&quot;注册与分发&quot;&gt;注册与分发&lt;/h3&gt;

&lt;h4 id=&quot;注册-eventhook&quot;&gt;注册 EventHook&lt;/h4&gt;
&lt;p&gt;可以看到使用 &lt;code&gt;eventHooks.LoadOrStore&lt;/code&gt;方法，不必赘述&lt;/p&gt;
&lt;pre class=&quot;go&quot;&gt;
&lt;code&gt;func RegisterEventHook(name string, hook EventHook){
    if name == &quot;&quot; {
        panic(&quot;event hook must have a name&quot;)
    }
    _, dup := eventHooks.LoadOrStore(name, hook)
    if dup {
        panic(&quot;hook named&quot; + name + &quot;already registered&quot;)
    }
}&lt;/code&gt;
&lt;/pre&gt;

&lt;h4 id=&quot;分发-emitevent&quot;&gt;分发 &lt;a href=&quot;https://sourcegraph.com/github.com/caddyserver/caddy/-/blob/plugins.go#L297:6&quot;&gt;EmitEvent&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;通过传入函数为参数调用回调函数&lt;/p&gt;
&lt;pre class=&quot;go&quot;&gt;
&lt;code&gt;// EmitEvent executes the different hooks passing the EventType as an
// argument. This is a blocking function. Hook developers should
// use 'go' keyword if they don't want to block Caddy.
func EmitEvent(event EventName, info interface{}) {
    eventHooks.Range(func(k, v interface{}) bool {
        err := v.(EventHook)(event, info)
        if err != nil {
            log.Printf(&quot;error on '%s' hook: %v&quot;, k.(string), err)
        }
        return true //注意这里返回的是 true
    })
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;这里使用的 &lt;a href=&quot;https://sourcegraph.com/github.com/golang/go@go1.12.5/-/blob/src/sync/map.go#L306:15&quot;&gt;Range&lt;/a&gt;函数，实际上是把事件信息给每一个上述提过 map 中的 EventHook 提供参数进行回调执行，按顺序调用，但是如果 传入函数返回 false ，迭代遍历执行就会中断。&lt;/p&gt;
&lt;p&gt;可以知道，上文 &lt;a href=&quot;https://www.cnblogs.com/abser/p/11337662.html#4HB1R&quot;&gt;Overview中启动服务器&lt;/a&gt; 所说的发送 caddy.StartupEvent 事件就是调用的&lt;/p&gt;
&lt;pre class=&quot;go&quot;&gt;
&lt;code&gt;caddy.EmitEvent(caddy.StartupEvent, nil)&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;讲到这，相信已经对大致的流程有了一点框架的概念。&lt;/p&gt;
&lt;p&gt;下面我们继续深入了解 在读取 &lt;code&gt;caddyfile&lt;/code&gt; 文件的时候发生了什么。&lt;/p&gt;

&lt;h2 id=&quot;loader&quot;&gt;Loader&lt;/h2&gt;
&lt;p&gt;自定义的配置文件都会有读取分析。在 caddy 中 由 &lt;code&gt;Loader&lt;/code&gt; 执行这一项职能。首先我们看一下它的工作流程。&lt;br/&gt;这个图来源于 &lt;a href=&quot;https://sourcegraph.com/github.com/caddyserver/caddy/-/blob/plugins.go#L404:6&quot;&gt;plugin.go&lt;/a&gt; 文件&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://cdn.nlark.com/yuque/0/2019/png/176280/1564935806859-36a63dfe-a085-400a-8210-c8874094296e.png#align=left&amp;amp;display=inline&amp;amp;height=319&amp;amp;originHeight=319&amp;amp;originWidth=642&amp;amp;size=0&amp;amp;status=done&amp;amp;width=642&quot;/&gt;&lt;/p&gt;
&lt;p&gt;可以看到这里通过 &lt;code&gt;Loader&lt;/code&gt; 解耦了 caddyfile 文件的读取，所以把它放在了 plugin.go 文件中，作为一个插件注册在 caddy app 中。&lt;br/&gt;这里可以看到最终流程是 name -&amp;gt; &lt;code&gt;caddy.Input&lt;/code&gt; 那么这个 &lt;a href=&quot;https://sourcegraph.com/github.com/caddyserver/caddy/-/blob/caddy.go#L979:6&quot;&gt;&lt;code&gt;Input&lt;/code&gt;&lt;/a&gt; 是什么呢？&lt;br/&gt;实际上 &lt;code&gt;Input&lt;/code&gt; 就是 caddyfile 在代码中的映射。可以理解为，caddyfile 转化为了 &lt;code&gt;Input&lt;/code&gt; 给 caddy 读取。谁来读取它呢？&lt;br/&gt;那么干活的主角登场啦！&lt;/p&gt;

&lt;h3 id=&quot;parser&quot;&gt;&lt;a href=&quot;https://sourcegraph.com/github.com/caddyserver/caddy/-/blob/caddyfile/parse.go&quot;&gt;Parser&lt;/a&gt;&lt;/h3&gt;

&lt;h3 id=&quot;section&quot;&gt;&lt;img src=&quot;https://cdn.nlark.com/yuque/0/2019/png/176280/1564935807562-822cf30b-e86d-4e6e-ae1b-8bb0e2c27ba2.png#align=left&amp;amp;display=inline&amp;amp;height=743&amp;amp;originHeight=743&amp;amp;originWidth=1042&amp;amp;size=0&amp;amp;status=done&amp;amp;width=1042&quot;/&gt;&lt;/h3&gt;
&lt;p&gt;这里我们来看，各个流程的终点 &lt;code&gt;Token&lt;/code&gt; 是如何被分析出来的,需要知道，这里的 &lt;code&gt;Token&lt;/code&gt; 代表着 caddyfile 中的每行选项配置&lt;/p&gt;

&lt;h4 id=&quot;词法分析&quot;&gt;词法分析&lt;/h4&gt;
&lt;pre class=&quot;go&quot;&gt;
&lt;code&gt;// allTokens lexes the entire input, but does not parse it.
// It returns all the tokens from the input, unstructured
// and in order.
func allTokens(input io.Reader) ([]Token, error) {
    l := new(lexer)
    err := l.load(input)
    if err != nil {
        return nil, err
    }
    var tokens []Token
    for l.next() {
        tokens = append(tokens, l.token)
    }
    return tokens, nil
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;这里实际上关键在于 读取，可以看到在 &lt;code&gt;dispenser&lt;/code&gt; 中由 &lt;code&gt;cursor&lt;/code&gt; 来进行 &lt;code&gt;Token&lt;/code&gt; 数组中的迭代&lt;br/&gt;关键在于移动 &lt;code&gt;cursor&lt;/code&gt; 索引的函数&lt;br/&gt;&lt;a href=&quot;https://sourcegraph.com/github.com/caddyserver/caddy/-/blob/caddyfile/lexer.go#L73:17&quot;&gt;&lt;code&gt;next()&lt;/code&gt;&lt;/a&gt;&lt;/p&gt;
&lt;pre class=&quot;go&quot;&gt;
&lt;code&gt;// next loads the next token into the lexer.
// A token is delimited by whitespace, unless
// the token starts with a quotes character (&quot;)
// in which case the token goes until the closing
// quotes (the enclosing quotes are not included).
// Inside quoted strings, quotes may be escaped
// with a preceding \ character. No other chars
// may be escaped. The rest of the line is skipped
// if a &quot;#&quot; character is read in. Returns true if
// a token was loaded; false otherwise.
func (l *lexer) next() bool {
    var val []rune
    var comment, quoted, escaped bool

    makeToken := func() bool {
        l.token.Text = string(val)
        return true
    }

    for {
        ch, _, err := l.reader.ReadRune()
        if err != nil {
            if len(val) &amp;gt; 0 {
                return makeToken()
            }
            if err == io.EOF {
                return false
            }
            panic(err)
        }

        if quoted {
            if !escaped {
                if ch == '\\' {
                    escaped = true
                    continue
                } else if ch == '&quot;' {
                    quoted = false
                    return makeToken()
                }
            }
            if ch == '\n' {
                l.line++
            }
            if escaped {
                // only escape quotes
                if ch != '&quot;' {
                    val = append(val, '\\')
                }
            }
            val = append(val, ch)
            escaped = false
            continue
        }

        if unicode.IsSpace(ch) {
            if ch == '\r' {
                continue
            }
            if ch == '\n' {
                l.line++
                comment = false
            }
            if len(val) &amp;gt; 0 {
                return makeToken()
            }
            continue
        }

        if ch == '#' {
            comment = true
        }

        if comment {
            continue
        }

        if len(val) == 0 {
            l.token = Token{Line: l.line}
            if ch == '&quot;' {
                quoted = true
                continue
            }
        }

        val = append(val, ch)
    }
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;理解了 &lt;code&gt;next&lt;/code&gt; 函数，就很容易知道如何分析一块选项的 &lt;code&gt;token&lt;/code&gt; 了，不过都是 &lt;code&gt;next()&lt;/code&gt; 的包装函数罢了。&lt;/p&gt;

&lt;h3 id=&quot;excutedirective&quot;&gt;&lt;a href=&quot;https://sourcegraph.com/github.com/caddyserver/caddy/-/blob/caddy.go#L624:6&quot;&gt;excuteDirective&lt;/a&gt;&lt;/h3&gt;
&lt;pre class=&quot;go&quot;&gt;
&lt;code&gt;func executeDirectives(inst *Instance, filename string,
    directives []string, sblocks []caddyfile.ServerBlock, justValidate bool) error {
    // map of server block ID to map of directive name to whatever.
    storages := make(map[int]map[string]interface{})

    // It is crucial that directives are executed in the proper order.
    // We loop with the directives on the outer loop so we execute
    // a directive for all server blocks before going to the next directive.
    // This is important mainly due to the parsing callbacks (below).
    for _, dir := range directives {
        for i, sb := range sblocks {
            var once sync.Once
            if _, ok := storages[i]; !ok {
                storages[i] = make(map[string]interface{})
            }

            for j, key := range sb.Keys {
                // Execute directive if it is in the server block
                if tokens, ok := sb.Tokens[dir]; ok {
                    controller := &amp;amp;Controller{
                        instance:  inst,
                        Key:       key,
                        Dispenser: caddyfile.NewDispenserTokens(filename, tokens),
                        OncePerServerBlock: func(f func() error) error {
                            var err error
                            once.Do(func() {
                                err = f()
                            })
                            return err
                        },
                        ServerBlockIndex:    i,
                        ServerBlockKeyIndex: j,
                        ServerBlockKeys:     sb.Keys,
                        ServerBlockStorage:  storages[i][dir],
                    }

                    setup, err := DirectiveAction(inst.serverType, dir)
                    if err != nil {
                        return err
                    }

                    err = setup(controller)
                    if err != nil {
                        return err
                    }

                    storages[i][dir] = controller.ServerBlockStorage // persist for this server block
                }
            }
        }

        if !justValidate {
            // See if there are any callbacks to execute after this directive
            if allCallbacks, ok := parsingCallbacks[inst.serverType]; ok {
                callbacks := allCallbacks[dir]
                for _, callback := range callbacks {
                    if err := callback(inst.context); err != nil {
                        return err
                    }
                }
            }
        }
    }

    return nil
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;caddyfile 既然被解析完毕，那么就要开始执行配置更改了，这里实际上是 caddy.go 中的 函数，最后在 caddy 的 main.go 中调用来执行更改。&lt;/p&gt;

&lt;h3 id=&quot;directiveaction&quot;&gt;DirectiveAction&lt;/h3&gt;

&lt;h3 id=&quot;section-1&quot;&gt;&lt;img src=&quot;https://cdn.nlark.com/yuque/0/2019/png/176280/1564935806823-6ae5b1b9-1dfa-4c6e-b896-4324a91db2f8.png#align=left&amp;amp;display=inline&amp;amp;height=453&amp;amp;originHeight=453&amp;amp;originWidth=943&amp;amp;size=0&amp;amp;status=done&amp;amp;width=943&quot;/&gt;&lt;/h3&gt;
&lt;p&gt;很容易发现，这里是通过 操作 Controller 来实现的，此时可以再返回最上文查看上一次提到 Controller 的时候。&lt;/p&gt;
&lt;pre class=&quot;go&quot;&gt;
&lt;code&gt;// DirectiveAction gets the action for directive dir of
// server type serverType.
func DirectiveAction(serverType, dir string) (SetupFunc, error) {
    if stypePlugins, ok := plugins[serverType]; ok {
        if plugin, ok := stypePlugins[dir]; ok {
            return plugin.Action, nil
        }
    }
    if genericPlugins, ok := plugins[&quot;&quot;]; ok {
        if plugin, ok := genericPlugins[dir]; ok {
            return plugin.Action, nil
        }
    }
    return nil, fmt.Errorf(&quot;no action found for directive '%s' with server type '%s' (missing a plugin?)&quot;,
        dir, serverType)
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;了解完这些，我们注意到有一个 叫做 &lt;code&gt;Action&lt;/code&gt; 的东西，它又是怎么来的？别急，他就在 &lt;code&gt;Plugin&lt;/code&gt; 包中。我们知道了，配置文件实际上是配置各种 &lt;code&gt;plugin&lt;/code&gt; 作为插件安装在 caddy 服务器上，而 caddyfile 正是被转化为了 Token，Dispenser 来执行配置更改，即不同的插件安装。那么 &lt;code&gt;Action&lt;/code&gt; 就是 &lt;code&gt;Plugin&lt;/code&gt; 的 &lt;code&gt;SetupFunc&lt;/code&gt;啦，来看看吧。&lt;/p&gt;

&lt;h2 id=&quot;plugin&quot;&gt;Plugin&lt;/h2&gt;
&lt;p&gt;你会注意到，在目录中有一个 叫 caddyhttp 的文件夹中的文件夹特别多，不用问，这就是 http 的可选 &lt;code&gt;Plugin&lt;/code&gt; 啦&lt;/p&gt;

&lt;h3 id=&quot;overview&quot;&gt;Overview&lt;/h3&gt;
&lt;p&gt;这里概览了 &lt;code&gt;Plugin&lt;/code&gt; 是如何注册的。&lt;br/&gt;&lt;img src=&quot;https://cdn.nlark.com/yuque/0/2019/png/176280/1564935806939-e9426b47-48f7-456c-b0fb-77ef8e325461.png#align=left&amp;amp;display=inline&amp;amp;height=727&amp;amp;originHeight=727&amp;amp;originWidth=1032&amp;amp;size=0&amp;amp;status=done&amp;amp;width=1032&quot;/&gt;&lt;/p&gt;
&lt;p&gt;可以在这里看到我们之前讲解的很多的熟悉的概念，这是因为我们快要读完 caddy 的架构了，剩下的实际上是具体的 &lt;code&gt;Plugin&lt;/code&gt; 的各种扩展实现了。&lt;br/&gt;可以看到，&lt;code&gt;Plugin&lt;/code&gt; 是注册在不同的 服务器类型 &lt;code&gt;serverType&lt;/code&gt; 下的，实际上是在两重 map 映射的结构中，图中可以看出，然后是 &lt;code&gt;Action&lt;/code&gt; ，最近的上文才说明了它，用它来进行 &lt;code&gt;Plugin&lt;/code&gt; 的安装。&lt;br/&gt;然后来到 &lt;code&gt;Controller&lt;/code&gt; ，实际进行配置的家伙，看到了之前所说的 &lt;code&gt;Dispenser&lt;/code&gt; 和 &lt;code&gt;Token&lt;/code&gt; 配置，还记得吗，他们在刚才的词法分析里才出现过。&lt;/p&gt;
&lt;p&gt;接下来我们看一个 &lt;code&gt;HTTP&lt;/code&gt; 的 &lt;code&gt;Plugin&lt;/code&gt; 的例子 &lt;code&gt;errors&lt;/code&gt; 的实现&lt;/p&gt;

&lt;h3 id=&quot;caddyhttp&quot;&gt;caddyHTTP&lt;/h3&gt;

&lt;h4 id=&quot;errors&quot;&gt;errors&lt;/h4&gt;
&lt;p&gt;&lt;img src=&quot;https://cdn.nlark.com/yuque/0/2019/png/176280/1564935807283-f07d9e59-a33f-4ab9-b259-490b25014154.png#align=left&amp;amp;display=inline&amp;amp;height=694&amp;amp;originHeight=694&amp;amp;originWidth=940&amp;amp;size=0&amp;amp;status=done&amp;amp;width=940&quot;/&gt;&lt;/p&gt;
&lt;p&gt;这里我们从下看，&lt;a href=&quot;https://sourcegraph.com/github.com/caddyserver/caddy/-/blob/caddy.go#L367:15&quot;&gt;caddy.Listener&lt;/a&gt; 定义在 caddy.go 中，用来支持 零停机时间加载。&lt;/p&gt;
&lt;p&gt;往上看到 Middleware 调用，我们来看看 errorsHandle 的结构&lt;/p&gt;
&lt;pre class=&quot;go&quot;&gt;
&lt;code&gt;// ErrorHandler handles HTTP errors (and errors from other middleware).
type ErrorHandler struct {
    Next             httpserver.Handler
    GenericErrorPage string         // default error page filename
    ErrorPages       map[int]string // map of status code to filename
    Log              *httpserver.Logger
    Debug            bool // if true, errors are written out to client rather than to a log
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;可以看到，Next 字段明显是 Chain 调用的下一个 Handler 处理。事实上，每一个 Plugin 或者算是 HTTP 服务中的中间件都有这个字段用于 构建链式调用。&lt;/p&gt;
&lt;p&gt;每一个 Plugin 值得注意的两个，&lt;br/&gt;一个是他们会实现 ServeHTTP 接口进行 HTTP 请求处理。&lt;/p&gt;
&lt;pre class=&quot;go&quot;&gt;
&lt;code&gt;func (h ErrorHandler) ServeHTTP(w http.ResponseWriter, r *http.Request) (int, error) {
    defer h.recovery(w, r)

    status, err := h.Next.ServeHTTP(w, r)

    if err != nil {
        errMsg := fmt.Sprintf(&quot;%s [ERROR %d %s] %v&quot;, time.Now().Format(timeFormat), status, r.URL.Path, err)
        if h.Debug {
            // Write error to response instead of to log
            w.Header().Set(&quot;Content-Type&quot;, &quot;text/plain; charset=utf-8&quot;)
            w.WriteHeader(status)
            fmt.Fprintln(w, errMsg)
            return 0, err // returning 0 signals that a response has been written
        }
        h.Log.Println(errMsg)
    }

    if status &amp;gt;= 400 {
        h.errorPage(w, r, status)
        return 0, err
    }

    return status, err
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;另一个是安装到 caddy 中的 &lt;a href=&quot;https://sourcegraph.com/github.com/caddyserver/caddy/-/blob/caddyhttp/errors/setup.go&quot;&gt;setup.go&lt;/a&gt; 文件，我们看一下 Plugin 安装的全流程。&lt;/p&gt;

&lt;h3 id=&quot;directives&quot;&gt;Directives&lt;/h3&gt;
&lt;p&gt;前面提到过很多次 Directives 这里做一个它的整个流程概览。上文中提到，这些注册实际上都是 Controller 执行的。下半部分是 关于 HTTP 的服务配置&lt;br/&gt;这里的重点在 errors.serup() 可以看到，它创建了 errors.ErrHandler 并注册到了 httpserver 的一对中间件中&lt;/p&gt;
&lt;pre class=&quot;go&quot;&gt;
&lt;code&gt;// setup configures a new errors middleware instance.
func setup(c *caddy.Controller) error {
    handler, err := errorsParse(c)
    ···
    httpserver.GetConfig(c).AddMiddleware(func(next httpserver.Handler) httpserver.Handler {
        handler.Next = next
        return handler
    })
    return nil
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;实际上这里还有一个关于 caddy.Controller 到 ErrorHandler 的一个转换 通过 &lt;a href=&quot;https://sourcegraph.com/github.com/caddyserver/caddy/-/blob/caddyhttp/errors/setup.go#L52:1&quot;&gt;errorsParse&lt;/a&gt; 函数&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://cdn.nlark.com/yuque/0/2019/png/176280/1564935807173-ebe470e1-2eff-440c-a88c-5bc62681a3da.png#align=left&amp;amp;display=inline&amp;amp;height=846&amp;amp;originHeight=846&amp;amp;originWidth=837&amp;amp;size=0&amp;amp;status=done&amp;amp;width=837&quot;/&gt;&lt;/p&gt;
&lt;p&gt;谢谢阅读，如果有不对的地方欢迎指正。&lt;/p&gt;
</description>
<pubDate>Mon, 12 Aug 2019 00:20:00 +0000</pubDate>
<dc:creator>abser</dc:creator>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/abser/p/11337662.html</dc:identifier>
</item>
<item>
<title>Flink 源码解析 —— 深度解析 Flink 是如何管理好内存的？ - zhisheng_tian</title>
<link>http://www.cnblogs.com/zhisheng/p/11337650.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/zhisheng/p/11337650.html</guid>
<description>&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/860214/201908/860214-20190812081250279-2058876417.jpg&quot;/&gt;&lt;/p&gt;
&lt;h3 id=&quot;前言&quot;&gt;前言&lt;/h3&gt;
&lt;p&gt;如今，许多用于分析大型数据集的开源系统都是用 Java 或者是基于 JVM 的编程语言实现的。最着名的例子是 Apache Hadoop，还有较新的框架，如 Apache Spark、Apache Drill、Apache Flink。基于 JVM 的数据分析引擎面临的一个常见挑战就是如何在内存中存储大量的数据（包括缓存和高效处理）。合理的管理好 JVM 内存可以将 难以配置且不可预测的系统 与 少量配置且稳定运行的系统区分开来。&lt;/p&gt;
&lt;p&gt;在这篇文章中，我们将讨论 Apache Flink 如何管理内存，讨论其自定义序列化与反序列化机制，以及它是如何操作二进制数据的。&lt;/p&gt;
&lt;h3 id=&quot;数据对象直接放在堆内存中&quot;&gt;数据对象直接放在堆内存中&lt;/h3&gt;
&lt;p&gt;在 JVM 中处理大量数据最直接的方式就是将这些数据做为对象存储在堆内存中，然后直接在内存中操作这些数据，如果想进行排序则就是对对象列表进行排序。然而这种方法有一些明显的缺点，首先，在频繁的创建和销毁大量对象的时候，监视和控制堆内存的使用并不是一件很简单的事情。如果对象分配过多的话，那么会导致内存过度使用，从而触发 OutOfMemoryError，导致 JVM 进程直接被杀死。另一个方面就是因为这些对象大都是生存在新生代，当 JVM 进行垃圾回收时，垃圾收集的开销很容易达到 50% 甚至更多。最后就是 Java 对象具有一定的空间开销（具体取决于 JVM 和平台）。对于具有许多小对象的数据集，这可以显著减少有效可用的内存量。如果你精通系统设计和系统调优，你可以根据系统进行特定的参数调整，可以或多或少的控制出现 OutOfMemoryError 的次数和避免堆内存的过多使用，但是这种设置和调优的作用有限，尤其是在数据量较大和执行环境发生变化的情况下。&lt;/p&gt;
&lt;h3 id=&quot;flink-是怎么做的&quot;&gt;Flink 是怎么做的?&lt;/h3&gt;
&lt;p&gt;Apache Flink 起源于一个研究项目，该项目旨在结合基于 MapReduce 的系统和并行数据库系统的最佳技术。在此背景下，Flink 一直有自己的内存数据处理方法。Flink 将对象序列化为固定数量的预先分配的内存段，而不是直接把对象放在堆内存上。它的 DBMS 风格的排序和连接算法尽可能多地对这个二进制数据进行操作，以此将序列化和反序列化开销降到最低。如果需要处理的数据多于可以保存在内存中的数据，Flink 的运算符会将部分数据溢出到磁盘。事实上，很多Flink 的内部实现看起来更像是 C / C ++，而不是普通的 Java。下图概述了 Flink 如何在内存段中存储序列化数据并在必要时溢出到磁盘：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/860214/201908/860214-20190812081251257-1732297859.jpg&quot;/&gt;&lt;/p&gt;
&lt;p&gt;Flink 的主动内存管理和操作二进制数据有几个好处：&lt;/p&gt;
&lt;p&gt;1、&lt;strong&gt;内存安全执行和高效的核外算法&lt;/strong&gt; 由于分配的内存段的数量是固定的，因此监控剩余的内存资源是非常简单的。在内存不足的情况下，处理操作符可以有效地将更大批的内存段写入磁盘，后面再将它们读回到内存。因此，OutOfMemoryError 就有效的防止了。&lt;/p&gt;
&lt;p&gt;2、&lt;strong&gt;减少垃圾收集压力&lt;/strong&gt; 因为所有长生命周期的数据都是在 Flink 的管理内存中以二进制表示的，所以所有数据对象都是短暂的，甚至是可变的，并且可以重用。短生命周期的对象可以更有效地进行垃圾收集，这大大降低了垃圾收集的压力。现在，预先分配的内存段是 JVM 堆上的长期存在的对象，为了降低垃圾收集的压力，Flink 社区正在积极地将其分配到堆外内存。这种努力将使得 JVM 堆变得更小，垃圾收集所消耗的时间将更少。&lt;/p&gt;
&lt;p&gt;3、&lt;strong&gt;节省空间的数据存储&lt;/strong&gt; Java 对象具有存储开销，如果数据以二进制的形式存储，则可以避免这种开销。&lt;/p&gt;
&lt;p&gt;4、&lt;strong&gt;高效的二进制操作和缓存敏感性&lt;/strong&gt; 在给定合适的二进制表示的情况下，可以有效地比较和操作二进制数据。此外，二进制表示可以将相关值、哈希码、键和指针等相邻地存储在内存中。这使得数据结构通常具有更高效的缓存访问模式。&lt;/p&gt;
&lt;p&gt;主动内存管理的这些特性在用于大规模数据分析的数据处理系统中是非常可取的，但是要实现这些功能的代价也是高昂的。要实现对二进制数据的自动内存管理和操作并非易事，使用 &lt;code&gt;java.util.HashMap&lt;/code&gt; 比实现一个可溢出的 &lt;code&gt;hash-table&lt;/code&gt; （由字节数组和自定义序列化支持）。当然，Apache Flink 并不是唯一一个基于 JVM 且对二进制数据进行操作的数据处理系统。例如 Apache Drill、Apache Ignite、Apache Geode 也有应用类似技术，最近 Apache Spark 也宣布将向这个方向演进。&lt;/p&gt;
&lt;p&gt;下面我们将详细讨论 Flink 如何分配内存、如果对对象进行序列化和反序列化以及如果对二进制数据进行操作。我们还将通过一些性能表现数据来比较处理堆内存上的对象和对二进制数据的操作。&lt;/p&gt;
&lt;h3 id=&quot;flink-如何分配内存&quot;&gt;Flink 如何分配内存?&lt;/h3&gt;
&lt;p&gt;Flink TaskManager 是由几个内部组件组成的：actor 系统（负责与 Flink master 协调）、IOManager（负责将数据溢出到磁盘并将其读取回来）、MemoryManager（负责协调内存使用）。在本篇文章中，我们主要讲解 MemoryManager。&lt;/p&gt;
&lt;p&gt;MemoryManager 负责将 MemorySegments 分配、计算和分发给数据处理操作符，例如 sort 和 join 等操作符。MemorySegment 是 Flink 的内存分配单元，由常规 Java 字节数组支持(默认大小为 32 KB)。MemorySegment 通过使用 Java 的 unsafe 方法对其支持的字节数组提供非常有效的读写访问。你可以将 MemorySegment 看作是 Java 的 NIO ByteBuffer 的定制版本。为了在更大的连续内存块上操作多个 MemorySegment，Flink 使用了实现 Java 的 java.io.DataOutput 和 java.io.DataInput 接口的逻辑视图。&lt;/p&gt;
&lt;p&gt;MemorySegments 在 TaskManager 启动时分配一次，并在 TaskManager 关闭时销毁。因此，在 TaskManager 的整个生命周期中，MemorySegment 是重用的，而不会被垃圾收集的。在初始化 TaskManager 的所有内部数据结构并且已启动所有核心服务之后，MemoryManager 开始创建 MemorySegments。默认情况下，服务初始化后，70％ 可用的 JVM 堆内存由 MemoryManager 分配（也可以配置全部）。剩余的 JVM 堆内存用于在任务处理期间实例化的对象，包括由用户定义的函数创建的对象。下图显示了启动后 TaskManager JVM 中的内存分布：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/860214/201908/860214-20190812081251988-1898440449.jpg&quot;/&gt;&lt;/p&gt;
&lt;h3 id=&quot;flink-如何序列化对象&quot;&gt;Flink 如何序列化对象？&lt;/h3&gt;
&lt;p&gt;Java 生态系统提供了几个库，可以将对象转换为二进制表示形式并返回。常见的替代方案是标准 Java 序列化，Kryo，Apache Avro，Apache Thrift 或 Google 的 Protobuf。Flink 包含自己的自定义序列化框架，以便控制数据的二进制表示。这一点很重要，因为对二进制数据进行操作需要对序列化布局有准确的了解。此外，根据在二进制数据上执行的操作配置序列化布局可以显著提升性能。Flink 的序列化机制利用了这一特性，即在执行程序之前，要序列化和反序列化的对象的类型是完全已知的。&lt;/p&gt;
&lt;p&gt;Flink 程序可以处理表示为任意 Java 或 Scala 对象的数据。在优化程序之前，需要识别程序数据流的每个处理步骤中的数据类型。对于 Java 程序，Flink 提供了一个基于反射的类型提取组件，用于分析用户定义函数的返回类型。Scala 程序可以在 Scala 编译器的帮助下进行分析。Flink 使用 TypeInformation 表示每种数据类型。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/860214/201908/860214-20190812081252970-736773634.jpg&quot; alt=&quot;Flink 类型分类&quot;/&gt;&lt;/p&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;注：该图选自董伟柯的文章《Apache Flink 类型和序列化机制简介》，侵删&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Flink 有如下几种数据类型的 TypeInformations：&lt;/p&gt;
&lt;ul readability=&quot;5&quot;&gt;&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;BasicTypeInfo：所有 Java 的基础类型或 java.lang.String&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;BasicArrayTypeInfo：Java 基本类型构成的数组或 java.lang.String&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;WritableTypeInfo：Hadoop 的 Writable 接口的任何实现&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;TupleTypeInfo：任何 Flink tuple（Tuple1 到 Tuple25）。Flink tuples 是具有类型化字段的固定长度元组的 Java 表示&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;CaseClassTypeInfo：任何 Scala CaseClass（包括 Scala tuples）&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;PojoTypeInfo：任何 POJO（Java 或 Scala），即所有字段都是 public 的或通过 getter 和 setter 访问的对象，遵循通用命名约定&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;GenericTypeInfo：不能标识为其他类型的任何数据类型&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/860214/201908/860214-20190812081253680-1458702596.jpg&quot; alt=&quot;TypeInformation 类继承关系图&quot;/&gt;&lt;/p&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;注：该图选自董伟柯的文章《Apache Flink 类型和序列化机制简介》，侵删&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;每个 TypeInformation 都为它所代表的数据类型提供了一个序列化器。例如，BasicTypeInfo 返回一个序列化器，该序列化器写入相应的基本类型；WritableTypeInfo 的序列化器将序列化和反序列化委托给实现 Hadoop 的 Writable 接口的对象的 write() 和 readFields() 方法；GenericTypeInfo 返回一个序列化器，该序列化器将序列化委托给 Kryo。对象将自动通过 Java 中高效的 Unsafe 方法来序列化到 Flink MemorySegments 支持的 DataOutput。对于可用作键的数据类型，例如哈希值，TypeInformation 提供了 TypeComparators，TypeComparators 比较和哈希对象，并且可以根据具体的数据类型有效的比较二进制并提取固定长度的二进制 key 前缀。&lt;/p&gt;
&lt;p&gt;Tuple，Pojo 和 CaseClass 类型是复合类型，它们可能嵌套一个或者多个数据类型。因此，它们的序列化和比较也都比较复杂，一般将其成员数据类型的序列化和比较都交给各自的 Serializers（序列化器） 和 Comparators（比较器）。下图说明了 &lt;code&gt;Tuple3&amp;lt;Integer, Double, Person&amp;gt;&lt;/code&gt;对象的序列化，其中&lt;code&gt;Person&lt;/code&gt; 是 POJO 并定义如下：&lt;/p&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;public class Person {
    public int id;
    public String name;
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/860214/201908/860214-20190812081254671-65840501.jpg&quot;/&gt;&lt;/p&gt;
&lt;p&gt;通过提供定制的 TypeInformations、Serializers（序列化器） 和 Comparators（比较器），可以方便地扩展 Flink 的类型系统，从而提高序列化和比较自定义数据类型的性能。&lt;/p&gt;
&lt;h3 id=&quot;flink-如何对二进制数据进行操作&quot;&gt;Flink 如何对二进制数据进行操作？&lt;/h3&gt;
&lt;p&gt;与其他的数据处理框架的 API（包括 SQL）类似，Flink 的 API 也提供了对数据集进行分组、排序和连接等转换操作。这些转换操作的数据集可能非常大。关系数据库系统具有非常高效的算法，比如 merge-sort、merge-join 和 hash-join。Flink 建立在这种技术的基础上，但是主要分为使用自定义序列化和自定义比较器来处理任意对象。在下面文章中我们将通过 Flink 的内存排序算法示例演示 Flink 如何使用二进制数据进行操作。&lt;/p&gt;
&lt;p&gt;Flink 为其数据处理操作符预先分配内存，初始化时，排序算法从 MemoryManager 请求内存预算，并接收一组相应的 MemorySegments。这些 MemorySegments 变成了缓冲区的内存池，缓冲区中收集要排序的数据。下图说明了如何将数据对象序列化到排序缓冲区中：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/860214/201908/860214-20190812081255467-1911447881.jpg&quot;/&gt;&lt;/p&gt;
&lt;p&gt;排序缓冲区在内部分为两个内存区域：第一个区域保存所有对象的完整二进制数据，第二个区域包含指向完整二进制对象数据的指针（取决于 key 的数据类型）。将对象添加到排序缓冲区时，它的二进制数据会追加到第一个区域，指针(可能还有一个 key)被追加到第二个区域。分离实际数据和指针以及固定长度的 key 有两个目的：它可以有效的交换固定长度的 entries（key 和指针），还可以减少排序时需要移动的数据。如果排序的 key 是可变长度的数据类型（比如 String），则固定长度的排序 key 必须是前缀 key，比如字符串的前 n 个字符。请注意：并非所有数据类型都提供固定长度的前缀排序 key。将对象序列化到排序缓冲区时，两个内存区域都使用内存池中的 MemorySegments 进行扩展。一旦内存池为空且不能再添加对象时，则排序缓冲区将会被完全填充并可以进行排序。Flink 的排序缓冲区提供了比较和交换元素的方法，这使得实际的排序算法是可插拔的。默认情况下， Flink 使用了 Quicksort（快速排序）实现，可以使用 HeapSort（堆排序）。下图显示了如何比较两个对象：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/860214/201908/860214-20190812081256242-802285446.jpg&quot;/&gt;&lt;/p&gt;
&lt;p&gt;排序缓冲区通过比较它们的二进制固定长度排序 key 来比较两个元素。如果元素的完整 key（不是前缀 key） 或者二进制前缀 key 不相等，则代表比较成功。如果前缀 key 相等(或者排序 key 的数据类型不提供二进制前缀 key)，则排序缓冲区遵循指向实际对象数据的指针，对两个对象进行反序列化并比较对象。根据比较结果，排序算法决定是否交换比较的元素。排序缓冲区通过移动其固定长度 key 和指针来交换两个元素，实际数据不会移动，排序算法完成后，排序缓冲区中的指针被正确排序。下图演示了如何从排序缓冲区返回已排序的数据：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/860214/201908/860214-20190812081257108-581585768.jpg&quot;/&gt;&lt;/p&gt;
&lt;p&gt;通过顺序读取排序缓冲区的指针区域，跳过排序 key 并按照实际数据的排序指针返回排序数据。此数据要么反序列化并作为对象返回，要么在外部合并排序的情况下复制二进制数据并将其写入磁盘。&lt;/p&gt;
&lt;h3 id=&quot;基准测试数据&quot;&gt;基准测试数据&lt;/h3&gt;
&lt;p&gt;那么，对二进制数据进行操作对性能意味着什么？我们将运行一个基准测试，对 1000 万个&lt;code&gt;Tuple2&amp;lt;Integer, String&amp;gt;&lt;/code&gt;对象进行排序以找出答案。整数字段的值从均匀分布中采样。String 字段值的长度为 12 个字符，并从长尾分布中进行采样。输入数据由返回可变对象的迭代器提供，即返回具有不同字段值的相同 Tuple 对象实例。Flink 在从内存，网络或磁盘读取数据时使用此技术，以避免不必要的对象实例化。基准测试在具有 900 MB 堆大小的 JVM 中运行，在堆上存储和排序 1000 万个 Tuple 对象并且不会导致触发 OutOfMemoryError 大约需要这么大的内存。我们使用三种排序方法在Integer 字段和 String 字段上对 Tuple 对象进行排序：&lt;/p&gt;
&lt;p&gt;1、&lt;strong&gt;对象存在堆中&lt;/strong&gt;：Tuple 对象存储在常用的 &lt;code&gt;java.util.ArrayList&lt;/code&gt; 中，初始容量设置为 1000 万，并使用 Java 中常用的集合排序进行排序。&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;&lt;strong&gt;Flink 序列化&lt;/strong&gt;：使用 Flink 的自定义序列化程序将 Tuple 字段序列化为 600 MB 大小的排序缓冲区，如上所述排序，最后再次反序列化。在 Integer 字段上进行排序时，完整的 Integer 用作排序 key，以便排序完全发生在二进制数据上（不需要对象的反序列化）。对于 String 字段的排序，使用 8 字节前缀 key，如果前缀 key 相等，则对 Tuple 对象进行反序列化。&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;3、&lt;strong&gt;Kryo 序列化&lt;/strong&gt;：使用 Kryo 序列化将 Tuple 字段序列化为 600 MB 大小的排序缓冲区，并在没有二进制排序 key 的情况下进行排序。这意味着每次比较需要对两个对象进行反序列化。&lt;/p&gt;
&lt;p&gt;所有排序方法都使用单线程实现。结果的时间是十次运行结果的平均值。在每次运行之后，我们调用&lt;code&gt;System.gc()&lt;/code&gt;请求垃圾收集运行，该运行不会进入测量的执行时间。下图显示了将输入数据存储在内存中，对其进行排序并将其作为对象读回的时间。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/860214/201908/860214-20190812081257618-112159736.jpg&quot;/&gt;&lt;/p&gt;
&lt;p&gt;我们看到 Flink 使用自己的序列化器对二进制数据进行排序明显优于其他两种方法。与存储在堆内存上相比，我们看到将数据加载到内存中要快得多。因为我们实际上是在收集对象，没有机会重用对象实例，但必须重新创建每个 Tuple。这比 Flink 的序列化器（或Kryo序列化）效率低。另一方面，与反序列化相比，从堆中读取对象是无性能消耗的。在我们的基准测试中，对象克隆比序列化和反序列化组合更耗性能。查看排序时间，我们看到对二进制数据的排序也比 Java 的集合排序更快。使用没有二进制排序 key 的 Kryo 序列化的数据排序比其他方法慢得多。这是因为反序列化带来很大的开销。在String 字段上对 Tuple 进行排序比在 Integer 字段上排序更快，因为长尾值分布显着减少了成对比较的数量。为了更好地了解排序过程中发生的状况，我们使用 VisualVM 监控执行的 JVM。以下截图显示了执行 10次 运行时的堆内存使用情况、垃圾收集情况和 CPU 使用情况。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/860214/201908/860214-20190812081258378-1627716453.jpg&quot;/&gt;&lt;/p&gt;
&lt;p&gt;测试是在 8 核机器上运行单线程，因此一个核心的完全利用仅对应 12.5％ 的总体利用率。截图显示，对二进制数据进行操作可显著减少垃圾回收活动。对于对象存在堆中，垃圾收集器在排序缓冲区被填满时以非常短的时间间隔运行，并且即使对于单个处理线程也会导致大量 CPU 使用（排序本身不会触发垃圾收集器）。JVM 垃圾收集多个并行线程，解释了高CPU 总体利用率。另一方面，对序列化数据进行操作的方法很少触发垃圾收集器并且 CPU 利用率低得多。实际上，如果使用 Flink 序列化的方式在 Integer 字段上对 Tuple 进行排序，则垃圾收集器根本不运行，因为对于成对比较，不需要反序列化任何对象。Kryo 序列化需要比较多的垃圾收集，因为它不使用二进制排序 key 并且每次排序都要反序列化两个对象。&lt;/p&gt;
&lt;p&gt;内存使用情况上图显示 Flink 序列化和 Kryo 序列化不断的占用大量内存&lt;/p&gt;
&lt;p&gt;存使用情况图表显示flink-serialized和kryo-serialized不断占用大量内存。这是由于 MemorySegments 的预分配。实际内存使用率要低得多，因为排序缓冲区并未完全填充。下表显示了每种方法的内存消耗。1000 万条数据产生大约 280 MB 的二进制数据（对象数据、指针和排序 key），具体取决于使用的序列化程序以及二进制排序 key 的存在和大小。将其与数据存储在堆上的方法进行比较，我们发现对二进制数据进行操作可以显著提高内存效率。在我们的基准测试中，如果序列化为排序缓冲区而不是将其作为堆上的对象保存，则可以在内存中对两倍以上的数据进行排序。&lt;/p&gt;
&lt;table&gt;&lt;thead/&gt;&lt;tbody readability=&quot;6&quot;&gt;&lt;tr class=&quot;odd&quot; readability=&quot;6&quot;&gt;&lt;td&gt;对 Integer 排序&lt;/td&gt;
&lt;td&gt;约 700 MB（堆内存）&lt;/td&gt;
&lt;td&gt;277 MB（排序缓冲区）&lt;/td&gt;
&lt;td&gt;266 MB（排序缓冲区）&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;even&quot; readability=&quot;6&quot;&gt;&lt;td&gt;对 String 排序&lt;/td&gt;
&lt;td&gt;约 700 MB（堆内存）&lt;/td&gt;
&lt;td&gt;315 MB（排序缓冲区）&lt;/td&gt;
&lt;td&gt;266 MB（排序缓冲区）&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;总而言之，测试验证了文章前面说的对二进制数据进行操作的好处。&lt;/p&gt;
&lt;h3 id=&quot;展望未来&quot;&gt;展望未来&lt;/h3&gt;
&lt;p&gt;Apache Flink 具有相当多的高级技术，可以通过有限的内存资源安全有效地处理大量数据。但是有几点可以使 Flink 更有效率。Flink 社区正在努力将管理内存移动到堆外内存。这将允许更小的 JVM，更低的垃圾收集开销，以及更容易的系统配置。使用 Flink 的 Table API，所有操作（如 aggregation 和 projection）的语义都是已知的（与黑盒用户定义的函数相反）。因此，我们可以为直接对二进制数据进行操作的 Table API 操作生成代码。进一步的改进包括序列化设计，这些设计针对应用于二进制数据的操作和针对序列化器和比较器的代码生成而定制。&lt;/p&gt;
&lt;h3 id=&quot;总结&quot;&gt;总结&lt;/h3&gt;
&lt;ul readability=&quot;1.5&quot;&gt;&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;Flink 的主动内存管理减少了因触发 OutOfMemoryErrors 而杀死 JVM 进程和垃圾收集开销的问题。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;Flink 具有高效的数据序列化和反序列化机制，有助于对二进制数据进行操作，并使更多数据适合内存。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;Flink 的 DBMS 风格的运算符本身在二进制数据上运行，在必要时可以在内存中高性能地传输到磁盘。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;本文地址: &lt;a href=&quot;http://www.54tianzhisheng.cn/2019/03/24/Flink-code-memory-management/&quot; class=&quot;uri&quot;&gt;http://www.54tianzhisheng.cn/2019/03/24/Flink-code-memory-management/&lt;/a&gt;&lt;/p&gt;
&lt;blockquote readability=&quot;3.4772727272727&quot;&gt;
&lt;p&gt;本文翻译自：&lt;a href=&quot;https://flink.apache.org/news/2015/05/11/Juggling-with-Bits-and-Bytes.html&quot; class=&quot;uri&quot;&gt;https://flink.apache.org/news/2015/05/11/Juggling-with-Bits-and-Bytes.html&lt;/a&gt;&lt;br/&gt;翻译：zhisheng，二次转载请注明地址，否则保留追究法律责任。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&quot;关注我&quot;&gt;关注我&lt;/h3&gt;
&lt;p&gt;微信公众号：&lt;strong&gt;zhisheng&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;另外我自己整理了些 Flink 的学习资料，目前已经全部放到微信公众号了。你可以加我的微信：&lt;strong&gt;zhisheng_tian&lt;/strong&gt;，然后回复关键字：&lt;strong&gt;Flink&lt;/strong&gt; 即可无条件获取到。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/860214/201908/860214-20190812081258877-1246957589.jpg&quot;/&gt;&lt;/p&gt;
&lt;p&gt;更多私密资料请加入知识星球！&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/860214/201908/860214-20190812081259267-219185390.jpg&quot;/&gt;&lt;/p&gt;
&lt;h3 id=&quot;github-代码仓库&quot;&gt;Github 代码仓库&lt;/h3&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/zhisheng17/flink-learning/&quot; class=&quot;uri&quot;&gt;https://github.com/zhisheng17/flink-learning/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;以后这个项目的所有代码都将放在这个仓库里，包含了自己学习 flink 的一些 demo 和博客。&lt;/p&gt;
&lt;h3 id=&quot;博客&quot;&gt;博客&lt;/h3&gt;
&lt;p&gt;1、&lt;a href=&quot;http://www.54tianzhisheng.cn/2018/10/13/flink-introduction/&quot;&gt;Flink 从0到1学习 —— Apache Flink 介绍&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;2、&lt;a href=&quot;http://www.54tianzhisheng.cn/2018/09/18/flink-install&quot;&gt;Flink 从0到1学习 —— Mac 上搭建 Flink 1.6.0 环境并构建运行简单程序入门&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;3、&lt;a href=&quot;http://www.54tianzhisheng.cn/2018/10/27/flink-config/&quot;&gt;Flink 从0到1学习 —— Flink 配置文件详解&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;4、&lt;a href=&quot;http://www.54tianzhisheng.cn/2018/10/28/flink-sources/&quot;&gt;Flink 从0到1学习 —— Data Source 介绍&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;5、&lt;a href=&quot;http://www.54tianzhisheng.cn/2018/10/30/flink-create-source/&quot;&gt;Flink 从0到1学习 —— 如何自定义 Data Source ？&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;6、&lt;a href=&quot;http://www.54tianzhisheng.cn/2018/10/29/flink-sink/&quot;&gt;Flink 从0到1学习 —— Data Sink 介绍&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;7、&lt;a href=&quot;http://www.54tianzhisheng.cn/2018/10/31/flink-create-sink/&quot;&gt;Flink 从0到1学习 —— 如何自定义 Data Sink ？&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;8、&lt;a href=&quot;http://www.54tianzhisheng.cn/2018/11/04/Flink-Data-transformation/&quot;&gt;Flink 从0到1学习 —— Flink Data transformation(转换)&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;9、&lt;a href=&quot;http://www.54tianzhisheng.cn/2018/12/08/Flink-Stream-Windows/&quot;&gt;Flink 从0到1学习 —— 介绍 Flink 中的 Stream Windows&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;10、&lt;a href=&quot;http://www.54tianzhisheng.cn/2018/12/11/Flink-time/&quot;&gt;Flink 从0到1学习 —— Flink 中的几种 Time 详解&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;11、&lt;a href=&quot;http://www.54tianzhisheng.cn/2018/12/30/Flink-ElasticSearch-Sink/&quot;&gt;Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 ElasticSearch&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;12、&lt;a href=&quot;http://www.54tianzhisheng.cn/2019/01/05/Flink-run/&quot;&gt;Flink 从0到1学习 —— Flink 项目如何运行？&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;13、&lt;a href=&quot;http://www.54tianzhisheng.cn/2019/01/06/Flink-Kafka-sink/&quot;&gt;Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Kafka&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;14、&lt;a href=&quot;http://www.54tianzhisheng.cn/2019/01/13/Flink-JobManager-High-availability/&quot;&gt;Flink 从0到1学习 —— Flink JobManager 高可用性配置&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;15、&lt;a href=&quot;http://www.54tianzhisheng.cn/2019/01/14/Flink-parallelism-slot/&quot;&gt;Flink 从0到1学习 —— Flink parallelism 和 Slot 介绍&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;16、&lt;a href=&quot;http://www.54tianzhisheng.cn/2019/01/15/Flink-MySQL-sink/&quot;&gt;Flink 从0到1学习 —— Flink 读取 Kafka 数据批量写入到 MySQL&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;17、&lt;a href=&quot;http://www.54tianzhisheng.cn/2019/01/20/Flink-RabbitMQ-sink/&quot;&gt;Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 RabbitMQ&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;18、&lt;a href=&quot;https://t.zsxq.com/zV7MnuJ&quot;&gt;Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 HBase&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;19、&lt;a href=&quot;https://t.zsxq.com/zV7MnuJ&quot;&gt;Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 HDFS&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;20、&lt;a href=&quot;https://t.zsxq.com/zV7MnuJ&quot;&gt;Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Redis&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;21、&lt;a href=&quot;https://t.zsxq.com/uVbi2nq&quot;&gt;Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Cassandra&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;22、&lt;a href=&quot;https://t.zsxq.com/zV7MnuJ&quot;&gt;Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Flume&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;23、&lt;a href=&quot;https://t.zsxq.com/zV7MnuJ&quot;&gt;Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 InfluxDB&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;24、&lt;a href=&quot;https://t.zsxq.com/zV7MnuJ&quot;&gt;Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 RocketMQ&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;25、&lt;a href=&quot;http://www.54tianzhisheng.cn/2019/03/13/flink-job-jars/&quot;&gt;Flink 从0到1学习 —— 你上传的 jar 包藏到哪里去了&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;26、&lt;a href=&quot;https://t.zsxq.com/zV7MnuJ&quot;&gt;Flink 从0到1学习 —— 你的 Flink job 日志跑到哪里去了&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;27、&lt;a href=&quot;http://www.54tianzhisheng.cn/2019/02/28/blink/&quot;&gt;阿里巴巴开源的 Blink 实时计算框架真香&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;28、&lt;a href=&quot;http://www.54tianzhisheng.cn/2019/03/28/flink-additional-data/&quot;&gt;Flink 从0到1学习 —— Flink 中如何管理配置？&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;29、&lt;a href=&quot;http://www.54tianzhisheng.cn/2019/06/12/flink-split/&quot;&gt;Flink 从0到1学习—— Flink 不可以连续 Split(分流)？&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;30、&lt;a href=&quot;http://www.54tianzhisheng.cn/2019/06/13/flink-book-paper/&quot;&gt;Flink 从0到1学习—— 分享四本 Flink 国外的书和二十多篇 Paper 论文&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;31、&lt;a href=&quot;http://www.54tianzhisheng.cn/2019/06/14/flink-architecture-deploy-test/&quot;&gt;Flink 架构、原理与部署测试&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;32、&lt;a href=&quot;http://www.54tianzhisheng.cn/2019/06/15/Stream-processing/&quot;&gt;为什么说流处理即未来？&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;33、&lt;a href=&quot;http://www.54tianzhisheng.cn/2019/06/16/flink-sql-oppo/&quot;&gt;OPPO 数据中台之基石：基于 Flink SQL 构建实时数据仓库&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;34、&lt;a href=&quot;http://www.54tianzhisheng.cn/2019/06/17/flink-vs-storm/&quot;&gt;流计算框架 Flink 与 Storm 的性能对比&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;35、&lt;a href=&quot;http://www.54tianzhisheng.cn/2019/06/18/flink-state/&quot;&gt;Flink状态管理和容错机制介绍&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;36、&lt;a href=&quot;http://www.54tianzhisheng.cn/2019/06/20/flink-kafka-Exactly-Once/&quot;&gt;Apache Flink 结合 Kafka 构建端到端的 Exactly-Once 处理&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;37、&lt;a href=&quot;http://www.54tianzhisheng.cn/2019/06/21/flink-in-360/&quot;&gt;360深度实践：Flink与Storm协议级对比&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;38、&lt;a href=&quot;http://www.54tianzhisheng.cn/2019/06/26/flink-TensorFlow/&quot;&gt;如何基于Flink+TensorFlow打造实时智能异常检测平台？只看这一篇就够了&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;39、&lt;a href=&quot;http://www.54tianzhisheng.cn/2019/07/01/flink-1.9-preview/&quot;&gt;Apache Flink 1.9 重大特性提前解读&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;40、&lt;a href=&quot;http://www.54tianzhisheng.cn/2019/12/31/Flink-resources/&quot;&gt;Flink 全网最全资源（视频、博客、PPT、入门、实战、源码解析、问答等持续更新）&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;41、&lt;a href=&quot;https://mp.weixin.qq.com/s/ok-YwuVbwAVtJz7hUCiZxg&quot;&gt;Flink 灵魂两百问，这谁顶得住？&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&quot;源码解析&quot;&gt;源码解析&lt;/h3&gt;
&lt;p&gt;1、&lt;a href=&quot;http://www.54tianzhisheng.cn/2019/01/30/Flink-code-compile/&quot;&gt;Flink 源码解析 —— 源码编译运行&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;2、&lt;a href=&quot;http://www.54tianzhisheng.cn/2019/03/14/Flink-code-structure/&quot;&gt;Flink 源码解析 —— 项目结构一览&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;3、&lt;a href=&quot;http://www.54tianzhisheng.cn/tags/Flink/&quot;&gt;Flink 源码解析—— local 模式启动流程&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;4、&lt;a href=&quot;http://www.54tianzhisheng.cn/2019/03/15/Flink-code-Standalone-start/&quot;&gt;Flink 源码解析 —— standalone session 模式启动流程&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;5、&lt;a href=&quot;http://www.54tianzhisheng.cn/2019/03/16/Flink-code-Standalone-JobManager-start/&quot;&gt;Flink 源码解析 —— Standalone Session Cluster 启动流程深度分析之 Job Manager 启动&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;6、&lt;a href=&quot;http://www.54tianzhisheng.cn/2019/03/17/Flink-code-Standalone-TaskManager-start/&quot;&gt;Flink 源码解析 —— Standalone Session Cluster 启动流程深度分析之 Task Manager 启动&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;7、&lt;a href=&quot;http://www.54tianzhisheng.cn/2019/03/18/Flink-code-batch-wordcount-start/&quot;&gt;Flink 源码解析 —— 分析 Batch WordCount 程序的执行过程&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;8、&lt;a href=&quot;http://www.54tianzhisheng.cn/2019/03/19/Flink-code-streaming-wordcount-start/&quot;&gt;Flink 源码解析 —— 分析 Streaming WordCount 程序的执行过程&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;9、&lt;a href=&quot;http://www.54tianzhisheng.cn/2019/03/21/Flink-code-JobGraph/&quot;&gt;Flink 源码解析 —— 如何获取 JobGraph？&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;10、&lt;a href=&quot;http://www.54tianzhisheng.cn/2019/03/20/Flink-code-StreamGraph/&quot;&gt;Flink 源码解析 —— 如何获取 StreamGraph？&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;11、&lt;a href=&quot;http://www.54tianzhisheng.cn/2019/03/25/Flink-code-jobmanager/&quot;&gt;Flink 源码解析 —— Flink JobManager 有什么作用？&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;12、&lt;a href=&quot;http://www.54tianzhisheng.cn/2019/03/25/Flink-code-taskmanager/&quot;&gt;Flink 源码解析 —— Flink TaskManager 有什么作用？&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;13、&lt;a href=&quot;http://www.54tianzhisheng.cn/2019/03/27/Flink-code-JobManager-submitJob/&quot;&gt;Flink 源码解析 —— JobManager 处理 SubmitJob 的过程&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;14、&lt;a href=&quot;http://www.54tianzhisheng.cn/2019/03/28/Flink-code-TaskManager-submitJob/&quot;&gt;Flink 源码解析 —— TaskManager 处理 SubmitJob 的过程&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;15、&lt;a href=&quot;http://www.54tianzhisheng.cn/2019/03/23/Flink-code-checkpoint/&quot;&gt;Flink 源码解析 —— 深度解析 Flink Checkpoint 机制&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;16、&lt;a href=&quot;http://www.54tianzhisheng.cn/2019/03/22/Flink-code-serialize/&quot;&gt;Flink 源码解析 —— 深度解析 Flink 序列化机制&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;17、&lt;a href=&quot;http://www.54tianzhisheng.cn/2019/03/24/Flink-code-memory-management/&quot;&gt;Flink 源码解析 —— 深度解析 Flink 是如何管理好内存的？&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;18、&lt;a href=&quot;http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/&quot;&gt;Flink Metrics 源码解析 —— Flink-metrics-core&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;19、&lt;a href=&quot;http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/&quot;&gt;Flink Metrics 源码解析 —— Flink-metrics-datadog&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;20、&lt;a href=&quot;http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/&quot;&gt;Flink Metrics 源码解析 —— Flink-metrics-dropwizard&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;21、&lt;a href=&quot;http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/&quot;&gt;Flink Metrics 源码解析 —— Flink-metrics-graphite&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;22、&lt;a href=&quot;http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/&quot;&gt;Flink Metrics 源码解析 —— Flink-metrics-influxdb&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;23、&lt;a href=&quot;http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/&quot;&gt;Flink Metrics 源码解析 —— Flink-metrics-jmx&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;24、&lt;a href=&quot;http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/&quot;&gt;Flink Metrics 源码解析 —— Flink-metrics-slf4j&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;25、&lt;a href=&quot;http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/&quot;&gt;Flink Metrics 源码解析 —— Flink-metrics-statsd&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;26、&lt;a href=&quot;http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/&quot;&gt;Flink Metrics 源码解析 —— Flink-metrics-prometheus&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/860214/201908/860214-20190812081300346-998425264.jpg&quot;/&gt;&lt;/p&gt;
&lt;p&gt;26、&lt;a href=&quot;http://www.54tianzhisheng.cn/2019/07/03/Flink-code-Annotations/&quot;&gt;Flink Annotations 源码解析&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/860214/201908/860214-20190812081300826-549101978.jpg&quot;/&gt;&lt;/p&gt;
&lt;p&gt;27、&lt;a href=&quot;http://www.54tianzhisheng.cn/2019/03/26/Flink-code-ExecutionGraph/&quot;&gt;Flink 源码解析 —— 如何获取 ExecutionGraph ？&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;28、&lt;a href=&quot;https://t.zsxq.com/UvrRNJM&quot;&gt;大数据重磅炸弹——实时计算框架 Flink&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;29、&lt;a href=&quot;https://t.zsxq.com/QVFqjea&quot;&gt;Flink Checkpoint-轻量级分布式快照&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;30、&lt;a href=&quot;http://www.54tianzhisheng.cn/2019/07/04/Flink-code-clients/&quot;&gt;Flink Clients 源码解析&lt;/a&gt;原文出处：&lt;a href=&quot;http://www.54tianzhisheng.cn/&quot;&gt;zhisheng的博客&lt;/a&gt;，欢迎关注我的公众号：zhisheng&lt;/p&gt;
</description>
<pubDate>Mon, 12 Aug 2019 00:13:00 +0000</pubDate>
<dc:creator>zhisheng_tian</dc:creator>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/zhisheng/p/11337650.html</dc:identifier>
</item>
<item>
<title>10分钟安装Elasticsearch - 代码无止境</title>
<link>http://www.cnblogs.com/endless-code/p/11337090.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/endless-code/p/11337090.html</guid>
<description>&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;关注公众号 itweknow，回复“ES”获取《Elasticsearch权威指南 中文版》。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;最近在尝试着搭建一个ELK（一个开源的实时日志分析平台），而本文所讲的Elasticsearch（下文简称ES）就是其中的E。这篇文章我们就一起来看下如何在Ubuntu上安装ES。至于ELK平台的搭建过程，后续会有文章介绍。&lt;/p&gt;
&lt;h3 id=&quot;什么是es&quot;&gt;什么是ES&lt;/h3&gt;
&lt;p&gt;ES是个开源分布式搜索引擎，它具有以下特点。&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;查询：ES允许执行和合并多种类型的搜索 — 结构化、非结构化、地理位置、度量指标 — 搜索方式随心而变。&lt;/li&gt;
&lt;li&gt;分析：ES聚合让您能够从大处着眼，探索数据的趋势和模式。&lt;/li&gt;
&lt;li&gt;速度：ES很快。真的，真的很快。&lt;/li&gt;
&lt;li&gt;可扩展性：可以在笔记本电脑上运行。也可以在承载了PB级数据的成百上千台服务器上运行。&lt;/li&gt;
&lt;li&gt;弹性：ES运行在一个分布式的环境中，从设计之初就考虑到了这一点。&lt;/li&gt;
&lt;li&gt;灵活性：具备多个案例场景。数字、文本、地理位置、结构化、非结构化。所有的数据类型都欢迎。&lt;/li&gt;
&lt;/ul&gt;&lt;h3 id=&quot;es能干啥&quot;&gt;ES能干啥&lt;/h3&gt;
&lt;p&gt;ES建立在全文搜索引擎Apache Lucene(TM)的基础之上。但它并不像Lucene那么简单，它不仅包括了全文搜索功能，还可以进行以下工作:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;分布式实时文件存储，并将每一个字段都编入索引，使其可以被搜索。&lt;/li&gt;
&lt;li&gt;实时分析的分布式搜索引擎。&lt;/li&gt;
&lt;li&gt;可以扩展到上百台服务器，处理PB级别的结构化或非结构化数据。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;因为数据量庞大之后关系型数据库的查询速度会下降的非常快，很多情况下我们会将一些数量级非常庞大的数据存储在ES中，比如说服务运行过程中产生的日志等。&lt;/p&gt;
&lt;h3 id=&quot;es的安装&quot;&gt;ES的安装&lt;/h3&gt;
&lt;p&gt;简单的介绍了一下ES之后，我们回归正题，进入ES的安装步骤。在安装之前，你需要做如下准备：&lt;/p&gt;
&lt;p&gt;1.由于ES不能以root用户运行，所以我们需要为其创建一个其他用户。&lt;/p&gt;
&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;root@es01:~# useradd -m es
# 密码
root@es01:~# passwd es
Enter new UNIX password: 
Retype new UNIX password: 
passwd: password updated successfully
# 为该用户指定命令解释程序（通常为/bin/bash）
root@es01:~# usermod -s /bin/bash es&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;2.将ES的安装包copy到&lt;code&gt;~/es/&lt;/code&gt;目录下，并解压。&lt;/p&gt;
&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;es@es01:~/es$ tar -xzvf elasticsearch-7.3.0-linux-x86_64.tar.gz&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;3..启动Elasticsearch&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;cd elasticsearch-7.3.0/
bin/elasticsearch&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;4.另起会话窗口执行&lt;code&gt;curl http://localhost:9200&lt;/code&gt;命令，若看到如下信息则代表安装成功。&lt;/p&gt;
&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;es@es01:~$ curl http://localhost:9200
{
  &quot;name&quot; : &quot;es01&quot;,
  &quot;cluster_name&quot; : &quot;elasticsearch&quot;,
  &quot;cluster_uuid&quot; : &quot;V7athqhfT8KM4G6cjwQgsA&quot;,
  &quot;version&quot; : {
    &quot;number&quot; : &quot;7.3.0&quot;,
    &quot;build_flavor&quot; : &quot;default&quot;,
    &quot;build_type&quot; : &quot;tar&quot;,
    &quot;build_hash&quot; : &quot;de777fa&quot;,
    &quot;build_date&quot; : &quot;2019-07-24T18:30:11.767338Z&quot;,
    &quot;build_snapshot&quot; : false,
    &quot;lucene_version&quot; : &quot;8.1.0&quot;,
    &quot;minimum_wire_compatibility_version&quot; : &quot;6.8.0&quot;,
    &quot;minimum_index_compatibility_version&quot; : &quot;6.0.0-beta1&quot;
  },
  &quot;tagline&quot; : &quot;You Know, for Search&quot;
}&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;安装中遇到的问题&quot;&gt;安装中遇到的问题&lt;/h3&gt;
&lt;p&gt;在安装ES的过程中，也遇到了两个问题，在此处记录，希望能给大家帮助。&lt;/p&gt;
&lt;p&gt;1.问题一：内存不足，报错如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://user-gold-cdn.xitu.io/2019/8/11/16c81125f0e82fc6?w=1024&amp;amp;h=493&amp;amp;f=png&amp;amp;s=127384&quot; alt=&quot;内存不足&quot;/&gt;&lt;/p&gt;
&lt;p&gt;解决方案是，修改&lt;code&gt;elasticsearch-7.3.0/config/jvm.options&lt;/code&gt;文件中的下面的配置为适合自己机器的内存大小，若修改后还是报这个错误，可重新连接服务器再试一次。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;# Xms represents the initial size of total heap space
# Xmx represents the maximum size of total heap space

-Xms512m
-Xmx512m
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;2.问题二：如果您是以root用户启动的话，就会报如下错误。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://user-gold-cdn.xitu.io/2019/8/11/16c81125f0f7d9cf?w=1024&amp;amp;h=691&amp;amp;f=png&amp;amp;s=182260&quot; alt=&quot;root用户运行ES报错&quot;/&gt;&lt;/p&gt;
&lt;p&gt;解决方案自然就是添加一个新用户启动ES，添加用户的方法上面有提到。&lt;/p&gt;
&lt;h3 id=&quot;结束语&quot;&gt;结束语&lt;/h3&gt;
&lt;p&gt;本文只是简单的介绍了安装单机版的ES，为了维持ES的高可用性通常ES都是以集群的方式出现。对于集群的搭建以及ES的详细使用介绍会在后面的文章中逐一讲解。如果您想现在学习的话，关注公众号itweknow回复ES获取《Elasticsearch权威指南 中文版》。&lt;/p&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;PS:码不停蹄，学无止境！如果您喜欢我的文章，就关注我吧！&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div align=&quot;center&quot;&gt;&lt;img src=&quot;https://g-blog.oss-cn-beijing.aliyuncs.com/image/qrcode_for_gh_526c6f450b21_258.jpg&quot; alt=&quot;扫码关注“代码无止境”&quot;/&gt;&lt;/div&gt;
</description>
<pubDate>Mon, 12 Aug 2019 00:10:00 +0000</pubDate>
<dc:creator>代码无止境</dc:creator>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/endless-code/p/11337090.html</dc:identifier>
</item>
<item>
<title>漫画 |《程序员十二时辰》，内容过于真实 ... - 纯洁的微笑</title>
<link>http://www.cnblogs.com/ityouknow/p/11337642.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/ityouknow/p/11337642.html</guid>
<description>&lt;p&gt;据说程序员的一天是这样渡过....&lt;/p&gt;
&lt;h2 id=&quot;开始新的一天&quot;&gt;7：00 开始新的一天&lt;/h2&gt;
&lt;p&gt;起床缓冲中，已经进行 ……6%&lt;/p&gt;
&lt;p&gt;回想昨晚不该又 High 到 2 点&lt;/p&gt;
&lt;p&gt;7：10 闹钟响到第 6 次的时候，终于鼓起勇气起床。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://favorites.ren/assets/images/2019/it/1.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;其实我也不想那么晚睡，但，只有凌晨以后的时间&lt;/p&gt;
&lt;p&gt;我才觉得时间属于自己！&lt;/p&gt;
&lt;h2 id=&quot;地铁中&quot;&gt;7：40 地铁中&lt;/h2&gt;
&lt;p&gt;上班的心情比上坟还要沉重&lt;/p&gt;
&lt;p&gt;每天在地铁就拼劲了一天的力气&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://favorites.ren/assets/images/2019/it/2.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;哪怕你是一个96公斤的胖子，也可以被挤得双脚悬空。&lt;/p&gt;
&lt;p&gt;住在燕郊的同事总是对我说：&lt;/p&gt;
&lt;p&gt;上班不累，上下班累&lt;/p&gt;
&lt;p&gt;我懂！&lt;/p&gt;
&lt;h2 id=&quot;公司打卡&quot;&gt;9：01 公司打卡&lt;/h2&gt;
&lt;p&gt;仅仅迟到1分钟的痛，有谁能懂？&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://favorites.ren/assets/images/2019/it/3.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;据公司HR说，三次迟到就可以领取公司的特殊奖状...&lt;/p&gt;
&lt;p&gt;我一直想鼓起勇气问问 HR&lt;/p&gt;
&lt;p&gt;为什么领导可以 12 点以后才来...&lt;/p&gt;
&lt;h2 id=&quot;开始办公&quot;&gt;9：10 开始办公&lt;/h2&gt;
&lt;p&gt;打开电脑，提示您有106条未读邮件&lt;/p&gt;
&lt;p&gt;明明就坐在你的对面，偏偏要发个邮件来沟通&lt;/p&gt;
&lt;p&gt;有可能怕背锅吧...&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://favorites.ren/assets/images/2019/it/4.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;顺便打开博客园，瞅瞅今天又更了什么新技术。&lt;/p&gt;
&lt;h2 id=&quot;项目开会&quot;&gt;10：00 项目开会&lt;/h2&gt;
&lt;p&gt;项目沟通会议，永远是一场PK大赛！&lt;/p&gt;
&lt;p&gt;董事长说你们研发都是一群高智商人群，1个月肯定就可以搞定&lt;/p&gt;
&lt;p&gt;偷偷瞄了一眼，技术老大下意识的又摸了摸自己的秃头&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://favorites.ren/assets/images/2019/it/5.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;原定1个小时的会议，又拖延了51分钟，精准卡到了饭点。&lt;/p&gt;
&lt;h2 id=&quot;公司食堂&quot;&gt;12：00 公司食堂&lt;/h2&gt;
&lt;p&gt;排队半小时，吃饭三分钟&lt;/p&gt;
&lt;p&gt;三分钟吃饭时间，总能发现各种各样的惊喜（吓）&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://favorites.ren/assets/images/2019/it/6.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;头发丝、洗锅细铁丝、环保材料、小动物...&lt;/p&gt;
&lt;p&gt;食堂吃饭就是另一种野外生存锻炼。&lt;/p&gt;
&lt;h2 id=&quot;公司附近遛弯&quot;&gt;12：40 公司附近遛弯&lt;/h2&gt;
&lt;p&gt;不小心又遇到了领导，每次遇到领导都不知道如何打招呼&lt;/p&gt;
&lt;p&gt;“领导吃了吗”好像是废话&lt;/p&gt;
&lt;p&gt;“领导去干嘛”我能管得着吗？&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://favorites.ren/assets/images/2019/it/7.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;正在犹豫之间，领导把头转向了另外一个方向，擦肩而过。&lt;/p&gt;
&lt;h2 id=&quot;午休&quot;&gt;13：00 午休&lt;/h2&gt;
&lt;p&gt;各种鼾声此消彼长，一度有种进了民工房的错觉&lt;/p&gt;
&lt;p&gt;有的喜欢趴着睡，有的喜欢仰着睡，有的喜欢脱掉鞋睡...&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://favorites.ren/assets/images/2019/it/8.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;夏天，配上浓浓的脚臭和各种外卖的味道，刺激、酸爽！&lt;/p&gt;
&lt;h2 id=&quot;修改-bug-中&quot;&gt;14：00 修改 Bug 中&lt;/h2&gt;
&lt;p&gt;终于可以好好改改 Bug 了&lt;/p&gt;
&lt;p&gt;为了修改一个很深的 Bug，无意中在一个很老的组件包中，发现一段醒目的代码注释&lt;/p&gt;
&lt;p&gt;突然有一种泪流满面的感动，兄弟诚不欺我&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://favorites.ren/assets/images/2019/it/9.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;面对前任兄弟的真诚，对着代码注释，深情的拜了三拜。&lt;/p&gt;
&lt;h2 id=&quot;沟通需求&quot;&gt;16：30 沟通需求&lt;/h2&gt;
&lt;p&gt;新来了一个产品妹子&lt;/p&gt;
&lt;p&gt;第 106 次来到我的身边，看来梁静茹又给了她一次勇气&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://favorites.ren/assets/images/2019/it/10.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;努力镇压住心中的杀气，问道，这次又改什么？&lt;/p&gt;
&lt;h2 id=&quot;启动加班中&quot;&gt;18：20 启动加班中&lt;/h2&gt;
&lt;p&gt;非研发部门，总是可以在下班十分钟之内撤退完毕，整齐如一&lt;/p&gt;
&lt;p&gt;当办公司都走空的时候，才是程序员真正的 Coding 时间&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://favorites.ren/assets/images/2019/it/11.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;当没有人打扰时，Coding 就是一种享受&lt;/p&gt;
&lt;p&gt;有种改变世界的感觉&lt;/p&gt;
&lt;p&gt;虽然有可能是一种错觉。&lt;/p&gt;
&lt;h2 id=&quot;继续加班中&quot;&gt;19：00 继续加班中&lt;/h2&gt;
&lt;p&gt;不在加班中爆发，就在加班中灭亡&lt;/p&gt;
&lt;p&gt;995、996、997、711、007...&lt;/p&gt;
&lt;p&gt;有的公司为了鼓励加班，设置很多变态的规定&lt;/p&gt;
&lt;p&gt;17：30 下班 ，18：30 有班车，19：00 有工作餐，21：00 后打车报销&lt;/p&gt;
&lt;p&gt;总有一个坑等着你&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://favorites.ren/assets/images/2019/it/12.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;想想1.5-2H 的地铁，还不如再干两个小时吧...&lt;/p&gt;
&lt;p&gt;每次回家坐在出租车上，看着窗外这座城市的繁华&lt;/p&gt;
&lt;p&gt;却始终感觉自己是局外人&lt;/p&gt;
&lt;p&gt;永远融不进去这个待了好多年的城市。&lt;/p&gt;
&lt;h2 id=&quot;作为一名程序员&quot;&gt;作为一名程序员&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;有几句知心话要对大家说：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;每一个北漂人都不容易，&lt;/p&gt;
&lt;p&gt;老板的情怀很重要，但自己的身体更重要。&lt;/p&gt;
&lt;p&gt;没有听说哪个公司离开了一个程序员就倒闭了。&lt;/p&gt;
&lt;p&gt;但，如果你的家庭没有了顶梁柱的你，&lt;/p&gt;
&lt;p&gt;一切都垮了！&lt;/p&gt;
&lt;p&gt;有时候很多读者问我，&lt;/p&gt;
&lt;p&gt;一线城市重要，还是二线城市重要？&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;对我来讲和家人在一起最重要！&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;程序员的生活不应该只有工作，&lt;/p&gt;
&lt;p&gt;虽然工作有可能改变世界，&lt;/p&gt;
&lt;p&gt;但最需要你改变的可能是你的家庭。&lt;/p&gt;
&lt;p&gt;最近看新闻，有很多些程序员，&lt;/p&gt;
&lt;p&gt;在工作中就突然倒下了，&lt;/p&gt;
&lt;p&gt;有的只是意外，&lt;/p&gt;
&lt;p&gt;有的却永远没有起来。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;未来很远，只有打好地基，才能走得更稳！&lt;/strong&gt;&lt;/p&gt;
</description>
<pubDate>Mon, 12 Aug 2019 00:09:00 +0000</pubDate>
<dc:creator>纯洁的微笑</dc:creator>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/ityouknow/p/11337642.html</dc:identifier>
</item>
<item>
<title>以kaldi中的yesno为例谈谈transition - davidtym</title>
<link>http://www.cnblogs.com/talkaudiodev/p/11323088.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/talkaudiodev/p/11323088.html</guid>
<description>&lt;p&gt;在基于GMM-HMM的传统语音识别里，比音素（phone）更小的单位是状态（state）。一般每个音素由三个状态组成，特殊的是静音（SIL）由五个状态组成。这里所说的状态就是指HMM里的隐藏的状态，而每帧数据就是指HMM里的观测值。每个状态可以用一个GMM模型表示（这个GMM模型的参数是通过训练得到的）。在识别时把每帧数据对应的特征值放进每个状态的GMM里算概率，概率最大的那个就是这帧对应的状态。再从状态得到音素（HMM负责），从音素得到词（字典模型负责），从词得到句子（语言模型负责），最终完成识别。可以从一个状态转到另一个状态，即状态之间存在转移（transition）。Transition是kaldi里一个非常重要的概念，相关的有transition-state、transition-index、transition-id等，初一看云里雾里不太好理解，其实它们都是根据topo图（/s5/data/lang/topo）得到的。今天就基于yesno的例子对它们做一个讲解。&lt;/p&gt;

&lt;p&gt;先看yesno中的topo图（见下图），它有三个音素：SIL、yes、no (yes和no均作为一个音素处理)，id 分别为1、2、3. SIL有5个状态，id为0—4 ，5为结束态。yes/no分别有三个状态，id为0—2 ，3为结束态。&lt;/p&gt;
&lt;p&gt;SIL中状态0—3 分别有4条状态转移路径（或者叫转移弧），以状态0为例，可以自环（self-loop）到0，也可以转移到1或者2或者3. 状态4有2条状态转移路径，可以自环（self-loop）到4，也可以转移到结束态5. Yes/no中状态0—1均有2条状态转移路径。所以这个topo图中共有30条（4*4+2（SIL）+ 3*2（yes）+3*2（no）= 30）状态转移路径。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1181527/201908/1181527-20190809133738420-161521190.jpg&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;再来看transition中相关的几个概念：&lt;/p&gt;
&lt;p&gt;Phone：音素，前文已提过，id是从1开始的整数。在yesno中共三个音素（SIL、yes、no），id分别为1、2、3。&lt;/p&gt;
&lt;p&gt;HMM-state：HMM里隐藏的状态。每个音素的HMM-state都是从0开始的整数。在yesno中SIL的HMM-state分别为0、1、2、3、4，yes/no的HMM-state分别为0、1、2。&lt;/p&gt;
&lt;p&gt;pdf-id:每个state相对应的GMM概率密度函数（pdf: probability density function）的id，这个值是全局唯一从0开始的整数。pdf-id分为forward-pdf-id和self-loop-pdf-id两种，值一样，即pdf-id = forward-pdf-id = self-loop-pdf-id。在yesno中SIL有5个状态，pdf-id分别为0、1、2、3、4、5，yes有3个状态，pdf-id分别为5、6、7，no有3个状态，pdf-id分别为8、9、10。&lt;/p&gt;
&lt;p&gt;transition-state：表示一个转移状态，用（phone，HMM-state，forward-pdf-id ， self-loop-pdf-id）表示。这个概念相对抽象些。&lt;/p&gt;
&lt;p&gt;transition-index：表示一个状态的转移路径的index，在每个状态内从0开始的整数。在yesno中SIL的状态0有4个转移路径，其transition-index分别为0、1、2、3。其他状态类似。&lt;/p&gt;
&lt;p&gt;transition-id: 所有状态转移路径的id，全局唯一从1开始的整数，跟（transition-state， transition-index）一一对应。在yesno中SIL的状态0有4个转移路径，其transition-id分别为1、2、3、4，SIL的状态1有4个转移路径，其transition-id分别为5、6、7、8，SIL的状态2有4个转移路径，其transition-id分别为9、10、11、12，SIL的状态3有4个转移路径，其transition-id分别为13、14、15、16，SIL的状态4有2个转移路径，其transition-id分别为17、18；yes的状态0有2个转移路径，其transition-id分别为19、20，yes的状态1有2个转移路径，其transition-id分别为21、22，yes的状态2有2个转移路径，其transition-id分别为23、24；no的状态0有2个转移路径，其transition-id分别为25、26，no的状态1有2个转移路径，其transition-id分别为27、28，no的状20有2个转移路径，其transition-id分别为29、30，所以yesno中transition-id范围是1—30.&lt;/p&gt;

&lt;p&gt;下表列出了yesno中这些变量的具体值，它们会被存起来，有一一对应的关系，知道一个值后就可以知道相对应的其他值。比如常用的通过transition-id得到pdf-id。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1181527/201908/1181527-20190809133810403-1253480342.jpg&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;以上通过对例子yesno的讲解就可以很好的理解跟transition相关的概念了。&lt;/p&gt;
</description>
<pubDate>Mon, 12 Aug 2019 00:05:00 +0000</pubDate>
<dc:creator>davidtym</dc:creator>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/talkaudiodev/p/11323088.html</dc:identifier>
</item>
<item>
<title>基于hprose-golang创建RPC微服务 - 飞鸿影</title>
<link>http://www.cnblogs.com/52fhy/p/11185895.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/52fhy/p/11185895.html</guid>
<description>&lt;blockquote readability=&quot;7&quot;&gt;
&lt;p&gt;&lt;code&gt;Hprose&lt;/code&gt;（High Performance Remote Object Service Engine）&lt;br/&gt;是一款先进的轻量级、跨语言、跨平台、无侵入式、高性能动态远程对象调用引擎库。它不仅简单易用，而且功能强大。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;官网：https://hprose.com/&lt;/p&gt;
&lt;p&gt;本文将讲解如何使用&lt;code&gt;Hprose&lt;/code&gt; go 服务端编写一个微服务，并实现客户端调用。&lt;/p&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;本文的涉及的项目代码托管在github：https://github.com/52fhy/hprose-sample 。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;使用go实现服务端&quot;&gt;使用Go实现服务端&lt;/h2&gt;
&lt;h3 id=&quot;初始化&quot;&gt;初始化&lt;/h3&gt;
&lt;p&gt;git初始化：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;git init
echo &quot;main&quot; &amp;gt;&amp;gt; .gitignore 
echo &quot;# hprose-sample&quot; &amp;gt;&amp;gt; README.md&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;项目使用&lt;code&gt;go mod&lt;/code&gt;管理依赖，请确保安装的Go版本支持该命令。先初始化&lt;code&gt;go.mod&lt;/code&gt;文件：&lt;/p&gt;
&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;go mod init sample&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;最终项目目录结构一览：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;├── config
│   └── rd.ini
├── dao
├── main.go
├── model
└── util
    ├── config.go
    └── state.go
├── service
│   └── sample.go
├── go.mod
├── go.sum
├── client_test.go
├── README.md
├── php
├── logs&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;golang写微服务的好处就是我们可以按照自己理想的目录结构写代码，而无需关注代码 &lt;code&gt;autoload&lt;/code&gt; 问题。&lt;/p&gt;
&lt;h3 id=&quot;配置项&quot;&gt;配置项&lt;/h3&gt;
&lt;p&gt;我们使用&lt;code&gt;go-ini/ini&lt;/code&gt;来管理配置文件。&lt;/p&gt;
&lt;p&gt;项目地址：https://github.com/go-ini/ini&lt;br/&gt;文档地址：https://ini.unknwon.io/&lt;/p&gt;
&lt;p&gt;这个库使用起来很简单，文档完善。有2种用法，一种是直接加载配置文件，一种是将配置映射到结构体，使用面向对象的方法获取配置。这里我们采用第二种方案。&lt;/p&gt;
&lt;p&gt;首先在&lt;code&gt;conf/&lt;/code&gt;里建个配置文件&lt;code&gt;rd.ini&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&quot;ini&quot;&gt;
&lt;code&gt;ListenAddr = 0.0.0.0:8080

[Mysql]
Host = localhost
Port = 3306
User = root
Password =
Database = sample

[Redis]
Host = localhost
Port = 6379
Auth =&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;编写&lt;code&gt;util/config.go&lt;/code&gt;加载配置：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;package util

import &quot;github.com/go-ini/ini&quot;

type MysqlCfg struct{
    Host string
    Port int32
    User string
    Password string
    Database string
}

type RedisCfg struct{
    Host string
    Port int32
    Auth string
}

type Config struct {
    ListenAddr string
    Mysql MysqlCfg
    Redis RedisCfg
}

//全局变量
var Cfg Config

//加载配置
func InitConfig(ConfigFile string) error {
    return ini.MapTo(Cfg, ConfigFile)
}&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;main.go&quot;&gt;main.go&lt;/h3&gt;
&lt;p&gt;这里我们需要实现项目初始化、服务注册到RPC并启动一个TCP server。&lt;/p&gt;
&lt;pre class=&quot;go&quot;&gt;
&lt;code&gt;package main

import (
    &quot;flag&quot;
    &quot;fmt&quot;
    &quot;github.com/hprose/hprose-golang/rpc&quot;
    &quot;sample/service&quot;
    &quot;sample/util&quot;
)

func hello(name string) string {
    return &quot;Hello &quot; + name + &quot;!&quot;
}

func main() {
    //解析命令行参数
    configFile := flag.String(&quot;c&quot;, &quot;config/rd.ini&quot;, &quot;config file&quot;)
    flag.Parse()

    err := util.InitConfig(*configFile)
    if err != nil {
        fmt.Printf(&quot;load config file fail, err:%v\n&quot;, err)
        return
    }

    fmt.Printf(&quot;server is running at %s\n&quot;, util.Cfg.ListenAddr)

    //tcp,推荐
    server := rpc.NewTCPServer(&quot;tcp4://&quot; + util.Cfg.ListenAddr + &quot;/&quot;)

    //注册func
    server.AddFunction(&quot;hello&quot;, hello)

    //注册struct，命名空间是Sample
    server.AddInstanceMethods(&amp;amp;service.SampleService{}, rpc.Options{NameSpace: &quot;Sample&quot;})
    err = server.Start()
    if err != nil {
        fmt.Printf(&quot;start server fail, err:%v\n&quot;, err)
        return
    }
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;我们看到，RPC里注册了一个函数&lt;code&gt;hello&lt;/code&gt;，还注册了&lt;code&gt;service.SampleService&lt;/code&gt;里的所有方法。&lt;/p&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;注：这里注册服务的时候使用了&lt;code&gt;NameSpace&lt;/code&gt;选项从而支持命名空间，这个在官方的WIKI里没有示例说明，很容易忽略。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;其中&lt;code&gt;SampleService&lt;/code&gt;是一个结构体，定义在&lt;code&gt;service/sample.go&lt;/code&gt;文件里：&lt;/p&gt;
&lt;p&gt;&lt;code&gt;sample.go&lt;/code&gt;：&lt;/p&gt;
&lt;pre class=&quot;go&quot;&gt;
&lt;code&gt;package service

import (
    &quot;sample/model&quot;
    &quot;sample/util&quot;
)

//定义服务
type SampleService struct {
}

//服务里的方法
func (this *SampleService) GetUserInfo(uid int64) util.State {
    var state util.State

    if uid &amp;lt;= 0 {
        return state.SetErrCode(1001).SetErrMsg(&quot;uid不正确&quot;).End()
    }

    var user model.User
    user.Id = uid
    user.Name = &quot;test&quot;
    return state.SetData(user).End()
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;日志&quot;&gt;日志&lt;/h3&gt;
&lt;p&gt;作为一个线上项目，我们需要在业务代码里打印一些日志辅助我们排查问题。日志这里直接使用 &lt;code&gt;beego&lt;/code&gt;的日志库&lt;code&gt;logs&lt;/code&gt;。&lt;/p&gt;
&lt;pre class=&quot;go&quot;&gt;
&lt;code&gt;package util

import (
    &quot;errors&quot;
    &quot;fmt&quot;
    &quot;github.com/astaxie/beego/logs&quot;
)

var Logger *logs.BeeLogger

func InitLog() error {
    Logger = logs.NewLogger(10)

    err := Logger.SetLogger(logs.AdapterMultiFile, fmt.Sprintf(`{&quot;filename&quot;:&quot;/work/git/hprose-sample/logs/main.log&quot;, &quot;daily&quot;:true,&quot;maxdays&quot;:7,&quot;rotate&quot;:true}`))
    if err != nil {
        return errors.New(&quot;init beego log error:&quot; + err.Error())
    }
    Logger.Async(1000)
    return nil
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;这里定义里全局变量&lt;code&gt;Logger&lt;/code&gt;，之后可以在项目任意地方使用。&lt;/p&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;日志选项里&lt;code&gt;filename&lt;/code&gt;最好是动态配置，这里为了演示，直接写的固定值。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;使用示例：&lt;/p&gt;
&lt;pre class=&quot;go&quot;&gt;
&lt;code&gt;if uid &amp;lt;= 0 {
    util.Logger.Debug(&quot;uid error. uid:%d&quot;, uid)
}&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;go测试用例&quot;&gt;Go测试用例&lt;/h2&gt;
&lt;p&gt;每个项目都应该写测试用例。下面的用例里，我们将测试上面注册的服务是否正常。&lt;/p&gt;
&lt;pre class=&quot;go&quot;&gt;
&lt;code&gt;package main

import (
    &quot;github.com/hprose/hprose-golang/rpc&quot;
    &quot;sample/util&quot;
    &quot;testing&quot;
)

//stub：申明服务里拥有的方法
type clientStub struct {
    Hello       func(string) string
    GetUserInfo func(uid int64) util.State
}

//获取一个客户端
func GetClient() *rpc.TCPClient {
    return rpc.NewTCPClient(&quot;tcp4://127.0.0.1:8050&quot;)
}

//测试服务里的方法
func TestSampleService_GetUserInfo(t *testing.T) {
    client := GetClient()

    defer client.Close()
    var stub clientStub
    client.UseService(&amp;amp;stub, &quot;Sample&quot;) //使用命名空间

    rep := stub.GetUserInfo(10001)
    if rep.ErrCode &amp;gt; 0 {
        t.Error(rep.ErrMsg)
    } else {
        t.Log(rep.Data)
    }
}

//测试普通方法
func TestHello(t *testing.T) {
    client := GetClient()

    defer client.Close()
    var stub clientStub
    client.UseService(&amp;amp;stub)

    rep := stub.Hello(&quot;func&quot;)
    if rep == &quot;&quot; {
        t.Error(rep)
    } else {
        t.Log(rep)
    }
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;运行：&lt;/p&gt;
&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;$ go test -v

=== RUN   TestSampleService_GetUserInfo
--- PASS: TestSampleService_GetUserInfo (0.00s)
    client_test.go:31: map[name:test id:10001]
=== RUN   TestHello
--- PASS: TestHello (0.00s)
    client_test.go:47: Hello func!
PASS
ok      sample  0.016s
&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;php调用&quot;&gt;PHP调用&lt;/h2&gt;
&lt;h3 id=&quot;php-client&quot;&gt;php-client&lt;/h3&gt;
&lt;p&gt;需要先下载&lt;code&gt;hprose/hprose&lt;/code&gt;：&lt;/p&gt;
&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;composer config repo.packagist composer https://packagist.phpcomposer.com
composer require &quot;hprose/hprose:^2.0&quot;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;client.php&lt;/code&gt;&lt;/p&gt;
&lt;pre class=&quot;php&quot;&gt;
&lt;code&gt;&amp;lt;?php

include &quot;vendor/autoload.php&quot;;

try{
    $TcpServerAddr = &quot;tcp://127.0.0.1:8050&quot;;
    $client = \Hprose\Socket\Client::create($TcpServerAddr, false);
    $service = $client-&amp;gt;useService('', 'Sample');
    $rep = $service-&amp;gt;GetUserInfo(10);
    print_r($rep);
} catch (Exception $e){
    echo $e-&amp;gt;getMessage();
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;运行：&lt;/p&gt;
&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;$ php php/client.php 

stdClass Object
(
    [errCode] =&amp;gt; 0
    [errMsg] =&amp;gt; 
    [data] =&amp;gt; stdClass Object
        (
            [id] =&amp;gt; 10
            [name] =&amp;gt; test
        )

)
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;实际使用时最好对该处调用的代码做进一步的封装，例如实现异常捕获、返回码转换、日志打印等等。&lt;/p&gt;
&lt;h3 id=&quot;编写codetips&quot;&gt;编写codetips&lt;/h3&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;本节不是必须的，但是在多人合作的项目上，可以提高沟通效率。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;hprose 不支持一键生成各语言的客户端代码（没有IDL支持），在写代码的时候PHP编译器没法提示。我们可以写一个类或者多个类，主要是Model类和Service类：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;Model类定义字段属性，当传参或者读取返回对象里内容的是，可以使用&lt;code&gt;Get/Set&lt;/code&gt;方法；&lt;/li&gt;
&lt;li&gt;Service类类似于抽象类，仅仅是把go服务端里的方法用PHP定义一个空方法，包括参数类型、返回值类型，这个类并不会真正引入，只是给IDE作为代码提示用的。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;示例：&lt;/p&gt;
&lt;pre class=&quot;php&quot;&gt;
&lt;code&gt;class SampleService
{
    /**
     * 获取用户信息
     * @param int $uid
     * @return State
     */
    public function GetUserInfo(int $uid): State
    {
    }

}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;调用的地方（请使用phpStorm查看提示效果）：&lt;/p&gt;
&lt;pre class=&quot;php&quot;&gt;
&lt;code&gt;/**
 * @return SampleService
 * @throws Exception
 */
function getClient()
{
    $TcpServerAddr = &quot;tcp://127.0.0.1:8050&quot;;
    $client = \Hprose\Socket\Client::create($TcpServerAddr, false);
    $service = $client-&amp;gt;useService('', 'Sample');
    return $service;
}

try {
    $client = getClient();
    $rep = $client-&amp;gt;GetUserInfo(10);
    echo $rep-&amp;gt;errCode . PHP_EOL;
    print_r($rep);
} catch (Exception $e) {
    echo $e-&amp;gt;getMessage();
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;方法&lt;code&gt;getClient&lt;/code&gt;返回的注释里加了&lt;code&gt;@return SampleService&lt;/code&gt;，下面调用的&lt;code&gt;$rep-&amp;gt;errCode&lt;/code&gt;就会有代码提示了。详见：https://github.com/52fhy/hprose-sample/tree/master/php 。&lt;/p&gt;
&lt;h2 id=&quot;部署&quot;&gt;部署&lt;/h2&gt;
&lt;p&gt;线上微服务需要后台长期稳定运行，可以使用&lt;code&gt;supervisord&lt;/code&gt;工具。&lt;/p&gt;
&lt;p&gt;如果还没有安装，请餐参考：&lt;a href=&quot;https://www.cnblogs.com/52fhy/p/10161253.html&quot;&gt;Supervisor使用教程&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;新增一个常驻任务，需要新建配置。&lt;/p&gt;
&lt;p&gt;以上述sample为例，新建配置：&lt;code&gt;go_hprose_sample.ini&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&quot;ini&quot;&gt;
&lt;code&gt;[program:go_hprose_sample]
command=/usr/local/bin/go  /work/git/hprose-sample/main
priority=999                ; the relative start priority (default 999)
autostart=true              ; start at supervisord start (default: true)
autorestart=true            ; retstart at unexpected quit (default: true)
startsecs=10                ; number of secs prog must stay running (def. 10)
startretries=3              ; max # of serial start failures (default 3)
exitcodes=0,2               ; 'expected' exit codes for process (default 0,2)
stopsignal=QUIT             ; signal used to kill process (default TERM)
stopwaitsecs=10             ; max num secs to wait before SIGKILL (default 10)
user=root                 ; setuid to this UNIX account to run the program
log_stdout=true
log_stderr=true             ; if true, log program stderr (def false)
logfile=/work/git/hprose-sample/logs/supervisor/go_hprose_sample.log
logfile_maxbytes=1MB        ; max # logfile bytes b4 rotation (default 50MB)
logfile_backups=10          ; # of logfile backups (default 10)
stdout_logfile_maxbytes=20MB  ; stdout 日志文件大小，默认 50MB
stdout_logfile_backups=20     ; stdout 日志文件备份数
stdout_logfile=/work/git/hprose-sample/logs/supervisor/go_hprose_sample.stdout.log&lt;/code&gt;
&lt;/pre&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;注：上述配置仅供参考，请务必理解配置的含义。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;然后启动任务：&lt;/p&gt;
&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;supervisorctl reread
supervisorctl update
supervisorctl start go_hprose_sample&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;线上部署最少要2台机器，组成负载均衡。这样当升级的时候，可以一台一台的上线，避免服务暂停。&lt;/p&gt;
&lt;h2 id=&quot;hprose-总结&quot;&gt;Hprose 总结&lt;/h2&gt;
&lt;p&gt;优点：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;轻量级、跨语言、跨平台&lt;/li&gt;
&lt;li&gt;更少的网络传输量，使用二进制传输协议&lt;/li&gt;
&lt;li&gt;简单，跟着官方提供的例子很快就能掌握基本的使用&lt;/li&gt;
&lt;li&gt;文档完善&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;缺点：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;不支持IDL（接口描述语言），所以无法一键生成客户端调用代码，需要手动维护&lt;/li&gt;
&lt;/ul&gt;&lt;h2 id=&quot;参考&quot;&gt;参考&lt;/h2&gt;
&lt;p&gt;1、Supervisor使用教程 - 飞鸿影 - 博客园&lt;br/&gt;https://www.cnblogs.com/52fhy/p/10161253.html&lt;br/&gt;2、Home · hprose/hprose-golang Wiki&lt;br/&gt;https://github.com/hprose/hprose-golang/wiki&lt;br/&gt;3、go-ini/ini: 超赞的 Go 语言 INI 文件操作&lt;br/&gt;https://ini.unknwon.io/&lt;br/&gt;4、golang中os/exec包用法&lt;br/&gt;https://www.cnblogs.com/vijayfly/p/6102470.html&lt;/p&gt;
</description>
<pubDate>Mon, 12 Aug 2019 00:04:00 +0000</pubDate>
<dc:creator>飞鸿影</dc:creator>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/52fhy/p/11185895.html</dc:identifier>
</item>
<item>
<title>.netcore持续集成测试篇之Xunit数据驱动测试 - 周国通</title>
<link>http://www.cnblogs.com/tylerzhou/p/11337635.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/tylerzhou/p/11337635.html</guid>
<description>&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&quot;https://www.cnblogs.com/tylerzhou/p/11204826.html&quot;&gt;系列目录&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Nunit里提供了丰富的数据测试功能,虽然Xunit里提供的比较少,但是也能满足很多场景下使用了,如果数据场景非常复杂,Nunit和Xunit都是无法胜任的,有不少测试者选择自己编写一个数据提供程序,但是更建议使用AutoFixture框架,一是因为自己工作中写的往往只是为了解决某个或者部分问题,只能随着业务逻辑的扩展才能不断的健壮起来,二是这样的框架往往缺少良好文档,主要由核心开发者口口相传,这就导致后来者遇到不明白了功能就去问核心开发者,影响这些开发者的其它工作.&lt;/p&gt;
&lt;p&gt;下面介绍一下Xunit里的数据提供方式.&lt;/p&gt;
&lt;h3 id=&quot;inlinedata&quot;&gt;InlineData&lt;/h3&gt;
&lt;p&gt;InlineData相当于Nunit里的TestCase,用注解的方式给测试方法提供数据.&lt;br/&gt;我们通过以下代码片段了解它的基本用法&lt;/p&gt;
&lt;pre class=&quot;cs&quot;&gt;
&lt;code&gt;        [Theory]
        [InlineData(1, 2)]
        [InlineData(5, 9)]
        public void Test1(int x,int y)
        {
            int result = x + y;
            Assert.Equal(x + y, result);
        }&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;以上方法与普通测试方法相比最大的区别是它使用的是Theory注解,而不是fact注解.使用Theory注解的方法必须提供相应的参数,否则会报编译错误.&lt;/p&gt;
&lt;p&gt;以上测试我们提供了两组InlineData,这样在测试运行的时候测试方法就会根据这些数据生成两个方法实例.同Nunit里的表现行为相似.&lt;/p&gt;
&lt;h2 id=&quot;memberdata&quot;&gt;MemberData&lt;/h2&gt;
&lt;p&gt;MemberData顾名思义,就是成员数据,它类似于Nunit里的&lt;code&gt;TestCaseSource&lt;/code&gt;但是不同的是Xunit的MemberData的数据提供者必须是当前测试类的成员,测试数据提供者和测试方法耦合在一块可能不是太好的设计,如果需要大量测试数据,建议使用AutoFixture.&lt;/p&gt;
&lt;h3 id=&quot;数据提供者之属性提供数据&quot;&gt;数据提供者之属性提供数据&lt;/h3&gt;
&lt;p&gt;通过属性提供测试数据适应于一些比较简单的场景,这些数据是简单的,确定的.&lt;br/&gt;下面看一个示例&lt;/p&gt;
&lt;pre class=&quot;cs&quot;&gt;
&lt;code&gt;        [Theory]
        [MemberData(nameof(UnitTest1.ProvideData))]
        public void Test1(int x,int y)
        {
            int result = x + y;
            Assert.Equal(x + y, result);
        }
        public static IEnumerable&amp;lt;object[]&amp;gt; ProvideData
        {
            get
            {
                yield return new object[] { 3, 4 };
                yield return new object[] { 5, 9 };
                yield return new object[] { 11, 13 };
            }
        }&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;以上代码中,测试方法和数据提供者必须位于同一个类中,并且数据提供者必须是一个公开的,静态的属性.并且它的集合元素类型必须是Object类型.像以上Test1方法虽然需要的是int类型参数,但是提供者类型也必须是object类型,而不能是具体类型.&lt;/p&gt;
&lt;p&gt;以上数据提供属性一共yield了三组数据,因此测试方法会生成三个测试实例.&lt;/p&gt;
&lt;h3 id=&quot;数据提供者之方法提供数据&quot;&gt;数据提供者之方法提供数据&lt;/h3&gt;
&lt;pre class=&quot;cs&quot;&gt;
&lt;code&gt;
        [Theory]
        [MemberData(nameof(UnitTest1.ProvideData))]
        public void Test1(int x,int y)
        {
            int result = x + y;
            Assert.Equal(x + y, result);
        }
        public static IEnumerable&amp;lt;object[]&amp;gt; ProvideData()
        {
            yield return new object[]{3,4 };
            yield return new object[] {5, 9};
            yield return new object[] { 11, 13 };
        }&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;你可能会感觉以上方法和属性并没太大的区别,其实方法的功能更为强大,因为属性无法动态指定参数,而方法可以,我们可以指定方法接收动态运行时需要的参数,然后在MemberData的构造函数里传入参数来动态获取数据.&lt;/p&gt;
&lt;h3 id=&quot;数据提供者之成员提供数据&quot;&gt;数据提供者之成员提供数据&lt;/h3&gt;
&lt;p&gt;成员提供数据可以把外部对象作为本类成员,然后给测试方法提供数据.外部对象须继承自TheoryData.&lt;/p&gt;
&lt;p&gt;我们定义一个MyDataprovider&lt;/p&gt;
&lt;pre class=&quot;cs&quot;&gt;
&lt;code&gt;public  class MyDataprovider&amp;lt;TData1,TData2&amp;gt;:TheoryData&amp;lt;TData1,TData2&amp;gt;
    {
        public MyDataprovider(IEnumerable&amp;lt;TData1&amp;gt; dataSource1,IEnumerable&amp;lt;TData2&amp;gt; datasource2)
        {
            if (dataSource1 == null || datasource2 == null || !dataSource1.Any() || !datasource2.Any())
                throw new Exception(&quot;集合不为能空或者null&quot;);
            foreach (TData1 data1 in dataSource1)
            {
                foreach (TData2 data2 in datasource2)
                {
                    Add(data1, data2);
                }
            }
        }
    }&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;我们再看测试类&lt;/p&gt;
&lt;pre class=&quot;cs&quot;&gt;
&lt;code&gt; public class UnitTest1
    {
        public static MyDataprovider&amp;lt;int, int&amp;gt; myprovider =
            new MyDataprovider&amp;lt;int, int&amp;gt;(new[] {3, 4, 5}, new[] {6, 7, 8});
        [Theory]
        [MemberData(nameof(UnitTest1.myprovider))]
        public void Test1(int x,int y)
        {
            int result = x + y;
            Assert.Equal(x + y, result);
        }
    }&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;我们在new MyDataprovider的时候通过构造函数传入两个集合,MyDataprovider继承了TheoryData的Add方法,把数据添加到theorydata中.&lt;/p&gt;
&lt;p&gt;以上方法实际上生成了一个笛卡尔集{{3,6},{3,7},{3,8},{4,6},{4,7},{4,8},{5,6},{5,7},{5,8}}类似于Nunit里的values注解不加sequential,这个行为很多时候可能并不是我们想要的,我们想要的可能是{{3,6},{4,7},{5,8}}这样的组合,这其实是可以在MyDataprovider里自定义的.&lt;br/&gt;我们把MyDataprovider改为如下就可以了&lt;/p&gt;
&lt;pre class=&quot;cs&quot;&gt;
&lt;code&gt;public  class MyDataprovider&amp;lt;TData1,TData2&amp;gt;:TheoryData&amp;lt;TData1,TData2&amp;gt;
    {
        public MyDataprovider(IEnumerable&amp;lt;TData1&amp;gt; dataSource1,IEnumerable&amp;lt;TData2&amp;gt; datasource2)
        {
            if (dataSource1 == null || datasource2 == null || !dataSource1.Any() || !datasource2.Any())
                throw new Exception(&quot;集合不为能空或者null&quot;);
            var count1 = dataSource1.Count();
            var count2 = datasource2.Count();
            if (count1 != count2) throw new ArgumentException(&quot;两个集合长度必须相等&quot;);
            for (int i = 0; i &amp;lt; count1; i++)
            {
                Add(dataSource1.ElementAt(i), datasource2.ElementAt(i));
            }
        }
    }&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;这样虽然可以把数据提供者转移到外部了,然而去把简单的问题搞的相当复杂!&lt;/p&gt;
&lt;h3 id=&quot;数据提供者之类数据提供者&quot;&gt;数据提供者之类数据提供者&lt;/h3&gt;
&lt;p&gt;前面介绍的数据提供者除了InlineData比较常用外,其它几个都不是很实用,因为数据和测试方法混合在一个类中,违反了职责单一的原则,最后一个看似比较好的解开了耦合,实际上却带来了更高的复杂度.这里介绍ClassDataAttribute,类数据提供者.&lt;/p&gt;
&lt;p&gt;类数据提供者需要实现IEnumerable&amp;lt;Object[]&amp;gt;泛型接口,Xunit会自动的调用其GetEnumerator方法来遍历数据然后提供给测试类.&lt;/p&gt;
&lt;p&gt;我们看以下数据提供类&lt;/p&gt;
&lt;pre class=&quot;cs&quot;&gt;
&lt;code&gt; public class MyDataClassProvider:IEnumerable&amp;lt;object[]&amp;gt;
    {
        public IEnumerator&amp;lt;object[]&amp;gt; GetEnumerator()
        {
            yield return new object[] {3, 4};
            yield return new object[] {5, 9};
        }

        IEnumerator IEnumerable.GetEnumerator()
        {
            return GetEnumerator();
        }
    }&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;以上类型的GetEnumerator继承自接口,我们这里只提供了一些简单数据,当然带可以编写更为复杂的数据提供逻辑,比如从数据库里遍历,然后转化为可遍历集合.&lt;/p&gt;
&lt;p&gt;下面再看看它是如何被使用的.&lt;/p&gt;
&lt;pre class=&quot;cs&quot;&gt;
&lt;code&gt;        [Theory]
        [ClassData(typeof(MyDataClassProvider))]
        public void Test1(int x,int y)
        {
            var result = x + y;
            Assert.Equal(x + y, result);
        }&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;这里使用ClassData注解,传入一个type类型.运行的时候Xunit便可以给测试方法提供测试数据了&lt;/p&gt;
</description>
<pubDate>Mon, 12 Aug 2019 00:02:00 +0000</pubDate>
<dc:creator>周国通</dc:creator>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/tylerzhou/p/11337635.html</dc:identifier>
</item>
<item>
<title>Spark 系列（八）—— Spark SQL 之 DataFrame 和 Dataset - 黑白影</title>
<link>http://www.cnblogs.com/heibaiying/p/11337617.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/heibaiying/p/11337617.html</guid>
<description>&lt;h2 id=&quot;一spark-sql简介&quot;&gt;一、Spark SQL简介&lt;/h2&gt;
&lt;p&gt;Spark SQL 是 Spark 中的一个子模块，主要用于操作结构化数据。它具有以下特点：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;能够将 SQL 查询与 Spark 程序无缝混合，允许您使用 SQL 或 DataFrame API 对结构化数据进行查询；&lt;/li&gt;
&lt;li&gt;支持多种开发语言；&lt;/li&gt;
&lt;li&gt;支持多达上百种的外部数据源，包括 Hive，Avro，Parquet，ORC，JSON 和 JDBC 等；&lt;/li&gt;
&lt;li&gt;支持 HiveQL 语法以及 Hive SerDes 和 UDF，允许你访问现有的 Hive 仓库；&lt;/li&gt;
&lt;li&gt;支持标准的 JDBC 和 ODBC 连接；&lt;/li&gt;
&lt;li&gt;支持优化器，列式存储和代码生成等特性；&lt;/li&gt;
&lt;li&gt;支持扩展并能保证容错。&lt;/li&gt;
&lt;/ul&gt;&lt;div align=&quot;center&quot;&gt;&lt;img src=&quot;https://raw.githubusercontent.com/heibaiying/BigData-Notes/master/pictures/sql-hive-arch.png&quot;/&gt;&lt;/div&gt;
&lt;h2 id=&quot;二dataframe-dataset&quot;&gt;二、DataFrame &amp;amp; DataSet&lt;/h2&gt;
&lt;h3 id=&quot;dataframe&quot;&gt;2.1 DataFrame&lt;/h3&gt;
&lt;p&gt;为了支持结构化数据的处理，Spark SQL 提供了新的数据结构 DataFrame。DataFrame 是一个由具名列组成的数据集。它在概念上等同于关系数据库中的表或 R/Python 语言中的 &lt;code&gt;data frame&lt;/code&gt;。 由于 Spark SQL 支持多种语言的开发，所以每种语言都定义了 &lt;code&gt;DataFrame&lt;/code&gt; 的抽象，主要如下：&lt;/p&gt;
&lt;table&gt;&lt;thead/&gt;&lt;tbody readability=&quot;1&quot;&gt;&lt;tr class=&quot;odd&quot; readability=&quot;2&quot;&gt;&lt;td&gt;Scala&lt;/td&gt;
&lt;td&gt;Dataset[T] &amp;amp; DataFrame (Dataset[Row] 的别名)&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;even&quot;&gt;&lt;td&gt;Java&lt;/td&gt;
&lt;td&gt;Dataset[T]&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;odd&quot;&gt;&lt;td&gt;Python&lt;/td&gt;
&lt;td&gt;DataFrame&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;even&quot;&gt;&lt;td&gt;R&lt;/td&gt;
&lt;td&gt;DataFrame&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;h3 id=&quot;dataframe-对比-rdds&quot;&gt;2.2 DataFrame 对比 RDDs&lt;/h3&gt;
&lt;p&gt;DataFrame 和 RDDs 最主要的区别在于一个面向的是结构化数据，一个面向的是非结构化数据，它们内部的数据结构如下：&lt;/p&gt;
&lt;div align=&quot;center&quot;&gt;&lt;img src=&quot;https://raw.githubusercontent.com/heibaiying/BigData-Notes/master/pictures/spark-dataFrame+RDDs.png&quot;/&gt;&lt;/div&gt;
&lt;p&gt;DataFrame 内部的有明确 Scheme 结构，即列名、列字段类型都是已知的，这带来的好处是可以减少数据读取以及更好地优化执行计划，从而保证查询效率。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;DataFrame 和 RDDs 应该如何选择？&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;如果你想使用函数式编程而不是 DataFrame API，则使用 RDDs；&lt;/li&gt;
&lt;li&gt;如果你的数据是非结构化的 (比如流媒体或者字符流)，则使用 RDDs，&lt;/li&gt;
&lt;li&gt;如果你的数据是结构化的 (如 RDBMS 中的数据) 或者半结构化的 (如日志)，出于性能上的考虑，应优先使用 DataFrame。&lt;/li&gt;
&lt;/ul&gt;&lt;h3 id=&quot;dataset&quot;&gt;2.3 DataSet&lt;/h3&gt;
&lt;p&gt;Dataset 也是分布式的数据集合，在 Spark 1.6 版本被引入，它集成了 RDD 和 DataFrame 的优点，具备强类型的特点，同时支持 Lambda 函数，但只能在 Scala 和 Java 语言中使用。在 Spark 2.0 后，为了方便开发者，Spark 将 DataFrame 和 Dataset 的 API 融合到一起，提供了结构化的 API(Structured API)，即用户可以通过一套标准的 API 就能完成对两者的操作。&lt;/p&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;这里注意一下：DataFrame 被标记为 Untyped API，而 DataSet 被标记为 Typed API，后文会对两者做出解释。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div align=&quot;center&quot;&gt;&lt;img width=&quot;600px&quot; src=&quot;https://raw.githubusercontent.com/heibaiying/BigData-Notes/master/pictures/spark-unifed.png&quot;/&gt;&lt;/div&gt;
&lt;h3 id=&quot;静态类型与运行时类型安全&quot;&gt;2.4 静态类型与运行时类型安全&lt;/h3&gt;
&lt;p&gt;静态类型 (Static-typing) 与运行时类型安全 (runtime type-safety) 主要表现如下:&lt;/p&gt;
&lt;p&gt;在实际使用中，如果你用的是 Spark SQL 的查询语句，则直到运行时你才会发现有语法错误，而如果你用的是 DataFrame 和 Dataset，则在编译时就可以发现错误 (这节省了开发时间和整体代价)。DataFrame 和 Dataset 主要区别在于：&lt;/p&gt;
&lt;p&gt;在 DataFrame 中，当你调用了 API 之外的函数，编译器就会报错，但如果你使用了一个不存在的字段名字，编译器依然无法发现。而 Dataset 的 API 都是用 Lambda 函数和 JVM 类型对象表示的，所有不匹配的类型参数在编译时就会被发现。&lt;/p&gt;
&lt;p&gt;以上这些最终都被解释成关于类型安全图谱，对应开发中的语法和分析错误。在图谱中，Dataset 最严格，但对于开发者来说效率最高。&lt;/p&gt;
&lt;div align=&quot;center&quot;&gt;&lt;img width=&quot;600px&quot; src=&quot;https://raw.githubusercontent.com/heibaiying/BigData-Notes/master/pictures/spark-%E8%BF%90%E8%A1%8C%E5%AE%89%E5%85%A8.png&quot;/&gt;&lt;/div&gt;
&lt;p&gt;上面的描述可能并没有那么直观，下面的给出一个 IDEA 中代码编译的示例：&lt;/p&gt;
&lt;div align=&quot;center&quot;&gt;&lt;img src=&quot;https://raw.githubusercontent.com/heibaiying/BigData-Notes/master/pictures/spark-%E8%BF%90%E8%A1%8C%E6%97%B6%E7%B1%BB%E5%9E%8B%E5%AE%89%E5%85%A8.png&quot;/&gt;&lt;/div&gt;
&lt;p&gt;这里一个可能的疑惑是 DataFrame 明明是有确定的 Scheme 结构 (即列名、列字段类型都是已知的)，但是为什么还是无法对列名进行推断和错误判断，这是因为 DataFrame 是 Untyped 的。&lt;/p&gt;
&lt;h3 id=&quot;untyped-typed&quot;&gt;2.5 Untyped &amp;amp; Typed&lt;/h3&gt;
&lt;p&gt;在上面我们介绍过 DataFrame API 被标记为 &lt;code&gt;Untyped API&lt;/code&gt;，而 DataSet API 被标记为 &lt;code&gt;Typed API&lt;/code&gt;。DataFrame 的 &lt;code&gt;Untyped&lt;/code&gt; 是相对于语言或 API 层面而言，它确实有明确的 Scheme 结构，即列名，列类型都是确定的，但这些信息完全由 Spark 来维护，Spark 只会在运行时检查这些类型和指定类型是否一致。这也就是为什么在 Spark 2.0 之后，官方推荐把 DataFrame 看做是 &lt;code&gt;DatSet[Row]&lt;/code&gt;，Row 是 Spark 中定义的一个 &lt;code&gt;trait&lt;/code&gt;，其子类中封装了列字段的信息。&lt;/p&gt;
&lt;p&gt;相对而言，DataSet 是 &lt;code&gt;Typed&lt;/code&gt; 的，即强类型。如下面代码，DataSet 的类型由 Case Class(Scala) 或者 Java Bean(Java) 来明确指定的，在这里即每一行数据代表一个 &lt;code&gt;Person&lt;/code&gt;，这些信息由 JVM 来保证正确性，所以字段名错误和类型错误在编译的时候就会被 IDE 所发现。&lt;/p&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;case class Person(name: String, age: Long)
val dataSet: Dataset[Person] = spark.read.json(&quot;people.json&quot;).as[Person]&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;三dataframe-dataset-rdds-总结&quot;&gt;三、DataFrame &amp;amp; DataSet &amp;amp; RDDs 总结&lt;/h2&gt;
&lt;p&gt;这里对三者做一下简单的总结：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;RDDs 适合非结构化数据的处理，而 DataFrame &amp;amp; DataSet 更适合结构化数据和半结构化的处理；&lt;/li&gt;
&lt;li&gt;DataFrame &amp;amp; DataSet 可以通过统一的 Structured API 进行访问，而 RDDs 则更适合函数式编程的场景；&lt;/li&gt;
&lt;li&gt;相比于 DataFrame 而言，DataSet 是强类型的 (Typed)，有着更为严格的静态类型检查；&lt;/li&gt;
&lt;li&gt;DataSets、DataFrames、SQL 的底层都依赖了 RDDs API，并对外提供结构化的访问接口。&lt;/li&gt;
&lt;/ul&gt;&lt;div align=&quot;center&quot;&gt;&lt;img width=&quot;600px&quot; src=&quot;https://raw.githubusercontent.com/heibaiying/BigData-Notes/master/pictures/spark-structure-api.png&quot;/&gt;&lt;/div&gt;
&lt;h2 id=&quot;四spark-sql的运行原理&quot;&gt;四、Spark SQL的运行原理&lt;/h2&gt;
&lt;p&gt;DataFrame、DataSet 和 Spark SQL 的实际执行流程都是相同的：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;进行 DataFrame/Dataset/SQL 编程；&lt;/li&gt;
&lt;li&gt;如果是有效的代码，即代码没有编译错误，Spark 会将其转换为一个逻辑计划；&lt;/li&gt;
&lt;li&gt;Spark 将此逻辑计划转换为物理计划，同时进行代码优化；&lt;/li&gt;
&lt;li&gt;Spark 然后在集群上执行这个物理计划 (基于 RDD 操作) 。&lt;/li&gt;
&lt;/ol&gt;&lt;h3 id=&quot;逻辑计划logical-plan&quot;&gt;4.1 逻辑计划(Logical Plan)&lt;/h3&gt;
&lt;p&gt;执行的第一个阶段是将用户代码转换成一个逻辑计划。它首先将用户代码转换成 &lt;code&gt;unresolved logical plan&lt;/code&gt;(未解决的逻辑计划)，之所以这个计划是未解决的，是因为尽管您的代码在语法上是正确的，但是它引用的表或列可能不存在。 Spark 使用 &lt;code&gt;analyzer&lt;/code&gt;(分析器) 基于 &lt;code&gt;catalog&lt;/code&gt;(存储的所有表和 &lt;code&gt;DataFrames&lt;/code&gt; 的信息) 进行解析。解析失败则拒绝执行，解析成功则将结果传给 &lt;code&gt;Catalyst&lt;/code&gt; 优化器 (&lt;code&gt;Catalyst Optimizer&lt;/code&gt;)，优化器是一组规则的集合，用于优化逻辑计划，通过谓词下推等方式进行优化，最终输出优化后的逻辑执行计划。&lt;/p&gt;
&lt;div align=&quot;center&quot;&gt;&lt;img src=&quot;https://raw.githubusercontent.com/heibaiying/BigData-Notes/master/pictures/spark-Logical-Planning.png&quot;/&gt;&lt;/div&gt;
&lt;h3 id=&quot;物理计划physical-plan&quot;&gt;4.2 物理计划(Physical Plan)&lt;/h3&gt;
&lt;p&gt;得到优化后的逻辑计划后，Spark 就开始了物理计划过程。 它通过生成不同的物理执行策略，并通过成本模型来比较它们，从而选择一个最优的物理计划在集群上面执行的。物理规划的输出结果是一系列的 RDDs 和转换关系 (transformations)。&lt;/p&gt;
&lt;div align=&quot;center&quot;&gt;&lt;img src=&quot;https://raw.githubusercontent.com/heibaiying/BigData-Notes/master/pictures/spark-Physical-Planning.png&quot;/&gt;&lt;/div&gt;
&lt;h3 id=&quot;执行&quot;&gt;4.3 执行&lt;/h3&gt;
&lt;p&gt;在选择一个物理计划后，Spark 运行其 RDDs 代码，并在运行时执行进一步的优化，生成本地 Java 字节码，最后将运行结果返回给用户。&lt;/p&gt;
&lt;h2 id=&quot;参考资料&quot;&gt;参考资料&lt;/h2&gt;
&lt;ol&gt;&lt;li&gt;Matei Zaharia, Bill Chambers . Spark: The Definitive Guide[M] . 2018-02&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://spark.apache.org/docs/latest/sql-programming-guide.html&quot;&gt;Spark SQL, DataFrames and Datasets Guide&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://www.infoq.cn/article/three-apache-spark-apis-rdds-dataframes-and-datasets&quot;&gt;且谈 Apache Spark 的 API 三剑客：RDD、DataFrame 和 Dataset(译文)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://databricks.com/blog/2016/07/14/a-tale-of-three-apache-spark-apis-rdds-dataframes-and-datasets.html&quot;&gt;A Tale of Three Apache Spark APIs: RDDs vs DataFrames and Datasets(原文)&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;blockquote readability=&quot;3.75&quot;&gt;
&lt;p&gt;&lt;strong&gt;更多大数据系列文章可以参见 GitHub 开源项目&lt;/strong&gt;： &lt;a href=&quot;https://github.com/heibaiying/BigData-Notes&quot;&gt;&lt;strong&gt;大数据入门指南&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
</description>
<pubDate>Sun, 11 Aug 2019 23:35:00 +0000</pubDate>
<dc:creator>黑白影</dc:creator>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/heibaiying/p/11337617.html</dc:identifier>
</item>
</channel>
</rss>