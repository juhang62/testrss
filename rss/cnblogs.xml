<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="css/feed.xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/" xmlns:og="http://ogp.me/ns#">
<channel>
<atom:link rel="self" href="http://192.168.1.4/fivefilters/makefulltextfeed.php?url=feed.cnblogs.com%2Fblog%2Fsitehome%2Frss&amp;max=10&amp;links=preserve&amp;exc=" />
<atom:link rel="alternate" title="Source URL" href="http://feed.cnblogs.com/blog/sitehome/rss" />
<atom:link rel="related" title="Subscribe to feed" href="http://www.subtome.com/#/subscribe?feeds=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed.cnblogs.com%252Fblog%252Fsitehome%252Frss%26max%3D10%26links%3Dpreserve%26exc%3D&amp;back=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed.cnblogs.com%252Fblog%252Fsitehome%252Frss%26max%3D10%26links%3Dpreserve%26exc%3D" />
<title>博客园_首页</title>
<link></link>
<description>代码改变世界</description>
<item>
<title>HBase轻松入门之HBase架构图解析 - 碎岁语</title>
<link>http://www.cnblogs.com/chorm590/p/10115343.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/chorm590/p/10115343.html</guid>
<description>&lt;p&gt;2018-12-13&lt;/p&gt;
&lt;p&gt;2018-12-20&lt;/p&gt;
&lt;hr/&gt;&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;本篇文章旨在针对初学者以我本人现阶段所掌握的知识就HBase的架构图中各模块作一个概念科普。不对文章内容的“绝对、完全正确性”负责。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;　　关于HBase的架构图，直接抓取网络上图片来分析就好了。它大概长成下面的样子：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1146198/201812/1146198-20181213171418437-1641530045.png&quot; alt=&quot;&quot; width=&quot;948&quot; height=&quot;538&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;图1 HBase架构图&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;　　从上图中可以很直观地看到整个HBase都是基于HDFS之上的。这个HDFS呢，它的全称是Hadoop distributed file system，Hadoop分布式文件系统。关于在《HBase入门指南》中提到的HBase的概念：HBase是一个用于处理大数据的分布式数据库软件。它的分布式特性在这张架构图中已经很直观地体现出来了，并且它的分布式能力是由Hadoop来提供并保证的。（&lt;span&gt;其实哦，HBase的分布式能力并不一定非得基于HDFS的，理论上你任意一个分布式软件都能用来给HBase“基于”用，只不过由于HDFS太流行了，加上大多数的人其实都挺忙的，不喜欢瞎折腾，就拿HDFS来凑合过呗还能换咋的。。。&lt;/span&gt;）&lt;/p&gt;
&lt;p&gt;　　上面图1其实挺零乱挺复杂的，对于这么复杂的一张图，小白同学表示他刚一进来，什么都不知道，就看到常威在打来福。。。哦哦，不是，小白同学说本来我学HBase的干劲挺足的，但刚开始就看到这张图，着实很打击小白同学的自信心啊。既然如此，那我们就来稍微给它简化一下。图1中的各种元素其实都是有它们各自的派系的，稍微划分一下派系后后它大概长成下图2的样子：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1146198/201812/1146198-20181213184836629-1367226765.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;图2 HBase架构派系划分&lt;/span&gt;&lt;/p&gt;
&lt;p&gt; 　　上图2给这个架构图加了几个框框，把它们分成了四个派系A, B, C, D。这个框框虽然很不明显，但是眼睛睁大点还是能看清的，就当锻炼锻炼视力了。&lt;/p&gt;
&lt;p&gt;　　A派系呢就像是王自如的Zealer手机测评团队一样，是独立客观以及第三方的。它就是上帝，A呢就是B, C, D存在的意义。&lt;/p&gt;
&lt;p&gt;　　B派系是Zookeeper，它是用来保证HBase集群的一致性的。&lt;/p&gt;
&lt;p&gt;　　C派系就是HBase集群了。有些同学可能发现了，C派系HBase中好像霸占了架构图中Zookeeper的一部分啊，这是画错了吗？非也，其实之所以这样划分，是因为现在的HBase软件体系中已经集成了有Zookeeper模块了，在默认的情况下，你不需要下载一个额外的Zookeeper软件，也能够正常运行HBase系统，并且拥有一个Zookeeper相关的进程。因此C派系中也占有了一丢丢Zookeeper的内容。但是其实是生产环境中，很少会用HBase自带的Zookeeper的。&lt;/p&gt;
&lt;p&gt;　　D派系呢，就是任劳任怨的HDFS了。&lt;/p&gt;
&lt;p&gt;　　上面简单的了解了一下HBase架构图中的各大派系，相信到这里，各位小白同学能够稍微对这张HBase的架构图不那么陌生了。什么？上面的图还是太恶心？好吧，那我们再进一步的处理一下这张图片，这次我直接放大招，把HBase架构图抽象一下，排除一切外在干扰，就不信你还看不懂它们之间的关系。看下图：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1146198/201812/1146198-20181213190517507-378708130.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;图3 HBase架构图抽象版&lt;/span&gt;&lt;/p&gt;


&lt;p&gt;　　继续继续，下面要详细讲讲图1 HBase架构中各模块的含义了，这部分的内容就相当让人脑阔疼咯。我们以上帝视角，从客户端Client自上往下讲起。&lt;/p&gt;
&lt;h2&gt;2.1、Client&lt;/h2&gt;
&lt;p&gt;　　首先还是要来了解一下概念。Client到底是什么东东？&lt;/p&gt;
&lt;p&gt;　　从广义的角度来说， Client其实就是你自己，Client是人！上面我们才刚刚讲过，B, C, D，也就是Hadoop， HBase以及Zookeeper存在的意义就是要服务于A，也就是Client，也就是人。假如都没有人去操作这个HBase系统了，那你HBase系统的功能再强大又有什么意义呢？有的同学可能要抬杠了，说人家企业里的HBase系统，都是无人植守，按照程序自动去运行，一样跑的很嗨啊，哪像你说的那样，没有人去操作HBase系统就没有意义了。好的，这位同学请坐下。这些跑的很嗨的程序还不是由人去写的。。程序其实就是人类的意志的产物而已，程序怎么跑还不是由人说了算。所以，归根结底。无论是你坐在电脑前对着hbase shell敲命令行，还是自己写代码去操纵HBase，亦或是在地球的另一端通过各种软件来向HBase下达指令，你就是Client。&lt;/p&gt;
&lt;p&gt;　　那从狭义的角度来说，我们下到代码层面来说，Client是HBase开放出来给程序员们使用的&lt;span&gt;各种API接口&lt;/span&gt;。Client也像是一个承上启下的角色，对上要接收来自人的意志，对下要将人的意志转化成一条条HBase程序并逐一执行。&lt;/p&gt;
&lt;p&gt;　　那说了这么多，Client在HBase系统中有什么用呢？其实它只有一个作用。&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;它是整个HBase系统的入口。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;在代码层面来讲，它就是各种API接口。有了这些接口，我们就可以实现对数据的CURD，甚至是发送一些管理级的命令。&lt;/p&gt;

&lt;hr/&gt;
&lt;h2&gt;2.2、Zookeeper&lt;/h2&gt;
&lt;p&gt;Zookeeper也是Apache软件基金会中的一个顶级项目。它是&lt;strong&gt;给分布式系统提供协同服务的软件&lt;/strong&gt;。协同服务是什么鬼？也许会有不少人对这个词很陌生。下面我们就来解释一下什么是协同服务。&lt;/p&gt;
&lt;p&gt;Zookeeper从字面上翻译过来就是：动物园管理员。那为什么会起这么个名字呢？原来啊Apache软件基金会下面关于分布式的软件有很多，它们基本都会联系上一种动物，或名字或LOGO。如Hadoop（小象象）,Pig（油腻猪）,Hive（怪蜜蜂）,HBase（酷海豚）等等等等。那么，在分布式应用当中，同步无疑是其最重要的特性，常有的同步包括：&lt;/p&gt;
&lt;p&gt;　　1、配置同步；&lt;/p&gt;
&lt;p&gt;　　2、时间同步；&lt;/p&gt;
&lt;p&gt;　　3、相互感知（集群中各主机的上线下线消息及各种状态）。&lt;/p&gt;
&lt;p&gt;上面提到的这几个“同步”就是“协同”的白话语言。&lt;/p&gt;
&lt;p&gt;而为了 blah,blah,blah... 就需要一个Zookeeper来专门负责这种“同步服务”。&lt;/p&gt;

&lt;p&gt;除了“同步服务”以外，Zookeeper还保存着HBase系统中的配置信息。什么配置信息呢？&lt;/p&gt;
&lt;p&gt;　　1、master与slaver机器的信息&lt;/p&gt;
&lt;p&gt;地址啊端口啊这些。&lt;/p&gt;
&lt;p&gt;HMaster可以通过查询Zookeeper来了解当前哪些slaver还在正常工作当中。&lt;/p&gt;
&lt;p&gt;假如当前master宕机了，Zookeeper还可以通过保存着的backup master的信息来重新推选出一个新的master，起到保证HBase系统高可用性的作用。&lt;/p&gt;
&lt;p&gt;　　2、保存 hbase:meta 表所在的位置&lt;/p&gt;
&lt;p&gt;hbase:meta 表在HBase中是非常重要的一张表，它是由HBase系统创建并维护的。这里暂且记住它非常重要就好了。&lt;/p&gt;
&lt;p&gt;　　3、保存HBase系统中所有的表信息&lt;/p&gt;
&lt;p&gt;假如客户端发起一个CRUD请求，首先要知道这张表存不存在吧，又保存在哪吧。通过Zookeeper就可以实现非常快速的响应，因为整个Zookeeper都是驻留在内存中的。&lt;/p&gt;
&lt;p&gt;　　4、其它信息&lt;/p&gt;
&lt;p&gt;还有各种杂七杂八但很重要的信息，都由Zookeeper来保存。&lt;/p&gt;

&lt;p&gt;因此，Zookeeper在HBase系统中就是用于给运行在不同机器上的HBase程序提供协同服务的。&lt;/p&gt;

&lt;hr/&gt;
&lt;h2&gt;2.3、HBase&lt;/h2&gt;
&lt;p&gt;　　HBase模块个人理解它就像是一个装饰器。把原本HDFS(&lt;span&gt;Hadoop distributed file system&lt;/span&gt;)的功能用“数据库的语言”来复述一遍。它在集群中共有两个进程：1. &lt;strong&gt;HMaster&lt;/strong&gt;； 2. &lt;strong&gt;HRegionServer&lt;/strong&gt;。整个架构图中HBase部分这么繁杂，概括出来其实也就两个东东而已。。。&lt;/p&gt;
&lt;h3&gt;　　2.3.1、HMaster&lt;/h3&gt;
&lt;p&gt;首先在这里先简单了解一下“HBase集群”的概念。HBase集群中有若干台计算机，其中有一台是“主机（Master）”，其余的都是“从机（Slaver）”。一般在生产系统中，还会有一台“备用主机（backup master）”。&lt;/p&gt;
&lt;p&gt;这个HMaster进程，就是运行在“主机”上的。准确的说，应该是HMaster在哪一台计算机上运行，哪一台计算机就是“主机”。&lt;/p&gt;
&lt;p&gt;HMaster既然作为一个“上位者”，那它肯定是轻易不会去干活的，不然领导的尊严何在？类比一下企业当中的master，他们的日常工作就对外搞搞外交，对内签签名，再视察一下各部门的工作情况，还会根据企业现阶段的发展状况作一下资源调度等等。那我们的HBase当中也基本一样，唯一的不同就是HMaster不用去外面搞外交，它只处理自己HBase系统内部的事务。&lt;/p&gt;
&lt;p&gt;　　　　HMaster的作用主要有以下几个：&lt;/p&gt;
&lt;p&gt;　　　　　　&lt;span&gt;&lt;strong&gt;1、分发Region&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;首先，Region是什么？在HBase中，如果一张表所包含的内容超过设定的上限，即一张表很大的话，会将这张表水平地分成两半。比如，某张表共有1000行20列数据，HBase嫌这张表太大了，影响我检索效率。将它分成两部分，第一部分内容为第1 ~ 499行。第二部分内容为第500 ~ 1000行。那这切分出来的部分，就被称为Region。在这里，就是有两个Region。&lt;/p&gt;
&lt;p&gt;其次，HBase系统会将这些Region尽量均衡地分发给这些“从机（Slaver）”。让集群中每台从机都干同样多同样重的活。这可以说是HMaster的首要任务。&lt;/p&gt;
&lt;p&gt;　　　　　　&lt;span&gt;&lt;strong&gt;2、监控HRegionServer&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;　　　　　　　　&lt;strong&gt;* 负责HRegionServer的故障转移&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;HRegionServer会定期地向HMaster发送心跳报告。当HMaster收不到HRegionServer的消息时，就认为该HRegionServer已经失去作用了。这个时候HMaster就得下达指令，将原本在HRegionServer上的数据迁移到其它正常工作的机器上去。到这里你肯定会有个疑问：根据前面讲到的判断HRegionServer故障的方式来看，这个时候HMaster已经不能够和该HRegionServer通信了，那你是怎么下达指令，让原本在这台HRegionServer上的数据进行迁移的呢？这个问题，这里暂且不讲，我们只要知道，它能够做到就是了。刚开始接触，不要一下子灌输太多概念，很容易乱的。HDFS的好处在这就体现出来了。&lt;/p&gt;

&lt;p&gt;　　　　　　　　&lt;strong&gt;* 负责HRegionServer的负载均衡&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;当HBase系统中某台机器上的某个Region的大小超过上限时，它会被RegionServer切割成两半，切割后多出来的一个Region又会由HMaster根据集群的情况来做负载均衡，其目的就是尽可能地让每台从机干同样多同样重的活。这里还有一个：RegionServer中由“小合并”“大合并”生成的Region也会需要HMaster来做负载均衡。&lt;/p&gt;
&lt;p&gt;那这里又有一个新的疑问：HMaster是如何得知HRegionServer是忙还是闲的呢？  HRegionServer会定期向HMaster发送一份自己的运行报告，类似于企业当中各部门领导定期向老板递交工作报告一样。然后HMaster就汇总这些运行报告并分析从而作出决策并最终下达指令。&lt;/p&gt;

&lt;p&gt;　　　　　　&lt;strong&gt;&lt;span&gt;3、管理元数据&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;在HBase中有一个由系统创建的表： hbase:meta 。这里我们姑且称它为“元数据表”。那这个“元数据表”是干什么用的呢？&lt;/p&gt;
&lt;p&gt;原来啊，在HBase中，所有的数据都是以“表”的形式来管理的。而当你的表增长到一定程度的时候，它会影响到你CRUD的效率。举个粟子，假设你的某张表A里有1亿条数据，现在你要查询其中一条数据。又假设你又有一张表B里面有1000条数据，同样你要查询其中一条数据，你说A和B哪个检索速度快？因此，当你的表增长到一定程度时，HMaster就会把这个表切割成几块，假设有一张表共有1000行，HMaster把它分割成两块T1和T2，T1的数据范围从第0行到第499行。T2的数据范围从第500行到第999行。不同的块根据负载均衡存储在不同的HRegionServer中。然后你要查询某一条数据的话，就首先确定你这条数据是坐落在哪一个“块”当中的，确定好后直接去这个“块”当中查询，这样检索速度就快很多了。那么，这些不同的“块”被分别存储到哪个HRegionServer中呢？这些不同的“块”又是包含了哪些范围的数据呢？这些信息就是记载在这个 hbase:meta 也就是“元数据”表中的了。一句大白话总结：&lt;strong&gt;元数据表是负责记载你想要查询的数据是在哪台HRegionServer上保存着的信息的&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;那话说回来，HMaster对于“元数据表”的管理方式，就是负责更新这个表中的数据内容的咯，换句话说就是如果HMaster挂掉了，那这个hbase:meta的数据就停止更新了。&lt;/p&gt;

&lt;h3&gt;　　2.3.2、HRegionServer&lt;/h3&gt;
&lt;p&gt;　　　　HRegionServer就复杂咯。。。&lt;/p&gt;
&lt;p&gt;　　　　我们还是再来看看HRegionServer的架构图吧。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1146198/201812/1146198-20181214103340382-596022782.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;图4 HRegionServer架构图&lt;/span&gt;&lt;/p&gt;
&lt;p&gt; 　　　　首先呢要明确一个概念：一个HRegionServer就代表着一台计算机。我们这里所讲的一切都是基于这个大前提来讲的。事实上确实也是，一台计算机上就运行一个HRegionServer进程，我不确定会不会有运行两个HRegionServer进程的计算机，但是我觉得既然你要玩分布式，一台机器上跑两个HRegionServer就没有分布式的意义了。&lt;/p&gt;
&lt;p&gt;　　　　接着我们来看一下HRegionServer中都有哪些东西。A picture is worth than a thousand words.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1146198/201812/1146198-20181214110050368-1189372635.png&quot; alt=&quot;&quot; width=&quot;685&quot; height=&quot;493&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;图5 HRegionServer组成&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;　　　　下面来了解了解HRegionServer的各个组成部分的基本概念。。。&lt;/p&gt;
&lt;h4&gt;　　　　　　1、 HLog&lt;/h4&gt;
&lt;p&gt;首先，一个HRegionServer中就只有一个HLog。&lt;/p&gt;
&lt;p&gt;HLog它是采用一种叫做预写日志（write-ahead logging，简称WAL）的方式来记录数据的日志文件。数据在这个日志文件里起到一个备份的作用，它是用来作容灾的。HLog也是存储在HDFS上的。&lt;/p&gt;
&lt;p&gt;当Client想要写数据到HBase数据库中时，数据首先会写到这个HLog中。当数据在HLog中成功保存以后就会告诉客户端：我已经成功保存好你要我保存的数据了。随后进行下一步的保存操作。需要注意的是，数据成功保存进HLog中以后，仅仅完成了HBase数据存储的三分之一而已。但在这里，不讲这么多。&lt;/p&gt;

&lt;h4&gt;　　　　　　2、HRegion&lt;/h4&gt;
&lt;p&gt;一个HRegionServer中有0 ~ n个HRegion。HRegion同HRegionServer一样，在计算机中都只是一段程序而已。一个HRegion代表着一个从“表”中分割出来的“块”，即&lt;strong&gt;HRegion代表着Region&lt;/strong&gt;。很费解吧！HRegion是一段程序，Region是一小段逻辑表数据。每一个HRegion内部又维护着0 ~ n个Store，结合上图5来看，这部分非常的绕。一个Store呢就代表着一个列族。什么是列族？在这里先简单地把它理解成是“好几个列的集合”。同时，每一个Store内部又维护着一个MemStore和0 ~ n个StoreFile。这个MemStore是一段内存空间。而这个StoreFile就是HFile，是最终存储数据用的在HDFS之上的真实文件。就是说，假如你往HBase中保存了你心仪小姐姐的照片，那么这个照片最终会被存储到某一个HFile文件中。&lt;/p&gt;

&lt;p&gt;这里我们再来淡淡HRegionServer是如何存储数据的。前面在HLog部分只讲了HBase数据存储的三分之一。HRegionServer在收到数据存储的请求以后，首先会将这些要被存储的数据写到HLog中。当HLog中写成功以后，再将这些数据写到MemStore中。而MemStore由于是内存，你往内存中写数据那速度就快了，在往内存中也写成功以后呢，HRegionServer就要向Client返回一个“我已经把你要我保存的数据保存起来了”的信号了。但是实际上HRegionServer在“骗”你。这个时候你如果到HDFS的后台上去看，你根本找不到你要保存的那段数据的文件。换句话说，HBase之所以要管理起大数据来速度这么快，很大一部分功劳在于它是一个很“狡猾的骗子”。HRegionServer啊，只有在MemStore中存储的数据达到一定的量以后，才会一次性的将这些数据输出到HFile中。其实这种方式优点还是很明显的，既以提升“Client的响应”速度，又能减少IO操作，在数据存储中，减少IO就意味着延长存储介质的寿命，存储介质寿命延长了更意味着企业能降低运维成本。厉害了。。。&lt;/p&gt;
&lt;p&gt;好了关于HBase的存储流程，当然没有这么简单，但是在这里仅需要简单地了解这些就够了，慢慢来嘛，整个HBase系统可是比女人心还要复杂的，一下子让你接受太多，恐怕你要受不住啊。。。&lt;/p&gt;

&lt;p&gt;　　　　在知道了HRegionServer的组成以后，就可以了解了解HRegionServer的职责了。&lt;/p&gt;
&lt;p&gt;　　　　　　1、托管数据&lt;/p&gt;
&lt;p&gt;前面我们已经知道了HMaster它只负责作决策。实际的数据存储的工作则全部交由HRegionServer来做。即&lt;strong&gt;HRegionServer就是用来存储实际数据的&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;　　　　　　2、维护HLog&lt;/p&gt;
&lt;p&gt;　　　　　　　　负责更新或删除HLog中的内容。HLog是直接按行存储的，即只要你客户端发送一次存储请求过来，我都直接在HLog的末尾按一定格式添加进去，不给你分类。并且在这些数据内容被持久化到HDFS中以后，会删除掉HLog中对应的信息。&lt;/p&gt;

&lt;p&gt;　　　　　　3、大、小合并。&lt;/p&gt;
&lt;p&gt;　　　　　　　　就是minor compaction与major compaction。简言之，如果HBase系统中小文件太多了，将它合并成一个大一点的文件。&lt;/p&gt;

&lt;p&gt;　　　　　　4、监控Region&lt;/p&gt;
&lt;p&gt;HRegionServer监控Region的什么东西呢？ 当然是监控它的尺寸了。你想想嘛，HBase就是号称针对大数据高速检索的数据库，你一个Region要是过于庞大那就是一个文件过于庞大，那它还怎么来保证大数据的高速检索。HRegionServer会定期将自己管辖的Region的尺寸数据生成一个报告发给HMaster。如果HMaster发现某个Region过大了，就要下达指令，让HRegionServer将这个Region分割成2块。下达分割指令的是HMaster，指令的执行者是RegionServer。&lt;/p&gt;


&lt;hr/&gt;
&lt;h2&gt;2.4、Hadoop&lt;/h2&gt;
&lt;p&gt;　　Hadoop也是Apache软件基金会的顶级项目。它是一个分布式系统架构。&lt;/p&gt;
&lt;p&gt;　　它在HBase系统中就负责帮RegionServer以分布式的方式管理各个HFile文件。&lt;/p&gt;
&lt;p&gt;　　再说的通俗一点吧。把整个HBase系统比喻成一家企业。Master是这家企业的老板，Slaver可以比喻成是公司财务。数据比喻成是资金。由老板下达决策，将所有资金划拨到不同用途。财务负责帮老板管钱。那这么多的钱，财务精力有限能力有限，不可能自己管的过来啊。那怎么办？只能交给银行来管了。Hadoop，也就是HDFS就起到类似于银行的角色。&lt;/p&gt;
&lt;p&gt;　　这篇文章已经够长了，就只聊这么多了。个人认为，如果你是一个初学者的话，就不要一下子灌输太多的概念，一来很难消化的了这么多内容，二来容易打击自己的积极性。只了解一个基本的概念，详细的知识可以在后面的使用过程中慢慢学习。这里尤其千万要告诫你们的一点就是：&lt;strong&gt;初学者不要接触HBase源代码&lt;/strong&gt;。不解释，信我，没错的。&lt;/p&gt;

&lt;p&gt; - The end -&lt;/p&gt;

</description>
<pubDate>Thu, 20 Dec 2018 07:25:00 +0000</pubDate>
<dc:creator>碎岁语</dc:creator>
<og:description>2018-12-13 2018-12-20 本篇文章旨在针对初学者以我本人现阶段所掌握的知识就HBase的架构图中各模块作一个概念科普。不对文章内容的“绝对、完全正确性”负责。 1、开胃小菜 关于HB</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/chorm590/p/10115343.html</dc:identifier>
</item>
<item>
<title>Asp.NetCore程序发布到CentOs(含安装部署netcore)--最佳实践 - 幕三少</title>
<link>http://www.cnblogs.com/smiler/p/10149603.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/smiler/p/10149603.html</guid>
<description>&lt;h2 id=&quot;环境&quot;&gt;环境&lt;/h2&gt;
&lt;ul&gt;&lt;li&gt;本地 win7&lt;/li&gt;
&lt;li&gt;服务器：Virtual Box 上的Centos&lt;/li&gt;
&lt;li&gt;ssh工具： Xshell&lt;/li&gt;
&lt;li&gt;文件传输： xftp&lt;/li&gt;
&lt;/ul&gt;&lt;h2 id=&quot;在本地创建asp.net-core应用发布&quot;&gt;1.在本地创建asp.net core应用发布&lt;/h2&gt;
&lt;h3 id=&quot;使用vs2017-新建一个asp.netcore项目&quot;&gt;1.1 使用Vs2017 新建一个asp.netcore项目&lt;/h3&gt;
&lt;p&gt;步骤略(一路next),当然你也可以用命令行创建。&lt;/p&gt;
&lt;h3 id=&quot;发布项目&quot;&gt;1.2 发布项目&lt;/h3&gt;
&lt;p&gt;在项目路径下执行命令&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;dotnet publish –c release&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;先本地运行是否有问题，减少因为本地程序造成发布不成功的几率。程序就简单介绍一下，下面部署是管件。&lt;/p&gt;
&lt;h2 id=&quot;安装netcore-sdk&quot;&gt;2.安装netcore SDK&lt;/h2&gt;
&lt;h3 id=&quot;环境准备&quot;&gt;2.1 环境准备&lt;/h3&gt;
&lt;p&gt;我这里是在VirtualBox上安装的Centos.&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;需要首先记录一点，就是虚拟机最小化安装CentOS 7 默认没有启动网络配置,所以是不能上网的。&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;接下来就通过vi命令编辑网卡配置文件ifcfg-enp0s3（其他版本名称可能略有不同，但路径一致）。具体命令如下&lt;/p&gt;
&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;vi /etc/sysconfig/network-scripts/ifcfg-enp0s3&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;将ONBOOT=no改为ONBOOT=yes，设置随系统开机运行。然后:wq强制保存并退出编辑文件即可。&lt;/p&gt;
&lt;p&gt;最后，需要重启一下网络服务。命令如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;service network restart&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;然后ping www.baidu.com 检查是否可以正常上网了。&lt;br/&gt;这时就可以用xshell连接服务器。&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;最小化安装同样没有ifconfig等网络命令，这里为了方便可以安装net-tools工具包&lt;/li&gt;
&lt;/ol&gt;&lt;pre&gt;
&lt;code&gt;yum update
yum install net-tools&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;安装.net-core-sdk&quot;&gt;2.2 安装.NET Core SDK&lt;/h3&gt;
&lt;h4 id=&quot;安装libicu依赖&quot;&gt;2.2.1 安装libicu依赖&lt;/h4&gt;
&lt;pre&gt;
&lt;code&gt;yum install libunwind libicu&lt;/code&gt;
&lt;/pre&gt;
&lt;h4 id=&quot;注册dotnet-的repository&quot;&gt;2.2.2 注册dotnet 的repository&lt;/h4&gt;
&lt;p&gt;您需要注册Microsoft签名密钥并添加Microsoft产品提要&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;sudo rpm -Uvh https://packages.microsoft.com/config/rhel/7/packages-microsoft-prod.rpm&lt;/code&gt;
&lt;/pre&gt;
&lt;h4 id=&quot;安装&quot;&gt;2.2.3 安装&lt;/h4&gt;
&lt;pre&gt;
&lt;code&gt;sudo yum update
sudo yum install dotnet-sdk-2.2&lt;/code&gt;
&lt;/pre&gt;
&lt;h4 id=&quot;安装完成&quot;&gt;2.2.4 安装完成&lt;/h4&gt;
&lt;pre&gt;
&lt;code&gt;dotnet --info&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;a href=&quot;https://dotnet.microsoft.com/learn/dotnet/hello-world-tutorial&quot;&gt;微软官方参考&lt;/a&gt;&lt;br/&gt;&lt;a href=&quot;https://blog.csdn.net/u012920852/article/details/79404433&quot;&gt;参考1&lt;/a&gt;&lt;/p&gt;
&lt;h4 id=&quot;发布程序测试&quot;&gt;2.2.5 发布程序测试&lt;/h4&gt;
&lt;ol&gt;&lt;li&gt;这里先将刚开始发布的程序通过xftp传输到centos服务器上，进入程序文件夹。运行程序&lt;/li&gt;
&lt;/ol&gt;&lt;pre&gt;
&lt;code&gt;dotnet MyApp.dll&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;但是报错了，如下图&lt;br/&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/75468/201812/75468-20181220151544380-615578116.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;这里说明一下：因为本地使用的sdk2.1，所以我没选最高版本，而是yum search dotnet-sdk,选的是显示的2.1的最高版本，也就是dotnet-skd-2.1.4。&lt;br/&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/75468/201812/75468-20181220151857452-283774571.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;以为是服务端的sdk版本太,但是通过dotnet --info查看本地版本，如下图：&lt;br/&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/75468/201812/75468-20181220151950856-1502988493.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;服务端如下：&lt;br/&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/75468/201812/75468-20181220151932677-1759810734.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;显然是服务器端安装的版本太低了。所以重新安装了2.2版本，&lt;br/&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/75468/201812/75468-20181220152013559-593581249.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;然后再运行&lt;br/&gt;显示运行成功。这里耽误了好一会时间。&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;测试&lt;/li&gt;
&lt;/ol&gt;&lt;pre&gt;
&lt;code&gt;curl http://locahost:5000/api/values&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;可以正常获取信息了&lt;br/&gt;但是远程浏览器访问，无法访问。这就怪了，为啥呢？&lt;br/&gt;服务器上用ip地址访问：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;curl http://10.100.15.17:5000/api/values&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/75468/201812/75468-20181220152114001-1245546242.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;也是不通，最后才发现，原来默认是无法通过ip访问。（有大神知道原因可以知道一下）&lt;br/&gt;然后关闭重新启动，加上url参数&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;dotnet MyApp.dll --server.urls=&quot;http://*:5000&quot;
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/75468/201812/75468-20181220152146620-1574691259.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;此时再通过IP访问，OK通过。&lt;br/&gt;本地浏览器访问，OK也通过。&lt;/p&gt;
&lt;p&gt;好了这里就可以正常使用，当然测试没问题了，生产绝对不能这样搞。下边还要使用nginx，以及守护程序之类的。&lt;/p&gt;
</description>
<pubDate>Thu, 20 Dec 2018 07:23:00 +0000</pubDate>
<dc:creator>幕三少</dc:creator>
<og:description>环境 本地 win7 服务器：Virtual Box 上的Centos ssh工具： Xshell 文件传输： xftp 1.在本地创建asp.net core应用发布 1.1 使用Vs2017 新建</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/smiler/p/10149603.html</dc:identifier>
</item>
<item>
<title>Kafka的安全认证机制SASL/PLAINTEXT - pinezhang</title>
<link>http://www.cnblogs.com/ilovena/p/10123516.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/ilovena/p/10123516.html</guid>
<description>&lt;p&gt;kafka提供了多种&lt;a href=&quot;http://kafka.apache.org/documentation/#security&quot;&gt;安全认证机制&lt;/a&gt;，主要分为SSL和SASL2大类。其中SASL/PLAIN是基于账号密码的认证方式，比较常用。最近做了个kafka的鉴权，发现官网上讲的不是很清楚，网上各种博客倒是很多，但是良莠不齐，巨多坑。经过一天的研究，终于搞定了，特在此记录下。&lt;/p&gt;

&lt;p&gt;操作系统：linux&lt;br/&gt;kafka版本：kafka_2.12-0.11.0.1&lt;br/&gt;zookeeper版本：zookeeper-3.5.1-alpha&lt;/p&gt;

&lt;h2 id=&quot;zookeeper配置和启动&quot;&gt;3.1.Zookeeper配置和启动&lt;/h2&gt;
&lt;p&gt;1.为zookeeper添加SASL支持，在配置文件zoo.cfg添加&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;authProvider.1=org.apache.zookeeper.server.auth.SASLAuthenticationProvider
requireClientAuthScheme=sasl
jaasLoginRenew=3600000&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;2.新建zk_server_jaas.conf文件，为Zookeeper添加账号认证信息&lt;br/&gt;这个文件你放在哪里随意，只要后面zkEnv配置正确的路径就好了。我是放在/home路径下。zk_server_jaas.conf文件的内容如下&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;Server {
    org.apache.kafka.common.security.plain.PlainLoginModule required
    username=&quot;cluster&quot;
    password=&quot;clusterpasswd&quot;
    user_kafka=&quot;kafkapasswd&quot;;
};&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;username和paasword是zk集群之间的认证密码。&lt;br/&gt;user_kafka=&quot;kafkapasswd&quot;定义了一个用户&quot;kafka&quot;，密码是&quot;kafkapasswd&quot;，本次测试用户是kafka broker。&lt;br/&gt;3.导入kafka的相关jar&lt;br/&gt;由上一步可发现，认证方式使用的是Kafka的认证类org.apache.kafka.common.security.plain.PlainLoginModule。因此zk需要依赖几个jar包。&lt;br/&gt;在/home下新建zk_sasl_dependency目录，从kafka/lib目录下复制以下几个jar包到该目录下。根据kafka版本不同，几个jar包的版本可能不一样&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;kafka-clients-0.11.0.1.jar
lz4-1.3.0.jar
slf4j-api-1.7.25.jar
slf4j-log4j12-1.7.25.jar
snappy-java-1.1.2.6.jar&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;4.修改zkEnv.sh&lt;br/&gt;在zkEnv.sh添加&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;for i in /home/zk_sasl_dependency/*.jar; 
do 
    CLASSPATH=&quot;$i:$CLASSPATH&quot;
done
SERVER_JVMFLAGS=&quot; -Djava.security.auth.login.config=/home/zk_server_jaas.conf &quot;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;关于这一步，网上的配置五花八门，但是原理都是jar包导入和认证信息配置。&lt;br/&gt;在zk启动的时候导入/home/zk_sasl_dependency/的jar包，SERVER_JVMFLAGS配置jvm参数，导入zk的sasl认证信息。&lt;br/&gt;5.启动zk服务端&lt;br/&gt;执行./zkServer.sh start启动zk。如果启动异常查看日志排查问题。&lt;/p&gt;

&lt;p&gt;1.新建kafka_server_jaas.conf,为kafka添加认证信息&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;KafkaServer {
 org.apache.kafka.common.security.plain.PlainLoginModule required
 username=&quot;cluster&quot;
 password=&quot;cluster&quot;
 user_cluster=“clusterpasswd”
 user_kafka=&quot;kafkapasswd&quot; ;
};
Client{
 org.apache.kafka.common.security.plain.PlainLoginModule required  
 username=&quot;kafka&quot;  
 password=&quot;kafkapasswd&quot;;  
};&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;KafkaServer，第一行指定了认证方法为PLAIN,usernam和password是kafka的多个broker之间进行认证的账号密码。&lt;br/&gt;user_kafka=&quot;kafkapasswd&quot;设置了用户kafka，密码为kafkapswd，用于客户端的生产者和消费者连接认证。&lt;br/&gt;网上的说法是 &lt;em&gt;Client，是kafka作为用户使用zk的认证信息，这里的username和password一定要和zk_server_jaas.conf的配置对的上。&lt;/em&gt;&lt;br/&gt;&lt;strong&gt;但是我试验发现 user_cluster=“clusterpasswd”才是真正进行认证的信息，这个Client好像一点用没有，删掉也可以正常启动server，kafka服务也是正常的，费解啊！&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;2.在kafka的配置文件开启SASL认证&lt;br/&gt;在server.properties添加如下信息&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;listeners=SASL_PLAINTEXT://(IP):9092
security.inter.broker.protocol=SASL_PLAINTEXT
sasl.mechanism.inter.broker.protocol=PLAIN 
sasl.enabled.mechanisms=PLAIN
allow.everyone.if.no.acl.found=true&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;3.在server启动脚本JVM参数&lt;br/&gt;我是直接在&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;export KAFKA_HEAP_OPTS=&quot;-Xmx1G -Xms1G&quot;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;添加了认证信息,修改后为&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;export KAFKA_HEAP_OPTS=&quot;-Xmx1G -Xms1G -Djava.security.auth.login.config=/home/kafka_server_jaas.conf&quot;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;4.启动kafka服务端&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;./kafka-server-start.sh ../config/server.properties&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;kafka服务端正常启动后，应该会有类似下面这行的日志信息,说明认证功能开启成功&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;Registered broker 0 at path /brokers/ids/0 with addresses: EndPoint((IP),9092,ListenerName(SASL_PLAINTEXT),SASL_PLAINTEXT) (kafka.utils.ZkUtils)&lt;/code&gt;
&lt;/pre&gt;

&lt;h2 id=&quot;使用kafka脚本认证&quot;&gt;1.使用kafka脚本认证&lt;/h2&gt;
&lt;p&gt;我们使用kafka自带的脚本进行认证。&lt;br/&gt;1.新建kafka_client_jaas.conf,为客户端添加认证信息&lt;br/&gt;在/home下新建kafka_client_jaas.conf，添加以下信息&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;KafkaClient {
  org.apache.kafka.common.security.plain.PlainLoginModule required
  username=&quot;kafka&quot;
  password=&quot;kafkapasswd&quot;;
};&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;2.修改客户端配置信息&lt;br/&gt;修改producer.properties和consumer.properties，添加认证机制&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;security.protocol=SASL_PLAINTEXT 
sasl.mechanism=PLAIN &lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;3.修改客户端启动脚本&lt;br/&gt;修改kafka-console-producer.sh，配置认证文件kafka_client_jaas.conf，将&lt;br/&gt;&lt;code&gt;export KAFKA_HEAP_OPTS=&quot;-Xmx512M&quot;&lt;/code&gt;修改为&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;export KAFKA_HEAP_OPTS=&quot;-Xmx512M -Djava.security.auth.login.config=/home/kafka_client_jaas.conf&quot;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;kafka-console-consumer.sh的修改类似。&lt;br/&gt;4.客户端启动并认证&lt;br/&gt;启动consumer&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;./bin/kafka-console-consumer.sh --bootstrap-server (IP):9092 --topic test --from-beginning --consumer.config config/consumer.properties&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;启动producer&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;./bin/kafka-console-producer.sh --broker-list (IP):9092 --topic test --producer.config configoducer.properties&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;producer端发送消息，consumer端成功接收到消息。&lt;/p&gt;
&lt;h2 id=&quot;java客户端认证&quot;&gt;2.Java客户端认证&lt;/h2&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;package com.zte.sdn.oscp.jms.kafka;

import org.apache.kafka.clients.consumer.ConsumerRecord;
import org.apache.kafka.clients.consumer.ConsumerRecords;
import org.apache.kafka.clients.consumer.KafkaConsumer;
import org.apache.kafka.clients.producer.KafkaProducer;
import org.apache.kafka.clients.producer.Producer;
import org.apache.kafka.clients.producer.ProducerRecord;
import org.junit.Test;

import java.util.Collections;
import java.util.Properties;

public class KafkaTest {

    @Test
    public void testProduct() throws Exception {
        System.setProperty(&quot;java.security.auth.login.config&quot;, &quot;F:/kafka_client_jaas.conf&quot;);

        Properties props = new Properties();
        props.put(&quot;bootstrap.servers&quot;, &quot;IP:9092&quot;);
        props.put(&quot;acks&quot;, &quot;all&quot;);
        props.put(&quot;retries&quot;, 0);
        props.put(&quot;batch.size&quot;, 16384);
        props.put(&quot;linger.ms&quot;, 1);
        props.put(&quot;buffer.memory&quot;, 33554432);
        props.put(&quot;key.serializer&quot;, &quot;org.apache.kafka.common.serialization.StringSerializer&quot;);
        props.put(&quot;value.serializer&quot;, &quot;org.apache.kafka.common.serialization.StringSerializer&quot;);

        props.put(&quot;security.protocol&quot;, &quot;SASL_PLAINTEXT&quot;);
        props.put(&quot;sasl.mechanism&quot;, &quot;PLAIN&quot;);

        Producer&amp;lt;String, String&amp;gt; producer = new KafkaProducer&amp;lt;&amp;gt;(props);
        while (true){
            long startTime = System.currentTimeMillis();
            for (int i = 0; i &amp;lt; 100; i++) {
                producer.send(new ProducerRecord&amp;lt;&amp;gt;(&quot;kafkatest&quot;, Integer.toString(i), Integer.toString(i)));
            }
            System.out.println(System.currentTimeMillis()-startTime);
            Thread.sleep(5000);
        }
    }

    @Test
    public void testConsumer() throws Exception {
        System.setProperty(&quot;java.security.auth.login.config&quot;, &quot;F:/kafka_client_jaas.conf&quot;);

        Properties props = new Properties();
        props.put(&quot;bootstrap.servers&quot;, &quot;(IP):9092&quot;);
        props.put(&quot;enable.auto.commit&quot;, &quot;true&quot;);
        props.put(&quot;auto.commit.interval.ms&quot;, &quot;1000&quot;);
        props.put(&quot;group.id&quot;, &quot;kafka_test_group&quot;);
        props.put(&quot;session.timeout.ms&quot;, &quot;6000&quot;);
        props.put(&quot;key.deserializer&quot;, &quot;org.apache.kafka.common.serialization.StringDeserializer&quot;);
        props.put(&quot;value.deserializer&quot;, &quot;org.apache.kafka.common.serialization.StringDeserializer&quot;);

        props.put(&quot;security.protocol&quot;, &quot;SASL_PLAINTEXT&quot;);
        props.put(&quot;sasl.mechanism&quot;, &quot;PLAIN&quot;);

        KafkaConsumer&amp;lt;String, String&amp;gt; consumer = new KafkaConsumer&amp;lt;&amp;gt;(props);
        consumer.subscribe(Collections.singletonList(&quot;kafkatest&quot;));
        while (true) {
            long startTime = System.currentTimeMillis();
            ConsumerRecords&amp;lt;String, String&amp;gt; records = consumer.poll(1000);
            System.out.println(System.currentTimeMillis() - startTime);
            System.out.println(&quot;recieve message number is &quot; + records.count());
            for (ConsumerRecord&amp;lt;String, String&amp;gt; record : records) {
                System.out.printf(&quot;offset = %d, key = %s, value = %s, partition = %d %n&quot;,
                        record.offset(),
                        record.key(),
                        record.value(),
                        record.partition());
            }
        }
    }
}&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;客户端认证时延问题&quot;&gt;3.4客户端认证时延问题&lt;/h2&gt;
&lt;p&gt;认证时发现生产者和消费者和kafka的broker建立连接都有一定时延。在生产者的日志发现时延主要发生在&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;2018-12-17 10:55:46[DEBUG][kafka-producer-network-thread | producer-1]-NetworkClient.java: 762 - Initiating connection to node (IP):9092 (id: 0 rack: null)
2018-12-17 10:55:50[DEBUG][kafka-producer-network-thread | producer-1]-SaslClientAuthenticator.java: 209 - Set SASL client state to SEND_HANDSHAKE_REQUEST&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;难道客户端连接服务端时，认证时间需要这么长？？&lt;/strong&gt;&lt;/p&gt;
</description>
<pubDate>Thu, 20 Dec 2018 07:22:00 +0000</pubDate>
<dc:creator>pinezhang</dc:creator>
<og:description>一.背景 kafka提供了多种</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/ilovena/p/10123516.html</dc:identifier>
</item>
<item>
<title>SpringCloud系列——Config 配置中心 - huanzi-qch</title>
<link>http://www.cnblogs.com/huanzi-qch/p/10149547.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/huanzi-qch/p/10149547.html</guid>
<description>&lt;h2&gt;　　前言&lt;/h2&gt;
&lt;p&gt;　　Spring Cloud Config为分布式系统中的外部化配置提供了服务器端和客户端支持。有了配置服务器，您就有了一个中心位置来管理跨所有环境的应用程序的外部属性。本文记录实现一个配置中心、客户端获取配置参数、refresh手动刷新&lt;/p&gt;
&lt;p&gt;　　官方文档：&lt;a href=&quot;https://cloud.spring.io/spring-cloud-config/single/spring-cloud-config.html&quot; target=&quot;_blank&quot;&gt;https://cloud.spring.io/spring-cloud-config/single/spring-cloud-config.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;　　帮助文档：&lt;a href=&quot;https://spring.io/guides/gs/centralized-configuration/&quot; target=&quot;_blank&quot;&gt;https://spring.io/guides/gs/centralized-configuration/&lt;/a&gt;&lt;/p&gt;

&lt;h2&gt;　　Config Server&lt;/h2&gt;
&lt;p&gt;　　首先我们基于之前的代码，在springCloud工程下面新建一个Config Server，是一个springboot项目，并且在Eureka上面注册服务（还不会服务注册与发现的，请戳：&lt;a id=&quot;cb_post_title_url&quot; class=&quot;postTitle2&quot; href=&quot;https://www.cnblogs.com/huanzi-qch/p/10131985.html&quot;&gt;SpringCloud系列——Eureka 服务注册与发现&lt;/a&gt;），本例使用的是GitHub&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1353055/201812/1353055-20181220115447632-1700182145.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　maven引jar&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;33&quot;&gt;
&lt;pre&gt;
        &lt;span&gt;&amp;lt;!--&lt;/span&gt;&lt;span&gt; config-server &lt;/span&gt;&lt;span&gt;--&amp;gt;&lt;/span&gt;
        &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;dependency&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
            &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;groupId&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;org.springframework.cloud&lt;span&gt;&amp;lt;/&lt;/span&gt;&lt;span&gt;groupId&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
            &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;artifactId&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;spring-cloud-config-server&lt;span&gt;&amp;lt;/&lt;/span&gt;&lt;span&gt;artifactId&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
        &lt;span&gt;&amp;lt;/&lt;/span&gt;&lt;span&gt;dependency&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　登录GitHub，新建一个public仓库：config-server，并且添加测试项目对应的配置文件：myspringboot-dev.properties，并设置几个值&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1353055/201812/1353055-20181220120244364-371077329.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　配置文件&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;35&quot;&gt;
&lt;pre&gt;
server.port=&lt;span&gt;1112&lt;/span&gt;&lt;span&gt;
spring&lt;/span&gt;.application.name=config-&lt;span&gt;server&lt;br/&gt;eureka&lt;/span&gt;.client.serviceUrl.defaultZone=http://localhost:&lt;span&gt;1111&lt;/span&gt;/eureka/
&lt;span&gt;#&lt;/span&gt;&lt;span&gt;健康检查（需要spring-boot-starter-actuator依赖）&lt;/span&gt;
eureka.client.healthcheck.enabled=&lt;span&gt;true
&lt;/span&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt; 续约更新时间间隔（默认30秒）&lt;/span&gt;
eureka.instance.lease-renewal-interval-in-seconds=&lt;span&gt;10&lt;/span&gt;
&lt;span&gt;#&lt;/span&gt;&lt;span&gt; 续约到期时间（默认90秒）&lt;/span&gt;
eureka.instance.lease-expiration-duration-in-seconds=&lt;span&gt;10&lt;/span&gt;

&lt;span&gt;#&lt;/span&gt;&lt;span&gt;连接GitHub&lt;/span&gt;
spring.cloud.config.server.git.uri=https://github.com/huanzi-qch/config-server.&lt;span&gt;git
spring&lt;/span&gt;.cloud.config.server.git.search-paths=config-&lt;span&gt;server
spring&lt;/span&gt;.cloud.config.label=&lt;span&gt;master
spring&lt;/span&gt;.cloud.config.server.git.username=******&lt;span&gt;
spring&lt;/span&gt;.cloud.config.server.git.password=******
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　启动类加入注解@EnableConfigServer&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;35&quot;&gt;
&lt;pre&gt;
&lt;span&gt;@EnableConfigServer
@EnableEurekaClient
@SpringBootApplication
&lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;&lt;span&gt; ConfigServerApplication {

    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; &lt;span&gt;void&lt;/span&gt;&lt;span&gt; main(String[] args) {
        SpringApplication.run(ConfigServerApplication.&lt;/span&gt;&lt;span&gt;class&lt;/span&gt;&lt;span&gt;, args);
    }
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt; 　　启动项目，访问http://localhost:1112/myspringboot-dev.properties/，发现有中文乱码&lt;/p&gt;
&lt;p&gt;　　注：仓库中的配置文件会被转换成web接口，访问规则：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;/{application}/{profile}[/{label}]&lt;/li&gt;
&lt;li&gt;/{application}-{profile}.yml&lt;/li&gt;
&lt;li&gt;/{label}/{application}-{profile}.yml&lt;/li&gt;
&lt;li&gt;/{application}-{profile}.properties&lt;/li&gt;
&lt;li&gt;/{label}/{application}-{profile}.properties&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1353055/201812/1353055-20181220120742933-1470393603.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　解决中文乱码，参考：https://blog.csdn.net/sinat_38843093/article/details/79960777&lt;/p&gt;
&lt;p&gt;　　新建自定义解析器MyPropertiesHandler，继承PropertiesPropertySourceLoader，重写方法&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;39&quot;&gt;
&lt;pre&gt;
&lt;span&gt;/**&lt;/span&gt;&lt;span&gt;
 * 解决中文乱码问题
 * 参考：&lt;/span&gt;&lt;span&gt;https://blog.csdn.net/sinat_38843093/article/details/79960777&lt;/span&gt;
 &lt;span&gt;*/&lt;/span&gt;
&lt;span&gt;public&lt;/span&gt; &lt;span&gt;class&lt;/span&gt; MyPropertiesHandler &lt;span&gt;extends&lt;/span&gt;&lt;span&gt; PropertiesPropertySourceLoader {

    @Override
    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt;&lt;span&gt; String[] getFileExtensions() {
        &lt;/span&gt;&lt;span&gt;return&lt;/span&gt; &lt;span&gt;new&lt;/span&gt; String[]{&quot;properties&quot;, &quot;xml&quot;&lt;span&gt;};
    }

    @Override
    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; List&amp;lt;PropertySource&amp;lt;?&amp;gt;&amp;gt; load(String name, Resource resource) &lt;span&gt;throws&lt;/span&gt;&lt;span&gt; IOException {
        ArrayList&lt;/span&gt;&amp;lt;PropertySource&amp;lt;?&amp;gt;&amp;gt; list = &lt;span&gt;new&lt;/span&gt; ArrayList&amp;lt;&amp;gt;&lt;span&gt;();
        Properties properties &lt;/span&gt;=&lt;span&gt; getProperties(resource);
        &lt;/span&gt;&lt;span&gt;if&lt;/span&gt; (!&lt;span&gt;properties.isEmpty()) {
            list.add(&lt;/span&gt;&lt;span&gt;new&lt;/span&gt;&lt;span&gt; PropertiesPropertySource(name, properties));
        }
        &lt;/span&gt;&lt;span&gt;return&lt;/span&gt;&lt;span&gt; list;
    }

    &lt;/span&gt;&lt;span&gt;private&lt;/span&gt; Properties getProperties(Resource resource) &lt;span&gt;throws&lt;/span&gt;&lt;span&gt; IOException {
        Properties properties &lt;/span&gt;= &lt;span&gt;new&lt;/span&gt;&lt;span&gt; Properties();
        InputStream inputStream &lt;/span&gt;=&lt;span&gt; resource.getInputStream();
        properties.load(&lt;/span&gt;&lt;span&gt;new&lt;/span&gt;&lt;span&gt; InputStreamReader(inputStream, StandardCharsets.UTF_8));
        inputStream.close();
        &lt;/span&gt;&lt;span&gt;return&lt;/span&gt;&lt;span&gt; properties;
    }
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　resources文件夹下面新建META-INF文件夹，在里面创建spring.factories文件，指定使用我们自定义的解析器&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;33&quot;&gt;
&lt;pre&gt;
org.springframework.boot.env.PropertySourceLoader=cn.huanzi.qch.config.configserver.MyPropertiesHandler
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　重新启动项目，在自定义解析器后进行断点调试，发现解析的时候中文乱码问题得以解决，但响应回去还是乱码&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1353055/201812/1353055-20181220121610987-915192934.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1353055/201812/1353055-20181220121712329-1904066888.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　解决http响应中文乱码问题&lt;/p&gt;
&lt;p&gt;　　配置文件添加&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;33&quot;&gt;
&lt;pre&gt;
&lt;span&gt;#&lt;/span&gt;&lt;span&gt;解决http响应数据中文乱码问题&lt;/span&gt;
spring.http.encoding.force=&lt;span&gt;true
spring&lt;/span&gt;.http.encoding.charset=UTF-&lt;span&gt;8&lt;/span&gt;&lt;span&gt;
spring&lt;/span&gt;.http.encoding.enabled=&lt;span&gt;true
server&lt;/span&gt;.tomcat.uri-encoding=UTF-&lt;span&gt;8&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　最终效果&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1353055/201812/1353055-20181220121430338-1936394793.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt; 　　我们去GitHub修改配置中心的值，看下config server能不能实时获取最新数据&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1353055/201812/1353055-20181220121948846-77063093.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　改完后刷新http://localhost:1112/myspringboot-dev.properties/，配置中心可以实时获取最新数据&lt;/p&gt;
&lt;p&gt; &lt;img src=&quot;https://img2018.cnblogs.com/blog/1353055/201812/1353055-20181220122020566-2026455732.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;h2&gt;　　Config Client&lt;/h2&gt;
&lt;p&gt;　　客户端我们直接用之前的项目：myspringboot，这里就当做一个在Eureka上注册了的普通springboot项目&lt;/p&gt;
&lt;p&gt;　　maven引入jar&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;33&quot;&gt;
&lt;pre&gt;
        &lt;span&gt;&amp;lt;!--&lt;/span&gt;&lt;span&gt; config-client &lt;/span&gt;&lt;span&gt;--&amp;gt;&lt;/span&gt;
        &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;dependency&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
            &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;groupId&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;org.springframework.cloud&lt;span&gt;&amp;lt;/&lt;/span&gt;&lt;span&gt;groupId&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
            &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;artifactId&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;spring-cloud-starter-config&lt;span&gt;&amp;lt;/&lt;/span&gt;&lt;span&gt;artifactId&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
        &lt;span&gt;&amp;lt;/&lt;/span&gt;&lt;span&gt;dependency&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　application.properties&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;35&quot;&gt;
&lt;pre&gt;
&lt;span&gt;#&lt;/span&gt;&lt;span&gt;设置服务端口&lt;/span&gt;
server.port=&lt;span&gt;10087&lt;/span&gt;&lt;span&gt;
spring&lt;/span&gt;.application.name=&lt;span&gt;myspringboot&lt;/span&gt;&lt;span&gt;

#eureka&lt;/span&gt;
eureka.client.serviceUrl.defaultZone=http://localhost:&lt;span&gt;1111&lt;/span&gt;/eureka/
&lt;span&gt;#&lt;/span&gt;&lt;span&gt;健康检查（需要spring-boot-starter-actuator依赖）&lt;/span&gt;
eureka.client.healthcheck.enabled=&lt;span&gt;true
&lt;/span&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt; 续约更新时间间隔（默认30秒）&lt;/span&gt;
eureka.instance.lease-renewal-interval-in-seconds=&lt;span&gt;10&lt;/span&gt;
&lt;span&gt;#&lt;/span&gt;&lt;span&gt; 续约到期时间（默认90秒）&lt;/span&gt;
eureka.instance.lease-expiration-duration-in-seconds=&lt;span&gt;10&lt;/span&gt;
&lt;span&gt;#&lt;/span&gt;&lt;span&gt;超时时间&lt;/span&gt;
feign.httpclient.connection-timeout=&lt;span&gt;30000&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　使用优先级更高的bootstrap.properties进行config的配置，因为&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;35&quot;&gt;
&lt;pre&gt;
&lt;span&gt;#&lt;/span&gt;&lt;span&gt;关闭spring cloud config，spring cloud默认要从config中读取配置，通过该配置，只从本地application.properties中读取配置
#spring.cloud.config.enabled=false

#配置文件名（当应用名跟配置文件相同时可以不用配置）&lt;/span&gt;
spring.cloud.config.name=&lt;span&gt;myspringboot
&lt;/span&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt; dev 开发环境配置文件 |  test 测试环境  |  pro 正式环境&lt;/span&gt;
spring.cloud.config.profile=&lt;span&gt;dev
&lt;/span&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt; 远程仓库的分支&lt;/span&gt;
spring.cloud.config.label=&lt;span&gt;master

&lt;/span&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt;指定配置中心名称（如果使用eureka可以这样配置）
#spring.cloud.config.discovery.service-id=config-server
#启用发现服务功能
#spring.cloud.config.discovery.enabled=true

#配置服务中心地址（如果不使用eureka可以直接配置url路径）&lt;/span&gt;
spring.cloud.config.uri=http://localhost:&lt;span&gt;1112&lt;/span&gt;/
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　如果使用从eureka获取配置中心实例，则要在指定服务之前进行注册配置，否则会报错，因为你还没在Eureka注册就去Eureka查找配置中心，如：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;35&quot;&gt;
&lt;pre&gt;
&lt;span&gt;#&lt;/span&gt;&lt;span&gt;设置服务端口&lt;/span&gt;
server.port=&lt;span&gt;10087&lt;/span&gt;&lt;span&gt;
spring&lt;/span&gt;.application.name=&lt;span&gt;myspringboot

&lt;/span&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt;eureka&lt;/span&gt;
eureka.client.serviceUrl.defaultZone=http://localhost:&lt;span&gt;1111&lt;/span&gt;/eureka/
&lt;span&gt;#&lt;/span&gt;&lt;span&gt;健康检查（需要spring-boot-starter-actuator依赖）&lt;/span&gt;
eureka.client.healthcheck.enabled=&lt;span&gt;true
&lt;/span&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt; 续约更新时间间隔（默认30秒）&lt;/span&gt;
eureka.instance.lease-renewal-interval-in-seconds=&lt;span&gt;10&lt;/span&gt;
&lt;span&gt;#&lt;/span&gt;&lt;span&gt; 续约到期时间（默认90秒）&lt;/span&gt;
eureka.instance.lease-expiration-duration-in-seconds=&lt;span&gt;10&lt;/span&gt;
&lt;span&gt;#&lt;/span&gt;&lt;span&gt;超时时间&lt;/span&gt;
feign.httpclient.connection-timeout=&lt;span&gt;30000&lt;/span&gt;

&lt;span&gt;#&lt;/span&gt;&lt;span&gt;关闭spring cloud config，spring cloud默认要从config中读取配置，通过该配置，只从本地application.properties中读取配置
#spring.cloud.config.enabled=false

#配置文件名（当应用名跟配置文件相同时可以不用配置）&lt;/span&gt;
spring.cloud.config.name=&lt;span&gt;myspringboot
&lt;/span&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt; dev 开发环境配置文件 |  test 测试环境  |  pro 正式环境&lt;/span&gt;
spring.cloud.config.profile=&lt;span&gt;dev
&lt;/span&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt; 远程仓库的分支&lt;/span&gt;
spring.cloud.config.label=&lt;span&gt;master

&lt;/span&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt;指定配置中心名称（如果使用eureka可以这样配置）&lt;/span&gt;
spring.cloud.config.discovery.service-id=config-&lt;span&gt;server
&lt;/span&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt;启用发现服务功能&lt;/span&gt;
spring.cloud.config.discovery.enabled=&lt;span&gt;true

&lt;/span&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt;配置服务中心地址（如果不使用eureka可以直接配置url路径）
#spring.cloud.config.uri=http://localhost:1112/&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1353055/201812/1353055-20181220131853218-442184453.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　测试&lt;/p&gt;
&lt;p&gt;　　我们直接在启动类进行测试&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;36&quot;&gt;
&lt;pre&gt;
&lt;span&gt;@EnableEurekaClient
@SpringBootApplication
@RestController
&lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;&lt;span&gt; MyspringbootApplication{

    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; &lt;span&gt;void&lt;/span&gt;&lt;span&gt; main(String[] args) {
        SpringApplication.run(MyspringbootApplication.&lt;/span&gt;&lt;span&gt;class&lt;/span&gt;&lt;span&gt;, args);
    }

    @Value(&lt;/span&gt;&quot;${huanzi.qch.config.server.username}&quot;&lt;span&gt;)
    &lt;/span&gt;&lt;span&gt;private&lt;/span&gt;&lt;span&gt; String username;

    &lt;/span&gt;&lt;span&gt;/**&lt;/span&gt;&lt;span&gt;
     * 访问首页
     &lt;/span&gt;&lt;span&gt;*/&lt;/span&gt;&lt;span&gt;
    @GetMapping(&lt;/span&gt;&quot;/index&quot;&lt;span&gt;)
    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt;&lt;span&gt; String index(){
        &lt;/span&gt;&lt;span&gt;return&lt;/span&gt; &quot;hello springboot！username：&quot; +&lt;span&gt; username;
    }

}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　查看启动日志，客户端已经发现了配置中心，并且从配置中心发现了myspringboot配置文件&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1353055/201812/1353055-20181220132643751-1003675600.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　访问http://localhost:10087/index，值已经取到了&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1353055/201812/1353055-20181220132723799-799516466.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;h2&gt;　　refresh手动刷新&lt;/h2&gt;
&lt;p&gt;　　我们已经在客户端取到了配置中心的值，但当我们修改GitHub上面的值时，服务端（Config Server）能实时获取最新的值，但客户端（Config Client）读的是缓存，无法实时获取最新值&lt;/p&gt;
&lt;p&gt;　　spring已经为我们解决了这个问题，那就是客户端使用post去触发refresh，获取最新数据，需要依赖spring-boot-starter-actuator&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;33&quot;&gt;
&lt;pre&gt;
        &lt;span&gt;&amp;lt;!--&lt;/span&gt;&lt;span&gt; actuator &lt;/span&gt;&lt;span&gt;--&amp;gt;&lt;/span&gt;
        &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;dependency&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
            &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;groupId&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;org.springframework.boot&lt;span&gt;&amp;lt;/&lt;/span&gt;&lt;span&gt;groupId&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
            &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;artifactId&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;spring-boot-starter-actuator&lt;span&gt;&amp;lt;/&lt;/span&gt;&lt;span&gt;artifactId&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
        &lt;span&gt;&amp;lt;/&lt;/span&gt;&lt;span&gt;dependency&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　对应的controller类加上@RefreshScope&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;36&quot;&gt;
&lt;pre&gt;
&lt;span&gt;@RefreshScope
@EnableEurekaClient
@SpringBootApplication
@RestController
&lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;&lt;span&gt; MyspringbootApplication{

    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; &lt;span&gt;void&lt;/span&gt;&lt;span&gt; main(String[] args) {
        SpringApplication.run(MyspringbootApplication.&lt;/span&gt;&lt;span&gt;class&lt;/span&gt;&lt;span&gt;, args);
    }

    @Value(&lt;/span&gt;&quot;${huanzi.qch.config.server.username}&quot;&lt;span&gt;)
    &lt;/span&gt;&lt;span&gt;private&lt;/span&gt;&lt;span&gt; String username;

    &lt;/span&gt;&lt;span&gt;/**&lt;/span&gt;&lt;span&gt;
     * 访问首页
     &lt;/span&gt;&lt;span&gt;*/&lt;/span&gt;&lt;span&gt;
    @GetMapping(&lt;/span&gt;&quot;/index&quot;&lt;span&gt;)
    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt;&lt;span&gt; String index(){
        &lt;/span&gt;&lt;span&gt;return&lt;/span&gt; &quot;hello springboot！username：&quot; +&lt;span&gt; username;
    }

}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　启动后查看日志发现，actuator有个基础路径/actuator，同时还暴露了两个终端（不知道是哪两个端点...）&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1353055/201812/1353055-20181220134335446-493143227.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　但是当我们post访问http://localhost:10087/actuator/refresh时，报404，这是什么回事？&lt;/p&gt;
&lt;p&gt;　　注：这里插一句话：从网上找了个js的ajax（要注意content-type的类型）&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;46&quot;&gt;
&lt;pre&gt;
&lt;span&gt;var&lt;/span&gt; Ajax=&lt;span&gt;{
  get: &lt;/span&gt;&lt;span&gt;function&lt;/span&gt;&lt;span&gt;(url, fn) {
    &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; XMLHttpRequest对象用于在后台与服务器交换数据&lt;/span&gt;
    &lt;span&gt;var&lt;/span&gt; xhr = &lt;span&gt;new&lt;/span&gt;&lt;span&gt; XMLHttpRequest();            
    xhr.open(&lt;/span&gt;'GET', url, &lt;span&gt;true&lt;/span&gt;&lt;span&gt;);
    xhr.onreadystatechange &lt;/span&gt;= &lt;span&gt;function&lt;/span&gt;&lt;span&gt;() {
      &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; readyState == 4说明请求已完成&lt;/span&gt;
      &lt;span&gt;if&lt;/span&gt; (xhr.readyState == 4 &amp;amp;&amp;amp; xhr.status == 200 || xhr.status == 304&lt;span&gt;) { 
        &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; 从服务器获得数据&lt;/span&gt;
        fn.call(&lt;span&gt;this&lt;/span&gt;&lt;span&gt;, xhr.responseText);  
      }
    };
    xhr.send();
  },
  &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; datat应为'a=a1&amp;amp;b=b1'这种字符串格式，在jq里如果data为对象会自动将对象转成这种字符串格式&lt;/span&gt;
  post: &lt;span&gt;function&lt;/span&gt;&lt;span&gt; (url, data, fn) {
    &lt;/span&gt;&lt;span&gt;var&lt;/span&gt; xhr = &lt;span&gt;new&lt;/span&gt;&lt;span&gt; XMLHttpRequest();
    xhr.open(&lt;/span&gt;&quot;POST&quot;, url, &lt;span&gt;true&lt;/span&gt;&lt;span&gt;);
    &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; 添加http头，发送信息至服务器时内容编码类型&lt;/span&gt;
    xhr.setRequestHeader(&quot;Content-Type&quot;, &quot;application/json&quot;&lt;span&gt;);  
    xhr.onreadystatechange &lt;/span&gt;= &lt;span&gt;function&lt;/span&gt;&lt;span&gt;() {
      &lt;/span&gt;&lt;span&gt;if&lt;/span&gt; (xhr.readyState == 4 &amp;amp;&amp;amp; (xhr.status == 200 || xhr.status == 304&lt;span&gt;)) {
        fn.call(&lt;/span&gt;&lt;span&gt;this&lt;/span&gt;&lt;span&gt;, xhr.responseText);
      }
    };
    xhr.send(data);
  }
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;34&quot;&gt;
&lt;pre&gt;
Ajax.post(&quot;http://localhost:10087/actuator/refresh&quot;,&lt;span&gt;null&lt;/span&gt;,&lt;span&gt;function&lt;/span&gt;(data){console.log(data)})
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1353055/201812/1353055-20181220134644023-399020788.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　经过层层查找，最后在帮助文档发现：默认情况下，自Spring Boot 2.0以来，默认情况下不会公开Actuator端点，需要手动暴露端点&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1353055/201812/1353055-20181220135101077-211153809.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　配置文件暴露端点&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;33&quot;&gt;
&lt;pre&gt;
&lt;span&gt;#&lt;/span&gt;&lt;span&gt;只暴露refresh，当然也可以暴露所有：=*&lt;/span&gt;
management.endpoints.web.exposure.include=refresh
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　重启客户端，我们将GitHub配置文件改回：&lt;span class=&quot;pl-c1&quot;&gt;huanzi.qch.config.server.username: &lt;span class=&quot;pl-s&quot;&gt;张三&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;　　访问测试接口，还是张三1&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1353055/201812/1353055-20181220135634872-654400342.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　post调用refresh&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1353055/201812/1353055-20181220135706286-2092417128.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　刷新，数据更新&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1353055/201812/1353055-20181220135740045-585843644.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;h2&gt;　　总结&lt;/h2&gt;
&lt;p&gt;　　这里总结一下遇到的坑：&lt;/p&gt;
&lt;p&gt;　　调用refresh报404的时候，百度查找都是说默认安全拦截，配置关闭：management.security.enabled=false，配置上去的时候发现报错，波浪线，被弃用了，最后还是靠科学上网，在知乎（&lt;a href=&quot;https://zhuanlan.zhihu.com/p/34784934&quot; target=&quot;_blank&quot;&gt;https://zhuanlan.zhihu.com/p/34784934&lt;/a&gt;）上面找到了答案&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1353055/201812/1353055-20181220142539943-1375181306.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;　　并且吐槽吐槽百度：&lt;/p&gt;
&lt;p&gt;　　同样的关键字，Google搜出来的第一个就能解决问题 &lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1353055/201812/1353055-20181220142930636-148210212.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　而垃圾百度，没一个可以...&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1353055/201812/1353055-20181220143040661-72684610.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
</description>
<pubDate>Thu, 20 Dec 2018 07:16:00 +0000</pubDate>
<dc:creator>huanzi-qch</dc:creator>
<og:description>前言 Spring Cloud Config为分布式系统中的外部化配置提供了服务器端和客户端支持。有了配置服务器，您就有了一个中心位置来管理跨所有环境的应用程序的外部属性。本文记录实现一个配置中心、客</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/huanzi-qch/p/10149547.html</dc:identifier>
</item>
<item>
<title>【原创】redis库存操作，分布式锁的四种实现方式[连载二]--基于Redisson实现分布式锁 - 李军军</title>
<link>http://www.cnblogs.com/ft535535/p/10149526.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/ft535535/p/10149526.html</guid>
<description>&lt;p&gt;&lt;span&gt;&lt;strong&gt;一、redisson介绍&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;redisson实现了分布式和可扩展的java数据结构，支持的数据结构有：List, Set, Map, Queue, SortedSet, ConcureentMap, Lock, AtomicLong, CountDownLatch。并且是线程安全的，底层使用Netty 4实现网络通信。和jedis相比，功能比较简单，不支持排序，事务，管道，分区等redis特性，可以认为是jedis的补充，不能替换jedis。&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;二、redisson几种锁介绍&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;1、可重入锁（Reentrant Lock）&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;基于Redis的Redisson分布式可重入锁&lt;a href=&quot;http://static.javadoc.io/org.redisson/redisson/3.4.3/org/redisson/api/RLock.html&quot; rel=&quot;nofollow&quot; target=&quot;_blank&quot;&gt;&lt;code&gt;RLock&lt;/code&gt;&lt;/a&gt;&lt;span&gt; Java对象实现了&lt;code&gt;java.util.concurrent.locks.Lock&lt;/code&gt;&lt;span&gt;接口&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;32&quot;&gt;
&lt;pre&gt;
&lt;span&gt;1&lt;/span&gt; RLock lock = redisson.getLock(&quot;anyLock&quot;&lt;span&gt;);
&lt;/span&gt;&lt;span&gt;2&lt;/span&gt; &lt;span&gt;//&lt;/span&gt;&lt;span&gt; 最常见的使用方法&lt;/span&gt;
&lt;span&gt;3&lt;/span&gt; lock.lock();
&lt;/pre&gt;&lt;/div&gt;

&lt;div class=&quot;cnblogs_code&quot; readability=&quot;37&quot;&gt;
&lt;pre&gt;
&lt;span&gt;1&lt;/span&gt; &lt;span&gt;//&lt;/span&gt;&lt;span&gt; 加锁以后10秒钟自动解锁
&lt;/span&gt;&lt;span&gt;2&lt;/span&gt; &lt;span&gt;//&lt;/span&gt;&lt;span&gt; 无需调用unlock方法手动解锁&lt;/span&gt;
&lt;span&gt;3&lt;/span&gt; lock.lock(10&lt;span&gt;, TimeUnit.SECONDS);
&lt;/span&gt;&lt;span&gt;4&lt;/span&gt; 
&lt;span&gt;5&lt;/span&gt; &lt;span&gt;//&lt;/span&gt;&lt;span&gt; 尝试加锁，最多等待100秒，上锁以后10秒自动解锁&lt;/span&gt;
&lt;span&gt;6&lt;/span&gt; &lt;span&gt;boolean&lt;/span&gt; res = lock.tryLock(100, 10&lt;span&gt;, TimeUnit.SECONDS);
&lt;/span&gt;&lt;span&gt;7&lt;/span&gt; &lt;span&gt;...
&lt;/span&gt;&lt;span&gt;8&lt;/span&gt; lock.unlock();
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span&gt;Redisson同时还为分布式锁提供了异步执行的相关方法：&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;36&quot;&gt;
&lt;pre&gt;
&lt;span&gt;1&lt;/span&gt; RLock lock = redisson.getLock(&quot;anyLock&quot;&lt;span&gt;);
&lt;/span&gt;&lt;span&gt;2&lt;/span&gt; &lt;span&gt;lock.lockAsync();
&lt;/span&gt;&lt;span&gt;3&lt;/span&gt; lock.lockAsync(10&lt;span&gt;, TimeUnit.SECONDS);
&lt;/span&gt;&lt;span&gt;4&lt;/span&gt; Future&amp;lt;Boolean&amp;gt; res = lock.tryLockAsync(100, 10, TimeUnit.SECONDS);
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span&gt;2.公平锁（Fair Lock）&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;span&gt;基于Redis的Redisson分布式可重入公平锁也是实现了&lt;code&gt;java.util.concurrent.locks.Lock&lt;/code&gt;&lt;span&gt;接口的一种&lt;code&gt;RLock&lt;/code&gt;&lt;span&gt;对象。它保证了当多个Redisson客户端线程同时请求加锁时，优先分配给先发出请求的线程。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;33&quot;&gt;
&lt;pre&gt;
&lt;span&gt;1&lt;/span&gt; RLock fairLock = redisson.getFairLock(&quot;anyLock&quot;&lt;span&gt;);
&lt;/span&gt;&lt;span&gt;2&lt;/span&gt; &lt;span&gt;//&lt;/span&gt;&lt;span&gt; 最常见的使用方法&lt;/span&gt;
&lt;span&gt;3&lt;/span&gt; fairLock.lock();
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span&gt;同样的，Fair lock也提供加锁时间&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;37&quot;&gt;
&lt;pre&gt;
&lt;span&gt;1&lt;/span&gt; &lt;span&gt;//&lt;/span&gt;&lt;span&gt; 10秒钟以后自动解锁
&lt;/span&gt;&lt;span&gt;2&lt;/span&gt; &lt;span&gt;//&lt;/span&gt;&lt;span&gt; 无需调用unlock方法手动解锁&lt;/span&gt;
&lt;span&gt;3&lt;/span&gt; fairLock.lock(10&lt;span&gt;, TimeUnit.SECONDS);
&lt;/span&gt;&lt;span&gt;4&lt;/span&gt; 
&lt;span&gt;5&lt;/span&gt; &lt;span&gt;//&lt;/span&gt;&lt;span&gt; 尝试加锁，最多等待100秒，上锁以后10秒自动解锁&lt;/span&gt;
&lt;span&gt;6&lt;/span&gt; &lt;span&gt;boolean&lt;/span&gt; res = fairLock.tryLock(100, 10&lt;span&gt;, TimeUnit.SECONDS);
&lt;/span&gt;&lt;span&gt;7&lt;/span&gt; &lt;span&gt;...
&lt;/span&gt;&lt;span&gt;8&lt;/span&gt; fairLock.unlock();
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span&gt;&lt;span&gt;Redisson同时还为分布式可重入公平锁提供了异步执行的相关方法：&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;36&quot;&gt;
&lt;pre&gt;
&lt;span&gt;1&lt;/span&gt; RLock fairLock = redisson.getFairLock(&quot;anyLock&quot;&lt;span&gt;);
&lt;/span&gt;&lt;span&gt;2&lt;/span&gt; &lt;span&gt;fairLock.lockAsync();
&lt;/span&gt;&lt;span&gt;3&lt;/span&gt; fairLock.lockAsync(10&lt;span&gt;, TimeUnit.SECONDS);
&lt;/span&gt;&lt;span&gt;4&lt;/span&gt; Future&amp;lt;Boolean&amp;gt; res = fairLock.tryLockAsync(100, 10, TimeUnit.SECONDS);
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span&gt;3.联锁（MultiLock）&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;基于Redis的Redisson分布式联锁&lt;a href=&quot;http://static.javadoc.io/org.redisson/redisson/3.4.3/org/redisson/RedissonMultiLock.html&quot; rel=&quot;nofollow&quot; target=&quot;_blank&quot;&gt;&lt;code&gt;RedissonMultiLock&lt;/code&gt;&lt;/a&gt;&lt;span&gt;对象可以将多个&lt;code&gt;RLock&lt;/code&gt;&lt;span&gt;对象关联为一个联锁，每个&lt;code&gt;RLock&lt;/code&gt;&lt;span&gt;对象实例可以来自于不同的Redisson实例。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;37&quot;&gt;
&lt;pre&gt;
&lt;span&gt; 1&lt;/span&gt; RLock lock1 = redissonInstance1.getLock(&quot;lock1&quot;&lt;span&gt;);
&lt;/span&gt;&lt;span&gt; 2&lt;/span&gt; RLock lock2 = redissonInstance2.getLock(&quot;lock2&quot;&lt;span&gt;);
&lt;/span&gt;&lt;span&gt; 3&lt;/span&gt; RLock lock3 = redissonInstance3.getLock(&quot;lock3&quot;&lt;span&gt;);
&lt;/span&gt;&lt;span&gt; 4&lt;/span&gt; 
&lt;span&gt; 5&lt;/span&gt; RedissonMultiLock lock = &lt;span&gt;new&lt;/span&gt;&lt;span&gt; RedissonMultiLock(lock1, lock2, lock3);
&lt;/span&gt;&lt;span&gt; 6&lt;/span&gt; &lt;span&gt;//&lt;/span&gt;&lt;span&gt; 同时加锁：lock1 lock2 lock3
&lt;/span&gt;&lt;span&gt; 7&lt;/span&gt; &lt;span&gt;//&lt;/span&gt;&lt;span&gt; 所有的锁都上锁成功才算成功。&lt;/span&gt;
&lt;span&gt; 8&lt;/span&gt; &lt;span&gt;lock.lock();
&lt;/span&gt;&lt;span&gt; 9&lt;/span&gt; &lt;span&gt;...
&lt;/span&gt;&lt;span&gt;10&lt;/span&gt; lock.unlock();
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span&gt;&lt;span&gt;另外Redisson还通过加锁的方法提供了&lt;code&gt;leaseTime&lt;/code&gt;&lt;span&gt;的参数来指定加锁的时间。超过这个时间后锁便自动解开了。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;40&quot;&gt;
&lt;pre&gt;
&lt;span&gt;1&lt;/span&gt; RedissonMultiLock lock = &lt;span&gt;new&lt;/span&gt;&lt;span&gt; RedissonMultiLock(lock1, lock2, lock3);
&lt;/span&gt;&lt;span&gt;2&lt;/span&gt; &lt;span&gt;//&lt;/span&gt;&lt;span&gt; 给lock1，lock2，lock3加锁，如果没有手动解开的话，10秒钟后将会自动解开&lt;/span&gt;
&lt;span&gt;3&lt;/span&gt; lock.lock(10&lt;span&gt;, TimeUnit.SECONDS);
&lt;/span&gt;&lt;span&gt;4&lt;/span&gt; 
&lt;span&gt;5&lt;/span&gt; &lt;span&gt;//&lt;/span&gt;&lt;span&gt; 为加锁等待100秒时间，并在加锁成功10秒钟后自动解开&lt;/span&gt;
&lt;span&gt;6&lt;/span&gt; &lt;span&gt;boolean&lt;/span&gt; res = lock.tryLock(100, 10&lt;span&gt;, TimeUnit.SECONDS);
&lt;/span&gt;&lt;span&gt;7&lt;/span&gt; &lt;span&gt;...
&lt;/span&gt;&lt;span&gt;8&lt;/span&gt; lock.unlock();
&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;&lt;span&gt;4.红锁（Red Lock）&lt;/span&gt;&lt;/h3&gt;
&lt;h3 id=&quot;84-红锁redlock&quot;&gt;&lt;span&gt;基于Redis的Redisson红锁&lt;code&gt;RedissonRedLock&lt;/code&gt;&lt;span&gt;对象实现了&lt;a href=&quot;http://redis.cn/topics/distlock.html&quot; rel=&quot;nofollow&quot; target=&quot;_blank&quot;&gt;Redlock&lt;/a&gt;&lt;span&gt;介绍的加锁算法。该对象也可以用来将多个&lt;code&gt;RLock&lt;/code&gt;&lt;span&gt;对象关联为一个红锁，每个&lt;code&gt;RLock&lt;/code&gt;&lt;span&gt;对象实例可以来自于不同的Redisson实例。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;37&quot;&gt;
&lt;pre&gt;
&lt;span&gt; 1&lt;/span&gt; RLock lock1 = redissonInstance1.getLock(&quot;lock1&quot;&lt;span&gt;);
&lt;/span&gt;&lt;span&gt; 2&lt;/span&gt; RLock lock2 = redissonInstance2.getLock(&quot;lock2&quot;&lt;span&gt;);
&lt;/span&gt;&lt;span&gt; 3&lt;/span&gt; RLock lock3 = redissonInstance3.getLock(&quot;lock3&quot;&lt;span&gt;);
&lt;/span&gt;&lt;span&gt; 4&lt;/span&gt; 
&lt;span&gt; 5&lt;/span&gt; RedissonRedLock lock = &lt;span&gt;new&lt;/span&gt;&lt;span&gt; RedissonRedLock(lock1, lock2, lock3);
&lt;/span&gt;&lt;span&gt; 6&lt;/span&gt; &lt;span&gt;//&lt;/span&gt;&lt;span&gt; 同时加锁：lock1 lock2 lock3
&lt;/span&gt;&lt;span&gt; 7&lt;/span&gt; &lt;span&gt;//&lt;/span&gt;&lt;span&gt; 红锁在大部分节点上加锁成功就算成功。&lt;/span&gt;
&lt;span&gt; 8&lt;/span&gt; &lt;span&gt;lock.lock();
&lt;/span&gt;&lt;span&gt; 9&lt;/span&gt; &lt;span&gt;...
&lt;/span&gt;&lt;span&gt;10&lt;/span&gt; lock.unlock();
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span&gt;&lt;span&gt;另外Redisson还通过加锁的方法提供了&lt;code&gt;leaseTime&lt;/code&gt;&lt;span&gt;的参数来指定加锁的时间。超过这个时间后锁便自动解开了。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;40&quot;&gt;
&lt;pre&gt;
&lt;span&gt;1&lt;/span&gt; RedissonRedLock lock = &lt;span&gt;new&lt;/span&gt;&lt;span&gt; RedissonRedLock(lock1, lock2, lock3);
&lt;/span&gt;&lt;span&gt;2&lt;/span&gt; &lt;span&gt;//&lt;/span&gt;&lt;span&gt; 给lock1，lock2，lock3加锁，如果没有手动解开的话，10秒钟后将会自动解开&lt;/span&gt;
&lt;span&gt;3&lt;/span&gt; lock.lock(10&lt;span&gt;, TimeUnit.SECONDS);
&lt;/span&gt;&lt;span&gt;4&lt;/span&gt; 
&lt;span&gt;5&lt;/span&gt; &lt;span&gt;//&lt;/span&gt;&lt;span&gt; 为加锁等待100秒时间，并在加锁成功10秒钟后自动解开&lt;/span&gt;
&lt;span&gt;6&lt;/span&gt; &lt;span&gt;boolean&lt;/span&gt; res = lock.tryLock(100, 10&lt;span&gt;, TimeUnit.SECONDS);
&lt;/span&gt;&lt;span&gt;7&lt;/span&gt; &lt;span&gt;...
&lt;/span&gt;&lt;span&gt;8&lt;/span&gt; lock.unlock();
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span&gt;5. 读写锁（ReadWriteLock）&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;基于Redis的Redisson分布式可重入读写锁&lt;a href=&quot;http://static.javadoc.io/org.redisson/redisson/3.4.3/org/redisson/api/RReadWriteLock.html&quot; rel=&quot;nofollow&quot; target=&quot;_blank&quot;&gt;&lt;code&gt;RReadWriteLock&lt;/code&gt;&lt;/a&gt;&lt;span&gt; Java对象实现了&lt;code&gt;java.util.concurrent.locks.ReadWriteLock&lt;/code&gt;&lt;span&gt;接口。同时还支持自动过期解锁。该对象允许同时有多个读取锁，但是最多只能有一个写入锁。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;33&quot;&gt;
&lt;pre&gt;
&lt;span&gt;1&lt;/span&gt; RReadWriteLock rwlock = redisson.getLock(&quot;anyRWLock&quot;&lt;span&gt;);
&lt;/span&gt;&lt;span&gt;2&lt;/span&gt; &lt;span&gt;//&lt;/span&gt;&lt;span&gt; 最常见的使用方法&lt;/span&gt;
&lt;span&gt;3&lt;/span&gt; &lt;span&gt;rwlock.readLock().lock();
&lt;/span&gt;&lt;span&gt;4&lt;/span&gt; &lt;span&gt;//&lt;/span&gt;&lt;span&gt; 或&lt;/span&gt;
&lt;span&gt;5&lt;/span&gt; rwlock.writeLock().lock();
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span&gt;&lt;span&gt;另外Redisson还通过加锁的方法提供了&lt;code&gt;leaseTime&lt;/code&gt;&lt;span&gt;的参数来指定加锁的时间。超过这个时间后锁便自动解开了。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;41&quot;&gt;
&lt;pre&gt;
&lt;span&gt;//&lt;/span&gt;&lt;span&gt; 10秒钟以后自动解锁
&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; 无需调用unlock方法手动解锁&lt;/span&gt;
rwlock.readLock().lock(10&lt;span&gt;, TimeUnit.SECONDS);
&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; 或&lt;/span&gt;
rwlock.writeLock().lock(10&lt;span&gt;, TimeUnit.SECONDS);

&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; 尝试加锁，最多等待100秒，上锁以后10秒自动解锁&lt;/span&gt;
&lt;span&gt;boolean&lt;/span&gt; res = rwlock.readLock().tryLock(100, 10&lt;span&gt;, TimeUnit.SECONDS);
&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; 或&lt;/span&gt;
&lt;span&gt;boolean&lt;/span&gt; res = rwlock.writeLock().tryLock(100, 10&lt;span&gt;, TimeUnit.SECONDS);
...
lock.unlock();&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span&gt;6. 闭锁（CountDownLatch）&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;基于Redisson的Redisson分布式闭锁（&lt;a href=&quot;http://static.javadoc.io/org.redisson/redisson/3.4.3/org/redisson/api/RCountDownLatch.html&quot; rel=&quot;nofollow&quot; target=&quot;_blank&quot;&gt;CountDownLatch&lt;/a&gt;&lt;span&gt;）Java对象&lt;code&gt;RCountDownLatch&lt;/code&gt;&lt;span&gt;采用了与&lt;code&gt;java.util.concurrent.CountDownLatch&lt;/code&gt;&lt;span&gt;相似的接口和用法。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;34&quot;&gt;
&lt;pre&gt;
RCountDownLatch latch = redisson.getCountDownLatch(&quot;anyCountDownLatch&quot;&lt;span&gt;);
latch.trySetCount(&lt;/span&gt;1&lt;span&gt;);
latch.await();

&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; 在其他线程或其他JVM里&lt;/span&gt;
RCountDownLatch latch = redisson.getCountDownLatch(&quot;anyCountDownLatch&quot;&lt;span&gt;);
latch.countDown();&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;三、redisson分布式锁在业务中的应用&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;1、引入相关pom&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;33&quot;&gt;
&lt;pre&gt;
        &lt;span&gt;&amp;lt;!--&lt;/span&gt;&lt;span&gt; redisson &lt;/span&gt;&lt;span&gt;--&amp;gt;&lt;/span&gt;
        &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;dependency&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
            &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;groupId&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;org.redisson&lt;span&gt;&amp;lt;/&lt;/span&gt;&lt;span&gt;groupId&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
            &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;artifactId&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;redisson&lt;span&gt;&amp;lt;/&lt;/span&gt;&lt;span&gt;artifactId&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
            &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;version&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;3.5.0&lt;span&gt;&amp;lt;/&lt;/span&gt;&lt;span&gt;version&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
        &lt;span&gt;&amp;lt;/&lt;/span&gt;&lt;span&gt;dependency&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span&gt;2、将redisson交由spring管理，本文采用redisson的集群模式装配，另外可配置哨兵模式，单点等&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;35&quot;&gt;
&lt;pre&gt;
&lt;span&gt;/**&lt;/span&gt;&lt;span&gt;
 * redisson客户端参数配置类
 &lt;/span&gt;&lt;span&gt;*/&lt;/span&gt;&lt;span&gt;
@Configuration
@Data
&lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;&lt;span&gt; RedissonProperties {

    &lt;/span&gt;&lt;span&gt;private&lt;/span&gt; &lt;span&gt;int&lt;/span&gt; idleConnectionTimeout = 10000&lt;span&gt;;

    &lt;/span&gt;&lt;span&gt;private&lt;/span&gt; &lt;span&gt;int&lt;/span&gt; pingTimeout = 1000&lt;span&gt;;

    &lt;/span&gt;&lt;span&gt;private&lt;/span&gt; &lt;span&gt;int&lt;/span&gt; connectTimeout = 10000&lt;span&gt;;

    &lt;/span&gt;&lt;span&gt;private&lt;/span&gt; &lt;span&gt;int&lt;/span&gt; timeout = 3000&lt;span&gt;;

    &lt;/span&gt;&lt;span&gt;private&lt;/span&gt; &lt;span&gt;int&lt;/span&gt; retryAttempts = 3&lt;span&gt;;

    &lt;/span&gt;&lt;span&gt;private&lt;/span&gt; &lt;span&gt;int&lt;/span&gt; retryInterval = 1500&lt;span&gt;;

    &lt;/span&gt;&lt;span&gt;private&lt;/span&gt; &lt;span&gt;int&lt;/span&gt; reconnectionTimeout = 3000&lt;span&gt;;

    &lt;/span&gt;&lt;span&gt;private&lt;/span&gt; &lt;span&gt;int&lt;/span&gt; failedAttempts = 3&lt;span&gt;;

    &lt;/span&gt;&lt;span&gt;private&lt;/span&gt; &lt;span&gt;int&lt;/span&gt; subscriptionsPerConnection = 5&lt;span&gt;;

    &lt;/span&gt;&lt;span&gt;private&lt;/span&gt; String clientName = &quot;none&quot;&lt;span&gt;;

    &lt;/span&gt;&lt;span&gt;private&lt;/span&gt; &lt;span&gt;int&lt;/span&gt; subscriptionConnectionMinimumIdleSize = 64&lt;span&gt;;

    &lt;/span&gt;&lt;span&gt;private&lt;/span&gt; &lt;span&gt;int&lt;/span&gt; subscriptionConnectionPoolSize = 256&lt;span&gt;;

    &lt;/span&gt;&lt;span&gt;private&lt;/span&gt; &lt;span&gt;int&lt;/span&gt; slaveConnectionMinimumIdleSize = 64&lt;span&gt;;

    &lt;/span&gt;&lt;span&gt;private&lt;/span&gt; &lt;span&gt;int&lt;/span&gt; slaveConnectionPoolSize = 256&lt;span&gt;;

    &lt;/span&gt;&lt;span&gt;private&lt;/span&gt; &lt;span&gt;int&lt;/span&gt; masterConnectionMinimumIdleSize = 64&lt;span&gt;;

    &lt;/span&gt;&lt;span&gt;private&lt;/span&gt; &lt;span&gt;int&lt;/span&gt; masterConnectionPoolSize = 256&lt;span&gt;;

    &lt;/span&gt;&lt;span&gt;private&lt;/span&gt; ReadMode readMode =&lt;span&gt; ReadMode.MASTER;

    &lt;/span&gt;&lt;span&gt;private&lt;/span&gt; SubscriptionMode subscriptionMode =&lt;span&gt; SubscriptionMode.MASTER;

    &lt;/span&gt;&lt;span&gt;private&lt;/span&gt; &lt;span&gt;int&lt;/span&gt; scanInterval = 1000&lt;span&gt;;

    @Value(&lt;/span&gt;&quot;${rediscluster.pwd}&quot;&lt;span&gt;)
    &lt;/span&gt;&lt;span&gt;private&lt;/span&gt;&lt;span&gt; String password;

    @Value(&lt;/span&gt;&quot;${redis.cluster}&quot;&lt;span&gt;)
    &lt;/span&gt;&lt;span&gt;private&lt;/span&gt;&lt;span&gt; String nodeAddress;

    @Value(&lt;/span&gt;&quot;${redis.cluster1}&quot;&lt;span&gt;)
    &lt;/span&gt;&lt;span&gt;private&lt;/span&gt;&lt;span&gt; String nodeAddress1;

    @Value(&lt;/span&gt;&quot;${redis.cluster2}&quot;&lt;span&gt;)
    &lt;/span&gt;&lt;span&gt;private&lt;/span&gt;&lt;span&gt; String nodeAddress2;

}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;37&quot;&gt;
&lt;pre&gt;
&lt;span&gt;/**&lt;/span&gt;&lt;span&gt;
 * 初始化redisson Bean
 *
 * &lt;/span&gt;&lt;span&gt;@author&lt;/span&gt;&lt;span&gt; LiJunJun
 * @date 2018/10/19
 &lt;/span&gt;&lt;span&gt;*/&lt;/span&gt;&lt;span&gt;
@Configuration
&lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;&lt;span&gt; RedissonAutoConfiguration {

    @Autowired
    &lt;/span&gt;&lt;span&gt;private&lt;/span&gt;&lt;span&gt; RedissonProperties redssionProperties;

    &lt;/span&gt;&lt;span&gt;/**&lt;/span&gt;&lt;span&gt;
     * 集群模式自动装配
     *
     * &lt;/span&gt;&lt;span&gt;@return&lt;/span&gt;
     &lt;span&gt;*/&lt;/span&gt;&lt;span&gt;
    @Bean
    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt;&lt;span&gt; RedissonClient redissonClient() {

        Config config &lt;/span&gt;= &lt;span&gt;new&lt;/span&gt;&lt;span&gt; Config();
        String passWord &lt;/span&gt;=&lt;span&gt; redssionProperties.getPassword();
        ClusterServersConfig serverConfig &lt;/span&gt;=&lt;span&gt; config.useClusterServers();
        serverConfig.addNodeAddress(redssionProperties.getNodeAddress(), redssionProperties.getNodeAddress1(), redssionProperties.getNodeAddress2());
        serverConfig.setPingTimeout(redssionProperties.getPingTimeout());
        serverConfig.setConnectTimeout(redssionProperties.getConnectTimeout());
        serverConfig.setTimeout(redssionProperties.getTimeout());
        serverConfig.setRetryAttempts(redssionProperties.getRetryAttempts());
        serverConfig.setRetryInterval(redssionProperties.getRetryInterval());
        serverConfig.setReconnectionTimeout(redssionProperties.getReconnectionTimeout());
        serverConfig.setFailedAttempts(redssionProperties.getFailedAttempts());
        serverConfig.setSubscriptionsPerConnection(redssionProperties.getSubscriptionsPerConnection());
        serverConfig.setClientName(redssionProperties.getClientName());
        serverConfig.setSubscriptionConnectionMinimumIdleSize(redssionProperties.getSubscriptionConnectionMinimumIdleSize());
        serverConfig.setSubscriptionConnectionPoolSize(redssionProperties.getSubscriptionConnectionPoolSize());
        serverConfig.setSlaveConnectionMinimumIdleSize(redssionProperties.getSlaveConnectionMinimumIdleSize());
        serverConfig.setSlaveConnectionPoolSize(redssionProperties.getSlaveConnectionPoolSize());
        serverConfig.setMasterConnectionMinimumIdleSize(redssionProperties.getMasterConnectionMinimumIdleSize());
        serverConfig.setMasterConnectionPoolSize(redssionProperties.getMasterConnectionPoolSize());
        serverConfig.setReadMode(redssionProperties.getReadMode());
        serverConfig.setSubscriptionMode(redssionProperties.getSubscriptionMode());
        serverConfig.setScanInterval(redssionProperties.getScanInterval());
        serverConfig.setPassword(StringUtils.isNotBlank(passWord) &lt;/span&gt;&amp;amp;&amp;amp; !&quot;null&quot;.equals(passWord) ? passWord : &lt;span&gt;null&lt;/span&gt;&lt;span&gt;);
        &lt;/span&gt;&lt;span&gt;return&lt;/span&gt;&lt;span&gt; Redisson.create(config);
    }
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span&gt;3、业务代码中的应用。此处使用的是悲观锁，即必须拿到锁之后才能继续往下执行，也可使用乐观锁，tryLock，利用重试去获取锁&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;52&quot;&gt;
&lt;pre&gt;
    &lt;span&gt;/**&lt;/span&gt;&lt;span&gt;
     * redissonClient
     &lt;/span&gt;&lt;span&gt;*/&lt;/span&gt;&lt;span&gt;
    @Resource
    &lt;/span&gt;&lt;span&gt;private&lt;/span&gt;&lt;span&gt; RedissonClient redissonClient;

    &lt;/span&gt;&lt;span&gt;/**&lt;/span&gt;&lt;span&gt;
     * 减库存
     *
     * &lt;/span&gt;&lt;span&gt;@param&lt;/span&gt;&lt;span&gt; trace 请求流水
     * &lt;/span&gt;&lt;span&gt;@param&lt;/span&gt;&lt;span&gt; stockManageReq（stockId、decrNum）
     * &lt;/span&gt;&lt;span&gt;@return&lt;/span&gt;&lt;span&gt; -1为失败，大于-1的正整数为减后的库存量，-2为库存不足无法减库存
     &lt;/span&gt;&lt;span&gt;*/&lt;/span&gt;&lt;span&gt;
    @Override
    @ApiOperation(value &lt;/span&gt;= &quot;减库存&quot;, notes = &quot;减库存&quot;&lt;span&gt;)
    @RequestMapping(value &lt;/span&gt;= &quot;/decrByStock&quot;, method = RequestMethod.POST, consumes = MediaType.APPLICATION_JSON_UTF8_VALUE, produces =&lt;span&gt; MediaType.APPLICATION_JSON_UTF8_VALUE)
    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;int&lt;/span&gt; decrByStock(@RequestHeader(name = &quot;Trace&quot;&lt;span&gt;) String trace, @RequestBody StockManageReq stockManageReq) {

        &lt;/span&gt;&lt;span&gt;long&lt;/span&gt; startTime =&lt;span&gt; System.currentTimeMillis();

        LOGGER.reqPrint(Log.CACHE_SIGN, Log.CACHE_REQUEST, trace, &lt;/span&gt;&quot;decrByStock&quot;&lt;span&gt;, JSON.toJSONString(stockManageReq));

        &lt;/span&gt;&lt;span&gt;int&lt;/span&gt; res = 0&lt;span&gt;;
        String stockId &lt;/span&gt;=&lt;span&gt; stockManageReq.getStockId();
        Integer decrNum &lt;/span&gt;=&lt;span&gt; stockManageReq.getDecrNum();

        &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; 添加分布式锁&lt;/span&gt;
        RLock stockLock = &lt;span&gt;null&lt;/span&gt;&lt;span&gt;;

        &lt;/span&gt;&lt;span&gt;try&lt;/span&gt;&lt;span&gt; {
            &lt;/span&gt;&lt;span&gt;if&lt;/span&gt; (&lt;span&gt;null&lt;/span&gt; != stockId &amp;amp;&amp;amp; &lt;span&gt;null&lt;/span&gt; !=&lt;span&gt; decrNum) {

                stockId &lt;/span&gt;= PREFIX +&lt;span&gt; stockId;

                &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; 添加分布式锁&lt;/span&gt;
                stockLock =&lt;span&gt; redissonClient.getFairLock(stockId);

                stockLock.lock();

                &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; redis 减库存逻辑&lt;/span&gt;
                String vStock =&lt;span&gt; redisStockPool.get(stockId);
                &lt;/span&gt;&lt;span&gt;long&lt;/span&gt; realV = 0L&lt;span&gt;;
                &lt;/span&gt;&lt;span&gt;if&lt;/span&gt;&lt;span&gt; (StringUtils.isNotEmpty(vStock)) {
                    realV &lt;/span&gt;=&lt;span&gt; Long.parseLong(vStock);
                }
                &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;库存数  大于等于 要减的数目，则执行减库存&lt;/span&gt;
                &lt;span&gt;if&lt;/span&gt; (realV &amp;gt;=&lt;span&gt; decrNum) {
                    Long v &lt;/span&gt;=&lt;span&gt; redisStockPool.decrBy(stockId, decrNum);
                    res &lt;/span&gt;=&lt;span&gt; v.intValue();
                } &lt;/span&gt;&lt;span&gt;else&lt;/span&gt;&lt;span&gt; {
                    res &lt;/span&gt;= -2&lt;span&gt;;
                }

                stockLock.unlock();
            }
        } &lt;/span&gt;&lt;span&gt;catch&lt;/span&gt;&lt;span&gt; (Exception e) {
            LOGGER.error(trace, &lt;/span&gt;&quot;decr sku stock failure.&quot;&lt;span&gt;, e);
            res &lt;/span&gt;= -1&lt;span&gt;;
        } &lt;/span&gt;&lt;span&gt;finally&lt;/span&gt;&lt;span&gt; {
            &lt;/span&gt;&lt;span&gt;if&lt;/span&gt; (stockLock != &lt;span&gt;null&lt;/span&gt; &amp;amp;&amp;amp; stockLock.isLocked() &amp;amp;&amp;amp;&lt;span&gt; stockLock.isHeldByCurrentThread()) {
                stockLock.unlock();
            }
            LOGGER.respPrint(Log.CACHE_SIGN, Log.CACHE_RESPONSE, trace, &lt;/span&gt;&quot;decrByStock&quot;, System.currentTimeMillis() -&lt;span&gt; startTime, String.valueOf(res));
        }
        &lt;/span&gt;&lt;span&gt;return&lt;/span&gt;&lt;span&gt; res;
    }&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;四、ab压测及结果分析&lt;/strong&gt;&lt;/span&gt;&lt;br/&gt;&lt;span&gt;同样的，我们以5000的请求量100的并发量来压、tps在330左右，相对于zk做分布式锁来看，提升了10倍的性能，但仍然不能满足我们的要求&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/884976/201812/884976-20181220150501453-1932770368.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt; 五、总结&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;redisson提供了丰富的分布式锁实现机制，并且使用起来相对比较简单方便，具体选用哪种锁，可以根据业务来选择，但在高并发的情况下，性能还是有些差强人意，下一篇，我们使用redis的watch来实现分布式锁。&lt;/span&gt;&lt;/p&gt;

</description>
<pubDate>Thu, 20 Dec 2018 07:14:00 +0000</pubDate>
<dc:creator>李军军</dc:creator>
<og:description>一、redisson介绍 redisson实现了分布式和可扩展的java数据结构，支持的数据结构有：List, Set, Map, Queue, SortedSet, ConcureentM</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/ft535535/p/10149526.html</dc:identifier>
</item>
<item>
<title>Spring 事务管理详解 - Liant</title>
<link>http://www.cnblogs.com/liantdev/p/10149443.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/liantdev/p/10149443.html</guid>
<description>&lt;h4 id=&quot;事务的概念&quot;&gt;事务的概念&lt;/h4&gt;
&lt;p&gt;我们知道，在JavaEE的开发过程中，service方法用于处理主要的业务逻辑，而业务逻辑的处理往往伴随着对数据库的多个操作。以我们生活中常见的转账为例，service方法要实现将A账户转账到B账户的功能，则该方法内必定要有两个操作：先将A账户的金额减去要转账的数目，然后将B账户加上相应的金额数目。这两个操作必定要全部成功，方才表示本次转账成功；若有任何一方失败，则另一方必须回滚（即全部失败）。事务指的就是这样一组操作：这组操作是不可分割的，要么全部成功，要么全部失败&lt;/p&gt;
&lt;h4 id=&quot;事务的特性&quot;&gt;事务的特性&lt;/h4&gt;
&lt;p&gt;事务具有ACID四个特性：&lt;br/&gt;&lt;strong&gt;原子性(Atomicity)&lt;/strong&gt;：事务是一个不可分割的工作单位，事务中的操作要么都发生，要么都不发生&lt;br/&gt;&lt;strong&gt;一致性(Consistency)&lt;/strong&gt;：事务在完成后数据的完整性必须保持一致&lt;br/&gt;&lt;strong&gt;隔离性(Isolation)&lt;/strong&gt;：多个用户并发访问数据库时，一个用户的事务不能被其他用户的事务所干扰，多个并发事务之间的数据要相互隔离&lt;br/&gt;&lt;strong&gt;持久性（Durability）&lt;/strong&gt;：一个事务一旦被提交，它对数据库中数据的改变应该是永久性的，即使数据库发生故障也不应该对其有任何影响&lt;/p&gt;
&lt;h4 id=&quot;spring-事务管理接口&quot;&gt;Spring 事务管理接口&lt;/h4&gt;
&lt;p&gt;Spring 事务管理为我们提供了三个高层抽象的接口，分别是TransactionProxyFactoryBean，TransactionDefinition，TransactionStatus&lt;/p&gt;
&lt;h5 id=&quot;transactionproxyfactorybean事务管理器&quot;&gt;1.TransactionProxyFactoryBean事务管理器&lt;/h5&gt;
&lt;p&gt;Spring事务管理器的接口是org.springframework.transaction.PlatformTransactionManager，Spring框架并不直接管理事务，而是通过这个接口为不同的持久层框架提供了不同的PlatformTransactionManager接口实现类，也就是将事务管理的职责委托给Hibernate或者iBatis等持久化框架的事务来实现&lt;/p&gt;
&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;org.springframework.jdbc.datasource.DataSourceTransactionManager：使用JDBC或者iBatis进行持久化数据时使用&lt;br/&gt;org.springframework.orm.hibernate5.HibernateTransactionManager：使用hibernate5版本进行持久化数据时使用&lt;br/&gt;org.springframework.orm.jpa.JpaTransactionManager：使用JPA进行持久化数据时使用&lt;br/&gt;org.springframework.jdo.JdoTransactionManager：当持久化机制是jdo时使用&lt;br/&gt;org.springframework.transaction.jta.JtaTransactionManager：使用一个JTA实现来管理事务，在一个事务跨越多个资源时必须使用&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;PlatformTransactionManager接口源码：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;public interface PlatformTransactionManager {
    //事务管理器通过TransactionDefinition，获得“事务状态”，从而管理事务
    TransactionStatus getTransaction(@Nullable TransactionDefinition var1) throws TransactionException;
    //根据状态提交
    void commit(TransactionStatus var1) throws TransactionException;
   //根据状态回滚
    void rollback(TransactionStatus var1) throws TransactionException;
}&lt;/code&gt;
&lt;/pre&gt;
&lt;h5 id=&quot;transactiondefinition定义事务基本属性&quot;&gt;2.TransactionDefinition定义事务基本属性&lt;/h5&gt;
&lt;p&gt;org.springframework.transaction.TransactionDefinition接口用于定义一个事务，它定义了Spring事务管理的五大属性：&lt;strong&gt;隔离级别&lt;/strong&gt;、&lt;strong&gt;传播行为&lt;/strong&gt;、&lt;strong&gt;是否只读&lt;/strong&gt;、&lt;strong&gt;事务超时&lt;/strong&gt;、&lt;strong&gt;回滚规则&lt;/strong&gt;&lt;/p&gt;
&lt;h6 id=&quot;隔离级别&quot;&gt;2.1隔离级别&lt;/h6&gt;
&lt;p&gt;什么是事务的隔离级别？我们知道，隔离性是事务的四大特性之一，表示多个并发事务之间的数据要相互隔离，隔离级别就是用来描述并发事务之间隔离程度的大小&lt;br/&gt;在并发事务之间如果不考虑隔离性，会引发如下安全性问题：&lt;br/&gt;&lt;strong&gt;脏读&lt;/strong&gt; ：一个事务读到了另一个事务的未提交的数据&lt;br/&gt;&lt;strong&gt;不可重复读&lt;/strong&gt; ：一个事务读到了另一个事务已经提交的 update 的数据导致多次查询结果不一致&lt;br/&gt;&lt;strong&gt;幻读&lt;/strong&gt; ：一个事务读到了另一个事务已经提交的 insert 的数据导致多次查询结果不一致&lt;br/&gt;在 Spring 事务管理中，为我们定义了如下的隔离级别：&lt;br/&gt;&lt;strong&gt;ISOLATION_DEFAULT&lt;/strong&gt;：使用数据库默认的隔离级别&lt;br/&gt;&lt;strong&gt;ISOLATION_READ_UNCOMMITTED&lt;/strong&gt;：最低的隔离级别，允许读取已改变而没有提交的数据，可能会导致脏读、幻读或不可重复读&lt;br/&gt;&lt;strong&gt;ISOLATION_READ_COMMITTED&lt;/strong&gt;：允许读取事务已经提交的数据，可以阻止脏读，但是幻读或不可重复读仍有可能发生&lt;br/&gt;&lt;strong&gt;ISOLATION_REPEATABLE_READ&lt;/strong&gt;：对同一字段的多次读取结果都是一致的，除非数据事务本身改变，可以阻止脏读和不可重复读，但幻读仍有可能发生&lt;br/&gt;&lt;strong&gt;ISOLATION_SERIALIZABLE&lt;/strong&gt;：最高的隔离级别，完全服从ACID的隔离级别，确保不发生脏读、不可重复读以及幻读，也是最慢的事务隔离级别，因为它通常是通过完全锁定事务相关的数据库表来实现的&lt;/p&gt;
&lt;h6 id=&quot;传播行为&quot;&gt;2.2传播行为&lt;/h6&gt;
&lt;p&gt;Spring事务传播机制规定了事务方法和事务方法发生嵌套调用时事务如何进行传播，即协调已经有事务标识的方法之间的发生调用时的事务上下文的规则&lt;br/&gt;Spring定义了七种传播行为，这里以方法A和方法B发生嵌套调用时如何传播事务为例说明：&lt;br/&gt;&lt;strong&gt;PROPAGATION_REQUIRED&lt;/strong&gt;：A如果有事务，B将使用该事务；如果A没有事务，B将创建一个新的事务&lt;br/&gt;&lt;strong&gt;PROPAGATION_SUPPORTS&lt;/strong&gt;：A如果有事务，B将使用该事务；如果A没有事务，B将以非事务执行&lt;br/&gt;&lt;strong&gt;PROPAGATION_MANDATORY&lt;/strong&gt;：A如果有事务，B将使用该事务；如果A没有事务，B将抛异常&lt;br/&gt;&lt;strong&gt;PROPAGATION_REQUIRES_NEW&lt;/strong&gt;：A如果有事务，将A的事务挂起，B创建一个新的事务；如果A没有事务，B创建一个新的事务&lt;br/&gt;&lt;strong&gt;PROPAGATION_NOT_SUPPORTED&lt;/strong&gt;：A如果有事务，将A的事务挂起，B将以非事务执行；如果A没有事务，B将以非事务执行&lt;br/&gt;&lt;strong&gt;PROPAGATION_NEVER&lt;/strong&gt;：A如果有事务，B将抛异常；A如果没有事务，B将以非事务执行&lt;br/&gt;&lt;strong&gt;PROPAGATION_NESTED&lt;/strong&gt;：A和B底层采用保存点机制，形成嵌套事务&lt;/p&gt;
&lt;h6 id=&quot;是否只读&quot;&gt;2.3是否只读&lt;/h6&gt;
&lt;p&gt;如果将事务设置为只读，表示这个事务只读取数据但不更新数据, 这样可以帮助数据库引擎优化事务&lt;/p&gt;
&lt;h6 id=&quot;事务超时&quot;&gt;2.4事务超时&lt;/h6&gt;
&lt;p&gt;事务超时就是事务的一个定时器，在特定时间内事务如果没有执行完毕，那么就会自动回滚，而不是一直等待其结束。在 TransactionDefinition 中以 int 的值来表示超时时间，默认值是-1，其单位是秒&lt;/p&gt;
&lt;h6 id=&quot;回滚规则&quot;&gt;2.5回滚规则&lt;/h6&gt;
&lt;p&gt;回滚规则定义了哪些异常会导致事务回滚而哪些不会。默认情况下，事务只有遇到运行期异常时才会回滚&lt;/p&gt;
&lt;h5 id=&quot;transactionstatus事务状态&quot;&gt;3.TransactionStatus事务状态&lt;/h5&gt;
&lt;p&gt;org.springframework.transaction.TransactionStatus接口用来记录事务的状态，该接口定义了一组方法，用来获取或判断事务的相应状态信息&lt;br/&gt;TransactionStatus接口源码：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;public interface TransactionStatus extends SavepointManager, Flushable {
    boolean isNewTransaction();// 是否是新的事物

    boolean hasSavepoint();// 是否有恢复点

    void setRollbackOnly();// 设置为只回滚

    boolean isRollbackOnly();// 是否为只回滚

    void flush();// 刷新

    boolean isCompleted();// 是否已完成
}&lt;/code&gt;
&lt;/pre&gt;
&lt;h4 id=&quot;spring-事务管理实现方式&quot;&gt;Spring 事务管理实现方式&lt;/h4&gt;
&lt;p&gt;Spring 事务管理有两种方式：&lt;strong&gt;编程式事务管理&lt;/strong&gt;、&lt;strong&gt;声明式事务管理&lt;/strong&gt;&lt;br/&gt;编程式事务管理通过TransactionTemplate手动管理事务，在实际应用中很少使用，我们来重点学习声明式事务管理&lt;br/&gt;声明式事务管理有三种实现方式：&lt;strong&gt;基于TransactionProxyFactoryBean的方式&lt;/strong&gt;、&lt;strong&gt;基于AspectJ的XML方式&lt;/strong&gt;、&lt;strong&gt;基于注解的方式&lt;/strong&gt;&lt;br/&gt;我们以用户转账为例来学习这三种不同的实现方式，首先来搭建转账环境&lt;br/&gt;&lt;strong&gt;1.建表，初始化数据库&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;create table account
(
  id    bigint auto_increment primary key,
  name  varchar(32) not null,
  money bigint      not null,
  constraint account_name_uindex
  unique (name)
);
insert into account (name, money) values('Bill', 2000),('Jack', 2000);&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;数据库原始数据：&lt;br/&gt;&lt;img src=&quot;https://upload-images.jianshu.io/upload_images/13172436-4428b7019f33a636.JPG?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240&quot; alt=&quot;数据库.JPG&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2.创建DAO实现类&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;public class TransferDaoImpl extends JdbcDaoSupport implements TransferDao {

    /**
     * @param name 账户名称
     * @param amount 支出金额
     */
    @Override
    public void payMoney(String name, Long amount) {

        String sql = &quot;update account set money=money-? where name=?&quot;;
        this.getJdbcTemplate().update(sql, amount, name);
    }

    /**
     * @param name 账户名称
     * @param amount 收入金额
     */
    @Override
    public void collectMoney(String name, Long amount) {

        String sql = &quot;update account set money=money+? where name=?&quot;;
        this.getJdbcTemplate().update(sql, amount, name);
    }
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;3.创建Service实现类（事务管理类）&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;public class TransferServiceImpl implements TransferService {

    private TransferDao transferDao;

    public void setTransferDao(TransferDao transferDao) {
        this.transferDao = transferDao;
    }
     /**
     * @param source 支出方账户名称
     * @param name 收入方账户名称
     * @param amount 转账金额
     */
    @Override
    public void transferMoney(String source, String destination, Long amount) {
        transferDao.payMoney(source, amount);
        int i = 100/0;//此处用于测试抛异常时是否会回滚
        transferDao.collectMoney(destination, amount);
    }
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;4.创建Spring核心配置文件&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;    &amp;lt;!-- 读取db.properties配置信息 --&amp;gt;
    &amp;lt;context:property-placeholder location=&quot;db.properties&quot;&amp;gt;&amp;lt;/context:property-placeholder&amp;gt;
    &amp;lt;!-- 配置c3p0数据源 --&amp;gt;
    &amp;lt;bean id=&quot;dataSource&quot; class=&quot;com.mchange.v2.c3p0.ComboPooledDataSource&quot;&amp;gt;
        &amp;lt;property name=&quot;driverClass&quot; value=&quot;${db.driverClass}&quot; /&amp;gt;
        &amp;lt;property name=&quot;jdbcUrl&quot; value=&quot;${db.url}&quot; /&amp;gt;
        &amp;lt;property name=&quot;user&quot; value=&quot;${db.username}&quot; /&amp;gt;
        &amp;lt;property name=&quot;password&quot; value=&quot;${db.password}&quot; /&amp;gt;
    &amp;lt;/bean&amp;gt;

    &amp;lt;bean id=&quot;transferDao&quot; class=&quot;com.tx.dao.impl.TransferDaoImpl&quot;&amp;gt;
        &amp;lt;property name=&quot;dataSource&quot; ref=&quot;dataSource&quot; /&amp;gt;
    &amp;lt;/bean&amp;gt;

    &amp;lt;bean id=&quot;transferService&quot; class=&quot;com.tx.service.impl.TransferServiceImpl&quot;&amp;gt;
        &amp;lt;property name=&quot;transferDao&quot; ref=&quot;transferDao&quot; /&amp;gt;
    &amp;lt;/bean&amp;gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;h5 id=&quot;基于transactionproxyfactorybean的方式&quot;&gt;基于TransactionProxyFactoryBean的方式&lt;/h5&gt;
&lt;p&gt;在spring核心配置文件中添加事务管理器的配置和TransactionProxyFactoryBean代理对象&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;    &amp;lt;!--配置事务管理器--&amp;gt;
    &amp;lt;bean id=&quot;transactionManager&quot; class=&quot;org.springframework.jdbc.datasource.DataSourceTransactionManager&quot;&amp;gt;
        &amp;lt;property name=&quot;dataSource&quot; ref=&quot;dataSource&quot; /&amp;gt;
    &amp;lt;/bean&amp;gt;

    &amp;lt;!--配置业务层的代理--&amp;gt;
    &amp;lt;bean id=&quot;transferServiceProxy&quot; class=&quot;org.springframework.transaction.interceptor.TransactionProxyFactoryBean&quot;&amp;gt;
        &amp;lt;!--配置目标对象--&amp;gt;
        &amp;lt;property name=&quot;target&quot; ref=&quot;transferService&quot; /&amp;gt;
        &amp;lt;!--注入事务管理器--&amp;gt;
        &amp;lt;property name=&quot;transactionManager&quot; ref=&quot;transactionManager&quot; /&amp;gt;
        &amp;lt;!--注入事务属性--&amp;gt;
        &amp;lt;property name=&quot;transactionAttributes&quot;&amp;gt;
            &amp;lt;props&amp;gt;
                &amp;lt;!--
                    prop的格式：
                        * PROPAGATION :事务的传播行为
                        * ISOLATION :事务的隔离级别
                        * readOnly :是否只读
                        * -Exception :发生哪些异常回滚事务
                        * +Exception :发生哪些异常不回滚事务
                --&amp;gt;
                &amp;lt;prop key=&quot;transfer*&quot;&amp;gt;PROPAGATION_REQUIRED&amp;lt;/prop&amp;gt;
            &amp;lt;/props&amp;gt;
        &amp;lt;/property&amp;gt;
    &amp;lt;/bean&amp;gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;测试代码：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;@RunWith(SpringRunner.class)
@SpringBootTest
public class SpringTransactionApplicationTests {

    @Autowired
    TransferService transferService;

    @Resource(name=&quot;transferServiceProxy&quot;)
    TransferService transferServiceProxy;

    @Test
    public void contextLoads() {
        //注意，此处引入的是代理对象transferServiceProxy，而不是transferService
        transferServiceProxy.transferMoney(&quot;Bill&quot;,&quot;Jack&quot;, 200L);
    }
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;运行结果：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;java.lang.ArithmeticException: / by zero

    at com.tx.service.impl.TransferServiceImpl.transferMoney(TransferServiceImpl.java:22)
    at com.tx.service.impl.TransferServiceImpl$$FastClassBySpringCGLIB$$5196ddf2.invoke(&amp;lt;generated&amp;gt;)&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;执行service事务方法时抛出异常，事务回滚，数据库中数据未发生改变&lt;br/&gt;&lt;img src=&quot;https://upload-images.jianshu.io/upload_images/13172436-1867090c728aaa3e.JPG?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240&quot; alt=&quot;数据库.JPG&quot;/&gt;&lt;/p&gt;
&lt;h5 id=&quot;基于aspectj的xml方式&quot;&gt;基于AspectJ的XML方式&lt;/h5&gt;
&lt;p&gt;在spring核心配置文件中添加事务管理器的配置、事务的增强以及切面&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;    &amp;lt;!--配置事务管理器--&amp;gt;
    &amp;lt;bean id=&quot;transactionManager&quot; class=&quot;org.springframework.jdbc.datasource.DataSourceTransactionManager&quot;&amp;gt;
        &amp;lt;property name=&quot;dataSource&quot; ref=&quot;dataSource&quot; /&amp;gt;
    &amp;lt;/bean&amp;gt;

   &amp;lt;!--配置事务的通知--&amp;gt;
    &amp;lt;tx:advice id=&quot;txAdvice&quot; transaction-manager=&quot;transactionManager&quot;&amp;gt;
        &amp;lt;tx:attributes&amp;gt;
            &amp;lt;tx:method name=&quot;transfer*&quot; propagation=&quot;REQUIRED&quot; /&amp;gt;
        &amp;lt;/tx:attributes&amp;gt;
    &amp;lt;/tx:advice&amp;gt;

    &amp;lt;!--配置切面--&amp;gt;
    &amp;lt;aop:config&amp;gt;
        &amp;lt;aop:pointcut id=&quot;pointcut1&quot; expression=&quot;execution(* com.tx.service.impl.*ServiceImpl.*(..))&quot; /&amp;gt;
        &amp;lt;aop:advisor advice-ref=&quot;txAdvice&quot; pointcut-ref=&quot;pointcut1&quot; /&amp;gt;
    &amp;lt;/aop:config&amp;gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;测试代码：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;@RunWith(SpringRunner.class)
@SpringBootTest
public class SpringTransactionApplicationTests {

    @Autowired
    TransferService transferService;

    @Test
    public void contextLoads() {
        transferService.transferMoney(&quot;Bill&quot;,&quot;Jack&quot;, 200L);
    }
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;运行结果：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;java.lang.ArithmeticException: / by zero

    at com.tx.service.impl.TransferServiceImpl.transferMoney(TransferServiceImpl.java:22)
    at com.tx.service.impl.TransferServiceImpl$$FastClassBySpringCGLIB$$5196ddf2.invoke(&amp;lt;generated&amp;gt;)&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;执行service事务方法时抛出异常，事务回滚，数据库中数据未发生改变&lt;br/&gt;&lt;img src=&quot;https://upload-images.jianshu.io/upload_images/13172436-1867090c728aaa3e.JPG?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240&quot; alt=&quot;数据库.JPG&quot;/&gt;&lt;/p&gt;
&lt;h5 id=&quot;基于注解的方式&quot;&gt;基于注解的方式&lt;/h5&gt;
&lt;p&gt;在spring核心配置文件中添加事务管理器的配置和开启事务注解&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;    &amp;lt;!--配置事务管理器--&amp;gt;
    &amp;lt;bean id=&quot;transactionManager&quot; class=&quot;org.springframework.jdbc.datasource.DataSourceTransactionManager&quot;&amp;gt;
        &amp;lt;property name=&quot;dataSource&quot; ref=&quot;dataSource&quot; /&amp;gt;
    &amp;lt;/bean&amp;gt;

    &amp;lt;!--开启事务注解--&amp;gt;
    &amp;lt;tx:annotation-driven transaction-manager=&quot;transactionManager&quot; /&amp;gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;在事务方法中添加@Transaction注解&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;    @Transactional
    public void transferMoney(String source, String destination, Long amount) {

        transferDao.payMoney(source, amount);
        int i = 100/0;
        transferDao.collectMoney(destination, amount);
    }&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;测试代码：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;@RunWith(SpringRunner.class)
@SpringBootTest
public class SpringTransactionApplicationTests {

    @Autowired
    TransferService transferService;

    @Test
    public void contextLoads() {
        transferService.transferMoney(&quot;Bill&quot;,&quot;Jack&quot;, 200L);
    }
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;运行结果：&lt;br/&gt;```&lt;br/&gt;java.lang.ArithmeticException: / by zero&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;at com.tx.service.impl.TransferServiceImpl.transferMoney(TransferServiceImpl.java:24)
at com.tx.service.impl.TransferServiceImpl$$FastClassBySpringCGLIB$$5196ddf2.invoke(&amp;lt;generated&amp;gt;)&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;```&lt;br/&gt;数据库中数据位发生任何改变&lt;br/&gt;&lt;img src=&quot;https://upload-images.jianshu.io/upload_images/13172436-649c1505a139d33c.JPG?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240&quot; alt=&quot;数据库.JPG&quot;/&gt;&lt;/p&gt;
&lt;h5 id=&quot;总结&quot;&gt;总结&lt;/h5&gt;
&lt;p&gt;在声明式事务管理的三种实现方式中，基于TransactionProxyFactoryBean的方式需要为每个进行事务管理的类配置一个TransactionProxyFactoryBean对象进行增强，所以开发中很少使用；基于AspectJ的XML方式一旦在XML文件中配置好后，不需要修改源代码，所以开发中经常使用；基于注解的方式开发较为简单，配置好后只需要在事务类上或方法上添加@Transaction注解即可，所以开发中也经常使用&lt;/p&gt;
</description>
<pubDate>Thu, 20 Dec 2018 07:03:00 +0000</pubDate>
<dc:creator>Liant</dc:creator>
<og:description>事务的概念 我们知道，在JavaEE的开发过程中，service方法用于处理主要的业务逻辑，而业务逻辑的处理往往伴随着对数据库的多个操作。以我们生活中常见的转账为例，service方法要实现将A账户转</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/liantdev/p/10149443.html</dc:identifier>
</item>
<item>
<title>【中文版 | 论文原文】BERT：语言理解的深度双向变换器预训练 - 郭耀华</title>
<link>http://www.cnblogs.com/guoyaohua/p/bert.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/guoyaohua/p/bert.html</guid>
<description>&lt;blockquote readability=&quot;7.603305785124&quot;&gt;
&lt;p&gt;谷歌AI语言组论文&lt;strong&gt;《&lt;/strong&gt;&lt;strong&gt;BERT&lt;/strong&gt;&lt;strong&gt;：语言理解的深度双向变换器预训练》&lt;/strong&gt;，介绍一种新的语言表征模型BERT——来自变换器的双向编码器表征量。异于最新语言表征模型，BERT基于所有层的左、右语境来预训练深度双向表征量。BERT是首个大批句子层面和词块层面任务中取得当前最优性能的表征模型，性能超越许多使用任务特定架构的系统，刷新&lt;strong&gt;11&lt;/strong&gt;&lt;strong&gt;项&lt;/strong&gt;&lt;strong&gt;NLP&lt;/strong&gt;&lt;strong&gt;任务&lt;/strong&gt;当前最优性能记录，堪称最强NLP预训练模型！未来可能成为新行业基础。本文参考网上各大文章，整理翻译了&lt;strong&gt;BERT&lt;/strong&gt;&lt;strong&gt;论文，在自己学习的同时也分享给大家，欢迎交流指教。&lt;/strong&gt;论文地址：&lt;a href=&quot;https://arxiv.org/pdf/1810.04805.pdf&quot; target=&quot;_blank&quot;&gt;https://arxiv.org/pdf/1810.04805.pdf&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;　　本文介绍一种称之为&lt;strong&gt;BERT&lt;/strong&gt;的新&lt;span&gt;&lt;strong&gt;语言表征模型&lt;/strong&gt;&lt;/span&gt;，意为来自变换器的双向编码器表征量(BidirectionalEncoder Representations from Transformers)。不同于最近的&lt;strong&gt;语言表征模型&lt;/strong&gt;&lt;span&gt;(Peters等，2018; Radford等，2018)&lt;/span&gt;，BERT旨在基于所有层的左、右语境来预训练&lt;strong&gt;&lt;span&gt;深度双向表征&lt;/span&gt;&lt;/strong&gt;。因此，预训练的BERT表征可以仅用一个额外的输出层进行微调，进而为很多任务(如&lt;strong&gt;问答&lt;/strong&gt;和&lt;strong&gt;语言推理&lt;/strong&gt;)创建当前最优模型，无需对任务特定架构做出大量修改。&lt;/p&gt;
&lt;p&gt;　　BERT的概念很简单，但实验效果很强大。它刷新了11个NLP任务的当前最优结果，包括将GLUE基准提升至80.4%(7.6%的绝对改进)、将MultiNLI的准确率提高到86.7%(5.6%的绝对改进)，以及将SQuADv1.1问答测试F1的得分提高至93.2分(1.5分绝对提高)——比人类性能还高出2.0分。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;　　&lt;span&gt;语言模型预训练&lt;/span&gt;&lt;/strong&gt;已被证明可有效改进许多自然语言处理任务&lt;span&gt;(Dai and Le, 2015;Peters等，2017, 2018; Radford等，2018; Howard and Ruder, 2018)&lt;/span&gt;。这些任务包括&lt;strong&gt;句子级任务&lt;/strong&gt;，如&lt;strong&gt;自然语言推理&lt;/strong&gt;&lt;strong&gt;inference&lt;/strong&gt;&lt;span&gt;(Bowman等，2015; Williams等，2018)&lt;/span&gt;和&lt;strong&gt;释义&lt;/strong&gt;&lt;strong&gt;paraphrasing&lt;/strong&gt;&lt;span&gt;(Dolan and Brockett, 2005)&lt;/span&gt;，旨在通过整体分析来预测句子之间的关系；以及&lt;strong&gt;词块级任务&lt;/strong&gt;，如&lt;strong&gt;命名实体识别&lt;/strong&gt;&lt;span&gt;(Tjong Kim Sang andDe Meulder, 2003)&lt;/span&gt;和&lt;strong&gt;SQuAD&lt;/strong&gt;&lt;strong&gt;问题回答&lt;/strong&gt;&lt;span&gt;(Rajpurkar等，2016)&lt;/span&gt;，其中模型需要在词块级别生成细粒度输出。&lt;/p&gt;
&lt;p&gt;　　将&lt;strong&gt;预训练语言表征&lt;/strong&gt;应用于下游任务有两种现有策略：&lt;span&gt;&lt;strong&gt;基于特征feature-based&lt;/strong&gt;&lt;/span&gt;和&lt;strong&gt;&lt;span&gt;微调fine-tuning&lt;/span&gt;&lt;/strong&gt;。&lt;strong&gt;基于特征的方法&lt;/strong&gt;，例如&lt;strong&gt;ELMo&lt;/strong&gt;&lt;span&gt;(Peters等，2018)&lt;/span&gt;，使用特定于任务的架构，其包括将预训练表征作为附加特征。&lt;strong&gt;微调方法&lt;/strong&gt;，例如&lt;strong&gt;GenerativePre-trained Transformer&lt;/strong&gt;(OpenAIGPT生成型预训练变换器)&lt;span&gt;(Radford等，2018)&lt;/span&gt;，引入了最小的任务特定参数，并通过简单地微调预训练参数在下游任务中进行训练。在以前的工作中，两种方法在预训练期间共享相同的目标函数，它们使用单向语言模型来学习&lt;strong&gt;通用语言表征&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;　　我们认为，当前技术严重制约了预训练表征的能力，特别是对于微调方法。其主要局限在于标准语言模型是单向的，这限制了可以在预训练期间使用的架构类型。例如，在OpenAI GPT，作者们用一个从左到右的架构，其中每个词块只能注意变换器&lt;strong&gt;自注意层&lt;/strong&gt;中的&lt;strong&gt;前验词块&lt;/strong&gt;&lt;span&gt;(Vaswani等，2017)&lt;/span&gt;。这种局限对于句子层面任务而言是次优选择，对于词块级任务的方法，则可能是毁灭性的。在这种任务中应用基于词块级微调法，如SQuAD问答&lt;span&gt;(Rajpurkar等，2016)&lt;/span&gt;，结合两个方向语境至关重要。&lt;/p&gt;
&lt;p&gt;　　在本论文，我们通过提出&lt;strong&gt;BERT&lt;/strong&gt;模型：来自&lt;span&gt;&lt;strong&gt;变换器的双向编码器表征量(Bidirectional Encoder Representations fromTransformers)&lt;/strong&gt;&lt;/span&gt;，改进了基于微调的方法。BERT通过提出一个新的预训练目标：“遮蔽语言模型”(maskedlanguage model，MLM)，来自Cloze任务&lt;span&gt;(Taylor，1953)&lt;/span&gt;的启发，来解决前面提到的单向局限。该遮蔽语言模型随机地从输入中遮蔽一些词块，并且，目标是仅基于该遮蔽词语境语境来预测其&lt;strong&gt;原始词汇&lt;/strong&gt;&lt;strong&gt;id&lt;/strong&gt;。不像从左到右的语言模型预训练，该MLM目标允许表征融合左右两侧语境语境，这允许我们预训练一个深度双向变换器。除了该遮蔽语言模型，我们还引入了一个“下一句预测”(nextsentence prediction)任务，该任务联合预训练&lt;strong&gt;文本对表征量&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;　　我们的论文贡献如下：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;我们证明了双向预训练对&lt;strong&gt;语言表征量&lt;/strong&gt;的重要性。与&lt;span&gt;Radford等人(2018)&lt;/span&gt;不同，其使用单向语言模型进行预训练，BERT使用遮蔽语言模型来实现预训练的深度双向表征量。这也与&lt;span&gt;Peters等人(2018)&lt;/span&gt;形成对比，其使用由独立训练的从左到右和从右到左LMs(语言模型)的浅层串联。&lt;/li&gt;
&lt;li&gt;我们展示了预训练表征量能消除许多重型工程&lt;strong&gt;任务特定架构&lt;/strong&gt;的需求。BERT是第一个基于微调的表征模型，它在大量的句子级和词块级任务上实现了最先进的性能，优于许多具有任务特定架构的系统。&lt;/li&gt;
&lt;li&gt;BERT推进了11项NLP任务的最高水平。因此，我们报告了广泛的&lt;strong&gt;BERT&lt;/strong&gt;&lt;strong&gt;消融&lt;/strong&gt;，证明我们模型的双向性质是最重要的新贡献。代码和预训练模型将在&lt;a href=&quot;http://www.cnblogs.com/guoyaohua/p/goo.gl/language/bert&quot; target=&quot;_blank&quot;&gt;goo.gl/language/bert&lt;/a&gt;上提供。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;　　预训练通用语言表征有很长历史，本节我们简要回顾中这些最常用的方法。&lt;/p&gt;
&lt;h2&gt;&lt;strong&gt;2.1&lt;span class=&quot;Apple-converted-space&quot;&gt; 基于特征的方法&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;　　广泛采用的&lt;span&gt;&lt;strong&gt;单词表征学习&lt;/strong&gt;&lt;/span&gt;，已经是数十年的活跃研究领域，包括&lt;strong&gt;非神经&lt;/strong&gt;&lt;span&gt;(Brown等，1992; Ando and Zhang, 2005; Blitzer等，2006)&lt;/span&gt;和&lt;strong&gt;神经&lt;/strong&gt;&lt;span&gt;(Collobert andWeston, 2008; Mikolov等，2013; Pennington等，2014)&lt;/span&gt;方法。&lt;span&gt;&lt;strong&gt;预训练的单词嵌入&lt;/strong&gt;&lt;/span&gt;被认为是现代NLP系统的组成部分，与从头学习的&lt;strong&gt;嵌入&lt;/strong&gt;相比提供了显着的改进&lt;span&gt;(Turian等，2010)&lt;/span&gt;。&lt;/p&gt;
&lt;p&gt;　　这些方法已经被推广到更粗的粒度，如&lt;span&gt;&lt;strong&gt;句子嵌入&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;(Kiros等，2015; Logeswaran and Lee, 2018)&lt;/span&gt;或&lt;span&gt;&lt;strong&gt;段落嵌入&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;(Le and Mikolov, 2014)&lt;/span&gt;。与传统词嵌入一样，这些学习到的表征通常用作下游模型中的特征。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;　　ELMo&lt;/strong&gt;&lt;span&gt;(Peters等，2017)&lt;/span&gt;将传统的词嵌入研究概括为不同维度。他们建议从语言模型中提取语境敏感型特征。把语境字词嵌入与现有任务特定架构集成时，&lt;strong&gt;ELMo&lt;/strong&gt;针对一些主要的&lt;strong&gt;NLP&lt;/strong&gt;&lt;strong&gt;基准&lt;/strong&gt;&lt;span&gt;(Peters et al., 2018)&lt;/span&gt;提出了最先进的技术，包括关于SQUAD问答&lt;span&gt;(Rajpurkar等，2016)&lt;/span&gt;，情绪分析&lt;span&gt;(Socher等，2013)&lt;/span&gt;，以及命名实体识别&lt;span&gt;(Tjong Kim Sang和De Meulder，2003)&lt;/span&gt;。&lt;/p&gt;
&lt;h2&gt;&lt;strong&gt;2.2&lt;span class=&quot;Apple-converted-space&quot;&gt; 微调方法&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;　　一种源于&lt;strong&gt;语言模型&lt;/strong&gt;&lt;strong&gt;(LMs)&lt;/strong&gt;的&lt;strong&gt;迁移学习&lt;/strong&gt;新趋势，是微调前预训练一些LM目标上的模型架构，该微调是相同型号的一种监督下游任务&lt;span&gt;(Dai and Le, 2015;Howard and Ruder, 2018; Radford等，2018)&lt;/span&gt;。这些方法的优点是几乎没有参数需要从头开始学习。至少部分是由于这一优势，&lt;span&gt;&lt;span&gt;&lt;strong&gt;OpenAIGPT&lt;/strong&gt;&lt;/span&gt;(Radford等，2018)&lt;/span&gt;在许多句子级别任务的GLUE基准&lt;span&gt;(Wang等，2018)&lt;/span&gt;，取得此前最好测试结果。&lt;/p&gt;
&lt;h2&gt;&lt;strong&gt;2.3&lt;span class=&quot;Apple-converted-space&quot;&gt; 从监督数据转移学习&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;　　虽然无监督预训练的优势在于可获得的数据量几乎无限，但也有工作表明从具有大型数据集的监督任务中可有效迁移，例如&lt;strong&gt;自然语言推理&lt;/strong&gt;&lt;span&gt;(Conneau等，2017)&lt;/span&gt;和&lt;strong&gt;机器翻译&lt;/strong&gt;&lt;span&gt;(Mc-Cann等，2017)&lt;/span&gt;。在NLP之外，&lt;strong&gt;计算机视觉&lt;/strong&gt;研究也证明了从大型预训练模型迁移学习的重要性，其中一个有效的方法是微调在ImageNet上预训练的模型&lt;span&gt;(Deng等，2009; Yosinski等，2014)&lt;/span&gt;。&lt;/p&gt;

&lt;p&gt;　　我们在本节介绍BERT及其详细实现。我们先介绍BERT的模型架构和输入表征。然后，我们将在3.3节中介绍预训练任务，即&lt;strong&gt;本文的核心创新&lt;/strong&gt;。预训练程序和微调程序分别在第3.4节和第3.5节中详述。最后，第3.6节讨论了BERT和OpenAIGPT之间的差异。&lt;/p&gt;
&lt;h2&gt;&lt;strong&gt;3.1&lt;span class=&quot;Apple-converted-space&quot;&gt; 模型架构Model Architecture&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;　　BERT模型架构是一种&lt;span&gt;&lt;strong&gt;多层双向变换器（Transformer）编码器&lt;/strong&gt;&lt;/span&gt;，基于Vaswani等人&lt;span&gt;(2017年)&lt;/span&gt;描述并在&lt;span&gt;&lt;a href=&quot;https://github.com/tensorflow/tensor2tensor&quot; target=&quot;_blank&quot;&gt;&lt;strong&gt;tensor2tensor&lt;/strong&gt;&lt;strong&gt;库&lt;/strong&gt;&lt;/a&gt;&lt;/span&gt;发行的原始实现。因为变换器的使用最近变得无处不在，我们架构的实施有效地等同于原始实现，所以我们会忽略模型架构详尽的背景描述，并向读者推荐Vaswani等人(2017)的优秀指南，如“&lt;span&gt;&lt;strong&gt;注释变换器&lt;/strong&gt;&lt;/span&gt;”。(&lt;a href=&quot;http://nlp.seas.harvard.edu/2018/04/03/attention.html&quot; target=&quot;_blank&quot;&gt;http://nlp.seas.harvard.edu/2018/04/03/attention.html&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;在这项工作中，我们把&lt;span&gt;&lt;strong&gt;层数&lt;/strong&gt;&lt;/span&gt;(即Transformer blocks变换器块)表征为L，&lt;span&gt;&lt;strong&gt;隐节点大小&lt;/strong&gt;&lt;/span&gt;表征为H，&lt;span&gt;&lt;strong&gt;自注意力数目&lt;/strong&gt;&lt;/span&gt;表征为A。在所有情况下，我们设置前馈/过滤器的尺寸为4H，如H=768时为3072，H=1024时为4096。我们主要报告在两种模型尺寸上的结果：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;span&gt;&lt;strong&gt;BERT&lt;sub&gt;BASE&lt;/sub&gt;&lt;/strong&gt;：L=12，H=768，A=12，总参数=110M&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span&gt;&lt;strong&gt;BERT&lt;sub&gt;LARGE&lt;/sub&gt;&lt;/strong&gt;：L=24，H=1024，A=16，总参数=340M&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;span&gt;　　选择的BERT&lt;sub&gt;BASE&lt;/sub&gt;模型尺寸等同于OpenAIGPT模型尺寸，以进行比较。然而，重要的是，BERT变换器使用&lt;span&gt;双向自注意&lt;/span&gt;，而GPT变换器使用受限自注意，&lt;span&gt;每个词块只能注意其左侧语境&lt;/span&gt;。我们注意到，在文献中，&lt;span&gt;&lt;strong&gt;双向变换器通&lt;/strong&gt;常指称为“变换器编码器”，而其&lt;strong&gt;左侧语境&lt;/strong&gt;版本被称为“变换器解码器”&lt;/span&gt;，因为它可用于文本生成。BERT，OpenAIGPT和ELMo之间的比较如图1所示。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1192699/201812/1192699-20181207115222802-1434326712.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;em&gt;图1：预训练模型架构间差异。BERT使用双向变换器，OpenAI GPT使用从左到右的变换器，ELMo使用独立训练的从左到右和从右到左LSTM级联来生成下游任务的特征。三种模型中只有BERT表征基于所有层左右两侧语境。&lt;/em&gt;&lt;/span&gt; &lt;/p&gt;
&lt;h2&gt;&lt;span&gt;&lt;strong&gt;3.2&lt;span class=&quot;Apple-converted-space&quot;&gt; 输入表征&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;
&lt;p&gt;&lt;span&gt;　　我们的&lt;span&gt;&lt;strong&gt;输入表征&lt;/strong&gt;&lt;strong&gt;(input representation)&lt;/strong&gt;&lt;/span&gt;能在一个词块序列中明确地表征单个文本句子或一对文本句子(例如，[问题，答案][Question,Answer])。(注：&lt;span class=&quot;Apple-converted-space&quot;&gt;在整个这项工作中，“&lt;strong&gt;句子&lt;/strong&gt;”可以是连续文本的任意跨度，而不是实际的语言句子。“&lt;strong&gt;序列&lt;/strong&gt;”指BERT的输入词块序列，其可以是单个句子或两个句子打包在一起。)对于给定词块，&lt;span&gt;其&lt;strong&gt;输入表征&lt;/strong&gt;通过对相应词块的&lt;strong&gt;&lt;span&gt;词块嵌入&lt;/span&gt;、&lt;span&gt;段嵌入&lt;/span&gt;和&lt;span&gt;位嵌入&lt;/span&gt;求和&lt;/strong&gt;来构造。&lt;/span&gt;图2给出了我们的输入表征的直观表征。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1192699/201812/1192699-20181213165937465-2014841944.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;em&gt;图2：BERT输入表征。输入嵌入是词块嵌入、段嵌入和位嵌入的总和。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;具体是：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;我们使用&lt;span&gt;&lt;strong&gt;WordPiece&lt;/strong&gt;&lt;strong&gt;嵌入&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;(Wu等，2016)&lt;/span&gt;和&lt;span&gt;30,000个&lt;strong&gt;词块表&lt;/strong&gt;&lt;/span&gt;。我们用##表征&lt;strong&gt;分词&lt;/strong&gt;。&lt;/li&gt;
&lt;li&gt;我们使用学习的位置嵌入，支持的序列长度最多为&lt;span&gt;512&lt;/span&gt;个&lt;strong&gt;词块&lt;/strong&gt;。&lt;/li&gt;
&lt;li&gt;每个序列的第一个词块始终是&lt;strong&gt;特殊分类嵌入&lt;/strong&gt;&lt;strong&gt;([CLS])&lt;/strong&gt;。对应该词块的最终隐藏状态(即，变换器输出)被用作分类任务的&lt;strong&gt;聚合序列表征&lt;/strong&gt;。对于非分类任务，将忽略此向量。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;句子对&lt;/strong&gt;被打包成单个序列。我们以两种方式区分句子。首先，我们用&lt;strong&gt;特殊词块&lt;/strong&gt;&lt;strong&gt;([SEP])&lt;/strong&gt;将它们分开。其次，我们添加一个&lt;strong&gt;学习句子&lt;/strong&gt;&lt;strong&gt;A&lt;/strong&gt;嵌入到第一个句子的每个词块中，一个&lt;strong&gt;句子&lt;/strong&gt;&lt;strong&gt;B&lt;/strong&gt;嵌入到第二个句子的每个词块中。&lt;/li&gt;
&lt;li&gt;对于单句输入，我们只使用句子A嵌入。&lt;/li&gt;
&lt;/ul&gt;&lt;h2&gt;&lt;strong&gt;3.3&lt;span class=&quot;Apple-converted-space&quot;&gt; 预训练任务&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;　　与&lt;span&gt;Peters等人(2018)&lt;/span&gt;和&lt;span&gt;Radford等人(2018)&lt;/span&gt;不同，我们不使用传统的从左到右或从右到左的语言模型来预训练BERT。相反，我们使用两个新型无监督预测任务对BERT进行预训练，如本节所述。&lt;/p&gt;
&lt;h3&gt;&lt;strong&gt;3.3.1&lt;span class=&quot;Apple-converted-space&quot;&gt; &lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;任务&lt;/strong&gt;&lt;strong&gt;#1&lt;/strong&gt;&lt;strong&gt;：遮蔽语言模型&lt;/strong&gt;&lt;strong&gt;&lt;span class=&quot;Apple-converted-space&quot;&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;　　直观地说，有理由相信&lt;strong&gt;深度双向模型&lt;/strong&gt;比&lt;strong&gt;左向右模型&lt;/strong&gt;或&lt;strong&gt;从左到右和右到左模型&lt;/strong&gt;的浅层连接更严格。遗憾的是，&lt;strong&gt;标准条件语言模型&lt;/strong&gt;只能从左到右或从右到左进行训练，因为&lt;strong&gt;双向调节&lt;/strong&gt;将允许每个单词在多层语境中间接地“看到自己”。&lt;/p&gt;
&lt;p&gt;　　为了训练深度双向表征，我们采用一种直接方法，&lt;span&gt;随机遮蔽输入词块的某些部分，然后仅预测那些被遮蔽词块。我们将这个过程称为&lt;strong&gt;“遮蔽&lt;/strong&gt;&lt;strong&gt;LM&lt;/strong&gt;&lt;strong&gt;”&lt;/strong&gt;&lt;strong&gt;(MLM)&lt;/strong&gt;&lt;/span&gt;，尽管它在文献中通常被称为&lt;strong&gt;Cloze&lt;/strong&gt;&lt;strong&gt;完形任务&lt;/strong&gt;&lt;span&gt;(Taylor, 1953)&lt;/span&gt;。在这种情况下，对应于遮蔽词块的&lt;strong&gt;最终隐藏向量&lt;/strong&gt;被馈送到词汇表上的输出softmax函数中，如在标准LM中那样预测所有词汇的概率。在我们所有实验中，我们随机地遮蔽蔽每个序列中所有WordPiece词块的&lt;span&gt;&lt;strong&gt;15％&lt;/strong&gt;&lt;/span&gt;。与去噪自动编码器&lt;span&gt;(Vincent等，2008)&lt;/span&gt;相反，我们只预测遮蔽单词而不是重建整个输入。&lt;/p&gt;
&lt;p&gt;　　虽然这确实允许我们获得双向预训练模型，但该方法有两个缺点。首先，我们正在创建预训练和微调之间的不匹配，因为在微调期间从未看到&lt;strong&gt;[MASK]&lt;/strong&gt;&lt;strong&gt;词块&lt;/strong&gt;。为了缓解这个问题，我们并不总是用实际的&lt;strong&gt;[MASK]&lt;/strong&gt;&lt;strong&gt;词块&lt;/strong&gt;替换“遮蔽”单词。相反，训练数据生成器随机选择15％的词块，例如，在句子：&lt;span&gt;&lt;em&gt;我的狗是毛茸茸的&lt;/em&gt;&lt;/span&gt;，它选择毛茸茸的。然后完成以下过程：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;并非始终用[MASK]替换所选单词，数据生成器将执行以下操作：&lt;/li&gt;
&lt;li&gt;80％的时间：用[MASK]词块替换单词，例如，&lt;em&gt;我的狗是毛茸茸的&lt;/em&gt;！我的狗是[MASK]&lt;/li&gt;
&lt;li&gt;10％的时间：用随机词替换遮蔽词，例如，&lt;em&gt;我的狗是毛茸茸的&lt;/em&gt;！我的狗是苹果&lt;/li&gt;
&lt;li&gt;10％的时间：保持单词不变，例如，&lt;em&gt;我的狗是毛茸茸的！我的狗毛茸茸的&lt;/em&gt;。这样做的目的是将该&lt;strong&gt;表征&lt;/strong&gt;偏向于实际观察到的单词。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;　　变换器编码器&lt;strong&gt;不知道它将被要求预测哪些单词或哪些单词已被随机单词替换&lt;/strong&gt;，因此它被迫保持每个输入词块的&lt;strong&gt;分布式语境表征&lt;/strong&gt;。此外，因为随机替换只发生在所有词块的1.5％(即15％的10％)，这似乎不会损害模型的语言理解能力。&lt;/p&gt;
&lt;p&gt;　　使用MLM的第二个缺点是&lt;strong&gt;每批中只预测了&lt;/strong&gt;&lt;strong&gt;15&lt;/strong&gt;&lt;strong&gt;％的词块&lt;/strong&gt;，这表明模型可能需要更多的预训练步骤才能收敛。在5.3节中，我们证明MLM的收敛速度略慢于从左到右的模型(预测每个词块)，但MLM模型在实验上的改进远远超过所增加的训练成本。&lt;/p&gt;
&lt;h3&gt;&lt;strong&gt;3.3.2&lt;span class=&quot;Apple-converted-space&quot;&gt; &lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;任务&lt;/strong&gt;&lt;strong&gt;#2&lt;/strong&gt;&lt;strong&gt;：下一句预测&lt;/strong&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;　　很多重要的下游任务，例如问答(QA)和自然语言推理(NLI)，都是基于对两个文本句子间关系的理解，而这种关系并非通过&lt;strong&gt;语言建模&lt;/strong&gt;直接获得。为了训练一个理解句子关系的模型，我们预训练了一个&lt;strong&gt;二值化下一句预测任务&lt;/strong&gt;，该任务可以从任何单语语料库中轻松生成。具体来说，选择句子A和B作为预训练样本：B有50%的可能是A的下一句，也有50%的可能是来自语料库的随机句子。例如：&lt;/p&gt;
&lt;blockquote readability=&quot;7&quot;&gt;
&lt;p&gt;&lt;span&gt;&lt;em&gt;输入&lt;/em&gt;&lt;em&gt;=[CLS]&lt;/em&gt;&lt;em&gt;男子去&lt;/em&gt;&lt;em&gt;[MASK]&lt;/em&gt;&lt;em&gt;商店&lt;/em&gt;&lt;em&gt;[SEP]&lt;/em&gt;&lt;em&gt;他买了一加仑&lt;/em&gt;&lt;em&gt;[MASK]&lt;/em&gt;&lt;em&gt;牛奶&lt;/em&gt;&lt;em&gt;[SEP]&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;em&gt;Label= IsNext&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;em&gt;输入&lt;/em&gt;&lt;em&gt;=[CLS]&lt;/em&gt;&lt;em&gt;男人&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;em&gt;面具&lt;/em&gt;&lt;em&gt;]&lt;/em&gt;&lt;em&gt;到商店&lt;/em&gt;&lt;em&gt;[SEP]&lt;/em&gt;&lt;em&gt;企鹅&lt;/em&gt;&lt;em&gt;[&lt;/em&gt;&lt;em&gt;面具&lt;/em&gt;&lt;em&gt;]&lt;/em&gt;&lt;em&gt;是飞行&lt;/em&gt;&lt;em&gt;##&lt;/em&gt;&lt;em&gt;少鸟&lt;/em&gt;&lt;em&gt;[SEP]&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;em&gt;Label=&lt;span class=&quot;Apple-converted-space&quot;&gt; NotNext&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;　　我们完全随机选择这些NotNext语句，最终预训练模型在此任务中达到97％-98％的准确率。尽管它很简单，但我们在5.1节中证明，&lt;strong&gt;面向该任务的预训练&lt;/strong&gt;对QA和NLI都非常有益。&lt;/p&gt;
&lt;h2&gt;&lt;strong&gt;3.4&lt;span class=&quot;Apple-converted-space&quot;&gt; 预训练过程&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;　　BERT预训练过程主要遵循现有的&lt;strong&gt;语言模型预训练文献&lt;/strong&gt;。对于&lt;strong&gt;预训练语料库&lt;/strong&gt;，我们使用&lt;span&gt;&lt;strong&gt;BooksCorpus&lt;/strong&gt;&lt;/span&gt;(800M单词)&lt;span&gt;(Zhu等，2015)&lt;/span&gt;和&lt;span&gt;&lt;strong&gt;英语维基百科&lt;/strong&gt;&lt;/span&gt;(2,500M单词)的串联。对于维基百科，我们只提取文本段落并忽略列表、表格和题头。至关重要的是，使用&lt;strong&gt;文档级语料库&lt;/strong&gt;而不是&lt;strong&gt;洗牌式&lt;/strong&gt;&lt;strong&gt;(&lt;/strong&gt;&lt;strong&gt;乱词序&lt;/strong&gt;&lt;strong&gt;)&lt;/strong&gt;&lt;strong&gt;句子级语料库&lt;/strong&gt;，例如&lt;strong&gt;Billion Word Benchmark&lt;/strong&gt;&lt;span&gt;(Chelba等，2013)&lt;/span&gt;，以便提取长的连续序列。&lt;/p&gt;
&lt;p&gt;　　为了生成每个训练输入序列，我们从语料库中采样两个文本跨度，我们将其称为“&lt;strong&gt;句子&lt;/strong&gt;”，即使它们通常比单个句子长得多(但也可以更短)。第一个句子接收A嵌入，第二个句子接收B嵌入。B有50％可能刚好是A嵌入后的下一个句子，亦有50％可能是个随机句子，此乃为“下一句预测”任务而做。对它们采样，使其组合长度≦512个词块。该&lt;strong&gt;LM&lt;/strong&gt;&lt;strong&gt;遮蔽&lt;/strong&gt;应用于具有15％统一掩蔽率的WordPiece词块化之后，并且不特别考虑&lt;strong&gt;部分字块&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;　　&lt;span&gt;我们训练批量大小为256个序列(256个序列*512个词块=128,000个词块/批次)，持续1,000,000个步骤，这比33亿个&lt;strong&gt;单词语料库&lt;/strong&gt;大约40个周期。我们使用Adam(学习程序)，设其&lt;strong&gt;学习率&lt;/strong&gt;为1e-4，β&lt;sub&gt;1&lt;/sub&gt;=0.9，β&lt;sub&gt;2&lt;/sub&gt;=0.999，&lt;strong&gt;L2&lt;/strong&gt;&lt;strong&gt;权重&lt;/strong&gt;衰减为0.01，学习率预热超过前10,000步以上以及线性衰减该学习率。我们在所有层上使用0.1的丢失概率。在OpenAIGPT之后，我们使用gelu激活&lt;span&gt;(Hendrycks和Gimpel, 2016)&lt;/span&gt;而不是标准relu。训练损失是平均的遮蔽LM可能性和平均的下一句子预测可能性的&lt;strong&gt;总和&lt;/strong&gt;。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;　　在Pod配置的4个云TPU上进行了&lt;strong&gt;BERT&lt;sub&gt;BASE&lt;/sub&gt;&lt;/strong&gt;&lt;strong&gt;训练&lt;/strong&gt;(总共16个TPU芯片)。&lt;span&gt;(注：https://cloudplatform.googleblog.com/2018/06/Cloud-TPU-now-offers-preemptible-pricing-and-globalavailability.html)&lt;/span&gt;在16个云TPU(总共64个TPU芯片)进行了&lt;strong&gt;BERT&lt;sub&gt;LARGE&lt;/sub&gt;&lt;/strong&gt;&lt;strong&gt;训练&lt;/strong&gt;。每次预训练需4天完成。&lt;/p&gt;
&lt;h2&gt;&lt;strong&gt;3.5&lt;span class=&quot;Apple-converted-space&quot;&gt; 微调过程&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;　　对于序列级分类任务，BERT微调很简单。为了获得输入序列的&lt;strong&gt;固定维度池化表征&lt;/strong&gt;，我们对该输入第一个词块采取&lt;strong&gt;最终隐藏状态&lt;/strong&gt;(例如，该变换器输出)，通过对应于特殊[CLS]词嵌入来构造。我们将该&lt;strong&gt;向量&lt;/strong&gt;表示为C∈R&lt;sup&gt;H&lt;/sup&gt;。微调期间添加的唯一新参数是分类层向量W∈R&lt;sup&gt;KxH&lt;/sup&gt;，其中K是&lt;strong&gt;分类器标签&lt;/strong&gt;的数量。该&lt;strong&gt;标签概率&lt;/strong&gt;P∈R&lt;sup&gt;K&lt;/sup&gt;用标准softmax函数，P=softmax(CW&lt;sup&gt;T&lt;/sup&gt;)计算。BERT和W的所有参数都经过联动地微调，以最大化&lt;strong&gt;正确标签&lt;/strong&gt;的对数概率。对于跨度级和词块级预测任务，必须以&lt;strong&gt;任务特定方式&lt;/strong&gt;稍微修改上述过程。详情见第4节的相应小节。&lt;/p&gt;
&lt;p&gt;　　对于微调，大多数&lt;strong&gt;模型超参数&lt;/strong&gt;与预训练相同，但批量大小、学习率和训练周期数量除外。丢失概率始终保持在0.1。最佳超参数值是特定于任务的，但我们发现以下范围的可能值可以在所有任务中很好地工作：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;批量大小&lt;/strong&gt;：16,32&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;学习率&lt;/strong&gt;&lt;strong&gt;(Adam)&lt;/strong&gt;：5e-5,3e-5,2e-5&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;周期数量&lt;/strong&gt;：3,4&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;　　我们还观察到，&lt;strong&gt;大数据集&lt;/strong&gt;(如100k+词块的训练样例)对超参数选择的敏感性远小于&lt;strong&gt;小数据集&lt;/strong&gt;。微调通常非常快，因此需合理简单地对上述参数进行详尽搜索，并选择开发集上性能最佳的模型。&lt;/p&gt;
&lt;h2&gt;&lt;strong&gt;3.6 BERT和OpenAI GPT比较&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;　　与BERT最具可比性的现有预训练方法是&lt;span&gt;&lt;strong&gt;OpenAI GPT&lt;/strong&gt;&lt;/span&gt;，它在大型文本语料库中训练左到右的&lt;strong&gt;变换器&lt;/strong&gt;&lt;strong&gt;LM&lt;/strong&gt;。实际上，许多BERT设计决策被有意地选择为尽可能接近GPT，以便最细微地比较这两种方法。这项工作的核心论点是占主要经验改进的3.3节中提出的两个&lt;strong&gt;新型预训练任务&lt;/strong&gt;，但我们注意到BERT和GPT在如何训练之间还存在其他一些差异：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;GPT在BooksCorpus(800M单词)训练；BERT在BooksCorpus(800M单词)和维基百科(2,500M单词)训练。&lt;/li&gt;
&lt;li&gt;GPT使用一种句子分隔符([SEP])和分类符词块([CLS])，它们仅在微调时引入；BERT在预训练期间学习[SEP]，[CLS]和句子A/B嵌入。&lt;/li&gt;
&lt;li&gt;GPT用一个批量32,000单词训练1M步；BERT用一个批量128,000单词训练1M步。&lt;/li&gt;
&lt;li&gt;GPT对所有微调实验使用的5e-5&lt;strong&gt;相同学习率&lt;/strong&gt;；BERT选择特定于任务的微调学习率，在开发集表现最佳。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;　　为了分离这些差异的影响，我们在5.1节进行了消融实验，证明大多数改进实际上来自&lt;strong&gt;新型预训练任务&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;　　在本节中，我们将介绍11个NLP任务的BERT微调结果。&lt;/p&gt;
&lt;h2&gt;&lt;strong&gt;4.1 GLUE数据集&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;　　通用语言理解评估(GLUE)基准&lt;span&gt;(Wang等，2018)&lt;/span&gt;是各种自然语言理解任务的集合。大多数GLUE数据集已存在多年，但GLUE的目的是：(1) 使用规范的Train、Dev和Test拆分发行这些数据集； (2) 设置评估服务器以减轻评估不一致事件和测试集过度拟合。GLUE不会为测试集分发标签，用户必须将其预测上传到GLUE服务器进行评估，并限制提交的数量。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;GLUE&lt;/strong&gt;&lt;strong&gt;基准&lt;/strong&gt;包括以下数据集，其描述最初在Wang等人&lt;span&gt;(2018)&lt;/span&gt;的文章中进行了总结：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;　　　　多类型自然语言推理&lt;/strong&gt;是一项大规模的众包蕴涵分类任务&lt;span&gt;(Williams等，2018)&lt;/span&gt;。给定一对句子，目标是预测第二句与第一句相比是蕴涵、矛盾还是中立。&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;Apple-converted-space&quot;&gt;&lt;strong&gt;　　　　Quora&lt;/strong&gt;&lt;strong&gt;问题对&lt;/strong&gt;是一个二元分类任务，其目的是确定Quora上提出的两个问题是否在语义上是等价的&lt;span&gt;(Chen等，2018)&lt;/span&gt;。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;　　　　问题自然语言推理&lt;/strong&gt;是斯坦福问题答疑数据集&lt;span&gt;(Rajpurkar等，2016)&lt;/span&gt;的一个版本，已被转换为二元分类任务&lt;span&gt;(Wang等，2018)&lt;/span&gt;。正例是&lt;strong&gt;(&lt;/strong&gt;&lt;strong&gt;问题，句子&lt;/strong&gt;&lt;strong&gt;)&lt;/strong&gt;&lt;strong&gt;对&lt;/strong&gt;包含正确答案，而负例是&lt;strong&gt;(&lt;/strong&gt;&lt;strong&gt;问题，句子&lt;/strong&gt;&lt;strong&gt;)&lt;/strong&gt;来自同一段落，不包含答案。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;　　　　斯坦福情感树库&lt;/strong&gt;&lt;strong&gt;2&lt;/strong&gt;是一个二元单句分类任务，由从电影评论中提取的句子和人类注释的情绪组成&lt;span&gt;(Socher等，2013)&lt;/span&gt;。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;　　　　语言可接受性语料库&lt;/strong&gt;是一个二元单句分类任务，其目标是预测英语句子在语言上是否“可接受”&lt;span&gt;(Warstadt等，2018)&lt;/span&gt;。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;　　　　语义文本相似性基准&lt;/strong&gt;是从新闻标题和其他来源中提取的句子对的集合&lt;span&gt;(Cer等，2017)&lt;/span&gt;。它们用1到5的分数进行注释，表示两个句子在语义上的相似程度。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;　　　　微软研究院解释语料库&lt;/strong&gt;由从在线新闻源自动提取的句子对组成，其中人类注释是否该对中的句子是否在语义上相等&lt;span&gt;(Dolan和Brockett，2005)&lt;/span&gt;。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;　　　　识别文本蕴涵&lt;/strong&gt;是类似于MNLI的二进制蕴涵任务，但训练数据少得多&lt;span&gt;(Bentivogli等，2009)&lt;/span&gt;。&lt;span&gt;(注：&lt;span class=&quot;Apple-converted-space&quot;&gt;请注意，本文仅报告单任务微调结果。多任务微调方法可能会进一步推动结果。例如，我们确实观察到MNLI多任务培训对RTE的实质性改进。)&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;　　　　威诺格拉德自然语言推理&lt;/strong&gt;是一个源自&lt;span&gt;(Levesque等，2011)&lt;/span&gt;的小型自然语言推理数据集。GLUE网页指出，该数据集的构建存在问题，并且每个提交给GLUE训练过的系统的性能都比预测&lt;strong&gt;大多数类别&lt;/strong&gt;的65.1基线准确度差。&lt;span&gt;(注：https://gluebenchmark.com/faq) &lt;/span&gt;因此，我们将这一组排除在OpenAIGPT的公平性之外。对于我们的GLUE提交，我们总是预测其大多数的类。&lt;/p&gt;
&lt;h3&gt;&lt;strong&gt;4.1.1 GLUE&lt;/strong&gt;&lt;strong&gt;结果&lt;/strong&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1192699/201812/1192699-20181214173656763-179180216.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;em&gt;图3：我们的任务特定模型是由向BERT添加一个额外输出层而形成的，因此一小部分参数需要从头开始学习。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;em&gt;在该任务中，(a)和(b)是序列级任务，(c)和(d)是词块级任务。图中E代表其输入嵌入，Ti代表词块i的语境表征，[CLS]是分类输出的特殊符号，[SEP]是分割非连续词块序列的特殊符号。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;　　对GLUE微调，我们呈现了第3节中描述的&lt;strong&gt;输入序列&lt;/strong&gt;或&lt;strong&gt;序列对&lt;/strong&gt;，并使用对应于第一个输入词块([CLS])的最终隐藏向量C∈R&lt;sup&gt;H&lt;/sup&gt;作为聚合表征。这都呈现在可视化图3(a)和(b)中。在微调期间引入的唯一新参数是分类层W∈R&lt;sup&gt;K&lt;/sup&gt;&lt;sup&gt;×&lt;/sup&gt;&lt;sup&gt;H&lt;/sup&gt;，其中K是&lt;strong&gt;标签数量&lt;/strong&gt;。我们用C和W计算标准分类损失，即log(softmax(CW&lt;sup&gt;T&lt;/sup&gt;))。&lt;/p&gt;
&lt;p&gt;　　对所有GLUE任务，我们均在其数据上使用一个批量大小为32和3个周期。对于每项任务，我们用学习率5e-5,4e-5,3e-5和2e-5做了微调，并选择了在其Dev集上性能最佳的那一个。此外，对于BERT&lt;sub&gt;LARGE&lt;/sub&gt;，我们发现微调有时在小数据集上不稳定(如，某些运行会产生退化结果)，因此我们运行了几次随机重启并选择了在Dev集上性能最佳的模型。通过随机重启，我们使用相同的&lt;strong&gt;预训练检查点&lt;/strong&gt;，但执行不同的微调数据混洗和分类器层初始化。我们注意到GLUE数据集分布不包括其&lt;strong&gt;测试标签&lt;/strong&gt;，我们只为每个BERT&lt;sub&gt;BASE&lt;/sub&gt;和BERT&lt;sub&gt;LARGE&lt;/sub&gt;做单一的&lt;strong&gt;GLUE&lt;/strong&gt;&lt;strong&gt;评估服务器提交&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1192699/201812/1192699-20181214173907110-205952700.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&lt;span&gt;表1：GLUE测试结果，评分来自其GLUE评估服务器。每个任务下面的数字代表该训练样本数量。“Average”列与GLUE官方分数略微不同，因为我们排除了有问题的WNLI集。&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&lt;span&gt;OpenAI GPT = (L=12, H=768, A=12)；BERT&lt;sub&gt;BASE&lt;/sub&gt;= (L=12, H=768, A=12)；BERT&lt;sub&gt;LARGE&lt;/sub&gt;&lt;span class=&quot;Apple-converted-space&quot;&gt; = (L=24, H=1024,A=16)。&lt;/span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&lt;span&gt;&lt;span class=&quot;Apple-converted-space&quot;&gt;BERT和OpenAI GPT是单模型、单任务。所有结果来自于以下地址：https://gluebenchmark.com/leaderboard和https://blog.openai. com/language-unsupervised/。&lt;/span&gt;&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&lt;span&gt;&lt;span class=&quot;Apple-converted-space&quot;&gt;　　&lt;/span&gt;&lt;/span&gt;&lt;/em&gt;结果如表1所示。BERT&lt;sub&gt;BASE&lt;/sub&gt;和BERT&lt;sub&gt;LARGE&lt;/sub&gt;在所有任务上的性能均优于所有现有系统，相对于最先进水平，平均准确度提高了4.4％和6.7％。请注意，BERT&lt;sub&gt;BASE&lt;/sub&gt;和OpenAIGPT在其&lt;strong&gt;注意遮蔽&lt;/strong&gt;之外的模型架构几乎相同。对于规模最大、报道最广泛的GLUE任务，MNLI、BERT的绝对精度提高了4.7％，超过了最先进水平。在官方GLUE排行榜&lt;sup&gt;8&lt;/sup&gt;上，BERT&lt;sub&gt;LARGE&lt;/sub&gt;得分为80.4，而该排行榜系统登顶的OpenAIGPT在本文撰写之日获得72.8分。&lt;span&gt;(注 https://gluebenchmark.com/leaderboard)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;　　有趣的是，BERT&lt;sub&gt;LARGE&lt;/sub&gt;在所有任务中都明显优于BERT&lt;sub&gt;BASE&lt;/sub&gt;，即使训练数据非常少的那些也是如此。第5.2节更全面地探讨了&lt;strong&gt;BERT&lt;/strong&gt;&lt;strong&gt;模型尺寸&lt;/strong&gt;的影响。&lt;/p&gt;
&lt;h2&gt;&lt;strong&gt;4.2&lt;span class=&quot;Apple-converted-space&quot;&gt; 斯坦福问答数据集 SQuAD v1.1&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;　　Standford问题回答数据集(SQuAD)是一种100k众包问答对的集合&lt;span&gt;(Rajpurkar等，2016)&lt;/span&gt;。给出一个问题和包含答案的来自维基百科的一个段落，任务是预测该段落中的其答案文本的跨度。例如：&lt;/p&gt;
&lt;blockquote readability=&quot;7&quot;&gt;
&lt;p&gt;&lt;span&gt;•输入问题：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;em&gt;水滴在哪里与冰晶碰撞形成沉淀？&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;•输入段落：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;em&gt;...&lt;/em&gt;&lt;em&gt;沉淀形成为较小的液滴通过与云中的其他雨滴或冰晶碰撞而聚结。&lt;/em&gt;&lt;em&gt;...&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;•输出答案：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;em&gt;在云中&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;　　这种类型的跨度预测任务与GLUE的序列分类任务完全不同，但我们能以简单的方式调整BERT以在SQuAD上运行。与GLUE一样，我们将输入问题和段落表示为单个打包序列，问题使用A嵌入和使用B嵌入的段落。在微调期间学习的唯一新参数是起始矢量S∈R&lt;sup&gt;H&lt;/sup&gt;和结束矢量E∈R&lt;sup&gt;H&lt;/sup&gt;。让来自BERT的第i个输入词块的最终隐藏向量表示为Ti∈R&lt;sup&gt;H&lt;/sup&gt;。请参见可视化图3(c)。然后，单词 i 作为答案跨度开始的概率被计算为Ti和S之间的点积(dot product)，跟随着段落中所有单词的softmax：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1192699/201812/1192699-20181220114949078-713910837.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　相同公式用于其答案跨度的末端，最大评分范围用作其预测。训练目标是正确的开始和结束位置的&lt;strong&gt;log&lt;/strong&gt;&lt;strong&gt;似然&lt;/strong&gt;(log-likelihood)。&lt;/p&gt;
&lt;p&gt;　　我们以学习率5e-5批量大小32来训练3个周期。推理时，由于结束预测不以开始为条件，我们添加了在开始后必须结束的约束，但是没有使用其他启发式方法。&lt;strong&gt;词块化标记跨度&lt;/strong&gt;与&lt;strong&gt;原始非词块化输入&lt;/strong&gt;对齐，以做评估。&lt;/p&gt;
&lt;p&gt;　　结果呈现在表2。SQuAD用很严格的测试过程，其提交者必须人工联系SQuAD组织者以在一个隐藏测试集上运行他们的系统，因此我们只提交了我们最好的系统进行测试。该表显示的结果是我们向SQuAD提交的第一个也是唯一的测试。我们注意到SQuAD排行榜最好高结果没有最新的可用公共系统描述，并且在训练他们的系统时可以使用任何公共数据。因此，我们通过我们提交的系统中使用非常适度的数据增强，在SQuAD和TriviaQA&lt;span&gt;(Joshi等，2017)&lt;/span&gt;上联合训练。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1192699/201812/1192699-20181214174559171-1400833149.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&lt;span&gt;表2：SQuAD结果。本BERT集成是使用不同预训练检查点和微调种子(fine-tuning seed)的7x系统。&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;　　我们性能最佳的系统在整体排名中优于顶级排行榜系统+1.5 F1项，在单一系统中优于+1.3 F1项。事实上，我们的单一BERT模型在F1得分方面优于顶级全体系统。如果我们只微调SQuAD(没有TriviaQA)，我们将失去0.1-0.4的F1得分，但仍然大幅超越所有现有系统。&lt;/p&gt;
&lt;h2&gt;&lt;strong&gt;4.3&lt;span class=&quot;Apple-converted-space&quot;&gt; 命名实体识别（Named Entity Recognition）&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;　　为了评估词块标记任务的性能，我们在CoNLL 2003&lt;strong&gt;命名实体识别&lt;/strong&gt;&lt;strong&gt;(NER)&lt;/strong&gt;数据集上微调BERT。该数据集由&lt;strong&gt;200k&lt;/strong&gt;&lt;strong&gt;个训练单词&lt;/strong&gt;组成，这些单词已注释为&lt;span&gt;人员、组织、位置、杂项或其他&lt;/span&gt;(非命名实体)。&lt;/p&gt;
&lt;p&gt;　　为做微调，我们将最终隐藏表征Ti∈R&lt;sup&gt;H&lt;/sup&gt;提供给每个&lt;strong&gt;词块&lt;/strong&gt;&lt;strong&gt;i&lt;/strong&gt;到NER标签集上的分类层。此预测不以周围预测为条件(即，非自回归和无CRF)。为了使其与WordPiece词块化相兼容，我们将每个&lt;strong&gt;CoNLL&lt;/strong&gt;&lt;strong&gt;词块化输入单词&lt;/strong&gt;提供给我们的WordPiece词块化器，并使用与第一个子标记相对应的隐藏状态作为分类器的输入。例如：&lt;/p&gt;
&lt;blockquote readability=&quot;7&quot;&gt;
&lt;p&gt;&lt;span&gt;&lt;em&gt;Jim　　Hen　　##&lt;/em&gt;&lt;em&gt;son　　was　　a　　puppet　　##eer&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;em&gt;I-PER　　I-PER　　X　　O　　O　　O　　X&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;　　在没有对X做预测的情况下。由于&lt;strong&gt;WordPiece&lt;/strong&gt;&lt;strong&gt;词块化边界&lt;/strong&gt;是一个该输入的已知部分，因此对训练和测试都做了预测。图3(d)中还给出了可视化呈现。一种事例WordPiece模型用于NER，而非事例模型用于所有其他任务。&lt;/p&gt;
&lt;p&gt;　　结果呈现在表3中。BERT&lt;sub&gt;LARGE&lt;/sub&gt;优于现有SOTA——具有多任务学习(Clark等，2018)的跨视图训练，在CoNLL-2003NER测试中达+0.2。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1192699/201812/1192699-20181214175151318-519298288.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;img_loading&quot; src=&quot;data:image/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVQImWNgYGBgAAAABQABh6FO1AAAAABJRU5ErkJggg==&quot; alt=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.42575558475689884&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/UEhXjOtUwhSeXKtKF1s0jj1BeguGYXjibaZmU6kqhPrSydPkahsKS5kA59Pt2YhlAjK30Rvjoticr3O1iaYMTodjw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;761&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;em&gt;表3：CoNLL-2003命名实体识别结果。超参数通过开发集来选择，得出的开发和测试分数是使用这些超参数进行五次随机重启的平均值。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h2&gt;&lt;strong&gt;4.4&lt;span class=&quot;Apple-converted-space&quot;&gt; 对抗生成情境数据集（SWAG）&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;　　此对抗生成情境(SWAG)数据集包含113k个句子对的完成样例，用于评估&lt;strong&gt;基础常识推理&lt;/strong&gt;&lt;span&gt;(Zellers等，2018)&lt;/span&gt;。&lt;/p&gt;
&lt;p&gt;　　给定一个视频字幕数据集中的某一个句子，任务是在四个选项中决定最合理的后续。例如：&lt;/p&gt;
&lt;blockquote readability=&quot;13&quot;&gt;
&lt;p&gt;&lt;span&gt;&lt;em&gt;一个女孩正穿过一套猴架杆。她&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;em&gt;(i) &lt;/em&gt;&lt;em&gt;跳过猴架杆。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;em&gt;(ii) &lt;/em&gt;&lt;em&gt;挣扎到架杆抓住她的头。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;em&gt;(iii) &lt;/em&gt;&lt;em&gt;走到尽头，站在木板上。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;em&gt;(iv) &lt;/em&gt;&lt;em&gt;跳起并做后退。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;em&gt;(译注：monkey bars n.猴架，供孩子们攀爬玩耍的架子)&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;　　调到SWAG数据集的BERT，类似于其GLUE适配。对于每个样本，我们构造四个输入序列，每个输入序列包含给定句子(句子A)和可能后续(句子B)的串联。我们引入的唯一任务特定参数是一个矢量V∈R&lt;sup&gt;H&lt;/sup&gt;，其具有最终聚合表征Ci∈R&lt;sup&gt;H&lt;/sup&gt;的&lt;strong&gt;点积&lt;/strong&gt;代表每个选择i的&lt;strong&gt;得分&lt;/strong&gt;。概率分布是四种选择的softmax：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1192699/201812/1192699-20181220115058877-1203308287.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　我们用学习率2e-5批量大小16，对此模型做了3个周期的微调。结果呈现在表4。BERT&lt;sub&gt;LARGE&lt;/sub&gt;的性能优于该作者ESIM+ELMo系统的基线达+27.1％。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1192699/201812/1192699-20181220115151741-396249415.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;em&gt;表4：SWAG开发和测试精度。测试结果由SWAG作者们对其隐藏标签进行评分。如SWAG论文所述，人类性能是用100个样本测量的。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;　　虽然我们已经演示了极其强大的实验结果，但到目前为止所呈现的结果并未分离BERT框架各个方面的具体贡献。在本节中，我们将对BERT多个方面进行消模实验，以便更好地了解它们的相对重要性。&lt;span&gt;(译注：Quora上对ablation study的解释：An ablation study typicallyrefers to removing some “feature” of the model or algorithm, and seeing howthat affects performance.&lt;span class=&quot;Apple-converted-space&quot;&gt; 消模实验通常是指删除模型或算法的某些“特征”，并查看如何影响性能。ablation study是为研究模型中提出的一些结构是否有效而设计的实验。比如你提出了某结构，但要想确定这个结构是否有利于最终效果，就要将去掉该结构的模型与加上该结构的模型所得到的结果进行对比。ablation study直译为“消融研究”，意译是“模型简化测试”或“消模实验”。)&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h2&gt;&lt;strong&gt;5.1&lt;span class=&quot;Apple-converted-space&quot;&gt; 预训练任务的影响&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;　　我们的核心主张之一是BERT的深度双向性，这是通过遮蔽LM预训练实现的，是BERT与以前工作相比最重要的改进。为证明这一主张，我们评估了两个使用完全相同预训练数据、微调方案和变换器超参数的BERT&lt;sub&gt;BASE&lt;/sub&gt;新模型：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;&lt;strong&gt;无&lt;/strong&gt;&lt;strong&gt;NSP&lt;/strong&gt;：一种使用“遮蔽LM”(MLM)训练但没有“下一句预测”(NSP)任务的模型。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;LTR&lt;/strong&gt;&lt;strong&gt;＆&lt;/strong&gt;&lt;strong&gt;NoNSP&lt;/strong&gt;：使用从左到右(LTR)LM而不是MLM训练的模型。在这种情况下，我们预测每个输入单词，不应用任何遮蔽。&lt;strong&gt;左侧约束&lt;/strong&gt;也用于微调，因为我们发现使用左侧语境预训练和双向语境微调，效果总是更差。此外，该模型在没有NSP任务的情况下做了预训练。这与OpenAIGPT直接相当，但使用我们更大的训练数据集、我们的输入表征和我们的微调方案。&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;　　结果显示在表5中。我们首先检查NSP任务带来的影响。我们可以看到，删除NSP会严重损害QNLI，MNLI和SQuAD的性能。这些结果表明，我们的预训练方法对于获得先前提出的强有力的实证结果至关重要。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1192699/201812/1192699-20181220115652731-1683199029.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;em&gt;表5：用BERT&lt;sub&gt;BASE&lt;/sub&gt;架构做的预训练任务消融。“无NSP”是无下一句话预测任务的训练。“LTR＆无NSP”用作从左到右的LM，没有下一个句子预测，如OpenAI GPT的训练。“+ BiLSTM”在微调期间在“LTR +无NSP”模型上添加随机初始化BiLSTM。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;　　接下来，我们通过比较“No NSP”与“LTR＆No NSP”来评估训练&lt;strong&gt;双向表征&lt;/strong&gt;的影响。LTR模型在所有任务上的性能都比MLM模型差，在MRPC和SQuAD上有极大下降。对于SQuAD，直观清楚的是LTR模型在跨度和词块预测方面性能非常差，因为其词块级隐藏状态没有&lt;strong&gt;右侧语境&lt;/strong&gt;。对于MRPC，目前尚不清楚性能不佳是由于其小数据量还是该任务本质，但我们发现这种不良性能在有很多随机重启的&lt;strong&gt;完整超参数扫描&lt;/strong&gt;&lt;span&gt;(full hyperparameter sweep)&lt;/span&gt;中是一致的。&lt;/p&gt;
&lt;p&gt;　　为了诚心尝试加强该LTR系统，我们试着在其上面添加一个随机初始化BiLSTM做微调。这确实显着提升了SQuAD结果，但结果仍比预训练双向模型差得多。它还影响所有四个GLUE任务的性能。&lt;/p&gt;
&lt;p&gt;　　我们认识到，也可以训练独立的LTR和RTL模型，并将每个词块表示为这两个模型的串联，如ELMo所做的那样。但是：(a) 这是单一双向模型的两倍代价；(b) 对于像QA这样的任务来说，这是不直观的，因为RTL模型无法对其问题的答案作出规定；(c) 它的强度远低于深度双向模型，因为深度双向模型可以选择使用左或右语境。&lt;/p&gt;
&lt;h2&gt;&lt;strong&gt;5.2&lt;span class=&quot;Apple-converted-space&quot;&gt; 模型大小的影响&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;　　在本节，我们将探讨&lt;strong&gt;模型大小&lt;/strong&gt;对微调任务准确性的影响。我们训练了许多具有不同层数、隐藏单元和注意头的BERT模型，与此同时，使用与前面描述的相同的超参数和训练过程。&lt;/p&gt;
&lt;p&gt;　　选定GLUE任务的结果如表6所示。此表中，我们报告了5次随机重启微调的平均DevSet开发集精度。我们可以看到，较大的模型导致所有四个数据集的严格精度提高，即使对于仅有3,600个标记训练样例的MRPC，并且与预训练任务有很大不同。同样令人惊讶的是，我们能够在相对于现有文献已经相当大的模型之上实现这种显著改进。例如，Vaswani等人&lt;span&gt;(2017)&lt;/span&gt;探索的其最大变换器，是&lt;span&gt;(L=6，H=1024，A=16)&lt;/span&gt;有100M参数的编码器，我们在文献中找到的最大变换器是&lt;span&gt;(L=64，H=512，A=2)&lt;/span&gt;有235M参数&lt;span&gt;(Al-Rfou等，2018)&lt;/span&gt;。相比之下，BERT&lt;sub&gt;BASE&lt;/sub&gt;包含110M参数，BERT&lt;sub&gt;LARGE&lt;/sub&gt;包含340M参数。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1192699/201812/1192699-20181220120029161-1444790981.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;em&gt;表6：BERT模型大小的消融。#L=层数; #H=隐藏的大小; #A=关注头数。“LM(ppl)”是保持训练数据的遮蔽LM混乱。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;　　众所周知，增加模型尺寸将导致&lt;strong&gt;机器翻译&lt;/strong&gt;和&lt;strong&gt;语言建模&lt;/strong&gt;等大型任务的持续改进，这可通过表6中所示该LM训练数据的复杂性来证明。但是，我们相信这是第一个证明扩展到极端模型尺寸的工作也可以在非常小规模的任务上实现大幅改进，前提是该模型已经过充分预训练。&lt;/p&gt;
&lt;h2&gt;&lt;strong&gt;5.3&lt;span class=&quot;Apple-converted-space&quot;&gt; 训练步数的影响&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;　　图4呈现了从已&lt;strong&gt;预训练&lt;/strong&gt;&lt;strong&gt;k&lt;/strong&gt;&lt;strong&gt;步的检查点&lt;/strong&gt;进行微调后的MNLI Dev精度。这使我们可以回答以下问题：&lt;/p&gt;
&lt;blockquote readability=&quot;18&quot;&gt;
&lt;p&gt;1. 问题：BERT是否真的需要如此大量预训练(128,000字/批*1,000,000步)才能实现高微调精度？&lt;/p&gt;
&lt;p&gt;　　答：是的，当训练1M步时，BERT&lt;sub&gt;BASE&lt;/sub&gt;在MNLI上实现了近1.0％的额外准确度，而步数为500k。&lt;/p&gt;
&lt;p&gt;2. 问题：MLM预训练是否比LTR预训练收敛慢，因为每批只有15％的单词被预测而不是每个单词？&lt;/p&gt;
&lt;p&gt;　　答：MLM模型的收敛速度略慢于LTR模型。然而，就绝对精度而言，MLM模型几乎立即开始优于LTR模型。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1192699/201812/1192699-20181220120357985-401489932.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;em&gt;图4：多次训练步骤的消融。这显示了微调后的MNLI精度，从已经预训练了k步的模型参数开始。x轴是k的值。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h2&gt;&lt;strong&gt;5.4&lt;span class=&quot;Apple-converted-space&quot;&gt; 基于特征的BERT方法&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;　　到目前为止呈现的所有&lt;strong&gt;BERT&lt;/strong&gt;&lt;strong&gt;结果&lt;/strong&gt;都使用了微调方法，其中将一个简单分类层添加到预训练模型，并且所有参数在下游任务上联合微调。然而，基于特征的方法具有某些优点，其固定特征从预训练模型中提取。首先，并非所有&lt;strong&gt;NLP&lt;/strong&gt;&lt;strong&gt;任务&lt;/strong&gt;都可以通过&lt;span&gt;&lt;strong&gt;变换器编码器架构&lt;/strong&gt;&lt;/span&gt;轻松表示，因此需要添加&lt;strong&gt;特定于任务的模型架构&lt;/strong&gt;。其次，主要计算益处在于能够一旦预计算其训练数据的一个高开销表征，就在该表征顶部使用较少开销模型运行多次实验。&lt;/p&gt;
&lt;p&gt;　　在本节中，我们通过在CoNLL-2003 NER任务上生成类似ELMo预训练的&lt;strong&gt;语境表征&lt;/strong&gt;，来评估基于特征的方法中BERT性能如何。为此，我们用4.3节相同的&lt;strong&gt;输入表征&lt;/strong&gt;，但用其来自一层或多层的激活，而不微调任何BERT参数。这些&lt;strong&gt;语境嵌入&lt;/strong&gt;用作分类层之前随机初始化的双层768维BiLSTM作为&lt;strong&gt;输入&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;结果显示在表7中。性能最佳的方法是连接来自预训练变换器其顶部四个隐藏层的&lt;strong&gt;词块表征&lt;/strong&gt;，微调此整个模型后仅为0.3 F1。这表明BERT对于微调和基于特征的方法都是有效的。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1192699/201812/1192699-20181220120835989-514484635.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;em&gt;表7：用BERT和CoNLL-2003 NER基于特征的方法消模。将来自此指定层的激活做组合，并馈送到双层BiLSTM中，而不向BERT反向传播。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;　　近期实验改进表明，使用&lt;span&gt;&lt;strong&gt;迁移学习语言模型&lt;/strong&gt;&lt;/span&gt;展示出的丰富、无监督预训练，是许多&lt;strong&gt;语言理解系统&lt;/strong&gt;的集成部分。特别是，这些结果使得即使低资源任务，也能从&lt;strong&gt;很深的单向架构&lt;/strong&gt;中受益。我们的主要贡献是将这些发现进一步推广到&lt;span&gt;&lt;strong&gt;深度双向架构&lt;/strong&gt;&lt;/span&gt;，允许其相同的预训练模型去成功解决一系列广泛的NLP任务。&lt;/p&gt;
&lt;p&gt;　　虽然实验结果很强，在某些情况下超过&lt;strong&gt;人类性能&lt;/strong&gt;，但重要的&lt;strong&gt;未来工作&lt;/strong&gt;是研究BERT能不能捕获其语言现象。&lt;/p&gt;

</description>
<pubDate>Thu, 20 Dec 2018 06:47:00 +0000</pubDate>
<dc:creator>郭耀华</dc:creator>
<og:description>BERT：Pre-training of Deep Bidirectional Transformers for Language Understanding 谷歌AI语言组论文《BERT：语言理解的</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/guoyaohua/p/bert.html</dc:identifier>
</item>
<item>
<title>用 python 抓取知乎指定回答下的视频 - leetao94</title>
<link>http://www.cnblogs.com/leetao94/p/10149303.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/leetao94/p/10149303.html</guid>
<description>&lt;p&gt;现在知乎允许上传视频，奈何不能下载视频，好气哦，无奈之下研究一下了，然后撸了代码，方便下载视频保存。&lt;/p&gt;
&lt;p&gt;接下来以 &lt;a href=&quot;https://www.zhihu.com/question/268021660/answer/520507373&quot;&gt;猫为什么一点也不怕蛇？&lt;/a&gt; 回答为例，分享一下整个下载过程。&lt;/p&gt;

&lt;p&gt;打开 F12, 找到光标，如下图：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://ww1.sinaimg.cn/large/006wYWbGly1fwy64j8p3mj31o215nagi.jpg&quot;/&gt;&lt;/p&gt;
&lt;p&gt;然后将光标移动到视频上。如下图：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://ww1.sinaimg.cn/large/006wYWbGly1fwy65i2f89j31iy0x5nar.jpg&quot;/&gt;&lt;/p&gt;
&lt;p&gt;咦这是什么？视野中出现了一条神秘的链接: &lt;code&gt;&lt;a href=&quot;https://www.zhihu.com/video/xxxxx&quot; class=&quot;uri&quot;&gt;https://www.zhihu.com/video/xxxxx&lt;/a&gt;&lt;/code&gt;，让我们将这条链接复制到浏览器上，然后打开：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://ww1.sinaimg.cn/large/006wYWbGly1fwy699p9hvj31050v0k15.jpg&quot;/&gt;&lt;/p&gt;
&lt;p&gt;似乎这就是我们要找的视频，不要着急，让我们看一看，网页的请求，然后你会发现一个很有意思的请求(重点来了):&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://ww1.sinaimg.cn/large/006wYWbGly1fwy6bnesp3j322j0g9din.jpg&quot;/&gt;&lt;/p&gt;
&lt;p&gt;让我们自己看一下数据吧:&lt;/p&gt;
&lt;pre class=&quot;json&quot;&gt;
&lt;code&gt;{
    &quot;playlist&quot;: {
        &quot;ld&quot;: {
            &quot;width&quot;: 360,
            &quot;format&quot;: &quot;mp4&quot;,
            &quot;play_url&quot;: &quot;https://vdn.vzuu.com/LD/05fc411e-d8e0-11e8-bb8b-0242ac112a0b.mp4?auth_key=1541477643-0-0-987c2c504d14ab1165ce2ed47759d927&amp;amp;expiration=1541477643&amp;amp;disable_local_cache=1&quot;,
            &quot;duration&quot;: 17,
            &quot;size&quot;: 1123111,
            &quot;bitrate&quot;: 509,
            &quot;height&quot;: 640
        },
        &quot;hd&quot;: {
            &quot;width&quot;: 720,
            &quot;format&quot;: &quot;mp4&quot;,
            &quot;play_url&quot;: &quot;https://vdn.vzuu.com/HD/05fc411e-d8e0-11e8-bb8b-0242ac112a0b.mp4?auth_key=1541477643-0-0-8b8024a22a62f097ca31b8b06b7233a1&amp;amp;expiration=1541477643&amp;amp;disable_local_cache=1&quot;,
            &quot;duration&quot;: 17,
            &quot;size&quot;: 4354364,
            &quot;bitrate&quot;: 1974,
            &quot;height&quot;: 1280
        },
        &quot;sd&quot;: {
            &quot;width&quot;: 480,
            &quot;format&quot;: &quot;mp4&quot;,
            &quot;play_url&quot;: &quot;https://vdn.vzuu.com/SD/05fc411e-d8e0-11e8-bb8b-0242ac112a0b.mp4?auth_key=1541477643-0-0-5948c2562d817218c9a9fc41abad1df8&amp;amp;expiration=1541477643&amp;amp;disable_local_cache=1&quot;,
            &quot;duration&quot;: 17,
            &quot;size&quot;: 1920976,
            &quot;bitrate&quot;: 871,
            &quot;height&quot;: 848
        }
    },
    &quot;title&quot;: &quot;&quot;,
    &quot;duration&quot;: 17,
    &quot;cover_info&quot;: {
        &quot;width&quot;: 720,
        &quot;thumbnail&quot;: &quot;https://pic2.zhimg.com/80/v2-97b9435a0c32d01c7c931bd00120327d_b.jpg&quot;,
        &quot;height&quot;: 1280
    },
    &quot;type&quot;: &quot;video&quot;,
    &quot;id&quot;: &quot;1039146361396174848&quot;,
    &quot;misc_info&quot;: {}
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;没错了，我们要下载的视频就在这里面，其中 ld 代表普清,sd 代表标清, hd 代表高清，把相应链接再次在浏览器打开，然后右键保存就可以下载视频了。&lt;/p&gt;

&lt;p&gt;知道整个流程是什么样子，接下来撸代码的过程就简单了，这里就不过再做过多解释了，直接上代码:&lt;/p&gt;
&lt;pre class=&quot;python&quot;&gt;
&lt;code&gt;# -*- encoding: utf-8 -*-

import re
import requests
import uuid
import datetime


class DownloadVideo:

    __slots__ = [
        'url', 'video_name', 'url_format', 'download_url', 'video_number',
        'video_api', 'clarity_list', 'clarity'
    ]

    def __init__(self, url, clarity='ld', video_name=None):
        self.url = url
        self.video_name = video_name
        self.url_format = &quot;https://www.zhihu.com/question/\d+/answer/\d+&quot;
        self.clarity = clarity
        self.clarity_list = ['ld', 'sd', 'hd']
        self.video_api = 'https://lens.zhihu.com/api/videos'

    def check_url_format(self):
        pattern = re.compile(self.url_format)
        matches = re.match(pattern, self.url)
        if matches is None:
            raise ValueError(
                &quot;链接格式应符合:https://www.zhihu.com/question/{number}/answer/{number}&quot;
            )
        return True

    def get_video_number(self):
        try:
            headers = {
                'User-Agent':
                'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/66.0.3359.181 Safari/537.36'
            }
            response = requests.get(self.url, headers=headers)
            response.encoding = 'utf-8'
            html = response.text
            video_ids = re.findall(r'data-lens-id=&quot;(\d+)&quot;', html)
            if video_ids:
                video_id_list = list(set([video_id for video_id in video_ids]))
                self.video_number = video_id_list[0]
                return self
            raise ValueError(&quot;获取视频编号异常:{}&quot;.format(self.url))
        except Exception as e:
            raise Exception(e)

    def get_video_url_by_number(self):
        url = &quot;{}/{}&quot;.format(self.video_api, self.video_number)

        headers = {}
        headers['Referer'] = 'https://v.vzuu.com/video/{}'.format(
            self.video_number)
        headers['Origin'] = 'https://v.vzuu.com'
        headers[
            'User-Agent'] = 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.67 Safari/537.36'
        headers['Content-Type'] = 'application/json'

        try:
            response = requests.get(url, headers=headers)
            response_dict = response.json()
            if self.clarity in response_dict['playlist']:
                self.download_url = response_dict['playlist'][
                    self.clarity]['play_url']
            else:
                for clarity in self.clarity_list:
                    if clarity in response_dict['playlist']:
                        self.download_url = response_dict['playlist'][
                            self.clarity]['play_url']
                        break
            return self
        except Exception as e:
            raise Exception(e)

    def get_video_by_video_url(self):
        response = requests.get(self.download_url)
        datetime_str = datetime.datetime.now().strftime(&quot;%Y-%m-%d %H-%M-%S&quot;)
        if self.video_name is not None:
            video_name = &quot;{}-{}.mp4&quot;.format(self.video_name, datetime_str)
        else:
            video_name = &quot;{}-{}.mp4&quot;.format(str(uuid.uuid1()), datetime_str)
        path = &quot;{}&quot;.format(video_name)
        with open(path, 'wb') as f:
            f.write(response.content)

    def download_video(self):

        if self.clarity not in self.clarity_list:
            raise ValueError(&quot;清晰度参数异常,仅支持:ld(普清),sd(标清),hd(高清)&quot;)

        if self.check_url_format():
            return self.get_video_number().get_video_url_by_number().get_video_by_video_url()


if __name__ == '__main__':
    a = DownloadVideo('https://www.zhihu.com/question/53031925/answer/524158069')
    print(a.download_video())&lt;/code&gt;
&lt;/pre&gt;

&lt;p&gt;代码还有优化空间，这里面我只是下载了回答中的第一个视频，理论上应该存在一个回答下可以有多个视频的。如果还有什么疑问或者建议，可以多多交流。&lt;/p&gt;
</description>
<pubDate>Thu, 20 Dec 2018 06:47:00 +0000</pubDate>
<dc:creator>leetao94</dc:creator>
<og:description>前言 现在知乎允许上传视频，奈何不能下载视频，好气哦，无奈之下研究一下了，然后撸了代码，方便下载视频保存。 接下来以</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/leetao94/p/10149303.html</dc:identifier>
</item>
<item>
<title>从SQL Server CloudDBA 看云数据库智能化 - 阿里云云栖社区</title>
<link>http://www.cnblogs.com/yunqishequ/p/10149256.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/yunqishequ/p/10149256.html</guid>
<description>&lt;p&gt;最近阿里云数据库SQL Server在控制台推出了CloudDBA服务，重点解决数据库性能优化领域问题，帮助客户更好的使用好RDS数据库，这是继MySQL之后第二个关系型数据库提供类似的服务。&lt;/p&gt;

&lt;p&gt;数据库可认为是系统运行的关键，因为它存储数据，确保事务一致性，是企业的核心资产。一般大型企业都有专职的数据库管理员（DBA）来负责数据库的日常运维管理，这些管理工作的好坏其实非常依赖于DBA的经验。一个好的DBA，至少要负责如下几个方面的工作：&lt;/p&gt;
&lt;p&gt;1. 基础运维管理工作：包括安装、卸载、升级、打patch、基础联通配置等方面的工作。&lt;/p&gt;
&lt;p&gt;2. 安全管理工作：防火墙、连接管理、密码管理、权限管理等。要特别说明下，千万不要小看安全管理工作，如密码管理，看似是个简单的问题，但是实际中有很多DBA设置数据库的密码是非常简单的数字，这样基本上黑客就可以利用撞库的方式获取到你的密码。同样地很多程序为了图方便、甚至包括DBA，都直接拿sa账号作为业务账号使用，这可谓完全没有安全意识，尤其是SQL Server数据库，个人认为这样的DBA是应该要被开除的。&lt;/p&gt;
&lt;p&gt;3. 稳定性管理工作：如搭建高可用环境并且定期演练，备份和恢复其实既属于安全也属于稳定性相关工作，并不代表备份的结果肯定能恢复出来的，恢复过程的时效如何都是需要反复演练的，所以一个好的DBA会让公司业务行云流水，没有异常、或者异常期间处理有节有奏是一个DBA优秀素质的体现。&lt;/p&gt;
&lt;p&gt;4. 性能优化管理工作：这是一个非常大的课题，涵盖了DBA理解数据库的方方面面，也是DBA综合素质的直接体现，不同的DBA在这块的处理结果会给业务带来直接不同的效果，因此性能优化话题永远是DBA圈的热门话题，各种语句写法、各种索引使用技巧、各种信息分析排查充分体现了经验的丰富度。这块内容重要性的直接体现，就是对数据库使用效能，做的好可以为公司节省一大笔钱。之前本人在公司作为DBA服务的时候，衡量是否称职的标准，是否对数据库每日三餐，即在早上、下午下班前、夜里高峰时，查看下数据库的性能包括，并且给出诊断意见，这件事情不做，基本上算是在偷懒了。&lt;/p&gt;
&lt;p&gt;5. 数据管理和业务逻辑处理工作：这是一块繁重的工作，DBA除了支持日常业务研发的表、数据等变更需求外，有些场景还需要DBA编写存储过程、数据库函数等来完成，这里的DBA其实是半个开发了。&lt;/p&gt;

&lt;p&gt;在云时代，阿里云提供的关系型数据库服务（RDS）解放了大量繁重的DBA日常工作，包括基础运维管理的琐事、稳定性管理、安全管理等多个方面都有涉及，同时云上数据库数据管理工具DMS提供了可视化的数据管理界面，方便DBA日常数据管理，大大提升了性能。但是云数据和传统自建机房的自建数据库是一样的，它们一直都是在运行的，它们在运行过程中会遇到很多问题的，我暂且统称为“运行态管理工作”，主要包含的就是性能优化相关的管理工作，而也是基于此考虑在2017年阿里云数据库推出了CloudDBA服务，首先服务于MySQL引擎。一年以后，SQL Server 版 CloudDBA正式发布，标志着阿里云数据库已经开始多引擎内置“运行态管理”功能，重点是性能优化、当然也会涉及到监控管理、安全管理等和运行有关的部分。&lt;/p&gt;

&lt;p&gt;为了表述方便，我将以SQL Server CloudDBA作为蓝本来阐述阿里云数据库CloudDBA产品思路和它集中要解决的问题是什么。&lt;/p&gt;
&lt;p&gt;CloudDBA设计之初就是希望能够帮助客户更好的用好云数据库，因为阿里云有数十万数据库实例，几乎遇到所有的客户使用场景，大量的案例沉淀，以及阿里云数据库专家积年累月的大量经验，我们希望将这些内容能够通过系统的方式智能的赋能给客户，因此CloudDBA首先是智能化的，或者流行的说法是AI的。其次，我们希望能够站在用户面来看待解决问题的方式，也就是以此从看问题、解决问题、智能修复问题三个角度来帮助客户。看问题的目标就是要将数据库的相关信息全部展现给用户，并且要努力做到一眼就能发现问题；解决问题的做法是将阿里云数据库专家处理这类问题的方法建议，形成脚本提供给用户，用户根据建议脚本去数据库执行就能解决问题；至于智能修复问题，是CloudDBA的终极服务状态，系统会智能识别问题点，然后自动启动内部免疫系统直接去修复此类问题，举个例子针对异常高峰和客户的设置，直接在代理层控制异常SQL的流量来自动保护数据库。因此CloudDBA是个体系化的系统，它不仅仅是数据库里面hack一个小组件，下图就是CloudDBA的基础组件描述图。&lt;/p&gt;

&lt;div&gt;&lt;img src=&quot;https://yqfile.alicdn.com/35e985541099aa8bc7054140191f9c2356e511c9.png&quot; alt=&quot;35e985541099aa8bc7054140191f9c2356e511c9&quot; width=&quot;500&quot; height=&quot;372&quot;/&gt;&lt;/div&gt;

&lt;p&gt;CloudDBA底层依赖于阿里云采集的大量数据库运行态数据，涵盖数据库引擎的运行数据，业务SQL语句，OS运行数据，主机数据和从应用到数据库的全链路数据，然后整合数据，以不同的引擎为业务场景服务。特别要介绍的就是规则引擎，这里面沉淀了阿里云数十万的运行案例，它是不断完善和进化，数据会不停的补充进去。另外，智能化的自治系统是CloudDBA对外服务的终极状态，它会在背后默默为客户修复数据库的问题，甚至在问题未发生时候就完成修复。&lt;/p&gt;

&lt;p&gt;具体解决哪些实际的问题？如果是一位资深DBA可能会依据自己的经验列出一二三，一个新DBA的话可能就无法准确回答了。而我们做产品优先去解决客户哪些问题，是依据于多年数据而来的，在我们对外服务中，由于云数据库已经很好的解决了数据库基础运维工作，数据库运行中CPU使用率过高、IOPS过高、查询语句性能底下（返回很慢）、应用超时卡顿、空间异常等占云数据库运行问题95%。SQL Server CloudDBA本版本优先解决此类问题，你可以很轻松的：&lt;/p&gt;
&lt;p&gt;1. 依层次管理和查看空间问题，从实例到数据库到表甚至到索引，帮助有效规划空间，除了能够及时解决问题外，有效的利用空间也能够降低成本。&lt;/p&gt;
&lt;p&gt;2. 性能的杀手和利器都是索引，为此我们专门对缺失索引、索引利用率、索引碎片等设置了专门模块，用户可以轻松的发现缺失哪些索引，哪些索引利用率不高综合考虑可以删除，哪些索引碎片太多影响性能，正常情况采取SQL Server CloudDBA的建议，性能会带来急速提升。&lt;/p&gt;
&lt;p&gt;3. 统计信息：统计信息的好坏，直接关系到底层引擎选择执行 SQL 语句的最佳路径，根据建议及时更新优化统计信息，可始终保障数据库处于最优状态，未来这块功能会优先走向自治，彻底解除人工干预的烦恼。&lt;/p&gt;
&lt;p&gt;4. SQL 语句：包含了当前实例的SQL语句运行情况，以及历史SQL语句的运行情况，历史SQL语句来自SQL审计日志，记录的信息更全面。SQL语句从多个维度将TOP SQL展示给用户，如包括CPU开销、执行时间、返回行、逻辑读、物理读、逻辑写等。以此根据建议优化SQL语句，就能很好的提高性能。&lt;/p&gt;

&lt;p&gt;深入解读下CloudDBA的输出展示，从客户资源使用视角展示优化项（如空间管理、SQL语句），每个优化项页面，头部是概览信息方便用户急速判断是否有问题是否需要优化、中间是形象化的图信息从比较宏观的角度展示本优化项的各方面信息，最后一部分则包含一个更细粒度的表格，具体的详情都在表格中列出来，如空间管理中列出具体数据的空间使用情况，用户点击进去还能看到具体数据文件的空间使用情况，而且针对每项目都提供对应的解决方案，如缺失索引中直接给出要创建索引的SQL语句，用户只需要在维护时间段执行对应的语句就可以完成优化。未来会引入命令执行系统，用户只要同意执行，后台就会自动按指令运行，大大简化操作流程。&lt;/p&gt;
&lt;p&gt;另外，在SQL Server CloudDBA中引入了一个贴心功能，保存成pdf，可以迅速将本优化项目页保存成一份pdf文件，方便传阅分享。&lt;/p&gt;

&lt;p&gt;SQL Server CloudDBA以用户视角，提供专家级建议方案，以帮助用户最优的使用好云数据，这是产品的源动力。&lt;/p&gt;

&lt;p&gt;&lt;br/&gt;&lt;a href=&quot;https://yq.aliyun.com/articles/680057?utm_content=g_1000032340&quot; target=&quot;_blank&quot;&gt;原文链接&lt;/a&gt;&lt;br/&gt;本文为云栖社区原创内容，未经允许不得转载。&lt;/p&gt;
</description>
<pubDate>Thu, 20 Dec 2018 06:41:00 +0000</pubDate>
<dc:creator>阿里云云栖社区</dc:creator>
<og:description>最近阿里云数据库SQL Server在控制台推出了CloudDBA服务，重点解决数据库性能优化领域问题，帮助客户更好的使用好RDS数据库，这是继MySQL之后第二个关系型数据库提供类似的服务。 数据库</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/yunqishequ/p/10149256.html</dc:identifier>
</item>
<item>
<title>selenium面试问题答案总结 - 长安。</title>
<link>http://www.cnblogs.com/pingan666/p/10149232.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/pingan666/p/10149232.html</guid>
<description>&lt;p&gt;1. 什么是Selenium？&lt;br/&gt;Selenium是一个开源的web自动化测试框架，主要是基于web uI的自动化测试。现在的版本，逐步增加了对移动端的自动化测试。Selenium支持多种语言进行开发自动化测试脚本，有Java,python，C#，Javascript等等。Selenium支持跨浏览器平台测试。&lt;/p&gt;
&lt;p&gt;2.Selenium是否支持桌面应用软件的自动化测试。&lt;br/&gt;Selenium不支持桌面软件的自动化测试，Selenium是根据网页元素的属性才定位元素，而其他桌面软件自动化测试工具是根据桌面元素的位置来定位元素，当然现在也有根据桌面元素的属性来定位的。&lt;/p&gt;
&lt;p&gt;3.Selenium是否支持用例的执行的引擎。&lt;br/&gt;引擎好比就是一个发动机。Selenium是没有关于测试用例和测试套件管理和执行的模块。我们需要借助第三方单元测试框架来实现用例管理和用例的执行。例如Java中有Junit或者testNG,Python中有unittest单元测试框架。&lt;/p&gt;
&lt;p&gt;4.Seleinum是否有读取excel文件的库&lt;br/&gt;没有，这里需要用到第三方工具。例如Apache POI插件。&lt;/p&gt;
&lt;p&gt;5.Selenium有哪些组件？&lt;br/&gt;最早的有Selenium IDE,IDE只支持安装在fiefox上一个插件，支持录制自动化脚本。还有&lt;br/&gt;remote RC,和Grid 和webdriver。我们一般最重要的就是使用webdriver。&lt;/p&gt;
&lt;p&gt;6.Selenium有什么限制或者缺陷&lt;br/&gt;       除了基于web的软件和mobile的程序，selenium不支持桌面软件自动化测试。软件测试报告，和用例管理只能&lt;br/&gt;依赖第三方插件，例如Junit/TestNG和unittest。由于它是免费的软件，所以没有供应商去提供支持和服务，有问题，只能求助selenium社区。还有一个就是，selenium入门门槛可能有点高，需要具备一定编程语言基础的才能玩转。&lt;/p&gt;
&lt;p&gt;7.在selenium中，有哪些不同定位元素方法&lt;br/&gt;ID/className/Name/LinkText/PartialLinkText/Xpath/CSS selector&lt;/p&gt;
&lt;p&gt;8.什么是imlicitlyWait&lt;br/&gt;imlicitlyWait是隐式等待，一般在查找元素的时候使用。例如，我设置一个查找元素最大时间为10秒，使用了&lt;br/&gt;imlicitlyWait后，如果第一次没有找到元素，会在10秒之内不断循环去找元素，知道超过10秒，报超时错误。&lt;/p&gt;
&lt;p&gt;9.什么是expliciteWait&lt;br/&gt;这个是显式等待，就是不管如何都是要等10秒，如果你设置了10秒超时，这个是selenium2的功能&lt;br/&gt;在selenium3中，我暂时没有找到这个接口。&lt;/p&gt;
&lt;p&gt;10.什么是线程等待&lt;br/&gt;有时候，我们需要强制设置线程等待，Thread.sleep(2000),driver这个实例，就是当前的线程。&lt;/p&gt;
&lt;p&gt;11.什么是pollingEvery&lt;br/&gt;这个是设置个一段时间就去做一件事，例如下面设置隔一秒就去查找元素一次。&lt;br/&gt; WebDriverWait wait = new WebDriverWait(driver,30);&lt;br/&gt; wait.pollingEvery(1, TimeUnit.SECONDS);&lt;br/&gt; driver.findElement(By.xpath(&quot;xxxx&quot;));&lt;/p&gt;
&lt;p&gt;12你能解释下Selenium这个框架吗？&lt;/p&gt;
&lt;p&gt;    这个问题在面试中被问到的概率还是比较高的，同样类似的问题有，selenium的原理是什么？首先不要被这个问题吓到，我们主要围绕selenium的历史版本演化和基本的组件去展开描述就好，最后回到webdriver这个组件上面，我们基本上都是在使用webdriver提供的API。所以这个题目的最好的答案就是把图画出来，然后自己解释几句就可以。 早期Selenium1.0是有Selenium Grid，Selenium RC, Selenium IDE, Webdriver四部分组成，后来Selenium RC和Webdriver合并之后，就是Selenium2,当前我们在使用Selenium3。&lt;/p&gt;
&lt;p&gt; Selenium Grid：它是selenium框架的一部分，主要是专门用来把测试用例并行地在不同浏览器，不同操作系统，不同机器上运行。一般我们写脚本，调试都在单机上线性地一个测试用例接着一个测试用例执行下去。如果有人问题如何提高测试用例执行效率，告诉他Selenium Grid可以实现。&lt;/p&gt;
&lt;p&gt; Selenium IDE: 这个算Selenium里面最简单的一个组建，只支持在火狐浏览器上安装这个扩展程序，支持录制web ui脚本，然后导出不同语言的脚本，例如java c#等。这个功能算鸡肋，因为很多时候导出脚本debug的时间还不如自己代码重新写来的快。&lt;/p&gt;
&lt;p&gt; Selenium RC: RC是remote control的缩写,主要的功能就是让你不管使用什么语言（Selenium支持的这几种语言之一）来写测试脚本，只要是这个浏览器支持java script，那么写一遍测试脚本，都能在这些不同浏览器运行脚本。&lt;/p&gt;
&lt;p&gt; Webdriver：这个是用来替代Selenium RC，就是一个网页自动化工具，支持在不同浏览器上运行测试脚本，运行速度比Selenium RC要快很多。据说（我也记得不清楚），webdriver最早是google内部开发的一个工具，用来捐给selenium了，变成开源了。&lt;/p&gt;
&lt;p&gt;    目前，我们做的web ui的自动化测试，大部分都是在使用webdriver提供的API来模拟手动测试过程中的一系列动作和行为。基本上通过这个方式来回答这个问题，那就没问题了。&lt;/p&gt;
&lt;p&gt; 13.你写的测试脚本能在不同浏览器上运行吗，支持跨浏览器平台吗&lt;/p&gt;
&lt;p&gt; 这里出现了跨浏览器平台的概念，就是写一个测试用例，可以在主流的几个浏览器跑起来。&lt;/p&gt;
&lt;p&gt;   是的，我写的测试用例能在IE，火狐和谷歌这三种浏览器上运行。主要是在windows平台上运行脚本，所以mac的safari浏览器暂时没有写过。主要实现这个跨浏览器的思想就是，把浏览器类型写到配置文件，代码里写if语句去判断配置文件的浏览器的类型，来决定用什么浏览器去执行测试用例。&lt;/p&gt;
&lt;p&gt;14.一天你写多少个自动化测试用例&lt;/p&gt;
&lt;p&gt;  这个要看具体情况，完全取决于手工测试用例的实现难易程度。通常，熟练的话，写一个5到8个步骤的测试用例，差不多要半小时。时间最多花在元素定位和报错debug上面，例如在POM思想的框架中，某一些元素定位和方法是复用的，可能会更快一些。所以，一天，大概能完成15-30个自动化测试用例。&lt;/p&gt;
&lt;p&gt; 15.什么是POM，为什么要使用它&lt;/p&gt;
&lt;p&gt;  POM是Page Object Model的简称，它是一种设计思想，而不是框架。大概的意思是，把一个一个页面，当做一个对象，页面的元素和元素之间操作方法就是页面对象的属性和行为，所以自然而然就用了类的思想来组织我们的页面。一般一个页面写一个类文件，这个类文件包含该页面的元素定位和业务操作方法。&lt;/p&gt;
&lt;p&gt; 为了我们测试用例写的简单，清晰，我们很多时候在页面对象会封装很多业务操作方法，测试脚本只需要调用相关方法就可以。&lt;/p&gt;
&lt;p&gt; 还有一个可能和这个问题相关的面试题，如果页面元素经常发生需求变化，你是如何做，答案就是采用POM思想。好处就是只要该一个页面，我就去修改这个页面对象的元素定位和相关方法，脚本不需要修改。&lt;/p&gt;
&lt;p&gt;16.在你做自动化过程中，遇到了什么问题吗？举例下&lt;/p&gt;
&lt;p&gt; 这个问题，不管是自动化还是任何工作，都会被问到。主要想知道你是如何解决问题的，从而推断你问题分析和解决的能力。&lt;/p&gt;
&lt;p&gt; 当然有遇到问题和挑战，主要有以下几点：&lt;/p&gt;
&lt;p&gt; 频繁地变更UI，经常要修改页面对象里面代码&lt;br/&gt; 运行用例报错和处理，例如元素不可见，元素找不到这样异常&lt;br/&gt; 测试脚本复用，尽可能多代码复用&lt;br/&gt; 一些新框架产生的页面元素定位问题，例如ck编辑器，动态表格等&lt;br/&gt;  这个遇到的难点完全取决写脚本人的代码能力。回答三个左右就差不多，记得既然抛出了难点问题，一定要记得处理这个问题的方法。&lt;/p&gt;
&lt;p&gt;17.举例一下你遇到过那些异常，在selenium自动化测试过程中&lt;/p&gt;
&lt;p&gt;通过这个问题，大概知道你写过多少脚本。写脚本过程最常见的异常就是，这个元素无法找到。常见的selenium有以下这些：&lt;/p&gt;
&lt;p&gt;1. ElementNotSelectableException ：元素不能选择异常&lt;br/&gt;2. ElementNotVisibleException ：元素不可见异常&lt;br/&gt;3. NoSuchAttributeException ：没有这样属性异常&lt;br/&gt;4. NoSuchElementException：没有该元素异常&lt;br/&gt;5. NoSuchFrameException ：没有该frame异常&lt;br/&gt;6. TimeoutException ： 超时异常&lt;br/&gt;7. Element not visible at this point  ：在当前点元素不可见&lt;/p&gt;
&lt;p&gt; 18. 如何处理alert弹窗&lt;/p&gt;
&lt;p&gt;我们常见的alert弹窗有两种：基于windows弹窗和基于web页面弹窗&lt;/p&gt;
&lt;p&gt;我们知道，webdriver是能够处理alert弹窗的，Selenium提供了Alert这个接口。相关操作代码如下：&lt;/p&gt;
&lt;p&gt; // 切换到Alert&lt;/p&gt;
&lt;p&gt;Alert alert = driver.switchTo().alert();&lt;/p&gt;
&lt;p&gt;// 点击弹窗上确定按钮&lt;/p&gt;
&lt;p&gt;alert.accept();&lt;/p&gt;
&lt;p&gt;// 点击弹窗的取消按钮&lt;br/&gt;alert.dismiss()&lt;/p&gt;
&lt;p&gt;// 获取弹窗上线上的文本文字内容&lt;br/&gt;alert.getText();&lt;/p&gt;
&lt;p&gt;// 有些弹窗还支持文本输入，这个可以把要输入字符通过sendkeys方法输入&lt;br/&gt;alert.sendkeys();&lt;/p&gt;
&lt;p&gt;19. 在selenium中如何处理多窗口？&lt;/p&gt;
&lt;p&gt;这个多窗口之间跳转处理，在实际selenium自动化测试经常遇到。就是，你点击一个链接，这个链接会在一个新的tab打开，然后你接下来要查找元素在新tab打开的页面，所以这里需要用到swithTo方法。&lt;/p&gt;
&lt;p&gt;需要获取当前浏览器多窗口句柄，然后根据判断跳转新句柄还是旧句柄，具体代码可以参考我博客文章：http://blog.csdn.net/u011541946/article/details/73611301&lt;/p&gt;
&lt;p&gt; 20. 你查找元素遇到过在Frame里面吗?你是如何处理Frame里面元素定位的？&lt;/p&gt;
&lt;p&gt;有时候我们知道元素定位表达式没有问题，但是还是提示no such element，那么我们就需要考虑这个元素是否在frame中。如果在，我们就需要从topwindow，通过swithcTo.Frame()方法来切换到目标frame中，可以通过frame的name和id和索引三种方法来定位frame。&lt;/p&gt;
&lt;p&gt; 21. 怎么验证勾选框是enable/disabled/ checked/Unchecked/ displayed/ not displayed？&lt;/p&gt;
&lt;p&gt; 通过以下方法来验证元素是enable 还是disable&lt;/p&gt;
&lt;p&gt;boolean enabled = driver.findElement(By.xpath(&quot;元素定位表达式&quot;)).isEnabled();&lt;/p&gt;
&lt;p&gt; 通过以下方法来验证元素是select/check&lt;/p&gt;
&lt;p&gt;boolean checked = driver.findElement(By.xpath(&quot;元素定位表达式&quot;)).isSelected();&lt;/p&gt;
&lt;p&gt; 通过以下方法来验证元素是dispalyed还是not display&lt;/p&gt;
&lt;p&gt;boolean displayed = driver.findElement(By.xpath(&quot;元素定位表达式&quot;)).isDisplayed();&lt;/p&gt;
&lt;p&gt;22. 如何处理下拉菜单？&lt;/p&gt;
&lt;p&gt;通常我们也可以通过Click方法来点击下拉菜单里面的元素，还有一种方法，在Selenium中有一个类叫Select，支持这种下拉菜单交互的操作。&lt;/p&gt;
&lt;p&gt;基本使用语法是这样的：&lt;/p&gt;
&lt;p&gt;Select Se=new Select(element);&lt;br/&gt;Se.selectByIndex(index);&lt;br/&gt;Se.selectByvalue(value);&lt;br/&gt;Se.selectByVisibleText(text);&lt;/p&gt;
&lt;p&gt; 23. 在日历这种web 表单你是如何处理的?&lt;/p&gt;
&lt;p&gt;首先要分析当前网页试用日历插件的前端代码，看看能不能通过元素定位，点击日期实现，如果不能，可能需要借助javascript。还有些日历控件一个文本输入框，可以直接sendKeys()方法来实现传入一个时间的数据。&lt;/p&gt;
&lt;p&gt; 24. 关闭浏览器中quit和close的区别&lt;/p&gt;
&lt;p&gt;简单来说，两个都可以实现退出浏览器session功能，close是关闭你当前聚焦的tab页面，而quit是关闭全部浏览器tab页面，并退出浏览器session。知道这两个区别，我们就知道quit一般用在结束测试之前的操作，close用在执行用例过程中关闭某一个页面的操作。&lt;br/&gt;25. 什么是页面加载超时&lt;/p&gt;
&lt;p&gt; Selenium中有一个 Page Load wait的方法，有时候，我们执行脚本的速度太快，但是网页程序还有一部分页面没有完全加载出来，就会遇到元素不可见或者元素找不到的异常。为了解决问题，让脚本流畅的运行，我们可以通过设置页面加载超时时间。具体代码是这个：driver.manage().timeouts().pageLoadTimeout(10,TimeUnit.SECONDS);&lt;/p&gt;
&lt;p&gt; 这行作用就是，如果页面加载超过10秒还没有完成，就抛出页面加载超时的异常。&lt;/p&gt;
&lt;p&gt; 26.什么是JavaScript Executor，你什么时候会用到这个？&lt;/p&gt;
&lt;p&gt; JavaScript Executor是一个接口，给driver对象提供一个执行javaScript并访问和修改前端元素属性和值。&lt;/p&gt;
&lt;p&gt; 还是有比较多的场景，我们可能或者需要借助javaScript来实现：&lt;/p&gt;
&lt;p&gt;1.元素通过现有定位表达式不能够实现点击&lt;/p&gt;
&lt;p&gt;2.前端页面试用了ck-editor这个插件&lt;/p&gt;
&lt;p&gt;3.处理时间日期插件（可能）&lt;/p&gt;
&lt;p&gt;4.生成一个alert弹窗&lt;/p&gt;
&lt;p&gt;5.拖拽滚动条&lt;/p&gt;
&lt;p&gt; 基本语法：&lt;/p&gt;
&lt;p&gt;JavascriptExecutor js =(JavascriptExecutor) driver;&lt;br/&gt;js.executeScript(Script,Arguments);&lt;/p&gt;
&lt;p&gt;27.在Selenium中如何实现截图，如何实现用例执行失败才截图&lt;/p&gt;
&lt;p&gt; 在Selenium中提供了一个TakeScreenShot这么一个接口，这个接口提供了一个getScreenshotAs（）方法可以实现全屏截图。然后我们通过java中的FileUtils来实现把这个截图拷贝到保存截图的路径。&lt;/p&gt;
&lt;p&gt; 代码举例：&lt;/p&gt;
&lt;p&gt;File src=((TakesScreenshot)driver).getScreenshotAs(OutputType.FILE);&lt;br/&gt;try {&lt;br/&gt;// 拷贝到我们实际保存图片的路径&lt;/p&gt;
&lt;p&gt;FileUtils.copyFile(src,new File(&quot;C:/selenium/error.png&quot;));&lt;br/&gt;}&lt;br/&gt;catch (IOException e)&lt;br/&gt;{&lt;br/&gt;System.out.println(e.getMessage());&lt;br/&gt;}&lt;/p&gt;
&lt;p&gt; 如果要实现执行用例发现失败就自动截图，那么我们需要把这个截图方法进行封装。然后在测试代码中的catch代码块去调用这个截图方法。这个我们在POM的框架中一般是把截图方法封装到BasePage这个文件中。&lt;/p&gt;
&lt;p&gt; 28.在Selenium中如何实现拖拽滚动条？&lt;/p&gt;
&lt;p&gt;  在Selenium中通过元素定位会自动帮你拖拽到对应位置，所以是没有自带的scoll方法。但是这个是有限制，例如当前页面高度太长，默认是页上半部分，你定位的元素在页尾，这个时候可能就会报元素不可见的异常。我们就需要利用javaScript来实现拖拽页面滚动条。&lt;/p&gt;
&lt;p&gt;我们一般可以两个方法去拖拽，一个是根据拖拽的坐标（像素单位），另外一个是根据拖拽到一个参考元素附件。&lt;/p&gt;
&lt;p&gt; 代码举例（根据元素坐标拖拽）：&lt;/p&gt;
&lt;p&gt;JavascriptExecutor jse= (JavascriptExecutor)driver;&lt;br/&gt;jse.executeScript(&quot;window.scrollBy(0,250)&quot;, &quot;&quot;);&lt;/p&gt;
&lt;p&gt; 29.如何实现文件上传？&lt;/p&gt;
&lt;p&gt; 我们在web页面实现文件上传过程中，可以直接把文件在磁盘完整路径，通过sendKeys方法实现上传。如果这种方法不能实现上传，我们就可能需要借助第三方工具，我用过一个第三方工具叫autoIT.&lt;/p&gt;
&lt;p&gt; 还有一个方法是利用robot类：&lt;/p&gt;
&lt;p&gt;http://blog.csdn.net/u011541946/article/details/74332938&lt;/p&gt;
&lt;p&gt; 30.如何处理“不受信任的证书”的问题？&lt;/p&gt;
&lt;p&gt; 例如，在登录12306网站的时候，如果你没有下载和安装过这个网站的根证书，那么你就会遇到打开12306网站提示证书不受信任的拦截页面。&lt;/p&gt;
&lt;p&gt; 下面举例火狐和谷歌上处理这个问题的基本代码&lt;/p&gt;
&lt;p&gt; 火狐：&lt;/p&gt;
&lt;p&gt;// 创建firefoxprofile&lt;br/&gt;FirefoxProfile profile=new FirefoxProfile();&lt;br/&gt;// 点击继续浏览不安全的网站&lt;br/&gt;profile.setAcceptUntrustedCertificates(true);&lt;br/&gt;// 使用带条件的profile去创建一个driver对象&lt;br/&gt;WebDriver driver=new FirefoxDriver(profile);&lt;/p&gt;
&lt;p&gt; Chrome：&lt;/p&gt;
&lt;p&gt;// 创建类DesiredCapabilities的对象&lt;br/&gt;DesiredCapabilities cap=DesiredCapabilities.chrome();&lt;br/&gt;// 设置ACCEPT_SSL_CERTS 变量值为true&lt;br/&gt;cap.setCapability(CapabilityType.ACCEPT_SSL_CERTS, true);&lt;br/&gt;// 新建一个带capability的chromedriver对象&lt;br/&gt;WebDriver driver=new ChromeDriver(cap);&lt;/p&gt;
&lt;p&gt;31.findElement 和 FindElements有什么区别？&lt;/p&gt;
&lt;p&gt; 首先，两个都是查找元素，都支持八大元素定位方法。findElement()得到的只有一个元素，如果根据提供的元素定位方式找不到，会报noSuchElement异常。&lt;/p&gt;
&lt;p&gt; findElements()返回的是一组元素，所以我们需要根据能够找到一组元素的表达式去定位，返回一组元素我们可以放在集合里，这样我们就可以使用集合里面的迭代方法去遍历元素，拿到元素去做其他操作。&lt;/p&gt;
&lt;p&gt; 32.在执行脚本过程，如何实现当前元素高亮显示？&lt;/p&gt;
&lt;p&gt; 这个其实就是利用javaScript去修改当前元素的背景颜色来到达高亮显示的效果，&lt;/p&gt;
&lt;p&gt;33.如何获取页面标题，悬浮文本和错误文本，并验证？&lt;/p&gt;
&lt;p&gt; 标题，我们可以通过driver.getTitle()方法来得到一个字符串，然后使用字符串的containts方法或者equals方法去进行断言。&lt;/p&gt;
&lt;p&gt; 悬浮文本（tooltip），一般是利用Actions类，然后鼠标悬停方法，然后通过getText()方法来得到这个tooltip字符串。&lt;/p&gt;
&lt;p&gt; 错误信息，直接把这个错误字段先进行定位，然后通过getText()方法拿到错误文本，主要的断言有包含，相等，不相等，不包含，以什么开头等。&lt;/p&gt;
&lt;p&gt; 34.在selenium自动化测试中，你一般完成什么类型的测试？&lt;/p&gt;
&lt;p&gt;     主要是冒烟测试和回归测试。回归测试主要写一些功能稳定，容易实现的场景，通过自动化手段去实现，节约测试时间。&lt;/p&gt;
&lt;p&gt; 35.你是如何管理你的测试用例并执行？&lt;/p&gt;
&lt;p&gt;     写用例和管理并执行用例，我们都需要借助单元测试框架来实现，如果是Java语言一般有junit和TestNG，如果是python，常见的有unittest。&lt;/p&gt;
&lt;p&gt;     就你实际情况，说一下。例如我使用TestNG比较多，需要配置testng.xml文件来实现测试用例的执行。有时候需要配置多个testng.xml去实现不同的任务场景。再展开，可能问你一下testng框架的知识点。例如，方法依赖，用例执行优先级，数据源驱动等。&lt;/p&gt;
&lt;p&gt; 36.关于自动化测试报告生成？&lt;/p&gt;
&lt;p&gt; 我个人一般用TestNG原生的测试报告，也有第三方叫reportNG的插件，不过我没有实际使用过。&lt;/p&gt;
&lt;p&gt;Python下报告生成一般使用HTMLTestRunner.py&lt;/p&gt;
&lt;p&gt; 37. 了解或者使用过框架不？&lt;/p&gt;
&lt;p&gt; 类似的问题还有，你知道那些自动化测试框。&lt;/p&gt;
&lt;p&gt;我们知道POM自动化测试框，还有关键字驱动框架。当然还有数据驱动框架，最近几年出的行为驱动框架。&lt;/p&gt;
&lt;p&gt; 38. 这个框架是你自己写的吗？&lt;/p&gt;
&lt;p&gt; 我自己设计过POM的框架和关键字驱动框架。&lt;/p&gt;
&lt;p&gt; 39.能不能介绍下你的框架&lt;/p&gt;
&lt;p&gt;&lt;em id=&quot;__mceDel&quot;&gt;    把你自己POM的框架从上往下，树形结构画图出来，然后讲下有哪些层，哪些包，包下几个重点的类的作用和一些工具类说一下。用例如何执行，页面对象和元素定位放哪里，错误日志和截图如何处理，报告如何得到等。&lt;/em&gt;&lt;/p&gt;

</description>
<pubDate>Thu, 20 Dec 2018 06:39:00 +0000</pubDate>
<dc:creator>长安。</dc:creator>
<og:description>1. 什么是Selenium？Selenium是一个开源的web自动化测试框架，主要是基于web uI的自动化测试。现在的版本，逐步增加了对移动端的自动化测试。Selenium支持多种语言进行开发自动</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/pingan666/p/10149232.html</dc:identifier>
</item>
</channel>
</rss>