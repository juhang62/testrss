<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="css/feed.xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/" xmlns:og="http://ogp.me/ns#">
<channel>
<atom:link rel="self" href="http://192.168.1.4/fivefilters/makefulltextfeed.php?url=feed.cnblogs.com%2Fblog%2Fsitehome%2Frss&amp;max=10&amp;links=preserve&amp;exc=" />
<atom:link rel="alternate" title="Source URL" href="http://feed.cnblogs.com/blog/sitehome/rss" />
<atom:link rel="related" title="Subscribe to feed" href="http://www.subtome.com/#/subscribe?feeds=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed.cnblogs.com%252Fblog%252Fsitehome%252Frss%26max%3D10%26links%3Dpreserve%26exc%3D&amp;back=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed.cnblogs.com%252Fblog%252Fsitehome%252Frss%26max%3D10%26links%3Dpreserve%26exc%3D" />
<title>博客园_首页</title>
<link></link>
<description>代码改变世界</description>
<item>
<title>QQ登录功能之如何获取用于本地测试的APPID - 字母哥博客</title>
<link>http://www.cnblogs.com/zimug/p/11986912.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/zimug/p/11986912.html</guid>
<description>&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1815316/201912/1815316-20191205080700177-1012670553.jpg&quot; alt=&quot;file&quot;/&gt;&lt;/p&gt;
&lt;p&gt;本文主要说明一下开发者如何在QQ互联创建测试应用，从而分配给我们一套APP ID和APP KEY，在我们平时学习的时候使用。&lt;/p&gt;
&lt;h2 id=&quot;一qq互联注册开发者&quot;&gt;一、QQ互联注册开发者&lt;/h2&gt;
&lt;p&gt;要想使用QQ登陆的功能，首先你必须是腾讯开发者。腾讯搞了一大堆的开放平台，有点乱。如果你还不是腾讯开发者，先去QQ互联网站&lt;a href=&quot;https://connect.qq.com/&quot;&gt;https://connect.qq.com&lt;/a&gt;注册一下开发者。&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;可以选择企业或者个人，进行开发者注册&lt;/li&gt;
&lt;li&gt;准备一个个人邮箱和手机号&lt;/li&gt;
&lt;li&gt;手持身份证正面照&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;以上所填信息真实完整，通常1个工作日即可审核完成，审核结果通过邮件通知。审核之后才能创建应用。下面的状态是开发者资格审核中的状态。&lt;br/&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1815316/201912/1815316-20191205080700482-63898018.jpg&quot; alt=&quot;file&quot;/&gt;&lt;/p&gt;
&lt;h2 id=&quot;二创建应用&quot;&gt;二、创建应用&lt;/h2&gt;
&lt;p&gt;注意：本文旨在教大家如何创建一个QQ互联的测试应用，目的是为了学习。所有的填的内容都是以满足本地测试为目的。如果你真的需要为一个生产环境开发QQ互联登录动能，请先准备好如下内容：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;您的应用要申请域名，域名通过备案，要有备案号&lt;/li&gt;
&lt;li&gt;想好您的应用名称和应用简介&lt;/li&gt;
&lt;li&gt;准备100 * 100px的网站图标&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;下面我们开始申请，如果您和我一样就是创建一个测试应用，我们什么也不用准备，现在就开始吧。但是测试账号只能使用当前的创建应用的QQ用户进行登录相关测试，这对我们来说就已经足够了。&lt;/p&gt;
&lt;p&gt;在开发者资格审核通过之后，再次登录QQ互联网站，创建网站应用。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1815316/201912/1815316-20191205080700732-1210084655.jpg&quot; alt=&quot;file&quot;/&gt;&lt;/p&gt;
&lt;p&gt;弹出框内选择创建网站应用&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1815316/201912/1815316-20191205080700981-1375318019.jpg&quot; alt=&quot;file&quot;/&gt;&lt;/p&gt;
&lt;p&gt;创建应用的应用名称和应用简介，随便填写一下即可，最后结果：审核不通过。但是不耽误我们测试使用。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1815316/201912/1815316-20191205080701239-1233677999.jpg&quot; alt=&quot;file&quot;/&gt;&lt;/p&gt;
&lt;p&gt;最重要的是填写网站域名和回调地址，其他两项随便填。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1815316/201912/1815316-20191205080701517-1126475997.jpg&quot; alt=&quot;file&quot;/&gt;&lt;/p&gt;
&lt;p&gt;填写完成之后等待审核。已经为我们分配了APP ID 和 APP KEY。并且获取了QQ登录接口的权限。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1815316/201912/1815316-20191205080701809-1630668837.jpg&quot; alt=&quot;file&quot;/&gt;&lt;/p&gt;
&lt;h2 id=&quot;三概念解释&quot;&gt;三、概念解释&lt;/h2&gt;
&lt;p&gt;完成开发者注册和应用创建之后，我们就可以使用APP ID和APP Key搭建本地环境，开发QQ登录代码。&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;APP ID：在QQ互联创建的应用的唯一标识。&lt;/li&gt;
&lt;li&gt;APP Key：在QQ互联创建的应用的密钥，与APP ID结合使用，确定该应用访问QQ互联相关接口的合法性。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;在进行网站QQ登录功能开发之前，建议开发者一定要仔细阅读该文档：&lt;a href=&quot;https://wiki.connect.qq.com/%E7%BD%91%E7%AB%99%E5%BA%94%E7%94%A8%E6%8E%A5%E5%85%A5%E6%B5%81%E7%A8%8B&quot;&gt;QQ互联网站接入流程&lt;/a&gt; ，这样在我们后续的开发中才能更顺畅。&lt;/p&gt;
&lt;h2 id=&quot;期待您的关注&quot;&gt;期待您的关注&lt;/h2&gt;
</description>
<pubDate>Thu, 05 Dec 2019 00:07:00 +0000</pubDate>
<dc:creator>字母哥博客</dc:creator>
<og:description>本文主要说明一下开发者如何在QQ互联创建测试应用，从而分配给我们一套APP ID和APP KEY，在我们平时学习的时候使用。 一、QQ互联注册开发者 要想使用QQ登陆的功能，首先你必须是腾讯开发者。腾</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/zimug/p/11986912.html</dc:identifier>
</item>
<item>
<title>SpringMVC参数绑定学习总结【前后端数据参数传递】 - 宜春</title>
<link>http://www.cnblogs.com/yichunguo/p/11974573.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/yichunguo/p/11974573.html</guid>
<description>[unable to retrieve full-text content]SpringMVC作为Controller层（等价servlet和struts中的action）专门用来处理页面的一些请求，然后将数据再通过视图返回给用户的，因此可见前后端数据参数传递相对springmvc的重要性，这篇文章将总结一下springmvc中如何接收前台页面的参数，即springmvc中</description>
<pubDate>Thu, 05 Dec 2019 00:06:00 +0000</pubDate>
<dc:creator>宜春</dc:creator>
<dc:identifier>https://www.cnblogs.com/yichunguo/p/11974573.html</dc:identifier>
</item>
<item>
<title>Elasticsearch系列---并发控制及乐观锁实现原理 - 清茶豆奶</title>
<link>http://www.cnblogs.com/huangying2124/p/11986897.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/huangying2124/p/11986897.html</guid>
<description>&lt;h3 id=&quot;概要&quot;&gt;概要&lt;/h3&gt;
&lt;p&gt;本篇主要介绍一下Elasticsearch的并发控制和乐观锁的实现原理，列举常见的电商场景，关系型数据库的并发控制、ES的并发控制实践。&lt;/p&gt;
&lt;h3 id=&quot;并发场景&quot;&gt;并发场景&lt;/h3&gt;
&lt;p&gt;不论是关系型数据库的应用，还是使用Elasticsearch做搜索加速的场景，只要有数据更新，并发控制是永恒的话题。&lt;/p&gt;
&lt;p&gt;当我们使用ES更新document的时候，先读取原始文档，做修改，然后把document重新索引，如果有多人同时在做相同的操作，不做并发控制的话，就极有可能会发生修改丢失的。可能有些场景，丢失一两条数据不要紧（比如文章阅读数量统计，评论数量统计），但有些场景对数据严谨性要求极高，丢失一条可能会导致很严重的生产问题，比如电商系统中商品的库存数量，丢失一次更新，可能会导致超卖的现象。&lt;/p&gt;
&lt;p&gt;我们还是以电商系统的下单环节举例，某商品库存100个，两个用户下单购买，都包含这件商品，常规下单扣库存的实现步骤&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;客户端完成订单数据校验，准备执行下单事务。&lt;/li&gt;
&lt;li&gt;客户端从ES中获取商品的库存数量。&lt;/li&gt;
&lt;li&gt;客户端提交订单事务，并将库存数量扣减。&lt;/li&gt;
&lt;li&gt;客户端将更新后的库存数量写回到ES。&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;示例流程图如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1834889/201912/1834889-20191205073859329-531100462.png&quot; alt=&quot;库存更新示例&quot;/&gt;&lt;/p&gt;
&lt;p&gt;如果没有并发控制，这件商品的库存就会更新成99（实际正确的值是98），这样就会导致超卖现象。假定http-1比http-2先一步执行，出现这个问题的原因是http-2在获取库存数据时，http-1还未完成下单扣减库存后，更新到ES的环节，导致http-2获取的数据已经是过期数据，后续的更新肯定也是错的。&lt;/p&gt;
&lt;p&gt;上述的场景，如果更新操作越是频繁，并发数越多，读取到更新这一段的耗时越长，数据出错的概率就越大。&lt;/p&gt;
&lt;h3 id=&quot;常用的锁方案&quot;&gt;常用的锁方案&lt;/h3&gt;
&lt;p&gt;并发控制尤为重要，有两种通用的方案可以确保数据在并发更新时的正确性。&lt;/p&gt;
&lt;h4 id=&quot;悲观并发控制&quot;&gt;悲观并发控制&lt;/h4&gt;
&lt;p&gt;悲观锁的含义：我认为每次更新都有冲突的可能，并发更新这种操作特别不靠谱，我只相信只有严格按我定义的粒度进行串行更新，才是最安全的，一个线程更新时，其他的线程等着，前一个线程更新完成后，下一个线程再上。&lt;/p&gt;
&lt;p&gt;关系型数据库中广泛使用该方案，常见的表锁、行锁、读锁、写锁，依赖redis或memcache等实现的分布式锁，都属于悲观锁的范畴。明显的特征是后续的线程会被挂起等待，性能一般来说比较低，不过自行实现的分布式锁，粒度可以自行控制（按行记录、按客户、按业务类型等），在数据正确性与并发性能方面也能找到很好的折衷点。&lt;/p&gt;
&lt;h4 id=&quot;乐观并发控制&quot;&gt;乐观并发控制&lt;/h4&gt;
&lt;p&gt;乐观锁的含义：我认为冲突不经常发生，我想提高并发的性能，如果真有冲突，被冲突的线程重新再尝试几次就好了。&lt;/p&gt;
&lt;p&gt;在使用关系型数据库的应用，也经常会自行实现乐观锁的方案，有性能优势，方案实现也不难，还是挺吸引人的。&lt;/p&gt;
&lt;p&gt;Elasticsearch默认使用的是乐观锁方案，前面介绍的_version字段，记录的就是每次更新的版本号，只有拿到最新版本号的更新操作，才能更新成功，其他拿到过期数据的更新失败，由客户端程序决定失败后的处理方案，一般是重试。&lt;/p&gt;
&lt;h3 id=&quot;es的乐观锁方案&quot;&gt;ES的乐观锁方案&lt;/h3&gt;
&lt;p&gt;我们还是以上面的案例为背景，若http-2向ES提交更新数据时，ES会判断提交过来的版本号与当前document版本号，document版本号单调递增，如果提交过来的版本号比document版本号小，则说明是过期数据，更新请求将提示错误，过程图如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1834889/201912/1834889-20191205073859730-1551062688.png&quot; alt=&quot;有并发控制的库存更新示例&quot;/&gt;&lt;/p&gt;
&lt;h4 id=&quot;使用内置_version实战乐观锁控制效果&quot;&gt;使用内置_version实战乐观锁控制效果&lt;/h4&gt;
&lt;p&gt;我们在kibana平台上模拟两个线程修改同一条document数据，打开两个浏览器标签即可，我们使用原有的案例数据：&lt;/p&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;{
  &quot;_index&quot;: &quot;music&quot;,
  &quot;_type&quot;: &quot;children&quot;,
  &quot;_id&quot;: &quot;2&quot;,
  &quot;_version&quot;: 2,
  &quot;found&quot;: true,
  &quot;_source&quot;: {
    &quot;name&quot;: &quot;wake me, shark me&quot;,
    &quot;content&quot;: &quot;don't let me sleep too late, gonna get up brightly early in the morning&quot;,
    &quot;language&quot;: &quot;english&quot;,
    &quot;length&quot;: &quot;55&quot;
  }
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;当前的version是2，我们使用一个浏览器标签页，发出更新请求，把当前的version带上：&lt;/p&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;POST /music/children/2?version=2
{
 &quot;doc&quot;: {
   &quot;length&quot;: 56
 }
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;此时更新成功&lt;/p&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;{
  &quot;_index&quot;: &quot;music&quot;,
  &quot;_type&quot;: &quot;children&quot;,
  &quot;_id&quot;: &quot;2&quot;,
  &quot;_version&quot;: 3,
  &quot;result&quot;: &quot;updated&quot;,
  &quot;_shards&quot;: {
    &quot;total&quot;: 2,
    &quot;successful&quot;: 1,
    &quot;failed&quot;: 0
  },
  &quot;_seq_no&quot;: 2,
  &quot;_primary_term&quot;: 2
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;同时我们在另一个标签页上，也使用version=2进行更新，得到的错误结果如下：&lt;/p&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;{
  &quot;error&quot;: {
    &quot;root_cause&quot;: [
      {
        &quot;type&quot;: &quot;version_conflict_engine_exception&quot;,
        &quot;reason&quot;: &quot;[children][2]: version conflict, current version [3] is different than the one provided [2]&quot;,
        &quot;index_uuid&quot;: &quot;9759yb44TFuJSejo6boy4A&quot;,
        &quot;shard&quot;: &quot;2&quot;,
        &quot;index&quot;: &quot;music&quot;
      }
    ],
    &quot;type&quot;: &quot;version_conflict_engine_exception&quot;,
    &quot;reason&quot;: &quot;[children][2]: version conflict, current version [3] is different than the one provided [2]&quot;,
    &quot;index_uuid&quot;: &quot;9759yb44TFuJSejo6boy4A&quot;,
    &quot;shard&quot;: &quot;2&quot;,
    &quot;index&quot;: &quot;music&quot;
  },
  &quot;status&quot;: 409
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;关键错误信息：version_conflict_engine_exception，版本冲突，将version升到3,模拟失败后重试，此时更新成功。&lt;/p&gt;
&lt;p&gt;真实的场景，重试的次数跟线程并发数有关，线程越多，更新越频繁，就可能需要重试多次才可能更新成功。&lt;/p&gt;
&lt;h4 id=&quot;使用外部_version实战乐观锁控制效果&quot;&gt;使用外部_version实战乐观锁控制效果&lt;/h4&gt;
&lt;p&gt;ES允许不使用内置的version进行版本控制，可以自定义使用外部的version，例如常见的使用Elasticsearch做数据查询加速的经典方案，关系型数据库作为主数据库，然后使用Elasticsearch做搜索数据，主数据会同步数据到Elasticsearch中，而主数据库并发控制，本身就是使用的乐观锁机制，有自己的一套version生成机制，数据同步到ES那里时，直接使用更方便。&lt;/p&gt;
&lt;p&gt;请求语法上加上version_type参数即可：&lt;/p&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;POST /music/children/2?version=2&amp;amp;version_type=external
{
 &quot;doc&quot;: {
   &quot;length&quot;: 56
 }
}&lt;/code&gt;
&lt;/pre&gt;
&lt;h5 id=&quot;唯一的区别&quot;&gt;唯一的区别&lt;/h5&gt;
&lt;ul&gt;&lt;li&gt;内置_version，只有当你提供的version与es中的_version完全一样的时候，才可以进行更新，否则报错；&lt;/li&gt;
&lt;li&gt;外部_version，只有当你提供的version比es中的_version大的时候，才能完成修改。&lt;/li&gt;
&lt;/ul&gt;&lt;h3 id=&quot;replica-shard数据同步并发控制&quot;&gt;Replica Shard数据同步并发控制&lt;/h3&gt;
&lt;p&gt;在Elasticsearch内部，每当primary shard收到新的数据时，都需要向replica shard进行数据同步，这种同步请求特别多，并且是异步的。如果同一个document进行了多次修改，Shard同步的请求是无序的，可能会出现&quot;后发先至&quot;的情况，如果没有任何的并发控制机制，那结果将无法相像。&lt;/p&gt;
&lt;p&gt;Shard的数据同步也是基于内置的_version进行乐观锁并发控制的。&lt;/p&gt;
&lt;p&gt;例如Java客户端向Elasticsearch某条document发起更新请求，共发出3次，Java端有严谨的并发请求控制，在ElasticSearch的primary shard中写入的结果是正确的，但Elasticsearch内部数据启动同步时，顺序不能保证都是先到先得，情况可能是这样，第三次更新请求比第二次更新请求先到，如下图：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1834889/201912/1834889-20191205073859885-898755252.png&quot; alt=&quot;ES内部更新并发控制示例&quot;/&gt;&lt;/p&gt;
&lt;p&gt;如果Elasticsearch内部没有并发的控制，这个document在replica的结果可能是text2，并且与primary shard的值不一致，这样肯定错了。&lt;/p&gt;
&lt;p&gt;预期的更新顺序应该是text1--&amp;gt;text2--&amp;gt;text3，最终的正确结果是text3。那Elasticsearch内部是如何做的呢？&lt;/p&gt;
&lt;p&gt;Elasticsearch内部在更新document时，会比较一下version，如果请求的version与document的version相等，就做更新，如果document的version已经大于请求的version，说明此数据已经被后到的线程更新过了，此时会丢弃当前的请求，最终的结果为text3。&lt;br/&gt;此时的更新顺序为text1--&amp;gt;text3，最终结果也是对的。&lt;/p&gt;
&lt;h3 id=&quot;小结&quot;&gt;小结&lt;/h3&gt;
&lt;p&gt;本篇主要介绍并发场景出现数据错乱的原因，Elasticsearch乐观锁的实原理，以及ES内部数据同步时的并发控制，有不正确之处或未详尽之处请知会修改，谢谢。&lt;/p&gt;
&lt;p&gt;专注Java高并发、分布式架构，更多技术干货分享与心得，请关注公众号：Java架构社区&lt;br/&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1834889/201912/1834889-20191205073900048-1636888349.jpg&quot; alt=&quot;Java架构社区&quot;/&gt;&lt;/p&gt;
</description>
<pubDate>Wed, 04 Dec 2019 23:39:00 +0000</pubDate>
<dc:creator>清茶豆奶</dc:creator>
<og:description>并发控制及乐观锁实现原理</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/huangying2124/p/11986897.html</dc:identifier>
</item>
<item>
<title>机器学习回顾篇（11）：支持向量机（SVM） - 奥辰</title>
<link>http://www.cnblogs.com/chenhuabin/p/11986889.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/chenhuabin/p/11986889.html</guid>
<description>&lt;p&gt;SVM，Support Vector Machine，也就是我们中文名的支持向量机，我相信，只要是与机器学习有过照面的童鞋或多或少都听说过这个名字。作为机器学习家族中的老牌成员，其经典自不必说。从原理和特性上讲，&lt;strong&gt;SVM属于有监督学习中线性二分类中的一员，基本思想就是采用最大化间隔策略寻找一个最优决策超平面将所有样本点划分到平面两侧，实现对数据的分类&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;注意几个关键词：线性、二分类、最大化间隔。这么一说，你可能会以为SVM算法只能用于线性可分问题和和二分类问题中，然而，事实却是SVM算法在非线性和多分类场景中有卓越表现，这并不矛盾，至于原因，下文中会陆续解答。&lt;/p&gt;
&lt;p&gt;先来说说超平面和最大化间隔，这是SVM算法的根本所在。&lt;/p&gt;

&lt;p&gt;因为SVM算法探究的是一个线性可分的二分类问题，首要任务就寻找一个超平面。这里的超平面，定义的是$n$维线性空间中维度为$n-1$的子空间，可以把线性空间分割成不相交的两部分。一般的，在数学上，超平面表示如下：&lt;/p&gt;
$${w^T}x + b = 0 \tag{1}$$

&lt;p&gt;不需要想得太复杂，想想3维以下的空间就可以理解了，例如在二维空间中，超平面就表现为一维的直线，它把平面分成了两块，对于直线的表示，大家都不陌生：$wx + b = 0$，这时候的$x$就是一个一维向量；三维空间中，超平面就是二维的平面，它把空间分成了两块，这个二维平面表示为：${w_1}{x_1} + {w_2}{x_2} = 0$。对于更高的n维空间原理是一样的。&lt;/p&gt;
&lt;p&gt;对于数据空间中给定的样本集合$D = \{ ({x_1},{y_1}),({x_2},{y_2}), \cdots ,({x_N},{y_N})\} $，其中${x_i} \in X = {R^n}$，${y_i} \in Y = \{ - 1, + 1\} $，SVM算法的目标就是寻找一个超平面将数据集$D$划分为两个不相交的子集，对于两个子集分别满足当${y_i} = + 1$时，${w^T}{x_i} + b &amp;gt; 0$，当${y_i} = - 1$时，${w^T}{x_i} + b &amp;lt; 0$，即：&lt;/p&gt;
$${y_i}({w^T}{x_i} + b) &amp;gt; 0 \tag{2}$$
&lt;p&gt;但是，对与任意线性可分数据集，满足这一条件超平面都不可能不只一个，以我们熟悉的二维空间为例，如下图所示：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;data:image/png;base64,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&quot; alt=&quot;image&quot;/&gt;&lt;/p&gt;
&lt;p&gt;在上面图中，有数量不等的蓝点和红点，分别代表着数据集中的+1类和-1类，在图中我们可以看到，直线A、B、C、D都满足上述两个条件，可以做到能将数据集进行正确分类，但是哪一条才是最优的呢？&lt;/p&gt;
&lt;p&gt;从直观上来判断，我相信大家都会选择B（红色那条）最优，具有最强的鲁棒性。因为它与蓝点和红点都有足够的距离，如果选择其他直线，例如C，它与红点非常接近，如果数据稍有波动，就容易越过C线被误判为蓝点所在类别（+1类）。&lt;/p&gt;
&lt;p&gt;所以，我们会选择离两边数据集都尽量远的超平面来划分数据空间，这样的误判率会低一些——这就是间隔最大化选取超平面的方法。其中离超平面最近的点，我们称之为&lt;strong&gt;支持向量&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;假设样本$({x_i},y_i)$就是数据集$D$中的支持向量，$({x_i},y_i)$到超平面${w^T}x + b = 0$的几何距离可以表示为： $$\frac{{|{w^T}{x_i} + b|}}{{\left\| w \right\|}}$$&lt;/p&gt;
&lt;p&gt;支持向量机算法的思想就是最大化这个距离，即： $$\max \frac{{|{w^T}{x_i} + b|}}{{\left\| w \right\|}}\tag{3}$$&lt;/p&gt;
&lt;p&gt;式（3）太过于复杂，我们可以进一步化简。因为$x_i$与$y_i$是同号的，所以${y_i}({w^T}{x_i} + b) &amp;gt; 0$，那么式（3）可转化为： $$\max \frac{{{y_i}({w^T}{x_i} + b)}}{{\left\| w \right\|}} \tag{4}$$&lt;/p&gt;
&lt;p&gt;对于式（4）中的分子${{y_i}({w^T}{x_i} + b)}$，许多教材中定义了一个专门的概念，那就是函数距离，当参数$w$和$b$固定时，点与超平面间的间隔越大，函数间隔越大。但函数间隔有一个不好的地方，当参数$w$和$b$按比例缩放时，所描述的超平面不会发生变化，但是函数距离却会跟着按比例缩放。为了克服这一不足，我们可以将函数距离固定为一个确定值，例如缩放到函数距离为1，这样求解出来的$w$和$b$虽然不是原来的$w$和$b$，但是所确定的超平面却是一样的，所以并不会对我们求解支持向量机最优超平面造成影响。那么，式（4）就再次化简为： $$\max \frac{1}{{\left\| w \right\|}}$$&lt;/p&gt;
&lt;p&gt;因为我们刚假设支持向量到超平面的函数距离为1，所以，对于数据集中任意样本到超平面的函数距离都至少为1，求解时必须考虑上这一约束条件。另外，最大化$\frac{1}{{\left\| w \right\|}}$和最小化${\frac{1}{2}{{\left\| w \right\|}^2}}$是等价的，所以，支持向量机最大化间隔可以表示为如下优化问题： $$\eqalign{ &amp;amp; \mathop {\min }\limits_{w,b} {\text{ }}\frac{1}{2}{\left\| w \right\|^2} \tag{5}\cr &amp;amp; s.t.{\text{ }}{y_i}({w^T}{x_i} + b) \geqslant 1,{\text{ }}i = 1,2, \cdots ,N \cr} $$&lt;/p&gt;

&lt;p&gt;很明显，式（5）是一个二次凸优化问题（简单来说，如果目标函数是二次函数且约束函数是线性的，这类问题就是二次凸优化问题），对于这类问题，可以引入拉格朗日乘子法进行转化，将有约束条件的问题转化为无约束条件的问题进行求解。于是式（5）就可以转化为：&lt;/p&gt;
$$\eqalign{ &amp;amp; \mathop {\min }\limits_{w,b} \mathop {{\text{max}}}\limits_\lambda {\text{ }}L(w,b,\lambda ) \tag{6}\cr &amp;amp; s.t.{\text{ }}{\lambda _i} \geqslant 0,{\text{ }}i = 1,2, \cdots ,N \cr} $$$$L(w,b,\lambda ) = \frac{1}{2}{\left\| w \right\|^2} - \sum\limits_{i = 1}^N {{\lambda _i}({y_i}({w^T}{x_i} + b)-1)}\tag{7}$$
&lt;p&gt;式中，$\lambda $为拉格朗日乘子。&lt;br/&gt;如果你不理解从式（5）到式（6）的转化原理和细节，没关系，你姑且可以认为这就是公理，套公式就好了。此时，式（6）对参数$w$和$b$已经是没有约束条件了。接下来，根据拉格朗日的对偶性，我们不妨将式（6）中求最大值的最小值问题转化为求最小值的最大值问题，不理解没关系，姑且认为就是将max和min交换一下位置，对我们的最终结果不会有太大影响，但是却方便求解。转化后，式（6）如下： $$\eqalign{ &amp;amp; \mathop {{\text{max}}}\limits_\lambda \mathop {\min }\limits_{w,b} {\text{ }}L(w,b,\lambda ) \tag{8}\cr &amp;amp; s.t.{\text{ }}{\lambda _i} \geqslant 0,{\text{ }}i = 1,2, \cdots ,N \cr} $$ 在式（7）中，第一步要做的就是求$\mathop {\min }\limits_{w,b} {\text{ }}L(w,b,\lambda )$,也就是$L(w,b,\lambda )$的最小值，我们可以通过求$L(w,b,\lambda )$对$w$和$b$的偏导，并令偏导为$0$的方式来求解。 $$\frac{{\partial L(w,b,\lambda )}}{{\partial w}} = w - \sum\limits_{i = 1}^N {{\lambda _i}{y_i}{x_i}} = 0$$ $$\frac{{\partial L(w,b,\lambda )}}{{\partial b}} = - \sum\limits_{i = 1}^N {{\lambda _i}{y_i}} = 0$$ 于是有： $$w = \sum\limits_{i = 1}^N {{\lambda _i}{y_i}{x_i}} \tag{9}$$ $$\sum\limits_{i = 1}^N {{\lambda _i}{y_i}} = 0 \tag{10}$$ 将拉格朗日函数，也就是式（7）中展开，得： $$L(w,b,\lambda ) = \frac{1}{2}{\left\| w \right\|^2} - {w^T}\sum\limits_{i = 1}^N {{\lambda _i}{y_i}{x_i}} - b\sum\limits_{i = 1}^N {{\lambda _i}{y_i}} + \sum\limits_{i = 1}^N {{\lambda _i}} \tag{11}$$ 式（9）代入式（11）再结合（10）进行化简： $$\displaylines{ L(w,b,\lambda ) = \frac{1}{2}{\left\| w \right\|^2} - \sum\limits_{i = 1}^N {{\lambda _i}({y_i}({w^T}{x_i} + b) - 1)} \cr = \frac{1}{2}{\left\| w \right\|^2} - {w^T}\sum\limits_{i = 1}^N {{\lambda _i}{y_i}{x_i}} - b\sum\limits_{i = 1}^N {{\lambda _i}{y_i}} + \sum\limits_{i = 1}^N {{\lambda _i}} \cr = \frac{1}{2}{\left\| w \right\|^2} - {w^T}w - b \cdot 0 + \sum\limits_{i = 1}^N {{\lambda _i}} \cr = - \frac{1}{2}{\left\| w \right\|^2} + \sum\limits_{i = 1}^N {{\lambda _i}} \cr = - \frac{1}{2}\sum\limits_{i = 1}^N {\sum\limits_{i = 1}^N {{\lambda _i}{\lambda _j}{y_i}{y_j}{x_i}{x_j}} } + \sum\limits_{i = 1}^N {{\lambda _i}} \cr} $$ 即： $$\mathop {\min }\limits_{w,b} L(w,b,\lambda ) = - \frac{1}{2}\sum\limits_{i = 1}^N {\sum\limits_{i = 1}^N {{\lambda _i}{\lambda _j}{y_i}{y_j}{x_i}{x_j}} } + \sum\limits_{i = 1}^N {{\lambda _i}} $$&lt;/p&gt;
&lt;p&gt;至此，式（8）可以转化为如下形式： $$\eqalign{ &amp;amp; \mathop {\max }\limits_\lambda {\text{ }} - \frac{1}{2}\sum\limits_{i = 1}^N {\sum\limits_{i = 1}^N {{\lambda _i}{\lambda _j}{y_i}{y_j}{x_i}{x_j}} } + \sum\limits_{i = 1}^N {{\lambda _i}} \tag{12}\cr &amp;amp; s.t.{\text{ }}{\lambda _i} \geqslant 0,{\text{ }}\sum\limits_{i = 1}^N {{\lambda _i}{y_i}} = 0,{\text{ }}i = 1,2, \cdots ,N \cr} $$ 可以看出，这是一个二次规划的问题，问题规模正比于训练样本数，我们常用 SMO(Sequential Minimal Optimization) 算法求解。对于SMO算法求解过程，感觉有些复杂（我也没看明白），不敢多想说，后续完全弄明白再补充。此刻，我们假设通过SMO算法求解出式（12）最优解为${\lambda ^*}$，将${\lambda ^*}$代入式（9）可的参数$w$的最优解： $${w^*} = \sum\limits_{i = 1}^N {\lambda _i^*{y_i}{x_i}} $$ 对于参数$b$，由Kuhn Tuker定理可知，式（12）的最优解必须满足一下最优化条件（KKT条件）： $${\lambda ^*}[{y_i}({w^*}{x_i} + {b^*}) - 1] = 0 \tag{13}$$ 式（13）要成立，就必须是${\lambda ^*}=0$或者${y_i}({w^*}{x_i} + {b^*}) = 1$。对于${\lambda ^*}=0$，肯定是不能成立的，可以通过反证法证明。如果${\lambda ^*}=0$成立，通过式（9）可知必然使得$w^*=0$，而$w^*=0$显然不是式（5）的解，产生矛盾，因此${\lambda ^*}$不能为0。&lt;br/&gt;所以${y_i}({w^*}{x_i} + {b^*}) = 1$必然适用。对于这个条件，若要满足，$x_i$必然是是支持向量，这也是为什么只有支持向量才能绝对最终的最优超平面的原因。将式（9）代入${y_i}({w^*}{x_i} + {b^*}) = 1$中，然后移项可得： $${b^*} = {y_j} - \sum\limits_{i = 1}^N {\lambda _i^*{y_i}{x_i}} {x_j}$$ $w^*$和$b^*$求解出来了，最终的最优超平面自然也就确定了。&lt;/p&gt;

&lt;p&gt;本文总结了在数据集线性可分情况下，使用支持向量机算法进行分类的思想——硬间隔最大化。然而，在多数应用中，数据集并非线性可分，如果只是在分类边界附近少数点造成线性不可分，这种情况下需要在硬间隔最大化目标函数基础上，引入松弛变量和惩罚因子，然后通过拉格朗日对偶性求解，这种方法称为软间隔最大化。如果大量样本线性不可分，则需要引入核技巧，往高维空间映射，转化为线性可分。对于这两部分内容，在后续博客中在总结了（吐槽一下，写这类博客，真是耗时、费神、心累）。&lt;/p&gt;
</description>
<pubDate>Wed, 04 Dec 2019 23:25:00 +0000</pubDate>
<dc:creator>奥辰</dc:creator>
<og:description>SVM，Support Vector Machine，也就是我们中文名的支持向量机，我相信，只要是与机器学习有过照面的童鞋或多或少都听说过这个名字。作为机器学习家族中的老牌成员，其经典自不必说。从原理</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/chenhuabin/p/11986889.html</dc:identifier>
</item>
<item>
<title>Debug 利器：pstack &amp; strace  - 陈心朔</title>
<link>http://www.cnblogs.com/chenxinshuo/p/11986858.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/chenxinshuo/p/11986858.html</guid>
<description>&lt;p&gt;工作中难免会遇到各种各样的 bug，对于开发环境 or 测试环境的问题还好解决，可以使用 gdb 打断点或者在代码中埋点来定位异常;&lt;br/&gt;但是遇到线上的 bug 就很难受了，由于生产环境不能随意替换、中断程序，如果日志中找不到问题原因，解决问题就会很棘手&lt;/p&gt;
&lt;p&gt;这时候就需要请出这两位 debug 利器了 ———— pstack &amp;amp; strace&lt;/p&gt;
&lt;h2 id=&quot;什么是-pstack&quot;&gt;什么是 pstack&lt;/h2&gt;
&lt;p&gt;pstack 是 Linux 系统下的一个命令行工具，此命令可以显示指定进程每个线程的堆栈快照，便于排查程序异常和性能评估&lt;/p&gt;
&lt;p&gt;pstack 是基于 gdb 实现的，通过 man pstack 可以发现，它其实是 gstack 的一个软链接&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;GSTACK(1)                  Linux Programmer's Manual                 GSTACK(1)
 
NAME
       gstack - print a stack trace of a running process
 
SYNOPSIS
       gstack pid
 
DESCRIPTION
       gstack attaches to the active process named by the pid on the command line, and prints out an execution stack trace.  If ELF symbols exist
       in the binary (usually the case unless you have run strip(1)), then symbolic addresses are printed as well.
 
       If the process is part of a thread group, then gstack will print out a stack trace for each of the threads in the group.
 
SEE ALSO
       nm(1), ptrace(2), gdb(1)
 
AUTHORS
       Ross Thompson &amp;lt;ross@whatsis.com&amp;gt;
 
       Red Hat, Inc. &amp;lt;http://bugzilla.redhat.com/bugzilla&amp;gt;
 
Red Hat Linux                     Feb 15 2008                        GSTACK(1)&lt;/code&gt;
&lt;/pre&gt;
&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;[root@Centos6x64 bin]# pwd
/usr/bin
[root@Centos6x64 bin]# ll -h | grep gstack
-rwxr-xr-x. 1 root root    1.1K 3月  22 2017 gstack
lrwxrwxrwx. 1 root root       6 8月  24 21:21 pstack -&amp;gt; gstack&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;而 gstack 则是封装了 gdb 功能的 shell 脚本，通过 &quot; thread apply all bt &quot; 的命令获得输出所有的线程堆栈信息，再用 sed 进行替换和过滤&lt;/p&gt;
&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;# Run GDB, strip out unwanted noise.
$GDB --quiet $readnever -nx /proc/$1/exe $1 &amp;lt;&amp;lt;EOF 2&amp;gt;&amp;amp;1 |
set width 0
set height 0
set pagination no
$backtrace
EOF
/bin/sed -n \
    -e 's/^\((gdb) \)*//' \
    -e '/^#/p' \
    -e '/^Thread/p'&lt;/code&gt;
&lt;/pre&gt;

&lt;h2 id=&quot;什么是-strace&quot;&gt;什么是 strace&lt;/h2&gt;
&lt;p&gt;使用 pstack 获得的进程堆栈是程序的静态信息，而使用 strace 可以获得程序的动态信息，即程序现在正在做什么（执行哪些系统调用和所接收的信号）&lt;/p&gt;
&lt;p&gt;strace 的功能主要是通过 ptrace 这个系统调用来实现的，它提供了父进程观察/控制子进程的能力&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;#include &amp;lt;sys/ptrace.h&amp;gt;
long ptrace(enum __ptrace_request request, pid_t pid, void *addr, void *data);&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;详见：&lt;a href=&quot;https://linux.die.net/man/2/ptrace&quot;&gt;ptrace(2) - Linux man page&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;当使用了 pstrace 跟踪子进程后，所有发送给被跟踪子进程的信号都会转发给父进程（SIGKILL 除外），而子进程则会阻塞，被标注为 TASK_TRACED 状态&lt;/p&gt;
&lt;p&gt;父进程收到信号后，可以对阻塞的子进程进行检查和修改，然后让子进程继续运行&lt;/p&gt;

&lt;p&gt;关于 strace 的参数可以参考：&lt;a href=&quot;https://www.bookstack.cn/read/linuxtools/20.md&quot;&gt;strace 跟踪进程中的系统调用&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;或者查看 Linux 手册 man strace&lt;/p&gt;

&lt;h2 id=&quot;如何使用-pstack-strace-排查程序问题&quot;&gt;如何使用 pstack &amp;amp; strace 排查程序问题&lt;/h2&gt;
&lt;h3 id=&quot;pstack-的用法&quot;&gt;pstack 的用法&lt;/h3&gt;
&lt;p&gt;通过 ps / pidof 命令获取到异常进程的 pid，执行 pstack [pid]，我们可以获得以下输出：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1879468/201912/1879468-20191205032812508-2060952628.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;从上面的输出中我们可以得到很多信息&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;当前进程中有多少线程&lt;/li&gt;
&lt;li&gt;各线程当前的调用堆栈（即这个线程正在做什么）&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;通过这些信息，我们可以简单判断线程是否挂死或者阻塞，再通过堆栈信息定位到代码中具体的函数进一步排查&lt;/p&gt;
&lt;p&gt;另外需要注意一点，只有保留了 debug symbols 的程序才可以 pstack，否则将看不到调用栈（如下图）&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1879468/201912/1879468-20191205033418655-372027025.png&quot;/&gt;&lt;/p&gt;

&lt;h3 id=&quot;strace-的用法&quot;&gt;strace 的用法&lt;/h3&gt;
&lt;p&gt;strace 的用法也很简单，常用的选项有这几个：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;-f 跟踪目标进程，以及目标进程创建的所有子进程&lt;/li&gt;
&lt;li&gt;-t 在输出中的每一行前加上时间信息(-tt 表示微秒级)&lt;/li&gt;
&lt;li&gt;-T 显示每个系统调用所耗的时间&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;执行 strace ... -p [pid] 我们将获得如下的输出：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1879468/201912/1879468-20191205034344005-745145855.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;通过观察系统调用我们可以确认当前程序的行为，分析其消耗的时间、返回值是否正常&lt;/p&gt;
&lt;p&gt;可以过滤指定的线程号，确认当前线程的行为是否符合预期&lt;/p&gt;
&lt;p&gt;如果执行命令后完全没有输出，那么可以怀疑是否由于网络、IO等原因导致阻塞，或程序产生死锁&lt;/p&gt;

&lt;h2 id=&quot;小结&quot;&gt;小结&lt;/h2&gt;
&lt;p&gt;有了这两个工具，当出现线上异常时，如果情况紧急，我们可以收集程序当前状态的信息，再进行救灾&lt;br/&gt;待生产环境稳定后，可以慢慢分析是哪里产生的问题&lt;/p&gt;
&lt;p&gt;另外分析 pstack / strace 的信息时，最好和日志对照观察&lt;/p&gt;
</description>
<pubDate>Wed, 04 Dec 2019 20:15:00 +0000</pubDate>
<dc:creator>陈心朔</dc:creator>
<og:description>使用 pstack &amp; strace 工具解决程序的各种疑难杂症</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/chenxinshuo/p/11986858.html</dc:identifier>
</item>
<item>
<title>asp.net core 从 3.0 到 3.1 - WeihanLi</title>
<link>http://www.cnblogs.com/weihanli/p/migrate-to-netcore3_1-from-netcore3_0.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/weihanli/p/migrate-to-netcore3_1-from-netcore3_0.html</guid>
<description>&lt;h2 id=&quot;intro&quot;&gt;Intro&lt;/h2&gt;
&lt;p&gt;今天 .net core 3.1 正式发布了，.net core 3.1 正式版已发布，3.1 主要是对 3.0 的 bug 修复，以及一些小优化，而且作为 LTS 版本，建议大家升级。值得一提的是.net core 2.2 这个月就要寿终正寝了，微软将不再提供支持，如果你在使用 2.2 ，强烈建议升级到 3.1，如果在使用 2.1，尤其是公司项目，可以暂时不用着急升级，2.1也是 LTS 版本&lt;/p&gt;
&lt;p&gt;总体来说，从 .net core 3.0 更新到 .net core 3.1 还是比较简单的，并没有遇到什么问题&lt;/p&gt;
&lt;h2 id=&quot;类库更新&quot;&gt;类库更新&lt;/h2&gt;
&lt;p&gt;类库更新起来和 .net core 3.0 差不多，要增加对 asp.net core 3.1 的支持，需要 &lt;code&gt;TargetFrameworks&lt;/code&gt; 增加对 &lt;code&gt;netcoreapp3.1&lt;/code&gt; 的支持&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/489462/201912/489462-20191205000127919-1283708759.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;TargetFramework&lt;/code&gt; 为 &lt;code&gt;netcoreapp3.0&lt;/code&gt; 和 &lt;code&gt;netcoreapp3.1&lt;/code&gt; 时添加 Framework 引用&lt;/p&gt;
&lt;p&gt;&lt;code&gt;&amp;lt;FrameworkReference Include=&quot;Microsoft.AspNetCore.App&quot; /&amp;gt;&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/489462/201912/489462-20191205000225327-556066055.png&quot;/&gt;&lt;/p&gt;
&lt;h2 id=&quot;应用更新&quot;&gt;应用更新&lt;/h2&gt;
&lt;h3 id=&quot;targetframework-更新&quot;&gt;&lt;code&gt;TargetFramework&lt;/code&gt; 更新&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;TargetFramework&lt;/code&gt; 从 &lt;code&gt;netcoreapp3.0&lt;/code&gt; 更新为 &lt;code&gt;netcoreapp3.1&lt;/code&gt;&lt;/p&gt;
&lt;h3 id=&quot;dockerfile-更新&quot;&gt;Dockerfile 更新&lt;/h3&gt;
&lt;p&gt;Dockerfile 只需要把镜像的 tag 从 3.0 更新到 3.1 即可&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/489462/201912/489462-20191205001450899-171028139.png&quot;/&gt;&lt;/p&gt;
&lt;h3 id=&quot;package-版本更新可选&quot;&gt;Package 版本更新（可选）&lt;/h3&gt;
&lt;p&gt;3.0 版本的包可以更新为 3.1 版本&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/489462/201912/489462-20191205001835302-953669549.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;注：EF Core 如果之前使用的是 3.0 版本，强烈建议更新到 3.1 版本，EF Core 3.1版本修复了好多bug，如果之前使用的 2.x 版本的 EF Core 可以不更新&lt;/p&gt;
&lt;h2 id=&quot;more&quot;&gt;More&lt;/h2&gt;
&lt;p&gt;本文所讲适用于从 .net core 3.0 升级到 .net core 3.1 版本，如果从 2.x 版本更新到 3.1，可以参考此前的 asp.net core 3.0 更新简记 &lt;a href=&quot;https://www.cnblogs.com/weihanli/p/notes-on-update-aspnetcore3_0.html&quot; class=&quot;uri&quot;&gt;https://www.cnblogs.com/weihanli/p/notes-on-update-aspnetcore3_0.html&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;reference&quot;&gt;Reference&lt;/h2&gt;
</description>
<pubDate>Wed, 04 Dec 2019 16:25:00 +0000</pubDate>
<dc:creator>WeihanLi</dc:creator>
<og:description>asp.net core 从 3.0 更新到 3.1</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/weihanli/p/migrate-to-netcore3_1-from-netcore3_0.html</dc:identifier>
</item>
<item>
<title>HDFS原理概念扫盲 - bainianminguo</title>
<link>http://www.cnblogs.com/bainianminguo/p/11986605.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/bainianminguo/p/11986605.html</guid>
<description>&lt;h3&gt;1、概述&lt;/h3&gt;
&lt;p&gt;hdfs文件系统主要设计为了存储大文件的文件系统；如果有个TB级别的文件，我们该怎么存储呢？分布式文件系统未出现的时候，一个文件只能存储在个服务器上，可想而知，单个服务器根本就存储不了这么大的文件；退而求其次，就算一个服务器可以存储这么大的文件，你如果想打开这个文件，效率会高吗&lt;/p&gt;
&lt;p&gt;hdfs的出现就是为了解决上面的问题&lt;/p&gt;

&lt;p&gt;hdfs为了满足大文件的存储和可读性，对数据进行切成多个小块进行存储，同时为了保证数据的可靠性，又对每个小块数据做复制，然后分别存储到多个节点中&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1101486/201912/1101486-20191204223827667-430209175.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;


&lt;p&gt;hdfs2.7.3后，默认每个块的大小是128MB，在hdfs1.0的时候，默认每个块的大小是64MB&lt;/p&gt;
&lt;p&gt;可以通过修改hdfs的配置文件自定义块大小&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;32&quot;&gt;
&lt;pre&gt;
hdfs-site.xml文件中的dfs.blocksize
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;默认每个块的副本数是3，可以通过修改hdfs的配置文件自定义副本数&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;32&quot;&gt;
&lt;pre&gt;
hdfs-site.xml的dfs.replication
&lt;/pre&gt;&lt;/div&gt;

&lt;h3&gt;二、hdfs的结构体系&lt;/h3&gt;
&lt;p&gt;hdfs是一个分布式的文件系统，采用主从（master/slave）的结构体系，一个hdfs集群由NameNode和多个datanode组成，其中namenode作为主节点，DataNode为从节点&lt;/p&gt;
&lt;p&gt;Namenode简称NN&lt;/p&gt;
&lt;p&gt;DataNode简称DN&lt;/p&gt;
&lt;p&gt;NN的作用&lt;/p&gt;
&lt;p&gt;a、存储元数据信息&lt;/p&gt;
&lt;p&gt;b、元数据存储两份，一份在内存中，一份在硬盘中&lt;/p&gt;
&lt;p&gt;c、保存文件、block、datanode的映射关系&lt;/p&gt;

&lt;p&gt;DN的作用&lt;/p&gt;
&lt;p&gt;a、存储block信息&lt;/p&gt;
&lt;p&gt;b、block存储在硬盘中&lt;/p&gt;
&lt;p&gt;c、维护block和文件的映射关系&lt;/p&gt;

&lt;p&gt;数据存储在内存中是为了读取性能，保证效率，数据存储在硬盘中，为了持久化数据，保证数据不丢失&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1101486/201912/1101486-20191204225234652-1969483996.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;



&lt;h3&gt;三、hdfs的优缺点&lt;/h3&gt;
&lt;h4&gt;1、hdfs的优点&lt;/h4&gt;
&lt;p&gt;a、支持超大文件&lt;/p&gt;
&lt;p&gt;支持超大文件，这里的超大文件几百MB，几百GB，甚至TB级别大小的文件，一般来说hadoop的文件系统会存储TB级别或者 PB级别的数据，所以在企业节点中，数据节点可能有上千个&lt;/p&gt;
&lt;p&gt;b、检测和快速 应对 硬件故障&lt;/p&gt;
&lt;p&gt;在集群中 环境中，硬件故障是常见的问题，因为 有上千台服务器，这样会导致高故障率，因此故障检测和自动 恢复 是hdfs文件系统 的一个设计目标&lt;/p&gt;
&lt;p&gt;c、流式数据访问&lt;/p&gt;
&lt;p&gt;Hdfs的数据处理规模比较大，应用一次要 访问大量的 数据，同时这些应用一般都是批量处理，而不是用户交互式 处理，应用程序能以流的形式访问数据集，主要是数据的吞吐量，而不是访问速度；适合做离线数据的处理&lt;/p&gt;
&lt;p&gt;d、简化的一致性模型&lt;/p&gt;
&lt;p&gt;大部分 hdfs操作文件时，需要一次 写入，多次读取，在 hdfs文件系统中，一个文件块一旦经过 创建，写入，关闭后就不允许 修改了，在hdfs2.7后 ，才允许对block进行追加修改，但是不能改变已有的数据，这样简单的一致性模型，保证数据操作的简单化&lt;/p&gt;
&lt;p&gt;e、高容错性&lt;/p&gt;
&lt;p&gt;数据自动保存多个 副本，副本丢失自动恢复&lt;/p&gt;
&lt;p&gt;f、可构建在廉价的机器上&lt;/p&gt;
&lt;p&gt;构建在廉价的机器上，可以启动通过扩展机器 个数里线性提高存储能力&lt;/p&gt;

&lt;h4&gt;2、hdfs的缺点&lt;/h4&gt;
&lt;p&gt;a、低延迟数据访问&lt;/p&gt;
&lt;p&gt;低延迟数据 ，如果用户进行交互的应用，比如京东，需要数据在毫秒后者秒级范围内得到响应，由于 hadoop对高吞吐 模型 做了优化，牺牲了获取数据的延迟，所以对于低延时的应用，不适合 用hadoop，而且hdfs的数据也不是结构化的数据&lt;/p&gt;
&lt;p&gt;b、不适合大量小文件&lt;/p&gt;
&lt;p&gt;Hdfs支持超大的文件，是通过数据分别在不同的数据节点，数据的元数据保存在namenode上，namenode的内存大小决定了hdfs可以保存的文件数量，虽然现在 内存已经很大，但是大量的 小文件还是会 影响namenode的节点性能，每个block会占用一片内存空间&lt;/p&gt;
&lt;p&gt;c、不支持多次写入文件，修改文件&lt;/p&gt;
&lt;p&gt;为了保证吞吐量，设计为这样&lt;/p&gt;

&lt;h3&gt;四、hdfs的技术细节&lt;/h3&gt;
&lt;h4&gt;1、Block&lt;/h4&gt;
&lt;p&gt;数据块（block）是hdfs存储文件的基本单位&lt;/p&gt;
&lt;p&gt;在hdfs中，有一个特别重要的概念，数据块（block），前面介绍过，在hdfs存储的文件都是超大数据的文件，我们可以把这个超大规模的文件以一个标准切分成几块，分别存储到不同的磁盘上，这个标准就是block&lt;/p&gt;
&lt;p&gt;a、为了存储大文件，一个服务器很难存储超大型的文件，拆分的话，文件块可以保存在不同的磁盘，在hdfs文件系统中，一个文件可以分成不同的block存储在不同的磁盘上&lt;/p&gt;
&lt;p&gt;b、简化存储系统，这样就不需要管理文件，而是直接管理文件块就可以了&lt;/p&gt;
&lt;p&gt;c、有利于数据的复制，在hdfs系统中，一个block块一般会复制三份（可以修改），比如复制一个1TB的数据和复制多个128MB的文件复制哪个更快？&lt;/p&gt;

&lt;p&gt;对于一个文件而言，一个block id从0开始，按照固定的大小，顺序对文件进行划分和编号，划分好的每一块称一个block。Hdfs默认的block的大小是128MB，所以一个256MB的文件，共有256/128=2个块&lt;/p&gt;
&lt;p&gt;不同于普通的文件系统（比如ext4或者ntfs），hdfs中，如果一个文件小于一个数据块的大小，并不用占用整个数据存储空间，而是仅仅会占用文件实际大小的空间&lt;/p&gt;

&lt;h4&gt;2、Namenode&lt;/h4&gt;
&lt;p&gt;Namenode是维护hdfs中的元信息，包括文件和block之间的映射关系，block数量的信息，block和datanode之间的关系信息，数据格式参照入下&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;40&quot;&gt;
&lt;pre&gt;
Filename replicas block-&lt;span&gt;ids id2host

&lt;/span&gt;/test/log，3，{b1,b2},{b1:[host0,host1,host2]} ,{b2:[host3,host4,host5]}
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Namenode中的元数据信息存储在内存/磁盘中，内存中为实时信息，磁盘中为数据的持久化存储使用使用&lt;/p&gt;

&lt;p&gt;在磁盘中存储的信息主要下面两个&lt;/p&gt;
&lt;p&gt;fsimage：元数据的镜像文件，存储namenode元数据信息&lt;/p&gt;
&lt;p&gt;edit：操作日志文件（比如你上次，追加内容，这里只有写操作的日志，读操作不会记录）&lt;/p&gt;

&lt;p&gt;下面重点讲一下这2个文件流程&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1101486/201912/1101486-20191204231630791-470988332.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;


&lt;p&gt;上面的流程如果明白了，就会发现有2个问题&lt;/p&gt;
&lt;p&gt;a、一般namenode会持续运行，不会被启动，那么edit文件会增长很大，这个时候就不好管理&lt;/p&gt;
&lt;p&gt;b、如果edit文件增长到很大，那么每次namenode启动合并edit文件和fsimage就会很久，那namenode启动就会很慢&lt;/p&gt;

&lt;p&gt;这个时候就有了SNN（second NameNode）&lt;/p&gt;
&lt;p&gt;听名字，大家以为SNN是NN的热备份，其实SNN是NN的协助者，帮助进行元数据合并的&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1101486/201912/1101486-20191204232641858-1842337762.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;



&lt;p&gt;a、SNN会定时通过http的get方法从NN获取最新的edit和fsimage文件&lt;/p&gt;
&lt;p&gt;b、然后NN会生成一个空的edit文件，该文件继续接受client的i写请求操作日志&lt;/p&gt;
&lt;p&gt;c、SNN拿到最新的edit文件和fsimage文件，进行合并，生成最新的fsimage文件&lt;/p&gt;
&lt;p&gt;d、SNN通过http的post方法把最新的fsimage文件发送到NN&lt;/p&gt;
&lt;p&gt;e、这样就把上面那2个文件解决了&lt;/p&gt;

&lt;p&gt;触发checkpoint的条件有3个&lt;/p&gt;
&lt;p&gt;a、默认是3600s合并一次，可以通过修改fs.checkpoint.period自定义&lt;/p&gt;
&lt;p&gt;b、根据edit.log文件的大小触发合并，默认是64MB会触发合并，可以通过修改fs.checkpoint.size自定义&lt;/p&gt;

&lt;h4&gt;3、Datanode&lt;/h4&gt;
&lt;p&gt;在hadoop中，数据是存放在datanode上面的，是以block的形式存储的，datanode节点会不断的向namenode节点发送心跳报告，初始化，每个数据节点将当前存储的数据告知namenode节点，通过向namenode主动发送心跳保持联系，3s会发送一次&lt;/p&gt;
&lt;p&gt;Datanode节点在工作的过程中，数据节点仍会不断的更新namenode节点与之对应的元数据信息，并接受来自namenode节点的指令，创建，移动或者删除本地磁盘上的数据块&lt;/p&gt;
&lt;p&gt;如果10min都没有收到nd的心跳，则认为其已经挂了，并copy其上的block到其他dn&lt;/p&gt;

&lt;h3&gt;五、hdfs的执行流程&lt;/h3&gt;
&lt;h4&gt;1、读数据流程&lt;/h4&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1101486/201912/1101486-20191204234610808-1799854516.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;





&lt;p&gt;a、client向远程namenode发起读请求&lt;/p&gt;
&lt;p&gt;b、NN会视情况返回文件的部分或者全部block列表，对于每个block，namenode都会返回该block的地址和副本的DN的地址&lt;/p&gt;
&lt;p&gt;c、客户端会选取最接近的DN来读取block&lt;/p&gt;
&lt;p&gt;d、读取完当前的block的数据后，关闭与当前的DN的连接，并为读取下一个block寻找最佳的DN&lt;/p&gt;
&lt;p&gt;e、当读完列表的block后，且文件读取还没有结束，客户端会继续向NN获取下一批的block列表&lt;/p&gt;
&lt;p&gt;f、读取完一个block都会进行checksum验证，如果读取的时候出现错误，client会通知NN，然后在从下一个拥有该block块的DN继续读取数据&lt;/p&gt;


&lt;p&gt;2、写数据流程&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1101486/201912/1101486-20191204235450286-1939988219.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;





&lt;p&gt;a、client向namenode发起写请求&lt;/p&gt;
&lt;p&gt;b、NN会检查路径是否存在、权限是否正确、文件是否存在&lt;/p&gt;
&lt;p&gt;c、条件满足后，client开始写入文件，首先开发库会将文件拆分成多个packets，并在内部以数据队列的形式来管理这些packet，并向NN申请新的blocks，获取用来存储block和副本的DN的列表，&lt;/p&gt;
&lt;p&gt;d、开始已经pipiline（管道）的形式将packet写入到第一个DN中，当第一个DN写入成功后，在将其传递给下一个DN，直到最后一个DN存储完成&lt;/p&gt;
&lt;p&gt;e、然后开始上传下一个packet&lt;/p&gt;

&lt;h4&gt; 3、删除流程&lt;/h4&gt;

&lt;p&gt;a、现在NN上执行节点名字的删除&lt;/p&gt;
&lt;p&gt;b、当NN上执行delete方式时，他这是标记操作涉及需要被删除的数据块，而不是主动联系这些数据块所在的DN节点&lt;/p&gt;
&lt;p&gt;c、当保存这些数据库的DN节点向NN节点发送心跳时，在心跳应答里，NN会向DN发出指令，从而把数据删除&lt;/p&gt;
&lt;p&gt;d、所以在执行delete方法后一段时间内，数据块才会被删除掉&lt;/p&gt;

</description>
<pubDate>Wed, 04 Dec 2019 16:00:00 +0000</pubDate>
<dc:creator>bainianminguo</dc:creator>
<og:description>1、概述 hdfs文件系统主要设计为了存储大文件的文件系统；如果有个TB级别的文件，我们该怎么存储呢？分布式文件系统未出现的时候，一个文件只能存储在个服务器上，可想而知，单个服务器根本就存储不了这么大</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/bainianminguo/p/11986605.html</dc:identifier>
</item>
<item>
<title>图像风格迁移原理 - |旧市拾荒|</title>
<link>http://www.cnblogs.com/xiaoyh/p/11932095.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/xiaoyh/p/11932095.html</guid>
<description>&lt;p&gt;&lt;span&gt;所谓&lt;span&gt;图像风格迁移&lt;/span&gt;，是指利用算法学习著名画作的风格，然后再把这种风格应用到另外一张图片上的技术。著名的图像处理应用Prisma是利用风格迁移技术，普通用户的照片自动变换为具有艺术家风格的图片。&lt;/span&gt;&lt;/p&gt;

&lt;h2&gt;1、原始图像风格迁移的原理&lt;/h2&gt;
&lt;p&gt;&lt;span&gt;　　在学习原始的图像风格迁移之前，可以在先看看ImageNet图像识别模型VGGNet（&lt;span&gt;&lt;a class=&quot;entrylistItemTitle&quot; href=&quot;https://www.cnblogs.com/xiaoyh/p/11735686.html&quot;&gt;微调(Fine-tune)原理&lt;/a&gt;&lt;/span&gt;）。事实上，可以这样理解VGGNet的结构：前面的卷积层是从图像中提取“特征”，而后面的全连接层把图片的“特征”转换为类别概率。其中，VGGNet中的浅层（如conv1_1，conv1_2），提取的特征往往是比较简单的（如检测点、线、亮度），VGGNet中的深层（如conv5_1，conv5_2），提取的特征往往比较复杂（如有无人脸或某种特定物体）。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　VGGNet本意是输入图像，提取特征，并输出图像类别。图像风格迁移正好与其相反，&lt;span&gt;输入的是特征，输出对应这种特征的图片&lt;/span&gt;，如下图所示：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;　　　&lt;img src=&quot;https://img2018.cnblogs.com/i-beta/1126989/201911/1126989-20191126221353841-1557215891.png&quot; alt=&quot;&quot; width=&quot;553&quot; height=&quot;131&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　具体来说，风格迁移使&lt;span&gt;用卷积层的中间特征还原出对应这种特征的原始图像&lt;/span&gt;。如下图所示，先选取一幅原始图像，经过VGGNet计算后得到各个卷积层的特征。接下来，根据这些卷积层的特征，还原出对应这种特征的原始图像。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;　　　&lt;img src=&quot;https://img2018.cnblogs.com/i-beta/1126989/201911/1126989-20191126221843075-1494814717.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　下面的a、b、c、d、e分别为使用conv1_2、conv2_2、conv3_2、conv4_2、conv5_2的还原图像。可以发现：浅层的还原效果往往比较好，卷积特征基本保留了所有原始图像中形状、位置、颜色、纹理等信息；深层对应的还原图像丢失了部分颜色和纹理信息，但大体保留原始图像中物体的形状和位置。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;　　　&lt;img src=&quot;https://img2018.cnblogs.com/i-beta/1126989/201911/1126989-20191126222128734-1574147705.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　还原图像的方法是&lt;span&gt;梯度下降法&lt;/span&gt;。设原始图像为$\vec{p}$，期望还原的图像为$\vec{x}$（即自动生成的图像）。使用的卷积是第$l$层，原始图像$\vec{p}$在第$l$层的卷积特征为$P_{ij}^{l}$。$i$表示卷积的第$i$个通道，$j$表示卷积的第$j$个位置。通常卷积的特征是三维的，三维坐标分别对应（高、宽、通道）。此处不考虑具体的高和宽，只考虑位置$j$，相当于把卷积“压扁”了。比如一个10x10x32的卷积特征，对应$1\leqslant i\leqslant 32$，$1\leqslant j\leqslant 100$。对于生成图像$\vec{x}$，同样定义它在$l$层的卷积特征为$F_{ij}^{l}$。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　有了上面这些符号后，可以写出“&lt;span&gt;内容损失&lt;/span&gt;”（Content Loss）。内容损失$L_{content}(\vec{p},\vec{x},l)$的定义是：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　$L_{content}(\vec{p},\vec{x},l)=\frac{1}{2}\sum\limits_{i,j}(F_{ij}^{l}-P_{ij}^{l})^{2}$&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　$L_{content}(\vec{p},\vec{x},l)$描述了原始图像$\vec{p}$和生成图像$\vec{x}$在内容上的“差异”。&lt;span&gt;内容损失越小，说明它们的内容越接近；内容损失越大，说明它们的内容差距也越大&lt;/span&gt;。先使用原始图像$\vec{p}$计算出它的卷积特征$P_{ij}^{l}$，同时随机初始化$\vec{x}$。接着，以内容损失$L_{content}(\vec{p},\vec{x},l)$为优化目标，通过梯度下降法逐步改变$\vec{x}$。经过一定步数后，得到的$\vec{x}$是希望的还原图像了。在这个过程中，内容损失$L_{content}(\vec{p},\vec{x},l)$应该是越来越小的。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　除了还原图像原本的“内容”之外，另一方面，还希望还原图像的“风格”。那么，图像的“&lt;span&gt;风格&lt;/span&gt;”应该怎么样来表示呢？一种方法是使用图像的卷积层特征的Gram矩阵。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　&lt;span&gt;Gram矩阵是关于一组向量的内积的对称矩阵&lt;/span&gt;，例如，向量组$\vec{x_{1}}$,$\vec{x_{2}}$,...,$\vec{x_{n}}$的Gram矩阵是&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;　　$\begin{bmatrix}&lt;br/&gt;(\vec{x_{1}},\vec{x_{1}}) &amp;amp;(\vec{x_{1}},\vec{x_{2}}) &amp;amp;... &amp;amp;(\vec{x_{1}},\vec{x_{n}}) \\&lt;br/&gt;(\vec{x_{2}},\vec{x_{1}}) &amp;amp; (\vec{x_{2}},\vec{x_{2}}) &amp;amp; ... &amp;amp; (\vec{x_{2}},\vec{x_{n}})\\&lt;br/&gt;...&amp;amp; ...&amp;amp; ...&amp;amp;... \\&lt;br/&gt;(\vec{x_{n}},\vec{x_{1}})&amp;amp; (\vec{x_{n}},\vec{x_{2}}) &amp;amp; ... &amp;amp; (\vec{x_{n}},\vec{x_{n}})&lt;br/&gt;\end{bmatrix}$&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　通常取内积为欧几里得空间上的标准内积，即$(\vec{x_{i}},\vec{x_{j}}) = \vec{x_{i}}^{T}\vec{x_{j}}$。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　设卷积层的输出为$F_{ij}^{l}$，那么这个卷积特征对应的Gram矩阵的第$i$行第$j$个元素定义为&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　$G_{ij}^{l}=\sum\limits_{k}F_{ik}^{l}F_{jk}^{l}$&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　设在第$l$层中，卷积特征的通道数为$N_{l}$，卷积的高、宽乘积为$M_{l}$，那么$F_{ij}^{l}$满足$1\leqslant i\leqslant N_{l}$，$1\leqslant j\leqslant M_{l}$。G实际是向量组$F_{1}^{l}$，$F_{2}^{l}$，...，$F_{i}^{l}$，...，$F_{N_{l}}^{l}$的Gram矩阵，其中，其中$F_{i}^{l}=(F_{i1}^{l},F_{i2}^{l},...,F_{ij}^{l},...,F_{iM_{l}}^{l})$。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　此处数学符号较多，因此再举一个例子来加深读者对此Gram矩阵的理解。假设某一层输出的卷积特征为10x10x32，即它是一个宽、高均为10，通道数为32的张量。$F_{1}^{l}$表示第一个通道的特征，它是一个100维的向量，$F_{2}^{l}$表示第二个通道的特征，它同样是一个100维的向量，它对应的Gram矩阵G是&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;　　$\begin{bmatrix}&lt;br/&gt;(F_{1}^{l})^{T}(F_{1}^{l}) &amp;amp; (F_{1}^{l})^{T}(F_{2}^{l}) &amp;amp; ... &amp;amp;(F_{1}^{l})^{T}(F_{32}^{l}) \\&lt;br/&gt;(F_{2}^{l})^{T}(F_{1}^{l}) &amp;amp; (F_{2}^{l})^{T}(F_{2}^{l}) &amp;amp; ... &amp;amp; (F_{2}^{l})^{T}(F_{32}^{l})\\&lt;br/&gt;...&amp;amp; ... &amp;amp;... &amp;amp;... \\&lt;br/&gt;(F_{32}^{l})^{T}(F_{1}^{l})&amp;amp; (F_{32}^{l})^{T}(F_{2}^{l}) &amp;amp; ... &amp;amp; (F_{32}^{l})^{T}(F_{32}^{l})&lt;br/&gt;\end{bmatrix}$&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　Gram矩阵可以在一定程度上反映原始图片中的“风格” 。仿照“内容损失”，还可以定义一个“&lt;span&gt;风格损失&lt;/span&gt;”（Style Loss）。设原始图像为$\vec{a}$，要还原的风格图像为$\vec{x}$，先计算出原始图像某一次卷积的Gram矩阵为$A^{l}$，要还原的图像$\vec{x}$经过同样的计算得到对应卷积层的Gram矩阵是$G^{l}$，风格损失定义为&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　$L_{style}(\vec{p},\vec{x},l)=\frac{1}{4N_{l}^{2}M_{l}^{2}}\sum \limits_{i,j}(A_{ij}^{l}-G_{ij}^{l})^{2}$&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　分母上的$4N_{l}^{2}M_{l}^{2}$是一个归一化项，目的是&lt;span&gt;防止风格损失的数量级相比内容损失过大&lt;/span&gt;。在实际应用中，常常利用多层而非一层的风格损失，多层的风格损失是单层风格损失的加权累加，即$L_{style}(\vec{p},\vec{x})=\sum \limits_{i}w_{l}L_{style}(\vec{p},\vec{x},l)$，其中$w_{l}$表示第$l$层权重。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　利用风格损失，可以还原出图像的风格了。如下图所示，尝试还原梵高的著名画作《星空》的风格。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;　　　&lt;img src=&quot;https://img2018.cnblogs.com/i-beta/1126989/201912/1126989-20191201193434399-1153313738.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　 &lt;img src=&quot;https://img2018.cnblogs.com/i-beta/1126989/201912/1126989-20191201193504752-1516170471.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　其中，图a是由conv1_1的风格损失还原的，图b是由conv1_1，conv2_1两层的风格损失还原的，图c是由conv1_1，conv2_1，conv3_1，图d为conv1_1，conv2_1，conv3_1，conv4_1风格损失还原的。&lt;span&gt;使用浅层还原的“风格图像”的纹理尺度往往比较小&lt;/span&gt;，只保留了颜色和局部的纹理（如图a）；组合深层、浅层还原出的“风格图像”更加真实且接近原图片（如图e）。&lt;/span&gt;&lt;br/&gt;&lt;span&gt;总结一下，到目前为止介绍了两个内容：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　（1）利用内容损失还原图像内容。&lt;/span&gt;&lt;br/&gt;&lt;span&gt;　　（2）利用风格损失还原图像风格。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　&lt;span&gt;那么，可不可以将内容损失和风格损失结合起来，在还原一张图像的同时还原另一张图像的风格呢？答案是肯定的，这是图像风格迁移的基本算法。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　设原始的内容图像为$\vec{p}$，原始的风格图像为$\vec{a}$，待生成的图像为$\vec{x}$。希望$\vec{x}$可以保持内容图像$\vec{p}$的内容，同时具备风格图像$\vec{a}$的风格。因此组合$\vec{p}$的内容损失和$\vec{a}$的风格损失，定义&lt;span&gt;总的损失函数&lt;/span&gt;为&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　$L_{total}(\vec{p},\vec{a},\vec{x})=\alpha L_{content}(\vec{p},\vec{x})+\beta L_{style}(\vec{a},\vec{x})$&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　$\alpha$，$\beta$是&lt;span&gt;平衡两个损失&lt;/span&gt;的超参数。如果$\alpha$偏大，还原的图像会更接近于$\vec{p}$中，如果$\beta$偏大，还原的图像会更接近$\vec{a}$。使用总的损失函数可以组合$\vec{p}$的内容和$\vec{x}$的风格，这实现了图像风格的迁移。部分还原的图像如下图所示&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;　　　&lt;img src=&quot;https://img2018.cnblogs.com/i-beta/1126989/201912/1126989-20191201195027513-1002812676.png&quot; alt=&quot;&quot; width=&quot;599&quot; height=&quot;447&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　以上是原始的图像风格迁移的基本原理。事实上，原始的图像风格迁移速度非常慢，在CPU上生成一张图片需要数十分钟甚至几个小时，即使在GPU上也需要数分钟才能生成一张较大的图片，这大大的限制了这项技术的使用场景。速度慢的原因在于，要使用总损失$L_{total}(\vec{p},\vec{a},\vec{x})$优化图片$\vec{x}$，这意味着生成一张图片需要&lt;span&gt;几百步梯度下降法的迭代&lt;/span&gt;，而每一步的迭代都需要耗费大量的时间。从另一个角度看，优化$\vec{x}$可以看作是一个“训练模型”的过程，以往都是针对模型参数训练，而这里训练的目标是图片$\vec{x}$，而训练模型一般都比执行训练好的模型要慢很多。下面将会讲到快速图像风格迁移，它把原来的“训练”的过程变成了一个“执行”的过程，因此大大加快了生成风格话图片的过程。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;　　原始的图像风格迁移用一个损失$L_{total}(\vec{p},\vec{a},\vec{x})$来衡量$\vec{x}$是否成功组合了$\vec{p}$的内容和$\vec{a}$的风格。然后以$L_{total}(\vec{p},\vec{a},\vec{x})$为目标，用梯度下降法来逐步迭代$\vec{x}$。因为在生成图像的过程中需要逐步对$\vec{x}$做优化，所以速度比较慢。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　快速图像风格迁移的方法是：&lt;span&gt;不使用优化的方法来逐步迭代生成$\vec{x}$，而是使用一个神经网络之间生成$\vec{x}$&lt;/span&gt;。对应的网络结构如下图所示：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;　　　&lt;img src=&quot;https://img2018.cnblogs.com/i-beta/1126989/201912/1126989-20191201200345807-1908892889.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　整个系统由两个神经网络组成，它们在图中由两个虚线框分别标出。&lt;span&gt;左边的是图像生成网络，右边是损失网络&lt;/span&gt;。损失网络实际上是VGGNet，这与原始的风格迁移是一致的。同原始图像风格迁移一样，利用损失网络来定义内容损失、风格损失。这个损失用来训练图像生成网络。图像生成网络的职责是生成某一种风格的图像，它的输入是一个图像，输出同样是一个图像。由于生成图像只需要在网络中计算一遍，所以速度比原始图像风格迁移提高很多。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　同样使用数学符号严格地阐述上面地过程：设输入的图像为$\vec{x}$，经过图像生成网络生成的图像为$\vec{y}$。$\vec{y}$在内容上应该与原始的内容图像$\vec{y}_{c}$接近，因此可以利用损失网络定义内容损失$L_{content}(\vec{y},\vec{y}_{c})$，内容损失使用的是VGG-16中的relu3_3层输出的特征，对应上图中的$l_{feat}^{\phi ,relu3\_3}$。另一方面，我们还希望$\vec{y}$具有目标风格图像$\vec{y}_{s}$的风格，因此又可以定义一个风格损失$L_{total}(\vec{y},\vec{y}_{c},\vec{y}_{s})$。定义风格损失时使用了VGG-16的四个中间层relu1_2，relu2_2，relu3_3，relu4_3，对应图中的$l_{style}^{\phi ,relu1\_2}$、$l_{style}^{\phi ,relu2\_2}$、$l_{style}^{\phi ,relu3\_3}$、$l_{style}^{\phi ,relu4\_3}$。同样组合这两个损失得到一个总损失$L_{total}(\vec{y},\vec{y}_{c},\vec{y}_{s})$。利用总损失可以训练图像生成网络。训练完成后直接使用图像生成网络生成图像。值得一提的是，在整个训练过程中，一般只固定一种风格$\vec{y}_{s}$，而内容图像$\vec{y}_{c}$取和输入$\vec{x}$一样，即$\vec{y}_{s}$=$\vec{x}$。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　下面&lt;span&gt;详细的比较&lt;/span&gt;原始图像风格迁移与快速图像风格迁移。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;　　　&lt;img src=&quot;https://img2018.cnblogs.com/i-beta/1126989/201912/1126989-20191201215501175-1448989448.png&quot; alt=&quot;&quot; width=&quot;691&quot; height=&quot;163&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　这篇博客详细介绍了原始图像风格迁移的基本原理，其中内容损失、风格损失两种损失函数的定义尤为关键。接着还介绍了快速图像风格迁移的原理，以及它和原始图像风格迁移的&lt;span&gt;对比&lt;/span&gt;。&lt;/span&gt;&lt;/p&gt;

</description>
<pubDate>Wed, 04 Dec 2019 15:19:00 +0000</pubDate>
<dc:creator>|旧市拾荒|</dc:creator>
<og:description>所谓图像风格迁移，是指利用算法学习著名画作的风格，然后再把这种风格应用到另外一张图片上的技术。著名的图像处理应用Prisma是利用风格迁移技术，普通用户的照片自动变换为具有艺术家风格的图片。 一、图像</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/xiaoyh/p/11932095.html</dc:identifier>
</item>
<item>
<title>.Net Core使用分布式缓存Redis：基础 - 树杈</title>
<link>http://www.cnblogs.com/xwc1996/p/11973611.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/xwc1996/p/11973611.html</guid>
<description>&lt;h3&gt;一、前言&lt;/h3&gt;
&lt;p&gt;　　&lt;span&gt;Redis的介绍网上很多不再赘述。本次环境为net core 2.2，使用的StackExchange.Redis来操作Redis。&lt;/span&gt;&lt;/p&gt;
&lt;h3&gt;二、引用Microsoft.Extensions.Caching.StackExchangeRedis&lt;/h3&gt;
&lt;p&gt;　　&lt;span&gt;通过nuget搜索Microsoft.Extensions.Caching.StackExchangeRedis安装，因为依赖项版本的问题我这里用的版本是2.2.5，其本质上也是封装的StackExchange.Redis，但是它实现了net core规定的IDistributedCache接口。&lt;/span&gt;&lt;/p&gt;
&lt;h3&gt;三、添加redis服务&lt;/h3&gt;
&lt;p&gt;　　&lt;span&gt;在Startup.cs中的ConfigureServices中添加Redis的服务，会自动进行依赖注入。最简单的如下：&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;34&quot;&gt;
&lt;pre&gt;
        &lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt;&lt;span&gt; ConfigureServices(IServiceCollection services)
        {&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;......
            &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;添加redis连接&lt;/span&gt;
            services.AddStackExchangeRedisCache(options =&amp;gt;&lt;span&gt;
            {
                options.Configuration &lt;/span&gt;= &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;127.0.0.1:6379&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;;
                options.InstanceName &lt;/span&gt;= &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;SampleInstance&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;;
            });
            &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;......&lt;/span&gt;
        }    
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span&gt;　　InstaceName：实例名，加在redis的key前面的。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　Configuration：连接redis的链接。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　还存在一个优先级更高的ConfigurationOptions，可以配置多个redis服务的连接、密码等。&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;36&quot;&gt;
&lt;pre&gt;
        &lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt;&lt;span&gt; ConfigureServices(IServiceCollection services)
        {&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;.....
            &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;添加redis连接&lt;/span&gt;
            services.AddStackExchangeRedisCache(options =&amp;gt;&lt;span&gt;
            {
                options.ConfigurationOptions &lt;/span&gt;= &lt;span&gt;new&lt;/span&gt;&lt;span&gt; ConfigurationOptions()
                {
                    EndPoints &lt;/span&gt;= { { &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;127.0.0.1&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;, &lt;span&gt;6379&lt;/span&gt;&lt;span&gt; } },
                    &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;Password = &quot;123456&quot;&lt;/span&gt;
&lt;span&gt;                };
            });
            &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;......&lt;/span&gt;
        }
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　&lt;span&gt;具体的属性如下：&lt;/span&gt;&lt;/p&gt;
&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;&lt;span&gt;&lt;code&gt;配置选项&lt;/code&gt;&lt;/span&gt;&lt;/th&gt;
&lt;th&gt;&lt;span&gt;默认&lt;/span&gt;&lt;/th&gt;
&lt;th&gt;&lt;span&gt;含义&lt;/span&gt;&lt;/th&gt;
&lt;/tr&gt;&lt;/thead&gt;&lt;tbody readability=&quot;20.5&quot;&gt;&lt;tr readability=&quot;4&quot;&gt;&lt;td&gt;&lt;span&gt;&lt;code&gt;AbortOnConnectFail&lt;/code&gt;&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;&lt;span&gt;&lt;code&gt;true&lt;/code&gt;（&lt;code&gt;false&lt;/code&gt;在Azure上）&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;&lt;span&gt;如果为true，&lt;code&gt;Connect&lt;/code&gt;则在没有服务器可用时将不会创建连接&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;&lt;span&gt;&lt;code&gt;AllowAdmin&lt;/code&gt;&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;&lt;span&gt;&lt;code&gt;false&lt;/code&gt;&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;&lt;span&gt;启用一系列被认为具有风险的命令&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;&lt;span&gt;&lt;code&gt;ChannelPrefix&lt;/code&gt;&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;&lt;span&gt;&lt;code&gt;null&lt;/code&gt;&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;&lt;span&gt;所有发布/订阅操作的可选通道前缀&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;&lt;span&gt;&lt;code&gt;ConnectRetry&lt;/code&gt;&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;&lt;span&gt;&lt;code&gt;3&lt;/code&gt;&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;&lt;span&gt;初始期间重复尝试连接的次数 &lt;code&gt;Connect&lt;/code&gt;&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;&lt;span&gt;&lt;code&gt;ConnectTimeout&lt;/code&gt;&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;&lt;span&gt;&lt;code&gt;5000&lt;/code&gt;&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;&lt;span&gt;连接操作超时（毫秒）&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;4&quot;&gt;&lt;td&gt;&lt;span&gt;&lt;code&gt;ConfigurationChannel&lt;/code&gt;&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;&lt;span&gt;&lt;code&gt;__Booksleeve_MasterChanged&lt;/code&gt;&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;&lt;span&gt;用于传达配置更改的广播频道名称&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;3&quot;&gt;&lt;td&gt;&lt;span&gt;&lt;code&gt;ConfigCheckSeconds&lt;/code&gt;&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;&lt;span&gt;&lt;code&gt;60&lt;/code&gt;&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;&lt;span&gt;检查配置的时间（秒）。如果支持，它可以充当交互式套接字的保持活动状态。&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;&lt;span&gt;&lt;code&gt;DefaultDatabase&lt;/code&gt;&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;&lt;span&gt;&lt;code&gt;null&lt;/code&gt;&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;&lt;span&gt;默认数据库索引，从&lt;code&gt;0&lt;/code&gt;到&lt;code&gt;databases - 1&lt;/code&gt;&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;&lt;span&gt;&lt;code&gt;KeepAlive&lt;/code&gt;&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;&lt;span&gt;&lt;code&gt;-1&lt;/code&gt;&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;&lt;span&gt;发送消息以帮助套接字保持活动的时间（秒）（默认为60秒）&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;span&gt;&lt;code&gt;ClientName&lt;/code&gt;&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;&lt;span&gt;&lt;code&gt;null&lt;/code&gt;&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;&lt;span&gt;标识Redis中的连接&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;span&gt;&lt;code&gt;Password&lt;/code&gt;&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;&lt;span&gt;&lt;code&gt;null&lt;/code&gt;&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;&lt;span&gt;Redis服务器密码&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;&lt;span&gt;&lt;code&gt;Proxy&lt;/code&gt;&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;&lt;span&gt;&lt;code&gt;Proxy.None&lt;/code&gt;&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;&lt;span&gt;使用中的代理类型（如果有）；例如“ twemproxy”&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;&lt;span&gt;&lt;code&gt;ResolveDns&lt;/code&gt;&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;&lt;span&gt;&lt;code&gt;false&lt;/code&gt;&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;&lt;span&gt;指定DNS解析应该是明确且渴望的，而不是隐式的&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;&lt;span&gt;&lt;code&gt;ResponseTimeout&lt;/code&gt;&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;&lt;span&gt;&lt;code&gt;SyncTimeout&lt;/code&gt;&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;&lt;span&gt;决定套接字是否不健康的时间（毫秒）&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;span&gt;&lt;code&gt;Ssl&lt;/code&gt;&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;&lt;span&gt;&lt;code&gt;false&lt;/code&gt;&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;&lt;span&gt;指定应使用SSL加密&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;&lt;span&gt;&lt;code&gt;SslHost&lt;/code&gt;&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;&lt;span&gt;&lt;code&gt;null&lt;/code&gt;&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;&lt;span&gt;在服务器的证书上强制使用特定的SSL主机身份&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;&lt;span&gt;&lt;code&gt;SslProtocols&lt;/code&gt;&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;&lt;span&gt;&lt;code&gt;null&lt;/code&gt;&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;&lt;span&gt;使用加密连接时支持Ssl / Tls版本。使用“ |” 提供多个值。&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;&lt;span&gt;&lt;code&gt;SyncTimeout&lt;/code&gt;&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;&lt;span&gt;&lt;code&gt;5000&lt;/code&gt;&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;&lt;span&gt;允许同步操作的时间（毫秒）&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;&lt;span&gt;&lt;code&gt;TieBreaker&lt;/code&gt;&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;&lt;span&gt;&lt;code&gt;__Booksleeve_TieBreak&lt;/code&gt;&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;&lt;span&gt;在模棱两可的主方案中用于选择服务器的密钥&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;4&quot;&gt;&lt;td&gt;&lt;span&gt;&lt;code&gt;DefaultVersion&lt;/code&gt;&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;&lt;span&gt;（&lt;code&gt;3.0&lt;/code&gt;在Azure中，否则&lt;code&gt;2.0&lt;/code&gt;）&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;&lt;span&gt;Redis版本级别（在服务器不可用时有用）&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;span&gt;&lt;code&gt;WriteBuffer&lt;/code&gt;&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;&lt;span&gt;&lt;code&gt;4096&lt;/code&gt;&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;&lt;span&gt;输出缓冲区的大小&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;h3&gt;四、操作Redis&lt;/h3&gt;
&lt;p&gt;　　&lt;span&gt;在控制器中通过构造函数依赖注入获取redis连接对象。&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;33&quot;&gt;
&lt;pre&gt;
&lt;span&gt;public&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;&lt;span&gt; HomeController : Controller
{
　　&lt;/span&gt;&lt;span&gt;private&lt;/span&gt; &lt;span&gt;readonly&lt;/span&gt;&lt;span&gt; IDistributedCache cache;
　　&lt;/span&gt;&lt;span&gt;public&lt;/span&gt;&lt;span&gt; HomeController(IDistributedCache _cache)
　　{
　　　　&lt;/span&gt;&lt;span&gt;this&lt;/span&gt;.cache =&lt;span&gt; _cache;
　　}
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　&lt;span&gt;由于是实现了IDistributedCache规定的接口Get、Set、Remove、Refresh等。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;　　&lt;span&gt;所以设置缓存（有则更新，无则新增）、获取缓存、刷新缓存(不是刷新值是刷新过期时间)和删除缓存的代码如下。&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;34&quot;&gt;
&lt;pre&gt;
&lt;span&gt;//&lt;/span&gt;&lt;span&gt;编辑缓存&lt;/span&gt;
&lt;span&gt;cache.SetString(key, value);
&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;获取缓存&lt;/span&gt;
&lt;span&gt;var&lt;/span&gt; values =&lt;span&gt; cache.GetString(key);
&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;更新缓存过期时间&lt;/span&gt;
&lt;span&gt;cache.RefreshAsync(key);
&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;删除缓存&lt;/span&gt;
cache.RemoveAsync(key);
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span&gt;　　如果想设置缓存过期时间则通过DistributedCacheEntryOptions，它可以设置滑动过期时间(SlidingExpiration)、绝对过期时间(AbsoluteExpiration)和相对于现在的绝对过期时间(AbsoluteExpirationRelativeToNow)。&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;35&quot;&gt;
&lt;pre&gt;
&lt;span&gt;var&lt;/span&gt; options = &lt;span&gt;new&lt;/span&gt; DistributedCacheEntryOptions().SetSlidingExpiration(TimeSpan.FromSeconds(&lt;span&gt;20&lt;/span&gt;&lt;span&gt;))；
cache.SetString(key, value, options);&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　&lt;span&gt;　通过redis的可视化工具Redis Desktop Manager可以看到缓存存储在一号库为hash类型，有我们存储的值、滑动过期时间和绝对过期时间。不过获取到的数据为string。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/i-beta/988132/201912/988132-20191203214347966-2079226315.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;h3&gt; &lt;span&gt;五、使用StackExchange.Redis&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;&lt;span&gt;　　上面的代码存在一个问题，就是IDistributedCache之后对缓存的存储默认为其规定格式的hash类型，虽然我们获取到的数据为string。这样我们想操作list、set等其他类型就不行了，并且不能指定库进行存储。所以为了更加灵活这时候就要直接用StackExchange.Redis。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　因为引用Microsoft.Extensions.Caching.StackExchangeRedis的时候已经带上了StackExchange.Redis.dll的依赖项，所以不用再引用了，否则在nuget中搜索StackExchange.Redis进行引用。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　&lt;strong&gt;&lt;span&gt;1.基本使用&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;　　&lt;span&gt;StackExchange.Redis 中核心对象是在 StackExchange.Redis 命名空间中的 ConnectionMultiplexer 类，这个对象隐藏了多个服务器的详细信息。 因为 ConnectionMultiplexer 要做很多事，所以它被设计为在调用者之间可以共享和重用，不需要在执行每一个操作的时候就创建一个 ConnectionMultiplexer ，它完全是线程安全的。 但现在，让我们来先创建一个ConnectionMultiplexer 类的实例保存以重用。 使用 ConnectionMultiplexer.Connect 或 ConnectionMultiplexer.ConnectAsync方法，传递配置字符串或ConfigurationOptions 对象（同上面提到过的）。 配置字符串可以采用逗号分隔的一系列节点的形式访问多个服务，所以让我们在默认端口（6379）上连接到本地机器上的一个实例：&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;33&quot;&gt;
&lt;pre&gt;
&lt;span&gt;private&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; ConnectionMultiplexer redisConnection { &lt;span&gt;get&lt;/span&gt;&lt;span&gt;; }
&lt;/span&gt;&lt;span&gt;static&lt;/span&gt;&lt;span&gt; RedisCache()
{
　　redisConnection &lt;/span&gt;= ConnectionMultiplexer.Connect(&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;127.0.0.1:6379&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;);
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　&lt;span&gt;ConnectionMultiplexer实现了IDisposable接口而且可以在不再需要的时候处理释放掉。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　&lt;strong&gt;&lt;span&gt;2.使用Redis&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;　　&lt;/strong&gt;&lt;span&gt;访问Redis使用上述获取的连接对象：&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;32&quot;&gt;
&lt;pre&gt;
IDatabase db = redisConnection.GetDatabase(&lt;span&gt;0&lt;/span&gt;);
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　&lt;span&gt;用GetDatabase()返回的对象成本很低，不需要特殊存储。可以传入redis数据库的号码，使用指定数据库，上面的例子就是使用0号数据库。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　拥有了IDatabase就可以调用方法去操作redis，所有的方法都有同步和异步两套，命名和微软要求的一样。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;　　下面简单的对五种数据类型进行基础操作：&lt;/p&gt;
&lt;p&gt;　　(1)String字符串&lt;/p&gt;
&lt;p&gt;　　添加&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;34&quot;&gt;
&lt;pre&gt;
&lt;span&gt;await&lt;/span&gt; redisConnection.GetDatabase().StringSetAsync(key, value, TimeSpan.FromSeconds(&lt;span&gt;20&lt;/span&gt;));
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　获取&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;32&quot;&gt;
&lt;pre&gt;
&lt;span&gt;await&lt;/span&gt; redisConnection.GetDatabase().StringGetAsync(key);
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　(2)List列表&lt;/p&gt;
&lt;p&gt;　　从列表底部和顶部插入&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;35&quot;&gt;
&lt;pre&gt;
&lt;span&gt;//&lt;/span&gt;&lt;span&gt;底部插入&lt;/span&gt;
&lt;span&gt;await&lt;/span&gt;&lt;span&gt; redisConnection.GetDatabase().ListRightPushAsync(key, value);
&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;顶部插入&lt;/span&gt;
&lt;span&gt;await&lt;/span&gt; redisConnection.GetDatabase().ListLeftPushAsync(key, value);
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　从列表底部和顶部获取一个数据&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;33&quot;&gt;
&lt;pre&gt;
&lt;span&gt;//&lt;/span&gt;&lt;span&gt;底部获取一个&lt;/span&gt;
&lt;span&gt;await&lt;/span&gt;&lt;span&gt; redisConnection.GetDatabase().ListRightPopAsync(key);
&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;顶部获取一个&lt;/span&gt;
&lt;span&gt;await&lt;/span&gt; redisConnection.GetDatabase().ListLeftPopAsync(key);
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　(3)Hash哈希&lt;/p&gt;
&lt;p&gt;　　添加&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;37&quot;&gt;
&lt;pre&gt;
&lt;span&gt;await&lt;/span&gt;&lt;span&gt; redisConnection.GetDatabase().HashSetAsync(key, primaryKey, value1);
&lt;/span&gt;&lt;span&gt;await&lt;/span&gt; redisConnection.GetDatabase().HashSetAsync(key, primaryKey, value2);
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　获取&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;33&quot;&gt;
&lt;pre&gt;
&lt;span&gt;await&lt;/span&gt; redisConnection.GetDatabase().HashGetAsync(key, primaryKey);
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　(4)Set集合&lt;/p&gt;
&lt;p&gt;　　添加&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;33&quot;&gt;
&lt;pre&gt;
&lt;span&gt;await&lt;/span&gt; redisConnection.GetDatabase().SetAddAsync(key, value);
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　获取并集&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;34&quot;&gt;
&lt;pre&gt;
&lt;span&gt;await&lt;/span&gt; redisConnection.GetDatabase().SetCombine(SetOperation.Union, key1, key2);
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　(5)Sorted Set有序集合&lt;/p&gt;
&lt;p&gt;　　添加&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;34&quot;&gt;
&lt;pre&gt;
&lt;span&gt;await&lt;/span&gt; redisConnection.GetDatabase().SortedSetAdd(key, value, sort);
&lt;/pre&gt;&lt;/div&gt;


</description>
<pubDate>Wed, 04 Dec 2019 13:54:00 +0000</pubDate>
<dc:creator>树杈</dc:creator>
<og:description>一、前言 Redis的介绍网上很多不再赘述。本次环境为net core 2.2，使用的StackExchange.Redis来操作Redis。 二、引用Microsoft.Extensions.Cac</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/xwc1996/p/11973611.html</dc:identifier>
</item>
<item>
<title>Docker 学习笔记 - 赐我白日梦</title>
<link>http://www.cnblogs.com/ZhuChangwu/p/11985742.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/ZhuChangwu/p/11985742.html</guid>
<description>&lt;h3 id=&quot;安装&quot;&gt;安装&lt;/h3&gt;
&lt;p&gt;docker的安装最好需要centos内核版本在3.1及以上&lt;/p&gt;
&lt;p&gt;查看系统内核版本&lt;/p&gt;
&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;uname -r&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1496926/201912/1496926-20191204183217506-272790618.png&quot; alt=&quot;uname-r&quot;/&gt;&lt;/p&gt;
&lt;p&gt;安装依赖&lt;/p&gt;
&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;yum install -y yum-utils device-mapper-persistent-data lvm2&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;添加yum源&lt;/p&gt;
&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;更新yum源&lt;/p&gt;
&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;yum makecache fast&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;安装docker&lt;/p&gt;
&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;yum install docker-ce -y&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;配置镜像加速&quot;&gt;配置镜像加速&lt;/h3&gt;
&lt;p&gt;使用阿里云的镜像加速服务&lt;br/&gt;https://cr.console.aliyun.com/cn-hangzhou/instances/mirrors&lt;/p&gt;
&lt;p&gt;在/etc/docker 目录下创建damon.json添加下面 的信息,没有的话新建这个文件&lt;/p&gt;
&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;sudo mkdir -p /etc/docker
sudo tee /etc/docker/daemon.json &amp;lt;&amp;lt;-'EOF'
{
  &quot;registry-mirrors&quot;: [&quot;https://7djn00qt.mirror.aliyuncs.com&quot;]
}
EOF&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;重新加载配置,重启docker&lt;/p&gt;
&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;sudo systemctl daemon-reload
sudo systemctl restart docker   &lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;常用的操作&quot;&gt;常用的操作&lt;/h3&gt;
&lt;p&gt;查找镜像&lt;/p&gt;
&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;docker search 关键字&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;如&lt;code&gt;docker search mysql&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1496926/201912/1496926-20191204183216949-1594282358.png&quot; alt=&quot;dockersearchmysql&quot;/&gt;&lt;/p&gt;
&lt;p&gt;拉取镜像&lt;/p&gt;
&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;docker pull 镜像名&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;如:&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1496926/201912/1496926-20191204183216090-1756235226.png&quot; alt=&quot;dockerpullmysql&quot;/&gt;&lt;/p&gt;
&lt;p&gt;查看系统中的镜像&lt;/p&gt;
&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;docker images # 未来可能被删除
docker image list
docker image ls&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1496926/201912/1496926-20191204183215438-1071955031.png&quot; alt=&quot;dockerimagelist&quot;/&gt;&lt;/p&gt;
&lt;p&gt;删除镜像&lt;/p&gt;
&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;docker rm -f 镜像id或者镜像名:TAG&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;查看镜像的元数据&lt;/p&gt;
&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;docker inspect 镜像ID或者镜像名:TAG&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;运行镜像--&amp;gt;容器&lt;/p&gt;
&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;docker run --name 容器名 -i -t -p 主机端口:容器端口 -d -v 主机目录:容器目录:ro 镜像ID或镜像名:TAG
--name 指定容器的名字
-i 以交互的模式运行容器
-t 分配一个伪终端(可以理解成bash命令行)
-p 端口映射,将主机的端口映射向容器内部的端口
-d 后台运行
-v 将主机目录(全路径)挂载到容器的目录中,比如可以让容器中的软件读取宿主机上的配置文件(默认rw读写,ro只读)
-v 注意它进行的目录级别的挂载,在使用-v启动容器之前,确保将容器目录中的配置文件拷贝到主机目录下
-v 根据需求修改主机目录配置文件,再启动时,容器会去主机目录下读取配置文件
-i -t 通常都被简写成-it, 容器中必须运行一个进程容器才不会自动退出,通常使用这个-it让容器运行bash,不让他退出
-v和-p都是可以重复使用的&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;命令中的tag和镜像id在上面的命令中都能找到&lt;/p&gt;
&lt;p&gt;启动时可以通过指定容器的名字, 容器的名字是上图中的REPOSITORY, 如果不是lasted版本的需要添加上tag&lt;/p&gt;
&lt;p&gt;查看容器列表&lt;/p&gt;
&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;docker ps # 正在运行的
docker container list # 正在运行的
docker ps -a # 能看到停止状态Containner&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1496926/201912/1496926-20191204183215206-1098838835.png&quot; alt=&quot;dokcercontainerlist&quot;/&gt;&lt;/p&gt;
&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;容器中必须存在一个或者的进程容器才不会退出,上面的COMMAND表示的容器中指定的命令,一般都是通过这个命令去启动一个进程&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;停止容器&lt;/p&gt;
&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;docker stop 容器ID或者容器名&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;重启容器&lt;/p&gt;
&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;docker restart 容器ID或者容器名&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;删除容器&lt;/p&gt;
&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;docker rm -f 容器id或者容器名
-f 表示强制删除&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;查看日志&lt;/p&gt;
&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;docker logs 容器ID和容器名&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;进入正在运行的容器&lt;/p&gt;
&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;docker container exec -it 指定的容器名或者容器的ID /bin/bash
# 顺序别乱
# 进入正在运行的容器并开启交互模式终端
# 这个正在运行中的容器可以理解成它是一个简化的linux
# /bin/bash 是固定的写法,标准的linux的shell,表示docker作为一个deaman在后台运行&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;退出容器&lt;/p&gt;
&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;exit&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;拷贝文件&lt;/p&gt;
&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;docker cp 主机文件路径 容器ID或者容器名:容器路径 将主机中的文件拷贝到容器中
docker cp 容器ID或者容器名 主机文件路径 # 将容器中的文件拷贝到主机中

这两条命令很常用,因为docker容器里面没有vim vi命令,不能直接修改它里面的配置文件
如果真的做配置文件的映射,别忘了将原来的Containner杀掉,然后从新启动image产生新的Containner
重新运行时需要在命令行上添加参数表示告诉docker来宿主机读取配置文件 参数: -v&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;获取容器的元信息&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;docker container inspect 容器ID或容器名&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;dockerfile简介&quot;&gt;Dockerfile简介&lt;/h3&gt;
&lt;p&gt;&lt;a href=&quot;https://docs.docker.com/develop/develop-images/dockerfile_best-practices/&quot;&gt;点击进入dockerfile的官方地址&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;dockerfile其实一个文件,但是这个文件中存在着一些命令,docker会读取这个文件中的命令然后构建出命令对应的image&lt;/p&gt;
&lt;p&gt;容器是分层的,就像下面的图一样&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1496926/201912/1496926-20191204183214909-1460710730.png&quot; alt=&quot;分层&quot;/&gt;&lt;/p&gt;
&lt;p&gt;When you run an image and generate a container, you add a new &lt;em&gt;writable layer&lt;/em&gt; (the “container layer”) on top of the underlying layers. All changes made to the running container, such as writing new files, modifying existing files, and deleting files, are written to this thin writable container layer&lt;/p&gt;
&lt;p&gt;我们一运行镜像,这个镜像就会变成一个容器, 看看上图,可以发现我们手里的容器其实本身就是分层的,(然而容器是第三方提供的我们跟不用关系有多少层),但是我们能在现有分层的基础上继续添加可写的层, 比如我们可以创建新文件啊,修改现存的文件啊,或者删除现存的一些文件,并且这些修改对docker会生效&lt;/p&gt;
&lt;p&gt;其实上面说的分层的概念还是有点模糊,就是说如果我们想构建自己的镜像的话,不用从0开始了,我们可以复用现有的仅可读的镜像,在此基础上构建我们的镜像,比如举个例子,我们jar包的执行需要借助java环境,那如果我们想构建一个镜像跑一个jar包,就得依赖现存的java 的镜像当成基础镜像&lt;/p&gt;
&lt;p&gt;docker file中的每一行都会成为一层,所以官方推荐: dockerfile中的指令越少越好,越短越好&lt;/p&gt;
&lt;h3 id=&quot;使用dockerfile构建springboot镜像&quot;&gt;使用Dockerfile构建SpringBoot镜像&lt;/h3&gt;
&lt;ol&gt;&lt;li&gt;将jar包上传到linux上,并切换到jar包所在的目录&lt;/li&gt;
&lt;li&gt;在jar所在的目录中创建如下的vim Dockerfile,添加如下内容&lt;/li&gt;
&lt;/ol&gt;&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;# 指定基础镜像,我们的jar包依赖java8的镜像
FROM java:8
# maintainer作者
LABEL maintainer=changwu
# 将可执行jar包复制到可执行目录的根目录下
ADD lawyer-lover-consumer-1.0-SNAPSHOT.jar /lawyer-lover-consumer-1.0-SNAPSHOT.jar
# 镜像要暴露的端口,如果要使用端口,docker run -p [端口]
EXPOSE 80
# entrypoint 在镜像运行为容器后执行的命令
ENTRYPOINT [&quot;java&quot;,&quot;-jar&quot;,&quot;/lawyer-lover-consumer-1.0-SNAPSHOT.jar&quot;]&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;构建&lt;/p&gt;
&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;docker build -t myproject:v1 .
-t 跟镜像名和TAG
-f 跟Dockerfile的路径
. 指当前目录&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;运行&lt;/p&gt;
&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;docker run --name myproject -p 9998:80 -d 镜像名:TAG
docker run --name myproject -P -d 镜像名:TAG&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;dockerfile参数&quot;&gt;Dockerfile参数&lt;/h3&gt;
&lt;table&gt;&lt;thead/&gt;&lt;tbody readability=&quot;13&quot;&gt;&lt;tr class=&quot;odd&quot; readability=&quot;2&quot;&gt;&lt;td&gt;FROM&lt;/td&gt;
&lt;td&gt;设置镜像使用的基础镜像&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;even&quot;&gt;&lt;td&gt;MAINTAINER&lt;/td&gt;
&lt;td&gt;设置镜像的&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;odd&quot; readability=&quot;3&quot;&gt;&lt;td&gt;LABEL&lt;/td&gt;
&lt;td&gt;MAINTAINER的替代者,设置镜像的标签&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;even&quot;&gt;&lt;td&gt;EXPOSE&lt;/td&gt;
&lt;td&gt;暴露容器的端口&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;odd&quot; readability=&quot;3&quot;&gt;&lt;td&gt;ADD&lt;/td&gt;
&lt;td&gt;构建镜像时,拷贝文件到容器中&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;even&quot; readability=&quot;2&quot;&gt;&lt;td&gt;COPY&lt;/td&gt;
&lt;td&gt;构建镜像时从宿主机拷贝文件到容器中&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;odd&quot; readability=&quot;2&quot;&gt;&lt;td&gt;ENTRIPOINT&lt;/td&gt;
&lt;td&gt;设置容器启动后执行的命令&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;even&quot; readability=&quot;2&quot;&gt;&lt;td&gt;CMD&lt;/td&gt;
&lt;td&gt;设置容器启动后执行的命令&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;odd&quot;&gt;&lt;td&gt;VOLUME&lt;/td&gt;
&lt;td&gt;设置挂载卷&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;even&quot; readability=&quot;2&quot;&gt;&lt;td&gt;ENV&lt;/td&gt;
&lt;td&gt;设置容器的环境变量&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;odd&quot; readability=&quot;2&quot;&gt;&lt;td&gt;ARG&lt;/td&gt;
&lt;td&gt;设置系统的环境变量&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;even&quot; readability=&quot;2&quot;&gt;&lt;td&gt;USER&lt;/td&gt;
&lt;td&gt;设置运行RUN CMD ENTRYPOINT的用户名&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;odd&quot; readability=&quot;2&quot;&gt;&lt;td&gt;WORKDIR&lt;/td&gt;
&lt;td&gt;设置RUN CMD ENTRYPOINT COPY ADD指令的工作目录&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;even&quot; readability=&quot;2&quot;&gt;&lt;td&gt;ONBUILD&lt;/td&gt;
&lt;td&gt;设置镜像的ONBUILD指令&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;odd&quot; readability=&quot;2&quot;&gt;&lt;td&gt;STOPSIGNAL&lt;/td&gt;
&lt;td&gt;设置容器的退出信号量&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;h4 id=&quot;from&quot;&gt;FROM&lt;/h4&gt;
&lt;p&gt;Dockerfile中的第一个非注释行,用来指定基础镜像,默认情况下会先尝试从本地获取基础镜像,本地没有的话就会去DockerHub中拉取,常用的书写格式 如下:&lt;/p&gt;
&lt;p&gt;这是官方推荐的基础镜像地址 : &lt;a href=&quot;https://hub.docker.com/_/alpine/&quot; class=&quot;uri&quot;&gt;https://hub.docker.com/_/alpine/&lt;/a&gt;&lt;/p&gt;
&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;FROM image
FROM image:tag
FORM image:@:digest&lt;/code&gt;
&lt;/pre&gt;
&lt;h4 id=&quot;maintainer&quot;&gt;MAINTAINER&lt;/h4&gt;
&lt;p&gt;用来指定作者的信息,但是在未来的版本将会被弃用&lt;/p&gt;
&lt;h4 id=&quot;label&quot;&gt;LABEL&lt;/h4&gt;
&lt;p&gt;现在官方推荐的使用LABEL去描述镜像的各种元数据,比如向下面这样,支持同时设置多个label&lt;/p&gt;
&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;# Set one or more individual labels
LABEL com.example.version=&quot;0.0.1-beta&quot;
LABEL vendor1=&quot;ACME Incorporated&quot;
LABEL vendor2=ZENITH\ Incorporated
LABEL com.example.release-date=&quot;2015-02-12&quot;
LABEL com.example.version.is-production=&quot;&quot;&lt;/code&gt;
&lt;/pre&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;&lt;strong&gt;注意上面的细节: 带空格的字符串必须加引号或空格必须转义。内部引用字符(&quot;)也必须转义&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;并且官方不建议上面的书写格式(因为每一条指令都会生成一个镜像),而是建议我们向下面这样合并起来label&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;# Set multiple labels on one line
LABEL com.example.version=&quot;0.0.1-beta&quot; com.example.release-date=&quot;2015-02-12&quot;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;或者这样也行&lt;/p&gt;
&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;# Set multiple labels at once, using line-continuation characters to break long lines
LABEL vendor=ACME\ Incorporated \
      com.example.is-beta= \
      com.example.is-production=&quot;&quot; \
      com.example.version=&quot;0.0.1-beta&quot; \
      com.example.release-date=&quot;2015-02-12&quot;&lt;/code&gt;
&lt;/pre&gt;
&lt;h4 id=&quot;add-or-copy&quot;&gt;ADD or COPY&lt;/h4&gt;
&lt;p&gt;ADD 和 COPY看起来很像,但是一般来说都会优先选择COPY,因为它比ADD更透明, COPY仅仅支持将本地的文件复制到容器中,使用ADD支持TAR文件和URL路径(网上文件的下载路径), 命令不能很好的却分 是从本地进行复制还是通过url从远程拉取文件&lt;/p&gt;
&lt;p&gt;使用ADD时注意,如果是tar包的话,宿主机上的tar包拷贝到image中会被解压, 但是过URL下载链接的制作镜像时,tar包不会被自动解压, 而且容器中的目录最后需要加上/ 不然启动不起来&lt;/p&gt;
&lt;h4 id=&quot;entripoint-or-cmd&quot;&gt;ENTRIPOINT or CMD&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;entrypoint和cmd 都是在指定容器启动后的命令&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;entrypoint两种格式&lt;/strong&gt;&lt;/p&gt;
&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;ENTRYPOINT [&quot;executable&quot;,&quot;param1&quot;,&quot;param2&quot;]
ENTRYPOINT command param1 param2  (shell中执行)&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;ENTRYPOINT可以指定容器启动后执行的命令,当指定多个时,同样也只有最后一个命令会生效,并且它不能被docker run中指定的参数所覆盖&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;(不过可以这样进行覆盖docker run命令的--entrypoint参数可以覆盖ENTRYPOINT)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;cmd的三种格式&lt;/strong&gt;&lt;/p&gt;
&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;CMD [&quot;executable&quot;,&quot;param1&quot;,&quot;param2&quot;]  # 使用exec执行
CMD command param1 param2  # 在 /bin/sh 中执行
CMD [&quot;param1&quot;,&quot;param2&quot;] # 给ENTRYPOINT提供默认的参数&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;cmd可以指定容器启动时执行的命令,每个Dockerfile中 只能有一个CMD命令,如果写了多个CMD,只有最后一个会生效, 并且,用户在通过docker run 启动容器时添加的参数 会覆盖原CMD的命令&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;小结:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;他们可以指定容器启动后执行的命令,并且当同时存在多个CMD或者多个ENTRYPOINT时,只有最一个会生效&lt;/li&gt;
&lt;li&gt;当Dockerfile中同时存在CMD和ENTRYPOINT时.并且CMD又不是为了给ENTRYPOINT提供默认的参数,那么谁在最后谁生效&lt;/li&gt;
&lt;/ul&gt;&lt;h4 id=&quot;volume&quot;&gt;VOLUME&lt;/h4&gt;
&lt;p&gt;卷， 这个参数和我们启动容器时使用的&lt;code&gt;docker run -v 宿主机目录：容器目录&lt;/code&gt;类似这种挂载券操作， &lt;strong&gt;下面命令中的挂载点其实是容器中的目录，宿主机中的目录会被随机生成&lt;/strong&gt;&lt;/p&gt;
&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;VOLUME mountpoint # 如 VOLUME /data1&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;举个应用的场景，当我们想将容器中mysql数据库中的数据同步到宿主机的目录下面时，我们可以使用VOLUME，这样配置后会随机在宿主机上创建一个目录存放数据&lt;/p&gt;
&lt;h4 id=&quot;expose&quot;&gt;　EXPOSE&lt;/h4&gt;
&lt;p&gt;指定容器和外部进行通信的端口以及协议, EXPOSE 可以指个端口. 默认的协议是tcp协议&lt;/p&gt;
&lt;p&gt;语法:&lt;/p&gt;
&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;EXPOSE &amp;lt;port&amp;gt;
EXPOSE 80/tcp 9999/udp&lt;/code&gt;
&lt;/pre&gt;
&lt;blockquote readability=&quot;12&quot;&gt;
&lt;p&gt;&lt;strong&gt;当我们运行镜像时,使用-p手动指定宿主机和容器的端口映射规则, 使用-P 的话,会自动完成-p的工作, 首先会自动的分配一个宿主机的端口, 然后将宿主机的端口映射到EXPOSE的端口上&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4 id=&quot;env&quot;&gt;ENV&lt;/h4&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1496926/201912/1496926-20191204183214400-1224201980.png&quot; alt=&quot;env&quot;/&gt;&lt;/p&gt;
&lt;p&gt;类似于环境变量,在Dockerfile中通过ENV定义的环境变量,之后可以通过&lt;code&gt;$variable_name&lt;/code&gt; 或者{variable_name}取出值使用&lt;/p&gt;
&lt;p&gt;两种格式:&lt;/p&gt;
&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;ENV &amp;lt;key&amp;gt; &amp;lt;value&amp;gt; # 一次只能指定一对k-v
ENV &amp;lt;kay&amp;gt;=&amp;lt;value&amp;gt; # 一行指定多个k-v, 如果中间有空格通过\转义,或者使用&quot;&quot;标识, 而且\还可以表示换行&lt;/code&gt;
&lt;/pre&gt;
&lt;h4 id=&quot;arg&quot;&gt;ARG&lt;/h4&gt;
&lt;p&gt;作用和ENV相仿,都可以类型指定环境变量,而且可以在docker build创建镜像的时候，使用 &lt;code&gt;--build-arg=指定参数&lt;/code&gt;来指定参数&lt;/p&gt;
&lt;h3 id=&quot;docker-网络模型&quot;&gt;Docker 网络模型&lt;/h3&gt;
&lt;p&gt;docker允许通过外部访问容器或者容器互联的方式提供网络服务, 安装docker deamon时,会自动安装一个docker网卡,叫做Docker0 (通多 ip addr 可以查看,如下图)&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1496926/201912/1496926-20191204183213219-1344679378.png&quot; alt=&quot;ipaddr&quot;/&gt;&lt;/p&gt;
&lt;h4 id=&quot;一个小例子&quot;&gt;一个小例子&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;在开始Docker网络的笔记前,我想说这个真实的小例子,如果你精通网络方面的知识希望你在评论区指出我说的不对的地方&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote readability=&quot;32&quot;&gt;
&lt;p&gt;&lt;strong&gt;在说docker之前,我想说一个现实的例子: 我们学校想举办一场ACM区域赛,学校给了两个机房,每个机房都有一百多台电脑,老师的意思是将我们的CLP平台运行在内网中,在内网中举行这次比赛,于是我的同学开始筹划组建一个局域网,要组建一个内网,我们手里面有什么设备呢? 斐讯的路由器,还有机房的交换机.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;其实说是搭建一个局域网感觉是有点花哨了,我们的最终目的是啥呢? 其实就是让所有的同学都连接一个路由器实现电脑机房的互联(就是可以通过ip相互访问到),但是路由器上有两种接口,lanip和wanip,如果本地的机器之间想互联的话,就使用lan口, wan口是用来连接外网使用的, 路由器上面lan口就4个,两个机房中两百个机器怎么互联呢? 还好我们有交换机&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;常见的内网网段: 10.X.X.X 100.X.X.X 192.168.X.X 172.16.X.X - 172.31.X.X&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;下面是路由器控制台配置lan口的图片&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1496926/201912/1496926-20191204183212670-510747456.png&quot; alt=&quot;lan口&quot;/&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;hr/&gt;&lt;/blockquote&gt;
&lt;blockquote readability=&quot;11&quot;&gt;
&lt;p&gt;&lt;strong&gt;然后大家都去连接路由器的无限信号,看上图将DHCP关掉了,连接上路由器的网络后不能不会被分配一个随机的ip使用,于是我们就得自己去手动配置自己电脑的ipv4地址,像下面这样&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1496926/201912/1496926-20191204183212022-1247215521.png&quot; alt=&quot;配置ip&quot;/&gt;&lt;/p&gt;
&lt;blockquote readability=&quot;14&quot;&gt;
&lt;p&gt;&lt;strong&gt;上面我们配置了当前的局域网中当前机器的ip地址,两个机房中的ip地址不会存在重复的情况,并且他们都能都过ip经过交换机访问到彼此&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;**最后我们找一台虚拟机当成服务器,在上面启动Tomcat,跑我们的CLP,同学们通过ip+_端口来访问这个虚拟机上面的WebServer.就能欢快的比赛了**&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;为什么说这个例子呢? 其实这应该就是大家说的桥接模型,整个局域网中,所有的机器想互联就得在一个网段里面,就像上面的子网掩码限制了我们的网段是192.168.1.XXX (XXX的范围是1-254),同时处于这个网段的电脑之间是可以互联的,拥有自己的ip,并且路由器如果能连接外网,那么局域网中的电脑就能中继连接外网&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;说了这么多和Docker有什么关系呢? docker默认的网络模型就是桥接模型, 上图中的Docker0网卡是Docker deamon的虚拟网卡, 我们可不可以将docker demon想象成他是我们虚拟机里面的一个虚拟内网呢? 这个比喻就好比是下面这样&lt;/strong&gt;&lt;/p&gt;
&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;华为云ECS == 笔记本电脑
docker deamon == VMware Workstation Pro
Containner1 == VMware中的虚拟机1
Containner2 == VMware中的虚拟机2
Containner3 == VMware中的虚拟机3&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;就好比我们当初想让VMware中的虚拟机连接外网一样&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;docker container 其实就是一个极简的linux镜像,麻雀虽小五脏俱全啊...什么dns解析,路由表,host文件它都有, 每一个docker容器模式使用桥接的网络模型就意味着没个容器都有自己的ip地址, 宿主机和容器之间怎么通信呢? 这个问题就好比你的笔记本怎么和VMare中的虚拟机如何通信一样, 可以理解成docker将物理机上的网卡虚拟化成一个交换机,进而实现彼此互联&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;有啥不懂的欢迎关注计算机网络大佬前端大佬: &lt;a href=&quot;https://home.cnblogs.com/u/camwang&quot; class=&quot;uri&quot;&gt;https://home.cnblogs.com/u/camwang&lt;/a&gt;&lt;/p&gt;
&lt;h4 id=&quot;docker网络中的核心概念&quot;&gt;&lt;strong&gt;docker网络中的核心概念&lt;/strong&gt;&lt;/h4&gt;
&lt;ul&gt;&lt;li&gt;沙盒: Docker的沙盒可以&lt;strong&gt;让docker拥有完全独立的容器网络环境&lt;/strong&gt;, 沙盒提供了端口socket,ip路由表,防火墙等内容&lt;/li&gt;
&lt;li&gt;网络: 为了保证容器之间的安全通信, Docker的虚拟网络和宿主机的网络之间是隔离的,这里说的网络可以理解成docker内部的虚拟子网,Docker中的容器之间可以在这个虚拟子网中相互可见相互通信&lt;/li&gt;
&lt;li&gt;端点: 容器通过这个端点实现和外网的通信,这个端点就是可控的突破封闭的网络环境的出入口&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;docker中存在四种网络模式 &lt;strong&gt;Bridge,Host,None,Containner&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;拓展网络模式解释: &lt;a href=&quot;https://www.cnblogs.com/ggjucheng/archive/2012/08/19/2646007.html&quot; class=&quot;uri&quot;&gt;https://www.cnblogs.com/ggjucheng/archive/2012/08/19/2646007.html&lt;/a&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;[root@139 ~]# docker network ls
NETWORK ID          NAME                DRIVER              SCOPE
0dd04b1074d6        bridge              bridge              local
d3c5ff224f6d        host                host                local
83a97a50d16f        none                null                local&lt;/code&gt;
&lt;/pre&gt;
&lt;h4 id=&quot;bridge-桥接模式&quot;&gt;&lt;strong&gt;bridge 桥接模式&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;最直观的看bridge就是, 宿主机和容器各有各的ip,但是可以互联&lt;/p&gt;
&lt;p&gt;我们在使用docker run命令时从来没有配置过添加参数配置docker的网络模式, 那是因为docker中默认使用桥接模式网络模式, 而且,bridge模式应该是可以满足大部分的需求&lt;/p&gt;
&lt;p&gt;我们可以是要使用bridge自定义一些网络配置&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;修改主机名称(就像我们常改的host文件)&lt;/strong&gt;&lt;/p&gt;
&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;[root@139 ~]# docker run --name test1 -it --network bridge -h changwu  --rm busybox:latest
/ # hostname 
changwu

/ # cat /etc/hosts
127.0.0.1   localhost
::1 localhost ip6-localhost ip6-loopback
fe00::0 ip6-localnet
ff00::0 ip6-mcastprefix
ff02::1 ip6-allnodes
ff02::2 ip6-allrouters
172.17.0.3  changwu

/ # cat /etc/resolv.conf 
# Generated by NetworkManager
nameserver 100.125.1.250
nameserver 100.125.136.29
options single-request-reopen
 / # nslookup -type=A www.baidu.com
Server:     100.125.1.250
Address:    100.125.1.250:53

Non-authoritative answer:
www.baidu.com   canonical name = www.a.shifen.com
Name:   www.a.shifen.com
Address: 180.101.49.12
Name:   www.a.shifen.com
Address: 180.101.49.11

---------命令详解------------
在busybox容器中查看这个容器的host文件,已经修改成我在启动参数规定的值了
也就是说,当前的容器会将changwu解析成前面的ip地址 172.17.0.3

你看这个容器和linux没啥区别,确实是一个极简的linux,而且它同样有自己的dns解析配置
上面的查看resolv.conf ,100.125.1.250是外往的地址
换句话说,当前的容器访问XXX.com域名时,先找本机host文件,找不到的话,就访问这个100.125.1.250 去解析

------参数详解--------
-h  主机名
-it 运行这个极简的bash
--network 网络模式
--rm 一旦退出容器就删除该容器&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;自定义DNS地址&lt;/strong&gt;&lt;/p&gt;
&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;[root@139 ~]# docker run --name test -it --network bridge --dns 8.8.8.8 --rm busybox
/ # cat /etc/resolv.conf 
nameserver 8.8.8.8
options single-request-reopen

-------参 数解释-------
 --dns 跟dns地址&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;更多命令使用 docker network --help 查看&lt;/strong&gt;&lt;/p&gt;
&lt;h4 id=&quot;host-宿主机网络模式&quot;&gt;&lt;strong&gt;host 宿主机网络模式&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;host网络模式和bridge桥接的区别就是 host模式中,虚拟机和主机共用一块网卡上网,这时候虚拟机和主机的之间相当于是一个机器, &lt;strong&gt;容器启动后对外暴露的提供服务的端口直接绑定到注解对应的端口上, 容器的ip地址就是我的华为云ECS的公网ip&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;[root@139 ~]# docker run --name test -it --network host --rm busybox
/ # hostname 
139.9X.92.X35&lt;/code&gt;
&lt;/pre&gt;
&lt;h4 id=&quot;none&quot;&gt;&lt;strong&gt;none&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;会形成一个全封闭的容器,没有网络配置,无法和外网互联&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;[root@139 ~]# docker run --name test -it --network none --rm busybox
/ # hostname
6511ba02c5e3&lt;/code&gt;
&lt;/pre&gt;
&lt;h4 id=&quot;container&quot;&gt;&lt;strong&gt;container&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;他和host模式很像, host模式会容器共享主机的ip, 这个container模式就是让当前容器共享另一个容器的 network namespace&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;[root@139 ~]# docker run --name test -it --network container:the_other_container --rm busybox&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;docker-端口映射&quot;&gt;Docker 端口映射&lt;/h3&gt;
&lt;h4 id=&quot;p-小写的几种用法&quot;&gt;-p (小写)的几种用法&lt;/h4&gt;
&lt;ul&gt;&lt;li&gt;指定容器的端口动态的映射到宿主机的端口上&lt;/li&gt;
&lt;/ul&gt;&lt;pre&gt;
&lt;code&gt;[root@139 ~]# docker run --name mysql -d -p 3306 -e MYSQL_ROOT_PASSWORD=123123  mysql
291f7337a1ac0232d84eae4b3632bd044bcc433c7a0bafaf97b638a05ddddaf8
[root@139 ~]# docker port mysql 
3306/tcp -&amp;gt; 0.0.0.0:32770
--------解释-----------
在宿主机上找一个动态的端口,映射到 Containner的 3306端口上&lt;/code&gt;
&lt;/pre&gt;
&lt;ul&gt;&lt;li&gt;端口映射&lt;/li&gt;
&lt;/ul&gt;&lt;pre&gt;
&lt;code&gt;[root@139 ~]# docker run --name mysql -d -p 3306:3306 -e MYSQL_ROOT_PASSWORD=123123  mysql
eaa6bdb54df54419cce5866d5050fec8d1aba4d7d5b85ab41c3e41fd1887c6d0
[root@139 ~]# docker port mysql
3306/tcp -&amp;gt; 0.0.0.0:3306
--------解释-----------
成功的将宿主机上的3306端口映射到 mysql Containner的3306端口上&lt;/code&gt;
&lt;/pre&gt;
&lt;ul&gt;&lt;li&gt;通过宿主机ip+端口, 映射到容器的指定端口上&lt;/li&gt;
&lt;/ul&gt;&lt;pre&gt;
&lt;code&gt;[root@139 ~]# docker run --name mysql -d -e MYSQL_ROOT_PASSWORD=123123 -p 192.168.0.32:3306:3306 mysql
e1ef0d628415a41d6a122c78909cb63c00a788056395d64e667c496ac0c68cdc
[root@139 ~]# docker port mysql
3306/tcp -&amp;gt; 192.168.0.32:3306&lt;/code&gt;
&lt;/pre&gt;
&lt;ul&gt;&lt;li&gt;指定宿主机的ip, 将容器中的指定端口映射到动态的宿主机端口&lt;/li&gt;
&lt;/ul&gt;&lt;pre&gt;
&lt;code&gt;[root@139 ~]# docker run --name mysql -d -e MYSQL_ROOT_PASSWORD=123123 -p 192.168.0.32::3306 mysql
2f125488de4dbe4b5583baa46cbedb11a6b15cd38804c23815475d39a262dff5
[root@139 ~]# docker port mysql
3306/tcp -&amp;gt; 192.168.0.32:32768&lt;/code&gt;
&lt;/pre&gt;
&lt;h4 id=&quot;p-大写-的用法&quot;&gt;-P (大写) 的用法&lt;/h4&gt;
&lt;p&gt;目的是暴露容器中的所有端口, 哪些端口呢? 就是我们在Dockerfile中通过Export指定的端口&lt;/p&gt;
&lt;h3 id=&quot;docker-compose-编排springcloud&quot;&gt;Docker Compose 编排SpringCloud&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;将项目容器化后固然很方便,但是总不能真的就挨个去启动吧,其实是不用的,我们使用DockerCompose, 使用Componse我们可以在yml中去配置我们的服务,使用单行命令实现启动配置中的所有服务&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;下面的示例是使用Docker Compose编排我写的 一个法律助手的项目&lt;/p&gt;
&lt;h4 id=&quot;下载安装&quot;&gt;下载安装&lt;/h4&gt;
&lt;p&gt;项目在github上面: &lt;a href=&quot;https://github.com/docker/compose/releases&quot; class=&quot;uri&quot;&gt;https://github.com/docker/compose/releases&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;下载：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;curl -L https://github.com/docker/compose/releases/download/1.25.0-rc3/docker-compose-`uname -s`-`uname -m` -o /usr/local/bin/docker-compose&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;给docket-compose 可执行的权限&lt;/p&gt;
&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;chmod +x /usr/local/bin/docker-compose&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;设置软链接&lt;/p&gt;
&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;ln -s /usr/local/bin/docker-compose /usr/bin/docker-compose&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;验证是否安装&lt;/p&gt;
&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;docker-compose version&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;卸载&lt;/p&gt;
&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;rm /usr/local/bin/docker-compose&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;思路: DockerComponse的配置文件和Dickerfile中的配置文件类似的, 它的格式的 yml&lt;/p&gt;
&lt;p&gt;首先就是安排好jar包和文件的目录位置, 比如下图, 四个蓝色名称的目录中存放着不同功能的jar包,DockerComponse需要的配置文件 docker-componse.yml 也在这里面&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1496926/201912/1496926-20191204183211112-1251097109.png&quot; alt=&quot;目录&quot;/&gt;&lt;/p&gt;
&lt;p&gt;docker-componse.yml 实战模板:&lt;/p&gt;
&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;version: '2.1'
services:
  eurekaserver:
    image: eurekaserver:v1
    ports:
     - 10086:10086
  lawyer-lover-consumer:
    image: lawyer-lover-consumer:v1
    ports:
     - 8082:8082
  lawyer-lover-main:
    image: lawyer-lover-main:v1
    ports:
     - 8081:8081
  lawyer-lover-zuul:
    image: lawyer-lover-zuul:v1
    ports:
     - 10010:10010    
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;输入命令进行自动编排&lt;/p&gt;
&lt;pre class=&quot;docker&quot;&gt;
&lt;code&gt;docker-compose up -d
-----------------------
-d 表示后台启动&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;结果: 看着自己写了这些天的项目上线了, 真的爽歪歪啊...&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1496926/201912/1496926-20191204183210799-1077750538.png&quot; alt=&quot;https://img2018.cnblogs.com/blog/1496926/201912/1496926-20191204183210799-1077750538.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;验证结果:&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1496926/201912/1496926-20191204183210257-1855810232.png&quot; alt=&quot;验证结果&quot;/&gt;&lt;/p&gt;
&lt;h3 id=&quot;将本地镜像发布到阿里云仓库&quot;&gt;将本地镜像发布到阿里云仓库&lt;/h3&gt;
&lt;p&gt;如果你也想一处构建, 导出运行的话, 可以玩玩这个功能&lt;/p&gt;
&lt;p&gt;网址: https://cr.console.aliyun.com/cn-hangzhou/repositories&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;将镜像推送到阿里云&lt;/li&gt;
&lt;/ul&gt;&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;# 登录阿里云的docker仓库
  docker login --username=[用户名] registry.cn-hangzhou.aliyuncs.com
# 创建指定镜像的tag，归入某个仓库
  docker tag [镜像ID] registry.cn-hangzhou.aliyuncs.com/huaan/huaan:[镜像版本号]
# 将镜像推送到仓库
  docker push registry.cn-hangzhou.aliyuncs.com/huaan/huaan:[镜像版本号&lt;/code&gt;
&lt;/pre&gt;
&lt;ul&gt;&lt;li&gt;拉取镜像到本地&lt;/li&gt;
&lt;/ul&gt;&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;docker pull registry.cn-hangzhou.aliyuncs.com/coldest7/mytom:v1&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;dokcer run --help&lt;/p&gt;
&lt;p&gt;docker --help&lt;/p&gt;
&lt;p&gt;docker network --help&lt;/p&gt;
&lt;p&gt;dokcer Containner --help&lt;/p&gt;
&lt;p&gt;docker image --help&lt;/p&gt;
</description>
<pubDate>Wed, 04 Dec 2019 13:30:00 +0000</pubDate>
<dc:creator>赐我白日梦</dc:creator>
<og:description>安装 docker的安装最好需要centos内核版本在3.1及以上 查看系统内核版本 安装依赖 添加yum源 更新yum源 安装docker 配置镜像加速 使用阿里云的镜像加速服务 https://c</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/ZhuChangwu/p/11985742.html</dc:identifier>
</item>
</channel>
</rss>