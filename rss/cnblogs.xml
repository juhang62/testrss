<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="css/feed.xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/" xmlns:og="http://ogp.me/ns#">
<channel>
<atom:link rel="self" href="http://192.168.1.4/fivefilters/makefulltextfeed.php?url=feed.cnblogs.com%2Fblog%2Fsitehome%2Frss&amp;max=10&amp;links=preserve&amp;exc=" />
<atom:link rel="alternate" title="Source URL" href="http://feed.cnblogs.com/blog/sitehome/rss" />
<atom:link rel="related" title="Subscribe to feed" href="http://www.subtome.com/#/subscribe?feeds=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed.cnblogs.com%252Fblog%252Fsitehome%252Frss%26max%3D10%26links%3Dpreserve%26exc%3D&amp;back=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed.cnblogs.com%252Fblog%252Fsitehome%252Frss%26max%3D10%26links%3Dpreserve%26exc%3D" />
<title>博客园_首页</title>
<link></link>
<description>代码改变世界</description>
<item>
<title>Redis基础篇（八）数据分片 - 大杂草</title>
<link>http://www.cnblogs.com/liang24/p/14189712.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/liang24/p/14189712.html</guid>
<description>&lt;p&gt;现在有一个场景：要用Redis保存5000万个键值对，每个键值对大约是512B，要怎么部署Redis服务呢？&lt;/p&gt;
&lt;p&gt;第一个方案，也是最容易想到的，需要保存5000万个键值对，每个键值对约为512B，一共需要25GB空间，选择一台32GB内存的用品来部署Redis，还剩余7GB空间，可以采用RDB对数据做持续久。&lt;/p&gt;
&lt;p&gt;但是Redis服务使用不久后出现Redis的响应有时会非常慢。原因是采用了RDB持久化，在前面介绍RDB原理时，我们知道fork子进程的瞬间会阻塞主线程，而且内存越大，阻塞越长。&lt;/p&gt;
&lt;p&gt;第一个方案不太适合，那么有更好的方案吗？Redis提供切片集群机制，多个Redis实例组成一个集群，按照一定的规则，把收到数据划分成多份，每一份用一个实例来保存。这样一来，在生成RDB时，数据量就小了，fork就不会阻塞主线程太长时间。&lt;/p&gt;
&lt;p&gt;这里就引出一个问题：该如何保存更多的数据？&lt;/p&gt;
&lt;h2&gt;如何保存更多数据&lt;/h2&gt;
&lt;p&gt;通常有两种方案，分别是纵向扩展和横向扩展。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;纵向扩展&lt;/strong&gt;，指通过增加硬件配置来扩展，采用更大的内存，更多的CPU。好处是实施简单，但缺点是受到硬件和成本的限制，不可能无限扩展。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;横向扩展&lt;/strong&gt;，指通过增加机器来组成更大的集群，这也是分布式方案常用的方式。好处是扩展性好，但缺点是管理复杂。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;在面向百万、千万级别的用户规模时，横向扩展的Redis切片集群会是一个非常好的选择。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;在使用单个实例时，数据保存在哪里，客户端访问哪里，都是非常明确的。但是切片集群不可避免要解决多个实例分布式管理的问题，需要解决两大问题：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;数据切片后，在多个实例之间如何分布？&lt;/li&gt;
&lt;li&gt;客户端怎么确定想要访问的数据在哪个实例上？&lt;/li&gt;
&lt;/ul&gt;&lt;h2&gt;数据切片和实例的对应分布关系&lt;/h2&gt;
&lt;p&gt;在Redis 3.0之前，官方没有切片集群的方案，从3.0开始，官方提供了一个名为Redis Cluster的方案，用于实现切片集群。&lt;/p&gt;
&lt;p&gt;Redis Cluster方案采用哈希槽来处理数据和实例之间的映射关系。这里有两个映射关系：键值对与哈希槽的映射关系和哈希槽与实例的映射关系。下面我们来介绍一下这两个映射关系的映射过程。&lt;/p&gt;
&lt;h3&gt;键值对与哈希槽的映射过程&lt;/h3&gt;
&lt;p&gt;根据键值对的key，按照&lt;a href=&quot;https://www.cnblogs.com/yueerya/p/11507698.html&quot;&gt;CRC16算法&lt;/a&gt;计算一个16bit的值。&lt;/p&gt;
&lt;p&gt;再用这个16bit值对16384取模，得到0~16383范围内的模数，每个模数代表一个相应编号的哈希槽。&lt;/p&gt;
&lt;p&gt;说明：&lt;strong&gt;Redis切片集群最多提供16384个哈希槽。&lt;/strong&gt;&lt;/p&gt;
&lt;h3&gt;哈希槽与实例的映射过程&lt;/h3&gt;
&lt;p&gt;哈希槽与实例的映射关系有两个方案设置，分为自动和手动。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;自动映射&lt;/strong&gt;：使用&lt;code&gt;cluster create&lt;/code&gt;命令创建集群，Redis会自动把这些槽平均分布在集群实例上。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;手动映射&lt;/strong&gt;：使用&lt;code&gt;cluster meet&lt;/code&gt;命令搬运建立实例间的连接，形成集群，再使用&lt;code&gt;cluster addslots&lt;/code&gt;命令，指定每个实例上的哈希槽个数。&lt;/p&gt;
&lt;p&gt;说明：&lt;strong&gt;在手动分配哈希槽时，需要把16384个槽都分配完，否则Redis集群无法正常工作。&lt;/strong&gt;&lt;/p&gt;
&lt;h2&gt;客户端如何定位数据&lt;/h2&gt;
&lt;p&gt;客户端和集群实例建立连接后，实例就会把哈希槽的分配信息发给客户端。&lt;/p&gt;
&lt;p&gt;集群刚创建时，实例如何互相知道哈希槽信息？Redis实例会扩展哈希槽信息，每个Redis实例都拥有完整的哈希槽信息。&lt;/p&gt;
&lt;p&gt;另外，客户端收到哈希槽信息后，会缓存在本地，以便在客户端后续请求直接访问实例。&lt;/p&gt;
&lt;p&gt;但在集群中，实例和哈希槽的对应关系不是一成不变的。最常见的变化：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;在集群中，实例有新增或删除，Redis需要重新分配哈希槽；&lt;/li&gt;
&lt;li&gt;为了负载均衡，Redis需要把哈希槽在所有实例上重新分布一遍。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;Redis Cluster提供一种&lt;strong&gt;重定向机制&lt;/strong&gt;，类似于HTTP协议的重定向。&lt;/p&gt;
&lt;p&gt;客户端把一个键值对操作请求发给一个实例，如果这个实例没有这个键值对映射的哈希槽，这个实例就会给客户端返回MOVED命令的响应结果，包含新实例的访问地址。&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;32&quot;&gt;
&lt;pre&gt;
&lt;span&gt;GET hello:key (error) 
MOVED &lt;/span&gt;13320 172.16.19.5:6379
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;其中，MOVED命令表示，客户端请求的键值对所在的哈希槽13320，实际是在172.16.19.5这个实例上。&lt;/p&gt;
&lt;p&gt;如果哈希槽没有完成迁移，客户端请求的数据并不在哈希槽时，客户端就会收到一条ASK报错信息，如下所示：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;32&quot;&gt;
&lt;pre&gt;
&lt;span&gt;GET hello:key (error) 
ASK &lt;/span&gt;13320 172.16.19.5:6379
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;这个结果中的ASK命令就表示，客户端请求的键值对所在的哈希槽13320，在172.16.19.5这个实例上，但是这个哈希槽正在迁移。&lt;/p&gt;
&lt;p&gt;和MOVED命令不同，&lt;strong&gt;ASK命令并不会更新客户端缓存的哈希槽分配信息&lt;/strong&gt;。&lt;/p&gt;
&lt;h2&gt;Redis Cluster为什么不采用把key直接映射到实例的方式&lt;/h2&gt;
&lt;p&gt;整个集群存储key的数量是无法预估的，key的数量非常多时，直接记录每个key对应的实例映射关系，这个映射表会非常庞大，这个映射表无论是存储在服务端还是客户端都占用了非常大的内存空间。&lt;/p&gt;
&lt;p&gt;Redis Cluster采用无中心化的模式（无proxy，客户端与服务端直连），客户端在某个节点访问一个key，如果这个key不在这个节点上，这个节点需要有纠正客户端路由到正确节点的能力（MOVED响应），这就需要节点之间互相交换路由表，每个节点拥有整个集群完整的路由关系。如果存储的都是key与实例的对应关系，节点之间交换信息也会变得非常庞大，消耗过多的网络资源，而且就算交换完成，相当于每个节点都需要额外存储其他节点的路由表，内存占用过大造成资源浪费。&lt;/p&gt;
&lt;p&gt;当集群在扩容、缩容、数据均衡时，节点之间会发生数据迁移，迁移时需要修改每个key的映射关系，维护成本高。&lt;/p&gt;
&lt;p&gt;而在中间增加一层哈希槽，可以把数据和节点解耦，key通过Hash计算，只需要关心映射到了哪个哈希槽，然后再通过哈希槽和节点的映射表找到节点，相当于消耗了很少的CPU资源，不但让数据分布更均匀，还可以让这个映射表变得很小，利于客户端和服务端保存，节点之间交换信息时也变得轻量。&lt;/p&gt;
&lt;p&gt;当集群在扩容、缩容、数据均衡时，节点之间的操作例如数据迁移，都以哈希槽为基本单位进行操作，简化了节点扩容、缩容的难度，便于集群的维护和管理。&lt;/p&gt;
&lt;h2&gt;小结&lt;/h2&gt;
&lt;ul&gt;&lt;li&gt;数据扩容有两种方式：纵向扩展和横向扩展。Redis切片集群提供了横向扩展的模式。&lt;/li&gt;
&lt;li&gt;集群的实例增减或者数据重新分布，会导致哈希槽和实例的映射关系发生变化。当客户端发送请求时，会收到命令执行报错信息。&lt;/li&gt;
&lt;li&gt;在Redis3.0之前，Redis官方并没有提供切片集群方案。业界提供了一些成熟的方案，例如基于客户端分区的ShardedJedis，基于代理的Codis、Twemproxy等。&lt;/li&gt;
&lt;/ul&gt;&lt;h2&gt;参考资料&lt;/h2&gt;
</description>
<pubDate>Tue, 05 Jan 2021 00:24:00 +0000</pubDate>
<dc:creator>大杂草</dc:creator>
<og:description>现在有一个场景：要用Redis保存5000万个键值对，每个键值对大约是512B，要怎么部署Redis服务呢？ 第一个方案，也是最容易想到的，需要保存5000万个键值对，每个键值对约为512B，一共需要</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/liang24/p/14189712.html</dc:identifier>
</item>
<item>
<title>一个以小说的叙述方式书写的项目 - 咖啡机（K.F.J）</title>
<link>http://www.cnblogs.com/strick/p/14143349.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/strick/p/14143349.html</guid>
<description>&lt;p&gt;　　最近在读一本名为《&lt;span&gt;&lt;a href=&quot;https://book.douban.com/subject/34820436/&quot; target=&quot;_blank&quot;&gt;&lt;span&gt;凤凰项目：一个IT运维的传奇故事&lt;/span&gt;&lt;/a&gt;&lt;/span&gt;》的书，读后颇有感触，从业这么多年，的确碰到过书中的很多场景，书中描绘的故事其实就是现实工作中的各类缩影。&lt;/p&gt;
&lt;p&gt;　　本书讲述了一位IT经理临危受命，在未来董事的帮助和自己经验的支撑下，改变了公司混乱的局面，最终挽救了一家具有悠久历史的汽车配件制造商的故事。&lt;/p&gt;

&lt;p&gt;　　书中出场的人物，囊括了公司中的各类岗位（有管理层，也有基层），并且性格虽然各异，但很具有代表性。下面只列出了书中的几个人物。&lt;/p&gt;
&lt;p&gt;　　比尔：本书主人公，由于他的两个上司被赶走了，所以只能被CEO临危受命，直升为IT运营部副总裁。&lt;/p&gt;
&lt;p&gt;　　史蒂夫：公司CEO，刚辞去担任8年之久的董事长职务，董事会给了他6个月时间，要求他对公司现状作出显著的改进。&lt;/p&gt;
&lt;p&gt;　　莎拉：运营部高级副总裁，总是能让别人替她背黑锅，特别是让IT部门的人背黑锅。多年来，她一直能逃脱各种应负的责任。&lt;/p&gt;
&lt;p&gt;　　韦斯：技术运营部总监，负责一千多台Windows服务器以及数据库和网络团队的技术问题。说话响亮、直率、信口开河。&lt;/p&gt;
&lt;p&gt;　　布伦特：首席工程师，韦斯的下属，一直参与IT部门开展的各大重要项目。每天在疲于奔命，处理突发、棘手或没人知道的项目问题，常常因为各种原因而导致各类计划延期。&lt;/p&gt;
&lt;p&gt;　　帕蒂：IT服务支持部总监，管理所有的1级和2级客服技术人员，处理故障维修事件，并为业务部门提出的需求提供支持。还掌管一些维系整个IT运维部的关键流程和工具，比如报修系统、监控系统，以及组织变更管理会议。&lt;/p&gt;
&lt;p&gt;　　约翰：首席信息安全官，曾让公司很多人厌恶的人，因为大家觉得他在阻碍自己的工作，不过最终他做出了改变，适应了公司环境，和同事一起改变了公司。&lt;/p&gt;
&lt;p&gt;　　克里斯：应用程序开发部副总裁，开发业务所需的应用程序和代码，现在生活完全以凤凰项目为主导。&lt;/p&gt;
&lt;p&gt;　　埃瑞克：候选董事，公司主席和史蒂夫都特别关注的人，想尽办法邀请他加入董事会，经常为比尔指点迷津。&lt;/p&gt;

&lt;p&gt;&lt;span&gt;&lt;strong&gt;1）工资核算故障&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;　　比尔刚任命就遇到了麻烦的工资核算故障，这个故障会影响员工的工资，这样就触犯了无数条州立劳动法，而且毫无疑问，工会马上就要大吵大闹了。&lt;/p&gt;
&lt;p&gt;　　韦斯：“联系SAN供应商，因为在尝试恢复SAN之后，数据服务就完全停止了，但SAN现场工程师至少还要4个小时才能过来。”&lt;/p&gt;
&lt;p&gt;　　比尔判断当前的方向是错误的，于是去找布伦特了解情况。期间查检查了昨天从工资核算数据库里导出的数据，发现所有工厂小时工的社保卡号全乱了。&lt;/p&gt;
&lt;p&gt;　　这是一条非常重要的线索。数据库里只有一个字段损坏了，听起来绝对不像是个SAN故障。&lt;/p&gt;
&lt;p&gt;　　再次询问布伦特，他说：“昨天开发计时应用程序的人，反馈了一个数据库表结构的奇怪问题。”&lt;/p&gt;
&lt;p&gt;　　马上联系那名开发人员，但他在休假中。事情有些眉目了，也许是一个开发人员为了能去度假，塞进了一个紧急的变更。可能是约翰推进的某个紧急项目的一部分。&lt;/p&gt;
&lt;p&gt;　　约翰的人从不按照我们的流程来，所以总是惹出麻烦。于是马上联系了他，他那边有一个关于PII存储的紧急审计问题，PII就是个人验证信息的简称，欧盟法律禁止存储这类数据。&lt;/p&gt;
&lt;p&gt;　　约翰：“根据原定计划，差不多一年之前就该完成部署，但尽管我不断催促，它一直都没能完成。现在没时间了。支付卡行业审计师，本月晚些时候要来，所以就加快了计时应用团队的工作进度。”&lt;/p&gt;
&lt;p&gt;　　帕蒂听后强调：“对产品进行任何变更，都有一套规定的程序和流程。如果绕过它们，惹出大麻烦，自己的人还得帮忙修补。 为什么不按照流程去做？”&lt;/p&gt;
&lt;p&gt;　　约翰不以为然：“如果按照流程来，那么下一个可能的部署窗口期要等4个月。但审计师们可是下周就要来了！”&lt;/p&gt;
&lt;p&gt;　　当比尔问约翰有没有进行过测试时，他回答没有测试环境。虽然之前已经提出过预算申请，但还是不了了之。&lt;/p&gt;
&lt;p&gt;　　帕蒂抱怨道，她一直试图让大家使用变更管理流 程和工具，但就像约翰那样，没人用它。报修系统也一样，都是有一搭没一搭的。&lt;/p&gt;
&lt;p&gt;　　帕蒂继续说：“变更咨询委员会，也就是CAB，会碰一两次头。用不了几个星期，大家就会说自己太忙，不再参加会议了。或者由于时间紧迫，他们不等得到授权就进行变更。不论是哪一种情况，变更咨询委员会都会在一个月内变得形同虚设。”&lt;/p&gt;
&lt;p&gt;　　计时应用直到晚上7点才得以恢复。半夜11点，SAN终于恢复运行。比尔作为IT运维部副总裁的第一天表现并不太好。&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;2）凤凰项目批斗会&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;　　会议室里大约有25个人。很多业务领域负责人都到场了，其中有些是莎拉的下属，克里斯也在。&lt;/p&gt;
&lt;p&gt;　　为了支援凤凰项目，最近两年他的团队人数增加了50人，其中很多来自外包公司。克里斯经常被要求用更短的时间、更少的经费去完成并交付更多的产品。&lt;/p&gt;
&lt;p&gt;　　史蒂夫坐在会议桌边唯一一张空椅子的右侧。&lt;/p&gt;
&lt;p&gt;　　上周凤凰项目第1阶段 的关键路径上有12项任务，目前只完成了其中的3项。会议室里响起一片叹息声，好几个人开始窃窃私语。&lt;/p&gt;
&lt;p&gt;　　莎拉认为是比尔的团队一直在拖后腿。分不清轻重缓急，不适应去支持这样举足轻重的项目。&lt;/p&gt;
&lt;p&gt;　　莎拉继续强调，已经为凤凰项目投入了超过两千万美元，而且已经延迟了将近两年。现在必须把凤凰项目推向市场。&lt;/p&gt;
&lt;p&gt;　　克里斯信口开河地确定了一个投产日期，全然不理会在部署之前比尔团队需要做多少工作。&lt;/p&gt;
&lt;p&gt;　　韦斯认为克里斯团队的代码性能太差，部署的技术参数也不提供，测试环境无法搭建，并且必需的服务器和网络设备的交货时间需要三周。&lt;/p&gt;
&lt;p&gt;　　比尔见过类似场景，剧本很简单，首先，接到一项紧急的日期驱动项目，对外承诺发布日期不能延迟；然后，增添一大帮开发人员，用完了所有的进度时间，没时间进行测试或运营部署；随后，由于没人愿意错过部署日期，开发部门之后接手的人只得不计后果地猛抄近路。&lt;/p&gt;
&lt;p&gt;　　结果从来不理想。通常情况下，软件产品实在太不稳定、太不可用，连那些曾经强烈要求这些产品的人最终也会说它不值得上市。到最后，总是IT运维部在通宵达旦地为那些糟糕的代码埋单，每隔一小时重启一次服务器。&lt;/p&gt;
&lt;p&gt;　　莎拉指责比尔缺乏对于紧迫性的必要认知。追求完美是成事的大敌。当前需要建立正向现金流，如果不夺回市场份额，就无法做到这一点。而要夺回市场份额，就必须部署凤凰。&lt;/p&gt;
&lt;p&gt;　　在大家争论不休时，史蒂夫最终说道，“我们已经向投资方和分析师们许诺过，会在本季度发布凤凰项目。”&lt;/p&gt;
&lt;p&gt;　　莎拉驳斥了比尔的所有观点，把史蒂夫引上了一条不计后果的毁灭之路。&lt;/p&gt;
&lt;p&gt;　　史蒂夫最终敲定下周六为上线时间，凤凰将在前一天下午5点部署。&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;3）人力资源问题&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;　　IT运维部有150名员工，平均每1.5人就有一个项目。大部分人力资源都流向了凤凰项 目。审计合规修复是第二大项目。&lt;/p&gt;
&lt;p&gt;　　第三大项目是事故及故障修复工作。目前为止，它占用了员工大约75%的工作时间。由于这些工作常常涉及关键业务系统，所以事故处理的优先级比包括凤凰和审计发现修复在内的其他所有工作都要高。&lt;/p&gt;
&lt;p&gt;　　几乎每个人都难以完成他们的项目工作。即使有时间，他们也得尽力优先处理所有的工作任务。业务部门的人不断要求我们的员工为他们办事，尤其是市场部的人。&lt;/p&gt;
&lt;p&gt;　　公司的所有管理人员几乎都是直接去找他们喜欢的IT人员办事，不是请人帮个忙，就是强迫他们做事。 &lt;/p&gt;
&lt;p&gt;　　根据粗略估算，团队可能需要多招7个人：3 个数据库管理员、2个服务器工程师、1个网络工程师，还有1个虚拟技术工程师。当然啦，找到这些人需要一定时间，上岗之后他们还要经过6~12个月的时间才能完全胜任工作。&lt;/p&gt;
&lt;p&gt;　　在向史蒂夫提出招人时，他回答：“凤凰项目已经超支一千万美元，我们必须马上得到正向现金流。你拥有全公司最昂贵的一些人力资源。只能好好使用现有的人手。”&lt;/p&gt;
&lt;p&gt;　　他继续说道：“我给你的建议是，去找你的同事提出充分的理由。如果理由确实合情合理，他们应该会愿意转让一部分预算给你。不过我要说清楚：增加任何预算都是不可能的。如果说会有什么调整的话，可能还得在你的部门里减掉几个人。”&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;4）布伦特&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;　　布伦特实际上并不像我们认为的那样聪明绝顶。也可能他是个技术界的爱因斯坦，别指望能找得到和他同等水平的员工。还可能他是故意让自己显得无可或缺，以免其他人抢了他的工作。&lt;/p&gt;
&lt;p&gt;　　布伦特看起来确实是在真心诚意地帮助所有依靠IT系统的人解决问题。但让我失望的是，大家似乎都把他当作免费的私人极客电脑特工。这是以损害凤凰项目为代价的。&lt;/p&gt;
&lt;p&gt;　　比尔把项目管理会议上提到的五项任务拿给他看。他迅速地说：“这些我都已经完成一半了。只是需要有几个小时不受打扰，安安静静地完成它们。假如可以的话，我会在家里把这些做完的，但是网络连接太慢了。”&lt;/p&gt;
&lt;p&gt;　　随后比尔让布伦特把每个向他求助的人都转给韦斯，确保人力资源完成凤凰项目的关键工作。&lt;/p&gt;
&lt;p&gt;　　每一次让布伦特处理某个别人谁都无法处理的修复工作，他就变得更加 聪明，而整个系统则变得更加蠢笨。现在得终止这种状态。&lt;/p&gt;
&lt;p&gt;　　可以建立一个3级工程师的人力资源库，由他们处理流转过来的工作，但是得把布伦特屏蔽在资源库之外。这些3级工程师要负责完成所有故障的处理，而且他们应该是唯一能够接近布伦特的人——在规定条件下。&lt;/p&gt;
&lt;p&gt;　　如果想和布伦特讨论，他们必须先得到韦斯或比尔的批准。他们要负责记录学到的东西，永远不准布伦特反复解决同一个问 题。比尔每周都会逐项检查这些问题，如果发现布伦特就同一个问题出手了两次，3级工程师和布伦特都要受罚。&lt;/p&gt;
&lt;p&gt;　　每解决一个问题，知识库里就会多一篇关于如何解决某个疑难杂症的文章，而且能够实施修复的人会越来越多。&lt;/p&gt;
&lt;p&gt;　　帕蒂说，“我会定义布伦特的新流程。很乐意通过你和韦斯去找布伦特解决问题。但我们怎么才能劝阻物流部副总裁之类的人不再直接去找布伦特呢？”&lt;/p&gt;
&lt;p&gt;　　比尔立刻回答：“谁要那么做了，就把他们的名单收集起来，我还会给他们的上司打电话，让他们不准再犯。然后我会让史蒂夫知道，这些人都是怎么干扰凤凰项目的。”&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;5）凤凰上线&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;　　周五晚上7点30分，凤凰部署工作如期启动后的两小时，进展并不顺利。&lt;/p&gt;
&lt;p&gt;　　IT运维团队下午4点就在这里全体集合，严阵以待。但无事可做， 因为克里斯的团队没有发出任何指令；他们一直调试到最后一刻。&lt;/p&gt;
&lt;p&gt;　　下午4点30分，威廉一阵风似地冲进了凤凰作战室，他暴跳如雷，因为没人能在测试环境下运行所有的凤凰代码。更糟糕的是，凤凰为数不多正在运行的部分也没能通过各项关键检测。&lt;/p&gt;
&lt;p&gt;　　几分钟前，有个开发人员居然走进来说：“看，在我的笔记本电脑上，它已经在运行了。这能有多难？”&lt;/p&gt;
&lt;p&gt;　　韦斯开始骂脏话，两个我们的工程师和三个威廉的工程师则开始仔细研究那个开发人员的笔记本电脑，设法弄明白它和测试环境有什么不一样。&lt;/p&gt;
&lt;p&gt;　　威廉继续说道：“我真的毫无头绪。代码改得太快了，我们跟不上，凤凰将在投产中炸毁。我和克里斯谈过好几次停止发布的事，但他和莎拉完全压我一头。”&lt;/p&gt;
&lt;p&gt;　　每次发现问题，重发一个新版本，要把所有东西都设置好并运行起来，大约需要半小时，然后执行冒烟测试又需要三小时。在那段时间里，QA可能会从开发部那边收到另外三个版本。&lt;/p&gt;
&lt;p&gt;　　威廉相信每个人都得通宵加班了。并且真正的风险是，明天上午8点门店开始营业时，恐怕无法让凤凰运转起来。那是个大问题。&lt;/p&gt;
&lt;p&gt;　　比尔给史蒂夫、克里斯和莎拉发一封电子邮件，看看能否推 迟部署时间。&lt;/p&gt;
&lt;p&gt;　　史蒂夫说：“要是你能说服莎拉推迟试运行，那我们就谈谈。否则的话，继续努力吧。”&lt;/p&gt;
&lt;p&gt;　　莎拉说：“每个人都做好了准备，唯独你没有。市场营销、开发、项目管理等部门都全力以赴地扑在这个项目上。现在轮到你了。 我们必须继续！”&lt;/p&gt;
&lt;p&gt;　　与此同时，韦斯还带来另一个坏消息，凤凰数据库转换要比原先设想慢上几千倍。 几小时前就应该完成转换，但现在只完成了10%。也就是说，全部数据要到周二才能转换好。&lt;/p&gt;
&lt;p&gt;　　这会导致明天所有店内POS系统都会宕机，那就意味着门店的收银机将无法工作。也就是说，得手动收银，手动刷卡。&lt;/p&gt;
&lt;p&gt;　　他继续说：“我们找到了十五台服务器，但数据中心的机架上没有足够空间安置这些服务器了。只得花大力气重新布线、搭架子，把各种垃圾移来移去。我们对虚拟化投入巨资，这本该避免此类麻烦。但是，开发部解决不了性能问题，却归咎于虚拟化。所以，只能把所有东西都挪回实体服务器！”&lt;/p&gt;
&lt;p&gt;　　到了周六下午2点，事态愈发不可收拾，糟糕程度不断突破比尔原本以为的底线。&lt;/p&gt;
&lt;p&gt;　　使用凤凰网站的客户抱怨，网站不是宕机就是慢到无法使用。在看过电视和报纸广告后，所有原本兴致勃勃尝试新服务的客户都开始抱怨IT大败笔。&lt;/p&gt;
&lt;p&gt;　　而那些成功在线订购的客户则在去门店提货时才如梦初醒。那时大家才发现，凤凰似乎会随机丢失交易，其他情况下，它又会从客户信用卡上划走两倍乃至三倍的费用。&lt;/p&gt;
&lt;p&gt;　　因为可能已无法保证销售订单数据的完整性，财务部的安愤怒地驾车赶了过来。现在她的团队已经在走廊对面建立了另一间作战室，接听门店的来电，处理问题订单。中午时分，数百名愤怒客户的传真从各门店发来，已经堆成了小山。&lt;/p&gt;
&lt;p&gt;　　下午4点30分，比尔又收到一个坏消息，推特上疯传凤凰网站正在泄露客户的信用卡号。他们甚至贴出了截屏。当你清空购物车时，会话崩溃，并显示出上一个成功订单的信用卡号。&lt;/p&gt;
&lt;p&gt;　　到了周一，凤凰危机已经演变成了一场公关丑闻。它上了所有技术网站的头条新闻。&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;6）救火&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;　　那些救火的事情（计划外的工作）代替了计划内的工作，不论是项目工作还是变更工作。&lt;/p&gt;
&lt;p&gt;　　埃瑞克说它是最具破坏性的一类工作。它不像其他类型的工作那样，是真正意义上的“工作”。其他三类工作（业务项目，内部项目以及变更）都是出于需要而计划去做的。&lt;/p&gt;
&lt;p&gt;　　比尔想到了与埃瑞克的对话，立刻向他打电话取经。&lt;/p&gt;
&lt;p&gt;　　埃瑞克说：“计划外工作是恢复性工作，几乎总是让你远离目标。因此，知道你的计划外工作从何而来就显得尤为重要。”&lt;/p&gt;
&lt;p&gt;　　他认为比尔已经开始着手稳定工作环境了，已经开始可视化管理IT运维部里的半成品了，而且已经开始保护自己的约束点——布伦特了，还强化了一种严明纪律的工作氛围。&lt;/p&gt;
&lt;p&gt;　　在大多数工厂里，总有那么一小部分资源，不论是人、机器还是原材料，决定了整个系统的产出。将其称之为约束点——或者瓶颈。&lt;/p&gt;
&lt;p&gt;　　在建立起一个可信赖的系统用以管理通向约束点的工作流之前，约束点经常是被闲置的，也就是说，约束点可能在很大程度上未被充分利用。&lt;/p&gt;
&lt;p&gt;　　那就意味着，没有向业务部门交付全部的可用资源。也可能没有还清技术债务，因此随着时间的推移，遇到的问题和计划外工作量会不断增加。&lt;/p&gt;
&lt;p&gt;　　高德拉特在《目标》里描述了五个聚焦步骤，第一步是确认约束点。&lt;/p&gt;
&lt;p&gt;　　第二步是利用约束点，确保不让约束点浪费任何时间。永远不要让约束点迁就别的资源而干等着，而是应该专注于 IT运维部对当前所需完成工作中优先级最高的那一项。&lt;/p&gt;
&lt;p&gt;　　第三步就是把约束点置于次要地位。&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;7）封版两周&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;　　比尔提出IT运维部和开发部在两周内不再接受新项目，并且除了与凤凰相关的工作之外，停止IT运维部的其他所有工作。&lt;/p&gt;
&lt;p&gt;　　两周后一切照常，此举的目标是提高整个系统的生产能力，不只是提高任务的完成数量。&lt;/p&gt;
&lt;p&gt;　　韦斯说：“难道那不会让我们中的大部分人闲得无聊、无事可干吗？那就是130个IT运维部的人干坐着。那听起来不是有点儿……浪费吗？” &lt;/p&gt;
&lt;p&gt;　　埃瑞克嘲讽地笑了笑，说：“我来告诉你什么是浪费。超过一千个变更卡在系统里，看不到完成它们的方法，这听起来怎么样？”&lt;/p&gt;
&lt;p&gt;　　卡片数量一直在增加。如果那就是半成品，显然增加的速度已经失控了。恐怕用不了几周，那些卡片会堆到天花板上。&lt;/p&gt;
&lt;p&gt;　　接下来一小时中大家达成的一致意见令人惊讶。IT运维部将会冻结所有和凤凰无关的工作。开发部不能让他们的二十多个与凤凰无关的项目空转，但他们会冻结所有部署工作。&lt;/p&gt;
&lt;p&gt;　　换句话说，接下来两周内，不会有工作从开发部流向IT运维部了。&lt;/p&gt;
&lt;p&gt;　　此外，大家将确认最主要的技术债务，开发部会对其进行处理，以减少问题应用程序所产生的计划外工作量。这些都会让我团队的工作负荷变得截然不同。&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;8）跨团队协交接&lt;/strong&gt; &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;　　埃瑞克说过，等待时间取决于资源使用率。“等待时间是‘忙碌时间百分比’除以‘空闲时间百分比’。也就是说，如果一个资源的忙碌时间是50%，那么它的空闲时间也是50%。等待时间就是50%除以50%，也就是一个时间单位，一个任务在处理前的排队等待时间为一个小时。”&lt;/p&gt;
&lt;p&gt;　　对这个凤凰任务来说，假设有7个交接步骤，而且每一个资源都有90%的时间是忙碌的，那么任务排队等待的总时间就是9小时乘以7个步骤。&lt;/p&gt;
&lt;p&gt;　　在一个部门内创建工作并确定其优先级就很难，而管理多个部门之间的工作则是难上加难。&lt;/p&gt;
&lt;p&gt;　　板上的每一张纸都像是这个凤凰‘任务’。看起来似乎是一个单独人员的任务，但实际上，它是需要在多个人员之间进行多次交接的多个步骤。难怪柯尔斯顿的项目时间预排都没能兑现。&lt;/p&gt;
&lt;p&gt;　　比尔补充道：“如果能够把所有的经常性部署工作标准化，最终就能达到产品配置的一致性。现在的基础架构过于多样化，就像雪花一样——没有两片重样的。布伦特之所以会成为布伦特，是因为允许他建立起只有他能理解的基础架构。”&lt;/p&gt;
&lt;p&gt;　　部署就像是制造工厂里的总装配。每一条工作流都要经过它，而且缺了它你就不能发出产品。&lt;/p&gt;
&lt;p&gt;　　帕蒂提出了一个新角色，兼有项目经理和稽查员的职能。让所有已完成的工作都快速有效地交接到下一个工作中心。必要时，这个人要在工作中心等待，直到工作完成并运往下一个工作中心。&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;9）与业务人员的访谈&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;　　帕蒂和比尔将对业务流程负责人进行访谈，主题是“理解客户的需求 与期望”、“产品系列”、“上市时间”以及“销售渠道”。&lt;/p&gt;
&lt;p&gt;　　今天是星期五，计划访谈制造销售部副总裁罗恩·约翰逊。&lt;/p&gt;
&lt;p&gt;　　他认为差劲的‘了解客户的需求和期望’影响了‘销售预测准确率’。他还详细地告诉我们，他手下的经理们想从客户关系管理系统 （CRM）中拿到他们需要的报告有多困难。&lt;/p&gt;
&lt;p&gt;　　他继续说道：“在季末最后几天电话不能用了，客户没法下订单，或者作出临时变更！这件事延误了150万美元的订单，十个客户重新评估了他们的合同，又有500万美元的订单岌岌可危。”&lt;/p&gt;
&lt;p&gt;　　下次的访谈对象是玛姬·李，她发起了凤凰项目。她是超过一半IT项目的业务发起人。此外，玛姬还负责保证每一家门店的货品都尽可能地丰富多样，她还负责确定公司的售货类别和定价方针。&lt;/p&gt;
&lt;p&gt;　　她总结道：“归根结底，我对‘了解客户的需求和期望’的衡量标准是，客户是否会向朋友推荐我们。”&lt;/p&gt;
&lt;p&gt;　　她继续说道，“大多数时候，我们都在盲目行动。理想情况下，销售数据会告诉我们客户想要什么。也许你认为，有了订单输入系统和库存管理系统中的数据，就能做到这一点。但这些数据几乎总是错的。”&lt;/p&gt;
&lt;p&gt;　　数据质量太差，因此无法凭借这些数据来进行各种预测。现有的最佳数据，来自于两月一次的门店经理访谈，以及一年两次的核心客户群访谈。&lt;/p&gt;
&lt;p&gt;　　她希望从门店和在线渠道得到准确及时的订单信息。不用像现在这样杂乱无章地运用这些数据。运用那些数据来设计市场推广活动，不断推出“A或B”产品选择测试，以发现客户认可的报价。一旦发现哪些有效，就能在全部客户中复制推广。这样做就能为罗恩创建一个巨大的、可预测的销售漏斗。&lt;/p&gt;
&lt;p&gt;　　运用那些信息来推进生产计划，那样就能管理供求曲线。让正确的产品出现在正确的货架上，并一直备好库存。平均每客户销售额将会一路冲高，平均订单金额也会上升。&lt;/p&gt;
&lt;p&gt;　　帕蒂插话说：“你们把产品推向市场的合理时间是多久？”&lt;/p&gt;
&lt;p&gt;　　她立刻回答：“现在？产品需要在六个月内上市。最多九个月。否则， 一些其他的公司就会剽窃我们的想法，让产品出现在竞争对手的货架上，并抢走大部分市场份额。”&lt;/p&gt;
&lt;p&gt;　　在竞争的时代，游戏规则就是‘快速上市，快速淘汰’。不能为推出一个产品而制定为期几年的工作计划，一直等到最后才弄清手上拿的牌是赢家还是输家。而是需要短而快的周期，不断整合来自市场的反馈。&lt;/p&gt;
&lt;p&gt;　　迪克希望研发投入可以平均回报超过十个百分点。那是内部最低预期资本收益率。&lt;/p&gt;
&lt;p&gt;　　九个月内向公司返回现金，这是最长时间了？而凤凰上花了将近三年时间，依然尚未创造出期望的商业价值。也许致力于凤凰项目是完全走错了路。&lt;/p&gt;
&lt;p&gt;　　接着，玛姬描述了围绕IT项目资源的激烈竞争。“我们的计划周期是6~12个月。谁能知道自己三年以后应该做什么项目？”&lt;/p&gt;
&lt;p&gt;　　她说了一些想法，包括招聘更多IT人员，把一些IT人员专门划拨给她的团队，更多关注那些妨碍IT项目队列的项目，等等。&lt;/p&gt;
&lt;p&gt;　　离开玛姬的办公室后，帕蒂欢呼道，“我无法相信玛姬和罗恩居然这么沮丧。你能相信吗，订单输入和库存管理系统中的不可靠数据又出现了？我也不能相信，按照当前的设计，凤凰实际上不能解决数据质量问题！”&lt;/p&gt;
&lt;p&gt;　　三年多来，已经为凤凰投入了两千多万美元。这个项目锁住了那么多半成品和资金，恐怕再也不能达到10%的内部最低预期资本收益率。 换句话说，凤凰原本就不该被批准。&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;10）访谈后的应对处理&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;　　比尔在白板上画了一张表格，其中有一列是“由于IT导致的业务风险”。&lt;/p&gt;
&lt;p&gt;　　约翰说，“通过描述IT可能会出现哪些阻碍业务成果实现的问题，就能帮助业务流程负责人拿到他们的奖金。这应该会非常有说服力。业务部门也许还会为我们所做的事而感谢我们呢，那可是让人耳目一新的改变。”&lt;/p&gt;
&lt;p&gt;　　对于电话和MRP系统，很快确定，预测评估指标包括遵守变更管理流程、监督审核生产变更、完成定期维护，以及排除所有已知单点故障。&lt;/p&gt;
&lt;p&gt;　　但在处理“客户的需求和期望”时遇到了困难。克里斯指出，“大部分问题是在上游产生的，因为市场营销人员不断输入格式不正确的库存量单位（Stock Keeping Unit，以下简称SKU）。市场营销部也得解决他们的问题。”&lt;/p&gt;
&lt;p&gt;　　对于“市场营销的需求和期望”，我们提出的评估指标包括凤凰支持每周报告并且最终支持每日报告的能力，市场营销部生成的有效SKU比例，等等。&lt;/p&gt;
&lt;p&gt;　　迪克在看好演示后说道：“比尔，你是说，公司里每一个人都在做每一件正确的事，但因为这些IT问题，我们大家还是不能完成目标？”&lt;/p&gt;
&lt;p&gt;　　“是的，先生。”比尔说，“和其他业务风险一样，由IT引起的运营风险也应该得到管理。换句说话，由IT引起的运营风险不是IT风险，而是业务风险。”&lt;/p&gt;
&lt;p&gt;　　然后他问：“好吧，你有什么建议？我想你已经想好一个建议了吧？”&lt;/p&gt;
&lt;p&gt;　　比尔开始推销自己的想法，“我想用三个星期的时间，逐一会见那张电子表格上的每一位业务流程负责人。我们需要更好地定义由IT引发的业务风险，并且达成共识，然后向你提出把那些风险纳入主要业绩指标的办法。我们的目标不只是提高经营业绩，还要对能否达成目标提供前瞻性指标，那样我们就能采取适当的行动了。”&lt;/p&gt;
&lt;p&gt;　　比尔继续说：“我们的进展太慢了，还有那么多半成品和功能吊在半当中。我们应该把发布变小变短，更快地回笼资金，那样才能达到内部最低预期资本回收率。克里斯和我有一些想法，但是会和公司现行的既定计划大不相同。”&lt;/p&gt;
&lt;p&gt;　　他保持沉默。然后果断地宣布：“你的两个提议我都同意。我会派安去帮助你。你需要公司里最优秀的人才。”&lt;/p&gt;
&lt;p&gt;　　星期五，约翰召集韦斯、帕蒂和比尔开了个会，为了将与安全性相关的工作量减少75%，他提出了五条建议。&lt;/p&gt;
&lt;p&gt;　　第一条建议是大幅度缩减SOX-404合规项目的范围。&lt;/p&gt;
&lt;p&gt;　　第二条建议是要求技术部弄清楚生产薄弱点一开始是如何产生的，并要求调整部署流程，杜绝此类情况再次发生。&lt;/p&gt;
&lt;p&gt;　　第三条建议是要求在帕蒂的变更管理流程中，标记出所有列入合规审计范围的系统——那样就能避免可能危及审计工作的变更—并要求创建持续记录文档，今后审计师会要求提供这些文档。&lt;/p&gt;
&lt;p&gt;　　第四条建议是通过清除所有存储或处理持卡人数据的东西，来缩减PCI合规项目规模，从销售系统里那个该死的自助餐厅销售点着手。&lt;/p&gt;
&lt;p&gt;　　第五条建议是用前几条建议所节省下来的时间，来偿还凤凰的所有技术债务。&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;11）又一次凤凰部署&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;　　按时完成了所有的应交付成果，不过和往常一样，依然有数不清的细节问题需要研究。&lt;/p&gt;
&lt;p&gt;　　目前已经稳定了基础架构。一旦真的发生难以避免的服务中断和事故，大家就像一台运行良好的机器一样运作起来。大家已建立起部落文化般的工作共识，这帮助大家比以往任何时候都能够更快地排除故障，而且，一旦真的需要把工作升级，也是可控而有序的。&lt;/p&gt;
&lt;p&gt;　　由于不断提高对基础架构和应用程序的产品监控，大家常常在业务部门察觉之前就知道了事故的情况。&lt;/p&gt;
&lt;p&gt;　　已经减少了项目积压，一部分是通过剔除序列中的无用项目来实现的。约翰已经完成了这件事。大家已经从审计准备和整改工作中削减了很多不必要的安全项目，代之以团队全员帮助实施的预防性安全项目。&lt;/p&gt;
&lt;p&gt;　　通过调整开发和部署流程，以一种有意义的、系统化的方式，加固并保护了应用程序和生产基础设施。而且，大家的信心不断增加，这些缺陷今后再也不会发生了。&lt;/p&gt;
&lt;p&gt;　　变更管理会议比以往更加顺利，也更有规律。大家不仅能了解团队正在做什么，还能了解工作确实在不断推进。&lt;/p&gt;
&lt;p&gt;　　大家比以往更加明白，自己应该做哪些事。员工从故障修复中获得了成就感。&lt;/p&gt;
&lt;p&gt;　　改进的不只是布伦特的工作。通过减少悬而未定的项目数量，让工作流转的通路保持通畅，那样，工作就能从一个工作中心快速移到另一个工作中心，并以打破纪录的速度完成。&lt;/p&gt;
&lt;p&gt;　　埃瑞克说，“我们正在制止工作缺 陷交接至下游工作中心，我们正在管理工作流，运用约束点来控制节奏，而且我们以审计部门和迪克那里拿到的结果为依据，比以往更好地理解了哪些是重要的工作，哪些不是。”&lt;/p&gt;
&lt;p&gt;　　最终，比尔主导发起了回顾小结环节，对我们自身的工作开展情况以及需要改进的方面进行自我评估。&lt;/p&gt;
&lt;p&gt;　　训练让伟大的团队达成最优表现。对任何流程或技能来说，训练成习惯，习惯成精通。&lt;/p&gt;
&lt;p&gt;　　约翰很快获得了迪克和史蒂夫的批准，找一个外包商接管自助餐厅POS 系统，并将其替换成具有商业支撑的体系。&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;12）特战队&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;　　威廉走到白板前开始画方框，一边画一边讲解那些步骤。接下来的十分钟里，他证明了一共有一百多个步骤，包括在开发环境下运行的自动测试、创建与开发相吻合的QA环境、朝其中部署代码、运行所有测试、部署并移至与QA相吻合的新模拟环境、负载测试，最后再把接力棒传给IT运维部。&lt;/p&gt;
&lt;p&gt;　　威廉弄完后，白板上有了三十个方框。&lt;/p&gt;
&lt;p&gt;　　布伦特站起身来，开始画方框，这些方框表示要部署的代码包，准备新的服务器实例，载入并配置操作系统、数据库及应用程序，对网络、防火墙及负载平衡器开展各种变更，随后进行测试，确保部署大功告成。&lt;/p&gt;
&lt;p&gt;　　有无数的配置需要正确地设定，系统要有足够的内存，所有文件都要安装到正确的位置，所有代码和整个环境也需要正确地操作。&lt;/p&gt;
&lt;p&gt;　　哪怕是一个小小的失误就能让一切崩塌。这显然意味着，大家应该比生产制造领域更加严格，更守纪律，更有规划性 。&lt;/p&gt;
&lt;p&gt;　　帕蒂指出：“在现有流程下，有两个问题不断出现： 在部署流程的每个阶段，在我们需要的时候，部署环境却总是没有就绪，即使已经准备就绪了，也需要大量返工才能让它们彼此同步。”&lt;/p&gt;
&lt;p&gt;　　她继续说：“返工和准备时间过长问题的另一个显著来源是代码打包流 程，在此阶段，IT运维部对经过开发部检查的内容进行版本控制，然后生成部署包。尽管克里斯和他的团队尽可能地记录代码和配置，总还有东西会遗漏，这些东西只有在部署之后，代码无法在环境中运行时才会被发现。”&lt;/p&gt;
&lt;p&gt;　　比尔问道，“布伦特，我们要怎么做才能建立一个通用环境创建流程，从而在同一时刻同时构建开发、QA和生产环境，并让它们保持同步？”&lt;/p&gt;
&lt;p&gt;　　他站起身来，画了三个方框，分 别叫作“开发”、“QA”和“生产”。然后他在它们下方画了另一个叫作“构建过程”的方框，这个方框有三个箭头，分别指向上方的三个方框。&lt;/p&gt;
&lt;p&gt;　　比尔对克里斯说：“这看起来很有希望。如果能把环境标准化，并把这些环境投入开发部、QA和IT运维部的日常使用，我们就能消除大部分在部署流程中因差异而导致的悲剧。” &lt;/p&gt;
&lt;p&gt;　　帕蒂看着画满方框的第一块白板说：“如果我们重新设计流程，就需要让正确的人员事先介入。这就像是制造工程组确保所有零部件都设计得有利于生产，而生产线也规划得有利于零部件的流转，理想状态下达到单一工作流。”&lt;/p&gt;
&lt;p&gt;　　威廉走到白板前，指着一个名叫“代码提交”的方框说：“我会改变这个步骤。不再通过源代码控制从开发部获得源代码或编译代码，而是希望拿到准备部署的打包好的代码。”&lt;/p&gt;
&lt;p&gt;　　他继续说，“我迫切地想要这样的代码包，我很乐意主动接管创建包。我也完全知道应该派谁去做这件事。她将负责开发交接。 一旦代码被标记为‘准备测试’，我们就要生成并提交代码包，那会触发一个QA环境的自动部署。今后，也许连生产环境也能自动部署。”&lt;/p&gt;
&lt;p&gt;　　未完待续.......&lt;/p&gt;


</description>
<pubDate>Tue, 05 Jan 2021 00:06:00 +0000</pubDate>
<dc:creator>咖啡机（K.F.J）</dc:creator>
<og:description>最近在读一本名为《凤凰项目：一个IT运维的传奇故事》的书，读后颇有感触，从业这么多年，的确碰到过书中的很多场景，书中描绘的故事其实就是现实工作中的各类缩影。 本书讲述了一位IT经理临危受命，在未来董事</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/strick/p/14143349.html</dc:identifier>
</item>
<item>
<title>Kubernetes官方java客户端之三：外部应用 - 程序员欣宸</title>
<link>http://www.cnblogs.com/bolingcavalry/p/14233415.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/bolingcavalry/p/14233415.html</guid>
<description>&lt;h3 id=&quot;欢迎访问我的github&quot;&gt;欢迎访问我的GitHub&lt;/h3&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/zq2599/blog_demos&quot; target=&quot;_blank&quot;&gt;https://github.com/zq2599/blog_demos&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;内容：所有原创文章分类汇总及配套源码，涉及Java、Docker、Kubernetes、DevOPS等；&lt;/p&gt;
&lt;h3 id=&quot;概览&quot;&gt;概览&lt;/h3&gt;
&lt;ol&gt;&lt;li&gt;以下提到的&lt;span&gt;java客户端&lt;/span&gt;都是指&lt;span&gt;client-jar.jar&lt;/span&gt;；&lt;/li&gt;
&lt;li&gt;本文是《Kubernetes官方java客户端》系列的第三篇，&lt;a href=&quot;https://xinchen.blog.csdn.net/article/details/107480015&quot; target=&quot;_blank&quot;&gt;《Kubernetes官方java客户端：准备》&lt;/a&gt;一文中咱们为实战做好了准备工作，从本文开始进入实战阶段；&lt;/li&gt;
&lt;li&gt;本文的目标是开发名为&lt;span&gt;OutsideclusterApplication的SpringBoot&lt;/span&gt;应用，该应用没有部署在K8S环境，使用的config文件是手动从K8S环境复制过来的，java客户端通过此config文件，能够远程访问到K8S上的API Server，实现所有客户端功能，整体部署情况如下图：&lt;br/&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/485422/202101/485422-20210105075620850-22254055.png&quot; alt=&quot;在这里插入图片描述&quot; loading=&quot;lazy&quot;/&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;ul&gt;&lt;li&gt;介绍完毕，开始编码；&lt;/li&gt;
&lt;/ul&gt;&lt;h3 id=&quot;源码下载&quot;&gt;源码下载&lt;/h3&gt;
&lt;ol&gt;&lt;li&gt;如果您不想编码，可以在GitHub下载所有源码，地址和链接信息如下表所示(&lt;a href=&quot;https://github.com/zq2599/blog_demos&quot; target=&quot;_blank&quot;&gt;https://github.com/zq2599/blog_demos&lt;/a&gt;)：&lt;/li&gt;
&lt;/ol&gt;&lt;ol start=&quot;2&quot;&gt;&lt;li&gt;这个git项目中有多个文件夹，本章的应用在&lt;span&gt;kubernetesclient&lt;/span&gt;文件夹下，如下图红框所示：&lt;br/&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/485422/202101/485422-20210105075621156-986482659.png&quot; alt=&quot;在这里插入图片描述&quot; loading=&quot;lazy&quot;/&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;h3 id=&quot;部署在k8s之外的应用：outsideclusterapplication&quot;&gt;部署在K8S之外的应用：OutsideclusterApplication&lt;/h3&gt;
&lt;p&gt;名为&lt;span&gt;OutsideclusterApplication&lt;/span&gt;的应用并未部署在K8S环境，该应用能够访问到K8S环境的关键，就是将K8S环境的config文件复制一份，然后放在OutsideclusterApplication能够访问到的位置：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;登录K8S环境，在~/.kube目录下找到config文件，复制此文件到OutsideclusterApplication运行的机器上(我这里存放的路径是/Users/zhaoqin/temp/202007/05/，和后面的代码中一致)；&lt;/li&gt;
&lt;li&gt;打开&lt;a href=&quot;https://xinchen.blog.csdn.net/article/details/107480015&quot; target=&quot;_blank&quot;&gt;《Kubernetes官方java客户端：准备》&lt;/a&gt;中创建的的&lt;span&gt;kubernetesclient&lt;/span&gt;工程，在里面创建子工程，名为&lt;span&gt;OutsideclusterApplication&lt;/span&gt;，这是个SpringBoot工程，pom.xml内容如下：&lt;/li&gt;
&lt;/ol&gt;&lt;pre&gt;
&lt;code class=&quot;language-xml&quot;&gt;&amp;lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&amp;gt;
&amp;lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;
         xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&amp;gt;
    &amp;lt;modelVersion&amp;gt;4.0.0&amp;lt;/modelVersion&amp;gt;

    &amp;lt;parent&amp;gt;
        &amp;lt;groupId&amp;gt;com.bolingcavalry&amp;lt;/groupId&amp;gt;
        &amp;lt;artifactId&amp;gt;kubernetesclient&amp;lt;/artifactId&amp;gt;
        &amp;lt;version&amp;gt;1.0-SNAPSHOT&amp;lt;/version&amp;gt;
        &amp;lt;relativePath&amp;gt;../pom.xml&amp;lt;/relativePath&amp;gt;
    &amp;lt;/parent&amp;gt;

    &amp;lt;groupId&amp;gt;com.bolingcavalry&amp;lt;/groupId&amp;gt;
    &amp;lt;artifactId&amp;gt;outsidecluster&amp;lt;/artifactId&amp;gt;
    &amp;lt;version&amp;gt;0.0.1-SNAPSHOT&amp;lt;/version&amp;gt;
    &amp;lt;name&amp;gt;outsidecluster&amp;lt;/name&amp;gt;
    &amp;lt;description&amp;gt;Demo project for Spring Boot&amp;lt;/description&amp;gt;
    &amp;lt;packaging&amp;gt;jar&amp;lt;/packaging&amp;gt;

    &amp;lt;dependencies&amp;gt;
        &amp;lt;dependency&amp;gt;
            &amp;lt;groupId&amp;gt;org.springframework.boot&amp;lt;/groupId&amp;gt;
            &amp;lt;artifactId&amp;gt;spring-boot-starter-web&amp;lt;/artifactId&amp;gt;
            &amp;lt;exclusions&amp;gt;
                &amp;lt;exclusion&amp;gt;
                    &amp;lt;groupId&amp;gt;org.springframework.boot&amp;lt;/groupId&amp;gt;
                    &amp;lt;artifactId&amp;gt;spring-boot-starter-json&amp;lt;/artifactId&amp;gt;
                &amp;lt;/exclusion&amp;gt;
            &amp;lt;/exclusions&amp;gt;
        &amp;lt;/dependency&amp;gt;
        &amp;lt;dependency&amp;gt;
            &amp;lt;groupId&amp;gt;org.projectlombok&amp;lt;/groupId&amp;gt;
            &amp;lt;artifactId&amp;gt;lombok&amp;lt;/artifactId&amp;gt;
            &amp;lt;optional&amp;gt;true&amp;lt;/optional&amp;gt;
        &amp;lt;/dependency&amp;gt;
        &amp;lt;dependency&amp;gt;
            &amp;lt;groupId&amp;gt;io.kubernetes&amp;lt;/groupId&amp;gt;
            &amp;lt;artifactId&amp;gt;client-java&amp;lt;/artifactId&amp;gt;
        &amp;lt;/dependency&amp;gt;
    &amp;lt;/dependencies&amp;gt;

    &amp;lt;build&amp;gt;
        &amp;lt;plugins&amp;gt;
            &amp;lt;plugin&amp;gt;
                &amp;lt;groupId&amp;gt;org.springframework.boot&amp;lt;/groupId&amp;gt;
                &amp;lt;artifactId&amp;gt;spring-boot-maven-plugin&amp;lt;/artifactId&amp;gt;
                &amp;lt;version&amp;gt;2.3.0.RELEASE&amp;lt;/version&amp;gt;
            &amp;lt;/plugin&amp;gt;
        &amp;lt;/plugins&amp;gt;
    &amp;lt;/build&amp;gt;

&amp;lt;/project&amp;gt;
&lt;/code&gt;
&lt;/pre&gt;
&lt;ol start=&quot;3&quot;&gt;&lt;li&gt;上述pom.xml中，需要注意的是在依赖spring-boot-starter-web的时候，使用exclusion语法排除了spring-boot-starter-json的依赖，这样做是为了将jackson的依赖全部去掉(spring-boot-starter-json依赖了jackson)，如此一来整个classpath下面就没有了jackson库，此时SpringBoot框架就会使用gson作为序列化和反序列化工具(client-java.jar依赖了gson库)；(这个问题在&lt;a href=&quot;https://xinchen.blog.csdn.net/article/details/107503695&quot; target=&quot;_blank&quot;&gt;《Kubernetes官方java客户端之二：序列化和反序列化问题》&lt;/a&gt;一文有详细介绍)&lt;/li&gt;
&lt;li&gt;新增OutsideclusterApplication.java，简单起见，该类即是引导类又是Controller：&lt;/li&gt;
&lt;/ol&gt;&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;package com.bolingcavalry.outsidecluster;

import com.google.gson.GsonBuilder;
import io.kubernetes.client.openapi.ApiClient;
import io.kubernetes.client.openapi.Configuration;
import io.kubernetes.client.openapi.apis.CoreV1Api;
import io.kubernetes.client.openapi.models.V1PodList;
import io.kubernetes.client.util.ClientBuilder;
import io.kubernetes.client.util.KubeConfig;
import lombok.extern.slf4j.Slf4j;
import org.springframework.boot.SpringApplication;
import org.springframework.boot.autoconfigure.SpringBootApplication;
import org.springframework.web.bind.annotation.RequestMapping;
import org.springframework.web.bind.annotation.RestController;

import java.io.FileReader;

@SpringBootApplication
@RestController
@Slf4j
public class OutsideclusterApplication {

    public static void main(String[] args) {
        SpringApplication.run(OutsideclusterApplication.class, args);
    }

    @RequestMapping(value = &quot;/hello&quot;)
    public V1PodList hello() throws Exception {
        // 存放K8S的config文件的全路径
        String kubeConfigPath = &quot;/Users/zhaoqin/temp/202007/05/config&quot;;

        // 以config作为入参创建的client对象，可以访问到K8S的API Server
        ApiClient client = ClientBuilder
                .kubeconfig(KubeConfig.loadKubeConfig(new FileReader(kubeConfigPath)))
                .build();

        Configuration.setDefaultApiClient(client);

        CoreV1Api api = new CoreV1Api();

        // 调用客户端API取得所有pod信息
        V1PodList v1PodList = api.listPodForAllNamespaces(null, null, null, null, null, null, null, null, null);

        // 使用jackson将集合对象序列化成JSON，在日志中打印出来
        log.info(&quot;pod info \n{}&quot;, new GsonBuilder().setPrettyPrinting().create().toJson(v1PodList));

        return v1PodList;
    }

}
&lt;/code&gt;
&lt;/pre&gt;
&lt;ol start=&quot;5&quot; readability=&quot;-0.5&quot;&gt;&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;运行上述代码，在浏览器访问http://localhost:8080/hello ，即可取得K8S所有pod的详情，如下所示(为了让返回数据更加整齐美观，我用的是Firefox浏览器)：&lt;br/&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/485422/202101/485422-20210105075621677-216786293.png&quot; alt=&quot;在这里插入图片描述&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;查看控制台，可见日志也将详情打印出来：&lt;br/&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/485422/202101/485422-20210105075622149-140709387.png&quot; alt=&quot;在这里插入图片描述&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;&lt;ul&gt;&lt;li&gt;至此，咱们的第一个使用K8S官方java客户端的应用就完成了，接下来的实战会尝试将应用部署在K8S环境内，在K8S内部进行各项操作；&lt;/li&gt;
&lt;/ul&gt;&lt;h3 id=&quot;你不孤单，欣宸原创一路相伴&quot;&gt;你不孤单，欣宸原创一路相伴&lt;/h3&gt;
&lt;ol&gt;&lt;li&gt;&lt;a href=&quot;https://xinchen.blog.csdn.net/article/details/105068742&quot; target=&quot;_blank&quot;&gt;Java系列&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://xinchen.blog.csdn.net/article/details/105086498&quot; target=&quot;_blank&quot;&gt;Spring系列&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://xinchen.blog.csdn.net/article/details/105086732&quot; target=&quot;_blank&quot;&gt;Docker系列&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://xinchen.blog.csdn.net/article/details/105086794&quot; target=&quot;_blank&quot;&gt;kubernetes系列&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://xinchen.blog.csdn.net/article/details/105086850&quot; target=&quot;_blank&quot;&gt;数据库+中间件系列&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://xinchen.blog.csdn.net/article/details/105086920&quot; target=&quot;_blank&quot;&gt;DevOps系列&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;h3 id=&quot;欢迎关注公众号：程序员欣宸&quot;&gt;欢迎关注公众号：程序员欣宸&lt;/h3&gt;
&lt;blockquote readability=&quot;4.258064516129&quot;&gt;
&lt;p&gt;微信搜索「程序员欣宸」，我是欣宸，期待与您一同畅游Java世界...&lt;br/&gt;&lt;a href=&quot;https://github.com/zq2599/blog_demos&quot; target=&quot;_blank&quot;&gt;https://github.com/zq2599/blog_demos&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
</description>
<pubDate>Mon, 04 Jan 2021 23:56:00 +0000</pubDate>
<dc:creator>程序员欣宸</dc:creator>
<og:description>欢迎访问我的GitHub https://github.com/zq2599/blog_demos 内容：所有原创文章分类汇总及配套源码，涉及Java、Docker、Kubernetes、DevOPS</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/bolingcavalry/p/14233415.html</dc:identifier>
</item>
<item>
<title>Python正则表达式 - 测试开发小记</title>
<link>http://www.cnblogs.com/hiyong/p/14175955.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/hiyong/p/14175955.html</guid>
<description>&lt;p&gt;正则表达式（Regular expression）是组成搜索模式的一组字符序列，是&lt;strong&gt;记录文本规则&lt;/strong&gt;的代码，用来检查文本中是否包含指定模式的字符串，通过定义一个规则来匹配字符串。正则表达式广泛应用于在字符串查找和处理中，大多文本编辑器基本都支持正则表达式查找。本文将简要介绍正则表达式语法，然后介绍Python语言中正则表达式使用方法。&lt;/p&gt;

&lt;p&gt;Unix之父Ken Tompson将正则表达式引入Unix，后面发展成了grep（Global Regular Expression Print）命令，由于grep不支持&lt;code&gt;+&lt;/code&gt;、&lt;code&gt;|&lt;/code&gt;与&lt;code&gt;?&lt;/code&gt; ，且分组比较麻烦，AT&amp;amp;T的Alfred Aho开发了egrep命令。随着Unix的版本不断演化，Unix中的程序（比如Linux三剑客中的awk、sed）所支持的正则表达式有差异，比较混乱。在1986年制定了POSIX（Portable Operating System Interface）标准，其中统一了正则表达式的语法。&lt;/p&gt;
&lt;p&gt;POSIX标准把正则表达式分为两种：BRE（Basic Regular Expressions）和ERE（Extended Regular Expressions ）。BRE就是unix系统使用的grep命令，ERE对应egrep命令，是BRE的扩展。而linux系统使用的是GNU标准，linux发行版集成了GNU（Gnu’s Not Unix）套件，GNU在实现了POXIS标准的同时，做了一定的扩展。也包括GNU Basic Regular Expressions 和GNU Extends Regular Expressions。&lt;/p&gt;
&lt;p&gt;正则表达式除了POSIX标准之外还有一个Perl分支，Perl与sed和awk兼容，后来演化成为PCRE（Perl Compatible Regular Expressions），是一个用C语言编写的正则表达式函数库，功能很强大，性能比POSIX正则表达式好。PCRE被引入了其他语言中，比如PHP, Tcl, Python, Ruby, C++, Java, R语言等等。&lt;/p&gt;
&lt;h2 id=&quot;普通正则&quot;&gt;普通正则&lt;/h2&gt;
&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;代码&lt;/th&gt;
&lt;th&gt;说明&lt;/th&gt;
&lt;/tr&gt;&lt;/thead&gt;&lt;tbody readability=&quot;3&quot;&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;.&lt;/td&gt;
&lt;td&gt;匹配除换行符以外的任意字符&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;\w&lt;/td&gt;
&lt;td&gt;匹配字母或数字或下划线或汉字&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;\s&lt;/td&gt;
&lt;td&gt;匹配任意的空白符&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;\d&lt;/td&gt;
&lt;td&gt;匹配数字&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;\b&lt;/td&gt;
&lt;td&gt;匹配单词的开始或结束&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;^&lt;/td&gt;
&lt;td&gt;匹配字符串的开始&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;$&lt;/td&gt;
&lt;td&gt;匹配字符串的结束&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;*&lt;/td&gt;
&lt;td&gt;重复零次或更多次&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;h2 id=&quot;扩展正则&quot;&gt;扩展正则&lt;/h2&gt;
&lt;p&gt;扩展正则：grep加 &lt;code&gt;-E&lt;/code&gt; 参数&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;grep -E ' 404 | 500' nginx.log&lt;/li&gt;
&lt;/ul&gt;&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;代码/语法&lt;/th&gt;
&lt;th&gt;说明&lt;/th&gt;
&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;+&lt;/td&gt;
&lt;td&gt;重复一次或更多次&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;？&lt;/td&gt;
&lt;td&gt;重复零次或一次&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;{n}&lt;/td&gt;
&lt;td&gt;重复n次&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;{n,}&lt;/td&gt;
&lt;td&gt;重复n次或更多次&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;{n,m}&lt;/td&gt;
&lt;td&gt;重复n到m次&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;|&lt;/td&gt;
&lt;td&gt;表示或&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;h2 id=&quot;零宽断言&quot;&gt;零宽断言&lt;/h2&gt;
&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;语法&lt;/th&gt;
&lt;th&gt;说明&lt;/th&gt;
&lt;/tr&gt;&lt;/thead&gt;&lt;tbody readability=&quot;2&quot;&gt;&lt;tr&gt;&lt;td&gt;(?=exp)&lt;/td&gt;
&lt;td&gt;匹配exp前面的位置&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;(?&amp;lt;=exp)&lt;/td&gt;
&lt;td&gt;匹配exp后面的位置&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;(?!exp)&lt;/td&gt;
&lt;td&gt;匹配后面不是exp的位置&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;(?&amp;lt;!exp)&lt;/td&gt;
&lt;td&gt;匹配前面不是exp的位置&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;h2 id=&quot;正则表达式实例&quot;&gt;正则表达式实例&lt;/h2&gt;
&lt;p&gt;正则表达式在线测试工具：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;&lt;a href=&quot;https://regex101.com/&quot; target=&quot;_blank&quot;&gt;https://regex101.com/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://c.runoob.com/front-end/854&quot; target=&quot;_blank&quot;&gt;http://c.runoob.com/front-end/854&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://tool.oschina.net/regex&quot; target=&quot;_blank&quot;&gt;https://tool.oschina.net/regex&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;h3 id=&quot;1-匹配以字母a开头的单词&quot;&gt;1. 匹配以字母a开头的单词&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;\ba\w*\b&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/2229336/202012/2229336-20201222223542814-1656574309.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h3 id=&quot;2-匹配刚好6个字符的单词&quot;&gt;2. 匹配刚好6个字符的单词&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;\b\w{6}\b&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/2229336/202012/2229336-20201222223552612-730555817.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h3 id=&quot;3-匹配1个或更多连续的数字&quot;&gt;3. 匹配1个或更多连续的数字&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;\d+&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/2229336/202012/2229336-20201222223602375-2070501685.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h3 id=&quot;4-5位到12位qq号&quot;&gt;4. 5位到12位QQ号&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;\d{5,12}&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/2229336/202012/2229336-20201222223611914-38926592.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;^\d{5,12}$&lt;/code&gt;&lt;br/&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/2229336/202012/2229336-20201222223618298-1657931604.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h3 id=&quot;5-匹配电话号码&quot;&gt;5. 匹配电话号码&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;0\d{2}-\d{8}&lt;/code&gt;&lt;br/&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/2229336/202012/2229336-20201222223626011-406712467.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h3 id=&quot;6-只匹配3位数字&quot;&gt;6. 只匹配3位数字&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;^\d{3}$&lt;/code&gt;&lt;br/&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/2229336/202012/2229336-20201222223634128-999895298.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h3 id=&quot;7-查找单词get&quot;&gt;7. 查找单词‘GET’&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;\bGET\b&lt;/code&gt;&lt;br/&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/2229336/202012/2229336-20201222223640832-567803480.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;^GET$&lt;/code&gt;&lt;br/&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/2229336/202012/2229336-20201222223648618-621155258.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h3 id=&quot;8-查找hello-world&quot;&gt;8. 查找‘Hello World’&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;\bHello\b.*\bWorld\b&lt;/code&gt;&lt;br/&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/2229336/202012/2229336-20201222223657467-306443199.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;

&lt;p&gt;Python有一个内置正则表达式模块 &lt;code&gt;re&lt;/code&gt; ，可以使用它来进行字符串操作：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-python&quot;&gt;import re
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;re&lt;/code&gt;模块提供了以下4种方法：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;findall：返回所有匹配项&lt;/li&gt;
&lt;li&gt;search：如果匹配到目标字符，返回一个匹配对象，用于判断是否存在目标字符串&lt;/li&gt;
&lt;li&gt;split：分割&lt;/li&gt;
&lt;li&gt;sub：替换&lt;/li&gt;
&lt;/ul&gt;&lt;h2 id=&quot;匹配数字、字母&quot;&gt;匹配数字、字母&lt;/h2&gt;
&lt;pre&gt;
&lt;code class=&quot;language-python&quot;&gt;text = '1&amp;amp;\nbsp;hour(s) 2&amp;amp;\nbsp;min 25&amp;amp;\nbsp;s'
re.findall(r'\d+',text) # 匹配时间（数字）
re.findall(r'\d+|(?&amp;lt;=;)\w+',text) # 匹配时间和单位
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;output:&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;['1', '2', '25']
['1', 'hour', '2', 'min', '25', 's']
&lt;/code&gt;
&lt;/pre&gt;
&lt;pre&gt;
&lt;code class=&quot;language-python&quot;&gt;re.findall(r'\d{2}+',text) # 匹配2位数字
&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;查找替换两个字符串之间内容&quot;&gt;查找替换两个字符串之间内容&lt;/h2&gt;
&lt;p&gt;替换字符&lt;code&gt;target_text&lt;/code&gt;：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-python&quot;&gt;xpath_path = '//*[contains(text(),&quot;target_text&quot;)]/../td[5]/span' # xpath路径
repl = &quot;需要替换成的字符串&quot;
re.sub(r&quot;(?&amp;lt;=\&quot;).*?(?=\&quot;)&quot;, repl, xpath_path) # 替换要查找的文本
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;output:&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;'//*[contains(text(),&quot;需要替换成的字符串&quot;)]/../td[5]/span'
&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;添加千位分割符&quot;&gt;添加千位分割符&lt;/h2&gt;
&lt;pre&gt;
&lt;code class=&quot;language-python&quot;&gt;number = '12345678' 
re.sub(r&quot;\B(?=(?:\d{3})+(?!\d))&quot;, &quot;,&quot;,number) # 替换要查找的文本
re.sub(r&quot;\B(?:(?:\d{3})+(?!\d))&quot;, &quot;,&quot;,number) 
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;output:&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;'12,345,678'
'12,'
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;(?:\d{3})+(?!\d)&lt;/code&gt;:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;查找3n(数字) + 非数字 组合&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;code&gt;(?:exp)&lt;/code&gt; :&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;匹配exp,不捕获匹配的文本(非获取匹配)，也不给此分组分配组号，当执行了第一次匹配时，匹配到了行尾，直接将345678替换成了“,”。&lt;/li&gt;
&lt;/ul&gt;
&lt;ol&gt;&lt;li&gt;正则表达式30分钟入门教程：&lt;a href=&quot;https://deerchao.cn/tutorials/regex/regex.htm&quot; target=&quot;_blank&quot;&gt;https://deerchao.cn/tutorials/regex/regex.htm&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;github项目learn-regex：&lt;a href=&quot;https://github.com/ziishaned/learn-regex&quot; target=&quot;_blank&quot;&gt;https://github.com/ziishaned/learn-regex&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://www.w3schools.com/python/python_regex.asp&quot; target=&quot;_blank&quot;&gt;https://www.w3schools.com/python/python_regex.asp&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;center&gt;&lt;strong&gt;--THE END--&lt;/strong&gt;&lt;/center&gt;
&lt;blockquote readability=&quot;4.6060606060606&quot;&gt;
&lt;p&gt;&lt;strong&gt;文章标题：Python正则表达式&lt;br/&gt;本文作者：hiyo&lt;br/&gt;本文链接：&lt;a href=&quot;https://www.cnblogs.com/hiyong/p/14175955.html&quot; target=&quot;_blank&quot;&gt;https://www.cnblogs.com/hiyong/p/14175955.html&lt;/a&gt;&lt;br/&gt;欢迎关注公众号:「测试开发小记」及时接收最新技术文章！&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
</description>
<pubDate>Mon, 04 Jan 2021 23:20:00 +0000</pubDate>
<dc:creator>测试开发小记</dc:creator>
<og:description>正则表达式（Regular expression）是组成搜索模式的一组字符序列，是记录文本规则的代码，用来检查文本中是否包含指定模式的字符串，通过定义一个规则来匹配字符串。正则表达式广泛应用于在字符串</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/hiyong/p/14175955.html</dc:identifier>
</item>
<item>
<title>纵然前路坎坷，也要毅然前行！2020年终总结！ - 虚无境</title>
<link>http://www.cnblogs.com/xuwujing/p/14233270.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/xuwujing/p/14233270.html</guid>
<description>&lt;h2 id=&quot;前言&quot;&gt;前言&lt;/h2&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;阳历2020年已过，那么按照去年所希望的，今年的我也将继续写下今年的年终总结！对过去的自己进行总结，对未来的自己给予展望！&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;今年事件&quot;&gt;今年事件&lt;/h2&gt;
&lt;p&gt;今年对于中国，对于全世界而言，都是一个多灾多难的一年，在这一年里，发生了太多的不幸了，这里我就不过多阐述了。在这一年中，有几件事对我影响很大，分别是在家办公、换地工作以及车祸。&lt;/p&gt;
&lt;h3 id=&quot;在家办公&quot;&gt;在家办公&lt;/h3&gt;
&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;体验了在家办公。&lt;br/&gt;疫情缘故，在老家武汉，体验了2个多月的在家办公，开始还很不习惯，但是习惯之后发现可能这就是我想要的生活，工作的时候好好工作，很多问题通过IM聊天工具沟通，避免很多无意义的开会讨论，很大程度上提升了个人的开发效率；因为在家办公，吃住都和家人在一起，久违的感受到了温暖，不再是一个人在外漂泊了。于是在去深圳的时候做了一个决定。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&quot;换地工作&quot;&gt;换地工作&lt;/h3&gt;
&lt;blockquote readability=&quot;9&quot;&gt;
&lt;p&gt;从深圳辞职回武汉了发展了。&lt;br/&gt;人生如戏, 白驹过隙。遥想三年前，毅然从武汉裸辞，来到深圳，为了开阔眼界，也为了学习技术，从零开始。如今，技术虽未小成，对我而言已经学到了，也赚到了一些，同时也失去了很多， 想了许久，纵然将最好的青春在此奋斗，繁华依旧与我无关，还可能落下一堆问题，于是，想好之后辞职回老家武汉发展，虽然在今年因为疫情缘故，回武汉不是一个很好的时机，但是想了，想好了，那么就去做了，至少在现在看来尚可。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&quot;车祸&quot;&gt;车祸&lt;/h3&gt;
&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;人生中第一次被车撞了。&lt;br/&gt;在今年11月份，一向警惕的我还是在骑共享单车的时候被车撞了，有趣的事，被车撞在空中时，竟然第一时间在想是不是要穿越，看来当时脑子已经神志不清了。。。 所幸司机刹车还算及时，经常锻炼身体使身体还算硬朗，除了臀股特疼，几天无法仰躺以及坐下，在家休息一个礼拜左右，就可以正常生活了，虽然长时间坐还是做疼痛。。。，直到一个月之后才真正好起来。&lt;br/&gt;关于车祸的事情经过，不太想讲述，不过在这件事中让我感受到了车祸其实不那么可怕，真正可怕的是人心。。。&lt;br/&gt;这件事让我吸取到一个教训，&lt;br/&gt;第一、尽量不要再机动车上面骑自行车或者步行，即使没有非机动车道；&lt;br/&gt;第二、无论在什么情况下，都多注意来往车辆；&lt;br/&gt;第三、被车撞了之后，如果有意识，第一时间联系家人或朋友，后续事件交给家人或有经验能力的朋友处理，并且不要轻易相信司机、交警以及当天自己的判断，以免后续事件再次吃亏!!!&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;技术成长方面&quot;&gt;技术成长方面&lt;/h2&gt;
&lt;ul&gt;&lt;li&gt;技术方面&lt;/li&gt;
&lt;/ul&gt;&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;相比去年，今年总体而言进步不大，甚至可以说基本没有啥进步。&lt;br/&gt;新技术学习也就一个prometheus和clickhouse，但是掌握程度都不是很深，因为使用场景有限。其他的原有技术方面，也就ElasticSearch勉强还在加强学习，以后有时间的话可以尝试考考ElasticSearch相关证书之类的。剩下的就是crud更加得心应手，对于配置化编程有了更深的了解，以及不在盲目的学习新技术，而是在慢慢学习其中的想法。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;社区方面&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;今年相比去年，写文章的数量更少了，github的提交也更少，根本原因在于个人对技术的学习没有以前那么有热情了，或许是人间冷暖更吸引我吧。不过技术方面还是要坚持下去的，哪怕只是一点点。。。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20210104235843734.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FhendzeHBjbQ==,size_16,color_FFFFFF,t_70&quot; alt=&quot;在这里插入图片描述&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h2 id=&quot;对比和期待&quot;&gt;对比和期待&lt;/h2&gt;
&lt;p&gt;今年在写年终总结的时候，发现了一个很本质的事情，年终总结是写给自己看的，准确的来说是写个未来的自己看的，那么趁着现在有这个想法，那么就写写对未来自己的展望吧！不过对于未来，如果是明年的话，感觉有点太近了，五年后的也感觉太远了，那么就以之前有过重要想法的时候作为分割线吧，这样想来，刚好三年有过，那就是在武汉辞职来深圳学习技术。于是就写一个三年前对比以及三年后的展望吧。&lt;/p&gt;
&lt;h3 id=&quot;对比三年前的我&quot;&gt;对比三年前的我&lt;/h3&gt;
&lt;ul&gt;&lt;li&gt;技术方面&lt;/li&gt;
&lt;/ul&gt;&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;对比三年前刚来深圳的我而言技术这方面进步非常大，学会了使用github寻找学习资料以及上传项目，学习了springboot、springcloud、mina、netty、redis、kafka、storm、elasticsearch等技术，由一个只会crud的小菜鸟成长为了一个懂一点主流技术的大菜鸟。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;&lt;li&gt;工作方面&lt;/li&gt;
&lt;/ul&gt;&lt;blockquote readability=&quot;7&quot;&gt;
&lt;p&gt;在工作中的事情相比而言更加得心应手，工作模式的我感觉还是挺靠谱，基本的工作任务都能按时按量完成，偶尔也能超出预期完成，也可以独立负责一个从零开始的项目。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;&lt;li&gt;生活方面&lt;/li&gt;
&lt;/ul&gt;&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;相比以前，认识的人更多了，更沉稳了，为人处世也更加圆滑了，但是相对的活力不足了，不服输的劲少了，身体变差了，都在开始学习养身了。。。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&quot;希望三年后的我&quot;&gt;希望三年后的我&lt;/h3&gt;
&lt;ul&gt;&lt;li&gt;技术方面&lt;/li&gt;
&lt;/ul&gt;&lt;blockquote readability=&quot;7&quot;&gt;
&lt;p&gt;希望你能够保持现有你已经学会的技术不落下，并且在其中有几个可以突破一下，并且学习一门新的语言或很流行的技术，当然更重要的是学习这些技术的思想，技术会过时，但是思想不会。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;&lt;li&gt;工作方面&lt;/li&gt;
&lt;/ul&gt;&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;希望你依旧能够好好的完成工作，但是如果有比工作更重要的东西的话，希望优先考虑它！&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;&lt;li&gt;生活方面&lt;/li&gt;
&lt;/ul&gt;&lt;blockquote readability=&quot;7&quot;&gt;
&lt;p&gt;希望身体至少不必现在差，还是要坚持锻炼，也要开心过好每一天，以后或许会很艰难，道路很坎坷，成年人的世界没有容易二字，但是无论发生了什么事情，也不要放弃！当然最重要的是还是先活着 ~&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;感悟&quot;&gt;感悟&lt;/h2&gt;
&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;一寸光阴一寸金，寸金难买寸光阴，这是在小学学习到的知识，在以前一直都不太理解，时间是这么重要吗？直到工作之后，特别是在长时间加班下班回来之后就深有感触了，每天就是上班、吃饭、下班、睡觉，周而复始，周末难得有时间也是在睡觉或在家恶补追的番剧，然后一天就这样过了，然来我是那么缺少时间啊。我想看有趣的影视作品，有意思的书籍，静下心来欣赏动人的音乐，和朋友一起好好玩玩，在游戏中体验各种事件， 去电影院看想看的电影，去各种地方旅行。。。&lt;br/&gt;希望我的这些想法&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;今年的一些感悟如下:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;一寸光阴一寸金，寸金难买寸光阴，好好珍惜当下，珍惜眼前人！&lt;/li&gt;
&lt;li&gt;人啊，光是活着就已经很累，所以为何不活得快乐一些呢！&lt;/li&gt;
&lt;li&gt;不要轻易叹气，叹气越多，会越累，有压力烦恼时，一步一步做好眼前事即可！&lt;/li&gt;
&lt;li&gt;没有遗憾的人生是不完美的，过去的遗憾就让它过去吧，迎接美好的未来才是当务之急！&lt;/li&gt;
&lt;/ul&gt;&lt;h2 id=&quot;明年的目标&quot;&gt;明年的目标&lt;/h2&gt;
&lt;p&gt;想来想去，目标这个东西目前对我而言没有太大意义了，该去做的我一定回去做，不太重要的基本不会做，emmm，所以还是按照我以前最真实的想法来定吧。&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;明年先活过去，然后这个时间段写明年的总结；&lt;/li&gt;
&lt;li&gt;明年要活的比今年更好，开心日子的比例要比今年多；&lt;/li&gt;
&lt;li&gt;明年的身体要加强锻炼，要比今年的强；&lt;/li&gt;
&lt;li&gt;纵然前路坎坷，也要毅然前行;&lt;/li&gt;
&lt;/ul&gt;&lt;h2 id=&quot;其它&quot;&gt;其它&lt;/h2&gt;
&lt;p&gt;相关文章推荐:&lt;/p&gt;
&lt;h3 id=&quot;音乐推荐&quot;&gt;音乐推荐&lt;/h3&gt;
&lt;p&gt;推荐一首非常舒适的音乐。&lt;/p&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;《春雪》韩愈&lt;br/&gt;新年都未有芳华，&lt;br/&gt;二月初惊见草芽。&lt;br/&gt;白雪却嫌春色晚，&lt;br/&gt;故穿庭树作飞花。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;原创不易，如果感觉不错，希望给个推荐！您的支持是我写作的最大动力！&lt;br/&gt;版权声明:&lt;br/&gt;作者：虚无境&lt;br/&gt;博客园出处：&lt;a href=&quot;http://www.cnblogs.com/xuwujing&quot; target=&quot;_blank&quot;&gt;http://www.cnblogs.com/xuwujing&lt;/a&gt;&lt;br/&gt;CSDN出处：&lt;a href=&quot;http://blog.csdn.net/qazwsxpcm&quot; target=&quot;_blank&quot;&gt;http://blog.csdn.net/qazwsxpcm&lt;/a&gt;　　　　&lt;br/&gt;掘金出处：&lt;a href=&quot;https://juejin.im/user/5ae45d5bf265da0b8a6761e4&quot; target=&quot;_blank&quot;&gt;https://juejin.im/user/5ae45d5bf265da0b8a6761e4&lt;/a&gt;&lt;br/&gt;个人博客出处：&lt;a href=&quot;http://www.panchengming.com&quot; target=&quot;_blank&quot;&gt;http://www.panchengming.com&lt;/a&gt;&lt;/p&gt;
</description>
<pubDate>Mon, 04 Jan 2021 16:20:00 +0000</pubDate>
<dc:creator>虚无境</dc:creator>
<og:description>前言 阳历2020年已过，那么按照去年所希望的，今年的我也将继续写下今年的年终总结！对过去的自己进行总结，对未来的自己给予展望！ 今年事件 今年对于中国，对于全世界而言，都是一个多灾多难的一年，在这一</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/xuwujing/p/14233270.html</dc:identifier>
</item>
<item>
<title>浅谈面试官的“被面试”技能 - bee0060</title>
<link>http://www.cnblogs.com/bee0060/p/14157785.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/bee0060/p/14157785.html</guid>
<description>&lt;h2 id=&quot;前言&quot;&gt;前言&lt;/h2&gt;
&lt;p&gt;面试其实也是一个双向选择的过程，面试官在筛选候选人的同时，候选人也在筛选面试官和企业。特别是能力较强的候选人，他们往往可以拿到多个offer，这个时候就很看面试官吸引候选人的能力了。这不光看面试官的个人魅力，也是一项可以学习的技能。&lt;/p&gt;
&lt;p&gt;能力判断和筛选是面试官最主要的职责，这毋庸置疑。但此外，作为招聘流程中的一环，除了“筛选”之外，“招”才是最终目标，如果我们筛选出来的候选人，却招不进来（候选人没选我们），那筛选也将失去意义。如果面试官具有良好的“被面试”技能，除了能帮助我们招到心仪的候选人，还能帮公司节约不少成本。&lt;/p&gt;
&lt;h2 id=&quot;本文范围&quot;&gt;本文范围&lt;/h2&gt;
&lt;p&gt;本文主要讨论如何吸引感兴趣的候选人，不讨论能力筛选方面的内容。&lt;/p&gt;
&lt;h2 id=&quot;招聘的困境&quot;&gt;招聘的困境&lt;/h2&gt;
&lt;p&gt;为什么想写这篇文章呢？ 因为最近我们部门也在招人，招前端，面了挺多人，满意的很少，但是我们满意的几乎都去别的公司了，这让我们很无奈，好不容易面了这么多人才遇到几个合适的，结果他们又不来，感觉白面了。其实回头一想，也对，我们觉得好的人，自然也有其他企业觉得好，那么对这些我们满意的候选人，就不是我们在挑他们了，是他们在挑企业了，类似一些相亲节目里的“权力反转”环节。如果我们感兴趣的人最终对我们不感兴趣，对企业来说会是面试成本的损失。而且面试要求越高的岗位，要遇到合适人选的平均面试次数可能也越多，一旦合适人选没来，企业和团队的损失越大。&lt;/p&gt;
&lt;p&gt;只是大多数面试官面试时，注意力主要集中在如何筛选、甄别候选人的能力，而没太注意如何在遇到满意的候选人时如何让候选人也对我们足够感兴趣，这就导致了遇到“对的人”，“对的人”却不觉得我们是“对的企业”的尴尬局面。&lt;/p&gt;
&lt;p&gt;那么对这种情况，我们是不是什么都做不了？ 难道能吸引候选人的只有HR、薪资福利和公司品牌吗？我认为不是的。那怎么做才能让候选人对我们感兴趣呢？ 一般如果正着想想不到的话，我就会试试反着想， 即“做什么会让候选人对我们丧失兴趣？” ，也就是“错误示范”了。&lt;/p&gt;
&lt;h2 id=&quot;错误示范&quot;&gt;错误示范&lt;/h2&gt;
&lt;p&gt;相信大家都有被面试的经验，也许也有过一些不愉快的面试经历，让你对一家企业的期待或兴趣大幅降低，可能甚至还有面试完就把这家企业加到你的“黑名单”中的。下面是我能想到的一些错误示范：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;浪费对方时间，如迟到、因协调组织不善让候选人长时间等候&lt;/li&gt;
&lt;li&gt;无礼， 言语中不讲礼貌，面试官显得高高在上等。&lt;/li&gt;
&lt;li&gt;忽视候选人，注意力长时间在面试之外，如长时间看手机、接私人电话等，又如面试过程中与候选人没有任何的眼神交流，即几乎没正眼看过候选人&lt;/li&gt;
&lt;li&gt;候选人回答错误后表现出鄙夷&lt;/li&gt;
&lt;li&gt;否定、贬低候选人，通过个别小问题而对候选人进行大范围的负面评判&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;其实以上这些点，大部分源于缺乏了2个字： &lt;strong&gt;尊重&lt;/strong&gt;。 如果面试官尊重并尽量平等的对待候选人，在积累一定的面试经验后，一般也不容易做出上面这些事情，所以大多数时候是意识上的问题。企业招聘其实也是在求贤，而且越好的人才越需要“求”。实在没啥理由不尊重候选人的。心态先摆正，之后的技巧问题都好解决。&lt;/p&gt;
&lt;h2 id=&quot;影响候选人决定的因素&quot;&gt;影响候选人决定的因素&lt;/h2&gt;
&lt;p&gt;能影响候选人决定来不来的因素很多，例如钱多活少离家近什么的，朗朗上口啊。另外还有企业品牌与口碑（大厂大部分人都向往）、项目前景、成长机会、薪资等等等等。&lt;/p&gt;
&lt;p&gt;面试体验是其中一个因素，我当然不能因为写这篇文章就夸大面试体验的作用，但是不可否认，在其他因素相差不大的情况下，面试体验大多会是候选人考虑的比较重要的一个因素。因为面试体验除了影响情绪之外，也间接体现企业文化，团队氛围，团队成员的风格等，对候选人来说，这可能直接反映下一份工作是否愉快。&lt;/p&gt;
&lt;p&gt;如果面试官就让人感觉很难相处，换位思考一下，我们会不会担心入职后这个团队不好融入？或不希望跟这个面试官共事？如果我们自己找工作，咱们何苦去受这个罪呢？如果我们真能忍受这种不愉快，那么对其他因素的要求自然会提高很多。换句话说，面试体验好一点， 企业在其他方面就可以少付出一点，如企业品牌、薪资等。 但其实少付点工资只是省小钱，能提升招聘成功率才是省了大钱。&lt;/p&gt;
&lt;p&gt;所以好的面试体验，可以在其他因素相差不大时，帮助企业在招聘竞争中胜出。&lt;/p&gt;
&lt;p&gt;此外面试体验还能有其他影响，这在后面再聊。&lt;/p&gt;
&lt;h2 id=&quot;怎么做&quot;&gt;怎么做&lt;/h2&gt;
&lt;p&gt;铺垫那么久，终于到正题了。结合上面的错误示范，首当其冲的当然是：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;尊重 - 首先避免上面的错误示范，尽量表现出对候选人的尊重&lt;/li&gt;
&lt;li&gt;友善 - 这个和尊重相交却不完全重叠。 在尊重的基础上，尽量友善、讲礼貌，这除了可以提高面试体验，也更容易让候选人放松，在面试中将自己展示得更好，让我们对候选人能力的判断更准确&lt;/li&gt;
&lt;li&gt;收获 - 如果可以让候选人觉得能从这场面试中有所收获，候选人一般也会心存感激。可能是通过有价值的问题，或客观且对候选人有益的建议等。有价值的问题可以很多，例如候选人过去项目中没有意识到的问题，可以改进的方面等等，但不包括那些很刁钻或很偏门的细节的问题。&lt;/li&gt;
&lt;li&gt;机会 - 让候选人知道所应聘的岗位与他的契合程度，他将会从这个岗位获得些什么。这需要先了解候选人的特长和兴趣，再展示他可能感兴趣的点，这些点可能是所作的项目、所用技术、团队状况（可能有他崇拜的开源作者等）、工作方式、成长机会等等。&lt;/li&gt;
&lt;li&gt;表现出兴趣 - 如果我们觉得候选人表现不错，不妨适当表现出对候选人的兴趣或认可，但切记，在我们没有足够权限时，不应附带任何承诺。一般如果我们对候选人表现出兴趣，候选人会更自信，跟我们的互动会更多，距离感更小，自然也会对我们的企业更感兴趣。&lt;/li&gt;
&lt;li&gt;真诚 - 这个可能有点玄，这不是一个外在的技巧，但我觉得这一点对招聘成功率也会有很大帮助。待人以诚，对方一般是能感受到的，谁不愿意和对自己真诚的人打交道呢？当然，真诚不代表毫无保留，由于面试中有些信息是不方便随便透露的，如果候选人问到这些，我们可以坦率的告知由于流程或规章制度所限，有些东西不方便说就是了。&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;能吸引候选人的方法当然不止这些，还需要大家积累经验后发掘行之有效和适合自身和企业的方法。通过有意识的吸引满意的候选人，可以帮助企业提高招聘的成功率，降低招聘成本。要知道招聘的成本可不止这一场面试，从发广告、筛简历、联系协调面试官、安排会议室等等之后才到这一场面试，再加上可能要面N个候选人才能遇到一个满意的，这里包含了大量的金钱、时间和机会成本。&lt;/p&gt;
&lt;h2 id=&quot;面试体验的其他影响&quot;&gt;面试体验的其他影响&lt;/h2&gt;
&lt;ol&gt;&lt;li&gt;企业的品牌和名声 - 咱们在很多社区都能看到候选人吐槽面试的， 如果这些负面评价多了，会影响到企业的名声。 而大部分企业的品牌和名声往往需要花费很多时间、金钱和努力才能慢慢积攒起来，付出的成本一般比招聘成本大得多。&lt;/li&gt;
&lt;li&gt;对外界人才的吸引力 - 企业的品牌和名声其实也会进而影响到对外界人才的吸引力。试想一家公司很多人吐槽他的面试，一些有能力有选择余地的人才，还会有兴趣来吗？如果连简历都不给，面试官连候选人的面都见不到，还谈何吸引？相反如果社区中有人在吐槽一些企业的面试的同时，说某某企业的面试体验很好，那这个被说好的公司，自然会有更多的人才愿意来面试。但我这不是让大家找水军来宣传，要长久良性发展还是要通过好的面试体验。&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;除此之外当然还有会有其他影响，不过暂时只想到这些。&lt;/p&gt;
&lt;h2 id=&quot;对于不合适的候选人&quot;&gt;对于不合适的候选人&lt;/h2&gt;
&lt;p&gt;由于面试官是代表企业进行面试，面试除了对招聘结果有影响外，还会对企业的品牌、公众形象等产生影响。所以对于感觉不合适的候选人，建议大家至少做到尊重这一点，大家都是人在江湖，都不容易，何苦为难别人呢。如果还能让候选人在面试中有所收获，那就更好了。&lt;/p&gt;
&lt;h2 id=&quot;例外情况&quot;&gt;例外情况&lt;/h2&gt;
&lt;p&gt;凡是都有例外。虽然可能性很低，假如遇到本身不懂尊重人的候选人，由于尊重应该是双向的，就不必参考本文的建议了。&lt;/p&gt;
&lt;h2 id=&quot;最后&quot;&gt;最后&lt;/h2&gt;
&lt;p&gt;本文只是在下的一家之言，限于能力与经验，有说的不对的地方欢迎大家纠正探讨，共同进步。&lt;/p&gt;
&lt;p&gt;最后祝找工作的都能找到心仪的工作，招人的都能找到合适的人。&lt;/p&gt;
&lt;p&gt;谢谢观看。&lt;/p&gt;
</description>
<pubDate>Mon, 04 Jan 2021 15:46:00 +0000</pubDate>
<dc:creator>bee0060</dc:creator>
<og:description>前言 面试其实也是一个双向选择的过程，面试官在筛选候选人的同时，候选人也在筛选面试官和企业。特别是能力较强的候选人，他们往往可以拿到多个offer，这个时候就很看面试官吸引候选人的能力了。这不光看面试</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/bee0060/p/14157785.html</dc:identifier>
</item>
<item>
<title>原来大数据 Hadoop 是这样存储数据的 - 后青春期的Keats</title>
<link>http://www.cnblogs.com/keatsCoder/p/14233180.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/keatsCoder/p/14233180.html</guid>
<description>&lt;p&gt;大数据 Hadoop 主要解决了数据的存储和分析计算问题，那么它是以何种方式解决数据存储问题的呢？读完这篇博客，我相信你会清楚很多&lt;/p&gt;&lt;div id=&quot;cnblogs_post_body&quot; readability=&quot;373.9038181727&quot;&gt;
&lt;h2 id=&quot;hdfs概述&quot;&gt;HDFS概述&lt;/h2&gt;
&lt;h3 id=&quot;产生背景&quot;&gt;产生背景&lt;/h3&gt;
&lt;p&gt;随着数据量越来越大，在一个操作系统中存不下所有的数据。需要将这些数据分配到更多的操作系统中，带来的问题是多操作系统不方便管理和维护。需要&lt;strong&gt;一种系统来管理多台机器上的文件&lt;/strong&gt;，这就是分布式文件管理系统。&lt;strong&gt;HDFS是分布式文件管理系统中的一种&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&quot;定义&quot;&gt;定义&lt;/h3&gt;
&lt;p&gt;HDFS（Hadoop Distributed File System）它是一个文件系统，用于存储文件，通过目录树来定位文件。其次，他是分布式的，由很多服务器联合起来实现其功能，集群中的服务器有各自的角色&lt;/p&gt;
&lt;p&gt;HDFS 的使用场景：适合一次写，多次读的场景，且不支持文件的修改。适合用来做数据分析&lt;/p&gt;
&lt;h3 id=&quot;优缺点&quot;&gt;优缺点&lt;/h3&gt;
&lt;h4 id=&quot;优点&quot;&gt;优点&lt;/h4&gt;
&lt;ul&gt;&lt;li&gt;高容错
&lt;ul&gt;&lt;li&gt;数据自动保存多个副本，通过增加副本的形式，提高容错性&lt;/li&gt;
&lt;li&gt;某一个副本丢失以后，可以自动恢复&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;适合处理大数据
&lt;ul&gt;&lt;li&gt;数据规模：达到 GB、TB、甚至 PB 级别的数据&lt;/li&gt;
&lt;li&gt;文件规模：能够处理百万规模以上的文件数量&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;可以构建在廉价机器上&lt;/li&gt;
&lt;/ul&gt;&lt;h4 id=&quot;缺点&quot;&gt;缺点&lt;/h4&gt;
&lt;ul&gt;&lt;li&gt;不适合低延时数据访问。比如毫秒级的存储数据，做不到&lt;/li&gt;
&lt;li&gt;无法高效的对大量小文件进行存储
&lt;ul&gt;&lt;li&gt;namenode 对每个文件至少需要消耗 150 字节去存储目录和块信息，小文件相比大文件更消耗 namenode 服务器内存&lt;/li&gt;
&lt;li&gt;小文件寻址时间会超过读取时间，违背 HDFS 设计初衷&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;不支持并发写入、文件随机修改
&lt;ul&gt;&lt;li&gt;一个文件只能有一个写，不允许多线程同时写&lt;/li&gt;
&lt;li&gt;仅支持数据追加，不支持修改&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;h3 id=&quot;组成架构&quot;&gt;组成架构&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1654189/202101/1654189-20210104233008483-1523232254.png&quot; alt=&quot;image-20201221211014820&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1654189/202101/1654189-20210104233007659-1878299835.png&quot; alt=&quot;image-20201221211229108&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h3 id=&quot;hdfs-文件块大小&quot;&gt;HDFS 文件块大小&lt;/h3&gt;
&lt;p&gt;HDFS 中的文件在物理上是分块存储（Block），块的大小可以手动配置参数 &lt;code&gt;dfs.blocksize&lt;/code&gt; 来修改（Hadoop 2.x 是 128m，之前是 64m）&lt;/p&gt;
&lt;h4 id=&quot;为什么取-128m-呢？&quot;&gt;为什么取 128m 呢？&lt;/h4&gt;
&lt;p&gt;普遍认为，寻址时间（即查找目标 block 的时间）为 10ms，而寻址时间为传输时间的 1% 时，为 HDFS 运行的理想最佳状态。此时传输时间为 10ms / 1% = 1000ms = 1s，而目前硬盘的传输速度普遍为 100m/s ，因此 block 的大小取 1s*100m/s = 100m。离它最近的 2 的次幂就是 128 了。这块可以看出，影响 block 大小的主要因素就是硬盘的读取速度。因此当采用固态硬盘的时候完全可以把数值调整到 256 m 甚至更多。&lt;/p&gt;
&lt;p&gt;块太小的时候，会增加寻址时间&lt;/p&gt;
&lt;p&gt;但当块变得很大时，就要想办法避免热点数据的频繁读取了。这一点在 Google 的论文中有提到，论文中给到的解决思路是客户端缓存，但是并没有提具体实现 &lt;a href=&quot;https://www.cnblogs.com/zzjhn/p/3834729.html&quot; target=&quot;_blank&quot;&gt;https://www.cnblogs.com/zzjhn/p/3834729.html&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;hdfs-的-shell-操作&quot;&gt;HDFS 的 Shell 操作&lt;/h2&gt;
&lt;h3 id=&quot;基本语法&quot;&gt;基本语法&lt;/h3&gt;
&lt;p&gt;bin/hadoop fs 具体命令 OR bin/hdfs dfs 具体命令&lt;/p&gt;
&lt;p&gt;dfs是fs的实现类&lt;/p&gt;
&lt;h3 id=&quot;常用命令&quot;&gt;常用命令&lt;/h3&gt;
&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;命令&lt;/th&gt;
&lt;th&gt;解释&lt;/th&gt;
&lt;th&gt;示例&lt;/th&gt;
&lt;th&gt;备注&lt;/th&gt;
&lt;/tr&gt;&lt;/thead&gt;&lt;tbody readability=&quot;14&quot;&gt;&lt;tr&gt;&lt;td&gt;-ls&lt;/td&gt;
&lt;td&gt;显示目录信息&lt;/td&gt;
&lt;td/&gt;
&lt;td/&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;-mkdir&lt;/td&gt;
&lt;td&gt;在HDFS上创建目录&lt;/td&gt;
&lt;td&gt;hadoop fs -mkdir -p /user/keats/love&lt;/td&gt;
&lt;td&gt;-p 创建多级目录&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;6&quot;&gt;&lt;td&gt;-moveFromLocal&lt;/td&gt;
&lt;td&gt;从本地剪切粘贴到HDFS&lt;/td&gt;
&lt;td&gt;hadoop fs -moveFromLocal ./yaya.txt /user/keats/love/&lt;/td&gt;
&lt;td&gt;前面是来源路径 后面是目标路径，下同&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;-appendToFile&lt;/td&gt;
&lt;td&gt;追加一个文件到已经存在的文件末尾&lt;/td&gt;
&lt;td/&gt;
&lt;td/&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;-cat&lt;/td&gt;
&lt;td&gt;显示文件内容&lt;/td&gt;
&lt;td/&gt;
&lt;td/&gt;
&lt;/tr&gt;&lt;tr readability=&quot;4&quot;&gt;&lt;td&gt;-chgrp 、-chmod、-chown&lt;/td&gt;
&lt;td&gt;Linux文件系统中的用法一样，修改文件所属权限&lt;/td&gt;
&lt;td/&gt;
&lt;td/&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;-copyFromLocal&lt;/td&gt;
&lt;td&gt;从本地文件系统中拷贝文件到HDFS路径去&lt;/td&gt;
&lt;td/&gt;
&lt;td&gt;同 -put&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;-copyToLocal&lt;/td&gt;
&lt;td&gt;从HDFS拷贝到本地&lt;/td&gt;
&lt;td/&gt;
&lt;td&gt;同 -get&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;-getmerge&lt;/td&gt;
&lt;td&gt;合并下载多个文件&lt;/td&gt;
&lt;td&gt;hadoop fs -getmerge /user/keats/love/* ./yaya.txt&lt;/td&gt;
&lt;td/&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;-tail&lt;/td&gt;
&lt;td&gt;显示一个文件的末尾&lt;/td&gt;
&lt;td/&gt;
&lt;td/&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;-rm&lt;/td&gt;
&lt;td&gt;删除文件或文件夹&lt;/td&gt;
&lt;td/&gt;
&lt;td/&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;-rmdir&lt;/td&gt;
&lt;td&gt;删除空目录&lt;/td&gt;
&lt;td/&gt;
&lt;td/&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;-du&lt;/td&gt;
&lt;td&gt;统计文件夹的大小信息&lt;/td&gt;
&lt;td/&gt;
&lt;td&gt;可以理解为 disk use&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;6&quot;&gt;&lt;td&gt;-setrep&lt;/td&gt;
&lt;td&gt;设置HDFS中文件的副本数量&lt;/td&gt;
&lt;td/&gt;
&lt;td&gt;里设置的副本数只是记录在NameNode的元数据中，是否真的会有这么多副本，还得看DataNode的数量。因为目前只有3台设备，最多也就3个副本，只有节点数的增加到10台时，副本数才能达到10&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;h2 id=&quot;hdfs-客户端操作&quot;&gt;HDFS 客户端操作&lt;/h2&gt;
&lt;h3 id=&quot;环境准备&quot;&gt;环境准备&lt;/h3&gt;
&lt;ol&gt;&lt;li&gt;把之前下载的 hadoop 安装包解压，复制到一个不含中文路径的目录下（建议所有开发相关东西放在一个目录下，方便管理）&lt;/li&gt;
&lt;li&gt;配置环境变量 HADOOP_HOME 和 Path&lt;/li&gt;
&lt;/ol&gt;&lt;h3 id=&quot;项目准备&quot;&gt;项目准备&lt;/h3&gt;
&lt;p&gt;项目地址 &lt;a href=&quot;https://github.com/keatsCoder/HdfsClientDemo&quot; target=&quot;_blank&quot;&gt;https://github.com/keatsCoder/HdfsClientDemo&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;创建 maven 项目，引入依赖&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-xml&quot;&gt; &amp;lt;dependencies&amp;gt;
        &amp;lt;dependency&amp;gt;
            &amp;lt;groupId&amp;gt;junit&amp;lt;/groupId&amp;gt;
            &amp;lt;artifactId&amp;gt;junit&amp;lt;/artifactId&amp;gt;
            &amp;lt;version&amp;gt;RELEASE&amp;lt;/version&amp;gt;
        &amp;lt;/dependency&amp;gt;
        &amp;lt;dependency&amp;gt;
            &amp;lt;groupId&amp;gt;org.apache.logging.log4j&amp;lt;/groupId&amp;gt;
            &amp;lt;artifactId&amp;gt;log4j-core&amp;lt;/artifactId&amp;gt;
            &amp;lt;version&amp;gt;2.8.2&amp;lt;/version&amp;gt;
        &amp;lt;/dependency&amp;gt;
        &amp;lt;dependency&amp;gt;
            &amp;lt;groupId&amp;gt;org.apache.hadoop&amp;lt;/groupId&amp;gt;
            &amp;lt;artifactId&amp;gt;hadoop-common&amp;lt;/artifactId&amp;gt;
            &amp;lt;version&amp;gt;2.10.1&amp;lt;/version&amp;gt;
        &amp;lt;/dependency&amp;gt;
        &amp;lt;dependency&amp;gt;
            &amp;lt;groupId&amp;gt;org.apache.hadoop&amp;lt;/groupId&amp;gt;
            &amp;lt;artifactId&amp;gt;hadoop-client&amp;lt;/artifactId&amp;gt;
            &amp;lt;version&amp;gt;2.10.1&amp;lt;/version&amp;gt;
        &amp;lt;/dependency&amp;gt;
        &amp;lt;dependency&amp;gt;
            &amp;lt;groupId&amp;gt;org.apache.hadoop&amp;lt;/groupId&amp;gt;
            &amp;lt;artifactId&amp;gt;hadoop-hdfs&amp;lt;/artifactId&amp;gt;
            &amp;lt;version&amp;gt;2.10.1&amp;lt;/version&amp;gt;
        &amp;lt;/dependency&amp;gt;
        &amp;lt;dependency&amp;gt;
            &amp;lt;groupId&amp;gt;jdk.tools&amp;lt;/groupId&amp;gt;
            &amp;lt;artifactId&amp;gt;jdk.tools&amp;lt;/artifactId&amp;gt;
            &amp;lt;version&amp;gt;1.8&amp;lt;/version&amp;gt;
            &amp;lt;scope&amp;gt;system&amp;lt;/scope&amp;gt;
            &amp;lt;systemPath&amp;gt;${JAVA_HOME}/lib/tools.jar&amp;lt;/systemPath&amp;gt;
        &amp;lt;/dependency&amp;gt;
    &amp;lt;/dependencies&amp;gt;
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;创建 Java 类，HdfsClient 主要进行了三步操作&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;创建 FileSystem 对象&lt;/li&gt;
&lt;li&gt;通过 FileSystem 对象执行命令&lt;/li&gt;
&lt;li&gt;关闭 FileSystem&lt;/li&gt;
&lt;/ol&gt;&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;public class HdfsClient {
    static FileSystem fs;

    static {
        Configuration conf = new Configuration();
        conf.set(&quot;fs.defaultFS&quot;, &quot;hdfs://linux102:9000&quot;);

        try {
            fs = FileSystem.get(conf);
        } catch (IOException e) {
            e.printStackTrace();
        }
    }

    public static void main(String[] args) throws IOException {
        // 执行操作
        mkDir();

        // 释放资源
        fs.close();
    }

    private static void mkDir() throws IOException {
        fs.mkdirs(new Path(&quot;/john/keats&quot;));
    }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;尝试运行，会得到第一个错误，大意是权限被拒绝，这个时候就需要配置 JVM 参数 &lt;code&gt;-DHADOOP_USER_NAME=root&lt;/code&gt; 来告诉集群，使用 root 用户进行操作&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1654189/202101/1654189-20210104233006919-1844737090.png&quot; alt=&quot;image-20201222213812660&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;配置好之后再运行，会遇到第二个错误&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;Could not locate Hadoop executable: D:\develop\hadoop\bin\winutils.exe -see https://wiki.apache.org/hadoop/WindowsProblems
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;这是因为我们之前配置环境的时候，解压的 hadoop 文件 bin 目录下&lt;strong&gt;没有 winutils.exe 这个文件&lt;/strong&gt;，根据后面地址 wiki 百科的指示，可以下载该文件放在 bin 目录下。但是目前那个文件的最新版本是 2.8.1，也许会存在某些方面不兼容的问题，目前还暂时没有发现。因此可以直接下载该版本使用 &lt;a href=&quot;https://github.com/steveloughran/winutils/releases&quot; target=&quot;_blank&quot;&gt;https://github.com/steveloughran/winutils/releases&lt;/a&gt;&lt;/p&gt;
&lt;h4 id=&quot;简化配置用户名和访问路径&quot;&gt;简化配置用户名和访问路径&lt;/h4&gt;
&lt;p&gt;FileSystem.get() 有一个重载方法，三个参数，第一个是 hadoop namenode 地址，第二个是 conf 对象，第三个是用户名。可以一次配好&lt;/p&gt;
&lt;p&gt;测试方法详见示例代码 HdfsClient2.java 类&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;fs = FileSystem.get(new URI(&quot;hdfs://linux102:9000&quot;), conf, &quot;root&quot;);
&lt;/code&gt;
&lt;/pre&gt;
&lt;h4 id=&quot;上传文件&quot;&gt;上传文件&lt;/h4&gt;
&lt;p&gt;在项目 resource 目录下创建文件 zhangsan.txt&lt;/p&gt;
&lt;p&gt;调用 copyFromLocalFile 方法上传文件&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;private static void uploadFile() throws IOException {
    URL systemResource = ClassLoader.getSystemResource(&quot;zhangsan.txt&quot;);
    String path = systemResource.getPath();

    fs.copyFromLocalFile(new Path(path), new Path(&quot;/john/keats/love&quot;));
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;copyFromLocalFile 还有三个重载方法，分别提供以下功能&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;是否删除源文件&lt;/li&gt;
&lt;li&gt;当目标文件存在时，是否覆盖目标文件&lt;/li&gt;
&lt;li&gt;多文件批量上传，但目标路径必须是文件夹路径&lt;/li&gt;
&lt;/ul&gt;&lt;h4 id=&quot;配置文件优先级&quot;&gt;配置文件优先级&lt;/h4&gt;
&lt;p&gt;之前我们在 hadoop 集群配置的副本数量是 3 ，而 hadoop client 也支持两种方式配置参数&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;conf 对象通过 key-value 形式配置&lt;/li&gt;
&lt;li&gt;resources 目录下放置 xml 配置文件配置&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;加上默认的 default-xxxx.xml 一共四种配置的方式。他们的优先级是&lt;/p&gt;
&lt;p&gt;conf &amp;gt; resources 下的配置文件 &amp;gt; hadoop 集群配置文件 &amp;gt; default&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ConfigFileTest.java&lt;/strong&gt; 类对此处的配置进行的说明与测试，读者可以运行体验&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1654189/202101/1654189-20210104233006461-1394556333.png&quot; alt=&quot;image-20201222223559044&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h4 id=&quot;下载文件&quot;&gt;下载文件&lt;/h4&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;fs.copyToLocalFile(new Path(&quot;/three.txt&quot;), new Path(&quot;D://zhangsan.txt&quot;));
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;copyToLocalFile 还有两个重载方法，分别添加了。具体代码可参考 DownLoadFileTest.java&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;// 是否删除源文件
boolean delSrc
&lt;/code&gt;
&lt;/pre&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;// 是否使用RawLocalFileSystem作为本地文件系统
// 默认是 false，目前比较直观的就是 false 状态下下载文件会同时生成 .crc 格式的校验文件，设置为 true 时不会生成
boolean useRawLocalFileSystem
&lt;/code&gt;
&lt;/pre&gt;
&lt;h4 id=&quot;删除文件&quot;&gt;删除文件&lt;/h4&gt;
&lt;p&gt;删除文件的API，第二个参数表示是否递归删除。如果要删除的 Path 对应的是文件夹，recursive 需要设置为 true ，否则会抛异常。其实就相当于 &lt;code&gt;rm -r&lt;/code&gt; 中的参数 -r&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;public abstract boolean delete(Path f, boolean recursive) throws IOException;
&lt;/code&gt;
&lt;/pre&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;private static void deleteFile() throws IOException {
    // /john/keats 是文件夹目录，递归设置为 false 会报错 PathIsNotEmptyDirectoryException: ``/john/keats is non empty': Directory is not empty
    //  fs.delete(new Path(&quot;/john/keats&quot;), false);

    // 先上传，再删除
    HdfsClient2.uploadFile(true);
    fs.delete(new Path(&quot;/john/keats/love/zhangsan.txt&quot;), true);
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;这块我在删除之前添加了上传操作，目的是为了防止文件不存在。而上传又存在一种可能就是目标文件已存在。这是个薛定谔的文件- -，因此我查看了 FileSystem 的上传 API，他是提供 overwrite 开关的，默认是 true 即覆盖目标文件&lt;/p&gt;
&lt;h4 id=&quot;文件重命名&quot;&gt;文件重命名&lt;/h4&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;private static void renameFile() throws IOException {

    String dstFileName = &quot;wangwu.txt&quot;;
    HdfsClient2.uploadFile();
    deleteFile(dstFileName);
    // 目标文件不存在，则更名成功
    boolean rename = fs.rename(new Path(&quot;/john/keats/love/zhangsan.txt&quot;), new Path(&quot;/john/keats/love/&quot;, dstFileName));
    Assert.assertTrue(rename);

    // 目标文件存在，则更名失败
    boolean renameButDstIsExist = fs.rename(new Path(&quot;/john/keats/love/zhangsan.txt&quot;), new Path(&quot;/john/keats/love/&quot;, dstFileName));
    Assert.assertFalse(renameButDstIsExist);
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;h4 id=&quot;读取文件详细信息&quot;&gt;读取文件详细信息&lt;/h4&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;public static void listFiles() throws IOException {
    // 获取文件详情
    RemoteIterator&amp;lt;LocatedFileStatus&amp;gt; listFiles = fs.listFiles(new Path(&quot;/&quot;), true);

    while (listFiles.hasNext()) {
        LocatedFileStatus status = listFiles.next();

        // 输出详情
        // 文件名称
        System.out.println(status.getPath().getName());
        // 长度
        System.out.println(status.getLen());
        // 权限
        System.out.println(status.getPermission());
        // 分组
        System.out.println(status.getGroup());

        // 获取存储的块信息
        BlockLocation[] blockLocations = status.getBlockLocations();

        for (BlockLocation blockLocation : blockLocations) {

            // 获取块存储的主机节点
            String[] hosts = blockLocation.getHosts();

            for (String host : hosts) {
                System.out.println(host);
            }
        }

        System.out.println(&quot;-----------分割线----------&quot;);
    }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;判断某路径下的内容是文件还是文件夹&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;public static void isFile() throws IOException {
    // FileStatus[] listStatus = fs.listStatus(new Path(&quot;/&quot;));
    FileStatus[] listStatus = fs.listStatus(new Path(&quot;/three.txt&quot;));

    for (FileStatus fileStatus : listStatus) {
        // 如果是文件
        if (fileStatus.isFile()) {
            System.out.println(&quot;f:&quot;+fileStatus.getPath().getName());
        }else {
            System.out.println(&quot;d:&quot;+fileStatus.getPath().getName());
        }
    }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;hdfs的io流操作&quot;&gt;HDFS的I/O流操作&lt;/h3&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;// 从本地上传到HDFS
public static void copyFileFromDiskByIO() throws IOException {
    // 2 创建输入流
    FileInputStream fis = new FileInputStream(new File(&quot;D:/zhangsan.txt&quot;));

    // 3 获取输出流
    FSDataOutputStream fos = fs.create(new Path(&quot;/zhangsan.txt&quot;));

    // 4 流对拷
    IOUtils.copyBytes(fis, fos, conf);
}

// 从HDFS拷贝到本地
public static void copyFileFromHDFSByIO() throws IOException {
    FSDataInputStream fis = fs.open(new Path(&quot;/zhangsan.txt&quot;));

    // 3 获取输出流
    FileOutputStream fos = new FileOutputStream(new File(&quot;D:/zhangsan1.txt&quot;));

    // 4 流的对拷
    IOUtils.copyBytes(fis, fos, conf);
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;h4 id=&quot;文件的定位读取&quot;&gt;文件的定位读取&lt;/h4&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;/**
 * 从某个位置开始拷贝文件，用于读取某个完整文件的部分内容
 */
public static void copyFileSeek() throws Exception{
    // 2 打开输入流
    FSDataInputStream fis = fs.open(new Path(&quot;/hadoop-2.10.1.tar.gz&quot;));

    // 3 定位输入数据位置
    fis.seek(1024*1024*128);

    // 4 创建输出流
    FileOutputStream fos = new FileOutputStream(new File(&quot;D:/hadoop-2.7.2.tar.gz.part2&quot;));

    // 5 流的对拷
    IOUtils.copyBytes(fis, fos, conf);
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;hdfs-原理&quot;&gt;HDFS 原理&lt;/h2&gt;
&lt;h3 id=&quot;hdfs的读写数据流程&quot;&gt;HDFS的读写数据流程&lt;/h3&gt;
&lt;h4 id=&quot;写数据&quot;&gt;写数据&lt;/h4&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1654189/202101/1654189-20210104233005937-1862741208.png&quot; alt=&quot;image-20201229221340913&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;1）客户端通过Distributed FileSystem模块向NameNode请求上传文件，NameNode检查目标文件是否已存在，父目录是否存在&lt;/p&gt;
&lt;p&gt;2）NameNode返回是否可以上传&lt;/p&gt;
&lt;p&gt;3）客户端请求第一个 Block上传到哪几个DataNode服务器上（根据服务器距离以及负载排序，取前副本数个服务器返回）&lt;/p&gt;
&lt;p&gt;4）NameNode返回3个DataNode节点，分别为dn1、dn2、dn3&lt;/p&gt;
&lt;p&gt;5）客户端通过FSDataOutputStream模块请求dn1上传数据，dn1收到请求会继续调用dn2，然后dn2调用dn3，将这个通信管道建立完成&lt;/p&gt;
&lt;p&gt;6）dn1、dn2、dn3逐级应答客户端&lt;/p&gt;
&lt;p&gt;7）客户端开始往dn1上传第一个Block（先从磁盘读取数据放到一个本地内存缓存），以Packet为单位，dn1收到一个Packet就会传给dn2，dn2传给dn3；dn1每传一个packet会放入一个应答队列等待应答&lt;/p&gt;
&lt;p&gt;8）当一个Block传输完成之后，客户端再次请求NameNode上传第二个Block的服务器。（重复执行3-7步）&lt;/p&gt;
&lt;h4 id=&quot;读数据&quot;&gt;读数据&lt;/h4&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1654189/202101/1654189-20210104233005079-1265421473.png&quot; alt=&quot;image-20210104210100229&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;1）客户端通过Distributed FileSystem向NameNode请求下载文件，NameNode通过查询元数据，找到文件块所在的DataNode地址&lt;/p&gt;
&lt;p&gt;2）挑选一台DataNode（就近原则，然后随机）服务器，请求读取数据&lt;/p&gt;
&lt;p&gt;3）DataNode开始传输数据给客户端（从磁盘里面读取数据输入流，以Packet为单位来做校验）&lt;/p&gt;
&lt;p&gt;4）客户端以Packet为单位接收，先在本地缓存，然后写入目标文件&lt;/p&gt;
&lt;h3 id=&quot;网络拓扑图，节点距离计算&quot;&gt;网络拓扑图，节点距离计算&lt;/h3&gt;
&lt;p&gt;在HDFS写数据的过程中，NameNode会选择距离待上传数据最近距离的DataNode接收数据。那么这个最近距离怎么计算呢？&lt;/p&gt;
&lt;p&gt;节点距离：两个节点到达最近的共同祖先的距离总和&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1654189/202101/1654189-20210104233004466-839496650.png&quot; alt=&quot;image-20201229222511164&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h3 id=&quot;机架感知，副本存储节点选择&quot;&gt;机架感知，副本存储节点选择&lt;/h3&gt;
&lt;p&gt;机架感知说明&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://hadoop.apache.org/docs/r2.10.1/hadoop-project-dist/hadoop-hdfs/HdfsDesign.html#Data_Replication&quot; target=&quot;_blank&quot;&gt;http://hadoop.apache.org/docs/r2.10.1/hadoop-project-dist/hadoop-hdfs/HdfsDesign.html#Data_Replication&lt;/a&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;For the common case, when the replication factor is three, HDFS’s placement policy is to put one replica on one node in the local rack, another on a different node in the local rack, and the last on a different node in a different rack.
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1654189/202101/1654189-20210104233003834-211736912.png&quot; alt=&quot;image-20201229223021321&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;这样布置，第一考虑的是速度，也兼顾了容灾的要求&lt;/p&gt;
&lt;h3 id=&quot;namenode和secondarynamenode&quot;&gt;NameNode和SecondaryNameNode&lt;/h3&gt;
&lt;h4 id=&quot;namenode中的元数据是存储在哪里的？&quot;&gt;NameNode中的元数据是存储在哪里的？&lt;/h4&gt;
&lt;p&gt;首先，我们做个假设，如果存储在NameNode节点的磁盘中，因为经常需要进行随机访问，还有响应客户请求，必然是效率过低。因此，元数据需要存放在内存中。但如果只存在内存中，一旦断电，元数据丢失，整个集群就无法工作了。因此产生在磁盘中备份元数据的&lt;strong&gt;FsImage&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;这样又会带来新的问题，当在内存中的元数据更新时，如果同时更新FsImage，就会导致效率过低，但如果不更新，就会发生一致性问题，一旦NameNode节点断电，就会产生数据丢失。因此，&lt;strong&gt;引入Edits文件(只进行追加操作，效率很高)&lt;/strong&gt;。每当元数据有更新或者添加元数据时，修改内存中的元数据并追加到Edits中。这样，一旦NameNode节点断电，可以通过FsImage和Edits的合并，合成元数据。&lt;/p&gt;
&lt;p&gt;但是，如果长时间添加数据到Edits中，会导致该文件数据过大，效率降低，而且一旦断电，恢复元数据需要的时间过长。因此，需要定期进行FsImage和Edits的合并，如果这个操作由NameNode节点完成，又会效率过低。因此，引入一个新的节点&lt;strong&gt;SecondaryNamenode，专门用于FsImage和Edits的合并&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;整体的操作机制和 Redis 差不多，FsImage 相当于 Redis 中的 RDB 快照，Edits 相当于 Redis 中的 AOF 日志，两者结合。而 Redis 合并两个文件是采用的 Fork 进程的方式&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1654189/202101/1654189-20210104233003049-1955110365.png&quot; alt=&quot;image-20210104211308789&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;第一阶段：NameNode启动&lt;/p&gt;
&lt;p&gt;（1）第一次启动NameNode格式化后，创建Fsimage和Edits文件。如果不是第一次启动，直接加载编辑日志和镜像文件到内存&lt;/p&gt;
&lt;p&gt;（2）客户端对元数据进行增删改的请求&lt;/p&gt;
&lt;p&gt;（3）NameNode记录操作日志，更新滚动日志&lt;/p&gt;
&lt;p&gt;（4）NameNode在内存中对数据进行增删改&lt;/p&gt;
&lt;p&gt;第二阶段：Secondary NameNode工作&lt;/p&gt;
&lt;p&gt;​ （1）Secondary NameNode询问NameNode是否需要CheckPoint。直接带回NameNode是否检查结果&lt;/p&gt;
&lt;p&gt;​ （2）Secondary NameNode请求执行CheckPoint&lt;/p&gt;
&lt;p&gt;​ （3）NameNode滚动正在写的Edits日志&lt;/p&gt;
&lt;p&gt;​ （4）将滚动前的编辑日志和镜像文件拷贝到Secondary NameNode&lt;/p&gt;
&lt;p&gt;​ （5）Secondary NameNode加载编辑日志和镜像文件到内存，并合并&lt;/p&gt;
&lt;p&gt;​ （6）生成新的镜像文件fsimage.chkpoint&lt;/p&gt;
&lt;p&gt;​ （7）拷贝fsimage.chkpoint到NameNode&lt;/p&gt;
&lt;p&gt;​ （8）NameNode将fsimage.chkpoint重新命名成fsimage&lt;/p&gt;
&lt;h3 id=&quot;datanode-工作机制&quot;&gt;DataNode 工作机制&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1654189/202101/1654189-20210104233001739-2097650147.png&quot; alt=&quot;image-20210104220225348&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;1）一个数据块在DataNode上以文件形式存储在磁盘上，包括两个文件，一个是数据本身，一个是元数据包括数据块的长度，块数据的校验和，以及时间戳&lt;/p&gt;
&lt;p&gt;2）DataNode启动后向NameNode注册，通过后，周期性（1小时）的向NameNode上报所有的块信息&lt;/p&gt;
&lt;p&gt;3）心跳是每3秒一次，心跳返回结果带有NameNode给该DataNode的命令如复制块数据到另一台机器，或删除某个数据块。如果超过10分钟没有收到某个DataNode的心跳，则认为该节点不可用&lt;/p&gt;
&lt;p&gt;4）集群运行中可以安全加入和退出一些机器&lt;/p&gt;
&lt;h4 id=&quot;datanode-多目录配置&quot;&gt;DataNode 多目录配置&lt;/h4&gt;
&lt;p&gt;DataNode 也可以配置成多个目录，每个目录存储的数据不一样。不同于 NameNode 多目录配置，NameNode 多个目录直接的数据是一样的，仅做备份和容灾用。我想是因为 DataNode 已经使用副本来做备份了，如果还继续在本机复制多份，不是很有必要。而 NameNode 在未做高可用之前并没有足够的备份，因此产生了差异&lt;/p&gt;
&lt;p&gt;hdfs-site.xml&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-xml&quot;&gt;&amp;lt;property&amp;gt;
        &amp;lt;name&amp;gt;dfs.datanode.data.dir&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;file:///${hadoop.tmp.dir}/dfs/data1,file:///${hadoop.tmp.dir}/dfs/data2&amp;lt;/value&amp;gt;
&amp;lt;/property&amp;gt;
&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;添加新数据节点&quot;&gt;添加新数据节点&lt;/h3&gt;
&lt;p&gt;（1）在hadoop104主机上再克隆一台hadoop105主机&lt;/p&gt;
&lt;p&gt;（2）修改IP地址和主机名称&lt;/p&gt;
&lt;p&gt;（3）&lt;strong&gt;删除原来HDFS文件系统留存的文件（/opt/module/hadoop/data和log）&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;（4）source一下配置文件&lt;/p&gt;
&lt;p&gt;（5）直接启动DataNode，即可关联到集群&lt;/p&gt;
&lt;p&gt;如果数据不均衡，可以使用 &lt;code&gt;./start-balancer.sh&lt;/code&gt; 命令实现集群的再均衡&lt;/p&gt;
&lt;p&gt;但是这样存在一个问题：如果某些恶意分子知道了 NameNode 的地址，便可以连接集群并克隆出集群的数据，这样是极不安全的&lt;/p&gt;
&lt;h4 id=&quot;添加白名单&quot;&gt;添加白名单&lt;/h4&gt;
&lt;p&gt;只允许白名单内的地址连接 NameNode&lt;/p&gt;
&lt;p&gt;在 NameNode 的 /opt/module/hadoop/etc/hadoop目录下创建 dfs.hosts 文件，并添加如下主机名称&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;linux102
linux103
linux104
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;在 NameNode 的 hdfs-site.xml 配置文件中增加 dfs.hosts 属性&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-xml&quot;&gt;&amp;lt;property&amp;gt;
    &amp;lt;name&amp;gt;dfs.hosts&amp;lt;/name&amp;gt;
    &amp;lt;value&amp;gt;/opt/module/hadoop/etc/hadoop/dfs.hosts&amp;lt;/value&amp;gt;
&amp;lt;/property&amp;gt;
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;文件分发&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-shell&quot;&gt;xsync hdfs-site.xml
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;刷新NameNode&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;hdfs dfsadmin -refreshNodes
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;打开 Web 页面，可以看到不在白名单的 DataNode 会被下线&lt;/p&gt;
&lt;h4 id=&quot;黑名单退役&quot;&gt;黑名单退役&lt;/h4&gt;
&lt;p&gt;在黑名单上的节点会被强制退出&lt;/p&gt;
&lt;p&gt;黑名单的配置 key 如下&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-xml&quot;&gt;&amp;lt;property&amp;gt;
        &amp;lt;name&amp;gt;dfs.hosts.exclude&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;/opt/module/hadoop/etc/hadoop/dfs.hosts.exclude&amp;lt;/value&amp;gt;
&amp;lt;/property&amp;gt;
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;需要注意&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;退役节点时，需要等待退役节点状态为 decommissioned（所有块已经复制完成），停止该节点及节点资源管理器&lt;/li&gt;
&lt;li&gt;如果副本数是3，服役的节点小于等于3，是不能退役成功的，需要修改副本数后才能退役&lt;/li&gt;
&lt;li&gt;不允许黑白名单同时出现一个主机名&lt;/li&gt;
&lt;/ol&gt;&lt;h2 id=&quot;hdfs-2x-新特性&quot;&gt;HDFS 2.X 新特性&lt;/h2&gt;
&lt;h3 id=&quot;集群间数据拷贝&quot;&gt;集群间数据拷贝&lt;/h3&gt;
&lt;pre&gt;
&lt;code class=&quot;language-shell&quot;&gt;bin/hadoop distcp
hdfs://linux102:9000/user/keats/hello.txt hdfs://linux103:9000/user/keats/hello.txt
&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;小文件存档&quot;&gt;小文件存档&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1654189/202101/1654189-20210104232958754-1538981754.png&quot; alt=&quot;image-20210104231711569&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h3 id=&quot;回收站&quot;&gt;回收站&lt;/h3&gt;
&lt;p&gt;开启回收站功能，可以将删除的文件在不超时的情况下，恢复原数据，起到防止误删除、备份等作用&lt;/p&gt;
&lt;h3 id=&quot;快照管理&quot;&gt;快照管理&lt;/h3&gt;
&lt;p&gt;快照相当于对目录做一个备份，&lt;strong&gt;并不会立刻复制所有文件&lt;/strong&gt;。而是记录文件变化&lt;/p&gt;
&lt;h2 id=&quot;参考内容&quot;&gt;参考内容&lt;/h2&gt;
&lt;p&gt;&lt;a href=&quot;https://www.bilibili.com/video/BV1cW411r7c5?p=65&quot; target=&quot;_blank&quot;&gt;B站尚硅谷大数据课程&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;</description>
<pubDate>Mon, 04 Jan 2021 15:35:00 +0000</pubDate>
<dc:creator>后青春期的Keats</dc:creator>
<og:description>大数据 Hadoop 主要解决了数据的存储和分析计算问题，那么它是以何种方式解决数据存储问题的呢？读完这篇博客，我相信你会清楚很多</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/keatsCoder/p/14233180.html</dc:identifier>
</item>
<item>
<title>springcloud学习（一）之Eureka - 易水寒的博客</title>
<link>http://www.cnblogs.com/liuyj-top/p/14233056.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/liuyj-top/p/14233056.html</guid>
<description>&lt;h2 id=&quot;前言&quot;&gt;前言&lt;/h2&gt;
&lt;p&gt;微服务原则上是应该有多个服务提供者的实例的，在通常情况下服务提供者的数量和分布往往是动态变化的，这样在传统的单体应用中的那种硬编码服务url进行远程调用的方式就不足取。服务注册中心就是为了解决服务之间的注册与发现而产生的。&lt;br/&gt;服务注册中心本质上是为了&lt;strong&gt;解耦服务提供者和服务消费者&lt;/strong&gt;。&lt;/p&gt;
&lt;h3 id=&quot;服务注册中心的一般原理&quot;&gt;服务注册中心的一般原理&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;https://img.liuyj.top/eureka-10_1609082633126.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;服务注册中心的一般原理：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;服务注册中心启动&lt;/li&gt;
&lt;li&gt;服务提供者启动，并注册到服务注册中心&lt;/li&gt;
&lt;li&gt;服务消费者从注册中心获取服务信息&lt;/li&gt;
&lt;li&gt;服务消费者远程调用服务提供者&lt;/li&gt;
&lt;/ol&gt;&lt;h3 id=&quot;主流服务注册中心对比&quot;&gt;主流服务注册中心对比&lt;/h3&gt;
&lt;h4 id=&quot;zookeeper&quot;&gt;Zookeeper&lt;/h4&gt;
&lt;p&gt;Zookeeper它是⼀个分布式服务框架，是Apache Hadoop 的⼀个⼦项⽬，它主要是⽤来解决分布式应⽤中经常遇到的⼀些数据管理问题，如：统⼀命名服务、状态同步服务、集群管理、分布式应⽤配置项的管理等。&lt;br/&gt;简单来说zookeeper&lt;strong&gt;本质=存储+监听通知&lt;/strong&gt;。&lt;br/&gt;Zookeeper ⽤来做服务注册中⼼，主要是因为它具有节点(znode)变更通知功能，只要客户端监听相关服务节点，服务节点的所有变更，都能及时的通知到监听客户端，这样作为调⽤⽅只要使⽤Zookeeper 的客户端就能实现服务节点的订阅和变更通知功能了，⾮常⽅便。另外，Zookeeper可⽤性也可以，因为只要半数以上的选举节点存活，整个集群就是可⽤的。&lt;/p&gt;
&lt;h4 id=&quot;eureka&quot;&gt;Eureka&lt;/h4&gt;
&lt;p&gt;由Netflix开源，并被Pivatal集成到SpringCloud体系中，它是基于 RestfulAPI ⻛格开发的服务注册与发现组件。&lt;/p&gt;
&lt;h4 id=&quot;consul&quot;&gt;Consul&lt;/h4&gt;
&lt;p&gt;Consul是由HashiCorp基于Go语⾔开发的⽀持多数据中⼼分布式⾼可⽤的服务发布和注册服务软件， 采⽤Raft算法保证服务的⼀致性，且⽀持健康检查。&lt;/p&gt;
&lt;h4 id=&quot;nacos&quot;&gt;Nacos&lt;/h4&gt;
&lt;p&gt;Nacos是⼀个更易于构建云原⽣应⽤的动态服务发现、配置管理和服务管理平台。简单来说 Nacos就是 &lt;strong&gt;注册中⼼ + 配置中⼼&lt;/strong&gt;的组合，帮助我们解决微服务开发必会涉及到的服务注册与发现，服务配置，服务管理等问题。 Nacos 是 Spring Cloud Alibaba 核⼼组件之⼀，负责服务注册与发现，还有配置。&lt;/p&gt;
&lt;hr/&gt;&lt;p&gt;&lt;strong&gt;CAP&lt;/strong&gt;原理三者对比：&lt;br/&gt;&lt;img src=&quot;https://img.liuyj.top/eureka-13_1609082670944.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h3 id=&quot;eureka基础架构&quot;&gt;Eureka基础架构&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;https://img.liuyj.top/eureka-11_1609082711757.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img.liuyj.top/eureka-12_1609082712611.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;Eureka 包含两个组件：&lt;strong&gt;Eureka Server&lt;/strong&gt; 和 &lt;strong&gt;Eureka Client&lt;/strong&gt;， Eureka Client是⼀个Java客户端，⽤于简化与Eureka Server的交互； Eureka Server提供服务发现的能⼒，各个微服务启动时，会通过Eureka Client向Eureka Server 进⾏注册⾃⼰的信息（例如⽹络信息），Eureka Server会存储该服务的信息；&lt;br/&gt;详细流程如下：&lt;/p&gt;
&lt;ul readability=&quot;4&quot;&gt;&lt;li readability=&quot;2&quot;&gt;
&lt;p&gt;服务提供者向Eureka Server中注册服务， Eureka Server接受到注册事件会在集群和分区中进⾏数据同步，Application Client作为消费端（服务消费者）可以从Eureka Server中获取到服务注册信息，进⾏服务调⽤。微服务启动后，会周期性地向Eureka Server发送⼼跳（默认周期为30秒）以续约⾃⼰的信息&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;Eureka Server在⼀定时间内没有接收到某个微服务节点的⼼跳， Eureka Server将会注销该微服务节点（默认90秒）&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;每个Eureka Server同时也是Eureka Client，多个Eureka Server之间通过复制的⽅式完成服务注册列表的同步&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;Eureka Client会缓存Eureka Server中的信息。即使所有的Eureka Server节点都宕掉，服务消费者依然可以使⽤缓存中的信息找到服务提供者&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;hr/&gt;&lt;p&gt;下面我们来分别进行Eureka单实例及集群环境的搭建及使用（仅列出部分关键代码，详细代码请看文末源码）：&lt;/p&gt;
&lt;h2 id=&quot;搭建单实例eurekaserver&quot;&gt;搭建单实例EurekaServer&lt;/h2&gt;
&lt;p&gt;新建父工程lagou-parent，在pom.xml中统一规定springcloud的版本：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-xml&quot;&gt;&amp;lt;dependencyManagement&amp;gt;
        &amp;lt;dependencies&amp;gt;
            &amp;lt;dependency&amp;gt;
                &amp;lt;groupId&amp;gt;org.springframework.cloud&amp;lt;/groupId&amp;gt;
                &amp;lt;artifactId&amp;gt;spring-cloud-dependencies&amp;lt;/artifactId&amp;gt;
                &amp;lt;version&amp;gt;Greenwich.RELEASE&amp;lt;/version&amp;gt;
                &amp;lt;type&amp;gt;pom&amp;lt;/type&amp;gt;
                &amp;lt;scope&amp;gt;import&amp;lt;/scope&amp;gt;
            &amp;lt;/dependency&amp;gt;
        &amp;lt;/dependencies&amp;gt;
    &amp;lt;/dependencyManagement&amp;gt;
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;新建一个子模块spring-cloud-eureka-server8761，&lt;br/&gt;添加依赖&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt; &amp;lt;!--Eureka server依赖--&amp;gt;
        &amp;lt;dependency&amp;gt;
            &amp;lt;groupId&amp;gt;org.springframework.cloud&amp;lt;/groupId&amp;gt;
            &amp;lt;artifactId&amp;gt;spring-cloud-starter-netflix-eureka-server&amp;lt;/artifactId&amp;gt;
        &amp;lt;/dependency&amp;gt;
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;在启动类上面添加@EnableEurekaServer注解，表明此工程为EurekaServer服务工程。&lt;/p&gt;
&lt;p&gt;application.yml：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-yml&quot;&gt;#eureka server服务端口
server:
  port: 8761
spring:
  application:
    name: lagou-cloud-eureka-server # 应用名称，应用名称会在Eureka中作为服务名称

    # eureka 客户端配置（和Server交互），Eureka Server 其实也是一个Client
eureka:
  instance:
    hostname: localhost  # 当前eureka实例的主机名
  client:
    service-url:
      # 配置客户端所交互的Eureka Server的地址（Eureka Server集群中每一个Server其实相对于其它Server来说都是Client）
      # 集群模式下，defaultZone应该指向其它Eureka Server，如果有更多其它Server实例，逗号拼接即可
      defaultZone: http://${eureka.instance.hostname}:${server.port}/eureka/
    register-with-eureka: false  # ⾃⼰就是服务不需要注册⾃⼰ 集群模式下可以改成true
    fetch-registry: false # ⾃⼰就是服务不需要从Eureka Server获取服务信息,默认为true，集群模式下可以改成true
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;执行启动类，浏览器访问http://localhost:8761/，出现以下界面说明启动成功。&lt;br/&gt;&lt;img src=&quot;https://img.liuyj.top/eureka-1_1609082811541.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;对界面上的信息进行说明：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img.liuyj.top/eureka-2_1609082812424.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img.liuyj.top/eureka-3_1609082814528.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img.liuyj.top/eureka-4_1609082911953.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;至此，单个Eureka server搭建完成。&lt;/p&gt;
&lt;h2 id=&quot;eurekaserver集群搭建&quot;&gt;EurekaServer集群搭建&lt;/h2&gt;
&lt;p&gt;在上面单体Eureka server的基础上搭建Eureka集群。&lt;br/&gt;为了模拟服务器集群的效果，修改本机hosts文件：C:\Windows\System32\drivers\etc\hosts&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;127.0.0.1 LagouCloudEurekaServerA
127.0.0.1 LagouCloudEurekaServerB
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;在原有工程上新建一个Eureka server模块，命名为spring-cloud-eureka-server8762，&lt;br/&gt;spring-cloud-eureka-server8761和spring-cloud-eureka-server8762的application.yml文件如下：&lt;br/&gt;8761:&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-yml&quot;&gt;#eureka server服务端口
server:
  port: 8761
spring:
  application:
    name: lagou-cloud-eureka-server # 应用名称，应用名称会在Eureka中作为服务名称

    # eureka 客户端配置（和Server交互），Eureka Server 其实也是一个Client
eureka:
  instance:
    hostname: LagouCloudEurekaServerA  # 当前eureka实例的主机名
  client:
    service-url:
      # 配置客户端所交互的Eureka Server的地址（Eureka Server集群中每一个Server其实相对于其它Server来说都是Client）
      # 集群模式下，defaultZone应该指向其它Eureka Server，如果有更多其它Server实例，逗号拼接即可
      defaultZone: http://LagouCloudEurekaServerB:8762/eureka/
    register-with-eureka: true  # ⾃⼰就是服务不需要注册⾃⼰ 集群模式下可以改成true
    fetch-registry: true # ⾃⼰就是服务不需要从Eureka Server获取服务信息,默认为true，集群模式下可以改成true
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;8762:&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-yml&quot;&gt;#eureka server服务端口
server:
  port: 8762
spring:
  application:
    name: lagou-cloud-eureka-server

   
eureka:
  instance:
    hostname: LagouCloudEurekaServerB  
  client:
    service-url:
       defaultZone: http://LagouCloudEurekaServerA:8761/eureka/
    register-with-eureka: true  
    fetch-registry: true 
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;浏览器中访问&lt;br/&gt;&lt;a href=&quot;http://LagouCloudEurekaServerA:8761/eureka/&quot; target=&quot;_blank&quot;&gt;http://LagouCloudEurekaServerA:8761/eureka/&lt;/a&gt;&lt;br/&gt;及&lt;br/&gt;&lt;a href=&quot;http://LagouCloudEurekaServerB:8762/eureka/&quot; target=&quot;_blank&quot;&gt;http://LagouCloudEurekaServerB:8762/eureka/&lt;/a&gt;&lt;br/&gt;效果如下：&lt;br/&gt;8761：&lt;br/&gt;&lt;img src=&quot;https://img.liuyj.top/eureka-5_1609082957630.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;br/&gt;8762：&lt;br/&gt;&lt;img src=&quot;https://img.liuyj.top/eureka-6_1609082958885.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h2 id=&quot;注册服务提供者到eurekaserver&quot;&gt;注册服务提供者到EurekaServer&lt;/h2&gt;
&lt;p&gt;父工程中引入&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-xml&quot;&gt;&amp;lt;dependency&amp;gt;
&amp;lt;groupId&amp;gt;org.springframework.cloud&amp;lt;/groupId&amp;gt;
&amp;lt;artifactId&amp;gt;spring-cloud-commons&amp;lt;/artifactId&amp;gt;
&amp;lt;/dependency&amp;gt;
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;服务提供者微服务中引入&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-xml&quot;&gt; &amp;lt;dependency&amp;gt;
&amp;lt;groupId&amp;gt;org.springframework.cloud&amp;lt;/groupId&amp;gt;
&amp;lt;artifactId&amp;gt;spring-cloud-starter-netflix-eureka-client&amp;lt;/artifactId&amp;gt;
&amp;lt;/dependency&amp;gt;
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;服务提供者微服务applicaion.yml:&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-yml&quot;&gt;# Eureka配置
eureka:
  client:
    service-url:
      defaultZone: http://LagouCloudEurekaServerA:8761/eureka/,http://LagouCloudEurekaServerB:8762/eureka/   #把 eureka 集群中的所有 url 都填写了进来，也可以只写⼀台，因为各个eureka server可以同步注册表
  instance:
    prefer-ip-address: true  #使⽤ip注册，否则会使⽤主机名注册了（此处考虑到对⽼版本的兼容，新版本经过实验都是ip）
    #⾃定义实例显示格式，加上版本号，便于多版本管理，注意是ip-address，早期版本是ipAddress
    instance-id: ${spring.cloud.client.ipaddress}:${spring.application.name}:${server.port}:@project.version@

&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;服务提供者启动类添加注解 @EnableDiscoveryClient或@EnableEurekaClient。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;说明：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;1）从Spring Cloud Edgware版本开始， @EnableDiscoveryClient 或 EnableEurekaClient&lt;br/&gt;可省略。只需加上相关依赖，并进⾏相应配置，即可将微服务注册到服务发现组件上。&lt;/p&gt;
&lt;p&gt;2）@EnableDiscoveryClient和@EnableEurekaClient⼆者的功能是⼀样的。但是如果选⽤的是eureka服务器，那么就推荐@EnableEurekaClient，如果是其他的注册中⼼，那么推荐使⽤&lt;br/&gt;@EnableDiscoveryClient，考虑到通⽤性，后期我们可以使⽤@EnableDiscoveryClient&lt;/p&gt;
&lt;h3 id=&quot;启动测试：&quot;&gt;启动测试：&lt;/h3&gt;
&lt;p&gt;启动EurekaServer，可以看到服务提供者实例已经成功注册到EurekaServer上：&lt;br/&gt;&lt;img src=&quot;https://img.liuyj.top/eureka-7_1609083080544.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h2 id=&quot;注册服务消费者到eurekaserver&quot;&gt;注册服务消费者到EurekaServer&lt;/h2&gt;
&lt;p&gt;注册服务消费者和服务提供者类似，pom中添加依赖，在启动类添加@EnableDiscoveryClient，在application.yml中添加eureka的配置信息。&lt;br/&gt;可以看到服务消费者信息成功注册到EurekaServer上：&lt;br/&gt;&lt;img src=&quot;https://img.liuyj.top/eureka-8_1609083011416.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h2 id=&quot;服务提供者调用服务消费者（通过eureka）&quot;&gt;服务提供者调用服务消费者（通过eureka）&lt;/h2&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;package com.lagou.edu.controller;

import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.cloud.client.ServiceInstance;
import org.springframework.cloud.client.discovery.DiscoveryClient;
import org.springframework.web.bind.annotation.GetMapping;
import org.springframework.web.bind.annotation.PathVariable;
import org.springframework.web.bind.annotation.RestController;
import org.springframework.web.client.RestTemplate;

import java.util.List;

@RestController
public class AutoDeliverController {
   @Autowired
   private RestTemplate restTemplate;
   @Autowired
   private DiscoveryClient discoveryClient;
   @GetMapping(&quot;/checkState/{userId}&quot;)
   public Integer findResumeOpenState(@PathVariable Long userId) {

       List&amp;lt;ServiceInstance&amp;gt; serviceInstanceList = discoveryClient.getInstances(&quot;lagou-service-resume&quot;);
       ServiceInstance serviceInstance = serviceInstanceList.get(0);
       String host = serviceInstance.getHost();
       int port = serviceInstance.getPort();
       String url=&quot;http://&quot;+host+&quot;:&quot;+port+&quot;/resume/openstate/&quot;+userId;

       Integer forObject =restTemplate.getForObject(url,Integer.class);
       System.out.println(&quot;======&amp;gt;&amp;gt;&amp;gt;从eureka server获取服务提供者实例：&quot;+url);
       return forObject;
   }
}


&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;调用成功信息如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img.liuyj.top/eureka-9_1609083125188.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h2 id=&quot;源码地址&quot;&gt;源码地址&lt;/h2&gt;
&lt;p&gt;源码地址：&lt;a href=&quot;https://gitee.com/mikecn/eureka-demo&quot; target=&quot;_blank&quot;&gt;eureka-demo 源码&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;欢迎访问我的博客：&lt;a href=&quot;https://www.liuyj.top&quot; target=&quot;_blank&quot;&gt;https://www.liuyj.top&lt;/a&gt;&lt;/p&gt;
</description>
<pubDate>Mon, 04 Jan 2021 14:58:00 +0000</pubDate>
<dc:creator>易水寒的博客</dc:creator>
<og:description>前言 微服务原则上是应该有多个服务提供者的实例的，在通常情况下服务提供者的数量和分布往往是动态变化的，这样在传统的单体应用中的那种硬编码服务url进行远程调用的方式就不足取。服务注册中心就是为了解决服</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/liuyj-top/p/14233056.html</dc:identifier>
</item>
<item>
<title>浅入kubernetes(2)：Kubernetes 的组成 - 痴者工良</title>
<link>http://www.cnblogs.com/whuanle/p/14232932.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/whuanle/p/14232932.html</guid>
<description>&lt;h3 id=&quot;说明&quot;&gt;说明&lt;/h3&gt;
&lt;p&gt;本本内容从 &lt;a href=&quot;https://www.vmware.com/topics/glossary&quot; target=&quot;_blank&quot;&gt;https://www.vmware.com/topics/glossary&lt;/a&gt; 获取、翻译，网站内容政策请参考 &lt;a href=&quot;https://www.vmware.com/community_terms.html%EF%BC%8C%E5%86%85%E5%AE%B9%E5%A4%8D%E5%88%B6%E3%80%81%E7%BF%BB%E8%AF%91%E8%AF%B7%E5%8F%82%E8%80%83%E7%89%88%E6%9D%83%E5%8D%8F%E8%AE%AE&quot; target=&quot;_blank&quot;&gt;https://www.vmware.com/community_terms.html，内容复制、翻译请参考版权协议&lt;/a&gt; &lt;a href=&quot;http://creativecommons.org/licenses/by-nc/3.0/%E3%80%82&quot; target=&quot;_blank&quot;&gt;http://creativecommons.org/licenses/by-nc/3.0/。&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;本文内容从 vmware 网站的术语词汇知识库收集、翻译、整理，文章主要介绍 Kubernetes 各组成部件中的一些术语，以及概念。&lt;/p&gt;
&lt;h3 id=&quot;kubernetes集群的组成&quot;&gt;Kubernetes集群的组成&lt;/h3&gt;
&lt;p&gt;我们谈起 Kubernetes 和应用部署时，往往会涉及到容器、节点、Pods 等概念，还有各种术语，令人眼花缭乱。为了更好地摸清 Kubernetes，下面我们将介绍 Kubernetes 中与应用程序部署(deployment)和执行(execution)相关的知识。&lt;/p&gt;
&lt;p&gt;Kubernetes 集群由多个组件(components)、硬件(hardware)、软件(software)组成，它们共同工作来管理容器化(containerized)应用的部署和执行，这些相关的组成的概念有：&lt;/p&gt;
&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;成分&lt;/th&gt;
&lt;th&gt;名称&lt;/th&gt;
&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;Cluster&lt;/td&gt;
&lt;td&gt;集群&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Node&lt;/td&gt;
&lt;td&gt;节点&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Pod&lt;/td&gt;
&lt;td&gt;不翻译&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Container&lt;/td&gt;
&lt;td&gt;容器&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Containerzed Application&lt;/td&gt;
&lt;td&gt;容器化应用&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;接下来的内容，按将从小到大的粒度介绍这些组成成分。&lt;/p&gt;
&lt;h3 id=&quot;what-are-containerized-applications&quot;&gt;What are containerized applications?&lt;/h3&gt;
&lt;p&gt;containerized applications 指容器化的应用，我们常常说使用镜像打包应用程序，使用 Docker 发布、部署应用程序，那么当你的应用成功在 Docker 上运行时，称这个应用是 containerized applications。&lt;/p&gt;
&lt;p&gt;定义：&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Containerized applications are bundled with their required libraries, binaries, and configuration files into a container.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;容器化的应用程序与它们所需的库、二进制文件和配置文件绑定到一个容器中。&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;当然，并不是说能够将一个应用程序打包到容器中运行，就可以鼓吹产品；并不是每个应用程序都是容器化的优秀对象，例如在 DDD 设计中被称为大泥球的应用程序，由于其设计复杂、依赖程度高、程序不稳定等原因，难以迁移、难以配置的应用程序明显是失败的产品。&lt;/p&gt;
&lt;p&gt;在多年经验中，许多开发者总结了经验，形成十二个云计算应用程序因素指导原则：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;1. Codebase:&lt;/strong&gt; One codebase tracked in revision control, many deploys&lt;/p&gt;
&lt;p&gt;​ 代码库: 一个代码库可以在版本控制和多份部署中被跟踪&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2. Dependencies:&lt;/strong&gt; Explicitly declare and isolate dependencies&lt;/p&gt;
&lt;p&gt;依赖项: 显式声明和隔离依赖项&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;3. Config:&lt;/strong&gt; Store config in the environment&lt;/p&gt;
&lt;p&gt;配置: 在环境中存储配置&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;4. Backing services:&lt;/strong&gt; Treat backing services as attached resources&lt;/p&gt;
&lt;p&gt;支持服务: 将支持服务视为附加资源(可拓展，而不是做成大泥球)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;5. Build, release, run:&lt;/strong&gt; Strictly separate build and run stages&lt;/p&gt;
&lt;p&gt;构建、发布、运行: 严格区分构建和运行阶段(连 Debug、Release 都没有区分的产品是真的垃圾)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;6. Processes:&lt;/strong&gt; Execute the app as one or more stateless processes&lt;/p&gt;
&lt;p&gt;过程: 作为一个或多个无状态过程执行应用程序&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;7. Port binding:&lt;/strong&gt; Export services via port binding&lt;/p&gt;
&lt;p&gt;端口绑定: 可通过端口绑定服务对外提供服务&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;8. Concurrency&lt;/strong&gt;: Scale out via the process model&lt;/p&gt;
&lt;p&gt;并发性: 通过进程模型进行扩展&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;9. Disposability:&lt;/strong&gt; Maximize robustness with fast startup and graceful shutdown&lt;/p&gt;
&lt;p&gt;可处理性: 快速启动和完美关机，最大限度地增强健壮性&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;10. Dev/prod parity&lt;/strong&gt;: Keep development, staging, and production as similar as possible&lt;/p&gt;
&lt;p&gt;Dev/prod parity: 尽可能保持开发中、演示时和生产时的相似性&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;11. Logs:&lt;/strong&gt; Treat logs as event streams&lt;/p&gt;
&lt;p&gt;Logs: 将日志视为事件流&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;12. Admin processes:&lt;/strong&gt; Run admin/management tasks as one-off processes&lt;/p&gt;
&lt;p&gt;管理流程: 将管理/管理任务作为一次性流程运行&lt;/p&gt;
&lt;p&gt;上述内容可能有笔者翻译不到位的地方，读者可阅读原文了解：&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.vmware.com/topics/glossary/content/components-kubernetes&quot; target=&quot;_blank&quot;&gt;https://www.vmware.com/topics/glossary/content/components-kubernetes&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;许多流行的编程语言和应用被容器化并存储在开源仓库中，然而，只使用运行应用程序所需的库和二进制文件来构建应用程序容器，不需要导入所有可用的东西，这样可能会更有效率。创建容器可以采用编程方式，从而可以创建持续集成和部署(CI/CD)管道以提高效率。容器化应用位于开发人员领域之中，开发人员需要掌握如何容器化应用。&lt;/p&gt;
&lt;h3 id=&quot;what-are-kubernetes-containers&quot;&gt;What are Kubernetes containers?&lt;/h3&gt;
&lt;p&gt;&lt;em&gt;Containers are standardized, self-contained execution enclosures for applications.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;容器是应用的标准化、独立的执行外壳。&lt;/p&gt;
&lt;p&gt;通常，容器都包含一个应用程序，以及正确执行二进制程序所需的依赖库、文件等，例如 Linux 文件系统+应用程序组成一个简单的容器。通过将容器限制为单个进程，问题诊断和更新应用程序都变得更加容易。与 VM(虚拟机)不同，容器不包含底层操作系统，因此容器被认为是轻量级的。Kubernentes 容器属于开发领域。&lt;/p&gt;
&lt;h3 id=&quot;what-are-kubernetes-pods&quot;&gt;What are Kubernetes pods?&lt;/h3&gt;
&lt;p&gt;Pod 是 Kubernetes 集群中最小的执行单位。在 Kubernetes 中，容器不直接在集群节点上运行，而是将一个或多个容器封装在一个 Pod 中。Pod 中的所有应用程序共享相同的资源和本地网络，从而简化了 Pod 中应用程序之间的通讯。Pod 在每个节点(Node)上利用一个名为 Kubelet 的代理和 Kubernetes API 以及集群中其余部分进行通讯。尽管现在开发人员需要 API 访问完成集群管理，但 Pod 的管理是正在向 Devops 领域过渡。&lt;/p&gt;
&lt;p&gt;随着 Pod 负载的增加，Kubernetes 可以自动复制 Pod 以达到预期的可拓展性(部署更多的 Pod 提供相同的服务，负载均衡)。因此，设计一个尽可能精简的 Pod 是很重要的，降低因复制扩容、减少收缩过程中带来的资源损失。&lt;/p&gt;
&lt;p&gt;Pod 似乎被认为是 DevOps 的专业领域。&lt;/p&gt;
&lt;h3 id=&quot;what-is-the-difference-between-containers-vs-pods&quot;&gt;What is the difference between containers vs. pods?&lt;/h3&gt;
&lt;p&gt;容器包含执行特定流程或函数所需的代码(编译后的二进制可执行程序)。在 Kubernetes 之前，组织可以直接在物理或虚拟服务器上运行容器，但是缺乏 Kubernetes 集群所提供的可伸缩性和灵活性。&lt;/p&gt;
&lt;p&gt;Pod 为容器提供了一种抽象，可以将一个或多个应用程序包装到一个 Pod 中，而 Pod 是 Kubernetes 集群中最小的执行单元。例如 Pod 可以包含初始化容器，这些容器为其它应用提供了准备环境，然后在应用程序开始执行前终结。Pod 是集群中复制的最小单位，Pod 中的容器作为整体被扩展或缩小。&lt;/p&gt;
&lt;p&gt;如果应用程序需要访问持久性的存储，那么 Pod 也包括持久性存储和容器。&lt;/p&gt;
&lt;h3 id=&quot;what-are-kubernetes-nodes&quot;&gt;What are Kubernetes nodes?&lt;/h3&gt;
&lt;p&gt;Pod 是 Kubernetes 中最小的执行单元，而 Node 是 Kubernetes 中最小的计算硬件单元。节点可以是物理的本地服务器，也可以是虚拟机。&lt;/p&gt;
&lt;p&gt;与容器一样，Node 提供了一个抽象层。如果操作团队认为一个 Node 只是一个具有处理能力和内存的资源，那么每个 Node 就可以与下一个 Node 互换。多个 Node 一起工作形成了 Kubernetes 集群，它可以根据需求的变化自动分配工作负载。如果一个节点失败，它将自动从集群中移除，由其他节点接管。每个节点都运行着一个名为 kubelet 的代理，该代理与集群控制平面通信。&lt;/p&gt;
&lt;p&gt;Node 是 DevOps 和 IT 的专业领域。&lt;/p&gt;
&lt;h4 id=&quot;what-is-the-difference-between-kubernetes-pods-vs-nodes&quot;&gt;What is the difference between Kubernetes pods vs. nodes?&lt;/h4&gt;
&lt;p&gt;Pod 是可执行代码的抽象，Node 是计算机硬件的抽象，所以这种比较有点像苹果和橘子。&lt;/p&gt;
&lt;p&gt;Pods 是 Kubernetes 最小的执行单元，由一个或多个容器组成；&lt;/p&gt;
&lt;p&gt;Node 是组成 Kubernetes 集群的物理服务器或虚拟机。Node 是可互换的，通常不会由用户或 IT 单独处理，除非需要进行维护。&lt;/p&gt;
&lt;h3 id=&quot;what-is-a-kubernetes-control-plane&quot;&gt;What is a Kubernetes Control Plane?&lt;/h3&gt;
&lt;p&gt;Kubernetes 控制平面是用于 Kubernetes 集群的控制器，主要包含 &lt;strong&gt;apiserver&lt;/strong&gt;、&lt;strong&gt;etcd&lt;/strong&gt;、&lt;strong&gt;scheduler&lt;/strong&gt;、&lt;strong&gt;controller-manager&lt;/strong&gt; 。&lt;/p&gt;
&lt;p&gt;在第一篇时已经提到过，这里不需要深入介绍，故不再赘述。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1315495/202101/1315495-20210104222435824-1879446607.png&quot; alt=&quot;Kubernetes_Architecture_graphic&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://rancher.com/blog/2019/2019-04-12-understanding-kubernetes-node/&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1315495/202101/1315495-20210104222451356-2080442765.png&quot; alt=&quot;rancher-k8s-node-components-architecture&quot; loading=&quot;lazy&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&quot;what-is-a-kubernetes-cluster&quot;&gt;What is a Kubernetes Cluster?&lt;/h3&gt;
&lt;p&gt;Kubernetes 集群由 Node 组成，Node 可以是虚拟机或物理服务器。当你使用 Kubernetes 时，大多时间是在管理集群。在一个 Node 上必须至少有一个运行的 Kubernetes 控制平面的实例，以及至少一个要在其上运行的 Pod。通常，当工作负载发生变化时，集群将有多个节点来处理应用程序的变更。&lt;/p&gt;
&lt;h4 id=&quot;what-is-the-difference-between-kubernetes-nodes-vs-clusters&quot;&gt;What is the difference between Kubernetes Nodes vs. Clusters?&lt;/h4&gt;
&lt;p&gt;Node 是集群中最小的元素。集群由 Node 组成。集群是一个集体，共享 Pod 的总体执行，反映在 Google Kubernetes 集群项目的原始名称: Borg。&lt;/p&gt;
&lt;h3 id=&quot;what-are-kubernetes-volumes&quot;&gt;What are Kubernetes volumes?&lt;/h3&gt;
&lt;p&gt;由于容器最初设计为临时性和无状态的，因此几乎不需要解决存储持久性问题。然而，随着越来越多需要从持久性存储读写的应用程序被容器化，对持久性存储卷的访问需求也随之出现。&lt;/p&gt;
&lt;p&gt;为了实现这一点，Kubernetes 有持久的卷。独特之处在于它们是集群外部的，可以将持久卷挂载到集群，而不需要将它们与特定节点、容器或 pod 关联。&lt;/p&gt;
&lt;p&gt;持久卷可以是本地的，也可以是基于云的，并且是 DevOps 和 IT 的专业领域。&lt;/p&gt;
&lt;p&gt;在 Docker 中，我们可以使用以下命令管理卷&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;# 创建自定义容器卷
docker volume create {卷名称}
&lt;/code&gt;
&lt;/pre&gt;
&lt;pre&gt;
&lt;code&gt;# 查看所有容器卷
docker volume ls
&lt;/code&gt;
&lt;/pre&gt;
&lt;pre&gt;
&lt;code&gt;# 查看指定容器卷的详细信息
docker volume inspect {卷名称}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;我们可以在运行容器时，使用 &lt;code&gt;-v&lt;/code&gt; 映射主机目录，或者映射容器卷到容器中。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;docker -itd ... -v /var/tmp:/opt/app ...
docker -itd ... -v {卷名}:/opt/app    ...
&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;how-do-the-components-of-kubernetes-work-together&quot;&gt;How do the components of Kubernetes work together?&lt;/h3&gt;
&lt;p&gt;简单地说，刚开始时，应用程序被创建或迁移到容器中，然后运行在 Kubernetes 集群创建的 Pod上。&lt;/p&gt;
&lt;p&gt;一旦 Pod 被创建，Kubernetes 会将它们分配给集群中的一个或多个 Node ，并确保运行的副本 Node 的正确数量。Kubernetes 扫描集群以确保每组 Container 都按照指定的方式运行。&lt;/p&gt;
</description>
<pubDate>Mon, 04 Jan 2021 14:25:00 +0000</pubDate>
<dc:creator>痴者工良</dc:creator>
<og:description>说明 本本内容从 https://www.vmware.com/topics/glossary 获取、翻译，网站内容政策请参考 https://www.vmware.com/community_ter</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/whuanle/p/14232932.html</dc:identifier>
</item>
<item>
<title>记录一次 Nginx 配置 proxy_pass 后 返回404问题 - 自由早晚乱余生</title>
<link>http://www.cnblogs.com/operationhome/p/14232793.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/operationhome/p/14232793.html</guid>
<description>&lt;h2 id=&quot;一、-nginx-配置-proxy_pass-后-返回404问题-故障解决和定位&quot;&gt;一、 Nginx 配置 proxy_pass 后 返回404问题 故障解决和定位&lt;/h2&gt;
&lt;h3 id=&quot;11、-问题&quot;&gt;1.1、 问题&lt;/h3&gt;
&lt;p&gt;在一次生产涉及多次转发的配置中， 需求是下面的图： &lt;img src=&quot;https://djxblog.oss-cn-shenzhen.aliyuncs.com/picture/Nginx/proxy_set_header.png&quot; alt=&quot;image&quot; loading=&quot;lazy&quot;/&gt;&lt;br/&gt;在配置好了 proxy_pass 之后，请求 www.djx.com 直接返回 404，没有什么其他的异常。 但是我们直接请求后端 www.baidu.com 是正常响应的。这就很怪异的。 看日志请求也是转发到了 www.baidu.com 的。但是请求响应就是404.&lt;/p&gt;
&lt;h3 id=&quot;12、--寻找问题原因&quot;&gt;1.2、 寻找问题原因&lt;/h3&gt;
&lt;p&gt;我们的默认的 Nginx的 &lt;code&gt;proxy_set_header&lt;/code&gt; 配置是&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;proxy_set_header Host $host;

&lt;/code&gt;
&lt;/pre&gt;
&lt;ul&gt;&lt;li&gt;服务端： 192.168.2.189&lt;/li&gt;
&lt;li&gt;服务端1：192.168.1.180 Nginx1&lt;/li&gt;
&lt;li&gt;服务端2：192.168.1.90 Nginx2&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;img src=&quot;https://djxblog.oss-cn-shenzhen.aliyuncs.com/picture/Nginx/proxy_set_header.png&quot; alt=&quot;image&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;当我们是这个的设置的时候，当第一层 Nginx(Nginx1)代理后，我们请求的域名是 www.djx.com ,从这个请求的 header 获取到的 host 的值是 &lt;code&gt;www.djx.com&lt;/code&gt;, 我们通过 配置&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;proxy_set_header Host $host;
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;将 host 的值设置为转发 的Host 值，但是请求的域名是 &lt;code&gt;www.baidu.com&lt;/code&gt; , 也就是 header 里面的是 host 字段是 www.djx.com , 请求的域名和 header 里面的 Host 的不一致导致的。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://djxblog.oss-cn-shenzhen.aliyuncs.com/picture/Nginx/proxy_set_header-2.png&quot; alt=&quot;image&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://nginx.org/en/docs/http/ngx_http_proxy_module.html#proxy_set_header&quot; target=&quot;_blank&quot;&gt;官方文档&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;默认设置为&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;proxy_set_header Host $proxy_host;
proxy_set_header Connection close;
&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;14、----解决办法&quot;&gt;1.4、 解决办法&lt;/h3&gt;
&lt;p&gt;Host 的值设置为 &lt;code&gt;$proxy_host&lt;/code&gt;, &lt;code&gt;$proxy_host&lt;/code&gt; 的值详解见下面扩展。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;proxy_set_header Host $proxy_host;
&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;二、扩展--常用的配置&quot;&gt;二、扩展 常用的配置&lt;/h2&gt;
&lt;h3 id=&quot;1--proxy_host&quot;&gt;1. $proxy_host&lt;/h3&gt;
&lt;pre&gt;
&lt;code&gt;proxy_set_header Host        $proxy_host; 
# 默认配置
# 顾名思义，请求头设置的为代理后的域名。 
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;示例1：&lt;br/&gt;当我们配置了 upstream， 那么$proxy_host 的值就是 upstream 的名字&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;
upstream open-hz8443{
server 10.60.6.184:8000 max_fails=1 fail_timeout=3s weight=10;
}

&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;那么这里 $proxy_host 的值就是 open-hz8443。&lt;/p&gt;
&lt;p&gt;示例2：&lt;br/&gt;当我们没有配置 upstream， 那么 $proxy_host 的值就是 &lt;code&gt;proxy_pass&lt;/code&gt; 后面的地址ip和端口. &lt;code&gt;10.60.6.184:8000&lt;/code&gt;. 如果是 &lt;code&gt;proxy_pass http://www.djx.com:8000;&lt;/code&gt; 那么 $proxy_host 的值就是 &lt;code&gt;www.djx.com:8000&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;location ^~ /wss/v1
{
    proxy_pass  http://10.60.6.184:8000;
    proxy_set_header   Host    $proxy_host;
    proxy_set_header Connection &quot;upgrade&quot;;
    proxy_set_header Upgrade $http_upgrade;
    tcp_nodelay on; 
    
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;2-host&quot;&gt;2. $host&lt;/h3&gt;
&lt;pre&gt;
&lt;code&gt;proxy_set_header Host       $host;
# 当字段不在请求头中就无法传递了，在这种情况下，可通过设置Host变量，将需传递值赋给Host变量
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;当请求 Header 里 Host 无值的时候，直接拿 server_name 的值进行填充。&lt;/p&gt;
&lt;p&gt;当请求 Header 里 Host 的值的时候，就直接拿 请求 Header 里面的 Host 的值。&lt;/p&gt;
&lt;h3 id=&quot;3-hostproxy_port&quot;&gt;3. $host:$proxy_port&lt;/h3&gt;
&lt;pre&gt;
&lt;code&gt;proxy_set_header Host       $host:$proxy_port;

# 服务器名称和端口一起通过代理服务器传递，相对上一项，多了一个 $proxy_port，这个 $proxy_port 是proxy_pass 里面的那个端口，如果没有端口，像80 和 443 的话。也是会使用 80 /443 填充， 

示例： 
proxy_pass http://www.baidu.com;

$host:$proxy_port = 百度ip:80
&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;4-http_host&quot;&gt;4. $http_host&lt;/h3&gt;
&lt;pre&gt;
&lt;code&gt;proxy_set_header Host       $http_host; 
# 一个不会变化的“Host”头请求字段可通过如下方式被传递：

&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;当请求 Header 里 Host 无值的时候，直接拿 server_name 的值进行填充。并加上端口。如果是 80/443 则不加。 其实就是去 请求url 里面的值。 &lt;code&gt;http://server:port/v1&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;当请求 Header 里 Host 的值的时候，就直接拿 请求 Header 里面的 Host 的值。&lt;/p&gt;
&lt;h4 id=&quot;示例&quot;&gt;示例&lt;/h4&gt;
&lt;ul&gt;&lt;li&gt;服务端： 192.168.2.189&lt;/li&gt;
&lt;li&gt;服务端1：192.168.1.180 Nginx1&lt;/li&gt;
&lt;li&gt;服务端2：192.168.1.90 Nginx2&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;img src=&quot;https://djxblog.oss-cn-shenzhen.aliyuncs.com/picture/Nginx/proxy_set_header.png&quot; alt=&quot;image&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;基础配置&lt;br/&gt;192.168.1.180 Nginx1&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;server{
    listen 80;
    server_name www.djx.com;
    
    location / {
        proxy_pass http://www.baidu.com/;
    }
    
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;192.168.1.190 Nginx2&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;server{
    listen 80;
    server_name www.baidu.com;
    
    location / {
        proxy_pass http://192.168.1.80:8080/;
    }
    
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;** 使用基础配置 **&lt;br/&gt;也就是&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;proxy_set_header Host        $proxy_host; 
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;那么到 &lt;a href=&quot;http://192.168.1.80:8080/&quot; target=&quot;_blank&quot;&gt;http://192.168.1.80:8080/&lt;/a&gt; header 的值为 www.baidu.com.&lt;/p&gt;
&lt;p&gt;** 使用 $host **&lt;br/&gt;也就是&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;proxy_set_header Host        $host; 
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;参考文章：&lt;a href=&quot;https://cloud.tencent.com/developer/article/1557504&quot; target=&quot;_blank&quot;&gt;https://cloud.tencent.com/developer/article/1557504&lt;/a&gt;&lt;/p&gt;
</description>
<pubDate>Mon, 04 Jan 2021 14:15:00 +0000</pubDate>
<dc:creator>自由早晚乱余生</dc:creator>
<og:description>一、 Nginx 配置 proxy_pass 后 返回404问题 故障解决和定位 1.1、 问题 在一次生产涉及多次转发的配置中， 需求是下面的图： 在配置好了 proxy_pass 之后，请求 ww</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/operationhome/p/14232793.html</dc:identifier>
</item>
</channel>
</rss>