<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="css/feed.xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/" xmlns:og="http://ogp.me/ns#">
<channel>
<atom:link rel="self" href="http://192.168.1.4/fivefilters/makefulltextfeed.php?url=feed.cnblogs.com%2Fblog%2Fsitehome%2Frss&amp;max=10&amp;links=preserve&amp;exc=" />
<atom:link rel="alternate" title="Source URL" href="http://feed.cnblogs.com/blog/sitehome/rss" />
<atom:link rel="related" title="Subscribe to feed" href="http://www.subtome.com/#/subscribe?feeds=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed.cnblogs.com%252Fblog%252Fsitehome%252Frss%26max%3D10%26links%3Dpreserve%26exc%3D&amp;back=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed.cnblogs.com%252Fblog%252Fsitehome%252Frss%26max%3D10%26links%3Dpreserve%26exc%3D" />
<title>博客园_首页</title>
<link></link>
<description>代码改变世界</description>
<item>
<title>[从源码学设计]蚂蚁金服SOFARegistry之推拉模型 - 罗西的思考</title>
<link>http://www.cnblogs.com/rossiXYZ/p/14123647.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/rossiXYZ/p/14123647.html</guid>
<description>&lt;p&gt;SOFARegistry 是蚂蚁金服开源的一个生产级、高时效、高可用的服务注册中心。本系列文章重点在于分析设计和架构，即利用多篇文章，从多个角度反推总结 DataServer 或者 SOFARegistry 的实现机制和架构思路，让大家借以学习阿里如何设计。本文为第七篇，介绍SOFARegistry网络操作的推拉模型。&lt;/p&gt;&lt;div id=&quot;cnblogs_post_body&quot; readability=&quot;352.34323967948&quot;&gt;


&lt;h2 id=&quot;0x00-摘要&quot;&gt;0x00 摘要&lt;/h2&gt;
&lt;p&gt;SOFARegistry 是蚂蚁金服开源的一个生产级、高时效、高可用的服务注册中心。&lt;/p&gt;
&lt;p&gt;本系列文章重点在于分析设计和架构，即利用多篇文章，从多个角度反推总结 DataServer 或者 SOFARegistry 的实现机制和架构思路，让大家借以学习阿里如何设计。&lt;/p&gt;
&lt;p&gt;本文为第七篇，介绍SOFARegistry网络操作的推拉模型。&lt;/p&gt;
&lt;h2 id=&quot;0x01-相关概念&quot;&gt;0x01 相关概念&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Push还是Pull？？？&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&quot;11-推模型和拉模型&quot;&gt;1.1 推模型和拉模型&lt;/h3&gt;
&lt;p&gt;在观察者模式中，又分为推模型和拉模型两种方式。　&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;推模型&lt;/strong&gt;：主题对象向观察者推送主题的详细信息，不管观察者是否需要，推送的信息通常是主题对象的全部或部分数据。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;拉模型&lt;/strong&gt;：主题对象在通知观察者的时候，只传递少量信息。如果观察者需要更具体的信息，由观察者主动到主题对象中获取，相当于是观察者从主题对象中拉数据。&lt;/p&gt;
&lt;p&gt;具体两个模型详细剖析如下：&lt;/p&gt;
&lt;h4 id=&quot;111-推模型：&quot;&gt;1.1.1 推模型：&lt;/h4&gt;
&lt;h5 id=&quot;特点：&quot;&gt;特点：&lt;/h5&gt;
&lt;ul&gt;&lt;li&gt;基于客户器/服务器机制、由服务器主动将信息送到客户器的技术；&lt;/li&gt;
&lt;li&gt;“推”的方式是指，Subject维护一份观察者的列表，每当有更新发生，Subject会把更新消息主动推送到各个Observer去。&lt;/li&gt;
&lt;li&gt;服务器把信息送给客户器之前，并没有明显的客户请求，push事务由服务器发起；&lt;/li&gt;
&lt;li&gt;主题对象向观察者推送主题的详细信息，不管观察者是否需要，推送的信息通常是主题对象的全部或部分数据。&lt;/li&gt;
&lt;li&gt;推模型是假定主题对象知道观察者需要的数据；&lt;/li&gt;
&lt;/ul&gt;&lt;h5 id=&quot;优点：&quot;&gt;优点：&lt;/h5&gt;
&lt;ul&gt;&lt;li&gt;push模式可以让信息主动、快速地寻找用户/客户器，信息的主动性和实时性比较好。&lt;/li&gt;
&lt;li&gt;高效。如果没有更新发生，不会有任何更新消息推送的动作，即每次消息推送都发生在确确实实的更新事件之后，都是有意义的。&lt;/li&gt;
&lt;li&gt;实时。事件发生后的第一时间即可触发通知操作。&lt;/li&gt;
&lt;li&gt;可以由Subject确立通知的时间，可以避开一些繁忙时间。&lt;/li&gt;
&lt;li&gt;可以表达出不同事件发生的先后顺序&lt;/li&gt;
&lt;/ul&gt;&lt;h5 id=&quot;缺点：&quot;&gt;缺点：&lt;/h5&gt;
&lt;ul&gt;&lt;li&gt;精确性较差，可能推送的信息并不一定满足客户的需求。推送模式不能保证能把信息送到客户器；&lt;/li&gt;
&lt;li&gt;因为推模式采用了广播机制，如果客户器正好联网并且和服务器在同一个频道上，推送模式才是有效的；&lt;/li&gt;
&lt;li&gt;push模式无法跟踪状态，采用了开环控制模式，没有用户反馈信息；&lt;/li&gt;
&lt;li&gt;不管观察者是否需要，推送的信息通常是主题对象的全部或部分数据；&lt;/li&gt;
&lt;/ul&gt;&lt;h4 id=&quot;112-拉模型&quot;&gt;1.1.2 拉模型&lt;/h4&gt;
&lt;h5 id=&quot;特点：-1&quot;&gt;特点：&lt;/h5&gt;
&lt;ul&gt;&lt;li&gt;是由客户器主动发起的事务。服务器把自己所拥有的信息放在指定地址（如IP、port），客户器向指定地址发送请求，把自己需要的资源“拉”回来；&lt;/li&gt;
&lt;li&gt;“拉”的方式是指，各个Observer维护各自所关心的Subject列表，自行决定在合适的时间去Subject获取相应的更新数据；&lt;/li&gt;
&lt;li&gt;拉模型是主题对象不知道观察者具体需要什么数据，没有办法的情况下，干脆把自身传递给观察者，让观察者自己去按需要取值；&lt;/li&gt;
&lt;/ul&gt;&lt;h5 id=&quot;优点：-1&quot;&gt;优点：&lt;/h5&gt;
&lt;ul&gt;&lt;li&gt;不仅可以准确获取自己需要的资源，还可以及时把客户端的状态反馈给服务器；&lt;/li&gt;
&lt;li&gt;如果观察者众多，Subject来维护订阅者的列表可能困难或者臃肿，这样可以把订阅关系解脱到Observer去完成；&lt;/li&gt;
&lt;li&gt;Observer可以不理会它不关心的变更事件，只需要去获取自己感兴趣的事件即可；&lt;/li&gt;
&lt;li&gt;Observer可以自行决定获取更新事件的时间；&lt;/li&gt;
&lt;li&gt;拉的形式可以让Subject更好地控制各个Observer每次查询更新的访问权限；&lt;/li&gt;
&lt;/ul&gt;&lt;h5 id=&quot;缺点：-1&quot;&gt;缺点：&lt;/h5&gt;
&lt;ul&gt;&lt;li&gt;最大的缺点就是不及时；&lt;/li&gt;
&lt;/ul&gt;&lt;h3 id=&quot;12-guava-loadingcache&quot;&gt;1.2 Guava LoadingCache&lt;/h3&gt;
&lt;p&gt;Guava是Google guava中的一个内存缓存模块，用于将数据缓存到JVM内存中。实际项目开发中经常将一些公共或者常用的数据缓存起来方便快速访问。&lt;/p&gt;
&lt;p&gt;Google Guava Cache提供了基于容量，时间和引用的缓存回收方式。基于容量的方式内部实现采用LRU算法，基于引用回收很好的利用了Java虚拟机的垃圾回收机制。&lt;/p&gt;
&lt;p&gt;其中的缓存构造器CacheBuilder采用构建者模式提供了设置好各种参数的缓存对象，缓存核心类LocalCache里面的内部类Segment与jdk1.7及以前的ConcurrentHashMap非常相似，都继承于ReetrantLock，还有六个队列，以实现丰富的本地缓存方案。&lt;/p&gt;
&lt;h2 id=&quot;0x02-业务领域&quot;&gt;0x02 业务领域&lt;/h2&gt;
&lt;h3 id=&quot;21-应用场景&quot;&gt;2.1 应用场景&lt;/h3&gt;
&lt;p&gt;SOFARegistry 的业务特点如下：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;SOFARegistry 系统分为三个集群，分别是元数据集群 MetaServer、会话集群 SessionServer、数据集群 DataServer。&lt;/li&gt;
&lt;li&gt;DataServer，SessionServer，MetaServer 本质上都是网络应用程序；&lt;/li&gt;
&lt;li&gt;复杂的系统有多个地方需要考虑到一致性问题，比如当服务 Publisher 上下线或者断连时，相应的数据会通过 SessionServer 注册到 DataServer 中。此时，DataServer 的数据与 SessionServer 会出现&lt;u&gt;短暂的不一致性&lt;/u&gt;；&lt;/li&gt;
&lt;li&gt;SOFARegistry 针对不同模块的一致性需求采取了不同的方案。对于 MetaServer 模块来说，采用了强一致性的 Raft 协议来保证集群信息的一致性。对&lt;u&gt;于数据模块来说，SOFARegistry 选择了 AP 保证可用性，同时保证了最终一致性&lt;/u&gt;；&lt;/li&gt;
&lt;/ul&gt;&lt;h3 id=&quot;22-问题点&quot;&gt;2.2 问题点&lt;/h3&gt;
&lt;p&gt;我们通过业务，能够想到的问题点如下：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;新消息数据需要即时更新，想做到&lt;u&gt;秒级的通知&lt;/u&gt;，这一般来说需要推模型；&lt;/li&gt;
&lt;li&gt;但是推模型难以确保稳定性；&lt;/li&gt;
&lt;li&gt;推模式，客户端代码简单，由服务端进行推送数据，省去了客户端无谓的轮询类操作。但是需要服务端复杂化推送逻辑。&lt;/li&gt;
&lt;li&gt;拉模式，需要自行维护偏移量，负载均衡等；&lt;/li&gt;
&lt;/ul&gt;&lt;h3 id=&quot;23-解决方案&quot;&gt;2.3 解决方案&lt;/h3&gt;
&lt;p&gt;对于以上的问题点，业界一般来说会采用“推”和“拉”结合的形式，例如，服务端只负责通知 “某一些数据已经准备好”，至于是否需要获取和什么时候客户端来获取这些数据，完全由客户端自行确定。&lt;/p&gt;
&lt;h3 id=&quot;24-阿里方案&quot;&gt;2.4 阿里方案&lt;/h3&gt;
&lt;p&gt;我们首先看看阿里都应用了什么方案。&lt;/p&gt;
&lt;h4 id=&quot;241-各种模型应用&quot;&gt;2.4.1 各种模型应用&lt;/h4&gt;
&lt;p&gt;在SOFARegistry‘中，应用了&lt;strong&gt;&lt;u&gt;各种模型&lt;/u&gt;&lt;/strong&gt;，比如 ：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;SessionServer 和 DataServer 之间的通信，是基于&lt;u&gt;推拉结合&lt;/u&gt;的机制&lt;/strong&gt;
&lt;ul&gt;&lt;li&gt;推：DataServer 在数据有变化时，会主动通知 SessionServer，SessionServer 检查确认需要更新（对比 version） 后主动向 DataServer 获取数据。&lt;/li&gt;
&lt;li&gt;拉：除了上述的 DataServer 主动推以外，SessionServer 每隔一定的时间间隔（默认30秒），会主动向 DataServer 查询所有 dataInfoId 的 version 信息，然后再与 SessionServer 内存的 version 作比较，若发现 version 有变化，则主动向 DataServer 获取数据。这个“拉”的逻辑，主要是对“推”的一个补充，若在“推”的过程有错漏的情况可以在这个时候及时弥补。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;SOFARegistry 服务发现模式采用的是&lt;u&gt;推拉结合方式&lt;/u&gt;。&lt;/strong&gt;
&lt;ul&gt;&lt;li&gt;客户端订阅信息发布到服务端时可以进行一次地址列表查询，获取到全量数据，并且把对应的服务 ID 版本信息存储在 Session 回话层，后续如果服务端发布数据变更，通过服务 ID 版本变更通知回话层 Session，Session 因为存储客户端订阅关系，了解哪些客户端需要这个服务信息，再根据版本号大小决定是否需要推送给这个版本较旧的订阅者，客户端也通过版本比较确定是否更新本次推送的结果覆盖内存。&lt;/li&gt;
&lt;li&gt;此外，为了避免某次变更通知获取失败，定期还会进行版本号差异比较，定期去拉取版本低的订阅者所需的数据进行推送保证数据最终一致。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Client 与 SessionServer 之间，完全基于&lt;u&gt;推的机制&lt;/u&gt;&lt;/strong&gt;
&lt;ul&gt;&lt;li&gt;SessionServer 在接收到 DataServer 的数据变更推送，或者 SessionServer 定期查询 DataServer 发现数据有变更并重新获取之后，直接将 dataInfoId 的数据推送给 Client。如果这个过程因为网络原因没能成功推送给 Client，SessionServer 会尝试做一定次数（默认5次）的重试，最终还是失败的话，依然会在 SessionServer 定期每隔 30s 轮训 DataServer 时，会再次推送数据给 Client。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;下面是两种场景的数据推送对比图。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://imgconvert.csdnimg.cn/aHR0cHM6Ly9tbWJpei5xcGljLmNuL21tYml6X3BuZy9uaWJPWnBhUUt3MDhsYWxKYlg1RkJFUVEzUDE2V1pKRzhaY0VFVWVrRmdMb2tJTElTZVNCdG5UdjRITDJaRTMzWFM1Sm5ITDhLVkc3V1RseXpiVXpnb1EvNjQw?x-oss-process=image/format,png&quot; alt=&quot;img&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h4 id=&quot;242-推拉模型&quot;&gt;2.4.2 推拉模型&lt;/h4&gt;
&lt;p&gt;就本文涉及的问题域来说，蚂蚁金服在这里采用了经典的推拉模型来维持数据一致性，下面我们仅以 &lt;code&gt;Session Server和 Data Server 之间维护数据一致性&lt;/code&gt; 为例说明。大致逻辑如下：&lt;/p&gt;
&lt;p&gt;SOFARegistry 中采用了 &lt;code&gt;LoadingCache&lt;/code&gt; 的数据结构来在 SessionServer 中缓存从 DataServer 中同步来的数据。&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;拉模型&lt;/strong&gt;：
&lt;ul&gt;&lt;li&gt;每个 cache 中的 entry 都有过期时间，在拉取数据的时候可以设置过期时间（默认是 30s）；&lt;/li&gt;
&lt;li&gt;这个过期时间使得 cache 定期去 DataServer 查询当前 session 所有 sub 的 dataInfoId，对比如果 session 记录的最近推送version（见&lt;code&gt;com.alipay.sofa.registry.server.session.store.SessionInterests#interestVersions&lt;/code&gt; ）比 DataServer 小，说明需要推送；&lt;/li&gt;
&lt;li&gt;然后 SessionServer 主动从 DataServer 获取该 dataInfoId 的数据(此时会缓存到 cache 里)，推送给 client；&lt;/li&gt;
&lt;li&gt;这个“拉”的逻辑，&lt;u&gt;主要是对“推”的一个补充，若在“推”的过程有错漏的情况可以在这个时候及时弥补&lt;/u&gt;。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;推模型&lt;/strong&gt;：
&lt;ul&gt;&lt;li&gt;当 DataServer 中有数据更新时，也会主动向 SessionServer 发请求使对应 cache entry 失效；&lt;/li&gt;
&lt;li&gt;当SessionServer 检查确认需要更新（对比 version） 之后，主动向 DataServer 获取数据；&lt;/li&gt;
&lt;li&gt;SessionServer去更新失效 entry。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;h2 id=&quot;0x03-拉模型-in-session-server&quot;&gt;0x03 拉模型 in Session Server&lt;/h2&gt;
&lt;p&gt;这里 SOFARegistry 采用了 Guava LoadingCache 的数据结构，通过给 cache 中的 entry 设置过期时间的方式，使得 cache 定期从 DataServer 中拉取数据以替换过期的 entry。&lt;/p&gt;
&lt;p&gt;模型大致示例如下，下文会详细讲解：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt; +-----------------------------------------+
 |            Session Server               |
 |                                         |
 | +-------------------------------------+ |
 | |        SessionCacheService          | |
 | |                                     | |
 | | +--------------------------------+  | |
 | | |                                |  | |
 | | |    LoadingCache&amp;lt;Key, Value&amp;gt;    |  | |
 | | |            +                   |  | |
 | | |            |  expireAfterWrite |  | |
 | | |            |                   |  | |
 | | |            v                   |  | |
 | | |     DatumCacheGenerator        |  | |
 | | |            +                   |  | |
 | | +--------------------------------+  | |
 | +-------------------------------------+ |
 |                |                        |
 |                v                        |
 |       +--------+------------+           |
 |       | DataNodeServiceImpl |           |
 |       +--------+------------+           |
 |                |                        |
 +-----------------------------------------+
                  |
                  |   GetDataRequest
                  |
+-------------------------------------------+
                  |
                  |
                  v
          +-------+-----------+
          |   Data Server     |
          +-------------------+
&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;31-bean&quot;&gt;3.1 Bean&lt;/h3&gt;
&lt;p&gt;相关的Bean定义如下，其中SessionCacheService应用了Guava LoadingCache，DatumCacheGenerator是具体加载实现。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;@Configuration
public static class SessionCacheConfiguration {

    @Bean
    public CacheService sessionCacheService() {
        return new SessionCacheService();
    }

    @Bean(name = &quot;com.alipay.sofa.registry.server.session.cache.DatumKey&quot;)
    public DatumCacheGenerator datumCacheGenerator() {
        return new DatumCacheGenerator();
    }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;32-代码分析&quot;&gt;3.2 代码分析&lt;/h3&gt;
&lt;p&gt;拉模型的实现是在SessionCacheService类，其删减版代码 如下&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;public class SessionCacheService implements CacheService {
    private final LoadingCache&amp;lt;Key, Value&amp;gt; readWriteCacheMap; 
    private Map&amp;lt;String, CacheGenerator&amp;gt;    cacheGenerators;

    ......
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;可以看到其核心就是利用了&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;private final LoadingCache&amp;lt;Key, Value&amp;gt; readWriteCacheMap;
&lt;/code&gt;
&lt;/pre&gt;
&lt;h4 id=&quot;321-cache构造&quot;&gt;3.2.1 Cache构造&lt;/h4&gt;
&lt;p&gt;构造LoadingCache举例如下：&lt;/p&gt;
&lt;ul readability=&quot;0&quot;&gt;&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;其缓存池大小为1000，在缓存项接近该大小时， Guava开始回收旧的缓存项；&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;其设置缓存在写入之后，设定时间31000毫秒后失效；&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;生成一个CacheLoader类 实现自动加载，具体加载是调用generatePayload；&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;代码如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;this.readWriteCacheMap = CacheBuilder.newBuilder().maximumSize(1000L)
    .expireAfterWrite(31000, TimeUnit.MILLISECONDS).build(new CacheLoader&amp;lt;Key, Value&amp;gt;() {
        @Override
        public Value load(Key key) {
            return generatePayload(key);
        }
    });
&lt;/code&gt;
&lt;/pre&gt;
&lt;h4 id=&quot;322-获取value&quot;&gt;3.2.2 获取value&lt;/h4&gt;
&lt;p&gt;获取value的函数比较简单：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;@Override
public Value getValue(final Key key) throws CacheAccessException {
    Value payload = null;
    payload = readWriteCacheMap.get(key);
    return payload;
}

@Override
public Map&amp;lt;Key, Value&amp;gt; getValues(final Iterable&amp;lt;Key&amp;gt; keys) throws CacheAccessException {
    Map&amp;lt;Key, Value&amp;gt; valueMap = null;
    valueMap = readWriteCacheMap.getAll(keys);
    return valueMap;
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;h4 id=&quot;323-批量清除&quot;&gt;3.2.3 批量清除&lt;/h4&gt;
&lt;p&gt;清除批量缓存对象，这个API&lt;u&gt;在Data Server 主动给 Session Server 发送 Push 数据时候会用到&lt;/u&gt;，这样就将引发一次主动获取。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;@Override
public void invalidate(Key... keys) {
    for (Key key : keys) {
        readWriteCacheMap.invalidate(key);
    }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;h4 id=&quot;324-自动加载&quot;&gt;3.2.4 自动加载&lt;/h4&gt;
&lt;p&gt;自动加载是通过CacheGenerator完成。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;private Value generatePayload(Key key) {
    Value value = null;
    switch (key.getKeyType()) {
        case OBJ:
            EntityType entityType = key.getEntityType();
            CacheGenerator cacheGenerator = cacheGenerators
                .get(entityType.getClass().getName());
            value = cacheGenerator.generatePayload(key);
            break;
        case JSON:
            break;
        case XML:
            break;
        default:
            value = new Value(new HashMap&amp;lt;String, Object&amp;gt;());
            break;
    }
    return value;
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;h4 id=&quot;325-设置加载&quot;&gt;3.2.5 设置加载&lt;/h4&gt;
&lt;p&gt;设置加载是通过如下代码完成。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;/**
 * Setter method for property &amp;lt;tt&amp;gt;cacheGenerators&amp;lt;/tt&amp;gt;.
 *
 * @param cacheGenerators  value to be assigned to property cacheGenerators
 */
@Autowired
public void setCacheGenerators(Map&amp;lt;String, CacheGenerator&amp;gt; cacheGenerators) {
    this.cacheGenerators = cacheGenerators;
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;具体设置时候runtime参数如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;cacheGenerators = {LinkedHashMap@3368}  size = 1
 &quot;com.alipay.sofa.registry.server.session.cache.DatumKey&quot; -&amp;gt; {DatumCacheGenerator@3374} 
&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;33-加载类实现&quot;&gt;3.3 加载类实现&lt;/h3&gt;
&lt;p&gt;加载类是通过DatumCacheGenerator完成。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;public class DatumCacheGenerator implements CacheGenerator {
    @Autowired
    private DataNodeService     dataNodeService;

    @Override
    public Value generatePayload(Key key) {

        EntityType entityType = key.getEntityType();
        if (entityType instanceof DatumKey) {
            DatumKey datumKey = (DatumKey) entityType;

            String dataCenter = datumKey.getDataCenter();
            String dataInfoId = datumKey.getDataInfoId();

            if (isNotBlank(dataCenter) &amp;amp;&amp;amp; isNotBlank(dataInfoId)) {
                return new Value(dataNodeService.fetchDataCenter(dataInfoId, dataCenter));
            } 
        } 

        return null;
    }

    public boolean isNotBlank(String ss) {
        return ss != null &amp;amp;&amp;amp; !ss.isEmpty();
    }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;可以看到，加载具体就是通过DataNodeServiceImpl向 DataServer 发起请求。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;public class DataNodeServiceImpl implements DataNodeService {
    @Autowired
    private NodeExchanger         dataNodeExchanger;

    @Autowired
    private NodeManager           dataNodeManager;
  
    @Override
    public Datum fetchDataCenter(String dataInfoId, String dataCenterId) {

        Map&amp;lt;String/*datacenter*/, Datum&amp;gt; map = getDatumMap(dataInfoId, dataCenterId);
        if (map != null &amp;amp;&amp;amp; map.size() &amp;gt; 0) {
            return map.get(dataCenterId);
        }
        return null;
    }
  
    @Override
    public Map&amp;lt;String, Datum&amp;gt; getDatumMap(String dataInfoId, String dataCenterId) {

        Map&amp;lt;String/*datacenter*/, Datum&amp;gt; map;

        try {
            GetDataRequest getDataRequest = new GetDataRequest();

            //dataCenter null means all dataCenters
            if (dataCenterId != null) {
                getDataRequest.setDataCenter(dataCenterId);
            }

            getDataRequest.setDataInfoId(dataInfoId);

            Request&amp;lt;GetDataRequest&amp;gt; getDataRequestStringRequest = new Request&amp;lt;GetDataRequest&amp;gt;() {

                @Override
                public GetDataRequest getRequestBody() {
                    return getDataRequest;
                }

                @Override
                public URL getRequestUrl() {
                    return getUrl(dataInfoId);
                }

                @Override
                public Integer getTimeout() {
                    return sessionServerConfig.getDataNodeExchangeForFetchDatumTimeOut();
                }
            };

            Response response = dataNodeExchanger.request(getDataRequestStringRequest);
            Object result = response.getResult();
            GenericResponse genericResponse = (GenericResponse) result;
            if (genericResponse.isSuccess()) {
                map = (Map&amp;lt;String, Datum&amp;gt;) genericResponse.getData();
                map.forEach((dataCenter, datum) -&amp;gt; Datum.internDatum(datum));
            } 
        } 
        return map;
    }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;拉模型具体如下图所示：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt; +-----------------------------------------+
 |            Session Server               |
 |                                         |
 | +-------------------------------------+ |
 | |        SessionCacheService          | |
 | |                                     | |
 | | +--------------------------------+  | |
 | | |                                |  | |
 | | |    LoadingCache&amp;lt;Key, Value&amp;gt;    |  | |
 | | |            +                   |  | |
 | | |            |  expireAfterWrite |  | |
 | | |            |                   |  | |
 | | |            v                   |  | |
 | | |     DatumCacheGenerator        |  | |
 | | |            +                   |  | |
 | | +--------------------------------+  | |
 | +-------------------------------------+ |
 |                |                        |
 |                v                        |
 |       +--------+------------+           |
 |       | DataNodeServiceImpl |           |
 |       +--------+------------+           |
 |                |                        |
 +-----------------------------------------+
                  |
                  |   GetDataRequest
                  |
+-------------------------------------------+
                  |
                  |
                  v
          +-------+-----------+
          |   Data Server     |
          +-------------------+
&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;0x04-推模型&quot;&gt;0x04 推模型&lt;/h2&gt;
&lt;p&gt;当 DataServer 中有数据更新时，也会主动向 SessionServer 发请求使对应 entry 失效，从而促使 SessionServer 去更新失效 entry。&lt;/p&gt;
&lt;h3 id=&quot;41-发起推动作&quot;&gt;4.1 发起推动作&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;DataChangeRequest in Data Server&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;u&gt;当Data Server&lt;/u&gt; 有数据变化时候，会主动发送 &lt;strong&gt;DataChangeRequest&lt;/strong&gt; 给 Session Server。&lt;/p&gt;
&lt;p&gt;具体代码是在SessionServerNotifier之中，具体如下（这就与前文的Notifier联系起来）：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;public class SessionServerNotifier implements IDataChangeNotifier {

    private AsyncHashedWheelTimer          asyncHashedWheelTimer;

    @Autowired
    private DataServerConfig               dataServerConfig;

    @Autowired
    private Exchange                       boltExchange;

    @Autowired
    private SessionServerConnectionFactory sessionServerConnectionFactory;

    @Autowired
    private DatumCache                     datumCache;
  
    @Override
    public void notify(Datum datum, Long lastVersion) {
        DataChangeRequest request = new DataChangeRequest(datum.getDataInfoId(),
            datum.getDataCenter(), datum.getVersion());
        List&amp;lt;Connection&amp;gt; connections = sessionServerConnectionFactory.getSessionConnections();
        for (Connection connection : connections) {
            doNotify(new NotifyCallback(connection, request));
        }
    }

    private void doNotify(NotifyCallback notifyCallback) {
        Connection connection = notifyCallback.connection;
        DataChangeRequest request = notifyCallback.request;
        try {
            //check connection active
            if (!connection.isFine()) {
                return;
            }
            Server sessionServer = boltExchange.getServer(dataServerConfig.getPort());
            sessionServer.sendCallback(sessionServer.getChannel(connection.getRemoteAddress()),
                request, notifyCallback, dataServerConfig.getRpcTimeout());
        } catch (Exception e) {
            onFailed(notifyCallback);
        }
    }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;42-接收推消息&quot;&gt;4.2 接收推消息&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;DataChangeRequestHandler in Session Server&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;u&gt;在Session Server&lt;/u&gt;，DataChangeRequestHandler负责响应处理收到的推消息 &lt;strong&gt;DataChangeRequest&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;可以看到，其调用了如下代码&lt;u&gt;使得Cache失效&lt;/u&gt;，进而&lt;u&gt;后续Cache会去Data Server重新load value&lt;/u&gt;。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;sessionCacheService.invalidate(new Key(KeyType.OBJ, DatumKey.class.getName(), new DatumKey(
        dataChangeRequest.getDataInfoId(), dataChangeRequest.getDataCenter())));
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;其删减版代码如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;public class DataChangeRequestHandler extends AbstractClientHandler {

    /**
     * store subscribers
     */
    @Autowired
    private Interests                        sessionInterests;

    @Autowired
    private SessionServerConfig              sessionServerConfig;

    @Autowired
    private ExecutorManager                  executorManager;

    @Autowired
    private CacheService                     sessionCacheService;

    @Autowired
    private DataChangeRequestHandlerStrategy dataChangeRequestHandlerStrategy;

    @Override
    public Object reply(Channel channel, Object message) {
        DataChangeRequest dataChangeRequest = (DataChangeRequest) message;
        dataChangeRequest.setDataCenter(dataChangeRequest.getDataCenter());
        dataChangeRequest.setDataInfoId(dataChangeRequest.getDataInfoId());

        //update cache when change
        sessionCacheService.invalidate(new Key(KeyType.OBJ, DatumKey.class.getName(), new DatumKey(
            dataChangeRequest.getDataInfoId(), dataChangeRequest.getDataCenter())));

        try {
            boolean result = sessionInterests.checkInterestVersions(
                dataChangeRequest.getDataCenter(), dataChangeRequest.getDataInfoId(),
                dataChangeRequest.getVersion());
            fireChangFetch(dataChangeRequest);
        } 

        return null;
    }

    private void fireChangFetch(DataChangeRequest dataChangeRequest) {
        dataChangeRequestHandlerStrategy.doFireChangFetch(dataChangeRequest);
    }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;于是我们的架构图变化为：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt; +----------------------------------------------------------------+
 |                        Session Server                          |
 |                                                                |
 | +-----------------------------------------------------------+  |
 | |                  SessionCacheService                      |  |
 | |                                                           |  |
 | | +-------------------------------------------------------+ |  |
 | | |                                                       | |  |
 | | |    LoadingCache&amp;lt;Key, Value&amp;gt;  &amp;lt;----------+             | |  |
 | | |            +                            |             | |  |
 | | |            |  expireAfterWrite          | invalidate  | |  |
 | | |            |                            |             | |  |
 | | |            v                            |             | |  |
 | | |     DatumCacheGenerator                 |             | |  |
 | | |            +                            |             | |  |
 | | +-------------------------------------------------------+ |  |
 | +-----------------------------------------------------------+  |
 |                |                            |                  |
 |                v                            |                  |
 |       +--------+------------+     +---------+----------------+ |
 |       | DataNodeServiceImpl |     | DataChangeRequestHandler | |
 |       +--------+------------+     +---------+----------------+ |
 |                |                            ^                  |
 +----------------------------------------------------------------+
                  |                            |
   GetDataRequest |                            | DataChangeRequest
                  |                            |
+--------------------------------------------------------------------+
                  |                            |
                  |  Pull                      | Push
                  v                            |
                +-+----------------------------+-+
                |           Data Server          |
                +--------------------------------+
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;手机上如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1850883/202012/1850883-20201212075128689-2098977546.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;让我们在SessionServer内部继续延伸下，看看&lt;u&gt;当收到推消息之后，SessionServer是怎样进行后续的push，就是通知Client&lt;/u&gt;。即我们之前提到的：&lt;strong&gt;Client 与 SessionServer 之间，完全基于&lt;u&gt;推的机制&lt;/u&gt;&lt;/strong&gt;。&lt;/p&gt;
&lt;h3 id=&quot;43-延伸处理strategy&quot;&gt;4.3 延伸处理Strategy&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;DefaultDataChangeRequestHandlerStrategy&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;前面代码来到了处理dataChangeRequest的部分。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;dataChangeRequestHandlerStrategy.doFireChangFetch(dataChangeRequest);
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;剩下部分还是 Strategy -- Listener -- Task 的套路（后续有文章讲解）。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;public class DefaultDataChangeRequestHandlerStrategy implements DataChangeRequestHandlerStrategy {
    @Autowired
    private TaskListenerManager taskListenerManager;

    @Override
    public void doFireChangFetch(DataChangeRequest dataChangeRequest) {
        TaskEvent taskEvent = new TaskEvent(dataChangeRequest.getDataInfoId(),
            TaskEvent.TaskType.DATA_CHANGE_FETCH_CLOUD_TASK);
        taskListenerManager.sendTaskEvent(taskEvent);
    }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;44-延伸处理listener&quot;&gt;4.4 延伸处理Listener&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;DataChangeFetchCloudTaskListener&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;DataChangeFetchCloudTaskListener在 support函数中配置了支持 DATA_CHANGE_FETCH_CLOUD_TASK。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;@Override
public TaskType support() {
    return TaskType.DATA_CHANGE_FETCH_CLOUD_TASK;
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;具体代码如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;public class DataChangeFetchCloudTaskListener implements TaskListener {

    @Autowired
    private Interests                                    sessionInterests;

    @Autowired
    private SessionServerConfig                          sessionServerConfig;

    /**
     * trigger task com.alipay.sofa.registry.server.meta.listener process
     */
    @Autowired
    private TaskListenerManager                          taskListenerManager;

    @Autowired
    private ExecutorManager                              executorManager;

    @Autowired
    private CacheService                                 sessionCacheService;

    private volatile TaskDispatcher&amp;lt;String, SessionTask&amp;gt; singleTaskDispatcher;

    private TaskProcessor                                dataNodeSingleTaskProcessor;

    public DataChangeFetchCloudTaskListener(TaskProcessor dataNodeSingleTaskProcessor) {
        this.dataNodeSingleTaskProcessor = dataNodeSingleTaskProcessor;
    }

    public TaskDispatcher&amp;lt;String, SessionTask&amp;gt; getSingleTaskDispatcher() {
        if (singleTaskDispatcher == null) {
            synchronized (this) {
                if (singleTaskDispatcher == null) {
                    singleTaskDispatcher = TaskDispatchers.createSingleTaskDispatcher(
                        TaskDispatchers.getDispatcherName(TaskType.DATA_CHANGE_FETCH_CLOUD_TASK
                            .getName()), sessionServerConfig.getDataChangeFetchTaskMaxBufferSize(),
                        sessionServerConfig.getDataChangeFetchTaskWorkerSize(), 1000, 100,
                        dataNodeSingleTaskProcessor);
                }
            }
        }
        return singleTaskDispatcher;
    }

    @Override
    public TaskType support() {
        return TaskType.DATA_CHANGE_FETCH_CLOUD_TASK;
    }

    @Override
    public void handleEvent(TaskEvent event) {
        SessionTask dataChangeFetchTask = new DataChangeFetchCloudTask(sessionServerConfig,
            taskListenerManager, sessionInterests, executorManager, sessionCacheService);
        dataChangeFetchTask.setTaskEvent(event);
        getSingleTaskDispatcher().dispatch(dataChangeFetchTask.getTaskId(), dataChangeFetchTask,
            dataChangeFetchTask.getExpiryTime());
    }

}
&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;45-延伸处理task&quot;&gt;4.5 延伸处理Task&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;DataChangeFetchCloudTask&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;DataChangeFetchCloudTask 会&lt;u&gt;进行后续的push，就是通知Client&lt;/u&gt;。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;public class DataChangeFetchCloudTask extends AbstractSessionTask {
    private final SessionServerConfig sessionServerConfig;

    private Interests                 sessionInterests;

    /**
     * trigger task com.alipay.sofa.registry.server.meta.listener process
     */
    private final TaskListenerManager taskListenerManager;

    private final ExecutorManager     executorManager;

    private String                    fetchDataInfoId;

    private final CacheService        sessionCacheService;
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;会获取每个Subscriber的 IP，然后向 taskListenerManager 发送若干种消息，比如：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;RECEIVED_DATA_MULTI_PUSH_TASK；&lt;/li&gt;
&lt;li&gt;USER_DATA_ELEMENT_PUSH_TASK；&lt;/li&gt;
&lt;li&gt;USER_DATA_ELEMENT_MULTI_PUSH_TASK；&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;从而进行后续对client的 push。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;@Override
public void execute() {
    Map&amp;lt;String/*dataCenter*/, Datum&amp;gt; datumMap = getDatumsCache();

    if (datumMap != null &amp;amp;&amp;amp; !datumMap.isEmpty()) {

        PushTaskClosure pushTaskClosure = getTaskClosure(datumMap);

        for (ScopeEnum scopeEnum : ScopeEnum.values()) {
            Map&amp;lt;InetSocketAddress, Map&amp;lt;String, Subscriber&amp;gt;&amp;gt; map = getCache(fetchDataInfoId,
                scopeEnum);
            if (map != null &amp;amp;&amp;amp; !map.isEmpty()) {
                for (Entry&amp;lt;InetSocketAddress, Map&amp;lt;String, Subscriber&amp;gt;&amp;gt; entry : map.entrySet()) {
                    Map&amp;lt;String, Subscriber&amp;gt; subscriberMap = entry.getValue();
                    if (subscriberMap != null &amp;amp;&amp;amp; !subscriberMap.isEmpty()) {
                        List&amp;lt;String&amp;gt; subscriberRegisterIdList = new ArrayList&amp;lt;&amp;gt;(
                            subscriberMap.keySet());

                        //select one row decide common info
                        Subscriber subscriber = subscriberMap.values().iterator().next();

                        //remove stopPush subscriber avoid push duplicate
                        evictReSubscribers(subscriberMap.values());

                        fireReceivedDataMultiPushTask(datumMap, subscriberRegisterIdList,
                            scopeEnum, subscriber, subscriberMap, pushTaskClosure);
                    }
                }
            }
        }

        pushTaskClosure.start();
    } 
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;以 RECEIVED_DATA_MULTI_PUSH_TASK 为例，我们的架构流程图更改如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;+-------------------------------------------------------------------------------------------------------------------+
|                        Session Server                                  +-------------------------------------+    |
|                                                                        |  ReceivedDataMultiPushTaskListener  |    |
| +-----------------------------------------------------------+          +------+------------------------------+    |
| |                  SessionCacheService                      |                 ^                                   |
| |                                                           |                 |  RECEIVED_DATA_MULTI_PUSH_TASK    |
| | +-------------------------------------------------------+ |                 |                                   |
| | |                                                       | |             +---+------------------------+          |
| | |    LoadingCache&amp;lt;Key, Value&amp;gt;  &amp;lt;----------+             | |             |  DataChangeFetchCloudTask  |          |
| | |            +                            |             | |             +---+------------------------+          |
| | |            |  expireAfterWrite          | invalidate  | |                 ^                                   |
| | |            |                            |             | |                 |                                   |
| | |            v                            |             | |                 |                                   |
| | |     DatumCacheGenerator                 |             | |           +-----+----------------------------+      |
| | |            +                            |             | |           | DataChangeFetchCloudTaskListener |      |
| | +-------------------------------------------------------+ |           +-----+----------------------------+      |
| +-----------------------------------------------------------+                 ^                                   |
|                |                            |                                 |  DATA_CHANGE_FETCH_CLOUD_TASK     |
|                v                            |                                 |                                   |
|       +--------+------------+     +---------+----------------+       +--------+--------------------------------+  |
|       | DataNodeServiceImpl |     | DataChangeRequestHandler +-----&amp;gt; | DefaultDataChangeRequestHandlerStrategy |  |
|       +--------+------------+     +---------+----------------+       +-----------------------------------------+  |
|                |                            ^                                                                     |
+-------------------------------------------------------------------------------------------------------------------+
                 |                            ^
  GetDataRequest |                            | DataChangeRequest
                 |                            |
+-------------------------------------------------------------------------------------------------------------------+
                 |                            ^
                 | Pull                       |  Push
                 v                            |
               +-+----------------------------+-+
               |           Data Server          |
               +--------------------------------+
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;手机上如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1850883/202012/1850883-20201212075145840-1268755593.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h2 id=&quot;0x05-总结&quot;&gt;0x05 总结&lt;/h2&gt;
&lt;p&gt;本文讲解了蚂蚁金服在维持数据一致性上采用的经典的推拉模型，以 &lt;code&gt;Session Server和 Data Server 之间维护数据一致性&lt;/code&gt; 为例。其大致逻辑如下：&lt;/p&gt;
&lt;p&gt;SOFARegistry 中采用了 &lt;code&gt;LoadingCache&lt;/code&gt; 的数据结构来在 SessionServer 中缓存从 DataServer 中同步来的数据。&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;拉模型&lt;/strong&gt;：
&lt;ul&gt;&lt;li&gt;每个 cache 中的 entry 都有过期时间，在拉取数据的时候可以设置过期时间（默认是 30s）；&lt;/li&gt;
&lt;li&gt;这个过期时间使得 cache 定期去 DataServer 查询当前 session 所有 sub 的 dataInfoId，对比如果 session 记录的最近推送version（见&lt;code&gt;com.alipay.sofa.registry.server.session.store.SessionInterests#interestVersions&lt;/code&gt; ）比 DataServer 小，说明需要推送；&lt;/li&gt;
&lt;li&gt;然后 SessionServer 主动从 DataServer 获取该 dataInfoId 的数据(此时会缓存到 cache 里)，推送给 client；&lt;/li&gt;
&lt;li&gt;这个“拉”的逻辑，&lt;u&gt;主要是对“推”的一个补充，若在“推”的过程有错漏的情况可以在这个时候及时弥补&lt;/u&gt;。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;推模型&lt;/strong&gt;：
&lt;ul&gt;&lt;li&gt;当 DataServer 中有数据更新时，也会主动向 SessionServer 发请求使对应 cache entry 失效；&lt;/li&gt;
&lt;li&gt;当SessionServer 检查确认需要更新（对比 version） 之后，主动向 DataServer 获取数据；&lt;/li&gt;
&lt;li&gt;SessionServer去更新失效 entry。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;大家在日常开发中，可以借鉴。&lt;/p&gt;
&lt;h2 id=&quot;0xff-参考&quot;&gt;0xFF 参考&lt;/h2&gt;
&lt;p&gt;&lt;a href=&quot;https://blog.csdn.net/qq_41878532/article/details/109489239&quot; target=&quot;_blank&quot;&gt;Guava LoadingCache详解及工具类&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.jianshu.com/p/38bd5f1cf2f2&quot; target=&quot;_blank&quot;&gt;Google Guava Cache 全解析&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://my.oschina.net/sofastack/blog/3187743&quot; target=&quot;_blank&quot;&gt;蚂蚁金服服务注册中心数据一致性方案分析 | SOFARegistry 解析&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;</description>
<pubDate>Fri, 11 Dec 2020 23:54:00 +0000</pubDate>
<dc:creator>罗西的思考</dc:creator>
<og:description>SOFARegistry 是蚂蚁金服开源的一个生产级、高时效、高可用的服务注册中心。本系列文章重点在于分析设计和架构，即利用多篇文章，从多个角度反推总结 DataServer 或者 SOFARegis</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/rossiXYZ/p/14123647.html</dc:identifier>
</item>
<item>
<title>Tensorflow学习笔记No.11 - VioletOrz</title>
<link>http://www.cnblogs.com/VioletOrz/p/14123604.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/VioletOrz/p/14123604.html</guid>
<description>&lt;p&gt;&lt;span&gt;图像定位是指在图像中将我们需要识别的部分使用定位框进行定位标记，本次主要讲述如何使用tensorflow2.0实现简单的&lt;span&gt;图像定位&lt;/span&gt;任务。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;span&gt;我所使用的定位方法是训练神经网络使它&lt;strong&gt;输出定位框的四个顶点的坐标&lt;/strong&gt;，通过这四个坐标来定位需要识别对象的位置。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;span&gt;数据集：&lt;a href=&quot;https://pan.baidu.com/s/1dv-r19KixYhA1CfX2n06Hg&quot; target=&quot;_blank&quot;&gt;https://pan.baidu.com/s/1dv-r19KixYhA1CfX2n06Hg&lt;/a&gt;  提取码：2kbc (数据集中的压缩文件需要解压)&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h2&gt;&lt;span&gt;&lt;span&gt;1.数据读入&lt;/span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/h2&gt;
&lt;h2&gt;&lt;span&gt;1.1图片读入&lt;/span&gt;&lt;/h2&gt;
&lt;p&gt;&lt;span&gt;图片的读入在前面的博客中已经展示过很多次了，这里不再赘述，详情可以参考&lt;strong&gt;&lt;span&gt;&lt;a href=&quot;https://www.cnblogs.com/VioletOrz/p/13779995.html&quot; target=&quot;_blank&quot;&gt;&lt;span&gt;Tensorflow学习笔记No.5&lt;/span&gt;&lt;/a&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;，&lt;/span&gt;&lt;span&gt;里面详细介绍了读取图片的过程。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;span&gt;图像定位数据集的标签与之前的分类任务不同，是一个xml文件，我们需要使用爬虫从文件中爬取需要的信息。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;span&gt;导入需要的库&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;34&quot;&gt;
&lt;pre&gt;
&lt;span&gt;1&lt;/span&gt; import tensorflow &lt;span&gt;as&lt;/span&gt;&lt;span&gt; tf
&lt;/span&gt;&lt;span&gt;2&lt;/span&gt; import numpy &lt;span&gt;as&lt;/span&gt;&lt;span&gt; np
&lt;/span&gt;&lt;span&gt;3&lt;/span&gt; import matplotlib.pyplot &lt;span&gt;as&lt;/span&gt;&lt;span&gt; plt
&lt;/span&gt;&lt;span&gt;4&lt;/span&gt; &lt;span&gt;from&lt;/span&gt;&lt;span&gt; lxml import etree
&lt;/span&gt;&lt;span&gt;5&lt;/span&gt; &lt;span&gt;import glob
&lt;/span&gt;&lt;span&gt;6&lt;/span&gt; %&lt;span&gt;matplotlib inline
&lt;/span&gt;&lt;span&gt;7&lt;/span&gt; &lt;span&gt;import pathlib
&lt;/span&gt;&lt;span&gt;8&lt;/span&gt; &lt;span&gt;from&lt;/span&gt; matplotlib.patches import Rectangle
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span&gt;&lt;span&gt;首先设置路径&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;33&quot;&gt;
&lt;pre&gt;
&lt;span&gt;1&lt;/span&gt; image_root =  pathlib.Path(&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;E:/BaiduNetdiskDownload/图片定位与分割数据集/images&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;)
&lt;/span&gt;&lt;span&gt;2&lt;/span&gt; label_root = pathlib.Path(&lt;span&gt;'&lt;/span&gt;&lt;span&gt;E:/BaiduNetdiskDownload/图片定位与分割数据集/annotations/xmls&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;)
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span&gt;通过.glob()方法获得所有的图片和标签路径，并转换为字符串的形式。&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;34&quot;&gt;
&lt;pre&gt;
&lt;span&gt;1&lt;/span&gt; all_image_path = list(image_root.glob(&lt;span&gt;'&lt;/span&gt;&lt;span&gt;*.jpg&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;))
&lt;/span&gt;&lt;span&gt;2&lt;/span&gt; all_label_path = list(label_root.glob(&lt;span&gt;'&lt;/span&gt;&lt;span&gt;*.xml&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;))
&lt;/span&gt;&lt;span&gt;3&lt;/span&gt; 
&lt;span&gt;4&lt;/span&gt; all_image_path = [str(p) &lt;span&gt;for&lt;/span&gt; p &lt;span&gt;in&lt;/span&gt;&lt;span&gt; all_image_path]
&lt;/span&gt;&lt;span&gt;5&lt;/span&gt; all_label_path = [str(p) &lt;span&gt;for&lt;/span&gt; p &lt;span&gt;in&lt;/span&gt; all_label_path]
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span&gt;&lt;span&gt;然后简单展示一下我们的数据集是什么样子的，同时简单讲解一下如何使用爬虫爬取需要的信息。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;随便找一找图片作为例子。&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;34&quot;&gt;
&lt;pre&gt;
&lt;span&gt;1&lt;/span&gt; path =&lt;span&gt; all_image_path[0]
&lt;/span&gt;&lt;span&gt;2&lt;/span&gt; path_ =&lt;span&gt; all_label_path[0]
&lt;/span&gt;&lt;span&gt;3&lt;/span&gt; 
&lt;span&gt;4&lt;/span&gt; &lt;span&gt;#&lt;/span&gt;&lt;span&gt;path E:\\BaiduNetdiskDownload\\图片定位与分割数据集\\images\\Abyssinian_1.jpg&lt;/span&gt;
&lt;span&gt;5&lt;/span&gt; &lt;span&gt;#&lt;/span&gt;&lt;span&gt;path_ E:\\BaiduNetdiskDownload\\图片定位与分割数据集\\annotations\\xmls\\Abyssinian_1.xml&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span&gt;首先解码并输出这张图片(我使用的是jypyter notebook进行可视化)&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;32&quot;&gt;
&lt;pre&gt;
&lt;span&gt;1&lt;/span&gt; img =&lt;span&gt; tf.io.read_file(path)
&lt;/span&gt;&lt;span&gt;2&lt;/span&gt; img =&lt;span&gt; tf.image.decode_jpeg(img)
&lt;/span&gt;&lt;span&gt;3&lt;/span&gt; plt.imshow(img)
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span&gt;得到如下图片:&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1924931/202012/1924931-20201212010749461-1444908980.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h2&gt;1.2xml文件解析与数据爬取&lt;/h2&gt;
&lt;p&gt;&lt;span&gt;我们本次的图像定位任务是定位动物的头部，也就是说我们得到的输出结果是把动物的头部框起来。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;span&gt;接下来对xml文件进行解析，文件内容如下：&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1924931/202012/1924931-20201212011134998-2068407896.png&quot; alt=&quot;&quot; width=&quot;423&quot; height=&quot;577&quot; loading=&quot;lazy&quot;/&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;文件中是非常整齐的xml格式&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;name&amp;gt;和&amp;lt;/name&amp;gt;就相当于一对括号把其中的内容括起来，里面的内容就属于这个标签之下。例如上图中的annotation就是最大的标签，里面包含了folder、source等标签(有点类似电脑里的文件夹？)。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;我们可以使用爬虫来访问这种整齐格式之中的内容&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;首先使用python自带的open方法打开这个xml文件&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;32&quot;&gt;
&lt;pre&gt;
&lt;span&gt;1&lt;/span&gt; xml = open(path_).read()
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span&gt;然后创建一个选择器来对内容进行访问&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot;&gt;
&lt;pre&gt;
&lt;span&gt;1&lt;/span&gt; sel = etree.HTML(xml)
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span&gt;sel.xpath()方法可以访问xml文件中某个目录下的内容，我们用这个方法获得其中的文本信息。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;例如，我们可以获得长宽信息，width和height位于size标签下，用text()访问其中的文本内容，内容会以字符串列表的形式返回。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;由于只有一个长宽信息，我们直接取列表的首位元素转换成int类型即可。&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;33&quot;&gt;
&lt;pre&gt;
&lt;span&gt;1&lt;/span&gt; width = int(sel.xpath(&lt;span&gt;'&lt;/span&gt;&lt;span&gt;//size/width/text()&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;)[0])
&lt;/span&gt;&lt;span&gt;2&lt;/span&gt; height = int(sel.xpath(&lt;span&gt;'&lt;/span&gt;&lt;span&gt;//size/height/text()&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;)[0])
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span&gt;同样的我们获取其他需要的信息。&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;34&quot;&gt;
&lt;pre&gt;
&lt;span&gt;1&lt;/span&gt; xmin = int(sel.xpath(&lt;span&gt;'&lt;/span&gt;&lt;span&gt;//bndbox/xmin/text()&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;)[0])
&lt;/span&gt;&lt;span&gt;2&lt;/span&gt; ymin = int(sel.xpath(&lt;span&gt;'&lt;/span&gt;&lt;span&gt;//bndbox/ymin/text()&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;)[0])
&lt;/span&gt;&lt;span&gt;3&lt;/span&gt; xmax = int(sel.xpath(&lt;span&gt;'&lt;/span&gt;&lt;span&gt;//bndbox/xmax/text()&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;)[0])
&lt;/span&gt;&lt;span&gt;4&lt;/span&gt; ymax = int(sel.xpath(&lt;span&gt;'&lt;/span&gt;&lt;span&gt;//bndbox/ymax/text()&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;)[0])
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span&gt;事实上我们只需要知道左上和右下的顶点坐标即可确定一个矩形框，xmin，ymin代表左上角的坐标，xmax，ymax代表右上角的坐标。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;我们把这个框展示在图片中看一下效果&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;38&quot;&gt;
&lt;pre&gt;
&lt;span&gt;1&lt;/span&gt; &lt;span&gt;plt.imshow(img)
&lt;/span&gt;&lt;span&gt;2&lt;/span&gt; rect = Rectangle((xmin, ymin), (xmax - xmin), (ymax - ymin), fill = False, color = &lt;span&gt;'&lt;/span&gt;&lt;span&gt;blue&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;)
&lt;/span&gt;&lt;span&gt;3&lt;/span&gt; pimg =&lt;span&gt; plt.gca()
&lt;/span&gt;&lt;span&gt;4&lt;/span&gt; pimg.axes.add_patch(rect)
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span&gt;得到如下所示图片：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1924931/202012/1924931-20201212012332795-1187225716.png&quot; alt=&quot;&quot; width=&quot;312&quot; height=&quot;215&quot; loading=&quot;lazy&quot;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;可以看到猫猫的头部被框起来了(&lt;span&gt;爱猫人士表示强烈谴责)&lt;/span&gt;，这就是我们最终想要得到的效果。我们希望神经网络能够识别出动物的头像并把它框出来。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;span&gt;事实上我们的图片大小各不相同，但神经网络的输入尺寸是固定的，所有我们要把图片和lable坐标转换到同一尺度上，即224×224。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;方法如下，同时输出效果图：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;42&quot;&gt;
&lt;pre&gt;
&lt;span&gt; 1&lt;/span&gt; img = tf.image.resize(img, (256, 256&lt;span&gt;))
&lt;/span&gt;&lt;span&gt; 2&lt;/span&gt; img = img / 255
&lt;span&gt; 3&lt;/span&gt; &lt;span&gt;plt.imshow(img)
&lt;/span&gt;&lt;span&gt; 4&lt;/span&gt; 
&lt;span&gt; 5&lt;/span&gt; xmin = xmin / width * 256
&lt;span&gt; 6&lt;/span&gt; xmax = xmax / width * 256
&lt;span&gt; 7&lt;/span&gt; ymin = ymin / height * 256
&lt;span&gt; 8&lt;/span&gt; ymax = ymax / height * 256
&lt;span&gt; 9&lt;/span&gt; 
&lt;span&gt;10&lt;/span&gt; &lt;span&gt;plt.imshow(img)
&lt;/span&gt;&lt;span&gt;11&lt;/span&gt; rect = Rectangle((xmin, ymin), (xmax - xmin), (ymax - ymin), fill = False, color = &lt;span&gt;'&lt;/span&gt;&lt;span&gt;blue&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;)
&lt;/span&gt;&lt;span&gt;12&lt;/span&gt; pimg =&lt;span&gt; plt.gca()
&lt;/span&gt;&lt;span&gt;13&lt;/span&gt; pimg.axes.add_patch(rect)
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1924931/202012/1924931-20201212012709727-1110769123.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1924931/202012/1924931-20201212012801462-1691406652.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h2&gt;1.3数据集构建&lt;/h2&gt;
&lt;p&gt;&lt;span&gt;我们的数据集中并非每一张图片都有对应的xml文件，所以我们只用有label的数据作为训练集和验证集。(共3686张可训练数据）&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;首先我们把标签的文件名从路径中分割出来，图片与标签名称一致，通过这种方式来筛选出我们需要的图片。&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;35&quot;&gt;
&lt;pre&gt;
&lt;span&gt;1&lt;/span&gt; names = [x.split(&lt;span&gt;'&lt;/span&gt;&lt;span&gt;\\&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;)[-1].split(&lt;span&gt;'&lt;/span&gt;&lt;span&gt;.xml&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;)[0] &lt;span&gt;for&lt;/span&gt; x &lt;span&gt;in&lt;/span&gt;&lt;span&gt; all_label_path]
&lt;/span&gt;&lt;span&gt;2&lt;/span&gt; train_image = [i &lt;span&gt;for&lt;/span&gt; i &lt;span&gt;in&lt;/span&gt; all_image_path &lt;span&gt;if&lt;/span&gt; i.split(&lt;span&gt;'&lt;/span&gt;&lt;span&gt;\\&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;)[-1].split(&lt;span&gt;'&lt;/span&gt;&lt;span&gt;.jpg&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;)[0] &lt;span&gt;in&lt;/span&gt;&lt;span&gt; names]
&lt;/span&gt;&lt;span&gt;3&lt;/span&gt; train_image.sort(key=&lt;span&gt;lambda&lt;/span&gt; x: x.split(&lt;span&gt;'&lt;/span&gt;&lt;span&gt;\\&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;)[-1].split(&lt;span&gt;'&lt;/span&gt;&lt;span&gt;.jpg&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;)[0])
&lt;/span&gt;&lt;span&gt;4&lt;/span&gt; all_label_path.sort(key=&lt;span&gt;lambda&lt;/span&gt; x: x.split(&lt;span&gt;'&lt;/span&gt;&lt;span&gt;\\&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;)[-1].split(&lt;span&gt;'&lt;/span&gt;&lt;span&gt;.xml&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;)[0])
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span&gt;通过排序可以保证label和图片一一对应&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;然后我们将之前爬取并处理数据尺寸的方法写成函数&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;38&quot;&gt;
&lt;pre&gt;
&lt;span&gt; 1&lt;/span&gt; &lt;span&gt;def&lt;/span&gt;&lt;span&gt; to_label(path):
&lt;/span&gt;&lt;span&gt; 2&lt;/span&gt;     xml = open(r&lt;span&gt;'&lt;/span&gt;&lt;span&gt;{}&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;.format(path)).read()
&lt;/span&gt;&lt;span&gt; 3&lt;/span&gt;     sel =&lt;span&gt; etree.HTML(xml)
&lt;/span&gt;&lt;span&gt; 4&lt;/span&gt;     width = int(sel.xpath(&lt;span&gt;'&lt;/span&gt;&lt;span&gt;//size/width/text()&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;)[0])
&lt;/span&gt;&lt;span&gt; 5&lt;/span&gt;     height = int(sel.xpath(&lt;span&gt;'&lt;/span&gt;&lt;span&gt;//size/height/text()&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;)[0])
&lt;/span&gt;&lt;span&gt; 6&lt;/span&gt;     xmin = int(sel.xpath(&lt;span&gt;'&lt;/span&gt;&lt;span&gt;//bndbox/xmin/text()&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;)[0])
&lt;/span&gt;&lt;span&gt; 7&lt;/span&gt;     ymin = int(sel.xpath(&lt;span&gt;'&lt;/span&gt;&lt;span&gt;//bndbox/ymin/text()&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;)[0])
&lt;/span&gt;&lt;span&gt; 8&lt;/span&gt;     xmax = int(sel.xpath(&lt;span&gt;'&lt;/span&gt;&lt;span&gt;//bndbox/xmax/text()&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;)[0])
&lt;/span&gt;&lt;span&gt; 9&lt;/span&gt;     ymax = int(sel.xpath(&lt;span&gt;'&lt;/span&gt;&lt;span&gt;//bndbox/ymax/text()&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;)[0])
&lt;/span&gt;&lt;span&gt;10&lt;/span&gt;     &lt;span&gt;return&lt;/span&gt; [xmin / width, ymin / height, xmax / width, ymax / height]
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span&gt;我们用这个函数来处理数据的标签部分，同时分为四部分，对应了两个顶点的xy坐标，也就是神经网络的四个输出。&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;35&quot;&gt;
&lt;pre&gt;
&lt;span&gt;1&lt;/span&gt; labels = [to_label(p) &lt;span&gt;for&lt;/span&gt; p &lt;span&gt;in&lt;/span&gt;&lt;span&gt; all_label_path]
&lt;/span&gt;&lt;span&gt;2&lt;/span&gt; out1, out2, out3, out4 = list(zip(*labels))
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span&gt;下面进行乱序处理(&lt;strong&gt;&lt;span&gt;这一步非常重要，否则模型训练的效果非常差，我一开始训练的时候拟合效果差就是因为没乱序。。。嘤嘤嘤ε(┬┬﹏┬┬)3&lt;/span&gt;&lt;/strong&gt;）&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;34&quot;&gt;
&lt;pre&gt;
&lt;span&gt;1&lt;/span&gt; index =&lt;span&gt; np.random.permutation(len(train_image))
&lt;/span&gt;&lt;span&gt;2&lt;/span&gt; images =&lt;span&gt; np.array(train_image)[index]
&lt;/span&gt;&lt;span&gt;3&lt;/span&gt; 
&lt;span&gt;4&lt;/span&gt; out1 =&lt;span&gt; np.array(out1)[index]
&lt;/span&gt;&lt;span&gt;5&lt;/span&gt; out2 =&lt;span&gt; np.array(out2)[index]
&lt;/span&gt;&lt;span&gt;6&lt;/span&gt; out3 =&lt;span&gt; np.array(out3)[index]
&lt;/span&gt;&lt;span&gt;7&lt;/span&gt; out4 = np.array(out4)[index]
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span&gt;使用index列表来保证乱序后图片和标签依然一一对应。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;然后将其封装为dataset类型的数据&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;35&quot;&gt;
&lt;pre&gt;
&lt;span&gt;1&lt;/span&gt; label_data = tf.data.Dataset.from_tensor_slices((out1, out2, out3, out4))
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span&gt;下面就是对图片的尺寸变换和封装处理了&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;39&quot;&gt;
&lt;pre&gt;
&lt;span&gt; 1&lt;/span&gt; &lt;span&gt;def&lt;/span&gt;&lt;span&gt; load_image(path):
&lt;/span&gt;&lt;span&gt; 2&lt;/span&gt;     img =&lt;span&gt; tf.io.read_file(path)
&lt;/span&gt;&lt;span&gt; 3&lt;/span&gt;     img = tf.image.decode_jpeg(img, channels = 3&lt;span&gt;)
&lt;/span&gt;&lt;span&gt; 4&lt;/span&gt;     img = tf.image.resize(img, (224, 224&lt;span&gt;))
&lt;/span&gt;&lt;span&gt; 5&lt;/span&gt;     img =&lt;span&gt; tf.cast(img, tf.float32)
&lt;/span&gt;&lt;span&gt; 6&lt;/span&gt;     img = img / 127.5 - 1
&lt;span&gt; 7&lt;/span&gt;     &lt;span&gt;return&lt;/span&gt;&lt;span&gt; img
&lt;/span&gt;&lt;span&gt; 8&lt;/span&gt; 
&lt;span&gt; 9&lt;/span&gt; image_data =&lt;span&gt; tf.data.Dataset.from_tensor_slices(images)
&lt;/span&gt;&lt;span&gt;10&lt;/span&gt; image_data = image_data.map(load_image)
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span&gt;完成后再将image_data和label_data合并成为一个dataset，然后分成训练集和验证集。&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;36&quot;&gt;
&lt;pre&gt;
&lt;span&gt; 1&lt;/span&gt; dataset =&lt;span&gt; tf.data.Dataset.zip((image_data, label_data))
&lt;/span&gt;&lt;span&gt; 2&lt;/span&gt; 
&lt;span&gt; 3&lt;/span&gt; image_count =&lt;span&gt; len(train_image)
&lt;/span&gt;&lt;span&gt; 4&lt;/span&gt; train_count = int(image_count * 0.8&lt;span&gt;)
&lt;/span&gt;&lt;span&gt; 5&lt;/span&gt; test_count = image_count -&lt;span&gt; train_count
&lt;/span&gt;&lt;span&gt; 6&lt;/span&gt; train_dataset =&lt;span&gt; dataset.take(train_count)
&lt;/span&gt;&lt;span&gt; 7&lt;/span&gt; test_dataset =&lt;span&gt; dataset.skip(train_count)
&lt;/span&gt;&lt;span&gt; 8&lt;/span&gt; 
&lt;span&gt; 9&lt;/span&gt; BATCH_SIZE = 8
&lt;span&gt;10&lt;/span&gt; STEPS_PER_EPOCH = train_count //&lt;span&gt; BATCH_SIZE
&lt;/span&gt;&lt;span&gt;11&lt;/span&gt; VALIDATION_STEPS = test_count //&lt;span&gt; BATCH_SIZE
&lt;/span&gt;&lt;span&gt;12&lt;/span&gt; 
&lt;span&gt;13&lt;/span&gt; train_dataset =&lt;span&gt; train_dataset.shuffle(train_count).repeat().batch(BATCH_SIZE)
&lt;/span&gt;&lt;span&gt;14&lt;/span&gt; train_dataset = train_dataset.prefetch(buffer_size=&lt;span&gt;tf.data.experimental.AUTOTUNE)
&lt;/span&gt;&lt;span&gt;15&lt;/span&gt; test_dataset = test_dataset.batch(BATCH_SIZE)
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span&gt;数据集构建完毕，下一步就是模型的构建。&lt;/span&gt;&lt;/p&gt;
&lt;h2&gt;2.模型构建与训练&lt;/h2&gt;
&lt;p&gt;&lt;span&gt;不难发现这次的任务依然需要多输出模型来完成。我们选用预训练的Xception-Net的卷积部分作为卷积基来构建多输出模型。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;迁移学习请参考&lt;a href=&quot;https://www.cnblogs.com/VioletOrz/p/13869628.html&quot; target=&quot;_blank&quot;&gt;&lt;strong&gt;&lt;span&gt;Tensorflow学习笔记No.8&lt;/span&gt;&lt;/strong&gt;&lt;/a&gt;，多输出模型请参考&lt;a href=&quot;https://www.cnblogs.com/VioletOrz/p/14118391.html&quot; target=&quot;_blank&quot;&gt;&lt;strong&gt;&lt;span&gt;Tensorflow学习笔记No.10&lt;/span&gt;&lt;/strong&gt;&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;模型如下：&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;47&quot;&gt;
&lt;pre&gt;
&lt;span&gt; 1&lt;/span&gt; xception = tf.keras.applications.Xception(weights=&lt;span&gt;'&lt;/span&gt;&lt;span&gt;imagenet&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;, 
&lt;/span&gt;&lt;span&gt; 2&lt;/span&gt;                                           include_top=&lt;span&gt;False,
&lt;/span&gt;&lt;span&gt; 3&lt;/span&gt;                                           input_shape=(224, 224, 3&lt;span&gt;))
&lt;/span&gt;&lt;span&gt; 4&lt;/span&gt; 
&lt;span&gt; 5&lt;/span&gt; xception.trianable =&lt;span&gt; False
&lt;/span&gt;&lt;span&gt; 6&lt;/span&gt; 
&lt;span&gt; 7&lt;/span&gt; inputs = tf.keras.layers.Input(shape=(224, 224, 3&lt;span&gt;))
&lt;/span&gt;&lt;span&gt; 8&lt;/span&gt; 
&lt;span&gt; 9&lt;/span&gt; x =&lt;span&gt; xception(inputs)
&lt;/span&gt;&lt;span&gt;10&lt;/span&gt; 
&lt;span&gt;11&lt;/span&gt; x =&lt;span&gt; tf.keras.layers.GlobalAveragePooling2D()(x)
&lt;/span&gt;&lt;span&gt;12&lt;/span&gt; 
&lt;span&gt;13&lt;/span&gt; x = tf.keras.layers.Dense(2048, activation=&lt;span&gt;'&lt;/span&gt;&lt;span&gt;relu&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;)(x)
&lt;/span&gt;&lt;span&gt;14&lt;/span&gt; x = tf.keras.layers.Dense(256, activation=&lt;span&gt;'&lt;/span&gt;&lt;span&gt;relu&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;)(x)
&lt;/span&gt;&lt;span&gt;15&lt;/span&gt; 
&lt;span&gt;16&lt;/span&gt; out1 = tf.keras.layers.Dense(1&lt;span&gt;)(x)
&lt;/span&gt;&lt;span&gt;17&lt;/span&gt; out2 = tf.keras.layers.Dense(1&lt;span&gt;)(x)
&lt;/span&gt;&lt;span&gt;18&lt;/span&gt; out3 = tf.keras.layers.Dense(1&lt;span&gt;)(x)
&lt;/span&gt;&lt;span&gt;19&lt;/span&gt; out4 = tf.keras.layers.Dense(1&lt;span&gt;)(x)
&lt;/span&gt;&lt;span&gt;20&lt;/span&gt; 
&lt;span&gt;21&lt;/span&gt; predictions =&lt;span&gt; [out1, out2, out3, out4]
&lt;/span&gt;&lt;span&gt;22&lt;/span&gt; 
&lt;span&gt;23&lt;/span&gt; model = tf.keras.models.Model(inputs=inputs, outputs=predictions)
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span&gt;由于输出的是坐标，是一个大于0的数字，所以输出层可以直接去掉激活函数。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;随后对模型进行训练，损失函数选择均方误差MSE&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;40&quot;&gt;
&lt;pre&gt;
&lt;span&gt; 1&lt;/span&gt; model.compile(optimizer = tf.keras.optimizers.Adam(lr = 0.0001&lt;span&gt;),
&lt;/span&gt;&lt;span&gt; 2&lt;/span&gt;               loss = &lt;span&gt;'&lt;/span&gt;&lt;span&gt;mse&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;,
&lt;/span&gt;&lt;span&gt; 3&lt;/span&gt;               metrics = [&lt;span&gt;'&lt;/span&gt;&lt;span&gt;mae&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;]
&lt;/span&gt;&lt;span&gt; 4&lt;/span&gt; &lt;span&gt;             )
&lt;/span&gt;&lt;span&gt; 5&lt;/span&gt; 
&lt;span&gt; 6&lt;/span&gt; history =&lt;span&gt; model.fit(train_dataset, 
&lt;/span&gt;&lt;span&gt; 7&lt;/span&gt;                           epochs=10&lt;span&gt;,
&lt;/span&gt;&lt;span&gt; 8&lt;/span&gt;                           steps_per_epoch=&lt;span&gt;STEPS_PER_EPOCH,
&lt;/span&gt;&lt;span&gt; 9&lt;/span&gt;                           validation_steps=&lt;span&gt;VALIDATION_STEPS,
&lt;/span&gt;&lt;span&gt;10&lt;/span&gt;                           validation_data=test_dataset)
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span&gt;训练结果如图所示：&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;42&quot;&gt;
&lt;pre&gt;
&lt;span&gt; 1&lt;/span&gt; loss = history.history[&lt;span&gt;'&lt;/span&gt;&lt;span&gt;loss&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;]
&lt;/span&gt;&lt;span&gt; 2&lt;/span&gt; val_loss = history.history[&lt;span&gt;'&lt;/span&gt;&lt;span&gt;val_loss&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;]
&lt;/span&gt;&lt;span&gt; 3&lt;/span&gt; 
&lt;span&gt; 4&lt;/span&gt; epochs = range(10&lt;span&gt;)
&lt;/span&gt;&lt;span&gt; 5&lt;/span&gt; 
&lt;span&gt; 6&lt;/span&gt; &lt;span&gt;plt.figure()
&lt;/span&gt;&lt;span&gt; 7&lt;/span&gt; plt.plot(epochs, loss, &lt;span&gt;'&lt;/span&gt;&lt;span&gt;r&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;, label=&lt;span&gt;'&lt;/span&gt;&lt;span&gt;Training loss&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;)
&lt;/span&gt;&lt;span&gt; 8&lt;/span&gt; plt.plot(epochs, val_loss, &lt;span&gt;'&lt;/span&gt;&lt;span&gt;bo&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;, label=&lt;span&gt;'&lt;/span&gt;&lt;span&gt;Validation loss&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;)
&lt;/span&gt;&lt;span&gt; 9&lt;/span&gt; plt.title(&lt;span&gt;'&lt;/span&gt;&lt;span&gt;Training and Validation Loss&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;)
&lt;/span&gt;&lt;span&gt;10&lt;/span&gt; plt.xlabel(&lt;span&gt;'&lt;/span&gt;&lt;span&gt;Epoch&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;)
&lt;/span&gt;&lt;span&gt;11&lt;/span&gt; plt.ylabel(&lt;span&gt;'&lt;/span&gt;&lt;span&gt;Loss Value&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;)
&lt;/span&gt;&lt;span&gt;12&lt;/span&gt; plt.ylim([0, 0.15&lt;span&gt;])
&lt;/span&gt;&lt;span&gt;13&lt;/span&gt; &lt;span&gt;plt.legend()
&lt;/span&gt;&lt;span&gt;14&lt;/span&gt; plt.show()
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1924931/202012/1924931-20201212015237217-651200614.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;可以发现loss最初下降的很快然后逐渐减缓，最终的拟合效果也不错。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;然后我们找一组图片试试模型效果。&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;55&quot;&gt;
&lt;pre&gt;
&lt;span&gt; 1&lt;/span&gt; plt.figure(figsize = (8, 8&lt;span&gt;))
&lt;/span&gt;&lt;span&gt; 2&lt;/span&gt; &lt;span&gt;for&lt;/span&gt; img, _ &lt;span&gt;in&lt;/span&gt; test_dataset.skip(1).take(1&lt;span&gt;):
&lt;/span&gt;&lt;span&gt; 3&lt;/span&gt;     out1, out2, out3, out4 =&lt;span&gt; model.predict(img)
&lt;/span&gt;&lt;span&gt; 4&lt;/span&gt;     &lt;span&gt;for&lt;/span&gt; i &lt;span&gt;in&lt;/span&gt; range(0, 6&lt;span&gt;):
&lt;/span&gt;&lt;span&gt; 5&lt;/span&gt;         plt.subplot(2, 3, i + 1&lt;span&gt;)
&lt;/span&gt;&lt;span&gt; 6&lt;/span&gt; &lt;span&gt;        plt.imshow(tf.keras.preprocessing.image.array_to_img(img[i]))
&lt;/span&gt;&lt;span&gt; 7&lt;/span&gt;         xmin, ymin, xmax, ymax = out1[i] * 224, out2[i] * 224, out3[i] * 224, out4[i] * 224&lt;span&gt;,
&lt;/span&gt;&lt;span&gt; 8&lt;/span&gt;         rect = Rectangle((xmin, ymin), (xmax - xmin), (ymax - ymin), fill = False, color = &lt;span&gt;'&lt;/span&gt;&lt;span&gt;red&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;)
&lt;/span&gt;&lt;span&gt; 9&lt;/span&gt;         ax =&lt;span&gt; plt.gca()
&lt;/span&gt;&lt;span&gt;10&lt;/span&gt;         ax.axes.add_patch(rect)
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1924931/202012/1924931-20201212020544024-1500312699.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;效果还不错，嘿嘿ヾ(≧▽≦*)o&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;本次对图像定位的介绍到这里就结束了，Bey~ o(*￣▽￣*)ブ&lt;/span&gt;&lt;/p&gt;

</description>
<pubDate>Fri, 11 Dec 2020 18:04:00 +0000</pubDate>
<dc:creator>VioletOrz</dc:creator>
<og:description>图像定位 图像定位是指在图像中将我们需要识别的部分使用定位框进行定位标记，本次主要讲述如何使用tensorflow2.0实现简单的图像定位任务。 我所使用的定位方法是训练神经网络使它输出定位框的四个顶</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/VioletOrz/p/14123604.html</dc:identifier>
</item>
<item>
<title>TimSort源码详解 - he_jia</title>
<link>http://www.cnblogs.com/hejiayang/p/14119741.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/hejiayang/p/14119741.html</guid>
<description>&lt;p&gt;Python的排序算法由Peter Tim提出，因此称为TimSort。它最先被使用于Python语言，后被多种语言作为默认的排序算法。TimSort实际上可以看作是mergeSort+binarySort，它主要是针对归并排序做了一系列优化。如果想看&lt;span&gt;Python的TimSort源码，在&lt;a href=&quot;https://github.com/python/cpython/blob/master/Python/bltinmodule.c#L2204-L2245&quot; target=&quot;_blank&quot;&gt;Cpython的Github仓库&lt;/a&gt;能找到，这里面还包含一个List对象的&lt;a href=&quot;https://github.com/python/cpython/blob/master/Objects/listobject.c#L2443-L2455&quot; target=&quot;_blank&quot;&gt;PyList_Sort&lt;/a&gt;函数。这篇文章为了方便借用JAVA对TimSort的实现源码来说明其原理。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;一.binarySort函数&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;TimSort非常适合大量数据的排序，对于少量数据的排序，TimSort选择使用binarySort来实现，因此我想先介绍一下binarySort的过程。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;我们知道插入排序的思路是通过交换元素位置的方式依次插入元素(如果不太了解插入排序可以先去熟悉一下)，当要插入元素时，从已排序的部分的最后一位开始，依次比较其与待插入的元素的值，这样来找到待插入元素的位置。显然，在插入排序的过程中，始终是有一个在增长的有序部分和在缩短的无序部分。排序过程见下图(图源自&lt;a class=&quot;follow-nickName&quot; href=&quot;https://blog.csdn.net/qq_33289077&quot; rel=&quot;noopener&quot; target=&quot;_blank&quot;&gt;RainySouL1994&lt;/a&gt;的&lt;a href=&quot;https://blog.csdn.net/qq_33289077/article/details/90370899&quot; target=&quot;_blank&quot;&gt;博客&lt;/a&gt;)：&lt;/p&gt;
&lt;p&gt; &lt;img src=&quot;https://img2020.cnblogs.com/blog/2110822/202012/2110822-20201211170532773-461230604.png&quot; alt=&quot;&quot; width=&quot;482&quot; height=&quot;438&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt; 但是插入排序有个很明显的问题，在找当前元素的位置时它是一步一步地在有序部分往前推进的，而有序列表的插入可以通过二分法来减少比较次数，这和二分查找的目的不同但是思路相同(可以自己尝试一下&lt;a href=&quot;https://leetcode-cn.com/problems/search-insert-position/&quot; target=&quot;_blank&quot;&gt;实现它&lt;/a&gt;)，我们称其为二分插入，通过二分插入实现的排序就是二分排序(binarySort)。我们可以看一下它的Java源码：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;47&quot;&gt;
&lt;pre&gt;
&lt;span&gt;//&lt;/span&gt;&lt;span&gt;a是数组,lo是待排序部分(有序部分+无序部分)的最低位(包含)，hi是最高位(不包含),start是无序部分的最低位,c是比较函数即排序的依据&lt;/span&gt;
&lt;span&gt;private&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; &amp;lt;T&amp;gt; &lt;span&gt;void&lt;/span&gt; binarySort(T[] a, &lt;span&gt;int&lt;/span&gt; lo, &lt;span&gt;int&lt;/span&gt; hi, &lt;span&gt;int&lt;/span&gt;&lt;span&gt; start, Comparator&lt;/span&gt;&amp;lt;? &lt;span&gt;super&lt;/span&gt; T&amp;gt;&lt;span&gt; c) {
    &lt;/span&gt;&lt;span&gt;assert&lt;/span&gt; lo &amp;lt;= start &amp;amp;&amp;amp; start &amp;lt;=&lt;span&gt; hi;
    &lt;/span&gt;&lt;span&gt;if&lt;/span&gt; (start ==&lt;span&gt; lo)
        start&lt;/span&gt;++&lt;span&gt;;
    &lt;/span&gt;&lt;span&gt;for&lt;/span&gt; ( ; start &amp;lt; hi; start++) {&lt;span&gt;//&lt;/span&gt;&lt;span&gt;接下来就是二分插入的过程&lt;/span&gt;
        T pivot =&lt;span&gt; a[start];
        &lt;/span&gt;&lt;span&gt;int&lt;/span&gt; left =&lt;span&gt; lo;
        &lt;/span&gt;&lt;span&gt;int&lt;/span&gt; right =&lt;span&gt; start;
        &lt;/span&gt;&lt;span&gt;assert&lt;/span&gt; left &amp;lt;=&lt;span&gt; right;
        &lt;/span&gt;&lt;span&gt;while&lt;/span&gt; (left &amp;lt;&lt;span&gt; right) {
            &lt;/span&gt;&lt;span&gt;int&lt;/span&gt; mid = (left + right) &amp;gt;&amp;gt;&amp;gt; 1&lt;span&gt;;
            &lt;/span&gt;&lt;span&gt;if&lt;/span&gt; (c.compare(pivot, a[mid]) &amp;lt; 0&lt;span&gt;)
                right &lt;/span&gt;=&lt;span&gt; mid;
            &lt;/span&gt;&lt;span&gt;else&lt;/span&gt;&lt;span&gt;
                left &lt;/span&gt;= mid + 1&lt;span&gt;;
        }
        &lt;/span&gt;&lt;span&gt;assert&lt;/span&gt; left ==&lt;span&gt; right;
        &lt;/span&gt;&lt;span&gt;int&lt;/span&gt; n = start - left;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;n表示要移动的元素数量
        &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;优化插入过程，当要移动的元素数量为1或2时，可以直接交换元素位置；
        &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;否则将left后的元素往后挪一位再插入，方式是通过arraycopy函数复制&lt;/span&gt;
        &lt;span&gt;switch&lt;/span&gt;&lt;span&gt; (n) {
            &lt;/span&gt;&lt;span&gt;case&lt;/span&gt; 2:  a[left + 2] = a[left + 1&lt;span&gt;];
            &lt;/span&gt;&lt;span&gt;case&lt;/span&gt; 1:  a[left + 1] =&lt;span&gt; a[left];
                &lt;/span&gt;&lt;span&gt;break&lt;/span&gt;&lt;span&gt;;
            &lt;/span&gt;&lt;span&gt;default&lt;/span&gt;: System.arraycopy(a, left, a, left + 1&lt;span&gt;, n);
        }
        a[left] &lt;/span&gt;=&lt;span&gt; pivot;
    }
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;&lt;span&gt;二.run&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;这是TimSort中最重要的一个概念，实在找不到合适的翻译(无奈脸)。&lt;code&gt;run实际上&lt;/code&gt;就是一个连续上升（包含相等）或者下降（不包含相等）的子串。比如对于数组&lt;code&gt;[1,3,2,4,6,4,7,7,3,2]&lt;/code&gt;，其中有四个&lt;code&gt;run&lt;/code&gt;，第一个是&lt;code&gt;[1,3]&lt;/code&gt;，第二个是&lt;code&gt;[2,4,6]&lt;/code&gt;，第三个是&lt;code&gt;[4,7,7]&lt;/code&gt;，第四个是&lt;code&gt;[3,2]，&lt;/code&gt;在函数中对于单调递减的&lt;code&gt;run&lt;/code&gt;会被反转成递增的序列。源码中通过countRunAndMakeAscending()函数来得到run：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;43&quot;&gt;
&lt;pre&gt;
&lt;span&gt;private&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; &amp;lt;T&amp;gt; &lt;span&gt;int&lt;/span&gt; countRunAndMakeAscending(T[] a, &lt;span&gt;int&lt;/span&gt; lo, &lt;span&gt;int&lt;/span&gt;&lt;span&gt; hi, Comparator&lt;/span&gt;&amp;lt;? &lt;span&gt;super&lt;/span&gt; T&amp;gt;&lt;span&gt; c) {
    &lt;/span&gt;&lt;span&gt;assert&lt;/span&gt; lo &amp;lt;&lt;span&gt; hi;
    &lt;/span&gt;&lt;span&gt;int&lt;/span&gt; runHi = lo + 1&lt;span&gt;;
    &lt;/span&gt;&lt;span&gt;if&lt;/span&gt; (runHi ==&lt;span&gt; hi)
        &lt;/span&gt;&lt;span&gt;return&lt;/span&gt; 1&lt;span&gt;;

    &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;找到run的结束位置，如果是下降的序列将其反转&lt;/span&gt;
    &lt;span&gt;if&lt;/span&gt; (c.compare(a[runHi++], a[lo]) &amp;lt; 0&lt;span&gt;) {
        &lt;/span&gt;&lt;span&gt;while&lt;/span&gt; (runHi &amp;lt; hi &amp;amp;&amp;amp; c.compare(a[runHi], a[runHi - 1]) &amp;lt; 0&lt;span&gt;)
            runHi&lt;/span&gt;++&lt;span&gt;;
        reverseRange(a, lo, runHi);
    } &lt;/span&gt;&lt;span&gt;else&lt;/span&gt;&lt;span&gt; {
        &lt;/span&gt;&lt;span&gt;while&lt;/span&gt; (runHi &amp;lt; hi &amp;amp;&amp;amp; c.compare(a[runHi], a[runHi - 1]) &amp;gt;= 0&lt;span&gt;)
            runHi&lt;/span&gt;++&lt;span&gt;;
    }

    &lt;/span&gt;&lt;span&gt;return&lt;/span&gt; runHi -&lt;span&gt; lo;//&lt;span&gt;返回值为run的长度&lt;/span&gt;
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt; &lt;strong&gt;&lt;span&gt;三.TimSort排序过程&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;直接上源码分析，可以参考代码注释和下面的解释来阅读：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;61&quot;&gt;
&lt;pre&gt;
&lt;span&gt;static&lt;/span&gt; &amp;lt;T&amp;gt; &lt;span&gt;void&lt;/span&gt; sort(T[] a, &lt;span&gt;int&lt;/span&gt; lo, &lt;span&gt;int&lt;/span&gt; hi, Comparator&amp;lt;? &lt;span&gt;super&lt;/span&gt; T&amp;gt;&lt;span&gt; c, T[] work, &lt;/span&gt;&lt;span&gt;int&lt;/span&gt; workBase, &lt;span&gt;int&lt;/span&gt;&lt;span&gt; workLen) {
    &lt;/span&gt;&lt;span&gt;assert&lt;/span&gt; c != &lt;span&gt;null&lt;/span&gt; &amp;amp;&amp;amp; a != &lt;span&gt;null&lt;/span&gt; &amp;amp;&amp;amp; lo &amp;gt;= 0 &amp;amp;&amp;amp; lo &amp;lt;= hi &amp;amp;&amp;amp; hi &amp;lt;=&lt;span&gt; a.length;

    &lt;/span&gt;&lt;span&gt;int&lt;/span&gt; nRemaining  = hi - lo;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;待排序的数组长度&lt;/span&gt;
    &lt;span&gt;if&lt;/span&gt; (nRemaining &amp;lt; 2&lt;span&gt;)
        &lt;/span&gt;&lt;span&gt;return&lt;/span&gt;;  &lt;span&gt;//&lt;/span&gt;&lt;span&gt;长度为0或1的数组无需排序

    &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; 如果数组长度小于32(即MIN_MERGE，TimSort的Python版本里这个值为64)，直接用binarySort排序&lt;/span&gt;
    &lt;span&gt;if&lt;/span&gt; (nRemaining &amp;lt;&lt;span&gt; MIN_MERGE) {
        &lt;/span&gt;&lt;span&gt;int&lt;/span&gt; initRunLen = countRunAndMakeAscending(a, lo, hi, c);&lt;span&gt;//&lt;/span&gt;&lt;span&gt;找到第一个run，返回其长度&lt;/span&gt;
        binarySort(a, lo, hi, lo + initRunLen, c);&lt;span&gt;//&lt;/span&gt;&lt;span&gt;第一个run已排好序，因此binarySort的参数start=lo+initRunLen&lt;/span&gt;
        &lt;span&gt;return&lt;/span&gt;&lt;span&gt;;
    }
&lt;/span&gt;&lt;span&gt;
    TimSort&lt;/span&gt;&amp;lt;T&amp;gt; ts = &lt;span&gt;new&lt;/span&gt; TimSort&amp;lt;&amp;gt;&lt;span&gt;(a, c, work, workBase, workLen);
    &lt;/span&gt;&lt;span&gt;int&lt;/span&gt; minRun = minRunLength(nRemaining);&lt;span&gt;//&lt;/span&gt;&lt;span&gt;最小run长度，见解释A&lt;/span&gt;
    &lt;span&gt;do&lt;/span&gt;&lt;span&gt; {
        &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; 找run&lt;/span&gt;
        &lt;span&gt;int&lt;/span&gt; runLen =&lt;span&gt; countRunAndMakeAscending(a, lo, hi, c);

        &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; 如果run长度小于minRun，将其扩展为min(nRemaining,minRun)&lt;/span&gt;
        &lt;span&gt;if&lt;/span&gt; (runLen &amp;lt;&lt;span&gt; minRun) {
            &lt;/span&gt;&lt;span&gt;int&lt;/span&gt; force = nRemaining &amp;lt;= minRun ?&lt;span&gt; nRemaining : minRun;
            binarySort(a, lo, lo &lt;/span&gt;+ force, lo + runLen, c);&lt;span&gt;//&lt;/span&gt;&lt;span&gt;扩展run到长度force&lt;/span&gt;
            runLen =&lt;span&gt; force;
        }

        ts.pushRun(lo, runLen);&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; 将run保存到栈中，见解释B&lt;/span&gt;
        ts.mergeCollapse();&lt;span&gt;//&lt;/span&gt;&lt;span&gt; 根据规则合并相邻的run，见解释C

        &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; 继续寻找run&lt;/span&gt;
        lo +=&lt;span&gt; runLen;
        nRemaining &lt;/span&gt;-=&lt;span&gt; runLen;
    } &lt;/span&gt;&lt;span&gt;while&lt;/span&gt; (nRemaining != 0&lt;span&gt;);

    &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; Merge all remaining runs to complete sort&lt;/span&gt;
    &lt;span&gt;assert&lt;/span&gt; lo ==&lt;span&gt; hi;
    ts.mergeForceCollapse();&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;最后收尾，将栈中所有run从栈顶开始依次邻近合并，得到一个run&lt;/span&gt;
    &lt;span&gt;assert&lt;/span&gt; ts.stackSize == 1&lt;span&gt;;
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;解释A：&lt;/strong&gt;在执行排序算法之前，会计算&lt;code&gt;minRun&lt;/code&gt;的值，&lt;code&gt;minRun&lt;/code&gt;会从[16,32]区间中选择一个数字，使得数组的长度除以&lt;code&gt;minRun&lt;/code&gt;等于或者略小于&lt;code&gt;2&lt;/code&gt;的幂次方。比如长度是&lt;code&gt;65&lt;/code&gt;，那么&lt;code&gt;minrun&lt;/code&gt;的值就是&lt;code&gt;17&lt;/code&gt;；如果长度是&lt;code&gt;174&lt;/code&gt;，&lt;code&gt;minrun&lt;/code&gt;就是22。minRunLength()函数代码如下：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;33&quot;&gt;
&lt;pre&gt;
&lt;span&gt;private&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; &lt;span&gt;int&lt;/span&gt; minRunLength(&lt;span&gt;int&lt;/span&gt;&lt;span&gt; n) {
    &lt;/span&gt;&lt;span&gt;assert&lt;/span&gt; n &amp;gt;= 0&lt;span&gt;;
    &lt;/span&gt;&lt;span&gt;int&lt;/span&gt; r = 0;      &lt;span&gt;//&lt;/span&gt;&lt;span&gt; 如果n的低位有任何一位为1，r就会置1&lt;/span&gt;
    &lt;span&gt;while&lt;/span&gt; (n &amp;gt;= 32&lt;span&gt;) {
        r &lt;/span&gt;|= (n &amp;amp; 1&lt;span&gt;);
        n &lt;/span&gt;&amp;gt;&amp;gt;= 1&lt;span&gt;;
    }
    &lt;/span&gt;&lt;span&gt;return&lt;/span&gt; n +&lt;span&gt; r;
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;解释B：&lt;/strong&gt;存run是通过两个栈，分别保存run的起始位置和长度，可以看pushRun()函数代码：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;35&quot;&gt;
&lt;pre&gt;
&lt;span&gt;private&lt;/span&gt; &lt;span&gt;int&lt;/span&gt; stackSize = 0;  &lt;span&gt;//&lt;/span&gt;&lt;span&gt; 栈中run的数量&lt;/span&gt;
&lt;span&gt;private&lt;/span&gt; &lt;span&gt;final&lt;/span&gt; &lt;span&gt;int&lt;/span&gt;&lt;span&gt;[] runBase;
&lt;/span&gt;&lt;span&gt;private&lt;/span&gt; &lt;span&gt;final&lt;/span&gt; &lt;span&gt;int&lt;/span&gt;&lt;span&gt;[] runLen;

&lt;/span&gt;&lt;span&gt;private&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; pushRun(&lt;span&gt;int&lt;/span&gt; runBase, &lt;span&gt;int&lt;/span&gt;&lt;span&gt; runLen) {
     &lt;/span&gt;&lt;span&gt;this&lt;/span&gt;.runBase[stackSize] =&lt;span&gt; runBase;
     &lt;/span&gt;&lt;span&gt;this&lt;/span&gt;.runLen[stackSize] =&lt;span&gt; runLen;
     stackSize&lt;/span&gt;++&lt;span&gt;;
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;解释C：&lt;/strong&gt;这里的合并规则如下：假设栈顶三个run依次为X，Y，Z，X为栈顶run，要求它们的长度满足X+Y&amp;lt;Z及X&amp;lt;Y两个条件。其实这就是TimSort算法的精髓所在了，它通过这样的方式尽力保证合并的平衡性，即让待合并的两个数组尽可能长度接近，从而提高合并的效率。通过这两个条件限制，保证了栈中的run从栈底到栈顶是从大到小排列的，并且合并的收敛速度与斐波那契数列一样。可以看mergeCollapse()函数代码：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;35&quot;&gt;
&lt;pre&gt;
&lt;span&gt;private&lt;/span&gt; &lt;span&gt;void&lt;/span&gt;&lt;span&gt; mergeCollapse() {
    &lt;/span&gt;&lt;span&gt;while&lt;/span&gt; (stackSize &amp;gt; 1&lt;span&gt;) {
        &lt;/span&gt;&lt;span&gt;int&lt;/span&gt; n = stackSize - 2&lt;span&gt;;
        &lt;/span&gt;&lt;span&gt;if&lt;/span&gt; (n &amp;gt; 0 &amp;amp;&amp;amp; runLen[n-1] &amp;lt;= runLen[n] + runLen[n+1]) {&lt;span&gt;//&lt;/span&gt;&lt;span&gt;条件一不满足的话，Y就会和X、Z中较小的run合并&lt;/span&gt;
            &lt;span&gt;if&lt;/span&gt; (runLen[n - 1] &amp;lt; runLen[n + 1&lt;span&gt;])
                n&lt;/span&gt;--&lt;span&gt;;
            mergeAt(n);
        } &lt;/span&gt;&lt;span&gt;else&lt;/span&gt; &lt;span&gt;if&lt;/span&gt; (runLen[n] &amp;lt;= runLen[n + 1]) {&lt;span&gt;//&lt;/span&gt;&lt;span&gt;条件二不满足的话，Y就和X合并&lt;/span&gt;
&lt;span&gt;            mergeAt(n);
        } &lt;/span&gt;&lt;span&gt;else&lt;/span&gt;&lt;span&gt; {
            &lt;/span&gt;&lt;span&gt;break&lt;/span&gt;; &lt;span&gt;//&lt;/span&gt;&lt;span&gt; Invariant is established&lt;/span&gt;
&lt;span&gt;        }
    }
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;&lt;span&gt;四.合并的方式&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;到这里我们就把整个流程讲完了，还有最后一个问题没有讲--如何合并run？合并两个run需要额外空间(可以不用，但是效率太低)，额外空间大小我们可以设为较小的run的长度。假设我们有前后X、Y两个run需要合并，X较小，那么X可以放入临时内存中，然后从小到大合并；如果Y较小，那么把Y放入临时内存，然后从大到小排序。这个流程其实也比较简单(图源自&lt;a href=&quot;https://home.cnblogs.com/u/sunshuyi/&quot; target=&quot;_blank&quot;&gt;佛西先森&lt;/a&gt;的&lt;a href=&quot;https://www.cnblogs.com/sunshuyi/p/12680918.html&quot; target=&quot;_blank&quot;&gt;博客&lt;/a&gt;)：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/2110822/202012/2110822-20201211220318476-1254216589.png&quot; alt=&quot;&quot; width=&quot;535&quot; height=&quot;301&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;


&lt;p&gt; 并且，由于两个run都是已经排好序的序列，我们可以在run合并之前计算A中最后一个元素在B中的位置i，那么B中i之后的元素都不需要参与合并；同理，我们也可以计算B中第一个元素在A中位置j，A中j之前的元素都不需要参与合并。&lt;/p&gt;
&lt;p&gt;在归并排序算法中合并两个数组就是一一比较每个元素，把较小的放到相应的位置，然后比较下一个，这样有一个缺点就是如果&lt;code&gt;A&lt;/code&gt;中如果有大量的元素&lt;code&gt;A[i...j]&lt;/code&gt;是小于&lt;code&gt;B&lt;/code&gt;中某一个元素&lt;code&gt;B[k]&lt;/code&gt;的，程序仍然会持续的比较&lt;code&gt;A[i...j]&lt;/code&gt;中的每一个元素和&lt;code&gt;B[k]&lt;/code&gt;，增加合并过程中的时间消耗。&lt;/p&gt;
&lt;p&gt;为了优化合并的过程，TimSort设定了一个阈值&lt;code&gt;MIN_GALLOP&lt;/code&gt;，如果&lt;code&gt;A&lt;/code&gt;中连续&lt;code&gt;MIN_GALLOP&lt;/code&gt;个元素比&lt;code&gt;B&lt;/code&gt;中某一个元素要小，则通过二分搜索找到&lt;code&gt;A[0]&lt;/code&gt;在&lt;code&gt;B&lt;/code&gt;中的位置&lt;code&gt;i0&lt;/code&gt;，把&lt;code&gt;B&lt;/code&gt;中&lt;code&gt;i0&lt;/code&gt;之前的元素直接放入合并的空间中，然后再在&lt;code&gt;A&lt;/code&gt;中找到&lt;code&gt;B[i0]&lt;/code&gt;所在的位置&lt;code&gt;j0&lt;/code&gt;，把&lt;code&gt;A&lt;/code&gt;中&lt;code&gt;j0&lt;/code&gt;之前的元素直接放入合并空间中，如此循环直至在&lt;code&gt;A&lt;/code&gt;和&lt;code&gt;B&lt;/code&gt;中每次找到的新的位置和原位置的差值是小于&lt;code&gt;MIN_GALLOP&lt;/code&gt;的，这才停止然后继续进行一对一的比较。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;span&gt;五.总结&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;总结一下上面的排序的过程：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;如果长度小于32直接进行二分插入排序&lt;/li&gt;
&lt;li&gt;遍历数组组成一个&lt;code&gt;run&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;得到一个&lt;code&gt;run&lt;/code&gt;之后会把他放入栈中&lt;/li&gt;
&lt;li&gt;如果栈顶部几个的&lt;code&gt;run&lt;/code&gt;符合合并条件，就会合并相邻的两个&lt;code&gt;run&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;合并会使用尽量小的内存空间和GALLOP模式来加速合并&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;参考资料：1.&lt;span&gt;&lt;a id=&quot;cb_post_title_url&quot; class=&quot;postTitle2 vertical-middle&quot; href=&quot;https://www.cnblogs.com/sunshuyi/p/12680918.html&quot;&gt;世界上最快的排序算法——Timsort&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　　　　 2.JDK8官方源码&lt;/span&gt;&lt;/p&gt;
</description>
<pubDate>Fri, 11 Dec 2020 15:37:00 +0000</pubDate>
<dc:creator>he_jia</dc:creator>
<og:description>Python的排序算法由Peter Tim提出，因此称为TimSort。它最先被使用于Python语言，后被多种语言作为默认的排序算法。TimSort实际上可以看作是mergeSort+binaryS</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/hejiayang/p/14119741.html</dc:identifier>
</item>
<item>
<title>傲视Kubernetes(二)：Docker镜像搭建与本地Kubernetes环境搭建 - 淡墨痕</title>
<link>http://www.cnblogs.com/zzq6032010/p/14099984.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/zzq6032010/p/14099984.html</guid>
<description>&lt;p&gt;&lt;span&gt;&lt;strong&gt;主要内容：&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;1、Docker与Kubernetes的关系&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2、SpringBoot微服务的Docker镜像创建&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;3、Kubernetes本地环境搭建&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;一、Docker与Kubernetes的关系&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;在说明Docker与Kubernetes的关系之前，要先同步一下Docker定义--Docker是什么？Docker是一个打包、分发和运行应用程序的平台。&lt;strong&gt;&lt;span&gt;它是一种容器化技术&lt;/span&gt;&lt;/strong&gt;，可以使它创建的容器运行在不同的机器、不同的操作系统上（此处可以类比Java的跨平台特性）。不过docker是依赖于linux内核的，所以如果在windows系统上运行，实际是运行于windows上的虚拟linux环境中。&lt;/p&gt;
&lt;p&gt;一个Docker运行时容器就是一个进程。Docker与虚拟机的区别，很大一点在于容器没有自己的操作系统内核，它依赖于宿主机的操作系统，更轻量级；而虚拟机有自己的操作系统内核，相对更自由，但更重量级。&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;二、SpringBoot微服务的Docker镜像搭建&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;由于SpringBoot自带tomcat，所以找一个JDK镜像就够了。此处博主用的基础镜像是 williamyeh/java8:latest。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;1、简易项目构建：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1558028/202012/1558028-20201207215144017-390348101.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;

&lt;p&gt; bootstrap.yml文件内容（指定服务端口）：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot;&gt;
&lt;pre&gt;
&lt;span&gt;1&lt;/span&gt; &lt;span&gt;server:
&lt;/span&gt;&lt;span&gt;2&lt;/span&gt;   port: 8001
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Dockerfile文件内容（在pom中指定了打包文件名jugg）：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;36&quot;&gt;
&lt;pre&gt;
&lt;span&gt;1&lt;/span&gt; FROM williamyeh/&lt;span&gt;java8:latest
&lt;/span&gt;&lt;span&gt;2&lt;/span&gt; EXPOSE 8001
&lt;span&gt;3&lt;/span&gt; 
&lt;span&gt;4&lt;/span&gt; ADD jugg.jar /&lt;span&gt;jugg.jar
&lt;/span&gt;&lt;span&gt;5&lt;/span&gt; ENTRYPOINT [&quot;java&quot;,&quot;-jar&quot;,&quot;/jugg.jar&quot;,&quot;--server.port=8001&quot;]
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;2、构建镜像&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;先将jar包和Dockerfile文件上传到服务器的同一个目录上去：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1558028/202012/1558028-20201207215731513-2098088462.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;

&lt;p&gt;然后执行指令创建镜像（镜像名jugg）：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot;&gt;
&lt;pre&gt;
&lt;span&gt;1&lt;/span&gt; docker build -t jugg .
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt; &lt;img src=&quot;https://img2020.cnblogs.com/blog/1558028/202012/1558028-20201207220131592-1409489136.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt; 成功后执行下 docker images，可以看到我们刚创建的镜像：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1558028/202012/1558028-20201207220213377-332347478.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt; 再执行run让镜像运行起来 &lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;32&quot;&gt;
&lt;pre&gt;
&lt;span&gt;1&lt;/span&gt; docker run --name juggcontainer -p 8001:8001 -d jugg
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;name后面是指定容器名，-p后面指定端口。注意Dockerfile文件中EXPOSE暴露的端口并没有实际效果，执行run命令时指定的端口才是最终使用的端口。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1558028/202012/1558028-20201208223106963-1883150639.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;

&lt;p&gt; 浏览器访问下服务，完美！(注意检查服务器的端口是否能被访问到)&lt;/p&gt;
&lt;p&gt; &lt;img src=&quot;https://img2020.cnblogs.com/blog/1558028/202012/1558028-20201208222742857-1902374267.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;三、Kubernetes本地环境搭建&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;1、minikube的安装与启动&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt; Kubernetes本地环境搭建一般都是用minikube，这玩意的版本和环境关系很大，稍不注意安装的时候就会有各种意外。minikube安装时有两种下载地址，一个是国内阿里云的，一个是国外谷歌的地址。阿里的好处就是网络稳定，基本都会下载成功。而用谷歌的地址，很不稳定。但是呢，博主用阿里云的下载启动时，遇到了各种各样的问题（&lt;strong&gt;博主的云主机是单核CPU，有的报错就跟此相关，如果是双核CPU，估计安装与启动会顺利得多&lt;/strong&gt;），一怒之下又改用谷歌的minikube地址，虽然网络波动较大，但多试了几次，最后顺利启动成功。&lt;/p&gt;
&lt;p&gt;首先执行命令下载minikube（若无下载进度，则ctrl+C终止后重新执行命令，反复几次，总会有成功的时候）：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;33&quot;&gt;
&lt;pre&gt;
&lt;span&gt;1&lt;/span&gt; curl -Lo minikube https:&lt;span&gt;//&lt;/span&gt;&lt;span&gt;storage.googleapis.com/minikube/releases/v0.23.0/minikube-linux-amd64 &amp;amp;&amp;amp; chmod +x minikube &amp;amp;&amp;amp; sudo mv minikube /usr/local/bin&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;然后执行启动指令，如下。博主的云主机上未安装虚拟驱动，所以直接指定为none，但还得指定下cpu核数以及忽略掉核数不匹配的错误，否则会终止启动流程：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;32&quot;&gt;
&lt;pre&gt;
&lt;span&gt;1&lt;/span&gt; minikube start  --vm-driver=none --extra-config=kubeadm.ignore-preflight-errors=NumCPU --cpus 1
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;博主前两次执行都报错获取不到版本：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1558028/202012/1558028-20201211225919821-1800660157.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;

&lt;p&gt; 直到执行第三次才成功启动：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1558028/202012/1558028-20201211230029713-1339848771.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;

&lt;p&gt;注意每次因为版本问题导致start失败之后，最好清空一下minikube的记录，重新下载，清空minikube记录的指令：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;32&quot;&gt;
&lt;pre&gt;
minikube delete &amp;amp;&amp;amp; rm -rf ~/.minikube &amp;amp;&amp;amp; rm -rf ~/.kube
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;2、kubectl的安装&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;kubectl是kubenetes的客户端，有了它我们才能通过命令行与kubernetes集群进行交互。这个的安装就简单多了，执行指令：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;33&quot;&gt;
&lt;pre&gt;
curl -LO https:&lt;span&gt;//&lt;/span&gt;&lt;span&gt;storage.googleapis.com/kubenetes-releases/release/v1.19.4/bin/linux/amd64/kubectl &amp;amp;&amp;amp; chmod +x kubectl &amp;amp;&amp;amp; sudo mv kubectl /usr/local/bin/&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;如果多执行几次也下载不下来，你又没啥办法的话，可以点击这个链接下载：&lt;a href=&quot;https://www.cnblogs.com/wangjq19920210/p/11445818.html&quot;&gt;【&lt;/a&gt;&lt;a href=&quot;https://link.jianshu.com/?t=https%3A%2F%2Fstorage.googleapis.com%2Fkubernetes-release%2Frelease%2Fv1.10.0%2Fbin%2Flinux%2Famd64%2Fkubectl&quot; rel=&quot;nofollow&quot; target=&quot;_blank&quot;&gt;https://storage.googleapis.com/kubernetes-release/release/v1.10.0/bin/linux/amd64/kubectl&lt;/a&gt;】&lt;/p&gt;
&lt;p&gt;下载下来之后手动往usr/local/bin目录传上去，再执行上面指令中的  chmod +x kubectl 命令即可。&lt;/p&gt;
&lt;p&gt;安装好之后，打个kubectl指令检验一下效果：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1558028/202012/1558028-20201211231211012-401301020.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;

&lt;p&gt; 完美！&lt;/p&gt;

&lt;p&gt;参考文献：&lt;/p&gt;
&lt;p&gt;1、《Kubernetes in Action》  ...Marko Luksa&lt;/p&gt;
&lt;p&gt;2、Kubenetes官网，minikube官网&lt;/p&gt;
</description>
<pubDate>Fri, 11 Dec 2020 15:22:00 +0000</pubDate>
<dc:creator>淡墨痕</dc:creator>
<og:description>主要内容： 1、Docker与Kubernetes的关系 2、SpringBoot微服务的Docker镜像创建 3、Kubernetes本地环境搭建 一、Docker与Kubernetes的关系 在说</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/zzq6032010/p/14099984.html</dc:identifier>
</item>
<item>
<title>实践01：实现一个在线身份证号生成器（仅做测试数据用途） - zy7y</title>
<link>http://www.cnblogs.com/zy7y/p/14123327.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/zy7y/p/14123327.html</guid>
<description>[unable to retrieve full-text content]前言 很久没更新博客了，django也是断更了，minium小程序自动化也鸽了，哈哈，今天给大家带来个生成假身份证号码的工具（基于faker库） 在线身份证号码生成器 在测试过程中，很多地方需要使用到身份证号码，不知道各位测试人都是怎么处理的，我之前都是使用的；http://sfz.uzuzuz.c</description>
<pubDate>Fri, 11 Dec 2020 15:09:00 +0000</pubDate>
<dc:creator>zy7y</dc:creator>
<og:description>主要内容： 1、Docker与Kubernetes的关系 2、SpringBoot微服务的Docker镜像创建 3、Kubernetes本地环境搭建 一、Docker与Kubernetes的关系 在说</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/zzq6032010/p/14099984.html</dc:identifier>
</item>
<item>
<title>我的第一次shell - 晨曦001</title>
<link>http://www.cnblogs.com/chenxi001/p/14123300.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/chenxi001/p/14123300.html</guid>
<description>&lt;h2 id=&quot;我的第一次shell&quot;&gt;我的第一次shell&lt;/h2&gt;
&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;最近我们的项目需要进行优化，整体架构进行改造。&lt;br/&gt;然后我们红超哥就看我骨骼惊奇，说小伙子你想不想当做掌门人呀。（我说不想哈哈）&lt;br/&gt;想不想也没用了，红超哥说我们现在的架构有所改变，需要你写一套自动部署脚本。（弱小的我没有说出一个不字）&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&quot;shell可以干啥&quot;&gt;Shell可以干啥&lt;/h3&gt;
&lt;ul&gt;&lt;li&gt;如果小伙伴们使用过Linux操作系统那肯定使用过shell命令，&lt;strong&gt;cd&lt;/strong&gt; 、 &lt;strong&gt;ls&lt;/strong&gt; 再或者你们一定看过 &lt;strong&gt;rm -rf xxxx&lt;/strong&gt; 哈哈，这些其实都是我们的shell命令，我们将程序部署到系统上面去的时候每次都需要输入一推命令，如果一天部署一个程序你还受得了，但是如果红超哥一定要我部署50个程序。&lt;strong&gt;那当然我也不会说一个不字&lt;/strong&gt; ，但是我们经常会出现多打一个字母，少打一个字母的情况，当前一个两个项目的工作量我还能接受，但是红超哥说的50个程序部署，那我也能完成。但是为了早点下班，多摸鱼。所以我们还是要弄自动化。&lt;/li&gt;
&lt;/ul&gt;&lt;h3 id=&quot;shell是个啥&quot;&gt;&lt;a href=&quot;https://www.runoob.com/linux/linux-shell.html&quot; target=&quot;_blank&quot;&gt;Shell是个啥&lt;/a&gt;&lt;/h3&gt;
&lt;ul&gt;&lt;li&gt;Shell 是一个用 C 语言编写的程序，它是用户使用 Linux 的桥梁。Shell 既是一种命令语言，又是一种程序设计语言。Shell 是指一种应用程序，这个应用程序提供了一个界面，用户通过这个界面访问操作系统内核的服务。Ken Thompson 的 sh 是第一种 Unix Shell，Windows Explorer 是一个典型的图形界面 Shell。&lt;/li&gt;
&lt;li&gt;不管他三七二二的先把菜鸟教程文档看一遍，你就已经是菜鸟了。然后就是编写脚本测试脚本。一步一步进化成为大鹏叉烧&lt;img src=&quot;https://img2020.cnblogs.com/blog/1808958/202012/1808958-20201211225941290-1228085039.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;h3 id=&quot;开搞之前&quot;&gt;开搞之前&lt;/h3&gt;
&lt;ul&gt;&lt;li&gt;所以我先将菜鸟教程文档都看了一遍，然后在园子看了其他大佬写的shell博文，先吸收一点经验，减少一些没必要的弯路（而且最近红超哥也挺忙的，哈哈，不过虽然问红超哥虽好，但是程序人生中该踩的坑，还是要踩） &lt;a href=&quot;https://www.cnblogs.com/hzxyf/p/13896893.html#4721453&quot; target=&quot;_blank&quot;&gt;推荐博文&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;h3 id=&quot;搞搞&quot;&gt;搞搞&lt;/h3&gt;
&lt;ul readability=&quot;8.5&quot;&gt;&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;因为写自己写的代码肯定需要给别人看的，所以我们需要先定义这个脚本是干嘛的。（#!/bin/bash告诉系统使用shell那种核心执行脚本）&lt;br/&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1808958/202012/1808958-20201211225951249-2135359130.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;日志信息一定要有。这个很重要，因为我们不像红超哥一样写代码一次过，所以我们还是需要使用日志记录我们的信息。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;也可以更好的返回提示给执行脚本的人看到脚本执行情况。&lt;br/&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1808958/202012/1808958-20201211230013431-174009030.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;在我编写的过程中会发现很多方法都是一样的，作为码农练习生的我肯定会想到封装啦。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;然后我们的可以使用 &lt;strong&gt;.&lt;/strong&gt; 或者&lt;strong&gt;source&lt;/strong&gt; 进行包含外包shell脚本。&lt;br/&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1808958/202012/1808958-20201211230024012-325802328.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;如果我们在之心执行教程出现换行符报错的问题我们可以通过 &lt;strong&gt;sed -i 's/\r$//' xxl.sh&lt;/strong&gt; 进行转换。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;或者将脚本字符格式进行修改LF格式就可以了。&lt;br/&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1808958/202012/1808958-20201211230032579-825634303.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;我们在执行脚本的时候如果出现权限不够的是时候，我们可以使用 &lt;strong&gt;sudo sh xxx.sh&lt;/strong&gt; 让脚本提升一下权限。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;当我们的功能比较多的时候，尽量将功能封装成为一个一个的方法。&lt;br/&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1808958/202012/1808958-20201211230057749-1928485697.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;h3 id=&quot;总结&quot;&gt;总结&lt;/h3&gt;
&lt;ul&gt;&lt;li&gt;这也是我第一次写shell脚本，总结的一些经验，后续还会持续补充一些自己的经验。&lt;/li&gt;
&lt;/ul&gt;</description>
<pubDate>Fri, 11 Dec 2020 15:02:00 +0000</pubDate>
<dc:creator>晨曦001</dc:creator>
<og:description>我的第一次shell 最近我们的项目需要进行优化，整体架构进行改造。 然后我们红超哥就看我骨骼惊奇，说小伙子你想不想当做掌门人呀。（我说不想哈哈） 想不想也没用了，红超哥说我们现在的架构有所改变，需要</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/chenxi001/p/14123300.html</dc:identifier>
</item>
<item>
<title>使用Tomcat Native提升Tomcat IO效率 - flydean</title>
<link>http://www.cnblogs.com/flydean/p/14123243.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/flydean/p/14123243.html</guid>
<description>&lt;p&gt;IO有很多种，从最开始的Block IO，到nonblocking IO，再到IO多路复用和异步IO，一步一步的将IO的性能提升做到极致。&lt;/p&gt;
&lt;p&gt;今天我们要介绍一下怎么使用Tomcat Native来提升Tomcat IO的效率。&lt;/p&gt;

&lt;p&gt;Tomcat中使用连接器来处理与外部客户端的通信。Connecter主要用来接受外部客户端的请求，并转交给处理引擎处理。&lt;/p&gt;
&lt;p&gt;在Tomcat中有两种Connector。一种是 HTTP connector， 一种是AJP connector。&lt;/p&gt;
&lt;p&gt;HTTP connector大家应该很好理解，它也是tomcat默认使用的连接器。&lt;/p&gt;
&lt;p&gt;还有一个连接器叫做AJP，AJP主要是用来和web服务器进行通信用的，因为AJP协议的速度要比HTTP的快，所以AJP除了用来和其他webserver进行通信之外，还可以通过AJP来构建tomcat集群。&lt;/p&gt;
&lt;p&gt;这两种方式都支持4中协议，分别是BIO，NIO，NIO2和APR。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;#以下四种Connector实现都是直接处理来自客户端Http请求
org.apache.coyote.http11.Http11Protocol : 支持HTTP/1.1 协议的连接器。

org.apache.coyote.http11.Http11NioProtocol : 支持HTTP/1.1 协议+New IO的连接器。

org.apache.coyote.http11.Http11Nio2Protocol : 支持HTTP/1.1 协议+New IO2的连接器。

org.apache.coyote.http11.Http11AprProtocol : 使用APR（Apache portable runtime)技术的连接器,利用Native


#以下四种实现方法则是与web server打交道
org.apache.coyote.ajp.AjpProtocol：使用AJP协议的连接器，实现与web server（如Apache httpd）之间的通信

org.apache.coyote.ajp.AjpNioProtocol：SJP协议+ New IO

org.apache.coyote.ajp.AjpNio2Protocol：SJP协议+ New IO2

org.apache.coyote.ajp.AjpAprProtocol：AJP + APR
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;讲下他们的区别，BIO就是block IO是最最基础的IO方式， 我们通过这样来配置：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-xml&quot;&gt;&amp;lt;Connector  port=”8080”  
protocol=”HTTP/1.1”
  
maxThreads=”150”  
connectionTimeout=”20000”   
redirectPort=”8443” /&amp;gt;
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;Tomcat7以下版本在默认情况下是以bio模式运行的。自Tomcat 8.5 版本开始，Tomcat就移除了对BIO的支持。&lt;/p&gt;
&lt;p&gt;New IO是基于java.nio包及其子包的一种IO方式。能提供非阻塞IO方式，比传统的BIO拥有与更加高效的运行效率。&lt;/p&gt;
&lt;p&gt;我们这样配置New IO:&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-xml&quot;&gt;&amp;lt;Connector port=&quot;8080&quot; protocol=&quot;org.apache.coyote.http11.Http11NioProtocol&quot;
connectionTimeout=&quot;20000&quot;
redirectPort=&quot;8443&quot; /&amp;gt;
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;New IO和New IO2有什么区别呢？&lt;/p&gt;
&lt;p&gt;New IO2是tomcat8中引入的IO方式，我们可以这样配置：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-xml&quot;&gt;&amp;lt;Connector port=&quot;8080&quot; protocol=&quot;org.apache.coyote.http11.Http11Nio2Protocol&quot;
connectionTimeout=&quot;20000&quot;
redirectPort=&quot;8443&quot; /&amp;gt;
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;apr这种方式就高级了，这个是我们今天要讲解的tomcat native的主要作用。&lt;/p&gt;

&lt;p&gt;apr的全称是Apache Portable Runtime，它是一个高度可移植的库，它是Apache HTTP Server 2.x的核心。 APR有许多用途，包括访问高级IO功能（例如sendfile，epoll和OpenSSL），操作系统级别的功能（生成随机数，系统状态等）和本机进程处理（共享内存，NT管道和Unix套接字）。&lt;/p&gt;
&lt;p&gt;Tomcat可以通过JNI的形式调用Apache HTTP服务器的核心动态链接库来处理文件读取或网络传输操作，从而大大地提高Tomcat对静态文件的处理性能。&lt;/p&gt;
&lt;p&gt;通过使用APR我们可以获得如下的特性：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;Non-blocking I/O和请求连接保持。&lt;/li&gt;
&lt;li&gt;支持OpenSSL和TLS/SSL。&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;Tomcat Native是一个库，通过这个库，Tomcat可以使用APR。&lt;/p&gt;
&lt;p&gt;所以使用Tomcat Native的前提是需要安装好APR library，OpenSSL和JDK。&lt;/p&gt;
&lt;p&gt;我们可以通过下面的方式来安装apr和openssl：&lt;/p&gt;
&lt;p&gt;debian based linux系统：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;apt-get install libapr1.0-dev libssl-dev
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;rpm based Linux 系统：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;yum install apr-devel openssl-devel
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;在windows下面，tcnative是以一个dll的形式来提供的，我们直接下载使用就可以了。&lt;/p&gt;
&lt;p&gt;但是在linux下面，因为平台不同，所以在linux下面tcnative是需要自行编译的。&lt;/p&gt;
&lt;p&gt;一般来说我们可以在 bin/tomcat-native.tar.gz 找到tcnative的源码包。将其解压。&lt;/p&gt;
&lt;p&gt;先运行configure命令：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-shell&quot;&gt;./configure --with-apr=/usr/bin/apr-1-config \
            --with-java-home=/home/jfclere/JAVA/jdk1.7.0_80/ \
            --with-ssl=yes \
            --prefix=$CATALINA_HOME
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;再进行make操作：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-shell&quot;&gt;make &amp;amp;&amp;amp; make install
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;生成的lib文件将会被放入$CATALINA_HOME/lib中。&lt;/p&gt;

&lt;p&gt;安装好tcnative之后，我们就可以在tomcat中使用APR了。&lt;/p&gt;
&lt;p&gt;先检查一下conf/server.xml中是否有下面的配置：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-xml&quot;&gt;&amp;lt;Listener className=&quot;org.apache.catalina.core.AprLifecycleListener&quot; SSLEngine=&quot;on&quot; /&amp;gt;
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;然后我们需要修改 $CATALINA_HOME/bin/setenv.sh 将tc-native 的lib文件添加到LD_LIBRARY_PATH中。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-shell&quot;&gt;LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$CATALINA_HOME/lib
export LD_LIBRARY_PATH
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;最后添加APR的连接：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-xml&quot;&gt;&amp;lt;Connector port=&quot;8080&quot; protocol=&quot;org.apache.coyote.http11.Http11AprProtocol&quot;
connectionTimeout=&quot;20000&quot;
redirectPort=&quot;8443&quot; /&amp;gt;
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;运行即可。&lt;/p&gt;
&lt;p&gt;从日志中，我们会发现下面的内容：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-shell&quot;&gt;org.apache.catalina.core.AprLifecycleListener init
INFO: Loaded APR based Apache Tomcat Native library 1.x.y.
org.apache.catalina.core.AprLifecycleListener init
INFO: APR capabilities: IPv6 [true], sendfile [true], accept filters [false], random [true].
org.apache.coyote.http11.Http11AprProtocol init
INFO: Initializing Coyote HTTP/1.1 on http-8080
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;说明APR安装完毕并且已经在被使用了。&lt;/p&gt;
&lt;blockquote readability=&quot;10.144329896907&quot;&gt;
&lt;p&gt;本文作者：flydean程序那些事&lt;/p&gt;
&lt;p&gt;本文链接：&lt;a href=&quot;http://www.flydean.com/tomcat-native-startup/&quot; target=&quot;_blank&quot;&gt;http://www.flydean.com/tomcat-native-startup/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;本文来源：flydean的博客&lt;/p&gt;
&lt;p&gt;欢迎关注我的公众号:「程序那些事」最通俗的解读，最深刻的干货，最简洁的教程，众多你不知道的小技巧等你来发现！&lt;/p&gt;
&lt;/blockquote&gt;
</description>
<pubDate>Fri, 11 Dec 2020 14:44:00 +0000</pubDate>
<dc:creator>flydean</dc:creator>
<og:description>简介 IO有很多种，从最开始的Block IO，到nonblocking IO，再到IO多路复用和异步IO，一步一步的将IO的性能提升做到极致。 今天我们要介绍一下怎么使用Tomcat Native来</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/flydean/p/14123243.html</dc:identifier>
</item>
<item>
<title>【MindSpore】Ubuntu16.04上成功安装GPU版MindSpore1.0.1 - 老妹儿的</title>
<link>http://www.cnblogs.com/old-sister/p/14123227.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/old-sister/p/14123227.html</guid>
<description>&lt;p&gt;&lt;br/&gt;本文是在宿主机Ubuntu16.04上拉取cuda10.1-cudnn7-ubuntu18.04的镜像，在容器中通过Miniconda3创建python3.7.5的环境并成功安装mindspore_gpu_1.0.1；&lt;/p&gt;
&lt;p&gt;&lt;br/&gt;&lt;strong&gt;一、前期踩过的坑&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;二、安装成功的流程&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;【1】拉取cuda10.1-cudnn7-ubuntu18.04的镜像&lt;br/&gt;【2】镜像内创建容器,&lt;strong&gt;此处一定是nvidia-docker创建&lt;/strong&gt;&lt;br/&gt;【3】在容器内安装Miniconda&lt;br/&gt;【4】使用conda创建python3.7.5的虚拟环境并激活&lt;br/&gt;【5】通过可执行文件安装mindspore_gpu_1.0.1.whl并测试&lt;/p&gt;
&lt;p&gt;&lt;br/&gt;&lt;strong&gt;一、前期踩过的坑&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.mindspore.cn/install/&quot; target=&quot;_blank&quot;&gt;在ubuntu上安装GPU版本mindspore的具体流程&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;em id=&quot;__mceDel&quot;&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1255847/202012/1255847-20201211222506147-853232185.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;br/&gt;主要有以下几点：&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;1. Ubuntu18.04（系统版本至少为18.04及以上） ：&lt;br/&gt;基于我使用的是共用版Ubuntu16.04的服务器，无法直接升级，只能通过容器方式，拉取Ubuntu18.04的镜像；&lt;/p&gt;
&lt;p&gt;&lt;br/&gt;2. cuda10.1 （cuda版本必须为10.1）：&lt;br/&gt;3. cudnn &amp;gt;= 7.6 （cudnn7.6.5可行，但cudnn8是会报错的）：&lt;/p&gt;
&lt;p&gt;&lt;br/&gt;因Nvidia提供了[cuda+cudnn+ubuntu的镜像](https://hub.docker.com/r/nvidia/cuda)，&lt;br/&gt;所以可以一次性拉取需要的cuda10.1-cudnn7-ubuntu18.04的镜像;&lt;/p&gt;
&lt;p&gt;&lt;br/&gt;因要求的是cudnn&amp;gt;=7.6，所以最开始拉取的是cudnn8版本的，一直报错 `libcudnn.so.7: cannot open shared object file: No such file or directory` ，后改为cudnn7版本就没报错了；&lt;/p&gt;

&lt;p&gt;4. devel和runtime版本区别：&lt;strong&gt;本文选择devel版&lt;/strong&gt;&lt;br/&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1255847/202012/1255847-20201211222623921-2023751798.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;br/&gt;找到cuda10.1-cudnn7-ubuntu18.04，（cudnn7它标明的是cudnn7.6.5）发现有两个版本cuda devel和cuda runtime：&lt;br/&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1255847/202012/1255847-20201211222648770-372495489.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;官方解释：&lt;br/&gt;devel是说只涵盖了开发bai所需的所有工具，包含编译、debug等，以及编译需要的头文件、静态库。&lt;br/&gt;runtime是说只涵盖了运行环境的最小集合，例如动态库等&lt;br/&gt;所以runtime的镜像大小会比devel小一些&lt;/p&gt;
&lt;p&gt;5. docker与nvidia-docker的区别：&lt;br/&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1255847/202012/1255847-20201211222717869-504426888.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;docker创建的容器里需要再次安装nvidia-driver，且需要容器里的nvidia-driver版本与宿主机里的nvidia-driver版本一致，才能在容器里使用GPU；&lt;/p&gt;
&lt;p&gt;nvidia-docker创建的容器，只需要在宿主机上安装nvidia-driver，容器内就可以直接使用GPU；&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;安装nvidia-docker之前必须在宿主机上安装nvidia-driver和docker；&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;33&quot;&gt;
&lt;pre&gt;
nvidia-smi # 检查宿主机是否安装了 nvidia-&lt;span&gt;driver
docker version # 检查宿主机上安装的docker版本
nvidia&lt;/span&gt;-docker version # 检查宿主机上安装的nvidia-docker版本
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1255847/202012/1255847-20201211222808650-1814728357.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1255847/202012/1255847-20201211222819501-739794016.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1255847/202012/1255847-20201211222831614-668373739.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;二、 安装成功的流程&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;【1】拉取nvidia/cuda:10.1-cudnn8-devel-ubuntu18.04的镜像&lt;/p&gt;&lt;p&gt;&lt;strong&gt;为避免不必要的错误，后续使用的全部都是nvidia-docker&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;选择&lt;strong&gt;devel&lt;/strong&gt;版本&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;32&quot;&gt;
&lt;pre&gt;
nvidia-docker pull nvidia/cuda:&lt;span&gt;10.1&lt;/span&gt;-cudnn7-devel-ubuntu18.&lt;span&gt;04&lt;/span&gt; 
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1255847/202012/1255847-20201211222918973-862740951.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;

&lt;p&gt;【2】镜像内创建容器,&lt;strong&gt;此处一定是nvidia-docker创建&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;32&quot;&gt;
&lt;pre&gt;
nvidia-docker run -it nvidia/cuda:&lt;span&gt;10.1&lt;/span&gt;-cudnn7-devel-ubuntu18.&lt;span&gt;04&lt;/span&gt; /bin/bash
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1255847/202012/1255847-20201211223008929-1223450191.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;【3】在容器内安装Miniconda&lt;/p&gt;&lt;p&gt;&lt;strong&gt;因为在容器内使用wget下载miniconda一直失败，所以选择在windows上下载并上传至ubuntu宿主机上，再从ubuntu宿主机上拷贝至容器内；&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;34&quot;&gt;
&lt;pre&gt;
nvidia-docker cp miniconda3.sh路径 containerID:/&lt;span&gt; # 退出容器，并将miniconda3.sh 文件拷贝至容器根目录下

nvidia&lt;/span&gt;-&lt;span&gt;docker start containerID # 启动容器并进入
nvidia&lt;/span&gt;-docker exec -it containerID /bin/&lt;span&gt;bash

bash Miniconda3&lt;/span&gt;-latest-Linux-x86_64.sh # 安装miniconda
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1255847/202012/1255847-20201211223338972-602795695.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;

&lt;p&gt;【4】使用conda创建python3.7.5的虚拟环境并激活&lt;/p&gt;
&lt;p&gt;&lt;br/&gt;&lt;strong&gt;安装miniconda后需先退出容器再进入，才能再容器中使用conda&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;32&quot;&gt;
&lt;pre&gt;
conda create -n mindspore1.&lt;span&gt;0.1&lt;/span&gt; python=&lt;span&gt;3.7&lt;/span&gt;.&lt;span&gt;5&lt;/span&gt; # conda create -n 虚拟环境名 指定python版本
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1255847/202012/1255847-20201211223410174-1718021306.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;32&quot;&gt;
&lt;pre&gt;
conda activate mindspore1.&lt;span&gt;0.1&lt;/span&gt; # 激活指定环境
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;同上,windows上下载mindspore_gpu_1.0.1.whl,并拷贝至容器内；&lt;/p&gt;
&lt;p&gt;&lt;br/&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1255847/202012/1255847-20201211223441645-1191820984.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;【5】通过可执行文件安装mindspore_gpu_1.0.1.whl并测试；&lt;br/&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;32&quot;&gt;
&lt;pre&gt;
pip install mindspore_gpu-&lt;span&gt;1.0&lt;/span&gt;.&lt;span&gt;1&lt;/span&gt;-cp37-cp37m-linux_x86_64.whl
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1255847/202012/1255847-20201211223503761-222557153.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;安装完成后，在python环境下执行以下代码&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;41&quot;&gt;
&lt;pre&gt;
import numpy &lt;span&gt;as&lt;/span&gt;&lt;span&gt; np
&lt;/span&gt;&lt;span&gt;from&lt;/span&gt;&lt;span&gt; mindspore import Tensor
&lt;/span&gt;&lt;span&gt;from&lt;/span&gt; mindspore.ops import functional &lt;span&gt;as&lt;/span&gt;&lt;span&gt; F
import mindspore.context &lt;/span&gt;&lt;span&gt;as&lt;/span&gt;&lt;span&gt; context

context.set_context(device_target&lt;/span&gt;=&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;GPU&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;)
x &lt;/span&gt;= Tensor(np.ones([&lt;span&gt;1&lt;/span&gt;,&lt;span&gt;3&lt;/span&gt;,&lt;span&gt;3&lt;/span&gt;,&lt;span&gt;4&lt;/span&gt;&lt;span&gt;]).astype(np.float32))
y &lt;/span&gt;= Tensor(np.ones([&lt;span&gt;1&lt;/span&gt;,&lt;span&gt;3&lt;/span&gt;,&lt;span&gt;3&lt;/span&gt;,&lt;span&gt;4&lt;/span&gt;&lt;span&gt;]).astype(np.float32))
print(F.tensor_add(x, y))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;如果出现以下，则说明安装成功：&lt;br/&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1255847/202012/1255847-20201211223529938-609058178.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
</description>
<pubDate>Fri, 11 Dec 2020 14:39:00 +0000</pubDate>
<dc:creator>老妹儿的</dc:creator>
<og:description>本文是在宿主机Ubuntu16.04上拉取cuda10.1-cudnn7-ubuntu18.04的镜像，在容器中通过Miniconda3创建python3.7.5的环境并成功安装mindspore_g</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/old-sister/p/14123227.html</dc:identifier>
</item>
<item>
<title>DarkMode(1)：产品应用深色模式分析 - zhoulujun</title>
<link>http://www.cnblogs.com/zhoulujun/p/14123192.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/zhoulujun/p/14123192.html</guid>
<description>&lt;p&gt;Dark Mode 并不是简单的颜色反转！在界面色彩复杂一些的情况下，直接的颜色反转就完全没法用了。苹果是如何为 iOS 设计 Dark Mode 的？Dark Mode 的设计难点在哪？为什么Dark Mode变得越来越流行&lt;/p&gt;&lt;div id=&quot;cnblogs_post_body&quot; readability=&quot;216.418&quot;&gt;
&lt;p&gt;为什么Dark Mode变得越来越流行&lt;/p&gt;
&lt;p&gt;2018 年的 macOS Mojave 率先支持了深色外观，紧接着 Windows 10 在 2018 年的 10 月份大版本更新中，也引入了 Dark Mode。&lt;/p&gt;
&lt;p&gt;iOS 13 的发推出了深色模式（Dark Mode），不仅可以大幅减少电量的消耗，减弱强光对比，还能提供更好的可视性和沉浸感。&lt;/p&gt;
&lt;p&gt; Android Q 重点推出了Dark Mode&lt;/p&gt;
&lt;p&gt;目前主流的操作系统也都在逐步支持 Dark Mode。&lt;/p&gt;
&lt;p&gt;像Facebook 、Slack、WhatsApp、Chrome 等等软件都支持Dark Mode&lt;/p&gt;
&lt;p&gt;那么，增加暗黑模式的目的是什么呢？&lt;/p&gt;
&lt;h3&gt;夜间使用时不那么刺眼&lt;/h3&gt;
&lt;p&gt;Google 提出了「Digital Wellbeing（数字健康）」的概念，注重在科技设备与使用者之间，找到一个健康的平衡点。&lt;/p&gt;
&lt;ul class=&quot; list-paddingleft-2&quot; readability=&quot;-0.5&quot;&gt;&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;&lt;strong&gt;夜览模式让屏幕在晚上减少蓝光，帮助我们更好地睡眠；&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;&lt;strong&gt;隐式推送减少了各类通知打扰我们的次数，使手机不会频繁打断我们的注意力&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;虽然有许多 app 已经支持了夜间模式，但还远远不够。首先，每个 app 的支持程度不尽相同，同时由于缺乏系统级的 API 支持，每个 app 的开发适配工作也比较烦琐。&lt;/p&gt;
&lt;h3&gt;让使用者沉浸于内容&lt;/h3&gt;
&lt;p&gt;将 Dark Mode 翻译为「夜间模式」，是因为前者的使用场景更广，因此使用「深色模式」这样的翻译更恰当。&lt;/p&gt;
&lt;p&gt;黑色更有利于我们沉浸于内容本身，无论是生产内容还是消费内容。如果你细心观察，你会发现&lt;strong&gt;许多专业级的多媒体内容生产软件，一直以来都是黑色的界面&lt;/strong&gt;。不管是 Adobe 系列的软件，还是苹果的 Final Cut Pro，或者是 Pixelmator、Affinity 系列软件，都是深色的主界面基调。同样的道理，你会发现许多视频网站或者影音播放工具，都是使用深色作为主基调。&lt;/p&gt;
&lt;h3&gt;OLED 屏幕节电&lt;/h3&gt;
&lt;p&gt;大多旗舰机的手机屏幕都抛弃了 LCD 材质，转而使用 OLED 材质的屏幕，例如，从 iPhone X 到 iPhone XS，搭配 Dark Mode，这样就能更加省电。&lt;/p&gt;
&lt;ul class=&quot; list-paddingleft-2&quot; readability=&quot;-0.5&quot;&gt;&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;LCD 屏幕分两层：像素层不发光，另外有背光面板照亮像素。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;OLED 屏幕只有一层，像素本身是自发光的。这样，在显示黑色时，&lt;strong&gt;OLED 的屏幕像素只需要关闭，就是纯正的黑色&lt;/strong&gt;了。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;在 macOS 的深色模式中，基底色并不是纯黑，而是带有一定灰度的黑色。&lt;/p&gt;
&lt;p&gt;在 iOS 上，苹果设计 Dark Mode 的基底色就是纯黑，这样一方面来可以省电，另一方面也与「刘海」的衔接更加自然。&lt;/p&gt;
&lt;h2&gt;Dark Mode 的设计难点在哪？&lt;/h2&gt;
&lt;p&gt;既然 Dark Mode 有不少吸引人的优点，为什么 Google 和苹果，一直等到2019年才正式推出系统级的 Dark Mode&lt;/p&gt;
&lt;p&gt;Dark Mode 并不像想像中的那么简单。&lt;/p&gt;
&lt;h3&gt;Dark Mode 并不是简单的颜色反转&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;在界面色彩复杂一些的情况下，直接的颜色反转就完全没法用&lt;/strong&gt;了。以下面的桌面为例，绿色的反转色是粉色，红色的反转色是青蓝色，而原本就是黑色的桌面被反转成了白色，最终得到的效果惨不忍睹。&lt;/p&gt;
&lt;blockquote readability=&quot;8.393063583815&quot;&gt;
&lt;p&gt;任意颜色可以由三原色组成，在电子设备上，一个色彩也可以表示成 RGB 值，即红绿蓝三种颜色的比例。每种颜色的取值范围是 0-255 之间，例如，白色可以表示为（255，255，255），黑色可以表示为（0，0，0）。那么，颜色反转实际上，是把一种颜色（R，G，B），自动变换到它的对立面，成为新的颜色（255-R，255-G，255-B）。&lt;/p&gt;
&lt;p&gt;更多相关内容推荐阅读：《&lt;a href=&quot;https://www.zhoulujun.cn/html/theory/multimedia/CG-CV-IP/6112.html&quot;&gt;色彩空间RGB/CMYK/HSL/HSB/HSV/Lab/YUV基础理论及转换方法:RGB与YUV&lt;/a&gt;》、《&lt;a href=&quot;https://www.zhoulujun.cn/html/design/photograph/2015_0720_151.html&quot; target=&quot;_blank&quot;&gt;水煮RGB与CMYK色彩模型—色彩与光学相关物理理论浅叙&lt;/a&gt;》、《&lt;a href=&quot;https://www.zhoulujun.cn/html/theory/CG-CV-IP/3843.html&quot; target=&quot;_blank&quot;&gt;三色视者与四色视者身后的理论基础:色彩原理&lt;/a&gt;》&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;所以Android与iOS的开启颜色反转，并不能开启暗黑模式。&lt;/p&gt;
&lt;h3&gt;要重新考虑色彩对比度&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;内容与背景之间的色彩对比度问题，两者之间必须保持才能使内容具有可读性&lt;/strong&gt;。要衡量这一点，其实是有一个明确的指标的：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;色彩对比率（Color Contrast Ratio），它能够提供两种颜色之间，相对亮度的一个衡量关系&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;色彩对比率的取值范围在 1:1 到 21:1 之间，数值越大，表示对比度越强烈，内容的可辨认度越高&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;Web 标准制定组织 W3C 在其 Web 内容无障碍指南（WCAG）中建议&lt;/p&gt;
&lt;h4&gt;要如何计算色彩对比率呢？&lt;/h4&gt;
&lt;p&gt;它的计算相对比较复杂，感兴趣的同学可以在这个页面搜索「Contrast Ratio」查看具体的计算方法。一般情况下，你可以使用各种现成的工具，只需要数入两种颜色的数值，就可以直接看到最终的计算结果了。&lt;/p&gt;
&lt;h3&gt;界面的层级与明暗关系&lt;/h3&gt;
&lt;p&gt;除了色彩对比度的关系外，还有一个更深层次的界面层级带来的问题，是通过颜色反转无法解决的。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://www.zhoulujun.cn/uploadfile/images/2020/09/20200914181505407255919.jpg&quot; alt=&quot;界面的层级与明暗关系.jpg&quot; width=&quot;918&quot; height=&quot;459&quot; title=&quot;界面的层级与明暗关系.jpg&quot;/&gt;&lt;/p&gt;
&lt;p&gt;论是浅色还是深色外观下，我们都应该在界面层级中，让离用户在逻辑关系上更近的颜色更亮一些。&lt;/p&gt;
&lt;p&gt;再让我们看一看实际 iOS 13 版本中 Dark Mode 的效果。你会发现，Dark Mode 的界面配色，并不是简单的颜色反转，可操作区域的颜色更浅一些，而背景色才是全黑的。这样，不管是浅色还是深色外观下，始终都保持了逻辑上的统一：离用户逻辑关系上越近的层级，颜色越浅越亮一些。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://www.zhoulujun.cn/uploadfile/images/2020/09/20200914181908289419691.jpg&quot; alt=&quot;iOS 13 版本中 Dark Mode 的效果&quot; width=&quot;418&quot; height=&quot;404&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; title=&quot;iOS 13 版本中 Dark Mode 的效果&quot; data-original=&quot;https://pic2.zhimg.com/v2-6553c298fb144e357384feb23cbcd4c5_r.jpg&quot;/&gt;&lt;/p&gt;
&lt;p&gt;界面层级与明暗的逻辑关系，本质上是与颜色反转不兼容的。&lt;/p&gt;
&lt;h2&gt;苹果是如何为 iOS 设计 Dark Mode 的？&lt;/h2&gt;
&lt;p&gt;苹果在今年 WWDC 的「What's New in iOS Design」专题中，花了不少的篇幅专门用来介绍如何升级适配 Dark Mode。&lt;/p&gt;
&lt;h2&gt;引入语义色彩（semantic color）&lt;/h2&gt;
&lt;p&gt;在以往的界面设计与开发过程中，需要单独针对每一个元素，指定一个颜色。既然不能简单地通过颜色反转来实现 Dark Mode，那么最简单的方式就是：&lt;strong&gt;为浅色外观和深色外观分别设计两套配色方案&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://www.zhoulujun.cn/uploadfile/images/2020/09/20200914182300881984854.jpg&quot; alt=&quot;light模式与Dark Mode模式设计对白&quot; width=&quot;640&quot; height=&quot;356&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; title=&quot;light模式与Dark Mode模式设计对白&quot; data-original=&quot;https://pic1.zhimg.com/v2-a3c037a9c294b93bdb16357ed06abdce_r.jpg&quot;/&gt;&lt;/p&gt;
&lt;p&gt;然而，这样的做法带来了一系列问题，尤其是 iOS 作为一个平台，需要考虑平台化的统一标准，以及尽可能地方便第三方开发者的适配工作。如果单纯地使用两套配色方案，那么每改动一处界面，都不能忘了要改动两个颜色值。同时，界面和界面之间，同样的页面元素，需要重复地指定具体的颜色，也造成了不必要的工作。&lt;/p&gt;
&lt;p&gt;因此，苹果引入了语义色彩（Semantic Color）这个概念。如同字面意思一样，&lt;strong&gt;不再通过 RGB 的值来描述一个颜色，而是通过 LabelColor、SeparatorColor 这样的文字描述，来说明这里应该使用文字标签的颜色、分隔线的颜色&lt;/strong&gt;……例如，在深浅两种模式下，系统界面的背景色会自动地去对应 SystemBackground，在浅色外观下 SystemBackground=#FFFFFF（白色），在深色外观下 SystemBackground=#000000（黑色）。&lt;/p&gt;
&lt;h4&gt;语义色彩带来了两个显而易见的好处：&lt;/h4&gt;
&lt;p&gt;语义色彩带来了两个显而易见的好处：&lt;/p&gt;
&lt;ol class=&quot; list-paddingleft-2&quot; readability=&quot;2&quot;&gt;&lt;li readability=&quot;2&quot;&gt;
&lt;p&gt;&lt;strong&gt;趋动设计师规划全局的配色方案&lt;/strong&gt;：在 Dark Mode 的设计难点中我们提到了，一套完整而悦目的 Dark  Mode，需要设计师深入地调整明暗关系下色彩的搭配。&lt;strong&gt;通过引入语义色彩，设计师可以自上而下地进行框架性设计&lt;/strong&gt;，首先定义好界面中一共存在哪些元素，然后，为这些元素规划好相应的配色方案，以确保在深浅外观中都获得最佳显示效果。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;2&quot;&gt;
&lt;p&gt;&lt;strong&gt;更容易复用&lt;/strong&gt;：通过语义色彩，无论是对于设计师还是程序员，都可以实现「&lt;strong&gt;一次声明，处处使用&lt;/strong&gt;」。通过语义色彩，设计师可以整理出配色模板，程序员可以在不同界面的同类型元素中，直接使用语义色彩，而不用重复地去指定相同的颜色。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhoulujun.cn/uploadfile/images/2020/09/20200914183808231306218.jpg&quot; alt=&quot;苹果在系统层面整理出了一套配色方案&quot; width=&quot;650&quot;/&gt;&lt;/p&gt;
&lt;p&gt;苹果在系统层面整理出了一套配色方案，其中包含了背景色、文字标签色、填充色等等，大多提供了四种不同醒目程度的层级，从应用在标题上的一级，到提示或说明性文字的四级。当然，除了系统内置的这些色彩，开发者也可以根据自己的需要创建和声明新的语义色彩。&lt;/p&gt;
&lt;h3&gt;背景色区分基底色（Base）与提亮色（Elevated）&lt;/h3&gt;
&lt;p&gt;在设计难点中我们提到了，层级上离用户越近的区域，应该在视觉上更明亮一些。苹果在设计 Dark Mode 时，也充分考虑到了这一点。&lt;/p&gt;
&lt;p&gt;iOS 深色外观的背景色，是纯正的黑色（#000000），苹果称之为基底色（Base）。不过，这个背景色会随着界面层级的变化，而变成提亮色（Elevated）。下图就是一个例子：在左边的通讯录 app    中，背景色就是纯正的黑色。而到了右边的电话 app 中，有些操作会需要弹出浮层供你选择联系人，这时候浮在上方的界面背景色，就变成了亮一些的提亮色。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://www.zhoulujun.cn/uploadfile/2020/0914/webp&quot; alt=&quot;背景色区分基底色（Base）与提亮色（Elevated）&quot; width=&quot;640&quot;/&gt;&lt;/p&gt;
&lt;h3&gt;材质（Material）与系统控件的原生支持&lt;/h3&gt;
&lt;p&gt;苹果在介绍 Dark Mode 时，还提到了材质（Material）。在我们常见的说法中，就是自 iOS 7    中引入的毛玻璃效果，常用于系统的文件夹、下拉菜单、通知、Dock 栏等处。苹果为这些材质设计了深浅两套配色方案，并提供了从厚到薄的四种感观效果。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://www.zhoulujun.cn/uploadfile/2020/0914/webp&quot; alt=&quot;苹果为材质设计了深浅两套配色方案并提供了从厚到薄的四种感观效果&quot; width=&quot;640&quot;/&gt;&lt;/p&gt;
&lt;p&gt;更重要的是，苹果还为材质上的内容颜色进行了单独的鲜活化（Vibrancy）处理。以下图为例，第一行的文字「Solid    Color」为固定色彩，随着背景颜色的变更，到最后两幅图中几乎不可辨识了。第二行的「Vibrant」则为经过了鲜活化处理的文字效果，在背景色变亮时，也能保证文字的可读性。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://www.zhoulujun.cn/uploadfile/images/2020/09/20200914183816255558647.jpg&quot; alt=&quot;材质效果&quot; width=&quot;640&quot;/&gt;&lt;/p&gt;
&lt;p&gt;此外，苹果还更新了 UIKit    中的系统级控件，以适配深浅两种颜色外观。值得注意的是，在浅色模式下，许多元素是存在投影的，例如开关按钮、拖动条的拉动点……而到了深色外观中，这些投影被统统移除了，这也是苹果设计的细微精致之处。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://www.zhoulujun.cn/uploadfile/2020/0914/webp&quot; alt=&quot;空间暗黑模式效果对比&quot; width=&quot;640&quot;/&gt;&lt;/p&gt;
&lt;h3&gt;引入字体化图标&lt;/h3&gt;
&lt;p&gt;在 iOS 13 中，苹果还为了 Dark Mode 引入了多达 1500 余个字体化图标 SF Symbols。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://www.zhoulujun.cn/uploadfile/images/2020/09/20200914183819157905708.jpg&quot; alt=&quot;字体图表效果&quot; width=&quot;480&quot;/&gt;&lt;/p&gt;
&lt;p&gt;前面我们已经看到了，苹果通过语义色彩解决了界面与内容的色彩管理，同时通过更新一系列的系统级控件确保适应两种不同的配色方案。然而，界面中还存在着一个重要元素，就是图标。如果我们希望获得良好的效果，往往需要针对深浅外观重新填充图标的颜色，准备两套图标素材。&lt;/p&gt;
&lt;p&gt;而字体化图标彻底解决了这个问题，还带来了一系列的优势。什么是字体化图标呢？简而言之，你可以对文字进行的处理，也可以针对图标做到。所以，字体化图标可以像文字一样修改颜色、粗细、大小、对齐。前面提到的语义色彩、鲜活化处理等技术，也一样可以运用在图标上。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://www.zhoulujun.cn/uploadfile/images/2020/09/20200914183819934173360.jpg&quot; alt=&quot;字体化图表效果&quot; width=&quot;480&quot;/&gt;&lt;/p&gt;
&lt;p&gt;以上四点，就是苹果如何为 iOS 设计 Dark Mode 的。你可以在&lt;a href=&quot;https://developer.apple.com/design/downloads/iOS-13-Sketch.dmg&quot;&gt;这里下载&lt;/a&gt;苹果官方提供的    iOS 13设计模板的 Sketch 文件，其中包含了 iOS 13 的最新范式、内置语义色彩、材质等元素。&lt;/p&gt;
&lt;p&gt;Dark Mode 在 iOS 13    上的呈现感不错，但距离完美还有一定距离。这其中既有客观因素，也有系统的主观原因。例如，iOS 的 Dark Mode 针对图像不会进行特别的处理，如果你的备忘录中有一张白色的照片，就会变得十分刺眼。而 Instapaper    在深色外观下，会自动暗化（Dimmed）处理内容中的图片元素。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://www.zhoulujun.cn/uploadfile/images/2020/09/20200914183827187325023.jpg&quot; alt=&quot;自动暗化处理图表元素&quot; width=&quot;480&quot;/&gt;&lt;/p&gt;
&lt;p&gt;此外，从客观因素上来说，许多网页还没有针对 Dark Mode 进行适配，导致打开时会一片惨白刺眼。同时，在 Power+ 1.0 中的《&lt;a class=&quot; wrap external&quot; href=&quot;https://sspai.com/post/45713&quot;&gt;深色模式对视疲劳和效率的影响&lt;/a&gt;》这篇文章，对 Dark Mode    也提出了许多非常有深度的论述。例如，深色模式其实未必适合文字的阅读，以及即使开启了深色模式，在昏暗环境中使用电子设备对视力的伤害也不容小觑。&lt;/p&gt;
&lt;p&gt;但不管怎么说，Dark Mode 都给我们提供了额外的选择，数字健康（Digital Wellbeing）不仅仅只体现在硬件的迭代与软件的更新上，更应该成为每一位使用者与开发者的主动意识，借此也希望所有的 app 和 web 开发者，尽早适配 Dark    Mode。&lt;/p&gt;

&lt;p&gt;参考文章：&lt;/p&gt;
&lt;p&gt;Dark Mode 的设计要点 &lt;a href=&quot;https://zhuanlan.zhihu.com/p/141465632&quot;&gt;https://zhuanlan.zhihu.com/p/141465632&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;写给设计师的指南：如何为即将到来的Dark Mode做好准备 &lt;a href=&quot;https://zhuanlan.zhihu.com/p/67583152&quot;&gt;https://zhuanlan.zhihu.com/p/67583152&lt;/a&gt;&lt;/p&gt;



&lt;p&gt;转载&lt;a href=&quot;https://www.zhoulujun.cn/&quot; target=&quot;_blank&quot;&gt;本站&lt;/a&gt;文章《&lt;a href=&quot;https://www.zhoulujun.cn/html/webfront/style/darkMode/8557.html&quot;&gt;DarkMode(1)：产品应用深色模式分析&lt;/a&gt;》,&lt;br/&gt;请注明出处：&lt;a href=&quot;https://www.zhoulujun.cn/html/webfront/style/darkMode/8557.html&quot;&gt;https://www.zhoulujun.cn/html/webfront/style/darkMode/8557.html&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;</description>
<pubDate>Fri, 11 Dec 2020 14:31:00 +0000</pubDate>
<dc:creator>zhoulujun</dc:creator>
<og:description>Dark Mode 并不是简单的颜色反转！在界面色彩复杂一些的情况下，直接的颜色反转就完全没法用了。苹果是如何为 iOS 设计 Dark Mode 的？Dark Mode 的设计难点在哪？为什么Dar</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/zhoulujun/p/14123192.html</dc:identifier>
</item>
<item>
<title>Java程序执行过程及内存机制 - 说人话</title>
<link>http://www.cnblogs.com/linj7/p/14122919.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/linj7/p/14122919.html</guid>
<description>&lt;p&gt;本讲介绍了Java代码是如何一步步运行起来的，其中涉及的编译器，类加载器，字节码校验器，解释器和JIT编译器在整个过程中是发挥着怎样的作用。此外还介绍了Java程序所占用的内存是被如何管理的：堆、栈和方法区都各自负责存储哪些内容。最后用一小块代码示例来帮助理解Java程序运行时内存的变化。&lt;/p&gt;&lt;div id=&quot;cnblogs_post_body&quot; readability=&quot;116.55886426593&quot;&gt;
&lt;p&gt;本讲将介绍Java代码是如何一步步运行起来的，其中涉及的编译器，类加载器，字节码校验器，解释器和JIT编译器在整个过程中是发挥着怎样的作用。此外还会介绍Java程序所占用的内存是被如何管理的：堆、栈和方法区都各自负责存储哪些内容。最后用一小块代码示例来帮助理解Java程序运行时内存的变化。&lt;/p&gt;
&lt;h2 id=&quot;java程序执行过程&quot;&gt;Java程序执行过程&lt;/h2&gt;
&lt;div align=&quot;center&quot;&gt;&lt;img src=&quot;https://i.loli.net/2020/12/08/ZOYfmKJIopUDleP.jpg&quot; width=&quot;80%&quot; height=&quot;80%&quot;/&gt;&lt;/div&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;步骤 1：&lt;/strong&gt; 写源代码，源代码将以.java的文件格式保存在电脑硬盘中。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;步骤 2：&lt;/strong&gt; 编译器（compiler）检查是否存在编译期错误（例如缺少分号，关键字拼写错误等）。若通过检测，编译器就会将源代码翻译成字节码（bytecode），以.class的文件格式保存在电脑硬盘中。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;步骤 3：&lt;/strong&gt; 若要运行此Java程序，JVM中会有一个叫类加载器（class loader）的内置程序把字节码从硬盘载入到正位于内存中的JVM里去。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;步骤 4：&lt;/strong&gt; JVM中还有一个叫字节码校验器（bytecode verifier）的内置程序检测是否存在运行期错误（例如栈溢出）。若通过检测，字节码校验器就会将字节码传递给解释器（interpreter）。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;步骤 5：&lt;/strong&gt; 解释器会对字节码进行逐行翻译，将其翻译成当前所在系统可以理解的机器码（machine code），&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;步骤 6&lt;/strong&gt;：将机器码交给操作系统，操作系统会以main方法作为入口开始执行程序。至此，一个Java程序就这样运行起来了。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;细心的读者可能注意到了，在流程图中还涉及到一个叫JIT的东西在步骤中没有被解释。那么JIT编译器（Just-In-Time Compiler）是如果参与进程序的执行过程中呢？让我们来看以下两个例子。&lt;/p&gt;
&lt;div align=&quot;center&quot;&gt;&lt;img src=&quot;https://i.loli.net/2020/12/08/AtMqLoDRHeSI8Xn.png&quot; width=&quot;80%&quot; height=&quot;80%&quot;/&gt;&lt;/div&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;情况 1：&lt;/strong&gt; 解释器对代码进行逐行解释，正如我们在步骤中所介绍的。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;情况 2：&lt;/strong&gt; 这是JIT编译器参与进Java执行过程的情况，JIT编译器会扫描所有代码并对其进行优化。例如此时它发现最后一行代码是重复多余的，就会将其移除，只传递前4行代码给解释器。这样解释器就能运行地更快速高效，毕竟少了一行多余的代码需要翻译。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;当然，这只是JIT编译器的优化手段之一，不同公司设计的JIT编译器对Java程序的运行会有不同的优化方式。此外需要知道的是，JIT编译器并不是每次都会参与到执行过程中来。&lt;/p&gt;
&lt;h2 id=&quot;内存机制&quot;&gt;内存机制&lt;/h2&gt;
&lt;p&gt;在步骤3中我们谈到字节码会被类加载器载入到内存，那么载入之后JVM是如何对其进行内存管理的呢？&lt;/p&gt;
&lt;p&gt;通常，在载入内存后，一个Java程序所占用的内存会被大致分为3块区域：堆（heap），栈（stack）和方法区（method area）。&lt;/p&gt;
&lt;div align=&quot;center&quot;&gt;&lt;img src=&quot;https://i.loli.net/2020/12/08/5kOsfj1PyIvh7C3.jpg&quot; width=&quot;80%&quot; height=&quot;80%&quot;/&gt;&lt;/div&gt;
&lt;p&gt;堆：存放new出来的东西。&lt;/p&gt;
&lt;p&gt;栈：存放局部变量。&lt;/p&gt;
&lt;p&gt;方法区：类型信息，字段信息，常量池（constant pool），静态变量，方法信息等。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;public final class Student extends Object implements Serializable { // 1.类信息
    // 2.对象字段信息
    private String name;
    private int score;
 
    // 3.常量池
    public final int id = 0;
    public final String gender = &quot;male&quot;;
  
        // 4.静态变量
        public static int a = 0;
    
    // 5.方法信息
    public int getid() {
        return id;
    }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;PC寄存器：存放将要执行的指令的地址。（因为机器的脑子不灵活，所以需要一块专门的区域帮他记住执行到哪一步，不然它会忘记）&lt;/p&gt;
&lt;p&gt;本地方法栈：与JVM栈所发挥的作用是非常相似的，其区别不过是JVM栈为Java方法服务，而本地方法栈则是为使用到的Native方法服务。有的虚拟机（例如Sun HotSpot虚拟机）甚至直接就把本地方法栈和虚拟机栈合二为一。&lt;/p&gt;
&lt;p&gt;每个线程拥有各自独立的（虚拟机）栈、PC寄存器和本地方法栈。而堆和方法区则是所有线程共享的。&lt;/p&gt;
&lt;p&gt;最后让我们通过一个小例子来理解Java程序执行时内存的变化。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;public class Person {
  int id;
  int age;
  
  Person(int id1, int age1) {
    id = id1;
    age = age1;
  }
  
  public static void main(String[] args) {
                Person Tom = new Person(1, 25);
  }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;首先，在stack中申请了一块内存，这块内存区域名字叫Tom，此时区域里存储的内容为null。&lt;/p&gt;
&lt;p&gt;接着，调用Person的构造方法，方法的参数属于局部变量，因此在stack中有两块区域分别存放id1和age1。&lt;/p&gt;
&lt;p&gt;通过构造方法，可以new出来一个Person的对象，这个对象连带着其成员变量会被存放在heap中。成员变量id和age的值由存放在stack中的局部变量id1和age1赋予。&lt;/p&gt;
&lt;p&gt;最后，将这个对象的引用值（类似于地址）传递给Tom，通过引用值我们就可以找到这个对象。&lt;/p&gt;
&lt;div align=&quot;center&quot;&gt;&lt;img src=&quot;https://i.loli.net/2020/12/08/ipa5FXq1szjtymQ.png&quot; width=&quot;80%&quot; height=&quot;80%&quot;/&gt;&lt;/div&gt;
&lt;p&gt;（注意：位于stack中的id1和age1会随着构造方法调用的结束而消失，这里为了更好地表现全过程，因此保留在图中。）&lt;/p&gt;
&lt;h3 id=&quot;关于栈和堆的其他小知识&quot;&gt;关于栈和堆的其他小知识&lt;/h3&gt;
&lt;ul&gt;&lt;li&gt;栈和堆的大小都是固定为一个默认值的，它们作为jvm的参数设定好了，不同的jvm设定的参数不同，相应的栈和堆的大小也就不同。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;栈是运行时的单位&lt;/strong&gt;：里面存储的信息都是跟当前线程相关的，包括局部变量、程序运行状态、方法返回值等；而&lt;strong&gt;堆是存储的单位&lt;/strong&gt;：它只负责存储对象。&lt;/li&gt;
&lt;li&gt;当一个方法调用结束后，方法里的局部变量会随之消失，不会在stack中继续占用空间。&lt;/li&gt;
&lt;li&gt;栈与堆的分离使得不同线程可以访问同一个对象，这是一种有效的数据交互方式（共享内存）；此外也节省了空间，因为堆中的共享常量和缓存可以被所有栈访问。&lt;/li&gt;
&lt;/ul&gt;&lt;h2 id=&quot;参考&quot;&gt;参考&lt;/h2&gt;
&lt;ol&gt;&lt;li&gt;&lt;a href=&quot;https://simplesnippets.tech/execution-process-of-java-program-in-detail-working-of-just-it-time-compiler-jit-in-detail/&quot; target=&quot;_blank&quot;&gt;https://simplesnippets.tech/execution-process-of-java-program-in-detail-working-of-just-it-time-compiler-jit-in-detail/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://blog.csdn.net/yfqnihao/article/details/8289363&quot; target=&quot;_blank&quot;&gt;https://blog.csdn.net/yfqnihao/article/details/8289363&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://www.zhihu.com/question/29833675&quot; target=&quot;_blank&quot;&gt;https://www.zhihu.com/question/29833675&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;有问题欢迎大家在评论区留言，转载请注明出处。&lt;/p&gt;
&lt;/div&gt;</description>
<pubDate>Fri, 11 Dec 2020 13:47:00 +0000</pubDate>
<dc:creator>说人话</dc:creator>
<og:description>本讲介绍了Java代码是如何一步步运行起来的，其中涉及的编译器，类加载器，字节码校验器，解释器和JIT编译器在整个过程中是发挥着怎样的作用。此外还介绍了Java程序所占用的内存是被如何管理的：堆、栈和</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/linj7/p/14122919.html</dc:identifier>
</item>
</channel>
</rss>