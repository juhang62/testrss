<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="css/feed.xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/" xmlns:og="http://ogp.me/ns#">
<channel>
<atom:link rel="self" href="http://192.168.1.4/fivefilters/makefulltextfeed.php?url=feed.cnblogs.com%2Fblog%2Fsitehome%2Frss&amp;max=10&amp;links=preserve&amp;exc=" />
<atom:link rel="alternate" title="Source URL" href="http://feed.cnblogs.com/blog/sitehome/rss" />
<atom:link rel="related" title="Subscribe to feed" href="http://www.subtome.com/#/subscribe?feeds=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed.cnblogs.com%252Fblog%252Fsitehome%252Frss%26max%3D10%26links%3Dpreserve%26exc%3D&amp;back=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed.cnblogs.com%252Fblog%252Fsitehome%252Frss%26max%3D10%26links%3Dpreserve%26exc%3D" />
<title>博客园_首页</title>
<link></link>
<description>代码改变世界</description>
<item>
<title>分布式全局ID生成方案 - JaJian</title>
<link>http://www.cnblogs.com/jajian/p/11101213.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/jajian/p/11101213.html</guid>
<description>&lt;p&gt;传统的单体架构的时候，我们基本是单库然后业务单表的结构。每个业务表的ID一般我们都是从1增，通过&lt;code&gt;AUTO_INCREMENT=1&lt;/code&gt;设置自增起始值，但是在分布式服务架构模式下分库分表的设计，使得多个库或多个表存储相同的业务数据。这种情况根据数据库的自增ID就会产生相同ID的情况，不能保证主键的唯一性。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1162587/201907/1162587-20190703202345984-877149422.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;如上图，如果第一个订单存储在 DB1 上则订单 ID 为1，当一个新订单又入库了存储在 DB2 上订单 ID 也为1。我们系统的架构虽然是分布式的，但是在用户层应是无感知的，重复的订单主键显而易见是不被允许的。那么针对分布式系统如何做到主键唯一性呢？&lt;/p&gt;

&lt;p&gt;UUID （Universally Unique Identifier），通用唯一识别码的缩写。UUID是由一组32位数的16进制数字所构成，所以UUID理论上的总数为 16^32=2^128，约等于 3.4 x 10^38。也就是说若每纳秒产生1兆个UUID，要花100亿年才会将所有UUID用完。&lt;/p&gt;
&lt;p&gt;生成的UUID是由 &lt;code&gt;8-4-4-4-12&lt;/code&gt;格式的数据组成，其中32个字符和4个连字符' - '，一般我们使用的时候会将连字符删除 &lt;code&gt;uuid.toString().replaceAll(&quot;-&quot;,&quot;&quot;)&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;目前UUID的产生方式有5种版本，每个版本的算法不同，应用范围也不同。&lt;/p&gt;
&lt;ul readability=&quot;5&quot;&gt;&lt;li readability=&quot;2&quot;&gt;
&lt;p&gt;&lt;strong&gt;基于时间的UUID - 版本1&lt;/strong&gt;：&lt;br/&gt;这个一般是通过当前时间，随机数，和本地Mac地址来计算出来，可以通过 &lt;code&gt;org.apache.logging.log4j.core.util&lt;/code&gt;包中的 &lt;code&gt;UuidUtil.getTimeBasedUuid()&lt;/code&gt;来使用或者其他包中工具。由于使用了MAC地址，因此能够确保唯一性，但是同时也暴露了MAC地址，私密性不够好。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;1&quot;&gt;
&lt;p&gt;&lt;strong&gt;DCE安全的UUID - 版本2&lt;/strong&gt;&lt;br/&gt;DCE（Distributed Computing Environment）安全的UUID和基于时间的UUID算法相同，但会把时间戳的前4位置换为POSIX的UID或GID。这个版本的UUID在实际中较少用到。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;基于名字的UUID（MD5）- 版本3&lt;/strong&gt;&lt;br/&gt;基于名字的UUID通过计算名字和名字空间的MD5散列值得到。这个版本的UUID保证了：相同名字空间中不同名字生成的UUID的唯一性；不同名字空间中的UUID的唯一性；相同名字空间中相同名字的UUID重复生成是相同的。&lt;/li&gt;
&lt;li readability=&quot;1&quot;&gt;
&lt;p&gt;&lt;strong&gt;随机UUID - 版本4&lt;/strong&gt;&lt;br/&gt;根据随机数，或者伪随机数生成UUID。这种UUID产生重复的概率是可以计算出来的，但是重复的可能性可以忽略不计，因此该版本也是被经常使用的版本。JDK中使用的就是这个版本。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;&lt;strong&gt;基于名字的UUID（SHA1） - 版本5&lt;/strong&gt;&lt;br/&gt;和基于名字的UUID算法类似，只是散列值计算使用SHA1（Secure Hash Algorithm 1）算法。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;我们 Java中 JDK自带的 UUID产生方式就是版本4根据随机数生成的 UUID 和版本3基于名字的 UUID，有兴趣的可以去看看它的源码。&lt;/p&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;public static void main(String[] args) {

    //获取一个版本4根据随机字节数组的UUID。
    UUID uuid = UUID.randomUUID();
    System.out.println(uuid.toString().replaceAll(&quot;-&quot;,&quot;&quot;));

    //获取一个版本3(基于名称)根据指定的字节数组的UUID。
    byte[] nbyte = {10, 20, 30};
    UUID uuidFromBytes = UUID.nameUUIDFromBytes(nbyte);
    System.out.println(uuidFromBytes.toString().replaceAll(&quot;-&quot;,&quot;&quot;));
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;得到的UUID结果，&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;59f51e7ea5ca453bbfaf2c1579f09f1d
7f49b84d0bbc38e9a493718013baace6&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;虽然 UUID 生成方便，本地生成没有网络消耗，但是使用起来也有一些缺点，&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;不易于存储：UUID太长，16字节128位，通常以36长度的字符串表示，很多场景不适用。&lt;/li&gt;
&lt;li&gt;信息不安全：基于MAC地址生成UUID的算法可能会造成MAC地址泄露，暴露使用者的位置。&lt;/li&gt;
&lt;li&gt;对MySQL索引不利：如果作为数据库主键，在InnoDB引擎下，UUID的无序性可能会引起数据位置频繁变动，严重影响性能，可以查阅 Mysql 索引原理 B+树的知识。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;是不是一定要基于外界的条件才能满足分布式唯一ID的需求呢，我们能不能在我们分布式数据库的基础上获取我们需要的ID？&lt;/p&gt;
&lt;p&gt;由于分布式数据库的起始自增值一样所以才会有冲突的情况发生，那么我们将分布式系统中数据库的同一个业务表的自增ID设计成不一样的起始值，然后设置固定的步长，步长的值即为分库的数量或分表的数量。&lt;/p&gt;
&lt;p&gt;以MySQL举例，利用给字段设置&lt;code&gt;auto_increment_increment&lt;/code&gt;和&lt;code&gt;auto_increment_offset&lt;/code&gt;来保证ID自增。&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;auto_increment_offset：表示自增长字段从那个数开始，他的取值范围是1 .. 65535。&lt;/li&gt;
&lt;li&gt;auto_increment_increment：表示自增长字段每次递增的量，其默认值是1，取值范围是1 .. 65535。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;假设有三台机器，则DB1中order表的起始ID值为1，DB2中order表的起始值为2，DB3中order表的起始值为3，它们自增的步长都为3，则它们的ID生成范围如下图所示：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1162587/201907/1162587-20190703202807719-1624656040.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;通过这种方式明显的优势就是依赖于数据库自身不需要其他资源，并且ID号单调自增，可以实现一些对ID有特殊要求的业务。&lt;/p&gt;
&lt;p&gt;但是缺点也很明显，首先它强依赖DB，当DB异常时整个系统不可用。虽然配置主从复制可以尽可能的增加可用性，但是数据一致性在特殊情况下难以保证。主从切换时的不一致可能会导致重复发号。还有就是ID发号性能瓶颈限制在单台MySQL的读写性能。&lt;/p&gt;

&lt;p&gt;Redis实现分布式唯一ID主要是通过提供像 &lt;em&gt;INCR&lt;/em&gt; 和 &lt;em&gt;INCRBY&lt;/em&gt; 这样的自增原子命令，由于Redis自身的单线程的特点所以能保证生成的 ID 肯定是唯一有序的。&lt;/p&gt;
&lt;p&gt;但是单机存在性能瓶颈，无法满足高并发的业务需求，所以可以采用集群的方式来实现。集群的方式又会涉及到和数据库集群同样的问题，所以也需要设置分段和步长来实现。&lt;/p&gt;
&lt;p&gt;为了避免长期自增后数字过大可以通过与当前时间戳组合起来使用，另外为了保证并发和业务多线程的问题可以采用 Redis + Lua的方式进行编码，保证安全。&lt;/p&gt;
&lt;p&gt;Redis 实现分布式全局唯一ID，它的性能比较高，生成的数据是有序的，对排序业务有利，但是同样它依赖于redis，需要系统引进redis组件，增加了系统的配置复杂性。&lt;/p&gt;
&lt;p&gt;当然现在Redis的使用性很普遍，所以如果其他业务已经引进了Redis集群，则可以资源利用考虑使用Redis来实现。&lt;/p&gt;

&lt;p&gt;Snowflake，雪花算法是由Twitter开源的分布式ID生成算法，以划分命名空间的方式将 64-bit位分割成多个部分，每个部分代表不同的含义。而 Java中64bit的整数是Long类型，所以在 Java 中 SnowFlake 算法生成的 ID 就是 long 来存储的。&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;第1位占用1bit，其值始终是0，可看做是符号位不使用。&lt;/li&gt;
&lt;li&gt;第2位开始的41位是时间戳，41-bit位可表示2^41个数，每个数代表毫秒，那么雪花算法可用的时间年限是(1L&amp;lt;&amp;lt;41)/(1000L&lt;em&gt;3600&lt;/em&gt;24*365)=69 年的时间。&lt;/li&gt;
&lt;li&gt;中间的10-bit位可表示机器数，即2^10 = 1024台机器，但是一般情况下我们不会部署这么台机器。如果我们对IDC（互联网数据中心）有需求，还可以将 10-bit 分 5-bit 给 IDC，分5-bit给工作机器。这样就可以表示32个IDC，每个IDC下可以有32台机器，具体的划分可以根据自身需求定义。&lt;/li&gt;
&lt;li&gt;最后12-bit位是自增序列，可表示2^12 = 4096个数。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;这样的划分之后相当于在一毫秒一个数据中心的一台机器上可产生4096个有序的不重复的ID。但是我们 IDC 和机器数肯定不止一个，所以毫秒内能生成的有序ID数是翻倍的。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1162587/201907/1162587-20190703224510482-1120058153.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;Snowflake 的&lt;a href=&quot;https://github.com/twitter/snowflake/blob/snowflake-2010/src/main/scala/com/twitter/service/snowflake/IdWorker.scala&quot;&gt;Twitter官方原版&lt;/a&gt;是用Scala写的，对Scala语言有研究的同学可以去阅读下，以下是 Java 版本的写法。&lt;/p&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;package com.jajian.demo.distribute;

/**
 * Twitter_Snowflake&amp;lt;br&amp;gt;
 * SnowFlake的结构如下(每部分用-分开):&amp;lt;br&amp;gt;
 * 0 - 0000000000 0000000000 0000000000 0000000000 0 - 00000 - 00000 - 000000000000 &amp;lt;br&amp;gt;
 * 1位标识，由于long基本类型在Java中是带符号的，最高位是符号位，正数是0，负数是1，所以id一般是正数，最高位是0&amp;lt;br&amp;gt;
 * 41位时间截(毫秒级)，注意，41位时间截不是存储当前时间的时间截，而是存储时间截的差值（当前时间截 - 开始时间截)
 * 得到的值），这里的的开始时间截，一般是我们的id生成器开始使用的时间，由我们程序来指定的（如下下面程序IdWorker类的startTime属性）。41位的时间截，可以使用69年，年T = (1L &amp;lt;&amp;lt; 41) / (1000L * 60 * 60 * 24 * 365) = 69&amp;lt;br&amp;gt;
 * 10位的数据机器位，可以部署在1024个节点，包括5位datacenterId和5位workerId&amp;lt;br&amp;gt;
 * 12位序列，毫秒内的计数，12位的计数顺序号支持每个节点每毫秒(同一机器，同一时间截)产生4096个ID序号&amp;lt;br&amp;gt;
 * 加起来刚好64位，为一个Long型。&amp;lt;br&amp;gt;
 * SnowFlake的优点是，整体上按照时间自增排序，并且整个分布式系统内不会产生ID碰撞(由数据中心ID和机器ID作区分)，并且效率较高，经测试，SnowFlake每秒能够产生26万ID左右。
 */
public class SnowflakeDistributeId {


    // ==============================Fields===========================================
    /**
     * 开始时间截 (2015-01-01)
     */
    private final long twepoch = 1420041600000L;

    /**
     * 机器id所占的位数
     */
    private final long workerIdBits = 5L;

    /**
     * 数据标识id所占的位数
     */
    private final long datacenterIdBits = 5L;

    /**
     * 支持的最大机器id，结果是31 (这个移位算法可以很快的计算出几位二进制数所能表示的最大十进制数)
     */
    private final long maxWorkerId = -1L ^ (-1L &amp;lt;&amp;lt; workerIdBits);

    /**
     * 支持的最大数据标识id，结果是31
     */
    private final long maxDatacenterId = -1L ^ (-1L &amp;lt;&amp;lt; datacenterIdBits);

    /**
     * 序列在id中占的位数
     */
    private final long sequenceBits = 12L;

    /**
     * 机器ID向左移12位
     */
    private final long workerIdShift = sequenceBits;

    /**
     * 数据标识id向左移17位(12+5)
     */
    private final long datacenterIdShift = sequenceBits + workerIdBits;

    /**
     * 时间截向左移22位(5+5+12)
     */
    private final long timestampLeftShift = sequenceBits + workerIdBits + datacenterIdBits;

    /**
     * 生成序列的掩码，这里为4095 (0b111111111111=0xfff=4095)
     */
    private final long sequenceMask = -1L ^ (-1L &amp;lt;&amp;lt; sequenceBits);

    /**
     * 工作机器ID(0~31)
     */
    private long workerId;

    /**
     * 数据中心ID(0~31)
     */
    private long datacenterId;

    /**
     * 毫秒内序列(0~4095)
     */
    private long sequence = 0L;

    /**
     * 上次生成ID的时间截
     */
    private long lastTimestamp = -1L;

    //==============================Constructors=====================================

    /**
     * 构造函数
     *
     * @param workerId     工作ID (0~31)
     * @param datacenterId 数据中心ID (0~31)
     */
    public SnowflakeDistributeId(long workerId, long datacenterId) {
        if (workerId &amp;gt; maxWorkerId || workerId &amp;lt; 0) {
            throw new IllegalArgumentException(String.format(&quot;worker Id can't be greater than %d or less than 0&quot;, maxWorkerId));
        }
        if (datacenterId &amp;gt; maxDatacenterId || datacenterId &amp;lt; 0) {
            throw new IllegalArgumentException(String.format(&quot;datacenter Id can't be greater than %d or less than 0&quot;, maxDatacenterId));
        }
        this.workerId = workerId;
        this.datacenterId = datacenterId;
    }

    // ==============================Methods==========================================

    /**
     * 获得下一个ID (该方法是线程安全的)
     *
     * @return SnowflakeId
     */
    public synchronized long nextId() {
        long timestamp = timeGen();

        //如果当前时间小于上一次ID生成的时间戳，说明系统时钟回退过这个时候应当抛出异常
        if (timestamp &amp;lt; lastTimestamp) {
            throw new RuntimeException(
                    String.format(&quot;Clock moved backwards.  Refusing to generate id for %d milliseconds&quot;, lastTimestamp - timestamp));
        }

        //如果是同一时间生成的，则进行毫秒内序列
        if (lastTimestamp == timestamp) {
            sequence = (sequence + 1) &amp;amp; sequenceMask;
            //毫秒内序列溢出
            if (sequence == 0) {
                //阻塞到下一个毫秒,获得新的时间戳
                timestamp = tilNextMillis(lastTimestamp);
            }
        }
        //时间戳改变，毫秒内序列重置
        else {
            sequence = 0L;
        }

        //上次生成ID的时间截
        lastTimestamp = timestamp;

        //移位并通过或运算拼到一起组成64位的ID
        return ((timestamp - twepoch) &amp;lt;&amp;lt; timestampLeftShift) //
                | (datacenterId &amp;lt;&amp;lt; datacenterIdShift) //
                | (workerId &amp;lt;&amp;lt; workerIdShift) //
                | sequence;
    }

    /**
     * 阻塞到下一个毫秒，直到获得新的时间戳
     *
     * @param lastTimestamp 上次生成ID的时间截
     * @return 当前时间戳
     */
    protected long tilNextMillis(long lastTimestamp) {
        long timestamp = timeGen();
        while (timestamp &amp;lt;= lastTimestamp) {
            timestamp = timeGen();
        }
        return timestamp;
    }

    /**
     * 返回以毫秒为单位的当前时间
     *
     * @return 当前时间(毫秒)
     */
    protected long timeGen() {
        return System.currentTimeMillis();
    }
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;测试的代码如下&lt;/p&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;public static void main(String[] args) {
    SnowflakeDistributeId idWorker = new SnowflakeDistributeId(0, 0);
    for (int i = 0; i &amp;lt; 1000; i++) {
        long id = idWorker.nextId();
//      System.out.println(Long.toBinaryString(id));
        System.out.println(id);
    }
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;雪花算法提供了一个很好的设计思想，雪花算法生成的ID是趋势递增，不依赖数据库等第三方系统，以服务的方式部署，稳定性更高，生成ID的性能也是非常高的，而且可以根据自身业务特性分配bit位，非常灵活。&lt;/p&gt;
&lt;p&gt;但是雪花算法强依赖机器时钟，如果机器上时钟回拨，会导致发号重复或者服务会处于不可用状态。如果恰巧回退前生成过一些ID，而时间回退后，生成的ID就有可能重复。官方对于此并没有给出解决方案，而是简单的抛错处理，这样会造成在时间被追回之前的这段时间服务不可用。&lt;/p&gt;
&lt;p&gt;很多其他类雪花算法也是在此思想上的设计然后改进规避它的缺陷，后面介绍的百度 UidGenerator 和 美团分布式ID生成系统 Leaf 中snowflake模式都是在 snowflake 的基础上演进出来的。&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/baidu/uid-generator&quot;&gt;百度的 UidGenerator&lt;/a&gt; 是百度开源基于Java语言实现的唯一ID生成器，是在雪花算法 snowflake 的基础上做了一些改进。UidGenerator以组件形式工作在应用项目中, 支持自定义workerId位数和初始化策略，适用于docker等虚拟化环境下实例自动重启、漂移等场景。&lt;/p&gt;
&lt;p&gt;在实现上，UidGenerator 提供了两种生成唯一ID方式，分别是 DefaultUidGenerator 和 CachedUidGenerator，官方建议如果有性能考虑的话使用 CachedUidGenerator 方式实现。&lt;/p&gt;
&lt;p&gt;UidGenerator 依然是以划分命名空间的方式将 64-bit位分割成多个部分，只不过它的默认划分方式有别于雪花算法 snowflake。它默认是由 1-28-22-13 的格式进行划分。可根据你的业务的情况和特点，自己调整各个字段占用的位数。&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;第1位仍然占用1bit，其值始终是0。&lt;/li&gt;
&lt;li&gt;第2位开始的28位是时间戳，28-bit位可表示2^28个数，&lt;strong&gt;这里不再是以毫秒而是以秒为单位&lt;/strong&gt;，每个数代表秒则可用（1L&amp;lt;&amp;lt;28）/ (3600&lt;em&gt;24&lt;/em&gt;365) ≈ 8.51 年的时间。&lt;/li&gt;
&lt;li&gt;中间的 workId （数据中心+工作机器，可以其他组成方式）则由 22-bit位组成，可表示 2^22 = 4194304个工作ID。&lt;/li&gt;
&lt;li&gt;最后由13-bit位构成自增序列，可表示2^13 = 8192个数。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1162587/201907/1162587-20190705155449555-583981868.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;其中 workId （机器 id），最多可支持约420w次机器启动。内置实现为在启动时由数据库分配（表名为 WORKER_NODE），默认分配策略为用后即弃，后续可提供复用策略。&lt;/p&gt;
&lt;pre class=&quot;sql&quot;&gt;
&lt;code&gt;DROP TABLE IF EXISTS WORKER_NODE;
CREATE TABLE WORKER_NODE
(
ID BIGINT NOT NULL AUTO_INCREMENT COMMENT 'auto increment id',
HOST_NAME VARCHAR(64) NOT NULL COMMENT 'host name',
PORT VARCHAR(64) NOT NULL COMMENT 'port',
TYPE INT NOT NULL COMMENT 'node type: ACTUAL or CONTAINER',
LAUNCH_DATE DATE NOT NULL COMMENT 'launch date',
MODIFIED TIMESTAMP NOT NULL COMMENT 'modified time',
CREATED TIMESTAMP NOT NULL COMMENT 'created time',
PRIMARY KEY(ID)
)
 COMMENT='DB WorkerID Assigner for UID Generator',ENGINE = INNODB;&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;defaultuidgenerator-实现&quot;&gt;DefaultUidGenerator 实现&lt;/h2&gt;
&lt;p&gt;DefaultUidGenerator 就是正常的根据时间戳和机器位还有序列号的生成方式，和雪花算法很相似，对于时钟回拨也只是抛异常处理。仅有一些不同，如以秒为为单位而不再是毫秒和支持Docker等虚拟化环境。&lt;/p&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;protected synchronized long nextId() {
    long currentSecond = getCurrentSecond();

    // Clock moved backwards, refuse to generate uid
    if (currentSecond &amp;lt; lastSecond) {
        long refusedSeconds = lastSecond - currentSecond;
        throw new UidGenerateException(&quot;Clock moved backwards. Refusing for %d seconds&quot;, refusedSeconds);
    }

    // At the same second, increase sequence
    if (currentSecond == lastSecond) {
        sequence = (sequence + 1) &amp;amp; bitsAllocator.getMaxSequence();
        // Exceed the max sequence, we wait the next second to generate uid
        if (sequence == 0) {
            currentSecond = getNextSecond(lastSecond);
        }

    // At the different second, sequence restart from zero
    } else {
        sequence = 0L;
    }

    lastSecond = currentSecond;

    // Allocate bits for UID
    return bitsAllocator.allocate(currentSecond - epochSeconds, workerId, sequence);
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;如果你要使用 DefaultUidGenerator 的实现方式的话，以上划分的占用位数可通过 spring 进行参数配置。&lt;/p&gt;
&lt;pre class=&quot;xml&quot;&gt;
&lt;code&gt;&amp;lt;bean id=&quot;defaultUidGenerator&quot; class=&quot;com.baidu.fsg.uid.impl.DefaultUidGenerator&quot; lazy-init=&quot;false&quot;&amp;gt;
    &amp;lt;property name=&quot;workerIdAssigner&quot; ref=&quot;disposableWorkerIdAssigner&quot;/&amp;gt;

    &amp;lt;!-- Specified bits &amp;amp; epoch as your demand. No specified the default value will be used --&amp;gt;
    &amp;lt;property name=&quot;timeBits&quot; value=&quot;29&quot;/&amp;gt;
    &amp;lt;property name=&quot;workerBits&quot; value=&quot;21&quot;/&amp;gt;
    &amp;lt;property name=&quot;seqBits&quot; value=&quot;13&quot;/&amp;gt;
    &amp;lt;property name=&quot;epochStr&quot; value=&quot;2016-09-20&quot;/&amp;gt;
&amp;lt;/bean&amp;gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;cacheduidgenerator-实现&quot;&gt;CachedUidGenerator 实现&lt;/h2&gt;
&lt;p&gt;而官方建议的性能较高的 CachedUidGenerator 生成方式，是使用 RingBuffer 缓存生成的id。数组每个元素成为一个slot。RingBuffer容量，默认为Snowflake算法中sequence最大值（2^13 = 8192）。可通过 boostPower 配置进行扩容，以提高 RingBuffer 读写吞吐量。&lt;/p&gt;
&lt;p&gt;Tail指针、Cursor指针用于环形数组上读写slot：&lt;/p&gt;
&lt;ul readability=&quot;1&quot;&gt;&lt;li readability=&quot;1&quot;&gt;
&lt;p&gt;Tail指针&lt;br/&gt;表示Producer生产的最大序号(此序号从0开始，持续递增)。Tail不能超过Cursor，即生产者不能覆盖未消费的slot。当Tail已赶上curosr，此时可通过rejectedPutBufferHandler指定PutRejectPolicy&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;1&quot;&gt;
&lt;p&gt;Cursor指针&lt;br/&gt;表示Consumer消费到的最小序号(序号序列与Producer序列相同)。Cursor不能超过Tail，即不能消费未生产的slot。当Cursor已赶上tail，此时可通过rejectedTakeBufferHandler指定TakeRejectPolicy&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1162587/201907/1162587-20190707142503899-1530677221.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;CachedUidGenerator采用了双RingBuffer，Uid-RingBuffer用于存储Uid、Flag-RingBuffer用于存储Uid状态(是否可填充、是否可消费)。&lt;/p&gt;
&lt;p&gt;由于数组元素在内存中是连续分配的，可最大程度利用CPU cache以提升性能。但同时会带来「伪共享」FalseSharing问题，为此在Tail、Cursor指针、Flag-RingBuffer中采用了CacheLine 补齐方式。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1162587/201907/1162587-20190707142450492-1894906450.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;RingBuffer填充时机&lt;/p&gt;
&lt;ul readability=&quot;1.5&quot;&gt;&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;初始化预填充&lt;br/&gt;RingBuffer初始化时，预先填充满整个RingBuffer。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;1&quot;&gt;
&lt;p&gt;即时填充&lt;br/&gt;Take消费时，即时检查剩余可用slot量(tail - cursor)，如小于设定阈值，则补全空闲slots。阈值可通过paddingFactor来进行配置，请参考Quick Start中CachedUidGenerator配置。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;周期填充&lt;br/&gt;通过Schedule线程，定时补全空闲slots。可通过scheduleInterval配置，以应用定时填充功能，并指定Schedule时间间隔。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Leaf是美团基础研发平台推出的一个分布式ID生成服务，名字取自德国哲学家、数学家莱布尼茨的著名的一句话：“There are no two identical leaves in the world”，世间不可能存在两片相同的叶子。&lt;/p&gt;
&lt;p&gt;Leaf 也提供了两种ID生成的方式，分别是 Leaf-segment 数据库方案和 Leaf-snowflake 方案。&lt;/p&gt;
&lt;h2 id=&quot;leaf-segment-数据库方案&quot;&gt;Leaf-segment 数据库方案&lt;/h2&gt;
&lt;p&gt;Leaf-segment 数据库方案，是在上文描述的在使用数据库的方案上，做了如下改变：&lt;/p&gt;
&lt;ul readability=&quot;1&quot;&gt;&lt;li readability=&quot;1&quot;&gt;
&lt;p&gt;原方案每次获取ID都得读写一次数据库，造成数据库压力大。改为利用proxy server批量获取，每次获取一个segment(step决定大小)号段的值。用完之后再去数据库获取新的号段，可以大大的减轻数据库的压力。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;1&quot;&gt;
&lt;p&gt;各个业务不同的发号需求用 &lt;code&gt;biz_tag&lt;/code&gt;字段来区分，每个biz-tag的ID获取相互隔离，互不影响。如果以后有性能需求需要对数据库扩容，不需要上述描述的复杂的扩容操作，只需要对biz_tag分库分表就行。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;数据库表设计如下：&lt;/p&gt;
&lt;pre class=&quot;sql&quot;&gt;
&lt;code&gt;CREATE TABLE `leaf_alloc` (
  `biz_tag` varchar(128)  NOT NULL DEFAULT '' COMMENT '业务key',
  `max_id` bigint(20) NOT NULL DEFAULT '1' COMMENT '当前已经分配了的最大id',
  `step` int(11) NOT NULL COMMENT '初始步长，也是动态调整的最小步长',
  `description` varchar(256)  DEFAULT NULL COMMENT '业务key的描述',
  `update_time` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '更新时间',
  PRIMARY KEY (`biz_tag`)
) ENGINE=InnoDB;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;原来获取ID每次都需要写数据库，现在只需要把step设置得足够大，比如1000。那么只有当1000个号被消耗完了之后才会去重新读写一次数据库。读写数据库的频率从1减小到了1/step，大致架构如下图所示：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1162587/201907/1162587-20190707145304450-2077732965.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;同时Leaf-segment 为了解决 TP999（满足千分之九百九十九的网络请求所需要的最低耗时）数据波动大，当号段使用完之后还是会hang在更新数据库的I/O上，TP999 数据会出现偶尔的尖刺的问题，提供了双buffer优化。&lt;/p&gt;
&lt;p&gt;简单的说就是，Leaf 取号段的时机是在号段消耗完的时候进行的，也就意味着号段临界点的ID下发时间取决于下一次从DB取回号段的时间，并且在这期间进来的请求也会因为DB号段没有取回来，导致线程阻塞。如果请求DB的网络和DB的性能稳定，这种情况对系统的影响是不大的，但是假如取DB的时候网络发生抖动，或者DB发生慢查询就会导致整个系统的响应时间变慢。&lt;/p&gt;
&lt;p&gt;为了DB取号段的过程能够做到无阻塞，不需要在DB取号段的时候阻塞请求线程，即当号段消费到某个点时就异步的把下一个号段加载到内存中，而不需要等到号段用尽的时候才去更新号段。这样做就可以很大程度上的降低系统的 TP999 指标。详细实现如下图所示：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1162587/201907/1162587-20190707145904035-1903303849.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;采用双buffer的方式，Leaf服务内部有两个号段缓存区segment。当前号段已下发10%时，如果下一个号段未更新，则另启一个更新线程去更新下一个号段。当前号段全部下发完后，如果下个号段准备好了则切换到下个号段为当前segment接着下发，循环往复。&lt;/p&gt;
&lt;ul readability=&quot;0&quot;&gt;&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;每个biz-tag都有消费速度监控，通常推荐segment长度设置为服务高峰期发号QPS的600倍（10分钟），这样即使DB宕机，Leaf仍能持续发号10-20分钟不受影响。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;每次请求来临时都会判断下个号段的状态，从而更新此号段，所以偶尔的网络抖动不会影响下个号段的更新。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;对于这种方案依然存在一些问题，它仍然依赖 DB的稳定性，需要采用主从备份的方式提高 DB的可用性，还有 Leaf-segment方案生成的ID是趋势递增的，这样ID号是可被计算的，例如订单ID生成场景，通过订单id号相减就能大致计算出公司一天的订单量，这个是不能忍受的。&lt;/p&gt;
&lt;h2 id=&quot;leaf-snowflake方案&quot;&gt;Leaf-snowflake方案&lt;/h2&gt;
&lt;p&gt;Leaf-snowflake方案完全沿用 snowflake 方案的bit位设计，对于workerID的分配引入了Zookeeper持久顺序节点的特性自动对snowflake节点配置 wokerID。避免了服务规模较大时，动手配置成本太高的问题。&lt;/p&gt;
&lt;p&gt;Leaf-snowflake是按照下面几个步骤启动的：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;启动Leaf-snowflake服务，连接Zookeeper，在leaf_forever父节点下检查自己是否已经注册过（是否有该顺序子节点）。&lt;/li&gt;
&lt;li&gt;如果有注册过直接取回自己的workerID（zk顺序节点生成的int类型ID号），启动服务。&lt;/li&gt;
&lt;li&gt;如果没有注册过，就在该父节点下面创建一个持久顺序节点，创建成功后取回顺序号当做自己的workerID号，启动服务。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1162587/201907/1162587-20190707150856232-1431838397.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;为了减少对 Zookeeper的依赖性，会在本机文件系统上缓存一个workerID文件。当ZooKeeper出现问题，恰好机器出现问题需要重启时，能保证服务能够正常启动。&lt;/p&gt;
&lt;p&gt;上文阐述过在类 snowflake算法上都存在时钟回拨的问题，Leaf-snowflake在解决时钟回拨的问题上是通过校验自身系统时间与 &lt;code&gt;leaf_forever/${self}&lt;/code&gt;节点记录时间做比较然后启动报警的措施。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1162587/201907/1162587-20190707151138303-18638511.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;美团官方建议是由于强依赖时钟，对时间的要求比较敏感，在机器工作时NTP同步也会造成秒级别的回退，建议可以直接关闭NTP同步。要么在时钟回拨的时候直接不提供服务直接返回ERROR_CODE，等时钟追上即可。或者做一层重试，然后上报报警系统，更或者是发现有时钟回拨之后自动摘除本身节点并报警。&lt;/p&gt;
&lt;p&gt;在性能上官方提供的数据目前 Leaf 的性能在4C8G 的机器上QPS能压测到近5w/s，TP999 1ms。&lt;/p&gt;

&lt;p&gt;以上基本列出了所有常用的分布式ID生成方式，其实大致分类的话可以分为两类：&lt;/p&gt;
&lt;p&gt;一种是类DB型的，根据设置不同起始值和步长来实现趋势递增，需要考虑服务的容错性和可用性。&lt;/p&gt;
&lt;p&gt;另一种是类snowflake型，这种就是将64位划分为不同的段，每段代表不同的涵义，基本就是时间戳、机器ID和序列数。这种方案就是需要考虑时钟回拨的问题以及做一些 buffer的缓冲设计提高性能。&lt;/p&gt;
&lt;p&gt;而且可通过将三者（时间戳，机器ID，序列数）划分不同的位数来改变使用寿命和并发数。&lt;/p&gt;
&lt;p&gt;例如对于并发数要求不高、期望长期使用的应用，可增加时间戳位数，减少序列数的位数. 例如配置成{&quot;workerBits&quot;:23,&quot;timeBits&quot;:31,&quot;seqBits&quot;:9}时, 可支持28个节点以整体并发量14400 UID/s的速度持续运行68年。&lt;/p&gt;
&lt;p&gt;对于节点重启频率频繁、期望长期使用的应用, 可增加工作机器位数和时间戳位数, 减少序列数位数. 例如配置成{&quot;workerBits&quot;:27,&quot;timeBits&quot;:30,&quot;seqBits&quot;:6}时, 可支持37个节点以整体并发量2400 UID/s的速度持续运行34年。&lt;/p&gt;
&lt;p&gt;参考：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;&lt;a href=&quot;https://blog.csdn.net/chen_changying/article/details/79454901&quot;&gt;blog.csdn.net&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/baidu/uid-generator/blob/master/README.zh_cn.md&quot;&gt;github.com/baidu/uid-generator&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://tech.meituan.com/2017/04/21/mt-leaf.html&quot;&gt;tech.meituan.com&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s/8NsTXexf03wrT0tsW24EHA&quot;&gt;mp.weixin.qq.com&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;</description>
<pubDate>Mon, 08 Jul 2019 01:00:00 +0000</pubDate>
<dc:creator>JaJian</dc:creator>
<og:description>传统的单体架构的时候，我们基本是单库然后业务单表的结构。每个业务表的ID一般我们都是从1增，通过 设置自增起始值，但是在分布式服务架构模式下分库分表的设计，使得多个库或多个表存储相同的业务数据。这种情</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/jajian/p/11101213.html</dc:identifier>
</item>
<item>
<title>程序员修神之路--做好分库分表其实很难之一（继续送书） - 架构师修行之路</title>
<link>http://www.cnblogs.com/zhanlang/p/11143657.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/zhanlang/p/11143657.html</guid>
<description>&lt;p&gt;说到数据库分库分表，不能一味的追求，我们要明白为什么要进行分库分表才是最终目的。现在网上一些人鼓吹分库分表如何应对了多大数据，却不知针对很多人的业务来说，分库分表策略也许并非是银弹，而是令人焦虑的焦油坑。&lt;/p&gt;&lt;p&gt;分库分表是业务发展到一定阶段，数据积累到一定量级而衍生出来的解决方案。当DB的数据量级到达一个阶段，写入和读取的速度会出现瓶颈，即使是有索引，索引也会变的很大，而且数据库的物理文件大的会使备份和恢复等操作变的很困难。这个时候由于DB的瓶颈已经严重危害到了业务，最有效的解决方案莫过于DB的分库分表了。&lt;/p&gt;

&lt;p&gt;有的leader甚至架构师会在业务初期以自己的主观意愿就进行分库分表，会为以后业务高速发展做铺垫。但是这里我要表达我几个观点：&lt;/p&gt;
&lt;p&gt;&lt;span&gt;1.&lt;/span&gt; 如果当前这个业务并非公司的核心业务，而且在业务是否能存活的前提下，初级的设计不要这么复杂。如果每个业务我们都按淘宝那样的规模做系统架构设计，将来不但会害死业务，更会让程序员死的更惨，背上黑锅的数量会更多。&lt;/p&gt;
&lt;p&gt;&lt;span&gt;2.&lt;/span&gt; 单台数据库的能力并非想象中那么脆弱。就算是mysql单表数据量大部分场景下也在百万级别（当然这和存储的具体数据格式有关），sqlserver更是不在话下，我司用的sqlserver，单表千万级别数据的大有所在，亿级的也有几个，Oracle更是不用多说。&lt;/p&gt;
&lt;p&gt;&lt;span&gt;3.&lt;/span&gt; 如果业务周期比较短，或者人力物力不足的情况下，盲目的在初期就进行分库分表设计，更是给自己下了绩效背D的套，&lt;/p&gt;
&lt;p&gt;&lt;span&gt;4.&lt;/span&gt; 系统的设计初期和公司的基础数据有直接关系，比如微信这样的数据规模，稍微一个小系统就有可能是千万甚至上亿的数据级别，但是多数初创公司有多少能有这样的级别呢？我这里喷一句：有的创业公司号称从XX大公司重金挖来的CTO，技术总监等等高人，尤其是这些带着金色光环的人在创业初期给开发人员埋雷，一个创业公司搞一套XX分布式，XX设计，殊不知，在当前的公司环境下这些其实没有必要，给公司带来的更多是苦不堪言。&lt;/p&gt;
</description>
<pubDate>Mon, 08 Jul 2019 00:58:00 +0000</pubDate>
<dc:creator>架构师修行之路</dc:creator>
<og:description>菜哥，领导让我开发新系统了 这么说领导对你还是挺信任的呀~ 必须的，为了设计好这个新系统，数据库设计我花了好多心思呢 做一个系统我觉得不应该从数据库入手，应该从设计业务模型开始，先不说这个，说说你的数</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/zhanlang/p/11143657.html</dc:identifier>
</item>
<item>
<title>Python爬虫的起点 - 猪哥66</title>
<link>http://www.cnblogs.com/pig66/p/11146898.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/pig66/p/11146898.html</guid>
<description>&lt;p&gt;第一章主要讲解爬虫相关的知识如：http、网页、爬虫法律等，让大家对爬虫有了一个比较完善的了解和一些题外的知识点。&lt;br/&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20190706223036649.png?&quot; alt=&quot;在这里插入图片描述&quot;/&gt;&lt;/p&gt;
&lt;p&gt;今天这篇文章将是我们第二章的第一篇，我们从今天开始就正式进入实战阶段，后面将会有更多的实际案例。&lt;/p&gt;
&lt;p&gt;爬虫系列文章的第一篇，猪哥便为大家讲解了HTTP原理，很多人好奇：好好的讲爬虫和HTTP有什么关系？其实我们常说的爬虫（也叫网络爬虫）就是使用一些网络协议发起的网络请求，而目前使用最多的网络协议便是HTTP/S网络协议簇。&lt;/p&gt;
&lt;h2 id=&quot;-python-&quot;&gt;一、Python有哪些网络库&lt;/h2&gt;
&lt;p&gt;在真实浏览网页我们是通过鼠标点击网页然后由浏览器帮我们发起网络请求，那在Python中我们又如何发起网络请求的呢？答案当然是库，具体哪些库？猪哥给大家列一下：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;Python2: httplib、httplib2、urllib、urllib2、urllib3、requests&lt;/li&gt;
&lt;li&gt;Python3: httplib2、urllib、urllib3、requests&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;Python网络请求库有点多，而且还看见网上还都有用过的，那他们之间有何关系？又该如何选择？&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;httplib/2：这是一个Python内置http库，但是&lt;strong&gt;它是偏于底层的库，一般不直接用&lt;/strong&gt;。而httplib2是一个基于httplib的第三方库，比httplib实现更完整，支持缓存、压缩等功能。&lt;strong&gt;一般这两个库都用不到&lt;/strong&gt;，如果需要自己 封装网络请求可能会需要用到。&lt;img src=&quot;https://img-blog.csdnimg.cn/20190704162815800.jpg?&quot; alt=&quot;在这里插入图片描述&quot;/&gt;&lt;/li&gt;
&lt;li&gt;urllib/urllib2/urllib3：urlliib是一个基于httplib的上层库，而urllib2和urllib3都是第三方库，urllib2相对于urllib增加一些高级功能，如：HTTP身份验证或Cookie等，在Python3中将urllib2合并到了urllib中。urllib3提供线程安全连接池和文件post等支持，与urllib及urllib2的关系不大。&lt;img src=&quot;https://img-blog.csdnimg.cn/20190705152705117.jpg?&quot; alt=&quot;在这里插入图片描述&quot;/&gt;&lt;/li&gt;
&lt;li&gt;requests：requests库是一个基于urllib/3的第三方网络库，它的特点是功&lt;strong&gt;能强大，API优雅&lt;/strong&gt;。由上图我们可以看到，对于http客户端python官方文档也推荐我们使用requests库，实际工作中requests库也是使用的比较多的库。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;综上所述，我们选择选择&lt;strong&gt;requests库作为我们爬虫入门的起点&lt;/strong&gt;。另外以上的这些库都是同步网络库，如果需要高并发请求的话可以使用异步网络库：aiohttp，这个后面猪哥也会为大家讲解。&lt;/p&gt;
&lt;h2 id=&quot;-requests-&quot;&gt;二、requests介绍&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;希望大家永远记住：学任何一门语言，都不要忘记去看看官方文档。&lt;/strong&gt;也许官方文档不是最好的入门教程，但绝对是最新、最全的教学文档！&lt;/p&gt;
&lt;h3 id=&quot;1-&quot;&gt;1.首页&lt;/h3&gt;
&lt;p&gt;requests的官方文档（目前已支持中文）链接：&lt;a href=&quot;http://cn.python-requests.org/&quot;&gt;http://cn.python-requests.org&lt;/a&gt;&lt;br/&gt;源代码地址：&lt;a href=&quot;https://github.com/kennethreitz/requests&quot;&gt;https://github.com/kennethreitz/requests&lt;/a&gt;&lt;br/&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20190705173606529.jpg&quot; alt=&quot;在这里插入图片描述&quot;/&gt;&lt;/p&gt;
&lt;p&gt;从首页中&lt;code&gt;让HTTP服务人类&lt;/code&gt;这几个字中我们便能看出，requests核心宗旨便是让用户使用方便，间接表达了他们设计优雅的理念。&lt;img src=&quot;https://img-blog.csdnimg.cn/20190705174410408.jpg&quot; alt=&quot;在这里插入图片描述&quot;/&gt;&lt;br/&gt;注：PEP 20便是鼎鼎大名的&lt;code&gt;Python之禅&lt;/code&gt;。&lt;/p&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;警告：非专业&lt;strong&gt;使用其他 HTTP 库&lt;/strong&gt;会导致危险的副作用，包括：安全缺陷症、冗余代码症、重新发明轮子症、啃文档症、抑郁、头疼、甚至死亡。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&quot;2-&quot;&gt;2.功能特性&lt;/h3&gt;
&lt;p&gt;都说requests功能强大，那我们来看看requests到底有哪些功能特性吧：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;Keep-Alive &amp;amp; 连接池&lt;/li&gt;
&lt;li&gt;国际化域名和 URL&lt;/li&gt;
&lt;li&gt;带持久 Cookie 的会话&lt;/li&gt;
&lt;li&gt;浏览器式的 SSL 认证&lt;/li&gt;
&lt;li&gt;自动内容解码&lt;/li&gt;
&lt;li&gt;基本/摘要式的身份认证&lt;/li&gt;
&lt;li&gt;优雅的 key/value Cookie&lt;/li&gt;
&lt;li&gt;自动解压&lt;/li&gt;
&lt;li&gt;Unicode 响应体&lt;/li&gt;
&lt;li&gt;HTTP(S) 代理支持&lt;/li&gt;
&lt;li&gt;文件分块上传&lt;/li&gt;
&lt;li&gt;流下载&lt;/li&gt;
&lt;li&gt;连接超时&lt;/li&gt;
&lt;li&gt;分块请求&lt;/li&gt;
&lt;li&gt;支持 .netrc&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;requests 完全满足今日 web 的需求。Requests 支持 Python 2.6—2.7以及3.3—3.7，而且能在 PyPy 下完美运行&lt;/p&gt;
&lt;h2 id=&quot;-requests&quot;&gt;三、安装requests&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;pip install requests&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;如果是pip3则使用&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;pip3 install requests&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;如果你使用anaconda则可以&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;conda install requests&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;如果你不想用命令行，可在pycharm中这样下载库&lt;br/&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20190706100224142.jpg?&quot; alt=&quot;在这里插入图片描述&quot;/&gt;&lt;/p&gt;
&lt;h2 id=&quot;-&quot;&gt;四、爬虫流程&lt;/h2&gt;
&lt;p&gt;下图是猪哥之前工作总结的一个&lt;strong&gt;项目开发流程&lt;/strong&gt;，算是比较详细，在开发一个大型的项目真的需要这么详细，不然项目上线出故障或者修改需求都无法做&lt;strong&gt;项目复盘&lt;/strong&gt;，到时候程序员就有可能背锅祭天。。。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20190706150247531.jpg?&quot; alt=&quot;在这里插入图片描述&quot;/&gt;&lt;/p&gt;
&lt;p&gt;言归正传，给大家看项目的开发流程是想引出爬虫爬取数据的流程：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;确定需要爬取的网页&lt;/li&gt;
&lt;li&gt;浏览器检查数据来源（静态网页or动态加载）&lt;/li&gt;
&lt;li&gt;寻找加载数据url的参数规律（如分页）&lt;/li&gt;
&lt;li&gt;代码模拟请求爬取数据&lt;/li&gt;
&lt;/ol&gt;&lt;h2 id=&quot;-&quot;&gt;五、爬取某东商品页&lt;/h2&gt;
&lt;p&gt;猪哥就以某东商品页为例子带大家学习爬虫的简单流程，为什么以某东下手而不是某宝？因为某东浏览商品页不需要登录，简单便于大家快速入门！&lt;/p&gt;
&lt;h3 id=&quot;1-&quot;&gt;1.第一步：浏览器中找到你想爬取的商品&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20190706162635282.jpg?&quot; alt=&quot;在这里插入图片描述&quot;/&gt;&lt;br/&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20190706162801813.jpg?&quot; alt=&quot;在这里插入图片描述&quot;/&gt;&lt;br/&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20190706162952519.jpg?&quot; alt=&quot;在这里插入图片描述&quot;/&gt;&lt;br/&gt;ps：猪哥并不是在开车哦，为什么选这款商品？因为后面会爬取这款商品的评价做数据分析，是不是很刺激！&lt;/p&gt;
&lt;h3 id=&quot;2-&quot;&gt;2.第二步：浏览器检查数据来源&lt;/h3&gt;
&lt;p&gt;打开浏览器调试窗口是为了查看网络请求，看看数据是怎么加载的？是直接返回静态页面呢，还是js动态加载呢？&lt;br/&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/201907061708580.jpg?&quot; alt=&quot;在这里插入图片描述&quot;/&gt;&lt;br/&gt;&lt;strong&gt;鼠标右键然后点检查或者直接F12&lt;/strong&gt;即可打开调试窗口，这里猪哥推荐大家使用Chrome浏览器，为什么？因为好用，程序员都在用！具体的Chrome如何调试，大家自行网上看教程！&lt;/p&gt;
&lt;p&gt;打开调试窗口之后，我们就可以重新请求数据，然后查看返回的数据，确定数据来源。&lt;br/&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20190706171602343.jpg?&quot; alt=&quot;在这里插入图片描述&quot;/&gt;&lt;/p&gt;
&lt;h3 id=&quot;3-url-&quot;&gt;3.第三步：寻找加载数据url的参数规律&lt;/h3&gt;
&lt;p&gt;我们可以看到第一个请求链接：&lt;a href=&quot;https://item.jd.com/1263013576.html&quot;&gt;https://item.jd.com/1263013576.html&lt;/a&gt; 返回的数据便是我们要的网页数据。因为我们是爬取商品页，所以不存在分页之说。&lt;br/&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20190706175623380.jpg?&quot; alt=&quot;在这里插入图片描述&quot;/&gt;&lt;/p&gt;
&lt;p&gt;当然价格和一些优惠券等核心信息是通过另外的请求加载，这里我们暂时不讨论，先完成我们的第一个小例子！&lt;/p&gt;
&lt;h3 id=&quot;4-&quot;&gt;4.第四步：代码模拟请求爬取数据&lt;/h3&gt;
&lt;p&gt;获取url链接之后我们来开始写代码吧&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;hljs language-python&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;import&lt;/span&gt; requests

&lt;span class=&quot;hljs-function&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;hljs-title&quot;&gt;spider_jd&lt;/span&gt;&lt;span class=&quot;hljs-params&quot;&gt;()&lt;/span&gt;:&lt;/span&gt;
    &lt;span class=&quot;hljs-string&quot;&gt;&quot;&quot;&quot;爬取京东商品页&quot;&quot;&quot;&lt;/span&gt;
    url = &lt;span class=&quot;hljs-string&quot;&gt;'https://item.jd.com/1263013576.html'&lt;/span&gt;
    &lt;span class=&quot;hljs-keyword&quot;&gt;try&lt;/span&gt;:
        r = requests.get(url)
        
        
        r.raise_for_status()
        print(r.text[:&lt;span class=&quot;hljs-number&quot;&gt;500&lt;/span&gt;])
    &lt;span class=&quot;hljs-keyword&quot;&gt;except&lt;/span&gt;:
        print(&lt;span class=&quot;hljs-string&quot;&gt;'爬取失败'&lt;/span&gt;)

&lt;span class=&quot;hljs-keyword&quot;&gt;if&lt;/span&gt; __name__ == &lt;span class=&quot;hljs-string&quot;&gt;'__main__'&lt;/span&gt;:
    spider_jd()
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;检查返回结果&lt;br/&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20190706181122245.jpg&quot; alt=&quot;在这里插入图片描述&quot;/&gt;&lt;br/&gt;至此我们就完成了某东商品页的爬取，虽然案例简单，代码很少，但是爬虫的流程基本差不多，希望想学爬虫的同学自己动动手实践一把，选择自己喜欢的商品抓取一下，只有自己动手才能真的学到知识！&lt;/p&gt;
&lt;h2 id=&quot;-requests-&quot;&gt;六、requests库介绍&lt;/h2&gt;
&lt;p&gt;上面我们使用了requests的get方法，我们可以查看源码发现还有其他几个方法：post、put、patch、delete、options、head，他们就是对应HTTP的请求方法。&lt;br/&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20190706210542936.jpg?&quot; alt=&quot;在这里插入图片描述&quot;/&gt;&lt;br/&gt;这里简单给大家列一下，后面会用大量的案例来&lt;strong&gt;用而后学&lt;/strong&gt;，毕竟枯燥的讲解没人愿意看。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;hljs language-python&quot;&gt;requests.post(&lt;span class=&quot;hljs-string&quot;&gt;'http://httpbin.org/post'&lt;/span&gt;, data = {&lt;span class=&quot;hljs-string&quot;&gt;'key'&lt;/span&gt;:&lt;span class=&quot;hljs-string&quot;&gt;'value'&lt;/span&gt;})
requests.patch(&lt;span class=&quot;hljs-string&quot;&gt;'http://httpbin.org/post'&lt;/span&gt;, data = {&lt;span class=&quot;hljs-string&quot;&gt;'key'&lt;/span&gt;:&lt;span class=&quot;hljs-string&quot;&gt;'value'&lt;/span&gt;})
requests.put(&lt;span class=&quot;hljs-string&quot;&gt;'http://httpbin.org/put'&lt;/span&gt;, data = {&lt;span class=&quot;hljs-string&quot;&gt;'key'&lt;/span&gt;:&lt;span class=&quot;hljs-string&quot;&gt;'value'&lt;/span&gt;})
requests.delete(&lt;span class=&quot;hljs-string&quot;&gt;'http://httpbin.org/delete'&lt;/span&gt;)
requests.head(&lt;span class=&quot;hljs-string&quot;&gt;'http://httpbin.org/get'&lt;/span&gt;)
requests.options(&lt;span class=&quot;hljs-string&quot;&gt;'http://httpbin.org/get'&lt;/span&gt;)
&lt;/code&gt;
&lt;/pre&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;注：httpbin.org是一个测试http请求的网站，能正常回应请求&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;对于HTTP的几种请求方法，没做过RestFul API的同学并不是很清楚每个请求方式表达的含义，这里给大家列一下：&lt;/p&gt;
&lt;p&gt;想了解requests更多使用方法请参考：&lt;a href=&quot;http://cn.python-requests.org/&quot;&gt;http://cn.python-requests.org&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;后面猪哥也会用大量案例来一点一点学习requests库的一些使用技巧。&lt;img src=&quot;https://img2018.cnblogs.com/blog/1599951/201907/1599951-20190707171955717-1957733716.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;h2 id=&quot;-&quot;&gt;七、总结&lt;/h2&gt;
&lt;p&gt;今天为大家简单介绍了一下这个非常重要的库：requests，requests可以胜任很多简单的爬虫需求，它强大的功能以及优美的api得到一致的认同。&lt;/p&gt;
&lt;p&gt;有人多同学会问：爬虫到什么境界才算是入门？&lt;strong&gt;你会熟练使用requests库去实现一些简单的爬虫功能就算入门&lt;/strong&gt;，并不是说需要会各种框架才算是入门，相反能使用低级工具实现功能的才更具潜力！&lt;/p&gt;
&lt;p&gt;如果你有 有趣的爬虫案例或者想法，务必在下方留言，让我看看你们的骚操作。&lt;/p&gt;

&lt;p&gt;​&lt;/p&gt;
</description>
<pubDate>Mon, 08 Jul 2019 00:51:00 +0000</pubDate>
<dc:creator>猪哥66</dc:creator>
<og:description>第一章主要讲解爬虫相关的知识如：http、网页、爬虫法律等，让大家对爬虫有了一个比较完善的了解和一些题外的知识点。 今天这篇文章将是我们第二章的第一篇，我们从今天开始就正式进入实战阶段，后面将会有更多</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/pig66/p/11146898.html</dc:identifier>
</item>
<item>
<title>跟我学SpringCloud | 第八篇：Spring Cloud Bus 消息总线 - 极客挖掘机</title>
<link>http://www.cnblogs.com/babycomeon/p/11141160.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/babycomeon/p/11141160.html</guid>
<description>&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;Springboot: 2.1.6.RELEASE&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;SpringCloud: Greenwich.SR1&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;如无特殊说明，本系列教程全采用以上版本&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;前面两篇文章我们聊了Spring Cloud Config配置中心，当我们在更新github上面的配置以后，如果想要获取到最新的配置，需要手动刷新或者利用webhook的机制每次提交代码发送请求来刷新客户端，客户端越来越多的时候，需要每个客户端都执行一遍，这种方案就不太适合了。使用Spring Cloud Bus（国人很形象的翻译为消息总线，我比较喜欢叫消息巴士）可以完美解决这一问题。&lt;/p&gt;
&lt;h2 id=&quot;spring-cloud-bus&quot;&gt;1. Spring Cloud Bus&lt;/h2&gt;
&lt;p&gt;Spring cloud bus通过轻量消息代理连接各个分布的节点。这会用在广播状态的变化（例如配置变化）或者其他的消息指令。Spring bus的一个核心思想是通过分布式的启动器对spring boot应用进行扩展，也可以用来建立一个多个应用之间的通信频道。目前唯一实现的方式是用AMQP消息代理作为通道，同样特性的设置（有些取决于通道的设置）在更多通道的文档中。&lt;/p&gt;
&lt;p&gt;大家可以将它理解为管理和传播所有分布式项目中的消息既可，其实本质是利用了MQ的广播机制在分布式的系统中传播消息，目前常用的有Kafka和RabbitMQ。利用bus的机制可以做很多的事情，其中配置中心客户端刷新就是典型的应用场景之一，我们用一张图来描述bus在配置中心使用的机制。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://springcloud-oss.oss-cn-shanghai.aliyuncs.com/chapter8/configbus1.jpg&quot;/&gt;&lt;/p&gt;
&lt;p&gt;根据此图我们可以看出利用Spring Cloud Bus做配置更新的步骤:&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;提交代码触发post给客户端A发送bus/refresh&lt;/li&gt;
&lt;li&gt;客户端A接收到请求从Server端更新配置并且发送给Spring Cloud Bus&lt;/li&gt;
&lt;li&gt;Spring Cloud bus接到消息并通知给其它客户端&lt;/li&gt;
&lt;li&gt;其它客户端接收到通知，请求Server端获取最新配置&lt;/li&gt;
&lt;li&gt;全部客户端均获取到最新的配置&lt;/li&gt;
&lt;/ol&gt;&lt;h2 id=&quot;项目示例&quot;&gt;2. 项目示例&lt;/h2&gt;
&lt;p&gt;我们使用上一篇文章中的config-server和config-client来进行改造，mq使用rabbitmq来做示例。&lt;/p&gt;
&lt;h3 id=&quot;客户端config-client&quot;&gt;2.1 客户端config-client&lt;/h3&gt;
&lt;h4 id=&quot;添加依赖&quot;&gt;2.1.1 添加依赖&lt;/h4&gt;
&lt;pre&gt;
&lt;code&gt;&amp;lt;dependency&amp;gt;
    &amp;lt;groupId&amp;gt;org.springframework.cloud&amp;lt;/groupId&amp;gt;
    &amp;lt;artifactId&amp;gt;spring-cloud-starter-bus-amqp&amp;lt;/artifactId&amp;gt;
&amp;lt;/dependency&amp;gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;需要多引入spring-cloud-starter-bus-amqp包，增加对消息总线的支持&lt;/p&gt;
&lt;h4 id=&quot;配置文件-bootstrap.properties&quot;&gt;2.1.2 配置文件 bootstrap.properties&lt;/h4&gt;
&lt;pre&gt;
&lt;code&gt;spring.application.name=spring-cloud-config-client
server.port=8081

spring.cloud.config.name=springcloud-config
spring.cloud.config.profile=dev
spring.cloud.config.label=master
spring.cloud.config.discovery.enabled=true
spring.cloud.config.discovery.serviceId=spring-cloud-config-server

eureka.client.service-url.defaultZone=http://localhost:8761/eureka/

management.endpoints.web.exposure.include=*

## 开启消息跟踪
spring.cloud.bus.trace.enabled=true

spring.rabbitmq.host=127.0.0.1
spring.rabbitmq.port=5672
spring.rabbitmq.username=
spring.rabbitmq.password=&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;配置文件需要增加RebbitMq的相关配置，这样客户端代码就改造完成了。&lt;/p&gt;
&lt;h4 id=&quot;测试&quot;&gt;2.1.3 测试&lt;/h4&gt;
&lt;p&gt;依次启动eureka，config-serve，config-client。&lt;/p&gt;
&lt;p&gt;修改config-client启动配置，同时在8081和8082端口启动服务。&lt;/p&gt;
&lt;p&gt;启动完成后，浏览器分别访问连接：&lt;a href=&quot;http://localhost:8081/hello&quot; class=&quot;uri&quot;&gt;http://localhost:8081/hello&lt;/a&gt;， &lt;a href=&quot;http://localhost:8082/hello&quot; class=&quot;uri&quot;&gt;http://localhost:8082/hello&lt;/a&gt;， 可以发现页面显示的内容都是：hello dev update1，说明客户端都已经读取到了server端的内容。&lt;/p&gt;
&lt;p&gt;现在我们更新github上的配置文件，将配置内容改为hello dev update，先访问一下http://localhost:8081/hello，可以看到页面依然显示为：hello dev update1。&lt;/p&gt;
&lt;p&gt;我们对端口为8081的服务发送一个/actuator/bus-refresh的POST请求，在win10下使用下面命令来模拟webhook。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;curl -X POST http://localhost:8081/actuator/bus-refresh&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;注意：&lt;/strong&gt; 在springboot2.x的版本中刷新路径为：/actuator/bus-refresh，在springboot1.5.x的版本中刷新路径为：/bus/refresh。&lt;/p&gt;
&lt;p&gt;执行完成后，我们先访问http://localhost:8082/hello，可以看到页面打印内容已经变为：hello dev update，这样说明，我们8081端口的服务已经把更新后的信息通过rabbitmq推送给了8082端口的服务，这样我们就实现了图一中的示例。&lt;/p&gt;
&lt;h3 id=&quot;改进版&quot;&gt;2.2 改进版&lt;/h3&gt;
&lt;p&gt;上面的流程中，虽然我们做到了利用一个消息总线触发刷新，而刷新所有客户端配置的目的，但是这种方式并不合适，如下：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;打破了微服务的职责单一性。微服务本身是业务模块，它本不应该承担配置刷新的职责。&lt;/li&gt;
&lt;li&gt;破坏了微服务各节点的对等性。&lt;/li&gt;
&lt;li&gt;如果客户端ip有变化，这时我们就需要修改WebHook的配置。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;我们可以将上面的流程改进一下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://springcloud-oss.oss-cn-shanghai.aliyuncs.com/chapter8/configbus2.jpg&quot;/&gt;&lt;/p&gt;
&lt;p&gt;这时Spring Cloud Bus做配置更新步骤如下:&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;提交代码触发post给Server端发送bus/refresh&lt;/li&gt;
&lt;li&gt;Server端接收到请求并发送给Spring Cloud Bus&lt;/li&gt;
&lt;li&gt;Spring Cloud bus接到消息并通知给其它客户端&lt;/li&gt;
&lt;li&gt;其它客户端接收到通知，请求Server端获取最新配置&lt;/li&gt;
&lt;li&gt;全部客户端均获取到最新的配置&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;这样的话我们在server端的代码做一些改动，来支持/actuator/bus-refresh&lt;/p&gt;
&lt;p&gt;和上面的client端的改动基本一致&lt;/p&gt;
&lt;h4 id=&quot;添加依赖-1&quot;&gt;2.2.1 添加依赖&lt;/h4&gt;
&lt;pre&gt;
&lt;code&gt;&amp;lt;dependency&amp;gt;
    &amp;lt;groupId&amp;gt;org.springframework.cloud&amp;lt;/groupId&amp;gt;
    &amp;lt;artifactId&amp;gt;spring-cloud-starter-bus-amqp&amp;lt;/artifactId&amp;gt;
&amp;lt;/dependency&amp;gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;需要多引入spring-cloud-starter-bus-amqp包，增加对消息总线的支持&lt;/p&gt;
&lt;h4 id=&quot;配置文件application.yml&quot;&gt;2.2.2 配置文件application.yml&lt;/h4&gt;
&lt;pre&gt;
&lt;code&gt;server:
  port: 8080
spring:
  application:
    name: spring-cloud-config-server
  cloud:
    config:
      server:
        git:
          uri: https://github.com/meteor1993/SpringCloudLearning
          search-paths: chapter6/springcloud-config
          username: 
          password: 
  rabbitmq:
    host: 217.0.0。1
    port: 5672
    username: 
    password: 
management:
  endpoints:
    web:
      exposure:
        include: &quot;*&quot;
eureka:
  client:
    service-url:
      defaultZone: http://localhost:8761/eureka/&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;配置文件需要增加RebbitMq的相关配置，actuator开启所有访问。&lt;/p&gt;
&lt;h4 id=&quot;测试-1&quot;&gt;2.2.3 测试&lt;/h4&gt;
&lt;p&gt;依次启动eureka，config-serve，config-client。&lt;/p&gt;
&lt;p&gt;修改config-client启动配置，同时在8081和8082端口启动服务。&lt;/p&gt;
&lt;p&gt;按照上面的测试方式，访问两个客户端测试均可以正确返回信息。同样修改配置文件，将值改为：hello im dev update并提交到仓库中。在win10下使用下面命令来模拟webhook。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;curl -X POST http://localhost:8081/actuator/bus-refresh&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;执行完成后，依次访问两个客户端，返回：hello im dev update。说明三个客户端均已经拿到了最新配置文件的信息，这样我们就实现了上图中的示例。&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/meteor1993/SpringCloudLearning/tree/master/chapter8&quot; title=&quot;示例代码-Github&quot;&gt;示例代码-Github&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;参考：&lt;a href=&quot;http://www.ityouknow.com/springcloud/2017/05/26/springcloud-config-eureka-bus.html&quot; class=&quot;uri&quot;&gt;http://www.ityouknow.com/springcloud/2017/05/26/springcloud-config-eureka-bus.html&lt;/a&gt;&lt;/p&gt;
</description>
<pubDate>Mon, 08 Jul 2019 00:40:00 +0000</pubDate>
<dc:creator>极客挖掘机</dc:creator>
<og:description>SpringCloud系列教程 | 第八篇：Spring Cloud Bus 消息总线 Springboot: 2.1.6.RELEASE SpringCloud: Greenwich.SR1 如无特</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/babycomeon/p/11141160.html</dc:identifier>
</item>
<item>
<title>kubernetes实战篇之docker镜像的打包与加载 - 周国通</title>
<link>http://www.cnblogs.com/tylerzhou/p/11149139.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/tylerzhou/p/11149139.html</guid>
<description>&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&quot;https://www.cnblogs.com/tylerzhou/p/11100649.html&quot;&gt;系列目录&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;前面我们讲到了使用nexus搭建docker镜像仓库,操作还是有点复杂的,可能有的童鞋仅仅是想尝试kubernetes功能,并不想在搭建仓库上花费过多时间,但是又想在不同的主机之间传递镜像.其实可以通过&lt;code&gt;docker save&lt;/code&gt;命令来实现,通过docker save把一个镜像保存为&lt;code&gt;tar&lt;/code&gt;格式压缩文件,然后在要使用这个镜像机器上执行&lt;code&gt;docker load&lt;/code&gt;命令来加载这个镜像.&lt;/p&gt;
&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;复制文件的方式不方便对文件进行版本管理,大家为了方便测试可以这样玩玩,强烈建议生产环境中不要这么做.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;通过docker-save保存镜像为文件&quot;&gt;通过docker save保存镜像为文件&lt;/h2&gt;
&lt;p&gt;docker save命令的格式如下&lt;/p&gt;
&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;docker save -o &amp;lt;path for generated tar file&amp;gt; &amp;lt;image name&amp;gt;&amp;lt;/image&amp;gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;ul readability=&quot;1&quot;&gt;&lt;li readability=&quot;3&quot;&gt;
&lt;p&gt;-o或者--output,指定输出文件(tar格式)的位置,这里的位置不仅仅是要输出的目录,还包括要保存的tar文件的名称&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;image name 要保存的镜像的名称&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;例如,以下命令把alpine:latest镜像保存为名为alpine.tar文件(保存位置为当前目录,也可以通过指定绝对路径把镜像保存到指定位置)&lt;/p&gt;
&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;docker save -o alpine.tar alpine:latest&lt;/code&gt;
&lt;/pre&gt;
&lt;blockquote readability=&quot;9&quot;&gt;
&lt;p&gt;保存为文件以后,我们就可以通过cp,scp,ftp等工具把镜像文件复制到目标电脑上&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;通过docker-load加载保存的tar文件&quot;&gt;通过docker load加载保存的tar文件&lt;/h2&gt;
&lt;p&gt;命令格式如下:&lt;/p&gt;
&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;docker load -i &amp;lt;path to image tar file&amp;gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;-i同--input,指定一个tar文件&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;我们执行命令&lt;code&gt;docker load -i alpine.tar&lt;/code&gt;就可以在目标机器上加载我们保存的alpine镜像了.&lt;/p&gt;
&lt;h2 id=&quot;使用docker-exportimport来打包加载镜像&quot;&gt;使用docker export/import来打包/加载镜像&lt;/h2&gt;
&lt;p&gt;使用docker export/import与使用docker save/load用法类似,不同的是docker save是把一个镜像保存为tar文件,而docker export是把一个运行的容器的文件系统的快照保存为压缩文件,通过docker import从导出的文件系统中创建一个镜像&lt;/p&gt;
&lt;blockquote readability=&quot;13&quot;&gt;
&lt;p&gt;注意,docker import并不是把导出的容器还原,而是从中生成一个镜像.&lt;br/&gt;通过docker import 导入的镜像将丢失所有元数据和历史记录,实际项目中我们并不关心容器的历史记录和元数据,我们关系的是应用程序的正常运行的优化,使用这种方式生成的镜像一定程度上减小了镜像的体积.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;&lt;li&gt;docker export 导出容器为压缩文件&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;命令格式如下:&lt;/p&gt;
&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;docker export -o &amp;lt;path for generated tar file&amp;gt; &amp;lt;container name&amp;gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;此命令类似于docker save,指定要输出的文件路径和文件名,后面跟上要导出的容器的名称或者id&lt;/p&gt;
&lt;p&gt;例如通过&lt;code&gt;docker export -o alpine.tar c054&lt;/code&gt;把一个运行的容器(id开头为c054)导出为文件.&lt;/p&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;我们可以查看生成的alpine.tar文件,里面其实是一个linux文件系统&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;&lt;li&gt;docker import 把导出的文件系统导入为镜像&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;我们通过命令&lt;code&gt;docker import alpine.tar myalpine&lt;/code&gt;把刚导出的容器文件系统导出为镜像,并且命名为&lt;code&gt;myalpine&lt;/code&gt;&lt;/p&gt;
&lt;blockquote readability=&quot;9&quot;&gt;
&lt;p&gt;注,这里与docker load不同的是这里不需要&lt;code&gt;-i&lt;/code&gt;来指定input对象,而是直接跟要导入的对象,并且可以给导入的镜像命名.&lt;/p&gt;
&lt;/blockquote&gt;
</description>
<pubDate>Mon, 08 Jul 2019 00:27:00 +0000</pubDate>
<dc:creator>周国通</dc:creator>
<og:description>'系列目录' 前面我们讲到了使用nexus搭建docker镜像仓库,操作还是有点复杂的,可能有的童鞋仅仅是想尝试kubernetes功能,并不想在搭建仓库上花费过多时间,但是又想在不同的主机之间传递镜</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/tylerzhou/p/11149139.html</dc:identifier>
</item>
<item>
<title>使用Jenkins部署.Net Core遇到的几个坑 - 张飞洪</title>
<link>http://www.cnblogs.com/jackyfei/p/11146353.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/jackyfei/p/11146353.html</guid>
<description>&lt;blockquote readability=&quot;7&quot;&gt;
&lt;p class=&quot;ql-long-13832613&quot; data-header=&quot;1&quot;&gt;搞过CI/CD的同学一定吃过不少苦头，或者说遇到不少坑，但是对自动化的执着住挡不了前进的步伐，如果你缺少了运维这一块知识，那么你的流水线总是不那么完美，本文记录的是自己躺过的坑，希望对你有所帮助。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;&lt;li&gt;&lt;span class=&quot;ql-author-13832613&quot;&gt;服务器：windows2008【历史遗留服务器，建议升级到2012以上，2016支持Windows的容器化技术】&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&quot;ql-author-13832613&quot;&gt;源代码管理：git&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&quot;ql-author-13832613&quot;&gt;.net core版本：net core 2.2&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;span class=&quot;ql-author-13832613&quot;&gt;　　这里最应该注意的是操作系统版本和Jenkins的版本，不同的版本，特别是操作系统操作的shell可能千差万别，你会在网上看到各种命令，所以选择好自己的环境。&lt;/span&gt;&lt;/p&gt;
&lt;p class=&quot;ql-long-13832613&quot;&gt;&lt;a class=&quot;ql-link ql-author-13832613&quot; href=&quot;https://jenkins.io/zh/&quot; rel=&quot;noopener noreferrer nofollow&quot; target=&quot;_blank&quot;&gt;安装Jenkins&lt;/a&gt;&lt;span class=&quot;ql-author-13832613&quot;&gt;比较简单，这里略过……&lt;/span&gt;&lt;/p&gt;

&lt;p class=&quot;ql-long-13832613&quot;&gt;&lt;strong class=&quot;ql-author-13832613&quot;&gt;Step1.创建一个自由风格的Jenkins项目，这一步比较简单略过（pipeline项目是一项更加挑战，也许运维高手更需要熟悉，这里跳过）&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong class=&quot;ql-author-13832613&quot;&gt;Step2.在&lt;/strong&gt;&lt;strong class=&quot;ql-author-13832613 ql-size-14&quot;&gt;配置git&lt;/strong&gt;&lt;strong class=&quot;ql-author-13832613&quot;&gt;源码路径的时候报错：&lt;/strong&gt;&lt;/p&gt;
&lt;p class=&quot;ql-long-13832613&quot;&gt;&lt;span class=&quot;ql-author-13832613&quot;&gt;&lt;img src=&quot;https://uploader.shimo.im/f/nOx5QuBxwmUnBcgK.png!thumbnail&quot; alt=&quot;&quot; width=&quot;786&quot; height=&quot;auto&quot;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p class=&quot;ql-long-13832613&quot;&gt;&lt;strong class=&quot;ql-author-13832613&quot;&gt;解决方法&lt;/strong&gt;&lt;span class=&quot;ql-author-13832613&quot;&gt;：&lt;/span&gt;&lt;/p&gt;
&lt;p class=&quot;ql-long-13832613&quot;&gt;&lt;span class=&quot;ql-author-13832613&quot;&gt;1.安装git client插件，并重启jenkins&lt;/span&gt;&lt;/p&gt;
&lt;p class=&quot;ql-long-13832613&quot;&gt;&lt;span class=&quot;ql-author-13832613&quot;&gt;2.确保安装jenkins的服务器同时也安装了git，并在jenkins上配置git的路径，如下图：&lt;/span&gt;&lt;/p&gt;
&lt;p class=&quot;ql-long-13832613&quot;&gt;&lt;span class=&quot;ql-author-13832613&quot;&gt;&lt;img src=&quot;https://uploader.shimo.im/f/NJmlyJbne6M3wbjE.png!thumbnail&quot; alt=&quot;&quot; width=&quot;776&quot; height=&quot;auto&quot;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p class=&quot;ql-long-13832613&quot;&gt;&lt;span class=&quot;ql-author-13832613&quot;&gt;3.成功配置git源码路径&lt;/span&gt;&lt;/p&gt;
&lt;p class=&quot;ql-long-13832613&quot;&gt;&lt;span class=&quot;ql-author-13832613&quot;&gt;&lt;img src=&quot;https://uploader.shimo.im/f/rtmeZF6n3yQabCOH.png!thumbnail&quot; alt=&quot;&quot; width=&quot;780&quot; height=&quot;auto&quot;/&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p class=&quot;ql-long-13832613&quot;&gt;&lt;strong class=&quot;ql-author-13832613&quot;&gt;Step3.构建时候报错：&lt;/strong&gt;&lt;/p&gt;
&lt;p class=&quot;ql-long-13832613&quot;&gt;&lt;span class=&quot;ql-author-13832613&quot;&gt;&lt;img src=&quot;https://uploader.shimo.im/f/piCzn4DfIaoyxrdp.png!thumbnail&quot; alt=&quot;&quot; width=&quot;1153&quot; height=&quot;auto&quot;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p class=&quot;ql-long-13832613&quot;&gt;&lt;span class=&quot;ql-author-13832613&quot;&gt;从中可以判断，我的邮件还没有配置，所以发送报错……&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong class=&quot;ql-author-13832613&quot;&gt;Step4.进行&lt;/strong&gt;&lt;strong class=&quot;ql-author-13832613 ql-size-14&quot;&gt;邮件的配置&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;
&lt;h3&gt;&lt;span class=&quot;ql-author-13832613&quot;&gt;Jenkins内置邮箱功能：&lt;/span&gt;&lt;/h3&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;p class=&quot;ql-long-13832613&quot;&gt;&lt;span class=&quot;ql-author-13832613&quot;&gt;1.首先配置Jenkins Location&lt;/span&gt;&lt;/p&gt;
&lt;p class=&quot;ql-long-13832613&quot;&gt;&lt;span class=&quot;ql-author-13832613&quot;&gt;所在路径：Manage Jenkins=》Configure System=&amp;gt;Jenkins Location&lt;/span&gt;&lt;/p&gt;
&lt;p class=&quot;ql-long-13832613&quot;&gt;&lt;span class=&quot;ql-author-13832613&quot;&gt;&lt;img src=&quot;https://uploader.shimo.im/f/lKf2JnaWWiIGn3Dl.png!thumbnail&quot; alt=&quot;&quot; width=&quot;536&quot; height=&quot;auto&quot;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p class=&quot;ql-long-13832613&quot;&gt;&lt;span class=&quot;ql-author-13832613&quot;&gt;2.配置E-mail Notification如下图所示&lt;/span&gt;&lt;/p&gt;
&lt;p class=&quot;ql-long-13832613&quot;&gt;&lt;span class=&quot;ql-author-13832613&quot;&gt;&lt;img src=&quot;https://uploader.shimo.im/f/CgU2QAb9v7A7pXuO.png!thumbnail&quot; alt=&quot;&quot; width=&quot;636&quot; height=&quot;auto&quot;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p class=&quot;ql-long-13832613&quot;&gt;&lt;span class=&quot;ql-author-13832613&quot;&gt;3.测试发送成功&lt;/span&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;
&lt;h3&gt;&lt;span class=&quot;ql-author-13832613&quot;&gt;Email插件：Email Extension&lt;/span&gt;&lt;/h3&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;p class=&quot;ql-text-indent-1 ql-long-13832613&quot;&gt;&lt;span class=&quot;ql-author-13832613&quot;&gt;插件安装后如下图所示：&lt;/span&gt;&lt;/p&gt;
&lt;p class=&quot;ql-long-13832613&quot;&gt;&lt;span class=&quot;ql-author-13832613&quot;&gt;&lt;img src=&quot;https://uploader.shimo.im/f/Ju4yG6pKUPMkz0Uu.png!thumbnail&quot; alt=&quot;&quot; width=&quot;436&quot; height=&quot;auto&quot;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;ql-author-13832613&quot;&gt;step5.构建的坑[该坑最耗时间，最后发现却是最简单]&lt;/span&gt;&lt;/p&gt;
&lt;p class=&quot;ql-long-13832613&quot;&gt;&lt;strong class=&quot;ql-author-13832613&quot;&gt;1.请指定项目或解决方案文件。当前工作目录中未包含项目或解决方案文件。&lt;/strong&gt;&lt;/p&gt;
&lt;p class=&quot;ql-long-13832613&quot;&gt;&lt;span class=&quot;ql-author-13832613&quot;&gt;&lt;img src=&quot;https://uploader.shimo.im/f/fsNq9bm3z9MgtmeI.png!thumbnail&quot; alt=&quot;&quot; width=&quot;724&quot; height=&quot;auto&quot;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p class=&quot;ql-long-13832613&quot;&gt;&lt;span class=&quot;ql-author-13832613&quot;&gt;排查：切换到服务器cmd下进行restore后发现，原来是nuget作怪，因为服务器无法找到部署在本地服务器的nuget包&lt;/span&gt;&lt;/p&gt;
&lt;p class=&quot;ql-long-13832613&quot;&gt;&lt;span class=&quot;ql-author-13832613&quot;&gt;&lt;img src=&quot;https://uploader.shimo.im/f/mkZW5RapyH4w6MF6.png!thumbnail&quot; alt=&quot;&quot; width=&quot;650&quot; height=&quot;auto&quot;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;ql-author-13832613&quot;&gt;2.发布Nuget包到官网&lt;/span&gt;&lt;/p&gt;
&lt;p class=&quot;ql-long-13832613&quot;&gt;&lt;span class=&quot;ql-author-13832613&quot;&gt;试着解决：试着把nuget包发布到官网。具体如何发布请&lt;a class=&quot;ql-link ql-author-13832613&quot; href=&quot;https://www.cnblogs.com/stulzq/p/8874426.html&quot; rel=&quot;noopener noreferrer nofollow&quot; target=&quot;_blank&quot;&gt;跳转&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p class=&quot;ql-long-13832613&quot;&gt;&lt;span class=&quot;ql-author-13832613&quot;&gt;新版本的发布需要增加License.txt，否则无法通过，配置如下：其中Licese是从&lt;a class=&quot;ql-link ql-author-13832613&quot; href=&quot;https://github.com/Nuget/Samples&quot; rel=&quot;noopener noreferrer nofollow&quot; target=&quot;_blank&quot;&gt;github&lt;/a&gt;&lt;span class=&quot;ql-author-13832613&quot;&gt;上拷贝过来的。&lt;strong class=&quot;ql-author-13832613&quot;&gt;&lt;span&gt;如果你发布后发现代码没有生效，请确认你是否在release下进行编译，并且build过？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p class=&quot;ql-long-13832613&quot;&gt;&lt;span class=&quot;ql-author-13832613&quot;&gt;&lt;img src=&quot;https://uploader.shimo.im/f/lI6PlerYyww9h1yo.png!thumbnail&quot; alt=&quot;&quot; width=&quot;676&quot; height=&quot;auto&quot;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt; &lt;strong class=&quot;ql-author-13832613&quot;&gt;解决方法&lt;/strong&gt;&lt;span class=&quot;ql-author-13832613&quot;&gt;：如下图所示，极其简单，折腾的半天，晕！你甚至dotnet restore和dotnet build都不用写，因为dotnet publish本身包含restore和build&lt;/span&gt;&lt;/p&gt;
&lt;p class=&quot;ql-long-13832613&quot;&gt;&lt;span class=&quot;ql-author-13832613&quot;&gt;&lt;img src=&quot;https://uploader.shimo.im/f/DNWGrX7wk5kqOPu7.png!thumbnail&quot; alt=&quot;&quot; width=&quot;903&quot; height=&quot;auto&quot;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong class=&quot;ql-author-13832613&quot;&gt;Step6.&lt;/strong&gt;&lt;span class=&quot;ql-author-13832613&quot;&gt;卡住在using GIT_ASKPASS to set credentials&lt;strong class=&quot;ql-author-13832613&quot;&gt;的坑&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p class=&quot;ql-long-13832613&quot;&gt;&lt;span class=&quot;ql-author-13832613&quot;&gt;Unable to delete 'D:\Program Files (x86)\Jenkins\workspace\Stone.Base.API'. Tried 3 times (of a maximum of 3) waiting 0.1 秒 between attempts.&lt;/span&gt;&lt;/p&gt;
&lt;p class=&quot;ql-long-13832613&quot;&gt;&lt;strong class=&quot;ql-author-13832613&quot;&gt;解决方法&lt;/strong&gt;&lt;span class=&quot;ql-author-13832613&quot;&gt;：关闭配置里的删除功能&lt;/span&gt;&lt;/p&gt;
&lt;p class=&quot;ql-long-13832613&quot;&gt;&lt;span class=&quot;ql-author-13832613&quot;&gt;6.构建的时候卡住在using GIT_ASKPASS to set credentials &lt;/span&gt;&lt;/p&gt;
&lt;p class=&quot;ql-long-13832613&quot;&gt;&lt;a class=&quot;ql-link ql-author-13832613&quot; href=&quot;https://dotblogs.com.tw/milkgreenteaprograme_c_sharp/2018/01/09/002251&quot; rel=&quot;noopener noreferrer nofollow&quot; target=&quot;_blank&quot;&gt;&lt;strong&gt;解决方法&lt;/strong&gt;&lt;/a&gt;&lt;a class=&quot;ql-link ql-author-13832613&quot; href=&quot;https://dotblogs.com.tw/milkgreenteaprograme_c_sharp/2018/01/09/002251&quot; rel=&quot;noopener noreferrer nofollow&quot; target=&quot;_blank&quot;&gt;：&lt;/a&gt;&lt;/p&gt;
&lt;p class=&quot;ql-long-13832613&quot;&gt;&lt;span class=&quot;ql-author-13832613&quot;&gt;Step 1:開始 -&amp;gt; 命令提示字元 -&amp;gt; 滑鼠右鍵 -&amp;gt; 以系統管理員身分執行&lt;/span&gt;&lt;/p&gt;
&lt;p class=&quot;ql-long-13832613&quot;&gt;&lt;span class=&quot;ql-author-13832613&quot;&gt;Step 2: 找出Jenkins Server 的Git 布置位置，可以從自己的Jenkins 錯誤中知道位置在哪裡，以下是第一張圖顯示的Git &lt;/span&gt;&lt;/p&gt;
&lt;p class=&quot;ql-long-13832613&quot;&gt;&lt;span class=&quot;ql-author-13832613&quot;&gt;Step3: 將命令提示字元(管理者權限) 移動到該位置，輸入cd C:\Program Files\Git\bin 移動到該目錄&lt;/span&gt;&lt;/p&gt;
&lt;p class=&quot;ql-long-13832613&quot;&gt;&lt;span class=&quot;ql-author-13832613&quot;&gt;Step 4: 輸入 git config --system --unset credential.helper ，按下Enter&lt;/span&gt;&lt;/p&gt;
&lt;p class=&quot;ql-long-13832613&quot;&gt;&lt;span class=&quot;ql-author-13832613&quot;&gt;Step 5: 再重新建置Jenkins Job 就可以正常運行了&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong class=&quot;ql-author-13832613&quot;&gt;Step7.&lt;/strong&gt;&lt;span class=&quot;ql-author-13832613&quot;&gt;无法复制的坑&lt;/span&gt;&lt;/p&gt;
&lt;p class=&quot;ql-long-13832613&quot;&gt;&lt;span class=&quot;ql-author-13832613&quot;&gt;现象：无法将“obj\Debug\netcoreapp2.2\Stone.Base.API.dll”复制到“E:\Jacky\WebAPI\Base.API\Stone.Base.API.dll”&lt;/span&gt;&lt;/p&gt;
&lt;p class=&quot;ql-long-13832613&quot;&gt;&lt;span class=&quot;ql-author-13832613&quot;&gt;&lt;img src=&quot;https://uploader.shimo.im/f/H7jZrxOtFDwSOQt2.png!thumbnail&quot; alt=&quot;&quot; width=&quot;856&quot; height=&quot;auto&quot;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p class=&quot;ql-long-13832613&quot;&gt;&lt;span class=&quot;ql-author-13832613&quot;&gt;原因：该站点正在运行，dll被占用，无法进行替换覆盖&lt;/span&gt;&lt;/p&gt;
&lt;p class=&quot;ql-long-13832613&quot;&gt;&lt;strong class=&quot;ql-author-13832613&quot;&gt;解决方法&lt;/strong&gt;&lt;span class=&quot;ql-author-13832613&quot;&gt;：&lt;/span&gt;&lt;/p&gt;
&lt;p class=&quot;ql-long-13832613&quot;&gt;　　目前暂时还没有找到方法，后面再做补充……&lt;/p&gt;
&lt;p&gt;&lt;strong class=&quot;ql-author-13832613&quot;&gt;Step8.无法删除的坑&lt;/strong&gt;&lt;/p&gt;
&lt;p class=&quot;ql-long-13832613&quot;&gt;&lt;span class=&quot;ql-author-13832613&quot;&gt;&lt;img src=&quot;https://uploader.shimo.im/f/CnGoPFnZg6o06H0A.png!thumbnail&quot; alt=&quot;&quot; width=&quot;934&quot; height=&quot;auto&quot;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p class=&quot;ql-long-13832613&quot;&gt;&lt;span class=&quot;ql-author-13832613&quot;&gt;原因：该站点正在运行，无法进行替换覆盖&lt;/span&gt;&lt;/p&gt;
&lt;p class=&quot;ql-long-13832613&quot;&gt;&lt;strong class=&quot;ql-author-13832613&quot;&gt;解决方法&lt;/strong&gt;&lt;span class=&quot;ql-author-13832613&quot;&gt;：把&lt;span class=&quot;ql-author-13832613&quot;&gt;Delete workspace before build starts选项勾去掉，如下图：&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p class=&quot;ql-long-13832613&quot;&gt;&lt;span class=&quot;ql-author-13832613&quot;&gt;&lt;img src=&quot;https://uploader.shimo.im/f/QcBmWjX1IEQSCGWd.png!thumbnail&quot; alt=&quot;&quot; width=&quot;420&quot; height=&quot;auto&quot;/&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p class=&quot;ql-text-indent-1 ql-long-13832613&quot;&gt;&lt;span class=&quot;ql-author-13832613&quot;&gt;　　这里的发布改进了以往的手工发布。从代码上传那一刻开始，jenkins自动到git抓取代码，自动编译打包，然后上传到nuget服务器。&lt;/span&gt;&lt;/p&gt;
&lt;p class=&quot;ql-text-indent-1 ql-long-13832613&quot;&gt;&lt;span class=&quot;ql-author-13832613&quot;&gt;jenkins配置如下：这里有很多坑，特别是linux和windows很不一样，同学们要留意。配置其实不麻烦，所有的jenkins编译都可以在系统内部自行跑一遍，如果系统能跑通，jenkins绝对没有问题。具体配置如下图所示：&lt;/span&gt;&lt;/p&gt;
&lt;p class=&quot;ql-text-indent-1 ql-long-13832613&quot;&gt;&lt;span class=&quot;ql-author-13832613&quot;&gt;&lt;img src=&quot;https://uploader.shimo.im/f/6GA4npXmCMMdIAnE.png!thumbnail&quot; alt=&quot;&quot; width=&quot;1365&quot; height=&quot;auto&quot;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;35&quot;&gt;
&lt;pre&gt;
dotnet build &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;D:\Program Files (x86)\Jenkins\workspace\Stone.Util\UtilLib\Stone.Util&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;  -&lt;span&gt;c Release


md publish\nuget
md publish\archives


dotnet pack &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;D:\Program Files (x86)\Jenkins\workspace\Stone.Util\UtilLib\Stone.Util&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; -c Release -&lt;span&gt;o publish\nuget


dotnet nuget push &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;D:\Program Files (x86)\Jenkins\workspace\Stone.Util\UtilLib\Stone.Util\publish\nuget\*.nupkg&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; -k {自己key} -s https:&lt;span&gt;//&lt;/span&gt;&lt;span&gt;api.nuget.org/v3/index.json&lt;/span&gt;
&lt;span&gt;

move &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;D:\Program Files (x86)\Jenkins\workspace\Stone.Util\UtilLib\Stone.Util\publish\nuget\*&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;D:\Program Files (x86)\Jenkins\workspace\Stone.Util\UtilLib\Stone.Util\publish\archiv&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p class=&quot;ql-text-indent-1&quot;&gt;&lt;strong&gt;参考文献：&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;&lt;li&gt;&lt;span class=&quot;ql-author-13832613&quot;&gt;Green Balls&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p class=&quot;ql-text-indent-1 ql-long-13832613&quot;&gt;&lt;span class=&quot;ql-author-13832613&quot;&gt;该插件让你的感官有了更好的提升，客官请看：&lt;/span&gt;&lt;/p&gt;
&lt;p class=&quot;ql-text-indent-1 ql-long-13832613&quot;&gt;&lt;span class=&quot;ql-author-13832613&quot;&gt;&lt;img src=&quot;https://uploader.shimo.im/f/xPn6mKiinlwurDP3.png!thumbnail&quot; alt=&quot;&quot; width=&quot;326&quot; height=&quot;auto&quot;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p class=&quot;ql-text-indent-1 ql-long-13832613&quot;&gt;&lt;span class=&quot;ql-author-13832613&quot;&gt;&lt;img src=&quot;https://uploader.shimo.im/f/gVpsRZ7oBZw3mX3y.png!thumbnail&quot; alt=&quot;&quot; width=&quot;260&quot; height=&quot;auto&quot;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;span class=&quot;ql-author-13832613&quot;&gt;Build Monitor View&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p class=&quot;ql-text-indent-1 ql-long-13832613&quot;&gt;&lt;span class=&quot;ql-author-13832613&quot;&gt;非常棒的构建看板，把团队信息透明度提升一个档次，再也不用听到前端开发在问：“有人在构建吗？”，客官请看：&lt;/span&gt;&lt;/p&gt;
&lt;p class=&quot;ql-text-indent-1 ql-long-13832613&quot;&gt;&lt;span class=&quot;ql-author-13832613&quot;&gt;&lt;img src=&quot;https://uploader.shimo.im/f/hrs9KfZqfH8gpxvB.png!thumbnail&quot; alt=&quot;&quot; width=&quot;705&quot; height=&quot;auto&quot;/&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span class=&quot;ql-author-13832613&quot;&gt;　　jenkins是如此强大，以至于今年来基本上一统CI、CD的江山，他的内容又是如此之多，足够写一本书，感叹所学只不过它的冰山一角。在pipeline项目中，它也支持python等其他脚本语言的流水化作业，功能非常之强大，期待后面的挖掘和丰富……&lt;/span&gt;&lt;/p&gt;




&lt;p class=&quot;ql-text-indent-1 ql-long-13832613&quot;&gt; &lt;/p&gt;

</description>
<pubDate>Mon, 08 Jul 2019 00:24:00 +0000</pubDate>
<dc:creator>张飞洪</dc:creator>
<og:description>搞过CI/CD的同学一定吃过不少苦头，或者说遇到不少坑，但是对自动化的执着住挡不了前进的步伐，如果你缺少了运维这一块知识，那么你的流水线总是不那么完美，本文记录的是自己躺过的坑，希望对你有所帮助。 一</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/jackyfei/p/11146353.html</dc:identifier>
</item>
<item>
<title>高性能微服务网关.NETCore客户端Kong.Net开源发布 - Ron.Liang</title>
<link>http://www.cnblogs.com/viter/p/11142940.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/viter/p/11142940.html</guid>
<description>&lt;h2 id=&quot;前言&quot;&gt;前言&lt;/h2&gt;
&lt;p&gt;项目地址：&lt;a href=&quot;https://github.com/lianggx/Kong.Net&quot; class=&quot;uri&quot;&gt;https://github.com/lianggx/Kong.Net&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;你的支持使我们更加强大，请单击 star 让更多的 .NETCore 认识它。&lt;/p&gt;
&lt;p&gt;拥抱开源的脚步，我们从来都是一直在路上；.NETCore作为后起之秀，带给我们太多的惊喜和感动；但是也正是由于年轻，.NETCore 的生态还是不够完善，这就非常需要我们社区的力量，需要大家一起参与，把开源社区好的工具、组件、应用接入到 .NETCore 应用中。&lt;/p&gt;
&lt;p&gt;他山之石，可以攻玉！&lt;/p&gt;
&lt;p&gt;在很多时候，我们想要在项目中引入高性能开源网关 Kong 的时候，苦于没有 .NETCore 客户端而放弃，Nuget 仓库曾经有一个 .NETFramework 版本的客户端，但是已经年久失修了，可见开源项目的维护极其不易。&lt;/p&gt;
&lt;h2 id=&quot;kong-是什么&quot;&gt;Kong 是什么？&lt;/h2&gt;
&lt;p&gt;Github 地址：&lt;a href=&quot;https://github.com/Kong/kong&quot; class=&quot;uri&quot;&gt;https://github.com/Kong/kong&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Kong 的 Logo 是金刚，是一个支持云原生应用的高性能网关，于 2015 年开源，其核心价值在于高性能和可扩展性，Kong 的贡献值高达 151 人，目前为止共有 5073 次代码提交记录，976 个关注，22353 个 star 和 2736 个fork；Kong 的有点非常多，特别是其基于 lua 编写，性能卓越，且具有平台无关性，还有丰富的第三方插件，以及用户体验良好的的仪表盘操作界面（Konga另一个开源作品），可以说，Kong 具备了一个优秀网关的所必须的所有能力，支持 docker 部署，使用 postgresql 进行数据持久化，高可扩展性，可轻松升级为服务网格方案，REST API 访问，非常灵活的接入控制方式。&lt;/p&gt;
&lt;h3 id=&quot;技术选型&quot;&gt;技术选型&lt;/h3&gt;
&lt;h4 id=&quot;consul&quot;&gt;Consul&lt;/h4&gt;
&lt;p&gt;我是由于在最近的技术选型中了解到 Kong 的，在此之前，我曾经考虑过 Nginx+Consul 方案（详情见我的博客），对 Consul 也进行了深入的了解和测试，但是由于 Consul 始终只是一个服务发现的组件，不具备网关能力，且维护复杂（脚本维护），虽然在 .NETCore 下接入非常的方便，但是还是只能放弃了。&lt;/p&gt;
&lt;h4 id=&quot;spring-cloud&quot;&gt;Spring-cloud&lt;/h4&gt;
&lt;p&gt;也考察了 Spring-cloud Gateway，Spring 大法好，特别是阿里的 Nacos 的支持和跟进，使得 Spring 占据了80%的江山（不知道我是否高估了），而且搭建 Spring Gateway 的步骤非常简单，一个小白，只要花2天时间，就能快速的搭建出一个 Spring-cloud Gateway，Java 的生态真的是让人垂涎欲滴，没办法，惯性太大了。同时，由于 Spring-cloud Gateway 的 .NetCore 客户端不提供（废话来的，人家是玩 Java 的），所以从成本上考虑，也得放弃。&lt;/p&gt;
&lt;h4 id=&quot;kong&quot;&gt;kong&lt;/h4&gt;
&lt;p&gt;终于还是选择了 Kong，Kong 的平台无关性和设计良好的 REST API ，让我们有机会快速的接入到这款高性能的网关中，我个人开发 Kong.Net 这款客户端，用时 3 天，REST API 共有 81 个 API，支持Kong：latest最新版本为1.2.x。&lt;/p&gt;
&lt;h2 id=&quot;kong.net&quot;&gt;Kong.Net&lt;/h2&gt;
&lt;h3 id=&quot;项目结构&quot;&gt;项目结构&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/26882/201907/26882-20190706154025834-1826196443.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;项目结构比较简单，就是一个标准的开源框架的样子，包含了 examples、src、test 三大块的内容，其中 src 包含两个项目 Kong/Kong.Extensions，单元测试一共有 80 个，已全部测试通过。&lt;/p&gt;
&lt;h3 id=&quot;使用-kong.net&quot;&gt;使用 Kong.Net&lt;/h3&gt;
&lt;p&gt;在 .NETCore 项目中使用 Kont.Net 非常简单，只需要在项目中进行 Nuget 包的引用即可，截止本文发文时，版本号为 Kong.Net-0.0.4。为了更方便的使用 Kong.Net ，建议同时引用 Kong.Extension-0.0.4 包，扩展包封装了一些初始化配置信息，比如健康检查路径和响应，非常方便。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/26882/201907/26882-20190706154032313-874376732.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;完全基于 .NetCore ，目前依赖 Json.Net&lt;/p&gt;
&lt;h3 id=&quot;在配置文件中加入以下配置以初始化客户端&quot;&gt;在配置文件中加入以下配置，以初始化客户端&lt;/h3&gt;
&lt;pre&gt;
&lt;code&gt;&quot;kong&quot;: {
    &quot;host&quot;: &quot;http://10.23.11.1:8001&quot;,
    &quot;upstream&quot;: {
      &quot;tags&quot;: [ &quot;example&quot;, &quot;low-priority&quot; ],
      &quot;name&quot;: &quot;Kong.Example&quot;,
      &quot;hash_on&quot;: &quot;none&quot;,
      &quot;healthchecks&quot;: {
        &quot;active&quot;: {
          &quot;unhealthy&quot;: {
            &quot;http_statuses&quot;: [ 429, 500, 501, 502, 503, 504, 505 ],
            &quot;tcp_failures&quot;: 1,
            &quot;timeouts&quot;: 1,
            &quot;http_failures&quot;: 1,
            &quot;interval&quot;: 5
          },
          &quot;type&quot;: &quot;http&quot;,
          &quot;http_path&quot;: &quot;/kong/healthchecks&quot;,
          &quot;timeout&quot;: 1,
          &quot;healthy&quot;: {
            &quot;successes&quot;: 1,
            &quot;interval&quot;: 5,
            &quot;http_statuses&quot;: [ 200, 302 ]
          },
          &quot;https_verify_certificate&quot;: true,
          &quot;concurrency&quot;: 1
        },
        &quot;passive&quot;: {
          &quot;unhealthy&quot;: {
            &quot;http_statuses&quot;: [ 429, 500, 501, 502, 503, 504, 505 ]
          },
          &quot;healthy&quot;: {
            &quot;http_statuses&quot;: [ 200, 302 ]
          },
          &quot;type&quot;: &quot;http&quot;
        }
      },
      &quot;hash_on_cookie_path&quot;: &quot;/&quot;,
      &quot;hash_fallback&quot;: &quot;none&quot;,
      &quot;slots&quot;: 10000
    },
    &quot;target&quot;: {
      &quot;tags&quot;: [ &quot;example&quot;, &quot;low-priority&quot; ],
      &quot;target&quot;: &quot;192.168.1.10:5200&quot;,
      &quot;weight&quot;: 100
    }
  }&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;*注意：配置节点 kong.target.target 这个值就是要注册到 Kong 网关的地址，如果配置了，这个过程是自动的，否则需要手动指定客户端地址&lt;br/&gt;上面的配置，和 Kong 内部的 UpStream 完全一致，在Kong 中怎么配置 UpStream ，在 Kong.Net 中就怎么配置，字段名称和类型完全平移。&lt;/p&gt;
&lt;h3 id=&quot;修改-startup.cs-服务注入和配置&quot;&gt;修改 startup.cs 服务注入和配置&lt;/h3&gt;
&lt;pre&gt;
&lt;code&gt;public void ConfigureServices(IServiceCollection services)
{
    services.AddSingleton&amp;lt;KongClient&amp;gt;(fat =&amp;gt;
    {
        var options = new KongClientOptions(HttpClientFactory.Create(), this.Configuration[&quot;kong:host&quot;]);
        var client = new KongClient(options);
        return client;
    });
    ...
}
public void Configure(IApplicationBuilder app, IHostingEnvironment env, KongClient kongClient)
{
    app.UseKong(Configuration, kongClient);
    ...
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;到这里就配置完成，可以启动了。&lt;/p&gt;
&lt;h2 id=&quot;自定义启动&quot;&gt;自定义启动&lt;/h2&gt;
&lt;p&gt;如果需要在系统启动的时候动态的传入服务地址，参考下面的代码&lt;/p&gt;
&lt;h3 id=&quot;修改program.cs为外部参数启动&quot;&gt;修改Program.cs为外部参数启动&lt;/h3&gt;
&lt;pre&gt;
&lt;code&gt; public static IWebHostBuilder CreateWebHostBuilder(string[] args)
 {
     var config = new ConfigurationBuilder().AddCommandLine(args).Build();
     var url = config[&quot;server.urls&quot;];

     return WebHost.CreateDefaultBuilder(args)
           .UseStartup&amp;lt;Startup&amp;gt;()
           .UseUrls(url);
 }&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;获得命令行传入的参数配置---server.urls&quot;&gt;获得命令行传入的参数配置 --server.urls&lt;/h3&gt;
&lt;pre&gt;
&lt;code&gt; // This method gets called by the runtime. Use this method to configure the HTTP request pipeline.
 public void Configure(IApplicationBuilder app, IHostingEnvironment env, KongClient kongClient)
 {
     UseKong(app, kongClient);
    ...
 }

 public void UseKong(IApplicationBuilder app, KongClient kongClient)
 {
     var upStream = Configuration.GetSection(&quot;kong:upstream&quot;).Get&amp;lt;UpStream&amp;gt;();
     var target = Configuration.GetSection(&quot;kong:target&quot;).Get&amp;lt;TargetInfo&amp;gt;();
     var uri = new Uri(Configuration[&quot;server.urls&quot;]);
     target.Target = uri.Authority;
     app.UseKong(kongClient, upStream, target);
 }&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;到这里，就大功告成了&lt;/p&gt;
&lt;h3 id=&quot;启动项目完成服务自动注册健康检查&quot;&gt;启动项目，完成服务自动注册、健康检查&lt;/h3&gt;
&lt;p&gt;输入命令&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;dotnet run --server.urls http://172.16.10.227:5200&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/26882/201907/26882-20190706154042081-1834602196.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;上面绿色输出部分，表示服务注册成功，蓝色部分，表示 Kong 正在执行对 Kong.Net 客户端的检查，从运行情况来看，已经完美运行成功了。&lt;/p&gt;
&lt;h3 id=&quot;健康检查&quot;&gt;健康检查&lt;/h3&gt;
&lt;p&gt;使用 Kong.Extensions 客户端扩展包，内部自动将健康检查地址设置为：/kong/healthchecks，然后在内部自动应答，其代码实现为：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;private static IApplicationBuilder UseKongHealthChecks(this IApplicationBuilder app, UpStream upStream)
{
    app.Map(upStream.HealthChecks.Active.Http_path, s =&amp;gt;
    {
        s.Run(async context =&amp;gt;
        {
            Console.ForegroundColor = ConsoleColor.Blue;
            Console.WriteLine(&quot;Healthchecks at: {0}&quot;, DateTime.Now);
            Console.ForegroundColor = ConsoleColor.Gray;
            await context.Response.WriteAsync(&quot;ok&quot;);
        });
    });
    return app;
}&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;结束语&quot;&gt;结束语&lt;/h2&gt;
&lt;p&gt;拥抱开源的脚步，我们从来都是一直在路上；.NETCore作为后起之秀，带给我们太多的惊喜和感动；但是也正是由于年轻，.NETCore 的生态还是不够完善，这就非常需要我们社区的力量，需要大家一起参与，把开源社区好的工具、组件、应用接入到 .NETCore 应用中。&lt;/p&gt;
&lt;p&gt;项目地址：&lt;a href=&quot;https://github.com/lianggx/Kong.Net&quot; class=&quot;uri&quot;&gt;https://github.com/lianggx/Kong.Net&lt;/a&gt;&lt;br/&gt;你的支持使我们更加强大，点击 star 让更多的 .NETCore 认识它，从而能在 .NETCore 的路上更快速的前行。&lt;/p&gt;
&lt;p&gt;如果你非常喜欢这个项目，想成为该项目的贡献者，请及时联系博主，我希望有更多的朋友加入进来，毕竟一个人维护太难了。&lt;/p&gt;
</description>
<pubDate>Mon, 08 Jul 2019 00:01:00 +0000</pubDate>
<dc:creator>Ron.Liang</dc:creator>
<og:description>前言 项目地址：https://github.com/lianggx/Kong.Net 你的支持使我们更加强大，请单击 star 让更多的 .NETCore 认识它。 拥抱开源的脚步，我们从来都是一直</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/viter/p/11142940.html</dc:identifier>
</item>
<item>
<title>【半小时大话.net依赖注入】（一）理论基础+实战控制台程序实现AutoFac注入 - 在7楼</title>
<link>http://www.cnblogs.com/RayWang/p/11128554.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/RayWang/p/11128554.html</guid>
<description>&lt;ol readability=&quot;1.5451263537906&quot;&gt;&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;&lt;a href=&quot;https://www.cnblogs.com/RayWang/p/11128554.html&quot;&gt;第一章|理论基础+实战控制台程序实现AutoFac注入&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;第二章|AutoFac的常见使用套路&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;第三章|实战Asp.Net Framework Web程序实现AutoFac注入&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;第四章|实战Asp.Net Core自带DI实现依赖注入&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;第五章|实战Asp.Net Core引入AutoFac的两种方式&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&quot;简介&quot;&gt;简介&lt;/h2&gt;
&lt;p&gt;该系列共5篇文章，旨在以实战模式，在.net下的&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;
&lt;p&gt;控制台程序&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Framework Mvc程序&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Framework WebApi程序&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Core Api程序&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;分别实现依赖注入。&lt;/p&gt;
&lt;p&gt;其中.Net Framework框架主要以如何引入&lt;strong&gt;AutoFac&lt;/strong&gt;作为容器以及如何运用&lt;strong&gt;AuotoFac&lt;/strong&gt;为主，.Net Core框架除了研究引入AutoFac的两种方式，同时也运用反射技巧对其&lt;strong&gt;自带的DI框架&lt;/strong&gt;进行了初步封装，实现了相同的依赖注入效果。&lt;br/&gt;项目架构如下图：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1327955/201907/1327955-20190704172315934-1174377068.png&quot;/&gt;&lt;/p&gt;
&lt;table&gt;&lt;thead/&gt;&lt;tbody readability=&quot;10&quot;&gt;&lt;tr class=&quot;odd&quot; readability=&quot;2&quot;&gt;&lt;td&gt;Ray.EssayNotes.AutoFac.Infrastructure.CoreIoc&lt;/td&gt;
&lt;td&gt;Core容器&lt;/td&gt;
&lt;td&gt;类库&lt;/td&gt;
&lt;td&gt;.NET Core 2.2&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;even&quot; readability=&quot;2&quot;&gt;&lt;td&gt;Ray.EssayNotes.AutoFac.Infrastructure.Ioc&lt;/td&gt;
&lt;td&gt;Framework容器&lt;/td&gt;
&lt;td&gt;类库&lt;/td&gt;
&lt;td&gt;.NET Framework 4.5&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;odd&quot; readability=&quot;2&quot;&gt;&lt;td&gt;Ray.EssayNotes.AutoFac.Model&lt;/td&gt;
&lt;td&gt;实体层&lt;/td&gt;
&lt;td&gt;类库&lt;/td&gt;
&lt;td&gt;.NET Framework 4.5&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;even&quot; readability=&quot;2&quot;&gt;&lt;td&gt;Ray.EssayNotes.AutoFac.Repository&lt;/td&gt;
&lt;td&gt;仓储层&lt;/td&gt;
&lt;td&gt;类库&lt;/td&gt;
&lt;td&gt;.NET Framework 4.5&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;odd&quot; readability=&quot;2&quot;&gt;&lt;td&gt;Ray.EssayNotes.AutoFac.Service&lt;/td&gt;
&lt;td&gt;业务逻辑层&lt;/td&gt;
&lt;td&gt;类库&lt;/td&gt;
&lt;td&gt;.NET Framework 4.5&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;even&quot; readability=&quot;2&quot;&gt;&lt;td&gt;Ray.EssayNotes.AutoFac.ConsoleApp&lt;/td&gt;
&lt;td&gt;控制台主程序&lt;/td&gt;
&lt;td&gt;控制台项目&lt;/td&gt;
&lt;td&gt;.NET Framework 4.5&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;odd&quot; readability=&quot;2&quot;&gt;&lt;td&gt;Ray.EssayNotes.AutoFac.CoreApi&lt;/td&gt;
&lt;td&gt;Core WebApi主程序&lt;/td&gt;
&lt;td&gt;Core Api项目&lt;/td&gt;
&lt;td&gt;.NET Core 2.2&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;even&quot; readability=&quot;4&quot;&gt;&lt;td&gt;Ray.EssayNotes.AutoFac.NetFrameworkApi&lt;/td&gt;
&lt;td&gt;Framework WebApi主程序&lt;/td&gt;
&lt;td&gt;Framework WebApi项目&lt;/td&gt;
&lt;td&gt;.NET Framework 4.5&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;odd&quot; readability=&quot;2&quot;&gt;&lt;td&gt;Ray.EssayNotes.AutoFac.NetFrameworkMvc&lt;/td&gt;
&lt;td&gt;Framework MVC主程序&lt;/td&gt;
&lt;td&gt;Framework MVC项目&lt;/td&gt;
&lt;td&gt;.NET Framework 4.5&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;GitHub源码地址：&lt;a href=&quot;https://github.com/WangRui321/Ray.EssayNotes.AutoFac&quot; class=&quot;uri&quot;&gt;https://github.com/WangRui321/Ray.EssayNotes.AutoFac&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Welcome to fork me~(欢迎来叉我~)&lt;/p&gt;
&lt;h2 id=&quot;适用对象&quot;&gt;适用对象&lt;/h2&gt;
&lt;p&gt;该项目主要&lt;strong&gt;实战为主&lt;/strong&gt;，理论部分我会结合例子和代码，深入浅出地阐述，如果你是：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;从来没听过IoC、DI这些劳什子&lt;/li&gt;
&lt;li&gt;了解一些依赖注入的理论知识但是缺乏实战&lt;/li&gt;
&lt;li&gt;在.Net Framework下已熟练运用依赖注入，但在.Net Core还比较陌生&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;只要你花上半个小时认真读完每一句话，我有信心这篇文章一定会对你有所帮助。&lt;/p&gt;
&lt;p&gt;如果你是：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;发量比我还少的秒天秒地的大牛&lt;br/&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1327955/201907/1327955-20190704170034980-1208556913.jpg&quot;/&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;那么也欢迎阅读，虽然可能对你帮助并不大，但是欢迎提供宝贵的意见，有写的不好的地方可以互相交流~&lt;/p&gt;
&lt;p&gt;下面开始第一章《理论知识+实战控制台程序实现AutoFac注入》&lt;/p&gt;
&lt;hr/&gt;
&lt;h2 id=&quot;依赖&quot;&gt;依赖&lt;/h2&gt;
&lt;p&gt;依赖，简单说就是，当一个类需要另一个类协作来完成工作的时候就产生了依赖。这也是耦合的一种形式。&lt;/p&gt;
&lt;p&gt;举个例子，比如标准的&lt;strong&gt;三层架构&lt;/strong&gt;模式&lt;/p&gt;
&lt;table&gt;&lt;thead/&gt;&lt;tbody&gt;&lt;tr class=&quot;odd&quot;&gt;&lt;td&gt;界面层（UI）&lt;/td&gt;
&lt;td&gt;负责展示数据&lt;/td&gt;
&lt;td&gt;StudentController&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;even&quot;&gt;&lt;td&gt;业务逻辑层（BLL）&lt;/td&gt;
&lt;td&gt;负责业务逻辑运算&lt;/td&gt;
&lt;td&gt;StudentService&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;odd&quot;&gt;&lt;td&gt;数据访问层（DAL）&lt;/td&gt;
&lt;td&gt;负责提供数据&lt;/td&gt;
&lt;td&gt;StudentRepository&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;数据访问层（DAL）代码：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;    /// &amp;lt;summary&amp;gt;
    /// 学生仓储
    /// &amp;lt;/summary&amp;gt;
    public class StudentRepository
    {
        public string GetName(long id)
        {
            return &quot;学生张三&quot;;//造个假数据返回
        }
    }&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;业务层（BLL）代码：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;    /// &amp;lt;summary&amp;gt;
    /// 学生逻辑处理
    /// &amp;lt;/summary&amp;gt;
    public class StudentService
    {
        private readonly StudentRepository _studentRepository;

        public StudentService()
        {
            _studentRepository = new StudentRepository();
        }

        public string GetStuName(long id)
        {
            var stu = _studentRepository.Get(id);
            return stu.Name;
        }
    }&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;其中，StudentService的实现，就必须要依赖于StudentRepository。而且这是一种紧耦合，一旦StudentRepository有任何更改，必然导致StudentService的代码同样也需要更改，这种情况是程序员们不愿意看到的。&lt;/p&gt;
&lt;h2 id=&quot;接口驱动&quot;&gt;接口驱动&lt;/h2&gt;
&lt;p&gt;接口驱动是为了实现一个设计原则：&lt;strong&gt;要依赖于抽象，而不是具体的实现&lt;/strong&gt;。&lt;br/&gt;还拿上面的例子说明，现在我添加一个DAL的&lt;strong&gt;接口层&lt;/strong&gt;，IStudentRepository，抽象出所需方法：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;    /// &amp;lt;summary&amp;gt;
    /// 学生仓储interface
    /// &amp;lt;/summary&amp;gt;
    public interface IStudentRepository
    {
        string GetName(long id);
    }&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;然后让StudentRepository去实现这个接口：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;    /// &amp;lt;summary&amp;gt;
    /// 学生仓储
    /// &amp;lt;/summary&amp;gt;
    public class StudentRepository : IStudentRepository
    {
        public string GetName(long id)
        {
            return &quot;学生张三&quot;;//造个假数据返回
        }
    }&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;然后在StudentService里只依赖于IStudentRepository，以后的增删改查都通过IStudentRepository这个抽象来做：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;    /// &amp;lt;summary&amp;gt;
    /// 学生逻辑处理
    /// &amp;lt;/summary&amp;gt;
    public class StudentService
    {
        private readonly IStudentRepository _studentRepository;

        public StudentService()
        {
            _studentRepository = new StudentRepository();
        }

        public string GetStuName(long id)
        {
            var stu = _studentRepository.Get(id);
            return stu.Name;
        }
    }&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;这样做的好处有两个，一个是低耦合，一个是职责清晰。如果对此还有怀疑的话，我们可以想象一个情景，就是负责写StudentService的是程序员A，负责写StudentRepository的是另一个程序员B，那么：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;针对程序员A&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;我（程序员A）只需要关注业务逻辑层面，如果我需要从仓储层拿数据库的数据，比如我需要根据Id获取学生实体，那么我只需要去IStudentRepository找Get(long id)函数就可以了，至于实现它的仓储怎么实现这个方法我完全不用管，你怎么从数据库拿数据不是我该关心的事情。&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;针对程序员B&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;我（程序员B）的工作就是实现IStudentRepository接口的所有方法就行了，简单而明确，至于谁来调用我，我不用管。IStudentRepository里有根据Id获取学生姓名的方法，我实现了就行，至于业务逻辑层拿这个名字干啥，那不是我要关心的事情。&lt;/p&gt;
&lt;p&gt;这样看的话是不是彼此的职责就清晰多了，更进一步再举个极端的例子：&lt;br/&gt;比如程序员B是个实习生，整天划水摸鱼，技术停留在上个世纪，结果他写的仓储层读取数据库全部用的手写sql语句的方式，极难维护，后来被领导发现领了盒饭，公司安排了另一个程序员C来重写仓储层，C这时不需要动其他代码，只需要新建一个仓储StudentNewRepository,然后实现之前的IStudentRepository，C使用Dapper或者EF，写完新的仓储层之后，剩下的只需要在StudentService里改一个地方就行了：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;        public StudentService()
        {
            _studentRepository = new StudentNewRepository();
        }&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;是不是很清晰，耦合不会像以前那么重。&lt;br/&gt;其实对于这个小例子来说，接口驱动的优势还不太明显，但是在系统层面优势就会被放大。比如上面换仓储的例子，虽然职责是清晰了，但是项目里有几个Service就需要改几个地方，还是很麻烦。原因就是上面讲的，这是一种依赖关系，Service要依赖Repository，有没有一种方法可以让这种控制关系反转过来呢？当Service需要使用Repository，有没有办法让我需要的Repository自己注入到我这里来？&lt;br/&gt;当然有，这就是我们将要实现的依赖注入。使用依赖注入后你会发现，当C写完新的仓储后，业务逻辑层（StudentService）是不需要改任何代码的，所有的Service都不需要一个一个去改，直接在注入的时候修改规则，不要注入以前老的直接注入新的仓储就可以了。&lt;/p&gt;
&lt;p&gt;面向接口后的架构：&lt;/p&gt;
&lt;table&gt;&lt;thead/&gt;&lt;tbody readability=&quot;3&quot;&gt;&lt;tr class=&quot;odd&quot;&gt;&lt;td&gt;界面层（UI）&lt;/td&gt;
&lt;td&gt;负责展示数据&lt;/td&gt;
&lt;td&gt;StudentController&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;even&quot; readability=&quot;4&quot;&gt;&lt;td&gt;业务逻辑抽象层（InterfaceBLL）&lt;/td&gt;
&lt;td&gt;业务逻辑运算抽象接口&lt;/td&gt;
&lt;td&gt;IStudentService&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;odd&quot;&gt;&lt;td&gt;业务逻辑层（BLL）&lt;/td&gt;
&lt;td&gt;负责业务逻辑运算&lt;/td&gt;
&lt;td&gt;StudentService&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;even&quot; readability=&quot;2&quot;&gt;&lt;td&gt;数据访问抽象层（InterfaceDAL）&lt;/td&gt;
&lt;td&gt;数据访问抽象接口&lt;/td&gt;
&lt;td&gt;IStudentRepository&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;odd&quot;&gt;&lt;td&gt;数据访问层（DAL）&lt;/td&gt;
&lt;td&gt;负责提供数据&lt;/td&gt;
&lt;td&gt;StudentRepository&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;h2 id=&quot;什么是ioc&quot;&gt;什么是IoC&lt;/h2&gt;
&lt;p&gt;IoC，全称Inversion of Control，即“&lt;strong&gt;控制反转&lt;/strong&gt;”，是一种&lt;strong&gt;设计原则&lt;/strong&gt;，最早由Martin Fowler提出，因为其理论提出时间和成熟时间相对较晚，所以并没有被包含在GoF的《设计模式》中。&lt;/p&gt;
&lt;h2 id=&quot;什么是di&quot;&gt;什么是DI&lt;/h2&gt;
&lt;p&gt;DI，全称Dependency Injection，即&lt;strong&gt;依赖注入&lt;/strong&gt;，是实现IoC的其中一种设计方法。&lt;br/&gt;其特征是通过一些技巧，将依赖的对象注入到调用者当中。（比如把Repository注入到Service当中）&lt;br/&gt;这里说的技巧目前主要指的就是引入&lt;strong&gt;容器&lt;/strong&gt;，先把所有会产生依赖的对象统一添加到容器当中，比如StudentRepository和StudentService，把分配权限交给容器，当StudentService内部需要使用StudentRepository时，这时不应该让它自己new出来一个，而是通过容器，把StudentRepository注入到StudentService当中。&lt;br/&gt;这就是名称“依赖注入”的由来。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1327955/201907/1327955-20190704174344478-682084802.jpg&quot;/&gt;&lt;/p&gt;
&lt;h2 id=&quot;di和ioc有什么区别&quot;&gt;DI和IoC有什么区别&lt;/h2&gt;
&lt;p&gt;这是个老生常谈的问题了，而且这两个名字经常在各种大牛和伪大牛的吹逼现场频繁出现 ，听的新手云里雾里，莫名感到神圣不可侵犯。那么DI和IoC是同一个东西吗？如果不是，它们又有什么区别呢？&lt;br/&gt;回答很简单：&lt;strong&gt;不是一个东西&lt;/strong&gt;。&lt;br/&gt;区别也很简单，一句话概括就是：&lt;strong&gt;IoC是一种很宽泛的理念，DI是实现了IoC的其中一种方法&lt;/strong&gt;。&lt;br/&gt;说到这里我已经感觉到屏幕后的你性感地添了一下嘴唇，囤积好口水，准备开始喷我了。&lt;br/&gt;先别慌，我有证据，我们先来看下微软怎么说：&lt;/p&gt;
&lt;blockquote readability=&quot;7&quot;&gt;
&lt;p&gt;ASP.NET Core supports the dependency injection (DI) software design pattern, which is a technique for achieving Inversion of Control (IoC) between classes and their dependencies.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;地址：&lt;a href=&quot;https://docs.microsoft.com/en-us/aspnet/core/fundamentals/dependency-injection?view=aspnetcore-2.2&quot; class=&quot;uri&quot;&gt;https://docs.microsoft.com/en-us/aspnet/core/fundamentals/dependency-injection?view=aspnetcore-2.2&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;翻译过来就是“&lt;em&gt;ASP.NET Core支持依赖注入（DI）的软件设计模式，该模式是一种在类和它依赖的对象之间实现了控制反转（IoC）的技术&lt;/em&gt;”。&lt;/p&gt;
&lt;p&gt;如果有人觉得辣鸡微软不够权威，那我们去看下IoC以及DI这两个概念的发明人——Martin Fowler怎么说：&lt;/p&gt;
&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;几位轻量级容器的作者曾骄傲地对我说：这些容器非常有用，因为它们实现了控制反转。这样的说辞让我深感迷惑：控制反转是框架所共有的特征，如果仅仅因为使用了控制反转就认为这些轻量级容器与众不同，就好象在说我的轿车是与众不同的，因为它有四个轮子。&lt;br/&gt;因此，我想我们需要给这个模式起一个更能说明其特点的名字——”控制反转”这个名字太泛了，常常让人有些迷惑。经与多位IoC 爱好者讨论之后，我们决定将这个模式叫做”依赖注入”（Dependency Injection）。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;地址：&lt;a href=&quot;http://insights.thoughtworkers.org/injection/&quot; class=&quot;uri&quot;&gt;http://insights.thoughtworkers.org/injection/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Martin Fowler说的比较委婉，其实说白了就是建议我们，&lt;strong&gt;不要乱用IoC装逼&lt;/strong&gt;，IoC是一种设计理念，很宽泛，&lt;em&gt;你把程序里的一个写死的变量改成从配置文件里读取也是一种控制反转（由&lt;strong&gt;程序控制&lt;/strong&gt;反转为由&lt;strong&gt;框架控制&lt;/strong&gt;），你把这个配置改成用户UI界面的一个输入文本框由用户输入也是一种控制反转（由&lt;strong&gt;框架控制&lt;/strong&gt;反转为由&lt;strong&gt;用户自己控制&lt;/strong&gt;）&lt;/em&gt;。&lt;br/&gt;所以，如果确定讨论的模式是DI，那么就表述为DI，还是尽量少用IoC这种宽泛的表达。&lt;/p&gt;
&lt;h2 id=&quot;autofac&quot;&gt;AutoFac&lt;/h2&gt;
&lt;p&gt;AutoFac是一个开源的轻量级的DI容器，也是.net下最受大家欢迎的实现依赖注入的工具之一，通过AutoFac我们可以很方便的实现一些DI的骚操作。&lt;/p&gt;

&lt;p&gt;目标很简单，就是控制台程序启动后，将学生姓名打印出来。&lt;br/&gt;程序启动流程是，控制台主程序调用Service层，Service层调用Repository层获取数据（示例项目的仓储层没有连接数据库，只是直接造个假数据返回）。&lt;br/&gt;没有依赖注入的情况下，肯定是主程序会new一个StudentService，StudentService里会new一个StudentRepository，现在引入依赖注入后，就不应该这么new出来了，而是通过容器注入，也就是容器会把StudentRepository自动注入到StudentService当中。&lt;/p&gt;
&lt;h2 id=&quot;架构&quot;&gt;架构&lt;/h2&gt;
&lt;h3 id=&quot;实体层&quot;&gt;实体层&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1327955/201907/1327955-20190705141612498-192467374.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;学生实体类StudentEntity：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;namespace Ray.EssayNotes.AutoFac.Model
{
    /// &amp;lt;summary&amp;gt;学生实体&amp;lt;/summary&amp;gt;
    public class StudentEntity
    {
        /// &amp;lt;summary&amp;gt;唯一标识&amp;lt;/summary&amp;gt;
        public long Id { get; set; }
        /// &amp;lt;summary&amp;gt;姓名&amp;lt;/summary&amp;gt;
        public string Name { get; set; }
        /// &amp;lt;summary&amp;gt;成绩&amp;lt;/summary&amp;gt;
        public int Grade { get; set; }
    }
}&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;仓储层&quot;&gt;仓储层&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1327955/201907/1327955-20190705141745503-486248562.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;IStudentRepository接口：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;using Ray.EssayNotes.AutoFac.Model;

namespace Ray.EssayNotes.AutoFac.Repository.IRepository
{
    /// &amp;lt;summary&amp;gt;学生仓储interface&amp;lt;/summary&amp;gt;
    public interface IStudentRepository
    {
        string GetName(long id);
    }
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;StudentRepository仓储类：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;using Ray.EssayNotes.AutoFac.Model;
using Ray.EssayNotes.AutoFac.Repository.IRepository;

namespace Ray.EssayNotes.AutoFac.Repository.Repository
{
    /// &amp;lt;summary&amp;gt;
    /// 学生仓储
    /// &amp;lt;/summary&amp;gt;
    public class StudentRepository : IStudentRepository
    {
        public string GetName(long id)
        {
            return &quot;学生张三&quot;;//造个假数据返回
        }
    }
}&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;service层&quot;&gt;Service层&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1327955/201907/1327955-20190705141852070-1256475620.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;IStudentService接口&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;namespace Ray.EssayNotes.AutoFac.Service.IService
{
    /// &amp;lt;summary&amp;gt;
    /// 学生逻辑处理interface
    /// &amp;lt;/summary&amp;gt;
    public interface IStudentService
    {
        string GetStuName(long id);
    }
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;StudentService类:&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;using Ray.EssayNotes.AutoFac.Repository.IRepository;
using Ray.EssayNotes.AutoFac.Repository.Repository;
using Ray.EssayNotes.AutoFac.Service.IService;

namespace Ray.EssayNotes.AutoFac.Service.Service
{
    /// &amp;lt;summary&amp;gt;
    /// 学生逻辑处理
    /// &amp;lt;/summary&amp;gt;
    public class StudentService : IStudentService
    {
        private readonly IStudentRepository _studentRepository;
        /// &amp;lt;summary&amp;gt;
        /// 构造注入
        /// &amp;lt;/summary&amp;gt;
        /// &amp;lt;param name=&quot;studentRepository&quot;&amp;gt;&amp;lt;/param&amp;gt;
        public StudentService(IStudentRepository studentRepository)
        {
            _studentRepository = studentRepository;
        }

        public string GetStuName(long id)
        {
            var stu = _studentRepository.Get(id);
            return stu.Name;
        }
    }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;其中构造函数是一个有参的函数，参数是学生仓储，这个后面依赖注入时会用。&lt;/p&gt;
&lt;h3 id=&quot;autofac容器&quot;&gt;AutoFac容器&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1327955/201907/1327955-20190705142010578-1627792237.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;需要先通过Nuget导入Autofac包：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1327955/201907/1327955-20190705143325598-1976348318.png&quot;/&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;using System;
using System.Reflection;
//
using Autofac;
using Autofac.Core;
//
using Ray.EssayNotes.AutoFac.Repository.IRepository;
using Ray.EssayNotes.AutoFac.Repository.Repository;
using Ray.EssayNotes.AutoFac.Service.IService;
using Ray.EssayNotes.AutoFac.Service.Service;

namespace Ray.EssayNotes.AutoFac.Infrastructure.Ioc
{
    /// &amp;lt;summary&amp;gt;
    /// 控制台程序容器
    /// &amp;lt;/summary&amp;gt;
    public static class Container
    {
        /// &amp;lt;summary&amp;gt;
        /// 容器
        /// &amp;lt;/summary&amp;gt;
        public static IContainer Instance;

        /// &amp;lt;summary&amp;gt;
        /// 初始化容器
        /// &amp;lt;/summary&amp;gt;
        /// &amp;lt;returns&amp;gt;&amp;lt;/returns&amp;gt;
        public static void Init()
        {
            //新建容器构建器，用于注册组件和服务
            var builder = new ContainerBuilder();
            //自定义注册
            MyBuild(builder);
            //利用构建器创建容器
            Instance = builder.Build();
        }

        /// &amp;lt;summary&amp;gt;
        /// 自定义注册
        /// &amp;lt;/summary&amp;gt;
        /// &amp;lt;param name=&quot;builder&quot;&amp;gt;&amp;lt;/param&amp;gt;
        public static void MyBuild(ContainerBuilder builder)
        {
            builder.RegisterType&amp;lt;StudentRepository&amp;gt;().As&amp;lt;IStudentRepository&amp;gt;();
            builder.RegisterType&amp;lt;StudentService&amp;gt;().As&amp;lt;IStudentService&amp;gt;();
        }
    }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;其中：&lt;/p&gt;
&lt;ul readability=&quot;-0.5&quot;&gt;&lt;li&gt;public static IContainer Instance&lt;br/&gt;为单例容器&lt;/li&gt;
&lt;li&gt;Init()方法&lt;br/&gt;用于初始化容器，即往容器中添加对象，我们把这个添加的过程称为&lt;strong&gt;注册&lt;/strong&gt;（Register）。&lt;br/&gt;ContainerBuilder为AutoFac定义的&lt;strong&gt;容器构造器&lt;/strong&gt;，我们通过使用它往容器内注册对象。&lt;/li&gt;
&lt;li readability=&quot;2&quot;&gt;
&lt;p&gt;MyBuild(ContainerBuilder builder)方法&lt;br/&gt;我们具体注册的实现函数。RegisterType是AutoFac封装的一种最基本的注册方法，传入的泛型（StudentService）就是我们欲添加到容器的对象；As函数负责绑定注册对象的&lt;strong&gt;暴露类型&lt;/strong&gt;，一般是以其实现的接口类型暴露，这个暴露类型是我们后面去容器内查找对象时使用的搜索标识，我们从容器外部只有通过暴露类型才能找到容器内的对象。&lt;/p&gt;
&lt;h3 id=&quot;主程序&quot;&gt;主程序&lt;/h3&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1327955/201907/1327955-20190705142126846-1286011074.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;需要先Nuget导入AutoFac程序包：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1327955/201907/1327955-20190705143325598-1976348318.png&quot;/&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;using System;
//
using Autofac;
//
using Ray.EssayNotes.AutoFac.Infrastructure.Ioc;
using Ray.EssayNotes.AutoFac.Service.IService;


namespace Ray.EssayNotes.AutoFac.ConsoleApp
{
    class Program
    {
        static void Main(string[] args)
        {
            Container.Init();//初始化容器，将需要用到的组件添加到容器中

            PrintStudentName(10001);

            Console.ReadKey();
        }

        /// &amp;lt;summary&amp;gt;
        /// 输出学生姓名
        /// &amp;lt;/summary&amp;gt;
        /// &amp;lt;param name=&quot;id&quot;&amp;gt;&amp;lt;/param&amp;gt;
        public static void PrintStudentName(long id)
        {
            //从容器中解析出对象
            IStudentService stuService = Container.Instance.Resolve&amp;lt;IStudentService&amp;gt;();
            string name = stuService.GetStuName(id);
            Console.WriteLine(name);
        }
     }
 }&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;进入Main函数，先调用容器的初始化函数，该函数执行成功后，StudentRepository和StudentService就被注册到容器中了。&lt;br/&gt;然后调用打印学生姓名的函数，其中Resolve()方法是AutoFac封装的容器的解析方法，传入的泛型就是之前注册时的暴露类型，下面可以详细看下这一步到底发生了哪些事情：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;容器根据暴露类型解析对象&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;也就是容器会根据暴露类型IStudentService去容器内部找到其对应类（即StudentService），找到后会试图实例化一个对象出来。&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;实例化StudentService&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;AutoFac容器在解析StudentService的时候，会调用StudentService的构造函数进行实例化。&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;构造注入&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;AutoFac容器发现StudentService的构造函数需要一个IStudnetRepository类型的参数，于是会自动去容器内寻找，根据这个暴露类型找到对应的StudnetRepository后，自动将其注入到了StudentService当中&lt;/p&gt;
&lt;p&gt;经过这几步，一个简单的基于依赖注入的程序就完成了。&lt;/p&gt;
&lt;h2 id=&quot;结果&quot;&gt;结果&lt;/h2&gt;
&lt;p&gt;我们将控制台程序设置为启动项目，点击运行，如图调用成功：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1327955/201907/1327955-20190705145101450-1330667943.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;如果把调试断点加在容器初始化函数里，可以很清晰的看到哪些对象被注册到了容器里：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1327955/201907/1327955-20190705145627740-971128318.png&quot;/&gt;&lt;/p&gt;
</description>
<pubDate>Sun, 07 Jul 2019 23:10:00 +0000</pubDate>
<dc:creator>在7楼</dc:creator>
<og:description>系列目录 1. '第一章|理论基础+实战控制台程序实现AutoFac注入' 1. 第二章|AutoFac的常见使用套路 1. 第三章|实战Asp.Net Framework Web程序实现AutoFa</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/RayWang/p/11128554.html</dc:identifier>
</item>
<item>
<title>渐进式web应用开发---service worker (二) - 龙恩0707</title>
<link>http://www.cnblogs.com/tugenhua0707/p/11148968.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/tugenhua0707/p/11148968.html</guid>
<description>&lt;p&gt;1. 创建第一个service worker 及环境搭建&lt;/p&gt;
&lt;p&gt;在上一篇文章，我们已经讲解了 service worker 的基本原理，请看&lt;a href=&quot;https://www.cnblogs.com/tugenhua0707/p/11142077.html&quot; target=&quot;_blank&quot;&gt;上一篇文章&lt;/a&gt; . 从这篇文章开始我们来学习下 service worker的基本知识。&lt;/p&gt;
&lt;p&gt;在讲解之前，我们先来搭建一个简单的项目，和之前一样，首先我们来看下我们整个项目目录结构，如下所示：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;34&quot;&gt;
&lt;pre&gt;
|-----&lt;span&gt; 项目
&lt;/span&gt;|  |---&lt;span&gt; public
&lt;/span&gt;|  | |---&lt;span&gt; js               # 存放所有的js
&lt;/span&gt;|  | | |---&lt;span&gt; main.js        # js入口文件
&lt;/span&gt;|  | |---&lt;span&gt; style            # 存放所有的css
&lt;/span&gt;|  | | |---&lt;span&gt; main.styl      # css 入口文件
&lt;/span&gt;|  | |---&lt;span&gt; index.html       # index.html 页面
&lt;/span&gt;|  | |---&lt;span&gt; images
&lt;/span&gt;|  |---&lt;span&gt; package.json
&lt;/span&gt;|  |---&lt;span&gt; webpack.config.js
&lt;/span&gt;|  |--- node_modules
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;如上目录结构就是我们项目的最简单的目录结构。我们先来看下我们各个目录的文件代码。&lt;/p&gt;
&lt;p&gt;index.html 代码如下：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;33&quot;&gt;
&lt;pre&gt;
&lt;span&gt;&amp;lt;!&lt;/span&gt;&lt;span&gt;DOCTYPE html&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;html &lt;/span&gt;&lt;span&gt;lang&lt;/span&gt;&lt;span&gt;=&quot;en&quot;&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;head&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
  &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;meta &lt;/span&gt;&lt;span&gt;charset&lt;/span&gt;&lt;span&gt;=&quot;UTF-8&quot;&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
  &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;title&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;service worker 实列&lt;span&gt;&amp;lt;/&lt;/span&gt;&lt;span&gt;title&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
&lt;span&gt;&amp;lt;/&lt;/span&gt;&lt;span&gt;head&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;body&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
  &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;div &lt;/span&gt;&lt;span&gt;id&lt;/span&gt;&lt;span&gt;=&quot;app&quot;&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;22222&lt;span&gt;&amp;lt;/&lt;/span&gt;&lt;span&gt;div&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
&lt;span&gt;&amp;lt;/&lt;/span&gt;&lt;span&gt;body&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
&lt;span&gt;&amp;lt;/&lt;/span&gt;&lt;span&gt;html&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;其他的文件代码目前可以忽略不计，基本上没有什么代码。因此我们在项目的根目录下 运行  npm run dev 后，就会启动我们的页面。如下运行的页面。如下所示：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/561794/201907/561794-20190708000247939-1835259345.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;如上就是我们的页面简单的整个项目的目录架构了，现在我们来创建我们的第一个 service worker了。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;一：创建我们的第一个service worker&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;首先从当前页面注册一个新的service worker， 因此在我们的 public/js/main.js 添加如下代码：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;37&quot;&gt;
&lt;pre&gt;
&lt;span&gt;//&lt;/span&gt;&lt;span&gt; 加载css样式&lt;/span&gt;
require('../styles/main.styl'&lt;span&gt;);

console.log(navigator);

&lt;/span&gt;&lt;span&gt;if&lt;/span&gt; (&quot;serviceWorker&quot; &lt;span&gt;in&lt;/span&gt;&lt;span&gt; navigator) {
  navigator.serviceWorker.register(&lt;/span&gt;'/sw.js'&lt;span&gt;)
    .then(&lt;/span&gt;&lt;span&gt;function&lt;/span&gt;&lt;span&gt;(registration){
      console.log(&lt;/span&gt;&quot;Service Worker registered with scope: &quot;&lt;span&gt;, registration.scope);
    }).&lt;/span&gt;&lt;span&gt;catch&lt;/span&gt;(&lt;span&gt;function&lt;/span&gt;&lt;span&gt;(err) {
      console.log(&lt;/span&gt;&quot;Service Worker registered failed:&quot;&lt;span&gt;, err);
    });
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;如上代码，首先在我们的chrome下打印 console.log(navigator); 看到如下信息：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/561794/201907/561794-20190708000349796-2022244452.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;切记：&lt;/strong&gt;&lt;/span&gt;要想支持service worker 的话，在本地必须以 http://localhost:8081/ 或 http://127.0.0.1:8081 来访问页面，在线上必须以https来访问页面，否则的话，浏览器是不支持的，因为http访问会涉及到service worker安全性问题。 比如我在本地启动的是以 http://0.0.0.0:8081/ 这样来访问页面的话，浏览器是不支持 service worker的。如下所示：&lt;br/&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/561794/201907/561794-20190708000429026-1745341335.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;如上代码，使用了if语句判断了浏览器是否支持 service worker， 如果支持的话，我们会使用 navigator.serviceWorker.register 方法注册了我们的 service worker，该方法接收2个参数，第一个参数是我们的脚本的URL，第二个参数是作用域(晚点会讲到)。&lt;/p&gt;
&lt;p&gt;如上register方法会返回一个promise对象，如果promise成功，说明注册service worker 成功，就会执行我们的then函数代码，否则的话就会执行我们的catch内部代码。&lt;/p&gt;
&lt;p&gt;如上代码我们的 navigator.serviceWorker.register('/sw.js')， 注册了一个 sw.js，因此我们需要在我们的 项目的根目录下新建一个 sw.js 。目前它没有该目录文件，然后我们继续刷新页面，可以看到它进入了catch语句代码；如下所示：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/561794/201907/561794-20190708000521003-1471471133.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;现在我们需要在 我们的项目根目录下新建 sw.js.&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;注意：&lt;/strong&gt;&lt;/span&gt;我们的sw.js文件路径放到了项目的根目录下，这就意味着 serviceworker 和网站是同源的，因此在 项目的根目录下的所有请求都可以代理的。如果我们把 sw.js 放入到我们的 public 目录下的话，那么就意味这我们只能代理public下的网络请求了。但是我们可以在注册service worker的时候传入一个scope选项，用来覆盖默认的service worker的作用域。比如如下：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;34&quot;&gt;
&lt;pre&gt;
navigator.serviceWorker.register('/sw.js'&lt;span&gt;);
navigator.serviceWorker.register(&lt;/span&gt;'/sw.js', {scope: '/'});
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;如上两条命令是完全相同的作用域了。&lt;/p&gt;
&lt;p&gt;下面我们的两条命令将注册两个不同的作用域，因为他们是放在两个不同的目录下。如下代码：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;35&quot;&gt;
&lt;pre&gt;
navigator.serviceWorker.register('/sw.js', {scope: '/xxx'&lt;span&gt;});
navigator.serviceWorker.register(&lt;/span&gt;'/sw22.js', {scope: '/yyy'});
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;现在在我们的项目根目录下有sw.js 这个文件，因此这个时候我们再刷新下我们的页面，就可以看到打印出消息出来了 Service Worker registered with scope:  http://localhost:8081/ ，说明注册成功了。如下所示：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/561794/201907/561794-20190708000633865-1722312663.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;下面我们继续在我们的 项目的根目录 sw.js 添加代码如下：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;35&quot;&gt;
&lt;pre&gt;
&lt;span&gt;console.log(self);

self.addEventListener(&lt;/span&gt;&quot;fetch&quot;, &lt;span&gt;function&lt;/span&gt;&lt;span&gt;(e) {
  console.log(&lt;/span&gt;&quot;Fetch request for: &quot;&lt;span&gt;, e.request.url);
});&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;如上代码，我们首先可以打印下self是什么，在service worker中，self它是指向service worker本身的。我们首先在控制台中看看self到底是什么，我们可以先打印出来看看，如下所示：&lt;br/&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/561794/201907/561794-20190708000716725-1462787652.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;如上代码，我们的service worker添加了一个事件监听器，这个监听器会监听所有经过service worker的fetch事件，并允许我们的回调函数，我们修改sw.js后，我们并没有看到控制台打印我们的消息，因此我们先来简单的学习下我们的service worker的生命周期。&lt;/p&gt;
&lt;p&gt;当我们修改sw.js 代码后，这些修改并没有在刷新浏览器之后立即生效，这是因为原先的service worker依然处于激活状态，但是我们新注册的 service worker 仍然处于等待状态，如果这个时候我们把原先第一个service worker停止掉就可以了，为什么有这么多service worker，那是因为我刷新下页面，浏览器会重新执行我们的main.js 代码中注册 sw.js 代码，因此会有很多service worker，现在我们要怎么做呢？我们打开我们的chrome控制台，切换到 Application 选项，然后禁用掉我们的第一个正处于激活状态下的service worker 即可，如下图所示：&lt;br/&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/561794/201907/561794-20190708000818584-1015769591.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;禁用完成后，我们再刷新下页面即可看到我们console.log(self);会打印出来了，说明已经生效了。&lt;/p&gt;
&lt;p&gt;但是我们现在是否注意到，我们的监听fetch事件，第一次刷新的时候没有打印出 console.log(&quot;Fetch request for: &quot;, e.request.url); 这个信息，这是因为service worker第一次是注册，注册完成后，我们才可以监听该事件，因此当我们第二次以后刷新的时候，我们就可以使用fetch事件监听到我们页面上所有的请求了，我们可以继续第二次刷新后，在控制台我们可以看到如下信息，如下图所示：&lt;br/&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/561794/201907/561794-20190708000837477-1389904364.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;下面为了使我们更能理解我们的整个目录架构，我们再来看下我们整个目录结构变成如下样子：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;35&quot;&gt;
&lt;pre&gt;
|-----&lt;span&gt; 项目
&lt;/span&gt;|  |---&lt;span&gt; public
&lt;/span&gt;|  | |---&lt;span&gt; js               # 存放所有的js
&lt;/span&gt;|  | | |---&lt;span&gt; main.js        # js入口文件
&lt;/span&gt;|  | |---&lt;span&gt; style            # 存放所有的css
&lt;/span&gt;|  | | |---&lt;span&gt; main.styl      # css 入口文件
&lt;/span&gt;|  | |---&lt;span&gt; index.html       # index.html 页面
&lt;/span&gt;|  | |---&lt;span&gt; images
&lt;/span&gt;|  |---&lt;span&gt; package.json
&lt;/span&gt;|  |---&lt;span&gt; webpack.config.js
&lt;/span&gt;|  |---&lt;span&gt; node_modules
&lt;/span&gt;|  |--- sw.js
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;2. 使用service worker 对请求拦截&lt;/p&gt;
&lt;p&gt; 我们第二次以后刷新的时候，我们可以监听到我们页面上所有的请求，那是不是也意味着我们可以对这些请求进行拦截，并且修改代码，然后返回呢？当然可以的，因此我们把sw.js 代码改成如下这个样子：代码如下所示：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;35&quot;&gt;
&lt;pre&gt;
self.addEventListener(&quot;fetch&quot;, &lt;span&gt;function&lt;/span&gt;&lt;span&gt;(e) {
  &lt;/span&gt;&lt;span&gt;if&lt;/span&gt; (e.request.url.includes(&quot;main.css&quot;&lt;span&gt;)) {
    e.respondWith(
      &lt;/span&gt;&lt;span&gt;new&lt;/span&gt;&lt;span&gt; Response(
        &lt;/span&gt;&quot;#app {color:red;}&quot;&lt;span&gt;,
        {headers: { &lt;/span&gt;&quot;Content-Type&quot;: &quot;text/css&quot;&lt;span&gt; }}
      )
    )
  }
});&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;如上代码，我们监听fetch事件，并检查每个请求的URL是否包含我们的 main.css 字符串，如果包含的话，service worker 会动态的创建一个Response对象，在响应中包含了自定义的css，并使用这个对象作为我们的响应，而不会向远程服务器请求这个文件。效果如下所示：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/561794/201907/561794-20190708001110074-1738427056.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;3. 从web获取内容&lt;/p&gt;
&lt;p&gt;在第二点中，我们拦截main.css ，我们通过指定内容和头部，从零开始创建了一个新的响应对象，并使用它作为响应内容。但是service worker 更广泛的用途是响应来源于网络请求。我们也可以监听图片。&lt;/p&gt;
&lt;p&gt;我们在我们的index.html页面中添加一张图片的代码；如下所示：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;33&quot;&gt;
&lt;pre&gt;
&lt;span&gt;&amp;lt;!&lt;/span&gt;&lt;span&gt;DOCTYPE html&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;html &lt;/span&gt;&lt;span&gt;lang&lt;/span&gt;&lt;span&gt;=&quot;en&quot;&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;head&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
  &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;meta &lt;/span&gt;&lt;span&gt;charset&lt;/span&gt;&lt;span&gt;=&quot;UTF-8&quot;&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
  &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;title&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;service worker 实列&lt;span&gt;&amp;lt;/&lt;/span&gt;&lt;span&gt;title&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
&lt;span&gt;&amp;lt;/&lt;/span&gt;&lt;span&gt;head&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;body&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
  &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;div &lt;/span&gt;&lt;span&gt;id&lt;/span&gt;&lt;span&gt;=&quot;app&quot;&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;22222&lt;span&gt;&amp;lt;/&lt;/span&gt;&lt;span&gt;div&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
  &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;img &lt;/span&gt;&lt;span&gt;src&lt;/span&gt;&lt;span&gt;=&quot;/public/images/xxx.jpg&quot;&lt;/span&gt; &lt;span&gt;/&amp;gt;&lt;/span&gt;
&lt;span&gt;&amp;lt;/&lt;/span&gt;&lt;span&gt;body&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
&lt;span&gt;&amp;lt;/&lt;/span&gt;&lt;span&gt;html&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;然后我们在页面上浏览下，效果如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/561794/201907/561794-20190708001053950-1055060308.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;现在我们通过service worker来监听该图片的请求，然后替换成另外一张图片，sw.js 代码如下所示：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;34&quot;&gt;
&lt;pre&gt;
self.addEventListener(&quot;fetch&quot;, &lt;span&gt;function&lt;/span&gt;&lt;span&gt;(e) {
  &lt;/span&gt;&lt;span&gt;if&lt;/span&gt; (e.request.url.includes(&quot;/public/images/xxx.jpg&quot;&lt;span&gt;)) {
    e.respondWith(
      fetch(&lt;/span&gt;&quot;/public/images/yyy.png&quot;&lt;span&gt;)
    );
  }
});&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;然后我们继续刷新下页面，把之前的service worker禁用掉，继续刷新页面，我们就可以看到如下效果：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/561794/201907/561794-20190708001157304-616617678.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;和我们之前一样，我们监听fetch事件，这次我们查找的字符串是 &quot;/public/images/xxx.jpg&quot;，当检测到有这样的请求的时候，我们会使用fetch命令创建一个新的请求，并把第二张图片作为响应返回，fetch它会返回一个promise对象。&lt;/p&gt;
&lt;p&gt;注意：fetch方法的第一个参数是必须传递的，可以是request对象，也可以是包含一个相对路径或绝对路径的URL的字符串。比如如下：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;34&quot;&gt;
&lt;pre&gt;
&lt;span&gt;//&lt;/span&gt;&lt;span&gt; url 请求&lt;/span&gt;
fetch(&quot;/public/images/xxx.jpg&quot;&lt;span&gt;);

&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; 通过request对象中的url请求&lt;/span&gt;
&lt;span&gt;fetch(e.request.url);

&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; 通过传递request对象请求，在这个request对象中，除了url，可能还包含额外的头部信息，表单数据等。&lt;/span&gt;
fetch(e.request);
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;fetch它还有第二个参数，可以包含是一个对象，对象里面是请求的选项。比如如下：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;34&quot;&gt;
&lt;pre&gt;
fetch(&quot;/public/images/xxx.jpg&quot;&lt;span&gt;, {
  method: &lt;/span&gt;'POST'&lt;span&gt;,
  credentials: &lt;/span&gt;&quot;include&quot;&lt;span&gt;
});&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;如上代码，对一个图片发起了一个post请求，并在头部中包含了cookie信息。fetch会返回一个promise对象。&lt;/p&gt;

&lt;p&gt;4. 捕获离线请求&lt;/p&gt;
&lt;p&gt;我们现在有了上面的service worker的基础知识后，我们来使用service worker检测用户何时处于离线状态，如果检测到用户是处于离线状态，我们会返回一个友好的错误提示，用来代替默认的错误提示。因此我们需要把我们的sw.js 代码改成如下所示：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;34&quot;&gt;
&lt;pre&gt;
self.addEventListener(&quot;fetch&quot;, &lt;span&gt;function&lt;/span&gt;&lt;span&gt;(event) {
  event.respondWith(
    fetch(event.request).&lt;/span&gt;&lt;span&gt;catch&lt;/span&gt;(&lt;span&gt;function&lt;/span&gt;&lt;span&gt;() {
      &lt;/span&gt;&lt;span&gt;return&lt;/span&gt; &lt;span&gt;new&lt;/span&gt;&lt;span&gt; Response(
        &lt;/span&gt;&quot;欢迎来到我们的service worker应用&quot;&lt;span&gt;
      )
    })
  );
});&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;如上代码我们监听并捕获了所有的fetch事件，然后使用另一个完全相同的fetch操作进行相应，我们的fetch它是返回的是一个promise对象，因此它有catch失败时候来捕获异常的，因此当我们刷新页面后，然后再切换到离线状态时候，我们可以看到页面变成如下提示了，如下图所示：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/561794/201907/561794-20190708001349213-1350013399.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;5. 创建html响应&lt;/p&gt;
&lt;p&gt; 如上响应都是对字符串进行响应的，但是我们也可以拼接html返回进行响应，比如我们可以把sw.js 代码改成如下：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;37&quot;&gt;
&lt;pre&gt;
&lt;span&gt;var&lt;/span&gt; responseContent = `&amp;lt;html&amp;gt;
  &amp;lt;body&amp;gt;
    &amp;lt;head&amp;gt;
      &amp;lt;meta charset=&quot;UTF-8&quot;&amp;gt;
      &amp;lt;title&amp;gt;service+worker异常&amp;lt;/title&amp;gt;
      &amp;lt;style&amp;gt;body{color:red;font-size:18px;}&amp;lt;/style&amp;gt;
    &amp;lt;/head&amp;gt;
    &amp;lt;h2&amp;gt;service worker异常的处理&amp;lt;/h2&amp;gt;
  &amp;lt;/body&amp;gt;
&lt;span&gt;`

self.addEventListener(&lt;/span&gt;&quot;fetch&quot;, &lt;span&gt;function&lt;/span&gt;&lt;span&gt;(event) {
  console.log(event.request);
  event.respondWith(
    fetch(event.request).&lt;/span&gt;&lt;span&gt;catch&lt;/span&gt;(&lt;span&gt;function&lt;/span&gt;&lt;span&gt;() {
      &lt;/span&gt;&lt;span&gt;return&lt;/span&gt; &lt;span&gt;new&lt;/span&gt;&lt;span&gt; Response(
        responseContent,
        {headers: {&lt;/span&gt;&quot;Content-Type&quot;: &quot;text/html&quot;&lt;span&gt;}}
      )
    })
  );
});&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;然后我们继续刷新页面，结束掉第一个service worker应用，可以看到如下所示：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/561794/201907/561794-20190708001430471-570140061.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;如上代码，我们先定义了给离线用户的html内容，并将其赋值给 responseContent变量中，然后我们添加一个事件监听器，监听所有的fetch事件，我们的回调函数就会被调用，它接收一个 event事件对象作为参数，随后我们调用了该事件对象的 respondWith 方法来响应这个事件，避免其触发默认行为。&lt;/p&gt;
&lt;p&gt;respondWith方法接收一个参数，它可以是一个响应对象，也可以是一段通过promise得出响应对象的代码。&lt;/p&gt;
&lt;p&gt;如上我们调用fetch，并传入原始请求对象，不仅仅是URL，它还包括头部信息、cookie、和请求方法等，如上我们的打印的 console.log(event.request); 如下所示：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/561794/201907/561794-20190708001510448-1793935663.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;fetch方法它返回的是一个promise对象，如果用户和服务器在线正常的话，那么他们就返回页面中正常的页面，那么这个时候promise对象会返回完成状态。如下我们把利息勾选框去掉，再刷新下页面，可以看到如下信息：&lt;br/&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/561794/201907/561794-20190708001538146-1091910023.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;如上页面正常返回了，它就不会进入promise中catch异常的情况下，但是如果离线状态或者异常的情况下，那么就会进入catch异常代码。&lt;br/&gt;因此catch函数就会被调用到。&lt;/p&gt;

&lt;p&gt;6. 理解 CacheStorage缓存&lt;/p&gt;
&lt;p&gt;在前面的学习当中，当用户离线的时候，我们可以向他们的页面显示自定义的html内容，而不是浏览器的默认错误提示，但是这样也不是最好的处理方式，我们现在想要做的是，如果用户在线的时候，我们以正常的index.html内容显示给用户，包括html内容，图片和css样式等，当用户离线的时候，我们的目标还是想显示index.html中的内容，图片和css样式等这样的显示给用户，也就是说，不管是在线也好，离线也好，我们都喜欢这样显示内容给用户访问。因此如果我们想要实现这么一个功能的话，我们需要在用户在线访问的时候，使用缓存去拿到文件，然后当用户离线的时候，我们就显示缓存中的文件和内容即可实现这样的功能。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;什么是CacheStorage？&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;CacheStorage 是一种全新的缓存层，它拥有完全的控制权。既然CacheStorage可以缓存，那么我们现在要想的问题是，我们什么时候进行缓存呢？到目前为止，我们先来看下 service worker的简单的生命周期如下：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;安装中 ----&amp;gt; 激活中 -----&amp;gt; 已激活&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;我们之前是使用 service worker 监听了fetch事件，那么该事件只能够被激活状态的service worker所捕获，但是我们目前不能在该事件中来缓存我们的文件。我们需要监听一个更早的事件来缓存我们的service worker页面所依赖的文件。&lt;/p&gt;
&lt;p&gt;因此我们需要使用 service worker中的install事件，在每个service worker中，该事件只会发生一次。即首次在注册之后以及激活之前，该事件会发生。在service worker接管页面并开始监听fetch事件之前，我们通过该事件进行监听，因此就可以很好的缓存我们所有离线可用的文件。&lt;/p&gt;
&lt;p&gt;如果安装有问题的话，我们可以在install事件中取消安装service worker，如果在缓存时出现问题的话，我们可以终止安装，因为当用户刷新页面后，浏览器会在用户下次访问页面时再次尝试安装service worker。通过这种方式，我们可以有效的为service worker创建安装依赖，也就是说在service worker安装并激活之前，我们必须下载并缓存这些文件。&lt;/p&gt;
&lt;p&gt;因此我们现在把 sw.js 全部代码改成如下代码：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;34&quot;&gt;
&lt;pre&gt;
&lt;span&gt;//&lt;/span&gt;&lt;span&gt; 监听install的事件&lt;/span&gt;
self.addEventListener(&quot;install&quot;, &lt;span&gt;function&lt;/span&gt;&lt;span&gt;(e) {
  e.waitUntil(
    caches.open(&lt;/span&gt;&quot;cacheName&quot;).then(&lt;span&gt;function&lt;/span&gt;&lt;span&gt;(cache) {
      &lt;/span&gt;&lt;span&gt;return&lt;/span&gt; cache.add(&quot;/public/index.html&quot;&lt;span&gt;);
    })
  )
});&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;如上代码，我们为install事件添加了事件监听器，在新的service worker注册之后，该事件会立即在其安装阶段被调用。&lt;/p&gt;
&lt;p&gt;如上我们的service worker 依赖于 &quot;/public/index.html&quot;, 我们需要验证它是否成功缓存，然后我们才能认为它安装成功，并激活新的 service worker，因为需要异步获取文件并缓存起来，所以我们需要延迟install事件，直到异步事件完成，因此我们这边使用了waitUntil，waitUntil会延长事件存在的时间，直到promise成功，我们才会调用then方法后面的函数。&lt;br/&gt;在waitUntil函数中，我们调用了 caches.open并传入了缓存的名称为 &quot;cacheName&quot;. caches.open 打开并返回一个现有的缓存，如果没有找到该缓存，我们就创建该缓存并返回他。最后我们执行then里面的回调函数，我们使用了 cache.add(&quot;/public/index.html&quot;).这个方法将请求文件放入缓存中，缓存的键名是 &quot;/public/index.html&quot;。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2. 从CacheStorage中取回请求&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;上面我们使用 cache.add 将页面的离线版本存储到 CacheStorage当中，现在我们需要做的事情是从缓存中取回并返回给用户。&lt;/p&gt;
&lt;p&gt;因此我们需要在sw.js 中添加fetch事件代码，添加如下代码：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;34&quot;&gt;
&lt;pre&gt;
&lt;span&gt;//&lt;/span&gt;&lt;span&gt; 监听fetch事件&lt;/span&gt;
self.addEventListener(&quot;fetch&quot;, &lt;span&gt;function&lt;/span&gt;&lt;span&gt;(e) {
  e.respondWith(
    fetch(e.request).&lt;/span&gt;&lt;span&gt;catch&lt;/span&gt;(&lt;span&gt;function&lt;/span&gt;&lt;span&gt;() {
      &lt;/span&gt;&lt;span&gt;return&lt;/span&gt; caches.match(&quot;/public/index.html&quot;&lt;span&gt;);
    })
  )
});&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;如上代码和我们之前的fetch事件代码很相似，我们这边使用 caches.match 从CacheStorage中返回内容。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;注意：&lt;/strong&gt;match方法可以在caches对象上调用，这样会在所有缓存中寻找，也可以在某个特定的cache对象上调用。如下所示：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;34&quot;&gt;
&lt;pre&gt;
&lt;span&gt;//&lt;/span&gt;&lt;span&gt; 在所有缓存中寻找匹配的请求&lt;/span&gt;
caches.match('/public/index.html'&lt;span&gt;);

&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; 在特定的缓存中寻找匹配的请求&lt;/span&gt;
cache.open(&quot;cacheName&quot;).then(&lt;span&gt;function&lt;/span&gt;&lt;span&gt;(cache) {
  &lt;/span&gt;&lt;span&gt;return&lt;/span&gt; cache.match(&quot;/public/index.html&quot;&lt;span&gt;);
});&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;match方法会返回一个promise对象，并且向resolve方法传入在缓存中找到的第一个response对象，当找不到任何内容的时候，它的值是undefined。也就是说，即使match找不到对应的响应的时候，match方法也不会被拒绝。如下所示：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;32&quot;&gt;
&lt;pre&gt;
caches.match(&quot;/public/index.html&quot;).then(&lt;span&gt;function&lt;/span&gt;&lt;span&gt;(response) {
  &lt;/span&gt;&lt;span&gt;if&lt;/span&gt;&lt;span&gt; (response) {
    &lt;/span&gt;&lt;span&gt;return&lt;/span&gt;&lt;span&gt; response;
  }
});&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;3. 在demo中使用缓存&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;在如上我们已经把sw.js 代码改成如下了：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;37&quot;&gt;
&lt;pre&gt;
&lt;span&gt;//&lt;/span&gt;&lt;span&gt; 监听install的事件&lt;/span&gt;
self.addEventListener(&quot;install&quot;, &lt;span&gt;function&lt;/span&gt;&lt;span&gt;(e) {
  e.waitUntil(
    caches.open(&lt;/span&gt;&quot;cacheName&quot;).then(&lt;span&gt;function&lt;/span&gt;&lt;span&gt;(cache) {
      &lt;/span&gt;&lt;span&gt;return&lt;/span&gt; cache.add(&quot;/public/index.html&quot;&lt;span&gt;);
    })
  )
});

&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; 监听fetch事件&lt;/span&gt;
self.addEventListener(&quot;fetch&quot;, &lt;span&gt;function&lt;/span&gt;&lt;span&gt;(e) {
  e.respondWith(
    fetch(e.request).&lt;/span&gt;&lt;span&gt;catch&lt;/span&gt;(&lt;span&gt;function&lt;/span&gt;&lt;span&gt;() {
      &lt;/span&gt;&lt;span&gt;return&lt;/span&gt; caches.match(&quot;/public/index.html&quot;&lt;span&gt;);
    })
  )
});&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;当我们第一次访问页面的时候，我们会监听install事件，对我们的 &quot;/public/index.html&quot; 进行缓存，然后当我们切换到离线状态的时候，我们再次刷新可以看到我们的页面只是缓存了 index.html页面，但是页面中的css和图片并没有缓存，如下所示：&lt;br/&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/561794/201907/561794-20190708002041292-799065851.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;现在我们要做的事情是，我们需要对我们所有页面的上的css，图片，js等资源文件进行缓存，因此我们的sw.js 代码需要改成如下所示：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;39&quot;&gt;
&lt;pre&gt;
&lt;span&gt;var&lt;/span&gt; CACHE_NAME = &quot;cacheName&quot;&lt;span&gt;;
&lt;/span&gt;&lt;span&gt;var&lt;/span&gt; CACHE_URLS =&lt;span&gt; [
  &lt;/span&gt;&quot;/public/index.html&quot;&lt;span&gt;,
  &lt;/span&gt;&quot;/main.css&quot;&lt;span&gt;,
  &lt;/span&gt;&quot;/public/images/xxx.jpg&quot;&lt;span&gt;
];

self.addEventListener(&lt;/span&gt;&quot;install&quot;, &lt;span&gt;function&lt;/span&gt;&lt;span&gt;(e) {
  e.waitUntil(
    caches.open(CACHE_NAME).then(&lt;/span&gt;&lt;span&gt;function&lt;/span&gt;&lt;span&gt;(cache) {
      &lt;/span&gt;&lt;span&gt;return&lt;/span&gt;&lt;span&gt; cache.addAll(CACHE_URLS);
    })
  )
});

&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; 监听fetch事件&lt;/span&gt;
self.addEventListener(&quot;fetch&quot;, &lt;span&gt;function&lt;/span&gt;&lt;span&gt;(e) {
  e.respondWith(
    fetch(e.request).&lt;/span&gt;&lt;span&gt;catch&lt;/span&gt;(&lt;span&gt;function&lt;/span&gt;&lt;span&gt;() {
      &lt;/span&gt;&lt;span&gt;return&lt;/span&gt; caches.match(e.request).then(&lt;span&gt;function&lt;/span&gt;&lt;span&gt;(response) {
        &lt;/span&gt;&lt;span&gt;if&lt;/span&gt;&lt;span&gt; (response) {
          &lt;/span&gt;&lt;span&gt;return&lt;/span&gt;&lt;span&gt; response;
        } &lt;/span&gt;&lt;span&gt;else&lt;/span&gt; &lt;span&gt;if&lt;/span&gt; (e.request.headers.get(&quot;accept&quot;).includes(&quot;text/html&quot;&lt;span&gt;)) {
          &lt;/span&gt;&lt;span&gt;return&lt;/span&gt; caches.match(&quot;/public/index.html&quot;&lt;span&gt;);
        }
      })
    })
  )
});&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;如上代码，我们设置了两个变量，第一个变量 CACHE_NAME 是缓存的名称，第二个变量是一个数组，它包含了一份需要存储的URL列表。&lt;/p&gt;
&lt;p&gt;然后我们使用了 cache.addAll()方法，它接收的参数是一个数组，它的作用是把数组里面的每一项存入缓存当中去，当然如果任何一个缓存失败的话，那么它返回的promise会被拒绝。&lt;/p&gt;
&lt;p&gt;我们监听了install事件后对所有的资源文件进行了缓存后，当用户处于离线状态的时候，我们使用fetch的事件来监听所有的请求。当请求失败的时候，我们会调用catch里面的函数来匹配所有的请求，它也是返回一个promise对象，当匹配成功后，找到对应的项的时候，直接从缓存里面读取，如果没有找到的话，就直接返回 &quot;/public/index.html&quot; 的内容作为代替。为了安全起见，我们在返回&quot;/public/index.html&quot; 之前，我们还进行了一项检查，该检查确保请求是包含 text/html的accept的头部，因此我们就不会返回html内容给其他的请求类型。比如图片，样式请求等。&lt;/p&gt;
&lt;p&gt;我们之前创建一个html响应的时候，必须将其 Content-Type的值定义为 text/html，方便浏览器可以正确的响应识别它是html类型的，那么为什么我们这边没有定义呢，而直接返回了呢？那是因为我们的 cache.addAll()请求并缓存的是一个完整的response对象，该对象不仅包含了响应体，还包含了服务器返回的任何响应头。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;注意：使用 caches.match(e.request) 来查找缓存中的条目会存在一个陷阱。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;比如用户可能不会总是以相同的url来访问我们的页面，比如它会从其他的网站中跳转到我们的页面上来，比如后面带了一些参数，比如：&quot;/public/index.html?id=xxx&quot; 这样的，也就是说url后面带了一些查询字符串等这些字段，如果我们还是和之前一样进行匹配，是匹配不到的，因此我们需要在match方法中添加一个对象选项；如下所示：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;33&quot;&gt;
&lt;pre&gt;
caches.match(e.request, {ignoreSearch: &lt;span&gt;true&lt;/span&gt;});
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;这样的，通过 ignoreSearch 这个参数，通知match方法来忽略查询字符串。&lt;/p&gt;
&lt;p&gt;现在我们先请求下我们的页面，然后我们勾选离线复选框，再来查看下我们的页面效果如下所示：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/561794/201907/561794-20190708002249277-107252372.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;如上可以看到，我们在离线的状态下，页面显示也是正常的。&lt;/p&gt;

&lt;p&gt;7. 理解service worker生命周期&lt;/p&gt;
&lt;p&gt; service worker 的生命周期如下图所示：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/561794/201907/561794-20190708002318297-380953293.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;installing(正在安装)&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;当我们使用 navigator.serviceWorker.register 注册一个新的 service worker的时候，javascript代码就会被下载、解析、并进入安装状态。如果安装成功的话，service worker 就会进入 installed(已安装)的状态。但是如果在安装过程中出现错误，脚本将被永久进入 redundant(废弃中)。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;installed/waiting(已安装/等待中)&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;一旦service worker 安装成功了，就会进入 installed状态，一般情况中，会马上进入 activating(激活中)状态。除非另一个正在激活的 service worker 依然在被控制中。在这种情况下它会维持在 waiting(等待中)状态。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;activating(激活中)&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;在service worker激活并接管应用之前，会触发 activate 事件。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;activated(已激活)&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;一旦 service worker 被激活了，它就准备好接管页面并监听功能性事件(比如fetch事件)。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;redundant(废弃)&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;如果service worker在注册或安装过程中失败了，或者被新的版本代替，就会被置为 redundant 状态，处于这种 service worker将不再对应用产生任何影响。&lt;/p&gt;
&lt;p&gt;注意：service worker的状态和浏览器的任何一个窗口或标签页都没有关系的，也就是说 如果service worker是activated(已激活)状态的话，它就会保持这个状态。&lt;/p&gt;

&lt;p&gt;8. 理解 service worker 注册过程&lt;/p&gt;
&lt;p&gt; 当我们第一次访问我们的网站的时候(我们也可以通过删除service worker后刷新页面的方式进行模拟)，页面就会加载我们的main.js 代码，如下所示：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;37&quot;&gt;
&lt;pre&gt;
&lt;span&gt;if&lt;/span&gt; (&quot;serviceWorker&quot; &lt;span&gt;in&lt;/span&gt;&lt;span&gt; navigator) {
  navigator.serviceWorker.register(&lt;/span&gt;'/sw.js', {scope: '/'}).then(&lt;span&gt;function&lt;/span&gt;&lt;span&gt;(registration) {
    console.log(&lt;/span&gt;&quot;Service Worker registered with scope: &quot;&lt;span&gt;, registration.scope);
  }).&lt;/span&gt;&lt;span&gt;catch&lt;/span&gt;(&lt;span&gt;function&lt;/span&gt;&lt;span&gt;(err) {
    console.log(&lt;/span&gt;&quot;Service Worker registered failed:&quot;&lt;span&gt;, err);
  });
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;那么我们的应用就会注册service worker，那么service worker的文件将会被下载，然后就开始安装，install事件就会被触发，并且在service worker整个生命周期中只会触发一次，然后触发了我们的函数，将调用的时机记录在控制台中。service worker随后就会进入 installed状态。然后立即就会变成 activating 状态。这个时候，我们的另一个函数就会被触发，因此 activate事件就会把状态记录到控制台中。最后，service worker 进入 activated(已激活)状态。现在service worker被激活状态了。&lt;/p&gt;
&lt;p&gt;但是当我们的service worker 正在安装的时候，我们的页面已经开始加载并且渲染了。也就是说 service worker 变成了 active状态了。因此就不能控制页面了，只有我们再刷新页面的时候，我们的已经被激活的service worker才能控制页面。因此我们就可以监听和操控fetch事件了。&lt;/p&gt;

&lt;p&gt;9. 理解更新service worker&lt;/p&gt;
&lt;p&gt; 我们首先来修改下 sw.js 代码，改成如下：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;35&quot;&gt;
&lt;pre&gt;
self.addEventListener(&quot;fetch&quot;, &lt;span&gt;function&lt;/span&gt;&lt;span&gt;(e) {
  &lt;/span&gt;&lt;span&gt;if&lt;/span&gt; (e.request.url.includes(&quot;main.css&quot;&lt;span&gt;)) {
    e.respondWith(
      &lt;/span&gt;&lt;span&gt;new&lt;/span&gt;&lt;span&gt; Response(
        &lt;/span&gt;&quot;#app {color:red;}&quot;&lt;span&gt;,
        {headers: { &lt;/span&gt;&quot;Content-Type&quot;: &quot;text/css&quot;&lt;span&gt; }}
      )
    )
  }
});&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;然后我们再刷新页面，发现页面中的颜色并没有改变，为什么呢？但是我们service worker明明控制了页面，但是页面为什么没有生效？&lt;br/&gt;我们可以打开chrome开发者工具中 Application -&amp;gt; Service Worker 来理解这段代码的含义：如下图所示：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/561794/201907/561794-20190708002623915-990929333.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;如上图所示，页面注册了多个service worker，但是只有一个在控制页面，旧的service worker是激活的，而新的service worker仍处于等待状态。&lt;/p&gt;
&lt;p&gt;每当页面加载一个激活的service worker，就会检查 service worker 脚本的更新。如果文件在当前的service worker注册之后发生了修改，新的文件就会被注册和安装。安装完成后，它并不会替换原先的service worker，而是会保持 waiting 状态。它将会一直保持等待状态，直到原先的service worker作用域中的每个标签和窗口关闭。或者导航到一个不再控制范围内的页面。但是我们可以关闭原先的service worker, 那么原先的service worker 就会变成废弃状态。然后我们新的service worker就会被激活。因此我们可以如下图所示：&lt;br/&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/561794/201907/561794-20190708002717424-1035680790.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;但是如果我们想修改完成后，不结束原来的service worker的话，想改动代码，刷新一下就生效的话，我们需要把 Update on reload这个复选框勾上即可生效，比如如下所示：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/561794/201907/561794-20190708002747791-1876874861.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;注意：&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;那么为什么安装完成新的service worker 不能实时生效呢？比如说安装新的service worker不能控制新的页面呢？原先的service worker 控制原先的页面呢？为什么浏览器不能跟踪多个service worker 呢？为什么所有的页面都必须由单一的service worker所控制呢？&lt;/p&gt;
&lt;p&gt;我们可以设想下如下这么一个场景，如果我们发布了一个新版本的service worker，并且该service worker的install事件会从缓存中删除 update.json 该文件，并添加 update2.json文件作为代替，并且修改fetch事件，让其在请求用户数据的时候，返回新的文件，如果多个service worker控制了不同的页面，那么旧的service worker控制的页面可能会在缓存中搜索旧的 update.json 文件，但是该文件又被删除了，那么就会导致该应用奔溃。因此我们需要被确保打开所有的标签页或窗口由一个service worker控制的话，就可以避免类似的问题发生。&lt;/p&gt;

&lt;p&gt;10. 理解缓存管理和清除缓存&lt;/p&gt;
&lt;p&gt;为什么需要管理缓存呢？&lt;/p&gt;
&lt;p&gt;我们首先把我们的sw.js 代码改成原先的如下代码：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;39&quot;&gt;
&lt;pre&gt;
&lt;span&gt;var&lt;/span&gt; CACHE_NAME = &quot;cacheName&quot;&lt;span&gt;;
&lt;/span&gt;&lt;span&gt;var&lt;/span&gt; CACHE_URLS =&lt;span&gt; [
  &lt;/span&gt;&quot;/public/index.html&quot;&lt;span&gt;,
  &lt;/span&gt;&quot;/main.css&quot;&lt;span&gt;,
  &lt;/span&gt;&quot;/public/images/xxx.jpg&quot;&lt;span&gt;
];

self.addEventListener(&lt;/span&gt;&quot;install&quot;, &lt;span&gt;function&lt;/span&gt;&lt;span&gt;(e) {
  e.waitUntil(
    caches.open(CACHE_NAME).then(&lt;/span&gt;&lt;span&gt;function&lt;/span&gt;&lt;span&gt;(cache) {
      &lt;/span&gt;&lt;span&gt;return&lt;/span&gt;&lt;span&gt; cache.addAll(CACHE_URLS);
    })
  )
});

&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; 监听fetch事件&lt;/span&gt;
self.addEventListener(&quot;fetch&quot;, &lt;span&gt;function&lt;/span&gt;&lt;span&gt;(e) {
  e.respondWith(
    fetch(e.request).&lt;/span&gt;&lt;span&gt;catch&lt;/span&gt;(&lt;span&gt;function&lt;/span&gt;&lt;span&gt;() {
      &lt;/span&gt;&lt;span&gt;return&lt;/span&gt; caches.match(e.request).then(&lt;span&gt;function&lt;/span&gt;&lt;span&gt;(response) {
        &lt;/span&gt;&lt;span&gt;if&lt;/span&gt;&lt;span&gt; (response) {
          &lt;/span&gt;&lt;span&gt;return&lt;/span&gt;&lt;span&gt; response;
        } &lt;/span&gt;&lt;span&gt;else&lt;/span&gt; &lt;span&gt;if&lt;/span&gt; (e.request.headers.get(&quot;accept&quot;).includes(&quot;text/html&quot;&lt;span&gt;)) {
          &lt;/span&gt;&lt;span&gt;return&lt;/span&gt; caches.match(&quot;/public/index.html&quot;&lt;span&gt;);
        }
      })
    })
  )
});&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;如上代码，我们的service worker会在安装阶段下载并缓存所需要的文件。如果希望它再次下载并缓存这些文件的话，我们就需要触发另一个安装事件。在sw.js中的，我们把 CACHE_NAME 名字改下即可。比如叫 var CACHE_NAME = &quot;cacheName2&quot;; 这样的。&lt;/p&gt;
&lt;p&gt;通过如上给缓存名称添加版本号，并且每次修改文件时自增它，可以实现两个目的。&lt;/p&gt;
&lt;p&gt;1）修改缓存名称后，浏览器就知道安装新的service worker来代替旧的service worker了，因此会触发install事件，因此会导致文件被下载并存储在缓存中。&lt;/p&gt;
&lt;p&gt;2）它为每一个版本的service worker都创建了一份单独的缓存。即使我们更新了缓存，在用户关闭所有页面之前，旧的service worker依然是激活的。旧的service worker可能会用到缓存中的某些文件，而这些文件又是可以被新的service worker所修改的，通过让每个版本的service worker所拥有自己的缓存，就可以确保不会出现其他的异常情况。&lt;/p&gt;
&lt;p&gt;如何清除缓存呢？&lt;/p&gt;
&lt;p&gt;caches.delete(cacheName); 该方法接收一个缓存名字作为第一个参数，并删除对应的缓存。&lt;/p&gt;
&lt;p&gt;caches.keys(); 该方法是获取所有缓存的名称，并且返回一个promsie对象，其完成的时候会返回一个包含缓存名称的数组。如下所示：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;33&quot;&gt;
&lt;pre&gt;
caches.keys().then(&lt;span&gt;function&lt;/span&gt;&lt;span&gt;(cacheNames){
  cacheNames.forEach(&lt;/span&gt;&lt;span&gt;function&lt;/span&gt;&lt;span&gt;(cacheName){
    caches.&lt;/span&gt;&lt;span&gt;delete&lt;/span&gt;&lt;span&gt;(cacheName);
  });
});&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;如何缓存管理呢？&lt;/p&gt;
&lt;p&gt;在service worker生命周期中，我们需要实现如下目标：&lt;br/&gt;1）每次安装 service worker，我们都需要创建一份新的缓存。&lt;br/&gt;2）当新的service worker激活的时候，就可以安全删除过去的service worker 创建的所有缓存。&lt;/p&gt;
&lt;p&gt;因此我们在现有的代码中，添加一个新的事件监听器，监听 activate 事件。&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;35&quot;&gt;
&lt;pre&gt;
self.addEventListener(&quot;activate&quot;, &lt;span&gt;function&lt;/span&gt;&lt;span&gt;(e) {
  e.waitUntil(
    caches.keys().then(&lt;/span&gt;&lt;span&gt;function&lt;/span&gt;&lt;span&gt;(cacheNames) {
      &lt;/span&gt;&lt;span&gt;return&lt;/span&gt;&lt;span&gt; Promise.all(
        cacheNames.map(&lt;/span&gt;&lt;span&gt;function&lt;/span&gt;&lt;span&gt;(cacheName) {
          &lt;/span&gt;&lt;span&gt;if&lt;/span&gt; (CACHE_NAME !== cacheName &amp;amp;&amp;amp; cacheName.startWith(&quot;cacheName&quot;&lt;span&gt;)) {
            &lt;/span&gt;&lt;span&gt;return&lt;/span&gt; caches.&lt;span&gt;delete&lt;/span&gt;&lt;span&gt;(cacheName);
          }
        })
      )
    })
  )
});&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;11. 理解重用已缓存的响应&lt;/p&gt;
&lt;p&gt;如上我们的带版本号缓存已经实现了，为我们提供了一个非常灵活的方式来控制我们的缓存，并且保持最新的缓存。但是缓存内的实现是非常低下的。&lt;/p&gt;
&lt;p&gt;比如每次我们创建一个新的缓存的时候，我们会使用 cache.add() 或 cache.addAll() 这样的方法来缓存应用需要的所有文件。但是，如果用户已经在本地拥有了 cacheName 这个缓存的话，那如果这个时候我们创建 cacheName2 这个缓存的话，我们发现我们创建的 cacheName2 需要缓存的文件 在 cacheName 已经有了，并且我们发现这些文件是永远不会被改变的。如果我们重新缓存这些文件的话，就浪费了宝贵的带宽和时间从网络再次下载他们。&lt;/p&gt;
&lt;p&gt;为了解决如上的问题，我们需要如下做：&lt;/p&gt;
&lt;p&gt;如果我们创建一个新的缓存，我们首先要遍历一份不可变的文件列表，然后从现有的缓存中寻找他们，并直接复制到新的缓存中。因此我们的sw.js 代码变成如下所示：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;38&quot;&gt;
&lt;pre&gt;
&lt;span&gt;var&lt;/span&gt; CACHE_NAME = &quot;cacheName&quot;&lt;span&gt;;
&lt;/span&gt;&lt;span&gt;var&lt;/span&gt; immutableRequests =&lt;span&gt; [
  &lt;/span&gt;&quot;/main.css&quot;&lt;span&gt;,
  &lt;/span&gt;&quot;/public/images/xxx.jpg&quot;&lt;span&gt;
];

&lt;/span&gt;&lt;span&gt;var&lt;/span&gt; mutableRequests =&lt;span&gt; [
  &lt;/span&gt;&quot;/public/index.html&quot;&lt;span&gt;
];

self.addEventListener(&lt;/span&gt;&quot;install&quot;, &lt;span&gt;function&lt;/span&gt;&lt;span&gt;(e) {
  e.waitUntil(
    caches.open(CACHE_NAME).then(&lt;/span&gt;&lt;span&gt;function&lt;/span&gt;&lt;span&gt;(cache) {
      &lt;/span&gt;&lt;span&gt;var&lt;/span&gt; newImmutableRequests =&lt;span&gt; [];
      &lt;/span&gt;&lt;span&gt;return&lt;/span&gt;&lt;span&gt; Promise.all(
        immutableRequests.map(&lt;/span&gt;&lt;span&gt;function&lt;/span&gt;&lt;span&gt;(url) {
          &lt;/span&gt;&lt;span&gt;return&lt;/span&gt; caches.match(url).then(&lt;span&gt;function&lt;/span&gt;&lt;span&gt;(response) {
            &lt;/span&gt;&lt;span&gt;if&lt;/span&gt;&lt;span&gt; (response) {
              &lt;/span&gt;&lt;span&gt;return&lt;/span&gt;&lt;span&gt; cache.put(url, response);
            } &lt;/span&gt;&lt;span&gt;else&lt;/span&gt;&lt;span&gt; {
              newImmutableRequests.push(url);
              &lt;/span&gt;&lt;span&gt;return&lt;/span&gt;&lt;span&gt; Promise.resolve();
            }
          });
        })
      ).then(&lt;/span&gt;&lt;span&gt;function&lt;/span&gt;&lt;span&gt;(){
        &lt;/span&gt;&lt;span&gt;return&lt;/span&gt;&lt;span&gt; cache.addAll(newImmutableRequests.concat(mutableRequests));
      })
    })
  )
});&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;如上代码。&lt;/p&gt;
&lt;p&gt;1）immutableRequests 数组中包含了我们知道永远不会改变的资源URL，这些资源可以安全地在缓存之间复制。&lt;/p&gt;
&lt;p&gt;2）mutableRequests 中包含了每次创建新缓存时，我们都需要从网络中请求的url。&lt;/p&gt;
&lt;p&gt;如上代码，我们的 install 事件会遍历所有的 immutableRequests，并且在所有现有的缓存中寻找他们。如果被找到的话，都会使用cache.put()复制到新的缓存中。如果没有找到该资源的话，会被放入到新的 newImmutableRequests 数组中。&lt;/p&gt;
&lt;p&gt;一旦所有的请求被检查完毕，代码就会使用 cache.addAll()来缓存 mutableRequests 和 newImmutableRequests 中所有的URL。&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/tugenhua0707/service-worker-demo/tree/master/service-worker-demo1&quot; target=&quot;_blank&quot;&gt;github源码查看&lt;/a&gt;&lt;/p&gt;
</description>
<pubDate>Sun, 07 Jul 2019 16:32:00 +0000</pubDate>
<dc:creator>龙恩0707</dc:creator>
<og:description>渐进式web应用开发---service worker (二)</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/tugenhua0707/p/11148968.html</dc:identifier>
</item>
<item>
<title>网络IO-阻塞、非阻塞、IO复用、异步 - killianxu</title>
<link>http://www.cnblogs.com/killianxu/p/11148522.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/killianxu/p/11148522.html</guid>
<description>&lt;p&gt;&lt;br/&gt;　　网络socket输入操作分为两个阶段:等待网络数据到达和将到达内核的数据复制到应用进程缓冲区。对这两个阶段不同的处理方式将网络IO分为不同的模型:IO阻塞模型、非阻塞模型、多路复用和异步IO。本文可运行代码链接:&lt;a href=&quot;https://github.com/killianxu/network_example&quot; target=&quot;_blank&quot;&gt;https://github.com/killianxu/network_example&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;一 阻塞模型&lt;/h2&gt;
&lt;p&gt;　　阻塞模型原理如下图1.1,当进行系统调用recvfrom时,应用进程进入内核态,内核判断是否已收到数据报，若没有则阻塞直到数据报准备好,接着复制数据到应用进程缓冲区,然后函数返回。&lt;/p&gt;
&lt;p&gt; &lt;img src=&quot;https://img2018.cnblogs.com/blog/1497240/201907/1497240-20190707225945523-1393648398.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;br/&gt;图1.1 阻塞IO模型&lt;/p&gt;
&lt;p&gt;&lt;br/&gt;　　阻塞模型缺点:若数据报未准备好,则线程阻塞,不能进行其它操作和网络连接请求。&lt;br/&gt;　　利用多进程多线程方案,为每个连接创建一个进程或线程,这样一个线程的阻塞不会影响到其它连接,但当遇到连接请求比较多时,会创建较多的进程或线程,严重浪费系统资源,影响进程的响应效率,进程和线程也更容易进入假死状态。&lt;br/&gt;　　利用线程池或连接池,可以减少资源消耗。线程池利用已有线程,减少线程频繁创建和销毁,线程维持在一定数量,当有新的连接请求时，重用已有线程。连接池尽量重用已有连接,减少连接的创建和关闭。线程池和连接池一定程度上缓解频繁IO的资源消耗,但线程池和连接池都有一定规模，当连接请求数远超过池上线，池系统构成的响应并不比多线程方案好多少。[1]&lt;br/&gt;　　阻塞模型python实例demo如下:&lt;br/&gt;　　阻塞模型server端&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;39&quot;&gt;
&lt;pre&gt;
&lt;span&gt;def&lt;/span&gt;&lt;span&gt; start_blocking(self):
        &lt;/span&gt;&lt;span&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span&gt;同步阻塞server&lt;/span&gt;&lt;span&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span&gt;
        self.ssock &lt;/span&gt;=&lt;span&gt; socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        self.ssock.bind((&lt;/span&gt;&lt;span&gt;''&lt;/span&gt;, 8080&lt;span&gt;))
        self.ssock.listen(&lt;/span&gt;5&lt;span&gt;)
        count &lt;/span&gt;=&lt;span&gt; 0
        &lt;/span&gt;&lt;span&gt;while&lt;/span&gt;&lt;span&gt; True:
            conn, addr &lt;/span&gt;=&lt;span&gt; self.ssock.accept()
            count &lt;/span&gt;+= 1
            &lt;span&gt;print&lt;/span&gt; &lt;span&gt;'&lt;/span&gt;&lt;span&gt;Connected by&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;, addr
            &lt;/span&gt;&lt;span&gt;print&lt;/span&gt; &lt;span&gt;'&lt;/span&gt;&lt;span&gt;Accepted clinet count:%d&lt;/span&gt;&lt;span&gt;'&lt;/span&gt; %&lt;span&gt; count
            data &lt;/span&gt;= conn.recv(1024) &lt;span&gt;#&lt;/span&gt;&lt;span&gt;若无数据则阻塞&lt;/span&gt;
            &lt;span&gt;if&lt;/span&gt;&lt;span&gt; data:
                conn.sendall(data)
            conn.close()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　阻塞模型client&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;36&quot;&gt;
&lt;pre&gt;
&lt;span&gt;def&lt;/span&gt;&lt;span&gt; start_blocking(self):
        self.host &lt;/span&gt;= &lt;span&gt;'&lt;/span&gt;&lt;span&gt;123.207.123.108&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;
        self.port &lt;/span&gt;= 8080&lt;span&gt;
        self.csock &lt;/span&gt;=&lt;span&gt; socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        self.csock.connect((self.host, self.port))
        data &lt;/span&gt;= self.csock.recv(1024&lt;span&gt;)
        &lt;/span&gt;&lt;span&gt;print&lt;/span&gt; data
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　运行server端,并运行两个client实例去连接服务端,运行结果如下图1.2,可以看到虽然有两个客户端去连接,但却只有一个连接上,服务端的socket conn为阻塞套接字,conn.recv(1024)未收到客户端发送的数据,处于阻塞状态,服务端无法再响应另一个客户端的连接。&lt;br/&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1497240/201907/1497240-20190707232444935-1189933895.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;图1.2 阻塞IO服务端运行结果&lt;/p&gt;
&lt;h2&gt;二 非阻塞模型&lt;/h2&gt;
&lt;p&gt;　　由于阻塞IO无法满足大规模请求的缺点,因此出现了非阻塞模型。非阻塞IO模型如下图1.3所示,当数据报未准备好,recvfrom立即返回一个EWOULDBLOCK错误,可以利用轮询不停调用recvfrom,当数据报准备好,内核则将数据复制到应用进程缓冲区。&lt;br/&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1497240/201907/1497240-20190707232635471-1687123207.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;图1.3 非阻塞IO模型&lt;/p&gt;
&lt;p&gt;&lt;br/&gt;　　非阻塞IO模型需要利用轮询不断调用recvfrom,浪费大量CPU时间,且当内核接收到数据时,需要等到下一次轮询才能复制到应用进程缓冲区,数据得不到立刻处理。&lt;br/&gt;　　非阻塞模型python demo如下:&lt;br/&gt;　　非阻塞服务端&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;40&quot;&gt;
&lt;pre&gt;
&lt;span&gt;def&lt;/span&gt;&lt;span&gt; start_noblocking(self):
        &lt;/span&gt;&lt;span&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span&gt;
        同步非阻塞
        &lt;/span&gt;&lt;span&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span&gt;
        self.ssock &lt;/span&gt;=&lt;span&gt; socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        self.ssock.bind((&lt;/span&gt;&lt;span&gt;''&lt;/span&gt;, 8080&lt;span&gt;))
        self.ssock.listen(&lt;/span&gt;5&lt;span&gt;)
        count &lt;/span&gt;=&lt;span&gt; 0
        &lt;/span&gt;&lt;span&gt;while&lt;/span&gt;&lt;span&gt; True:
            conn, addr &lt;/span&gt;=&lt;span&gt; self.ssock.accept()
            conn.setblocking(0) &lt;/span&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt;设置为非阻塞socket&lt;/span&gt;
            count += 1
            &lt;span&gt;print&lt;/span&gt; &lt;span&gt;'&lt;/span&gt;&lt;span&gt;Connected by&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;, addr
            &lt;/span&gt;&lt;span&gt;print&lt;/span&gt; &lt;span&gt;'&lt;/span&gt;&lt;span&gt;Accepted clinet count:%d&lt;/span&gt;&lt;span&gt;'&lt;/span&gt; %&lt;span&gt; count
            &lt;/span&gt;&lt;span&gt;try&lt;/span&gt;&lt;span&gt;:
                data &lt;/span&gt;= conn.recv(1024) &lt;span&gt;#&lt;/span&gt;&lt;span&gt;非阻塞,没有数据会立刻返回&lt;/span&gt;
                &lt;span&gt;if&lt;/span&gt;&lt;span&gt; data:
                    conn.sendall(data)
            &lt;/span&gt;&lt;span&gt;except&lt;/span&gt;&lt;span&gt; Exception as e:
               &lt;/span&gt;&lt;span&gt;pass&lt;/span&gt;
            &lt;span&gt;finally&lt;/span&gt;&lt;span&gt;:
                conn.close()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　运行非阻塞服务端和两个客户端实例,结果如下图1.4所示,服务端接收两个连接请求。由于conn被设置为非阻塞socket,即使客户端并没有向服务端发送数据,conn.recv(1024)也会立即返回,不会阻塞,从而进程可以接收新的连接请求。&lt;br/&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1497240/201907/1497240-20190707232909431-275881961.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;图1.4 非阻塞服务端运行结果&lt;/p&gt;
&lt;h2&gt;三 IO复用&lt;/h2&gt;
&lt;p&gt;　　IO复用在linux中包括select、poll、epoll模型三种,这三个IO复用模型有各自的API实现,以select模型为例,调用select函数,进程进入阻塞, 同时监控多个套接字描述符的状态 ,当有数据报变为可读或阻塞超时才返回,接着进程可调用recvfrom接收数据报到应用进程缓冲区。&lt;br/&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1497240/201907/1497240-20190707233046167-654265624.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;图3.1 IO复用模型&lt;/p&gt;
&lt;p&gt;&lt;br/&gt;　　使用IO复用的优点是可以等待多个描述符就绪。&lt;sup&gt;[2]&lt;/sup&gt;&lt;/p&gt;
&lt;h3&gt;3.1 select模型&lt;/h3&gt;
&lt;p&gt;　　select模型api如下:&lt;br/&gt;　　int select(int maxfdp1, fd_set *readset, fd_set *writeset, fd_set *exceptset,struct timeval *timeout);&lt;br/&gt;timout表示内核等待任一描述符就绪可等待的时间,有三种情况:&lt;br/&gt;　　1) 空指针,表示可以一直等下去,直到有描述符就绪。&lt;br/&gt;　　2) timeout时间为0,不等待检查描述符状态立即返回。&lt;br/&gt;　　3) 时间不为0，表示等待一定时间,在有描述符准备好但不超过timeval结构所指定的秒数和微秒数。&lt;br/&gt;readset、writeset、exceptset指定需要内核测试读、写和异常条件的描述符。fd_set表示描述符集,在select中用整数数组表示,整数的每一位表示一个描述符, readset、writeset、exceptset这三个参数是值-结果类型。&lt;br/&gt;　　可以用以下几个宏设置和测试fd_set。在调用select函数前,用1、2、3设置需要监控的描述符,循环调用4测试调用select函数后的描述符,看是否准备好。&lt;br/&gt;　　1) int FD_ZERO(int fd, fd_set *fdset);&lt;br/&gt;　　2) int FD_CLR(int fd, fd_set *fdset);&lt;br/&gt;　　3) int FD_SET(int fd, fd_set *fd_set);&lt;br/&gt;　　4) int FD_ISSET(int fd, fd_set *fdset);&lt;br/&gt;　　导致select返回某个套接字就绪的条件如下:&lt;br/&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1497240/201907/1497240-20190707233454487-360564261.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;图3.2 就绪条件&lt;/p&gt;
&lt;p&gt;　　maxfd1表示指定待测试描述符个数,值为待测试描述符最大值加1,用这个参数可告诉内核最大只遍历到maxfd1-1的描述符。maxfd1最大不能超过常量FD_SETSIZE(值默认为1024，更改该值需重新编译内核)。&lt;/p&gt;
&lt;p&gt;　　select函数的返回值为整数,表示跨所有描述符集已就绪的总位数。如果超时则返回0。返回-1表示出错,比如被中断&lt;sup&gt;[3]&lt;/sup&gt;。&lt;br/&gt;　　select实现原理:从用户空间拷贝fd_set到内核空间,遍历所有fd,将当前进程挂到各个设备的等待队列中,挂到队列的同时会返回是否就绪的掩码,当所有fd返回的掩码均未就绪,则当前进程睡眠。当fd对应设备驱动发现可读写时，则会唤醒处于睡眠态的进程。如果超过一定时间还未唤醒, 则调用select的进程会重新被唤醒获得CPU，进而重新遍历fd，判断有没有就绪的fd,将fd_set从内核空间拷到用户空间&lt;sup&gt;[4]&lt;/sup&gt;。&lt;br/&gt;　　select实现的缺点:&lt;br/&gt;　　1) 每次都需要将fd_set拷贝到内核空间,当fd_set较大时开销很大&lt;br/&gt;　　2) 每次都需要在内核中遍历fd加入到等待队列,fd较多开销较大&lt;br/&gt;　　3) Select支持的文件描述符太小,默认为1024。&lt;/p&gt;
&lt;p&gt;　　select模型python demo如下:&lt;br/&gt;　　select模型服务端&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;58&quot;&gt;
&lt;pre&gt;
&lt;span&gt;def&lt;/span&gt;&lt;span&gt; start(self):
        &lt;/span&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt; create a socket&lt;/span&gt;
        server =&lt;span&gt; socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        server.setblocking(False)
        &lt;/span&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt; set option reused&lt;/span&gt;
        server.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1&lt;span&gt;)
        server_address &lt;/span&gt;= (&lt;span&gt;''&lt;/span&gt;, 8080&lt;span&gt;)
        server.bind(server_address)

        server.listen(&lt;/span&gt;10&lt;span&gt;)

        &lt;/span&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt; sockets from which we except to read&lt;/span&gt;
        inputs =&lt;span&gt; [server]

        &lt;/span&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt; sockets from which we expect to write&lt;/span&gt;
        outputs =&lt;span&gt; []

        &lt;/span&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt; Outgoing message queues (socket:Queue)&lt;/span&gt;
        message_queues =&lt;span&gt; {}

        &lt;/span&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt; A optional parameter for select is TIMEOUT&lt;/span&gt;
        timeout = 20

        &lt;span&gt;while&lt;/span&gt;&lt;span&gt; inputs:
            &lt;/span&gt;&lt;span&gt;print&lt;/span&gt; &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;waiting for next event&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;
            &lt;span&gt;#&lt;/span&gt;&lt;span&gt; 每次调用select函数,需要将所有socket重新传一次&lt;/span&gt;
            readable, writable, exceptional =&lt;span&gt; select.select(
                inputs, outputs, inputs, timeout)

            &lt;/span&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt; When timeout reached , select return three empty lists&lt;/span&gt;
            &lt;span&gt;if&lt;/span&gt; &lt;span&gt;not&lt;/span&gt; (readable &lt;span&gt;or&lt;/span&gt; writable &lt;span&gt;or&lt;/span&gt;&lt;span&gt; exceptional):
                &lt;/span&gt;&lt;span&gt;print&lt;/span&gt; &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;Time out ! &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;
                &lt;span&gt;break&lt;/span&gt;
            &lt;span&gt;for&lt;/span&gt; s &lt;span&gt;in&lt;/span&gt;&lt;span&gt; readable:
                &lt;/span&gt;&lt;span&gt;if&lt;/span&gt; s &lt;span&gt;is&lt;/span&gt; server:  &lt;span&gt;#&lt;/span&gt;&lt;span&gt; 监听套接字&lt;/span&gt;
                    &lt;span&gt;#&lt;/span&gt;&lt;span&gt; A &quot;readable&quot; socket is ready to accept a connection&lt;/span&gt;
                    connection, client_address =&lt;span&gt; s.accept()
                    &lt;/span&gt;&lt;span&gt;print&lt;/span&gt; &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;    connection from &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;, client_address
                    connection.setblocking(0)
                    inputs.append(connection)
                    message_queues[connection] &lt;/span&gt;=&lt;span&gt; Queue.Queue()
                &lt;/span&gt;&lt;span&gt;else&lt;/span&gt;&lt;span&gt;:
                    data &lt;/span&gt;= s.recv(1024)  &lt;span&gt;#&lt;/span&gt;&lt;span&gt; 接收到数据&lt;/span&gt;
                    &lt;span&gt;if&lt;/span&gt;&lt;span&gt; data:
                        &lt;/span&gt;&lt;span&gt;print&lt;/span&gt; &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt; received &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;, data, &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;from &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;, s.getpeername()
                        message_queues[s].put(data)
                        &lt;/span&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt; Add output channel for response&lt;/span&gt;
                        &lt;span&gt;if&lt;/span&gt; s &lt;span&gt;not&lt;/span&gt; &lt;span&gt;in&lt;/span&gt;&lt;span&gt; outputs:
                            outputs.append(s)
                    &lt;/span&gt;&lt;span&gt;else&lt;/span&gt;:  &lt;span&gt;#&lt;/span&gt;&lt;span&gt; 读这端的连接关闭&lt;/span&gt;
                        &lt;span&gt;#&lt;/span&gt;&lt;span&gt; Interpret empty result as closed connection&lt;/span&gt;
                        &lt;span&gt;print&lt;/span&gt; &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;  closing&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;, client_address
                        &lt;/span&gt;&lt;span&gt;if&lt;/span&gt; s &lt;span&gt;in&lt;/span&gt;&lt;span&gt; outputs:
                            outputs.remove(s)
                        inputs.remove(s)
                        s.close()
                        &lt;/span&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt; remove message queue&lt;/span&gt;
                        &lt;span&gt;del&lt;/span&gt;&lt;span&gt; message_queues[s]
            &lt;/span&gt;&lt;span&gt;for&lt;/span&gt; s &lt;span&gt;in&lt;/span&gt;&lt;span&gt; writable:
                &lt;/span&gt;&lt;span&gt;try&lt;/span&gt;&lt;span&gt;:
                    next_msg &lt;/span&gt;=&lt;span&gt; message_queues[s].get_nowait()
                &lt;/span&gt;&lt;span&gt;except&lt;/span&gt;&lt;span&gt; Queue.Empty:
                    &lt;/span&gt;&lt;span&gt;print&lt;/span&gt; &lt;span&gt;&quot;&lt;/span&gt; &lt;span&gt;&quot;&lt;/span&gt;, s.getpeername(), &lt;span&gt;'&lt;/span&gt;&lt;span&gt;queue empty&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;
                    outputs.remove(s)
                &lt;/span&gt;&lt;span&gt;else&lt;/span&gt;&lt;span&gt;:
                    &lt;/span&gt;&lt;span&gt;print&lt;/span&gt; &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt; sending &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;, next_msg, &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt; to &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;, s.getpeername()
                    s.send(next_msg)

            &lt;/span&gt;&lt;span&gt;for&lt;/span&gt; s &lt;span&gt;in&lt;/span&gt;&lt;span&gt; exceptional:
                &lt;/span&gt;&lt;span&gt;print&lt;/span&gt; &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt; exception condition on &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;, s.getpeername()
                &lt;/span&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt; stop listening for input on the connection&lt;/span&gt;
&lt;span&gt;                inputs.remove(s)
                &lt;/span&gt;&lt;span&gt;if&lt;/span&gt; s &lt;span&gt;in&lt;/span&gt;&lt;span&gt; outputs:
                    outputs.remove(s)
                s.close()
                &lt;/span&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt; Remove message queue&lt;/span&gt;
                &lt;span&gt;del&lt;/span&gt; message_queues[s]
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　select模型客户端&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;39&quot;&gt;
&lt;pre&gt;
&lt;span&gt;def&lt;/span&gt;&lt;span&gt; start(self):
        messages &lt;/span&gt;= [&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;hello world&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;]
        &lt;/span&gt;&lt;span&gt;print&lt;/span&gt; &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;Connect to the server&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;
         
        server_address &lt;/span&gt;= (&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;123.207.123.108&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;,8080&lt;span&gt;)
         
        &lt;/span&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt;Create a TCP/IP sock&lt;/span&gt;
&lt;span&gt;         
        socks &lt;/span&gt;=&lt;span&gt; []
         
        &lt;/span&gt;&lt;span&gt;for&lt;/span&gt; i &lt;span&gt;in&lt;/span&gt; range(3&lt;span&gt;):
            socks.append(socket.socket(socket.AF_INET,socket.SOCK_STREAM))
         
        &lt;/span&gt;&lt;span&gt;for&lt;/span&gt; s &lt;span&gt;in&lt;/span&gt;&lt;span&gt; socks:
            s.connect(server_address)
         
        counter &lt;/span&gt;=&lt;span&gt; 0
        &lt;/span&gt;&lt;span&gt;for&lt;/span&gt; message &lt;span&gt;in&lt;/span&gt;&lt;span&gt; messages :
            &lt;/span&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt;Sending message from different sockets&lt;/span&gt;
            &lt;span&gt;for&lt;/span&gt; s &lt;span&gt;in&lt;/span&gt;&lt;span&gt; socks:
                counter&lt;/span&gt;+=1
                &lt;span&gt;print&lt;/span&gt; &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;  %s sending %s&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; % (s.getpeername(),message+&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt; version &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;+&lt;span&gt;str(counter))
                s.send(message&lt;/span&gt;+&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt; version &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;+&lt;span&gt;str(counter))
            &lt;/span&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt;Read responses on both sockets&lt;/span&gt;
            &lt;span&gt;for&lt;/span&gt; s &lt;span&gt;in&lt;/span&gt;&lt;span&gt; socks:
                data &lt;/span&gt;= s.recv(1024&lt;span&gt;)
                &lt;/span&gt;&lt;span&gt;print&lt;/span&gt; &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt; %s received %s&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; %&lt;span&gt; (s.getpeername(),data)
                &lt;/span&gt;&lt;span&gt;if&lt;/span&gt; &lt;span&gt;not&lt;/span&gt;&lt;span&gt; data:
                    &lt;/span&gt;&lt;span&gt;print&lt;/span&gt; &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;%s closing socket &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;%&lt;span&gt;s.getpeername()
                    s.close()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;br/&gt;　　分别运行服务端和客户端,结果如下:&lt;br/&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1497240/201907/1497240-20190707234249174-1687053372.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;图3.3 select模型服务端运行结果&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1497240/201907/1497240-20190707234338560-1834159256.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;图3.4 select模型客户端运行结果&lt;/p&gt;
&lt;h3&gt;3.2 poll模型&lt;/h3&gt;
&lt;p&gt;　　poll模型api如下&lt;sup&gt;[8]&lt;/sup&gt;:&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;36&quot;&gt;
&lt;pre&gt;
#include &amp;lt;poll.h&amp;gt;
&lt;span&gt;int&lt;/span&gt; poll(&lt;span&gt;struct&lt;/span&gt; pollfd fds[], nfds_t nfds, &lt;span&gt;int&lt;/span&gt;&lt;span&gt; timeout);

typedef &lt;/span&gt;&lt;span&gt;struct&lt;/span&gt;&lt;span&gt; pollfd {
        &lt;/span&gt;&lt;span&gt;int&lt;/span&gt; fd;      &lt;span&gt;//&lt;/span&gt;&lt;span&gt; 需要被检测或选择的文件描述符&lt;/span&gt;
        &lt;span&gt;short&lt;/span&gt; events;  &lt;span&gt;//&lt;/span&gt;&lt;span&gt; 对文件描述符fd上感兴趣的事件&lt;/span&gt;
        &lt;span&gt;short&lt;/span&gt; revents;   &lt;span&gt;//&lt;/span&gt;&lt;span&gt; 文件描述符fd上当前实际发生的事件*/&lt;/span&gt;
} pollfd_t;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　1) poll()函数返回fds集合中就绪的读、写，或出错的描述符数量，返回0表示超时，返回-1表示出错；&lt;br/&gt;　　2) fds是一个struct pollfd类型的数组，用于存放需要检测其状态的socket描述符，并且调用poll函数之后fds数组不会被清空；&lt;br/&gt;　　3) nfds记录数组fds中描述符的总数量；&lt;br/&gt;　　4) timeout是调用poll函数阻塞的超时时间，单位毫秒；&lt;br/&gt;　　5) 一个pollfd结构体表示一个被监视的文件描述符，通过传递fds[]指示 poll() 监视多个文件描述符。其中，结构体的events域是监视该文件描述符的事件掩码，由用户来设置这个域，结构体的revents域是文件描述符的操作结果事件掩码，内核在调用返回时设置这个域。events域中请求的任何事件都可能在revents域中返回。&lt;br/&gt;　　合法的事件如下：&lt;br/&gt;　　1) POLLIN 有数据可读&lt;br/&gt;　　2) POLLRDNORM 有普通数据可读&lt;br/&gt;　　3) POLLRDBAND 有优先数据可读&lt;br/&gt;　　4) POLLPRI 有紧迫数据可读&lt;br/&gt;　　5) POLLOUT 写数据不会导致阻塞&lt;br/&gt;　　6) POLLWRNORM 写普通数据不会导致阻塞&lt;br/&gt;　　7) POLLWRBAND 写优先数据不会导致阻塞&lt;br/&gt;　　8) POLLERR 发生错误&lt;br/&gt;　　9) POLLHUP 发生挂起&lt;br/&gt;　　当需要监听多个事件时，使用POLLIN | POLLPRI设置 events 域；当poll调用之后检测某事件是否发生时，fds[i].revents &amp;amp; POLLIN进行判断&lt;br/&gt;poll模型和select模型相似,poll模型同样需要将所有监控的描述符重新拷贝到内核,并在内核中对所有描述符进行遍历,没有解决select模型的性能问题,但是poll模型没有最大文件描述符数量的限制。&lt;br/&gt;　　select()和poll()将就绪的文件描述符告诉进程后，如果进程没有对其进行IO操作，那么下次调用select()和poll()的时候将再次报告这些文件描述符，所以它们一般不会丢失就绪的消息，这种方式称为水平触发&lt;sup&gt;[5]&lt;/sup&gt;。&lt;br/&gt;　　poll模型python demo如下:&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;57&quot;&gt;
&lt;pre&gt;
&lt;span&gt;def&lt;/span&gt;&lt;span&gt; start(self)://poll模型服务端
        &lt;/span&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt; Create a TCP/IP socket, and then bind and listen&lt;/span&gt;
        server =&lt;span&gt; socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        server.setblocking(False)
        server_address &lt;/span&gt;= (&lt;span&gt;''&lt;/span&gt;, 8080&lt;span&gt;)
        &lt;/span&gt;&lt;span&gt;print&lt;/span&gt; &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;Starting up on %s port %s&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; %&lt;span&gt; server_address
        server.bind(server_address)
        server.listen(&lt;/span&gt;5&lt;span&gt;)
        message_queues &lt;/span&gt;=&lt;span&gt; {}
        &lt;/span&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt; The timeout value is represented in milliseconds, instead of seconds.&lt;/span&gt;
        timeout = 5000
        &lt;span&gt;#&lt;/span&gt;&lt;span&gt; Create a limit for the event,POLLIN = POLLRDNORM | POLLRDBAND&lt;/span&gt;
        READ_ONLY = (select.POLLIN |&lt;span&gt; select.POLLPRI)
        READ_WRITE &lt;/span&gt;= (READ_ONLY | select.POLLOUT) &lt;span&gt;#&lt;/span&gt;&lt;span&gt;POLLOUT=POLLWRNORM | POLLWRBAND&lt;/span&gt;
        &lt;span&gt;#&lt;/span&gt;&lt;span&gt; Set up the poller&lt;/span&gt;
        poller =&lt;span&gt; select.poll()
        poller.register(server, READ_ONLY)
        &lt;/span&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt; Map file descriptors to socket objects&lt;/span&gt;
        fd_to_socket =&lt;span&gt; {server.fileno(): server, }
        &lt;/span&gt;&lt;span&gt;while&lt;/span&gt;&lt;span&gt; True:
            &lt;/span&gt;&lt;span&gt;print&lt;/span&gt; &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;Waiting for the next event&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;
            events &lt;/span&gt;=&lt;span&gt; poller.poll(timeout)
            &lt;/span&gt;&lt;span&gt;if&lt;/span&gt; len(events) ==&lt;span&gt; 0:
                &lt;/span&gt;&lt;span&gt;print&lt;/span&gt; &lt;span&gt;'&lt;/span&gt;&lt;span&gt;Time out&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;
                &lt;span&gt;break&lt;/span&gt;
            &lt;span&gt;print&lt;/span&gt; &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;*&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; * 20
            &lt;span&gt;print&lt;/span&gt;&lt;span&gt; len(events)
            &lt;/span&gt;&lt;span&gt;print&lt;/span&gt;&lt;span&gt; events
            &lt;/span&gt;&lt;span&gt;print&lt;/span&gt; &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;*&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; * 20
            &lt;span&gt;for&lt;/span&gt; fd, flag &lt;span&gt;in&lt;/span&gt;&lt;span&gt; events:
                s &lt;/span&gt;=&lt;span&gt; fd_to_socket[fd]
                &lt;/span&gt;&lt;span&gt;if&lt;/span&gt; flag &amp;amp; (select.POLLIN |&lt;span&gt; select.POLLPRI):
                    &lt;/span&gt;&lt;span&gt;if&lt;/span&gt; s &lt;span&gt;is&lt;/span&gt;&lt;span&gt; server:
                        &lt;/span&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt; A readable socket is ready to accept a connection&lt;/span&gt;
                        connection, client_address =&lt;span&gt; s.accept()
                        &lt;/span&gt;&lt;span&gt;print&lt;/span&gt; &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt; Connection &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;, client_address
                        connection.setblocking(False)

                        fd_to_socket[connection.fileno()] &lt;/span&gt;=&lt;span&gt; connection
                        poller.register(connection, READ_ONLY)

                        &lt;/span&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt; Give the connection a queue to send data&lt;/span&gt;
                        message_queues[connection] =&lt;span&gt; Queue.Queue()
                    &lt;/span&gt;&lt;span&gt;else&lt;/span&gt;&lt;span&gt;:
                        data &lt;/span&gt;= s.recv(1024&lt;span&gt;)
                        &lt;/span&gt;&lt;span&gt;if&lt;/span&gt;&lt;span&gt; data:
                            &lt;/span&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt; A readable client socket has data&lt;/span&gt;
                            &lt;span&gt;print&lt;/span&gt; &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;  received %s from %s &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; %&lt;span&gt; (data, s.getpeername())
                            message_queues[s].put(data)
                            poller.modify(s, READ_WRITE)
                        &lt;/span&gt;&lt;span&gt;else&lt;/span&gt;&lt;span&gt;:
                            &lt;/span&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt; Close the connection&lt;/span&gt;
                            &lt;span&gt;print&lt;/span&gt; &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;  closing&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;, s.getpeername()
                            &lt;/span&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt; Stop listening for input on the connection&lt;/span&gt;
&lt;span&gt;                            poller.unregister(s)
                            s.close()
                            &lt;/span&gt;&lt;span&gt;del&lt;/span&gt;&lt;span&gt; message_queues[s]
                &lt;/span&gt;&lt;span&gt;elif&lt;/span&gt; flag &amp;amp;&lt;span&gt; select.POLLHUP:
                    &lt;/span&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt; A client that &quot;hang up&quot; , to be closed.&lt;/span&gt;
                    &lt;span&gt;print&lt;/span&gt; &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt; Closing &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;, s.getpeername(), &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;(HUP)&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;
                    poller.unregister(s)
                    s.close()
                &lt;/span&gt;&lt;span&gt;elif&lt;/span&gt; flag &amp;amp;&lt;span&gt; select.POLLOUT:
                    &lt;/span&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt; Socket is ready to send data , if there is any to send&lt;/span&gt;
                    &lt;span&gt;try&lt;/span&gt;&lt;span&gt;:
                        next_msg &lt;/span&gt;=&lt;span&gt; message_queues[s].get_nowait()
                    &lt;/span&gt;&lt;span&gt;except&lt;/span&gt;&lt;span&gt; Queue.Empty:
                        &lt;/span&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt; No messages waiting so stop checking&lt;/span&gt;
                        &lt;span&gt;print&lt;/span&gt; s.getpeername(), &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt; queue empty&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;
                        poller.modify(s, READ_ONLY)
                    &lt;/span&gt;&lt;span&gt;else&lt;/span&gt;&lt;span&gt;:
                        &lt;/span&gt;&lt;span&gt;print&lt;/span&gt; &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt; sending %s to %s&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; %&lt;span&gt; (next_msg, s.getpeername())
                        s.send(next_msg)
                &lt;/span&gt;&lt;span&gt;elif&lt;/span&gt; flag &amp;amp;&lt;span&gt; select.POLLERR:
                    &lt;/span&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt; Any events with POLLERR cause the server to close the&lt;/span&gt;
                    &lt;span&gt;#&lt;/span&gt;&lt;span&gt; socket&lt;/span&gt;
                    &lt;span&gt;print&lt;/span&gt; &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;  exception on&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;, s.getpeername()
                    poller.unregister(s)
                    s.close()
                    &lt;/span&gt;&lt;span&gt;del&lt;/span&gt; message_queues[s]
&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;3.3 epoll模型&lt;/h3&gt;
&lt;p&gt;　　epoll模型api包含三个系统调用&lt;sup&gt;[7]&lt;/sup&gt;:&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;40&quot;&gt;
&lt;pre&gt;
#include &amp;lt;sys/epoll.h&amp;gt;
&lt;span&gt;int&lt;/span&gt; epoll_create(&lt;span&gt;int&lt;/span&gt;&lt;span&gt; size);
&lt;/span&gt;&lt;span&gt;int&lt;/span&gt; epoll_ctl(&lt;span&gt;int&lt;/span&gt; epfd, &lt;span&gt;int&lt;/span&gt; op, &lt;span&gt;int&lt;/span&gt; fd, &lt;span&gt;struct&lt;/span&gt; epoll_event *&lt;span&gt;event&lt;/span&gt;&lt;span&gt;);
&lt;/span&gt;&lt;span&gt;int&lt;/span&gt; epoll_wait(&lt;span&gt;int&lt;/span&gt; epfd, &lt;span&gt;struct&lt;/span&gt; epoll_event * events, &lt;span&gt;int&lt;/span&gt; maxevents, &lt;span&gt;int&lt;/span&gt; timeout);
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　1. epoll_create创建epoll句柄epfd。size表示在这个epoll fd上能关注的最大fd数,失败时返回-1。&lt;br/&gt;　　2. epoll_ctl注册要监听的事件。&lt;br/&gt;　　　　1) epfd表示epoll句柄；&lt;br/&gt;　　　　2) op表示fd操作类型：EPOLL_CTL_ADD（注册新的fd到epfd中），EPOLL_CTL_MOD（修改已注册的fd的监听事件），EPOLL_CTL_DEL（从epfd中删除一个fd）&lt;br/&gt;　　　　3) fd是要监听的描述符；&lt;br/&gt;　　　　4) event表示要监听的事件; EPOLLIN表示对应的文件描述符可以读（包括对端SOCKET正常关闭）；EPOLLOUT表示对应的文件描述符可以写；EPOLLPRI表示对应的文件描述符有紧急的数据可读（这里应该表示有带外数据到来）；EPOLLERR表示对应的文件描述符发生错误；EPOLLHUP表示对应的文件描述符被挂断；EPOLLET将EPOLL设为边缘触发(Edge Triggered)模式，这是相对于水平触发(Level Triggered)来说的。EPOLLONESHOT只监听一次事件，当监听完这次事件之后，如果还需要继续监听这个socket的话，需要再次把这个socket加入到EPOLL队列里&lt;sup&gt;[8]&lt;/sup&gt;。&lt;br/&gt;　　3. epoll_wait函数等待事件就绪，成功时返回就绪的事件数目，调用失败时返回 -1，等待超时返回 0。&lt;br/&gt;　　　　1) epfd是epoll句柄&lt;br/&gt;　　　　2) events表示从内核得到的就绪事件集合&lt;br/&gt;　　　　3) maxevents告诉内核events的大小&lt;br/&gt;　　　　4) timeout表示等待的超时事件&lt;br/&gt;　　epoll_event结构体定义如下:&lt;br/&gt;　　&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;33&quot;&gt;
&lt;pre&gt;
&lt;span&gt;struct&lt;/span&gt;&lt;span&gt; epoll_event {
__uint32_t events; &lt;/span&gt;&lt;span&gt;/*&lt;/span&gt;&lt;span&gt; Epoll events &lt;/span&gt;&lt;span&gt;*/&lt;/span&gt;&lt;span&gt;
epoll_data_t data; &lt;/span&gt;&lt;span&gt;/*&lt;/span&gt;&lt;span&gt; User data variable &lt;/span&gt;&lt;span&gt;*/&lt;/span&gt;&lt;span&gt;
};
typedef union epoll_data {
&lt;/span&gt;&lt;span&gt;void&lt;/span&gt; *&lt;span&gt;ptr;
&lt;/span&gt;&lt;span&gt;int&lt;/span&gt;&lt;span&gt; fd;
__uint32_t u32;
__uint64_t u64;
} epoll_data_t;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　epoll模型利用三个函数代替select和poll模型的三个函数,可以避免select模型的三个缺点。&lt;br/&gt;　　1) 不需要每次都将相同的fd监听事件重新拷贝到内核。epoll的解决方案在epoll_ctl函数中。每次注册新的事件到epoll句柄中时（在epoll_ctl中指定EPOLL_CTL_ADD），会把所有的fd拷贝进内核，而不是在epoll_wait的时候重复拷贝。epoll保证了每个fd在整个过程中只会拷贝一次。&lt;br/&gt;　　2) 不需要再内核中遍历所有fd来看事件是否就绪。epoll的解决方案不像select或poll一样每次都把current进程轮流加入fd对应的设备等待队列中，而只在epoll_ctl时把current进程挂一遍（这一遍必不可少）并为每个fd指定一个回调函数，当设备就绪，唤醒等待队列上的等待者时，就会调用这个回调函数，而这个回调函数会把就绪的fd加入一个就绪链表）。epoll_wait的工作实际上就是在这个就绪链表中查看有没有就绪的fd。&lt;br/&gt;　　3) 所监听的文件描述符的数目不像select有上限限制, 所支持的FD上限是最大可以打开文件的数目。&lt;/p&gt;
&lt;p&gt;　　epoll对文件描述符的操作有两种模式：LT(level trigger，水平触发)和ET(edge trigger)。&lt;br/&gt;　　1) 水平触发：默认工作模式，即当epoll_wait检测到某描述符事件就绪并通知应用程序时，应用程序可以不立即处理该事件；下次调用epoll_wait时，会再次通知此事件。&lt;br/&gt;　　2) 边缘触发：当epoll_wait检测到某描述符事件就绪并通知应用程序时，应用程序必须立即处理该事件。如果不处理，下次调用epoll_wait时，不会再次通知此事件。（直到你做了某些操作导致该描述符变成未就绪状态了，也就是说边缘触发只在状态由未就绪变为就绪时通知一次）。&lt;/p&gt;
&lt;p&gt;　　ET模式很大程度上减少了epoll事件的触发次数，因此效率比LT模式高。&lt;/p&gt;
&lt;p&gt;　　epoll模型python demo如下:&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;56&quot;&gt;
&lt;pre&gt;
&lt;span&gt;def&lt;/span&gt;&lt;span&gt; start(self):
        &lt;/span&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt; Create a TCP/IP socket, and then bind and listen&lt;/span&gt;
        server =&lt;span&gt; socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        server.setblocking(False)
        server_address &lt;/span&gt;= (&lt;span&gt;''&lt;/span&gt;, 8080&lt;span&gt;)
        &lt;/span&gt;&lt;span&gt;print&lt;/span&gt; &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;Starting up on %s port %s&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; %&lt;span&gt; server_address
        server.bind(server_address)
        server.listen(&lt;/span&gt;5&lt;span&gt;)
        message_queues &lt;/span&gt;=&lt;span&gt; {}
        &lt;/span&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt; The timeout value is represented in milliseconds, instead of seconds.&lt;/span&gt;
        timeout = 5000
        &lt;span&gt;#&lt;/span&gt;&lt;span&gt; Create a limit for the event&lt;/span&gt;
        READ_ONLY =&lt;span&gt; (select.EPOLLIN)
        READ_WRITE &lt;/span&gt;= (READ_ONLY |&lt;span&gt; select.EPOLLOUT)
        &lt;/span&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt; Set up the epoll&lt;/span&gt;
        epoll =&lt;span&gt; select.epoll()
        epoll.register(server.fileno(), READ_ONLY)
        &lt;/span&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt; Map file descriptors to socket objects&lt;/span&gt;
        fd_to_socket =&lt;span&gt; {server.fileno(): server, }
        &lt;/span&gt;&lt;span&gt;while&lt;/span&gt;&lt;span&gt; True:
            &lt;/span&gt;&lt;span&gt;print&lt;/span&gt; &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;Waiting for the next event&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;
            events &lt;/span&gt;=&lt;span&gt; epoll.poll(timeout)
            &lt;/span&gt;&lt;span&gt;if&lt;/span&gt; len(events) ==&lt;span&gt; 0:
                &lt;/span&gt;&lt;span&gt;print&lt;/span&gt; &lt;span&gt;'&lt;/span&gt;&lt;span&gt;Time out&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;
                &lt;span&gt;break&lt;/span&gt;
            &lt;span&gt;print&lt;/span&gt; &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;*&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; * 20
            &lt;span&gt;print&lt;/span&gt;&lt;span&gt; len(events)
            &lt;/span&gt;&lt;span&gt;print&lt;/span&gt;&lt;span&gt; events
            &lt;/span&gt;&lt;span&gt;print&lt;/span&gt; &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;*&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; * 20
            &lt;span&gt;for&lt;/span&gt; fd, flag &lt;span&gt;in&lt;/span&gt;&lt;span&gt; events:
                s &lt;/span&gt;=&lt;span&gt; fd_to_socket[fd]
                &lt;/span&gt;&lt;span&gt;if&lt;/span&gt; flag &amp;amp;&lt;span&gt; (select.EPOLLIN):
                    &lt;/span&gt;&lt;span&gt;if&lt;/span&gt; s &lt;span&gt;is&lt;/span&gt;&lt;span&gt; server:
                        &lt;/span&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt; A readable socket is ready to accept a connection&lt;/span&gt;
                        connection, client_address =&lt;span&gt; s.accept()
                        &lt;/span&gt;&lt;span&gt;print&lt;/span&gt; &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt; Connection &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;, client_address
                        connection.setblocking(False)

                        fd_to_socket[connection.fileno()] &lt;/span&gt;=&lt;span&gt; connection
                        epoll.register(connection, READ_ONLY)

                        &lt;/span&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt; Give the connection a queue to send data&lt;/span&gt;
                        message_queues[connection] =&lt;span&gt; Queue.Queue()
                    &lt;/span&gt;&lt;span&gt;else&lt;/span&gt;&lt;span&gt;:
                        data &lt;/span&gt;= s.recv(1024&lt;span&gt;)
                        &lt;/span&gt;&lt;span&gt;if&lt;/span&gt;&lt;span&gt; data:
                            &lt;/span&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt; A readable client socket has data&lt;/span&gt;
                            &lt;span&gt;print&lt;/span&gt; &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;  received %s from %s &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; %&lt;span&gt; (data, s.getpeername())
                            message_queues[s].put(data)
                            epoll.modify(s, READ_WRITE)
                        &lt;/span&gt;&lt;span&gt;else&lt;/span&gt;&lt;span&gt;:
                            &lt;/span&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt; Close the connection&lt;/span&gt;
                            &lt;span&gt;print&lt;/span&gt; &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;  closing&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;, s.getpeername()
                            &lt;/span&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt; Stop listening for input on the connection&lt;/span&gt;
&lt;span&gt;                            epoll.unregister(s)
                            s.close()
                            &lt;/span&gt;&lt;span&gt;del&lt;/span&gt;&lt;span&gt; message_queues[s]
                &lt;/span&gt;&lt;span&gt;elif&lt;/span&gt; flag &amp;amp;&lt;span&gt; select.EPOLLHUP:
                    &lt;/span&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt; A client that &quot;hang up&quot; , to be closed.&lt;/span&gt;
                    &lt;span&gt;print&lt;/span&gt; &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt; Closing &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;, s.getpeername(), &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;(HUP)&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;
                    epoll.unregister(s)
                    s.close()
                &lt;/span&gt;&lt;span&gt;elif&lt;/span&gt; flag &amp;amp;&lt;span&gt; select.EPOLLOUT:
                    &lt;/span&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt; Socket is ready to send data , if there is any to send&lt;/span&gt;
                    &lt;span&gt;try&lt;/span&gt;&lt;span&gt;:
                        next_msg &lt;/span&gt;=&lt;span&gt; message_queues[s].get_nowait()
                    &lt;/span&gt;&lt;span&gt;except&lt;/span&gt;&lt;span&gt; Queue.Empty:
                        &lt;/span&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt; No messages waiting so stop checking&lt;/span&gt;
                        &lt;span&gt;print&lt;/span&gt; s.getpeername(), &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt; queue empty&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;
                        epoll.modify(s, READ_ONLY)
                    &lt;/span&gt;&lt;span&gt;else&lt;/span&gt;&lt;span&gt;:
                        &lt;/span&gt;&lt;span&gt;print&lt;/span&gt; &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt; sending %s to %s&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; %&lt;span&gt; (next_msg, s.getpeername())
                        s.send(next_msg)
                &lt;/span&gt;&lt;span&gt;elif&lt;/span&gt; flag &amp;amp;&lt;span&gt; select.epollERR:
                    &lt;/span&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt; Any events with epollR cause the server to close the&lt;/span&gt;
                    &lt;span&gt;#&lt;/span&gt;&lt;span&gt; socket&lt;/span&gt;
                    &lt;span&gt;print&lt;/span&gt; &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;  exception on&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;, s.getpeername()
                    epoll.unregister(s)
                    s.close()
                    &lt;/span&gt;&lt;span&gt;del&lt;/span&gt; message_queues[s]
&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;3.4 IO复用小结&lt;/h3&gt;
&lt;p&gt;　　没有IO复用之前,用阻塞型IO,必须为每个建立的连接创建线程或线程,当面对大量连接时, 严重浪费系统资源,影响进程的响应效率,用非阻塞IO,需要轮询测试socket集合是否已经读写就绪,在已经就绪和测试到就绪有一定的时延,数据得不到及时处理。利用IO复用, 同时可监控多个套接字描述符的状态,而不用像阻塞型IO,每个套接字需要一个线程或进程处理,也不像非阻塞IO,存在处理时延,IO复用函数是阻塞函数,不用轮询测试,有socket就绪或超时才会返回。&lt;br/&gt;IO复用分为select、poll、epoll模型三种,select模型存在如下三个缺点:&lt;br/&gt;　　1) 每次都需要将fd_set拷贝到内核空间,当fd_set较大时开销很大&lt;br/&gt;　　2) 每次都需要在内核中遍历fd加入到等待队列,fd较多开销较大&lt;br/&gt;　　3) select支持的文件描述符太小,默认为1024&lt;br/&gt;　　poll模型不存在同时监听的描述符大小限制,但是仍然存在缺点1和2。epoll模型克服了这三个缺点,epoll模型对于加入监听的socket描述符,会将描述符和监听的事件记在内核,无需像select和poll每次都需要将文件描述符集拷贝到内核。在判断是否有读写就绪时。当有读写事件就绪时,内核会调用函数将就绪的fd加入就绪链表,因此epoll模型只需读就绪链表,而不需要将所有fd遍历一遍,性能会比select和poll模型高。&lt;/p&gt;

&lt;h2&gt;四 信号驱动和异步IO&lt;/h2&gt;
&lt;h3&gt;4.1 信号驱动IO&lt;/h3&gt;
&lt;p&gt;　　信号驱动式IO模型原理如下图4.1:&lt;br/&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1497240/201907/1497240-20190707235520654-979787496.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;图4.1 信号驱动IO&lt;/p&gt;
&lt;p&gt;　　Signal Driven I/O 的工作原理就是用户进程首先和 kernel 之间建立信号的通知机制，即用户进程告诉 kernel，如果 kernel 中数据准备好了，就通过 SIGIO 信号通知进程。然后用户空间的进程就会调用 read 系统调用将准备好的数据从 kernel 拷贝到用户空间。&lt;/p&gt;
&lt;p&gt;　　但是这种 I/O 模型存在一个非常重大的缺陷问题：SIGIO 这种信号对于每个进程来说只有一个！如果使该信号对进程中的两个描述符（这两个文件描述符都等待着 I/O 操作）都起作用，那么进程在接到此信号后就无法判别是哪一个文件描述符准备好了。所以 Signal Driven I/O 模型在现实中用的非常少。&lt;/p&gt;
&lt;h3&gt;4.2 异步IO&lt;/h3&gt;
&lt;p&gt;　　异步IO模型原理如下图:&lt;br/&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1497240/201907/1497240-20190707235638605-1484212584.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;图4.2 异步IO&lt;/p&gt;
&lt;p&gt;　　在异步IO中,用户进程调用aio_read立即返回,直到内核将数据拷贝到进程缓冲区,然后通知进程完成,整个过程完全没阻塞,连recvfrom都不用用户进程调用。其它的IO模型都属于同步IO。&lt;br/&gt;在异步非阻塞 I/O 中，可以同时发起多个传输操作。这需要每个传输操作都有惟一的上下文，这样才能在它们完成时区分到底是哪个传输操作完成了。在 AIO 中，这是一个 aiocb（AIO I/O Control Block）结构。这个结构包含了有关传输的所有信息，包括为数据准备的用户缓冲区。在产生 I/O （称为完成）通知时，aiocb 结构就被用来惟一标识所完成的 I/O 操作。这个 API 的展示显示了如何使用它&lt;sup&gt;[10]&lt;/sup&gt;。&lt;br/&gt;　　aiocb结构如下:&lt;br/&gt;　　&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;34&quot;&gt;
&lt;pre&gt;
&lt;span&gt;struct&lt;/span&gt;&lt;span&gt; aiocb {
&lt;/span&gt;&lt;span&gt;int&lt;/span&gt; aio_fildes; &lt;span&gt;//&lt;/span&gt;&lt;span&gt; File Descriptor&lt;/span&gt;
&lt;span&gt;int&lt;/span&gt; aio_lio_opcode; &lt;span&gt;//&lt;/span&gt;&lt;span&gt; Valid only for lio_listio (r/w/nop)&lt;/span&gt;
&lt;span&gt;volatile&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; *aio_buf; &lt;span&gt;//&lt;/span&gt;&lt;span&gt; Data Buffer&lt;/span&gt;
size_t aio_nbytes; &lt;span&gt;//&lt;/span&gt;&lt;span&gt; Number of Bytes in Data Buffer&lt;/span&gt;
&lt;span&gt;struct&lt;/span&gt; sigevent aio_sigevent; &lt;span&gt;//&lt;/span&gt;&lt;span&gt; Notification Structure&lt;/span&gt;

&lt;span&gt;/*&lt;/span&gt;&lt;span&gt; Internal fields &lt;/span&gt;&lt;span&gt;*/&lt;/span&gt;&lt;span&gt;
...

};&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　sigevent 结构告诉 AIO 在 I/O 操作完成时应该执行什么操作。Aio api如下:&lt;br/&gt;　　1) int aio_read( struct aiocb *aiocbp ) 请求异步读操作&lt;br/&gt;　　2) aio_error 检查异步请求的状态&lt;br/&gt;　　3) aio_return 获得完成的异步请求的返回状态&lt;br/&gt;　　4) aio_write 请求异步写操作&lt;br/&gt;　　5) aio_suspend 挂起调用进程，直到一个或多个异步请求已经完成（或失败）&lt;br/&gt;　　6) aio_cancel 取消异步 I/O 请求&lt;br/&gt;　　7) lio_listio 发起一系列 I/O 操作&lt;/p&gt;
&lt;p&gt;　　为了便于理解,这里使用c语言,使用 aio_read 进行异步读操作c实例如下:&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;39&quot;&gt;
&lt;pre&gt;
//使用aio api读实例&lt;br/&gt;#include &amp;lt;aio.h&amp;gt;&lt;span&gt;

...

&lt;/span&gt;&lt;span&gt;int&lt;/span&gt;&lt;span&gt; fd, ret;
&lt;/span&gt;&lt;span&gt;struct&lt;/span&gt;&lt;span&gt; aiocb my_aiocb;

fd &lt;/span&gt;= open( &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;file.txt&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;, O_RDONLY );
&lt;/span&gt;&lt;span&gt;if&lt;/span&gt; (fd &amp;lt; &lt;span&gt;0&lt;/span&gt;) perror(&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;open&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;);

&lt;/span&gt;&lt;span&gt;/*&lt;/span&gt;&lt;span&gt; Zero out the aiocb structure (recommended) &lt;/span&gt;&lt;span&gt;*/&lt;/span&gt;&lt;span&gt;
bzero( (&lt;/span&gt;&lt;span&gt;char&lt;/span&gt; *)&amp;amp;my_aiocb, &lt;span&gt;sizeof&lt;/span&gt;(&lt;span&gt;struct&lt;/span&gt;&lt;span&gt; aiocb) );

&lt;/span&gt;&lt;span&gt;/*&lt;/span&gt;&lt;span&gt; Allocate a data buffer for the aiocb request &lt;/span&gt;&lt;span&gt;*/&lt;/span&gt;&lt;span&gt;
my_aiocb.aio_buf &lt;/span&gt;= &lt;span&gt;malloc&lt;/span&gt;(BUFSIZE+&lt;span&gt;1&lt;/span&gt;);&lt;span&gt;//&lt;/span&gt;&lt;span&gt; 清空了 aiocb 结构，分配一个数据缓冲区&lt;/span&gt;
&lt;span&gt;if&lt;/span&gt; (!my_aiocb.aio_buf) perror(&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;malloc&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;);

&lt;/span&gt;&lt;span&gt;/*&lt;/span&gt;&lt;span&gt; Initialize the necessary fields in the aiocb &lt;/span&gt;&lt;span&gt;*/&lt;/span&gt;&lt;span&gt;
my_aiocb.aio_fildes &lt;/span&gt;= fd; &lt;span&gt;//&lt;/span&gt;&lt;span&gt;文件描述符&lt;/span&gt;
my_aiocb.aio_nbytes = BUFSIZE;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;缓冲区大小&lt;/span&gt;
my_aiocb.aio_offset = &lt;span&gt;0&lt;/span&gt;;&lt;span&gt;//&lt;/span&gt; &lt;span&gt;//&lt;/span&gt;&lt;span&gt; 将 aio_offset 设置成 0（该文件中的第一个偏移量）&lt;/span&gt;
&lt;span&gt;
ret &lt;/span&gt;= aio_read( &amp;amp;my_aiocb );&lt;span&gt;//&lt;/span&gt;&lt;span&gt;发起异步读请求&lt;/span&gt;
&lt;span&gt;if&lt;/span&gt; (ret &amp;lt; &lt;span&gt;0&lt;/span&gt;) perror(&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;aio_read&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;);

&lt;/span&gt;&lt;span&gt;while&lt;/span&gt; ( aio_error( &amp;amp;my_aiocb ) == EINPROGRESS ) ;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;检查异步请求是否完成&lt;/span&gt;

&lt;span&gt;if&lt;/span&gt; ((ret = aio_return( &amp;amp;my_iocb )) &amp;gt; &lt;span&gt;0&lt;/span&gt;) {&lt;span&gt;//&lt;/span&gt;&lt;span&gt;所传输的字节数，如果发生错误，返回值就为 -1&lt;/span&gt;&lt;span&gt;
/*&lt;/span&gt;&lt;span&gt; got ret bytes on the read &lt;/span&gt;&lt;span&gt;*/&lt;/span&gt;&lt;span&gt;
} &lt;/span&gt;&lt;span&gt;else&lt;/span&gt;&lt;span&gt; {
&lt;/span&gt;&lt;span&gt;/*&lt;/span&gt;&lt;span&gt; read failed, consult errno &lt;/span&gt;&lt;span&gt;*/&lt;/span&gt;&lt;span&gt;
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　当异步请求完成时,内核有两种方式通知进程,一种是通过信号,另一种是调用回调函数。&lt;br/&gt;　　使用信号作为AIO通知demo如下,应用程序对指定信号注册信号处理函数, 在产生指定的信号时就会调用这个处理程序。并指定AIO操作完成时,由内核发出指定信号,将aiocb作为信号的上下文,用来分辨多个IO请求。&lt;br/&gt;　　&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;41&quot;&gt;
&lt;pre&gt;
AIO完成通知-&lt;span&gt;信号
&lt;/span&gt;&lt;span&gt;void&lt;/span&gt;&lt;span&gt; setup_io( ... )
{
&lt;/span&gt;&lt;span&gt;int&lt;/span&gt;&lt;span&gt; fd;
&lt;/span&gt;&lt;span&gt;struct&lt;/span&gt;&lt;span&gt; sigaction sig_act;
&lt;/span&gt;&lt;span&gt;struct&lt;/span&gt;&lt;span&gt; aiocb my_aiocb;

...

&lt;/span&gt;&lt;span&gt;/*&lt;/span&gt;&lt;span&gt; Set up the signal handler &lt;/span&gt;&lt;span&gt;*/&lt;/span&gt;&lt;span&gt;
sigemptyset(&lt;/span&gt;&amp;amp;&lt;span&gt;sig_act.sa_mask);
sig_act.sa_flags &lt;/span&gt;=&lt;span&gt; SA_SIGINFO;
sig_act.sa_sigaction &lt;/span&gt;=&lt;span&gt; aio_completion_handler;


&lt;/span&gt;&lt;span&gt;/*&lt;/span&gt;&lt;span&gt; Set up the AIO request &lt;/span&gt;&lt;span&gt;*/&lt;/span&gt;&lt;span&gt;
bzero( (&lt;/span&gt;&lt;span&gt;char&lt;/span&gt; *)&amp;amp;my_aiocb, &lt;span&gt;sizeof&lt;/span&gt;(&lt;span&gt;struct&lt;/span&gt;&lt;span&gt; aiocb) );
my_aiocb.aio_fildes &lt;/span&gt;=&lt;span&gt; fd;
my_aiocb.aio_buf &lt;/span&gt;= &lt;span&gt;malloc&lt;/span&gt;(BUF_SIZE+&lt;span&gt;1&lt;/span&gt;&lt;span&gt;);
my_aiocb.aio_nbytes &lt;/span&gt;=&lt;span&gt; BUF_SIZE;
my_aiocb.aio_offset &lt;/span&gt;=&lt;span&gt; next_offset;

&lt;/span&gt;&lt;span&gt;/*&lt;/span&gt;&lt;span&gt; Link the AIO request with the Signal Handler &lt;/span&gt;&lt;span&gt;*/&lt;/span&gt;&lt;span&gt;
my_aiocb.aio_sigevent.sigev_notify &lt;/span&gt;= SIGEV_SIGNAL;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;指定信号作为通知方法&lt;/span&gt;
my_aiocb.aio_sigevent.sigev_signo =&lt;span&gt; SIGIO;
my_aiocb.aio_sigevent.sigev_value.sival_ptr &lt;/span&gt;= &amp;amp;&lt;span&gt;my_aiocb;

&lt;/span&gt;&lt;span&gt;/*&lt;/span&gt;&lt;span&gt; Map the Signal to the Signal Handler &lt;/span&gt;&lt;span&gt;*/&lt;/span&gt;&lt;span&gt;
ret &lt;/span&gt;= sigaction( SIGIO, &amp;amp;&lt;span&gt;sig_act, NULL );

...

ret &lt;/span&gt;= aio_read( &amp;amp;&lt;span&gt;my_aiocb );

}


&lt;/span&gt;&lt;span&gt;void&lt;/span&gt; aio_completion_handler( &lt;span&gt;int&lt;/span&gt; signo, siginfo_t *info, &lt;span&gt;void&lt;/span&gt; *&lt;span&gt;context )
{
&lt;/span&gt;&lt;span&gt;struct&lt;/span&gt; aiocb *&lt;span&gt;req;


&lt;/span&gt;&lt;span&gt;/*&lt;/span&gt;&lt;span&gt; Ensure it's our signal &lt;/span&gt;&lt;span&gt;*/&lt;/span&gt;
&lt;span&gt;if&lt;/span&gt; (info-&amp;gt;si_signo ==&lt;span&gt; SIGIO) {

req &lt;/span&gt;= (&lt;span&gt;struct&lt;/span&gt; aiocb *)info-&amp;gt;&lt;span&gt;si_value.sival_ptr;

&lt;/span&gt;&lt;span&gt;/*&lt;/span&gt;&lt;span&gt; Did the request complete? &lt;/span&gt;&lt;span&gt;*/&lt;/span&gt;
&lt;span&gt;if&lt;/span&gt; (aio_error( req ) == &lt;span&gt;0&lt;/span&gt;&lt;span&gt;) {

&lt;/span&gt;&lt;span&gt;/*&lt;/span&gt;&lt;span&gt; Request completed successfully, get the return status &lt;/span&gt;&lt;span&gt;*/&lt;/span&gt;&lt;span&gt;
ret &lt;/span&gt;=&lt;span&gt; aio_return( req );

}

}

&lt;/span&gt;&lt;span&gt;return&lt;/span&gt;&lt;span&gt;;
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　使用回调函数作为异步请求通知demo如下, 这种机制不会为通知而产生一个信号，而是会调用用户空间的一个函数来实现通知功能.&lt;br/&gt;　　&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;37&quot;&gt;
&lt;pre&gt;
&lt;span&gt;//&lt;/span&gt;&lt;span&gt;AIO完成通知-回调函数&lt;/span&gt;
&lt;span&gt;void&lt;/span&gt;&lt;span&gt; setup_io( ... )
{
&lt;/span&gt;&lt;span&gt;int&lt;/span&gt;&lt;span&gt; fd;
&lt;/span&gt;&lt;span&gt;struct&lt;/span&gt;&lt;span&gt; aiocb my_aiocb;

...

&lt;/span&gt;&lt;span&gt;/*&lt;/span&gt;&lt;span&gt; Set up the AIO request &lt;/span&gt;&lt;span&gt;*/&lt;/span&gt;&lt;span&gt;
bzero( (&lt;/span&gt;&lt;span&gt;char&lt;/span&gt; *)&amp;amp;my_aiocb, &lt;span&gt;sizeof&lt;/span&gt;(&lt;span&gt;struct&lt;/span&gt;&lt;span&gt; aiocb) );
my_aiocb.aio_fildes &lt;/span&gt;=&lt;span&gt; fd;
my_aiocb.aio_buf &lt;/span&gt;= &lt;span&gt;malloc&lt;/span&gt;(BUF_SIZE+&lt;span&gt;1&lt;/span&gt;&lt;span&gt;);
my_aiocb.aio_nbytes &lt;/span&gt;=&lt;span&gt; BUF_SIZE;
my_aiocb.aio_offset &lt;/span&gt;=&lt;span&gt; next_offset;

&lt;/span&gt;&lt;span&gt;/*&lt;/span&gt;&lt;span&gt; Link the AIO request with a thread callback &lt;/span&gt;&lt;span&gt;*/&lt;/span&gt;&lt;span&gt;
my_aiocb.aio_sigevent.sigev_notify &lt;/span&gt;= SIGEV_THREAD;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; SIGEV_THREAD 指定线程回调函数来作为通知方法&lt;/span&gt;
my_aiocb.aio_sigevent.notify_function =&lt;span&gt; aio_completion_handler;
my_aiocb.aio_sigevent.notify_attributes &lt;/span&gt;=&lt;span&gt; NULL;
my_aiocb.aio_sigevent.sigev_value.sival_ptr &lt;/span&gt;= &amp;amp;&lt;span&gt;my_aiocb;

...

ret &lt;/span&gt;= aio_read( &amp;amp;&lt;span&gt;my_aiocb );

}


&lt;/span&gt;&lt;span&gt;void&lt;/span&gt;&lt;span&gt; aio_completion_handler( sigval_t sigval )
{
&lt;/span&gt;&lt;span&gt;struct&lt;/span&gt; aiocb *&lt;span&gt;req;

req &lt;/span&gt;= (&lt;span&gt;struct&lt;/span&gt; aiocb *&lt;span&gt;)sigval.sival_ptr;

&lt;/span&gt;&lt;span&gt;/*&lt;/span&gt;&lt;span&gt; Did the request complete? &lt;/span&gt;&lt;span&gt;*/&lt;/span&gt;
&lt;span&gt;if&lt;/span&gt; (aio_error( req ) == &lt;span&gt;0&lt;/span&gt;&lt;span&gt;) {

&lt;/span&gt;&lt;span&gt;/*&lt;/span&gt;&lt;span&gt; Request completed successfully, get the return status &lt;/span&gt;&lt;span&gt;*/&lt;/span&gt;&lt;span&gt;
ret &lt;/span&gt;=&lt;span&gt; aio_return( req );

}

&lt;/span&gt;&lt;span&gt;return&lt;/span&gt;&lt;span&gt;;
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;总结&lt;/h2&gt;
&lt;p&gt;　　网络IO模型包括阻塞、非阻塞、IO复用、信号驱动IO和异步IO五种类型。阻塞IO无法应对多个连接的情形,单个socket操作阻塞会导致服务端无法接受其他连接,虽然可以用多线程、多进程的方式,将不同的连接放在不同的线程中和客户端交互,并利用线程池和连接池进行优化。但创建进程和线程会占用系统资源,当面对大规模连接时,系统资源浪费严重,系统响应效率不高。&lt;br/&gt;非阻塞模型当socket读写操作未就绪时会立即返回,而不会阻塞等待,可以利用轮询的方式来进行读写操作,但当内核收到数据报到应用进程感知并处理会有时延。&lt;br/&gt;利用IO复用,将监控socket读写操作是否就绪和进行读写操作分开,且IO复用可监控socket集合,IO复用包含select、poll、epoll三种模型。&lt;br/&gt;　　select模型存在如下三种缺点:&lt;br/&gt;　　1) 每次都需要将fd_set拷贝到内核空间,当fd_set较大时开销很大&lt;br/&gt;　　2) 每次都需要在内核中遍历fd加入到等待队列,fd较多开销较大&lt;br/&gt;　　3) select支持的文件描述符太小,默认为1024。&lt;br/&gt;　　poll模型可同时监控的socket没有上线限制,取决于系统资源,但poll模型不能避免缺点1和2。epoll模型可以避免select和poll模型的缺点。select，poll每次调用都要把fd集合从用户态往内核态拷贝一次，并且要把current进程往设备等待队列中挂一次，而epoll只要一次拷贝，而且把current进程往等待队列上挂也只挂一次。这也能节省不少的开销。select，poll内部实现需要自己不断轮询所有fd集合，直到设备就绪，期间可能要睡眠和唤醒多次交替。而epoll其实也需要调用epoll_wait不断轮询就绪链表，期间也可能多次睡眠和唤醒交替，但是它是设备就绪时，调用回调函数，把就绪fd放入就绪链表中，并唤醒在epoll_wait中进入睡眠的进程。虽然都要睡眠和交替，但是select和poll在“醒着”的时候要遍历整个fd集合，而epoll在“醒着”的时候只要判断一下就绪链表是否为空就行了，这节省了大量的CPU时间。这就是回调机制带来的性能提升。&lt;br/&gt;　　信号驱动式IO,当内核数据准备好时,发出信号,调用进程提前注册好的信号处理函数,但当存在多个socket操作时，无法分清是哪个socket准备好,因此实际应用中较少。&lt;br/&gt;无论是阻塞IO、非阻塞IO、IO复用还是信号驱动IO模型,都是同步IO模型。其要么是监控socket就绪,要么是从内核拷贝数据到进程缓冲区,至少其中一个是阻塞的,不会立即返回。异步IO模型发起读写操作后,立即返回,可以接着进行其它操作,内核完成将数据拷贝到应用进程后,通过信号或者回调函数通知进程。&lt;/p&gt;
&lt;h2&gt;&lt;br/&gt;参考文献&lt;/h2&gt;
&lt;p&gt;&lt;br/&gt;[1]. 阻塞IO（blocking IO）. https://www.chenxie.net/archives/1956.html&lt;br/&gt;[2]. Unix网络编程卷1.124~125.&lt;br/&gt;[3]. linux select函数详解. https://blog.csdn.net/lingfengtengfei/article/details/12392449&lt;br/&gt;[4]. select，poll，epoll实现分析—结合内核源代码. https://www.linuxidc.com/Linux/2012-05/59873.htm&lt;br/&gt;[5]. Python网络编程中的select 和 poll I/O复用的简单使用. https://www.cnblogs.com/coser/archive/2012/01/06/2315216.html&lt;br/&gt;[6]. socket选项总结（setsocketopt). https://blog.csdn.net/c1520006273/article/details/50420408&lt;br/&gt;[7]. Linux下I/O多路复用系统调用(select, poll, epoll)介绍. https://zhuanlan.zhihu.com/p/22834126&lt;br/&gt;[8]. IO多路复用：select、poll、epoll示例. https://blog.csdn.net/lisonglisonglisong/article/details/51328062&lt;br/&gt;[9]. Linux I/O 模型. https://woshijpf.github.io/linux/2017/07/10/Linux-IO%E6%A8%A1%E5%9E%8B.html.&lt;br/&gt;[10]. 使用异步 I/O 大大提高应用程序的性能. https://www.ibm.com/developerworks/cn/linux/l-async/&lt;/p&gt;

</description>
<pubDate>Sun, 07 Jul 2019 16:11:00 +0000</pubDate>
<dc:creator>killianxu</dc:creator>
<og:description>网络IO模型包括阻塞、非阻塞、IO复用、信号驱动IO和异步IO五种类型。阻塞IO无法应对多个连接的情形,单个socket操作阻塞会导致服务端无法接受其他连接,虽然可以用多线程、多进程的方式,将不同的连</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/killianxu/p/11148522.html</dc:identifier>
</item>
</channel>
</rss>