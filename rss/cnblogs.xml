<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="css/feed.xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/" xmlns:og="http://ogp.me/ns#">
<channel>
<atom:link rel="self" href="http://192.168.1.4/fivefilters/makefulltextfeed.php?url=feed.cnblogs.com%2Fblog%2Fsitehome%2Frss&amp;max=10&amp;links=preserve&amp;exc=" />
<atom:link rel="alternate" title="Source URL" href="http://feed.cnblogs.com/blog/sitehome/rss" />
<atom:link rel="related" title="Subscribe to feed" href="http://www.subtome.com/#/subscribe?feeds=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed.cnblogs.com%252Fblog%252Fsitehome%252Frss%26max%3D10%26links%3Dpreserve%26exc%3D&amp;back=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed.cnblogs.com%252Fblog%252Fsitehome%252Frss%26max%3D10%26links%3Dpreserve%26exc%3D" />
<title>博客园_首页</title>
<link></link>
<description>代码改变世界</description>
<item>
<title>JDK、JRE、JVM，是什么关系？ - 小傅哥</title>
<link>http://www.cnblogs.com/xiaofuge/p/14182469.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/xiaofuge/p/14182469.html</guid>
<description>&lt;p&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20201224083231703.jpg&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;br/&gt;作者：小傅哥&lt;br/&gt;博客：&lt;a href=&quot;https://bugstack.cn&quot; target=&quot;_blank&quot;&gt;https://bugstack.cn&lt;/a&gt;&lt;br/&gt;Github：&lt;a href=&quot;https://github.com/fuzhengwei/CodeGuide/wiki&quot; target=&quot;_blank&quot;&gt;https://github.com/fuzhengwei/CodeGuide/wiki&lt;/a&gt;&lt;/p&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;沉淀、分享、成长，让自己和他人都能有所收获！😄&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;一、前言&quot;&gt;一、前言&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;截至到这已经写了22篇面经手册，你看了多少？&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;😄其实小傅哥就是借着面经的幌子在讲 &lt;code&gt;Java 核心技术&lt;/code&gt;，探索这些核心知识点面试的背后到底在问什么。&lt;/p&gt;
&lt;p&gt;&lt;em&gt;想问一些面试官，是因为大家都在问所以你问，还是你想从这里问出什么？&lt;/em&gt; 其实可能很多面试官如果不了解这些技术，往往会被求职者的答案击碎内心，哈哈哈哈哈哈。比如：&lt;code&gt;梅森旋转算法&lt;/code&gt;、&lt;code&gt;开放寻址&lt;/code&gt;、&lt;code&gt;斐波那契散列&lt;/code&gt;、&lt;code&gt;启发式清理&lt;/code&gt;、&lt;code&gt;Javassist代理方式&lt;/code&gt;、&lt;code&gt;扰动函数&lt;/code&gt;、&lt;code&gt;哈希一致&lt;/code&gt;等等。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;记住&lt;/strong&gt;，让懂了就是真的懂，比看水文、背答案要爽的多！嗯，就是有时候烧脑！&lt;/p&gt;
&lt;h2 id=&quot;二、面试题&quot;&gt;二、面试题&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;谢飞机，小记！&lt;/code&gt;，也不知道咋了，总感觉有些面试&lt;code&gt;攻击性不大，但侮辱性极强&lt;/code&gt;！&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;面试官&lt;/strong&gt;：谢飞机写过 Java 吗？&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;谢飞机&lt;/strong&gt;：那当然写过，写了3年多了！&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;面试官&lt;/strong&gt;：那，&lt;code&gt;JDK&lt;/code&gt;、&lt;code&gt;JRE&lt;/code&gt;、&lt;code&gt;JVM&lt;/code&gt; 之间是什么关系？&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;谢飞机&lt;/strong&gt;：嗯 J J J，JDK 里面有 JRE，JVM 好像在 JRE 里！？&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;面试官&lt;/strong&gt;：那，Client模式、Server模式是啥？&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;谢飞机&lt;/strong&gt;：嗯！？啥？&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;面试官&lt;/strong&gt;：好吧，问个简单的。JVM 是如何工作的？&lt;em&gt;背答案了吗？&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;谢飞机&lt;/strong&gt;：再见，面试官！&lt;/p&gt;
&lt;h2 id=&quot;三、jdk、jre、jvm&quot;&gt;三、JDK、JRE、JVM&lt;/h2&gt;
&lt;h3 id=&quot;1-java-平台标准jdk-8&quot;&gt;1. Java 平台标准(JDK 8)&lt;/h3&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;Oracle has two products that implement Java Platform Standard Edition (Java SE) 8: Java SE Development Kit (JDK) 8 and Java SE Runtime Environment (JRE) 8.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote readability=&quot;13&quot;&gt;
&lt;p&gt;JDK 8 is a superset of JRE 8, and contains everything that is in JRE 8, plus tools such as the compilers and debuggers necessary for developing applets and applications. JRE 8 provides the libraries, the Java Virtual Machine (JVM), and other components to run applets and applications written in the Java programming language. Note that the JRE includes components not required by the Java SE specification, including both standard and non-standard Java components.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;The following conceptual diagram illustrates the components of Oracle's Java SE products:&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;Description of Java Conceptual Diagram&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/img_convert/f05c209af9c3d90b571dfac9c51b9a4a.png&quot; alt=&quot;Java Platform Standard Edition 8 Documentation&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;关于 JDK、JRE、JVM 之间是什么关系，在 Java 平台标准中已经明确定义了。也就是上面的英文介绍部分。&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;Oracle 有两个 Java 平台标准的产品，Java SE 开发工具包(JDK) 和 Java SE 运行时环境(JRE)。&lt;/li&gt;
&lt;li&gt;JDK(Java Development Kit Java开发工具包)，JDK是提供给Java开发人员使用的，其中包含了java的开发工具，也包括了JRE。所以安装了JDK，就不用在单独安装JRE了。其中的开发工具包括编译工具(javac.exe) 打包工具(jar.exe)等。&lt;/li&gt;
&lt;li&gt;JRE(Java Runtime Environment Java运行环境) 是 JDK 的子集，也就是包括 JRE 所有内容，以及开发应用程序所需的编译器和调试器等工具。JRE 提供了库、Java 虚拟机（JVM）和其他组件，用于运行 Java 编程语言、小程序、应用程序。&lt;/li&gt;
&lt;li&gt;JVM(Java Virtual Machine Java虚拟机)，JVM可以理解为是一个虚拟出来的计算机，具备着计算机的基本运算方式，它主要负责把 Java 程序生成的字节码文件，解释成具体系统平台上的机器指令，让其在各个平台运行。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;综上&lt;/strong&gt;，从这段官网的平台标准介绍和概念图可以看出，我们运行程序的 JVM 是已经安装到 JDK 中，只不过可能你开发了很久的代码，也没有注意过。&lt;em&gt;没有注意过的最大原因是，没有开发过一些和 JVM 相关的组件代码&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;关于&lt;/strong&gt;，各 JDK 版本的平台标准，可以自行比对学习，如下：&lt;/p&gt;
&lt;h3 id=&quot;2-jdk-目录结构和作用&quot;&gt;2. JDK 目录结构和作用&lt;/h3&gt;
&lt;p&gt;我们默认安装完 JDK 会有 &lt;code&gt;jdk1.8.0_45&lt;/code&gt;、&lt;code&gt;jre1.8.0_45&lt;/code&gt;，两个文件夹。其实在 JDK 的文件中还会有 JRE 的文件夹，他们两个 JRE 文件夹的结构是一样的。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/img_convert/e235fc356d1c6fca5c7f6c26aeb0d30f.png&quot; alt=&quot;JDK 目录结构&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;bin：一堆 EXE 可执行文件，java.exe、javac.exe、javadoc.exe，已经密钥管理工具等。&lt;/li&gt;
&lt;li&gt;db：内置了 Derby 数据库，体积小，免安装。&lt;/li&gt;
&lt;li&gt;include：Java 和 JVM 交互的头文件，例如我们 JVMTI 写的 C++ 工程时，就需要把这个 include 包引入进去&lt;code&gt;jvmti.h&lt;/code&gt;。&lt;a href=&quot;https://bugstack.cn/interview/2020/12/16/%E9%9D%A2%E7%BB%8F%E6%89%8B%E5%86%8C-%E7%AC%AC22%E7%AF%87-%E7%BA%BF%E7%A8%8B%E6%B1%A0%E7%9A%84%E4%BB%8B%E7%BB%8D%E5%92%8C%E4%BD%BF%E7%94%A8-%E4%BB%A5%E5%8F%8A%E5%9F%BA%E4%BA%8Ejvmti%E8%AE%BE%E8%AE%A1%E9%9D%9E%E5%85%A5%E4%BE%B5%E7%9B%91%E6%8E%A7.html&quot; target=&quot;_blank&quot;&gt;例如：基于jvmti设计非入侵监控&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;jre：Java 运行环境，包含了运行时需要的可执行文件，以及运行时需要依赖的 Java 类库和动态链接库&lt;code&gt;.so&lt;/code&gt; &lt;code&gt;.dll&lt;/code&gt; &lt;code&gt;.dylib&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;lib：Java 类库，例如 dt.jar、tools.jar&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;那么 jvm 在哪个文件夹呢？&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/img_convert/4ed01e1e2ffb0df692a22fba29bb26ef.png&quot; alt=&quot;jvm.dll&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;可能你之前并没有注意过 jvm 原来在这里：C:\Program Files\Java\jdk1.8.0_45\jre\bin\server&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;这部分是整个 Java 实现跨平台的最核心内容，由 Java 程序编译成的 .class 文件会在虚拟机上执行。&lt;/li&gt;
&lt;li&gt;另外在 JVM 解释 class 文件时需要调用类库 lib。在 JRE 目录下有两个文件夹 lib、bin，而 lib 就是 JVM 执行所需要的类库。&lt;/li&gt;
&lt;li&gt;jvm.dll 并不能独立工作，当 jvm.dll 启动后，会使用 explicit 方法来载入辅助动态链接库一起执行。&lt;/li&gt;
&lt;/ul&gt;&lt;h3 id=&quot;3-jdk-是什么？&quot;&gt;3. JDK 是什么？&lt;/h3&gt;
&lt;p&gt;综上通过 &lt;code&gt;Java 平台标准&lt;/code&gt;和 &lt;code&gt;JDK 的目录结构&lt;/code&gt;，JDK 是 JRE 的超集，JDK 包含了 JRE 所有的开发、调试以及监视应用程序的工具。以及如下重要的组件：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;java – 运行工具，运行 .class 的字节码&lt;/li&gt;
&lt;li&gt;javac– 编译器，将后缀名为.java的源代码编译成后缀名为.class的字节码&lt;/li&gt;
&lt;li&gt;javap – 反编译程序&lt;/li&gt;
&lt;li&gt;javadoc – 文档生成器，从源码注释中提取文档，注释需符合规范&lt;/li&gt;
&lt;li&gt;jar – 打包工具，将相关的类文件打包成一个文件&lt;/li&gt;
&lt;li&gt;jdb – debugger，调试工具&lt;/li&gt;
&lt;li&gt;jps – 显示当前java程序运行的进程状态&lt;/li&gt;
&lt;li&gt;appletviewer – 运行和调试applet程序的工具，不需要使用浏览器&lt;/li&gt;
&lt;li&gt;javah – 从Java类生成C头文件和C源文件。这些文件提供了连接胶合，使 Java 和 C 代码可进行交互。&lt;/li&gt;
&lt;li&gt;javaws – 运行 JNLP 程序&lt;/li&gt;
&lt;li&gt;extcheck – 一个检测jar包冲突的工具&lt;/li&gt;
&lt;li&gt;apt – 注释处理工具&lt;/li&gt;
&lt;li&gt;jhat – java堆分析工具&lt;/li&gt;
&lt;li&gt;jstack – 栈跟踪程序&lt;/li&gt;
&lt;li&gt;jstat – JVM检测统计工具&lt;/li&gt;
&lt;li&gt;jstatd – jstat守护进程&lt;/li&gt;
&lt;li&gt;jinfo – 获取正在运行或崩溃的java程序配置信息&lt;/li&gt;
&lt;li&gt;jmap – 获取java进程内存映射信息&lt;/li&gt;
&lt;li&gt;idlj – IDL-to-Java 编译器. 将IDL语言转化为java文件&lt;/li&gt;
&lt;li&gt;policytool – 一个GUI的策略文件创建和管理工具&lt;/li&gt;
&lt;li&gt;jrunscript – 命令行脚本运行&lt;/li&gt;
&lt;li&gt;appletviewer：小程序浏览器，一种执行HTML文件上的Java小程序的Java浏览器&lt;/li&gt;
&lt;/ul&gt;&lt;h3 id=&quot;4-jre-是什么？&quot;&gt;4. JRE 是什么？&lt;/h3&gt;
&lt;p&gt;JRE 本身也是一个运行在 CPU 上的程序，用于解释执行 Java 代码。&lt;/p&gt;
&lt;p&gt;一般像是实施的工作，会在客户现场安装 JRE，因为这是运行 Java 程序的最低要求。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/img_convert/d3f4debddeabb5eaf5bdd7b8802831ab.png&quot; alt=&quot;JRE 目录结构 lib、bin&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;bin：有 java.exe 但没有 javac.exe。也就是无法编译 Java 程序，但可以运行 Java 程序，可以把这个bin目录理解成JVM。&lt;/li&gt;
&lt;li&gt;lib：Java 基础&amp;amp;核心类库，包含 JVM 运行时需要的类库和 rt.jar。也包含用于安全管理的文件，这些文件包括安全策略(security policy)和安全属性(security properties)等。&lt;/li&gt;
&lt;/ul&gt;&lt;h3 id=&quot;5-jvm-是什么？&quot;&gt;5. JVM 是什么？&lt;/h3&gt;
&lt;p&gt;其实简单说 JVM 就是运行 Java 字节码的虚拟机，JVM 是一种规范，各个供应商都可以实现自己 JVM虚拟机。就像小傅哥自己也按照虚拟机规范和手写JVM的相关书籍实现了，基于Java实现的JVM虚拟机。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/img_convert/009b09f2dc3a1559b59d04cc72db9c2c.png&quot; alt=&quot;用Java实现JVM源码&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;源码地址&lt;/strong&gt;：&lt;a href=&quot;https://github.com/fuzhengwei/itstack-demo-jvm&quot; target=&quot;_blank&quot;&gt;https://github.com/fuzhengwei/itstack-demo-jvm&lt;/a&gt;&lt;br/&gt;&lt;strong&gt;内容简介&lt;/strong&gt;：本代码主要介绍如何通过 java 代码来实现 JVM 的基础功能（搜索解析class文件、字节码命令、运行时数据区等），从而让java程序员通过最熟知的java程序，学习JVM是如何将java程序一步步跑起来的。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;当然&lt;/strong&gt;，我们下载 Oracle 公司的 JVM 与自己实现的相比，要高级的多。他们的设计有不断优化的内存模型、GC回收策略、自适应优化器等。&lt;/p&gt;
&lt;p&gt;另外，JVM 之所以称为虚拟机，主要就是因为它为了实现 “write-once-run-anywhere”。提供了一个不依赖于底层操作系统和机器硬件结构的运行环境。&lt;/p&gt;
&lt;h4 id=&quot;51-client模式、server模式&quot;&gt;5.1 Client模式、Server模式&lt;/h4&gt;
&lt;p&gt;在 JVM 中有两种不同风格的启动模式， Client模式、Server模式。&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;Client模式：加载速度较快。可以用于运行GUI交互程序。&lt;/li&gt;
&lt;li&gt;Server模式：加载速度较慢但运行起来较快。可以用于运行服务器后台程序。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;修改配置模式文件：&lt;code&gt;C:\Program Files\Java\jre1.8.0_45\lib\amd64\jvm.cfg&lt;/code&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;# List of JVMs that can be used as an option to java, javac, etc.
# Order is important -- first in this list is the default JVM.
# NOTE that this both this file and its format are UNSUPPORTED and
# WILL GO AWAY in a future release.
#
# You may also select a JVM in an arbitrary location with the
# &quot;-XXaltjvm=&amp;lt;jvm_dir&amp;gt;&quot; option, but that too is unsupported
# and may not be available in a future release.
#
-server KNOWN
-client IGNORE
&lt;/code&gt;
&lt;/pre&gt;
&lt;ul&gt;&lt;li&gt;如果需要调整，可以把 client 设置为 KNOWN，并调整到 server 前面。&lt;/li&gt;
&lt;li&gt;JVM 默认在 Server模式下，-Xms128M、-Xmx1024M&lt;/li&gt;
&lt;li&gt;JVM 默认在 Client 模式下，-Xms1M、-Xmx64M&lt;/li&gt;
&lt;/ul&gt;&lt;h4 id=&quot;52-jvm-结构和执行器&quot;&gt;5.2 JVM 结构和执行器&lt;/h4&gt;
&lt;p&gt;这部分属于 JVM 的核心知识，但不是本篇重点，会在后续的章节中陆续讲到。本章只做一些介绍。&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;Class Loader：类装载器是用于加载类文件的一个子系统，其主要功能有三个：loading(加载），linking（链接）,initialization（初始化）。&lt;/li&gt;
&lt;li&gt;JVM Memory Areas：方法区、堆区、栈区、程序计数器。&lt;/li&gt;
&lt;li&gt;Interpreter(解释器)：通过查找预定义的 JVM 指令到机器指令映射，JVM 解释器可以将每个字节码指令转换为相应的本地指令。它直接执行字节码，不执行任何优化。&lt;/li&gt;
&lt;li&gt;JIT Compiler(即时编译器)：为了提高效率，JIT Compiler 在运行时与 JVM 交互，并适当将字节码序列编译为本地机器代码。典型地，JIT Compiler执行一段代码，不是每次一条语句。优化这块代码，并将其翻译为优化的机器代码。&lt;em&gt;JIT Compiler是默认开启&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;h2 id=&quot;四、总结&quot;&gt;四、总结&lt;/h2&gt;
&lt;ul&gt;&lt;li&gt;这篇的知识并不复杂，涉及的面试内容也较少，更多的是对接下来要讲到 JVM 相关面试内容的一个开篇介绍，为后续的要讲的内容做一个铺垫。&lt;/li&gt;
&lt;li&gt;如果你在此之前没有关注过JDK、JRE、JVM的结构和相应的组件配置以及执行模式，那么可以在此基础上继续学习加深印象。另外想深入学习JVM并不太容易，既要学习JVM规范也要上手应用实践，所以很建议先手写JVM，再实践验证JVM。&lt;/li&gt;
&lt;li&gt;好了，本章节就扯到这了。这些知识点即使分享给大家，也是我自己学习、收录、整理、验证的过程。互相学习、互相成长，如果有错误之处，直接留言给我，我会不断的改正。大家一起进步！&lt;/li&gt;
&lt;/ul&gt;&lt;h2 id=&quot;五、系列推荐&quot;&gt;五、系列推荐&lt;/h2&gt;
</description>
<pubDate>Thu, 24 Dec 2020 00:38:00 +0000</pubDate>
<dc:creator>小傅哥</dc:creator>
<og:description>作者：小傅哥 博客：https://bugstack.cn Github：https://github.com/fuzhengwei/CodeGuide/wiki 沉淀、分享、成长，让自己和他人都能有</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/xiaofuge/p/14182469.html</dc:identifier>
</item>
<item>
<title>30G 上亿数据的超大文件，如何快速导入生产环境？ - 楼下小黑哥</title>
<link>http://www.cnblogs.com/goodAndyxublog/p/14182457.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/goodAndyxublog/p/14182457.html</guid>
<description>&lt;p&gt;Hello，大家好，我是楼下小黑哥~&lt;/p&gt;
&lt;p&gt;如果给你一个包含一亿行数据的超大文件，让你在一周之内将数据转化导入生产数据库，你会如何操作？&lt;/p&gt;
&lt;p&gt;上面的问题其实是小黑哥前段时间接到一个真实的业务需求，将一个老系统历史数据通过线下文件的方式迁移到新的生产系统。&lt;/p&gt;
&lt;p&gt;&lt;s&gt;由于老板们已经敲定了新系统上线时间，所以只留给小黑哥一周的时间将历史数据导入生产系统。&lt;/s&gt;&lt;/p&gt;
&lt;p&gt;由于时间紧，而数据量又超大，所以小黑哥设计的过程想到一下解决办法：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;拆分文件&lt;/li&gt;
&lt;li&gt;多线程导入&lt;/li&gt;
&lt;/ul&gt;&lt;blockquote readability=&quot;5.5555555555556&quot;&gt;
&lt;p&gt;欢迎关注我的公众号：小黑十一点半，获得日常干货推送。如果您对我的专题内容感兴趣，也可以关注我的博客：&lt;a href=&quot;https://studyidea.cn&quot; target=&quot;_blank&quot;&gt;studyidea.cn&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;拆分文件&quot;&gt;拆分文件&lt;/h2&gt;
&lt;p&gt;首先我们可以写个小程序，或者使用拆分命令 &lt;code&gt;split&lt;/code&gt; 将这个超大文件拆分一个个小文件。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-shell&quot;&gt;-- 将一个大文件拆分成若干个小文件，每个文件 100000 行
split -l 100000 largeFile.txt -d -a 4 smallFile_
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;这里之所以选择先将大文件拆分，主要考虑到两个原因：&lt;/p&gt;
&lt;p&gt;第一如果程序直接读取这个大文件，假设读取一半的时候，程序突然宕机，这样就会直接丢失文件读取的进度，又需要重新开头读取。&lt;/p&gt;
&lt;p&gt;而文件拆分之后，一旦小文件读取结束，我们可以将小文件移动一个指定文件夹。&lt;/p&gt;
&lt;p&gt;这样即使应用程序宕机重启，我们重新读取时，只需要读取剩余的文件。&lt;/p&gt;
&lt;p&gt;第二，一个文件，只能被一个应用程序读取，这样就限制了导入的速度。&lt;/p&gt;
&lt;p&gt;而文件拆分之后，我们可以采用多节点部署的方式，水平扩展。每个节点读取一部分文件，这样就可以成倍的加快导入速度。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/1419561/202012/1419561-20201224083138027-1258893766.jpg&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h2 id=&quot;多线程导入&quot;&gt;多线程导入&lt;/h2&gt;
&lt;p&gt;当我们拆分完文件，接着我们就需要读取文件内容，进行导入。&lt;/p&gt;
&lt;p&gt;之前拆分的时候，设置每个小文件包含 10w 行的数据。由于担心一下子将 10w 数据读取应用中，导致堆内存占用过高，引起频繁的 &lt;strong&gt;Full GC&lt;/strong&gt;，所以下面采用流式读取的方式，一行一行的读取数据。&lt;/p&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;当然了，如果拆分之后文件很小，或者说应用的堆内存设置很大，我们可以直接将文件加载到应用内存中处理。这样相对来说简单一点。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;逐行读取的代码如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;File file = ...
try (LineIterator iterator = IOUtils.lineIterator(new FileInputStream(file), &quot;UTF-8&quot;)) {
    while (iterator.hasNext()) {
        String line=iterator.nextLine();
        convertToDB(line);
    }

}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;上面代码使用 &lt;code&gt;commons-io&lt;/code&gt; 中的 &lt;code&gt;LineIterator&lt;/code&gt;类，这个类底层使用了 &lt;code&gt;BufferedReader&lt;/code&gt; 读取文件内容。它将其封装成迭代器模式，这样我们可以很方便的迭代读取。&lt;/p&gt;
&lt;p&gt;如果当前使用 JDK1.8 ，那么上述操作更加简单，我们可以直接使用 JDK 原生的类 &lt;code&gt;Files&lt;/code&gt;将文件转成 &lt;code&gt;Stream&lt;/code&gt; 方式读取，代码如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;Files.lines(Paths.get(&quot;文件路径&quot;), Charset.defaultCharset()).forEach(line -&amp;gt; {
    convertToDB(line);
});
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;其实仔细看下 &lt;code&gt;Files#lines&lt;/code&gt;底层源码，其实原理跟上面的 &lt;code&gt;LineIterator&lt;/code&gt;类似，同样也是封装成迭代器模式。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/1419561/202012/1419561-20201224083138660-588710224.jpg&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h3 id=&quot;多线程的引入存在的问题&quot;&gt;多线程的引入存在的问题&lt;/h3&gt;
&lt;p&gt;上述读取的代码写起来不难，但是存在效率问题，主要是因为只有单线程在导入，上一行数据导入完成之后，才能继续操作下一行。&lt;/p&gt;
&lt;p&gt;为了加快导入速度，那我们就多来几个线程，并发导入。&lt;/p&gt;
&lt;p&gt;多线程我们自然将会使用线程池的方式，相关代码改造如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;File file = ...;
ExecutorService executorService = new ThreadPoolExecutor(
        5,
        10,
        60,
        TimeUnit.MINUTES,
                        // 文件数量，假设文件包含 10W 行
        new ArrayBlockingQueue&amp;lt;&amp;gt;(10*10000),
                         // guava 提供
        new ThreadFactoryBuilder().setNameFormat(&quot;test-%d&quot;).build());
try (LineIterator iterator = IOUtils.lineIterator(new FileInputStream(file), &quot;UTF-8&quot;)) {
    while (iterator.hasNext()) {
        String line = iterator.nextLine();
        executorService.submit(() -&amp;gt; {
            convertToDB(line);
        });
    }

}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;上述代码中，每读取到一行内容，就会直接交给线程池来执行。&lt;/p&gt;
&lt;p&gt;我们知道线程池原理如下：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;如果核心线程数未满，将会直接创建线程执行任务。&lt;/li&gt;
&lt;li&gt;如果核心线程数已满，将会把任务放入到队列中。&lt;/li&gt;
&lt;li&gt;如果队列已满，将会再创建线程执行任务。&lt;/li&gt;
&lt;li&gt;如果最大线程数已满，队列也已满，那么将会执行拒绝策略。&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/1419561/202012/1419561-20201224083139040-992119937.jpg&quot; alt=&quot;线程池执行流程图&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;由于我们上述线程池设置的核心线程数为 5，很快就到达了最大核心线程数，后续任务只能被加入队列。&lt;/p&gt;
&lt;p&gt;为了后续任务不被线程池拒绝，我们可以采用如下方案：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;将队列容量设置成很大，包含整个文件所有行数&lt;/li&gt;
&lt;li&gt;将最大线程数设置成很大，数量大于件所有行数&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;以上两种方案都存在同样的问题，第一种是相当于将文件所有内容加载到内存，将会占用过多内存。&lt;/p&gt;
&lt;p&gt;而第二种创建过多的线程，同样也会占用过多内存。&lt;/p&gt;
&lt;p&gt;一旦内存占用过多，GC 无法清理，就可能会引起频繁的 &lt;strong&gt;Full GC&lt;/strong&gt;，甚至导致 &lt;strong&gt;OOM&lt;/strong&gt;，导致程序导入速度过慢。&lt;/p&gt;
&lt;p&gt;解决这个问题，我们可以如下两种解决方案：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;code&gt;CountDownLatch&lt;/code&gt; 批量执行&lt;/li&gt;
&lt;li&gt;扩展线程池&lt;/li&gt;
&lt;/ul&gt;&lt;h3 id=&quot;countdownlatch-批量执行&quot;&gt;&lt;code&gt;CountDownLatch&lt;/code&gt; 批量执行&lt;/h3&gt;
&lt;p&gt;JDK 提供的 &lt;code&gt;CountDownLatch&lt;/code&gt;，可以让主线程等待子线程都执行完成之后，再继续往下执行。&lt;/p&gt;
&lt;p&gt;利用这个特性，我们可以改造多线程导入的代码,主体逻辑如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;try (LineIterator iterator = IOUtils.lineIterator(new FileInputStream(file), &quot;UTF-8&quot;)) {
    // 存储每个任务执行的行数
    List&amp;lt;String&amp;gt; lines = Lists.newArrayList();
    // 存储异步任务
    List&amp;lt;ConvertTask&amp;gt; tasks = Lists.newArrayList();
    while (iterator.hasNext()) {
        String line = iterator.nextLine();
        lines.add(line);
        // 设置每个线程执行的行数
        if (lines.size() == 1000) {
            // 新建异步任务，注意这里需要创建一个 List
            tasks.add(new ConvertTask(Lists.newArrayList(lines)));
            lines.clear();
        }
        if (tasks.size() == 10) {
            asyncBatchExecuteTask(tasks);
        }

    }
    // 文件读取结束，但是可能还存在未被内容
    tasks.add(new ConvertTask(Lists.newArrayList(lines)));
    // 最后再执行一次
    asyncBatchExecuteTask(tasks);
}

&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;这段代码中，每个异步任务将会导入 1000 行数据，等积累了 10 个异步任务，然后将会调用 &lt;code&gt;asyncBatchExecuteTask&lt;/code&gt; 使用线程池异步执行。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;/**
 * 批量执行任务
 *
 * @param tasks
 */
private static void asyncBatchExecuteTask(List&amp;lt;ConvertTask&amp;gt; tasks) throws InterruptedException {
    CountDownLatch countDownLatch = new CountDownLatch(tasks.size());
    for (ConvertTask task : tasks) {
        task.setCountDownLatch(countDownLatch);
        executorService.submit(task);
    }
    // 主线程等待异步线程 countDownLatch 执行结束
    countDownLatch.await();
    // 清空，重新添加任务
    tasks.clear();
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;asyncBatchExecuteTask&lt;/code&gt; 方法内将会创建 &lt;code&gt;CountDownLatch&lt;/code&gt;，然后主线程内调用 &lt;code&gt;await&lt;/code&gt;方法等待所有异步线程执行结束。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;ConvertTask&lt;/code&gt; 异步任务逻辑如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;/**
 * 异步任务
 * 等数据导入完成之后，一定要调用 countDownLatch.countDown()
 * 不然，这个主线程将会被阻塞，
 */
private static class ConvertTask implements Runnable {

    private CountDownLatch countDownLatch;

    private List&amp;lt;String&amp;gt; lines;

    public ConvertTask(List&amp;lt;String&amp;gt; lines) {
        this.lines = lines;
    }

    public void setCountDownLatch(CountDownLatch countDownLatch) {
        this.countDownLatch = countDownLatch;
    }

    @Override
    public void run() {
        try {
            for (String line : lines) {
                convertToDB(line);
            }
        } finally {
            countDownLatch.countDown();
        }
    }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;ConvertTask&lt;/code&gt;任务类逻辑就非常简单，遍历所有行，将其导入到数据库中。所有数据导入结束，调用 &lt;code&gt;countDownLatch#countDown&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;一旦所有异步线程执行结束，调用 &lt;code&gt;countDownLatch#countDown&lt;/code&gt;，主线程将会被唤醒，继续执行文件读取。&lt;/p&gt;
&lt;p&gt;虽然这种方式解决上述问题，但是这种方式，每次都需要积累一定任务数才能开始异步执行所有任务。&lt;/p&gt;
&lt;p&gt;另外每次都需要等待所有任务执行结束之后，才能开始下一批任务，批量执行消耗的时间等于最慢的异步任务消耗的时间。&lt;/p&gt;
&lt;p&gt;这种方式线程池中线程存在一定的闲置时间，那有没有办法一直压榨线程池，让它一直在干活呢？&lt;/p&gt;
&lt;h3 id=&quot;扩展线程池&quot;&gt;扩展线程池&lt;/h3&gt;
&lt;p&gt;回到最开始的问题，文件读取导入，其实就是一个&lt;strong&gt;生产者-消费者&lt;/strong&gt;消费模型。&lt;/p&gt;
&lt;p&gt;主线程作为生产者不断读取文件，然后将其放置到队列中。&lt;/p&gt;
&lt;p&gt;异步线程作为消费者不断从队列中读取内容，导入到数据库中。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;一旦队列满载，生产者应该阻塞，直到消费者消费任务。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;其实我们使用线程池的也是一个&lt;strong&gt;生产者-消费者&lt;/strong&gt;消费模型，其也使用阻塞队列。&lt;/p&gt;
&lt;p&gt;那为什么线程池在队列满载的时候，不发生阻塞？&lt;/p&gt;
&lt;p&gt;这是因为线程池内部使用 &lt;code&gt;offer&lt;/code&gt; 方法，这个方法在队列满载的时候&lt;strong&gt;不会发生阻塞&lt;/strong&gt;，而是直接返回 。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/1419561/202012/1419561-20201224083139377-18183902.jpg&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;那我们有没有办法在线程池队列满载的时候，阻塞主线程添加任务？&lt;/p&gt;
&lt;p&gt;其实是可以的，我们自定义线程池拒绝策略，当队列满时改为调用 &lt;code&gt;BlockingQueue.put&lt;/code&gt; 来实现生产者的阻塞。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;RejectedExecutionHandler rejectedExecutionHandler = new RejectedExecutionHandler() {
    @Override
    public void rejectedExecution(Runnable r, ThreadPoolExecutor executor) {
        if (!executor.isShutdown()) {
            try {
                executor.getQueue().put(r);
            } catch (InterruptedException e) {
                // should not be interrupted
            }
        }

    }
};
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;这样一旦线程池满载，主线程将会被阻塞。&lt;/p&gt;
&lt;p&gt;使用这种方式之后，我们可以直接使用上面提到的多线程导入的代码。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;ExecutorService executorService = new ThreadPoolExecutor(
        5,
        10,
        60,
        TimeUnit.MINUTES,
        new ArrayBlockingQueue&amp;lt;&amp;gt;(100),
        new ThreadFactoryBuilder().setNameFormat(&quot;test-%d&quot;).build(),
        (r, executor) -&amp;gt; {
            if (!executor.isShutdown()) {
                try {
                        // 主线程将会被阻塞
                    executor.getQueue().put(r);
                } catch (InterruptedException e) {
                    // should not be interrupted
                }
            }

        });
File file = new File(&quot;文件路径&quot;);

try (LineIterator iterator = IOUtils.lineIterator(new FileInputStream(file), &quot;UTF-8&quot;)) {
    while (iterator.hasNext()) {
        String line = iterator.nextLine();
        executorService.submit(() -&amp;gt; convertToDB(line));
    }
}    
&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;小结&quot;&gt;小结&lt;/h2&gt;
&lt;p&gt;一个超大的文件，我们可以采用拆分文件的方式，将其拆分成多份文件，然后部署多个应用程序提高读取速度。&lt;/p&gt;
&lt;p&gt;另外读取过程我们还可以使用多线程的方式并发导入，不过我们需要注意线程池满载之后，将会拒绝后续任务。&lt;/p&gt;
&lt;p&gt;我们可以通过扩展线程池，自定义拒绝策略，使读取主线程阻塞。&lt;/p&gt;
&lt;p&gt;好了，今天文章内容就到这里，不知道各位有没有其他更好的解决办法，欢迎留言讨论。&lt;/p&gt;
&lt;blockquote readability=&quot;5.5555555555556&quot;&gt;
&lt;p&gt;欢迎关注我的公众号：小黑十一点半，获得日常干货推送。如果您对我的专题内容感兴趣，也可以关注我的博客：&lt;a href=&quot;https://studyidea.cn&quot; target=&quot;_blank&quot;&gt;studyidea.cn&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
</description>
<pubDate>Thu, 24 Dec 2020 00:32:00 +0000</pubDate>
<dc:creator>楼下小黑哥</dc:creator>
<og:description>Hello，大家好，我是楼下小黑哥~ 如果给你一个包含一亿行数据的超大文件，让你在一周之内将数据转化导入生产数据库，你会如何操作？ 上面的问题其实是小黑哥前段时间接到一个真实的业务需求，将一个老系统历</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/goodAndyxublog/p/14182457.html</dc:identifier>
</item>
<item>
<title>C#中的深度学习（四）：使用Keras.NET识别硬币 - 码农译站</title>
<link>http://www.cnblogs.com/hhhnicvscs/p/14182453.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/hhhnicvscs/p/14182453.html</guid>
<description>&lt;p&gt;在本文中，我们将研究一个卷积神经网络来解决硬币识别问题，并且我们将在Keras.NET中实现一个卷积神经网络。&lt;/p&gt;
&lt;p&gt;在这里，我们将介绍卷积神经网络(CNN)，并提出一个CNN的架构，我们将训练它来识别硬币。&lt;/p&gt;
&lt;p&gt;什么是CNN?正如我们在本系列的前一篇文章中提到的，CNN是一类经常用于图像分类任务的神经网络(NN)，比如物体和人脸识别。在CNN中，并非每个节点都连接到下一层的所有节点。这种部分连通性有助于防止在完全连接的网络神经网络中出现的过拟合问题，并且加速了神经网络的收敛速度。&lt;/p&gt;
&lt;p&gt;围绕CNN的核心概念是一种被称为卷积的数学运算，卷积在数字信号处理领域非常常见。卷积被定义为两个函数的乘积，产生的第三个函数表示前两个函数之间的重叠量。&lt;/p&gt;
&lt;p&gt;在物体识别中，卷积操作允许我们检测图像中的不同特征，如垂直和水平的边缘，纹理和曲线。这就是为什么任何CNN的第一层都是卷积层。&lt;/p&gt;
&lt;p&gt;CNN中另一个常见的层是池化层。池化用于减少图像表示的大小，这意味着减少参数的数量，并最终减少计算量。最常见的池化类型是最大池化，它在每个位置上从匹配的单元格组中获取最大值。最后，根据所获得的最大值建立新的图像。&lt;/p&gt;
&lt;p&gt;另一个与卷积相关的概念是填充。填充保证了卷积过程将均匀地发生在整个图像，包括边界像素。这个保证是由一个零像素的边框支持的，该边框在缩小后的图像周围添加(在池化之后)，以便可以以相同的次数访问图像的所有像素。&lt;/p&gt;
&lt;p&gt;最常见的CNN架构通常从卷积层开始，接着是激活层，然后是池化层，最后是传统的全连接网络，比如多层NN。这种类型的模型是层次化的，称为顺序模型。为什么以一个完全连接的网络结束?为了学习转换后图像(经过卷积和池化)中的特征的非线性组合。&lt;/p&gt;
&lt;p&gt;下面是我们将在CNN中实现的架构:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;Conv2D层- 32个过滤器，过滤器大小为3&lt;/li&gt;
&lt;li&gt;激活层使用ReLU函数&lt;/li&gt;
&lt;li&gt;Conv2D层- 32个过滤器，过滤器大小为3&lt;/li&gt;
&lt;li&gt;激活层使用ReLU函数&lt;/li&gt;
&lt;li&gt;MaxPooling2D层-应用(2,2)池窗口&lt;/li&gt;
&lt;li&gt;DropOut图层，25% -通过随机删除前一层的一些值来防止过拟合(设置为0);也就是稀释法&lt;/li&gt;
&lt;li&gt;Conv2D层- 64个过滤器，过滤器大小为3&lt;/li&gt;
&lt;li&gt;激活层使用ReLU函数&lt;/li&gt;
&lt;li&gt;Conv2D图层- 64个过滤器，过滤器大小为3，步幅为3&lt;/li&gt;
&lt;li&gt;激活层使用ReLU函数&lt;/li&gt;
&lt;li&gt;MaxPooling2D层-应用(2,2)池窗口&lt;/li&gt;
&lt;li&gt;DropOut层，25%&lt;/li&gt;
&lt;li&gt;Flatten层-转换数据，以在下一层中使用&lt;/li&gt;
&lt;li&gt;Dense 层——表示具有512个节点的传统神经网络的全连接。&lt;/li&gt;
&lt;li&gt;激活层使用ReLU函数&lt;/li&gt;
&lt;li&gt;DropOut层，在50%&lt;/li&gt;
&lt;li&gt;Dense层，与节点数量匹配的类的数量&lt;/li&gt;
&lt;li&gt;Softmax层&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;该体系结构遵循了一种用于物体识别的CNN体系结构模式;层参数通过实验进行了微调。&lt;/p&gt;
&lt;p&gt;我们经过的参数微调过程的结果部分存储在Settings类中，我们在这里展示:&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;36&quot;&gt;
&lt;pre&gt;
&lt;span&gt;public&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;&lt;span&gt; Settings
{
        &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;const&lt;/span&gt; &lt;span&gt;int&lt;/span&gt; ImgWidth = &lt;span&gt;64&lt;/span&gt;&lt;span&gt;;
        &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;const&lt;/span&gt; &lt;span&gt;int&lt;/span&gt; ImgHeight = &lt;span&gt;64&lt;/span&gt;&lt;span&gt;;
        &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;const&lt;/span&gt; &lt;span&gt;int&lt;/span&gt; MaxValue = &lt;span&gt;255&lt;/span&gt;&lt;span&gt;;
        &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;const&lt;/span&gt; &lt;span&gt;int&lt;/span&gt; MinValue = &lt;span&gt;0&lt;/span&gt;&lt;span&gt;;
        &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;const&lt;/span&gt; &lt;span&gt;int&lt;/span&gt; Channels = &lt;span&gt;3&lt;/span&gt;&lt;span&gt;;
        &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;const&lt;/span&gt; &lt;span&gt;int&lt;/span&gt; BatchSize = &lt;span&gt;12&lt;/span&gt;&lt;span&gt;;
        &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;const&lt;/span&gt; &lt;span&gt;int&lt;/span&gt; Epochs = &lt;span&gt;10&lt;/span&gt;&lt;span&gt;;
        &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;const&lt;/span&gt; &lt;span&gt;int&lt;/span&gt; FullyConnectedNodes = &lt;span&gt;512&lt;/span&gt;&lt;span&gt;;
        &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;const&lt;/span&gt; &lt;span&gt;string&lt;/span&gt; LossFunction = &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;categorical_crossentropy&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;;
        &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;const&lt;/span&gt; &lt;span&gt;string&lt;/span&gt; Accuracy = &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;accuracy&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;;
        &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;const&lt;/span&gt; &lt;span&gt;string&lt;/span&gt; ActivationFunction = &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;relu&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;;
        &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;const&lt;/span&gt; &lt;span&gt;string&lt;/span&gt; PaddingMode = &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;same&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;;
        &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; StringOrInstance Optimizer = &lt;span&gt;new&lt;/span&gt;&lt;span&gt; RMSprop(lr: Lr, decay: Decay);
        &lt;/span&gt;&lt;span&gt;private&lt;/span&gt; &lt;span&gt;const&lt;/span&gt; &lt;span&gt;float&lt;/span&gt; Lr = &lt;span&gt;0.0001f&lt;/span&gt;&lt;span&gt;;
        &lt;/span&gt;&lt;span&gt;private&lt;/span&gt; &lt;span&gt;const&lt;/span&gt; &lt;span&gt;float&lt;/span&gt; Decay = &lt;span&gt;1e-6f&lt;/span&gt;&lt;span&gt;;
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;我们现在有了CNN的体系结构。接下来，我们将研究使用Keras.NET实现的用于硬币识别的CNN。&lt;/p&gt;
&lt;p&gt;首先，让我们从Nuget包管理器下载Keras.NET包。我们可以在&lt;strong&gt;Tools&lt;/strong&gt; &amp;gt; &lt;strong&gt;Nuget package manager&lt;/strong&gt;中找到Nuget包管理器。Keras.NET依赖于包Numpy.NET和pythonnet_netstandard。如果没有安装它们，让我们继续安装它们。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/2248030/202012/2248030-20201224082737220-326953956.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;需要指出的是，Keras.NET 需要在你的操作系统中安装Python 2.7-3.7版本。它还需要安装Python库Numpy和TensorFlow。在本例中，我们使用的是64位的Python 3.7。&lt;/p&gt;
&lt;p&gt;如果在执行本文中的代码时遇到任何问题，请在控制台应用程序中主方法的开始执行时尝试运行以下代码一次。这段代码将设置所需的环境变量，以便找到所有dll:&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;42&quot;&gt;
&lt;pre&gt;
&lt;span&gt;private&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; &lt;span&gt;void&lt;/span&gt;&lt;span&gt; SetupPyEnv()
{
     &lt;/span&gt;&lt;span&gt;string&lt;/span&gt; envPythonHome = &lt;span&gt;@&quot;&lt;/span&gt;&lt;span&gt;C:\Users\arnal\AppData\Local\Programs\Python\Python37\&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;;
     &lt;/span&gt;&lt;span&gt;string&lt;/span&gt; envPythonLib = envPythonHome + &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;Lib\\;&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; + envPythonHome + &lt;span&gt;@&quot;&lt;/span&gt;&lt;span&gt;Lib\site-packages\&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;;
     Environment.SetEnvironmentVariable(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;PYTHONHOME&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;, envPythonHome, EnvironmentVariableTarget.Process);
     Environment.SetEnvironmentVariable(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;PATH&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;, envPythonHome + &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; + envPythonLib + &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; + Environment.GetEnvironmentVariable(&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;PATH&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;, EnvironmentVariableTarget.Machine), EnvironmentVariableTarget.Process);
     Environment.SetEnvironmentVariable(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;PYTHONPATH&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;, envPythonLib, EnvironmentVariableTarget.User);
     PythonEngine.PythonHome &lt;/span&gt;=&lt;span&gt; envPythonHome;
     PythonEngine.PythonPath &lt;/span&gt;= Environment.GetEnvironmentVariable(&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;PYTHONPATH&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;);
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;现在我们将看到使用Keras.NET创建我们的硬币识别CNN是多么简单和透明。下面的类显示了包含模型的所有逻辑的Cnn类。&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;62&quot;&gt;
&lt;pre&gt;
&lt;span&gt;public&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;&lt;span&gt; Cnn
    {
        &lt;/span&gt;&lt;span&gt;private&lt;/span&gt;&lt;span&gt; DataSet _dataset;
        &lt;/span&gt;&lt;span&gt;private&lt;/span&gt;&lt;span&gt; Sequential _model;

        &lt;/span&gt;&lt;span&gt;public&lt;/span&gt;&lt;span&gt; Cnn(DataSet dataset)
        {
            _dataset &lt;/span&gt;=&lt;span&gt; dataset;
            _model &lt;/span&gt;= &lt;span&gt;new&lt;/span&gt;&lt;span&gt; Sequential();
        }

        &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt;&lt;span&gt; Train()
        {
            &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; Build CNN model&lt;/span&gt;
            _model.Add(&lt;span&gt;new&lt;/span&gt; Conv2D(&lt;span&gt;32&lt;/span&gt;, kernel_size: (&lt;span&gt;3&lt;/span&gt;, &lt;span&gt;3&lt;/span&gt;&lt;span&gt;).ToTuple(),
                                 padding: Settings.PaddingMode,
                                 input_shape: &lt;/span&gt;&lt;span&gt;new&lt;/span&gt;&lt;span&gt; Shape(Settings.ImgWidth, Settings.ImgHeight, Settings.Channels)));
            _model.Add(&lt;/span&gt;&lt;span&gt;new&lt;/span&gt;&lt;span&gt; Activation(Settings.ActivationFunction));
            _model.Add(&lt;/span&gt;&lt;span&gt;new&lt;/span&gt; Conv2D(&lt;span&gt;32&lt;/span&gt;, (&lt;span&gt;3&lt;/span&gt;, &lt;span&gt;3&lt;/span&gt;&lt;span&gt;).ToTuple()));
            _model.Add(&lt;/span&gt;&lt;span&gt;new&lt;/span&gt;&lt;span&gt; Activation(Settings.ActivationFunction));
            _model.Add(&lt;/span&gt;&lt;span&gt;new&lt;/span&gt; MaxPooling2D(pool_size: (&lt;span&gt;2&lt;/span&gt;, &lt;span&gt;2&lt;/span&gt;&lt;span&gt;).ToTuple()));
            _model.Add(&lt;/span&gt;&lt;span&gt;new&lt;/span&gt; Dropout(&lt;span&gt;0.25&lt;/span&gt;&lt;span&gt;));

            _model.Add(&lt;/span&gt;&lt;span&gt;new&lt;/span&gt; Conv2D(&lt;span&gt;64&lt;/span&gt;, kernel_size: (&lt;span&gt;3&lt;/span&gt;, &lt;span&gt;3&lt;/span&gt;&lt;span&gt;).ToTuple(),
                                padding: Settings.PaddingMode));
            _model.Add(&lt;/span&gt;&lt;span&gt;new&lt;/span&gt;&lt;span&gt; Activation(Settings.ActivationFunction));
            _model.Add(&lt;/span&gt;&lt;span&gt;new&lt;/span&gt; Conv2D(&lt;span&gt;64&lt;/span&gt;, (&lt;span&gt;3&lt;/span&gt;, &lt;span&gt;3&lt;/span&gt;&lt;span&gt;).ToTuple()));
            _model.Add(&lt;/span&gt;&lt;span&gt;new&lt;/span&gt;&lt;span&gt; Activation(Settings.ActivationFunction));
            _model.Add(&lt;/span&gt;&lt;span&gt;new&lt;/span&gt; MaxPooling2D(pool_size: (&lt;span&gt;2&lt;/span&gt;, &lt;span&gt;2&lt;/span&gt;&lt;span&gt;).ToTuple()));
            _model.Add(&lt;/span&gt;&lt;span&gt;new&lt;/span&gt; Dropout(&lt;span&gt;0.25&lt;/span&gt;&lt;span&gt;));

            _model.Add(&lt;/span&gt;&lt;span&gt;new&lt;/span&gt;&lt;span&gt; Flatten());
            _model.Add(&lt;/span&gt;&lt;span&gt;new&lt;/span&gt;&lt;span&gt; Dense(Settings.FullyConnectedNodes));
            _model.Add(&lt;/span&gt;&lt;span&gt;new&lt;/span&gt;&lt;span&gt; Activation(Settings.ActivationFunction));
            _model.Add(&lt;/span&gt;&lt;span&gt;new&lt;/span&gt; Dropout(&lt;span&gt;0.5&lt;/span&gt;&lt;span&gt;));
            _model.Add(&lt;/span&gt;&lt;span&gt;new&lt;/span&gt;&lt;span&gt; Dense(_dataset.NumberClasses));
            _model.Add(&lt;/span&gt;&lt;span&gt;new&lt;/span&gt;&lt;span&gt; Softmax());
            
            _model.Compile(loss: Settings.LossFunction,
              optimizer: Settings.Optimizer, 
              metrics: &lt;/span&gt;&lt;span&gt;new&lt;/span&gt; &lt;span&gt;string&lt;/span&gt;&lt;span&gt;[] { Settings.Accuracy });
            
            _model.Fit(_dataset.TrainX, _dataset.TrainY,
                          batch_size: Settings.BatchSize,
                          epochs: Settings.Epochs,
                          validation_data: &lt;/span&gt;&lt;span&gt;new&lt;/span&gt;&lt;span&gt; NDarray[] { _dataset.ValidationX, _dataset.ValidationY });

            &lt;/span&gt;&lt;span&gt;var&lt;/span&gt; score = _model.Evaluate(_dataset.ValidationX, _dataset.ValidationY, verbose: &lt;span&gt;0&lt;/span&gt;&lt;span&gt;);
            Console.WriteLine(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;Test loss:&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; + score[&lt;span&gt;0&lt;/span&gt;&lt;span&gt;]);
            Console.WriteLine(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;Test accuracy:&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; + score[&lt;span&gt;1&lt;/span&gt;&lt;span&gt;]);
        }

        &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; NDarray Predict(&lt;span&gt;string&lt;/span&gt;&lt;span&gt; imgPath)
        {
            NDarray x &lt;/span&gt;=&lt;span&gt; Utils.Normalize(imgPath);
            x &lt;/span&gt;= x.reshape(&lt;span&gt;1&lt;/span&gt;, x.shape[&lt;span&gt;0&lt;/span&gt;], x.shape[&lt;span&gt;1&lt;/span&gt;], x.shape[&lt;span&gt;2&lt;/span&gt;&lt;span&gt;]);
            &lt;/span&gt;&lt;span&gt;return&lt;/span&gt;&lt;span&gt; _model.Predict(x);
        }
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;如我们所见，我们首先有一个构造函数，用于接收数据集(在本系列的第二篇文章中导入和处理)，并创建Sequential类的新实例存储在私有变量_model中。Sequential是什么?这是一个空模型，它给了我们叠加层次的可能性，而这正是我们所需要的。&lt;/p&gt;
&lt;p&gt;然后，在Train方法中，我们首先按照上一篇文章中介绍的架构创建我们的层堆栈，然后编译模型并调用fit方法开始训练。使用的损失函数是categorical_crossentropy。什么是损失函数?它是我们用来优化学习过程的函数，也就是说，我们要么最小化它，要么最大化它。负责最小化损失函数的是优化器——一种通过改变网络的权重和学习率来最小化损失的算法。&lt;/p&gt;
&lt;p&gt;最后，利用验证数据集对模型进行评估。另一个方法是Predict，顾名思义，它预测新输入数据的标签。训练结束后，应调用此方法。开始训练阶段就像运行以下代码一样简单:&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;32&quot;&gt;
&lt;pre&gt;
&lt;span&gt;var&lt;/span&gt; cnn = &lt;span&gt;new&lt;/span&gt;&lt;span&gt; Cnn(dataSet);
cnn.Train();&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;让我们来看看在这个系列中我们正在经历的硬币识别问题的训练中所获得的结果:&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/2248030/202012/2248030-20201224082850731-180258357.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;我们可以看到，在训练过程中，我们能够达到100%的准确率。在prediction方法中，它的输出将是一个NDarray，它包含了物体或图像属于CNN某个类的概率。&lt;/p&gt;
&lt;p&gt;那么，什么样的架构需要GPU而不是CPU呢?例如，AlexNet体系结构包括5个卷积层和3个完全连接的层，以及池化和激活层。这种类型的深度CNN由于其复杂性，在GPU上表现得更好。一般的规则是，你添加的层越多，权重的计算就会越复杂。&lt;/p&gt;
&lt;p&gt;在了解了如何编写自己的CNN之后，我们将进入预训练模型的领域。下一篇文章将详细介绍这一点!&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;欢迎关注我的公众号，如果你有喜欢的外文技术文章，可以通过公众号留言推荐给我。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/2248030/202012/2248030-20201224082903965-1422171829.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;原文链接:https://www.codeproject.com/Articles/5284228/Deep-Learning-in-Csharp-Coin-Recognition-in-Keras&lt;/p&gt;

</description>
<pubDate>Thu, 24 Dec 2020 00:30:00 +0000</pubDate>
<dc:creator>码农译站</dc:creator>
<og:description>在本文中，我们将研究一个卷积神经网络来解决硬币识别问题，并且我们将在Keras.NET中实现一个卷积神经网络。 在这里，我们将介绍卷积神经网络(CNN)，并提出一个CNN的架构，我们将训练它来识别硬币</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/hhhnicvscs/p/14182453.html</dc:identifier>
</item>
<item>
<title>Spring Cloud 2020.0.0正式发布，再见了Netflix - YourBatman</title>
<link>http://www.cnblogs.com/yourbatman/p/14182433.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/yourbatman/p/14182433.html</guid>
<description>&lt;p&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20201223221110542.png#pic_center&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;blockquote readability=&quot;6.2222222222222&quot;&gt;
&lt;p&gt;分享、成长，拒绝浅藏辄止。关注公众号【&lt;strong&gt;BAT的乌托邦&lt;/strong&gt;】，回复关键字&lt;code&gt;专栏&lt;/code&gt;有Spring技术栈、中间件等小而美的&lt;strong&gt;原创专栏&lt;/strong&gt;供以免费学习。本文已被 &lt;a href=&quot;https://www.yourbatman.cn&quot; target=&quot;_blank&quot;&gt;https://www.yourbatman.cn&lt;/a&gt; 收录。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;你好，我是YourBatman。&lt;/p&gt;
&lt;p&gt;北京时间2020-12-22深夜，&lt;code&gt;Spring Cloud 2020.0.0&lt;/code&gt;版本正式发布。2020.0.0是第一个使用新版本方案的Spring Cloud发行版本。&lt;/p&gt;
&lt;p&gt;关于版本号这里啰嗦几句：在这之前，Spring Cloud的Release Train名称采用的是伦敦地铁站命名方式，如：Hoxton、Greenwich等。&lt;/p&gt;
&lt;blockquote readability=&quot;7&quot;&gt;
&lt;p&gt;说明：2020.0.0版本又名&lt;code&gt;Ilford&lt;/code&gt;（地铁站名），因为此项目3月后才按照新规更名，估计是为了团队内沟通方便吧，你也可以理解为它仅是一个内部代号而已，方便沟通&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;虽按照字母表顺序排列，但仍存在两个致命问题：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;对非英语&lt;strong&gt;母语&lt;/strong&gt;国家（比如天朝）非常不友好，无法快速理清版本号关系&lt;/li&gt;
&lt;li&gt;A-Z，倘若版本号到Z了呢？如何继续发展？你品，你细品&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20201223185627672.png#pic_center&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;Spring团队意识到了这的确是个问题，因此在今年3月份作出了&lt;strong&gt;改变&lt;/strong&gt;。详情参考我前面写的一篇文章（&lt;strong&gt;强烈建议&lt;/strong&gt;每个进来的你都了解下这次规则变更）：&lt;a href=&quot;https://mp.weixin.qq.com/s/ZoUG9h1TndW2QpnPyGeIQA&quot; target=&quot;_blank&quot;&gt;Spring改变版本号命名规则：此举对非英语国家很友好&lt;/a&gt;&lt;/p&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;说明：版本号规则变更适用于所有Spring技术栈，包含Spring Framework、Spring Boot、Spring Cloud、Spring Data...&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;文归正传。Spring Cloud早在年初就启动了该版本的研发工作，并在今年4月份就已经发布了其2020.0.0-M1版本（第一个里程碑版本），直到离2020年结束不到10天了才“憋出”大招，正式RELEASE。&lt;/p&gt;
&lt;p&gt;Spring Cloud作为构建在Spring Boot之上的云计算框架，我觉得本次难产的原因主要有二：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;Spring Boot 2.4.0版本2020-11-12才正式RELEASE（Spirng Framework 5.3.0版本2020-10-27才RELEASE）
&lt;ol&gt;&lt;li&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s/Sw6EqAY0DmF-p2qPoaetUg&quot; target=&quot;_blank&quot;&gt;Spring Framework 5.3.0正式发布，在云原生路上继续发力&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s/KywpJkLDHZbZTxUf4WFxhw&quot; target=&quot;_blank&quot;&gt;Spring Boot 2.4.0正式发布，全新的配置文件加载机制（不向下兼容）&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;li&gt;改动确实太大，研发、测试、文档编写工作量都是巨大的&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;从Spring Framework、Spring Boot、Spring Cloud三者的发版线路图再一次验证了我的那句话：&lt;strong&gt;你对Spring Cloud多了解源自于你对Spring Boot有多了解，你对Spring Boot多了解源自于你对Spring Framework有多了解&lt;/strong&gt;。这就是为何我文章花大量笔墨在Spring Framework上而非Spring Boot上的根本原因，底层通透了，上层运用自如。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20201223213749175.png#pic_center&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h2 id=&quot;版本约定&quot;&gt;版本约定&lt;/h2&gt;
&lt;ul&gt;&lt;li&gt;Spring Framework：5.3.2&lt;/li&gt;
&lt;li&gt;Spring Boot：2.4.1&lt;/li&gt;
&lt;li&gt;Spring Cloud：2020.0.0
&lt;ul&gt;&lt;li&gt;以上版本为SC“携带”的版本&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/2020122406543886.png#pic_center&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;

&lt;p&gt;有个有趣的现象，截止稿前（2020-12-23 22:00:00）&lt;strong&gt;官网&lt;/strong&gt;还并未同步标注好当前最新版本为2020.0.0版（如图）：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20201223214028434.png#pic_center&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;其实早在24h之前官方博客就做出了发版宣告：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20201223214714540.png#pic_center&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;并且Maven中央仓库也已存在最新Jar包（证明你正常引包、使用是没问题的了）：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/2020122321485778.png#pic_center&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;其实，文档层面不止官网这一处没有sync最新版本，我就不一一例举，毕竟不太重要。针对此现象我yy一下，是不是Spring Cloud团队缺人人手不够用呢？请问社招吗？O(∩_∩)O哈哈~&lt;/p&gt;
&lt;h2 id=&quot;spring-cloud版本管理&quot;&gt;Spring Cloud版本管理&lt;/h2&gt;
&lt;p&gt;版本管理对于软件开发来说太重要，在Spring Boot出现之前依赖关系、版本管理让人着实头大（即使有Spring BOM存在），特别是当出现版本&lt;strong&gt;不适配&lt;/strong&gt;时很容易就偷走你一下午甚至一整天的时间。&lt;/p&gt;
&lt;p&gt;Spring Cloud作为上层应用框架，底层版本匹配了才能正常work，其中最主要就是和Spring Boot的版本号要对齐。&lt;/p&gt;
&lt;h3 id=&quot;与spring-boot版本对应关系&quot;&gt;与Spring Boot版本对应关系&lt;/h3&gt;
&lt;p&gt;Spring Boot的出现和流行大大缓解了上述些情况，但使用起Spring Cloud时它和Spring Boot的版本对应关系依旧是需要&lt;strong&gt;特别关注&lt;/strong&gt;的。为此我帮你总结出了这个表格：&lt;/p&gt;
&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;Release Train&lt;/th&gt;
&lt;th&gt;发布时间&lt;/th&gt;
&lt;th&gt;Spring Boot版本&lt;/th&gt;
&lt;th&gt;SC Commons版本&lt;/th&gt;
&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;2020.0.x&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;2020-12&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;2.4.x&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;3.0.0&lt;/strong&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Hoxton&lt;/td&gt;
&lt;td&gt;2019-07&lt;/td&gt;
&lt;td&gt;2.2.x, 2.3.x (从SR5起)&lt;/td&gt;
&lt;td&gt;2.2.x&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Greenwich&lt;/td&gt;
&lt;td&gt;2018-11&lt;/td&gt;
&lt;td&gt;2.1.x&lt;/td&gt;
&lt;td&gt;2.1.x&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Finchley&lt;/td&gt;
&lt;td&gt;2017-10&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;2.0.x&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;2.0.x&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Edgware&lt;/td&gt;
&lt;td&gt;2017-08&lt;/td&gt;
&lt;td&gt;1.5.x&lt;/td&gt;
&lt;td&gt;1.3.x&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Dalston&lt;/td&gt;
&lt;td&gt;2017-05&lt;/td&gt;
&lt;td&gt;1.5.x&lt;/td&gt;
&lt;td&gt;1.2.x&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Brixton&lt;/td&gt;
&lt;td&gt;2016-09&lt;/td&gt;
&lt;td&gt;1.3.x&lt;/td&gt;
&lt;td&gt;1.1.x&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Angel&lt;/td&gt;
&lt;td&gt;2016-05&lt;/td&gt;
&lt;td&gt;1.2.x&lt;/td&gt;
&lt;td&gt;1.0.x&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;说明：对于Spring Cloud内部组件、Spring Boot、Spirng Framework、Security等这个庞大体系的版本对照关系，文章已整理好，下篇发出，请记得搜藏哦&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;特别提醒：&lt;code&gt;spring-cloud-starter-loadbalancer&lt;/code&gt;是伴随着Spring Cloud Commons 2.2.0版本才开始商用的（Hoxton版本），这个版本节点请稍微关注下，因为它替代了Ribbon。&lt;/p&gt;
&lt;h3 id=&quot;当前支持的版本&quot;&gt;当前支持的版本&lt;/h3&gt;
&lt;p&gt;Spring Cloud遵循&lt;strong&gt;Pivotal OSS support policy&lt;/strong&gt; 协议对&lt;strong&gt;主要版本&lt;/strong&gt;提供3年的支持。此外，在Spring Cloud的主要或次要版本发布后，若存在严重的bug和安全问题，就会再维护一段时间（6-12个月不等）。&lt;/p&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;特别注意：这里指的&lt;strong&gt;主要版本&lt;/strong&gt;才是3年，主要版本可不常有的哦&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;现在2020.0.0版本已发布，又到了淘汰的时候。现在Spring Cloud官方还会支持的版本有：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;2020.0版本&lt;/strong&gt;：（支持Spring Boot 2.4.x）它是&lt;strong&gt;主要版本&lt;/strong&gt;，按计划会支持到2023年12月份
&lt;ul&gt;&lt;li&gt;它是自Finchley后的又一主要版本&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Hoxton版本&lt;/strong&gt;：（支持Spring Boot 2.2.x和2.3.x）作为Finchley发行系列的一个次要版本，它的常规维护将持续到2021年6月底。从2020-07开始进入到特殊维护期（不加新功能，只改紧急bug），2021-12月底就只会发布重大错误/安全补丁了&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Greenwich版本&lt;/strong&gt;：（支持Spring Boot 2.1.x）2020-01就停止维护了，2020-12-31号也将终结它的特殊维护期&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Finchley版本&lt;/strong&gt;：（支持Spring Boot 2.0.x）它是一个&lt;strong&gt;主要版本&lt;/strong&gt;的开始，2018年发布&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;更老版本&lt;/strong&gt;：嗯，忘了吧&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20201223233224440.png#pic_center&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;Spring官方&lt;strong&gt;建议&lt;/strong&gt;：尽量使用最新版本。不过建议归建议，作为只使用&lt;strong&gt;晚期大众&lt;/strong&gt;技术的我们，坐在第二排甚至第三排看戏才有安全感。但历史的巨浪总归会把前排淘汰，因此早点做足准备总是好的，不至于时至被推至前排时只能&lt;strong&gt;裸泳&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;Spring Cloud 2020.0作为一个&lt;strong&gt;主要版本&lt;/strong&gt;，带来了众多显著的变化，其中进行了一些阻断式更新（不向下兼容）是本文最大看点，来吧上菜。&lt;/p&gt;
&lt;h2 id=&quot;阻断式升级（不向下兼容）&quot;&gt;阻断式升级（不向下兼容）&lt;/h2&gt;
&lt;p&gt;差不多在去年（2019年）的这个时候，Spring Cloud在其Roadmap（之前文章有介绍过）里就宣布将要&lt;strong&gt;终结&lt;/strong&gt;的一些库/版本，其中最重要的就是指&lt;strong&gt;Spring Cloud Netflix项目进入维护模式&lt;/strong&gt;，然后计划在2020年完全移除。&lt;/p&gt;
&lt;p&gt;Spring Cloud做出这样的决定其实也是“被迫的”。我们知道Spring Cloud一直以来把&lt;code&gt;Netflix OSS&lt;/code&gt;套件作为其官方默认的一站式解决方案，那时的Netflix OSS套件恨不得可以跟Spring Cloud划等号。奈何呀，Netflix公司在2018年前后宣布其核心组件Hystrix、Ribbon、Zuul、Archaius等均进入&lt;strong&gt;维护状态&lt;/strong&gt;。&lt;/p&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;虽然有Zuul 2.x，Archaius 2.x，但它们均不能向下兼容，无法平滑升级，因此几乎等于无法使用&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;从2018年至今处于维护状态的模块有（包括其对应的starter，此处并未列出）：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;spring-cloud-netflix-archaius&lt;/li&gt;
&lt;li&gt;spring-cloud-netflix-hystrix-contract&lt;/li&gt;
&lt;li&gt;spring-cloud-netflix-hystrix-dashboard&lt;/li&gt;
&lt;li&gt;spring-cloud-netflix-hystrix-stream&lt;/li&gt;
&lt;li&gt;spring-cloud-netflix-hystrix&lt;/li&gt;
&lt;li&gt;spring-cloud-netflix-ribbon&lt;/li&gt;
&lt;li&gt;spring-cloud-netflix-turbine-stream&lt;/li&gt;
&lt;li&gt;spring-cloud-netflix-turbine&lt;/li&gt;
&lt;li&gt;spring-cloud-netflix-zuul&lt;/li&gt;
&lt;/ol&gt;&lt;h3 id=&quot;1、再见了，netflix&quot;&gt;1、再见了，Netflix&lt;/h3&gt;
&lt;p&gt;时至今日，Spring Cloud 2020.0正式发布，在这个主要版本里，按既定计划终于对&lt;code&gt;spring-cloud-netflix&lt;/code&gt;动刀了。我帮你画了幅&lt;code&gt;spring-cloud-netflix-dependencies&lt;/code&gt;的xml文件前后版本主要差异的对比图，一目了然：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/2020122400165972.png#pic_center&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;code&gt;spring-cloud-netflix-dependencies&lt;/code&gt;没有消失哦，它依旧存在，版本号跟随大部队升级为3.0.x版本&lt;/li&gt;
&lt;li&gt;旧版本的&lt;code&gt;spring-cloud-netflix-dependencies&lt;/code&gt;管理着Netflix所有组件，包括Hystrix、Ribbon、Zuul、Eureka等。而自2020.0版本起，&lt;strong&gt;它有且只管理Eureka（包括Server和Client）&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;解释说明：Feign虽然最初属Netflix公司，但从9.x版本开始就移交给OpenFeign组织管理了，因此不再划入Netflix管辖范畴&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;简单一句话概括：Spring Cloud 2020.0.0版本&lt;strong&gt;彻底删除&lt;/strong&gt;掉了Netflix除Eureka外的&lt;strong&gt;所有&lt;/strong&gt;组件。至此，我们怀着感恩的心可以对Netflix OSS套件道一声谢谢，并可以对它说再见了。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20201224000042869.png#pic_center&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;说明：Netflix的Eureka项目仍旧是活跃状态，这个注册中心设计上还是蛮优秀的，综合表现尚可，市场上竞争力依旧可圈可点，因此Spring Cloud暂还未放弃它&lt;/p&gt;
&lt;/blockquote&gt;
&lt;pre&gt;
&lt;code class=&quot;language-xml&quot;&gt;&amp;lt;dependency&amp;gt;
    &amp;lt;groupId&amp;gt;org.springframework.cloud&amp;lt;/groupId&amp;gt;
    &amp;lt;artifactId&amp;gt;spring-cloud-starter-netflix-eureka-client&amp;lt;/artifactId&amp;gt;
&amp;lt;/dependency&amp;gt;
&lt;/code&gt;
&lt;/pre&gt;
&lt;h4 id=&quot;netflix组件替代方案&quot;&gt;Netflix组件替代方案&lt;/h4&gt;
&lt;p&gt;Spring Cloud既然把Netflix OSS套件大刀阔斧的砍掉了，那总归得有替代方案吧。那是必然的，Spring Cloud团队给我们推荐了用于替代的产品：&lt;/p&gt;
&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;Netflix&lt;/th&gt;
&lt;th&gt;推荐替代品&lt;/th&gt;
&lt;th&gt;说明&lt;/th&gt;
&lt;/tr&gt;&lt;/thead&gt;&lt;tbody readability=&quot;9&quot;&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;Hystrix&lt;/td&gt;
&lt;td&gt;Resilience4j&lt;/td&gt;
&lt;td&gt;Hystrix自己也推荐你使用它代替自己&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;6&quot;&gt;&lt;td&gt;Hystrix Dashboard / Turbine&lt;/td&gt;
&lt;td&gt;Micrometer + Monitoring System&lt;/td&gt;
&lt;td&gt;说白了，监控这件事交给更专业的组件去做&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;4&quot;&gt;&lt;td&gt;Ribbon&lt;/td&gt;
&lt;td&gt;Spring Cloud Loadbalancer&lt;/td&gt;
&lt;td&gt;忍不住了，Spring终究亲自出手&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;Zuul 1&lt;/td&gt;
&lt;td&gt;Spring Cloud Gateway&lt;/td&gt;
&lt;td&gt;忍不住了，Spring终究亲自出手&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;4&quot;&gt;&lt;td&gt;Archaius 1&lt;/td&gt;
&lt;td&gt;Spring Boot外部化配置 + Spring Cloud配置&lt;/td&gt;
&lt;td&gt;比Netflix实现的更好、更强大&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;h5 id=&quot;spring-cloud-loadbalancer是什么？&quot;&gt;Spring Cloud LoadBalancer是什么？&lt;/h5&gt;
&lt;p&gt;以上替代品中，你可能最陌生、最好奇的是&lt;code&gt;Spring Cloud Loadbalancer&lt;/code&gt;，它一度只是Spring Cloud &lt;strong&gt;孵化器&lt;/strong&gt;里的一个小项目，并且一度搁浅。后再经过重启，发展，现行使其伟大使命，正式用于&lt;strong&gt;完全替换&lt;/strong&gt; Ribbon，成为Spring Cloud负载均衡器&lt;strong&gt;唯一实现&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;值得注意的是：Spring Cloud LoadBalancer首次引入是在Spring Cloud Commons 2.2.0时，也就是Hoxton发布时就引入了，只不过那会还只是备胎/备选，默认依旧是Ribbon挑大梁。下截图是在Hoxton版本的情况：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20201224004316321.png#pic_center&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;如图，负载均衡抽象&lt;code&gt;LoadBalancerClient&lt;/code&gt;接口有两个实现，而到了Spring Cloud 2020.0版本后，&lt;code&gt;BlockingLoadBalancerClient&lt;/code&gt;就是唯一实现了。&lt;/p&gt;
&lt;blockquote readability=&quot;2.5277777777778&quot;&gt;
&lt;p&gt;关于spring-cloud-loadbalancer负载均衡器的使用，官方有个极其建议教程：&lt;a href=&quot;https://spring.io/guides/gs/spring-cloud-loadbalancer%E3%80%82%E6%9C%89%E5%85%B4%E8%B6%A3%E5%8F%AF%E8%87%AA%E5%B7%B1%E7%8E%A9%E7%8E%A9%EF%BC%8C%E8%8B%A5%E6%B2%A1%E5%85%B4%E8%B6%A3%EF%BC%8C%E9%82%A3%E5%B0%B1%E5%85%B3%E6%B3%A8%E6%88%91%E5%90%8E%E9%9D%A2%E6%96%87%E7%AB%A0%E5%88%86%E6%9E%90%E5%90%A7%EF%BC%8C%E6%88%91%E4%BC%9A%E4%B8%93%E7%A8%8B%E4%BB%8B%E7%BB%8D%E5%AE%83%E7%9A%84&quot; target=&quot;_blank&quot;&gt;https://spring.io/guides/gs/spring-cloud-loadbalancer。有兴趣可自己玩玩，若没兴趣，那就关注我后面文章分析吧，我会专程介绍它的&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4 id=&quot;spring-cloud-alibaba是否可作为替代方案？&quot;&gt;Spring Cloud Alibaba是否可作为替代方案？&lt;/h4&gt;
&lt;p&gt;嗯，也可以。&lt;/p&gt;
&lt;p&gt;不过它目前来说并不是Spring Cloud官方的推荐的默认方案。期待国人一起努力，能早日送Spring Cloud Alibaba上去，让歪果仁用上咱天朝的框架，提issue必须用中文O(∩_∩)O哈哈~。&lt;/p&gt;
&lt;h4 id=&quot;显示导入netflix包还能否正常work？&quot;&gt;显示导入Netflix包还能否正常work？&lt;/h4&gt;
&lt;p&gt;既想升级到最新版本的Spring Cloud，又想保持向下兼容使用Netflix的技术。虽说spring-cloud-netflix-dependencies里不再包含netflix的核心组件，那我手动导包并指定版本号行不行？能否正常work呢？&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;答&lt;/strong&gt;：我拍脑袋就给你个答案，&lt;strong&gt;不行&lt;/strong&gt;。既然我没论证过，但这么使用太畸形了，此方案应被枪毙在萌芽中，不应该有。&lt;/p&gt;
&lt;p&gt;另外，从此事也告诉我们：使用Spring Cloud时尽量面向它的&lt;strong&gt;抽象&lt;/strong&gt;编程，这样即使Spirng Cloud换底层组件（如换熔断器、负载均衡器）等等，理论上对我们业务是无影响或者影响很小的，这都得益于它的Spring Cloud Commons抽象，那里是精华。&lt;/p&gt;
&lt;h3 id=&quot;2、bootstrap上下文默认不再启动&quot;&gt;2、Bootstrap上下文默认不再启动&lt;/h3&gt;
&lt;p&gt;知晓原理的同学知道，Spring Cloud容器是靠&lt;code&gt;Bootstrap Context&lt;/code&gt;引导上下文来启动的，对应的类是&lt;code&gt;BootstrapApplicationListener&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;这在2020.0版本发生了改变，&lt;strong&gt;新版本的Spring Cloud不再依赖于此上下文而启动&lt;/strong&gt;。因此默认情况下，将不再启动Bootstrap上下文。代码层面的改变发生在这里：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;BootstrapApplicationListener：

        @Override
        public void onApplicationEvent(ApplicationEnvironmentPreparedEvent event) {
                ConfigurableEnvironment environment = event.getEnvironment();
                // 在方法开头加了这麽个判断
                if (!bootstrapEnabled(environment) &amp;amp;&amp;amp; !useLegacyProcessing(environment)) {
                        return;
                }
                ...
        }

PropertyUtils：

        // BOOTSTRAP_ENABLED_PROPERTY = spring.cloud.bootstrap.enabled
        public static boolean bootstrapEnabled(Environment environment) {
                return environment.getProperty(BOOTSTRAP_ENABLED_PROPERTY, Boolean.class, false) || MARKER_CLASS_EXISTS;
        }
        // USE_LEGACY_PROCESSING_PROPERTY = spring.config.use-legacy-processing
        public static boolean useLegacyProcessing(Environment environment) {
                return environment.getProperty(USE_LEGACY_PROCESSING_PROPERTY, Boolean.class, false);
        }
&lt;/code&gt;
&lt;/pre&gt;
&lt;h4 id=&quot;开启方式&quot;&gt;开启方式&lt;/h4&gt;
&lt;p&gt;若你需要开启Bootstrap上下文，有两种办法可以实现：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;设置值&lt;code&gt;spring.cloud.bootstrap.enabled=true&lt;/code&gt;或者 &lt;code&gt;spring.config.use-legacy-processing=true&lt;/code&gt;即可。注意：这些个属性值必须确保其能放进环境里才能生效。比如靠谱的方式是：系统属性、环境变量、命令行等&lt;/li&gt;
&lt;li&gt;引入一个Jar：&lt;code&gt;org.springframework.cloud:spring-cloud-starter-bootstrap&lt;/code&gt;，然后什么都不用做了
&lt;ol&gt;&lt;li&gt;说明：这个jar里面有且仅有一个&lt;code&gt;Marker&lt;/code&gt;类，作用你懂的，此处不做过多解释&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;说明：手动开启Bootstrap上下文，证明你fallback到老的方式去加载SC，那么一切请按照老方式做即可&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&quot;3、全新的配置方式&quot;&gt;3、全新的配置方式&lt;/h3&gt;
&lt;p&gt;得益于Spring Boot 2.4.x支持全新的配置文件书写方式，自此可以使用&lt;code&gt;spring.config.import&lt;/code&gt;俩导入其它组建的配置。如：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;spring.config.import=configserver:xxx&lt;/li&gt;
&lt;li&gt;spring.config.import=zookeeper:&lt;/li&gt;
&lt;li&gt;...&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;这么做更具模块化，更符合云原生环境的要求。&lt;/p&gt;
&lt;h3 id=&quot;4、其它&quot;&gt;4、其它&lt;/h3&gt;
&lt;ul&gt;&lt;li&gt;之前若要禁用Spring Cloud Config Client端的健康指示用的是&lt;code&gt;health.config.enabled=false&lt;/code&gt;，现改为&lt;code&gt;management.health.config.enabled=false&lt;/code&gt;。保持了和Spring Boot控制端点风格一致&lt;/li&gt;
&lt;li&gt;带有无效字符(破折号)的端点id已经改为符合标准的了，自此启动时再也没有讨厌的警告了，拯救洁癖者。
&lt;ul&gt;&lt;li&gt;bus-env -&amp;gt; busenv&lt;/li&gt;
&lt;li&gt;bus-refresh -&amp;gt; busrefresh&lt;/li&gt;
&lt;li&gt;service-registry -&amp;gt; serviceregistry&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;// old
@Endpoint(id = &quot;service-registry&quot;)
public class ServiceRegistryEndpoint { ... }

// new
@Endpoint(id = &quot;serviceregistry&quot;)
public class ServiceRegistryEndpoint { ... }
&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;常规式升级&quot;&gt;常规式升级&lt;/h2&gt;
&lt;p&gt;常规升级这块关注点就没那么多了，主要对其组件如&lt;code&gt;Spring Cloud Commons、Spring Cloud Kubernetes、Spring Cloud Openfeign...&lt;/code&gt;等做些常规升级，乏善可陈。&lt;/p&gt;
&lt;p&gt;值得关注的一点：Spirng Cloud所有的Module版本号均升级到了&lt;code&gt;3.0.0&lt;/code&gt;（大版本号的升级），除Spring Cloud Circuitbreaker/Spring Cloud Kubernetes（2.0.0）和Spring Cloud Task（2.3.0）之外。&lt;/p&gt;
&lt;h2 id=&quot;仍旧存在的问题&quot;&gt;仍旧存在的问题&lt;/h2&gt;
&lt;p&gt;虽然2020.0已经RELEASE了，但是仍存在着未解决的问题，例举几个此版本&lt;strong&gt;现存&lt;/strong&gt;的问题：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;若使用&lt;code&gt;spring.config.import=configserver:&lt;/code&gt;来配置配置中心，此版本漏掉了支持retry参数
&lt;ul&gt;&lt;li&gt;解决方案：若你要使用的话，你只得fallback到传统方式喽（写在bootstrap.yaml里）&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;spring-cloud-config-dependencies&lt;/code&gt;里出现了一个非release版本的jar（具体看下截图）
&lt;ul&gt;&lt;li&gt;解决方案：手动指定该jar的版本号&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20201224012523158.png#pic_center&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;说明：M1属于里程碑版本，还属于较为早起阶段，可能存在bug，建议你使用时手动指定版本号替换掉这个jar&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;看来即使强如Spring团队，也会出现各种各样的纰漏呀。这么一想的话，我又敢放心大胆的回去写bug去喽。&lt;/p&gt;

&lt;p&gt;Spring Cloud 2020.0.0是Spring Cloud的&lt;strong&gt;主要版本&lt;/strong&gt;，是非常重要的存在，升级、改变也是巨大的。特别体现在Netflix模块的全部移除、Spring Cloud启动方式变了等等。伴随着Spring Boot 2.4.x以及Spirng Cloud 2020.0的发布，并且弃用Netflix OSS套件后，必将走入一个新的&lt;strong&gt;深度编程&lt;/strong&gt;体验，满怀惊喜，很是期待。&lt;/p&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;说明：因为此版本完全摈弃掉了Netflix的一套东西，为了跟上时代，我会使用一段时间后，尽快写出最新版本的系列教程，助你少踩坑&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;文末有提到2020.0版本虽已发布，但仍旧存在些问题。不过话说回来，那些都属于很小的问题，可能在下个小版本里就得到修复。但尴尬的是，距离2020年结束只有不到10天了，倘若进入到了2021年，按照版本号命名新规，彼时发出的版本将不能再叫2020.x.x而只能是2021.x.x，显然这就属于大版本号的迭代了，需要谨慎啊。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;你觉得Spring Cloud团队在2020年还会发版吗？欢迎在评论区留下你的看法。&lt;/strong&gt;&lt;/p&gt;
&lt;hr/&gt;&lt;h3 id=&quot;推荐阅读&quot;&gt;✔✔✔推荐阅读✔✔✔&lt;/h3&gt;
&lt;p&gt;【Spring类型转换】系列：&lt;/p&gt;
&lt;p&gt;【Jackson】系列：&lt;/p&gt;
&lt;p&gt;【数据校验Bean Validation】系列：&lt;/p&gt;
&lt;p&gt;【新特性】系列：&lt;/p&gt;
&lt;p&gt;【程序人生】系列：&lt;/p&gt;
&lt;p&gt;还有诸如【Spring配置类】【Spring-static】【Spring数据绑定】【Spring Cloud Netflix】【Feign】【Ribbon】【Hystrix】...更多原创专栏，关注&lt;code&gt;BAT的乌托邦&lt;/code&gt;回复&lt;code&gt;专栏&lt;/code&gt;二字即可全部获取，也可加我&lt;code&gt;fsx1056342982&lt;/code&gt;，交个朋友。&lt;/p&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;有些&lt;strong&gt;已完结&lt;/strong&gt;，有些&lt;strong&gt;连载中&lt;/strong&gt;。我是A哥(YourBatman)，咱们下期见&lt;/p&gt;
&lt;/blockquote&gt;
</description>
<pubDate>Thu, 24 Dec 2020 00:12:00 +0000</pubDate>
<dc:creator>YourBatman</dc:creator>
<og:description>再见了Netflix，你好Spring Cloud</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/yourbatman/p/14182433.html</dc:identifier>
</item>
<item>
<title>5分钟教你在Linux下安装VMware - JasonCeng</title>
<link>http://www.cnblogs.com/JasonCeng/p/14182395.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/JasonCeng/p/14182395.html</guid>
<description>&lt;p&gt;如果我们只有一台笔记本，又想要搭建一个小集群，怎么办？虚拟机帮你实现梦想，市面上较为常用的虚拟机软件有VMware、VirtualBox、Xen、KVM、hyper-v等，本文主要介绍如何在Linux下安装VMware，以为后续开启多个虚拟机，搭建小集群做准备。&lt;/p&gt;&lt;div id=&quot;cnblogs_post_body&quot; readability=&quot;71.549387755102&quot;&gt;
&lt;p&gt;如果我们只有一台笔记本，又想要搭建一个小集群，怎么办？虚拟机帮你实现梦想，市面上较为常用的虚拟机软件有VMware、VirtualBox、Xen、KVM、hyper-v等，本文主要介绍如何在Linux下安装VMware，以为后续开启多个虚拟机，搭建小集群做准备。&lt;/p&gt;
&lt;h2 id=&quot;1、下载vmware安装包&quot;&gt;1、下载VMware安装包&lt;/h2&gt;
&lt;p&gt;下载地址：&lt;a href=&quot;https://my.vmware.com/group/vmware/downloads/info/slug/desktop_end_user_computing/vmware_workstation_pro/16_0&quot; target=&quot;_blank&quot;&gt;https://my.vmware.com/group/vmware/downloads/info/slug/desktop_end_user_computing/vmware_workstation_pro/16_0&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;下载linux版本：VMware Workstation Pro 16.1.0 for Linux&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1001136/202012/1001136-20201224064932911-1684232288.png&quot; alt=&quot;1&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h2 id=&quot;2、目录规划&quot;&gt;2、目录规划&lt;/h2&gt;
&lt;p&gt;我创建了&lt;code&gt;/download/vmware&lt;/code&gt;用于存放vmware安装包&lt;/p&gt;
&lt;p&gt;进入下载目录：&lt;code&gt;cd /Downloads&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;将vmware安装包复制到我自建的目录下：&lt;code&gt;sudo cp VMware-Workstation-Full-16.1.0-17198959.x86_64.bundle /download/vmware&lt;/code&gt;&lt;/p&gt;
&lt;h2 id=&quot;3、安装&quot;&gt;3、安装&lt;/h2&gt;
&lt;p&gt;赋予执行权限：&lt;code&gt;sudo chmod +x VMware-Workstation-Full-16.1.0-17198959.x86_64.bundle&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;运行vmware安装包：&lt;code&gt;sudo ./VMware-Workstation-Full-16.1.0-17198959.x86_64.bundle&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;进入图形化界面，选择默认选型即可&lt;/p&gt;
&lt;p&gt;安装完毕后进入虚拟机，接下来你便可以开始使用VMware搭建你的小集群了！&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1001136/202012/1001136-20201224065109764-1411848879.png&quot; alt=&quot;2&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h2 id=&quot;参考资料&quot;&gt;参考资料&lt;/h2&gt;
&lt;p&gt;[1]如何在linux上安装虚拟机[&lt;a href=&quot;https://zhuanlan.zhihu.com/p/107102515&quot; target=&quot;_blank&quot;&gt;https://zhuanlan.zhihu.com/p/107102515&lt;/a&gt;]&lt;br/&gt;[2]VMware官网[&lt;a href=&quot;https://my.vmware.com/&quot; target=&quot;_blank&quot;&gt;https://my.vmware.com/&lt;/a&gt;]&lt;/p&gt;
&lt;/div&gt;</description>
<pubDate>Wed, 23 Dec 2020 22:52:00 +0000</pubDate>
<dc:creator>JasonCeng</dc:creator>
<og:description>如果我们只有一台笔记本，又想要搭建一个小集群，怎么办？虚拟机帮你实现梦想，市面上较为常用的虚拟机软件有VMware、VirtualBox、Xen、KVM、hyper-v等，本文主要介绍如何在Linux</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/JasonCeng/p/14182395.html</dc:identifier>
</item>
<item>
<title>容器编排系统K8s之Volume的基础使用 - Linux-1874</title>
<link>http://www.cnblogs.com/qiuhom-1874/p/14180752.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/qiuhom-1874/p/14180752.html</guid>
<description>&lt;p&gt;　　前文我们聊到了k8s上的ingress资源相关话题，回顾请参考：&lt;a href=&quot;https://www.cnblogs.com/qiuhom-1874/p/14167581.html&quot; target=&quot;_blank&quot;&gt;https://www.cnblogs.com/qiuhom-1874/p/14167581.html&lt;/a&gt;；今天们来聊一下k8s上volume相关话题；&lt;/p&gt;
&lt;p&gt; 　　在说k8s上的volume的使用前，我们先来回顾下docker里的volume；对于docker容器来说，镜像是分成构建的且每一层都是只读的，只读就意味着不能修改数据；只有当一个镜像运行为容器以后，在镜像的最顶端才会加上一个可写层，一旦这个容器被删除，对应可写层上的数据也随之被删除；为了解决docker容器上的数据持久化的问题；docker使用了volume；在docker上volume有两种管理方式，第一种是用户手动指定把宿主机（对于宿主机上的目录可能是挂载存储系统上的某目录）上的某个目录挂载到容器某个目录，这种管理方式叫做绑定挂载卷；还有一种就是docker自身维护把某个目录挂载到容器某个目录，这种叫docker自己管理的卷；不管使用那种方式管理的volume，它都是容器直接关联宿主机上的某个目录或文件；docker中的volume解决了容器生命周期内产生的数据在容器终止后能够持久化保存的问题；同样k8s也有同样的烦恼，不同的是k8s面对的是pod；我们知道pod是k8s上最小调度单元，一个pod被删除以后，pod里运行的容器也随之被删除，那么pod里容器产生的数据该如何被持久化呢？要想解决这个问题，我们先来看看pod的组成；&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1503305/202012/1503305-20201223205040924-228713033.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　提示：在k8s上pod里可以运行一个或多个容器，运行多个容器，其中一个容器我们叫主容器，其他的容器是用来辅助主容器，我们叫做sidecar；对于pod来说，不管里面运行多少个容器，在最底层都会运行一个pause容器，该容器最主要用来为pod提供基础架构支撑；并且位于同一个pod中的容器都共享pause容器的网络名称空间以及IPC和UTS；这样一来我们要想给pod里的容器提供存储卷，首先要把存储卷关联到pause容器，然后在容器里挂载pause里的存储卷即可；如下图所示&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1503305/202012/1503305-20201223223729775-1171257769.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　提示：如上图所示，对于pause容器来说它可以关联存储A，也可以关联存储B；对于pause关联某个存储，其位于同一pod中的其他容器就也可以挂载pause里关联的存储目录或文件；对于k8s来说存储本来就不属于k8s内部组件，它是一个外来系统，这也意味着我们要想k8s使用外部存储系统，首先pause容器要有适配其对应存储系统的驱动；我们知道同一宿主机上运行的多个容器都是共享同一内核，即宿主机内核上有某个存储系统的驱动，那么pause就可以使用对应的驱动去适配对应的存储；&lt;/p&gt;
&lt;p&gt;　　volumes类型&lt;/p&gt;
&lt;p&gt;　　我们知道要想在k8s上使用存储卷，我们需要在对应的节点上提供对应存储系统的驱动，对应运行在该节点上的所有pod就可以使用对应的存储系统，那么问题来了，pod怎么使用对应的存储系统呢？该怎么向其驱动程序传递参数呢？我们知道在k8s上一切皆对象，要在k8s上使用存储卷，我们还需要把对应的驱动抽象成k8s上的资源；在使用时，我们直接初始化对应的资源为对象即可；为了在k8s上简化使用存储卷的复杂度，k8s内置了一些存储接口，对于不同类型的存储，其使用的接口、传递的参数也有所不同；除此之外在k8s上也支持用户使用自定义存储，通过csi接口来定义；&lt;/p&gt;
&lt;p&gt;　　查看k8s上支持的volumes接口&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;43&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
[root@master01 ~]# kubectl explain pod.spec.volumes
KIND:     Pod
VERSION:  v1

RESOURCE: volumes &amp;lt;[]Object&amp;gt;

DESCRIPTION:
     List of volumes that can be mounted by containers belonging to the pod.
     More info: https://kubernetes.io/docs/concepts/storage/volumes

     Volume represents a named volume in a pod that may be accessed by any
     container in the pod.

FIELDS:
   awsElasticBlockStore &amp;lt;Object&amp;gt;
     AWSElasticBlockStore represents an AWS Disk resource that is attached to a
     kubelet's host machine and then exposed to the pod. More info:
     https://kubernetes.io/docs/concepts/storage/volumes#awselasticblockstore

   azureDisk    &amp;lt;Object&amp;gt;
     AzureDisk represents an Azure Data Disk mount on the host and bind mount to
     the pod.

   azureFile    &amp;lt;Object&amp;gt;
     AzureFile represents an Azure File Service mount on the host and bind mount
     to the pod.

   cephfs       &amp;lt;Object&amp;gt;
     CephFS represents a Ceph FS mount on the host that shares a pod's lifetime

   cinder       &amp;lt;Object&amp;gt;
     Cinder represents a cinder volume attached and mounted on kubelets host
     machine. More info: https://examples.k8s.io/mysql-cinder-pd/README.md

   configMap    &amp;lt;Object&amp;gt;
     ConfigMap represents a configMap that should populate this volume

   csi  &amp;lt;Object&amp;gt;
     CSI (Container Storage Interface) represents ephemeral storage that is
     handled by certain external CSI drivers (Beta feature).

   downwardAPI  &amp;lt;Object&amp;gt;
     DownwardAPI represents downward API about the pod that should populate this
     volume

   emptyDir     &amp;lt;Object&amp;gt;
     EmptyDir represents a temporary directory that shares a pod's lifetime.
     More info: https://kubernetes.io/docs/concepts/storage/volumes#emptydir

   ephemeral    &amp;lt;Object&amp;gt;
     Ephemeral represents a volume that is handled by a cluster storage driver
     (Alpha feature). The volume's lifecycle is tied to the pod that defines it
     - it will be created before the pod starts, and deleted when the pod is
     removed.

     Use this if: a) the volume is only needed while the pod runs, b) features
     of normal volumes like restoring from snapshot or capacity tracking are
     needed, c) the storage driver is specified through a storage class, and d)
     the storage driver supports dynamic volume provisioning through a
     PersistentVolumeClaim (see EphemeralVolumeSource for more information on
     the connection between this volume type and PersistentVolumeClaim).

     Use PersistentVolumeClaim or one of the vendor-specific APIs for volumes
     that persist for longer than the lifecycle of an individual pod.

     Use CSI for light-weight local ephemeral volumes if the CSI driver is meant
     to be used that way - see the documentation of the driver for more
     information.

     A pod can use both types of ephemeral volumes and persistent volumes at the
     same time.

   fc   &amp;lt;Object&amp;gt;
     FC represents a Fibre Channel resource that is attached to a kubelet's host
     machine and then exposed to the pod.

   flexVolume   &amp;lt;Object&amp;gt;
     FlexVolume represents a generic volume resource that is
     provisioned/attached using an exec based plugin.

   flocker      &amp;lt;Object&amp;gt;
     Flocker represents a Flocker volume attached to a kubelet's host machine.
     This depends on the Flocker control service being running

   gcePersistentDisk    &amp;lt;Object&amp;gt;
     GCEPersistentDisk represents a GCE Disk resource that is attached to a
     kubelet's host machine and then exposed to the pod. More info:
     https://kubernetes.io/docs/concepts/storage/volumes#gcepersistentdisk

   gitRepo      &amp;lt;Object&amp;gt;
     GitRepo represents a git repository at a particular revision. DEPRECATED:
     GitRepo is deprecated. To provision a container with a git repo, mount an
     EmptyDir into an InitContainer that clones the repo using git, then mount
     the EmptyDir into the Pod's container.

   glusterfs    &amp;lt;Object&amp;gt;
     Glusterfs represents a Glusterfs mount on the host that shares a pod's
     lifetime. More info: https://examples.k8s.io/volumes/glusterfs/README.md

   hostPath     &amp;lt;Object&amp;gt;
     HostPath represents a pre-existing file or directory on the host machine
     that is directly exposed to the container. This is generally used for
     system agents or other privileged things that are allowed to see the host
     machine. Most containers will NOT need this. More info:
     https://kubernetes.io/docs/concepts/storage/volumes#hostpath

   iscsi        &amp;lt;Object&amp;gt;
     ISCSI represents an ISCSI Disk resource that is attached to a kubelet's
     host machine and then exposed to the pod. More info:
     https://examples.k8s.io/volumes/iscsi/README.md

   name &amp;lt;string&amp;gt; -required-
     Volume's name. Must be a DNS_LABEL and unique within the pod. More info:
     https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names

   nfs  &amp;lt;Object&amp;gt;
     NFS represents an NFS mount on the host that shares a pod's lifetime More
     info: https://kubernetes.io/docs/concepts/storage/volumes#nfs

   persistentVolumeClaim        &amp;lt;Object&amp;gt;
     PersistentVolumeClaimVolumeSource represents a reference to a
     PersistentVolumeClaim in the same namespace. More info:
     https://kubernetes.io/docs/concepts/storage/persistent-volumes#persistentvolumeclaims

   photonPersistentDisk &amp;lt;Object&amp;gt;
     PhotonPersistentDisk represents a PhotonController persistent disk attached
     and mounted on kubelets host machine

   portworxVolume       &amp;lt;Object&amp;gt;
     PortworxVolume represents a portworx volume attached and mounted on
     kubelets host machine

   projected    &amp;lt;Object&amp;gt;
     Items for all in one resources secrets, configmaps, and downward API

   quobyte      &amp;lt;Object&amp;gt;
     Quobyte represents a Quobyte mount on the host that shares a pod's lifetime

   rbd  &amp;lt;Object&amp;gt;
     RBD represents a Rados Block Device mount on the host that shares a pod's
     lifetime. More info: https://examples.k8s.io/volumes/rbd/README.md

   scaleIO      &amp;lt;Object&amp;gt;
     ScaleIO represents a ScaleIO persistent volume attached and mounted on
     Kubernetes nodes.

   secret       &amp;lt;Object&amp;gt;
     Secret represents a secret that should populate this volume. More info:
     https://kubernetes.io/docs/concepts/storage/volumes#secret

   storageos    &amp;lt;Object&amp;gt;
     StorageOS represents a StorageOS volume attached and mounted on Kubernetes
     nodes.

   vsphereVolume        &amp;lt;Object&amp;gt;
     VsphereVolume represents a vSphere volume attached and mounted on kubelets
     host machine

[root@master01 ~]# 
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　提示：从上面的帮助信息可以看到k8s上支持的存储接口还是很多，每一个存储接口都是一种类型；对于这些存储类型我们大致可以分为云存储，分布式存储，网络存储、临时存储，节点本地存储，特殊类型存储、用户自定义存储等等；比如awsElasticBlockStore、azureDisk、azureFile、gcePersistentDisk、vshperVolume、cinder这些类型划分为云存储；cephfs、glusterfs、rbd这些划分为分布式存储；nfs、iscsi、fc这些划分为网络存储；enptyDIR划分为临时存储；hostPath、local划分为本地存储；自定义存储csi；特殊存储configMap、secret、downwardAPId；持久卷申请persistentVolumeClaim等等；&lt;/p&gt;
&lt;p&gt;　　volumes的使用&lt;/p&gt;
&lt;p&gt;　　示例：创建使用hostPath类型存储卷Pod&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;35&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
[root@master01 ~]# cat hostPath-demo.yaml
apiVersion: v1
kind: Pod
metadata:
  name: vol-hostpath-demo
  namespace: default
spec:
  containers:
  - name: nginx
    image: nginx:1.14-alpine
    volumeMounts: 
    - name: webhtml
      mountPath: /usr/share/nginx/html
      readOnly: true
  volumes:
  - name: webhtml
    hostPath:
      path: /vol/html/
      type: DirectoryOrCreate
[root@master01 ~]# 
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　提示：以上配置清单表示创建一个名为nginx的pod，对应使用nginx:1.14-alpine的镜像；并且定义了一个存储卷，该存储卷的名称为webhtml，其类型为hostPath；在定义存储卷时，我们需要在spec字段下使用volumes字段来指定，该字段的值为一个对象列表；其中name是必须字段，用于指定存储卷的名称，方便容器挂载其存储卷时引用的标识符；其次我们需要对应的存储卷类型来表示使用对应的存储接口；hostPath表示使用hostPath类型存储接口；该类型存储接口需要我们手动传递两个参数，第一个是path指定宿主机的某个目录或文件路径；type用来指定当宿主机上的指定的路径不存在时该怎么办，这个值有7个值；其中DirectoryOrCteate表示对应path字段指定的文件必须是一个目录，当这个目录在宿主机上不存在时就创建；Directory表示对应path字段指定的文件必须是一个已存在的目录；FileOrCreate表示对应path字段指定的文件必须是一个文件，如果文件不存在就创建；File表示对应path字段必须为一个已存在的文件；Socket表示对应path必须为一个已存在的Socket文件；CharDevice表示对应path字段指定的文件必须是一个已存在的字符设备；BlockDevice表示对应path字段指定的是一个已存在的块设备；&lt;/p&gt;
&lt;p&gt;　　应用配置清单&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;37&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
[root@master01 ~]# kubectl apply -f hostPath-demo.yaml 
pod/vol-hostpath-demo created
[root@master01 ~]# kubectl get pod 
NAME                     READY   STATUS    RESTARTS   AGE
myapp-6479b786f5-9d4mh   1/1     Running   1          47h
myapp-6479b786f5-k252c   1/1     Running   1          47h
vol-hostpath-demo        1/1     Running   0          11s
[root@master01 ~]# kubectl describe pod/vol-hostpath-demo
Name:         vol-hostpath-demo
Namespace:    default
Priority:     0
Node:         node03.k8s.org/192.168.0.46
Start Time:   Wed, 23 Dec 2020 23:14:35 +0800
Labels:       &amp;lt;none&amp;gt;
Annotations:  &amp;lt;none&amp;gt;
Status:       Running
IP:           10.244.3.92
IPs:
  IP:  10.244.3.92
Containers:
  nginx:
    Container ID:   docker://eb8666714b8697457ce2a88271a4615f836873b4729b6a0938776e3d527c6536
    Image:          nginx:1.14-alpine
    Image ID:       docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7
    Port:           &amp;lt;none&amp;gt;
    Host Port:      &amp;lt;none&amp;gt;
    State:          Running
      Started:      Wed, 23 Dec 2020 23:14:37 +0800
    Ready:          True
    Restart Count:  0
    Environment:    &amp;lt;none&amp;gt;
    Mounts:
      /usr/share/nginx/html from webhtml (ro)
      /var/run/secrets/kubernetes.io/serviceaccount from default-token-xvd4c (ro)
Conditions:
  Type              Status
  Initialized       True 
  Ready             True 
  ContainersReady   True 
  PodScheduled      True 
Volumes:
  webhtml:
    Type:          HostPath (bare host directory volume)
    Path:          /vol/html/
    HostPathType:  DirectoryOrCreate
  default-token-xvd4c:
    Type:        Secret (a volume populated by a Secret)
    SecretName:  default-token-xvd4c
    Optional:    false
QoS Class:       BestEffort
Node-Selectors:  &amp;lt;none&amp;gt;
Tolerations:     node.kubernetes.io/not-ready:NoExecute op=Exists for 300s
                 node.kubernetes.io/unreachable:NoExecute op=Exists for 300s
Events:
  Type    Reason     Age   From               Message
  ----    ------     ----  ----               -------
  Normal  Scheduled  43s   default-scheduler  Successfully assigned default/vol-hostpath-demo to node03.k8s.org
  Normal  Pulled     42s   kubelet            Container image &quot;nginx:1.14-alpine&quot; already present on machine
  Normal  Created    41s   kubelet            Created container nginx
  Normal  Started    41s   kubelet            Started container nginx
[root@master01 ~]# 
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　提示：可以看到对应pod里以只读方式挂载了webhtml存储卷，对应webhtm存储卷类型为HostPath，对应path是/vol/html/；&lt;/p&gt;
&lt;p&gt;　　查看对应pod所在节点&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;34&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
[root@master01 ~]# kubectl get pod vol-hostpath-demo -o wide
NAME                READY   STATUS    RESTARTS   AGE     IP            NODE             NOMINATED NODE   READINESS GATES
vol-hostpath-demo   1/1     Running   0          3m39s   10.244.3.92   node03.k8s.org   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
[root@master01 ~]# 
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　在node03上查看对应目录是否创建？&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;35&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
[root@node03 ~]# ll /
total 16
lrwxrwxrwx.   1 root root    7 Sep 15 20:33 bin -&amp;gt; usr/bin
dr-xr-xr-x.   5 root root 4096 Sep 15 20:39 boot
drwxr-xr-x   20 root root 3180 Dec 23 23:10 dev
drwxr-xr-x.  80 root root 8192 Dec 23 23:10 etc
drwxr-xr-x.   2 root root    6 Nov  5  2016 home
lrwxrwxrwx.   1 root root    7 Sep 15 20:33 lib -&amp;gt; usr/lib
lrwxrwxrwx.   1 root root    9 Sep 15 20:33 lib64 -&amp;gt; usr/lib64
drwxr-xr-x.   2 root root    6 Nov  5  2016 media
drwxr-xr-x.   2 root root    6 Nov  5  2016 mnt
drwxr-xr-x.   4 root root   35 Dec  8 14:25 opt
dr-xr-xr-x  141 root root    0 Dec 23 23:09 proc
dr-xr-x---.   4 root root  213 Dec 21 22:46 root
drwxr-xr-x   26 root root  780 Dec 23 23:13 run
lrwxrwxrwx.   1 root root    8 Sep 15 20:33 sbin -&amp;gt; usr/sbin
drwxr-xr-x.   2 root root    6 Nov  5  2016 srv
dr-xr-xr-x   13 root root    0 Dec 23 23:09 sys
drwxrwxrwt.   9 root root  251 Dec 23 23:11 tmp
drwxr-xr-x.  13 root root  155 Sep 15 20:33 usr
drwxr-xr-x.  19 root root  267 Sep 15 20:38 var
drwxr-xr-x    3 root root   18 Dec 23 23:14 vol
[root@node03 ~]# ll /vol
total 0
drwxr-xr-x 2 root root 6 Dec 23 23:14 html
[root@node03 ~]# ll /vol/html/
total 0
[root@node03 ~]# 
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　提示：可以看到对应节点上已经创建/vol/html/目录，对应目录下没有任何文件；&lt;/p&gt;
&lt;p&gt;　　在对应节点对应目录下创建一个网页文件，访问对应pod看看是否对应网页文件是否能够被访问到？&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;35&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
[root@node03 ~]# echo &quot;this is test page from node03 /vol/html/test.html&quot; &amp;gt; /vol/html/test.html
[root@node03 ~]# cat /vol/html/test.html
this is test page from node03 /vol/html/test.html
[root@node03 ~]# exit
logout
Connection to node03 closed.
[root@master01 ~]# kubectl get pod -o wide
NAME                     READY   STATUS    RESTARTS   AGE     IP            NODE             NOMINATED NODE   READINESS GATES
myapp-6479b786f5-9d4mh   1/1     Running   1          47h     10.244.2.99   node02.k8s.org   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
myapp-6479b786f5-k252c   1/1     Running   1          47h     10.244.4.21   node04.k8s.org   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
vol-hostpath-demo        1/1     Running   0          7m45s   10.244.3.92   node03.k8s.org   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
[root@master01 ~]# curl 10.244.3.92/test.html
this is test page from node03 /vol/html/test.html
[root@master01 ~]# 
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　提示：可以看到在对应节点上创建网页文件，访问pod能够正常被访问到；&lt;/p&gt;
&lt;p&gt;　　测试：删除pod，看看对应节点上的目录是否会被删除？&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;35&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
[root@master01 ~]# kubectl delete -f hostPath-demo.yaml 
pod &quot;vol-hostpath-demo&quot; deleted
[root@master01 ~]# kubectl get pod 
NAME                     READY   STATUS    RESTARTS   AGE
myapp-6479b786f5-9d4mh   1/1     Running   1          47h
myapp-6479b786f5-k252c   1/1     Running   1          47h
[root@master01 ~]# ssh node03 
Last login: Wed Dec 23 23:18:51 2020 from master01
[root@node03 ~]# ll /vol/html/
total 4
-rw-r--r-- 1 root root 50 Dec 23 23:22 test.html
[root@node03 ~]# exit
logout
Connection to node03 closed.
[root@master01 ~]# 
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　提示：可以看到删除了pod以后，在对应节点上的目录并不会被删除；对应的网页文件还是完好无损；&lt;/p&gt;
&lt;p&gt;　　测试：重新引用配置清单，访问对应的pod，看看是否能够访问到对应的网页文件内容？&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;35&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
[root@master01 ~]# kubectl apply -f hostPath-demo.yaml 
pod/vol-hostpath-demo created
[root@master01 ~]# kubectl get pod -o wide
NAME                     READY   STATUS    RESTARTS   AGE   IP            NODE             NOMINATED NODE   READINESS GATES
myapp-6479b786f5-9d4mh   1/1     Running   1          47h   10.244.2.99   node02.k8s.org   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
myapp-6479b786f5-k252c   1/1     Running   1          47h   10.244.4.21   node04.k8s.org   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
vol-hostpath-demo        1/1     Running   0          7s    10.244.3.93   node03.k8s.org   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
[root@master01 ~]# curl 10.244.3.93/test.html
this is test page from node03 /vol/html/test.html
[root@master01 ~]# 
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　提示：可以看到对应pod被调度到node03上了，访问对应的pod能够访问到我们创建的网页文件；假如我们明确指定将此pod运行在node02上，对应pod是否还可以访问到对应的网页文件呢？&lt;/p&gt;
&lt;p&gt;　　测试：绑定pod运行在node02.k8s.org上&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;35&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
[root@master01 ~]# cat hostPath-demo.yaml
apiVersion: v1
kind: Pod
metadata:
  name: vol-hostpath-demo
  namespace: default
spec:
  nodeName: node02.k8s.org
  containers:
  - name: nginx
    image: nginx:1.14-alpine
    volumeMounts: 
    - name: webhtml
      mountPath: /usr/share/nginx/html
      readOnly: true
  volumes:
  - name: webhtml
    hostPath:
      path: /vol/html/
      type: DirectoryOrCreate
[root@master01 ~]# 
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　提示：绑定pod运行为某个节点上，我们可以在spec字段中用nodeName字段来指定对应节点的主机名即可；&lt;/p&gt;
&lt;p&gt;　　删除原有pod，重新应用新资源清单&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;35&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
[root@master01 ~]# kubectl delete pod/vol-hostpath-demo
pod &quot;vol-hostpath-demo&quot; deleted
[root@master01 ~]# kubectl get pod
NAME                     READY   STATUS    RESTARTS   AGE
myapp-6479b786f5-9d4mh   1/1     Running   1          47h
myapp-6479b786f5-k252c   1/1     Running   1          47h
[root@master01 ~]# kubectl apply -f hostPath-demo.yaml 
pod/vol-hostpath-demo created
[root@master01 ~]# kubectl get pod -o wide
NAME                     READY   STATUS    RESTARTS   AGE   IP             NODE             NOMINATED NODE   READINESS GATES
myapp-6479b786f5-9d4mh   1/1     Running   1          47h   10.244.2.99    node02.k8s.org   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
myapp-6479b786f5-k252c   1/1     Running   1          47h   10.244.4.21    node04.k8s.org   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
vol-hostpath-demo        1/1     Running   0          8s    10.244.2.100   node02.k8s.org   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
[root@master01 ~]# 
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　提示：可以看到重新应用新资源清单，对应pod运行在node02上；&lt;/p&gt;
&lt;p&gt;　　访问对应pod，看看test.html是否能够被访问到？&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;34&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
[root@master01 ~]# curl 10.244.2.100/test.html
&amp;lt;html&amp;gt;
&amp;lt;head&amp;gt;&amp;lt;title&amp;gt;404 Not Found&amp;lt;/title&amp;gt;&amp;lt;/head&amp;gt;
&amp;lt;body bgcolor=&quot;white&quot;&amp;gt;
&amp;lt;center&amp;gt;&amp;lt;h1&amp;gt;404 Not Found&amp;lt;/h1&amp;gt;&amp;lt;/center&amp;gt;
&amp;lt;hr&amp;gt;&amp;lt;center&amp;gt;nginx/1.14.2&amp;lt;/center&amp;gt;
&amp;lt;/body&amp;gt;
&amp;lt;/html&amp;gt;
[root@master01 ~]# 
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　提示：可以看到现在访问pod，对应网页文件就不能被访问到；其实原因很简单；hostPath类型存储卷是将宿主机上的某个目录或文件当作存储卷映射进pause容器，然后供pod里的容器挂载使用；这种类型的存储卷不能跨节点；所以在node02上创建的pod，node03上的文件肯定是不能被访问到的；为此，如果要使用hostPath类型的存储卷，我们就必须绑定节点；除此之外我们就应该在k8s节点上创建相同的文件或目录；&lt;/p&gt;
&lt;p&gt;　　示例：创建使用emptyDir类型存储卷pod&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;36&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
[root@master01 ~]# cat emptyDir-demo.yaml
apiVersion: v1
kind: Pod
metadata:
  name: vol-emptydir-demo
  namespace: default
spec:
  containers:
  - name: nginx
    image: nginx:1.14-alpine
    volumeMounts:
    - name: web-cache-dir
      mountPath: /usr/share/nginx/html
      readOnly: true
readOnly: true
  - name: alpine
    image: alpine
    volumeMounts:
    - name: web-cache-dir
      mountPath: /nginx/html
    command: [&quot;/bin/sh&quot;, &quot;-c&quot;]
    args:
    - while true; do
        echo $(hostname) $(date) &amp;gt;&amp;gt; /nginx/html/index.html;
        sleep 10;
      done
  volumes:
  - name: web-cache-dir
    emptyDir: 
      medium: Memory
      sizeLimit: &quot;10Mi&quot;
[root@master01 ~]# 
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　提示：以上清单表示定义运行一个名为vol-emptydir-demo的pod；在其pod内部运行两个容器，一个名为nginx，一个名为alpine；同时这两个容器都同时挂载一个名为web-cache-dir的存储卷，其类型为emptyDir，如下图所示；定义empytDir类型的存储卷，我们需要在spec.volumes字段下使用name指定其存储卷的名称；用emptyDir指定其存储卷类型为emptyDir；对于empytDir类型存储卷，它有两个属性，medium字段用于指定媒介类型，Memory表示使用内存作为存储媒介；默认该字段的值为“”，表示使用默认的对应节点默认的存储媒介；sizeLimit字段是用来限制其对应存储大小，默认是空，表示不限制；&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1503305/202012/1503305-20201224004054607-549340166.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　提示：如上图，其pod内部有两个容器，一个名为alpine的容器，它会每隔10往/nginx/html/inde.html文件中写入对应主机名+时间；而nginx容器挂载对应的empytDir类型存储卷到本地的网页存储目录；简单讲就是alpine容器往/nginx/html/index.html写数据，nginx容器挂载对应文件到网页目录；&lt;/p&gt;
&lt;p&gt;　　应用资源清单&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;38&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
[root@master01 ~]# kubectl apply -f emptyDir-demo.yaml
pod/vol-emptydir-demo created
[root@master01 ~]# kubectl get pods -o wide
NAME                     READY   STATUS              RESTARTS   AGE   IP             NODE             NOMINATED NODE   READINESS GATES
myapp-6479b786f5-9d4mh   1/1     Running             1          2d    10.244.2.99    node02.k8s.org   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
myapp-6479b786f5-k252c   1/1     Running             1          2d    10.244.4.21    node04.k8s.org   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
vol-emptydir-demo        0/2     ContainerCreating   0          8s    &amp;lt;none&amp;gt;         node03.k8s.org   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
vol-hostpath-demo        1/1     Running             0          72m   10.244.2.100   node02.k8s.org   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
[root@master01 ~]# kubectl get pods -o wide
NAME                     READY   STATUS    RESTARTS   AGE   IP             NODE             NOMINATED NODE   READINESS GATES
myapp-6479b786f5-9d4mh   1/1     Running   1          2d    10.244.2.99    node02.k8s.org   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
myapp-6479b786f5-k252c   1/1     Running   1          2d    10.244.4.21    node04.k8s.org   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
vol-emptydir-demo        2/2     Running   0          16s   10.244.3.94    node03.k8s.org   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
vol-hostpath-demo        1/1     Running   0          72m   10.244.2.100   node02.k8s.org   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
[root@master01 ~]# kubectl describe pod vol-emptydir-demo 
Name:         vol-emptydir-demo
Namespace:    default
Priority:     0
Node:         node03.k8s.org/192.168.0.46
Start Time:   Thu, 24 Dec 2020 00:46:56 +0800
Labels:       &amp;lt;none&amp;gt;
Annotations:  &amp;lt;none&amp;gt;
Status:       Running
IP:           10.244.3.94
IPs:
  IP:  10.244.3.94
Containers:
  nginx:
    Container ID:   docker://58af9ef80800fb22543d1c80be58849f45f3d62f3b44101dbca024e0761cead5
    Image:          nginx:1.14-alpine
    Image ID:       docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7
    Port:           &amp;lt;none&amp;gt;
    Host Port:      &amp;lt;none&amp;gt;
    State:          Running
      Started:      Thu, 24 Dec 2020 00:46:57 +0800
    Ready:          True
    Restart Count:  0
    Environment:    &amp;lt;none&amp;gt;
    Mounts:
      /usr/share/nginx/html from web-cache-dir (ro)
      /var/run/secrets/kubernetes.io/serviceaccount from default-token-xvd4c (ro)
  alpine:
    Container ID:  docker://327f110a10e8ef9edb5f86b5cb3dad53e824010b52b1c2a71d5dbecab6f49f05
    Image:         alpine
    Image ID:      docker-pullable://alpine@sha256:3c7497bf0c7af93428242d6176e8f7905f2201d8fc5861f45be7a346b5f23436
    Port:          &amp;lt;none&amp;gt;
    Host Port:     &amp;lt;none&amp;gt;
    Command:
      /bin/sh
      -c
    Args:
      while true; do echo $(hostname) $(date) &amp;gt;&amp;gt; /nginx/html/index.html; sleep 10; done
    State:          Running
      Started:      Thu, 24 Dec 2020 00:47:07 +0800
    Ready:          True
    Restart Count:  0
    Environment:    &amp;lt;none&amp;gt;
    Mounts:
      /nginx/html from web-cache-dir (rw)
      /var/run/secrets/kubernetes.io/serviceaccount from default-token-xvd4c (ro)
Conditions:
  Type              Status
  Initialized       True 
  Ready             True 
  ContainersReady   True 
  PodScheduled      True 
Volumes:
  web-cache-dir:
    Type:       EmptyDir (a temporary directory that shares a pod's lifetime)
    Medium:     Memory
    SizeLimit:  10Mi
  default-token-xvd4c:
    Type:        Secret (a volume populated by a Secret)
    SecretName:  default-token-xvd4c
    Optional:    false
QoS Class:       BestEffort
Node-Selectors:  &amp;lt;none&amp;gt;
Tolerations:     node.kubernetes.io/not-ready:NoExecute op=Exists for 300s
                 node.kubernetes.io/unreachable:NoExecute op=Exists for 300s
Events:
  Type    Reason     Age   From               Message
  ----    ------     ----  ----               -------
  Normal  Scheduled  51s   default-scheduler  Successfully assigned default/vol-emptydir-demo to node03.k8s.org
  Normal  Pulled     51s   kubelet            Container image &quot;nginx:1.14-alpine&quot; already present on machine
  Normal  Created    51s   kubelet            Created container nginx
  Normal  Started    50s   kubelet            Started container nginx
  Normal  Pulling    50s   kubelet            Pulling image &quot;alpine&quot;
  Normal  Pulled     40s   kubelet            Successfully pulled image &quot;alpine&quot; in 10.163157508s
  Normal  Created    40s   kubelet            Created container alpine
  Normal  Started    40s   kubelet            Started container alpine
[root@master01 ~]# 
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　提示：可以看到对应pod已经正常运行起来，其内部有2个容器；其中nginx容器一只读方式挂载名为web-cache-dir的存储卷，alpine以读写方式挂载web-cache-dir的存储卷；对应存储卷类型为emptyDir；&lt;/p&gt;
&lt;p&gt;　　访问对应pod，看看是否能够访问到对应存储卷中index.html的内容？&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;35&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
[root@master01 ~]# kubectl get pods -o wide              
NAME                     READY   STATUS    RESTARTS   AGE     IP             NODE             NOMINATED NODE   READINESS GATES
myapp-6479b786f5-9d4mh   1/1     Running   1          2d      10.244.2.99    node02.k8s.org   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
myapp-6479b786f5-k252c   1/1     Running   1          2d      10.244.4.21    node04.k8s.org   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
vol-emptydir-demo        2/2     Running   0          4m38s   10.244.3.94    node03.k8s.org   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
vol-hostpath-demo        1/1     Running   0          77m     10.244.2.100   node02.k8s.org   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
[root@master01 ~]# curl 10.244.3.94
vol-emptydir-demo Wed Dec 23 16:47:07 UTC 2020
vol-emptydir-demo Wed Dec 23 16:47:17 UTC 2020
vol-emptydir-demo Wed Dec 23 16:47:27 UTC 2020
vol-emptydir-demo Wed Dec 23 16:47:37 UTC 2020
vol-emptydir-demo Wed Dec 23 16:47:47 UTC 2020
vol-emptydir-demo Wed Dec 23 16:47:57 UTC 2020
vol-emptydir-demo Wed Dec 23 16:48:07 UTC 2020
vol-emptydir-demo Wed Dec 23 16:48:17 UTC 2020
vol-emptydir-demo Wed Dec 23 16:48:27 UTC 2020
vol-emptydir-demo Wed Dec 23 16:48:37 UTC 2020
vol-emptydir-demo Wed Dec 23 16:48:47 UTC 2020
vol-emptydir-demo Wed Dec 23 16:48:57 UTC 2020
vol-emptydir-demo Wed Dec 23 16:49:07 UTC 2020
vol-emptydir-demo Wed Dec 23 16:49:17 UTC 2020
vol-emptydir-demo Wed Dec 23 16:49:27 UTC 2020
vol-emptydir-demo Wed Dec 23 16:49:37 UTC 2020
vol-emptydir-demo Wed Dec 23 16:49:47 UTC 2020
vol-emptydir-demo Wed Dec 23 16:49:57 UTC 2020
vol-emptydir-demo Wed Dec 23 16:50:07 UTC 2020
vol-emptydir-demo Wed Dec 23 16:50:17 UTC 2020
vol-emptydir-demo Wed Dec 23 16:50:27 UTC 2020
vol-emptydir-demo Wed Dec 23 16:50:37 UTC 2020
vol-emptydir-demo Wed Dec 23 16:50:47 UTC 2020
vol-emptydir-demo Wed Dec 23 16:50:57 UTC 2020
vol-emptydir-demo Wed Dec 23 16:51:07 UTC 2020
vol-emptydir-demo Wed Dec 23 16:51:17 UTC 2020
vol-emptydir-demo Wed Dec 23 16:51:27 UTC 2020
vol-emptydir-demo Wed Dec 23 16:51:37 UTC 2020
vol-emptydir-demo Wed Dec 23 16:51:47 UTC 2020
[root@master01 ~]# 
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　提示：可以看到能够访问到index.html文件内容，并且该文件内容是alpine容器动态生成的内容；从上面的示例，不难理解，在同一个pod内部可以共享同一存储卷；&lt;/p&gt;
&lt;p&gt;　　示例：创建使用nfs类型的存储卷pod&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;35&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
[root@master01 ~]# cat nfs-demo.yaml
apiVersion: v1
kind: Pod
metadata:
  name: vol-nfs-demo
  namespace: default
spec:
  containers:
  - name: nginx
    image: nginx:1.14-alpine
    volumeMounts:
    - name: webhtml
      mountPath: /usr/share/nginx/html
      readOnly: true
  volumes:
  - name: webhtml
    nfs:
      path: /data/html/
      server: 192.168.0.99
[root@master01 ~]# 
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　提示：定义nfs类型存储卷，对应spec.volumes.nfs字段下必须定义path字段，该字段用于指定其nfs文件系统的导出文件路径；server字段是用于指定其nfs服务器地址；在使用nfs存储作为pod的后端存储，首先我们要准备好nfs服务器，并导出对应的目录；&lt;/p&gt;
&lt;p&gt;　　准备nfs服务器，在192.168.0.99这台服务器上安装nfs-utils包&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;36&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
[root@docker_registry ~]# ip a|grep 192.168.0.99
    inet 192.168.0.99/24 brd 192.168.0.255 scope global enp3s0
[root@docker_registry ~]# yum install nfs-utils -y
Loaded plugins: fastestmirror, langpacks
Repository epel is listed more than once in the configuration
Repository epel-debuginfo is listed more than once in the configuration
Repository epel-source is listed more than once in the configuration
base                                                                                                                  | 3.6 kB  00:00:00     
docker-ce-stable                                                                                                      | 3.5 kB  00:00:00     
epel                                                                                                                  | 4.7 kB  00:00:00     
extras                                                                                                                | 2.9 kB  00:00:00     
kubernetes/signature                                                                                                  |  844 B  00:00:00     
kubernetes/signature                                                                                                  | 1.4 kB  00:00:00 !!! 
mariadb-main                                                                                                          | 2.9 kB  00:00:00     
mariadb-maxscale                                                                                                      | 2.4 kB  00:00:00     
mariadb-tools                                                                                                         | 2.9 kB  00:00:00     
mongodb-org                                                                                                           | 2.5 kB  00:00:00     
proxysql_repo                                                                                                         | 2.9 kB  00:00:00     
updates                                                                                                               | 2.9 kB  00:00:00     
(1/6): docker-ce-stable/x86_64/primary_db                                                                             |  51 kB  00:00:00     
(2/6): kubernetes/primary                                                                                             |  83 kB  00:00:01     
(3/6): mongodb-org/primary_db                                                                                         |  26 kB  00:00:01     
(4/6): epel/x86_64/updateinfo                                                                                         | 1.0 MB  00:00:02     
(5/6): updates/7/x86_64/primary_db                                                                                    | 4.7 MB  00:00:01     
(6/6): epel/x86_64/primary_db                                                                                         | 6.9 MB  00:00:02     
Determining fastest mirrors
 * base: mirrors.aliyun.com
 * extras: mirrors.aliyun.com
 * updates: mirrors.aliyun.com
kubernetes                                                                                                                           612/612
Resolving Dependencies
--&amp;gt; Running transaction check
---&amp;gt; Package nfs-utils.x86_64 1:1.3.0-0.66.el7_8 will be updated
---&amp;gt; Package nfs-utils.x86_64 1:1.3.0-0.68.el7 will be an update
--&amp;gt; Finished Dependency Resolution

Dependencies Resolved

=============================================================================================================================================
 Package                          Arch                          Version                                    Repository                   Size
=============================================================================================================================================
Updating:
 nfs-utils                        x86_64                        1:1.3.0-0.68.el7                           base                        412 k

Transaction Summary
=============================================================================================================================================
Upgrade  1 Package

Total download size: 412 k
Downloading packages:
No Presto metadata available for base
nfs-utils-1.3.0-0.68.el7.x86_64.rpm                                                                                   | 412 kB  00:00:00     
Running transaction check
Running transaction test
Transaction test succeeded
Running transaction
  Updating   : 1:nfs-utils-1.3.0-0.68.el7.x86_64                                                                                         1/2 
  Cleanup    : 1:nfs-utils-1.3.0-0.66.el7_8.x86_64                                                                                       2/2 
  Verifying  : 1:nfs-utils-1.3.0-0.68.el7.x86_64                                                                                         1/2 
  Verifying  : 1:nfs-utils-1.3.0-0.66.el7_8.x86_64                                                                                       2/2 

Updated:
  nfs-utils.x86_64 1:1.3.0-0.68.el7                                                                                                          

Complete!
[root@docker_registry ~]# 
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　创建/data/html目录&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;33&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
[root@docker_registry ~]# mkdir /data/html -pv
mkdir: created directory ‘/data/html’
[root@docker_registry ~]# 
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　配置该目录能够被k8s集群节点所访问&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;34&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
[root@docker_registry ~]# cat /etc/exports
/data/html 192.168.0.0/24 (rw,no_root_squash)
[root@docker_registry ~]# 
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　提示：以上配置表示把/data/html这个目录以读写，不压榨root权限共享给192.168.0.0/24这个网络中的所有主机使用；&lt;/p&gt;
&lt;p&gt;　　启动nfs&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;35&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
[root@docker_registry ~]# systemctl start nfs
[root@docker_registry ~]# ss -tnl
State       Recv-Q Send-Q                         Local Address:Port                                        Peer Address:Port              
LISTEN      0      128                                127.0.0.1:1514                                                   *:*                  
LISTEN      0      128                                        *:111                                                    *:*                  
LISTEN      0      128                                        *:20048                                                  *:*                  
LISTEN      0      64                                         *:42837                                                  *:*                  
LISTEN      0      5                              192.168.122.1:53                                                     *:*                  
LISTEN      0      128                                        *:22                                                     *:*                  
LISTEN      0      128                             192.168.0.99:631                                                    *:*                  
LISTEN      0      100                                127.0.0.1:25                                                     *:*                  
LISTEN      0      64                                         *:2049                                                   *:*                  
LISTEN      0      128                                        *:59396                                                  *:*                  
LISTEN      0      128                                       :::34922                                                 :::*                  
LISTEN      0      128                                       :::111                                                   :::*                  
LISTEN      0      128                                       :::20048                                                 :::*                  
LISTEN      0      128                                       :::80                                                    :::*                  
LISTEN      0      128                                       :::22                                                    :::*                  
LISTEN      0      100                                      ::1:25                                                    :::*                  
LISTEN      0      128                                       :::443                                                   :::*                  
LISTEN      0      128                                       :::4443                                                  :::*                  
LISTEN      0      64                                        :::2049                                                  :::*                  
LISTEN      0      64                                        :::36997                                                 :::*                  
[root@docker_registry ~]# 
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　提示：nfs监听在tcp的2049端口，启动请确保该端口能够正常处于监听状态；到此nfs服务器就准备好了；&lt;/p&gt;
&lt;p&gt;　　在k8s节点上安装nfs-utils包，为其使用nfs提供所需驱动&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
yum install nfs-utils -y
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　验证：在node01上，看看能不能正常挂载nfs服务器共享出来的目录&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;49&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
[root@node01 ~]# showmount -e 192.168.0.99
Export list for 192.168.0.99:
/data/html (everyone)
[root@node01 ~]# mount -t nfs 192.168.0.99:/data/html /mnt
[root@node01 ~]# mount |grep /data/html
192.168.0.99:/data/html on /mnt type nfs4 (rw,relatime,vers=4.1,rsize=262144,wsize=262144,namlen=255,hard,proto=tcp,port=0,timeo=600,retrans=2,sec=sys,clientaddr=192.168.0.44,local_lock=none,addr=192.168.0.99)
[root@node01 ~]# umount /mnt
[root@node01 ~]# mount |grep /data/html
[root@node01 ~]# 
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　提示：可以看到在node01上能够正常看到nfs服务器共享出来的目录，并且也能正常挂载使用；等待其他节点把nfs-utils包安装完成以后，接下来就可以在master上应用配置清单了；&lt;/p&gt;
&lt;p&gt;　　应用资源清单&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;37&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
[root@master01 ~]# kubectl apply -f nfs-demo.yaml
pod/vol-nfs-demo created
[root@master01 ~]# kubectl get pods -o wide
NAME                     READY   STATUS    RESTARTS   AGE    IP             NODE             NOMINATED NODE   READINESS GATES
myapp-6479b786f5-9d4mh   1/1     Running   1          2d1h   10.244.2.99    node02.k8s.org   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
myapp-6479b786f5-k252c   1/1     Running   1          2d1h   10.244.4.21    node04.k8s.org   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
vol-hostpath-demo        1/1     Running   0          141m   10.244.2.100   node02.k8s.org   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
vol-nfs-demo             1/1     Running   0          10s    10.244.3.101   node03.k8s.org   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
[root@master01 ~]# kubectl describe pod vol-nfs-demo
Name:         vol-nfs-demo
Namespace:    default
Priority:     0
Node:         node03.k8s.org/192.168.0.46
Start Time:   Thu, 24 Dec 2020 01:55:51 +0800
Labels:       &amp;lt;none&amp;gt;
Annotations:  &amp;lt;none&amp;gt;
Status:       Running
IP:           10.244.3.101
IPs:
  IP:  10.244.3.101
Containers:
  nginx:
    Container ID:   docker://72227e3a94622a4ea032a1ab0d7d353aef167d5a0e80c3739e774050eaea3914
    Image:          nginx:1.14-alpine
    Image ID:       docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7
    Port:           &amp;lt;none&amp;gt;
    Host Port:      &amp;lt;none&amp;gt;
    State:          Running
      Started:      Thu, 24 Dec 2020 01:55:52 +0800
    Ready:          True
    Restart Count:  0
    Environment:    &amp;lt;none&amp;gt;
    Mounts:
      /usr/share/nginx/html from webhtml (ro)
      /var/run/secrets/kubernetes.io/serviceaccount from default-token-xvd4c (ro)
Conditions:
  Type              Status
  Initialized       True 
  Ready             True 
  ContainersReady   True 
  PodScheduled      True 
Volumes:
  webhtml:
    Type:      NFS (an NFS mount that lasts the lifetime of a pod)
    Server:    192.168.0.99
    Path:      /data/html/
    ReadOnly:  false
  default-token-xvd4c:
    Type:        Secret (a volume populated by a Secret)
    SecretName:  default-token-xvd4c
    Optional:    false
QoS Class:       BestEffort
Node-Selectors:  &amp;lt;none&amp;gt;
Tolerations:     node.kubernetes.io/not-ready:NoExecute op=Exists for 300s
                 node.kubernetes.io/unreachable:NoExecute op=Exists for 300s
Events:
  Type    Reason     Age   From               Message
  ----    ------     ----  ----               -------
  Normal  Scheduled  28s   default-scheduler  Successfully assigned default/vol-nfs-demo to node03.k8s.org
  Normal  Pulled     27s   kubelet            Container image &quot;nginx:1.14-alpine&quot; already present on machine
  Normal  Created    27s   kubelet            Created container nginx
  Normal  Started    27s   kubelet            Started container nginx
[root@master01 ~]# 
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　提示：可以看到对应pod已经正常运行，并且其内部容器已经正常挂载对应目录；&lt;/p&gt;
&lt;p&gt;　　在nfs服务器对应目录，创建一个index.html文件&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;34&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
[root@docker_registry ~]# cd /data/html
[root@docker_registry html]# echo &quot;this is test file from nfs server ip addr is 192.168.0.99&quot; &amp;gt; index.html
[root@docker_registry html]# cat index.html
this is test file from nfs server ip addr is 192.168.0.99
[root@docker_registry html]# 
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　访问对应pod，看看是否能够访问到对应文件内容？&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;35&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
[root@master01 ~]# kubectl get pods -o wide
NAME                     READY   STATUS    RESTARTS   AGE    IP             NODE             NOMINATED NODE   READINESS GATES
myapp-6479b786f5-9d4mh   1/1     Running   1          2d2h   10.244.2.99    node02.k8s.org   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
myapp-6479b786f5-k252c   1/1     Running   1          2d2h   10.244.4.21    node04.k8s.org   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
vol-hostpath-demo        1/1     Running   0          145m   10.244.2.100   node02.k8s.org   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
vol-nfs-demo             1/1     Running   0          4m6s   10.244.3.101   node03.k8s.org   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
[root@master01 ~]# curl 10.244.3.101
this is test file from nfs server ip addr is 192.168.0.99
[root@master01 ~]# 
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　提示：可以看到对应文件内容能够通过pod访问到；&lt;/p&gt;
&lt;p&gt;　　删除pod&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;35&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
[root@master01 ~]# kubectl delete -f nfs-demo.yaml
pod &quot;vol-nfs-demo&quot; deleted
[root@master01 ~]# kubectl get pod -o wide        
NAME                     READY   STATUS    RESTARTS   AGE    IP             NODE             NOMINATED NODE   READINESS GATES
myapp-6479b786f5-9d4mh   1/1     Running   1          2d2h   10.244.2.99    node02.k8s.org   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
myapp-6479b786f5-k252c   1/1     Running   1          2d2h   10.244.4.21    node04.k8s.org   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
vol-hostpath-demo        1/1     Running   0          149m   10.244.2.100   node02.k8s.org   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
[root@master01 ~]#
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　绑定pod运行在node02.k8s.org上，重新应用配置文件创建pod，再次访问对应pod，看看对应文件是否能够正常访问到呢？&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;35&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
[root@master01 ~]# cat nfs-demo.yaml
apiVersion: v1
kind: Pod
metadata:
  name: vol-nfs-demo
  namespace: default
spec:
  nodeName: node02.k8s.org
  containers:
  - name: nginx
    image: nginx:1.14-alpine
    volumeMounts:
    - name: webhtml
      mountPath: /usr/share/nginx/html
      readOnly: true
  volumes:
  - name: webhtml
    nfs:
      path: /data/html/
      server: 192.168.0.99
[root@master01 ~]# kubectl apply -f nfs-demo.yaml
pod/vol-nfs-demo created
[root@master01 ~]# kubectl get pod -o wide
NAME                     READY   STATUS    RESTARTS   AGE    IP             NODE             NOMINATED NODE   READINESS GATES
myapp-6479b786f5-9d4mh   1/1     Running   1          2d2h   10.244.2.99    node02.k8s.org   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
myapp-6479b786f5-k252c   1/1     Running   1          2d2h   10.244.4.21    node04.k8s.org   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
vol-hostpath-demo        1/1     Running   0          151m   10.244.2.100   node02.k8s.org   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
vol-nfs-demo             1/1     Running   0          8s     10.244.2.101   node02.k8s.org   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
[root@master01 ~]# curl 10.244.2.101
this is test file from nfs server ip addr is 192.168.0.99
[root@master01 ~]# 
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　提示：可以看到把对应pod绑定到node02上，访问对应pod也能正常访问到nfs服务器上的文件；从上述测试过程来看，nfs这种类型的存储卷能够脱离pod的生命周期，跨节点将pod里容器产生的数据持久化到对应的nfs文件系统服务器上；当然nfs此时是单点，一旦nfs服务器宕机挂掉，对应pod运行时产生的数据将全部丢失；所以对应外部存储系统，我们应该选择一个对数据有冗余，且k8s集群支持的类型的存储系统，比如cephfs，glusterfs等等；&lt;/p&gt;
</description>
<pubDate>Wed, 23 Dec 2020 18:23:00 +0000</pubDate>
<dc:creator>Linux-1874</dc:creator>
<og:description>前文我们聊到了k8s上的ingress资源相关话题，回顾请参考：https://www.cnblogs.com/qiuhom-1874/p/14167581.html；今天们来聊一下k8s上volum</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/qiuhom-1874/p/14180752.html</dc:identifier>
</item>
<item>
<title>如何让公司少不了你？ - pointersss</title>
<link>http://www.cnblogs.com/pointers/p/14182292.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/pointers/p/14182292.html</guid>
<description>&lt;blockquote readability=&quot;7&quot;&gt;
&lt;p&gt;成长&amp;amp;认知 丨 作者 / 袁吴范&lt;/p&gt;
&lt;p&gt;这是pointers公众号的第32篇原创文章&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;今天，团队内一个小伙伴，找到我，跟我说要离职。&lt;/p&gt;
&lt;p&gt;第一感觉，感到很惊讶，为啥来了几个月就要离开呢？&lt;/p&gt;
&lt;p&gt;是不是缺少人文关怀？&lt;/p&gt;
&lt;p&gt;还是团队气氛不对，他适应不了？&lt;/p&gt;
&lt;p&gt;融入不了团队？&lt;/p&gt;
&lt;p&gt;带着这些疑问，一番询问得知，原来是感情问题。&lt;/p&gt;
&lt;p&gt;谈了好几年的女朋友给他带了绿帽子。&lt;/p&gt;
&lt;p&gt;现在心思已经完全不在工作上。&lt;/p&gt;
&lt;p&gt;这个原因，让我哭笑不得，一个女孩子有那么夸张吗？工作都不要干了。可能太爱她了吧。&lt;/p&gt;
&lt;p&gt;当遇到这种人生变故，我会一般会提供一周的假，让他好好的调整下状态。&lt;/p&gt;
&lt;p&gt;很显然他拒绝了，他肯定告诉我，他想要离开杭州这个伤心的城市，想要尽快的离开，早点回到老家。&lt;/p&gt;
&lt;p&gt;现在的95年，还是比较任性的，年终奖也不要了。&lt;/p&gt;
&lt;p&gt;当然我还是支持他的。希望他能找回自己，重新燃起对生活的热情。&lt;/p&gt;
&lt;p&gt;大家可能要问了，你为啥不极力的把他留下？&lt;/p&gt;
&lt;p&gt;对这就是我接下来想说的。&lt;/p&gt;
&lt;p&gt;可能你不会爱听，但是这就是事实。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;我常说的，站在企业的角度看问题，会更加的通透，能够让我们针对性提升自己。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;不留下他的原因有两点：&lt;/p&gt;
&lt;p&gt;1、他在近期已经无法进入到工作状态，他的状态会严重影响到团队。&lt;/p&gt;
&lt;p&gt;2、他的能力没有达到不可替代的地步。&lt;/p&gt;
&lt;p&gt;事实并不可怕，最怕的是还没意识到，自己已经是那个随意可以替代的人。&lt;/p&gt;
&lt;p&gt;那么，如何才能做职场上最有价值的员工，成为不可取代的人呢？&lt;/p&gt;
&lt;p&gt;这个问题我思考了很久，总结出了三类不可替代的人：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;一、你手握公司重要的资源，公司缺少你手上的资源就会业务大跌甚至无法经营&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;我曾经在知乎上看到这样一个案例：王小塔是一家公司的客户经理，她负责的客户业务量，占公司业务总量的百分之六十。但由于领导的区别对待，王小塔在公司备受排挤，做出来的业绩经常得不到承认。&lt;/p&gt;
&lt;p&gt;于是王小塔提出了辞职，随后把自己的客户全部转移到了新入职的公司。结果王小塔走后，前公司的业务一蹶不振，没过多久就倒闭了。而新公司由于得到了王小塔的客户资源支持，业务量一下子上涨了很多，王小塔也很快在新公司站稳了脚跟。&lt;/p&gt;
&lt;p&gt;这个故事中的王小塔就是不可替代的。她的不可替代性在于：她即便离职，也能够把资源掌握在自己手上。&lt;/p&gt;
&lt;p&gt;当然，如果你希望自己在这个方向上不可替代，也要注重职业道德，不要做违反行业规则和突破个人道德底线的事。&lt;/p&gt;
&lt;p&gt;这个重要资源可以是&lt;strong&gt;核心技术、客户、战略规划&lt;/strong&gt;等等。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;二、你是公司的精神支柱，甚至影响公司的发展&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;这类人中，最为传奇的代表就是陆奇了。2017年，百度宣布任命前微软全球执行副总裁陆奇为百度集团总裁和首席运营官，负责产品、技术、销售和营销。&lt;/p&gt;
&lt;p&gt;在陆奇加入百度一年多的时间里，百度的市值从不到五百亿美元提升到了近千亿美元；而在陆奇离职后，百度的市值直接蒸发了近一百亿美元，陆奇充分证明了自己作为职业经理人的价值。&lt;/p&gt;
&lt;p&gt;可以说，陆奇对于百度不可替代的那种价值，已经完全体现出来了，即便离开百度，也是被其他公司抢着要的。&lt;/p&gt;
&lt;p&gt;**虽然现在的你无法达到，但是你要努力成为这样的人。&lt;br/&gt;**&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;三、你是老员工，公司要培养新人的成本太高&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;为什么很多时候，老员工的价值相对更高？&lt;/p&gt;
&lt;p&gt;因为老员工往往掌握了公司的核心业务，如果公司要培训新人来替代，往往成本过高。&lt;/p&gt;
&lt;p&gt;这一类员工也许能力并不是最强的，但也是公司的重要组成部分之一，只要能够做好自己的本职工作，基本不会被其他人取代。&lt;/p&gt;
&lt;p&gt;当然也不能太差，&lt;strong&gt;记住：不要只能干应届生也能干的事情&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;不过，俗话说得好：&lt;strong&gt;最大的安全感，是你有随时离开的能力。那些最有价值的员工，往往并不需要把自己和公司绑定在一起&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;我有一个朋友暂且叫他小轩，他毕业后跟我在同一家公司。在工作之余，他没有像大多数人那样消磨时间，而是经常给自己充电。在这个过程中，他通过不断学习，极大地提升了自己的技术能力。&lt;/p&gt;
&lt;p&gt;去年年初跟主管闹了一点矛盾，愤然离职。去了华为，拿到了华为的18级offer。继续照样干技术，干的风生水起。现在，年收入已经是当时的2倍了。&lt;/p&gt;
&lt;p&gt;总之，以上讲述的一些方法，是你在公司站稳脚跟的几种方式。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;即使一时做不到也不要紧，只要慢慢磨炼自己，每个人都能在职场上获得长远的发展。&lt;/strong&gt;&lt;/p&gt;
&lt;hr/&gt;&lt;p&gt;我是袁吴范，大厂技术总监，公众号：”pointers“&lt;/p&gt;
&lt;p&gt;你可以长按这个二维码加我微信，空位不多。&lt;/p&gt;
&lt;p&gt;记得备注下技术方向，我会将你拉进一个高品质群，群里有开发、产品、技术经理、技术总监。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/PVZcww4Su3icxqW28rtgt1ib4Iia7XUeWT9EdiapicwxdyHQCKDTRFDWqvErKb0FiaLWzZXQkPANFr00h9RRBC249MHQ/640?wx_fmt=jpeg&amp;amp;tp=webp&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&quot; alt=&quot;图片&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;hr/&gt;&lt;p&gt;&lt;em&gt;推荐阅读（干货）&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=Mzg4MTU0NTkxNA==&amp;amp;mid=2247484159&amp;amp;idx=1&amp;amp;sn=5d3b5d416a98f6a0d91e3d105b464924&amp;amp;chksm=cf65052af8128c3c1af6649b83d8ebdb5c0aad01f8bc9757976b7ab7418af68c155cdcf114d7&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot;&gt;7年，从“游戏少年”到大厂技术总监的逆袭之路&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=Mzg4MTU0NTkxNA==&amp;amp;mid=2247484330&amp;amp;idx=1&amp;amp;sn=0dc5e73f99dd1aa294bdb3ba574db586&amp;amp;chksm=cf65047ff8128d69dee9f6ce0a94f76df09159b2e45c0e78e1b760d5ace866283d8e0e0ff315&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot;&gt;职场PUA，管理者的五宗罪&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=Mzg4MTU0NTkxNA==&amp;amp;mid=2247484150&amp;amp;idx=1&amp;amp;sn=a75d0eb3811746b204007b36f260d7cc&amp;amp;chksm=cf650523f8128c356ef04f44ca060566d711e2aa8c83927c1206598ba9ae43b17fa23fc8fd08&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot;&gt;35岁以后，不要成为程序员中的钻石&lt;/a&gt;&lt;/p&gt;
</description>
<pubDate>Wed, 23 Dec 2020 16:40:00 +0000</pubDate>
<dc:creator>pointersss</dc:creator>
<og:description>成长&amp;amp;amp;认知 丨 作者 / 袁吴范 这是pointers公众号的第32篇原创文章 今天，团队内一个小伙伴，找到我，跟我说要离职。 第一感觉，感到很惊讶，为啥来了几个月就要离开呢？ 是不是</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/pointers/p/14182292.html</dc:identifier>
</item>
<item>
<title>【Tomcat】Tomcat原理与系统架构 - 邓晓晖</title>
<link>http://www.cnblogs.com/isdxh/p/14182278.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/isdxh/p/14182278.html</guid>
<description>&lt;h2 id=&quot;版本：&quot;&gt;版本：&lt;/h2&gt;
&lt;p&gt;&lt;a href=&quot;https://archive.apache.org/dist/tomcat/tomcat-8/v8.5.50/&quot; target=&quot;_blank&quot;&gt;https://archive.apache.org/dist/tomcat/tomcat-8/v8.5.50/&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;一，目录说明&quot;&gt;一，目录说明&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;https://typora-files.oss-cn-beijing.aliyuncs.com/file/image-20201223212212784.png&quot; alt=&quot;image-20201223212212784&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;bin/&lt;br/&gt;bin目录下关注两个文件：启动和停止的脚本文件&lt;br/&gt;启动：&lt;code&gt;startup.bat&lt;/code&gt;(win)，&lt;code&gt;startup.sh&lt;/code&gt;(Linux &amp;amp; Mac)&lt;br/&gt;停止：&lt;code&gt;shutdown.bat&lt;/code&gt;(win)，&lt;code&gt;shutdown.sh&lt;/code&gt;(Linux &amp;amp; Mac)&lt;/li&gt;
&lt;li&gt;conf/ 配置文件存放的目录&lt;br/&gt;&lt;code&gt;logging.properties&lt;/code&gt;：日志的配置&lt;br/&gt;&lt;code&gt;server.xml&lt;/code&gt;：服务器配置文件，例如端口的指定&lt;br/&gt;&lt;code&gt;tomcat-users.xml&lt;/code&gt;：定义了tomcat的角色以及角色拥有的功能&lt;br/&gt;&lt;code&gt;web.xml&lt;/code&gt;：全局配置，很熟悉，我们java web工程也有自己的web.xml，这个是Tomcat级别的，自己的web.xml如果和它重复那么自己的会覆盖Tomcat的。&lt;/li&gt;
&lt;li&gt;lib/ 存放jar包&lt;br/&gt;tomcat本身也是基于java开发的，它的运行也依赖于一些基础的jar包&lt;/li&gt;
&lt;li&gt;logs/ 存放日志&lt;/li&gt;
&lt;li&gt;temp/ 临时目录&lt;/li&gt;
&lt;li&gt;webapps/ 默认发布项目的目录&lt;br/&gt;当我们发布一个项目时，需要把我们项目的jar包（如发布jar包，它会解压出来）或者文件存放在该目录&lt;/li&gt;
&lt;li&gt;work/ jsp编译运行存放过程文件的目录&lt;/li&gt;
&lt;/ul&gt;&lt;h2 id=&quot;二，浏览器访问服务器的流程&quot;&gt;二，浏览器访问服务器的流程&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Http请求的处理过程：&lt;/strong&gt;&lt;br/&gt;&lt;img src=&quot;https://typora-files.oss-cn-beijing.aliyuncs.com/file/image-20201223213708344.png&quot; alt=&quot;image-20201223213708344&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;http请求只是定义了数据的组织格式（通讯格式），是一个应用层协议，数据传输依靠的是TCP/IP协议。&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;用户发起请求（url地址、点击、搜索等）动作被&lt;strong&gt;浏览器&lt;/strong&gt;捕获&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;浏览器&lt;/strong&gt;发送TCP连接请求，到服务器（socket处理）&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;服务器&lt;/strong&gt;接收请求并建立连接（三次握手）&lt;/li&gt;
&lt;li&gt;连接上之后，&lt;strong&gt;浏览器&lt;/strong&gt;生成Http协议格式（比如说定义请求头里放xxxx，请求体里放xxxxx）的数据包&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;浏览器&lt;/strong&gt;发送请求数据包（也是依靠TCP协议）&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;服务器&lt;/strong&gt;解析Http格式的数据包&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;服务器&lt;/strong&gt;执行请求完成业务逻辑&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;服务器&lt;/strong&gt;生成Http协议格式的数据包&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;服务器&lt;/strong&gt;发送响应数据包（同样依靠TCP协议）&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;浏览器&lt;/strong&gt;解析Http格式的数据包&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;浏览器&lt;/strong&gt;呈现静态数据给用户&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;传输的形式：&lt;br/&gt;&lt;img src=&quot;https://typora-files.oss-cn-beijing.aliyuncs.com/file/image-20201223214317941.png&quot; alt=&quot;image-20201223214317941&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h2 id=&quot;三，tomcat系统总体架构&quot;&gt;三，Tomcat系统总体架构&lt;/h2&gt;
&lt;h3 id=&quot;31-tomcat请求的大致流程&quot;&gt;3.1 Tomcat请求的大致流程&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Tomcat是一个Http服务器(因为它能够接收处理Http请求)&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;我们使⽤浏览器向某⼀个⽹站发起请求，发出的是Http请求，那么在远程，Http服务器接收到这个请求之后，会调⽤具体的程序（Java类）进⾏处理，往往不同的请求由不同的Java类完成处理。&lt;br/&gt;&lt;img src=&quot;https://typora-files.oss-cn-beijing.aliyuncs.com/file/image-20201223221200909.png&quot; alt=&quot;image-20201223221200909&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;大致流程：&lt;/strong&gt;与上图不同，增加了Servlet容器解耦&lt;br/&gt;&lt;img src=&quot;https://typora-files.oss-cn-beijing.aliyuncs.com/file/image-20201223221419723.png&quot; alt=&quot;image-20201223221419723&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;HTTP 服务器接收到请求之后把请求交给Servlet容器来处理，Servlet 容器通过Servlet接⼝调⽤业务类。&lt;strong&gt;Servlet接⼝和Servlet容器这⼀整套内容叫作Servlet规范。&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote readability=&quot;10&quot;&gt;
&lt;p&gt;注意：Tomcat既按照Servlet规范的要求去实现了Servlet容器，同时它也具有HTTP服务器的功能。&lt;/p&gt;
&lt;p&gt;Tomcat的两个重要身份&lt;/p&gt;
&lt;p&gt;1）http服务器&lt;/p&gt;
&lt;p&gt;2）Tomcat是⼀个Servlet容器&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&quot;32-servlet容器处理请求流程&quot;&gt;3.2 Servlet容器处理请求流程&lt;/h3&gt;
&lt;p&gt;当⽤户请求某个URL资源时&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;HTTP服务器会把请求信息封装成Request对象，然后转换为&lt;strong&gt;ServletRequest&lt;/strong&gt;对象&lt;/li&gt;
&lt;li&gt;进⼀步去调⽤Servlet容器中某个具体的&lt;strong&gt;Servlet&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;在 2中，Servlet容器拿到请求后，根据URL和Servlet的映射关系，找到相应的Servlet&lt;/li&gt;
&lt;li&gt;如果Servlet还没有被加载，就⽤反射机制创建这个Servlet，并调⽤Servlet的init⽅法来完成初始化（反射）&lt;/li&gt;
&lt;li&gt;接着调⽤这个具体Servlet的service⽅法来处理请求，请求处理结果使⽤ServletResponse对象封装&lt;/li&gt;
&lt;li&gt;把ServletResponse对象返回给HTTP服务器，HTTP服务器会把响应发送给客户端&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;&lt;img src=&quot;https://typora-files.oss-cn-beijing.aliyuncs.com/file/image-20201223222637232.png&quot; alt=&quot;image-20201223222637232&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h3 id=&quot;33-tomcat系统总体架构&quot;&gt;3.3 Tomcat系统总体架构&lt;/h3&gt;
&lt;p&gt;从上可以看出，Tomcat两个重要的功能：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;和客户端浏览器进⾏交互，进⾏socket通信，将字节流和Request/Response等对象进⾏转换&lt;/li&gt;
&lt;li&gt;Servlet容器处理业务逻辑&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;Tomcat 设计了两个核⼼组件&lt;strong&gt;连接器（Connector）&lt;/strong&gt;和&lt;strong&gt;容器（Container）&lt;/strong&gt;来完成 Tomcat 的两⼤核⼼功能：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;连接器&lt;/strong&gt;，负责对外交流： 处理Socket连接，负责⽹络字节流与Request和Response对象的转化；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;容器&lt;/strong&gt;，负责内部处理：加载和管理Servlet，以及具体处理Request请求；&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;img src=&quot;https://typora-files.oss-cn-beijing.aliyuncs.com/file/image-20201223222843720.png&quot; alt=&quot;image-20201223222843720&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h2 id=&quot;四，tomcat连接器组件coyote&quot;&gt;四，Tomcat连接器组件Coyote&lt;/h2&gt;
&lt;h3 id=&quot;41-简介&quot;&gt;4.1 简介&lt;/h3&gt;
&lt;p&gt;Coyote 是Tomcat 中连接器的组件名称 , 是对外的接⼝。客户端通过Coyote与服务器建⽴连接、发送请求并接受响应 。&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;Coyote 封装了底层的⽹络通信（Socket 请求及响应处理）&lt;/li&gt;
&lt;li&gt;Coyote 使&lt;strong&gt;Catalina 容器（容器组件的名称）&lt;/strong&gt;与具体的请求协议及IO操作⽅式完全解耦&lt;/li&gt;
&lt;li&gt;Coyote 将Socket 输⼊转换&lt;strong&gt;封装为 Request 对象&lt;/strong&gt;，进⼀步封装后（&lt;strong&gt;再次封装为ServletRequest&lt;/strong&gt;）交由Catalina 容器进⾏处理，处理请求完成后, Catalina 通过Coyote 提供的Response 对象将结果写⼊输出流&lt;/li&gt;
&lt;li&gt;Coyote 负责的是具体&lt;strong&gt;协议（应⽤层）&lt;/strong&gt;和&lt;strong&gt;IO（传输层）&lt;/strong&gt;相关内容&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;&lt;img src=&quot;https://typora-files.oss-cn-beijing.aliyuncs.com/file/image-20201223224257261.png&quot; alt=&quot;image-20201223224257261&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Tomcat Coyote支持的IO模型与协议：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://typora-files.oss-cn-beijing.aliyuncs.com/file/image-20201223224941404.png&quot; alt=&quot;image-20201223224941404&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;应用层默认协议：HTTP/1.1&lt;br/&gt;传输层默认IO模型：NIO&lt;/p&gt;
&lt;blockquote readability=&quot;7&quot;&gt;
&lt;p&gt;在 8.0 之前 ，Tomcat 默认采⽤的I/O⽅式为 BIO（同步阻塞IO），之后改为 NIO。 无论 NIO、NIO2 还是 APR， 在性能⽅⾯均优于以往的BIO。 如果采⽤APR， 甚⾄可以达到 Apache HTTP Server 的影响性能。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&quot;42-coyote内部组件以及流程&quot;&gt;4.2 Coyote内部组件以及流程&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;https://typora-files.oss-cn-beijing.aliyuncs.com/file/image-20201223230210550.png&quot; alt=&quot;image-20201223230210550&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;组件&lt;/th&gt;
&lt;th&gt;作用描述&lt;/th&gt;
&lt;/tr&gt;&lt;/thead&gt;&lt;tbody readability=&quot;8.5&quot;&gt;&lt;tr readability=&quot;3&quot;&gt;&lt;td&gt;&lt;strong&gt;EndPoint&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;EndPoint 是 Coyote 通信端点，即&lt;strong&gt;通信监听的接⼝&lt;/strong&gt;，是&lt;strong&gt;具体Socket接收和发送处理器&lt;/strong&gt;，是&lt;strong&gt;对传输层的抽象&lt;/strong&gt;，因此EndPoint⽤来&lt;strong&gt;实现TCP/IP协议&lt;/strong&gt;的&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;5&quot;&gt;&lt;td&gt;&lt;strong&gt;Processor&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;Processor 是Coyote 协议处理接⼝ ，如果说EndPoint是⽤来实现TCP/IP协议的，那么Processor&lt;strong&gt;⽤来实现HTTP协议&lt;/strong&gt;，Processor接收来⾃EndPoint的 Socket，读取字节流&lt;strong&gt;解析成Tomcat Request和Response对象&lt;/strong&gt;，并&lt;strong&gt;通过 Adapter将其提交到容器&lt;/strong&gt;处理，Processor是&lt;strong&gt;对应⽤层协议的抽象&lt;/strong&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;4&quot;&gt;&lt;td&gt;&lt;strong&gt;ProtocolHandler&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;Coyote 协议接⼝， 通过Endpoint 和 Processor ， 实现针对具体协议的处 理能⼒。Tomcat 按照协议和I/O 提供了6个实现类 ： &lt;strong&gt;AjpNioProtocol&lt;/strong&gt; ， &lt;strong&gt;AjpAprProtocol&lt;/strong&gt;， &lt;strong&gt;AjpNio2Protocol&lt;/strong&gt; ， &lt;strong&gt;Http11NioProtocol&lt;/strong&gt; ， &lt;strong&gt;Http11Nio2Protocol&lt;/strong&gt; ，&lt;strong&gt;Http11AprProtocol&lt;/strong&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;5&quot;&gt;&lt;td&gt;&lt;strong&gt;Adapter&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;由于协议不同，客户端发过来的请求信息也不尽相同，Tomcat定义了⾃⼰的 Request类来封装这些请求信息。ProtocolHandler接⼝负责解析请求并⽣成 Tomcat Request类。但是这个Request对象不是标准的ServletRequest，不能⽤Tomcat Request作为参数来调⽤容器。Tomcat设计者的解决⽅案是引⼊CoyoteAdapter，这是&lt;strong&gt;适配器模式的经典运⽤&lt;/strong&gt;，连接器调⽤ CoyoteAdapter的Sevice⽅法，传⼊的是Tomcat Request对象， CoyoteAdapter负责&lt;strong&gt;将Tomcat Request转成ServletRequest&lt;/strong&gt;，&lt;strong&gt;再调⽤容器&lt;/strong&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;h2 id=&quot;五，tomcat-servlet-容器-catalina&quot;&gt;五，Tomcat Servlet 容器 Catalina&lt;/h2&gt;
&lt;h3 id=&quot;51--tomcat模块分层结构图及catalina位置&quot;&gt;5.1 Tomcat模块分层结构图及Catalina位置&lt;/h3&gt;
&lt;p&gt;Tomcat是⼀个由⼀系列可配置（conf/server.xml）的组件构成的Web容器，⽽Catalina是Tomcat的servlet容器。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Tomcat本质上就是⼀款Servlet容器&lt;/strong&gt;， 因为&lt;strong&gt;Catalina才是Tomcat的核⼼&lt;/strong&gt; ， &lt;strong&gt;其他模块都是为Catalina 提供⽀撑的&lt;/strong&gt;。 ⽐如 ：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;通过 Coyote 模块提供链接通信&lt;/li&gt;
&lt;li&gt;Jasper 模块提供 JSP 引擎&lt;/li&gt;
&lt;li&gt;Naming 提供JNDI 服务&lt;/li&gt;
&lt;li&gt;Juli 提供⽇志服务。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;模块分层结构图：&lt;/strong&gt;&lt;br/&gt;&lt;img src=&quot;https://typora-files.oss-cn-beijing.aliyuncs.com/file/image-20201223235736095.png&quot; alt=&quot;image-20201223235736095&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h3 id=&quot;52-servlet容器catalina结构&quot;&gt;5.2 Servlet容器Catalina结构&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;也可以这么说：Tomcat就是一个Catalina的实例，因为Catalina是Tomcat的核心。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Tomcat/Catalina实例:&lt;br/&gt;&lt;img src=&quot;https://typora-files.oss-cn-beijing.aliyuncs.com/file/image-20201224001249519.png&quot; alt=&quot;image-20201224001249519&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;Tomcat 启动的时候会初始化这个实例，Catalina 实例通过加载server.xml完成其他实例的创建，创建并管理⼀个Server，Server创建并管理多个服务， 每个服务⼜可以有多个Connector和⼀个Container。&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;⼀个Catalina实例（容器）&lt;/li&gt;
&lt;li&gt;⼀个&lt;strong&gt;Server&lt;/strong&gt;实例（容器）&lt;/li&gt;
&lt;li&gt;多个&lt;strong&gt;Service&lt;/strong&gt;实例（容器）&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;对应关系：每⼀个Service实例下可以有多个Connector实例和⼀个Container实例&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Catalina&lt;/strong&gt;&lt;br/&gt;负责解析Tomcat的配置⽂件（server.xml） , 以此来创建服务器Server组件并进⾏管理&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Server&lt;/strong&gt;&lt;br/&gt;服务器表示整个Catalina Servlet容器以及其它组件，负责组装并启动Servlet引擎、Tomcat连接器。Server通过实现&lt;code&gt;Lifecycle&lt;/code&gt;接⼝，提供了⼀种优雅的启动和关闭整个系统的⽅式&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Service&lt;/strong&gt;&lt;br/&gt;服务是Server内部的组件，⼀个Server包含多个Service。它将若⼲个Connector组件绑定到⼀个 Container&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Container&lt;/strong&gt;&lt;br/&gt;容器，负责处理⽤户的servlet请求，并返回对象给web⽤户的模块&lt;/li&gt;
&lt;/ul&gt;&lt;h3 id=&quot;52-container组件的具体结构&quot;&gt;5.2 Container组件的具体结构&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;https://typora-files.oss-cn-beijing.aliyuncs.com/file/image-20201224002346585.png&quot; alt=&quot;image-20201224002346585&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;Container组件下有⼏种具体的组件，分别是&lt;strong&gt;Engine&lt;/strong&gt;、&lt;strong&gt;Host&lt;/strong&gt;、&lt;strong&gt;Context&lt;/strong&gt;和&lt;strong&gt;Wrapper&lt;/strong&gt;。这4种组件（容器） 是⽗⼦关系。Tomcat通过⼀种分层的架构，使得Servlet容器具有很好的灵活性。&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Engine&lt;/strong&gt;&lt;br/&gt;表示整个Catalina的Servlet引擎，⽤来管理多个虚拟站点，⼀个Service最多只能有⼀个Engine， 但是⼀个引擎可包含多个Host&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Host&lt;/strong&gt;&lt;br/&gt;代表⼀个虚拟主机，或者说⼀个站点，可以给Tomcat配置多个虚拟主机地址，⽽⼀个虚拟主机下 可包含多个Context&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Context&lt;/strong&gt;&lt;br/&gt;表示⼀个Web应⽤程序， ⼀个Web应⽤可包含多个Wrapper&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Wrapper&lt;/strong&gt;&lt;br/&gt;表示⼀个Servlet，Wrapper 作为容器中的最底层，不能包含⼦容器&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;上述组件的配置其实就体现在conf/server.xml中。&lt;/strong&gt;&lt;br/&gt;&lt;img src=&quot;https://typora-files.oss-cn-beijing.aliyuncs.com/file/image-20201224002723935.png&quot; alt=&quot;image-20201224002723935&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
</description>
<pubDate>Wed, 23 Dec 2020 16:30:00 +0000</pubDate>
<dc:creator>邓晓晖</dc:creator>
<og:description>版本： https://archive.apache.org/dist/tomcat/tomcat-8/v8.5.50/ 一，目录说明 bin/ bin目录下关注两个文件：启动和停止的脚本文件 启动：</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/isdxh/p/14182278.html</dc:identifier>
</item>
<item>
<title>k8s之深入解剖Pod（三） - Liusy01</title>
<link>http://www.cnblogs.com/liusy01/p/14182153.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/liusy01/p/14182153.html</guid>
<description>&lt;p&gt;目录：&lt;/p&gt;
&lt;p&gt;Pod的调度&lt;/p&gt;
&lt;p&gt;Pod的扩容和缩容&lt;/p&gt;
&lt;p&gt;Pod的滚动升级&lt;/p&gt;

&lt;p&gt;Pod只是容器的载体，通常需要通过RC、Deployment、DaemonSet、Job等对象来完成Pod的调度和自动控制功能。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;1、RC、Deployment全自动调度&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;RC的主要功能之一就是自动部署一个容器应用的多份副本，以及持续监控副本的数量，在集群内始终维持用户指定的副本数量。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2、NodeSelector：定向调度&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Master上的Schedule负责实现Pod的调度，但无法知道Pod会调度到哪个节点上。可以通过Node的标签（Label）和Pod的nodeSelector属性相匹配，达到将Pod调度到指定的Node上。&lt;/p&gt;
&lt;p&gt;（1）首先通过kubectl label命令给目标Node打上标签&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;32&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
kubectl label nodes node-name key=value
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;例如这边给cnode-2和cnode-3添加标签&lt;/p&gt;
&lt;div class=&quot;pgc-img&quot;&gt;&lt;img src=&quot;https://p6-tt-ipv6.byteimg.com/img/pgc-image/03b6df315f164280ac4f95898adab2cf~tplv-tt-shrink:640:0.image&quot;/&gt;&lt;p class=&quot;pgc-img-caption&quot;&gt; &lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;查看是否已打上标签可以使用如下命令&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;32&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
kubelct describe nodes node-name
&lt;/pre&gt;&lt;/div&gt;

&lt;div class=&quot;pgc-img&quot;&gt;&lt;img src=&quot;https://p26-tt.byteimg.com/img/pgc-image/e7abf9dc83d845c7ba83e7f2a8a8967c~tplv-tt-shrink:640:0.image&quot;/&gt;&lt;p class=&quot;pgc-img-caption&quot;&gt; &lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;（2）在Pod定义上添加nodeSelector的设置，&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;35&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
apiVersion: v1
kind: ReplicationController
metadata:
  name: nodeselectorrc
  labels:
    name: nodeselectorrc
spec:
  replicas: 1
  template:
    metadata:
      name: nodeselectorrc
      labels:
        name: nodeselectorrc
    spec:
      containers:
      - name: nodeselectorrc
        image: nginx
        imagePullPolicy: IfNotPresent
        ports:
        - containerPort: 80
      nodeSelector:
        name: cnode-2
&lt;/pre&gt;&lt;/div&gt;

&lt;div class=&quot;pgc-img&quot;&gt;&lt;img src=&quot;https://p26-tt.byteimg.com/img/pgc-image/7eae1fcfdb524a1e8c896ad46629ce64~tplv-tt-shrink:640:0.image&quot;/&gt;&lt;p class=&quot;pgc-img-caption&quot;&gt; &lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;【注】如果没有节点有这个标签，那么Pod会无法进行调度&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;3、NodeAffinity：亲和性调度&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;由于NodeSelector通过Node的label进行精确匹配，所以NodeAffinity增加了In，NotIn，Exists、DoesNotExist、Gt、Lt等操作符来选择Node，能够使调度更加灵活，同时在NodeAffinity中将增加一些信息来设置亲和性调度策略&lt;/p&gt;
&lt;p&gt;（1）RequiredDuringSchedulingIgnoredDuringExecution：必须满足指定的规则才可以调度Pod到Node上&lt;/p&gt;
&lt;p&gt;（2）PreferredDuringSchedulingIngoredDuringExecution：强调优选满足指定规则，调度器尝试将Pod调度到Node上，但不强求，多个优先级规则还可以设置权重，以定义执行的选后顺序。&lt;/p&gt;
&lt;p&gt;需要在Pod的metadata.annotations中设置NodeAffinity的内容，例如&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;34&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
spec:
  affinity:
    nodeAffinity:
      preferredDuringSchedulingIngoredDuringExecution:
      - weight: 1
        preference:
          matchExpressions:
          - key: name
            operator: In
            values: [&quot;cnode-1&quot;,&quot;cnode-2&quot;]
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;上述yaml脚本是说明只有Node的label中包含key=name，并且值并非是[&quot;cnode-1&quot;,&quot;cnode-2&quot;]中的一个，才能成为Pod的调度目标，其中操作符还有In，Exists，DoesNotExist，Gt，Lt。&lt;/p&gt;
&lt;div class=&quot;pgc-img&quot;&gt;&lt;img src=&quot;https://p26-tt.byteimg.com/img/pgc-image/16c051879fc04c03a288013afa42f3e2~tplv-tt-shrink:640:0.image&quot;/&gt;&lt;p class=&quot;pgc-img-caption&quot;&gt; &lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;PreferredDuringSchedulingIngoredDuringExecution使用如下：&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;34&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
spec:
  affinity:
    nodeAffinity:
      preferredDuringSchedulingIngoredDuringExecution:
      - weight: 1
        preference:
          matchExpressions:
          - key: name
            operator: In
            values: [&quot;cnode-1&quot;,&quot;cnode-2&quot;]
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;4、DaemonSet：特定场景调度&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;用于管理在集群中每个Node上仅运行一份Pod的副本实例&lt;/p&gt;
&lt;div class=&quot;pgc-img&quot;&gt;&lt;img src=&quot;https://p1-tt-ipv6.byteimg.com/img/pgc-image/d319f4181d3243e4be207a821d5d8df7~tplv-tt-shrink:640:0.image&quot;/&gt;&lt;p class=&quot;pgc-img-caption&quot;&gt; &lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;适合以下场景：&lt;/p&gt;
&lt;p&gt;1、在每个Node上运行GlusterFS存储或者Ceph存储的daemon进程&lt;/p&gt;
&lt;p&gt;2、每个Node上运行一个日志采集程序 ，例如fluentd或者logstach。&lt;/p&gt;
&lt;p&gt;3、每个Node上运行一个健康程序，采集该Node的运行性能数据，例如Prometheus node Exporter&lt;/p&gt;
&lt;p&gt;调度策略于RC类似，也可使用NodeSelector或者NodeAffinity来进行调度&lt;/p&gt;
&lt;p&gt;例如：为每个Node上启动一个nginx&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;34&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: ds-nginx
  labels:
    name: ds-nginx
spec:
  selector:
    matchLabels:
      name: ds-nginx
  template:
    metadata:
      name: ds-nginx
      labels:
        name: ds-nginx
    spec:
      containers:
      - name: ds-nginx
        image: nginx
        imagePullPolicy: IfNotPresent
        ports:
        - containerPort: 80
&lt;/pre&gt;&lt;/div&gt;

&lt;div class=&quot;pgc-img&quot;&gt;&lt;img src=&quot;https://p6-tt-ipv6.byteimg.com/img/pgc-image/d5e353f08dcd4190b04a9936fe2c09f1~tplv-tt-shrink:640:0.image&quot;/&gt;&lt;p class=&quot;pgc-img-caption&quot;&gt; &lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;5、Job批处理调度&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;可通过Job资源对象定义并启动一个批处理任务，通常并行或串行启动多个计算进程去处理一批工作任务，处理完成后，整个批处理任务结束。&lt;/p&gt;
&lt;p&gt;按照批处理任务实现方式的不同，可分为如下几种模式 ：&lt;/p&gt;
&lt;div class=&quot;pgc-img&quot;&gt;&lt;img src=&quot;https://p9-tt-ipv6.byteimg.com/img/pgc-image/676511543290466bb846cae1cce01179~tplv-tt-shrink:640:0.image&quot;/&gt;&lt;p class=&quot;pgc-img-caption&quot;&gt; &lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;1、Job Template Expansion模式：一个Job对象对应一个待处理的Work Item，有几个Work item就产生几个独立的Job，适合Work item少，每个Work item要处理的数据量比较大的场景&lt;/p&gt;
&lt;p&gt;例如：定义一个Job模板，job.yaml.txt&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;37&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
apiVersion: batch/v1
kind: Job
metadata:
  name: process-item-$ITEM
  labels:
    jobgroup: jobexample
spec:
  template:
    metadata:
      name: jobexample
      labels:
        jobgroup: jobexample
    spec:
      containers:
      - name: c
        image: busybox
        imagePullPolicy: IfNotPresent
        command: [&quot;sh&quot;,&quot;-c&quot;,&quot;echo $Item &amp;amp;&amp;amp; sleep 5&quot;]
      restartPolicy: Never
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class=&quot;syl-page-code hljs bash&quot;&gt;
&lt;code/&gt;
&lt;/pre&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;32&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
for i in a b c; do cat job.yaml.txt | sed &quot;s/\$ITEM/${i}/&quot; &amp;gt; ./job-$i.yaml; done
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class=&quot;syl-page-code hljs bash&quot;&gt;
&lt;code/&gt;
&lt;/pre&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;32&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
kubectl get jobs -l jobgroup=jobexample
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;2、Queue with Pod Per Work Item模式：采用一个任务队列存放Work Item，一个Job作为消费者去完成这些Work item，此模式下，Job会启动N个Pod，每个Pod对应一个WorkItem&lt;/p&gt;
&lt;p&gt;3、Queue with Variable Pod Count模式：采用一个任务队列存放Work Item，一个Job作为消费者去完成这些Work item，Job启动的Pod数量是可变的&lt;/p&gt;
&lt;p&gt;4、Single Job with Static Work Assignment模式：一个Job产生多个Pod，采用程序静态方式分配任务项&lt;/p&gt;
&lt;p&gt;考虑到批处理的并行问题，k8s将job分为以下三种类型：&lt;/p&gt;
&lt;p&gt;1、Non-parallel Jobs&lt;/p&gt;
&lt;p&gt;一个Job只启动一个Pod，除非Pod异常，才会 重启该Pod，一旦 Pod正常结束，Job将结束。&lt;/p&gt;
&lt;p&gt;2、Parallel Jobs with a fixed completion count&lt;/p&gt;
&lt;p&gt;并行job会 启动多个Pod，需要设定Pod的参数.spec.completions为一个正数，当正常 结束的Pod数量达到此数时，Job结束，同时此参数用于控制并行度，即同时启动几个Job来处理Work item&lt;/p&gt;
&lt;p&gt;3、Parallel Jobs with a work queue&lt;/p&gt;
&lt;p&gt;任务队列的并行job需要一个独立的队列，work item都在一个队列中存放，不能设置job的 .spec.completions参数，此时job有以下一些特性&lt;/p&gt;
&lt;p&gt;（1）每个Pod能独立判断和决定是否还有任务项需要储里&lt;/p&gt;
&lt;p&gt;（2）如果某个Pod能正常结束，则Job不会在启动新的Pod&lt;/p&gt;
&lt;p&gt;（3）如果一个Pod成功结束，则此时应该不存在其他Pod还在干活 的情况，应该都处于即将结束 、退出的状态 。&lt;/p&gt;
&lt;p&gt;（4）如果 所有Pod都结束了，且至少有一个Pod成功结束，则整个Job才算成功 结束。&lt;/p&gt;
&lt;p&gt;另外，k8s从1.12版本后给job加入了ttl控制，当pod完成任务后，自动进行Pod的关闭，资源回收。&lt;/p&gt;


&lt;p&gt;&lt;strong&gt;6、Cronjob：定时任务&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;能根据设定的定时表达式定时调度Pod&lt;/p&gt;
&lt;p&gt;（1）Cron Job的定时表达式（与Linux的基本相同）&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;32&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
Minutes Hours DayOfMonth Month DayOfWeek Year
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;其中每个域都可出现的字符如下。&lt;/p&gt;
&lt;p&gt;◎ Minutes：可出现【,-*/】这4个字符，有效范围为0～59的整数。&lt;/p&gt;
&lt;p&gt;◎ Hours：可出现【,-*/】这4个字符，有效范围为0～23的整 数。&lt;/p&gt;
&lt;p&gt;◎ DayofMonth：可出现【,-*/?LWC】这8个字符，有效范围为0～31的整数。&lt;/p&gt;
&lt;p&gt;◎ Month：可出现【,-*/】这4个字符，有效范围为1～12的整数或JAN～DEC。&lt;/p&gt;
&lt;p&gt;◎ DayofWeek：可出现【,-*/?LC#】这8个字符，有效范围为1～7的整数或SUN～SAT。1表示星期天，2表示星期一，以此类推&lt;/p&gt;
&lt;p&gt;◎ *：表示匹配该域的任意值，假如在Minutes域使用，则表示每分钟都会触发事件。&lt;/p&gt;
&lt;p&gt;◎ /：表示从起始时间开始触发，然后每隔固定时间触发一次，例如在Minutes域设置为5/20，则意味着第1次触发在第5min时，接下来每20min触发一次&lt;/p&gt;
&lt;p&gt;◎ -：指定一个整数范围。譬如，1-4 意味着整数 1、2、3、4。&lt;br/&gt;◎ ,：隔开的一系列值指定一个列表。譬如3, 4, 6, 8 标明这四个指定的整数。&lt;/p&gt;
&lt;p&gt;比如需要每分钟执行一次：&lt;/p&gt;
&lt;pre class=&quot;syl-page-code hljs markdown&quot;&gt;
&lt;code&gt;&lt;span class=&quot;hljs-emphasis&quot;&gt;*/1 * &lt;span class=&quot;hljs-emphasis&quot;&gt;* * * &lt;/span&gt;&lt;/span&gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;（2）创建Cron Job&lt;/p&gt;
&lt;p&gt;使用yaml文件&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;36&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
apiVersion: batch/v1beta1
kind: CronJob
metadata:
  name: hello
spec:
  schedule: &quot;*/1 * * * *&quot;
  jobTemplate:
    spec:
      template:
        spec:
          containers:
          - name: hello
            image: busybox
            command: [&quot;/bin/bash&quot;,&quot;-c&quot;,&quot;date;echo Hello&quot;]
          restartPolicy: OnFailure
&lt;/pre&gt;&lt;/div&gt;

&lt;div class=&quot;pgc-img&quot;&gt;&lt;img src=&quot;https://p1-tt-ipv6.byteimg.com/img/pgc-image/082f60fb906d4197adc20d273011dbef~tplv-tt-shrink:640:0.image&quot;/&gt;&lt;p class=&quot;pgc-img-caption&quot;&gt; &lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;7、PodAffinity：Pod亲和与互斥调度策略&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;根据在节点上正在运行的 Pod的标签而不是节点的标签进行判断和调度，要求对节点和Pod两个条 件进行匹配。这种规则可以描述为：如果在具有标签X的Node上运行了一个或者多个符合条件Y的Pod，那么Pod应该（如果是互斥的情况，那么就变成拒绝）运行在这个Node上。&lt;/p&gt;
&lt;p&gt;这里X指的是一个集群中的节点、机架、区域等概念，通过 Kubernetes内置节点标签中的key来进行声明。这个key的名字为 topologyKey，意为表达节点所属的topology范围。&lt;/p&gt;
&lt;p&gt;◎ kubernetes.io/hostname&lt;/p&gt;
&lt;p&gt;◎ failure-domain.beta.kubernetes.io/zone&lt;/p&gt;
&lt;p&gt;◎ failure-domain.beta.kubernetes.io/region&lt;/p&gt;
&lt;p&gt;与节点不同的是，Pod是属于某个命名空间的，所以条件Y表达的 是一个或者全部命名空间中的一个Label Selector。&lt;/p&gt;
&lt;p&gt;和节点亲和相同，Pod亲和与互斥的条件设置也是requiredDuringSchedulingIgnoredDuringExecution和 preferredDuringSchedulingIgnoredDuringExecution。&lt;/p&gt;
&lt;p&gt;Pod的亲和性被定义于PodSpec的affinity字段下的podAffinity子字段中。Pod间的互斥性则被定义于同一层次的podAntiAffinity子字段中。&lt;/p&gt;
&lt;p&gt;例如：&lt;/p&gt;
&lt;p&gt;参照目标Pod&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;33&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
apiVerison: v1
kind: Pod
metadata:
  name: pod-flag
  labels:
    security: s1
    app: nginx
spec:
  containers:
  - name: nginx
    image: nginx
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;（1）Pod亲和性调度&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;34&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
apiVersion: v1
kind: Pod
metadata:
  name: pod-affinity
spec:
  affinity:
    podAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
      - labelSelector:
          matchExpressions:
          - key: security
            operator: In
            values: [&quot;s1&quot;]
        topologyKey: kubernetes.io/hostname
  containers:
  - name: nginx
    image: nginx
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;创建之后会发现两个Pod在同一个节点上&lt;/p&gt;
&lt;div class=&quot;pgc-img&quot;&gt;&lt;img src=&quot;https://p26-tt.byteimg.com/img/pgc-image/56bdb2e06d9247e3aa1761b3478403db~tplv-tt-shrink:640:0.image&quot;/&gt;&lt;p class=&quot;pgc-img-caption&quot;&gt; &lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;（2）Pod互斥性调度&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;34&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
apiVersion: v1
kind: Pod
metadata:
  name: pod-antiaffinity
spec:
  affinity:
    podAntiAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
      - labelSelector:
          matchExpressions:
          - key: security
            operator: In
            values: [&quot;s1&quot;]
        topologyKey: kubernetes.io/hostname
  containers:
  - name: nginx
    image: nginx
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;创建之后会发现这个Pod跟参照Pod不在同一个节点上&lt;/p&gt;
&lt;div class=&quot;pgc-img&quot;&gt;&lt;img src=&quot;https://p6-tt-ipv6.byteimg.com/img/pgc-image/297de541016449bfb107bdb608529659~tplv-tt-shrink:640:0.image&quot;/&gt;&lt;p class=&quot;pgc-img-caption&quot;&gt; &lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;8、Pod Priority Preemption：Pod优先级调度&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;在中大型集群中，为了尽可能提高集群的资源利用率，会采用优先级方案，即不同类型的负载对应不同的优先级，同时允许集群中的所有负载所需的资源总量超过集群可提供的资源，在这种情况下，当发生资源不足的情况时，系统可以选择释放一些不重要的负载（优先级最低的），保障最重要的负载能够获取足够的资源稳定运行。&lt;/p&gt;
&lt;p&gt;如果发生了需要抢占的调度，高优先级Pod就可能抢占节点N，并将其低优先级Pod驱逐出节点N。&lt;/p&gt;
&lt;p&gt;（1）首先创建PriorityClasses&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;33&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
apiVersion: v1
kind: scheduling.k8s.io/v1beta1
metadata:
  name: high-priority
value: 10000
globalDefault: false
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;（2）然后在Pod中引用Pod优先级&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;33&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
apiVersion: v1
kind: Pod
metadata:
  name: nginx-priority
spec:
  containers:
  - name: nginx
    image: nginx
  priorityClassName: high-priority
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;1、通过kubectl scale&lt;/p&gt;
&lt;p&gt;通过kubectl scale进行扩容和缩容，其实就是修改控制器的副本数字段&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;32&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
kubectl scale rc rc-name --replicas=副本数量
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class=&quot;syl-page-code hljs lua&quot;&gt;
&lt;span&gt;比如我将nodeselectorrc扩容为3&lt;/span&gt;
&lt;/pre&gt;
&lt;div class=&quot;pgc-img&quot;&gt;&lt;img src=&quot;https://p6-tt-ipv6.byteimg.com/img/pgc-image/098d00808fcb458b91c103e8f3c38b13~tplv-tt-shrink:640:0.image&quot;/&gt;&lt;p class=&quot;pgc-img-caption&quot;&gt; &lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;缩容也是一样，将副本数量改小就行&lt;/p&gt;
&lt;p&gt;2、Horizontal Pod AutoScale（HPA）&lt;/p&gt;
&lt;p&gt;实现基于cpu使用率进行自动Pod扩缩容，HPA控制器基于Master的kube-controller-manager服务启动参数&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;32&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
--horizontal-pod-authscaler-sync-period
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;定义的时长（默认为30s），周期性的监测目标pod的cpu使用率，并在满足条件时对RC或Deployment中的Pod副本数量进行调整，以符合用户定义的平均Pod CPU使用率&lt;/p&gt;
&lt;p&gt;创建HPA时可以使用kubectl autoscale命令进行快速创建或者使用yaml配置文件进行创建，在创建HPA前，需要已经存在一个RC或者Deployment对象，并且必须定义resources.requests.cpu的资源请求值，如果不设置该值，则heapster将无法采集Pod的cpu使用率&lt;/p&gt;
&lt;p&gt;【注】此方式需要安装heapster进行采集资源的cpu使用率&lt;/p&gt;
&lt;p&gt;命令行方式：&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;32&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
kubectl autoscale rc rc-name --min=1 --max=10 --cpu-percent=50
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;yaml方式：&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;34&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
apiVersion: autoscaling/v1
kind: HorizontalPodAutoscaler
metadata:
  name: hpa-name
spec:
  scaleTargetRef:
    apiVersion: v1
    kind: ReplicationController
    name: rc-name
  minReplicas: 1
  maxReplicas: 10
  targetCPUUtilizationPercentage: 50
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;上述两种方式都是在cpu使用率达到50%的时候进行扩缩容，最小副本数为1，最大副本数为10&lt;/p&gt;

&lt;p&gt;滚动升级通过kubectl rolling-update命令完成，该命令创建了一个RC，然后自动控制旧的RC中的Pod副本的数量逐渐减少至0，同时新的RC中的Pod副本的数量从0逐步增加至目标值，最终实现了Pod的升级。新旧的RC需要在同一个Namespace下。&lt;/p&gt;
&lt;div class=&quot;pgc-img&quot;&gt;&lt;img src=&quot;https://p26-tt.byteimg.com/img/pgc-image/435ca0142854425f98e93510beaf40b7~tplv-tt-shrink:640:0.image&quot;/&gt;&lt;p class=&quot;pgc-img-caption&quot;&gt; &lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;1、使用yaml进行升级&lt;/p&gt;
&lt;p&gt;比如有一个nginx的v1版本：nginx-v1.yaml&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;35&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
apiVersion: v1
kind: ReplicationController
metadata:
  name: roll-v1
  labels:
    name: roll-v1
    version: v1
spec:
  replicas: 3
  selector:
    name: roll-v1
    version: v1
  template:
    metadata:
      name: roll-v1
      labels:
        name: roll-v1
        version: v1
    spec:
      containers:
      - name: roll-v1
        image: nginx
        imagePullPolicy: IfNotPresent
        ports:
        - containerPort: 80
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;创建之后如下：&lt;/p&gt;
&lt;div class=&quot;pgc-img&quot;&gt;&lt;img src=&quot;https://p1-tt-ipv6.byteimg.com/img/pgc-image/5277073b3a8a4fcfacce7bb9b08dd4c5~tplv-tt-shrink:640:0.image&quot;/&gt;&lt;p class=&quot;pgc-img-caption&quot;&gt; &lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;需要将其升级为v2版本：nginx-v2.yaml&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;35&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
apiVersion: v1
kind: ReplicationController
metadata:
  name: roll-v2
  labels:
    name: roll-v2
    version: v2
spec:
  replicas: 3
  selector:
    name: roll-v2
    version: v2
  template:
    metadata:
      name: roll-v2
      labels:
        name: roll-v2
        version: v2
    spec:
      containers:
      - name: roll-v2
        image: nginx
        imagePullPolicy: IfNotPresent
        ports:
        - containerPort: 8080
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;使用如下命令进行升级：&lt;/p&gt;
&lt;pre class=&quot;syl-page-code hljs css&quot;&gt;
&lt;code&gt;&lt;span class=&quot;hljs-selector-tag&quot;&gt;kubectl &lt;span class=&quot;hljs-selector-tag&quot;&gt;rolling-update &lt;span class=&quot;hljs-selector-tag&quot;&gt;roll-v1 &lt;span class=&quot;hljs-selector-tag&quot;&gt;-f &lt;span class=&quot;hljs-selector-tag&quot;&gt;nginx-v2&lt;span class=&quot;hljs-selector-class&quot;&gt;.yaml&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;div class=&quot;pgc-img&quot;&gt;&lt;img src=&quot;https://p9-tt-ipv6.byteimg.com/img/pgc-image/86bec1cede8b4940b874032671f22fa3~tplv-tt-shrink:640:0.image&quot;/&gt;&lt;p class=&quot;pgc-img-caption&quot;&gt; &lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;执行之后会逐步替换掉v1版本的pod&lt;/p&gt;
&lt;div class=&quot;pgc-img&quot;&gt;&lt;img src=&quot;https://p9-tt-ipv6.byteimg.com/img/pgc-image/9524b04f5f6047d2bb34422e8ae03172~tplv-tt-shrink:640:0.image&quot;/&gt;&lt;p class=&quot;pgc-img-caption&quot;&gt; &lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;需要注意的是：&lt;/p&gt;
&lt;p&gt;1、RC的名字不能与旧的RC相同&lt;/p&gt;
&lt;p&gt;2、在selector中至少有一个Label与旧的不同，以表示其是新的RC。（其实是必须所有label不一样）&lt;/p&gt;
&lt;p&gt;2、使用命令方式直接升级&lt;/p&gt;
&lt;p&gt;也可以使用命令行直接替换掉容器的镜像&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;32&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
kubectl rolling-update rc-name --image=image-name:version
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;3、回滚&lt;/p&gt;
&lt;p&gt;当滚动更新出现问题时，可以进行回滚&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;32&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
kubectl rolling-update rc-name --image=image-name:version --rollback
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;===============================&lt;/p&gt;
&lt;p&gt;我是Liusy，一个喜欢健身的程序员。&lt;/p&gt;
&lt;p&gt;欢迎关注微信公众号【Liusy01】，一起交流Java技术及健身，获取更多干货，领取Java进阶干货，领取最新大厂面试资料，一起成为Java大神。&lt;/p&gt;
&lt;p&gt;来都来了，关注一波再溜呗。&lt;/p&gt;
</description>
<pubDate>Wed, 23 Dec 2020 15:49:00 +0000</pubDate>
<dc:creator>Liusy01</dc:creator>
<og:description>目录： Pod的调度 Pod的扩容和缩容 Pod的滚动升级 一、Pod的调度 Pod只是容器的载体，通常需要通过RC、Deployment、DaemonSet、Job等对象来完成Pod的调度和自动控制</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/liusy01/p/14182153.html</dc:identifier>
</item>
<item>
<title>梯度下降法原理及小结 - 早起的小虫子</title>
<link>http://www.cnblogs.com/liuxiaochong/p/14086698.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/liuxiaochong/p/14086698.html</guid>
<description>&lt;p&gt;&lt;span&gt;　　在机器学习的核心内容就是把数据喂给一个人工设计的模型，然后让模型自动的“学习”，从而优化模型自身的各种参数，最终使得在某一组参数下该模型能够最佳的匹配该学习任务。那么这个“学习”的过程就是机器学习算法的关键。梯度下降法就是实现该“学习”过程的一种最常见的方式，尤其是在深度学习(神经网络)模型中，BP反向传播方法的核心就是对每层的权重参数不断使用梯度下降来进行优化。另一种常用的方法是最小二乘法。本文详细介绍梯度下降法。&lt;/span&gt;&lt;/p&gt;

&lt;h2&gt;&lt;span&gt;　　1.1 梯度下降的直观解释&lt;/span&gt;&lt;/h2&gt;
&lt;p&gt;&lt;span&gt;　　首先来看看梯度下降的一个直观的解释。比如我们在一座大山上的某处位置，由于我们不知道怎么下山，于是决定走一步算一步，也就是在每走到一个位置的时候，求解当前位置的梯度，沿着梯度的负方向，也就是当前最陡峭的位置向下走一步，然后继续求解当前位置梯度，向这一步所在位置沿着最陡峭最易下山的位置走一步。这样一步步的走下去，一直走到觉得我们已经到了山脚。当然这样走下去，有可能我们不能走到山脚，而是到了某一个局部的山峰低处。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　　　从上面的解释可以看出，梯度下降不一定能够找到全局的最优解，有可能是一个局部最优解。当然，如果损失函数是凸函数，梯度下降法得到的解就一定是全局最优解。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;img src=&quot;https://images2015.cnblogs.com/blog/1042406/201610/1042406-20161017221342935-1872962415.png&quot; width=&quot;600&quot;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h2&gt;&lt;span&gt;　　1.2 梯度下降的相关概念&lt;/span&gt;&lt;/h2&gt;
&lt;p&gt;&lt;span&gt;　　在详细了解梯度下降的算法之前，我们先看看相关的一些概念。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　1、步长（Learning rate）：步长决定了在梯度下降迭代的过程中，每一步沿梯度负方向前进的长度。用上面下山的例子，步长就是在当前这一步所在位置沿着最陡峭最易下山的位置走的那一步的长度。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　2、特征（feature）：指的是样本中输入部分，比如2个单特征的样本(&lt;em&gt;x&lt;/em&gt;&lt;sup&gt;(0&lt;/sup&gt;&lt;sup&gt;)&lt;/sup&gt;,&lt;em&gt;y&lt;/em&gt;&lt;sup&gt;(0)&lt;/sup&gt;)，(&lt;em&gt;x&lt;/em&gt;&lt;sup&gt;(1)&lt;/sup&gt;,&lt;em&gt;y&lt;/em&gt;&lt;sup&gt;(1)&lt;/sup&gt;)，则第一个样本特征为&lt;em&gt;x&lt;/em&gt;&lt;sup&gt;(0&lt;/sup&gt;&lt;sup&gt;)&lt;/sup&gt;，第一个样本输出为&lt;em&gt;y&lt;/em&gt;&lt;sup&gt;(0)&lt;/sup&gt;。&lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;span id=&quot;MathJax-Element-1-Frame&quot; class=&quot;MathJax&quot; data-mathml=&quot;&amp;lt;math xmlns=&amp;quot;http://www.w3.org/1998/Math/MathML&amp;quot;&amp;gt;&amp;lt;mrow class=&amp;quot;MJX-TeXAtom-ORD&amp;quot;&amp;gt;&amp;lt;mo&amp;gt;&amp;amp;#xFF08;&amp;lt;/mo&amp;gt;&amp;lt;/mrow&amp;gt;&amp;lt;msup&amp;gt;&amp;lt;mi&amp;gt;x&amp;lt;/mi&amp;gt;&amp;lt;mrow class=&amp;quot;MJX-TeXAtom-ORD&amp;quot;&amp;gt;&amp;lt;mo stretchy=&amp;quot;false&amp;quot;&amp;gt;(&amp;lt;/mo&amp;gt;&amp;lt;mn&amp;gt;0&amp;lt;/mn&amp;gt;&amp;lt;mo stretchy=&amp;quot;false&amp;quot;&amp;gt;)&amp;lt;/mo&amp;gt;&amp;lt;/mrow&amp;gt;&amp;lt;/msup&amp;gt;&amp;lt;mo&amp;gt;,&amp;lt;/mo&amp;gt;&amp;lt;msup&amp;gt;&amp;lt;mi&amp;gt;y&amp;lt;/mi&amp;gt;&amp;lt;mrow class=&amp;quot;MJX-TeXAtom-ORD&amp;quot;&amp;gt;&amp;lt;mo stretchy=&amp;quot;false&amp;quot;&amp;gt;(&amp;lt;/mo&amp;gt;&amp;lt;mn&amp;gt;0&amp;lt;/mn&amp;gt;&amp;lt;mo stretchy=&amp;quot;false&amp;quot;&amp;gt;)&amp;lt;/mo&amp;gt;&amp;lt;/mrow&amp;gt;&amp;lt;/msup&amp;gt;&amp;lt;mrow class=&amp;quot;MJX-TeXAtom-ORD&amp;quot;&amp;gt;&amp;lt;mo&amp;gt;&amp;amp;#xFF09;&amp;lt;/mo&amp;gt;&amp;lt;/mrow&amp;gt;&amp;lt;mo&amp;gt;,&amp;lt;/mo&amp;gt;&amp;lt;mrow class=&amp;quot;MJX-TeXAtom-ORD&amp;quot;&amp;gt;&amp;lt;mo&amp;gt;&amp;amp;#xFF08;&amp;lt;/mo&amp;gt;&amp;lt;/mrow&amp;gt;&amp;lt;msup&amp;gt;&amp;lt;mi&amp;gt;x&amp;lt;/mi&amp;gt;&amp;lt;mrow class=&amp;quot;MJX-TeXAtom-ORD&amp;quot;&amp;gt;&amp;lt;mo stretchy=&amp;quot;false&amp;quot;&amp;gt;(&amp;lt;/mo&amp;gt;&amp;lt;mn&amp;gt;1&amp;lt;/mn&amp;gt;&amp;lt;mo stretchy=&amp;quot;false&amp;quot;&amp;gt;)&amp;lt;/mo&amp;gt;&amp;lt;/mrow&amp;gt;&amp;lt;/msup&amp;gt;&amp;lt;mo&amp;gt;,&amp;lt;/mo&amp;gt;&amp;lt;msup&amp;gt;&amp;lt;mi&amp;gt;y&amp;lt;/mi&amp;gt;&amp;lt;mrow class=&amp;quot;MJX-TeXAtom-ORD&amp;quot;&amp;gt;&amp;lt;mo stretchy=&amp;quot;false&amp;quot;&amp;gt;(&amp;lt;/mo&amp;gt;&amp;lt;mn&amp;gt;1&amp;lt;/mn&amp;gt;&amp;lt;mo stretchy=&amp;quot;false&amp;quot;&amp;gt;)&amp;lt;/mo&amp;gt;&amp;lt;/mrow&amp;gt;&amp;lt;/msup&amp;gt;&amp;lt;mrow class=&amp;quot;MJX-TeXAtom-ORD&amp;quot;&amp;gt;&amp;lt;mo&amp;gt;&amp;amp;#xFF09;&amp;lt;/mo&amp;gt;&amp;lt;/mrow&amp;gt;&amp;lt;/math&amp;gt;&quot;&gt;&lt;span class=&quot;MJX_Assistive_MathML&quot;&gt;&lt;br/&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　3、假设函数（hypothesis function）：在监督学习中，为了拟合输入样本，而使用的假设函数，记为$h_{\theta }(x)$。比如对于单个特征的m个样本(&lt;em&gt;x&lt;/em&gt;&lt;sup&gt;(i)&lt;/sup&gt;,&lt;em&gt;y&lt;/em&gt;&lt;sup&gt;(i)&lt;/sup&gt;)(i=1,2,...m)，可以采用拟合函数如下：$h_{\theta }(x)=\theta _{0}+\theta _{1}x$&lt;/span&gt;&lt;span&gt;&lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;span id=&quot;MathJax-Element-4-Frame&quot; class=&quot;MathJax&quot; data-mathml=&quot;&amp;lt;math xmlns=&amp;quot;http://www.w3.org/1998/Math/MathML&amp;quot;&amp;gt;&amp;lt;msub&amp;gt;&amp;lt;mi&amp;gt;h&amp;lt;/mi&amp;gt;&amp;lt;mrow class=&amp;quot;MJX-TeXAtom-ORD&amp;quot;&amp;gt;&amp;lt;mi&amp;gt;&amp;amp;#x03B8;&amp;lt;/mi&amp;gt;&amp;lt;/mrow&amp;gt;&amp;lt;/msub&amp;gt;&amp;lt;mo stretchy=&amp;quot;false&amp;quot;&amp;gt;(&amp;lt;/mo&amp;gt;&amp;lt;mi&amp;gt;x&amp;lt;/mi&amp;gt;&amp;lt;mo stretchy=&amp;quot;false&amp;quot;&amp;gt;)&amp;lt;/mo&amp;gt;&amp;lt;/math&amp;gt;&quot;&gt;&lt;span class=&quot;MJX_Assistive_MathML&quot;&gt; &lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　4、损失函数（loss function）：为了评估模型拟合的好坏，通常用损失函数来度量拟合的程度。损失函数极小化，意味着拟合程度最好，对应的模型参数即为最优参数。在线性回归中，损失函数通常为样本输出和假设函数的差取平方。比如对于m个样本（&lt;em&gt;x&lt;sub&gt;i&lt;/sub&gt;&lt;/em&gt;,&lt;em&gt;y&lt;sub&gt;i&lt;/sub&gt;&lt;/em&gt;)(&lt;em&gt;i&lt;/em&gt;=1,2,..&lt;em&gt;m&lt;/em&gt;),采用线性回归，损失函数为：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;             $J(\theta _{0},\theta _{1})=\sum_{i=1}^{m}(h_{\theta }(x_{i})-y_{i})^{2}$&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt; 　　　其中&lt;em&gt;x&lt;sub&gt;i&lt;/sub&gt;&lt;/em&gt;表示第&lt;em&gt;i&lt;/em&gt;个样本特征，&lt;em&gt;y&lt;sub&gt;i&lt;/sub&gt;&lt;/em&gt;表示第&lt;em&gt;i&lt;/em&gt;个样本对应的输出，$h_{\theta }(x_{i})$为假设函数。&lt;/span&gt;&lt;span&gt;&lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;span id=&quot;MathJax-Element-9-Frame&quot; class=&quot;MathJax&quot; data-mathml=&quot;&amp;lt;math xmlns=&amp;quot;http://www.w3.org/1998/Math/MathML&amp;quot;&amp;gt;&amp;lt;msub&amp;gt;&amp;lt;mi&amp;gt;x&amp;lt;/mi&amp;gt;&amp;lt;mi&amp;gt;i&amp;lt;/mi&amp;gt;&amp;lt;/msub&amp;gt;&amp;lt;/math&amp;gt;&quot;&gt;&lt;span class=&quot;MJX_Assistive_MathML&quot;&gt;&lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;span id=&quot;MathJax-Element-10-Frame&quot; class=&quot;MathJax&quot; data-mathml=&quot;&amp;lt;math xmlns=&amp;quot;http://www.w3.org/1998/Math/MathML&amp;quot;&amp;gt;&amp;lt;msub&amp;gt;&amp;lt;mi&amp;gt;y&amp;lt;/mi&amp;gt;&amp;lt;mi&amp;gt;i&amp;lt;/mi&amp;gt;&amp;lt;/msub&amp;gt;&amp;lt;/math&amp;gt;&quot;&gt;&lt;span class=&quot;MJX_Assistive_MathML&quot;&gt;&lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;span id=&quot;MathJax-Element-11-Frame&quot; class=&quot;MathJax&quot; data-mathml=&quot;&amp;lt;math xmlns=&amp;quot;http://www.w3.org/1998/Math/MathML&amp;quot;&amp;gt;&amp;lt;msub&amp;gt;&amp;lt;mi&amp;gt;h&amp;lt;/mi&amp;gt;&amp;lt;mi&amp;gt;&amp;amp;#x03B8;&amp;lt;/mi&amp;gt;&amp;lt;/msub&amp;gt;&amp;lt;mo stretchy=&amp;quot;false&amp;quot;&amp;gt;(&amp;lt;/mo&amp;gt;&amp;lt;msub&amp;gt;&amp;lt;mi&amp;gt;x&amp;lt;/mi&amp;gt;&amp;lt;mi&amp;gt;i&amp;lt;/mi&amp;gt;&amp;lt;/msub&amp;gt;&amp;lt;mo stretchy=&amp;quot;false&amp;quot;&amp;gt;)&amp;lt;/mo&amp;gt;&amp;lt;/math&amp;gt;&quot;&gt;&lt;span class=&quot;MJX_Assistive_MathML&quot;&gt; &lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h2&gt;&lt;span&gt;　　1.3 梯度下降的详细算法&lt;/span&gt;&lt;/h2&gt;
&lt;p&gt;&lt;span&gt;　　梯度下降法的算法可以有代数法和矩阵法（也称向量法）两种表示，如果对矩阵分析不熟悉，则代数法更加容易理解。不过矩阵法更加的简洁，且由于使用了矩阵，实现逻辑更加的一目了然。这里先介绍代数法，后介绍矩阵法。&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;/p&gt;
&lt;h3&gt;&lt;span&gt;　　1.3.1 梯度下降法的代数方式描述&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;&lt;span&gt;　　　　1、先决条件： 确认优化模型的假设函数和损失函数。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　　　比如对于线性回归，假设函数表示为$h_{\theta }(x_{1},x_{2},...x_{n})=\theta _{0}+\theta _{1}x_{1}+...+\theta _{n}x_{n}$，其中$\theta _{i}(i=0,1,2...n)$为模型参数，$x _{i}(i=0,1,2...n)$为每个样本的n个特征值。我们增加一个特征$x _{0}=1$，这样$h_{\theta }(x_{0},x_{1},...x_{n})=\sum_{i=0}^{n}\theta _{i}x_{i}$。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　　　同样是线性回归，对应于上面的假设函数，损失函数为：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　　　$J(\theta _{0},\theta _{1}...,\theta _{n})=\frac{1}{2m}\sum_{j=1}^{m}(h_{\theta }(x_{0}^{(j)},x_{1}^{(j)},...x_{n}^{(j)}-y_{j})^{2}$&lt;/span&gt;&lt;span&gt;        &lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　　　2、算法相关参数初始化：主要是初始化$\theta _{0},\theta _{1}...,\theta _{n}$，算法终止距离$\varepsilon $以及步长$\alpha$。在没有任何先验知识的时候，将所有$\theta _{0}$初始化为0，将步长初始化为1，在调优的时候再优化。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　　　3、 算法过程：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　　　　　1）确定当前位置的损失函数的梯度，对于$\theta _{i}$，其梯度表达式如下：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　　　　　　　$\frac{\partial }{\partial \theta _{i}}J(\theta _{0},\theta _{1}...,\theta _{n})$&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　　　　　2）用步长乘以损失函数的梯度，得到当前位置下降的距离，即$a\frac{\partial }{\partial \theta _{i}}J(\theta _{0},\theta _{1}...,\theta _{n})$对应前面登山例子中的某一步。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　　　　　3）确定是否所有的$\theta _{i}$，梯度下降的距离都小于$\varepsilon $，如果小于$\varepsilon $则算法终止，当前所有的$\theta _{i}(i=0,1,2...n)$即为最终结果。否则进入步骤4.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　　　　　4）更新所有的$\theta $，对于$\theta _{i}$，其更新表达式如下。更新完毕后继续转入步骤1.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　　　　　　　$J(\theta _{0},\theta _{1}...,\theta _{n})=\frac{1}{2m}\sum_{j=1}^{m}(h_{\theta }(x_{0}^{(j)},x_{1}^{(j)},...x_{n}^{(j)})-y_{j})^{2}$&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　下面用线性回归的例子来具体描述梯度下降。假设我们的样本是$(x_{1}^{(0)},x_{2}^{(0)},...x_{n}^{(0)},y_{0})$,$(x_{1}^{(1)},x_{2}^{(1)},...x_{n}^{(1)},y_{1})$,...$(x_{1}^{(m)},x_{2}^{(m)},...x_{n}^{(m)},y_{m})$,损失函数如前面先决条件所述：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　$J(\theta _{0},\theta _{1}...,\theta _{n})=\frac{1}{m}\sum_{j=1}^{m}(h_{\theta }(x_{0}^{(j)},x_{1}^{(j)},...x_{n}^{(j)}-y_{j})^{2}$&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　则在算法过程步骤1中对于$\theta _{i}$的偏导数计算如下：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　$\frac{\partial }{\partial \theta _{t}}J(\theta _{0},\theta _{1}...,\theta _{n})=\frac{1}{m}\sum_{j=1}^{m}(h_{\theta }(x_{0}^{(j)},x_{1}^{(j)},...x_{n}^{(j)})-y_{j})x_{i}^{(j)}$&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　由于样本中没有$x_{0}$上式中令所有$x_{0}^{j}$为1.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　步骤4中$\theta _{i}$的更新表达式如下：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　$\theta _{i}=\theta _{i}-a\frac{1}{m}\sum_{j=1}^{m}(h_{\theta }(x_{0}^{(j)},x_{1}^{(j)},...x_{n}^{(j)})-y_{j})x_{i}^{(j)}$&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　从这个例子可以看出当前点的梯度方向是由所有的样本决定的，加$\frac{1}{m}$是为了好理解。由于步长也为常数，他们的乘积也为常数，所以这里$a\frac{1}{m}$可以用一个常数表示。&lt;/span&gt;&lt;/p&gt;
&lt;h3&gt;&lt;span&gt;　　1.3.2 梯度下降法的矩阵方式描述&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;&lt;span&gt;　　　　这一部分主要讲解梯度下降法的矩阵方式表述，相对于1.3.1的代数法，要求有一定的矩阵分析的基础知识，尤其是矩阵求导的知识。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　　　1、 先决条件： 和1.3.1类似， 需要确认优化模型的假设函数和损失函数。对于线性回归，假设函数$h_{\theta }(x_{1},x_{2},...x_{n})=\theta _{0}+\theta _{1}x_{1}+...+\theta _{n}x_{n}$的矩阵表达方式为：$h_{\theta }(X)=X\theta $，其中，假设函数$h_{\theta }(X)$为m*1的向量，$h_{\theta }$为(n+1)*1的向量，里面n+1个代数法的模型参数。X为m*(n+1)维的矩阵。m代表样本的个数，n+1代表样本的特征数。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　　　损失函数的表达式为：$J(\theta )=\frac{1}{2}(X\theta -Y)^{T}(X\theta -Y)$，其中Y是样本的输出向量，维度为m*1.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　　　2、算法相关参数初始化: $\theta $向量可以初始化为默认值，或者调优后的值。算法终止距离$\varepsilon $，步长$\alpha$和1.3.1比没有变化。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　　　3、算法过程：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　　　　　1）确定当前位置的损失函数的梯度，对于$\theta $向量，其梯度表达式如下：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　　　　　　　$\frac{\partial }{\partial \theta }J(\theta )$&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　　　　　2）用步长乘以损失函数的梯度，得到当前位置下降的距离，即$a\frac{\partial }{\partial \theta }J(\theta )$对应于前面登山例子中的某一步。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　　　　　3）确定$\theta $向量里面的每个值，梯度下降的距离都小于$\varepsilon $，如果小于$\varepsilon $则算法终止，当前$\theta $向量即为最终结果。否则进入步骤4.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　　　　　4）更新$\theta $向量，其更新表达式如下。更新完毕后继续转入步骤1.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　　　　　$\theta =\theta -a\frac{\partial }{\partial \theta }J(\theta )$&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　　　还是用线性回归的例子来描述具体的算法过程。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　　　损失函数对于$\theta $向量的偏导数计算如下：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　　　$\frac{\partial }{\partial \theta }J(\theta )=X^{T}(X\theta -Y)$&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　　　步骤4中$\theta $向量的更新表达式如下：$\theta =\theta -aX^{T}(X\theta -Y)$&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　　　对于3.3.1的代数法，可以看到矩阵法要简洁很多。这里面用到了矩阵求导链式法则，和两个矩阵求导的公式。&lt;/span&gt;&lt;span&gt;　&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　　　这里面用到了矩阵求导链式法则，和两个个矩阵求导的公式。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　　　　　公式1：$\frac{\partial }{\partial x}(X^{T}X)=2X$ &lt;em&gt;x&lt;/em&gt;为向量&lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;span id=&quot;MathJax-Element-65-Frame&quot; class=&quot;MathJax&quot; data-mathml=&quot;&amp;lt;math xmlns=&amp;quot;http://www.w3.org/1998/Math/MathML&amp;quot;&amp;gt;&amp;lt;mfrac&amp;gt;&amp;lt;mi mathvariant=&amp;quot;normal&amp;quot;&amp;gt;&amp;amp;#x2202;&amp;lt;/mi&amp;gt;&amp;lt;mrow&amp;gt;&amp;lt;mi mathvariant=&amp;quot;normal&amp;quot;&amp;gt;&amp;amp;#x2202;&amp;lt;/mi&amp;gt;&amp;lt;mrow class=&amp;quot;MJX-TeXAtom-ORD&amp;quot;&amp;gt;&amp;lt;mi mathvariant=&amp;quot;bold&amp;quot;&amp;gt;x&amp;lt;/mi&amp;gt;&amp;lt;/mrow&amp;gt;&amp;lt;/mrow&amp;gt;&amp;lt;/mfrac&amp;gt;&amp;lt;mo stretchy=&amp;quot;false&amp;quot;&amp;gt;(&amp;lt;/mo&amp;gt;&amp;lt;mrow class=&amp;quot;MJX-TeXAtom-ORD&amp;quot;&amp;gt;&amp;lt;msup&amp;gt;&amp;lt;mi mathvariant=&amp;quot;bold&amp;quot;&amp;gt;x&amp;lt;/mi&amp;gt;&amp;lt;mi mathvariant=&amp;quot;bold&amp;quot;&amp;gt;T&amp;lt;/mi&amp;gt;&amp;lt;/msup&amp;gt;&amp;lt;mi mathvariant=&amp;quot;bold&amp;quot;&amp;gt;x&amp;lt;/mi&amp;gt;&amp;lt;/mrow&amp;gt;&amp;lt;mo stretchy=&amp;quot;false&amp;quot;&amp;gt;)&amp;lt;/mo&amp;gt;&amp;lt;mo&amp;gt;=&amp;lt;/mo&amp;gt;&amp;lt;mn&amp;gt;2&amp;lt;/mn&amp;gt;&amp;lt;mrow class=&amp;quot;MJX-TeXAtom-ORD&amp;quot;&amp;gt;&amp;lt;mi mathvariant=&amp;quot;bold&amp;quot;&amp;gt;x&amp;lt;/mi&amp;gt;&amp;lt;/mrow&amp;gt;&amp;lt;mspace width=&amp;quot;thickmathspace&amp;quot; /&amp;gt;&amp;lt;mspace width=&amp;quot;thickmathspace&amp;quot; /&amp;gt;&amp;lt;mi&amp;gt;x&amp;lt;/mi&amp;gt;&amp;lt;mrow class=&amp;quot;MJX-TeXAtom-ORD&amp;quot;&amp;gt;&amp;lt;mo&amp;gt;&amp;amp;#x4E3A;&amp;lt;/mo&amp;gt;&amp;lt;/mrow&amp;gt;&amp;lt;mrow class=&amp;quot;MJX-TeXAtom-ORD&amp;quot;&amp;gt;&amp;lt;mo&amp;gt;&amp;amp;#x5411;&amp;lt;/mo&amp;gt;&amp;lt;/mrow&amp;gt;&amp;lt;mrow class=&amp;quot;MJX-TeXAtom-ORD&amp;quot;&amp;gt;&amp;lt;mo&amp;gt;&amp;amp;#x91CF;&amp;lt;/mo&amp;gt;&amp;lt;/mrow&amp;gt;&amp;lt;/math&amp;gt;&quot;&gt;&lt;span id=&quot;MathJax-Span-1192&quot; class=&quot;math&quot;&gt;&lt;span id=&quot;MathJax-Span-1193&quot; class=&quot;mrow&quot;&gt;&lt;span id=&quot;MathJax-Span-1194&quot; class=&quot;mfrac&quot;&gt;&lt;span id=&quot;MathJax-Span-1195&quot; class=&quot;mi&quot;&gt;&lt;br/&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　　　　　公式2：$\bigtriangledown _{\chi }f(AX+B)=A^{T}\bigtriangledown _{Y}f$，$Y=AX+B$，$f(Y)$为标量&lt;span class=&quot;MathJax_Preview&quot;&gt;&lt;span id=&quot;MathJax-Element-66-Frame&quot; class=&quot;MathJax&quot; data-mathml=&quot;&amp;lt;math xmlns=&amp;quot;http://www.w3.org/1998/Math/MathML&amp;quot;&amp;gt;&amp;lt;msub&amp;gt;&amp;lt;mi mathvariant=&amp;quot;normal&amp;quot;&amp;gt;&amp;amp;#x2207;&amp;lt;/mi&amp;gt;&amp;lt;mi&amp;gt;X&amp;lt;/mi&amp;gt;&amp;lt;/msub&amp;gt;&amp;lt;mi&amp;gt;f&amp;lt;/mi&amp;gt;&amp;lt;mo stretchy=&amp;quot;false&amp;quot;&amp;gt;(&amp;lt;/mo&amp;gt;&amp;lt;mi&amp;gt;A&amp;lt;/mi&amp;gt;&amp;lt;mi&amp;gt;X&amp;lt;/mi&amp;gt;&amp;lt;mo&amp;gt;+&amp;lt;/mo&amp;gt;&amp;lt;mi&amp;gt;B&amp;lt;/mi&amp;gt;&amp;lt;mo stretchy=&amp;quot;false&amp;quot;&amp;gt;)&amp;lt;/mo&amp;gt;&amp;lt;mo&amp;gt;=&amp;lt;/mo&amp;gt;&amp;lt;msup&amp;gt;&amp;lt;mi&amp;gt;A&amp;lt;/mi&amp;gt;&amp;lt;mi&amp;gt;T&amp;lt;/mi&amp;gt;&amp;lt;/msup&amp;gt;&amp;lt;msub&amp;gt;&amp;lt;mi mathvariant=&amp;quot;normal&amp;quot;&amp;gt;&amp;amp;#x2207;&amp;lt;/mi&amp;gt;&amp;lt;mi&amp;gt;Y&amp;lt;/mi&amp;gt;&amp;lt;/msub&amp;gt;&amp;lt;mi&amp;gt;f&amp;lt;/mi&amp;gt;&amp;lt;mo&amp;gt;,&amp;lt;/mo&amp;gt;&amp;lt;mspace width=&amp;quot;thickmathspace&amp;quot; /&amp;gt;&amp;lt;mspace width=&amp;quot;thickmathspace&amp;quot; /&amp;gt;&amp;lt;mi&amp;gt;Y&amp;lt;/mi&amp;gt;&amp;lt;mo&amp;gt;=&amp;lt;/mo&amp;gt;&amp;lt;mi&amp;gt;A&amp;lt;/mi&amp;gt;&amp;lt;mi&amp;gt;X&amp;lt;/mi&amp;gt;&amp;lt;mo&amp;gt;+&amp;lt;/mo&amp;gt;&amp;lt;mi&amp;gt;B&amp;lt;/mi&amp;gt;&amp;lt;mo&amp;gt;,&amp;lt;/mo&amp;gt;&amp;lt;mspace width=&amp;quot;thickmathspace&amp;quot; /&amp;gt;&amp;lt;mspace width=&amp;quot;thickmathspace&amp;quot; /&amp;gt;&amp;lt;mi&amp;gt;f&amp;lt;/mi&amp;gt;&amp;lt;mo stretchy=&amp;quot;false&amp;quot;&amp;gt;(&amp;lt;/mo&amp;gt;&amp;lt;mi&amp;gt;Y&amp;lt;/mi&amp;gt;&amp;lt;mo stretchy=&amp;quot;false&amp;quot;&amp;gt;)&amp;lt;/mo&amp;gt;&amp;lt;mrow class=&amp;quot;MJX-TeXAtom-ORD&amp;quot;&amp;gt;&amp;lt;mo&amp;gt;&amp;amp;#x4E3A;&amp;lt;/mo&amp;gt;&amp;lt;/mrow&amp;gt;&amp;lt;mrow class=&amp;quot;MJX-TeXAtom-ORD&amp;quot;&amp;gt;&amp;lt;mo&amp;gt;&amp;amp;#x6807;&amp;lt;/mo&amp;gt;&amp;lt;/mrow&amp;gt;&amp;lt;mrow class=&amp;quot;MJX-TeXAtom-ORD&amp;quot;&amp;gt;&amp;lt;mo&amp;gt;&amp;amp;#x91CF;&amp;lt;/mo&amp;gt;&amp;lt;/mrow&amp;gt;&amp;lt;/math&amp;gt;&quot;&gt;&lt;span id=&quot;MathJax-Span-1226&quot; class=&quot;math&quot;&gt;&lt;span id=&quot;MathJax-Span-1227&quot; class=&quot;mrow&quot;&gt;&lt;span id=&quot;MathJax-Span-1228&quot; class=&quot;msubsup&quot;&gt;&lt;span id=&quot;MathJax-Span-1229&quot; class=&quot;mi&quot;&gt;&lt;br/&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　　　如果需要熟悉矩阵求导建议参考张贤达的《矩阵分析与应用》一书。&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;/p&gt;
&lt;h2&gt;&lt;span&gt;　　1.4 梯度下降的算法调优&lt;/span&gt;&lt;/h2&gt;
&lt;p&gt;&lt;span&gt;　　　　在使用梯度下降时，需要进行调优。哪些地方需要调优呢？&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　　　1. 算法的步长选择。在前面的算法描述中，我提到取步长为1，但是实际上取值取决于数据样本，可以多取一些值，从大到小，分别运行算法，看看迭代效果，如果损失函数在变小，说明取值有效，否则要增大步长。前面说了。步长太大，会导致迭代过快，甚至有可能错过最优解。步长太小，迭代速度太慢，很长时间算法都不能结束。所以算法的步长需要多次运行后才能得到一个较为优的值。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　　　2. 算法参数的初始值选择。 初始值不同，获得的最小值也有可能不同，因此梯度下降求得的只是局部最小值；当然如果损失函数是凸函数则一定是最优解。由于有局部最优解的风险，需要多次用不同初始值运行算法，关键损失函数的最小值，选择损失函数最小化的初值。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　　　3.归一化。由于样本不同特征的取值范围不一样，可能导致迭代很慢，为了减少特征取值的影响，可以对特征数据归一化，也就是对于每个特征$x$，求出它的期望$\bar{x}$和标准差std(x)，然后转化为：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　　　$\frac{x-\bar{x}}{std(x)}$&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　　　这样特征的新期望为0，新方差为1，迭代速度可以大大加快。&lt;/span&gt;&lt;/p&gt;
&lt;h2&gt;&lt;span&gt;二、梯度下降法的分类与对比&lt;/span&gt;&lt;/h2&gt;
&lt;p&gt;&lt;span&gt;　　根据梯度下降时使用数据量的不同，梯度下降可以分为3类：&lt;strong&gt;批量梯度下降（Batch Gradient Descent，BGD）&lt;/strong&gt;、&lt;strong&gt;随机梯度下降（Stochastic Gradient Descent， SGD）&lt;/strong&gt;和&lt;strong&gt;小批量梯度下降（Mini-Batch Gradient Descent, MBGD）&lt;/strong&gt;。&lt;/span&gt;&lt;/p&gt;
&lt;h4 id=&quot;批量梯度下降（sgd）&quot;&gt;&lt;span&gt;　　批量梯度下降（SGD）&lt;/span&gt;&lt;/h4&gt;
&lt;p&gt;&lt;span&gt;　　批量梯度下降每次都使用训练集中的所有样本来更新参数，也就是&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　$L(w)=\frac{1}{2N}\sum_{i=1}^{N}(f_{M}(x,w)-y)^{2}$&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　更新方法为&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　$w^{(k+1)}=w^{k}-a*\frac{\partial L(w)}{\partial w}$&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　当样本数据集很大时，批量梯度下降的速度就会非常慢。&lt;/span&gt;&lt;br/&gt;&lt;span&gt;&lt;strong&gt;　　&lt;span&gt;优点&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：&lt;/span&gt;可以得到全局最优解&lt;/span&gt;&lt;br/&gt;&lt;span&gt;&lt;strong&gt;　　&lt;span&gt;缺点&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：&lt;/span&gt;训练时间长&lt;/span&gt;&lt;/p&gt;
&lt;h4 id=&quot;随机梯度下降（sgd）&quot;&gt;&lt;span&gt;　　随机梯度下降（SGD）&lt;/span&gt;&lt;/h4&gt;
&lt;p&gt;&lt;span&gt;　　每次梯度下降过程都使用全部的样本数据可能会造成训练过慢，随机梯度下降（SGD）每次只从样本中选择1组数据进行梯度下降，这样经过足够多的迭代次数，SGD也可以发挥作用，但过程会非常杂乱。“随机”的含义是每次从全部数据中中随机抽取一个样本。这样损失函数就变为：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　$L(w)=\frac{1}{2}(f_{M}(x,w)-y)^{2}$&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　参数更新方法同上：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　$w^{(k+1)}=w^{k}-a*\frac{\partial L(w)}{\partial w}$ &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;　　&lt;span&gt;优点&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：&lt;/span&gt;训练速度快&lt;/span&gt;&lt;br/&gt;&lt;span&gt;&lt;strong&gt;　　&lt;span&gt;缺点&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：&lt;/span&gt;准确度下降，得到的可能只是局部最优解&lt;/span&gt;&lt;/p&gt;
&lt;h4 id=&quot;小批量梯度下降（mbgd）&quot;&gt;&lt;span&gt;　　小批量梯度下降（MBGD）&lt;/span&gt;&lt;/h4&gt;
&lt;p&gt;&lt;span&gt;　　小批量梯度下降是 BGD 和 SGD 之间的折中，MBGD 通常包含 10-1000 个随机选择的样本。MBGD降低了了SGD训练过程的杂乱程度，同时也保证了速度。&lt;/span&gt;&lt;/p&gt;
&lt;h2&gt;&lt;span&gt;三、总结&lt;/span&gt;&lt;/h2&gt;
&lt;p&gt;&lt;span&gt;　　梯度下降法是一种常用的优化器，梯度可以理解为多元函数偏导数组成的向量（一元函数就是导数），沿着梯度方向函数增加最快，在梯度下降中要沿着梯度相反的方向。根据训练周期使用的数据量的不同，梯度下降可以分为批量梯度下降（BGD）、随机梯度下降（SGD）和小批量梯度下降（MBGD）。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　在机器学习中的无约束优化算法，除了梯度下降以外，还有前面提到的最小二乘法，此外还有牛顿法和拟牛顿法。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　梯度下降法和最小二乘法相比，梯度下降法需要选择步长，而最小二乘法不需要。梯度下降法是迭代求解，最小二乘法是计算解析解。如果样本量不算很大，且存在解析解，最小二乘法比起梯度下降法要有优势，计算速度很快。但是如果样本量很大，用最小二乘法由于需要求一个超级大的逆矩阵，这时就很难或者很慢才能求解解析解了，使用迭代的梯度下降法比较有优势。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　梯度下降法和牛顿法/拟牛顿法相比，两者都是迭代求解，不过梯度下降法是梯度求解，而牛顿法/拟牛顿法是用二阶的海森矩阵的逆矩阵或伪逆矩阵求解。相对而言，使用牛顿法/拟牛顿法收敛更快。但是每次迭代的时间比梯度下降法长。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;span&gt;参考：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/36564434&quot; target=&quot;_blank&quot;&gt;https://zhuanlan.zhihu.com/p/36564434&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;a href=&quot;https://www.jianshu.com/p/c7e642877b0e&quot; target=&quot;_blank&quot;&gt;https://www.jianshu.com/p/c7e642877b0e&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;a href=&quot;https://blog.csdn.net/qq_41800366/article/details/86583789&quot; target=&quot;_blank&quot;&gt;https://blog.csdn.net/qq_41800366/article/details/86583789&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;a href=&quot;https://www.cnblogs.com/pinard/p/5970503.html&quot; target=&quot;_blank&quot;&gt;https://www.cnblogs.com/pinard/p/5970503.html&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;
</description>
<pubDate>Wed, 23 Dec 2020 15:31:00 +0000</pubDate>
<dc:creator>早起的小虫子</dc:creator>
<og:description>在机器学习的核心内容就是把数据喂给一个人工设计的模型，然后让模型自动的“学习”，从而优化模型自身的各种参数，最终使得在某一组参数下该模型能够最佳的匹配该学习任务。那么这个“学习”的过程就是机器学习算法</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/liuxiaochong/p/14086698.html</dc:identifier>
</item>
</channel>
</rss>