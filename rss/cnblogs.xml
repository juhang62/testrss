<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="css/feed.xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/" xmlns:og="http://ogp.me/ns#">
<channel>
<atom:link rel="self" href="http://192.168.1.4/fivefilters/makefulltextfeed.php?url=feed.cnblogs.com%2Fblog%2Fsitehome%2Frss&amp;max=10&amp;links=preserve&amp;exc=" />
<atom:link rel="alternate" title="Source URL" href="http://feed.cnblogs.com/blog/sitehome/rss" />
<atom:link rel="related" title="Subscribe to feed" href="http://www.subtome.com/#/subscribe?feeds=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed.cnblogs.com%252Fblog%252Fsitehome%252Frss%26max%3D10%26links%3Dpreserve%26exc%3D&amp;back=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed.cnblogs.com%252Fblog%252Fsitehome%252Frss%26max%3D10%26links%3Dpreserve%26exc%3D" />
<title>博客园_首页</title>
<link></link>
<description>代码改变世界</description>
<item>
<title>搭建一个点播跟直播流媒体服务器玩玩 - 程序员众推</title>
<link>http://www.cnblogs.com/codhome/p/13838276.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/codhome/p/13838276.html</guid>
<description>&lt;blockquote readability=&quot;7&quot;&gt;
&lt;p&gt;现在抖音、快手等直播实在是太火了，因此对音视频的开发非常感兴趣，查阅了相关资料，使用Nginx搭建一个简单的直播跟点播流媒体服务器，能够实时推流到服务器，同时在网页端播放直播的视频。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;先上效果&quot;&gt;先上效果&lt;/h2&gt;
&lt;p&gt;​ 使用OBS软件录制电脑桌面操作&lt;strong&gt;推流&lt;/strong&gt;到自己搭建的流媒体服务器，然后在网页&lt;strong&gt;拉流&lt;/strong&gt;播放。当然也可以采集摄像头、麦克风推流，或者推送本地视频到流媒体服务器。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://i.loli.net/2020/10/18/yO24gYIdNUXD68m.gif&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h2 id=&quot;搭建步骤&quot;&gt;搭建步骤&lt;/h2&gt;
&lt;h3 id=&quot;ubuntu1804安装nginx-flv模块扩展&quot;&gt;Ubuntu18.04安装nginx-flv模块扩展&lt;/h3&gt;
&lt;p&gt;这里我是用虚拟机安装了Ubuntu18.04先下载nginx1.19.3的源码与nginx-http-flv-module的源码。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;wget https://github.com/winshining/nginx-http-flv-module/archive/master.zip
wget http://nginx.org/download/nginx-1.19.3.tar.gz  &amp;amp;&amp;amp; tar -zxvf nginx-1.19.3.tar.gz
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;解压下载的个源码进行编译，这样一个Nginx搭建的流媒体服务器就好了。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt; cd nginx-1.19.3 #进入nginx源码目录
 ./configure --add-module=../nginx-http-flv-module-master
 vim objs/Makefile #删除-Werror
 make
 make install
&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;进行点播与直播配置&quot;&gt;进行点播与直播配置&lt;/h2&gt;
&lt;p&gt;​ 上面已经安装好了nginx，编辑/usr/local/nginx/conf/nginx.conf进行相关配置。这里直接贴出完整的配置。其中rtmp为开启rtmp服务功能，并且为了能够在网页端播放开启了hls。推流的rmtp流会转换成hls协议的ts切片，保存在服务器上，nginx配置了location让网页能够访问切好的hls切片。&lt;/p&gt;
&lt;p&gt;​ 这里解释下rtmp是adobe的私有协议，必须使用flash播放。hls是苹果开发的视频传输协议使用http进行传输。ios跟android支撑的都很好，一般进行跨平台直播使用hls协议比较常见。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-nginx&quot;&gt;#user  nobody;
worker_processes  1;
events {
    worker_connections  1024;
}

rtmp {                #RTMP服务
   server {
        listen 1935;  #//服务端口
        chunk_size 4096;   #//数据传输块的大小


        application vod {
                play /opt/video/vod; #//视频文件存放位置。
        }
        application live{
            live on; #直播
            hls on; #把直播服务器改造成实时回发服务器,视频切片成ts
            wait_key on; #对视频切片进行保护
            hls_path /opt/video/rtmp/hls; #ts切片存放位置
            hls_fragment 10s; #切片大小
            hls_playlist_length 60s; #回看的时间
            hls_continuous on; #连续模式
            hls_cleanup on; #对多余切片进行删除
            hls_nested on; #嵌套模式
        }
   }
}
http {
    include       mime.types;
    default_type  application/octet-stream;
    sendfile        on;
    keepalive_timeout  65;
    server {
        listen       80;
        server_name  localhost;
        location /stat {    #第二处添加的location字段。
            rtmp_stat all;
                rtmp_stat_stylesheet stat.xsl;
        }

                location /stat.xsl { #第二处添加的location字段。
         root /usr/local/nginx-http-flv-module/;
                }
                location /hls {
                types {
                        application/vnd.apple.mpegurl m3u8;
                        video/mp2t ts;
                }
                alias /opt/video/rtmp/hls;
                add_header Cache-Control no-cache;
                add_header Access-Control-Allow-Origin *; 
                }
                location / {
            root   html;
            index  index.html index.htm;
          }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;进行测试&quot;&gt;进行测试&lt;/h2&gt;
&lt;p&gt;使用obs推流推送到rtmp://192.168.227.128/live串流密钥随便填写即可。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://i.loli.net/2020/10/17/htXIEPV4Nl3ODz8.png&quot; alt=&quot;image-20201017125252531&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;​ h5网页端采用video.js进行播放直播流视频,这里的播放的地址是切好片的m3u8文件地址，m3u8存放了每一个小切片的地址。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-html&quot;&gt;&amp;lt;body&amp;gt;
                &amp;lt;video id=example-video width=600 height=300 class=&quot;video-js vjs-default-skin&quot; controls&amp;gt;
                  &amp;lt;source
                     src=&quot;http://192.168.227.128/hls/test/index.m3u8&quot;
                     type=&quot;application/x-mpegURL&quot;&amp;gt;
                &amp;lt;/video&amp;gt;
                &amp;lt;link href=&quot;//vjs.zencdn.net/7.8.2/video-js.min.css&quot; rel=&quot;stylesheet&quot;&amp;gt;
                &amp;lt;script src=&quot;//vjs.zencdn.net/7.8.2/video.min.js&quot;&amp;gt;&amp;lt;/script&amp;gt;
                &amp;lt;script src=&quot;videojs-contrib-hls.min.js&quot;&amp;gt;&amp;lt;/script&amp;gt;
                &amp;lt;script src=&quot;https://unpkg.com/browse/@videojs/http-streaming@2.2.3/dist/videojs-http-streaming.min.js&quot;&amp;gt;&amp;lt;/script&amp;gt;
                &amp;lt;script&amp;gt;
                var player = videojs('example-video');
                player.play();
                &amp;lt;/script&amp;gt;
        &amp;lt;/body&amp;gt;
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;​ 上面的nginx配置还配置了本地视频文件点播配置，把视频文件放在/opt/video/vod位置，使用vlc填写rtmp://192.168.227.128/vod/qlgame.mp4进行播放即可。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://i.loli.net/2020/10/18/s5x14WuYrSeAqQp.png&quot; alt=&quot;image-20201018163103770&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;以上搭建只是测试学习使用，实际音视频开发涉及采集、编码、推流、传输、拉流、解码等等过程，每一个过程都设计许多知识。后面音视频开发学习笔记，等我攒了一些笔记发出来互相学习。&lt;/strong&gt;&lt;/p&gt;
</description>
<pubDate>Mon, 19 Oct 2020 00:45:00 +0000</pubDate>
<dc:creator>程序员众推</dc:creator>
<og:description>现在抖音、快手等直播实在是太火了，因此对音视频的开发非常感兴趣，查阅了相关资料，使用Nginx搭建一个简单的直播跟点播流媒体服务器，能够实时推流到服务器，同时在网页端播放直播的视频。 先上效果 ​	使</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/codhome/p/13838276.html</dc:identifier>
</item>
<item>
<title>一文读懂MySQL的事务隔离级别及MVCC机制 - 行无际</title>
<link>http://www.cnblogs.com/itwild/p/13796221.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/itwild/p/13796221.html</guid>
<description>&lt;p&gt;回顾前文:&lt;br/&gt;&lt;a href=&quot;https://www.cnblogs.com/itwild/p/13424113.html&quot;&gt;一文学会MySQL的explain工具&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.cnblogs.com/itwild/p/13703259.html&quot;&gt;一文读懂MySQL的索引结构及查询优化&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;(同时再次强调，这几篇关于MySQL的探究都是基于&lt;code&gt;5.7&lt;/code&gt;版本，相关总结与结论&lt;code&gt;不一定适用&lt;/code&gt;于其他版本)&lt;/p&gt;
&lt;p&gt;就软件开发而言，既要保证数据读写的&lt;code&gt;效率&lt;/code&gt;，还要保证&lt;code&gt;并发读写&lt;/code&gt;数据的&lt;code&gt;可靠性&lt;/code&gt;、&lt;code&gt;正确性&lt;/code&gt;。因此，除了要对MySQL的索引结构及查询优化有所了解外，还需要对MySQL的事务隔离级别及MVCC机制有所认知。&lt;/p&gt;
&lt;p&gt;MySQL官方文档中的词汇表(&lt;code&gt;https://dev.mysql.com/doc/refman/5.7/en/glossary.html&lt;/code&gt;)有助于我们对相关概念、理论的理解。下文中我会从概念表中摘录部分原文描述，以加深对原理机制的理解。&lt;/p&gt;
&lt;h2 id=&quot;事务隔离级别&quot;&gt;事务隔离级别&lt;/h2&gt;
&lt;h3 id=&quot;事务是什么&quot;&gt;事务是什么&lt;/h3&gt;
&lt;blockquote readability=&quot;9&quot;&gt;
&lt;p&gt;Transactions are atomic units of work that can be committed or rolled back. When a transaction makes multiple changes to the database, either all the changes succeed when the transaction is committed, or all the changes are undone when the transaction is rolled back.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;事务是由一组SQL语句组成的原子操作单元，其对数据的变更，要么全都执行成功(&lt;code&gt;Committed&lt;/code&gt;)，要么全都不执行(&lt;code&gt;Rollback&lt;/code&gt;)。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1546632/202010/1546632-20201003090232837-258120887.png&quot; alt=&quot;事务的示意图&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;blockquote readability=&quot;12&quot;&gt;
&lt;p&gt;Database transactions, as implemented by InnoDB, have properties that are collectively known by the acronym ACID, for atomicity, consistency, isolation, and durability.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;code&gt;InnoDB&lt;/code&gt;实现的数据库事务具有常说的&lt;code&gt;ACID&lt;/code&gt;属性，即原子性(&lt;code&gt;atomicity&lt;/code&gt;)，一致性(&lt;code&gt;consistency&lt;/code&gt;)、隔离性(&lt;code&gt;isolation&lt;/code&gt;)和持久性(&lt;code&gt;durability&lt;/code&gt;)。&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;code&gt;原子性&lt;/code&gt;：事务被视为不可分割的最小单元，所有操作要么全部执行成功，要么失败回滚(即还原到事务开始前的状态，就像这个事务从来没有执行过一样)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;一致性&lt;/code&gt;：在成功提交或失败回滚之后以及正在进行的事务期间，数据库始终保持一致的状态。如果正在多个表之间更新相关数据，那么查询将看到所有旧值或所有新值，而不会一部分是新值，一部分是旧值&lt;/li&gt;
&lt;li&gt;&lt;code&gt;隔离性&lt;/code&gt;：事务处理过程中的中间状态应该对外部不可见，换句话说，事务在进行过程中是隔离的，事务之间不能互相干扰，不能访问到彼此未提交的数据。这种隔离可通过锁机制实现。有经验的用户可以根据实际的业务场景，通过调整事务隔离级别，以提高并发能力&lt;/li&gt;
&lt;li&gt;&lt;code&gt;持久性&lt;/code&gt;：一旦事务提交，其所做的修改将会永远保存到数据库中。即使系统发生故障，事务执行的结果也不能丢失&lt;/li&gt;
&lt;/ul&gt;&lt;blockquote readability=&quot;13&quot;&gt;
&lt;p&gt;In InnoDB, all user activity occurs inside a transaction. If autocommit mode is enabled, each SQL statement forms a single transaction on its own. By default, MySQL starts the session for each new connection with autocommit enabled, so MySQL does a commit after each SQL statement if that statement did not return an error. If a statement returns an error, the commit or rollback behavior depends on the error&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;MySQL默认采用自动提交(&lt;code&gt;autocommit&lt;/code&gt;)模式。也就是说，如果不显式使用&lt;code&gt;START TRANSACTION&lt;/code&gt;或&lt;code&gt;BEGIN&lt;/code&gt;语句来开启一个事务，那么每个SQL语句都会被当做一个事务自动提交。&lt;/p&gt;
&lt;blockquote readability=&quot;7&quot;&gt;
&lt;p&gt;A session that has autocommit enabled can perform a multiple-statement transaction by starting it with an explicit START TRANSACTION or BEGIN statement and ending it with a COMMIT or ROLLBACK statement.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;多个SQL语句开启一个事务也很简单，以&lt;code&gt;START TRANSACTION&lt;/code&gt;或者&lt;code&gt;BEGIN&lt;/code&gt;语句开头，以&lt;code&gt;COMMIT&lt;/code&gt;或&lt;code&gt;ROLLBACK&lt;/code&gt;语句结尾。&lt;/p&gt;
&lt;blockquote readability=&quot;7&quot;&gt;
&lt;p&gt;If autocommit mode is disabled within a session with SET autocommit = 0, the session always has a transaction open. A COMMIT or ROLLBACK statement ends the current transaction and a new one starts.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;使用&lt;code&gt;SET autocommit = 0&lt;/code&gt;可手动关闭当前&lt;code&gt;session&lt;/code&gt;自动提交模式。&lt;/p&gt;
&lt;h3 id=&quot;并发事务的问题&quot;&gt;并发事务的问题&lt;/h3&gt;
&lt;h4 id=&quot;引出事务隔离级别&quot;&gt;引出事务隔离级别&lt;/h4&gt;
&lt;p&gt;相关文档：&lt;code&gt;https://dev.mysql.com/doc/refman/5.7/en/innodb-transaction-isolation-levels.html&lt;/code&gt;&lt;/p&gt;
&lt;blockquote readability=&quot;9&quot;&gt;
&lt;p&gt;Isolation is the I in the acronym ACID; the isolation level is the setting that fine-tunes the balance between performance and reliability, consistency, and reproducibility of results when multiple transactions are making changes and performing queries at the same time.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;也就是说当多个并发请求访问MySQL，其中有对数据的增删改请求时，考虑到并发性，又为了避免&lt;code&gt;脏读&lt;/code&gt;、&lt;code&gt;不可重复读&lt;/code&gt;、&lt;code&gt;幻读&lt;/code&gt;等问题，就需要对事务之间的读写进行隔离，至于隔离到啥程度需要看具体的业务场景，这时就要引出事务的隔离级别了。&lt;/p&gt;
&lt;blockquote readability=&quot;10&quot;&gt;
&lt;p&gt;InnoDB offers all four transaction isolation levels described by the SQL:1992 standard: READ UNCOMMITTED, READ COMMITTED, REPEATABLE READ, and SERIALIZABLE. The default isolation level for InnoDB is REPEATABLE READ.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;code&gt;InnoDB&lt;/code&gt;存储引擎实现了SQL标准中描述的4个事务隔离级别：读未提交(&lt;code&gt;READ UNCOMMITTED&lt;/code&gt;)、读已提交(&lt;code&gt;READ COMMITTED&lt;/code&gt;)、可重复读(&lt;code&gt;REPEATABLE READ&lt;/code&gt;)、可串行化(&lt;code&gt;SERIALIZABLE&lt;/code&gt;)。&lt;code&gt;InnoDB&lt;/code&gt;默认隔离级别是可重复读(&lt;code&gt;REPEATABLE READ&lt;/code&gt;)。&lt;/p&gt;
&lt;h4 id=&quot;设置事务隔离级别&quot;&gt;设置事务隔离级别&lt;/h4&gt;
&lt;p&gt;既然可以调整隔离级别，那么如何设置事务隔离级别呢？详情见官方文档：&lt;code&gt;https://dev.mysql.com/doc/refman/5.7/en/set-transaction.html&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;MySQL&lt;code&gt;5.7.18&lt;/code&gt;版本演示如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-sh&quot;&gt;mysql&amp;gt; select version();
+-----------+
| version() |
+-----------+
| 5.7.18    |
+-----------+
1 row in set (0.00 sec)

mysql&amp;gt; set global transaction isolation level REPEATABLE READ;
Query OK, 0 rows affected (0.00 sec)

mysql&amp;gt; set session transaction isolation level READ COMMITTED;
Query OK, 0 rows affected (0.00 sec)

mysql&amp;gt; select @@global.tx_isolation, @@session.tx_isolation, @@tx_isolation;
+-----------------------+------------------------+----------------+
| @@global.tx_isolation | @@session.tx_isolation | @@tx_isolation |
+-----------------------+------------------------+----------------+
| REPEATABLE-READ       | READ-COMMITTED         | READ-COMMITTED |
+-----------------------+------------------------+----------------+
1 row in set (0.00 sec)
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;MySQL&lt;code&gt;8.0.21&lt;/code&gt;版本演示如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-sh&quot;&gt;mysql&amp;gt; select version();
+-----------+
| version() |
+-----------+
| 8.0.21    |
+-----------+
1 row in set (0.01 sec)

mysql&amp;gt; set global transaction isolation level REPEATABLE READ;
Query OK, 0 rows affected (0.00 sec)

mysql&amp;gt; set session transaction isolation level READ COMMITTED;
Query OK, 0 rows affected (0.00 sec)

mysql&amp;gt; select @@global.transaction_isolation, @@session.transaction_isolation, @@transaction_isolation;
+--------------------------------+---------------------------------+-------------------------+
| @@global.transaction_isolation | @@session.transaction_isolation | @@transaction_isolation |
+--------------------------------+---------------------------------+-------------------------+
| REPEATABLE-READ                | READ-COMMITTED                  | READ-COMMITTED          |
+--------------------------------+---------------------------------+-------------------------+
1 row in set (0.00 sec)
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;注意&lt;/strong&gt;：&lt;/p&gt;
&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;transaction_isolation was added in MySQL 5.7.20 as a synonym for tx_isolation, which is now deprecated and is removed in MySQL 8.0. Applications should be adjusted to use transaction_isolation in preference to tx_isolation.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote readability=&quot;7&quot;&gt;
&lt;p&gt;Prior to MySQL 5.7.20, use tx_isolation and tx_read_only rather than transaction_isolation and transaction_read_only.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;如果使用系统变量(&lt;code&gt;system variables&lt;/code&gt;)来查看或者设置事务隔离级别，需要注意MySQL的版本。在MySQL&lt;code&gt;5.7.20&lt;/code&gt;之前，应使用&lt;code&gt;tx_isolation&lt;/code&gt;；在MySQL&lt;code&gt;5.7.20&lt;/code&gt;之后，应使用&lt;code&gt;transaction_isolation&lt;/code&gt;。&lt;/p&gt;
&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;You can set transaction characteristics globally, for the current session, or for the next transaction only.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;事务的隔离级别范围(&lt;code&gt;Transaction Characteristic Scope&lt;/code&gt;)可以精确到全局(&lt;code&gt;global&lt;/code&gt;)、当前会话(&lt;code&gt;session&lt;/code&gt;)、甚至是仅针对下一个事务生效(&lt;code&gt;the next transaction only&lt;/code&gt;)。&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;含&lt;code&gt;global&lt;/code&gt;关键词时，事务隔离级别的设置应用于所有后续&lt;code&gt;session&lt;/code&gt;，已存在的&lt;code&gt;session&lt;/code&gt;不受影响&lt;/li&gt;
&lt;li&gt;含&lt;code&gt;session&lt;/code&gt;关键词时，事务隔离级别的设置应用于在当前&lt;code&gt;session&lt;/code&gt;中执行的所有后续事务，不会影响当前正在进行的事务&lt;/li&gt;
&lt;li&gt;不含&lt;code&gt;global&lt;/code&gt;以及&lt;code&gt;session&lt;/code&gt;关键词时，事务隔离级别的设置仅应用于在当前&lt;code&gt;session&lt;/code&gt;中执行的下一个事务&lt;/li&gt;
&lt;/ul&gt;&lt;h4 id=&quot;数据准备&quot;&gt;数据准备&lt;/h4&gt;
&lt;p&gt;为了演示&lt;code&gt;脏读&lt;/code&gt;、&lt;code&gt;不可重复读&lt;/code&gt;、&lt;code&gt;幻读&lt;/code&gt;等问题，准备了一些初始化数据如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-sql&quot;&gt;-- ----------------------------
--  create database
-- ----------------------------
create database `transaction_test` DEFAULT CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci;

-- switch database
use `transaction_test`;

-- ----------------------------
--  table structure for `tb_book`
-- ----------------------------
CREATE TABLE `tb_book` (
  `book_id` int(11) NOT NULL,
  `book_name` varchar(64) DEFAULT NULL,
  `author` varchar(32) DEFAULT NULL,
  PRIMARY KEY (`book_id`),
  UNIQUE KEY `uk_book_name` (`book_name`) USING BTREE
) ENGINE = InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci;

BEGIN;
INSERT INTO `tb_book`(`book_id`, `book_name`, `author`) VALUES (1, '多情剑客无情剑', '古龙');
INSERT INTO `tb_book`(`book_id`, `book_name`, `author`) VALUES (2, '笑傲江湖', '金庸');
INSERT INTO `tb_book`(`book_id`, `book_name`, `author`) VALUES (3, '倚天屠龙记', '金庸');
INSERT INTO `tb_book`(`book_id`, `book_name`, `author`) VALUES (4, '射雕英雄传', '金庸');
INSERT INTO `tb_book`(`book_id`, `book_name`, `author`) VALUES (5, '绝代双骄', '古龙');
COMMIT;
&lt;/code&gt;
&lt;/pre&gt;
&lt;h4 id=&quot;脏读read-uncommitted&quot;&gt;脏读(read uncommitted)&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;事务A读到了事务B已经修改但尚未提交的数据&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;操作：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;&lt;code&gt;session A&lt;/code&gt;事务隔离级别设置为&lt;code&gt;read uncommitted&lt;/code&gt;并开启事务，首次查询&lt;code&gt;book_id&lt;/code&gt;为1的记录；&lt;/li&gt;
&lt;li&gt;然后&lt;code&gt;session B&lt;/code&gt;开启事务，并修改&lt;code&gt;book_id&lt;/code&gt;为1的记录，不提交事务，在&lt;code&gt;session A&lt;/code&gt;中再次查询&lt;code&gt;book_id&lt;/code&gt;为1的记录；&lt;/li&gt;
&lt;li&gt;最后让&lt;code&gt;session B&lt;/code&gt;中的事务回滚，再在&lt;code&gt;session A&lt;/code&gt;中查询&lt;code&gt;book_id&lt;/code&gt;为1的记录。&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;session A：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-sql&quot;&gt;mysql&amp;gt; set session transaction isolation level read uncommitted;
Query OK, 0 rows affected (0.00 sec)

mysql&amp;gt; begin;
Query OK, 0 rows affected (0.00 sec)

mysql&amp;gt; select * from tb_book where book_id = 1;
+---------+-----------------------+--------+
| book_id | book_name             | author |
+---------+-----------------------+--------+
|       1 | 多情剑客无情剑        | 古龙   |
+---------+-----------------------+--------+
1 row in set (0.00 sec)

mysql&amp;gt; select * from tb_book where book_id = 1;
+---------+-----------------------+--------+
| book_id | book_name             | author |
+---------+-----------------------+--------+
|       1 | 多情刀客无情刀        | 古龙   |
+---------+-----------------------+--------+
1 row in set (0.00 sec)

mysql&amp;gt; select * from tb_book where book_id = 1;
+---------+-----------------------+--------+
| book_id | book_name             | author |
+---------+-----------------------+--------+
|       1 | 多情剑客无情剑        | 古龙   |
+---------+-----------------------+--------+
1 row in set (0.00 sec)

mysql&amp;gt; commit;
Query OK, 0 rows affected (0.00 sec)
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;session B：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-sql&quot;&gt;mysql&amp;gt; begin;
Query OK, 0 rows affected (0.00 sec)

mysql&amp;gt; update tb_book set book_name = '多情刀客无情刀' where book_id = 1;
Query OK, 1 row affected (0.00 sec)
Rows matched: 1  Changed: 1  Warnings: 0

mysql&amp;gt; rollback;
Query OK, 0 rows affected (0.00 sec)
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;结果：&lt;code&gt;事务A&lt;/code&gt;读到了&lt;code&gt;事务B&lt;/code&gt;还没提交的中间状态，即产生了&lt;code&gt;脏读&lt;/code&gt;。&lt;/p&gt;
&lt;h4 id=&quot;不可重复读read-committed&quot;&gt;不可重复读(read committed)&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;事务A读到了事务B已经提交的修改数据&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;操作：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;&lt;code&gt;session A&lt;/code&gt;事务隔离级别设置为&lt;code&gt;read committed&lt;/code&gt;并开启事务，首次查询&lt;code&gt;book_id&lt;/code&gt;为1的记录；&lt;/li&gt;
&lt;li&gt;然后&lt;code&gt;session B&lt;/code&gt;开启事务，并修改&lt;code&gt;book_id&lt;/code&gt;为1的记录，不提交事务，在&lt;code&gt;session A&lt;/code&gt;中再次查询&lt;code&gt;book_id&lt;/code&gt;为1的记录；&lt;/li&gt;
&lt;li&gt;最后提交&lt;code&gt;session B&lt;/code&gt;中的事务，再在&lt;code&gt;session A&lt;/code&gt;中查看&lt;code&gt;book_id&lt;/code&gt;为1的记录。&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;session A：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-sql&quot;&gt;mysql&amp;gt; set session transaction isolation level read committed;
Query OK, 0 rows affected (0.01 sec)

mysql&amp;gt; begin;
Query OK, 0 rows affected (0.00 sec)

mysql&amp;gt; select * from tb_book where book_id = 1;
+---------+-----------------------+--------+
| book_id | book_name             | author |
+---------+-----------------------+--------+
|       1 | 多情剑客无情剑        | 古龙   |
+---------+-----------------------+--------+
1 row in set (0.00 sec)

mysql&amp;gt; select * from tb_book where book_id = 1;
+---------+-----------------------+--------+
| book_id | book_name             | author |
+---------+-----------------------+--------+
|       1 | 多情剑客无情剑        | 古龙   |
+---------+-----------------------+--------+
1 row in set (0.00 sec)

mysql&amp;gt; select * from tb_book where book_id = 1;
+---------+-----------------------+--------+
| book_id | book_name             | author |
+---------+-----------------------+--------+
|       1 | 多情刀客无情刀        | 古龙   |
+---------+-----------------------+--------+
1 row in set (0.00 sec)

mysql&amp;gt; commit;
Query OK, 0 rows affected (0.00 sec)
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;session B：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-sql&quot;&gt;mysql&amp;gt; begin;
Query OK, 0 rows affected (0.00 sec)

mysql&amp;gt; update tb_book set book_name = '多情刀客无情刀' where book_id = 1;
Query OK, 1 row affected (0.00 sec)
Rows matched: 1  Changed: 1  Warnings: 0

mysql&amp;gt; commit;
Query OK, 0 rows affected (0.00 sec)
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;结果：&lt;code&gt;事务B&lt;/code&gt;没有提交事务时，&lt;code&gt;事务A&lt;/code&gt;不会读到&lt;code&gt;事务B&lt;/code&gt;修改的中间状态，即&lt;code&gt;read committed&lt;/code&gt;解决了上面所说的&lt;code&gt;脏读&lt;/code&gt;问题，但是当&lt;code&gt;事务B&lt;/code&gt;中的事务提交后，&lt;code&gt;事务A&lt;/code&gt;读到了修改后的记录，而对于&lt;code&gt;事务A&lt;/code&gt;来说，仅仅读了两次，却读到了两个不同的结果，违背了事务之间的隔离性，所以说该事务隔离级别下产生了&lt;code&gt;不可重复读&lt;/code&gt;的问题。&lt;/p&gt;
&lt;h4 id=&quot;幻读repeatable-read&quot;&gt;幻读(repeatable read)&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;事务A读到了事务B提交的新增数据&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;操作：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;&lt;code&gt;session A&lt;/code&gt;事务隔离级别设置为&lt;code&gt;repeatable read&lt;/code&gt;并开启事务，并查询&lt;code&gt;book&lt;/code&gt;列表&lt;/li&gt;
&lt;li&gt;&lt;code&gt;session B&lt;/code&gt;开启事务，先修改&lt;code&gt;book_id&lt;/code&gt;为5的记录，再插入一条新的数据，提交事务，在&lt;code&gt;session A&lt;/code&gt;中再次查询&lt;code&gt;book&lt;/code&gt;列表&lt;/li&gt;
&lt;li&gt;在&lt;code&gt;session A&lt;/code&gt;中更新&lt;code&gt;session B&lt;/code&gt;中新插入的那条数据，再查询&lt;code&gt;book&lt;/code&gt;列表&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;session A：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-sql&quot;&gt;mysql&amp;gt; set session transaction isolation level repeatable read;
Query OK, 0 rows affected (0.00 sec)

mysql&amp;gt; begin;
Query OK, 0 rows affected (0.00 sec)

mysql&amp;gt; select * from tb_book;
+---------+-----------------------+--------+
| book_id | book_name             | author |
+---------+-----------------------+--------+
|       1 | 多情刀客无情刀        | 古龙   |
|       2 | 笑傲江湖              | 金庸   |
|       3 | 倚天屠龙记            | 金庸   |
|       4 | 射雕英雄传            | 金庸   |
|       5 | 绝代双骄              | 古龙   |
+---------+-----------------------+--------+
5 rows in set (0.00 sec)

mysql&amp;gt; select * from tb_book;
+---------+-----------------------+--------+
| book_id | book_name             | author |
+---------+-----------------------+--------+
|       1 | 多情刀客无情刀        | 古龙   |
|       2 | 笑傲江湖              | 金庸   |
|       3 | 倚天屠龙记            | 金庸   |
|       4 | 射雕英雄传            | 金庸   |
|       5 | 绝代双骄              | 古龙   |
+---------+-----------------------+--------+
5 rows in set (0.00 sec)

mysql&amp;gt; update tb_book set book_name = '圆月弯剑' where book_id = 6;
Query OK, 1 row affected (0.00 sec)
Rows matched: 1  Changed: 1  Warnings: 0

mysql&amp;gt; select * from tb_book;
+---------+-----------------------+--------+
| book_id | book_name             | author |
+---------+-----------------------+--------+
|       1 | 多情刀客无情刀        | 古龙   |
|       2 | 笑傲江湖              | 金庸   |
|       3 | 倚天屠龙记            | 金庸   |
|       4 | 射雕英雄传            | 金庸   |
|       5 | 绝代双骄              | 古龙   |
|       6 | 圆月弯剑              | 古龙   |
+---------+-----------------------+--------+
6 rows in set (0.00 sec)

mysql&amp;gt; rollback;
Query OK, 0 rows affected (0.00 sec)
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;session B：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-sql&quot;&gt;mysql&amp;gt; begin;
Query OK, 0 rows affected (0.00 sec)

mysql&amp;gt; update tb_book set book_name = '绝代双雄' where book_id = 5;
Query OK, 1 row affected (0.00 sec)
Rows matched: 1  Changed: 1  Warnings: 0

mysql&amp;gt; insert into tb_book values (6, '圆月弯刀', '古龙');
Query OK, 1 row affected (0.00 sec)

mysql&amp;gt; commit;
Query OK, 0 rows affected (0.00 sec)

mysql&amp;gt; select * from tb_book;
+---------+-----------------------+--------+
| book_id | book_name             | author |
+---------+-----------------------+--------+
|       1 | 多情刀客无情刀        | 古龙   |
|       2 | 笑傲江湖              | 金庸   |
|       3 | 倚天屠龙记            | 金庸   |
|       4 | 射雕英雄传            | 金庸   |
|       5 | 绝代双雄              | 古龙   |
|       6 | 圆月弯刀              | 古龙   |
+---------+-----------------------+--------+
6 rows in set (0.00 sec)
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;结果：&lt;code&gt;事务B&lt;/code&gt;已提交的修改记录(即&lt;code&gt;绝代双骄&lt;/code&gt;修改为&lt;code&gt;绝代双雄&lt;/code&gt;)在&lt;code&gt;事务A&lt;/code&gt;中是不可见的，说明该事务隔离级别下解决了上面&lt;code&gt;不可重复读&lt;/code&gt;的问题，但魔幻的是一开始&lt;code&gt;事务A&lt;/code&gt;中虽然读不到&lt;code&gt;事务B&lt;/code&gt;中的新增记录，却可以更新这条新增记录，执行更新(&lt;code&gt;update&lt;/code&gt;)后，在&lt;code&gt;事务A&lt;/code&gt;中居然可见该新增记录了，这便产生了所谓的&lt;code&gt;幻读&lt;/code&gt;问题。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;为什么会出现这样莫名其妙的结果？&lt;/strong&gt; 别急，后文会慢慢揭开这个神秘的面纱。先看如何解决幻读问题。&lt;/p&gt;
&lt;h4 id=&quot;串行化serializable&quot;&gt;串行化(serializable)&lt;/h4&gt;
&lt;p&gt;&lt;code&gt;serializable&lt;/code&gt;事务隔离级别可以避免幻读问题，但会极大的降低数据库的并发能力。&lt;/p&gt;
&lt;blockquote readability=&quot;9&quot;&gt;
&lt;p&gt;SERIALIZABLE: the isolation level that uses the most conservative locking strategy, to prevent any other transactions from inserting or changing data that was read by this transaction, until it is finished.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;操作：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;&lt;code&gt;session A&lt;/code&gt;事务隔离级别设置为&lt;code&gt;serializable&lt;/code&gt;并开启事务，并查询&lt;code&gt;book&lt;/code&gt;列表，不提交事务；&lt;/li&gt;
&lt;li&gt;然后&lt;code&gt;session B&lt;/code&gt;中分别执行&lt;code&gt;insert&lt;/code&gt;、&lt;code&gt;delete&lt;/code&gt;、&lt;code&gt;update&lt;/code&gt;操作&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;session A：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-sql&quot;&gt;mysql&amp;gt; set session transaction isolation level serializable;
Query OK, 0 rows affected (0.00 sec)

mysql&amp;gt; begin;
Query OK, 0 rows affected (0.00 sec)

mysql&amp;gt; select * from tb_book;
+---------+-----------------------+--------+
| book_id | book_name             | author |
+---------+-----------------------+--------+
|       1 | 多情刀客无情刀        | 古龙   |
|       2 | 笑傲江湖              | 金庸   |
|       3 | 倚天屠龙记            | 金庸   |
|       4 | 射雕英雄传            | 金庸   |
|       5 | 绝代双雄              | 古龙   |
|       6 | 圆月弯刀              | 古龙   |
+---------+-----------------------+--------+
6 rows in set (0.00 sec)
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;session B：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-sql&quot;&gt;mysql&amp;gt; insert into tb_book values (7, '神雕侠侣', '金庸');
ERROR 1205 (HY000): Lock wait timeout exceeded; try restarting transaction

mysql&amp;gt; delete from tb_book where book_id = 1;
ERROR 1205 (HY000): Lock wait timeout exceeded; try restarting transaction

mysql&amp;gt; update tb_book set book_name = '绝代双骄' where book_id = 5;
ERROR 1205 (HY000): Lock wait timeout exceeded; try restarting transaction
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;结果：只要&lt;code&gt;session A&lt;/code&gt;中的事务一直不提交，&lt;code&gt;session B&lt;/code&gt;中尝试更改数据(&lt;code&gt;insert&lt;/code&gt;、&lt;code&gt;delete&lt;/code&gt;、&lt;code&gt;update&lt;/code&gt;)的事务都会被阻塞至超时(&lt;code&gt;timeout&lt;/code&gt;)。显然，该事务隔离级别下能有效解决上面&lt;code&gt;幻读&lt;/code&gt;、&lt;code&gt;不可重复读&lt;/code&gt;、&lt;code&gt;脏读&lt;/code&gt;等问题。&lt;/p&gt;
&lt;p&gt;注意：除非是一些特殊的应用场景需要&lt;code&gt;serializable&lt;/code&gt;事务隔离级别，否则很少会使用该隔离级别，因为并发性极低。&lt;/p&gt;
&lt;h3 id=&quot;事务隔离级别小结&quot;&gt;事务隔离级别小结&lt;/h3&gt;
&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;事务隔离级别&lt;/th&gt;
&lt;th&gt;脏读&lt;/th&gt;
&lt;th&gt;不可重复读&lt;/th&gt;
&lt;th&gt;幻读&lt;/th&gt;
&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;read uncommitted&lt;/td&gt;
&lt;td&gt;可能&lt;/td&gt;
&lt;td&gt;可能&lt;/td&gt;
&lt;td&gt;可能&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;read committed&lt;/td&gt;
&lt;td&gt;不可能&lt;/td&gt;
&lt;td&gt;可能&lt;/td&gt;
&lt;td&gt;可能&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;repeatable read&lt;/td&gt;
&lt;td&gt;不可能&lt;/td&gt;
&lt;td&gt;不可能&lt;/td&gt;
&lt;td&gt;可能&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;serializable&lt;/td&gt;
&lt;td&gt;不可能&lt;/td&gt;
&lt;td&gt;不可能&lt;/td&gt;
&lt;td&gt;不可能&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;h2 id=&quot;mvcc机制&quot;&gt;MVCC机制&lt;/h2&gt;
&lt;p&gt;上面在演示&lt;code&gt;幻读&lt;/code&gt;问题时，出现的结果让人捉摸不透。原来&lt;code&gt;InnoDB&lt;/code&gt;存储引擎的默认事务隔离级别可重复读(&lt;code&gt;repeatable read&lt;/code&gt;)，是通过 &quot;行级锁+MVCC&quot;一起实现的。这就不得不去了解MVCC机制了。&lt;/p&gt;
&lt;p&gt;相关文档：&lt;code&gt;https://dev.mysql.com/doc/refman/5.7/en/innodb-multi-versioning.html&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;参考：&lt;br/&gt;《MySQL中MVCC的正确打开方式（源码佐证）》 &lt;code&gt;https://blog.csdn.net/Waves___/article/details/105295060&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;《InnoDB事务分析-MVCC》&lt;code&gt;http://www.leviathan.vip/2019/03/20/InnoDB的事务分析-MVCC/&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;《Innodb中的事务隔离级别和锁的关系》 &lt;code&gt;https://tech.meituan.com/2014/08/20/innodb-lock.html&lt;/code&gt;&lt;/p&gt;
&lt;h3 id=&quot;mvcc概念&quot;&gt;MVCC概念&lt;/h3&gt;
&lt;p&gt;多版本并发控制(&lt;code&gt;multiversion concurrency control&lt;/code&gt;，即&lt;code&gt;MVCC&lt;/code&gt;): 指的是一种提高并发的技术。最早期的数据库系统，只有读读之间可以并发，读写、写读、写写都要阻塞。引入多版本之后，只有写写之间相互阻塞，其他三种操作都可以并行，这样大幅度提高了&lt;code&gt;InnoDB&lt;/code&gt;的并发性能。在内部实现中，&lt;code&gt;InnoDB&lt;/code&gt;通过&lt;code&gt;undo log&lt;/code&gt;保存每条数据的多个版本，并且能够提供数据历史版本给用户读，每个事务读到的数据版本可能是不一样的。在同一个事务中，用户只能看到该事务创建快照之前已经提交的修改和该事务本身做的修改。&lt;/p&gt;
&lt;p&gt;简单来说，&lt;code&gt;MVCC&lt;/code&gt;表达的是&lt;strong&gt;维持一个数据的多个版本，使得读写操作没有冲突&lt;/strong&gt;这么一个思想。&lt;/p&gt;
&lt;p&gt;MVCC在&lt;code&gt;read committed&lt;/code&gt;和&lt;code&gt;repeatable read&lt;/code&gt;两个事务隔离级别下工作。&lt;/p&gt;
&lt;h4 id=&quot;隐藏字段&quot;&gt;隐藏字段&lt;/h4&gt;
&lt;blockquote readability=&quot;13&quot;&gt;
&lt;p&gt;Internally, InnoDB adds three fields to each row stored in the database. A 6-byte DB_TRX_ID field indicates the transaction identifier for the last transaction that inserted or updated the row. Also, a deletion is treated internally as an update where a special bit in the row is set to mark it as deleted. Each row also contains a 7-byte DB_ROLL_PTR field called the roll pointer. The roll pointer points to an undo log record written to the rollback segment. If the row was updated, the undo log record contains the information necessary to rebuild the content of the row before it was updated. A 6-byte DB_ROW_ID field contains a row ID that increases monotonically as new rows are inserted. If InnoDB generates a clustered index automatically, the index contains row ID values. Otherwise, the DB_ROW_ID column does not appear in any index.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;code&gt;InnoDB&lt;/code&gt;存储引擎在每行数据的后面添加了三个隐藏字段，如下图所示：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1546632/202010/1546632-20201018163556324-1921643603.png&quot; alt=&quot;表中某行数据示意图&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;ol readability=&quot;2&quot;&gt;&lt;li readability=&quot;1&quot;&gt;
&lt;p&gt;&lt;code&gt;DB_TRX_ID&lt;/code&gt;(6字节)：表示最近一次对本记录行做修改(&lt;code&gt;insert&lt;/code&gt;或&lt;code&gt;update&lt;/code&gt;)的事务ID。至于&lt;code&gt;delete&lt;/code&gt;操作，&lt;code&gt;InnoDB&lt;/code&gt;认为是一个&lt;code&gt;update&lt;/code&gt;操作，不过会更新一个另外的删除位，将行标识为deleted。并非真正删除。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;&lt;code&gt;DB_ROLL_PTR&lt;/code&gt;(7字节)：回滚指针，指向当前记录行的&lt;code&gt;undo log&lt;/code&gt;信息。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;1&quot;&gt;
&lt;p&gt;&lt;code&gt;DB_ROW_ID&lt;/code&gt;(6字节)：随着新行插入而单调递增的行ID。当表没有主键或唯一非空索引时，&lt;code&gt;InnoDB&lt;/code&gt;就会使用这个行ID自动产生聚集索引。前文《一文读懂MySQL的索引结构及查询优化》中也有所提及。这个&lt;code&gt;DB_ROW_ID&lt;/code&gt;跟&lt;code&gt;MVCC&lt;/code&gt;关系不大。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;&lt;h4 id=&quot;undo-log&quot;&gt;undo log&lt;/h4&gt;
&lt;p&gt;&lt;code&gt;undo log&lt;/code&gt;中存储的是老版本数据，当一个事务需要读取记录行时，如果当前记录行不可见，可以顺着&lt;code&gt;undo log&lt;/code&gt;链表找到满足其可见性条件的记录行版本。&lt;/p&gt;
&lt;p&gt;对数据的变更操作主要包括&lt;code&gt;insert/update/delete&lt;/code&gt;，在&lt;code&gt;InnoDB&lt;/code&gt;中，&lt;code&gt;undo log&lt;/code&gt;分为如下两类：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;code&gt;insert undo log&lt;/code&gt;: 事务对&lt;code&gt;insert&lt;/code&gt;新记录时产生的&lt;code&gt;undo log&lt;/code&gt;, 只在事务回滚时需要, 并且在事务提交后就可以立即丢弃。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;update undo log&lt;/code&gt;: 事务对记录进行&lt;code&gt;delete&lt;/code&gt;和&lt;code&gt;update&lt;/code&gt;操作时产生的&lt;code&gt;undo log&lt;/code&gt;，不仅在事务回滚时需要，快照读也需要，只有当数据库所使用的快照中不涉及该日志记录，对应的回滚日志才会被&lt;code&gt;purge&lt;/code&gt;线程删除。&lt;/li&gt;
&lt;/ul&gt;&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;&lt;code&gt;Purge&lt;/code&gt;线程：为了实现&lt;code&gt;InnoDB&lt;/code&gt;的&lt;code&gt;MVCC&lt;/code&gt;机制，更新或者删除操作都只是设置一下旧记录的&lt;code&gt;deleted_bit&lt;/code&gt;，并不真正将旧记录删除。为了节省磁盘空间，&lt;code&gt;InnoDB&lt;/code&gt;有专门的&lt;code&gt;purge&lt;/code&gt;线程来清理&lt;code&gt;deleted_bit&lt;/code&gt;为&lt;code&gt;true&lt;/code&gt;的记录。&lt;code&gt;purge&lt;/code&gt;线程自己也维护了一个&lt;code&gt;read view&lt;/code&gt;，如果某个记录的&lt;code&gt;deleted_bit&lt;/code&gt;为&lt;code&gt;true&lt;/code&gt;，并且&lt;code&gt;DB_TRX_ID&lt;/code&gt;相对于&lt;code&gt;purge&lt;/code&gt;线程的&lt;code&gt;read view&lt;/code&gt;可见，那么这条记录一定是可以被安全清除的。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;不同事务或者相同事务的对同一记录行的修改形成的&lt;code&gt;undo log&lt;/code&gt;如下图所示：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1546632/202010/1546632-20201018214116601-1252297826.png&quot; alt=&quot;undo log的示意图&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;可见链首就是最新的记录，链尾就是最早的旧记录。&lt;/p&gt;
&lt;h4 id=&quot;read-view结构&quot;&gt;Read View结构&lt;/h4&gt;
&lt;p&gt;&lt;code&gt;Read View&lt;/code&gt;(读视图)提供了某一时刻事务系统的快照，主要是用来做&lt;code&gt;可见性&lt;/code&gt;判断的, 里面保存了&quot;对本事务不可见的其他活跃事务&quot;。&lt;/p&gt;
&lt;p&gt;MySQL&lt;code&gt;5.7&lt;/code&gt;源码中对&lt;code&gt;Read View&lt;/code&gt;定义如下(详情见&lt;code&gt;https://github.com/mysql/mysql-server/blob/5.7/storage/innobase/include/read0types.h#L306&lt;/code&gt;)：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-cpp&quot;&gt;class ReadView {
        private:
                /** The read should not see any transaction with trx id &amp;gt;= this
                value. In other words, this is the &quot;high water mark&quot;. */
                trx_id_t        m_low_limit_id;

                /** The read should see all trx ids which are strictly
                smaller (&amp;lt;) than this value.  In other words, this is the
                low water mark&quot;. */
                trx_id_t        m_up_limit_id;

                /** trx id of creating transaction, set to TRX_ID_MAX for free
                views. */
                trx_id_t        m_creator_trx_id;

                /** Set of RW transactions that was active when this snapshot
                was taken */
                ids_t           m_ids;

                /** The view does not need to see the undo logs for transactions
                whose transaction number is strictly smaller (&amp;lt;) than this value:
                they can be removed in purge if not needed by other views */
                trx_id_t        m_low_limit_no;

                /** AC-NL-RO transaction view that has been &quot;closed&quot;. */
                bool            m_closed;

                typedef UT_LIST_NODE_T(ReadView) node_t;

                /** List of read views in trx_sys */
                byte            pad1[64 - sizeof(node_t)];
                node_t          m_view_list;
};
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;重点解释下面几个变量(建议仔细看上面的源码注释，以下仅为个人理解，有理解不到位的地方欢迎指出(●´ω｀●))：&lt;/p&gt;
&lt;p&gt;(1) &lt;code&gt;m_ids&lt;/code&gt;: &lt;code&gt;Read View&lt;/code&gt;创建时其他未提交的活跃事务ID列表。具体说来就是创建&lt;code&gt;Read View&lt;/code&gt;时，将当前未提交事务ID记录下来，后续即使它们修改了记录行的值，对于当前事务也是不可见的。注意：该事务ID列表不包括当前事务自己和已提交的事务。&lt;/p&gt;
&lt;p&gt;(2) &lt;code&gt;m_low_limit_id&lt;/code&gt;：某行数据的&lt;code&gt;DB_TRX_ID &amp;gt;= m_low_limit_id&lt;/code&gt;的任何版本对该查询&lt;code&gt;不可见&lt;/code&gt;。那么这个值是怎么确定的呢？其实就是读的时刻出现过的最大的事务ID+1，即下一个将被分配的事务ID。见&lt;code&gt;https://github.com/mysql/mysql-server/blob/5.7/storage/innobase/read/read0read.cc#L459&lt;/code&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-cpp&quot;&gt;/**
Opens a read view where exactly the transactions serialized before this
point in time are seen in the view.
@param id               Creator transaction id */

void
ReadView::prepare(trx_id_t id)
{
        m_creator_trx_id = id;

        m_low_limit_no = m_low_limit_id = trx_sys-&amp;gt;max_trx_id;
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;max_trx_id&lt;/code&gt;见&lt;code&gt;https://github.com/mysql/mysql-server/blob/5.7/storage/innobase/include/trx0sys.h#L576&lt;/code&gt;中的描述，翻译过来就是“还未分配的最小事务ID”，也就是下一个将被分配的事务ID。（注意，&lt;code&gt;m_low_limit_id&lt;/code&gt;并不是活跃事务列表中最大的事务ID）&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-cpp&quot;&gt;struct trx_sys_t {
/*!&amp;lt; The smallest number not yet
                                        assigned as a transaction id or
                                        transaction number. This is declared
                                        volatile because it can be accessed
                                        without holding any mutex during
                                        AC-NL-RO view creation. */
        volatile trx_id_t max_trx_id;
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;(3) &lt;code&gt;m_up_limit_id&lt;/code&gt;：某行数据的&lt;code&gt;DB_TRX_ID &amp;lt; m_up_limit_id&lt;/code&gt;的所有版本对该查询&lt;code&gt;可见&lt;/code&gt;。同样这个值又是如何确定的呢？&lt;code&gt;m_up_limit_id&lt;/code&gt;是活跃事务列表&lt;code&gt;m_ids&lt;/code&gt;中最小的事务ID，如果trx_ids为空，则&lt;code&gt;m_up_limit_id&lt;/code&gt;为&lt;code&gt;m_low_limit_id&lt;/code&gt;。代码见&lt;code&gt;https://github.com/mysql/mysql-server/blob/5.7/storage/innobase/read/read0read.cc#L485&lt;/code&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-cpp&quot;&gt;void
ReadView::complete()
{
        /* The first active transaction has the smallest id. */
        m_up_limit_id = !m_ids.empty() ? m_ids.front() : m_low_limit_id;

        ut_ad(m_up_limit_id &amp;lt;= m_low_limit_id);

        m_closed = false;
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;这样就有下面的可见性比较算法了。代码见&lt;code&gt;https://github.com/mysql/mysql-server/blob/5.7/storage/innobase/include/read0types.h#L169&lt;/code&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-cpp&quot;&gt;/** Check whether the changes by id are visible.
        @param[in]      id      transaction id to check against the view
        @param[in]      name    table name
        @return whether the view sees the modifications of id. */
bool changes_visible(
        trx_id_t                id,
        const table_name_t&amp;amp; name) const
        MY_ATTRIBUTE((warn_unused_result))
{
        ut_ad(id &amp;gt; 0);


        /* 假如 trx_id 小于 Read view 限制的最小活跃事务ID m_up_limit_id 或者等于正在创建的事务ID m_creator_trx_id
     * 即满足事务的可见性.
     */
        if (id &amp;lt; m_up_limit_id || id == m_creator_trx_id) {
                return(true);
        }

        /* 检查 trx_id 是否有效. */
        check_trx_id_sanity(id, name);

        if (id &amp;gt;= m_low_limit_id) {
                /* 假如 trx_id 大于等于m_low_limit_id, 即不可见. */
                return(false);

        } else if (m_ids.empty()) {
                /* 假如目前不存在活跃的事务，即可见. */
                return(true);
        }

        const ids_t::value_type*        p = m_ids.data();

        /* 利用二分查找搜索活跃事务列表
         * 当 trx_id 在 m_up_limit_id 和 m_low_limit_id 之间
   * 如果 id 在 m_ids 数组中, 表明 ReadView 创建时候，事务处于活跃状态，因此记录不可见.
   */
        return (!std::binary_search(p, p + m_ids.size(), id));
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1546632/202010/1546632-20201018232747852-703197062.png&quot; alt=&quot;事务可见性比较算法图示&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;完整梳理一下整个过程。&lt;/p&gt;
&lt;p&gt;在&lt;code&gt;InnoDB&lt;/code&gt;中，创建一个新事务后，执行第一个&lt;code&gt;select&lt;/code&gt;语句的时候，&lt;code&gt;InnoDB&lt;/code&gt;会创建一个快照（&lt;code&gt;read view&lt;/code&gt;），快照中会保存系统当前不应该被本事务看到的其他活跃事务id列表（即&lt;code&gt;m_ids&lt;/code&gt;）。当用户在这个事务中要读取某个记录行的时候，&lt;code&gt;InnoDB&lt;/code&gt;会将该记录行的&lt;code&gt;DB_TRX_ID&lt;/code&gt;与该&lt;code&gt;Read View&lt;/code&gt;中的一些变量进行比较，判断是否满足可见性条件。&lt;/p&gt;
&lt;p&gt;假设当前事务要读取某一个记录行，该记录行的&lt;code&gt;DB_TRX_ID&lt;/code&gt;（即最新修改该行的事务ID）为&lt;code&gt;trx_id&lt;/code&gt;，&lt;code&gt;Read View&lt;/code&gt;的活跃事务列表&lt;code&gt;m_ids&lt;/code&gt;中最早的事务ID为&lt;code&gt;m_up_limit_id&lt;/code&gt;，将在生成这个&lt;code&gt;Read Vew&lt;/code&gt;时系统出现过的最大的事务ID+1记为&lt;code&gt;m_low_limit_id&lt;/code&gt;（即还未分配的事务ID）。&lt;/p&gt;
&lt;p&gt;具体的比较算法如下:&lt;/p&gt;
&lt;ol readability=&quot;4&quot;&gt;&lt;li readability=&quot;1&quot;&gt;
&lt;p&gt;如果&lt;code&gt;trx_id &amp;lt; m_up_limit_id&lt;/code&gt;,那么表明“最新修改该行的事务”在“当前事务”创建快照之前就提交了，所以该记录行的值对当前事务是可见的。跳到步骤5。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;2&quot;&gt;
&lt;p&gt;如果&lt;code&gt;trx_id &amp;gt;= m_low_limit_id&lt;/code&gt;, 那么表明“最新修改该行的事务”在“当前事务”创建快照之后才修改该行，所以该记录行的值对当前事务不可见。跳到步骤4。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;2&quot;&gt;
&lt;p&gt;如果&lt;code&gt;m_up_limit_id &amp;lt;= trx_id &amp;lt; m_low_limit_id&lt;/code&gt;, 表明“最新修改该行的事务”在“当前事务”创建快照的时候可能处于“活动状态”或者“已提交状态”；所以就要对活跃事务列表trx_ids进行查找（源码中是用的二分查找，因为是有序的）&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;(1) 如果在活跃事务列表&lt;code&gt;m_ids&lt;/code&gt;中能找到id为&lt;code&gt;trx_id&lt;/code&gt;的事务，表明①在“当前事务”创建快照前，“该记录行的值”被“id为&lt;code&gt;trx_id&lt;/code&gt;的事务”修改了，但没有提交；或者②在“当前事务”创建快照后，“该记录行的值”被“id为&lt;code&gt;trx_id&lt;/code&gt;的事务”修改了（不管有无提交）；这些情况下，这个记录行的值对当前事务都是不可见的，跳到步骤4；&lt;/p&gt;
&lt;p&gt;(2) 在活跃事务列表中找不到，则表明“id为&lt;code&gt;trx_id&lt;/code&gt;的事务”在修改“该记录行的值”后，在“当前事务”创建快照前就已经提交了，所以记录行对当前事务可见，跳到步骤5。&lt;/p&gt;
&lt;ol start=&quot;4&quot; readability=&quot;0&quot;&gt;&lt;li readability=&quot;1&quot;&gt;
&lt;p&gt;在该记录行的&lt;code&gt;DB_ROLL_PTR&lt;/code&gt;指针所指向的&lt;code&gt;undo log&lt;/code&gt;回滚段中，取出最新的的旧事务号&lt;code&gt;DB_TRX_ID&lt;/code&gt;, 将它赋给&lt;code&gt;trx_id&lt;/code&gt;，然后跳到步骤1重新开始判断。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;将该可见行的值返回。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;&lt;h3 id=&quot;read-committed与repeatable-read的区别&quot;&gt;read committed与repeatable read的区别&lt;/h3&gt;
&lt;p&gt;有了上面的知识铺垫后，就可以从本质上区别&lt;code&gt;read committed&lt;/code&gt;与&lt;code&gt;repeatable read&lt;/code&gt;这两种事务隔离级别了。&lt;/p&gt;
&lt;blockquote readability=&quot;9&quot;&gt;
&lt;p&gt;With REPEATABLE READ isolation level, the snapshot is based on the time when the first read operation is performed. With READ COMMITTED isolation level, the snapshot is reset to the time of each consistent read operation.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;在&lt;code&gt;InnoDB&lt;/code&gt;中的&lt;code&gt;repeatable read&lt;/code&gt;级别, 事务&lt;code&gt;begin&lt;/code&gt;之后，执行第一条&lt;code&gt;select&lt;/code&gt;（读操作）时, 会创建一个快照(&lt;code&gt;read view&lt;/code&gt;)，将当前系统中活跃的其他事务记录起来；并且在此事务中之后的其他&lt;code&gt;select&lt;/code&gt;操作都是使用的这个&lt;code&gt;read view&lt;/code&gt;对象，不会重新创建，直到事务结束。&lt;/p&gt;
&lt;p&gt;在&lt;code&gt;InnoDB&lt;/code&gt;中的&lt;code&gt;read committed&lt;/code&gt;级别, 事务&lt;code&gt;begin&lt;/code&gt;之后，执行每条&lt;code&gt;select&lt;/code&gt;（读操作）语句时，快照会被重置，即会基于当前&lt;code&gt;select&lt;/code&gt;重新创建一个快照(&lt;code&gt;read view&lt;/code&gt;)，所以显然该事务隔离级别下会读到其他事务已经提交的修改数据。&lt;/p&gt;
&lt;p&gt;那么，现在能解释上面演示&lt;code&gt;幻读&lt;/code&gt;问题时，出现的诡异结果吗？我的理解是，因为是在&lt;code&gt;repeatable read&lt;/code&gt;隔离级别下，肯定还是快照读，即第一次&lt;code&gt;select&lt;/code&gt;后创建的&lt;code&gt;read view&lt;/code&gt;对象还是不变的，但是在当前事务中&lt;code&gt;update&lt;/code&gt;一条记录时，会把当前事务ID设置到更新后的记录的隐藏字段&lt;code&gt;DB_TRX_ID&lt;/code&gt;上，即&lt;code&gt;id == m_creator_trx_id&lt;/code&gt;显然成立，于是该条记录就可见了，再次执行&lt;code&gt;select&lt;/code&gt;操作时就多出这条记录了。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-cpp&quot;&gt;if (id &amp;lt; m_up_limit_id || id == m_creator_trx_id) {
  return(true);
 }
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;另外，有了这样的基本认知后，如果你在MySQL事务隔离相关问题遇到一些其他看似很神奇的现象，也可以试试能不能解释得通。&lt;/p&gt;
&lt;h2 id=&quot;总结&quot;&gt;总结&lt;/h2&gt;
&lt;p&gt;通过学习MySQL事务隔离级别及&lt;code&gt;MVCC&lt;/code&gt;原理机制，有助于加深对MySQL的理解与掌握，更为重要的是，如果让你编写一个并发读写的存储程序，&lt;code&gt;MVCC&lt;/code&gt;的设计与实现或许能给你一些启发。&lt;/p&gt;
</description>
<pubDate>Mon, 19 Oct 2020 00:30:00 +0000</pubDate>
<dc:creator>行无际</dc:creator>
<og:description>回顾前文: 一文学会MySQL的explain工具 一文读懂MySQL的索引结构及查询优化 (同时再次强调，这几篇关于MySQL的探究都是基于5.7版本，相关总结与结论不一定适用于其他版本) 就软件开</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/itwild/p/13796221.html</dc:identifier>
</item>
<item>
<title>为什么堆化 heapify() 只用 O(n) 就做到了？ - 码农田小齐</title>
<link>http://www.cnblogs.com/nycsde/p/13838180.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/nycsde/p/13838180.html</guid>
<description>&lt;h2 id=&quot;heapify&quot;&gt;heapify()&lt;/h2&gt;
&lt;p&gt;前面两篇文章介绍了什么是堆以及堆的两个基本操作，但其实呢，堆还有一个大名鼎鼎的非常重要的操作，就是 &lt;code&gt;heapify()&lt;/code&gt; 了，它是一个很神奇的操作，&lt;/p&gt;
&lt;h4 id=&quot;可以用-on-的时间把一个乱序的数组变成一个-heap。&quot;&gt;可以用 &lt;code&gt;O(n)&lt;/code&gt; 的时间把一个乱序的数组变成一个 heap。&lt;/h4&gt;
&lt;p&gt;但是呢，&lt;code&gt;heapify()&lt;/code&gt; 并不是一个 public API，看：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/2000306/202010/2000306-20201019081015091-1668926016.jpg&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;所以我们没有办法直接使用。&lt;/p&gt;
&lt;p&gt;唯一使用 &lt;code&gt;heapify()&lt;/code&gt; 的方式呢，就是使用&lt;br/&gt;&lt;code&gt;PriorityQueue(Collection&amp;lt;? extends E&amp;gt; c)&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;这个 constructor 的时候，人家会自动调用 heapify() 这个操作。&lt;/p&gt;
&lt;p&gt;&lt;span&gt;那具体是怎么做的呢？&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;哈哈源码已经暴露了：&lt;/p&gt;
&lt;h4 id=&quot;从最后一个非叶子节点开始，从后往前做-siftdown&quot;&gt;从最后一个非叶子节点开始，从后往前做 &lt;code&gt;siftDown()&lt;/code&gt;.&lt;/h4&gt;
&lt;p&gt;因为叶子节点没必要操作嘛，已经到了最下面了，还能和谁 swap？&lt;/p&gt;
&lt;p&gt;举个例子：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/2000306/202010/2000306-20201019081016128-778595507.jpg&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;我们想把这个数组进行 &lt;code&gt;heapify()&lt;/code&gt; 操作，想把它变成一个最小堆，拿到它的最小值。&lt;/p&gt;
&lt;p&gt;那就要从 3 开始，对 3，7，5进行 &lt;code&gt;siftDown()&lt;/code&gt;.&lt;/p&gt;
&lt;h4 id=&quot;step-1&quot;&gt;Step 1.&lt;/h4&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/2000306/202010/2000306-20201019081016924-1503772762.jpg&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;尴尬 😅，3 并不用交换，因为以它为顶点的这棵小树已经满足了堆序性。&lt;/p&gt;
&lt;h4 id=&quot;step-2&quot;&gt;Step 2.&lt;/h4&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/2000306/202010/2000306-20201019081017933-436376318.jpg&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;7 比它的两个孩子都要大，所以和较小的那个交换一下。&lt;/p&gt;
&lt;p&gt;交换完成后；&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/2000306/202010/2000306-20201019081018541-2001300434.jpg&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h4 id=&quot;step-3&quot;&gt;Step 3.&lt;/h4&gt;
&lt;p&gt;最后一个要处理的就是 5 了，那这里 5 比它的两个孩子都要大，所以也和较小的那个交换一下。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/2000306/202010/2000306-20201019081019030-988510324.jpg&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;换完之后结果如下，注意并没有满足堆序性，因为 4 还比 5 小呢。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/2000306/202010/2000306-20201019081019665-1917480673.jpg&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;所以接着和 4 换，结果如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/2000306/202010/2000306-20201019081020125-886886013.jpg&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;这样整个 &lt;code&gt;heapify()&lt;/code&gt; 的过程就完成了。&lt;/p&gt;
&lt;h4 id=&quot;好了难点来了，为什么时间复杂度是-on-的呢？&quot;&gt;好了难点来了，为什么时间复杂度是 O(n) 的呢？&lt;/h4&gt;
&lt;p&gt;怎么计算这个时间复杂度呢？&lt;/p&gt;
&lt;p&gt;其实我们在这个过程里做的操作无非就是交换交换。&lt;/p&gt;
&lt;p&gt;那到底交换了多少次呢？&lt;/p&gt;
&lt;p&gt;没错，交换了多少次，时间复杂度就是多少。&lt;/p&gt;
&lt;p&gt;那我们可以看出来，其实&lt;strong&gt;同一层的节点&lt;/strong&gt;最多交换的次数都是相同的。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;那么这个总的交换次数 = 每层的节点数 * 每个节点最多交换的次数&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/2000306/202010/2000306-20201019081020655-918114387.jpg&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;这里设 k 为层数，那么这个例子里 k=3.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;每层的节点数是从上到下以指数增长：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;$$\ce{1, 2, 4, ..., 2^{k-1}}$$&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;每个节点交换的次数，&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;从下往上就是：&lt;/p&gt;
&lt;p&gt;$$ 0, 1, ..., k-2, k-1 $$&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;那么总的交换次数 &lt;em&gt;S(k)&lt;/em&gt; 就是两者相乘再相加：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;$$S(k) = \left(2^{0} *(k-1) + 2^{1} *(k-2) + ... + 2^{k-2} *1 \right)$$&lt;/p&gt;
&lt;p&gt;这是一个等比等差数列，标准的求和方式就是&lt;strong&gt;错位相减法&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;那么&lt;br/&gt;$$2S(k) = \left(2^{1} *(k-1) + 2^{2} *(k-2) + ... + 2^{k-1} *1 \right)$$&lt;/p&gt;
&lt;p&gt;两者相减得：&lt;/p&gt;
&lt;p&gt;$$S(k) = \left(-2^{0} *(k-1) + 2^{1} + 2^{2} + ... + 2^{k-2} + 2^{k-1} \right)$$&lt;/p&gt;
&lt;p&gt;化简一下：&lt;/p&gt;
&lt;p&gt;（不好意思我实在受不了这个编辑器了。。。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/2000306/202010/2000306-20201019081021192-1536740698.jpg&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;所以 &lt;code&gt;heapify()&lt;/code&gt; 时间复杂度是 &lt;code&gt;O(n)&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;以上就是堆的三大重要操作，最后一个 &lt;code&gt;heapify()&lt;/code&gt; 虽然不能直接操作，但是堆排序中用到了这种思路，之前的「选择排序」那篇文章里也提到了一些，感兴趣的同学可以后台回复「选择排序」获得文章～至于堆排序的具体实现和应用，以及为什么实际生产中并不爱用它，我们之后再讲。&lt;/p&gt;
&lt;p&gt;如果你喜欢这篇文章，记得给我点赞留言哦～你们的支持和认可，就是我创作的最大动力，我们下篇文章见！&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;我是小齐，纽约程序媛，终生学习者，每天晚上 9 点，云自习室里不见不散！&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;更多干货文章见我的 Github: &lt;a href=&quot;https://github.com/xiaoqi6666/NYCSDE&quot;&gt;https://github.com/xiaoqi6666/NYCSDE&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
</description>
<pubDate>Mon, 19 Oct 2020 00:10:00 +0000</pubDate>
<dc:creator>码农田小齐</dc:creator>
<og:description>heapify() 前面两篇文章介绍了什么是堆以及堆的两个基本操作，但其实呢，堆还有一个大名鼎鼎的非常重要的操作，就是 heapify() 了，它是一个很神奇的操作， 可以用 O(n) 的时间把一个乱</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/nycsde/p/13838180.html</dc:identifier>
</item>
<item>
<title>eShopOnContainers 知多少[12]：Envoy gateways - 「圣杰」</title>
<link>http://www.cnblogs.com/sheng-jie/p/use-envoy-proxy-as-apigateways-in-eshoponcontainers.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/sheng-jie/p/use-envoy-proxy-as-apigateways-in-eshoponcontainers.html</guid>
<description>&lt;p&gt;&lt;img src=&quot;https://upload-images.jianshu.io/upload_images/2799767-907fa556a105bc40.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;

&lt;p&gt;在最新的eShopOnContainers 3.0 中Ocelot 网关被Envoy Proxy 替换。下面就来简要带大家了解下Envoy，并尝试梳理下为什么要使用Envoy替代Ocelot。&lt;/p&gt;

&lt;blockquote readability=&quot;6.7865853658537&quot;&gt;
&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://www.envoyproxy.io&quot;&gt;ENVOY&lt;/a&gt;&lt;/strong&gt; IS AN OPEN SOURCE EDGE AND SERVICE PROXY, DESIGNED FOR CLOUD-NATIVE APPLICATIONS.&lt;br/&gt;&lt;em&gt;Enovy(信使) 是一款开源的专为云原生应用设计的服务代理&lt;/em&gt;。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;21-快速体验&quot;&gt;2.1. 快速体验&lt;/h2&gt;
&lt;p&gt;首先基于本地Dockers快速体验以下，先启动本地Docker-Desktop，拉取Envoy镜像：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;&amp;gt; docker search envoy-dev
NAME                        DESCRIPTION                                     STARS               OFFICIAL            AUTOMATED
envoyproxy/envoy            Images for tagged releases. Use envoy-dev fo…   96
&amp;gt; docker image pull envoyproxy:envoy-dev
latest: Pulling from envoyproxy/envoy-dev
171857c49d0f: Pull complete
419640447d26: Pull complete
61e52f862619: Pull complete
3f2a8c910457: Pull complete
b2ce823b3fd3: Pull complete
ec09faba9bc7: Pull complete
b0b9168845d0: Pull complete
39a220277151: Pull complete
9081a11f5983: Pull complete
1880b475bc3a: Pull complete
Digest: sha256:cd8dbbbd8ce4c8c6eb52e4f8eebf55f29d1e597ca8311fecf9eda08b8cca813a
Status: Downloaded newer image for envoyproxy/envoy-dev:latest
docker.io/envoyproxy/envoy-dev:latest
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;该Docker 镜像将包含最新版本的 Envoy 和一个基本的 Envoy 配置，可以将10000端口的入站请求路由到&lt;code&gt;www.google.com&lt;/code&gt;。&lt;br/&gt;下面启动容器测试：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;&amp;gt; docker run -d --name envoy -p 10000:10000 envoyproxy/envoy-dev:latest
27e422f34b389d99e9180e47d8109a19975ccd139f42ac2f4fa9f724906b72f6
&amp;gt; docker ps | findstr 'envoy'
27e422f34b38        envoyproxy/envoy-dev:latest   &quot;/docker-entrypoint.??   2 minutes ago        Up 2 minutes       0.0.0.0:10000-&amp;gt;10000/tcp   envoy
&amp;gt; curl -I http://localhost:10000
HTTP/1.1 200 OK
content-type: text/html; charset=ISO-8859-1
p3p: CP=&quot;This is not a P3P policy! See g.co/p3phelp for more info.&quot;
date: Sat, 17 Oct 2020 04:38:38 GMT
server: envoy
x-xss-protection: 0
x-frame-options: SAMEORIGIN
expires: Sat, 17 Oct 2020 04:38:38 GMT
cache-control: private
set-cookie: 1P_JAR=2020-10-17-04; expires=Mon, 16-Nov-2020 04:38:38 GMT; path=/; domain=.google.com; Secure
set-cookie: NID=204=h0EoJXNOTbQA11L-tVowqcwloS0-BCTR71IeN4irsmpubdPIIS4sU8Gco79pt1NhONAxxFdUJ46SKvbX4Ni-jKMWbSW0k_kn3fFkVrfLm7OOBbAtUWtxGGOCRJGbSNIRyOPfDB7_wMngEWW3yoFEs9diSCtZK9DWFZdtJJZtWuI; expires=Sun, 18-Apr-2021 04:38:38 GMT; path=/; domain=.google.com; HttpOnly
alt-svc: h3-Q050=&quot;:443&quot;; ma=2592000,h3-29=&quot;:443&quot;; ma=2592000,h3-27=&quot;:443&quot;; ma=2592000,h3-T051=&quot;:443&quot;; ma=2592000,h3-T050=&quot;:443&quot;; ma=2592000,h3-Q046=&quot;:443&quot;; ma=2592000,h3-Q043=&quot;:443&quot;; ma=2592000,quic=&quot;:443&quot;; ma=2592000; v=&quot;46,43&quot;
x-envoy-upstream-service-time: 37
transfer-encoding: chunked
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;em&gt;PS: 请确保本地机器能访问Google，否则&lt;code&gt;curl -I http://localhost:10000&lt;/code&gt; 会出错。&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;接下来我们进入容器内部，查看下配置文件，默认路径为&lt;code&gt;/etc/envoy/envoy.yaml&lt;/code&gt;：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;docker exec -it envoy /bin/bash
root@27e422f34b38:/# cat /etc/envoy/envoy.yaml
admin:
  access_log_path: /tmp/admin_access.log
  address:
    socket_address:
      protocol: TCP
      address: 127.0.0.1
      port_value: 9901
static_resources:
  listeners:
  - name: listener_0
    address:
      socket_address:
        protocol: TCP
        address: 0.0.0.0
        port_value: 10000
    filter_chains:
    - filters:
      - name: envoy.filters.network.http_connection_manager
        typed_config:
          &quot;@type&quot;: type.googleapis.com/envoy.extensions.filters.network.http_connection_manager.v3.HttpConnectionManager
          stat_prefix: ingress_http
          route_config:
            name: local_route
            virtual_hosts:
            - name: local_service
              domains: [&quot;*&quot;]
              routes:
              - match:
                  prefix: &quot;/&quot;
                route:
                  host_rewrite_literal: www.google.com
                  cluster: service_google
          http_filters:
          - name: envoy.filters.http.router
  clusters:
  - name: service_google
    connect_timeout: 30s
    type: LOGICAL_DNS
    # Comment out the following line to test on v6 networks
    dns_lookup_family: V4_ONLY
    lb_policy: ROUND_ROBIN
    load_assignment:
      cluster_name: service_google
      endpoints:
      - lb_endpoints:
        - endpoint:
            address:
              socket_address:
                address: www.google.com
                port_value: 443
    transport_socket:
      name: envoy.transport_sockets.tls
      typed_config:
        &quot;@type&quot;: type.googleapis.com/envoy.extensions.transport_sockets.tls.v3.UpstreamTlsContext
        sni: www.google.com
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;我们把上面的配置文件拷贝到本地，将上面的&lt;code&gt;www.google.com&lt;/code&gt;改为&lt;code&gt;www.baidu.com&lt;/code&gt;，将&lt;code&gt;admin.address.socket_address.address: 127.0.0.1&lt;/code&gt;该为&lt;code&gt;0.0.0.0&lt;/code&gt;，然后把配置文件命名为&lt;code&gt;envoy-baidu.yaml&lt;/code&gt;，然后挂载到容器的&lt;code&gt;/etc/envoy/envoy.yaml&lt;/code&gt;。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;&amp;gt; docker run --rm -d --name envoy-baidu -v $Home/k8s/envoy-baidu.yaml:/etc/envoy/envoy.yaml -p 9901:9901 -p 15001:15001 envoyproxy/envoy-dev:latest
&amp;gt; docker ps | findstr 'envoy'
f07f6a1e9305        envoyproxy/envoy-dev:latest   &quot;/docker-entrypoint.??   2 minutes ago       Up 2 minutes        10000/tcp, 0.0.0.0:9901-&amp;gt;9901/tcp, 0.0.0.0:15001-&amp;gt;15001/tcp   envoy-baidu
3cd12b5f6ddd        envoyproxy/envoy-dev:latest   &quot;/docker-entrypoint.??   About an hour ago   Up About an hour    0.0.0.0:10000-&amp;gt;10000/tcp              envoy
&amp;gt; curl -I http://localhost:15001
HTTP/1.1 200 OK
accept-ranges: bytes
cache-control: private, no-cache, no-store, proxy-revalidate, no-transform
content-length: 277
content-type: text/html
date: Sat, 17 Oct 2020 05:41:01 GMT
etag: &quot;575e1f65-115&quot;
last-modified: Mon, 13 Jun 2016 02:50:13 GMT
pragma: no-cache
server: envoy
x-envoy-upstream-service-time: 24
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;使用浏览器访问http://localhost:9901即可访问envoy管理页面，如下图所示：&lt;br/&gt;&lt;img src=&quot;https://upload-images.jianshu.io/upload_images/2799767-799930f950c87a20.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240&quot; alt=&quot;envoy admin page&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h2 id=&quot;22-配置简介&quot;&gt;2.2. 配置简介&lt;/h2&gt;
&lt;p&gt;第一次看Envoy的配置文件，和第一次接触Nginx的配置文件一样，绝对一脸懵逼。没关系，咱们来理一理。&lt;/p&gt;
&lt;p&gt;作为一个代理，不管是Nginx、HAProxy，还是Envoy，其处理流程都是一样的。其首先都是要监听指定端口获取请求流量，然后分析请求数据，进行请求转发。脑补完大致流程后，再来看 Envoy 是如何组织配置信息的。先来了几个核心配置：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;listener&lt;/strong&gt; : Envoy 的监听地址，用来接收请求，处理入站请求。Envoy 会暴露一个或多个 Listener 来监听客户端的请求。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;filter&lt;/strong&gt; : 过滤器是处理入站和出站流量的链式结构的一部分。在过滤器链上可以集成很多特定功能的过滤器，例如，通过集成 GZip 过滤器可以在数据发送到客户端之前压缩数据。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;route_config&lt;/strong&gt; : 路由规则配置。即将请求路由到后端的哪个集群。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;cluster&lt;/strong&gt; : 集群定义了流量的目标端点，同时还包括一些其他可选配置，如负载均衡策略等。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;整体流程如下图所示：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://upload-images.jianshu.io/upload_images/2799767-51ed0f50d336c308.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240&quot; alt=&quot;图片来源：https://fuckcloudnative.io/envoy-handbook/docs/gettingstarted/quick-start/&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h2 id=&quot;23-代理-aspnet-core-webapi&quot;&gt;2.3. 代理 ASP.NET Core WebApi&lt;/h2&gt;
&lt;p&gt;有了上面的基础，下面尝试使用Envoy代理ASP.NET Core WebApi。&lt;br/&gt;首先创建两个简单API，然后创建一个Envoy配置文件，最后通过docker compose启动三个容器进行测试。由于项目文件结构简单，这里不再过多阐述，主要包含四个部分：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;City Api&lt;/li&gt;
&lt;li&gt;Weather Api&lt;/li&gt;
&lt;li&gt;Envoy 代理配置&lt;/li&gt;
&lt;li&gt;docker compose 配置&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;整体解决方案如下图所示。源码路径：&lt;a href=&quot;https://github.com/sheng-jie/dotnet.on.k8s/tree/master/K8S.NET.Envoy&quot;&gt;K8S.NET.Envoy&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://upload-images.jianshu.io/upload_images/2799767-dcab57e426d6dcc0.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;Envoy 代理配置基于第一节的基础上进行修改，如下所示：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;admin:
  access_log_path: /tmp/admin_access.log
  address:
    socket_address:
      protocol: TCP
      address: 0.0.0.0
      port_value: 9903
static_resources:
  listeners:
    - name: listener_0
      address:
        socket_address:
          protocol: TCP
          address: 0.0.0.0
          port_value: 10003
      filter_chains:
        - filters:
            - name: envoy.filters.network.http_connection_manager
              typed_config:
                &quot;@type&quot;: type.googleapis.com/envoy.config.filter.network.http_connection_manager.v2.HttpConnectionManager
                stat_prefix: ingress_http
                route_config:
                  name: local_route
                  virtual_hosts:
                    - name: local_service
                      domains: [&quot;*&quot;]
                      routes:
                        - match:
                            prefix: &quot;/c&quot;
                          route:
                            prefix_rewrite: &quot;/city&quot;
                            cluster: city_service
                        - match:
                            prefix: &quot;/w&quot;
                          route:
                            prefix_rewrite: &quot;/weather&quot;
                            cluster: weather_service
                http_filters:
                  - name: envoy.filters.http.router
  clusters:
    - name: city_service
      connect_timeout: 0.25s
      type: LOGICAL_DNS
      # Comment out the following line to test on v6 networks
      dns_lookup_family: V4_ONLY
      lb_policy: ROUND_ROBIN
      load_assignment:
        cluster_name: city_service
        endpoints:
          - lb_endpoints:
              - endpoint:
                  address:
                    socket_address:
                      address: cityapi
                      port_value: 80
    - name: weather_service
      connect_timeout: 0.25s
      type: LOGICAL_DNS
      # Comment out the following line to test on v6 networks
      dns_lookup_family: V4_ONLY
      lb_policy: ROUND_ROBIN
      load_assignment:
        cluster_name: weather_service
        endpoints:
          - lb_endpoints:
              - endpoint:
                  address:
                    socket_address:
                      address: weatherapi
                      port_value: 80
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;以上配置Envoy监听&lt;code&gt;10003&lt;/code&gt;端口，通过指定&lt;code&gt;prefix_rewrite&lt;/code&gt;重写前缀，将&lt;code&gt;/c&lt;/code&gt;路由至&lt;code&gt;cityapi&lt;/code&gt;的&lt;code&gt;/city&lt;/code&gt;路径，将&lt;code&gt;/w&lt;/code&gt;路由至&lt;code&gt;weatherapi&lt;/code&gt;的&lt;code&gt;/weather&lt;/code&gt;路径。&lt;/p&gt;
&lt;p&gt;docker-compose配置如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;version: '3'
services:
  envoygateway:
    build: Envoy/
    ports:
      - &quot;9903:9903&quot;
      - &quot;10003:10003&quot;
    volumes:
      - ./Envoy/envoy.yaml:/etc/envoy/envoy.yaml
  cityapi:
    build: K8S.NET.CityApi/
    ports:
      - &quot;8080:80&quot;
    environment:
      ASPNETCORE_URLS: &quot;http://+&quot;
      ASPNETCORE_ENVIRONMENT: &quot;Development&quot;

  weatherapi:
    build: K8S.NET.WeatherApi/
    ports:
      - &quot;8082:80&quot;
    environment:
      ASPNETCORE_URLS: &quot;http://+&quot;
      ASPNETCORE_ENVIRONMENT: &quot;Development&quot;
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;从上可以看到，主要用来启动三个服务：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;envoy gateway：其中将项目路径下&lt;code&gt;/Envoy/envoy.yaml&lt;/code&gt;挂载到容器目录&lt;code&gt;/etc/envoy/envoy.yaml&lt;/code&gt;。同时暴露2个端口，9903，10003。&lt;/li&gt;
&lt;li&gt;city api&lt;/li&gt;
&lt;li&gt;weather api&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;因此最终可以通过以下路径进行访问：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;&lt;a href=&quot;http://localhost:10003/c&quot;&gt;http://localhost:10003/c&lt;/a&gt; 访问city api。&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://localhost:10003/w&quot;&gt;http://localhost:10003/w&lt;/a&gt; 访问weather api。&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;执行以下命令，启动应用和代理，并测试：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;&amp;gt; docker-compose up -d
Starting k8snetenvoy_envoygateway_1 ... done
Starting k8snetenvoy_cityapi_1      ... done
Starting k8snetenvoy_weatherapi_1   ... done
&amp;gt; docker-compose ps
           Name                         Command               State                         Ports
-----------------------------------------------------------------------------------------------------------------------
k8snetenvoy_cityapi_1        dotnet K8S.NET.CityApi.dll       Up      443/tcp, 0.0.0.0:8080-&amp;gt;80/tcp
k8snetenvoy_envoygateway_1   /docker-entrypoint.sh envo ...   Up      10000/tcp, 0.0.0.0:10003-&amp;gt;10003/tcp,
                                                                      0.0.0.0:9903-&amp;gt;9903/tcp
k8snetenvoy_weatherapi_1     dotnet K8S.NET.WeatherApi.dll    Up      443/tcp, 0.0.0.0:8082-&amp;gt;80/tcp

&amp;gt; curl http://localhost:10003/c
Shanghai
&amp;gt; curl http://localhost:10003/w
Cool
&lt;/code&gt;
&lt;/pre&gt;

&lt;p&gt;eShopOnContainer 中主要定义了四个API 网关（BFF 模式），服务间通信方式主要有两种，一种是HTTP，一种是gRPC。如果启用Service Mesh并且部署至K8S，服务整体通信架构如下图所示：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://upload-images.jianshu.io/upload_images/2799767-47be05d0bd32c83d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;有两点需要补充说明：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;&lt;a href=&quot;https://linkerd.io&quot;&gt;Linkerd&lt;/a&gt;是一种Service Mesh，其核心思想是借助&lt;strong&gt;Sidecar&lt;/strong&gt;模式无侵入式对应用进行服务治理，包括服务发现、流量管理、负载均衡、路由等。&lt;/li&gt;
&lt;li&gt;了解过Istio（目前比较流行的Service Mesh）应该知道，Envoy在Istio中作为Sidecar而存在，而在eShopOnContainers中Envoy被充当API Gateways。&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;基于上面的基础，再来看eShopOnContainers中的配置，其实就很明白了，主要是配置文件从Ocelot 转变到envoy.yaml，配置如下图所示。&lt;br/&gt;&lt;img src=&quot;https://upload-images.jianshu.io/upload_images/2799767-5425c94996b90bd5.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240&quot; alt=&quot;eShopOnContainers envoy proxy configuration&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;路由配置如下：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;/m/ 、/marketing-api/ 路由至：marketing api&lt;/li&gt;
&lt;li&gt;/c/、/catalog-api/ 路由至：catalog api&lt;/li&gt;
&lt;li&gt;/o/、/ordering-api/ 路由至：ordering api&lt;/li&gt;
&lt;li&gt;/b/、/basket-api/ 路由至：basket api&lt;/li&gt;
&lt;li&gt;/ 路由至：web bff aggregator api&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;部署时，基于helm将&lt;code&gt;envoy.yaml&lt;/code&gt;保存至&lt;code&gt;ConfigMap&lt;/code&gt;，在基于&lt;code&gt;envoyproxy/enovy&lt;/code&gt;镜像构建容器，将配置从&lt;code&gt;ConfigMap&lt;/code&gt;挂载到容器中，容器内部即可基于配置启动Envoy 网关了。&lt;br/&gt;&lt;img src=&quot;https://upload-images.jianshu.io/upload_images/2799767-7166fb7fafa25e35.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;

&lt;p&gt;经过上面的了解发现，Envoy还是充当的网关角色，那为什么要替换呢？ 先来了解下Envoy的优势：&lt;/p&gt;
&lt;ul readability=&quot;8.3598090277778&quot;&gt;&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;&lt;strong&gt;非侵入式架构&lt;/strong&gt; : &lt;code&gt;Envoy&lt;/code&gt; 基于&lt;code&gt;Sidecar&lt;/code&gt;模式，是一个独立进程，对应用透明。（在eShopOnContainer中还是独立的网关项目，并非以&lt;code&gt;Sidecar&lt;/code&gt;模式注入到服务中。）&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://upload-images.jianshu.io/upload_images/2799767-d4f4df96d0ad4b1a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;&lt;strong&gt;基于C++开发实现&lt;/strong&gt;：拥有强大的定制化能力和优异的性能。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;&lt;strong&gt;L3/L4/L7 架构&lt;/strong&gt; : 传统的网络代理，要么在 &lt;code&gt;HTTP&lt;/code&gt; 层工作，要么在 &lt;code&gt;TCP&lt;/code&gt; 层工作。而&lt;code&gt;Envoy&lt;/code&gt; 同时支持 3/4 层和 7 层代理。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;&lt;strong&gt;顶级 HTTP/2 支持&lt;/strong&gt; : 它将 &lt;code&gt;HTTP/2&lt;/code&gt; 视为一等公民，并且可以在 &lt;code&gt;HTTP/2&lt;/code&gt; 和 &lt;code&gt;HTTP/1.1&lt;/code&gt; 之间相互转换（双向），建议使用 &lt;code&gt;HTTP/2&lt;/code&gt;。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;&lt;strong&gt;gRPC 支持&lt;/strong&gt; : Envoy 完美支持 HTTP/2，也可以很方便地支持 &lt;code&gt;gRPC&lt;/code&gt; (&lt;a href=&quot;http://www.grpc.io/&quot;&gt;gRPC&lt;/a&gt; 使用 &lt;code&gt;HTTP/2&lt;/code&gt; 作为底层多路复用传输协议)。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;&lt;strong&gt;服务发现和动态配置&lt;/strong&gt; : 与 &lt;code&gt;Nginx&lt;/code&gt; 等代理的热加载不同，&lt;code&gt;Envoy&lt;/code&gt; 可以通过 &lt;code&gt;API&lt;/code&gt; 接口动态更新配置，无需重启代理。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;&lt;strong&gt;特殊协议支持&lt;/strong&gt; : Envoy 支持对特殊协议在 L7 进行嗅探和统计，包括：&lt;a href=&quot;https://www.envoyproxy.io/docs/envoy/latest/configuration/listeners/network_filters/mongo_proxy_filter#&quot;&gt;MongoDB&lt;/a&gt;、&lt;a href=&quot;https://www.servicemesher.com/envoy/intro/arch_overview/dynamo.html#arch-overview-dynamo&quot;&gt;DynamoDB&lt;/a&gt; 等。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;&lt;strong&gt;可观测性&lt;/strong&gt; : &lt;code&gt;Envoy&lt;/code&gt; 内置 &lt;code&gt;stats&lt;/code&gt; 模块，可以集成诸如 &lt;code&gt;prometheus/statsd&lt;/code&gt; 等监控方案。还可以集成分布式追踪系统，对请求进行追踪。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;再来看下Ocelot：其本质还是ASP.NET Core中的一个请求中间件。只能进行7层代理，不支持 gRPC，不支持监控。因此总体而言，Envoy更契合云原生对网络代理的诉求。&lt;/p&gt;

&lt;p&gt;本文简要梳理了Envoy的基本用法，以及其在eShopOnContainers中的运用。Envoy作为一个比肩Nginx的服务代理，其特性在Service Mesh中有着灵活的运用。本文就讲到这里了，下次有机会在和大家分享下Envoy在Service Mesh中的应用。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;参考资料：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;&lt;a href=&quot;https://fuckcloudnative.io/envoy-handbook/docs/overview/overview/&quot;&gt;Envoy 介绍 - Envoy 中文指南&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=UsoH5cqE1OA&quot;&gt;Build an API Gateway with Envoy and use with .NET Core APIs&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/blockquote&gt;
</description>
<pubDate>Sun, 18 Oct 2020 23:32:00 +0000</pubDate>
<dc:creator>「圣杰」</dc:creator>
<og:description>1. 引言 在最新的eShopOnContainers 3.0 中Ocelot 网关被Envoy Proxy 替换。下面就来简要带大家了解下Envoy，并尝试梳理下为什么要使用Envoy替代Ocelo</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/sheng-jie/p/use-envoy-proxy-as-apigateways-in-eshoponcontainers.html</dc:identifier>
</item>
<item>
<title>Flink on Yarn三部曲之一：准备工作 - 程序员欣宸</title>
<link>http://www.cnblogs.com/bolingcavalry/p/13838153.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/bolingcavalry/p/13838153.html</guid>
<description>&lt;h3 id=&quot;欢迎访问我的github&quot;&gt;欢迎访问我的GitHub&lt;/h3&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/zq2599/blog_demos&quot;&gt;https://github.com/zq2599/blog_demos&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;内容：所有原创文章分类汇总及配套源码，涉及Java、Docker、Kubernetes、DevOPS等；&lt;/p&gt;
&lt;h3 id=&quot;关于flink-on-yarn三部曲&quot;&gt;关于Flink on Yarn三部曲&lt;/h3&gt;
&lt;p&gt;本文是《Flink on Yarn三部曲》的第一篇，整个系列由以下三篇组成：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;准备工作：搭建Flink on Yarn环境前，将所有硬件、软件资源准备好；&lt;/li&gt;
&lt;li&gt;部署和设置：部署CDH和Flink，然后做相关设置&lt;/li&gt;
&lt;li&gt;Flink实战：在Yarn环境提交Flink任务&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;整个三部曲的实战内容如下图所示：&lt;br/&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/485422/202010/485422-20201019072643284-1359582137.png&quot; alt=&quot;在这里插入图片描述&quot; loading=&quot;lazy&quot;/&gt;&lt;br/&gt;接下来就从最基本的准备工作开始吧。&lt;/p&gt;
&lt;h3 id=&quot;全文链接&quot;&gt;全文链接&lt;/h3&gt;
&lt;ol&gt;&lt;li&gt;&lt;a href=&quot;https://xinchen.blog.csdn.net/article/details/105356306&quot;&gt;《Flink on Yarn三部曲之一：准备工作》&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://xinchen.blog.csdn.net/article/details/105356347&quot;&gt;《&lt;br/&gt;Flink on Yarn三部曲之二：部署和设置&lt;br/&gt;》&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://xinchen.blog.csdn.net/article/details/105356399&quot;&gt;《Flink on Yarn三部曲之三：提交Flink任务》&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;h3 id=&quot;关于flink-on-yarn&quot;&gt;关于Flink on Yarn&lt;/h3&gt;
&lt;p&gt;除了常见的standalone模式，Flink还支持将任务提交到Yarn环境执行，任务所需的计算资源由Yarn Remource Manager来分配，如下图(来自Flink官网)：&lt;br/&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/485422/202010/485422-20201019072643802-1064562101.png&quot; alt=&quot;在这里插入图片描述&quot; loading=&quot;lazy&quot;/&gt;&lt;br/&gt;因此需要搭建一套Yarn环境，通过CDH部署Yarn、HDFS等服务是常见方式，接下来就采用此方式来部署；&lt;/p&gt;
&lt;h3 id=&quot;部署方式&quot;&gt;部署方式&lt;/h3&gt;
&lt;p&gt;ansible是常用的运维工具，可以大幅度简化整个部署过程，接下来会使用ansible来完成部署工作，如果您对ansible还不够了解，请参考&lt;a href=&quot;https://xinchen.blog.csdn.net/article/details/105342744&quot;&gt;《ansible2.4安装和体验》&lt;/a&gt;,部署操作如下图所示，在一台安装了ansible的电脑上运行脚本，由ansible远程连接到一台CentOS7.7的服务器上，完成部署工作：&lt;br/&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/485422/202010/485422-20201019072644102-1518170600.png&quot; alt=&quot;在这里插入图片描述&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h3 id=&quot;硬件准备&quot;&gt;硬件准备&lt;/h3&gt;
&lt;ol&gt;&lt;li&gt;一台可以运行ansible的电脑，我这里用的是MacBook Pro，也用CentOS验证过，都可以顺利完成部署；&lt;/li&gt;
&lt;li&gt;一台CentOS7.7的电脑用于运行Yarn和Flink(文中的&lt;span&gt;CDH服务器&lt;/span&gt;就是指该电脑)，为了操作简单，本次实战将CDH、Yarn、HDFS、Flink都部署在这一台机器上，实测发现，&lt;span&gt;此电脑CPU至少要双核，内存不低于16G&lt;/span&gt;，如果您想用多台电脑部署CDH，建议自行修改ansible脚本来分别部署，脚本地址后面会给出；&lt;/li&gt;
&lt;/ol&gt;&lt;h3 id=&quot;软件版本&quot;&gt;软件版本&lt;/h3&gt;
&lt;ol&gt;&lt;li&gt;ansible电脑操作系统：macOS Catalina 10.15(实测用CentOS也能成功)&lt;/li&gt;
&lt;li&gt;CDH服务器操作系统：CentOS Linux release 7.7.1908&lt;/li&gt;
&lt;li&gt;cm版本：6.3.1&lt;/li&gt;
&lt;li&gt;parcel版本：5.16.2&lt;/li&gt;
&lt;li&gt;flink版本：1.7.2&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;&lt;span&gt;注意&lt;/span&gt;：因为flink需要hadoop2.6版本，所以parcel选择了5.16.2，这里面对应的hadoop是2.6版&lt;/p&gt;
&lt;h3 id=&quot;cdh服务器设置&quot;&gt;CDH服务器设置&lt;/h3&gt;
&lt;p&gt;需要登录CDH服务器执行以下设置：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;检查&lt;span&gt;/etc/hostname&lt;/span&gt;文件是否正确，如下图：&lt;br/&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/485422/202010/485422-20201019072644388-382160875.png&quot; alt=&quot;在这里插入图片描述&quot; loading=&quot;lazy&quot;/&gt;&lt;/li&gt;
&lt;li&gt;修改&lt;span&gt;/etc/hosts&lt;/span&gt;文件，将自己的IP地址和hostname配置上去，如下图红框所示（&lt;span&gt;事实证明这一步很重要&lt;/span&gt;，如果不做可能导致在部署时一直卡在&quot;分配&quot;阶段，看agent日志显示agent下载parcel的进度一直是百分之零）：&lt;br/&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/485422/202010/485422-20201019072644751-244318507.png&quot; alt=&quot;在这里插入图片描述&quot; loading=&quot;lazy&quot;/&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;h3 id=&quot;下载文件ansible电脑&quot;&gt;下载文件(ansible电脑)&lt;/h3&gt;
&lt;p&gt;本次实战要准备13个文件，如下表所示(后面会给出每个文件的获取方式)：&lt;/p&gt;
&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;编号&lt;/th&gt;
&lt;th&gt;文件名&lt;/th&gt;
&lt;th&gt;简介&lt;/th&gt;
&lt;/tr&gt;&lt;/thead&gt;&lt;tbody readability=&quot;15&quot;&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;jdk-8u191-linux-x64.tar.gz&lt;/td&gt;
&lt;td&gt;Linux版的jdk安装包&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;mysql-connector-java-5.1.34.jar&lt;/td&gt;
&lt;td&gt;mysql的JDBC驱动&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;3&lt;/td&gt;
&lt;td&gt;cloudera-manager-server-6.3.1-1466458.el7.x86_64.rpm&lt;/td&gt;
&lt;td&gt;cm的server安装包&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;cloudera-manager-daemons-6.3.1-1466458.el7.x86_64.rpm&lt;/td&gt;
&lt;td&gt;cm的daemon安装包&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;5&lt;/td&gt;
&lt;td&gt;cloudera-manager-agent-6.3.1-1466458.el7.x86_64.rpm&lt;/td&gt;
&lt;td&gt;cm的agent安装包&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;6&lt;/td&gt;
&lt;td&gt;CDH-5.16.2-1.cdh5.16.2.p0.8-el7.parcel&lt;/td&gt;
&lt;td&gt;CDH应用离线安装包&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;4&quot;&gt;&lt;td&gt;7&lt;/td&gt;
&lt;td&gt;CDH-5.16.2-1.cdh5.16.2.p0.8-el7.parcel.sha&lt;/td&gt;
&lt;td&gt;CDH应用离线安装包sha验证码&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;8&lt;/td&gt;
&lt;td&gt;flink-1.7.2-bin-hadoop26-scala_2.11.tgz&lt;/td&gt;
&lt;td&gt;flink安装包&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;9&lt;/td&gt;
&lt;td&gt;hosts&lt;/td&gt;
&lt;td&gt;ansible用到的远程主机配置，里面记录了CDH6服务器的信息&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;10&lt;/td&gt;
&lt;td&gt;ansible.cfg&lt;/td&gt;
&lt;td&gt;ansible用到的配置信息&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;4&quot;&gt;&lt;td&gt;11&lt;/td&gt;
&lt;td&gt;cm6-cdh5-flink1.7-single-install.yml&lt;/td&gt;
&lt;td&gt;部署CDH时用到的ansible脚本&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;12&lt;/td&gt;
&lt;td&gt;cdh-single-start.yml&lt;/td&gt;
&lt;td&gt;初次启动CDH时用到的ansible脚本&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;13&lt;/td&gt;
&lt;td&gt;var.yml&lt;/td&gt;
&lt;td&gt;脚本中用到的变量都在在此设值，&lt;br/&gt;例如CDH包名、flink文件名等，便于维护&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;下面是每个文件的下载地址：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;jdk-8u191-linux-x64.tar.gz：Oracle官网可下，另外我将jdk-8u191-linux-x64.tar.gz和mysql-connector-java-5.1.34.jar一起打包上传到csdn，您可以一次性下载，地址：&lt;a href=&quot;https://download.csdn.net/download/boling_cavalry/12098987&quot;&gt;https://download.csdn.net/download/boling_cavalry/12098987&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;mysql-connector-java-5.1.34.jar：maven中央仓库可下，另外我将jdk-8u191-linux-x64.tar.gz和mysql-connector-java-5.1.34.jar一起打包上传到csdn，您可以一次性下载，地址：&lt;a href=&quot;https://download.csdn.net/download/boling_cavalry/12098987&quot;&gt;https://download.csdn.net/download/boling_cavalry/12098987&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;cloudera-manager-server-6.3.1-1466458.el7.x86_64.rpm：&lt;a href=&quot;https://archive.cloudera.com/cm6/6.3.1/redhat7/yum/RPMS/x86_64/cloudera-manager-server-6.3.1-1466458.el7.x86_64.rpm&quot;&gt;https://archive.cloudera.com/cm6/6.3.1/redhat7/yum/RPMS/x86_64/cloudera-manager-server-6.3.1-1466458.el7.x86_64.rpm&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;cloudera-manager-daemons-6.3.1-1466458.el7.x86_64.rpm：&lt;a href=&quot;https://archive.cloudera.com/cm6/6.3.1/redhat7/yum/RPMS/x86_64/cloudera-manager-daemons-6.3.1-1466458.el7.x86_64.rpm&quot;&gt;https://archive.cloudera.com/cm6/6.3.1/redhat7/yum/RPMS/x86_64/cloudera-manager-daemons-6.3.1-1466458.el7.x86_64.rpm&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;cloudera-manager-agent-6.3.1-1466458.el7.x86_64.rpm：&lt;a href=&quot;https://archive.cloudera.com/cm6/6.3.1/redhat7/yum/RPMS/x86_64/cloudera-manager-agent-6.3.1-1466458.el7.x86_64.rpm&quot;&gt;https://archive.cloudera.com/cm6/6.3.1/redhat7/yum/RPMS/x86_64/cloudera-manager-agent-6.3.1-1466458.el7.x86_64.rpm&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;CDH-5.16.2-1.cdh5.16.2.p0.8-el7.parcel：&lt;a href=&quot;https://archive.cloudera.com/cdh5/parcels/5.16.2/CDH-5.16.2-1.cdh5.16.2.p0.8-el7.parcel&quot;&gt;https://archive.cloudera.com/cdh5/parcels/5.16.2/CDH-5.16.2-1.cdh5.16.2.p0.8-el7.parcel&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;CDH-5.16.2-1.cdh5.16.2.p0.8-el7.parcel.sha：&lt;a href=&quot;https://archive.cloudera.com/cdh5/parcels/5.16.2/CDH-5.16.2-1.cdh5.16.2.p0.8-el7.parcel.sha1&quot;&gt;https://archive.cloudera.com/cdh5/parcels/5.16.2/CDH-5.16.2-1.cdh5.16.2.p0.8-el7.parcel.sha1&lt;/a&gt; （下载完毕后，将扩展名从.sha1为.sha）&lt;/li&gt;
&lt;li&gt;flink-1.7.2-bin-hadoop26-scala_2.11.tgz：&lt;a href=&quot;http://ftp.jaist.ac.jp/pub/apache/flink/flink-1.7.2/flink-1.7.2-bin-hadoop26-scala_2.11.tgz&quot;&gt;http://ftp.jaist.ac.jp/pub/apache/flink/flink-1.7.2/flink-1.7.2-bin-hadoop26-scala_2.11.tgz&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;hosts、ansible.cfg、cm6-cdh5-flink1.7-single-install.yml、cdh-single-start.yml、var.yml ：这五个文件都保存在我的GitHub仓库，地址是：&lt;a href=&quot;https://github.com/zq2599/blog_demos&quot;&gt;https://github.com/zq2599/blog_demos&lt;/a&gt; ，这里面有多个文件夹，上述文件在名为&lt;span&gt;ansible-cm6-cdh5-flink172-single&lt;/span&gt;的文件夹中，如下图红框所示：&lt;br/&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/485422/202010/485422-20201019072645270-1860031537.png&quot; alt=&quot;在这里插入图片描述&quot; loading=&quot;lazy&quot;/&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;h3 id=&quot;文件摆放ansible电脑&quot;&gt;文件摆放(ansible电脑)&lt;/h3&gt;
&lt;p&gt;如果您已经下载好了上述13个文件，请按照如下位置摆放，这样才能顺利完成部署：&lt;/p&gt;
&lt;ol readability=&quot;4.5&quot;&gt;&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;在家目录下新建名为&lt;span&gt;playbooks&lt;/span&gt;的文件夹：&lt;span&gt;mkdir ~/playbooks&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;把这五个文件放入&lt;span&gt;playbooks&lt;/span&gt;文件夹：hosts、ansible.cfg、cm6-cdh5-flink1.7-single-install.yml、cdh-single-start.yml、vars.yml&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;在&lt;span&gt;playbooks&lt;/span&gt;文件夹里新建名为&lt;span&gt;cdh6&lt;/span&gt;的子文件夹；&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;2&quot;&gt;
&lt;p&gt;把这八个文件放入&lt;span&gt;cdh6&lt;/span&gt;文件夹(即剩余的八个)：jdk-8u191-linux-x64.tar.gz、mysql-connector-java-5.1.34.jar、cloudera-manager-server-6.3.1-1466458.el7.x86_64.rpm、cloudera-manager-daemons-6.3.1-1466458.el7.x86_64.rpm、cloudera-manager-agent-6.3.1-1466458.el7.x86_64.rpm、CDH-5.16.2-1.cdh5.16.2.p0.8-el7.parcel、CDH-5.16.2-1.cdh5.16.2.p0.8-el7.parcel.sha、flink-1.7.2-bin-hadoop26-scala_2.11.tgz&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;摆放完毕后目录和文件情况如下图，再次提醒：&lt;span&gt;文件夹playbooks一定要放在家目录下&lt;/span&gt;（即：&lt;span&gt;~/&lt;/span&gt;）：&lt;br/&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/485422/202010/485422-20201019072645965-232801519.png&quot; alt=&quot;在这里插入图片描述&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;&lt;h3 id=&quot;ansible参数设置ansible电脑&quot;&gt;ansible参数设置(ansible电脑)&lt;/h3&gt;
&lt;p&gt;ansible参数设置的操作设置很简单：配置好CDH服务器的访问参数即可，包括IP地址、登录账号、密码等，修改&lt;span&gt;~/playbooks/hosts&lt;/span&gt;文件，内容如下所示，您需要根据自身情况修改deskmini、ansible_host、ansible_port、ansible_user、ansible_password：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-shell&quot;&gt;[cdh_group]deskmini ansible_host=192.168.50.134 ansible_port=22 ansible_user=root ansible_password=888888
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;至此，所有准备工作已完成，下一篇文章我们将完成这些操作：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;部署CDH和Flink&lt;/li&gt;
&lt;li&gt;启动CDH&lt;/li&gt;
&lt;li&gt;设置CDH、在线安装Yarn、HDFS等&lt;/li&gt;
&lt;li&gt;调整Yarn参数，使Flink任务可以提交成功&lt;/li&gt;
&lt;/ol&gt;&lt;h3 id=&quot;欢迎关注公众号：程序员欣宸&quot;&gt;欢迎关注公众号：程序员欣宸&lt;/h3&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;微信搜索「程序员欣宸」，我是欣宸，期待与您一同畅游Java世界...&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/zq2599/blog_demos&quot;&gt;https://github.com/zq2599/blog_demos&lt;/a&gt;&lt;/p&gt;
</description>
<pubDate>Sun, 18 Oct 2020 23:27:00 +0000</pubDate>
<dc:creator>程序员欣宸</dc:creator>
<og:description>欢迎访问我的GitHub https://github.com/zq2599/blog_demos 内容：所有原创文章分类汇总及配套源码，涉及Java、Docker、Kubernetes、DevOPS</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/bolingcavalry/p/13838153.html</dc:identifier>
</item>
<item>
<title>Java9系列第6篇-Stream流API的增强 - 字母哥博客</title>
<link>http://www.cnblogs.com/zimug/p/13838150.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/zimug/p/13838150.html</guid>
<description>&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/1815316/202010/1815316-20201019063436562-2038165749.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;br/&gt;我计划在后续的一段时间内，写一系列关于java 9的文章，虽然java 9 不像Java 8或者Java 11那样的核心java版本，但是还是有很多的特性值得关注。期待您能关注我，我将把java 9 写成一系列的文章，大概十篇左右，本文是第6篇。&lt;/p&gt;
&lt;p&gt;本文带大家快速的了解一下在Java 9 种集合类Colleaction子类都发生了哪些比较有用的变化与增强。&lt;/p&gt;
&lt;p&gt;在Java 9中对Java Util Stream的语法进行了优化和增强，下面我就和大家一起看一下有哪些比较有价值的使用方法。&lt;/p&gt;
&lt;h2 id=&quot;1-streamtakewhilepredicate&quot;&gt;1. &lt;code&gt;Stream.takeWhile(Predicate)&lt;/code&gt;&lt;/h2&gt;
&lt;p&gt;在进行Stream流的管道数据处理的时候，提供的Predicate条件返回false之后，将跳过剩余的数据元素直接返回。在下面的示例中，一旦Predicate条件&lt;code&gt;!&quot;orange&quot; .equals(s)&lt;/code&gt;返回false，则将跳过其他元素：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt; String[] fruits = {&quot;apple&quot;, &quot;banana&quot;, &quot;orange&quot;, &quot;mango&quot;, &quot;peach&quot;};
 Stream&amp;lt;String&amp;gt; stream = Arrays.stream(fruits)
                               .takeWhile(s -&amp;gt; !&quot;orange&quot;.equals(s));
 stream.forEach(System.out::println);
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;控制台输出结果为，依次对数组中元素过滤，到orange元素满足了&lt;code&gt;!&quot;orange&quot; .equals(s)&lt;/code&gt; === false，流式处理不再继续直接返回。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt; apple
 banana
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;需要注意的是：对于无序Stream，如果存在多个与提供的Predicate匹配的元素(多个orange)，则此操作返回值是不确定的。&lt;/p&gt;
&lt;p&gt;这种方法看上去和Java 8中的Stream.filter()很相似，但是它们的不同之处在于filter()方法只是跳过了不匹配的元素，然后继续进行处理。然而takeWhile()方法在存在匹配项之后会跳过所有剩余的元素，有点像continue和break的区别。以下是具有相同流和Predicate的filter()方法示例：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt; String[] fruits = {&quot;apple&quot;, &quot;banana&quot;, &quot;orange&quot;, &quot;mango&quot;, &quot;peach&quot;};
 Stream&amp;lt;String&amp;gt; stream = Arrays.stream(fruits).filter(s -&amp;gt; !&quot;orange&quot;.equals(s));
 stream.forEach(System.out::println);
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;控制台输出如下，只是把orange过滤掉了。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt; apple
 banana
 mango
 peach
&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;2streamdropwhilepredicate&quot;&gt;2.&lt;code&gt;Stream.dropWhile(Predicate)&lt;/code&gt;&lt;/h2&gt;
&lt;p&gt;提供的Predicate条件在管道流中返回false之后，此元素后面的所有数据元素作为返回值返回。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;String[] fruits = {&quot;apple&quot;, &quot;banana&quot;, &quot;orange&quot;, &quot;mango&quot;, &quot;peach&quot;};
 Stream&amp;lt;String&amp;gt; stream = Arrays.stream(fruits)
                            .dropWhile(s -&amp;gt; !&quot;orange&quot;.equals(s));
 stream.forEach(System.out::println);
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;在上面示例中，一旦Predicate条件&lt;code&gt;!&quot;orange&quot;.equals(s)&lt;/code&gt; 返回false，管道流中剩余的元素将被接受(不被过滤)，作为返回值返回：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt; orange
 mango
 peach
&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;3stream--streamiteratet，predicate，unaryoperator&quot;&gt;3.&lt;code&gt;Stream Stream.iterate(T，Predicate，UnaryOperator)&lt;/code&gt;&lt;/h2&gt;
&lt;p&gt;一旦Predicate条件返回false，此方法将返回一个顺序流，该顺序流将停止迭代操作。T为初始值，迭代操作由UnaryOperator来提供&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt; Stream&amp;lt;String&amp;gt; iterate = Stream.iterate(&quot;-&quot;, 
                                  s -&amp;gt; s.length() &amp;lt; 5,    //Predicate条件
                                  s -&amp;gt; s + &quot;-&quot;);   //迭代操作
 iterate.forEach(System.out::println);
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;控制台打印输出的结果，只输出四个横杠，到第五个的时候停止。这是由Predicate条件决定的。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt; -
 --
 ---
 ----
&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;4stream--streamofnullablet&quot;&gt;4.&lt;code&gt;Stream Stream.ofNullable(T)&lt;/code&gt;&lt;/h2&gt;
&lt;p&gt;此方法返回一个包含单个元素的顺序Stream。如果提供的元素为null，则此方法返回空Stream。当我们要将非空单个元素附加到流时，此方法很有用。例如：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt; String nullableItem = &quot;peach&quot;;
 Stream&amp;lt;String&amp;gt; stream = Stream.of(&quot;apple&quot;, &quot;banana&quot;, &quot;orange&quot;);
 Stream&amp;lt;String&amp;gt; stream2 = Stream.concat(stream, Stream.ofNullable(nullableItem));
 stream2.forEach(System.out::println);
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;控制台打印输出结果如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt; apple
 banana
 orange
 peach
&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;5intstream，longstream和doublestream方法&quot;&gt;5.&lt;code&gt;IntStream，LongStream和DoubleStream方法&lt;/code&gt;&lt;/h2&gt;
&lt;p&gt;下面的这些XxxStream类也具有与Stream类等效的方法（ofNullable()方法除外）。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt; IntStream.of(2, 4, 6, 8, 9, 10, 11)
          .takeWhile(i -&amp;gt; i % 2 == 0)
          .forEach(System.out::println);   //2，4，6，8
&lt;/code&gt;
&lt;/pre&gt;
&lt;pre&gt;
&lt;code&gt; IntStream.of(2, 4, 6, 8, 9, 10, 11)
          .dropWhile(i -&amp;gt; i % 2 == 0)
          .forEach(System.out::println);  // 9,10,11
&lt;/code&gt;
&lt;/pre&gt;
&lt;pre&gt;
&lt;code&gt; IntStream.iterate(0, i -&amp;gt; i &amp;lt; 10, i -&amp;gt; i + 1)
          .forEach(System.out::print); // 0123456789
&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;欢迎关注我的博客，里面有很多精品合集&quot;&gt;欢迎关注我的博客，里面有很多精品合集&lt;/h2&gt;
&lt;ul&gt;&lt;li&gt;本文转载注明出处（必须带连接，不能只转文字）：&lt;a href=&quot;http://www.zimug.com&quot;&gt;字母哥博客&lt;/a&gt;。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;觉得对您有帮助的话，帮我点赞、分享！您的支持是我不竭的创作动力！&lt;/strong&gt; 。另外，笔者最近一段时间输出了如下的精品内容，期待您的关注。&lt;/p&gt;
</description>
<pubDate>Sun, 18 Oct 2020 22:35:00 +0000</pubDate>
<dc:creator>字母哥博客</dc:creator>
<og:description>我计划在后续的一段时间内，写一系列关于java 9的文章，虽然java 9 不像Java 8或者Java 11那样的核心java版本，但是还是有很多的特性值得关注。期待您能关注我，我将把java 9</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/zimug/p/13838150.html</dc:identifier>
</item>
<item>
<title>nginx 是如何处理过期事件的？ - 吴丹阳-cn</title>
<link>http://www.cnblogs.com/wudanyang/p/13837667.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/wudanyang/p/13837667.html</guid>
<description>&lt;p&gt;对于不需要加入到 &lt;code&gt;post&lt;/code&gt; 队列 延后处理的事件，&lt;code&gt;nginx&lt;/code&gt; 的事件都是通过 &lt;code&gt;ngx_epoll_process_events&lt;/code&gt; 函数进行处理的&lt;/p&gt;
&lt;p&gt;举例：假如 &lt;code&gt;epoll_wait&lt;/code&gt; 一次性返回 3 个事件，在第一个事件关闭了一个连接对应的正好是第三个事件的连接，第二个事件 &lt;code&gt;accept&lt;/code&gt; 了一个连接，正好使用的是第二个事件的文件描述符&lt;/p&gt;
&lt;p&gt;如图所示:&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/713751/202010/713751-20201018230647305-132580226.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;那么如果仅仅判断是否使用的同一个描述符或者描述符是否被置为 -1，就不能判断是否是同一个连接&lt;/p&gt;
&lt;p&gt;上面的这个问题，称之为&lt;code&gt;事件过期问题&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;nginx&lt;/code&gt; 中的指针的最后一位一定是 0 ，于是，&lt;code&gt;nginx&lt;/code&gt; 就使用这最后一位用来表示是否过期&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.zhihu.com/question/40636241?sort=created&quot;&gt;深入理解nginx中，第9章中有一句：利用指针的最后一位一定是0的特性。能解释一下这个特性？&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;看下面代码中取出与判断 &lt;code&gt;instance&lt;/code&gt; 位的操作&lt;/p&gt;
&lt;p&gt;&lt;code&gt;nginx&lt;/code&gt; 会在每次 &lt;code&gt;accept&lt;/code&gt; 一个连接的时候，将 &lt;code&gt;instance&lt;/code&gt; 位取反，那么只需要判断 &lt;code&gt;instance&lt;/code&gt; 位是否一直就能判断事件是否过期了&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-c&quot;&gt;// nginx-1.9.2/src/core/ngx_connection.c
// ngx_get_connection
    instance = rev-&amp;gt;instance;

    ngx_memzero(rev, sizeof(ngx_event_t));
    ngx_memzero(wev, sizeof(ngx_event_t));

    rev-&amp;gt;instance = !instance;
    wev-&amp;gt;instance = !instance
&lt;/code&gt;
&lt;/pre&gt;
&lt;pre&gt;
&lt;code class=&quot;language-c&quot;&gt;// nginx-1.9.2/src/event/modules/ngx_epoll_module.c
// ngx_epoll_process_events
    //遍历本次epoll_wait返回的所有事件
    for (i = 0; i &amp;lt; events; i++) { //和ngx_epoll_add_event配合使用
        /*
        对照着上面提到的ngx_epoll_add_event方法，可以看到ptr成员就是ngx_connection_t连接的地址，但最后1位有特殊含义，需要把它屏蔽掉
          */
        c = event_list[i].data.ptr; //通过这个确定是那个连接

        instance = (uintptr_t) c &amp;amp; 1; //将地址的最后一位取出来，用instance变量标识, 见ngx_epoll_add_event

        /*
          无论是32位还是64位机器，其地址的最后1位肯定是0，可以用下面这行语句把ngx_connection_t的地址还原到真正的地址值
          */ //注意这里的c有可能是accept前的c，用于检测是否客户端发起tcp连接事件,accept返回成功后会重新创建一个ngx_connection_t，用来读写客户端的数据
        c = (ngx_connection_t *) ((uintptr_t) c &amp;amp; (uintptr_t) ~1);

        rev = c-&amp;gt;read; //取出读事件 //注意这里的c有可能是accept前的c，用于检测是否客户端发起tcp连接事件,accept返回成功后会重新创建一个ngx_connection_t，用来读写客户端的数据

        if (c-&amp;gt;fd == -1 || rev-&amp;gt;instance != instance) { //判断这个读事件是否为过期事件
          //当fd套接字描述符为-l或者instance标志位不相等时，表示这个事件已经过期了，不用处理
            /*
             * the stale event from a file descriptor
             * that was just closed in this iteration
             */

            ngx_log_debug1(NGX_LOG_DEBUG_EVENT, cycle-&amp;gt;log, 0,
                           &quot;epoll: stale event %p&quot;, c);
            continue;
        }

        // 还有代码，但是不贴这么多了
        ......
    }
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;那么你可能也跟我有一样的疑问，如果是下面两种情形怎么办？&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/713751/202010/713751-20201018233253184-1884781299.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;br/&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/713751/202010/713751-20201018233253689-59582324.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;这样 &lt;code&gt;instance&lt;/code&gt; 位又成了 1，那 &lt;code&gt;e&lt;/code&gt; 事件处理的岂不是 3 连接的事件了，这样过期事件并没有解决啊&lt;/p&gt;
&lt;p&gt;首先，第二张图片中的情况不可能存在，因为 &lt;code&gt;epoll&lt;/code&gt; 中的事件是有顺序的，&lt;code&gt;c&lt;/code&gt; 事件必然是再 &lt;code&gt;e&lt;/code&gt; 事件之后&lt;/p&gt;
&lt;p&gt;那么第一张图片中的情况还是没有解决过期事件啊&lt;/p&gt;
&lt;p&gt;于是我就翻阅很多资料（主要靠百度）&lt;/p&gt;
&lt;p&gt;看到有人遇到过这个疑问：&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.itdaan.com/blog/2012/05/03/b6c3a68fcfd4f37b5e9416ee7f0a244d.html&quot;&gt;nginx中事件模型中instance变量的处理细节&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;如果觉得上面文章太长可以看我的讲解：&lt;/p&gt;
&lt;p&gt;意思呢就是&lt;/p&gt;
&lt;p&gt;&lt;code&gt;nginx&lt;/code&gt; &lt;code&gt;accept&lt;/code&gt; 连接之后，会立刻将连接放到 &lt;code&gt;post&lt;/code&gt; 延迟处理队列中，不会出现 &lt;code&gt;accept&lt;/code&gt; 之后立刻 &lt;code&gt;close&lt;/code&gt; 的情况&lt;/p&gt;
&lt;p&gt;于是呢，&lt;code&gt;nginx&lt;/code&gt; 就完美的解决了事件过期的情况&lt;/p&gt;

&lt;p&gt;《深入理解 Nginx》&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.zhihu.com/question/40636241?sort=created&quot;&gt;深入理解nginx中，第9章中有一句：利用指针的最后一位一定是0的特性。能解释一下这个特性？&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.itdaan.com/blog/2012/05/03/b6c3a68fcfd4f37b5e9416ee7f0a244d.html&quot;&gt;nginx中事件模型中instance变量的处理细节&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/y123456yz/reading-code-of-nginx-1.9.2&quot;&gt;github 项目：reading-code-of-nginx-1.9.2&lt;/a&gt;&lt;/p&gt;
</description>
<pubDate>Sun, 18 Oct 2020 15:40:00 +0000</pubDate>
<dc:creator>吴丹阳-cn</dc:creator>
<og:description>[toc]# 什么是过期事件对于不需要加入到 `post` 队列 延后处理的事件，`nginx` 的事件都是通过 `ngx_epoll_process_events` 函数进行处理的举例：假如 `ep</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/wudanyang/p/13837667.html</dc:identifier>
</item>
<item>
<title>nginx 内存池分析 - 小胖西瓜</title>
<link>http://www.cnblogs.com/shuqin/p/13837898.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/shuqin/p/13837898.html</guid>
<description>&lt;p&gt;nginx 是自己实现了内存池的，所以在nginx ngx_pool_t 这个结构也随处可见，这里主要分析一下内存池的分配逻辑。&lt;/p&gt;
&lt;p&gt;内存池实现了包括小块内存、大块内存和清理资源几种资源的处理，应该来说覆盖了绝大数的使用场景了。&lt;/p&gt;
&lt;h2 id=&quot;相关结构定义&quot;&gt;相关结构定义&lt;/h2&gt;
&lt;pre&gt;
&lt;code class=&quot;language-c&quot;&gt;// 大块内存
typedef struct ngx_pool_large_s  ngx_pool_large_t;
struct ngx_pool_large_s {
    ngx_pool_large_t     *next;         // 下一个大块内存池
    void                 *alloc;        // 实际分配内存
};

// 小块内存池
typedef struct {
    u_char               *last;         // 可分配内存起始地址
    u_char               *end;          // 可分配内存结束地址
    ngx_pool_t           *next;         // 指向内存管理结构
    ngx_uint_t            failed;       // 内存分配失败次数
} ngx_pool_data_t;

// 内存池管理结构
typedef struct ngx_pool_s            ngx_pool_t;
struct ngx_pool_s {
    ngx_pool_data_t       d;            // 小块内存池
    size_t                max;          // 小块内存最大的分配内存，评估大内存还是小块内存
    ngx_pool_t           *current;      // 当前开始分配的小块内存池
    ngx_chain_t          *chain;        // chain
    ngx_pool_large_t     *large;        // 大块内存
    ngx_pool_cleanup_t   *cleanup;      // 待清理资源
    ngx_log_t            *log;          // 日志对象
};
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;ngx_pool_t 是整个内存池的管理结构，这种结构对于个内存池对象来说可能存在多个，但是对于用户而言，第一下访问的始终是创建时返回的那个。多个 ngx_pool_t 通过 &lt;code&gt;d.next&lt;/code&gt; 来进行连接，&lt;code&gt;current&lt;/code&gt; 指向 当前开始分配的小块内存池，注意 ngx_pool_data_t 在内存池结构的起始处，可以进行类型转换访问到不同的成员。&lt;/p&gt;
&lt;h2 id=&quot;实现&quot;&gt;实现&lt;/h2&gt;
&lt;h3 id=&quot;内存对齐&quot;&gt;内存对齐&lt;/h3&gt;
&lt;pre&gt;
&lt;code class=&quot;language-c&quot;&gt;#define ngx_align(d, a)     (((d) + (a - 1)) &amp;amp; ~(a - 1))
#define ngx_align_ptr(p, a)                                                   \
    (u_char *) (((uintptr_t) (p) + ((uintptr_t) a - 1)) &amp;amp; ~((uintptr_t) a - 1))
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;参考 &lt;a href=&quot;https://www.cnblogs.com/shuqin/p/13832722.html&quot;&gt;ngx_align 值对齐宏&lt;/a&gt; 分析，&lt;code&gt;ngx_align_ptr&lt;/code&gt; 同理&lt;/p&gt;
&lt;h3 id=&quot;创建内存池&quot;&gt;创建内存池&lt;/h3&gt;
&lt;p&gt;max 的最大值为 4095，当从内存池中申请的内存大小大于 max 时，不会从小块内存中进行分配。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-c&quot;&gt;ngx_uint_t  ngx_pagesize = getpagesize();  // Linux 上是 4096
#define NGX_POOL_ALIGNMENT 16
#define NGX_MAX_ALLOC_FROM_POOL  (ngx_pagesize - 1)  // 4095

ngx_pool_t *
ngx_create_pool(size_t size, ngx_log_t *log)
{
    ngx_pool_t  *p;

    p = ngx_memalign(NGX_POOL_ALIGNMENT, size, log);  // 16 字节对齐申请 size 大小的内存
    if (p == NULL) {
        return NULL;
    }

    p-&amp;gt;d.last = (u_char *) p + sizeof(ngx_pool_t);  // 设置可分配内存的起始处
    p-&amp;gt;d.end = (u_char *) p + size;                 // 设置可分配内存的终止处
    p-&amp;gt;d.next = NULL;
    p-&amp;gt;d.failed = 0;                                // 内存分配失败次数

    size = size - sizeof(ngx_pool_t);               // 设置小块内存可分配的最大值（小于 4095）
    p-&amp;gt;max = (size &amp;lt; NGX_MAX_ALLOC_FROM_POOL) ? size : NGX_MAX_ALLOC_FROM_POOL;

    p-&amp;gt;current = p;                                 // 设置起始分配内存池
    p-&amp;gt;chain = NULL;
    p-&amp;gt;large = NULL;
    p-&amp;gt;cleanup = NULL;
    p-&amp;gt;log = log;

    return p;
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;内存池创建后的结构逻辑如图所示：&lt;br/&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1461087/202010/1461087-20201018233124363-407757885.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h3 id=&quot;内存申请&quot;&gt;内存申请&lt;/h3&gt;
&lt;p&gt;申请的内存块以 max 作为区分&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-c&quot;&gt;void *
ngx_palloc(ngx_pool_t *pool, size_t size)
{
#if !(NGX_DEBUG_PALLOC)
    if (size &amp;lt;= pool-&amp;gt;max) {
        return ngx_palloc_small(pool, size, 1);
    }
#endif

    return ngx_palloc_large(pool, size);
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;h4 id=&quot;小块内存申请&quot;&gt;小块内存申请&lt;/h4&gt;
&lt;p&gt;current 指向每次申请内存时开始检索分配的小块内存池，而 ngx_palloc_small 的参数 pool 在内存池没有回收时，是固定不变的。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-c&quot;&gt;static ngx_inline void *
ngx_palloc_small(ngx_pool_t *pool, size_t size, ngx_uint_t align)
{
    u_char      *m;
    ngx_pool_t  *p;

    p = pool-&amp;gt;current;  // 从 current 处开始分配合适的内存

    do {
        m = p-&amp;gt;d.last;

        if (align) {  // 是否需要内存对齐
            m = ngx_align_ptr(m, NGX_ALIGNMENT);
        }

        // 当前小块内存池的剩余容量满足申请的内存
        if ((size_t) (p-&amp;gt;d.end - m) &amp;gt;= size) {
            p-&amp;gt;d.last = m + size;

            return m;  // 一旦满足分配直接退出
        }

        p = p-&amp;gt;d.next;  // 不满足的情况下寻找下一个小块内存池

    } while (p);

    return ngx_palloc_block(pool, size); // 没有满足分配的内存池，再申请一个小块内存池
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;当在小块内存池中找到了合适的内存后的结构如下：&lt;br/&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1461087/202010/1461087-20201018233157028-1243893997.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;当没有小块内存池满足申请时，会再申请一个小块内存池来满足分配，在设置完 last 和 end 两个内存指示器后，对从 current 开始的内存池成员 failed 进行自增操作，并且当这个内存池的 failed 分配次数大于 4 时，表面这个内存分配失败的次数太多，根据经验应该下一次分配可能还是失败，所以直接跳过这个内存池，移动 current。&lt;/p&gt;
&lt;p&gt;新的内存块插入至内存池链表的尾端。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-c&quot;&gt;#define NGX_ALIGNMENT   sizeof(unsigned long)  // 8

static void *
ngx_palloc_block(ngx_pool_t *pool, size_t size)
{
    u_char      *m;
    size_t       psize;
    ngx_pool_t  *p, *new;

    psize = (size_t) (pool-&amp;gt;d.end - (u_char *) pool);  // 每一个内存池的大小都相同

    m = ngx_memalign(NGX_POOL_ALIGNMENT, psize, pool-&amp;gt;log);  // 16 字节对齐申请
    if (m == NULL) {
        return NULL;
    }

    new = (ngx_pool_t *) m;

    new-&amp;gt;d.end = m + psize;
    new-&amp;gt;d.next = NULL;
    new-&amp;gt;d.failed = 0;

    m += sizeof(ngx_pool_data_t);
    m = ngx_align_ptr(m, NGX_ALIGNMENT);
    new-&amp;gt;d.last = m + size;

    for (p = pool-&amp;gt;current; p-&amp;gt;d.next; p = p-&amp;gt;d.next) {
        if (p-&amp;gt;d.failed++ &amp;gt; 4) {
            pool-&amp;gt;current = p-&amp;gt;d.next;
        }
    }

    p-&amp;gt;d.next = new;  // 尾插法插入至链表末端

    return m;
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;分配一块内存池后逻辑结构如下：&lt;br/&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1461087/202010/1461087-20201018233249049-153853293.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h4 id=&quot;大块内存申请&quot;&gt;大块内存申请&lt;/h4&gt;
&lt;p&gt;大块内存是通过 &lt;code&gt;large&lt;/code&gt; 连接的，并且都属于 ngx_create_pool 返回的 ngx_pool_t 结构。malloc 分配的内存由一个 ngx_pool_large_t 节点来挂载，而这个 ngx_pool_large_t 节点又是从小块内存池中分配的。&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;为避免large链表长度过大导致在遍历寻找空闲挂载节点耗时过长，限制了遍历的节点为3，如果没有满足要求则直接分配&lt;/li&gt;
&lt;li&gt;头插法 插入至large链表中，新的节点后面也是最先被访问&lt;/li&gt;
&lt;/ul&gt;&lt;pre&gt;
&lt;code class=&quot;language-c&quot;&gt;static void *
ngx_palloc_large(ngx_pool_t *pool, size_t size)
{
    void              *p;
    ngx_uint_t         n;
    ngx_pool_large_t  *large;

    p = ngx_alloc(size, pool-&amp;gt;log);  // 调用 malloc
    if (p == NULL) {
        return NULL;
    }

    n = 0;

    for (large = pool-&amp;gt;large; large; large = large-&amp;gt;next) {  // 从large 中链表中找到 alloc 为 NULL 的节点，将分配的内存挂在该节点上
        if (large-&amp;gt;alloc == NULL) {
            large-&amp;gt;alloc = p;
            return p;
        }

        if (n++ &amp;gt; 3) {  // 为了避免过多的遍历，限制次数为 0
            break;
        }
    }

    // 当遍历的 ngx_pool_large_t 节点中 alloc 都有指向的内存时，从小块内存中分配一个 ngx_pool_large_t 节点用于挂载新分配的大内存
    large = ngx_palloc_small(pool, sizeof(ngx_pool_large_t), 1);
    if (large == NULL) {
        ngx_free(p);
        return NULL;
    }

    large-&amp;gt;alloc = p;
    large-&amp;gt;next = pool-&amp;gt;large;  // 头插法 插入至大块内存链表中
    pool-&amp;gt;large = large;

    return p;
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;第一次大块内存分配后的结构如下：&lt;br/&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1461087/202010/1461087-20201018233232368-357289374.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h3 id=&quot;完整内存池结构逻辑&quot;&gt;完整内存池结构逻辑&lt;/h3&gt;
&lt;ul&gt;&lt;li&gt;所有的内存池结构都通过 d.next 连接&lt;/li&gt;
&lt;li&gt;前两个内存池结构的 current 都指向第三个内存池结构&lt;/li&gt;
&lt;li&gt;所有的 ngx_pool_large_t 节点都是从小内存池中分配的&lt;/li&gt;
&lt;li&gt;所有的 ngx_pool_large_t 节点都是连接在首个内存池结构上的&lt;/li&gt;
&lt;li&gt;ngx_pool_large_t 节点的 alloc 被释放但 ngx_pool_large_t 节点不回收&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1461087/202010/1461087-20201018233212941-1409715236.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h2 id=&quot;总结&quot;&gt;总结&lt;/h2&gt;
&lt;p&gt;ngx_pool_t 内存分配方面&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;通过 current 和 d.next 来访问其他的内存池结构&lt;/li&gt;
&lt;li&gt;插入方式
&lt;ul&gt;&lt;li&gt;小块内存池通过尾插法插入至内存池链表的尾端&lt;/li&gt;
&lt;li&gt;大块内存通过头插法插入至large链表的首部&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;限制次数
&lt;ul&gt;&lt;li&gt;小内存分配失败（failed）次数大于4次后就不再作为分配内存的池子了&lt;/li&gt;
&lt;li&gt;大内存只寻找 large 链表中前三节点是否可以挂载新分配的内存&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;内存对齐，多处内存对齐减少内存跨 cache 的数量&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;其实总体而言这是一个比较简单的内存池了，还是有一些内存浪费的地方，&lt;code&gt;限制次数&lt;/code&gt; 可以说明这个情况，不过这也是在简单、高效和内存分配上的一个平衡了&lt;/p&gt;
</description>
<pubDate>Sun, 18 Oct 2020 15:37:00 +0000</pubDate>
<dc:creator>小胖西瓜</dc:creator>
<og:description>nginx 内存池 ngx_pool_t nginx 是自己实现了内存池的，所以在nginx ngx_pool_t 这个结构也随处可见，这里主要分析一下内存池的分配逻辑。 内存池实现了包括小块内存、大</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/shuqin/p/13837898.html</dc:identifier>
</item>
<item>
<title>samesite-cookie详解（译文） - snicker</title>
<link>http://www.cnblogs.com/bellhey/p/13837866.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/bellhey/p/13837866.html</guid>
<description>&lt;p&gt;Cookie是便于向网站添加持久化状态的方式之一。随着时间推移，它们的能力得到了扩展和进化，也造成了很多历史遗留问题。为了解决这个问题，浏览器产商（包括Chrome，Firefox,和Edge）改变了他们的处理逻辑以加强个人隐私的默认配置。&lt;/p&gt;
&lt;p&gt;每一个cookie都是拥有一些为了控制何时何处被使用的键值对。你可能已经通过这些属性去设置过期时间或者指明当前cookie只能在https协议下传输。服务器通过在响应中携带&lt;code&gt;Set-Cookie&lt;/code&gt;头来设置cookie。想要了解详细信息，可以深入阅读&lt;a href=&quot;https://tools.ietf.org/html/draft-ietf-httpbis-rfc6265bis-03#section-4.1&quot;&gt;RFC6265bis&lt;/a&gt;,现在只是快速的回顾一下。&lt;/p&gt;
&lt;p&gt;现在假设你的博客网站需要向用户推送一个“最新内容”的提示。用户可能会取消这个提示并且一段时间内他们也不会再看这个提示。你可以将这种喜好设置在一个cookie中，给它设置一个月（2，600，000 seconds）后到期，并且只能在HTTPS协议下传输。这个头部可能看起来像这样：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;Set-Cookie: promo_shown=1; Max-Age=2600000; Secure
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;img src=&quot;https://webdev.imgix.net/samesite-cookies-explained/set-cookie-response-header.png&quot; alt=&quot;server set-cookie&quot; loading=&quot;lazy&quot;/&gt;&lt;br/&gt;服务器通过&lt;code&gt;Set-Cookie&lt;/code&gt;头来设置cookie&lt;/p&gt;
&lt;p&gt;当你的读者正在访问一个做了上面这些设置的页面，具体说来就是他们正在使用HTTPS进行连接并且这个cookie存续时间小于一个月，那么他们的浏览器就会请求里携带如下的头部：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;Cookie: promo_shown=1
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;img src=&quot;https://webdev.imgix.net/samesite-cookies-explained/cookie-request-header.png&quot; alt=&quot;browser send back cookie&quot; loading=&quot;lazy&quot;/&gt;&lt;br/&gt;浏览器通过&lt;code&gt;Cookie&lt;/code&gt;头回传cookie&lt;/p&gt;
&lt;p&gt;在javascript中通过使用&lt;code&gt;document.cookie&lt;/code&gt;可以读取或者添加站点的cookie。对&lt;code&gt;document.cookie&lt;/code&gt;进行赋值操作将会覆盖对应键的cookie。举个例子，尝试在你的浏览器javascript console中输入以下语句：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;&amp;gt; document.cookie = &quot;promo_shown=1; Max-Age=2600000; Secure&quot;
&amp;lt; &quot;promo_shown=1; Max-Age=2600000; Secure&quot;
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;读取&lt;code&gt;document.cookie&lt;/code&gt;将会打印出所有能够在当前环境中获取到的cookie，每个cookie通过一个分号分隔&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;&amp;gt; document.cookie;
&amp;lt; &quot;promo_shown=1; color_theme=peachpuff; sidebar_loc=left&quot;
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;img src=&quot;https://webdev.imgix.net/samesite-cookies-explained/document-cookie.png&quot; alt=&quot;read cookie in javascript&quot; loading=&quot;lazy&quot;/&gt;&lt;br/&gt;JavaScript中可以通过使用&lt;code&gt;document.cookie&lt;/code&gt;获取cookie&lt;/p&gt;
&lt;p&gt;如果你尝试在一些流行的站点上读取cookie，你会明显发现它们中大多数设置了超过3个cookie。在大多数场景下，这些cookie将会根据一系列因素携带在对应域名的请求中。对于你的用户来说，一般上行带宽一般比下行带宽拥有更多的限制，所以将大量cookie携带在对外请求上将会导致获取第一个字节的延迟。为了合理控制设置的cookie数量。通过设置&lt;code&gt;Max-Age&lt;/code&gt;属性来帮助保证cookie在不需要的时候及时被清除掉。&lt;/p&gt;
&lt;h2 id=&quot;什么是自有和第三方cookie？&quot;&gt;什么是自有和第三方cookie？&lt;/h2&gt;
&lt;p&gt;重新访问前面一系列站点，很可能会发现有些cookie会在很多不同域名下出现，不仅仅是当前正在访问站点域名。当前站点域名（显示在浏览器地址栏里面的域名），被称为自有域名。同样的，那些来自当前站点外域名的cookie被称为第三方域名。这只是相对用户的角度并不是一个绝对的标签，同样的cookie既可能是自有的也可能是第三方的，取决于用户当前访问的站点。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://webdev.imgix.net/samesite-cookies-explained/cross-site-set-cookie-response-header.png&quot; alt=&quot;cookies come from different domains&quot; loading=&quot;lazy&quot;/&gt;&lt;br/&gt;一个页面上的cookie可能来自多个不同域名&lt;/p&gt;
&lt;p&gt;继续前面的例子，假设你的一篇博客当中有一张极其可爱的小猫图片，这张图片存储在&lt;code&gt;/blog/img/amazing-cat.png&lt;/code&gt;下。由于这张图片太可爱了，其他人在他们的网站上直接使用了它。如果一个用户访问过你的博客将会有promo_shown cookie,当他在其他网站上看到这张直接被引用的图片时，图片的请求将会携带这个cookie。这并不是对任何人都特别有用，因为promo_shown在其他人的网站上并不是对任何请求都有用，这样只会增加请求的负载。&lt;/p&gt;
&lt;p&gt;如果这并不是有意达成的效果，那在什么情况下你需要这样了。这是一种允许在第三方站点环境上保持会话状态的机制。例如，如果你的站点页面上添加了一个YouTube播放器,那么访问者将会在播放器中看到一个&quot;watch later&quot;的操作项。如果访问者已经登陆了YouTube,第三方cookie将会使得用户通过一步点击&quot;watch later&quot;按钮收藏这个视频到YouTube供后续观看，而不需要提醒他们登陆YouTube或者离开当前站点并跳转到YouTube。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://webdev.imgix.net/samesite-cookies-explained/cross-site-cookie-request-header.png&quot; alt=&quot;third-party cookie used for maintain state&quot; loading=&quot;lazy&quot;/&gt;&lt;br/&gt;在第三方环境下访问不同的页面cookie将被传输&lt;/p&gt;
&lt;p&gt;万维网文化属性之一是开放共识。这使得许多人创造自己的内容和应用程序成为可能。然而这也带来了一些安全和隐私风险。跨站请求伪造攻击（Cross-site request forgery attack-csrf）制造依赖于那些cookie将会被携带在针对指定域名的请求中,而不论这些请求具体由谁触发。举个例子，当你访问了&lt;code&gt;evil.example&lt;/code&gt;并且它可以触发&lt;code&gt;your-blog.example&lt;/code&gt;的请求，那么浏览器将会很乐意携带上关联的cookie。如果你的博客对这些请求的验证不够仔细那么&lt;code&gt;evil.example&lt;/code&gt;可以触发删除和添加内容的任何操作。&lt;/p&gt;
&lt;p&gt;用户现在更加清醒的意识到cookie怎样被用来跟踪他们在不同页面的活动轨迹。然而直到现在仍然没有一种明确的方式表明对cookie本来用意。你的&lt;code&gt;promo_shown&lt;/code&gt;cookie本应该只被用在自有站点环境下，而嵌入到第三方站点的组件所携带的会话cookie是被用来保持会话状态。&lt;/p&gt;
&lt;h2 id=&quot;使用samesite明确表明cookie的用途&quot;&gt;使用SameSite明确表明cookie的用途&lt;/h2&gt;
&lt;p&gt;SameSite属性的引入（定义在&lt;a href=&quot;https://tools.ietf.org/html/draft-ietf-httpbis-rfc6265bis-03#section-4.1&quot;&gt;RFC6265bis&lt;/a&gt;）允许你表明你的cookie被用在第三方或者自己的站点环境下。搞清楚站点的确切意义将会大有裨益。站点是域名后缀和它前面部分的混合。例如，&lt;code&gt;www.web.dev&lt;/code&gt;域名站点是&lt;code&gt;web.dev&lt;/code&gt;域名站点的一部分。&lt;/p&gt;
&lt;h3 id=&quot;关键词same-site&quot;&gt;关键词same-site&lt;/h3&gt;
&lt;p&gt;如果用户在&lt;code&gt;www.web.dev&lt;/code&gt;发起了一个向&lt;code&gt;static.web.dev&lt;/code&gt;的图片请求这是一个&lt;code&gt;same-site&lt;/code&gt;请求。&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://publicsuffix.org/&quot;&gt;public suffix list&lt;/a&gt;定义了这些，不仅是像&lt;code&gt;.com&lt;/code&gt;这样的顶级域名也包括像&lt;code&gt;github.io&lt;/code&gt;这样的域名。这使得&lt;code&gt;your-project.github&lt;/code&gt;和&lt;code&gt;my-project.github&lt;/code&gt;被认为为不同的站点。&lt;/p&gt;
&lt;h3 id=&quot;关键词cross-site&quot;&gt;关键词cross-site&lt;/h3&gt;
&lt;p&gt;如果用户在&lt;code&gt;your-project.github.io&lt;/code&gt;站点发起了一个向&lt;code&gt;my-project.github.io&lt;/code&gt;的请求，这是一个&lt;code&gt;cross-site&lt;/code&gt;请求。&lt;/p&gt;
&lt;p&gt;在cookie中引入&lt;code&gt;SameSite&lt;/code&gt;属性三种控制这种行为的方式。你可以不指定指定这个属性，或者通过使用&lt;code&gt;Strict&lt;/code&gt;或&lt;code&gt;Lax&lt;/code&gt;来限制cookie只在&lt;code&gt;same-site&lt;/code&gt;请求下携带。&lt;/p&gt;
&lt;p&gt;如果你设置&lt;code&gt;SameSite&lt;/code&gt;属性为&lt;code&gt;Strict&lt;/code&gt;,那么你的cookie将会只在自有环境下发送。在用户看来，那个cookie只会在匹配当前显示在地址栏的站点时才会被发送。所以，假设&lt;code&gt;Promo_shown&lt;/code&gt;cookie如下设置：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;Set-Cookie: promo_shown=1; SameSite=Strict
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;那么当你的用户在你的站点上时，cookie将会预期发送。然而当从一个指向你站点的引用链接跳转时，详细地说当从另一个站点或者通过一个朋友发给你的一个链接跳转时，在初始请求里这个cookie并不会被发送。当你拥有一些关联后置于初始导航你站点功能cookie的情形下，例如修改密码或者下订单的情形，这是极其有用的，但是对于&lt;code&gt;promo_shown&lt;/code&gt;这个功能限制就太多了。如果你的用户通过链接进入你的站点，他们希望cookie能被发送，这样他们的设置能够生效。&lt;/p&gt;
&lt;p&gt;当你的用户初始导航到你的网站上时cookie将会被发送，这就是&lt;code&gt;SameSite=Lax&lt;/code&gt;的使用场景。让我们继续回顾那个引用小猫图片的例子，那个例子中其他站点正在引用你的内容。他们直接使用你的小猫图片并且提供了一个指向你的原始文章的链接地址。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;&amp;lt;p&amp;gt;Look at this amazing cat!&amp;lt;/p&amp;gt;
&amp;lt;img src=&quot;https://blog.example/blog/img/amazing-cat.png&quot; /&amp;gt;
&amp;lt;p&amp;gt;Read the &amp;lt;a href=&quot;https://blog.example/blog/cat.html&quot;&amp;gt;article&amp;lt;/a&amp;gt;.&amp;lt;/p&amp;gt;
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;cookie这样设置：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;Set-Cookie: promo_shown=1; SameSite=Lax
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;当浏览者在其他人的博客上请求&lt;code&gt;amzing-cat.png&lt;/code&gt;，cookie将不会被发送。然而当读者通过点击一个指向你站点&lt;code&gt;cat.html&lt;/code&gt;链接时，cookie将会被发送。这样的话，使得&lt;code&gt;Lax&lt;/code&gt;成为设置影响网站外观cookie的好选择而&lt;code&gt;Strict&lt;/code&gt;将会对那些关联到用户当前操作的cookie极其有用。&lt;/p&gt;
&lt;h4 id=&quot;注意&quot;&gt;注意&lt;/h4&gt;
&lt;p&gt;&lt;code&gt;Strict&lt;/code&gt;和&lt;code&gt;Lax&lt;/code&gt;对于你的站点安全都不是一个完整的解决方案。cookie将会作为用户输入的一部分,你需要像对待其他输入一样。意味着，需要对这些输入进行脱敏和验证。绝对不要将服务端的重要数据存储在cookie中。&lt;/p&gt;
&lt;p&gt;最后还有一个不设置这个值的默认行为，这种情形下cookie将会在所有上下文情形下被发送。在最新的&lt;a href=&quot;https://tools.ietf.org/html/draft-ietf-httpbis-rfc6265bis-03#section-4.1&quot;&gt;RFC6265bis&lt;/a&gt;草案中这种方式被&lt;code&gt;SameSite=None&lt;/code&gt;这个新值明确表达。这表明你可以通过设置&lt;code&gt;SameSite=None&lt;/code&gt;来明确表明你希望cookie在所有第三方上下文环境下被发送。&lt;/p&gt;
&lt;p&gt;!(None Lax Strict)[&lt;a href=&quot;https://webdev.imgix.net/samesite-cookies-explained/samesite-none-lax-strict.png&quot;&gt;https://webdev.imgix.net/samesite-cookies-explained/samesite-none-lax-strict.png&lt;/a&gt;]&lt;br/&gt;通过&lt;code&gt;None&lt;/code&gt;，&lt;code&gt;Lax&lt;/code&gt;和&lt;code&gt;Strict&lt;/code&gt;来明确表明cookie的使用上下文&lt;/p&gt;
&lt;p&gt;★ 如果你提供了供其他网站使用的服务，例如嵌入式组件、嵌入式多媒体内容、联合程序、广告、跨站登陆那么你需要使用&lt;code&gt;None&lt;/code&gt;来明确表明的意图。&lt;/p&gt;
&lt;h2 id=&quot;未设置samesite属性默认行为的变化&quot;&gt;未设置SameSite属性默认行为的变化&lt;/h2&gt;
&lt;p&gt;尽管&lt;code&gt;SameSite&lt;/code&gt;属性得到广泛支持，很不幸的是并没有很广泛的被开发者使用。cookie在所有地方都会被发送的开放默认行为使得所有场景都能正常工作，但是这样提高了用户受到CSRF和意外信息泄漏的风险指数。为了号召开发者明确表明他们的意图并且提供用户更高的安全使用体验，IETF发布了一个提议，&lt;a href=&quot;https://tools.ietf.org/html/draft-west-cookie-incrementalism-00&quot;&gt;Incrementally Better Cookies&lt;/a&gt; 提供了两项关键改进：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;那些没有设置&lt;code&gt;SameSite&lt;/code&gt;属性的cookie将等同设置了&lt;code&gt;SameSite=Lax&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;cookie设置&lt;code&gt;SameSite=None&lt;/code&gt;必须同时设置&lt;code&gt;Secure&lt;/code&gt;,这意味着需要在更安全的环境下传输。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;Chrome在84版本实现了以上默认行为。Firefox在69版本可以测试使用，并且未来会加入默认配置中。为了在Firefox中测试这些行为，打开&lt;code&gt;about:config&lt;/code&gt;然后&lt;code&gt;network.cookie.sameSite.laxByDefault&lt;/code&gt;。Edge也计划改变其默认行为。&lt;/p&gt;
&lt;h2 id=&quot;原文&quot;&gt;原文&lt;/h2&gt;
&lt;p&gt;&lt;a href=&quot;https://web.dev/samesite-cookies-explained/&quot;&gt;https://web.dev/samesite-cookies-explained/&lt;/a&gt;&lt;/p&gt;
</description>
<pubDate>Sun, 18 Oct 2020 15:25:00 +0000</pubDate>
<dc:creator>snicker</dc:creator>
<og:description>Cookie是便于向网站添加持久化状态的方式之一。随着时间推移，它们的能力得到了扩展和进化，也造成了很多历史遗留问题。为了解决这个问题，浏览器产商（包括Chrome，Firefox,和Edge）改变了</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/bellhey/p/13837866.html</dc:identifier>
</item>
<item>
<title>迎难而上，QPS提高22+倍 - JacobusLi李依洁</title>
<link>http://www.cnblogs.com/jacobus/p/13837695.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/jacobus/p/13837695.html</guid>
<description>&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;记录1次性能提升的经历，它最大的挑战不在于性能提升，而在于时间急，涉及的面广（比如：机房F5的SSL/TLS性能，机房互联网流量费和项目投入产出比等）。性能指标：至少支持10K QPS，10ms内服务应答，2+%的超时会被[流量方]（BATJ中的一家）打低业务流量，10+%的超时封号。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;因EA整体的架构规划，部门A的试错尝鲜类需求被划分给部门B来实现。这是1个互联网引流的需求：[流量方]会将客户移动端的加密设备信息调用我司接口，我司需告知[流量方]这个设备是否需要看我司的广告。9.20号部门B和[流量方]做了2次性能压测，没通过：1200 QPS，60+%超时率；800 QPS，17+% 超时率。本计划9.22号上线，兼着部门A架构的我被安排进入项目。经多轮沟通分析，因该需求涉及的面比较广，需向多位部门长、CTO汇报请示，同时要向集团IT报备，再加之8天的国庆假期，最后于10.13上线该需求。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;兄弟部门B的失误在于过于乐观、简单地看待了这个业务需求。通过了解生产环境现状、多轮和[流量方]&amp;amp;集团IT沟通后，摸清了大体的情况&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1534363/202010/1534363-20201019075942522-1548825917.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;

&lt;p&gt;开始分析代码，以及整个链路的运行环境&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1534363/202010/1534363-20201018221403947-438877418.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;

&lt;p&gt;通过修改代码、变更Web容器提升单机性能，为后续横向scaling做好基础&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1534363/202010/1534363-20201018221733546-712748486.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;

&lt;p&gt;下图描述的主要是测试环境压测的情况。可以看出，测试环境的压测数据单机性能已经达到16+K 的QPS，但担心[流量方]的统计指标（主要是并发数）有出入，因此预估生产环境集群可以正常抗10K的QPS。在10.16日和[流量方]进行生产压测后，发现集群可以抗30K的QPS（这也是下图【3倍生产环境[流量方]实压转换比】的参考来源）。其实还可以再往上压，35K时[流量方]反馈响应耗时出现了波动，但互联网的宽带有限制，也担心机房F5的问题，同时已超额满足业务预期，就停止了生产的压测&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1534363/202010/1534363-20201019080047402-1837001832.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;

&lt;p&gt;部门B确实做过一些压测，但测试目标不明确（众多的性能指标中，应该以该需求最核心的Web服务器响应耗时这个指标作为基线，来测试单台机器支持的最大QPS），测试工具不准确（当时用部门B的压测方法模拟1000 QPS，我查了下其实只有48的QPS），这也导致了上线前最后1关也就轻易的过了&lt;/p&gt;
&lt;p&gt;另外，我也过于轻信了运维和安全同事他们对Openresty的压测指标（可支持80+w的QPS），测试环境压测时没有测Openresty的性能。不过还好，安全的同事心虚了，在和[流量方]生产压测前，当天下午生产环境压测了一下Openresty的性能，紧急去掉了Openresty节点。当时Openresty压测数据表明：在保证吞吐量的前提下，响应耗时只能是标准需求的接口延迟在200ms左右。关于Openresty的性能调优，或者是不是Openresty中的Lua脚本有性能问题（理论上编译型的Java会比解释型的Lua快），这又是另1个话题了&lt;/p&gt;
</description>
<pubDate>Sun, 18 Oct 2020 14:51:00 +0000</pubDate>
<dc:creator>JacobusLi李依洁</dc:creator>
<og:description>#简介 记录1次性能提升的经历，它最大的挑战不在于性能提升，而在于时间急，涉及的面广（比如：机房F5的SSL/TLS性能，机房互联网流量费和项目投入产出比等）。性能指标：至少支持10K QPS，10m</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/jacobus/p/13837695.html</dc:identifier>
</item>
</channel>
</rss>