<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="css/feed.xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/" xmlns:og="http://ogp.me/ns#">
<channel>
<atom:link rel="self" href="http://192.168.1.4/fivefilters/makefulltextfeed.php?url=feed.cnblogs.com%2Fblog%2Fsitehome%2Frss&amp;max=10&amp;links=preserve&amp;exc=" />
<atom:link rel="alternate" title="Source URL" href="http://feed.cnblogs.com/blog/sitehome/rss" />
<atom:link rel="related" title="Subscribe to feed" href="http://www.subtome.com/#/subscribe?feeds=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed.cnblogs.com%252Fblog%252Fsitehome%252Frss%26max%3D10%26links%3Dpreserve%26exc%3D&amp;back=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed.cnblogs.com%252Fblog%252Fsitehome%252Frss%26max%3D10%26links%3Dpreserve%26exc%3D" />
<title>博客园_首页</title>
<link></link>
<description>代码改变世界</description>
<item>
<title>Kafka Eagle 管理平台 - 常见-youmen</title>
<link>http://www.cnblogs.com/you-men/p/14191288.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/you-men/p/14191288.html</guid>
<description>&lt;h3 id=&quot;kafka-eagle简介&quot;&gt;Kafka-Eagle简介&lt;/h3&gt;
&lt;p&gt;源代码地址：&lt;a href=&quot;https://github.com/smartloli/kafka-eagle&quot; target=&quot;_blank&quot;&gt;https://github.com/smartloli/kafka-eagle&lt;/a&gt;&lt;/p&gt;
&lt;h4 id=&quot;kafka-eagle是什么&quot;&gt;Kafka Eagle是什么&lt;/h4&gt;
&lt;blockquote readability=&quot;10.848275862069&quot;&gt;
&lt;p&gt;Kafka Eagle是一款用于监控和管理Apache Kafka的完全开源系统，目前托管在&lt;a href=&quot;https://github.com/smartloli/kafka-eagle&quot; target=&quot;_blank&quot;&gt;Github&lt;/a&gt;，由笔者和一些开源爱好者共同维护。它提供了完善的管理页面，很方面的去管理和可视化Kafka集群的一些信息，例如Broker详情、性能指标趋势、Topic集合、消费者信息等。&lt;/p&gt;
&lt;p&gt;同时，兼容若干Kafka版本，例如0.8，0.9，...，以及截止到2019-12-16最新发布的2.4.0版本&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&quot;kafka-eagle包含哪些功能&quot;&gt;Kafka Eagle包含哪些功能&lt;/h3&gt;
&lt;blockquote readability=&quot;7&quot;&gt;
&lt;p&gt;Kafka Eagle监控管理系统，提供了一个可视化页面，使用者可以拥有不同的角色，例如管理员、开发者、游客等。不同的角色对应不同的使用权限。在知道了Kafka Eagle的作用之后，那么它包含哪些功能呢？核心功能如下所示:&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&quot;https://cdn.nlark.com/yuque/0/2020/png/2579212/1608907761393-47ee83bb-0031-4d24-9204-51d297ce02c6.png&quot; alt=&quot;image&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h4 id=&quot;数据面板&quot;&gt;数据面板&lt;/h4&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;负责展示Kafka集群的Broker数、Topic数、Consumer数、以及Topic LogSize Top10和Topic Capacity Top10数据。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&quot;https://cdn.nlark.com/yuque/0/2020/png/2579212/1608907761337-711c4654-3440-4803-a44b-45032181d37a.png?x-oss-process=image%2Fresize%2Cw_1500&quot; alt=&quot;image&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h4 id=&quot;主题&quot;&gt;主题&lt;/h4&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;该模块包含主题创建、主题管理、主题预览、KSQL查询主题、主题数据写入、主题属性配置等。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&quot;https://cdn.nlark.com/yuque/0/2020/png/2579212/1608907761370-5138b0b3-4cb7-4b1c-b32a-47cdcd6e472b.png?x-oss-process=image%2Fresize%2Cw_1500&quot; alt=&quot;image&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h4 id=&quot;消费者组&quot;&gt;消费者组&lt;/h4&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;该模块包含监控不同消费者组中的Topic被消费的详情，例如LogSize、Offsets、以及Lag等。同时，支持查看Lag的历史趋势图。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&quot;https://cdn.nlark.com/yuque/0/2020/png/2579212/1608907761397-83a3651f-51d3-4cc4-9cc8-c030bacc4908.png?x-oss-process=image%2Fresize%2Cw_1500&quot; alt=&quot;image&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h4 id=&quot;集群管理&quot;&gt;集群管理&lt;/h4&gt;
&lt;blockquote readability=&quot;7&quot;&gt;
&lt;p&gt;该模块包含Kafka集群和Zookeeper集群的详情展示，例如Kafka的IP和端口、版本号、启动时间、Zookeeper的Leader和Follower。同时，还支持多Kafka集群切换，以及Zookeeper Client数据查看等功能。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&quot;https://cdn.nlark.com/yuque/0/2020/png/2579212/1608907761381-19b6dab3-6ec9-496a-914a-b3bc1bb9b653.png?x-oss-process=image%2Fresize%2Cw_1500&quot; alt=&quot;image&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h4 id=&quot;指标监控&quot;&gt;指标监控&lt;/h4&gt;
&lt;blockquote readability=&quot;7&quot;&gt;
&lt;p&gt;该模块包含监控Kafka集群和Zookeeper集群的核心指标，包含Kafka的消息发送趋势、消息大小接收与发送趋势、Zookeeper的连接数趋势等。同时，还支持查看Broker的瞬时指标数据。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&quot;https://cdn.nlark.com/yuque/0/2020/png/2579212/1608907761396-d7d5ee79-5a14-48b5-8043-1fcadec9b14c.png?x-oss-process=image%2Fresize%2Cw_1500&quot; alt=&quot;image&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h4 id=&quot;告警&quot;&gt;告警&lt;/h4&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;该模块包含告警集群异常和消费者应用Lag异常。同时，支持多种IM告警方式，例如邮件、钉钉、微信、Webhook等。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&quot;https://cdn.nlark.com/yuque/0/2020/png/2579212/1608907761366-43eb674e-d2f8-4a2c-9de8-6e63d1ac4f0c.png?x-oss-process=image%2Fresize%2Cw_1500&quot; alt=&quot;image&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h4 id=&quot;系统管理&quot;&gt;系统管理&lt;/h4&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;该模块包含用户管理，例如创建用户、用户授权、资源管理等&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&quot;https://cdn.nlark.com/yuque/0/2020/png/2579212/1608907761380-01d93b2d-210e-44b8-9dca-34ace59d2528.png?x-oss-process=image%2Fresize%2Cw_1500&quot; alt=&quot;image&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h4 id=&quot;数据大屏&quot;&gt;数据大屏&lt;/h4&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;该模块包含展示消费者和生产者当日及最近7天趋势、Kafka集群读写速度、Kafka集群历史总记录等。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&quot;https://cdn.nlark.com/yuque/0/2020/png/2579212/1608907761398-9905921a-2c30-42b0-8813-3ece8c89ec05.png?x-oss-process=image%2Fresize%2Cw_1500&quot; alt=&quot;image&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h3 id=&quot;kafka-eagle部署&quot;&gt;Kafka Eagle部署&lt;/h3&gt;
&lt;blockquote readability=&quot;7.7894736842105&quot;&gt;
&lt;p&gt;Kafka Eagle安装部署非常方便，可以从&lt;a href=&quot;http://www.kafka-eagle.org/&quot; target=&quot;_blank&quot;&gt;官网&lt;/a&gt;下载最新版本进行安装，或者从Github下载最新的Release源代码进行编译安装。&lt;/p&gt;
&lt;p&gt;例如，从官网下载Kafka Eagle安装包，按如下命令操作即可&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4 id=&quot;下载包安装&quot;&gt;下载包安装&lt;/h4&gt;
&lt;pre&gt;
&lt;code&gt;# 解压安装包
tar xf kafka-eagle-bin-2.0.3.tar.gz -C /opt/
mv /opt/kafka-eagle-bin-2.0.3/kafka-eagle-web-2.0.3-bin.tar.gz  ./
rm -rf /opt/kafka-eagle-bin-2.0.3/
tar xf kafka-eagle-web-2.0.3-bin.tar.gz -C /opt/

然后，是配置环境变量，这里需要注意的是，KE_HOME和JAVA_HOME均需在环境变量文件中进行配置（建议在~/.bash_profile文件中进行设置好，否则，可能在启动的时候抛出环境变量找不到的错误），配置内容如下：
# 配置JAVA_HOME和KE_HOME：
vi ~/.bash_profile
export JAVA_HOME=/usr/local/jdk1.8.0_151
export PATH=$PATH:$JAVA_HOME/bin
export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar
export KE_HOME=/opt/kafka-eagle-web-2.0.3
export PATH=$PATH:$JAVA_HOME/bin:$KE_HOME/bin
&lt;/code&gt;
&lt;/pre&gt;
&lt;h4 id=&quot;配置&quot;&gt;配置&lt;/h4&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;接下来是配置Kafka Eagle的系统文件，这里需要注意一些事项，配置内容如下：&lt;/p&gt;
&lt;/blockquote&gt;
&lt;pre&gt;
&lt;code&gt;# 设置Kafka多集群，这里只需要设置Zookeeper,
# 系统会自动识别Kafka Broker
######################################
kafka.eagle.zk.cluster.alias=cluster1
# cluster1.zk.list=127.0.0.1:2181
cluster1.zk.list=zk01:2181,zk02:2181,zk03:2181
# cluster2.zk.list=127.0.0.1:2181/plain
# cluster3.zk.list=127.0.0.1:2181/scram
# cluster4.zk.list=vmn4:2181
######################################
# Zookeeper线程池最大连接数
######################################
kafka.zk.limit.size=25
######################################
# Kafka Eagle的页面访问端口
######################################
kafka.eagle.webui.port=8048
######################################
# 存储消费信息的类型，一般在0.9版本之前，消费
# 信息会默认存储在Zookeeper中，所以存储类型
# 设置zookeeper即可，如果是在0.10版本之后，
# 消费者信息默认存储在Kafka中，所以存储类型
# 设置为kafka。而且，在使用消费者API时，尽量
# 客户端Kafka API版本和Kafka服务端的版本保持
# 一致性。
######################################
cluster1.kafka.eagle.offset.storage=kafka
cluster2.kafka.eagle.offset.storage=kafka
#cluster3.kafka.eagle.offset.storage=kafka
cluster4.kafka.eagle.offset.storage=kafka
######################################
# 开启性能监控，数据默认保留30天
######################################
kafka.eagle.metrics.charts=true
kafka.eagle.metrics.retain=30
######################################
# KSQL查询Topic数据默认是最新的5000条，如果
# 在使用KSQL查询的过程中出现异常，可以将下面
# 的false属性修改为true，Kafka Eagle会在
# 系统中自动修复错误。
######################################
kafka.eagle.sql.topic.records.max=5000
kafka.eagle.sql.fix.error=false
######################################
# 删除Kafka Topic时需要输入删除密钥，由
# 管理员执行
######################################
kafka.eagle.topic.token=keadmin
######################################
# 开启Kafka ACL特性，例如SCRAM或者PLAIN，
# 一般生产环境会使用SCRAM来做ACL，应为SCRAM
# 可以动态创建和管理用户。
######################################
cluster1.kafka.eagle.sasl.enable=false
cluster1.kafka.eagle.sasl.protocol=SASL_PLAINTEXT
cluster1.kafka.eagle.sasl.mechanism=SCRAM-SHA-256
cluster1.kafka.eagle.sasl.jaas.config=org.apache.kafka.common.security.scram.ScramLoginModule required username=&quot;admin&quot; password=&quot;admin-secret&quot;;
cluster1.kafka.eagle.sasl.client.id=
cluster2.kafka.eagle.sasl.enable=true
cluster2.kafka.eagle.sasl.protocol=SASL_PLAINTEXT
cluster2.kafka.eagle.sasl.mechanism=PLAIN
cluster2.kafka.eagle.sasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required username=&quot;admin&quot; password=&quot;admin-secret&quot;;
cluster2.kafka.eagle.sasl.client.id=
######################################
# 存储Kafka Eagle元数据信息的数据库，目前支持
# MySQL和Sqlite，默认使用Sqlite进行存储
######################################

kafka.eagle.driver=org.sqlite.JDBC
kafka.eagle.url=jdbc:sqlite:/opt/kafka-eagle-web-2.0.3/db/ke.db
kafka.eagle.username=root
kafka.eagle.password=www.kafka-eagle.org

######################################
# kafka mysql jdbc driver address
######################################
#kafka.eagle.driver=com.mysql.jdbc.Driver
#kafka.eagle.url=jdbc:mysql://127.0.0.1:3306/ke?useUnicode=true&amp;amp;characterEncoding=UTF-8&amp;amp;zeroDateTimeBehavior=convertToNull
#kafka.eagle.username=root
#kafka.eagle.password=123456
&lt;/code&gt;
&lt;/pre&gt;
&lt;h4 id=&quot;查看服务状态&quot;&gt;查看服务状态&lt;/h4&gt;
&lt;pre&gt;
&lt;code&gt;# 启动Kafka Eagle系统，执行如下命令：
ke.sh start

# 查看Kafka Eagle运行状态
ke.sh status

# 停止Kafka Eagle
ke.sh stop

# 查看Kafka Eagle GC情况
ke.sh gc

# 查看Kafka Eagle服务器资源占用情况，例如TCP、句柄等
ke.sh stats

# 查看Kafka Eagle版本号
ke.sh version

# 查看Kafka Eagle服务器上JDK的编码情况（如果JDK编码不是UTF-8，可能会有异常出现，执行如下命令，根据提示来修复JDK编码问题）
ke.sh jdk

# 查看Kafka Eagle中是否存在某个类（如果需要精确，类名前面可以加上包名）
ke.sh find [ClassName]
&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;总结&quot;&gt;总结&lt;/h3&gt;
&lt;blockquote readability=&quot;7.8598540145985&quot;&gt;
&lt;p&gt;总的来说，Kafka Eagle提供了简单、易用的页面，部署方便。同时，提供非常详细的&lt;a href=&quot;https://docs.kafka-eagle.org/&quot; target=&quot;_blank&quot;&gt;操作手册&lt;/a&gt;，根据官网提供的操作手册来安装Kafka Eagle，一般都可以正常使用。另外，有时候可能会在日志中发现一些连接超时或是空指针异常，对于这类问题，首先需要检测Kafka集群的各个Broker节点JMX_PORT是否开启（这个Kafka默认是不开启），然后就是空指针异常问题，这类问题通常发生在Kafka集群配置了ACL，这就需要认真检测Kafka Eagle配置文件中ACL信息是否正确（比如设置的用户名和密码是否正确，以及用户是否拥有访问Topic的权限等）&lt;/p&gt;
&lt;/blockquote&gt;
&lt;pre&gt;
&lt;code&gt;vi kafka-server-start.sh
...
if [ &quot;x$KAFKA_HEAP_OPTS&quot; = &quot;x&quot; ]; then
    export KAFKA_HEAP_OPTS=&quot;-server -Xms8G -Xmx8G -XX:PermSize=128m -XX:+UseG1GC -XX:MaxGCPauseMillis=200 -XX:ParallelGCThreads=8 -XX:ConcGCThreads=5 -XX:InitiatingHeapOccupancyPercent=70&quot;
    # 开启JMX_PORT端口，端口开启后，Kafka Eagle系统会自动感知获取
    export JMX_PORT=&quot;9999&quot;
    # 注释脚本中默认的信息
    # export KAFKA_HEAP_OPTS=&quot;-Xmx1G -Xms1G&quot;
fi
&lt;/code&gt;
&lt;/pre&gt;</description>
<pubDate>Fri, 25 Dec 2020 17:02:00 +0000</pubDate>
<dc:creator>常见-youmen</dc:creator>
<og:description>Kafka-Eagle简介 源代码地址：https://github.com/smartloli/kafka-eagle Kafka Eagle是什么 Kafka Eagle是一款用于监控和管理Apa</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/you-men/p/14191288.html</dc:identifier>
</item>
<item>
<title>Linux学习笔记 - Grey Zeng</title>
<link>http://www.cnblogs.com/greyzeng/p/14093197.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/greyzeng/p/14093197.html</guid>
<description>&lt;p&gt;作者：&lt;a href=&quot;https://www.cnblogs.com/greyzeng/&quot; target=&quot;_blank&quot;&gt;Grey&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;原文地址：&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/GreyZeng/articles/blob/master/Linux%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0.md&quot; target=&quot;_blank&quot;&gt;Github&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.yuque.com/greyzeng/uzfhep/xb2ggs&quot; target=&quot;_blank&quot;&gt;语雀&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.cnblogs.com/greyzeng/articles/14093197.html&quot; target=&quot;_blank&quot;&gt;博客园&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;linux的安装&quot;&gt;Linux的安装&lt;/h2&gt;
&lt;p&gt;说明：本安装说明是基于Windows10 下VMware安装Linux，Linux版本是CentOS 7&lt;/p&gt;
&lt;p&gt;&lt;em&gt;自2020年12月01日起，CentOS社区不再为CentOS 6版本提供安全更新，详情请查看&lt;a href=&quot;https://wiki.centos.org/About/Product&quot; target=&quot;_blank&quot;&gt;CentOS官方公告&lt;/a&gt;。&lt;/em&gt;&lt;/p&gt;
&lt;h3 id=&quot;环境&quot;&gt;环境&lt;/h3&gt;
&lt;p&gt;VMware-workstation-full-15.5.2-15785246&lt;/p&gt;
&lt;p&gt;CentOS-7-x86_64-Minimal-1908.iso&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;其他版本的安装可作为参考&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&quot;安装步骤&quot;&gt;安装步骤&lt;/h3&gt;
&lt;p&gt;打开VMware，&lt;/p&gt;
&lt;p&gt;点击创建新的虚拟机，进入新建虚拟机向导,然后依次按照截图步骤进行安装&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://cdn.nlark.com/yuque/0/2020/png/757806/1608912705881-f8721088-b5f7-4807-9f64-b539e16ec8dc.png#align=left&amp;amp;display=inline&amp;amp;height=440&amp;amp;margin=%5Bobject%20Object%5D&amp;amp;name=1.png&amp;amp;originHeight=440&amp;amp;originWidth=513&amp;amp;size=30124&amp;amp;status=done&amp;amp;style=none&amp;amp;width=513&quot; alt=&quot;1.png&quot; loading=&quot;lazy&quot;/&gt;&lt;br/&gt;&lt;img src=&quot;https://cdn.nlark.com/yuque/0/2020/png/757806/1608912706641-0f667be4-33d1-44fa-81d8-c8e2c2f4a0e4.png#align=left&amp;amp;display=inline&amp;amp;height=440&amp;amp;margin=%5Bobject%20Object%5D&amp;amp;name=2.png&amp;amp;originHeight=440&amp;amp;originWidth=513&amp;amp;size=14544&amp;amp;status=done&amp;amp;style=none&amp;amp;width=513&quot; alt=&quot;2.png&quot; loading=&quot;lazy&quot;/&gt;&lt;br/&gt;&lt;img src=&quot;https://cdn.nlark.com/yuque/0/2020/png/757806/1608912707506-b675ddeb-c1af-463a-98e2-6daaa6b6f360.png#align=left&amp;amp;display=inline&amp;amp;height=440&amp;amp;margin=%5Bobject%20Object%5D&amp;amp;name=3.png&amp;amp;originHeight=440&amp;amp;originWidth=513&amp;amp;size=11853&amp;amp;status=done&amp;amp;style=none&amp;amp;width=513&quot; alt=&quot;3.png&quot; loading=&quot;lazy&quot;/&gt;&lt;br/&gt;&lt;img src=&quot;https://cdn.nlark.com/yuque/0/2020/png/757806/1608912708292-54d9e6cb-2455-46f5-aef4-0f41e72e1fe2.png#align=left&amp;amp;display=inline&amp;amp;height=440&amp;amp;margin=%5Bobject%20Object%5D&amp;amp;name=4.png&amp;amp;originHeight=440&amp;amp;originWidth=513&amp;amp;size=11432&amp;amp;status=done&amp;amp;style=none&amp;amp;width=513&quot; alt=&quot;4.png&quot; loading=&quot;lazy&quot;/&gt;&lt;br/&gt;&lt;img src=&quot;https://cdn.nlark.com/yuque/0/2020/png/757806/1608912709067-1066608f-00bf-4628-826c-558e1be17b11.png#align=left&amp;amp;display=inline&amp;amp;height=440&amp;amp;margin=%5Bobject%20Object%5D&amp;amp;name=5.png&amp;amp;originHeight=440&amp;amp;originWidth=513&amp;amp;size=15434&amp;amp;status=done&amp;amp;style=none&amp;amp;width=513&quot; alt=&quot;5.png&quot; loading=&quot;lazy&quot;/&gt;&lt;br/&gt;&lt;img src=&quot;https://cdn.nlark.com/yuque/0/2020/png/757806/1608912709906-6f11a8b8-dae7-48fc-ac8d-8e5a10f5b82b.png#align=left&amp;amp;display=inline&amp;amp;height=440&amp;amp;margin=%5Bobject%20Object%5D&amp;amp;name=6.png&amp;amp;originHeight=440&amp;amp;originWidth=513&amp;amp;size=14968&amp;amp;status=done&amp;amp;style=none&amp;amp;width=513&quot; alt=&quot;6.png&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;点击完成即可，在启动过程中，有可能会出现如下错误：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://cdn.nlark.com/yuque/0/2020/png/757806/1588731755864-7f1860d1-c7b0-44ef-8440-e0603046d391.png#align=left&amp;amp;display=inline&amp;amp;height=171&amp;amp;margin=%5Bobject%20Object%5D&amp;amp;originHeight=171&amp;amp;originWidth=386&amp;amp;status=done&amp;amp;style=none&amp;amp;width=386&quot; alt=&quot;error&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;这里是&lt;a href=&quot;http://www.bubuko.com/infodetail-3314116.html&quot; target=&quot;_blank&quot;&gt;解决方案&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;点击：编辑虚拟机设置&lt;/p&gt;
&lt;p&gt;在CD/DVD这里，选择使用ISO映像文件，选择对应的CentOS的iso文件&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://cdn.nlark.com/yuque/0/2020/png/757806/1608912746012-40780714-8c0b-49fb-a732-bb7a624fda1f.png#align=left&amp;amp;display=inline&amp;amp;height=756&amp;amp;margin=%5Bobject%20Object%5D&amp;amp;name=7.png&amp;amp;originHeight=756&amp;amp;originWidth=745&amp;amp;size=23539&amp;amp;status=done&amp;amp;style=none&amp;amp;width=745&quot; alt=&quot;7.png&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;点击：开启此虚拟机，然后按如下截图安装&lt;br/&gt;语言选择English&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://cdn.nlark.com/yuque/0/2020/png/757806/1608912803990-7e391ad8-fb5b-4fc1-8198-28445f548028.png#align=left&amp;amp;display=inline&amp;amp;height=600&amp;amp;margin=%5Bobject%20Object%5D&amp;amp;name=8.png&amp;amp;originHeight=600&amp;amp;originWidth=800&amp;amp;size=124836&amp;amp;status=done&amp;amp;style=none&amp;amp;width=800&quot; alt=&quot;8.png&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;DATE &amp;amp; TIME选择Asia，Shanghai&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://cdn.nlark.com/yuque/0/2020/png/757806/1608912805359-ad4bfaaa-eb7f-4edc-b001-a35292d62146.png#align=left&amp;amp;display=inline&amp;amp;height=630&amp;amp;margin=%5Bobject%20Object%5D&amp;amp;name=9.png&amp;amp;originHeight=630&amp;amp;originWidth=798&amp;amp;size=121141&amp;amp;status=done&amp;amp;style=none&amp;amp;width=798&quot; alt=&quot;9.png&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;Software Selection 这里，选择Minimal Install&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://cdn.nlark.com/yuque/0/2020/png/757806/1608912807013-818263c1-ca3e-41cb-b4b9-6b21d1b8ce80.png#align=left&amp;amp;display=inline&amp;amp;height=638&amp;amp;margin=%5Bobject%20Object%5D&amp;amp;name=10.png&amp;amp;originHeight=638&amp;amp;originWidth=808&amp;amp;size=123669&amp;amp;status=done&amp;amp;style=none&amp;amp;width=808&quot; alt=&quot;10.png&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://cdn.nlark.com/yuque/0/2020/png/757806/1608912808398-317f543d-dd88-47c0-91e6-c3c34f01fe47.png#align=left&amp;amp;display=inline&amp;amp;height=632&amp;amp;margin=%5Bobject%20Object%5D&amp;amp;name=11.png&amp;amp;originHeight=632&amp;amp;originWidth=802&amp;amp;size=58612&amp;amp;status=done&amp;amp;style=none&amp;amp;width=802&quot; alt=&quot;11.png&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;KDUMP这里，Enable kdump这个选项不要勾选&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://cdn.nlark.com/yuque/0/2020/png/757806/1608912809479-0426ff34-b499-4110-a98b-21276e42ca15.png#align=left&amp;amp;display=inline&amp;amp;height=662&amp;amp;margin=%5Bobject%20Object%5D&amp;amp;name=12.png&amp;amp;originHeight=662&amp;amp;originWidth=817&amp;amp;size=122310&amp;amp;status=done&amp;amp;style=none&amp;amp;width=817&quot; alt=&quot;12.png&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://cdn.nlark.com/yuque/0/2020/png/757806/1608912810823-ebd61d0b-afad-46e2-87fa-a3c263dac9be.png#align=left&amp;amp;display=inline&amp;amp;height=621&amp;amp;margin=%5Bobject%20Object%5D&amp;amp;name=13.png&amp;amp;originHeight=621&amp;amp;originWidth=803&amp;amp;size=65835&amp;amp;status=done&amp;amp;style=none&amp;amp;width=803&quot; alt=&quot;13.png&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;NETWORK &amp;amp; HOST NAME这里，把Ethernet开关打开&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://cdn.nlark.com/yuque/0/2020/png/757806/1608912811959-a4b26c98-a508-4d21-98c8-70e20021948e.png#align=left&amp;amp;display=inline&amp;amp;height=640&amp;amp;margin=%5Bobject%20Object%5D&amp;amp;name=14.png&amp;amp;originHeight=640&amp;amp;originWidth=834&amp;amp;size=129708&amp;amp;status=done&amp;amp;style=none&amp;amp;width=834&quot; alt=&quot;14.png&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://cdn.nlark.com/yuque/0/2020/png/757806/1608912813235-e5f8c572-f460-4f3c-bf20-db92dd497d75.png#align=left&amp;amp;display=inline&amp;amp;height=668&amp;amp;margin=%5Bobject%20Object%5D&amp;amp;name=15.png&amp;amp;originHeight=668&amp;amp;originWidth=840&amp;amp;size=88566&amp;amp;status=done&amp;amp;style=none&amp;amp;width=840&quot; alt=&quot;15.png&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;设置Root密码&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://cdn.nlark.com/yuque/0/2020/png/757806/1608912814385-dce299f9-eea7-4cd5-a771-aa1ee2421f52.png#align=left&amp;amp;display=inline&amp;amp;height=643&amp;amp;margin=%5Bobject%20Object%5D&amp;amp;name=16.png&amp;amp;originHeight=643&amp;amp;originWidth=815&amp;amp;size=197436&amp;amp;status=done&amp;amp;style=none&amp;amp;width=815&quot; alt=&quot;16.png&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;点击USER CREATION，新建一个管理员账户&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://cdn.nlark.com/yuque/0/2020/png/757806/1608912815461-e5cac508-a863-428e-9667-86cdff20186f.png#align=left&amp;amp;display=inline&amp;amp;height=610&amp;amp;margin=%5Bobject%20Object%5D&amp;amp;name=17.png&amp;amp;originHeight=610&amp;amp;originWidth=812&amp;amp;size=67750&amp;amp;status=done&amp;amp;style=none&amp;amp;width=812&quot; alt=&quot;17.png&quot; loading=&quot;lazy&quot;/&gt;**&lt;/p&gt;
&lt;p&gt;然后系统会自动安装，安装好了以后，有个Reboot按钮，点击Reboot按钮，即可，Linux安装完成&lt;/p&gt;
&lt;h2 id=&quot;设置hostname&quot;&gt;设置HostName&lt;/h2&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;hostnamectl set-hostname sec
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;使用以上命令，可以把Host Name设置为sec&lt;/p&gt;
&lt;h2 id=&quot;网络配置&quot;&gt;网络配置&lt;/h2&gt;
&lt;ol&gt;&lt;li&gt;找到网卡位置：&lt;/li&gt;
&lt;/ol&gt;&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;cd /etc/sysconfig/network-scripts/
&lt;/code&gt;
&lt;/pre&gt;
&lt;ol start=&quot;2&quot;&gt;&lt;li&gt;配置网卡协议&lt;/li&gt;
&lt;/ol&gt;&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;vim ifcfg-ens33
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;注：如无vim，可以执行&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;yum install -y vim
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;安装Vim&lt;/p&gt;
&lt;p&gt;然后再执行：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;vim ifcfg-ens33
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;删除UUID这一行&lt;br/&gt;&lt;img src=&quot;https://cdn.nlark.com/yuque/0/2020/png/757806/1608913225772-cd0cb721-a88a-4bb6-a89b-203172976434.png#align=left&amp;amp;display=inline&amp;amp;height=484&amp;amp;margin=%5Bobject%20Object%5D&amp;amp;name=19.png&amp;amp;originHeight=484&amp;amp;originWidth=702&amp;amp;size=20830&amp;amp;status=done&amp;amp;style=none&amp;amp;width=702&quot; alt=&quot;19.png&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;重启网卡服务&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;service network restart
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;测试：&lt;/p&gt;
&lt;p&gt;ping www.baidu.com 查看是否有数据接收到。&lt;/p&gt;
&lt;h2 id=&quot;快照与克隆&quot;&gt;快照与克隆&lt;/h2&gt;
&lt;p&gt;克隆之前，先打快照&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;关闭虚拟机&lt;/li&gt;
&lt;li&gt;在节点这里，选择快照-&amp;gt;快照管理器&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;&lt;img src=&quot;https://cdn.nlark.com/yuque/0/2020/png/757806/1588602217391-024b5957-a05c-44d8-88cf-6bf5b8d462ca.png#align=left&amp;amp;display=inline&amp;amp;height=484&amp;amp;margin=%5Bobject%20Object%5D&amp;amp;originHeight=484&amp;amp;originWidth=498&amp;amp;status=done&amp;amp;style=none&amp;amp;width=498&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://cdn.nlark.com/yuque/0/2020/png/757806/1588602249181-10bce7a3-1f2f-4a74-a7d9-81b7e193e87e.png#align=left&amp;amp;display=inline&amp;amp;height=550&amp;amp;margin=%5Bobject%20Object%5D&amp;amp;originHeight=550&amp;amp;originWidth=739&amp;amp;status=done&amp;amp;style=none&amp;amp;width=739&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;为快照设置一个名字，假设为base，&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://cdn.nlark.com/yuque/0/2020/png/757806/1588602264236-9fbc5596-994e-49c7-ad32-06c3946f421f.png#align=left&amp;amp;display=inline&amp;amp;height=272&amp;amp;margin=%5Bobject%20Object%5D&amp;amp;originHeight=272&amp;amp;originWidth=436&amp;amp;status=done&amp;amp;style=none&amp;amp;width=436&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://cdn.nlark.com/yuque/0/2020/png/757806/1588602313478-4b6e322c-f5c8-4d0d-8cec-5531105cdd6b.png#align=left&amp;amp;display=inline&amp;amp;height=550&amp;amp;margin=%5Bobject%20Object%5D&amp;amp;originHeight=550&amp;amp;originWidth=732&amp;amp;status=done&amp;amp;style=none&amp;amp;width=732&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;然后开始克隆，在需要克隆节点上右键：克隆&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://cdn.nlark.com/yuque/0/2020/png/757806/1608913346693-afc53602-5603-439b-88ed-39c3de37176f.png#align=left&amp;amp;display=inline&amp;amp;height=434&amp;amp;margin=%5Bobject%20Object%5D&amp;amp;name=22.png&amp;amp;originHeight=434&amp;amp;originWidth=524&amp;amp;size=11851&amp;amp;status=done&amp;amp;style=none&amp;amp;width=524&quot; alt=&quot;22.png&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://cdn.nlark.com/yuque/0/2020/png/757806/1608913347571-10bd5609-dfc2-4a72-b3d0-686fc4b67347.png#align=left&amp;amp;display=inline&amp;amp;height=434&amp;amp;margin=%5Bobject%20Object%5D&amp;amp;name=23.png&amp;amp;originHeight=434&amp;amp;originWidth=524&amp;amp;size=13824&amp;amp;status=done&amp;amp;style=none&amp;amp;width=524&quot; alt=&quot;23.png&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;这里选择创建链接克隆&lt;/strong&gt;可以节省资源，为克隆的虚拟机设置一个名称，假设叫：node02&lt;/p&gt;
&lt;p&gt;克隆完毕&lt;/p&gt;
&lt;h2 id=&quot;永久关闭selinux的方法&quot;&gt;永久关闭SELinux的方法&lt;/h2&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;vim /etc/selinux/config
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;把SELinux设置为disabled&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://cdn.nlark.com/yuque/0/2020/png/757806/1608913578583-214cb33d-ede1-4904-a3ef-257602812e4c.png#align=left&amp;amp;display=inline&amp;amp;height=217&amp;amp;margin=%5Bobject%20Object%5D&amp;amp;name=image.png&amp;amp;originHeight=217&amp;amp;originWidth=738&amp;amp;size=17487&amp;amp;status=done&amp;amp;style=none&amp;amp;width=738&quot; alt=&quot;image.png&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h2 id=&quot;配置ssh密钥连接linux&quot;&gt;配置ssh密钥连接Linux&lt;/h2&gt;
&lt;p&gt;首先Win10系统上需要有OpenSSH，像这样：终端输入ssh&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://cdn.nlark.com/yuque/0/2020/png/757806/1583580986229-a39ca5f4-a6df-43c1-9e57-e85003836fa0.png#align=left&amp;amp;display=inline&amp;amp;height=136&amp;amp;margin=%5Bobject%20Object%5D&amp;amp;originHeight=163&amp;amp;originWidth=689&amp;amp;status=done&amp;amp;style=none&amp;amp;width=576#align=left&amp;amp;display=inline&amp;amp;height=163&amp;amp;margin=%5Bobject%20Object%5D&amp;amp;originHeight=163&amp;amp;originWidth=689&amp;amp;status=done&amp;amp;style=none&amp;amp;width=689&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;这样就是有的（好像Win10 1809+默认就是有的）。&lt;br/&gt;然后生成密钥对：&lt;br/&gt;ssh-keygen -t rsa&lt;br/&gt;接着按提示信息可根据个人需求选择，这里是默认（连续三个回车即可）。&lt;br/&gt;生成的密钥对默认保存在当前用户的根目录下的.ssh目录中（C:\Users\username.ssh）：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://cdn.nlark.com/yuque/0/2020/png/757806/1583580986262-866d2d74-0511-4d07-b535-42f34c103bd8.png#align=left&amp;amp;display=inline&amp;amp;height=128&amp;amp;margin=%5Bobject%20Object%5D&amp;amp;originHeight=153&amp;amp;originWidth=691&amp;amp;status=done&amp;amp;style=none&amp;amp;width=576#align=left&amp;amp;display=inline&amp;amp;height=153&amp;amp;margin=%5Bobject%20Object%5D&amp;amp;originHeight=153&amp;amp;originWidth=691&amp;amp;status=done&amp;amp;style=none&amp;amp;width=691&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;接着我们将公钥id_rsa.pub上传至Linux服务器（保存到你要连接的用户根目录下~/.ssh/中，没有.ssh目录则创建）：&lt;br/&gt;修改/etc/ssh/sshd_config配制文件，修改以下内容&lt;br/&gt;RSAAuthentication yes&lt;br/&gt;PubkeyAuthentication yes&lt;br/&gt;PasswordAuthentication no&lt;/p&gt;
&lt;p&gt;上传好后，将Linux中的id_rsa.pub重命名为authorized_keys，更改文件权限为600，更改.ssh目录权限为700：&lt;br/&gt;mv id_rsa.pub authorized_keys&lt;br/&gt;chmod 600 authorized_keys&lt;br/&gt;chmod 700 .ssh&lt;/p&gt;
&lt;p&gt;然后就可以通过ssh方式连接到Linux&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://cdn.nlark.com/yuque/0/2020/png/757806/1583580986286-d1deb211-ea47-403c-9ffb-048f2a97373f.png#align=left&amp;amp;display=inline&amp;amp;height=507&amp;amp;margin=%5Bobject%20Object%5D&amp;amp;originHeight=507&amp;amp;originWidth=504&amp;amp;status=done&amp;amp;style=none&amp;amp;width=504#align=left&amp;amp;display=inline&amp;amp;height=507&amp;amp;margin=%5Bobject%20Object%5D&amp;amp;originHeight=507&amp;amp;originWidth=504&amp;amp;status=done&amp;amp;style=none&amp;amp;width=504&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h2 id=&quot;linux的命令&quot;&gt;Linux的命令&lt;/h2&gt;
&lt;p&gt;分为内部命令和外部命令 内部命令（Shell自带的命令）&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://cdn.nlark.com/yuque/0/2020/png/757806/1588604727521-7fce2dd3-d1f9-4bc5-95ac-7071c77c78d7.png#align=left&amp;amp;display=inline&amp;amp;height=52&amp;amp;margin=%5Bobject%20Object%5D&amp;amp;name=image.png&amp;amp;originHeight=52&amp;amp;originWidth=275&amp;amp;size=3550&amp;amp;status=done&amp;amp;style=none&amp;amp;width=275#align=left&amp;amp;display=inline&amp;amp;height=52&amp;amp;margin=%5Bobject%20Object%5D&amp;amp;originHeight=52&amp;amp;originWidth=275&amp;amp;status=done&amp;amp;style=none&amp;amp;width=275&quot; alt=&quot;image.png&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;外部命令（不是Shell自带的命令，由用户安装的）&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://cdn.nlark.com/yuque/0/2020/png/757806/1588604749548-b6dde106-d9d3-4529-95ff-f9891a6c0bca.png#align=left&amp;amp;display=inline&amp;amp;height=59&amp;amp;margin=%5Bobject%20Object%5D&amp;amp;name=image.png&amp;amp;originHeight=59&amp;amp;originWidth=300&amp;amp;size=3679&amp;amp;status=done&amp;amp;style=none&amp;amp;width=300#align=left&amp;amp;display=inline&amp;amp;height=59&amp;amp;margin=%5Bobject%20Object%5D&amp;amp;originHeight=59&amp;amp;originWidth=300&amp;amp;status=done&amp;amp;style=none&amp;amp;width=300&quot; alt=&quot;image.png&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;查看命令是一个什么类型的文件&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://cdn.nlark.com/yuque/0/2020/png/757806/1588604859481-c0c12d62-f6b8-448c-a17f-97024f9785ae.png#align=left&amp;amp;display=inline&amp;amp;height=74&amp;amp;margin=%5Bobject%20Object%5D&amp;amp;name=image.png&amp;amp;originHeight=74&amp;amp;originWidth=773&amp;amp;size=9768&amp;amp;status=done&amp;amp;style=none&amp;amp;width=773#align=left&amp;amp;display=inline&amp;amp;height=74&amp;amp;margin=%5Bobject%20Object%5D&amp;amp;originHeight=74&amp;amp;originWidth=773&amp;amp;status=done&amp;amp;style=none&amp;amp;width=773&quot; alt=&quot;image.png&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;查看ifconfig命令在哪个位置&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-shell&quot;&gt;whereis ifconfig
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;什么是Shell? bash shell，就是一个程序，就是Linux系统安装的一个软件&lt;/p&gt;
&lt;p&gt;root/密码写对后，直接进入bash shell软件&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://cdn.nlark.com/yuque/0/2020/png/757806/1588605290609-77801687-5dca-4abf-8eaf-483e70d72e06.png#align=left&amp;amp;display=inline&amp;amp;height=294&amp;amp;margin=%5Bobject%20Object%5D&amp;amp;name=image.png&amp;amp;originHeight=294&amp;amp;originWidth=680&amp;amp;size=84812&amp;amp;status=done&amp;amp;style=none&amp;amp;width=680#align=left&amp;amp;display=inline&amp;amp;height=294&amp;amp;margin=%5Bobject%20Object%5D&amp;amp;originHeight=294&amp;amp;originWidth=680&amp;amp;status=done&amp;amp;style=none&amp;amp;width=680&quot; alt=&quot;image.png&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://cdn.nlark.com/yuque/0/2020/png/757806/1588605354987-f9976149-de96-4db0-8e20-28c521255c87.png#align=left&amp;amp;display=inline&amp;amp;height=78&amp;amp;margin=%5Bobject%20Object%5D&amp;amp;name=image.png&amp;amp;originHeight=78&amp;amp;originWidth=276&amp;amp;size=23804&amp;amp;status=done&amp;amp;style=none&amp;amp;width=276#align=left&amp;amp;display=inline&amp;amp;height=78&amp;amp;margin=%5Bobject%20Object%5D&amp;amp;originHeight=78&amp;amp;originWidth=276&amp;amp;status=done&amp;amp;style=none&amp;amp;width=276&quot; alt=&quot;image.png&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;echo $PATH&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://cdn.nlark.com/yuque/0/2020/png/757806/1588605392931-c4e9cc67-60a5-46ec-9490-5b2c1080ebab.png#align=left&amp;amp;display=inline&amp;amp;height=41&amp;amp;margin=%5Bobject%20Object%5D&amp;amp;name=image.png&amp;amp;originHeight=41&amp;amp;originWidth=514&amp;amp;size=3691&amp;amp;status=done&amp;amp;style=none&amp;amp;width=514#align=left&amp;amp;display=inline&amp;amp;height=41&amp;amp;margin=%5Bobject%20Object%5D&amp;amp;originHeight=41&amp;amp;originWidth=514&amp;amp;status=done&amp;amp;style=none&amp;amp;width=514&quot; alt=&quot;image.png&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;内部命令的帮助用help指令，外部命令的帮助用man指令&lt;/p&gt;
&lt;p&gt;echo $$: 当前bash shell的进程号&lt;/p&gt;
&lt;p&gt;如果平时退出不了某个程序，可以复制一个ssh对话，用ps -ef找到那个进程，用kill -9 退出即可&lt;/p&gt;
&lt;p&gt;bash shell在执行命令的时候，做了两步优化：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;通过PATH来&lt;/li&gt;
&lt;li&gt;通过hash来，hash查看，hash -r（清空hash）&lt;/li&gt;
&lt;/ol&gt;&lt;h2 id=&quot;shell&quot;&gt;Shell&lt;/h2&gt;
&lt;p&gt;编写脚本时候要赋予该文件执行权限&lt;code&gt;chmod u+rx filename&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;如果bash执行，不需要赋予执行权限&lt;/p&gt;
&lt;p&gt;bash ./filename.sh&lt;br/&gt;./filename.sh&lt;br/&gt;以上两种执行方式都是新开一个进程&lt;/p&gt;
&lt;p&gt;source ./filename.sh&lt;br/&gt;.filename.sh&lt;br/&gt;这种方式执行不会产生新的子进程&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-shell&quot;&gt;#!/bin/bash/
cd /tmp
pwd
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;输入重定向符号 &amp;lt;&lt;/p&gt;
&lt;p&gt;read var &amp;lt; /path/to/a/file&lt;/p&gt;
&lt;p&gt;输出重定向 &amp;gt;   &amp;gt;&amp;gt; 2&amp;gt; &amp;amp;&amp;gt;&lt;/p&gt;
&lt;p&gt;echo 123 &amp;gt; /path/to/a/file  清空输入&lt;br/&gt;echo 123 &amp;gt;&amp;gt; /path/to/a/file 追加&lt;br/&gt;echo 12343 2&amp;gt; /path/to/a/file 错误输入&lt;br/&gt;echo 122 &amp;amp;&amp;gt; /path/to/a/file 全部输入&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-shell&quot;&gt;#!/bin/bash

cat &amp;gt; /data/m.sh &amp;lt;&amp;lt; EOF
echo &quot;hello bash&quot;
EOF
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;变量赋值&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;a=123&lt;/li&gt;
&lt;li&gt;let a=10+2&lt;/li&gt;
&lt;li&gt;l=ls&lt;/li&gt;
&lt;li&gt;letc=$(ls -l /etc) 或 letc=&lt;code&gt;ls -l /etc&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;变量值有空格等特殊字符可以包括在&quot;&quot; 或 ``中&lt;/li&gt;
&lt;li&gt;echo ${变量名} 查看变量的值&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;变量的默认作用范围&lt;br/&gt;默认自己的shell进程中&lt;/p&gt;
&lt;p&gt;变量的导出，让子进程获得父进程的变量值&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;export 变量名&lt;br/&gt;变量的删除&lt;/li&gt;
&lt;li&gt;unset 变量名&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;环境变量：每个Shell打开都可以获得的变量&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;set和env命令&lt;/li&gt;
&lt;li&gt;$? 上一条命令是否正确执行（正确：0， 错误：1）&lt;/li&gt;
&lt;li&gt;$PATH&lt;/li&gt;
&lt;li&gt;$PS1&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;位置变量&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;$1 $2 ... $n&lt;/li&gt;
&lt;/ul&gt;&lt;pre&gt;
&lt;code class=&quot;language-shell&quot;&gt;#!/bin/bash

# $1 $2 ...$9 ${10}


echo $1
# 默认打印第二个参数值，如果为空则显示_
echo ${2-_}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;环境变量配置文件所在目录&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;/etc/profile&lt;/li&gt;
&lt;li&gt;/etc/profile.d/&lt;/li&gt;
&lt;li&gt;~/.bash_profile&lt;/li&gt;
&lt;li&gt;~/.bashrc&lt;/li&gt;
&lt;li&gt;/etc/bashrc&lt;/li&gt;
&lt;/ul&gt;&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;说明：/etc/下的配置文件，表示所有用户通用的配置，用户家目录的配置文件只能特定用户使用，&lt;br/&gt;su - 用户名  login shell 所有都可以执行&lt;br/&gt;su 用户名 nologin shell  /bashrc, /etc/bashrc&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;所用终端都应用新的环境变量: export PATH=$PATH:/new/to/path&lt;br/&gt;让环境变量立即生效：source /etc/profile&lt;/p&gt;
&lt;p&gt;定义数组&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-shell&quot;&gt;# 数组定义
IPTS=(10.0 1.0 3.0)

# 显示数组中所有元素
echo ${IPTS[@]}

#显示数组元素个数
echo ${#IPTS[@]}

显示数组的第一个元素
echo ${IPTS[0]}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;Q：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;内建命令不需要创建子进程&lt;/li&gt;
&lt;li&gt;内建命令对当前shell有效&lt;/li&gt;
&lt;/ul&gt;&lt;h2 id=&quot;linux文件系统&quot;&gt;Linux文件系统&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;https://cdn.nlark.com/yuque/0/2020/png/757806/1588638734029-d7f3e8d9-e5b6-42ab-ad0f-bfa9d99e4541.png#align=left&amp;amp;display=inline&amp;amp;height=775&amp;amp;margin=%5Bobject%20Object%5D&amp;amp;name=image.png&amp;amp;originHeight=775&amp;amp;originWidth=807&amp;amp;size=217381&amp;amp;status=done&amp;amp;style=none&amp;amp;width=807#align=left&amp;amp;display=inline&amp;amp;height=775&amp;amp;margin=%5Bobject%20Object%5D&amp;amp;originHeight=775&amp;amp;originWidth=807&amp;amp;status=done&amp;amp;style=none&amp;amp;width=807&quot; alt=&quot;image.png&quot; loading=&quot;lazy&quot;/&gt;&lt;br/&gt;除了/boot的数据，其他目录下的数据都存在了sda3里面了&lt;/p&gt;
&lt;p&gt;/var 可变化的文件，比如：日志文件，数据文件&lt;/p&gt;
&lt;p&gt;更多文件类型说明见：&lt;br/&gt;&lt;img src=&quot;https://cdn.nlark.com/yuque/0/2020/png/757806/1588639527449-93861280-c798-4615-ad30-2a992ffa29a1.png#align=left&amp;amp;display=inline&amp;amp;height=604&amp;amp;margin=%5Bobject%20Object%5D&amp;amp;name=image.png&amp;amp;originHeight=604&amp;amp;originWidth=687&amp;amp;size=223193&amp;amp;status=done&amp;amp;style=none&amp;amp;width=687#align=left&amp;amp;display=inline&amp;amp;height=604&amp;amp;margin=%5Bobject%20Object%5D&amp;amp;originHeight=604&amp;amp;originWidth=687&amp;amp;status=done&amp;amp;style=none&amp;amp;width=687&quot; alt=&quot;image.png&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-shell&quot;&gt;## 级联创建目录
mkdir -p a/adir/bdir

mkdir a/adir a/bdir a/cdir
mkdir a/{1,2,3}dir


## 复制文件夹
cp -r a cpp/ ## 将a文件夹复制到cpp文件夹中，复制文件夹用
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;stat和touch 组合使用，可以增量监控数据改变的时间 &lt;a href=&quot;https://www.cnblogs.com/z-joshua/p/10042681.html&quot; target=&quot;_blank&quot;&gt;linux命令系列 stat &amp;amp; touch&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;命令积累&quot;&gt;命令积累&lt;/h2&gt;
&lt;p&gt;与时间服务器上的时间同步&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;安装ntpdate工具&lt;/li&gt;
&lt;/ol&gt;&lt;pre&gt;
&lt;code class=&quot;language-shell&quot;&gt;yum -y install ntp ntpdate
&lt;/code&gt;
&lt;/pre&gt;
&lt;ol start=&quot;2&quot;&gt;&lt;li&gt;设置时间为阿里服务器的时间&lt;/li&gt;
&lt;/ol&gt;&lt;pre&gt;
&lt;code class=&quot;language-shell&quot;&gt;ntpdate ntp1.aliyun.com
&lt;/code&gt;
&lt;/pre&gt;
&lt;ol start=&quot;3&quot;&gt;&lt;li&gt;将系统时间写入硬件时间&lt;/li&gt;
&lt;/ol&gt;&lt;pre&gt;
&lt;code class=&quot;language-shell&quot;&gt;hwclock –systohc
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;一屏可以显示的文件，可以用cat 一屏显示不出来的内容，用more命令，space翻页，无法回看 使用less 命令就可以往后推（space），按b键往前翻（less是将文件一次性load内存，所以文件大的时候只能用more）&lt;/p&gt;
&lt;p&gt;head -n 文件名 前n行的数据 tail -n 文件名 后n行数据 tail -f 文件名 监控文件内容改变&lt;/p&gt;
&lt;p&gt;管道命令 cat xxx | head -3 cat xxx作为输出流的形式作为后面命令的输入流&lt;/p&gt;
&lt;p&gt;ls -l 无法接受前面的输出流的内容，如果要解决，需要这样用： echo &quot;/&quot; | xargs ls -l&lt;/p&gt;
&lt;p&gt;head -5 xxx | tail -1 获取第五行的数据&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-shell&quot;&gt;screen -S yourname ## 新建一个叫yourname的session
screen -ls         ## 列出当前所有的session
screen -r yourname ## 回到yourname这个session
screen -d yourname ## 远程detach某个session
screen -d -r yourname ## 结束当前session并回到yourname这个session
&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;参考资料&quot;&gt;参考资料&lt;/h2&gt;
&lt;p&gt;&lt;a href=&quot;https://book.douban.com/subject/22226727/&quot; target=&quot;_blank&quot;&gt;Linux命令行大全&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://book.douban.com/subject/27198046/&quot; target=&quot;_blank&quot;&gt;Linux就该这么学&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://pan.baidu.com/s/1qLY7x29EtZO-uz3a06QzFQ&quot; target=&quot;_blank&quot;&gt;Linux预习资料&lt;/a&gt; 提取码：7w30&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://pan.baidu.com/s/1_M0ADqa8LeHrJJTCwTDUpA&quot; target=&quot;_blank&quot;&gt;CentOS6.x升级到CentOS7.x的注意事项视频&lt;/a&gt; 提取码: yhfd&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://book.douban.com/subject/6097773/&quot; target=&quot;_blank&quot;&gt;Linux内核设计与实现&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://time.geekbang.org/course/intro/100029601&quot; target=&quot;_blank&quot;&gt;极客时间-Linux实战技能100讲&lt;/a&gt;&lt;/p&gt;
</description>
<pubDate>Fri, 25 Dec 2020 16:37:00 +0000</pubDate>
<dc:creator>Grey Zeng</dc:creator>
<og:description>作者：Grey 原文地址： Github 语雀 博客园 Linux的安装 说明：本安装说明是基于Windows10 下VMware安装Linux，Linux版本是CentOS 7 自2020年12月0</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/greyzeng/p/14093197.html</dc:identifier>
</item>
<item>
<title>x264编码demo定制修改介绍 - OnlyTime_唯有时光</title>
<link>http://www.cnblogs.com/Dreaming-in-Gottingen/p/14191229.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/Dreaming-in-Gottingen/p/14191229.html</guid>
<description>&lt;p&gt;&lt;span&gt;　　x264编码器，提供了两个demo来验证编码功能：一个是大而全的x264.c，另外一个是简洁版的example.c。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　其中，前者demo，可以配置很多编码参数，但太冗长繁杂，对初学者不太友好。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;　　 &lt;span&gt;后者demo，大多参数都已hard code，用户仅需调整width、height、color_space信息即可，阅读起来比较easy。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　但是存在一个问题，默认输入/输出文件是stdin/stdout，这怎么能行？因此修改了一版来方便大家使用。已上传至&lt;span&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/Dreaming-in-Gottingen/h264_tools/tree/main/x264_demo&quot; target=&quot;_blank&quot;&gt;&lt;span&gt;这儿&lt;/span&gt;&lt;/a&gt;&lt;/strong&gt;&lt;/span&gt;。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;span&gt;　　修改部分需要做几点说明：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;1. sps/pps头补加方式：param.&lt;/span&gt;&lt;/strong&gt;&lt;span class=&quot;pl-smi&quot;&gt;&lt;strong&gt;&lt;span&gt;b_repeat_headers&lt;/span&gt;&lt;/strong&gt;&lt;span class=&quot;pl-c1&quot;&gt;&lt;br/&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　原生方式，在每个关键帧前编码器都会自动增加该头信息（因为设置值为1）。而实际上，一般编码参数配置了后（不需送yuv帧），&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;就可以出该csd（Codec Specific Data，对于h264为sps/pps）数据了，不需每个关键帧前都加该头信息，因此我将该值修改为了0。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;2. 基于1的修改，需要增加特定接口获得csd数据。&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　该特定接口函数为x264_encoder_headers(h, &amp;amp;nal, &amp;amp;i_nal)，打开编码器后，直接调用该接口就可以获得csd数据。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;针对该接口，需要补充说明一点，函数返回后i_nal值代表多少个nalu单元，这里的值是3，即SPS+PPS+SEI共三种类型。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;span&gt;3. profile级别设定：&lt;span class=&quot;pl-c1&quot;&gt;x264_param_apply_profile&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;pl-c1&quot;&gt;　　原生profile为“high”，其实我比较排斥B帧，因此修改为了baseline，因为规范中只有该profile不带B帧。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span class=&quot;pl-c1&quot;&gt;4. 固定关键帧间隔 &lt;span&gt;or&lt;/span&gt; 根据场景自动生成&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;pl-c1&quot;&gt;　　原生方式为根据场景变换来生成一个关键帧，因此什么时候来KeyFrame是不确定的。其实，这种方式有其很强的合理性。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;span class=&quot;pl-c1&quot;&gt;　　什么场景使用x264编码器？一般是视频剪辑，&lt;/span&gt;&lt;span class=&quot;pl-c1&quot;&gt;而不是像具体手持设备实时编码场景（场景画面变化是物理连续、渐进的），&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;pl-c1&quot;&gt;　　因此，常常会出现场景切换，这个时候最合理的方案是切换后的第一帧，编码为关键帧，当然前提条件是需要一定算法去检测到场景变化了！&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;pl-c1&quot;&gt;　　而我的需求是：需要出固定关键帧间隔！怎么做呢？编码参数进行如下配置：&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;32&quot;&gt;
&lt;pre&gt;
&lt;span&gt;1&lt;/span&gt; param.i_keyint_max = &lt;span&gt;25&lt;/span&gt;&lt;span&gt;;
&lt;/span&gt;&lt;span&gt;2&lt;/span&gt; 
&lt;span&gt;3&lt;/span&gt; param.i_keyint_min = &lt;span&gt;25&lt;/span&gt;;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span class=&quot;pl-smi&quot;&gt;　　然而，这样做起作用了吗？&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;pl-smi&quot;&gt;　　答案可能不是那么干脆利索，不能简单用“是”或“否”来回答，只能用“几乎是”，呵呵。。。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;pl-smi&quot;&gt;　　详细说来，如果图像帧序列画风比较平稳，没有大变天，那么就会按照25的关键帧间隔编码；&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;pl-smi&quot;&gt;　　而如果遇到画风大变，就会智能地编出关键帧，然后以该帧为起点再按25的关键帧间隔出帧，直到下一次画风大变。&lt;/span&gt;&lt;/p&gt;
</description>
<pubDate>Fri, 25 Dec 2020 16:08:00 +0000</pubDate>
<dc:creator>OnlyTime_唯有时光</dc:creator>
<og:description>x264编码器，提供了两个demo来验证编码功能：一个是大而全的x264.c，另外一个是简洁版的example.c。 其中，前者demo，可以配置很多编码参数，但太冗长繁杂，对初学者不太友好。 后者d</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/Dreaming-in-Gottingen/p/14191229.html</dc:identifier>
</item>
<item>
<title>Kafka超详细学习笔记【概念理解，安装配置】 - 天乔巴夏丶</title>
<link>http://www.cnblogs.com/summerday152/p/14191221.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/summerday152/p/14191221.html</guid>
<description>&lt;blockquote readability=&quot;1.8706896551724&quot;&gt;
&lt;p&gt;官方文档：&lt;a href=&quot;http://kafka.apache.org/23/documentation.html#introduction&quot; target=&quot;_blank&quot;&gt;http://kafka.apache.org/23/documentation.html#introduction&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;中文文档：&lt;a href=&quot;https://kafka.apachecn.org/&quot; target=&quot;_blank&quot;&gt;https://kafka.apachecn.org/&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;本篇要点&quot;&gt;本篇要点&lt;/h2&gt;
&lt;ol&gt;&lt;li&gt;介绍kafka的特性、概念、API及专业术语。&lt;/li&gt;
&lt;li&gt;介绍Windows环境下kafka的安装配置，启动测试。&lt;/li&gt;
&lt;li&gt;Java客户端连接kafka的案例演示。&lt;/li&gt;
&lt;/ol&gt;&lt;h2 id=&quot;kafka介绍&quot;&gt;Kafka介绍&lt;/h2&gt;
&lt;p&gt;Apache Kafka 是一个分布式流处理平台：&lt;code&gt;distributed streaming platform&lt;/code&gt;。&lt;/p&gt;
&lt;h3 id=&quot;作为流处理平台的三种特性&quot;&gt;作为流处理平台的三种特性&lt;/h3&gt;
&lt;ol&gt;&lt;li&gt;可发布和订阅消息（流），这与消息队列或企业消息系统类似。&lt;/li&gt;
&lt;li&gt;以容错（故障转移）的方式存储消息（流）。&lt;/li&gt;
&lt;li&gt;提供实时的流处理。&lt;/li&gt;
&lt;/ol&gt;&lt;h3 id=&quot;主要应用&quot;&gt;主要应用&lt;/h3&gt;
&lt;p&gt;kafka主要应用于两大类应用：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;构建实时的流数据通道，可靠地获取系统和应用程序之间的数据。&lt;/li&gt;
&lt;li&gt;构建实时流的应用程序，对数据流进行转换或反应。&lt;/li&gt;
&lt;/ol&gt;&lt;h3 id=&quot;四个核心api&quot;&gt;四个核心API&lt;/h3&gt;
&lt;ol&gt;&lt;li&gt;Producer API：发布消息到一个或多个topic主题上。&lt;/li&gt;
&lt;li&gt;Consumer API：订阅一个或多个topic，处理产生的消息。&lt;/li&gt;
&lt;li&gt;Streams API：流处理器，从一个或多个topic消费输入流，并产生一个输出流到一个或多个输出topic，有效地将输入流转换到输出流。&lt;/li&gt;
&lt;li&gt;Connector API：可构建或运行可重用地生产者或消费者，将topic连接到现有地应用程序或数据系统。&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1771072/202012/1771072-20201226000139657-373886892.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h3 id=&quot;基本术语&quot;&gt;基本术语&lt;/h3&gt;
&lt;p&gt;Topic：kafka将消息分类，每一类的消息都有一个主题topic。&lt;/p&gt;
&lt;p&gt;Producer：生产者，发布消息的对象。&lt;/p&gt;
&lt;p&gt;Consumer：消费者，订阅消息的对象。&lt;/p&gt;
&lt;p&gt;Broker：代理，已发布的消息保存在一组服务器中，称之为kafka集群，集群中每个服务器都是一个代理(broker)。消费者可以订阅一个或多个主题，并从broker上拉取数据，从而消费这些已发布的消息。&lt;/p&gt;
&lt;p&gt;Partition：Topic物理上的分组，&lt;strong&gt;一个Topic可以分为多个partition，每个partition都是一个顺序的、不可变的消息队列，且可以持续添加&lt;/strong&gt;。Partition中的每条消息都会被分配一个有序的序列号，称为偏移量（offset），因此每个分区中偏移量都是唯一的。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1771072/202012/1771072-20201226000144668-1992046745.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;Consumer Group：每个Consumer属于一个特定的Consumer Group，这是kafka用来实现一个Topic消息的广播【发送给所有的consumer的&lt;strong&gt;发布订阅式&lt;/strong&gt;消息模型】和单播【发送给任意一个consumer&lt;strong&gt;队列&lt;/strong&gt;消息模型】的手段。一个topic可以有多个consumer group。&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;如果要实现广播，只要每个consumer有独立的consumer group就可以，此时就是发布订阅模型。&lt;/li&gt;
&lt;li&gt;如果要实现单播，只要所有的consumer在同一个consumer group中就可以，此时就是队列模型。&lt;/li&gt;
&lt;/ul&gt;&lt;blockquote readability=&quot;18&quot;&gt;
&lt;p&gt;&lt;strong&gt;关于Consumer group的补充&lt;/strong&gt;：一般来说，我们可以创建一些consumer group作为逻辑上的订阅者，每个组中包含数目不等的consumer，一个组内的多个消费者可以用来扩展性能和容错。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;关于partition分区的补充&lt;/strong&gt;：&lt;/p&gt;
&lt;p&gt;1、【负载均衡】处理更多的消息，不受单台服务器的限制。&lt;/p&gt;
&lt;p&gt;2、【顺序保证】kafka不能保证并行的时候消息的有序性，但是可以保证一个partition分区之中，消息只能由消费者组中的唯一一个消费者处理，以保证一个分区的消息先后顺序。&lt;/p&gt;
&lt;p&gt;如下图：2个kafka集群托管4个分区(p0-p3)，2个消费者组，组A有2个消费者实例，组B有4个消费者实例。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1771072/202012/1771072-20201226000205176-2118157738.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;关于偏移量的补充：kafka集群将会保持所有的消息，直到他们过期，无论他们是否被消费。当消费者消费消息时，偏移量offset将会线性增加，但是&lt;strong&gt;消费者其实可以控制实际的偏移量，可以重置偏移量为更早的位置，意为着重新读取消息&lt;/strong&gt;，且不会影响其他消费者对此log的处理。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1771072/202012/1771072-20201226000210300-164160335.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h2 id=&quot;快速开始&quot;&gt;快速开始&lt;/h2&gt;
&lt;h3 id=&quot;安装配置zookeeper&quot;&gt;安装配置Zookeeper&lt;/h3&gt;
&lt;p&gt;Kafka的安装配置启动需要依赖于Zookeeper，Zookeeper的安装配置可以参考我的前一篇文章。&lt;/p&gt;
&lt;p&gt;当然，其实你下载kafka之后，就自动已经集成了Zookeeper，你可以通过修改配置，启动内置的zookeeper。&lt;/p&gt;
&lt;blockquote readability=&quot;4.1830985915493&quot;&gt;
&lt;p&gt;关于使用内置的Zookeeper还是自己安装的Zookeeper的区别，可以看看这篇文章：&lt;a href=&quot;https://segmentfault.com/q/1010000021110446&quot; target=&quot;_blank&quot;&gt;https://segmentfault.com/q/1010000021110446&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&quot;下载kafka&quot;&gt;下载kafka&lt;/h3&gt;
&lt;p&gt;下载地址：&lt;a href=&quot;http://kafka.apache.org/downloads&quot; target=&quot;_blank&quot;&gt;http://kafka.apache.org/downloads&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;下载二进制版本【Binary downloads】，下载完成之后，解压到合适的目录下。&lt;/p&gt;
&lt;p&gt;笔者目录为：&lt;code&gt;D:\dev\kafka_2.11-2.3.1&lt;/code&gt;。&lt;/p&gt;
&lt;h3 id=&quot;配置文件&quot;&gt;配置文件&lt;/h3&gt;
&lt;p&gt;进入&lt;code&gt;config&lt;/code&gt;目录下，找到&lt;code&gt;server.properties&lt;/code&gt;文件并修改如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-properties&quot;&gt;log.dirs=D:\\dev\\kafka_2.11-2.3.1\\config\\kafka-logs
zookeeper.connect=localhost:2182 # 默认端口是2181，这里修改为2182
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;找到&lt;code&gt;zookeeper.properties&lt;/code&gt;文件，修改如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-properties&quot;&gt;dataDir=D:\\softs\\zookeeper-3.4.13\\datas 
dataLogDir=D:\\softs\\zookeeper-3.4.13\\logs
clientPort=2182
&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;windows的命令&quot;&gt;Windows的命令&lt;/h3&gt;
&lt;p&gt;在bin目录下存放着所有可以使用的命令行指令，Linux和Windows的存放目录需要注意：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1771072/202012/1771072-20201226000218781-2098268767.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h3 id=&quot;启动zookeeper&quot;&gt;启动Zookeeper&lt;/h3&gt;
&lt;pre&gt;
&lt;code class=&quot;language-shell&quot;&gt;D:\dev\kafka_2.11-2.3.1&amp;gt; .\bin\windows\zookeeper-server-start.bat .\config\zookeeper.properties
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1771072/202012/1771072-20201226000225846-32102130.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h3 id=&quot;启动kafka&quot;&gt;启动Kafka&lt;/h3&gt;
&lt;pre&gt;
&lt;code class=&quot;language-shell&quot;&gt;D:\dev\kafka_2.11-2.3.1&amp;gt; .\bin\windows\kafka-server-start.bat .\config\server.properties
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1771072/202012/1771072-20201226000230085-193293748.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h2 id=&quot;进行测试&quot;&gt;进行测试&lt;/h2&gt;
&lt;h3 id=&quot;创建topic&quot;&gt;创建topic&lt;/h3&gt;
&lt;p&gt;创建1个分区1个副本，topic为test-topic&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-shell&quot;&gt;D:\dev\kafka_2.11-2.3.1&amp;gt;.\bin\windows\kafka-topics.bat --create --zookeeper localhost:2182 --replication-factor 1 --partitions 1 --topic test-topic
Created topic test-topic.
&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;查看topic&quot;&gt;查看topic&lt;/h3&gt;
&lt;pre&gt;
&lt;code class=&quot;language-shell&quot;&gt;D:\dev\kafka_2.11-2.3.1&amp;gt;.\bin\windows\kafka-topics.bat --list --zookeeper localhost:2182
test-topic
&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;生产者&quot;&gt;生产者&lt;/h3&gt;
&lt;pre&gt;
&lt;code class=&quot;language-shell&quot;&gt;D:\dev\kafka_2.11-2.3.1&amp;gt;.\bin\windows\kafka-console-producer.bat --broker-list localhost:9092 --topic test-topic
&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;消费者&quot;&gt;消费者&lt;/h3&gt;
&lt;pre&gt;
&lt;code class=&quot;language-shell&quot;&gt;D:\dev\kafka_2.11-2.3.1&amp;gt;.\bin\windows\kafka-console-consumer.bat --bootstrap-server localhost:9092 --topic test-topic --from-beginning
&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;生产者与消费者消息传递&quot;&gt;生产者与消费者消息传递&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1771072/202012/1771072-20201226000235352-2137046562.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h3 id=&quot;删除topic&quot;&gt;删除topic&lt;/h3&gt;
&lt;p&gt;如果kafka启动时加载的配置文件中 server.properties 中没有配置delete.topic.enable=true，则此删除非真正删除，而是仅仅将topic标记为marked for deletion&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-shell&quot;&gt;D:\dev\kafka_2.11-2.3.1&amp;gt;.\bin\windows\kafka-topics.bat --delete --zookeeper localhost:2182 --topic test-topic

Topic test-topic is marked for deletion.
Note: This will have no impact if delete.topic.enable is not set to true.
&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;登录内置的zookeeper客户端&quot;&gt;登录内置的zookeeper客户端&lt;/h3&gt;
&lt;pre&gt;
&lt;code class=&quot;language-shell&quot;&gt;D:\dev\kafka_2.11-2.3.1\bin\windows&amp;gt;zookeeper-shell.bat localhost:2182

Connecting to localhost:2182
Welcome to ZooKeeper!
JLine support is disabled
&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;物理删除topic&quot;&gt;物理删除topic&lt;/h3&gt;
&lt;pre&gt;
&lt;code class=&quot;language-shell&quot;&gt;ls /brokers
[ids, topics, seqid]
ls /brokers/topics
[test, test-topic, __consumer_offsets]
rmr /brokers/topics/test-topic # 物理删除 test-topic 
ls /brokers/topics
[test, __consumer_offsets]
&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;java客户端使用&quot;&gt;Java客户端使用&lt;/h2&gt;
&lt;h3 id=&quot;引入依赖&quot;&gt;引入依赖&lt;/h3&gt;
&lt;pre&gt;
&lt;code class=&quot;language-xml&quot;&gt;        &amp;lt;dependency&amp;gt;
            &amp;lt;groupId&amp;gt;org.apache.kafka&amp;lt;/groupId&amp;gt;
            &amp;lt;artifactId&amp;gt;kafka-clients&amp;lt;/artifactId&amp;gt;
            &amp;lt;version&amp;gt;2.6.0&amp;lt;/version&amp;gt;
        &amp;lt;/dependency&amp;gt;
&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;生产者-1&quot;&gt;生产者&lt;/h3&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;public class ProducerExample {

    public static void main(String[] args) {
        Map&amp;lt;String, Object&amp;gt; props = new HashMap&amp;lt;&amp;gt;();
        props.put(&quot;zk.connect&quot;, &quot;localhost:2182&quot;);
        props.put(&quot;bootstrap.servers&quot;, &quot;localhost:9092&quot;);
        props.put(&quot;acks&quot;, &quot;all&quot;); 
        props.put(&quot;retries&quot;, 0);
        props.put(&quot;batch.size&quot;, 16384);
        props.put(&quot;linger.ms&quot;, 1);
        props.put(&quot;buffer.memory&quot;, 33554432);
        props.put(&quot;key.serializer&quot;, &quot;org.apache.kafka.common.serialization.StringSerializer&quot;);
        props.put(&quot;value.serializer&quot;, &quot;org.apache.kafka.common.serialization.StringSerializer&quot;);
        Producer&amp;lt;String, String&amp;gt; producer = new KafkaProducer&amp;lt;&amp;gt;(props);
        String topic = &quot;test&quot;;
        for (int i = 1; i &amp;lt;= 100; i++) {
            // send方法是异步的 ， 返回Future对象，如果调用get()，将阻塞，直到相关请求完成并返回消息的metadata或抛出异常
            producer.send(new ProducerRecord&amp;lt;&amp;gt;(topic, &quot;key&quot; + i, &quot;msg&quot; + i * 100));
        }
        // 生产者的传冲空间池保留尚未发送到服务器的消息，后台I/O线程负责将这些消息转换程请求发送到集群
        // 如果使用后不关闭生产者，将会丢失这些消息。
        producer.close();
    }

}
&lt;/code&gt;
&lt;/pre&gt;
&lt;ul readability=&quot;10.5&quot;&gt;&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;zk.connect：设置zookeeper的地址。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;bootstrap.servers：用于建立与 kafka 集群连接的 host/port 组。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;acks：判断是不是成功发送，指定&lt;code&gt;all&lt;/code&gt;将会阻塞消息，这种设置性能最低，但是是最可靠的。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;retries：如果请求失败，生产者会自动重试，我们指定是0次，如果启用重试，则会有重复消息的可能性。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;1&quot;&gt;
&lt;p&gt;batch.size：(生产者)缓存每个分区未发送的消息。缓存的大小是通过 &lt;code&gt;batch.size&lt;/code&gt; 配置指定的。值较大的话将会产生更大的批。并需要更多的内存（因为每个“活跃”的分区都有1个缓冲区）。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;2&quot;&gt;
&lt;p&gt;linger.ms：默认缓冲可立即发送，即便缓冲空间还没有满，但是，如果你想减少请求的数量，可以设置linger.ms大于0。这将指示生产者发送请求之前等待一段时间，希望更多的消息填补到未满的批中。这类似于TCP的算法，例如上面的代码段，可能100条消息在一个请求发送，因为我们设置了linger(逗留)时间为1毫秒，然后，如果我们没有填满缓冲区，这个设置将增加1毫秒的延迟请求以等待更多的消息。需要注意的是，在高负载下，相近的时间一般也会组成批，即使是 &lt;code&gt;linger.ms=0&lt;/code&gt;。在不处于高负载的情况下，如果设置比0大，以少量的延迟代价换取更少的，更有效的请求。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;1&quot;&gt;
&lt;p&gt;buffer.memory：控制生产者可用的缓存总量，如果消息发送速度比其传输到服务器的快，将会耗尽这个缓存空间。当缓存空间耗尽，其他发送调用将被阻塞，阻塞时间的阈值通过&lt;code&gt;max.block.ms&lt;/code&gt;设定，之后它将抛出一个TimeoutException。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;key.serializer：用于序列化。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;value.serializer：用于序列化。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;h3 id=&quot;消费者-1&quot;&gt;消费者&lt;/h3&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;public class ConsumerSample {

    public static void main(String[] args) {
        String topic = &quot;test&quot;;// topic name

        Properties props = new Properties();
        props.put(&quot;bootstrap.servers&quot;, &quot;localhost:9092&quot;);
        props.put(&quot;group.id&quot;, &quot;testGroup1&quot;);
        props.put(&quot;enable.auto.commit&quot;, &quot;true&quot;);
        props.put(&quot;auto.commit.interval.ms&quot;, &quot;1000&quot;); 
        props.put(&quot;key.deserializer&quot;, &quot;org.apache.kafka.common.serialization.StringDeserializer&quot;);
        props.put(&quot;value.deserializer&quot;, &quot;org.apache.kafka.common.serialization.StringDeserializer&quot;);
        Consumer&amp;lt;String, String&amp;gt; consumer = new KafkaConsumer(props);
        // 订阅多个主题
        consumer.subscribe(Arrays.asList(topic));
        while (true) {
            // 订阅一组topic之后，调用poll时，消费者将自动加入到组中。
            // 只要持续调用poll，消费者将一直保持可用，并继续从分配的分区中接收消息。
            // 消费者向服务器定时发送心跳，如果在session.timeout.ms配置的时间内无法发送心跳，被视为死亡，分区将重新分配
            ConsumerRecords&amp;lt;String, String&amp;gt; records = consumer.poll(100);
            for (ConsumerRecord&amp;lt;String, String&amp;gt; record : records)
                System.out.printf(&quot;*****************partition = %d, offset = %d, key = %s, value = %s%n&quot;, record.partition(), record.offset(), record.key(), record.value());
        }
    }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;ul&gt;&lt;li&gt;bootstrap.servers：用于建立与 kafka 集群连接的 host/port 组。&lt;/li&gt;
&lt;li&gt;group.id：消费者的组名，组名相同的消费者被视为同一个消费组。&lt;/li&gt;
&lt;li&gt;enable.auto.commit：设置Consumer 的 offset 是否自动提交。&lt;/li&gt;
&lt;li&gt;auto.commit.interval.ms：上面属性设置为true，由本属性设置自动提交 offset 到 zookeeper 的时间间隔，时间是毫秒&lt;/li&gt;
&lt;li&gt;key.deserializer：用于反序列化。&lt;/li&gt;
&lt;li&gt;value.deserializer：用于反序列化。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;Kafka通过进程池瓜分消息并处理消息，这些进程可以在同一台机器运行，也可以分布到多台机器上，以增加可扩展型和容错性，相同的&lt;code&gt;group.id&lt;/code&gt;的消费者将视为同一个消费者组。&lt;/p&gt;
&lt;p&gt;组中的每个消费者都通过&lt;code&gt;subscribe API&lt;/code&gt;动态的订阅一个topic列表。kafka将已订阅topic的消息发送到每个消费者组中。并通过平衡分区在消费者分组中所有成员之间来达到平均。因此每个分区恰好地分配1个消费者（一个消费者组中）。所有如果一个topic有4个分区，并且一个消费者分组有只有2个消费者。那么每个消费者将消费2个分区。&lt;/p&gt;
&lt;p&gt;消费者组的成员是动态维护的：如果一个消费者故障。分配给它的分区将重新分配给同一个分组中其他的消费者。同样的，如果一个新的消费者加入到分组，将从现有消费者中移一个给它。这被称为&lt;code&gt;重新平衡分组&lt;/code&gt;。&lt;/p&gt;
&lt;h3 id=&quot;启动zookeeper和kafka&quot;&gt;启动Zookeeper和kafka&lt;/h3&gt;
&lt;p&gt;创建topic&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-shell&quot;&gt;D:\dev\kafka_2.11-2.3.1&amp;gt;.\bin\windows\kafka-topics.bat --create --zookeeper localhost:2182 --replication-factor 1 --partitions 1 --topic test
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;启动zookeeper&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-shell&quot;&gt;D:\dev\kafka_2.11-2.3.1&amp;gt;.\bin\windows\zookeeper-server-start.bat .\config\zookeeper.properties
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;启动kafka&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-shell&quot;&gt;D:\dev\kafka_2.11-2.3.1&amp;gt;.\bin\windows\kafka-server-start.bat .\config\server.properties
&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;测试&quot;&gt;测试&lt;/h3&gt;
&lt;p&gt;先启动消费者ConsumerExample，再启动生产者ProducerExample，观察控制台。&lt;/p&gt;
&lt;h2 id=&quot;总结&quot;&gt;总结&lt;/h2&gt;
&lt;ul&gt;&lt;li&gt;kafka作为一个消息系统，它设计了partition分区，提供了负载均衡能力，保证了消息分区内的顺序。&lt;/li&gt;
&lt;li&gt;kafka拥有消费者组的概念，很好地实现发布订阅和队列式的消息模型。&lt;/li&gt;
&lt;li&gt;kafka作为一个存储系统，高性能，低延迟。&lt;/li&gt;
&lt;li&gt;kafka能够提供实时的流处理，提供强大的StreamsAPI，而不是简单的读写和存储。&lt;/li&gt;
&lt;/ul&gt;&lt;h2 id=&quot;参考阅读&quot;&gt;参考阅读&lt;/h2&gt;
</description>
<pubDate>Fri, 25 Dec 2020 16:04:00 +0000</pubDate>
<dc:creator>天乔巴夏丶</dc:creator>
<og:description>官方文档：http://kafka.apache.org/23/documentation.html#introduction 中文文档：https://kafka.apachecn.org/ 本篇要</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/summerday152/p/14191221.html</dc:identifier>
</item>
<item>
<title>容器编排系统K8s之PV、PVC、SC资源 - Linux-1874</title>
<link>http://www.cnblogs.com/qiuhom-1874/p/14188621.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/qiuhom-1874/p/14188621.html</guid>
<description>&lt;p&gt;　　前文我们聊到了k8s中给Pod添加存储卷相关话题，回顾请参考：&lt;a href=&quot;https://www.cnblogs.com/qiuhom-1874/p/14180752.html&quot; target=&quot;_blank&quot;&gt;https://www.cnblogs.com/qiuhom-1874/p/14180752.html&lt;/a&gt;；今天我们来聊一下持久存储卷相关话题；&lt;/p&gt;
&lt;p&gt;　　volume的基础使用，需要我们用户手动来向不同类型存储接口传递不同的参数，从而实现把外部存储映射到k8s上的一个volume对象，使得pod才能正常的挂载对应的存储卷，对应pod里的容器才能正常使用；这种使用方式的前提是用户必须了解对应的存储系统，了解对应类型的存储接口，以及相关参数；这使得用户在k8s上使用存储卷变得有些复杂；为了简化这一过程，在k8s上使用pv和pvc资源来把对应底层存储接口给隐藏了，用户使用存储卷不再关心底层存储系统接口；不管底层是那种类型的存储，用户只需面对一个pvc接口即可；&lt;/p&gt;
&lt;p&gt;　　PV、PVC和K8s集群以及pod的关系&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1503305/202012/1503305-20201225143626594-1079301982.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　提示：用户在创建pod时使用存储卷只需要关心对应名称空间的pvc对象；而对应pv是需要集群管理管理员定义；后端存储是专门的存储管理员负责管理；pv是k8s上的一种标准资源，全称叫做PersistentVolume翻译成中文就是持久存储卷；它主要作用是把后端存储中的某个逻辑单元，映射为k8s上的pv资源；pv是集群级别的资源；任意名称空间都可以直接关联某一个pv；关联pv的过程我们叫做绑定pv；而对应名称空间关联某一pv需要使用pvc资源来定义；pvc全称PersistentVolumeClaim的缩写，意思就是持久存储卷申请；在一个名称空间下创建一个pvc就是把对应名称空间同集群上的某一pv做绑定；一旦一个名称空间绑定了一个pv后，对应的pv就会从available状态转变成bond状态，其他名称空间将不能再使用，只有对应pv是available状态才能正常的被其他名称空间关联绑定；简单讲pvc和pv的关系是一一对应的，一个pv只能对应一个pvc；至于同一名称空间下的多个pod是否能够同时使用一个PVC取决pv是否允许多路读写，对应pv是否支持多路读写取决后端存储系统；不同类型的存储系统，对应访问模式也有所不同。访问模式有三种，单路读写(ReadWriteOnce简称RWO)，多路读写(ReadWriteMany简称RWX)，多路只读(ReadOnlyMany简称ROX)；&lt;/p&gt;
&lt;p&gt;　　示例：pv资源创建&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;37&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
[root@master01 ~]# cat pv-v1-demo.yaml 
apiVersion: v1
kind: PersistentVolume
metadata:
  name: nfs-pv-v1
  labels:
    storsystem: nfs-v1
    rel: stable
spec:
  capacity:
    storage: 1Gi
  volumeMode: Filesystem
  accessModes: [&quot;ReadWriteOnce&quot;,&quot;ReadWriteMany&quot;,&quot;ReadOnlyMany&quot;]
  persistentVolumeReclaimPolicy: Retain
  mountOptions:
  - hard
  - nfsvers=4.1
  nfs:
    path: /data/v1
    server: 192.168.0.99
[root@master01 ~]# 
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　提示：pv是k8s的标准资源，其群组版本为v1,类型为PersistentVolume；spec.capacity.storage字段用来描述pv的存储容量；volumeMode用来描述对应存储系统提供的存储卷类型接口，一般存储卷类型接口有两种，分别是文件系统接口和块设备接口；accessModes用来描述pv的访问模式；presistentVolumeReclaimPolicy字段用来描述存储卷回收策略，持久卷回收策略有3中，一种是Delete，表示当pvc删除以后，对应pv也随之删除；第二种是Recycle,表示当pvc删除以后，对应pv的数据也随之被删除；第三种是Retain表示当pvc被删除以后，pv原封动，即pv也在，对应数据也在；mountOptions字段用来指定挂载选项；nfs表示后端存储为nfs，对于不同类型的存储，对应的要传递的参数各不相同，对于nfs这种类型的存储，我们只需要指定其nfs服务器地址以及对应共享出来的文件路径；以上配置就表示把nfs上的/data/v1目录映射到k8s上的pv，对应pv的名称为nfs-pv-v1；这里需要注意一点，在创建pv时，对应后端存储应该提前准备好；&lt;/p&gt;
&lt;p&gt;　　应用配置清单&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;39&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
[root@master01 ~]# kubectl apply -f pv-v1-demo.yaml
persistentvolume/nfs-pv-v1 created
[root@master01 ~]# kubectl get pv
NAME        CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS      CLAIM   STORAGECLASS   REASON   AGE
nfs-pv-v1   1Gi        RWO,ROX,RWX    Retain           Available                                   4s
[root@master01 ~]# kubectl describe pv nfs-pv-v1
Name:            nfs-pv-v1
Labels:          rel=stable
                 storsystem=nfs-v1
Annotations:     &amp;lt;none&amp;gt;
Finalizers:      [kubernetes.io/pv-protection]
StorageClass:    
Status:          Available
Claim:           
Reclaim Policy:  Retain
Access Modes:    RWO,ROX,RWX
VolumeMode:      Filesystem
Capacity:        1Gi
Node Affinity:   &amp;lt;none&amp;gt;
Message:         
Source:
    Type:      NFS (an NFS mount that lasts the lifetime of a pod)
    Server:    192.168.0.99
    Path:      /data/v1
    ReadOnly:  false
Events:        &amp;lt;none&amp;gt;
[root@master01 ~]# 
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　提示：在pv的详细信息中能够看到，当前pv的状态为available，pv对应后端的存储是nfs，对应存储的ip地址为192.168.0.99，当前pv对应后端存储的逻辑单元就是/data/v1；&lt;/p&gt;
&lt;p&gt;　　示例：创建pvc&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;35&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
[root@master01 ~]# cat pvc-v1-demo.yaml 
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: pvc-nfs-pv-v1
  namespace: default
  labels:
    storsystem: nfs-v1
spec:
  accessModes:
    - ReadWriteMany
  volumeMode: Filesystem
  resources:
    requests:
      storage: 500Mi
  selector:
    matchLabels:
      storsystem: nfs-v1
      rel: stable
[root@master01 ~]# 
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　提示：pvc也是k8s上的标准资源，对应的群组版本为v1,类型为PersistentVolumeClaim；其中spec.accessModes字段是用来指定其pvc的访问模式，一般这个模式是被pv的accessModes包含，也就说pvc的访问模式必须是pv的子集，即等于小于pv的访问模式；resources用来描述对应pvc的存储空间限制，requests用来描述对应pvc最小容量限制，limits用来描述最大容量限制；selector用来定义标签选择器，主要作用过滤符合对应标签的pv；如果不定义标签选择器，它会在所有available状态的pv中，通过其容量大小限制以及访问模式去匹配一个最佳的pv进行关联；&lt;/p&gt;
&lt;p&gt;　　应用配置清单&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;41&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
[root@master01 ~]# kubectl apply -f pvc-v1-demo.yaml 
persistentvolumeclaim/pvc-nfs-pv-v1 created
[root@master01 ~]# kubectl get pvc
NAME            STATUS   VOLUME      CAPACITY   ACCESS MODES   STORAGECLASS   AGE
pvc-nfs-pv-v1   Bound    nfs-pv-v1   1Gi        RWO,ROX,RWX                   8s
[root@master01 ~]# kubectl describe pvc pvc-nfs-pv-v1
Name:          pvc-nfs-pv-v1
Namespace:     default
StorageClass:  
Status:        Bound
Volume:        nfs-pv-v1
Labels:        storsystem=nfs-v1
Annotations:   pv.kubernetes.io/bind-completed: yes
               pv.kubernetes.io/bound-by-controller: yes
Finalizers:    [kubernetes.io/pvc-protection]
Capacity:      1Gi
Access Modes:  RWO,ROX,RWX
VolumeMode:    Filesystem
Used By:       &amp;lt;none&amp;gt;
Events:        &amp;lt;none&amp;gt;
[root@master01 ~]# kubectl get pv
NAME        CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS   CLAIM                   STORAGECLASS   REASON   AGE
nfs-pv-v1   1Gi        RWO,ROX,RWX    Retain           Bound    default/pvc-nfs-pv-v1                           19m
[root@master01 ~]# 
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　提示：这里显示pvc的大小是pvc最大容量显示，默认不限制最大容量就是其pv的最大容量；从上面的显示可以看到对应pv被pvc绑定以后，其状态就变成了bound；&lt;/p&gt;
&lt;p&gt;　　示例：创建pod关联pvc，并在其pod容器里挂载pvc&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;35&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
[root@master01 ~]# cat redis-demo.yaml
apiVersion: v1
kind: Pod
metadata:
  name: redis-demo
  labels:
    app: redis
spec:
  containers:
  - name: redis
    image: redis:alpine
    volumeMounts:
    - mountPath: /data
      name: redis-data
  volumes:
  - name: redis-data
    persistentVolumeClaim:
      claimName: pvc-nfs-pv-v1
[root@master01 ~]# 
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　提示：在pod里关联pvc，只需要指定后端存储类型为persistentVolumeClaim，然后指定对应的pvc名称；&lt;/p&gt;
&lt;p&gt;　　应用资源清单&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;37&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
[root@master01 ~]# kubectl apply -f redis-demo.yaml
pod/redis-demo created
[root@master01 ~]# kubectl get pod
NAME         READY   STATUS              RESTARTS   AGE
redis-demo   0/1     ContainerCreating   0          7s
[root@master01 ~]# kubectl get pod
NAME         READY   STATUS    RESTARTS   AGE
redis-demo   1/1     Running   0          27s
[root@master01 ~]# kubectl describe pod redis-demo
Name:         redis-demo
Namespace:    default
Priority:     0
Node:         node03.k8s.org/192.168.0.46
Start Time:   Fri, 25 Dec 2020 21:55:41 +0800
Labels:       app=redis
Annotations:  &amp;lt;none&amp;gt;
Status:       Running
IP:           10.244.3.105
IPs:
  IP:  10.244.3.105
Containers:
  redis:
    Container ID:   docker://8e8965f52fd0144f8d6ce68185209114163a42f8437d7d845d431614f3d6dd05
    Image:          redis:alpine
    Image ID:       docker-pullable://redis@sha256:68d4030e07912c418332ba6fdab4ac69f0293d9b1daaed4f1f77bdeb0a5eb048
    Port:           &amp;lt;none&amp;gt;
    Host Port:      &amp;lt;none&amp;gt;
    State:          Running
      Started:      Fri, 25 Dec 2020 21:55:48 +0800
    Ready:          True
    Restart Count:  0
    Environment:    &amp;lt;none&amp;gt;
    Mounts:
      /data from redis-data (rw)
      /var/run/secrets/kubernetes.io/serviceaccount from default-token-xvd4c (ro)
Conditions:
  Type              Status
  Initialized       True 
  Ready             True 
  ContainersReady   True 
  PodScheduled      True 
Volumes:
  redis-data:
    Type:       PersistentVolumeClaim (a reference to a PersistentVolumeClaim in the same namespace)
    ClaimName:  pvc-nfs-pv-v1
    ReadOnly:   false
  default-token-xvd4c:
    Type:        Secret (a volume populated by a Secret)
    SecretName:  default-token-xvd4c
    Optional:    false
QoS Class:       BestEffort
Node-Selectors:  &amp;lt;none&amp;gt;
Tolerations:     node.kubernetes.io/not-ready:NoExecute op=Exists for 300s
                 node.kubernetes.io/unreachable:NoExecute op=Exists for 300s
Events:
  Type    Reason     Age   From               Message
  ----    ------     ----  ----               -------
  Normal  Scheduled  37s   default-scheduler  Successfully assigned default/redis-demo to node03.k8s.org
  Normal  Pulling    36s   kubelet            Pulling image &quot;redis:alpine&quot;
  Normal  Pulled     30s   kubelet            Successfully pulled image &quot;redis:alpine&quot; in 5.284107704s
  Normal  Created    30s   kubelet            Created container redis
  Normal  Started    30s   kubelet            Started container redis
[root@master01 ~]# 
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　提示：可以看到对应pod已经正常运行起来；从详细信息中可以看到对应pod使用的volumes类型为PersistentVolumeClaim，对应名称为pvc-nfs-pv-v1；对应容器以读写方式挂载了对应存储卷；&lt;/p&gt;
&lt;p&gt;　　测试：在redis-demo上产生数据，看看是否能够正常保存到nfs服务器上？&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;35&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
[root@master01 ~]# kubectl get pod
NAME         READY   STATUS    RESTARTS   AGE
redis-demo   1/1     Running   0          5m28s
[root@master01 ~]# kubectl exec -it redis-demo -- /bin/sh
/data # redis-cli 
127.0.0.1:6379&amp;gt; set mykey &quot;this is test key &quot;
OK
127.0.0.1:6379&amp;gt; get mykey
&quot;this is test key &quot;
127.0.0.1:6379&amp;gt; BGSAVE
Background saving started
127.0.0.1:6379&amp;gt; exit
/data # ls
dump.rdb
/data # 
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　在nfs服务器上查看对应目录下是否有dump.rdb文件产生？&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;33&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
[root@docker_registry ~]# ll /data/v1
total 4
-rw-r--r-- 1 polkitd qiuhom 122 Dec 25 22:02 dump.rdb
[root@docker_registry ~]# 
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　提示：可以看到，redis上产生的快照文件在nfs服务器上有对应的文件存在；&lt;/p&gt;
&lt;p&gt;　　测试：删除pod，看看对应文件是否还在？&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;35&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
[root@master01 ~]# kubectl delete -f redis-demo.yaml 
pod &quot;redis-demo&quot; deleted
[root@master01 ~]# kubectl get pods
No resources found in default namespace.
[root@master01 ~]# ssh 192.168.0.99
The authenticity of host '192.168.0.99 (192.168.0.99)' can't be established.
ECDSA key fingerprint is SHA256:hQoossQnTJMXB0+DxJdTt6DMHuPFLDd5084tHyJ7920.
ECDSA key fingerprint is MD5:ef:61:b6:ee:76:46:9d:0e:38:b6:b5:dd:11:66:23:26.
Are you sure you want to continue connecting (yes/no)? yes
Warning: Permanently added '192.168.0.99' (ECDSA) to the list of known hosts.
root@192.168.0.99's password: 
Last login: Fri Dec 25 20:13:05 2020 from 192.168.0.232
[root@docker_registry ~]# ll /data/v1
total 4
-rw-r--r-- 1 polkitd qiuhom 122 Dec 25 22:05 dump.rdb
[root@docker_registry ~]# exit
logout
Connection to 192.168.0.99 closed.
[root@master01 ~]# 
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　提示：可以看到删除了pod对应快照文件在nfs服务器还是存在；&lt;/p&gt;
&lt;p&gt;　　绑定节点，重新新建pod，看看对应是否能够自动应用快照中的数据？&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;35&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
[root@master01 ~]# cat redis-demo.yaml
apiVersion: v1
kind: Pod
metadata:
  name: redis-demo
  labels:
    app: redis
spec:
  nodeName: node01.k8s.org
  containers:
  - name: redis
    image: redis:alpine
    volumeMounts:
    - mountPath: /data
      name: redis-data
  volumes:
  - name: redis-data
    persistentVolumeClaim:
      claimName: pvc-nfs-pv-v1
[root@master01 ~]# kubectl apply -f redis-demo.yaml
pod/redis-demo created
[root@master01 ~]# kubectl get pod -o wide
NAME         READY   STATUS              RESTARTS   AGE   IP       NODE             NOMINATED NODE   READINESS GATES
redis-demo   0/1     ContainerCreating   0          8s    &amp;lt;none&amp;gt;   node01.k8s.org   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
[root@master01 ~]# kubectl get pod -o wide
NAME         READY   STATUS    RESTARTS   AGE   IP            NODE             NOMINATED NODE   READINESS GATES
redis-demo   1/1     Running   0          21s   10.244.1.88   node01.k8s.org   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
[root@master01 ~]# 
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　提示：可以看到新建的pod被调度到node01上了；&lt;/p&gt;
&lt;p&gt;　　进入对应pod，看看是否应用了其快照文件中的数据？对应key是否能够被应用到内存？&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;34&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
[root@master01 ~]# kubectl get pods
NAME         READY   STATUS    RESTARTS   AGE
redis-demo   1/1     Running   0          2m39s
[root@master01 ~]# kubectl exec -it redis-demo -- /bin/sh
/data # redis-cli 
127.0.0.1:6379&amp;gt; get mykey
&quot;this is test key &quot;
127.0.0.1:6379&amp;gt; exit
/data # ls 
dump.rdb
/data # exit
[root@master01 ~]# 
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　提示：可以看到新建的pod能够正常读取到nfs上的快照文件并应用到内存中；&lt;/p&gt;
&lt;p&gt;　　删除pvc，看看对应pv是否被删除？&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1503305/202012/1503305-20201225221945958-384705616.gif&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　提示：可以看到在没有删除pod的情况下，对应删除操作被阻塞了；&lt;/p&gt;
&lt;p&gt;　　查看pvc状态&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;43&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
[root@master01 ~]# kubectl delete pvc pvc-nfs-pv-v1
persistentvolumeclaim &quot;pvc-nfs-pv-v1&quot; deleted
^C
[root@master01 ~]# kubectl get pvc
NAME            STATUS        VOLUME      CAPACITY   ACCESS MODES   STORAGECLASS   AGE
pvc-nfs-pv-v1   Terminating   nfs-pv-v1   1Gi        RWO,ROX,RWX                   34m
[root@master01 ~]# kubectl get pvc
NAME            STATUS        VOLUME      CAPACITY   ACCESS MODES   STORAGECLASS   AGE
pvc-nfs-pv-v1   Terminating   nfs-pv-v1   1Gi        RWO,ROX,RWX                   34m
[root@master01 ~]# kubectl get pvc
NAME            STATUS        VOLUME      CAPACITY   ACCESS MODES   STORAGECLASS   AGE
pvc-nfs-pv-v1   Terminating   nfs-pv-v1   1Gi        RWO,ROX,RWX                   34m
[root@master01 ~]# kubectl get pv
NAME        CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS   CLAIM                   STORAGECLASS   REASON   AGE
nfs-pv-v1   1Gi        RWO,ROX,RWX    Retain           Bound    default/pvc-nfs-pv-v1                           52m
[root@master01 ~]# 
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　提示：可以看到现在pvc的状态变成了terminating，但对应pvc还在并没有被删除；对应pv还处于绑定状态；&lt;/p&gt;
&lt;p&gt;　　删除pod，看看对应pvc是否会被删除呢？&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;37&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
[root@master01 ~]# kubectl get pod
NAME         READY   STATUS    RESTARTS   AGE
redis-demo   1/1     Running   0          14m
[root@master01 ~]# kubectl delete pod redis-demo
pod &quot;redis-demo&quot; deleted
[root@master01 ~]# kubectl get pvc
No resources found in default namespace.
[root@master01 ~]# kubectl get pv
NAME        CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS     CLAIM                   STORAGECLASS   REASON   AGE
nfs-pv-v1   1Gi        RWO,ROX,RWX    Retain           Released   default/pvc-nfs-pv-v1                           54m
[root@master01 ~]# 
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　提示：可以看到删除对应pod以后，pvc就立即删除了；对应pvc被删除以后，对应pv的状态就从bound状态转变为Released状态，表示等待回收；我们在资源清单中使用的是Retain回收策略，pv和pvc都是我们人工手动回收；&lt;/p&gt;
&lt;p&gt;　　删除pv，看看对应数据是否会被删除？&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;37&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
[root@master01 ~]# kubectl get pv
NAME        CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS     CLAIM                   STORAGECLASS   REASON   AGE
nfs-pv-v1   1Gi        RWO,ROX,RWX    Retain           Released   default/pvc-nfs-pv-v1                           57m
[root@master01 ~]# kubectl delete pv nfs-pv-v1
persistentvolume &quot;nfs-pv-v1&quot; deleted
[root@master01 ~]# kubectl get pv
No resources found
[root@master01 ~]# ssh 192.168.0.99
root@192.168.0.99's password: 
Last login: Fri Dec 25 22:05:53 2020 from 192.168.0.41
[root@docker_registry ~]# ll /data/v1
total 4
-rw-r--r-- 1 polkitd qiuhom 122 Dec 25 22:24 dump.rdb
[root@docker_registry ~]# exit
logout
Connection to 192.168.0.99 closed.
[root@master01 ~]# 
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　提示：可以看到删除了pv，对应快照文件并没有清除；&lt;/p&gt;
&lt;p&gt;　　以上就是pv和pvc资源的用法，下面我们再来说一下sc资源&lt;/p&gt;
&lt;p&gt;　　SC是StorageClass的缩写，表示存储类；这种资源主要用来对pv资源的自动供给提供接口；所谓自动供给是指用户无需手动创建pv，而是在创建pvc时对应pv会由persistentVolume-controller自动创建并完成pv和pvc的绑定；使用sc资源的前提是对应后端存储必须支持rustfull类型接口的管理接口，并且pvc必须指定对应存储类名称来引用SC；简单讲SC资源就是用来为后端存储提供自动创建pv并关联对应pvc的接口；如下图&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1503305/202012/1503305-20201226005642604-183616597.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　提示：使用sc动态创建pv，对应pvc必须也是属于对应的sc；上图主要描述了用户在创建pvc时，引用对应的sc以后，对应sc会调用底层存储系统的管理接口，创建对应的pv并关联至对应pvc；&lt;/p&gt;
&lt;p&gt;　　示例：创建sc资源&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;35&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: slow
provisioner: kubernetes.io/glusterfs
parameters:
  resturl: &quot;http://127.0.0.1:8081&quot;
  clusterid: &quot;630372ccdc720a92c681fb928f27b53f&quot;
  restauthenabled: &quot;true&quot;
  restuser: &quot;admin&quot;
  secretNamespace: &quot;default&quot;
  secretName: &quot;heketi-secret&quot;
  gidMin: &quot;40000&quot;
  gidMax: &quot;50000&quot;
  volumetype: &quot;replicate:3&quot;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　提示：上述是官方文档中的一个示例，在创建sc资源时，对应群组是storage.k8s.io/v1，类型为StorageClass；provisioner字段用于描述对应供给接口名称；parameters用来定义向对应存储管理接口要传递的参数；&lt;/p&gt;
&lt;p&gt;　　在pvc资源中引用SC资源对象&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;33&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: foo-pvc
  namespace: foo
spec:
  storageClassName: &quot;slow&quot;
  volumeName: foo-pv
  ...
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　提示：在创建pvc时用storageClassName字段来指定对应的SC名称即可；&lt;/p&gt;
</description>
<pubDate>Fri, 25 Dec 2020 15:59:00 +0000</pubDate>
<dc:creator>Linux-1874</dc:creator>
<og:description>前文我们聊到了k8s中给Pod添加存储卷相关话题，回顾请参考：https://www.cnblogs.com/qiuhom-1874/p/14180752.html；今天我们来聊一下持久存储卷相关话题</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/qiuhom-1874/p/14188621.html</dc:identifier>
</item>
<item>
<title>Vue2+Koa2+Typescript前后端框架教程--02后端KOA2框架自动重启编译服务（nodemon） - 老吕4519</title>
<link>http://www.cnblogs.com/laolv4519/p/14191168.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/laolv4519/p/14191168.html</guid>
<description>&lt;p&gt;上一篇讲完搭建Typescritp版的Koa框架后，F5运行服务端，页面进行正常显示服务。&lt;/p&gt;
&lt;p&gt;今天要分享的是，如果要修改服务端代码，如果让编译服务自动重启，免去手动结束服务再重启的过程。&lt;/p&gt;
&lt;p&gt;自动重启服务需要使用nodemon工具。nodemon可以自动检测到目录中的文件更改时，通过重新启动应用程序来调试基于node.js的应用程序。&lt;/p&gt;
&lt;p&gt;1. 全局安装nodemon&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot;&gt;
&lt;pre&gt;
npm i nodemon -g
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;2. 配置引导文件lunch.json，修改为如下代码&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;59.5&quot;&gt;
&lt;div readability=&quot;64&quot;&gt;
&lt;p&gt;{&lt;/p&gt;
&lt;p&gt;    // Use IntelliSense to learn about possible attributes.&lt;/p&gt;
&lt;p&gt;    // Hover to view descriptions of existing attributes.&lt;/p&gt;
&lt;p&gt;    // For more information, visit: https://go.microsoft.com/fwlink/?linkid=830387&lt;/p&gt;
&lt;p&gt;    &quot;version&quot;: &quot;0.2.0&quot;,&lt;/p&gt;
&lt;p&gt;    &quot;configurations&quot;: [{&lt;/p&gt;
&lt;p&gt;        &quot;type&quot;: &quot;node&quot;,&lt;/p&gt;
&lt;p&gt;        &quot;request&quot;: &quot;launch&quot;,&lt;/p&gt;
&lt;p&gt;        &quot;name&quot;: &quot;Launch Program&quot;,&lt;/p&gt;
&lt;p&gt;        &quot;preLaunchTask&quot;: &quot;typescript&quot;,&lt;/p&gt;
&lt;p&gt;        &quot;protocol&quot;: &quot;inspector&quot;,&lt;/p&gt;
&lt;p&gt;        &quot;program&quot;: &quot;${workspaceFolder}/index.ts&quot;,&lt;/p&gt;
&lt;p&gt;        &quot;outFiles&quot;: [&lt;/p&gt;
&lt;p&gt;            &quot;${workspaceFolder}/bin/*.js&quot;&lt;/p&gt;
&lt;p&gt;        ],&lt;/p&gt;
&lt;p&gt;        &quot;runtimeExecutable&quot;: &quot;npm&quot;,&lt;/p&gt;
&lt;p&gt;        &quot;runtimeArgs&quot;: [&lt;/p&gt;
&lt;p&gt;            &quot;run&quot;,&lt;/p&gt;
&lt;p&gt;            &quot;debug&quot;&lt;/p&gt;
&lt;p&gt;        ],&lt;/p&gt;
&lt;p&gt;        &quot;port&quot;: 5858,&lt;/p&gt;
&lt;p&gt;        &quot;env&quot;: {&lt;/p&gt;
&lt;p&gt;            &quot;NODE_ENV&quot;: &quot;dev&quot;&lt;/p&gt;
&lt;p&gt;        },&lt;/p&gt;
&lt;p&gt;        &quot;restart&quot;: true,&lt;/p&gt;
&lt;p&gt;        &quot;console&quot;: &quot;integratedTerminal&quot;,&lt;/p&gt;
&lt;p&gt;        &quot;internalConsoleOptions&quot;: &quot;neverOpen&quot;&lt;/p&gt;
&lt;p&gt;    }]&lt;/p&gt;
&lt;p&gt;}&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;3. 修改package.json的scripts，如下：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;40&quot;&gt;
&lt;pre&gt;
&lt;span&gt;{
    &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; See https://go.microsoft.com/fwlink/?LinkId=733558 &lt;/span&gt;
    &lt;span&gt;//&lt;/span&gt;&lt;span&gt; for the documentation about the tasks.json format&lt;/span&gt;
    &quot;version&quot;: &quot;2.0.0&quot;&lt;span&gt;,
    &lt;/span&gt;&quot;tasks&quot;&lt;span&gt;: [{
        &lt;/span&gt;&quot;label&quot;: &quot;typescript&quot;&lt;span&gt;,
        &lt;/span&gt;&quot;type&quot;: &quot;typescript&quot;&lt;span&gt;,
        &lt;/span&gt;&quot;tsconfig&quot;: &quot;tsconfig.json&quot;&lt;span&gt;,
        &lt;/span&gt;&quot;isBackground&quot;: &lt;span&gt;true&lt;/span&gt;&lt;span&gt;,
        &lt;/span&gt;&quot;problemMatcher&quot;: &quot;$tsc-watch&quot;&lt;span&gt;,
        &lt;/span&gt;&quot;option&quot;: &quot;watch&quot;&lt;span&gt;
    }]
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;4. 修改task.json，如下：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;39&quot;&gt;
&lt;pre&gt;
 &quot;scripts&quot;&lt;span&gt;: {
    &lt;/span&gt;&quot;start&quot;: &quot;node ./bin/index.js&quot;&lt;span&gt;,
    &lt;/span&gt;&quot;debug&quot;: &quot;nodemon --watch ./bin --inspect=0.0.0.0:5858 --nolazy ./bin/index.js&quot;&lt;span&gt;,
    &lt;/span&gt;&quot;build&quot;: &quot;npm run build-ts&quot;&lt;span&gt;,
    &lt;/span&gt;&quot;build-ts&quot;: &quot;tsc&quot;&lt;span&gt;,
    &lt;/span&gt;&quot;watch&quot;: &quot;npm run watch-ts&quot;&lt;span&gt;,
    &lt;/span&gt;&quot;watch-ts&quot;: &quot;tsc -w&quot;&lt;span&gt;
  }&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;5. F5运行调试，控制台显示如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/127945/202012/127945-20201225232319851-1033107853.png&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;  6. index.ts如上篇文章内容不变，打开浏览器，输入地址：localhost:3000，显示效果如下：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;33&quot;&gt;
&lt;pre&gt;
const Koa = require('koa'&lt;span&gt;);
const app &lt;/span&gt;= &lt;span&gt;new&lt;/span&gt;&lt;span&gt; Koa();

app.use(async (ctx: any) &lt;/span&gt;=&amp;gt;&lt;span&gt; {
  ctx.body &lt;/span&gt;= 'Hello World'&lt;span&gt;;
});

console.log(&lt;/span&gt;'app server start on port 3000...'&lt;span&gt;)
app.listen(&lt;/span&gt;3000);
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/127945/202012/127945-20201225232530204-1952346657.png&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt; 7. 修改index.ts代码，如下：（仅修改：ctx.body = 'Hello World...Hello LaoLv';）&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;33&quot;&gt;
&lt;pre&gt;
const Koa = require('koa'&lt;span&gt;);
const app &lt;/span&gt;= &lt;span&gt;new&lt;/span&gt;&lt;span&gt; Koa();

app.use(async (ctx: any) &lt;/span&gt;=&amp;gt;&lt;span&gt; {
  ctx.body &lt;/span&gt;= 'Hello World...Hello LaoLv'&lt;span&gt;;
});

console.log(&lt;/span&gt;'app server start on port 3000...'&lt;span&gt;)
app.listen(&lt;/span&gt;3000);
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;8. 保存index.ts，此时控制台自动编译输出内容：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/127945/202012/127945-20201225232743212-1138425210.png&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;9. 打开浏览器，刷新，自动更改为修改后的结果，效果如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/127945/202012/127945-20201225232835601-1855431050.png&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt; 到此，后端调试，自动编译重启服务的功能完成。&lt;/p&gt;

&lt;p&gt;可能F5后vs code会弹出下面问题：Cannot connect to runtime process,timeout after 10000 ms -......&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/127945/202012/127945-20201225233051255-1233508728.png&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;解决办法就是，launch.json中，一定要加上：&quot;port&quot;: 5858，因为此处的port要与package.json中scripts--&amp;gt;debug中的 --inspect 0.0.0.0:5858的端口一致。&lt;/p&gt;

&lt;p&gt;附：文档结构如下&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/127945/202012/127945-20201226004613934-1116563006.png&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;

</description>
<pubDate>Fri, 25 Dec 2020 15:41:00 +0000</pubDate>
<dc:creator>老吕4519</dc:creator>
<og:description>上一篇讲完搭建Typescritp版的Koa框架后，F5运行服务端，页面进行正常显示服务。 今天要分享的是，如果要修改服务端代码，如果让编译服务自动重启，免去手动结束服务再重启的过程。 自动重启服务需</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/laolv4519/p/14191168.html</dc:identifier>
</item>
<item>
<title>（十五）、shell脚本之简单控制流结构 - ai_bingjie</title>
<link>http://www.cnblogs.com/ai-bingjie/p/14191113.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/ai-bingjie/p/14191113.html</guid>
<description>&lt;h3&gt;一、基本的控制结构&lt;/h3&gt;
&lt;h4&gt;&lt;span&gt;1、控制流&lt;/span&gt;&lt;/h4&gt;
&lt;p&gt;&lt;span&gt;常见的控制流就是if、then、else语句提供测试条件，测试条件可以基于各种条件。例如创建文件是否成功、是否有读写权限等，&lt;span&gt;凡是执行的操作有失败的可能就可以用控制流，&lt;span&gt;注意控制流的真为0，假为1。&lt;/span&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;单层if语句&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;　　if 条件；&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;then                            if 条件&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;　　　　命令                或               then 命令&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;　　fi                                               fi&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;　    if后跟条件，如果条件为真，执行then后面的命令，而then必须放在新行，fi结束控制流，可以理解为endif；&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;我们更推荐第一种写法，这样可以更加增强代码的可读性，使得代码层次更加清晰，下面的例子简单阐述if...else语句。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;举例：$ vim simple_if&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;　　　#!/bin/sh&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;　　　if [ &quot;159&quot; -lt &quot;520&quot; ]; then&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;　　　　　echo &quot;yes, 159 is less then 520&quot;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;　　　fi&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt; 输入变量测试&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;　　通过测试设置为接受用户输入的变量可以测知用户是否输入信息，下面的例子中测试用户键入 enter后变量addr的值是否包含任何信息。&lt;/p&gt;
&lt;p&gt;　　$ vim  iftest2&lt;/p&gt;
&lt;p&gt;        #!/bin/sh&lt;/p&gt;
&lt;p&gt;　　 echo &quot;Enter your addr:&quot;&lt;/p&gt;
&lt;p&gt;　　  read ADDR&lt;/p&gt;
&lt;p&gt;　　  if [ &quot;$ADDR&quot; = &quot;&quot; ]; then&lt;/p&gt;
&lt;p&gt;　　　　echo &quot;you did not enter any information&quot;&lt;/p&gt;
&lt;p&gt;　　  fi&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;grep输出检查&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;　　对grep使用if语句找出grep是否成功返回信息&lt;/p&gt;
&lt;p&gt;　　#!/bin/sh&lt;/p&gt;
&lt;p&gt;　　if grep &quot;liming&quot; name.file &amp;gt; /tmp/null 2&amp;gt;&amp;amp;1; then&lt;/p&gt;
&lt;p&gt;　　　　echo &quot;liming is in the file&quot;&lt;/p&gt;
&lt;p&gt;　　else&lt;/p&gt;
&lt;p&gt;　　　　echo &quot;no liming is not in the file&quot;&lt;/p&gt;
&lt;p&gt;　　fi&lt;/p&gt;
&lt;h4&gt;&lt;span&gt;2、if...else语句&lt;/span&gt;&lt;/h4&gt;
&lt;p&gt;if 条件；then&lt;/p&gt;
&lt;p&gt;　　命令1&lt;/p&gt;
&lt;p&gt;else&lt;/p&gt;
&lt;p&gt;　　命令2&lt;/p&gt;
&lt;p&gt;fi&lt;/p&gt;
&lt;p&gt;检查运行脚本的用户，环境变量用作测试条件，即LOGNAME是否包含root值，这类语句是加在脚本开头作为安全性准则的普遍方法，&lt;/p&gt;
&lt;p&gt;#!/bin/sh&lt;/p&gt;
&lt;p&gt;if [ &quot;$LOGNAME&quot; != &quot;root&quot; ]; then&lt;/p&gt;
&lt;p&gt;　　echo &quot;you need to be root to run this script&quot; &amp;gt; &amp;amp;2&lt;/p&gt;
&lt;p&gt;　　exit 1&lt;/p&gt;
&lt;p&gt;else&lt;/p&gt;
&lt;p&gt;　　echo &quot;yes indeed you are $LOGNAME proceed&quot;&lt;/p&gt;
&lt;p&gt;fi&lt;/p&gt;






















&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt; &lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
</description>
<pubDate>Fri, 25 Dec 2020 15:34:00 +0000</pubDate>
<dc:creator>ai_bingjie</dc:creator>
<og:description>一、基本的控制结构 1、控制流 常见的控制流就是if、then、else语句提供测试条件，测试条件可以基于各种条件。例如创建文件是否成功、是否有读写权限等，凡是执行的操作有失败的可能就可以用控制流，注</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/ai-bingjie/p/14191113.html</dc:identifier>
</item>
<item>
<title>深入理解MySQL系列之redo log、undo log和binlog - 曹自标</title>
<link>http://www.cnblogs.com/caozibiao/p/14191164.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/caozibiao/p/14191164.html</guid>
<description>&lt;h4 id=&quot;事务的实现&quot;&gt;事务的实现&lt;/h4&gt;
&lt;p&gt;redo log保证事务的持久性，undo log用来帮助事务回滚及MVCC的功能。&lt;/p&gt;
&lt;h4 id=&quot;innodb存储引擎体系结构&quot;&gt;InnoDB存储引擎体系结构&lt;/h4&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/2211828/202012/2211828-20201222093735507-1384823192.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/2211828/202012/2211828-20201222100947419-1191003124.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h4 id=&quot;redo-log&quot;&gt;redo log&lt;/h4&gt;
&lt;h6 id=&quot;write-ahead-log策略&quot;&gt;Write Ahead Log策略&lt;/h6&gt;
&lt;p&gt;事务提交时，先写重做日志再修改页；当由于发生宕机而导致数据丢失时，就可以通过重做日志来完成数据的恢复。&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;InnoDB首先将重做日志信息先放到重做日志缓存&lt;/li&gt;
&lt;li&gt;按一定频率刷新到重做日志文件&lt;/li&gt;
&lt;/ul&gt;&lt;blockquote readability=&quot;7&quot;&gt;
&lt;p&gt;重做日志文件： 在默认情况，InnoDB存储引擎的数据目录下会有两个名为ib_logfile1和ib_logfile2的文件。每个InnoDB存储引擎至少有1个重做日志文件组(group)，每个文件组下至少有2个重做日志文件。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;下面图一，很好说明重做日志组以循环写入方式运行，InnoDB存储引擎先写ib_logfile1，当达到文件最后时，会切换至重做日志文件ib_logfile2.&lt;/p&gt;
&lt;p&gt;而图2，增加一个OS Buffer，有助于理解fsync过程。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/2211828/202012/2211828-20201225150739662-1647919243.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20201225210053166.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80Mzg0MzEwNA==,size_16,color_FFFFFF,t_70&quot; alt=&quot;在这里插入图片描述&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;关于log group，称为重做日志组，是一个逻辑上的概念。InnoDB存储引擎实际只有一个log group。&lt;br/&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/2211828/202012/2211828-20201225155925755-1140903197.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;log group中第一个redo log file，其前2KB部分保存4个512字节大小块：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/2211828/202012/2211828-20201225155506599-747896265.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h6 id=&quot;重做日志缓冲刷新到磁盘&quot;&gt;重做日志缓冲刷新到磁盘&lt;/h6&gt;
&lt;p&gt;下面三种情况刷新：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;Master Thread每一秒将重做日志缓冲刷新到重做日志文件&lt;/li&gt;
&lt;li&gt;每个事务提交时会将重做日志缓冲刷新到重做日志文件&lt;/li&gt;
&lt;li&gt;当重做日志缓冲池剩余空间小于1/2时，重做日志刷新到重做日志文件&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;补充上述三种情况第二种，触发写磁盘过程由参数innodb_flush_log_at_trx_commit控制，表示提交(commit)操作时，处理重做日志的方式。&lt;/p&gt;
&lt;p&gt;参数innodb_flush_log_at_trx_commit有效值有0、1、2&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;0表示当提交事务时，并不将事务的重做日志写入磁盘上日志文件，而是等待主线程每秒刷新。&lt;/li&gt;
&lt;li&gt;1表示在执行commit时将重做日志缓冲同步写到磁盘，即伴有fsync的调用&lt;/li&gt;
&lt;li&gt;2表示将重做日志异步写到磁盘，即写到文件系统的缓存中。不保证commit时肯定会写入重做日志文件。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;0，当数据库发生宕机时，部分日志未刷新到磁盘，因此会丢失最后一段时间的事务。&lt;br/&gt;2，当操作系统宕机时，重启数据库后会丢失未从文件系统缓存刷新到重做日志文件那部分事务。&lt;/p&gt;
&lt;p&gt;下图有助于理解&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20201225205948912.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80Mzg0MzEwNA==,size_16,color_FFFFFF,t_70&quot; alt=&quot;在这里插入图片描述&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h6 id=&quot;重做日志块&quot;&gt;重做日志块&lt;/h6&gt;
&lt;p&gt;在InnoDB存储引擎中，重做日志都是以512字节进行存储的。意味着重做日志缓存、重做日志文件都是以块(block)的方式进行保存的，每块512字节。&lt;/p&gt;
&lt;p&gt;重做日志头12字节，重做日志尾8字节，故每个重做日志块实际可以存储492字节。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/2211828/202012/2211828-20201225154415197-1539644797.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h6 id=&quot;重做日志格式&quot;&gt;重做日志格式&lt;/h6&gt;
&lt;p&gt;redo log是基于页的格式来记录的。默认情况下，innodb的页大小是16KB(由 innodb_page_size变量控制)，一个页内可以存放非常多的log block(每个512字节)，而log block中记录的又是数据页的变化。&lt;/p&gt;
&lt;p&gt;log body的格式分为4部分：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;redo_log_type：占用1个字节，表示redo log的日志类型。&lt;/li&gt;
&lt;li&gt;space：表示表空间的ID，采用压缩的方式后，占用的空间可能小于4字节。&lt;/li&gt;
&lt;li&gt;page_no：表示页的偏移量，同样是压缩过的。&lt;/li&gt;
&lt;li&gt;redo_log_body表示每个重做日志的数据部分，恢复时会调用相应的函数进行解析。例如insert语句和delete语句写入redo log的内容是不一样的。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20201225212707954.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80Mzg0MzEwNA==,size_16,color_FFFFFF,t_70&quot; alt=&quot;在这里插入图片描述&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;如下图，分别是insert和delete大致的记录方式。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20201225212942519.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80Mzg0MzEwNA==,size_16,color_FFFFFF,t_70&quot; alt=&quot;在这里插入图片描述&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h6 id=&quot;redo日志恢复&quot;&gt;redo日志恢复&lt;/h6&gt;
&lt;p&gt;下面LSN(Log Sequence Number)代表checkpoint，当数据库在LSN为10000时发生宕机，恢复操作仅恢复LSN10000-LSN13000范围内日志&lt;br/&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/2211828/202012/2211828-20201225161529975-533870419.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h4 id=&quot;undo-log&quot;&gt;undo log&lt;/h4&gt;
&lt;h6 id=&quot;undo-log的作用&quot;&gt;undo log的作用&lt;/h6&gt;
&lt;p&gt;undo是逻辑日志，只是将数据库逻辑地恢复到原来的样子；所有修改都被逻辑地取消了，但是数据结构和页本身在回滚之后可能不大相同。&lt;/p&gt;
&lt;p&gt;undo log有两个作用：提供回滚和多个行版本控制(MVCC)。&lt;/p&gt;
&lt;ul readability=&quot;0.5&quot;&gt;&lt;li readability=&quot;1&quot;&gt;
&lt;p&gt;InnoDB存储引擎回滚时，对于每个INSERT，会完成一个DELETE；对于每个DELETE，会执行一个INSERT；对于每个UPDATE，会执行一个相反的UPDATE，将修改前的行放回去。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;MVCC： 当用户读取一行记录时，若该记录已经被其他事务占用，当前事务可以通过undo读取之前的行版本信息，以此实现非锁定读取。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;h6 id=&quot;undo-log的存储方式&quot;&gt;undo log的存储方式&lt;/h6&gt;
&lt;p&gt;innodb存储引擎对undo的管理采用段的方式。rollback segment称为回滚段，每个回滚段中有1024个undo log segment。&lt;/p&gt;
&lt;p&gt;在以前老版本，只支持1个rollback segment，这样就只能记录1024个undo log segment。后来MySQL5.5可以支持128个rollback segment，即支持128*1024个undo操作，还可以通过变量 innodb_undo_logs (5.6版本以前该变量是 innodb_rollback_segments )自定义多少个rollback segment，默认值为128。&lt;/p&gt;
&lt;p&gt;undo log默认存放在共享表空间中。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/2020122521452338.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80Mzg0MzEwNA==,size_16,color_FFFFFF,t_70&quot; alt=&quot;在这里插入图片描述&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h6 id=&quot;事务提交undo-log处理过程&quot;&gt;事务提交undo log处理过程&lt;/h6&gt;
&lt;p&gt;当事务提交时，InnoDB存储引擎会做以下两件事：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;将undo log放入一个列表中，以供之后的purge使用，是否可以最终删除undo log及所在页由purge线程来判断&lt;/li&gt;
&lt;li&gt;判断undo log 所在的页是否可以重用，若可以，分配给下个事务使用&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;当事务提交时，首先将undo log放入链表中，然后判断undo页的使用空间是否小于3/4，若是，则表示该undo页可以被重用，之后新的undo log记录在当前undo log的后面&lt;/p&gt;
&lt;p&gt;undo log分为：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;insert undo log&lt;/li&gt;
&lt;li&gt;update undo log&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;因为事务隔离性，insert undo log对其他事务不可见，所以该undo log可以在事务提交后直接删除，不需要进行purge操作。&lt;/p&gt;
&lt;p&gt;update undo log记录的是对delete和update操作产生的undo log。该undo log可能需要提供MVCC机制，因此不能提交时就进行删除&lt;/p&gt;
&lt;p&gt;update分为两种情况：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;update的列如果不是主键列，在undo log中直接反向记录是如何update的。即update是直接进行的。&lt;/li&gt;
&lt;li&gt;update主键的操作可以分为两步：&lt;/li&gt;
&lt;/ol&gt;&lt;ul&gt;&lt;li&gt;首先将原主键记录标记为已删除，因此需要产生一个类型为TRX_UNDO_DEL_MARK_REC的undo log&lt;/li&gt;
&lt;li&gt;之后插入一条新的记录，产生一个类型为TRX_UNDO_INSERT_MARK_REC的undo log&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/2211828/202012/2211828-20201225195408205-772882966.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;InnoDB purge时，会先从history列表找undo log，然后再从undo page中找undo log；可以避免大量随机读取操作，从而提高purge效率。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/2211828/202012/2211828-20201225195553389-1247068452.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h6 id=&quot;mvcc多版本并发控制&quot;&gt;MVCC(多版本并发控制)&lt;/h6&gt;
&lt;p&gt;MVCC其实就是在每一行记录后面增加两个隐藏列，记录创建版本号和删除版本号，而每一个事务在启动的时候，都有一个唯一的递增的版本号。&lt;/p&gt;
&lt;p&gt;MVCC只在REPEATABLE READ 和READ COMMITTED两个隔离级别下工作。读未提交不存在版本问题，序列化则对所有读取行加锁。&lt;/p&gt;
&lt;p&gt;示例：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;插入操作：记录的创建版本号就是事务版本号&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;如插入一条记录，事务id假设是1，则创建版本号也是1&lt;/p&gt;
&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;id&lt;/th&gt;
&lt;th&gt;name&lt;/th&gt;
&lt;th&gt;create version&lt;/th&gt;
&lt;th&gt;delete version&lt;/th&gt;
&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;test&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td/&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;ol start=&quot;2&quot;&gt;&lt;li&gt;更新操作：先标记旧版本号为已删除，版本号就是当前版本号，再插入一条新的记录&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;如事务2把name字段更新&lt;br/&gt;update table set name = 'new test' where id = 1;&lt;/p&gt;
&lt;p&gt;原来的记录被标记删除，删除版本号为2，并插入新记录，创建版本号为2&lt;/p&gt;
&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;id&lt;/th&gt;
&lt;th&gt;name&lt;/th&gt;
&lt;th&gt;create version&lt;/th&gt;
&lt;th&gt;delete version&lt;/th&gt;
&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;test&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;new test&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td/&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;ol start=&quot;3&quot;&gt;&lt;li&gt;删除操作：把事务版本作为删除版本号&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;如事务3把记录删除&lt;br/&gt;delete from table where id = 1;&lt;/p&gt;
&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;id&lt;/th&gt;
&lt;th&gt;name&lt;/th&gt;
&lt;th&gt;create version&lt;/th&gt;
&lt;th&gt;delete version&lt;/th&gt;
&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;test&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;3&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;ol start=&quot;4&quot;&gt;&lt;li&gt;查询操作&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;需满足以下两个条件的记录才能被事务查询出来：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;InnoDB只查找版本早于当前事务版本的数据行&lt;/li&gt;
&lt;li&gt;行的删除版本要么未定义，要么大于当前版本号，这可以确保事务读取到的行，在事务未开始之前未被删除&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;MVCC好处：减少锁的争用，提升性能&lt;/p&gt;
&lt;h4 id=&quot;binlog&quot;&gt;binlog&lt;/h4&gt;
&lt;h6 id=&quot;二进制文件概念及作用&quot;&gt;二进制文件概念及作用&lt;/h6&gt;
&lt;p&gt;二进制文件(binary log)记录了对MySQL数据库执行更改的所有操作(不包含SELECT、SHOW等，因为对数据没有修改)&lt;/p&gt;
&lt;p&gt;二进制文件主要几种作用：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;恢复：某些数据的恢复需要二进制日志&lt;/li&gt;
&lt;li&gt;复制： 通过复制和执行二进制日志使一台远程的MySQL(slave)与另一台MySQL数据库(master)进行实时同步&lt;/li&gt;
&lt;li&gt;审计： 用户可以通过二进制日志中信息来进行审计，判断是否有对数据库进行注入的攻击&lt;/li&gt;
&lt;/ul&gt;&lt;h6 id=&quot;二进制文件三个格式&quot;&gt;二进制文件三个格式&lt;/h6&gt;
&lt;p&gt;MySQL 5.1开始引入binlog_format参数，该参数可设值有STATEMENT、ROW和MIX&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;STATEMENT： 二进制文件记录的是日志的逻辑SQL语句&lt;/li&gt;
&lt;li&gt;ROW：记录表的行更改情况。如果设置了ROW模式，可以将InnoDB事务隔离级别设为READ_COMMITTED，以获得更好的并发性&lt;/li&gt;
&lt;li&gt;MIX：MySQL默认采用STATEMENT格式进行二进制文件的记录，但在一些情况下会使用ROW，可能的情况有：&lt;/li&gt;
&lt;/ol&gt;&lt;ul&gt;&lt;li&gt;表的存储引擎为NDB，这时对表DML操作都以ROW格式进行&lt;/li&gt;
&lt;li&gt;使用了UUID()、USER()、CURRENT_USER()、FOUND_ROWS()、ROW_COUNT()等不确定函数&lt;/li&gt;
&lt;li&gt;使用了INSERT DELAY语句&lt;/li&gt;
&lt;li&gt;使用了用户定义函数&lt;/li&gt;
&lt;li&gt;使用了临时表&lt;/li&gt;
&lt;/ul&gt;&lt;h6 id=&quot;redo-log和二进制文件区别&quot;&gt;redo log和二进制文件区别&lt;/h6&gt;
&lt;p&gt;(二进制文件用来进行POINT-IN-TIME(PIT))的恢复及主从复制环境的建立。&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;二进制文件会记录所有与MySQL数据库有关的日志记录，包括InnoDB、MyISAM等其他存储引擎的日志。而InnoDB存储引擎的重做日志只记录有关该存储引擎本身的事务日志。&lt;/li&gt;
&lt;li&gt;记录的内容不同，无论用户将二进制日志文件记录的格式设为STATEMENT、ROW或MIXED，其记录的都是关于一个事务的具体操作内容，即该日志是逻辑日志。而InnoDB存储引擎的重做日志文件记录的是关于每个页的更改的物理情况。&lt;/li&gt;
&lt;li&gt;此外，写入的时间页不同，二进制日志文件仅再事务提交前进行提交，即只写磁盘一次，不论这时该事务多大。而在事务进行的过程中，却不断有重做日志条目(reod entry)被写入到重做日志文件中。&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/2211828/202012/2211828-20201225153945245-1493854256.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h6 id=&quot;group-commit&quot;&gt;group commit&lt;/h6&gt;
&lt;p&gt;若事务为非只读事务，则每次事务提交时需要进行一次fsync操作，以此保证重做日志都已经写入磁盘。但磁盘fsync性能有限，为提高磁盘fsync效率，当前数据库都提供group commit功能，即一次可以刷新确保多个事务日志被写入文件。&lt;/p&gt;
&lt;p&gt;对InnoDB group commit，进行两阶段操作：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;修改内存中事务对应的信息，并且将日志写入重做日志缓冲&lt;/li&gt;
&lt;li&gt;调用fsync将确保日志都从重做日志缓冲写入磁盘&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;InnoDB1.2前，开启二进制文件，group commit功能失效问题：&lt;/p&gt;
&lt;p&gt;开启二进制文件后，其步骤如下：&lt;br/&gt;1）当事务提交时，InnoDB存储引擎进行prepare操作&lt;br/&gt;2）MySQL数据库上层写入二进制文件&lt;br/&gt;3）InnoDB将日志写入重做日志文件&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;a）修改内存中事务对应的信息，并将日志写入重做日志缓冲&lt;/li&gt;
&lt;li&gt;b）调用fsync将确保日志都从重做日志缓冲写入磁盘&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;其中在保证MySQL数据库上层二进制文件的写入顺序，和InnoDB事务提交顺序一致，MySQL内部使用了prepare_commit_mutex锁，从而步骤3）中a）步不可以在其他事务执行步骤b）时进行，从而导致roup commit功能失效。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20201225223824387.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80Mzg0MzEwNA==,size_16,color_FFFFFF,t_70&quot; alt=&quot;在这里插入图片描述&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;解决方案便是BLGC(Binary Log Group Commit)&lt;/p&gt;
&lt;p&gt;MySQL 5.6 BLGC实现方式分为三个阶段：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;Flush阶段：将每个事务的二进制文件写入内存&lt;/li&gt;
&lt;li&gt;Sync阶段：将内存中的二进制刷新到磁盘，若队列有多个事务，那么仅一次fsync操作就完成了二进制日志的写入，这就是BLGC&lt;/li&gt;
&lt;li&gt;Commit阶段：leader根据顺序调用存储引擎层事务提交，由于innodb本就支持group commit，所以解决了因为锁 prepare_commit_mutex 而导致的group commit失效问题。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20201225223115682.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80Mzg0MzEwNA==,size_16,color_FFFFFF,t_70&quot; alt=&quot;在这里插入图片描述&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;参考：&lt;br/&gt;《MySQL技术内幕》&lt;br/&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s/rNFy_qwnNWUvzjYznOXKJw&quot; target=&quot;_blank&quot;&gt;https://mp.weixin.qq.com/s/rNFy_qwnNWUvzjYznOXKJw&lt;/a&gt;&lt;br/&gt;&lt;a href=&quot;https://www.cnblogs.com/hapjin/archive/2019/09/28/11521506.html&quot; target=&quot;_blank&quot;&gt;https://www.cnblogs.com/hapjin/archive/2019/09/28/11521506.html&lt;/a&gt;&lt;/p&gt;
</description>
<pubDate>Fri, 25 Dec 2020 15:33:00 +0000</pubDate>
<dc:creator>曹自标</dc:creator>
<og:description>事务的实现 redo log保证事务的持久性，undo log用来帮助事务回滚及MVCC的功能。 InnoDB存储引擎体系结构 redo log Write Ahead Log策略 事务提交时，先写重</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/caozibiao/p/14191164.html</dc:identifier>
</item>
<item>
<title>Redis 设计与实现 4：字典 - 小新是也</title>
<link>http://www.cnblogs.com/chenchuxin/p/14191156.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/chenchuxin/p/14191156.html</guid>
<description>&lt;p&gt;Redis 中，字典是基础结构。Redis 数据库数据、过期时间、哈希类型都是把字典作为底层结构。&lt;/p&gt;

&lt;h2 id=&quot;哈希表&quot;&gt;哈希表&lt;/h2&gt;
&lt;p&gt;哈希表的实现代码在：&lt;code&gt;dict.h/dictht&lt;/code&gt; ，Redis 的字典用哈希表的方式实现。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-c&quot;&gt;typedef struct dictht {
        // 哈希表数组，俗称的哈希桶(bucket)
    dictEntry **table;
    // 哈希表的长度
    unsigned long size;
    // 哈希表的长度掩码，用来计算索引值，保证不越界。总是 size - 1
    // h = dictHashKey(ht, he-&amp;gt;key) &amp;amp; n.sizemask;
    unsigned long sizemask;
    // 哈希表已经使用的节点数
    unsigned long used;
} dictht;
&lt;/code&gt;
&lt;/pre&gt;
&lt;ul&gt;&lt;li&gt;&lt;code&gt;table&lt;/code&gt; 是一个哈希表数组，每个节点的实现在 &lt;code&gt;dict.h/dictEntry&lt;/code&gt;，每个 &lt;code&gt;dictEntry&lt;/code&gt; 保存一个键值对。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;size&lt;/code&gt; 属性记录了向系统申请的哈希表的长度，不一定都用完，有预留空间的。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;sizemask&lt;/code&gt; 属性主要是用来计算 &lt;code&gt;索引值 = 哈希值 &amp;amp; sizemask&lt;/code&gt;，这个索引值决定了键值对放在 &lt;code&gt;table&lt;/code&gt; 的哪个位置。它的值总是 &lt;code&gt;size - 1&lt;/code&gt;，其实我有点不明白为啥计算的时候不直接用 &lt;code&gt;size - 1&lt;/code&gt;，知道的大佬请明示。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;used&lt;/code&gt; 属性用来记录已经使用的节点数，&lt;code&gt;size&lt;/code&gt; - &lt;code&gt;use&lt;/code&gt; 就是未使用的节点啦。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;下图展示了一个大小为 4 的空哈希表结构，没有任何键值对&lt;br/&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20201225202646424.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2lkZXNpcmVjY3g=,size_16,color_FFFFFF,t_70&quot; alt=&quot;一个空哈希表&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h2 id=&quot;哈希节点&quot;&gt;哈希节点&lt;/h2&gt;
&lt;p&gt;哈希表 &lt;code&gt;dictht&lt;/code&gt; 的 &lt;code&gt;table&lt;/code&gt; 的元素由哈希节点 &lt;code&gt;dictEntry&lt;/code&gt; 组成，每一个 &lt;code&gt;dictEntry&lt;/code&gt; 就是一个键值对&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-c&quot;&gt;typedef struct dictEntry {
        // 键
    void *key;
    // 值
    union {
        void *val;
        uint64_t u64;
        int64_t s64;
        double d;
    } v;
    // 下一个哈希节点，用于哈希冲突时拉链表用的
    struct dictEntry *next;
} dictEntry;
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;next 指针是用于当&lt;strong&gt;哈希冲突&lt;/strong&gt;的时候，可以形成链表用的。后续会将&lt;/p&gt;
&lt;h2 id=&quot;字典&quot;&gt;字典&lt;/h2&gt;
&lt;p&gt;Redis 的字典实现在： &lt;code&gt;dict.h/dict&lt;/code&gt; 。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-c&quot;&gt;typedef struct dict {
        // 哈希算法
    dictType *type;
    // 私有数据，用于不同类型的哈希算法的参数
    void *privdata;
    // 两个哈希表，用两个的原因是 rehash 扩容缩容用的
    dictht ht[2];
    // rehash 进行到的索引值，当没有在 rehash 的时候，为 -1
    long rehashidx; /* rehashing not in progress if rehashidx == -1 */
    // 正在跑的迭代器
    unsigned long iterators; /* number of iterators currently running */
} dict;

// dictType 实际上就是哈希算法，不知道为啥名字叫 dictType
typedef struct dictType {
        // hash方法，根据 key 计算哈希值
    uint64_t (*hashFunction)(const void *key);
    // 复制 key
    void *(*keyDup)(void *privdata, const void *key);
    // 复制 value
    void *(*valDup)(void *privdata, const void *obj);
    // key 比较
    int (*keyCompare)(void *privdata, const void *key1, const void *key2);
    // 销毁 key
    void (*keyDestructor)(void *privdata, void *key);
    // 销毁 value
    void (*valDestructor)(void *privdata, void *obj);
} dictType;
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;dictType&lt;/code&gt; 属性表示字典类型，实际上这个字典类型就是一组操作键值对算法，里面规定了很多函数。&lt;br/&gt;&lt;code&gt;privdata&lt;/code&gt; 则是为不同类型的 &lt;code&gt;dictType&lt;/code&gt; 提供的可选参数。&lt;br/&gt;如果有需要，在创建字典的时候，可以传入&lt;code&gt;dictType&lt;/code&gt; 和 &lt;code&gt;privdata&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;dict.c&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-c&quot;&gt;// 创建字典，这里有 type 和 privdata 可以传
dict *dictCreate(dictType *type, void *privDataPtr) {
    dict *d = zmalloc(sizeof(*d));
    _dictInit(d,type,privDataPtr);
    return d;
}

// 初始化字典
int _dictInit(dict *d, dictType *type, void *privDataPtr) {
    _dictReset(&amp;amp;d-&amp;gt;ht[0]);
    _dictReset(&amp;amp;d-&amp;gt;ht[1]);
    d-&amp;gt;type = type;
    d-&amp;gt;privdata = privDataPtr;
    d-&amp;gt;rehashidx = -1;
    d-&amp;gt;iterators = 0;
    return DICT_OK;
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;下图是比较完整的普通状态下的 &lt;code&gt;dict&lt;/code&gt; 的结构(没有进行 rehash，也没有迭代器的状态)：&lt;br/&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20201225214614680.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2lkZXNpcmVjY3g=,size_16,color_FFFFFF,t_70&quot; alt=&quot;dict 结构图&quot; loading=&quot;lazy&quot;/&gt;# 哈希算法&lt;br/&gt;当字典中需要添加新的键值对时，需要先对键进行哈希，算出哈希值，然后在根据字典的长度，算出索引值。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-c&quot;&gt;// 使用哈希字典里面的哈希算法，算出哈希值
hash = dict-&amp;gt;type-&amp;gt;hashFunction(key)
// 使用 sizemask 和 哈希值算出索引值
idx = hash &amp;amp; d-&amp;gt;ht[table].sizemask;
// 通过索引值，定位哈希节点
he = d-&amp;gt;ht[table].table[idx];
&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;哈希冲突&quot;&gt;哈希冲突&lt;/h2&gt;
&lt;p&gt;哈希冲突指的是多个不同的 key，算出的索引值一样。&lt;/p&gt;
&lt;p&gt;Redis 解决哈希冲突的方法是：拉链法。就是每个哈希节点后面有个 &lt;code&gt;next&lt;/code&gt; 指针，当发现计算出的索引值对应的位置有其他节点，那么直接加在前面节点后即可，这样就形成了一个链表。&lt;/p&gt;
&lt;p&gt;下图展示了 &lt;code&gt;{k1, v1}&lt;/code&gt; 和 &lt;code&gt;{k2, v2}&lt;/code&gt; 哈希冲突的结构。&lt;br/&gt;假设 &lt;code&gt;k1&lt;/code&gt; 和 &lt;code&gt;k2&lt;/code&gt; 算出的索引值都是 3，当 &lt;code&gt;k2&lt;/code&gt; 发现 &lt;code&gt;table[3]&lt;/code&gt; 已经有 &lt;code&gt;dictEntry{k1,v1}&lt;/code&gt;，那就 &lt;code&gt;dictEntry{k1,v1}.next = dictEntry{k2,v2}&lt;/code&gt;。&lt;br/&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20201225214716935.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2lkZXNpcmVjY3g=,size_16,color_FFFFFF,t_70&quot; alt=&quot;哈希冲突拉链表的示意图&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h2 id=&quot;rehash&quot;&gt;rehash&lt;/h2&gt;
&lt;p&gt;随着操作的不断进行，哈希表的长度会不断增减。哈希表的长度太长会造成空间浪费，太短哈希冲突明显导致性能下降，哈希表需要通过扩容或缩容，让哈希表的长度保持在一个合理的范围内。&lt;br/&gt;Redis 通过 ht[0] 和 ht[1] 来完成 rehash 的操作，步骤如下：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;为 ht[1] 分配空间，分配的空间长度有两种情况：
&lt;ul&gt;&lt;li&gt;扩容：第一个大于等于 &lt;code&gt;ht[0].used * 2&lt;/code&gt; 的 &lt;span class=&quot;math inline&quot;&gt;\(2^n\)&lt;/span&gt; 的数，例如 ht[0].used = 3，那么分配的是距离 6 最近的 &lt;span class=&quot;math inline&quot;&gt;\(2^3=8\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;缩容：第一个大于等于 &lt;code&gt;ht[0].used / 2&lt;/code&gt; 的 &lt;span class=&quot;math inline&quot;&gt;\(2^n\)&lt;/span&gt; 的数，例如 ht[0].used = 6，那么分配的是距离 3 最近的 &lt;span class=&quot;math inline&quot;&gt;\(2^2=4\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;将 h[0] 上的键值对都迁移到 h[1]，迁移的时候都是重新计算索引值的。由于 h[1] 的长度较长，之前在 h[0] 拉链的元素大概率会被分到不同的位置。&lt;/li&gt;
&lt;li&gt;ht[0] 所有的键值对迁移完之后，h[0] 释放，然后 &lt;code&gt;h[0] = h[1]&lt;/code&gt;，并把 h[1] 清空，为下次 rehash 准备&lt;/li&gt;
&lt;/ol&gt;&lt;h2 id=&quot;渐进式-rehash&quot;&gt;渐进式 rehash&lt;/h2&gt;
&lt;p&gt;上面说的 rehash 中的第二步，迁移的过程不是一次完成的。如果哈希表的长度比较小，一次完成很快。但是如果哈希表很长，例如百万千万，那这个迁移的过程就没有那么快了，会造成命令阻塞！&lt;br/&gt;下面来说说，redis 是如何渐进式地将 &lt;code&gt;h[0]&lt;/code&gt; 中的键值对迁移到 &lt;code&gt;h[1]&lt;/code&gt; 中的：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;为 h[1] 开辟空间，字典同时持有 h[0] 和 h[1]&lt;/li&gt;
&lt;li&gt;字典中的 &lt;code&gt;rehashidx&lt;/code&gt; 维护了 rehash 的进度，设置为 0 的时候，开始 rehash&lt;/li&gt;
&lt;li&gt;字典每次增删改查的时候，除了完成指定操作之外，还会顺带把 &lt;code&gt;rehashidx&lt;/code&gt; 上的整条链表迁移到 &lt;code&gt;h[1]&lt;/code&gt; 中。迁移完之后 &lt;code&gt;rehashidx + 1&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;随着字典的不断读取、操作，最终 &lt;code&gt;h[0]&lt;/code&gt; 上的所有键值对都会迁移到 &lt;code&gt;h[1]&lt;/code&gt; 中。全部迁移完成之后 &lt;code&gt;rehashidx = -1&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;这种渐进式 rehash 的方式的好处在于，将庞大的迁移工作，分摊到每次的增删改查中，避免了一次性操作带来的性能的巨大损耗。&lt;br/&gt;缺点就是迁移过程中 &lt;code&gt;h[0]&lt;/code&gt; 和 &lt;code&gt;h[1]&lt;/code&gt; 同时存在的时间比较长，空间利用率较低。&lt;/p&gt;
&lt;p&gt;下面一系列的图，演示了字典是如何渐进式地 rehash ( 图片来自 &lt;a href=&quot;http://1e-gallery.redisbook.com/4-dict.html&quot; target=&quot;_blank&quot;&gt;《Redis 设计与实现》图片集&lt;/a&gt; )&lt;br/&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20201225222019520.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2lkZXNpcmVjY3g=,size_16,color_FFFFFF,t_70&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;br/&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20201225222018728.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2lkZXNpcmVjY3g=,size_16,color_FFFFFF,t_70&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20201225222030731.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2lkZXNpcmVjY3g=,size_16,color_FFFFFF,t_70&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;br/&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20201225222030662.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2lkZXNpcmVjY3g=,size_16,color_FFFFFF,t_70&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;br/&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20201225222030658.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2lkZXNpcmVjY3g=,size_16,color_FFFFFF,t_70&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;br/&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20201225222030657.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2lkZXNpcmVjY3g=,size_16,color_FFFFFF,t_70&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;br/&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20201225222030557.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2lkZXNpcmVjY3g=,size_16,color_FFFFFF,t_70&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;br/&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20201225222029835.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2lkZXNpcmVjY3g=,size_16,color_FFFFFF,t_70&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;br/&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20201225222029701.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2lkZXNpcmVjY3g=,size_16,color_FFFFFF,t_70&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;br/&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20201225222029648.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2lkZXNpcmVjY3g=,size_16,color_FFFFFF,t_70&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
</description>
<pubDate>Fri, 25 Dec 2020 15:29:00 +0000</pubDate>
<dc:creator>小新是也</dc:creator>
<og:description>Redis 中，字典是基础结构。Redis 数据库数据、过期时间、哈希类型都是把字典作为底层结构。 字典的结构 哈希表 哈希表的实现代码在：dict.h/dictht ，Redis 的字典用哈希表的方</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/chenchuxin/p/14191156.html</dc:identifier>
</item>
<item>
<title>Azure Terraform（一）入门简介 - Grant_Allen</title>
<link>http://www.cnblogs.com/AllenMaster/p/14188380.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/AllenMaster/p/14188380.html</guid>
<description>&lt;h2&gt;一，引言&lt;/h2&gt;
&lt;p&gt;　　众所周知，当企业将项目整体架构资源迁移到云上，云基础设施架构师就要根据现有项目搭建整体项目的基础设施资源的架构，然后我们的云运维工程师就要根据设计好基础设施的架构图来创建云上资源，但是在构筑的过程太单一，太传统。动动鼠标创建资源的方式成本太高，同时还有一定几率出错的风险，这种方式已经不适合现代企业迁移基础设施架构的方式。如果能够通过一种 IT 基础设施架构自动化编排工具来管理维护IT资源岂不能够大大降低企业在基础设施构建过程中成本问题，同时也可以提高云基础设施开发人员在 IAC(基础设施即代码) 方面的技能。&lt;/p&gt;
&lt;p&gt;　　Terraform ----- 是一个基础设施管理工具，它允许我们以代码的方式构建、更改和管理基础设施。Terraform 并不局限于任何特定的云服务提供商，它可以与多个云提供商和环境协同工作。虽然 Azure,AWS 分明有针对自己云平台的资源管理、设置的解决方案。&lt;/p&gt;
&lt;p&gt;（1）Azure：ARM 模板（ARM&lt;span data-ttu-id=&quot;3135f-115&quot;&gt;模板是一个定义项目基础结构和配置的 JavaScript 对象表示法 (JSON) 文件。 &lt;span data-ttu-id=&quot;3135f-116&quot;&gt;该模板使用声明性语法，使你可以指明要部署的内容，而不需要编写一系列编程命令来创建内容。 &lt;span data-ttu-id=&quot;3135f-117&quot;&gt;在该模板中，指定要部署的资源以及这些资源的属性。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;）&lt;/p&gt;
&lt;p&gt;（2）AWS：CloudFormation（AWS CloudFormation 是一项服务，可帮助您对 Amazon Web Services 资源进行建模和设置，以便能花较少的时间管理这些资源，而将更多的时间花在运行于 AWS 中的应用程序上。您创建一个描述您所需的所有 AWS 资源（如 Amazon EC2 实例或 Amazon RDS 数据库实例）的模板，并且 AWS CloudFormation 将负责为您设置和配置这些资源。）&lt;/p&gt;
&lt;p&gt;Terraform CLI 提供一种简单机制，用于将配置文件部署到 Azure 并对其进行版本控制，使用 Terraform 基于模板的配置文件，能够以可重复、可预测的方式定义、预配和配置 Azure 资源。&lt;/p&gt;
&lt;p&gt;在本系列博客文章中，我将详细介绍有关使用Terraform以及为Microsoft Azure基础结构设置持续部署和测试的一些最佳实践。&lt;/p&gt;
&lt;table border=&quot;0&quot;&gt;&lt;tbody readability=&quot;8&quot;&gt;&lt;tr&gt;&lt;td&gt; &lt;/td&gt;
&lt;td&gt;&lt;strong&gt;许可支持&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;模块化&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;状态管理&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;导入现有资源&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;可视化依赖&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;语言&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;验证&lt;/strong&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;16&quot;&gt;&lt;td&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1996262/202012/1996262-20201225153541332-1922180558.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/td&gt;
&lt;td&gt;免费、开源，来自 Hashicorp 和社区的支持&lt;/td&gt;
&lt;td&gt;Terraform Registry中提供了一些可用于模块化模板的功能介绍和使用示例。我们可以将这些独立的模块进行拼接，使得模块之间能够建立联系。&lt;/td&gt;
&lt;td&gt;默认情况下，将状态保存在本地，但是可以使用远程状态功能将状态保存在Terraform Cloud，Storage Account&lt;/td&gt;
&lt;td&gt;可以将现有资源导入terraform来管理&lt;/td&gt;
&lt;td&gt;可以使用terraform graph命令生成配置或执行计划的直观表示。&lt;/td&gt;
&lt;td&gt;HCL是Terraform的配置语言，它是HashiCorp发明的一种声明式语言&lt;/td&gt;
&lt;td&gt;提供了检查模板文件语法错误&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;h2&gt;二，正文&lt;/h2&gt;
&lt;h3&gt;1，下载并安装 Terraform&lt;/h3&gt;
&lt;p&gt;(1)，使用chocolatey 安装&lt;/p&gt;
&lt;p&gt; 需要安装Terraform，请使用 CMD 或者 PowerShell 中运行一下命令&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
choco install terraform
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;特意说明一下，我这里使用的是 chocolatey 包管理器进行下载安装 terraform&lt;/p&gt;
&lt;p&gt;chocolatey 安装方式：&lt;a href=&quot;https://chocolatey.org/install&quot; target=&quot;_blank&quot;&gt;https://chocolatey.org/install&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;(2)，下载terraform 安装包&lt;/p&gt;
&lt;p&gt;Terraform 下载链接：&lt;a href=&quot;https://www.terraform.io/downloads.html&quot; target=&quot;_blank&quot;&gt;https://www.terraform.io/downloads.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;记得下载完成的 Terraform 文件之后，将其配置到环境变量中&lt;/p&gt;
&lt;p&gt;两个方式安装完成后并且配置后，测试是否配置成功&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1996262/202012/1996262-20201225192653478-1462470138.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h3&gt;2，创建 Terraform 项目&lt;/h3&gt;
&lt;p&gt;打开 VS CODE 创建 terraform_demo_code 文件夹，并且在此文件夹中创建名为 “main.tf” 文件，作为基本的Terraform 配置文件&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1996262/202012/1996262-20201225194820327-2128904794.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;指定云提供者，配置资源组代码块，并保存&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;33&quot;&gt;
&lt;pre&gt;
provider &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;azurerm&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt; {
  version &lt;/span&gt;= &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;~&amp;gt;2.0&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;
  features {}
}

resource &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;azurerm_resource_group&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; &lt;span&gt;&quot;example&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt; {
  name &lt;/span&gt;= &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;Web_Test_TF_RG&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;
  location &lt;/span&gt;= &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;East Asia&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;3，初始化并执行Terraform &lt;/h3&gt;
&lt;p&gt;3.1，在初始化 terraform 部署之前，我们需要向Azure 进行验证身份，terraform 支持多种向Azure 进行身份验证的选项&lt;/p&gt;
&lt;p&gt;(1)，通过 Azure 账号登陆进行身份验证&lt;/p&gt;
&lt;p&gt;(2)，通过配置Azure 服务主题进行身份验证&lt;/p&gt;
&lt;p&gt;注意这里的方式的身份方式二选一，尽量不要&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;方式一，直接在 CMD 中执行&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;使用Azure 账号进行微软账号身份验证，输入登陆用户名，密码即可完成身份验证&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1996262/202012/1996262-20201225200203054-1206692530.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;提示已经登陆到微软Azure&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1996262/202012/1996262-20201225200254091-559873455.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;CMD 中也可以看到登陆成功的提示&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1996262/202012/1996262-20201225200417022-344457695.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;方式二，配置服务主体&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;span data-ttu-id=&quot;c9ee2-152&quot;&gt;创建一个具有“参与者”角色的服务主体。 &lt;span data-ttu-id=&quot;c9ee2-153&quot;&gt;此“参与者”角色（默认角色）具有读取和写入到 Azure 帐户的完全权限&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;这个可以参考我之前讲解的 &lt;a id=&quot;cb_post_title_url&quot; class=&quot;postTitle2 vertical-middle&quot; href=&quot;https://www.cnblogs.com/AllenMaster/p/13065643.html&quot;&gt;Azure AD（四）知识补充-服务主体&lt;/a&gt;，文中有介绍如何创建服务主题&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1996262/202012/1996262-20201225201747850-2129465783.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;接下来我们需要将生成好的 “appId”，“password”，&quot;tenant&quot;，“subscriptionid” 配置到环境变量中&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;33&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
setx ARM_SUBSCRIPTION_ID xxxx-xxxx-xxxx-xxxx
setx ARM_CLIENT_ID xxxx-xxxx-xxxx-xxxx     
setx ARM_CLIENT_SECRET xxxx-xxxx-xxxx-xxxx
setx ARM_TENANT_ID xxxx-xxxx-xxxx-xxxx
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;注意，我在此演示使用的时方法一&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;3.2，认证完成后，就可以开始执行Terraform 的初始化操作了&lt;/p&gt;
&lt;p&gt;CMD 中执行 terraform init 下载创建 Azure 资源组所需的 Azure 模块&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot;&gt;
&lt;pre&gt;
terraform init
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1996262/202012/1996262-20201225202534455-46342158.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;3.3，terraform plan 执行计划&lt;/p&gt;
&lt;p&gt;CMD 中执行 terraform plan 创建执行计划，这个执行计划可以理解为 terraform 会预处理执行，展示那些资源被创建，修改，删除，此执行计划不会真的执行，只验证执行计划是否符合预期&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
terraform plan
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1996262/202012/1996262-20201225203222973-1581655043.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;3.4，terraform apply 执行部署计划到云端&lt;/p&gt;
&lt;p&gt;CMD 中执行 terraform apply 执行部署计划&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
terraform apply
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;执行完成后，需要一个确认过程，输入 “yes” 确认同意此次操作&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1996262/202012/1996262-20201225203518925-2082917539.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;接下来，我们就可以通过控制台看到执行部署过程的日志信息，资源组创建完成&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1996262/202012/1996262-20201225203649189-432051645.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;为了检验真实性，我们登陆到Azure portal 中查看所以资源组，检查一下是否名为 &quot;Web_Test_TF_RG&quot; 的资源组被创建完成&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1996262/202012/1996262-20201225203902778-1355112623.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;bingo，大功告成。&lt;/p&gt;
&lt;p&gt;3.5，销毁通过 terraform 创建的资源&lt;/p&gt;
&lt;p&gt;撤销，销毁通过terraform 执行部署计划的资源，CMD 中执行 terraform destroy 执行部署销毁计划&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
terraform destroy
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;执行完成后，需要一个确认销毁的确认过程，输入 “yes” 确认同意此次操作&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1996262/202012/1996262-20201225204343146-601849912.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;接下来，我们就可以通过控制台看到执行销毁过程的日志信息，资源组被删除&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1996262/202012/1996262-20201225204605111-293258803.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;再次回到Azure Portal 中查看所有资源组，名为“Web_Test_TF_RG” 已经被删除&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1996262/202012/1996262-20201225204714607-281253932.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;*★,°*:.☆(￣▽￣)/$:*.°★* ，截至到现在，通过以上步骤，我们具备了在Microsoft Azure上开始使用Terraform的所有基础知识，创建，删除资源。&lt;/p&gt;
&lt;h2&gt;三，结尾&lt;/h2&gt;
&lt;p&gt;　　今天的内容不多，实战演示了通过  terraform 这种 iac 工具实现管理云基础设施，利用Terraform这把利器，节约资源开销，提高从部署到运维的自动化生产力。&lt;/p&gt;
&lt;p&gt;参考资料：&lt;a href=&quot;https://docs.microsoft.com/zh-cn/azure/developer/terraform/&quot; target=&quot;_blank&quot;&gt;Azure 上的Terraform&lt;/a&gt;&lt;a href=&quot;https://docs.microsoft.com/zh-cn/azure/developer/terraform/&quot; target=&quot;_blank&quot;&gt;&lt;br/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;作者：&lt;a href=&quot;https://www.cnblogs.com/AllenMaster&quot; target=&quot;_blank&quot;&gt;Allen&lt;/a&gt; &lt;/p&gt;
&lt;p&gt;版权：转载请在文章明显位置注明作者及出处。如发现错误，欢迎批评指正。&lt;/p&gt;
</description>
<pubDate>Fri, 25 Dec 2020 15:06:00 +0000</pubDate>
<dc:creator>Grant_Allen</dc:creator>
<og:description>一，引言 众所周知，当企业将项目整体架构资源迁移到云上，云基础设施架构师就要根据现有项目搭建整体项目的基础设施资源的架构，然后我们的云运维工程师就要根据设计好基础设施的架构图来创建云上资源，但是在构筑</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/AllenMaster/p/14188380.html</dc:identifier>
</item>
</channel>
</rss>