<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="css/feed.xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/" xmlns:og="http://ogp.me/ns#">
<channel>
<atom:link rel="self" href="http://192.168.1.4/fivefilters/makefulltextfeed.php?url=feed.cnblogs.com%2Fblog%2Fsitehome%2Frss&amp;max=10&amp;links=preserve&amp;exc=" />
<atom:link rel="alternate" title="Source URL" href="http://feed.cnblogs.com/blog/sitehome/rss" />
<atom:link rel="related" title="Subscribe to feed" href="http://www.subtome.com/#/subscribe?feeds=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed.cnblogs.com%252Fblog%252Fsitehome%252Frss%26max%3D10%26links%3Dpreserve%26exc%3D&amp;back=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed.cnblogs.com%252Fblog%252Fsitehome%252Frss%26max%3D10%26links%3Dpreserve%26exc%3D" />
<title>博客园_首页</title>
<link></link>
<description>代码改变世界</description>
<item>
<title>搭建博客、自己的小窝？快来看看这些开源静态网站生成器 - 削微寒</title>
<link>http://www.cnblogs.com/xueweihan/p/12401541.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/xueweihan/p/12401541.html</guid>
<description>&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/759200/202003/759200-20200303121153214-2099109889.jpg&quot;/&gt;&lt;/p&gt;
&lt;p&gt;作者：&lt;a href=&quot;https://chungzh.cn/&quot;&gt;HelloGitHub-ChungZH&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;相信很多人都想要搭建一个自己的博客或是给项目做文档网站。本文将要推荐的静态网站生成器（Static Site Generator, SSG），它做的事情就是把你的文档、内容（通常为 Markdown 文件）生成可发布成网站（html）的工具，这样你就可以专心创作，同时也有了一块自己发表自己想法的网站。然后 GitHub、Gitee 等均支持免费 Page 服务，通过简单的配置 SSG 就可以实现一条命令发布，有一个自己小窝就是这么简单和方便～&lt;/p&gt;
&lt;p&gt;下面就是 HelloGitHub 精心挑选的 GitHub 上流行、优秀的开源静态网站生成器，欢迎小伙伴们评鉴讨论。&lt;/p&gt;
&lt;h2 id=&quot;hexo&quot;&gt;1. Hexo&lt;/h2&gt;
&lt;p&gt;Hexo 使用 Node.js 开发，很流行。它有数以百计的主题和插件，支持 GFM（GitHub Flavored Markdown），只需要一条命令也能将 Hexo 网站部署到 GitHub Pages、Heroku 等平台上。目前 Vue.js 的官方文档就由它驱动着。不过 Hexo 的速度对比其他框架而言，并不算非常快。&lt;/p&gt;
&lt;p&gt;这里顺便安利一个 Hexo 的教程：&lt;a href=&quot;https://github.com/EasyHexo/Easy-Hexo&quot;&gt;EasyHexo&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/759200/202003/759200-20200303121214170-326802813.png&quot;/&gt;&lt;/p&gt;
&lt;h2 id=&quot;hugo&quot;&gt;2. Hugo&lt;/h2&gt;
&lt;p&gt;Hugo 使用 Go 语言开发，号称”世界上最快的网页生成器“。Stars 数量远高于 Hexo。目前有三百多个主题。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/759200/202003/759200-20200303121231361-563528303.png&quot;/&gt;&lt;/p&gt;
&lt;h3 id=&quot;vuepress&quot;&gt;3. VuePress&lt;/h3&gt;
&lt;p&gt;VuePress 在一众生成器之中算是一个”后起之秀“，起初由尤雨溪牵头开发。等发展到一定程度之后，将会取代 Hexo 成为 Vue.js 官方文档的生成器。它基于 Vue，可以在 Markdown 中使用 Vue 组件，又可以使用 Vue 来开发自定义主题。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/759200/202003/759200-20200303121242392-2139580320.png&quot;/&gt;&lt;/p&gt;
&lt;h2 id=&quot;mkdocs&quot;&gt;4. MkDocs&lt;/h2&gt;
&lt;p&gt;MkDocs 使用 Python 开发，更偏向于文档生成。用户不是特别多，只有十几个主题。&lt;/p&gt;
&lt;h2 id=&quot;gatsby&quot;&gt;5. Gatsby&lt;/h2&gt;
&lt;p&gt;Gatsby 作为 GitHub 上面 &lt;code&gt;#static-site-generator&lt;/code&gt; 话题最多 Star 数量的项目，基于 React。它超越了静态网站，更强大。可以从任何地方加载数据。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/759200/202003/759200-20200303121302190-1322217545.png&quot;/&gt;&lt;/p&gt;
&lt;h2 id=&quot;docsify&quot;&gt;6. Docsify&lt;/h2&gt;
&lt;p&gt;Docsify 同样基于 Vue，偏向于文档，动态生成网页，最大的特点是它只有一个 &lt;code&gt;index.html&lt;/code&gt;，在你打开网页的时候才开始生成。Docsify 还兼容 IE 11。缺点是对 SEO 并不太友好。&lt;/p&gt;
&lt;h2 id=&quot;jekyll&quot;&gt;7. Jekyll&lt;/h2&gt;
&lt;p&gt;Jekyll 使用 Ruby 开发，它足够简单，能够让你专注于内容。它有将近四百种主题和两百多个插件，光这两项就足以证明它的优秀。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/759200/202003/759200-20200303121318313-1640090701.png&quot;/&gt;&lt;/p&gt;
&lt;hr/&gt;&lt;p&gt;最后提醒一下大家，写博客最重要的是内容，所以你选好一个生成器、挑一个喜欢的主题之后，不要过度折腾、美化，内容才是最重要的。&lt;/p&gt;
&lt;hr/&gt;&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/759200/202002/759200-20200213201956024-782757549.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;关注公众号加入交流群&lt;/strong&gt;&lt;/p&gt;
</description>
<pubDate>Wed, 04 Mar 2020 00:20:00 +0000</pubDate>
<dc:creator>削微寒</dc:creator>
<og:description>作者： &amp;quot;HelloGitHub ChungZH&amp;quot; 相信很多人都想要搭建一个自己的博客或是给项目做文档网站。本文将要推荐的静态网站生成器（Static Site Generator</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/xueweihan/p/12401541.html</dc:identifier>
</item>
<item>
<title>机器学习基础——详解自然语言处理之tf-idf - TechFlow2019</title>
<link>http://www.cnblogs.com/techflow/p/12407502.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/techflow/p/12407502.html</guid>
<description>&lt;p&gt;本文始发于个人公众号：&lt;strong&gt;TechFlow&lt;/strong&gt;，原创不易，求个关注&lt;/p&gt;

&lt;p&gt;今天的文章和大家聊聊文本分析当中的一个简单但又大名鼎鼎的算法——&lt;strong&gt;TF-idf&lt;/strong&gt;。说起来这个算法是自然语言处理领域的重要算法，但是因为它太有名了，以至于虽然我不是从事NLP领域的，但在面试的时候仍然被问过好几次，可见这个算法的重要性。&lt;/p&gt;
&lt;p&gt;好在算法本身并不困难，虽然从名字上看疑惑重重，但是一旦理解了其中的原理，一切都水到渠成，再也不怕面试的时候想不起来了。废话不多说，我们进入正题。&lt;/p&gt;

&lt;h2 id=&quot;算法原理&quot;&gt;算法原理&lt;/h2&gt;

&lt;p&gt;TF-idf名字的中间用分隔号进行了分割，并且TF和idf都不像是人名，所以它其实是表明了这个算法是由TF和idf两个部分构成的。我们先来看TF的部分。&lt;/p&gt;

&lt;h3 id=&quot;tf的解释&quot;&gt;TF的解释&lt;/h3&gt;
&lt;p&gt;TF的英文全称是Term Frequency，Frequency很好理解就是频次、频率。而这个Term硬翻译是项的意思，联系上下文，它其实是指的文本当中的单词或者短语。所以结合起来，Term Frequency就是&lt;strong&gt;短语的频率&lt;/strong&gt;。其实如果你明白了它的意思，剩下的光凭猜测都可以猜测出一个大概。&lt;/p&gt;
&lt;p&gt;它的意思很朴素，就是字面意思，即一个单词在本文当中的重要性和它出现的频率有关。&lt;/p&gt;
&lt;p&gt;这个观点很直观，比如我们在网页搜索”&lt;strong&gt;TechFlow&lt;/strong&gt;“，出来的网站当中通篇连一个”TechFlow“都没有，显然这次搜索的质量很差。如果一个网站当中包含的”TechFlow“很多，那说明很有可能搜索正确，这个网站就是我们想要的。&lt;/p&gt;
&lt;p&gt;除此之外，它还可以反映单词的重要程度。如果在同一个文本当中，一个Term的出现频率比另一个大，那么一般情况下，显然它的重要程度也更大。&lt;/p&gt;
&lt;p&gt;据说早期的搜索引擎就是用的这个策略，它衡量用户搜索的关键词在各个网页文本当中出现的频率。倾向于将出现频率高的网页排在前面，由于排名靠前的网页能够获得大量的流量。所以由于利益的驱动，后来越来越多的网页倾向于在内容当中嵌入更多的&lt;strong&gt;搜索热词&lt;/strong&gt;，以此来获得更高的排名和更多的流量。相信大家也都有过类似的体会，当我们使用搜索引擎输入某个关键词，搜索出来的网页号称有相关的匹配，但是当我们真正点击进去却什么也没有发现，或者是满屏的广告。&lt;/p&gt;
&lt;p&gt;在早期的互联网当中存在大量这样的网页，它们以囊括更多的搜索热词为生。以此还衍生出了一个技术工种——SEO，即search engine optimization搜索引擎优化，专门用各种手段来替各大网页优化搜索引擎当中的排名。&lt;/p&gt;
&lt;p&gt;很快搜索引擎的工程师也都发现了这个问题，也正是为了解决这个问题，才引入了IDF的概念。&lt;/p&gt;

&lt;h2 id=&quot;idf的概念&quot;&gt;IDF的概念&lt;/h2&gt;

&lt;p&gt;IDF的英文是Inverse Document Frequency，即&lt;strong&gt;逆文档频率&lt;/strong&gt;。这个概念很难翻译，也很难直白地解释，所以往往我们还是使用它的英文缩写。它表达的意思也很简单，就是&lt;strong&gt;越广泛存在的Term越不重要&lt;/strong&gt;，也就是Term的重要性和出现的广泛性成反比。&lt;/p&gt;
&lt;p&gt;举个例子，最常用的”的“，”了“，”是的“这些单词肯定广泛出现在各个文章当中，而像是“搜索”，“机器学习”这些短语会出现的文章可能就要少得多。显然对于搜索引擎或者是一些其他模型而言，这些&lt;strong&gt;出现更少的单词的参考意义更大，因为往往意味着更加精准的导向&lt;/strong&gt;。所以IDF可以简单理解成出现广泛程度的倒数，它的定义也很简单：&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;math display&quot;&gt;\[\displaystyle idf_i=\log\frac{|D|}{1 + |\{j:t_i \in d_j \}|}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;其中&lt;span class=&quot;math inline&quot;&gt;\(|D|\)&lt;/span&gt;是所有文档的数量，&lt;span class=&quot;math inline&quot;&gt;\(t_i\)&lt;/span&gt;是第i个短语，&lt;span class=&quot;math inline&quot;&gt;\(|\{j:t_i \in d_j \}|\)&lt;/span&gt;表示包含第i个短语的文档的数量。为了防止它为0，我们为它加上一个常数1。同样，我们也可以写出TF的公式：&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;math display&quot;&gt;\[TF(t) = \frac{TF_i}{TN_t}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;分母的&lt;span class=&quot;math inline&quot;&gt;\(TN_t\)&lt;/span&gt;表示文章t当中包含的所有Term的数量，分子&lt;span class=&quot;math inline&quot;&gt;\(TF_i\)&lt;/span&gt;表示&lt;span class=&quot;math inline&quot;&gt;\(Term_i\)&lt;/span&gt;在文档中的数量。&lt;/p&gt;
&lt;p&gt;我们回顾一下这两个概念可以发现，TF衡量的是短语和文档的关系，而idf衡量的是短语和所有文档的关系。也就是说前者衡量的是短语对于某一个具体文档的重要性，而idf衡量的是短语对于所有文档的重要性。这两者有点像是局部和整体的关系，我们将两者相乘就可以得到一个Term兼容两者最终得到的重要性，也就是说TF-idf是用来&lt;strong&gt;计算短语在某个文档中重要性的算法&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;TF-idf的算法也很简单，我们&lt;strong&gt;直接将TF和idf计算得到的取值相乘&lt;/strong&gt;即可。&lt;/p&gt;
&lt;p&gt;算法的原理理解了之后，我们可以自己动手写一个计算TF-idf的算法，并不复杂，整个过程不超过40行：&lt;/p&gt;
&lt;pre class=&quot;python&quot;&gt;
&lt;code&gt;class TFIdfCalculator:

    # 初始化方法
    def __init__(self, text=[]):
        # 自定义的文本预处理，包括停用词过滤和分词，归一化等
        self.preprocessor = SimpleTextPreprocessing()
        # 防止用户只传了单条文本，做兼容处理
        if isinstance(text, list):
            rows = self.preprocessor.preprocess(text)
        else:
            rows = self.preprocessor.preprocess([text])

        self.count_list = []
        # 使用Counter来计算词频
        for row in rows:
            self.count_list.append(Counter(row))

    # fit接口，初始化工作
    def fit(self, text):
        self.__init__(text)

    # 计算词频，即单词出现次数除以总词数
    # 用在初始化之后
    def tf(self, word, count):
        return count[word] / sum(count.values())

    # 计算包含单词的文本数量
    def num_containing(self, word):
        return sum(1 for count in self.count_list if word in count)

    # 计算idf，即log(文档数除以出现次数+1)
    def idf(self, word):
        return math.log(len(self.count_list) / (1 + self.num_containing(word)))

    # 计算tfidf，即tf*idf
    def tf_idf(self, word, count_id):
        if isinstance(count_id, int) and count_id &amp;lt; len(self.count_list):
            return self.tf(word, self.count_list[count_id]) * self.idf(word)
        else:
            return 0.0&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;其中SimpleTextPreprocessing是我自己开发的一个进行文本预处理的类，包括分词、去除停用词以及词性归一化等基本操作。这些内容在之前朴素贝叶斯分类的文章当中曾经提到过，感兴趣的同学可以点击下方的链接进行查看。&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzUyMTM5OTM2NA==&amp;amp;mid=2247484188&amp;amp;idx=1&amp;amp;sn=cbe089c77c87b5467095633c4acb5be6&amp;amp;chksm=f9dafe37cead7721ce890be04ca429652327cabd34ea94404ef799237f31597c251040155e66&amp;amp;scene=21#wechat_redirect&quot;&gt;机器学习基础——朴素贝叶斯做文本分类代码实战&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;我们来实验一下代码：&lt;/p&gt;
&lt;pre class=&quot;python&quot;&gt;
&lt;code&gt;tfidf = TFIdfCalculator()
tfidf.fit(['go until jurong', 'point craze go', 'cine there got amore', 'cine point until'])
print(tfidf.tf_idf('jurong', 0))
print(tfidf.tf_idf('go', 0))&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;我们自己创建了一些无意义的文本进行调用，我们计算第一条文本当中go和jurong单词的重要程度。根据TFidf的定义，go出现在了第一条和第二条文本当中，它出现的次数更多，所以它的idf更小，并且两者在第一条文本当中出现的词频一致，所以应该jurong的TFidf更大。&lt;/p&gt;
&lt;p&gt;最后的结果也符合我们预期，jurong的TFidf是0.345，而go的TFidf是0.143。&lt;/p&gt;

&lt;h2 id=&quot;深度思考&quot;&gt;深度思考&lt;/h2&gt;

&lt;p&gt;TFidf的原理我们都理解了，代码也写出来了，看似圆满了，但其实有一个关键的点被我们忽略了。有一点很奇怪，为什么我们计算idf的时候需要对拟文本频率这个值&lt;strong&gt;求log&lt;/strong&gt;呢？虽然从结果上来看求了log之后的结果看起来更加正常，并且分布也更加合理。但这是结果不是原因，而从原理上来说，这个log出现的原因是什么呢？&lt;/p&gt;
&lt;p&gt;其实在TFidf这个理论出现的早期，并没有人想过这个问题，可以说是误打误撞。后来有大神从香农信息论的角度给与了解释，这一切才完美的自圆其说。&lt;/p&gt;
&lt;p&gt;在之前关于交叉熵的推导文章当中，我们曾经讨论过，如果存在一个事件A，它包含的信息量是&lt;span class=&quot;math inline&quot;&gt;\(-\log(P(A))\)&lt;/span&gt;，即它发生概率的对数。也就是说&lt;strong&gt;发生概率越小的事件，它的信息量越大&lt;/strong&gt;。这个log的出现是有玄机的，信息论的本质是将信息&lt;strong&gt;量化&lt;/strong&gt;。信息量化的结果是bit，也就是二进制位。我们都知道一个二进制位能够表示0和1两个数字，代表了2分量的信息。随着bit的增多，我们能表示的信息量也在增大，但是信息量不是线性增长的，而是&lt;strong&gt;指数&lt;/strong&gt;增长的。&lt;/p&gt;
&lt;p&gt;举个简单又经典的例子，32支球队挺近了世界杯，这其中只有一支球队能够获胜。假设最终获胜的是法国队、西班牙队，我们知道消息的时候并不会惊讶。而如果获胜的是日本队，估计所有人会大吃一惊。这背后的原因就和信息量有关，我们都知道虽然从表面上来看32支球队是平等的，哪一支都有获胜的可能，但是实际上各个球队获胜的概率是不同的。&lt;/p&gt;
&lt;p&gt;假设法国队、西班牙这种劲旅获胜的概率是1/4，&lt;span class=&quot;math inline&quot;&gt;\(-\log(\frac{1}{4})=2\)&lt;/span&gt;那么我们只需要2个bit就可以表示。假设日本队获胜的概率是1/128，那么我们需要7个bit才能表示，显然后者的信息量大得多。&lt;/p&gt;
&lt;p&gt;到这里，大家也就明白了，我们取对数的本质是计算信息量对应的bit的数量。bit的数量是线性的，信息量是指数级的，也就是说我们将一个指数级的信息量转化成了线性的bit。对于大多数模型而言，&lt;strong&gt;线性的特征更加容易拟合&lt;/strong&gt;，这也是TFidf效果出色的本质原因。&lt;/p&gt;
&lt;p&gt;最后，我们从信息论的角度解释一下idf，假设互联网世界当中所有的文档有&lt;span class=&quot;math inline&quot;&gt;\(2^{30}\)&lt;/span&gt;。现在用户搜索中美贸易战，其中包含中国和美国的文档数量都是&lt;span class=&quot;math inline&quot;&gt;\(2^{14}\)&lt;/span&gt;，那么中国和美国这两个词包含的信息量就是&lt;span class=&quot;math inline&quot;&gt;\(\log(\frac{2^{30}}{2^{14}})=16\)&lt;/span&gt;，而如果包含贸易战这个词的文档数量只有&lt;span class=&quot;math inline&quot;&gt;\(2^6\)&lt;/span&gt;，那么贸易战这个词包含的信息量就是&lt;span class=&quot;math inline&quot;&gt;\(\log(\frac{2^{30}}{2^6})=24\)&lt;/span&gt;，那么显然，贸易战这个词的信息量要比中国和美国大得多，那么它在文档排序当中起到的作用也就应该更大。&lt;/p&gt;
&lt;p&gt;如果你能从信息论的角度对TFidf的原理进行解释，而不只是简单地了解原理，那我觉得这个知识点才是真正掌握了，那么当你在面试当中遇到自然也就能游刃有余了。&lt;/p&gt;
&lt;p&gt;今天的文章就是这些，如果觉得有所收获，请顺手扫码点个&lt;strong&gt;关注&lt;/strong&gt;吧，你们的举手之劳对我来说很重要。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://user-gold-cdn.xitu.io/2020/3/4/170a2e28ff42888c?w=258&amp;amp;h=258&amp;amp;f=png&amp;amp;s=23988&quot;/&gt;&lt;/p&gt;
</description>
<pubDate>Wed, 04 Mar 2020 00:14:00 +0000</pubDate>
<dc:creator>TechFlow2019</dc:creator>
<og:description>本文始发于个人公众号： TechFlow ，原创不易，求个关注 今天的文章和大家聊聊文本分析当中的一个简单但又大名鼎鼎的算法—— TF idf 。说起来这个算法是自然语言处理领域的重要算法，但是因为它</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/techflow/p/12407502.html</dc:identifier>
</item>
<item>
<title>[ASP.NET Core 3框架揭秘]服务承载系统[3]:总体设计[上篇] - Artech</title>
<link>http://www.cnblogs.com/artech/p/inside-asp-net-core-09-03.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/artech/p/inside-asp-net-core-09-03.html</guid>
<description>&lt;div id=&quot;cnblogs_post_description&quot; readability=&quot;35&quot;&gt;&lt;img src=&quot;http://images.cnblogs.com/cnblogs_com/artech/158198/o_.netcore.png&quot; class=&quot;desc_img&quot;/&gt;前面的实例演示了服务承载的基本编程模式，接下来我们从设计的角度来重新认识服务承载模型。总的来说，服务承载模型主要由如下图所示的三个核心对象组成：多个通过IHostedService接口表示的服务被承载于通过IHost接口表示的宿主上，IHostBuilder接口表示IHost对象的构建者。&lt;/div&gt;&lt;div id=&quot;cnblogs_post_body&quot; readability=&quot;136.21355932203&quot;&gt;
&lt;p&gt;前面的实例演示了服务承载的基本编程模式，接下来我们从设计的角度来重新认识服务承载模型。总的来说，服务承载模型主要由如下图所示的三个核心对象组成：多个通过IHostedService接口表示的服务被承载于通过IHost接口表示的宿主上，IHostBuilder接口表示IHost对象的构建者。&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://img2018.cnblogs.com/blog/19327/202003/19327-20200304081134714-1632907511.png&quot;&gt;&lt;img width=&quot;347&quot; height=&quot;149&quot; title=&quot;10-7&quot; alt=&quot;10-7&quot; src=&quot;https://img2018.cnblogs.com/blog/19327/202003/19327-20200304081135235-86242359.png&quot; border=&quot;0&quot;/&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;承载的服务总是会被定义成IHostedService接口的实现类型。如下面的代码片段所示，该接口仅定义了两个用来启动和关闭自身服务的方法。当作为宿主的IHost对象被启动的时候，它会利用依赖注入框架激活每个注册的IHostedService服务，并通过调用StartAsync方法来启动它们。当服务承载应用程序关闭的时候，作为服务宿主的IHost对象会被关闭，由它承载的每个IHostedService服务对象的StopAsync方法也随之被调用。&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;33&quot;&gt;
&lt;pre&gt;
&lt;span&gt;public&lt;/span&gt; &lt;span&gt;interface&lt;/span&gt;&lt;span&gt; IHostedService
{
    Task StartAsync(CancellationToken cancellationToken);
    Task StopAsync(CancellationToken cancellationToken);
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;承载系统无缝集成了.NET Core的依赖注入框架，在服务承载过程中所需的依赖服务，包括承载服务自身和它所依赖的服务均由此框架提供，承载服务注册的本质就是将对应的IHostedService实现类型或者实例注册到依赖注入框架中。由于承载服务大都需要长时间运行直到应用被关闭，所以针对承载服务的注册一般采用&lt;span&gt;Singleton&lt;/span&gt;生命周期模式。承载系统为承载服务的注册定义了如下这个&lt;span&gt;AddHostedService&amp;lt;THostedService&amp;gt;&lt;/span&gt;扩展方法。由于该方法通过调用&lt;span&gt;TryAddEnumerable&lt;/span&gt;扩展方法来注册服务，所以不用担心服务重复注册的问题。&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;37&quot;&gt;
&lt;pre&gt;
&lt;span&gt;public&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;&lt;span&gt; ServiceCollectionHostedServiceExtensions
{
    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; IServiceCollection AddHostedService&amp;lt;THostedService&amp;gt;(&lt;span&gt;this&lt;/span&gt; IServiceCollection services) &lt;span&gt;where&lt;/span&gt; THostedService: &lt;span&gt;class&lt;/span&gt;&lt;span&gt;, IHostedService
    {
        services.TryAddEnumerable(ServiceDescriptor.Singleton&lt;/span&gt;&amp;lt;IHostedService, THostedService&amp;gt;&lt;span&gt;());
        &lt;/span&gt;&lt;span&gt;return&lt;/span&gt;&lt;span&gt; services;
    }
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;通过IHostedService接口表示的承载服务最终被承载于通过IHost接口表示的&lt;span&gt;宿主&lt;/span&gt;上。一般来说，一个服务承载应用在整个生命周期内只会创建一个IHost对象，&lt;span&gt;我们启动和关闭应用程序本质上就是启动和关闭作为宿主的IHost对象&lt;/span&gt;。如下面的代码片段所示，IHost接口派生于IDisposable接口，所以当它在关闭之后，应用程序还会调用其Dispose方法作一些额外的资源释放工作。IHost接口的Services属性返回作为依赖注入容器的IServiceProvider对象，该对象提供了服务承载过程中所需的服务实例，其中就包括需要承载的&lt;span&gt;IHostedService&lt;/span&gt;服务。定义在IHost接口中的StartAsync和StopAsync方法完成了针对服务宿主的启动和关闭。&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;34&quot;&gt;
&lt;pre&gt;
&lt;span&gt;public&lt;/span&gt; &lt;span&gt;interface&lt;/span&gt;&lt;span&gt; IHost : IDisposable
{
    IServiceProvider Services { &lt;/span&gt;&lt;span&gt;get&lt;/span&gt;&lt;span&gt;; }
    Task StartAsync(CancellationToken cancellationToken &lt;/span&gt;= &lt;span&gt;default&lt;/span&gt;&lt;span&gt;);
    Task StopAsync(CancellationToken cancellationToken &lt;/span&gt;= &lt;span&gt;default&lt;/span&gt;&lt;span&gt;);
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;在前面演示的实例中，在利用HostBuilder对象构建出IHost对象之后，我们并没有调用其StartAsync方法启动它，而是另一个名为Run的扩展方法。Run方法涉及到服务承载应用生命周期的管理，如果想了解该方法的本质，就得先来认识一个名为&lt;span&gt;IHostApplicationLifetime&lt;/span&gt;的接口。顾名思义，IHostApplicationLifetime接口体现了服务承载应用程序的生命周期。如下面的代码片段所示，该接口除了提供了三个CancellationToken类型的属性来检测应用何时开启与关闭之外，还提供了一个StopApplication来关闭应用程序。&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;34&quot;&gt;
&lt;pre&gt;
&lt;span&gt;public&lt;/span&gt; &lt;span&gt;interface&lt;/span&gt;&lt;span&gt; IHostApplicationLifetime
{
    CancellationToken ApplicationStarted { &lt;/span&gt;&lt;span&gt;get&lt;/span&gt;&lt;span&gt;; }
    CancellationToken ApplicationStopping { &lt;/span&gt;&lt;span&gt;get&lt;/span&gt;&lt;span&gt;; }
    CancellationToken ApplicationStopped { &lt;/span&gt;&lt;span&gt;get&lt;/span&gt;&lt;span&gt;; }

    &lt;/span&gt;&lt;span&gt;void&lt;/span&gt;&lt;span&gt; StopApplication();
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;如下所示的ApplicationLifetime类型是对IHostApplicationLifetime接口的默认实现。我们可以看到它实现的三个属性返回的CancellationToken对象来源于三个对应的CancellationTokenSource对象，后者对应着三个不同的方法（NotifyStarted、StopApplication和NotifyStopped）。我们可以利用IHostApplicationLifetime服务的三个属性提供的CancellationToken对象得到关于应用被启动和关闭通知，这些通知最初就是由这三个对应的方法发出来的。&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;41&quot;&gt;
&lt;pre&gt;
&lt;span&gt;public&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;&lt;span&gt; ApplicationLifetime : IHostApplicationLifetime
{
    &lt;/span&gt;&lt;span&gt;private&lt;/span&gt; &lt;span&gt;readonly&lt;/span&gt; ILogger&amp;lt;ApplicationLifetime&amp;gt;&lt;span&gt; _logger;
    &lt;/span&gt;&lt;span&gt;private&lt;/span&gt; &lt;span&gt;readonly&lt;/span&gt;&lt;span&gt; CancellationTokenSource _startedSource;
    &lt;/span&gt;&lt;span&gt;private&lt;/span&gt; &lt;span&gt;readonly&lt;/span&gt;&lt;span&gt; CancellationTokenSource _stoppedSource;
    &lt;/span&gt;&lt;span&gt;private&lt;/span&gt; &lt;span&gt;readonly&lt;/span&gt;&lt;span&gt; CancellationTokenSource _stoppingSource;

    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; ApplicationLifetime(ILogger&amp;lt;ApplicationLifetime&amp;gt;&lt;span&gt; logger)
    {
        _startedSource &lt;/span&gt;= &lt;span&gt;new&lt;/span&gt;&lt;span&gt; CancellationTokenSource();
        _stoppedSource &lt;/span&gt;= &lt;span&gt;new&lt;/span&gt;&lt;span&gt; CancellationTokenSource();
        _stoppingSource &lt;/span&gt;= &lt;span&gt;new&lt;/span&gt;&lt;span&gt; CancellationTokenSource();
        _logger &lt;/span&gt;=&lt;span&gt; logger;
    }

    &lt;/span&gt;&lt;span&gt;private&lt;/span&gt; &lt;span&gt;void&lt;/span&gt;&lt;span&gt; ExecuteHandlers(CancellationTokenSource cancel)
    {
        &lt;/span&gt;&lt;span&gt;if&lt;/span&gt; (!&lt;span&gt;cancel.IsCancellationRequested)
        {
            cancel.Cancel(&lt;/span&gt;&lt;span&gt;false&lt;/span&gt;&lt;span&gt;);
        }
    }

    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt;&lt;span&gt; NotifyStarted()
    {
        &lt;/span&gt;&lt;span&gt;try&lt;/span&gt;&lt;span&gt;
        {
            &lt;/span&gt;&lt;span&gt;this&lt;/span&gt;.ExecuteHandlers(&lt;span&gt;this&lt;/span&gt;&lt;span&gt;._startedSource);
        }
        &lt;/span&gt;&lt;span&gt;catch&lt;/span&gt;&lt;span&gt; (Exception exception)
        {
            _logger.ApplicationError(&lt;/span&gt;&lt;span&gt;6&lt;/span&gt;, &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;An error occurred starting the application&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;,exception);
        }
    }

    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt;&lt;span&gt; NotifyStopped()
    {
        &lt;/span&gt;&lt;span&gt;try&lt;/span&gt;&lt;span&gt;
        {
            ExecuteHandlers(&lt;/span&gt;&lt;span&gt;this&lt;/span&gt;&lt;span&gt;._stoppedSource);
        }
        &lt;/span&gt;&lt;span&gt;catch&lt;/span&gt;&lt;span&gt; (Exception exception)
        {
            _logger.ApplicationError(&lt;/span&gt;&lt;span&gt;8&lt;/span&gt;, &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;An error occurred stopping the application&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;,exception);
        }
    }

    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt;&lt;span&gt; StopApplication()
    {
        CancellationTokenSource source &lt;/span&gt;= &lt;span&gt;this&lt;/span&gt;&lt;span&gt;._stoppingSource;
        &lt;/span&gt;&lt;span&gt;lock&lt;/span&gt;&lt;span&gt; (source)
        {
            &lt;/span&gt;&lt;span&gt;try&lt;/span&gt;&lt;span&gt;
            {
                ExecuteHandlers(&lt;/span&gt;&lt;span&gt;this&lt;/span&gt;&lt;span&gt;._stoppingSource);
            }
            &lt;/span&gt;&lt;span&gt;catch&lt;/span&gt;&lt;span&gt; (Exception exception)
            {
                _logger.ApplicationError(&lt;/span&gt;&lt;span&gt;7&lt;/span&gt;, &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;An error occurred stopping the application&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;, exception);
            }
        }
    }

    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; CancellationToken ApplicationStarted =&amp;gt;&lt;span&gt; _startedSource.Token;
    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; CancellationToken ApplicationStopped =&amp;gt;&lt;span&gt; _stoppedSource.Token;
    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; CancellationToken ApplicationStopping =&amp;gt;&lt;span&gt; _stoppingSource.Token;
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;我们接下来通过一个简单的实例来演示如何利用IHostApplicationLifetime服务来关闭整个承载应用程序。我们在一个控制台应用程序中定义了如下这个承载服务FakeHostedService。在FakeHostedService类型的构造函数中，我们注入了IHostApplicationLifetime服务。在得到其三个属性返回的CancellationToken对象之后，我们在它们上面分别注册了一个回调，回调操作通过在控制台上输出相应的文字使我们可以知道应用程序何时被启动和关闭。&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;38&quot;&gt;
&lt;pre&gt;
&lt;span&gt;public&lt;/span&gt; &lt;span&gt;sealed&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;&lt;span&gt; FakeHostedService : IHostedService
{
    &lt;/span&gt;&lt;span&gt;private&lt;/span&gt; &lt;span&gt;readonly&lt;/span&gt;&lt;span&gt; IHostApplicationLifetime _lifetime;
    &lt;/span&gt;&lt;span&gt;private&lt;/span&gt;&lt;span&gt; IDisposable _tokenSource;

    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt;&lt;span&gt; FakeHostedService(IHostApplicationLifetime lifetime)
    {
        _lifetime &lt;/span&gt;=&lt;span&gt; lifetime;
        _lifetime.ApplicationStarted.Register(() &lt;/span&gt;=&amp;gt; Console.WriteLine(&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;[{0}]Application started&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;, DateTimeOffset.Now));
        _lifetime.ApplicationStopping.Register(() &lt;/span&gt;=&amp;gt; Console.WriteLine(&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;[{0}]Application is stopping.&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;, DateTimeOffset.Now));
        _lifetime.ApplicationStopped.Register(() &lt;/span&gt;=&amp;gt; Console.WriteLine(&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;[{0}]Application stopped.&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;, DateTimeOffset.Now));
    }

    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt;&lt;span&gt; Task StartAsync(CancellationToken cancellationToken)
    {
        _tokenSource &lt;/span&gt;= &lt;span&gt;new&lt;/span&gt; CancellationTokenSource(TimeSpan.FromSeconds(&lt;span&gt;5&lt;/span&gt;&lt;span&gt;)).Token.Register(_lifetime.StopApplication);
        &lt;/span&gt;&lt;span&gt;return&lt;/span&gt;&lt;span&gt; Task.CompletedTask;
    }

    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt;&lt;span&gt; Task StopAsync(CancellationToken cancellationToken)
    {
        _tokenSource&lt;/span&gt;?&lt;span&gt;.Dispose();
        &lt;/span&gt;&lt;span&gt;return&lt;/span&gt;&lt;span&gt; Task.CompletedTask;
    }
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;在实现的StartAsync方法中，我们采用如上的方式在5秒之后调用IHostApplicationLifetime服务的StopApplication方法来关闭整个应用程序。这个FakeHostedService服务最后采用如下的方式承载于当前应用程序中。&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;33&quot;&gt;
&lt;pre&gt;
&lt;span&gt;class&lt;/span&gt;&lt;span&gt; Program
{
    &lt;/span&gt;&lt;span&gt;static&lt;/span&gt; &lt;span&gt;void&lt;/span&gt;&lt;span&gt; Main()
    {
        &lt;/span&gt;&lt;span&gt;new&lt;/span&gt;&lt;span&gt; HostBuilder()
            .ConfigureServices(svcs &lt;/span&gt;=&amp;gt; svcs.AddHostedService&amp;lt;FakeHostedService&amp;gt;&lt;span&gt;())
            .Build()
            .Run();
    }
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;该程序运行之后会在控制台上输出如下图所示的结果，从三条消息产生的时间间隔我们可以确定当前应用程序正是承载FakeHostedService通过调用IHostApplicationLifetime服务的StopApplication方法关闭的。（源代码从&lt;a href=&quot;https://files.cnblogs.com/files/artech/S1007.7z&quot;&gt;这里&lt;/a&gt;下载）&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://img2018.cnblogs.com/blog/19327/202003/19327-20200304081135464-809814419.png&quot;&gt;&lt;img width=&quot;392&quot; height=&quot;144&quot; title=&quot;10-8&quot; alt=&quot;10-8&quot; src=&quot;https://img2018.cnblogs.com/blog/19327/202003/19327-20200304081135697-1898013145.png&quot; border=&quot;0&quot;/&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;如果我们调用IHost对象的扩展方法Run，它会在内部调用StartAsync方法，接下来它会持续等待下去直到接收到应用被关闭的通知。当IHost对象对象利用IHostApplicationLifetime服务接收到关于应用关闭的通知后，它会调用自身的StopAsync方法，针对Run方法的调用此时才会返回。启动IHost对象直到应用关闭这一实现体现在如下这个WaitForShutdownAsync扩展方法上。&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;38&quot;&gt;
&lt;pre&gt;
&lt;span&gt;public&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;&lt;span&gt; HostingAbstractionsHostExtensions
{
    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; &lt;span&gt;async&lt;/span&gt; Task WaitForShutdownAsync(&lt;span&gt;this&lt;/span&gt; IHost host, CancellationToken token = &lt;span&gt;default&lt;/span&gt;&lt;span&gt;)
    {
        &lt;/span&gt;&lt;span&gt;var&lt;/span&gt; applicationLifetime = host.Services.GetService&amp;lt;IHostApplicationLifetime&amp;gt;&lt;span&gt;();
        token.Register(state &lt;/span&gt;=&amp;gt;&lt;span&gt; ((IHostApplicationLifetime)state).StopApplication(), applicationLifetime);

        &lt;/span&gt;&lt;span&gt;var&lt;/span&gt; waitForStop = &lt;span&gt;new&lt;/span&gt; TaskCompletionSource&amp;lt;&lt;span&gt;object&lt;/span&gt;&amp;gt;&lt;span&gt;(TaskCreationOptions.RunContinuationsAsynchronously);
        applicationLifetime.ApplicationStopping.Register(state &lt;/span&gt;=&amp;gt;&lt;span&gt;
        {
            &lt;/span&gt;&lt;span&gt;var&lt;/span&gt; tcs = (TaskCompletionSource&amp;lt;&lt;span&gt;object&lt;/span&gt;&amp;gt;&lt;span&gt;)state;
            tcs.TrySetResult(&lt;/span&gt;&lt;span&gt;null&lt;/span&gt;&lt;span&gt;);
        }, waitForStop);

        &lt;/span&gt;&lt;span&gt;await&lt;/span&gt;&lt;span&gt; waitForStop.Task;
        &lt;/span&gt;&lt;span&gt;await&lt;/span&gt;&lt;span&gt; host.StopAsync();
    }
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;如下所示的WaitForShutdown方法是上面这个WaitForShutdownAsync方法的同步版本。同步的Run方法和异步的RunAsync方法的实现也体现在下面的代码片段中。除此之外，下面的代码片段还提供了Start和StopAsync这两个扩展方法，前者可以视为StartAsync方法的同步版本，后者可以在关闭IHost对象的时候指定一个超时时限。&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;37&quot;&gt;
&lt;pre&gt;
&lt;span&gt;public&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;&lt;span&gt; HostingAbstractionsHostExtensions
{
    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; WaitForShutdown(&lt;span&gt;this&lt;/span&gt; IHost host) =&amp;gt;&lt;span&gt; host.WaitForShutdownAsync().GetAwaiter().GetResult();
    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; Run(&lt;span&gt;this&lt;/span&gt; IHost host) =&amp;gt;&lt;span&gt; host.RunAsync().GetAwaiter().GetResult();
    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; &lt;span&gt;async&lt;/span&gt; Task RunAsync(&lt;span&gt;this&lt;/span&gt; IHost host, CancellationToken token = &lt;span&gt;default&lt;/span&gt;&lt;span&gt;)
    {
        &lt;/span&gt;&lt;span&gt;try&lt;/span&gt;&lt;span&gt;
        {
            &lt;/span&gt;&lt;span&gt;await&lt;/span&gt;&lt;span&gt; host.StartAsync(token);
            &lt;/span&gt;&lt;span&gt;await&lt;/span&gt;&lt;span&gt; host.WaitForShutdownAsync(token);
        }
        &lt;/span&gt;&lt;span&gt;finally&lt;/span&gt;&lt;span&gt;
        {
            host.Dispose();
        }
    }
    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; Start(&lt;span&gt;this&lt;/span&gt; IHost host) =&amp;gt;&lt;span&gt; host.StartAsync().GetAwaiter().GetResult();
    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; Task StopAsync(&lt;span&gt;this&lt;/span&gt; IHost host, TimeSpan timeout) =&amp;gt; host.StopAsync(&lt;span&gt;new&lt;/span&gt;&lt;span&gt; CancellationTokenSource(timeout).Token);
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;a href=&quot;https://www.cnblogs.com/artech/p/inside-asp-net-core-09-01.html&quot;&gt;服务承载系统[1]: 承载长时间运行的服务[上篇]&lt;/a&gt;&lt;br/&gt;&lt;a href=&quot;https://www.cnblogs.com/artech/p/inside-asp-net-core-09-02.html&quot;&gt;服务承载系统[2]: 承载长时间运行的服务[下篇]&lt;/a&gt;&lt;br/&gt;&lt;a href=&quot;https://www.cnblogs.com/artech/p/inside-asp-net-core-09-03.html&quot;&gt;服务承载系统[3]: 总体设计[上篇]&lt;/a&gt;&lt;br/&gt;&lt;a href=&quot;https://www.cnblogs.com/artech/p/inside-asp-net-core-09-04.html&quot;&gt;服务承载系统[4]: 总体设计[下篇]&lt;/a&gt;&lt;br/&gt;&lt;a href=&quot;https://www.cnblogs.com/artech/p/inside-asp-net-core-09-05.html&quot;&gt;服务承载系统[5]: 承载服务启动流程[上篇]&lt;/a&gt;&lt;br/&gt;&lt;a href=&quot;https://www.cnblogs.com/artech/p/inside-asp-net-core-09-06.html&quot;&gt;服务承载系统[6]: 承载服务启动流程[下篇]&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;</description>
<pubDate>Wed, 04 Mar 2020 00:12:00 +0000</pubDate>
<dc:creator>Artech</dc:creator>
<og:description>前面的实例演示了服务承载的基本编程模式，接下来我们从设计的角度来重新认识服务承载模型。总的来说，服务承载模型主要由如下图所示的三个核心对象组成：多个通过IHostedService接口表示的服务被承载</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/artech/p/inside-asp-net-core-09-03.html</dc:identifier>
</item>
<item>
<title>Nginx之常用基本配置（三） - Linux-1874</title>
<link>http://www.cnblogs.com/qiuhom-1874/p/12398242.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/qiuhom-1874/p/12398242.html</guid>
<description>&lt;p&gt;　　前面我们聊了下了Nginx作为WEB服务器对客户端请求相关配置，文件操作优化、Nginx访问控制、basic验证，、状态模块状态页、gzip压缩配置；回顾请参考&lt;a href=&quot;https://www.cnblogs.com/qiuhom-1874/p/12381331.html&quot; target=&quot;_blank&quot;&gt;https://www.cnblogs.com/qiuhom-1874/p/12381331.html&lt;/a&gt;；今天我们来聊一聊日志模块、ssl模块、rewrite模块；&lt;/p&gt;
&lt;p&gt;　　一、ngx_http_log_module：此模块作用是指定nginx的访问日志格式；&lt;/p&gt;
&lt;p&gt;　　　　log_format name [escape=default|json|none] string ...;此指令就是用来定义ngxin访问日志的格式，其中escape这个参数允许设置在变量中转义的json或默认字符，默认情况下使用默认转义，none表示禁止转义。string可以使用nginx核心模块及其它模块内嵌的变量；注意这个指令只用于http配置段中，用于定义日志格式，后面对所有虚拟主机都可以在定义日志文件时可以调用定义的日志格式；&lt;/p&gt;
&lt;p&gt;　　　　access_log path [format [buffer=size] [gzip[=level]] [flush=time] [if=condition]];指定日志文件路径，其中buffer=size表示指定日志缓冲区大小，gzip=level表示指定日志压缩级别，fulsh=time表示指定日志每隔多久就把缓冲区的日志内容存到磁盘文件中去；&lt;/p&gt;
&lt;p&gt;　　示例：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/i-beta/1503305/202003/1503305-20200302202831743-1312956053.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt; 　　提示：以上配置表示定义一个日志格式其名称是 main ，后面用单引号引起来的部分就是日志格式内容，其中$remote_addr表示客户端ip这个值不一定是客户端ip，这个要看应用环境，如果nginx服务器前面有代理服务器，这个变量就会记录前端代理的ip，如果nginx是直接面向客户端，那么这个值就是记录客户端ip，具体它记录那个ip 这个要看应用环境；$remote_user表示远端用户，如果我们配置的网站有验证的话，这个值就是记录的是用于验证的用户名，如果没有则默认就是“-”；$time_local表示本地服务器时间；$request表示客户端使用的方法请求资源路径，以及http协议版本；$status这个变量记录客户端请求服务器资源时的响应状态码；$body_bytes_sent这个变量记录客户端访问服务器时响应体的字节数，这个字节数不包含响应头部；$http_referer此变量记录客户端的referer信息；referer是http头部的一部分，通常情况下客户端浏览器访问web服务器时，都会把这个referer信息带上，目的是告诉服务器本次请求是从那个页面链接过来的；$http_user_agent此变量记录客户端的User_Agent信息，User_Agent也是http头部的一部分，客户端访问web服务器时会带上这个信息，目的就是告诉服务器客户端的操作系统类型，版本，浏览器信息等；$http_x_forwarded_for这个变量用于记录客户端真实IP，如果客户端是通过代理访问本服务器，那么这个值不是记录代理客户端的IP，而是客户端真实IP信息；更多内建变量可参考&lt;a href=&quot;http://nginx.org/en/docs/http/ngx_http_core_module.html#variables&quot; target=&quot;_blank&quot;&gt;http://nginx.org/en/docs/http/ngx_http_core_module.html#variables&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;　　定义好上面的日志格式，我们可以通过access_log 来指定存放日志的文件路径并明确指定用我们定义的日志格式“main”,当我们浏览器访问web服务器时，服务端就会以我们定义的格式记录日志，如下所示&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/i-beta/1503305/202003/1503305-20200302210830486-1506191982.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt; 　　　　open_log_file_cache max=N [inactive=time] [min_uses=N] [valid=time];指定缓存各日志文件相关的元数据信息；其中max=N表示缓存的最大文件描述符数量，如果满了就用LRU算法清理缓存；inactive=time表示指定非活动时长，&lt;span class=&quot;tgt&quot; data-group=&quot;0-0&quot; data-section=&quot;0&quot; data-sentence=&quot;0&quot;&gt;&lt;span class=&quot;tgt&quot; data-group=&quot;0-1&quot; data-section=&quot;0&quot; data-sentence=&quot;1&quot;&gt;默认情况下，10秒；&lt;/span&gt;&lt;/span&gt;min_user=N表示在inactive指定的时长内访问大于等于此值方可被当作活动项；；vaild=time指定验正缓存中各缓存项是否为活动项的时间间隔；&lt;/p&gt;
&lt;p&gt;　　二、ngx_http_ssl_module：此模块实现nginx基于https提供web服务&lt;/p&gt;
&lt;p&gt;　　　　ssl on | off;启用或禁用ssl功能&lt;/p&gt;
&lt;p&gt;　　　　ssl_certificate file;设置当前虚拟主机的证书&lt;/p&gt;
&lt;p&gt;　　　　ssl_certificate_key file;设置当前虚拟主机证书私钥文件&lt;/p&gt;
&lt;p&gt;　　　　ssl_protocols [SSLv2] [SSLv3] [TLSv1] [TLSv1.1] [TLSv1.2];支持ssl协议版本，默认为后三个；&lt;/p&gt;
&lt;p&gt;　　　　ssl_session_cache off | none | [builtin[:size]] [shared:name:size];其中builtin[:size]表示使用OpenSSL内建的缓存，此缓存为每worker进程私有；[shared:name:size]：表示在各worker之间使用一个共享的缓存；&lt;/p&gt;
&lt;p&gt;　　　　ssl_session_timeout time;客户端一侧的连接可以复用ssl session cache中缓存 的ssl参数的有效时长；&lt;/p&gt;
&lt;p&gt;　　示例：&lt;/p&gt;
&lt;p&gt;　　　　要让nginx工作为https服务器，首先我们要对其申请证书，有关CA服务器搭建，以及证书申请相关原理说明请参考&lt;a href=&quot;https://www.cnblogs.com/qiuhom-1874/p/12237944.html&quot; target=&quot;_blank&quot;&gt;https://www.cnblogs.com/qiuhom-1874/p/12237944.html&lt;/a&gt;，这里说下过程，首先我们要准备一台CA（可以是本机），然后在nginx服务器上生成证书申请文件，然后把该文件发送给CA服务器，然后CA服务器签发证书申请文件生成对应的证书，然后CA把签好的证书文件发给nginx服务器，然后nginx服务器拿到证书后在配置文件中配置使用证书即可，当然以上步骤也可以直接在CA上做，最后把生成的私钥文件和证书发送给nginx服务器，过程入下；&lt;/p&gt;
&lt;p&gt;　　　　1、搭建CA，其实很简单，所谓CA就是生成一个自签名证书即可&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;38&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
[root@test ~]# cd /etc/pki/CA/
[root@test CA]# tree
.
├── certs
├── crl
├── newcerts
└── private

4 directories, 0 files
[root@test CA]# (umask 077;openssl genrsa -out private/cakey.pem 2048)
Generating RSA private key, 2048 bit long modulus
...+++
...................+++
e is 65537 (0x10001)
[root@test CA]# tree
.
├── certs
├── crl
├── newcerts
└── private
    └── cakey.pem

4 directories, 1 file
[root@test CA]#
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　提示：以上是生成CA私钥&lt;/p&gt;
&lt;p&gt;　　2、生成自签名证书&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;42&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
[root@test CA]# openssl req -new -x509 -key private/cakey.pem -out cacert.pem -days 3650
You are about to be asked to enter information that will be incorporated
into your certificate request.
What you are about to enter is what is called a Distinguished Name or a DN.
There are quite a few fields but you can leave some blank
For some fields there will be a default value,
If you enter '.', the field will be left blank.
-----
Country Name (2 letter code) [XX]:CN
State or Province Name (full name) []:SICHUAN
Locality Name (eg, city) [Default City]:GUANGYUAN
Organization Name (eg, company) [Default Company Ltd]:TEST
Organizational Unit Name (eg, section) []:DEVOPS
Common Name (eg, your name or your server's hostname) []:ca.ilinux.io
Email Address []:
[root@test CA]# touch index.txt
[root@test CA]# echo 01 &amp;gt;serial
[root@test CA]# tree
.
├── cacert.pem
├── certs
├── crl
├── index.txt
├── newcerts
├── private
│   └── cakey.pem
└── serial

4 directories, 4 files
[root@test CA]# 
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　提示：到此CA就准备好了&lt;/p&gt;
&lt;p&gt;　　3、准备nginx服务器证书私钥和服务器证书申请文件&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;42&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
[root@www ~]# mkdir /etc/nginx/ssl
[root@www ~]# cd /etc/nginx/ssl
[root@www ssl]# ls
[root@www ssl]# (umask 077;openssl genrsa -out nginx.key 2048)
Generating RSA private key, 2048 bit long modulus
.........................................+++
.......+++
e is 65537 (0x10001)
[root@www ssl]# ll
total 4
-rw------- 1 root root 1679 Mar  2 23:06 nginx.key
[root@www ssl]# openssl req -new -key nginx.key -out nginx.csr 
You are about to be asked to enter information that will be incorporated
into your certificate request.
What you are about to enter is what is called a Distinguished Name or a DN.
There are quite a few fields but you can leave some blank
For some fields there will be a default value,
If you enter '.', the field will be left blank.
-----
Country Name (2 letter code) [XX]:CN
State or Province Name (full name) []:SICHUAN
Locality Name (eg, city) [Default City]:GUANGYUAN
Organization Name (eg, company) [Default Company Ltd]:TEST
Organizational Unit Name (eg, section) []:DEVOPS
Common Name (eg, your name or your server's hostname) []:www.ilinux.io
Email Address []:

Please enter the following 'extra' attributes
to be sent with your certificate request
A challenge password []:
An optional company name []:
[root@www ssl]# ll
total 8
-rw-r--r-- 1 root root 1009 Mar  2 23:07 nginx.csr
-rw------- 1 root root 1679 Mar  2 23:06 nginx.key
[root@www ssl]#
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　提示：到此nginx服务器的证书申请文件就做好了，我们只需要把这个申请文件发送给CA&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;33&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
[root@www ssl]# scp -P 41319 nginx.csr qiuhom@192.168.0.99:/tmp/
qiuhom@192.168.0.99's password: 
nginx.csr                                                     100% 1009   225.4KB/s   00:00    
[root@www ssl]# 
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　提示：如果SSH没有工作在标准端口，用scp命令时需要用-P（大写）指定ssh端口&lt;/p&gt;
&lt;p&gt;　　4、CA签发nginx证书&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;37&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
[root@test CA]# openssl ca -in /tmp/nginx.csr -out certs/nginx.pem -days 365
Using configuration from /etc/pki/tls/openssl.cnf
Check that the request matches the signature
Signature ok
Certificate Details:
        Serial Number: 1 (0x1)
        Validity
            Not Before: Mar  2 15:11:02 2020 GMT
            Not After : Mar  2 15:11:02 2021 GMT
        Subject:
            countryName               = CN
            stateOrProvinceName       = SICHUAN
            organizationName          = TEST
            organizationalUnitName    = DEVOPS
            commonName                = www.ilinux.io
        X509v3 extensions:
            X509v3 Basic Constraints: 
                CA:FALSE
            Netscape Comment: 
                OpenSSL Generated Certificate
            X509v3 Subject Key Identifier: 
                F7:76:62:31:04:D8:CE:0E:6E:CD:C5:14:05:EF:7F:E4:A5:AD:A0:91
            X509v3 Authority Key Identifier: 
                keyid:D5:61:A5:2F:BF:67:51:78:D7:5D:F8:51:F4:3C:FB:22:F9:E5:A7:3B

Certificate is to be certified until Mar  2 15:11:02 2021 GMT (365 days)
Sign the certificate? [y/n]:y


1 out of 1 certificate requests certified, commit? [y/n]y
Write out database with 1 new entries
Data Base Updated
[root@test CA]# tree
.
├── cacert.pem
├── certs
│   └── nginx.pem
├── crl
├── index.txt
├── index.txt.attr
├── index.txt.old
├── newcerts
│   └── 01.pem
├── private
│   └── cakey.pem
├── serial
└── serial.old

4 directories, 9 files
[root@test CA]# 
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　提示：我们只需要把签好的证书发送给nginx服务器即可&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;35&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
[root@test CA]# scp certs/nginx.pem 192.168.0.30:/etc/nginx/ssl/
The authenticity of host '192.168.0.30 (192.168.0.30)' can't be established.
ECDSA key fingerprint is SHA256:EG9nua4JJuUeofheXlgQeL9hX5H53JynOqf2vf53mII.
ECDSA key fingerprint is MD5:57:83:e6:46:2c:4b:bb:33:13:56:17:f7:fd:76:71:cc.
Are you sure you want to continue connecting (yes/no)? yes
Warning: Permanently added '192.168.0.30' (ECDSA) to the list of known hosts.
root@192.168.0.30's password: 
nginx.pem                                                             100% 4464     2.1MB/s   00:00    
[root@test CA]# 
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　提示：到此CA的工作就完成了，接下来我们直接在nginx服务器上直接配置ngxin使用证书&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;35&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
[root@www conf.d]# cat login.conf 
server {
        listen 443 ssl;
        server_name 192.168.0.30;
        root /data/web/html;
        gzip on;
        gzip_types text/xml text/plain;
        gzip_disable Firefox;
        location /basic_status {
                stub_status;
                auth_basic &quot;please input you username and passwd login&quot;;
                auth_basic_user_file /etc/nginx/conf.d/.ngxpasswd;
        }
        ssl_certificate &quot;/etc/nginx/ssl/nginx.pem&quot;;
        ssl_certificate_key &quot;/etc/nginx/ssl/nginx.key&quot;;
        ssl_protocols sslv2 sslv3 tlsv1 tlsv1.1 tlsv1.2;
        ssl_session_cache shared:SSL:10m;


}
[root@www conf.d]# nginx -t
nginx: the configuration file /etc/nginx/nginx.conf syntax is ok
nginx: configuration file /etc/nginx/nginx.conf test is successful
[root@www conf.d]# nginx -s reload
[root@www conf.d]# 
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　验证：用浏览器访问下看看我们配置的证书是否生效&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/i-beta/1503305/202003/1503305-20200303000443038-1866606507.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt; 　　提示：出现这个界面上正常的，因为我们的CA是自己搭建的，浏览器默认不认识，我们可以把CA证书导入浏览器就不会存在这个问题了，接下来我们把CA证书导入浏览器吧&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1503305/202003/1503305-20200303003038277-169619268.gif&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　提示：windows默认是通过后缀来识别文件，所以把CA证书放到windows上后需要更改为.crt为后缀即可.&lt;/p&gt;
&lt;p&gt;　　导入CA的证书后，我们再来用浏览器访问下我们的网站是否还会提示不是私密连接呢？&lt;/p&gt;
&lt;p&gt; &lt;img src=&quot;https://img2020.cnblogs.com/blog/1503305/202003/1503305-20200303011100195-66150323.gif&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　我们导入CA证书后，我们重新打开浏览器访问网站，就没有提示不是私密连接了，同时我们访问我们网站也是基于https访问，不再是http;以上就是nginx工作成https服务器搭建过程；&lt;/p&gt;
&lt;p&gt; 　　三、ngx_http_rewrite_module：此模块用于使用PCRE正则表达式查找匹配用户请求的URI，返回重定向和有条件地选择配置来更改请求URI。本质上就是查找替换的过程，用户请求的url通过正则匹配，然后用其他url或uri进行替换，随后把新的url或uri返回给客户端，由客户端重新对新的URL或URI发送请求；&lt;/p&gt;
&lt;p&gt;　　1、rewrite regex replacement [flag]：将用户请求的URI基于regex所描述的模式进行检查，匹配到时将其替换为replacement指定的新的URI；注意：如果在同一级配置块中存在多个rewrite规则，那么会自上而下逐个检查；被某条件规则替换完成后，会重新一轮的替换检查，因此，隐含有循环机制；[flag]所表示的标志位用于控制此循环机制；如果replacement是以http://或https://开头，则替换结果会直接以重向返回给客户端；其中flag有四种，last表示重写完成后停止对当前URI在当前location中后续的其它重写操作，而后对新的URI启动新一轮重写检查；提前重启新一轮循环； 这个也是默认行为，有点类似continue指令的意思，不退出循环，只是退出当次循环，提前进入下次循环；break表示重写完成后停止对当前URI在当前location中后续的其它重写操作，而后直接跳转至重写规则配置块之后的其它配置；结束循环；这个我们可以理解为循环里的break指令，直接跳出循环，进行下面的配置指令；redirect表示重写完成后以临时重定向方式直接返回重写后生成的新URI给客户端，由客户端重新发起请求；不能以http://或https://开头；permanent表示重写完成后以永久重定向方式直接返回重写后生成的新URI给客户端，由客户端重新发起请求；这四个值的区别是，前两个浏览器上都看不到跳转（用户是看不到明确的跳转），后两者者看得到；&lt;/p&gt;
&lt;p&gt;　　示例：&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;32&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
rewrite /(.*)$ https://www.ilinux.io/basic_status;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　提示：以上配置表示客户端访问我们服务器的任何uri都给重写为https://www.ilinux.io/basic_status这个url&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1503305/202003/1503305-20200303231945123-876721191.gif&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　提示：之所以能够看到302的响应码是因为我们在规则里把用户的rul重写成https://www.ilinux.io/basic_status ，浏览器看到重写后的URL是以https开头的，它就会拿着这个url去请求新的URL，所以我们这里可以看到302响应码；&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/i-beta/1503305/202003/1503305-20200303232704729-1055884023.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt; 　　提示：以上配置表示，用户访问.jpg结尾的URL时，我们都对它重写为访问/test/test.html&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1503305/202003/1503305-20200303233706077-1841249145.gif&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　提示：我们对用户请求的url进行替换时，没有用到http或https去替换时，我们在浏览器上是看不到后面浏览器重新对新的url发起请求的请求信息，这是我们重写规则默认使用了last，last和break如果都不以http或https去替换用户的rul，在浏览器是看不到跳转的响应码，要想看到该过程我们可以在后面加redirect或者permanent，它俩的区别在于，一个是临时重定向，响应码是302，一个是永久重定向响应码是301；如下&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;32&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
 rewrite /(.*)\.jpg  /test/ redirect;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　提示：我们只在上面的配置上在rewrite规则上加了一个redirect标记，加上它，浏览器就会对新的uri发起新的请求，如下&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1503305/202003/1503305-20200303234609520-913891079.gif&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　2、return：停止处理并将指定的响应码或URL返回给客户端&lt;/p&gt;
&lt;p&gt;　　　　return code [text];表示返回状态码或简短原因短语&lt;/p&gt;
&lt;p&gt;　　　　return code URL;返回状态码和url&lt;/p&gt;
&lt;p&gt;　　　　return URL;返回url&lt;/p&gt;
&lt;p&gt;　　3、rewrite_log on | off;是否开启重写日志&lt;/p&gt;
&lt;p&gt;　　4、if(condition) {……};引入一个新的配置上下文；条件满足时执行配置块中的配置指令；可用在server和location配置段中；这里的条件可以是变量，如果变量是字符串，非空为真，空为假；如果变量是数字则非0为真，0为假；当然条件也可以是一个比较表达式，所谓表达式就是由操作符连接起来的式子，常用的操作符有比较操作符，文件及目录存在性判断；比较操作符有：== 、!= 、～表示模式匹配，区分字符大小写；～*表示模式匹配，不区分字符大小写；!~表示模式不匹配，区分字符大小写；!~*表示模式不匹配，不区分字符大小写；文件及目录存在性判断的有 -e，!-e、-f，!-f、-d,!-d,、-x，!-x，这里的文件或目录存在性判断同shell里面的文件或目录存在性判断是一样的；&lt;/p&gt;
&lt;p&gt;　　5、set $variable value;设置用户指定以变量；&lt;/p&gt;
&lt;p&gt;　　示例：&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;34&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
if ($http_user_agent ~ MSIE) {
    rewrite ^(.*)$ /msie/$1 break;
}

if ($http_cookie ~* &quot;id=([^;]+)(?:;|$)&quot;) {
    set $id $1;
}

if ($request_method = POST) {
    return 405;
}

if ($slow) {
    limit_rate 10k;
}

if ($invalid_referer) {
    return 403;
}
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　提示：第一个if表示判断用户浏览器类型，如果匹配MSIE 则进行url重写，重写为/msie/$1 ，这里的$1表示rewrite规则里匹配到第一个括号里的内容的引用，和sed命令里的\1类似；第二个if表示判断变量$http_cookie 里的值是否匹配后面的正则表达式，如果匹配则设置$id变量的值为$1,这里的$1表示正则表达式里括号分组匹配到的内容；第三个if表示判断用户请求的方法是否是POST，如果是就返回405，意思就是不让用户用POST方法提交数据；第五个if表示判断$slow是否为空，不为空就设置limit_rate 10k,意思就是如果$slow的值为真，则限制客户端的响应；最后一个if表示判断$invalid_referer 是否为空，为空表示没有非法的referer，没有非法referer就不做处理，如果有非法referer，即不为空，则返回403，这是一个防盗链的配置；通常我们要先定义合法的referer,然后再来判断非法referer来实现防盗链（定义了合法的referer后相对的不在合法的referer列表里就表示非法的referer）；合法referer的定义可以用valid_referers来指定；&lt;/p&gt;
</description>
<pubDate>Tue, 03 Mar 2020 16:44:00 +0000</pubDate>
<dc:creator>Linux-1874</dc:creator>
<og:description>前面我们聊了下了Nginx作为WEB服务器对客户端请求相关配置，文件操作优化、Nginx访问控制、basic验证，、状态模块状态页、gzip压缩配置；回顾请参考https://www.cnblogs.</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/qiuhom-1874/p/12398242.html</dc:identifier>
</item>
<item>
<title>Spring Boot 2.x基础教程：使用 ECharts 绘制各种华丽的数据图表 - 程序猿DD</title>
<link>http://www.cnblogs.com/didispace/p/12405821.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/didispace/p/12405821.html</guid>
<description>&lt;p&gt;&lt;a href=&quot;http://blog.didispace.com/spring-boot-learning-21-4-1/&quot;&gt;上一节&lt;/a&gt;我们介绍了如何在Spring Boot中使用模板引擎Thymeleaf开发Web应用的基础。接下来，我们介绍一下后端开发经常会遇到的一个场景：可视化图表。&lt;/p&gt;
&lt;p&gt;通常，这类需求在客户端应用中不太会用到，但是在后端的各种统计分析模块会经常碰到。比如：通过折线图、柱状图、雷达图等可视化形式，更直观的展现和分析经营状况或系统运行情况。这里我们将引入的数据可视化组件库 ECharts来帮助我们完成这样的任务。&lt;/p&gt;
&lt;h2 id=&quot;echarts简介&quot;&gt;ECharts简介&lt;/h2&gt;
&lt;p&gt;ECharts是百度开源的一个前端组件。它是一个使用 JavaScript 实现的开源可视化库，可以流畅的运行在 PC 和移动设备上，兼容当前绝大部分浏览器（IE8/9/10/11，Chrome，Firefox，Safari等），底层依赖矢量图形库 ZRender，提供直观，交互丰富，可高度个性化定制的数据可视化图表。&lt;/p&gt;
&lt;p&gt;它提供了常规的折线图、柱状图、散点图、饼图、K线图，用于统计的盒形图，用于地理数据可视化的地图、热力图、线图，用于关系数据可视化的关系图、treemap、旭日图，多维数据可视化的平行坐标，还有用于 BI 的漏斗图，仪表盘，并且支持图与图之间的混搭。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/626506/202003/626506-20200304002326197-574356620.png&quot; alt=&quot;file&quot;/&gt;&lt;/p&gt;
&lt;p&gt;除了已经内置的包含了丰富功能的图表，ECharts 还提供了自定义系列，只需要传入一个renderItem函数，就可以从数据映射到任何你想要的图形，更棒的是这些都还能和已有的交互组件结合使用而不需要操心其它事情。&lt;/p&gt;
&lt;p&gt;你可以在下载界面下载包含所有图表的构建文件，如果只是需要其中一两个图表，又嫌包含所有图表的构建文件太大，也可以在在线构建中选择需要的图表类型后自定义构建。&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;官方网站：https://www.echartsjs.com/zh/index.html&lt;/li&gt;
&lt;li&gt;案例页面：https://www.echartsjs.com/examples/zh/index.html&lt;/li&gt;
&lt;/ul&gt;&lt;h2 id=&quot;动手试一试&quot;&gt;动手试一试&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;第一步&lt;/strong&gt;：创建一个基础Spring Boot应用，或者拿上一节的工程chapter4-1（仓库地址见文末）来进行加工。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;第二步&lt;/strong&gt;：在&lt;code&gt;pom.xml&lt;/code&gt;中引入Web应用需要的&lt;code&gt;web模块&lt;/code&gt;和模板引擎&lt;code&gt;thymeleaf模块&lt;/code&gt;，比如用Thymeleaf的时候：&lt;/p&gt;
&lt;pre class=&quot;xml&quot;&gt;
&lt;code&gt;&amp;lt;dependency&amp;gt;
    &amp;lt;groupId&amp;gt;org.springframework.boot&amp;lt;/groupId&amp;gt;
    &amp;lt;artifactId&amp;gt;spring-boot-starter-web&amp;lt;/artifactId&amp;gt;
&amp;lt;/dependency&amp;gt;

&amp;lt;dependency&amp;gt;
    &amp;lt;groupId&amp;gt;org.springframework.boot&amp;lt;/groupId&amp;gt;
    &amp;lt;artifactId&amp;gt;spring-boot-starter-thymeleaf&amp;lt;/artifactId&amp;gt;
&amp;lt;/dependency&amp;gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;第三步&lt;/strong&gt;：编写一个Controller，将&lt;code&gt;/&lt;/code&gt;路径的请求，映射到&lt;code&gt;index.html&lt;/code&gt;页面&lt;/p&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;@Controller
public class HelloController {

    @GetMapping(&quot;/&quot;)
    public String index(ModelMap map) {
        return &quot;index&quot;;
    }

}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;第四步&lt;/strong&gt;：在&lt;code&gt;resources/templates&lt;/code&gt;目录下创建&lt;code&gt;index.html&lt;/code&gt;页面，具体内容如下：&lt;/p&gt;
&lt;pre class=&quot;html&quot;&gt;
&lt;code&gt;&amp;lt;!DOCTYPE html&amp;gt;
&amp;lt;html&amp;gt;
&amp;lt;head lang=&quot;en&quot;&amp;gt;
    &amp;lt;meta charset=&quot;UTF-8&quot; /&amp;gt;
    &amp;lt;title&amp;gt;Spring Boot中使用ECharts&amp;lt;/title&amp;gt;
    &amp;lt;script src=&quot;https://cdn.bootcss.com/echarts/4.6.0/echarts.min.js&quot;&amp;gt;&amp;lt;/script&amp;gt;
&amp;lt;/head&amp;gt;
&amp;lt;body&amp;gt;
&amp;lt;div id=&quot;main&quot; style=&quot;width: 1000px;height:400px;&quot;&amp;gt;&amp;lt;/div&amp;gt;
&amp;lt;/body&amp;gt;

&amp;lt;script type=&quot;text/javascript&quot;&amp;gt;
    // 初始化ECharts组件到id为main的元素上
    let myChart = echarts.init(document.getElementById('main'));
    // 定义图标的配置项
    let option = {
        title: {
            text: 'Spring Boot中使用ECharts'
        },
        tooltip: {},
        // x轴配置
        xAxis: {
            data: ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']
        },
        // y轴配置
        yAxis: {},
        series: [{
            // 数据集（也可以从后端的Controller中传入）
            data: [820, 932, 901, 934, 1290, 1330, 1320],
            // 图表类型，这里使用line，为折线图
            type: 'line'
        }]
    };
    myChart.setOption(option);
&amp;lt;/script&amp;gt;
&amp;lt;/html&amp;gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;在页面内容中主要包含三部分：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;code&gt;&amp;lt;head&amp;gt;&lt;/code&gt;中通过&lt;code&gt;&amp;lt;script&amp;gt;&lt;/code&gt;标签引入ECharts的组件JS，这里使用了bootcss的免费公共cdn。如果用于自己生产环境，不建议使用这类免费CDN的JS或者CSS等静态资源。可以从官网下载所需的静态内容，放到Spring Boot的静态资源位置（如果不知道在哪，可见&lt;a href=&quot;http://blog.didispace.com/spring-boot-learning-21-4-1/&quot;&gt;上一篇&lt;/a&gt;），或是放到自己公司的静态资源管理的服务器上，实现动静分离。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;&amp;lt;body&amp;gt;&lt;/code&gt;中定义了一个id为main的&lt;code&gt;&amp;lt;div&amp;gt;&lt;/code&gt;标签，这个标签后续将用来渲染EChart组件&lt;/li&gt;
&lt;li&gt;最后的一段&lt;code&gt;&amp;lt;script&amp;gt;&lt;/code&gt;内容则是具体的EChart图标的展现初始化和配置。具体配置内容可见代码中的注释信息。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;第五步&lt;/strong&gt;：启动应用，访问&lt;code&gt;localhost:8080&lt;/code&gt;，如果上面操作均无差错，那我们就会得到类似下面的折线图：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/626506/202003/626506-20200304002326628-1607485681.png&quot; alt=&quot;file&quot;/&gt;&lt;/p&gt;
&lt;p&gt;关于ECharts图表的调试，官方还提供了一个在线工具，有兴趣的读者可以&lt;a href=&quot;https://www.echartsjs.com/examples/zh/editor.html?c=line-simple&quot;&gt;点击这里&lt;/a&gt;尝试一下。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/626506/202003/626506-20200304002328163-797328832.png&quot; alt=&quot;file&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;更多本系列免费教程连载&lt;a href=&quot;http://blog.didispace.com/spring-boot-learning-2x/&quot;&gt;「点击进入汇总目录」&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;h2 id=&quot;代码示例&quot;&gt;代码示例&lt;/h2&gt;
&lt;p&gt;本文的相关例子可以查看下面仓库中的&lt;code&gt;chapter4-2&lt;/code&gt;目录：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;如果您觉得本文不错，欢迎&lt;code&gt;Star&lt;/code&gt;支持，您的关注是我坚持的动力！&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote readability=&quot;5.5828877005348&quot;&gt;
&lt;p&gt;欢迎关注我的公众号：程序猿DD，获得独家整理的学习资源和日常干货推送。&lt;br/&gt;如果您对我的专题内容感兴趣，也可以关注我的博客：&lt;a href=&quot;http://blog.didispace.com&quot;&gt;didispace.com&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
</description>
<pubDate>Tue, 03 Mar 2020 16:23:00 +0000</pubDate>
<dc:creator>程序猿DD</dc:creator>
<og:description>&amp;quot;上一节&amp;quot; 我们介绍了如何在Spring Boot中使用模板引擎Thymeleaf开发Web应用的基础。接下来，我们介绍一下后端开发经常会遇到的一个场景：可视化图表。 通常，这类需</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/didispace/p/12405821.html</dc:identifier>
</item>
<item>
<title>Docker深入浅出系列 | Docker Compose多容器实战 - EvanLeung</title>
<link>http://www.cnblogs.com/evan-liang/p/12405745.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/evan-liang/p/12405745.html</guid>
<description>&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;Docker已经上市很多年，不是什么新鲜事物了，很多企业或者开发同学以前也不多不少有所接触，但是有实操经验的人不多，本系列教程主要偏重实战，尽量讲干货，会根据本人理解去做阐述，具体官方概念可以查阅官方教程，因为本系列教程对前一章节有一定依赖，建议先学习前面章节内容。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;本系列教程导航:&lt;br/&gt;&lt;a href=&quot;https://www.cnblogs.com/evan-liang/p/12237400.html&quot;&gt;Docker深入浅出系列 | 容器初体验&lt;/a&gt;&lt;br/&gt;&lt;a href=&quot;https://www.cnblogs.com/evan-liang/p/12244304.html&quot;&gt;Docker深入浅出系列 | Image实战演练&lt;/a&gt;&lt;br/&gt;&lt;a href=&quot;https://www.cnblogs.com/evan-liang/p/12271468.html&quot;&gt;Docker深入浅出系列 | 单节点多容器网络通信&lt;/a&gt;&lt;br/&gt;&lt;a href=&quot;https://www.cnblogs.com/evan-liang/p/12372371.html&quot;&gt;Docker深入浅出系列 | 容器数据持久化&lt;/a&gt;&lt;br/&gt;&lt;a href=&quot;https:////www.cnblogs.com/evan-liang/p/12390315.html&quot;&gt;Docker深入浅出系列 | 单机Nginx+Springboot实战&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;教程目的：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;了解docker-compose是什么&amp;amp;为什么要用&lt;/li&gt;
&lt;li&gt;了解docker-compose如何安装&lt;/li&gt;
&lt;li&gt;了解如何创建docker-compose 文件&lt;/li&gt;
&lt;li&gt;了解如何利用docker-compose 文件去创建服务&lt;/li&gt;
&lt;li&gt;了解docker compose的基本命令&lt;/li&gt;
&lt;li&gt;了解如何通过docker compose进行弹性扩容&lt;/li&gt;
&lt;li&gt;掌握docker-compose在nginx+springboot实战应用&lt;/li&gt;
&lt;/ul&gt;&lt;hr/&gt;
&lt;p&gt;1.下载mysql&lt;/p&gt;
&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;docker pull mysql&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;2.下载nginx&lt;/p&gt;
&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;docker pull nginx&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;3.克隆&lt;code&gt;credit-facility-service&lt;/code&gt;作为后面部署演示使用，使用&lt;code&gt;docker&lt;/code&gt;分支&lt;/p&gt;
&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;git clone https://github.com/EvanLeung08/credit-facility-service.git&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;4.虚拟机、centos和docker环境安装请查看第一章，本章默认已经安装好centos和docker&lt;br/&gt;&lt;a href=&quot;https://www.cnblogs.com/evan-liang/p/12237400.html&quot;&gt;Docker深入浅出系列 | 容器初体验&lt;/a&gt;&lt;/p&gt;
&lt;hr/&gt;
&lt;p&gt;Docker Compose是一个用于定义和运行多容器应用程序的工具。 通过compose，我们可以使用yaml文件来配置应用程序的服务，然后使用一个命令来创建和启动所有已配置的服务。 在微服务环境中进行本地开发测试时，我们经常使用此工具。 它也是轻量级的，只需要简单的配置。 您可以预先配置所需的环境和服务，然后专注于当前开发的服务，而不必管理开发时如何运行每个服务的方式。&lt;br/&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/2020030221195175.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0V2YW5fTGV1bmc=,size_16,color_FFFFFF,t_70&quot;/&gt;&lt;br/&gt;***&lt;/p&gt;

&lt;p&gt;首先，我们回顾&lt;a href=&quot;https://blog.csdn.net/Evan_Leung/article/details/104584572&quot;&gt;前一章&lt;/a&gt;，我们要部署一个微服务项目，需要手动配置一堆命令，十分繁琐，假如有几十上百个容器，并且容器之间还存在依赖，光是忙着搭建容器都耗掉一天了，还谈什么Devops，那有没有什么方便快捷的组建，可以让我们通过一个配置就搞定容器编排和运行呢？&lt;/p&gt;
&lt;p&gt;Docker compose就是为了简化多容器配置和管理工作而生的，可以简化大量重复的手动工作，具有以下主要特点：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;提供工具用于定义和运行多个docker容器应用&lt;/li&gt;
&lt;li&gt;使用yaml文件来配置应用服务(docker-compse.yml)&lt;/li&gt;
&lt;li&gt;可以通过一个简单的命令&lt;code&gt;docker-compse up&lt;/code&gt;可以按照依赖关系启动所有服务&lt;/li&gt;
&lt;li&gt;可以通过一个简单的命令&lt;code&gt;docker-compose down&lt;/code&gt;停止所有服务&lt;/li&gt;
&lt;li&gt;当一个服务需要的时候，可以很简单地通过&lt;code&gt;--scale&lt;/code&gt;进行扩容&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;Docker Compose&lt;/strong&gt;的考虑理由:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;可移植性&lt;/strong&gt;：&lt;br/&gt;Docker Compose仅需一个命令即可提供完整的开发环境：&lt;code&gt;docker-compose up&lt;/code&gt;，然后使用&lt;code&gt;docker-compose down&lt;/code&gt;轻松将其拆解。 这使我们的开发人员可以将开发环境保持在一个中立位置，并帮助我们轻松地部署应用程序。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;测试&lt;/strong&gt;：&lt;br/&gt;Compose的另一个重要功能是通过将其置于自己的环境中，以快速可重复的方式支持运行单元和E2E测试。 这意味着，您可以运行与生产环境非常相似的环境，而不是在本地/主机系统上测试应用程序。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;单个主机上的多个隔离环境&lt;/strong&gt;：&lt;br/&gt;Compose使用项目名称将环境彼此隔离，这带来了以下好处：
&lt;ul&gt;&lt;li&gt;您可以在一台计算机上运行同一环境的多个副本&lt;/li&gt;
&lt;li&gt;它可以防止不同的项目和服务相互干扰&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;hr/&gt;
&lt;p&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20200302233829276.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0V2YW5fTGV1bmc=,size_16,color_FFFFFF,t_70&quot;/&gt;&lt;/p&gt;
&lt;ul readability=&quot;3&quot;&gt;&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;&lt;strong&gt;单主机部署&lt;/strong&gt;：&lt;br/&gt;传统上，Compose专注于开发和测试，但现在可用于在单个主机系统上进行部署和管理容器的整个部署过程。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;2&quot;&gt;
&lt;p&gt;&lt;strong&gt;开发环境&lt;/strong&gt;：&lt;br/&gt;Compose提供了在孤立的环境中运行应用程序的能力，该环境可以在安装了Docker的任何计算机上运行。 这使测试你的应用程序变得非常容易，并提供了一种尽可能接近生产环境的工作方式。&lt;br/&gt;Compose文件管理应用程序的所有依赖项（数据库，队列，缓存等），并且可以使用单个命令创建每个容器。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;1&quot;&gt;
&lt;p&gt;&lt;strong&gt;自动化测试环境&lt;/strong&gt;：&lt;br/&gt;持续集成和整个开发过程的重要组成部分是自动化测试套件，该套件要求可以在其中执行测试的环境。 Compose提供了一种方便的方法来创建和销毁与您的生产环境接近的隔离测试环境。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;hr/&gt;
&lt;p&gt;可以参考官网:&lt;a href=&quot;https://docs.docker.com/compose/install/&quot;&gt;Docker Compose安装&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;1.下载当前稳定版本，选择对应系统版本，我这里用的是&lt;code&gt;Centos&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;通过官方下载&lt;/p&gt;
&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;sudo curl -L &quot;https://github.com/docker/compose/releases/download/1.25.4/docker-compose-$(uname -s)-$(uname -m)&quot; -o /usr/local/bin/docker-compose
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;通过国内源下载&lt;br/&gt;&lt;code&gt;bash sudo curl -L https://get.daocloud.io/docker/compose/releases/download/1.25.0/docker-compose-`uname -s`-`uname -m` &amp;gt; /usr/local/bin/docker-compose&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;2.赋予可执行权限&lt;/p&gt;
&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;sudo chmod +x /usr/local/bin/docker-compose&lt;/code&gt;
&lt;/pre&gt;
&lt;hr/&gt;
&lt;p&gt;通过Compose，我们开发人员可以通过应用在docker-compose.yml文件中声明的许多规则轻松地一次处理多个Docker容器。&lt;/p&gt;
&lt;p&gt;它由多个层级组成，这些层级使用制表符或空格分隔，而不是大多数编程语言中已知的括号。 几乎每个Compose-File应该具有以下四个主要方面：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;Compose文件的&lt;code&gt;Version&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;我们将要构建的&lt;code&gt;Services&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;所有要使用的&lt;code&gt;Volumes&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;用来连接不同服务的&lt;code&gt;network&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;docker-compose.yml 示例:&lt;/strong&gt;&lt;/p&gt;
&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;version: '3.3'

services:
   db:
     image: mysql:5.7
     volumes:
       - db_data:/var/lib/mysql
     restart: always
     environment:
       MYSQL_ROOT_PASSWORD: somewordpress
       MYSQL_DATABASE: wordpress
       MYSQL_USER: wordpress
       MYSQL_PASSWORD: wordpress

   wordpress:
     depends_on:
       - db
     image: wordpress:latest
     ports:
       - &quot;8000:80&quot;
     restart: always
     environment:
       WORDPRESS_DB_HOST: db:3306
       WORDPRESS_DB_USER: wordpress
       WORDPRESS_DB_PASSWORD: wordpress
       WORDPRESS_DB_NAME: wordpress
volumes:
    db_data: {}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;以上文件包含整个Wordpress应用程序，包括MySQL数据库。 这些服务中的每一个都被视为一个单独的容器，可以在需要时进行添加或删除&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;我是怎么知道这些命令怎么使用?&lt;/strong&gt;&lt;br/&gt;详细的配置参数，可以查阅: &lt;a href=&quot;https://docs.docker.com/compose/compose-file/#rollback_config&quot;&gt;官方配置参数&lt;/a&gt;&lt;br/&gt;***&lt;/p&gt;

&lt;p&gt;查看docker-compose的基本操作命令，可以通过&lt;code&gt;docker-compose --help&lt;/code&gt;进行查看，很多命令其实是跟docker相似&lt;/p&gt;
&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;[root@localhost credit-facility]# docker-compose --help
Define and run multi-container applications with Docker.

Usage:
  docker-compose [-f &amp;lt;arg&amp;gt;...] [options] [COMMAND] [ARGS...]
  docker-compose -h|--help

Options:
  -f, --file FILE             Specify an alternate compose file
                              (default: docker-compose.yml)
  -p, --project-name NAME     Specify an alternate project name
                              (default: directory name)
  --verbose                   Show more output
  --log-level LEVEL           Set log level (DEBUG, INFO, WARNING, ERROR, CRITICAL)
  --no-ansi                   Do not print ANSI control characters
  -v, --version               Print version and exit
  -H, --host HOST             Daemon socket to connect to

  --tls                       Use TLS; implied by --tlsverify
  --tlscacert CA_PATH         Trust certs signed only by this CA
  --tlscert CLIENT_CERT_PATH  Path to TLS certificate file
  --tlskey TLS_KEY_PATH       Path to TLS key file
  --tlsverify                 Use TLS and verify the remote
  --skip-hostname-check       Don't check the daemon's hostname against the
                              name specified in the client certificate
  --project-directory PATH    Specify an alternate working directory
                              (default: the path of the Compose file)
  --compatibility             If set, Compose will attempt to convert keys
                              in v3 files to their non-Swarm equivalent
  --env-file PATH             Specify an alternate environment file

Commands:
  build              Build or rebuild services
  bundle             Generate a Docker bundle from the Compose file
  config             Validate and view the Compose file
  create             Create services
  down               Stop and remove containers, networks, images, and volumes
  events             Receive real time events from containers
  exec               Execute a command in a running container
  help               Get help on a command
  images             List images
  kill               Kill containers
  logs               View output from containers
  pause              Pause services
  port               Print the public port for a port binding
  ps                 List containers
  pull               Pull service images
  push               Push service images
  restart            Restart services
  rm                 Remove stopped containers
  run                Run a one-off command
  scale              Set number of containers for a service
  start              Start services
  stop               Stop services
  top                Display the running processes
  unpause            Unpause services
  up                 Create and start containers
  version            Show the Docker-Compose version information&lt;/code&gt;
&lt;/pre&gt;
&lt;hr/&gt;
&lt;p&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20200302234520251.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0V2YW5fTGV1bmc=,size_16,color_FFFFFF,t_70&quot;/&gt;&lt;br/&gt;相信大家都已经看过上一章，如果大家还没有看过，请先回到&lt;a href=&quot;https://blog.csdn.net/Evan_Leung/article/details/104584572&quot;&gt;上一章节教程&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;在上一章，我们通过手动方式，一步步搭建了Nginx、Mysql以及额度服务，相信大家都体会到整个流程非常繁琐，有一部出错了，都要重新敲一遍指令，在本章我们沿用上一章的环境配置，但是整个过程会通过docker compose来帮我们自动部署而不是手动部署。&lt;/p&gt;
&lt;h2 id=&quot;实战目标&quot;&gt;&lt;strong&gt;实战目标&lt;/strong&gt;&lt;/h2&gt;
&lt;ul&gt;&lt;li&gt;创建docker网络，设置静态子网ip&lt;code&gt;168.18.0.0/24&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;搭建额度服务集群
&lt;ul&gt;&lt;li&gt;[额度服务]credit-facility01 - 168.18.0.10&lt;/li&gt;
&lt;li&gt;[额度服务]credit-facility02 - 168.18.0.11&lt;/li&gt;
&lt;li&gt;[额度服务]credit-facility03 - 168.18.0.12&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;搭建Mysql数据库
&lt;ul&gt;&lt;li&gt;[Mysql服务]credit-facility-db - 168.18.0.4&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;搭建Nginx服务，并配置负载均衡规则
&lt;ul&gt;&lt;li&gt;[Nginx服务]credit-facility-nginx - 168.18.0.5&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;创建Volume &lt;code&gt;credit-facility-volume&lt;/code&gt;，用于持久化Mysql容器数据&lt;/li&gt;
&lt;li&gt;利用docker内置DNS服务器的特点，docker网络内容器之间通过容器名称进行通信&lt;/li&gt;
&lt;li&gt;通过浏览器访问swagger进行业务操作&lt;/li&gt;
&lt;/ul&gt;&lt;h2 id=&quot;实战步骤&quot;&gt;&lt;strong&gt;实战步骤&lt;/strong&gt;&lt;/h2&gt;
&lt;h3 id=&quot;清理旧配置&quot;&gt;&lt;strong&gt;清理旧配置&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;1.如果上一章已经创建好了容器，先清理上一章已经创建的容器，避免冲突&lt;/p&gt;
&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;docker container stop credit-facility01
docker container stop credit-facility02
docker container stop credit-facility03
docker container stop credit-facility-db
docker container stop credit-facility-nginx
docker container rm credit-facility01
docker container rm credit-facility02
docker container rm credit-facility03
docker container rm credit-facility-db
docker container rm credit-facility-nginx&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;2.清理上一章创建好的网络&lt;code&gt;credit-facility-net&lt;/code&gt;&lt;/p&gt;
&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;docker network rm credit-facility-net&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;3.核对下当前Centos系统上&lt;code&gt;credit-facility&lt;/code&gt;目录下的文件是否跟我一致，如果不一样，请先查看上一章&lt;/p&gt;
&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;[root@localhost credit-facility]# ls
Dockerfile nginx  start-1.0.0-SNAPSHOT.jar&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;我们上一章创建好的文件应该是以上三个&lt;/p&gt;
&lt;h3 id=&quot;搭建环境&quot;&gt;&lt;strong&gt;搭建环境&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;1.上传&lt;code&gt;credit-facility-service&lt;/code&gt;项目里的&lt;code&gt;docker-compose.yml&lt;/code&gt;文件到Centos系统&lt;code&gt;credit-facility&lt;/code&gt;目录下，如果还没克隆额度服务到本地，请查看&lt;a href=&quot;https://www.cnblogs.com/evan-liang/p/12405745.html#&quot; title=&quot;前期准备&quot;&gt;前期准备&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;docker-compose.yml&lt;/code&gt;文件存放在&lt;code&gt;credit-facility-service&lt;/code&gt;项目&lt;code&gt;dockerfile&lt;/code&gt;目录下&lt;/p&gt;
&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;[root@localhost credit-facility]# ls
Dockerfile  docker-compose.yml  nginx  start-1.0.0-SNAPSHOT.jar&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;这时候会多了一个&lt;code&gt;docker-compose.yml&lt;/code&gt;文件&lt;/p&gt;
&lt;p&gt;2.通过&lt;code&gt;docker config&lt;/code&gt;校验compose文件，如果文件格式有问题，通过该命令可以帮你校验并输出错误信息&lt;/p&gt;
&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;[root@localhost credit-facility]# docker-compose config
networks:
  credit-facility-net:
    driver: bridge
    ipam:
      config:
      - subnet: 168.18.0.0/24
services:
  credit-facility-service1:
    build:
      context: /usr/local/credit-facility
    container_name: credit-facility01
    image: credit-facility-image
    networks:
      credit-facility-net:
        ipv4_address: 168.18.0.10
    ports:
    - 8081:8080/tcp
    restart: always
  credit-facility-service2:
    build:
      context: /usr/local/credit-facility
    container_name: credit-facility02
    image: credit-facility-image
    networks:
      credit-facility-net:
        ipv4_address: 168.18.0.11
    ports:
    - 8082:8080/tcp
    restart: always
  credit-facility-service3:
    build:
      context: /usr/local/credit-facility
    container_name: credit-facility03
    image: credit-facility-image
    networks:
      credit-facility-net:
        ipv4_address: 168.18.0.12
    ports:
    - 8083:8080/tcp
    restart: always
  mysql:
    build:
      context: /usr/local/credit-facility
    container_name: credit-facility-db
    environment:
      MYSQL_DATABASE: db_credit_facility
      MYSQL_ROOT_PASSWORD: evan123
    image: mysql
    networks:
      credit-facility-net:
        ipv4_address: 168.18.0.4
    ports:
    - 3301:3306/tcp
    restart: always
    volumes:
    - credit-facility-volume:/var/lib/mysql:rw
  nginx:
    build:
      context: /usr/local/credit-facility
    container_name: credit-facility-nginx
    image: nginx
    networks:
      credit-facility-net:
        ipv4_address: 168.18.0.5
    ports:
    - 80:80/tcp
    restart: always
    volumes:
    - /usr/local/credit-facility/nginx/nginx.conf:/etc/nginx/nginx.conf:rw
version: '3.0'
volumes:
  credit-facility-volume: {}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;这里可以看到，我们的配置文件检验通过，接下来我们分段拆解来说明下每一段脚本的意思&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;配置网络&lt;/strong&gt;&lt;/p&gt;
&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;networks:
  credit-facility-net:
    driver: bridge
    ipam:
      config:
      - subnet: 168.18.0.0/24&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;跟前面一样，这里创建了一个自定义网络&lt;code&gt;credit-facility-net&lt;/code&gt;，指定了docker的网络模式是&lt;code&gt;bridge&lt;/code&gt;，划分了一个子网ip段&lt;code&gt;168.18.0.0/24&lt;/code&gt;，跟前一章手动配置对应的命令如下:&lt;/p&gt;
&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;[root@localhost ~]# docker network create --subnet=168.18.0.0/24 credit-facility-net&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;配置Mysql容器&lt;/strong&gt;&lt;/p&gt;
&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;  mysql:
    restart: always
    container_name: credit-facility-db
    image: mysql
    ports:
      - &quot;3301:3306&quot;
    volumes:
      - &quot;credit-facility-volume:/var/lib/mysql:rw&quot;
    environment:
      - MYSQL_DATABASE=db_credit_facility
      - MYSQL_ROOT_PASSWORD=evan123
    networks:
      credit-facility-net:
        ipv4_address: 168.18.0.4&lt;/code&gt;
&lt;/pre&gt;
&lt;ul&gt;&lt;li&gt;restart - 指定了容器每次部署都会重新重启&lt;/li&gt;
&lt;li&gt;container_name - 指定了容器名称为&lt;code&gt;credit-facility-db&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;image - 指定了我们用来运行容器的镜像是&lt;code&gt;mysql&lt;/code&gt;，如果指定的image不存在，它会自动从远程仓库下载&lt;/li&gt;
&lt;li&gt;ports - 指定了我们映射端口，这里把容器3306端口映射到宿主机器3301端口&lt;/li&gt;
&lt;li&gt;volumes - 指定了容器里的存储路径以volume挂载方式映射到宿主机器上&lt;code&gt;credit-facility-volume&lt;/code&gt;，并且分配读写权限&lt;/li&gt;
&lt;li&gt;environment - 这里环境变量的作用是向容器传递参数，指定了数据库实例为&lt;code&gt;db_credit_facility&lt;/code&gt;，数据库root用户密码为&lt;code&gt;evan123&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;networks - 指定了网络选用自定义网络&lt;code&gt;credit-facility-net&lt;/code&gt;,分配静态IP &lt;code&gt;168.18.0.4&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;上面的compose文件配置对应前一章的手动配置命令如下:&lt;/p&gt;
&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;[root@localhost ~]# docker run -d --name credit-facility-db -v credit-facility-volume:/var/lib/mysql -p 3301:3306 -e MYSQL_ROOT_PASSWORD=evan123 --net=credit-facility-net --ip 168.18.0.4 mysql&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;配置额度服务集群&lt;/strong&gt;&lt;/p&gt;
&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;  credit-facility-service1:
    restart: always
    container_name: credit-facility01
    depends_on:
      - mysql
    image: credit-facility-image
    build: .
    ports:
      - &quot;8081:8080&quot;
    networks:
      credit-facility-net:
        ipv4_address: 168.18.0.10


  credit-facility-service2:
    restart: always
    container_name: credit-facility02
    depends_on:
      - mysql
    image: credit-facility-image
    build: .
    ports:
      - &quot;8082:8080&quot;
    networks:
      credit-facility-net:
        ipv4_address: 168.18.0.11

  credit-facility-service3:
    restart: always
    container_name: credit-facility03
    depends_on:
      - mysql
    image: credit-facility-image
    build: .
    ports:
      - &quot;8083:8080&quot;
    networks:
      credit-facility-net:
        ipv4_address: 168.18.0.12&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;核心配置:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;container_name - 这里主要是配置3个额度服务实例，分别为&lt;code&gt;credit-facility01&lt;/code&gt;、&lt;code&gt;credit-facility02&lt;/code&gt;和&lt;code&gt;credit-facility03&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;build - 这里指定了docker-compose从当前目录寻找dockerfile文件进行镜像创建和启动容器&lt;/li&gt;
&lt;li&gt;depends_on - 它指定当前容器依赖mysql容器，这样子&lt;code&gt;docker-compose&lt;/code&gt;启动时会按照依赖关系来启动&lt;/li&gt;
&lt;li&gt;networks - 指定了自定义网络&lt;code&gt;credit-facility-net&lt;/code&gt;，并对三个实例分别分配了静态ip&lt;code&gt;168.18.0.10&lt;/code&gt;、&lt;code&gt;168.18.0.11&lt;/code&gt;和&lt;code&gt;168.18.0.12&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;大部分命令跟前面一样，所以这里不作重复讲解。这里对应前一章的手动配置命令如下:&lt;/p&gt;
&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;[root@localhost credit-facility]# docker build -t credit-facility-image .
[root@localhost credit-facility]# docker run -d --name credit-facility01 -p 8081:8080  --net=credit-facility-net --ip 168.18.0.10 credit-facility-image
[root@localhost credit-facility]# docker run -d --name credit-facility02 -p 8082:8080  --net=credit-facility-net --ip 168.18.0.11 credit-facility-image
[root@localhost credit-facility]# docker run -d --name credit-facility03 -p 8083:8080  --net=credit-facility-net --ip 168.18.0.12 credit-facility-image&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;这里沿用上一章在&lt;code&gt;credit-facility&lt;/code&gt;目录下创建的dockerfile：&lt;/p&gt;
&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;FROM openjdk:8-jre-alpine
MAINTAINER evan
LABEL name=&quot;credit-facility&quot; version=&quot;1.0&quot; author=&quot;evan&quot;
COPY start-1.0.0-SNAPSHOT.jar credit-facility-service.jar
CMD [&quot;java&quot;,&quot;-jar&quot;,&quot;credit-facility-service.jar&quot;]&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;配置Nginx服务&lt;/strong&gt;&lt;/p&gt;
&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt; nginx:
    restart: always
    container_name: credit-facility-nginx
    depends_on:
      - mysql
      - credit-facility-service1
      - credit-facility-service2
      - credit-facility-service3
    image: nginx
    ports:
      - &quot;80:80&quot;
    volumes:
      - /usr/local/credit-facility/nginx/nginx.conf:/etc/nginx/nginx.conf
    networks:
      credit-facility-net:
        ipv4_address: 168.18.0.5&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;核心配置：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;container_name - 把nginx容器命名为&lt;code&gt;credit-facility-nginx&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;depends_on - 定义了容器启动依赖关系&lt;/li&gt;
&lt;li&gt;ports - 把容器80端口映射到宿主机80端口&lt;/li&gt;
&lt;li&gt;volumes - 把容器目录下的&lt;code&gt;/etc/nginx/nginx.conf&lt;/code&gt;文件映射到宿主机&lt;code&gt;/usr/local/credit-facility/nginx/nginx.conf&lt;/code&gt;，这里的nginx配置沿用上一章的配置不变，宿主机的配置会自动覆盖容器的nginx.conf文件&lt;/li&gt;
&lt;li&gt;networks - 指定网络为credit-facility-net，并分配静态ip为&lt;code&gt;168.18.0.5&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;大部分命令跟前面一样，所以这里不作重复讲解。这里对应前一章的手动配置命令如下:&lt;/p&gt;
&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;[root@localhost nginx]# docker run -d --name credit-facility-nginx -p 80:80 -v /usr/local/credit-facility/nginx/nginx.conf:/etc/nginx/ningx.conf --network=credit-facility-net --ip 168.18.0.5 nginx&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;这里沿用上一章的Nginx配置&lt;code&gt;/usr/local/credit-facility/nginx/nginx.conf&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;user nginx;
worker_processes  1;
events {
    worker_connections  1024;
}
http {
    include       /etc/nginx/mime.types;
    default_type  application/octet-stream;
    sendfile        on;
    keepalive_timeout  65;


    server {
        listen 80;
        location / {
         proxy_pass http://balance;
        }
    }

    upstream balance{
       server credit-facility01:8080;
       server credit-facility02:8080 ;
       server credit-facility03:8080;
    }
    include /etc/nginx/conf.d/*.conf;
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;这里是通过容器名称访问，因此不需要管每个容器的ip是多少&lt;/p&gt;
&lt;p&gt;4.通过&lt;code&gt;docker-compose up&lt;/code&gt;启动所有服务&lt;/p&gt;
&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;[root@localhost credit-facility]# docker-compose up
Creating network &quot;credit-facility_credit-facility-net&quot; with driver &quot;bridge&quot;
Creating credit-facility02     ... done
Creating credit-facility-db    ... done
Creating credit-facility03     ... done
Creating credit-facility-nginx ... done
Creating credit-facility01     ... done
...&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;通过&lt;code&gt;docker-compose&lt;/code&gt;命令，会按照我们在docker-compose.yml配置的信息去创建和启动服务，并且把日志打印到控制台输出，这里因为日志太多，只截取了部分日志，只要日志没有报错信息，所有服务到这里已经搭建完成&lt;/p&gt;
&lt;h3 id=&quot;验证环境&quot;&gt;&lt;strong&gt;验证环境&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;1.验证Nginx服务是否已经成功，这里需要通过宿主机ip+映射端口访问&lt;/p&gt;
&lt;p&gt;先查看下当前centos机器的ip&lt;/p&gt;
&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;[root@localhost credit-facility]# ip add
...
3: eth1: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; mtu 1500 qdisc pfifo_fast state UP group default qlen 1000
    link/ether 08:00:27:ba:0a:28 brd ff:ff:ff:ff:ff:ff
    inet 192.168.101.23/24 brd 192.168.101.255 scope global noprefixroute dynamic eth1
       valid_lft 68553sec preferred_lft 68553sec
    inet6 fe80::a00:27ff:feba:a28/64 scope link 
       valid_lft forever preferred_lft forever&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;从上面可以看到，宿主机外网ip是&lt;code&gt;192.168.101.23&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;在本机浏览器输入&lt;code&gt;192.168.101.23&lt;/code&gt;进行验证&lt;br/&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20200303144945387.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0V2YW5fTGV1bmc=,size_16,color_FFFFFF,t_70&quot;/&gt;Nginx服务已经启动成功&lt;/p&gt;
&lt;p&gt;2.验证额度服务是否成功访问&lt;/p&gt;
&lt;p&gt;通过Nginx 80端口验证&lt;br/&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20200303151301432.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0V2YW5fTGV1bmc=,size_16,color_FFFFFF,t_70&quot;/&gt;&lt;/p&gt;
&lt;p&gt;分别通过每个实例自身映射端口访问&lt;br/&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/2020030315074955.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0V2YW5fTGV1bmc=,size_16,color_FFFFFF,t_70&quot; alt=&quot;在这里插入图片描述&quot;/&gt;&lt;br/&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20200303152309131.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0V2YW5fTGV1bmc=,size_16,color_FFFFFF,t_70&quot;/&gt;&lt;br/&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20200303152342373.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0V2YW5fTGV1bmc=,size_16,color_FFFFFF,t_70&quot;/&gt;&lt;/p&gt;
&lt;p&gt;3.验证额度服务接口是否可以处理成功&lt;/p&gt;
&lt;p&gt;在验证额度服务前，需要先把表创建好，把&lt;code&gt;credit-facility-service&lt;/code&gt;下的db script在DB里执行&lt;br/&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20200303161120502.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0V2YW5fTGV1bmc=,size_16,color_FFFFFF,t_70&quot;/&gt;&lt;br/&gt;进入到Mysql容器，把表创建sql放进去执行&lt;/p&gt;
&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;[root@localhost credit-facility]# docker exec -it credit-facility-db bash
root@d0d2fb8006c9:/# mysql -uroot -pevan123
mysql&amp;gt; show databases;
+--------------------+
| Database           |
+--------------------+
| db_credit_facility |
| information_schema |
| mysql              |
| performance_schema |
| sys                |
+--------------------+
5 rows in set (0.01 sec)

mysql&amp;gt; use db_credit_facility;
Database changed
mysql&amp;gt; CREATE TABLE `t_product_limit`
...&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;输入下面请求数据测试接口&lt;/p&gt;
&lt;pre class=&quot;json&quot;&gt;
&lt;code&gt;{
    &quot;registrationLimitCO&quot;: {
        &quot;applicationId&quot;: &quot;1111&quot;,
        &quot;userId&quot;: 1111,
        &quot;quotaLimit&quot;: 10000,
        &quot;productCode&quot;: &quot;tb&quot;,
        &quot;expirationTime&quot;: &quot;2030-01-01&quot;,
        &quot;accountType&quot;: 1
    }

}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20200303163025166.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0V2YW5fTGV1bmc=,size_16,color_FFFFFF,t_70&quot;/&gt;&lt;br/&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20200303163208137.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0V2YW5fTGV1bmc=,size_16,color_FFFFFF,t_70&quot;/&gt;&lt;br/&gt;从上面输出结果可以看到，接口已经处理成功&lt;/p&gt;
&lt;p&gt;4.进去数据库查看是否已经保存数据成功&lt;/p&gt;
&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;mysql&amp;gt; select * from t_product_limit;
+--------------------+---------------------+---------------------+---------+---------+--------------------+--------------------+-------------+---------+--------------+-------------+---------------+-----------------+--------------+------------+--------------+------------+---------------+-------------+---------------+---------------------+---------------+---------------+-----------+-----------+
| id                 | create_time         | edit_time           | deleted | version | serial_number      | account_id         | customer_id | user_id | product_code | quota_limit | quota_balance | quota_occupancy | quota_frozen | quota_base | quota_change | quota_mode | frozen_status | frozen_time | expire_status | expiration_time     | active_status | inactive_time | parent_id | abandoned |
+--------------------+---------------------+---------------------+---------+---------+--------------------+--------------------+-------------+---------+--------------+-------------+---------------+-----------------+--------------+------------+--------------+------------+---------------+-------------+---------------+---------------------+---------------+---------------+-----------+-----------+
| 684437432334159872 | 2020-03-03 08:30:00 | 2020-03-03 08:30:00 |       0 |       0 | 684437432338354177 | 684437432338354176 |      111111 |    1111 | tb           |       10000 |             0 |               0 |            0 |          0 |            0 |       NULL |             1 | NULL        |          NULL | 2030-01-01 00:00:00 |          NULL | NULL          |      NULL |         0 |
+--------------------+---------------------+---------------------+---------+---------+--------------------+--------------------+-------------+---------+--------------+-------------+---------------+-----------------+--------------+------------+--------------+------------+---------------+-------------+---------------+---------------------+---------------+---------------+-----------+-----------+
1 row in set (0.00 sec)&lt;/code&gt;
&lt;/pre&gt;
&lt;hr/&gt;
&lt;p&gt;在互联网公司比较场景，经常会遇到服务器资源不足，特别是遇到节假日公司要搞活动，需要临时扩容增大服务的计算能力，假如我们公司已经用上docker，&lt;code&gt;docker-compose&lt;/code&gt;就可以帮我们很简单做到服务器扩容，当然，&lt;code&gt;docker-compose&lt;/code&gt;很少直接在生产上独立使用，更多是在开发测试环境，后面讲解k8s的时候会介绍生产上如何做到弹性扩容。&lt;br/&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20200303180649902.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0V2YW5fTGV1bmc=,size_16,color_FFFFFF,t_70&quot;/&gt;&lt;br/&gt;接下来，我们只需要通过简单的命令就可以实现弹性扩容&lt;/p&gt;
&lt;p&gt;1.对于前面我们创建的docker-compose.yml做一点改动，加入一个新的服务定义，如下&lt;/p&gt;
&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;  web:
    restart: always
    image: credit-facility-image
    build: .
    expose:
      - &quot;8080&quot;
    depends_on:
      - mysql
      - credit-facility-service1
      - credit-facility-service2
      - credit-facility-service3
    networks:
      - credit-facility-net&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;这里指定了容器端口是8080，但是没有配置宿主机端口映射，网络也加入到&lt;code&gt;credit-facility-net&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Nginx也需要调整下，把静态ip去掉，并且加上依赖，避免ip冲突，docker会自动分配一个静态ip&lt;/p&gt;
&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;    nginx:
    restart: always
    container_name: credit-facility-nginx
    depends_on:
      - mysql
      - credit-facility-service1
      - credit-facility-service2
      - credit-facility-service3
      - web
    image: nginx
    ports:
      - &quot;80:80&quot;
    links:
      - web
    volumes:
      - /usr/local/credit-facility/nginx/nginx.conf:/etc/nginx/nginx.conf
    networks:
      - credit-facility-net&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;在这里我复制了一份&lt;code&gt;credit-facility-service&lt;/code&gt;配置，为了方便演示，我去掉了网络配置和端口映射，因为如果想使用弹性扩容，端口和ip不能固定，否则会启动失败，改造后完整的配置如下:&lt;/p&gt;
&lt;pre class=&quot;yaml&quot;&gt;
&lt;code&gt;version: '3'
services:

  mysql:
    restart: always
    container_name: credit-facility-db
    image: mysql
    ports:
      - &quot;3301:3306&quot;
    volumes:
      - &quot;credit-facility-volume:/var/lib/mysql:rw&quot;
    environment:
      - MYSQL_DATABASE=db_credit_facility
      - MYSQL_ROOT_PASSWORD=evan123
    networks:
      credit-facility-net:
        ipv4_address: 168.18.0.4

  credit-facility-service1:
    restart: always
    container_name: credit-facility01
    depends_on:
      - mysql
    image: credit-facility-image
    build: .
    ports:
      - &quot;8081:8080&quot;
    networks:
      credit-facility-net:
        ipv4_address: 168.18.0.10


  credit-facility-service2:
    restart: always
    container_name: credit-facility02
    depends_on:
      - mysql
    image: credit-facility-image
    build: .
    ports:
      - &quot;8082:8080&quot;
    networks:
      credit-facility-net:
        ipv4_address: 168.18.0.11

  credit-facility-service3:
    restart: always
    container_name: credit-facility03
    depends_on:
      - mysql
    image: credit-facility-image
    build: .
    ports:
      - &quot;8083:8080&quot;
    networks:
      credit-facility-net:
        ipv4_address: 168.18.0.12

  web:
    restart: always
    image: credit-facility-image
    build: .
    expose:
      - &quot;8080&quot;
    depends_on:
      - mysql
      - credit-facility-service1
      - credit-facility-service2
      - credit-facility-service3
    networks:
      - credit-facility-net

  nginx:
    restart: always
    container_name: credit-facility-nginx
    depends_on:
      - mysql
      - credit-facility-service1
      - credit-facility-service2
      - credit-facility-service3
      - web
    image: nginx
    ports:
      - &quot;80:80&quot;
    links:
      - web
    volumes:
      - /usr/local/credit-facility/nginx/nginx.conf:/etc/nginx/nginx.conf
    networks:
      - credit-facility-net

networks:
  credit-facility-net:
    driver: bridge
    ipam:
      config:
        - subnet: 168.18.0.0/24
volumes:
  credit-facility-volume: {}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;2.执行以下命令，对web服务进行弹性扩容，创建三个容器实例&lt;/p&gt;
&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;[root@localhost credit-facility]# docker-compose up --scale web=3 -d
Creating network &quot;credit-facility_credit-facility-net&quot; with driver &quot;bridge&quot;
Creating network &quot;credit-facility_default&quot; with the default driver
Creating credit-facility_web_1 ... done
Creating credit-facility_web_2 ... done
Creating credit-facility_web_3 ... done
Creating credit-facility01     ... done
Creating credit-facility02     ... done
Creating credit-facility03     ... done
Creating credit-facility-nginx ... done
Creating credit-facility-db    ... done&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;从上图可以看到，web服务对应的容器实例已经创建成功，它的命名方式是基于dockerfile里面的&lt;code&gt;Label名称+_web_&amp;lt;实例序号&amp;gt;&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;3.通过&lt;code&gt;docker-compose ps&lt;/code&gt;查看下当前已启动的容器&lt;/p&gt;
&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;[root@localhost credit-facility]# docker-compose ps
        Name                       Command               State                 Ports              
--------------------------------------------------------------------------------------------------
credit-facility-db      docker-entrypoint.sh mysqld      Up      0.0.0.0:3301-&amp;gt;3306/tcp, 33060/tcp
credit-facility-nginx   nginx -g daemon off;             Up      0.0.0.0:80-&amp;gt;80/tcp               
credit-facility01       java -jar credit-facility- ...   Up      0.0.0.0:8081-&amp;gt;8080/tcp           
credit-facility02       java -jar credit-facility- ...   Up      0.0.0.0:8082-&amp;gt;8080/tcp           
credit-facility03       java -jar credit-facility- ...   Up      0.0.0.0:8083-&amp;gt;8080/tcp           
credit-facility_web_1   java -jar credit-facility- ...   Up      8080/tcp                         
credit-facility_web_2   java -jar credit-facility- ...   Up      8080/tcp                         
credit-facility_web_3   java -jar credit-facility- ...   Up      8080/tcp   &lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;这里可以看到，我们配置的所有容器都启动成功，并且新增了三个web容器实例&lt;/p&gt;
&lt;p&gt;4.通过&lt;code&gt;docker-compose logs web&lt;/code&gt;可以查看web服务每个实例的日志&lt;/p&gt;
&lt;p&gt;5.修改下nginx.conf的配置，改为新的web容器名称，注释掉我们原来的credit-facility容器&lt;/p&gt;
&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;user nginx;
worker_processes  1;
events {
    worker_connections  1024;
}
http {
    include       /etc/nginx/mime.types;
    default_type  application/octet-stream;
    sendfile        on;
    keepalive_timeout  65; 

   
    server {
        listen 80;
        location / {
         proxy_pass http://balance;
        }
    }
    
    upstream balance{  
      #  server credit-facility01:8080;
      # server credit-facility02:8080 ;
      # server credit-facility03:8080;
      server credit-facility_web_1:8080;
      server credit-facility_web_2:8080;
      server credit-facility_web_3:8080;
    }
    include /etc/nginx/conf.d/*.conf;
} &lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;6.重启nginx服务&lt;/p&gt;
&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;[root@localhost nginx]# docker restart credit-facility-nginx 
credit-facility-nginx&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;7.通过Postman测试WEB服务&lt;/p&gt;
&lt;p&gt;请求Url输入你宿主机ip，请求方式是&lt;code&gt;POST&lt;/code&gt;，在请求body输入以下请求数据:&lt;/p&gt;
&lt;pre class=&quot;json&quot;&gt;
&lt;code&gt;{
    &quot;registrationLimitCO&quot;: {
        &quot;applicationId&quot;: &quot;1111&quot;,
        &quot;userId&quot;: 1111,
        &quot;quotaLimit&quot;: 10000,
        &quot;productCode&quot;: &quot;tb&quot;,
        &quot;expirationTime&quot;: &quot;2030-01-01&quot;,
        &quot;accountType&quot;: 1
    }

}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20200303231954414.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0V2YW5fTGV1bmc=,size_16,color_FFFFFF,t_70&quot;/&gt;&lt;br/&gt;从上面相应结果可以看到，服务处理成功&lt;/p&gt;
&lt;hr/&gt;
&lt;h2 id=&quot;引用&quot;&gt;&lt;strong&gt;引用&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Docker Compose官方文档：&lt;/strong&gt;&lt;a href=&quot;https://docs.docker.com/compose/&quot;&gt;官方文档&lt;/a&gt;&lt;br/&gt;&lt;strong&gt;Demo项目地址：&lt;/strong&gt;&lt;a href=&quot;https://github.com/EvanLeung08/credit-facility-service.git&quot;&gt;Demo下载&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;qa&quot;&gt;&lt;strong&gt;Q&amp;amp;A&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;1.&lt;code&gt;docker-compose up&lt;/code&gt;启动报错&lt;/p&gt;
&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;[root@localhost credit-facility]# docker-compose up
ERROR: Named volume &quot;credit-facility-volume:/var/lib/mysql:rw&quot; is used in service &quot;mysql&quot; but no declaration was found in the volumes section.&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;解决方案：&lt;/strong&gt;&lt;br/&gt;这是因为缺少Volume声明，在&lt;code&gt;docker-compose.yml&lt;/code&gt;按如下配置(上文的配置文件已经配置好)&lt;/p&gt;
&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;- &quot;credit-facility-volume:/var/lib/mysql:rw&quot;
volumes:
  credit-facility-volume: {}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;2.&lt;code&gt;credit-facility-service&lt;/code&gt;在服务器上启动报错&lt;br/&gt;先确定你是否已经切换到&lt;code&gt;docker&lt;/code&gt;分支，并且本地构建可以成功，然后再打包部署&lt;/p&gt;
</description>
<pubDate>Tue, 03 Mar 2020 16:04:00 +0000</pubDate>
<dc:creator>EvanLeung</dc:creator>
<og:description>[TOC] Docker已经上市很多年，不是什么新鲜事物了，很多企业或者开发同学以前也不多不少有所接触，但是有实操经验的人不多，本系列教程主要偏重实战，尽量讲干货，会根据本人理解去做阐述，具体官方概念</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/evan-liang/p/12405745.html</dc:identifier>
</item>
<item>
<title>JSR310新日期API(完结篇)-生产实战 - throwable</title>
<link>http://www.cnblogs.com/throwable/p/12405693.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/throwable/p/12405693.html</guid>
<description>&lt;h2 id=&quot;前提&quot;&gt;前提&lt;/h2&gt;
&lt;p&gt;前面通过五篇文章基本介绍完&lt;code&gt;JSR-310&lt;/code&gt;常用的日期时间&lt;code&gt;API&lt;/code&gt;以及一些工具类，这篇博文主要说说笔者在生产实战中使用&lt;code&gt;JSR-310&lt;/code&gt;日期时间&lt;code&gt;API&lt;/code&gt;的一些经验。&lt;/p&gt;
&lt;p&gt;系列文章：&lt;/p&gt;
&lt;p&gt;::: info&lt;br/&gt;不经意间，JDK8发布已经超过6年了，如果还在用旧的日期时间API，可以抽点时间熟悉一下JSR-310的日期时间API。&lt;br/&gt;:::&lt;/p&gt;
&lt;h2 id=&quot;仿真场景&quot;&gt;仿真场景&lt;/h2&gt;
&lt;p&gt;下面会结合一下仿真场景介绍具体的&lt;code&gt;API&lt;/code&gt;选取，由于&lt;code&gt;OffsetDateTime&lt;/code&gt;基本能满足大部分场景，因此挑选&lt;code&gt;OffsetDateTime&lt;/code&gt;进行举例。&lt;/p&gt;
&lt;h3 id=&quot;场景一字符串输入转换为日期时间对象&quot;&gt;场景一：字符串输入转换为日期时间对象&lt;/h3&gt;
&lt;p&gt;一般在&lt;code&gt;Web&lt;/code&gt;应用的表单提交或者&lt;code&gt;Reuqest Body&lt;/code&gt;提交的内容中，需要把字符串形式的日期时间转换为对应的日期时间对象。&lt;code&gt;Web&lt;/code&gt;应用多数情况下会使用&lt;code&gt;SpringMVC&lt;/code&gt;，而&lt;code&gt;SpringMVC&lt;/code&gt;的消息转换器在处理&lt;code&gt;application/json&lt;/code&gt;类型的请求内容的时候会使用&lt;code&gt;ObjectMapper&lt;/code&gt;（&lt;code&gt;Jackson&lt;/code&gt;）进行反序列化。这里引入&lt;code&gt;org.springframework.boot:spring-boot-starter-web:2.2.5.RELEASE&lt;/code&gt;做一个演示。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1412331/202003/1412331-20200303235018594-225569791.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;引入&lt;code&gt;spring-boot-starter-web&lt;/code&gt;的最新版本之后，内置的&lt;code&gt;Jackson&lt;/code&gt;已经引入了&lt;code&gt;JSR-310&lt;/code&gt;相关的两个依赖。&lt;code&gt;SpringBoot&lt;/code&gt;中引入在装载&lt;code&gt;ObjectMapper&lt;/code&gt;通过&lt;code&gt;Jackson2ObjectMapperBuilder&lt;/code&gt;中的建造器方法加载了&lt;code&gt;JavaTimeModule&lt;/code&gt;和&lt;code&gt;Jdk8Module&lt;/code&gt;，实现了对&lt;code&gt;JSR-310&lt;/code&gt;特性的支持。值得注意的是&lt;code&gt;JavaTimeModule&lt;/code&gt;中和日期时间相关的格式化器&lt;code&gt;DateTimeFormatter&lt;/code&gt;都使用了内置的实现，如日期时间使用的是&lt;code&gt;DateTimeFormatter.ISO_OFFSET_DATE_TIME&lt;/code&gt;，无法解析&lt;code&gt;yyyy-MM-dd HH:mm:ss&lt;/code&gt;模式的字符串。例如：&lt;/p&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;public class Request {

    private OffsetDateTime createTime;

    public OffsetDateTime getCreateTime() {
        return createTime;
    }

    public void setCreateTime(OffsetDateTime createTime) {
        this.createTime = createTime;
    }
}

@PostMapping(path = &quot;/test&quot;)
public void test(@RequestBody Request request) throws Exception {
    LOGGER.info(&quot;请求内容:{}&quot;, objectMapper.writeValueAsString(request));
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;请求如下：&lt;/p&gt;
&lt;pre class=&quot;shell&quot;&gt;
&lt;code&gt;curl --location --request POST 'localhost:9091/test' \
--header 'Content-Type: application/json' \
--data-raw '{
    &quot;createTime&quot;: &quot;2020-03-01T21:51:03+08:00&quot;
}'
// 请求内容:{&quot;createTime&quot;:&quot;2020-03-01T13:51:03Z&quot;} &lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;如果执意要选用&lt;code&gt;yyyy-MM-dd HH:mm:ss&lt;/code&gt;模式的字符串，那么属性的类型只能选用&lt;code&gt;LocalDateTime&lt;/code&gt;并且要重写对应的序列化器和反序列化器，覆盖&lt;code&gt;JavaTimeModule&lt;/code&gt;中原有的实现，参考前面的一篇文章。&lt;/p&gt;
&lt;h3 id=&quot;场景二查询两个日期时间范围内的数据&quot;&gt;场景二：查询两个日期时间范围内的数据&lt;/h3&gt;
&lt;p&gt;笔者负责的系统中，经常有定时调度的场景，举个例子：每天凌晨1点要跑一个定时任务，查询&lt;code&gt;T-1&lt;/code&gt;日或者上一周的业务数据，更新到对应的业务统计表中，以便第二天早上运营的同事查看报表数据。查询&lt;code&gt;T-1&lt;/code&gt;日的数据，实际上就是查询&lt;code&gt;T-1&lt;/code&gt;日&lt;code&gt;00:00:00&lt;/code&gt;到&lt;code&gt;23:59:59&lt;/code&gt;的数据。这里举一个案例，计算&lt;code&gt;T-1&lt;/code&gt;日所有订单的总金额：&lt;/p&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;@Slf4j
public class Process {

    static ZoneId Z = ZoneId.of(&quot;Asia/Shanghai&quot;);
    static DateTimeFormatter F = DateTimeFormatter.ofPattern(&quot;yyyy-MM-dd HH:mm:ss&quot;);

    JdbcTemplate jdbcTemplate;

    @Data
    private static class Order {

        private Long id;
        private String orderId;
        private BigDecimal amount;
        private OffsetDateTime createTime;
    }

    public void processTask() {
        // 这里的时区要按实际情况选择
        OffsetDateTime now = OffsetDateTime.now(Z);
        OffsetDateTime start = now.plusDays(-1L).withHour(0).withMinute(0).withSecond(0).withNano(0);
        OffsetDateTime end = start.withHour(23).withMinute(59).withSecond(59).withNano(0);
        BigDecimal totalAmount = BigDecimal.ZERO;
        int limit = 500;
        long maxId = 0L;
        while (true) {
            List&amp;lt;Order&amp;gt; orders = selectPendingProcessingOrders(start, end, limit, maxId);
            if (!orders.isEmpty()) {
                totalAmount = totalAmount.add(orders.stream().map(Order::getAmount).reduce(BigDecimal::add)
                        .orElse(BigDecimal.ZERO));
                maxId = orders.stream().map(Order::getId).max(Long::compareTo).orElse(Long.MAX_VALUE);
            } else {
                break;
            }
        }
        log.info(&quot;统计[{}-{}]的订单总金额为:{}&quot;, start.format(F), end.format(F), totalAmount);
    }

    static ResultSetExtractor&amp;lt;List&amp;lt;Order&amp;gt;&amp;gt; MANY = r -&amp;gt; {
        List&amp;lt;Order&amp;gt; orders = new ArrayList&amp;lt;&amp;gt;();
        while (r.next()) {
            Order order = new Order();
            orders.add(order);
            order.setId(r.getLong(&quot;id&quot;));
            order.setOrderId(r.getString(&quot;order_id&quot;));
            order.setAmount(r.getBigDecimal(&quot;amount&quot;));
            order.setCreateTime(OffsetDateTime.ofInstant(r.getTimestamp(&quot;create_time&quot;).toInstant(), Z));
        }
        return orders;
    };

    private List&amp;lt;Order&amp;gt; selectPendingProcessingOrders(OffsetDateTime start, OffsetDateTime end, int limit, long id) {
        return jdbcTemplate.query(&quot;SELECT * FROM t_order WHERE create_time &amp;gt;= ? AND create_time &amp;lt;= ? AND id &amp;gt; ? LIMIT ?&quot;,
                p -&amp;gt; {
                    p.setTimestamp(1, Timestamp.from(start.toInstant()));
                    p.setTimestamp(2, Timestamp.from(end.toInstant()));
                    p.setLong(3, id);
                    p.setInt(4, limit);
                }, MANY);
    }
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;上面的只是伪代码，不能直接执行，使用的是基于日期时间和&lt;code&gt;ID&lt;/code&gt;翻页的设计，在保证效率的同时可以降低&lt;code&gt;IO&lt;/code&gt;，常用于查询比较多的定时任务或者数据迁移。&lt;/p&gt;
&lt;h3 id=&quot;场景三计算两个日期时间之间的差值&quot;&gt;场景三：计算两个日期时间之间的差值&lt;/h3&gt;
&lt;p&gt;计算两个日期时间之间的差值也是很常见的场景，笔者遇到过的场景就是：运营需要导出一批用户数据，主要包括用户&lt;code&gt;ID&lt;/code&gt;、脱敏信息、用户注册日期时间以及注册日期时间距当前日期的天数。&lt;/p&gt;
&lt;table&gt;&lt;thead/&gt;&lt;tbody&gt;&lt;tr class=&quot;odd&quot;&gt;&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;张小狗&lt;/td&gt;
&lt;td&gt;2019-01-03 12:11:23&lt;/td&gt;
&lt;td&gt;x&lt;/td&gt;
&lt;td/&gt;
&lt;/tr&gt;&lt;tr class=&quot;even&quot;&gt;&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;张大狗&lt;/td&gt;
&lt;td&gt;2019-10-02 23:22:13&lt;/td&gt;
&lt;td&gt;y&lt;/td&gt;
&lt;td/&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;设计的伪代码如下：&lt;/p&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;@Data
private static class CustomerDto {

    private Long id;
    private String name;
    private OffsetDateTime registerTime;
    private Long durationInDay;
}

@Data
private static class Customer {

    private Long id;
    private String name;
    private OffsetDateTime registerTime;

}

static ZoneId Z = ZoneId.of(&quot;Asia/Shanghai&quot;);
static OffsetDateTime NOW = OffsetDateTime.now(Z);

public List&amp;lt;CustomerDto&amp;gt; processUnit() {
    return Optional.ofNullable(select()).filter(Objects::nonNull)
            .map(list -&amp;gt; {
                List&amp;lt;CustomerDto&amp;gt; result = new ArrayList&amp;lt;&amp;gt;();
                list.forEach(x -&amp;gt; {
                    CustomerDto dto = new CustomerDto();
                    dto.setId(x.getId());
                    dto.setName(x.getName());
                    dto.setRegisterTime(x.getRegisterTime());
                    Duration duration = Duration.between(x.getRegisterTime(), NOW);
                    dto.setDurationInDay(duration.toDays());
                    result.add(dto);
                });
                return result;
            }).orElse(null);
}

private List&amp;lt;Customer&amp;gt; select() {
    // 模拟查询
    return null;
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;通过&lt;code&gt;Duration&lt;/code&gt;可以轻松计算两个日期时间之间的差值，并且可以轻松转换为不同的时间计量单位。&lt;/p&gt;
&lt;h3 id=&quot;场景四计算特殊节假日的日期&quot;&gt;场景四：计算特殊节假日的日期&lt;/h3&gt;
&lt;p&gt;利用日期时间校准器&lt;code&gt;TemporalAdjuster&lt;/code&gt;可以十分方便地计算&lt;code&gt;XX月YY日是ZZ节&lt;/code&gt;这种日期形式的节日。例如：五月第二个星期日是母亲节，六月的第三个星期日是父亲节。&lt;/p&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;public class X {

    public static void main(String[] args) throws Exception {
        OffsetDateTime time = OffsetDateTime.now();
        System.out.println(String.format(&quot;%d年母亲节是:%s&quot;, time.getYear(),
                time.withMonth(5).with(TemporalAdjusters.dayOfWeekInMonth(2, DayOfWeek.SUNDAY)).toLocalDate().toString()));
        System.out.println(String.format(&quot;%d年父亲节是:%s&quot;, time.getYear(),
                time.withMonth(6).with(TemporalAdjusters.dayOfWeekInMonth(3, DayOfWeek.SUNDAY)).toLocalDate().toString()));
        time = time.plusYears(1);
        System.out.println(String.format(&quot;%d年母亲节是:%s&quot;, time.getYear(),
                time.withMonth(5).with(TemporalAdjusters.dayOfWeekInMonth(2, DayOfWeek.SUNDAY)).toLocalDate().toString()));
        System.out.println(String.format(&quot;%d年父亲节是:%s&quot;, time.getYear(),
                time.withMonth(6).with(TemporalAdjusters.dayOfWeekInMonth(3, DayOfWeek.SUNDAY)).toLocalDate().toString()));
    }
}

// 输出结果
2020年母亲节是:2020-05-10
2020年父亲节是:2020-06-21
2021年母亲节是:2021-05-09
2021年父亲节是:2021-06-20&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;有些定时调度或者提醒消息发送需要在这类特定的日期时间触发，那么通过&lt;code&gt;TemporalAdjuster&lt;/code&gt;就可以相对简单地计算出具体的日期。&lt;/p&gt;
&lt;h2 id=&quot;小结&quot;&gt;小结&lt;/h2&gt;
&lt;p&gt;关于&lt;code&gt;JSR-310&lt;/code&gt;的日期时间&lt;code&gt;API&lt;/code&gt;就介绍这么多，笔者最近从事数据方面的工作，不过肯定会持续和&lt;code&gt;JSR-310&lt;/code&gt;打交道。&lt;/p&gt;
&lt;h2 id=&quot;附录&quot;&gt;附录&lt;/h2&gt;
&lt;p&gt;这里贴一个工具类&lt;code&gt;OffsetDateTimeUtils&lt;/code&gt;：&lt;/p&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;@Getter
@RequiredArgsConstructor
public enum TimeZoneConstant {

    CHINA(ZoneId.of(&quot;Asia/Shanghai&quot;), &quot;上海-中国时区&quot;);

    private final ZoneId zoneId;
    private final String description;
}

public enum DateTimeUtils {

    // 单例
    X;

    public static final DateTimeFormatter L_D_T_F = DateTimeFormatter.ofPattern(&quot;yyyy-MM-dd HH:mm:ss&quot;);
    public static final DateTimeFormatter S_D_F = DateTimeFormatter.ofPattern(&quot;yyyy-MM-dd&quot;);
    public static final DateTimeFormatter S_D_M_F = DateTimeFormatter.ofPattern(&quot;yyyy-MM&quot;);
    public static final DateTimeFormatter S_T_F = DateTimeFormatter.ofPattern(&quot;HH:mm:ss&quot;);

    public OffsetDateTime getCurrentOffsetDateTime() {
        return OffsetDateTime.now(TimeZoneConstant.CHINA.getZoneId());
    }

    public OffsetDateTime getDeltaDayOffsetDateTimeStart(long delta) {
        return getCurrentOffsetDateTime().plusDays(delta).withHour(0).withMinute(0).withSecond(0).withNano(0);
    }

    public OffsetDateTime getDeltaDayOffsetDateTimeEnd(long delta) {
        return getCurrentOffsetDateTime().plusDays(delta).withHour(23).withMinute(59).withSecond(59).withNano(0);
    }

    public OffsetDateTime getYesterdayOffsetDateTimeStart() {
        return getDeltaDayOffsetDateTimeStart(-1L);
    }

    public OffsetDateTime getYesterdayOffsetDateTimeEnd() {
        return getDeltaDayOffsetDateTimeEnd(-1L);
    }

    public long durationInDays(OffsetDateTime start, OffsetDateTime end) {
        return Duration.between(start, end).toDays();
    }

    public OffsetDateTime getThisMonthOffsetDateTimeStart() {
        OffsetDateTime offsetDateTime = getCurrentOffsetDateTime();
        return offsetDateTime.with(TemporalAdjusters.firstDayOfMonth()).withHour(0).withMinute(0).withSecond(0).withNano(0);
    }

    public OffsetDateTime getThisMonthOffsetDateTimeEnd() {
        OffsetDateTime offsetDateTime = getCurrentOffsetDateTime();
        return offsetDateTime.with(TemporalAdjusters.lastDayOfMonth()).withHour(23).withMinute(59).withSecond(59).withNano(0);
    }
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;（本文完 c-3-d e-a-20200302）&lt;/p&gt;
</description>
<pubDate>Tue, 03 Mar 2020 15:51:00 +0000</pubDate>
<dc:creator>throwable</dc:creator>
<og:description>前提 前面通过五篇文章基本介绍完 常用的日期时间 以及一些工具类，这篇博文主要说说笔者在生产实战中使用 日期时间 的一些经验。 系列文章： &amp;quot;JSR310新日期API(一) 时区与时间偏移量</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/throwable/p/12405693.html</dc:identifier>
</item>
<item>
<title>Rust入坑指南：朝生暮死 - Jackeyzhe</title>
<link>http://www.cnblogs.com/Jackeyzhe/p/12405190.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/Jackeyzhe/p/12405190.html</guid>
<description>&lt;p&gt;今天想和大家一起把我们之前挖的坑再刨深一些。在Java中，一个对象能存活多久全靠JVM来决定，程序员并不需要去关心对象的生命周期，但是在Rust中就大不相同，一个对象从生到死我们都需要掌握的很清楚。&lt;/p&gt;
&lt;p&gt;在&lt;a href=&quot;https://jackeyzhe.github.io/2019/10/13/Rust%E5%85%A5%E5%9D%91%E6%8C%87%E5%8D%97%EF%BC%9A%E6%A0%B8%E5%BF%83%E6%A6%82%E5%BF%B5/&quot;&gt;Rust入坑指南：核心概念&lt;/a&gt;一文中我们介绍了Rust的几个核心概念：所有权（Ownership）、所有权转移和所有权借用。今天就来介绍Rust中的另外一个核心概念：生命周期。&lt;/p&gt;
&lt;p&gt;为什么生命周期要单独介绍呢？因为我在这之前一直没搞清楚Rust中的生命周期参数究竟是怎么一回事。&lt;/p&gt;
&lt;p&gt;现在我终于弄明白了，于是迫不及待要和大家分享，当然如果我有什么说的不对的地方请帮忙指正。&lt;/p&gt;
&lt;p&gt;在Rust中，值的生命周期与作用域有关，这里你可以结合所有权一起理解。在一个函数内，Rust中值的所有权的范围即为其生命周期。Rust通过借用检查器对值的生命周期进行检查，其目的是为了避免出现悬垂指针。这点很容易理解，我们通过一段简单的代码来看一下。&lt;/p&gt;
&lt;pre class=&quot;rust&quot;&gt;
&lt;code&gt;fn main() {
    let a;  // 'a ---------------+
    {                   //       |
        let b = 1; // 'b ----+   |
        a = &amp;amp;b;           // |   |
    }// ---------------------+   |
    println!(&quot;a: {}&quot;, a); //     |
} // ----------------------------+&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;在上面这段代码中，我已经标注了a和b的生命周期。在代码的第5行，b将所有权出借给了a，而在第7行我们想使用a时，b的生命周期已经结束，也就是说，从第7行开始，a成为了一个悬垂指针。因此这段代码会报一个编译错误。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://res.cloudinary.com/dxydgihag/image/upload/v1582994323/Blog/rust/10/rust10-1.png&quot; alt=&quot;生命周期编译错误&quot;/&gt;&lt;/p&gt;
&lt;p&gt;而当所有权在函数之间传递时，Rust的借用检查器就没有办法来确定值的生命周期了。这个时候我们就需要借助生命周期参数来帮助Rust的借用检查器来进行生命周期的检查。生命周期参数分为显式的和隐式的两种。&lt;/p&gt;
&lt;h3 id=&quot;显式生命周期参数&quot;&gt;显式生命周期参数&lt;/h3&gt;
&lt;p&gt;显式生命周期的标注方式通常是&lt;code&gt;'a&lt;/code&gt;这样的。它应该写在&lt;code&gt;&amp;amp;&lt;/code&gt;之后，&lt;code&gt;mut&lt;/code&gt;之前（如果有）。&lt;/p&gt;
&lt;h4 id=&quot;函数签名中的生命周期参数&quot;&gt;函数签名中的生命周期参数&lt;/h4&gt;
&lt;p&gt;在正式开始学习之前，我们还要先明确一些概念。下面是一个代有生命周期参数的函数签名。&lt;/p&gt;
&lt;pre class=&quot;rust&quot;&gt;
&lt;code&gt;fn foo &amp;lt;'a&amp;gt;(s: &amp;amp;'a str, t: &amp;amp;'a str) -&amp;gt;&amp;amp;'a str;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;其中第一个&lt;code&gt;'a&lt;/code&gt;，是生命周期参数的声明。参数的生命周期叫做输入声明周期，返回值的生命周期叫做输出生命周期。需要记住的一点是：&lt;strong&gt;输出的生命周期长度不能长于输入的生命周期&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;另外还要注意：&lt;strong&gt;禁止在没有任何输入参数的情况下返回引用&lt;/strong&gt;。因为这样明显会造成悬垂指针。试想当你没有任何输入参数时返回了引用，那么引用本身的值在函数返回时必然会被析构，返回的引用也就成了悬垂指针。&lt;/p&gt;
&lt;p&gt;同样的道理我们可以得出另一个结论：&lt;strong&gt;从函数中返回一个引用，其生命周期参数必须与函数的参数相匹配，否则，标注生命周期参数也毫无意义&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;说了这么多“不允许”之后，我们来看一个正常使用生命周期参数的例子吧。&lt;/p&gt;
&lt;pre class=&quot;rust&quot;&gt;
&lt;code&gt;fn the_longest&amp;lt;'a&amp;gt; (s1: &amp;amp;'a str, s2: &amp;amp;'a str) -&amp;gt; &amp;amp;'a str {
    if s1.len() &amp;gt; s2.len() {
        s1
    } else {
        s2
    }
}
fn main() {
    let s1 = String::from(&quot;Rust&quot;);
    let s1_r = &amp;amp;s1;
    {
        let s2 = String::from(&quot;C&quot;);
        let res = the_longest(s1_r, &amp;amp;s2);
        println!(&quot;{} is the longest&quot;, res);
    }
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;我们来看看这段代码的各个值的生命周期是否符合我们前面说的那一点原则。在调用th_longest函数时，两个参数的生命周期已经确定，s1的生命周期贯穿了main函数，s2的生命周期在内部的代码块中。函数返回时，将返回值绑定给了res，也就是说返回的生命周期为res的生命周期，由于后定义先析构的原则，res的生命周期是短于s2的生命周期的，当然也短于s1的生命周期。因此这个例子符合了我们说的&lt;strong&gt;输出的生命周期长度不能长于输入的生命周期&lt;/strong&gt;的原则。&lt;/p&gt;
&lt;p&gt;对于像示例当中有多个参数的函数，我们也可以为其标注不同的生命周期参数，但是编译器无法确定两个生命周期参数的大小，因此需要我们显式的指定。&lt;/p&gt;
&lt;pre class=&quot;rust&quot;&gt;
&lt;code&gt;fn the_longest&amp;lt;'a, 'b: 'a&amp;gt; (s1: &amp;amp;'a str, s2: &amp;amp;'b str) -&amp;gt; &amp;amp;'a str {
    if s1.len() &amp;gt; s2.len() {
        s1
    } else {
        s2
    }
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;这里&lt;code&gt;'b: 'a&lt;/code&gt;的意思是&lt;code&gt;'b&lt;/code&gt;的存活周期长于&lt;code&gt;'a&lt;/code&gt;。这点有些令人疑惑，&lt;code&gt;'a&lt;/code&gt;明明是长于&lt;code&gt;'b&lt;/code&gt;的，为什么会这样标注呢？还记得我们说过生命周期参数的意义吗？它是用来帮助Rust借用检查器来检查非法借用的，输出生命周期必须短于输入生命周期。因此这里的&lt;code&gt;'a&lt;/code&gt;实际上是返回值的生命周期，而不是第一个输入参数的生命周期。&lt;/p&gt;
&lt;p&gt;函数中的生命周期参数的使用我们暂时先介绍到这里。生命周期在其他使用场景中的使用方法也比较类似，不过还是有一些值得注意的地方的。&lt;/p&gt;
&lt;h4 id=&quot;结构体中的生命周期参数&quot;&gt;结构体中的生命周期参数&lt;/h4&gt;
&lt;p&gt;如果一个结构体包含引用类型的成员，那么结构体应该声明生命周期参数&lt;code&gt;&amp;lt;'a&amp;gt;&lt;/code&gt;。这是为了保证&lt;strong&gt;结构体实例的生命周期应该短于或等于任意一个成员的生命周期&lt;/strong&gt;。&lt;/p&gt;
&lt;pre class=&quot;rust&quot;&gt;
&lt;code&gt;struct ImportantExcept&amp;lt;'a&amp;gt; {
    part: &amp;amp;'a str,
}

fn main() {
    let novel = String::from(&quot;call me Ishmael. Some year ago...&quot;);
    let first_sentence = novel.split('.')
        .next()
        .expect(&quot;Could not find a '.'&quot;);
    let i = ImportantExcept { part: first_sentence};
    assert_eq!(i.part, &quot;call me Ishmael&quot;);
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;在这段代码中&lt;code&gt;first_sentence&lt;/code&gt;先于结构体实例&lt;code&gt;i&lt;/code&gt;被定义，因此&lt;code&gt;i&lt;/code&gt;的生命周期是短于&lt;code&gt;first_sentence&lt;/code&gt;的，如果反过来，&lt;code&gt;i&lt;/code&gt;的生命周期长于&lt;code&gt;first_sentence&lt;/code&gt;即长于&lt;code&gt;part&lt;/code&gt;，那么在&lt;code&gt;part&lt;/code&gt;被析构以后，&lt;code&gt;i.part&lt;/code&gt;就会成为悬垂指针。&lt;/p&gt;
&lt;h4 id=&quot;方法中的生命周期参数&quot;&gt;方法中的生命周期参数&lt;/h4&gt;
&lt;p&gt;现在我们为刚才的结构体增加一个实现方法&lt;/p&gt;
&lt;pre class=&quot;rust&quot;&gt;
&lt;code&gt;impl&amp;lt;'a&amp;gt; ImportantExcept&amp;lt;'a&amp;gt; {
    fn get_first_sentence(s: &amp;amp;'a str) -&amp;gt; &amp;amp;'a str {
        let first_sentence = s.split('.')
            .next()
            .expect(&quot;Could not find a '.'&quot;);
        first_sentence
    }
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;因为&lt;code&gt;ImportantExcept&lt;/code&gt;包含引用成员，因此需要标注生命周期参数。在&lt;code&gt;impl&lt;/code&gt;后面声明生命周期参数&lt;code&gt;&amp;lt;'a&amp;gt;&lt;/code&gt;在结构体名称后面使用。在&lt;code&gt;get_first_sentence&lt;/code&gt;方法中使用的生命周期参数也是刚刚定义好的那个。这样就可以约束输入引用的生命周期长度长于结构体实例的生命周期长度。&lt;/p&gt;
&lt;h4 id=&quot;静态生命周期参数&quot;&gt;静态生命周期参数&lt;/h4&gt;
&lt;p&gt;前面聊的都是我们自己定义的生命周期参数，现在来聊聊Rust中内置的生命周期参数&lt;code&gt;'static&lt;/code&gt;。&lt;code&gt;'static&lt;/code&gt;生命周期存活于整个程序运行期间。所有的字符串字面量都有&lt;code&gt;'static&lt;/code&gt;生命周期，类型为&lt;code&gt;&amp;amp;'static str&lt;/code&gt;。&lt;/p&gt;
&lt;h3 id=&quot;隐式生命周期参数&quot;&gt;隐式生命周期参数&lt;/h3&gt;
&lt;p&gt;在某些情况下，我们可以省略生命周期参数，对于省略的生命周期参数通常有三条规则：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;每个输入位置上省略的生命周期都将成为一个不同的生命周期参数&lt;/li&gt;
&lt;li&gt;如果只有一个输入生命周期的位置，则该生命周期将分配给输出生命周期&lt;/li&gt;
&lt;li&gt;如果存在多个输入生命周期的位置，但是其中包含&amp;amp;self或&amp;amp;mut self，则self的生命周期将分配给输出生命周期&lt;/li&gt;
&lt;/ul&gt;&lt;h3 id=&quot;生命周期限定&quot;&gt;生命周期限定&lt;/h3&gt;
&lt;p&gt;生命周期参数也可以像trait那样作为范型的限定&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;T: 'a：表示T类型中的任何引用都要“活得”和'a一样长&lt;/li&gt;
&lt;li&gt;T：Trait + 'a：表示T类型必须实现Trait这个trait，并且T类型中的任何引用都要“活得”和'a一样长&lt;/li&gt;
&lt;/ul&gt;&lt;h3 id=&quot;总结&quot;&gt;总结&lt;/h3&gt;
&lt;p&gt;现在我把我对Rust生命周期的了解都分享完了。其实只要记住一个原则就可以了，那就是：&lt;strong&gt;生命周期参数的目的是帮助借用检查器验证引用的合法性，避免出现悬垂指针&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;Rust还有几个深坑，我们下次继续。&lt;/p&gt;
</description>
<pubDate>Tue, 03 Mar 2020 14:29:00 +0000</pubDate>
<dc:creator>Jackeyzhe</dc:creator>
<og:description>今天想和大家一起把我们之前挖的坑再刨深一些。在Java中，一个对象能存活多久全靠JVM来决定，程序员并不需要去关心对象的生命周期，但是在Rust中就大不相同，一个对象从生到死我们都需要掌握的很清楚。</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/Jackeyzhe/p/12405190.html</dc:identifier>
</item>
<item>
<title>Docker实战之Zookeeper集群 - 当我遇上你csy</title>
<link>http://www.cnblogs.com/idea360/p/12405113.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/idea360/p/12405113.html</guid>
<description>&lt;p&gt;这里是 Docker 实战系列第四篇。主要介绍分布式系统中的元老级组件 Zookeeper。&lt;/p&gt;
&lt;p&gt;ZooKeeper 是一个开源的分布式协调服务，是 Hadoop，HBase 和其他分布式框架使用的有组织服务的标准。&lt;/p&gt;
&lt;p&gt;分布式应用程序可以基于 ZooKeeper 实现诸如数据发布/订阅、负载均衡、命名服务、分布式协调/通知、集群管理、Master 选举、分布式锁和分布式队列等功能。&lt;/p&gt;
&lt;p&gt;读过 &lt;a href=&quot;https://mp.weixin.qq.com/s/PKK7EsiiLQfevxaOTpfIZA&quot;&gt;Docker 实战之 Consul 集群&lt;/a&gt; 的小伙伴应该有印象，里边有一张一致性算法的对比图。所有的分布式系统都面临着 CAP 理论的抉择，都需要一致性算法的保障。这里先放上一个简单的总结，用于大家借鉴那些顶级开源软件在分布式上的思路。&lt;/p&gt;
&lt;table&gt;&lt;thead/&gt;&lt;tbody readability=&quot;3&quot;&gt;&lt;tr class=&quot;odd&quot; readability=&quot;2&quot;&gt;&lt;td&gt;Redis Cluster&lt;/td&gt;
&lt;td&gt;Gossip&lt;/td&gt;
&lt;td&gt;master 提供读写，slave 只备份&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;even&quot; readability=&quot;2&quot;&gt;&lt;td&gt;Zookeeper&lt;/td&gt;
&lt;td&gt;ZAB&lt;/td&gt;
&lt;td&gt;Leader 提供读写，Follower 只读，遇到写请求转发给 Leader&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;odd&quot; readability=&quot;2&quot;&gt;&lt;td&gt;Kafka&lt;/td&gt;
&lt;td&gt;ZK 临时节点&lt;/td&gt;
&lt;td&gt;只有 leader 提供读写服务&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;p&gt;大致来说，zookeeper 的使用场景如下:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;分布式协调&lt;/li&gt;
&lt;li&gt;分布式锁&lt;/li&gt;
&lt;li&gt;元数据/配置信息管理&lt;/li&gt;
&lt;li&gt;HA 高可用性&lt;/li&gt;
&lt;li&gt;发布/订阅&lt;/li&gt;
&lt;li&gt;负载均衡&lt;/li&gt;
&lt;li&gt;Master 选举&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;这里引用中华石杉老师的例子&lt;/p&gt;
&lt;h2 id=&quot;分布式协调&quot;&gt;2.1 分布式协调&lt;/h2&gt;
&lt;p&gt;这个其实是 zookeeper 很经典的一个用法，简单来说，就好比，你 A 系统发送个请求到 mq，然后 B 系统消息消费之后处理了。那 A 系统如何知道 B 系统的处理结果？用 zookeeper 就可以实现分布式系统之间的协调工作。A 系统发送请求之后可以在 zookeeper 上对某个节点的值注册个监听器，一旦 B 系统处理完了就修改 zookeeper 那个节点的值，A 系统立马就可以收到通知，完美解决。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://gitee.com/idea360/oss/raw/master/images/zookeeper-distributed-coordination.png&quot;/&gt;&lt;/p&gt;
&lt;h2 id=&quot;分布式锁&quot;&gt;2.2 分布式锁&lt;/h2&gt;
&lt;p&gt;举个栗子。对某一个数据连续发出两个修改操作，两台机器同时收到了请求，但是只能一台机器先执行完另外一个机器再执行。那么此时就可以使用 zookeeper 分布式锁，一个机器接收到了请求之后先获取 zookeeper 上的一把分布式锁，就是可以去创建一个 znode，接着执行操作；然后另外一个机器也尝试去创建那个 znode，结果发现自己创建不了，因为被别人创建了，那只能等着，等第一个机器执行完了自己再执行。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://gitee.com/idea360/oss/raw/master/images/zookeeper-distributed-lock-demo.png&quot;/&gt;&lt;/p&gt;
&lt;h2 id=&quot;元数据配置信息管理&quot;&gt;2.3 元数据/配置信息管理&lt;/h2&gt;
&lt;p&gt;zookeeper 可以用作很多系统的配置信息的管理，比如 kafka、storm 等等很多分布式系统都会选用 zookeeper 来做一些元数据、配置信息的管理，包括 dubbo 注册中心不也支持 zookeeper 么？&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://gitee.com/idea360/oss/raw/master/images/zookeeper-meta-data-manage.png&quot;/&gt;&lt;/p&gt;
&lt;h2 id=&quot;ha-高可用性&quot;&gt;2.4 HA 高可用性&lt;/h2&gt;
&lt;p&gt;这个应该是很常见的，比如 hadoop、hdfs、yarn 等很多大数据系统，都选择基于 zookeeper 来开发 HA 高可用机制，就是一个重要进程一般会做主备两个，主进程挂了立马通过 zookeeper 感知到切换到备用进程。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://gitee.com/idea360/oss/raw/master/images/zookeeper-active-standby.png&quot;/&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;docker-compose-zookeeper-cluster.yml&lt;/strong&gt;&lt;/p&gt;
&lt;pre class=&quot;yaml&quot;&gt;
&lt;code&gt;version: '3.7'

networks:
  docker_net:
    external: true


services:
  zoo1:
    image: zookeeper
    restart: unless-stopped
    hostname: zoo1
    container_name: zoo1
    ports:
      - 2182:2181
    environment:
      ZOO_MY_ID: 1
      ZOO_SERVERS: server.1=0.0.0.0:2888:3888;2181 server.2=zoo2:2888:3888;2181 server.3=zoo3:2888:3888;2181
    volumes:
      - ./zookeeper/zoo1/data:/data
      - ./zookeeper/zoo1/datalog:/datalog
    networks:
      - docker_net

  zoo2:
    image: zookeeper
    restart: unless-stopped
    hostname: zoo2
    container_name: zoo2
    ports:
      - 2183:2181
    environment:
      ZOO_MY_ID: 2
      ZOO_SERVERS: server.1=zoo1:2888:3888;2181 server.2=0.0.0.0:2888:3888;2181 server.3=zoo3:2888:3888;2181
    volumes:
      - ./zookeeper/zoo2/data:/data
      - ./zookeeper/zoo2/datalog:/datalog
    networks:
      - docker_net

  zoo3:
    image: zookeeper
    restart: unless-stopped
    hostname: zoo3
    container_name: zoo3
    ports:
      - 2184:2181
    environment:
      ZOO_MY_ID: 3
      ZOO_SERVERS: server.1=zoo1:2888:3888;2181 server.2=zoo2:2888:3888;2181 server.3=0.0.0.0:2888:3888;2181
    volumes:
      - ./zookeeper/zoo3/data:/data
      - ./zookeeper/zoo3/datalog:/datalog
    networks:
      - docker_net&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;启动集群&lt;/strong&gt;&lt;/p&gt;
&lt;pre class=&quot;docker&quot;&gt;
&lt;code&gt;docker-compose -f docker-compose-zookeeper-cluster.yml up -d&lt;/code&gt;
&lt;/pre&gt;

&lt;p&gt;在 ZAB 算法中，存在 Leader、Follower、Observer 三种角色，现在我们就来认识下它们。&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;查看 zoo1 角色&lt;/li&gt;
&lt;/ul&gt;&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;➜  docker docker exec -it zoo1 /bin/sh
# zkServer.sh status
ZooKeeper JMX enabled by default
Using config: /conf/zoo.cfg
Client port found: 2181. Client address: localhost.
Mode: follower&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;由上结果可知，zoo1 是 follower&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;查看 zoo2 角色&lt;/li&gt;
&lt;/ul&gt;&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;➜  docker docker exec -it zoo2 /bin/sh
# zkServer.sh status
ZooKeeper JMX enabled by default
Using config: /conf/zoo.cfg
Client port found: 2181. Client address: localhost.
Mode: follower&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;由上结果可知，zoo2 是 follower&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;查看 zoo3 角色&lt;/li&gt;
&lt;/ul&gt;&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;➜  docker docker exec -it zoo3 /bin/sh
# zkServer.sh status
ZooKeeper JMX enabled by default
Using config: /conf/zoo.cfg
Client port found: 2181. Client address: localhost.
Mode: leader&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;由上结果可知，zoo3 是 leader。负责集群的读写。&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;查看 zoo3 选举数据&lt;/li&gt;
&lt;/ul&gt;&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;➜  docker echo srvr | nc localhost 2184
Zookeeper version: 3.5.6-c11b7e26bc554b8523dc929761dd28808913f091, built on 10/08/2019 20:18 GMT
Latency min/avg/max: 0/0/0
Received: 2
Sent: 1
Connections: 1
Outstanding: 0
Zxid: 0x100000000
Mode: leader
Node count: 5
Proposal sizes last/min/max: -1/-1/-1&lt;/code&gt;
&lt;/pre&gt;
&lt;ul&gt;&lt;li&gt;查看映射数据&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;如果实践了上述操作的小伙伴一定会发现，映射路径下的文件夹多了好多东西，感兴趣的小伙伴可以打开看一下，了解下 ZAB 的选举算法(没错，里边记录的就是选举相关的数据)。&lt;/p&gt;
&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;➜  zookeeper cd zoo1
➜  zoo1 tree
.
├── data
│   ├── myid
│   └── version-2
│       ├── acceptedEpoch
│       ├── currentEpoch
│       └── snapshot.0
└── datalog
    └── version-2&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;em&gt;注意：留意 currentEpoch 中的数值&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;5.1 模拟 Leader 掉线&lt;/strong&gt;&lt;/p&gt;
&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;➜  zoo1 docker stop zoo3
zoo3&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;查看此时的选举结果(操作同查看角色操作步骤)。可以看到 Zookeeper 集群重新选举结果: zoo2 被选为 leader&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;5.2 zoo3 节点重新上线&lt;/strong&gt;&lt;/p&gt;
&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;➜  zoo1 docker start zoo3
zoo3&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;查看 zoo3 角色，发现 zoo3 自动作为 follower 加入集群。&lt;/p&gt;
&lt;p&gt;&lt;em&gt;注意：查看 currentEpoch 中的数值，存储值为 2，代表经过了 2 次选举。第一次为刚启动时触发选举，第二次为 leader 宕机后重新选举&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&quot;查看文件目录&quot;&gt;6.1 查看文件目录&lt;/h2&gt;
&lt;p&gt;笔者本地有安装的 Zookeeper 环境，所以这里用本地的 zkCli 进行测试。&lt;/p&gt;
&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;zkCli -server localhost:2182,localhost:2183,localhost:2184
Connecting to localhost:2182,localhost:2183,localhost:2184
Welcome to ZooKeeper!
JLine support is enabled

WATCHER::

WatchedEvent state:SyncConnected type:None path:null
[zk: localhost:2182,localhost:2183,localhost:2184(CONNECTED) 0] ls /
[zookeeper]&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;创建顺序节点&quot;&gt;6.2 创建顺序节点&lt;/h2&gt;
&lt;p&gt;顺序节点保证 znode 路径将是唯一的。&lt;/p&gt;
&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;[zk: localhost:2182,localhost:2183,localhost:2184(CONNECTED) 1] create -s /zk-test 123
Created /zk-test0000000000
[zk: localhost:2182,localhost:2183,localhost:2184(CONNECTED) 2] ls /
[zk-test0000000000, zookeeper]&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;创建临时节点&quot;&gt;6.3 创建临时节点&lt;/h2&gt;
&lt;p&gt;当会话过期或客户端断开连接时，临时节点将被自动删除&lt;/p&gt;
&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;[zk: localhost:2182,localhost:2183,localhost:2184(CONNECTED) 3] create -e /zk-temp 123
Created /zk-temp
[zk: localhost:2182,localhost:2183,localhost:2184(CONNECTED) 4] ls /
[zk-test0000000000, zookeeper, zk-temp]&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;临时节点在客户端会话结束后就会自动删除，下面使用 quit 命令行退出客户端,再次连接后即可验证。&lt;/p&gt;
&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;[zk: localhost:2182,localhost:2183,localhost:2184(CONNECTED) 5] quit
Quitting...
➜  docker zkCli -server localhost:2182,localhost:2183,localhost:2184
Connecting to localhost:2182,localhost:2183,localhost:2184
Welcome to ZooKeeper!
JLine support is enabled

WATCHER::

WatchedEvent state:SyncConnected type:None path:null
[zk: localhost:2182,localhost:2183,localhost:2184(CONNECTED) 0] ls /
[zk-test0000000000, zookeeper]&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;创建永久节点&quot;&gt;6.4 创建永久节点&lt;/h2&gt;
&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;[zk: localhost:2182,localhost:2183,localhost:2184(CONNECTED) 1] create /zk-permanent 123
Created /zk-permanent
[zk: localhost:2182,localhost:2183,localhost:2184(CONNECTED) 2] ls /
[zk-permanent, zk-test0000000000, zookeeper]&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;读取节点&quot;&gt;6.5 读取节点&lt;/h2&gt;
&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;[zk: localhost:2182,localhost:2183,localhost:2184(CONNECTED) 3] get /

cZxid = 0x0
ctime = Thu Jan 01 08:00:00 CST 1970
mZxid = 0x0
mtime = Thu Jan 01 08:00:00 CST 1970
pZxid = 0x400000008
cversion = 3
dataVersion = 0
aclVersion = 0
ephemeralOwner = 0x0
dataLength = 0
numChildren = 3
[zk: localhost:2182,localhost:2183,localhost:2184(CONNECTED) 4] ls2 /
[zk-permanent, zk-test0000000000, zookeeper]
cZxid = 0x0
ctime = Thu Jan 01 08:00:00 CST 1970
mZxid = 0x0
mtime = Thu Jan 01 08:00:00 CST 1970
pZxid = 0x400000008
cversion = 3
dataVersion = 0
aclVersion = 0
ephemeralOwner = 0x0
dataLength = 0
numChildren = 3&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;使用 ls2 命令来查看某个目录包含的所有文件，与 ls 不同的是它查看到 time、version 等信息&lt;/p&gt;
&lt;h2 id=&quot;更新节点&quot;&gt;6.6 更新节点&lt;/h2&gt;
&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;[zk: localhost:2182,localhost:2183,localhost:2184(CONNECTED) 5] set /zk-permanent 456
cZxid = 0x400000008
ctime = Tue Mar 03 21:35:20 CST 2020
mZxid = 0x400000009
mtime = Tue Mar 03 21:40:11 CST 2020
pZxid = 0x400000008
cversion = 0
dataVersion = 1
aclVersion = 0
ephemeralOwner = 0x0
dataLength = 3
numChildren = 0&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;检查状态&quot;&gt;6.7 检查状态&lt;/h2&gt;
&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;[zk: localhost:2182,localhost:2183,localhost:2184(CONNECTED) 6] stat /zk-permanent
cZxid = 0x400000008
ctime = Tue Mar 03 21:35:20 CST 2020
mZxid = 0x400000009
mtime = Tue Mar 03 21:40:11 CST 2020
pZxid = 0x400000008
cversion = 0
dataVersion = 1
aclVersion = 0
ephemeralOwner = 0x0
dataLength = 3
numChildren = 0&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;删除节点&quot;&gt;6.8 删除节点&lt;/h2&gt;
&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;[zk: localhost:2182,localhost:2183,localhost:2184(CONNECTED) 7] rmr /zk-permanent
[zk: localhost:2182,localhost:2183,localhost:2184(CONNECTED) 8] ls /
[zk-test0000000000, zookeeper]&lt;/code&gt;
&lt;/pre&gt;

&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;公众号【当我遇上你】, 每天带给你不一样的内容&lt;/p&gt;
&lt;/blockquote&gt;
</description>
<pubDate>Tue, 03 Mar 2020 14:20:00 +0000</pubDate>
<dc:creator>当我遇上你csy</dc:creator>
<og:description>1. 概述 这里是 Docker 实战系列第四篇。主要介绍分布式系统中的元老级组件 Zookeeper。 ZooKeeper 是一个开源的分布式协调服务，是 Hadoop，HBase 和其他分布式框架</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/idea360/p/12405113.html</dc:identifier>
</item>
<item>
<title>ORB-SLAM2 运行 —— ROS + Android 手机摄像头 - MingruiYu</title>
<link>http://www.cnblogs.com/MingruiYu/p/12404730.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/MingruiYu/p/12404730.html</guid>
<description>&lt;p&gt;本文介绍了如何实现以 Android 手机摄像头为输入，运行 ORB-SLAM2 ROS Mono。1. 介绍了 ROS 的配置安装和 ORB-SLAM2 ROS 的配置安装；2.介绍了如何实现Android 手机摄像头与 PC 进行基于 ROS 的通信；3. 进行手机摄像头标定；4. 使用 Android 手机摄像头，运行 ORB-SLAM2 ROS Mono；5. 简化启动 ，一个脚本运行多个终端。&lt;/p&gt;&lt;div id=&quot;cnblogs_post_body&quot; readability=&quot;242.23664980326&quot;&gt;
&lt;p&gt;转载请注明出处，谢谢&lt;br/&gt;原创作者：Mingrui&lt;br/&gt;原创链接：&lt;a href=&quot;https://www.cnblogs.com/MingruiYu/p/12404730.html&quot; class=&quot;uri&quot;&gt;https://www.cnblogs.com/MingruiYu/p/12404730.html&lt;/a&gt;&lt;/p&gt;
&lt;hr/&gt;&lt;p&gt;本文要点：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;ROS 配置安装
&lt;ul&gt;&lt;li&gt;解决 &lt;code&gt;sudo rosdep init&lt;/code&gt; 报错 &lt;code&gt;Website may be down.&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;ORB-SLAM2 ROS 配置安装
&lt;ul&gt;&lt;li&gt;解决报错 &lt;code&gt;DSO missing from command line&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Android 手机摄像头与 PC 进行基于 ROS 的通信&lt;/li&gt;
&lt;li&gt;手机摄像头标定
&lt;ul&gt;&lt;li&gt;采集标定图像&lt;/li&gt;
&lt;li&gt;OpenCV samples 相机标定例程&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;使用 Android 手机摄像头，运行 ORB-SLAM2 ROS Mono&lt;/li&gt;
&lt;li&gt;简化启动
&lt;ul&gt;&lt;li&gt;使用 gnome-terminal，一个脚本运行多个终端&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;最近研究 ORB-SLAM2，自然是想能自己实时跑一跑。但最近因为疫情只能待在家里，身边能当摄像头的东西好像只有笔记本摄像头和手机摄像头。笔记本摄像头不方便（特别是我的 matebook 14 这个在键盘上的弹出摄像头，如想实现可&lt;a href=&quot;https://www.cnblogs.com/feifanrensheng/p/8995836.html&quot;&gt;参考&lt;/a&gt;），所以选择使用手机摄像头。ORB-SLAM2 官方提供了 ROS 的支持，再结合网上各路大佬提供的工具，最终实现了以 Android 手机摄像头为输入，基于 ROS 在 PC 上实时运行 ORB-SLAM2 Mono。本文将从零开始，介绍如何实现这一目标。&lt;/p&gt;
&lt;p&gt;本文环境为：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;Ubuntu 18.04&lt;/li&gt;
&lt;li&gt;ROS Melodic&lt;/li&gt;
&lt;li&gt;Android 手机（MI 9 SE）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;首先是 ROS 的配置安装，参照 &lt;a href=&quot;http://wiki.ros.org/melodic/Installation/Ubuntu&quot;&gt;ROS 官方安装教程&lt;/a&gt;，其中第一步使用国内镜像：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;sudo sh -c '. /etc/lsb-release &amp;amp;&amp;amp; echo &quot;deb http://mirrors.ustc.edu.cn/ros/ubuntu/ $DISTRIB_CODENAME main&quot; &amp;gt; /etc/apt/sources.list.d/ros-latest.list'&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;sudo-rosdep-init-出错&quot;&gt;sudo rosdep init 出错&lt;/h3&gt;
&lt;p&gt;安装步骤中 &lt;code&gt;sudo rosdep init&lt;/code&gt; 报错：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;ERROR: cannot download default sources list from:
https://raw.githubusercontent.com/ros/rosdistro/master/rosdep/sources.list.d/20-default.list
Website may be down.&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;首先试一试在浏览器中能不能打开，如果打不开的话，说明该网站需要翻。&lt;/p&gt;
&lt;p&gt;因为在终端中安装，所以光浏览器能翻不够，还得配置终端翻。如果使用的是 ss 的话，终端还需要额外配置。配置方法可自行 google。&lt;/p&gt;
&lt;p&gt;成功配置终端后，如果还报这个错，则需要：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;sudo c_rehash /etc/ssl/certs 
sudo -E rosdep init&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;之后再 rosdep update 就可以了。&lt;/p&gt;
&lt;h3 id=&quot;学习教程&quot;&gt;学习教程&lt;/h3&gt;
&lt;p&gt;&lt;a href=&quot;http://wiki.ros.org/ROS/Tutorials&quot;&gt;ROS-Tutorials&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;编译&quot;&gt;编译&lt;/h2&gt;
&lt;p&gt;ORB-SLAM2 的配置安装可见 &lt;a href=&quot;https://github.com/raulmur/ORB_SLAM2&quot;&gt;raulmur/ORB_SLAM2&lt;/a&gt;。之前的博文 &lt;a href=&quot;https://www.cnblogs.com/MingruiYu/p/12286752.html&quot;&gt;ORB-SLAM2 初体验 —— 配置安装&lt;/a&gt; 中介绍了不包括 ROS 支持的 ORB-SLAM2 配置安装。包括 ROS 支持的配置安装可见 &lt;a href=&quot;https://github.com/raulmur/ORB_SLAM2#7-ros-examples&quot;&gt;raulmur/ORB_SLAM2#7-ros-examples&lt;/a&gt;：&lt;/p&gt;
&lt;p&gt;在 ~/.bashrc 中添加 ORB-SLAM2 path 至 ROS_PACKAGE_PATH&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;# 打开 ~/.bashrc
sudo gedit ~/.bashrc

# 添加
export ROS_PACKAGE_PATH=${ROS_PACKAGE_PATH}:PATH/ORB_SLAM2/Examples/ROS
# （注意修改 PATH 为自己 ORB-SLAM2 的目录）&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;NOTICE:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;${ROS_PACKAGE_PATH}:和PATH之间不能有空格。&lt;/li&gt;
&lt;li&gt;添加的位置要在之前添加的其它的 source 命令之后。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;之后进行编译：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;cd PATH/ORB_SLAM2
chmod +x build_ros.sh

./build_ros.sh&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;会报错：&lt;code&gt;DSO missing from command line&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;解决方法：&lt;a href=&quot;https://github.com/raulmur/ORB_SLAM2/issues/535&quot;&gt;ERROR while running ./build_ros.sh #535&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;运行&quot;&gt;运行&lt;/h2&gt;
&lt;p&gt;例如运行单目 ORB-SLAM2：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;rosrun ORB_SLAM2 Mono PATH_TO_VOCABULARY PATH_TO_SETTINGS_FILE&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;下文会详细介绍如何运行。&lt;/p&gt;
&lt;h2 id=&quot;android-手机摄像头与-pc-进行基于-ros-的通信&quot;&gt;Android 手机摄像头与 PC 进行基于 ROS 的通信&lt;/h2&gt;
&lt;p&gt;该实现基于 GitHub 上的一个项目：&lt;a href=&quot;https://github.com/hitcm/Android_Camera-IMU&quot;&gt;hitcm/Android_Camera-IMU&lt;/a&gt;，作者实现了将手机的摄像头信息和 IMU 信息传给 PC（可参考作者博文 &lt;a href=&quot;https://www.cnblogs.com/hitcm/p/5616364.html&quot;&gt;ROS实时采集Android的图像和IMU数据&lt;/a&gt;）。本文中，我们只需使用摄像头信息。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;git clone https://github.com/hitcm/Android_Camera-IMU.git

sudo apt-get install ros-melodic-imu-tools  # 修改对应自己的 ROS 版本（本文中其实不需要）&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;将 clone 下来的文件夹中已经编译好的 apk 拷到 Android 手机上，在手机上安装。并将 PC 和 Android 手机 置于同一局域网下。&lt;/p&gt;
&lt;h3 id=&quot;运行方式&quot;&gt;运行方式：&lt;/h3&gt;
&lt;p&gt;PC Terminal 1: &lt;code&gt;roscore&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Android: 打开应用，在 在 IP Port 中修改 IP 地址为 PC的 IP地址，port不需要修改（PC 的 IP 可在 PC 终端输入 &lt;code&gt;ifconfig&lt;/code&gt; 查看），之后点击 Connect，连接成功则进入相机界面。&lt;/p&gt;
&lt;p&gt;PC Terminal 2:&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;cd Android_Camera-IMU
roslaunch android_cam-imu.launch&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;之后会弹出一个 Rviz 界面:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;如果要实时显示 image，需要 Add - By topic - 添加/camera/image_raw/image。&lt;/li&gt;
&lt;li&gt;如果要显示 imu，则需要 Add - By topic - 添加 imu，且在 Fix Frame 中 将 map 改为 imu。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;为了 ORB-SLAM2 准确运行，需要对手机摄像头进行标定。标定方式为：对棋盘格标定板进行各个方向的拍照，之后基于 OpenCV 进行标定。注意这里采集的图片需要和 ORB-SLAM2 程序读取到的一致，所以不能直接使用手机自带相机 app 拍照，因为手机会自动通过算法进行校正，而上述通信传输的是 raw images。因此，首先我们需要完成的任务是：采集并保存摄像头图像。&lt;/p&gt;
&lt;p&gt;使用下图作为标定板（&lt;a href=&quot;https://www.jianshu.com/p/967a35dbb56a&quot;&gt;参考资料&lt;/a&gt;），可直接在电脑屏幕上显示，对其拍照即可。&lt;/p&gt;
&lt;div align=&quot;center&quot;&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1921421/202003/1921421-20200303204007458-1541078895.png&quot; width=&quot;80%&quot;/&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;注意：&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;实验发现，使用长宽格数不一样的棋盘标定板效果更好。&lt;/li&gt;
&lt;li&gt;实验发现，标定板周围要是白色的才行，黑色的提取不出角点来（在电脑屏幕上显示标定板时尤其需要注意）。&lt;/li&gt;
&lt;li&gt;摄像头需要从不同方向拍摄棋盘格，可参考 OpenCV 安装目录下 samples/data 中的 left0x.jpg 系列标定图片。&lt;/li&gt;
&lt;/ul&gt;&lt;h2 id=&quot;采集并保存图片&quot;&gt;采集并保存图片&lt;/h2&gt;
&lt;p&gt;目前没有找到直接保存的方法，所以我们选择写一个 ROS node 来接收手机传来的图像，再通过 OpenCV 进行显示和保存。&lt;/p&gt;
&lt;p&gt;为了方便，我们选择直接在 ORB-SLAM2 的 ros_mono.cc 的代码基础上进行修改，在 ros_mono.cc 同一目录下写了个 ros_camera_capture.cc：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;/**
* This file is to capture images from Android phone, for camera calibration
* This file is used with Android_Camera-IMU
*/

#include&amp;lt;iostream&amp;gt;
#include&amp;lt;algorithm&amp;gt;
#include&amp;lt;fstream&amp;gt;
#include&amp;lt;chrono&amp;gt;

#include&amp;lt;ros/ros.h&amp;gt;
#include &amp;lt;cv_bridge/cv_bridge.h&amp;gt;

#include&amp;lt;opencv2/core/core.hpp&amp;gt;

#include&quot;../../../include/System.h&quot;

using namespace std;

string save_dir = &quot;PATH&quot;; // 修改为自己保存图片的路径
int imgId = 0;

void GrabImage(const sensor_msgs::ImageConstPtr&amp;amp; msg);

int main(int argc, char **argv)
{

    std::cout &amp;lt;&amp;lt; &quot;To save the current frame, please press 'Q' or 'q' &quot; &amp;lt;&amp;lt; std::endl;
    std::cout &amp;lt;&amp;lt; &quot;The images will be saved to &quot; &amp;lt;&amp;lt;  save_dir &amp;lt;&amp;lt; std::endl;

    ros::init(argc, argv, &quot;PClistener&quot;);
    ros::start();

    ros::NodeHandle nodeHandler;
    ros::Subscriber sub = nodeHandler.subscribe(&quot;/camera/image_raw&quot;, 1, GrabImage);

    ros::spin();

    ros::shutdown();

    return 0;
}

void GrabImage(const sensor_msgs::ImageConstPtr&amp;amp; msg)
{
    string imgname;
    cv_bridge::CvImageConstPtr cv_ptr;
    try
    {
        cv_ptr = cv_bridge::toCvShare(msg);
        cv::Mat img = cv_ptr-&amp;gt;image;
        cv::imshow(&quot;img_name&quot;, img);

        char key = cv::waitKey(1);
        // press &quot;q&quot; to save the image 
        if(key == 'q' || key == 'Q'){  
            imgId++;
            imgname = &quot;img_&quot; + to_string(imgId) + &quot;.jpg&quot;;
            cv::imwrite(save_dir + imgname, img);
            std::cout &amp;lt;&amp;lt; &quot;has saved image &quot;&amp;lt;&amp;lt; imgId &amp;lt;&amp;lt; &quot; to &quot; &amp;lt;&amp;lt; save_dir &amp;lt;&amp;lt; std::endl;
        }
    }
    catch (cv_bridge::Exception&amp;amp; e)
    {
        ROS_ERROR(&quot;cv_bridge exception: %s&quot;, e.what());
        return;
    }
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;注意修改其中保存图像的目录。&lt;/p&gt;
&lt;p&gt;另外，在 ORB_SLAM2/Examples/ROS/ORB_SLAM2 目录中的 CMakeLists.txt 中添加如下内容（添加在 # Node for monocular camera 上方即可）：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;# Node for capture images for camera calibration
rosbuild_add_executable(CameraCapture
src/ros_camera_capture.cc
)

target_link_libraries(CameraCapture
${LIBS}
)&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;之后重新编译 ORB_SLAM2 项目。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;cd PATH/ORB_SLAM2
./build_ros.sh&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;使用方法&quot;&gt;使用方法：&lt;/h3&gt;
&lt;p&gt;Terminal 1:&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;roscore&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;手机进入 app 运行&lt;/p&gt;
&lt;p&gt;Terminal 2: 在 Android_Camera-IMU 目录&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;roslaunch android_cam-imu.launch&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;（可以关掉 Rviz）&lt;/p&gt;
&lt;p&gt;Terminal 3:&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;rosrun ORB_SLAM2 CameraCapture&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;鼠标选中图像框，按下 q 键保存图像。&lt;/p&gt;
&lt;h2 id=&quot;进行标定&quot;&gt;进行标定&lt;/h2&gt;
&lt;p&gt;使用 OpenCV samples 中的代码实现。&lt;a href=&quot;https://www.jianshu.com/p/967a35dbb56a&quot;&gt;参考资料&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&quot;标定例程&quot;&gt;标定例程&lt;/h3&gt;
&lt;p&gt;新建一个工作目录（文件夹）camera_calibration_opencv，将 OpenCV 安装目录中的 samples/cpp/tutorial_code/calib3d/camera_calibration 文件夹内的内容拷贝至该目录。&lt;/p&gt;
&lt;h3 id=&quot;修改-vid5.xml&quot;&gt;修改 VID5.xml&lt;/h3&gt;
&lt;p&gt;VID5.xml 中存储着标定图像的路径，所以要在 VID.xml 中添加所有标定图像的路径，eg：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;&amp;lt;?xml version=&quot;1.0&quot;?&amp;gt;
&amp;lt;opencv_storage&amp;gt;
&amp;lt;images&amp;gt;
PATH/img_1.jpg
PATH/img_2.jpg
PATH/img_3.jpg
&amp;lt;/images&amp;gt;
&amp;lt;/opencv_storage&amp;gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;修改-in_vid5.xml&quot;&gt;修改 in_VID5.xml&lt;/h3&gt;
&lt;pre&gt;
&lt;code&gt;&amp;lt;BoardSize_Width&amp;gt; 9&amp;lt;/BoardSize_Width&amp;gt;
&amp;lt;BoardSize_Height&amp;gt;6&amp;lt;/BoardSize_Height&amp;gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;表示棋盘格的宽和高，注意，这里的宽度和高度是指内部交叉点的个数，而不是方形格的个数。如上图棋盘的数据就是9和6。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;&amp;lt;Square_Size&amp;gt;20&amp;lt;/Square_Size&amp;gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;修改为每格的边长 (mm)，拿尺子量。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;&amp;lt;Input&amp;gt;&quot;VID5.xml&quot;&amp;lt;/Input&amp;gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;修改 VID5.xml 的路径。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;&amp;lt;Calibrate_FixPrincipalPointAtTheCenter&amp;gt; 1 &amp;lt;/Calibrate_FixPrincipalPointAtTheCenter&amp;gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;此处原来是0，需要改为1，表示引入切向畸变参数（因为 ORB-SLAM2 中也引入了切向畸变参数），否则只有径向畸变参数。&lt;/p&gt;
&lt;p&gt;其它地方应该不需要改动，想进一步了解可看其中的注释。&lt;/p&gt;
&lt;h3 id=&quot;编译-1&quot;&gt;编译&lt;/h3&gt;
&lt;p&gt;在工作目录 camera_calibration_opencv 中新建 CMakeLists.txt:&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;project(Camera_Calibration)
set(CMAKE_CXX_STANDARD 11)

find_package(OpenCV 3.0 QUIET)
if(NOT OpenCV_FOUND)    
    find_package(OpenCV 2.4.3 QUIET)
    if(NOT OpenCV_FOUND)
        message(FATAL_ERROR &quot;OpenCV &amp;gt; 2.4.3 not found.&quot;)
    endif()
endif()

include_directories(${OpenCV_INCLUDE_DIR})
add_executable(Camera_Calibration camera_calibration.cpp)
target_link_libraries(Camera_Calibration ${OpenCV_LIBS})&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;之后编译：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;cd camera_calibration_opencv
mkdir build
cd build
cmake ..
make&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;运行标定&quot;&gt;运行，标定&lt;/h3&gt;
&lt;pre&gt;
&lt;code&gt;cd camera_calibration_opencv
./Camera_Calibration in_VID5.xml&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;程序启动后会显示标定图像的角点提取情况，之后会显示校正后图像，一个一个全部关闭后才会保存标定参数至 out_camera_data.xml。&lt;/p&gt;
&lt;h3 id=&quot;参数填入-orb-slam2-的配置文件&quot;&gt;参数填入 ORB-SLAM2 的配置文件&lt;/h3&gt;
&lt;p&gt;参数输出在 out_camera_data.xml 中:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;code&gt;&amp;lt;camera_matrix type_id=&quot;opencv-matrix&quot;&amp;gt;&lt;/code&gt; 是相机内参矩阵，顺序为 fx, 0, cx; 0, fy, cy; 0, 0, 1。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;&amp;lt;distortion_coefficients type_id=&quot;opencv-matrix&quot;&amp;gt;&lt;/code&gt; 是畸变参数，其顺序为 k1, k2, p1, p2, k3。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;之后在 ORB_SLAM2 中新建一个配置文件 AndroidPhone.yaml（建哪儿都行，我为了方便就和 TUM1.yaml 放在了一个目录下），将 TUM1.yaml 的内容拷贝过来，并把其中的 Camera 参数进行修改。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;注意：&lt;/strong&gt; 相机参数对 ORB-SLAM2 的运行效果有极大影响（尤其是初始化），所以标定过程须认真完成。&lt;/p&gt;

&lt;p&gt;Terminal 1:&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;roscore&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;手机进入 app 运行&lt;/p&gt;
&lt;p&gt;Terminal 2: 在 Android_Camera-IMU 目录&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;roslaunch android_cam-imu.launch&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;（可以关掉 rvis）&lt;/p&gt;
&lt;p&gt;Terminal 3:&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;rosrun ORB_SLAM2 Mono PATH_TO_VOCABULARY PATH_TO_SETTINGS_FILE&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;运行效果展示：&lt;/p&gt;
&lt;div align=&quot;center&quot;&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1921421/202003/1921421-20200303212256982-1764388506.gif&quot; width=&quot;100%&quot;/&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;注意：&lt;/strong&gt; ORB-SLAM2 Mono 还是比较难以初始化的（其设置的初始化条件相对苛刻），在开始时，选择特征纹理丰富的区域，多上下左右平移相机，有利于初始化。&lt;/p&gt;

&lt;p&gt;上述启动步骤需要启动3个终端，挺麻烦的，所以可以选择写一个脚本来自动启动这3个终端。&lt;a href=&quot;https://blog.csdn.net/zhubaohua_bupt/article/details/53925641&quot;&gt;参考资料&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;新建 ORB_SLAM2_with_AndroidPhone.sh，在其中填入：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;gnome-terminal --title=&quot;roscore&quot; -x bash -c &quot;roscore&quot;
# 暂停 2s，保证几个不同终端的启动顺序
sleep 2s;  

gnome-terminal --title=&quot;AndroidPhone&quot; -x bash -c &quot;cd PATH/Android_Camera-IMU; roslaunch android_cam-imu.launch&quot;
sleep 2s;

gnome-terminal --title=&quot;ORB-SLAM2&quot; -x bash -c &quot;rosrun ORB_SLAM2 Mono PATH_TO_VOCABULARY PATH_TO_SETTINGS_FILE&quot;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;之后赋予权限（仅需一次）：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;chmod +x ORB_SLAM2_with_AndroidPhone.sh&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;运行：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;./ORB_SLAM2_with_AndroidPhone.sh&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;即可一次性打开3个终端，并运行相关命令。之后手机再打开 app 就可以了。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;注意：&lt;/strong&gt; 此时终端运行结束后会自动退出，如果不想自动退出，可 在terminal点右键，选择Profiles-&amp;gt;Profile Preferences然后找到Title and Command，里面有一项When command exits，后面选择为Hold the terminal open。&lt;a href=&quot;https://www.cnblogs.com/chay/p/10303873.html&quot;&gt;参考资料&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;&lt;a href=&quot;https://www.cnblogs.com/MingruiYu/tag/ORB-SLAM2/&quot;&gt;ORB-SLAM2 系列博文&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;</description>
<pubDate>Tue, 03 Mar 2020 14:07:00 +0000</pubDate>
<dc:creator>MingruiYu</dc:creator>
<og:description>本文介绍了如何实现以 Android 手机摄像头为输入，运行 ORB-SLAM2 ROS Mono。1. 介绍了 ROS 的配置安装和 ORB-SLAM2 ROS 的配置安装；2.介绍了如何实现And</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/MingruiYu/p/12404730.html</dc:identifier>
</item>
</channel>
</rss>