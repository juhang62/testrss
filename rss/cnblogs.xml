<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="css/feed.xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/" xmlns:og="http://ogp.me/ns#">
<channel>
<atom:link rel="self" href="http://192.168.1.4/fivefilters/makefulltextfeed.php?url=feed.cnblogs.com%2Fblog%2Fsitehome%2Frss&amp;max=10&amp;links=preserve&amp;exc=" />
<atom:link rel="alternate" title="Source URL" href="http://feed.cnblogs.com/blog/sitehome/rss" />
<atom:link rel="related" title="Subscribe to feed" href="http://www.subtome.com/#/subscribe?feeds=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed.cnblogs.com%252Fblog%252Fsitehome%252Frss%26max%3D10%26links%3Dpreserve%26exc%3D&amp;back=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed.cnblogs.com%252Fblog%252Fsitehome%252Frss%26max%3D10%26links%3Dpreserve%26exc%3D" />
<title>博客园_首页</title>
<link></link>
<description>代码改变世界</description>
<item>
<title>自定义值类型一定不要忘了重写Equals，否则性能和空间双双堪忧 - 一线码农</title>
<link>http://www.cnblogs.com/huangxincheng/p/12996361.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/huangxincheng/p/12996361.html</guid>
<description>&lt;h2 id=&quot;一：背景&quot;&gt;一：背景&lt;/h2&gt;
&lt;h3 id=&quot;1-讲故事&quot;&gt;1. 讲故事&lt;/h3&gt;
&lt;p&gt;曾今在项目中发现有同事自定义结构体的时候，居然没有重写Equals方法，比如下面这段代码：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-C#&quot;&gt;
    static void Main(string[] args)
    {
        var list = Enumerable.Range(0, 1000).Select(m =&amp;gt; new Point(m, m)).ToList();
        var item = list.FirstOrDefault(m =&amp;gt; m.Equals(new Point(int.MaxValue, int.MaxValue)));
        Console.ReadLine();
    }

    public struct Point
    {
        public int x;
        public int y;

        public Point(int x, int y)
        {
            this.x = x;
            this.y = y;
        }
    }

&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;这代码貌似也没啥什么问题，好像大家平时也是这么写，没关系，有没有问题，跑一下再用windbg看一下。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/214741/202005/214741-20200531083918119-51310012.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-C#&quot;&gt;
0:000&amp;gt; !dumpheap -stat
Statistics:
              MT    Count    TotalSize Class Name
00007ff8826fba20       10        16592 ConsoleApp6.Point[]
00007ff8e0055e70        6        35448 System.Object[]
00007ff8826f5b50     2000        48000 ConsoleApp6.Point

0:000&amp;gt; !dumpheap  -mt 00007ff8826f5b50
         Address               MT     Size
0000020d00006fe0 00007ff8826f5b50       24     

0:000&amp;gt; !do 0000020d00006fe0
Name:        ConsoleApp6.Point
Fields:
              MT    Field   Offset                 Type VT     Attr            Value Name
00007ff8e00585a0  4000001        8         System.Int32  1 instance                0 x
00007ff8e00585a0  4000002        c         System.Int32  1 instance                0 y

&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;从上面的输出不知道你看出问题了没有？ 托管堆上居然有2000个Point，而且还可以用 &lt;code&gt;!do&lt;/code&gt; 打出来，说明这些都是引用类型。。。这些引用类型哪里来的？ 看代码应该是 &lt;code&gt;equals&lt;/code&gt; 比较时产生的，一次比较就有2个point被装箱放到托管堆上，这下惨了，，，而且大家应该知道引用对象本身还有&lt;code&gt;(8+8) byte&lt;/code&gt; 自带开销，这在时间和空间上都是巨大的浪费呀。。。&lt;/p&gt;
&lt;h2 id=&quot;二-探究默认的equals实现&quot;&gt;二: 探究默认的Equals实现&lt;/h2&gt;
&lt;h3 id=&quot;1-寻找valuetype的equals实现&quot;&gt;1. 寻找ValueType的Equals实现&lt;/h3&gt;
&lt;p&gt;为什么会这样呢？ 我们知道&lt;code&gt;equals&lt;/code&gt;是继承自&lt;code&gt;ValueType&lt;/code&gt;的，所以把 &lt;code&gt;ValueType&lt;/code&gt; 翻出来看看便知：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-C#&quot;&gt;
    public abstract class ValueType
    {
        public override bool Equals(object obj)
        {
            if (CanCompareBits(this)) {return FastEqualsCheck(this, obj);}
            FieldInfo[] fields = runtimeType.GetFields(BindingFlags.Instance | BindingFlags.Public | BindingFlags.NonPublic);
            for (int i = 0; i &amp;lt; fields.Length; i++)
            {
                object obj2 = ((RtFieldInfo)fields[i]).UnsafeGetValue(this);
                object obj3 = ((RtFieldInfo)fields[i]).UnsafeGetValue(obj);
                ...
            }
            return true;
        }
    }

&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;从上面代码中可以看出有如下三点信息：&lt;/p&gt;
&lt;p&gt;&amp;lt;1&amp;gt; 通用的 &lt;code&gt;equals&lt;/code&gt; 方法接收object类型，参数装箱一次。&lt;/p&gt;
&lt;p&gt;&amp;lt;2&amp;gt; &lt;code&gt;CanCompareBits,FastEqualsCheck&lt;/code&gt; 都是采用object类型，&lt;code&gt;this&lt;/code&gt;也需要装箱一次。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/214741/202005/214741-20200531083918375-2079005314.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&amp;lt;3&amp;gt; 有两种比较方式，要么采用 &lt;code&gt;FastEqualsCheck&lt;/code&gt; 比较，要么采用&lt;code&gt;反射&lt;/code&gt;比较，我去.... 反射就玩大了。&lt;/p&gt;
&lt;p&gt;综合来看确实没毛病， &lt;code&gt;equals&lt;/code&gt; 会把比较的两个对象都进行装箱。&lt;/p&gt;
&lt;h3 id=&quot;2-改进方案&quot;&gt;2. 改进方案&lt;/h3&gt;
&lt;p&gt;问题找到了，解决起来就简单了，不走这个通用的 equals 不就行啦，我自定义一个equals方法，然后跑一下代码。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-C#&quot;&gt;        public bool Equals(Point other)
        {
            return this.x == other.x &amp;amp;&amp;amp; this.y == other.y;
        }
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/214741/202005/214741-20200531083918658-344113624.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;可以看到走了我的自定义的Equals，🐮👃。 貌似问题就这样简单粗暴的解决了，真开心，打脸时刻开始。。。&lt;/p&gt;
&lt;h2 id=&quot;三：真的解决问题了吗？&quot;&gt;三：真的解决问题了吗？&lt;/h2&gt;
&lt;h3 id=&quot;1-遇到问题&quot;&gt;1. 遇到问题&lt;/h3&gt;
&lt;p&gt;很多时候我们会定义各种泛型类，在泛型操作中通常会涉及到T之间的 equals, 比如下面我设计的一段代码，为了方便,我把&lt;code&gt;Point&lt;/code&gt;的默认Equals也重写一下。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-C#&quot;&gt;
    class Program
    {
        static void Main(string[] args)
        {

            var p1 = new Point(1, 1);
            var p2 = new Point(1, 1);

            TProxy&amp;lt;Point&amp;gt; proxy = new TProxy&amp;lt;Point&amp;gt;() { Instance = p1 };

            Console.WriteLine($&quot;p1==p2 {proxy.IsEquals(p2)}&quot;);
            Console.ReadLine();
        }
    }

    public struct Point
    {
        public int x;
        public int y;

        public Point(int x, int y)
        {
            this.x = x;
            this.y = y;
        }

        public override bool Equals(object obj)
        {
            Console.WriteLine(&quot;我是通用的Equals&quot;);
            return base.Equals(obj);
        }

        public bool Equals(Point other)
        {
            Console.WriteLine(&quot;我是自定义的Equals&quot;);
            return this.x == other.x &amp;amp;&amp;amp; this.y == other.y;
        }
    }

    public class TProxy&amp;lt;T&amp;gt;
    {
        public T Instance { get; set; }

        public bool IsEquals(T obj)
        {
            var b = Instance.Equals(obj);

            return b;
        }
    }

&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/214741/202005/214741-20200531083918931-1988527314.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;从输出结果看，还是走了通用的equals方法，这就尴尬了，为什么会这样呢？&lt;/p&gt;
&lt;h3 id=&quot;2-从fcl的值类型实现上寻找问题&quot;&gt;2. 从FCL的值类型实现上寻找问题&lt;/h3&gt;
&lt;p&gt;有时候苦思冥想找不出问题，突然灵光一现，FCL中不也有一些自定义值类型吗？ 比如 &lt;code&gt;int,long,decimal&lt;/code&gt;，何不看它们是怎么实现的，寻找寻找灵感, 对吧。。。说干就干，把 &lt;code&gt;int32&lt;/code&gt; 源码翻出来。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-C#&quot;&gt;
public struct Int32 : IComparable, IFormattable, IConvertible, IComparable&amp;lt;int&amp;gt;, IEquatable&amp;lt;int&amp;gt;
{
        public override bool Equals(object obj)
        {
                if (!(obj is int))
                {
                        return false;
                }
                return this == (int)obj;
        }

    public bool Equals(int obj)
        {
                return this == obj;
        }
}

&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;我去，还是int🐮👃，貌似我的Point就比int少了接口实现，问题应该就出在这里，而且最后一个泛型接口&lt;code&gt;IEquatable&amp;lt;int&amp;gt;&lt;/code&gt;特别显眼，看下定义：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-C#&quot;&gt;
public interface IEquatable&amp;lt;T&amp;gt;
{
        bool Equals(T other);
}

&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;这个泛型接口也仅仅只有一个&lt;code&gt;equals&lt;/code&gt;方法，不过灵感告诉我，貌似。。。也许。。。应该。。。就是这个泛型的&lt;code&gt;equals&lt;/code&gt;是用来解决泛型情况下的&lt;code&gt;equals&lt;/code&gt;比较。&lt;/p&gt;
&lt;h3 id=&quot;3-补上-iequatable-接口&quot;&gt;3. 补上 IEquatable 接口&lt;/h3&gt;
&lt;p&gt;有了这个思路，我也跟FCL学，让Point实现 &lt;code&gt;IEquatable&amp;lt;T&amp;gt;&lt;/code&gt;接口,然后在&lt;code&gt;TProxy&amp;lt;T&amp;gt;&lt;/code&gt;代理类中约束下必须实现&lt;code&gt;IEquatable&amp;lt;T&amp;gt;&lt;/code&gt;，修改代码如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-C#&quot;&gt;
    public struct Point : IEquatable&amp;lt;Point&amp;gt; { ...  }
    public class TProxy&amp;lt;T&amp;gt; where T: IEquatable&amp;lt;T&amp;gt; { ... }

&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;然后将程序跑起来，如下图：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/214741/202005/214741-20200531083919096-396404763.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;🐮👃，虽然是成功了，但有一个地方让我不是很舒服，就是上面的第二行代码，在 &lt;code&gt;TProxy&amp;lt;T&amp;gt;&lt;/code&gt; 处约束了&lt;code&gt;T&lt;/code&gt;，因为我翻看&lt;code&gt;List&lt;/code&gt;的实现也没做这样的泛型约束呀，可能有点强迫症吧，贴一下代码给大家看看。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-C#&quot;&gt;
public class List&amp;lt;T&amp;gt; : IList&amp;lt;T&amp;gt;, ICollection&amp;lt;T&amp;gt;, IEnumerable&amp;lt;T&amp;gt;, IEnumerable, IList, ICollection, IReadOnlyList&amp;lt;T&amp;gt;, IReadOnlyCollection&amp;lt;T&amp;gt;
{}

&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;然后我继续模仿List，把 &lt;code&gt;TProxy&amp;lt;T&amp;gt;&lt;/code&gt; 上的T约束去掉，结果就出问题了，又回到了 &lt;code&gt;通用Equals&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/214741/202005/214741-20200531083919369-461352308.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;h3 id=&quot;4-从list的contains源码中寻找答案&quot;&gt;4. 从List的Contains源码中寻找答案&lt;/h3&gt;
&lt;p&gt;好奇心再次驱使我寻找List中是如何做到的，为了能看到List中原生方法，修改代码如下，从&lt;code&gt;Contains&lt;/code&gt;方法入手。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-C#&quot;&gt;
    var list = Enumerable.Range(0, 1000).Select(m =&amp;gt; new Point(m, m)).ToList();
    var item = list.Contains(new Point(int.MaxValue, int.MaxValue));

---------- outout ---------------
我是自定义的Equals
我是自定义的Equals
我是自定义的Equals
...

&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;我也是太好奇了，翻看下 &lt;code&gt;Contains&lt;/code&gt; 的源码，简化后实现如下。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-C#&quot;&gt;
public bool Contains(T item)
{
    ...
        EqualityComparer&amp;lt;T&amp;gt; @default = EqualityComparer&amp;lt;T&amp;gt;.Default;
        for (int j = 0; j &amp;lt; _size; j++)
        {
                if (@default.Equals(_items[j], item)) {return true;}
        }
        return false;
}

&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;原来List是在进行 &lt;code&gt;equals&lt;/code&gt;比较之前，自己构建了一个泛型比较器&lt;code&gt;EqualityComparer&amp;lt;T&amp;gt;&lt;/code&gt;，🐮👃，然后继续追一下代码。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/214741/202005/214741-20200531083919632-1627927390.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;因为这里的&lt;code&gt;runtimeType&lt;/code&gt;实现了&lt;code&gt;IEquatable&amp;lt;T&amp;gt;&lt;/code&gt;接口，所以代码返回了一个泛型比较器：&lt;code&gt;GenericEqualityComparer&amp;lt;T&amp;gt;&lt;/code&gt;，然后我们继续查看这个泛型比较器是咋样的。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/214741/202005/214741-20200531083919996-1749654737.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;从图中可以看到最终还是对&lt;code&gt;T&lt;/code&gt;进行了&lt;code&gt;IEquatable&amp;lt;T&amp;gt;&lt;/code&gt;约束，不过这里给提取出来了，还是挺厉害的，然后我也学的模仿一下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/214741/202005/214741-20200531083920253-1830880346.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;可以看到也走了我的自定义实现，两种方式大家都可以用哈😁😁😁。&lt;/p&gt;
&lt;p&gt;最后要注意一点的是，当你重写了&lt;code&gt;Equals&lt;/code&gt;之后，编译器会告知你最好也把 &lt;code&gt;GetHashCode&lt;/code&gt;重写一下，只是建议，如果看不惯这个提示，尽可能自定义&lt;code&gt;GetHashCode&lt;/code&gt;方法让&lt;code&gt;hashcode&lt;/code&gt;分布的均匀一点。&lt;/p&gt;
&lt;h2 id=&quot;四：总结&quot;&gt;四：总结&lt;/h2&gt;
&lt;p&gt;一定要实现自定义值类型的 &lt;code&gt;Equals&lt;/code&gt;方法，人家的 &lt;code&gt;Equals&lt;/code&gt;方法是用来兜底的，一次比较两次装箱，对你的程序可是双杀哦😁😁😁。&lt;/p&gt;
&lt;hr/&gt;&lt;h3 id=&quot;如您有更多问题与我互动，扫描下方进来吧&quot;&gt;如您有更多问题与我互动，扫描下方进来吧~&lt;/h3&gt;
&lt;hr/&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/214741/202005/214741-20200522143723695-575216767.png&quot; width=&quot;600&quot; height=&quot;200&quot; alt=&quot;图片名称&quot; align=&quot;center&quot;/&gt;</description>
<pubDate>Sun, 31 May 2020 00:39:00 +0000</pubDate>
<dc:creator>一线码农</dc:creator>
<og:description>一：背景 1. 讲故事 曾今在项目中发现有同事自定义结构体的时候，居然没有重写Equals方法，比如下面这段代码： static void Main(string[] args) { var list</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/huangxincheng/p/12996361.html</dc:identifier>
</item>
<item>
<title>女生适合学编程吗？ - 沉默王二</title>
<link>http://www.cnblogs.com/qing-gee/p/12996317.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/qing-gee/p/12996317.html</guid>
<description>&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;二哥，你好，我 Java 是自学的，现在很迷茫，头发越掉越多，还是单身狗，真怕再学下去就嫁不出去了。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;以上是一个妹子私信我的内容，看完后觉得蛮感慨的。就来谈谈这个话题吧：女生到底适不适合学编程？&lt;/p&gt;
&lt;img src=&quot;http://www.itwanger.com/assets/images/2020/05/nvsheng-biancheng-01.gif&quot; alt=&quot;&quot; title=&quot;&quot;/&gt;&lt;p&gt;按照我目前的理解来看，编程属于脑力活动，女生在这方面好像没有什么劣势。假如非要把编程定义为体力劳动的话，我想巾帼不会让须眉的，毕竟你看男足有多差，女足就有多优秀。&lt;/p&gt;
&lt;p&gt;最近一段时间，找我说自己迷茫的小伙伴非常多，有女生，当然也有男生。也就是说，迷茫对性别没有歧视。&lt;/p&gt;
&lt;p&gt;小伙伴们之所以迷茫，除了自身能力之外，和大环境不无关系，毕竟社会是一个整体，哪一个环节出了问题，其他环节肯定会受到不同程度的影响，这是必然的。&lt;/p&gt;
&lt;p&gt;你比如说，我就发现，朋友圈的微商多了起来。有些人生意做得不错，红红火火，有些就比较惨淡了。&lt;/p&gt;
&lt;p&gt;如果说本职工作蒸蒸日上的话，恐怕分到别处的精力就不会很多。拿我来说吧，之所以能够保持高频（母猪似的）的创作，很大一部分原因就是因为公司的业务停滞不前，频临倒闭——这是一件挺让我不爽的事，没办法，为了生活，只能把更多的经历投入到写作上面。不过这没什么，我也不需要遮遮掩掩的，编程相关的写作前程挺好的。&lt;/p&gt;
&lt;p&gt;我这么说，就是告诉小伙伴们一个事实，无论是男性还是女性，大家都不容易，迷茫是现阶段最正常不过的状态了。迷茫并不一定是坏事，对吧？它意味着你对自身感到不满，对现状感到不满，直白点说，就是你想进步了。那么一旦你提前做好了心理建设，从迷茫的困境中走出来，你可能就脱颖而出了。&lt;/p&gt;
&lt;p&gt;就我的程序生涯来说，女性程序员确实没有男性多，但这并不意味着女生就不适合学编程。有些女生心思细腻，写出来的代码就会更简洁，bug 更少。&lt;/p&gt;
&lt;p&gt;另外，我可以肯定一点的是，掉不掉头发真的与编程无关，我就觉得自己发量挺充足的——之前朋友圈爆过照，很多小伙伴都调侃我不是程序员，因为发型不太配，超出了他们的预期。我上高中那会还有不少白头发，这些年完全没有了——有点返老回童的感觉。&lt;/p&gt;
&lt;p&gt;如果真的是掉头发，我想编程不是嫌疑犯，过大的压力、糟糕的精神状态才是。无论从事什么职业，总要乐观一点，心态放轻松一点。&lt;/p&gt;
&lt;p&gt;我就认识这样一个女程序员，看她晒的电脑桌，我的口水就要流出来了，非常优雅和高贵，真真自愧不如啊。她平常还会在朋友圈晒一些自制的咖啡（带拉花的那种），总之，给人的感觉就是挺会生活的，偶尔寒暄几句，也可以感受到她惬意的生活品质。&lt;/p&gt;
&lt;p&gt;女生嘛，不能说把时间全部花费在容貌的搭理上，但至少应该花一些心思，一个美美的自己，一个美美的心情，学编程也许就会变得更轻松自如了。&lt;/p&gt;
&lt;p&gt;至于对象嘛，女生完全不用发愁，愁的应该是男生才对啊。真需要的话，我在公众号喊一声，我怕踊跃报名的男生能把妹子的微信加爆，搞不好微信都要封号处理。&lt;/p&gt;
&lt;p&gt;我在想，以后有机会，遇到特殊的日子，比如说 520，小伙伴们就可以提前私信我，“二哥，明天我要报名相亲，这是我的工资单，这是我的照骗，你看能不能匹配一下。”没准我就帮大家脱单了，也算是网络一线牵了。&lt;/p&gt;
&lt;p&gt;至于编程难不难，反正我觉得不容易，这恐怕是程序员高薪最重要的一个原因了。至于编程累不累，我想和学生做作业是一个道理，不会的学生永远都累。&lt;/p&gt;
&lt;p&gt;再来说说工作，女性在职场上，因为生理方面的因素，会受到一些歧视。但我总觉得这是社会的偏见，女性要学会自尊自爱，男性要学会尊重客观，性别上的差异不应该成为职场上的阻碍。&lt;/p&gt;
&lt;p&gt;在人类漫长的发展进程中，有一位女性值得所有人铭记，那就是居里夫人，首位获得诺贝尔奖（物理和化学，两次）的女性。在我看来，她最伟大的贡献不是这些，而是她改变了世界对女性的看法：谁说女性就不适合搞化学、搞物理？&lt;/p&gt;
&lt;p&gt;下面是我对女生学编程的一些建议，有些也适合男生了。&lt;/p&gt;
&lt;p&gt;诚实点说吧，我对编程算不上感兴趣。但当我确信编程能够养家糊口后，我就愿意为编程倾其所有。这么多年过去了，我深刻地认识到，我只能干好编程这一件事，如果说还有一件的话，就是写编程相关的文章。&lt;/p&gt;
&lt;p&gt;所以，如果编程是你的第一兴趣，那太完美了！但如果不是，也可以像我一样，渐渐地爱上它，尽自己最大的努力做好它。&lt;/p&gt;
&lt;p&gt;既然选择了远方，便只顾风雨兼程。真的，别怕。至于这个过程辛不辛苦，有所谓吗？谈恋爱辛苦吗？我有时候想想，谈恋爱真的比编程还要辛苦，但也有甜蜜和幸福啊。&lt;/p&gt;
&lt;p&gt;至于生理期，实在是说不下去了，我能说的就是尽量早睡早起，该锻炼锻炼。&lt;/p&gt;
&lt;p&gt;至于聪不聪明，喜不喜欢编程，有没有意志力，心能不能静下来，环境糟不糟糕，和性别完全没有关系，不管是女生还是男生，如果把借口放在最前面，恐怕编程学不好，其他任何一个行业都学不好。&lt;/p&gt;
&lt;p&gt;我是有这么一个打算，假如今年高考结束后，我妹妹找不到她的兴趣爱好，我就建议她学编程去，最次最次，还有我这个哥哥可以教教她，对吧？&lt;/p&gt;
&lt;p&gt;反正如果有女生遇到编程问题咨询我的话，我肯定第一时间冲过去。（逃逃逃&lt;/p&gt;
&lt;p&gt;如果觉得文章对你有点帮助，请微信搜索「 &lt;strong&gt;沉默王二&lt;/strong&gt; 」第一时间阅读。回复关键字「&lt;strong&gt;简历&lt;/strong&gt;」更有一份技术大佬整理的优质简历模板，助你一臂之力。&lt;/p&gt;
&lt;blockquote readability=&quot;4.4565217391304&quot;&gt;
&lt;p&gt;本文已收录 GitHub，&lt;a href=&quot;https://github.com/qinggee/itwanger.github.io&quot;&gt;&lt;strong&gt;传送门~&lt;/strong&gt;&lt;/a&gt; ，里面更有大厂面试完整考点，欢迎 Star。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;我是沉默王二，一枚有颜值却靠才华苟且的程序员。&lt;strong&gt;关注即可提升学习效率，别忘了三连啊，点赞、收藏、留言，我不挑，嘻嘻&lt;/strong&gt;。&lt;/p&gt;
</description>
<pubDate>Sat, 30 May 2020 23:40:00 +0000</pubDate>
<dc:creator>沉默王二</dc:creator>
<og:description>二哥，你好，我 Java 是自学的，现在很迷茫，头发越掉越多，还是单身狗，真怕再学下去就嫁不出去了。 以上是一个妹子私信我的内容，看完后觉得蛮感慨的。就来谈谈这个话题吧：女生到底适不适合学编程？ 按照</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/qing-gee/p/12996317.html</dc:identifier>
</item>
<item>
<title>图解大顶堆的构建、排序过程 - 鹿呦呦</title>
<link>http://www.cnblogs.com/sunshineliulu/p/12995910.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/sunshineliulu/p/12995910.html</guid>
<description>&lt;p&gt;这两天在复习大顶堆和小顶堆，比起两年前的懵懵懂懂，这次理解起来就容易了一些。又翻看了一下自己之前的笔记&lt;a href=&quot;https://www.cnblogs.com/sunshineliulu/p/8610645.html&quot;&gt;数据结构与算法之PHP排序算法（堆排序）&lt;/a&gt;，发现自己这次查阅资料，和之前的思路不太一样，遂写下这篇笔记，算是和以前的笔记做一个对照。&lt;/p&gt;
&lt;h4 id=&quot;一、什么是堆&quot;&gt;一、什么是堆&lt;/h4&gt;
&lt;p&gt;堆是一种非线性结构，可以把堆看作一棵二叉树，也可以看作一个数组，即：&lt;strong&gt;堆就是利用完全二叉树的结构来维护的一维数组&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;堆可以分为大顶堆和小顶堆。&lt;br/&gt;&lt;strong&gt;大顶堆&lt;/strong&gt;：每个结点的值都大于或等于其左右孩子结点的值。&lt;br/&gt;&lt;strong&gt;小顶堆&lt;/strong&gt;：每个结点的值都小于或等于其左右孩子结点的值。&lt;/p&gt;
&lt;p&gt;如果是排序，&lt;strong&gt;求升序&lt;/strong&gt;用大顶堆，&lt;strong&gt;求降序&lt;/strong&gt;用小顶堆。&lt;/p&gt;
&lt;p&gt;一般我们说 &lt;code&gt;topK&lt;/code&gt; 问题，就可以用大顶堆或小顶堆来实现，&lt;br/&gt;&lt;strong&gt;最大的 K 个&lt;/strong&gt;：小顶堆&lt;br/&gt;&lt;strong&gt;最小的 K 个&lt;/strong&gt;：大顶堆&lt;/p&gt;
&lt;h4 id=&quot;二、大顶堆的构建过程&quot;&gt;二、大顶堆的构建过程&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;大顶堆的构建过程就是从最后一个非叶子结点开始从下往上调整。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;最后一个非叶子节点怎么找&lt;/strong&gt;？这里我们用数组表示待排序序列，则最后一个非叶子结点的位置是：数组长度/2-1。假如数组长度为9，则最后一个非叶子结点位置是 9/2-1=3。&lt;/p&gt;
&lt;p&gt;比较当前结点的值和左子树的值，如果当前节点小于左子树的值，就交换当前节点和左子树；&lt;br/&gt;交换完后要检查左子树是否满足大顶堆的性质，不满足则重新调整子树结构；&lt;/p&gt;
&lt;p&gt;再比较当前结点的值和右子树的值，如果当前节点小于右子树的值，就交换当前节点和右子树；&lt;br/&gt;交换完后要检查右子树是否满足大顶堆的性质，不满足则重新调整子树结构；&lt;/p&gt;
&lt;p&gt;无需交换调整的时候，则大顶堆构建完成。&lt;/p&gt;
&lt;p&gt;画个图理解下，以 [3, 7, 16, 10, 21, 23] 为例：&lt;br/&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/953680/202005/953680-20200531004135177-1000133948.png&quot; alt=&quot;&quot;/&gt;&lt;br/&gt;代码如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-php&quot;&gt;&amp;lt;?php
/**
 * 构建大顶堆
 * 大顶堆的性质：每个结点的值都大于或等于其左右子结点的值。
 */
function buildBigHeap(&amp;amp;$arr, $len) {
    for ($i = floor($len/2) - 1; $i &amp;gt;= 0; $i--) {
        //根节点小于左子树
        if (2 * $i + 1 &amp;lt; $len &amp;amp;&amp;amp; $arr[$i] &amp;lt; $arr[2 * $i + 1]) {
            //交换根节点和左子树的值
            swap($arr, $i, 2 * $i + 1);
            // $temp = $arr[$i];
            // $arr[$i] = $arr[2 * $i + 1];
            // $arr[2 * $i + 1] = $temp;
            //检查左子树是否满足大顶堆的性质，如果不满足，则重新调整
            if ((2 * (2 * $i + 1) + 1 &amp;lt; $len &amp;amp;&amp;amp; $arr[2 * $i + 1] &amp;lt; $arr[2 * (2 * $i + 1) + 1])
            || (2 * (2 * $i + 1) + 2 &amp;lt; $len &amp;amp;&amp;amp; $arr[2 * $i + 1] &amp;lt; $arr[2 * (2 * $i + 1) + 2])) {
                buildBigHeap($arr, $len);
            }
        }
        //根节点小于右子树
        if (2 * $i + 2 &amp;lt; $len &amp;amp;&amp;amp; $arr[$i] &amp;lt; $arr[2 * $i + 2]) {
            //交换根节点和右子树的值
            swap($arr, $i, 2 * $i + 2);
            // $temp = $arr[$i];
            // $arr[$i] = $arr[2 * $i + 2];
            // $arr[2 * $i + 2] = $temp;
            //检查右子树是否满足大顶堆的性质，如果不满足，则重新调整
            if ((2 * (2 * $i + 2) + 1 &amp;lt; $len &amp;amp;&amp;amp; $arr[2 * $i + 2] &amp;lt; $arr[2 * (2 * $i + 2) + 1])
            || (2 * (2 * $i + 2) + 2 &amp;lt; $len &amp;amp;&amp;amp; $arr[2 * $i + 2] &amp;lt; $arr[2 * (2 * $i + 2) + 2])) {
                buildBigHeap($arr, $len);
            }
        }
    }
}

/**
 * 交换两个值
 * m n 为数组的下标
 */
function swap(&amp;amp;$arr, $m, $n) {
    $temp = $arr[$m];
    $arr[$m] = $arr[$n];
    $arr[$n] = $temp;
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;h4 id=&quot;三、大顶堆的排序过程&quot;&gt;三、大顶堆的排序过程&lt;/h4&gt;
&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;将待排序序列构造成一个大顶堆，此时，整个序列的最大值就是堆顶的根节点。将其与末尾元素进行交换，此时末尾就为最大值。然后将剩余n-1个元素重新构造成一个堆，这样会得到n个元素的次小值，如此反复执行，便能得到一个有序序列了。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;是不是对上面这一大段文字很头疼？其实排序过程用下面 4 步就能概括：&lt;br/&gt;第 1 步：先 n 个元素的无序序列，构建成大顶堆&lt;br/&gt;第 2 步：将根节点与最后一个元素交换位置，（将最大元素&quot;沉&quot;到数组末端）&lt;br/&gt;第 3 步：交换过后可能不再满足大顶堆的条件，所以需要将剩下的 n-1 个元素重新构建成大顶堆&lt;br/&gt;第 4 步：重复第 2 步、第 3 步直到整个数组排序完成。&lt;br/&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/953680/202005/953680-20200531013230974-864063180.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-php&quot;&gt;/**
 * 交换交换根节点和数组末尾元素的值
 */
function adjustHeap(&amp;amp;$heap, $len) {
    $temp = $heap[0];
    $heap[0] = $heap[$len - 1];
    $heap[$len - 1] = $temp;
}
/**
 * 堆排序
 */
function heapSort(&amp;amp;$arr) {
    $len = count($arr);
    for ($i = $len; $i &amp;gt; 0; $i--) {
        buildBigHeap($arr, $i);
        adjustHeap($arr, $i);
    }
}
&lt;/code&gt;
&lt;/pre&gt;</description>
<pubDate>Sat, 30 May 2020 16:42:00 +0000</pubDate>
<dc:creator>鹿呦呦</dc:creator>
<og:description>图解大顶堆的构建、排序过程</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/sunshineliulu/p/12995910.html</dc:identifier>
</item>
<item>
<title>图解MySQL索引(二)—为什么使用B+Tree - 浪人~</title>
<link>http://www.cnblogs.com/liqiangchn/p/12995831.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/liqiangchn/p/12995831.html</guid>
<description>&lt;p&gt;&lt;strong&gt;失踪人口回归，近期换工作一波三折，耽误了不少时间，从今开始每周更新~&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;索引是一种支持快速查询的数据结构，同时索引优化也是后端工程师的必会知识点。各个公司都有所谓的MySQL”军规“，其实这些所谓的优化和规定，并不是什么高深的技术，只是要求大家正确建立和使用索引而已。工欲善其事必先利其器，想要正确运用索引，需要了解其底层实现原理，本文将探索关于索引的“是什么”以及”为什么“。&lt;/p&gt;
&lt;p&gt;MySQL中关于索引的概念有很多，为了避免混淆，在上一篇文章中关于索引在不同维度分类设计到的一些名词进行了解释，如辅助索引，唯一索引，覆盖索引，B+Tree索引…., 墙裂建议不明白的小伙伴可以先去看看&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzI4MTA0OTIxMg==&amp;amp;mid=2247483703&amp;amp;idx=1&amp;amp;sn=8f186c5e1f09440b539594ece0a311eb&amp;amp;chksm=ebae6024dcd9e932e32c4468f0eb1fb8c148bed73ae0c33d06cb05314f2e12e07c977a144002&amp;amp;token=1212138108&amp;amp;lang=zh_CN#rd&quot;&gt;图解MySQL索引(上)—聊聊索引的分类&lt;/a&gt;，本文中关于索引类型的各种定义不再复述。&lt;/p&gt;
&lt;h3 id=&quot;hio&quot;&gt;&lt;span&gt;一，磁盘IO问题&lt;/span&gt;&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;1.1 磁盘IO&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;所谓磁盘IO，简单来讲就是就是将磁盘中的数据读取到内存或者是从内存写入磁盘。在系统开发与设计过程中，磁盘IO的瓶颈往往不可忽略，因为这是一个相对比较耗时的操作。&lt;/p&gt;
&lt;img src=&quot;http://source.mycookies.cn/202003152303_834.png?ERROR&quot; alt=&quot;&quot; title=&quot;&quot;/&gt;&lt;p&gt;上图是一个机械硬盘，虽然速度不如SSD，但是由于价格低廉，目前仍是主流的存储介质。它的IO操作通常需要&lt;strong&gt;寻道，旋转和传输&lt;/strong&gt;三个步骤。&lt;/p&gt;
&lt;img src=&quot;http://source.mycookies.cn/202003152308_686.png?ERROR&quot; alt=&quot;&quot; title=&quot;&quot;/&gt;&lt;p&gt;寻道，是指将读写磁头移动到正确的磁道，寻道时间越短，IO操作越快，目前磁盘的平均寻道时间一般在3-15ms左右。&lt;/p&gt;
&lt;p&gt;旋转，是指将盘片旋转到请求数据所在的扇区，这部分所需要的时间由硬盘的配置所决定。旋转延迟由磁盘转速所决定，也就是常说的7200转和5400转等。&lt;/p&gt;
&lt;p&gt;例如，7200转是指每分钟可以旋转7200圈，那么旋转一圈所需要的时间就是60*1000/7200 ≈ 8.33ms，而旋转延迟通常取旋转一周时间的1/2，也就是大约4.17ms。&lt;/p&gt;
&lt;p&gt;传输，磁盘传输的速度通常在几十到上百M每秒，假设速度为20M/s，要传输的数据为64kb，则传输时间则是 64 / 1024 / 20 * 1000 = 3.125ms。不过目前流行的SSD传输速度大幅度提升，SATA Ⅱ可以达到300M/s，传输速度往往远小于前两步操作所以传输时间往往可以忽略不记。&lt;/p&gt;
&lt;p&gt;机械硬盘的连续读写性能很好，但随机读写性能很差，这主要是因为磁头移动到正确的磁道上需要时间，随机读写时，磁头需要不停的移动，时间都浪费在了磁头寻址上，所以性能不高。&lt;/p&gt;
&lt;p&gt;上述过程是对传统机械磁盘IO延迟的粗略介绍，目的是告诉大家磁盘IO过程是个耗时的过程，内存操作往往与之速度不在同一个数量级。即使是目前比较流行的SSD，想必内存中数据读取性能也差之千里。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;1.2 局部性原理&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;由于磁盘IO是一个比较耗时的操作，而操作系统在设计时则定义一个空间局部性原则，局部性原理是指CPU访问存储器时，&lt;strong&gt;无论是存取指令还是存取数据，所访问的存储单元都趋于聚集在一个较小的连续区域中&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;在操作系统的文件系统中，数据也是按照page划分的，一般为4k或8k。&lt;strong&gt;当计算机访问一个地址数据时，不仅会加载当前数据所在的数据页，还会将当前数据页相邻的数据页一同加载到内存&lt;/strong&gt;。而这个过程实际上只发生了1次磁盘IO，这个理论对于索引的数据结构设计非常有帮助。&lt;/p&gt;
&lt;h3 id=&quot;h&quot;&gt;&lt;span&gt;二，索引数据结构演进&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;索引是一种&lt;strong&gt;支持快速查找的数据结构&lt;/strong&gt;，在运用中往往还要求能够支持&lt;strong&gt;顺序查询&lt;/strong&gt;，而常见的数据结构有很多，比如数组，链表，二叉树，散列表，二叉搜索树，平衡搜索二叉树，红黑树，跳表等。仅仅从数据结构那么为什么选择B+Tree呢？&lt;/p&gt;
&lt;p&gt;首先对于数组，链表这种线性表来说，适合存储数据，而不是查找数据，同样，对于普通二叉树来说，数据存储没有特定规律，所以也不适合。&lt;/p&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;2.1 哈希索引不能满足业务需求&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;哈希（Hash）是一种非常快的查找方法，在一般情况下这种查找的时间复杂度为O（1），即一般仅需要一次查找就能定位到数据。在各种编程语言和数据库中应用广泛，如Java，Python，Redis中都有使用。&lt;/p&gt;
&lt;img src=&quot;http://source.mycookies.cn/202005172358_399.gif?ERROR&quot; alt=&quot;&quot; title=&quot;&quot;/&gt;&lt;p&gt;哈希结构在单条数据的等值查询是性能非常优秀，但是&lt;strong&gt;只能用来搜索等值的查询&lt;/strong&gt;， 对于范围查询，模糊查询（最左前缀原则）都不支持，所以不能很好的支持业务需求；所以MySQL并没有显式支持Hash索引，而是根据数据的访问频次和模式自动的为热点数据页建立哈希索引，称之为自适应哈希索引。&lt;/p&gt;
&lt;p&gt;并且由于哈希函数的随机性，Hash索引通常都是&lt;strong&gt;随机的内存访问，对于缓存不友好&lt;/strong&gt;，会造成频繁的磁盘IO。&lt;/p&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;2.2 二叉搜索树退化成链表&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;二叉搜索树，如果左子树不为空，则左子树上所有节点均小于根节点，右子树节点均大于根节点；由其属性不难看出，这种树非常适合数据查找。不过有个致命的缺点是&lt;strong&gt;二叉搜索树的树型取决于数据的输入顺序&lt;/strong&gt;，极端情况下会退化成链表。&lt;/p&gt;
&lt;img src=&quot;http://source.mycookies.cn/202005112234_652.png?ERROR&quot; alt=&quot;&quot; title=&quot;&quot;/&gt;&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;2.3 平衡二叉搜索树过于严格&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;为了解决上述问题，平衡二叉搜索树就诞生了。在保证数据顺序的基础上，又能维持树型，保证每个节点的左右子树高度相差不超过1。&lt;/p&gt;
&lt;p&gt;不过由于要维持树的平衡，&lt;strong&gt;在插入数据时可能要进行大量的数据移动&lt;/strong&gt;。平衡搜索二叉树过于严格的平衡要求，导致几乎每次插入和删除节点都会破坏树的平衡性，使得树的性能大打折扣。&lt;/p&gt;
&lt;img src=&quot;http://source.mycookies.cn/202005112235_894.gif?ERROR&quot; alt=&quot;&quot; title=&quot;&quot;/&gt;&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;2.4 红黑树高度过高，磁盘IO次数频繁&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;有没有一种数据结构，即能够快速查找数据，又不需要频繁的调整以维持平衡呢？这时红黑树就闪亮登场了。&lt;/p&gt;
&lt;p&gt;红黑树和其他二叉搜索树类似， 都是在进行插入和删除操作时通过特定操作保持二叉查找树的性质，从而获得较高的查找性能。与之不同的是，红黑树的平衡性并不像平衡搜索二叉树一样严格的同时，又能保证在， O(log n) 时间复杂度内做查找和删除。&lt;/p&gt;
&lt;p&gt;红黑树通过改变节点的颜色，可以有效减少节点的移动次数，由于红黑树的实现比较复杂，本文不再展开，感兴趣的小伙伴可以去深入学习。&lt;/p&gt;
&lt;img src=&quot;http://source.mycookies.cn/202005112242_809.gif?ERROR&quot; alt=&quot;&quot; title=&quot;&quot;/&gt;&lt;p&gt;看似红黑树是一种完美的数据结构，能够胜任索引的工作。但MySQL并未使用其作为索引的实现，主要原因在于&lt;strong&gt;红黑树的深度过大，数据检索时造成磁盘IO频繁&lt;/strong&gt;，假设一个每个节点存储在一个page中，树的高度为10，则每次检索可能就需要进行10次磁盘IO。&lt;/p&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;2.5 B-Tree不支持顺序查询&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;B-Tree是一种自平衡的多叉搜索树，一个节点可以拥有两个以上的子节点。适合读写相对大的数据块的存储系统，例如磁盘。&lt;/p&gt;
&lt;img src=&quot;http://source.mycookies.cn/202005172317_874.png?ERROR&quot; alt=&quot;&quot; title=&quot;&quot;/&gt;&lt;p&gt;由于MySQL索引一般都存储在内存中，如果使用B-Tree作为索引的话，索引和数据存储在一块，分布在各个节点中；而内存资源往往比较宝贵，&lt;strong&gt;一定内存的情况下可以存储的索引数量相对有限&lt;/strong&gt;，毕竟每条数据的大小一般远大于索引列的大小，导致内存使用率不高。&lt;/p&gt;
&lt;p&gt;数据查询过程中往往会有顺序查询，而&lt;strong&gt;B-Tree和红黑树对于顺序查询并不友好&lt;/strong&gt;。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;2.6 为什么选B+Tree&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;B+Tree是在B-Tree基础上演进而来的。与之不同的是B+Tree的数据页只存储在叶子节点中，并且叶子节点之间通过指针相连，为双向链表结构。&lt;/p&gt;
&lt;img src=&quot;http://source.mycookies.cn/202005172315_242.png?ERROR&quot; alt=&quot;&quot; title=&quot;&quot;/&gt;&lt;p&gt;B+Tree的优点可以分为以四个：&lt;/p&gt;
&lt;ol readability=&quot;1.5&quot;&gt;&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;充分利用空间局部性原理，适合磁盘存储。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;树的高度很低，能够在存储大量数据情况下，进行较少的磁盘IO【见下文介绍】。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;能够很好支持单值，范围查询，有序性查询。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;索引和数据分开存储，让更多的索引存储在内存中。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;&lt;h3 id=&quot;hmysql&quot;&gt;&lt;span&gt;三，MySQL中索引实现&lt;/span&gt;&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;3.1 巧妙利用B+Tree&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;MySQL中的数据存储通常以Page为单位，俗称数据页，每个Page对应B+Tree的一个节点。页是InnoDB磁盘管理的最小单位，默认每个数据页的大小为16kb，也可以通过参数innodb_page_size将页的大小设置成其他值。&lt;/p&gt;
&lt;p&gt;数据库的页大小和操作系统类似，是指存放数据时，每一块连续区域数据的大小。比如一个1M的数据存放在数据库中时， 需要大概64个页来存放（1024=64*16）。如果是在操作系统上安装的数据库，最好将数据库页大小设置为操作系统页大小的倍数，才是最佳设置。&lt;/p&gt;
&lt;img src=&quot;http://source.mycookies.cn/202005172300_673.png?ERROR&quot; alt=&quot;&quot; title=&quot;&quot;/&gt;&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;3.2 树的高度-有效减少磁盘IO次数&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;通常情况下，一张MySQL表中有成千上万条数据，而磁盘IO次数往往与数的高度成正比。默认情况下一个Page的大小为16kb，由于每个Page中数据通过指针相连，且每个指针大小为6字节。&lt;/p&gt;
&lt;p&gt;在工作中，我们通常使用长度为8个字节的bigint类型作为主键id的类型。已知，每一条数据都会包含一个6字节的指针（数据页中每条记录都有指向下一条记录的指针，但是没有指向上一条记录的指针）；所以一条索引数据大约占用8+6=14个字节，一个Page中能存储16 * 1024 / 14 ≈ 1170条索引数据。高度为2的B+Tree大约能存储1170*16 = 18720条这样的记录。同理，高度为3的B+Tree的B+Tree大约能存储1170 * 1170 * 16 = 21902400，大约两千万条数据。 （每个节点大约能存储1170条记录，可以理解为此时B+Tree为1170叉树）&lt;/p&gt;
&lt;p&gt;例如，要检索id=008的数据，则需要进行三次磁盘IO找到对应的数据页（最多三次，因为Page可能在缓存中），然后在数据页中进行二分查找，定位到对应的记录。&lt;/p&gt;
&lt;img src=&quot;http://source.mycookies.cn/202005172311_661.png?ERROR&quot; alt=&quot;&quot; title=&quot;&quot;/&gt;&lt;h3 id=&quot;h-1&quot;&gt;&lt;span&gt;四，总结&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;大家耳熟能详的B+Tree索引是一种非常优秀的数据结构，也是面试热点问题。本文从数据结构和磁盘IO两个方面分析了为什么使用B+Tree，以及MySQL的InnoDB存储引擎的索引实现。在笔者面试过程中，被问到MySQL索引时通常也是从&lt;strong&gt;底层数据结构特点以及结合磁盘IO&lt;/strong&gt;两个角度去分析，屡试不爽。&lt;/p&gt;
&lt;p&gt;学习一门技术时，我们不仅要知道其优点更要了解其缺点和瓶颈。在分析MySQL索引的实现时，不妨试试从其他数据结构的缺点入手！在Redis中使用跳表实现了有序集合Zset，同样支持高效的顺序查询，对比MySQL索引实现，&lt;strong&gt;跳表能否替换B+Tree&lt;/strong&gt;？如果不行，是因为什么呢？&lt;/p&gt;
&lt;img src=&quot;http://source.mycookies.cn/202002212337_444.png?ERROR&quot; alt=&quot;&quot; title=&quot;&quot;/&gt;</description>
<pubDate>Sat, 30 May 2020 16:25:00 +0000</pubDate>
<dc:creator>浪人~</dc:creator>
<og:description>MySQL面试必问，最近找工作频频被问到的知识点，学一次用n年，不用花费一分钱~</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/liqiangchn/p/12995831.html</dc:identifier>
</item>
<item>
<title>【python系统学习16】编码基础知识 - xing.org1^</title>
<link>http://www.cnblogs.com/padding1015/p/12995673.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/padding1015/p/12995673.html</guid>
<description>&lt;p&gt;除了0、1这些阿拉伯数字，像a、b、c这样的52个字母（包括大小写），还有一些常用的符号（例如*、#、@等）在计算机中存储时也要使用二进制数来表示，而具体用哪些二进制数字表示哪个符号，理论上每个人都可以有自己的一套规则（这就叫编码规则，形成编码表）。&lt;/p&gt;&lt;div id=&quot;cnblogs_post_body&quot; readability=&quot;105&quot;&gt;
&lt;section id=&quot;nice&quot; data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot; readability=&quot;100&quot;&gt;
&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;计算机是怎么传输和存储数据的？&lt;/strong&gt;&lt;/p&gt;
&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;就是把人类认识的中英文字、其他国家语言、数字甚至运算符等符号转成二进制的0、1，并进行存储和传输。&lt;/p&gt;
&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span class=&quot;content&quot;&gt;编码&lt;/span&gt;&lt;/h2&gt;
&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;人类语言&lt;/strong&gt;：中英文字、其他国家语言、数字甚至运算符等符号&lt;/p&gt;
&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;计算机语言&lt;/strong&gt;：二进制的0、1【没错，计算机只认识0和1】&lt;/p&gt;
&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;编码&lt;/strong&gt;：将人类语言转换为计算机语言。&lt;/p&gt;
&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;除了0、1这些阿拉伯数字，像a、b、c这样的52个字母（包括大小写），还有一些常用的符号（例如*、#、@等）在计算机中存储时也要使用二进制数来表示，而具体用哪些二进制数字表示哪个符号，理论上每个人都可以有自己的一套规则（这就叫编码规则，形成编码表）。&lt;/p&gt;
&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果使用了不同的编码规则，就会有计算机识别不了的情况，出现&lt;strong&gt;乱码&lt;/strong&gt;。&lt;/p&gt;
&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span class=&quot;content&quot;&gt;进制&lt;/span&gt;&lt;/h2&gt;
&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;二进制、八进制、十六进制。&lt;/p&gt;
&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;八进制和十六进制分别是二进制的3次方和4次方。方便和二进制之间非常直接的相互转换&lt;/p&gt;
&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span class=&quot;content&quot;&gt;二进制&lt;/span&gt;&lt;/h3&gt;
&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;由0和1构成的&lt;/p&gt;
&lt;table data-tool=&quot;mdnice编辑器&quot;&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;二进制&lt;/th&gt;
&lt;th&gt;十进制&lt;/th&gt;
&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;00&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;01&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;10&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;11&lt;/td&gt;
&lt;td&gt;3&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;100&lt;/td&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;101&lt;/td&gt;
&lt;td&gt;5&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;110&lt;/td&gt;
&lt;td&gt;6&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;111&lt;/td&gt;
&lt;td&gt;7&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;1000&lt;/td&gt;
&lt;td&gt;8&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot;&gt;&lt;li&gt;
&lt;section&gt;二进制的00，代表十进制的0&lt;/section&gt;&lt;/li&gt;
&lt;li&gt;
&lt;section&gt;二进制的01，代表十进制的1&lt;/section&gt;&lt;/li&gt;
&lt;li&gt;
&lt;section&gt;二进制的10，代表十进制的2【笑话：世界上有10种人，懂二进制的和不懂二进制的】&lt;/section&gt;&lt;/li&gt;
&lt;li&gt;
&lt;section&gt;二进制的11，代表十进制的3&lt;/section&gt;&lt;/li&gt;
&lt;li&gt;
&lt;section&gt;二进制的100，代表十进制的4&lt;/section&gt;&lt;/li&gt;
&lt;li&gt;
&lt;section&gt;以此类推...&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot;&gt;&lt;li&gt;
&lt;section&gt;当有两位数时，我们可以表示0到3，共4种状态，即2的平方&lt;/section&gt;&lt;/li&gt;
&lt;li&gt;
&lt;section&gt;当有三位数时，我们可以表示0到7，共8种状态，即2的三次方&lt;/section&gt;&lt;/li&gt;
&lt;li&gt;
&lt;section&gt;当有八位数时，我们可以表示0到255，共256种状态，即2的8次方&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span class=&quot;content&quot;&gt;八进制&lt;/span&gt;&lt;/h3&gt;
&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;使用0、1、2、3、4、5、6、7组成的&lt;/p&gt;
&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span class=&quot;content&quot;&gt;十六进制&lt;/span&gt;&lt;/h3&gt;
&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;使用0、1、2、3、4、5、6、7、8、9、a、b、c、d、e、f组成的&lt;/p&gt;
&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span class=&quot;content&quot;&gt;ASCII编码表中的“K”&lt;/span&gt;&lt;/h3&gt;
&lt;table data-tool=&quot;mdnice编辑器&quot;&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;二进制&lt;/th&gt;
&lt;th&gt;八进制&lt;/th&gt;
&lt;th&gt;十进制&lt;/th&gt;
&lt;th&gt;十六进制&lt;/th&gt;
&lt;th&gt;字母&lt;/th&gt;
&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;01001011&lt;/td&gt;
&lt;td&gt;113&lt;/td&gt;
&lt;td&gt;75&lt;/td&gt;
&lt;td&gt;4B&lt;/td&gt;
&lt;td&gt;K&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;注意这里还是大写的字母K哦～&lt;/p&gt;
&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span class=&quot;content&quot;&gt;存储单位&lt;/span&gt;&lt;/h2&gt;
&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;计算机里的存储单位&lt;/p&gt;
&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span class=&quot;content&quot;&gt;位/比特（bit）&lt;/span&gt;&lt;/h3&gt;
&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;位：又叫比特（bit）是计算机里&lt;strong&gt;最小的存储单位&lt;/strong&gt;。用来存放一位二进制书，即0或1。&lt;/p&gt;
&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span class=&quot;content&quot;&gt;字节（byte）&lt;/span&gt;&lt;/h3&gt;
&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;八个比特是一个字节，是计算机里&lt;strong&gt;最常用的单位&lt;/strong&gt;。简写“B”&lt;/p&gt;
&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span class=&quot;content&quot;&gt;千字节（Kilobyte）&lt;/span&gt;&lt;/h3&gt;
&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span class=&quot;content&quot;&gt;兆字节（Megabyte）&lt;/span&gt;&lt;/h3&gt;
&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;简称“兆”&lt;/p&gt;
&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span class=&quot;content&quot;&gt;吉字节（Gigabyte）&lt;/span&gt;&lt;/h3&gt;
&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;又叫千兆&lt;/p&gt;
&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span class=&quot;content&quot;&gt;单位换算&lt;/span&gt;&lt;/h3&gt;
&lt;pre class=&quot;custom&quot; data-tool=&quot;mdnice编辑器&quot;&gt;
&lt;code class=&quot;hljs&quot;&gt;1B(byte 字节) = 8bit&lt;br/&gt;1KB(Kilobyte 千字节) = 1024B&lt;br/&gt;1MB(Megabyte 兆字节) = 1024KB&lt;br/&gt;1GB(Gigabyte) = 1024MB&lt;br/&gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;为什么办的100兆的宽带，撑死就只有10几兆的下载速度？&lt;/strong&gt;&lt;/p&gt;
&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;因为运营商的带宽是以比特每秒为单位的，比如100M就是100Mbit/s。&lt;/p&gt;
&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;而我们常看到的下载速度KB却是以字节每秒为单位显示的，&lt;code&gt;1byte = 8bit&lt;/code&gt;，所以运营商说的带宽得先除以8，你的百兆宽带下载速度，也就是十几兆了。&lt;/p&gt;
&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span class=&quot;content&quot;&gt;编码表&lt;/span&gt;&lt;/h2&gt;
&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;为了避免乱码，人类就约定了一套共同的编码规则。就像计算机世界的新华字典、牛津英语字典。&lt;/p&gt;
&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span class=&quot;content&quot;&gt;编码表历史&lt;/span&gt;&lt;/h3&gt;
&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span class=&quot;content&quot;&gt;ASCII&lt;/span&gt;&lt;/h4&gt;
&lt;ul data-tool=&quot;mdnice编辑器&quot;&gt;&lt;li readability=&quot;-0.5&quot;&gt;
&lt;section readability=&quot;5&quot;&gt;&lt;p&gt;&lt;code&gt;ASCII&lt;/code&gt;编码（读音：/ˈæski/），美国首先出台。统一规定了常用符号用哪些二进制数来表示。 因为英文字母、数字再加上其他常用符号，也就100来个，因此使用7个比特位（最多表示128位）就够用了，所以一个字节中被剩下的那个比特位就被默认为0。&lt;/p&gt;
&lt;/section&gt;&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;section readability=&quot;4&quot;&gt;&lt;p&gt;但欧洲不光有英语，还有法语字母上的注音符。于是欧洲用了美国剩下的那个比特位，普遍使用一个全字节（8个比特位）进行编码，最多可表示256位，至此，一个字节就用满了！&lt;/p&gt;
&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;ASCII统一了前面0-127位，但从状态128到255这一段的解释就完全乱套了，比如135在法语，希伯来语，俄语编码中完全是不同的符号。&lt;/p&gt;
&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span class=&quot;content&quot;&gt;GB2312和GBK&lt;/span&gt;&lt;/h4&gt;
&lt;ul data-tool=&quot;mdnice编辑器&quot;&gt;&lt;li&gt;
&lt;section&gt;中国10万汉字，256位也不够用。于是一张新编码表&lt;code&gt;GB2312&lt;/code&gt;被中国科学家发明了。 用2个字节，也就是16个比特位，来表示绝大部分（65535个）常用汉字。后来，为了能显示更多的中文，又出台了&lt;code&gt;GBK&lt;/code&gt;标准。&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span class=&quot;content&quot;&gt;Unicode&lt;/span&gt;&lt;/h4&gt;
&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;因各个国家的编码表都不同。不同国家间通信又会乱码。&lt;/p&gt;
&lt;ul data-tool=&quot;mdnice编辑器&quot;&gt;&lt;li&gt;
&lt;section&gt;于是&lt;code&gt;Unicode&lt;/code&gt;（万国码）来统一。 这套编码表将世界上所有的符号都纳入其中。每个符号都有一个独一无二的编码，现在Unicode可以容纳100多万个符号，所有语言都可以互通，一个网页上也可以显示多国语言。&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;万国码的缺点是让英文字符被迫占用两个字节，耗费计算机存储空间。（如A：用00010001就行，但是为了顺从统一，需要用两个字节：00000000 00010001）&lt;/p&gt;
&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span class=&quot;content&quot;&gt;UTF-8&lt;/span&gt;&lt;/h4&gt;
&lt;ul data-tool=&quot;mdnice编辑器&quot;&gt;&lt;li&gt;
&lt;section&gt;&lt;code&gt;UTF-8&lt;/code&gt;（8-bit Unicode Transformation Format）被提出。针对Unicode的可变长度字符编码。它可以使用1~4个字节表示一个符号，根据不同的符号而变化字节长度。而当字符在ASCII码的范围时，就用一个字节表示，所以UTF-8还可以兼容ASCII编码。&lt;/section&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;em&gt;Unicode与UTF-8这种暧昧的关系一言以蔽之：Unicode是内存编码的规范，而UTF-8是如何保存和传输Unicode的手段。&lt;/em&gt;&lt;/p&gt;
&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span class=&quot;content&quot;&gt;编码表对比&lt;/span&gt;&lt;/h3&gt;
&lt;table data-tool=&quot;mdnice编辑器&quot;&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;编码表&lt;/th&gt;
&lt;th&gt;适用性&lt;/th&gt;
&lt;th&gt;特点&lt;/th&gt;
&lt;/tr&gt;&lt;/thead&gt;&lt;tbody readability=&quot;6.5&quot;&gt;&lt;tr readability=&quot;4&quot;&gt;&lt;td&gt;ASCII码&lt;/td&gt;
&lt;td&gt;英文大小写，字符，不支持中文&lt;/td&gt;
&lt;td&gt;美国人发明，占用空间小，用一个字节就行&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;GB2312码、GBK码&lt;/td&gt;
&lt;td&gt;支持中文&lt;/td&gt;
&lt;td&gt;中国人发明，GBK是GB2312的升级，增加了更多原来没有的文字字符&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;4&quot;&gt;&lt;td&gt;Unicode码&lt;/td&gt;
&lt;td&gt;支持国际语言，万国码&lt;/td&gt;
&lt;td&gt;适用性强但占用空间大。在ASCII码前面补8个bit位就是Unicode码&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;3&quot;&gt;&lt;td&gt;UTF-8码&lt;/td&gt;
&lt;td&gt;支持国际语言&lt;/td&gt;
&lt;td&gt;Unicode的升级，两者容易互相转化。占用空间小、适用性强。ASCII码被UTF-8码包含。&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span class=&quot;content&quot;&gt;编码方案使用情况表&lt;/span&gt;&lt;/h3&gt;
&lt;table data-tool=&quot;mdnice编辑器&quot;&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;编码表&lt;/th&gt;
&lt;th&gt;当前使用情况&lt;/th&gt;
&lt;th&gt;备注&lt;/th&gt;
&lt;/tr&gt;&lt;/thead&gt;&lt;tbody readability=&quot;5&quot;&gt;&lt;tr&gt;&lt;td&gt;ASCII码&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;GB2312码、GBK码&lt;/td&gt;
&lt;td&gt;中文的文件和中文网站，使用GBK、GB2312&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;4&quot;&gt;&lt;td&gt;Unicode码&lt;/td&gt;
&lt;td&gt;计算机内存中处理数据时使用的统一标准格式&lt;/td&gt;
&lt;td&gt;Python3中，程序处理我们输入的字符串使用Unicode编码&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;4&quot;&gt;&lt;td&gt;UTF-8码&lt;/td&gt;
&lt;td&gt;数据在硬盘上存储，或者网络上传输时，用的UTF-8&lt;/td&gt;
&lt;td&gt;因为节省空间。程序来转换编码。&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;基于上表，有时候面对不同编码的数据，我们还需要手动操作实现编码转换。就要用到&lt;code&gt;encode(编码)&lt;/code&gt;和&lt;code&gt;decode(解码)&lt;/code&gt;。&lt;/p&gt;
&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span class=&quot;content&quot;&gt;编码操作和解码操作&lt;/span&gt;&lt;/h2&gt;
&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span class=&quot;content&quot;&gt;编码：&lt;code&gt;encode()&lt;/code&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;语法：&lt;/p&gt;
&lt;pre class=&quot;custom&quot; data-tool=&quot;mdnice编辑器&quot;&gt;
&lt;code class=&quot;hljs&quot;&gt;&lt;span class=&quot;hljs-string&quot;&gt;'你想编码的内容'&lt;/span&gt;.encode(&lt;span class=&quot;hljs-string&quot;&gt;'你使用的编码表名称'&lt;/span&gt;)&lt;br/&gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;用法：&lt;/p&gt;
&lt;pre class=&quot;custom&quot; data-tool=&quot;mdnice编辑器&quot;&gt;
&lt;code class=&quot;hljs&quot;&gt;print(&lt;span class=&quot;hljs-string&quot;&gt;'一天打鱼两个月晒网的小石头'&lt;/span&gt;.encode(&lt;span class=&quot;hljs-string&quot;&gt;'utf-8'&lt;/span&gt;))&lt;br/&gt;print(&lt;span class=&quot;hljs-string&quot;&gt;'I Love U'&lt;/span&gt;.encode(&lt;span class=&quot;hljs-string&quot;&gt;'gbk'&lt;/span&gt;))&lt;br/&gt;print(&lt;span class=&quot;hljs-string&quot;&gt;'小石头'&lt;/span&gt;.encode(&lt;span class=&quot;hljs-string&quot;&gt;'utf-8'&lt;/span&gt;))&lt;br/&gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;将上述人类语言编码得到机器语言后的打印结果在注释里。&lt;/p&gt;
&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span class=&quot;content&quot;&gt;字母b&lt;/span&gt;&lt;/h4&gt;
&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这里之所以有个&lt;code&gt;字母b&lt;/code&gt;，代表他是bytes（字节）类型的数据。 可以用&lt;code&gt;type()&lt;/code&gt;函数验证一下：&lt;/p&gt;
&lt;pre class=&quot;custom&quot; data-tool=&quot;mdnice编辑器&quot;&gt;
&lt;code class=&quot;hljs&quot;&gt;print(type(&lt;span class=&quot;hljs-string&quot;&gt;b'\xe5\xb0\x8f\xe7\x9f\xb3\xe5\xa4\xb4'&lt;/span&gt;)) &lt;br/&gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span class=&quot;content&quot;&gt;符号\x&lt;/span&gt;&lt;/h4&gt;
&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;另外，几乎每个字母/数字前边都有的&lt;code&gt;\x&lt;/code&gt;，他的作用是分隔符，用来分隔一个字节和另一个字节。&lt;/p&gt;
&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这样的分隔符，我们还见过：&lt;/p&gt;
&lt;pre class=&quot;custom&quot; data-tool=&quot;mdnice编辑器&quot;&gt;
&lt;code class=&quot;hljs&quot;&gt;&lt;span class=&quot;hljs-tag&quot;&gt;&amp;lt;&lt;span class=&quot;hljs-name&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;hljs-attr&quot;&gt;href&lt;/span&gt;=&lt;span class=&quot;hljs-string&quot;&gt;&quot;https://www.baidu.com/s?wd=%e5%b0%8f%e7%9f%b3%e5%a4%b4&quot;&lt;/span&gt; /&amp;gt;&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;对比发现下边两段字符串，你有发现什么奥妙么！：&lt;/p&gt;
&lt;pre class=&quot;custom&quot; data-tool=&quot;mdnice编辑器&quot;&gt;
&lt;code class=&quot;hljs&quot;&gt;%e5%b0%8f%e7%9f%b3%e5%a4%b4
\xe5\xb0\x8f\xe7\x9f\xb3\xe5\xa4\xb4
&lt;/code&gt;
&lt;/pre&gt;
&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;%&lt;/code&gt;和&lt;code&gt;\x&lt;/code&gt;一样，都是一种分隔符。只不过%是url中的、\x是python中的&lt;/p&gt;
&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span class=&quot;content&quot;&gt;解码：&lt;code&gt;decode()&lt;/code&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;语法：&lt;/p&gt;
&lt;pre class=&quot;custom&quot; data-tool=&quot;mdnice编辑器&quot;&gt;
&lt;code class=&quot;hljs&quot;&gt;&lt;span class=&quot;hljs-string&quot;&gt;'你想解码的内容'&lt;/span&gt;.encode(&lt;span class=&quot;hljs-string&quot;&gt;'你使用的编码表名称'&lt;/span&gt;)&lt;br/&gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;用法：&lt;/p&gt;
&lt;pre class=&quot;custom&quot; data-tool=&quot;mdnice编辑器&quot;&gt;
&lt;code class=&quot;hljs&quot;&gt;print(&lt;span class=&quot;hljs-string&quot;&gt;b'\xe5\xb0\x8f\xe7\x9f\xb3\xe5\xa4\xb4'&lt;/span&gt;.decode(&lt;span class=&quot;hljs-string&quot;&gt;'UTF-8'&lt;/span&gt;)) &lt;br/&gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;::: warning 注意 你要解码的内容得跟编码时用的编码表一致。不然会报错。 :::&lt;/p&gt;
&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;也就是说，UTF-8编码的字节就一定要用UTF-8的规则解码，其他编码同理，否则就会出现乱码或者报错的情况，&lt;/p&gt;
&lt;pre class=&quot;custom&quot; data-tool=&quot;mdnice编辑器&quot;&gt;
&lt;code class=&quot;hljs&quot;&gt;print(&lt;span class=&quot;hljs-string&quot;&gt;b'\xe5\xb0\x8f\xe7\x9f\xb3\xe5\xa4\xb4'&lt;/span&gt;.decode(&lt;span class=&quot;hljs-string&quot;&gt;'GBK'&lt;/span&gt;))&lt;br/&gt;&lt;/code&gt;
&lt;/pre&gt;&lt;/section&gt;&lt;/div&gt;</description>
<pubDate>Sat, 30 May 2020 15:38:00 +0000</pubDate>
<dc:creator>xing.org1^</dc:creator>
<og:description>除了0、1这些阿拉伯数字，像a、b、c这样的52个字母（包括大小写），还有一些常用的符号（例如*、#、@等）在计算机中存储时也要使用二进制数来表示，而具体用哪些二进制数字表示哪个符号，理论上每个人都可</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/padding1015/p/12995673.html</dc:identifier>
</item>
<item>
<title>记一次接口性能优化实践总结：优化接口性能的八个建议 - Jay_huaxiao</title>
<link>http://www.cnblogs.com/jay-huaxiao/p/12995510.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/jay-huaxiao/p/12995510.html</guid>
<description>&lt;h3 id=&quot;前言&quot;&gt;前言&lt;/h3&gt;
&lt;p&gt;最近对外接口偶现504超时问题，原因是代码执行时间过长，超过nginx配置的15秒，然后真枪实弹搞了一次接口性能优化。在这里结合优化过程，总结了接口优化的八个要点，希望对大家有帮助呀~&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;数据量比较大，批量操作数据入库&lt;/li&gt;
&lt;li&gt;耗时操作考虑异步处理&lt;/li&gt;
&lt;li&gt;恰当使用缓存&lt;/li&gt;
&lt;li&gt;优化程序逻辑、代码&lt;/li&gt;
&lt;li&gt;SQL优化&lt;/li&gt;
&lt;li&gt;压缩传输内容&lt;/li&gt;
&lt;li&gt;考虑使用文件/MQ等其他方式暂存，异步再落地DB&lt;/li&gt;
&lt;li&gt;跟产品讨论需求最恰当，最舒服的实现方式&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;嘻嘻，先看一下我们对外转账接口的大概流程吧&lt;br/&gt;&lt;img src=&quot;https://user-gold-cdn.xitu.io/2020/5/30/1726375c0d0162f3?w=1393&amp;amp;h=586&amp;amp;f=png&amp;amp;s=50348&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;h3 id=&quot;1数据量比较大，批量操作数据入库&quot;&gt;1.数据量比较大，批量操作数据入库&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;优化前：&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;//for循环单笔入库
for(TransDetail detail:list){
  insert(detail);  
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;优化后：&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;// 批量入库,mybatis demo实现
&amp;lt;insert id=&quot;insertBatch&quot; parameterType=&quot;java.util.List&quot;&amp;gt;
insert into trans_detail( id,amount,payer,payee) values
 &amp;lt;foreach collection=&quot;list&quot; item=&quot;item&quot; index=&quot;index&quot; separator=&quot;,&quot;&amp;gt;(
    #{item.id}, #{item.amount},
    #{item.payer},#{item.payee}
  )
&amp;lt;/foreach&amp;gt;
&amp;lt;/insert&amp;gt;
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;性能对比：&lt;/strong&gt;&lt;/p&gt;
&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;单位（ms）&lt;/th&gt;
&lt;th&gt;for循环单笔入库&lt;/th&gt;
&lt;th&gt;批量入库&lt;/th&gt;
&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;500条&lt;/td&gt;
&lt;td&gt;1432&lt;/td&gt;
&lt;td&gt;1153&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;1000条&lt;/td&gt;
&lt;td&gt;1876&lt;/td&gt;
&lt;td&gt;1425&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;&lt;strong&gt;解析&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;批量插入性能更好，更加省时间，为什么呢？&lt;/li&gt;
&lt;/ul&gt;&lt;pre&gt;
&lt;code&gt;打个比喻:假如你需要搬一万块砖到楼顶,你有一个电梯,电梯一次可以放适量的砖（最多放500）,
你可以选择一次运送一块砖,也可以一次运送500,你觉得哪种方式更方便，时间消耗更少?
&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;2耗时操作考虑异步处理&quot;&gt;2.耗时操作考虑异步处理&lt;/h3&gt;
&lt;p&gt;耗时操作，考虑用异步处理，这样可以降低接口耗时。本次转账接口优化，匹配联行号的操作耗时有点长，所以优化过程把它移到异步处理啦，如下：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;优化前：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://user-gold-cdn.xitu.io/2020/5/30/17265b8162520449?w=732&amp;amp;h=599&amp;amp;f=png&amp;amp;s=50717&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;优化后&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;匹配联行号的操作异步处理&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://user-gold-cdn.xitu.io/2020/5/30/17265bddbe759306?w=707&amp;amp;h=554&amp;amp;f=png&amp;amp;s=50118&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;性能对比：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;假设一个联行号匹配6ms&lt;/p&gt;
&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th/&gt;
&lt;th&gt;同步&lt;/th&gt;
&lt;th&gt;异步&lt;/th&gt;
&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;500条&lt;/td&gt;
&lt;td&gt;3000ms&lt;/td&gt;
&lt;td&gt;~&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;1000条&lt;/td&gt;
&lt;td&gt;6000ms&lt;/td&gt;
&lt;td&gt;~&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;&lt;strong&gt;解析：&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;因为联行号匹配比较耗时，放在异步处理的话，同步联机返回可以省掉这部分时间，大大提升接口性能，并且不会影响到转账主流程功能。&lt;/li&gt;
&lt;li&gt;除了这个例子，平时我们类似功能，如用户注册成功后，短信邮件通知，也是可以异步处理的，这个优化建议香饽饽的~&lt;/li&gt;
&lt;li&gt;所以，太耗时的操作，在不影响主流程功能的情况下，可以考虑开子线程异步处理的啦。&lt;/li&gt;
&lt;/ul&gt;&lt;h3 id=&quot;3恰当使用缓存&quot;&gt;3.恰当使用缓存&lt;/h3&gt;
&lt;p&gt;在适当的业务场景，恰当地使用缓存，是可以大大提高接口性能的。这里的缓存包括：Redis，JVM本地缓存，memcached，或者Map等。&lt;/p&gt;
&lt;p&gt;这次转账接口，使用到缓存啦，举个简单例子吧~&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;优化前&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;以下是输入用户账号，匹配联行号的流程图&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://user-gold-cdn.xitu.io/2020/5/30/17263c548352f480?w=396&amp;amp;h=719&amp;amp;f=png&amp;amp;s=36528&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;优化后：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;恰当使用缓存，代替查询DB表，流程图如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://user-gold-cdn.xitu.io/2020/5/30/17263cc73ccd1e76?w=723&amp;amp;h=785&amp;amp;f=png&amp;amp;s=70764&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;解析：&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;把热点数据放到缓存，不用每次查询都去DB拉取，节省了这部分查SQL的耗时，美滋滋呀~&lt;/li&gt;
&lt;li&gt;当然，不是什么数据都适合放到缓存的哦，访问比较频繁的热点数据才考虑缓存起来呢~&lt;/li&gt;
&lt;/ul&gt;&lt;h3 id=&quot;4-优化程序逻辑、代码&quot;&gt;4. 优化程序逻辑、代码&lt;/h3&gt;
&lt;p&gt;优化程序逻辑、程序代码，是可以节省耗时的。&lt;/p&gt;
&lt;p&gt;我这里就本次的转账接口优化，举个例子吧~&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;优化前：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;优化前，联行号查询了两次（检验参数一次，插入DB前查询一次），如下伪代码：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;
punlic void process(Req req){
  //检验参数,包括联行号（前端传来的payeeBankNo可以为空,但是如果后端没匹配到，会抛异常）
   checkTransParams(Req req);
   //Save DB
  saveTransDetail(req); 
}

void checkTransParams（Req req）{
    //check Amount,and so on.
    checkAmount(req.getamount)；
    //check payeebankNo
    if（Utils.isEmpty(req.getPayeeBankNo())）{
        String payeebankNo = getPayeebankNo(req.getPayeeAccountNo);
        if(Utils.isEmpty(payeebankNo){
            throws Exception();
        }
    }
}

int saveTransDetail(req){
    String payeebankNo = getPayeebankNo(req.getPayeeAccountNo);
    req.setPayeeBankNo(payeebankNo);
    insert(req);
    ...
}

&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;优化后：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;优化后，只在校验参数的时候插叙一次，然后设置到对象里面~ 入库前就不用再查啦，伪代码如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;void checkTransParams（Req req）{
    //check Amount,and so on.
    checkAmount(req.getamount)；
    //check payeebankNo
    if（Utils.isEmpty(req.getPayeeBankNo())）{
        String payeebankNo = getPayeebankNo(req.getPayeeAccountNo);
        if(Utils.isEmpty(payeebankNo){
            throws Exception();
        }
    }
    //查询到有联行号，直接设置进去啦，这样等下入库不用再插入多一次
    req.setPayeeBankNo(payeebankNo);
}

int saveTransDetail(req){
    insert(req);
    ...
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;解析：&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;对于优化程序逻辑、代码，是可以降低接口耗时的。以上demo只是一个很简单的例子，就是优化前payeeBankNo查询了两次，但是其实只查一次就可以了。很多时候，我们都知道这个点，但就是到写代码的时候，又忘记了呀~所以，写代码的时候，留点心吧，优化你的程序逻辑、代码哦。&lt;/li&gt;
&lt;li&gt;除了以上demo这点，还有其它的点，如优化if复杂的逻辑条件，考虑是否可以调整顺序，或者for循环，是否重复实例化对象等等，这些适当优化，都是可以让你的代码跑得更快的。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;之前我这篇文章，也提了几个优化点噢，有兴趣的朋友可以看一下哈~&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://juejin.im/post/5dfe2e72518825125f39a2de#heading-1&quot;&gt;写代码有这些想法，同事才不会认为你是复制粘贴程序员&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&quot;5-优化你的sql&quot;&gt;5. 优化你的SQL&lt;/h3&gt;
&lt;p&gt;很多时候，你的接口性能瓶颈就在SQL这里，慢查询需要我们重点关注的点呢。&lt;/p&gt;
&lt;p&gt;我们可以通过这些方式优化我们的SQL：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;加索引&lt;/li&gt;
&lt;li&gt;避免返回不必要的数据&lt;/li&gt;
&lt;li&gt;优化sql结构&lt;/li&gt;
&lt;li&gt;分库分表&lt;/li&gt;
&lt;li&gt;读写分离&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;有兴趣的朋友可以看一下我这篇文章呢，很详细的SQL优化点：&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://juejin.im/post/5e624d156fb9a07ca80ab6f2&quot;&gt;后端程序员必备：书写高质量SQL的30条建议&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&quot;6压缩传输内容&quot;&gt;6.压缩传输内容&lt;/h3&gt;
&lt;p&gt;压缩传输内容，文件变得更小，因此传输会更快啦。10M带宽，传输10k的报文，一般比传输1M的会快呀；打个比喻，一匹千里马，它驮着一百斤的货跑得快，还是驮着10斤的货物跑得快呢？&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;解析：&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;如果你的接口性能不好，然后传输报文比较大的话，这时候是可以考虑压缩文件内容传输的，最后优化效果可能很不错哦~&lt;/li&gt;
&lt;/ul&gt;&lt;h3 id=&quot;7-考虑使用文件mq等其他方式暂存数据，异步再落地db&quot;&gt;7. 考虑使用文件/MQ等其他方式暂存数据，异步再落地DB&lt;/h3&gt;
&lt;p&gt;如果数据太大，落地数据库实在是慢的话，可以考虑先用文件的方式保存，或者考虑MQ，先落地，再异步保存到数据库~&lt;/p&gt;
&lt;blockquote readability=&quot;7&quot;&gt;
&lt;p&gt;本次转账接口，如果是并发开启，10个并发度，每个批次1000笔数据，数据库插入会特别耗时，大概10秒左右，这个跟我们公司的数据库同步机制有关，并发情况下，因为优先保证同步，所以并行的插入变成串行啦，就很耗时。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;优化前：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;优化前，1000笔先落地DB数据库，再异步转账，如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://user-gold-cdn.xitu.io/2020/5/30/17265cde30477f97?w=663&amp;amp;h=513&amp;amp;f=png&amp;amp;s=45382&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;优化后：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;先保存数据到文件，再异步下载下来，插入数据库，如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://user-gold-cdn.xitu.io/2020/5/30/17265d09e9deb059?w=753&amp;amp;h=540&amp;amp;f=png&amp;amp;s=52581&quot; alt=&quot;&quot;/&gt;&lt;br/&gt;&lt;strong&gt;解析：&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;如果你的耗时瓶颈就在数据库插入操作这里了，那就考虑文件保存或者MQ或者其他方式暂存吧，文件保存数据，对比一下耗时，有时候会有意想不到的效果哦。&lt;/li&gt;
&lt;/ul&gt;&lt;h3 id=&quot;8跟产品讨论需求最恰当，最舒服的实现方式&quot;&gt;8.跟产品讨论需求最恰当，最舒服的实现方式&lt;/h3&gt;
&lt;p&gt;这点个人觉得还是很重要的，有些需求需要好好跟产品沟通的。&lt;/p&gt;
&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;比如有个用户连麦列表展示的需求，产品说要展示所有的连麦信息，如果一个用户的连麦列表信息好大，你拉取所有连麦数据回来，接口性能就降下来啦。如果产品打桩分析，会发现，一般用户看连麦列表，也就看前几页&lt;sub&gt;因此，奸笑，哈哈&lt;/sub&gt; 其实，那个超大分页加载问题也是类似的。即limit +一个超大的数，一般会很慢的~~&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&quot;总结&quot;&gt;总结&lt;/h3&gt;
&lt;p&gt;本文呢，基于一次对外接口耗时优化的实践，总结了优化接口性能的八个点，希望对大家日常开发有帮助哦~嘻嘻，有兴趣可以逛逛我的github哈，本文会收藏到github里滴哈&lt;/p&gt;
&lt;blockquote readability=&quot;0&quot;&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/whx123/JavaHome&quot;&gt;https://github.com/whx123/JavaHome&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&quot;公众号&quot;&gt;公众号&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;https://user-gold-cdn.xitu.io/2020/5/16/1721b50d00331393?w=900&amp;amp;h=500&amp;amp;f=png&amp;amp;s=389569&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;欢迎关注我个人公众号，交个朋友，一起学习哈~&lt;/li&gt;
&lt;/ul&gt;</description>
<pubDate>Sat, 30 May 2020 14:57:00 +0000</pubDate>
<dc:creator>Jay_huaxiao</dc:creator>
<og:description>前言 最近对外接口偶现504超时问题，原因是代码执行时间过长，超过nginx配置的15秒，然后真枪实弹搞了一次接口性能优化。在这里结合优化过程，总结了接口优化的八个要点，希望对大家有帮助呀~ 数据量比</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/jay-huaxiao/p/12995510.html</dc:identifier>
</item>
<item>
<title>​云中奈飞（一）：Netflix的上云之旅 - SammyLiu</title>
<link>http://www.cnblogs.com/sammyliu/p/12995447.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/sammyliu/p/12995447.html</guid>
<description>&lt;p&gt;对奈飞（Netflix）的上云之旅及其云上运行进行梳理和总结，形成系列文章。本文为这系列文章的第一篇，介绍奈飞的总体上云历程。&lt;/p&gt;&lt;div id=&quot;cnblogs_post_body&quot; readability=&quot;204&quot;&gt;
&lt;p&gt;作者按： &lt;/p&gt;
&lt;p&gt;Netflix（译为奈飞/网飞）公司自1997年创立以来，已发展成为美国最大的互联网流媒体服务商。它从2008到2015年间长达七年的将其所有IT系统从自有数据中心迁移到AWS之上的旅程，在当时可谓前无古人的创举，对公有云的发展、传统企业上云及基于云的业务转型等都有很大的推动和促进作用。虽然已过去多年，有些东西已略微显得过时，但奈飞上云的理念、步骤、做法等，对当今企业上云及用云仍有很大的参考价值。 &lt;/p&gt;
&lt;p&gt;因此，在接下来的几周内，笔者打算花上些许时间，对奈飞的上云之旅，及其云上运行，基于网上公开资料，从上云历程、云上架构、支撑团队、云上安全等维度做下梳理和总结，形成系列文章。它山之石，可以攻玉。本文为这系列文章的第一篇，介绍奈飞的总体上云历程。&lt;/p&gt;

&lt;p&gt;本文目录&lt;/p&gt;
&lt;p&gt;零、公司简介....................................... 1&lt;/p&gt;
&lt;p&gt;一、发端.............................................. 4&lt;/p&gt;
&lt;p&gt;二、验证.............................................. 6&lt;/p&gt;
&lt;p&gt;三、进行.............................................. 8&lt;/p&gt;
&lt;p&gt;四、完成.............................................. 11 &lt;/p&gt;



&lt;p&gt;&lt;img class=&quot;rich_pages&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ibOaboJGeVrREOUX9ZI7WNjCTNEeoZqXPniamuCZic70IWu3xr4JWbW1SOpJ9aibnlx8l9NYZVq5U0cMDW3yDa1UxQ/640?wx_fmt=png&quot; alt=&quot;&quot; data-backh=&quot;410&quot; data-backw=&quot;578&quot; data-ratio=&quot;0.7094155844155844&quot; data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-w=&quot;616&quot;/&gt;&lt;/p&gt;

&lt;p&gt;Netflix（https://www.netflix.com/）公司总部设在美国加利福尼亚州，是全世界最大的视频流媒体平台，在除中国大陆地区以外的所有国家和地区均提供视频点播服务，相当于国内的爱奇艺、优酷和腾讯视频等视频网站。 &lt;/p&gt;
&lt;p&gt;1997年，当Reed Hastings和Marc Randolph创建 Netflix时，这家公司唯一业务是DVD邮购业务。2002年上市，股票发行价为15美元；2007年开始发展流媒体业务；2013年，发布其首部原创电视剧《纸牌屋》；2016年宣布全球化，全世界200多个国家和地区可订阅Netflix观看电影电视剧。 2017年，Netflix用户数量超过美国有线电视用户总数。如今，Netflix的股价是419美元，已成为世界上大型的电视剧和电影制片公司之一、美国最大的互联网流媒体服务商，在世界范围内拥有很强的影响力，高峰时刻占据了互联网流媒体流量的33%。 &lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;rich_pages&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ibOaboJGeVrREOUX9ZI7WNjCTNEeoZqXPLWolljxwZB0RYKXIp3oFwlG5TmHkpwKCYd0zFf11LE41ENl7Vxuqug/640?wx_fmt=png&quot; alt=&quot;&quot; data-backh=&quot;404&quot; data-backw=&quot;539&quot; data-ratio=&quot;0.7495361781076066&quot; data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-w=&quot;539&quot;/&gt;&lt;/p&gt;

&lt;p&gt;除了商业上非常成功外，Netflix在技术上也非常成功，它虽然是家娱乐公司，但实际上是一家技术公司。从2008年开始，直到2015年底，它花了整整七年时间，把公司整套IT系统搬到了AWS上。这可谓前无来者。除此之外，Netflix在分布式系统开源上具有巨大的影响力，其开源项目叫做Netflix OSS(Open Source Software)，涵盖范围基本包括了业界绝大部分分布式系统领域，包括但不限于： &lt;/p&gt;
&lt;p&gt;·       公共运行时服务及库，比如Eureka, Ribbon, Hystrix&lt;/p&gt;
&lt;p&gt;·       大数据，比如Genie&lt;/p&gt;
&lt;p&gt;·       构建和发布工具，比如Asgard/Spinnaker&lt;/p&gt;
&lt;p&gt;·       数据持久化，比如EVCache&lt;/p&gt;
&lt;p&gt;·       可观察性、可靠性和性能，比如Simian Army &lt;/p&gt;



&lt;p&gt;Netflix的上云之旅始于2008年8月。从公开资料来看，当时主要有两个驱动力促使其上云： &lt;/p&gt;
&lt;p&gt;（1）发生了系统宕机。 &lt;/p&gt;
&lt;p&gt;当时，Netflix的IT系统运行在高端昂贵的IBM服务器、Oracle数据库和SAN存储搭建的平台之上。某次，因为SAN存储硬件故障导致的数据库宕机，使得Netflix的DVD配送服务不得不停止了3天。这个故障使得公司管理层开始意识到，由IT团队利用昂贵的平台来保证系统可用性的做法存在问题，更应该从应用层面去保障系统可用性。因此，需考虑IT系统从传统垂直扩展的带有单点故障的架构，转向高可用、水平扩展的分布式架构。与此同时，他们开始思考是否可以利用刚刚出现的低成本云基础设施来替代昂贵传统IT基础设施来支撑需具备高可用性的应用。&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;rich_pages&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ibOaboJGeVrREOUX9ZI7WNjCTNEeoZqXP6F6Og8iaW8LCNVh6Fd6pGtRFTSHRQ9lIpCPr1JyhkibponQ93RE75guA/640?wx_fmt=png&quot; alt=&quot;&quot; data-backh=&quot;121&quot; data-backw=&quot;578&quot; data-ratio=&quot;0.210016155088853&quot; data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-w=&quot;619&quot;/&gt;&lt;/p&gt;

&lt;p&gt;（2）新业务带来巨大数据中心扩容压力。 &lt;/p&gt;
&lt;p&gt;Netflix的传统DVD寄送服务的服务模式下，客户浏览Netflix网站选择DVD，然后公司开始寄送。因为受到DVD来回寄送速度的限制，通常是以周为周期给客户寄送DVD。因此，这种传统业务模式对IT系统的业务压力较轻。 &lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;rich_pages&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ibOaboJGeVrREOUX9ZI7WNjCTNEeoZqXP4ewUeOMZ4LWMfn7Y2dgXAvbxLGYHPyfYgaLq1P2u7iaWr2QDGUb9voA/640?wx_fmt=png&quot; alt=&quot;&quot; data-backh=&quot;309&quot; data-backw=&quot;578&quot; data-ratio=&quot;0.5351437699680511&quot; data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-w=&quot;626&quot;/&gt;&lt;/p&gt;
&lt;p&gt;传统DVD寄送业务模式&lt;/p&gt;

&lt;p&gt;尽管DVD业务增长迅速，但2007年Netflix仍然决定推出第一款流媒体产品“Watch Now”来革新其业务。这种业务也是它后来蓬勃发展的关键因素之一。这种新服务模式下，用户与Netflix网站之间的交互频率是传统DVD寄送业务下交互频率的100倍甚至不止。 &lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;rich_pages&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ibOaboJGeVrREOUX9ZI7WNjCTNEeoZqXPn6jh7kfxmlcBJXkV5ib7VkDReEcXeMicRhicIVeMiaJRkTxnPrDUgBVASQ/640?wx_fmt=png&quot; alt=&quot;&quot; data-backh=&quot;313&quot; data-backw=&quot;578&quot; data-ratio=&quot;0.5408&quot; data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-w=&quot;625&quot;/&gt;&lt;/p&gt;
&lt;p&gt;流媒体服务模式&lt;/p&gt;

&lt;p&gt;新模式下，用户每周看的视频数量是之前的十倍，而每个视频对数据中心中的IT系统产生的流量则是百倍，因此每个用户对IT系统产生的流量是之前的千倍。也就是说，只要0.1%的用户从传统模式转向新模式，那IT系统的容量就必须翻倍。其实这种规律也很常见。即使用户并没有显著增长，只要因为业务模式的变化，对IT系统的压力也可能成倍增加。 &lt;/p&gt;
&lt;p&gt;这就要求Netflix找到一种快速扩容数据中心的方法，因为根据当时的业务预测，其用户很快就会转向在线流媒体服务模式。时间来到2009年，随着新业务的发展，Netflix面临两个选择：自建数据中心，或利用其业务竞争对手亚马逊于2006年才发布的AWS云。前者需要大量前期资金投入，并且未来的容量需求无法预测且是变化不定的，而后者则是在视频流领域的最大竞争对手Amazon的云上开展业务。Netflix决定选择后者。他们认为，相比在不实际产生业务价值的数据中心上做前期巨大投入，将资金投入在视频内容和开发人员身上会更有价值。&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;rich_pages&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ibOaboJGeVrREOUX9ZI7WNjCTNEeoZqXPaoPrJ6Vly2RYRJFr6BdoXKbv0DhtbXOROmEpLLQQqibBtHgcBgUa9rg/640?wx_fmt=png&quot; alt=&quot;&quot; data-backh=&quot;210&quot; data-backw=&quot;578&quot; data-ratio=&quot;0.36363636363636365&quot; data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-w=&quot;627&quot;/&gt;&lt;/p&gt;


&lt;p&gt;于是这一年（2009年），Netflix开始研究利用AWS云来开展业务的各种风险，包括业务竞争风险、规模性风险、商业风险和公关风险等。就业务竞争风险，Netflix与AWS沟融了AWS是如何与Amazon Premier做业务分离的。然后开展实验去验证AWS上的资源快速扩容能力。Netflix还与AWS签订了首批企业许可协议，这种协议下Netflix不需要通过授权信用卡方式来使用AWS资源，而信用卡授权是当时大多数人在AWS上消费时使用的主要方式。 &lt;/p&gt;
&lt;p&gt;随着两家合作消息的传开，2010年4月，纽约时报还发表了一篇关于Netflix和AWS业务的文章，说两者将进行业务合作。请注意其中的“peculiar（特有）“一词，表示那时候企业上云是新闻，而上到竞争对手的云上更是新闻。 &lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;rich_pages&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ibOaboJGeVrREOUX9ZI7WNjCTNEeoZqXPJbkia2xakpVKdYG1bKziauvj0N1lu3SIsqyCNheXMQDiaFjviaJxmjvz3g/640?wx_fmt=png&quot; alt=&quot;&quot; data-ratio=&quot;0.9415481832543444&quot; data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-w=&quot;633&quot;/&gt;&lt;/p&gt;

&lt;p&gt;当时Netflix还咨询了一些业界专家，专家们认为这种做法非常疯狂，因为当时很少有企业这么做，而且企业业务上云在当时还是一个非常不成熟的策略。但Netflix决定坚持下去，成为首批上云企业客户之一。 &lt;/p&gt;
&lt;p&gt;接下来，Netflix实验性地将一些没有真正面向客户的应用迁移到AWS上。首先从电影编码开始，当时其只有数据中心没有足够的容量来容纳编码服务器。有一次Netflix申请3000台服务器，结果AWS一个小时内就交付了，这就验证AWS资源交付的弹性和及时性。而且随着这项工作的完成，不用的机器即被释放，这证明了云计算的“按需使用和付费”特征。&lt;/p&gt;
&lt;p&gt;接下来验证视频服务QoS日志上云。随着进入数据中心数据库的流量越来越多，这些流量正在溢出，而且自己的机房缺乏足够的存储空间来保存想要的信息。于是，Netflix利用S3来存储数据，利用EMR来处理数据。Netflix是Hadoop早期用户之一，曾与AWS合作将Hive作为基于EMR的处理选项。&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;rich_pages&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ibOaboJGeVrREOUX9ZI7WNjCTNEeoZqXPm9saeuNgMP3vl3lFuUkXE6tuIKhic9ZicNRJ5EcZz3qfX0orYdtx4kyQ/640?wx_fmt=png&quot; alt=&quot;&quot; data-backh=&quot;166&quot; data-backw=&quot;578&quot; data-ratio=&quot;0.2864&quot; data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-w=&quot;625&quot;/&gt;&lt;/p&gt;

&lt;p&gt;到2010年，可行性验证基本完成，Netflix认为上云看起来是可行的。于是2011年，Netflix作出决定，不再扩容自有IDC。&lt;/p&gt;



&lt;p&gt;Netflix开始真正地要在AWS云上起飞了。从最简单的API服务开始，然后是最简单的Web网页，然后是更多的API和网页。&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;rich_pages&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ibOaboJGeVrREOUX9ZI7WNjCTNEeoZqXPicpiarfwkyhs98wficiaRSG0IwJhVn3iajwbaRlYXabmb6vFibXr29weP56Q/640?wx_fmt=png&quot; alt=&quot;&quot; data-ratio=&quot;0.19808306709265175&quot; data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-w=&quot;626&quot; data-backw=&quot;578&quot; data-backh=&quot;114&quot;/&gt;&lt;/p&gt;

&lt;p&gt;到2010年底，Netflix成功地将网站前端都迁移到了AWS上，但后端依然在自有数据中心内。&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;rich_pages&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ibOaboJGeVrREOUX9ZI7WNjCTNEeoZqXPjPEVocgd3mooD7BB9kaq2fuZYew5OAOSBaLbUU2C652Spia5jUibmia3Q/640?wx_fmt=png&quot; alt=&quot;&quot; data-backh=&quot;291&quot; data-backw=&quot;578&quot; data-ratio=&quot;0.5040128410914928&quot; data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-w=&quot;623&quot;/&gt;&lt;/p&gt;

&lt;p&gt;用户访问流量还是进入其自有数据中心，但是有选择地将部分流量利用HTTP Redirect将请求转向AWS Cloud。这其实也就是我们现在常常提到的金丝雀模式，通过导入部分用户到新环境上来验证和逐步地完成系统迁移。&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;rich_pages&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ibOaboJGeVrREOUX9ZI7WNjCTNEeoZqXPIMO0VQTz1aobYwPaBBUUHF0DG1icEH9Sje33kJ9NhGxiaXxSWWweb84g/640?wx_fmt=png&quot; alt=&quot;&quot; data-ratio=&quot;0.536115569823435&quot; data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-w=&quot;623&quot; data-backw=&quot;578&quot; data-backh=&quot;310&quot;/&gt;&lt;/p&gt;

&lt;p&gt;接下来是数据迁移。2010年的主要工作之一，是将主数据系统放在数据中心，将副本放在云中，并将数据从本地持续地同步到云中。&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;rich_pages&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ibOaboJGeVrREOUX9ZI7WNjCTNEeoZqXPawhzIxPWWUtXesn0rkBsIZXYzrLwLCHEXKr4fCgHatG8rjeXpNNdug/640?wx_fmt=png&quot; alt=&quot;&quot; data-backh=&quot;307&quot; data-backw=&quot;578&quot; data-ratio=&quot;0.5313001605136437&quot; data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-w=&quot;623&quot;/&gt;&lt;/p&gt;

&lt;p&gt;2011年，Netflix决定将所有数据放到云上。其中一个问题是如何做数据备份。Netflix没有采用当时常见的利用本地数据中心中的磁带来备份云中数据的做法，而是充分利用了S3的安全性和持久性，用不同的账户在不同的AWS区域中创建S3存储桶，然后将生产数据导入生产区域S3存储桶，再经过压缩和加密并传送到容灾区域的桶中。利用不同的账户，主要是从安全角度考虑。后来，AWS发布了Glacier后，Netflix利用它来做长期归档的数据存储。&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;rich_pages&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ibOaboJGeVrREOUX9ZI7WNjCTNEeoZqXPsmZWOg6M5iadbHDLKVvbGFiayo85nH46hC8Q8abvLiczvnaVWGSTgEKIw/640?wx_fmt=png&quot; alt=&quot;&quot; data-backh=&quot;281&quot; data-backw=&quot;578&quot; data-ratio=&quot;0.4864&quot; data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-w=&quot;625&quot;/&gt; &lt;/p&gt;

&lt;p&gt;到2015年，除了计费和账单系统外，其余所有系统都已经迁移到AWS上了。到2016年1月4日，Netflix完成了最后这两个系统的迁移，详细信息请参加其公司博客https://netflixtechblog.com/netflix-billing-migration-to-aws-451fba085a4。&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;rich_pages&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ibOaboJGeVrREOUX9ZI7WNjCTNEeoZqXP8Oy1Xt9RYBl3zcYXABjSO6gGfLKaClRWICblVOezvoIGHGeFGvSULw/640?wx_fmt=png&quot; alt=&quot;&quot; data-ratio=&quot;0.5463414634146342&quot; data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-w=&quot;615&quot; data-backw=&quot;578&quot; data-backh=&quot;316&quot;/&gt;&lt;/p&gt;



&lt;p&gt;2016年2月，Netflix宣布其上云迁移工作全部完成。这一年，Netflix的用户数是2008年开始上云迁移时候的8倍，而用户的月度观看视频数则有几千倍的增长，用户遍布全球超过130个国家，Netflix也成为了一家国际化视频服务提供商。&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;rich_pages&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ibOaboJGeVrREOUX9ZI7WNjCTNEeoZqXPMxALC6qP4b2MSBtVMniaK61MjDydibc8eHOicNTjeT4iauRicSj5GZJHhwQ/640?wx_fmt=png&quot; alt=&quot;&quot; data-ratio=&quot;0.5893719806763285&quot; data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-w=&quot;621&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;rich_pages&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ibOaboJGeVrREOUX9ZI7WNjCTNEeoZqXPjoCkKQDvPPDiaZQvnAlLZveOvIOhSVGnNtibzJ70JfMojYPY0MicH84PQ/640?wx_fmt=png&quot; alt=&quot;&quot; data-ratio=&quot;0.6944&quot; data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-w=&quot;625&quot;/&gt;&lt;/p&gt;

&lt;p&gt;到2017年，除了CDN由其自建外，Netflix使用AWS来满足其几乎所有计算和存储需求，包括数据库、分析、建议引擎、视频转码等数百种功能。而且，Netflix系统的可用性在持续增加，正在不断接近99.99%的既定目标。&lt;/p&gt;
&lt;ul class=&quot; list-paddingleft-2&quot; readability=&quot;3.5&quot;&gt;&lt;li readability=&quot;2&quot;&gt;
&lt;p&gt;Netflix的视频服务在高峰时段占据了高达37%的Internet流量。相比之下，YouTube 仅占到15.6%，网页浏览约 6%, Facebook约2.7%, Amazon Instant Video 约2.0%。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;在AWS上共利用超过10万个 EC2 Instances 的80万CPU Cores，且在此基础上有约 20% 的波动。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;在每个服务区域上的 AWS Elastic Load Balancing 的流量超过 50Gbps&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;在 S3 上存储和管理超过15亿个对象的 60 PB 的数据。其中每天要丢弃超过 400TB 的过期数据以及新增 600TB 的数据。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;2016年Netflix在AWS上的系统架构：&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;rich_pages&quot; src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ibOaboJGeVrREOUX9ZI7WNjCTNEeoZqXPdtZYhibZxRqdZ8mLckWbEZURJiazuuB8WHQQib3GoicqicyzmPC3GwOQnVw/640?wx_fmt=png&quot; alt=&quot;&quot; data-ratio=&quot;0.7275641025641025&quot; data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-w=&quot;624&quot;/&gt;&lt;/p&gt;
&lt;p&gt;尽管降低成本支出并不是Netflix上云的主要出发点之一，但是实际上，现在每个视频的播放成本是当初利用自有数据中心的几分之一，这是一种非常可观的额外收益。这主要归功于云的弹性，使得Netflix可以持续地优化实例类型，近乎实时地增加或减少所用的资源，而不需要维持大规模的备用容量，以及公有云的规模不断扩大带来的单位成本下降。 &lt;/p&gt;
&lt;p&gt;那为什么需要7年时间才能完成上云迁移呢？这是因为全业务上云是一项艰巨的工作，需要做好多的艰难决策。可以想到的是，最简单的方式是将所有系统缘分不断地搬到云上，但是随着系统一起搬过去的还有你在传统数据中心中遇到的所有问题和限制。因此，Netflix选择了一条另外的道路，重构所有系统，彻底改变公司IT运营方式，将单体应用改变为微服务架构应用、重构数据模型、使用NoSQL数据库。将过去那种预算严格受控制、版本发布严格受管控、花几周时间来做物理容量扩容的传统方式，改变为持续集成和发布、技术团队独立做决策、基于松耦合DevOps环境的新方式。这种方式使得Netflix花了七年时间才完成上云之旅，但是正是这种转变，也使得它成为了一家国际化的网络视频服务提供商。 &lt;/p&gt;

&lt;p&gt;参考资料：&lt;/p&gt;
&lt;ul class=&quot; list-paddingleft-2&quot; readability=&quot;4.5&quot;&gt;&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;复盘Netflix发展史：如何用20年成为一家千亿美元公司？，克鲁斯2018年5月14日。https://www.gelonghui.com/p/179693&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;Completing the Netflix Cloud Migration，https://media.netflix.com/en/company-blog/completing-the-netflix-cloud-migration，2016.1&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;YouTube video，Globally Distributed Cloud Applications at Netflix，October 2012，Adrian Cockcro&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;1&quot;&gt;
&lt;p&gt;Migrating to Cloud - Lessons from Netflix, Brought Up to Date，Adrian Cockcroft，https://media.netflix.com/en/company-blog/completing-the-netflix-cloud-migration&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;Companies Slowly Join Cloud-Computing，By &lt;span&gt;Brad Stone and &lt;span&gt;Ashlee Vance，https://www.nytimes.com/2010/04/19/technology/19cloud.html&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;感谢您的阅读，欢迎关注我的微信公众号：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ibOaboJGeVrRyeJlFTfQZSuPbibz5RyCBgyKs5VcucqyKqE11e5rLsAUuJ0jz1rDPnwav00QFW1btsaFOKfo00zA/640?wx_fmt=jpeg&quot; alt=&quot;&quot; data-ratio=&quot;0.9665271966527197&quot; data-type=&quot;jpeg&quot; data-w=&quot;239&quot;/&gt;&lt;/p&gt;
&lt;/div&gt;</description>
<pubDate>Sat, 30 May 2020 14:49:00 +0000</pubDate>
<dc:creator>SammyLiu</dc:creator>
<og:description>对奈飞（Netflix）的上云之旅及其云上运行进行梳理和总结，形成系列文章。本文为这系列文章的第一篇，介绍奈飞的总体上云历程。</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/sammyliu/p/12995447.html</dc:identifier>
</item>
<item>
<title>TechEmpower Web 框架性能第19轮测试结果正式发布，ASP.NET Core在主流框架中拔得头筹 - 张善友</title>
<link>http://www.cnblogs.com/shanyou/p/12995227.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/shanyou/p/12995227.html</guid>
<description>&lt;p&gt;TechEmpower 第19轮编程语言框架性能排行榜2020年5月28日正式发布,详见官方博客：&lt;a title=&quot;https://www.techempower.com/blog/2020/05/28/framework-benchmarks-round-19/&quot; href=&quot;https://www.techempower.com/blog/2020/05/28/framework-benchmarks-round-19/&quot;&gt;https://www.techempower.com/blog/2020/05/28/framework-benchmarks-round-19/&lt;/a&gt;，TechEmpower基准测试有许多场景（也称为测试类型），此次评测多了一个综合评分选项，把拥有完整测试覆盖的框架现在将具有综合&lt;strong&gt;分数&lt;/strong&gt;，这反映了测试项目类型的总体性能得分：JSON serialization, Single-query, Multi-query, Updates, Fortunes 和 Plaintext. 。对于每一轮，我们使每个测试类型的结果规范化，然后为每个测试类型应用主观权重（例如，Fortunes的权重比 Plaintext 高，因为Fortunes 是一种更现实的测试类型）。asp.net core排第6名，asp.net 排名倒数第二，第103名， 微软从倒数一路追赶到第一。&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://img2020.cnblogs.com/blog/510/202005/510-20200530220107529-1000140091.png&quot;&gt;&lt;img width=&quot;569&quot; height=&quot;411&quot; title=&quot;image&quot; alt=&quot;image&quot; src=&quot;https://img2020.cnblogs.com/blog/510/202005/510-20200530220108275-2025555255.png&quot; border=&quot;0&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;表上前缀T标签表示精选的主流编程语言&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;第1名 C++的drogon 9676分&lt;/li&gt;
&lt;li&gt;第2名 Rust的actix 9064分&lt;/li&gt;
&lt;li&gt;第6名 C#的ASP.NET Core 5659分&lt;/li&gt;
&lt;li&gt;第29名 Go的Chi 2229分&lt;/li&gt;
&lt;li&gt;第34名 Java的Spring 1867分&lt;/li&gt;
&lt;li&gt;第73名 Nodejs的Express 821分&lt;/li&gt;
&lt;li&gt;第94名 PHP的laravel 348分&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;在主流的编程语言中ASP.NET Core 获得了排名三的好成绩，本次的测试的是ASP.NET Core 3.1, .NET 5 在生产任务调度方面还在继续优化，相信未来性能还会继续提升，具体可以关注:&lt;a title=&quot;https://aka.ms/aspnet/benchmarks&quot; href=&quot;https://aka.ms/aspnet/benchmarks&quot;&gt;https://aka.ms/aspnet/benchmarks&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;在当今无服务器和容器的时代，很高兴看到行业竞争并在冷启动和内存消耗方面进行艰难的测试，PlaintText单项排名很好的体现了这一项：&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://img2020.cnblogs.com/blog/510/202005/510-20200530220108877-214968884.png&quot;&gt;&lt;img width=&quot;577&quot; height=&quot;467&quot; title=&quot;image&quot; alt=&quot;image&quot; src=&quot;https://img2020.cnblogs.com/blog/510/202005/510-20200530220109519-538614771.png&quot; border=&quot;0&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Fortunes测试类型是最有趣的，因为它包括使用对象关系映射器（ORM）和数据库。这是Web应用程序/服务中的常见用例。以前版本的ASP.NET Core在这种情况下表现不佳。由于堆栈和PostgreSQL驱动程序中的优化，ASP.NET Core 2.1得到了显著改进, 3.1 版本又 提升到了27万。 其他方案不太代表典型的应用程序。他们强调堆栈的特定方面。如果它们与您的用例紧密匹配，它们可能会很有趣。对于框架开发人员，他们帮助识别进一步优化堆栈的机会。 例如，考虑Plaintext方案。此方案涉及客户端发送16个请求背靠背（流水线），服务器知道响应，而无需执行I / O操作或计算。这不代表典型的请求，但它是解析HTTP请求的良好压力测试。 每个实现都有一个类。例如，ASP.NET Core Plaintext具有platform, micro和full 实现。full 的实现是使用MVC中间件。Micro实现在管道级实现，platform实现直接建立在Kestrel之上。虽然Platform 类提供了引擎功能强大的概念，但它不是用于应用程序开发人员编程的API。 基准测试结果包括Latency选项卡。一些实现每秒实现非常多的请求，但是以相当大的延迟成本。&lt;/p&gt;
</description>
<pubDate>Sat, 30 May 2020 14:46:00 +0000</pubDate>
<dc:creator>张善友</dc:creator>
<og:description>TechEmpower 第19轮编程语言框架性能排行榜2020年5月28日正式发布,详见官方博客：https://www.techempower.com/blog/2020/05/28/framewo</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/shanyou/p/12995227.html</dc:identifier>
</item>
<item>
<title>一篇文章，全面掌握Git - 一直奋斗的程序猿</title>
<link>http://www.cnblogs.com/sky233/p/12995362.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/sky233/p/12995362.html</guid>
<description>&lt;h2 id=&quot;版本控制&quot;&gt;版本控制&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;版本控制&lt;/strong&gt;就是记录项目文件的历史变化。它为我们&lt;strong&gt;查阅日志&lt;/strong&gt;，&lt;strong&gt;回退&lt;/strong&gt;，&lt;strong&gt;协作&lt;/strong&gt;等方面提供了有力的帮助。&lt;/p&gt;
&lt;p&gt;版本控制一般分为集中化版本控制和分布式版本控制。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://upload-images.jianshu.io/upload_images/19724385-e9ae0e66f0c693ea.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240&quot; alt=&quot;集中式&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://upload-images.jianshu.io/upload_images/19724385-bb4f74594a8124d3.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240&quot; alt=&quot;分布式&quot;/&gt;&lt;/p&gt;
&lt;p&gt;集中化主要的版本数据都保存服务端。&lt;/p&gt;
&lt;p&gt;分布式版本数据分散在多端。&lt;/p&gt;
&lt;h2 id=&quot;git&quot;&gt;Git&lt;/h2&gt;
&lt;p&gt;Git属于分布式版本控制，也是现在比较流行的一种版本管理工具。&lt;/p&gt;
&lt;p&gt;Git项目有三个区块：工作区 / 暂存区 / 版本库&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;工作区存放从版本库提取出来的文件，供我们编辑修改；&lt;/li&gt;
&lt;li&gt;暂存区保存了下一次要提交的目录信息；&lt;/li&gt;
&lt;li&gt;版本库保存项目版本元数据和Objects数据，后文会详解。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;img src=&quot;https://upload-images.jianshu.io/upload_images/19724385-f6fd498f7ca2ebfc.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240&quot; alt=&quot;Git工作流程&quot;/&gt;&lt;/p&gt;
&lt;p&gt;Git工作流程&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;# 下载
&amp;lt;&amp;lt;==== clone 
# 上传
====&amp;gt;&amp;gt; add ====&amp;gt;&amp;gt; commit ====&amp;gt;&amp;gt; push
# 更新
&amp;lt;&amp;lt;==== merge|rebase &amp;lt;&amp;lt;===== fetch

&lt;/code&gt;
&lt;/pre&gt;
&lt;h4 id=&quot;区分-pull-vs-fetch&quot;&gt;区分 Pull vs Fetch&lt;/h4&gt;
&lt;p&gt;我们将一个更新操作拆分为&lt;strong&gt;数据更新+合并处理&lt;/strong&gt;两部分，这样来看 fetch 只是进行数据更新。而pull 其实是 ( fetch + (merge|rebase) )组合操作，它执行&lt;strong&gt;数据更新&lt;/strong&gt;同时执行&lt;strong&gt;合并处理&lt;/strong&gt;。pull 默认是fetch+merge 组合 ，也可以通过参数 --rebase 指定为 fetch + rebase。&lt;/p&gt;
&lt;h4 id=&quot;区分merge-vs-rebase&quot;&gt;区分Merge vs Rebase&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;合并处理&lt;/strong&gt;是Git很重要的一块知识。两个命令在工作中也经常使用，区分它们对我们很有用。&lt;/p&gt;
&lt;p&gt;场景如下&lt;/p&gt;
&lt;p&gt;项目有一个mywork分支。C2时间点我和小明各自下载项目进行功能开发，小明效率比较高，先推送了C3 C4 到远程仓库。我本地仓库现在有C5 C6两个提交，要推送到远程仓库，需先同步远程仓库版本。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://upload-images.jianshu.io/upload_images/19724385-a7659059cab50789.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240&quot; alt=&quot;git&quot;/&gt;&lt;/p&gt;
&lt;p&gt;如果通过 fetch + merge 方式，Git会将远程最新(C4)和本地最新(C6)进行合并并产生一个新的(C7)。&lt;/p&gt;
&lt;p&gt;冲突处理步骤&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;git merge # 发生冲突会出现冲突标记
“&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt; HEAD
40
=======
41
&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt; 41”
# 手动处理冲突
git add .
git commit -m 'fix conflict'
git push origin HEAD
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;img src=&quot;https://upload-images.jianshu.io/upload_images/19724385-7c8fba26a4901ea4.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240&quot; alt=&quot;git merge&quot;/&gt;&lt;/p&gt;
&lt;p&gt;如果通过 fetch + rebase 方式，git会先将C5 C6存储到.git/rebase零时目录，合并成功后删除。&lt;/p&gt;
&lt;p&gt;冲突处理步骤&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;git rebase # 发生冲突会出现冲突标记
“&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt; HEAD
40
=======
41
&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt; 41”
# 手动处理冲突
git add .
git rebase --continue
git push origin HEAD
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;img src=&quot;https://upload-images.jianshu.io/upload_images/19724385-dbd184aefc6b1c45.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240&quot; alt=&quot;git rebase&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://upload-images.jianshu.io/upload_images/19724385-9e2a3fe48b566a19.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240&quot; alt=&quot;git rebase&quot;/&gt;&lt;/p&gt;
&lt;h4 id=&quot;小结&quot;&gt;小结&lt;/h4&gt;
&lt;p&gt;git merge 会产生大量Merge日志，可能会对查看带来不便。不过大家还是根据实际情况进行选取。&lt;/p&gt;
&lt;h4 id=&quot;关于撤销回退几种场景&quot;&gt;关于撤销回退几种场景&lt;/h4&gt;
&lt;p&gt;提交后发现有文件漏了，又不想提交两次。此时通过 “git commit --amend” 可以合并为一个提交。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;git commit -m 'initial commit'
git add .gitignore
git commit --amend
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;如果文件想撤回且尚未提交，执行下面命令撤出暂存空间（index）&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;git reset HEAD &amp;lt;file&amp;gt;...
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;关于 reset 其它用法&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;# 重置到指定版本，之前提交内容将丢失
git reset --hard HEAD 
# 重置到指定版本，保留更改的文件但未标记为提交
git reset --mixed HEAD 
# 重置到指定版本，保留所有改动文件
git reset –soft HEAD 
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;特别注意&lt;/strong&gt; 当你使用 “git reset --hard HEAD” 重置到某一版本，发现搞错了想回退。这时你可能会执行“git log”，但是发现已经没有以前的版本记录，怎么办？送你一瓶后悔药如下&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;# reflog 是Git操作的全日志记录
git reflog

6241462 (HEAD -&amp;gt; master) HEAD@{0}: reset: moving to 6241462
ea9b5ab HEAD@{1}: reset: moving to ea9b5ab
6241462 (HEAD -&amp;gt; master) HEAD@{2}: commit: Hello
34cd1e3 HEAD@{3}: commit: 3
ea9b5ab HEAD@{4}: commit: 2
729a8b1 (origin/master) HEAD@{5}: commit (initial): 1

# 找到最左边对应hash值就可以回退到任意位置
git reset --hard {index}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;如果想撤回文件修改内容且文件尚未提交，执行下面命令&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;git checkout -- &amp;lt;file&amp;gt;
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;如果创建的分支名称需要更改&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;git branch -m old new

# 如果分支已经推送到远程，先删除再推送新分支
git push origin --delete old
git push origin new
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;如果&lt;strong&gt;需要撤回的提交&lt;/strong&gt;已经推送到了远程仓库，那么补救的方式只有创建新的提交。&lt;/p&gt;
&lt;p&gt;可以利用revert快速撤回到需要回退的版本。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;# 还原最近一个提交
git revert HEAD
# 还原倒数第二个
git revert HEAD^
# 还原倒数第第四个
git revert HEAD~3
&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;版本库-objects&quot;&gt;版本库 Objects&lt;/h2&gt;
&lt;p&gt;这一节介绍一下Git版本库的存储模型。&lt;/p&gt;
&lt;p&gt;项目历史变动信息都记录在object文件。文件名称是通过&lt;strong&gt;哈希算法&lt;/strong&gt; ( 这里是SHA1(对象内容) ) 产生的40位字符。&lt;/p&gt;
&lt;p&gt;这种做法的一个优点就是“在对比两对象是否相同时，只需要比较文件名称就能迅速得出结果”&lt;/p&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;哈希算法：简单来说就是向函数输入一些内容，输出长度固定的字符串。这里SHA1函数固定输出40长度字符。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;object文件分 &lt;strong&gt;blob&lt;/strong&gt; &lt;strong&gt;tree&lt;/strong&gt; &lt;strong&gt;commit&lt;/strong&gt; &lt;strong&gt;tag&lt;/strong&gt; 四种类型&lt;/p&gt;
&lt;ul readability=&quot;1&quot;&gt;&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;&lt;strong&gt;blob&lt;/strong&gt; 存储文件数据，一般是一个文件；&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;&lt;strong&gt;tree&lt;/strong&gt; 存储目录和树的引用（子文件目录）；&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;&lt;strong&gt;commit&lt;/strong&gt; 存储单一树引用，时间点，提交作者，上一次提交指针；&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;&lt;strong&gt;tag&lt;/strong&gt; 标记特定的&lt;strong&gt;commit&lt;/strong&gt; 比如说发版。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;特别注意：Subversion，CVS，Perforce，Mercurial等是存储前后两次提交的差异数据。Gi-每次提交时，它都会以树状结构存储项目中所有文件的外观快照。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4 id=&quot;blob&quot;&gt;Blob&lt;/h4&gt;
&lt;p&gt;&lt;img src=&quot;https://upload-images.jianshu.io/upload_images/19724385-d0c5995ba38b52ce.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240&quot; alt=&quot;blob&quot;/&gt;&lt;/p&gt;
&lt;p&gt;Blob 是二进制数据块，不会引用其它东西。如果目录树（或存储库中多个不同版本）中的两个文件具有内容相同，它们将共享相同的Blob对象。&lt;/p&gt;
&lt;h4 id=&quot;tree&quot;&gt;Tree&lt;/h4&gt;
&lt;p&gt;&lt;img src=&quot;https://upload-images.jianshu.io/upload_images/19724385-bbbf43b0393565b0.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240&quot; alt=&quot;tree&quot;/&gt;&lt;/p&gt;
&lt;p&gt;Tree 存储blob和tree的引用。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;# 我查询 add1a1306e20...
git ls-tree add1a1306e20...

100644 blob 4661b39c3460a5c1f9e9309e6341962e0499b037    README.md
040000 tree ad46b24a4b0648ede3ca090dde32c89b89f7f2c1    src
...
&lt;/code&gt;
&lt;/pre&gt;
&lt;h4 id=&quot;commit&quot;&gt;Commit&lt;/h4&gt;
&lt;p&gt;&lt;img src=&quot;https://upload-images.jianshu.io/upload_images/19724385-c16560cf172ae42d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240&quot; alt=&quot;commit&quot;/&gt;&lt;/p&gt;
&lt;p&gt;Commit 包含下面几个信息&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;&lt;strong&gt;tree&lt;/strong&gt; 提交时间点的目录；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;parent&lt;/strong&gt; 上一个提交；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;author&lt;/strong&gt; 提交人；&lt;/li&gt;
&lt;/ol&gt;&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;git show -s --pretty=raw add1a1306e....

commit add1a1306e....
tree 81d4e4271a56575da7f992dc0dfc72ff7ddff94c
parent cd397e4c373013b19825b857b43ad8f677607f5d
author lixingping &amp;lt;lixingping233@gmail.com&amp;gt; 1589783810 +0800
committer lixingping &amp;lt;lixingping233@gmail.com&amp;gt; 1589783810 +0800
&lt;/code&gt;
&lt;/pre&gt;
&lt;h4 id=&quot;tag&quot;&gt;Tag&lt;/h4&gt;
&lt;p&gt;&lt;img src=&quot;https://upload-images.jianshu.io/upload_images/19724385-ee5d12a073747496.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240&quot; alt=&quot;tag&quot;/&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;git cat-file tag v_1.0

object 24d16acd6aa08f74556c7ce551fa571b4bfe4079
type commit
tag v_1.0
tagger lixingping &amp;lt;lixingping233@gmail.com&amp;gt; 1588591122 +0800
&lt;/code&gt;
&lt;/pre&gt;
&lt;h4 id=&quot;例子&quot;&gt;例子&lt;/h4&gt;
&lt;p&gt;假设项目目录结构如下，我们进行一个初始提交。几种文件关系如下图&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;|-- read.txt
    --| lib
      --| hello.java
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;img src=&quot;https://upload-images.jianshu.io/upload_images/19724385-a14f0dc859c15a28.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240&quot; alt=&quot;关系图&quot;/&gt;&lt;/p&gt;
&lt;h2 id=&quot;附上一些常用命令&quot;&gt;附上一些常用命令&lt;/h2&gt;
&lt;p&gt;生成SSH key&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-shell&quot;&gt;ssh-keygen -t rsa -b 4096 -C &quot;email@example.com&quot;
# 指定生成的文件
ssh-keygen -t rsa -b 4096 -C &quot;email@example.com&quot; -f ~/.ssh/id_rsa_example
# id_rsa_example.pub 粘贴远程仓库

# 配置多个远程仓库
touch ~/.ssh/config

#添加一下内容
Host github.com
HostName github.com
User git
IdentityFile ~/.ssh/id_rsa_github

Host example.com
HostName example.com
User git
IdentityFile ~/.ssh/id_rsa_example

&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;配置&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;git config –global user.name “xxx”
git config –global user.email “xxx@email.com“
git config --global core.autocrlf true # 建议配置 windows mac换行符不统一问题
git config --global core.editor vim # 配置默认编辑器
git config --global core.excludesfile ~/.gitignore_global # 配置全局忽略文件
git config –list # 查看配置信息
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;分支管理&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;git branch --list # 罗列本地所有分支
git branch --all  # 罗列本地和远程所有分支
git branch -r     # 罗列远程所有分支
git branch -v     # 显示各分支最后提交信息
git checkout &amp;lt;branch name&amp;gt; # 切换分支
git checkout -b &amp;lt;new branch name&amp;gt; # 创建新分支
git push origin &amp;lt;new branch name&amp;gt; # 推送新分支到远程
git checkout -m &amp;lt;old branch&amp;gt; &amp;lt;new branch&amp;gt; # 重命名分支名称
git branch -d &amp;lt;[list]branch name&amp;gt; # 删除本地分支
git push origin --delete &amp;lt;branch name&amp;gt; # 删除远程分支
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;标签管理&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;git tag -l # 罗列本地所有标签
git show &amp;lt;tag name&amp;gt; # 显示指定标签
git tag -a v_1.0.0 -m &quot;备注&quot; # 创建标签
git push origin &amp;lt;tag name&amp;gt; # 推送标签到远程
git tag -d &amp;lt;tag name&amp;gt; # 删除本地标签
git push --delete origin &amp;lt;tag name&amp;gt; # 删除远程标签
&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;总结&quot;&gt;总结&lt;/h2&gt;
&lt;p&gt;工作多年以来一直在使用Git，但是对Git没有一个系统了解，所以写这篇文章归整一下。&lt;/p&gt;
&lt;p&gt;欢迎大家留言交流，一起学习分享！！！&lt;/p&gt;
</description>
<pubDate>Sat, 30 May 2020 14:32:00 +0000</pubDate>
<dc:creator>一直奋斗的程序猿</dc:creator>
<og:description>版本控制 版本控制就是记录项目文件的历史变化。它为我们查阅日志，回退，协作等方面提供了有力的帮助。 版本控制一般分为集中化版本控制和分布式版本控制。 集中化主要的版本数据都保存服务端。 分布式版本数据</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/sky233/p/12995362.html</dc:identifier>
</item>
<item>
<title>TCP 半连接队列和全连接队列满了会发生什么？又该如何应对？ - 小林coding</title>
<link>http://www.cnblogs.com/xiaolincoding/p/12995358.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/xiaolincoding/p/12995358.html</guid>
<description>&lt;h2 id=&quot;h&quot;&gt;&lt;span&gt;前言&lt;/span&gt;&lt;/h2&gt;
&lt;p&gt;网上许多博客针对增大 TCP 半连接队列和全连接队列的方式如下：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;span&gt;增大 TCP 半连接队列的方式是增大 /proc/sys/net/ipv4/tcp_max_syn_backlog；&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span&gt;增大 TCP 全连接队列的方式是增大 listen() 函数中的 backlog；&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;这里先跟大家说下，&lt;strong&gt;上面的方式都是不准确的。&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;“你怎么知道不准确？”&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;很简单呀，因为我做了实验和看了 TCP 协议栈的内核源码，发现要增大这两个队列长度，不是简简单单增大某一个参数就可以的。&lt;/p&gt;
&lt;p&gt;接下来，就会以&lt;strong&gt;实战 + 源码分析，带大家解密 TCP 半连接队列和全连接队列。&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;“源码分析，那不是劝退吗？我们搞 Java 的看不懂呀”&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;放心，本文的源码分析不会涉及很深的知识，因为都被我删减了，你只需要会条件判断语句 if、左移右移操作符、加减法等基本语法，就可以看懂。&lt;/p&gt;
&lt;p&gt;另外，不仅有源码分析，还会介绍 Linux 排查半连接队列和全连接队列的命令。&lt;/p&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;“哦？似乎很有看头，那我姑且看一下吧！”&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;行，没有被劝退的小伙伴，值得鼓励，下面这图是本文的提纲：&lt;/p&gt;
&lt;img title=&quot;本文提纲&quot; src=&quot;https://imgkr.cn-bj.ufileos.com/f8a75556-6947-4fff-9641-7437dd4192b5.png&quot; alt=&quot;本文提纲&quot;/&gt;本文提纲
&lt;hr/&gt;&lt;h2 id=&quot;h-1&quot;&gt;&lt;span&gt;正文&lt;/span&gt;&lt;/h2&gt;
&lt;h3 id=&quot;htcp&quot;&gt;&lt;span&gt;什么是 TCP 半连接队列和全连接队列？&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;在 TCP 三次握手的时候，Linux 内核会维护两个队列，分别是：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;span&gt;半连接队列，也称 SYN 队列；&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span&gt;全连接队列，也称 accepet 队列；&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;服务端收到客户端发起的 SYN 请求后，&lt;strong&gt;内核会把该连接存储到半连接队列&lt;/strong&gt;，并向客户端响应 SYN+ACK，接着客户端会返回 ACK，服务端收到第三次握手的 ACK 后，&lt;strong&gt;内核会把连接从半连接队列移除，然后创建新的完全的连接，并将其添加到 accept 队列，等待进程调用 accept 函数时把连接取出来。&lt;/strong&gt;&lt;/p&gt;
&lt;img title=&quot;半连接队列与全连接队列&quot; src=&quot;https://imgkr.cn-bj.ufileos.com/ff7b0667-a0b3-4686-958d-1662eb77991d.png&quot; alt=&quot;半连接队列与全连接队列&quot;/&gt;半连接队列与全连接队列
&lt;p&gt;不管是半连接队列还是全连接队列，都有最大长度限制，超过限制时，内核会直接丢弃，或返回 RST 包。&lt;/p&gt;
&lt;hr/&gt;&lt;h3 id=&quot;htcp-1&quot;&gt;&lt;span&gt;实战 - TCP 全连接队列溢出&lt;/span&gt;&lt;/h3&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;如何知道应用程序的 TCP 全连接队列大小？&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;在服务端可以使用 &lt;code&gt;ss&lt;/code&gt; 命令，来查看 TCP 全连接队列的情况：&lt;/p&gt;
&lt;p&gt;但需要注意的是 &lt;code&gt;ss&lt;/code&gt; 命令获取的 &lt;code&gt;Recv-Q/Send-Q&lt;/code&gt; 在「LISTEN 状态」和「非 LISTEN 状态」所表达的含义是不同的。从下面的内核代码可以看出区别：&lt;/p&gt;
&lt;img title=&quot;&quot; src=&quot;https://imgkr.cn-bj.ufileos.com/639b5630-83c3-4823-a802-9510ef593385.png&quot; alt=&quot;&quot;/&gt;&lt;p&gt;在「LISTEN 状态」时，&lt;code&gt;Recv-Q/Send-Q&lt;/code&gt; 表示的含义如下：&lt;/p&gt;
&lt;img title=&quot;&quot; src=&quot;https://imgkr.cn-bj.ufileos.com/a62f572a-f4ed-4bef-bac2-27430eac6a67.png&quot; alt=&quot;&quot;/&gt;&lt;ul&gt;&lt;li&gt;Recv-Q：当前全连接队列的大小，也就是当前已完成三次握手并等待服务端 &lt;code&gt;accept()&lt;/code&gt; 的 TCP 连接；&lt;/li&gt;
&lt;li&gt;&lt;span&gt;Send-Q：当前全连接最大队列长度，上面的输出结果说明监听 8088 端口的 TCP 服务，最大全连接长度为 128；&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;在「非 LISTEN 状态」时，&lt;code&gt;Recv-Q/Send-Q&lt;/code&gt; 表示的含义如下：&lt;/p&gt;
&lt;img title=&quot;&quot; src=&quot;https://imgkr.cn-bj.ufileos.com/d51db075-bdcc-4d5b-ba42-d71de3de440f.png&quot; alt=&quot;&quot;/&gt;&lt;ul&gt;&lt;li&gt;&lt;span&gt;Recv-Q：已收到但未被应用进程读取的字节数；&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span&gt;Send-Q：已发送但未收到确认的字节数；&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;如何模拟 TCP 全连接队列溢出的场景？&lt;/p&gt;
&lt;/blockquote&gt;
&lt;img title=&quot;测试环境&quot; src=&quot;https://imgkr.cn-bj.ufileos.com/fefe24ad-6cc6-4386-a472-35f369c08435.png&quot; alt=&quot;测试环境&quot;/&gt;测试环境
&lt;p&gt;实验环境：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;span&gt;客户端和服务端都是 CentOs 6.5 ，Linux 内核版本 2.6.32&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span&gt;服务端 IP 192.168.3.200，客户端 IP 192.168.3.100&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span&gt;服务端是 Nginx 服务，端口为 8088&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;这里先介绍下 &lt;code&gt;wrk&lt;/code&gt; 工具，它是一款简单的 HTTP 压测工具，它能够在单机多核 CPU 的条件下，使用系统自带的高性能 I/O 机制，通过多线程和事件模式，对目标机器产生大量的负载。&lt;/p&gt;
&lt;p&gt;本次模拟实验就使用 &lt;code&gt;wrk&lt;/code&gt; 工具来压力测试服务端，发起大量的请求，一起看看服务端 TCP 全连接队列满了会发生什么？有什么观察指标？&lt;/p&gt;
&lt;p&gt;客户端执行 &lt;code&gt;wrk&lt;/code&gt; 命令对服务端发起压力测试，并发 3 万个连接：&lt;/p&gt;
&lt;img title=&quot;&quot; src=&quot;https://imgkr.cn-bj.ufileos.com/fd4897e4-5d31-407e-9447-65d5cf8abed3.png&quot; alt=&quot;&quot;/&gt;&lt;p&gt;在服务端可以使用 &lt;code&gt;ss&lt;/code&gt; 命令，来查看当前 TCP 全连接队列的情况：&lt;/p&gt;
&lt;img title=&quot;&quot; src=&quot;https://imgkr.cn-bj.ufileos.com/26833da1-6a0e-41b9-a1d9-de960f6a5f43.png&quot; alt=&quot;&quot;/&gt;&lt;p&gt;其间共执行了两次 ss 命令，从上面的输出结果，可以发现当前 TCP 全连接队列上升到了 129 大小，超过了最大 TCP 全连接队列。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;当超过了 TCP 最大全连接队列，服务端则会丢掉后续进来的 TCP 连接&lt;/strong&gt;，丢掉的 TCP 连接的个数会被统计起来，我们可以使用 netstat -s 命令来查看：&lt;/p&gt;
&lt;img title=&quot;&quot; src=&quot;https://imgkr.cn-bj.ufileos.com/01803f19-b061-40ea-8eed-05466a7e11af.png&quot; alt=&quot;&quot;/&gt;&lt;p&gt;上面看到的 41150 times ，表示全连接队列溢出的次数，注意这个是累计值。可以隔几秒钟执行下，如果这个数字一直在增加的话肯定全连接队列偶尔满了。&lt;/p&gt;
&lt;p&gt;从上面的模拟结果，可以得知，&lt;strong&gt;当服务端并发处理大量请求时，如果 TCP 全连接队列过小，就容易溢出。发生 TCP 全连接队溢出的时候，后续的请求就会被丢弃，这样就会出现服务端请求数量上不去的现象。&lt;/strong&gt;&lt;/p&gt;
&lt;img title=&quot;全连接队列溢出&quot; src=&quot;https://imgkr.cn-bj.ufileos.com/fb25464a-0306-44a6-9cef-0075e64b9f0e.png&quot; alt=&quot;全连接队列溢出&quot;/&gt;全连接队列溢出
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;Linux 有个参数可以指定当 TCP 全连接队列满了会使用什么策略来回应客户端。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;实际上，丢弃连接只是 Linux 的默认行为，我们还可以选择向客户端发送 RST 复位报文，告诉客户端连接已经建立失败。&lt;/p&gt;
&lt;img title=&quot;&quot; src=&quot;https://imgkr.cn-bj.ufileos.com/a08d38aa-fb91-466c-bb08-52d5f2820bfc.png&quot; alt=&quot;&quot;/&gt;&lt;p&gt;tcp_abort_on_overflow 共有两个值分别是 0 和 1，其分别表示：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;span&gt;0 ：如果全连接队列满了，那么 server 扔掉 client 发过来的 ack ；&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;1 ：如果全连接队列满了，server 发送一个 &lt;code&gt;reset&lt;/code&gt; 包给 client，表示废掉这个握手过程和这个连接；&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;如果要想知道客户端连接不上服务端，是不是服务端 TCP 全连接队列满的原因，那么可以把 tcp_abort_on_overflow 设置为 1，这时如果在客户端异常中可以看到很多 &lt;code&gt;connection reset by peer&lt;/code&gt; 的错误，那么就可以证明是由于服务端 TCP 全连接队列溢出的问题。&lt;/p&gt;
&lt;p&gt;通常情况下，应当把 tcp_abort_on_overflow 设置为 0，因为这样更有利于应对突发流量。&lt;/p&gt;
&lt;p&gt;举个例子，当 TCP 全连接队列满导致服务器丢掉了 ACK，与此同时，客户端的连接状态却是 ESTABLISHED，进程就在建立好的连接上发送请求。只要服务器没有为请求回复 ACK，请求就会被多次&lt;strong&gt;重发&lt;/strong&gt;。如果服务器上的进程只是&lt;strong&gt;短暂的繁忙造成 accept 队列满，那么当 TCP 全连接队列有空位时，再次接收到的请求报文由于含有 ACK，仍然会触发服务器端成功建立连接。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;所以，tcp_abort_on_overflow 设为 0 可以提高连接建立的成功率，只有你非常肯定 TCP 全连接队列会长期溢出时，才能设置为 1 以尽快通知客户端。&lt;/p&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;如何增大 TCP 全连接队列呢？&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;是的，当发现 TCP 全连接队列发生溢出的时候，我们就需要增大该队列的大小，以便可以应对客户端大量的请求。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;TCP 全连接队列足最大值取决于 somaxconn 和 backlog 之间的最小值，也就是 min(somaxconn, backlog)&lt;/strong&gt;。从下面的 Linux 内核代码可以得知：&lt;/p&gt;
&lt;img title=&quot;&quot; src=&quot;https://imgkr.cn-bj.ufileos.com/18a6c99b-40ce-49c9-8686-9731747563d6.png&quot; alt=&quot;&quot;/&gt;&lt;ul&gt;&lt;li&gt;&lt;code&gt;somaxconn&lt;/code&gt; 是 Linux 内核的参数，默认值是 128，可以通过 &lt;code&gt;/proc/sys/net/core/somaxconn&lt;/code&gt; 来设置其值；&lt;/li&gt;
&lt;li&gt;&lt;code&gt;backlog&lt;/code&gt; 是 &lt;code&gt;listen(int sockfd, int backlog)&lt;/code&gt; 函数中的 backlog 大小，Nginx 默认值是 511，可以通过修改配置文件设置其长度；&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;前面模拟测试中，我的测试环境：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;span&gt;somaxconn 是默认值 128；&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span&gt;Nginx 的 backlog 是默认值 511&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;所以测试环境的 TCP 全连接队列最大值为 min(128, 511)，也就是 &lt;code&gt;128&lt;/code&gt;，可以执行 &lt;code&gt;ss&lt;/code&gt; 命令查看：&lt;/p&gt;
&lt;img title=&quot;&quot; src=&quot;https://imgkr.cn-bj.ufileos.com/4415889d-50e6-4db5-a4e5-2f8ff818aca9.png&quot; alt=&quot;&quot;/&gt;&lt;p&gt;现在我们重新压测，把 TCP 全连接队列&lt;strong&gt;搞大&lt;/strong&gt;，把 &lt;code&gt;somaxconn&lt;/code&gt; 设置成 5000：&lt;/p&gt;
&lt;img title=&quot;&quot; src=&quot;https://imgkr.cn-bj.ufileos.com/6f35fac4-dc59-4123-bad3-79491f1fd819.png&quot; alt=&quot;&quot;/&gt;&lt;p&gt;接着把 Nginx 的 backlog 也同样设置成 5000：&lt;/p&gt;
&lt;img title=&quot;&quot; src=&quot;https://imgkr.cn-bj.ufileos.com/880facf1-69ae-46a0-953b-5a6e58e0883b.png&quot; alt=&quot;&quot;/&gt;&lt;p&gt;最后要重启 Nginx 服务，因为只有重新调用 &lt;code&gt;listen()&lt;/code&gt; 函数 TCP 全连接队列才会重新初始化。&lt;/p&gt;
&lt;p&gt;重启完后 Nginx 服务后，服务端执行 ss 命令，查看 TCP 全连接队列大小：&lt;/p&gt;
&lt;img title=&quot;&quot; src=&quot;https://imgkr.cn-bj.ufileos.com/99bcb281-ea8e-414a-b440-e6826e3a779f.png&quot; alt=&quot;&quot;/&gt;&lt;p&gt;从执行结果，可以发现 TCP 全连接最大值为 5000。&lt;/p&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;增大 TCP 全连接队列后，继续压测&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;客户端同样以 3 万个连接并发发送请求给服务端：&lt;/p&gt;
&lt;img title=&quot;&quot; src=&quot;https://imgkr.cn-bj.ufileos.com/fd4897e4-5d31-407e-9447-65d5cf8abed3.png&quot; alt=&quot;&quot;/&gt;&lt;p&gt;服务端执行 &lt;code&gt;ss&lt;/code&gt; 命令，查看 TCP 全连接队列使用情况：&lt;/p&gt;
&lt;img title=&quot;&quot; src=&quot;https://imgkr.cn-bj.ufileos.com/8239acb1-95f4-45c5-90d7-a5bb8cb44255.png&quot; alt=&quot;&quot;/&gt;&lt;p&gt;从上面的执行结果，可以发现全连接队列使用增长的很快，但是一直都没有超过最大值，所以就不会溢出，那么 &lt;code&gt;netstat -s&lt;/code&gt; 就不会有 TCP 全连接队列溢出个数的显示：&lt;/p&gt;
&lt;img title=&quot;&quot; src=&quot;https://imgkr.cn-bj.ufileos.com/88ae59fb-27b6-40c7-b567-2d4f1ef5451d.png&quot; alt=&quot;&quot;/&gt;&lt;p&gt;说明 TCP 全连接队列最大值从 128 增大到 5000 后，服务端抗住了 3 万连接并发请求，也没有发生全连接队列溢出的现象了。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;如果持续不断地有连接因为 TCP 全连接队列溢出被丢弃，就应该调大 backlog 以及 somaxconn 参数。&lt;/strong&gt;&lt;/p&gt;
&lt;hr/&gt;&lt;h3 id=&quot;htcp-2&quot;&gt;&lt;span&gt;实战 - TCP 半连接队列溢出&lt;/span&gt;&lt;/h3&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;如何查看 TCP 半连接队列长度？&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;很遗憾，TCP 半连接队列长度的长度，没有像全连接队列那样可以用 ss 命令查看。&lt;/p&gt;
&lt;p&gt;但是我们可以抓住 TCP 半连接的特点，就是服务端处于 &lt;code&gt;SYN_RECV&lt;/code&gt; 状态的 TCP 连接，就是在 TCP 半连接队列。&lt;/p&gt;
&lt;p&gt;于是，我们可以使用如下命令计算当前 TCP 半连接队列长度：&lt;/p&gt;
&lt;img title=&quot;&quot; src=&quot;https://imgkr.cn-bj.ufileos.com/eac839c7-6325-4fcb-885e-673da156e6c3.png&quot; alt=&quot;&quot;/&gt;&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;如何模拟 TCP 半连接队列溢出场景？&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;模拟 TCP 半连接溢出场景不难，实际上就是对服务端一直发送 TCP SYN 包，但是不回第三次握手 ACK，这样就会使得服务端有大量的处于 &lt;code&gt;SYN_RECV&lt;/code&gt; 状态的 TCP 连接。&lt;/p&gt;
&lt;p&gt;这其实也就是所谓的 SYN 洪泛、SYN 攻击、DDos 攻击。&lt;/p&gt;
&lt;img title=&quot;测试环境&quot; src=&quot;https://imgkr.cn-bj.ufileos.com/6f760794-2964-4f60-af2d-afa686edadd5.png&quot; alt=&quot;测试环境&quot;/&gt;测试环境
&lt;p&gt;实验环境：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;span&gt;客户端和服务端都是 CentOs 6.5 ，Linux 内核版本 2.6.32&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span&gt;服务端 IP 192.168.3.200，客户端 IP 192.168.3.100&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span&gt;服务端是 Nginx 服务，端口为 8088&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;注意：本次模拟实验是没有开启 tcp_syncookies，关于 tcp_syncookies 的作用，后续会说明。&lt;/p&gt;
&lt;p&gt;本次实验使用 &lt;code&gt;hping3&lt;/code&gt; 工具模拟 SYN 攻击：&lt;/p&gt;
&lt;img title=&quot;&quot; src=&quot;https://imgkr.cn-bj.ufileos.com/7861ed17-5a0d-48b7-b27e-89074d813440.png&quot; alt=&quot;&quot;/&gt;&lt;p&gt;当服务端受到 SYN 攻击后，连接服务端 ssh 就会断开了，无法再连上。只能在服务端主机上执行查看当前 TCP 半连接队列大小：&lt;/p&gt;
&lt;img title=&quot;&quot; src=&quot;https://imgkr.cn-bj.ufileos.com/90e9aa9c-e1dc-4012-aa45-049085f01d81.png&quot; alt=&quot;&quot;/&gt;&lt;p&gt;同时，还可以通过 netstat -s 观察半连接队列溢出的情况：&lt;/p&gt;
&lt;img title=&quot;&quot; src=&quot;https://imgkr.cn-bj.ufileos.com/dc03c52b-29ed-4a77-965e-9edf8d2a3f22.png&quot; alt=&quot;&quot;/&gt;&lt;p&gt;上面输出的数值是&lt;strong&gt;累计值&lt;/strong&gt;，表示共有多少个 TCP 连接因为半连接队列溢出而被丢弃。&lt;strong&gt;隔几秒执行几次，如果有上升的趋势，说明当前存在半连接队列溢出的现象&lt;/strong&gt;。&lt;/p&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;大部分人都说 tcp_max_syn_backlog 是指定半连接队列的大小，是真的吗？&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;很遗憾，半连接队列的大小并不单单只跟 &lt;code&gt;tcp_max_syn_backlog&lt;/code&gt; 有关系。&lt;/p&gt;
&lt;p&gt;上面模拟 SYN 攻击场景时，服务端的 tcp_max_syn_backlog 的默认值如下：&lt;/p&gt;
&lt;img title=&quot;&quot; src=&quot;https://imgkr.cn-bj.ufileos.com/c1f4d40a-6889-461b-b92b-fc3e5cee06d0.png&quot; alt=&quot;&quot;/&gt;&lt;p&gt;但是在测试的时候发现，服务端最多只有 256 个半连接队列，而不是 512，所以&lt;strong&gt;半连接队列的最大长度不一定由 tcp_max_syn_backlog 值决定的&lt;/strong&gt;。&lt;/p&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;接下来，走进 Linux 内核的源码，来分析 TCP 半连接队列的最大值是如何决定的。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;TCP 第一次握手（收到 SYN 包）的 Linux 内核代码如下，其中缩减了大量的代码，只需要重点关注 TCP 半连接队列溢出的处理逻辑：&lt;/p&gt;
&lt;img title=&quot;&quot; src=&quot;https://imgkr.cn-bj.ufileos.com/b272f1b9-fac2-4288-b07b-b799afcfb8d4.png&quot; alt=&quot;&quot;/&gt;&lt;p&gt;从源码中，我可以得出共有三个条件因队列长度的关系而被丢弃的：&lt;/p&gt;
&lt;img title=&quot;&quot; src=&quot;https://imgkr.cn-bj.ufileos.com/18481a31-9252-4fcc-b6b2-326d2daed0df.png&quot; alt=&quot;&quot;/&gt;&lt;ol&gt;&lt;li&gt;&lt;strong&gt;如果半连接队列满了，并且没有开启 tcp_syncookies，则会丢弃；&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;若全连接队列满了，且没有重传 SYN+ACK 包的连接请求多于 1 个，则会丢弃；&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;如果没有开启 tcp_syncookies，并且 max_syn_backlog 减去 当前半连接队列长度小于 (max_syn_backlog &amp;gt;&amp;gt; 2)，则会丢弃；&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;关于 tcp_syncookies 的设置，后面在详细说明，可以先给大家说一下，开启 tcp_syncookies 是缓解 SYN 攻击其中一个手段。&lt;/p&gt;
&lt;p&gt;接下来，我们继续跟一下检测半连接队列是否满的函数 inet_csk_reqsk_queue_is_full 和 检测全连接队列是否满的函数 sk_acceptq_is_full ：&lt;/p&gt;
&lt;img title=&quot;&quot; src=&quot;https://imgkr.cn-bj.ufileos.com/536f7465-c1af-48ce-82a1-f489687cc15c.png&quot; alt=&quot;&quot;/&gt;&lt;p&gt;从上面源码，可以得知：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;全&lt;/strong&gt;连接队列的最大值是 &lt;code&gt;sk_max_ack_backlog&lt;/code&gt; 变量，sk_max_ack_backlog 实际上是在 listen() 源码里指定的，也就是 &lt;strong&gt;min(somaxconn, backlog)&lt;/strong&gt;；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;半&lt;/strong&gt;连接队列的最大值是 &lt;code&gt;max_qlen_log&lt;/code&gt; 变量，max_qlen_log 是在哪指定的呢？现在暂时还不知道，我们继续跟进；&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;我们继续跟进代码，看一下是哪里初始化了半连接队列的最大值 max_qlen_log：&lt;/p&gt;
&lt;img title=&quot;&quot; src=&quot;https://imgkr.cn-bj.ufileos.com/e8385a98-5acb-40f5-968b-eb5124ec60d5.png&quot; alt=&quot;&quot;/&gt;&lt;p&gt;从上面的代码中，我们可以算出 max_qlen_log 是 8，于是代入到 检测半连接队列是否满的函数 reqsk_queue_is_full ：&lt;/p&gt;
&lt;img title=&quot;&quot; src=&quot;https://imgkr.cn-bj.ufileos.com/5b759d77-6e49-4778-a706-0d9d4b000624.png&quot; alt=&quot;&quot;/&gt;&lt;p&gt;也就是 &lt;code&gt;qlen &amp;gt;&amp;gt; 8&lt;/code&gt; 什么时候为 1 就代表半连接队列满了。这计算这不难，很明显是当 qlen 为 256 时，&lt;code&gt;256 &amp;gt;&amp;gt; 8 = 1&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;至此，总算知道为什么上面模拟测试 SYN 攻击的时候，服务端处于 &lt;code&gt;SYN_RECV&lt;/code&gt; 连接最大只有 256 个。&lt;/p&gt;
&lt;p&gt;可见，&lt;strong&gt;半连接队列最大值不是单单由 max_syn_backlog 决定，还跟 somaxconn 和 backlog 有关系。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;在 Linux 2.6.32 内核版本，它们之间的关系，总体可以概况为：&lt;/p&gt;
&lt;img title=&quot;&quot; src=&quot;https://imgkr.cn-bj.ufileos.com/1c04a5d9-cfbf-4a02-8730-af8bbcaf929c.png&quot; alt=&quot;&quot;/&gt;&lt;ul&gt;&lt;li&gt;&lt;span&gt;当 max_syn_backlog &amp;gt; min(somaxconn, backlog) 时， 半连接队列最大值 max_qlen_log = min(somaxconn, backlog) * 2;&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span&gt;当 max_syn_backlog &amp;lt; min(somaxconn, backlog) 时， 半连接队列最大值 max_qlen_log = max_syn_backlog * 2;&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;半连接队列最大值 max_qlen_log 就表示服务端处于 SYN_REVC 状态的最大个数吗？&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;依然很遗憾，并不是。&lt;/p&gt;
&lt;p&gt;max_qlen_log 是&lt;strong&gt;理论&lt;/strong&gt;半连接队列最大值，并不一定代表服务端处于 SYN_REVC 状态的最大个数。&lt;/p&gt;
&lt;p&gt;在前面我们在分析 TCP 第一次握手（收到 SYN 包）时会被丢弃的三种条件：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;&lt;span&gt;如果半连接队列满了，并且没有开启 tcp_syncookies，则会丢弃；&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span&gt;若全连接队列满了，且没有重传 SYN+ACK 包的连接请求多于 1 个，则会丢弃；&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;如果没有开启 tcp_syncookies，并且 max_syn_backlog 减去 当前半连接队列长度小于 (max_syn_backlog &amp;gt;&amp;gt; 2)，则会丢弃；&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;假设条件 1 当前半连接队列的长度 「没有超过」理论的半连接队列最大值 max_qlen_log，那么如果条件 3 成立，则依然会丢弃 SYN 包，也就会使得服务端处于 SYN_REVC 状态的最大个数不会是理论值 max_qlen_log。&lt;/p&gt;
&lt;p&gt;似乎很难理解，我们继续接着做实验，实验见真知。&lt;/p&gt;
&lt;p&gt;服务端环境如下：&lt;/p&gt;
&lt;img title=&quot;&quot; src=&quot;https://imgkr.cn-bj.ufileos.com/4685c08f-ac0e-4f8d-b87a-97102ec96b75.png&quot; alt=&quot;&quot;/&gt;&lt;p&gt;配置完后，服务端要重启 Nginx，因为全连接队列最大和半连接队列最大值是在 listen() 函数初始化。&lt;/p&gt;
&lt;p&gt;根据前面的源码分析，我们可以计算出半连接队列 max_qlen_log 的最大值为 256：&lt;/p&gt;
&lt;img title=&quot;&quot; src=&quot;https://imgkr.cn-bj.ufileos.com/5b8b6295-46f6-48c4-b58d-6494f742475f.png&quot; alt=&quot;&quot;/&gt;&lt;p&gt;客户端执行 hping3 发起 SYN 攻击：&lt;/p&gt;
&lt;img title=&quot;&quot; src=&quot;https://imgkr.cn-bj.ufileos.com/0f582a66-3030-4a04-b529-8377f2156bb5.png&quot; alt=&quot;&quot;/&gt;&lt;p&gt;服务端执行如下命令，查看处于 SYN_RECV 状态的最大个数：&lt;/p&gt;
&lt;img title=&quot;&quot; src=&quot;https://imgkr.cn-bj.ufileos.com/70810025-a971-42c3-ad96-baa2a5d368f3.png&quot; alt=&quot;&quot;/&gt;&lt;p&gt;可以发现，服务端处于 SYN_RECV 状态的最大个数并不是 max_qlen_log 变量的值。&lt;/p&gt;
&lt;p&gt;这就是前面所说的原因：&lt;strong&gt;如果当前半连接队列的长度 「没有超过」理论半连接队列最大值 max_qlen_log，那么如果条件 3 成立，则依然会丢弃 SYN 包，也就会使得服务端处于 SYN_REVC 状态的最大个数不会是理论值 max_qlen_log。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;我们来分析一波条件 3 :&lt;/p&gt;
&lt;img title=&quot;&quot; src=&quot;https://imgkr.cn-bj.ufileos.com/d85c0015-4a38-439d-8926-331c768eebd9.png&quot; alt=&quot;&quot;/&gt;&lt;p&gt;从上面的分析，可以得知如果触发「当前半连接队列长度 &amp;gt; 192」条件，TCP 第一次握手的 SYN 包是会被丢弃的。&lt;/p&gt;
&lt;p&gt;在前面我们测试的结果，服务端处于 SYN_RECV 状态的最大个数是 193，正好是触发了条件 3，所以处于 SYN_RECV 状态的个数还没到「理论半连接队列最大值 256」，就已经把 SYN 包丢弃了。&lt;/p&gt;
&lt;p&gt;所以，服务端处于 SYN_RECV 状态的最大个数分为如下两种情况：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;如果「当前半连接队列」&lt;strong&gt;没超过&lt;/strong&gt;「理论半连接队列最大值」，但是&lt;strong&gt;超过&lt;/strong&gt; max_syn_backlog - (max_syn_backlog &amp;gt;&amp;gt; 2)，那么处于 SYN_RECV 状态的最大个数就是 max_syn_backlog - (max_syn_backlog &amp;gt;&amp;gt; 2)；&lt;/li&gt;
&lt;li&gt;如果「当前半连接队列」&lt;strong&gt;超过&lt;/strong&gt;「理论半连接队列最大值」，那么处于 SYN_RECV 状态的最大个数就是「理论半连接队列最大值」；&lt;/li&gt;
&lt;/ul&gt;&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;每个 Linux 内核版本「理论」半连接最大值计算方式会不同。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;在上面我们是针对 Linux 2.6.32 版本分析的「理论」半连接最大值的算法，可能每个版本有些不同。&lt;/p&gt;
&lt;p&gt;比如在 Linux 5.0.0 的时候，「理论」半连接最大值就是全连接队列最大值，但依然还是有队列溢出的三个条件：&lt;/p&gt;
&lt;img title=&quot;&quot; src=&quot;https://imgkr.cn-bj.ufileos.com/58e3c3ef-ceb6-42da-882d-ec4ce7081d6d.png&quot; alt=&quot;&quot;/&gt;&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;如果 SYN 半连接队列已满，只能丢弃连接吗？&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;并不是这样，&lt;strong&gt;开启 syncookies 功能就可以在不使用 SYN 半连接队列的情况下成功建立连接&lt;/strong&gt;，在前面我们源码分析也可以看到这点，当开启了 syncookies 功能就不会丢弃连接。&lt;/p&gt;
&lt;p&gt;syncookies 是这么做的：服务器根据当前状态计算出一个值，放在己方发出的 SYN+ACK 报文中发出，当客户端返回 ACK 报文时，取出该值验证，如果合法，就认为连接建立成功，如下图所示。&lt;/p&gt;
&lt;img title=&quot;开启 syncookies 功能&quot; src=&quot;https://imgkr.cn-bj.ufileos.com/28a6ced8-7e3d-4de8-87b3-11139f9af380.png&quot; alt=&quot;开启 syncookies 功能&quot;/&gt;开启 syncookies 功能
&lt;p&gt;syncookies 参数主要有以下三个值：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;span&gt;0 值，表示关闭该功能；&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span&gt;1 值，表示仅当 SYN 半连接队列放不下时，再启用它；&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span&gt;2 值，表示无条件开启功能；&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;那么在应对 SYN 攻击时，只需要设置为 1 即可：&lt;/p&gt;
&lt;img title=&quot;&quot; src=&quot;https://imgkr.cn-bj.ufileos.com/bf3d0431-29ef-46e0-be15-216593fd04c1.png&quot; alt=&quot;&quot;/&gt;&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;如何防御 SYN 攻击？&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;这里给出几种防御 SYN 攻击的方法：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;span&gt;增大半连接队列；&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span&gt;开启 tcp_syncookies 功能&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span&gt;减少 SYN+ACK 重传次数&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;em&gt;方式一：增大半连接队列&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;在前面源码和实验中，得知&lt;strong&gt;要想增大半连接队列，我们得知不能只单纯增大 tcp_max_syn_backlog 的值，还需一同增大 somaxconn 和 backlog，也就是增大全连接队列&lt;/strong&gt;。否则，只单纯增大 tcp_max_syn_backlog 是无效的。&lt;/p&gt;
&lt;p&gt;增大 tcp_max_syn_backlog 和 somaxconn 的方法是修改 Linux 内核参数：&lt;/p&gt;
&lt;img title=&quot;&quot; src=&quot;https://imgkr.cn-bj.ufileos.com/badba1bf-692f-43dc-9ac7-3042f0bbee61.png&quot; alt=&quot;&quot;/&gt;&lt;p&gt;增大 backlog 的方式，每个 Web 服务都不同，比如 Nginx 增大 backlog 的方法如下：&lt;/p&gt;
&lt;img title=&quot;&quot; src=&quot;https://imgkr.cn-bj.ufileos.com/02d8b91e-fef9-4c31-bb0e-d69ed60df18f.png&quot; alt=&quot;&quot;/&gt;&lt;p&gt;最后，改变了如上这些参数后，要重启 Nginx 服务，因为半连接队列和全连接队列都是在 listen() 初始化的。&lt;/p&gt;
&lt;p&gt;&lt;em&gt;方式二：开启 tcp_syncookies 功能&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;开启 tcp_syncookies 功能的方式也很简单，修改 Linux 内核参数：&lt;/p&gt;
&lt;img title=&quot;&quot; src=&quot;https://imgkr.cn-bj.ufileos.com/bf3d0431-29ef-46e0-be15-216593fd04c1.png&quot; alt=&quot;&quot;/&gt;&lt;p&gt;&lt;em&gt;方式三：减少 SYN+ACK 重传次数&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;当服务端受到 SYN 攻击时，就会有大量处于 SYN_REVC 状态的 TCP 连接，处于这个状态的 TCP 会重传 SYN+ACK ，当重传超过次数达到上限后，就会断开连接。&lt;/p&gt;
&lt;p&gt;那么针对 SYN 攻击的场景，我们可以减少 SYN+ACK 的重传次数，以加快处于 SYN_REVC 状态的 TCP 连接断开。&lt;/p&gt;
&lt;img title=&quot;&quot; src=&quot;https://imgkr.cn-bj.ufileos.com/cccd22b4-e4ad-44bf-a366-a0847d55e29c.png&quot; alt=&quot;&quot;/&gt;&lt;hr/&gt;&lt;h5 id=&quot;h-2&quot;&gt;&lt;span&gt;巨人的肩膀&lt;/span&gt;&lt;/h5&gt;
&lt;p&gt;[1] 系统性能调优必知必会.陶辉.极客时间.&lt;/p&gt;
&lt;p&gt;[2] https://www.cnblogs.com/zengkefu/p/5606696.html&lt;/p&gt;
&lt;p&gt;[3] https://blog.cloudflare.com/syn-packet-handling-in-the-wild/&lt;/p&gt;
&lt;hr/&gt;&lt;img title=&quot;&quot; src=&quot;https://imgkr.cn-bj.ufileos.com/4d25725d-c42a-40ee-a4b1-723dbc520a53.png&quot; alt=&quot;&quot;/&gt;&lt;p&gt;&lt;strong&gt;小林是专为大家图解的工具人，Goodbye，我们下次见！&lt;/strong&gt;&lt;/p&gt;
</description>
<pubDate>Sat, 30 May 2020 14:30:00 +0000</pubDate>
<dc:creator>小林coding</dc:creator>
<og:description>前言 网上许多博客针对增大 TCP 半连接队列和全连接队列的方式如下： 增大 TCP 半连接队列的方式是增大 /proc/sys/net/ipv4/tcp_max_syn_backlog； 增大 TC</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/xiaolincoding/p/12995358.html</dc:identifier>
</item>
</channel>
</rss>