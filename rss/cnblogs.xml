<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="css/feed.xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/" xmlns:og="http://ogp.me/ns#">
<channel>
<atom:link rel="self" href="http://192.168.1.4/fivefilters/makefulltextfeed.php?url=feed.cnblogs.com%2Fblog%2Fsitehome%2Frss&amp;max=10&amp;links=preserve&amp;exc=" />
<atom:link rel="alternate" title="Source URL" href="http://feed.cnblogs.com/blog/sitehome/rss" />
<atom:link rel="related" title="Subscribe to feed" href="http://www.subtome.com/#/subscribe?feeds=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed.cnblogs.com%252Fblog%252Fsitehome%252Frss%26max%3D10%26links%3Dpreserve%26exc%3D&amp;back=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed.cnblogs.com%252Fblog%252Fsitehome%252Frss%26max%3D10%26links%3Dpreserve%26exc%3D" />
<title>博客园_首页</title>
<link></link>
<description>代码改变世界</description>
<item>
<title>深度学习中的batch_size,iterations,epochs等概念的理解 - 控球强迫症</title>
<link>http://www.cnblogs.com/XDU-Lakers/p/10607358.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/XDU-Lakers/p/10607358.html</guid>
<description>&lt;p&gt;&lt;span&gt;在自己完成的几个有关深度学习的Demo中，几乎都出现了batch_size,iterations,epochs这些字眼，刚开始我也没在意，觉得Demo能运行就OK了，但随着学习的深入，我就觉得不弄懂这几个基本的概念，对整个深度学习框架理解的自然就不够透彻，所以今天让我们一起了解一下这三个概念。&lt;/span&gt;&lt;/p&gt;
&lt;hr/&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;1.batch_size&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;深度学习的优化算法，用大白话来说其实主要就是梯度下降算法，而每次的参数权重更新主要有两种方法。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;（1）遍历全部数据集算一次损失函数，然后算函数对各个参数的梯度，更新梯度&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;这种方法每更新一次参数都要把数据集里的所有样本都看一遍，计算量开销大，计算速度慢，不支持在线学习，这称为Batch gradient descent，批梯度下降。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;（2）stochastic gradient descent&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;每看一个数据就算一下损失函数，然后求梯度更新参数，这个称为随机梯度下降。这个方法速度比较快，但是收敛性能不太好，可能在最优点附近晃来晃去，hit不到最优点。两次参数的更新也有可能互相抵消掉，造成目标函数震荡的比较剧烈。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;为了克服两种方法的缺点，现在一般采用的是一种折中手段，mini-batch gradient decent，小批的梯度下降，这种方法把数据分为若干个批，按批来更新参数，这样，一个批中的一组数据共同决定了本次梯度的方向，下降起来就不容易跑偏，减少了随机性。另一方面因为批的样本数与整个数据&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;集相比小了很多，计算量也不是很大。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;基本上现在的梯度下降都是基于mini-batch的，所以深度学习框架的函数中经常会出现batch_size，就是指这个意思。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;span&gt;2.iterations&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;iterations（迭代）：每一次迭代都是一次权重更新，每一次权重更新需要batch_size个数据进行Forward运算得到损失函数，再BP算法(反向传播算法)更新参数。1个iteration等于使用batchsize个样本训练一次。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;3.epochs&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;epochs被定义为向前和向后传播中所有批次的单次训练迭代。这意味着1个周期是整个输入数据的单次向前和向后传递。简单说，epochs指的就是训练过程中数据将被“轮”多少次，就这样。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;接下来让我们看个例子：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;假设&lt;/span&gt;&lt;span&gt;训练集有1000个样本，batchsize=10，&lt;/span&gt;&lt;span&gt;那么： &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;训练完整个样本集需要： &lt;/span&gt;&lt;span&gt;100次iteration，1次epoch。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;具体的计算公式为： &lt;/span&gt;&lt;span&gt;one epoch = numbers of iterations = N = 训练样本的数量/batch_size&lt;/span&gt;&lt;/p&gt;

</description>
<pubDate>Wed, 27 Mar 2019 06:36:00 +0000</pubDate>
<dc:creator>控球强迫症</dc:creator>
<og:description>在自己完成的几个有关深度学习的Demo中，几乎都出现了batch_size,iterations,epochs这些字眼，刚开始我也没在意，觉得Demo能运行就OK了，但随着学习的深入，我就觉得不弄懂这</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/XDU-Lakers/p/10607358.html</dc:identifier>
</item>
<item>
<title>我眼中的 Nginx（五）：Nginx — 子请求设计之道 - 又拍云</title>
<link>http://www.cnblogs.com/upyun/p/10607346.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/upyun/p/10607346.html</guid>
<description>&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;张超：又拍云系统开发高级工程师，负责又拍云 CDN 平台相关组件的更新及维护。Github ID: tokers，活跃于 OpenResty 社区和 Nginx 邮件列表等开源社区，专注于服务端技术的研究；曾为 ngx_lua 贡献源码，在 Nginx、ngx_lua、CDN 性能优化、日志优化方面有较为深入的研究。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2&gt;子请求、父请求和主请求&lt;/h2&gt;
&lt;p&gt;Nginx 所处理的大部分请求，都是在接收到客户端发来的 HTTP 请求报文后创建的，这些请求直接与客户端打交道，称之为主请求；与之相对的则是子请求，顾名思义，子请求是由另外的请求创建的，比如主请求（当然子请求本身也可以创建子请求），当一个请求创建一个子请求后，它就成了该子请求的父请求。从源码层面来说，当前请求的主请求通过 r-&amp;gt;main 指针获取，父请求则通过 r-&amp;gt;parent 指针获取。&lt;/p&gt;
&lt;p&gt;使用子请求机制的意义在于，它能够分散原本集中在单个请求里的处理逻辑，简化任务，大大降低请求的复杂度。例如当既需要访问一个 MySQL 集群，又需要访问一个 Redis 集群时，我们就可以分别创建一个子请求负责和 MySQL 的交互，另外一个负责和 Redis 的交互，简化主请求的业务复杂度。而且创建子请求的过程不涉及任何的网络 I/O，仅仅是一些内存的分配，其代价非常可控，因此在笔者看来，子请求机制是 Nginx 里最为巧妙的设计之一。&lt;/p&gt;
&lt;h2&gt;子请求创建与驱动&lt;/h2&gt;
&lt;p&gt;通常需要创建子请求时，模块开发者们可以调用函数 ngx_http_subrequest 来实现，默认情况下，子请求会共享父请求的内存池，变量缓存，下游连接和 HTTP 请求头等数据。当子请求创建完毕后，它会被挂到 r-&amp;gt;main-&amp;gt;posted_requests 链表上，这个链表用以保存需要延迟处理的请求（不局限于子请求）。因此子请求会在父请求本地调度完毕后得到运行的机会，这通常是子请求获得首次运行机会的手段。&lt;/p&gt;
&lt;p&gt;我们知道 Nginx 针对一个 HTTP 请求，将其处理逻辑分别划分到了 11 个不同的阶段。当一个子请求被创建出来后，它首先运行的是 find config 阶段，即寻找一个合适的 location，然后开始后续的逻辑处理。通常，如果一个子请求不涉及任何的网络 I/O 操作，或者定时器处理，一次调度即可完成当前的子请求；而如果子请求需要处理一些网络、定时器事件，那么后续该子请求的调度，都会由这些事件来驱动，这使得它的调度和普通的主请求变得无差别。&lt;/p&gt;
&lt;p&gt;既然除第一次外，子请求的驱动可能是由网络事件来驱动的，那么子请求的调度就是乱序的了。假设当前主请求需要向后端请求一个大小 2MB 的资源，我们通过产生两个子请求，分别获取 0-1MB 和 1MB - 2MB 的部分，然后发往下游，因为网络的不确定性，很有可能后者（1MB - 2MB）先获取到并往下游传输。那么此时下游所得到的数据就成了脏数据了。&lt;/p&gt;
&lt;p&gt;为了解决这个问题，Nginx 为子请求机制引入了另外一个称为 postpone_filter 的模块。该模块的目的在于，判断当前准备发送数据的请求，是否是“活跃的”，如果当前请求不是“活跃”的，则它期望发送的数据会被暂时保存起来，直到某一刻它“活跃”了，才能将这些数据发往下游。&lt;/p&gt;
&lt;p&gt;怎么判断一个请求是否是“活跃”的？我们需要先了解父、子请求之间的保存形式。对于当前请求，它的子请求以链表的方式被维护起来，而前面提到，子请求也可以创建子请求，因此这些请求间完整的保存形式可以理解成一颗分层树，如下图所示。&lt;/p&gt;
&lt;div class=&quot;image-package&quot;&gt;
&lt;div class=&quot;image-container&quot;&gt;

&lt;div class=&quot;image-view&quot; data-width=&quot;1280&quot; data-height=&quot;1657&quot;&gt;&lt;img src=&quot;https://upload-images.jianshu.io/upload_images/80097-f43e9e9d44ed2dfa.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1000/format/webp&quot; alt=&quot;&quot; width=&quot;588&quot; height=&quot;762&quot; data-original-src=&quot;//upload-images.jianshu.io/upload_images/80097-f43e9e9d44ed2dfa.png&quot; data-original-width=&quot;1280&quot; data-original-height=&quot;1657&quot; data-original-format=&quot;image/png&quot; data-original-filesize=&quot;590204&quot;/&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;上图中，每个红圈表示一个请求，每一层的请求分别是上一层请求的子请求。从树遍历的角度讲，在这样一棵树上，哪个节点应该最先被处理？结合子请求机制的实际意义来分析，子请求是为了分摊父请求的处理逻辑，降低业务复杂度。换而言之，父请求是依赖于子请求的。很大程度上父请求可能需要等到当前子请求运行完毕后根据子请求反馈的结果来做一些收尾工作。所以需要采用的是类似后序遍历的规则。即上图最右下角的请求是第一个“活跃”的请求。&lt;/p&gt;
&lt;p&gt;从源码层面来说，这颗分层树的保存用到了两个数据结构，r-&amp;gt;postponed 和 r-&amp;gt;parent这两个指针，遍历 r-&amp;gt;postponed 来按序访问当前请求的子请求（树中同层的兄弟节点）；遍历 r-&amp;gt;parent 访问到父请求（树中上一层的父节点）。&lt;/p&gt;
&lt;p&gt;postpone_filter 模块会判断当前请求是否“活跃”，如果不“活跃”，则把将要发送的数据临时拦截到它自己的 r-&amp;gt;postponed链表上（所以这个链表上其实既有数据也有请求）；如果是活跃的，则遍历它的 r-&amp;gt;postponed 链表，要么把被临时拦截下来的数据发送出去，要么找到第一个子请求，将其标记为 “活跃”，然后返回。等到该子请求处理结束，重新将其父请求标记为“活跃”，这样一来，当父请求再一次运行到 postpone_filter 模块的时候，又可以遍历 r-&amp;gt;postponed 链表，循环往复直到所有请求或者数据处理完毕。感兴趣的同学可以自行阅读相关源码（&lt;a href=&quot;https://links.jianshu.com/go?to=https%3A%2F%2Flink.zhihu.com%2F%3Ftarget%3Dhttp%253A%2F%2Fhg.nginx.org%2Fnginx%2Ffile%2Ftip%2Fsrc%2Fhttp%2Fngx_http_postpone_filter_module.c&quot; rel=&quot;nofollow&quot; target=&quot;_blank&quot;&gt;http://hg.nginx.org/nginx/file/tip/src/http/ngx_http_postpone_filter_module.c&lt;/a&gt;）。&lt;/p&gt;
&lt;h2&gt;使用了子请求机制的模块&lt;/h2&gt;
&lt;p&gt;目前整个 Nginx 生态圈，有很多使用子请求的例子，最著名的便是 ngx_lua 的子请求和 Nginx 官方的 slice_filter 模块了。&lt;/p&gt;
&lt;p&gt;ngx_lua 提供给用户的 API （ngx.location.capture）灵活性非常大。 包括针对是否共享变量也可自行选择。特别地，ngx_lua 的子请求运行时，会阻塞父请求（挂起其对应的 Lua 协程）。直到子请求运行完毕，子请求的响应头、响应体（所以如果响应体比较大，则会消耗很多内存）等信息都会返回给父请求。ngx_lua 的子请求是不经过 postpone_filter模块的，它在一个较早的 filter 模块（ngx_http_lua_capture_filter） 里就完成了对子请求响应体的拦截。&lt;/p&gt;
&lt;p&gt;Nginx 官方提供的 slice_filter模块，可以将一个资源下载，拆分成若干个 HTTP Range 请求，这样做最大的好处是分散热点。这个模块允许我们设置一个指令 slice_size，用以设置后续 Range 请求的区间大小。该模块会陆续创建子请求（在前一个完成后），直到所需资源下载完毕。&lt;/p&gt;
&lt;p&gt;另外， Nginx/1.13.1 也引入了一个称为 Background subrequests 的机制（用以更新缓存）。基于这个机制，Nginx/1.13.4 引入了一个 mirror 模块，通过创建子请求，可以让用户自定义一些后台任务。比如预热一些资源，直接将它们放入 Nginx 自身的 proxy_cache 缓存中。&lt;/p&gt;
&lt;h2&gt;陷阱与缺陷&lt;/h2&gt;
&lt;p&gt;前文说到，子请求创建出来时，复用了父请求的一些数据，这无形中引入了一些坑点。&lt;/p&gt;
&lt;p&gt;比如变量缓存，如果在子请求中访问并缓存了某个变量，当后续在父请求中使用时，我们就会得到之前的缓存数据，这可能造成工程师们花费大量的时间和精力去调试这个问题。&lt;/p&gt;
&lt;p&gt;另外笔者认为一个非常重大的缺陷是，子请求复用了父请求的内存池，以 slice_filter 模块举例，它将一个 HTTP 请求划分成若干个的子请求，每个子请求向后端发起 HTTP Range 请求，在资源非常大 ，而配置的 slice_size 相对比较小的时候，会造成有大量的子请求的创建，整个资源下载过程可能会持续很长一段时间，这导致父请求的内存池在一段时间内没有释放，加之如果并发数比较大，可能会造成进程内存使用率变得很高，严重时可能会 OOM，影响到服务。因此在考虑使用的时候，需要权衡这些问题，有必要的话可能需要自行修改源码，以满足业务上的需要。&lt;/p&gt;
&lt;p&gt;虽然一些缺点是在所难免的，但是子请求机制很大程度上简化了请求的处理逻辑，它分而治之的处理思想非常值得我们去学习和借鉴，无论如何，子请求机制也将是后续进行系统设计时的一大参考范例。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;《我眼中的 Nginx》系列：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://links.jianshu.com/go?to=https%3A%2F%2Flink.zhihu.com%2F%3Ftarget%3Dhttps%253A%2F%2Ftech.upyun.com%2Farticle%2F378%2F%2525E6%252588%252591%2525E7%25259C%2525BC%2525E4%2525B8%2525AD%2525E7%25259A%252584%252520Nginx%2525EF%2525BC%252588%2525E4%2525B8%252580%2525EF%2525BC%252589%2525EF%2525BC%25259ANginx%252520%2525E5%252592%25258C%2525E4%2525BD%25258D%2525E8%2525BF%252590%2525E7%2525AE%252597.html&quot; rel=&quot;nofollow&quot; target=&quot;_blank&quot;&gt;我眼中的 Nginx（一）：Nginx 和位运算&lt;/a&gt;&lt;br/&gt;&lt;a href=&quot;https://links.jianshu.com/go?to=https%3A%2F%2Flink.zhihu.com%2F%3Ftarget%3Dhttps%253A%2F%2Ftech.upyun.com%2Farticle%2F381%2F%2525E6%252588%252591%2525E7%25259C%2525BC%2525E4%2525B8%2525AD%2525E7%25259A%252584%252520Nginx%2525EF%2525BC%252588%2525E4%2525BA%25258C%2525EF%2525BC%252589%2525EF%2525BC%25259AHTTP%25252F2%252520dynamic%252520table%252520size%252520update.html&quot; rel=&quot;nofollow&quot; target=&quot;_blank&quot;&gt;我眼中的 Nginx（二）：HTTP/2 dynamic table size update&lt;/a&gt;&lt;br/&gt;&lt;a href=&quot;https://links.jianshu.com/go?to=https%3A%2F%2Flink.zhihu.com%2F%3Ftarget%3Dhttps%253A%2F%2Ftech.upyun.com%2Farticle%2F383%2F%2525E6%252588%252591%2525E7%25259C%2525BC%2525E4%2525B8%2525AD%2525E7%25259A%252584%252520Nginx%2525EF%2525BC%252588%2525E4%2525B8%252589%2525EF%2525BC%252589%2525EF%2525BC%25259ANginx%252520%2525E5%25258F%252598%2525E9%252587%25258F%2525E5%252592%25258C%2525E5%25258F%252598%2525E9%252587%25258F%2525E6%25258F%252592%2525E5%252580%2525BC.html&quot; rel=&quot;nofollow&quot; target=&quot;_blank&quot;&gt;我眼中的 Nginx（三）：Nginx 变量和变量插值​&lt;/a&gt;&lt;br/&gt;&lt;a href=&quot;https://links.jianshu.com/go?to=https%3A%2F%2Flink.zhihu.com%2F%3Ftarget%3Dhttps%253A%2F%2Ftech.upyun.com%2Farticle%2F385%2F%2525E6%252588%252591%2525E7%25259C%2525BC%2525E4%2525B8%2525AD%2525E7%25259A%252584%252520Nginx%2525EF%2525BC%252588%2525E5%25259B%25259B%2525EF%2525BC%252589%2525EF%2525BC%25259A%2525E6%252598%2525AF%2525E4%2525BB%252580%2525E4%2525B9%252588%2525E8%2525AE%2525A9%2525E4%2525BD%2525A0%2525E7%25259A%252584%252520Nginx%252520%2525E6%25259C%25258D%2525E5%25258A%2525A1%2525E9%252580%252580%2525E5%252587%2525BA%2525E8%2525BF%252599%2525E4%2525B9%252588%2525E6%252585%2525A2%2525EF%2525BC%25259F.html&quot; rel=&quot;nofollow&quot; target=&quot;_blank&quot;&gt;我眼中的 Nginx（四）：是什么让你的 Nginx 服务退出这么慢？&lt;/a&gt;&lt;/p&gt;
</description>
<pubDate>Wed, 27 Mar 2019 06:35:00 +0000</pubDate>
<dc:creator>又拍云</dc:creator>
<og:description>张超：又拍云系统开发高级工程师，负责又拍云 CDN 平台相关组件的更新及维护。Github ID: tokers，活跃于 OpenResty 社区和 Nginx 邮件列表等开源社区，专注于服务端技术的</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/upyun/p/10607346.html</dc:identifier>
</item>
<item>
<title>ProxySQL 部署 Single Writer Failover 读写分离 (PXC) - 黑洞中的奇点</title>
<link>http://www.cnblogs.com/kelvin19840813/p/10607293.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/kelvin19840813/p/10607293.html</guid>
<description>


&lt;p&gt;主机信息:&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/992711/201903/992711-20190307182859865-1119640589.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;Proxysql:&lt;/p&gt;
&lt;p&gt;如果你忽略了ProxySQL会报告主机组的变化，我建议把它设置为0，除非你试图调试“某些东西”，否则你的日志将很快变得巨大。&lt;br/&gt;UPDATE global_variables SET Variable_Value=0 WHERE Variable_name='mysql-hostgroup_manager_verbose';&lt;/p&gt;
&lt;p&gt;在PXC 5.7添加proxysql监控用户:&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;32&quot;&gt;
&lt;pre&gt;
CREATE USER 'proxysql'@'%' IDENTIFIED BY 'proxysql'&lt;span&gt;;
GRANT USAGE ON *.* TO 'proxysql'@'%';&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;添加访问mysql用户配置&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;44&quot;&gt;
&lt;pre&gt;
INSERT INTO mysql_users (username,password,active,default_hostgroup,default_schema,transaction_persistent) VALUES ('proxysql','proxysql',1,50,'mysql',1&lt;span&gt;);
LOAD MYSQL USERS TO&lt;span&gt; RUNTIME;
SAVE MYSQL USERS TO DISK;&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;添加您的服务器：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;96&quot;&gt;
&lt;pre&gt;
INSERT INTO mysql_servers (hostname,hostgroup_id,port,weight,max_connections) VALUES ('10.1.1.11',50,3306,1000000,2000&lt;span&gt;);
INSERT INTO mysql_servers (hostname,hostgroup_id,port,weight,max_connections) VALUES ('10.1.1.11',52,3306,1,2000&lt;span&gt;);
INSERT INTO mysql_servers (hostname,hostgroup_id,port,weight,max_connections) VALUES ('10.1.1.11',8050,3306,1000000,2000&lt;span&gt;);

INSERT INTO mysql_servers (hostname,hostgroup_id,port,weight,max_connections) VALUES ('10.1.1.33',52,3306,1,2000&lt;span&gt;);
INSERT INTO mysql_servers (hostname,hostgroup_id,port,weight,max_connections) VALUES ('10.1.1.33',8050,3306,10000,2000&lt;span&gt;);

INSERT INTO mysql_servers (hostname,hostgroup_id,port,weight,max_connections) VALUES ('10.1.1.44',52,3306,1,2000&lt;span&gt;);
INSERT INTO mysql_servers (hostname,hostgroup_id,port,weight,max_connections) VALUES ('10.1.1.44',8050,3306,100000,2000&lt;span&gt;);

LOAD MYSQL SERVERS TO&lt;span&gt; RUNTIME;
SAVE MYSQL SERVERS TO DISK&lt;span&gt;;

select hostgroup_id,hostname,port,STATUS,weight FROM runtime_mysql_servers ORDER BY hostgroup_id,weight DESC;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;检查配置:&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;38&quot;&gt;
&lt;pre&gt;
select hostgroup_id,hostname,port,STATUS,weight FROM runtime_mysql_servers ORDER BY hostgroup_id,weight DESC;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/992711/201903/992711-20190307183207815-668373288.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;添加查询规则：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;77&quot;&gt;
&lt;pre&gt;
INSERT INTO mysql_query_rules (rule_id,proxy_port,username,destination_hostgroup,active,retries,match_digest,apply) VALUES(4,6033,'proxysql',50,1,3,'^\(?SELECT',1&lt;span&gt;);

INSERT INTO mysql_query_rules (rule_id,proxy_port,username,destination_hostgroup,active,retries,match_digest,apply) VALUES(40,6033,'proxysql',50,1,3,'^SELECT.*FOR UPDATE$',1&lt;span&gt;);

INSERT INTO mysql_query_rules (rule_id,proxy_port,username,destination_hostgroup,active,retries,match_digest,apply) VALUES(41,6033,'proxysql',52,1,3,'^SELECT',1&lt;span&gt;);

LOAD MYSQL QUERY RULES TO RUNTIME;SAVE MYSQL QUERY RULES TO DISK;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;加入故障转移脚本,利用scheduler 修改配置提升44为new writer：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;44&quot;&gt;
&lt;pre&gt;
cd /opt/&lt;span&gt;
git clone https://github.com/Tusamarco/&lt;span&gt;proxy_sql_tools
chmod +x /opt/proxy_sql_tools/&lt;span&gt;galera_check.pl

INSERT  INTO scheduler (id,active,interval_ms,filename,arg1) VALUES (10,0,2000,&quot;/opt/proxy_sql_tools/galera_check.pl&quot;,&quot;-u=admin -p=admin -h=127.0.0.1 -H=50:W,52:R -P=6032 --execution_time=0 --retry_down=0 --retry_up=0 --main_segment=1 --debug=0  --log=/var/lib/proxysql/galeraLog --active_failover=1&quot;);
LOAD SCHEDULER TO&lt;span&gt; RUNTIME;
SAVE SCHEDULER TO DISK;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;激活scheduler：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;32&quot;&gt;
&lt;pre&gt;
UPDATE scheduler SET active=1 WHERE id=10&lt;span&gt;;
LOAD scheduler TO run;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;当你想做一个CONTROLLED故障转移时，&lt;/p&gt;
&lt;p&gt;以最小的影响做最好的方法是手动添加非常低权重的第二个节点，&lt;/p&gt;
&lt;p&gt;并在删除节点后，您需要处理。我会告诉你如何安全地做到这一点。&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;41&quot;&gt;
&lt;pre&gt;
INSERT INTO mysql_servers (hostname,hostgroup_id,port,weight,max_connections) VALUES('10.1.1.11',50,3306,1,2000&lt;span&gt;);
LOAD mysql servers TO run;&lt;br/&gt;SELECT * FROM stats_mysql_connection_pool;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/992711/201903/992711-20190307183519974-238288896.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt; 把10.1.1.11 kill了mysqld 和 mysqld_safe进程 ,发现10.1.1.44 已经提升为writer&lt;/p&gt;

&lt;div class=&quot;cnblogs_code&quot; readability=&quot;38&quot;&gt;
&lt;pre&gt;
select hostgroup_id,hostname,port,STATUS,weight FROM runtime_mysql_servers ORDER BY hostgroup_id,weight DESC;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/992711/201903/992711-20190307183604720-1900188432.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;10.1.1.11 恢复之后,重新读取配置&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;38&quot;&gt;
&lt;pre&gt;
load mysql servers to&lt;span&gt; runtime;
save mysql servers to disk&lt;span&gt;;  
select hostgroup_id,hostname,port,STATUS,weight FROM runtime_mysql_servers ORDER BY hostgroup_id,weight DESC;&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/992711/201903/992711-20190307183723274-355321774.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

</description>
<pubDate>Wed, 27 Mar 2019 06:29:00 +0000</pubDate>
<dc:creator>黑洞中的奇点</dc:creator>
<og:description>主机信息: Proxysql: 如果你忽略了ProxySQL会报告主机组的变化，我建议把它设置为0，除非你试图调试“某些东西”，否则你的日志将很快变得巨大。UPDATE global_variable</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/kelvin19840813/p/10607293.html</dc:identifier>
</item>
<item>
<title>SQLServer 中有五种约束， Primary Key 约束、 Foreign Key 约束、 Unique 约束、 Default 约束和 Check 约束 - 可均可可</title>
<link>http://www.cnblogs.com/PatrickLiu/p/10607235.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/PatrickLiu/p/10607235.html</guid>
<description>&lt;p&gt;　　　　一直在关注软件设计方面，数据库方面就忽略了很多，最近在设计数据库时遇到了一些小麻烦，主要是数据库中约束和性能调优方面的应用，以前在学习 Sql Server 2000，还有后来的 Sql Server 2005 数据库时进行了总结，现在也暴露出了一些问题，由于学习的不深入，有一段时间不使用，就会忘记一些东西，所以为了让自己的知识更加牢固，还是要经常拿出来，看看。&lt;/p&gt;&lt;p&gt;    　　 那闲话少说进入我们今天的主题， SQLServer 中有五种约束， Primary Key 约束、 Foreign Key 约束、 Unique 约束、 Default 约束和 Check 约束，今天使用SQL Server2008 来演示下这几种约束的创建和使用的方法。&lt;/p&gt;
&lt;p&gt;&lt;br/&gt;&lt;strong&gt;1 、 Primary Key 约束&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;    　　在表中常有一列或多列的组合，其值能唯一标识表中的每一行。&lt;/p&gt;&lt;p&gt;    　　这样的一列或多列成为表的主键(PrimaryKey)。一个表只能有一个主键，而且主键约束中的列不能为空值。只有主键列才能被作为其他表的外键所创建。&lt;/p&gt;&lt;p&gt;   　　创建主键约束可以右键单击表，选择设计 。&lt;/p&gt;&lt;p&gt; 　　　　&lt;img src=&quot;https://img2018.cnblogs.com/blog/1048776/201903/1048776-20190327140532394-1125411492.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;&lt;p&gt;   　　选中要创建主键的列，然后单击上面的小钥匙。&lt;/p&gt;&lt;p&gt; 　　　　&lt;img src=&quot;https://img2018.cnblogs.com/blog/1048776/201903/1048776-20190327140610266-1604776592.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;&lt;p&gt;   　　也可以右键需要创建主键的列，然后单击小钥匙。&lt;/p&gt;&lt;p&gt;　　　　&lt;img src=&quot;https://img2018.cnblogs.com/blog/1048776/201903/1048776-20190327140640478-1971816678.png&quot; alt=&quot;&quot;/&gt;&lt;br/&gt; &lt;br/&gt;&lt;strong&gt;2 、 Foreign Key 约束&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;    　　外键约束是用来加强两个表（主表和从表）的一列或多列数据之间的连接的。创建外键约束的顺序是先定义主表的主键，然后定义从表的外键。也就是说只有主表的主键才能被从表用来作为外键使用，被约束的从表中的列可以不是主键，主表限制了从表更新和插入的操作。&lt;/p&gt;&lt;p&gt;   　　右键单击需要设置外键的列（此时的表是作为从表在外键中出现），选择关系。&lt;/p&gt;&lt;p&gt;　　　　&lt;img src=&quot;https://img2018.cnblogs.com/blog/1048776/201903/1048776-20190327140736660-612523690.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;&lt;p&gt;   　　接下来点击添加 --&amp;gt; 表和列规范。&lt;br/&gt;　　　　&lt;br/&gt;　　　　&lt;img src=&quot;https://img2018.cnblogs.com/blog/1048776/201903/1048776-20190327140839961-906868021.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;&lt;p&gt;   　　在主键表中选择主表和主表的主键列。&lt;/p&gt;&lt;p&gt; 　　　　&lt;img src=&quot;https://img2018.cnblogs.com/blog/1048776/201903/1048776-20190327140916058-1139275122.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;&lt;p&gt;   　　设置完后保存即可。&lt;br/&gt;　　　　&lt;br/&gt; &lt;br/&gt;&lt;strong&gt;3 、 Unique 约束&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;    　　唯一约束确保表中的一列数据没有相同的值。与主键约束类似，唯一约束也强制唯一性，但唯一约束用于非主键的一列或者多列的组合，且一个表可以定义多个唯一约束。&lt;/p&gt;&lt;p&gt;   　　右键单击要设置的列选择索引 / 键。&lt;/p&gt;&lt;p&gt;　　　　&lt;img src=&quot;https://img2018.cnblogs.com/blog/1048776/201903/1048776-20190327140953658-531652207.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;&lt;p&gt;   　　然后单击添加按钮。&lt;/p&gt;&lt;p&gt;　　　　&lt;img src=&quot;https://img2018.cnblogs.com/blog/1048776/201903/1048776-20190327141020932-1280696088.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;&lt;p&gt;  　　 选择需要设置的列，可以是一列也可以是多列的组合。&lt;/p&gt;
&lt;p&gt;　　　　&lt;img src=&quot;https://img2018.cnblogs.com/blog/1048776/201903/1048776-20190327141054643-261009753.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;br/&gt;   　　关闭并保存设置。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;4 、 Default 约束&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;    　　若在表中定义了默认值约束，用户在插入新的数据行时，如果该行没有指定数据，那么系统将默认值赋给该列，如果我们不设置默认值，系统默认为 NULL 。&lt;/p&gt;&lt;p&gt;    　　以学生信息表为例，在表设计器中，为性别 sex 列填写默认值男。&lt;/p&gt;
&lt;p&gt;　　　　&lt;img src=&quot;https://img2018.cnblogs.com/blog/1048776/201903/1048776-20190327141143427-236927821.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;5 、 Check 约束&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;    　　Check 约束通过逻辑表达式来判断数据的有效性，用来限制输入一列或多列的值的范围。在列中更新数据时，所要输入的内容必须满足 Check 约束的条件，否则将无法正确输入。&lt;/p&gt;&lt;p&gt;   　　以学生信息表中的 sex 为例，我们要限制 sex 列的值只能为男或女。&lt;/p&gt;
&lt;p&gt;　　　　&lt;img src=&quot;https://img2018.cnblogs.com/blog/1048776/201903/1048776-20190327141224106-1842802641.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　　　&lt;img src=&quot;https://img2018.cnblogs.com/blog/1048776/201903/1048776-20190327141301872-195619084.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　　　&lt;img src=&quot;https://img2018.cnblogs.com/blog/1048776/201903/1048776-20190327141314839-1591444427.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　　　&lt;img src=&quot;https://img2018.cnblogs.com/blog/1048776/201903/1048776-20190327141341647-2136495127.png&quot; alt=&quot;&quot;/&gt;　　　　&lt;/p&gt;&lt;p&gt;   关闭并保存设计。&lt;/p&gt;
</description>
<pubDate>Wed, 27 Mar 2019 06:20:00 +0000</pubDate>
<dc:creator>可均可可</dc:creator>
<og:description>一直在关注软件设计方面，数据库方面就忽略了很多，最近在设计数据库时遇到了一些小麻烦，主要是数据库中约束和性能调优方面的应用，以前在学习 Sql Server 2000，还有后来的 Sql Server</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/PatrickLiu/p/10607235.html</dc:identifier>
</item>
<item>
<title>RabbitMQ 初探 - 掸尘</title>
<link>http://www.cnblogs.com/liuzhang/p/10605701.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/liuzhang/p/10605701.html</guid>
<description>&lt;h2&gt;  有哪些优点&lt;/h2&gt;
&lt;ul readability=&quot;0&quot;&gt;&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;&lt;span&gt; 可靠性：RabbitMQ 提供了多种技术可以让你在性能和可靠性之间进行权衡。这些技术包括持久性、投递确认、发布者证实和高可用性。&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;&lt;span&gt;灵活的路由：提供了多种内置交换机类型。如果你有更复杂的路由需求，可以将这些交换机组合起来使用，甚至你可以写自己的交换机类型&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;span&gt;多协议和广泛的客户端：RabbitMQ 支持多种消息协议中的消息传递以及 你能想到的语言几乎都有与其相适配的 RabbitMQ 客户端。&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;h2&gt;  原理&lt;/h2&gt;
&lt;h2&gt; &lt;img src=&quot;https://img2018.cnblogs.com/blog/353089/201903/353089-20190327110732763-1016620490.png&quot; alt=&quot;&quot;/&gt;&lt;/h2&gt;
&lt;ul&gt;&lt;li&gt;&lt;span&gt;&lt;strong&gt;Broker&lt;/strong&gt;: 接收和分发消息的应用，RabbitMQ Server就是Message Broker。&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span&gt;&lt;strong&gt;Channel&lt;/strong&gt;: 如果每一次访问都建立一个Connection，在消息量大的时候建立Connection的开销将是巨大的，效率也较低。Channel作为轻量级的Connection极大减少了操作系统建立connection的开销。线程池的思想。&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span&gt;&lt;strong&gt;Exchange&lt;/strong&gt;: message到达broker的第一站，根据分发规则，匹配查询表中的routing key，分发消息到queue中去。常用的类型有：direct (point-to-point), topic (publish-subscribe) and fanout (multicast)。&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span&gt;&lt;strong&gt;Queue&lt;/strong&gt;: 消息最终被送到这里等待consumer取走。一个message可以被同时拷贝到多个queue中。&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span&gt;&lt;strong&gt;Binding&lt;/strong&gt;: exchange和queue之间的虚拟连接，binding中可以包含routing key。Binding信息被保存到exchange中的查询表中，用于message的分发依据。其实可以理解为Exchange与Queue的关系对照表。&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;h2&gt;  工作流程&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/353089/201903/353089-20190327111328593-1970586839.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;span&gt;消息被发布到exchanges，通常可将exchanges比作邮局或者邮箱&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span&gt;exchanges将消息副本分发到queues，按照bindings中的规则&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span&gt;AMQP brokers传递消息给与queues关联的consumers，或者consumers按照需求从queues拉取信息&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;blockquote readability=&quot;7&quot;&gt;
&lt;p&gt;&lt;span&gt;以一个例子来解释Exchange、Queue、Binding三者之间的关系：乘客乘坐飞机到北京。&lt;br/&gt;乘客是消息，飞机就是Exchange，Queue就是目的地北京，飞机可以通过不同的路线到达北京，这个路线就是Binding&lt;/span&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2&gt;  交换机（exchange）&lt;/h2&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;40&quot;&gt;
&lt;pre&gt;
&lt;span&gt;$connection&lt;/span&gt; = &lt;span&gt;new&lt;/span&gt; AMQPStreamConnection('localhost', 5672, 'guest', 'guest'&lt;span&gt;);
&lt;/span&gt;&lt;span&gt;$channel&lt;/span&gt; = &lt;span&gt;$connection&lt;/span&gt;-&amp;gt;&lt;span&gt;channel();
&lt;/span&gt;&lt;span&gt;$channel&lt;/span&gt;-&amp;gt;exchange_declare('direct_logs', 'direct', &lt;span&gt;false&lt;/span&gt;, &lt;span&gt;false&lt;/span&gt;, &lt;span&gt;false&lt;/span&gt;);
&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;类型&lt;/h2&gt;
&lt;table border=&quot;0&quot;&gt;&lt;tbody readability=&quot;7&quot;&gt;&lt;tr readability=&quot;4&quot;&gt;&lt;td&gt;
&lt;h2&gt;Name（交换机类型）&lt;/h2&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;h2&gt;Default pre-declared names（预声明的默认名称）&lt;/h2&gt;
&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;4&quot;&gt;&lt;td&gt;&lt;span&gt;Direct exchange（直连交换机） &lt;/span&gt;&lt;/td&gt;
&lt;td&gt;&lt;span&gt;(Empty string) and amq.direct&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;&lt;span&gt;Fanout exchange（扇型交换机）&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;&lt;span&gt;amq.fanout &lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;&lt;span&gt;Topic exchange（主题交换机）&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;&lt;span&gt;amq.topic&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;&lt;span&gt;Headers exchange&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;&lt;span&gt;amq.match (and amq.headers in RabbitMQ)&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;

&lt;h2 id=&quot;3-1-exchange&quot;&gt; &lt;/h2&gt;


&lt;p&gt;除交换机类型外，在声明交换机时还有许多其他的属性，其中最重要的几个分别是：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;Durability (exchanges survive broker restart) ：持久化（消息代理重启后，交换机是否还存在）&lt;/li&gt;
&lt;li&gt;Auto-delete (exchange is deleted when all queues have finished using it) ： 自动删除（当所有与之绑定的消息队列都完成了对此交换机的使用后，删掉它）&lt;/li&gt;
&lt;li&gt;Arguments (these are broker-dependent) ：其他属性（依赖代理本身）&lt;/li&gt;
&lt;/ul&gt;&lt;h3&gt;&lt;strong&gt;默认交换机&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;&lt;span&gt;default exchange是一个没有名称的、被broker预先申明的direct exchange。它所拥有的一个特殊属性使它对于简单的应用程序很有作用：每个创建的queue会与它自动绑定，使用queue名称作为routing key。&lt;/span&gt;&lt;br/&gt;&lt;span&gt;举例说，当你申明一个名称为“search-indexing-online”的queue时，AMQP broker使用“search-indexing-online”作为routing key将它绑定到default exchange。因此，一条被发布到default exchange并且routing key为”search-indexing-online”将被路由到名称为”search-indexing-online”的queue&lt;/span&gt;&lt;/p&gt;
&lt;h3&gt;&lt;strong&gt;直连交换机&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;&lt;span&gt;直连型交换机（direct exchange）是根据消息携带的路由键（routing key）来将消息投递给队列的。直连交换机用来处理消息的单播路由（unicast routing）（尽管它也可以处理多播路由）。下边介绍它是如何工作的：&lt;/span&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;span&gt;一个队列绑定到某个交换机上，同时赋予该绑定一个路由键（routing key）&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span&gt;当一个携带着路由键为R的消息被发送给直连交换机时，交换机会把它路由给绑定值同样为R的队列。&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;h3&gt;&lt;strong&gt;扇型交换机&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;&lt;span&gt;扇型交换机（funout exchange）将消息路由给绑定到它身上的所有队列，而不理会绑定的路由键。如果N个队列绑定到某个扇型交换机上，当有消息发送给此扇型交换机时，交换机会将消息的拷贝分别发送给这所有的N个队列。扇型交换机处理消息的广播路由（broadcast routing）。&lt;/span&gt;&lt;/p&gt;
&lt;h3&gt;&lt;strong&gt;主题交换机（Topic Exchange）&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;&lt;span&gt;主题交换机（topic exchanges）通过对消息的路由键和队列到交换机的绑定模式之间的匹配，将消息路由给一个或多个队列。主题交换机经常用来实现各种分发/订阅模式及其变种。主题交换机通常用来实现消息的多播路由（multicast routing）&lt;/span&gt;&lt;/p&gt;
&lt;h3&gt;&lt;strong&gt;&lt;span&gt;头交换机（Headers Exchange）&lt;/span&gt;&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;&lt;span&gt;对于消息的路由来说，有时使用多个属性来表示消息头比用路由键更方便，头交换机（headers exchange）就是为此而生的。头交换机使用多个消息属性来代替路由键建立路由规则。这个规则的建立是通过判断消息头的值是否与指定绑定相匹配而来的。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;头交换机可以视为直连交换机的另一种表现形式。头交换机能够像直连交换机一样工作，不同之处在于头交换机的路由规则是建立在头属性值之上，而不是路由键。路由键必须是一个字符串，而头属性值则没有这个约束，它们甚至可以是整数或者哈希值（字典）等。&lt;/span&gt;&lt;/p&gt;
&lt;h2&gt;  路由&lt;/h2&gt;
&lt;p&gt;&lt;span&gt;绑定（Binding）是交换机（exchange）将消息（message）路由给队列（queue）所需遵循的规则。如果要指示交换机-E将消息路由给队列-Q，那么Q就需要与E进行绑定。绑定操作需要定义一个可选的路由键（routing key）属性给某些类型的交换机。路由键的意义在于从发送给交换机的众多消息中选择出某些消息，将其路由给绑定的队列。&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;34&quot;&gt;
&lt;pre&gt;
&lt;span&gt;$channel&lt;/span&gt;-&amp;gt;basic_publish(&lt;span&gt;$msg&lt;/span&gt;, 'direct_logs', 'error');
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span&gt;最后一个 参数 error 就是 routing_key,具体可参考文档的用法。&lt;/span&gt;&lt;/p&gt;
&lt;h2&gt;  消息确认&lt;/h2&gt;
&lt;p&gt;&lt;span&gt;为了防止消息丢失，RabbitMQ 提供了消息响应（acknowledgments）。消费者会通过一个 ack（响应），告诉 RabbitMQ 已经收到并处理了某条消息，然后RabbitMQ 就会释放并删除这条消息。如果消费者（consumer）挂掉了，没有发送响应，RabbitMQ 就会认为消息没有被完全处理，然后重新发送给其他消费者（consumer）。这样，及时工作者（workers）偶尔的挂掉，也不会丢失消息。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;消息是没有超时这个概念的；当工作者与它断开连的时候，RabbitMQ 会重新发送消息。这样在处理一个耗时非常长的消息任务的时候就不会出问题了。消息响应默认是开启的。之前的例子中我们可以使用 no_ack=True 标识把它关闭。是时候移除这个标识了，当工作者（worker）完成了任务，就发送一个响应。&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;42&quot;&gt;
&lt;pre&gt;
&lt;span&gt;$callback&lt;/span&gt; = &lt;span&gt;function&lt;/span&gt; (&lt;span&gt;$msg&lt;/span&gt;&lt;span&gt;) {

    &lt;/span&gt;&lt;span&gt;$channel&lt;/span&gt; = &lt;span&gt;$msg&lt;/span&gt;-&amp;gt;delivery_info['channel'&lt;span&gt;];
    &lt;/span&gt;&lt;span&gt;$channel&lt;/span&gt;-&amp;gt;basic_ack(&lt;span&gt;$msg&lt;/span&gt;-&amp;gt;delivery_info['delivery_tag'&lt;span&gt;]);

    &lt;/span&gt;&lt;span&gt;echo&lt;/span&gt; ' [x] Received ', &lt;span&gt;$msg&lt;/span&gt;-&amp;gt;body, &quot;\n&quot;&lt;span&gt;;
};


&lt;/span&gt;&lt;span&gt;$channel&lt;/span&gt;-&amp;gt;basic_consume('hello', '', &lt;span&gt;false&lt;/span&gt;, &lt;span&gt;false&lt;/span&gt;, &lt;span&gt;false&lt;/span&gt;, &lt;span&gt;false&lt;/span&gt;, &lt;span&gt;$callback&lt;/span&gt;);
&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;
&lt;span&gt;basic_consume 函数第 4 个参数 no_ack 设置为 false， 就是要消息确认。 通过 callback 回调处理。&lt;/span&gt;&lt;span&gt;一个很容易犯的错误就是忘了 basic_ack，后果很严重。消息在你的程序退出之后就会重新发送，如果它不能够释放没响应的消息，RabbitMQ 就会占用越来越多的内存。&lt;/span&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;span&gt;   为了排除这种错误，你可以使用 rabbitmqctl 命令，输出 messages_unacknowledged 字段：&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;33&quot;&gt;
&lt;pre&gt;
$ &lt;span&gt;sudo&lt;/span&gt;&lt;span&gt; rabbitmqctl list_queues name messages_ready messages_unacknowledged
Listing queues ...
hello    &lt;/span&gt;&lt;span&gt;0&lt;/span&gt;       &lt;span&gt;0&lt;/span&gt;&lt;span&gt;
...&lt;/span&gt;&lt;span&gt;done&lt;/span&gt;.
&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;  消息持久化&lt;/h2&gt;
&lt;p&gt;&lt;span&gt;如果你没有特意告诉 RabbitMQ，那么在它退出或者崩溃的时候，将会丢失所有队列和消息。为了确保信息不会丢失，有两个事情是需要注意的：我们必须把“队列”和“消息”设为持久化。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;首先，为了不让队列消失，需要把队列声明为持久化（durable）：&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;36&quot;&gt;
&lt;pre&gt;
&lt;span&gt;$channel&lt;/span&gt;-&amp;gt;queue_declare('hello', &lt;span&gt;false&lt;/span&gt;, true, &lt;span&gt;false&lt;/span&gt;, &lt;span&gt;false&lt;/span&gt;);
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span&gt;第 3 个参数就是持久化的设置. &lt;/span&gt;&lt;/p&gt;

&lt;h2&gt;参考文献&lt;/h2&gt;

&lt;p&gt;&lt;span&gt;&lt;a href=&quot;http://duqingfeng.net/2018/05/15/RabbitMQ%E5%AD%A6%E4%B9%A0%EF%BC%88%E4%B8%80%EF%BC%89%EF%BC%9A%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E5%8D%8F%E8%AE%AEAMQP%E7%9A%84%E8%AE%BE%E8%AE%A1%E5%8E%9F%E7%90%86/&quot; target=&quot;_blank&quot;&gt;消息队列协议AMQP的设计原理&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;a href=&quot;http://wiki.jikexueyuan.com/project/rabbitmq/work-queues.html&quot; target=&quot;_blank&quot;&gt;RabbitMQ文档&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;
</description>
<pubDate>Wed, 27 Mar 2019 06:19:00 +0000</pubDate>
<dc:creator>掸尘</dc:creator>
<og:description>有哪些优点 可靠性：RabbitMQ 提供了多种技术可以让你在性能和可靠性之间进行权衡。这些技术包括持久性、投递确认、发布者证实和高可用性。 灵活的路由：提供了多种内置交换机类型。如果你有更复杂的路由</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/liuzhang/p/10605701.html</dc:identifier>
</item>
<item>
<title>Git学习（一）：如何登陆以及创建本地代码仓库、提交本地代码 - Geeksongs</title>
<link>http://www.cnblogs.com/geeksongs/p/10606906.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/geeksongs/p/10606906.html</guid>
<description>&lt;p&gt;在我们的实际开发当中，代码经常会被公司要求上传到网络上，能够大家共同完成一个项目，因此掌握git技能也是一项必不可少的技能了，这里我们来学习以下基本的git操作。首先我们要想使用git这个东西需要把它安装好，具体安装的部分可参见其他大佬的博客：https://blog.csdn.net/sishen47k/article/details/80211002&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;span&gt;第一步.登录&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;在我们的git操作当中，登录和注册是一体化的，直接在命令行模式下输入自己的用户名和登录的邮箱即可，首先我们的点击电脑上的“win”键，然后搜索git bash，打开之后就是我们的命令行界面了。&lt;br/&gt;需要输入的代码如下，每输入一行代码就按下一个回车键即可：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;33&quot;&gt;
&lt;pre&gt;
git config --&lt;span&gt;global&lt;/span&gt; user.name &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;(你自己的登录名)&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;
git config &lt;/span&gt;--&lt;span&gt;global&lt;/span&gt; user.emial &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;(你自己用的登陆邮箱)&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;注意：在user.name和user.email之后一定要打一个空格，再打上双引号，不然的话是不会登录成功的！！如果想确认自己已经登陆成功了，则可以输入代码：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;32&quot;&gt;
&lt;pre&gt;
git config --&lt;span&gt;global&lt;/span&gt; user.name
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;回车之后出现你自己的登录名则已经登陆成功，同理可得email的情况，两者同时成功才会真正的登陆成功。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;span&gt;第二步.创建本地代码仓库&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;首先我们来到需要创建代码仓库的地方，这个时候所使用的命令和我们的win下的cmd是大致相似的，因为笔者想使用的文件在F：androidapk/xihguanni文件夹下，因此需要输入以下代码：&lt;/p&gt;

&lt;p&gt;回车，再输入：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot;&gt;
&lt;pre&gt;
androidapk/xihuanni
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;如图所示：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1363478/201903/1363478-20190327131749963-456352665.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;这样就进入到了我们需要创建代码仓库的文件目录下了。&lt;/p&gt;
&lt;p&gt;然后输入命令：&lt;/p&gt;

&lt;p&gt;这样就完成了创建代码仓库的操作，创建完之后会在androidapk/xihuanni文件夹下生成一个隐藏的git文件夹，这个文件夹就是用来记录git操作的，如图所示：&lt;/p&gt;
&lt;p&gt;&lt;br/&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1363478/201903/1363478-20190327132146165-942920548.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;仓库创建完成之后我们可以通过ls -al 命令来查看一下所有的Git操作，如图所示：&lt;br/&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1363478/201903/1363478-20190327132314237-1114155176.png&quot; alt=&quot;&quot; width=&quot;804&quot; height=&quot;390&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;span&gt;第三步.提交本地代码：&lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;代码仓库创建完成之后就可以十分顺利地进行提交本地的代码了，首先我们需要选中需要添加的文件，因为我们一般都会把整个文件夹下的代码一起提交，一起提交的为一整个项目，因此我们直接输入：&lt;/p&gt;

&lt;p&gt;这样就可以吧整个文件夹的代码进行添加了，注意“.”之前会有一个空格的，不然的话是不会添加成功的。&lt;/p&gt;
&lt;p&gt;当我们把文件添加好了，就可以提交了，输入代码：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;32&quot;&gt;
&lt;pre&gt;
git commit -m &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;First commit&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;如图：&lt;br/&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1363478/201903/1363478-20190327132942143-1049415515.png&quot; alt=&quot;&quot; width=&quot;803&quot; height=&quot;815&quot;/&gt;&lt;/p&gt;
&lt;p&gt;这样的话，所有的代码就提交成功了！&lt;/p&gt;
</description>
<pubDate>Wed, 27 Mar 2019 05:32:00 +0000</pubDate>
<dc:creator>Geeksongs</dc:creator>
<og:description>在我们的实际开发当中，代码经常会被公司要求上传到网络上，能够大家共同完成一个项目，因此掌握git技能也是一项必不可少的技能了，这里我们来学习以下基本的git操作。首先我们要想使用git这个东西需要把它</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/geeksongs/p/10606906.html</dc:identifier>
</item>
<item>
<title>微服务架构 - SpringCloud整合分布式服务跟踪zipkin - 架构与我</title>
<link>http://www.cnblogs.com/atcloud/p/10606858.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/atcloud/p/10606858.html</guid>
<description>&lt;h2 id=&quot;zipkin&quot;&gt;1、zipkin&lt;/h2&gt;
&lt;p&gt;zipkin是Twitter的一个开源项目，它基于Google Dapper实现。我们可以使用它来收集各个服务器上请求链路的跟踪数据，并通过它提供的REST API接口来辅助我们查询跟踪数据以实现对分布式系统的监控程序，从而及时地发现系统中出现的延迟升高问题并找出系统性能瓶颈的根源。除了面向开发的API接口之外，它也提供了方便的UI组件来帮助我们直观的搜索跟踪信息和分析请求链路明细，比如：可以查询某段时间内各用户请求的处理时间等。&lt;/p&gt;
&lt;p&gt;zipkin的架构图如下：&lt;br/&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/840503/201903/840503-20190327131915558-1464999862.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;由上面的架构图可以看出，zipkin有四个核心组件：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;Collector：收集器组件，它主要用于处理从外部系统发送过来的跟踪信息，将这些信息转换为zipkin内部处理的Span格式，以支持后续的存储、分析、展示等功能。&lt;/li&gt;
&lt;li&gt;Storage：存储组件，它主要对处理收集器接收到的跟踪信息，默认会将这些信息存储在内存中，我们也可以修改此存储策略，通过使用其他存储组件将跟踪信息存储到数据库中，目前支持的数据库有Mysql、Cassandra和Elasticsearch。&lt;/li&gt;
&lt;li&gt;API：API组件，提供给UI组件，展示跟踪信息。&lt;/li&gt;
&lt;li&gt;UI：UI组件，基于API组件实现的上层应用。通过UI组件用户可以方便而有直观地查询和分析跟踪信息。&lt;/li&gt;
&lt;/ul&gt;&lt;h2 id=&quot;构建zipkin-server&quot;&gt;2、构建zipkin-server&lt;/h2&gt;
&lt;p&gt;目前最新版的zipkin-server，是直接到官网获取最新可执行的jar，然后直接运行该jar文件，例如：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;curl -sSL https://zipkin.io/quickstart.sh | bash -s
java -jar zipkin.jar&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;也可以用docker启动，在此通过docker来启动zipkin-server服务。&lt;/p&gt;
&lt;p&gt;由于在此存储组件使用Elasticsearch，所以先通过docker将Elasticsearch启动，执行如下命令：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;docker run -d -p 9200:9200 --name es elasticsearch:6.6.0&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;如果在启动elasticsearch的时候出现如下错误：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;[1]: max virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144]&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;可以先执行如下命令解决：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;sysctl -w vm.max_map_count=262144&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;接下来，启动zipkin-server服务，执行如下命令：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;docker run -d -e STORAGE_TYPE=elasticsearch -e ES_HOSTS=192.168.208.134:9200 -p 9411:9411 --name zipkin openzipkin/zipkin:2.12.1&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;通过浏览器打开http://192.168.208.134:9411页面，如果出现如下界面，则表示zipkin-server服务启动成功了：&lt;br/&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/840503/201903/840503-20190327131932813-1183596672.png&quot;/&gt;&lt;/p&gt;
&lt;h2 id=&quot;微服务集成zipkin&quot;&gt;3、微服务集成zipkin&lt;/h2&gt;
&lt;p&gt;在原来微服务的pom文件中，添加如下的依赖：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;&amp;lt;dependency&amp;gt;
    &amp;lt;groupId&amp;gt;org.springframework.cloud&amp;lt;/groupId&amp;gt;
    &amp;lt;artifactId&amp;gt;spring-cloud-starter-sleuth&amp;lt;/artifactId&amp;gt;
&amp;lt;/dependency&amp;gt;
&amp;lt;dependency&amp;gt;
    &amp;lt;groupId&amp;gt;org.springframework.cloud&amp;lt;/groupId&amp;gt;
    &amp;lt;artifactId&amp;gt;spring-cloud-starter-zipkin&amp;lt;/artifactId&amp;gt;
&amp;lt;/dependency&amp;gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;然后在application.yml文件需要新增如下配置：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;spring:
  zipkin:
    base-url: http://192.168.208.134:9411
  sleuth:
    sampler:
      percentage: 1&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;其中spring.sleuth.sampler.percentage表示收集跟踪信息的比例，1表示全部收集，它的值的范围是0-1之间的。&lt;/p&gt;
&lt;h2 id=&quot;部署zipkin-dependencies&quot;&gt;4、部署zipkin-dependencies&lt;/h2&gt;
&lt;p&gt;由于新版本当中，如果需要查看各个微服务之间的依赖关系，则必需要部署zipkin-dependencies，此处还是通过docker来部署，由于zipkin-dependencies运行一次就会结束，所以可以让其每小时运行一次，即：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;docker run -e STORAGE_TYPE=elasticsearch -e ES_HOSTS=192.168.208.134:9200 openzipkin/zipkin-dependencies:2.0.4 sh -c 'crond -f'&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;参考资料&quot;&gt;5、参考资料&lt;/h2&gt;
&lt;p&gt;&lt;a href=&quot;https://zipkin.io/&quot; class=&quot;uri&quot;&gt;https://zipkin.io/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/openzipkin/docker-zipkin&quot; class=&quot;uri&quot;&gt;https://github.com/openzipkin/docker-zipkin&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/openzipkin/docker-zipkin-dependencies&quot; class=&quot;uri&quot;&gt;https://github.com/openzipkin/docker-zipkin-dependencies&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;关注我&quot;&gt;关注我&lt;/h2&gt;
&lt;p&gt;以你最方便的方式关注我：&lt;br/&gt;微信公众号：&lt;br/&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/840503/201903/840503-20190327132008528-1181879832.jpg&quot;/&gt;&lt;/p&gt;
</description>
<pubDate>Wed, 27 Mar 2019 05:20:00 +0000</pubDate>
<dc:creator>架构与我</dc:creator>
<og:description>1、zipkin zipkin是Twitter的一个开源项目，它基于Google Dapper实现。我们可以使用它来收集各个服务器上请求链路的跟踪数据，并通过它提供的REST API接口来辅助我们查询</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/atcloud/p/10606858.html</dc:identifier>
</item>
<item>
<title>最详细的Windows平台安装MongoDB教程 - TM0831</title>
<link>http://www.cnblogs.com/TM0831/p/10606624.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/TM0831/p/10606624.html</guid>
<description>&lt;p&gt;&lt;span&gt;MongoDB是一个基于分布式文件存储的数据库，由C++语言编写，旨在为WEB应用提供可扩展的高性能数据存储解决方案。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;MongoDB将数据存储为一个文档，数据结构由键值(key=&amp;gt;value)对组成，MongoDB文档类似于JSON对象，字段值可以包含其他文档，数组及文档数组。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;MongoDB服务端可运行在Linux、Windows或mac os x平台，支持32位和64位应用，默认端口为27017。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;MongoDB支持各种编程语言: Python，Java，C++，PHP，C#等多种语言。&lt;/span&gt;&lt;/p&gt;


&lt;p&gt;&lt;span&gt;MongoDB提供了可用于32位系统和64位系统的预编译二进制包（新版本没有了32位系统的安装文件），你可以进入MongoDB官网下载安装，MongoDB的预编译二进制包的下载地址为：&lt;/span&gt;&lt;span&gt;&lt;a href=&quot;https://www.mongodb.com/download-center/community&quot;&gt;https://www.mongodb.com/download-center/community&lt;/a&gt;，打开之后会看到如下图，直接点击Download下载即可，也可以在Version中选择你想要的版本：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1450803/201903/1450803-20190327105035963-209099635.png&quot; alt=&quot;&quot;/&gt;&lt;/span&gt;&lt;/p&gt;


&lt;p&gt;&lt;span&gt;双击打开文件进行安装，在安装过程中，可以通过点击 &quot;Custom(自定义)&quot; 按钮来设置你的安装目录。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1450803/201903/1450803-20190327110956254-767522594.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;这里我选择安装在E:\MongoDB这个目录下（安装目录会影响我们后面的配置）。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1450803/201903/1450803-20190327111030712-1940620224.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;这里选择直接next：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1450803/201903/1450803-20190327111202101-1153181920.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;这里安装 &lt;strong&gt;&quot;Install MongoDB Compass&quot;&lt;/strong&gt; 不勾选，否则可能要很长时间都一直在执行安装，MongoDB Compass是一个图形界面管理工具，这里不安装也是没有问题的，可以自己去下载一个图形界面管理工具，比如&lt;a href=&quot;https://robomongo.org/&quot; target=&quot;_blank&quot;&gt;Robo3T&lt;/a&gt;。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1450803/201903/1450803-20190327111309421-1373386005.png&quot; alt=&quot;&quot;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;之后稍微等待一会就安装好了。&lt;/span&gt;&lt;/p&gt;


&lt;p&gt;&lt;span&gt;MongoDB的安装过程是很简单的，但是配置就比较麻烦了，可能会遇到各种各样的问题，需要你有足够的耐心和仔细。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;首先要在MongoDB的data文件夹里新建一个db文件夹和一个log文件夹：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1450803/201903/1450803-20190327111744600-236215096.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;然后在log文件夹下新建一个mongo.log：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt; &lt;img src=&quot;https://img2018.cnblogs.com/blog/1450803/201903/1450803-20190327111924389-669177821.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;然后将E:\MongoDB\bin添加到环境变量path中，此时打开cmd窗口运行一下mongo命令，出现如下情况：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1450803/201903/1450803-20190327112251064-657563650.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;这是为什么呢？这是因为我们还没有启动MongoDB服务，自然也就连接不上服务了。那要怎么启动呢？在cmd窗口中运行如下命令：&lt;/span&gt;&lt;/p&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;&lt;span&gt; mongod --dbpath E:\MongoDB\data\db&lt;/span&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;span&gt;需要注意的是：如果你没有提前创建db文件夹，是无法启动成功的。运行成功之后，我们打开浏览器，输入127.0.0.1:27017，看到如下图，就说明MongoDB服务已经成功启动了。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt; &lt;img src=&quot;https://img2018.cnblogs.com/blog/1450803/201903/1450803-20190327113150719-1117519860.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;但是如果每次都要这么启动服务的话也太麻烦了吧，这里你可以选择设置成开机自启动，也可以选择用命令net start mongodb来手动启动，这里我选择使用后者，具体方法如下。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;还是打开cmd窗口，不过这次是以管理员身份运行，然后输入如下命令：&lt;/span&gt;&lt;/p&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;&lt;span&gt;mongod --dbpath &quot;E:\MongoDB\data\db&quot; --logpath &quot;E:\MongoDB\data\log\mongo.log&quot; -install -serviceName &quot;MongoDB&quot;&lt;/span&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;span&gt;如果没有报错的话就说明成功添加到服务里了，可以使用win+R然后输入services.msc命令进行查看：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1450803/201903/1450803-20190327114446897-920534286.png&quot; alt=&quot;&quot;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;默认是自动运行的，这里我选择把它改成手动的。然后在cmd窗口中运行net start mongodb：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1450803/201903/1450803-20190327114857667-1105846938.png&quot; alt=&quot;&quot;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;怎么解决呢？两个步骤：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;1）运行sc delete mongodb删除服务；&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;2）再运行一次配置服务的命令：&lt;/span&gt;&lt;/p&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;&lt;span&gt;mongod --dbpath &quot;E:\MongoDB\data\db&quot; --logpath &quot;E:\MongoDB\data\log\mongo.log&quot; -install -serviceName &quot;MongoDB&quot;&lt;/span&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;span&gt;然后再运行net start mongodb，服务启动成功：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1450803/201903/1450803-20190327115145389-952518290.png&quot; alt=&quot;&quot;/&gt;&lt;/span&gt;&lt;/p&gt;


&lt;p&gt;&lt;strong&gt;&lt;span&gt;1.mongod不是内部或外部命令&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;出现这种问题说明你没有把bin目录添加到环境变量之中，重新添加一下即可解决。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;span&gt;2.服务名无效&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;首先是看你输入的服务名称是否有误，然后再查看本地服务中有没有MongoDB服务，如果没有服务，则运行命令添加服务即可。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;span&gt;3.发生服务特定错误：100&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;删除db文件夹下的mongod.lock和storage.bson两个文件，若删除完之后仍然出现这种问题，用sc delete mongodb删除服务，再配置一下服务就能解决了。&lt;/span&gt;&lt;/p&gt;
</description>
<pubDate>Wed, 27 Mar 2019 04:05:00 +0000</pubDate>
<dc:creator>TM0831</dc:creator>
<og:description>一、MongoDB简介 MongoDB是一个基于分布式文件存储的数据库，由C++语言编写，旨在为WEB应用提供可扩展的高性能数据存储解决方案。 MongoDB将数据存储为一个文档，数据结构由键值(ke</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/TM0831/p/10606624.html</dc:identifier>
</item>
<item>
<title>Kubernetes的DaemonSet（上篇） - 编程一生</title>
<link>http://www.cnblogs.com/xiexj/p/10588046.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/xiexj/p/10588046.html</guid>
<description>&lt;p&gt;&lt;strong&gt;背景&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;静儿作为美团容器化团队HULK的一员，经常需要和Kubernetes(k8s)打交道。第一次登陆node(宿主机)的时候，发现连续登陆几台都看到了Prometheus-Node-Exporter字样的docker进程。他们和普通的Pod(容器)一样，占用IP等资源，占用宿主机允许的pod数上限。后来通过看书了解到这是DaemonSet控制管理的Pod.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;DaemonSet官方文档译文&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;一个DaemonSet确保了所有的node上仅有一个的Pod的一个实例。当node被添加到集群中，Pod也被添加上去。当node被从集群移除，这些Pod会被垃圾回收。删除一个DaemonSet将会清理它创建的Pod。&lt;/p&gt;
&lt;p&gt;举一些DaemonSet典型用法的例子：&lt;/p&gt;
&lt;ul class=&quot;list-paddingleft-2&quot; readability=&quot;1&quot;&gt;&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;在每个node上运行一个集群存储守护进程，例如glusterd、ceph&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;在每个node上运行一个日志集合，例如fuentd或者logstash&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;1&quot;&gt;
&lt;p&gt;在每个node上运行一个node监控后台线程，例如Prometheus Node Exporter，collectd，Dynatrace OneAgent，AppDynamics Agent，Datadog agent，New Relic agent，Ganglia gmod 或者Instana agent.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;在一种简单的场合下，一个DeamonSet会被使用在任意种后台线程、覆盖所有的node。在更复杂的安装方式中，多个DaemonSet会被用于一种后台线程。但是在不同的硬件类型会对应不同的标识或者不同的内存和CPU请求。&lt;/p&gt;
&lt;h3&gt;写一个DaemonSet Spec&lt;/h3&gt;
&lt;h4&gt;创建一个DaemonSet&lt;/h4&gt;
&lt;p&gt;在YAML文件中生命一个DaemonSet。daemonset.yaml文件描述了一个运行着fluentd-elasticsearch的docker镜像的DaemonSet。&lt;/p&gt;
&lt;p&gt;controllers/daemonset.yaml&lt;/p&gt;
&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;properties&quot;&gt;
&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__attr&quot;&gt;apiVersion:&lt;span class=&quot;code-snippet__string&quot;&gt; apps/v1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__attr&quot;&gt;kind:&lt;span class=&quot;code-snippet__string&quot;&gt; DaemonSet&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__attr&quot;&gt;metadata:&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__meta&quot;&gt;  name:&lt;span class=&quot;code-snippet__string&quot;&gt; fluentd-elasticsearch&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__meta&quot;&gt;  namespace:&lt;span class=&quot;code-snippet__string&quot;&gt; kube-system&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__meta&quot;&gt;  labels:&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__meta&quot;&gt;    k8s-app:&lt;span class=&quot;code-snippet__string&quot;&gt; fluentd-logging&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__attr&quot;&gt;spec:&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__meta&quot;&gt;  selector:&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__meta&quot;&gt;    matchLabels:&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__meta&quot;&gt;      name:&lt;span class=&quot;code-snippet__string&quot;&gt; fluentd-elasticsearch&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__meta&quot;&gt;  template:&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__meta&quot;&gt;    metadata:&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__meta&quot;&gt;      labels:&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__meta&quot;&gt;        name:&lt;span class=&quot;code-snippet__string&quot;&gt; fluentd-elasticsearch&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__meta&quot;&gt;    spec:&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__meta&quot;&gt;      tolerations:&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__meta&quot;&gt;      - key:&lt;span class=&quot;code-snippet__string&quot;&gt; node-role.kubernetes.io/master&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__meta&quot;&gt;        effect:&lt;span class=&quot;code-snippet__string&quot;&gt; NoSchedule&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__meta&quot;&gt;      containers:&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__meta&quot;&gt;      - name:&lt;span class=&quot;code-snippet__string&quot;&gt; fluentd-elasticsearch&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__meta&quot;&gt;        image:&lt;span class=&quot;code-snippet__string&quot;&gt; k8s.gcr.io/fluentd-elasticsearch:1.20&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__meta&quot;&gt;        resources:&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__meta&quot;&gt;          limits:&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__meta&quot;&gt;            memory:&lt;span class=&quot;code-snippet__string&quot;&gt; 200Mi&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__meta&quot;&gt;          requests:&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__meta&quot;&gt;            cpu:&lt;span class=&quot;code-snippet__string&quot;&gt; 100m&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__meta&quot;&gt;            memory:&lt;span class=&quot;code-snippet__string&quot;&gt; 200Mi&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__meta&quot;&gt;        volumeMounts:&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__meta&quot;&gt;        - name:&lt;span class=&quot;code-snippet__string&quot;&gt; varlog&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__meta&quot;&gt;          mountPath:&lt;span class=&quot;code-snippet__string&quot;&gt; /var/log&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__meta&quot;&gt;        - name:&lt;span class=&quot;code-snippet__string&quot;&gt; varlibdockercontainers&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__meta&quot;&gt;          mountPath:&lt;span class=&quot;code-snippet__string&quot;&gt; /var/lib/docker/containers&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__meta&quot;&gt;          readOnly:&lt;span class=&quot;code-snippet__string&quot;&gt; true&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__meta&quot;&gt;      terminationGracePeriodSeconds:&lt;span class=&quot;code-snippet__string&quot;&gt; 30&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__meta&quot;&gt;      volumes:&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__meta&quot;&gt;      - name:&lt;span class=&quot;code-snippet__string&quot;&gt; varlog&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__meta&quot;&gt;        hostPath:&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__meta&quot;&gt;          path:&lt;span class=&quot;code-snippet__string&quot;&gt; /var/log&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__meta&quot;&gt;      - name:&lt;span class=&quot;code-snippet__string&quot;&gt; varlibdockercontainers&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__meta&quot;&gt;        hostPath:&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;          &lt;span class=&quot;code-snippet__attr&quot;&gt;path: &lt;span class=&quot;code-snippet__string&quot;&gt;/var/lib/docker/containers&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;h4&gt;所需的字段&lt;/h4&gt;
&lt;p&gt;和其他的Kubernetes配置文件一样，一个DaemonSet需要apiVersion，kind和metadata字段。配置文件的通用信息，可以看deploying application，configuring containers和object management using kubectl文档。&lt;/p&gt;
&lt;p&gt;一个DaemonSet也需要一个spec区&lt;/p&gt;
&lt;h3&gt;Pod模板&lt;/h3&gt;
&lt;p&gt;.spec.template是.spec的必需字段。&lt;/p&gt;
&lt;p&gt;.spec.template是一个pod模板。除了是嵌套的并且没有apiVersion或者kind之外，它的schema和pod是一样的。&lt;/p&gt;
&lt;p&gt;除了pod必需的字段，在DaemonSet中的pod模板必需指定合适的label（详见pod selector）。&lt;/p&gt;
&lt;p&gt;在DaemonSet中的pod模板必需要有一个Always的RestartPolicy。如果没有明确指定，默认也是Aways。&lt;/p&gt;
&lt;h3&gt;Pod选择器&lt;/h3&gt;
&lt;p&gt;.spec.selector字段是pod的选择器。它的功能和job的.spec.selector一样。&lt;/p&gt;
&lt;p&gt;在Kubernetes1.8中，必需指定一个带有.spec.template的pod选择器。当pod选择器为空时将不会再是默认的选择器。选择器默认和kubectl apply是不兼容的。一旦DaemonSet被创建，.spec.selector就不能变了。一旦改变了pod选择器，可能会导致意外将这个pod变成「孤岛」。用户会很迷惑。&lt;/p&gt;
&lt;p&gt;.spec.selector是有两个字段组成的对象：&lt;/p&gt;
&lt;p&gt;指定了两个，它们的作用关系是and。&lt;/p&gt;
&lt;p&gt;一旦.spec.selector被指定，就必须和.spec.template.metadata.labels匹配。不匹配的配置会被API拒掉。&lt;/p&gt;
&lt;p&gt;同时，用户平时也不应该创建匹配这些选择器的标签。包括直接创建、通过其他的DaemonSet创建，或者通过其他的像ReplicaSet这样的控制器来创建。否则，DaemonSet控制器会认为这些pod是自己创建的。但是如果说想手动创建一个值不同的pod放在node上做测试就另当别论了。&lt;/p&gt;
&lt;h4&gt;在指定node上运行pod&lt;/h4&gt;
&lt;p&gt;指定.spec.template.spec.nodeSelector，DaemonSet控制器会在node上创建一个匹配node选择器的pod。同时，如果指定.spec.template.spec.affinity，这时候DaemonSet控制器会创建匹配node的affinity的pod。如果什么两者都不指定，DaemonSet控制器将会在所有node上创建pod。&lt;/p&gt;
&lt;h3&gt;Daemon的pod是怎么被调度的&lt;/h3&gt;
&lt;h4&gt;通过DaemonSet控制器来调度（1.12版本被禁用）&lt;/h4&gt;
&lt;p&gt;pod实际运行的设备通常是Kubernetes调度器来选择的。但是DaemonSet控住器创建的pod是已经指定好了设备的(Pod在创建时.spec.nodeName已经被指定了，所以会被调度器忽略)。基于这个原因：&lt;/p&gt;
&lt;h4&gt;被默认调度器调度（1.12版本开始默认启动）&lt;/h4&gt;
&lt;p&gt;DaemonSet确保所有有资格的node运行一个pod的一个实例。一般来说，Kubernetes控制器决定了一个Pod选择哪个node。但是DaemonSet控制器却负责创建和调度DaemonSet的pod。这引入了下面的问题：&lt;/p&gt;
&lt;ul class=&quot;list-paddingleft-2&quot; readability=&quot;0&quot;&gt;&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;不一致的Pod行为：普通Pod会以Pending状态创建出来等待调度。但是DaemonSet的Pod的初始状态却不是Pending。这让用户很疑惑。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;默认调度器处理Pod优先权(Pod preemption)。当preemption被启用，DaemonSet控制器在做调度决策时就不考虑pod优先权。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;ScheduleDaemonSetPods允许你使用默认调度器而不是DaemonSet控制器来调度。这是通过添加NodeAffinity项而不是.spec.nodeName到DaemonSet的Pod来实现的。默认调度被应用于绑定pod到目标宿主机。DaemonSet Pod的node affinity已经存在时会被替换。DaemonSet控制器只在创建或者修改DaemonSet Pod时才会这样。不会修改DaemonSet的spec.template。&lt;/p&gt;
&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;properties&quot;&gt;
&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__attr&quot;&gt;nodeAffinity:&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;  &lt;span class=&quot;code-snippet__attr&quot;&gt;requiredDuringSchedulingIgnoredDuringExecution:&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &lt;span class=&quot;code-snippet__attr&quot;&gt;nodeSelectorTerms:&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &lt;span class=&quot;code-snippet__meta&quot;&gt;- &lt;span class=&quot;code-snippet__string&quot;&gt;matchFields:&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;      &lt;span class=&quot;code-snippet__meta&quot;&gt;- &lt;span class=&quot;code-snippet__string&quot;&gt;key: metadata.name&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;        &lt;span class=&quot;code-snippet__attr&quot;&gt;operator: &lt;span class=&quot;code-snippet__string&quot;&gt;In&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;        &lt;span class=&quot;code-snippet__attr&quot;&gt;values:&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;        &lt;span class=&quot;code-snippet__meta&quot;&gt;- &lt;span class=&quot;code-snippet__string&quot;&gt;target-host-name&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;h4&gt;污点和容忍&lt;/h4&gt;
&lt;p&gt;Daemon Pod支持污点和容忍。下面的容忍会根据相应的特性被自动添加到DaemonSet。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1112728/201903/1112728-20190324141503955-132787820.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;总结&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;初学一个技术如果感觉无法下手，学了也记不住的赶脚。不如先从一个问题出发：为什么会有这个Pod存在？这样先进行感知再系统学习。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;相关阅读&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzUzNjAxODg4MQ==&amp;amp;mid=2247483841&amp;amp;idx=1&amp;amp;sn=c236d6829a2cce8ad56236bf75085bbf&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-linktype=&quot;2&quot;&gt;《两地书》--K8s基础知识&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzUzNjAxODg4MQ==&amp;amp;mid=2247484268&amp;amp;idx=1&amp;amp;sn=d71f12722b0c031e4727359d0913ad5d&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-linktype=&quot;2&quot;&gt;Kubernetes的污点和容忍（上篇）&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzUzNjAxODg4MQ==&amp;amp;mid=2247484280&amp;amp;idx=4&amp;amp;sn=1fcddeb72c78ac671115977d9c71db5a&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-linktype=&quot;2&quot;&gt;Kubernetes的污点和容忍（下篇）&lt;/a&gt;&lt;/p&gt;
</description>
<pubDate>Wed, 27 Mar 2019 03:49:00 +0000</pubDate>
<dc:creator>编程一生</dc:creator>
<og:description>背景 静儿作为美团容器化团队HULK的一员，经常需要和Kubernetes(k8s)打交道。第一次登陆node(宿主机)的时候，发现连续登陆几台都看到了Prometheus-Node-Exporter</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/xiexj/p/10588046.html</dc:identifier>
</item>
<item>
<title>Docker最全教程之使用 Visual Studio Code玩转Docker（二十） - 雪雁</title>
<link>http://www.cnblogs.com/codelove/p/10606434.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/codelove/p/10606434.html</guid>
<description>&lt;p&gt;VS Code是一个年轻的编辑器，但是确实是非常犀利。通过本篇，老司机带你使用VS Code玩转Docker——相信阅读本篇之后，无论是初学者还是老手，都可以非常方便的玩转Docker了！所谓是“工欲善其事必先利其器”，VS Code，你值得拥有！&lt;/p&gt;

&lt;p&gt;⊙使用 Visual Studio Code玩转Docker&lt;/p&gt;
&lt;p&gt;⊙官方扩展插件Docker&lt;/p&gt;
&lt;p&gt;⊙Docker Compose扩展插件&lt;/p&gt;
&lt;p&gt;⊙最后&lt;/p&gt;


&lt;p&gt;Visual Studio是我们熟知的宇宙第一IDE，而Visual Studio Code（简称VS Code）则是微软推出的开源的跨平台编辑器，自从出世，一直是战斗力爆表——短短4年，就已拔得头筹，并且得到了众多开发者的拥护。如下图所示，以下是Stack Overflow 的 2018 年开发者最受欢迎的开发工具调查结果：&lt;img src=&quot;https://img2018.cnblogs.com/blog/70544/201903/70544-20190327094434126-1561952259.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt; 在Stack Overflow 的 2018 年开发者调查中，VSCode 成为了最受欢迎的开发工具&lt;/p&gt;

&lt;p&gt;目前VisualStudio Code已经拥有了超过一万个插件，插件市场生态是极其丰富。同时其对所有的编程语言都非常友好（体验很不错），包括Docker。接下来，我们就说说Visual Studio Code对Docker的一些支持。&lt;/p&gt;


&lt;p&gt;VS Code提供了对Docker支持的一些官方扩展，我们可以按Ctrl + Shift + X打开“扩展”视图，然后搜索docker以过滤结果，最后选择Microsoft Docker扩展进行安装：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/70544/201903/70544-20190327094508086-1291051579.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;使用此Docker扩展可以非常方便的从VisualStudio Code构建，管理和部署容器化应用程序，主要体现在以下几点：&lt;/p&gt;
&lt;p&gt; &lt;img src=&quot;https://img2018.cnblogs.com/blog/70544/201903/70544-20190327094728334-149802828.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/70544/201903/70544-20190327094741481-1267385642.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/70544/201903/70544-20190327094802898-2059091925.png&quot; alt=&quot;&quot;/&gt; &lt;/p&gt;
&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;
&lt;p&gt;悬停提示；&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/70544/201903/70544-20190327094819972-161186202.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/70544/201903/70544-20190327094831814-500829389.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt; 镜像搜索和智能提示；&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/70544/201903/70544-20190327094847087-773582471.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt; 集成最常见的Docker命令（例如docker build，docker push等，需按F1唤起）； &lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/70544/201903/70544-20190327094902186-590066821.gif&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;


&lt;p&gt; &lt;img src=&quot;https://img2018.cnblogs.com/blog/70544/201903/70544-20190327094940007-500925869.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/70544/201903/70544-20190327094946887-678452280.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/70544/201903/70544-20190327094953395-797707922.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/70544/201903/70544-20190327095003299-1051247464.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li class=&quot;_mce_tagged_br&quot;&gt;对Azure的支持（这块我们就不具体介绍了）；&lt;/li&gt;
&lt;/ul&gt;&lt;ul&gt;&lt;li class=&quot;_mce_tagged_br&quot;&gt;.NET Core程序调试支持；&lt;/li&gt;
&lt;/ul&gt;&lt;ul&gt;&lt;li class=&quot;_mce_tagged_br&quot;&gt;连接docker-machine；&lt;/li&gt;
&lt;/ul&gt;&lt;ul&gt;&lt;li class=&quot;_mce_tagged_br&quot;&gt;在Linux上允许命令。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;我们可以按Ctrl + Shift + X打开“扩展”视图，然后搜索Docker Compose来安装此插件，扩展如下图所示：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/70544/201903/70544-20190327095036907-679074184.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;该扩展支持以下功能：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/70544/201903/70544-20190327095049787-1876000726.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;管理Compose服务（支持Up, Shell, Start, Stop, Restart,Build, Kill, Down）；&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt; &lt;img src=&quot;https://img2018.cnblogs.com/blog/70544/201903/70544-20190327095109676-2119937323.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;支持多个根；&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;VS Code是一个年轻的编辑器，但是确实是非常犀利。通过这两个插件，无论是初学者还是老手，都可以非常方便的玩转容器了！所谓是“工欲善其事必先利其器”，VS Code，你值得拥有！&lt;/p&gt;
</description>
<pubDate>Wed, 27 Mar 2019 03:40:00 +0000</pubDate>
<dc:creator>雪雁</dc:creator>
<og:description>前言 VS Code是一个年轻的编辑器，但是确实是非常犀利。通过本篇，老司机带你使用VS Code玩转Docker——相信阅读本篇之后，无论是初学者还是老手，都可以非常方便的玩转Docker了！所谓是</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/codelove/p/10606434.html</dc:identifier>
</item>
</channel>
</rss>