<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="css/feed.xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/" xmlns:og="http://ogp.me/ns#">
<channel>
<atom:link rel="self" href="http://192.168.1.4/fivefilters/makefulltextfeed.php?url=feed.cnblogs.com%2Fblog%2Fsitehome%2Frss&amp;max=10&amp;links=preserve&amp;exc=" />
<atom:link rel="alternate" title="Source URL" href="http://feed.cnblogs.com/blog/sitehome/rss" />
<atom:link rel="related" title="Subscribe to feed" href="http://www.subtome.com/#/subscribe?feeds=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed.cnblogs.com%252Fblog%252Fsitehome%252Frss%26max%3D10%26links%3Dpreserve%26exc%3D&amp;back=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed.cnblogs.com%252Fblog%252Fsitehome%252Frss%26max%3D10%26links%3Dpreserve%26exc%3D" />
<title>博客园_首页</title>
<link></link>
<description>代码改变世界</description>
<item>
<title>Spring Cloud 之 Stream. - JMCui</title>
<link>http://www.cnblogs.com/jmcui/p/11279388.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/jmcui/p/11279388.html</guid>
<description>&lt;h2 id=&quot;一简介&quot;&gt;一、简介&lt;/h2&gt;
&lt;p&gt;Spring Cloud Stream 是一个用来为微服务应用构建消息驱动能力的框架。&lt;/p&gt;
&lt;p&gt;Spring Cloud Stream 为一些供应商的消息中间件产品（目前集成了 RabbitMQ 和 Kafka）提供了个性化的自动化配置实现，并且引入了发布/订阅、消费组以及消息分区这三个核心概念。简单地说，Spring Cloud Stream 本质上就是整合了 Spring Boot 和 Spring Integration, 实现了一套轻量级的消息驱动的微服务框架。&lt;/p&gt;
&lt;p&gt;通过使用 Spring Cloud Stream，可以忽略消息中间件的差异，有效简化开发人员对消息中间件的使用复杂度，让系统开发人员可以有更多的精力关注于核心业务逻辑的处理。&lt;/p&gt;
&lt;h2 id=&quot;二快速入门&quot;&gt;二、快速入门&lt;/h2&gt;
&lt;h3 id=&quot;pom.yml&quot;&gt;1. pom.yml&lt;/h3&gt;
&lt;pre&gt;
&lt;code&gt;    &amp;lt;dependencies&amp;gt;
        &amp;lt;dependency&amp;gt;
            &amp;lt;groupId&amp;gt;org.springframework.boot&amp;lt;/groupId&amp;gt;
            &amp;lt;artifactId&amp;gt;spring-boot-starter-web&amp;lt;/artifactId&amp;gt;
        &amp;lt;/dependency&amp;gt;
        &amp;lt;dependency&amp;gt;
            &amp;lt;groupId&amp;gt;org.springframework.cloud&amp;lt;/groupId&amp;gt;
            &amp;lt;artifactId&amp;gt;spring-cloud-starter-stream-rabbit&amp;lt;/artifactId&amp;gt;
        &amp;lt;/dependency&amp;gt;
    &amp;lt;/dependencies&amp;gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;application.yml&quot;&gt;2. application.yml&lt;/h3&gt;
&lt;p&gt;配置消息中间件的连接信息：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;spring:
  application:
    name: cloud-stream
  rabbitmq:
    host: 127.0.0.1
    port: 5672
    username: guest
    password: guest&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;消息监听消费&quot;&gt;3. 消息监听/消费&lt;/h3&gt;
&lt;pre&gt;
&lt;code&gt;@EnableBinding({Source.class, Sink.class})
public class SinkReceiver {

    private Logger log = LoggerFactory.getLogger(SinkReceiver.class);

    @StreamListener(Sink.INPUT)
    @SendTo(Source.OUTPUT)
    public Object processInput(String message) {
        log.info(&quot;Input Stream Receiver:{}&quot;, message);
        return message;
    }

    @StreamListener(Source.OUTPUT)
    public void processOutPut(String message) {
        log.info(&quot;Output Stream Receiver:{}&quot;, message);
    }
}&lt;/code&gt;
&lt;/pre&gt;
&lt;ul&gt;&lt;li&gt;@EnableBinding：实现对消息通道（Channel） 的绑定，其中 Sink 是 Spring Cloud Stream 默认的输入通道，Source 是 Spring Cloud Stream 中默认的输出通道。&lt;/li&gt;
&lt;li&gt;@StreamListener：将被修饰的方法注册为消息中间件上数据流的事件监听器，注解中的属性值对应了监听的消息通道名。如果不设置属性值，将默认使用方法名作为消息通道名。&lt;/li&gt;
&lt;li&gt;@SendTo：很多时候在处理完输入消息之后， 需要反馈一个消息给对方， 这时候可以通过 @SendTo 注解来指定返回内容的输出通道。&lt;/li&gt;
&lt;/ul&gt;&lt;h3 id=&quot;消息生产&quot;&gt;4.消息生产&lt;/h3&gt;
&lt;p&gt;消息生产有两种方式，一种是利用注入消息通道来发送消息，如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;@RunWith(SpringRunner.class)
@SpringBootTest(classes = StreamApplication.class)
public class SinkOutputTest {
    @Autowired
    private Sink sink;
    @Autowired
    private Source source;

    @Test
    public void sink() {
        sink.input().send(MessageBuilder.withPayload(&quot;From SinkSender&quot;).build());
    }

    @Test
    public void source() {
        source.output().send(MessageBuilder.withPayload(&quot;From SourceSender&quot;).build());
    }
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;另外一种是使用 Spring Integration 的原生支持 — @InboundChannelAdapter&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;@EnableBinding(value = {Source.class})
@SpringBootApplication
public class StreamApplication {

    public static void main(String[] args) {
        SpringApplication.run(StreamApplication.class, args);
    }
    
    @Bean
    @InboundChannelAdapter(value = Source.OUTPUT, poller = @Poller(fixedDelay = &quot;2000&quot;))
    public MessageSource&amp;lt;String&amp;gt; timerMessageSource() {
        return () -&amp;gt; new GenericMessage&amp;lt;&amp;gt;(&quot;2019/08/06&quot;);
    }
}&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;三绑定器&quot;&gt;三、绑定器&lt;/h2&gt;
&lt;p&gt;Spring Cloud Stream 构建的应用程序与消息中间件之间是通过绑定器 Binder 相关联的，绑定器对于应用程序而言起到了隔离作用， 它使得不同消息中间件的实现细节对应用程序来说是透明的。所以对于每一个 Spring Cloud Stream 的应用程序来说， 它不需要知晓消息中间件的通信细节，它只需知道 Binder 对应程序提供的抽象概念来使用消息中间件来实现业务逻辑即可，而这个抽象概念就是在快速入门中我们提到的消息通道：Channel。如下图所示，在应用程序和 Binder 之间定义了两条输入通道和三条输出通道来传递消息，而绑定器则是作为这些通道和消息中间件之间的桥梁进行通信。&lt;br/&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1153954/201907/1153954-20190731215924761-1223839386.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;通过定义绑定器作为中间层，完美地实现了应用程序与消息中间件细节之间的隔离。通过向应用程序暴露统一的 Channel 通道，使得应用程序不需要再考虑各种不同的消息中间件的实现。当需要升级消息中间件，或是更换其他消息中间件产品时，我们要做的就是更换它们对应的 Binder 绑定器而不需要修改任何 SpringBoot 的应用逻辑。&lt;/p&gt;
&lt;h2 id=&quot;四消费组&quot;&gt;四、消费组&lt;/h2&gt;
&lt;p&gt;Spring Cloud Stream中的消息通信方式遵循了发布－订阅模式，当一条消息被投递到消息中间件之后，它会通过共享的 Topic 主题进行广播，消息消费者在订阅的主题中收到它并触发自身的业务逻辑处理。（这里提到的 Topic 指的是 Stream 的抽象概念，可以是 RabbitMQ 中的 Exchange，也可以是 Kafka 中的 Topic）。&lt;/p&gt;
&lt;p&gt;发布-订阅模式会带来一个问题。因为在微服务架构中，我们的每一个微服务应用为了实现高可用和负载均衡， 实际上都会部署多个实例。按照消息广播的性质，多个实例都会接收到消息，从而导致重复消费。为了解决这个问题， 在Spring Cloud Stream中提供了消费组的概念。&lt;/p&gt;
&lt;p&gt;如果在同一个主题上的应用需要启动多个实例的时候，我们可以通过 spring.cloud.stream.bindings..group 属性为应用指定一个组名，这样这个应用的多个实例在接收到消息的时候，只会有一个成员真正收到消息并进行处理。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;spring:
  application:
    name: cloud-stream
  cloud:
    stream:
      bindings:
        input:
          # 设置消费组，保证只有一个实例消费到消息
          # 如果不设置消费组，Stream 将会为每个实例生成一个消费组
          group: ${spring.application.name}&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;五消息分区&quot;&gt;五、消息分区&lt;/h2&gt;
&lt;p&gt;通过引入消费组的概念，我们已经能够在多实例的清况下，保障每个消息只被组内的一个实例消费。但是消费组无法控制消息具体被哪个实例消费。也就是说，对于同一条消息，它多次到达之后可能是由不同的实例进行消费的。但是对于一些业务场景，需要对一些具有相同特征的消息设置每次都被同一个消费实例处理。&lt;/p&gt;
&lt;p&gt;消息分区的引入就是为了解决这样的问题：当生产者将消息数据发送给多个消费者实例时，保证拥有共同特征的消息数据始终是由同一个消费者实例接收和处理。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;消费者分区&lt;/strong&gt;：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;spring:
  application:
    name: cloud-stream
  cloud:
    stream:
      instance-count: 1
      instance-index: 0
      bindings:
        input:
          consumer:
            partitioned: true&lt;/code&gt;
&lt;/pre&gt;
&lt;ol&gt;&lt;li&gt;spring.cloud.stream.bindings.input.consumer.partitioned = true 开启消费者分区功能。&lt;/li&gt;
&lt;li&gt;spring.cloud.stream.instance-count = 1 当前消费者的总实例个数，即应用程序部署的实例数量。&lt;/li&gt;
&lt;li&gt;spring.cloud.stream.instance-index = 0 当前实例的索引号，从 0 开始，最大为 -1 。用于消息生产的时候锁定该实例。（消息生产的时候 &quot;hashCode(key) % partitionCount&quot; 的计算值等于该设置的值，即转发到该实例上）&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;&lt;strong&gt;生产者分区&lt;/strong&gt;：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;spring:
  application:
    name: cloud-stream
  cloud:
    stream:
      bindings:
        output:
          producer:
            partitionCount: 1
            partitionKeyExtractorName: keyStrategy&lt;/code&gt;
&lt;/pre&gt;
&lt;ol&gt;&lt;li&gt;spring.cloud.stream.bindings.output.producer.partitionCount = 1 ，消息生产需要广播的消费者数量。即消息分区的数量。&lt;/li&gt;
&lt;li&gt;spring.cloud.stream.bindings.output.producer.partitionKeyExtractorName = keyStrategy ，Spring Bean — 用来消息的特征值计算。（分区选择计算规则为 &quot;hashCode(key) % partitionCount&quot; , 这里的 key 根据 partitionKeyExpression 或 partitionKeyExtractorName 的配置计算得到）&lt;/li&gt;
&lt;/ol&gt;&lt;pre&gt;
&lt;code&gt;@Component
public class KeyStrategy implements PartitionKeyExtractorStrategy {
    
    @Override
    public Object extractKey(Message&amp;lt;?&amp;gt; message) {
        return message.getPayload();
    }
}&lt;/code&gt;
&lt;/pre&gt;

</description>
<pubDate>Thu, 08 Aug 2019 00:39:00 +0000</pubDate>
<dc:creator>JMCui</dc:creator>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/jmcui/p/11279388.html</dc:identifier>
</item>
<item>
<title>一次难得的分库分表实践 - crossoverJie</title>
<link>http://www.cnblogs.com/crossoverJie/p/11318984.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/crossoverJie/p/11318984.html</guid>
<description>&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1431471/201908/1431471-20190808083155444-238864822.jpg&quot;/&gt;&lt;/p&gt;

&lt;p&gt;前不久发过两篇关于分表的文章：&lt;/p&gt;
&lt;p&gt;从标题可以看得出来，当时我们只做了分表；还是由于业务发展，截止到现在也做了分库，目前看来都还比较顺利，所以借着脑子还记得清楚来一次复盘。&lt;/p&gt;
&lt;p&gt;先来回顾下整个分库分表的流程如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1431471/201908/1431471-20190808083155748-267472125.jpg&quot;/&gt;&lt;/p&gt;
&lt;p&gt;整个过程也很好理解，基本符合大部分公司的一个发展方向。&lt;/p&gt;
&lt;p&gt;很少会有业务一开始就会设计为分库分表，虽说这样会减少后续的坑，但部分公司刚开始都是以业务为主。&lt;/p&gt;
&lt;p&gt;直到业务发展到单表无法支撑时，自然而然会考虑分表甚至分库的事情。&lt;/p&gt;
&lt;p&gt;于是本篇会作一次总结，之前提过的内容可能会再重复一次。&lt;/p&gt;

&lt;p&gt;首先讨论下什么样的情况下适合分表？&lt;/p&gt;
&lt;p&gt;根据我的经验来看，当某张表的数据量已经达到千万甚至上亿，同时日增数据量在 2% 以上。&lt;/p&gt;
&lt;p&gt;当然这些数字并不是绝对的，最重要的还是对这张表的写入和查询都已经影响到正常业务执行，比如查询速度明显下降，数据库整体 IO 居高不下等。&lt;/p&gt;
&lt;p&gt;而谈到分表时我们着重讨论的还是水平分表；&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1431471/201908/1431471-20190808083156254-994618782.jpg&quot;/&gt;&lt;/p&gt;
&lt;p&gt;也就是将一张大表数据通过某种路由算法将数据尽可能的均匀分配到 N 张小表中。&lt;/p&gt;
&lt;h2 id=&quot;range&quot;&gt;Range&lt;/h2&gt;
&lt;p&gt;而分表策略也有好几种，分别适用不同的场景。&lt;/p&gt;
&lt;p&gt;首先第一种是按照范围划分，比如我们可以将某张表的创建时间按照日期划分存为月表；也可以将某张表的主键按照范围划分，比如 【1~10000】在一张表，【10001~20000】在一张表，以此类推。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1431471/201908/1431471-20190808083156588-1500908346.jpg&quot;/&gt;&lt;/p&gt;
&lt;p&gt;这样的分表适合需要对数据做归档处理，比如系统默认只提供近三个月历史数据的查询功能，这样也方便操作；只需要把三月之前的数据单独移走备份保存即可）。&lt;/p&gt;
&lt;p&gt;这个方案有好处也有弊端：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;好处是自带水平扩展，不需要过多干预。&lt;/li&gt;
&lt;li&gt;缺点是可能会出现数据不均匀的情况（比如某个月请求暴增）。&lt;/li&gt;
&lt;/ul&gt;&lt;h2 id=&quot;hash&quot;&gt;Hash&lt;/h2&gt;
&lt;p&gt;按照日期这样的范围分表固然简单，但适用范围还是比较窄；毕竟我们大部分的数据查询都不想带上时间。&lt;/p&gt;
&lt;p&gt;比如某个用户想查询他产生的所有订单信息，这是很常见的需求。&lt;/p&gt;
&lt;p&gt;于是我们分表的维度就得改改，分表算法可以采用主流的 &lt;code&gt;hash+mod&lt;/code&gt; 的组合。&lt;/p&gt;
&lt;p&gt;这是一个经典的算法，大名鼎鼎的 &lt;code&gt;HashMap&lt;/code&gt; 也是这样来存储数据。&lt;/p&gt;
&lt;p&gt;假设我们这里将原有的一张大表订单信息分为 64 张分表：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1431471/201908/1431471-20190808083158762-97773711.jpg&quot;/&gt;&lt;/p&gt;
&lt;p&gt;这里的 &lt;code&gt;hash&lt;/code&gt; 便是将我们需要分表的字段进行一次散列运算，使得经过散列的数据尽可能的均匀并且不重复。&lt;/p&gt;
&lt;p&gt;当然如果本身这个字段就是一个整形并且不重复也可以省略这个步骤，直接进行 &lt;code&gt;Mod&lt;/code&gt; 得到分表下标即可。&lt;/p&gt;
&lt;h3 id=&quot;分表数量选择&quot;&gt;分表数量选择&lt;/h3&gt;
&lt;p&gt;至于这里的分表数量（64）也是有讲究的，具体设为多少这个没有标准值，需要根据自身业务发展，数据增量进行预估。&lt;/p&gt;
&lt;p&gt;根据我个人的经验来看，至少需要保证分好之后的小表在业务发展的几年之内都不会出现单表数据量过大（比如达到千万级）。&lt;/p&gt;
&lt;p&gt;我更倾向于在数据库可接受的范围内尽可能的增大这个分表数，毕竟如果后续小表也达到瓶颈需要再进行一次分表扩容，那是非常痛苦的。&lt;/p&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;目前笔者还没经历这一步，所以本文没有相关介绍。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;但是这个数量又不是瞎选的，和 &lt;code&gt;HashMap&lt;/code&gt; 一样，也建议得是 &lt;code&gt;2^n&lt;/code&gt;，这样可以方便在扩容的时尽可能的少迁移数据。&lt;/p&gt;
&lt;h2 id=&quot;range-hash&quot;&gt;Range + Hash&lt;/h2&gt;
&lt;p&gt;当然还有一种思路，&lt;code&gt;Range&lt;/code&gt; 和 &lt;code&gt;Hash&lt;/code&gt; 是否可以混用。&lt;/p&gt;
&lt;p&gt;比如我们一开始采用的是 Hash 分表，但是数据增长巨大，导致每张分表数据很快达到瓶颈，这样就不得不再做扩容，比如由 64 张表扩容到 256 张。&lt;/p&gt;
&lt;p&gt;但扩容时想要做到不停机迁移数据非常困难，即便是停机，那停多久呢？也不好说。&lt;/p&gt;
&lt;p&gt;所以我们是否可以在 &lt;code&gt;Mod&lt;/code&gt; 分表的基础上再分为月表，借助于 &lt;code&gt;Range&lt;/code&gt; 自身的扩展性就不用考虑后续数据迁移的事情了。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1431471/201908/1431471-20190808083159525-1116786780.jpg&quot;/&gt;&lt;/p&gt;
&lt;p&gt;这种方式理论可行，但我没有实际用过，给大家的思路做个参考吧。&lt;/p&gt;
&lt;h2 id=&quot;烦人的数据迁移&quot;&gt;烦人的数据迁移&lt;/h2&gt;
&lt;p&gt;分表规则弄好后其实只是完成了分表的第一步，真正麻烦的是数据迁移，或者说是如何做到对业务影响最小的数据迁移。&lt;/p&gt;
&lt;p&gt;除非是一开始就做了分表，所以数据迁移这一步骤肯定是跑不掉的。&lt;/p&gt;
&lt;p&gt;下面整理下目前我们的做法供大家参考：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;一旦分表上线后所有的数据写入、查询都是针对于分表的，所以原有大表内的数据必须得迁移到分表里，不然对业务的影响极大。&lt;/li&gt;
&lt;li&gt;我们估算了对一张 2 亿左右的表进行迁移，自己写的迁移程序，大概需要花 4~5 天的时间才能完成迁移。&lt;/li&gt;
&lt;li&gt;意味着这段时间内，以前的数据对用户是不可见的，显然这样业务不能接受。&lt;/li&gt;
&lt;li&gt;于是我们做了一个兼容处理：分表改造上线后，所有新产生的数据写入分表，但对历史数据的操作还走老表，这样就少了数据迁移这一步骤。&lt;/li&gt;
&lt;li&gt;只是需要在操作数据之前做一次路由判断，当新数据产生的足够多时（我们是两个月时间），几乎所有的操作都是针对于分表，再从库启动数据迁移，数据迁移完毕后将原有的路由判断去掉。&lt;/li&gt;
&lt;li&gt;最后所有的数据都从分表产生和写入。&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;至此整个分表操作完成。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1431471/201908/1431471-20190808083200675-561028701.jpg&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1431471/201908/1431471-20190808083204878-856491677.jpg&quot;/&gt;&lt;/p&gt;
&lt;h2 id=&quot;业务兼容&quot;&gt;业务兼容&lt;/h2&gt;
&lt;p&gt;同时分表之后还需要兼容其他业务；比如原有的报表业务、分页查询等，现在来看看我们是如何处理的。&lt;/p&gt;
&lt;h3 id=&quot;报表&quot;&gt;报表&lt;/h3&gt;
&lt;p&gt;首先是报表，没分表之前之间查询一张表就搞定了，现在不同，由一张表变为 N 张表。&lt;/p&gt;
&lt;p&gt;所以原有的查询要改为遍历所有的分表，考虑到性能可以利用多线程并发查询分表数据然后汇总。&lt;/p&gt;
&lt;p&gt;不过只依靠 &lt;code&gt;Java&lt;/code&gt; 来对这么大量的数据做统计分析还是不现实，刚开始可以应付过去，后续还得用上大数据平台来处理。&lt;/p&gt;
&lt;h3 id=&quot;查询&quot;&gt;查询&lt;/h3&gt;
&lt;p&gt;再一个是查询，原有的分页查询肯定是不能用了，毕竟对上亿的数据分页其实没什么意义。&lt;/p&gt;
&lt;p&gt;只能提供通过分表字段的查询，比如是按照订单 ID 分表，那查询条件就得带上这个字段，不然就会涉及到遍历所有表。&lt;/p&gt;
&lt;p&gt;这也是所有分表之后都会遇到的一个问题，除非不用 &lt;code&gt;MySQL&lt;/code&gt; 这类关系型数据库。&lt;/p&gt;

&lt;p&gt;分表完成后可以解决单表的压力，但数据库本身的压力却没有下降。&lt;/p&gt;
&lt;p&gt;我们在完成分表之后的一个月内又由于数据库里“其他表”的写入导致整个数据库 IO 增加，而且这些“其他表”还和业务关系不大。&lt;/p&gt;
&lt;p&gt;也就是说一些可有可无的数据导致了整体业务受影响，这是非常不划算的事情。&lt;/p&gt;
&lt;p&gt;于是我们便把这几张表单独移到一个新的数据库中，完全和现有的业务隔离开来。&lt;/p&gt;
&lt;p&gt;这样就会涉及到几个改造：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;应用自身对这些数据的查询、写入都要改为调用一个独立的 &lt;code&gt;Dubbo&lt;/code&gt; 服务，由这个服务对迁移的表进行操作。&lt;/li&gt;
&lt;li&gt;暂时不做数据迁移，所以查询时也得按照分表那样做一个兼容，如果查询老数据就要在当前库查询，新数据就要调用 &lt;code&gt;Dubbo&lt;/code&gt; 接口进行查询。&lt;/li&gt;
&lt;li&gt;对这些表的一些关联查询也得改造为查询 &lt;code&gt;Dubbo&lt;/code&gt; 接口，在内存中进行拼接即可。&lt;/li&gt;
&lt;li&gt;如果数据量确实很大，也可将同步的 &lt;code&gt;Dubbo&lt;/code&gt; 接口换为写入消息队列来提高吞吐量。&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;目前我们将这类数据量巨大但对业务不太影响的表单独迁到一个库后，数据库的整体 &lt;code&gt;IO&lt;/code&gt; 下降明显，业务也恢复正常。&lt;/p&gt;

&lt;p&gt;最后我们还需要做一步历史数据归档的操作，将 N 个月之前的数据要定期迁移到 &lt;code&gt;HBASE&lt;/code&gt; 之类存储，保证 &lt;code&gt;MySQL&lt;/code&gt; 中的数据一直保持在一个可接受的范围。&lt;/p&gt;
&lt;p&gt;而归档数据的查询便依赖于大数据提供服务。&lt;/p&gt;
&lt;p&gt;本次分库分表是一次非常难得的实践操作，网上大部分的资料都是在汽车出厂前就换好了轮胎。&lt;/p&gt;
&lt;p&gt;而我们大部分碰到的场景都是要对高速路上跑着的车子换胎，一不小心就“车毁人亡”。&lt;/p&gt;
&lt;p&gt;有更好的方式方法欢迎大家评论区留言讨论。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;你的点赞与分享是对我最大的支持&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1431471/201908/1431471-20190808083206198-1201543178.jpg&quot;/&gt;&lt;/p&gt;
</description>
<pubDate>Thu, 08 Aug 2019 00:32:00 +0000</pubDate>
<dc:creator>crossoverJie</dc:creator>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/crossoverJie/p/11318984.html</dc:identifier>
</item>
<item>
<title>数据库中的乐观锁与悲观锁 - murphy_gb</title>
<link>http://www.cnblogs.com/kyoner/p/11318979.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/kyoner/p/11318979.html</guid>
<description>&lt;h2 id=&quot;悲观锁&quot;&gt;悲观锁&lt;/h2&gt;
&lt;p&gt;当我们要对一个数据库中的一条数据进行修改的时候，为了避免同时被其他人修改，最好的办法就是直接对该数据进行加锁以防止并发。&lt;/p&gt;
&lt;p&gt;这种借助数据库锁机制在修改数据之前先锁定，再修改的方式被称之为悲观并发控制（又名“悲观锁”，Pessimistic Concurrency Control，缩写“PCC”）。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;之所以叫做悲观锁，是因为这是一种对数据的修改抱有悲观态度的并发控制方式。我们一般认为数据被并发修改的概率比较大，所以需要在修改之前先加锁。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;悲观并发控制实际上是&lt;strong&gt;“先取锁再访问”的保守策略&lt;/strong&gt;，&lt;strong&gt;为数据处理的安全提供了保证&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;￼&lt;br/&gt;但是在效率方面，处理加锁的机制会&lt;strong&gt;让数据库产生额外的开销&lt;/strong&gt;，还有增加&lt;strong&gt;产生死锁&lt;/strong&gt;的机会；&lt;/p&gt;
&lt;p&gt;另外，还会&lt;strong&gt;降低并行性&lt;/strong&gt;，一个事务如果锁定了某行数据，其他事务就必须等待该事务处理完才可以处理那行数据。&lt;/p&gt;
&lt;h2 id=&quot;乐观锁&quot;&gt;乐观锁&lt;/h2&gt;
&lt;p&gt;乐观锁（ Optimistic Locking ） 是相对悲观锁而言的，乐观锁假设数据一般情况下不会造成冲突，所以在数据进行提交更新的时候，才会正式对数据的冲突与否进行检测，如果发现冲突了，则让返回用户错误的信息，让用户决定如何去做。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;相对于悲观锁，在对数据库进行处理的时候，乐观锁并不会使用数据库提供的锁机制。一般的实现乐观锁的方式就是记录数据版本。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;乐观并发控制相信事务之间的数据竞争(data race)的概率是比较小的，因此&lt;strong&gt;尽可能直接做下去，直到提交的时候才去锁定，所以不会产生任何锁和死锁&lt;/strong&gt;。&lt;/p&gt;
&lt;h2 id=&quot;悲观锁实现方式&quot;&gt;悲观锁实现方式&lt;/h2&gt;
&lt;p&gt;悲观锁的实现，往往依靠数据库提供的锁机制。在数据库中，悲观锁的流程如下：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;在对记录进行修改前，先尝试为该记录加上排他锁（exclusive locking）。&lt;/li&gt;
&lt;li&gt;如果加锁失败，说明该记录正在被修改，那么当前查询可能要等待或者抛出异常。具体响应方式由开发者根据实际需要决定。&lt;/li&gt;
&lt;li&gt;如果成功加锁，那么就可以对记录做修改，事务完成后就会解锁了。&lt;/li&gt;
&lt;li&gt;其间如果有其他事务对该记录做加锁的操作，都要等待当前事务解锁或直接抛出异常。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;我们拿比较常用的MySql Innodb引擎举例，来说明一下在SQL中如何使用悲观锁。&lt;/p&gt;
&lt;blockquote readability=&quot;7&quot;&gt;
&lt;p&gt;注意：要使用悲观锁，我们必须关闭mysql数据库中自动提交的属性，命令set autocommit=0;即可关闭，因为MySQL默认使用autocommit模式，也就是说，当你执行一个更新操作后，MySQL会立刻将结果进行提交。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;我们举一个简单的例子，如淘宝下单过程中扣减库存的需求说明一下如何使用悲观锁：&lt;/p&gt;
&lt;pre class=&quot;sql&quot;&gt;
&lt;code&gt;//0.开始事务
begin; 
//1.查询出商品库存信息
select quantity from items where id=1 for update;
//2.修改商品库存为2
update items set quantity=2 where id = 1;
//3.提交事务
commit;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;以上，在对id = 1的记录修改前，先通过for update的方式进行加锁，然后再进行修改。这就是比较典型的悲观锁策略。&lt;/p&gt;
&lt;p&gt;如果以上修改库存的代码发生并发，同一时间只有一个线程可以开启事务并获得id=1的锁，其它的事务必须等本次事务提交之后才能执行。这样我们可以保证当前的数据不会被其它事务修改。&lt;/p&gt;
&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;上面我们提到，使用select…for update会把数据给锁住，不过我们需要注意一些锁的级别，MySQL InnoDB默认行级锁。行级锁都是基于索引的，如果一条SQL语句用不到索引是不会使用行级锁的，会使用表级锁把整张表锁住，这点需要注意。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;乐观锁实现方式&quot;&gt;乐观锁实现方式&lt;/h2&gt;
&lt;p&gt;使用乐观锁就不需要借助数据库的锁机制了。&lt;/p&gt;
&lt;p&gt;乐观锁的概念中其实已经阐述了他的具体实现细节：主要就是两个步骤：冲突检测和数据更新。其实现方式有一种比较典型的就是&lt;strong&gt;Compare and Swap(CAS)技术&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;CAS是项乐观锁技术，当多个线程尝试使用CAS同时更新同一个变量时，只有其中一个线程能更新变量的值，而其它线程都失败，&lt;strong&gt;失败的线程并不会被挂起，而是被告知这次竞争中失败，并可以再次尝试。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;比如前面的扣减库存问题，通过乐观锁可以实现如下：&lt;/p&gt;
&lt;pre class=&quot;sql&quot;&gt;
&lt;code&gt;//查询出商品库存信息，quantity = 3
select quantity from items where id=1
//修改商品库存为2
update items set quantity=2 where id=1 and quantity = 3;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;以上，我们在更新之前，先查询一下库存表中当前库存数（quantity），然后在做update的时候，以库存数作为一个修改条件。当我们提交更新的时候，判断数据库表对应记录的当前库存数与第一次取出来的库存数进行比对，如果数据库表当前库存数与第一次取出来的库存数相等，则予以更新，否则认为是过期数据。&lt;/p&gt;
&lt;p&gt;但是以上更新语句存在一个比较重要的问题，即&lt;strong&gt;ABA问题。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;比如说一个线程1从数据库中取出库存数3，这时候另一个线程2也从数据库中库存数3，并且线程2进行了一些操作将库存数变成了2，紧接着又将库存数变成3，这时候线程1进行CAS操作发现数据库中仍然是3，然后线程1操作成功。尽管线程1的CAS操作成功，但是不代表这个过程就是没有问题的。&lt;/p&gt;
&lt;p&gt;有一个比较好的办法可以解决ABA问题，那就是通过一个单独的可以顺序递增的version字段。改为以下方式即可：&lt;/p&gt;
&lt;pre class=&quot;sql&quot;&gt;
&lt;code&gt;//查询出商品信息，version = 1
select version from items where id=1
//修改商品库存为2
update items set quantity=2,version = 3 where id=1 and version = 2;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;乐观锁每次在执行数据的修改操作时，都会带上一个版本号，一旦版本号和数据的版本号一致就可以执行修改操作并对版本号执行+1操作，否则就执行失败。因为每次操作的版本号都会随之增加，所以不会出现ABA问题，因为版本号只会增加不会减少。&lt;/p&gt;
&lt;p&gt;除了version以外，还可以使用时间戳，因为时间戳天然具有顺序递增性。&lt;/p&gt;
&lt;p&gt;以上SQL其实还是有一定的问题的，就是&lt;strong&gt;一旦高并发的时候，就只有一个线程可以修改成功，那么就会存在大量的失败。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;对于像淘宝这样的电商网站，高并发是常有的事，总让用户感知到失败显然是不合理的。所以，还是要想办法&lt;strong&gt;减小乐观锁的粒度&lt;/strong&gt;的。&lt;/p&gt;
&lt;p&gt;有一条比较好的建议，可以减小乐观锁力度，最大程度的提升吞吐率，提高并发能力！如下：&lt;/p&gt;
&lt;pre class=&quot;sql&quot;&gt;
&lt;code&gt;//修改商品库存
update item 
set quantity=quantity - 1 
where id = 1 and quantity - 1 &amp;gt; 0&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;以上SQL语句中，如果用户下单数为1，则通过&lt;code&gt;quantity - 1 &amp;gt; 0&lt;/code&gt;的方式进行乐观锁控制。&lt;/p&gt;
&lt;p&gt;以上update语句，在执行过程中，会在一次原子操作中自己查询一遍quantity的值，并将其扣减掉1。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;高并发环境下锁粒度把控是一门重要的学问，选择一个好的锁，在保证数据安全的情况下，可以大大提升吞吐率，进而提升性能。&lt;/strong&gt;&lt;/p&gt;
&lt;h2 id=&quot;如何选择&quot;&gt;如何选择&lt;/h2&gt;
&lt;p&gt;在乐观锁与悲观锁的选择上面，主要看下两者的区别以及适用场景就可以了。&lt;/p&gt;
&lt;p&gt;1、乐观锁并未真正加锁，效率高。一旦锁的粒度掌握不好，更新失败的概率就会比较高，容易发生业务失败。&lt;/p&gt;
&lt;p&gt;2、悲观锁依赖数据库锁，效率低。更新失败的概率比较低。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;随着互联网三高架构（高并发、高性能、高可用）的提出，悲观锁已经越来越少的被使用到生产环境中了，尤其是并发量比较大的业务场景。&lt;/strong&gt;&lt;/p&gt;
</description>
<pubDate>Thu, 08 Aug 2019 00:31:00 +0000</pubDate>
<dc:creator>murphy_gb</dc:creator>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/kyoner/p/11318979.html</dc:identifier>
</item>
<item>
<title>.net持续集成测试篇之Nunit 测试配置 - 周国通</title>
<link>http://www.cnblogs.com/tylerzhou/p/11318911.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/tylerzhou/p/11318911.html</guid>
<description>&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&quot;https://www.cnblogs.com/tylerzhou/p/11204826.html&quot;&gt;系列目录&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;在开始之前我们先看一个陷阱&lt;/p&gt;
&lt;p&gt;用到的Person类如下&lt;/p&gt;
&lt;pre class=&quot;cs&quot;&gt;
&lt;code&gt; public class Person:IPerson
    {
        public string Name { get; set; }
        public int Age { get; set; }
        public DateTime BirthDay { get; set; }
        /// &amp;lt;summary&amp;gt;
        /// 判断Name是否包含字母B
        /// &amp;lt;/summary&amp;gt;
        /// &amp;lt;returns&amp;gt;&amp;lt;/returns&amp;gt;
        public bool WhetherNameContainsB()
        {
            if (this.Name == null) throw new ArgumentNullException(&quot;参数不能为null&quot;);
            if (this.Name.Contains(&quot;B&quot;)) return true;
            return false;
        }
    }&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;这个类以前也用过,有三个属性和一个方法,其中方法用于判断Name字段是否包含大写字母B,如果包含返回true,不包含返回false,如果Name为null则抛出异常&lt;/p&gt;
&lt;p&gt;测试类如下&lt;/p&gt;
&lt;pre class=&quot;cs&quot;&gt;
&lt;code&gt;   [TestFixture]
    public class FirstUnitTest
    {
        private Person psn;
        public FirstUnitTest()
        {
         psn = new Person();
         }

        [Test]
        [Order(1)]
        public void SetPersonName()
        {
            psn.Name = &quot;sto&quot;;
            Assert.IsNotEmpty(psn.Name);
        }
        [Test]
        [Order(2)]
        public void DemoTest()
        {
            Assert.Throws&amp;lt;ArgumentNullException&amp;gt;(() =&amp;gt; psn.WhetherNameContainsB());
        }
       

    }&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;第一个测试给Name赋值,然后断言用户名不为空,这显然应该是通过的&lt;/p&gt;
&lt;p&gt;第二个测试用于断言调用WhetherNameContainsB时会抛异常,由于这里Name并没有赋值,所以会抛出异常,这里也应该能返回成功.&lt;/p&gt;
&lt;p&gt;然而运行以上代码第二个测试返回的是失败!这是因为Nunit在运行测试类的时候会调用所有的测试方法,由于我们显式指定的运行顺序&lt;code&gt;(使用order注解)&lt;/code&gt;则第一个方法先于第二个方法前执行,由于第一个方法把Name设置为&quot;sto&quot;,因此这时候全局psn的Name字段便有值了.所以第二个方法再调用psn的WhetherNameContainsB方法时,是不会抛出异常的(方法的逻辑是只有Name有值便不会抛出异常).&lt;/p&gt;
&lt;p&gt;如果不指定运行顺序,则第二个方法运行的结果是不确定的,如果它先于第一个方法执行,则就会返回成功,如果晚于第一个方法则返回失败.&lt;/p&gt;
&lt;p&gt;我们前面说到,单元测试的结果应该是稳定的,然而这里却是不确定的,因此我们要重新设计.&lt;/p&gt;
&lt;p&gt;当然其实解决这个问题很简单,只要把对全局的变量移动到方法里面就行了,这样每个方法的状态就不会被外部改变了.&lt;/p&gt;
&lt;p&gt;改造后的测试类如下&lt;/p&gt;
&lt;pre class=&quot;cs&quot;&gt;
&lt;code&gt; [TestFixture]
    public class FirstUnitTest
    {
       
        public FirstUnitTest()
        {
        
         }

        [Test]
        [Order(1)]
        public void SetPersonName()
        {
            Person psn = new Person();
            psn.Name = &quot;sto&quot;;
            Assert.IsNotEmpty(psn.Name);
        }
        [Test]
        [Order(2)]
        public void DemoTest()
        {
            Person psn = new Person();
            Assert.Throws&amp;lt;ArgumentNullException&amp;gt;(() =&amp;gt; psn.WhetherNameContainsB());
        }
       

    }&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;我们再运行,便都能通过了.&lt;/p&gt;
&lt;p&gt;然而这样设计有一个问题,第一如果多个测试方法都要用到这个对象,则需要复制很多,第二如果多个方法之间共用的代码非常多,那么每个方法里都要复制很多代码,我们前面说过单元测试里的代码应力求简洁明了,并且复制同样的代码不利于维护.下面我们介绍Nunit里的Setup&lt;/p&gt;
&lt;h2 id=&quot;setup注释&quot;&gt;&lt;code&gt;Setup注释&lt;/code&gt;&lt;/h2&gt;
&lt;p&gt;在单元测试类中如果把一个方法加上setup注解,则这个方法会先于其它未标的方法执行,并且&lt;code&gt;每个方法执行之前都会执行它&lt;/code&gt;,如果在setup注解的方法内初始化对象,则每个方法运行之前都会运行这个被注解的方法,则每次变量都重新初始化,不会再有数据被共享造成的各种问题了.我们用setup改造后的测试类如下&lt;/p&gt;
&lt;pre class=&quot;cs&quot;&gt;
&lt;code&gt;    [TestFixture]
    public class FirstUnitTest
    {
        private Person psn;
        public FirstUnitTest()
        {
        
         }

        [SetUp]
        public void Setup()
        {
            psn = new Person();
        }
        [Test]
        [Order(1)]
        public void SetPersonName()
        {
          
            psn.Name = &quot;sto&quot;;
            Assert.IsNotEmpty(psn.Name);
        }
        
        [Test]
        [Order(2)]
        public void DemoTest()
        {
           
            Assert.Throws&amp;lt;ArgumentNullException&amp;gt;(() =&amp;gt; psn.WhetherNameContainsB());
        }
       

    }&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;我们在标识为Setup的方法里初始化Person,这样测试就能通过了&lt;/p&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;被Setup注解的方法名可任意取,只要符合命名规范即可&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;Nunit并不限制一个测试类中有多个Setup方法,但是强烈不建议这么做.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;onetimesetup注释&quot;&gt;OneTimeSetup注释&lt;/h2&gt;
&lt;p&gt;OneTimeSetup也是在所有的测试方法运行之前运行,不同的是它并不像SetUp一样每个测试方法运行之前都会运行,而是在所有测试方法运行之前之运行一次.它适用这样场景:比如说我们程序里的数据访问封闭类,这个类里面一般都是访问数据库的各种方法和一些私有的变量像连接字符串之类的,数据访问方法里只会去读取这些字段而不去修改它.最为重要的是每个测试方法运行之前都去实体化一个这样的类会很耗费资源.像这种类型便可以放在OneTimeSetup方法里,在类创建的时候运行一次.&lt;/p&gt;
&lt;p&gt;这个方法功能很像构造函数,它能做的工作一般构造函数也能做.&lt;/p&gt;
&lt;h2 id=&quot;teardown&quot;&gt;Teardown&lt;/h2&gt;
&lt;p&gt;Teardown和Setup用法一样,只是它是在测试方法运行之后才运行,如果我们的测试方法里有需要释放的对象可以在这个方法里释放.&lt;/p&gt;
&lt;h2 id=&quot;onetimeteardown&quot;&gt;OneTimeTearDown&lt;/h2&gt;
&lt;p&gt;它是在所有的方法都运行完之后才运行一次,功能上相当于析构函数,用于在测试类所有方法都执行完以后释放掉类中使用的资源.&lt;/p&gt;
&lt;p&gt;前面部分我们讲了如何在所在单元测试运行之前以及在每一个单元测试之前如何运行一个特定的方法.下面讲解如何在程序集运行之前和运行之后运行某一指定方法.&lt;/p&gt;
&lt;p&gt;可能会有人怀疑这样做的意义,的确,大部分时候我们可能不需要在程序集运行之前或者之后运行某一方法,但是特定的情况下这样做确实会给测试带来很大帮助.比如以下场景&lt;/p&gt;
&lt;ul readability=&quot;9&quot;&gt;&lt;li&gt;我们想要统计一下所有测试方法的运行时间,这时候我们可以在程序集之前启动StopWatch并在所有方法运行完之后获得运行时间,并写入日志.当然这样做可能显得有点傻.&lt;/li&gt;
&lt;li readability=&quot;32.5&quot;&gt;
&lt;p&gt;在Web项目中可能会大量使用ConfigurationManager.AppSetting[xxx]来获取web项目配置,这样做给测试带来难题&lt;/p&gt;
&lt;blockquote readability=&quot;10&quot;&gt;
&lt;p&gt;由于单元测试的运行环境很多时候并非在程序的输出目录,因此web项目使用到AppSetting配置的方法在web环境运行正常,但是在单元测试环境得到的值都是Null,这将会导致测试时大量业务覆盖不到.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote readability=&quot;10&quot;&gt;
&lt;p&gt;在测试的时候我们很难通过传参来改变这个值,因为在程序中往往都是获取AppSetting里的值,而不是设置,因此它往往不包含在方法的参数里.也就没法通过传参来修改它.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote readability=&quot;12&quot;&gt;
&lt;p&gt;我们如果在Setup里给AppSetting赋值,比如ConfigurationManager.AppSettings[&quot;user&quot;] = &quot;sto&quot;;这样在运行的时候我们便可以获取到这个值了,但是AppSetting是全局的,可能程序中很多方法都用到了它,我们在每个测试方法里都写个Setup方法给它复制显然非常boring.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;这时候我们可以在程序集运行之前运行一个方法,在这个方法里给AppSetting赋值,这样测试方法运行的时候使用到AppSetting的地方就可以获取到值了.&lt;/p&gt;
&lt;p&gt;要做到这一点,我们需要新建一个类,并把类上加上SetUpFixture注解.然后方法上加上OneTimeSetUp和OneTimeTeardown注解.这样Nunit就会在程序集加载的时候扫描到这个类,然后对它处理.&lt;/p&gt;
&lt;p&gt;我们看一下示例代码&lt;/p&gt;
&lt;pre class=&quot;cs&quot;&gt;
&lt;code&gt;[SetUpFixture]
public  class AssemblySetup
  {
      [OneTimeSetUp]
      public void RunBeforeEveryMethod()
      {
          ConfigurationManager.AppSettings[&quot;user&quot;] = &quot;sto&quot;;
          ConfigurationManager.AppSettings[&quot;age&quot;] = &quot;32&quot;;
      }
  }&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;我们新建这个类以后&lt;code&gt;RunBeforeEveryMethod&lt;/code&gt;便会在程序集中所有代码运行之前运行了&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;我们看运行结果&lt;br/&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/811801/201908/811801-20190808075804416-944029610.png&quot; alt=&quot;Avatar&quot;/&gt;&lt;br/&gt;我们可以看到,在测试类中随便找一个方法里面去获取值,都可以获取到了.&lt;/p&gt;
&lt;p&gt;前面我们讲解了如何在方法运行前后,在测试类的所有方法运行前后以及如何在程序集,下面我们讲一下如何自定义一个方法在测试方法运行之前/之后运行.&lt;/p&gt;
&lt;p&gt;自定义方法的优势在于如果每个测试类的setup里运行的代码基本相同,只是稍微有一点差异,这样就会导致代码重复的问题.比如我们要在方法运行之前和之后记录一些日志,这样我们就可以自定义一个方法实现在测试方法运行前后运行这个自定义方法,减少代码重复.&lt;/p&gt;
&lt;p&gt;要实现自定义运行方法,我们要继承TestactionAttribute&lt;br/&gt;示例代码如下&lt;/p&gt;
&lt;pre class=&quot;cs&quot;&gt;
&lt;code&gt;public class MyTestAction:TestActionAttribute
    {
        public override void BeforeTest(ITest test)
        {
            Console.WriteLine(&quot;★★★★★★★★★★&quot; + test.FullName);
        }
       
    }&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;我们用Console.WriteLine模拟.&lt;/p&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;Itest对象由Nunit在运行时注入.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;然后我们要在运行这个自定义方法的类上加上&lt;code&gt;MyTestAction&lt;/code&gt;注解即可.&lt;/p&gt;
&lt;p&gt;自定义运行方法非常强大,还可以提供参数,这样会在大幅度减少相似代码的重复,提高可维护性,大家要以后的测试中慢慢体会.&lt;/p&gt;
</description>
<pubDate>Thu, 08 Aug 2019 00:04:00 +0000</pubDate>
<dc:creator>周国通</dc:creator>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/tylerzhou/p/11318911.html</dc:identifier>
</item>
<item>
<title>老板叫你别阻塞了 - LieBrother</title>
<link>http://www.cnblogs.com/liebrother/p/11318906.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/liebrother/p/11318906.html</guid>
<description>&lt;p&gt;&lt;img src=&quot;http://www.liebrother.com/upload/2a7d7e15b6b54d39806996f8ab877f0d_xc0004_01.jpg&quot;/&gt;&lt;/p&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;Java 多线程系列文章第 4 篇。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;继续咱们的 Java 多线程系列文章，今天再讲讲概念，这篇应该是最后一篇基础概念，接下来就直接进入 Java 多线程主题了，在后面的文章里如果有概念需要单独拿出来讲时再补充概念篇。&lt;/p&gt;
&lt;p&gt;这篇文章主要讲讲&lt;strong&gt;阻塞（Blocking）&lt;/strong&gt;和&lt;strong&gt;非阻塞（Non-blocking）&lt;/strong&gt;。&lt;/p&gt;
&lt;h2 id=&quot;上班后必学第一技能&quot;&gt;上班后必学第一技能&lt;/h2&gt;
&lt;p&gt;以前在学校做项目，基本上都是独立开发，每个人开发一个部分，以最小化沟通成本的方式划分工作量。到了职场，单纯的以最小化对接成本来安排工作是几乎不可能的，要考虑的因素变多了，各种跨小组、跨部门、甚至跨职场的工作，这就带来了沟通成本以及工作对接的各种阻塞问题。&lt;/p&gt;
&lt;p&gt;新人刚入职场的时候，对一切都不熟悉，在做一些小组以外的对接工作时，就会遇到种种问题，特别现在充斥着各种分布式架构，以前开发 Web 后台的同学要会开发 JSP 页面，而现在前后端都分离了。设想一下这个场景。&lt;/p&gt;
&lt;p&gt;小明是学习前端出身，刚开始步入职场，做的第一个需求就是登录和注册界面，需要对接一个写后台的同事小东，小东负责开发登录和注册的后台逻辑。小明开发了登录界面，准备和小东对接联调登录功能，这时小东回复说他刚好有生产 bug 在跟进，还没开发好，这时小明该怎么做？&lt;/p&gt;
&lt;p&gt;有 2 种做法：&lt;/p&gt;
&lt;ol readability=&quot;-0.5&quot;&gt;&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;干等着小东开发好登录后台，再和他联调。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;开发注册界面，开发过程中再时刻询问小东登录后台接口是否做完了，如果小东做完了，再去对接。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;这 2 种做法的关键区别是什么呢？对于小东来说，没啥区别，他能做的就是尽量早点实现他的功能点。主要关注小明，第一种做法，小明做好了登录界面，接着则等待小东的登录后台接口，如果小东要开发一下午，那么小明就一下午啥事也不干，这种情况就是&lt;strong&gt;阻塞&lt;/strong&gt;，小明的其他任务因为登录界面没对接联调，而一直阻塞着；第二种做法，小明得知小东登录后台接口还没实现，就着手先做注册界面的功能，然后每过一个小时跟小东确认一下登录后台接口开发是否开发完成，直到小东开发完登录后台接口，便开始对接联调，这种情况就是&lt;strong&gt;非阻塞&lt;/strong&gt;，登录界面没对接联调完全不影响小明的开发进度，能联调的时候就联调，无法联调就完成手头上的其他任务。&lt;/p&gt;
&lt;p&gt;可能有些同学初入职场会犯这类错误，做的功能依赖别人，因为别人还没做完，然后就采用第一种做法，一直干等着，直到对方完成后再继续工作。偶尔偷偷懒还行，如果一直是这样的工作状态，对初入职场的同学没有好处，而且这个被老板知道很不好。&lt;strong&gt;如果某一个需求点阻塞了，应该就先做手头上其他工作，如果手头上没其他工作，就跟老板反馈情况后领其他任务做，还要时刻去跟进阻塞的需求点的进度。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;下面用流程图来描述这 2 个概念：&lt;/p&gt;
&lt;h3 id=&quot;阻塞&quot;&gt;阻塞&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;http://www.liebrother.com/upload/524a6b6d51974b6aaffcb3a4ae82af14_01.jpg&quot; alt=&quot;阻塞&quot;/&gt;&lt;/p&gt;
&lt;h3 id=&quot;非阻塞&quot;&gt;非阻塞&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;http://www.liebrother.com/upload/dd2c2cb241de4733afe6ad1610189194_02.jpg&quot; alt=&quot;非阻塞&quot;/&gt;&lt;/p&gt;
&lt;p&gt;看了上面的图，是不是更加理解阻塞与非阻塞了呢？&lt;/p&gt;
&lt;h2 id=&quot;老板说了算&quot;&gt;老板说了算&lt;/h2&gt;
&lt;p&gt;如果你是老板，或者说是小明的领导，你会让小明怎么做？第一种做法还是第二种做法呢？有支持第一种做法的，麻烦联系我，你们公司还招人么？&lt;/p&gt;
&lt;p&gt;&lt;code&gt;推荐阅读&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s/Euc2NKvK_TsqvcT-DWpD5A&quot;&gt;吃个快餐都能学到串行、并行、并发&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s/yWqFw_S7suYpqszuJFDsGg&quot;&gt;泡一杯茶，学一学同异步&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s/HJIVxnzyDesYPGGyJsaFyQ&quot;&gt;进程知多少？&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s/WiPwb7AyVlxyr1_kYXt96w&quot;&gt;设计模式看了又忘，忘了又看？&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;后台回复『设计模式』可以获取《一故事一设计模式》电子书&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;觉得文章有用帮忙转发&amp;amp;点赞，多谢朋友们！&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://www.liebrother.com/upload/c50a23a8826d45a7b66b3be24c89205e_.jpg&quot; alt=&quot;LieBrother&quot;/&gt;&lt;/p&gt;
</description>
<pubDate>Wed, 07 Aug 2019 23:58:00 +0000</pubDate>
<dc:creator>LieBrother</dc:creator>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/liebrother/p/11318906.html</dc:identifier>
</item>
<item>
<title>Hadoop 系列（八）—— 基于 ZooKeeper 搭建 Hadoop 高可用集群 - 黑白影</title>
<link>http://www.cnblogs.com/heibaiying/p/11318886.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/heibaiying/p/11318886.html</guid>
<description>&lt;h2 id=&quot;一高可用简介&quot;&gt;一、高可用简介&lt;/h2&gt;
&lt;p&gt;Hadoop 高可用 (High Availability) 分为 HDFS 高可用和 YARN 高可用，两者的实现基本类似，但 HDFS NameNode 对数据存储及其一致性的要求比 YARN ResourceManger 高得多，所以它的实现也更加复杂，故下面先进行讲解：&lt;/p&gt;
&lt;h3 id=&quot;高可用整体架构&quot;&gt;1.1 高可用整体架构&lt;/h3&gt;
&lt;p&gt;HDFS 高可用架构如下：&lt;/p&gt;
&lt;div align=&quot;center&quot;&gt;&lt;img src=&quot;https://raw.githubusercontent.com/heibaiying/BigData-Notes/master/pictures/HDFS-HA-Architecture-Edureka.png&quot;/&gt;&lt;/div&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;&lt;em&gt;图片引用自：https://www.edureka.co/blog/how-to-set-up-hadoop-cluster-with-hdfs-high-availability/&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;HDFS 高可用架构主要由以下组件所构成：&lt;/p&gt;
&lt;ul readability=&quot;7&quot;&gt;&lt;li readability=&quot;1&quot;&gt;
&lt;p&gt;&lt;strong&gt;Active NameNode 和 Standby NameNode&lt;/strong&gt;：两台 NameNode 形成互备，一台处于 Active 状态，为主 NameNode，另外一台处于 Standby 状态，为备 NameNode，只有主 NameNode 才能对外提供读写服务。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;2&quot;&gt;
&lt;p&gt;&lt;strong&gt;主备切换控制器 ZKFailoverController&lt;/strong&gt;：ZKFailoverController 作为独立的进程运行，对 NameNode 的主备切换进行总体控制。ZKFailoverController 能及时检测到 NameNode 的健康状况，在主 NameNode 故障时借助 Zookeeper 实现自动的主备选举和切换，当然 NameNode 目前也支持不依赖于 Zookeeper 的手动主备切换。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;&lt;strong&gt;Zookeeper 集群&lt;/strong&gt;：为主备切换控制器提供主备选举支持。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;2&quot;&gt;
&lt;p&gt;&lt;strong&gt;共享存储系统&lt;/strong&gt;：共享存储系统是实现 NameNode 的高可用最为关键的部分，共享存储系统保存了 NameNode 在运行过程中所产生的 HDFS 的元数据。主 NameNode 和 NameNode 通过共享存储系统实现元数据同步。在进行主备切换的时候，新的主 NameNode 在确认元数据完全同步之后才能继续对外提供服务。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;1&quot;&gt;
&lt;p&gt;&lt;strong&gt;DataNode 节点&lt;/strong&gt;：除了通过共享存储系统共享 HDFS 的元数据信息之外，主 NameNode 和备 NameNode 还需要共享 HDFS 的数据块和 DataNode 之间的映射关系。DataNode 会同时向主 NameNode 和备 NameNode 上报数据块的位置信息。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;h3 id=&quot;基于-qjm-的共享存储系统的数据同步机制分析&quot;&gt;1.2 基于 QJM 的共享存储系统的数据同步机制分析&lt;/h3&gt;
&lt;p&gt;目前 Hadoop 支持使用 Quorum Journal Manager (QJM) 或 Network File System (NFS) 作为共享的存储系统，这里以 QJM 集群为例进行说明：Active NameNode 首先把 EditLog 提交到 JournalNode 集群，然后 Standby NameNode 再从 JournalNode 集群定时同步 EditLog，当 Active NameNode 宕机后， Standby NameNode 在确认元数据完全同步之后就可以对外提供服务。&lt;/p&gt;
&lt;p&gt;需要说明的是向 JournalNode 集群写入 EditLog 是遵循 “过半写入则成功” 的策略，所以你至少要有 3 个 JournalNode 节点，当然你也可以继续增加节点数量，但是应该保证节点总数是奇数。同时如果有 2N+1 台 JournalNode，那么根据过半写的原则，最多可以容忍有 N 台 JournalNode 节点挂掉。&lt;/p&gt;
&lt;div align=&quot;center&quot;&gt;&lt;img src=&quot;https://raw.githubusercontent.com/heibaiying/BigData-Notes/master/pictures/hadoop-QJM-%E5%90%8C%E6%AD%A5%E6%9C%BA%E5%88%B6.png&quot;/&gt;&lt;/div&gt;
&lt;h3 id=&quot;namenode-主备切换&quot;&gt;1.3 NameNode 主备切换&lt;/h3&gt;
&lt;p&gt;NameNode 实现主备切换的流程下图所示：&lt;/p&gt;
&lt;div align=&quot;center&quot;&gt;&lt;img src=&quot;https://raw.githubusercontent.com/heibaiying/BigData-Notes/master/pictures/hadoop-namenode%E4%B8%BB%E5%A4%87%E5%88%87%E6%8D%A2.png&quot;/&gt;&lt;/div&gt;
&lt;ol&gt;&lt;li&gt;HealthMonitor 初始化完成之后会启动内部的线程来定时调用对应 NameNode 的 HAServiceProtocol RPC 接口的方法，对 NameNode 的健康状态进行检测。&lt;/li&gt;
&lt;li&gt;HealthMonitor 如果检测到 NameNode 的健康状态发生变化，会回调 ZKFailoverController 注册的相应方法进行处理。&lt;/li&gt;
&lt;li&gt;如果 ZKFailoverController 判断需要进行主备切换，会首先使用 ActiveStandbyElector 来进行自动的主备选举。&lt;/li&gt;
&lt;li&gt;ActiveStandbyElector 与 Zookeeper 进行交互完成自动的主备选举。&lt;/li&gt;
&lt;li&gt;ActiveStandbyElector 在主备选举完成后，会回调 ZKFailoverController 的相应方法来通知当前的 NameNode 成为主 NameNode 或备 NameNode。&lt;/li&gt;
&lt;li&gt;ZKFailoverController 调用对应 NameNode 的 HAServiceProtocol RPC 接口的方法将 NameNode 转换为 Active 状态或 Standby 状态。&lt;/li&gt;
&lt;/ol&gt;&lt;h3 id=&quot;yarn高可用&quot;&gt;1.4 YARN高可用&lt;/h3&gt;
&lt;p&gt;YARN ResourceManager 的高可用与 HDFS NameNode 的高可用类似，但是 ResourceManager 不像 NameNode ，没有那么多的元数据信息需要维护，所以它的状态信息可以直接写到 Zookeeper 上，并依赖 Zookeeper 来进行主备选举。&lt;/p&gt;
&lt;div align=&quot;center&quot;&gt;&lt;img src=&quot;https://raw.githubusercontent.com/heibaiying/BigData-Notes/master/pictures/hadoop-rm-ha-overview.png&quot;/&gt;&lt;/div&gt;
&lt;h2 id=&quot;二集群规划&quot;&gt;二、集群规划&lt;/h2&gt;
&lt;p&gt;按照高可用的设计目标：需要保证至少有两个 NameNode (一主一备) 和 两个 ResourceManager (一主一备) ，同时为满足“过半写入则成功”的原则，需要至少要有 3 个 JournalNode 节点。这里使用三台主机进行搭建，集群规划如下：&lt;/p&gt;
&lt;div align=&quot;center&quot;&gt;&lt;img src=&quot;https://raw.githubusercontent.com/heibaiying/BigData-Notes/master/pictures/hadoop%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%E8%A7%84%E5%88%92.png&quot;/&gt;&lt;/div&gt;
&lt;h2 id=&quot;三前置条件&quot;&gt;三、前置条件&lt;/h2&gt;
&lt;h2 id=&quot;四集群配置&quot;&gt;四、集群配置&lt;/h2&gt;
&lt;h3 id=&quot;下载并解压&quot;&gt;4.1 下载并解压&lt;/h3&gt;
&lt;p&gt;下载 Hadoop。这里我下载的是 CDH 版本 Hadoop，下载地址为：http://archive.cloudera.com/cdh5/cdh/5/&lt;/p&gt;
&lt;pre class=&quot;shell&quot;&gt;
&lt;code&gt;# tar -zvxf hadoop-2.6.0-cdh5.15.2.tar.gz &lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;配置环境变量&quot;&gt;4.2 配置环境变量&lt;/h3&gt;
&lt;p&gt;编辑 &lt;code&gt;profile&lt;/code&gt; 文件：&lt;/p&gt;
&lt;pre class=&quot;shell&quot;&gt;
&lt;code&gt;# vim /etc/profile&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;增加如下配置：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;export HADOOP_HOME=/usr/app/hadoop-2.6.0-cdh5.15.2
export  PATH=${HADOOP_HOME}/bin:$PATH&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;执行 &lt;code&gt;source&lt;/code&gt; 命令，使得配置立即生效：&lt;/p&gt;
&lt;pre class=&quot;shell&quot;&gt;
&lt;code&gt;# source /etc/profile&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;修改配置&quot;&gt;4.3 修改配置&lt;/h3&gt;
&lt;p&gt;进入 &lt;code&gt;${HADOOP_HOME}/etc/hadoop&lt;/code&gt; 目录下，修改配置文件。各个配置文件内容如下：&lt;/p&gt;
&lt;h4 id=&quot;hadoop-env.sh&quot;&gt;1. hadoop-env.sh&lt;/h4&gt;
&lt;pre class=&quot;shell&quot;&gt;
&lt;code&gt;# 指定JDK的安装位置
export JAVA_HOME=/usr/java/jdk1.8.0_201/&lt;/code&gt;
&lt;/pre&gt;
&lt;h4 id=&quot;core-site.xml&quot;&gt;2. core-site.xml&lt;/h4&gt;
&lt;pre class=&quot;xml&quot;&gt;
&lt;code&gt;&amp;lt;configuration&amp;gt;
    &amp;lt;property&amp;gt;
        &amp;lt;!-- 指定 namenode 的 hdfs 协议文件系统的通信地址 --&amp;gt;
        &amp;lt;name&amp;gt;fs.defaultFS&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;hdfs://hadoop001:8020&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
    &amp;lt;property&amp;gt;
        &amp;lt;!-- 指定 hadoop 集群存储临时文件的目录 --&amp;gt;
        &amp;lt;name&amp;gt;hadoop.tmp.dir&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;/home/hadoop/tmp&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
    &amp;lt;property&amp;gt;
        &amp;lt;!-- ZooKeeper 集群的地址 --&amp;gt;
        &amp;lt;name&amp;gt;ha.zookeeper.quorum&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;hadoop001:2181,hadoop002:2181,hadoop002:2181&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
    &amp;lt;property&amp;gt;
        &amp;lt;!-- ZKFC 连接到 ZooKeeper 超时时长 --&amp;gt;
        &amp;lt;name&amp;gt;ha.zookeeper.session-timeout.ms&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;10000&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
&amp;lt;/configuration&amp;gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;h4 id=&quot;hdfs-site.xml&quot;&gt;3. hdfs-site.xml&lt;/h4&gt;
&lt;pre class=&quot;xml&quot;&gt;
&lt;code&gt;&amp;lt;configuration&amp;gt;
    &amp;lt;property&amp;gt;
        &amp;lt;!-- 指定 HDFS 副本的数量 --&amp;gt;
        &amp;lt;name&amp;gt;dfs.replication&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;3&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
    &amp;lt;property&amp;gt;
        &amp;lt;!-- namenode 节点数据（即元数据）的存放位置，可以指定多个目录实现容错，多个目录用逗号分隔 --&amp;gt;
        &amp;lt;name&amp;gt;dfs.namenode.name.dir&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;/home/hadoop/namenode/data&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
    &amp;lt;property&amp;gt;
        &amp;lt;!-- datanode 节点数据（即数据块）的存放位置 --&amp;gt;
        &amp;lt;name&amp;gt;dfs.datanode.data.dir&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;/home/hadoop/datanode/data&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
    &amp;lt;property&amp;gt;
        &amp;lt;!-- 集群服务的逻辑名称 --&amp;gt;
        &amp;lt;name&amp;gt;dfs.nameservices&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;mycluster&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
    &amp;lt;property&amp;gt;
        &amp;lt;!-- NameNode ID 列表--&amp;gt;
        &amp;lt;name&amp;gt;dfs.ha.namenodes.mycluster&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;nn1,nn2&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
    &amp;lt;property&amp;gt;
        &amp;lt;!-- nn1 的 RPC 通信地址 --&amp;gt;
        &amp;lt;name&amp;gt;dfs.namenode.rpc-address.mycluster.nn1&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;hadoop001:8020&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
    &amp;lt;property&amp;gt;
        &amp;lt;!-- nn2 的 RPC 通信地址 --&amp;gt;
        &amp;lt;name&amp;gt;dfs.namenode.rpc-address.mycluster.nn2&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;hadoop002:8020&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
    &amp;lt;property&amp;gt;
        &amp;lt;!-- nn1 的 http 通信地址 --&amp;gt;
        &amp;lt;name&amp;gt;dfs.namenode.http-address.mycluster.nn1&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;hadoop001:50070&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
    &amp;lt;property&amp;gt;
        &amp;lt;!-- nn2 的 http 通信地址 --&amp;gt;
        &amp;lt;name&amp;gt;dfs.namenode.http-address.mycluster.nn2&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;hadoop002:50070&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
    &amp;lt;property&amp;gt;
        &amp;lt;!-- NameNode 元数据在 JournalNode 上的共享存储目录 --&amp;gt;
        &amp;lt;name&amp;gt;dfs.namenode.shared.edits.dir&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;qjournal://hadoop001:8485;hadoop002:8485;hadoop003:8485/mycluster&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
    &amp;lt;property&amp;gt;
        &amp;lt;!-- Journal Edit Files 的存储目录 --&amp;gt;
        &amp;lt;name&amp;gt;dfs.journalnode.edits.dir&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;/home/hadoop/journalnode/data&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
    &amp;lt;property&amp;gt;
        &amp;lt;!-- 配置隔离机制，确保在任何给定时间只有一个 NameNode 处于活动状态 --&amp;gt;
        &amp;lt;name&amp;gt;dfs.ha.fencing.methods&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;sshfence&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
    &amp;lt;property&amp;gt;
        &amp;lt;!-- 使用 sshfence 机制时需要 ssh 免密登录 --&amp;gt;
        &amp;lt;name&amp;gt;dfs.ha.fencing.ssh.private-key-files&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;/root/.ssh/id_rsa&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
    &amp;lt;property&amp;gt;
        &amp;lt;!-- SSH 超时时间 --&amp;gt;
        &amp;lt;name&amp;gt;dfs.ha.fencing.ssh.connect-timeout&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;30000&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
    &amp;lt;property&amp;gt;
        &amp;lt;!-- 访问代理类，用于确定当前处于 Active 状态的 NameNode --&amp;gt;
        &amp;lt;name&amp;gt;dfs.client.failover.proxy.provider.mycluster&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
    &amp;lt;property&amp;gt;
        &amp;lt;!-- 开启故障自动转移 --&amp;gt;
        &amp;lt;name&amp;gt;dfs.ha.automatic-failover.enabled&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;true&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
&amp;lt;/configuration&amp;gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;h4 id=&quot;yarn-site.xml&quot;&gt;4. yarn-site.xml&lt;/h4&gt;
&lt;pre class=&quot;xml&quot;&gt;
&lt;code&gt;&amp;lt;configuration&amp;gt;
    &amp;lt;property&amp;gt;
        &amp;lt;!--配置 NodeManager 上运行的附属服务。需要配置成 mapreduce_shuffle 后才可以在 Yarn 上运行 MapReduce 程序。--&amp;gt;
        &amp;lt;name&amp;gt;yarn.nodemanager.aux-services&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;mapreduce_shuffle&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
    &amp;lt;property&amp;gt;
        &amp;lt;!-- 是否启用日志聚合 (可选) --&amp;gt;
        &amp;lt;name&amp;gt;yarn.log-aggregation-enable&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;true&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
    &amp;lt;property&amp;gt;
        &amp;lt;!-- 聚合日志的保存时间 (可选) --&amp;gt;
        &amp;lt;name&amp;gt;yarn.log-aggregation.retain-seconds&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;86400&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
    &amp;lt;property&amp;gt;
        &amp;lt;!-- 启用 RM HA --&amp;gt;
        &amp;lt;name&amp;gt;yarn.resourcemanager.ha.enabled&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;true&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
    &amp;lt;property&amp;gt;
        &amp;lt;!-- RM 集群标识 --&amp;gt;
        &amp;lt;name&amp;gt;yarn.resourcemanager.cluster-id&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;my-yarn-cluster&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
    &amp;lt;property&amp;gt;
        &amp;lt;!-- RM 的逻辑 ID 列表 --&amp;gt;
        &amp;lt;name&amp;gt;yarn.resourcemanager.ha.rm-ids&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;rm1,rm2&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
    &amp;lt;property&amp;gt;
        &amp;lt;!-- RM1 的服务地址 --&amp;gt;
        &amp;lt;name&amp;gt;yarn.resourcemanager.hostname.rm1&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;hadoop002&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
    &amp;lt;property&amp;gt;
        &amp;lt;!-- RM2 的服务地址 --&amp;gt;
        &amp;lt;name&amp;gt;yarn.resourcemanager.hostname.rm2&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;hadoop003&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
    &amp;lt;property&amp;gt;
        &amp;lt;!-- RM1 Web 应用程序的地址 --&amp;gt;
        &amp;lt;name&amp;gt;yarn.resourcemanager.webapp.address.rm1&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;hadoop002:8088&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
    &amp;lt;property&amp;gt;
        &amp;lt;!-- RM2 Web 应用程序的地址 --&amp;gt;
        &amp;lt;name&amp;gt;yarn.resourcemanager.webapp.address.rm2&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;hadoop003:8088&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
    &amp;lt;property&amp;gt;
        &amp;lt;!-- ZooKeeper 集群的地址 --&amp;gt;
        &amp;lt;name&amp;gt;yarn.resourcemanager.zk-address&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;hadoop001:2181,hadoop002:2181,hadoop003:2181&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
    &amp;lt;property&amp;gt;
        &amp;lt;!-- 启用自动恢复 --&amp;gt;
        &amp;lt;name&amp;gt;yarn.resourcemanager.recovery.enabled&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;true&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
    &amp;lt;property&amp;gt;
        &amp;lt;!-- 用于进行持久化存储的类 --&amp;gt;
        &amp;lt;name&amp;gt;yarn.resourcemanager.store.class&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
&amp;lt;/configuration&amp;gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;h4 id=&quot;mapred-site.xml&quot;&gt;5. mapred-site.xml&lt;/h4&gt;
&lt;pre class=&quot;xml&quot;&gt;
&lt;code&gt;&amp;lt;configuration&amp;gt;
    &amp;lt;property&amp;gt;
        &amp;lt;!--指定 mapreduce 作业运行在 yarn 上--&amp;gt;
        &amp;lt;name&amp;gt;mapreduce.framework.name&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;yarn&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
&amp;lt;/configuration&amp;gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;h4 id=&quot;slaves&quot;&gt;5. slaves&lt;/h4&gt;
&lt;p&gt;配置所有从属节点的主机名或 IP 地址，每行一个。所有从属节点上的 &lt;code&gt;DataNode&lt;/code&gt; 服务和 &lt;code&gt;NodeManager&lt;/code&gt; 服务都会被启动。&lt;/p&gt;
&lt;pre class=&quot;properties&quot;&gt;
&lt;code&gt;hadoop001
hadoop002
hadoop003&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;分发程序&quot;&gt;4.4 分发程序&lt;/h3&gt;
&lt;p&gt;将 Hadoop 安装包分发到其他两台服务器，分发后建议在这两台服务器上也配置一下 Hadoop 的环境变量。&lt;/p&gt;
&lt;pre class=&quot;shell&quot;&gt;
&lt;code&gt;# 将安装包分发到hadoop002
scp -r /usr/app/hadoop-2.6.0-cdh5.15.2/  hadoop002:/usr/app/
# 将安装包分发到hadoop003
scp -r /usr/app/hadoop-2.6.0-cdh5.15.2/  hadoop003:/usr/app/&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;五启动集群&quot;&gt;五、启动集群&lt;/h2&gt;
&lt;h3 id=&quot;启动zookeeper&quot;&gt;5.1 启动ZooKeeper&lt;/h3&gt;
&lt;p&gt;分别到三台服务器上启动 ZooKeeper 服务：&lt;/p&gt;
&lt;pre class=&quot;ssh&quot;&gt;
&lt;code&gt; zkServer.sh start&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;启动journalnode&quot;&gt;5.2 启动Journalnode&lt;/h3&gt;
&lt;p&gt;分别到三台服务器的的 &lt;code&gt;${HADOOP_HOME}/sbin&lt;/code&gt; 目录下，启动 &lt;code&gt;journalnode&lt;/code&gt; 进程：&lt;/p&gt;
&lt;pre class=&quot;shell&quot;&gt;
&lt;code&gt;hadoop-daemon.sh start journalnode&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;初始化namenode&quot;&gt;5.3 初始化NameNode&lt;/h3&gt;
&lt;p&gt;在 &lt;code&gt;hadop001&lt;/code&gt; 上执行 &lt;code&gt;NameNode&lt;/code&gt; 初始化命令：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;hdfs namenode -format&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;执行初始化命令后，需要将 &lt;code&gt;NameNode&lt;/code&gt; 元数据目录的内容，复制到其他未格式化的 &lt;code&gt;NameNode&lt;/code&gt; 上。元数据存储目录就是我们在 &lt;code&gt;hdfs-site.xml&lt;/code&gt; 中使用 &lt;code&gt;dfs.namenode.name.dir&lt;/code&gt; 属性指定的目录。这里我们需要将其复制到 &lt;code&gt;hadoop002&lt;/code&gt; 上：&lt;/p&gt;
&lt;pre class=&quot;shell&quot;&gt;
&lt;code&gt; scp -r /home/hadoop/namenode/data hadoop002:/home/hadoop/namenode/&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;初始化ha状态&quot;&gt;5.4 初始化HA状态&lt;/h3&gt;
&lt;p&gt;在任意一台 &lt;code&gt;NameNode&lt;/code&gt; 上使用以下命令来初始化 ZooKeeper 中的 HA 状态：&lt;/p&gt;
&lt;pre class=&quot;shell&quot;&gt;
&lt;code&gt;hdfs zkfc -formatZK&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;启动hdfs&quot;&gt;5.5 启动HDFS&lt;/h3&gt;
&lt;p&gt;进入到 &lt;code&gt;hadoop001&lt;/code&gt; 的 &lt;code&gt;${HADOOP_HOME}/sbin&lt;/code&gt; 目录下，启动 HDFS。此时 &lt;code&gt;hadoop001&lt;/code&gt; 和 &lt;code&gt;hadoop002&lt;/code&gt; 上的 &lt;code&gt;NameNode&lt;/code&gt; 服务，和三台服务器上的 &lt;code&gt;DataNode&lt;/code&gt; 服务都会被启动：&lt;/p&gt;
&lt;pre class=&quot;shell&quot;&gt;
&lt;code&gt;start-dfs.sh&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;启动yarn&quot;&gt;5.6 启动YARN&lt;/h3&gt;
&lt;p&gt;进入到 &lt;code&gt;hadoop002&lt;/code&gt; 的 &lt;code&gt;${HADOOP_HOME}/sbin&lt;/code&gt; 目录下，启动 YARN。此时 &lt;code&gt;hadoop002&lt;/code&gt; 上的 &lt;code&gt;ResourceManager&lt;/code&gt; 服务，和三台服务器上的 &lt;code&gt;NodeManager&lt;/code&gt; 服务都会被启动：&lt;/p&gt;
&lt;pre class=&quot;shell&quot;&gt;
&lt;code&gt;start-yarn.sh&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;需要注意的是，这个时候 &lt;code&gt;hadoop003&lt;/code&gt; 上的 &lt;code&gt;ResourceManager&lt;/code&gt; 服务通常是没有启动的，需要手动启动：&lt;/p&gt;
&lt;pre class=&quot;shell&quot;&gt;
&lt;code&gt;yarn-daemon.sh start resourcemanager&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;六查看集群&quot;&gt;六、查看集群&lt;/h2&gt;
&lt;h3 id=&quot;查看进程&quot;&gt;6.1 查看进程&lt;/h3&gt;
&lt;p&gt;成功启动后，每台服务器上的进程应该如下：&lt;/p&gt;
&lt;pre class=&quot;shell&quot;&gt;
&lt;code&gt;[root@hadoop001 sbin]# jps
4512 DFSZKFailoverController
3714 JournalNode
4114 NameNode
3668 QuorumPeerMain
5012 DataNode
4639 NodeManager


[root@hadoop002 sbin]# jps
4499 ResourceManager
4595 NodeManager
3465 QuorumPeerMain
3705 NameNode
3915 DFSZKFailoverController
5211 DataNode
3533 JournalNode


[root@hadoop003 sbin]# jps
3491 JournalNode
3942 NodeManager
4102 ResourceManager
4201 DataNode
3435 QuorumPeerMain&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;查看web-ui&quot;&gt;6.2 查看Web UI&lt;/h3&gt;
&lt;p&gt;HDFS 和 YARN 的端口号分别为 &lt;code&gt;50070&lt;/code&gt; 和 &lt;code&gt;8080&lt;/code&gt;，界面应该如下：&lt;/p&gt;
&lt;p&gt;此时 hadoop001 上的 &lt;code&gt;NameNode&lt;/code&gt; 处于可用状态：&lt;/p&gt;
&lt;div align=&quot;center&quot;&gt;&lt;img src=&quot;https://raw.githubusercontent.com/heibaiying/BigData-Notes/master/pictures/hadoop%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A41.png&quot;/&gt;&lt;/div&gt;
&lt;p&gt;而 hadoop002 上的 &lt;code&gt;NameNode&lt;/code&gt; 则处于备用状态：&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;&lt;img src=&quot;https://raw.githubusercontent.com/heibaiying/BigData-Notes/master/pictures/hadoop%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A43.png&quot;/&gt;&lt;/div&gt;

&lt;p&gt;hadoop002 上的 &lt;code&gt;ResourceManager&lt;/code&gt; 处于可用状态：&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;&lt;img src=&quot;https://raw.githubusercontent.com/heibaiying/BigData-Notes/master/pictures/hadoop%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A44.png&quot;/&gt;&lt;/div&gt;

&lt;p&gt;hadoop003 上的 &lt;code&gt;ResourceManager&lt;/code&gt; 则处于备用状态：&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;&lt;img src=&quot;https://raw.githubusercontent.com/heibaiying/BigData-Notes/master/pictures/hadoop%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A45.png&quot;/&gt;&lt;/div&gt;

&lt;p&gt;同时界面上也有 &lt;code&gt;Journal Manager&lt;/code&gt; 的相关信息：&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;&lt;img src=&quot;https://raw.githubusercontent.com/heibaiying/BigData-Notes/master/pictures/hadoop%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A42.png&quot;/&gt;&lt;/div&gt;
&lt;h2 id=&quot;七集群的二次启动&quot;&gt;七、集群的二次启动&lt;/h2&gt;
&lt;p&gt;上面的集群初次启动涉及到一些必要初始化操作，所以过程略显繁琐。但是集群一旦搭建好后，想要再次启用它是比较方便的，步骤如下（首选需要确保 ZooKeeper 集群已经启动）：&lt;/p&gt;
&lt;p&gt;在 &lt;code&gt;hadoop001&lt;/code&gt; 启动 HDFS，此时会启动所有与 HDFS 高可用相关的服务，包括 NameNode，DataNode 和 JournalNode：&lt;/p&gt;
&lt;pre class=&quot;shell&quot;&gt;
&lt;code&gt;start-dfs.sh&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;在 &lt;code&gt;hadoop002&lt;/code&gt; 启动 YARN：&lt;/p&gt;
&lt;pre class=&quot;shell&quot;&gt;
&lt;code&gt;start-yarn.sh&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;这个时候 &lt;code&gt;hadoop003&lt;/code&gt; 上的 &lt;code&gt;ResourceManager&lt;/code&gt; 服务通常还是没有启动的，需要手动启动：&lt;/p&gt;
&lt;pre class=&quot;shell&quot;&gt;
&lt;code&gt;yarn-daemon.sh start resourcemanager&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;参考资料&quot;&gt;参考资料&lt;/h2&gt;
&lt;p&gt;以上搭建步骤主要参考自官方文档：&lt;/p&gt;
&lt;p&gt;关于 Hadoop 高可用原理的详细分析，推荐阅读：&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.ibm.com/developerworks/cn/opensource/os-cn-hadoop-name-node/index.html&quot;&gt;Hadoop NameNode 高可用 (High Availability) 实现解析&lt;/a&gt;&lt;/p&gt;
&lt;blockquote readability=&quot;3.75&quot;&gt;
&lt;p&gt;&lt;strong&gt;更多大数据系列文章可以参见 GitHub 开源项目&lt;/strong&gt;： &lt;a href=&quot;https://github.com/heibaiying/BigData-Notes&quot;&gt;&lt;strong&gt;大数据入门指南&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
</description>
<pubDate>Wed, 07 Aug 2019 23:45:00 +0000</pubDate>
<dc:creator>黑白影</dc:creator>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/heibaiying/p/11318886.html</dc:identifier>
</item>
<item>
<title>Docker系列之烹饪披萨（二） - Jeffcky</title>
<link>http://www.cnblogs.com/CreateMyself/p/11317826.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/CreateMyself/p/11317826.html</guid>
<description>&lt;h2&gt;前言&lt;/h2&gt;
&lt;p&gt;上一篇我们讲解了虚拟机和容器的区别，本节我们来讲讲Docker中关于Dockerfile、镜像、容器等基本概念。Docker是一个在容器内开发、部署、运行应用程序的平台，Docker本质上是容器化的代名词，容器对于提高软件开发和数据科学的安全性，可重复性和可扩展性起到了重要作用，拥抱Docker已是趋势，让我们进入Docker课堂。&lt;/p&gt;
&lt;h2&gt;烹饪材料&lt;/h2&gt;
&lt;p&gt;接下来我们通过学习如何烹饪披萨，一探究竟Docker平台各个基本概念，一说到吃，大家应该马上就提起兴趣了。&lt;/p&gt;
&lt;h3&gt;Docker Container（容器）&lt;/h3&gt;
&lt;p&gt;啥是容器啊，搞的这么高深，这么玄乎的概念，于是乎 ，我终于找到容器是什么了，如下：&lt;/p&gt;
&lt;p&gt; &lt;img src=&quot;https://img2018.cnblogs.com/blog/589642/201908/589642-20190807222546518-1947904509.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;哈哈，这就是容器，还是在某宝上截图来的，不过此容器非彼容器，如上图是一个真实存在的物理收纳箱容器，看到如上真实存在的容器，我们能想到这样一个容器有什么特点呢？&lt;/p&gt;
&lt;blockquote readability=&quot;17&quot;&gt;
&lt;p&gt;1.承载东西-这当然是最基本的啦，既然是收纳箱，就是用来装东西的，有些东西可以放在收纳箱内，也可以放在收纳箱外（这就好比在容器内可以装载应用程序及其依赖）&lt;/p&gt;
&lt;p&gt;2.方便携带-有了收纳箱我们可以随处搬运，就像小孩的玩具一样，可以从家拿到学校，携带方便。（这就好比容器轻巧，可以在任何地方运行）&lt;/p&gt;
&lt;p&gt;3.接口访问-收纳箱上方有一个盖盖，我们将其打开，可以放入或取出物品（这就好比容器与外界有连接的机制，比如通过命令行进行数据交互）&lt;/p&gt;
&lt;p&gt;4.远程获取-制造商通过对应模具模板可以制造出成千上万个收纳箱，然后将收纳箱放到某宝或某东上，最终我们在某宝或某东上购买这个收纳箱（这就好比模具是镜像，通过镜像制作容器）&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;物理形式存在的收纳箱容器从被制造出来的那一刻就被赋予了生命，既然被赋予了生命当然也就存在对应的生命周期，我们可将收纳箱的生命周期归纳为四个阶段：孵化、闲置、使用、废弃。万事万物一旦存在，无论是物理形式还是虚拟形式都有其生命周期，容器也不例外，只不过容器由人为操纵控制其生命周期直至其关闭。&lt;/p&gt;

&lt;p&gt;通过以上引入生活实例物理收纳箱容器的隐喻来对比虚拟化容器，得出虚拟化容器的特点，想必到此应该对容器有了一点点通透的了解。&lt;/p&gt;

&lt;h3&gt;Docker Image（镜像） &lt;/h3&gt;
&lt;p&gt;上述关于关于物理存在的收纳箱容器是以某种实例而存在，虽说容器是虚拟的，但是到底是如何虚拟出来的呢？它是以何种生命形式而存在的呢？答案则是：镜像孕育了容器，也就是说镜像构造出了容器。那么镜像又是什么呢？从语义层面理解，我们可能认为就是图像，而图像可能是根据手机或者摄像机将拍摄范围的全部内容映射到物理图像上，但是事实情况真的如此吗？&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/589642/201908/589642-20190808000403092-2135749662.jpg&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;显然不是，镜像其实就是一个模具或模板，对于收纳箱的模板如下，我们根据模板而刻画出如上漂亮且精致的收纳箱容器。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/589642/201908/589642-20190807235503254-2103196840.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;如上所述，我们根据镜像刻画出了容器，镜像是不可变的主模板，用来抽取出完全相同的容器，而镜像包含应用程序所需要运行的Dockerfile、代码、库等，如此这些被完全捆绑在一起。&lt;/p&gt;
&lt;h3&gt;Dockerfile（镜像说明书）&lt;/h3&gt;
&lt;p&gt;讲完了镜像，我们又有疑惑了，镜像又是怎么来的呢？通过Dockerfile来创建，Dockerfile是一个文件，这个文件中包含了如何构建镜像的说明，Dockerfile只是用来构建初始镜像层的基本镜像，我们可将其看做是镜像的说明书。根据Dockerfile中的使用说明，我们可以将附加层堆叠在基础镜像层的顶部。最后根据Dockerfile代码，在其他层的顶部堆叠薄的可写层，每一层是如此的薄，堆叠可写的过程就好似洋葱的成长过程，多么形象而生动，如果你愿意一层一层，一层的剥开我的心，你会发现 你会讶异....哈哈。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/589642/201908/589642-20190808002803235-2082490871.jpg&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;h3&gt;Container Registry （镜像仓储）&lt;/h3&gt;
&lt;p&gt;如果我们希望其他人能够利用我们的镜像来创建容器，我们可以将镜像传送到容器注册表中，Docker Hub是最大的默认注册表位置。&lt;/p&gt;
&lt;h2&gt;烹饪披萨&lt;/h2&gt;
&lt;p&gt;关于披萨所需要的材料我们都已配齐，接下来我们试试来自制披萨，好不好吃不要紧，重要的是享受制作的过程。&lt;/p&gt;
&lt;p&gt;第一步：我们需要知道制作披萨的配方，这个配方好比Dockerfile，里面包含如何制作出披萨的说明。&lt;/p&gt;
&lt;p&gt;第二步：披萨有几层，比如包含面包层、奶酪层、酱汁层等等，因为配方说明我们知道要做什么，这是不可更改的计划，这就好比我们从底层首先构建出基本的镜像如ubuntu，然后添加奶酪层等，这一层相当于我们安装外部库，比如python，最后再刷上一层泰国甜辣酱，简直是人间美味，这就相当于我们已编写好的应用程序代码，最终就有了披萨的原型，也就形成了Docker Image（镜像），&lt;/p&gt;
&lt;p&gt;第三步：我们做好了披萨，这个时候我们需要将其放入烤箱中，烤箱就好比Docker平台，当我们将买回来的烤箱放在家里，这个时候就好比将Docker安装在计算机上一样，当我们扭动烤箱按钮的那一刻，我们就开始烹饪披萨，这就像我们开始创建并启动容器啦。&lt;/p&gt;
&lt;p&gt;第四步：等待一小会，当披萨熟了，熟透了的披萨就好比Docker容器。&lt;/p&gt;
&lt;p&gt;第五步：最终大功告成，我们开始吃披萨，吃披萨就好比我们在容器中使用应用程序一样。&lt;/p&gt;
&lt;h2&gt;烹饪总结&lt;/h2&gt;
&lt;p&gt;本节我们通过烹饪披萨讲述了Docker平台上基本概念，以及各个基本概念之间的关系，它们是如何关联起来的，希望通过本文的讲解，对于阅读本文的童鞋能对概念有更深入的理解，应该不会通过我的讲解，越讲越懵逼吧，哈哈。有了对基本概念的理解，后续陆续引入例子就一目了然啦，感谢阅读，我们下节再会。 &lt;/p&gt;
</description>
<pubDate>Wed, 07 Aug 2019 23:45:00 +0000</pubDate>
<dc:creator>Jeffcky</dc:creator>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/CreateMyself/p/11317826.html</dc:identifier>
</item>
<item>
<title>RocketMQ中Broker的HA策略源码分析 - 松饼人</title>
<link>http://www.cnblogs.com/a526583280/p/11318884.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/a526583280/p/11318884.html</guid>
<description>&lt;p&gt;Broker的HA策略分为两部分&lt;br/&gt;①同步元数据&lt;br/&gt;②同步消息数据&lt;/p&gt;

&lt;h2&gt;同步元数据&lt;/h2&gt;
&lt;p&gt;在Slave启动时，会启动一个定时任务用来从master同步元数据&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;39&quot;&gt;
&lt;pre&gt;
&lt;span&gt; 1&lt;/span&gt; &lt;span&gt;if&lt;/span&gt; (role ==&lt;span&gt; BrokerRole.SLAVE) {
&lt;/span&gt;&lt;span&gt; 2&lt;/span&gt;     &lt;span&gt;if&lt;/span&gt; (&lt;span&gt;null&lt;/span&gt; !=&lt;span&gt; slaveSyncFuture) {
&lt;/span&gt;&lt;span&gt; 3&lt;/span&gt;         slaveSyncFuture.cancel(&lt;span&gt;false&lt;/span&gt;&lt;span&gt;);
&lt;/span&gt;&lt;span&gt; 4&lt;/span&gt; &lt;span&gt;    }
&lt;/span&gt;&lt;span&gt; 5&lt;/span&gt;     &lt;span&gt;this&lt;/span&gt;.slaveSynchronize.setMasterAddr(&lt;span&gt;null&lt;/span&gt;&lt;span&gt;);
&lt;/span&gt;&lt;span&gt; 6&lt;/span&gt;     slaveSyncFuture = &lt;span&gt;this&lt;/span&gt;.scheduledExecutorService.scheduleAtFixedRate(&lt;span&gt;new&lt;/span&gt;&lt;span&gt; Runnable() {
&lt;/span&gt;&lt;span&gt; 7&lt;/span&gt; &lt;span&gt;        @Override
&lt;/span&gt;&lt;span&gt; 8&lt;/span&gt;         &lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt;&lt;span&gt; run() {
&lt;/span&gt;&lt;span&gt; 9&lt;/span&gt;             &lt;span&gt;try&lt;/span&gt;&lt;span&gt; {
&lt;/span&gt;&lt;span&gt;10&lt;/span&gt;                 BrokerController.&lt;span&gt;this&lt;/span&gt;&lt;span&gt;.slaveSynchronize.syncAll();
&lt;/span&gt;&lt;span&gt;11&lt;/span&gt; &lt;span&gt;            }
&lt;/span&gt;&lt;span&gt;12&lt;/span&gt;             &lt;span&gt;catch&lt;/span&gt;&lt;span&gt; (Throwable e) {
&lt;/span&gt;&lt;span&gt;13&lt;/span&gt;                 log.error(&quot;ScheduledTask SlaveSynchronize syncAll error.&quot;&lt;span&gt;, e);
&lt;/span&gt;&lt;span&gt;14&lt;/span&gt; &lt;span&gt;            }
&lt;/span&gt;&lt;span&gt;15&lt;/span&gt; &lt;span&gt;        }
&lt;/span&gt;&lt;span&gt;16&lt;/span&gt;     }, 1000 * 3, 1000 * 10&lt;span&gt;, TimeUnit.MILLISECONDS);
&lt;/span&gt;&lt;span&gt;17&lt;/span&gt; } 
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;这里设置了定时任务，执行slaveSynchronize的syncAll方法&lt;br/&gt;可以注意在之前会通过setMasterAddr将Master的地址设为null，这是由于在后面会通过另一个定时任务registerBrokerAll来向NameServer获取Master的地址，详见：&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.cnblogs.com/a526583280/p/11300861.html&quot; target=&quot;_blank&quot;&gt;【RocketMQ中Broker的启动源码分析（二）】&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;br/&gt;SlaveSynchronize的syncAll方法：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;33&quot;&gt;
&lt;pre&gt;
&lt;span&gt;1&lt;/span&gt; &lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt;&lt;span&gt; syncAll() {
&lt;/span&gt;&lt;span&gt;2&lt;/span&gt;     &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.syncTopicConfig();
&lt;/span&gt;&lt;span&gt;3&lt;/span&gt;     &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.syncConsumerOffset();
&lt;/span&gt;&lt;span&gt;4&lt;/span&gt;     &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.syncDelayOffset();
&lt;/span&gt;&lt;span&gt;5&lt;/span&gt;     &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.syncSubscriptionGroupConfig();
&lt;/span&gt;&lt;span&gt;6&lt;/span&gt; }
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;这个方法会依次调用四个方法，来同步相应信息：&lt;br/&gt;syncTopicConfig：同步topic的配置信息&lt;br/&gt;syncConsumerOffset：同步Consumer的Offset信息&lt;br/&gt;syncDelayOffset：同步延迟队列信息&lt;br/&gt;syncSubscriptionGroupConfig：同步订阅信息&lt;/p&gt;
&lt;p&gt;&lt;br/&gt;由于这几个方法的实现是类似的，这里就只看下syncTopicConfig的实现：&lt;br/&gt;syncTopicConfig方法：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;40&quot;&gt;
&lt;pre&gt;
&lt;span&gt; 1&lt;/span&gt; &lt;span&gt;private&lt;/span&gt; &lt;span&gt;void&lt;/span&gt;&lt;span&gt; syncTopicConfig() {
&lt;/span&gt;&lt;span&gt; 2&lt;/span&gt;     String masterAddrBak = &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.masterAddr;
&lt;/span&gt;&lt;span&gt; 3&lt;/span&gt;     &lt;span&gt;if&lt;/span&gt; (masterAddrBak != &lt;span&gt;null&lt;/span&gt; &amp;amp;&amp;amp; !&lt;span&gt;masterAddrBak.equals(brokerController.getBrokerAddr())) {
&lt;/span&gt;&lt;span&gt; 4&lt;/span&gt;         &lt;span&gt;try&lt;/span&gt;&lt;span&gt; {
&lt;/span&gt;&lt;span&gt; 5&lt;/span&gt;             TopicConfigSerializeWrapper topicWrapper =
&lt;span&gt; 6&lt;/span&gt;                 &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.brokerController.getBrokerOuterAPI().getAllTopicConfig(masterAddrBak);
&lt;/span&gt;&lt;span&gt; 7&lt;/span&gt;             &lt;span&gt;if&lt;/span&gt; (!&lt;span&gt;this&lt;/span&gt;&lt;span&gt;.brokerController.getTopicConfigManager().getDataVersion()
&lt;/span&gt;&lt;span&gt; 8&lt;/span&gt; &lt;span&gt;                .equals(topicWrapper.getDataVersion())) {
&lt;/span&gt;&lt;span&gt; 9&lt;/span&gt; 
&lt;span&gt;10&lt;/span&gt;                 &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.brokerController.getTopicConfigManager().getDataVersion()
&lt;/span&gt;&lt;span&gt;11&lt;/span&gt; &lt;span&gt;                    .assignNewOne(topicWrapper.getDataVersion());
&lt;/span&gt;&lt;span&gt;12&lt;/span&gt;                 &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.brokerController.getTopicConfigManager().getTopicConfigTable().clear();
&lt;/span&gt;&lt;span&gt;13&lt;/span&gt;                 &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.brokerController.getTopicConfigManager().getTopicConfigTable()
&lt;/span&gt;&lt;span&gt;14&lt;/span&gt; &lt;span&gt;                    .putAll(topicWrapper.getTopicConfigTable());
&lt;/span&gt;&lt;span&gt;15&lt;/span&gt;                 &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.brokerController.getTopicConfigManager().persist();
&lt;/span&gt;&lt;span&gt;16&lt;/span&gt; 
&lt;span&gt;17&lt;/span&gt;                 log.info(&quot;Update slave topic config from master, {}&quot;&lt;span&gt;, masterAddrBak);
&lt;/span&gt;&lt;span&gt;18&lt;/span&gt; &lt;span&gt;            }
&lt;/span&gt;&lt;span&gt;19&lt;/span&gt;         } &lt;span&gt;catch&lt;/span&gt;&lt;span&gt; (Exception e) {
&lt;/span&gt;&lt;span&gt;20&lt;/span&gt;             log.error(&quot;SyncTopicConfig Exception, {}&quot;&lt;span&gt;, masterAddrBak, e);
&lt;/span&gt;&lt;span&gt;21&lt;/span&gt; &lt;span&gt;        }
&lt;/span&gt;&lt;span&gt;22&lt;/span&gt; &lt;span&gt;    }
&lt;/span&gt;&lt;span&gt;23&lt;/span&gt; }
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;这里首先获取master的地址masterAddr，由于registerBrokerAll定时任务的存在，即便这一次没有获取到masterAddr，只要节点中有master，总会在后面定时执行时从NameServer中获取到&lt;/p&gt;
&lt;p&gt;&lt;br/&gt;当获取到master地址后，通过BrokerOuterAPI的getAllTopicConfig方法，向master请求&lt;br/&gt;BrokerOuterAPI的getAllTopicConfig方法：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;45&quot;&gt;
&lt;pre&gt;
&lt;span&gt; 1&lt;/span&gt; &lt;span&gt;public&lt;/span&gt;&lt;span&gt; TopicConfigSerializeWrapper getAllTopicConfig(
&lt;/span&gt;&lt;span&gt; 2&lt;/span&gt;     &lt;span&gt;final&lt;/span&gt; String addr) &lt;span&gt;throws&lt;/span&gt;&lt;span&gt; RemotingConnectException, RemotingSendRequestException,
&lt;/span&gt;&lt;span&gt; 3&lt;/span&gt; &lt;span&gt;    RemotingTimeoutException, InterruptedException, MQBrokerException {
&lt;/span&gt;&lt;span&gt; 4&lt;/span&gt;     RemotingCommand request = RemotingCommand.createRequestCommand(RequestCode.GET_ALL_TOPIC_CONFIG, &lt;span&gt;null&lt;/span&gt;&lt;span&gt;);
&lt;/span&gt;&lt;span&gt; 5&lt;/span&gt; 
&lt;span&gt; 6&lt;/span&gt;     RemotingCommand response = &lt;span&gt;this&lt;/span&gt;.remotingClient.invokeSync(MixAll.brokerVIPChannel(&lt;span&gt;true&lt;/span&gt;, addr), request, 3000&lt;span&gt;);
&lt;/span&gt;&lt;span&gt; 7&lt;/span&gt;     &lt;span&gt;assert&lt;/span&gt; response != &lt;span&gt;null&lt;/span&gt;&lt;span&gt;;
&lt;/span&gt;&lt;span&gt; 8&lt;/span&gt;     &lt;span&gt;switch&lt;/span&gt;&lt;span&gt; (response.getCode()) {
&lt;/span&gt;&lt;span&gt; 9&lt;/span&gt;         &lt;span&gt;case&lt;/span&gt;&lt;span&gt; ResponseCode.SUCCESS: {
&lt;/span&gt;&lt;span&gt;10&lt;/span&gt;             &lt;span&gt;return&lt;/span&gt; TopicConfigSerializeWrapper.decode(response.getBody(), TopicConfigSerializeWrapper.&lt;span&gt;class&lt;/span&gt;&lt;span&gt;);
&lt;/span&gt;&lt;span&gt;11&lt;/span&gt; &lt;span&gt;        }
&lt;/span&gt;&lt;span&gt;12&lt;/span&gt;         &lt;span&gt;default&lt;/span&gt;&lt;span&gt;:
&lt;/span&gt;&lt;span&gt;13&lt;/span&gt;             &lt;span&gt;break&lt;/span&gt;&lt;span&gt;;
&lt;/span&gt;&lt;span&gt;14&lt;/span&gt; &lt;span&gt;    }
&lt;/span&gt;&lt;span&gt;15&lt;/span&gt; 
&lt;span&gt;16&lt;/span&gt;     &lt;span&gt;throw&lt;/span&gt; &lt;span&gt;new&lt;/span&gt;&lt;span&gt; MQBrokerException(response.getCode(), response.getRemark());
&lt;/span&gt;&lt;span&gt;17&lt;/span&gt; }
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;首先构建GET_ALL_TOPIC_CONFIG求情指令，然后通过remotingClient的invokeSync进行同步发送，注意这里会通过MixAll的brokerVIPChannel方法，得到对应的master地址的VIP通道地址，就是端口号减2，这在我之前的博客中介绍过&lt;br/&gt;有关同步发送在  &lt;a href=&quot;https://www.cnblogs.com/a526583280/p/11290538.html&quot; target=&quot;_blank&quot;&gt;【RocketMQ中Producer消息的发送源码分析】&lt;/a&gt; 中详细介绍过&lt;/p&gt;

&lt;p&gt;请求发送给master后，来看看master是怎么处理的&lt;br/&gt;master端在收到请求后会通过AdminBrokerProcessor的processRequest方法判别请求指令：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;33&quot;&gt;
&lt;pre&gt;
&lt;span&gt;1&lt;/span&gt; &lt;span&gt;case&lt;/span&gt;&lt;span&gt; RequestCode.GET_ALL_TOPIC_CONFIG:
&lt;/span&gt;&lt;span&gt;2&lt;/span&gt;     &lt;span&gt;return&lt;/span&gt; &lt;span&gt;this&lt;/span&gt;.getAllTopicConfig(ctx, request);
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;执行getAllTopicConfig方法：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;39&quot;&gt;
&lt;pre&gt;
&lt;span&gt; 1&lt;/span&gt; &lt;span&gt;private&lt;/span&gt;&lt;span&gt; RemotingCommand getAllTopicConfig(ChannelHandlerContext ctx, RemotingCommand request) {
&lt;/span&gt;&lt;span&gt; 2&lt;/span&gt;     &lt;span&gt;final&lt;/span&gt; RemotingCommand response = RemotingCommand.createResponseCommand(GetAllTopicConfigResponseHeader.&lt;span&gt;class&lt;/span&gt;&lt;span&gt;);
&lt;/span&gt;&lt;span&gt; 3&lt;/span&gt;     &lt;span&gt;//&lt;/span&gt;&lt;span&gt; final GetAllTopicConfigResponseHeader responseHeader =
&lt;/span&gt;&lt;span&gt; 4&lt;/span&gt;     &lt;span&gt;//&lt;/span&gt;&lt;span&gt; (GetAllTopicConfigResponseHeader) response.readCustomHeader();&lt;/span&gt;
&lt;span&gt; 5&lt;/span&gt; 
&lt;span&gt; 6&lt;/span&gt;     String content = &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.brokerController.getTopicConfigManager().encode();
&lt;/span&gt;&lt;span&gt; 7&lt;/span&gt;     &lt;span&gt;if&lt;/span&gt; (content != &lt;span&gt;null&lt;/span&gt; &amp;amp;&amp;amp; content.length() &amp;gt; 0&lt;span&gt;) {
&lt;/span&gt;&lt;span&gt; 8&lt;/span&gt;         &lt;span&gt;try&lt;/span&gt;&lt;span&gt; {
&lt;/span&gt;&lt;span&gt; 9&lt;/span&gt; &lt;span&gt;            response.setBody(content.getBytes(MixAll.DEFAULT_CHARSET));
&lt;/span&gt;&lt;span&gt;10&lt;/span&gt;         } &lt;span&gt;catch&lt;/span&gt;&lt;span&gt; (UnsupportedEncodingException e) {
&lt;/span&gt;&lt;span&gt;11&lt;/span&gt;             log.error(&quot;&quot;&lt;span&gt;, e);
&lt;/span&gt;&lt;span&gt;12&lt;/span&gt; 
&lt;span&gt;13&lt;/span&gt; &lt;span&gt;            response.setCode(ResponseCode.SYSTEM_ERROR);
&lt;/span&gt;&lt;span&gt;14&lt;/span&gt;             response.setRemark(&quot;UnsupportedEncodingException &quot; +&lt;span&gt; e);
&lt;/span&gt;&lt;span&gt;15&lt;/span&gt;             &lt;span&gt;return&lt;/span&gt;&lt;span&gt; response;
&lt;/span&gt;&lt;span&gt;16&lt;/span&gt; &lt;span&gt;        }
&lt;/span&gt;&lt;span&gt;17&lt;/span&gt;     } &lt;span&gt;else&lt;/span&gt;&lt;span&gt; {
&lt;/span&gt;&lt;span&gt;18&lt;/span&gt;         log.error(&quot;No topic in this broker, client: {}&quot;&lt;span&gt;, ctx.channel().remoteAddress());
&lt;/span&gt;&lt;span&gt;19&lt;/span&gt; &lt;span&gt;        response.setCode(ResponseCode.SYSTEM_ERROR);
&lt;/span&gt;&lt;span&gt;20&lt;/span&gt;         response.setRemark(&quot;No topic in this broker&quot;&lt;span&gt;);
&lt;/span&gt;&lt;span&gt;21&lt;/span&gt;         &lt;span&gt;return&lt;/span&gt;&lt;span&gt; response;
&lt;/span&gt;&lt;span&gt;22&lt;/span&gt; &lt;span&gt;    }
&lt;/span&gt;&lt;span&gt;23&lt;/span&gt; 
&lt;span&gt;24&lt;/span&gt; &lt;span&gt;    response.setCode(ResponseCode.SUCCESS);
&lt;/span&gt;&lt;span&gt;25&lt;/span&gt;     response.setRemark(&lt;span&gt;null&lt;/span&gt;&lt;span&gt;);
&lt;/span&gt;&lt;span&gt;26&lt;/span&gt; 
&lt;span&gt;27&lt;/span&gt;     &lt;span&gt;return&lt;/span&gt;&lt;span&gt; response;
&lt;/span&gt;&lt;span&gt;28&lt;/span&gt; }
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;这里会将TopicConfigManager中保存的topicConfigTable：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;35&quot;&gt;
&lt;pre&gt;
&lt;span&gt;1&lt;/span&gt; &lt;span&gt;private&lt;/span&gt; &lt;span&gt;final&lt;/span&gt; ConcurrentMap&amp;lt;String, TopicConfig&amp;gt; topicConfigTable =
&lt;span&gt;2&lt;/span&gt;         &lt;span&gt;new&lt;/span&gt; ConcurrentHashMap&amp;lt;String, TopicConfig&amp;gt;(1024);
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;将这个map通过encode方法转换成json字符串，再通过Netty发送给slave&lt;/p&gt;
&lt;p&gt;&lt;br/&gt;回到slave中，在同步发送的情况下，会等待会送响应，收到响应后：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;34&quot;&gt;
&lt;pre&gt;
&lt;span&gt;1&lt;/span&gt; &lt;span&gt;switch&lt;/span&gt;&lt;span&gt; (response.getCode()) {
&lt;/span&gt;&lt;span&gt;2&lt;/span&gt;     &lt;span&gt;case&lt;/span&gt;&lt;span&gt; ResponseCode.SUCCESS: {
&lt;/span&gt;&lt;span&gt;3&lt;/span&gt;         &lt;span&gt;return&lt;/span&gt; TopicConfigSerializeWrapper.decode(response.getBody(), TopicConfigSerializeWrapper.&lt;span&gt;class&lt;/span&gt;&lt;span&gt;);
&lt;/span&gt;&lt;span&gt;4&lt;/span&gt; &lt;span&gt;    }
&lt;/span&gt;&lt;span&gt;5&lt;/span&gt;     &lt;span&gt;default&lt;/span&gt;&lt;span&gt;:
&lt;/span&gt;&lt;span&gt;6&lt;/span&gt;         &lt;span&gt;break&lt;/span&gt;&lt;span&gt;;
&lt;/span&gt;&lt;span&gt;7&lt;/span&gt; }
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;通过decode解码，将json字符串转换为map封装在 TopicConfigSerializeWrapper中&lt;/p&gt;
&lt;p&gt;&lt;br/&gt;回到syncTopicConfig方法中：&lt;br/&gt;得到TopicConfigSerializeWrapper实例后&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;37&quot;&gt;
&lt;pre&gt;
&lt;span&gt; 1&lt;/span&gt; &lt;span&gt;if&lt;/span&gt; (!&lt;span&gt;this&lt;/span&gt;&lt;span&gt;.brokerController.getTopicConfigManager().getDataVersion()
&lt;/span&gt;&lt;span&gt; 2&lt;/span&gt; &lt;span&gt;    .equals(topicWrapper.getDataVersion())) {
&lt;/span&gt;&lt;span&gt; 3&lt;/span&gt; 
&lt;span&gt; 4&lt;/span&gt;     &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.brokerController.getTopicConfigManager().getDataVersion()
&lt;/span&gt;&lt;span&gt; 5&lt;/span&gt; &lt;span&gt;        .assignNewOne(topicWrapper.getDataVersion());
&lt;/span&gt;&lt;span&gt; 6&lt;/span&gt;     &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.brokerController.getTopicConfigManager().getTopicConfigTable().clear();
&lt;/span&gt;&lt;span&gt; 7&lt;/span&gt;     &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.brokerController.getTopicConfigManager().getTopicConfigTable()
&lt;/span&gt;&lt;span&gt; 8&lt;/span&gt; &lt;span&gt;        .putAll(topicWrapper.getTopicConfigTable());
&lt;/span&gt;&lt;span&gt; 9&lt;/span&gt;     &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.brokerController.getTopicConfigManager().persist();
&lt;/span&gt;&lt;span&gt;10&lt;/span&gt; 
&lt;span&gt;11&lt;/span&gt;     log.info(&quot;Update slave topic config from master, {}&quot;&lt;span&gt;, masterAddrBak);
&lt;/span&gt;&lt;span&gt;12&lt;/span&gt; }
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;判断版本是否一致，若不一致，会进行替换，这样slave的Topic配置信息就和master保持同步了&lt;/p&gt;
&lt;p&gt;其他三种信息的同步同理&lt;/p&gt;

&lt;h2&gt; 同步消息数据&lt;/h2&gt;
&lt;p&gt;在master启动时，会通过JDK的NIO方式启动一个HA服务线程，用以处理slave的连接：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;39&quot;&gt;
&lt;pre&gt;
&lt;span&gt; 1&lt;/span&gt; &lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt;&lt;span&gt; run() {
&lt;/span&gt;&lt;span&gt; 2&lt;/span&gt;     log.info(&lt;span&gt;this&lt;/span&gt;.getServiceName() + &quot; service started&quot;&lt;span&gt;);
&lt;/span&gt;&lt;span&gt; 3&lt;/span&gt; 
&lt;span&gt; 4&lt;/span&gt;     &lt;span&gt;while&lt;/span&gt; (!&lt;span&gt;this&lt;/span&gt;&lt;span&gt;.isStopped()) {
&lt;/span&gt;&lt;span&gt; 5&lt;/span&gt;         &lt;span&gt;try&lt;/span&gt;&lt;span&gt; {
&lt;/span&gt;&lt;span&gt; 6&lt;/span&gt;             &lt;span&gt;this&lt;/span&gt;.selector.select(1000&lt;span&gt;);
&lt;/span&gt;&lt;span&gt; 7&lt;/span&gt;             Set&amp;lt;SelectionKey&amp;gt; selected = &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.selector.selectedKeys();
&lt;/span&gt;&lt;span&gt; 8&lt;/span&gt; 
&lt;span&gt; 9&lt;/span&gt;             &lt;span&gt;if&lt;/span&gt; (selected != &lt;span&gt;null&lt;/span&gt;&lt;span&gt;) {
&lt;/span&gt;&lt;span&gt;10&lt;/span&gt;                 &lt;span&gt;for&lt;/span&gt;&lt;span&gt; (SelectionKey k : selected) {
&lt;/span&gt;&lt;span&gt;11&lt;/span&gt;                     &lt;span&gt;if&lt;/span&gt; ((k.readyOps() &amp;amp; SelectionKey.OP_ACCEPT) != 0&lt;span&gt;) {
&lt;/span&gt;&lt;span&gt;12&lt;/span&gt;                         SocketChannel sc =&lt;span&gt; ((ServerSocketChannel) k.channel()).accept();
&lt;/span&gt;&lt;span&gt;13&lt;/span&gt; 
&lt;span&gt;14&lt;/span&gt;                         &lt;span&gt;if&lt;/span&gt; (sc != &lt;span&gt;null&lt;/span&gt;&lt;span&gt;) {
&lt;/span&gt;&lt;span&gt;15&lt;/span&gt;                             HAService.log.info(&quot;HAService receive new connection, &quot;
&lt;span&gt;16&lt;/span&gt;                                 +&lt;span&gt; sc.socket().getRemoteSocketAddress());
&lt;/span&gt;&lt;span&gt;17&lt;/span&gt; 
&lt;span&gt;18&lt;/span&gt;                             &lt;span&gt;try&lt;/span&gt;&lt;span&gt; {
&lt;/span&gt;&lt;span&gt;19&lt;/span&gt;                                 HAConnection conn = &lt;span&gt;new&lt;/span&gt; HAConnection(HAService.&lt;span&gt;this&lt;/span&gt;&lt;span&gt;, sc);
&lt;/span&gt;&lt;span&gt;20&lt;/span&gt; &lt;span&gt;                                conn.start();
&lt;/span&gt;&lt;span&gt;21&lt;/span&gt;                                 HAService.&lt;span&gt;this&lt;/span&gt;&lt;span&gt;.addConnection(conn);
&lt;/span&gt;&lt;span&gt;22&lt;/span&gt;                             } &lt;span&gt;catch&lt;/span&gt;&lt;span&gt; (Exception e) {
&lt;/span&gt;&lt;span&gt;23&lt;/span&gt;                                 log.error(&quot;new HAConnection exception&quot;&lt;span&gt;, e);
&lt;/span&gt;&lt;span&gt;24&lt;/span&gt; &lt;span&gt;                                sc.close();
&lt;/span&gt;&lt;span&gt;25&lt;/span&gt; &lt;span&gt;                            }
&lt;/span&gt;&lt;span&gt;26&lt;/span&gt; &lt;span&gt;                        }
&lt;/span&gt;&lt;span&gt;27&lt;/span&gt;                     } &lt;span&gt;else&lt;/span&gt;&lt;span&gt; {
&lt;/span&gt;&lt;span&gt;28&lt;/span&gt;                         log.warn(&quot;Unexpected ops in select &quot; +&lt;span&gt; k.readyOps());
&lt;/span&gt;&lt;span&gt;29&lt;/span&gt; &lt;span&gt;                    }
&lt;/span&gt;&lt;span&gt;30&lt;/span&gt; &lt;span&gt;                }
&lt;/span&gt;&lt;span&gt;31&lt;/span&gt; 
&lt;span&gt;32&lt;/span&gt; &lt;span&gt;                selected.clear();
&lt;/span&gt;&lt;span&gt;33&lt;/span&gt; &lt;span&gt;            }
&lt;/span&gt;&lt;span&gt;34&lt;/span&gt;         } &lt;span&gt;catch&lt;/span&gt;&lt;span&gt; (Exception e) {
&lt;/span&gt;&lt;span&gt;35&lt;/span&gt;             log.error(&lt;span&gt;this&lt;/span&gt;.getServiceName() + &quot; service has exception.&quot;&lt;span&gt;, e);
&lt;/span&gt;&lt;span&gt;36&lt;/span&gt; &lt;span&gt;        }
&lt;/span&gt;&lt;span&gt;37&lt;/span&gt; &lt;span&gt;    }
&lt;/span&gt;&lt;span&gt;38&lt;/span&gt; 
&lt;span&gt;39&lt;/span&gt;     log.info(&lt;span&gt;this&lt;/span&gt;.getServiceName() + &quot; service end&quot;&lt;span&gt;);
&lt;/span&gt;&lt;span&gt;40&lt;/span&gt; }
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;这里就是非常典型的JDK NIO的使用，在侦听到连接取得SocketChannel后，将其封装为HAConnection&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;37&quot;&gt;
&lt;pre&gt;
&lt;span&gt; 1&lt;/span&gt; &lt;span&gt;public&lt;/span&gt; HAConnection(&lt;span&gt;final&lt;/span&gt; HAService haService, &lt;span&gt;final&lt;/span&gt; SocketChannel socketChannel) &lt;span&gt;throws&lt;/span&gt;&lt;span&gt; IOException {
&lt;/span&gt;&lt;span&gt; 2&lt;/span&gt;     &lt;span&gt;this&lt;/span&gt;.haService =&lt;span&gt; haService;
&lt;/span&gt;&lt;span&gt; 3&lt;/span&gt;     &lt;span&gt;this&lt;/span&gt;.socketChannel =&lt;span&gt; socketChannel;
&lt;/span&gt;&lt;span&gt; 4&lt;/span&gt;     &lt;span&gt;this&lt;/span&gt;.clientAddr = &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.socketChannel.socket().getRemoteSocketAddress().toString();
&lt;/span&gt;&lt;span&gt; 5&lt;/span&gt;     &lt;span&gt;this&lt;/span&gt;.socketChannel.configureBlocking(&lt;span&gt;false&lt;/span&gt;&lt;span&gt;);
&lt;/span&gt;&lt;span&gt; 6&lt;/span&gt;     &lt;span&gt;this&lt;/span&gt;.socketChannel.socket().setSoLinger(&lt;span&gt;false&lt;/span&gt;, -1&lt;span&gt;);
&lt;/span&gt;&lt;span&gt; 7&lt;/span&gt;     &lt;span&gt;this&lt;/span&gt;.socketChannel.socket().setTcpNoDelay(&lt;span&gt;true&lt;/span&gt;&lt;span&gt;);
&lt;/span&gt;&lt;span&gt; 8&lt;/span&gt;     &lt;span&gt;this&lt;/span&gt;.socketChannel.socket().setReceiveBufferSize(1024 * 64&lt;span&gt;);
&lt;/span&gt;&lt;span&gt; 9&lt;/span&gt;     &lt;span&gt;this&lt;/span&gt;.socketChannel.socket().setSendBufferSize(1024 * 64&lt;span&gt;);
&lt;/span&gt;&lt;span&gt;10&lt;/span&gt;     &lt;span&gt;this&lt;/span&gt;.writeSocketService = &lt;span&gt;new&lt;/span&gt; WriteSocketService(&lt;span&gt;this&lt;/span&gt;&lt;span&gt;.socketChannel);
&lt;/span&gt;&lt;span&gt;11&lt;/span&gt;     &lt;span&gt;this&lt;/span&gt;.readSocketService = &lt;span&gt;new&lt;/span&gt; ReadSocketService(&lt;span&gt;this&lt;/span&gt;&lt;span&gt;.socketChannel);
&lt;/span&gt;&lt;span&gt;12&lt;/span&gt;     &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.haService.getConnectionCount().incrementAndGet();
&lt;/span&gt;&lt;span&gt;13&lt;/span&gt; }
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;在构造方法内进行了对socketChannel的一些配置，还创建了一个WriteSocketService和一个ReadSocketService，这两个是后续处理消息同步的基础&lt;/p&gt;
&lt;p&gt;&lt;br/&gt;在创建完HAConnection后，调用其start方法：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;32&quot;&gt;
&lt;pre&gt;
&lt;span&gt;1&lt;/span&gt; &lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt;&lt;span&gt; start() {
&lt;/span&gt;&lt;span&gt;2&lt;/span&gt;     &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.readSocketService.start();
&lt;/span&gt;&lt;span&gt;3&lt;/span&gt;     &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.writeSocketService.start();
&lt;/span&gt;&lt;span&gt;4&lt;/span&gt; }
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;这里会启动两个线程，分别处理读取slave发送的数据，以及向slave发送数据&lt;/p&gt;

&lt;p&gt;&lt;br/&gt;到这里，先不急着分析master了，来看看slave端&lt;br/&gt;slave在启动时，会启动HAClient的线程：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;41&quot;&gt;
&lt;pre&gt;
&lt;span&gt; 1&lt;/span&gt; &lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt;&lt;span&gt; run() {
&lt;/span&gt;&lt;span&gt; 2&lt;/span&gt;     log.info(&lt;span&gt;this&lt;/span&gt;.getServiceName() + &quot; service started&quot;&lt;span&gt;);
&lt;/span&gt;&lt;span&gt; 3&lt;/span&gt; 
&lt;span&gt; 4&lt;/span&gt;     &lt;span&gt;while&lt;/span&gt; (!&lt;span&gt;this&lt;/span&gt;&lt;span&gt;.isStopped()) {
&lt;/span&gt;&lt;span&gt; 5&lt;/span&gt;         &lt;span&gt;try&lt;/span&gt;&lt;span&gt; {
&lt;/span&gt;&lt;span&gt; 6&lt;/span&gt;             &lt;span&gt;if&lt;/span&gt; (&lt;span&gt;this&lt;/span&gt;&lt;span&gt;.connectMaster()) {
&lt;/span&gt;&lt;span&gt; 7&lt;/span&gt; 
&lt;span&gt; 8&lt;/span&gt;                 &lt;span&gt;if&lt;/span&gt; (&lt;span&gt;this&lt;/span&gt;&lt;span&gt;.isTimeToReportOffset()) {
&lt;/span&gt;&lt;span&gt; 9&lt;/span&gt;                     &lt;span&gt;boolean&lt;/span&gt; result = &lt;span&gt;this&lt;/span&gt;.reportSlaveMaxOffset(&lt;span&gt;this&lt;/span&gt;&lt;span&gt;.currentReportedOffset);
&lt;/span&gt;&lt;span&gt;10&lt;/span&gt;                     &lt;span&gt;if&lt;/span&gt; (!&lt;span&gt;result) {
&lt;/span&gt;&lt;span&gt;11&lt;/span&gt;                         &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.closeMaster();
&lt;/span&gt;&lt;span&gt;12&lt;/span&gt; &lt;span&gt;                    }
&lt;/span&gt;&lt;span&gt;13&lt;/span&gt; &lt;span&gt;                }
&lt;/span&gt;&lt;span&gt;14&lt;/span&gt; 
&lt;span&gt;15&lt;/span&gt;                 &lt;span&gt;this&lt;/span&gt;.selector.select(1000&lt;span&gt;);
&lt;/span&gt;&lt;span&gt;16&lt;/span&gt; 
&lt;span&gt;17&lt;/span&gt;                 &lt;span&gt;boolean&lt;/span&gt; ok = &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.processReadEvent();
&lt;/span&gt;&lt;span&gt;18&lt;/span&gt;                 &lt;span&gt;if&lt;/span&gt; (!&lt;span&gt;ok) {
&lt;/span&gt;&lt;span&gt;19&lt;/span&gt;                     &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.closeMaster();
&lt;/span&gt;&lt;span&gt;20&lt;/span&gt; &lt;span&gt;                }
&lt;/span&gt;&lt;span&gt;21&lt;/span&gt; 
&lt;span&gt;22&lt;/span&gt;                 &lt;span&gt;if&lt;/span&gt; (!&lt;span&gt;reportSlaveMaxOffsetPlus()) {
&lt;/span&gt;&lt;span&gt;23&lt;/span&gt;                     &lt;span&gt;continue&lt;/span&gt;&lt;span&gt;;
&lt;/span&gt;&lt;span&gt;24&lt;/span&gt; &lt;span&gt;                }
&lt;/span&gt;&lt;span&gt;25&lt;/span&gt; 
&lt;span&gt;26&lt;/span&gt;                 &lt;span&gt;long&lt;/span&gt; interval =
&lt;span&gt;27&lt;/span&gt;                     HAService.&lt;span&gt;this&lt;/span&gt;&lt;span&gt;.getDefaultMessageStore().getSystemClock().now()
&lt;/span&gt;&lt;span&gt;28&lt;/span&gt;                         - &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.lastWriteTimestamp;
&lt;/span&gt;&lt;span&gt;29&lt;/span&gt;                 &lt;span&gt;if&lt;/span&gt; (interval &amp;gt; HAService.&lt;span&gt;this&lt;/span&gt;&lt;span&gt;.getDefaultMessageStore().getMessageStoreConfig()
&lt;/span&gt;&lt;span&gt;30&lt;/span&gt; &lt;span&gt;                    .getHaHousekeepingInterval()) {
&lt;/span&gt;&lt;span&gt;31&lt;/span&gt;                     log.warn(&quot;HAClient, housekeeping, found this connection[&quot; + &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.masterAddress
&lt;/span&gt;&lt;span&gt;32&lt;/span&gt;                         + &quot;] expired, &quot; +&lt;span&gt; interval);
&lt;/span&gt;&lt;span&gt;33&lt;/span&gt;                     &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.closeMaster();
&lt;/span&gt;&lt;span&gt;34&lt;/span&gt;                     log.warn(&quot;HAClient, master not response some time, so close connection&quot;&lt;span&gt;);
&lt;/span&gt;&lt;span&gt;35&lt;/span&gt; &lt;span&gt;                }
&lt;/span&gt;&lt;span&gt;36&lt;/span&gt;             } &lt;span&gt;else&lt;/span&gt;&lt;span&gt; {
&lt;/span&gt;&lt;span&gt;37&lt;/span&gt;                 &lt;span&gt;this&lt;/span&gt;.waitForRunning(1000 * 5&lt;span&gt;);
&lt;/span&gt;&lt;span&gt;38&lt;/span&gt; &lt;span&gt;            }
&lt;/span&gt;&lt;span&gt;39&lt;/span&gt;         } &lt;span&gt;catch&lt;/span&gt;&lt;span&gt; (Exception e) {
&lt;/span&gt;&lt;span&gt;40&lt;/span&gt;             log.warn(&lt;span&gt;this&lt;/span&gt;.getServiceName() + &quot; service has exception. &quot;&lt;span&gt;, e);
&lt;/span&gt;&lt;span&gt;41&lt;/span&gt;             &lt;span&gt;this&lt;/span&gt;.waitForRunning(1000 * 5&lt;span&gt;);
&lt;/span&gt;&lt;span&gt;42&lt;/span&gt; &lt;span&gt;        }
&lt;/span&gt;&lt;span&gt;43&lt;/span&gt; &lt;span&gt;    }
&lt;/span&gt;&lt;span&gt;44&lt;/span&gt; 
&lt;span&gt;45&lt;/span&gt;     log.info(&lt;span&gt;this&lt;/span&gt;.getServiceName() + &quot; service end&quot;&lt;span&gt;);
&lt;/span&gt;&lt;span&gt;46&lt;/span&gt; }
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;在这个while循环中，首先通过connectMaster检查是否和master连接了&lt;/p&gt;
&lt;p&gt;&lt;br/&gt;connectMaster方法：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;36&quot;&gt;
&lt;pre&gt;
&lt;span&gt; 1&lt;/span&gt; &lt;span&gt;private&lt;/span&gt; &lt;span&gt;boolean&lt;/span&gt; connectMaster() &lt;span&gt;throws&lt;/span&gt;&lt;span&gt; ClosedChannelException {
&lt;/span&gt;&lt;span&gt; 2&lt;/span&gt;     &lt;span&gt;if&lt;/span&gt; (&lt;span&gt;null&lt;/span&gt; ==&lt;span&gt; socketChannel) {
&lt;/span&gt;&lt;span&gt; 3&lt;/span&gt;         String addr = &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.masterAddress.get();
&lt;/span&gt;&lt;span&gt; 4&lt;/span&gt;         &lt;span&gt;if&lt;/span&gt; (addr != &lt;span&gt;null&lt;/span&gt;&lt;span&gt;) {
&lt;/span&gt;&lt;span&gt; 5&lt;/span&gt; 
&lt;span&gt; 6&lt;/span&gt;             SocketAddress socketAddress =&lt;span&gt; RemotingUtil.string2SocketAddress(addr);
&lt;/span&gt;&lt;span&gt; 7&lt;/span&gt;             &lt;span&gt;if&lt;/span&gt; (socketAddress != &lt;span&gt;null&lt;/span&gt;&lt;span&gt;) {
&lt;/span&gt;&lt;span&gt; 8&lt;/span&gt;                 &lt;span&gt;this&lt;/span&gt;.socketChannel =&lt;span&gt; RemotingUtil.connect(socketAddress);
&lt;/span&gt;&lt;span&gt; 9&lt;/span&gt;                 &lt;span&gt;if&lt;/span&gt; (&lt;span&gt;this&lt;/span&gt;.socketChannel != &lt;span&gt;null&lt;/span&gt;&lt;span&gt;) {
&lt;/span&gt;&lt;span&gt;10&lt;/span&gt;                     &lt;span&gt;this&lt;/span&gt;.socketChannel.register(&lt;span&gt;this&lt;/span&gt;&lt;span&gt;.selector, SelectionKey.OP_READ);
&lt;/span&gt;&lt;span&gt;11&lt;/span&gt; &lt;span&gt;                }
&lt;/span&gt;&lt;span&gt;12&lt;/span&gt; &lt;span&gt;            }
&lt;/span&gt;&lt;span&gt;13&lt;/span&gt; &lt;span&gt;        }
&lt;/span&gt;&lt;span&gt;14&lt;/span&gt; 
&lt;span&gt;15&lt;/span&gt;         &lt;span&gt;this&lt;/span&gt;.currentReportedOffset = HAService.&lt;span&gt;this&lt;/span&gt;&lt;span&gt;.defaultMessageStore.getMaxPhyOffset();
&lt;/span&gt;&lt;span&gt;16&lt;/span&gt; 
&lt;span&gt;17&lt;/span&gt;         &lt;span&gt;this&lt;/span&gt;.lastWriteTimestamp =&lt;span&gt; System.currentTimeMillis();
&lt;/span&gt;&lt;span&gt;18&lt;/span&gt; &lt;span&gt;    }
&lt;/span&gt;&lt;span&gt;19&lt;/span&gt; 
&lt;span&gt;20&lt;/span&gt;     &lt;span&gt;return&lt;/span&gt; &lt;span&gt;this&lt;/span&gt;.socketChannel != &lt;span&gt;null&lt;/span&gt;&lt;span&gt;;
&lt;/span&gt;&lt;span&gt;21&lt;/span&gt; }
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;若是socketChannel为null，意味着并没有产生连接，或者连接断开&lt;br/&gt;需要重新根据masterAddress建立网络连接&lt;/p&gt;
&lt;p&gt;只要是需要建立连接，都需要通过defaultMessageStore的getMaxPhyOffset方法，获取本地最大的Offset，由currentReportedOffset保存，后续用于向master报告；以及保存了一个时间戳lastWriteTimestamp，用于之后的校对&lt;/p&gt;
&lt;p&gt;&lt;br/&gt;当确保与master的连接建立成功后，通过isTimeToReportOffset方法，检查是否需要向master报告当前的最大Offset&lt;/p&gt;
&lt;p&gt;isTimeToReportOffset方法：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;34&quot;&gt;
&lt;pre&gt;
&lt;span&gt;1&lt;/span&gt; &lt;span&gt;private&lt;/span&gt; &lt;span&gt;boolean&lt;/span&gt;&lt;span&gt; isTimeToReportOffset() {
&lt;/span&gt;&lt;span&gt;2&lt;/span&gt;     &lt;span&gt;long&lt;/span&gt; interval =
&lt;span&gt;3&lt;/span&gt;         HAService.&lt;span&gt;this&lt;/span&gt;.defaultMessageStore.getSystemClock().now() - &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.lastWriteTimestamp;
&lt;/span&gt;&lt;span&gt;4&lt;/span&gt;     &lt;span&gt;boolean&lt;/span&gt; needHeart = interval &amp;gt; HAService.&lt;span&gt;this&lt;/span&gt;&lt;span&gt;.defaultMessageStore.getMessageStoreConfig()
&lt;/span&gt;&lt;span&gt;5&lt;/span&gt; &lt;span&gt;        .getHaSendHeartbeatInterval();
&lt;/span&gt;&lt;span&gt;6&lt;/span&gt; 
&lt;span&gt;7&lt;/span&gt;     &lt;span&gt;return&lt;/span&gt;&lt;span&gt; needHeart;
&lt;/span&gt;&lt;span&gt;8&lt;/span&gt; }
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;这里就通过lastWriteTimestamp和当前时间检查，判断是否达到了报告时间间隔HaSendHeartbeatInterval，默认5s&lt;/p&gt;
&lt;p&gt;&lt;br/&gt;若是达到了，就需要通过reportSlaveMaxOffset方法，将记录的currentReportedOffset这个最大的offset发送给master&lt;/p&gt;
&lt;p&gt;&lt;br/&gt;reportSlaveMaxOffset方法：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;36&quot;&gt;
&lt;pre&gt;
&lt;span&gt; 1&lt;/span&gt; &lt;span&gt;private&lt;/span&gt; &lt;span&gt;boolean&lt;/span&gt; reportSlaveMaxOffset(&lt;span&gt;final&lt;/span&gt; &lt;span&gt;long&lt;/span&gt;&lt;span&gt; maxOffset) {
&lt;/span&gt;&lt;span&gt; 2&lt;/span&gt;     &lt;span&gt;this&lt;/span&gt;.reportOffset.position(0&lt;span&gt;);
&lt;/span&gt;&lt;span&gt; 3&lt;/span&gt;     &lt;span&gt;this&lt;/span&gt;.reportOffset.limit(8&lt;span&gt;);
&lt;/span&gt;&lt;span&gt; 4&lt;/span&gt;     &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.reportOffset.putLong(maxOffset);
&lt;/span&gt;&lt;span&gt; 5&lt;/span&gt;     &lt;span&gt;this&lt;/span&gt;.reportOffset.position(0&lt;span&gt;);
&lt;/span&gt;&lt;span&gt; 6&lt;/span&gt;     &lt;span&gt;this&lt;/span&gt;.reportOffset.limit(8&lt;span&gt;);
&lt;/span&gt;&lt;span&gt; 7&lt;/span&gt; 
&lt;span&gt; 8&lt;/span&gt;     &lt;span&gt;for&lt;/span&gt; (&lt;span&gt;int&lt;/span&gt; i = 0; i &amp;lt; 3 &amp;amp;&amp;amp; &lt;span&gt;this&lt;/span&gt;.reportOffset.hasRemaining(); i++&lt;span&gt;) {
&lt;/span&gt;&lt;span&gt; 9&lt;/span&gt;         &lt;span&gt;try&lt;/span&gt;&lt;span&gt; {
&lt;/span&gt;&lt;span&gt;10&lt;/span&gt;             &lt;span&gt;this&lt;/span&gt;.socketChannel.write(&lt;span&gt;this&lt;/span&gt;&lt;span&gt;.reportOffset);
&lt;/span&gt;&lt;span&gt;11&lt;/span&gt;         } &lt;span&gt;catch&lt;/span&gt;&lt;span&gt; (IOException e) {
&lt;/span&gt;&lt;span&gt;12&lt;/span&gt;             log.error(&lt;span&gt;this&lt;/span&gt;&lt;span&gt;.getServiceName()
&lt;/span&gt;&lt;span&gt;13&lt;/span&gt;                 + &quot;reportSlaveMaxOffset this.socketChannel.write exception&quot;&lt;span&gt;, e);
&lt;/span&gt;&lt;span&gt;14&lt;/span&gt;             &lt;span&gt;return&lt;/span&gt; &lt;span&gt;false&lt;/span&gt;&lt;span&gt;;
&lt;/span&gt;&lt;span&gt;15&lt;/span&gt; &lt;span&gt;        }
&lt;/span&gt;&lt;span&gt;16&lt;/span&gt; &lt;span&gt;    }
&lt;/span&gt;&lt;span&gt;17&lt;/span&gt; 
&lt;span&gt;18&lt;/span&gt;     &lt;span&gt;return&lt;/span&gt; !&lt;span&gt;this&lt;/span&gt;&lt;span&gt;.reportOffset.hasRemaining();
&lt;/span&gt;&lt;span&gt;19&lt;/span&gt; }
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;其中reportOffset是专门用来缓存offset的ByteBuffer&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;32&quot;&gt;
&lt;pre&gt;
&lt;span&gt;1&lt;/span&gt; &lt;span&gt;private&lt;/span&gt; &lt;span&gt;final&lt;/span&gt; ByteBuffer reportOffset = ByteBuffer.allocate(8);
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;将maxOffset存放在reportOffset中，然后通过socketChannel的write方法，完成向master的发送&lt;/p&gt;
&lt;p&gt;其中hasRemaining方法用来检查当前位置是否已经达到缓冲区极限limit，确保reportOffset 中的内容能被完全发送出去&lt;/p&gt;
&lt;p&gt;发送成功后，会调用selector的select方法，在超时时间内进行NIO的轮询，等待master的回送&lt;/p&gt;
&lt;p&gt;&lt;br/&gt;通过这我们可以看出slave在和master建立连接后，会定时向master报告自己当前的offset&lt;/p&gt;

&lt;p&gt;&lt;br/&gt;来看看master收到offset后是如何处理的：&lt;/p&gt;
&lt;p&gt;在master端会通过前面提到的ReadSocketService线程进行处理：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;39&quot;&gt;
&lt;pre&gt;
&lt;span&gt; 1&lt;/span&gt; &lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt;&lt;span&gt; run() {
&lt;/span&gt;&lt;span&gt; 2&lt;/span&gt;     HAConnection.log.info(&lt;span&gt;this&lt;/span&gt;.getServiceName() + &quot; service started&quot;&lt;span&gt;);
&lt;/span&gt;&lt;span&gt; 3&lt;/span&gt; 
&lt;span&gt; 4&lt;/span&gt;     &lt;span&gt;while&lt;/span&gt; (!&lt;span&gt;this&lt;/span&gt;&lt;span&gt;.isStopped()) {
&lt;/span&gt;&lt;span&gt; 5&lt;/span&gt;         &lt;span&gt;try&lt;/span&gt;&lt;span&gt; {
&lt;/span&gt;&lt;span&gt; 6&lt;/span&gt;             &lt;span&gt;this&lt;/span&gt;.selector.select(1000&lt;span&gt;);
&lt;/span&gt;&lt;span&gt; 7&lt;/span&gt;             &lt;span&gt;boolean&lt;/span&gt; ok = &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.processReadEvent();
&lt;/span&gt;&lt;span&gt; 8&lt;/span&gt;             &lt;span&gt;if&lt;/span&gt; (!&lt;span&gt;ok) {
&lt;/span&gt;&lt;span&gt; 9&lt;/span&gt;                 HAConnection.log.error(&quot;processReadEvent error&quot;&lt;span&gt;);
&lt;/span&gt;&lt;span&gt;10&lt;/span&gt;                 &lt;span&gt;break&lt;/span&gt;&lt;span&gt;;
&lt;/span&gt;&lt;span&gt;11&lt;/span&gt; &lt;span&gt;            }
&lt;/span&gt;&lt;span&gt;12&lt;/span&gt; 
&lt;span&gt;13&lt;/span&gt;             &lt;span&gt;long&lt;/span&gt; interval = HAConnection.&lt;span&gt;this&lt;/span&gt;.haService.getDefaultMessageStore().getSystemClock().now() - &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.lastReadTimestamp;
&lt;/span&gt;&lt;span&gt;14&lt;/span&gt;             &lt;span&gt;if&lt;/span&gt; (interval &amp;gt; HAConnection.&lt;span&gt;this&lt;/span&gt;&lt;span&gt;.haService.getDefaultMessageStore().getMessageStoreConfig().getHaHousekeepingInterval()) {
&lt;/span&gt;&lt;span&gt;15&lt;/span&gt;                 log.warn(&quot;ha housekeeping, found this connection[&quot; + HAConnection.&lt;span&gt;this&lt;/span&gt;.clientAddr + &quot;] expired, &quot; +&lt;span&gt; interval);
&lt;/span&gt;&lt;span&gt;16&lt;/span&gt;                 &lt;span&gt;break&lt;/span&gt;&lt;span&gt;;
&lt;/span&gt;&lt;span&gt;17&lt;/span&gt; &lt;span&gt;            }
&lt;/span&gt;&lt;span&gt;18&lt;/span&gt;         } &lt;span&gt;catch&lt;/span&gt;&lt;span&gt; (Exception e) {
&lt;/span&gt;&lt;span&gt;19&lt;/span&gt;             HAConnection.log.error(&lt;span&gt;this&lt;/span&gt;.getServiceName() + &quot; service has exception.&quot;&lt;span&gt;, e);
&lt;/span&gt;&lt;span&gt;20&lt;/span&gt;             &lt;span&gt;break&lt;/span&gt;&lt;span&gt;;
&lt;/span&gt;&lt;span&gt;21&lt;/span&gt; &lt;span&gt;        }
&lt;/span&gt;&lt;span&gt;22&lt;/span&gt; &lt;span&gt;    }
&lt;/span&gt;&lt;span&gt;23&lt;/span&gt; 
&lt;span&gt;24&lt;/span&gt;     &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.makeStop();
&lt;/span&gt;&lt;span&gt;25&lt;/span&gt; 
&lt;span&gt;26&lt;/span&gt; &lt;span&gt;    writeSocketService.makeStop();
&lt;/span&gt;&lt;span&gt;27&lt;/span&gt; 
&lt;span&gt;28&lt;/span&gt;     haService.removeConnection(HAConnection.&lt;span&gt;this&lt;/span&gt;&lt;span&gt;);
&lt;/span&gt;&lt;span&gt;29&lt;/span&gt; 
&lt;span&gt;30&lt;/span&gt;     HAConnection.&lt;span&gt;this&lt;/span&gt;&lt;span&gt;.haService.getConnectionCount().decrementAndGet();
&lt;/span&gt;&lt;span&gt;31&lt;/span&gt; 
&lt;span&gt;32&lt;/span&gt;     SelectionKey sk = &lt;span&gt;this&lt;/span&gt;.socketChannel.keyFor(&lt;span&gt;this&lt;/span&gt;&lt;span&gt;.selector);
&lt;/span&gt;&lt;span&gt;33&lt;/span&gt;     &lt;span&gt;if&lt;/span&gt; (sk != &lt;span&gt;null&lt;/span&gt;&lt;span&gt;) {
&lt;/span&gt;&lt;span&gt;34&lt;/span&gt; &lt;span&gt;        sk.cancel();
&lt;/span&gt;&lt;span&gt;35&lt;/span&gt; &lt;span&gt;    }
&lt;/span&gt;&lt;span&gt;36&lt;/span&gt; 
&lt;span&gt;37&lt;/span&gt;     &lt;span&gt;try&lt;/span&gt;&lt;span&gt; {
&lt;/span&gt;&lt;span&gt;38&lt;/span&gt;         &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.selector.close();
&lt;/span&gt;&lt;span&gt;39&lt;/span&gt;         &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.socketChannel.close();
&lt;/span&gt;&lt;span&gt;40&lt;/span&gt;     } &lt;span&gt;catch&lt;/span&gt;&lt;span&gt; (IOException e) {
&lt;/span&gt;&lt;span&gt;41&lt;/span&gt;         HAConnection.log.error(&quot;&quot;&lt;span&gt;, e);
&lt;/span&gt;&lt;span&gt;42&lt;/span&gt; &lt;span&gt;    }
&lt;/span&gt;&lt;span&gt;43&lt;/span&gt; 
&lt;span&gt;44&lt;/span&gt;     HAConnection.log.info(&lt;span&gt;this&lt;/span&gt;.getServiceName() + &quot; service end&quot;&lt;span&gt;);
&lt;/span&gt;&lt;span&gt;45&lt;/span&gt; }
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;这里的while循环中首先也是通过selector的select方法，在超时时间内进行NIO的轮询&lt;/p&gt;
&lt;p&gt;轮询结束后的进一步的处理由processReadEvent来完成：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;36&quot;&gt;
&lt;pre&gt;
&lt;span&gt; 1&lt;/span&gt; &lt;span&gt;private&lt;/span&gt; &lt;span&gt;boolean&lt;/span&gt;&lt;span&gt; processReadEvent() {
&lt;/span&gt;&lt;span&gt; 2&lt;/span&gt;         &lt;span&gt;int&lt;/span&gt; readSizeZeroTimes = 0&lt;span&gt;;
&lt;/span&gt;&lt;span&gt; 3&lt;/span&gt; 
&lt;span&gt; 4&lt;/span&gt;         &lt;span&gt;if&lt;/span&gt; (!&lt;span&gt;this&lt;/span&gt;&lt;span&gt;.byteBufferRead.hasRemaining()) {
&lt;/span&gt;&lt;span&gt; 5&lt;/span&gt;             &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.byteBufferRead.flip();
&lt;/span&gt;&lt;span&gt; 6&lt;/span&gt;             &lt;span&gt;this&lt;/span&gt;.processPostion = 0&lt;span&gt;;
&lt;/span&gt;&lt;span&gt; 7&lt;/span&gt; &lt;span&gt;        }
&lt;/span&gt;&lt;span&gt; 8&lt;/span&gt; 
&lt;span&gt; 9&lt;/span&gt;         &lt;span&gt;while&lt;/span&gt; (&lt;span&gt;this&lt;/span&gt;&lt;span&gt;.byteBufferRead.hasRemaining()) {
&lt;/span&gt;&lt;span&gt;10&lt;/span&gt;             &lt;span&gt;try&lt;/span&gt;&lt;span&gt; {
&lt;/span&gt;&lt;span&gt;11&lt;/span&gt;                 &lt;span&gt;int&lt;/span&gt; readSize = &lt;span&gt;this&lt;/span&gt;.socketChannel.read(&lt;span&gt;this&lt;/span&gt;&lt;span&gt;.byteBufferRead);
&lt;/span&gt;&lt;span&gt;12&lt;/span&gt;                 &lt;span&gt;if&lt;/span&gt; (readSize &amp;gt; 0&lt;span&gt;) {
&lt;/span&gt;&lt;span&gt;13&lt;/span&gt;                     readSizeZeroTimes = 0&lt;span&gt;;
&lt;/span&gt;&lt;span&gt;14&lt;/span&gt;                     &lt;span&gt;this&lt;/span&gt;.lastReadTimestamp = HAConnection.&lt;span&gt;this&lt;/span&gt;&lt;span&gt;.haService.getDefaultMessageStore().getSystemClock().now();
&lt;/span&gt;&lt;span&gt;15&lt;/span&gt;                     &lt;span&gt;if&lt;/span&gt; ((&lt;span&gt;this&lt;/span&gt;.byteBufferRead.position() - &lt;span&gt;this&lt;/span&gt;.processPostion) &amp;gt;= 8&lt;span&gt;) {
&lt;/span&gt;&lt;span&gt;16&lt;/span&gt;                         &lt;span&gt;int&lt;/span&gt; pos = &lt;span&gt;this&lt;/span&gt;.byteBufferRead.position() - (&lt;span&gt;this&lt;/span&gt;.byteBufferRead.position() % 8&lt;span&gt;);
&lt;/span&gt;&lt;span&gt;17&lt;/span&gt;                         &lt;span&gt;long&lt;/span&gt; readOffset = &lt;span&gt;this&lt;/span&gt;.byteBufferRead.getLong(pos - 8&lt;span&gt;);
&lt;/span&gt;&lt;span&gt;18&lt;/span&gt;                         &lt;span&gt;this&lt;/span&gt;.processPostion =&lt;span&gt; pos;
&lt;/span&gt;&lt;span&gt;19&lt;/span&gt; 
&lt;span&gt;20&lt;/span&gt;                         HAConnection.&lt;span&gt;this&lt;/span&gt;.slaveAckOffset =&lt;span&gt; readOffset;
&lt;/span&gt;&lt;span&gt;21&lt;/span&gt;                         &lt;span&gt;if&lt;/span&gt; (HAConnection.&lt;span&gt;this&lt;/span&gt;.slaveRequestOffset &amp;lt; 0&lt;span&gt;) {
&lt;/span&gt;&lt;span&gt;22&lt;/span&gt;                             HAConnection.&lt;span&gt;this&lt;/span&gt;.slaveRequestOffset =&lt;span&gt; readOffset;
&lt;/span&gt;&lt;span&gt;23&lt;/span&gt;                             log.info(&quot;slave[&quot; + HAConnection.&lt;span&gt;this&lt;/span&gt;.clientAddr + &quot;] request offset &quot; +&lt;span&gt; readOffset);
&lt;/span&gt;&lt;span&gt;24&lt;/span&gt; &lt;span&gt;                        }
&lt;/span&gt;&lt;span&gt;25&lt;/span&gt; 
&lt;span&gt;26&lt;/span&gt;                         HAConnection.&lt;span&gt;this&lt;/span&gt;.haService.notifyTransferSome(HAConnection.&lt;span&gt;this&lt;/span&gt;&lt;span&gt;.slaveAckOffset);
&lt;/span&gt;&lt;span&gt;27&lt;/span&gt; &lt;span&gt;                    }
&lt;/span&gt;&lt;span&gt;28&lt;/span&gt;                 } &lt;span&gt;else&lt;/span&gt; &lt;span&gt;if&lt;/span&gt; (readSize == 0&lt;span&gt;) {
&lt;/span&gt;&lt;span&gt;29&lt;/span&gt;                     &lt;span&gt;if&lt;/span&gt; (++readSizeZeroTimes &amp;gt;= 3&lt;span&gt;) {
&lt;/span&gt;&lt;span&gt;30&lt;/span&gt;                         &lt;span&gt;break&lt;/span&gt;&lt;span&gt;;
&lt;/span&gt;&lt;span&gt;31&lt;/span&gt; &lt;span&gt;                    }
&lt;/span&gt;&lt;span&gt;32&lt;/span&gt;                 } &lt;span&gt;else&lt;/span&gt;&lt;span&gt; {
&lt;/span&gt;&lt;span&gt;33&lt;/span&gt;                     log.error(&quot;read socket[&quot; + HAConnection.&lt;span&gt;this&lt;/span&gt;.clientAddr + &quot;] &amp;lt; 0&quot;&lt;span&gt;);
&lt;/span&gt;&lt;span&gt;34&lt;/span&gt;                     &lt;span&gt;return&lt;/span&gt; &lt;span&gt;false&lt;/span&gt;&lt;span&gt;;
&lt;/span&gt;&lt;span&gt;35&lt;/span&gt; &lt;span&gt;                }
&lt;/span&gt;&lt;span&gt;36&lt;/span&gt;             } &lt;span&gt;catch&lt;/span&gt;&lt;span&gt; (IOException e) {
&lt;/span&gt;&lt;span&gt;37&lt;/span&gt;                 log.error(&quot;processReadEvent exception&quot;&lt;span&gt;, e);
&lt;/span&gt;&lt;span&gt;38&lt;/span&gt;                 &lt;span&gt;return&lt;/span&gt; &lt;span&gt;false&lt;/span&gt;&lt;span&gt;;
&lt;/span&gt;&lt;span&gt;39&lt;/span&gt; &lt;span&gt;            }
&lt;/span&gt;&lt;span&gt;40&lt;/span&gt; &lt;span&gt;        }
&lt;/span&gt;&lt;span&gt;41&lt;/span&gt; 
&lt;span&gt;42&lt;/span&gt;         &lt;span&gt;return&lt;/span&gt; &lt;span&gt;true&lt;/span&gt;&lt;span&gt;;
&lt;/span&gt;&lt;span&gt;43&lt;/span&gt; &lt;span&gt;    }
&lt;/span&gt;&lt;span&gt;44&lt;/span&gt; }
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;这个方法其实就是通过socketChannel的read方法，将slave发送过来的数据存入byteBufferRead中&lt;br/&gt;在确保发送过来的数据能达到8字节时，取出long类型的offset值，然后交给HAConnection的slaveAckOffset成员进行保存&lt;/p&gt;
&lt;p&gt;其中slaveRequestOffset是用来处理第一次连接时的同步&lt;/p&gt;
&lt;p&gt;notifyTransferSome方法是作为同步master时，进行相应的唤醒操作，异步master则没有要求，在后面具体分析&lt;/p&gt;
&lt;p&gt;&lt;br/&gt;也就是说ReadSocketService这个线程，只是不断地读取并更新slave发送来的offset数据&lt;/p&gt;

&lt;p&gt;再来看看WriteSocketService线程是如何进行向slave的发送：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;38&quot;&gt;
&lt;pre&gt;
&lt;span&gt;  1&lt;/span&gt; &lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt;&lt;span&gt; run() {
&lt;/span&gt;&lt;span&gt;  2&lt;/span&gt;     HAConnection.log.info(&lt;span&gt;this&lt;/span&gt;.getServiceName() + &quot; service started&quot;&lt;span&gt;);
&lt;/span&gt;&lt;span&gt;  3&lt;/span&gt; 
&lt;span&gt;  4&lt;/span&gt;     &lt;span&gt;while&lt;/span&gt; (!&lt;span&gt;this&lt;/span&gt;&lt;span&gt;.isStopped()) {
&lt;/span&gt;&lt;span&gt;  5&lt;/span&gt;         &lt;span&gt;try&lt;/span&gt;&lt;span&gt; {
&lt;/span&gt;&lt;span&gt;  6&lt;/span&gt;             &lt;span&gt;this&lt;/span&gt;.selector.select(1000&lt;span&gt;);
&lt;/span&gt;&lt;span&gt;  7&lt;/span&gt; 
&lt;span&gt;  8&lt;/span&gt;             &lt;span&gt;if&lt;/span&gt; (-1 == HAConnection.&lt;span&gt;this&lt;/span&gt;&lt;span&gt;.slaveRequestOffset) {
&lt;/span&gt;&lt;span&gt;  9&lt;/span&gt;                 Thread.sleep(10&lt;span&gt;);
&lt;/span&gt;&lt;span&gt; 10&lt;/span&gt;                 &lt;span&gt;continue&lt;/span&gt;&lt;span&gt;;
&lt;/span&gt;&lt;span&gt; 11&lt;/span&gt; &lt;span&gt;            }
&lt;/span&gt;&lt;span&gt; 12&lt;/span&gt; 
&lt;span&gt; 13&lt;/span&gt;             &lt;span&gt;if&lt;/span&gt; (-1 == &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.nextTransferFromWhere) {
&lt;/span&gt;&lt;span&gt; 14&lt;/span&gt;                 &lt;span&gt;if&lt;/span&gt; (0 == HAConnection.&lt;span&gt;this&lt;/span&gt;&lt;span&gt;.slaveRequestOffset) {
&lt;/span&gt;&lt;span&gt; 15&lt;/span&gt;                     &lt;span&gt;long&lt;/span&gt; masterOffset = HAConnection.&lt;span&gt;this&lt;/span&gt;&lt;span&gt;.haService.getDefaultMessageStore().getCommitLog().getMaxOffset();
&lt;/span&gt;&lt;span&gt; 16&lt;/span&gt;                     masterOffset =
&lt;span&gt; 17&lt;/span&gt; &lt;span&gt;                        masterOffset
&lt;/span&gt;&lt;span&gt; 18&lt;/span&gt;                             - (masterOffset % HAConnection.&lt;span&gt;this&lt;/span&gt;&lt;span&gt;.haService.getDefaultMessageStore().getMessageStoreConfig()
&lt;/span&gt;&lt;span&gt; 19&lt;/span&gt; &lt;span&gt;                            .getMapedFileSizeCommitLog());
&lt;/span&gt;&lt;span&gt; 20&lt;/span&gt; 
&lt;span&gt; 21&lt;/span&gt;                     &lt;span&gt;if&lt;/span&gt; (masterOffset &amp;lt; 0&lt;span&gt;) {
&lt;/span&gt;&lt;span&gt; 22&lt;/span&gt;                         masterOffset = 0&lt;span&gt;;
&lt;/span&gt;&lt;span&gt; 23&lt;/span&gt; &lt;span&gt;                    }
&lt;/span&gt;&lt;span&gt; 24&lt;/span&gt; 
&lt;span&gt; 25&lt;/span&gt;                     &lt;span&gt;this&lt;/span&gt;.nextTransferFromWhere =&lt;span&gt; masterOffset;
&lt;/span&gt;&lt;span&gt; 26&lt;/span&gt;                 } &lt;span&gt;else&lt;/span&gt;&lt;span&gt; {
&lt;/span&gt;&lt;span&gt; 27&lt;/span&gt;                     &lt;span&gt;this&lt;/span&gt;.nextTransferFromWhere = HAConnection.&lt;span&gt;this&lt;/span&gt;&lt;span&gt;.slaveRequestOffset;
&lt;/span&gt;&lt;span&gt; 28&lt;/span&gt; &lt;span&gt;                }
&lt;/span&gt;&lt;span&gt; 29&lt;/span&gt; 
&lt;span&gt; 30&lt;/span&gt;                 log.info(&quot;master transfer data from &quot; + &lt;span&gt;this&lt;/span&gt;.nextTransferFromWhere + &quot; to slave[&quot; + HAConnection.&lt;span&gt;this&lt;/span&gt;&lt;span&gt;.clientAddr
&lt;/span&gt;&lt;span&gt; 31&lt;/span&gt;                     + &quot;], and slave request &quot; + HAConnection.&lt;span&gt;this&lt;/span&gt;&lt;span&gt;.slaveRequestOffset);
&lt;/span&gt;&lt;span&gt; 32&lt;/span&gt; &lt;span&gt;            }
&lt;/span&gt;&lt;span&gt; 33&lt;/span&gt; 
&lt;span&gt; 34&lt;/span&gt;             &lt;span&gt;if&lt;/span&gt; (&lt;span&gt;this&lt;/span&gt;&lt;span&gt;.lastWriteOver) {
&lt;/span&gt;&lt;span&gt; 35&lt;/span&gt; 
&lt;span&gt; 36&lt;/span&gt;                 &lt;span&gt;long&lt;/span&gt; interval =
&lt;span&gt; 37&lt;/span&gt;                     HAConnection.&lt;span&gt;this&lt;/span&gt;.haService.getDefaultMessageStore().getSystemClock().now() - &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.lastWriteTimestamp;
&lt;/span&gt;&lt;span&gt; 38&lt;/span&gt; 
&lt;span&gt; 39&lt;/span&gt;                 &lt;span&gt;if&lt;/span&gt; (interval &amp;gt; HAConnection.&lt;span&gt;this&lt;/span&gt;&lt;span&gt;.haService.getDefaultMessageStore().getMessageStoreConfig()
&lt;/span&gt;&lt;span&gt; 40&lt;/span&gt; &lt;span&gt;                    .getHaSendHeartbeatInterval()) {
&lt;/span&gt;&lt;span&gt; 41&lt;/span&gt; 
&lt;span&gt; 42&lt;/span&gt;                     &lt;span&gt;//&lt;/span&gt;&lt;span&gt; Build Header&lt;/span&gt;
&lt;span&gt; 43&lt;/span&gt;                     &lt;span&gt;this&lt;/span&gt;.byteBufferHeader.position(0&lt;span&gt;);
&lt;/span&gt;&lt;span&gt; 44&lt;/span&gt;                     &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.byteBufferHeader.limit(headerSize);
&lt;/span&gt;&lt;span&gt; 45&lt;/span&gt;                     &lt;span&gt;this&lt;/span&gt;.byteBufferHeader.putLong(&lt;span&gt;this&lt;/span&gt;&lt;span&gt;.nextTransferFromWhere);
&lt;/span&gt;&lt;span&gt; 46&lt;/span&gt;                     &lt;span&gt;this&lt;/span&gt;.byteBufferHeader.putInt(0&lt;span&gt;);
&lt;/span&gt;&lt;span&gt; 47&lt;/span&gt;                     &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.byteBufferHeader.flip();
&lt;/span&gt;&lt;span&gt; 48&lt;/span&gt; 
&lt;span&gt; 49&lt;/span&gt;                     &lt;span&gt;this&lt;/span&gt;.lastWriteOver = &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.transferData();
&lt;/span&gt;&lt;span&gt; 50&lt;/span&gt;                     &lt;span&gt;if&lt;/span&gt; (!&lt;span&gt;this&lt;/span&gt;&lt;span&gt;.lastWriteOver)
&lt;/span&gt;&lt;span&gt; 51&lt;/span&gt;                         &lt;span&gt;continue&lt;/span&gt;&lt;span&gt;;
&lt;/span&gt;&lt;span&gt; 52&lt;/span&gt; &lt;span&gt;                }
&lt;/span&gt;&lt;span&gt; 53&lt;/span&gt;             } &lt;span&gt;else&lt;/span&gt;&lt;span&gt; {
&lt;/span&gt;&lt;span&gt; 54&lt;/span&gt;                 &lt;span&gt;this&lt;/span&gt;.lastWriteOver = &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.transferData();
&lt;/span&gt;&lt;span&gt; 55&lt;/span&gt;                 &lt;span&gt;if&lt;/span&gt; (!&lt;span&gt;this&lt;/span&gt;&lt;span&gt;.lastWriteOver)
&lt;/span&gt;&lt;span&gt; 56&lt;/span&gt;                     &lt;span&gt;continue&lt;/span&gt;&lt;span&gt;;
&lt;/span&gt;&lt;span&gt; 57&lt;/span&gt; &lt;span&gt;            }
&lt;/span&gt;&lt;span&gt; 58&lt;/span&gt; 
&lt;span&gt; 59&lt;/span&gt;             SelectMappedBufferResult selectResult =
&lt;span&gt; 60&lt;/span&gt;                 HAConnection.&lt;span&gt;this&lt;/span&gt;.haService.getDefaultMessageStore().getCommitLogData(&lt;span&gt;this&lt;/span&gt;&lt;span&gt;.nextTransferFromWhere);
&lt;/span&gt;&lt;span&gt; 61&lt;/span&gt;             &lt;span&gt;if&lt;/span&gt; (selectResult != &lt;span&gt;null&lt;/span&gt;&lt;span&gt;) {
&lt;/span&gt;&lt;span&gt; 62&lt;/span&gt;                 &lt;span&gt;int&lt;/span&gt; size =&lt;span&gt; selectResult.getSize();
&lt;/span&gt;&lt;span&gt; 63&lt;/span&gt;                 &lt;span&gt;if&lt;/span&gt; (size &amp;gt; HAConnection.&lt;span&gt;this&lt;/span&gt;&lt;span&gt;.haService.getDefaultMessageStore().getMessageStoreConfig().getHaTransferBatchSize()) {
&lt;/span&gt;&lt;span&gt; 64&lt;/span&gt;                     size = HAConnection.&lt;span&gt;this&lt;/span&gt;&lt;span&gt;.haService.getDefaultMessageStore().getMessageStoreConfig().getHaTransferBatchSize();
&lt;/span&gt;&lt;span&gt; 65&lt;/span&gt; &lt;span&gt;                }
&lt;/span&gt;&lt;span&gt; 66&lt;/span&gt; 
&lt;span&gt; 67&lt;/span&gt;                 &lt;span&gt;long&lt;/span&gt; thisOffset = &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.nextTransferFromWhere;
&lt;/span&gt;&lt;span&gt; 68&lt;/span&gt;                 &lt;span&gt;this&lt;/span&gt;.nextTransferFromWhere +=&lt;span&gt; size;
&lt;/span&gt;&lt;span&gt; 69&lt;/span&gt; 
&lt;span&gt; 70&lt;/span&gt; &lt;span&gt;                selectResult.getByteBuffer().limit(size);
&lt;/span&gt;&lt;span&gt; 71&lt;/span&gt;                 &lt;span&gt;this&lt;/span&gt;.selectMappedBufferResult =&lt;span&gt; selectResult;
&lt;/span&gt;&lt;span&gt; 72&lt;/span&gt; 
&lt;span&gt; 73&lt;/span&gt;                 &lt;span&gt;//&lt;/span&gt;&lt;span&gt; Build Header&lt;/span&gt;
&lt;span&gt; 74&lt;/span&gt;                 &lt;span&gt;this&lt;/span&gt;.byteBufferHeader.position(0&lt;span&gt;);
&lt;/span&gt;&lt;span&gt; 75&lt;/span&gt;                 &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.byteBufferHeader.limit(headerSize);
&lt;/span&gt;&lt;span&gt; 76&lt;/span&gt;                 &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.byteBufferHeader.putLong(thisOffset);
&lt;/span&gt;&lt;span&gt; 77&lt;/span&gt;                 &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.byteBufferHeader.putInt(size);
&lt;/span&gt;&lt;span&gt; 78&lt;/span&gt;                 &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.byteBufferHeader.flip();
&lt;/span&gt;&lt;span&gt; 79&lt;/span&gt; 
&lt;span&gt; 80&lt;/span&gt;                 &lt;span&gt;this&lt;/span&gt;.lastWriteOver = &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.transferData();
&lt;/span&gt;&lt;span&gt; 81&lt;/span&gt;             } &lt;span&gt;else&lt;/span&gt;&lt;span&gt; {
&lt;/span&gt;&lt;span&gt; 82&lt;/span&gt; 
&lt;span&gt; 83&lt;/span&gt;                 HAConnection.&lt;span&gt;this&lt;/span&gt;.haService.getWaitNotifyObject().allWaitForRunning(100&lt;span&gt;);
&lt;/span&gt;&lt;span&gt; 84&lt;/span&gt; &lt;span&gt;            }
&lt;/span&gt;&lt;span&gt; 85&lt;/span&gt;         } &lt;span&gt;catch&lt;/span&gt;&lt;span&gt; (Exception e) {
&lt;/span&gt;&lt;span&gt; 86&lt;/span&gt; 
&lt;span&gt; 87&lt;/span&gt;             HAConnection.log.error(&lt;span&gt;this&lt;/span&gt;.getServiceName() + &quot; service has exception.&quot;&lt;span&gt;, e);
&lt;/span&gt;&lt;span&gt; 88&lt;/span&gt;             &lt;span&gt;break&lt;/span&gt;&lt;span&gt;;
&lt;/span&gt;&lt;span&gt; 89&lt;/span&gt; &lt;span&gt;        }
&lt;/span&gt;&lt;span&gt; 90&lt;/span&gt; &lt;span&gt;    }
&lt;/span&gt;&lt;span&gt; 91&lt;/span&gt; 
&lt;span&gt; 92&lt;/span&gt;     HAConnection.&lt;span&gt;this&lt;/span&gt;&lt;span&gt;.haService.getWaitNotifyObject().removeFromWaitingThreadTable();
&lt;/span&gt;&lt;span&gt; 93&lt;/span&gt; 
&lt;span&gt; 94&lt;/span&gt;     &lt;span&gt;if&lt;/span&gt; (&lt;span&gt;this&lt;/span&gt;.selectMappedBufferResult != &lt;span&gt;null&lt;/span&gt;&lt;span&gt;) {
&lt;/span&gt;&lt;span&gt; 95&lt;/span&gt;         &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.selectMappedBufferResult.release();
&lt;/span&gt;&lt;span&gt; 96&lt;/span&gt; &lt;span&gt;    }
&lt;/span&gt;&lt;span&gt; 97&lt;/span&gt; 
&lt;span&gt; 98&lt;/span&gt;     &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.makeStop();
&lt;/span&gt;&lt;span&gt; 99&lt;/span&gt; 
&lt;span&gt;100&lt;/span&gt; &lt;span&gt;    readSocketService.makeStop();
&lt;/span&gt;&lt;span&gt;101&lt;/span&gt; 
&lt;span&gt;102&lt;/span&gt;     haService.removeConnection(HAConnection.&lt;span&gt;this&lt;/span&gt;&lt;span&gt;);
&lt;/span&gt;&lt;span&gt;103&lt;/span&gt; 
&lt;span&gt;104&lt;/span&gt;     SelectionKey sk = &lt;span&gt;this&lt;/span&gt;.socketChannel.keyFor(&lt;span&gt;this&lt;/span&gt;&lt;span&gt;.selector);
&lt;/span&gt;&lt;span&gt;105&lt;/span&gt;     &lt;span&gt;if&lt;/span&gt; (sk != &lt;span&gt;null&lt;/span&gt;&lt;span&gt;) {
&lt;/span&gt;&lt;span&gt;106&lt;/span&gt; &lt;span&gt;        sk.cancel();
&lt;/span&gt;&lt;span&gt;107&lt;/span&gt; &lt;span&gt;    }
&lt;/span&gt;&lt;span&gt;108&lt;/span&gt; 
&lt;span&gt;109&lt;/span&gt;     &lt;span&gt;try&lt;/span&gt;&lt;span&gt; {
&lt;/span&gt;&lt;span&gt;110&lt;/span&gt;         &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.selector.close();
&lt;/span&gt;&lt;span&gt;111&lt;/span&gt;         &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.socketChannel.close();
&lt;/span&gt;&lt;span&gt;112&lt;/span&gt;     } &lt;span&gt;catch&lt;/span&gt;&lt;span&gt; (IOException e) {
&lt;/span&gt;&lt;span&gt;113&lt;/span&gt;         HAConnection.log.error(&quot;&quot;&lt;span&gt;, e);
&lt;/span&gt;&lt;span&gt;114&lt;/span&gt; &lt;span&gt;    }
&lt;/span&gt;&lt;span&gt;115&lt;/span&gt; 
&lt;span&gt;116&lt;/span&gt;     HAConnection.log.info(&lt;span&gt;this&lt;/span&gt;.getServiceName() + &quot; service end&quot;&lt;span&gt;);
&lt;/span&gt;&lt;span&gt;117&lt;/span&gt; }
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;这里一开始会对slaveRequestOffset进行一次判断，当且仅当slaveRequestOffset初始化的时候是才是-1&lt;/p&gt;
&lt;p&gt;也就是说当slave还没有发送过来offset时，WriteSocketService线程只会干等&lt;/p&gt;
&lt;p&gt;当slave发送来offset后&lt;br/&gt;首先对nextTransferFromWhere进行了判断，nextTransferFromWhere和slaveRequestOffset一样，在初始化的时候为-1&lt;br/&gt;也就代表着master和slave刚刚建立连接，并没有进行过一次消息的同步！&lt;/p&gt;
&lt;p&gt;此时会对修改了的slaveRequestOffset进行判断&lt;br/&gt;若是等于0，说明slave没有任何消息的历史记录，那么此时master会取得自身的MaxOffset，根据这个MaxOffset，通过：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;33&quot;&gt;
&lt;pre&gt;
&lt;span&gt;1&lt;/span&gt; masterOffset =&lt;span&gt;  masterOffset
&lt;/span&gt;&lt;span&gt;2&lt;/span&gt;                 - (masterOffset % HAConnection.&lt;span&gt;this&lt;/span&gt;&lt;span&gt;.haService.getDefaultMessageStore().getMessageStoreConfig()
&lt;/span&gt;&lt;span&gt;3&lt;/span&gt;                 .getMapedFileSizeCommitLog() &lt;span&gt;/*&lt;/span&gt;&lt;span&gt; 1G &lt;/span&gt;&lt;span&gt;*/&lt;/span&gt;);
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;计算出最后一个文件开始的offset&lt;br/&gt;也就是说，当slave没有消息的历史记录，master只会从本地最后一个CommitLog文件开始的地方，将消息数据发送给slave&lt;/p&gt;
&lt;p&gt;&lt;br/&gt;若是slave有数据，就从slave发送来的offset的位置起，进行发送，通过nextTransferFromWhere记录这个offset值&lt;/p&gt;
&lt;p&gt;&lt;br/&gt;接着对lastWriteOver进行了判断，lastWriteOver是一个状态量，用来表示上次发送是否传输完毕，初始化是true&lt;/p&gt;
&lt;p&gt;&lt;br/&gt;若是true，这里会进行一次时间检查，lastWriteTimestamp记录最后一次发送的时间&lt;br/&gt;一次来判断是否超过了时间间隔haSendHeartbeatInterval（默认5s）&lt;br/&gt;也就是说至少有5s，master没有向slave发送任何消息&lt;br/&gt;那么此时就会发送一个心跳包&lt;/p&gt;
&lt;p&gt;其中byteBufferHeader是一个12字节的ByteBuffer：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;33&quot;&gt;
&lt;pre&gt;
&lt;span&gt;1&lt;/span&gt; &lt;span&gt;private&lt;/span&gt; &lt;span&gt;final&lt;/span&gt; &lt;span&gt;int&lt;/span&gt; headerSize = 8 + 4&lt;span&gt;;
&lt;/span&gt;&lt;span&gt;2&lt;/span&gt; &lt;span&gt;private&lt;/span&gt; &lt;span&gt;final&lt;/span&gt; ByteBuffer byteBufferHeader = ByteBuffer.allocate(headerSize);
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;这里就简单地构造了一个心跳包，后续通过transferData方法来完成数据的发送&lt;/p&gt;
&lt;p&gt;&lt;br/&gt;若是 lastWriteOver为false，则表示上次数据没有发送完，就需要通过transferData方法，将剩余数据继续发送，只要没发送完，只会重复循环，直到发完&lt;/p&gt;
&lt;p&gt;&lt;br/&gt;先继续往下看，下面就是发送具体的消息数据了：&lt;br/&gt;首先根据nextTransferFromWhere，也就是刚才保存的offset，通过DefaultMessageStore的getCommitLogData方法，其实际上调用的是CommitLog的getData方法，这个方法在&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.cnblogs.com/a526583280/p/11300861.html&quot; target=&quot;_blank&quot;&gt;【RocketMQ中Broker的启动源码分析（二）】&lt;/a&gt;中关于消息调度（ReputMessageService）时详细介绍过&lt;/p&gt;
&lt;p&gt;&lt;br/&gt;根据offset找到对应的CommitLog文件，将其从offset对应起始处所有数据读入ByteBuffer中，由SelectMappedBufferResult封装&lt;/p&gt;
&lt;p&gt;&lt;br/&gt;这里若是master已将将所有本地数据同步给了slave，那么得到的SelectMappedBufferResult就会为null，会调用：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;32&quot;&gt;
&lt;pre&gt;
&lt;span&gt;1&lt;/span&gt; HAConnection.&lt;span&gt;this&lt;/span&gt;.haService.getWaitNotifyObject().allWaitForRunning(100);
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;将自身阻塞，超时等待100ms，要么一直等到超时时间到了，要么就会在后面所讲的&lt;strong&gt;同步双传&lt;/strong&gt;中被同步master唤醒&lt;/p&gt;

&lt;p&gt;在得到SelectMappedBufferResult后，这里会对读取到的数据大小进行一次判断，若是大于haTransferBatchSize（默认32K），将size改为32K，实际上就是对发送数据大小的限制，大于32K会切割，每次最多只允许发送32k&lt;/p&gt;
&lt;p&gt;&lt;br/&gt;通过thisOffset记录nextTransferFromWhere即offset&lt;br/&gt;更新nextTransferFromWhere值，以便下一次定位&lt;br/&gt;还会将读取到的数据结果selectResult交给selectMappedBufferResult保存&lt;/p&gt;
&lt;p&gt;然后构建消息头，这里就和心跳包格式一样，前八字节存放offset，后四字节存放数据大小&lt;/p&gt;
&lt;p&gt;&lt;br/&gt;最后调用transferData方法，进行发送：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;35&quot;&gt;
&lt;pre&gt;
&lt;span&gt; 1&lt;/span&gt; &lt;span&gt;private&lt;/span&gt; &lt;span&gt;boolean&lt;/span&gt; transferData() &lt;span&gt;throws&lt;/span&gt;&lt;span&gt; Exception {
&lt;/span&gt;&lt;span&gt; 2&lt;/span&gt;     &lt;span&gt;int&lt;/span&gt; writeSizeZeroTimes = 0&lt;span&gt;;
&lt;/span&gt;&lt;span&gt; 3&lt;/span&gt;     &lt;span&gt;//&lt;/span&gt;&lt;span&gt; Write Header&lt;/span&gt;
&lt;span&gt; 4&lt;/span&gt;     &lt;span&gt;while&lt;/span&gt; (&lt;span&gt;this&lt;/span&gt;&lt;span&gt;.byteBufferHeader.hasRemaining()) {
&lt;/span&gt;&lt;span&gt; 5&lt;/span&gt;         &lt;span&gt;int&lt;/span&gt; writeSize = &lt;span&gt;this&lt;/span&gt;.socketChannel.write(&lt;span&gt;this&lt;/span&gt;&lt;span&gt;.byteBufferHeader);
&lt;/span&gt;&lt;span&gt; 6&lt;/span&gt;         &lt;span&gt;if&lt;/span&gt; (writeSize &amp;gt; 0&lt;span&gt;) {
&lt;/span&gt;&lt;span&gt; 7&lt;/span&gt;             writeSizeZeroTimes = 0&lt;span&gt;;
&lt;/span&gt;&lt;span&gt; 8&lt;/span&gt;             &lt;span&gt;this&lt;/span&gt;.lastWriteTimestamp = HAConnection.&lt;span&gt;this&lt;/span&gt;&lt;span&gt;.haService.getDefaultMessageStore().getSystemClock().now();
&lt;/span&gt;&lt;span&gt; 9&lt;/span&gt;         } &lt;span&gt;else&lt;/span&gt; &lt;span&gt;if&lt;/span&gt; (writeSize == 0&lt;span&gt;) {
&lt;/span&gt;&lt;span&gt;10&lt;/span&gt;             &lt;span&gt;if&lt;/span&gt; (++writeSizeZeroTimes &amp;gt;= 3&lt;span&gt;) {
&lt;/span&gt;&lt;span&gt;11&lt;/span&gt;                 &lt;span&gt;break&lt;/span&gt;&lt;span&gt;;
&lt;/span&gt;&lt;span&gt;12&lt;/span&gt; &lt;span&gt;            }
&lt;/span&gt;&lt;span&gt;13&lt;/span&gt;         } &lt;span&gt;else&lt;/span&gt;&lt;span&gt; {
&lt;/span&gt;&lt;span&gt;14&lt;/span&gt;             &lt;span&gt;throw&lt;/span&gt; &lt;span&gt;new&lt;/span&gt; Exception(&quot;ha master write header error &amp;lt; 0&quot;&lt;span&gt;);
&lt;/span&gt;&lt;span&gt;15&lt;/span&gt; &lt;span&gt;        }
&lt;/span&gt;&lt;span&gt;16&lt;/span&gt; &lt;span&gt;    }
&lt;/span&gt;&lt;span&gt;17&lt;/span&gt; 
&lt;span&gt;18&lt;/span&gt;     &lt;span&gt;if&lt;/span&gt; (&lt;span&gt;null&lt;/span&gt; == &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.selectMappedBufferResult) {
&lt;/span&gt;&lt;span&gt;19&lt;/span&gt;         &lt;span&gt;return&lt;/span&gt; !&lt;span&gt;this&lt;/span&gt;&lt;span&gt;.byteBufferHeader.hasRemaining();
&lt;/span&gt;&lt;span&gt;20&lt;/span&gt; &lt;span&gt;    }
&lt;/span&gt;&lt;span&gt;21&lt;/span&gt; 
&lt;span&gt;22&lt;/span&gt;     writeSizeZeroTimes = 0&lt;span&gt;;
&lt;/span&gt;&lt;span&gt;23&lt;/span&gt; 
&lt;span&gt;24&lt;/span&gt;     &lt;span&gt;//&lt;/span&gt;&lt;span&gt; Write Body&lt;/span&gt;
&lt;span&gt;25&lt;/span&gt;     &lt;span&gt;if&lt;/span&gt; (!&lt;span&gt;this&lt;/span&gt;&lt;span&gt;.byteBufferHeader.hasRemaining()) {
&lt;/span&gt;&lt;span&gt;26&lt;/span&gt;         &lt;span&gt;while&lt;/span&gt; (&lt;span&gt;this&lt;/span&gt;&lt;span&gt;.selectMappedBufferResult.getByteBuffer().hasRemaining()) {
&lt;/span&gt;&lt;span&gt;27&lt;/span&gt;             &lt;span&gt;int&lt;/span&gt; writeSize = &lt;span&gt;this&lt;/span&gt;.socketChannel.write(&lt;span&gt;this&lt;/span&gt;&lt;span&gt;.selectMappedBufferResult.getByteBuffer());
&lt;/span&gt;&lt;span&gt;28&lt;/span&gt;             &lt;span&gt;if&lt;/span&gt; (writeSize &amp;gt; 0&lt;span&gt;) {
&lt;/span&gt;&lt;span&gt;29&lt;/span&gt;                 writeSizeZeroTimes = 0&lt;span&gt;;
&lt;/span&gt;&lt;span&gt;30&lt;/span&gt;                 &lt;span&gt;this&lt;/span&gt;.lastWriteTimestamp = HAConnection.&lt;span&gt;this&lt;/span&gt;&lt;span&gt;.haService.getDefaultMessageStore().getSystemClock().now();
&lt;/span&gt;&lt;span&gt;31&lt;/span&gt;             } &lt;span&gt;else&lt;/span&gt; &lt;span&gt;if&lt;/span&gt; (writeSize == 0&lt;span&gt;) {
&lt;/span&gt;&lt;span&gt;32&lt;/span&gt;                 &lt;span&gt;if&lt;/span&gt; (++writeSizeZeroTimes &amp;gt;= 3&lt;span&gt;) {
&lt;/span&gt;&lt;span&gt;33&lt;/span&gt;                     &lt;span&gt;break&lt;/span&gt;&lt;span&gt;;
&lt;/span&gt;&lt;span&gt;34&lt;/span&gt; &lt;span&gt;                }
&lt;/span&gt;&lt;span&gt;35&lt;/span&gt;             } &lt;span&gt;else&lt;/span&gt;&lt;span&gt; {
&lt;/span&gt;&lt;span&gt;36&lt;/span&gt;                 &lt;span&gt;throw&lt;/span&gt; &lt;span&gt;new&lt;/span&gt; Exception(&quot;ha master write body error &amp;lt; 0&quot;&lt;span&gt;);
&lt;/span&gt;&lt;span&gt;37&lt;/span&gt; &lt;span&gt;            }
&lt;/span&gt;&lt;span&gt;38&lt;/span&gt; &lt;span&gt;        }
&lt;/span&gt;&lt;span&gt;39&lt;/span&gt; &lt;span&gt;    }
&lt;/span&gt;&lt;span&gt;40&lt;/span&gt; 
&lt;span&gt;41&lt;/span&gt;     &lt;span&gt;boolean&lt;/span&gt; result = !&lt;span&gt;this&lt;/span&gt;.byteBufferHeader.hasRemaining() &amp;amp;&amp;amp; !&lt;span&gt;this&lt;/span&gt;&lt;span&gt;.selectMappedBufferResult.getByteBuffer().hasRemaining();
&lt;/span&gt;&lt;span&gt;42&lt;/span&gt; 
&lt;span&gt;43&lt;/span&gt;     &lt;span&gt;if&lt;/span&gt; (!&lt;span&gt;this&lt;/span&gt;&lt;span&gt;.selectMappedBufferResult.getByteBuffer().hasRemaining()) {
&lt;/span&gt;&lt;span&gt;44&lt;/span&gt;         &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.selectMappedBufferResult.release();
&lt;/span&gt;&lt;span&gt;45&lt;/span&gt;         &lt;span&gt;this&lt;/span&gt;.selectMappedBufferResult = &lt;span&gt;null&lt;/span&gt;&lt;span&gt;;
&lt;/span&gt;&lt;span&gt;46&lt;/span&gt; &lt;span&gt;    }
&lt;/span&gt;&lt;span&gt;47&lt;/span&gt; 
&lt;span&gt;48&lt;/span&gt;     &lt;span&gt;return&lt;/span&gt;&lt;span&gt; result;
&lt;/span&gt;&lt;span&gt;49&lt;/span&gt; }
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;首先将byteBufferHeader中的12字节消息头通过socketChannel的write方法发送出去&lt;br/&gt;然后将selectMappedBufferResult中的ByteBuffer的消息数据发送出去&lt;/p&gt;
&lt;p&gt;若是selectMappedBufferResult等于null，说明是心跳包，只发送消息头&lt;br/&gt;无论发送什么都会将时间记录在lastWriteTimestamp中，以便后续发送心跳包的判断&lt;/p&gt;
&lt;p&gt;&lt;br/&gt;看到这里其实就会发现WriteSocketService线程开启后，只要slave向master发出了第一个offset后，WriteSocketService线程都会不断地将对应位置自己本地的CommitLog文件中的内容发送给slave，直到完全同步后，WriteSocketService线程才会稍微缓缓，进入阻塞100ms以及每隔五秒发一次心跳包的状态&lt;/p&gt;
&lt;p&gt;但是只要当Producer向master发送来消息后，由刷盘线程完成持久化后，WriteSocketService线程又会忙碌起来，此时也才是体现&lt;strong&gt;同步双写&lt;/strong&gt;和&lt;strong&gt;异步复制&lt;/strong&gt;的时候&lt;/p&gt;
&lt;p&gt;先不急着说这个，来看看slave接收到消息是如何处理的：&lt;/p&gt;
&lt;p&gt;&lt;br/&gt;是在HAClient的线程中的processReadEvent方法处理的：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;39&quot;&gt;
&lt;pre&gt;
&lt;span&gt; 1&lt;/span&gt; &lt;span&gt;private&lt;/span&gt; &lt;span&gt;boolean&lt;/span&gt;&lt;span&gt; processReadEvent() {
&lt;/span&gt;&lt;span&gt; 2&lt;/span&gt;     &lt;span&gt;int&lt;/span&gt; readSizeZeroTimes = 0&lt;span&gt;;
&lt;/span&gt;&lt;span&gt; 3&lt;/span&gt;     &lt;span&gt;while&lt;/span&gt; (&lt;span&gt;this&lt;/span&gt;&lt;span&gt;.byteBufferRead.hasRemaining()) {
&lt;/span&gt;&lt;span&gt; 4&lt;/span&gt;         &lt;span&gt;try&lt;/span&gt;&lt;span&gt; {
&lt;/span&gt;&lt;span&gt; 5&lt;/span&gt;             &lt;span&gt;int&lt;/span&gt; readSize = &lt;span&gt;this&lt;/span&gt;.socketChannel.read(&lt;span&gt;this&lt;/span&gt;&lt;span&gt;.byteBufferRead);
&lt;/span&gt;&lt;span&gt; 6&lt;/span&gt;             &lt;span&gt;if&lt;/span&gt; (readSize &amp;gt; 0&lt;span&gt;) {
&lt;/span&gt;&lt;span&gt; 7&lt;/span&gt;                 lastWriteTimestamp = HAService.&lt;span&gt;this&lt;/span&gt;&lt;span&gt;.defaultMessageStore.getSystemClock().now();
&lt;/span&gt;&lt;span&gt; 8&lt;/span&gt;                 readSizeZeroTimes = 0&lt;span&gt;;
&lt;/span&gt;&lt;span&gt; 9&lt;/span&gt;                 &lt;span&gt;boolean&lt;/span&gt; result = &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.dispatchReadRequest();
&lt;/span&gt;&lt;span&gt;10&lt;/span&gt;                 &lt;span&gt;if&lt;/span&gt; (!&lt;span&gt;result) {
&lt;/span&gt;&lt;span&gt;11&lt;/span&gt;                     log.error(&quot;HAClient, dispatchReadRequest error&quot;&lt;span&gt;);
&lt;/span&gt;&lt;span&gt;12&lt;/span&gt;                     &lt;span&gt;return&lt;/span&gt; &lt;span&gt;false&lt;/span&gt;&lt;span&gt;;
&lt;/span&gt;&lt;span&gt;13&lt;/span&gt; &lt;span&gt;                }
&lt;/span&gt;&lt;span&gt;14&lt;/span&gt;             } &lt;span&gt;else&lt;/span&gt; &lt;span&gt;if&lt;/span&gt; (readSize == 0&lt;span&gt;) {
&lt;/span&gt;&lt;span&gt;15&lt;/span&gt;                 &lt;span&gt;if&lt;/span&gt; (++readSizeZeroTimes &amp;gt;= 3&lt;span&gt;) {
&lt;/span&gt;&lt;span&gt;16&lt;/span&gt;                     &lt;span&gt;break&lt;/span&gt;&lt;span&gt;;
&lt;/span&gt;&lt;span&gt;17&lt;/span&gt; &lt;span&gt;                }
&lt;/span&gt;&lt;span&gt;18&lt;/span&gt;             } &lt;span&gt;else&lt;/span&gt;&lt;span&gt; {
&lt;/span&gt;&lt;span&gt;19&lt;/span&gt;                 log.info(&quot;HAClient, processReadEvent read socket &amp;lt; 0&quot;&lt;span&gt;);
&lt;/span&gt;&lt;span&gt;20&lt;/span&gt;                 &lt;span&gt;return&lt;/span&gt; &lt;span&gt;false&lt;/span&gt;&lt;span&gt;;
&lt;/span&gt;&lt;span&gt;21&lt;/span&gt; &lt;span&gt;            }
&lt;/span&gt;&lt;span&gt;22&lt;/span&gt;         } &lt;span&gt;catch&lt;/span&gt;&lt;span&gt; (IOException e) {
&lt;/span&gt;&lt;span&gt;23&lt;/span&gt;             log.info(&quot;HAClient, processReadEvent read socket exception&quot;&lt;span&gt;, e);
&lt;/span&gt;&lt;span&gt;24&lt;/span&gt;             &lt;span&gt;return&lt;/span&gt; &lt;span&gt;false&lt;/span&gt;&lt;span&gt;;
&lt;/span&gt;&lt;span&gt;25&lt;/span&gt; &lt;span&gt;        }
&lt;/span&gt;&lt;span&gt;26&lt;/span&gt; &lt;span&gt;    }
&lt;/span&gt;&lt;span&gt;27&lt;/span&gt; 
&lt;span&gt;28&lt;/span&gt;     &lt;span&gt;return&lt;/span&gt; &lt;span&gt;true&lt;/span&gt;&lt;span&gt;;
&lt;/span&gt;&lt;span&gt;29&lt;/span&gt; }
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;在socketChannel通过read方法将master发送的数据读取到byteBufferRead缓冲区后，由dispatchReadRequest方法做进一步处理&lt;/p&gt;
&lt;p&gt;&lt;br/&gt;dispatchReadRequest方法：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;37&quot;&gt;
&lt;pre&gt;
&lt;span&gt; 1&lt;/span&gt; &lt;span&gt;private&lt;/span&gt; &lt;span&gt;boolean&lt;/span&gt;&lt;span&gt; dispatchReadRequest() {
&lt;/span&gt;&lt;span&gt; 2&lt;/span&gt;     &lt;span&gt;final&lt;/span&gt; &lt;span&gt;int&lt;/span&gt; msgHeaderSize = 8 + 4; &lt;span&gt;//&lt;/span&gt;&lt;span&gt; phyoffset + size&lt;/span&gt;
&lt;span&gt; 3&lt;/span&gt;     &lt;span&gt;int&lt;/span&gt; readSocketPos = &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.byteBufferRead.position();
&lt;/span&gt;&lt;span&gt; 4&lt;/span&gt; 
&lt;span&gt; 5&lt;/span&gt;     &lt;span&gt;while&lt;/span&gt; (&lt;span&gt;true&lt;/span&gt;&lt;span&gt;) {
&lt;/span&gt;&lt;span&gt; 6&lt;/span&gt;         &lt;span&gt;int&lt;/span&gt; diff = &lt;span&gt;this&lt;/span&gt;.byteBufferRead.position() - &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.dispatchPostion;
&lt;/span&gt;&lt;span&gt; 7&lt;/span&gt;         &lt;span&gt;if&lt;/span&gt; (diff &amp;gt;=&lt;span&gt; msgHeaderSize) {
&lt;/span&gt;&lt;span&gt; 8&lt;/span&gt;             &lt;span&gt;long&lt;/span&gt; masterPhyOffset = &lt;span&gt;this&lt;/span&gt;.byteBufferRead.getLong(&lt;span&gt;this&lt;/span&gt;&lt;span&gt;.dispatchPostion);
&lt;/span&gt;&lt;span&gt; 9&lt;/span&gt;             &lt;span&gt;int&lt;/span&gt; bodySize = &lt;span&gt;this&lt;/span&gt;.byteBufferRead.getInt(&lt;span&gt;this&lt;/span&gt;.dispatchPostion + 8&lt;span&gt;);
&lt;/span&gt;&lt;span&gt;10&lt;/span&gt; 
&lt;span&gt;11&lt;/span&gt;             &lt;span&gt;long&lt;/span&gt; slavePhyOffset = HAService.&lt;span&gt;this&lt;/span&gt;&lt;span&gt;.defaultMessageStore.getMaxPhyOffset();
&lt;/span&gt;&lt;span&gt;12&lt;/span&gt; 
&lt;span&gt;13&lt;/span&gt;             &lt;span&gt;if&lt;/span&gt; (slavePhyOffset != 0&lt;span&gt;) {
&lt;/span&gt;&lt;span&gt;14&lt;/span&gt;                 &lt;span&gt;if&lt;/span&gt; (slavePhyOffset !=&lt;span&gt; masterPhyOffset) {
&lt;/span&gt;&lt;span&gt;15&lt;/span&gt;                     log.error(&quot;master pushed offset not equal the max phy offset in slave, SLAVE: &quot;
&lt;span&gt;16&lt;/span&gt;                         + slavePhyOffset + &quot; MASTER: &quot; +&lt;span&gt; masterPhyOffset);
&lt;/span&gt;&lt;span&gt;17&lt;/span&gt;                     &lt;span&gt;return&lt;/span&gt; &lt;span&gt;false&lt;/span&gt;&lt;span&gt;;
&lt;/span&gt;&lt;span&gt;18&lt;/span&gt; &lt;span&gt;                }
&lt;/span&gt;&lt;span&gt;19&lt;/span&gt; &lt;span&gt;            }
&lt;/span&gt;&lt;span&gt;20&lt;/span&gt; 
&lt;span&gt;21&lt;/span&gt;             &lt;span&gt;if&lt;/span&gt; (diff &amp;gt;= (msgHeaderSize +&lt;span&gt; bodySize)) {
&lt;/span&gt;&lt;span&gt;22&lt;/span&gt;                 &lt;span&gt;byte&lt;/span&gt;[] bodyData = &lt;span&gt;new&lt;/span&gt; &lt;span&gt;byte&lt;/span&gt;&lt;span&gt;[bodySize];
&lt;/span&gt;&lt;span&gt;23&lt;/span&gt;                 &lt;span&gt;this&lt;/span&gt;.byteBufferRead.position(&lt;span&gt;this&lt;/span&gt;.dispatchPostion +&lt;span&gt; msgHeaderSize);
&lt;/span&gt;&lt;span&gt;24&lt;/span&gt;                 &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.byteBufferRead.get(bodyData);
&lt;/span&gt;&lt;span&gt;25&lt;/span&gt; 
&lt;span&gt;26&lt;/span&gt;                 HAService.&lt;span&gt;this&lt;/span&gt;&lt;span&gt;.defaultMessageStore.appendToCommitLog(masterPhyOffset, bodyData);
&lt;/span&gt;&lt;span&gt;27&lt;/span&gt; 
&lt;span&gt;28&lt;/span&gt;                 &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.byteBufferRead.position(readSocketPos);
&lt;/span&gt;&lt;span&gt;29&lt;/span&gt;                 &lt;span&gt;this&lt;/span&gt;.dispatchPostion += msgHeaderSize +&lt;span&gt; bodySize;
&lt;/span&gt;&lt;span&gt;30&lt;/span&gt; 
&lt;span&gt;31&lt;/span&gt;                 &lt;span&gt;if&lt;/span&gt; (!&lt;span&gt;reportSlaveMaxOffsetPlus()) {
&lt;/span&gt;&lt;span&gt;32&lt;/span&gt;                     &lt;span&gt;return&lt;/span&gt; &lt;span&gt;false&lt;/span&gt;&lt;span&gt;;
&lt;/span&gt;&lt;span&gt;33&lt;/span&gt; &lt;span&gt;                }
&lt;/span&gt;&lt;span&gt;34&lt;/span&gt; 
&lt;span&gt;35&lt;/span&gt;                 &lt;span&gt;continue&lt;/span&gt;&lt;span&gt;;
&lt;/span&gt;&lt;span&gt;36&lt;/span&gt; &lt;span&gt;            }
&lt;/span&gt;&lt;span&gt;37&lt;/span&gt; &lt;span&gt;        }
&lt;/span&gt;&lt;span&gt;38&lt;/span&gt; 
&lt;span&gt;39&lt;/span&gt;         &lt;span&gt;if&lt;/span&gt; (!&lt;span&gt;this&lt;/span&gt;&lt;span&gt;.byteBufferRead.hasRemaining()) {
&lt;/span&gt;&lt;span&gt;40&lt;/span&gt;             &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.reallocateByteBuffer();
&lt;/span&gt;&lt;span&gt;41&lt;/span&gt; &lt;span&gt;        }
&lt;/span&gt;&lt;span&gt;42&lt;/span&gt; 
&lt;span&gt;43&lt;/span&gt;         &lt;span&gt;break&lt;/span&gt;&lt;span&gt;;
&lt;/span&gt;&lt;span&gt;44&lt;/span&gt; &lt;span&gt;    }
&lt;/span&gt;&lt;span&gt;45&lt;/span&gt; 
&lt;span&gt;46&lt;/span&gt;     &lt;span&gt;return&lt;/span&gt; &lt;span&gt;true&lt;/span&gt;&lt;span&gt;;
&lt;/span&gt;&lt;span&gt;47&lt;/span&gt; }
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;这里就首先将12字节的消息头取出来&lt;br/&gt;masterPhyOffset：8字节offset ，bodySize ：4字节消息大小&lt;br/&gt;根据master发来的masterPhyOffset会和自己本地的slavePhyOffset进行校验，以便安全备份&lt;/p&gt;
&lt;p&gt;&lt;br/&gt;之后就会将byteBufferRead中存放在消息头后面的消息数据取出来，调用appendToCommitLog方法持久化到的CommitLog中&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;38&quot;&gt;
&lt;pre&gt;
&lt;span&gt; 1&lt;/span&gt; &lt;span&gt;public&lt;/span&gt; &lt;span&gt;boolean&lt;/span&gt; appendToCommitLog(&lt;span&gt;long&lt;/span&gt; startOffset, &lt;span&gt;byte&lt;/span&gt;&lt;span&gt;[] data) {
&lt;/span&gt;&lt;span&gt; 2&lt;/span&gt;     &lt;span&gt;if&lt;/span&gt; (&lt;span&gt;this&lt;/span&gt;&lt;span&gt;.shutdown) {
&lt;/span&gt;&lt;span&gt; 3&lt;/span&gt;         log.warn(&quot;message store has shutdown, so appendToPhyQueue is forbidden&quot;&lt;span&gt;);
&lt;/span&gt;&lt;span&gt; 4&lt;/span&gt;         &lt;span&gt;return&lt;/span&gt; &lt;span&gt;false&lt;/span&gt;&lt;span&gt;;
&lt;/span&gt;&lt;span&gt; 5&lt;/span&gt; &lt;span&gt;    }
&lt;/span&gt;&lt;span&gt; 6&lt;/span&gt; 
&lt;span&gt; 7&lt;/span&gt;     &lt;span&gt;boolean&lt;/span&gt; result = &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.commitLog.appendData(startOffset, data);
&lt;/span&gt;&lt;span&gt; 8&lt;/span&gt;     &lt;span&gt;if&lt;/span&gt;&lt;span&gt; (result) {
&lt;/span&gt;&lt;span&gt; 9&lt;/span&gt;         &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.reputMessageService.wakeup();
&lt;/span&gt;&lt;span&gt;10&lt;/span&gt;     } &lt;span&gt;else&lt;/span&gt;&lt;span&gt; {
&lt;/span&gt;&lt;span&gt;11&lt;/span&gt;         log.error(&quot;appendToPhyQueue failed &quot; + startOffset + &quot; &quot; +&lt;span&gt; data.length);
&lt;/span&gt;&lt;span&gt;12&lt;/span&gt; &lt;span&gt;    }
&lt;/span&gt;&lt;span&gt;13&lt;/span&gt; 
&lt;span&gt;14&lt;/span&gt;     &lt;span&gt;return&lt;/span&gt;&lt;span&gt; result;
&lt;/span&gt;&lt;span&gt;15&lt;/span&gt; }
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;实际上调用了commitLog的appendData方法将其写入磁盘，这个方法我在前面博客中介绍过&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.cnblogs.com/a526583280/p/11312750.html&quot; target=&quot;_blank&quot;&gt;【RocketMQ中Broker的刷盘源码分析】&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;br/&gt;在完成写入后，需要唤醒reputMessageService消息调度，以便Consumer的消费&lt;br/&gt;关于消息调度详见  &lt;a href=&quot;https://www.cnblogs.com/a526583280/p/11300861.html&quot; target=&quot;_blank&quot;&gt;【RocketMQ中Broker的启动源码分析（二）】&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;br/&gt;当然前面说过master还会发送心跳消息，但这里明显没对心跳消息进行处理，只是appendToCommitLog调用时，传入了一个大小为0的byte数组，显然有些不合理，想不通&lt;/p&gt;
&lt;p&gt;&lt;br/&gt;在完成后，还会调用reportSlaveMaxOffsetPlus方法：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;37&quot;&gt;
&lt;pre&gt;
&lt;span&gt; 1&lt;/span&gt; &lt;span&gt;private&lt;/span&gt; &lt;span&gt;boolean&lt;/span&gt;&lt;span&gt; reportSlaveMaxOffsetPlus() {
&lt;/span&gt;&lt;span&gt; 2&lt;/span&gt;     &lt;span&gt;boolean&lt;/span&gt; result = &lt;span&gt;true&lt;/span&gt;&lt;span&gt;;
&lt;/span&gt;&lt;span&gt; 3&lt;/span&gt;     &lt;span&gt;long&lt;/span&gt; currentPhyOffset = HAService.&lt;span&gt;this&lt;/span&gt;&lt;span&gt;.defaultMessageStore.getMaxPhyOffset();
&lt;/span&gt;&lt;span&gt; 4&lt;/span&gt;     &lt;span&gt;if&lt;/span&gt; (currentPhyOffset &amp;gt; &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.currentReportedOffset) {
&lt;/span&gt;&lt;span&gt; 5&lt;/span&gt;         &lt;span&gt;this&lt;/span&gt;.currentReportedOffset =&lt;span&gt; currentPhyOffset;
&lt;/span&gt;&lt;span&gt; 6&lt;/span&gt;         result = &lt;span&gt;this&lt;/span&gt;.reportSlaveMaxOffset(&lt;span&gt;this&lt;/span&gt;&lt;span&gt;.currentReportedOffset);
&lt;/span&gt;&lt;span&gt; 7&lt;/span&gt;         &lt;span&gt;if&lt;/span&gt; (!&lt;span&gt;result) {
&lt;/span&gt;&lt;span&gt; 8&lt;/span&gt;             &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.closeMaster();
&lt;/span&gt;&lt;span&gt; 9&lt;/span&gt;             log.error(&quot;HAClient, reportSlaveMaxOffset error, &quot; + &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.currentReportedOffset);
&lt;/span&gt;&lt;span&gt;10&lt;/span&gt; &lt;span&gt;        }
&lt;/span&gt;&lt;span&gt;11&lt;/span&gt; &lt;span&gt;    }
&lt;/span&gt;&lt;span&gt;12&lt;/span&gt; 
&lt;span&gt;13&lt;/span&gt;     &lt;span&gt;return&lt;/span&gt;&lt;span&gt; result;
&lt;/span&gt;&lt;span&gt;14&lt;/span&gt; }
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;由于完成了写入，那么此时获取到的offset肯定比currentReportedOffset中保存的大，然后再次通过reportSlaveMaxOffset方法，将当前的offset报告给master&lt;/p&gt;
&lt;p&gt;&lt;br/&gt;这其实上已经完成了异步master的&lt;strong&gt;异步复制&lt;/strong&gt;过程&lt;/p&gt;
&lt;p&gt;&lt;br/&gt;再来看看&lt;strong&gt;同步双写&lt;/strong&gt;是如何实现的：&lt;br/&gt;和刷盘一样，都是在Producer发送完消息，Broker进行完消息的存储后进行的&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.cnblogs.com/a526583280/p/11306645.html&quot; target=&quot;_blank&quot;&gt;【RocketMQ中Broker的消息存储源码分析】&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;在CommitLog的handleHA方法：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;41&quot;&gt;
&lt;pre&gt;
&lt;span&gt; 1&lt;/span&gt; &lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt;&lt;span&gt; handleHA(AppendMessageResult result, PutMessageResult putMessageResult, MessageExt messageExt) {
&lt;/span&gt;&lt;span&gt; 2&lt;/span&gt;     &lt;span&gt;if&lt;/span&gt; (BrokerRole.SYNC_MASTER == &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.defaultMessageStore.getMessageStoreConfig().getBrokerRole()) {
&lt;/span&gt;&lt;span&gt; 3&lt;/span&gt;         HAService service = &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.defaultMessageStore.getHaService();
&lt;/span&gt;&lt;span&gt; 4&lt;/span&gt;         &lt;span&gt;if&lt;/span&gt;&lt;span&gt; (messageExt.isWaitStoreMsgOK()) {
&lt;/span&gt;&lt;span&gt; 5&lt;/span&gt;             &lt;span&gt;//&lt;/span&gt;&lt;span&gt; Determine whether to wait&lt;/span&gt;
&lt;span&gt; 6&lt;/span&gt;             &lt;span&gt;if&lt;/span&gt; (service.isSlaveOK(result.getWroteOffset() +&lt;span&gt; result.getWroteBytes())) {
&lt;/span&gt;&lt;span&gt; 7&lt;/span&gt;                 GroupCommitRequest request = &lt;span&gt;new&lt;/span&gt; GroupCommitRequest(result.getWroteOffset() +&lt;span&gt; result.getWroteBytes());
&lt;/span&gt;&lt;span&gt; 8&lt;/span&gt; &lt;span&gt;                service.putRequest(request);
&lt;/span&gt;&lt;span&gt; 9&lt;/span&gt; &lt;span&gt;                service.getWaitNotifyObject().wakeupAll();
&lt;/span&gt;&lt;span&gt;10&lt;/span&gt;                 &lt;span&gt;boolean&lt;/span&gt; flushOK =
&lt;span&gt;11&lt;/span&gt;                     request.waitForFlush(&lt;span&gt;this&lt;/span&gt;&lt;span&gt;.defaultMessageStore.getMessageStoreConfig().getSyncFlushTimeout());
&lt;/span&gt;&lt;span&gt;12&lt;/span&gt;                 &lt;span&gt;if&lt;/span&gt; (!&lt;span&gt;flushOK) {
&lt;/span&gt;&lt;span&gt;13&lt;/span&gt;                     log.error(&quot;do sync transfer other node, wait return, but failed, topic: &quot; + messageExt.getTopic() + &quot; tags: &quot;
&lt;span&gt;14&lt;/span&gt;                         + messageExt.getTags() + &quot; client address: &quot; +&lt;span&gt; messageExt.getBornHostNameString());
&lt;/span&gt;&lt;span&gt;15&lt;/span&gt; &lt;span&gt;                    putMessageResult.setPutMessageStatus(PutMessageStatus.FLUSH_SLAVE_TIMEOUT);
&lt;/span&gt;&lt;span&gt;16&lt;/span&gt; &lt;span&gt;                }
&lt;/span&gt;&lt;span&gt;17&lt;/span&gt; &lt;span&gt;            }
&lt;/span&gt;&lt;span&gt;18&lt;/span&gt;             &lt;span&gt;//&lt;/span&gt;&lt;span&gt; Slave problem&lt;/span&gt;
&lt;span&gt;19&lt;/span&gt;             &lt;span&gt;else&lt;/span&gt;&lt;span&gt; {
&lt;/span&gt;&lt;span&gt;20&lt;/span&gt;                 &lt;span&gt;//&lt;/span&gt;&lt;span&gt; Tell the producer, slave not available&lt;/span&gt;
&lt;span&gt;21&lt;/span&gt; &lt;span&gt;                putMessageResult.setPutMessageStatus(PutMessageStatus.SLAVE_NOT_AVAILABLE);
&lt;/span&gt;&lt;span&gt;22&lt;/span&gt; &lt;span&gt;            }
&lt;/span&gt;&lt;span&gt;23&lt;/span&gt; &lt;span&gt;        }
&lt;/span&gt;&lt;span&gt;24&lt;/span&gt; &lt;span&gt;    }
&lt;/span&gt;&lt;span&gt;25&lt;/span&gt; 
&lt;span&gt;26&lt;/span&gt; }
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;这里就会检查Broker的类型，看以看到只对SYNC_MASTER即同步master进行了操作&lt;/p&gt;
&lt;p&gt;这个操作过程其实就和同步刷盘类似&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.cnblogs.com/a526583280/p/11312750.html&quot; target=&quot;_blank&quot;&gt;【RocketMQ中Broker的刷盘源码分析】&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;根据Offset+WroteBytes创建一条记录GroupCommitRequest，然后会将添加在List中&lt;br/&gt;然后调用getWaitNotifyObject的wakeupAll方法，把阻塞中的&lt;strong&gt;所有&lt;/strong&gt;WriteSocketService线程唤醒&lt;br/&gt;因为master和slave是一对多的关系，那么这里就会有多个slave连接，也就有多个WriteSocketService线程，保证消息能同步到所有slave中&lt;/p&gt;
&lt;p&gt;在唤醒WriteSocketService线程工作后，调用request的waitForFlush方法，将自身阻塞，预示着同步复制的真正开启&lt;/p&gt;
&lt;p&gt;&lt;br/&gt;在HAService开启时，还开启了一个GroupTransferService线程：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;36&quot;&gt;
&lt;pre&gt;
&lt;span&gt; 1&lt;/span&gt; &lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt;&lt;span&gt; run() {
&lt;/span&gt;&lt;span&gt; 2&lt;/span&gt;     log.info(&lt;span&gt;this&lt;/span&gt;.getServiceName() + &quot; service started&quot;&lt;span&gt;);
&lt;/span&gt;&lt;span&gt; 3&lt;/span&gt; 
&lt;span&gt; 4&lt;/span&gt;     &lt;span&gt;while&lt;/span&gt; (!&lt;span&gt;this&lt;/span&gt;&lt;span&gt;.isStopped()) {
&lt;/span&gt;&lt;span&gt; 5&lt;/span&gt;         &lt;span&gt;try&lt;/span&gt;&lt;span&gt; {
&lt;/span&gt;&lt;span&gt; 6&lt;/span&gt;             &lt;span&gt;this&lt;/span&gt;.waitForRunning(10&lt;span&gt;);
&lt;/span&gt;&lt;span&gt; 7&lt;/span&gt;             &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.doWaitTransfer();
&lt;/span&gt;&lt;span&gt; 8&lt;/span&gt;         } &lt;span&gt;catch&lt;/span&gt;&lt;span&gt; (Exception e) {
&lt;/span&gt;&lt;span&gt; 9&lt;/span&gt;             log.warn(&lt;span&gt;this&lt;/span&gt;.getServiceName() + &quot; service has exception. &quot;&lt;span&gt;, e);
&lt;/span&gt;&lt;span&gt;10&lt;/span&gt; &lt;span&gt;        }
&lt;/span&gt;&lt;span&gt;11&lt;/span&gt; &lt;span&gt;    }
&lt;/span&gt;&lt;span&gt;12&lt;/span&gt; 
&lt;span&gt;13&lt;/span&gt;     log.info(&lt;span&gt;this&lt;/span&gt;.getServiceName() + &quot; service end&quot;&lt;span&gt;);
&lt;/span&gt;&lt;span&gt;14&lt;/span&gt; }
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;这里的工作原理和同步刷盘GroupCommitService基本一致，相似的地方我就不仔细分析了&lt;/p&gt;
&lt;p&gt;&lt;br/&gt;GroupTransferService同样保存两张List：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;33&quot;&gt;
&lt;pre&gt;
&lt;span&gt;1&lt;/span&gt; &lt;span&gt;private&lt;/span&gt; &lt;span&gt;volatile&lt;/span&gt; List&amp;lt;CommitLog.GroupCommitRequest&amp;gt; requestsWrite = &lt;span&gt;new&lt;/span&gt; ArrayList&amp;lt;&amp;gt;&lt;span&gt;();
&lt;/span&gt;&lt;span&gt;2&lt;/span&gt; &lt;span&gt;private&lt;/span&gt; &lt;span&gt;volatile&lt;/span&gt; List&amp;lt;CommitLog.GroupCommitRequest&amp;gt; requestsRead = &lt;span&gt;new&lt;/span&gt; ArrayList&amp;lt;&amp;gt;();
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;由这两张List做一个类似JVM新生代的复制算法&lt;br/&gt;在handleHA方法中，就会将创建的GroupCommitRequest记录添加在requestsWrite这个List中&lt;/p&gt;
&lt;p&gt;&lt;br/&gt;其中doWaitTransfer方法：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;36&quot;&gt;
&lt;pre&gt;
&lt;span&gt; 1&lt;/span&gt; &lt;span&gt;private&lt;/span&gt; &lt;span&gt;void&lt;/span&gt;&lt;span&gt; doWaitTransfer() {
&lt;/span&gt;&lt;span&gt; 2&lt;/span&gt;     &lt;span&gt;synchronized&lt;/span&gt; (&lt;span&gt;this&lt;/span&gt;&lt;span&gt;.requestsRead) {
&lt;/span&gt;&lt;span&gt; 3&lt;/span&gt;         &lt;span&gt;if&lt;/span&gt; (!&lt;span&gt;this&lt;/span&gt;&lt;span&gt;.requestsRead.isEmpty()) {
&lt;/span&gt;&lt;span&gt; 4&lt;/span&gt;             &lt;span&gt;for&lt;/span&gt; (CommitLog.GroupCommitRequest req : &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.requestsRead) {
&lt;/span&gt;&lt;span&gt; 5&lt;/span&gt;                 &lt;span&gt;boolean&lt;/span&gt; transferOK = HAService.&lt;span&gt;this&lt;/span&gt;.push2SlaveMaxOffset.get() &amp;gt;=&lt;span&gt; req.getNextOffset();
&lt;/span&gt;&lt;span&gt; 6&lt;/span&gt;                 &lt;span&gt;for&lt;/span&gt; (&lt;span&gt;int&lt;/span&gt; i = 0; !transferOK &amp;amp;&amp;amp; i &amp;lt; 5; i++&lt;span&gt;) {
&lt;/span&gt;&lt;span&gt; 7&lt;/span&gt;                     &lt;span&gt;this&lt;/span&gt;.notifyTransferObject.waitForRunning(1000&lt;span&gt;);
&lt;/span&gt;&lt;span&gt; 8&lt;/span&gt;                     transferOK = HAService.&lt;span&gt;this&lt;/span&gt;.push2SlaveMaxOffset.get() &amp;gt;=&lt;span&gt; req.getNextOffset();
&lt;/span&gt;&lt;span&gt; 9&lt;/span&gt; &lt;span&gt;                }
&lt;/span&gt;&lt;span&gt;10&lt;/span&gt; 
&lt;span&gt;11&lt;/span&gt;                 &lt;span&gt;if&lt;/span&gt; (!&lt;span&gt;transferOK) {
&lt;/span&gt;&lt;span&gt;12&lt;/span&gt;                     log.warn(&quot;transfer messsage to slave timeout, &quot; +&lt;span&gt; req.getNextOffset());
&lt;/span&gt;&lt;span&gt;13&lt;/span&gt; &lt;span&gt;                }
&lt;/span&gt;&lt;span&gt;14&lt;/span&gt; 
&lt;span&gt;15&lt;/span&gt; &lt;span&gt;                req.wakeupCustomer(transferOK);
&lt;/span&gt;&lt;span&gt;16&lt;/span&gt; &lt;span&gt;            }
&lt;/span&gt;&lt;span&gt;17&lt;/span&gt; 
&lt;span&gt;18&lt;/span&gt;             &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.requestsRead.clear();
&lt;/span&gt;&lt;span&gt;19&lt;/span&gt; &lt;span&gt;        }
&lt;/span&gt;&lt;span&gt;20&lt;/span&gt; &lt;span&gt;    }
&lt;/span&gt;&lt;span&gt;21&lt;/span&gt; }
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;和刷盘一样，这里会通过复制算法，将requestsWrite和requestsRead进行替换，那么这里的requestsRead实际上就存放着刚才添加的记录&lt;/p&gt;
&lt;p&gt;&lt;br/&gt;首先取出记录中的NextOffset和push2SlaveMaxOffset比较&lt;/p&gt;
&lt;p&gt;push2SlaveMaxOffset值是通过slave发送过来的，在之前说过的ReadSocketService线程中的：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;32&quot;&gt;
&lt;pre&gt;
&lt;span&gt;1&lt;/span&gt; HAConnection.&lt;span&gt;this&lt;/span&gt;.haService.notifyTransferSome(HAConnection.&lt;span&gt;this&lt;/span&gt;.slaveAckOffset);
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;notifyTransferSome方法：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;36&quot;&gt;
&lt;pre&gt;
&lt;span&gt; 1&lt;/span&gt; &lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; notifyTransferSome(&lt;span&gt;final&lt;/span&gt; &lt;span&gt;long&lt;/span&gt;&lt;span&gt; offset) {
&lt;/span&gt;&lt;span&gt; 2&lt;/span&gt;     &lt;span&gt;for&lt;/span&gt; (&lt;span&gt;long&lt;/span&gt; value = &lt;span&gt;this&lt;/span&gt;.push2SlaveMaxOffset.get(); offset &amp;gt;&lt;span&gt; value; ) {
&lt;/span&gt;&lt;span&gt; 3&lt;/span&gt;         &lt;span&gt;boolean&lt;/span&gt; ok = &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.push2SlaveMaxOffset.compareAndSet(value, offset);
&lt;/span&gt;&lt;span&gt; 4&lt;/span&gt;         &lt;span&gt;if&lt;/span&gt;&lt;span&gt; (ok) {
&lt;/span&gt;&lt;span&gt; 5&lt;/span&gt;             &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.groupTransferService.notifyTransferSome();
&lt;/span&gt;&lt;span&gt; 6&lt;/span&gt;             &lt;span&gt;break&lt;/span&gt;&lt;span&gt;;
&lt;/span&gt;&lt;span&gt; 7&lt;/span&gt;         } &lt;span&gt;else&lt;/span&gt;&lt;span&gt; {
&lt;/span&gt;&lt;span&gt; 8&lt;/span&gt;             value = &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.push2SlaveMaxOffset.get();
&lt;/span&gt;&lt;span&gt; 9&lt;/span&gt; &lt;span&gt;        }
&lt;/span&gt;&lt;span&gt;10&lt;/span&gt; &lt;span&gt;    }
&lt;/span&gt;&lt;span&gt;11&lt;/span&gt; }
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;即便也多个slave连接，这里的push2SlaveMaxOffset永远会记录最大的那个offset&lt;/p&gt;
&lt;p&gt;&lt;br/&gt;所以在doWaitTransfer中，根据当前NextOffset（完成写入后master本地的offset），进行判断&lt;/p&gt;
&lt;p&gt;其实这里主要要考虑到WriteSocketService线程的工作原理，只要本地文件有更新，那么就会向slave发送数据，所以这里由于HA同步是发生在刷盘后的，那么就有可能在这个doWaitTransfer执行前，有slave已经将数据进行了同步，并且向master报告了自己offset，更新了push2SlaveMaxOffset的值&lt;/p&gt;
&lt;p&gt;那么&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;32&quot;&gt;
&lt;pre&gt;
&lt;span&gt;1&lt;/span&gt; &lt;span&gt;boolean&lt;/span&gt; transferOK = HAService.&lt;span&gt;this&lt;/span&gt;.push2SlaveMaxOffset.get() &amp;gt;=&lt;span&gt; req.getNextOffset();
&lt;/span&gt;&lt;span&gt;2&lt;/span&gt; ```
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;这个判断就会为真，意味着节点中已经有了备份，所以就会直接调用&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;32&quot;&gt;
&lt;pre&gt;
&lt;span&gt;1&lt;/span&gt; req.wakeupCustomer(transferOK);
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;以此来唤醒刚才在handleHA方法中的阻塞&lt;/p&gt;
&lt;p&gt;&lt;br/&gt;若是判断为假，就说明没有一个slave完成同步，就需要&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;33&quot;&gt;
&lt;pre&gt;
&lt;span&gt;1&lt;/span&gt; &lt;span&gt;for&lt;/span&gt; (&lt;span&gt;int&lt;/span&gt; i = 0; !transferOK &amp;amp;&amp;amp; i &amp;lt; 5; i++&lt;span&gt;) {
&lt;/span&gt;&lt;span&gt;2&lt;/span&gt;     &lt;span&gt;this&lt;/span&gt;.notifyTransferObject.waitForRunning(1000&lt;span&gt;);
&lt;/span&gt;&lt;span&gt;3&lt;/span&gt;     transferOK = HAService.&lt;span&gt;this&lt;/span&gt;.push2SlaveMaxOffset.get() &amp;gt;=&lt;span&gt; req.getNextOffset();
&lt;/span&gt;&lt;span&gt;4&lt;/span&gt; }
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;通过waitForRunning进行阻塞，超时等待，最多五次等待，超过时间会向Producer发送FLUSH_SLAVE_TIMEOUT&lt;/p&gt;
&lt;p&gt;&lt;br/&gt;若是在超时时间内，有slave完成了同步，并向master发送了offset后，在notifyTransferSome方法中：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;36&quot;&gt;
&lt;pre&gt;
&lt;span&gt; 1&lt;/span&gt; &lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; notifyTransferSome(&lt;span&gt;final&lt;/span&gt; &lt;span&gt;long&lt;/span&gt;&lt;span&gt; offset) {
&lt;/span&gt;&lt;span&gt; 2&lt;/span&gt;     &lt;span&gt;for&lt;/span&gt; (&lt;span&gt;long&lt;/span&gt; value = &lt;span&gt;this&lt;/span&gt;.push2SlaveMaxOffset.get(); offset &amp;gt;&lt;span&gt; value; ) {
&lt;/span&gt;&lt;span&gt; 3&lt;/span&gt;         &lt;span&gt;boolean&lt;/span&gt; ok = &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.push2SlaveMaxOffset.compareAndSet(value, offset);
&lt;/span&gt;&lt;span&gt; 4&lt;/span&gt;         &lt;span&gt;if&lt;/span&gt;&lt;span&gt; (ok) {
&lt;/span&gt;&lt;span&gt; 5&lt;/span&gt;             &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.groupTransferService.notifyTransferSome();
&lt;/span&gt;&lt;span&gt; 6&lt;/span&gt;             &lt;span&gt;break&lt;/span&gt;&lt;span&gt;;
&lt;/span&gt;&lt;span&gt; 7&lt;/span&gt;         } &lt;span&gt;else&lt;/span&gt;&lt;span&gt; {
&lt;/span&gt;&lt;span&gt; 8&lt;/span&gt;             value = &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.push2SlaveMaxOffset.get();
&lt;/span&gt;&lt;span&gt; 9&lt;/span&gt; &lt;span&gt;        }
&lt;/span&gt;&lt;span&gt;10&lt;/span&gt; &lt;span&gt;    }
&lt;/span&gt;&lt;span&gt;11&lt;/span&gt; }
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;就会更新push2SlaveMaxOffset，并通过notifyTransferSome唤醒上面所说的阻塞&lt;/p&gt;
&lt;p&gt;然后再次判断push2SlaveMaxOffset和getNextOffset&lt;br/&gt;成功后唤醒刚才在handleHA方法中的阻塞，同步master的主从复制也就结束&lt;br/&gt;由于同步master的刷盘是在主从复制前发生的，所以&lt;strong&gt;同步双写&lt;/strong&gt;意味着master和slave都会完成消息的持久化&lt;/p&gt;

&lt;p&gt;至此，RocketMQ中Broker的HA策略分析到此结束&lt;/p&gt;
</description>
<pubDate>Wed, 07 Aug 2019 23:41:00 +0000</pubDate>
<dc:creator>松饼人</dc:creator>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/a526583280/p/11318884.html</dc:identifier>
</item>
<item>
<title>创业周年记：召唤神龙一周年小记 - 张善友</title>
<link>http://www.cnblogs.com/shanyou/p/11312461.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/shanyou/p/11312461.html</guid>
<description>&lt;p&gt;2018年8月8日，我决定离开腾讯的光环，辞职开始创业。《&lt;a href=&quot;https://www.cnblogs.com/shanyou/p/9405102.html&quot;&gt;回顾4180天在腾讯使用C#的历程，开启新的征途&lt;/a&gt;》记录了我所说的拥有七龙珠，去召唤神龙，今天正好历时一年时间，非常有必要来回顾过去一年的创业历程。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;迎接.NET Core新时代&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;这一年的所有创业活动都是围绕哲.NET Core展开，.NET Core 经历了2.2版本，下个月9.23 的.NET 社区大会上将发布3.0 ，这里以图为证，这绝对不是我PS的，请访问&lt;a href=&quot;https://www.dotnetconf.net/&quot;&gt;https://www.dotnetconf.net/&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://img2018.cnblogs.com/blog/510/201908/510-20190806230714589-250693832.png&quot;&gt;&lt;img title=&quot;image&quot; src=&quot;https://img2018.cnblogs.com/blog/510/201908/510-20190806230722145-527689966.png&quot; alt=&quot;image&quot; width=&quot;541&quot; height=&quot;393&quot; border=&quot;0&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;.NET Core这一年在中国也得到大力的发展，特别是开源社区活动，我们dotnetcore 社区（&lt;a href=&quot;https://github.com/dotnetcore&quot;&gt;https://github.com/dotnetcore&lt;/a&gt;）发展也日趋完善，汇聚了很多小伙伴在这里将.NET Core的发扬光大，当然发展也不是一帆风顺的，也有挫折，我刚开始创业的几个月时间里投入了不少时间在微软的开源项目Service Fabric之上，经过一番探索形成了相关的解决方案，但是这个方案在kubernets 这一明星的光环之下显得有点渺小，还好我当时拥有一个4万人的公众号“dotnet跨平台”，及时通过公众号对.NET Core的采用情况进行了一个调查，具体请看《&lt;a href=&quot;https://www.cnblogs.com/shanyou/p/9745509.html&quot;&gt;.NET微服务调查结果&lt;/a&gt;》，从调查结果中及时调整方向到kubernetes 平台，目前我公司的所有系统都是基于kubernetes + .NET Core构建，从我的经验中可以肯定这是一个正确的方向，而且.NET Core对容器非常友好，特别是.NET Core 3.0在docker 运行环境上有着更好的改进，.NET Core的容器化也是.NET Core有优势的地方。云原生计算的发展驱动着各个企业转向遵循云原生原则（启动速度快、内存占用低）的平台， .NET Core正是在云原生背景下发展起来的平台，.NET Core的启动速度快，内存占用很低，反而Java平台在云原生时代大大的落后了。 .NET Core在国内逐步得到应用的另一个可以佐证的是在国内各大城市.NET Core相关的社区活动也开始丰富多彩，通过社区聚会分享实践.NET Core的经验，特别是微服务方面。最近我还做了一次《&lt;a href=&quot;https://www.cnblogs.com/shanyou/p/11266491.html&quot;&gt;一份关于.NET Core云原生采用情况调查&lt;/a&gt;》，从数据上也可以反应这一趋势。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;离开大平台是真正面对自我的过程&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;其实创业没有那么苦，也没有那么酷，没有996，很佛系。它只是众多生活方式中的一种，而我选择用创业者的身份和角度去和这个社会这个时代碰撞。现在的创业生活，用一个词来形容，就是“专注”。因为不必追逐一些不属于自己的光环，不需要在大公司里向谁做不必要的证明，不需要面对KPI，每天考虑的问题是怎么朝着理想目标更近一步，如何去调动资源去解决问题。&lt;/p&gt;
&lt;p&gt;离开腾讯，也就没有了工资收入，开始靠自己的能力向自己的理想目标前进，创业的过程也是对自己过往的一个刷新，微软CEO Satya写的那本书《&lt;a href=&quot;https://item.jd.com/12260025.html&quot;&gt;刷新：重新发现商业与未来&lt;/a&gt;》，他提出自我刷新的三个关键步骤：拥抱同理心，培养“无所不学”的求知欲，以及建立成长型思维。过往的一年也是我刷新自我的一年，服务了工业、医疗、零售、教育等各个领域多家企业，借助微软开源技术 .NET Core为各行业的数字化转型，成为微软合作伙伴和腾讯云合作伙伴，腾讯云为合作伙伴提供了一个展示的一块小地方 &lt;a href=&quot;https://partners.cloud.tencent.com/&quot;&gt;https://partners.cloud.tencent.com/&lt;/a&gt;：&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://img2018.cnblogs.com/blog/510/201908/510-20190806230729262-1630827700.png&quot;&gt;&lt;img title=&quot;image&quot; src=&quot;https://img2018.cnblogs.com/blog/510/201908/510-20190806230736332-1542958039.png&quot; alt=&quot;image&quot; width=&quot;561&quot; height=&quot;213&quot; border=&quot;0&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;欢迎成为我的客户，为你服务和上云，可以扫二维码：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://www.cnblogs.com/images/cnblogs_com/shanyou/54636/o_qrcode_for_gh_258.jpg&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;创业并不是一件轻松的事情。当真正身处其中，做每个战略、用人或者是管理的决定，每时每刻都是自己内心的试炼和博弈。有时候觉得自己是对的，有时候觉得自己想的全错了。万一把公司带到坑里怎么办？什么时候该民主？什么时候独断？坚持还是放弃？中间肯定有运气的成分，但是这本身就是自我修炼的过程。在服务客户过程中以及过往多年的工作经验，过去的一年一直在探索基于.NET Core的云原生应用开发，形成了一套基于kubernetes的中台应用架构雏形，目前开始应用于公司的应用开发。这一年最大的支持来自于友浩达科技的小伙伴，大家相互鼓励，共同进步。我们一起打造了一个基于kubernetes和.NET Core技术的应用平台，让将来的业务发展具有平台火力的支持。&lt;/p&gt;
</description>
<pubDate>Wed, 07 Aug 2019 23:04:00 +0000</pubDate>
<dc:creator>张善友</dc:creator>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/shanyou/p/11312461.html</dc:identifier>
</item>
<item>
<title>MyBatis 核心配置综述之 ResultSetHandler - c旋儿</title>
<link>http://www.cnblogs.com/cxuanBlog/p/11318861.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/cxuanBlog/p/11318861.html</guid>
<description>&lt;p&gt;我们之前介绍过了MyBatis 四大核心配置之 Executor、StatementHandler、 ParameterHandler，今天本文的主题是介绍一下 MyBatis 最后一个神器也就是 ResultSetHandler。那么开始我们的讨论&lt;/p&gt;
&lt;h2 id=&quot;resultsethandler-简介&quot;&gt;ResultSetHandler 简介&lt;/h2&gt;
&lt;p&gt;回想一下，一条 SQL 的请求过程会经过哪几个步骤？ 首先会经过 Executor 执行器，它主要负责管理创建 StatementHandler 对象，然后由 StatementHandler 对象做数据库的连接以及生成 Statement 对象，并解析 SQL 参数，由 ParameterHandler 对象负责把 Mapper 方法中的参数映射到 XML 中的 SQL 语句中，那么是不是还少了一个步骤，就能完成一个完整的 SQL 请求了？没错，这最后一步就是 SQL 结果集的处理工作，也就是 &lt;code&gt;ResultSetHandler&lt;/code&gt; 的主要工作&lt;/p&gt;
&lt;p&gt;要了解 ResultSetHandler 之前，首先需要了解 ResultSetHandler的继承关系以及基本方法&lt;/p&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;public interface ResultSetHandler {

  // 处理结果集
  &amp;lt;E&amp;gt; List&amp;lt;E&amp;gt; handleResultSets(Statement stmt) throws SQLException;

  // 批量处理结果集
  &amp;lt;E&amp;gt; Cursor&amp;lt;E&amp;gt; handleCursorResultSets(Statement stmt) throws SQLException;

  // 处理存储过程的结果集
  void handleOutputParameters(CallableStatement cs) throws SQLException;

}&lt;/code&gt;
&lt;/pre&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;ResultSetHandler是一个接口，它只有一个默认的实现类，像是 ParameterHandler 一样，它的默认实现类是DefaultResultSetHandler&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;resultsethandler-创建&quot;&gt;ResultSetHandler 创建&lt;/h2&gt;
&lt;p&gt;ResultSetHandler 是在处理查询请求的时候由 Configuration 对象负责创建，示例如下&lt;/p&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;protected BaseStatementHandler(Executor executor, MappedStatement mappedStatement, Object parameterObject, RowBounds rowBounds, ResultHandler resultHandler, BoundSql boundSql) {
  this.configuration = mappedStatement.getConfiguration();
  this.executor = executor;
  this.mappedStatement = mappedStatement;
  this.rowBounds = rowBounds;

  this.typeHandlerRegistry = configuration.getTypeHandlerRegistry();
  this.objectFactory = configuration.getObjectFactory();

  if (boundSql == null) { // issue #435, get the key before calculating the statement
    generateKeys(parameterObject);
    boundSql = mappedStatement.getBoundSql(parameterObject);
  }

  this.boundSql = boundSql;

  // 创建参数处理器
  this.parameterHandler = configuration.newParameterHandler(mappedStatement, parameterObject, boundSql);
  // 创建结果映射器
  this.resultSetHandler = configuration.newResultSetHandler(executor, mappedStatement, rowBounds, parameterHandler, resultHandler, boundSql);
}

public ResultSetHandler newResultSetHandler(Executor executor, MappedStatement mappedStatement, RowBounds rowBounds, ParameterHandler parameterHandler,
      ResultHandler resultHandler, BoundSql boundSql) {
  // 由 DefaultResultSetHandler 进行初始化
  ResultSetHandler resultSetHandler = new DefaultResultSetHandler(executor, mappedStatement, parameterHandler, resultHandler, boundSql, rowBounds);
  resultSetHandler = (ResultSetHandler) interceptorChain.pluginAll(resultSetHandler);
  return resultSetHandler;
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;上述的创建过程是对 ResultSetHandler 创建过程以及初始化的简单解释，下面是对具体的查询请求进行分析&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;resultsethandler-处理结果映射&quot;&gt;ResultSetHandler 处理结果映射&lt;/h2&gt;
&lt;p&gt;回想一下，我们在进行传统crud操作的时候，哪些方法是需要返回值的？当然我们说的返回值指的是从数据库中查询出来的值，而不是标识符，应该只有查询方法吧？所以 MyBatis 只针对 query 方法做了返回值的映射，代码如下：&lt;/p&gt;
&lt;p&gt;PreparedStatementHandler.java&lt;/p&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;@Override
public &amp;lt;E&amp;gt; List&amp;lt;E&amp;gt; query(Statement statement, ResultHandler resultHandler) throws SQLException {
  PreparedStatement ps = (PreparedStatement) statement;
  ps.execute();
  // 处理结果集
  return resultSetHandler.&amp;lt;E&amp;gt; handleResultSets(ps);
}

@Override
public &amp;lt;E&amp;gt; Cursor&amp;lt;E&amp;gt; queryCursor(Statement statement) throws SQLException {
  PreparedStatement ps = (PreparedStatement) statement;
  ps.execute();
  // 批量处理结果集
  return resultSetHandler.&amp;lt;E&amp;gt; handleCursorResultSets(ps);
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;CallableStatementHandler.java 处理存储过程的SQL&lt;/p&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;@Override
public &amp;lt;E&amp;gt; List&amp;lt;E&amp;gt; query(Statement statement, ResultHandler resultHandler) throws SQLException {
  CallableStatement cs = (CallableStatement) statement;
  cs.execute();
  List&amp;lt;E&amp;gt; resultList = resultSetHandler.&amp;lt;E&amp;gt;handleResultSets(cs);
  resultSetHandler.handleOutputParameters(cs);
  return resultList;
}

@Override
public &amp;lt;E&amp;gt; Cursor&amp;lt;E&amp;gt; queryCursor(Statement statement) throws SQLException {
  CallableStatement cs = (CallableStatement) statement;
  cs.execute();
  Cursor&amp;lt;E&amp;gt; resultList = resultSetHandler.&amp;lt;E&amp;gt;handleCursorResultSets(cs);
  resultSetHandler.handleOutputParameters(cs);
  return resultList;
}&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;defaultresultsethandler-源码解析&quot;&gt;DefaultResultSetHandler 源码解析&lt;/h2&gt;
&lt;p&gt;MyBatis 只有一个默认的实现类就是 &lt;code&gt;DefaultResultSetHandler&lt;/code&gt;，ResultSetHandler 主要负责处理两件事&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;处理 Statement 执行后产生的结果集，生成结果列表&lt;/li&gt;
&lt;li&gt;处理存储过程执行后的输出参数&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;按照 Mapper 文件中配置的 ResultType 或 ResultMap 来封装成对应的对象，最后将封装的对象返回即可。&lt;/p&gt;
&lt;p&gt;来看一下主要的源码：&lt;/p&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;@Override
public List&amp;lt;Object&amp;gt; handleResultSets(Statement stmt) throws SQLException {
  ErrorContext.instance().activity(&quot;handling results&quot;).object(mappedStatement.getId());

  final List&amp;lt;Object&amp;gt; multipleResults = new ArrayList&amp;lt;Object&amp;gt;();

  int resultSetCount = 0;
  // 获取第一个结果集
  ResultSetWrapper rsw = getFirstResultSet(stmt);
  // 获取结果映射
  List&amp;lt;ResultMap&amp;gt; resultMaps = mappedStatement.getResultMaps();
  // 结果映射的大小
  int resultMapCount = resultMaps.size();
  // 校验结果映射的数量
  validateResultMapsCount(rsw, resultMapCount);
  // 如果ResultSet 包装器不是null， 并且 resultmap 的数量  &amp;gt;  resultSet 的数量的话
  // 因为 resultSetCount 第一次肯定是0，所以直接判断 ResultSetWrapper 是否为 0 即可
  while (rsw != null &amp;amp;&amp;amp; resultMapCount &amp;gt; resultSetCount) {
    // 从 resultMap 中取出 resultSet 数量
    ResultMap resultMap = resultMaps.get(resultSetCount);
    // 处理结果集, 关闭结果集
    handleResultSet(rsw, resultMap, multipleResults, null);
    rsw = getNextResultSet(stmt);
    cleanUpAfterHandlingResultSet();
    resultSetCount++;
  }

  // 从 mappedStatement 取出结果集
  String[] resultSets = mappedStatement.getResultSets();
  if (resultSets != null) {
    while (rsw != null &amp;amp;&amp;amp; resultSetCount &amp;lt; resultSets.length) {
      ResultMapping parentMapping = nextResultMaps.get(resultSets[resultSetCount]);
      if (parentMapping != null) {
        String nestedResultMapId = parentMapping.getNestedResultMapId();
        ResultMap resultMap = configuration.getResultMap(nestedResultMapId);
        handleResultSet(rsw, resultMap, null, parentMapping);
      }
      rsw = getNextResultSet(stmt);
      cleanUpAfterHandlingResultSet();
      resultSetCount++;
    }
  }

  return collapseSingleResultList(multipleResults);
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;其中涉及的主要对象有：&lt;/p&gt;
&lt;p&gt;&lt;code&gt;ResultSetWrapper&lt;/code&gt; : 结果集的包装器，主要针对结果集进行的一层包装，它的主要属性有&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;ResultSet : Java JDBC ResultSet接口表示数据库查询的结果。 有关查询的文本显示了如何将查询结果作为java.sql.ResultSet返回。 然后迭代此ResultSet以检查结果。&lt;/li&gt;
&lt;li&gt;TypeHandlerRegistry: 类型注册器，TypeHandlerRegistry 在初始化的时候会把所有的 Java类型和类型转换器进行注册。&lt;/li&gt;
&lt;li&gt;ColumnNames: 字段的名称，也就是查询操作需要返回的字段名称&lt;/li&gt;
&lt;li&gt;ClassNames: 字段的类型名称，也就是 ColumnNames 每个字段名称的类型&lt;/li&gt;
&lt;li&gt;JdbcTypes: JDBC 的类型，也就是java.sql.Types 类型&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;code&gt;ResultMap&lt;/code&gt;: 负责处理更复杂的映射关系&lt;/p&gt;
&lt;p&gt;&lt;code&gt;multipleResults&lt;/code&gt;:&lt;/p&gt;
&lt;p&gt;其中的主要方法是 handleResultSet&lt;/p&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;private void handleResultSet(ResultSetWrapper rsw, ResultMap resultMap, List&amp;lt;Object&amp;gt; multipleResults, ResultMapping parentMapping) throws SQLException {
  try {
    if (parentMapping != null) {
      // 处理多行结果的值
      handleRowValues(rsw, resultMap, null, RowBounds.DEFAULT, parentMapping);
    } else {
      if (resultHandler == null) {
        DefaultResultHandler defaultResultHandler = new DefaultResultHandler(objectFactory);
        handleRowValues(rsw, resultMap, defaultResultHandler, rowBounds, null);
        multipleResults.add(defaultResultHandler.getResultList());
      } else {
        handleRowValues(rsw, resultMap, resultHandler, rowBounds, null);
      }
    }
  } finally {
    // issue #228 (close resultsets)
    closeResultSet(rsw.getResultSet());
  }
}

// 如果有嵌套的ResultMap 的话
  // 确保没有行绑定
  // 检查结果处理器
  // 如果没有的话，直接处理简单的ResultMap
  public void handleRowValues(ResultSetWrapper rsw, ResultMap resultMap, ResultHandler&amp;lt;?&amp;gt; resultHandler, RowBounds rowBounds, ResultMapping parentMapping) throws SQLException {
    if (resultMap.hasNestedResultMaps()) {
      ensureNoRowBounds();
      checkResultHandler();
      handleRowValuesForNestedResultMap(rsw, resultMap, resultHandler, rowBounds, parentMapping);
    } else {
      handleRowValuesForSimpleResultMap(rsw, resultMap, resultHandler, rowBounds, parentMapping);
    }
  }&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;handleResultSets 方法返回的是 collapseSingleResultList(multipleResults) ，它是什么呢？&lt;/p&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;private List&amp;lt;Object&amp;gt; collapseSingleResultList(List&amp;lt;Object&amp;gt; multipleResults) {
  return multipleResults.size() == 1 ? (List&amp;lt;Object&amp;gt;) multipleResults.get(0) : multipleResults;
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;它是判断的 multipleResults 的数量，如果数量是 1 ，就直接取位置为0的元素，如果不是1，那就返回 multipleResults 的真实数量&lt;/p&gt;
&lt;p&gt;那么 multipleResults 的数量是哪来的呢？&lt;/p&gt;
&lt;p&gt;它的值其实是处理结果集中传递进去的&lt;/p&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;handleResultSet(rsw, resultMap, multipleResults, null);&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;然后在处理结果集的方法中对 multipleResults 进行添加&lt;/p&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;multipleResults.add(defaultResultHandler.getResultList());&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;下面我们来看一下返回的真实实现类 DefaultResultSetHandler 中的结构组成&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1515111/201908/1515111-20190808064024845-640445981.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;在 DefaultResultSetHandler 中处理完结果映射，并把上述结构返回给调用的客户端，从而执行完成一条完整的SQL语句。&lt;/p&gt;
&lt;p&gt;我的公众号二维码：欢迎关注&lt;br/&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1515111/201908/1515111-20190808064211678-785830192.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;文章参考：&lt;/p&gt;
&lt;p&gt;https://blog.csdn.net/qq924862077/article/details/52704191&lt;/p&gt;
</description>
<pubDate>Wed, 07 Aug 2019 22:42:00 +0000</pubDate>
<dc:creator>c旋儿</dc:creator>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/cxuanBlog/p/11318861.html</dc:identifier>
</item>
</channel>
</rss>