<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="css/feed.xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/" xmlns:og="http://ogp.me/ns#">
<channel>
<atom:link rel="self" href="http://192.168.1.4/fivefilters/makefulltextfeed.php?url=feed.cnblogs.com%2Fblog%2Fsitehome%2Frss&amp;max=10&amp;links=preserve&amp;exc=" />
<atom:link rel="alternate" title="Source URL" href="http://feed.cnblogs.com/blog/sitehome/rss" />
<atom:link rel="related" title="Subscribe to feed" href="http://www.subtome.com/#/subscribe?feeds=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed.cnblogs.com%252Fblog%252Fsitehome%252Frss%26max%3D10%26links%3Dpreserve%26exc%3D&amp;back=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed.cnblogs.com%252Fblog%252Fsitehome%252Frss%26max%3D10%26links%3Dpreserve%26exc%3D" />
<title>博客园_首页</title>
<link></link>
<description>代码改变世界</description>
<item>
<title>Spark Streaming，Flink，Storm，Kafka Streams，Samza：如何选择流处理框架 - 独孤风</title>
<link>http://www.cnblogs.com/tree1123/p/13082643.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/tree1123/p/13082643.html</guid>
<description>&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1089984/202006/1089984-20200610080225004-690722209.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;根据最新的统计显示，仅在过去的两年中，当今世界上90％的数据都是在新产生的，每天创建2.5万亿字节的数据，并且随着新设备，传感器和技术的出现，数据增长速度可能会进一步加快。&lt;br/&gt;从技术上讲，这意味着我们的大数据处理将变得更加复杂且更具挑战性。而且，许多用例（例如，移动应用广告，欺诈检测，出租车预订，病人监护等）都需要在数据到达时进行实时数据处理，以便做出快速可行的决策。这就是为什么分布式流处理在大数据世界中变得非常流行的原因。&lt;/p&gt;
&lt;p&gt;如今，有许多可用的开源流框架。有趣的是，几乎所有它们都是相当新的，仅在最近几年才开发出来。因此，对于新手来说，很容易混淆流框架之间的理解和区分。在本文中，我将首先大致讨论流处理的类型和方面，然后比较最受欢迎的开源流框架：Flink，SparkStreaming，Storm，KafkaStream。我将尝试（简要地）解释它们的工作原理，它们的用例，优势，局限性，异同。&lt;/p&gt;
&lt;h2 id=&quot;什么是流流处理：&quot;&gt;&lt;strong&gt;什么是流/流处理：&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;流处理的最优雅的定义是：一种数据处理引擎，其设计时考虑了无限的数据集。&lt;/p&gt;
&lt;p&gt;与批处理不同，批处理以工作中的开始和结束为界，而工作是在处理有限数据之后完成的，而流处理则是指连续不断地处理天，月，年和永久到来的无边界数据。因此，流媒体应用程序始终需要启动和运行，因此难以实现且难以维护。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;流处理的重要方面：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;为了理解任何Streaming框架的优点和局限性，我们应该了解与Stream处理相关的一些重要特征和术语：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;em&gt;交付保证&lt;/em&gt;：&lt;br/&gt;这意味着无论如何，流引擎中的特定传入记录都将得到处理的保证。可以是&lt;strong&gt;at least once（至少一次）&lt;/strong&gt;（即使发生故障也至少处理一次），at &lt;strong&gt;most once : 至&lt;em&gt;多一次&lt;/em&gt;&lt;/strong&gt;（如果发生故障则可能不处理）或&lt;strong&gt;Exactly-once&lt;/strong&gt;（即使失败在这种情况下也只能处理一次））。显然，只处理一次是最好的，但是很难在分布式系统中实现，并且需要权衡性能。&lt;/li&gt;
&lt;li&gt;&lt;em&gt;容错：&lt;/em&gt;&lt;br/&gt;如果发生诸如节点故障，网络故障等故障，框架应该能够恢复，并且应该从其离开的位置开始重新处理。这是通过不时检查流向某些持久性存储的状态来实现的。例如，从Kafka获取记录并对其进行处理后，将Kafka检查点偏移给Zookeeper。&lt;/li&gt;
&lt;li&gt;&lt;em&gt;状态管理：&lt;/em&gt;在有状态处理需求的情况下，我们需要保持某种状态（例如，记录中每个不重复单词的计数），框架应该能够提供某种机制来保存和更新状态信息。&lt;/li&gt;
&lt;li&gt;&lt;em&gt;性能&lt;/em&gt;：&lt;br/&gt;这包括延迟（可以多久处理一条记录），吞吐量（每秒处理的记录数）和可伸缩性。延迟应尽可能小，而吞吐量应尽可能大。很难同时获得两者。&lt;/li&gt;
&lt;li&gt;&lt;em&gt;高级功能：事件时间处理，水印，窗口化&lt;/em&gt;&lt;br/&gt;如果流处理要求很复杂&lt;em&gt;，&lt;/em&gt;这些是必需的功能。例如，根据在源中生成记录的时间来处理记录（事件时间处理）。&lt;/li&gt;
&lt;li&gt;&lt;em&gt;成熟度：&lt;/em&gt;从采用的角度来看很重要，如果框架已经过大公司的验证和大规模测试，那就太好了。更有可能获得良好的社区支持并在堆栈溢出方面提供帮助。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;流处理的两种类型：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;现在了解了我们刚刚讨论的术语，现在很容易理解，有两种方法可以实现Streaming框架：&lt;/p&gt;
&lt;p&gt;&lt;em&gt;原生流处理&lt;/em&gt;：&lt;br/&gt;这意味着每条到达的记录都会在到达后立即处理，而无需等待其他记录。有一些连续运行的过程（根据框架，我们称之为操作员/任务/螺栓），这些过程将永远运行，每条记录都将通过这些过程进行处理。示例：Storm，Flink，Kafka Streams，Samza。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1089984/202006/1089984-20200610080319504-1718003550.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;微批处理&lt;/em&gt;：&lt;br/&gt;也称为快速批处理。这意味着每隔几秒钟就会将传入的记录分批处理，然后以单个小批处理的方式处理，延迟几秒钟。例如：Spark Streaming, Storm-Trident。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1089984/202006/1089984-20200610080325506-631418045.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;两种方法都有其优点和缺点。&lt;br/&gt;原生流传输感觉很自然，因为每条记录都会在到达记录后立即进行处理，从而使框架能够实现最小的延迟。但这也意味着在不影响吞吐量的情况下很难实现容错，因为对于每条记录，我们都需要在处理后跟踪和检查点。而且，状态管理很容易，因为有长时间运行的进程可以轻松维护所需的状态。&lt;/p&gt;
&lt;p&gt;另一方面，微批处理则完全相反。容错是免费提供的，因为它本质上是一个批处理，吞吐量也很高，因为处理和检查点将在一组记录中一次性完成。但这会花费一定的等待时间，并且感觉不自然。高效的状态管理也将是维持的挑战。&lt;/p&gt;
&lt;h2 id=&quot;流框架对比：&quot;&gt;&lt;strong&gt;流框架对比：&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Storm :&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Storm是流处理世界的强者。它是最古老的开源流框架，也是最成熟和可靠的框架之一。这是真正的流传输，适合基于简单事件的用例。&lt;/p&gt;
&lt;p&gt;&lt;em&gt;优点&lt;/em&gt;：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;极低的延迟，真正的流，成熟和高吞吐量&lt;/li&gt;
&lt;li&gt;非常适合简单的流媒体用例&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;em&gt;缺点&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;没有状态管理&lt;/li&gt;
&lt;li&gt;没有高级功能，例如事件时间处理，聚合，开窗，会话，水印等&lt;/li&gt;
&lt;li&gt;一次保证&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;Spark Streaming :&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Spark已成为批处理中hadoop的真正继任者，并且是第一个完全支持Lambda架构的框架（在该框架中，实现了批处理和流传输；实现了正确性的批处理；实现了流传输的速度）。它非常受欢迎，成熟并被广泛采用。Spark Streaming是随Spark免费提供的，它使用微批处理进行流媒体处理。在2.0版本之前，Spark Streaming有一些严重的性能限制，但是在新版本2.0+中，它被称为结构化流，并具有许多良好的功能，例如自定义内存管理（类似flink），水印，事件时间处理支持等。另外，结构化流媒体更加抽象，在2.3.0版本以后，可以选择在微批量和连续流媒体模式之间进行切换。连续流模式有望带来像Storm和Flink这样的子延迟，但是它仍处于起步阶段，操作上有很多限制。&lt;/p&gt;
&lt;p&gt;&lt;em&gt;优点&lt;/em&gt;：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;支持Lambda架构，Spark免费提供&lt;/li&gt;
&lt;li&gt;高吞吐量，适用于不需要亚延迟的许多使用情况&lt;/li&gt;
&lt;li&gt;由于微批量性质，默认情况下具有容错能力&lt;/li&gt;
&lt;li&gt;简单易用的高级API&lt;/li&gt;
&lt;li&gt;庞大的社区和积极的改进&lt;/li&gt;
&lt;li&gt;恰好一次&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;em&gt;缺点&lt;/em&gt;&lt;/p&gt;
&lt;ul readability=&quot;0&quot;&gt;&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;不是真正的流，不适合低延迟要求&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;要调整的参数太多。很难做到正确。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;天生无国籍&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;在许多高级功能方面落后于Flink&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;Flink&lt;/strong&gt; :&lt;/p&gt;
&lt;p&gt;Flink也来自类似Spark这样的学术背景。Spark来自加州大学伯克利分校，而Flink来自柏林工业大学。像Spark一样，它也支持Lambda架构。但是实现与Spark完全相反。虽然Spark本质上是一个批处理，其中Spark流是微批处理，并且是Spark Batch的特例，但Flink本质上是一个真正的流引擎，将批处理视为带边界数据流的特例。尽管这两个框架中的API都是相似的，但是它们在实现上没有任何相似性。在Flink中，诸如map，filter，reduce等的每个函数都实现为长时间运行的运算符（类似于Storm中的Bolt）&lt;/p&gt;
&lt;p&gt;Flink看起来像是Storm的真正继承者，就像Spark批量继承了hadoop一样。&lt;/p&gt;
&lt;p&gt;&lt;em&gt;优点&lt;/em&gt;：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;开源流媒体领域创新的领导者&lt;/li&gt;
&lt;li&gt;具有所有高级功能（例如事件时间处理，水印等）的第一个True流框架&lt;/li&gt;
&lt;li&gt;低延迟，高吞吐量，可根据要求进行配置&lt;/li&gt;
&lt;li&gt;自动调整，无需调整太多参数&lt;/li&gt;
&lt;li&gt;恰好一次&lt;/li&gt;
&lt;li&gt;被Uber，阿里巴巴等大型公司广泛接受。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;em&gt;缺点&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Kafka Streams :&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;与其他流框架不同，Kafka Streams是一个轻量级的库。对于从Kafka流式传输数据，进行转换然后发送回kafka很有用。我们可以将其理解为类似于Java Executor服务线程池的库，但具有对Kafka的内置支持。它可以与任何应用程序很好地集成，并且可以立即使用。&lt;/p&gt;
&lt;p&gt;由于其重量轻的特性，可用于微服务类型的体系结构。Flink在性能方面没有匹配之处，而且不需要运行单独的集群，非常方便并且易于部署和开始工作。&lt;/p&gt;
&lt;p&gt;Kafka Streams的一个主要优点是它的处理是完全精确的端到端。可能是因为来源和目的地均为Kafka以及从2017年6月左右发布的Kafka 0.11版本开始，仅支持一次。要启用此功能，我们只需要启用一个标志即可使用。&lt;/p&gt;
&lt;p&gt;&lt;em&gt;优点&lt;/em&gt;：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;重量很轻的库，适合微服务，IOT应用&lt;/li&gt;
&lt;li&gt;不需要专用集群&lt;/li&gt;
&lt;li&gt;继承卡夫卡的所有优良特性&lt;/li&gt;
&lt;li&gt;支持流连接，内部使用rocksDb维护状态。&lt;/li&gt;
&lt;li&gt;恰好一次（从Kafka 0.11开始）。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;em&gt;缺点&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;与卡夫卡紧密结合，在没有卡夫卡的情况下无法使用&lt;/li&gt;
&lt;li&gt;婴儿期还很新，尚待大公司测试&lt;/li&gt;
&lt;li&gt;不适用于繁重的工作，例如Spark Streaming，Flink。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;Samza :&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;简短介绍一下Samza。（Samza）看上去就像是（Kafka Streams）。有很多相似之处。这两个框架都是由同一位开发人员开发的，这些开发人员在LinkedIn上实现了Samza，然后在他们创建Kafka Streams的地方成立了Confluent。这两种技术都与Kafka紧密结合，从Kafka获取原始数据，然后将处理后的数据放回Kafka。使用相同的Kafka Log哲学。Samza是Kafka Streams的缩放版本。Kafka Streams是一个用于微服务的库，而Samza是在Yarn上运行的完整框架集群处理。&lt;br/&gt;优点 ：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;使用rocksDb和kafka日志可以很好地维护大量信息状态（适合于连接流的用例）。&lt;/li&gt;
&lt;li&gt;使用Kafka属性的容错和高性能&lt;/li&gt;
&lt;li&gt;如果已在处理管道中使用Yarn和Kafka，则要考虑的选项之一。&lt;/li&gt;
&lt;li&gt;低延迟，高吞吐量，成熟并经过大规模测试&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;缺点：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;与Kafka和Yarn紧密结合。如果这些都不在您的处理管道中，则不容易使用。&lt;/li&gt;
&lt;li&gt;至少一次加工保证。我不确定它是否像Kafka 0.11之后的Kafka Streams现在完全支持一次&lt;/li&gt;
&lt;li&gt;缺少高级流功能，例如水印，会话，触发器等&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;流框架比较：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;我们只能将技术与类似产品进行比较。尽管Storm，Kafka Streams和Samza现在对于更简单的用例很有用，但具有最新功能的重量级产品之间的真正竞争显而易见：Spark vs Flink&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1089984/202006/1089984-20200610080338728-1223981002.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;当我们谈论比较时，我们通常会问：&lt;em&gt;给我看数字&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;基准测试是仅当第三方进行比较时比较的好方法。&lt;/p&gt;
&lt;p&gt;例如，但这是在Spark Streaming 2.0之前的某个时期，当时它受RDD的限制。&lt;br/&gt;现在，随着Structured Streaming 2.0版本的发布，Spark Streaming试图赶上很多潮流，而且似乎还会面临艰巨的挑战。&lt;/p&gt;
&lt;p&gt;最近，基准测试已成为Spark和Flink之间的一场激烈争吵。&lt;/p&gt;
&lt;p&gt;最好不要相信这些天的基准测试，因为即使很小的调整也可以完全改变数字。没有什么比决定之前尝试和测试自己更好。&lt;br/&gt;到目前为止，很明显，Flink在流分析领域处于领先地位，它具有大多数所需的方面，例如精确一次，吞吐量，延迟，状态管理，容错，高级功能等。&lt;/p&gt;
&lt;p&gt;Flink的一个重要问题是成熟度和采用水平，直到一段时间之前，但是现在像Uber，Alibaba，CapitalOne这样的公司正在大规模使用Flink流传输，证明了Flink Streaming的潜力。&lt;/p&gt;
&lt;p&gt;最近，Uber开源了其最新的流分析框架AthenaX，该框架基于Flink引擎构建。&lt;/p&gt;
&lt;p&gt;如果您已经注意到，需要注意的重要一点是，所有支持状态管理的原生流框架（例如Flink，Kafka Streams，Samza）在内部都使用RocksDb。RocksDb从某种意义上说是独一无二的，它在每个节点上本地保持持久状态，并且性能很高。它已成为新流系统的关键部分。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;如何选择最佳的流媒体框架：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;这是最重要的部分。诚实的答案是：&lt;strong&gt;这取决于&lt;/strong&gt; :&lt;/p&gt;
&lt;p&gt;必须牢记，对于每个用例，没有一个单一的处理框架可以成为万灵丹。每个框架都有其优点和局限性。尽管如此，根据一些经验，他们仍然会分享一些有助于做出决定的建议：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;取决于用例：&lt;br/&gt;如果用例很简单，那么如果学习和实现起来很复杂，则无需寻求最新，最好的框架。在很大程度上取决于我们愿意投资多少来换取我们想要的回报。例如，如果它是基于事件的简单IOT事件警报系统，那么Storm或Kafka Streams非常适合使用。&lt;/li&gt;
&lt;li&gt;未来考虑因素：&lt;br/&gt;同时，我们还需要对未来可能的用例进行自觉考虑。将来可能会出现对诸如事件时间处理，聚合，流加入等高级功能的需求吗？如果答案是肯定的，则最好继续使用高级流框架（例如Spark Streaming或Flink）。一旦对一项技术进行了投资和实施，其变更的困难和巨大成本将在以后改变。例如，在之前的公司中，从过去的两年开始，Storm管道就已经启动并运行，并且在要求统一输入事件并仅报告唯一事件之前，它一直运行良好。现在，这需要状态管理，而Storm本身并不支持这种状态管理。虽然我使用基于时间的内存哈希表实现，但是在重启时状态会消失是有限制的。&lt;/li&gt;
&lt;li&gt;我要提出的观点是，如果我们尝试自行实现框架未明确提供的某些内容，则势必会遇到未知问题。&lt;/li&gt;
&lt;li&gt;现有技术堆栈：&lt;br/&gt;另一重要点是考虑现有技术堆栈。如果现有堆栈的首尾相连是Kafka，则Kafka Streams或Samza可能更容易安装。同样，如果处理管道基于Lambda架构，并且Spark Ba​​tch或Flink Batch已经到位，则考虑使用Spark Streaming或Flink Streaming是有意义的。例如，在我以前的项目中，我已经在管道中添加了Spark Ba​​tch，因此，当流需求到来时，选择需要几乎相同的技能和代码库的Spark Streaming非常容易。&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;简而言之，如果我们很好地了解框架的优点和局限性以及用例，那么选择或至少过滤掉可用的选项就更加容易。最后，一旦选择了几个选项。毕竟每个人都有不同的选择。&lt;/p&gt;
&lt;p&gt;Streaming的发展速度如此之快，以至于在信息方面，此帖子可能在几年后已经过时。目前，Spark和Flink在开发方面是领先的重量级人物，但仍有一些新手可以加入比赛。Apache Apex是其中之一。还有一些我没有介绍的专有流解决方案，例如Google Dataflow。我的这篇文章的目的是帮助刚接触流技术的人以最少的术语理解流技术的一些核心概念，以及流行的开源流框架的优点，局限性和用例。希望该文章对您有所帮助。&lt;/p&gt;
&lt;p&gt;更多实时数据分析相关博文与科技资讯，欢迎关注 “实时流式计算”&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1089984/202005/1089984-20200511083216576-1437389309.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
</description>
<pubDate>Wed, 10 Jun 2020 00:08:00 +0000</pubDate>
<dc:creator>独孤风</dc:creator>
<og:description>根据最新的统计显示，仅在过去的两年中，当今世界上90％的数据都是在新产生的，每天创建2.5万亿字节的数据，并且随着新设备，传感器和技术的出现，数据增长速度可能会进一步加快。 从技术上讲，这意味着我们的</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/tree1123/p/13082643.html</dc:identifier>
</item>
<item>
<title>动手造轮子：实现一个简单的依赖注入(三) --- 支持属性注入 - WeihanLi</title>
<link>http://www.cnblogs.com/weihanli/p/implement-dependency-injection-03.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/weihanli/p/implement-dependency-injection-03.html</guid>
<description>&lt;h2 id=&quot;intro&quot;&gt;Intro&lt;/h2&gt;
&lt;p&gt;前面写了几篇依赖注入的文章，有兴趣的小伙伴可以参考文末 &lt;code&gt;Reference&lt;/code&gt; 部分中的链接，一直有小伙伴希望增加属性注入的支持，昨天试着加了一下，思路很简单，在获取到服务实例之后检查实例中有没有需要注入的属性，如果有并且不为 &lt;code&gt;null&lt;/code&gt; 就从服务容器中获取一个对应属性类型的实例&lt;/p&gt;
&lt;h2 id=&quot;代码修改&quot;&gt;代码修改&lt;/h2&gt;
&lt;h3 id=&quot;fromserviceattribute&quot;&gt;FromServiceAttribute&lt;/h3&gt;
&lt;blockquote readability=&quot;2.0434782608696&quot;&gt;
&lt;p&gt;完整的代码修改可以参考这个 commit &lt;a href=&quot;https://github.com/WeihanLi/WeihanLi.Common/commit/91dc0b515d12e7c036771fba9419824cd0219544&quot;&gt;https://github.com/WeihanLi/WeihanLi.Common/commit/91dc0b515d12e7c036771fba9419824cd0219544&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;首先我们需要增加一个 &lt;code&gt;FromServiceAttribute&lt;/code&gt; 用来标识哪些属性需要注入，代码如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-csharp&quot;&gt;[AttributeUsage(AttributeTargets.Property | AttributeTargets.Field | AttributeTargets.Parameter, AllowMultiple = false, Inherited = false)]
public sealed class FromServiceAttribute : Attribute
{
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;这里 &lt;code&gt;AttributeTargets&lt;/code&gt; 除了属性之外增加了字段和参数，是想可能以后会用到，参数典型的应用场景就是类似于 asp.net core 里的 &lt;code&gt;[FromServices]&lt;/code&gt; 用来实现方法注入参数&lt;/p&gt;
&lt;h3 id=&quot;enrichobject&quot;&gt;EnrichObject&lt;/h3&gt;
&lt;p&gt;增加了一个 &lt;code&gt;EnrichObject&lt;/code&gt; 方法，用来在获取到服务实例之后，对服务实例做一些补充的配置，如我们要加的属性注入，如果我们要加字段注入等也可以在这个方法内完成，来看实现：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-csharp&quot;&gt;private object EnrichObject(object obj)
{
    if (null != obj)
    {
        // PropertyInjection
        var type = obj.GetType();
        foreach (var property in CacheUtil.TypePropertyCache.GetOrAdd(type, t =&amp;gt; t.GetProperties())
            .Where(x =&amp;gt; x.IsDefined(typeof(FromServiceAttribute))))
        {
            if (property.GetValueGetter()?.Invoke(obj) == null)
            {
                property.GetValueSetter()?.Invoke(
                    obj,
                    GetService(property.PropertyType)
                    );
            }
        }
    }

    return obj;
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;上面的逻辑就是获取这个 object 定义的所有需要注入的属性，如果属性的值不为 null 则，从服务容器中获取对应的服务实例，之所以要检查是不是null&lt;/p&gt;
&lt;p&gt;上面的 &lt;code&gt;CacheUtil.TypePropertyCache&lt;/code&gt; 是一个 Type 为 key，PropertyInfo 数组为 Value 的并发字典，用来缓存类型的属性&lt;/p&gt;
&lt;p&gt;GetValueGetter/GetValueSetter 是 PropertyInfo 的扩展方法，利用表达式树和缓存提高属性 Get/Set 的效率&lt;/p&gt;
&lt;h2 id=&quot;getsertviceinstance&quot;&gt;GetSertviceInstance&lt;/h2&gt;
&lt;p&gt;修改原来的 GetServiceInstance 方法为 GetServiceInstanceInternal，增加一个一样的方法，实现逻辑是在 GetServiceInstanceInternal 的基础上调用上面的 Enrich 方法来实现属性注入&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/489462/202006/489462-20200610080022383-972905473.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h2 id=&quot;more&quot;&gt;More&lt;/h2&gt;
&lt;p&gt;虽然增加了属性注入的支持，但是还是不太推荐使用，从上面属性注入的代码中可以看得到，如果用不好很容易出现循环依赖的问题，而且用构造器注入的话依赖关系很清晰，分析方法的构造方法即可，如果要使用属性注入请谨慎使用&lt;/p&gt;
&lt;h2 id=&quot;reference&quot;&gt;Reference&lt;/h2&gt;
</description>
<pubDate>Wed, 10 Jun 2020 00:06:00 +0000</pubDate>
<dc:creator>WeihanLi</dc:creator>
<og:description>给依赖注入增加属性注入支持</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/weihanli/p/implement-dependency-injection-03.html</dc:identifier>
</item>
<item>
<title>掌握SpringBoot-2.3的容器探针：深入篇 - zq2599</title>
<link>http://www.cnblogs.com/bolingcavalry/p/13082594.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/bolingcavalry/p/13082594.html</guid>
<description>&lt;h3 id=&quot;欢迎访问我的github&quot;&gt;欢迎访问我的GitHub&lt;/h3&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/zq2599/blog_demos&quot;&gt;https://github.com/zq2599/blog_demos&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;内容：原创分类汇总及配套源码，涉及Java、Docker、K8S、DevOPS等&lt;/li&gt;
&lt;/ul&gt;&lt;h3 id=&quot;关于《springboot-23容器化技术》系列&quot;&gt;关于《SpringBoot-2.3容器化技术》系列&lt;/h3&gt;
&lt;ul&gt;&lt;li&gt;《SpringBoot-2.3容器化技术》系列，旨在和大家一起学习实践2.3版本带来的最新容器化技术，让咱们的Java应用更加适应容器化环境，在云计算时代依旧紧跟主流，保持竞争力；&lt;/li&gt;
&lt;li&gt;全系列文章分为主题和辅助两部分，主题部分如下：&lt;/li&gt;
&lt;/ul&gt;&lt;ol&gt;&lt;li&gt;&lt;a href=&quot;https://blog.csdn.net/boling_cavalry/article/details/106597358&quot;&gt;《体验SpringBoot(2.3)应用制作Docker镜像(官方方案)》&lt;/a&gt;；&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://blog.csdn.net/boling_cavalry/article/details/106598189&quot;&gt;《详解SpringBoot(2.3)应用制作Docker镜像(官方方案)》&lt;/a&gt;；&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://blog.csdn.net/boling_cavalry/article/details/106605264&quot;&gt;《掌握SpringBoot-2.3的容器探针：基础篇》&lt;/a&gt;；&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://blog.csdn.net/boling_cavalry/article/details/106606442&quot;&gt;《掌握SpringBoot-2.3的容器探针：深入篇》&lt;/a&gt;；&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://blog.csdn.net/boling_cavalry/article/details/106607225&quot;&gt;《掌握SpringBoot-2.3的容器探针：实战篇》&lt;/a&gt;；&lt;/li&gt;
&lt;/ol&gt;&lt;ul&gt;&lt;li&gt;辅助部分是一些参考资料和备忘总结，如下：&lt;/li&gt;
&lt;/ul&gt;&lt;ol&gt;&lt;li&gt;&lt;a href=&quot;https://blog.csdn.net/boling_cavalry/article/details/106600620&quot;&gt;《SpringBoot-2.3镜像方案为什么要做多个layer》&lt;/a&gt;；&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://blog.csdn.net/boling_cavalry/article/details/106590784&quot;&gt;《设置非root账号不用sudo直接执行docker命令》&lt;/a&gt;；&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://blog.csdn.net/boling_cavalry/article/details/106594392&quot;&gt;《开发阶段，将SpringBoot应用快速部署到K8S》&lt;/a&gt;；&lt;/li&gt;
&lt;/ol&gt;&lt;h3 id=&quot;前文回顾&quot;&gt;前文回顾&lt;/h3&gt;
&lt;ol&gt;&lt;li&gt;本文是《掌握SpringBoot-2.3的容器探针》系列的第二篇，前文 &lt;a href=&quot;https://blog.csdn.net/boling_cavalry/article/details/106605264&quot;&gt;《掌握SpringBoot-2.3的容器探针：基础篇》&lt;/a&gt;知道了kubernetes的存活和就绪探针，以及SpringBoot-2.3的actuator新增的两个endpoint，当我们把应用部署到kubernetes环境时，这些知识让我们能配置出官方推荐的探针方案，如下图：&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/485422/202006/485422-20200610074506693-1682499065.png&quot; alt=&quot;在这里插入图片描述&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;ol start=&quot;2&quot;&gt;&lt;li&gt;尽管上述配置已经可以覆盖多数场景，依然有三个问题未解决：&lt;/li&gt;
&lt;/ol&gt;&lt;ul readability=&quot;3.5&quot;&gt;&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;首先，SpringBoot为kubernetes提供了两个actuator项，但是那些并未部署在kubernetes的SringBoot应用呢？用不上这两项也要对外暴露这两个服务地址吗？&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;2&quot;&gt;
&lt;p&gt;其次，就绪探针是什么时候开始返回200返回码的？应用启动阶段，业务服务可能需要一段时间才能正常工作，就绪探针要是提前返回了200，那k8s就认为容器可以正常工作了，这时候把外部请求调度过来是无法正常响应的，所以搞清楚就绪探针的状态变化逻辑很重要；&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;2&quot;&gt;
&lt;p&gt;最后，也是最重要的一点：有的场景下，例如外部依赖服务异常、本地全局异常等情况下，业务不想对外提供服务，等到问题解决后业务又可以对外提供服务了，如果此时我们能自己写代码控制就绪探针的返回码，那就做到了控制kubernetes是否将外部请求调度到此容器上，这可是个很实用的功能！&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;本篇就是为了解决上述问题而作，这些问题解决后才能用好探针技术，让它在容器环境带来更大价值；&lt;/p&gt;
&lt;h3 id=&quot;关键知识点&quot;&gt;关键知识点&lt;/h3&gt;
&lt;p&gt;解决上述问题的关键集中在以下几个知识点：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;SpringBoot对容器环境的判断；&lt;/li&gt;
&lt;li&gt;SpringBoot对状态定义；&lt;/li&gt;
&lt;li&gt;获取状态；&lt;/li&gt;
&lt;li&gt;监听状态；&lt;/li&gt;
&lt;li&gt;修改状态；&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;接下来挨个学习这些知识点；&lt;/p&gt;
&lt;h3 id=&quot;springboot对容器环境的判断&quot;&gt;SpringBoot对容器环境的判断&lt;/h3&gt;
&lt;ol readability=&quot;3&quot;&gt;&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;官方文档如下图所示，SpringBoot判断是否是kubernetes环境的逻辑很简单：是否有&lt;span&gt;&lt;em&gt;_SERVICE_HOST&lt;/em&gt;&lt;/span&gt;&lt;em&gt;和&lt;/em&gt;&lt;span&gt;_SERVICE_PORT&lt;/span&gt;这两个环境变量：&lt;br/&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/485422/202006/485422-20200610074506943-68039617.png&quot; alt=&quot;在这里插入图片描述&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;2&quot;&gt;
&lt;p&gt;熟悉kubernetes的读者看到&lt;span&gt;&lt;em&gt;_SERVICE_HOST&quot;&lt;/em&gt;&lt;/span&gt; &lt;em&gt;和&lt;/em&gt;&lt;span&gt;_SERVICE_PORT&lt;/span&gt;，应该会想起&lt;span&gt;KUBERNETES_SERVICE_HOST&lt;/span&gt;和&lt;span&gt;KUBERNETES_SERVICE_PORT&lt;/span&gt;，这是k8s给pod中配置的环境变量，看来SpringBoot也是针对k8s的这个规则来判定是否是容器环境的(如果将来k8s的某个版本不给pod设置这个环境变量，那些原本可以正常运行的pod岂不是有危险了？)；&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;接下来通过实践来验证上述规则是否有效；&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;创建一个SpringBoot-2.3.0.RELEASE的应用，其pom.xml中的parent信息如下：&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;&lt;pre&gt;
&lt;code class=&quot;language-xml&quot;&gt;&amp;lt;parent&amp;gt;
  &amp;lt;groupId&amp;gt;org.springframework.boot&amp;lt;/groupId&amp;gt;
  &amp;lt;artifactId&amp;gt;spring-boot-starter-parent&amp;lt;/artifactId&amp;gt;
  &amp;lt;version&amp;gt;2.3.0.RELEASE&amp;lt;/version&amp;gt;
  &amp;lt;relativePath/&amp;gt;
&amp;lt;/parent&amp;gt;
&lt;/code&gt;
&lt;/pre&gt;
&lt;ol start=&quot;5&quot;&gt;&lt;li&gt;增加actuator依赖：&lt;/li&gt;
&lt;/ol&gt;&lt;pre&gt;
&lt;code class=&quot;language-xml&quot;&gt;&amp;lt;dependency&amp;gt;
  &amp;lt;groupId&amp;gt;org.springframework.boot&amp;lt;/groupId&amp;gt;
  &amp;lt;artifactId&amp;gt;spring-boot-starter-actuator&amp;lt;/artifactId&amp;gt;
&amp;lt;/dependency&amp;gt;
&lt;/code&gt;
&lt;/pre&gt;
&lt;ol start=&quot;6&quot;&gt;&lt;li&gt;启动该应用，浏览器访问：&lt;a href=&quot;http://localhost:8080/actuator/health/liveness&quot;&gt;&lt;span&gt;http://localhost:8080/actuator/health/liveness&lt;/span&gt;&lt;/a&gt;，返回404错误：&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/485422/202006/485422-20200610074507239-1345076910.png&quot; alt=&quot;在这里插入图片描述&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;ol start=&quot;7&quot;&gt;&lt;li&gt;以上返回是符合预期的，因为此时并非在kubernetes环境，接下来将&quot;&lt;span&gt;&lt;em&gt;_SERVICE_HOST&lt;/em&gt;&lt;/span&gt; &lt;em&gt;和&lt;/em&gt;&lt;span&gt;_SERVICE_PORT&lt;/span&gt;这两个环境变量加入应用进程，看看是否有变化；&lt;/li&gt;
&lt;li&gt;如下图，编辑启动类的配置信息：&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/485422/202006/485422-20200610074507567-452988648.png&quot; alt=&quot;在这里插入图片描述&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;ol start=&quot;9&quot;&gt;&lt;li&gt;点击下图红框位置，即可进入编辑环境变量的窗口：&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/485422/202006/485422-20200610074507913-1861514923.png&quot; alt=&quot;在这里插入图片描述&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;ol start=&quot;10&quot;&gt;&lt;li&gt;新的窗口中，操作如下图红框中所示，新增了两个环境变量：&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/485422/202006/485422-20200610074508377-1348688480.png&quot; alt=&quot;在这里插入图片描述&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;ol start=&quot;11&quot;&gt;&lt;li&gt;再次运行程序，这次返回的状态码是200：&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/485422/202006/485422-20200610074508687-1464269414.png&quot; alt=&quot;在这里插入图片描述&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;ol start=&quot;12&quot;&gt;&lt;li&gt;至此，我们弄明白了SpringBoot是否开启探针的逻辑，即应用是否运行在容器环境，而是否是容器环境的判定逻辑则是&lt;span&gt;&lt;em&gt;_SERVICE_HOST&lt;/em&gt;&lt;/span&gt;&lt;em&gt;和&lt;/em&gt;&lt;span&gt;_SERVICE_PORT&lt;/span&gt;这两个环境变量是否存在；&lt;/li&gt;
&lt;/ol&gt;&lt;h3 id=&quot;非kubernetes环境开启探针&quot;&gt;非kubernetes环境开启探针&lt;/h3&gt;
&lt;p&gt;&lt;span&gt;/actuator/health/liveness&lt;/span&gt;和&lt;span&gt;/actuator/health/readiness&lt;/span&gt;在kubernetes环境才会开启，但是一般情况下，在开发阶段SpringBoot应用可能运行在自己的电脑上，此时如果想查看这两个接口的返回值有两种方式：&lt;/p&gt;
&lt;p&gt;第一种，就是前面提到的添加&lt;span&gt;&lt;em&gt;_SERVICE_HOST&lt;/em&gt;&lt;/span&gt;&lt;em&gt;和&lt;/em&gt;&lt;span&gt;_SERVICE_PORT&lt;/span&gt;这两个环境变量，让SpringBoot以为当前环境是kubernetes环境；&lt;/p&gt;
&lt;p&gt;第二种，是按照官方指导添加属性，如下图红框所示：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/485422/202006/485422-20200610074508987-1336819275.png&quot; alt=&quot;在这里插入图片描述&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h3 id=&quot;springboot对探针相关状态定义&quot;&gt;SpringBoot对探针相关状态定义&lt;/h3&gt;
&lt;ol&gt;&lt;li&gt;首先要弄清楚有哪些状态，源码是最准确的；&lt;/li&gt;
&lt;li&gt;如下图，存活探针一共有两种状态：&lt;span&gt;CORRECT&lt;/span&gt;表示应用运行中并且内部状态正常，&lt;span&gt;BROKEN&lt;/span&gt;表示应用运行中并且内部是BROKEN状态(请原谅我的英语水平)&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/485422/202006/485422-20200610074509281-1533585551.png&quot; alt=&quot;在这里插入图片描述&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;ol start=&quot;3&quot;&gt;&lt;li&gt;如下图，就绪探针一共有两种状态：&lt;span&gt;ACCEPTING_TRAFFIC&lt;/span&gt;表示应用可以对外提供服务，&lt;span&gt;REFUSING_TRAFFIC&lt;/span&gt;表示应用无法对外提供服务；&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/485422/202006/485422-20200610074509502-628665374.png&quot; alt=&quot;在这里插入图片描述&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;ol start=&quot;4&quot; readability=&quot;-0.5&quot;&gt;&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;另外，上图的since注解显示这两个枚举是从&lt;span&gt;2.3.0&lt;/span&gt;版本开始生效的；&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;小小八卦一下，上述两个枚举的作者&lt;span&gt;Brian Clozel&lt;/span&gt;，坐标法国里昂，目前在sringboot的提交次数排第8名：&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/485422/202006/485422-20200610074509703-15700355.png&quot; alt=&quot;在这里插入图片描述&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;ol start=&quot;6&quot;&gt;&lt;li&gt;在SpringBoot启动过程中，应用、存活探针、就绪探针三者状态对应关系如下图：&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/485422/202006/485422-20200610074509979-2013709261.png&quot; alt=&quot;在这里插入图片描述&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;ol start=&quot;7&quot;&gt;&lt;li&gt;在SpringBoot停止过程中，应用、存活探针、就绪探针三者状态对应关系如下图：&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/485422/202006/485422-20200610074510346-1894757529.png&quot; alt=&quot;在这里插入图片描述&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h3 id=&quot;获取状态&quot;&gt;获取状态&lt;/h3&gt;
&lt;p&gt;如果业务应用想获取当前的存活和就绪状态，将ApplicationAvailability接口autowire进来即可，下一篇&lt;a href=&quot;https://blog.csdn.net/boling_cavalry/article/details/106607225&quot;&gt;《实战篇》&lt;/a&gt;会有详细的使用方式，这里看下关键代码：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/485422/202006/485422-20200610074510653-1669256498.png&quot; alt=&quot;在这里插入图片描述&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h3 id=&quot;监听状态&quot;&gt;监听状态&lt;/h3&gt;
&lt;p&gt;得益于Spring完整的事件发布和订阅机制，业务应用通过EventListener注解就能监听到存活和就绪状态的变化，在EventListener注解修饰的方法中写入必要的业务代码即可实现状态监听，下一篇&lt;a href=&quot;https://blog.csdn.net/boling_cavalry/article/details/106607225&quot;&gt;《实战篇》&lt;/a&gt;会有详细的使用方式，这里看下关键代码：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/485422/202006/485422-20200610074510865-211293395.png&quot; alt=&quot;在这里插入图片描述&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h3 id=&quot;修改状态&quot;&gt;修改状态&lt;/h3&gt;
&lt;ol&gt;&lt;li&gt;修改状态，尤其是就绪状态，这应该是我们最关注的功能了，在某些业务场景下，应用无法对外提供服务，这时候我们希望K8S不要将外部请求调度到这里，如果K8S通过就绪探针收到返回码非200，就不再将请求调度到这个pod上；&lt;/li&gt;
&lt;li&gt;下一篇&lt;a href=&quot;https://blog.csdn.net/boling_cavalry/article/details/106607225&quot;&gt;《实战篇》&lt;/a&gt;会有详细的代码介绍，这里给出关键代码作为参考：&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/485422/202006/485422-20200610074511113-1877140164.png&quot; alt=&quot;在这里插入图片描述&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h3 id=&quot;请注意&quot;&gt;请注意&lt;/h3&gt;
&lt;p&gt;重要的事情一定要强调：咱们修改状态的最终目的，不是为了取得applicationAvailability.getReadinessState()返回新的枚举对象，而是要&lt;span&gt;改变/actuator/health/readiness接口的返回码(就绪是200，未就绪是503)&lt;/span&gt;，这是kubernetes的探针规则要用到的；&lt;/p&gt;
&lt;h3 id=&quot;为啥都放在下一篇&quot;&gt;为啥都放在下一篇&lt;/h3&gt;
&lt;ol&gt;&lt;li&gt;文章看到这里您可能已经火冒三丈了：关键代码都贴出来了，为啥不在本章给出完整源码？骗点击量？凑字数？凑文章数？&lt;/li&gt;
&lt;li&gt;存活和就绪探针是在kubernetes环境下的工具，为了给您提供尽量准确和完整的参考，所有的代码和操作都必须在kubernetes环境完成调试才能发布，而且这些操作应该作为单独章节，与当前的理论知识分开；&lt;/li&gt;
&lt;li&gt;欢迎进入&lt;a href=&quot;https://blog.csdn.net/boling_cavalry/article/details/106607225&quot;&gt;《实战篇》&lt;/a&gt;，随SpringBoot-2.3.0.RELEASE，一起在kubernetes世界畅游；&lt;/li&gt;
&lt;/ol&gt;&lt;h3 id=&quot;欢迎关注我的公众号：程序员欣宸&quot;&gt;欢迎关注我的公众号：程序员欣宸&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/485422/202006/485422-20200610074511383-952103949.jpg&quot; alt=&quot;在这里插入图片描述&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/zq2599/blog_demos&quot;&gt;https://github.com/zq2599/blog_demos&lt;/a&gt;&lt;/p&gt;
</description>
<pubDate>Tue, 09 Jun 2020 23:45:00 +0000</pubDate>
<dc:creator>zq2599</dc:creator>
<og:description>欢迎访问我的GitHub https://github.com/zq2599/blog_demos 内容：原创分类汇总及配套源码，涉及Java、Docker、K8S、DevOPS等 关于《Spring</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/bolingcavalry/p/13082594.html</dc:identifier>
</item>
<item>
<title>小师妹学JavaIO之:Buffer和Buff - flydean</title>
<link>http://www.cnblogs.com/flydean/p/java-io-nio-buffer.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/flydean/p/java-io-nio-buffer.html</guid>
<description>&lt;p&gt;小师妹在学习NIO的路上越走越远，唯一能够帮到她的就是在她需要的时候给她以全力的支持。什么都不说了，今天介绍的是NIO的基础Buffer。老铁给我上个Buff。&lt;/p&gt;

&lt;p&gt;小师妹：F师兄，这个Buffer是我们纵横王者峡谷中那句：老铁给我加个Buff的意思吗？&lt;/p&gt;
&lt;p&gt;当然不是了，此Buffer非彼Buff，Buffer是NIO的基础，没有Buffer就没有NIO，没有Buffer就没有今天的java。&lt;/p&gt;
&lt;p&gt;因为NIO是按Block来读取数据的，这个一个Block就可以看做是一个Buffer。我们在Buffer中存储要读取的数据和要写入的数据，通过Buffer来提高读取和写入的效率。&lt;/p&gt;
&lt;p&gt;更多精彩内容且看：&lt;/p&gt;
&lt;blockquote readability=&quot;2.9166666666667&quot;&gt;
&lt;p&gt;更多内容请访问&lt;a href=&quot;https://www.cnblogs.com/flydean/p/www.flydean.com&quot;&gt;www.flydean.com&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;还记得java对象的底层存储单位是什么吗？&lt;/p&gt;
&lt;p&gt;小师妹：这个我知道，java对象的底层存储单位是字节Byte。&lt;/p&gt;
&lt;p&gt;对，我们看下Buffer的继承图：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20200514142719108.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_0,text_aHR0cDovL3d3dy5mbHlkZWFuLmNvbQ==,size_35,color_8F8F8F,t_70&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;Buffer是一个接口，它下面有诸多实现，包括最基本的ByteBuffer和其他的基本类型封装的其他Buffer。&lt;/p&gt;
&lt;p&gt;小师妹：F师兄，有ByteBuffer不就够了吗？还要其他的类型Buffer做什么？&lt;/p&gt;
&lt;p&gt;小师妹，山珍再好，也有吃腻的时候，偶尔也要换个萝卜白菜啥的，你以为乾隆下江南都干了些啥？&lt;/p&gt;
&lt;p&gt;ByteBuffer虽然好用，但是它毕竟是最小的单位，在它之上我们还有Char，int，Double，Short等等基础类型，为了简单起见，我们也给他们都搞一套Buffer。&lt;/p&gt;

&lt;p&gt;小师妹：F师兄，既然Buffer是这些基础类型的集合，为什么不直接用结合来表示呢？给他们封装成一个对象，好像有点多余。&lt;/p&gt;
&lt;p&gt;我们既然在面向对象的世界，从表面来看自然是使用Object比较合乎情理，从底层的本质上看，这些封装的Buffer包含了一些额外的元数据信息，并且还提供了一些意想不到的功能。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20200519142644525.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_0,text_aHR0cDovL3d3dy5mbHlkZWFuLmNvbQ==,size_35,color_8F8F8F,t_70&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;上图列出了Buffer中的几个关键的概念，分别是Capacity，Limit，Position和Mark。Buffer底层的本质是数组，我们以ByteBuffer为例，它的底层是：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;final byte[] hb; 
&lt;/code&gt;
&lt;/pre&gt;
&lt;ul&gt;&lt;li&gt;Capacity表示的是该Buffer能够承载元素的最大数目，这个是在Buffer创建初期就设置的，不可以被改变。&lt;/li&gt;
&lt;li&gt;Limit表示的Buffer中可以被访问的元素个数，也就是说Buffer中存活的元素个数。&lt;/li&gt;
&lt;li&gt;Position表示的是下一个可以被访问元素的index，可以通过put和get方法进行自动更新。&lt;/li&gt;
&lt;li&gt;Mark表示的是历史index，当我们调用mark方法的时候，会把设置Mark为当前的position，通过调用reset方法把Mark的值恢复到position中。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;小师妹：F师兄呀，这么多Buffer创建起来是不是很麻烦？有没有什么快捷的使用办法？&lt;/p&gt;
&lt;p&gt;一般来说创建Buffer有两种方法，一种叫做allocate，一种叫做wrap。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;public void createBuffer(){
        IntBuffer intBuffer= IntBuffer.allocate(10);
        log.info(&quot;{}&quot;,intBuffer);
        log.info(&quot;{}&quot;,intBuffer.hasArray());
        int[] intArray=new int[10];
        IntBuffer intBuffer2= IntBuffer.wrap(intArray);
        log.info(&quot;{}&quot;,intBuffer2);
        IntBuffer intBuffer3= IntBuffer.wrap(intArray,2,5);
        log.info(&quot;{}&quot;,intBuffer3);
        intBuffer3.clear();
        log.info(&quot;{}&quot;,intBuffer3);
        log.info(&quot;{}&quot;,intBuffer3.hasArray());
    }
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;allocate可以为Buffer分配一个空间，wrap同样为Buffer分配一个空间，不同的是这个空间背后的数组是自定义的，wrap还支持三个参数的方法，后面两个参数分别是offset和length。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;INFO com.flydean.BufferUsage - java.nio.HeapIntBuffer[pos=0 lim=10 cap=10]
INFO com.flydean.BufferUsage - true
INFO com.flydean.BufferUsage - java.nio.HeapIntBuffer[pos=0 lim=10 cap=10]
INFO com.flydean.BufferUsage - java.nio.HeapIntBuffer[pos=2 lim=7 cap=10]
INFO com.flydean.BufferUsage - java.nio.HeapIntBuffer[pos=0 lim=10 cap=10]
INFO com.flydean.BufferUsage - true
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;hasArray用来判断该Buffer的底层是不是数组实现的，可以看到，不管是wrap还是allocate，其底层都是数组。&lt;/p&gt;
&lt;blockquote readability=&quot;7&quot;&gt;
&lt;p&gt;需要注意的一点，最后，我们调用了clear方法，clear方法调用之后，我们发现Buffer的position和limit都被重置了。这说明wrap的三个参数方法设定的只是初始值，可以被重置。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;小师妹：F师兄，你说了两种创建Buffer的方法，但是两种Buffer的后台都是数组，难道还有非数组的Buffer吗？&lt;/p&gt;
&lt;p&gt;自然是有的,但是只有ByteBuffer有。ByteBuffer有一个allocateDirect方法，可以分配Direct Buffer。&lt;/p&gt;
&lt;p&gt;小师妹：Direct和非Direct有什么区别呢？&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20200513225239404.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_0,text_aHR0cDovL3d3dy5mbHlkZWFuLmNvbQ==,size_35,color_8F8F8F,t_70&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;Direct Buffer就是说，不需要在用户空间再复制拷贝一份数据，直接在虚拟地址映射空间中进行操作。这叫Direct。这样做的好处就是快。缺点就是在分配和销毁的时候会占用更多的资源，并且因为Direct Buffer不在用户空间之内，所以也不受垃圾回收机制的管辖。&lt;/p&gt;
&lt;p&gt;所以通常来说只有在数据量比较大，生命周期比较长的数据来使用Direct Buffer。&lt;/p&gt;
&lt;p&gt;看下代码：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;public void createByteBuffer() throws IOException {
        ByteBuffer byteBuffer= ByteBuffer.allocateDirect(10);
        log.info(&quot;{}&quot;,byteBuffer);
        log.info(&quot;{}&quot;,byteBuffer.hasArray());
        log.info(&quot;{}&quot;,byteBuffer.isDirect());

        try (RandomAccessFile aFile = new RandomAccessFile(&quot;src/main/resources/www.flydean.com&quot;, &quot;r&quot;);
             FileChannel inChannel = aFile.getChannel()) {
            MappedByteBuffer buffer = inChannel.map(FileChannel.MapMode.READ_ONLY, 0, inChannel.size());
            log.info(&quot;{}&quot;,buffer);
            log.info(&quot;{}&quot;,buffer.hasArray());
            log.info(&quot;{}&quot;,buffer.isDirect());
        }
    }
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;除了allocateDirect,使用FileChannel的map方法也可以得到一个Direct的MappedByteBuffer。&lt;/p&gt;
&lt;p&gt;上面的例子输出结果：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;INFO com.flydean.BufferUsage - java.nio.DirectByteBuffer[pos=0 lim=10 cap=10]
INFO com.flydean.BufferUsage - false
INFO com.flydean.BufferUsage - true
INFO com.flydean.BufferUsage - java.nio.DirectByteBufferR[pos=0 lim=0 cap=0]
INFO com.flydean.BufferUsage - false
INFO com.flydean.BufferUsage - true
&lt;/code&gt;
&lt;/pre&gt;

&lt;p&gt;小师妹:F师兄，看起来Buffer确实有那么一点复杂，那么Buffer都有哪些操作呢？&lt;/p&gt;
&lt;p&gt;Buffer的操作有很多，下面我们一一来讲解。&lt;/p&gt;
&lt;h2 id=&quot;向buffer写数据&quot;&gt;向Buffer写数据&lt;/h2&gt;
&lt;p&gt;向Buffer写数据可以调用Buffer的put方法：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;public void putBuffer(){
        IntBuffer intBuffer= IntBuffer.allocate(10);
        intBuffer.put(1).put(2).put(3);
        log.info(&quot;{}&quot;,intBuffer.array());
        intBuffer.put(0,4);
        log.info(&quot;{}&quot;,intBuffer.array());
    }
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;因为put方法返回的还是一个IntBuffer类，所以Buffer的put方法可以像Stream那样连写。&lt;/p&gt;
&lt;p&gt;同时，我们还可以指定put在什么位置。上面的代码输出：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;INFO com.flydean.BufferUsage - [1, 2, 3, 0, 0, 0, 0, 0, 0, 0]
INFO com.flydean.BufferUsage - [4, 2, 3, 0, 0, 0, 0, 0, 0, 0]
&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;从buffer读数据&quot;&gt;从Buffer读数据&lt;/h2&gt;
&lt;p&gt;读数据使用get方法，但是在get方法之前我们需要调用flip方法。&lt;/p&gt;
&lt;p&gt;flip方法是做什么用的呢？上面讲到Buffer有个position和limit字段，position会随着get或者put的方法自动指向后面一个元素，而limit表示的是该Buffer中有多少可用元素。&lt;/p&gt;
&lt;p&gt;如果我们要读取Buffer的值则会从positon开始到limit结束：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;public void getBuffer(){
        IntBuffer intBuffer= IntBuffer.allocate(10);
        intBuffer.put(1).put(2).put(3);
        intBuffer.flip();
        while (intBuffer.hasRemaining()) {
            log.info(&quot;{}&quot;,intBuffer.get());
        }
        intBuffer.clear();
    }
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;可以通过hasRemaining来判断是否还有下一个元素。通过调用clear来清除Buffer，以供下次使用。&lt;/p&gt;
&lt;h2 id=&quot;rewind-buffer&quot;&gt;rewind Buffer&lt;/h2&gt;
&lt;p&gt;rewind和flip很类似，不同之处在于rewind不会改变limit的值，只会将position重置为0。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;public void rewindBuffer(){
        IntBuffer intBuffer= IntBuffer.allocate(10);
        intBuffer.put(1).put(2).put(3);
        log.info(&quot;{}&quot;,intBuffer);
        intBuffer.rewind();
        log.info(&quot;{}&quot;,intBuffer);
    }
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;上面的结果输出：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;INFO com.flydean.BufferUsage - java.nio.HeapIntBuffer[pos=3 lim=10 cap=10]
INFO com.flydean.BufferUsage - java.nio.HeapIntBuffer[pos=0 lim=10 cap=10]
&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;compact-buffer&quot;&gt;Compact Buffer&lt;/h2&gt;
&lt;p&gt;Buffer还有一个compact方法，顾名思义compact就是压缩的意思，就是把Buffer从当前position到limit的值赋值到position为0的位置：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;public void useCompact(){
        IntBuffer intBuffer= IntBuffer.allocate(10);
        intBuffer.put(1).put(2).put(3);
        intBuffer.flip();
        log.info(&quot;{}&quot;,intBuffer);
        intBuffer.get();
        intBuffer.compact();
        log.info(&quot;{}&quot;,intBuffer);
        log.info(&quot;{}&quot;,intBuffer.array());
    }
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;上面代码输出：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;INFO com.flydean.BufferUsage - java.nio.HeapIntBuffer[pos=0 lim=3 cap=10]
INFO com.flydean.BufferUsage - java.nio.HeapIntBuffer[pos=2 lim=10 cap=10]
INFO com.flydean.BufferUsage - [2, 3, 3, 0, 0, 0, 0, 0, 0, 0]
&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;duplicate-buffer&quot;&gt;duplicate Buffer&lt;/h2&gt;
&lt;p&gt;最后我们讲一下复制Buffer，有三种方法，duplicate，asReadOnlyBuffer，和slice。&lt;/p&gt;
&lt;p&gt;duplicate就是拷贝原Buffer的position，limit和mark，它和原Buffer是共享原始数据的。所以修改了duplicate之后的Buffer也会同时修改原Buffer。&lt;/p&gt;
&lt;p&gt;如果用asReadOnlyBuffer就不允许拷贝之后的Buffer进行修改。&lt;/p&gt;
&lt;p&gt;slice也是readOnly的，不过它拷贝的是从原Buffer的position到limit-position之间的部分。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;public void duplicateBuffer(){
        IntBuffer intBuffer= IntBuffer.allocate(10);
        intBuffer.put(1).put(2).put(3);
        log.info(&quot;{}&quot;,intBuffer);
        IntBuffer duplicateBuffer=intBuffer.duplicate();
        log.info(&quot;{}&quot;,duplicateBuffer);
        IntBuffer readOnlyBuffer=intBuffer.asReadOnlyBuffer();
        log.info(&quot;{}&quot;,readOnlyBuffer);
        IntBuffer sliceBuffer=intBuffer.slice();
        log.info(&quot;{}&quot;,sliceBuffer);
    }
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;输出结果：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;INFO com.flydean.BufferUsage - java.nio.HeapIntBuffer[pos=3 lim=10 cap=10]
INFO com.flydean.BufferUsage - java.nio.HeapIntBuffer[pos=3 lim=10 cap=10]
INFO com.flydean.BufferUsage - java.nio.HeapIntBufferR[pos=3 lim=10 cap=10]
INFO com.flydean.BufferUsage - java.nio.HeapIntBuffer[pos=0 lim=7 cap=7]
&lt;/code&gt;
&lt;/pre&gt;

&lt;p&gt;今天给小师妹介绍了Buffer的原理和基本操作。&lt;/p&gt;
&lt;p&gt;本文的例子&lt;a href=&quot;https://github.com/ddean2009/learn-java-io-nio&quot;&gt;https://github.com/ddean2009/learn-java-io-nio&lt;/a&gt;&lt;/p&gt;
&lt;blockquote readability=&quot;8.6666666666667&quot;&gt;
&lt;p&gt;本文作者：flydean程序那些事&lt;/p&gt;
&lt;p&gt;本文链接：&lt;a href=&quot;http://www.flydean.com/java-io-nio-buffer/&quot;&gt;http://www.flydean.com/java-io-nio-buffer/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;本文来源：flydean的博客&lt;/p&gt;
&lt;p&gt;欢迎关注我的公众号:程序那些事，更多精彩等着您！&lt;/p&gt;
&lt;/blockquote&gt;
</description>
<pubDate>Tue, 09 Jun 2020 22:07:00 +0000</pubDate>
<dc:creator>flydean</dc:creator>
<og:description>简介 小师妹在学习NIO的路上越走越远，唯一能够帮到她的就是在她需要的时候给她以全力的支持。什么都不说了，今天介绍的是NIO的基础Buffer。老铁给我上个Buff。 Buffer是什么 小师妹：F师</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/flydean/p/java-io-nio-buffer.html</dc:identifier>
</item>
<item>
<title>STM32的8*8点阵屏开发（小项目） - 东小东</title>
<link>http://www.cnblogs.com/dongxiaodong/p/13082539.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/dongxiaodong/p/13082539.html</guid>
<description>&lt;h2&gt;基础认识&lt;/h2&gt;
&lt;h3&gt; 实现效果&lt;/h3&gt;
&lt;p&gt;项目实现STM32点阵屏的操作，自动更改显示内容和串口控制显示内容&lt;/p&gt;
&lt;p&gt;STM32上电后：&lt;/p&gt;
&lt;p&gt;1)   程序将进行行和列的刷新&lt;/p&gt;
&lt;p&gt;2)   自动递增显示0-9变化&lt;/p&gt;
&lt;p&gt;3)   进行矩形由内向外动画&lt;/p&gt;
&lt;p&gt;4)   等等串口输出控制，输出范围为0x00-0x09，点阵屏将显示输入的数字&lt;/p&gt;
&lt;p&gt;代码为精简的最小系统，方便后续的扩展和移植&lt;/p&gt;
&lt;h3&gt;视频展示&lt;/h3&gt;
&lt;p&gt;&lt;a href=&quot;https://www.bilibili.com/video/BV1Pi4y1x7Fo&quot;&gt;https://www.bilibili.com/video/BV1Pi4y1x7Fo&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;环境配置&lt;/h3&gt;
&lt;p&gt;STM32固件版本：V3.5.0&lt;/p&gt;
&lt;p&gt;单片机：STM32 F103C8T6&lt;/p&gt;
&lt;p&gt;LED点阵管数码管：共阳1588BS&lt;/p&gt;
&lt;p&gt;编程工具：Keil uVision5&lt;/p&gt;
&lt;h3&gt; LED点阵管数码管认识&lt;/h3&gt;
&lt;p&gt;1.5英寸LED点阵管数码管8*8红色16pin&lt;/p&gt;
&lt;p&gt;有如下两种型号：&lt;/p&gt;
&lt;p&gt;l  共阳1588BS&lt;/p&gt;
&lt;p&gt;l  共阴1588AS&lt;/p&gt;
&lt;p&gt;这里使用的是：共阳1588BS&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1485202/202006/1485202-20200610031042227-488700857.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h2&gt;开始使用&lt;/h2&gt;
&lt;h3&gt; 环境准备&lt;/h3&gt;
&lt;p&gt;l  STM32固件版本：V3.5.0&lt;/p&gt;
&lt;p&gt;l  单片机：STM32 F103C8T6&lt;/p&gt;
&lt;p&gt;l  LED点阵管数码管：共阳1588BS&lt;/p&gt;
&lt;p&gt;l  编程工具：Keil uVision5&lt;/p&gt;
&lt;h3&gt; 点阵屏与STM32接线说明&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;接线编号：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;点阵屏1-8：A0、A1、A2、A3、A4、A5、A6、A7&lt;/p&gt;
&lt;p&gt;点阵屏9-16：B0、B1、B10、B11、B12、B13、B14、B15&lt;/p&gt;
&lt;h3&gt;打开/编译/烧写&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1485202/202006/1485202-20200610031155532-2093838796.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;

&lt;p&gt; &lt;img src=&quot;https://img2020.cnblogs.com/blog/1485202/202006/1485202-20200610031201014-600119438.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1485202/202006/1485202-20200610031206781-142908905.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h2&gt; 项目测试&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;打开串口助手&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt; &lt;img src=&quot;https://img2020.cnblogs.com/blog/1485202/202006/1485202-20200610031249027-890663985.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;连接USB串口模块&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1485202/202006/1485202-20200610031301795-685247940.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;上电后自动进行行列刷新&lt;/p&gt;
&lt;p&gt; &lt;img src=&quot;https://img2020.cnblogs.com/blog/1485202/202006/1485202-20200610031323269-1687026191.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;数字自动显示&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1485202/202006/1485202-20200610031338810-304214610.png&quot; alt=&quot;&quot; width=&quot;370&quot; height=&quot;338&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt; &lt;img src=&quot;https://img2020.cnblogs.com/blog/1485202/202006/1485202-20200610031354028-321222368.png&quot; alt=&quot;&quot; width=&quot;368&quot; height=&quot;390&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt; &lt;img src=&quot;https://img2020.cnblogs.com/blog/1485202/202006/1485202-20200610031358352-1279109294.png&quot; alt=&quot;&quot; width=&quot;368&quot; height=&quot;332&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;小动画显示&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1485202/202006/1485202-20200610031410863-1049411120.png&quot; alt=&quot;&quot; width=&quot;375&quot; height=&quot;345&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt; &lt;img src=&quot;https://img2020.cnblogs.com/blog/1485202/202006/1485202-20200610031417780-400104195.png&quot; alt=&quot;&quot; width=&quot;372&quot; height=&quot;308&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;串口控制：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1485202/202006/1485202-20200610031428718-701713795.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1485202/202006/1485202-20200610031435309-1395945627.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h2&gt; 编码说明&lt;/h2&gt;
&lt;p&gt; &lt;img src=&quot;https://img2020.cnblogs.com/blog/1485202/202006/1485202-20200610031513935-1809252386.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt; &lt;img src=&quot;https://img2020.cnblogs.com/blog/1485202/202006/1485202-20200610031523773-158255952.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;分析得到编码序列：&lt;/p&gt;
&lt;p&gt;因为列是固定为低电平，也就是只要行输出高电平，对应的点就点亮，确定行的高低位，设置从上到下为0-7行，所以第0行是十六进制的最低位而7是16进制的最高位。&lt;/p&gt;
&lt;p&gt;得到结果分析：&lt;/p&gt;
&lt;p&gt;第0列编码：0000 0000 = 0x00&lt;/p&gt;
&lt;p&gt;第1列编码：0111 1110 = 0x7E&lt;/p&gt;
&lt;p&gt;第2列编码：1010 0001 = 0xA1&lt;/p&gt;
&lt;p&gt;第3列编码：1001 0001 = 0x91&lt;/p&gt;
&lt;p&gt;第4列编码：1000 1001 = 0x89&lt;/p&gt;
&lt;p&gt;第5列编码：1000 0101 = 0x85&lt;/p&gt;
&lt;p&gt;第6列编码：0111 1110 = 0x7E&lt;/p&gt;
&lt;p&gt;第7列编码：0000 0000 = 0x00&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;所以得到数字0的编码数组为：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;{0x00,0x7E,0xA1,0x91,0x89,0x85,0x7E,0x00}&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1485202/202006/1485202-20200610031539652-437349202.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;

&lt;h3&gt;视频展示&lt;/h3&gt;
&lt;p&gt;&lt;a href=&quot;https://www.bilibili.com/video/BV1Pi4y1x7Fo&quot;&gt;https://www.bilibili.com/video/BV1Pi4y1x7Fo&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;span&gt; 以下内容不完全展示.......&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;

</description>
<pubDate>Tue, 09 Jun 2020 19:23:00 +0000</pubDate>
<dc:creator>东小东</dc:creator>
<og:description>基础认识 实现效果 项目实现STM32点阵屏的操作，自动更改显示内容和串口控制显示内容 STM32上电后： 1) 程序将进行行和列的刷新 2) 自动递增显示0-9变化 3) 进行矩形由内向外动画 4)</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/dongxiaodong/p/13082539.html</dc:identifier>
</item>
<item>
<title>心有 netty 一点通！ - WindWant</title>
<link>http://www.cnblogs.com/niejunlei/p/13070107.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/niejunlei/p/13070107.html</guid>
<description>&lt;p&gt;netty 高性能之道...&lt;/p&gt;&lt;div id=&quot;cnblogs_post_body&quot; readability=&quot;122&quot;&gt;
&lt;h2&gt;一、标准的netty线程模型&lt;/h2&gt;
&lt;p&gt;双池合璧：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/603942/202006/603942-20200609021151579-1438439519.png&quot; alt=&quot;&quot; width=&quot;472&quot; height=&quot;394&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h3&gt;1、连接线程池：&lt;/h3&gt;
&lt;p&gt;连接线程池专门负责监听客户端连接请求，并完成连接的建立（包括诸如握手、安全认证等过程）。&lt;/p&gt;
&lt;p&gt;连接的建立本身是一个极其复杂、损耗性能的过程，此处使用线程池，能够极大的增加处理客户端连接的能力。&lt;/p&gt;
&lt;h3&gt;2、I/O线程池：&lt;/h3&gt;
&lt;p&gt;连接线程池会将成功建立的连接注册到后端I/O线程池，由I/O线程池负责对相应连接的网络数据进行读写、编解码处理。&lt;/p&gt;
&lt;p&gt;在实际应用中，我们通常会定义相应的业务消息协议，并选择合适的序列化机制，netty I/O线程池部分根据预设的规则进行数据的编解码。&lt;/p&gt;
&lt;h2&gt;二、延伸的业务线程池&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/603942/202006/603942-20200609021251132-1352680505.png&quot; alt=&quot;&quot; width=&quot;612&quot; height=&quot;321&quot; loading=&quot;lazy&quot;/&gt; &lt;/p&gt;
&lt;p&gt;其实我们这里说的业务线程池不在网络层处理逻辑里。处理到I/O线程池部分，所需要的请求数据已经处理完毕，涉及具体的业务处理逻辑，比较复杂的，或者时间、性能消耗特别大的，通常我们会单独设置相应的线程池来处理。&lt;/p&gt;
&lt;h2&gt;三、netty的极致性能设计&lt;/h2&gt;
&lt;h3&gt;1、无锁化设计&lt;/h3&gt;
&lt;p&gt;I/O线程的内部串行化：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/603942/202006/603942-20200609021000902-1518664646.png&quot; alt=&quot;&quot; width=&quot;411&quot; height=&quot;344&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;局部无锁化串行处理，避免多线程切换带来的复杂性及性能损耗（锁竞争、CPU资源分配）。至于对于处理能力的考虑，可以通过调整I/O线程池容量来平衡。&lt;/p&gt;
&lt;p&gt;尽量避免I/O线程和业务线程混淆及切换。&lt;/p&gt;
&lt;h3&gt;2、直接内存使用&lt;/h3&gt;
&lt;p&gt;TCP接收和发送使用直接内存代替堆内存，避免了数据在堆内存和主内存之间的复制消耗，提升了I/O读取和写入的性能。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/603942/202006/603942-20200609133621198-1027354531.png&quot; alt=&quot;&quot; width=&quot;449&quot; height=&quot;316&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h3&gt; 3、transferTo&lt;/h3&gt;
&lt;p&gt;依赖于操作系统零拷贝特性直接将缓冲区数据发送到相应的通道。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/603942/202006/603942-20200609230903485-1202161602.png&quot; alt=&quot;&quot; width=&quot;595&quot; height=&quot;197&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;传统的方式，先将源文件拷贝到内存，然后由内存写到目的文件。&lt;/p&gt;
&lt;p&gt;netty 利用 NIO FileChannel transferTo方法，通道对通道写数据。&lt;/p&gt;
&lt;h3&gt;4、CompositeByteBuf&lt;/h3&gt;
&lt;p&gt;组合缓存使用可以像操作单个缓存一样操作多个缓存，避免了传统的操作方式带来的内存复制性能消耗。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/603942/202006/603942-20200609233257239-770227585.png&quot; alt=&quot;&quot; width=&quot;486&quot; height=&quot;163&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h3&gt;5、内存池使用&lt;/h3&gt;
&lt;p&gt;netty支持通过内存池的方式循环利用ByteBuf，避免了频繁的创建，销毁ByteBuf带来的资源及性能损耗。&lt;/p&gt;
&lt;p&gt;ByteBuf byte数据缓冲区，是NIO编程的主要对象。高负载情景下，ByteBuf内存池使用，可以有效降低GC频率。&lt;/p&gt;
&lt;p&gt;PoolArena netty的内存池实现类。PoolArena 是由多个Chunk组成的大块内存区域，每个Chunk由一个多个Page组成。&lt;/p&gt;
&lt;p&gt;Chunk：组织管理Page的内存分配和释放，Page被构建为二叉树形式：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/603942/202006/603942-20200610003125133-1991919483.png&quot; alt=&quot;&quot; width=&quot;298&quot; height=&quot;257&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;PoolSubpage：对于小于Page的内存使用，直接在Page中完成分配，每个Page切分为大小相同的多个存储块儿，存储块儿的大小由第一次申请的内存块儿大小决定。&lt;/p&gt;
&lt;p&gt;回收：netty使用状态位标识Chunk及Page内存可用性，Chunk标识二叉树Page节点使用状态；Page标识内部内存块儿的使用状态。&lt;/p&gt;
&lt;h3&gt;6、线程安全优化&lt;/h3&gt;
&lt;p&gt;合理的使用线程安全容器、原子类等，提升系统的并发处理能力，&lt;/p&gt;
&lt;h3&gt;7、引用计数器&lt;/h3&gt;
&lt;p&gt;通过引用计数器及时的申请释放不再引用的对象，细粒度的内存管理降低了GC的频率，减少GC带来的时延增大和CPU损耗。&lt;/p&gt;
&lt;p&gt;Netty 4中 ByteBuf 和 ByteBufHolder 引入引用计数器功能（实现ReferenceCounted接口），在特定的对象上跟踪引用的数目。&lt;/p&gt;
&lt;p&gt;引用计数器初始为1。如果对象活动的引用计数器大于0，则不会被释放。当引用计数减少到0，实例将会被释放。这也是 PooledByteBufAllocator 内存池应用的核心特性。&lt;/p&gt;

&lt;/div&gt;</description>
<pubDate>Tue, 09 Jun 2020 17:01:00 +0000</pubDate>
<dc:creator>WindWant</dc:creator>
<og:description>netty 高性能之道...</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/niejunlei/p/13070107.html</dc:identifier>
</item>
<item>
<title>03 . Prometheus监控容器和HTTP探针应用 - you-men</title>
<link>http://www.cnblogs.com/you-men/p/13081972.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/you-men/p/13081972.html</guid>
<description>&lt;h4 id=&quot;eeporter是什么及来源？&quot;&gt;Eeporter是什么及来源？&lt;/h4&gt;
&lt;h5 id=&quot;是什么&quot;&gt;是什么?&lt;/h5&gt;
&lt;blockquote readability=&quot;7&quot;&gt;
&lt;p&gt;广义上讲所有可以向Prometheus提供监控样本数据的程序都可以被称为一个Exporter。而Exporter的一个实例称为target，如下所示，Prometheus通过轮询的方式定期从这些target中获取样本数据:&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1871335/202006/1871335-20200609235145004-1647669731.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h5 id=&quot;来源有哪些&quot;&gt;来源有哪些?&lt;/h5&gt;
&lt;p&gt;&lt;strong&gt;社区提供的&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote readability=&quot;7&quot;&gt;
&lt;p&gt;Prometheus社区提供了丰富的Exporter实现，涵盖了从基础设施，中间件以及网络等各个方面的监控功能。这些Exporter可以实现大部分通用的监控需求。下表列举一些社区中常用的Exporter:&lt;/p&gt;
&lt;/blockquote&gt;
&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;范围&lt;/th&gt;
&lt;th&gt;常用Exporter&lt;/th&gt;
&lt;/tr&gt;&lt;/thead&gt;&lt;tbody readability=&quot;19.5&quot;&gt;&lt;tr readability=&quot;5&quot;&gt;&lt;td&gt;数据库&lt;/td&gt;
&lt;td&gt;MySQL Exporter, Redis Exporter, MongoDB Exporter, MSSQL Exporter等&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;3&quot;&gt;&lt;td&gt;硬件&lt;/td&gt;
&lt;td&gt;Apcupsd Exporter，IoT Edison Exporter， IPMI Exporter, Node Exporter等&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;5&quot;&gt;&lt;td&gt;消息队列&lt;/td&gt;
&lt;td&gt;Beanstalkd Exporter, Kafka Exporter, NSQ Exporter, RabbitMQ Exporter等&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;5&quot;&gt;&lt;td&gt;存储&lt;/td&gt;
&lt;td&gt;Ceph Exporter, Gluster Exporter, HDFS Exporter, ScaleIO Exporter等&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;4&quot;&gt;&lt;td&gt;HTTP服务&lt;/td&gt;
&lt;td&gt;Apache Exporter, HAProxy Exporter, Nginx Exporter等&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;4&quot;&gt;&lt;td&gt;API服务&lt;/td&gt;
&lt;td&gt;AWS ECS Exporter， Docker Cloud Exporter, Docker Hub Exporter, GitHub Exporter等&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;3&quot;&gt;&lt;td&gt;日志&lt;/td&gt;
&lt;td&gt;Fluentd Exporter, Grok Exporter等&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;6&quot;&gt;&lt;td&gt;监控系统&lt;/td&gt;
&lt;td&gt;Collectd Exporter, Graphite Exporter, InfluxDB Exporter, Nagios Exporter, SNMP Exporter等&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;4&quot;&gt;&lt;td&gt;其他&lt;/td&gt;
&lt;td&gt;Blockbox Exporter, JIRA Exporter, Jenkins Exporter， Confluence Exporter等&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;&lt;strong&gt;用户自定义的&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote readability=&quot;9&quot;&gt;
&lt;p&gt;除了直接使用社区提供的Exporter程序以外，用户还可以基于Prometheus提供的Client Library创建自己的Exporter程序，目前Promthues社区官方提供了对以下编程语言的支持：Go、Java/Scala、Python、Ruby。同时还有第三方实现的如：Bash、C++、Common Lisp、Erlang,、Haskeel、Lua、Node.js、PHP、Rust等。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4 id=&quot;exporter的运行方式&quot;&gt;Exporter的运行方式&lt;/h4&gt;
&lt;p&gt;&lt;code&gt;从Exporter的运行方式来讲,又可以分为&lt;/code&gt;&lt;/p&gt;
&lt;h5 id=&quot;独立使用的&quot;&gt;&lt;strong&gt;独立使用的&lt;/strong&gt;&lt;/h5&gt;
&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;以我们已经使用过的Node Exporter为例，由于操作系统本身并不直接支持Prometheus，同时用户也无法通过直接从操作系统层面上提供对Prometheus的支持。因此，用户只能通过独立运行一个程序的方式，通过操作系统提供的相关接口，将系统的运行状态数据转换为可供Prometheus读取的监控数据。 除了Node Exporter以外，比如MySQL Exporter、Redis Exporter等都是通过这种方式实现的。 这些Exporter程序扮演了一个中间代理人的角色。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h5 id=&quot;集成到应用中的&quot;&gt;&lt;strong&gt;集成到应用中的&lt;/strong&gt;&lt;/h5&gt;
&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;为了能够更好的监控系统的内部运行状态，有些开源项目如Kubernetes，ETCD等直接在代码中使用了Prometheus的Client Library，提供了对Prometheus的直接支持。这种方式打破的监控的界限，让应用程序可以直接将内部的运行状态暴露给Prometheus，适合于一些需要更多自定义监控指标需求的项目。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4 id=&quot;exporter规范&quot;&gt;Exporter规范&lt;/h4&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;所有的Exporter程序都需要按照Prometheus的规范，返回监控的样本数据。以Node Exporter为例，当访问/metrics地址时会返回以下内容：&lt;/p&gt;
&lt;/blockquote&gt;
&lt;pre&gt;
&lt;code class=&quot;language-shell&quot;&gt;# HELP node_cpu Seconds the cpus spent in each mode.
# TYPE node_cpu counter
node_cpu{cpu=&quot;cpu0&quot;,mode=&quot;idle&quot;} 362812.7890625
# HELP node_load1 1m load average.
# TYPE node_load1 gauge
node_load1 3.0703125
&lt;/code&gt;
&lt;/pre&gt;
&lt;blockquote readability=&quot;14&quot;&gt;
&lt;p&gt;这是一种基于文本的格式规范，在Prometheus 2.0之前的版本还支持Protocol buffer规范。相比于Protocol buffer文本具有更好的可读性，以及跨平台性。Prometheus 2.0的版本也已经不再支持Protocol buffer。&lt;/p&gt;
&lt;p&gt;Exporter返回的样本数据，主要由三个部分组成：样本的一般注释信息（HELP），样本的类型注释信息（TYPE）和样本。Prometheus会对Exporter响应的内容逐行解析:&lt;/p&gt;
&lt;p&gt;如果当前行以# HELP开始，Prometheus将会按照以下规则对内容进行解析，得到当前的指标名称以及相应的说明信息:&lt;/p&gt;
&lt;/blockquote&gt;
&lt;pre&gt;
&lt;code class=&quot;language-shell&quot;&gt;# HELP &amp;lt;metrics_name&amp;gt; &amp;lt;doc_string&amp;gt;
&lt;/code&gt;
&lt;/pre&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;如果当前行以# TYPE开始，Prometheus会按照以下规则对内容进行解析，得到当前的指标名称以及指标类型:&lt;/p&gt;
&lt;/blockquote&gt;
&lt;pre&gt;
&lt;code class=&quot;language-shell&quot;&gt;# TYPE &amp;lt;metrics_name&amp;gt; &amp;lt;metrics_type&amp;gt;
&lt;/code&gt;
&lt;/pre&gt;
&lt;blockquote readability=&quot;7&quot;&gt;
&lt;p&gt;TYPE注释行必须出现在指标的第一个样本之前。如果没有明确的指标类型需要返回为untyped。 除了# 开头的所有行都会被视为是监控样本数据。 每一行样本需要满足以下格式规范:&lt;/p&gt;
&lt;/blockquote&gt;
&lt;pre&gt;
&lt;code class=&quot;language-shell&quot;&gt;metric_name [
  &quot;{&quot; label_name &quot;=&quot; `&quot;` label_value `&quot;` { &quot;,&quot; label_name &quot;=&quot; `&quot;` label_value `&quot;` } [ &quot;,&quot; ] &quot;}&quot;
] value [ timestamp ]
&lt;/code&gt;
&lt;/pre&gt;
&lt;blockquote readability=&quot;27&quot;&gt;
&lt;p&gt;其中metric_name和label_name必须遵循PromQL的格式规范要求。value是一个float格式的数据，timestamp的类型为int64（从1970-01-01 00:00:00以来的毫秒数），timestamp为可选默认为当前时间。具有相同metric_name的样本必须按照一个组的形式排列，并且每一行必须是唯一的指标名称和标签键值对组合。&lt;/p&gt;
&lt;p&gt;需要特别注意的是对于histogram和summary类型的样本。需要按照以下约定返回样本数据：&lt;/p&gt;
&lt;p&gt;1 . 类型为summary或者histogram的指标x，该指标所有样本的值的总和需要使用一个单独的x_sum指标表示&lt;/p&gt;
&lt;p&gt;2 . 类型为summary或者histogram的指标x，该指标所有样本的总数需要使用一个单独的x_count指标表示。&lt;/p&gt;
&lt;p&gt;3 . 对于类型为summary的指标x，其不同分位数quantile所代表的样本，需要使用单独的x{quantile=&quot;y&quot;}表示。&lt;/p&gt;
&lt;p&gt;4 . 对于类型histogram的指标x为了表示其样本的分布情况，每一个分布需要使用x_bucket{le=&quot;y&quot;}表示，其中y为当前分布的上位数。同时必须包含一个样本x_bucket{le=&quot;+Inf&quot;}，并且其样本值必须和x_count相同。&lt;/p&gt;
&lt;p&gt;5 . 对于histogram和summary的样本，必须按照分位数quantile和分布le的值的递增顺序排序。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;code&gt;以下是类型为histogram和summary的样本输出示例&lt;/code&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-shell&quot;&gt;# A histogram, which has a pretty complex representation in the text format:
# HELP http_request_duration_seconds A histogram of the request duration.
# TYPE http_request_duration_seconds histogram
http_request_duration_seconds_bucket{le=&quot;0.05&quot;} 24054
http_request_duration_seconds_bucket{le=&quot;0.1&quot;} 33444
http_request_duration_seconds_bucket{le=&quot;0.2&quot;} 100392
http_request_duration_seconds_bucket{le=&quot;+Inf&quot;} 144320
http_request_duration_seconds_sum 53423
http_request_duration_seconds_count 144320

# Finally a summary, which has a complex representation, too:
# HELP rpc_duration_seconds A summary of the RPC duration in seconds.
# TYPE rpc_duration_seconds summary
rpc_duration_seconds{quantile=&quot;0.01&quot;} 3102
rpc_duration_seconds{quantile=&quot;0.05&quot;} 3272
rpc_duration_seconds{quantile=&quot;0.5&quot;} 4773
rpc_duration_seconds_sum 1.7560473e+07
rpc_duration_seconds_count 2693
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;指定样式格式的版本&lt;/strong&gt;&lt;br/&gt;在Exporter响应的HTTP头信息中，可以通过Content-Type指定特定的规范版本，例如:&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-shell&quot;&gt;HTTP/1.1 200 OK
Content-Encoding: gzip
Content-Length: 2906
Content-Type: text/plain; version=0.0.4
Date: Sat, 17 Mar 2018 08:47:06 GMT
&lt;/code&gt;
&lt;/pre&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;其中version用于指定Text-based的格式版本，当没有指定版本的时候，默认使用最新格式规范的版本。同时HTTP响应头还需要指定压缩格式为gzip。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4 id=&quot;容器监控&quot;&gt;容器监控&lt;/h4&gt;
&lt;blockquote readability=&quot;9&quot;&gt;
&lt;p&gt;Docker是一个开源的应用容器引擎，让开发者可以打包他们的应用以及依赖包到一个可移植的容器中，然后发布到任何流行的Linux/Windows/Mac机器上。容器镜像正成为一个新的标准化软件交付方式。&lt;/p&gt;
&lt;p&gt;例如，可以通过一下命令快速在本地启动一个Nginx服务:&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h5 id=&quot;安装docker&quot;&gt;安装docker&lt;/h5&gt;
&lt;pre&gt;
&lt;code class=&quot;language-shell&quot;&gt;# 安装一些必要的系统工具
sudo yum install -y yum-utils device-mapper-persistent-data lvm2
# 添加软件源信息
# docker 官方源
sudo yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo

# 阿里云源
sudo yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo

sudo yum makecache fast

# CentOS7安装 Docker-ce
yum -y install docker-ce   


mkdir /etc/docker
vim /etc/docker/daemon.json
{
&quot;registry-mirrors&quot;: [&quot;https://registry.docker-cn.com&quot;]
}

# 启动Docker后台服务
systemctl start docker &amp;amp;&amp;amp; systemctl enable docker
systemctl daemon-reload                 # 守护进程重启

# 运行一个nginx做测试
docker run -itd nginx
&lt;/code&gt;
&lt;/pre&gt;
&lt;blockquote readability=&quot;7&quot;&gt;
&lt;p&gt;为了能够获取到Docker容器的运行状态，用户可以通过Docker的stats命令获取到当前主机上运行容器的统计信息，可以查看容器的CPU利用率、内存使用量、网络IO总量以及磁盘IO总量等信息。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;pre&gt;
&lt;code class=&quot;language-shell&quot;&gt;docker stats
CONTAINER           CPU %      MEM USAGE / LIMIT     MEM %      NET I/O         BLOCK I/O   PIDS
9a1648bec3b2        0.30%      196KiB / 3.855GiB     0.00%      828B / 0B       827kB / 0B  1
# 除了使用命令以外，用户还可以通过docker提供的http api查看容器的监控统计信息.
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;使用CAdvisor&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote readability=&quot;9&quot;&gt;
&lt;p&gt;CAdvisor是Google开源的一款用于展示和分析容器运行状态的可视化工具。通过在主机上运行CAdvisor用户可以轻松的获取到当前主机上容器的运行统计信息，并以图表的形式向用户展示。&lt;/p&gt;
&lt;p&gt;在本地运行CAdvisor也非常简单，直接运行一下命令即可:&lt;/p&gt;
&lt;/blockquote&gt;
&lt;pre&gt;
&lt;code class=&quot;language-shell&quot;&gt;docker run \
  --volume=/:/rootfs:ro \
  --volume=/var/run:/var/run:rw \
  --volume=/sys:/sys:ro \
  --volume=/var/lib/docker/:/var/lib/docker:ro \
  --publish=8080:8080 \
  --detach=true \
  --name=cadvisor \
  google/cadvisor:latest
# 通过访问http://localhost:8080可以查看，当前主机上容器的运行状态.
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1871335/202006/1871335-20200609235203408-1067862805.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;blockquote readability=&quot;10.391221374046&quot;&gt;
&lt;p&gt;CAdvisor是一个简单易用的工具，相比于使用Docker命令行工具，用户不用再登录到服务器中即可以可视化图表的形式查看主机上所有容器的运行状态。&lt;/p&gt;
&lt;p&gt;而在多主机的情况下，在所有节点上运行一个CAdvisor再通过各自的UI查看监控信息显然不太方便，同时CAdvisor默认只保存2分钟的监控数据。好消息是CAdvisor已经内置了对Prometheus的支持。访问&lt;a href=&quot;http://localhost:8080/metrics&quot;&gt;http://localhost:8080/metrics&lt;/a&gt;即可获取到标准的Prometheus监控样本输出:&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1871335/202006/1871335-20200609235219723-831836535.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;下面列举了一些CAdvisor中获取的典型监控指标&lt;/p&gt;
&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;指标名称&lt;/th&gt;
&lt;th&gt;类型&lt;/th&gt;
&lt;th&gt;含义&lt;/th&gt;
&lt;/tr&gt;&lt;/thead&gt;&lt;tbody readability=&quot;2&quot;&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td/&gt;
&lt;td&gt;gauge&lt;/td&gt;
&lt;td&gt;再过去10秒内容器CPU的平均负载&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;container_cpu_usage_seconds_total&lt;/td&gt;
&lt;td/&gt;
&lt;td/&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;指标名称&lt;/th&gt;
&lt;th&gt;类型&lt;/th&gt;
&lt;th&gt;含义&lt;/th&gt;
&lt;/tr&gt;&lt;/thead&gt;&lt;tbody readability=&quot;13&quot;&gt;&lt;tr readability=&quot;4&quot;&gt;&lt;td&gt;container_cpu_load_average_10s&lt;/td&gt;
&lt;td&gt;gauge&lt;/td&gt;
&lt;td&gt;过去10秒内容器CPU的平均负载&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;4&quot;&gt;&lt;td&gt;container_cpu_usage_seconds_total&lt;/td&gt;
&lt;td&gt;counter&lt;/td&gt;
&lt;td&gt;容器在每个CPU内核上的累积占用时间 (单位：秒)&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;4&quot;&gt;&lt;td&gt;container_cpu_system_seconds_total&lt;/td&gt;
&lt;td&gt;counter&lt;/td&gt;
&lt;td&gt;System CPU累积占用时间（单位：秒）&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;4&quot;&gt;&lt;td&gt;container_cpu_user_seconds_total&lt;/td&gt;
&lt;td&gt;counter&lt;/td&gt;
&lt;td&gt;User CPU累积占用时间（单位：秒）&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;container_fs_usge_bytes&lt;/td&gt;
&lt;td&gt;gauge&lt;/td&gt;
&lt;td&gt;容器中文件系统的使用量(单位：字节)&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;4&quot;&gt;&lt;td&gt;container_network_receive_bytes_total&lt;/td&gt;
&lt;td&gt;counter&lt;/td&gt;
&lt;td&gt;容器网络累计接受数据总量（单位: 字节）&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;4&quot;&gt;&lt;td&gt;container_network_transmit_bytes_total&lt;/td&gt;
&lt;td&gt;counter&lt;/td&gt;
&lt;td&gt;容器网络累计传输数据总量（单位: 字节）&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;h4 id=&quot;与prometheus集成&quot;&gt;与Prometheus集成&lt;/h4&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;修改/etc/prometheus/prometheus.yml，将cAdvisor添加监控数据采集任务目标当中：&lt;/p&gt;
&lt;/blockquote&gt;
&lt;pre&gt;
&lt;code class=&quot;language-shell&quot;&gt;  - job_name: 'docker'
    static_configs:
    - targets: ['172.19.0.27:8080']

systemctl restart prometheus
&lt;/code&gt;
&lt;/pre&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;启动Prometheus服务,可以在Prometheus UI中看到当前所有的Target状态:&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1871335/202006/1871335-20200609235235114-227927707.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;当能够正常采集到cAdvisor的样本数据后，可以通过一下表达式计算容器的CPU使用率.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;pre&gt;
&lt;code class=&quot;language-shell&quot;&gt;sum(irate(container_cpu_usage_seconds_total{image!=&quot;&quot;}[1m])) without (cpu)
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1871335/202006/1871335-20200609235244393-449787207.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;查询容器内存使用量（单位: 字节）&lt;/code&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-shell&quot;&gt;container_memory_usage_bytes{image!=&quot;&quot;}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1871335/202006/1871335-20200609235253940-1341566108.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;查询容器网络接收量速率（单位: 字节/秒）&lt;/code&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;sum(rate(container_network_receive_bytes_total{image!=&quot;&quot;}[1m])) without (interface)
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1871335/202006/1871335-20200609235304616-1285563355.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;查询容器网络传输量速率&lt;/code&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-shell&quot;&gt;sum(rate(container_network_transmit_bytes_total{image!=&quot;&quot;}[1m])) without (interface)
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1871335/202006/1871335-20200609235315098-627654719.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;查询容器文件系统读取速率&lt;/code&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-shell&quot;&gt;sum(rate(container_fs_reads_bytes_total{image!=&quot;&quot;}[1m])) without (device)

# 为了方便看出效果，我们使用dd命令
docker exec -it 628d /bin/bash
dd if=/dev/zero of=test bs=1M count=1000
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1871335/202006/1871335-20200609235323722-411596133.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;查询容器文件系统写入速率（单位: 字节/秒）&lt;/li&gt;
&lt;/ul&gt;&lt;pre&gt;
&lt;code&gt;sum(rate(container_fs_writes_bytes_total{image!=&quot;&quot;}[1m])) without (device)
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1871335/202006/1871335-20200609235337931-200328147.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h4 id=&quot;prometheus网络探测&quot;&gt;Prometheus网络探测&lt;/h4&gt;
&lt;blockquote readability=&quot;13&quot;&gt;
&lt;p&gt;接下来我们主要介绍Prometheus下如何进行白盒监控，我们之前监控主机的资源用量、容器的运行状态、数据库中间件的运行数据。 这些都是支持业务和服务的基础设施，通过白盒能够了解其内部的实际运行状态，通过对监控指标的观察能够预判可能出现的问题，从而对潜在的不确定因素进行优化。而从完整的监控逻辑的角度，除了大量的应用白盒监控以外，还应该添加适当的黑盒监控。&lt;br/&gt;黑盒监控即以用户的身份测试服务的外部可见性，常见的黑盒监控包括HTTP探针、TCP探针等用于检测站点或者服务的可访问性，以及访问效率等。&lt;/p&gt;
&lt;p&gt;黑盒监控相较于白盒监控最大的不同在于黑盒监控是以故障为导向当故障发生时，黑盒监控能快速发现故障，而白盒监控则侧重于主动发现或者预测潜在的问题。一个完善的监控目标是要能够从白盒的角度发现潜在问题，能够在黑盒的角度快速发现已经发生的问题。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1871335/202006/1871335-20200609235449812-1976063748.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h5 id=&quot;安装blackbox-exporter&quot;&gt;安装Blackbox Exporter&lt;/h5&gt;
&lt;blockquote readability=&quot;7&quot;&gt;
&lt;p&gt;Blackbox Exporter是Prometheus社区提供的官方黑盒监控解决方案，其允许用户通过：HTTP、HTTPS、DNS、TCP以及ICMP的方式对网络进行探测。用户可以直接使用go get命令获取Blackbox Exporter源码并生成本地可执行文件：&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h5 id=&quot;下载安装blackbox_exporter&quot;&gt;下载安装blackbox_exporter&lt;/h5&gt;
&lt;p&gt;&lt;code&gt;wget https://github.com/prometheus/blackbox_exporter/releases/download/v0.16.0/blackbox_exporter-0.16.0.linux-amd64.tar.gz&lt;/code&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-shell&quot;&gt;tar xvf blackbox_exporter-0.16.0.linux-amd64.tar.gz -C /usr/local/prometheus/
mv blackbox_exporter-0.16.0.linux-amd64/ blackbox_exporter
useradd prometheus
chown -R prometheus:prometheus /usr/local/prometheus/

vim /usr/lib/systemd/system/blackbox_exporter.service
[Unit]
Description=blackbox_exporter
After=network.target

[Service]
Type=simple
User=prometheus
ExecStart=/usr/local/prometheus/blackbox_exporter/blackbox_exporter --config.file=/usr/local/prometheus/blackbox_exporter/blackbox.yml
Restart=on-failure

[Install]
WantedBy=multi-user.target

systemctl enable blackbox_exporter.service
systemctl start blackbox_exporter.service
&lt;/code&gt;
&lt;/pre&gt;
&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;运行Blackbox Exporter时，需要用户提供探针的配置信息，这些配置信息可能是一些自定义的HTTP头信息，也可能是探测时需要的一些TSL配置，也可能是探针本身的验证行为。在Blackbox Exporter每一个探针配置称为一个module，并且以YAML配置文件的形式提供给Blackbox Exporter。 每一个module主要包含以下配置内容，包括探针类型（prober）、验证访问超时时间（timeout）、以及当前探针的具体配置项:&lt;/p&gt;
&lt;/blockquote&gt;
&lt;pre&gt;
&lt;code class=&quot;language-shell&quot;&gt;# 探针类型：http、 tcp、 dns、 icmp.
prober: &amp;lt;prober_string&amp;gt;
# 超时时间
[ timeout: &amp;lt;duration&amp;gt; ]
# 探针的详细配置，最多只能配置其中的一个
[ http: &amp;lt;http_probe&amp;gt; ]
[ tcp: &amp;lt;tcp_probe&amp;gt; ]
[ dns: &amp;lt;dns_probe&amp;gt; ]
[ icmp: &amp;lt;icmp_probe&amp;gt; ]
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;下面是一个简化的探针配置文件blockbox.yml，包含两个HTTP探针配置项&lt;/code&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;modules:
  http_2xx:
    prober: http
    http:
      method: GET
  http_post_2xx:
    prober: http
    http:
      method: POST
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;通过运行一下命令，并指定使用的探针设置文件启动Blockbox Exporter实例:&lt;/code&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-shell&quot;&gt;blackbox_exporter --config.file=/etc/prometheus/blackbox.yml
or
systemctl restart blackbox_exporter.service
&lt;/code&gt;
&lt;/pre&gt;
&lt;blockquote readability=&quot;7&quot;&gt;
&lt;p&gt;启动成功后，就可以通过访问http://172.19.0.27:9115/probe?module=http_2xx&amp;amp;target=baidu.com对baidu.com进行探测。这里通过在URL中提供module参数指定了当前使用的探针，target参数指定探测目标，探针的探测结果通过Metrics的形式返回：&lt;/p&gt;
&lt;/blockquote&gt;
&lt;pre&gt;
&lt;code class=&quot;language-shell&quot;&gt;# HELP probe_dns_lookup_time_seconds Returns the time taken for probe dns lookup in seconds
# TYPE probe_dns_lookup_time_seconds gauge
probe_dns_lookup_time_seconds 0.004359875
# HELP probe_duration_seconds Returns how long the probe took to complete in seconds
# TYPE probe_duration_seconds gauge
probe_duration_seconds 0.046153996
# HELP probe_failed_due_to_regex Indicates if probe failed due to regex
# TYPE probe_failed_due_to_regex gauge
probe_failed_due_to_regex 0
# HELP probe_http_content_length Length of http content response
# TYPE probe_http_content_length gauge
probe_http_content_length 81
# HELP probe_http_duration_seconds Duration of http request by phase, summed over all redirects
# TYPE probe_http_duration_seconds gauge
probe_http_duration_seconds{phase=&quot;connect&quot;} 0.00105657
probe_http_duration_seconds{phase=&quot;processing&quot;} 0.039457402
probe_http_duration_seconds{phase=&quot;resolve&quot;} 0.004359875
probe_http_duration_seconds{phase=&quot;tls&quot;} 0
probe_http_duration_seconds{phase=&quot;transfer&quot;} 0.000337184
# HELP probe_http_last_modified_timestamp_seconds Returns the Last-Modified HTTP \
response header in unixtime
# TYPE probe_http_last_modified_timestamp_seconds gauge
probe_http_last_modified_timestamp_seconds 1.26330408e+09
# HELP probe_http_redirects The number of redirects
# TYPE probe_http_redirects gauge
probe_http_redirects 0
# HELP probe_http_ssl Indicates if SSL was used for the final redirect
# TYPE probe_http_ssl gauge
probe_http_ssl 0
# HELP probe_http_status_code Response HTTP status code
# TYPE probe_http_status_code gauge
probe_http_status_code 200
# HELP probe_http_uncompressed_body_length Length of uncompressed response body
# TYPE probe_http_uncompressed_body_length gauge
probe_http_uncompressed_body_length 81
# HELP probe_http_version Returns the version of HTTP of the probe response
# TYPE probe_http_version gauge
probe_http_version 1.1
# HELP probe_ip_protocol Specifies whether probe ip protocol is IP4 or IP6
# TYPE probe_ip_protocol gauge
probe_ip_protocol 4
# HELP probe_success Displays whether or not the probe was a success
# TYPE probe_success gauge
probe_success 1
&lt;/code&gt;
&lt;/pre&gt;
&lt;blockquote readability=&quot;7&quot;&gt;
&lt;p&gt;从返回的样本中，用户可以获取站点的DNS解析耗时，站点响应时间，HTTP响应状态码等等和站点访问质量相关的监控指标，从而帮助管理员主动的发现故障和问题.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4 id=&quot;prometheus集成&quot;&gt;Prometheus集成&lt;/h4&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;接下来，只需要在Prometheus下配置对Blockbox Exporter实例的采集任务即可、最直观的配置方式.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;pre&gt;
&lt;code class=&quot;language-shell&quot;&gt;  - job_name: 'baidu_http2xx_probe'
    params:
      module:
      - http_2xx
      target:
      - baidu.com
    metrics_path: /probe
    static_configs:
    - targets: ['172.19.0.27:9115']

  - job_name: 'prometheus_http2xx_probe'
    params:
      module:
      - http_2xx
      target:
      - prometheus.io
    metrics_path: /probe
    static_configs:
    - targets: ['172.19.0.27:9115']

systemctl restart prometheus
&lt;/code&gt;
&lt;/pre&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;这里分别配置了名为baidu_http2x_probe和prometheus_http2xx_probe的采集任务，并且通过params指定使用的探针（module）以及探测目标（target）.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1871335/202006/1871335-20200609235432294-1876810387.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;blockquote readability=&quot;7&quot;&gt;
&lt;p&gt;那问题就来了，假如我们有N个目标站点且都需要M种探测方式，那么Prometheus中将包含N * M个采集任务，从配置管理的角度来说显然是不可接受的。这里我们也可以采用Relabling的方式对这些配置进行简化，配置方式如下：&lt;/p&gt;
&lt;/blockquote&gt;
&lt;pre&gt;
&lt;code class=&quot;language-shell&quot;&gt;  - job_name: 'blackbox'
    metrics_path: /probe
    params:
      module: [http_2xx]
    static_configs:
      - targets:
        - http://prometheus.io    # Target to probe with http.
        - https://prometheus.io   # Target to probe with https.
        - http://example.com:8080 # Target to probe with http on port 8080.
    relabel_configs:
      - source_labels: [__address__]
        target_label: __param_target
      - source_labels: [__param_target]
        target_label: instance
      - target_label: __address__
        replacement: 172.19.0.27:9115
&lt;/code&gt;
&lt;/pre&gt;
&lt;blockquote readability=&quot;7&quot;&gt;
&lt;p&gt;这里针对每一个探针服务（如http_2xx）定义一个采集任务，并且直接将任务的采集目标定义为我们需要探测的站点，在采集样本数据之前通过relabel_configs对采集任务进行动态配置.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;pre&gt;
&lt;code class=&quot;language-shell&quot;&gt;* 第一步， 根据Target实例的地址，写入__param_target标签中，__param_&amp;lt;name&amp;gt;形式的标签来表示,
        # 在采集任务时会在请求目标地址中添加&amp;lt;name&amp;gt;参数，等同于params的设置.
* 第二步,  获取__param_target的值，并覆写到instance标签中.
* 第三步,  覆写Target实例的__address__标签值为BlockBox Exporter实例的访问地址.
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1871335/202006/1871335-20200609235414463-1311969316.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h4 id=&quot;http探针&quot;&gt;HTTP探针&lt;/h4&gt;
&lt;blockquote readability=&quot;11&quot;&gt;
&lt;p&gt;HTTP探针是进行黑盒监控时最常用的探针之一，通过HTTP探针能够网站或者HTTP服务建立有效的监控，包括其本身的可用性，以及用户体验相关的如响应时间等等。除了能够在服务出现异常的时候及时报警，还能帮助系统管理员分析和优化网站体验。&lt;/p&gt;
&lt;p&gt;Blockbox Exporter中所有的探针均是以Module的信息进行配置。如下所示，配置了一个最简单的HTTP探针:&lt;/p&gt;
&lt;/blockquote&gt;
&lt;pre&gt;
&lt;code class=&quot;language-shell&quot;&gt;modules:
  http_2xx_example:
    prober: http
    http:
&lt;/code&gt;
&lt;/pre&gt;
&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;通过prober配置项指定探针类型。配置项http用于自定义探针的探测方式，这里有没对http配置项添加任何配置，表示完全使用HTTP探针的默认配置，该探针将使用HTTP GET的方式对目标服务进行探测，并且验证返回状态码是否为2XX，是则表示验证成功，否则失败。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h5 id=&quot;自定义http请求&quot;&gt;&lt;strong&gt;自定义HTTP请求&lt;/strong&gt;&lt;/h5&gt;
&lt;blockquote readability=&quot;12&quot;&gt;
&lt;p&gt;HTTP服务通常会以不同的形式对外展现，有些可能就是一些简单的网页，而有些则可能是一些基于REST的API服务。 对于不同类型的HTTP的探测需要管理员能够对HTTP探针的行为进行更多的自定义设置，包括：HTTP请求方法、HTTP头信息、请求参数等。对于某些启用了安全认证的服务还需要能够对HTTP探测设置相应的Auth支持。对于HTTPS类型的服务还需要能够对证书进行自定义设置。&lt;/p&gt;
&lt;p&gt;如下所示，这里通过method定义了探测时使用的请求方法，对于一些需要请求参数的服务，还可以通过headers定义相关的请求头信息，使用body定义请求内容：&lt;/p&gt;
&lt;/blockquote&gt;
&lt;pre&gt;
&lt;code class=&quot;language-shell&quot;&gt;http_post_2xx:
    prober: http
    timeout: 5s
    http:
      method: POST
      headers:
        Content-Type: application/json
      body: '{}'
&lt;/code&gt;
&lt;/pre&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;如果HTTP服务启用了安全认证，Blockbox Exporter内置了对basic_auth的支持，可以直接设置相关的认证信息即可：&lt;/p&gt;
&lt;/blockquote&gt;
&lt;pre&gt;
&lt;code class=&quot;language-shell&quot;&gt;http_basic_auth_example:
    prober: http
    timeout: 5s
    http:
      method: POST
      headers:
        Host: &quot;login.example.com&quot;
      basic_auth:
        username: &quot;username&quot;
        password: &quot;mysecret&quot;
&lt;/code&gt;
&lt;/pre&gt;
&lt;blockquote readability=&quot;9&quot;&gt;
&lt;p&gt;对于使用了Bear Token的服务也可以通过bearer_token配置项直接指定令牌字符串，或者通过bearer_token_file指定令牌文件。&lt;/p&gt;
&lt;p&gt;对于一些启用了HTTPS的服务，但是需要自定义证书的服务，可以通过tls_config指定相关的证书信息：&lt;/p&gt;
&lt;/blockquote&gt;
&lt;pre&gt;
&lt;code class=&quot;language-shell&quot;&gt; http_custom_ca_example:
    prober: http
    http:
      method: GET
      tls_config:
        ca_file: &quot;/certs/my_cert.crt&quot;
&lt;/code&gt;
&lt;/pre&gt;
&lt;ul&gt;&lt;li&gt;自定义探针行为&lt;/li&gt;
&lt;li&gt;在默认情况下HTTP探针只会对HTTP返回状态码进行校验，如果状态码为2XX（200 &amp;lt;= StatusCode &amp;lt; 300）则表示探测成功，并且探针返回的指标probe_success值为1。&lt;/li&gt;
&lt;li&gt;如果用户需要指定HTTP返回状态码，或者对HTTP版本有特殊要求，如下所示，可以使用valid_http_versions和valid_status_codes进行定义：&lt;/li&gt;
&lt;/ul&gt;&lt;pre&gt;
&lt;code class=&quot;language-shell&quot;&gt;  http_2xx_example:
    prober: http
    timeout: 5s
    http:
      valid_http_versions: [&quot;HTTP/1.1&quot;, &quot;HTTP/2&quot;]
      valid_status_codes: []
&lt;/code&gt;
&lt;/pre&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;默认情况下，Blockbox返回的样本数据中也会包含指标probe_http_ssl，用于表明当前探针是否使用了SSL:&lt;/p&gt;
&lt;/blockquote&gt;
&lt;pre&gt;
&lt;code&gt;# HELP probe_http_ssl Indicates if SSL was used for the final redirect
# TYPE probe_http_ssl gauge
probe_http_ssl 0
&lt;/code&gt;
&lt;/pre&gt;
&lt;blockquote readability=&quot;7&quot;&gt;
&lt;p&gt;而如果用户对于HTTP服务是否启用SSL有强制的标准。则可以使用fail_if_ssl和fail_if_not_ssl进行配置。fail_if_ssl为true时，表示如果站点启用了SSL则探针失败，反之成功。fail_if_not_ssl刚好相反。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;pre&gt;
&lt;code class=&quot;language-shell&quot;&gt;  http_2xx_example:
    prober: http
    timeout: 5s
    http:
      valid_status_codes: []
      method: GET
      no_follow_redirects: false
      fail_if_ssl: false
      fail_if_not_ssl: false
&lt;/code&gt;
&lt;/pre&gt;
&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;除了基于HTTP状态码，HTTP协议版本以及是否启用SSL作为控制探针探测行为成功与否的标准以外，还可以匹配HTTP服务的响应内容。使用fail_if_matches_regexp和fail_if_not_matches_regexp用户可以定义一组正则表达式，用于验证HTTP返回内容是否符合或者不符合正则表达式的内容。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;pre&gt;
&lt;code class=&quot;language-shell&quot;&gt;  http_2xx_example:
    prober: http
    timeout: 5s
    http:
      method: GET
      fail_if_matches_regexp:
        - &quot;Could not connect to database&quot;
      fail_if_not_matches_regexp:
        - &quot;Download the latest version here&quot;
&lt;/code&gt;
&lt;/pre&gt;
&lt;blockquote readability=&quot;7&quot;&gt;
&lt;p&gt;最后需要提醒的时，默认情况下HTTP探针会走IPV6的协议。 在大多数情况下，可以使用preferred_ip_protocol=ip4强制通过IPV4的方式进行探测。在Bloackbox响应的监控样本中，也会通过指标probe_ip_protocol，表明当前的协议使用情况:&lt;/p&gt;
&lt;/blockquote&gt;
&lt;pre&gt;
&lt;code class=&quot;language-shell&quot;&gt;# HELP probe_ip_protocol Specifies whether probe ip protocol is IP4 or IP6
# TYPE probe_ip_protocol gauge
probe_ip_protocol 6
&lt;/code&gt;
&lt;/pre&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;除了支持对HTTP协议进行网络探测以外，Blackbox还支持对TCP、DNS、ICMP等其他网络协议![]&lt;/p&gt;
&lt;/blockquote&gt;
</description>
<pubDate>Tue, 09 Jun 2020 15:55:00 +0000</pubDate>
<dc:creator>you-men</dc:creator>
<og:description>Eeporter是什么及来源？ 是什么? 广义上讲所有可以向Prometheus提供监控样本数据的程序都可以被称为一个Exporter。而Exporter的一个实例称为target，如下所示，Prom</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/you-men/p/13081972.html</dc:identifier>
</item>
<item>
<title>一行代码引来的安全漏洞就让我们丢失了整个服务器的控制权 - 程序猿石头</title>
<link>http://www.cnblogs.com/leitang/p/13081693.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/leitang/p/13081693.html</guid>
<description>&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;之前在某厂的某次项目开发中，项目组同学设计和实现了一个“引以为傲”，额，有点扩张，不过自认为还说得过去的 feature，结果临上线前被啪啪打脸，因为实现过程中因为&lt;strong&gt;一行代码&lt;/strong&gt;（没有标题党，真的是一行代码）带来的安全漏洞让我们丢失了整个服务器控制权（测试环境）。多亏了上线之前有公司安全团队的人会对代码进行扫描，才让这个漏洞被扼杀在摇篮里。&lt;/p&gt;
&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;下面我们就一起来看看这个事故，啊，不对，是故事。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://www.tanglei.name/resources/a-security-vulnerability-of-spring-validator/gif-0.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span class=&quot;prefix&quot;&gt;&lt;span class=&quot;content&quot;&gt;背景说明&lt;/span&gt;&lt;/span&gt;&lt;/h2&gt;
&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我们的项目是一个面向全球用户的 Web 项目，用 SpringBoot 开发。在项目开发过程中，离不开各种异常信息的处理，比如表单提交参数不符合预期，业务逻辑的处理时离不开各种异常信息（例如网络抖动等）的处理。于是利用 SpringBoot 各种现成的组件支持，设计了一个统一的异常信息处理组件，统一管理各种业务流程中可能出现的错误码和错误信息，通过国际化的资源配置文件进行统一输出给用户。&lt;/p&gt;
&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span class=&quot;prefix&quot;&gt;&lt;span class=&quot;content&quot;&gt;统一错误信息配置管理&lt;/span&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我们的用户遍布全球，为了给各个国家用户比较好的体验会进行不同的翻译。具体而言，实现的效果如下，为了方便理解，以“找回登录密码”这样一个业务场景来进行阐述说明。&lt;/p&gt;
&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;假设找回密码时，需要用户输入手机或者邮箱验证码，假设这个时候用户输入的验证码通过后台数据库（可能是Redis）对比发现已经过期。在业务代码中，只需要简单的 &lt;code&gt;throw new ErrorCodeException(ErrorCodes.AUTHCODE_EXPIRED)&lt;/code&gt; 即可。具体而言，针对不同国家地区不同的语言看到的效果不一样：&lt;/p&gt;
&lt;ul data-tool=&quot;mdnice编辑器&quot;&gt;&lt;li&gt;中文用户看到的提示就是“您输入的验证码已过期，请重新获取”；&lt;/li&gt;
&lt;li&gt;欧美用户看到的效果是“The verification code you input is expired, ...”；&lt;/li&gt;
&lt;li&gt;德国用户看到的是：“Der von Ihnen eingegebene Verifizierungscode ist abgelaufen, bitte wiederholen” 。（我瞎找的翻译，不一定准）&lt;/li&gt;
&lt;li&gt;……&lt;/li&gt;
&lt;/ul&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span class=&quot;prefix&quot;&gt;&lt;span class=&quot;content&quot;&gt;统一错误信息配置管理代码实现&lt;/span&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;关键信息其实就在于一个 GlobalExceptionHandler，对所有Controller 入口进行 AOP 拦截，根据不同的错误信息，获取相应资源文件配置的 key，并从语言资源文件中读取不同国家的错误翻译信息。&lt;/p&gt;
&lt;pre class=&quot;custom&quot; data-tool=&quot;mdnice编辑器&quot;&gt;
&lt;code class=&quot;hljs&quot;&gt;&lt;span class=&quot;hljs-meta&quot;&gt;@ControllerAdvice
&lt;span class=&quot;hljs-keyword&quot;&gt;public &lt;span class=&quot;hljs-class&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;class &lt;span class=&quot;hljs-title&quot;&gt;GlobalExceptionHandler {

    &lt;span class=&quot;hljs-meta&quot;&gt;@ExceptionHandler(BadRequestException.class)
    &lt;span class=&quot;hljs-meta&quot;&gt;@ResponseBody
    &lt;span class=&quot;hljs-function&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;public ResponseEntity &lt;span class=&quot;hljs-title&quot;&gt;handle&lt;span class=&quot;hljs-params&quot;&gt;(HttpServletRequest request, BadRequestException e){
        String i18message = getI18nMessage(e.getKey(), request);
        &lt;span class=&quot;hljs-keyword&quot;&gt;return ResponseEntity.status(HttpStatus.BAD_REQUEST).body(Response.error(e.getCode(), i18message));
    }
    
    &lt;span class=&quot;hljs-meta&quot;&gt;@ExceptionHandler(ErrorCodeException.class)
    &lt;span class=&quot;hljs-meta&quot;&gt;@ResponseBody
    &lt;span class=&quot;hljs-function&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;public ResponseEntity &lt;span class=&quot;hljs-title&quot;&gt;handle&lt;span class=&quot;hljs-params&quot;&gt;(HttpServletRequest request, ErrorCodeException e){
        String i18message = getI18nMessage(e.getKey(), request);
        &lt;span class=&quot;hljs-keyword&quot;&gt;return ResponseEntity.status(HttpStatus.OK).body(Response.error(e.getCode(), i18message));
    }
}
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;img src=&quot;https://www.tanglei.name/resources/custom-validator-and-i18n-error-message-in-springboot/i18n-tree.png&quot; alt=&quot;不同语言的资源文件示例&quot;/&gt;不同语言的资源文件示例&lt;/p&gt;
&lt;pre class=&quot;custom&quot; data-tool=&quot;mdnice编辑器&quot;&gt;
&lt;code class=&quot;hljs&quot;&gt;&lt;span class=&quot;hljs-function&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;private String &lt;span class=&quot;hljs-title&quot;&gt;getI18nMessage&lt;span class=&quot;hljs-params&quot;&gt;(String key, HttpServletRequest request) {
   &lt;span class=&quot;hljs-keyword&quot;&gt;try {
       &lt;span class=&quot;hljs-keyword&quot;&gt;return messageSource.getMessage(key, &lt;span class=&quot;hljs-keyword&quot;&gt;null, LanguaggeUtils.currentLocale(request));
   } &lt;span class=&quot;hljs-keyword&quot;&gt;catch (Exception e) {
       &lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;详细代码实现可以参考本人之前写的这篇文章&lt;a href=&quot;https://www.cnblogs.com/blog/custom-validator-and-i18n-error-message-in-springboot.html&quot;&gt;一文教你实现 SpringBoot 中的自定义 Validator 和错误信息国际化配置&lt;/a&gt;，上面有附完整的代码实现。&lt;/p&gt;
&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span class=&quot;prefix&quot;&gt;&lt;span class=&quot;content&quot;&gt;基于注解的表单校验（含自定义注解）&lt;/span&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;还有一种常见的业务场景就是后端接口需要对用户提交的表单进行校验。以“注册用户”这样的场景举例说明， 注册用户时，往往会提交昵称，性别，邮箱等信息进行注册，简单起见，就以这 3 个属性为例。&lt;/p&gt;
&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;定义的表单如下：&lt;/p&gt;
&lt;pre class=&quot;custom&quot; data-tool=&quot;mdnice编辑器&quot;&gt;
&lt;code class=&quot;hljs&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;public &lt;span class=&quot;hljs-class&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;class &lt;span class=&quot;hljs-title&quot;&gt;UserRegForm {
 &lt;span class=&quot;hljs-keyword&quot;&gt;private String nickname;
 &lt;span class=&quot;hljs-keyword&quot;&gt;private String gender;
 &lt;span class=&quot;hljs-keyword&quot;&gt;private String email;
}
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;对于表单的约束，我们有：&lt;/p&gt;
&lt;ul data-tool=&quot;mdnice编辑器&quot;&gt;&lt;li&gt;昵称字段：“nickname” 必填，长度必须是 6 到 20 位；&lt;/li&gt;
&lt;li&gt;性别字段：“gender” 可选，如果填了，就必须是“Male/Female/Other/”中的一种。说啥，除了男女还有其他？对，是的。毕竟全球用户嘛，你去看看非死不可，还有更多。&lt;/li&gt;
&lt;li&gt;邮箱： “email”，必填，必须满足邮箱格式。&lt;/li&gt;
&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;对于以上约束，我们只需要在对应的字段上添加如下注解即可。&lt;/p&gt;
&lt;pre class=&quot;custom&quot; data-tool=&quot;mdnice编辑器&quot;&gt;
&lt;code class=&quot;hljs&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;public &lt;span class=&quot;hljs-class&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;class &lt;span class=&quot;hljs-title&quot;&gt;UserRegForm {
 &lt;span class=&quot;hljs-meta&quot;&gt;@Length(min = &lt;span class=&quot;hljs-number&quot;&gt;6, max = &lt;span class=&quot;hljs-number&quot;&gt;20, message = &lt;span class=&quot;hljs-string&quot;&gt;&quot;validate.userRegForm.nickname&quot;)
 &lt;span class=&quot;hljs-keyword&quot;&gt;private String nickname;

 &lt;span class=&quot;hljs-meta&quot;&gt;@Gender(message=&lt;span class=&quot;hljs-string&quot;&gt;&quot;validate.userRegForm.gender&quot;)
 &lt;span class=&quot;hljs-keyword&quot;&gt;private String gender;

 &lt;span class=&quot;hljs-meta&quot;&gt;@NotNull
 &lt;span class=&quot;hljs-meta&quot;&gt;@Email(message=&lt;span class=&quot;hljs-string&quot;&gt;&quot;validate.userRegForm.email&quot;)
 &lt;span class=&quot;hljs-keyword&quot;&gt;private String email;
}
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;然后在各个语言资源文件中配置好相应的错误信息提示即可。其中， &lt;code&gt;@Gender&lt;/code&gt; 就是一个自定义的注解。&lt;/p&gt;
&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span class=&quot;prefix&quot;&gt;&lt;span class=&quot;content&quot;&gt;基于含自定义注解的表单校验关键代码&lt;/span&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;自定义注解的实现主要的其实就是一个自定义注解的定义以及一个校验逻辑。 例如定义一个自定义注解 &lt;code&gt;CustomParam&lt;/code&gt;：&lt;/p&gt;
&lt;pre class=&quot;custom&quot; data-tool=&quot;mdnice编辑器&quot;&gt;
&lt;code class=&quot;hljs&quot;&gt;&lt;span class=&quot;hljs-meta&quot;&gt;@Documented
&lt;span class=&quot;hljs-meta&quot;&gt;@Constraint(validatedBy = CustomValidator.class)
&lt;span class=&quot;hljs-meta&quot;&gt;@Target({FIELD, METHOD, PARAMETER, ANNOTATION_TYPE})
&lt;span class=&quot;hljs-meta&quot;&gt;@Retention(RetentionPolicy.RUNTIME)
&lt;span class=&quot;hljs-keyword&quot;&gt;public &lt;span class=&quot;hljs-meta&quot;&gt;@interface CustomParam {
    &lt;span class=&quot;hljs-function&quot;&gt;String &lt;span class=&quot;hljs-title&quot;&gt;message&lt;span class=&quot;hljs-params&quot;&gt;() &lt;span class=&quot;hljs-keyword&quot;&gt;default &quot;name.tanglei.www.validator.CustomArray.defaultMessage&quot;;

    Class&amp;lt;?&amp;gt;[] groups() &lt;span class=&quot;hljs-keyword&quot;&gt;default {};
    Class&amp;lt;? extends Payload&amp;gt;[] payload() &lt;span class=&quot;hljs-keyword&quot;&gt;default { };

    &lt;span class=&quot;hljs-meta&quot;&gt;@Documented
    &lt;span class=&quot;hljs-meta&quot;&gt;@Retention(RetentionPolicy.RUNTIME)
    &lt;span class=&quot;hljs-meta&quot;&gt;@Target({FIELD, METHOD, PARAMETER, ANNOTATION_TYPE})
    &lt;span class=&quot;hljs-meta&quot;&gt;@interface List {
        CustomParam[] value();
    }
}
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;校验逻辑的实现 &lt;code&gt;CustomValidator&lt;/code&gt;：&lt;/p&gt;
&lt;pre class=&quot;custom&quot; data-tool=&quot;mdnice编辑器&quot;&gt;
&lt;code class=&quot;hljs&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;public &lt;span class=&quot;hljs-class&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;class &lt;span class=&quot;hljs-title&quot;&gt;CustomValidator &lt;span class=&quot;hljs-keyword&quot;&gt;implements &lt;span class=&quot;hljs-title&quot;&gt;ConstraintValidator&amp;lt;&lt;span class=&quot;hljs-title&quot;&gt;CustomParam, &lt;span class=&quot;hljs-title&quot;&gt;String&amp;gt; {
    &lt;span class=&quot;hljs-meta&quot;&gt;@Override
    &lt;span class=&quot;hljs-function&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;public &lt;span class=&quot;hljs-keyword&quot;&gt;boolean &lt;span class=&quot;hljs-title&quot;&gt;isValid&lt;span class=&quot;hljs-params&quot;&gt;(String s, ConstraintValidatorContext constraintValidatorContext) {
        &lt;span class=&quot;hljs-keyword&quot;&gt;if (&lt;span class=&quot;hljs-keyword&quot;&gt;null == s || s.isEmpty()) {
            &lt;span class=&quot;hljs-keyword&quot;&gt;return &lt;span class=&quot;hljs-keyword&quot;&gt;true;
        }
        &lt;span class=&quot;hljs-keyword&quot;&gt;if (s.equals(&lt;span class=&quot;hljs-string&quot;&gt;&quot;tanglei&quot;)) {
            &lt;span class=&quot;hljs-keyword&quot;&gt;return &lt;span class=&quot;hljs-keyword&quot;&gt;true;
        } &lt;span class=&quot;hljs-keyword&quot;&gt;else {
            error(constraintValidatorContext, &lt;span class=&quot;hljs-string&quot;&gt;&quot;Invalid params: &quot; + s);
            &lt;span class=&quot;hljs-keyword&quot;&gt;return &lt;span class=&quot;hljs-keyword&quot;&gt;false;
        }
    }

    &lt;span class=&quot;hljs-meta&quot;&gt;@Override
    &lt;span class=&quot;hljs-function&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;public &lt;span class=&quot;hljs-keyword&quot;&gt;void &lt;span class=&quot;hljs-title&quot;&gt;initialize&lt;span class=&quot;hljs-params&quot;&gt;(CustomParam constraintAnnotation) {
    }

    &lt;span class=&quot;hljs-function&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;private &lt;span class=&quot;hljs-keyword&quot;&gt;static &lt;span class=&quot;hljs-keyword&quot;&gt;void &lt;span class=&quot;hljs-title&quot;&gt;error&lt;span class=&quot;hljs-params&quot;&gt;(ConstraintValidatorContext context, String message) {
        context.disableDefaultConstraintViolation();
        context.buildConstraintViolationWithTemplate(message).addConstraintViolation();
    }
}
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;上面例子只为了阐述说明问题，其中校验逻辑没有实际意义，这样，如果输入参数不满足条件，就会明确提示用户输入的哪个参数不满足条件。例如输入参数 &lt;code&gt;xx&lt;/code&gt;，则会直接提示：&lt;code&gt;Invalid params: xx&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://www.tanglei.name/resources/custom-validator-and-i18n-error-message-in-springboot/validator-bug.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这个跟第一部分的处理方式类似，因为现有的 validator 组件实现中，如果违反相应的约束也是一种抛异常的方式实现的，因此只需要在上述的 &lt;code&gt;GlobalExceptionHandler&lt;/code&gt;中添加相应的异常信息即可，这里就不详述了。 这不是本文的重点，这里就不详细阐述了。 详细代码实现可以参考本人之前写的这篇文章&lt;a href=&quot;https://www.cnblogs.com/blog/custom-validator-and-i18n-error-message-in-springboot.html&quot;&gt;一文教你实现 SpringBoot 中的自定义 Validator 和错误信息国际化配置&lt;/a&gt;，上面有附完整的代码实现。&lt;/p&gt;
&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span class=&quot;prefix&quot;&gt;&lt;span class=&quot;content&quot;&gt;场景重现&lt;/span&gt;&lt;/span&gt;&lt;/h2&gt;
&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;一切都显得很完美，直到上线前代码提交至安全团队扫描，就被“啪啪打脸”，扫描报告反馈了一个严重的安全漏洞。而这个安全漏洞，属于很高危的远程代码执行漏洞。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://www.tanglei.name/resources/a-security-vulnerability-of-spring-validator/gif-1.gif&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;用前文提到的自定义 Validator，输入的参数用： “1+1=${1+1}”，看看效果：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://www.tanglei.name/resources/a-security-vulnerability-of-spring-validator/security-bug-calc-4wx.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;太 TM 神奇了，居然帮我运算出来了，返回 &lt;code&gt;&quot;message&quot;: &quot;Invalid params: 1+1=2&quot;&lt;/code&gt;。&lt;/p&gt;
&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;问题就出现在实现自定义注解进行校验的这行代码（如下图所示）：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://www.cnblogs.com/resources/a-security-vulnerability-of-spring-validator/security-bug-line-4wx.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;其实，最开始的时候，这里直接返回了“Invalid params”，当初为了更好的用户体验，要明确告诉用户哪个参数没有通过校验，因此在输出的提示上加上了用户输入的字段，也就是上面的&lt;code&gt;&quot;Invalid params: &quot; + s&lt;/code&gt;，没想到，这闯了大祸了（回过头来想，感觉这里没必要这么详细啊，因为前端已经有相应的校验了，正常情况下回拦住，针对不守规矩的用非常规手段来的接口请求，直接返回校验不通过就行了，毕竟不是对外提供的 OpenAPI 服务）。&lt;/p&gt;
&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;仔细看，这个方法实际上是 &lt;code&gt;ConstraintValidatorContext&lt;/code&gt;这个接口中声明的，看方法名字其实能知道输入参数是一个字符串模板，内部会进行解析替换的（这其实也符合“见名知意”的良好编程习惯）。（教训：&lt;strong&gt;大家应该把握好自己写的每一行代码背后实际在做什么&lt;/strong&gt;。）&lt;/p&gt;
&lt;pre class=&quot;custom&quot; data-tool=&quot;mdnice编辑器&quot;&gt;
&lt;code class=&quot;hljs&quot;/&gt;
&lt;/pre&gt;
&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这个 case，源码调试进去之后，就能跟踪到执行翻译阶段，在如下方法中： &lt;code&gt;org.hibernate.validator.messageinterpolation.AbstractMessageInterpolator.interpolateMessage&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://www.cnblogs.com/resources/a-security-vulnerability-of-spring-validator/security-bug-interpolate-4wx.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;再往后，就是表达式求值了。 &lt;img src=&quot;https://www.cnblogs.com/resources/a-security-vulnerability-of-spring-validator/security-bug-plus11-4wx.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span class=&quot;prefix&quot;&gt;&lt;span class=&quot;content&quot;&gt;以为就这样就完了吗？&lt;/span&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;https://www.tanglei.name/resources/a-security-vulnerability-of-spring-validator/gif-2.jpeg&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;刚开始感觉，能帮忙算简单的运算规则也就完了吧，你还能把我怎么样？其实这个相当于暴露了一个入口，支持用户输入任意 EL 表达式进行执行。网上通过关键字 “SpEL表达式注入漏洞” 找找，就能发现事情并没有想象中那么简单。&lt;/p&gt;
&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我们构造恰当的 EL 表达式（注意各种转义，下文的输入参数相对比较明显在做什么了，实际上还有更多黑科技，比如各种二进制转义编码啊等等），就能直接执行输入代码，例如：可以直接执行命令，“ls -al”， 返回了一个 UNIXProcess 实例，命令已经被执行过了。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://www.tanglei.name/resources/a-security-vulnerability-of-spring-validator/security-bug-run-process-4wx.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;比如，我们执行个打开计算器的命令，搞个计算器玩玩~&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://www.tanglei.name/resources/a-security-vulnerability-of-spring-validator/security-bug-run-open-calc-4wx.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我录制了一个动图，来个演示可能更生动一些。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://www.tanglei.name/resources/a-security-vulnerability-of-spring-validator/spel-bug-demo-0.gif&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这还得了吗？这相当于提供了一个 webshell 的功能呀，你看想运行啥命令就能运行啥命令，例如 ping 本人博客地址（&lt;code&gt;ping www.tanglei.name&lt;/code&gt;），下面动图演示一下整个过程（从运行 ping 到 kill ping）。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://www.tanglei.name/resources/a-security-vulnerability-of-spring-validator/spel-demo-ping.gif&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我录制了一个视频，点击&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzI3OTUzMzcwNw==&amp;amp;mid=100001493&amp;amp;idx=1&amp;amp;sn=d8d2374d8afa76e55bd37650c7ccde45&amp;amp;chksm=6b4707315c308e273f4eb62799c65677d849104125bb6e7a56fbded981554fb92e97c289804e#rd&quot;&gt;这里&lt;/a&gt;可以访问。&lt;/p&gt;
&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;岂不是直接创建一个用户，然后远程登录就可以了。后果很严重啊，别人想干嘛就干嘛了。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://www.tanglei.name/resources/a-security-vulnerability-of-spring-validator/gif-3.gif&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我们跟踪下对应的代码，看看内部实现，就会“恍然大悟”了。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://www.tanglei.name/resources/a-security-vulnerability-of-spring-validator/security-bug-el-express-4wx.png&quot; alt=&quot;&quot;/&gt;&lt;img src=&quot;https://www.tanglei.name/resources/a-security-vulnerability-of-spring-validator/security-bug-el-express-run-4wx.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span class=&quot;prefix&quot;&gt;&lt;span class=&quot;content&quot;&gt;经验教训&lt;/span&gt;&lt;/span&gt;&lt;/h2&gt;
&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;幸亏这个漏洞被扼杀在摇篮里，否则后果还真的挺严重的。通过这个案例，我们有啥经验和教训呢？那就是作为程序员，&lt;strong&gt;我们要对每一行代码都保持“敬畏”之心&lt;/strong&gt;。也许就是因为你的不经意的一行代码就带来了严重的安全漏洞，要是不小心被坏人利用，轻则……重则……（自己想象吧）&lt;/p&gt;
&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;此外，我们也应该看到，程序员需要对常见的安全漏洞（例如XSS/CSRF/SQL注入等等）有所了解，并且要有足够的安全意识（其实有时候研究一些安全问题还挺好玩的，比如这篇&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzI3OTUzMzcwNw==&amp;amp;mid=2247483759&amp;amp;idx=1&amp;amp;sn=9b37547a51ac99a8d3d50cb9cf54a99a&amp;amp;chksm=eb47008bdc30899dace5743edfc071d97d37764ed69bd9cebbfe32c14727a7407a6b8b76a433&amp;amp;scene=21#wechat_redirect&quot;&gt;《RSA算法及一种&quot;旁门左道&quot;的攻击方式》&lt;/a&gt;就比较有趣）。例如：&lt;/p&gt;
&lt;ul data-tool=&quot;mdnice编辑器&quot;&gt;&lt;li&gt;用户权限分离：运行程序的用户不应该用 root，例如新建一个“web”或者“www”之类的用户，并设置该用户的权限，比如不能有可执行 xx 的权限之类的。本文 case，如果权限进行了分离（遵循最小权限原则），应该也不会这么严重。（本文就刚好是因为是测试环境，所以没有强制实施）&lt;/li&gt;
&lt;li&gt;任何时候都不要相信用户的输入，必须对用户输入的进行校验和过滤，又特别是针对公网上的应用。&lt;/li&gt;
&lt;li&gt;敏感信息加密保存。退一万步讲，假设攻击者攻入了你的服务器，如果这个时候，你的数据库账户信息等配置都直接明文保存在服务器中。那数据库也被脱走了。&lt;/li&gt;
&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果可能的话，需要对开发者的代码进行漏洞扫描。一些常见的安全漏洞现在应该是有现成的工具支持的。另外，让专业的人做专业的事情，例如要有安全团队，可能你会说你们公司没有不也活的好好的，哈哈，只不过可能还没有被坏人盯上而已，坏人也会考虑到他们的成本和预期收益的，当然这就更加对我们开发者提高了要求。一些敏感权限尽量控制在少部分人手中，配合相应的流程来支撑（不得不说，大公司繁琐的流程还是有一定道理的）。&lt;/p&gt;
&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;毕竟我不是专业研究Web安全的，以上说得可能也不一定对，如果你有不同意见或者更好的建议欢迎留言参与讨论。&lt;/p&gt;
&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这篇文章从写代码做实验，到录屏做视频动图等等耗时还蛮久的（好几个周末的时间呢），原创真心不易，希望你能帮我个小忙呗，如果本文内容你觉得有所启发，有所收获，请帮忙点个“在看”呗，或者转发分享让更多的小伙伴看到。&lt;/p&gt;
&lt;h5 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span class=&quot;prefix&quot;&gt;&lt;span class=&quot;content&quot;&gt;精彩推荐&lt;/span&gt;&lt;/span&gt;&lt;/h5&gt;
&lt;blockquote data-tool=&quot;mdnice编辑器&quot; readability=&quot;6&quot;&gt;
&lt;p&gt;文章首发于本人微信公众号（ID：&lt;code&gt;tangleithu&lt;/code&gt;），请感兴趣的同学关注我的微信公众号，及时获取技术干货。&lt;/p&gt;
&lt;/blockquote&gt;
</description>
<pubDate>Tue, 09 Jun 2020 15:09:00 +0000</pubDate>
<dc:creator>程序猿石头</dc:creator>
<og:description>之前在某厂的某次项目开发中，项目组同学设计和实现了一个“引以为傲”，额，有点扩张，不过自认为还说得过去的 feature，结果临上线前被啪啪打脸，因为实现过程中因为一行代码（没有标题党，真的是一行代码</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/leitang/p/13081693.html</dc:identifier>
</item>
<item>
<title>Spring Boot 教程 - Elasticsearch - Butterfly-Tri</title>
<link>http://www.cnblogs.com/Butterfly-Tri/p/13081498.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/Butterfly-Tri/p/13081498.html</guid>
<description>&lt;p&gt;Elasticsearch是一个基于Lucene的搜索服务器。它提供了一个分布式多用户能力的全文搜索引擎，基于RESTful web接口。Elasticsearch是用Java语言开发的，并作为Apache许可条款下的开放源码发布，是一种流行的企业级搜索引擎。Elasticsearch用于云计算中，能够达到实时搜索，稳定，可靠，快速，安装使用方便。官方客户端在Java、.NET（C#）、PHP、Python、Apache Groovy、Ruby和许多其他语言中都是可用的。根据DB-Engines的排名显示，Elasticsearch是最受欢迎的企业搜索引擎，其次是Apache Solr，也是基于Lucene。以后再给大家详细介绍solr。&lt;/p&gt;&lt;p&gt;它能很方便的使大量数据具有搜索、分析和探索的能力。充分利用Elasticsearch的水平伸缩性，能使数据在生产环境变得更有价值。Elasticsearch 的实现原理主要分为以下几个步骤，首先用户将数据提交到Elasticsearch 数据库中，再通过分词控制器去将对应的语句分词，将其权重和分词结果一并存入数据，当用户搜索数据时候，再根据权重将结果排名，打分，再将返回结果呈现给用户。&lt;/p&gt;&lt;p&gt;Elasticsearch可以用于搜索各种文档。它提供可扩展的搜索，具有接近实时的搜索，并支持多租户。”Elasticsearch是分布式的，这意味着索引可以被分成分片，每个分片可以有0个或多个副本。每个节点托管一个或多个分片，并充当协调器将操作委托给正确的分片。再平衡和路由是自动完成的。“相关数据通常存储在同一个索引中，该索引由一个或多个主分片和零个或多个复制分片组成。一旦创建了索引，就不能更改主分片的数量。&lt;/p&gt;&lt;p&gt;Elasticsearch使用Lucene，并试图通过JSON和Java API提供其所有特性。它支持facetting和percolating，如果新文档与注册查询匹配，这对于通知非常有用。另一个特性称为“网关”，处理索引的长期持久性；例如，在服务器崩溃的情况下，可以从网关恢复索引。Elasticsearch支持实时GET请求，适合作为NoSQL数据存储，但缺少分布式事务。&lt;/p&gt;&lt;div id=&quot;&quot;&gt;&lt;li readability=&quot;6.8757396449704&quot;&gt;
&lt;p&gt;&lt;strong&gt;2.1.1 lucene&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Es是一个比较复杂的搜索服务器，本身也是使用Java语言编写的，在上面的简介中，说明了ES是一个基于lucene的搜索服务器，lucene是什么呢？Lucene是apache软件基金会4 jakarta项目组的一个子项目，是一个开放源代码的全文检索引擎工具包，但它不是一个完整的全文检索引擎，而是一个全文检索引擎的架构，提供了完整的查询引擎和索引引擎，部分文本分析引擎。lucene也是使用Java语言编写的，Java天下第一😁！&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Lucene&lt;/strong&gt;是一套用于&lt;a href=&quot;https://baike.baidu.com/item/%E5%85%A8%E6%96%87%E6%A3%80%E7%B4%A2/8028630&quot;&gt;全文检索&lt;/a&gt;和搜寻的开源程式库，由&lt;a href=&quot;https://baike.baidu.com/item/Apache&quot;&gt;Apache&lt;/a&gt;软件基金会支持和提供。Lucene提供了一个简单却强大的应用程式接口，能够做全文索引和搜寻。在Java开发环境里Lucene是一个成熟的免费开源工具。就其本身而言，Lucene是当前以及最近几年最受欢迎的免费Java信息检索程序库。至于lucene到底是怎么实现的，牛牛们可能要自己去百度或者谷歌一下啦。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;&lt;strong&gt;2.1.2 Elasticsearch的基本概念&lt;/strong&gt;&lt;/p&gt;
&lt;ol readability=&quot;22.5&quot;&gt;&lt;li readability=&quot;1&quot;&gt;
&lt;p&gt;集群(Cluster)：就是多台ES服务器在一起构成搜索服务器，现在很多应用基本上都有集群的概念，提高性能，让应用具有高可用性，一台服务器挂掉，可以很快有另一台ES服务器补上。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;节点(Node)：节点就是集群中的某一台ES服务器就称为一个节点。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;索引库(Index Indices)：就是ES服务器上的某一个索引，相当于Mysql数据库中的数据库的概念，一个节点可以有很多个索引库。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;2&quot;&gt;
&lt;p&gt;文档类型(Type)：这个概念就相当于Mysql数据库中表的概念，一个索引库可以有很多个文档类型，但是这个概念现在慢慢淡化了，因为在ES中一个索引库直接存数据文档就挺好的，这个概念现在来说有点多余了，所以ES官方也在淡化这个概念，在ES8中，这个概念将会彻底的消失。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;34&quot;&gt;
&lt;p&gt;文档(Doc)：文档就相当于Mysql是数据库中某个表的一条数据记录，现在ES已经到7.7版本了，我们也就忽略type这个概念，直接在索引库中存文档即可。另外需要说一下，我们一般把数据文档存到Es服务器的某个索引库的这个动作称之为&lt;strong&gt;索引&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;最后还有两个比较重要的概念，但是可能不是那么直观的可以感受得到：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;分片(Shards)和副本(Replicas)&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;索引可能会存储大量数据，这些数据可能超过单个节点的硬件限制。例如，十亿个文档的单个索引占用了1TB的磁盘空间，可能不适合单个节点的磁盘，或者可能太慢而无法单独满足来自单个节点的搜索请求。&lt;/p&gt;
&lt;p&gt;为了解决此问题，Elasticsearch提供了将索引细分为多个碎片的功能。创建索引时，只需定义所需的分片数量即可。每个分片本身就是一个功能齐全且独立的“索引”，可以托管在群集中的任何节点上。&lt;/p&gt;
&lt;p&gt;分片很重要，主要有两个原因：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;它允许您水平分割/缩放内容量&lt;/li&gt;
&lt;li&gt;它允许您跨碎片（可能在多个节点上）分布和并行化操作，从而提高性能/吞吐量&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;分片如何分布以及其文档如何聚合回到搜索请求中的机制由Elasticsearch完全管理，并且对您作为用户是透明的。&lt;/p&gt;
&lt;p&gt;在随时可能发生故障的网络/云环境中，非常有用，强烈建议您使用故障转移机制，以防碎片/节点因某种原因脱机或消失。为此，Elasticsearch允许您将索引分片的一个或多个副本制作为所谓的副本分片（简称副本）。&lt;/p&gt;
&lt;p&gt;复制很重要，主要有两个原因：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;如果分片/节点发生故障，它可提供高可用性。因此，重要的是要注意，副本碎片永远不会与从其复制原始/主要碎片的节点分配在同一节点上。&lt;/li&gt;
&lt;li&gt;由于可以在所有副本上并行执行搜索，因此它可以扩展搜索量/吞吐量。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;总而言之，每个索引可以分为多个碎片。索引也可以复制零（表示没有副本）或多次。复制后，每个索引将具有主碎片（从中进行复制的原始碎片）和副本碎片（主碎片的副本）。可以在创建索引时为每个索引定义分片和副本的数量。创建索引后，您可以随时动态更改副本数，但不能事后更改分片数。&lt;/p&gt;
&lt;p&gt;默认情况下，Elasticsearch中的每个索引分配有5个主碎片和1个副本，这意味着如果集群中至少有两个节点，则索引将具有5个主碎片和另外5个副本碎片（1个完整副本），总共每个索引10个碎片。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;li readability=&quot;36.174023338407&quot;&gt;
&lt;p&gt;&lt;strong&gt;2.1.3 Elasticsearch的索引原理&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Es作为一个全文检索服务器，那么它在搜索方面肯定很在行啦！那它是怎么做到的呢？&lt;/p&gt;
&lt;p&gt;Es官方有这么一句话：一切设计都是为了提高搜索的性能！&lt;/p&gt;
&lt;p&gt;Es能够快速的搜索出我们需要的内容，靠的就是倒排索引的思想，或者说是一种设计！&lt;/p&gt;
&lt;p&gt;在没有使用倒排索引的情况下，正常思路是根据搜索关键字去查找相应的内容，但是使用了倒排索引之后，ES会先将文档的所有内容拆分成多个词条，创建一个包含所有不重复词条的排序列表，然后列出每个词条出现在哪个文档。&lt;/p&gt;
&lt;p&gt;例如，假设我们有两个文档，每个文档的 &lt;code&gt;content&lt;/code&gt; 域包含如下内容：&lt;/p&gt;
&lt;p&gt;​ Doc_1:&lt;strong&gt;The quick brown fox jumped over the lazy dog&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;​ Doc_2:&lt;strong&gt;Quick brown foxes leap over lazy dogs in summer&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;ES首先会将这两个文档拆分成多个单独的词，或者叫做词条，然后为所有的词条创建一个排序列表，并记录每个词条出现的文档的信息。就像下面这样：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-table&quot;&gt;Term      Doc_1  Doc_2
-------------------------
Quick   |       |  X                        /*
The     |   X   |                                                               Term就是词条，比如第一个Term就是Quick关键字，在Doc_1中不存
brown   |   X   |  X                                                    在，在Doc_2中存在，其他的以此类推。
dog     |   X   |                                                       */
dogs    |       |  X
fox     |   X   |
foxes   |       |  X
in      |       |  X
jumped  |   X   |
lazy    |   X   |  X
leap    |       |  X
over    |   X   |  X
quick   |   X   |
summer  |       |  X
the     |   X   |
------------------------
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;现在，如果我们想搜索 &lt;strong&gt;quick&lt;/strong&gt;和&lt;strong&gt;brown&lt;/strong&gt;这两个关键字，我们只需要查找包含每个词条的文档，就相当于我们查询的时候，是通过这个索引表找到文档，在通过文档去找文档内容中的搜索关键字，与传统的通过关键字去找内容是不同的。&lt;/p&gt;
&lt;p&gt;倒排索引到底是个怎么实现的，怎么个思想，我在这里就不一一说明了，大家可以看下官方的详细介绍：&lt;a href=&quot;https://www.elastic.co/guide/cn/elasticsearch/guide/current/inverted-index.html&quot;&gt;倒排索引的原理&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;还有es官方的一系列的说明也都可以了解一下：&lt;strong&gt;&lt;a href=&quot;https://www.elastic.co/cn/what-is/elasticsearch&quot;&gt;什么是Elasticsearch?&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/div&gt;&lt;p&gt;本演示项目ES版本为7.0.0版本，其他版本的ES的maven依赖与其他的jar包关系请自行查阅官方文档，保证不冲突。&lt;/p&gt;&lt;div id=&quot;&quot;&gt;&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;Windows&lt;/p&gt;
&lt;p&gt;Es服务器的安装很简单，Windows版本特别的简单，直接去官网下载，运行 &lt;code&gt;bin/elasticsearch&lt;/code&gt; 或者&lt;code&gt;bin\elasticsearch.bat&lt;/code&gt; 。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;38&quot;&gt;
&lt;p&gt;Linux(CentOS7)&lt;/p&gt;
&lt;p&gt;首先我们去官网下载ES的tar.gz包，然后自建一个文件夹放好，然后解压tar.zg压缩包：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;tar -xvf elasticsearch-7.0.0.tar.gz
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;然后进入到bin目录下：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;cd elasticsearch-7.0.0/bin
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;然后运行elasticsearch：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;./elasticsearch
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;这个时候肯定会报错的，因为没有进行配置，所以我们先对es进行一些简单的配置，保证能单机运行，进入elasticsearch-7.7.0/config目录，对es的核心配置文件进行编辑：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;vim elasticsearch.yml
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;进入到了elasticsearch.yml文件的编辑页面：&lt;/p&gt;
&lt;p&gt;首先我们配置集群名称，集群名称自己取一个喜欢的名字就好：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/2039191/202006/2039191-20200609223901911-1189857514.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;接下来配置节点名称，就是在这个集群中，这个es服务器的名称：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/2039191/202006/2039191-20200609223914032-1354426989.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;接下来配置一些必要的参数：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/2039191/202006/2039191-20200609223925396-1237347551.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;bootstrap.memory_lock&lt;/code&gt;: 是否锁住内存，避免交换(swapped)带来的性能损失,默认值是: false。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;bootstrap.system_call_filter&lt;/code&gt;: 是否支持过滤掉系统调用。elasticsearch 5.2以后引入的功能，在bootstrap的时候check是否支持seccomp。&lt;/p&gt;
&lt;p&gt;配置network为所有人都可以访问，因为我们一般是使用ssh连接工具在其他的电脑上操作Linux系统，所以我们需要配置一下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/2039191/202006/2039191-20200609223944292-1328647128.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;到这里就配置完成了，但是当你重新去运行&lt;code&gt;.elasticsearch&lt;/code&gt;的可执行文件的时候，依然会报错。&lt;/p&gt;
&lt;p&gt;报错信息中可能包含以下几个错误：&lt;/p&gt;
&lt;ul readability=&quot;26.5&quot;&gt;&lt;li readability=&quot;11&quot;&gt;
&lt;p&gt;&lt;code&gt;max file descriptors [4096] for elasticsearch process is too low, increase to at least [65536]&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;原因：无法创建本地文件问题,用户最大可创建文件数太小。&lt;/p&gt;
&lt;p&gt;解决方法：切换到root账户下，进入Linux系统文件夹，编辑limits.conf文件：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;vim /etc/security/limits.conf
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;在文件的末尾加上：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-conf&quot;&gt;*                soft    nofile          65536
*                hard    nofile          65536
*                soft    nproc           4096
*                hard    nproc           4096
&lt;/code&gt;
&lt;/pre&gt;&lt;/li&gt;
&lt;li readability=&quot;7&quot;&gt;
&lt;p&gt;&lt;code&gt;max virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144]&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;原因：最大虚拟内存太小,需要修改系统变量的最大值。&lt;/p&gt;
&lt;p&gt;解决方法：切换到root账户下，进入Linux系统文件夹，编辑sysctl.conf文件：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;vim /etc/sysctl.conf
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;在文件的末尾加上：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;vm.max_map_count=262144
&lt;/code&gt;
&lt;/pre&gt;&lt;/li&gt;
&lt;li readability=&quot;32&quot;&gt;
&lt;p&gt;&lt;code&gt;max number of threads [1024] for user [es] likely too low, increase to at least [2048]&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;原因：无法创建本地线程问题,用户最大可创建线程数太小。&lt;/p&gt;
&lt;p&gt;解决方法：如果你是CentOS6及以下系统，编辑的文件是90-nproc.conf这个文件，如果你和我一样使用的是CentOS7的话，编辑的文件是20-nproc.conf文件，其实这两个文件是一样的，只是在不同CentOS系统中名称不一样而已。&lt;/p&gt;
&lt;p&gt;CentOS7使用这个命令：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;vim /etc/security/limits.d/20-nproc.conf
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;CentOS6使用这个命令：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;vim /etc/security/limits.d/90-nproc.conf
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;只需要在文件中加上以下配置：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;*          soft    nproc     4096
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;这个配置的意思是说赋予其他用户的可创建本地线程数为4096。在这个文件中本来就有一个配置，意思是说赋予root账户创建线程数不受限制。我们就把上面的配置加在本来存在的配置的下面一行就可以了。&lt;/p&gt;
&lt;p&gt;如果是CentOS7的使用者，还需要配置另一个文件，否则这个最大线程数是不会生效的。CentOS 7 使用systemd替换了SysV，Systemd目的是要取代Unix时代以来一直在使用的init系统，兼容SysV和LSB的启动脚本，而且够在进程启动过程中更有效地引导加载服务。在/etc/systemd目录下有一个系统的默认管理配置，这里有登陆、日志、服务、系统等。所以CentOS7的使用者还需要配置下面这个文件：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;vim /etc/systemd/system.conf
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;对其中的选项进行配置，在文件的末尾加上：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;DefaultLimitNOFILE=65536
DefaultLimitNPROC=4096
&lt;/code&gt;
&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;上面的所以错误解决完毕之后，我们再运行&lt;code&gt;.elasticsearch&lt;/code&gt;可执行文件，es才可以启动成功。&lt;/p&gt;
&lt;/li&gt;
&lt;/div&gt;&lt;p&gt;首先给大家介绍一个谷歌浏览器插件，这个插件是用来可视化展示es的索引库数据的，这个插件叫做&lt;strong&gt;ElasticVue&lt;/strong&gt;，个人感觉挺好用的，展示也比较方便，给大家截个图看看：&lt;/p&gt;&lt;p&gt;大家可以使用这个建立索引库，然后调用es官方的es专用的语法操作es服务器进行CRUD操作，但是此处我只介绍Java语言如何调用es服务器API，废话不多说，我们直接开始下一步。&lt;/p&gt;&lt;div id=&quot;&quot;&gt;&lt;li readability=&quot;4&quot;&gt;
&lt;p&gt;&lt;strong&gt;2.3.1 引入依赖&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;搭建工程的过程我就不演示了，直接上pom.xml依赖文件。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;pom.xml&lt;/code&gt;：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-xml&quot;&gt;&amp;lt;!--springboot父工程--&amp;gt;
    &amp;lt;parent&amp;gt;
        &amp;lt;groupId&amp;gt;org.springframework.boot&amp;lt;/groupId&amp;gt;
        &amp;lt;artifactId&amp;gt;spring-boot-starter-parent&amp;lt;/artifactId&amp;gt;
        &amp;lt;version&amp;gt;2.2.2.RELEASE&amp;lt;/version&amp;gt;
        &amp;lt;relativePath/&amp;gt; &amp;lt;!-- lookup parent from repository --&amp;gt;
    &amp;lt;/parent&amp;gt;

    &amp;lt;dependencies&amp;gt;
        &amp;lt;!--springboot-web组件--&amp;gt;
        &amp;lt;dependency&amp;gt;
            &amp;lt;groupId&amp;gt;org.springframework.boot&amp;lt;/groupId&amp;gt;
            &amp;lt;artifactId&amp;gt;spring-boot-starter-web&amp;lt;/artifactId&amp;gt;
            &amp;lt;version&amp;gt;2.2.2.RELEASE&amp;lt;/version&amp;gt;
        &amp;lt;/dependency&amp;gt;
        &amp;lt;!--elasticsearch-rest-client组件--&amp;gt;
        &amp;lt;dependency&amp;gt;
            &amp;lt;groupId&amp;gt;org.elasticsearch.client&amp;lt;/groupId&amp;gt;
            &amp;lt;artifactId&amp;gt;elasticsearch-rest-client&amp;lt;/artifactId&amp;gt;
            &amp;lt;version&amp;gt;7.7.0&amp;lt;/version&amp;gt;
        &amp;lt;/dependency&amp;gt;
        &amp;lt;!--elasticsearch-rest-high-level-client组件--&amp;gt;
        &amp;lt;dependency&amp;gt;
            &amp;lt;groupId&amp;gt;org.elasticsearch.client&amp;lt;/groupId&amp;gt;
            &amp;lt;artifactId&amp;gt;elasticsearch-rest-high-level-client&amp;lt;/artifactId&amp;gt;
            &amp;lt;version&amp;gt;7.7.0&amp;lt;/version&amp;gt;
        &amp;lt;/dependency&amp;gt;
        &amp;lt;!--elasticsearch组件--&amp;gt;
        &amp;lt;dependency&amp;gt;
            &amp;lt;groupId&amp;gt;org.elasticsearch&amp;lt;/groupId&amp;gt;
            &amp;lt;artifactId&amp;gt;elasticsearch&amp;lt;/artifactId&amp;gt;
            &amp;lt;version&amp;gt;7.7.0&amp;lt;/version&amp;gt;
        &amp;lt;/dependency&amp;gt;
        &amp;lt;!--mybatis整合springboot组件--&amp;gt;
        &amp;lt;dependency&amp;gt;
            &amp;lt;groupId&amp;gt;org.mybatis.spring.boot&amp;lt;/groupId&amp;gt;
            &amp;lt;artifactId&amp;gt;mybatis-spring-boot-starter&amp;lt;/artifactId&amp;gt;
            &amp;lt;version&amp;gt;2.1.0&amp;lt;/version&amp;gt;
        &amp;lt;/dependency&amp;gt;
        &amp;lt;!--mysql数据库连接驱动--&amp;gt;
        &amp;lt;dependency&amp;gt;
            &amp;lt;groupId&amp;gt;mysql&amp;lt;/groupId&amp;gt;
            &amp;lt;artifactId&amp;gt;mysql-connector-java&amp;lt;/artifactId&amp;gt;
            &amp;lt;version&amp;gt;8.0.18&amp;lt;/version&amp;gt;
        &amp;lt;/dependency&amp;gt;
        &amp;lt;!--lombok组件--&amp;gt;
        &amp;lt;dependency&amp;gt;
            &amp;lt;groupId&amp;gt;org.projectlombok&amp;lt;/groupId&amp;gt;
            &amp;lt;artifactId&amp;gt;lombok&amp;lt;/artifactId&amp;gt;
            &amp;lt;version&amp;gt;1.18.10&amp;lt;/version&amp;gt;
        &amp;lt;/dependency&amp;gt;
        &amp;lt;!--json组件gson--&amp;gt;
        &amp;lt;dependency&amp;gt;
            &amp;lt;groupId&amp;gt;com.google.code.gson&amp;lt;/groupId&amp;gt;
            &amp;lt;artifactId&amp;gt;gson&amp;lt;/artifactId&amp;gt;
            &amp;lt;version&amp;gt;2.8.5&amp;lt;/version&amp;gt;
        &amp;lt;/dependency&amp;gt;
        &amp;lt;!--springboot-test组件--&amp;gt;
        &amp;lt;dependency&amp;gt;
            &amp;lt;groupId&amp;gt;org.springframework.boot&amp;lt;/groupId&amp;gt;
            &amp;lt;artifactId&amp;gt;spring-boot-test&amp;lt;/artifactId&amp;gt;
        &amp;lt;/dependency&amp;gt;
        &amp;lt;!--单元测试junit组件--&amp;gt;
        &amp;lt;dependency&amp;gt;
            &amp;lt;groupId&amp;gt;junit&amp;lt;/groupId&amp;gt;
            &amp;lt;artifactId&amp;gt;junit&amp;lt;/artifactId&amp;gt;
            &amp;lt;version&amp;gt;4.12&amp;lt;/version&amp;gt;
            &amp;lt;scope&amp;gt;test&amp;lt;/scope&amp;gt;
        &amp;lt;/dependency&amp;gt;
        &amp;lt;!--spring-test组件--&amp;gt;
        &amp;lt;dependency&amp;gt;
            &amp;lt;groupId&amp;gt;org.springframework&amp;lt;/groupId&amp;gt;
            &amp;lt;artifactId&amp;gt;spring-test&amp;lt;/artifactId&amp;gt;
            &amp;lt;version&amp;gt;5.2.2.RELEASE&amp;lt;/version&amp;gt;
            &amp;lt;scope&amp;gt;test&amp;lt;/scope&amp;gt;
        &amp;lt;/dependency&amp;gt;
    &amp;lt;/dependencies&amp;gt;

    &amp;lt;build&amp;gt;
        &amp;lt;!--springboot的maven插件--&amp;gt;
        &amp;lt;plugins&amp;gt;
            &amp;lt;plugin&amp;gt;
                &amp;lt;groupId&amp;gt;org.springframework.boot&amp;lt;/groupId&amp;gt;
                &amp;lt;artifactId&amp;gt;spring-boot-maven-plugin&amp;lt;/artifactId&amp;gt;
            &amp;lt;/plugin&amp;gt;
            &amp;lt;plugin&amp;gt;
                &amp;lt;groupId&amp;gt;org.apache.maven.plugins&amp;lt;/groupId&amp;gt;
                &amp;lt;artifactId&amp;gt;maven-compiler-plugin&amp;lt;/artifactId&amp;gt;
                &amp;lt;configuration&amp;gt;
                    &amp;lt;compilerArgs&amp;gt;
                        &amp;lt;arg&amp;gt;-parameters&amp;lt;/arg&amp;gt;
                    &amp;lt;/compilerArgs&amp;gt;
                &amp;lt;/configuration&amp;gt;
            &amp;lt;/plugin&amp;gt;
        &amp;lt;/plugins&amp;gt;
    &amp;lt;/build&amp;gt;
&lt;/code&gt;
&lt;/pre&gt;&lt;/li&gt;
&lt;li readability=&quot;55&quot;&gt;
&lt;p&gt;&lt;strong&gt;2.3.2 Elasticsearch的配置类和Gson配置类和应用配置文件&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;application.yml&lt;/code&gt;：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-yml&quot;&gt;butterflytri:
  databaseurl-port: 127.0.0.1:3306 # 数据库端口
  database-name: student_db # 数据库名
  host: 192.168.129.100:9200 # es服务端
server:
  port: 8080 # 应用端口
  servlet:
    context-path: /butterflytri # 应用映射
spring:
  application:
    name: mybatis # 应用名称
  datasource:
    url: jdbc:mysql://${butterflytri.databaseurl-port}/${butterflytri.database-name}?useUnicode=true&amp;amp;characterEncoding=UTF-8&amp;amp;useJDBCCompliantTimezoneShift=true&amp;amp;useLegacyDatetimeCode=false&amp;amp;serverTimezone=UTC
    driver-class-name: com.mysql.jdbc.Driver
    username: root
    password: root
mybatis:
  type-aliases-package: com.butterflytri.entity # entity别名
  mapper-locations: classpath:com/butterflytri/mapper/*Mapper.xml # mapper映射包扫描
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;注意：yml文件中的192.168.129.100:9200是es对外的端口，使用的http协议进行操作，es服务器还有个9300端口，这个端口是es集群中各个节点进行交流的端口，使用的是tcp协议。所以我们连接的时候，端口要使用9200端口。&lt;/p&gt;
&lt;p&gt;项目启动类没有什么特别的东西，就不展示了。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;ElasticsearchConfig.java&lt;/code&gt;：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;package com.butterflytri.config;

import org.apache.http.HttpHost;
import org.elasticsearch.client.RestClient;
import org.elasticsearch.client.RestHighLevelClient;
import org.springframework.beans.factory.DisposableBean;
import org.springframework.beans.factory.FactoryBean;
import org.springframework.beans.factory.InitializingBean;
import org.springframework.beans.factory.annotation.Value;
import org.springframework.context.annotation.Configuration;

/**
 * @author: WJF
 * @date: 2020/5/22
 * @description: ElasticSearchConfig
 */
@Configuration
public class ElasticSearchConfig implements FactoryBean&amp;lt;RestHighLevelClient&amp;gt;, InitializingBean, DisposableBean {

    /**
     * {@link FactoryBean&amp;lt;T&amp;gt;}：FactoryBean&amp;lt;T&amp;gt;是spring对外提供的对接接口，当向spring对象使用getBean(&quot;..&quot;)方法时，
     *                         spring会使用FactoryBean&amp;lt;T&amp;gt;的getObject 方法返回对象。所以当一个类实现的factoryBean&amp;lt;T&amp;gt;接口时，
     *                         那么每次向spring要这个类时，spring就返回T对象。
     *
     * {@link InitializingBean}：InitializingBean接口为bean提供了初始化方法的方式，它只包括afterPropertiesSet方法，
     *                          凡是继承该接口的类，在初始化bean的时候会执行该方法。在spring初始化bean的时候，如果该bean是
     *                          实现了InitializingBean接口，并且同时在配置文件中指定了init-method，系统则是
     *                          先调用afterPropertiesSet方法，然后在调用init-method中指定的方法。
     *
     * {@link DisposableBean}：DisposableBean接口为bean提供了销毁方法destroy-method，会在程序关闭前销毁对象。
     */

    @Value(&quot;#{'${butterflytri.host}'.split(':')}&quot;)
    private String[] host;

    private RestHighLevelClient restHighLevelClient;

    private RestHighLevelClient restHighLevelClient() {
        restHighLevelClient = new RestHighLevelClient(

                RestClient.builder(new HttpHost(host[0],Integer.valueOf(host[1]),&quot;http&quot;))

        );
        return restHighLevelClient;
    }

    @Override
    public void destroy() throws Exception {
        restHighLevelClient.close();
    }

    @Override
    public RestHighLevelClient getObject() throws Exception {
        return restHighLevelClient;
    }

    @Override
    public Class&amp;lt;?&amp;gt; getObjectType() {
        return RestHighLevelClient.class;
    }

    @Override
    public void afterPropertiesSet() throws Exception {
        restHighLevelClient();
    }

}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;ES的配置类，这个配置类实现了三个接口，三个接口的作用我也写上了注释，大家可以看下，需要注意的是&lt;code&gt;FactoryBean&lt;/code&gt;这个接口，一但实现了这个接口，每当你需要使用泛型表示的对象T的时候，Spring不会从容器中去拿这个对象，而是会调用这个&lt;code&gt;FactoryBean.getObject()&lt;/code&gt;方法去拿对象。其他的就没有什么了。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Gson.java&lt;/code&gt;：&lt;/p&gt;
&lt;p&gt;Gson是一个操作json数据的类，它的执行效率可能会慢一点，但是它在解析json数据的时候不会出Bug。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;package com.butterflytri.config;

import com.google.gson.Gson;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;

/**
 * @author: WJF
 * @date: 2020/5/22
 * @description: GsonConfig
 */
@Configuration
public class GsonConfig {

    /**
     * {@link Gson}：一个操作json的对象，有比较好的json操作体验，相对于Alibaba的FastJson来说速度慢一些，但是FastJson在解析
     *              复杂的的json字符串时有可能会出现bug。
     * @return Gson
     */

    @Bean
    public Gson gson() {
        return new Gson();
    }

}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;Constants.java&lt;/code&gt;：&lt;/p&gt;
&lt;p&gt;这是我写的常量类，放一些ES使用的常量，直接写字符串也行，但是我建议这样做。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;package com.butterflytri.constants;


/**
 * @author: WJF
 * @date: 2020/5/22
 * @description: Constants
 */
public class Constants {

    /**
     * es搜索关键字
     */
    public static final String KEYWORD = &quot;.keyword&quot;;

    /**
     * es的type类型：type字段将在 elasticsearch-version：8 中彻底删除，本来就觉得没得啥用。
     */
    public static final String DOC_TYPE = &quot;_doc&quot;;

    /**
     * 学生信息索引类型
     */
    public static final String INDEX_STUDENT = &quot;student_info&quot;;


    /**
     * 自定连接符
     */
    public static final String CONNECTOR = &quot; --&amp;gt; &quot;;

}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;Student.java&lt;/code&gt;：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;package com.butterflytri.entity;

import lombok.Getter;
import lombok.Setter;
import lombok.ToString;

import java.io.Serializable;

/**
 * @author: WJF
 * @date: 2020/5/16
 * @description: Student
 */

@ToString
@Getter
@Setter
public class Student implements Serializable {

    private Long id;

    private String studentName;

    private String studentNo;

    private String sex;

    private Integer age;

    private String clazz;

}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;StudentMapper.java&lt;/code&gt;：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;package com.butterflytri.mapper;

import com.butterflytri.entity.Student;
import org.apache.ibatis.annotations.Mapper;

import java.util.List;

/**
 * @author: WJF
 * @date: 2020/5/16
 * @description: StudentMapper
 */
@Mapper
public interface StudentMapper {

    /**
     * 查询所有学生信息
     * @return List&amp;lt;Student&amp;gt;
     */
    List&amp;lt;Student&amp;gt; findAll();

    /**
     * 通过id查询学生信息
     * @param id：学生id
     * @return Student
     */
    Student findOne(Long id);

    /**
     * 通过学号查询学生信息
     * @param studentNo：学生学号
     * @return Student
     */
    Student findByStudentNo(String studentNo);

}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;mybatis的SQL映射文件我就不展示了，也很简单，大家看接口方法名就应该可以想象得到SQL语句是怎样的。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;25&quot;&gt;
&lt;p&gt;&lt;strong&gt;2.3.3 索引数据到ES服务器&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;IndexServiceImpl.java&lt;/code&gt;：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;package com.butterflytri.service.impl;

import com.butterflytri.constants.Constants;
import com.butterflytri.entity.Student;
import com.butterflytri.service.IndexService;
import com.google.gson.Gson;
import org.elasticsearch.action.ActionListener;
import org.elasticsearch.action.index.IndexRequest;
import org.elasticsearch.action.index.IndexResponse;
import org.elasticsearch.client.RequestOptions;
import org.elasticsearch.client.RestHighLevelClient;
import org.elasticsearch.common.xcontent.XContentType;
import org.springframework.stereotype.Service;

import javax.annotation.Resource;
import java.io.IOException;

/**
 * @author: WJF
 * @date: 2020/5/22
 * @description: IndexServiceImpl
 */
@Service
public class IndexServiceImpl implements IndexService {

    @Resource
    private Gson gson;

    @Resource
    private RestHighLevelClient restHighLevelClient;

    @Override
    public String index(Student student) {
        StringBuilder builder = new StringBuilder();
        IndexRequest indexRequest = this.initIndexRequest(student);
        try {
            // 同步索引到elasticsearch服务器，获取索引响应IndexResponse
            IndexResponse indexResponse = restHighLevelClient.index(indexRequest, RequestOptions.DEFAULT);
            String statusName = indexResponse.status().name();
            int statusCode = indexResponse.status().getStatus();
            builder.append(statusName).append(Constants.CONNECTOR).append(statusCode);
        } catch (IOException e) {
            builder.append(&quot;Fail&quot;).append(Constants.CONNECTOR).append(e.getMessage());
        }
        return builder.toString();
    }


    @Override
    public String indexAsync(Student student) {
        StringBuilder builder = new StringBuilder();
        IndexRequest indexRequest = this.initIndexRequest(student);
        // 异步索引到elasticsearch服务器，获取索引响应IndexResponse
        restHighLevelClient.indexAsync(indexRequest, RequestOptions.DEFAULT,actionListener(builder));
        return builder.toString();
    }



    /**
     * 初始化IndexRequest，并设置数据源。
     * @param student
     * @return IndexRequest
     */
    private IndexRequest initIndexRequest(Student student) {
        // 构建IndexRequest，设置索引名称，索引类型，索引id
        IndexRequest indexRequest = new IndexRequest(Constants.INDEX_STUDENT);
        // 可以不设置，默认就是'_doc'
        indexRequest.type(Constants.DOC_TYPE);
        // 设置索引id为studentId
        indexRequest.id(String.valueOf(student.getId()));
        // 设置数据源
        String studentJson = gson.toJson(student);
        indexRequest.source(studentJson, XContentType.JSON);
        return indexRequest;
    }

    /**
     * 异步索引的回调监听器，根据不同的结果做出不同的处理
     * @param builder
     * @return ActionListener&amp;lt;IndexResponse&amp;gt;
     */
    private ActionListener&amp;lt;IndexResponse&amp;gt; actionListener(StringBuilder builder) {
        return new ActionListener&amp;lt;IndexResponse&amp;gt;() {
            // 当索引数据到es服务器时，返回不同的状态
            @Override
            public void onResponse(IndexResponse indexResponse) {
                String statusName = indexResponse.status().name();
                int statusCode = indexResponse.status().getStatus();
                builder.append(statusName).append(Constants.CONNECTOR).append(statusCode);
            }

            // 当索引数据时出现异常
            @Override
            public void onFailure(Exception e) {
                builder.append(&quot;Fail&quot;).append(Constants.CONNECTOR).append(e.getMessage());
            }
        };
    }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;上面的内容很简单，就是将Student对象格式化为Json字符串，然后存到es服务器中，大家只要遵守一个规则就好，就是操作es服务器，不管是什么操作都是用RestHighLevelClient这个类去操作，上面的就是student对象索引的es服务器中，使用&lt;code&gt;restHighLevelClient.index(indexRequest, RequestOptions.DEFAULT)&lt;/code&gt;，首先就是构建indexRequest对象，这个对象就是索引请求对象，具体干了什么看代码上的注释。这里还有个&lt;code&gt;restHighLevelClient.indexAsync()&lt;/code&gt;这个方法，这个方法和上面的index方法一样的效果，只不过是异步调用。&lt;/p&gt;
&lt;p&gt;接下来我们测试一下这个代码，请看：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;@Test
    public void indexTest() {
        List&amp;lt;Student&amp;gt; list = studentMapper.findAll();
        for (Student student : list) {
            String message = indexService.index(student);
            System.out.println(message);
        }
    }
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;我们使用ElasticVue插件连接es服务器即可看到有一个索引库：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/2039191/202006/2039191-20200609224255242-78110057.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;当我们点击到show按钮的时候，可以看到student_info索引库中有几条记录：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/2039191/202006/2039191-20200609224308040-204837758.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;索引数据到数据库成功了。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;19&quot;&gt;
&lt;p&gt;&lt;strong&gt;2.3.4 获取Es服务器数据&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;获取数据，是es提供给我们的API，这个Api只能获取某个索引的某一条文档，示例如下：&lt;/p&gt;
&lt;p&gt;&lt;code&gt;GetServiceImpl.java&lt;/code&gt;：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;       @Override
    public Student get(String id) {
        Student student = new Student();
        GetRequest getRequest = new GetRequest(Constants.INDEX_STUDENT, id);
        try {
            GetResponse getResponse = restHighLevelClient.get(getRequest, RequestOptions.DEFAULT);
            String source = getResponse.getSourceAsString();
            student = gson.fromJson(source, Student.class);
        } catch (IOException e) {
            e.printStackTrace();
        }
        return student;
    }
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;接着我们在测试类中，调用这个方法然后打印一下结果：&lt;/p&gt;
&lt;p&gt;&lt;code&gt;GetServiceTest.java&lt;/code&gt;：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;       @Test
    public void getTest() {
        Student student = getService.get(&quot;1&quot;);
        System.out.println(student);
    }
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;结果如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/2039191/202006/2039191-20200609224320601-1300927597.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;更新数据文档和删除数据文档我就不演示了，都是大同小异，大家可以拉下我的代码，好好研究一下，都有详细的注释，觉得可以的话，给我点下star也是极好的。下面演示一下searchApi，这个Api是我们经常需要使用的，特别重要。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;72&quot;&gt;
&lt;p&gt;&lt;strong&gt;2.3.5 搜索Es服务器数据&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;ES的搜索API包含很多，比如说组合搜索，区间搜索，高亮显示，分词搜索等等。我先给大家演示一下组合搜索，区间搜索其实也是组合搜索的一个子条件，其他的搜索其实也都是，代码如下：&lt;/p&gt;
&lt;p&gt;&lt;code&gt;SearchServiceImpl.java&lt;/code&gt;：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;       @Override
    public List&amp;lt;Student&amp;gt; searchRange(Object from, Object to, String field, String index) {
        List&amp;lt;Student&amp;gt; list = new ArrayList&amp;lt;&amp;gt;();
        BoolQueryBuilder boolQueryBuilder = QueryBuilders.boolQuery();
        // 需要搜索的区间字段field
        RangeQueryBuilder rangeQueryBuilder = QueryBuilders.rangeQuery(field);
        // 左区间
        if (from != null) {
            rangeQueryBuilder.from(from, true);
        }
        // 右区间
        if (to != null) {
            rangeQueryBuilder.to(to, true);
        }
        boolQueryBuilder.must();
        SearchSourceBuilder searchSourceBuilder = new SearchSourceBuilder();
        searchSourceBuilder.query(boolQueryBuilder);
        SearchRequest searchRequest = new SearchRequest(index);
        searchRequest.source(searchSourceBuilder);
        try {
            SearchResponse search = restHighLevelClient.search(searchRequest, RequestOptions.DEFAULT);
            for (SearchHit hit : search.getHits()) {
                String source = hit.getSourceAsString();
                Student student = gson.fromJson(source, Student.class);
                list.add(student);
            }
        } catch (IOException e) {
            e.printStackTrace();
        }
        return list;
    }
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;上面的代码其实很简单，就是一个区间查询构建器，查询指定字段处于区间的所有数据，&lt;code&gt;rangeQueryBuilder.from(from, true)&lt;/code&gt;的第一个参数就是字段的下边界，第二个参数代表是否包含边界。&lt;code&gt;SearchResponse&lt;/code&gt;就是搜索的响应对象，所有的数据都在&lt;code&gt;SearchHit&lt;/code&gt;对象中。&lt;/p&gt;
&lt;p&gt;接下来给大家演示一些组合查询，这个方法搜索年龄在18到19岁并且班级为'G0305'的学生。记得ES默认是分页的，如果想不分页，一定要记得给搜索字段加上&lt;code&gt;.keyword&lt;/code&gt;(字符串加，数字不支持)。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;SearchServiceImpl.java&lt;/code&gt;：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;@Override
    public List&amp;lt;Student&amp;gt; searchBool() {
        List&amp;lt;Student&amp;gt; list = new ArrayList&amp;lt;&amp;gt;();
        BoolQueryBuilder boolQuery = QueryBuilders.boolQuery();
        boolQuery.must(QueryBuilders.rangeQuery(&quot;age&quot;).gte(18).lte(19));
        boolQuery.must(QueryBuilders.termQuery(&quot;clazz&quot; + Constants.KEYWORD,&quot;G0305&quot;));
        SearchSourceBuilder searchSourceBuilder = new SearchSourceBuilder();
        searchSourceBuilder.query(boolQuery);
        SearchRequest searchRequest = new SearchRequest(Constants.INDEX_STUDENT);
        searchRequest.source(searchSourceBuilder);
        try {
            SearchResponse search = restHighLevelClient.search(searchRequest, RequestOptions.DEFAULT);
            for (SearchHit hit : search.getHits()) {
                String source = hit.getSourceAsString();
                Student student = gson.fromJson(source, Student.class);
                list.add(student);
            }
        } catch (IOException e) {
            e.printStackTrace();
        }
        return list;
    }
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;上面的代码中的类&lt;code&gt;BoolQueryBuilder&lt;/code&gt;就是组合查询构建器，这个类可以用来构建组合的条件查询。&lt;code&gt;boolQuery.must()&lt;/code&gt;方法就是用来拼接条件的一种方式，使用这个方法代表必须满足这个条件才会查询出来，上面的代码说明必须满足年龄为18(包含18)到19(包含19)岁，并且班级为'G0305'的学生才会查询出来。还有其他的一些常见的组合查询方法，如下：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;code&gt;boolQuery.must()&lt;/code&gt;：必须满足此条件，相当于&lt;code&gt;=&lt;/code&gt;或者&lt;code&gt;&amp;amp;&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;boolQuery.mustNot()&lt;/code&gt;：必须不满足此条件，相当于&lt;code&gt;!=&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;boolQuery.should()&lt;/code&gt;：相当于&lt;code&gt;||&lt;/code&gt;或者&lt;code&gt;or&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;boolQuery.filter()&lt;/code&gt;：过滤。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;然后是聚合查询，很类似于MySQL中的聚合函数，这个示例我就不再解释了，代码注释很清楚：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;@Override
    public void searchBoolAndAggregation() {
        BoolQueryBuilder boolQuery = QueryBuilders.boolQuery();
        boolQuery.must(QueryBuilders.rangeQuery(&quot;age&quot;).gte(18).lte(19));
        boolQuery.must(QueryBuilders.termQuery(&quot;clazz&quot; + Constants.KEYWORD,&quot;G0305&quot;));
        // 聚合分组：按clazz字段分组，并将结果取名为clazz，es默认是分词的，为了精确配置，需要加上‘.keyword’关键词后缀。
        TermsAggregationBuilder aggregationBuilder = AggregationBuilders.terms(&quot;clazz&quot;).field(&quot;clazz&quot; + Constants.KEYWORD);
        // 聚合求和：求符合查询条件的学生的年龄的和，并将结果取名为ageSum，因为不是字符串，所以默认是精确匹配，不支持分词。
        aggregationBuilder.subAggregation(AggregationBuilders.sum(&quot;ageSum&quot;).field(&quot;age&quot;));
        // 聚合求平均：求符合查询条件的学生的年龄的平均值，并将结果取名为ageAvg，因为不是字符串，所以默认是精确匹配，不支持分词。
        aggregationBuilder.subAggregation(AggregationBuilders.avg(&quot;ageAvg&quot;).field(&quot;age&quot;));
        // 聚合求数量：按学号查询符合查询条件的学生个数，并将结果取名为count，es默认是分词的，为了精确配置，需要加上‘.keyword’关键词后缀。
        aggregationBuilder.subAggregation(AggregationBuilders.count(&quot;count&quot;).field(&quot;studentNo&quot; + Constants.KEYWORD));
        SearchSourceBuilder builder = new SearchSourceBuilder();
        builder.query(boolQuery);
        builder.aggregation(aggregationBuilder);
        // 按年龄降序排序。
        builder.sort(&quot;age&quot;, SortOrder.DESC);
        SearchRequest request = new SearchRequest(&quot;student_info&quot;);
        request.source(builder);
        try {
            SearchResponse search = restHighLevelClient.search(request, RequestOptions.DEFAULT);
            for (SearchHit hit : search.getHits()) {
                String source = hit.getSourceAsString();
                Student student = gson.fromJson(source, Student.class);
                System.out.println(student);
            }
            // 使用Terms对象接收
            Terms clazz = search.getAggregations().get(&quot;clazz&quot;);
            for (Terms.Bucket bucket : clazz.getBuckets()) {
                System.out.println(bucket.getDocCount());

                System.out.println(&quot;=====================&quot;);
                // 使用ParsedSum对象接收
                ParsedSum ageCount = bucket.getAggregations().get(&quot;ageSum&quot;);
                System.out.println(ageCount.getType());
                System.out.println(ageCount.getValue());
                System.out.println(ageCount.getValueAsString());
                System.out.println(ageCount.getMetaData());
                System.out.println(ageCount.getName());

                System.out.println(&quot;=====================&quot;);
                // 使用ParsedAvg对象接收
                ParsedAvg ageAvg = bucket.getAggregations().get(&quot;ageAvg&quot;);
                System.out.println(ageAvg.getType());
                System.out.println(ageAvg.getValue());
                System.out.println(ageAvg.getValueAsString());
                System.out.println(ageAvg.getMetaData());
                System.out.println(ageAvg.getName());

                System.out.println(&quot;=====================&quot;);
                // 使用ParsedValueCount对象接收
                ParsedValueCount count = bucket.getAggregations().get(&quot;count&quot;);
                System.out.println(count.getType());
                System.out.println(count.getValue());
                System.out.println(count.getValueAsString());
                System.out.println(count.getMetaData());
                System.out.println(count.getName());
            }
        } catch (IOException e) {
            e.printStackTrace();
        }
    }
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;最后还有分词查询，分词查询就不加&lt;code&gt;.keyword&lt;/code&gt;关键字即可。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;@Override
    public List&amp;lt;Student&amp;gt; searchMatch(String matchStudentName) {
        List&amp;lt;Student&amp;gt; list = new ArrayList&amp;lt;&amp;gt;();
        BoolQueryBuilder boolQueryBuilder = QueryBuilders.boolQuery();
        // 分词查询时不加'.keyword'关键字
        boolQueryBuilder.must(QueryBuilders.matchQuery(&quot;studentName&quot;,matchStudentName));
        SearchSourceBuilder searchSourceBuilder = new SearchSourceBuilder();
        searchSourceBuilder.query(boolQueryBuilder);
        SearchRequest searchRequest = new SearchRequest(&quot;student_info&quot;);
        searchRequest.source(searchSourceBuilder);
        try {
            SearchResponse search = restHighLevelClient.search(searchRequest, RequestOptions.DEFAULT);
            for (SearchHit hit : search.getHits().getHits()) {
                String source = hit.getSourceAsString();
                Student student = gson.fromJson(source, Student.class);
                list.add(student);
            }

        } catch (IOException e) {
            e.printStackTrace();
        }
        return list;
    }
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;请记住，一般的进行分词都是字符串才进行分词搜索，数字等类型只能是精准匹配。&lt;/p&gt;
&lt;p&gt;最后，ES功能很强大，作为搜索界的扛把子，ES的功能远远不止这些，它还可以高亮搜索，数据分析等等。我在这里演示的仅仅只是皮毛，甚至都不是皮毛，仅作为初学者的参考。如有大佬觉得我哪里写错了，或者有不同见解，欢迎留言。&lt;/p&gt;
&lt;/li&gt;
&lt;/div&gt;&lt;p&gt;此教程会一直更新下去，觉得博主写的可以的话，关注一下，也可以更方便下次来学习。&lt;/p&gt;</description>
<pubDate>Tue, 09 Jun 2020 14:45:00 +0000</pubDate>
<dc:creator>Butterfly-Tri</dc:creator>
<og:description>1. Elasticsearch简介 Elasticsearch是一个基于Lucene的搜索服务器。它提供了一个分布式多用户能力的全文搜索引擎，基于RESTful web接口。Elasticsearc</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/Butterfly-Tri/p/13081498.html</dc:identifier>
</item>
<item>
<title>[原创][开源] SunnyUI.Net 主题 - yhuse</title>
<link>http://www.cnblogs.com/yhuse/p/SunnyUI_Style.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/yhuse/p/SunnyUI_Style.html</guid>
<description>&lt;p&gt;SunnyUI为了避免视觉传达差异，使用一套特定的调色板来规定颜色，为你所搭建的产品提供一致的外观视觉感受。 主色 SunnyUI主要品牌颜色是鲜艳、友好的蓝色。&lt;/p&gt;&lt;div id=&quot;cnblogs_post_body&quot; readability=&quot;85.825037707391&quot;&gt;
&lt;h3 class=&quot;demo&quot;&gt;&lt;span&gt;SunnyUI.Net, 基于 C# .Net WinForm 开源控件库、工具类库、扩展类库、多页面开发框架&lt;/span&gt;&lt;/h3&gt;
&lt;p class=&quot;ql-long-11868091&quot;&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/398709/202005/398709-20200518230436949-1792928639.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;h3 class=&quot;Abstract&quot;&gt;主题&lt;/h3&gt;
&lt;p&gt;
&lt;h3 class=&quot;First&quot;&gt;1、Color 色彩&lt;/h3&gt;
&lt;/p&gt;
&lt;p class=&quot;ql-long-11868091&quot;&gt;&lt;span class=&quot;ql-font-microsoftyahei ql-author-11868091&quot;&gt;SunnyUI为了避免视觉传达差异，使用一套特定的调色板来规定颜色，为你所搭建的产品提供一致的外观视觉感受。主要颜色参照Element（&lt;a class=&quot;ql-link ql-author-11868091&quot; href=&quot;https://element.eleme.cn/&quot; rel=&quot;noopener noreferrer nofollow&quot; target=&quot;_blank&quot;&gt;https://element.eleme.cn/&lt;/a&gt;&lt;span class=&quot;ql-font-microsoftyahei ql-author-11868091&quot;&gt;）&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p class=&quot;ql-long-11868091&quot;&gt;&lt;span class=&quot;ql-font-microsoftyahei ql-author-11868091&quot;&gt;SunnyUI主要品牌颜色是鲜艳、友好的蓝色。&lt;/span&gt;&lt;/p&gt;
&lt;p class=&quot;ql-long-11868091&quot;&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/398709/202006/398709-20200609221820870-2000192072.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;

&lt;p class=&quot;ql-long-11868091&quot;&gt;&lt;span class=&quot;ql-font-microsoftyahei ql-author-11868091&quot;&gt;除了主色外的场景色，需要在不同的场景中使用（例如红色表示危险的操作）。&lt;/span&gt;&lt;/p&gt;
&lt;p class=&quot;ql-long-11868091&quot;&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/398709/202006/398709-20200609221828335-1959326557.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;

&lt;p class=&quot;ql-long-11868091&quot;&gt;&lt;span class=&quot;ql-font-microsoftyahei ql-author-11868091&quot;&gt;中性色用于文本、背景和边框颜色。通过运用不同的中性色，来表现层次结构。&lt;/span&gt;&lt;/p&gt;
&lt;p class=&quot;ql-long-11868091&quot;&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/398709/202006/398709-20200609221836770-563770915.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;

&lt;h3 class=&quot;First&quot;&gt;2、Rect边框&lt;/h3&gt;
&lt;p class=&quot;ql-long-11868091&quot;&gt;&lt;span class=&quot;ql-font-microsoftyahei ql-author-11868091&quot;&gt;我们对边框进行统一规范，可用于按钮、卡片、弹窗等组件里。&lt;/span&gt;&lt;/p&gt;
&lt;p class=&quot;ql-long-11868091&quot;&gt;&lt;span class=&quot;ql-author-11868091&quot;&gt;主要属性如下：&lt;/span&gt;&lt;/p&gt;
&lt;p class=&quot;ql-long-11868091&quot;&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/398709/202006/398709-20200609221846519-1022130315.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li class=&quot;ql-long-11868091&quot;&gt;&lt;span class=&quot;ql-author-11868091&quot;&gt;RectColor：边框颜色&lt;/span&gt;&lt;/li&gt;
&lt;li class=&quot;ql-long-11868091&quot;&gt;&lt;span class=&quot;ql-author-11868091&quot;&gt;RectDisableColor：控件不可用时边框颜色&lt;/span&gt;&lt;/li&gt;
&lt;li class=&quot;ql-long-11868091&quot;&gt;&lt;span class=&quot;ql-author-11868091&quot;&gt;RectSides：边框显示方向&lt;/span&gt;&lt;/li&gt;
&lt;li class=&quot;ql-long-11868091 ql-text-indent-1&quot;&gt;&lt;span class=&quot;ql-author-11868091&quot;&gt;无：不显示边框&lt;/span&gt;&lt;/li&gt;
&lt;li class=&quot;ql-long-11868091 ql-text-indent-1&quot;&gt;&lt;span class=&quot;ql-author-11868091&quot;&gt;全部：显示全部边框&lt;/span&gt;&lt;/li&gt;
&lt;li class=&quot;ql-long-11868091 ql-text-indent-1&quot;&gt;&lt;span class=&quot;ql-author-11868091&quot;&gt;顶：显示顶部边框&lt;/span&gt;&lt;/li&gt;
&lt;li class=&quot;ql-long-11868091 ql-text-indent-1&quot;&gt;&lt;span class=&quot;ql-author-11868091&quot;&gt;底：显示底部边框&lt;/span&gt;&lt;/li&gt;
&lt;li class=&quot;ql-long-11868091 ql-text-indent-1&quot;&gt;&lt;span class=&quot;ql-author-11868091&quot;&gt;左：显示左侧边框&lt;/span&gt;&lt;/li&gt;
&lt;li class=&quot;ql-long-11868091 ql-text-indent-1&quot;&gt;&lt;span class=&quot;ql-author-11868091&quot;&gt;右：显示右侧边框&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p class=&quot;ql-long-11868091 ql-text-indent-1&quot;&gt;&lt;strong&gt;&lt;span class=&quot;ql-author-11868091&quot;&gt;注：边框显示和圆角设置相关，如果一侧的边框两端端点为圆角，则此边框必定显示。&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;h3 class=&quot;First&quot;&gt;3、Radius圆角&lt;/h3&gt;
&lt;p class=&quot;ql-long-11868091&quot;&gt;&lt;span class=&quot;ql-font-microsoftyahei ql-author-11868091&quot;&gt;我们提供了以下几种圆角样式，以供选择。默认圆角大小为5px。&lt;/span&gt;&lt;/p&gt;
&lt;p class=&quot;ql-long-11868091&quot;&gt;&lt;span class=&quot;ql-author-11868091&quot;&gt;主要属性如下：&lt;/span&gt;&lt;/p&gt;
&lt;p class=&quot;ql-long-11868091&quot;&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/398709/202006/398709-20200609221856796-1231664121.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p class=&quot;ql-long-11868091&quot;&gt;&lt;span class=&quot;ql-author-11868091&quot;&gt;Radius：圆角大小&lt;/span&gt;&lt;/p&gt;
&lt;p class=&quot;ql-long-11868091&quot;&gt;&lt;span class=&quot;ql-author-11868091&quot;&gt;RadiusSides：显示四个角圆角的显示与否&lt;/span&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;&lt;span class=&quot;ql-author-11868091&quot;&gt;圆角不显示&lt;/span&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p class=&quot;ql-long-11868091&quot;&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/398709/202006/398709-20200609221905343-324020068.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;span&gt;&lt;strong&gt;&lt;span class=&quot;ql-author-11868091&quot;&gt;默认圆角大小为5px&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p class=&quot;ql-long-11868091&quot;&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/398709/202006/398709-20200609221911714-1644484414.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;span&gt;&lt;strong&gt;&lt;span class=&quot;ql-author-11868091&quot;&gt;圆角大小与控件高度相等时，显示大圆角&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p class=&quot;ql-long-11868091&quot;&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/398709/202006/398709-20200609221921769-1441408143.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;span&gt;&lt;strong&gt;&lt;span class=&quot;ql-author-11868091&quot;&gt;可通过四个角圆角的设置，对控件组合显示&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p class=&quot;ql-long-11868091&quot;&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/398709/202006/398709-20200609221931808-397869888.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;

&lt;h3 class=&quot;First&quot;&gt;4、Font字体&lt;/h3&gt;
&lt;p class=&quot;ql-long-11868091&quot;&gt;&lt;span class=&quot;ql-author-11868091&quot;&gt;默认字体为：微软雅黑, 12pt&lt;/span&gt;&lt;/p&gt;
&lt;p class=&quot;ql-long-11868091&quot;&gt; &lt;/p&gt;
&lt;h3 class=&quot;First&quot;&gt;5、Style主题&lt;/h3&gt;
&lt;p class=&quot;ql-long-11868091&quot;&gt;&lt;span class=&quot;ql-author-11868091&quot;&gt;SunnyUI&lt;span class=&quot;ql-size-12 ql-author-11868091&quot;&gt;包含 Element 风格主题 11 个，DotNetBar 主题 3 个，其他主题 2 个，包含主题管理组件 UIStyleManager，可自由切换主题。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;span&gt;&lt;strong&gt; &lt;span class=&quot;ql-size-12 ql-author-11868091&quot;&gt;UIStyleManager&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p class=&quot;ql-long-11868091&quot;&gt;&lt;span class=&quot;ql-size-12 ql-author-11868091&quot;&gt;参考SunnyUI.Demo.exe，将UIStyleManager放置在主窗体上，通过选择UIStyleManager的属性Style，或者通过代码设置统一主题风格。&lt;/span&gt;&lt;/p&gt;
&lt;p class=&quot;ql-long-11868091&quot;&gt;&lt;span class=&quot;ql-size-12 ql-author-11868091&quot;&gt;UIStyleManager&lt;span class=&quot;ql-author-11868091&quot;&gt;.Style = style;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt; &lt;/span&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;&lt;span class=&quot;ql-author-11868091&quot;&gt;Style主要属性如下：&lt;/span&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p class=&quot;ql-long-11868091&quot;&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/398709/202006/398709-20200609221941316-420417360.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p class=&quot;ql-long-11868091&quot;&gt;&lt;span class=&quot;ql-author-11868091&quot;&gt;Style：设置主题风格&lt;/span&gt;&lt;/p&gt;
&lt;p class=&quot;ql-long-11868091&quot;&gt;&lt;span class=&quot;ql-author-11868091&quot;&gt;StyleCustomMode：是否为自定义主题，设置为False时使用&lt;span class=&quot;ql-size-12 ql-author-11868091&quot;&gt;UIStyleManager提供的统一主题风格，设置为Ture时可手动调整控件配色，不受UIStyleManager约束。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;ul&gt;&lt;li&gt;&lt;span&gt;&lt;span class=&quot;ql-author-11868091&quot;&gt;UIStyle.Blue&lt;/span&gt;&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p class=&quot;ql-long-11868091&quot;&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/398709/202006/398709-20200609222004595-1832051078.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;span class=&quot;ql-author-11868091&quot;&gt;UIStyle.Green&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p class=&quot;ql-long-11868091&quot;&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/398709/202006/398709-20200609222013954-771287144.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;span class=&quot;ql-author-11868091&quot;&gt;UIStyle.Orange&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p class=&quot;ql-long-11868091&quot;&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/398709/202006/398709-20200609222020916-81374800.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;span class=&quot;ql-author-11868091&quot;&gt;UIStyle.Red&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p class=&quot;ql-long-11868091&quot;&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/398709/202006/398709-20200609222028605-1636418009.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;span class=&quot;ql-author-11868091&quot;&gt;UIStyle.Gray&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p class=&quot;ql-long-11868091&quot;&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/398709/202006/398709-20200609222036185-373049292.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;span class=&quot;ql-author-11868091&quot;&gt;UIStyle.White&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p class=&quot;ql-long-11868091&quot;&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/398709/202006/398709-20200609222046693-818573951.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;span class=&quot;ql-author-11868091&quot;&gt;UIStyle.DarkBlue&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p class=&quot;ql-long-11868091&quot;&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/398709/202006/398709-20200609222054982-1320458245.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;span class=&quot;ql-author-11868091&quot;&gt;UIStyle.Black&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p class=&quot;ql-long-11868091&quot;&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/398709/202006/398709-20200609222101934-1360660565.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;span class=&quot;ql-author-11868091&quot;&gt;UIStyle.Office2010Blue&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p class=&quot;ql-long-11868091&quot;&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/398709/202006/398709-20200609222111015-983627257.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;span class=&quot;ql-author-11868091&quot;&gt;UIStyle.Office2010Silver&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p class=&quot;ql-long-11868091&quot;&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/398709/202006/398709-20200609222118350-504685345.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;span class=&quot;ql-author-11868091&quot;&gt;UIStyle.Office2010Black&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p class=&quot;ql-long-11868091&quot;&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/398709/202006/398709-20200609222127568-2130472505.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;

&lt;h3 class=&quot;note&quot;&gt;原创文章，转载请保留链接 &lt;a title=&quot;Sunny's blog&quot; href=&quot;http://www.cnblogs.com/yhuse&quot; target=&quot;_blank&quot;&gt;Sunny's blog&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;</description>
<pubDate>Tue, 09 Jun 2020 14:33:00 +0000</pubDate>
<dc:creator>yhuse</dc:creator>
<og:description>SunnyUI为了避免视觉传达差异，使用一套特定的调色板来规定颜色，为你所搭建的产品提供一致的外观视觉感受。 主色 SunnyUI主要品牌颜色是鲜艳、友好的蓝色。</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/yhuse/p/SunnyUI_Style.html</dc:identifier>
</item>
</channel>
</rss>