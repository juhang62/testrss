<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="css/feed.xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/" xmlns:og="http://ogp.me/ns#">
<channel>
<atom:link rel="self" href="http://192.168.1.4/fivefilters/makefulltextfeed.php?url=feed.cnblogs.com%2Fblog%2Fsitehome%2Frss&amp;max=10&amp;links=preserve&amp;exc=" />
<atom:link rel="alternate" title="Source URL" href="http://feed.cnblogs.com/blog/sitehome/rss" />
<atom:link rel="related" title="Subscribe to feed" href="http://www.subtome.com/#/subscribe?feeds=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed.cnblogs.com%252Fblog%252Fsitehome%252Frss%26max%3D10%26links%3Dpreserve%26exc%3D&amp;back=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed.cnblogs.com%252Fblog%252Fsitehome%252Frss%26max%3D10%26links%3Dpreserve%26exc%3D" />
<title>博客园_首页</title>
<link></link>
<description>代码改变世界</description>
<item>
<title>2018年我跑去做淘宝了然后就随意总结了下 - 公羽翁</title>
<link>http://www.cnblogs.com/PleaseInputEnglish/p/10224753.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/PleaseInputEnglish/p/10224753.html</guid>
<description>&lt;h2 id=&quot;开篇&quot;&gt;开篇&lt;/h2&gt;
&lt;p&gt;根据往常惯例，依然还是需要对2018年的经历做一下总结，其实仔细想想，已经有点把博客园当成了自己另外一个家了，已经好久没有更新技术类的文章了，但是习惯了博客园，也在上面写了这么多文章，觉得自己离不开了，是不是技术文章又有什么关系呢？反正我又不是为了圈粉才写文章的。&lt;/p&gt;
&lt;h2 id=&quot;年经济上的经历&quot;&gt;18年经济上的经历&lt;/h2&gt;
&lt;ul&gt;&lt;li&gt;2018年大家都知道发生了贸易战，作为贸易战的牺牲者，大概亏损了资产的15%左右。&lt;/li&gt;
&lt;li&gt;然后这一年也深刻的意识到买房致富不是说说，现在回想当年的房子卖了后没有马上买房子。这边的经济损失大概是目前资产的一倍吧。&lt;/li&gt;
&lt;li&gt;在今年9月份左右狠下心来。想着钱留在身边也没什么用，商品房是买不起了（作为二三线城市下的一个小县城这边动则二三百万的房价不是尔等屌丝可以吃得消的，而且还会涨。）。毕竟目前新工作的经济收入还是很差的，于是乎就买了私人房子。&lt;/li&gt;
&lt;li&gt;如今口袋里只剩下了三位数的存款，每个月靠花呗，信用卡过活。&lt;/li&gt;
&lt;li&gt;明年要去银行贷款装修房子了，从口袋里有钱，终于还是走上了负债的道路。&lt;/li&gt;
&lt;/ul&gt;&lt;h2 id=&quot;年事业上的事&quot;&gt;18年事业上的事&lt;/h2&gt;
&lt;ul readability=&quot;1&quot;&gt;&lt;li&gt;18年年初的时候，其实是准备做点什么的，然而最后选择了跑去做淘宝。之所以选择做淘宝的主要原因还是在于想触摸实业，脚踏实地的做点实实在在的“生意”。&lt;/li&gt;
&lt;li&gt;初接触淘宝的时候，认为淘宝一直是有机会做起来的。因为它的规则是一直在更新的，而每一次规则的更新，势必会淘汰一部分人，同时也会有一部分新人起来。而我现在要做的就是在新的规则到来之前，尽快熟悉他历史的规则，追上老手的脚步，这样才有机会在新的规则出来后追上老手，甚至赶超老手。作为一名曾经的程序猿，是不会担心追不上时代的脚步的，毕竟程序猿一族可是拥有超强的学习能力以及紧追新鲜事物的本领的。&lt;/li&gt;
&lt;li&gt;真正接触了淘宝之后才发现现在做一家淘宝店所需要花费的资源实在是太多了，如果没有一定的资金或者资源还是一定要慎重考虑的。&lt;/li&gt;
&lt;li readability=&quot;1&quot;&gt;
&lt;p&gt;今年总体来说店铺的增长还是达到预期的。由于是小类目，同行店铺也不多，今年已经顺利做到行业同店铺前20左右了，19年的目标就是前15-10左右的位置。20年的目标就是行业前10-5了。努力努力 奋斗奋斗。&lt;/p&gt;
&lt;h2 id=&quot;做淘宝当中干了些啥&quot;&gt;做淘宝当中干了些啥&lt;/h2&gt;
该部分主要总结一下这一年我做淘宝都干了些什么以及个人对于淘宝的一些看法。各位不想看的就可以跳过咯&lt;/li&gt;
&lt;li readability=&quot;-0.5&quot;&gt;
&lt;p&gt;免费流量不可能了&lt;/p&gt;
&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;如今的淘宝已经不是很多免费商家可以操作的了，并不是说免费流量没有，而是免费流量所需要付出的成本已经非常高了，不再是你开个店起来它就有流量给你。如果你想要获取更多的流量，那么你必须要做文章、做视频、做直播等等。如果这些都不会那么只能花钱买流量了。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li readability=&quot;1.5&quot;&gt;
&lt;p&gt;搜索竞争--直通车--竞价排名&lt;/p&gt;
&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;直通车属于搜索竞价排名，里面的算法相对于百度的要合理很多，百度的竞价排名纯粹就是看谁出钱高，而淘宝的竞价系统则考虑了更多商品因素，如果你的商铺的综合评分不高那么你就必须要花更多的钱来获得对应的搜索流量，而对于本身综合评分高的产品相对的所需要的费用就会少了。&lt;br/&gt;另外我发现的一个问题就是广告投放一旦开始投入就很难停下来，目前我实测的结果就是我广告一停，要么没有流量了，要么就是流量还有，但是流量不精准了。吓的我赶紧加大了广告投入。&lt;br/&gt;由于今年刚开始做，今年在直通车上面花了大概一辆思域的钱，19年估计要花一辆奔驰的钱，20年大概要花一辆保时捷的钱。&lt;br/&gt;&lt;strong&gt;世界上最贵的车并不是什么法拉利保时捷，而是淘宝的直通车。&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li readability=&quot;1&quot;&gt;
&lt;p&gt;展示竞争--钻石展位--广告投放&lt;/p&gt;
&lt;blockquote readability=&quot;7&quot;&gt;
&lt;p&gt;钻石展位主要是做展示类广告。也是一个烧钱的大户，但是如果钻展跟直通车两个都能操作的好的话那么产品还卖不起来的话只能说是产品本身的问题了。而今年我也就主要研究了这两个东西。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li readability=&quot;-0.5&quot;&gt;
&lt;p&gt;刷单&lt;/p&gt;
&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;做淘宝的基本就逃不开刷单，不刷死，刷也死，这就是现在很多店铺的实际现状，因为店家太多了。虽然淘宝推出了千人千面，但是还是避免不了大批量的刷单出现。而对于我所在的行业的小类目来说，刷单真的比正常操作要划算多了。因为纯粹从刷单的投入跟产出来看明显要比直通车还有钻展好太多了。而我则亲眼看着我行业里的另外两个店铺靠刷单起来。明眼人一看就知道是刷单的。销量500评价400，都这个年代了哪还有这么多人评价？&lt;br/&gt;而淘宝的态度呢？大类目会抓。而像我所在的小类目，淘宝根本不管你。所以刷单还是有效的。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;h2 id=&quot;展望19年&quot;&gt;展望19年&lt;/h2&gt;
&lt;p&gt;啰啰嗦嗦的说了一堆。纯粹就瞎扯吧，对于19年的目标也就主要集中在以下几个方面&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;事业方面&lt;br/&gt;1.1. 店铺的营业额要翻倍成长&lt;br/&gt;1.2 完成一个秘密的小目标&lt;/li&gt;
&lt;li&gt;生活方面&lt;br/&gt;2.1. 看更多的书（18年由于转行做淘宝看了不少运营的书还是不错的）&lt;br/&gt;2.2. 装修房子&lt;br/&gt;2.3. 拍个照哈哈&lt;/li&gt;
&lt;/ol&gt;</description>
<pubDate>Sat, 05 Jan 2019 07:43:00 +0000</pubDate>
<dc:creator>公羽翁</dc:creator>
<og:description>2018年总结 开篇 根据往常惯例，依然还是需要对2018年的经历做一下总结，其实仔细想想，已经有点把博客园当成了自己另外一个家了，已经好久没有更新技术类的文章了，但是习惯了博客园，也在上面写了这么多</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/PleaseInputEnglish/p/10224753.html</dc:identifier>
</item>
<item>
<title>Java集合-09LinkedHashMap源码解析及使用实例 - Jzedy</title>
<link>http://www.cnblogs.com/JzedyBlogs/p/10224743.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/JzedyBlogs/p/10224743.html</guid>
<description>&lt;h2 id=&quot;linkedhashmap-简介&quot;&gt;LinkedHashMap 简介&lt;/h2&gt;
&lt;blockquote readability=&quot;7&quot;&gt;
&lt;p&gt;hash表和链表实现了map接口，迭代顺序是可以预测的。LinkedHashMap和HashMap的不同是它所有的entry&lt;br/&gt;维持了一个双向链表结构。该链表定义了通常迭代顺序是键插入的顺序。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;linkedhashmap-定义&quot;&gt;LinkedHashMap 定义&lt;/h2&gt;
&lt;p&gt;public class LinkedHashMap&amp;lt;K,V&amp;gt; extends HashMap&amp;lt;K,V&amp;gt; implements Map&amp;lt;K,V&amp;gt;&lt;/p&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;继承HashMap类，表明对于HashMap的操作LinkedHashMap都支持&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;linkedhashmap-结构图&quot;&gt;LinkedHashMap 结构图&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;https://github.com/Jzedy/Z-books/blob/master/src/main/image/LinkedHashMap.png?raw=true&quot; alt=&quot;LinkedHashMap 结构图&quot;/&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;属性解析&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;&lt;li&gt;transient LinkedHashMap.Entry&amp;lt;K,V&amp;gt; head;//链表头部&lt;/li&gt;
&lt;li&gt;transient LinkedHashMap.Entry&amp;lt;K,V&amp;gt; tail;//链表尾部&lt;/li&gt;
&lt;li&gt;final boolean accessOrder;//标明LinkedHashMap迭代顺序：true代表按照最近使用排序，false表示按照插入顺序排序&lt;/li&gt;
&lt;/ul&gt;&lt;h2 id=&quot;linkedhashmap-构造函数&quot;&gt;LinkedHashMap 构造函数&lt;/h2&gt;
&lt;ol readability=&quot;3&quot;&gt;&lt;li readability=&quot;-2&quot;&gt;
&lt;p&gt;public LinkedHashMap()&lt;/p&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;创建一个初始容量为16，加载因子为0.75，按照插入顺序迭代的Map&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li readability=&quot;0.5&quot;&gt;
&lt;p&gt;public LinkedHashMap(int initialCapacity)&lt;/p&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;创建一个初始容量为initialCapacity大小，加载因子为0.75，按照插入顺序迭代的Map&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li readability=&quot;1.5&quot;&gt;
&lt;p&gt;public LinkedHashMap(int initialCapacity, float loadFactor)&lt;/p&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;创建一个初始容量为initialCapacity大小，加载因子为loadFactor，按照插入顺序迭代的Map&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li readability=&quot;1&quot;&gt;
&lt;p&gt;public LinkedHashMap(Map&amp;lt;? extends K, ? extends V&amp;gt; m)&lt;/p&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;创建一个加载因子为0.75，包含m的键值对的Map&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li readability=&quot;2.5&quot;&gt;
&lt;p&gt;public LinkedHashMap(int initialCapacity,float loadFactor,boolean accessOrder)&lt;/p&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;创建一个初始容量为16，加载因子为0.75，accessOrder为true时为使用按照最近使用顺序迭代，false为插入顺序迭代的Map&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;/ol&gt;&lt;h2 id=&quot;linkedhashmap-源码分析&quot;&gt;LinkedHashMap 源码分析&lt;/h2&gt;
&lt;pre&gt;
&lt;code&gt;static class Entry&amp;lt;K,V&amp;gt; extends HashMap.Node&amp;lt;K,V&amp;gt; {
    Entry&amp;lt;K,V&amp;gt; before, after;
    Entry(int hash, K key, V value, Node&amp;lt;K,V&amp;gt; next) {
        super(hash, key, value, next);
    }
}&lt;/code&gt;
&lt;/pre&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;LinkedHashMap较于HashMap中Entry多了两个属性，before和after，从而维护了一个双向链表，&lt;br/&gt;同时类中的head和tail分别指向链表的头部和尾部&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;&lt;li readability=&quot;-1.5&quot;&gt;
&lt;p&gt;put&lt;/p&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;LinkedHashMap没有重写HashMap中的put方法。但是重写了构建新节点的newNode()方法，该方法会在&lt;br/&gt;HashMap的putVal()中调用&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;pre&gt;
&lt;code&gt;Node&amp;lt;K,V&amp;gt; newNode(int hash, K key, V value, Node&amp;lt;K,V&amp;gt; e) {
    LinkedHashMap.Entry&amp;lt;K,V&amp;gt; p =
        new LinkedHashMap.Entry&amp;lt;K,V&amp;gt;(hash, key, value, e);
    linkNodeLast(p);
    return p;
}&lt;/code&gt;
&lt;/pre&gt;
&lt;pre&gt;
&lt;code&gt;private void linkNodeLast(LinkedHashMap.Entry&amp;lt;K,V&amp;gt; p) {//p添加到双向链表的尾部
    LinkedHashMap.Entry&amp;lt;K,V&amp;gt; last = tail;
    tail = p;//链表最后一个节点指向新增的Entry
    if (last == null)//如果原来链表最后一个节点为null，表明双向链表为空
        head = p;//双向链表的头节点指向新增节点p
    else {//表明原链表不为空
        p.before = last;//p的前一个节点指向原链表最后一个节点
        last.after = p;//原最后一个节点的后一节点指向p
    }
}&lt;/code&gt;
&lt;/pre&gt;
&lt;blockquote readability=&quot;7&quot;&gt;
&lt;p&gt;同时LinkedHashMap重写了HashMap中void afterNodeAccess(Node&amp;lt;K,V&amp;gt; p) { }和void afterNodeInsertion(boolean evict) { }方法&lt;/p&gt;
&lt;/blockquote&gt;
&lt;pre&gt;
&lt;code&gt;void afterNodeAccess(Node&amp;lt;K,V&amp;gt; e) { // move node to last
    LinkedHashMap.Entry&amp;lt;K,V&amp;gt; last;
    if (accessOrder &amp;amp;&amp;amp; (last = tail) != e) {//对于accessOrder为true时候，将该Node移动到链表的最后位置，保证了遍历时候按照访问顺序迭代
        LinkedHashMap.Entry&amp;lt;K,V&amp;gt; p =
            (LinkedHashMap.Entry&amp;lt;K,V&amp;gt;)e, b = p.before, a = p.after;
        p.after = null;
        if (b == null)
            head = a;
        else
            b.after = a;
        if (a != null)
            a.before = b;
        else
            last = b;
        if (last == null)
            head = p;
        else {
            p.before = last;
            last.after = p;
        }
        tail = p;
        ++modCount;
    }
}&lt;/code&gt;
&lt;/pre&gt;
&lt;pre&gt;
&lt;code&gt;//需要说明的是这个方法中removeEldestEntry方法在LinkedHashMap是返回false的，故对于后续操作
//没有意义，通常构建一个LruCache会在达到Cache的上限是返回true
void afterNodeInsertion(boolean evict) { // possibly remove eldest
    LinkedHashMap.Entry&amp;lt;K,V&amp;gt; first;
    if (evict &amp;amp;&amp;amp; (first = head) != null &amp;amp;&amp;amp; removeEldestEntry(first)) {
        K key = first.key;
        removeNode(hash(key), key, null, false, true);
    }
}

protected boolean removeEldestEntry(Map.Entry&amp;lt;K,V&amp;gt; eldest) {
    return false;
}&lt;/code&gt;
&lt;/pre&gt;
&lt;ul&gt;&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;remove&lt;/p&gt;
&lt;blockquote readability=&quot;7&quot;&gt;
&lt;p&gt;LinkedHashMap中也没有重写remove方法，但是重写了HashMap中空方法void afterNodeRemoval(Node&amp;lt;K,V&amp;gt; p) { }&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;pre&gt;
&lt;code&gt;//删除节点e时，删除链表中节点e
void afterNodeRemoval(Node&amp;lt;K,V&amp;gt; e) { // unlink
    LinkedHashMap.Entry&amp;lt;K,V&amp;gt; p =
        (LinkedHashMap.Entry&amp;lt;K,V&amp;gt;)e, b = p.before, a = p.after;
    p.before = p.after = null;
    if (b == null)
        head = a;
    else
        b.after = a;
    if (a == null)
        tail = b;
    else
        a.before = b;
}&lt;/code&gt;
&lt;/pre&gt;
&lt;ul&gt;&lt;li readability=&quot;-2&quot;&gt;
&lt;p&gt;get&lt;/p&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;LinkedHashMap中重写了get方法&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;pre&gt;
&lt;code&gt;public V get(Object key) {
    Node&amp;lt;K,V&amp;gt; e;
    if ((e = getNode(hash(key), key)) == null)//查询时候使用HashMap的getNode方法
        return null;
    if (accessOrder)//如果accessOrder为true，调整链表中对应节点位置，保证遍历时候按照访问时间顺序迭代
        afterNodeAccess(e);
    return e.value;
}&lt;/code&gt;
&lt;/pre&gt;
&lt;ul&gt;&lt;li readability=&quot;-2&quot;&gt;
&lt;p&gt;遍历&lt;/p&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;LinkedHashMap重写了entrySet方法&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;pre&gt;
&lt;code&gt;public Set&amp;lt;Map.Entry&amp;lt;K,V&amp;gt;&amp;gt; entrySet() {
    Set&amp;lt;Map.Entry&amp;lt;K,V&amp;gt;&amp;gt; es;
    return (es = entrySet) == null ? (entrySet = new LinkedEntrySet()) : es;
}

final class LinkedEntrySet extends AbstractSet&amp;lt;Map.Entry&amp;lt;K,V&amp;gt;&amp;gt;{
//省略部分代码
    public final Iterator&amp;lt;Map.Entry&amp;lt;K,V&amp;gt;&amp;gt; iterator() {
            return new LinkedEntryIterator();
        }
}

final class LinkedEntryIterator extends LinkedHashIterator
    implements Iterator&amp;lt;Map.Entry&amp;lt;K,V&amp;gt;&amp;gt; {
    public final Map.Entry&amp;lt;K,V&amp;gt; next() { return nextNode(); }
}

abstract class LinkedHashIterator {
    LinkedHashMap.Entry&amp;lt;K,V&amp;gt; next;
    LinkedHashMap.Entry&amp;lt;K,V&amp;gt; current;
    int expectedModCount;

    LinkedHashIterator() {
        next = head;
        expectedModCount = modCount;
        current = null;
    }

    public final boolean hasNext() {
        return next != null;
    }

    final LinkedHashMap.Entry&amp;lt;K,V&amp;gt; nextNode() {
        LinkedHashMap.Entry&amp;lt;K,V&amp;gt; e = next;
        if (modCount != expectedModCount)
            throw new ConcurrentModificationException();
        if (e == null)
            throw new NoSuchElementException();
        current = e;
        next = e.after;
        return e;
    }

    public final void remove() {
        Node&amp;lt;K,V&amp;gt; p = current;
        if (p == null)
            throw new IllegalStateException();
        if (modCount != expectedModCount)
            throw new ConcurrentModificationException();
        current = null;
        K key = p.key;
        removeNode(hash(key), key, null, false, false);
        expectedModCount = modCount;
    }
}&lt;/code&gt;
&lt;/pre&gt;
&lt;blockquote readability=&quot;7&quot;&gt;
&lt;p&gt;最终可以看出迭代时候从&lt;strong&gt;内部维护的双向链表的表头开始遍历&lt;/strong&gt;，同时双向链表的顺序在&lt;strong&gt;LinkedHashMap的增、删、改、查时候都会维护，保证了遍历时候按照插入顺序或者访问时间顺序迭代&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
</description>
<pubDate>Sat, 05 Jan 2019 07:41:00 +0000</pubDate>
<dc:creator>Jzedy</dc:creator>
<og:description>LinkedHashMap 简介 hash表和链表实现了map接口，迭代顺序是可以预测的。LinkedHashMap和HashMap的不同是它所有的entry 维持了一个双向链表结构。该链表定义了通常</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/JzedyBlogs/p/10224743.html</dc:identifier>
</item>
<item>
<title>使用redis防止商品超发 - 李思琼</title>
<link>http://www.cnblogs.com/lisqiong/p/10223470.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/lisqiong/p/10223470.html</guid>
<description>&lt;ul&gt;&lt;li&gt;redis不仅仅是单纯的缓存，它还有一些特殊的功能，在一些特殊场景上很好用。redis中key的原子自增incrby和判断key不存在再写入的setnx方法，可以有效的防止超发。&lt;/li&gt;
&lt;li&gt;下面使用两个不同的方式来说明利用redis做商品购买库存数量限制。&lt;/li&gt;
&lt;li&gt;业务场景很简单，就是限制抢购5个商品，模拟并发请求抢购商品，每抢购一次对应redis中的key值增加一次，通过判断限购的数量来限制抢购，抢购成功写入成功日志，失败写入失败的信息记录，通过记录的数量来判断是否超发。&lt;/li&gt;
&lt;/ul&gt;&lt;h3 id=&quot;文件index.php&quot;&gt;文件index.php&lt;/h3&gt;
&lt;pre&gt;
&lt;code&gt;&amp;lt;?php
require_once './myRedis.php';
require_once './function.php';

class sendAward{
    public $conf = [];
    const V1 = 'way1';//版本一
    const V2 = 'way2';//版本二
    const AMOUNTLIMIT = 5;//抢购数量限制
    const INCRAMOUNT = 1;//redis递增数量值
    
    //初始化调用对应方法执行商品发放
    public function __construct($conf,$type){
        $this-&amp;gt;conf = $conf;
        if(empty($type))
            return '';
        if($type==self::V1){
            $this-&amp;gt;way1(self::V1);
        }elseif($type==self::V2){
            $this-&amp;gt;way2(self::V2);
        }else{
            return '';
        }
    }
    
    //抢购商品方式一
    protected  function way1($v){
        $redis = new myRedis($this-&amp;gt;conf);      
        $keyNmae = getKeyName($v);
        if(!$redis-&amp;gt;exists($keyNmae)){
            $redis-&amp;gt;set($keyNmae,0);
        }
        $currAmount = $redis-&amp;gt;get($keyNmae);
        if(($currAmount+self::INCRAMOUNT)&amp;gt;self::AMOUNTLIMIT){
            writeLog(&quot;没有抢到商品&quot;,$v);
            return;
        }
        $redis-&amp;gt;incrby($keyNmae,self::INCRAMOUNT);
        writeLog(&quot;抢到商品&quot;,$v);
    }
    
    //抢购商品方式二
    protected function way2($v){
        $redis = new myRedis($this-&amp;gt;conf);
        $keyNmae = getKeyName($v);
        if(!$redis-&amp;gt;exists($keyNmae)){
            $redis-&amp;gt;setnx($keyNmae,0);
        }
        if($redis-&amp;gt;incrby($keyNmae,self::INCRAMOUNT) &amp;gt; self::AMOUNTLIMIT){
            writeLog(&quot;没有抢到商品&quot;,$v);
            return;
        }
        writeLog(&quot;抢到商品&quot;,$v);
    }
            
}

//实例化调用对应执行方法
$type = isset($_GET['v'])?$_GET['v']:'way1';
$conf = [
    'host'=&amp;gt;'192.168.0.214','port'=&amp;gt;'6379',
    'auth'=&amp;gt;'test','db'=&amp;gt;2,
];
new sendAward($conf,$type);

&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;文件myredis.php&quot;&gt;文件myRedis.php&lt;/h3&gt;
&lt;pre&gt;
&lt;code&gt;&amp;lt;?php
/**
 * @desc 自定义redis操作类
 * **/
class myRedis{
    public $handler = NULL;
    public function __construct($conf){
        $this-&amp;gt;handler = new Redis();
        $this-&amp;gt;handler-&amp;gt;connect($conf['host'], $conf['port']); //连接Redis
        //设置密码
        if(isset($conf['auth'])){
            $this-&amp;gt;handler-&amp;gt;auth($conf['auth']); //密码验证
        }
        //选择数据库
        if(isset($conf['db'])){
            $this-&amp;gt;handler-&amp;gt;select($conf['db']);//选择数据库2
        }else{
            $this-&amp;gt;handler-&amp;gt;select(0);//默认选择0库
        }
    }

    //获取key的值
    public function get($name){
        return $this-&amp;gt;handler-&amp;gt;get($name);
    }
    
    //设置key的值
    public function set($name,$value){
        return $this-&amp;gt;handler-&amp;gt;set($name,$value);
    }

    //判断key是否存在
    public function exists($key){
        if($this-&amp;gt;handler-&amp;gt;exists($key)){
            return true;
        }
        return false;
    }

    //当key不存在的设置key的值，存在则不设置
    public function setnx($key,$value){
        return $this-&amp;gt;handler-&amp;gt;setnx($key,$value);
    }

    //将key的数值增加指定数值
    public function incrby($key,$value){
        return $this-&amp;gt;handler-&amp;gt;incrBy($key,$value);
    }
    
}

&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;文件function.php&quot;&gt;文件function.php&lt;/h3&gt;
&lt;pre&gt;
&lt;code&gt;
&amp;lt;?php
//获取商品key名称
function getKeyName($v)
{
    return &quot;send_goods_&quot;.$v;
}

//日志写入方法
function writeLog($msg,$v)
{
    $log = $msg.PHP_EOL;
    file_put_contents(&quot;log/$v.log&quot;,$log,FILE_APPEND);
}
&lt;/code&gt;
&lt;/pre&gt;

&lt;pre&gt;
&lt;code&gt;
[root@localhost oversend]# ab -c 100 -n 200 http://192.168.0.213:8083/index.php?v=way1
This is ApacheBench, Version 2.3 &amp;lt;$Revision: 655654 $&amp;gt;
Copyright 1996 Adam Twiss, Zeus Technology Ltd, http://www.zeustech.net/
Licensed to The Apache Software Foundation, http://www.apache.org/

Benchmarking 192.168.0.213 (be patient)
Completed 100 requests
Completed 200 requests
Finished 200 requests


Server Software:        nginx
Server Hostname:        192.168.0.213
Server Port:            8083

Document Path:          /index.php?v=way1
Document Length:        0 bytes

Concurrency Level:      100
Time taken for tests:   0.089 seconds
Complete requests:      200
Failed requests:        0
Write errors:           0
Total transferred:      30600 bytes
HTML transferred:       0 bytes
Requests per second:    2243.13 [#/sec] (mean)
Time per request:       44.581 [ms] (mean)
Time per request:       0.446 [ms] (mean, across all concurrent requests)
Transfer rate:          335.16 [Kbytes/sec] received

Connection Times (ms)
              min  mean[+/-sd] median   max
Connect:        0    6   2.2      5      17
Processing:     2   28  16.3     25      55
Waiting:        1   26  15.2     24      50
Total:          5   34  16.3     30      60

Percentage of the requests served within a certain time (ms)
  50%     30
  66%     35
  75%     54
  80%     56
  90%     57
  95%     60
  98%     60
  99%     60
 100%     60 (longest request)
&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;v1方法日志分析&quot;&gt;v1方法日志分析&lt;/h3&gt;
&lt;pre&gt;
&lt;code&gt;
[root@localhost log]# less -N way1.log  
      1 抢到商品
      2 抢到商品
      3 抢到商品
      4 抢到商品
      5 抢到商品
      6 抢到商品
      7 没有抢到商品
      8 没有抢到商品
      9 没有抢到商品
     10 没有抢到商品
     11 没有抢到商品
     12 没有抢到商品
&lt;/code&gt;
&lt;/pre&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;观察日志发现 抢到商品的记录有6条超过正常的5条，说明超发了&lt;/p&gt;
&lt;/blockquote&gt;

&lt;pre&gt;
&lt;code&gt;[root@localhost oversend]# ab -c 100 -n 200 http://192.168.0.213:8083/index.php?v=way2
This is ApacheBench, Version 2.3 &amp;lt;$Revision: 655654 $&amp;gt;
Copyright 1996 Adam Twiss, Zeus Technology Ltd, http://www.zeustech.net/
Licensed to The Apache Software Foundation, http://www.apache.org/

Benchmarking 192.168.0.213 (be patient)
Completed 100 requests
Completed 200 requests
Finished 200 requests


Server Software:        nginx
Server Hostname:        192.168.0.213
Server Port:            8083

Document Path:          /index.php?v=way2
Document Length:        0 bytes

Concurrency Level:      100
Time taken for tests:   0.087 seconds
Complete requests:      200
Failed requests:        0
Write errors:           0
Total transferred:      31059 bytes
HTML transferred:       0 bytes
Requests per second:    2311.68 [#/sec] (mean)
Time per request:       43.259 [ms] (mean)
Time per request:       0.433 [ms] (mean, across all concurrent requests)
Transfer rate:          350.58 [Kbytes/sec] received

Connection Times (ms)
              min  mean[+/-sd] median   max
Connect:        0    6   5.4      5      13
Processing:     3   31  16.6     30      70
Waiting:        1   30  16.6     30      70
Total:          5   37  18.5     32      82

Percentage of the requests served within a certain time (ms)
  50%     32
  66%     41
  75%     45
  80%     50
  90%     68
  95%     80
  98%     81
  99%     82
 100%     82 (longest request)
&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;v2方法日志分析&quot;&gt;v2方法日志分析&lt;/h3&gt;
&lt;pre&gt;
&lt;code&gt;[root@localhost log]# less -N v2.log  
[root@localhost log]# less -N way2.log  
      1 抢到商品
      2 抢到商品
      3 抢到商品
      4 抢到商品
      5 没有抢到商品
      6 抢到商品
      7 没有抢到商品
      8 没有抢到商品
      9 没有抢到商品
     10 没有抢到商品&lt;/code&gt;
&lt;/pre&gt;
&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;总结：观察日志可知抢到商品的日志记录是5条并没有超发，说明利用这种方式可以限制住库存的数量。之所以超发是因为方法一中通过加法来判断限制条件的同时，并发一大，就会越过这个判断条件出现会超发，redis的在这方面就体现优势了。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/lisiqiong/phper/tree/master/redis/oversend&quot;&gt;完整代码github地址&lt;/a&gt;&lt;/p&gt;
</description>
<pubDate>Sat, 05 Jan 2019 07:22:00 +0000</pubDate>
<dc:creator>李思琼</dc:creator>
<og:description>redis不仅仅是单纯的缓存，它还有一些特殊的功能，在一些特殊场景上很好用。redis中key的原子自增incrby和判断key不存在再写入的setnx方法，可以有效的防止超发。 下面使用两个不同的方</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/lisqiong/p/10223470.html</dc:identifier>
</item>
<item>
<title>python  结巴分词学习 - join_L</title>
<link>http://www.cnblogs.com/angle6-liu/p/10223957.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/angle6-liu/p/10223957.html</guid>
<description>&lt;p&gt;　　jieba分词算法使用了基于&lt;span&gt;前缀词典&lt;/span&gt;实现高效的词图扫描，生成句子中汉字所有可能生成词情况所构成的有向无环图(DAG), 再采用了动态规划查找最大概率路径，找出基于词频的最大切分组合，对于未登录词，采用了基于汉字成词能力的HMM模型，使用了Viterbi算法。&lt;/p&gt;
&lt;p&gt;jieba分词支持三种分词模式：&lt;/p&gt;
&lt;p&gt;　　1. 精确模式, 试图将句子最精确地切开，适合文本分析：&lt;/p&gt;
&lt;p&gt;　　2. 全模式，把句子中所有的可以成词的词语都扫描出来，速度非常快，但是不能解决歧义；&lt;/p&gt;
&lt;p&gt;　　3. 搜索引擎模式，在精确模式的基础上，对长词再词切分，提高召回率，适合用于搜索引擎分词。&lt;/p&gt;
&lt;h2&gt;一 结巴分词的安装&lt;/h2&gt;
&lt;div class=&quot;cnblogs_code&quot;&gt;
&lt;pre&gt;
pip3 install jieba
&lt;/pre&gt;&lt;/div&gt;

&lt;h2&gt;二 结巴分词的主要功能&lt;/h2&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;35&quot;&gt;
&lt;pre&gt;
1&lt;span&gt;. jieba.cut：该方法接受三个输入参数：
　　参数1：需要分词的字符串; 
　　参数2：cut_all参数用来控制是否采用全模式，默认为精确模式；
          cut_all&lt;/span&gt;=&lt;span&gt;True 全模式
          cut_all&lt;/span&gt;=&lt;span&gt;false 精确（默认）模式
　　参数3：HMM参数用来控制是否适用HMM模型    &lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;div class=&quot;cnblogs_code&quot; readability=&quot;34&quot;&gt;
&lt;pre&gt;
2&lt;span&gt;. jieba.cut_for_search：该方法接受两个参数：
　　参数1：需要分词的字符串；
　　参数2：是否使用HMM模型，
该方法适用于搜索引擎构建倒排索引的分词，粒度比较细。&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;div class=&quot;cnblogs_code&quot; readability=&quot;32&quot;&gt;
&lt;pre&gt;
&lt;span&gt;3. jieba.cut 以及jieba.cut_for_search
返回的结构都是可以得到的generator(生成器)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;div class=&quot;cnblogs_code&quot; readability=&quot;32&quot;&gt;
&lt;pre&gt;
&lt;span&gt;4. jieb.lcut 以及 jieba.lcut_for_search 
直接返回list&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;div class=&quot;cnblogs_code&quot; readability=&quot;33&quot;&gt;
&lt;pre&gt;
5.jieba.Tokenizer(dictionary=DEFUALT_DICT)&lt;br/&gt;新建自定义分词器，&lt;br/&gt;可用于同时使用不同字典，&lt;br/&gt;jieba.dt为默认分词器，所有全局分词相关函数都是该分词器的映射。
&lt;/pre&gt;&lt;/div&gt;

&lt;h2&gt;三 结巴分词的三种模式&lt;/h2&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;33&quot;&gt;
&lt;pre&gt;
&lt;span&gt;import&lt;/span&gt;&lt;span&gt;  jieba

text&lt;/span&gt;=&lt;span&gt;'&lt;/span&gt;&lt;span&gt;赵丽颖主演的正午阳光剧,知否知否应是绿肥红瘦&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h4&gt;&lt;span&gt;1 全模式 cut_all=True&lt;/span&gt;&lt;/h4&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;52&quot;&gt;
&lt;pre&gt;
seq_list=jieba.cut(text,cut_all=&lt;span&gt;True)
&lt;/span&gt;&lt;span&gt;print&lt;/span&gt;(seq_list) &lt;span&gt;#&lt;/span&gt;&lt;span&gt;&amp;lt;generator object Tokenizer.cut at 0x0000026EB6F0CD58&amp;gt;&lt;/span&gt;
&lt;span&gt;print&lt;/span&gt;&lt;span&gt;(list(seq_list))
&lt;/span&gt;&lt;span&gt;'''&lt;/span&gt;&lt;span&gt;
['赵', '丽', '颖', '主演', '的', '正午', '阳光', '剧', '', '', '知', '否', '知', '否', '应', '是', '绿肥', '绿肥红瘦']
&lt;/span&gt;&lt;span&gt;'''&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;h4&gt;&lt;span&gt;2 &lt;/span&gt; 精确模式 （默认模式） cut_all =False&lt;/h4&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;46&quot;&gt;
&lt;pre&gt;
&lt;span&gt;#&lt;/span&gt;&lt;span&gt; 02精确模式&lt;/span&gt;
seq_list=jieba.cut(text,cut_all=&lt;span&gt;False)
&lt;/span&gt;&lt;span&gt;print&lt;/span&gt;&lt;span&gt;(list(seq_list))
&lt;/span&gt;&lt;span&gt;'''&lt;/span&gt;&lt;span&gt;
['赵丽颖', '主演', '的', '正午', '阳光', '剧', ',', '知否', '知否', '应', '是', '绿肥红瘦']
&lt;/span&gt;&lt;span&gt;'''&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;h4&gt;3 搜索引擎模式 cut_for_search&lt;/h4&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;47&quot;&gt;
&lt;pre&gt;
seq_list=&lt;span&gt;jieba.cut_for_search(text,)
&lt;/span&gt;&lt;span&gt;print&lt;/span&gt;&lt;span&gt;(list(seq_list))
&lt;/span&gt;&lt;span&gt;'''&lt;/span&gt;&lt;span&gt;
['赵丽颖', '主演', '的', '正午', '阳光', '剧', ',', '知否', '知否', '应', '是', '绿肥', '绿肥红瘦']
&lt;/span&gt;&lt;span&gt;'''&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;h2&gt;四 自定义分词器(jieba.Tokenizer)&lt;/h2&gt;
&lt;h4&gt;1　创建词典内容的格式 &lt;/h4&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;32&quot;&gt;
&lt;pre&gt;
&lt;span&gt;一个词语占一行(分三部分)
格式: 词语 词频 词性
如:张三  &lt;/span&gt;5&lt;span&gt;
    李四  &lt;/span&gt;10 eng
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1521877/201901/1521877-20190105135659186-1711221062.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;h4&gt;2 自定义词典的导入(load_userdict)&lt;/h4&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;37&quot;&gt;
&lt;pre&gt;
text='赵丽颖主演的正午阳光剧,知否知否应是绿肥红瘦'
&lt;/pre&gt;
&lt;pre&gt;
&lt;span&gt;&lt;br/&gt;#&lt;/span&gt;&lt;span&gt; 自定义词典&lt;/span&gt;
jieba.load_userdict(&lt;span&gt;'&lt;/span&gt;&lt;span&gt;自定义词典.txt&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;)
sep_list&lt;/span&gt;=&lt;span&gt;jieba.lcut(text)
&lt;/span&gt;&lt;span&gt;print&lt;/span&gt;(&lt;span&gt;'&lt;/span&gt;&lt;span&gt;userdict&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;,sep_list)
&lt;/pre&gt;&lt;/div&gt;

&lt;div class=&quot;cnblogs_code&quot; readability=&quot;43&quot;&gt;
&lt;pre&gt;
userdict&amp;gt;&amp;gt;&amp;gt; [&lt;span&gt;'&lt;/span&gt;&lt;span&gt;赵丽颖&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;, &lt;span&gt;'&lt;/span&gt;&lt;span&gt;主演&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;, &lt;span&gt;'&lt;/span&gt;&lt;span&gt;的&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;, &lt;span&gt;'&lt;/span&gt;&lt;span&gt;正午&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;, &lt;span&gt;'&lt;/span&gt;&lt;span&gt;阳光剧&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;, &lt;span&gt;'&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;, &lt;span&gt;'&lt;/span&gt;&lt;span&gt;知否&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;, &lt;span&gt;'&lt;/span&gt;&lt;span&gt;知否&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;, &lt;span&gt;'&lt;/span&gt;&lt;span&gt;应是&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;, &lt;span&gt;'&lt;/span&gt;&lt;span&gt;绿肥红瘦&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;]
&lt;/pre&gt;&lt;/div&gt;

&lt;h2&gt; 五 利用jieba 进行关键词的抽取&lt;/h2&gt;
&lt;h4&gt;1 基于TF－IDF算法的关键词抽取&lt;/h4&gt;
&lt;p&gt;　　&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzIwNzYzNjA1OQ==&amp;amp;mid=2247484212&amp;amp;idx=1&amp;amp;sn=8a1f402fcdbf5c982c71859ce7e08c25&amp;amp;chksm=970e1000a079991611e03948ba0a74e6e45f6c2d64dcc0d65d9848d266ef751a0cb6a48864d2&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot;&gt;详解自然语言处理之TF-IDF模型和python实现&lt;/a&gt;&lt;/p&gt;
&lt;h4&gt;2 python 实现关键提取&lt;/h4&gt;

&lt;div class=&quot;cnblogs_code&quot; readability=&quot;41&quot;&gt;
&lt;pre&gt;
jieba.analyse.extract_tags(text,topK=20,withWeight=False,allowPOS=&lt;span&gt;())
&lt;/span&gt;&lt;span&gt;'''&lt;/span&gt;&lt;span&gt;
    text:为待提取的文本;
    topK:返回几个TF/IDF权重最大的关键字,默认值为20;
    withWeight:是否一并返回关键词权重值,默认False;
&lt;/span&gt;&lt;span&gt;'''&lt;/span&gt;&lt;span&gt;
jieba.analyse.TFIDF(idf_path&lt;/span&gt;=None) &lt;span&gt;#&lt;/span&gt;&lt;span&gt;新建tf-idf实例,idf_path为IDF实例&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;h2&gt;五 使用结巴的词云实例&lt;/h2&gt;
&lt;h4&gt;1 数据准备&lt;/h4&gt;
&lt;p&gt;文档:&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;32.5&quot;&gt;&lt;img id=&quot;code_img_closed_76fc258d-1c69-4fff-932c-29c68022bba9&quot; class=&quot;code_img_closed&quot; src=&quot;https://images.cnblogs.com/OutliningIndicators/ContractedBlock.gif&quot; alt=&quot;&quot;/&gt;&lt;img id=&quot;code_img_opened_76fc258d-1c69-4fff-932c-29c68022bba9&quot; class=&quot;code_img_opened&quot; src=&quot;https://images.cnblogs.com/OutliningIndicators/ExpandedBlockStart.gif&quot; alt=&quot;&quot;/&gt;&lt;div id=&quot;cnblogs_code_open_76fc258d-1c69-4fff-932c-29c68022bba9&quot; class=&quot;cnblogs_code_hide&quot; readability=&quot;60&quot;&gt;
&lt;pre&gt;
&lt;span&gt;死了都要爱
不淋漓尽致不痛快
感情多深只有这样
才足够表白
死了都要爱
不哭到微笑不痛快
宇宙毁灭心还在
把每天当成是末日来相爱
一分一秒都美到泪水掉下来
不理会别人是看好或看坏
只要你勇敢跟我来
爱不用刻意安排
凭感觉去亲吻相拥就会很愉快
享受现在别一开怀就怕受伤害
许多奇迹我们相信才会存在
死了都要爱
不淋漓尽致不痛快
感情多深只有这样才足够表白
死了都要爱
不哭到微笑不痛快
宇宙毁灭心还在
穷途末路都要爱
不极度浪漫不痛快
发会雪白土会掩埋
思念不腐坏
到绝路都要爱
不天荒地老不痛快
不怕热爱变火海
爱到沸腾才精采&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;span class=&quot;cnblogs_code_collapse&quot;&gt;死了都要爱.txt&lt;/span&gt;&lt;/div&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;40.5&quot;&gt;&lt;img id=&quot;code_img_closed_73ace9b1-ba45-4711-8523-dd552e72eb8f&quot; class=&quot;code_img_closed&quot; src=&quot;https://images.cnblogs.com/OutliningIndicators/ContractedBlock.gif&quot; alt=&quot;&quot;/&gt;&lt;img id=&quot;code_img_opened_73ace9b1-ba45-4711-8523-dd552e72eb8f&quot; class=&quot;code_img_opened&quot; src=&quot;https://images.cnblogs.com/OutliningIndicators/ExpandedBlockStart.gif&quot; alt=&quot;&quot;/&gt;&lt;div id=&quot;cnblogs_code_open_73ace9b1-ba45-4711-8523-dd552e72eb8f&quot; class=&quot;cnblogs_code_hide&quot; readability=&quot;76&quot;&gt;
&lt;pre&gt;
&lt;span&gt;Dream it possible

I will run, I will climb, I will soar.


I&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;m undefeated&lt;/span&gt;
&lt;span&gt;

Jumping out of my skin, pull the chord


Yeah I believe it


The past, &lt;/span&gt;&lt;span&gt;is&lt;/span&gt; everything we were don&lt;span&gt;'&lt;/span&gt;&lt;span&gt;t make us who we are&lt;/span&gt;
&lt;span&gt;

so I&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;ll dream, until I make it real, and all I see is stars&lt;/span&gt;
&lt;span&gt;

It&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;s not until you fall that you fly&lt;/span&gt;
&lt;span&gt;

When you dreams come alive you&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;re unstoppable&lt;/span&gt;
&lt;span&gt;

take a shot, chase the sun, find the beautiful


We will glow &lt;/span&gt;&lt;span&gt;in&lt;/span&gt;&lt;span&gt; the dark turning dust to gold


And we&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;ll dream it possible&lt;/span&gt;
&lt;span&gt;

I will chase, I will reach, I will fly


Until I&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;m breaking, until I&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;m breaking


Out of my cage, like a bird &lt;/span&gt;&lt;span&gt;in&lt;/span&gt;&lt;span&gt; the night


I know I&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;m changing, I know I&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;m changing


In,into something big, better than before


And &lt;/span&gt;&lt;span&gt;if&lt;/span&gt;&lt;span&gt; it takes, takes a thousand lives


Then it&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;s worth fighting for&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;span class=&quot;cnblogs_code_collapse&quot;&gt;dream ispossible.txt&lt;/span&gt;&lt;/div&gt;
&lt;p&gt;图片:(红心.jpg)&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1521877/201901/1521877-20190105120028947-1993850758.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;div class=&quot;cnblogs_code&quot; readability=&quot;38&quot;&gt;
&lt;pre&gt;
&lt;span&gt;#&lt;/span&gt;&lt;span&gt; 数据获取&lt;/span&gt;
with open(&lt;span&gt;'&lt;/span&gt;&lt;span&gt;死了都要爱.txt&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;,&lt;span&gt;'&lt;/span&gt;&lt;span&gt;r&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;,encoding=&lt;span&gt;'&lt;/span&gt;&lt;span&gt;utf8&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;)as f:
    text&lt;/span&gt;=&lt;span&gt;f.read()

&lt;/span&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt; with open('dream is possible.txt','r',encoding='utf8')as f:&lt;/span&gt;&lt;span&gt;
#&lt;/span&gt;&lt;span&gt;     text=f.read()&lt;/span&gt;&lt;span&gt;
#&lt;/span&gt;&lt;span&gt;图片获取&lt;/span&gt;
mask=np.array(Image.open(&lt;span&gt;'&lt;/span&gt;&lt;span&gt;红心.jpg&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;))
&lt;/pre&gt;&lt;/div&gt;

&lt;h4&gt;2 数据清洗&lt;/h4&gt;
&lt;p&gt;屏蔽不需要的数据和分词&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;35&quot;&gt;
&lt;pre&gt;
&lt;span&gt;#&lt;/span&gt;&lt;span&gt; 数据清洗&lt;/span&gt;&lt;span&gt;
#&lt;/span&gt;&lt;span&gt; 屏蔽死了都要爱&lt;/span&gt;
STOPWORDS.add(&lt;span&gt;'&lt;/span&gt;&lt;span&gt;死了都要爱&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;)
&lt;/pre&gt;
&lt;pre&gt;
sep_list=jieba.lcut(text,cut_all=False)&lt;br/&gt;sep_list=&quot; &quot;.join(sep_list) #转为字符串
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;自定义画布&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;40&quot;&gt;
&lt;pre&gt;
wc=&lt;span&gt;WordCloud(
    font_path&lt;/span&gt;=font,&lt;span&gt;#&lt;/span&gt;&lt;span&gt;使用的字体库&lt;/span&gt;
    margin=2&lt;span&gt;,
    mask&lt;/span&gt;=mask,&lt;span&gt;#&lt;/span&gt;&lt;span&gt;背景图片&lt;/span&gt;
    background_color=&lt;span&gt;'&lt;/span&gt;&lt;span&gt;white&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;, &lt;span&gt;#&lt;/span&gt;&lt;span&gt;背景颜色&lt;/span&gt;
    max_font_size=25&lt;span&gt;,
    max_words&lt;/span&gt;=200&lt;span&gt;,
    stopwords&lt;/span&gt;=STOPWORDS, &lt;span&gt;#&lt;/span&gt;&lt;span&gt;屏蔽的内容&lt;/span&gt;
)
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;生成词语,保存图片&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;32&quot;&gt;
&lt;pre&gt;
wc.generate(text) &lt;span&gt;#&lt;/span&gt;&lt;span&gt;制作词云&lt;/span&gt;
wc.to_file(&lt;span&gt;'&lt;/span&gt;&lt;span&gt;新增图片.jpg&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;) &lt;span&gt;#&lt;/span&gt;&lt;span&gt;保存到当地文件&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;h4&gt;3 数据展示&lt;/h4&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;33&quot;&gt;
&lt;pre&gt;
plt.imshow(wc,interpolation=&lt;span&gt;'&lt;/span&gt;&lt;span&gt;bilinear&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;)
plt.axis(&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;off&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;)
plt.show()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;h4&gt;完整代码和效果展示&lt;/h4&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;39.5&quot;&gt;&lt;img id=&quot;code_img_closed_d8726d84-05be-4ec7-af75-0d26e52e48b4&quot; class=&quot;code_img_closed&quot; src=&quot;https://images.cnblogs.com/OutliningIndicators/ContractedBlock.gif&quot; alt=&quot;&quot;/&gt;&lt;img id=&quot;code_img_opened_d8726d84-05be-4ec7-af75-0d26e52e48b4&quot; class=&quot;code_img_opened&quot; src=&quot;https://images.cnblogs.com/OutliningIndicators/ExpandedBlockStart.gif&quot; alt=&quot;&quot;/&gt;&lt;div id=&quot;cnblogs_code_open_d8726d84-05be-4ec7-af75-0d26e52e48b4&quot; class=&quot;cnblogs_code_hide&quot; readability=&quot;74&quot;&gt;
&lt;pre&gt;
&lt;span&gt;from&lt;/span&gt; wordcloud &lt;span&gt;import&lt;/span&gt;&lt;span&gt; WordCloud
&lt;/span&gt;&lt;span&gt;import&lt;/span&gt;&lt;span&gt; matplotlib.pyplot as plt

&lt;/span&gt;&lt;span&gt;import&lt;/span&gt;&lt;span&gt; numpy as np
&lt;/span&gt;&lt;span&gt;from&lt;/span&gt; PIL &lt;span&gt;import&lt;/span&gt;&lt;span&gt; Image

&lt;/span&gt;&lt;span&gt;import&lt;/span&gt;&lt;span&gt; jieba

&lt;/span&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt; 数据获取&lt;/span&gt;
with open(&lt;span&gt;'&lt;/span&gt;&lt;span&gt;死了都要爱.txt&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;,&lt;span&gt;'&lt;/span&gt;&lt;span&gt;r&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;,encoding=&lt;span&gt;'&lt;/span&gt;&lt;span&gt;utf8&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;)as f:
    text&lt;/span&gt;=&lt;span&gt;f.read()

&lt;/span&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt; with open('dream is possible.txt','r',encoding='utf8')as f:&lt;/span&gt;&lt;span&gt;
#&lt;/span&gt;&lt;span&gt;     text=f.read()&lt;/span&gt;&lt;span&gt;
#&lt;/span&gt;&lt;span&gt;图片获取&lt;/span&gt;
mask=np.array(Image.open(&lt;span&gt;'&lt;/span&gt;&lt;span&gt;关羽.jpg&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;))

&lt;/span&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt; 数据清洗&lt;/span&gt;&lt;span&gt;
#&lt;/span&gt;&lt;span&gt; 屏蔽死了都要爱&lt;/span&gt;&lt;span&gt;
#&lt;/span&gt;&lt;span&gt; STOPWORDS.add('死了都要爱')&lt;/span&gt;
&lt;span&gt;
font&lt;/span&gt;=r&lt;span&gt;'&lt;/span&gt;&lt;span&gt;C:\Windows\Fonts\simhei.ttf&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;
sep_list&lt;/span&gt;=jieba.lcut(text,cut_all=&lt;span&gt;False)
sep_list&lt;/span&gt;=&lt;span&gt;&quot;&lt;/span&gt; &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;.join(sep_list)
wc&lt;/span&gt;=&lt;span&gt;WordCloud(
    font_path&lt;/span&gt;=font,&lt;span&gt;#&lt;/span&gt;&lt;span&gt;使用的字体库&lt;/span&gt;
    margin=2&lt;span&gt;,
    mask&lt;/span&gt;=mask,&lt;span&gt;#&lt;/span&gt;&lt;span&gt;背景图片&lt;/span&gt;
    background_color=&lt;span&gt;'&lt;/span&gt;&lt;span&gt;white&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;, &lt;span&gt;#&lt;/span&gt;&lt;span&gt;背景颜色&lt;/span&gt;
    max_font_size=200&lt;span&gt;,
    &lt;/span&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt; min_font_size=1,&lt;/span&gt;
    max_words=200&lt;span&gt;,
    &lt;/span&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt; stopwords=STOPWORDS, #屏蔽的内容&lt;/span&gt;
&lt;span&gt;)

wc.generate(sep_list) &lt;/span&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt;制作词云&lt;/span&gt;
wc.to_file(&lt;span&gt;'&lt;/span&gt;&lt;span&gt;关羽新增.jpg&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;) &lt;span&gt;#&lt;/span&gt;&lt;span&gt;保存到当地文件&lt;/span&gt;

&lt;span&gt;#&lt;/span&gt;&lt;span&gt; 图片展示&lt;/span&gt;
plt.imshow(wc,interpolation=&lt;span&gt;'&lt;/span&gt;&lt;span&gt;bilinear&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;)
plt.axis(&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;off&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;)
plt.show()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;span class=&quot;cnblogs_code_collapse&quot;&gt;完整代码&lt;/span&gt;&lt;/div&gt;

&lt;p&gt;图片一(未分词):&lt;/p&gt;
&lt;p&gt; &lt;img src=&quot;https://img2018.cnblogs.com/blog/1521877/201901/1521877-20190105120533782-1092266218.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt; 图片二(分词效果)&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1521877/201901/1521877-20190105133012528-2003635257.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1521877/201901/1521877-20190105133435356-30635158.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;h2&gt; 推荐文章&lt;/h2&gt;
&lt;p&gt;&lt;a href=&quot;https://blog.csdn.net/gzmfxy/article/details/78994396&quot; target=&quot;_blank&quot;&gt;https://blog.csdn.net/gzmfxy/article/details/78994396&lt;/a&gt;&lt;/p&gt;

</description>
<pubDate>Sat, 05 Jan 2019 06:38:00 +0000</pubDate>
<dc:creator>join_L</dc:creator>
<og:description>结巴分词（自然语言处理之中文分词器） jieba分词算法使用了基于前缀词典实现高效的词图扫描，生成句子中汉字所有可能生成词情况所构成的有向无环图(DAG), 再采用了动态规划查找最大概率路径，找出基于</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/angle6-liu/p/10223957.html</dc:identifier>
</item>
<item>
<title>Python机器学习笔记：深入理解Keras中序贯模型和函数模型 - 战争热诚</title>
<link>http://www.cnblogs.com/wj-1314/p/9967480.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/wj-1314/p/9967480.html</guid>
<description>&lt;p&gt;　　 先从sklearn说起吧，如果学习了sklearn的话，那么学习Keras相对来说比较容易。为什么这样说呢？&lt;/p&gt;
&lt;p&gt;　　我们首先比较一下sklearn的机器学习大致使用流程和Keras的大致使用流程：&lt;/p&gt;
&lt;h4&gt;sklearn的机器学习使用流程：&lt;/h4&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;36&quot;&gt;
&lt;pre class=&quot;brush:csharp;gutter:true;&quot;&gt;
from  sklearn.模型簇    import  模型名
from  sklearn.metrics   import  评价指标


'''  数据预处理及训练测试集分离提取'''

myModel = 模型名称()     # 对象初始化
myModel.fit(训练集x ,  训练集y)     #模型训练
y预测集  = myModel.predict(开发集x)  #模型预测
评价指标 = 评价指标（y预测集，y测试集）   #模型效果评估
&lt;/pre&gt;&lt;/div&gt;

&lt;h4&gt;Keras的机器学习使用流程：&lt;/h4&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;34&quot;&gt;
&lt;pre class=&quot;brush:csharp;gutter:true;&quot;&gt;
import keras
...根据具体需求引入keras的包...

...keras模型搭建...
...keras模型编译(可选择模型指标)...

kerasModel.fit(训练集x，训练集y)#keras模型训练
y预测集=myModel.predict(开发集x)#keras模型预测
&lt;/pre&gt;&lt;/div&gt;

&lt;h4&gt;两者的区别&lt;/h4&gt;
&lt;p&gt;　　由上面伪代码可知Keras和sklearn最大不同在于需要进行模型搭建，可是既然有了这么多模型为什么还要模型搭建？&lt;/p&gt;
&lt;p&gt;　　如果你了解过神经网络感知机就会比较理解这个过程，一个感知器相当于一个神经元，可根据输入信息反馈出需要的电信号，根据我们的世界观，一个细胞可以单独执行很多功能但是大量单纯的任务会让细胞只针对一个方向发展。用生物学的说话就是分化能力逐渐减弱，机器学习说法就是过拟合。因此，只有大量细胞通过不同的组合才能完成纷繁复杂的预测任务，因而有证明说神经网络理论上可拟合出任何曲线。&lt;/p&gt;
&lt;p&gt;　　那么话说回来，Keras需要自行搭建模型，搭建方法有两种：序贯模型和函数式模型。而我本次的笔记就是学习序贯模型和函数式模型。&lt;/p&gt;
&lt;h2&gt;序贯模型&lt;/h2&gt;
&lt;p&gt;　　序贯模型是多个网络蹭的线性堆叠，是函数式模型的简略版，为最简单的线性，从头到尾的结构顺序，不发生分叉。是多个网络层的线性堆叠。&lt;/p&gt;
&lt;p&gt;　　Keras实现了很多层，包括core核心层，Convolution卷积层，Pooling池化层等非常丰富有趣的网络结构。&lt;/p&gt;
&lt;h3&gt;应用序贯模型的基本步骤&lt;/h3&gt;
&lt;ul&gt;&lt;li&gt;1，model.add()  　　　   　  添加层&lt;/li&gt;
&lt;li&gt;2，model.compile()　　　　 模型训练的BP模式设置&lt;/li&gt;
&lt;li&gt;3，model.fit()　　　　　　   模型训练参数设置+训练&lt;/li&gt;
&lt;li&gt;4，model.evaluate()   　　　   模型评估&lt;/li&gt;
&lt;li&gt;5，model.predict()　　　　　模型预测&lt;/li&gt;
&lt;/ul&gt;&lt;h3&gt;序贯模型的创建&lt;/h3&gt;
&lt;p&gt;　　1，可以通过向Sequential模型传递一个layer的list来构造Sequential模型：&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;40&quot;&gt;
&lt;pre class=&quot;brush:csharp;gutter:true;&quot;&gt;
from keras.models import Sequential
from keras.layers import Dense ,Activation

model = Sequential([
    Dense(32,input_shape=(784,)),
    Activation('relu'),
    Dense(10),
    Activation('softmax')
])

model.summary()
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;　　2，也可以通过.add()方法一个个的将layer加入模型中：&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;37&quot;&gt;
&lt;pre class=&quot;brush:csharp;gutter:true;&quot;&gt;
from keras.models import Sequential
from keras.layers import Dense ,Activation

model = Sequential()
model.add(Dense(32,input_shape=(784,)))
model.add(Activation('relu'))
model.add(Dense(10))
model.add(Activation('softmax'))

model.summary()
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　结果如下：&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;41&quot;&gt;
&lt;pre class=&quot;brush:csharp;gutter:true;&quot;&gt;
Using TensorFlow backend.
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_1 (Dense)              (None, 32)                25120     
_________________________________________________________________
activation_1 (Activation)    (None, 32)                0         
_________________________________________________________________
dense_2 (Dense)              (None, 10)                330       
_________________________________________________________________
activation_2 (Activation)    (None, 10)                0         
=================================================================
Total params: 25,450
Trainable params: 25,450
Non-trainable params: 0
_________________________________________________________________
&lt;/pre&gt;&lt;/div&gt;

&lt;h3&gt;3，指定输入数据的shape&lt;/h3&gt;
&lt;p&gt;　　模型需要知道输入数据的shape，因此，Sequential的第一层需要接受一个关于输入数据shape的参数，后面的各个层则可以自动的推导出中间数据的shape，因此不需要为每一层都指定这个参数。有几种方法来为第一层指定输入数据的shape&lt;/p&gt;
&lt;p&gt;　　1，传递一个input_shape的关键字参数给第一层，input_shape是一个tupel类型的数据（一个整数或者None的元祖，其中None表示可能为任何正整数）在input_shape中不包含数据的batch大小。&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;35&quot;&gt;
&lt;pre class=&quot;brush:csharp;gutter:true;&quot;&gt;
model = Sequential()
model.add(Dense(64,input_shape=(20,),activation='relu'))
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;　　2，有些2D层，如Dense，支持通过指定其输入维度input_dim来隐含的指定输入数据shape，是一个Int类型的数据。一些3D的时域层支持通过参数input_dim和input_length来指定输入shape。&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;34&quot;&gt;
&lt;pre class=&quot;brush:csharp;gutter:true;&quot;&gt;
model = Sequential()
model.add(Dense(64, input_dim=20, activation='relu'))
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　3，如果你需要为你的输入指定一个固定的batch大小（这对于statsful RNNs很有用），你可以传递一个batch_size参数给一个层。如果你同时将batch_size=32和input_shape = (6,8)传递给一个层，那么每一批输入的尺寸就是(32,6,8)。&lt;/p&gt;
&lt;p&gt;　　因此下面的代码是等价的：&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;36&quot;&gt;
&lt;pre class=&quot;brush:csharp;gutter:true;&quot;&gt;
model = Sequential()
model.add(Dense(32, input_shape=(784,)))
 
model = Sequential()
model.add(Dense(32, input_dim=784))
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　下面三种方法也是严格等价的&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;41&quot;&gt;
&lt;pre class=&quot;brush:csharp;gutter:true;&quot;&gt;
model = Sequential()
model.add(LSTM(32, input_shape=(10, 64)))
 
 
model = Sequential()
model.add(LSTM(32, batch_input_shape=(None, 10, 64)))
 
 
model = Sequential()
model.add(LSTM(32, input_length=10, input_dim=64))
&lt;/pre&gt;&lt;/div&gt;

&lt;h4&gt;4，编译&lt;/h4&gt;
&lt;p&gt;　　在训练模型之前，我们需要通过compile来对学习过程进行配置，compile接收三个参数：优化器optimizer，损失函数loss，指标列表metrics。&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;36&quot;&gt;
&lt;pre class=&quot;brush:csharp;gutter:true;&quot;&gt;
compile(self, optimizer, loss, metrics=None, sample_weight_mode=None)
&lt;/pre&gt;&lt;/div&gt;
&lt;h4&gt;其中：&lt;/h4&gt;
&lt;p&gt;　　optimizer：字符串（预定义优化器名）或者优化器对象，，如 &lt;code&gt;rmsprop&lt;/code&gt; 或 &lt;code&gt;adagrad&lt;/code&gt;，也可以是 Optimizer 类的实例。详见：&lt;a href=&quot;https://keras.io/zh/optimizers&quot;&gt;optimizers&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;　　loss：字符串（预定义损失函数名）或目标函数，模型试图最小化的目标函数，它可以是现有损失函数的字符串标识符，如&lt;code&gt;categorical_crossentropy&lt;/code&gt; 或 &lt;code&gt;mse&lt;/code&gt;，也可以是一个目标函数。详见：&lt;a href=&quot;https://keras.io/zh/losses&quot;&gt;losses&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;　　metrics：列表，包含评估模型在训练和测试时的网络性能的指标，典型用法是metrics=[‘accuracy’]。评估标准可以是现有的标准的字符串标识符，也可以是自定义的评估标准函数。&lt;/p&gt;
&lt;h4&gt;注意：&lt;/h4&gt;
&lt;p&gt;　　模型在使用前必须编译，否则在调用fit或者evaluate时会抛出异常。&lt;/p&gt;
&lt;h4&gt;例子：&lt;/h4&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;44&quot;&gt;
&lt;pre class=&quot;brush:csharp;gutter:true;&quot;&gt;
# 多分类问题
model.compile(optimizer='rmsprop',
              loss='categorical_crossentropy',
              metrics=['accuracy'])
 
# 二分类问题
model.compile(optimizer='rmsprop',
              loss='binary_crossentropy',
              metrics=['accuracy'])
 
# 均方误差回归问题
model.compile(optimizer='rmsprop',
              loss='mse')
 
# 自定义评估标准函数
import keras.backend as K
 
def mean_pred(y_true, y_pred):
    return K.mean(y_pred)
 
model.compile(optimizer='rmsprop',
              loss='binary_crossentropy',
              metrics=['accuracy', mean_pred])
&lt;/pre&gt;&lt;/div&gt;

&lt;h3&gt;5，训练&lt;/h3&gt;
&lt;p&gt;　　Keras 模型在输入数据和标签的 Numpy 矩阵上进行训练。为了训练一个模型，你通常会使用 &lt;code&gt;fit&lt;/code&gt; 函数。&lt;a href=&quot;https://keras.io/zh/models/sequential&quot;&gt;文档详见此处&lt;/a&gt;。&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;45&quot;&gt;
&lt;pre class=&quot;brush:csharp;gutter:true;&quot;&gt;
fit(self, x, y, batch_size=32, epochs=10, verbose=1, callbacks=None,
 validation_split=0.0, validation_data=None, shuffle=True,
 class_weight=None, sample_weight=None, initial_epoch=0)
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　本函数将模型训练nb_epoch轮，其参数有：&lt;/p&gt;
&lt;p&gt;　　x：输入数据，如果模型只有一个输入，那么x的类型是numpy array，如果模型有多个输入，那么x的类型应当是list，list的元素是对应于各个输入的numpy array&lt;/p&gt;
&lt;p&gt;　　y：标签 ，numpy array&lt;/p&gt;
&lt;p&gt;　　batch_size：整数，指定进行梯度下降时每个batch包含的样本数，训练时一个batch的样本会被计算一次梯度下降，使目标函数优化一步。&lt;/p&gt;
&lt;p&gt;　　epochs：整数，训练的轮数，每个epoch会把训练集轮一遍。&lt;/p&gt;
&lt;p&gt;　　verbose：日志显示，0为不在标准输出流输出日志信息，1为输出进度条记录，2为每个epoch输出一行记录&lt;/p&gt;
&lt;p&gt;　　callbacks：list,，其中的元素是keras.callbacks.Callback的对象。这个list中的回调函数将会在训练过程中的适当时机被调用，参考回调函数。&lt;/p&gt;
&lt;p&gt;　　validation_split：0~1之间的浮点数，用来指定训练集的一定比例数据作为验证集。验证集将不参与训练，并在每个epoch结束后测试的模型的指标，如损失函数，精确度等。注意，validation_split的划分在shuffle之前，因此如果你的数据本身是有序的，需要先手工打乱再指定validation_split，否则可能会出现验证集样本不均匀。&lt;/p&gt;
&lt;p&gt;　　validation_data：形式为（X，y）的tuple，是指定的验证集，此参数将覆盖validation_spilt。&lt;/p&gt;
&lt;p&gt;　　shuffle：布尔值或者字符串，一般为布尔值，表示是否在训练过程中随机打乱输入样本的顺序。若为字符串“batch”，则用来处理HDF5数据大特殊情况，它将在batch内部将数据打乱。&lt;/p&gt;
&lt;p&gt;　　class_weight：字典，将不同的类别映射为不同的权重，该参数用来训练过程中调整损失函数（只能用于训练）&lt;/p&gt;
&lt;p&gt;　　sample_weight：权值的numpy array，用于在训练时调整损失（仅用于训练）。&lt;/p&gt;
&lt;p&gt;可以传递一个1D的与样本等长的向量用于对样本进行1对1的加权，或者在面对时序数据时，传递一个的形式为（samples，sequence_length）的矩阵来为每个时间步上的样本赋不同的权。这种情况下请确定在编译模型时添加了sample_weight_mode=‘temporal’。&lt;br/&gt;　　initial_epoch：从该参数指定的epoch开始训练，在继续之前的训练时候有用。&lt;/p&gt;
&lt;p&gt;　　fit函数返回一个History的对象，其History.history属性记录了损失函数和其他指标的数值随着epoch变化的情况，如果有验证集的话，也包含了验证集的这些指标变化情况。&lt;/p&gt;
&lt;h4&gt; 示例一：&lt;/h4&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;46&quot;&gt;
&lt;pre class=&quot;brush:csharp;gutter:true;&quot;&gt;
# 对于具有2个类的单输入模型（二进制分类）：
 
model = Sequential()
model.add(Dense(32, activation='relu', input_dim=100))
model.add(Dense(1, activation='sigmoid'))
model.compile(optimizer='rmsprop',
              loss='binary_crossentropy',
              metrics=['accuracy'])
 
# 生成虚拟数据
import numpy as np
data = np.random.random((1000, 100))
labels = np.random.randint(2, size=(1000, 1))
 
# 训练模型，以 32 个样本为一个 batch 进行迭代
model.fit(data, labels, epochs=10, batch_size=32)
&lt;/pre&gt;&lt;/div&gt;

&lt;h4&gt;示例二：&lt;/h4&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;47&quot;&gt;
&lt;pre class=&quot;brush:csharp;gutter:true;&quot;&gt;
# 对于具有10个类的单输入模型（多分类分类）：
 
model = Sequential()
model.add(Dense(32, activation='relu', input_dim=100))
model.add(Dense(10, activation='softmax'))
model.compile(optimizer='rmsprop',
              loss='categorical_crossentropy',
              metrics=['accuracy'])
 
# 生成虚拟数据
import numpy as np
data = np.random.random((1000, 100))
labels = np.random.randint(10, size=(1000, 1))
 
# 将标签转换为分类的 one-hot 编码
one_hot_labels = keras.utils.to_categorical(labels, num_classes=10)
 
# 训练模型，以 32 个样本为一个 batch 进行迭代
model.fit(data, one_hot_labels, epochs=10, batch_size=32)
&lt;/pre&gt;&lt;/div&gt;

&lt;h3&gt;6，评估&lt;/h3&gt;
&lt;p&gt;　　根据验证集评估模型的好坏&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;37&quot;&gt;
&lt;pre class=&quot;brush:csharp;gutter:true;&quot;&gt;
evaluate(self, x, y, batch_size=32, verbose=1, sample_weight=None)
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　本函数按batch计算在某些输入数据上模型的误差，其参数有：&lt;/p&gt;
&lt;p&gt;　　x：输入数据，与fit一样，是numpy array 或者numpy array的list&lt;/p&gt;
&lt;p&gt;　　y：标签，numpy array&lt;/p&gt;
&lt;p&gt;　　batch_size：整数，含义同fit的同名参数&lt;/p&gt;
&lt;p&gt;　　verbose：含义同fit的同名参数，但是只能取0或1&lt;/p&gt;
&lt;p&gt;　　sample_weight：numpy array ，含义同fit的同名参数&lt;/p&gt;
&lt;p&gt;　　本函数返回一个测试误差的标量值（如果模型没有其他评价指标），或一个标量的list（如果模型还有其他的评价指标）。model.metrics_names将给出list中各个值的含义。&lt;/p&gt;
&lt;p&gt;　　如果没有特殊说明，以下函数的参数均保持与fit的同名参数相同的含义&lt;/p&gt;
&lt;p&gt;　　如果没有特殊说明，以下函数的verbose参数（如果有）均只能取0或者1&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;37&quot;&gt;
&lt;pre class=&quot;brush:csharp;gutter:true;&quot;&gt;
score = model.evaluate(x_val , y_val ,batch_size = 128)
print('val score:', score[0])
print('val accuracy:', score[1])
&lt;/pre&gt;&lt;/div&gt;

&lt;h3&gt;7，预测&lt;/h3&gt;
&lt;p&gt;　　对已经训练完成的模型，输入特征值x会预测得到标签y。&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;42&quot;&gt;
&lt;pre class=&quot;brush:csharp;gutter:true;&quot;&gt;
predict(self, x, batch_size=32, verbose=0)
predict_classes(self, x, batch_size=32, verbose=1)
predict_proba(self, x, batch_size=32, verbose=1)
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　本函数按batch获得输入数据对应的输出，其参数有：&lt;/p&gt;
&lt;p&gt;　　函数的返回值是预测值的numpy array&lt;/p&gt;
&lt;p&gt;　　predict_classes：本函数按batch产生输入数据的类别预测结果&lt;/p&gt;
&lt;p&gt;　　predict_proba：本函数按batch产生输入数据属于各个类别的概率&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;33&quot;&gt;
&lt;pre class=&quot;brush:csharp;gutter:true;&quot;&gt;
x = 1
y = model.predict(x,verbose=0)
print(y)
&lt;/pre&gt;&lt;/div&gt;

&lt;h3&gt;8，on_batch，batch的结果，检查&lt;/h3&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;41&quot;&gt;
&lt;pre class=&quot;brush:csharp;gutter:true;&quot;&gt;
train_on_batch(self, x, y, class_weight=None, sample_weight=None)
test_on_batch(self, x, y, sample_weight=None)
predict_on_batch(self, x)
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　train_on_batch：本函数在batch的数据上进行一次参数更新，函数返回训练误差的标量值或者标量值的list，与evaluate的情形相同。&lt;/p&gt;
&lt;p&gt;　　test_on_batch：本函数在一个batch的样本上对模型进行评估，函数的返回与evaluate的情形相同。&lt;/p&gt;
&lt;p&gt;　　predict_on_batch：本函数在一个batch的样本上对模型进行测试，函数返回模型在一个batch上的预测结果。&lt;/p&gt;
&lt;h3&gt; &lt;/h3&gt;
&lt;h3&gt;9，完整代码及其一次结果&lt;/h3&gt;
&lt;p&gt;代码：&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;57&quot;&gt;
&lt;pre class=&quot;brush:csharp;gutter:true;&quot;&gt;
from keras.models import Sequential
from keras.layers import Dense ,Activation,Dropout
import numpy as np

# 准备训练集和验证集
x_train = np.random.random((1000,20))
y_train = np.random.randint(2,size=(1000,1))
x_val = np.random.random((100,20))
y_val = np.random.randint(2,size=(100,1))

model = Sequential()
model.add(Dense(64,input_dim=20,activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(64,activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(1,activation='sigmoid'))

model.compile(loss='binary_crossentropy',optimizer='rmsprop',metrics=['accuracy'])
model.fit(x_train,y_train,epochs=20,batch_size=128)

score = model.evaluate(x_val , y_val ,batch_size = 128)
print('val score:', score[0])
print('val accuracy:', score[1])

# x = 1
# y = model.predict(x,verbose=0)
# print(y)
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;结果：&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;35&quot;&gt;
&lt;pre class=&quot;brush:csharp;collapse:true;;gutter:true;&quot;&gt;
Using TensorFlow backend.
Epoch 1/20

 128/1000 [==&amp;gt;...........................] - ETA: 1s - loss: 0.7093 - acc: 0.5469
1000/1000 [==============================] - 0s 291us/step - loss: 0.7098 - acc: 0.5090
Epoch 2/20

 128/1000 [==&amp;gt;...........................] - ETA: 0s - loss: 0.7191 - acc: 0.4766
1000/1000 [==============================] - 0s 15us/step - loss: 0.7087 - acc: 0.5080
Epoch 3/20

 128/1000 [==&amp;gt;...........................] - ETA: 0s - loss: 0.7009 - acc: 0.4766
1000/1000 [==============================] - 0s 15us/step - loss: 0.6969 - acc: 0.5040
Epoch 4/20

 128/1000 [==&amp;gt;...........................] - ETA: 0s - loss: 0.6946 - acc: 0.5312
1000/1000 [==============================] - 0s 15us/step - loss: 0.6969 - acc: 0.5240
Epoch 5/20

 128/1000 [==&amp;gt;...........................] - ETA: 0s - loss: 0.7029 - acc: 0.4609
1000/1000 [==============================] - 0s 15us/step - loss: 0.7002 - acc: 0.4950
Epoch 6/20

 128/1000 [==&amp;gt;...........................] - ETA: 0s - loss: 0.7027 - acc: 0.4531
1000/1000 [==============================] - 0s 15us/step - loss: 0.6992 - acc: 0.5090
Epoch 7/20

 128/1000 [==&amp;gt;...........................] - ETA: 0s - loss: 0.6907 - acc: 0.5312
1000/1000 [==============================] - 0s 16us/step - loss: 0.6895 - acc: 0.5290
Epoch 8/20

 128/1000 [==&amp;gt;...........................] - ETA: 0s - loss: 0.6906 - acc: 0.5000
1000/1000 [==============================] - 0s 16us/step - loss: 0.6969 - acc: 0.5040
Epoch 9/20

 128/1000 [==&amp;gt;...........................] - ETA: 0s - loss: 0.6860 - acc: 0.5078
1000/1000 [==============================] - 0s 16us/step - loss: 0.6914 - acc: 0.5280
Epoch 10/20

 128/1000 [==&amp;gt;...........................] - ETA: 0s - loss: 0.6784 - acc: 0.6016
1000/1000 [==============================] - 0s 17us/step - loss: 0.6912 - acc: 0.5390
Epoch 11/20

 128/1000 [==&amp;gt;...........................] - ETA: 0s - loss: 0.6812 - acc: 0.6406
1000/1000 [==============================] - 0s 16us/step - loss: 0.6874 - acc: 0.5330
Epoch 12/20

 128/1000 [==&amp;gt;...........................] - ETA: 0s - loss: 0.6997 - acc: 0.4766
1000/1000 [==============================] - 0s 16us/step - loss: 0.6949 - acc: 0.5080
Epoch 13/20

 128/1000 [==&amp;gt;...........................] - ETA: 0s - loss: 0.6843 - acc: 0.5781
1000/1000 [==============================] - 0s 15us/step - loss: 0.6912 - acc: 0.5380
Epoch 14/20

 128/1000 [==&amp;gt;...........................] - ETA: 0s - loss: 0.6746 - acc: 0.5703
1000/1000 [==============================] - 0s 17us/step - loss: 0.6873 - acc: 0.5360
Epoch 15/20

 128/1000 [==&amp;gt;...........................] - ETA: 0s - loss: 0.6959 - acc: 0.5000
1000/1000 [==============================] - 0s 16us/step - loss: 0.6891 - acc: 0.5310
Epoch 16/20

 128/1000 [==&amp;gt;...........................] - ETA: 0s - loss: 0.6780 - acc: 0.5938
1000/1000 [==============================] - 0s 17us/step - loss: 0.6907 - acc: 0.5280
Epoch 17/20

 128/1000 [==&amp;gt;...........................] - ETA: 0s - loss: 0.6835 - acc: 0.5938
1000/1000 [==============================] - 0s 16us/step - loss: 0.6858 - acc: 0.5690
Epoch 18/20

 128/1000 [==&amp;gt;...........................] - ETA: 0s - loss: 0.6845 - acc: 0.4922
1000/1000 [==============================] - 0s 16us/step - loss: 0.6921 - acc: 0.5220
Epoch 19/20

 128/1000 [==&amp;gt;...........................] - ETA: 0s - loss: 0.6861 - acc: 0.5625
1000/1000 [==============================] - 0s 15us/step - loss: 0.6859 - acc: 0.5540
Epoch 20/20

 128/1000 [==&amp;gt;...........................] - ETA: 0s - loss: 0.6959 - acc: 0.5312
1000/1000 [==============================] - 0s 16us/step - loss: 0.6841 - acc: 0.5530

100/100 [==============================] - 0s 440us/step
val score: 0.6957631707191467
val accuracy: 0.5099999904632568
&lt;/pre&gt;&lt;/div&gt;

&lt;h2&gt;函数式模型&lt;/h2&gt;
&lt;p&gt;　　比序贯模型要复杂，但是效果很好，可以同时/分阶段输入变量，分阶段输出想要的模型。&lt;/p&gt;
&lt;p&gt;　　所以说，只要你的模型不是类似VGG一样&lt;/p&gt;
&lt;h3&gt;1，应用函数式模型的基本步骤&lt;/h3&gt;
&lt;p&gt;1，model.layers()     添加层&lt;/p&gt;
&lt;p&gt;2，model.compile()  模型训练的BP模式设置&lt;/p&gt;
&lt;p&gt;3，model.fit()     　　模型训练参数设置+训练&lt;/p&gt;
&lt;p&gt;4，evaluate()             模型评估&lt;/p&gt;
&lt;p&gt;5，predict()                模型预测&lt;/p&gt;

&lt;h3&gt;2，常用Model属性&lt;/h3&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;33&quot;&gt;
&lt;pre class=&quot;brush:csharp;gutter:true;&quot;&gt;
model.layers：组成模型图的各个层
model.inputs：模型的输入张量列表
model.outputs：模型的输出张量列表
&lt;/pre&gt;&lt;/div&gt;

&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;33&quot;&gt;
&lt;pre class=&quot;brush:csharp;gutter:true;&quot;&gt;
model = Model(inputs=, outputs = )
&lt;/pre&gt;&lt;/div&gt;

&lt;h3&gt;3，指定输入数据的shape&lt;/h3&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;33&quot;&gt;
&lt;pre class=&quot;brush:csharp;gutter:true;&quot;&gt;
inputs = Input(shape = (20, ))
&lt;/pre&gt;&lt;/div&gt;

&lt;h3&gt;4，编译，训练，评估，预测等步骤与序贯式模型相同（这里不再赘述）&lt;/h3&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;37&quot;&gt;
&lt;pre class=&quot;brush:csharp;gutter:true;&quot;&gt;
compile(self, optimizer, loss, metrics=None, loss_weights=None, sample_weight_mode=None)
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　本函数按batch计算在某些输入数据上模型的误差，其参数有：&lt;/p&gt;
&lt;p&gt;　　x：输入数据，与fit一样，是numpy array或者numpy array的list&lt;/p&gt;
&lt;p&gt;　　y：标签，numpy array&lt;/p&gt;
&lt;p&gt;　　batch_size：整数，含义同fit的同名函数&lt;/p&gt;
&lt;p&gt;　　verbose：含义与fit的同名函数，但是只能取0或者1&lt;/p&gt;
&lt;p&gt;　　sample_weight：numpy array，含义同fit的同名函数&lt;/p&gt;
&lt;p&gt;　　本函数编译模型以供训练，参数有：&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;37&quot;&gt;
&lt;pre class=&quot;brush:csharp;gutter:true;&quot;&gt;
evaluate(self, x, y, batch_size=32, verbose=1, sample_weight=None)
&lt;/pre&gt;&lt;/div&gt;

&lt;h3&gt;5，示例一（基于上面序贯模型进行改造）&lt;/h3&gt;

&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;57&quot;&gt;
&lt;pre class=&quot;brush:csharp;gutter:true;&quot;&gt;
import numpy as np
from keras.models import Model
from keras.layers import Dense , Dropout,Input

# 准备训练集和验证集
x_train = np.random.random((1000,20))
y_train = np.random.randint(2,size=(1000,1))
x_val = np.random.random((100,20))
y_val = np.random.randint(2,size=(100,1))

inputs = Input(shape = (20,))
x = Dense(64,activation='relu')(inputs)
x = Dropout(0.5)(x)
x = Dense(64,activation='relu')(x)
x = Dropout(0.5)(x)
predictions = Dense(1,activation='sigmoid')(x)
model=Model(inputs=inputs, outputs=predictions)
model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])
model.fit(x_train, y_train,epochs=20,batch_size=128)

score = model.evaluate(x_val, y_val, batch_size=128)
print('val score:', score[0])
print('val accuracy:', score[1])
&lt;/pre&gt;&lt;/div&gt;


&lt;h3&gt;序贯模型和函数模型共同的API&lt;/h3&gt;
&lt;p&gt;　　model.summary()：打印出模型的概况，它实际调用的是keras.utils.print_summary&lt;/p&gt;
&lt;p&gt;　　model.get_config()：返回包含模型配置信息的Python字典，模型也可以从config中重构回去。&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;33&quot;&gt;
&lt;pre class=&quot;brush:csharp;gutter:true;&quot;&gt;
config = model.get_config()
model = Model.from_config(config)
model = Sequential.from_config(config)
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　上面是分别对序贯模型和函数式模型载入config&lt;/p&gt;
&lt;p&gt;model.get_layer()：依据层名或下标获得层对象&lt;/p&gt;
&lt;p&gt;model.get_weights()：返回模型权重张量的列表，类型为numpy.array&lt;/p&gt;
&lt;p&gt;model.set_weights()：从numpy array里载入给模型，要求数组与model.get_weights()一样&lt;/p&gt;
&lt;p&gt;model.to_json()：返回代表模型的JSON字符串，仅仅包含网络结构，不包含权重，可以从JSON字符串中重构模型&lt;/p&gt;

&lt;h2&gt;Keras模型保存&lt;/h2&gt;
&lt;p&gt;　　首先不推荐使用pickle或者cPickle来保存Keras模型&lt;/p&gt;
&lt;h3&gt;1，保存结构&lt;/h3&gt;
&lt;p&gt; 　　可以使用model.save(filepath)将Keras模型和权重保存在一个HDF5文件中，该文件将包含：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;模型的结构，以便重构该模型&lt;/li&gt;
&lt;li&gt;模型的权重&lt;/li&gt;
&lt;li&gt;训练配置（损失函数，优化器等）&lt;/li&gt;
&lt;li&gt;优化器的状态，以便从上次训练中断的地方开始&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;　　使用Keras.models.load_model(filepath)来重新实例化你的模型，如果文件中存储了训练配置的话，该函数还会同时完成模型的编译。例如：&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;34&quot;&gt;
&lt;pre class=&quot;brush:csharp;gutter:true;&quot;&gt;
from keras.models  import load_model

# create a HDF5 file 'my_load.h5'
model.save('my_load.h5')

# deletes the existing model
del  model

# returns a compiled model
# indentical to the previous one
model = load_model('my_load.h5')
&lt;/pre&gt;&lt;/div&gt;

&lt;h3&gt;2，保存结构&lt;/h3&gt;
&lt;p&gt;　　如果你只是希望保存模型的结构，而不包括其权重或者配置信息，可以使用：&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;32&quot;&gt;
&lt;pre class=&quot;brush:csharp;gutter:true;&quot;&gt;
# save as JSON
json_string = model.to_json()

# save as YAML
yaml_string = model.to_yaml()
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　这项操作可以将模型序列化为json或者yaml文件，如果需要的话你甚至可以手动打开这些文件进行编辑。&lt;/p&gt;
&lt;p&gt;　　当然你也可以从保存好的json文件或者yaml文件中载入模型：&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;33&quot;&gt;
&lt;pre class=&quot;brush:csharp;gutter:true;&quot;&gt;
# model reconstruction from JSON:
from keras.models import model_from_json
model = model_from_json(json_string)

# model reconstruction from YAML
model = model_from_yaml(yaml_string)
&lt;/pre&gt;&lt;/div&gt;

&lt;h3&gt;3，保存模型的权重&lt;/h3&gt;
&lt;p&gt;　　如果需要保存模型，可通过下面的代码利用HDF5进行保存。注意，在使用前需要确保你已经安装了HDF5 和Python的库h5py。&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;32&quot;&gt;
&lt;pre class=&quot;brush:csharp;gutter:true;&quot;&gt;
model.save_weights('my_model_weights.h5')
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　如果你需要在代码中初始化一个完全相同的模型，请使用：&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;32&quot;&gt;
&lt;pre class=&quot;brush:csharp;gutter:true;&quot;&gt;
model.load_weights('my_model_weights.h5')
&lt;/pre&gt;&lt;/div&gt;

&lt;h3&gt;4，加载权重到不同的网络结构&lt;/h3&gt;
&lt;p&gt;　　如果你需要加载权重到不同的网络结构（有些层一样）中，例如fine-tune或transfer-learning，你可以通过层名字来加载模型。&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;33&quot;&gt;
&lt;pre class=&quot;brush:csharp;gutter:true;&quot;&gt;
model.load_weights('my_model_weights.h5', by_name=True)
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　例如：&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;43&quot;&gt;
&lt;pre class=&quot;brush:csharp;gutter:true;&quot;&gt;
&quot;&quot;&quot;
假如原模型为：
    model = Sequential()
    model.add(Dense(2, input_dim=3, name=&quot;dense_1&quot;))
    model.add(Dense(3, name=&quot;dense_2&quot;))
    ...
    model.save_weights(fname)
&quot;&quot;&quot;
# new model
model = Sequential()
model.add(Dense(2, input_dim=3, name=&quot;dense_1&quot;))  # will be loaded
model.add(Dense(10, name=&quot;new_dense&quot;))  # will not be loaded

# load weights from first model; will only affect the first layer, dense_1.
model.load_weights(fname, by_name=True)
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　加载权重到不同的网络结构上多数用于迁移学习。&lt;/p&gt;

&lt;p&gt;参考文献：https://zhuanlan.zhihu.com/p/37376691&lt;/p&gt;
&lt;p&gt;https://zhuanlan.zhihu.com/p/50543770&lt;/p&gt;
</description>
<pubDate>Sat, 05 Jan 2019 06:33:00 +0000</pubDate>
<dc:creator>战争热诚</dc:creator>
<og:description>先从sklearn说起吧，如果学习了sklearn的话，那么学习Keras相对来说比较容易。为什么这样说呢？ 我们首先比较一下sklearn的机器学习大致使用流程和Keras的大致使用流程： skle</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/wj-1314/p/9967480.html</dc:identifier>
</item>
<item>
<title>JVM垃圾收集器组合--各种组合对应的虚拟机参数实践 - 三国梦回</title>
<link>http://www.cnblogs.com/grey-wolf/p/10222758.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/grey-wolf/p/10222758.html</guid>
<description>&lt;p&gt;相信很多人都看过下面这张图，（来自《深入理解Java虚拟机：JVM高级特性与最佳实践》）&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/519126/201901/519126-20190105105608573-81865164.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;


&lt;p&gt;在学完几种垃圾收集器类型及组合后，打算看看实际中程序用到的垃圾收集器。&lt;/p&gt;
&lt;p&gt;但是在jconsole中看到的，如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/519126/201901/519126-20190105101856124-1214329054.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt; 两边的名称并不完全匹配，给我造成了很多困惑之处。&lt;/p&gt;
&lt;p&gt;实际上，jconsole里面用到的，我想应该是JVM内部使用到的名字。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/519126/201901/519126-20190105105147299-1057859012.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;本文主要讲解新生代、老年代可用的垃圾收集器，如何查看运行中程序使用的垃圾收集器，可用的垃圾收集器组合及对应参数配置等。&lt;/p&gt;
&lt;p&gt;资料来源于：&lt;/p&gt;
&lt;p&gt;1、《深入理解Java虚拟机：JVM高级特性与最佳实践》&lt;/p&gt;
&lt;p&gt;2、&lt;a href=&quot;http://www.fasterj.com/articles/oraclecollectors1.shtml&quot; target=&quot;_blank&quot;&gt;http://www.fasterj.com/articles/oraclecollectors1.shtml&lt;/a&gt;&lt;/p&gt;


&lt;h2&gt;1.新生代&lt;/h2&gt;
&lt;h3&gt;1.1 &lt;strong&gt;Copy（别名：Serial、DefNew） &lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;-the serial copy collector, uses one thread to copy surviving objects from Eden to Survivor spaces and between Survivor spaces until it decides they've been there long enough, at which point it copies them into the old generation.&lt;/p&gt;
&lt;p&gt;译文：Serial垃圾收集器，使用单线程完成下列工作：&lt;/p&gt;
&lt;p&gt;从Eden区和From Survivor区拷贝存活对象到To Survivor区域、当存活对象在Survivor区超过年龄阈值时，拷贝到老年代。&lt;/p&gt;
&lt;p&gt;这里的名称为Copy，实际上就是上图的Serial收集器。&lt;/p&gt;
&lt;h3&gt;&lt;strong&gt;1.2 PS Scavenge（别名：Parallel Scavenge、PSYoungGen）&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;-the parallel scavenge collector, like the &lt;strong&gt;Copy&lt;/strong&gt; collector, but uses multiple threads in parallel and has some knowledge of how the old generation is collected (essentially written to work with the serial and PS old gen collectors).&lt;/p&gt;
&lt;p&gt;译文：即Parallel Scavenge收集器，和Copy收集器类似，不过差别是它采用多线程进行并行收集。&lt;span class=&quot;fontstyle0&quot;&gt;Parallel Scavenge收集器的目标则是达到一个可控制的吞吐量（Throughput） 。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;fontstyle0&quot;&gt;Parallel Scavenge收集器提供了两个参数用于精确控制吞吐量， 分别是控制最大垃圾收集停顿时间的-XX：MaxGCPauseMillis参数以及直接设置吞吐量大小的-XX： GCTimeRatio参数。&lt;/span&gt;由于与吞吐量关系密切， Parallel Scavenge收集器也经常称为“吞吐量优先” 收集器。 除上述两个参数之外， Parallel Scavenge收集器还有一个参数-XX： +UseAdaptiveSizePolicy值得关注。 这是一个开关参数， 当这个参数打开之后，虚拟机会根据当前系统的运行情况收集性能监控信息， 动态调整这些参数以提供最合适的停顿时间或者最大的吞吐量， 这种调节方式称为GC自适应的调节策略（GC Ergonomics） &lt;span class=&quot;fontstyle0&quot;&gt;[1]&lt;span class=&quot;fontstyle0&quot;&gt;。 &lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h3&gt;&lt;strong&gt;1.3 ParNew （别名和内部名一样为ParNew）&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;-the parallel copy collector, like the &lt;strong&gt;Copy&lt;/strong&gt; collector, but uses multiple threads in parallel and has an internal 'callback' that allows an old generation collector to operate on the objects it collects (really written to work with the concurrent collector).&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;fontstyle0&quot;&gt;ParNew收集器其实就是Serial收集器的多线程版本， 除了使用多条线程进行垃圾收集。&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;

&lt;h3&gt;&lt;strong&gt;1.4 G1 Young Generation&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;-the garbage first collector, uses the 'Garbage First' algorithm which splits up the heap into lots of smaller spaces, but these are still separated into Eden and Survivor spaces in the young generation for G1.&lt;/p&gt;

&lt;h2&gt;2.老年代&lt;/h2&gt;
&lt;h3&gt;2.1.&lt;strong&gt;MarkSweepCompact （别名：Serial Old（MSC））&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt; the serial mark-sweep collector, the daddy of them all, uses a serial (one thread) full mark-sweep garbage collection algorithm, with optional compaction.&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;fontstyle0&quot;&gt;Serial Old是Serial收集器的老年代版本， 它同样是一个单线程收集器， 使用“标记-整理” 算法。 &lt;br/&gt;&lt;/span&gt;&lt;/p&gt;

&lt;h3&gt; 2.2 &lt;strong&gt;PS MarkSweep（别名：&lt;span class=&quot;fontstyle0&quot;&gt;Parallel Old&lt;/span&gt; ）&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt; the parallel scavenge mark-sweep collector, parallelised version (i.e. uses multiple threads) of the &lt;strong&gt;MarkSweepCompact&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;fontstyle0&quot;&gt;Parallel Old是Parallel Scavenge收集器的老年代版本， 使用多线程和“标记-整理” 算法。 &lt;br/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;fontstyle0&quot;&gt;同样，也是上面&lt;/span&gt;&lt;strong&gt;MarkSweepCompact 的多线程版本。&lt;/strong&gt;&lt;/p&gt;

&lt;h3&gt; 2.3 &lt;strong&gt;ConcurrentMarkSweep （别名：CMS）&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt; the concurrent collector, a garbage collection algorithm that attempts to do most of the garbage collection work in the background without stopping application threads while it works (there are still phases where it has to stop application threads, but these phases are attempted to be kept to a minimum). Note if the concurrent collector fails to keep up with the garbage, it fails over to the serial &lt;strong&gt;MarkSweepCompact&lt;/strong&gt; collector for (just) the next GC.&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;fontstyle0&quot;&gt;CMS（Concurrent Mark Sweep） 收集器是一种以获取最短回收停顿时间为目标的收集器。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;CMS收集器工作时，会在后台完成大部分的垃圾收集工作而不停止用户线程（停止用户线程的阶段依然存在，只是会被维持在很低的水平）&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;fontstyle0&quot;&gt;CMS运行期间可能失败， 这时虚拟机将启动后备预案： 临时启用Serial Old（&lt;/span&gt;&lt;strong&gt;MarkSweepCompact &lt;/strong&gt;&lt;span class=&quot;fontstyle0&quot;&gt;）收集器来重新进行老年代的垃圾收集， 这样停顿时间就很长了。 &lt;/span&gt;&lt;/p&gt;

&lt;h3&gt;2.4 G1 Mixed Generation&lt;/h3&gt;
&lt;p&gt; the garbage first collector, uses the 'Garbage First' algorithm which splits up the heap into lots of smaller spaces.&lt;/p&gt;

&lt;h2&gt;3.总结&lt;/h2&gt;
&lt;p&gt;All of the garbage collection algorithms except &lt;strong&gt;ConcurrentMarkSweep&lt;/strong&gt; are stop-the-world, i.e. they stop all application threads while they operate - the stop is known as 'pause' time. The &lt;strong&gt;ConcurrentMarkSweep&lt;/strong&gt; tries to do most of it's work in the background and minimize the pause time, but it also has a stop-the-world phase and can fail into the &lt;strong&gt;MarkSweepCompact&lt;/strong&gt; which is fully stop-the-world. (The &lt;strong&gt;G1&lt;/strong&gt; collector has a concurrent phase but is currently mostly stop-the-world).&lt;/p&gt;
&lt;p&gt; 所有的垃圾回收算法，除了ConcurrentMarkSweep外， 都会stop-the-world，比如他们在进行垃圾回收时，会停止所有的应用程序线程。ConcurrentMarkSweep 试图在后台进行大部分的工作，尽量把停顿时间削减到最小，但是它仍然会有stop-the-world阶段。而且，当ConcurrentMarkSweep 收集失败时，会回退到MarkSweepCompact算法（该算法会完全阻止应用程序的运行） &lt;/p&gt;

&lt;p&gt;以上只是简单介绍，详细可以参考书籍或者以下链接：&lt;/p&gt;
&lt;div class=&quot;article-title-box&quot;&gt;
&lt;p class=&quot;title-article&quot;&gt;&lt;a href=&quot;https://blog.csdn.net/zhshulin/article/details/50614477&quot; target=&quot;_blank&quot;&gt;JVM-垃圾收集器&lt;/a&gt;&lt;/p&gt;

&lt;/div&gt;

&lt;h2&gt;4.判断当前正在使用的垃圾收集器&lt;/h2&gt;
&lt;p&gt;如果程序已经处于运行状态，可使用jconsole、jinfo（linux下）查看。&lt;/p&gt;


&lt;p&gt;That's the set of garbage collectors available, but they operate in two different heap spaces and it's the combination that is what we actually end up with for a particular JVM setting, so I'll also list the combinations that are possible. It doesn't explode into a dozen combinations because not all of these collectors work with each other. G1 is effectively an antisocial collector that doesn't like working with anyone else; the serial collectors are the &quot;last man picked&quot; collectors; the 'PS' collectors like to work with each other; and ParNew and Concurrent like to work together. &lt;/p&gt;
&lt;p&gt; 译文：以上即使存在的所有的垃圾收集器，但是他们分别在两块不同的堆区域上运行，针对一个特定的JVM，我们最终需要的内存设置是新生代和老年代的收集器组合。&lt;/p&gt;
&lt;p&gt;因此，我将会列举所有可能的收集器组合。这并不会造成组合数量激增，因为并不是所有的垃圾收集器都能愉快地两两组合。G1是最不善社交的收集器，它和任何一个别的收集器都不合群；单线程收集器是那个最后的备胎收集器；多线程&quot;PS&quot;收集器喜欢互相一起玩；ParNew喜欢和CMS一起工作。&lt;/p&gt;

&lt;p&gt;The full list of possible GC algorithm combinations that can work are:&lt;/p&gt;
&lt;table summary=&quot;All Main Combinations Of GC Options&quot; border=&quot;1&quot;&gt;&lt;tbody readability=&quot;18.5&quot;&gt;&lt;tr&gt;&lt;th&gt;Command Options*&lt;/th&gt;
&lt;th&gt;Resulting Collector Combination&lt;/th&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;&lt;strong&gt;-XX:+UseSerialGC&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;young &lt;strong&gt;Copy&lt;/strong&gt; and old &lt;strong&gt;MarkSweepCompact&lt;/strong&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;&lt;strong&gt;-XX:+UseG1GC&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;young &lt;strong&gt;G1 Young&lt;/strong&gt; and old &lt;strong&gt;G1 Mixed&lt;/strong&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;4&quot;&gt;&lt;td&gt;&lt;strong&gt;-XX:+UseParallelGC -XX:+UseParallelOldGC -XX:+UseAdaptiveSizePolicy&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;young &lt;strong&gt;PS Scavenge&lt;/strong&gt; old &lt;strong&gt;PS MarkSweep&lt;/strong&gt; with adaptive sizing&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;5&quot;&gt;&lt;td&gt;&lt;strong&gt;-XX:+UseParallelGC -XX:+UseParallelOldGC -XX:-UseAdaptiveSizePolicy&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;young &lt;strong&gt;PS Scavenge&lt;/strong&gt; old &lt;strong&gt;PS MarkSweep&lt;/strong&gt;, no adaptive sizing&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;5&quot;&gt;&lt;td&gt;&lt;strong&gt;-XX:+UseParNewGC (&lt;em&gt;deprecated in Java 8 and removed in Java 9 - for ParNew see the line below which is NOT deprecated&lt;/em&gt;)&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;young &lt;strong&gt;ParNew&lt;/strong&gt; old &lt;strong&gt;MarkSweepCompact&lt;/strong&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;4&quot;&gt;&lt;td&gt;&lt;strong&gt;-XX:+UseConcMarkSweepGC -XX:+UseParNewGC&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;young &lt;strong&gt;ParNew&lt;/strong&gt; old &lt;strong&gt;ConcurrentMarkSweep&lt;/strong&gt;**&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;4&quot;&gt;&lt;td&gt;&lt;strong&gt;-XX:+UseConcMarkSweepGC -XX:-UseParNewGC (&lt;em&gt;deprecated in Java 8 and removed in Java 9&lt;/em&gt;)&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;young &lt;strong&gt;Copy&lt;/strong&gt; old &lt;strong&gt;ConcurrentMarkSweep&lt;/strong&gt;**&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;5&quot;&gt;&lt;td colspan=&quot;2&quot;&gt;*All the combinations listed here will fail to let the JVM start if you add another GC algorithm not listed, with the exception of -XX:+UseParNewGC which is only combinable with -XX:+UseConcMarkSweepGC&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;6&quot;&gt;&lt;td colspan=&quot;2&quot;&gt;**there are many many options for use with -XX:+UseConcMarkSweepGC which change the algorithm, e.g.
&lt;ul&gt;&lt;li&gt;-XX:+/-CMSIncrementalMode (&lt;em&gt;deprecated in Java 8 and removed in Java 9&lt;/em&gt;) - uses or disables an incremental concurrent GC algorithm&lt;/li&gt;
&lt;li&gt;-XX:+/-CMSConcurrentMTEnabled - uses or disables parallel (multiple threads) concurrent GC algorithm&lt;/li&gt;
&lt;li&gt;-XX:+/-UseCMSCompactAtFullCollection - uses or disables a compaction when a full GC occurs&lt;/li&gt;
&lt;/ul&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;


&lt;h2&gt;1.测试程序&lt;/h2&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;35&quot;&gt;
&lt;pre&gt;
&lt;span&gt;import&lt;/span&gt;&lt;span&gt; java.lang.management.GarbageCollectorMXBean;
&lt;/span&gt;&lt;span&gt;import&lt;/span&gt;&lt;span&gt; java.lang.management.ManagementFactory;
&lt;/span&gt;&lt;span&gt;import&lt;/span&gt;&lt;span&gt; java.util.List;

&lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;&lt;span&gt; Test {
    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; &lt;span&gt;void&lt;/span&gt;&lt;span&gt; main(String args[]) {
        List&lt;/span&gt;&amp;lt;GarbageCollectorMXBean&amp;gt; l =&lt;span&gt; ManagementFactory.getGarbageCollectorMXBeans();
        &lt;/span&gt;&lt;span&gt;assert&lt;/span&gt; (l != &lt;span&gt;null&lt;/span&gt; &amp;amp;&amp;amp; l.size() ==2&lt;span&gt;);
        &lt;/span&gt;&lt;span&gt;assert&lt;/span&gt;(l.size() == 2&lt;span&gt;);

        &lt;/span&gt;&lt;span&gt;for&lt;/span&gt; (&lt;span&gt;int&lt;/span&gt; i = 0; i &amp;lt; l.size(); i++&lt;span&gt;) {
            GarbageCollectorMXBean garbageCollectorMXBean &lt;/span&gt;=&lt;span&gt; l.get(i);
            &lt;/span&gt;&lt;span&gt;if&lt;/span&gt; (i == 0&lt;span&gt;){
                System.out.println(&lt;/span&gt;&quot;young generation:&quot; +&lt;span&gt; garbageCollectorMXBean.getName());
            }&lt;/span&gt;&lt;span&gt;else&lt;/span&gt; &lt;span&gt;if&lt;/span&gt; (i == 1&lt;span&gt;){
                System.out.println(&lt;/span&gt;&quot;old generation:&quot; +&lt;span&gt; garbageCollectorMXBean.getName());
            }
        }
    }
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;2.测试过程&lt;/h2&gt;
&lt;h3&gt;2.0 《深入java虚拟机》中展示的虚拟机组合&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/519126/201901/519126-20190105101533561-2065351244.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;以上共有7种组合。我们在下面一一测试。&lt;/p&gt;
&lt;p&gt;本机环境：（jdk 1.8，Server模式）&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;36&quot;&gt;
&lt;pre&gt;
E:\javabase\src&amp;gt;java -XX:+PrintCommandLineFlags -&lt;span&gt;version
&lt;/span&gt;-XX:InitialHeapSize=&lt;span&gt;126839040&lt;/span&gt; -XX:MaxHeapSize=&lt;span&gt;2029424640&lt;/span&gt; -XX:+&lt;span&gt;PrintCommandLineFl
ags &lt;/span&gt;-XX:+UseCompressedClassPointers -XX:+UseCompressedOops -XX:-&lt;span&gt;UseLargePagesInd
ividualAllocation &lt;/span&gt;-XX:+&lt;span&gt;UseParallelGC
java version &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;1.8.0_11&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;
Java(TM) SE Runtime Environment (build &lt;/span&gt;&lt;span&gt;1.8&lt;/span&gt;.0_11-&lt;span&gt;b12)
Java HotSpot(TM) &lt;/span&gt;&lt;span&gt;64&lt;/span&gt;-Bit Server VM (build &lt;span&gt;25.11&lt;/span&gt;-b03, mixed mode)
&lt;/pre&gt;&lt;/div&gt;


&lt;h3&gt;2.1 默认无参数&lt;/h3&gt;
&lt;p&gt;E:\javabase\src&amp;gt;java Test&lt;br/&gt;&lt;span&gt;young generation:PS Scavenge&lt;/span&gt;&lt;br/&gt;&lt;span&gt;old generation:PS MarkSweep&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;根据前面的介绍，PS Scavenge对应Parallel Scavenge，PS MarkSweep对应Parallel Old，&lt;/p&gt;
&lt;p&gt;即对应上图中的连线组合6.&lt;/p&gt;

&lt;h3&gt;2.2 -XX:+UseSerialGC&lt;/h3&gt;
&lt;p&gt;E:\javabase\src&amp;gt;java -XX:+UseSerialGC Test&lt;br/&gt;&lt;span&gt;young generation:Copy&lt;/span&gt;&lt;br/&gt;&lt;span&gt;old generation:MarkSweepCompact&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;对应上图中的连线组合2.&lt;/p&gt;


&lt;h3&gt;2.3 +UseG1GC&lt;/h3&gt;
&lt;p&gt;E:\javabase\src&amp;gt;java -XX:+UseG1GC Test&lt;br/&gt;&lt;span&gt;young generation:G1 Young Generation&lt;/span&gt;&lt;br/&gt;&lt;span&gt;old generation:G1 Old Generation&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;对应上图中的连线组合7.&lt;/p&gt;


&lt;h3&gt;2.4 -XX:+UseParallelGC -XX:+UseParallelOldGC -XX:+UseAdaptiveSizePolicy&lt;/h3&gt;
&lt;p&gt;E:\javabase\src&amp;gt;java -XX:+UseParallelGC -XX:+UseParallelOldGC -XX:+UseAdaptiveSizePolicy Test&lt;/p&gt;
&lt;p&gt;&lt;span&gt;young generation:PS Scavenge&lt;br/&gt;old generation:PS MarkSweep&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;对应上图中的连线组合5.&lt;/p&gt;

&lt;h3&gt;2.5 -XX:+UseParallelGC -XX:+UseParallelOldGC -XX:-UseAdaptiveSizePolicy&lt;/h3&gt;
&lt;p&gt;E:\javabase\src&amp;gt;java -XX:+UseParallelGC -XX:+UseParallelOldGC -XX:-UseAdaptiveSizePolicy Test&lt;br/&gt;&lt;span&gt;young generation:PS Scavenge&lt;/span&gt;&lt;br/&gt;&lt;span&gt;old generation:PS MarkSweep&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;对应上图中的连线组合5.&lt;/p&gt;

&lt;h3&gt;2.6 -XX:+UseParNewGC&lt;/h3&gt;
&lt;p&gt;E:\javabase\src&amp;gt;java -XX:+UseParNewGC Test&lt;br/&gt;Java HotSpot(TM) 64-Bit Server VM warning: Using the ParNew young collector with the Serial old collector is deprecated and will likely be removed in a future release&lt;br/&gt;&lt;span&gt;young generation:ParNew&lt;/span&gt;&lt;br/&gt;&lt;span&gt;old generation:MarkSweepCompact&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;对应上图中的连线组合4. 该组合已过期，在未来版本将会移除。&lt;/p&gt;


&lt;h3&gt;2.7 -XX:+UseConcMarkSweepGC -XX:+UseParNewGC&lt;/h3&gt;
&lt;p&gt;E:\javabase\src&amp;gt;java -XX:+UseConcMarkSweepGC -XX:+UseParNewGC Test&lt;br/&gt;&lt;span&gt;young generation:ParNew&lt;/span&gt;&lt;br/&gt;&lt;span&gt;old generation:ConcurrentMarkSweep&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;对应上图中的连线组合3&lt;/p&gt;

&lt;h3&gt;2.8 -XX:+UseConcMarkSweepGC -XX:-UseParNewGC&lt;/h3&gt;
&lt;p&gt;E:\javabase\src&amp;gt;java -XX:+UseConcMarkSweepGC -XX:-UseParNewGC Test&lt;br/&gt;Java HotSpot(TM) 64-Bit Server VM warning: Using the DefNew young collector with the CMS collector is deprecated and will likely be removed in a future release&lt;br/&gt;&lt;span&gt;young generation:Copy&lt;/span&gt;&lt;br/&gt;&lt;span&gt;old generation:ConcurrentMarkSweep&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;对应上图中的连线组合1.  该组合已过期，在未来版本将会移除。&lt;/p&gt;


&lt;h2&gt;1.&lt;strong&gt;-XX:+UseSerialGC&lt;/strong&gt;&lt;/h2&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;32&quot;&gt;
&lt;pre&gt;
C:\Users\Administrator\Desktop&amp;gt;java -XX:+UseSerialGC -jar javadoc-jar-&lt;span&gt;vi&lt;/span&gt;&lt;span&gt;
ewer&lt;/span&gt;-&lt;span&gt;1.0&lt;/span&gt;.jar
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt; &lt;img src=&quot;https://img2018.cnblogs.com/blog/519126/201901/519126-20190104220626444-8441419.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;h2&gt;2.&lt;strong&gt;-XX:+UseG1GC&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt; &lt;img src=&quot;https://img2018.cnblogs.com/blog/519126/201901/519126-20190104220734968-1722868308.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;h2&gt;3.-XX:+UseParallelGC -XX:+UseParallelOldGC -XX:+UseAdaptiveSizePolicy&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/519126/201901/519126-20190104221058246-654569587.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;h2&gt;4.-XX:+UseParallelGC -XX:+UseParallelOldGC -XX:-UseAdaptiveSizePolicy&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/519126/201901/519126-20190104221316610-646218639.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;h2&gt;5.&lt;strong&gt;-XX:+UseParNewGC &lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt; &lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;该选项会有过期的提示：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;C:\Users\Administrator\Desktop&amp;gt;java -XX:+UseParNewGC -jar javadoc-jar-viewer-1.&lt;br/&gt;0.jar&lt;br/&gt;&lt;strong&gt;Java HotSpot(TM) 64-Bit Server VM warning:&lt;/strong&gt; Using the ParNew young collector with&lt;br/&gt;the Serial old collector is deprecated and will likely be removed in a future r&lt;br/&gt;elease&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/519126/201901/519126-20190104221610653-743655867.png&quot; alt=&quot;&quot;/&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;h2&gt;6.-XX:+UseConcMarkSweepGC -XX:+UseParNewGC &lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/519126/201901/519126-20190104221840319-69033949.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;h2&gt;7.-XX:+UseConcMarkSweepGC -XX:-UseParNewGC &lt;/h2&gt;
&lt;p&gt;该组合选项会有警告提示：&lt;/p&gt;
&lt;p&gt;C:\Users\Administrator\Desktop&amp;gt;java -XX:+UseConcMarkSweepGC -XX:-UseParNewGC -ja&lt;br/&gt;r javadoc-jar-viewer-1.0.jar&lt;br/&gt;Java HotSpot(TM) 64-Bit Server VM &lt;span&gt;warning&lt;/span&gt;: Using the DefNew young collector with&lt;br/&gt;the CMS collector is deprecated and will likely be removed in a future release&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/519126/201901/519126-20190104222006124-662241946.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;


&lt;table summary=&quot;Command Options Equivalent To Combinations In The Above Table&quot; border=&quot;1&quot;&gt;&lt;tbody readability=&quot;10.752190237797&quot;&gt;&lt;tr&gt;&lt;th&gt;Command Options Used On Their Own&lt;/th&gt;
&lt;th&gt;Equivalent To Entry In Table Above&lt;/th&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;&lt;strong&gt;-XX:+UseParallelGC&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;-XX:+UseParallelGC -XX:+UseParallelOldGC&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;&lt;strong&gt;-XX:+UseParallelOldGC&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;-XX:+UseParallelGC -XX:+UseParallelOldGC&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;4&quot;&gt;&lt;td&gt;&lt;strong&gt;-Xincgc (&lt;em&gt;deprecated in Java 8 and removed in Java 9&lt;/em&gt;)&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;-XX:+UseParNewGC -XX:+UseConcMarkSweepGC&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;&lt;strong&gt;-XX:+UseConcMarkSweepGC&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;-XX:+UseParNewGC -XX:+UseConcMarkSweepGC&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;4.5714285714286&quot;&gt;&lt;td&gt;&lt;strong&gt;no option on most Windows&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;-XX:+UseG1GC from Java 9, or before that -XX:+UseSerialGC (see also &lt;a href=&quot;http://www.techpaste.com/2012/02/default-jvm-settings-gc-jit-java-heap-sizes-xms-xmx-operating-systems/#more-3569&quot; target=&quot;_blank&quot;&gt;this page&lt;/a&gt;)&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;3.7647058823529&quot;&gt;&lt;td&gt;&lt;strong&gt;no option on most Unix&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;-XX:+UseG1GC from Java 9, or before that -XX:+UseParallelGC -XX:+UseParallelOldGC -XX:+UseAdaptiveSizePolicy (see also &lt;a href=&quot;http://www.techpaste.com/2012/02/default-jvm-settings-gc-jit-java-heap-sizes-xms-xmx-operating-systems/#more-3569&quot; target=&quot;_blank&quot;&gt;this page&lt;/a&gt;)&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;3&quot;&gt;&lt;td&gt;&lt;strong&gt;-XX:+AggressiveHeap&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;-XX:+UseParallelGC -XX:+UseParallelOldGC -XX:+UseAdaptiveSizePolicy with a bunch of other options related to sizing memory and threads and how they interact with the OS&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;&lt;span&gt; &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;1.&lt;strong&gt;-XX:+UseParallelGC&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/519126/201901/519126-20190104222444093-1928902620.png&quot; alt=&quot;&quot;/&gt;&lt;/span&gt;&lt;/p&gt;




&lt;h2&gt;2.&lt;strong&gt;-XX:+UseParallelOldGC&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/519126/201901/519126-20190104222556722-1590436089.png&quot; alt=&quot;&quot;/&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;h2&gt;3.&lt;strong&gt;-Xincgc &lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;C:\Users\Administrator\Desktop&amp;gt;java -Xincgc -jar javadoc-jar-viewer-1.0.jar&lt;br/&gt;Java HotSpot(TM) 64-Bit Server VM warning: Using incremental CMS is deprecated a&lt;br/&gt;nd will likely be removed in a future release&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/519126/201901/519126-20190104222737508-682067381.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;h2&gt;4.&lt;strong&gt;-XX:+UseConcMarkSweepGC&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/519126/201901/519126-20190104222844946-2014483796.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;h2&gt; 5.windows上默认无选项时&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/519126/201901/519126-20190104223040007-821169575.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/519126/201901/519126-20190104223131064-466880217.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;h2&gt; 6.-XX:+AggressiveHeap&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/519126/201901/519126-20190104223254541-1502350226.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;


&lt;p&gt;鼠标点选设置jvm参数：&lt;em id=&quot;__mceDel&quot;&gt;&lt;a href=&quot;http://jvmmemory.com/&quot; target=&quot;_blank&quot;&gt;http://jvmmemory.com/&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;

</description>
<pubDate>Sat, 05 Jan 2019 06:04:00 +0000</pubDate>
<dc:creator>三国梦回</dc:creator>
<og:description>前言 相信很多人都看过下面这张图，（来自《深入理解Java虚拟机：JVM高级特性与最佳实践》） 在学完几种垃圾收集器类型及组合后，打算看看实际中程序用到的垃圾收集器。 但是在jconsole中看到的，</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/grey-wolf/p/10222758.html</dc:identifier>
</item>
<item>
<title>WebGL------osg框架学习二 - ccentry</title>
<link>http://www.cnblogs.com/ccentry/p/10224312.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/ccentry/p/10224312.html</guid>
<description>&lt;p&gt;　　今天我们继续来学习osg.js框架。上一篇我们介绍了DrawActor对象绘制操作类和Drawable可绘制对象类，我们大致知道了osg对Drawable可绘制对象的绘制流程管理。今天我们要继续介绍StateBin状态树节点类。我们来看一下StateBin，他管理的是StateSet状态，他将每个模型节点的StateSet状态信息（shaderLink，材质，depth等）包装成树节点，从而能够将状态节点递归组装成一棵状态树。我们来看看StateBin的构造函数。&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;36&quot;&gt;
&lt;pre&gt;
&lt;span&gt; 1&lt;/span&gt; &lt;span&gt;/*&lt;/span&gt;
&lt;span&gt; 2&lt;/span&gt; &lt;span&gt;状态树结点
&lt;/span&gt;&lt;span&gt; 3&lt;/span&gt; &lt;span&gt;保存一个StateSet,每个StateSet都有一个唯一ID
&lt;/span&gt;&lt;span&gt; 4&lt;/span&gt;  &lt;span&gt;*/&lt;/span&gt;
&lt;span&gt; 5&lt;/span&gt; &lt;span&gt;//&lt;/span&gt;&lt;span&gt;let MemoryPool = require('../util/MemoryPool');&lt;/span&gt;
&lt;span&gt; 6&lt;/span&gt; 
&lt;span&gt; 7&lt;/span&gt; let StateBin = &lt;span&gt;function&lt;/span&gt;&lt;span&gt; () {
&lt;/span&gt;&lt;span&gt; 8&lt;/span&gt;     &lt;span&gt;this&lt;/span&gt;._stateset =&lt;span&gt; undefined;
&lt;/span&gt;&lt;span&gt; 9&lt;/span&gt;     &lt;span&gt;this&lt;/span&gt;._parent = undefined;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;StateBin&lt;/span&gt;
&lt;span&gt;10&lt;/span&gt;     &lt;span&gt;this&lt;/span&gt;._children = {};&lt;span&gt;//&lt;/span&gt;&lt;span&gt;属性名为StateSet的ID，值为StateBin&lt;/span&gt;
&lt;span&gt;11&lt;/span&gt;     &lt;span&gt;//&lt;/span&gt;&lt;span&gt;this._children._keys = [];//StateSet的ID&lt;/span&gt;
&lt;span&gt;12&lt;/span&gt;     &lt;span&gt;this&lt;/span&gt;._depth = 0;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;树的深度值&lt;/span&gt;
&lt;span&gt;13&lt;/span&gt; };
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　首先我们可以看到StateBin的成员，this._stateset这就是模型节点的状态信息（shaderLink，材质，depth），this._parent该树节点的父节点，this._children该树节点的子节点，this._depth树的深度。这是一个典型的树节点类，熟悉数据结构的同学都明白如何递归构造一棵树，鲫鱼就不再啰嗦了。我们接下来看看StateBin的成员函数有哪些。&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;44&quot;&gt;
&lt;pre&gt;
&lt;span&gt; 1&lt;/span&gt; StateBin.prototype =&lt;span&gt; {
&lt;/span&gt;&lt;span&gt; 2&lt;/span&gt;     getStateSet: &lt;span&gt;function&lt;/span&gt;&lt;span&gt; () {
&lt;/span&gt;&lt;span&gt; 3&lt;/span&gt;         &lt;span&gt;return&lt;/span&gt; &lt;span&gt;this&lt;/span&gt;&lt;span&gt;._stateset;
&lt;/span&gt;&lt;span&gt; 4&lt;/span&gt; &lt;span&gt;    },
&lt;/span&gt;&lt;span&gt; 5&lt;/span&gt;     setStateSet: &lt;span&gt;function&lt;/span&gt;&lt;span&gt; (s) {
&lt;/span&gt;&lt;span&gt; 6&lt;/span&gt;         &lt;span&gt;this&lt;/span&gt;._stateset =&lt;span&gt; s;
&lt;/span&gt;&lt;span&gt; 7&lt;/span&gt; &lt;span&gt;    },
&lt;/span&gt;&lt;span&gt; 8&lt;/span&gt;     getParent: &lt;span&gt;function&lt;/span&gt;&lt;span&gt; () {
&lt;/span&gt;&lt;span&gt; 9&lt;/span&gt;         &lt;span&gt;return&lt;/span&gt; &lt;span&gt;this&lt;/span&gt;&lt;span&gt;._parent;
&lt;/span&gt;&lt;span&gt;10&lt;/span&gt; &lt;span&gt;    },
&lt;/span&gt;&lt;span&gt;11&lt;/span&gt;     reset: &lt;span&gt;function&lt;/span&gt; () {&lt;span&gt;//&lt;/span&gt;&lt;span&gt;重置数据，一般都是根节点调用&lt;/span&gt;
&lt;span&gt;12&lt;/span&gt;         &lt;span&gt;this&lt;/span&gt;._stateset =&lt;span&gt; undefined;
&lt;/span&gt;&lt;span&gt;13&lt;/span&gt;         &lt;span&gt;this&lt;/span&gt;._parent =&lt;span&gt; undefined;
&lt;/span&gt;&lt;span&gt;14&lt;/span&gt; 
&lt;span&gt;15&lt;/span&gt;         &lt;span&gt;//&lt;/span&gt;&lt;span&gt;之所以遍历是为了StateGraph不被析构以内存复用，而不是每次都重新创建&lt;/span&gt;
&lt;span&gt;16&lt;/span&gt;         &lt;span&gt;//&lt;/span&gt;&lt;span&gt;然后是StateGraph的数据必须被清空，重新使用时不会出错&lt;/span&gt;
&lt;span&gt;17&lt;/span&gt;         &lt;span&gt;//&lt;/span&gt;&lt;span&gt; let keys = this._children.keys();&lt;/span&gt;
&lt;span&gt;18&lt;/span&gt;         &lt;span&gt;//&lt;/span&gt;&lt;span&gt; let l = keys.length;&lt;/span&gt;
&lt;span&gt;19&lt;/span&gt;         &lt;span&gt;//&lt;/span&gt;&lt;span&gt; for (let i = 0; i &amp;lt; l; i++) {&lt;/span&gt;
&lt;span&gt;20&lt;/span&gt;         &lt;span&gt;//&lt;/span&gt;&lt;span&gt;     let key = keys[i];&lt;/span&gt;
&lt;span&gt;21&lt;/span&gt;         &lt;span&gt;//&lt;/span&gt;&lt;span&gt;     let child = this._children[key];&lt;/span&gt;
&lt;span&gt;22&lt;/span&gt;         &lt;span&gt;//&lt;/span&gt;&lt;span&gt;     child.reset();&lt;/span&gt;
&lt;span&gt;23&lt;/span&gt;         &lt;span&gt;//&lt;/span&gt;&lt;span&gt;     //内存池&lt;/span&gt;
&lt;span&gt;24&lt;/span&gt;         &lt;span&gt;//&lt;/span&gt;&lt;span&gt;     //MemoryPool.StateBin.put(child);&lt;/span&gt;
&lt;span&gt;25&lt;/span&gt;         &lt;span&gt;//&lt;/span&gt;&lt;span&gt; }&lt;/span&gt;
&lt;span&gt;26&lt;/span&gt;         &lt;span&gt;this&lt;/span&gt;._children =&lt;span&gt; {};
&lt;/span&gt;&lt;span&gt;27&lt;/span&gt;         &lt;span&gt;//&lt;/span&gt;&lt;span&gt;this._children._keys.length = 0;&lt;/span&gt;
&lt;span&gt;28&lt;/span&gt;         &lt;span&gt;//&lt;/span&gt;&lt;span&gt;this._children._keys = [];&lt;/span&gt;
&lt;span&gt;29&lt;/span&gt;         &lt;span&gt;this&lt;/span&gt;._depth = 0&lt;span&gt;;
&lt;/span&gt;&lt;span&gt;30&lt;/span&gt; &lt;span&gt;    },
&lt;/span&gt;&lt;span&gt;31&lt;/span&gt;     addStateBinChild: &lt;span&gt;function&lt;/span&gt;&lt;span&gt; (bin) {
&lt;/span&gt;&lt;span&gt;32&lt;/span&gt;         bin._parent = &lt;span&gt;this&lt;/span&gt;&lt;span&gt;;
&lt;/span&gt;&lt;span&gt;33&lt;/span&gt;         bin._depth = &lt;span&gt;this&lt;/span&gt;._depth + 1&lt;span&gt;;
&lt;/span&gt;&lt;span&gt;34&lt;/span&gt;         let id =&lt;span&gt; bin._stateset.getID();
&lt;/span&gt;&lt;span&gt;35&lt;/span&gt;         &lt;span&gt;this&lt;/span&gt;._children[id] =&lt;span&gt; bin;
&lt;/span&gt;&lt;span&gt;36&lt;/span&gt; &lt;span&gt;    },
&lt;/span&gt;&lt;span&gt;37&lt;/span&gt;     addStateSetChild: &lt;span&gt;function&lt;/span&gt; (stateset) {&lt;span&gt;//&lt;/span&gt;&lt;span&gt;添加子节点，以stateset的id为key，返回新创建或者已经存在的StateBin&lt;/span&gt;
&lt;span&gt;38&lt;/span&gt;         let id =&lt;span&gt; stateset.getID();
&lt;/span&gt;&lt;span&gt;39&lt;/span&gt;         let child = &lt;span&gt;this&lt;/span&gt;&lt;span&gt;._children[id];
&lt;/span&gt;&lt;span&gt;40&lt;/span&gt;         &lt;span&gt;if&lt;/span&gt;&lt;span&gt; (child) {
&lt;/span&gt;&lt;span&gt;41&lt;/span&gt;             &lt;span&gt;return&lt;/span&gt;&lt;span&gt; child;
&lt;/span&gt;&lt;span&gt;42&lt;/span&gt;         } &lt;span&gt;else&lt;/span&gt;&lt;span&gt; {
&lt;/span&gt;&lt;span&gt;43&lt;/span&gt;             let sg = &lt;span&gt;new&lt;/span&gt;&lt;span&gt; StateBin();
&lt;/span&gt;&lt;span&gt;44&lt;/span&gt;             &lt;span&gt;//&lt;/span&gt;&lt;span&gt;let sg = MemoryPool.StateBin.get();&lt;/span&gt;
&lt;span&gt;45&lt;/span&gt;             sg._parent = &lt;span&gt;this&lt;/span&gt;&lt;span&gt;;
&lt;/span&gt;&lt;span&gt;46&lt;/span&gt;             sg._depth = &lt;span&gt;this&lt;/span&gt;._depth + 1&lt;span&gt;;
&lt;/span&gt;&lt;span&gt;47&lt;/span&gt;             sg._stateset =&lt;span&gt; stateset;
&lt;/span&gt;&lt;span&gt;48&lt;/span&gt;             &lt;span&gt;this&lt;/span&gt;._children[id] =&lt;span&gt; sg;
&lt;/span&gt;&lt;span&gt;49&lt;/span&gt;             &lt;span&gt;//&lt;/span&gt;&lt;span&gt;children._keys.push(id);&lt;/span&gt;
&lt;span&gt;50&lt;/span&gt;             &lt;span&gt;return&lt;/span&gt;&lt;span&gt; sg;
&lt;/span&gt;&lt;span&gt;51&lt;/span&gt; &lt;span&gt;        }
&lt;/span&gt;&lt;span&gt;52&lt;/span&gt; &lt;span&gt;    },
&lt;/span&gt;&lt;span&gt;53&lt;/span&gt;     removeStateBinChild: &lt;span&gt;function&lt;/span&gt;&lt;span&gt; (bin) {
&lt;/span&gt;&lt;span&gt;54&lt;/span&gt;         let id =&lt;span&gt; bin._stateset.getID();
&lt;/span&gt;&lt;span&gt;55&lt;/span&gt;         let cbin = &lt;span&gt;this&lt;/span&gt;&lt;span&gt;._children[id];
&lt;/span&gt;&lt;span&gt;56&lt;/span&gt;         &lt;span&gt;if&lt;/span&gt;&lt;span&gt; (cbin) {
&lt;/span&gt;&lt;span&gt;57&lt;/span&gt;             cbin.parent =&lt;span&gt; undefined;
&lt;/span&gt;&lt;span&gt;58&lt;/span&gt;             &lt;span&gt;delete&lt;/span&gt; &lt;span&gt;this&lt;/span&gt;&lt;span&gt;._children[id];
&lt;/span&gt;&lt;span&gt;59&lt;/span&gt; &lt;span&gt;        }
&lt;/span&gt;&lt;span&gt;60&lt;/span&gt; &lt;span&gt;    },
&lt;/span&gt;&lt;span&gt;61&lt;/span&gt;     removeStateSetChild: &lt;span&gt;function&lt;/span&gt;&lt;span&gt; (stateset) {
&lt;/span&gt;&lt;span&gt;62&lt;/span&gt;         let id =&lt;span&gt; stateset.getID();
&lt;/span&gt;&lt;span&gt;63&lt;/span&gt;         let cbin = &lt;span&gt;this&lt;/span&gt;&lt;span&gt;._children[id];
&lt;/span&gt;&lt;span&gt;64&lt;/span&gt;         &lt;span&gt;if&lt;/span&gt;&lt;span&gt; (cbin) {
&lt;/span&gt;&lt;span&gt;65&lt;/span&gt;             cbin.parent =&lt;span&gt; undefined;
&lt;/span&gt;&lt;span&gt;66&lt;/span&gt;             &lt;span&gt;delete&lt;/span&gt; &lt;span&gt;this&lt;/span&gt;&lt;span&gt;._children[id];
&lt;/span&gt;&lt;span&gt;67&lt;/span&gt; &lt;span&gt;        }
&lt;/span&gt;&lt;span&gt;68&lt;/span&gt; &lt;span&gt;    },
&lt;/span&gt;&lt;span&gt;69&lt;/span&gt;     removeChildren: &lt;span&gt;function&lt;/span&gt;&lt;span&gt; () {
&lt;/span&gt;&lt;span&gt;70&lt;/span&gt;         &lt;span&gt;this&lt;/span&gt;._children =&lt;span&gt; {};
&lt;/span&gt;&lt;span&gt;71&lt;/span&gt; &lt;span&gt;    },
&lt;/span&gt;&lt;span&gt;72&lt;/span&gt; };
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;我们一个一个来看，getStateSet获取当前树节点的渲染状态信息this._stateset；setStateSet设置当前树节点的渲染状态信息即修改this._stateset；getParent获取当前树节点的父节点；reset初始化节点数据，将节点属性清空析构；addStateBinChild向当前树节点中加入一个子节点；addStateSetChild如果当前树节点存在id是stateset的id的子节点，就返回该子节点，如果不存在就创建一个stateset状态的子节点并返回；removeStateBinChild删除当前节点的确定id的某个子节点；removeStateSetChild删除当前节点某个状态是stateset的子节点；removeChildren删除该树节点的所有子节点。&lt;/p&gt;
&lt;p&gt;　　我们可以清楚的看到，成员函数基本都是对树结构的操作，最后还有一个方法是对父状态的遍历继承，我们来看一下。&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;38&quot;&gt;
&lt;pre&gt;
&lt;span&gt; 1&lt;/span&gt; &lt;span&gt;//&lt;/span&gt;&lt;span&gt;父状态的匹配&lt;/span&gt;
&lt;span&gt; 2&lt;/span&gt; StateBin.moveStateBin = &lt;span&gt;function&lt;/span&gt;&lt;span&gt; (glstate, preStateBin, curStateBin) {
&lt;/span&gt;&lt;span&gt; 3&lt;/span&gt;     &lt;span&gt;if&lt;/span&gt; (curStateBin === preStateBin) {&lt;span&gt;//&lt;/span&gt;&lt;span&gt;两个相同什么都不做&lt;/span&gt;
&lt;span&gt; 4&lt;/span&gt;         &lt;span&gt;return&lt;/span&gt;&lt;span&gt;;
&lt;/span&gt;&lt;span&gt; 5&lt;/span&gt; &lt;span&gt;    }
&lt;/span&gt;&lt;span&gt; 6&lt;/span&gt; 
&lt;span&gt; 7&lt;/span&gt;     &lt;span&gt;if&lt;/span&gt; (curStateBin ===&lt;span&gt; undefined) {
&lt;/span&gt;&lt;span&gt; 8&lt;/span&gt;         &lt;span&gt;//&lt;/span&gt;&lt;span&gt;curStateBin已经到顶，弹出preStateBin的所有状态&lt;/span&gt;
&lt;span&gt; 9&lt;/span&gt;         &lt;span&gt;do&lt;/span&gt;&lt;span&gt; {
&lt;/span&gt;&lt;span&gt;10&lt;/span&gt;             &lt;span&gt;if&lt;/span&gt; (preStateBin._stateset !==&lt;span&gt; undefined) {
&lt;/span&gt;&lt;span&gt;11&lt;/span&gt; &lt;span&gt;                glstate.popStateSet();
&lt;/span&gt;&lt;span&gt;12&lt;/span&gt; &lt;span&gt;            }
&lt;/span&gt;&lt;span&gt;13&lt;/span&gt;             preStateBin =&lt;span&gt; preStateBin._parent;
&lt;/span&gt;&lt;span&gt;14&lt;/span&gt;         } &lt;span&gt;while&lt;/span&gt;&lt;span&gt; (preStateBin);
&lt;/span&gt;&lt;span&gt;15&lt;/span&gt;         &lt;span&gt;return&lt;/span&gt;&lt;span&gt;;
&lt;/span&gt;&lt;span&gt;16&lt;/span&gt; &lt;span&gt;    }
&lt;/span&gt;&lt;span&gt;17&lt;/span&gt; 
&lt;span&gt;18&lt;/span&gt;     &lt;span&gt;if&lt;/span&gt; (preStateBin ===&lt;span&gt; undefined) {
&lt;/span&gt;&lt;span&gt;19&lt;/span&gt;         &lt;span&gt;//&lt;/span&gt;&lt;span&gt;preStateBin已经到顶，压入curStateBin的所有状态&lt;/span&gt;
&lt;span&gt;20&lt;/span&gt;         &lt;span&gt;//&lt;/span&gt;&lt;span&gt;从子节点往根节点遍历获取所有的状态，但是推给glstate必须从根节点往子节点遍历&lt;/span&gt;
&lt;span&gt;21&lt;/span&gt;         &lt;span&gt;//&lt;/span&gt;&lt;span&gt;所以这里先塞到一个stack里面，然后再遍历stack推给glstate&lt;/span&gt;
&lt;span&gt;22&lt;/span&gt;         let stack =&lt;span&gt; [];
&lt;/span&gt;&lt;span&gt;23&lt;/span&gt;         &lt;span&gt;do&lt;/span&gt;&lt;span&gt; {
&lt;/span&gt;&lt;span&gt;24&lt;/span&gt;             &lt;span&gt;if&lt;/span&gt; (curStateBin._stateset !==&lt;span&gt; undefined) {
&lt;/span&gt;&lt;span&gt;25&lt;/span&gt; &lt;span&gt;                stack.push(curStateBin._stateset);
&lt;/span&gt;&lt;span&gt;26&lt;/span&gt; &lt;span&gt;            }
&lt;/span&gt;&lt;span&gt;27&lt;/span&gt;             curStateBin =&lt;span&gt; curStateBin._parent;
&lt;/span&gt;&lt;span&gt;28&lt;/span&gt;         } &lt;span&gt;while&lt;/span&gt;&lt;span&gt; (curStateBin);
&lt;/span&gt;&lt;span&gt;29&lt;/span&gt; 
&lt;span&gt;30&lt;/span&gt;         let size = stack.length - 1&lt;span&gt;;
&lt;/span&gt;&lt;span&gt;31&lt;/span&gt;         &lt;span&gt;for&lt;/span&gt; (let i = size; i &amp;gt;= 0; --&lt;span&gt;i) {
&lt;/span&gt;&lt;span&gt;32&lt;/span&gt; &lt;span&gt;            glstate.pushStateSet(stack[i]);
&lt;/span&gt;&lt;span&gt;33&lt;/span&gt; &lt;span&gt;        }
&lt;/span&gt;&lt;span&gt;34&lt;/span&gt;         &lt;span&gt;return&lt;/span&gt;&lt;span&gt;;
&lt;/span&gt;&lt;span&gt;35&lt;/span&gt;     } &lt;span&gt;else&lt;/span&gt; &lt;span&gt;if&lt;/span&gt; (preStateBin._parent ===&lt;span&gt; curStateBin._parent) {
&lt;/span&gt;&lt;span&gt;36&lt;/span&gt;         &lt;span&gt;//&lt;/span&gt;&lt;span&gt; first handle the typical case which is two glstate groups&lt;/span&gt;
&lt;span&gt;37&lt;/span&gt;         &lt;span&gt;//&lt;/span&gt;&lt;span&gt; are neighbours.&lt;/span&gt;
&lt;span&gt;38&lt;/span&gt; 
&lt;span&gt;39&lt;/span&gt;         &lt;span&gt;//&lt;/span&gt;&lt;span&gt; glstate has changed so need to pop old glstate.&lt;/span&gt;
&lt;span&gt;40&lt;/span&gt;         &lt;span&gt;if&lt;/span&gt; (preStateBin._stateset !==&lt;span&gt; undefined) {
&lt;/span&gt;&lt;span&gt;41&lt;/span&gt; &lt;span&gt;            glstate.popStateSet();
&lt;/span&gt;&lt;span&gt;42&lt;/span&gt; &lt;span&gt;        }
&lt;/span&gt;&lt;span&gt;43&lt;/span&gt;         &lt;span&gt;//&lt;/span&gt;&lt;span&gt; and push new glstate.&lt;/span&gt;
&lt;span&gt;44&lt;/span&gt;         &lt;span&gt;if&lt;/span&gt; (curStateBin._stateset !==&lt;span&gt; undefined) {
&lt;/span&gt;&lt;span&gt;45&lt;/span&gt; &lt;span&gt;            glstate.pushStateSet(curStateBin._stateset);
&lt;/span&gt;&lt;span&gt;46&lt;/span&gt; &lt;span&gt;        }
&lt;/span&gt;&lt;span&gt;47&lt;/span&gt;         &lt;span&gt;return&lt;/span&gt;&lt;span&gt;;
&lt;/span&gt;&lt;span&gt;48&lt;/span&gt; &lt;span&gt;    }
&lt;/span&gt;&lt;span&gt;49&lt;/span&gt; 
&lt;span&gt;50&lt;/span&gt;     &lt;span&gt;//&lt;/span&gt;&lt;span&gt;先弹出状态，保证preStateBin和curStateBin达到树节点平级&lt;/span&gt;
&lt;span&gt;51&lt;/span&gt;     &lt;span&gt;//&lt;/span&gt;&lt;span&gt;无法确定两个树节点谁的深度值更多，两个都做一次循环&lt;/span&gt;
&lt;span&gt;52&lt;/span&gt;     &lt;span&gt;while&lt;/span&gt; (preStateBin._depth &amp;gt;&lt;span&gt; curStateBin._depth) {
&lt;/span&gt;&lt;span&gt;53&lt;/span&gt;         &lt;span&gt;if&lt;/span&gt; (preStateBin._stateset !==&lt;span&gt; undefined) {
&lt;/span&gt;&lt;span&gt;54&lt;/span&gt; &lt;span&gt;            glstate.popStateSet();
&lt;/span&gt;&lt;span&gt;55&lt;/span&gt; &lt;span&gt;        }
&lt;/span&gt;&lt;span&gt;56&lt;/span&gt;         preStateBin =&lt;span&gt; preStateBin._parent;
&lt;/span&gt;&lt;span&gt;57&lt;/span&gt; &lt;span&gt;    }
&lt;/span&gt;&lt;span&gt;58&lt;/span&gt; 
&lt;span&gt;59&lt;/span&gt;     &lt;span&gt;//&lt;/span&gt;&lt;span&gt; use return path to trace back steps to curStateBin.&lt;/span&gt;
&lt;span&gt;60&lt;/span&gt;     let stack =&lt;span&gt; [];
&lt;/span&gt;&lt;span&gt;61&lt;/span&gt;     &lt;span&gt;//&lt;/span&gt;&lt;span&gt; need to pop back up to the same depth as the curr glstate group.&lt;/span&gt;
&lt;span&gt;62&lt;/span&gt;     &lt;span&gt;while&lt;/span&gt; (curStateBin._depth &amp;gt;&lt;span&gt; preStateBin._depth) {
&lt;/span&gt;&lt;span&gt;63&lt;/span&gt;         &lt;span&gt;if&lt;/span&gt; (curStateBin._stateset !==&lt;span&gt; undefined) {
&lt;/span&gt;&lt;span&gt;64&lt;/span&gt; &lt;span&gt;            stack.push(curStateBin._stateset);
&lt;/span&gt;&lt;span&gt;65&lt;/span&gt; &lt;span&gt;        }
&lt;/span&gt;&lt;span&gt;66&lt;/span&gt;         curStateBin =&lt;span&gt; curStateBin._parent;
&lt;/span&gt;&lt;span&gt;67&lt;/span&gt; &lt;span&gt;    }
&lt;/span&gt;&lt;span&gt;68&lt;/span&gt; 
&lt;span&gt;69&lt;/span&gt;     &lt;span&gt;//&lt;/span&gt;&lt;span&gt; now pop back up both parent paths until they agree.&lt;/span&gt;
&lt;span&gt;70&lt;/span&gt;     &lt;span&gt;//&lt;/span&gt;&lt;span&gt; should be this to conform with above case where two StateBin&lt;/span&gt;
&lt;span&gt;71&lt;/span&gt;     &lt;span&gt;//&lt;/span&gt;&lt;span&gt; nodes have the same parent&lt;/span&gt;
&lt;span&gt;72&lt;/span&gt;     &lt;span&gt;//&lt;/span&gt;&lt;span&gt;继续遍历直到两个树节点相同&lt;/span&gt;
&lt;span&gt;73&lt;/span&gt;     &lt;span&gt;while&lt;/span&gt; (preStateBin !==&lt;span&gt; curStateBin) {
&lt;/span&gt;&lt;span&gt;74&lt;/span&gt;         &lt;span&gt;if&lt;/span&gt; (preStateBin._stateset !== undefined) {&lt;span&gt;//&lt;/span&gt;&lt;span&gt;pre的从GLState中出栈&lt;/span&gt;
&lt;span&gt;75&lt;/span&gt; &lt;span&gt;            glstate.popStateSet();
&lt;/span&gt;&lt;span&gt;76&lt;/span&gt; &lt;span&gt;        }
&lt;/span&gt;&lt;span&gt;77&lt;/span&gt;         preStateBin =&lt;span&gt; preStateBin._parent;
&lt;/span&gt;&lt;span&gt;78&lt;/span&gt; 
&lt;span&gt;79&lt;/span&gt;         &lt;span&gt;if&lt;/span&gt; (curStateBin._stateset !== undefined) {&lt;span&gt;//&lt;/span&gt;&lt;span&gt;当前的入栈，临时保存&lt;/span&gt;
&lt;span&gt;80&lt;/span&gt; &lt;span&gt;            stack.push(curStateBin._stateset);
&lt;/span&gt;&lt;span&gt;81&lt;/span&gt; &lt;span&gt;        }
&lt;/span&gt;&lt;span&gt;82&lt;/span&gt;         curStateBin =&lt;span&gt; curStateBin._parent;
&lt;/span&gt;&lt;span&gt;83&lt;/span&gt; &lt;span&gt;    }
&lt;/span&gt;&lt;span&gt;84&lt;/span&gt; 
&lt;span&gt;85&lt;/span&gt;     &lt;span&gt;//&lt;/span&gt;&lt;span&gt;遍历结束后，从临时栈中推入GLState里&lt;/span&gt;
&lt;span&gt;86&lt;/span&gt;     &lt;span&gt;for&lt;/span&gt; (let i = stack.length - 1, l = 0; i &amp;gt;= l; --&lt;span&gt;i) {
&lt;/span&gt;&lt;span&gt;87&lt;/span&gt; &lt;span&gt;        glstate.pushStateSet(stack[i]);
&lt;/span&gt;&lt;span&gt;88&lt;/span&gt; &lt;span&gt;    }
&lt;/span&gt;&lt;span&gt;89&lt;/span&gt; };
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;这段代码我们仔细来看一下。&lt;/p&gt;
&lt;p&gt;第一件事比较当前节点状态和前一个节点状态，相同则直接返回。&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;32&quot;&gt;
&lt;pre&gt;
&lt;span&gt;1&lt;/span&gt; &lt;span&gt;if&lt;/span&gt; (curStateBin === preStateBin) {&lt;span&gt;//&lt;/span&gt;&lt;span&gt;两个相同什么都不做&lt;/span&gt;
&lt;span&gt;2&lt;/span&gt;         &lt;span&gt;return&lt;/span&gt;&lt;span&gt;;
&lt;/span&gt;&lt;span&gt;3&lt;/span&gt;     }
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;接下来如果前后节点状态不同，就继续下面的事情，我们来看下面接下来做了什么事。接下来是判断当前遍历到的状态节点是否已经是树的叶子节点，如果是叶子节点就向树根部遍历，依次弹出上一级父节点直到遍历到整棵树的根节点。弹出是靠glstate这个参数来操作实现的注意一下。遍历到根节点并弹出状态后就直接返回了。&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;34&quot;&gt;
&lt;pre&gt;
&lt;span&gt; 1&lt;/span&gt; &lt;span&gt;if&lt;/span&gt; (curStateBin ===&lt;span&gt; undefined) {
&lt;/span&gt;&lt;span&gt; 2&lt;/span&gt;         &lt;span&gt;//&lt;/span&gt;&lt;span&gt;curStateBin已经到顶，弹出preStateBin的所有状态&lt;/span&gt;
&lt;span&gt; 3&lt;/span&gt;         &lt;span&gt;do&lt;/span&gt;&lt;span&gt; {
&lt;/span&gt;&lt;span&gt; 4&lt;/span&gt;             &lt;span&gt;if&lt;/span&gt; (preStateBin._stateset !==&lt;span&gt; undefined) {
&lt;/span&gt;&lt;span&gt; 5&lt;/span&gt; &lt;span&gt;                glstate.popStateSet();
&lt;/span&gt;&lt;span&gt; 6&lt;/span&gt; &lt;span&gt;            }
&lt;/span&gt;&lt;span&gt; 7&lt;/span&gt;             preStateBin =&lt;span&gt; preStateBin._parent;
&lt;/span&gt;&lt;span&gt; 8&lt;/span&gt;         } &lt;span&gt;while&lt;/span&gt;&lt;span&gt; (preStateBin);
&lt;/span&gt;&lt;span&gt; 9&lt;/span&gt;         &lt;span&gt;return&lt;/span&gt;&lt;span&gt;;
&lt;/span&gt;&lt;span&gt;10&lt;/span&gt;     }
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;我们再看看接下来还做了什么操作，这个看注释就能理解他的操作。&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;35&quot;&gt;
&lt;pre&gt;
&lt;span&gt; 1&lt;/span&gt; &lt;span&gt;if&lt;/span&gt; (preStateBin ===&lt;span&gt; undefined) {
&lt;/span&gt;&lt;span&gt; 2&lt;/span&gt;         &lt;span&gt;//&lt;/span&gt;&lt;span&gt;preStateBin已经到顶，压入curStateBin的所有状态&lt;/span&gt;
&lt;span&gt; 3&lt;/span&gt;         &lt;span&gt;//&lt;/span&gt;&lt;span&gt;从子节点往根节点遍历获取所有的状态，但是推给glstate必须从根节点往子节点遍历&lt;/span&gt;
&lt;span&gt; 4&lt;/span&gt;         &lt;span&gt;//&lt;/span&gt;&lt;span&gt;所以这里先塞到一个stack里面，然后再遍历stack推给glstate&lt;/span&gt;
&lt;span&gt; 5&lt;/span&gt;         let stack =&lt;span&gt; [];
&lt;/span&gt;&lt;span&gt; 6&lt;/span&gt;         &lt;span&gt;do&lt;/span&gt;&lt;span&gt; {
&lt;/span&gt;&lt;span&gt; 7&lt;/span&gt;             &lt;span&gt;if&lt;/span&gt; (curStateBin._stateset !==&lt;span&gt; undefined) {
&lt;/span&gt;&lt;span&gt; 8&lt;/span&gt; &lt;span&gt;                stack.push(curStateBin._stateset);
&lt;/span&gt;&lt;span&gt; 9&lt;/span&gt; &lt;span&gt;            }
&lt;/span&gt;&lt;span&gt;10&lt;/span&gt;             curStateBin =&lt;span&gt; curStateBin._parent;
&lt;/span&gt;&lt;span&gt;11&lt;/span&gt;         } &lt;span&gt;while&lt;/span&gt;&lt;span&gt; (curStateBin);
&lt;/span&gt;&lt;span&gt;12&lt;/span&gt; 
&lt;span&gt;13&lt;/span&gt;         let size = stack.length - 1&lt;span&gt;;
&lt;/span&gt;&lt;span&gt;14&lt;/span&gt;         &lt;span&gt;for&lt;/span&gt; (let i = size; i &amp;gt;= 0; --&lt;span&gt;i) {
&lt;/span&gt;&lt;span&gt;15&lt;/span&gt; &lt;span&gt;            glstate.pushStateSet(stack[i]);
&lt;/span&gt;&lt;span&gt;16&lt;/span&gt; &lt;span&gt;        }
&lt;/span&gt;&lt;span&gt;17&lt;/span&gt;         &lt;span&gt;return&lt;/span&gt;&lt;span&gt;;
&lt;/span&gt;&lt;span&gt;18&lt;/span&gt;     } &lt;span&gt;else&lt;/span&gt; &lt;span&gt;if&lt;/span&gt; (preStateBin._parent ===&lt;span&gt; curStateBin._parent) {
&lt;/span&gt;&lt;span&gt;19&lt;/span&gt;         &lt;span&gt;//&lt;/span&gt;&lt;span&gt; first handle the typical case which is two glstate groups&lt;/span&gt;
&lt;span&gt;20&lt;/span&gt;         &lt;span&gt;//&lt;/span&gt;&lt;span&gt; are neighbours.&lt;/span&gt;
&lt;span&gt;21&lt;/span&gt; 
&lt;span&gt;22&lt;/span&gt;         &lt;span&gt;//&lt;/span&gt;&lt;span&gt; glstate has changed so need to pop old glstate.&lt;/span&gt;
&lt;span&gt;23&lt;/span&gt;         &lt;span&gt;if&lt;/span&gt; (preStateBin._stateset !==&lt;span&gt; undefined) {
&lt;/span&gt;&lt;span&gt;24&lt;/span&gt; &lt;span&gt;            glstate.popStateSet();
&lt;/span&gt;&lt;span&gt;25&lt;/span&gt; &lt;span&gt;        }
&lt;/span&gt;&lt;span&gt;26&lt;/span&gt;         &lt;span&gt;//&lt;/span&gt;&lt;span&gt; and push new glstate.&lt;/span&gt;
&lt;span&gt;27&lt;/span&gt;         &lt;span&gt;if&lt;/span&gt; (curStateBin._stateset !==&lt;span&gt; undefined) {
&lt;/span&gt;&lt;span&gt;28&lt;/span&gt; &lt;span&gt;            glstate.pushStateSet(curStateBin._stateset);
&lt;/span&gt;&lt;span&gt;29&lt;/span&gt; &lt;span&gt;        }
&lt;/span&gt;&lt;span&gt;30&lt;/span&gt;         &lt;span&gt;return&lt;/span&gt;&lt;span&gt;;
&lt;/span&gt;&lt;span&gt;31&lt;/span&gt;     }
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;随后我们看看最后的操作。这波操作就是为了比较currStateBin和preStateBin这两个树节点的深度和对其向树根部的操作。&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;36&quot;&gt;
&lt;pre&gt;
&lt;span&gt; 1&lt;/span&gt; &lt;span&gt;//&lt;/span&gt;&lt;span&gt;先弹出状态，保证preStateBin和curStateBin达到树节点平级&lt;/span&gt;
&lt;span&gt; 2&lt;/span&gt;     &lt;span&gt;//&lt;/span&gt;&lt;span&gt;无法确定两个树节点谁的深度值更多，两个都做一次循环&lt;/span&gt;
&lt;span&gt; 3&lt;/span&gt;     &lt;span&gt;while&lt;/span&gt; (preStateBin._depth &amp;gt;&lt;span&gt; curStateBin._depth) {
&lt;/span&gt;&lt;span&gt; 4&lt;/span&gt;         &lt;span&gt;if&lt;/span&gt; (preStateBin._stateset !==&lt;span&gt; undefined) {
&lt;/span&gt;&lt;span&gt; 5&lt;/span&gt; &lt;span&gt;            glstate.popStateSet();
&lt;/span&gt;&lt;span&gt; 6&lt;/span&gt; &lt;span&gt;        }
&lt;/span&gt;&lt;span&gt; 7&lt;/span&gt;         preStateBin =&lt;span&gt; preStateBin._parent;
&lt;/span&gt;&lt;span&gt; 8&lt;/span&gt; &lt;span&gt;    }
&lt;/span&gt;&lt;span&gt; 9&lt;/span&gt; 
&lt;span&gt;10&lt;/span&gt;     &lt;span&gt;//&lt;/span&gt;&lt;span&gt; use return path to trace back steps to curStateBin.&lt;/span&gt;
&lt;span&gt;11&lt;/span&gt;     let stack =&lt;span&gt; [];
&lt;/span&gt;&lt;span&gt;12&lt;/span&gt;     &lt;span&gt;//&lt;/span&gt;&lt;span&gt; need to pop back up to the same depth as the curr glstate group.&lt;/span&gt;
&lt;span&gt;13&lt;/span&gt;     &lt;span&gt;while&lt;/span&gt; (curStateBin._depth &amp;gt;&lt;span&gt; preStateBin._depth) {
&lt;/span&gt;&lt;span&gt;14&lt;/span&gt;         &lt;span&gt;if&lt;/span&gt; (curStateBin._stateset !==&lt;span&gt; undefined) {
&lt;/span&gt;&lt;span&gt;15&lt;/span&gt; &lt;span&gt;            stack.push(curStateBin._stateset);
&lt;/span&gt;&lt;span&gt;16&lt;/span&gt; &lt;span&gt;        }
&lt;/span&gt;&lt;span&gt;17&lt;/span&gt;         curStateBin =&lt;span&gt; curStateBin._parent;
&lt;/span&gt;&lt;span&gt;18&lt;/span&gt; &lt;span&gt;    }
&lt;/span&gt;&lt;span&gt;19&lt;/span&gt; 
&lt;span&gt;20&lt;/span&gt;     &lt;span&gt;//&lt;/span&gt;&lt;span&gt; now pop back up both parent paths until they agree.&lt;/span&gt;
&lt;span&gt;21&lt;/span&gt;     &lt;span&gt;//&lt;/span&gt;&lt;span&gt; should be this to conform with above case where two StateBin&lt;/span&gt;
&lt;span&gt;22&lt;/span&gt;     &lt;span&gt;//&lt;/span&gt;&lt;span&gt; nodes have the same parent&lt;/span&gt;
&lt;span&gt;23&lt;/span&gt;     &lt;span&gt;//&lt;/span&gt;&lt;span&gt;继续遍历直到两个树节点相同&lt;/span&gt;
&lt;span&gt;24&lt;/span&gt;     &lt;span&gt;while&lt;/span&gt; (preStateBin !==&lt;span&gt; curStateBin) {
&lt;/span&gt;&lt;span&gt;25&lt;/span&gt;         &lt;span&gt;if&lt;/span&gt; (preStateBin._stateset !== undefined) {&lt;span&gt;//&lt;/span&gt;&lt;span&gt;pre的从GLState中出栈&lt;/span&gt;
&lt;span&gt;26&lt;/span&gt; &lt;span&gt;            glstate.popStateSet();
&lt;/span&gt;&lt;span&gt;27&lt;/span&gt; &lt;span&gt;        }
&lt;/span&gt;&lt;span&gt;28&lt;/span&gt;         preStateBin =&lt;span&gt; preStateBin._parent;
&lt;/span&gt;&lt;span&gt;29&lt;/span&gt; 
&lt;span&gt;30&lt;/span&gt;         &lt;span&gt;if&lt;/span&gt; (curStateBin._stateset !== undefined) {&lt;span&gt;//&lt;/span&gt;&lt;span&gt;当前的入栈，临时保存&lt;/span&gt;
&lt;span&gt;31&lt;/span&gt; &lt;span&gt;            stack.push(curStateBin._stateset);
&lt;/span&gt;&lt;span&gt;32&lt;/span&gt; &lt;span&gt;        }
&lt;/span&gt;&lt;span&gt;33&lt;/span&gt;         curStateBin =&lt;span&gt; curStateBin._parent;
&lt;/span&gt;&lt;span&gt;34&lt;/span&gt; &lt;span&gt;    }
&lt;/span&gt;&lt;span&gt;35&lt;/span&gt; 
&lt;span&gt;36&lt;/span&gt;     &lt;span&gt;//&lt;/span&gt;&lt;span&gt;遍历结束后，从临时栈中推入GLState里&lt;/span&gt;
&lt;span&gt;37&lt;/span&gt;     &lt;span&gt;for&lt;/span&gt; (let i = stack.length - 1, l = 0; i &amp;gt;= l; --&lt;span&gt;i) {
&lt;/span&gt;&lt;span&gt;38&lt;/span&gt; &lt;span&gt;        glstate.pushStateSet(stack[i]);
&lt;/span&gt;&lt;span&gt;39&lt;/span&gt;     }
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　StateBin渲染状态树是对osg的StateSet单个模型渲染状态的管理数据结构，几乎在整个DrawActor的过程中都要大量应用，他的重要性不言而喻，鲫鱼也是一知半解的在学习这个数据结构，希望大家多提出宝贵的见解，多多斧正，谢谢同学们的支持关注。今天就到这里，下周再见。本文系原创，引用请注明出处：&lt;a id=&quot;Editor_Edit_hlEntryLink&quot; title=&quot;view: WebGL------osg框架学习二&quot; href=&quot;https://www.cnblogs.com/ccentry/p/10224312.html&quot; target=&quot;_blank&quot;&gt;https://www.cnblogs.com/ccentry/p/10224312.html&lt;/a&gt;                       &lt;/p&gt;
</description>
<pubDate>Sat, 05 Jan 2019 06:04:00 +0000</pubDate>
<dc:creator>ccentry</dc:creator>
<og:description>今天我们继续来学习osg.js框架。上一篇我们介绍了DrawActor对象绘制操作类和Drawable可绘制对象类，我们大致知道了osg对Drawable可绘制对象的绘制流程管理。今天我们要继续介绍S</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/ccentry/p/10224312.html</dc:identifier>
</item>
<item>
<title>asp.net core 系列 2  启动Startup类介绍 - 花阴偷移</title>
<link>http://www.cnblogs.com/MrHSR/p/10223694.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/MrHSR/p/10223694.html</guid>
<description>&lt;h3&gt;一.Startup类&lt;/h3&gt;
&lt;p&gt;　　ASP.NET Core 应用是一个控制台应用，它在其 &lt;code&gt;Program.Main&lt;/code&gt; 方法中创建 Web 服务器。其中Main方法是应用的托管入口点，Main 方法调用 WebHost.CreateDefaultBuilder来创建 Web 主机，自动分配了 Kestrel Web 服务器。IWebHostBuilder 的 Build 方法生成 IWebHost对象调用Run 方法启动WebHost，此时托管应用并开始侦听 HTTP 请求。代码如下所示：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;34&quot;&gt;
&lt;pre&gt;
&lt;span&gt;public&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;&lt;span&gt; Program
    {
        &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; Main(&lt;span&gt;string&lt;/span&gt;&lt;span&gt;[] args)
        {
            CreateWebHostBuilder(args).Build().Run();
        }

        &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; IWebHostBuilder CreateWebHostBuilder(&lt;span&gt;string&lt;/span&gt;[] args) =&amp;gt;&lt;span&gt;
            WebHost.CreateDefaultBuilder(args)
                .UseStartup&lt;/span&gt;&amp;lt;Startup&amp;gt;&lt;span&gt;();
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;　&lt;strong&gt;　1.1 应用启动 Startup类&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;　　　　IWebHostBuilder类的UseStartup调用启动类，按照约定命名为 Startup，该类必须是公共类，用于定义请求&lt;strong&gt;处理管道&lt;/strong&gt;和&lt;strong&gt;配置应用&lt;/strong&gt;所需的任何服务。当应用启动时会调用 &lt;code&gt;ConfigureServices&lt;/code&gt; 和 &lt;code&gt;Configur&lt;/code&gt;e两个方法。&lt;code&gt;ConfigureServices&lt;/code&gt; 用于注入服务, Configure用于响应HTTP请求。&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;34&quot;&gt;
&lt;pre&gt;
&lt;span&gt;public&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;&lt;span&gt; Startup
{
    &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; Use this method to add services to the container.&lt;/span&gt;
    &lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt;&lt;span&gt; ConfigureServices(IServiceCollection services)
    {
        ...
    }

    &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; Use this method to configure the HTTP request pipeline.&lt;/span&gt;
    &lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt;&lt;span&gt; Configure(IApplicationBuilder app)
    {
        ...
    }
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;　　&lt;strong&gt;1.2  ConfigureServices方法&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;　　　　ConfigureServices 方法负责注入服务。该方法在WebHost的Configure方法之前被调用，将服务添加到服务容器使得它们可以通过依赖注入在应用程序中使用，在webHost启动之前会加载该方法中的服务。典型模式是调用Add{service}方法注入服务，然后调用所有 services.Configure{Service} 方法。注入服务后，使其在应用和 Configure 方法中使用服务。在参数IServiceCollection （服务容器）上有 Add[Service] 扩展方法,用于添加自带的framework框架服务（例如添加EF,identity,mvc服务）也可以在IServiceCollection上注入自定义服务。&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;33&quot;&gt;
&lt;pre&gt;
  &lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt;&lt;span&gt; ConfigureServices(IServiceCollection services)
        {
            &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;注入 Razor Pages 和 MVC 需要的服务&lt;/span&gt;
&lt;span&gt;            services.AddMvc();
        }&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;　&lt;strong&gt;　1.3 Configure方法&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;　　　　Configure方法用于指定应用响应 HTTP 请求的方式。可将中间件注册到IApplicationBuilder 实例来配置请求管道。下面示例注册的中间件包括: ExceptionHandler异常/错误处理、HttpsRedirection重定向、StaticFiles静态文件服务器、CookiePolicy策略实施、mvc等中间件。每一个use开头的扩展方法将一个中间件添加到IApplicationBuilder请求管道中。&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;35&quot;&gt;
&lt;pre&gt;
&lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt;&lt;span&gt; Configure(IApplicationBuilder app, IHostingEnvironment env)
        {
            &lt;/span&gt;&lt;span&gt;if&lt;/span&gt;&lt;span&gt; (env.IsDevelopment())
            {
                app.UseDeveloperExceptionPage();
            }
            &lt;/span&gt;&lt;span&gt;else&lt;/span&gt;&lt;span&gt;
            {
                app.UseExceptionHandler(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;/Error&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;);
                app.UseHsts();
            }

            app.UseHttpsRedirection();
            app.UseStaticFiles();
            app.UseCookiePolicy();

            app.UseMvc();
        }&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;　　总结：　(1) Program的main方法用于创建WebHost服务,调用启动类Startup。&lt;/p&gt;
&lt;p&gt;　　　　　　(2) Startup中的ConfigureServices方法用于将服务注入到 IServiceCollection 服务容器中。&lt;/p&gt;
&lt;p&gt;　　　　　　(3) Startup中的Configure方法用于应用响应 HTTP 请求，将中间件注册到 ApplicationBuilder中来配置请求管道。&lt;/p&gt;
&lt;p&gt; 参考文献：&lt;/p&gt;
&lt;p&gt;　　　　&lt;a href=&quot;https://docs.microsoft.com/zh-cn/aspnet/core/fundamentals/startup?view=aspnetcore-2.1&quot; target=&quot;_blank&quot;&gt;https://docs.microsoft.com/zh-cn/aspnet/core/fundamentals/startup?view=aspnetcore-2.1&lt;/a&gt;&lt;/p&gt;
</description>
<pubDate>Sat, 05 Jan 2019 05:57:00 +0000</pubDate>
<dc:creator>花阴偷移</dc:creator>
<og:description>一.Startup类 ASP.NET Core 应用是一个控制台应用，它在其 Program.Main 方法中创建 Web 服务器。其中Main方法是应用的托管入口点，Main 方</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/MrHSR/p/10223694.html</dc:identifier>
</item>
<item>
<title>一次慢查询暴露的隐蔽的问题 - good_andyxu</title>
<link>http://www.cnblogs.com/goodAndyxublog/p/10224203.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/goodAndyxublog/p/10224203.html</guid>
<description>&lt;p&gt;最近解决了一个生产 SQL 慢查询的问题，排查问题之后发现一些比较隐匿且容易忽略的问题。&lt;/p&gt;
&lt;h2 id=&quot;业务背景介绍&quot;&gt;业务背景介绍&lt;/h2&gt;
&lt;p&gt;最近业务上需要上线一个预警功能，需要查出一段时间内交易，求出当前交易成功率。当成功率低于设定阈值时，短信预警。业务逻辑很简单，测试环境测试也没问题之后，部署上线。实际生产运行时却发现每次 SQL 查询需要花费 60 多秒。&lt;/p&gt;
&lt;h2 id=&quot;系统架构介绍&quot;&gt;系统架构介绍&lt;/h2&gt;
&lt;p&gt;Spring boot + Mybatis + Oracle。&lt;/p&gt;
&lt;p&gt;需要查询的表数量级为亿级。&lt;/p&gt;
&lt;h2 id=&quot;排查问题&quot;&gt;排查问题&lt;/h2&gt;
&lt;p&gt;交易表结构(已经简化)大致如下。&lt;/p&gt;
&lt;pre class=&quot;sql&quot;&gt;
&lt;code&gt;create table TB_TEST
(
  BANK_CODE   VARCHAR2(20),
  CREATE_TIME DATE,
  OID_BILL    NUMBER(16) not null
)
/
create index TB_TEST_CREATE_TIME_INDEX
  on TB_TEST (CREATE_TIME)
/

create unique index TB_TEST_OID_BILL_UINDEX
  on TB_TEST (OID_BILL)
/

alter table TB_TEST
  add constraint TB_TEST_PK
    primary key (OID_BILL)
/
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;该项目的增删改查语句使用 MybatisGenerate 自动生成，查询语句使用 CREATE_TIME 做为条件查询，自动生成 sql 如下。&lt;/p&gt;
&lt;pre class=&quot;sql&quot;&gt;
&lt;code&gt;
select *
from TB_TEST
where CREATE_TIME &amp;gt;= #{start_time}
  and CREATE_TIME &amp;lt; #{end_time};
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;我们通过设置 Druid 的配置，将具体查询 SQL 日志输出到控制台。具体设置如下。&lt;/p&gt;
&lt;pre class=&quot;xml&quot;&gt;
&lt;code&gt;  &amp;lt;bean id=&quot;dataSource&quot; class=&quot;com.alibaba.druid.pool.DruidDataSource&quot; init-method=&quot;init&quot; destroy-method=&quot;close&quot;&amp;gt;
    ... ...
    &amp;lt;property name=&quot;filters&quot; value=&quot;stat,slf4j&quot; /&amp;gt;
  &amp;lt;/bean&amp;gt;

  &amp;lt;!-- logback  --&amp;gt;
    &amp;lt;logger name=&quot;druid.sql.Statement&quot; level=&quot;DEBUG&quot; additivity=&quot;false&quot;&amp;gt;
        &amp;lt;appender-ref ref=&quot;STDOUT&quot;/&amp;gt;
    &amp;lt;/logger&amp;gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;具体 sql 日志如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://user-gold-cdn.xitu.io/2019/1/3/1681383aa6bfe27a?w=2048&amp;amp;h=580&amp;amp;f=png&amp;amp;s=150508&quot; alt=&quot;sql 调试日志&quot;/&gt;&lt;/p&gt;
&lt;p&gt;从日志中我们可以清楚看到实际运行的 SQL，以及查询参数与类型。&lt;/p&gt;
&lt;p&gt;从查询语句看来，我们查询条件正确，且由于 CREATE_TIME 存在独立索引，所以查询会走索引，查询速度应该很快，不至于每次查询需要花费 60 多秒。&lt;/p&gt;
&lt;p&gt;所以当时猜测这次查询由于某些原因发生了全表扫描，未走索引才导致慢查询。在 Google 搜索相关资料，看见一篇文章 &lt;a href=&quot;https://www.cnblogs.com/chen--biao/p/9770554.html&quot; class=&quot;uri&quot;&gt;https://www.cnblogs.com/chen--biao/p/9770554.html&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;根据文章描述的是 Oracle 中存在隐式转换的情况，当类型不匹配的时，Oracle 会主动将类型转换成目标类型。查看我们表结构，CREATE_TIME 为 Date 类型，而根据日志我们查询参数传递的 CREATE_TIME 却为 TIMESTAMP 类型。&lt;/p&gt;
&lt;p&gt;所以实际在数据库查询 SQL 如下：&lt;/p&gt;
&lt;pre class=&quot;sql&quot;&gt;
&lt;code&gt;
SELECT *
FROM TB_TEST
WHERE (CREATE_TIME &amp;gt;= to_timestamp('2018-03-03 18:45:32', 'yyyy-mm-dd hh24:mi:ss') and
       CREATE_TIME &amp;lt; to_timestamp('2019-01-03 18:45:32', 'yyyy-mm-dd hh24:mi:ss'));
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;可能这里发生一次隐式转换。&lt;/p&gt;
&lt;p&gt;如何证明这个猜想那？我们可以使用 EXPLAIN PLAN ，分析 SQL 执行计划.上面 SQL 执行计划如下。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://user-gold-cdn.xitu.io/2018/12/29/167f9961901c4bd3?w=1017&amp;amp;h=459&amp;amp;f=png&amp;amp;s=73156&quot; alt=&quot;慢 sql 执行计划&quot;/&gt;&lt;/p&gt;
&lt;p&gt;从上图我们可以从 &lt;code&gt;TB ACCESS FULL&lt;/code&gt; 看出，这次查询慢确实由于是全表扫描导致。&lt;/p&gt;
&lt;p&gt;然后我们查看执行计划中的 Predicate Information 信息，Oracle 使用 INTERNAL_FUNCATIPON 转换 CREATE_TIME 类型 。从这点那可以看出查询过程索引字段发生一次内联函数转换。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;SQL 性能优化往往会有一点，避免在索引字段使用函数。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;既然知道原因，那么解决办法也没有这么难了。我们将查询 sql 改为如下就能解决。&lt;/p&gt;
&lt;pre class=&quot;sql&quot;&gt;
&lt;code&gt;
select *
from TB_TEST
where CREATE_TIME &amp;gt;= TO_DATE(#{start_time}, 'yyyy-mm-dd hh24:mi:ss')
  and CREATE_TIME &amp;lt; TO_DATE(#{end_time}, 'yyyy-mm-dd hh24:mi:ss');

-- 或者使用 cast 函数
select *
from TB_TEST
where CREATE_TIME &amp;gt;= cast(#{start_time} as date)
  and CREATE_TIME &amp;lt; cast(#{end_time} as date);&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;分析原因&quot;&gt;分析原因&lt;/h2&gt;
&lt;p&gt;解决完问题，我们分析下 Java 类型中的　Date 类型为什么最终会转换成 Oracle 中的 TIMESTAMP 类型。&lt;/p&gt;
&lt;p&gt;这次案例中我们使用 Mybatis 框架，框架内部会将 Java 数据类型转换成对应的 JDBC 数据类型。查看&lt;a href=&quot;http://www.mybatis.org/mybatis-3/configuration.html#typeHandlers&quot;&gt;Mybatis 类型转换&lt;/a&gt; 这一节我们可以发现 Java Date 类型将会转换成 java.sql.TIMESTAMP。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://user-gold-cdn.xitu.io/2019/1/4/16818c3757bb2dcb?w=859&amp;amp;h=368&amp;amp;f=png&amp;amp;s=38856&quot; alt=&quot;DateTypeHandler&quot;/&gt;&lt;/p&gt;
&lt;p&gt;然后我们查看 Oracle JDBC 数据类型转换规则。在 &lt;a href=&quot;https://docs.oracle.com/cd/B19306_01/java.102/b14355/datacc.htm#BHCJBJCC&quot; class=&quot;uri&quot;&gt;https://docs.oracle.com/cd/B19306_01/java.102/b14355/datacc.htm#BHCJBJCC&lt;/a&gt; 我们可以看到，TIMESTAMP 将转换成 Oracle 中 TIMESTAMP。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://user-gold-cdn.xitu.io/2019/1/4/16818c5e182f54b7?w=962&amp;amp;h=191&amp;amp;f=pn&quot; alt=&quot;Oracle type&quot;/&gt;&lt;/p&gt;
&lt;h2 id=&quot;问题扩展&quot;&gt;问题扩展&lt;/h2&gt;
&lt;p&gt;假设我们将 CREATE_TIME 类型修改成 TIMESTAMP，然后查询的时候将 CREATE_TIME 转换成 Date 类型，是否也会发生内联函数转换，然后导致全表扫描那？查询 sql 如下。&lt;/p&gt;
&lt;pre class=&quot;sql&quot;&gt;
&lt;code&gt;--  CREATE_TIME 类型为 TIMESTAMP
select *
from TB_TEST
where CREATE_TIME &amp;gt;= TO_DATE('2018-02-27 19:36:21', 'yyyy-mm-dd hh24:mi:ss')
  and CREATE_TIME &amp;lt; TO_DATE('2018-12-27 19:36:21', 'yyyy-mm-dd hh24:mi:ss')
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;。。。。&lt;/p&gt;
&lt;p&gt;。。。。&lt;/p&gt;
&lt;p&gt;。。。。&lt;/p&gt;
&lt;p&gt;我们用 EXPLAIN PLAN 分析这个 SQL。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://user-gold-cdn.xitu.io/2018/12/29/167f996f87691634?w=1117&amp;amp;h=441&amp;amp;f=png&amp;amp;s=66936&quot; alt=&quot;内联转换&quot;/&gt;&lt;/p&gt;
&lt;p&gt;我们可以看到，确实发生了一次内联转化，但是却在另外一边。这次查询走的是索引。&lt;/p&gt;
&lt;p&gt;从这个例子我们可以看出，在索引字段上使用函数会导致全表扫描。但是在传入查询参数上使用函数并不会导致索引失效。&lt;/p&gt;
&lt;h2 id=&quot;总结&quot;&gt;总结&lt;/h2&gt;
&lt;p&gt;1 SQL 查询时需要注意两边数据类型的一致性，虽然数据库隐式转换会帮我们解决数据不一致的问题，但是这种隐式转化带来一些隐蔽问题，让我们第一时间并不能很快发现。所以使用显示转换代替隐式转换。这样我们的 SQL 清晰易懂，而且更加可控。&lt;/p&gt;
&lt;p&gt;2 学会使用 EXPLAIN PLAN 分析慢 SQL。&lt;/p&gt;
&lt;p&gt;3 索引字段上使用相关函数会导致慢查询，查询时切勿在索引字段上使用函数。&lt;/p&gt;
&lt;h2 id=&quot;参考文档&quot;&gt;参考文档&lt;/h2&gt;
&lt;p&gt;1、 &lt;a href=&quot;https://docs.oracle.com/cd/B19306_01/server.102/b14200/sql_elements002.htm#g195937&quot; class=&quot;uri&quot;&gt;https://docs.oracle.com/cd/B19306_01/server.102/b14200/sql_elements002.htm#g195937&lt;/a&gt;&lt;br/&gt;2、 &lt;a href=&quot;https://dev.mysql.com/doc/refman/8.0/en/date-and-time-types.html&quot; class=&quot;uri&quot;&gt;https://dev.mysql.com/doc/refman/8.0/en/date-and-time-types.html&lt;/a&gt;&lt;/p&gt;
&lt;hr/&gt;&lt;p&gt;&lt;strong&gt;如果觉得好的话，请帮作者点个赞呗~ 谢谢&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;喜欢本文的读者们，欢迎长按关注订阅号程序通事~让我与你分享程序那些事。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://user-gold-cdn.xitu.io/2018/12/15/167adc840d26df02?w=258&amp;amp;h=258&amp;amp;f=jpeg&amp;amp;s=28067&quot;/&gt;&lt;/p&gt;
</description>
<pubDate>Sat, 05 Jan 2019 05:32:00 +0000</pubDate>
<dc:creator>good_andyxu</dc:creator>
<og:description>最近解决了一个生产 SQL 慢查询的问题，排查问题之后发现一些比较隐匿且容易忽略的问题。 业务背景介绍 最近业务上需要上线一个预警功能，需要查出一段时间内交易，求出当前交易成功率。当成功率低于设定阈值</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/goodAndyxublog/p/10224203.html</dc:identifier>
</item>
<item>
<title>Windows版本redis高可用方案探究 - 杰哥很忙</title>
<link>http://www.cnblogs.com/Jack-Blog/p/10224193.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/Jack-Blog/p/10224193.html</guid>
<description>&lt;p class=&quot;toc&quot;&gt;目录&lt;/p&gt;
&lt;hr/&gt;&lt;h2 id=&quot;前言&quot;&gt;前言&lt;/h2&gt;
&lt;p&gt;本篇文章专注于讲解redis在windows环境下使用Redis Sentinel(哨兵)实现高可用方案。&lt;/p&gt;
&lt;p&gt;想要在windows环境下实现redis高可用，先要准备以下材料或知识点。&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;redis 3.2.100&lt;br/&gt;目前在windows版本最新的redis是3.2.100，可以到&lt;a href=&quot;https://github.com/MicrosoftArchive/redis/tags&quot;&gt;这里&lt;/a&gt;下载&lt;/li&gt;
&lt;li&gt;Redis Sentinel&lt;br/&gt;redis本身不支持高可用方案，通过sentinel对redis进行监控及动态调节等。&lt;/li&gt;
&lt;/ol&gt;&lt;h2 id=&quot;搭建redis主从&quot;&gt;搭建redis主从&lt;/h2&gt;
&lt;p&gt;下载的压缩文件内容如下图所示。&lt;br/&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/580757/201901/580757-20190105093939573-1127915260.png&quot; alt=&quot;1.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;具体结构如下图所示&lt;br/&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/580757/201901/580757-20190105095630588-1910152801.png&quot; alt=&quot;2.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;应用层连接redis集群，集群包括3个redis服务(1主2从)和3个哨兵。&lt;/p&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;哨兵用于监控主redis可用性。若长时间不可用，则哨兵进行投票选举出新的主redis。原来的主redis降级为从redis。哨兵会将所有redis的配置进行自动更新。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&quot;配置主redis-28380&quot;&gt;配置主redis-28380&lt;/h3&gt;
&lt;p&gt;将redis复制一份。一个文件夹用于部署redis服务，一个文件夹用于部署哨兵。&lt;br/&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/580757/201901/580757-20190105094347764-1883677257.png&quot; alt=&quot;3.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;规定redis服务端口为28380~28382。将redis.windiws-service.config改名为redis-28380.conf。打开进行修改。&lt;/p&gt;
&lt;ol readability=&quot;2.5&quot;&gt;&lt;li&gt;修改绑定端口&lt;br/&gt;注释掉&lt;code&gt;bind 127.0.0.1&lt;/code&gt;,默认为监听所有ip。&lt;/li&gt;
&lt;li&gt;将保护模式关闭&lt;br/&gt;修改&lt;code&gt;protected-mode yes&lt;/code&gt;为&lt;code&gt;protected-mode no&lt;/code&gt;，默认redis开启了保护模式，只允许本机通过127.0.0.1访问，其他ip无法访问。&lt;/li&gt;
&lt;li&gt;修改监听端口&lt;br/&gt;修改&lt;code&gt;port 6379&lt;/code&gt;为&lt;code&gt;port 28380&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;修改日志等级&lt;br/&gt;修改&lt;code&gt;loglevel debug&lt;/code&gt;为&lt;code&gt;loglevel notice&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;修改日志文件名&lt;br/&gt;修改&lt;code&gt;logfile &quot;server_log.txt&quot;&lt;/code&gt;为&lt;code&gt;logfile &quot;server_log_28380.txt&quot;&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;修改windows日志的事件名&lt;br/&gt;修改&lt;code&gt;syslog-ident redis&lt;/code&gt;为&lt;code&gt;syslog-ident &quot;redis-28380&quot;&lt;/code&gt;&lt;/li&gt;
&lt;li readability=&quot;3&quot;&gt;
&lt;p&gt;修改不保存rdb文件&lt;br/&gt;注释掉一下三行，由于rdb会每次全量写文件，当数据量较大时会对redis稳定性造成一定影响，尤其是rbd保存失败时会一定时间内拒绝写入数据。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt; save 900 1
 save 300 10
 save 60 10000&lt;/code&gt;
&lt;/pre&gt;&lt;/li&gt;
&lt;li readability=&quot;1.5&quot;&gt;
&lt;p&gt;创建密码&lt;br/&gt;修改&lt;code&gt;# requirepass foobared&lt;/code&gt;为&lt;code&gt;requirepass &quot;test1&quot;&lt;/code&gt;&lt;br/&gt;新增&lt;code&gt;masterauth &quot;test1&quot;&lt;/code&gt;&lt;/p&gt;
&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;若要设置密码，单台redis设置&lt;code&gt;requirepass&lt;/code&gt;即可。集群redis必须同时设置&lt;code&gt;requirepass&lt;/code&gt;和&lt;code&gt;masterauth&lt;/code&gt;。若主redis没有设置&lt;code&gt;masterauth&lt;/code&gt;当它变为从时，就认为主无密码。若从redis没有设置&lt;code&gt;requirepass&lt;/code&gt;，当它变为主时，会没有密码。以上两种情况自动切换都无法自动连接到新的主。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li readability=&quot;1.5&quot;&gt;
&lt;p&gt;启用aof保存&lt;br/&gt;修改&lt;code&gt;appendonly no&lt;/code&gt;为&lt;code&gt;appendonly yes&lt;/code&gt;&lt;br/&gt;修改&lt;code&gt;appendfilename &quot;appendonly.aof&quot;&lt;/code&gt;为&lt;code&gt;appendfilename &quot;appendonly_28380.aof&quot;&lt;/code&gt;&lt;/p&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;aof写入的是redis命令，每次向文件后面添加，因此对IO性能影响较小。最坏情况主redis丢失1s的数据。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;配置改好后保存，这个当作主redis的配置。将改配置复制2份，分别改名为redis-28381.conf和redis-28382.conf&lt;/p&gt;
&lt;h3 id=&quot;配置从redis-23381&quot;&gt;配置从redis-23381&lt;/h3&gt;
&lt;ol readability=&quot;0.5&quot;&gt;&lt;li&gt;修改监听端口&lt;br/&gt;修改&lt;code&gt;port 28380&lt;/code&gt;为&lt;code&gt;port 28381&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;修改日志文件名&lt;br/&gt;修改&lt;code&gt;logfile &quot;server_log-28380.txt&quot;&lt;/code&gt;为&lt;code&gt;logfile &quot;server_log_28381.txt&quot;&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;修改windows日志的事件名&lt;br/&gt;修改&lt;code&gt;syslog-ident &quot;redis-28380&quot;&lt;/code&gt;为&lt;code&gt;syslog-ident &quot;redis-28381&quot;&lt;/code&gt;&lt;br/&gt;&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;修改从库对应的主库ip&lt;br/&gt;修改&lt;code&gt;# slaveof &amp;lt;masterip&amp;gt; &amp;lt;masterport&amp;gt;&lt;/code&gt;为&lt;code&gt;slaveof 127.0.0.1 28380&lt;/code&gt;&lt;/p&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;23880做为主库，填写的就是28380的端口&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;修改从库竞选主库优先级&lt;br/&gt;修改&lt;code&gt;slave-priority 100&lt;/code&gt;为&lt;code&gt;slave-priority 99&lt;/code&gt;&lt;/p&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;将每个从库设置为不通的优先级，数字较低的优先被竞选为主库。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;修改aof保存的文件名&lt;br/&gt;修改&lt;code&gt;appendfilename &quot;appendonly_28380.aof&quot;&lt;/code&gt;为&lt;code&gt;appendfilename &quot;appendonly_28381.aof&quot;&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;&lt;h3 id=&quot;配置从redis-23382&quot;&gt;配置从redis-23382&lt;/h3&gt;
&lt;ol readability=&quot;0.5&quot;&gt;&lt;li&gt;修改监听端口&lt;br/&gt;修改&lt;code&gt;port 28380&lt;/code&gt;为&lt;code&gt;port 28382&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;修改日志文件名&lt;br/&gt;修改&lt;code&gt;logfile &quot;server_log-28380.txt&quot;&lt;/code&gt;为&lt;code&gt;logfile &quot;server_log_28382.txt&quot;&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;修改windows日志的事件名&lt;br/&gt;修改&lt;code&gt;syslog-ident &quot;redis-28380&quot;&lt;/code&gt;为&lt;code&gt;syslog-ident &quot;redis-28382&quot;&lt;/code&gt;&lt;br/&gt;&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;修改从库对应的主库ip&lt;br/&gt;修改&lt;code&gt;# slaveof &amp;lt;masterip&amp;gt; &amp;lt;masterport&amp;gt;&lt;/code&gt;为&lt;code&gt;slaveof 127.0.0.1 28380&lt;/code&gt;&lt;/p&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;23880做为主库，填写的就是28380的端口&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;修改从库竞选主库优先级&lt;br/&gt;修改&lt;code&gt;slave-priority 100&lt;/code&gt;为&lt;code&gt;slave-priority 98&lt;/code&gt;&lt;/p&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;将每个从库设置为不通的优先级，数字较低的优先被竞选为主库。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;修改aof保存的文件名&lt;br/&gt;修改&lt;code&gt;appendfilename &quot;appendonly_28380.aof&quot;&lt;/code&gt;为&lt;code&gt;appendfilename &quot;appendonly_28382.aof&quot;&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;&lt;h3 id=&quot;将redis部署为服务&quot;&gt;将redis部署为服务&lt;/h3&gt;
&lt;p&gt;通过命令&lt;code&gt;redis-server --service-install 配置名 --service-name 服务名&lt;/code&gt; 将redis安装为服务。&lt;br/&gt;先cd到redis所在目录，在cmd命令行中输入一下三条语句将三个redis安装成功为windows服务。&lt;/p&gt;
&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;redis-server --service-install redis-28380.conf --service-name redis-28380
redis-server --service-install redis-28381.conf --service-name redis-28381
redis-server --service-install redis-28382.conf --service-name redis-28382&lt;/code&gt;
&lt;/pre&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;设置服务别名是为了在服务中能更好的看到哪个是哪个服务，否则默认都是redis服务。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/580757/201901/580757-20190105111922318-585143415.png&quot; alt=&quot;4.png&quot;/&gt;&lt;/p&gt;
&lt;h3 id=&quot;启动redis&quot;&gt;启动redis&lt;/h3&gt;
&lt;p&gt;可以直接在服务中右键启动或者通过命令&lt;code&gt;redis-server --service-start --service-name 服务名&lt;/code&gt; 启动指定服务。&lt;/p&gt;
&lt;p&gt;通过redis-cli 连接到各个redis服务。&lt;/p&gt;
&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;F:\Study\redis&amp;gt; redis-cli -p 28380 -a test1
127.0.0.1:28380&amp;gt; info Replication
# Replication
role:master
connected_slaves:2
slave0:ip=127.0.0.1,port=28382,state=online,offset=183,lag=1
slave1:ip=127.0.0.1,port=28381,state=online,offset=183,lag=1
master_repl_offset:183
repl_backlog_active:1
repl_backlog_size:1048576
repl_backlog_first_byte_offset:2
repl_backlog_histlen:182&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;可以看到我们的主从配置已经生效了。&lt;/p&gt;
&lt;p&gt;连接到从库28381&lt;/p&gt;
&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;F:\Study\redis&amp;gt;  redis-cli -p 28381 -a test1
127.0.0.1:28381&amp;gt;  info Replication
# Replication
role:slave
master_host:127.0.0.1
master_port:28380
master_link_status:up
master_last_io_seconds_ago:9
master_sync_in_progress:0
slave_repl_offset:323
slave_priority:99
slave_read_only:1
connected_slaves:0
master_repl_offset:0
repl_backlog_active:0
repl_backlog_size:1048576
repl_backlog_first_byte_offset:0
repl_backlog_histlen:0&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;连接到从库28382&lt;/p&gt;
&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;F:\Study\redis&amp;gt;  redis-cli -p 28382 -a test1
127.0.0.1:28382&amp;gt; info Replication
# Replication
role:slave
master_host:127.0.0.1
master_port:28380
master_link_status:up
master_last_io_seconds_ago:8
master_sync_in_progress:0
slave_repl_offset:379
slave_priority:99
slave_read_only:1
connected_slaves:0
master_repl_offset:0
repl_backlog_active:0
repl_backlog_size:1048576
repl_backlog_first_byte_offset:0
repl_backlog_histlen:0&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;现在我们往主库写入数据会自动并主动同步到从库。&lt;/p&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;配置中默认配了以下配置了&lt;code&gt;slave-read-only yes&lt;/code&gt;,从库是只读的，不允许写入。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;配置哨兵&quot;&gt;配置哨兵&lt;/h2&gt;
&lt;p&gt;设置三个哨兵端口为 24381~24383&lt;/p&gt;
&lt;p&gt;配置哨兵24381&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;dir ./
logfile &quot;sentinel.28481.txt&quot;
port 28481
sentinel monitor master 127.0.0.1 28380 2
sentinel down-after-milliseconds master 5000
sentinel failover-timeout master 30000
sentinel auth-pass 127.0.0.1 28380 test1&lt;/code&gt;
&lt;/pre&gt;
&lt;ul readability=&quot;-0.5&quot;&gt;&lt;li&gt;&lt;code&gt;sentinel monitor master 127.0.0.1 28380 2&lt;/code&gt; 设置主redis的别名为master，后面都通过master表示主redis。后面的2表示2个哨兵检测到主redis挂了即为挂了，需要重新选举出新的主redis，而原来的主redis降级为从redis。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;sentinel down-after-milliseconds master 5000&lt;/code&gt; 哨兵多久连不上主redis即认为它挂了&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;&lt;code&gt;sentinel failover-timeout master 30000&lt;/code&gt; 投票选举超时时间，超过时间没有选出则该轮投票失败。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;&lt;code&gt;sentinel auth-pass master test1&lt;/code&gt; 主redis的密码 。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;由于哨兵只能设置主的密码，因此主从的密码应该设置为一样的。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;配置哨兵24382&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;dir ./
logfile &quot;sentinel.28482.txt&quot;
port 28482
sentinel monitor master 127.0.0.1 28380 2
sentinel down-after-milliseconds master 5000
sentinel failover-timeout master 30000
sentinel auth-pass 127.0.0.1 28380 test1&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;配置哨兵24383&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;dir ./
logfile &quot;sentinel.28483.txt&quot;
port 28483
sentinel monitor master 127.0.0.1 28380 2
sentinel down-after-milliseconds master 5000
sentinel failover-timeout master 30000
sentinel auth-pass 127.0.0.1 28380 test1&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;启动哨兵&quot;&gt;启动哨兵&lt;/h3&gt;
&lt;p&gt;通过命令&lt;code&gt;redis-server.exe 配置 --sentinel&lt;/code&gt; 启动哨兵&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;redis-server redis-sentinel-28481.conf --sentinel
redis-server redis-sentinel-28482.conf --sentinel
redis-server redis-sentinel-28483.conf --sentinel&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;启动哨兵28481后查看日志&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;
[8464] 21 Nov 02:02:05.258 # +tilt #tilt mode entered
[8464] 21 Nov 08:33:01.513 # +tilt #tilt mode entered
[8464] 21 Nov 08:33:31.561 # -tilt #tilt mode exited
                _._                                                  
           _.-``__ ''-._                                             
      _.-``    `.  `_.  ''-._           Redis 3.2.100 (00000000/0) 64 bit
  .-`` .-```.  ```\/    _.,_ ''-._                                   
 (    '      ,       .-`  | `,    )     Running in sentinel mode
 |`-._`-...-` __...-.``-._|'` _.-'|     Port: 28481
 |    `-._   `._    /     _.-'    |     PID: 22332
  `-._    `-._  `-./  _.-'    _.-'                                   
 |`-._`-._    `-.__.-'    _.-'_.-'|                                  
 |    `-._`-._        _.-'_.-'    |           http://redis.io        
  `-._    `-._`-.__.-'_.-'    _.-'                                   
 |`-._`-._    `-.__.-'    _.-'_.-'|                                  
 |    `-._`-._        _.-'_.-'    |                                  
  `-._    `-._`-.__.-'_.-'    _.-'                                   
      `-._    `-.__.-'    _.-'                                       
          `-._        _.-'                                           
              `-.__.-'                                               

[22332] 05 Jan 12:01:48.399 # Sentinel ID is 48693b2911456ef3da6ebfd14d1adf46e76fbb8b
[22332] 05 Jan 12:01:48.399 # +monitor master master 127.0.0.1 28382 quorum 2
[22332] 05 Jan 12:01:53.399 # +sdown sentinel ce50397a76e2e3ca165ce407859cbc94d7caf504 127.0.0.1 28482 @ master 127.0.0.1 28382
[22332] 05 Jan 12:01:53.399 # +sdown sentinel 162c66f370550a9926b794abecfb431cf3f8bcc9 127.0.0.1 28483 @ master 127.0.0.1 28382
[22332] 05 Jan 12:02:13.404 # +sdown master master 127.0.0.1 28382&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;同时启动完会自动在哨兵的配置文件中生成一些配置,完整的redis-sentinel-28481.conf配置如下&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;dir &quot;F:\\Study\\redis\\redis-sentinel&quot;
logfile &quot;sentinel.28481.txt&quot;
port 28481
sentinel myid 48693b2911456ef3da6ebfd14d1adf46e76fbb8b
sentinel monitor master 127.0.0.1 28381 2
sentinel down-after-milliseconds master 5000
sentinel failover-timeout master 30000
# Generated by CONFIG REWRITE
sentinel auth-pass master test1
sentinel config-epoch master 11
sentinel leader-epoch master 11
sentinel known-slave master 127.0.0.1 28382
sentinel known-slave master 127.0.0.1 28380
sentinel known-sentinel master 127.0.0.1 28482 ce50397a76e2e3ca165ce407859cbc94d7caf504
sentinel known-sentinel master 127.0.0.1 28483 162c66f370550a9926b794abecfb431cf3f8bcc9
sentinel current-epoch 11
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;启动后会为哨兵生成一个id，同时会记录一些关键信息。&lt;/p&gt;
&lt;h3 id=&quot;主从自动切换&quot;&gt;主从自动切换&lt;/h3&gt;
&lt;p&gt;将主redis关闭，让哨兵自动切换主从。&lt;br/&gt;哨兵24381日志&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;[22332] 05 Jan 12:34:49.286 # +sdown master master 127.0.0.1 28380
[22332] 05 Jan 12:34:49.295 # +new-epoch 16
[22332] 05 Jan 12:34:49.296 # +vote-for-leader ce50397a76e2e3ca165ce407859cbc94d7caf504 16
[22332] 05 Jan 12:34:49.363 # +odown master master 127.0.0.1 28380 #quorum 3/2
[22332] 05 Jan 12:34:49.363 # Next failover delay: I will not start a failover before Sat Jan 05 12:35:49 2019
[22332] 05 Jan 12:34:50.397 # +config-update-from sentinel ce50397a76e2e3ca165ce407859cbc94d7caf504 127.0.0.1 28482 @ master 127.0.0.1 28380
[22332] 05 Jan 12:34:50.397 # +switch-master master 127.0.0.1 28380 127.0.0.1 28382
[22332] 05 Jan 12:34:50.397 * +slave slave 127.0.0.1:28381 127.0.0.1 28381 @ master 127.0.0.1 28382
[22332] 05 Jan 12:34:50.397 * +slave slave 127.0.0.1:28380 127.0.0.1 28380 @ master 127.0.0.1 28382
[22332] 05 Jan 12:34:55.442 # +sdown slave 127.0.0.1:28380 127.0.0.1 28380 @ master 127.0.0.1 28382&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;哨兵24382日志&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;[8760] 05 Jan 12:34:49.237 # +sdown master master 127.0.0.1 28380
[8760] 05 Jan 12:34:49.292 # +odown master master 127.0.0.1 28380 #quorum 2/2
[8760] 05 Jan 12:34:49.292 # +new-epoch 16
[8760] 05 Jan 12:34:49.292 # +try-failover master master 127.0.0.1 28380
[8760] 05 Jan 12:34:49.293 # +vote-for-leader ce50397a76e2e3ca165ce407859cbc94d7caf504 16
[8760] 05 Jan 12:34:49.296 # 162c66f370550a9926b794abecfb431cf3f8bcc9 voted for ce50397a76e2e3ca165ce407859cbc94d7caf504 16
[8760] 05 Jan 12:34:49.296 # 48693b2911456ef3da6ebfd14d1adf46e76fbb8b voted for ce50397a76e2e3ca165ce407859cbc94d7caf504 16
[8760] 05 Jan 12:34:49.394 # +elected-leader master master 127.0.0.1 28380
[8760] 05 Jan 12:34:49.394 # +failover-state-select-slave master master 127.0.0.1 28380
[8760] 05 Jan 12:34:49.470 # +selected-slave slave 127.0.0.1:28382 127.0.0.1 28382 @ master 127.0.0.1 28380
[8760] 05 Jan 12:34:49.470 * +failover-state-send-slaveof-noone slave 127.0.0.1:28382 127.0.0.1 28382 @ master 127.0.0.1 28380
[8760] 05 Jan 12:34:49.541 * +failover-state-wait-promotion slave 127.0.0.1:28382 127.0.0.1 28382 @ master 127.0.0.1 28380
[8760] 05 Jan 12:34:50.341 # +promoted-slave slave 127.0.0.1:28382 127.0.0.1 28382 @ master 127.0.0.1 28380
[8760] 05 Jan 12:34:50.341 # +failover-state-reconf-slaves master master 127.0.0.1 28380
[8760] 05 Jan 12:34:50.396 * +slave-reconf-sent slave 127.0.0.1:28381 127.0.0.1 28381 @ master 127.0.0.1 28380
[8760] 05 Jan 12:34:51.380 * +slave-reconf-inprog slave 127.0.0.1:28381 127.0.0.1 28381 @ master 127.0.0.1 28380
[8760] 05 Jan 12:34:51.446 # -odown master master 127.0.0.1 28380
[8760] 05 Jan 12:34:52.393 * +slave-reconf-done slave 127.0.0.1:28381 127.0.0.1 28381 @ master 127.0.0.1 28380
[8760] 05 Jan 12:34:52.468 # +failover-end master master 127.0.0.1 28380
[8760] 05 Jan 12:34:52.468 # +switch-master master 127.0.0.1 28380 127.0.0.1 28382
[8760] 05 Jan 12:34:52.469 * +slave slave 127.0.0.1:28381 127.0.0.1 28381 @ master 127.0.0.1 28382
[8760] 05 Jan 12:34:52.469 * +slave slave 127.0.0.1:28380 127.0.0.1 28380 @ master 127.0.0.1 28382
[8760] 05 Jan 12:34:57.562 # +sdown slave 127.0.0.1:28380 127.0.0.1 28380 @ master 127.0.0.1 28382&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;哨兵24383日志&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;[26484] 05 Jan 12:34:49.161 # +sdown master master 127.0.0.1 28380
[26484] 05 Jan 12:34:49.294 # +new-epoch 16
[26484] 05 Jan 12:34:49.295 # +vote-for-leader ce50397a76e2e3ca165ce407859cbc94d7caf504 16
[26484] 05 Jan 12:34:50.284 # +odown master master 127.0.0.1 28380 #quorum 3/2
[26484] 05 Jan 12:34:50.284 # Next failover delay: I will not start a failover before Sat Jan 05 12:35:49 2019
[26484] 05 Jan 12:34:50.397 # +config-update-from sentinel ce50397a76e2e3ca165ce407859cbc94d7caf504 127.0.0.1 28482 @ master 127.0.0.1 28380
[26484] 05 Jan 12:34:50.397 # +switch-master master 127.0.0.1 28380 127.0.0.1 28382
[26484] 05 Jan 12:34:50.397 * +slave slave 127.0.0.1:28381 127.0.0.1 28381 @ master 127.0.0.1 28382
[26484] 05 Jan 12:34:50.397 * +slave slave 127.0.0.1:28380 127.0.0.1 28380 @ master 127.0.0.1 28382
[26484] 05 Jan 12:34:55.437 # +sdown slave 127.0.0.1:28380 127.0.0.1 28380 @ master 127.0.0.1 28382&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;具体投票过程这里不做具体分析。&lt;br/&gt;当选出新的主redis，哨兵会对redis配置进行更新，将主redis的&lt;code&gt;slaveof XXX XXX&lt;/code&gt;配置删除，将从的&lt;code&gt;slaveof XXX XXX&lt;/code&gt;设置为主的地址。同时哨兵会监控redis28380。当28380恢复后会将&lt;code&gt;slaveof XXX XXX&lt;/code&gt;添加到它的配置中。&lt;/p&gt;
&lt;p&gt;连接到28382查看&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;127.0.0.1:28382&amp;gt; info Replication
# Replication
role:master
connected_slaves:2
slave0:ip=127.0.0.1,port=28381,state=online,offset=193307,lag=1
slave1:ip=127.0.0.1,port=28380,state=online,offset=193441,lag=1
master_repl_offset:193575
repl_backlog_active:1
repl_backlog_size:1048576
repl_backlog_first_byte_offset:2
repl_backlog_histlen:193574&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;动态新增从库&quot;&gt;动态新增从库&lt;/h3&gt;
&lt;p&gt;若我们此时动态新增一个从redis，端口为28383，则复制一个28380的配置进行修改,将优先级改为97。并启动服务即可。&lt;/p&gt;
&lt;p&gt;redis-28383日志如下&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;[14048] 05 Jan 12:55:20.421 * Redis 3.2.100 (00000000/0) 64 bit, standalone mode, port 28383, pid 14048 ready to start.
[14048] 05 Jan 12:55:20.422 # Server started, Redis version 3.2.100
[14048] 05 Jan 12:55:20.423 * The server is now ready to accept connections on port 28383
[14048] 05 Jan 12:55:20.424 * Connecting to MASTER 127.0.0.1:28382
[14048] 05 Jan 12:55:20.426 * MASTER &amp;lt;-&amp;gt; SLAVE sync started
[14048] 05 Jan 12:55:20.427 * Non blocking connect for SYNC fired the event.
[14048] 05 Jan 12:55:20.428 * Master replied to PING, replication can continue...
[14048] 05 Jan 12:55:20.428 * Partial resynchronization not possible (no cached master)
[14048] 05 Jan 12:55:20.432 * Full resync from master: 2c344529e4acdc44cd311818fe8179825877a9f4:241347
[14048] 05 Jan 12:55:20.653 * MASTER &amp;lt;-&amp;gt; SLAVE sync: receiving 107 bytes from master
[14048] 05 Jan 12:55:20.655 * MASTER &amp;lt;-&amp;gt; SLAVE sync: Flushing old data
[14048] 05 Jan 12:55:20.655 * MASTER &amp;lt;-&amp;gt; SLAVE sync: Loading DB in memory
[14048] 05 Jan 12:55:20.656 * MASTER &amp;lt;-&amp;gt; SLAVE sync: Finished with success
[14048] 05 Jan 12:55:20.660 * Background append only file rewriting started by pid 29392
[14048] 05 Jan 12:55:20.827 * AOF rewrite child asks to stop sending diffs.
[14048] 05 Jan 12:55:20.927 # fork operation complete
[14048] 05 Jan 12:55:20.928 * Background AOF rewrite terminated with success
[14048] 05 Jan 12:55:20.929 * Residual parent diff successfully flushed to the rewritten AOF (0.00 MB)
[14048] 05 Jan 12:55:20.931 * Background AOF rewrite finished successfully&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;再看下28382的主从连接信息&lt;/p&gt;
&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;127.0.0.1:28382&amp;gt; info Replication
# Replication
role:master
connected_slaves:3
slave0:ip=127.0.0.1,port=28381,state=online,offset=268634,lag=0
slave1:ip=127.0.0.1,port=28380,state=online,offset=268768,lag=0
slave2:ip=127.0.0.1,port=28383,state=online,offset=268634,lag=0
master_repl_offset:268768
repl_backlog_active:1
repl_backlog_size:1048576
repl_backlog_first_byte_offset:2
repl_backlog_histlen:268767&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;哨兵也能检测到新的从库连接&lt;br/&gt;&lt;code&gt;[22332] 05 Jan 12:55:25.420 * +slave slave 127.0.0.1:28383 127.0.0.1 28383 @ master 127.0.0.1 28382&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;通过上述配置，就完成了redis高可用方案。&lt;/p&gt;
&lt;h2 id=&quot;程序连接redis高可用&quot;&gt;程序连接redis高可用&lt;/h2&gt;
&lt;p&gt;我使用的是&lt;code&gt;StackExchange.Redis&lt;/code&gt;连接redis。&lt;/p&gt;
&lt;p&gt;它本身就支持主从连接，在建立连接的时候输入多个连接地址接口。由于从库不允许写入。因此它能辨别出哪个是主哪个是从。主从切换后写入数据的时候重新判定哪个是主库。&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;通过代码设置redis地址&lt;/li&gt;
&lt;/ol&gt;&lt;pre class=&quot;c#&quot;&gt;
&lt;code&gt;    ConfigurationOptions options = ConfigurationOptions.Parse(&quot;password=test1&quot;);
    options.EndPoints.Add(&quot;127.0.0.1&quot;, 28380);
    options.EndPoints.Add(&quot;127.0.0.1&quot;, 28381);
    options.EndPoints.Add(&quot;127.0.0.1&quot;, 28382);&lt;/code&gt;
&lt;/pre&gt;
&lt;ol&gt;&lt;li&gt;通过配置字符串设置&lt;/li&gt;
&lt;/ol&gt;&lt;pre class=&quot;c#&quot;&gt;
&lt;code&gt;    ConfigurationOptions options = ConfigurationOptions.Parse(&quot;127.0.0.1:28380,127.0.0.1:28381,127.0.0.1:28382,keepAlive=5,password=test1&quot;);&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;总结&quot;&gt;总结&lt;/h2&gt;
&lt;p&gt;通过该篇文章详细的探究了window下的redis高可用方案如何实现。本文对具体配置没有做深入探究，仅仅为了抓住重点，具体配置其他的文档都介绍的比较详细，但是一些细节并没有说明，通过该片文章将reids高可用的坑都填满。若有错误，欢迎指正。&lt;/p&gt;
&lt;p&gt;实例可以从&lt;a href=&quot;https://files.cnblogs.com/files/Jack-Blog/redis%E9%AB%98%E5%8F%AF%E7%94%A8.rar&quot;&gt;这里&lt;/a&gt;下载&lt;/p&gt;
&lt;hr/&gt;&lt;h2 id=&quot;参考文档&quot;&gt;参考文档&lt;/h2&gt;
&lt;ol&gt;&lt;li&gt;&lt;a href=&quot;https://blog.csdn.net/csdnlyu/article/details/78738832&quot;&gt;redis sentinel配置（windows环境）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://www.cnblogs.com/zhoujinyi/p/5570024.html&quot;&gt;Redis 复制、Sentinel的搭建和原理说明&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;</description>
<pubDate>Sat, 05 Jan 2019 05:27:00 +0000</pubDate>
<dc:creator>杰哥很忙</dc:creator>
<og:description>本篇文章专注于讲解redis在windows环境下使用Redis Sentinel(哨兵)实现高可用方案。</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/Jack-Blog/p/10224193.html</dc:identifier>
</item>
</channel>
</rss>