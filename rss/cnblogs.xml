<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="css/feed.xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/" xmlns:og="http://ogp.me/ns#">
<channel>
<atom:link rel="self" href="http://192.168.1.4/fivefilters/makefulltextfeed.php?url=feed.cnblogs.com%2Fblog%2Fsitehome%2Frss&amp;max=10&amp;links=preserve&amp;exc=" />
<atom:link rel="alternate" title="Source URL" href="http://feed.cnblogs.com/blog/sitehome/rss" />
<atom:link rel="related" title="Subscribe to feed" href="http://www.subtome.com/#/subscribe?feeds=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed.cnblogs.com%252Fblog%252Fsitehome%252Frss%26max%3D10%26links%3Dpreserve%26exc%3D&amp;back=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed.cnblogs.com%252Fblog%252Fsitehome%252Frss%26max%3D10%26links%3Dpreserve%26exc%3D" />
<title>博客园_首页</title>
<link></link>
<description>代码改变世界</description>
<item>
<title>Selenium3+Python3_04：iframe切换 - 晶晶elaine</title>
<link>http://www.cnblogs.com/elaine888/p/10421315.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/elaine888/p/10421315.html</guid>
<description>&lt;p&gt;&lt;strong&gt;1.用iframe的id属性切换到iframe：&lt;/strong&gt;&lt;br/&gt;driver.switch_to.frame(&quot;id的值&quot;)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2.用iframe的name属性切换到iframe：&lt;/strong&gt;&lt;br/&gt;driver.switch_to.frame(&quot;name的值&quot;)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;3.iframe没有id和name属性，把iframe当作一个对象，用标签去定位全部iframe，然后用下标取某个iframe，再去切换&lt;/strong&gt;&lt;br/&gt;frame = driver.find_elements_by_tag_name (“iframe”)[0]&lt;br/&gt;driver.switch_to.frame(&quot;frame&quot;)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;4.用iframe的索引方式，去切换iframe：&lt;/strong&gt;&lt;br/&gt;&lt;span lang=&quot;EN-US&quot;&gt;driver.switch_to.frame(0)   #索引从0开始&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;span lang=&quot;EN-US&quot;&gt;5.切换到上一层：&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;driver.switch_to.parent_frame()&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;6.iframe上操作完成，切换回Top Windows：&lt;/strong&gt;&lt;br/&gt;driver.switch_to.default_content()&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;实例：126邮箱登陆，切换iframe&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1443313/201902/1443313-20190222232925081-917720748.png&quot; alt=&quot;&quot; width=&quot;493&quot; height=&quot;323&quot;/&gt;&lt;/strong&gt;&lt;/p&gt;

</description>
<pubDate>Fri, 22 Feb 2019 15:37:00 +0000</pubDate>
<dc:creator>晶晶elaine</dc:creator>
<og:description>1.用iframe的id属性切换到iframe：driver.switch_to.frame(&quot;id的值&quot;) 2.用iframe的name属性切换到iframe：driver.sw</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/elaine888/p/10421315.html</dc:identifier>
</item>
<item>
<title>从零开始学习开发人工智能(一) - 徵羽摩柯</title>
<link>http://www.cnblogs.com/hk-zzmk/p/10421289.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/hk-zzmk/p/10421289.html</guid>
<description>&lt;div class=&quot;cl-preview-section&quot; readability=&quot;10&quot;&gt;
&lt;p&gt;关于学习如何开发人工智能。&lt;br/&gt;我从今天开始，将开始学习如何开发人工智能。&lt;br/&gt;我将会从最基础的内容开始学起。&lt;/p&gt;
&lt;p&gt;这一次，我们开发一个真正的人工智能。&lt;br/&gt;我们需要学会的内容有：&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;cl-preview-section&quot;&gt;
&lt;ol&gt;&lt;li&gt;编程语言：C#&lt;/li&gt;
&lt;li&gt;建模引擎：Maya&lt;/li&gt;
&lt;li&gt;游戏引擎：Unity3D&lt;/li&gt;
&lt;li&gt;混合现实与全息投影：HoloLens开发&lt;/li&gt;
&lt;li&gt;人工智能：机器学习、深度学习、神经网络、自然语言处理&lt;/li&gt;
&lt;li&gt;人工智能框架：ML.NET(微软推出的本地人工智能框架)、WindowsML(微软内置的AI框架)&lt;/li&gt;
&lt;li&gt;数据库：SQL Server&lt;/li&gt;
&lt;li&gt;网站开发框架：&lt;a href=&quot;http://asp.net/&quot;&gt;ASP.NET&lt;/a&gt;(此处我们开发项目网站需要用到)&lt;/li&gt;
&lt;/ol&gt;&lt;/div&gt;
&lt;div class=&quot;cl-preview-section&quot; readability=&quot;7&quot;&gt;
&lt;p&gt;以后可能会增加新的学习内容。&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;cl-preview-section&quot; readability=&quot;20&quot;&gt;
&lt;p&gt;关于人工智能&lt;br/&gt;我先谈一谈我对人工智能的看法。其实机器人也是一样的。&lt;/p&gt;
&lt;p&gt;我认为人工智能一定要有这三个要素：颜值、交互、功能。&lt;/p&gt;
&lt;p&gt;颜值：人工智能一定要有一个好的形象，模型做的精度、清晰度要高，如果可以的话，应该带上特效、动画。(脑海中：人工智能穿漂亮的衣服、好看的皮肤……美美哒，和人工智能合影留念)。&lt;/p&gt;
&lt;p&gt;交互：人工智能一定要交互性好，交互不能太生硬，人与AI之间的交互、AI与AI之间的交互，应该向人和人之间的交流互动一样。(我和人工智能的亲密接触，可以和人工智能愉快的玩耍。)&lt;/p&gt;
&lt;p&gt;功能：其实功能就是指AI会做什么事情，可以想一下人会做什么事情，AI能够帮助人做什么事情。至于实现什么样的功能，最终进行到项目阶段再说吧。&lt;/p&gt;
&lt;/div&gt;
</description>
<pubDate>Fri, 22 Feb 2019 15:28:00 +0000</pubDate>
<dc:creator>徵羽摩柯</dc:creator>
<og:description>关于学习如何开发人工智能。我从今天开始，将开始学习如何开发人工智能。我将会从最基础的内容开始学起。 这一次，我们开发一个真正的人工智能。我们需要学会的内容有： 关于学习如何开发人工智能。我从今天开始，</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/hk-zzmk/p/10421289.html</dc:identifier>
</item>
<item>
<title>TensorFlow tutorial - sdu20112013</title>
<link>http://www.cnblogs.com/sdu20112013/p/10421287.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/sdu20112013/p/10421287.html</guid>
<description>&lt;p&gt;代码示例来自https://github.com/aymericdamien/TensorFlow-Examples&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;tensorflow先定义运算图,在run的时候才会进行真正的运算。&lt;/li&gt;
&lt;li&gt;run之前需要先建立一个session&lt;/li&gt;
&lt;li&gt;常量用constant 如a = tf.constant(2)&lt;/li&gt;
&lt;li&gt;变量用placeholder 需要指定类型 如a = tf.placeholder(tf.int16)&lt;/li&gt;
&lt;/ul&gt;&lt;h3 id=&quot;矩阵相乘&quot;&gt;矩阵相乘&lt;/h3&gt;
&lt;pre&gt;
&lt;code&gt;matrix1 = tf.constant([[3., 3.]])  #1*2矩阵
matrix2 = tf.constant([[2.],[2.]]) #2*1矩阵
product = tf.matmul(matrix1, matrix2) #矩阵相乘得到1*1矩阵
with tf.Session() as sess:
    result = sess.run(product)   #result类型为ndarray
    print(result)
    # ==&amp;gt; [[ 12.]]
&lt;/code&gt;
&lt;/pre&gt;
&lt;pre&gt;
&lt;code&gt;'''
Basic Operations example using TensorFlow library.
Author: Aymeric Damien
Project: https://github.com/aymericdamien/TensorFlow-Examples/
'''

from __future__ import print_function

import tensorflow as tf

# Basic constant operations
# The value returned by the constructor represents the output
# of the Constant op.
a = tf.constant(2)
b = tf.constant(3)

# Launch the default graph.
with tf.Session() as sess:
    print(&quot;a=2, b=3&quot;)
    print(&quot;Addition with constants: %i&quot; % sess.run(a+b))
    print(&quot;Multiplication with constants: %i&quot; % sess.run(a*b))

# Basic Operations with variable as graph input
# The value returned by the constructor represents the output
# of the Variable op. (define as input when running session)
# tf Graph input
a = tf.placeholder(tf.int16)
b = tf.placeholder(tf.int16)

# Define some operations
add = tf.add(a, b)
mul = tf.multiply(a, b)

# Launch the default graph.
with tf.Session() as sess:
    # Run every operation with variable input
    print(&quot;Addition with variables: %i&quot; % sess.run(add, feed_dict={a: 2, b: 3}))
    print(&quot;Multiplication with variables: %i&quot; % sess.run(mul, feed_dict={a: 2, b: 3}))


# ----------------
# More in details:
# Matrix Multiplication from TensorFlow official tutorial

# Create a Constant op that produces a 1x2 matrix.  The op is
# added as a node to the default graph.
#
# The value returned by the constructor represents the output
# of the Constant op.
matrix1 = tf.constant([[3., 3.]])

# Create another Constant that produces a 2x1 matrix.
matrix2 = tf.constant([[2.],[2.]])

# Create a Matmul op that takes 'matrix1' and 'matrix2' as inputs.
# The returned value, 'product', represents the result of the matrix
# multiplication.
product = tf.matmul(matrix1, matrix2)

# To run the matmul op we call the session 'run()' method, passing 'product'
# which represents the output of the matmul op.  This indicates to the call
# that we want to get the output of the matmul op back.
#
# All inputs needed by the op are run automatically by the session.  They
# typically are run in parallel.
#
# The call 'run(product)' thus causes the execution of threes ops in the
# graph: the two constants and matmul.
#
# The output of the op is returned in 'result' as a numpy `ndarray` object.
with tf.Session() as sess:
    result = sess.run(product)
    print(result)
    # ==&amp;gt; [[ 12.]]&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;eager-api&quot;&gt;eager api&lt;/h3&gt;
&lt;p&gt;详细解释参见https://www.zhihu.com/question/67471378&lt;br/&gt;之前说过tensorflow是先定义运算图,在session.run的时候才会真正做运算.&lt;br/&gt;tensorflow推出了eager api.使得tf(tensorflow简称)中的函数可以像我们熟知的普通函数一样,调用后立刻可以得到结果,更方便调试.&lt;br/&gt;坏处是和之前的有些代码不兼容.比如和Basic1里的示例代码就无法兼容.&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;tfe.enable_eager_execution() 开启eager模式要放在代码最前面&lt;/li&gt;
&lt;/ul&gt;&lt;pre&gt;
&lt;code&gt;'''
Basic introduction to TensorFlow's Eager API.

Author: Aymeric Damien
Project: https://github.com/aymericdamien/TensorFlow-Examples/

What is Eager API?
&quot; Eager execution is an imperative, define-by-run interface where operations are
executed immediately as they are called from Python. This makes it easier to
get started with TensorFlow, and can make research and development more
intuitive. A vast majority of the TensorFlow API remains the same whether eager
execution is enabled or not. As a result, the exact same code that constructs
TensorFlow graphs (e.g. using the layers API) can be executed imperatively
by using eager execution. Conversely, most models written with Eager enabled
can be converted to a graph that can be further optimized and/or extracted
for deployment in production without changing code. &quot; - Rajat Monga

'''
from __future__ import absolute_import, division, print_function

import numpy as np
import tensorflow as tf
import tensorflow.contrib.eager as tfe

# Set Eager API
print(&quot;Setting Eager mode...&quot;)
tfe.enable_eager_execution()

# Define constant tensors
print(&quot;Define constant tensors&quot;)
a = tf.constant(2)
print(&quot;a = %i&quot; % a)
b = tf.constant(3)
print(&quot;b = %i&quot; % b)

# Run the operation without the need for tf.Session
print(&quot;Running operations, without tf.Session&quot;)
c = a + b
print(&quot;a + b = %i&quot; % c)
d = a * b
print(&quot;a * b = %i&quot; % d)


# Full compatibility with Numpy
print(&quot;Mixing operations with Tensors and Numpy Arrays&quot;)

# Define constant tensors
a = tf.constant([[2., 1.],
                 [1., 0.]], dtype=tf.float32)
print(&quot;Tensor:\n a = %s&quot; % a)
b = np.array([[3., 0.],
              [5., 1.]], dtype=np.float32)
print(&quot;NumpyArray:\n b = %s&quot; % b)

# Run the operation without the need for tf.Session
print(&quot;Running operations, without tf.Session&quot;)

c = a + b
print(&quot;a + b = %s&quot; % c)

d = tf.matmul(a, b)
print(&quot;a * b = %s&quot; % d)

print(&quot;Iterate through Tensor 'a':&quot;)
for i in range(a.shape[0]):
    for j in range(a.shape[1]):
        print(a[i][j])
&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;卷积神经网络&quot;&gt;卷积神经网络&lt;/h3&gt;
&lt;p&gt;阅读这部分之前先要对卷积神经网络有多了解.参见https://www.cnblogs.com/sdu20112013/p/10149529.html&lt;br/&gt;神经网络的参数&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;输入层 样本X的维度 图片为28*28-&amp;gt;784&lt;/li&gt;
&lt;li&gt;全连接层的输出 图片种类,0到数字9共10种&lt;/li&gt;
&lt;li&gt;dropout = 0.25 # Dropout, probability to drop a unit 为了防止过拟合,丢弃某些神经元的输出&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;训练参数&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;学习率&lt;/li&gt;
&lt;li&gt;batch_size 梯度求解参考的样本数量&lt;/li&gt;
&lt;li&gt;num_steps 可能是只迭代的轮次？&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;构建一个CNN&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;卷积层,池化层,完成特征提取.&lt;/li&gt;
&lt;li&gt;卷积层 32个filter filter的size是5*5 激活函数relu&lt;/li&gt;
&lt;li&gt;池化层 2个filter filter的size是2*2&lt;/li&gt;
&lt;/ul&gt;&lt;pre&gt;
&lt;code&gt;# Convolution Layer with 32 filters and a kernel size of 5
conv1 = tf.layers.conv2d(x, 32, 5, activation=tf.nn.relu)
# Max Pooling (down-sampling) with strides of 2 and kernel size of 2
conv1 = tf.layers.max_pooling2d(conv1, 2, 2)&lt;/code&gt;
&lt;/pre&gt;
&lt;ul&gt;&lt;li&gt;卷积层,池化层,进一步提取特征&lt;/li&gt;
&lt;/ul&gt;&lt;pre&gt;
&lt;code&gt;# Convolution Layer with 64 filters and a kernel size of 3
conv2 = tf.layers.conv2d(conv1, 64, 3, activation=tf.nn.relu)
# Max Pooling (down-sampling) with strides of 2 and kernel size of 2
conv2 = tf.layers.max_pooling2d(conv2, 2, 2)&lt;/code&gt;
&lt;/pre&gt;
&lt;ul&gt;&lt;li&gt;全连接层,完成分类&lt;/li&gt;
&lt;/ul&gt;&lt;pre&gt;
&lt;code&gt;# Flatten the data to a 1-D vector for the fully connected layer
#全连接层接收的是个M*N的矩阵 flatten:拍平.可以理解为把一摞叠起来的矩阵拍平
fc1 = tf.contrib.layers.flatten(conv2)

# Fully connected layer (in tf contrib folder for now)
#全连接层有1024个神经元
fc1 = tf.layers.dense(fc1, 1024)
# Apply Dropout (if is_training is False, dropout is not applied)
#对训练集,要对部分神经元做dropout,以引入非线性.只有训练集才会dropout
fc1 = tf.layers.dropout(fc1, rate=dropout, training=is_training)

# Output layer, class prediction
#对全连接层输出做分类
out = tf.layers.dense(fc1, n_classes)&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;模型构建好了,现在需要告诉我们的模型损失函数有关的信息,这样模型才能够知道如何求梯度,并进而更新神经元之间的权重信息.&lt;br/&gt;tensorflow要求我们定一个Estimator&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;损失函数定义&lt;/li&gt;
&lt;li&gt;最优化算法定义&lt;/li&gt;
&lt;li&gt;模型准确度定义&lt;/li&gt;
&lt;li&gt;TF Estimators requires to return a EstimatorSpec, that specify the different ops for training, evaluating,&lt;/li&gt;
&lt;/ul&gt;&lt;pre&gt;
&lt;code&gt;logits_train = conv_net(features, num_classes, dropout, reuse=False,is_training=True)
loss_op = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits_train, labels=tf.cast(labels, dtype=tf.int32)))#损失函数定义
optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)#最优化算法 也可以用小批量梯度下降法SGD
train_op = optimizer.minimize(loss_op,global_step=tf.train.get_global_step())#最优化目标：使得loss最小&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;至此,我们已经完成了模型的创建,下面就是把数据转换成合适的格式喂给模型,进行训练.&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;# Define the input function for training
input_fn = tf.estimator.inputs.numpy_input_fn(
x={'images': mnist.train.images}, y=mnist.train.labels,
batch_size=batch_size, num_epochs=None, shuffle=True)
# Train the Model
model.train(input_fn, steps=num_steps)

# Evaluate the Model
# Define the input function for evaluating
input_fn = tf.estimator.inputs.numpy_input_fn(
x={'images': mnist.test.images}, y=mnist.test.labels,
batch_size=batch_size, shuffle=False)
# Use the Estimator 'evaluate' method
e = model.evaluate(input_fn)
&lt;/code&gt;
&lt;/pre&gt;
&lt;pre&gt;
&lt;code&gt;&quot;&quot;&quot; Convolutional Neural Network.

Build and train a convolutional neural network with TensorFlow.
This example is using the MNIST database of handwritten digits
(http://yann.lecun.com/exdb/mnist/)

This example is using TensorFlow layers API, see 'convolutional_network_raw' 
example for a raw implementation with variables.

Author: Aymeric Damien
Project: https://github.com/aymericdamien/TensorFlow-Examples/
&quot;&quot;&quot;
from __future__ import division, print_function, absolute_import

# Import MNIST data
from tensorflow.examples.tutorials.mnist import input_data
mnist = input_data.read_data_sets(&quot;/tmp/data/&quot;, one_hot=False)

import tensorflow as tf

# Training Parameters
learning_rate = 0.001
num_steps = 2000
batch_size = 128

# Network Parameters
num_input = 784 # MNIST data input (img shape: 28*28)
num_classes = 10 # MNIST total classes (0-9 digits)
dropout = 0.25 # Dropout, probability to drop a unit


# Create the neural network
def conv_net(x_dict, n_classes, dropout, reuse, is_training):
    # Define a scope for reusing the variables
    with tf.variable_scope('ConvNet', reuse=reuse):
        # TF Estimator input is a dict, in case of multiple inputs
        x = x_dict['images']

        # MNIST data input is a 1-D vector of 784 features (28*28 pixels)
        # Reshape to match picture format [Height x Width x Channel]
        # Tensor input become 4-D: [Batch Size, Height, Width, Channel]
        x = tf.reshape(x, shape=[-1, 28, 28, 1])

        # Convolution Layer with 32 filters and a kernel size of 5
        conv1 = tf.layers.conv2d(x, 32, 5, activation=tf.nn.relu)
        # Max Pooling (down-sampling) with strides of 2 and kernel size of 2
        conv1 = tf.layers.max_pooling2d(conv1, 2, 2)

        # Convolution Layer with 64 filters and a kernel size of 3
        conv2 = tf.layers.conv2d(conv1, 64, 3, activation=tf.nn.relu)
        # Max Pooling (down-sampling) with strides of 2 and kernel size of 2
        conv2 = tf.layers.max_pooling2d(conv2, 2, 2)

        # Flatten the data to a 1-D vector for the fully connected layer
        fc1 = tf.contrib.layers.flatten(conv2)
        print(&quot;fcl shape&quot;,fc1.shape)

        # Fully connected layer (in tf contrib folder for now)
        fc1 = tf.layers.dense(fc1, 1024)
        # Apply Dropout (if is_training is False, dropout is not applied)
        fc1 = tf.layers.dropout(fc1, rate=dropout, training=is_training)

        # Output layer, class prediction
        out = tf.layers.dense(fc1, n_classes)

    return out


# Define the model function (following TF Estimator Template)
def model_fn(features, labels, mode):
    # Build the neural network
    # Because Dropout have different behavior at training and prediction time, we
    # need to create 2 distinct computation graphs that still share the same weights.
    logits_train = conv_net(features, num_classes, dropout, reuse=False,
                            is_training=True)
    print(&quot;logits_train.shape&quot;,logits_train.shape)
    logits_test = conv_net(features, num_classes, dropout, reuse=True,
                           is_training=False)

    # Predictions
    pred_classes = tf.argmax(logits_test, axis=1)
    pred_probas = tf.nn.softmax(logits_test)

    # If prediction mode, early return
    if mode == tf.estimator.ModeKeys.PREDICT:
        return tf.estimator.EstimatorSpec(mode, predictions=pred_classes)

        # Define loss and optimizer
    loss_op = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(
        logits=logits_train, labels=tf.cast(labels, dtype=tf.int32)))
    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)
    train_op = optimizer.minimize(loss_op,
                                  global_step=tf.train.get_global_step())

    # Evaluate the accuracy of the model
    acc_op = tf.metrics.accuracy(labels=labels, predictions=pred_classes)

    # TF Estimators requires to return a EstimatorSpec, that specify
    # the different ops for training, evaluating, ...
    estim_specs = tf.estimator.EstimatorSpec(
        mode=mode,
        predictions=pred_classes,
        loss=loss_op,
        train_op=train_op,
        eval_metric_ops={'accuracy': acc_op})

    return estim_specs

# Build the Estimator
model = tf.estimator.Estimator(model_fn)

# Define the input function for training
input_fn = tf.estimator.inputs.numpy_input_fn(
    x={'images': mnist.train.images}, y=mnist.train.labels,
    batch_size=batch_size, num_epochs=None, shuffle=True)
# Train the Model
model.train(input_fn, steps=num_steps)

# Evaluate the Model
# Define the input function for evaluating
input_fn = tf.estimator.inputs.numpy_input_fn(
    x={'images': mnist.test.images}, y=mnist.test.labels,
    batch_size=batch_size, shuffle=False)
# Use the Estimator 'evaluate' method
e = model.evaluate(input_fn)

print(&quot;Testing Accuracy:&quot;, e['accuracy'])&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;顺便,说说我所理解的神经网络,&quot;神经元&quot;听着玄乎,其实每一个神经元就是y=ax+b而已,a,x都是矩阵. 神经元之间是有权重关系的,前一个神经元的输出作为下一个神经元的输入,赋以权重w. 通过这样的多层神经元,尽管每个神经元都做得是一个线性变化,（当然为了非线性会引入relu/sigmoid等)，组合起来确取得了模拟非线性的效果,利用反向传播算法,更新整个网络中的神经元直接的权重w.达到使误差最小. 本质上神经网络就是求矩阵w的运算.&lt;/p&gt;
</description>
<pubDate>Fri, 22 Feb 2019 15:28:00 +0000</pubDate>
<dc:creator>sdu20112013</dc:creator>
<og:description>代码示例来自https://github.com/aymericdamien/TensorFlow Examples tensorflow先定义运算图,在run的时候才会进行真正的运算。 run之前需</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/sdu20112013/p/10421287.html</dc:identifier>
</item>
<item>
<title>牛客网剑指offer java 全部题解 - 程序员乔戈里</title>
<link>http://www.cnblogs.com/qiaogeli/p/10421278.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/qiaogeli/p/10421278.html</guid>
<description>&lt;li&gt;每天一道剑指offer-二维数组中的查找&lt;br/&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzI5MzYzMDAwNw==&amp;amp;mid=2247484262&amp;amp;idx=2&amp;amp;sn=83fb17338c606e2080fe75331f1528f7&amp;amp;chksm=ec6e7a3edb19f32867e39964a4df4e38cacbc1779b7dbe708787d4b40851b41e21c7c4702c87&amp;amp;token=657087659&amp;amp;lang=zh_CN#rd&quot; class=&quot;uri&quot;&gt;https://mp.weixin.qq.com/s?__biz=MzI5MzYzMDAwNw==&amp;amp;mid=2247484262&amp;amp;idx=2&amp;amp;sn=83fb17338c606e2080fe75331f1528f7&amp;amp;chksm=ec6e7a3edb19f32867e39964a4df4e38cacbc1779b7dbe708787d4b40851b41e21c7c4702c87&amp;amp;token=657087659&amp;amp;lang=zh_CN#rd&lt;/a&gt;&lt;/li&gt;&lt;li readability=&quot;0.14117647058824&quot;&gt;
&lt;p&gt;每天一道剑指offer-替换空格&lt;br/&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzI5MzYzMDAwNw==&amp;amp;mid=2247484283&amp;amp;idx=3&amp;amp;sn=a8e3d735d5ea5d703856d9bd96a9e547&amp;amp;chksm=ec6e7a23db19f3353fc822e753e0eb91264dc772462e9d1d406a1f89853b86fd4dfcb5353a55&amp;amp;token=657087659&amp;amp;lang=zh_CN#rd&quot; class=&quot;uri&quot;&gt;https://mp.weixin.qq.com/s?__biz=MzI5MzYzMDAwNw==&amp;amp;mid=2247484283&amp;amp;idx=3&amp;amp;sn=a8e3d735d5ea5d703856d9bd96a9e547&amp;amp;chksm=ec6e7a23db19f3353fc822e753e0eb91264dc772462e9d1d406a1f89853b86fd4dfcb5353a55&amp;amp;token=657087659&amp;amp;lang=zh_CN#rd&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0.17977528089888&quot;&gt;
&lt;p&gt;每天一道剑指offer-从尾到头打印链表&lt;br/&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzI5MzYzMDAwNw==&amp;amp;mid=2247484302&amp;amp;idx=2&amp;amp;sn=193f840914f5f8b47cab0aee5fa43bf1&amp;amp;chksm=ec6e7ad6db19f3c08b574fea3ca328421ae679465c8c391a5224eb7c674804b53f3bad8d858e&amp;amp;token=657087659&amp;amp;lang=zh_CN#rd&quot; class=&quot;uri&quot;&gt;https://mp.weixin.qq.com/s?__biz=MzI5MzYzMDAwNw==&amp;amp;mid=2247484302&amp;amp;idx=2&amp;amp;sn=193f840914f5f8b47cab0aee5fa43bf1&amp;amp;chksm=ec6e7ad6db19f3c08b574fea3ca328421ae679465c8c391a5224eb7c674804b53f3bad8d858e&amp;amp;token=657087659&amp;amp;lang=zh_CN#rd&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0.15057915057915&quot;&gt;
&lt;p&gt;每天一道剑指offer-重建二叉树&lt;br/&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzI5MzYzMDAwNw==&amp;amp;mid=2247485461&amp;amp;idx=2&amp;amp;sn=8e837b43189575703a5ca72cc0a6ca9e&amp;amp;chksm=ec6e714ddb19f85bc58bb8cbd17408103d7f218ce684db1afa1bdb88e45293b2a5906cb9f306&amp;amp;token=1812131085&amp;amp;lang=zh_CN#rd&quot; class=&quot;uri&quot;&gt;https://mp.weixin.qq.com/s?__biz=MzI5MzYzMDAwNw==&amp;amp;mid=2247485461&amp;amp;idx=2&amp;amp;sn=8e837b43189575703a5ca72cc0a6ca9e&amp;amp;chksm=ec6e714ddb19f85bc58bb8cbd17408103d7f218ce684db1afa1bdb88e45293b2a5906cb9f306&amp;amp;token=1812131085&amp;amp;lang=zh_CN#rd&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0.17977528089888&quot;&gt;
&lt;p&gt;每天一道剑指offer-用两个栈实现队列&lt;br/&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzI5MzYzMDAwNw==&amp;amp;mid=2247484319&amp;amp;idx=2&amp;amp;sn=aed7b194077d4f4b90ab49a7081f9143&amp;amp;chksm=ec6e7ac7db19f3d1f2b756d603b8e7dd18f268ccfec98ef08b84f3e26c1c2067b201ff301cc6&amp;amp;token=657087659&amp;amp;lang=zh_CN#rd&quot; class=&quot;uri&quot;&gt;https://mp.weixin.qq.com/s?__biz=MzI5MzYzMDAwNw==&amp;amp;mid=2247484319&amp;amp;idx=2&amp;amp;sn=aed7b194077d4f4b90ab49a7081f9143&amp;amp;chksm=ec6e7ac7db19f3d1f2b756d603b8e7dd18f268ccfec98ef08b84f3e26c1c2067b201ff301cc6&amp;amp;token=657087659&amp;amp;lang=zh_CN#rd&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0.17977528089888&quot;&gt;
&lt;p&gt;每天一道剑指offer-旋转数组的最小值&lt;br/&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzI5MzYzMDAwNw==&amp;amp;mid=2247484332&amp;amp;idx=2&amp;amp;sn=1189afaddf726065d816329e1023cfc3&amp;amp;chksm=ec6e7af4db19f3e2be8ba63ec6b6b44528a1bafe82b991fd3bed6f21d1b4f7c46a9afc3b98c4&amp;amp;token=657087659&amp;amp;lang=zh_CN#rd&quot; class=&quot;uri&quot;&gt;https://mp.weixin.qq.com/s?__biz=MzI5MzYzMDAwNw==&amp;amp;mid=2247484332&amp;amp;idx=2&amp;amp;sn=1189afaddf726065d816329e1023cfc3&amp;amp;chksm=ec6e7af4db19f3e2be8ba63ec6b6b44528a1bafe82b991fd3bed6f21d1b4f7c46a9afc3b98c4&amp;amp;token=657087659&amp;amp;lang=zh_CN#rd&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0.18888888888889&quot;&gt;
&lt;p&gt;每天一道剑指offer-牛客网斐波那契数列&lt;br/&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzI5MzYzMDAwNw==&amp;amp;mid=2247484353&amp;amp;idx=3&amp;amp;sn=95d7568a4e32be37b5d0bfd28c666fac&amp;amp;chksm=ec6e7a99db19f38f3f7bc8a12dee7e77d0d7375998d82bd38430d8c249ec6b3384a449fdaa15&amp;amp;token=657087659&amp;amp;lang=zh_CN#rd&quot; class=&quot;uri&quot;&gt;https://mp.weixin.qq.com/s?__biz=MzI5MzYzMDAwNw==&amp;amp;mid=2247484353&amp;amp;idx=3&amp;amp;sn=95d7568a4e32be37b5d0bfd28c666fac&amp;amp;chksm=ec6e7a99db19f38f3f7bc8a12dee7e77d0d7375998d82bd38430d8c249ec6b3384a449fdaa15&amp;amp;token=657087659&amp;amp;lang=zh_CN#rd&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0.16091954022989&quot;&gt;
&lt;p&gt;每天一道剑指offer-牛客网跳台阶&lt;br/&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzI5MzYzMDAwNw==&amp;amp;mid=2247484365&amp;amp;idx=3&amp;amp;sn=9d7127136f3d605546f0463353e36743&amp;amp;chksm=ec6e7a95db19f38387ee5d64b84583a5dca92bc2dd9f84448c2e03b4f84152ae2dc0df167ed0&amp;amp;token=657087659&amp;amp;lang=zh_CN#rd&quot; class=&quot;uri&quot;&gt;https://mp.weixin.qq.com/s?__biz=MzI5MzYzMDAwNw==&amp;amp;mid=2247484365&amp;amp;idx=3&amp;amp;sn=9d7127136f3d605546f0463353e36743&amp;amp;chksm=ec6e7a95db19f38387ee5d64b84583a5dca92bc2dd9f84448c2e03b4f84152ae2dc0df167ed0&amp;amp;token=657087659&amp;amp;lang=zh_CN#rd&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0.17977528089888&quot;&gt;
&lt;p&gt;每天一道剑指offer-牛客网变态跳台阶&lt;br/&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzI5MzYzMDAwNw==&amp;amp;mid=2247484374&amp;amp;idx=3&amp;amp;sn=7f3165d24603b8bd7b29fd96b7100fb9&amp;amp;chksm=ec6e7a8edb19f3980d7460a827f2ad0df67f806e6cd337fff2baff79951b575f47412ea97745&amp;amp;token=657087659&amp;amp;lang=zh_CN#rd&quot; class=&quot;uri&quot;&gt;https://mp.weixin.qq.com/s?__biz=MzI5MzYzMDAwNw==&amp;amp;mid=2247484374&amp;amp;idx=3&amp;amp;sn=7f3165d24603b8bd7b29fd96b7100fb9&amp;amp;chksm=ec6e7a8edb19f3980d7460a827f2ad0df67f806e6cd337fff2baff79951b575f47412ea97745&amp;amp;token=657087659&amp;amp;lang=zh_CN#rd&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0.14117647058824&quot;&gt;
&lt;p&gt;每天一道剑指offer-矩形覆盖&lt;br/&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzI5MzYzMDAwNw==&amp;amp;mid=2247484385&amp;amp;idx=3&amp;amp;sn=cf7588e1d3ffbb34eb5a075baf1d7cdc&amp;amp;chksm=ec6e7ab9db19f3af357a95b980c6ef668c97c36dd1d57976db180d5b27a4db206e8af0c45ab6&amp;amp;token=657087659&amp;amp;lang=zh_CN#rd&quot; class=&quot;uri&quot;&gt;https://mp.weixin.qq.com/s?__biz=MzI5MzYzMDAwNw==&amp;amp;mid=2247484385&amp;amp;idx=3&amp;amp;sn=cf7588e1d3ffbb34eb5a075baf1d7cdc&amp;amp;chksm=ec6e7ab9db19f3af357a95b980c6ef668c97c36dd1d57976db180d5b27a4db206e8af0c45ab6&amp;amp;token=657087659&amp;amp;lang=zh_CN#rd&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0.2007299270073&quot;&gt;
&lt;p&gt;每天一道剑指offer-牛客网二进制中1的个数&lt;br/&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzI5MzYzMDAwNw==&amp;amp;mid=2247484405&amp;amp;idx=3&amp;amp;sn=ca8f0e57a41e522fa0525487bb6b54bc&amp;amp;chksm=ec6e7aaddb19f3bb0b00fcb39e5506fbaa888d3be4ae32fa7ee94ef39b1799307a1088bb2d29&amp;amp;token=657087659&amp;amp;lang=zh_CN#rd&quot; class=&quot;uri&quot;&gt;https://mp.weixin.qq.com/s?__biz=MzI5MzYzMDAwNw==&amp;amp;mid=2247484405&amp;amp;idx=3&amp;amp;sn=ca8f0e57a41e522fa0525487bb6b54bc&amp;amp;chksm=ec6e7aaddb19f3bb0b00fcb39e5506fbaa888d3be4ae32fa7ee94ef39b1799307a1088bb2d29&amp;amp;token=657087659&amp;amp;lang=zh_CN#rd&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0.1970802919708&quot;&gt;
&lt;p&gt;每天一道剑指offer-牛客网数值的整数次方&lt;br/&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzI5MzYzMDAwNw==&amp;amp;mid=2247484420&amp;amp;idx=3&amp;amp;sn=4d70430fae06d022c6cd75b61fa19ca1&amp;amp;chksm=ec6e7d5cdb19f44a8b6739a71f7874014c63af69e0cd0142cb119240635ba703f9c0b205f414&amp;amp;token=1812131085&amp;amp;lang=zh_CN#rd&quot; class=&quot;uri&quot;&gt;https://mp.weixin.qq.com/s?__biz=MzI5MzYzMDAwNw==&amp;amp;mid=2247484420&amp;amp;idx=3&amp;amp;sn=4d70430fae06d022c6cd75b61fa19ca1&amp;amp;chksm=ec6e7d5cdb19f44a8b6739a71f7874014c63af69e0cd0142cb119240635ba703f9c0b205f414&amp;amp;token=1812131085&amp;amp;lang=zh_CN#rd&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0.23875432525952&quot;&gt;
&lt;p&gt;每天一道剑指offer-调整数组顺序使奇数位于偶数前面&lt;br/&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzI5MzYzMDAwNw==&amp;amp;mid=2247484431&amp;amp;idx=2&amp;amp;sn=67a3c6e781c0017fe9ef1a71f112dcdd&amp;amp;chksm=ec6e7d57db19f441b06a7567c3ae00ee8cd73a5fe88b2bb8168847c7245802137e6446c7041e&amp;amp;token=1812131085&amp;amp;lang=zh_CN#rd&quot; class=&quot;uri&quot;&gt;https://mp.weixin.qq.com/s?__biz=MzI5MzYzMDAwNw==&amp;amp;mid=2247484431&amp;amp;idx=2&amp;amp;sn=67a3c6e781c0017fe9ef1a71f112dcdd&amp;amp;chksm=ec6e7d57db19f441b06a7567c3ae00ee8cd73a5fe88b2bb8168847c7245802137e6446c7041e&amp;amp;token=1812131085&amp;amp;lang=zh_CN#rd&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0.19188191881919&quot;&gt;
&lt;p&gt;每天一道剑指offer-链表中倒数第k个结点&lt;br/&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzI5MzYzMDAwNw==&amp;amp;mid=2247484441&amp;amp;idx=3&amp;amp;sn=0515c8f74b33fbf505d69e970bea0176&amp;amp;chksm=ec6e7d41db19f457298b82e0bd99ead09782778be51cc22283fb010c1270bc9ad21be31e0fef&amp;amp;token=657087659&amp;amp;lang=zh_CN#rd&quot; class=&quot;uri&quot;&gt;https://mp.weixin.qq.com/s?__biz=MzI5MzYzMDAwNw==&amp;amp;mid=2247484441&amp;amp;idx=3&amp;amp;sn=0515c8f74b33fbf505d69e970bea0176&amp;amp;chksm=ec6e7d41db19f457298b82e0bd99ead09782778be51cc22283fb010c1270bc9ad21be31e0fef&amp;amp;token=657087659&amp;amp;lang=zh_CN#rd&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0.140625&quot;&gt;
&lt;p&gt;每天一道剑指offer-反转链表&lt;br/&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzI5MzYzMDAwNw==&amp;amp;mid=2247484468&amp;amp;idx=3&amp;amp;sn=cb5301aba0a3d78580cb6517c45442e6&amp;amp;chksm=ec6e7d6cdb19f47a632e0076940979babf1bc9128788a1b5f8ed6da8e3c7ce9f2b7849f23c4c&amp;amp;token=1812131085&amp;amp;lang=zh_CN#rd&quot; class=&quot;uri&quot;&gt;https://mp.weixin.qq.com/s?__biz=MzI5MzYzMDAwNw==&amp;amp;mid=2247484468&amp;amp;idx=3&amp;amp;sn=cb5301aba0a3d78580cb6517c45442e6&amp;amp;chksm=ec6e7d6cdb19f47a632e0076940979babf1bc9128788a1b5f8ed6da8e3c7ce9f2b7849f23c4c&amp;amp;token=1812131085&amp;amp;lang=zh_CN#rd&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0.18888888888889&quot;&gt;
&lt;p&gt;每天一道剑指offer-合并两个排序的列表&lt;br/&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzI5MzYzMDAwNw==&amp;amp;mid=2247484487&amp;amp;idx=3&amp;amp;sn=fd1be32b550725d0affd73f8f56275bf&amp;amp;chksm=ec6e7d1fdb19f409588510b30a01494a59902ea26eca919579f4df74400eca5af07318413b8c&amp;amp;token=657087659&amp;amp;lang=zh_CN#rd&quot; class=&quot;uri&quot;&gt;https://mp.weixin.qq.com/s?__biz=MzI5MzYzMDAwNw==&amp;amp;mid=2247484487&amp;amp;idx=3&amp;amp;sn=fd1be32b550725d0affd73f8f56275bf&amp;amp;chksm=ec6e7d1fdb19f409588510b30a01494a59902ea26eca919579f4df74400eca5af07318413b8c&amp;amp;token=657087659&amp;amp;lang=zh_CN#rd&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0.15057915057915&quot;&gt;
&lt;p&gt;每天一道剑指offer-树的子结构&lt;br/&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzI5MzYzMDAwNw==&amp;amp;mid=2247484511&amp;amp;idx=2&amp;amp;sn=7eeae5a98a5b1a55b89e9dd54544b743&amp;amp;chksm=ec6e7d07db19f4117f38ece673ca5ace7ed2bc6abb782a001753bccfab79245d98f8622b49fa&amp;amp;token=1812131085&amp;amp;lang=zh_CN#rd&quot; class=&quot;uri&quot;&gt;https://mp.weixin.qq.com/s?__biz=MzI5MzYzMDAwNw==&amp;amp;mid=2247484511&amp;amp;idx=2&amp;amp;sn=7eeae5a98a5b1a55b89e9dd54544b743&amp;amp;chksm=ec6e7d07db19f4117f38ece673ca5ace7ed2bc6abb782a001753bccfab79245d98f8622b49fa&amp;amp;token=1812131085&amp;amp;lang=zh_CN#rd&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0.16030534351145&quot;&gt;
&lt;p&gt;每天一道剑指offer-二叉树的镜像&lt;br/&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzI5MzYzMDAwNw==&amp;amp;mid=2247484519&amp;amp;idx=3&amp;amp;sn=009e0d0d017d073bed34dc924ae78aeb&amp;amp;chksm=ec6e7d3fdb19f4297c0df2990886c9ee2685c528a4f59cc2bb339da95a0e8c8922606dbb7e8a&amp;amp;token=1812131085&amp;amp;lang=zh_CN#rd&quot; class=&quot;uri&quot;&gt;https://mp.weixin.qq.com/s?__biz=MzI5MzYzMDAwNw==&amp;amp;mid=2247484519&amp;amp;idx=3&amp;amp;sn=009e0d0d017d073bed34dc924ae78aeb&amp;amp;chksm=ec6e7d3fdb19f4297c0df2990886c9ee2685c528a4f59cc2bb339da95a0e8c8922606dbb7e8a&amp;amp;token=1812131085&amp;amp;lang=zh_CN#rd&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0.16981132075472&quot;&gt;
&lt;p&gt;每天一道剑指offer-顺时针打印矩阵&lt;br/&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzI5MzYzMDAwNw==&amp;amp;mid=2247484534&amp;amp;idx=2&amp;amp;sn=2909d7d1de88d12e90286a9521a9918a&amp;amp;chksm=ec6e7d2edb19f4380ad51905c66bc4c1a2f2ddf792d36fac1c6803204701613d305ad9932039&amp;amp;token=1812131085&amp;amp;lang=zh_CN#rd&quot; class=&quot;uri&quot;&gt;https://mp.weixin.qq.com/s?__biz=MzI5MzYzMDAwNw==&amp;amp;mid=2247484534&amp;amp;idx=2&amp;amp;sn=2909d7d1de88d12e90286a9521a9918a&amp;amp;chksm=ec6e7d2edb19f4380ad51905c66bc4c1a2f2ddf792d36fac1c6803204701613d305ad9932039&amp;amp;token=1812131085&amp;amp;lang=zh_CN#rd&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0.16981132075472&quot;&gt;
&lt;p&gt;每天一道剑指offer-包含min函数的栈&lt;br/&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzI5MzYzMDAwNw==&amp;amp;mid=2247484550&amp;amp;idx=2&amp;amp;sn=3bed9f8d59bf6996117423ed830dcc1f&amp;amp;chksm=ec6e7ddedb19f4c88b435989abaeebf745dd803c04e99630928f4a43bfda42ac2183ec20a72b&amp;amp;token=1812131085&amp;amp;lang=zh_CN#rd&quot; class=&quot;uri&quot;&gt;https://mp.weixin.qq.com/s?__biz=MzI5MzYzMDAwNw==&amp;amp;mid=2247484550&amp;amp;idx=2&amp;amp;sn=3bed9f8d59bf6996117423ed830dcc1f&amp;amp;chksm=ec6e7ddedb19f4c88b435989abaeebf745dd803c04e99630928f4a43bfda42ac2183ec20a72b&amp;amp;token=1812131085&amp;amp;lang=zh_CN#rd&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0.18819188191882&quot;&gt;
&lt;p&gt;每天一道剑指offer-栈的压入、弹出序列&lt;br/&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzI5MzYzMDAwNw==&amp;amp;mid=2247484561&amp;amp;idx=2&amp;amp;sn=27aeefcfc17e2829722ee298cc96b0d7&amp;amp;chksm=ec6e7dc9db19f4df87948f9fdf04fcee9681582ee83f0c8d5dbb228ec31546eaf335a6e9125f&amp;amp;token=1812131085&amp;amp;lang=zh_CN#rd&quot; class=&quot;uri&quot;&gt;https://mp.weixin.qq.com/s?__biz=MzI5MzYzMDAwNw==&amp;amp;mid=2247484561&amp;amp;idx=2&amp;amp;sn=27aeefcfc17e2829722ee298cc96b0d7&amp;amp;chksm=ec6e7dc9db19f4df87948f9fdf04fcee9681582ee83f0c8d5dbb228ec31546eaf335a6e9125f&amp;amp;token=1812131085&amp;amp;lang=zh_CN#rd&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0.18819188191882&quot;&gt;
&lt;p&gt;每天一道剑指offer-从上往下打印二叉树&lt;br/&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzI5MzYzMDAwNw==&amp;amp;mid=2247484625&amp;amp;idx=2&amp;amp;sn=7fb0343fee005be8ce7b9879ba7c891b&amp;amp;chksm=ec6e7d89db19f49fbeb8933b9c95f225b5b14fdc95285c7d3a6e110fed702691b9abc9936db9&amp;amp;token=1812131085&amp;amp;lang=zh_CN#rd&quot; class=&quot;uri&quot;&gt;https://mp.weixin.qq.com/s?__biz=MzI5MzYzMDAwNw==&amp;amp;mid=2247484625&amp;amp;idx=2&amp;amp;sn=7fb0343fee005be8ce7b9879ba7c891b&amp;amp;chksm=ec6e7d89db19f49fbeb8933b9c95f225b5b14fdc95285c7d3a6e110fed702691b9abc9936db9&amp;amp;token=1812131085&amp;amp;lang=zh_CN#rd&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0.21428571428571&quot;&gt;
&lt;p&gt;每天一道剑指offer-二叉搜索树的后序遍历序列&lt;br/&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzI5MzYzMDAwNw==&amp;amp;mid=2247484646&amp;amp;idx=3&amp;amp;sn=d6fd39a4cc7b7180e8014ad70ea1b21b&amp;amp;chksm=ec6e7dbedb19f4a8104428a654b884d966ec37a3c55a58848e0efa578f3dad3017974aad6483&amp;amp;token=1812131085&amp;amp;lang=zh_CN#rd&quot; class=&quot;uri&quot;&gt;https://mp.weixin.qq.com/s?__biz=MzI5MzYzMDAwNw==&amp;amp;mid=2247484646&amp;amp;idx=3&amp;amp;sn=d6fd39a4cc7b7180e8014ad70ea1b21b&amp;amp;chksm=ec6e7dbedb19f4a8104428a654b884d966ec37a3c55a58848e0efa578f3dad3017974aad6483&amp;amp;token=1812131085&amp;amp;lang=zh_CN#rd&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0.21428571428571&quot;&gt;
&lt;p&gt;每天一道剑指offer-二叉树中和为某一值的路径&lt;br/&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzI5MzYzMDAwNw==&amp;amp;mid=2247484663&amp;amp;idx=2&amp;amp;sn=56e65d5dab55831c42df7b0efbae3d01&amp;amp;chksm=ec6e7dafdb19f4b95a4c7affe969086a9606498c8ae33516c54384931cc3b9a9a2724e39b05f&amp;amp;token=1812131085&amp;amp;lang=zh_CN#rd&quot; class=&quot;uri&quot;&gt;https://mp.weixin.qq.com/s?__biz=MzI5MzYzMDAwNw==&amp;amp;mid=2247484663&amp;amp;idx=2&amp;amp;sn=56e65d5dab55831c42df7b0efbae3d01&amp;amp;chksm=ec6e7dafdb19f4b95a4c7affe969086a9606498c8ae33516c54384931cc3b9a9a2724e39b05f&amp;amp;token=1812131085&amp;amp;lang=zh_CN#rd&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;每天一道剑指offer-复杂链表的复制&lt;br/&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=Mzg4MDA3NTM2OQ%3D%3D&amp;amp;mid=2247483717&amp;amp;idx=1&amp;amp;sn=0afe107399dc99c8a22dd5cb0d5137df&amp;amp;scene=45#wechat_redirect&quot;&gt;https://mp.weixin.qq.com/s?__biz=Mzg4MDA3NTM2OQ%3D%3D&amp;amp;mid=2247483717&amp;amp;idx=1&amp;amp;sn=0afe107399dc99c8a22dd5cb0d5137df&amp;amp;scene=45#wechat_redirect&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0.1970802919708&quot;&gt;
&lt;p&gt;每天一道剑指offer-二叉搜索树与双向链表&lt;br/&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzI5MzYzMDAwNw==&amp;amp;mid=2247484676&amp;amp;idx=2&amp;amp;sn=dcf484b32398103580afcc642ceb3376&amp;amp;chksm=ec6e7c5cdb19f54a32a5f31c6e375758dbcaa0980ea48af2a1b9a65e5374efcc810e0c27eaf4&amp;amp;token=1812131085&amp;amp;lang=zh_CN#rd&quot; class=&quot;uri&quot;&gt;https://mp.weixin.qq.com/s?__biz=MzI5MzYzMDAwNw==&amp;amp;mid=2247484676&amp;amp;idx=2&amp;amp;sn=dcf484b32398103580afcc642ceb3376&amp;amp;chksm=ec6e7c5cdb19f54a32a5f31c6e375758dbcaa0980ea48af2a1b9a65e5374efcc810e0c27eaf4&amp;amp;token=1812131085&amp;amp;lang=zh_CN#rd&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0.16030534351145&quot;&gt;
&lt;p&gt;每天一道剑指offer-字符串的排列&lt;br/&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzI5MzYzMDAwNw==&amp;amp;mid=2247484748&amp;amp;idx=2&amp;amp;sn=4dd588af707d7a598206b090083f9a18&amp;amp;chksm=ec6e7c14db19f502489081a1aa1be260e288af7ef3f4c7dc6fddab1186cd34d0a93d750993bc&amp;amp;token=1812131085&amp;amp;lang=zh_CN#rd&quot; class=&quot;uri&quot;&gt;https://mp.weixin.qq.com/s?__biz=MzI5MzYzMDAwNw==&amp;amp;mid=2247484748&amp;amp;idx=2&amp;amp;sn=4dd588af707d7a598206b090083f9a18&amp;amp;chksm=ec6e7c14db19f502489081a1aa1be260e288af7ef3f4c7dc6fddab1186cd34d0a93d750993bc&amp;amp;token=1812131085&amp;amp;lang=zh_CN#rd&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0.23076923076923&quot;&gt;
&lt;p&gt;每天一道剑指offer-数组中出现次数超过一半的数字&lt;br/&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzI5MzYzMDAwNw==&amp;amp;mid=2247484690&amp;amp;idx=2&amp;amp;sn=39fde3af3fcb1f1e45be382063d85422&amp;amp;chksm=ec6e7c4adb19f55ce44772b7dde58ba4b7f4fd285ffdca84140499bd0b6e13bc774f99ac239d&amp;amp;token=1812131085&amp;amp;lang=zh_CN#rd&quot; class=&quot;uri&quot;&gt;https://mp.weixin.qq.com/s?__biz=MzI5MzYzMDAwNw==&amp;amp;mid=2247484690&amp;amp;idx=2&amp;amp;sn=39fde3af3fcb1f1e45be382063d85422&amp;amp;chksm=ec6e7c4adb19f55ce44772b7dde58ba4b7f4fd285ffdca84140499bd0b6e13bc774f99ac239d&amp;amp;token=1812131085&amp;amp;lang=zh_CN#rd&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0.15384615384615&quot;&gt;
&lt;p&gt;每天一道剑指offer-最小的K个数&lt;br/&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzI5MzYzMDAwNw==&amp;amp;mid=2247484700&amp;amp;idx=2&amp;amp;sn=f569859fab0b8919f5bbe6597db470a2&amp;amp;chksm=ec6e7c44db19f5529a7e5eaf8135f1b0b87852981767bdb19a43ae29262839970ac1b2c43cc7&amp;amp;token=1812131085&amp;amp;lang=zh_CN#rd&quot; class=&quot;uri&quot;&gt;https://mp.weixin.qq.com/s?__biz=MzI5MzYzMDAwNw==&amp;amp;mid=2247484700&amp;amp;idx=2&amp;amp;sn=f569859fab0b8919f5bbe6597db470a2&amp;amp;chksm=ec6e7c44db19f5529a7e5eaf8135f1b0b87852981767bdb19a43ae29262839970ac1b2c43cc7&amp;amp;token=1812131085&amp;amp;lang=zh_CN#rd&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0.18819188191882&quot;&gt;
&lt;p&gt;每天一道剑指offer-连续子数组的最大和&lt;br/&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzI5MzYzMDAwNw==&amp;amp;mid=2247484742&amp;amp;idx=2&amp;amp;sn=f92f21b4fd89e1fda7467590045c8dd3&amp;amp;chksm=ec6e7c1edb19f508d5454cf92e259c087ae2c93ec9e4ad0432317dff85d413aa72bdefae4ac3&amp;amp;token=1812131085&amp;amp;lang=zh_CN#rd&quot; class=&quot;uri&quot;&gt;https://mp.weixin.qq.com/s?__biz=MzI5MzYzMDAwNw==&amp;amp;mid=2247484742&amp;amp;idx=2&amp;amp;sn=f92f21b4fd89e1fda7467590045c8dd3&amp;amp;chksm=ec6e7c1edb19f508d5454cf92e259c087ae2c93ec9e4ad0432317dff85d413aa72bdefae4ac3&amp;amp;token=1812131085&amp;amp;lang=zh_CN#rd&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;每天一道剑指offer-整数中1出现的次数&lt;/p&gt;
&lt;/li&gt;
</description>
<pubDate>Fri, 22 Feb 2019 15:24:00 +0000</pubDate>
<dc:creator>程序员乔戈里</dc:creator>
<og:description>经过数月的努力，终于更完了牛客网的66道剑指offer，以下的顺序和大家在牛客网的顺序是一样的（排序也花了不少时间），希望对大家找工作/提高算法能力能起到些许帮助。 每天一道剑指offer 二维数组中</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/qiaogeli/p/10421278.html</dc:identifier>
</item>
<item>
<title>使用 FFT 分析周期性数据 - MATLAB基于模型的设计</title>
<link>http://www.cnblogs.com/52geek/p/10421208.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/52geek/p/10421208.html</guid>
<description>&lt;p class=&quot;shortdesc&quot;&gt;可以使用傅里叶变换来分析数据中的变化，例如一个时间段内的自然事件。&lt;/p&gt;
&lt;p&gt;天文学家使用苏黎世太阳黑子相对数将几乎 300 年的太阳黑子的数量和大小制成表格。对大约 1700 至 2000 年间的苏黎世数绘图。&lt;/p&gt;
&lt;div class=&quot;code_responsive&quot;&gt;
&lt;div class=&quot;programlisting&quot; readability=&quot;8&quot;&gt;
&lt;div class=&quot;codeinput&quot; readability=&quot;11&quot;&gt;
&lt;pre&gt;
load sunspot.dat
year = sunspot(:,1);
relNums = sunspot(:,2);
plot(year,relNums)
xlabel('Year')
ylabel('Zurich Number')
title('Sunspot Data')
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;为了更详细地看太阳黑子活动的周期特性，将对前 50 年的数据绘图。&lt;/p&gt;
&lt;div class=&quot;code_responsive&quot;&gt;
&lt;div class=&quot;programlisting&quot; readability=&quot;7&quot;&gt;
&lt;div class=&quot;codeinput&quot; readability=&quot;9&quot;&gt;
&lt;pre&gt;
plot(year(1:50),relNums(1:50),'b.-');
xlabel('Year')
ylabel('Zurich Number')
title('Sunspot Data')
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;傅里叶变换是一种基础的信号处理工具，可确定数据中的频率分量。使用 &lt;code class=&quot;literal&quot;&gt;fft&lt;/code&gt; 函数可获取苏黎世数据的傅里叶变换。删除存储数据总和的输出的第一个元素。绘制该输出的其余部分，其中包含复傅里叶系数关于实轴的镜像图像。&lt;/p&gt;
&lt;div class=&quot;code_responsive&quot;&gt;
&lt;div class=&quot;programlisting&quot; readability=&quot;7&quot;&gt;
&lt;div class=&quot;codeinput&quot; readability=&quot;9&quot;&gt;
&lt;pre&gt;
y = fft(relNums);
y(1) = [];
plot(y,'ro')
xlabel('real(y)')
ylabel('imag(y)')
title('Fourier Coefficients')
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;单独的傅里叶系数难以解释。计算系数更有意义的方法是计算其平方幅值，即计算幂。由于一半的系数在幅值中是重复的，因此您只需要对一半的系数计算幂。以频率函数的形式绘制功率频谱图，以每年的周期数为测量单位。&lt;/p&gt;
&lt;div class=&quot;code_responsive&quot;&gt;
&lt;div class=&quot;programlisting&quot; readability=&quot;7.5&quot;&gt;
&lt;div class=&quot;codeinput&quot; readability=&quot;10&quot;&gt;
&lt;pre&gt;
n = length(y);
power = abs(y(1:floor(n/2))).^2; % power of first half of transform data
maxfreq = 1/2;                   % maximum frequency
freq = (1:n/2)/(n/2)*maxfreq;    % equally spaced frequency grid
plot(freq,power)
xlabel('Cycles/Year')
ylabel('Power')
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;太阳黑子活动发生的最大频率低于每年一次。为了查看更易解释的周期活动，以周期函数形式绘制幂图，以每周期的年数为测量单位。该绘图揭示了太阳黑子活动约每 11 年出现一次高峰。&lt;/p&gt;
&lt;div class=&quot;code_responsive&quot;&gt;
&lt;div class=&quot;programlisting&quot; readability=&quot;7&quot;&gt;
&lt;div class=&quot;codeinput&quot; readability=&quot;9&quot;&gt;
&lt;pre&gt;
period = 1./freq;
plot(period,power);
xlim([0 50]); %zoom in on max power
xlabel('Years/Cycle')
ylabel('Power')
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

</description>
<pubDate>Fri, 22 Feb 2019 15:00:00 +0000</pubDate>
<dc:creator>MATLAB基于模型的设计</dc:creator>
<og:description>可以使用傅里叶变换来分析数据中的变化，例如一个时间段内的自然事件。 天文学家使用苏黎世太阳黑子相对数将几乎 300 年的太阳黑子的数量和大小制成表格。对大约 1700 至 2000 年间的苏黎世数绘图</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/52geek/p/10421208.html</dc:identifier>
</item>
<item>
<title>Perl多线程(1)：解释器线程的特性 - 骏马金龙</title>
<link>http://www.cnblogs.com/f-ck-need-u/p/10420910.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/f-ck-need-u/p/10420910.html</guid>
<description>&lt;p&gt;本文关于Perl线程的内容初始主要来自于《Pro Perl》的第21章，未来可能会逐渐添加、完善更多内容，当然也可能分离一部分内容单独成文。&lt;/p&gt;
&lt;h2 id=&quot;线程简介&quot;&gt;线程简介&lt;/h2&gt;
&lt;p&gt;线程(thread)是轻量级进程，和进程一样，都能独立、并行运行，也由父线程创建，并由父线程所拥有，线程也有线程ID作为线程的唯一标识符，也需要等待线程执行完毕后收集它们的退出状态(比如使用&lt;code&gt;join&lt;/code&gt;收尸)，就像waitpid对待子进程一样。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;线程运行在进程内部，每个进程都至少有一个线程，即main线程，它在进程创建之后就存在。线程非常轻量级，一个进程中可以有很多个线程，它们全都在进程内部并行地被调度、运行，就像多进程一样。每个线程都共享了进程的很多数据，除了线程自己所需要的数据，它们都直接使用父进程的，比如同一个线程解释器、同一段代码、同一段要处理的数据等&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;于是，现在开始从多进程编程转入到多线程编程。&lt;/p&gt;
&lt;h2 id=&quot;perl自己的线程&quot;&gt;Perl自己的线程&lt;/h2&gt;
&lt;p&gt;有些系统不原生支持线程模型(如某些Unix系统)，在Perl 5.8中，Perl提供了属于自己的线程模型：&lt;strong&gt;解释器线程(interpreter thread, ithreads)&lt;/strong&gt;。当然，Perl也依旧支持老线程。&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;code&gt;Thread&lt;/code&gt;模块提供老式线程&lt;br/&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;threads&lt;/code&gt;模块提供Perl解释器线程&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;可以通过以下代码来检测操作系统是否支持老式线程、解释器线程。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;#!/usr/bin/perl

BEGIN{
    use Config;
    if ($Config{usethreads}) {print &quot;support old thread\n&quot;;}
    if ($Config{useithreads}) {print &quot;support interpreter threads\n&quot;;}
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;或者简单的使用perldoc来检查这两个模块是否存在，一般来说安装Perl的时候就会自动安装它们：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;$ perldoc Thread
$ perldoc threads&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;threads&lt;/code&gt;模块提供的是面向对象的解释器线程，可以直接使用&lt;code&gt;new&lt;/code&gt;方法来创建一个线程，使用其它方法来维护线程。默认情况下，&lt;strong&gt;Perl解释器线程不会在线程之间共享数据和状态信息(也就是说数据是线程本地的)&lt;/strong&gt;，如果想要共享，可以使用&lt;code&gt;threads::shared&lt;/code&gt;。而老式线程模块&lt;code&gt;Thread&lt;/code&gt;的线程默认是自动在线程间共享数据的，且于解释器线程相互隔离，在编写复杂程序时这可能会很复杂。&lt;/p&gt;
&lt;p&gt;实际上，&lt;strong&gt;在Perl的解释器线程被创建的时候，会将父线程中所有的变量都拷贝到自己的空间中使之成为私有变量&lt;/strong&gt;，这样各线程之间就互相隔离了，并且自动实现了线程安全。如果想要在同进程的不同线程之间共享数据，需要专门使用&lt;code&gt;threads::shared&lt;/code&gt;模块将变量共享出去，这样每个线程都能访问到这个变量。&lt;/p&gt;
&lt;p&gt;解释器线程这样的行为对编写多线程来说非常的友好，但是这会影响Perl的线程性能，特别是父线程中数据量较大的时候，创建线程的成本以及内存占用上是非常昂贵的。所以，在使用Perl解释器线程的时候，应当尽量在数据量还小的时候创建子线程。&lt;/p&gt;
&lt;h2 id=&quot;创建线程&quot;&gt;创建线程&lt;/h2&gt;
&lt;p&gt;Perl线程在很多方面都像fork出来的进程一样，但是在创建线程上，它更像是一个子程序。&lt;/p&gt;
&lt;p&gt;创建线程的方式有两种：create/new、async，create和new是等价的别名，这3种(实际上是两种)创建线程的方式除了语法上不同，在线程执行上是完全一致的。&lt;/p&gt;
&lt;p&gt;创建线程的标准方法是使用&lt;code&gt;create&lt;/code&gt;或&lt;code&gt;new&lt;/code&gt;方法（它们是等价的别名），并且给它一个&lt;strong&gt;子程序或子程序引用或匿名子程序&lt;/strong&gt;，这表示创建一个新线程去运行这个子程序。&lt;/p&gt;
&lt;p&gt;例如：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;use threads;

my $thr = threads-&amp;gt;create(\&amp;amp;sub1);

sub sub1 {
    print(&quot;In Child Thread\n&quot;);
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;这里main线程创建了子线程运行sub1子程序，创建完成后，main线程继续向下运行。&lt;/p&gt;
&lt;p&gt;如果子程序要传递参数，直接在create/new的参数位上传递即可。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;use threads;

sub threadsub {
    my $self = threads-&amp;gt;self;
}

my $thr1 = threads-&amp;gt;create(\&amp;amp;threadsub, 'arg1', 'arg2');
# 或者使用new
my $thr2 = threads-&amp;gt;new(\&amp;amp;threadsub, @args);&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;如果使用async创建线程，那么给async一个语句块，就像匿名子程序一样。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;use threads;

my $thr = async {
    ... some code ...
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;这表示新建一个子线程来运行代码块中的代码。&lt;/p&gt;
&lt;p&gt;至于选择create/new还是选择async来创建新线程，随意。但是如果创建多个线程的话，使用create/new比较方便。而且，create/new也一样能创建新线程执行匿名子程序。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;my $thr1 = new threads \&amp;amp;threadsub, $arg1;
my $thr2 = new threads \&amp;amp;threadsub, $arg2;
my $thr3 = new threads \&amp;amp;threadsub, $arg3;

# create执行匿名子程序
my $thr = threads-&amp;gt;create( sub {...} );&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;线程标识&quot;&gt;线程标识&lt;/h2&gt;
&lt;p&gt;由于我们可能会创建很多个线程，我们需要区分它们。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;第一种方式是通过给不同线程的子程序传递不同参数的方式来区分不同的线程&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;例如：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;my $thr1 = threads-&amp;gt;create(\&amp;amp;mysub,&quot;first&quot;);
my $thr1 = threads-&amp;gt;create(\&amp;amp;mysub,&quot;second&quot;);
my $thr1 = threads-&amp;gt;create(\&amp;amp;mysub,&quot;third&quot;);

sub mysub {
    my $thr_num = shift @_;
    print &quot;I am thread $thr_num\n&quot;;
    ...
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;第二种方式是获取threads模块中的线程对象，线程对象中包含了线程的id属性&lt;/strong&gt;。通过类方法&lt;code&gt;threads-&amp;gt;self()&lt;/code&gt;可以获取当前线程对象，有了线程对象，可以通过tid()对象方法获取这个线程对象的ID，当然还可以直接使用类方法&lt;code&gt;threads-&amp;gt;tid()&lt;/code&gt;来获取当前线程对象的ID。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;my $myself = threads-&amp;gt;self;
my $mytid = $myself-&amp;gt;tid();

# 或
my $mytid = threads-&amp;gt;tid();&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;对于已知道tid的线程，可以使用类方法&lt;code&gt;threads-&amp;gt;object($tid)&lt;/code&gt;去获取这个tid的线程对象。注意，object()只能获取正激活的线程对象，对于joined和detached线程(join和detach见下文)，都返回undef，不仅如此，对于无法收集的线程对象，object()都返回undef，例如收集&lt;code&gt;$tid&lt;/code&gt;不存在的线程。&lt;/p&gt;
&lt;p&gt;线程对象的ID是从0开始计算的，然后每新建一个子线程，ID就加1.0号线程就是每个进程创建时的main线程，main线程再创建一个新子线程，这个新子线程的ID就是1。&lt;/p&gt;
&lt;p&gt;可以比较两个线程是否是同一个线程，使用equal()方法（或者重载的&lt;code&gt;==&lt;/code&gt;和&lt;code&gt;!=&lt;/code&gt;符号）即可，它们都基于线程ID进行比较：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;print &quot;Equal\n&quot; if $self-&amp;gt;equal($thr);
print &quot;Equal\n&quot; if $self == $thr;&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;线程状态和joindetach&quot;&gt;线程状态和join、detach&lt;/h2&gt;
&lt;p&gt;Perl中的线程实际上是一个子程序代码块，它可能会有子程序的返回值，所以父线程需要接收子线程的返回值。不仅如此，就像父进程需要使用wait/waitpid等待子进程并为退出的子进程收尸一样，父线程也需要等待子线程退出并为子线程收尸(做最后的清理工作)。为线程收尸是很重要的，如果只创建了几个运行时间短的子线程，那么操作系统可能会自动为子线程收尸，但创建了一大堆的子线程，操作系统可能不会给我们什么帮助，我们要自己去收尸。&lt;/p&gt;
&lt;p&gt;join()方法的功能就像waitpid一样，&lt;strong&gt;当父线程中将子线程join()后，表示将子线程从父线程管理的一个线程表中加入到父线程监控的另一个列表中（实际上并非如此，只是修改了进程的状态而已，稍后解释），这个列表中的所有线程是该父线程都需要等待的。所以，将join()方法的&quot;加入&quot;含义看作是加入到了父线程的某个监控列表中即可&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;join()做三件事：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;等待子线程退出，等待过程中父线程一直阻塞&lt;/strong&gt;&lt;br/&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;子线程退出后，为子线程收尸(OS clean up)&lt;/strong&gt;&lt;br/&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;如果子线程有返回值，则收集返回值&lt;/strong&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;而返回值是有上下文的，根据标量(scalar)、列表(list)、空(void)上下文，应该在合理的上下文中使用返回值&lt;/strong&gt;&lt;br/&gt;&lt;/li&gt;
&lt;li&gt;线程上下文相关，稍后解释&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;例如：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;use threads;

my ($thr) = threads-&amp;gt;create(\&amp;amp;sub1);

# join，父进程等待、收尸、收集返回值
my @returnData = $thr-&amp;gt;join();

print 'thread returned: ', join('@', @returnData), &quot;\n&quot;;

sub sub1 {
    # 返回值是列表
    return ('fifty-six', 'foo', 2);
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;join的三件事中，&lt;strong&gt;如果不想要等待子线程执行完毕，可以使用detach()，它将子线程脱离父线程，父线程不再阻塞等待。因为已经脱离，父线程也将不再为子线程收尸(子线程在执行完毕的时候自己收尸)，父线程也无法收集子线程的返回值导致子线程的返回值被丢弃&lt;/strong&gt;。当然，父子关系还在，只不过当父线程退出时，子线程会继续运行，这时才会摆脱父线程成为孤儿线程，这就像daemon进程(自己成立进程组)和父进程一样。&lt;/p&gt;
&lt;p&gt;刚才使用&quot;父线程监控的另一个列表&quot;来解释join的行为，这是不准确的。实际上，线程有6种状态(这些状态稍后还会解释)：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;detached(和joined是互斥的状态)&lt;br/&gt;&lt;/li&gt;
&lt;li&gt;joined(和detached是互斥的状态)&lt;br/&gt;&lt;/li&gt;
&lt;li&gt;finished execution(执行完但还没有返回，还没退出)，其实是running状态刚结束，可以被join的阶段(joinable)&lt;br/&gt;&lt;/li&gt;
&lt;li&gt;exit&lt;br/&gt;&lt;/li&gt;
&lt;li&gt;died&lt;br/&gt;&lt;/li&gt;
&lt;li&gt;creation failed&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;当执行detach()后，线程的状态就变成detached，当执行join()后，线程的状态就变成joined。detached线程可以看作是粗略地看作是脱离了父线程，它无法join，父线程也不会对其有等待、收尸、收集返回值行为，只有进程退出时detached线程才默默被终止(detached状态的线程也依然是线程，是进程的内部调度单元，进程终止，线程都将终止)&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;例如：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;use threads;

sub mysub {
    #alarm 10;
    for (1..10){
        print &quot;I am detached thread\n&quot;;
        sleep 1;
    }
}

my $thr1 = threads-&amp;gt;new(\&amp;amp;mysub)-&amp;gt;detach();

print &quot;main thread will exit in 2 seconds\n&quot;;
sleep 2;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;上面的子线程会被detach，父线程继续运行，在2秒后进程终止，detach后的子线程会被默默终止。&lt;/p&gt;
&lt;p&gt;更细分一点，一个线程正常执行子程序到结束可以划分为几个过程：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;1.线程入口，开始执行子程序。执行子程序的阶段称为running状态&lt;br/&gt;&lt;/li&gt;
&lt;li&gt;2.&lt;strong&gt;子程序执行完毕，但还没有返回，这个时候是running刚结束状态，也是前文提到的finished execution状态&lt;/strong&gt;
&lt;ul&gt;&lt;li&gt;如果这个线程未被detach，&lt;strong&gt;从这个状态开始，这个线程可以被join(除非是detached线程)，也就是joinable状态，父线程在这个阶段不再阻塞&lt;/strong&gt;&lt;br/&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;3.线程执行完毕
&lt;ul&gt;&lt;li&gt;如果这个线程被join，则父线程对该线程收尸并收集该线程的返回值&lt;br/&gt;&lt;/li&gt;
&lt;li&gt;如果这个线程被detach，则这个线程自己收尸并退出&lt;br/&gt;&lt;/li&gt;
&lt;li&gt;如果这个线程未join也未detach，则父线程不会收尸，并且在进程退出时报告相关消息&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;所以从另一种分类角度上看，&lt;strong&gt;线程可以分为：active、joined、detached三种状态&lt;/strong&gt;。其中detached线程已被脱离，所以不算是active线程，joined已经表示线程的子程序已经执行完毕了，也不算是active线程，只有unjoined、undetached线程才算是active线程，active包括running、joinable这两个过程。&lt;/p&gt;
&lt;p&gt;整个线程的状态和过程可以参考下图：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/733013/201902/733013-20190222140407479-1076540038.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;上面一直忽略了一种情况，线程在join之前就已经运行完毕了。例如：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;my $thr1 = threads-&amp;gt;create(\&amp;amp;sub1);

# 父线程睡5秒，给子线程5秒的执行时间
sleep 5;
$thr1-&amp;gt;join();&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;子线程先执行完毕，但是父线程还没对它进行join，这时子线程一直处于joinable的状态，其实这个时候子线程基本已经失去意义了，它的返回值和相关信息都保存在线程栈(或调用栈call stack)，当父线程对其进行join()的时候，自然能从线程栈中找到返回值或某些信息的栈地址从而取得相关数据，也能从现在开始对其进行收尸行为。&lt;/p&gt;
&lt;p&gt;实际上，解释器线程是一个双端链表结构，每个线程节点记录了自己的属性，包括自己的状态。而main线程中则包含了所有子线程的一些统计信息：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;typedef struct {
    /* Structure for 'main' thread
     * Also forms the 'base' for the doubly-linked list of threads */
    ithread main_thread;
 
    /* Protects the creation and destruction of threads*/
    perl_mutex create_destruct_mutex;
 
    UV tid_counter;        # tid计数器，可知道当前已经创建了几个线程
    IV joinable_threads;   # 可join的线程
    IV running_threads;    # 正在运行的线程
    IV detached_threads;   # detached状态的线程
    IV total_threads;      # 总线程数
    IV default_stack_size; # 线程的默认栈空间大小
    IV page_size;
} my_pool_t;&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;检查线程的状态&quot;&gt;检查线程的状态&lt;/h3&gt;
&lt;p&gt;使用&lt;code&gt;threads-&amp;gt;list()&lt;/code&gt;方法可以列出未detach的线程，列表上下文下返回这些线程列表，标量上下文下返回数量。它有4种形式：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;threads-&amp;gt;list()  # 返回non-detach、non-joined线程
threads-&amp;gt;list(threads::all)  # 同上
threads-&amp;gt;list(threads::running)  # non-detached、non-joined的线程对象，即正在运行的线程
threads-&amp;gt;list(threads::joinable)  # non-detached、non-joined但joinable的线程对象，即已完成子程序执行但未返回的线程&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;所以，list()只能统计未detach、未join的线程，&lt;code&gt;::running&lt;/code&gt;返回的是正在运行子程序主体的线程，&lt;code&gt;::joinable&lt;/code&gt;返回的是已完成子程序主体的线程，&lt;code&gt;::all&lt;/code&gt;返回的是它们之和。&lt;/p&gt;
&lt;p&gt;此外，我们还可以直接去测试线程的状态：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;$thr-&amp;gt;is_running()
如果该线程正在运行，则返回true

$thr-&amp;gt;is_joinable()
如果该线程已经完成了子程序的主体(即running刚结束)，且未detach未join，换句话说，这个线程是joinable，于是返回true

$thr-&amp;gt;is_detached()
threads-&amp;gt;is_detached()
测试该线程或线程自身是否已经detach&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;线程的上下文环境&quot;&gt;线程的上下文环境&lt;/h2&gt;
&lt;p&gt;因为解释器线程实际上是一个运行的子程序，而父线程可能需要收集子线程的返回值(join()的行为)，而返回值在不同上下文中有不同的行为。&lt;/p&gt;
&lt;p&gt;仍以前面的示例来解释：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;use threads;

# my(xxx)：列表上下文
# my xxx：标量上下文
my ($thr) = threads-&amp;gt;create(\&amp;amp;sub1);

# join，父进程等待、收尸、收集返回值
# @arr：列表上下文
my @returnData = $thr-&amp;gt;join();

print 'thread returned: ', join('@', @returnData), &quot;\n&quot;;

sub sub1 {
    # 返回值是列表
    return ('fifty-six', 'foo', 2);
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;上面的创建子线程后，父线程将这个子线程join()时一直阻塞，直到子线程运行完毕，父线程将子线程的返回值收集到数组&lt;code&gt;@returnData&lt;/code&gt;中。因为子程序的返回值是一个列表，所以这里join的上下文是列表上下文。&lt;/p&gt;
&lt;p&gt;其实，&lt;strong&gt;子线程的上下文是在被创建出来的时候决定的&lt;/strong&gt;，这样子程序中可以出现wantarray()。所以，&lt;strong&gt;在线程被创建时、在join时上下文都要指定：前者决定线程入口(即子程序)执行时所处何种上下文，后者决定子程序返回值环境&lt;/strong&gt;。这两个地方的上下文不一定要一样，例如创建线程的时候在标量上下文环境下，表示子程序在标量上下文中执行，而join的时候可以放在空上下文表示丢弃子程序的返回值。&lt;/p&gt;
&lt;p&gt;允许三种上下文：标量上下文、列表上下文、空上下文。&lt;/p&gt;
&lt;p&gt;对于join时的上下文没什么好解释的，根据上下文环境将返回值进行赋值而已。但是创建线程时的上下文环境需要解释。有显式和隐式两种方式来指定创建线程时的上下文。&lt;/p&gt;
&lt;p&gt;隐式上下文自然是通过所处上下文环境来暗示。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;# 列表上下文创建线程
my ($thr) = threads-&amp;gt;create(...);

# 标量上下文创建线程
my $thr = threads-&amp;gt;create(...);

# 空上下文创建线程
threads-&amp;gt;create(...);&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;显式上下文是在create/new创建线程的时候，在第一个参数位置上指定通过一个hash引用来指定上下文环境。也有两种方式：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;# 列表上下文创建线程
my $thr = threads-&amp;gt;create({ 'context' =&amp;gt; 'list' }, \&amp;amp;sub1)
my $thr = threads-&amp;gt;create({ 'list' =&amp;gt; 1 }, \&amp;amp;sub1)

# 标量上下文创建线程
my $thr = threads-&amp;gt;create({ 'context' =&amp;gt; 'scalar' }, \&amp;amp;sub1)
my $thr = threads-&amp;gt;create({ 'scalar' =&amp;gt; 1 }, \&amp;amp;sub1)

# 空上下文创建线程
my $thr = threads-&amp;gt;create({ 'context' =&amp;gt; 'void' }, \&amp;amp;sub1)
my $thr = threads-&amp;gt;create({ 'void' =&amp;gt; 1 }, \&amp;amp;sub1)&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;线程的退出&quot;&gt;线程的退出&lt;/h2&gt;
&lt;p&gt;正常情况并且大多情况下，线程都应该通过子程序return的方式退出线程。但是也有其它可能。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;threads-&amp;gt;exit()
线程自身可以调用threads-&amp;gt;exit()以便在任何时间点退出。这会使得线程在标量上下文返回undef，在列表上下文返回空列表。如果是在main线程中调用`threads-&amp;gt;exit()`，则等价于exit(0)

threads-&amp;gt;exit(status)
在线程中调用时，等价于threads-&amp;gt;exit()，退出状态码status会被忽略。在main线程中调用时，等价于exit(status)

die()
直接调用die函数会让线程直接退出，如果设置了 $SIG{__DIE__} 的信号处理机制，则调用该处理方法，像一般情况下的die一样

exit(status)
在线程内部调用exit()函数会导致整个程序终止(进程中断)，所以不建议在线程内部调用exit()。但是可以改变exit()终止整个程序的行为，见下面几个设置

use threads 'exit'=&amp;gt;'threads_only'
全局设置，使得在线程内部调用exit()时不会导致整个程序终止，而是只让线程终止。由于这是全局设置，所以不是很建议设置。另外，该设置对main线程无效

threads-&amp;gt;create({'exit'=&amp;gt;'thread_only},\&amp;amp;sub1)
在创建线程的时候，就设置该线程中的exit()只退出当前线程

$thr-&amp;gt;set_thread_exit_only(bool)
修改当前线程中的exit()效果。如果给了true值，则线程内部调用exit()将只退出该线程，给false值，则终止整个程序。对main线程无效

threads-&amp;gt;set_thread_exit_only(bool)
类方法，给true值表示当前线程中的exit()只退出当前线程。对main线程无效&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;最可能需要的退出方式是&lt;code&gt;threads-&amp;gt;exit()&lt;/code&gt;或&lt;code&gt;threads-&amp;gt;exit(status)&lt;/code&gt;，如果对于线程中严重错误的问题，则可能需要的是die或exit()来终止整个程序。&lt;/p&gt;
&lt;h2 id=&quot;线程的信号处理&quot;&gt;线程的信号处理&lt;/h2&gt;
&lt;p&gt;在threads定义的解释器线程中，可以在线程内部定义信号处理器(signal handler)，并通过&lt;code&gt;$thr-&amp;gt;kill(SIGNAME)&lt;/code&gt;的方式发送信号(对于某些自动触发的信号处理，稍后解释)，&lt;code&gt;kill&lt;/code&gt;方法会返回线程对象以便进行链式调用方法。&lt;/p&gt;
&lt;p&gt;例如，在main线程中发送SIGKILL信号，并在线程内部处理这个信号。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;use threads;

sub thr_func {
    # Thread signal handler for SIGKILL
    $SIG{KILL} = sub { 
        print &quot;Caught Signal: SIGKILL\n&quot;;
        threads-&amp;gt;exit();
    }
    ...
}

my $thr = threads-&amp;gt;create('thr_func');

...

# send SIGKILL to terminate thread, then detach 
# it so that it will clean up automatically
$thr-&amp;gt;kill('KILL')-&amp;gt;detach();&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;其实，&lt;strong&gt;threads对于线程信号的处理方式是模拟的，不是真的从操作系统发送信号(操作系统发送的信号是给进程的，会被main线程捕获)&lt;/strong&gt;。模拟的逻辑也很简单，通过&lt;code&gt;threads-&amp;gt;kill()&lt;/code&gt;发送信号给指定线程，然后通过调用子程序中的&lt;code&gt;%SIG&lt;/code&gt;中的signal handler即可。&lt;/p&gt;
&lt;p&gt;例如上面的示例中，我们想要发送KILL信号，但这个信号不是操作系统发送的，而是模拟了一个KILL信号，表示是要终止线程的执行，于是调用线程中的SIGKILL对应的signal handler，仅此而已。&lt;/p&gt;
&lt;p&gt;但是，有些信号是某些情况下自动触发的，比如在线程中使用一个alarm计时器，在计时结束时它会发送SIGALRM信号给进程，这会使得整个进程都退出，而不仅仅是那个单独的线程，这显然不是我们所期待的结果。&lt;/p&gt;
&lt;p&gt;实际上，&lt;strong&gt;操作系统所发送的信号都会在main线程中被捕获。所以如果想要处理上面的问题，只需在main线程中定义对应操作系统发送的信号的signal handler，并在handler中重新使用&lt;code&gt;threads-&amp;gt;kill()&lt;/code&gt;发送这个信号给指定线程，从而间接实现&quot;信号-&amp;gt;线程&quot;的机制&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;例如，在线程中使用alarm并在计时结束的时候停止该线程。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;use threads qw(yield);

# 带有计时器的线程
my $thr = threads-&amp;gt;create(
    sub {
        threads-&amp;gt;yield();
        eval {
            $SIG{ALRM} = sub {die &quot;Timeout&quot;;};
            alarm 10;
            ... do somework ...
        };
        if ( $@ =~ /Timeout/) {
            warn &quot;thread timeout&quot;;
        }
    }
);

$SIG{ALRM} = sub { $thr-&amp;gt;kill('ALRM') };
... main thread continue ...&lt;/code&gt;
&lt;/pre&gt;</description>
<pubDate>Fri, 22 Feb 2019 14:11:00 +0000</pubDate>
<dc:creator>骏马金龙</dc:creator>
<og:description>本文关于Perl线程的内容初始主要来自于《Pro Perl》的第21章，未来可能会逐渐添加、完善更多内容，当然也可能分离一部分内容单独成文。 线程简介 线程(thread)是轻量级进程，和进程一样，都</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/f-ck-need-u/p/10420910.html</dc:identifier>
</item>
<item>
<title>SLAM+语音机器人DIY系列：（七）语音交互与自然语言处理——1.语音交互相关技术 - 小虎哥哥爱学习</title>
<link>http://www.cnblogs.com/hiram-zhang/p/10420788.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/hiram-zhang/p/10420788.html</guid>
<description>&lt;p&gt;&lt;span&gt;这一章将进入机器人语音交互的学习，让机器人能跟人进行语音对话交流。这是一件很酷的事情，本章将涉及到语音识别、语音合成、自然语言处理方面的知识。本章内容：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.cnblogs.com/hiram-zhang/p/10420788.html&quot; target=&quot;_blank&quot;&gt;&lt;span&gt;1.语音交互相关技术&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.cnblogs.com/hiram-zhang/p/10421162.html&quot; target=&quot;_blank&quot;&gt;&lt;span&gt;2.机器人语音交互实现&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.cnblogs.com/hiram-zhang/p/10421186.html&quot; target=&quot;_blank&quot;&gt;&lt;span&gt;3.自然语言处理云计算引擎&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;
&lt;hr/&gt;&lt;hr/&gt;
&lt;p&gt;&lt;span&gt;要机器人能完成跟人对话，涉及到语音识别、语音合成、自然语言处理等技术。简单点说，语音识别就是将人的声音转换成文字便于机器人计算与理解；语音合成就是将机器人要说的文字内容转换为声音；自然语言处理相当于机器人的大脑，负责回答提问。整个语音交互的过程，如图&lt;/span&gt;1&lt;span&gt;。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1204799/201902/1204799-20190222213741739-886937597.png&quot; alt=&quot;&quot; width=&quot;700&quot;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;&lt;strong&gt;&lt;span&gt;（&lt;/span&gt;&lt;span&gt;图&lt;/span&gt;1&lt;span&gt;）&lt;/span&gt;&lt;span&gt;语音交互过程&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;h2&gt;&lt;span&gt;1.1.&lt;span&gt;语音识别                    &lt;/span&gt;&lt;/span&gt;&lt;/h2&gt;
&lt;p&gt;语音识别技术，也被称为自动语音识别Automatic Speech Recognition(ASR)，其目标是将人类的语音中的词汇内容转换为计算机可读的输入，例如按键、二进制编码或者字符序列，如图2。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1204799/201902/1204799-20190222214004811-1110548389.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;&lt;strong&gt;&lt;span&gt;（&lt;/span&gt;&lt;span&gt;图&lt;/span&gt;2&lt;span&gt;）&lt;/span&gt;&lt;span&gt;语音识别&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;语音识别技术所涉及的领域包括：信号处理、模式识别、概率论和信息论、发声机理和听觉机理、人工智能等等。语音识别技术的最重大突破是隐马尔科夫模型Hidden Markov Model的应用。从Baum提出相关数学推理，经过Labiner等人的研究，卡内基梅隆大学的李开复最终实现了第一个基于隐马尔科夫模型的非特定人大词汇量连续语音识别系统Sphinx。此后严格来说语音识别技术并没有脱离HMM框架。当然神经网络方法是一种新的语音识别方法，人工神经网络本质上是一个自适应非线性动力学系统，模拟了人类神经活动的原理，具有自适应性、并行性、鲁棒性、容错性和学习特性，其强的分类能力和输入-输出映射能力在语音识别中都很有吸引力。但由于存在训练、识别时间太长的缺点，目前仍处于实验探索阶段。&lt;/p&gt;
&lt;h2&gt;&lt;span&gt;1.2.&lt;span&gt;语音合成                    &lt;/span&gt;&lt;/span&gt;&lt;/h2&gt;
&lt;p&gt;&lt;span&gt;语音合成是语音识别的逆过程，也称为文字转语音（&lt;/span&gt;TTS&lt;span&gt;），&lt;/span&gt;&lt;span&gt;它是将计算机自己产生的、或外部输入的文字信息转变为可以听得懂的、流利的汉语&lt;/span&gt;&lt;span&gt;或其他&lt;/span&gt;&lt;span&gt;口语输出的技术。&lt;/span&gt;&lt;span&gt;如图&lt;/span&gt;3&lt;span&gt;。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1204799/201902/1204799-20190222215035400-717488909.png&quot; alt=&quot;&quot;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;&lt;strong&gt;&lt;span&gt;（&lt;/span&gt;&lt;span&gt;图&lt;/span&gt;3&lt;span&gt;）&lt;/span&gt;&lt;span&gt;语音合成&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;TTS&lt;span&gt;过程包括这些步骤：语言处理，&lt;/span&gt;&lt;span&gt;在文语转换系统中起着重要的作用，主要模拟人对自然语言的理解过程&lt;/span&gt;&lt;span&gt;，&lt;/span&gt;&lt;span&gt;文本规整、词的切分、&lt;/span&gt;&lt;span&gt;语法分析&lt;/span&gt;&lt;span&gt;和&lt;/span&gt;&lt;span&gt;语义分析&lt;/span&gt;&lt;span&gt;，使计算机对输入的文本能完全理解，并给出后两部分所需要的各种发音提示&lt;/span&gt;&lt;span&gt;；&lt;/span&gt;&lt;span&gt;韵律处理&lt;/span&gt;&lt;span&gt;，&lt;/span&gt;&lt;span&gt;为合成语音规划出音段特征，如音高、音长和音强等，使合成语音能正确表达语意，听起来更加自然&lt;/span&gt;&lt;span&gt;；&lt;/span&gt;&lt;span&gt;声学处理&lt;/span&gt;&lt;span&gt;，&lt;/span&gt;&lt;span&gt;根据前两部分处理结果的要求输出语音，即合成语音。&lt;/span&gt;&lt;/p&gt;
&lt;h2&gt;&lt;span&gt;1.3.&lt;span&gt;自然语言处理                &lt;br/&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h2&gt;
&lt;p&gt;&lt;span&gt;有了语音识别和语音合成，要让机器人能智能的对答如流的和人交谈，还需要赋予机器人以灵魂。自然语言处理技术（&lt;/span&gt;NLP&lt;span&gt;）就是来赋予聊天机器人内在灵魂的。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;NLP&lt;span&gt;是计算机领域与人工智能领域中的一个重要分支。由于数据的大幅度增强、计算力的大幅度提升、深度学习实现端到端的训练，深度学习引领人工智能进入有一个高潮。人们也逐渐开始将如日中天的深度学习方法引入到&lt;/span&gt;&lt;span&gt;NLP&lt;/span&gt;&lt;span&gt;领域，在机器翻译、问答系统、自动摘要等方向取得成功。经过互联网的发展，很多应用积累了足够多的数据可以用于学习。当数据量增大之后，以支持向量机（&lt;/span&gt;&lt;span&gt;SVM&lt;/span&gt;&lt;span&gt;）、条件随机场（&lt;/span&gt;&lt;span&gt;CRF&lt;/span&gt;&lt;span&gt;）为代表的传统浅层模型，由于模型过浅，无法对海量数据中的高维非线性映射做建模，所以不能带来性能的提升。然而，以&lt;/span&gt;&lt;span&gt;CNN&lt;/span&gt;&lt;span&gt;、&lt;/span&gt;&lt;span&gt;RNN&lt;/span&gt;&lt;span&gt;为代表的深度模型，可以随着模型复杂度的增大而增强，更好贴近数据的本质映射关系。一方面，深度学习的&lt;/span&gt;&lt;span&gt;word2vec&lt;/span&gt;&lt;span&gt;的出现，使得我们可以将词表示为更加低维的向量空间。另一方面，深度学习模型非常灵活，使得之前的很多任务，可以使用端到端的方式进行训练。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1204799/201902/1204799-20190222215232497-1887277437.png&quot; alt=&quot;&quot;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;&lt;strong&gt;&lt;span&gt;（&lt;/span&gt;&lt;span&gt;图&lt;/span&gt;4&lt;span&gt;）&lt;/span&gt;&lt;span&gt;基于深度学习的自然语言处理过程&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;为了让大家更好的理解基于深度学习的自然语言处理过程，举一个比较通用的模型，如图&lt;/span&gt;4。问题句子通过Seq2Seq循环神经网络进行预处理和编码，然后进入答案搜索，接着通过DQN强化学习网络对问答策略进程学习。这样，随着时间的推移，问答系统回答问题的水平会越来越高，就达到了不断在线学习的目的了。&lt;/p&gt;

&lt;p&gt;如果大家对博文的相关类容感兴趣，或有什么技术疑问，欢迎加入下面的《SLAM+语音机器人DIY》QQ技术交流群，一起讨论学习^_^&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1204799/201902/1204799-20190220162438739-1654241751.jpg&quot; alt=&quot;&quot;/&gt;&lt;/span&gt;&lt;/p&gt;

</description>
<pubDate>Fri, 22 Feb 2019 13:58:00 +0000</pubDate>
<dc:creator>小虎哥哥爱学习</dc:creator>
<og:description>摘要 这一章将进入机器人语音交互的学习，让机器人能跟人进行语音对话交流。这是一件很酷的事情，本章将涉及到语音识别、语音合成、自然语言处理方面的知识。本章内容： 1.语音交互相关技术 2.机器人语音交互</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/hiram-zhang/p/10420788.html</dc:identifier>
</item>
<item>
<title>行为型模式：命令模式 - LieBrother</title>
<link>http://www.cnblogs.com/liebrother/p/10420612.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/liebrother/p/10420612.html</guid>
<description>&lt;p&gt;LieBrother原文：&lt;br/&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s/MtZLDcVGAmEKq0PmbcnYvQ&quot;&gt;行为型模式：命令模式&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://www.liebrother.com/upload/b01637a5432a4df4813d10b6b9e7d0aa_0033_01.jpg&quot; alt=&quot;景&quot;/&gt;&lt;/p&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;十一大行为型模式之三：命令模式。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;简介&quot;&gt;简介&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;姓名&lt;/strong&gt; ：命令模式&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;英文名&lt;/strong&gt; ：Command Pattern&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;价值观&lt;/strong&gt; ：军令如山&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;个人介绍&lt;/strong&gt; ：&lt;/p&gt;
&lt;p&gt;Encapsulate a request as an object,thereby letting you parameterize clients with different requests,queue or log requests,and support undoable operations.&lt;br/&gt;将一个请求封装成一个对象，从而让你使用不同的请求把客户端参数化，对请求排队或者记录请求日志，可以提供命令的撤销和恢复功能。&lt;br/&gt;（来自《设计模式之禅》）&lt;/p&gt;
&lt;h2 id=&quot;你要的故事&quot;&gt;你要的故事&lt;/h2&gt;
&lt;p&gt;作为一个程序猿，我们每天都在经历着命令模式，技术经理把需求任务分配给工程师开发，有时因为第三方或者其他不可抗拒的因素导致需求停止开发。这种工作模式就是命令模式。好了，开始故事了。小明在 XX 科技公司做一个安静的程序猿，有一天技术经理给他分配了一个任务：新增黑名单，也就是在他们系统的某个模块里面可以手工对电话打黑名单标签的功能。小明接到任务后就立马开发，在开发了 2 天之后，因为战略原因，技术经理大明暂停了这个开发任务，接下来我们通过非命令模式和命令模式 2 种代码实现来体现这个过程。在这个场景中，为了简单，我们假定技术经理大明手下只有小明一个开发人员。&lt;/p&gt;
&lt;h3 id=&quot;非命令模式&quot;&gt;非命令模式&lt;/h3&gt;
&lt;p&gt;非命令模式也就是不使用命令模式的代码实现。代码中，我们出现了 Developer 开发人，开发同学是接受技术经理传达的任务，技术经理让他开发哪个需求就开发哪个需求，如果项目有问题需要中断，也需要技术经理评估后传达给开发同学，所以 Developer 有 2 个方法，分别是 develop() 开发需求和 suspend() 暂停需求。 Requirement 则为需求类，TechnicalManager1 则为技术经理类，他有一个方法 action()，通过这个方法来指定开发同学开发任务或者暂停任务。&lt;/p&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;public class NoCommandTest {

    public static void main(String[] args) {
        Developer xiaoMing = new Developer(&quot;小明&quot;);
        Requirement requirement = new Requirement(&quot;新增黑名单&quot;);
        TechnicalManager1 technicalManager2 = new TechnicalManager1(&quot;大明&quot;);
        technicalManager2.setDeveloper(xiaoMing);
        technicalManager2.action(requirement, &quot;develop&quot;);
        System.out.println(&quot;开发了 2 天，需求变故，需要暂停。。。&quot;);
        technicalManager2.action(requirement, &quot;suspend&quot;);
    }

}

/**
 * 开发人员
 */
class Developer {

    private String name;

    public Developer(String name) {
        this.name = name;
    }

    public void develop(Requirement requirement) {
        System.out.println(this.name + &quot; 开始开发需求：&quot; + requirement.getName());
    }

    public void suspend(Requirement requirement) {
        System.out.println(this.name + &quot; 停止开发需求：&quot; + requirement.getName());
    }

    public String getName() {
        return name;
    }

}

/**
 * 需求
 */
class Requirement {
    private String name;

    public Requirement(String name) {
        this.name = name;
    }

    public String getName() {
        return name;
    }

}

/**
 * 技术经理
 */
class TechnicalManager1 {

    private String name;

    private Developer developer;

    public TechnicalManager1(String name) {
        this.name = name;
    }

    public void setDeveloper(Developer developer) {
        this.developer = developer;
    }

    public void action(Requirement requirement, String type) {
        if (&quot;develop&quot;.equals(type)) {
            this.developer.develop(requirement);
        } else if (&quot;suspend&quot;.equals(type)) {
            this.developer.suspend(requirement);
        }
    }

}

打印结果：
小明 开始开发需求：新增黑名单
开发了 2 天，需求变故，需要暂停。。。
小明 停止开发需求：新增黑名单&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;通过代码，我们可以发现技术经理和开发同学是强依赖关系。如果技术经理下达了一个任务，要求小明写一下周报，这时候得怎么写？是不是小明需要一个写周报的方法，大明也需要新增一个处理事务类型？有没有更好的方法让技术经理不需要做任何改变？命令模式就来解决这个问题。&lt;/p&gt;
&lt;h3 id=&quot;命令模式&quot;&gt;命令模式&lt;/h3&gt;
&lt;p&gt;在这个例子中，不管大明叫小明做什么事情，其实都是一样的，就是下达任务命令，让小明去执行命令。我们可以利用命令模式把下达任务这个抽象起来，当做父类，下达开发命令、下达暂停命令、下达写周报等等都是不同的子命令。代码如下。&lt;/p&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;public class CommandTest {

    public static void main(String[] args) {
        Developer xiaoMing = new Developer(&quot;小明&quot;);
        Command developCommand = new DevelopCommand(xiaoMing);
        Command suspendCommand = new SuspendCommand(xiaoMing);
        Requirement requirement = new Requirement(&quot;新增黑名单&quot;);
        TechnicalManager2 technicalManager = new TechnicalManager2(&quot;大明&quot;);
        technicalManager.setCommand(developCommand);
        technicalManager.action(requirement);
        System.out.println(&quot;开发了 2 天，需求变故，需要暂停。。。&quot;);
        technicalManager.setCommand(suspendCommand);
        technicalManager.action(requirement);

    }

}

/**
 * 命令
 */
abstract class Command {

    protected Developer developer;

    public Command(Developer developer) {
        this.developer = developer;
    }

    public abstract void execute(Requirement requirement);
}

/**
 * 开始开发
 */
class DevelopCommand extends Command {

    public DevelopCommand(Developer developer) {
        super(developer);
    }

    @Override
    public void execute(Requirement requirement) {
        this.developer.develop(requirement);
    }
}

/**
 * 开发中断
 */
class SuspendCommand extends Command {

    public SuspendCommand(Developer developer) {
        super(developer);
    }

    @Override
    public void execute(Requirement requirement) {
        this.developer.suspend(requirement);
    }
}

/**
 * 技术经理
 */
class TechnicalManager2 {

    private String name;
    private Command command;

    public TechnicalManager2(String name) {
        this.name = name;
    }

    public void action(Requirement requirement) {
        this.command.execute(requirement);
    }

    public void setCommand(Command command) {
        this.command = command;
    }
}

打印结果：
小明 开始开发需求：新增黑名单
开发了 2 天，需求变故，需要暂停。。。
小明 停止开发需求：新增黑名单&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;代码中用 Command 来抽象下达任务，而技术经理 TechnicalManager2 并没有和 Developer 有直接的关系，而是 TechnicalManager2 和 Command 建立的联系，Command 和 Developer 建立了联系。这样子把大明和小明的强依赖关系给剥离开，而新增一个下达写周报的任务也很简单，在 Developer 中新增一个处理写周报的方法，新增一个写周报的 Command 子类，就可以了，TechnicalManager2 如上面所愿不用修改。这就是完整的一个命令模式代码。&lt;/p&gt;
&lt;p&gt;代码：&lt;br/&gt;&lt;a href=&quot;https://github.com/1CSH1/DesignPatterns/tree/master/src/com/liebrother/designpatterns/command&quot;&gt;Command Pattern&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;总结&quot;&gt;总结&lt;/h2&gt;
&lt;p&gt;从文章中我们就可以看到，利用命令模式能够&lt;strong&gt;进行类的解耦&lt;/strong&gt;，让调用者和接受者没有任何关系，也通过对行为的抽象，让新增其他行为变得清晰容易，也就是&lt;strong&gt;可扩展性大大增加&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;参考资料：《大话设计模式》、《设计模式之禅》&lt;/p&gt;
&lt;p&gt;推荐阅读：&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://mp.weixin.qq.com/mp/homepage?__biz=MzIxMzgwMTAyMg==&amp;amp;hid=2&amp;amp;sn=c97b64288d92312f57d3c8298f8d8888&quot;&gt;公众号之设计模式系列文章&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;希望文章对您有所帮助，设计模式系列会持续更新，感兴趣的同学可以关注公众号：&lt;strong&gt;LieBrother&lt;/strong&gt;，第一时间获取文章推送阅读，也可以一起交流，交个朋友。&lt;/p&gt;
</description>
<pubDate>Fri, 22 Feb 2019 12:47:00 +0000</pubDate>
<dc:creator>LieBrother</dc:creator>
<og:description>十一大行为型模式之三：命令模式。</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/liebrother/p/10420612.html</dc:identifier>
</item>
<item>
<title>要搞刷机!从它的尸体上踏过去!钢板云路由!WPR003N复活！成功启动OPENWRT - A.Z</title>
<link>http://www.cnblogs.com/A-Z/p/wpr003n_openwrt.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/A-Z/p/wpr003n_openwrt.html</guid>
<description>&lt;p&gt;这是一个很鼓舞人心的标题，自从上一篇&lt;a id=&quot;post_title_link_10408396&quot; href=&quot;https://www.cnblogs.com/A-Z/p/aria2_2019_0.html&quot;&gt;Aria2序之导言&lt;/a&gt; 00，成功的贴出两张开场图片，本来计划写它的开场引言 01，正好cp一个合格的导引（引导读起来有些奇怪），连续懒惰了好几天，突然想起了WPR003N, 当时记录了&lt;a id=&quot;post_title_link_10392928&quot; href=&quot;https://www.cnblogs.com/A-Z/p/WPR003N.html&quot;&gt;WPR003N变成尸体的后记&lt;/a&gt;，想着想着，突然就拿出来摸一摸，这一摸，还真的....嗯成功啦&lt;/p&gt;
&lt;p&gt;借着这个振奋的标题，先比较一下WPR003N和TPLINK 720N的区别，从功能上和性能上几乎相似，虽然隔了一代，但是本质上它们仍然属于同一系列，对IEEE 802.11n的支持从150M上升到300M，射频由原来1x2:1提升到了2x2:2，频率略有提升， 内存从DDR更新到DDR2, 丰富了ref/div。&lt;/p&gt;
&lt;p&gt;从硬件角度，720N的三态滑动开关已经在OPENWRT里非常成熟，正确的配置好kernel后可以在上层灵活的映射action，WPR003N的开关是电路控制，和gpio没有关系，形态上两者区别不大，720N方一点，003N边角是圆润的，并且多了一个LINEOUT接口。&lt;/p&gt;
&lt;p&gt;从pcb的视角，720N明显的落后于003N, Atheros的logo也有一处显著的区别，那就是代工方由原来的韩国迁移到了弯弯，pcb一个是绿色的一个是土黄色的。&lt;/p&gt;
&lt;p&gt;从OS的视角24kc和74kc的mtune完全是沿袭24kc，target归于同类。&lt;/p&gt;
&lt;p&gt;一顿分析猛于虎，下面开始正式环节，请继续听说书：&lt;/p&gt;
&lt;p&gt;上回说到摸与非摸间，突然有一个声音响起了那就是Atheros reference design， 这个声音听起来细微，但是仔细回想，突然灵感来了，发掘了AP123-031-D1156，这样的关键性息，这就像醍醐灌顶一样，在四周激荡，激荡，然后从这个点金石出发，123就开启了OPENWRT的大门，作为全网首发，你们可以问渡娘，我有没有抄袭，恩山上一群基友在帮沪郊松江区XXX消费接盘的同时，在那里发帖有关这个路由没有活人应答的当下，寥寥几笔，就把这个过程描绘的惟妙惟肖，为了做到老少皆宜，寓教于乐，有图有真相，请看下图：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://www.cnblogs.com/images/cnblogs_com/A-Z/117549/o_wpr003n.png&quot; alt=&quot;&quot; width=&quot;620&quot; height=&quot;auto&quot;/&gt;&lt;/p&gt;
&lt;p&gt;我在&lt;a id=&quot;post_title_link_10380969&quot; href=&quot;https://www.cnblogs.com/A-Z/p/super2019.html&quot;&gt;2019 Valentine's Day 圣地巡礼和WPR003N开箱刷U-boot记录&lt;/a&gt;的最后留下一个悬疑已经解开，仿佛听到了密封袋里的散热片痴痴一笑，百年好合，它是不是在妄想呢，请听下回分解。&lt;/p&gt;
&lt;p&gt;我们再闪回到中间的尸体环节，看一下这次成功的意义何在？重要的内容我要留在最后：&lt;/p&gt;
&lt;p&gt;为这个小众的路由找到了baseline, 一个ref board起了决定性作用，尽管没有去编译它，但是有了这样的平台，完善switch内的order和gpio cfg就变得可行了，在只有一个bootloader的环境，权衡ttl找手册找low uart gpio找pcb背面（cpu在背侧，居心叵测）排线的时效，切换思路是一种非常有成效的方式，实践证明了这是很好的捷径，规避了很多专业硬件开发才会去触碰的知识面。&lt;/p&gt;
&lt;p&gt;好了，当我看到图中的画面，想起一首歌词和一副画面：&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;让我们荡起双桨&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;小船儿推开波浪&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;海面倒映着美丽的白塔&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;四周环绕着绿树红墙&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;小船儿轻轻飘荡在水中&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;迎面吹来了凉爽的风&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;红领巾迎着太阳&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;阳光洒在海面上&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;水中鱼儿望着我们&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;悄悄地听我们愉快歌唱&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
</description>
<pubDate>Fri, 22 Feb 2019 12:32:00 +0000</pubDate>
<dc:creator>A.Z</dc:creator>
<og:description>这是一个很鼓舞人心的标题，自从上一篇Aria2序之导言 00，成功的贴出两张开场图片，本来计划写它的开场引言 01，正好cp一个合格的导引（引导读起来有些奇怪），连续懒惰了好几天，突然想起了WPR00</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/A-Z/p/wpr003n_openwrt.html</dc:identifier>
</item>
<item>
<title>关于获取资源文件，Class.getResource和ClassLoader.getResource的区别 - 夜月归途</title>
<link>http://www.cnblogs.com/guitu18/p/10420459.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/guitu18/p/10420459.html</guid>
<description>&lt;p&gt;&lt;span&gt;原文同步发表至个人博客&lt;a href=&quot;http://www.guitu18.com/&quot; target=&quot;_blank&quot;&gt;【夜月归途】&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;原文链接：&lt;a href=&quot;http://www.guitu18.com/se/java/2019-02-22/29.html&quot; target=&quot;_blank&quot;&gt;http://www.guitu18.com/se/java/2019-02-22/29.html&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;
&lt;div id=&quot;copyright&quot; readability=&quot;8.3793103448276&quot;&gt;作者：&lt;a href=&quot;http://www.guitu18.com/&quot; target=&quot;_blank&quot;&gt;夜月归途&lt;/a&gt;&lt;br/&gt;出处：&lt;a href=&quot;http://www.guitu18.com/&quot; target=&quot;_blank&quot;&gt;http://www.guitu18.com/&lt;/a&gt;&lt;br/&gt;本博客中未标明转载的文章归作者&lt;a href=&quot;http://www.guitu18.com/&quot; target=&quot;_blank&quot;&gt;夜月归途&lt;/a&gt;和博客园所有。 欢迎转载，但未经作者同意必须保留此段声明，且在文章页面明显位置给出原文连接，否则保留追究法律责任的权利。&lt;/div&gt;
&lt;p&gt;在Java中经常会需要读取各种各样的配置文件，在获取资源时，一般会用到 &lt;code&gt;Class.getResource()&lt;/code&gt; 或 &lt;code&gt;ClassLoader.getResource()&lt;/code&gt; ;&lt;/p&gt;
&lt;p&gt;那么这两种方式在获取资源文件时有什么相同或者不同的地方呢？&lt;/p&gt;
&lt;p&gt;先贴上代码目录结构：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;┌─src
│  └─main
│     └─java
│        └─com.guitu18.blog
│           ├─classpath
│           │  └─GetResourceTest.java
│           └─SpringbootApplication.java
└─resource
   ├─mapper
   │   └─BlogDao.xml
   └─confog.properties
&lt;/code&gt;
&lt;/pre&gt;
&lt;h2&gt;Class.getResource()&lt;/h2&gt;
&lt;p&gt;测试代码，先看 &lt;code&gt;this.getClass().getResource()&lt;/code&gt;：&lt;br/&gt;代码的输出结果我直接贴在代码的上一行了，下同。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;@Test
public void classGetResource() {
    // file:/E:/repo/guitu-blog/target/test-classes/com/guitu18/blog/classpath/
    System.out.println(this.getClass().getResource(&quot;&quot;));
    // file:/E:/repo/guitu-blog/target/test-classes/
    System.out.println(this.getClass().getResource(&quot;/&quot;));
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;可以看出，&lt;code&gt;getResource(&quot;&quot;)&lt;/code&gt; 获取的是当前类所在包的路径，而 &lt;code&gt;getResource(&quot;/&quot;)&lt;/code&gt; 获取的是 &lt;code&gt;classpath&lt;/code&gt; 根路径；&lt;/p&gt;
&lt;p&gt;继续测试，我们获取目录下的文件：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;@Test
public void classGetProperties() {
    // file:/E:/repo/guitu-blog/target/classes/config.properties
    System.out.println(this.getClass().getResource(&quot;/config.properties&quot;));
    // null
    System.out.println(this.getClass().getResource(&quot;BlogDao.xml&quot;));
    // file:/E:/repo/guitu-blog/target/classes/mapper/BlogDao.xml
    System.out.println(this.getClass().getResource(&quot;/mapper/BlogDao.xml&quot;));
    /**
     * .java文件在编译后编程.class，所以这里参数传的文件名是.class结尾
     */
    // file:/E:/repo/guitu-blog/target/classes/com/guitu18/blog/classpath/GetResourceTest.class
    System.out.println(this.getClass().getResource(&quot;GetResourceTest.class&quot;));
    // file:/E:/repo/guitu-blog/target/classes/com/guitu18/blog/SpringbootApplication.class
    System.out.println(this.getClass().getResource(&quot;../SpringbootApplication.class&quot;));
    // file:/E:/repo/guitu-blog/target/classes/com/guitu18/blog/classpath/GetResourceTest.class
    System.out.println(this.getClass().getResource(&quot;../classpath/GetResourceTest.class&quot;));
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;输出结果显示：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;当以 &lt;code&gt;&quot;/&quot;&lt;/code&gt; 开头时，是从 &lt;code&gt;classpath&lt;/code&gt; 路径开始匹配资源；&lt;/li&gt;
&lt;li&gt;当不以 &lt;code&gt;&quot;/&quot;&lt;/code&gt; 开头时，是从当前类所在包的路径开始匹配资源；&lt;/li&gt;
&lt;li&gt;两种方式都可以通过 &lt;code&gt;&quot;/&quot;&lt;/code&gt; 或 &lt;code&gt;&quot;../&quot;&lt;/code&gt; 在文件夹上下层路径切换；&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;另外，在获取文件时，我们还可以通过 &lt;code&gt;getResourceAsStream&lt;/code&gt; 直接获取文件输入流，如：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;InputStream inputStream = this.getClass().getResourceAsStream(&quot;/config.properties&quot;);
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;且 &lt;code&gt;getResourceAsStream()&lt;/code&gt; 和 &lt;code&gt;getResource()&lt;/code&gt; 在获取文件流和文件路径时，路径选择机制是一样的。&lt;/p&gt;
&lt;h2&gt;ClassLoader.getResource()&lt;/h2&gt;
&lt;p&gt;接着看 &lt;code&gt;this.getClass().getClassLoader().getResource&lt;/code&gt; ，上代码：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;@Test
public void classLoaderGetResource() {
    // file:/E:/repo/guitu-blog/target/test-classes/
    System.out.println(this.getClass().getClassLoader().getResource(&quot;&quot;));
    // null
    System.out.println(this.getClass().getClassLoader().getResource(&quot;/&quot;));
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;在使用 &lt;code&gt;ClassLoader().getResource&lt;/code&gt; 获取路径时，不能以 &lt;code&gt;&quot;/&quot;&lt;/code&gt; 开头，且路径总是从 &lt;code&gt;classpath&lt;/code&gt; 根路径开始；&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;@Test
public void classLoaderGetProperties() {
    /**
     * 同样可以通过&quot;/&quot;或&quot;../&quot;在文件夹上下层路径切换
     */
    // file:/E:/repo/guitu-blog/target/classes/config.properties
    System.out.println(this.getClass().getClassLoader().getResource(&quot;config.properties&quot;));
    // null
    System.out.println(this.getClass().getClassLoader().getResource(&quot;BlogDao.xml&quot;));
    // file:/E:/repo/guitu-blog/target/classes/mapper/BlogDao.xml
    System.out.println(this.getClass().getClassLoader().getResource(&quot;mapper/BlogDao.xml&quot;));
    /**
     * 同Class.getResourceAsStream()一样，我们还可以通过ClassLoader.getResourceAsStream()直接获取文件输入流
     * ClassLoader.getResourceAsStream()和ClassLoader.getResource()在获取文件流和文件路径时，路径选择机制也是一样的
     */
    InputStream inputStream = this.getClass().getClassLoader().getResourceAsStream(&quot;config.properties&quot;);
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;这里跟上面差别不大，所以直接把结果写在代码注释中了， &lt;code&gt;ClassLoader().getResource&lt;/code&gt; 只能从 &lt;code&gt;classpath&lt;/code&gt; 开始获取资源，同样也能使用&lt;code&gt;getResourceAsStream()&lt;/code&gt; 获取文件输入流，且路径机制一样；&lt;/p&gt;
&lt;h2&gt;总结&lt;/h2&gt;
&lt;ol&gt;&lt;li&gt;&lt;code&gt;Class.getResource()&lt;/code&gt; 可以从当前 &lt;code&gt;Class&lt;/code&gt; 所在包的路径开始匹配获取资源，也可以从 &lt;code&gt;classpath&lt;/code&gt; 根路径开始匹配获取资源；&lt;/li&gt;
&lt;li&gt;&lt;code&gt;ClassLoader().getResource()&lt;/code&gt; 只能从 &lt;code&gt;classpath&lt;/code&gt; 根路径开始匹配获取资源；&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Class.getResource()&lt;/code&gt; 从当前包所在路径获取资源时不能以 &lt;code&gt;&quot;/&quot;&lt;/code&gt; 开头，而从 &lt;code&gt;classpath&lt;/code&gt; 根路径获取资源时必须以 &lt;code&gt;&quot;/&quot;&lt;/code&gt; 开头；&lt;/li&gt;
&lt;li&gt;&lt;code&gt;ClassLoader().getResource()&lt;/code&gt; 不能以 &lt;code&gt;&quot;/&quot;&lt;/code&gt; 开头，且路径总是从 &lt;code&gt;classpath&lt;/code&gt; 根路径开始；&lt;/li&gt;
&lt;li&gt;它们都能通过 &lt;code&gt;getResourceAsStream()&lt;/code&gt; 方法获取对应路径文件的输入流，文件路径匹配机制和其 &lt;code&gt;getResource()&lt;/code&gt; 方法一样；&lt;/li&gt;
&lt;/ol&gt;</description>
<pubDate>Fri, 22 Feb 2019 12:12:00 +0000</pubDate>
<dc:creator>夜月归途</dc:creator>
<og:description>原文同步发表至个人博客【夜月归途】 原文链接：http://www.guitu18.com/se/java/2019-02-22/29.html 作者：夜月归途 出处：http://www.guitu</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/guitu18/p/10420459.html</dc:identifier>
</item>
</channel>
</rss>