<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="css/feed.xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/" xmlns:og="http://ogp.me/ns#">
<channel>
<atom:link rel="self" href="http://192.168.1.4/fivefilters/makefulltextfeed.php?url=feed.cnblogs.com%2Fblog%2Fsitehome%2Frss&amp;max=10&amp;links=preserve&amp;exc=" />
<atom:link rel="alternate" title="Source URL" href="http://feed.cnblogs.com/blog/sitehome/rss" />
<atom:link rel="related" title="Subscribe to feed" href="http://www.subtome.com/#/subscribe?feeds=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed.cnblogs.com%252Fblog%252Fsitehome%252Frss%26max%3D10%26links%3Dpreserve%26exc%3D&amp;back=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed.cnblogs.com%252Fblog%252Fsitehome%252Frss%26max%3D10%26links%3Dpreserve%26exc%3D" />
<title>博客园_首页</title>
<link></link>
<description>代码改变世界</description>
<item>
<title>死磕 java同步系列之Phaser源码解析 - 彤哥读源码</title>
<link>http://www.cnblogs.com/tong-yuan/p/11614755.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/tong-yuan/p/11614755.html</guid>
<description>&lt;h2 id=&quot;问题&quot;&gt;问题&lt;/h2&gt;
&lt;p&gt;（1）Phaser是什么？&lt;/p&gt;
&lt;p&gt;（2）Phaser具有哪些特性？&lt;/p&gt;
&lt;p&gt;（3）Phaser相对于CyclicBarrier和CountDownLatch的优势？&lt;/p&gt;
&lt;h2 id=&quot;简介&quot;&gt;简介&lt;/h2&gt;
&lt;p&gt;Phaser，翻译为阶段，它适用于这样一种场景，一个大任务可以分为多个阶段完成，且每个阶段的任务可以多个线程并发执行，但是必须上一个阶段的任务都完成了才可以执行下一个阶段的任务。&lt;/p&gt;
&lt;p&gt;这种场景虽然使用CyclicBarrier或者CountryDownLatch也可以实现，但是要复杂的多。首先，具体需要多少个阶段是可能会变的，其次，每个阶段的任务数也可能会变的。相比于CyclicBarrier和CountDownLatch，Phaser更加灵活更加方便。&lt;/p&gt;
&lt;h2 id=&quot;使用方法&quot;&gt;使用方法&lt;/h2&gt;
&lt;p&gt;下面我们看一个最简单的使用案例：&lt;/p&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;public class PhaserTest {

    public static final int PARTIES = 3;
    public static final int PHASES = 4;

    public static void main(String[] args) {

        Phaser phaser = new Phaser(PARTIES) {
            @Override
            protected boolean onAdvance(int phase, int registeredParties) {
                // 【本篇文章由公众号“彤哥读源码”原创，请支持原创，谢谢！】
                System.out.println(&quot;=======phase: &quot; + phase + &quot; finished=============&quot;);
                return super.onAdvance(phase, registeredParties);
            }
        };

        for (int i = 0; i &amp;lt; PARTIES; i++) {
            new Thread(()-&amp;gt;{
                for (int j = 0; j &amp;lt; PHASES; j++) {
                    System.out.println(String.format(&quot;%s: phase: %d&quot;, Thread.currentThread().getName(), j));
                    phaser.arriveAndAwaitAdvance();
                }
            }, &quot;Thread &quot; + i).start();
        }
    }
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;这里我们定义一个需要4个阶段完成的大任务，每个阶段需要3个小任务，针对这些小任务，我们分别起3个线程来执行这些小任务，查看输出结果为：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;Thread 0: phase: 0
Thread 2: phase: 0
Thread 1: phase: 0
=======phase: 0 finished=============
Thread 2: phase: 1
Thread 0: phase: 1
Thread 1: phase: 1
=======phase: 1 finished=============
Thread 1: phase: 2
Thread 0: phase: 2
Thread 2: phase: 2
=======phase: 2 finished=============
Thread 0: phase: 3
Thread 2: phase: 3
Thread 1: phase: 3
=======phase: 3 finished=============&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;可以看到，每个阶段都是三个线程都完成了才进入下一个阶段。这是怎么实现的呢，让我们一起来学习吧。&lt;/p&gt;
&lt;h2 id=&quot;原理猜测&quot;&gt;原理猜测&lt;/h2&gt;
&lt;p&gt;根据我们前面学习AQS的原理，大概猜测一下Phaser的实现原理。&lt;/p&gt;
&lt;p&gt;首先，需要存储当前阶段phase、当前阶段的任务数（参与者）parties、未完成参与者的数量，这三个变量我们可以放在一个变量state中存储。&lt;/p&gt;
&lt;p&gt;其次，需要一个队列存储先完成的参与者，当最后一个参与者完成任务时，需要唤醒队列中的参与者。&lt;/p&gt;
&lt;p&gt;嗯，差不多就是这样子。&lt;/p&gt;
&lt;p&gt;结合上面的案例带入：&lt;/p&gt;
&lt;p&gt;初始时当前阶段为0，参与者数为3个，未完成参与者数为3；&lt;/p&gt;
&lt;p&gt;第一个线程执行到&lt;code&gt;phaser.arriveAndAwaitAdvance();&lt;/code&gt;时进入队列；&lt;/p&gt;
&lt;p&gt;第二个线程执行到&lt;code&gt;phaser.arriveAndAwaitAdvance();&lt;/code&gt;时进入队列；&lt;/p&gt;
&lt;p&gt;第三个线程执行到&lt;code&gt;phaser.arriveAndAwaitAdvance();&lt;/code&gt;时先执行这个阶段的总结&lt;code&gt;onAdvance()&lt;/code&gt;，再唤醒前面两个线程继续执行下一个阶段的任务。&lt;/p&gt;
&lt;p&gt;嗯，整体能说得通，至于是不是这样呢，让我们一起来看源码吧。&lt;/p&gt;
&lt;h2 id=&quot;源码分析&quot;&gt;源码分析&lt;/h2&gt;
&lt;h3 id=&quot;主要内部类&quot;&gt;主要内部类&lt;/h3&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;static final class QNode implements ForkJoinPool.ManagedBlocker {
    final Phaser phaser;
    final int phase;
    final boolean interruptible;
    final boolean timed;
    boolean wasInterrupted;
    long nanos;
    final long deadline;
    volatile Thread thread; // nulled to cancel wait
    QNode next;

    QNode(Phaser phaser, int phase, boolean interruptible,
          boolean timed, long nanos) {
        this.phaser = phaser;
        this.phase = phase;
        this.interruptible = interruptible;
        this.nanos = nanos;
        this.timed = timed;
        this.deadline = timed ? System.nanoTime() + nanos : 0L;
        thread = Thread.currentThread();
    }
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;先完成的参与者放入队列中的节点，这里我们只需要关注&lt;code&gt;thread&lt;/code&gt;和&lt;code&gt;next&lt;/code&gt;两个属性即可，很明显这是一个单链表，存储着入队的线程。&lt;/p&gt;
&lt;h3 id=&quot;主要属性&quot;&gt;主要属性&lt;/h3&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;// 状态变量，用于存储当前阶段phase、参与者数parties、未完成的参与者数unarrived_count
private volatile long state;
// 最多可以有多少个参与者，即每个阶段最多有多少个任务
private static final int  MAX_PARTIES     = 0xffff;
// 最多可以有多少阶段
private static final int  MAX_PHASE       = Integer.MAX_VALUE;
// 参与者数量的偏移量
private static final int  PARTIES_SHIFT   = 16;
// 当前阶段的偏移量
private static final int  PHASE_SHIFT     = 32;
// 未完成的参与者数的掩码，低16位
private static final int  UNARRIVED_MASK  = 0xffff;      // to mask ints
// 参与者数，中间16位
private static final long PARTIES_MASK    = 0xffff0000L; // to mask longs
// counts的掩码，counts等于参与者数和未完成的参与者数的'|'操作
private static final long COUNTS_MASK     = 0xffffffffL;
private static final long TERMINATION_BIT = 1L &amp;lt;&amp;lt; 63;

// 一次一个参与者完成
private static final int  ONE_ARRIVAL     = 1;
// 增加减少参与者时使用
private static final int  ONE_PARTY       = 1 &amp;lt;&amp;lt; PARTIES_SHIFT;
// 减少参与者时使用
private static final int  ONE_DEREGISTER  = ONE_ARRIVAL|ONE_PARTY;
// 没有参与者时使用
private static final int  EMPTY           = 1;

// 用于求未完成参与者数量
private static int unarrivedOf(long s) {
    int counts = (int)s;
    return (counts == EMPTY) ? 0 : (counts &amp;amp; UNARRIVED_MASK);
}
// 用于求参与者数量（中间16位），注意int的位置
private static int partiesOf(long s) {
    return (int)s &amp;gt;&amp;gt;&amp;gt; PARTIES_SHIFT;
}
// 用于求阶段数（高32位），注意int的位置
private static int phaseOf(long s) {
    return (int)(s &amp;gt;&amp;gt;&amp;gt; PHASE_SHIFT);
}
// 已完成参与者的数量
private static int arrivedOf(long s) {
    int counts = (int)s; // 低32位
    return (counts == EMPTY) ? 0 :
        (counts &amp;gt;&amp;gt;&amp;gt; PARTIES_SHIFT) - (counts &amp;amp; UNARRIVED_MASK);
}
// 用于存储已完成参与者所在的线程，根据当前阶段的奇偶性选择不同的队列
private final AtomicReference&amp;lt;QNode&amp;gt; evenQ;
private final AtomicReference&amp;lt;QNode&amp;gt; oddQ;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;主要属性为&lt;code&gt;state&lt;/code&gt;和&lt;code&gt;evenQ&lt;/code&gt;及&lt;code&gt;oddQ&lt;/code&gt;：&lt;/p&gt;
&lt;p&gt;（1）state，状态变量，高32位存储当前阶段phase，中间16位存储参与者的数量，低16位存储未完成参与者的数量【本篇文章由公众号“彤哥读源码”原创，请支持原创，谢谢！】；&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1648938/201910/1648938-20191001081814517-989821021.png&quot; alt=&quot;Phaser&quot;/&gt;&lt;/p&gt;
&lt;p&gt;（2）evenQ和oddQ，已完成的参与者存储的队列，当最后一个参与者完成任务后唤醒队列中的参与者继续执行下一个阶段的任务，或者结束任务。&lt;/p&gt;
&lt;h3 id=&quot;构造方法&quot;&gt;构造方法&lt;/h3&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;public Phaser() {
    this(null, 0);
}

public Phaser(int parties) {
    this(null, parties);
}

public Phaser(Phaser parent) {
    this(parent, 0);
}

public Phaser(Phaser parent, int parties) {
    if (parties &amp;gt;&amp;gt;&amp;gt; PARTIES_SHIFT != 0)
        throw new IllegalArgumentException(&quot;Illegal number of parties&quot;);
    int phase = 0;
    this.parent = parent;
    if (parent != null) {
        final Phaser root = parent.root;
        this.root = root;
        this.evenQ = root.evenQ;
        this.oddQ = root.oddQ;
        if (parties != 0)
            phase = parent.doRegister(1);
    }
    else {
        this.root = this;
        this.evenQ = new AtomicReference&amp;lt;QNode&amp;gt;();
        this.oddQ = new AtomicReference&amp;lt;QNode&amp;gt;();
    }
    // 状态变量state的存储分为三段
    this.state = (parties == 0) ? (long)EMPTY :
        ((long)phase &amp;lt;&amp;lt; PHASE_SHIFT) |
        ((long)parties &amp;lt;&amp;lt; PARTIES_SHIFT) |
        ((long)parties);
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;构造函数中还有一个parent和root，这是用来构造多层级阶段的，不在本文的讨论范围之内，忽略之。&lt;/p&gt;
&lt;p&gt;重点还是看state的赋值方式，高32位存储当前阶段phase，中间16位存储参与者的数量，低16位存储未完成参与者的数量。&lt;/p&gt;
&lt;p&gt;下面我们一起来看看几个主要方法的源码：&lt;/p&gt;
&lt;h3 id=&quot;register方法&quot;&gt;register()方法&lt;/h3&gt;
&lt;p&gt;注册一个参与者，如果调用该方法时，onAdvance()方法正在执行，则该方法等待其执行完毕。&lt;/p&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;public int register() {
    return doRegister(1);
}
private int doRegister(int registrations) {
    // state应该加的值，注意这里是相当于同时增加parties和unarrived
    long adjust = ((long)registrations &amp;lt;&amp;lt; PARTIES_SHIFT) | registrations;
    final Phaser parent = this.parent;
    int phase;
    for (;;) {
        // state的值
        long s = (parent == null) ? state : reconcileState();
        // state的低32位，也就是parties和unarrived的值
        int counts = (int)s;
        // parties的值
        int parties = counts &amp;gt;&amp;gt;&amp;gt; PARTIES_SHIFT;
        // unarrived的值
        int unarrived = counts &amp;amp; UNARRIVED_MASK;
        // 检查是否溢出
        if (registrations &amp;gt; MAX_PARTIES - parties)
            throw new IllegalStateException(badRegister(s));
        // 当前阶段phase
        phase = (int)(s &amp;gt;&amp;gt;&amp;gt; PHASE_SHIFT);
        if (phase &amp;lt; 0)
            break;
        // 不是第一个参与者
        if (counts != EMPTY) {                  // not 1st registration
            if (parent == null || reconcileState() == s) {
                // unarrived等于0说明当前阶段正在执行onAdvance()方法，等待其执行完毕
                if (unarrived == 0)             // wait out advance
                    root.internalAwaitAdvance(phase, null);
                // 否则就修改state的值，增加adjust，如果成功就跳出循环
                else if (UNSAFE.compareAndSwapLong(this, stateOffset,
                                                   s, s + adjust))
                    break;
            }
        }
        // 是第一个参与者
        else if (parent == null) {              // 1st root registration
            // 计算state的值
            long next = ((long)phase &amp;lt;&amp;lt; PHASE_SHIFT) | adjust;
            // 修改state的值，如果成功就跳出循环
            if (UNSAFE.compareAndSwapLong(this, stateOffset, s, next))
                break;
        }
        else {
            // 多层级阶段的处理方式
            synchronized (this) {               // 1st sub registration
                if (state == s) {               // recheck under lock
                    phase = parent.doRegister(1);
                    if (phase &amp;lt; 0)
                        break;
                    // finish registration whenever parent registration
                    // succeeded, even when racing with termination,
                    // since these are part of the same &quot;transaction&quot;.
                    while (!UNSAFE.compareAndSwapLong
                           (this, stateOffset, s,
                            ((long)phase &amp;lt;&amp;lt; PHASE_SHIFT) | adjust)) {
                        s = state;
                        phase = (int)(root.state &amp;gt;&amp;gt;&amp;gt; PHASE_SHIFT);
                        // assert (int)s == EMPTY;
                    }
                    break;
                }
            }
        }
    }
    return phase;
}
// 等待onAdvance()方法执行完毕
// 原理是先自旋一定次数，如果进入下一个阶段，这个方法直接就返回了，
// 如果自旋一定次数后还没有进入下一个阶段，则当前线程入队列，等待onAdvance()执行完毕唤醒
private int internalAwaitAdvance(int phase, QNode node) {
    // 保证队列为空
    releaseWaiters(phase-1);          // ensure old queue clean
    boolean queued = false;           // true when node is enqueued
    int lastUnarrived = 0;            // to increase spins upon change
    // 自旋的次数
    int spins = SPINS_PER_ARRIVAL;
    long s;
    int p;
    // 检查当前阶段是否变化，如果变化了说明进入下一个阶段了，这时候就没有必要自旋了
    while ((p = (int)((s = state) &amp;gt;&amp;gt;&amp;gt; PHASE_SHIFT)) == phase) {
        // 如果node为空，注册的时候传入的为空
        if (node == null) {           // spinning in noninterruptible mode
            // 未完成的参与者数量
            int unarrived = (int)s &amp;amp; UNARRIVED_MASK;
            // unarrived有变化，增加自旋次数
            if (unarrived != lastUnarrived &amp;amp;&amp;amp;
                (lastUnarrived = unarrived) &amp;lt; NCPU)
                spins += SPINS_PER_ARRIVAL;
            boolean interrupted = Thread.interrupted();
            // 自旋次数完了，则新建一个节点
            if (interrupted || --spins &amp;lt; 0) { // need node to record intr
                node = new QNode(this, phase, false, false, 0L);
                node.wasInterrupted = interrupted;
            }
        }
        else if (node.isReleasable()) // done or aborted
            break;
        else if (!queued) {           // push onto queue
            // 节点入队列
            AtomicReference&amp;lt;QNode&amp;gt; head = (phase &amp;amp; 1) == 0 ? evenQ : oddQ;
            QNode q = node.next = head.get();
            if ((q == null || q.phase == phase) &amp;amp;&amp;amp;
                (int)(state &amp;gt;&amp;gt;&amp;gt; PHASE_SHIFT) == phase) // avoid stale enq
                queued = head.compareAndSet(q, node);
        }
        else {
            try {
                // 当前线程进入阻塞状态，跟调用LockSupport.park()一样，等待被唤醒
                ForkJoinPool.managedBlock(node);
            } catch (InterruptedException ie) {
                node.wasInterrupted = true;
            }
        }
    }
    
    // 到这里说明节点所在线程已经被唤醒了
    if (node != null) {
        // 置空节点中的线程
        if (node.thread != null)
            node.thread = null;       // avoid need for unpark()
        if (node.wasInterrupted &amp;amp;&amp;amp; !node.interruptible)
            Thread.currentThread().interrupt();
        if (p == phase &amp;amp;&amp;amp; (p = (int)(state &amp;gt;&amp;gt;&amp;gt; PHASE_SHIFT)) == phase)
            return abortWait(phase); // possibly clean up on abort
    }
    // 唤醒当前阶段阻塞着的线程
    releaseWaiters(phase);
    return p;
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;增加一个参与者总体的逻辑为：&lt;/p&gt;
&lt;p&gt;（1）增加一个参与者，需要同时增加parties和unarrived两个数值，也就是state的中16位和低16位；&lt;/p&gt;
&lt;p&gt;（2）如果是第一个参与者，则尝试原子更新state的值，如果成功了就退出；&lt;/p&gt;
&lt;p&gt;（3）如果不是第一个参与者，则检查是不是在执行onAdvance()，如果是等待onAdvance()执行完成，如果否则尝试原子更新state的值，直到成功退出；&lt;/p&gt;
&lt;p&gt;（4）等待onAdvance()完成是采用先自旋后进入队列排队的方式等待，减少线程上下文切换；&lt;/p&gt;
&lt;h3 id=&quot;arriveandawaitadvance方法&quot;&gt;arriveAndAwaitAdvance()方法&lt;/h3&gt;
&lt;p&gt;当前线程当前阶段执行完毕，等待其它线程完成当前阶段。&lt;/p&gt;
&lt;p&gt;如果当前线程是该阶段最后一个到达的，则当前线程会执行onAdvance()方法，并唤醒其它线程进入下一个阶段。&lt;/p&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;public int arriveAndAwaitAdvance() {
    // Specialization of doArrive+awaitAdvance eliminating some reads/paths
    final Phaser root = this.root;
    for (;;) {
        // state的值
        long s = (root == this) ? state : reconcileState();
        // 当前阶段
        int phase = (int)(s &amp;gt;&amp;gt;&amp;gt; PHASE_SHIFT);
        if (phase &amp;lt; 0)
            return phase;
        // parties和unarrived的值
        int counts = (int)s;
        // unarrived的值（state的低16位）
        int unarrived = (counts == EMPTY) ? 0 : (counts &amp;amp; UNARRIVED_MASK);
        if (unarrived &amp;lt;= 0)
            throw new IllegalStateException(badArrive(s));
        // 修改state的值
        if (UNSAFE.compareAndSwapLong(this, stateOffset, s,
                                      s -= ONE_ARRIVAL)) {
            // 如果不是最后一个到达的，则调用internalAwaitAdvance()方法自旋或进入队列等待
            if (unarrived &amp;gt; 1)
                // 这里是直接返回了，internalAwaitAdvance()方法的源码见register()方法解析
                return root.internalAwaitAdvance(phase, null);
            
            // 到这里说明是最后一个到达的参与者
            if (root != this)
                return parent.arriveAndAwaitAdvance();
            // n只保留了state中parties的部分，也就是中16位
            long n = s &amp;amp; PARTIES_MASK;  // base of next state
            // parties的值，即下一次需要到达的参与者数量
            int nextUnarrived = (int)n &amp;gt;&amp;gt;&amp;gt; PARTIES_SHIFT;
            // 执行onAdvance()方法，返回true表示下一阶段参与者数量为0了，也就是结束了
            if (onAdvance(phase, nextUnarrived))
                n |= TERMINATION_BIT;
            else if (nextUnarrived == 0)
                n |= EMPTY;
            else
                // n 加上unarrived的值
                n |= nextUnarrived;
            // 下一个阶段等待当前阶段加1
            int nextPhase = (phase + 1) &amp;amp; MAX_PHASE;
            // n 加上下一阶段的值
            n |= (long)nextPhase &amp;lt;&amp;lt; PHASE_SHIFT;
            // 修改state的值为n
            if (!UNSAFE.compareAndSwapLong(this, stateOffset, s, n))
                return (int)(state &amp;gt;&amp;gt;&amp;gt; PHASE_SHIFT); // terminated
            // 唤醒其它参与者并进入下一个阶段
            releaseWaiters(phase);
            // 返回下一阶段的值
            return nextPhase;
        }
    }
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;arriveAndAwaitAdvance的大致逻辑为：&lt;/p&gt;
&lt;p&gt;（1）修改state中unarrived部分的值减1；&lt;/p&gt;
&lt;p&gt;（2）如果不是最后一个到达的，则调用internalAwaitAdvance()方法自旋或排队等待；&lt;/p&gt;
&lt;p&gt;（3）如果是最后一个到达的，则调用onAdvance()方法，然后修改state的值为下一阶段对应的值，并唤醒其它等待的线程；&lt;/p&gt;
&lt;p&gt;（4）返回下一阶段的值；&lt;/p&gt;
&lt;h2 id=&quot;总结&quot;&gt;总结&lt;/h2&gt;
&lt;p&gt;（1）Phaser适用于多阶段多任务的场景，每个阶段的任务都可以控制得很细；&lt;/p&gt;
&lt;p&gt;（2）Phaser内部使用state变量及队列实现整个逻辑【本篇文章由公众号“彤哥读源码”原创，请支持原创，谢谢！】；&lt;/p&gt;
&lt;p&gt;（3）state的高32位存储当前阶段phase，中16位存储当前阶段参与者（任务）的数量parties，低16位存储未完成参与者的数量unarrived；&lt;/p&gt;
&lt;p&gt;（4）队列会根据当前阶段的奇偶性选择不同的队列；&lt;/p&gt;
&lt;p&gt;（5）当不是最后一个参与者到达时，会自旋或者进入队列排队来等待所有参与者完成任务；&lt;/p&gt;
&lt;p&gt;（6）当最后一个参与者完成任务时，会唤醒队列中的线程并进入下一个阶段；&lt;/p&gt;
&lt;h2 id=&quot;彩蛋&quot;&gt;彩蛋&lt;/h2&gt;
&lt;p&gt;Phaser相对于CyclicBarrier和CountDownLatch的优势？&lt;/p&gt;
&lt;p&gt;答：优势主要有两点：&lt;/p&gt;
&lt;p&gt;（1）Phaser可以完成多阶段，而一个CyclicBarrier或者CountDownLatch一般只能控制一到两个阶段的任务；&lt;/p&gt;
&lt;p&gt;（2）Phaser每个阶段的任务数量可以控制，而一个CyclicBarrier或者CountDownLatch任务数量一旦确定不可修改。&lt;/p&gt;
&lt;h2 id=&quot;推荐阅读&quot;&gt;推荐阅读&lt;/h2&gt;
&lt;p&gt;1、&lt;a href=&quot;https://mp.weixin.qq.com/s/gdQpO7kqnWT41gFd4vXTlQ&quot;&gt;死磕 java同步系列之开篇&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;2、&lt;a href=&quot;https://mp.weixin.qq.com/s/0s-u-MysppIaIHVrshp9fA&quot;&gt;死磕 java魔法类之Unsafe解析&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;3、&lt;a href=&quot;https://mp.weixin.qq.com/s/jownTN--npu3o8B4c3sbeA&quot;&gt;死磕 java同步系列之JMM（Java Memory Model）&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;4、&lt;a href=&quot;https://mp.weixin.qq.com/s/TROZ4BhcDImwHvhAl_I_6w&quot;&gt;死磕 java同步系列之volatile解析&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;5、&lt;a href=&quot;https://mp.weixin.qq.com/s/RT7VreIh9PU03HhE3WSLjg&quot;&gt;死磕 java同步系列之synchronized解析&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;6、&lt;a href=&quot;https://mp.weixin.qq.com/s/1RU5jh7UcXGtKlae8tusVA&quot;&gt;死磕 java同步系列之自己动手写一个锁Lock&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;7、&lt;a href=&quot;https://mp.weixin.qq.com/s/nAqgec8GscULz6DkkYFINg&quot;&gt;死磕 java同步系列之AQS起篇&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;8、&lt;a href=&quot;https://mp.weixin.qq.com/s/52Ib23kbmqqkWAZtlZF-zA&quot;&gt;死磕 java同步系列之ReentrantLock源码解析（一）——公平锁、非公平锁&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;9、&lt;a href=&quot;https://mp.weixin.qq.com/s/iipAVWynBUZazhSvBwMB5g&quot;&gt;死磕 java同步系列之ReentrantLock源码解析（二）——条件锁&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;10、&lt;a href=&quot;https://mp.weixin.qq.com/s/o8ZFXDoKhj237SsrqGeJPQ&quot;&gt;死磕 java同步系列之ReentrantLock VS synchronized&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;11、&lt;a href=&quot;https://mp.weixin.qq.com/s/aOQwZ0S8at-64xIXo8fLfA&quot;&gt;死磕 java同步系列之ReentrantReadWriteLock源码解析&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;12、&lt;a href=&quot;https://mp.weixin.qq.com/s/ft0_PU7Tgz7920yKy-xisQ&quot;&gt;死磕 java同步系列之Semaphore源码解析&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;13、&lt;a href=&quot;https://mp.weixin.qq.com/s/QHFXKVybKz_iwgC8reGfPQ&quot;&gt;死磕 java同步系列之CountDownLatch源码解析&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;14、&lt;a href=&quot;https://mp.weixin.qq.com/s/QHFXKVybKz_iwgC8reGfPQ&quot;&gt;死磕 java同步系列之AQS终篇&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;15、&lt;a href=&quot;https://mp.weixin.qq.com/s/6RaFax0ivM6UoDdo5qhtwQ&quot;&gt;死磕 java同步系列之StampedLock源码解析&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;16、&lt;a href=&quot;https://mp.weixin.qq.com/s/liFpAAwzQF1PECWYUBVpCg&quot;&gt;死磕 java同步系列之CyclicBarrier源码解析&lt;/a&gt;&lt;br/&gt;【本篇文章由“彤哥读源码”原创，请支持原创，谢谢！】&lt;/p&gt;
</description>
<pubDate>Tue, 01 Oct 2019 00:18:00 +0000</pubDate>
<dc:creator>彤哥读源码</dc:creator>
<og:description>问题 （1）Phaser是什么？ （2）Phaser具有哪些特性？ （3）Phaser相对于CyclicBarrier和CountDownLatch的优势？ 简介 Phaser，翻译为阶段，它适用于这</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/tong-yuan/p/11614755.html</dc:identifier>
</item>
<item>
<title>Sentinel Cluster流程分析 - 啊驼</title>
<link>http://www.cnblogs.com/cxyAtuo/p/11614749.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/cxyAtuo/p/11614749.html</guid>
<description>&lt;p&gt; 前面介绍了sentinel-core的流程，提到在进行流控判断时，会判断当前是本地限流，还是集群限流，若是集群模式，则会走另一个分支，这节便对集群模式做分析。&lt;/p&gt;
&lt;h4 id=&quot;一.基本概念&quot;&gt;一.基本概念&lt;/h4&gt;
&lt;p&gt; namespace：限流作用于，用于区分一个规则作用于什么范围&lt;/p&gt;
&lt;p&gt; flowId：代表全局唯一的规则 ID，Sentinel 集群限流服务端通过此 ID 来区分各个规则，因此务必保持全局唯一。一般 flowId 由统一的管控端进行分配，或写入至 DB 时生成。&lt;/p&gt;
&lt;p&gt; thresholdType：代表集群限流阈值模式。其中单机均摊模式下配置的阈值等同于单机能够承受的限额，token server 会根据客户端对应的 namespace（默认为 project.name 定义的应用名）下的连接数来计算总的阈值（比如独立模式下有 3 个 client 连接到了 token server，然后配的单机均摊阈值为 10，则计算出的集群总量就为 30）；而全局模式下配置的阈值等同于整个集群的总阈值。&lt;/p&gt;
&lt;h4 id=&quot;二.通信框架&quot;&gt;二.通信框架&lt;/h4&gt;
&lt;p&gt; sentinel-cluster基于netty提供了一套远程通信框架，分为客户端和服务，其使用了jdk自带的SPI，提供了一些接口的默认实现。如下图为sentinel-cluster-client客户端模块的默认实现类。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1812801/201910/1812801-20191001081022392-908269327.jpg&quot; alt=&quot;file&quot;/&gt;&lt;/p&gt;
&lt;p&gt; InitFunc的加载是通过InitExecutor加载的，InitExecutor在sentinel-core模块中。InitExecutor会在全局访问内加载所有InitFunc的实现类，并调用其init方法完成初始化。该模块中配置的InitFunc实现类为DefaultClusterClientInitFunc，该类会初始化通信协议中各种类型的编码和解码处理类。编解码器将调用注册工厂RequestDataWriterRegistry和ResponseDataDecodeRegistry的方法进行注册，供后续使用。系统提供了PING,FLOW（流控）和PARAM_FLOW（热点参数流控）三种编解码器。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1812801/201910/1812801-20191001081022737-41266083.jpg&quot; alt=&quot;file&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1812801/201910/1812801-20191001081022979-1916034784.jpg&quot; alt=&quot;file&quot;/&gt;&lt;/p&gt;
&lt;p&gt; 上图为sentinel-cluster的通信协议格式，请求和响应中有个4个字节的消息id和1个字节的消息类型，剩下的就是消息体，对于响应格式，有1个字节的状态信息。需要说明的是，在初始化Netty客户端时，增加了两个filter：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1812801/201910/1812801-20191001081023276-210108069.jpg&quot; alt=&quot;file&quot;/&gt;&lt;/p&gt;
&lt;p&gt; 也就是说在发送一个消息时，会自动加上长度为2个字节的消息长度头部，在读取时也会自动省略2个字节的消息长度头部。&lt;br/&gt;为了解析上面的消息格式，在提供了注册方法之上，sentinel还提供了ClientEntityCodeProvider，统一了报文的处理。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1812801/201910/1812801-20191001081023541-1650095362.jpg&quot; alt=&quot;file&quot;/&gt;&lt;/p&gt;
&lt;p&gt; 如上，该类在static静态代码块中进行了初始化，使用SPI，获取RequestEntityWriter和ResponseEntityDecoder的实现类，这两种实现类也在该模块中指定了默认实现：DefaultResponseEntityDecoder和DefaultRequestEntityWriter。即处理过程为&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;
ClientEntityCodecProvider-&amp;gt;ResponseEntityDecoder-&amp;gt;ResponseDataDecodeRegisty-&amp;gt; EntityDecoder

ClientEntityCodecProvider-&amp;gt;RequestEntityWriter-&amp;gt;RequestDataWriterRegisty-&amp;gt; EntityWriter
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt; 系统还提供了TokenClientHandler类，用于响应数据流，进行相应的处理&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1812801/201910/1812801-20191001081024101-1995813164.jpg&quot; alt=&quot;file&quot;/&gt;&lt;/p&gt;
&lt;p&gt; 如上只列出了比较重要的属性和方法。该类继承了ChannelInboundHandlerAdapter并实现了对应的方法，currentState属性用于标记客户端当前的状态，disconnectCallback则用于负责在断线时进行重连。TokenClientHandler实现channelActive方法，会在连接建立时会发送PING请求给服务端；实现channelUnregistered方法，会在连接断开时调用disconnectCallback，在一定时间后进行重连，等待时间跟失败次数有关；实现channelRead方法，会在有响应数据时，接收响应内容，并进行处理，处理流程如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1812801/201910/1812801-20191001081024338-867049854.jpg&quot; alt=&quot;file&quot;/&gt;&lt;/p&gt;
&lt;p&gt; 在经过Netty处理解析为消息类型对象后，会判断该响应的类型，如果是PING消息的响应，则直接输出日志，否则将从TokenClientPromiseHolder中根据消息id设置对应的响应内容，以便消息发送线程能够获得响应。&lt;br/&gt; 上面提到的TokenClientPromiseHolder用于缓存请求消息。如下图，发送消息后，会获取对应的ChannelPromise对象，并根据消息存于TokenClientPromiseHolder中。ChannelPromise会等待Netty请求响应回来，对应的流程如上面InBound流程。在请求正常响应后，会根据消息id再从TokenClientPromiseHolder中获取对应的响应结果。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1812801/201910/1812801-20191001081024831-44734890.jpg&quot; alt=&quot;file&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1812801/201910/1812801-20191001081025158-1078838708.jpg&quot; alt=&quot;file&quot;/&gt;&lt;/p&gt;
&lt;p&gt; Cluster模块的核心接口为TokenService ，ClusterTokenServer和ClusterTokenClient。其中ClusterTokenClient内部主要类为NettyTransportClient，在上面已经进行了说明，下面说下其他两个接口。TokenService ，ClusterTokenServer在模块中的关系如下图：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1812801/201910/1812801-20191001081025696-1360482457.jpg&quot; alt=&quot;file&quot;/&gt;&lt;/p&gt;
&lt;p&gt; 其中接口都由SPI给出了默认的实现，如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1812801/201910/1812801-20191001081026964-1494400737.jpg&quot; alt=&quot;file&quot;/&gt;&lt;/p&gt;
&lt;p&gt; 下面对涉及到的接口和类进行说明。&lt;/p&gt;
&lt;p&gt; TokenService：token服务接口，提供了requestToken和requestParamToken方法，分别表示获取流控令牌和获取热点参数令牌。提供的默认实现为DefaultTokenService，会在TokenServiceProvider初始化时使用SPI进行加载。&lt;/p&gt;
&lt;p&gt; ClusterTokenServer：服务端上层接口，提供了start和stop方法用于服务端的启动和停止。&lt;/p&gt;
&lt;p&gt; NettyTransportServer：ClusterTokenServer的netty实现，同客户端对应，有如下的pipeline配置&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1812801/201910/1812801-20191001081027303-441167354.jpg&quot; alt=&quot;file&quot;/&gt;&lt;/p&gt;
&lt;p&gt; 其中编解码器的处理同客户端类似，只是增加了服务端的处理器：TokenServerHandler。TokenServerHandler继承自ChannelInboundHandlerAdapter用以在连接建立和有数据交互时进行相应的处理：&lt;/p&gt;
&lt;ol readability=&quot;1.5&quot;&gt;&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;实现channelActive：在连接建立时将其缓存起来&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;实现channelInactive：在连接断开时移除缓存&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;2&quot;&gt;
&lt;p&gt;实现channelRead：在有数据到来时，进行处理。这里会使用RequestProcessorProvider加载的RequestProcessor实现类，根据请求的类型(type字段)选择相应的处理类进行处理。系统现在提供的处理类有FlowRequestProcessor和ParamFlowRequestProcessor，这两者最后都将通过TokenServiceProvider获得DefaultTokenService对象，调用其来完成请求。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt; SentinelDefaultTokenServer：包装了NettyTransportServer方法，增加了ServerTransportConfigObserver用于监听服务端配置项的更改，从而更新自身。&lt;/p&gt;
&lt;p&gt; EmbeddedClusterTokenServer：继承自TokenService和ClusterTokenServer，用于内嵌服务端模式，默认实现为DefaultEmbeddedClusterTokenServer。&lt;/p&gt;
&lt;p&gt; DefaultEmbeddedClusterTokenServer：主要组合了DefaultTokenService和SentinelDefaultTokenServer对象用以实现接口方法。&lt;/p&gt;
&lt;p&gt; 结合上面服务端的实现，可以得到客户端请求一个token的流程如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1812801/201910/1812801-20191001081027590-70236915.jpg&quot; alt=&quot;file&quot;/&gt;&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;客户端调用DefaultClusterTokenClient的requestToken方法获取token，其内部会委托NettyTransportClient编码后发给服务端&lt;/li&gt;
&lt;li&gt;服务端NettyTransportServer收到请求后，由TokenServerHandler的channelRead方法处理这里会根据请求内容中的type，委托给对应的消息处理处理，如FlowRequestProcessor&lt;/li&gt;
&lt;li&gt;FlowRequestProcessor会调用TokenServiceProvider获取对应的TokenService实现类，默认为DefaultTokenService。然后委托为该类进行处理。&lt;/li&gt;
&lt;/ol&gt;&lt;h4 id=&quot;三.统计逻辑&quot;&gt;三.统计逻辑&lt;/h4&gt;
&lt;p&gt; 由上可知，cluster模式下，token的获取是由DefaultTokenService来负责的，分为两种：普通流控和热点参数流控。二者的实现基本一致，这里只对普通流控做讲解，即DefaultTokenService中的requestToken方法，如下为处理流程。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1812801/201910/1812801-20191001081027833-1553628033.jpg&quot; alt=&quot;file&quot;/&gt;&lt;/p&gt;
&lt;p&gt; 当请求requestToken方法时，请求参数包括:&lt;/p&gt;
&lt;p&gt; ruleId：规则id&lt;/p&gt;
&lt;p&gt; acquireCount：需要获取的token数&lt;/p&gt;
&lt;p&gt; prioritized：是否支持优先&lt;/p&gt;
&lt;ol readability=&quot;5.5&quot;&gt;&lt;li readability=&quot;1&quot;&gt;
&lt;p&gt;DefaultTokenService会先根据ruleId，使用ClusterFlowRuleManager获得对应的FlowRule规则对象。ClusterFlowRuleManager会在更新规则或者加载规则时根据ruleId缓存在Map中，且分配唯一一个ClusterMetric。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;获得对应的FlowRule对象后，会调用ClusterFlowRuleChecker，判断是否能够获取所需要的token&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;2&quot;&gt;
&lt;p&gt;ClusterFlowRuleChecker会先根据规则Id获得该规则所对应的namespace，然后判断该namespace在全局状态下是否超过流控，该步骤主要由GlobalRequestLimiter提供，该类存储着各个namespace对应的RequestLimiter对象。RequestLimiter继承自LeapArray，只提供了QPS一个维度的滑动窗口实现，默认实现为一秒内10个格子，如下图。全局流控主要使用RequestLimiter的tryPass方法，计算当前qps是否大于规则设定的全局qps。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;2&quot;&gt;
&lt;p&gt;全局流控通过后，会根据ClusterMetricStatistics获取ruleId对应的ClusterMetric，以获取ruleId对应的统计维度。首先会判断当前时间是否有可用的token，这里会根据规则设定的thresholdType，区分设定的阈值模式，如果是全局模式，直接根据设定的值进行限流，如果是单机均摊模式，会将该值乘上已有的额客户端数达到设定的阈值。如果有则更新统计信息并返回成功，如果没有且不支持优先，则直接返回获取失败。如果支持优先，则尝试从下一个格子借用token(注：本地模式的借用会从后面的格子借用，只要不超过最大的等待时间)，如果借用成功则更新统计信息并返回成功，否则返回失败。ClusterMetric的结构如下，继承自ClusterMetriceLeapArray，该滑动窗口提供了cluster模式下多种模式的统计数据，还支持请求优先。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1812801/201910/1812801-20191001081028379-1315453534.jpg&quot; alt=&quot;file&quot;/&gt;&lt;/p&gt;
&lt;h4 id=&quot;四.服务端启动模式&quot;&gt;四.服务端启动模式&lt;/h4&gt;
&lt;p&gt; Sentinel服务端启动模式可以分为Alone独立模式和Embedded嵌入模式。&lt;/p&gt;
&lt;p&gt; 独立模式（Alone），即作为独立的 token server 进程启动，独立部署，隔离性好，但是需要额外的部署操作。独立模式适合作为 Global Rate Limiter 给集群提供流控服务。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1812801/201910/1812801-20191001081028873-1042461919.jpg&quot; alt=&quot;file&quot;/&gt;&lt;/p&gt;
&lt;ol readability=&quot;1&quot;&gt;&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;在独立模式下，我们可以直接创建对应的 ClusterTokenServer 实例并在 main 函数中通过 start 方法启动 Token Server。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;2&quot;&gt;
&lt;p&gt;嵌入模式（Embedded），即作为内置的 token server 与服务在同一进程中启动。在此模式下，集群中各个实例都是对等的，token server 和 client 可以随时进行转变，因此无需单独部署，灵活性比较好。但是隔离性不佳，需要限制 token server 的总 QPS，防止影响应用本身。嵌入模式适合某个应用集群内部的流控。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1812801/201910/1812801-20191001081029435-1445652876.jpg&quot; alt=&quot;file&quot;/&gt;&lt;/p&gt;
&lt;p&gt; 系统提供了 HTTP API 用于在 embedded 模式下转换集群流控身份：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;http://&amp;lt;ip&amp;gt;:&amp;lt;port&amp;gt;/setClusterMode?mode=&amp;lt;xxx&amp;gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt; 其中 mode 为 0 代表 client，1 代表 server，-1 代表关闭。&lt;/p&gt;
&lt;p&gt; 该请求会由ModifyClusterModeCommandHandler处理并最终调用ClusterStateManager.applyState方法来设置当前节点的状态。需要说明的是，嵌入模式可以不用显示启动服务端，而是由上面的applyState模式来设置，该方法会在内部启动服务。当然也可以不显示启动客户端，同样通过上面的方法，可以将当前节点设置为客户端模式。在将当前节点设置为客户端时，会先获取当前嵌入模式下的服务端对象，如果不为空，则停止该对象，并启动服务端；反之在设置服务端时，会先获取客户端对象，如果不为空，则先停掉，再启动嵌入模式下服务端对象。应用启动接入dashboard后，可以通过管理台来控制各节点的角色，或者通过从配置中心加载规则来更改规则。&lt;/p&gt;
&lt;h4 id=&quot;五.handler&quot;&gt;五.Handler&lt;/h4&gt;
&lt;p&gt; sentinel-transport-common中定义了一套handler接口，用于对外提供HTTP接口同系统交互，从而能够获取系统数据或者对应用节点下发命令。&lt;/p&gt;
&lt;p&gt; common模块提供了如下几个基本接口:&lt;/p&gt;
&lt;ol readability=&quot;2.5&quot;&gt;&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;CommandCenter：命令中心，作为服务启动，定义了start和stop方法，主要提供handler的初始化和注册服务。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;HeartbeatSender：心跳发送接口，用于给控制台dashboard定时发送心跳&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;CommandHandler：请求处理接口，请求对象为CommandRequest，响应对象为CommandResponse&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;CommandMapping：注解，用于为Handler添加元数据，包括处理器名(URL路径名)和描述&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1812801/201910/1812801-20191001081029976-1809434063.jpg&quot; alt=&quot;file&quot;/&gt;&lt;/p&gt;
&lt;p&gt; 针对上面的接口，common模块提供了相对应的Provider类，用于以SPI的方式加载默认/自定义的实现，如上图，包括：&lt;/p&gt;
&lt;ol readability=&quot;2&quot;&gt;&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;CommandCenterProvider：根据SPI，加载设定的实现，如果有多个实现，则根据Order注解，选择优先级最高的一个&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;HeartbeatSenderProvider：根据SPI，加载设定的实现，如果有多个实现，则根据Order注解，选择优先级最高的一个&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;1&quot;&gt;
&lt;p&gt;CommandHandlerProvider：会加载所有的Handler实现类，不同模块提供的Handler实现只要以SPI的方式，在META-INF中提供对应的全限定名就会被该类扫描并使用。实现类需要增加CommandMapping注解以指定URL。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt; 如下为common模块提供的Handler实现&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1812801/201910/1812801-20191001081030391-1598137671.jpg&quot; alt=&quot;file&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1812801/201910/1812801-20191001081031475-2118262689.jpg&quot; alt=&quot;file&quot;/&gt;&lt;/p&gt;
&lt;p&gt; 上图中common的SPI接口中还有一个InitFunc实现，包括CommandCenterInitFunc和HeartbeatSenderInitFunc两个实现类，这两个类实现了InitFunc接口，会在InitExecutor被调用时初始化所有的InitFunc实现。对应的作用为：&lt;/p&gt;
&lt;p&gt; CommandCenterInitFunc：使用CommandCenterProvider获取对应的CommandCenter实现，依次执行beforeStart和start方法，以启动服务。即只要加载了sentinel-transport-common模块并通过SPI提供CommandCenter的实现，便会在InitFunc被调用时启动服务。&lt;/p&gt;
&lt;p&gt; HeartbeatSenderInitFun：HeartbeatSenderProvider获取对应的HeartbeatSender实现，启动定时器，每隔5秒执行一次sendHeartbeat方法。即只要加载了sentinel-transport-common模块并通过SPI提供HeartbeatSender的实现，便会在InitFunc被调用时启动心跳定时器。&lt;/p&gt;
&lt;p&gt; 上面提到，只要提供了CommandCenter和HeartbeatSender的实现，并通过SPI注册对应的实现，并会自动启动对应的服务，而位于sentinel-transport-simple-http和sentinel-transport-netty的模块为这两个接口提供了默认实现。&lt;/p&gt;
&lt;p&gt; sentinel-transport-simple-http提供的实现为SimpleHttpCommandCenter和SimpleHttpHeartbeatSender。&lt;/p&gt;
&lt;p&gt; SimpleHttpCommandCenter：基于socket，以阻塞模式提供了简单的http服务器，会在启动前通过CommandHandlerProvider缓存所有的Handler对象，当请求进来时新开线程处理，并在线程中调用对应的Handler进行处理并返回&lt;/p&gt;
&lt;p&gt; SimpleHttpHeartbeatSender：使用内建的SimpleHttpRequest向dashboard发送Http心跳请求&lt;/p&gt;
&lt;p&gt; sentinel-transport-netty提供的实现为NettyHttpCommandCenter和HttpHeartbeatSender。&lt;/p&gt;
&lt;p&gt; NettyHttpCommandCenter：基于netty，以服务端模式启动，会在启动前通过CommandHandlerProvider缓存所有的Handler对象，内建的HttpServerHandler对象会在请求进来时获取解码后的对象，并根据请求类型调用对应的Handler进行处理并返回&lt;/p&gt;
&lt;p&gt; HttpHeartbeatSender：使用httpclient客户端想dashboard发送Http心跳请求&lt;/p&gt;
&lt;p&gt; 综上，sentinel-cluster-server-default模块提供了如下的Handelr实现，用于给dashboard提供集群信息并接受从dashboard发送过来的命令。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1812801/201910/1812801-20191001081031865-1391330340.jpg&quot; alt=&quot;file&quot;/&gt;&lt;/p&gt;
&lt;p&gt; 其中Fetch开头的为读取消息，Modify开头的为修改系统消息。&lt;/p&gt;
&lt;h4 id=&quot;六.集群管理接口&quot;&gt;六.集群管理接口&lt;/h4&gt;
&lt;p&gt; Sentinel预留了诸多管理接口，用于动态加载规则或者配置，然后更新本地的状态，这里对涉及到cluster模式下的几个管理接口进行说明。在这之前，先介绍下demo中以Nacos为配置中心的接入方式。&lt;/p&gt;
&lt;p&gt; 接入Nacos涉及到另外两个模块,sentinel-datasource-extension和sentinel-datasource-nacos。Extension模块定义了ReadableDataSource接口，用于从数据源读取数据，返回配置数据SentinelProperty。Extension模块提供了一个抽象类实现AbstractDataSource，实现了loadConfig方法。该类引入了Converter接口和DynamicSentinelProperty类，Converter接口用于将数据源中读取的数据结构转换为SentienlProperty存储的数据格式；DynameicSentinelProperty类为SentinelPorperty的默认实现，该类能够添加多个PropertyListener监听器，在添加时触发监听器的configLoad方法进行监听器的初次动作，并在数据发生变更时，逐个通知监听器，调用监听器的configLoad方法，提醒监听器进行更新。AbstractDataSource实现了loadConfig方法，该方法会调用readSource方法，从数据源读取原始数据，并调用Converter进行数据转换。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1812801/201910/1812801-20191001081032134-454297001.jpg&quot; alt=&quot;file&quot;/&gt;&lt;/p&gt;
&lt;p&gt; Nacos模块提供了NacosDataSource实现，继承自AbstractDataSource，以接入Nacos配置中心。NacosDataSource在初始化时会在Nacos上申请一个配置集，并添加监听器，然后执行一遍loadConfig，从配置中心加载一遍配置并，更新property中的值并通知配置集上的监听器。Nacos上的监听器会在配置发生变化时，调用Convert记性处理，并更新配置集，同时通知配置集上的监听器。&lt;/p&gt;
&lt;p&gt; 由上可知，可以通过使用DynamicSentinelProperty动态配置集上的监听器，配合数据眼监听配置变化，从而让系统做出相应的动作。事实上，sentinel内置的大部分管理接口都是这样处理的，如下为集群相关的主要管理接口，均以Manager结尾。这些管理接口的结构都同FlowRuleManager一样，内部维护这一个或者多个配置源，并在配置源上设置了监听器，当配置源有数据变化时，会调用配置源的updateValue方法，更新配置源数据并且通知监听器。&lt;/p&gt;
&lt;ol readability=&quot;24.5&quot;&gt;&lt;li readability=&quot;1&quot;&gt;
&lt;p&gt;FlowRuleManager&lt;/p&gt;
&lt;p&gt; 这个在讲解sentinel-core模块时有介绍过，主要是存储本地限流规则集SentinelProperty&amp;lt;List&amp;gt;。该规则集上有FlowPropertyListener监听器，会在规则发生变更时重新构建，加载规则。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;ParamFlowRuleManager&lt;/p&gt;
&lt;p&gt; 同FlowRuleManager，主要用于热点参数限流规则管理。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;10&quot;&gt;
&lt;p&gt;ClusterClientConfigManager&lt;/p&gt;
&lt;p&gt; 集群客户端配置管理，主要管理：&lt;/p&gt;
&lt;p&gt;1) 集群客户端配置，用于设定客户端超时时间，配置集为SentinelProperty和监听器ClientConfigPropertyListener。会在规则发生变更时，更新客户端的请求超时时间&lt;/p&gt;
&lt;p&gt;2) 集群服务端信息配置，用于设定服务端的ip和端口信息，配置集为SentinelProperty和监听器ClientAssignPropertyListener。会在规则发送变更时，更新本地配置，并通知ServerChangeObserver观察者服务端节点发送了变化，由之前的内容可以看到，DefaultClusterTokenClient为该接口的观察者，会在服务端信息发送变更时先断开同之前的链接，再同心的服务端节点建立新的链接。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;15&quot;&gt;
&lt;p&gt;ClusterServerConfigManager&lt;/p&gt;
&lt;p&gt; 集群服务端配置管理，主要管理：&lt;/p&gt;
&lt;p&gt;1) 集群服务端传输配置，用于设定服务端端口和idle时间，配置集为SentinelProperty和监听器ServerGlobalTransportPropertyListener。会在规则发生变更时，更新本地配置，并通知ServerTransportConfigObserver观察者配置发生了变化。由之前的内容可以看到，SentinelDefaultTokenServer为该接口的观察者，会在服务端信息发送变更时，停止自身应用，再重新启动。&lt;/p&gt;
&lt;p&gt;2) 集群服务端全局流控配置，用于设定全局流控配置项，包括滑动窗口实现大小，窗口格子数，允许通过的最大qps等。配置集为SentinelProperty和监听器ServerGlobalFlowPropertyListener，会在规则更新时重新设置这些配置内容。&lt;/p&gt;
&lt;p&gt;3) 集群服务端namespace集合配置，用于设定集群中的namespace集合，配置集为SentinelProperty&amp;lt;Set&amp;gt;和监听器ServerNamespaceSetPropertyListener，会在配置发生变更时移除老namesapce的配置，并重新载入新namesapce的配置，包括对应的全局限流器GlobalRequestLimiter，集群限流规则，集群热点限流规则。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;4&quot;&gt;
&lt;p&gt;ClusterFlowRuleManager&lt;/p&gt;
&lt;p&gt; 集群限流规则配置管理，主要管理：&lt;/p&gt;
&lt;p&gt;1) 集群规则配置，用于设定集群规则，配置集为SentinelProperty&amp;lt;List&amp;gt;和监听器FlowRulePropertyListener，会在配置发生变更时，移除对应namespace下的缓存的配置，并重新构建对应的规则。对于一个新的flowId，会为其分配一个对应的ClusterMetricStatistics统计节点。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;1&quot;&gt;
&lt;p&gt;ClusterParamFlowRuleManager&lt;/p&gt;
&lt;p&gt; 集群热点限流规则配置管理，同ClusterFlowRuleManager&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;4&quot;&gt;
&lt;p&gt;ClusterStateManager&lt;/p&gt;
&lt;p&gt; 集群全局状态管理，主要管理：&lt;/p&gt;
&lt;p&gt;1) 本机角色配置，配置集为SentinelProperty和监听器ClusterStatePropertyListener，会在规则发生变更时，调整本机的角色。角色包括：服务端，客户端和非集群模式。若规则为非集群模式，则会停止相关的客户端或者服务端；若设置为服务端模式，则会使用嵌入模式启动服务，若之前为客户端则会关闭客户端连接；若设置为客户端模式，则会启动客户端连接，若之前为服务端则会停止服务。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt; 上述几个管理接口都可以接入配置中心如Nacos，以通过配置中心和管理台来改变各配置项。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1812801/201910/1812801-20191001081033352-1204420263.jpg&quot; alt=&quot;file&quot;/&gt;&lt;/p&gt;
&lt;p&gt;个人公众号：啊驼&lt;/p&gt;
</description>
<pubDate>Tue, 01 Oct 2019 00:11:00 +0000</pubDate>
<dc:creator>啊驼</dc:creator>
<og:description>&amp;emsp;前面介绍了sentinel core的流程，提到在进行流控判断时，会判断当前是本地限流，还是集群限流，若是集群模式，则会走另一个分支，这节便对集群模式做分析。 一.基本概念 &amp;emsp;n</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/cxyAtuo/p/11614749.html</dc:identifier>
</item>
<item>
<title>[Job] 找工作小结 - listenviolet</title>
<link>http://www.cnblogs.com/shiyublog/p/11612061.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/shiyublog/p/11612061.html</guid>
<description>&lt;p&gt;有近2个月没有更新博客，主要精力放在了投递会议论文和秋招找工作方面。这里简单总结一下秋招面试的几点建议和感受。&lt;/p&gt;
&lt;p&gt;投递的主要是NLP算法工程师岗位，主要参加过面试的公司有腾讯(春招)，蚂蚁金服(春招)，追一科技，猿辅导，作业帮，依图科技，京东、拼多多、星图科技(校园宣讲面试，是否通过以及后续面试安排需要到10月份)、明略科技、还有工商银行(校内宣讲面试，银行正式笔试面试要到10月份)。&lt;/p&gt;
&lt;p&gt;这些公司的笔经面经牛客网等很多网站上有前辈的分享，我也不再赘述，只是总结一下自己的感想。&lt;/p&gt;
&lt;h2&gt;1.要有自己的东西&lt;/h2&gt;
&lt;p&gt;应聘算法工程师非常重要的一点是要有自己的东西。我把这点放在第一点来说，是想强调它的重要性。我了解的很多同学，包括我自己，前期花费了很多精力去看别人的论文和算法模型，去了解这些模型可能work的原因，甚至看有些书、面经之类的把它们当做“标准答案”来记，和&quot;应试&quot;差不多。&lt;/p&gt;
&lt;p&gt;但是，你看的再多，也都是别人的东西，自己的东西呢？很简单的道理，看论文就和看小说一样简单，但是 思考、形成自己的算法模型、验证、试错、改进、完善的整个过程于自己才是真实的收获，这更是能力的体现。在我看来，这也是一位算法工程师的本分，那就是不仅要有学习能力，更要有的是 分析、思考、形成解决方案的能力。而不是知道很多别人的模型，生搬硬套的能力。&lt;/p&gt;
&lt;p&gt;这点在面试中很重要，面试官会感兴趣你做了什么，解决或改进了什么，怎么做的，这么做的道理在哪里，有没有其他可能的方法，这些方法各自的优缺点是什么...? 当然看似这一串问题，都很简单，如果是自己认真思考反复验证过的算法，这些都是已经考虑过验证过的问题。那么这些看起来难的问题，实则是自己算法能力、实践能力的体现，逻辑清晰、实验充分的回答会为自己加分。(另外把这些都分析到位，会占用大量的面试时间，也会给面试官留下一个好印象；并且如果后面考代码或者逻辑问题、底层问题面试官要求也不会非常苛刻。第一印象很重要。)&lt;/p&gt;
&lt;p&gt;另外我想说的是，有一些书籍、面经、博客中对于经典算法的理解也可能是错误的，学习时候要有自己的思考，让算法思想为我所用，而不是当做标准答案来背，这是非常遗憾的，甚至浪费时间、产生算法思路上误导的。有这些背答案的时间还不如让大家多思考做好自己的工作。(举个简单的例子，XGBoost，与GDBT的对比，GBDT是率先使用二阶导数的，XGBoost沿用了GDBT的算法思想也采用了二阶导数，并不是面经中讲的 &quot;GDBT只使用了一阶导XGBoost用了二阶&quot;。建议直接看论文。)&lt;/p&gt;
&lt;h2&gt;2. 知道公司需要什么&lt;/h2&gt;
&lt;p&gt;并不是很多公司都像大学一样抱着教育你、培养你、发现你未知的潜能的态度来招人，除非这个岗缺人，否则很多公司很看重你现在是否具备直接干活的能力。这是公平合理的。如果想拿到公司付的薪水，需要知道公司需要什么，自己可以做什么，即使研究生期间没有深入研究公司现主要业务内容，在面试前也需要提前做好准备。即使没能非常expert in，也最好对最基本的架构、常用的算法、模型、工具有了解。&lt;/p&gt;
&lt;p&gt;比如，追一科技现阶段NLP的主要业务时对话系统，考虑企业产品上线可交付性等，一般并不会采用端到端模型而是pipe line，那么前期可以对对话系统各模块要解决的问题、主要算法等有所了解；京东商城主要做商品评价打分，主要用到情感分析、文本分类等，面试前可以了解一些，另外二面面试官问到了正则化、调参、spark，其实面试官喜欢问的一般都是他们业务中经常用的，如果前期了解他们的业务可以有针对性做更好的准备。依图科技只参加了一面，公司更注重算法编程能力，就是手撕代码的能力，对于应聘者的项目经历一笔带过。依图面试官问的我本科时期做的涉及CV的项目，我感觉很奇怪，自以为是认为体现不出NLP能力，问面试官换了讲NLP的内容。后来发现他并不了解，原来面试官是做CV的... &lt;/p&gt;
&lt;p&gt;讲这么多，是想说，要站在面试官的角度看问题。面试不是自己作秀，是为自己找买家。无论是第1点“有自己的东西”说的再好，也是为第2点服务的，那就是如果体现自己能胜任这份工作。知道公司需要什么，自己有什么，没有的话前期补一些什么，需要做好充足的准备。在交流方面，面试官一般会优先挑你所做的课题中和业务更相关的课题问，不仅因为业务需要，更因为他懂。大部分人会倾向于了解自己已经了解过一点的东西，面试官也有这个心理。&lt;/p&gt;
&lt;h2&gt;3. 基本功扎实&lt;/h2&gt;
&lt;p&gt;面试时主要考察的基本功包括，(1)对NLP或是深度学习基本算法的理解深度，这个一般从自己的课题介绍中延伸出来；(2)有的公司还会涉及到机器学习的算法；(3) 还有C++(腾讯),python(追一)；(4) 手撕代码 (基本都撕了); (5) 其他题目(依图考了智力题，拼多多考了概率题)。&lt;/p&gt;
&lt;p&gt;这些都是日积月累的，对于(1)深度学习和(2)机器学习算法，问的也都是常用且重要的部分，如果平时注意积累，把论文模型搞清楚，这部分基本没有问题，有个别比较难的答不上就诚实地说自己没有深入考虑，面试官也是本着想听一下你对这个问题的看法的态度来讨论，并不会为难。&lt;/p&gt;
&lt;p&gt;我个人觉得，写博客就是一种很好的展示自己不断学习积累，并且对问题有自己深入思考的很好的方式。写博客于我而言是很有益的。很多时候，自以为会的或是理解正确的内容，在再次思考并整理写下来的过程中，发现自己很多地方并没有弄懂，或者之前的理解不正确，又会刨根问题再搜集资料再思考整理。这个过程中，自己也会理清思路，理解的更深入；在动笔写下来的过程中也要想着怎样组织话语、利用图示能让不懂的人也能看懂，自己也在锻炼表达的能力；回答网友问题过程中还会收获一些友谊~；另外意想不到的收获是，把博客链接贴在简历上，真的有面试官愿意来翻一翻！他会看到你不断的努力，会乐意就某些问题和你交流，倾听你的理解，这个过程中确实自己也能学到很多东西。并且这样也可以将“平时成绩”引入进来，将面试“一考定终生”的高风险分散开来。当然博客只是其中一种方式，比如github项目等等，都是展现个人长期努力的方式，也都可以帮助别人在短时间内更充分全面的了解自己。&lt;/p&gt;
&lt;p&gt;对于(3) c++可以看 《c++ primer》的一些章节，当然还有一些编程中的常出错的点，比如野指针、内存泄露等需要平时积累一下；python是平时遇到问题顺手查，主要理解清楚可变对象不可变对象、进程线程、听说有的公司还考了装饰器；本科时入门python朋友推荐看 廖雪峰的python 博客, 这些都讲的很清楚，简单易懂，也可以过一遍。&lt;/p&gt;
&lt;p&gt;对于(4) 基本的是《剑指offer》, leetcode 刷题；听说有的公司会考手撕k-means这种机器学习算法的，也要做好积累。&lt;/p&gt;
&lt;p&gt;对于(5) 看面经。&lt;/p&gt;
&lt;h2&gt;4. 了解环境&lt;/h2&gt;
&lt;p&gt;HR面可能涉及的问题：你应聘的职位？为什么选择这个方向？工作城市在xx可以吗？为什么想来xx城市？家乡哪里？为什么选择这个公司？有师兄师姐在公司吗，对公司的了解？知道NLP工程师主要做什么吗？你的三个优点和三个缺点？抗压能力如何？期望薪资？是否接受调剂？&lt;/p&gt;
&lt;p&gt;建议就是，前期多了解，了解公司的发展前景、业务工作、上班(加班)情况等。&lt;/p&gt;
&lt;p&gt;对于涉及自己的部分：不需要说的“完全真实”，但需要自圆其说，核心就是要体现热爱并适合这个行业、可以胜任这份工作，而不是体现对自己的剖析有多么到位；抗压能力不要仅说“很好”，最好举例子出来体现自己的能力；&lt;/p&gt;
&lt;p&gt;薪资：需要根据自己对NLP算法工程师岗位行业平均薪资水准、该公司基本水准有了解，说一个自己认为合理的数值，不用贱卖自己。如果HR面通过进入最后谈薪资阶段，这时候可以根据自己对行业情况的了解看看这份薪资水平是否合理；如果薪资低，可以试着根据行业水准和自己能力和HR谈一谈调薪，为自己争取一份更为理想的薪资；当然如果薪资高，意味着公司对你的期望或是要求也高，需要做的更好。&lt;/p&gt;
&lt;h2&gt;5. 知道自己要什么&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;(1) 要不要转岗？&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;真正厉害的人都是offer收割机，但是对于更为广泛的同学，今年算法岗并不好找。在前面碰壁之后，周围很多朋友选择了转岗。&lt;/p&gt;
&lt;p&gt;今年需求量大的岗位：&lt;/p&gt;
&lt;p&gt;1) 客户端 -&amp;gt; 要求：不会没关系，可以进来学。但是需要有扎实的Java基础（对于安卓）和基本的编程能力(手撕代码)。另外涉及客户端的内容可以看面经学习和了解。有朋友应聘该岗位时，直言不会客户端，面试官直接说，你会什么可以讲一下，然后朋友就介绍了自己准备的一些内容，表达清楚也可以。&lt;/p&gt;
&lt;p&gt;2) 测试开发 -&amp;gt; 同上，依旧需要有Java基础，和对测试工作的一定了解。还是抱有不会可以进来学的态度。但是有的公司还是比较严，面试官会一眼看出，你是否做过这项工作，以及会说，面经中的内容在实际工作中并不会用等。&lt;/p&gt;
&lt;p&gt;其实做以上两份工作，在一些公司的薪资也很高，甚至有的公司的客户端的工资比某些公司开发岗甚至算法岗更高。所以，不是说薪资一定是 算法 &amp;gt; 开发 &amp;gt; 客户端 &amp;amp; 测开。&lt;/p&gt;
&lt;p&gt;所以，你是否愿意冒着找不到工作的风险坚持算法岗？还是转岗？去国网？去银行？公务员？读博？这是个人的选择。这里就是优先级排序的问题了，因人而异，没有对错。错的也许只有自己固有的执念，认为某个行业一定怎样怎样，其实各行各业都在进行自己的发展，所以不仅要看现在，也要看未来。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;(2) 找不到工作怎么办？&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;自己找工作挂了一串，挂到怀疑自己；但是我想，读书不是为了将自己囚禁在某一个固定的方向，所谓“君子不器”，会想到自己仍有很多不错的能力，即使失业也仍能凭借自己的本事谋生，所以不用害怕。能力不足可以学呀。而对于有能力但面试官没看到的，想着自己的智力和体魄依旧在，公司不要，是公司的损失，自己有什么损失呢？&lt;/p&gt;
&lt;p&gt;其实很多人都是在经历很多次被拒绝后，仍不放弃，才最终有一份结果。如果值得期待，也就值得坚守。希望大家都能有一份满意的工作，并且在工作中做得出色！&lt;/p&gt;
</description>
<pubDate>Mon, 30 Sep 2019 17:19:00 +0000</pubDate>
<dc:creator>listenviolet</dc:creator>
<og:description>有近2个月没有更新博客，主要精力放在了投递会议论文和秋招找工作方面。这里简单总结一下秋招面试的几点建议和感受。 投递的主要是NLP算法工程师岗位，主要参加过面试的公司有腾讯(春招)，蚂蚁金服(春招)，</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/shiyublog/p/11612061.html</dc:identifier>
</item>
<item>
<title>hadoop之mapreduce详解（优化篇） - 一寸HUI</title>
<link>http://www.cnblogs.com/zsql/p/11614580.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/zsql/p/11614580.html</guid>
<description>&lt;h2&gt;&lt;span&gt;一、概述&lt;/span&gt;&lt;/h2&gt;
&lt;p&gt;     优化前我们需要知道hadoop适合干什么活，适合什么场景，在工作中，我们要知道业务是怎样的，能才结合平台资源达到最有优化。除了这些我们当然还要知道mapreduce的执行过程，比如从文件的读取，map处理，shuffle过程，reduce处理，文件的输出或者存储。在工作中，往往平台的参数都是固定的，不可能为了某一个作业去修改整个平台的参数，所以在作业的执行过程中，需要对作业进行单独的设定，这样既不会对其他作业产生影响，也能很好的提高作业的性能，提高优化的灵活性。&lt;/p&gt;
&lt;p&gt;现在回顾下hadoop的优势（适用场景）：&lt;br/&gt;1、可构建在廉价机器上，设备成本相对低&lt;br/&gt;2、高容错性，HDFS将数据自动保存多个副本，副本丢失后，自动恢复，防止数据丢失或损坏&lt;br/&gt;3、适合批处理，HDFS适合一次写入、多次查询（读取）的情况，适合在已有的数据进行多次分析，稳定性好&lt;br/&gt;4、适合存储大文件，其中的大表示可以存储单个大文件，因为是分块存储，以及表示存储大量的数据&lt;/p&gt;
&lt;h2&gt;&lt;span&gt;二、小文件优化&lt;/span&gt;&lt;/h2&gt;
&lt;p&gt;从概述中我们知道，很明显hadoop适合大文件的处理和存储，那为什么不适合小文件呢？&lt;/p&gt;
&lt;p&gt;1、从存储方面来说：hadoop的存储每个文件都会在NameNode上记录元数据，如果同样大小的文件，文件很小的话，就会产生很多文件，造成NameNode的压力。&lt;br/&gt;2、从读取方面来说：同样大小的文件分为很多小文件的话，会增加磁盘寻址次数，降低性能&lt;br/&gt;3、从计算方面来说：我们知道一个map默认处理一个分片或者一个小文件，如果map的启动时间都比数据处理的时间还要长，那么就会造成性能低，而且在map端溢写磁盘的时候每一个map最终会产生reduce数量个数的中间结果，如果map数量特别多，就会造成临时文件很多，而且在reduce拉取数据的时候增加磁盘的IO。&lt;/p&gt;
&lt;p&gt;好，我们明白小文件造成的弊端之后，那我们应该怎么处理这些小文件呢？&lt;/p&gt;
&lt;p&gt;1、从源头干掉，也就是在hdfs上我们不存储小文件，也就是数据上传hdfs的时候我们就合并小文件&lt;br/&gt;2、在FileInputFormat读取入数据的时候我们使用实现类CombineFileInputFormat读取数据，在读取数据的时候进行合并。&lt;/p&gt;
&lt;h2&gt;&lt;span&gt;三、数据倾斜问题优化&lt;/span&gt;&lt;/h2&gt;
&lt;p&gt;我们都知道mapreduce是一个并行处理，那么处理的时间肯定是作业中所有任务最慢的那个了，可谓木桶效应？为什么会这样呢？&lt;/p&gt;
&lt;p&gt;1、数据倾斜，每个reduce处理的数据量不是同一个级别的，所有导致有些已经跑完了，而有些跑的很慢。&lt;br/&gt;2、还有可能就是某些作业所在的NodeManager有问题或者container有问题，导致作业执行缓慢。&lt;/p&gt;
&lt;p&gt;那么为什么会产生数据倾斜呢？&lt;/p&gt;
&lt;p&gt;数据本身就不平衡，所以在默认的hashpartition时造成分区数据不一致问题，还有就是代码设计不合理等。&lt;/p&gt;
&lt;p&gt;那如何解决数据倾斜的问题呢？&lt;/p&gt;
&lt;p&gt;1、既然默认的是hash算法进行分区，那我们自定义分区，修改分区实现逻辑，结合业务特点，使得每个分区数据基本平衡&lt;br/&gt;2、既然有默认的分区算法，那么我们可以修改分区的键，让其符合hash分区，并且使得最后的分区平衡，比如在key前加随机数n-key。&lt;br/&gt;3、既然reduce处理慢，我们可以增加reduce的内存和vcore呀，这样挺高性能就快了，虽然没从根本上解决问题，但是还有效果&lt;br/&gt;4、既然一个reduce处理慢，那我们可以增加reduce的个数来分摊一些压力呀，也不能根本解决问题，还是有一定的效果。&lt;/p&gt;
&lt;p&gt;那么如果不是数据倾斜带来的问题，而是节点服务有问题造成某些map和reduce执行缓慢呢？&lt;/p&gt;
&lt;p&gt;那么我们可以使用推测执行呀，你跑的慢，我们可以找个其他的节点重启一样的任务竞争，谁快谁为准。推测执行时以空间换时间的优化。会带来集群资源的浪费，会给集群增加压力，所以我司集群的推测执行都是关闭的。其实在作业执行的时候可以偷偷开启的呀&lt;/p&gt;
&lt;p&gt;推测执行参数控制：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;32&quot;&gt;
&lt;pre&gt;
&lt;span&gt;mapreduce.map.speculative
mapreduce.reduce.speculative&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;&lt;span&gt;四、mapreduce过程优化&lt;/span&gt;&lt;/h2&gt;
&lt;h3&gt;4.1、map端&lt;/h3&gt;
&lt;p&gt;上面我们从hadoop的特性场景等聊了下mapreduce的优化，接下来我们从mapreduce的执行过程进行优化。&lt;/p&gt;
&lt;p&gt;好吧，我们就从源头开始说，从数据的读取以及map数的确定：&lt;/p&gt;
&lt;p&gt;    在前面我们聊过小文件的问题，所以在数据的读取这里也可以做优化，所以选择一个合适数据的文件的读取类（FIleInputFormat的实现类）也很重要我们在作业提交的过程中，会把jar，分片信息，资源信息提交到hdfs的临时目录，默认会有10个复本，通过参数&lt;strong&gt;mapreduce.client.submit.file.replication&lt;/strong&gt;控制后期作业执行都会去下载这些东西到本地，中间会产生磁盘IO，所以如果集群很大的时候，可以增加该值，提高下载的效率。&lt;/p&gt;
&lt;p&gt;分片的计算公式：&lt;/p&gt;
&lt;p&gt;计算切片大小的逻辑：Math.max(minSize, Math.min(maxSize, blockSize))&lt;br/&gt;minSize的默认值是1,而maxSize的默认值是long类型的最大值,即可得切片的默认大小是blockSize(128M)&lt;br/&gt;maxSize参数如果调得比blocksize小，则会让切片变小，而且就等于配置的这个参数的值&lt;br/&gt;minSize参数调的比blockSize大，则可以让切片变得比blocksize还大&lt;/p&gt;
&lt;p&gt;     因为map数没有具体的参数指定，所以我们可以通过如上的公式调整切片的大小，这样我们就可以设置map数了，那么问题来了，map数该如何设置呢？&lt;/p&gt;
&lt;p&gt;这些东西一定要结合业务，map数太多，会产生很多中间结果，导致reduce拉取数据变慢，太少，每个map处理的时间又很长，结合数据的需求，可以把map的执行时间调至到一分钟左右比较合适，那如果数据量就是很大呢，我们有时候还是需要控制map的数量，这个时候每个map的执行时间就比较长了，那么我们可以调整每个map的资源来提升map的处理能力呀，我司就调整了&lt;strong&gt;mapreduce.map.memory.mb&lt;/strong&gt;=3G（默认1G）&lt;strong&gt;mapreduce.map.cpu.vcores&lt;/strong&gt;=1(默认也是1)&lt;/p&gt;
&lt;p&gt;从源头上我们确定好map之后。那么接下来看map的具体执行过程咯。&lt;/p&gt;
&lt;p&gt;首先写环形换冲区，那为啥要写环形换冲区呢，而不是直接写磁盘呢？这样的目的主要是为了减少磁盘i/o。&lt;/p&gt;
&lt;p&gt;每个Map任务不断地将键值对输出到在内存中构造的一个环形数据结构中。使用环形数据结构是为了更有效地使用内存空间，在内存中放置尽可能多的数据。执行流程是，该缓冲默认100M（&lt;strong&gt;mapreduce.task.io.sort.mb&lt;/strong&gt;参数控制），当到达80%（&lt;strong&gt;mapreduce.map.sort.spill.percent&lt;/strong&gt;参数控制）时就会溢写磁盘。每达到80%都会重写溢写到一个新的文件。那么，我们完全可以根据机器的配置和数据来两种这两个参数，当内存足够，我们增大mapreduce.task.io.sort.mb完全会提高溢写的过程，而且会减少中间结果的文件数量。我司调整mapreduce.task.io.sort.mb=512。当文件溢写完后，会对这些文件进行合并，默认每次合并10（&lt;strong&gt;mapreduce.task.io.sort.factor&lt;/strong&gt;参数控制）个溢写的文件，我司调整mapreduce.task.io.sort.factor=64。这样可以提高合并的并行度，减少合并的次数，降低对磁盘操作的次数。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;mapreduce.shuffle.max.threads&lt;/strong&gt;（默认为0，表示可用处理器的两倍），该参数表示每个节点管理器的工作线程，用于map输出到reduce。&lt;/p&gt;
&lt;p&gt;那么map算是完整了，在reduce拉取数据之前，我们完全还可以combiner呀（不影响最终结果的情况下），此时会根据Combiner定义的函数对map的结果进行合并这样就可以减少数据的传输，降低磁盘io，提高性能了。&lt;/p&gt;
&lt;p&gt;终于走到了map到reduce的数据传输过程了：&lt;br/&gt;这中间主要的影响无非就是磁盘IO，网络IO，数据量的大小了（是否压缩），其实减少数据量的大小，就可以做到优化了，所以我们可以选择性压缩数据，这样在传输的过程中&lt;br/&gt;就可以降低磁盘IO，网络IO等。可以通过&lt;strong&gt;mapreduce.map.output.compress&lt;/strong&gt;（default：false）设置为true进行压缩，数据会被压缩写入磁盘，读数据读的是压缩数据需要解压，在实际经验中Hive在Hadoop的运行的瓶颈一般都是IO而不是CPU，压缩一般可以10倍的减少IO操作，压缩的方式Gzip，Lzo,BZip2,Lzma等，其中Lzo是一种比较平衡选择，&lt;strong&gt;mapreduce.map.output.compress.codec&lt;/strong&gt;（default：org.apache.hadoop.io.compress.DefaultCodec）参数设置。我司使用org.apache.hadoop.io.compress.SnappyCodec算法，但这个过程会消耗CPU，适合IO瓶颈比较大。&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;35&quot;&gt;
&lt;pre&gt;
&lt;span&gt;mapreduce.task.io.sort.mb        #排序map输出所需要使用内存缓冲的大小，以兆为单位， 默认为100
mapreduce.map.sort.spill.percent #map输出缓冲和用来磁盘溢写过程的记录边界索引，这两者使用的阈值，默认0.&lt;/span&gt;&lt;span&gt;8&lt;/span&gt;&lt;span&gt;
mapreduce.task.io.sort.factor    #排序文件时，一次最多合并的文件数，默认10
mapreduce.map.output.compress    #在map溢写磁盘的过程是否使用压缩，默认false
org.apache.hadoop.io.compress.SnappyCodec  #map溢写磁盘的压缩算法，默认org.apache.hadoop.io.compress.DefaultCodec
mapreduce.shuffle.max.threads    #该参数表示每个节点管理器的工作线程，用于map输出到reduce，默认为0，表示可用处理器的两倍&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;4.1、reduce端&lt;/h3&gt;
&lt;p&gt;接下来就是reduce了，首先我们可以通过参数设置合理的reduce个数（&lt;strong&gt;mapreduce.job.reduces&lt;/strong&gt;参数控制），以及通过参数设置每个reduce的资源，&lt;strong&gt;mapreduce.reduce.memory.mb&lt;/strong&gt;=5G（默认1G）&lt;br/&gt;&lt;strong&gt;mapreduce.reduce.cpu.vcores&lt;/strong&gt;=1（默认为1）。&lt;/p&gt;
&lt;p&gt;reduce在copy的过程中默认使用5（&lt;strong&gt;mapreduce.reduce.shuffle.parallelcopies&lt;/strong&gt;参数控制）个并行度进行复制数据，我司调了mapreduce.reduce.shuffle.parallelcopies=100.reduce的每一个下载线程在下载某个map数据的时候，有可能因为那个map中间结果所在机器发生错误，或者中间结果的文件丢失，或者网络瞬断等等情况，这样reduce的下载就有可能失败，所以reduce的下载线程并不会无休止的等待下去，当一定时间后下载仍然失败，那么下载线程就会放弃这次下载，并在随后尝试从另外的地方下载（因为这段时间map可能重跑）。reduce下载线程的这个最大的下载时间段是可以通过&lt;strong&gt;mapreduce.reduce.shuffle.read.timeout&lt;/strong&gt;（default180000秒）调整的。&lt;/p&gt;
&lt;p&gt;Copy过来的数据会先放入内存缓冲区中，然后当使用内存达到一定量的时候才spill磁盘。这里的缓冲区大小要比map端的更为灵活，它基于JVM的heap size设置。这个内存大小的控制就不像map一样可以通过io.sort.mb来设定了，而是通过另外一个参数 &lt;strong&gt;mapreduce.reduce.shuffle.input.buffer.percent&lt;/strong&gt;（default 0.7）控制的。意思是说，shuffile在reduce内存中的数据最多使用内存量为：0.7 × maxHeap of reduce task，内存到磁盘merge的启动门限可以通过&lt;strong&gt;mapreduce.reduce.shuffle.merge.percent&lt;/strong&gt;（default0.66）配置。&lt;/p&gt;
&lt;p&gt;copy完成后，reduce进入归并排序阶段，合并因子默认为10（&lt;strong&gt;mapreduce.task.io.sort.factor&lt;/strong&gt;参数控制），如果map输出很多，则需要合并很多趟，所以可以提高此参数来减少合并次数。&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;35&quot;&gt;
&lt;pre&gt;
&lt;span&gt;mapreduce.reduce.shuffle.parallelcopies #把map输出复制到reduce的线程数，默认5
mapreduce.task.io.sort.factor  #排序文件时一次最多合并文件的个数
mapreduce.reduce.shuffle.input.buffer.percent #在shuffle的复制阶段，分配给map输出缓冲区占堆内存的百分比，默认0.&lt;/span&gt;&lt;span&gt;7&lt;/span&gt;&lt;span&gt;
mapreduce.reduce.shuffle.merge.percent #map输出缓冲区的阈值，用于启动合并输出和磁盘溢写的过程&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;更多hadoop生态文章见：&lt;a class=&quot;postTitle2&quot; href=&quot;https://www.cnblogs.com/zsql/p/11560374.html&quot;&gt; hadoop生态系列&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
</description>
<pubDate>Mon, 30 Sep 2019 16:06:00 +0000</pubDate>
<dc:creator>一寸HUI</dc:creator>
<og:description>一、概述 优化前我们需要知道hadoop适合干什么活，适合什么场景，在工作中，我们要知道业务是怎样的，能才结合平台资源达到最有优化。除了这些我们当然还要知道mapreduce的执行过程，比如从文件的读</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/zsql/p/11614580.html</dc:identifier>
</item>
<item>
<title>.NetCore技术研究-一套代码同时支持.NET Framework和.NET Core - Eric zhou</title>
<link>http://www.cnblogs.com/tianqing/p/11614303.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/tianqing/p/11614303.html</guid>
<description>&lt;p&gt;在.NET Core的迁移过程中，我们将原有的.NET Framework代码迁移到.NET Core。如果线上只有一个小型的应用还好，迁移升级完成后，只需要维护.NET Core这个版本的代码。&lt;/p&gt;
&lt;p&gt;但是，如果是一个大型分布式应用，几百台Server，上千个.NET 应用进程。这种场景下，在一定的时期内，我们需要同时维护.NET Framework和.NET Core两套代码，同一个产品&lt;/p&gt;
&lt;p&gt;特性，需要分别在两套代码中实现，这种代码同步的工作量是非常大的。因此，在这种场景下，有必要使用同一套代码既支持.NET Framework又支持.NET Core.&lt;/p&gt;
&lt;p&gt;带着这个需求场景，我们展开今天的.NET Core技术研究分享。先总结一下整体的思路：&lt;/p&gt;
&lt;p&gt;1. 在Project工程层面支持多个目标框架，面向不同的.NET 目标框架添加不同的引用&lt;/p&gt;
&lt;p&gt;2. 代码中使用预处理指令同时支持.NET Framework 和 .NET Core&lt;/p&gt;
&lt;p&gt;3. 编译生成两个.NET框架的Dll，制作支持多个.NET目标框架的Nuget包&lt;/p&gt;
&lt;p&gt;我们先看第一步：&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;一、在Project工程层面支持多个目标框架，面向不同的.NET 目标框架添加不同的引用&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;在这个示例代码中，我们使用了.NET Standard 2.0 Class Library Project。 目标框架同时支持.NET Framework 4.5.1和.NET Standard 2.0&lt;/p&gt;
&lt;p&gt; &lt;img src=&quot;https://img2018.cnblogs.com/blog/23525/201909/23525-20190930220715542-1215197833.jpg&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt; &lt;img src=&quot;https://img2018.cnblogs.com/blog/23525/201909/23525-20190930220808825-1674393588.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt; 双击Project, 进入XML文件编辑模式&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;33&quot;&gt;
&lt;pre&gt;
&lt;span&gt;1&lt;/span&gt; &amp;lt;Project Sdk=&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;Microsoft.NET.Sdk&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&amp;gt;
&lt;span&gt;2&lt;/span&gt;   &amp;lt;PropertyGroup&amp;gt;
&lt;span&gt;3&lt;/span&gt;     &amp;lt;TargetFramework&amp;gt;netstandard2.&lt;span&gt;0&lt;/span&gt;&amp;lt;/TargetFramework&amp;gt;
&lt;span&gt;4&lt;/span&gt;   &amp;lt;/PropertyGroup&amp;gt;
&lt;span&gt;5&lt;/span&gt; &amp;lt;/Project&amp;gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;我们重点编辑TargetFramework这个节，改为TargetFrameworks，例如：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;32&quot;&gt;
&lt;pre&gt;
&lt;span&gt;1&lt;/span&gt;  &amp;lt;PropertyGroup&amp;gt;
&lt;span&gt;2&lt;/span&gt;    &amp;lt;&lt;span&gt;&lt;strong&gt;TargetFrameworks&lt;/strong&gt;&lt;/span&gt;&amp;gt;netstandard2.&lt;span&gt;0&lt;/span&gt;;net451&amp;lt;/TargetFrameworks&amp;gt;
&lt;span&gt;3&lt;/span&gt;   &amp;lt;/PropertyGroup&amp;gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;保存后，会提示：&lt;br/&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/23525/201909/23525-20190930221431189-1722723336.jpg&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;  全部重新加载后，新的Project的依赖项是这样的：&lt;/p&gt;
&lt;p&gt;   &lt;img src=&quot;https://img2018.cnblogs.com/blog/23525/201909/23525-20190930221641916-446306556.jpg&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;这样,这个Project就支持了多个.NET 目标框架，我们可以面向不同的.NET 目标框架添加不同的引用，当然如果依赖的Nuget也同时支持相同的.NET 目标框架，那就最匹配了：例如：Newtonsoft.Json&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/23525/201909/23525-20190930222019625-1676220777.jpg&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;添加Nuget引用后，Project在不同的.NET 目标框架的引用是这样的：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/23525/201909/23525-20190930222332424-185418560.jpg&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;当然，我们可以为单独为指定的.NET 目标框架添加不同的引用，例如：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;35&quot;&gt;
&lt;pre&gt;
&lt;span&gt; 1&lt;/span&gt; &amp;lt;Project Sdk=&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;Microsoft.NET.Sdk&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&amp;gt;
&lt;span&gt; 2&lt;/span&gt; 
&lt;span&gt; 3&lt;/span&gt;   &amp;lt;PropertyGroup&amp;gt;
&lt;span&gt; 4&lt;/span&gt;     &amp;lt;TargetFrameworks&amp;gt;netstandard2.&lt;span&gt;0&lt;/span&gt;;net451;&amp;lt;/TargetFrameworks&amp;gt;
&lt;span&gt; 5&lt;/span&gt;   &amp;lt;/PropertyGroup&amp;gt;
&lt;span&gt; 6&lt;/span&gt; 
&lt;span&gt; 7&lt;/span&gt;   &amp;lt;ItemGroup&amp;gt;
&lt;span&gt; 8&lt;/span&gt;     &amp;lt;PackageReference Include=&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;Newtonsoft.Json&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; Version=&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;12.0.2&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; /&amp;gt;
&lt;span&gt; 9&lt;/span&gt;   &amp;lt;/ItemGroup&amp;gt;
&lt;span&gt;10&lt;/span&gt; 
&lt;span&gt;11&lt;/span&gt;   &amp;lt;ItemGroup &lt;span&gt;&lt;strong&gt;Condition&lt;/strong&gt;&lt;/span&gt;=&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt; '$(TargetFramework)' == '&lt;span&gt;net451&lt;/span&gt;' &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&amp;gt;
&lt;span&gt;12&lt;/span&gt;     &amp;lt;ProjectReference Include=&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;..\LibNetFramework\LibNetFramework.csproj&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; /&amp;gt;
&lt;span&gt;13&lt;/span&gt;   &amp;lt;/ItemGroup&amp;gt;
&lt;span&gt;14&lt;/span&gt;   
&lt;span&gt;15&lt;/span&gt;   &amp;lt;ItemGroup  &lt;span&gt;&lt;strong&gt;Condition&lt;/strong&gt;&lt;/span&gt;=&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt; '$(TargetFramework)' == '&lt;span&gt;netstandard2.0&lt;/span&gt;' &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&amp;gt;
&lt;span&gt;16&lt;/span&gt;     &amp;lt;ProjectReference Include=&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;..\LibNetCore\LibNetCore.csproj&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; /&amp;gt;
&lt;span&gt;18&lt;/span&gt;   &amp;lt;/ItemGroup&amp;gt;
&lt;span&gt;19&lt;/span&gt; 
&lt;span&gt;20&lt;/span&gt; &amp;lt;/Project&amp;gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt; &lt;img src=&quot;https://img2018.cnblogs.com/blog/23525/201909/23525-20190930222910402-1958835792.jpg&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;参考链接：&lt;a href=&quot;https://docs.microsoft.com/en-us/dotnet/standard/frameworks&quot;&gt;https://docs.microsoft.com/en-us/dotnet/standard/frameworks&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;二、. 代码中使用预处理指令同时支持.NET Framework 和 .NET Core&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;如果同一块业务逻辑，在.NET Framework和.NET Core实现不一样，我们在同一个代码中，如果通过预处理指令实现：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;36&quot;&gt;
&lt;pre&gt;
&lt;span&gt; 1&lt;/span&gt;  &lt;span&gt;public&lt;/span&gt; &lt;span&gt;string&lt;/span&gt;&lt;span&gt; UserID
&lt;/span&gt;&lt;span&gt; 2&lt;/span&gt; &lt;span&gt;        {
&lt;/span&gt;&lt;span&gt; 3&lt;/span&gt;             &lt;span&gt;get&lt;/span&gt;
&lt;span&gt; 4&lt;/span&gt; &lt;span&gt;            {
&lt;/span&gt;&lt;span&gt; 5&lt;/span&gt; &lt;span&gt;#if&lt;/span&gt; NET451
&lt;span&gt; 6&lt;/span&gt;                 &lt;span&gt;return&lt;/span&gt; Convert.ToString(HttpContext.Current.Session[&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;UserID&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;]);
&lt;/span&gt;&lt;span&gt; 7&lt;/span&gt; &lt;span&gt;#elif&lt;/span&gt; NETSTANDARD2_0
&lt;span&gt; 8&lt;/span&gt;                 &lt;span&gt;return&lt;/span&gt; httpContext.Session.GetString(&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;UserID&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;);
&lt;/span&gt;&lt;span&gt; 9&lt;/span&gt; &lt;span&gt;#endif&lt;/span&gt;
&lt;span&gt;10&lt;/span&gt; &lt;span&gt;            }
&lt;/span&gt;&lt;span&gt;11&lt;/span&gt;             &lt;span&gt;private&lt;/span&gt; &lt;span&gt;set&lt;/span&gt;
&lt;span&gt;12&lt;/span&gt; &lt;span&gt;            {
&lt;/span&gt;&lt;span&gt;13&lt;/span&gt; &lt;span&gt;#if&lt;/span&gt; NET451
&lt;span&gt;14&lt;/span&gt;                 HttpContext.Current.Session[&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;UserID&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;] =&lt;span&gt; value;
&lt;/span&gt;&lt;span&gt;15&lt;/span&gt; &lt;span&gt;#elif&lt;/span&gt; NETSTANDARD2_0
&lt;span&gt;16&lt;/span&gt;                 httpContext.Session.SetString(&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;UserID&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;, value);  
&lt;/span&gt;&lt;span&gt;17&lt;/span&gt; &lt;span&gt;#endif&lt;/span&gt;
&lt;span&gt;18&lt;/span&gt; &lt;span&gt;            }
&lt;/span&gt;&lt;span&gt;19&lt;/span&gt;         }
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;参考链接：&lt;a href=&quot;https://docs.microsoft.com/en-us/dotnet/csharp/language-reference/preprocessor-directives/preprocessor-if&quot;&gt;https://docs.microsoft.com/en-us/dotnet/csharp/language-reference/preprocessor-directives/preprocessor-if&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;这个地方有个对照表：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/23525/201909/23525-20190930223936815-151543847.jpg&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;这样，代码写完后，编译一下，可以看到有两个文件夹生成：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;39&quot;&gt;
&lt;pre&gt;
&lt;span&gt;1&lt;/span&gt;&amp;gt;------ 已启动全部重新生成: 项目: LibNetCore, 配置: Debug Any CPU ------
&lt;span&gt;1&lt;/span&gt;&amp;gt;C:\Program Files\dotnet\sdk\&lt;span&gt;3.0&lt;/span&gt;.&lt;span&gt;100&lt;/span&gt;-preview3-&lt;span&gt;010431&lt;/span&gt;\Sdks\Microsoft.NET.Sdk\targets\Microsoft.NET.RuntimeIdentifierInference.targets(&lt;span&gt;151&lt;/span&gt;,&lt;span&gt;5&lt;/span&gt;): message NETSDK1057: 你正在使用 .NET Core 的预览版。请查看 https:&lt;span&gt;//&lt;/span&gt;&lt;span&gt;aka.ms/dotnet-core-preview&lt;/span&gt;
&lt;span&gt;1&lt;/span&gt;&amp;gt;LibNetCore -&amp;gt; C:\Users\zhougq\source\repos\LibNetCore\bin\De&lt;span&gt;bug\netstandard2.0&lt;/span&gt;&lt;span&gt;\LibNetCore.dll
&lt;/span&gt;&lt;span&gt;2&lt;/span&gt;&amp;gt;------ 已启动全部重新生成: 项目: TestLibrary, 配置: Debug Any CPU ------
&lt;span&gt;2&lt;/span&gt;&amp;gt;C:\Program Files\dotnet\sdk\&lt;span&gt;3.0&lt;/span&gt;.&lt;span&gt;100&lt;/span&gt;-preview3-&lt;span&gt;010431&lt;/span&gt;\Sdks\Microsoft.NET.Sdk\targets\Microsoft.NET.RuntimeIdentifierInference.targets(&lt;span&gt;151&lt;/span&gt;,&lt;span&gt;5&lt;/span&gt;): message NETSDK1057: 你正在使用 .NET Core 的预览版。请查看 https:&lt;span&gt;//&lt;/span&gt;&lt;span&gt;aka.ms/dotnet-core-preview&lt;/span&gt;
&lt;span&gt;2&lt;/span&gt;&amp;gt;TestLibrary -&amp;gt; C:\Users\zhougq\source\repos\TestLibrary\bin\Debug\&lt;strong&gt;&lt;span&gt;netstandard2.0&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;\TestLibrary.dll
&lt;/span&gt;&lt;span&gt;2&lt;/span&gt;&amp;gt;TestLibrary -&amp;gt;&lt;span&gt; C:\Users\zhougq\source\repos\TestLibrary\bin\Debug\&lt;span&gt;&lt;strong&gt;net451&lt;/strong&gt;&lt;/span&gt;\TestLibrary.dll
&lt;/span&gt;========== 全部重新生成: 成功 &lt;span&gt;2&lt;/span&gt; 个，失败 &lt;span&gt;0&lt;/span&gt; 个，跳过 &lt;span&gt;0&lt;/span&gt; 个 ==========
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;三. 编译生成两个.NET框架的Dll，制作支持多个.NET目标框架的Nuget包&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt; &lt;/span&gt;上个步骤中生成的两个.NET 目标版本的dll，可以分别制作支持多个.NET 目标框架的Nuget包。&lt;/p&gt;
&lt;p&gt; 右键Project属性设置中，可以设置Nuget打包&lt;/p&gt;
&lt;p&gt; &lt;img src=&quot;https://img2018.cnblogs.com/blog/23525/201909/23525-20190930224549644-1970219628.jpg&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;   编译工程：Successfully created package 'C:\Users\zhougq\source\repos\TestLibrary\bin\Debug\TestLibrary.1.0.0.nupkg'.&lt;/p&gt;
&lt;p&gt;  使用PackageExplorer编辑生成好的Nuget包：&lt;/p&gt;
&lt;p&gt; &lt;img src=&quot;https://img2018.cnblogs.com/blog/23525/201909/23525-20190930224918496-654055359.jpg&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;  以上就是本次的.NETCore 技术分享。&lt;/p&gt;

&lt;p&gt;周国庆&lt;/p&gt;
&lt;p&gt;2019/9/30&lt;/p&gt;

</description>
<pubDate>Mon, 30 Sep 2019 14:50:00 +0000</pubDate>
<dc:creator>Eric zhou</dc:creator>
<og:description>在.NET Core的迁移过程中，我们将原有的.NET Framework代码迁移到.NET Core。如果线上只有一个小型的应用还好，迁移升级完成后，只需要维护.NET Core这个版本的代码。 但</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/tianqing/p/11614303.html</dc:identifier>
</item>
<item>
<title>先森林后树木：Elasticsearch各版本升级核心内容必看 - 会飞的笨石头</title>
<link>http://www.cnblogs.com/flyrock/p/11614396.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/flyrock/p/11614396.html</guid>
<description>&lt;p&gt;在学习Elasticsearch 时候，因为各个版本的问题，搞不清，非常的头疼，官方也给出了各个版本更新的情况，不过是英文版本，版本更新信息又特别多，最近学习，看了很多资料，没有一个整理很清楚的，然后自己就统一整理下,首先声明下面的整理都是各个版本个人认为比较重要点，因为每个大版本更新内容太多，也不能一一举例，详细需要参阅官方文档，文章底部有链接，我也是为了自己方便在整体上，了解Elasticsearch 各个版本的迭代，可以更好的理解和使用Elasticsearch 产品，所以有了这篇文章。&lt;/p&gt;
&lt;h3 id=&quot;-0-7-0&quot;&gt;初始版本 0.7.0&lt;/h3&gt;
&lt;p&gt;2010年5月14日发布,第一个可以查询到发版信息的版本，重要特性：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;Zen Discovery 自动发现模块&lt;/li&gt;
&lt;li&gt;Groovy Client支持&lt;/li&gt;
&lt;li&gt;简单的插件管理机制&lt;/li&gt;
&lt;li&gt;更好支持ICU分词器&lt;/li&gt;
&lt;li&gt;更多的管理API&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;初始化的版本，暂时不多介绍，先来这么多。&lt;/p&gt;
&lt;h3 id=&quot;-1-0-0-&quot;&gt;升级1.0.0 版本&lt;/h3&gt;
&lt;p&gt;2014年2月14日发布，重要特性： -Snapshot/Restore API 备份恢复API&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;支持聚合分析Aggregations&lt;/li&gt;
&lt;li&gt;CAT API 支持&lt;/li&gt;
&lt;li&gt;支持联盟查询&lt;/li&gt;
&lt;li&gt;断路器支持&lt;/li&gt;
&lt;li&gt;Doc values 引入&lt;/li&gt;
&lt;/ul&gt;&lt;h3 id=&quot;2-0-0-&quot;&gt;2.0.0 版本&lt;/h3&gt;
&lt;p&gt;2015年10月28日发布，重要特性：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;增加了 pipleline Aggregations&lt;/li&gt;
&lt;li&gt;query/filter 查询合并，都合并到query中，根据不同的上下文执行不同的查询&lt;/li&gt;
&lt;li&gt;存储压缩可配置&lt;/li&gt;
&lt;li&gt;Rivers 模块被移除&lt;/li&gt;
&lt;li&gt;Multicast 组播发现被移除，成为一个插件，生产环境必须配置单播地址&lt;/li&gt;
&lt;/ul&gt;&lt;h3 id=&quot;-5-0-0-&quot;&gt;新特性5.0.0 版本&lt;/h3&gt;
&lt;p&gt;2016年10月26日发布，重要特性：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;Lucene 6.x 的支持，磁盘空间少一半；索引时间少一半；查询性能提升25%；支持IPV6。&lt;/li&gt;
&lt;li&gt;Internal engine级别移除了用于避免同一文档并发更新的竞争锁，带来15%-20%的性能提升&lt;/li&gt;
&lt;li&gt;Shrink API ，它可将分片数进行收缩成它的因数，如之前你是15个分片，你可以收缩成5个或者3个又或者1个，那么我们就可以想象成这样一种场景，在写入压力非常大的收集阶段，设置足够多的索引，充分利用shard的并行写能力，索引写完之后收缩成更少的shard，提高查询性能&lt;/li&gt;
&lt;li&gt;提供了第一个Java原生的REST客户端SDK&lt;/li&gt;
&lt;li&gt;IngestNode，之前如果需要对数据进行加工，都是在索引之前进行处理，比如logstash可以对日志进行结构化和转换，现在直接在es就可以处理了&lt;/li&gt;
&lt;li&gt;提供了 Painless 脚本，代替Groovy脚本&lt;/li&gt;
&lt;li&gt;移除 site plugins ，就是说 head 、 bigdesk 都不能直接装 es 里面了，不过可以部署独立站点（反正都是静态文件）或开发 kibana 插件&lt;/li&gt;
&lt;li&gt;新增 Sliced Scroll类型，现在Scroll接口可以并发来进行数据遍历了。每个Scroll请求，可以分成多个Slice请求，可以理解为切片，各Slice独立并行，利用Scroll重建或者遍历要快很多倍。&lt;/li&gt;
&lt;li&gt;新增了Profile API&lt;/li&gt;
&lt;li&gt;新增了Rollover API&lt;/li&gt;
&lt;li&gt;新增Reindex&lt;/li&gt;
&lt;li&gt;提供了第一个Java原生的REST客户端SDK 基于HTTP协议的客户端对Elasticsearch的依赖解耦，没有jar包冲突，提供了集群节点自动发现、日志处理、节点请求失败自动进行请求轮询，充分发挥Elasticsearch的高可用能力&lt;/li&gt;
&lt;li&gt;引入新的字段类型 Text/Keyword 来替换 String&lt;/li&gt;
&lt;li&gt;限制索引请求大小，避免大量并发请求压垮 ES&lt;/li&gt;
&lt;li&gt;限制单个请求的 shards 数量，默认 1000 个&lt;/li&gt;
&lt;/ul&gt;&lt;h3 id=&quot;-6-0-0-&quot;&gt;新特性6.0.0 版本&lt;/h3&gt;
&lt;p&gt;2017年8月31日发布，重要特性：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;稀疏性 Doc Values 的支持&lt;/li&gt;
&lt;li&gt;Index sorting，即索引阶段的排序。&lt;/li&gt;
&lt;li&gt;顺序号的支持，每个 es 的操作都有一个顺序编号（类似增量设计）&lt;/li&gt;
&lt;li&gt;无缝滚动升级&lt;/li&gt;
&lt;li&gt;Removal of types，在 6.0 里面，开始不支持一个 index 里面存在多个 type&lt;/li&gt;
&lt;li&gt;Index-template inheritance，索引版本的继承，目前索引模板是所有匹配的都会合并，这样会造成索引模板有一些冲突问题， 6.0 将会只匹配一个，索引创建时也会进行验证&lt;/li&gt;
&lt;li&gt;Load aware shard routing， 基于负载的请求路由，目前的搜索请求是全节点轮询，那么性能最慢的节点往往会造成整体的延迟增加，新的实现方式将基于队列的耗费时间自动调节队列长度，负载高的节点的队列长度将减少，让其他节点分摊更多的压力，搜索和索引都将基于这种机制。&lt;/li&gt;
&lt;li&gt;已经关闭的索引将也支持 replica 的自动处理，确保数据可靠。&lt;/li&gt;
&lt;/ul&gt;&lt;h3 id=&quot;-7-0-0-&quot;&gt;新特性7.0.0 版本&lt;/h3&gt;
&lt;p&gt;2019年4月10日发布，重要特性：&lt;/p&gt;
&lt;ul readability=&quot;0.5&quot;&gt;&lt;li&gt;集群连接变化：TransportClient被废弃 以至于，es7的java代码，只能使用restclient。然后，个人综合了一下，对于java编程，建议采用 High-level-rest-client 的方式操作ES集群&lt;/li&gt;
&lt;li&gt;ES程序包默认打包jdk： 以至于7.x版本的程序包大小突然边300MB+ 对比6.x发现，包大了200MB+， 正是JDK的大小&lt;/li&gt;
&lt;li&gt;Lucene9.0&lt;/li&gt;
&lt;li readability=&quot;2&quot;&gt;
&lt;p&gt;重大改进-正式废除单个索引下多Type的支持 es6时，官方就提到了es7会删除type，并且es6时已经规定每一个index只能有一个type。在es7中使用默认的_doc作为type，官方说在8.x版本会彻底移除type。 api请求方式也发送变化，如获得某索引的某ID的文档：GET index/_doc/id其中index和id为具体的值&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;7.1开始，Security功能免费使用&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;ECK-ElasticSearch Operator on Kubernetes&lt;/li&gt;
&lt;li&gt;引入了真正的内存断路器，它可以更精准地检测出无法处理的请求，并防止它们使单个节点不稳定&lt;/li&gt;
&lt;li&gt;Zen2 是 Elasticsearch 的全新集群协调层，提高了可靠性、性能和用户体验，变得更快、更安全，并更易于使用&lt;/li&gt;
&lt;li&gt;新功能
&lt;ul&gt;&lt;li&gt;New Cluster coordination&lt;/li&gt;
&lt;li&gt;Feature - Complete High Level REST Client&lt;/li&gt;
&lt;li&gt;Script Score Query&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;性能优化
&lt;ul&gt;&lt;li&gt;Weak-AND算法提高查询性能&lt;/li&gt;
&lt;li&gt;默认的Primary Shared数从5改为1，避免Over Sharding&lt;/li&gt;
&lt;li&gt;更快的前 k 个查询&lt;/li&gt;
&lt;li&gt;间隔查询(Intervals queries) 某些搜索用例（例如，法律和专利搜索）引入了查找单词或短语彼此相距一定距离的记录的需要。 Elasticsearch 7.0中的间隔查询引入了一种构建此类查询的全新方式，与之前的方法（跨度查询span queries）相比，使用和定义更加简单。 与跨度查询相比，间隔查询对边缘情况的适应性更强。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;h3 id=&quot;-&quot;&gt;总结&lt;/h3&gt;
&lt;p&gt;通过各个版本的迭代升级会发现，Elasticsearch 的产品的重大改善体验，了解了版本间的不同，会让你认知提高一个档次，网上文章一大片，有的时候你发现，文章作者操作的时候成功的，到了你这里就失败了，百思不得其中的奥秘，或者我的一个方法或者对象怎么就没了，谁对谁错，没有定论，懂得事情的本质才是重点，回到问题的根源，才是解决问题的根本。&lt;/p&gt;
&lt;p&gt;希望本篇的介绍可以让你在学习 Elasticsearch 的路上更顺畅，等你学完了Elasticsearch最新版本后，回过头来再看这篇文章的时候，感觉是不是一样的，我觉得学习一门技术的时候，心里要对全部轮廓有个认知，不至于钻进一个空间，看不到整个森林的尴尬无效的境地。 就像本文标题所说，先看整个森林，再去钻研一课树木，才会更懂。&lt;/p&gt;
&lt;h3 id=&quot;end&quot;&gt;END&lt;/h3&gt;
&lt;p&gt;如有收获，请帮忙转发，后续会有更好文章贡献，您的鼓励是作者最大的动力！&lt;/p&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;欢迎关注我的公众号：架构师的修炼，获得独家整理的学习资源和日常干货推送。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;参考文章：&lt;/p&gt;
</description>
<pubDate>Mon, 30 Sep 2019 14:42:00 +0000</pubDate>
<dc:creator>会飞的笨石头</dc:creator>
<og:description>在学习Elasticsearch 时候，因为各个版本的问题，搞不清，非常的头疼，官方也给出了各个版本更新的情况，不过是英文版本，版本更新信息又特别多，最近学习，看了很多资料，没有一个整理很清楚的，然后</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/flyrock/p/11614396.html</dc:identifier>
</item>
<item>
<title>记腾讯一月 - 寒月十八</title>
<link>http://www.cnblogs.com/ihardcoder/p/11614339.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/ihardcoder/p/11614339.html</guid>
<description>&lt;p&gt;入职腾讯一月余，有喜有忧有苦有涩，其间种种有预想之内有意料之外，仔细品鉴颇得意趣。&lt;/p&gt;
&lt;p&gt;毕业之后五年经历的三份工作不论是技术侧重点还是行业方向都有很大差别。我记得校招面试时当时优酷的技术总监Peak问过我一个很经典的问题：你的职业规划是什么？&lt;/p&gt;
&lt;p&gt;这是一个几乎每个应聘者都会在面试过程中别问到的问题，但是能清楚并且坚持自己发展轨迹的人并不多。回想起当时我的答案，很庆幸时至今日仍未偏离。&lt;/p&gt;
&lt;p&gt;我要用三到五年的时间尽可能多地接触不同的技术方向，扩宽知识面和技能栈，在此期间公司规模也好产品类型也罢都是其次的。然后在此之后选择一个垂直技术领域深耕下去，幸运的话还可能遇到自己喜欢的产业方向。&lt;/p&gt;
&lt;p&gt;我一向认为在展望未来之前一定要扎根现在，职业生涯的规划同样如此。技术从业者如果要选择哪个领域值得终身投入，一定要有宽阔的技术视野以及丰富的技术沉淀。我这人很笨，所以需要多花点时间。&lt;/p&gt;
&lt;p&gt;幸运的是，在从业的第五年我确定了两个值的投身的技术领域：第一是serverless；第二是面向大数据的图形编程。然后以这两个方向为目标，我有幸得到阿里和腾讯抛来的橄榄枝。&lt;/p&gt;
&lt;p&gt;选择是件很难的事，尤其是吸引力相当的二选一。经过一番挣扎后最终还是拒绝了薪酬稍高一点的阿里。&lt;/p&gt;
&lt;p&gt;其实在现在这个年龄和阶段，要选择的不仅仅是一份聊以糊口的营生，而是付以终生的职业。薪酬自然也不再是衡量一份工作的核心因素了。&lt;/p&gt;
&lt;p&gt;选择腾讯的原因有二：第一是腾讯TCB团队的云开发是业内（不只是国内）鲜有的基于serverless的对端解决方案。这种敢为天下先的气魄就足够吸引人了；第二是因为团队初创，并且serverless该如何做其实业内还未完全统一，所以有很大的空间可供开拓。加入腾讯至今的一月余我充分感受到了创业氛围下的机遇和挑战。&lt;/p&gt;
&lt;p&gt;特殊的是，团队在深圳，而我因为家庭原因短期内无法过去只能暂时在北京办公。其实因为老婆有哮喘也不是没想过转移到空气好的南方城市，不过毕竟这是一个家庭的事，况且还有车子房子狗子。最终老周家董事会达成一致，过去深圳之前留出一年左右的过渡期，最晚明年秋天转移阵地。&lt;/p&gt;
&lt;p&gt;远程工作这一点在应聘之前就已经跟团队沟通过，对于团队的宽容还真有些惊讶，毕竟我从来没有经历过这种工作模式。&lt;/p&gt;
&lt;p&gt;不过还是有些低估了远程工作的难度，虽然这个时代的人都习惯了线上沟通（我工位旁边的两位邻居老哥从来没面对面说过话，都是腾讯会议线上聊...），但有些事情还是不如当面聊。而且工作不仅是工作本身，同事之间的感情也是重要的一部分，而线上沟通是没有温度的。&lt;/p&gt;
&lt;p&gt;我很清楚这种工作模式下一定要做出一些改变，不能等着别人给你派任务，一定要有很强的自驱动和主导性。不能太依赖团队的帮助，一个人就是一个团队。&lt;/p&gt;
&lt;p&gt;在这方面我本来是挺有自信的，在搜狗推动地铁图的重构和落地、webgl引擎从数据制备到开发，虽然最终很遗憾没有上线但是其间的过程还是很有成就感的。&lt;/p&gt;
&lt;p&gt;但腾讯不同。&lt;/p&gt;
&lt;p&gt;在搜狗之所以能技术推动有很大一部分原因是别人不愿意做这种吃力不讨好的事，只要坚持一定很成功。&lt;/p&gt;
&lt;p&gt;而腾讯的团队都是顶尖的人才，尤其是在这种创新型业务中从来不缺乏优秀的点子和落地能力。&lt;/p&gt;
&lt;p&gt;挑战很大。而远程工作的模式又进一步增强了难度。&lt;/p&gt;
&lt;p&gt;过去的这一个月，除了新员工培训的两天半里很轻松以外，其他的时间不论是工作日还是节假日，神经都是高度紧绷。在加入腾讯之前，这种状态只有在2013年刚参加第一份实习工作初期有过。&lt;/p&gt;
&lt;p&gt;不过这种紧迫感同时也令我有些兴奋，我很庆幸在这个阶段还能过面临如此挑战。加油，小（老）伙（家）子（伙）！&lt;/p&gt;
&lt;p&gt;院子里的花草很久没打理了，有几片枯叶落在地上，还未深秋，是缺水了。&lt;/p&gt;
</description>
<pubDate>Mon, 30 Sep 2019 14:13:00 +0000</pubDate>
<dc:creator>寒月十八</dc:creator>
<og:description>入职腾讯一月余，有喜有忧有苦有涩，其间种种有预想之内有意料之外，仔细品鉴颇得意趣。 毕业之后五年经历的三份工作不论是技术侧重点还是行业方向都有很大差别。我记得校招面试时当时优酷的技术总监Peak问过我</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/ihardcoder/p/11614339.html</dc:identifier>
</item>
<item>
<title>详解http报文 - stoneFang</title>
<link>http://www.cnblogs.com/stoneFang/p/11614253.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/stoneFang/p/11614253.html</guid>
<description>&lt;p&gt;作为一个web开发者，每天都在使用者Http协议，却总是一知半解。本文参看Http RFC7230规范，梳理了http报文部分。&lt;/p&gt;

&lt;p&gt;start-line: 起始行,描述请求或响应的基本信息&lt;br/&gt;*( header-field CRLF ): 头&lt;br/&gt;CRLF&lt;br/&gt;[ message-body ]: 消息body，实际传输的数据&lt;/p&gt;

&lt;h3 id=&quot;起始行&quot;&gt;起始行&lt;/h3&gt;
&lt;p&gt;起始行的格式就是&lt;br/&gt;start-line = request-line(请求起始行）/（响应起始行）status-line&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1147363/201909/1147363-20190930213910670-756614859.png&quot; alt=&quot;在这里插入图片描述&quot;/&gt;&lt;/p&gt;

&lt;p&gt;这些格式就是规则，用来解析的&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;顺序&lt;/strong&gt;&lt;br/&gt;理论上头字段的key顺序是无所谓的，但是最佳实践是将控制字段放在前面，比如请求的时候Host,响应的Date，这样可以尽快发现是否需要处理。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;重复&lt;/strong&gt;&lt;br/&gt;除了&lt;code&gt;Set-Cookie&lt;/code&gt;这个key，其他都不行，如果发送方发了重复的key，接收方会将它合并，值是以逗号分隔。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;字段限制&lt;/strong&gt;&lt;br/&gt;协议本身对每个头字段没有限制，但是在工程实践中的得出过一些实践，没有通用的限制，和字段具体的语义有关。整体的header大小限制没有定义标准值，有些4K，有些8K。server端检查到header头超过了限制值，处于安全考虑，不会忽略掉。而是会抛出4XX错误。&lt;/p&gt;
&lt;p&gt;只有&lt;code&gt;Host&lt;/code&gt;字段是请求头中必须带的,其他无所谓。&lt;/p&gt;
&lt;table&gt;&lt;thead/&gt;&lt;tbody readability=&quot;6&quot;&gt;&lt;tr class=&quot;odd&quot; readability=&quot;2&quot;&gt;&lt;td&gt;Host&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;告诉服务器应该由哪个主机处理&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;even&quot; readability=&quot;3&quot;&gt;&lt;td&gt;User-Agent&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;标识浏览器类型，虽然已经被用烂了，不太可信，但有时候可以用来自定义类型&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;odd&quot; readability=&quot;3&quot;&gt;&lt;td&gt;Accept&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;可以接收的body类型 mime type,比如text/html&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;even&quot;&gt;&lt;td&gt;Accept-Charset&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;可以接收的字符集&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;odd&quot; readability=&quot;2&quot;&gt;&lt;td&gt;Accept-Encoding&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;可以接收的编码格式&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;even&quot;&gt;&lt;td&gt;Accept-Language&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;可以接收的多语言&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;odd&quot; readability=&quot;2&quot;&gt;&lt;td&gt;Content-Type&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;发送的body类型mime type&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;even&quot;&gt;&lt;td&gt;Content-Encoding&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;发送的编码&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;odd&quot;&gt;&lt;td&gt;Content-Language&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;发送的语言&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;这边有完整的分类&lt;br/&gt;&lt;a href=&quot;https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers&quot; class=&quot;uri&quot;&gt;https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;body&quot;&gt;body&lt;/h2&gt;
&lt;p&gt;header是必须有要有的，但是body就不一定要用。&lt;/p&gt;
&lt;p&gt;body就是传输的内容。因为Http是应用层协议，所以除了传输数据，还需要定义传输的数据格式。这些格式定义在header中指定。&lt;code&gt;Content-Length&lt;/code&gt;请求或者响应的body长度，必须要带上这个字段，以便对方可以方便的分辨出报文的边界，也就是Body数据何时结束。如果Body太大，需要边计算边传输，不到最后计算结束是无法知道整个Body大小的，这个时候可以使用chunk传输，通过&lt;code&gt;Transfer-Encoding&lt;/code&gt;指定，这两个header key是互斥的，只能指定一个，如果指定了两个，接收端优先处理&lt;code&gt;Transfer-Encoding&lt;/code&gt;字段。通常body的数据比较多时，都使用chunk来传输，效率比较高。没有了length，怎么知道数据传输结束了，通过一个长度为 0的chunk，对应的分块数据没有内容，来表示body内容结束。&lt;br/&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1147363/201909/1147363-20190930213911554-369391225.png&quot; alt=&quot;在这里插入图片描述&quot;/&gt;&lt;/p&gt;

&lt;p&gt;jetty 是web容器，需要解析Http Request,发送Http Response。具体干了什么下回分析&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;关注公众号【方丈的寺院】，第一时间收到文章的更新，与方丈一起开始技术修行之路&lt;/strong&gt;&lt;br/&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1147363/201909/1147363-20190930213911828-1893601803.jpg&quot; alt=&quot;在这里插入图片描述&quot;/&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://tools.ietf.org/pdf/rfc7230.pdf&quot; class=&quot;uri&quot;&gt;https://tools.ietf.org/pdf/rfc7230.pdf&lt;/a&gt;&lt;br/&gt;&lt;a href=&quot;https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers&quot; class=&quot;uri&quot;&gt;https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers&lt;/a&gt;&lt;/p&gt;
</description>
<pubDate>Mon, 30 Sep 2019 13:39:00 +0000</pubDate>
<dc:creator>stoneFang</dc:creator>
<og:description>摘要 作为一个web开发者，每天都在使用者Http协议，却总是一知半解。本文参看Http RFC7230规范，梳理了http报文部分。 http 报文构成 start line: 起始行,描述请求或响</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/stoneFang/p/11614253.html</dc:identifier>
</item>
<item>
<title>三大特征提取器（RNN/CNN/Transformer） - 西多士NLP</title>
<link>http://www.cnblogs.com/sandwichnlp/p/11612596.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/sandwichnlp/p/11612596.html</guid>
<description>&lt;h2 id=&quot;简介&quot;&gt;简介&lt;/h2&gt;
&lt;p&gt;近年来，深度学习在各个NLP任务中都取得了SOTA结果。这一节，我们先了解一下现阶段在自然语言处理领域最常用的特征抽取结构。&lt;/p&gt;
&lt;blockquote readability=&quot;4.2805755395683&quot;&gt;
&lt;p&gt;本文部分参考张俊林老师的文章&lt;a href=&quot;https://zhuanlan.zhihu.com/p/54743941&quot;&gt;《放弃幻想，全面拥抱Transformer：自然语言处理三大特征抽取器（CNN/RNN/TF）比较》&lt;/a&gt;(写的非常好，学NLP必看博文)，这里一方面对博文进行一定程度上的总结，并加上一些个人理解。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;在深度学习流行起来之后，随着我们的网络越做越深，我们的神经网络模型越来越像一个黑箱，我们只要喂给它数据，我们的模型就能够根据我们的给予的目标，自动学习抽取对于该任务最有利的特征（这点在CV中更为明显，比如在卷积神经网络的不同层能够输出图像中不同层面上的细节特征），从而实现了著名的“端到端”模型。在这里，我们可以把我们的CNN、RNN以及Transformer看作抽取数据特征的特征抽取器。下面，本文将为大家简单介绍RNN、CNN及NLP新宠Transformer的基本结构及其优缺点。&lt;/p&gt;
&lt;h2 id=&quot;循环神经网络rnn&quot;&gt;循环神经网络RNN&lt;/h2&gt;
&lt;h3 id=&quot;传统rnn&quot;&gt;传统RNN&lt;/h3&gt;
&lt;p&gt;在2018年以前，在NLP各个子领域的State of Art的结果都是RNN（此处包含LSTM、GRU等变种）得到的。为什么RNN在NLP领域能够有如此广泛的应用？我们知道如果将全连接网络运用到NLP任务上，其会面临三个主要问题：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;对于不同的输入样本，输入和输出可能有不同的长度，因此输入层和输出层的神经元数量无法固定。&lt;/li&gt;
&lt;li&gt;从输入文本的不同位置学到的同一特征无法共享。&lt;/li&gt;
&lt;li&gt;模型中的参数太多，计算量太大。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;为了解决上述问题，我们就有了熟悉的RNN网络结构。其通过扫描数据输入的方式，使得每一个时间步的所有网络参数是共享的，且每个时间步不仅会接收当前时刻的输入，同时会接收上一个时刻的输出，从而使得其能够成功利用过去输入的信息来辅助当前时刻的判断。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1816627/201909/1816627-20190930141015118-2108536640.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;但是，原始的RNN也存在问题，它采取线性序列结构不断从前往后收集输入信息，但这种线性序列结构不擅长捕获文本中的长期依赖关系，如下图所示。这主要是因为反向传播路径太长，从而容易导致严重的梯度消失或梯度爆炸问题。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1816627/201909/1816627-20190930141026972-1584328027.png&quot;/&gt;&lt;/p&gt;
&lt;h3 id=&quot;长短期记忆网络lstm&quot;&gt;长短期记忆网络(LSTM)&lt;/h3&gt;
&lt;p&gt;传统RNN的做法是将的所有知识全部提取出来，不作任何处理的输入到下一个时间步进行迭代。就像参加考试一样，如果希望事先把书本上的所有知识都记住，到了考试的时候，早期的知识恐怕已经被近期的知识完全覆盖了，提取不到长远时间步的信息是很正常的。而人类是这样做的吗？显然不是的，我们通常的做法是对知识有一个理性性判断，重要的知识给予更高的权重，重点记忆，不那么重要的可能没多久就忘了，这样，才能在面对考试的时候有较好的发挥。&lt;/p&gt;
&lt;p&gt;在我看来，LSTM的结构更类似于人类对于知识的记忆方式。理解LSTM的关键就在于理解两个状态&lt;span class=&quot;math inline&quot;&gt;\(c^{t}\)&lt;/span&gt;和&lt;span class=&quot;math inline&quot;&gt;\(a^t\)&lt;/span&gt;和内部的三个门机制：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1816627/201909/1816627-20190930141204340-1433729632.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;图中我们可以看见，LSTM Cell在每个时间步接收上个时间步的输入有两个，传给下一个时间步的输出也有两个。通常，我们将&lt;span class=&quot;math inline&quot;&gt;\(c(t)\)&lt;/span&gt;看作全局信息，&lt;span class=&quot;math inline&quot;&gt;\(a^t\)&lt;/span&gt;看作全局信息对下一个Cell影响的隐藏状态。&lt;/p&gt;
&lt;p&gt;遗忘门、输入门(图中的update gate)和输出门分别都是一个激活函数为sigmoid的小型单层神经网络。由于sigmoid在&lt;span class=&quot;math inline&quot;&gt;\((0, 1)\)&lt;/span&gt;范围内的取值，有效的用于判断是保留还是“遗忘”信息（乘以接近1的值表示保留，乘以接近0的值表示遗忘），为我们提供了信息选择性传输的能力。这样，我们就很好理解门在LSTM是怎样工作的了：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;遗忘门有两个输入：当前时间步的输入&lt;span class=&quot;math inline&quot;&gt;\(x^t\)&lt;/span&gt;以及上一层输出的隐藏状态&lt;span class=&quot;math inline&quot;&gt;\(a^{t-1}\)&lt;/span&gt;，遗忘门通过这两个输入训练出一个门函数，注意这个门函数的输出是在&lt;span class=&quot;math inline&quot;&gt;\((0, 1)\)&lt;/span&gt;之间的，将其与上一层输出的全局信息&lt;span class=&quot;math inline&quot;&gt;\(c^{t-1}\)&lt;/span&gt;相乘，表示全局信息被选择部分遗忘。&lt;/li&gt;
&lt;li&gt;对于输入门，我们那同样训练出一个门函数，与此同时，将接收到的&lt;span class=&quot;math inline&quot;&gt;\(a^{t-1}\)&lt;/span&gt;和&lt;span class=&quot;math inline&quot;&gt;\(x^t\)&lt;/span&gt;一起通过一个激活函数为tanh的小型神经网络，这一部分与传统RNN无异了，就是将上一时刻得到的信息与该时刻得到的信息进行整合。将整合信息与门函数的输出相乘，相当于同样选择有保留的提取新信息，并将其直接加在全局信息中去。&lt;/li&gt;
&lt;li&gt;对于输出门，同样的训练出一个门函数，与此同时，将新的隐藏状态&lt;span class=&quot;math inline&quot;&gt;\(c^t\)&lt;/span&gt;通过一个简单的tanh函数(仅仅是激活函数)后与门函数的输出相乘，则可以得到该时刻全局信息对下一个Cell影响的隐藏状态&lt;span class=&quot;math inline&quot;&gt;\(a^t\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;这样看下来，是不是觉得LSTM已经十分&quot;智能&quot;了呢？但实际上，LSTM还是有其局限性：时序性的结构一方面使其很难具备高效的并行计算能力（当前状态的计算不仅要依赖当前的输入，还要依赖上一个状态的输出），另一方面使得整个LSTM模型（包括其他的RNN模型，如GRU）总体上更类似于一个马尔可夫决策过程，较难以提取全局信息。&lt;/p&gt;
&lt;p&gt;关于GRU的结构我这里就不细讲了，在参考文献中有很多相关资料，大家想了解的可以去看看，简单来说，GRU可以看作一个LSTM的简化版本，其将&lt;span class=&quot;math inline&quot;&gt;\(a^t\)&lt;/span&gt;与&lt;span class=&quot;math inline&quot;&gt;\(c^t\)&lt;/span&gt;两个变量整合在一起，且讲遗忘门和输入门整合为更新门，输出门变更为重制门，大体思路没有太大变化。两者之间的性能往往差别不大，但GRU相对来说参数量更少。收敛速度更快。对于较少的数据集我建议使用GRU就已经足够了，对于较大的数据集，可以试试有较多参数量的LSTM有没有令人意外的效果。&lt;/p&gt;
&lt;h2 id=&quot;卷积神经网络cnn&quot;&gt;卷积神经网络CNN&lt;/h2&gt;
&lt;p&gt;CNN是计算机视觉领域的重大突破，也是目前用于处理CV任务模型的核心。CNN同样适用于NLP任务中的特征提取，但其使用场景与RNN略有不同，这部分我会多写一点，因为关于CNN在NLP任务中的应用大家相对来说应该都没那么了解。&lt;br/&gt;关于二维卷积核的运算如下图所示，我就不赘述了。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1816627/201909/1816627-20190930141549815-705067012.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;从数据结构上来看，CV任务中的输入数据为图像像素矩阵，其各个方向上的像素点之间的相关性基本上是等同的。而NLP任务中的输入数据通常为序列文本，假设句子长度为&lt;span class=&quot;math inline&quot;&gt;\(n\)&lt;/span&gt;，我们词向量的维度为&lt;span class=&quot;math inline&quot;&gt;\(d\)&lt;/span&gt;，我们的输入就成了一个&lt;span class=&quot;math inline&quot;&gt;\(n \times d\)&lt;/span&gt;的矩阵，显然，该矩阵的行列“像素”之间的相关性是不一样的，矩阵的同一行为一个词的向量表征，而不同行表示不同词。要让卷积网络能够正常的”读“我们的文本，我们在NLP中就需要使用一维卷积。Kim在2014年首次将CNN用于NLP中的文本分类任务，其提出的网络结构如下图所示：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1816627/201909/1816627-20190930141607219-1978451424.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;可以看见，一维卷积与二维卷积不同的是，每一个卷积核的宽度与词向量的维度&lt;span class=&quot;math inline&quot;&gt;\(d\)&lt;/span&gt;是相同的，以保证卷积核每次处理n个词的完整词向量，从上往下依次滑动卷积，这个过程中的输出就成了我们需要的特征向量。这就是CNN抽取特征的过程。在卷积层之后通常接上Max Pooling层（用于抽取最显著的特征），用于对输出的特征向量进行降维提取操作，最后再接一层全连接层实现文本分类。&lt;/p&gt;
&lt;p&gt;虽然传统CNN经过简单的改变之后可以成功的应用于NLP任务，且效果还不错，但效果也仅仅是“不错“而已，很多任务还是处于完全被压制的情况。这表明传统的CNN在NLP领域中还是存在一些问题。&lt;/p&gt;
&lt;h3 id=&quot;nlp界cnn模型的进化史&quot;&gt;NLP界CNN模型的进化史&lt;/h3&gt;
&lt;p&gt;谈到CNN在NLP界的进化，我们首先来看看Kim版CNN存在哪些问题。&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;Kim版CNN实际上类似于一个k-gram模型(k即卷积核的window，表示每次卷积的时候覆盖多少单词)，对于一个单层的k-gram模型是难以捕捉到距离&lt;span class=&quot;math inline&quot;&gt;\(d \ge k\)&lt;/span&gt;的特征的；&lt;/li&gt;
&lt;li&gt;卷积层输出的特征向量是包含了位置信息的(与卷积核的卷积顺序有关)，在卷积层之后接Max Pooling层（仅仅保留提取特征中最大值）将导致特征信息中及其重要的位置编码信息丢失。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1816627/201909/1816627-20190930141702775-1273651806.jpg&quot;/&gt;&lt;/p&gt;
&lt;p&gt;为了解决上述问题，研究者们采取了一系列方法对Kim版的CNN进行改进。&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;解决长远距离的信息提取的一个主要方法就是可以把网络做的更深一些，越深的卷积核将会有更大的感受野，从而捕获更远距离的特征。&lt;/li&gt;
&lt;li&gt;另外，我们也可以采用膨胀卷积(Dilated Convolution)的方式，也就是说我们的卷积窗口不再覆盖连续区域，而是跳着覆盖，这样，同样尺寸的卷积核我们就能提取到更远距离的特征了。当然这里的空洞卷积与CV中的还是不一样的，其仅仅在词间存在空洞，在词向量内部是不存在空洞的。在&lt;a href=&quot;https://kexue.fm/archives/5409&quot;&gt;苏神的博客&lt;/a&gt;里对比了同样&lt;span class=&quot;math inline&quot;&gt;\(window=3\)&lt;/span&gt;的卷积核，膨胀卷积和普通卷积在三层网络时每个神经元的感受野大小，如下图所示，可以看见膨胀卷积的神经元感受野的范围是大大增加的。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1816627/201909/1816627-20190930141747052-26401651.png&quot;/&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;为了防止文本中的位置信息丢失，NLP领域里的CNN的发展趋势是抛弃Pooling层，靠全卷积层来叠加网络深度，并且在输入部分加入位置编码，人工将单词的位置特征加入到对应的词向量中。位置编码的方式可以采用《Attention is All You Need》中的方案，在下面介绍Transformer的时候再详细介绍&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1816627/201909/1816627-20190930141759716-884415447.png&quot;/&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;我们知道在CV领域中，网络做深之后将存在一系列问题，因此有了残差网络。在NLP中同样可以使用残差网络，解决梯度消失问题，解决梯度消失问题的本质是能够加速信息流动，使简单的信息传输可以有更简单的路径，从而使得网络做深的同时，能够保证良好的性能。&lt;/li&gt;
&lt;li&gt;激活函数开始采用GLU(Gated Linear Unit)，如下图所示，左右两个卷积核的尺寸完全一样，但是权值参数不共享，然后其中一个通过一个sigmoid函数，另一个不通过，将两者相乘。是不是感觉有点熟悉，这其实与LSTM中的门机制是相同的效果，该激活函数可以自行控制输出的特征的强弱大小。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1816627/201909/1816627-20190930141928264-1009756895.png&quot;/&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;在苏神的博客中还学到另一个应用，就是可以用&lt;span class=&quot;math inline&quot;&gt;\(window=1\)&lt;/span&gt;的一维卷积对人工合成的词嵌入表征进行特征压缩，从而得到一个更有效的词向量表征方法。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1816627/201909/1816627-20190930141939827-1101499779.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;在很多地方都看见CNN比较适用于文本分类的任务，事实上，从《Convolutional Sequence to Sequence Learning》、《Fast Reading Comprehension with ConvNets》等论文与实践报告来看，CNN已经发展成为一种成熟的特征提取器，并且，相比于RNN来说，CNN的窗口滑动完全没有先后关系，不同卷积核之前也没有相互影响，因此其具有非常高的并行自由度，这是其非常好的一个优点。&lt;/p&gt;
&lt;h2 id=&quot;transformer&quot;&gt;Transformer&lt;/h2&gt;
&lt;p&gt;Transformer是在论文《Attentnion is all you need》里首次被提出的。&lt;/p&gt;
&lt;blockquote readability=&quot;2.5333333333333&quot;&gt;
&lt;p&gt;Transformer详解推荐这篇文章：&lt;a href=&quot;https://zhuanlan.zhihu.com/p/54356280&quot; class=&quot;uri&quot;&gt;https://zhuanlan.zhihu.com/p/54356280&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;在介绍Transformer之前，我们先来看看Encoder-Decoder框架。现阶段的深度学习模型，我们通常都将其看作黑箱，而Encoder-Decoder框架则是将这个黑箱分为两个部分，一部分做编码，另一部分做解码。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1816627/201909/1816627-20190930142129185-758921483.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;在不同的NLP任务中，Encoder框架及Decoder框架均是由多个单独的特征提取器堆叠而成，比如说我们之前提到的LSTM结构或CNN结构。由最初的one-hot向量通过Encoder框架，我们将得到一个矩阵（或是一个向量），这就可以看作其对输入序列的一个编码。而对于Decoder结构就比较灵活饿了，我们可以根据任务的不同，对我们得到的“特征”矩阵或“特征”向量进行解码，输出为我们任务需要的输出结果。因此，对于不同的任务，如果我们堆叠的特征抽取器能够提取到更好的特征，那么理论上来说，在所有的NLP任务中我们都能够得到更好的表现。&lt;/p&gt;
&lt;p&gt;在2018年谷歌推出BERT，刷新各项记录，引爆了整个NLP界，其取得成功的一个关键因素是新的特征提取结构：Transformer的强大作用。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1816627/201909/1816627-20190930142140231-915392076.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;Transformer结构是在论文《Attention is All You Need》中提出的的模型，如上图所示。图中红框内为Encoder框架，黄框内为Decoder框架，其均是由多个Transformer Block堆叠而成的。这里的Transformer Block就代替了我们之前提到的LSTM和CNN结构作为了我们的特征提取器，也是其最关键的部分。更详细的示意图如下图所示。我们可以发现，编码器中的Transformer与解码器中的Transformer是有略微区别的，但我们通常使用的特征提取结构(包括Bert)主要是Encoder中的Transformer，那么我们这里主要理解一下Transformer在Encoder中是怎么工作的。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1816627/201909/1816627-20190930142150498-984956485.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;由上图可知，单个的Transformer Block主要由两部分组成：多头注意力机制(Multi-Head Attention)和前馈神经网络(Feed Forward)。&lt;/p&gt;
&lt;h3 id=&quot;多头注意力机制multi-head-attention&quot;&gt;3.1 多头注意力机制(Multi-Head Attention)&lt;/h3&gt;
&lt;p&gt;Multi-Head Attention模块结构如下图所示：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1816627/201909/1816627-20190930142201766-422858899.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;这里，我们就可以明白为什么这一部分被称为Multi-Head了，因为其本身就是由&lt;span class=&quot;math inline&quot;&gt;\(h\)&lt;/span&gt;个子模块Scaled Dot-Product Attention堆叠而成的，该模块也被称为Self-Attention模块。关于整个Multi-Head Attention，主要有一下几个关键点需要理解：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;Linear可以看作一个没有激活函数的全连接层，其各自维护了一个线性映射矩阵（神经网络的本质就是矩阵相乘）&lt;/li&gt;
&lt;li&gt;对于每一个Self-Attention，均有独立维护的三个线性映射矩阵&lt;span class=&quot;math inline&quot;&gt;\(W^V_i\)&lt;/span&gt;、&lt;span class=&quot;math inline&quot;&gt;\(W^K_i\)&lt;/span&gt;及&lt;span class=&quot;math inline&quot;&gt;\(W^Q_i\)&lt;/span&gt;(不同Self-Attention模块之间的权值不共享)，通过将输入的矩阵&lt;span class=&quot;math inline&quot;&gt;\(X\)&lt;/span&gt;与三个映射矩阵相乘，得到Self-Attetnion的三个输入Queries、Keys和Values。这V, Q, K三个矩阵的输入&lt;span class=&quot;math inline&quot;&gt;\(X\)&lt;/span&gt;是完全一样的(均为输入句子的Input Embedding + Positional Encoding或是上一层Transformer的输出)，这一点从整个的Encoder模型中也可以看出来。&lt;/li&gt;
&lt;li&gt;在论文中，作者对于8个Self-Attention的输出，进行简单的拼接，并通过与一个映射矩阵&lt;span class=&quot;math inline&quot;&gt;\(W^O\)&lt;/span&gt;与其相乘（目的是对输出矩阵进行压缩），从而得到整个Multi-Head Attention的输出&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;在Multi-Head Attention中，最关键的部分就是Self-Attention部分了，这也是整个模型的核心配方，我们将其展开，如下图所示。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1816627/201909/1816627-20190930142214423-2061562768.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;我们之前已经提到过，Self-Attention的输入仅仅是矩阵&lt;span class=&quot;math inline&quot;&gt;\(X\)&lt;/span&gt;的三个线性映射。那么Self-Attention内部的运算具有什么样的含义呢？我们从单个词编码的过程慢慢理解：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;首先，我们对于输入单词向量&lt;span class=&quot;math inline&quot;&gt;\(X\)&lt;/span&gt;生成三个对应的向量: Query, Key 和 Value。注意这三个向量相比于向量&lt;span class=&quot;math inline&quot;&gt;\(X\)&lt;/span&gt;要小的多(论文中&lt;span class=&quot;math inline&quot;&gt;\(X\)&lt;/span&gt;的长度是512，三个向量的长度为64，这只是一种基于架构上的选择，因为论文中的Multi-Head Attention有8个Self-Attention模块，8个Self-Attention的输出要拼接，将其恢复成长度为512的向量)，这一个部分是对每个单词独立操作的&lt;/li&gt;
&lt;li&gt;用Queries和Keys的点积计算所有单词相对于当前词(图中为Thinking)的得分Score，该分数决定在编码单词“Thinking”时其他单词给予了多少贡献&lt;/li&gt;
&lt;li&gt;将Score除以向量维度(64)的平方根(保证Score在一个较小的范围，否则softmax的结果非零即1了)，再对其进行Softmax(将所有单词的分数进行归一化，使得所有单词为正值且和为1)。这样对于每个单词都会获得所有单词对该单词编码的贡献分数，当然当前单词将获得最大分数，但也将会关注其他单词的贡献大小&lt;/li&gt;
&lt;li&gt;对于得到的Softmax分数，我们将其乘以每一个对应的Value向量(弱化了softmax分数较低单词的影响，有点类似于之前的sigmoid门函数的思想)&lt;/li&gt;
&lt;li&gt;对所得的所有加权向量求和，即得到Self-Attention对于当前词”Thinking“的输出&lt;br/&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1816627/201909/1816627-20190930142231249-698042230.png&quot;/&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1816627/201909/1816627-20190930142222180-936702842.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;其实仔细思考一下就可以发现，Self-Attention与CNN是十分相似的。CNN通过简单的卷积运算提取特征，虽然有Dilated Convolution以及增加深度等方式来增大感受野，但是其本质上是一个n-gram模型。而在Self-Attention中，&lt;span class=&quot;math inline&quot;&gt;\(W^Q\)&lt;/span&gt;, &lt;span class=&quot;math inline&quot;&gt;\(W^K\)&lt;/span&gt;, &lt;span class=&quot;math inline&quot;&gt;\(W^V\)&lt;/span&gt;不也能看作三个卷积核吗，但是其通过一种更加巧妙的方式将卷积运算的结果进行整合，实现了直观上所谓的”注意力“，从而使得每一个词的编码结果均是句子中所有词的共同作用结果，其本质上是一个超大的词袋模型(包括句子中所有的词)。显然，上述过程可以用以下的矩阵形式进行并行计算:&lt;br/&gt;&lt;span class=&quot;math display&quot;&gt;\[Attention(Q, K, V) = softmax(\frac{QK^T}{\sqrt{d_k}})V\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;其中，Q, V, K分别表示输入句子的Queries, Keys, Values矩阵，矩阵的每一行为每一个词对应的向量Query, Key, Value向量，&lt;span class=&quot;math inline&quot;&gt;\(d_k\)&lt;/span&gt;表示向量长度。因此，Transformer同样也具有十分高效的并行计算能力。&lt;/p&gt;
&lt;p&gt;我们再回到Multi-Head Attention，我们将独立维护的8个Self-Attention的输出进行简单的拼接，通过一个先行映射层，就得到了单个多头注意力的输出。其整个过程可以总结为下面这个示意图：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1816627/201909/1816627-20190930142257588-424099064.png&quot;/&gt;&lt;/p&gt;
&lt;h3 id=&quot;位置编码positional-encoding&quot;&gt;位置编码(Positional Encoding)&lt;/h3&gt;
&lt;p&gt;我们之前提到过，由于RNN的时序性结构，所以天然就具备位置编码信息。CNN本身其实也能提取一定位置信息，但多层叠加之后，位置信息将减弱，位置编码可以看作是一种辅助手段。Transformer的每一个词的编码过程使得其基本不具备任何的位置信息(将词序打乱之后并不会改变Self-Attention的计算结果)，因此位置向量在这里是必须的，使其能够更好的表达词与词之间的距离。构造位置编码的公式如下所示：&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;math display&quot;&gt;\[\begin{cases} PE_{2i}(p)=sin(p/10000^{2i/d_{pos}}) \\ PE_{2i+1}(p)=cos(p/10000^{2i/d_{pos}}) \end{cases}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;如果词嵌入的长度&lt;span class=&quot;math inline&quot;&gt;\(d_{pos}\)&lt;/span&gt;，则我们需要构造一个长度同样为&lt;span class=&quot;math inline&quot;&gt;\(d_{pos}\)&lt;/span&gt;的位置编码向量&lt;span class=&quot;math inline&quot;&gt;\(PE\)&lt;/span&gt;。其中&lt;span class=&quot;math inline&quot;&gt;\(p\)&lt;/span&gt;表示词的位置，&lt;span class=&quot;math inline&quot;&gt;\(PE_i(p)\)&lt;/span&gt;表示第p个词位置向量中的第i个元素的值，然后将词向量与位置向量直接相加。该位置编码不仅仅包含了绝对位置信息，由&lt;span class=&quot;math inline&quot;&gt;\(sin(\alpha + \beta) = sin \alpha cos \beta + cos \alpha sin \beta\)&lt;/span&gt;以及&lt;span class=&quot;math inline&quot;&gt;\(cos(\alpha + \beta) = cos \alpha cos \beta - sin \alpha sin \beta\)&lt;/span&gt;，这意味着我们可以&lt;span class=&quot;math inline&quot;&gt;\(p+k\)&lt;/span&gt;的位置向量可表示为位置&lt;span class=&quot;math inline&quot;&gt;\(p\)&lt;/span&gt;位置向量的线性变换，使得相对位置信息也得到了表达。Transformer论文中提到过他们用该方式得到的位置编码向量与训练得到的位置编码向量效果是十分接近的。&lt;/p&gt;
&lt;h3 id=&quot;残差模块residual-block&quot;&gt;残差模块(Residual Block)&lt;/h3&gt;
&lt;p&gt;我们之前说到Self-Attention与CNN的相似性。这里的残差运算同样是借鉴了CNN中的思想，其原理基本是一样的，我就不赘述了。在残差连接之后，还需要进行层归一化操作，其具体过程与&lt;a href=&quot;https://arxiv.org/abs/1607.06450&quot;&gt;Layer Normalization&lt;/a&gt;一致。&lt;/p&gt;
&lt;h3 id=&quot;transformer小结&quot;&gt;Transformer小结&lt;/h3&gt;
&lt;p&gt;到这里，整个Transformer的结构基本讲述完毕了。关于其相与RNN和CNN的性能比较，张俊林老师的文章里有详细的数据说明，我仅附上简单的总结：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;从语义特征提取能力：Transformer显著超过RNN和CNN，RNN和CNN两者能力差不太多。&lt;/li&gt;
&lt;li&gt;长距离特征捕获能力：CNN极为显著地弱于RNN和Transformer，Transformer微弱优于RNN模型，但在比较远的距离上（主语谓语距离大于13），RNN微弱优于Transformer，所以综合看，可以认为Transformer和RNN在这方面能力差不太多，而CNN则显著弱于前两者。这部分我们之前也提到过，CNN提取长距离特征的能力收到其卷积核感受野的限制，实验证明，增大卷积核的尺寸，增加网络深度，可以增加CNN的长距离特征捕获能力。而对于Transformer来说，其长距离特征捕获能力主要受到Multi-Head数量的影响，Multi-Head的数量越多，Transformer的长距离特征捕获能力越强&lt;/li&gt;
&lt;li&gt;任务综合特征抽取能力：通常，机器翻译任务是对NLP各项处理能力综合要求最高的任务之一，要想获得高质量的翻译结果，对于两种语言的词法，句法，语义，上下文处理能力，长距离特征捕获等方面的性能要求都是很高的。从综合特征抽取能力角度衡量，Transformer显著强于RNN和CNN，而RNN和CNN的表现差不太多。&lt;/li&gt;
&lt;li&gt;并行计算能力：对于并行计算能力，上文很多地方都提到过，并行计算是RNN的严重缺陷，而Transformer和CNN差不多。&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;由于平常科研任务也比较重，代码暂时没有时间上传，等发布序列标注以及文本分类等文章的时候代码会同步上传到Github，RNN/CNN/Transformer的代码也会包含在其中。&lt;/p&gt;
&lt;h4 id=&quot;参考资料&quot;&gt;参考资料&lt;/h4&gt;
&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/54743941&quot; class=&quot;uri&quot;&gt;https://zhuanlan.zhihu.com/p/54743941&lt;/a&gt;&lt;br/&gt;&lt;a href=&quot;http://www.ai-start.com/dl2017/html/lesson5-week1.html#header-n194&quot; class=&quot;uri&quot;&gt;http://www.ai-start.com/dl2017/html/lesson5-week1.html#header-n194&lt;/a&gt;&lt;br/&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/46327831&quot; class=&quot;uri&quot;&gt;https://zhuanlan.zhihu.com/p/46327831&lt;/a&gt;&lt;br/&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/55386469&quot; class=&quot;uri&quot;&gt;https://zhuanlan.zhihu.com/p/55386469&lt;/a&gt;&lt;br/&gt;&lt;a href=&quot;https://kexue.fm/archives/5409&quot; class=&quot;uri&quot;&gt;https://kexue.fm/archives/5409&lt;/a&gt;&lt;br/&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/54356280&quot; class=&quot;uri&quot;&gt;https://zhuanlan.zhihu.com/p/54356280&lt;/a&gt;&lt;br/&gt;&lt;a href=&quot;http://jalammar.github.io/illustrated-transformer/&quot; class=&quot;uri&quot;&gt;http://jalammar.github.io/illustrated-transformer/&lt;/a&gt;&lt;br/&gt;&lt;a href=&quot;https://kexue.fm/archives/4765&quot; class=&quot;uri&quot;&gt;https://kexue.fm/archives/4765&lt;/a&gt;&lt;/p&gt;
</description>
<pubDate>Mon, 30 Sep 2019 13:15:00 +0000</pubDate>
<dc:creator>西多士NLP</dc:creator>
<og:description>[TOC] 三大特征提取器 RNN、CNN和Transformer 简介 近年来，深度学习在各个NLP任务中都取得了SOTA结果。这一节，我们先了解一下现阶段在自然语言处理领域最常用的特征抽取结构。</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/sandwichnlp/p/11612596.html</dc:identifier>
</item>
<item>
<title>opencv目标检测之canny算法 - core!</title>
<link>http://www.cnblogs.com/sdu20112013/p/11614059.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/sdu20112013/p/11614059.html</guid>
<description>&lt;h2 id=&quot;canny&quot;&gt;canny&lt;/h2&gt;
&lt;p&gt;canny的目标有3个&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;低错误率 检测出的边缘都是真正的边缘&lt;/li&gt;
&lt;li&gt;定位良好 边缘上的像素点与真正的边缘上的像素点距离应该最小&lt;/li&gt;
&lt;li&gt;最小响应 边缘只能标识一次,噪声不应该标注为边缘&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;canny分几步&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;滤掉噪声 比如高斯滤波&lt;/li&gt;
&lt;li&gt;计算梯度 比如用索贝尔算子算出梯度&lt;/li&gt;
&lt;li&gt;非极大值抑制&lt;br/&gt;上一步算出来的边缘可能比较粗糙,假设边缘是一条很细的线的话,上面处理完的结果你可以理解为得到一条比较粗的线条,所谓非极大值抑制,就是要在局部像素点中找到变换最剧烈的一个点,这样就得到了更细的边缘.&lt;/li&gt;
&lt;li&gt;双阈值检测和连接边缘&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;前面2步我们应该很熟悉了,不熟悉的参考&lt;a href=&quot;https://www.cnblogs.com/sdu20112013/p/11608469.html&quot; class=&quot;uri&quot;&gt;https://www.cnblogs.com/sdu20112013/p/11608469.html&lt;/a&gt; 和 &lt;a href=&quot;https://www.cnblogs.com/sdu20112013/p/11600436.html&quot; class=&quot;uri&quot;&gt;https://www.cnblogs.com/sdu20112013/p/11600436.html&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&quot;非极大值抑制&quot;&gt;非极大值抑制&lt;/h3&gt;
&lt;p&gt;在求解梯度这一步,我们可以得到梯度的模长和方向&lt;br/&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/583030/201909/583030-20190930195434958-347290797.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;这一步为我们下面做nms(非极大值抑制)打下了基础,索贝尔算子处理后的图像得到的边缘可能是很粗糙的,反映到图像上也就是边缘比较宽,我们&lt;strong&gt;采用nms把非极大值的点的灰度都置为0,这样就可以滤掉很多非边缘的像素点&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;如下图所示，C表示为当前非极大值抑制的点，g1-4为它的8连通邻域点，图中蓝色线段表示上一步计算得到的角度图像C点的值，即梯度方向，第一步先判断C灰度值在8值邻域内是否最大，如是则继续检查图中梯度方向交点dTmp1,dTmp2值是否大于C，如C点大于dTmp1,dTmp2点的灰度值，则认定C点为极大值点，置为1，因此最后生成的图像应为一副二值图像，边缘理想状态下都为单像素边缘.&lt;br/&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/583030/201909/583030-20190930201325953-3879283.png&quot;/&gt;&lt;br/&gt;这一步里有一点需要注意的就是dTmp1,dTmp2,&lt;strong&gt;这两个像素点是不存在的,是通过双线性插值法算出来的&lt;/strong&gt;. 在John Canny提出的Canny算子的论文中，非最大值抑制就只是在0、90、45、135四个梯度方向上进行的，每个像素点梯度方向按照相近程度用这四个方向来代替.实际检测过程里,为了更准确地过滤出属于边缘的像素点,会做双线性插值得到dTmp1,dTmp2.再去做前面所说的nms过程去判断一个像素点是否属于边缘.&lt;br/&gt;推荐2篇讲的比较好的:&lt;a href=&quot;https://blog.csdn.net/kezunhai/article/details/11620357&quot; class=&quot;uri&quot;&gt;https://blog.csdn.net/kezunhai/article/details/11620357&lt;/a&gt; &lt;a href=&quot;https://www.cnblogs.com/techyan1990/p/7291771.html&quot; class=&quot;uri&quot;&gt;https://www.cnblogs.com/techyan1990/p/7291771.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;关于&lt;strong&gt;如何得到梯度方向的像素点&lt;/strong&gt;,如下图所示&lt;br/&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/583030/201909/583030-20190930195513689-1553981474.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;这样的话就达到了将&quot;粗大的边缘&quot;过滤地更加细腻.&lt;/p&gt;
&lt;p&gt;这一步之后,得到的边缘还包含很多由噪声及其他原因造成的假边缘.&lt;/p&gt;
&lt;h3 id=&quot;双阈值检测和边缘连接&quot;&gt;双阈值检测和边缘连接&lt;/h3&gt;
&lt;p&gt;经过nms以后,已经很接近真实边缘了.但还是有一些由于噪声或者别的一些原因造成的假的边缘.我们通过2个阈值来作进一步的过滤.&lt;/p&gt;
&lt;blockquote readability=&quot;11&quot;&gt;
&lt;p&gt;Hysteresis: The final step. Canny does use two thresholds (upper and lower): - If a pixel gradient is higher than the upper threshold, the pixel is accepted as an edge .If a pixel gradient value is below the lower threshold, then it is rejected.If the pixel gradient is between the two thresholds, then it will be accepted only if it is connected to a pixel that is above the upper threshold.&lt;br/&gt;&lt;strong&gt;Canny recommended a upper:lower ratio between 2:1 and 3:1.&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;&lt;li&gt;对于梯度大于高阈值的点,认为是真的边缘上的像素点.&lt;/li&gt;
&lt;li&gt;对于梯度小于低阈值的点,认为是假的边缘像素点,是噪声造成的,去掉这些点.&lt;/li&gt;
&lt;li&gt;对于梯度介于高低阈值之间的点,如果它周围的邻域像素点有&quot;真边缘点&quot;(也就是梯度大于高阈值的点),则认为这点也是&quot;真边缘点&quot;.&lt;br/&gt;&lt;strong&gt;推荐的高低阈值比在2:1到3:1之间&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;实际工程里,这两个参数要针对你自己的图像数据去调整,太低有可能造成假边缘太多,太高有可能造成想要保留的边缘也被滤掉了.&lt;br/&gt;&lt;a href=&quot;https://docs.opencv.org/master/dd/d1a/group__imgproc__feature.html#ga04723e007ed888ddf11d9ba04e2232de&quot;&gt;canny api&lt;/a&gt;&lt;br/&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/583030/201909/583030-20190930195644418-692091125.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;参数3,4表示低阈值和高阈值,L2gradient默认false,表示是否用开平方的方式计算梯度的大小.&lt;/p&gt;
&lt;h3 id=&quot;opencv示例&quot;&gt;opencv示例&lt;/h3&gt;
&lt;pre&gt;
&lt;code&gt;from __future__ import print_function
import cv2 as cv
import argparse
max_lowThreshold = 100
window_name = 'Edge Map'
title_trackbar = 'Min Threshold:'
ratio = 3
kernel_size = 3
def CannyThreshold(val):
    low_threshold = val
    #img_blur = cv.blur(src_gray, (3,3))
    detected_edges = cv.Canny(src_gray, low_threshold, low_threshold*ratio, kernel_size)
    mask = detected_edges != 0
    dst = src * (mask[:,:,None].astype(src.dtype))
    cv.imshow(window_name, dst)

src = cv.imread(&quot;/home/sc/disk/keepgoing/opencv_test/sidetest.jpeg&quot;)
src = cv.GaussianBlur(src, (3, 3), 0)
src_gray = cv.cvtColor(src, cv.COLOR_BGR2GRAY)
cv.namedWindow(window_name)
cv.createTrackbar(title_trackbar, window_name , 0, max_lowThreshold, CannyThreshold)
CannyThreshold(0)
cv.waitKey()&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/583030/201909/583030-20190930195723705-1412429496.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/583030/201909/583030-20190930195830091-1184608493.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;注意阈值的不同造成的影响,可以看到阈值很低的时候线条更多,当然&quot;伪边缘&quot;更多,当阈值很高的时候,&quot;伪边缘&quot;减少了,但也丢失了更多的细节.所以需要根据自己实际的图片数据去调参.&lt;/p&gt;
</description>
<pubDate>Mon, 30 Sep 2019 12:18:00 +0000</pubDate>
<dc:creator>core!</dc:creator>
<og:description>canny canny的目标有3个 低错误率 检测出的边缘都是真正的边缘 定位良好 边缘上的像素点与真正的边缘上的像素点距离应该最小 最小响应 边缘只能标识一次,噪声不应该标注为边缘 canny分几步</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/sdu20112013/p/11614059.html</dc:identifier>
</item>
</channel>
</rss>