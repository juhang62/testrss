<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="css/feed.xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/" xmlns:og="http://ogp.me/ns#">
<channel>
<atom:link rel="self" href="http://192.168.1.4/fivefilters/makefulltextfeed.php?url=feed.cnblogs.com%2Fblog%2Fsitehome%2Frss&amp;max=10&amp;links=preserve&amp;exc=" />
<atom:link rel="alternate" title="Source URL" href="http://feed.cnblogs.com/blog/sitehome/rss" />
<atom:link rel="related" title="Subscribe to feed" href="http://www.subtome.com/#/subscribe?feeds=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed.cnblogs.com%252Fblog%252Fsitehome%252Frss%26max%3D10%26links%3Dpreserve%26exc%3D&amp;back=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed.cnblogs.com%252Fblog%252Fsitehome%252Frss%26max%3D10%26links%3Dpreserve%26exc%3D" />
<title>博客园_首页</title>
<link></link>
<description>代码改变世界</description>
<item>
<title>什么是Activiti - zer0black</title>
<link>http://www.cnblogs.com/zer0Black/p/12423405.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/zer0Black/p/12423405.html</guid>
<description>&lt;p&gt;Activiti属于工作流引擎的一个开源实现。Activiti由Tom Bayen发起。在2010年5月发布了第一个版本。命名也很有意思的采取了Activities（活动）的化简方式命名了该项目。现在最新的Acitiviti版本已经更新到了7.1.0&lt;/p&gt;
&lt;h3 id=&quot;什么是工作流引擎&quot;&gt;什么是工作流引擎&lt;/h3&gt;
&lt;p&gt;工作流框架则是为了解决业务流程诞生的。对于同一件事件，从起始到结束中间会经历非常多的状态甚至事件回退等操作。通过业务代码的方式实现该套逻辑较为复杂，且不可复用。而工作流框架是针对此种情况（购物流程、请假流程等等）提取出来的通用解决方案，让开发省去事件流转状态的操作&lt;/p&gt;
&lt;p&gt;现在绝大部分的工作流引擎都是根据2011年发布的&lt;code&gt;BPMN2.0&lt;/code&gt;规范实现，&lt;code&gt;BPMN2.0&lt;/code&gt;统一了业务流程图的标准，让各种工作流引擎的流程设计器可以通用&lt;/p&gt;
&lt;h3 id=&quot;acitviti特点&quot;&gt;Acitviti特点&lt;/h3&gt;
&lt;ol readability=&quot;2&quot;&gt;&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;数据持久化&lt;/p&gt;
&lt;p&gt;Activiti在数据存储上依赖了数据库，启动时会自动的创建表单。并且内部使用了Mybatis完成数据库的表查询等功能&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;引擎Service接口&lt;/p&gt;
&lt;table&gt;&lt;thead/&gt;&lt;tbody readability=&quot;7&quot;&gt;&lt;tr class=&quot;odd&quot; readability=&quot;2&quot;&gt;&lt;td&gt;RespositoryService&lt;/td&gt;
&lt;td&gt;管理流程仓库，如部署、删除、读取流程资源等&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;even&quot; readability=&quot;2&quot;&gt;&lt;td&gt;IdentifyService&lt;/td&gt;
&lt;td&gt;管理和查询用户、组之间的关系&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;odd&quot; readability=&quot;2&quot;&gt;&lt;td&gt;RuntimeService&lt;/td&gt;
&lt;td&gt;处理所有正在运行状态的流程实例、任务&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;even&quot; readability=&quot;2&quot;&gt;&lt;td&gt;TaskService&lt;/td&gt;
&lt;td&gt;管理查询任务，如签收、办理、指派等&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;odd&quot; readability=&quot;2&quot;&gt;&lt;td&gt;FormService&lt;/td&gt;
&lt;td&gt;用于读取和流程、任务相关的表单数据&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;even&quot; readability=&quot;2&quot;&gt;&lt;td&gt;HistoryService&lt;/td&gt;
&lt;td&gt;查询所有历史数据，如流程实例、任务、活动、变量、附件等&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;odd&quot; readability=&quot;2&quot;&gt;&lt;td&gt;ManagementService&lt;/td&gt;
&lt;td&gt;引擎管理，和具体业务无关，如查询引擎配置、数据库、作业等&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;原生支持Spring&lt;/p&gt;
&lt;p&gt;在Spring Boot流行的今天，Activiti 7 已经可以快速的和Spring Boot 2.0进行整合了&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;2&quot;&gt;
&lt;p&gt;分离运行时与历史数据&lt;/p&gt;
&lt;p&gt;表结构设计上遵循运行时数据与历史数据分离，可快速读取运行时数据。需查询历史数据再从专门的历史表中读取。提高了当前执行流程的存取效率&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;&lt;h3 id=&quot;acitviti架构与组件&quot;&gt;Acitviti架构与组件&lt;/h3&gt;
&lt;ol readability=&quot;2.5&quot;&gt;&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;Activiti Engine&lt;/p&gt;
&lt;p&gt;核心模块，提供对BPMN2.0规范的解析、执行、创建、管理（如无、流程实例）、查询历史记录并根据结构生成报表等&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;Activiti Modeler&lt;/p&gt;
&lt;p&gt;模型设计器，帮助业务人员把需求转换成规范的流程定义&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;Activiti Designer&lt;/p&gt;
&lt;p&gt;类Activiti Modeler，但由Activiti团队自行研发&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;Activiti Explorer&lt;/p&gt;
&lt;p&gt;用于管理仓库、用户、组、启动流程、任务办理等。是基于REST风格的API&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;Activiti REST&lt;/p&gt;
&lt;p&gt;也是Restful风格的服务，允许客户端以JSON方式与引擎的API进行交互&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;&lt;h3 id=&quot;总结&quot;&gt;总结&lt;/h3&gt;
&lt;p&gt;Activiti作为流程引擎，提供了任务流转所需的所有功能。并且提供了设计器、API等多个组件用于进行流程的定义和流程的管理&lt;/p&gt;
</description>
<pubDate>Fri, 06 Mar 2020 00:52:00 +0000</pubDate>
<dc:creator>zer0black</dc:creator>
<og:description>什么是Activiti Activiti属于工作流引擎的一个开源实现。Activiti由Tom Bayen发起。在2010年5月发布了第一个版本。命名也很有意思的采取了Activities（活动）的化</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/zer0Black/p/12423405.html</dc:identifier>
</item>
<item>
<title>统计 Django 项目的测试覆盖率 - 削微寒</title>
<link>http://www.cnblogs.com/xueweihan/p/12419866.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/xueweihan/p/12419866.html</guid>
<description>&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/759200/202002/759200-20200213202051843-983322874.jpg&quot;/&gt;&lt;/p&gt;
&lt;p&gt;作者：&lt;a href=&quot;https://www.zmrenwu.com&quot;&gt;HelloGitHub-追梦人物&lt;/a&gt;&lt;/p&gt;
&lt;blockquote readability=&quot;3.4666666666667&quot;&gt;
&lt;p&gt;文中所涉及的示例代码，已同步更新到 &lt;a href=&quot;https://github.com/HelloGitHub-Team/HelloDjango-blog-tutorial&quot;&gt;HelloGitHub-Team 仓库&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;我们完成了对 blog 应用和 comment 应用这两个核心 app 的测试。现在我们想知道的是究竟测试效果怎么样呢？测试充分吗？测试全面吗？还有没有没有测到的地方呢？&lt;/p&gt;
&lt;p&gt;单凭肉眼观察难以回答上面的问题，接下来我们就借助 &lt;a href=&quot;https://coverage.readthedocs.io/en/coverage-5.0.3/index.html&quot;&gt;Coverage.py&lt;/a&gt;，从代码覆盖率的角度来检测一下我们的测试效果究竟如何。&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://coverage.readthedocs.io/en/coverage-5.0.3/index.html&quot;&gt;Coverage.py&lt;/a&gt; （以下简称 Coverage）是 Python 测试界最为流行的一个库之一，用来统计测试覆盖率。测试覆盖率可以从一个角度衡量代码的质量，覆盖率越高，说明测试越充分，代码出现 bug 的几率也就越小。当然需要注意的是，测试覆盖率仅仅只是衡量代码质量的一个角度，即使是 100% 的覆盖率也不能说代码就是完美的，没有 bug 的。&lt;/p&gt;
&lt;h2 id=&quot;安装-coverage&quot;&gt;安装 Coverage&lt;/h2&gt;
&lt;p&gt;要使用 Coverage，首先当然是安装它：&lt;/p&gt;
&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;$ pipenv install coverage --dev&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;因为只在开发时才用得到，所以使用 Pipenv 安装时加 --dev 选项将其标记为开发时的依赖库。&lt;/p&gt;
&lt;h2 id=&quot;简单配置-coverage&quot;&gt;简单配置 Coverage&lt;/h2&gt;
&lt;p&gt;Coverage 支持很多配置选项，为了方便，通常将这些配置写在名为 &lt;code&gt;.coveragerc&lt;/code&gt; 的文件中，Coverage 运行时会从项目根目录读取这个配置文件。因此先在&lt;strong&gt;项目根目录&lt;/strong&gt;创建这个文件并写入最基本的配置：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;[run]
branch = True
source = .

[report]
show_missing = True&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;Coverage 的配置遵循 ini 文件语法。简单来说就是，&lt;code&gt;[section]&lt;/code&gt; 代表一个配置块，用于组织相关的一组配置。例如这里 &lt;code&gt;[run]&lt;/code&gt; 是一个配置块，&lt;code&gt;[report]&lt;/code&gt; 是另一个配置块，两个块下都有相关的一些配置项。&lt;/p&gt;
&lt;p&gt;配置项的格式为 &lt;code&gt;key = value&lt;/code&gt; 。&lt;/p&gt;
&lt;p&gt;这几个简单配置项的含义为：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;code&gt;branch = True&lt;/code&gt;。是否统计条件语句的分支覆盖情况。if 条件语句中的判断通常有 True 和 False 两种情况，设置 &lt;code&gt;branch = True&lt;/code&gt; 后，Coverage 会测量这两种情况是否都被测试到。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;source = .&lt;/code&gt;。指定需统计的源代码目录，这里设置为当前目录（即项目根目录）。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;show_missing = True&lt;/code&gt;。在生成的统计报告中显示未被测试覆盖到的代码行号。&lt;/li&gt;
&lt;/ul&gt;&lt;h2 id=&quot;运行-coverage&quot;&gt;运行 Coverage&lt;/h2&gt;
&lt;p&gt;简单配置后，我们就可以来运行 Coverage 了。&lt;/p&gt;
&lt;p&gt;打开命令行，进入项目根目录，依次运行下面的命令（注意如果没有激活虚拟需使用 pipenv run 让命令在虚拟环境中执行）。&lt;/p&gt;
&lt;p&gt;首先运行 erase 命令清除上一次的统计信息&lt;/p&gt;
&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;$ pipenv run coverage erase&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;manage.py test 运行 django 单元测试，这是这一次用 coverage run 来运行&lt;/p&gt;
&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;$ pipenv run coverage run manage.py test&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;生成覆盖率统计报告&lt;/p&gt;
&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;$ pipenv run coverage report&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;覆盖率统计报告输出如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;Name                                             Stmts   Miss Branch BrPart  Cover   Missing
--------------------------------------------------------------------------------------------
_credentials.py                                      2      2      0      0     0%   1-2
blog\__init__.py                                     0      0      0      0   100%
blog\admin.py                                       11      0      0      0   100%
blog\apps.py                                         4      0      0      0   100%
blog\elasticsearch2_ik_backend.py                    8      0      0      0   100%
blog\feeds.py                                       12      0      0      0   100%
blog\migrations\0001_initial.py                      7      0      0      0   100%
blog\migrations\0002_auto_20190711_1802.py           7      0      0      0   100%
blog\migrations\0003_auto_20191011_2326.py           4      0      0      0   100%
blog\migrations\0004_post_views.py                   4      0      0      0   100%
blog\migrations\__init__.py                          0      0      0      0   100%
blog\models.py                                      62      0      0      0   100%
blog\search_indexes.py                               8      0      0      0   100%
blog\templatetags\__init__.py                        0      0      0      0   100%
blog\templatetags\blog_extras.py                    15      0      0      0   100%
blog\tests\__init__.py                               0      0      0      0   100%
blog\tests\test_models.py                           58      0      2      0   100%
blog\tests\test_smoke.py                             4      0      0      0   100%
blog\tests\test_templatetags.py                    115      0      2      0   100%
blog\tests\test_utils.py                            11      0      0      0   100%
blog\tests\test_views.py                           170      0      8      0   100%
blog\urls.py                                         4      0      0      0   100%
blog\utils.py                                       10      0      2      1    92%   14-&amp;gt;16
blog\views.py                                       40      7      2      0    79%   64-72
blogproject\__init__.py                              0      0      0      0   100%
blogproject\settings\__init__.py                     0      0      0      0   100%
blogproject\settings\common.py                      22      0      0      0   100%
blogproject\settings\local.py                        5      0      0      0   100%
blogproject\settings\production.py                   5      5      0      0     0%   1-8
blogproject\urls.py                                  4      0      0      0   100%
blogproject\wsgi.py                                  4      4      0      0     0%   10-16
comments\__init__.py                                 0      0      0      0   100%
comments\admin.py                                    6      0      0      0   100%
comments\apps.py                                     4      0      0      0   100%
comments\forms.py                                    6      0      0      0   100%
comments\migrations\0001_initial.py                  7      0      0      0   100%
comments\migrations\0002_auto_20191011_2326.py       4      0      0      0   100%
comments\migrations\__init__.py                      0      0      0      0   100%
comments\models.py                                  15      0      0      0   100%
comments\templatetags\__init__.py                    0      0      0      0   100%
comments\templatetags\comments_extras.py            12      0      2      0   100%
comments\tests\__init__.py                           0      0      0      0   100%
comments\tests\base.py                              10      0      0      0   100%
comments\tests\test_models.py                        8      0      0      0   100%
comments\tests\test_templatetags.py                 57      0      6      0   100%
comments\tests\test_views.py                        34      0      4      0   100%
comments\urls.py                                     4      0      0      0   100%
comments\views.py                                   17      0      2      0   100%
fabfile.py                                          21     21      0      0     0%   1-43
manage.py                                           12      2      2      1    79%   11-12, 20-&amp;gt;exit
scripts\__init__.py                                  0      0      0      0   100%
scripts\fake.py                                     63     63     14      0     0%   1-106
--------------------------------------------------------------------------------------------
TOTAL                                              876    104     46      2    87%&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;倒数第二列是被统计文件的测试覆盖率，第一列是未被覆盖的代码行号。&lt;/p&gt;
&lt;p&gt;大部分文件测试覆盖率为 100%，说明我们的测试还是比较充分的。但从报告结果中我们发现这样几个问题：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;有一些文件其实并不需要测试，或者并非项目的核心文件（例如部署脚本 fabfile.py，django 的 migrations 文件等），这些文件应该从统计中排除。&lt;/li&gt;
&lt;li&gt;Coverage 默认显示全部文件的覆盖率统计结果，如果文件比较多的话就不好查找非 100% 覆盖率的文件。毕竟我们的目标是提高代码覆盖率，因此已达 100% 覆盖的代码文件我们不再关心。我们要做的是找到非 100% 覆盖率的文件，为其添加缺失的测试。&lt;/li&gt;
&lt;/ol&gt;&lt;h2 id=&quot;完善-coverage-配置&quot;&gt;完善 Coverage 配置&lt;/h2&gt;
&lt;p&gt;可以通过添加 Coverage 配置项轻松解决上面 2 个问题。&lt;/p&gt;
&lt;p&gt;在 &lt;code&gt;[run]&lt;/code&gt; 配置块中增加 &lt;code&gt;omit&lt;/code&gt; 配置项可以指定排除统计的文件。&lt;/p&gt;
&lt;p&gt;在 &lt;code&gt;[report]&lt;/code&gt; 配置块中增加 &lt;code&gt;skip_covered&lt;/code&gt; 配置项可以指定统计报告中不显示 100% 覆盖的文件。&lt;/p&gt;
&lt;p&gt;这是 &lt;code&gt;.coveragerc&lt;/code&gt; 最终配置结果，注意我们在 omit 配置项中指定忽略了一些非核心的项目文件：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;[run]
branch = True
source = .
omit =
   _credentials.py
   manage.py
   blogproject/settings/*
   fabfile.py
   scripts/fake.py
   */migrations/*
   blogproject\wsgi.py

[report]
show_missing = True
skip_covered = True&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;再次按照上一节所说的方式运行 Coverage，最终报告结果如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;Name            Stmts   Miss Branch BrPart  Cover   Missing
-----------------------------------------------------------
blog\utils.py      10      0      2      1    92%   14-&amp;gt;16
blog\views.py      40      7      2      0    79%   64-72
-----------------------------------------------------------
TOTAL             709      7     30      1    99%

33 files skipped due to complete coverage.&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;这个报告指出我们仍有 2 个文件没有达到 100% 的覆盖率，我们要做的就是为这两个文件中未测试的代码增加单元测试，让其达到 100% 测试覆盖率。&lt;/p&gt;
&lt;p&gt;不过在动手写测试之前，我们要搞清楚哪些代码没被测到。命令行报告的最后一列指出了未被测试代码的行号，但是这样看着不是很直观。一种体验更好的方式是生成 HTML 报告，这样我们可以直接在 HTML 报告中查看到未被测试到的具体代码。&lt;/p&gt;
&lt;h2 id=&quot;生成-html-报告&quot;&gt;生成 HTML 报告&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;coverage report&lt;/code&gt; 命令在命令行生成统计报告，而 &lt;code&gt;coverage html&lt;/code&gt; 则可以生成 HTML 报告。&lt;/p&gt;
&lt;p&gt;在上一节的基础上，运行如下命令：&lt;/p&gt;
&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;$ pipenv run coverage html&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;运行完成后项目根目录会多出一个 htmlcov 的文件夹，里面就是测试覆盖率的 HTML 报告文件。用浏览器打开里面的 index.html 文件就可以查看报告结果了：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/759200/202003/759200-20200305135059863-1454372220.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;主页和命令行的结果是一样的，不过我们可以点击文件名，进入到对这个文件更加具体的统计报告页面，例如 &lt;strong&gt;blog\views.py&lt;/strong&gt; 结果如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/759200/202003/759200-20200305135117451-702760735.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;绿色部分代表已覆盖的代码，红色部分代表为覆盖的代码。&lt;/p&gt;
&lt;h2 id=&quot;完善单元测试&quot;&gt;完善单元测试&lt;/h2&gt;
&lt;p&gt;查看文件我们发现，&lt;strong&gt;blog\views.py&lt;/strong&gt; 中未被覆盖的代码原来是 &lt;a href=&quot;https://www.zmrenwu.com/courses/hellodjango-blog-tutorial/materials/85/&quot;&gt;Django 博客实现简单的全文搜索&lt;/a&gt; 中的代码，现在我们已经将搜索替换为 &lt;a href=&quot;https://www.zmrenwu.com/courses/hellodjango-blog-tutorial/materials/86/&quot;&gt;Django Haystack 全文检索&lt;/a&gt; 了，这段代码也就不需要了，可以直接删除。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;blog\views.py&lt;/strong&gt; 的报告结果则表明我们在 &lt;a href=&quot;https://www.zmrenwu.com/courses/hellodjango-blog-tutorial/materials/86/&quot;&gt;Django Haystack 全文检索与关键词高亮&lt;/a&gt; 中自定义的搜索关键词高亮器有一个 if 分支条件未被测试到：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/759200/202003/759200-20200305135125866-1113873626.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;检查 blog/tests/test_utils.py 中的测试用例，我们发现只测试了比较短的标题不被截断，也就是&lt;/p&gt;
&lt;pre class=&quot;python&quot;&gt;
&lt;code&gt;if len(text_block) &amp;lt; self.max_length:&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;判断条件为 True，缺失对判断条件为 False 的测试。所以我们来构造一个新的测试用例测试标题长度超过 &lt;code&gt;max_length&lt;/code&gt; （默认值为 200）的情况时会被截断：&lt;/p&gt;
&lt;pre class=&quot;python&quot;&gt;
&lt;code&gt;class HighlighterTestCase(TestCase):
    def test_highlight(self):
        # 省略已有代码 ...

        highlighter = Highlighter(&quot;标题&quot;)
        document = &quot;这是一个长度超过 200 的标题，应该被截断。&quot; + &quot;HelloDjangoTutorial&quot; * 200
        self.assertTrue(
            highlighter.highlight(document).startswith(
                '...&amp;lt;span class=&quot;highlighted&quot;&amp;gt;标题&amp;lt;/span&amp;gt;，应该被截断。'
            )
        )&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;再次运行 Coverage 生成报告，测试覆盖率全都 100% 了！&lt;/p&gt;
&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;$ pipenv run coverage erase
$ pipenv run coverage run manage.py test
$ pipenv run coverage report
# 输出
Name    Stmts   Miss Branch BrPart  Cover   Missing
---------------------------------------------------
---------------------------------------------------
TOTAL     704      0     28      0   100%&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;最后提醒一点，Coverage 运行后可能会在项目目录下生成一些文件，这些文件并不需要纳入版本管理，所以将其加入 .gitignore 文件中，防止被提交到代码库：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;htmlcov/
.coverage
.coverage.*
coverage.xml
*.cover&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;hellodjango-往期回顾&quot;&gt;HelloDjango 往期回顾：&lt;/h2&gt;
&lt;p&gt;第 30 篇：&lt;a href=&quot;https:////www.cnblogs.com/xueweihan/p/12372401.html&quot;&gt;Django 博客单元测试：测试评论应用&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;第 29 篇：&lt;a href=&quot;https:////www.cnblogs.com/xueweihan/p/12336462.html&quot;&gt;编写 Django 应用单元测试&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;第 28 篇：&lt;a href=&quot;https://www.cnblogs.com/xueweihan/p/12304983.html&quot;&gt;Django Haystack 全文检索与关键词高亮&lt;/a&gt;&lt;/p&gt;
&lt;hr/&gt;&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/759200/202002/759200-20200213201956024-782757549.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;关注公众号加入交流群&lt;/strong&gt;&lt;/p&gt;
</description>
<pubDate>Fri, 06 Mar 2020 00:21:00 +0000</pubDate>
<dc:creator>削微寒</dc:creator>
<og:description>作者： &amp;quot;HelloGitHub 追梦人物&amp;quot; 文中所涉及的示例代码，已同步更新到 &amp;quot;HelloGitHub Team 仓库&amp;quot; 我们完成了对 blog 应用和 c</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/xueweihan/p/12419866.html</dc:identifier>
</item>
<item>
<title>AI：深度学习用于文本处理 - renyuzhuo</title>
<link>http://www.cnblogs.com/renyuzhuo/p/12422886.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/renyuzhuo/p/12422886.html</guid>
<description>&lt;p&gt;同本文一起发布的另外一篇文章中，提到了 BlueDot 公司，这个公司致力于利用人工智能保护全球人民免受传染病的侵害，在本次疫情还没有引起强烈关注时，就提前一周发出预警，一周的时间，多么宝贵！&lt;/p&gt;
&lt;p&gt;他们的 AI 预警系统，就用到了深度学习对文本的处理，这个系统抓取网络上大量的新闻、公开声明等获取到的数十万的信息，对自然语言进行处理，我们今天就聊聊深度学习如何对文本的简单处理。&lt;/p&gt;
&lt;p&gt;文本，String 或 Text，就是字符的序列或单词的序列，最常见的是单词的处理（我们暂时不考虑中文，中文的理解和处理与英文相比要复杂得多）。计算机就是固化的数学，对文本的处理，在本质上来说就是固化的统计学，这样采用统计学处理后的模型就可以解决许多简单的问题了。下面我们开始吧。&lt;/p&gt;
&lt;h2 id=&quot;处理文本数据&quot;&gt;处理文本数据&lt;/h2&gt;
&lt;p&gt;与之前一致，如果原始要训练的数据不是向量，我们要进行向量化，文本的向量化，有几种方式：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;按照单词分割&lt;/li&gt;
&lt;li&gt;按照字符分割&lt;/li&gt;
&lt;li&gt;提取单词的 n-gram&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;我喜欢吃火……，你猜我接下来会说的是什么？1-gram 接下来说什么都可以，这个词与前文没关系；2-gram 接下来可能说“把，柴，焰”等，组成词语“火把、火柴、火焰”；3-gram 接下来可能说“锅”，组成“吃火锅”，这个概率更大一些。先简单这么理解，n-gram 就是与前 n-1 个词有关。&lt;/p&gt;
&lt;p&gt;我们今天先来填之前挖下来的一个坑，当时说以后将介绍 one-hot，现在是时候了。&lt;/p&gt;
&lt;h2 id=&quot;one-hot-编码&quot;&gt;one-hot 编码&lt;/h2&gt;
&lt;pre&gt;
&lt;code&gt;def one_hot():
​    samples = ['The cat sat on the mat', 'The dog ate my homework']
    token_index = {}
    # 分割成单词
    for sample in samples:
        for word in sample.split():
            if word not in token_index:
                token_index[word] = len(token_index) + 1
    # {'The': 1, 'cat': 2, 'sat': 3, 'on': 4, 'the': 5, 'mat.': 6, 'dog': 7, 'ate': 8, 'my': 9, 'homework.': 10}
    print(token_index)
 
    max_length = 8
    results = np.zeros(shape=(len(samples), max_length, max(token_index.values()) + 1))
    for i, sample in enumerate(samples):
        for j, word in list(enumerate(sample.split()))[:max_length]:
            index = token_index.get(word)
            results[i, j, index] = 1.
​
    print(results)&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;img src=&quot;https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy8yMDIzNTY5LTM3ZDI3YzNmMDQyMzY2MjI?x-oss-process=image/format,png&quot; alt=&quot;结果&quot;/&gt;&lt;/p&gt;
&lt;p&gt;我们看到，这个数据是不好的，mat 和 homework 后面都分别跟了一个英文的句话 '.'，要炫技写那种高级的正则表达式去匹配这个莫名其妙的符号吗？当然不是了，没错，Keras 有内置的方法。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;def keras_one_hot():
    samples = ['The cat sat on the mat.', 'The dog ate my homework.']
    tokenizer = Tokenizer(num_words=1000)
    tokenizer.fit_on_texts(samples)
    sequences = tokenizer.texts_to_sequences(samples)
    print(sequences)
    one_hot_results = tokenizer.texts_to_matrix(samples, mode='binary')
    print(one_hot_results)
    word_index = tokenizer.word_index
    print(word_index)
    print('Found %s unique tokens.' % len(word_index))&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;img src=&quot;https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy8yMDIzNTY5LWM2ZTIzYzg3MzA4MTRiMWM?x-oss-process=image/format,png&quot; alt=&quot;结果&quot;/&gt;&lt;/p&gt;
&lt;p&gt;这里的 num_words 和上面的 max_length 都是用来表示多少个最常用的单词，控制好这个，可以大大的减少运算量训练时间，甚至有点时候能更好的提高准确率，希望引起一定注意。我们还可以看到得到的编码的向量，很大一部分都是 0，不够紧凑，这会导致大量的内存占用，不好不好，有什么什么其他办法呢？答案是肯定的。&lt;/p&gt;
&lt;h2 id=&quot;词嵌入&quot;&gt;词嵌入&lt;/h2&gt;
&lt;p&gt;也叫词向量。词嵌入通常是密集的，维度低的（256、512、1024）。那到底什么叫词嵌入呢？&lt;/p&gt;
&lt;p&gt;本文我们的主题是处理文本信息，文本信息就是有语义的，对于没有语义的文本我们什么也干不了，但是我们之前的处理方法，其实就是概率上的统计，，是一种单纯的计算，没有理解的含义（或者说很少），但是考虑到真实情况，“非常好” 和 “非常棒” 的含义是相近的，它们与 “非常差” 的含义是相反的，因此我们希望转换成向量的时候，前两个向量距离小，与后一个向量距离大。因此看下面一张图，是不是就很容易理解了呢：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy8yMDIzNTY5LTE2MmI0Mzc3YTNlZDk5Y2Y?x-oss-process=image/format,png&quot; alt=&quot;image&quot;/&gt;&lt;/p&gt;
&lt;p&gt;可能直接让你去实现这个功能有点难，幸好 Keras 简化了这个问题，Embedding 是内置的网络层，可以完成这个映射关系。现在理解这个概念后，我们再来看看 IMDB 问题（电影评论情感预测），代码就简单了，差不都可以达到 75%的准确率：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;def imdb_run():
    max_features = 10000
    maxlen = 20
    (x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)
    x_train = preprocessing.sequence.pad_sequences(x_train, maxlen=maxlen)
    model = Sequential()
    model.add(Embedding(10000, 8, input_length=maxlen))
    model.add(Flatten())
    model.add(Dense(1, activation='sigmoid'))
    model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])
    model.summary()
    history = model.fit(x_train, y_train, epochs=10, batch_size=32, validation_split=0.2)&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;我们的数据量有点少，怎么办呢？上一节我们在处理图像的时候，用到的方法是使用预训练的网络，这里我们采用类似的方法，采用预训练的词嵌入。最流行的两种词嵌入是 GloVe 和 Word2Vec，我们后面还是会在合适的时候分别介绍这两个词嵌入。今天我们采用 GloVe 的方法，具体做法我写在了代码的注释中。我们还是先看结果，代码还是放在最后：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy8yMDIzNTY5LThiY2ZiOGYyMjEzNTlhNjU?x-oss-process=image/format,png&quot; alt=&quot;image&quot;/&gt;&lt;/p&gt;
&lt;p&gt;很快就过拟合了，你可能觉得这个验证精度接近 60%，考虑到训练样本只有 200 个，这个结果真的还挺不错的，当然，你可能不信，那么我再给出两组对比图，一组是没有词嵌入的：&lt;/p&gt;
&lt;p&gt;[外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-Uem4R2hO-1583414769394)(&lt;a href=&quot;https://upload-images.jianshu.io/upload_images/2023569-23b0d32d9d3db11d?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240&quot;&gt;https://upload-images.jianshu.io/upload_images/2023569-23b0d32d9d3db11d?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240&lt;/a&gt;)]&lt;/p&gt;
&lt;p&gt;验证精度明显偏低，再给出 2000 个训练集的数据：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy8yMDIzNTY5LWIzNmY3NTM0OGViNTA0Zjg?x-oss-process=image/format,png&quot; alt=&quot;image&quot;/&gt;&lt;/p&gt;
&lt;p&gt;这个精度就高了很多，追求这个高低不是我们的目的，我们的目的是说明词嵌入是有效的，我们达到了这个目的，好了，接下来我们看看代码吧：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;#!/usr/bin/env python3
​
import os
import time
​
import matplotlib.pyplot as plt
import numpy as np
from keras.layers import Embedding, Flatten, Dense
from keras.models import Sequential
from keras.preprocessing.sequence import pad_sequences
from keras.preprocessing.text import Tokenizer
​
​
def deal():
    # http://mng.bz/0tIo
    imdb_dir = '/Users/renyuzhuo/Documents/PycharmProjects/Data/aclImdb'
    train_dir = os.path.join(imdb_dir, 'train')
    labels = []
    texts = []
    # 读出所有数据
    for label_type in ['neg', 'pos']:
        dir_name = os.path.join(train_dir, label_type)
        for fname in os.listdir(dir_name):
            if fname[-4:] == '.txt':
                f = open(os.path.join(dir_name, fname))
                texts.append(f.read())
                f.close()
                if label_type == 'neg':
                    labels.append(0)
                else:
                    labels.append(1)
​
    # 对所有数据进行分词
    # 每个评论最多 100 个单词
    maxlen = 100
    # 训练样本数量
    training_samples = 200
    # 验证样本数量
    validation_samples = 10000
    # 只取最常见 10000 个单词
    max_words = 10000
    # 分词，前文已经介绍过了
    tokenizer = Tokenizer(num_words=max_words)
    tokenizer.fit_on_texts(texts)
    sequences = tokenizer.texts_to_sequences(texts)
    word_index = tokenizer.word_index
    print('Found %s unique tokens.' % len(word_index))
    # 将整数列表转换成张量
    data = pad_sequences(sequences, maxlen=maxlen)
    labels = np.asarray(labels)
    print('Shape of data tensor:', data.shape)
    print('Shape of label tensor:', labels.shape)
    # 打乱数据
    indices = np.arange(data.shape[0])
    np.random.shuffle(indices)
    data = data[indices]
    labels = labels[indices]
    # 切割成训练集和验证集
    x_train = data[:training_samples]
    y_train = labels[:training_samples]
    x_val = data[training_samples: training_samples + validation_samples]
    y_val = labels[training_samples: training_samples + validation_samples]
​
    # 下载词嵌入数据，下载地址：https: // nlp.stanford.edu / projects / glove
    glove_dir = '/Users/renyuzhuo/Documents/PycharmProjects/Data/glove.6B'
    embeddings_index = {}
    f = open(os.path.join(glove_dir, 'glove.6B.100d.txt'))
    # 构建单词与其x向量表示的索引
    for line in f:
        values = line.split()
        word = values[0]
        coefs = np.asarray(values[1:], dtype='float32')
        embeddings_index[word] = coefs
    f.close()
    print('Found %s word vectors.' % len(embeddings_index))
​
    # 构建嵌入矩阵
    embedding_dim = 100
    embedding_matrix = np.zeros((max_words, embedding_dim))
    for word, i in word_index.items():
        if i &amp;lt; max_words:
            embedding_vector = embeddings_index.get(word)
            if embedding_vector is not None:
                embedding_matrix[i] = embedding_vector
​
    # 构建模型
    model = Sequential()
    model.add(Embedding(max_words, embedding_dim, input_length=maxlen))
    model.add(Flatten())
    model.add(Dense(32, activation='relu'))
    model.add(Dense(1, activation='sigmoid'))
    model.summary()
​
    # 将 GloVe 加载到 Embedding 层，且将其设置为不可训练
    model.layers[0].set_weights([embedding_matrix])
    model.layers[0].trainable = False
​
    # 训练模型
    model.compile(optimizer='rmsprop',
                  loss='binary_crossentropy',
                  metrics=['acc'])
    history = model.fit(x_train, y_train,
                        epochs=10,
                        batch_size=32,
                        validation_data=(x_val, y_val))
    model.save_weights('pre_trained_glove_model.h5')
​
    # 画图
    acc = history.history['acc']
    val_acc = history.history['val_acc']
    loss = history.history['loss']
    val_loss = history.history['val_loss']
    epochs = range(1, len(acc) + 1)
    plt.plot(epochs, acc, 'bo', label='Training acc')
    plt.plot(epochs, val_acc, 'b', label='Validation acc')
    plt.title('Training and validation accuracy')
    plt.legend()
    plt.show()
​
    plt.figure()
    plt.plot(epochs, loss, 'bo', label='Training loss')
    plt.plot(epochs, val_loss, 'b', label='Validation loss')
    plt.title('Training and validation loss')
    plt.legend()
    plt.show()
​
​
if __name__ == &quot;__main__&quot;:
    time_start = time.time()
    deal()
    time_end = time.time()
    print('Time Used: ', time_end - time_start)&lt;/code&gt;
&lt;/pre&gt;
&lt;blockquote readability=&quot;4.3548387096774&quot;&gt;
&lt;p&gt;本文首发自公众号：&lt;a href=&quot;%5Bhttps://ai.renyuzhuo.cn/%5D(https://ai.renyuzhuo.cn/)&quot;&gt;RAIS&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
</description>
<pubDate>Thu, 05 Mar 2020 17:15:00 +0000</pubDate>
<dc:creator>renyuzhuo</dc:creator>
<og:description>同本文一起发布的另外一篇文章中，提到了 BlueDot 公司，这个公司致力于利用人工智能保护全球人民免受传染病的侵害，在本次疫情还没有引起强烈关注时，就提前一周发出预警，一周的时间，多么宝贵！ 他们的</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/renyuzhuo/p/12422886.html</dc:identifier>
</item>
<item>
<title>计算机科学之算法——你不得不知的递归 - WarrenRyan</title>
<link>http://www.cnblogs.com/WarrenRyan/p/12424152.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/WarrenRyan/p/12424152.html</guid>
<description>&lt;blockquote readability=&quot;3.4677419354839&quot;&gt;
&lt;p&gt;本系列文章在Github:&lt;a href=&quot;https://github.com/StevenEco/ComputerScience&quot;&gt;StevenEco&lt;/a&gt;以及&lt;a href=&quot;https://www.cnblogs.com/warrenryan&quot;&gt;WarrenRyan&lt;/a&gt;同步更新&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;简介&quot;&gt;简介&lt;/h2&gt;
&lt;p&gt;程序调用自身的编程技巧称为递归 &lt;strong&gt;&lt;em&gt;(recursion)&lt;/em&gt;&lt;/strong&gt; 。递归做为一种算法在程序设计语言中广泛应用。 一个过程或函数在其定义或说明中有直接或间接调用自身的一种方法，它通常把一个大型复杂的问题层层转化为一个与原问题相似的规模较小的问题来求解，递归策略只需少量的程序就可描述出解题过程所需要的多次重复计算，大大地减少了程序的代码量。递归的能力在于用有限的语句来定义对象的无限集合。一般来说，递归需要有边界条件、递归前进段和递归返回段。当边界条件不满足时，递归前进；当边界条件满足时，递归返回。&lt;/p&gt;
&lt;h2 id=&quot;小例子&quot;&gt;小例子&lt;/h2&gt;
&lt;p&gt;看着很抽象？那么我们举一个具体的例子：假设有一天，你正在学校上课，你坐在最后一排，突然你有一件重要的事情需要和第一排的同学进行沟通，你又不能随意走动，那么你应该怎么解决呢？于是你写了一个小纸条，给你前面的同学，并且告诉他转交给第一排的同学，于是前排同学又将小纸条递给了他的前排，循环往复，直到第一排的同学收到小纸条。第一排的同学看完小纸条，写了他要对你说的话，于是他又将纸条递给他的后座，一直递到你为止。这个小例子就是递归的本质思想，你的小纸条就是参数，而传递的过程，事实上都是在执行传递函数的本身。&lt;/p&gt;
&lt;p&gt;如果用编程语言来体现刚才的小例子，那么代码就是&lt;/p&gt;
&lt;pre class=&quot;c#&quot;&gt;
&lt;code&gt;string Deliver(int row,string msg)
{
    if(row == 1)
    {
        return &quot;Read:&quot; + msg;
    }
    return Deliver(--row,msg);
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;再举一个例子，斐波那契数列是一个很常见的数列，它的通项公式是 &lt;span class=&quot;math inline&quot;&gt;\(f(n+2) = f(n) + f(n+1)\)&lt;/span&gt;,我们可以发现，它并没有提及斐波那契数列的表达式，而是给了一个抽象的函数递推式，那么这个时候我们就可以使用递归，将问题简化成一个递推的内容而不是具体的实现。用代码则是&lt;/p&gt;
&lt;pre class=&quot;c#&quot;&gt;
&lt;code&gt;int fib(int n)
{
    if(n == 1 || n == 2)
    {
        return 1
    }
    return fib(n-1) + fib(n-2);
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;通常，递归必须拥有递推式和跳出条件，因为这可以保证函数不会爆栈，我们要从三个角度去做一个递归：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;递归的定义：接受什么参数，返回什么值，代表什么意思 。当函数直接或者间接调⽤⾃⼰时，则发⽣了递归&lt;/li&gt;
&lt;li&gt;递归的拆解：每次递归都是为了让问题规模变⼩&lt;/li&gt;
&lt;li&gt;递归的出⼝：必须有⼀个明确的结束条件。因为递归就是有“递”有“归”，所以必须又有一个明确的点，到了这个点，就不用“递下去”，而是开始“归来”。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;总而言之，递归就是尽可能忽略函数内部的实现，主要关注函数整体需要做的事情。&lt;/p&gt;
&lt;h2 id=&quot;递归的本质&quot;&gt;递归的本质&lt;/h2&gt;
&lt;p&gt;通过上述的小例子，你可能已经理解了递归的含义，但是为什么通过函数调用函数这种“诡异”的操作可以实现我们的内容呢？如果你在阅读本篇文章之前已经有了一些基础的数据结构和程序语言知识，那么你会知道函数的调用是在栈中实现的，当函数嵌套调用时，系统会将这些函数压入栈中，而栈是先进后出的性质，那么当递归调用时，会一次性将函数压栈到可以return的那个子函数，然后子函数执行完毕返回后，再将返回值带给父函数，再执行父函数。也就是说，递归其实就是一个隐式的栈。&lt;/p&gt;
&lt;p&gt;通过这个进栈出栈的过程，一个大的抽象问题就被分解成了若干个嵌套的子问题，子问题一层一层被解决，直到最后一个起始层。&lt;/p&gt;
&lt;p&gt;简单的解释就是，递归事实上也是两个问题&lt;/p&gt;
&lt;p&gt;递：将问题不断细化直到最小，例如斐波那契数列的问题，fib(5)在程序中的递大致是&lt;/p&gt;
&lt;pre class=&quot;c&quot;&gt;
&lt;code&gt;fib(5) = fib(4) + fib(3);
fib(5) = (fib(3) + fib(2)) + (fib(2) + fib(1))
fib(5) = ((fib(2) + fib(1)) + fib(2)) + (fib(2) + fib(1));&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;归过程就是将上述递过程的子问题逐步返回到顶层。&lt;/p&gt;
&lt;p&gt;整个过程和我们往第一排传纸条再传回来是完全一致的。&lt;/p&gt;
&lt;h2 id=&quot;递归的用途&quot;&gt;递归的用途&lt;/h2&gt;
&lt;p&gt;我们会发现递归非常的节省代码，而且看起来似乎也没有空间损耗。但真的是这样的吗？答案肯定是否的。诚然，递归会让代码的简洁程度和可读性大幅上涨（可读性上升，但是并不容易被理解和Debug），但是递归也并不是什么时候都是好的。&lt;/p&gt;
&lt;p&gt;首先递归最常用的地方就是链表、树、图等含指针的数据结构的操作和计算，因为在这种地方，使用队列、栈等辅助的数据结构会使得代码非常长，并且对于许多算法羸弱的码农并不容易写出来。例如树的中序遍历，对于非递归的方法，你需要借助栈，并且严格的需要保证入栈顺序。而对于后序遍历，你可能还需要借助哈希表来保证左右节点已经被访问，这显然不好。对于递归，只有短短的几行&lt;/p&gt;
&lt;pre class=&quot;c#&quot;&gt;
&lt;code&gt;void InOrder(Tree tree)
{
    if (tree == null)
        return;
    InOrder(tree.Left);
    Console.WriteLine(tree.Value);
    InOrder(tree.Right);
}
void PostOrder(Tree tree)
{
    if (tree == null)
        return;
    PostOrder(tree.Left);
    PostOrder(tree.Right);
    Console.WriteLine(tree.Value);
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;相比于普通的代码显得更加简洁明了。&lt;/p&gt;
&lt;h2 id=&quot;自顶向下与自底向上&quot;&gt;自顶向下与自底向上&lt;/h2&gt;
&lt;p&gt;但是有时候递归会造成严重的性能问题，尤其会导致栈溢出的问题，事实上函数本身压栈是并不消耗什么空间的，因为本身只是一个指针，并不需要存储任何内容。但是存在返回值的时候，函数需要将返回值保存，因此一同申请空间。当函数栈过深的时候，存储的子函数的返回值也会越来越多，你可以试试将上述斐波那契数列的代码参数设置为一个很大的数字，你会发现程序非常慢，并且有可能会导致栈溢出从而强制退出。因为你从上述分析的递归过程你会发现，有些函数被重复运算了，例如fib(2)就被计算了多次，而这是不需要的。因此浪费了时间和空间。&lt;/p&gt;
&lt;h3 id=&quot;自顶向下&quot;&gt;自顶向下&lt;/h3&gt;
&lt;p&gt;啥是自顶向下的方法？顶就是顶层任务，也就是我们的预期结果，向下就是指分解成小任务。自顶向下就是讲大任务拆解成若干小任务，随后将小任务组合起来的过程。&lt;/p&gt;
&lt;p&gt;通常来说自顶向下有时会造成严重的性能问题，例如我们举的例字，假设你只是想让第一排的同学把橡皮给你，信息却传递了整整一个来回。假设第一排的同学一开始就知道要把橡皮给你，那么就能节省不少时间。&lt;/p&gt;
&lt;p&gt;事实上对于斐波那契数列而言，我们并不关心他的前面项的结果，并且在前文的叙述中你也发现了有重复计算的问题。例如fib(10)的值，你完全没有必要关心fib(5)之类的是多少，你只需要关心fib(8)+fib(9)而已，因此对于fib(5)的值你也是完全没有必要压栈的。递归的斐波那契数列时间复杂度达到了惊人的&lt;span class=&quot;math inline&quot;&gt;\(O(2^n)\)&lt;/span&gt;,空间也用了&lt;span class=&quot;math inline&quot;&gt;\(S(n)\)&lt;/span&gt;。&lt;/p&gt;
&lt;p&gt;假设一个任务可以拆分成互相不干扰，没有直接联系的多个子任务，那么自顶向下的方法则是最优的方法，例如树的遍历，对于一个节点而言，它的兄弟节点必然不会是他的子节点（子函数的结果），那么你就可以大胆的用自顶向下的递归。而对于斐波那契数列，你会发现他的子任务显然会建立联系，那么自顶向下的方法必然会导致重复的运算，甚至爆栈。&lt;/p&gt;
&lt;h3 id=&quot;自底向上&quot;&gt;自底向上&lt;/h3&gt;
&lt;p&gt;为了解决子任务相关联导致的自顶向下的性能问题，我们引出自底向上的方法。自底向上则是将最小的子任务往大任务组合，这样就不会有重复计算的过程，因为子任务组合过程是单向的。&lt;/p&gt;
&lt;p&gt;对于下面这个改良版的斐波那契数列，尽管代码显得并不是那么可读和方便，但是时间复杂度却降到了&lt;span class=&quot;math inline&quot;&gt;\(O(n)\)&lt;/span&gt;,并且只使用了常数个的空间。显然我们的复杂度下降了。&lt;/p&gt;
&lt;pre class=&quot;c#&quot;&gt;
&lt;code&gt;int fib(int n)
{
    int rs = 0;
    int[] temp = new int []{ 1, 1 };
    for (int i = 2; i &amp;lt; n; i++)
    {
        rs = temp[0] + temp[1];
        temp[0] = temp[1];
        temp[1] = rs;
    }
    return rs;
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;并且对于斐波那契数列这种存在通项公式的递归,使用通项公式会使得你的时间复杂度进一步下降至&lt;span class=&quot;math inline&quot;&gt;\(O(logn)\)&lt;/span&gt;以下。因此可见递归虽好，但可不要滥用。&lt;/p&gt;
&lt;p&gt;但是自底向上并不是任何时候都是有效的，例如最小子任务不可知的情况下，树还是一个很好的例子，对于树的叶子结点，在父节点未知的情况下必然无法确定，因此自底向上失效。&lt;/p&gt;
&lt;h2 id=&quot;小题目&quot;&gt;小题目&lt;/h2&gt;
&lt;p&gt;为了加深各位对递归的理解，这里选取了几个使用递归解决的小题目，希望你能独立解决难题，答案将会在文末解析。请使用递归解决嗷！你可以将代码在评论中留下，我会仔细审阅，输入特殊用例来判断你的正确性。&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;Code1 - 反转字符串:&lt;/li&gt;
&lt;/ul&gt;&lt;pre class=&quot;c#&quot;&gt;
&lt;code&gt;//给你一个字符串，请将其反转。
//输入 Hello
//输出 olleH
public static string Reverse(string str)
{
}&lt;/code&gt;
&lt;/pre&gt;
&lt;ul&gt;&lt;li&gt;Code2 - 三个一组交换单链表&lt;/li&gt;
&lt;/ul&gt;&lt;pre class=&quot;c#&quot;&gt;
&lt;code&gt;//给你一个单链表，请返回三个一组反转后单链表的表头
//输入：1-&amp;gt;2-&amp;gt;3-&amp;gt;4-&amp;gt;5
//返回：3-&amp;gt;2-&amp;gt;1-&amp;gt;4-&amp;gt;5
class LinkNode
{
    public int Value { get; set;}
    public LinkNode Next { get; set;}
}
public LinkNode Reverse(LinkNode head)
{
}&lt;/code&gt;
&lt;/pre&gt;
&lt;ul&gt;&lt;li&gt;Code3 - 斐波那契数列&lt;/li&gt;
&lt;/ul&gt;&lt;pre class=&quot;c#&quot;&gt;
&lt;code&gt;//使用递归计算斐波那契数列
//要求时间复杂度降为O(n)
//Tip:验证时间复杂度可以输入一个50000去跑
public int Fib(int n)
{
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;如果我的文章帮助了你，请帮我点个赞，给个star，关注三连走一波。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/StevenEco/ComputerScience&quot;&gt;Github&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://space.bilibili.com/33311288&quot;&gt;BiliBili主页&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://cnblogs.com/warrenryan&quot;&gt;博客园&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
</description>
<pubDate>Thu, 05 Mar 2020 16:46:00 +0000</pubDate>
<dc:creator>WarrenRyan</dc:creator>
<og:description>递归 本系列文章在Github: &amp;quot;StevenEco&amp;quot; 以及 &amp;quot;WarrenRyan&amp;quot; 同步更新 简介 程序调用自身的编程技巧称为递归 (recursion)</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/WarrenRyan/p/12424152.html</dc:identifier>
</item>
<item>
<title>OpenCV3入门（十二）角点检测 - 啊哈彭</title>
<link>http://www.cnblogs.com/pingwen/p/12423976.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/pingwen/p/12423976.html</guid>
<description>&lt;h2&gt;1、角点介绍&lt;/h2&gt;
&lt;p&gt;角点检测(Corner Detection)是计算机视觉系统中用来获得图像特征的一种方法，广泛应用于运动检测、图像匹配、视频跟踪、三维建模和目标识别等领域中，也称为特征点检测。在图像中角点是一个重要的局部特征，它决定了图像中关键区域的形状，体现了图像中重要的特征信息。目前，角点检测方法主要有２大类：&lt;/p&gt;
&lt;p&gt;    １）基于图像边缘轮廓特征的方法。&lt;/p&gt;
&lt;p&gt;    ２）基于图像灰度信息的方法。此方法主要通过计算曲率及梯度进行角点检测，通过计算边缘的曲率来判断角点的存在性。典型代表有Harris算法、Susan算法、Moravec算法等。&lt;/p&gt;
&lt;p&gt;角点通常被定义为两条边的交点，更严格的说，角点的局部邻域应该具有两个不同区域的不同方向的边界。而实际应用中，大多数所谓的角点检测方法检测的是拥有特定特征的图像点，而不仅仅是“角点”。这些特征点在图像中有具体的坐标，并具有某些数学特征，如局部最大或最小灰度、某些梯度特征等。现有的角点检测算法并不是都十分的健壮。很多方法都要求有大量的训练集和冗余数据来防止或减少错误特征的出现。另外，角点检测方法的一个很重要的评价标准是其对多幅图像中相同或相似特征的检测能力，并且能够应对光照变化、图像旋转等图像变化。&lt;/p&gt;
&lt;h2&gt; 2、Harris算法介绍&lt;/h2&gt;
&lt;p&gt;Harris 是 Harris 和 Stephens 在 1988 年提出，专门针对 Moravec 算子的改进版。Harris 算子，又称 Plessey算子，它基于与 Moravec 相同的角点定义，即定义在各个方向上灰度值变化的点。&lt;/p&gt;
&lt;p&gt;角点可以如下图形象的定义，如果在各个方向上移动这个小窗口，窗口内的灰度发生了较大的变化，那么说明窗口内存在角点；如果在各个方向移动，灰度几乎不变，说明是平坦区域；如果只沿着某一个方向移动，灰度几乎不变，说明是直线（边缘）。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/i-beta/743748/202003/743748-20200305234630090-745960116.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;设图像窗口平移[u,v] ，产生的灰度变化为E[u,v] ，则：&lt;/p&gt;
&lt;p&gt; &lt;img src=&quot;https://img2020.cnblogs.com/i-beta/743748/202003/743748-20200305234708520-1816244577.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p align=&quot;left&quot;&gt;上式中，窗口函数是一个矩形窗口或高斯窗口，它给在其中的像素加权。&lt;/p&gt;
&lt;p align=&quot;left&quot;&gt;我们必须使边角检测的函数最大化，这意味着，我们必须最大限度地利用第二个参数。&lt;/p&gt;
&lt;p align=&quot;left&quot;&gt;根据角点的定义，平坦区域，像素变化小，那么上式后半部分基本接近为0；在边缘区域，会在沿着边缘方向上差值为一个稳定值；只有在角点处，无论向那个方向移动，都会发生变化。&lt;/p&gt;
&lt;p align=&quot;left&quot;&gt;根据泰勒级数展开：&lt;/p&gt;
&lt;p align=&quot;left&quot;&gt;&lt;img src=&quot;https://img2020.cnblogs.com/i-beta/743748/202003/743748-20200305234725531-1335746638.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;那么f(x+u, y+v)可以简化为：&lt;/p&gt;
&lt;p align=&quot;left&quot;&gt;&lt;strong&gt;f(x+u, y+v) ≈ f(x,y) + uf&lt;sub&gt;x&lt;/sub&gt;(x,y) + vf&lt;sub&gt;y&lt;/sub&gt;(x,y)&lt;/strong&gt;&lt;/p&gt;
&lt;p align=&quot;left&quot;&gt;Harris算式的可以写成矩阵模式。&lt;/p&gt;
&lt;p align=&quot;left&quot;&gt;&lt;img src=&quot;https://img2020.cnblogs.com/i-beta/743748/202003/743748-20200305234742325-2047839506.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;Harris算式可以近似得到下面的表达：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/i-beta/743748/202003/743748-20200305234759501-672251367.png&quot; alt=&quot;&quot;/&gt;其中M为：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/i-beta/743748/202003/743748-20200305234816211-816683304.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p align=&quot;left&quot;&gt;其中，表示 &lt;span&gt;Ix&lt;/span&gt; 方向的梯度，表示&lt;span&gt;Iy&lt;/span&gt; 方向的梯度，为高斯函数。矩阵的特征值是自相关函数的一阶曲率。特征值的大小与特征点的性质息息相关。即当两个特征值都比较小时，则此点可能位于平坦区，不为角点或边界点; 当两个特征值一个较大、而另一个却相对较小时，则此点位于边界上，属于边界点; 当两个特征值均相对较大时，则此点沿任意方向的曲率都较大，为需要提取的角点。&lt;/p&gt;
&lt;p align=&quot;left&quot;&gt;&lt;img src=&quot;https://img2020.cnblogs.com/i-beta/743748/202003/743748-20200305234845902-2031023005.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/i-beta/743748/202003/743748-20200305234853838-1252100215.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;M为梯度的协方差矩阵，在实际应用中为了能够应用更好的编程，定义了角点响应函数R，通过判定R大小来判断像素是否为角点。R取决于M的特征值，对于角点|R|很大，平坦的区域|R|很小，边缘的R为负值。Harris角点检测算法就是对角点响应函数R进行阈值处理：R &amp;gt; threshold，即提取R的局部极大值。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/i-beta/743748/202003/743748-20200305234914382-975346956.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;其中，det(M) = λ1* λ1, trace(M) =λ1+ λ1 。k是经验参数，一般取值为0.04~0.06。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/i-beta/743748/202003/743748-20200305235014743-334565746.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt; 当R为大数值正数的时候，表示为角点。如下图所示：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/i-beta/743748/202003/743748-20200305235033065-543197203.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;h2 align=&quot;left&quot;&gt;3、Harris实验&lt;/h2&gt;
&lt;p align=&quot;left&quot;&gt;OpenCV函数原型：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;40&quot;&gt;
&lt;pre&gt;
C++:&lt;span&gt;void&lt;/span&gt; cornerHarris( InputArray src, &lt;span&gt;//&lt;/span&gt;&lt;span&gt;输入8bit单通道灰度Mat矩阵&lt;/span&gt;
                  OutputArray dst, &lt;span&gt;//&lt;/span&gt;&lt;span&gt;保存角点检测结果，32位单通道，大小与src相同&lt;/span&gt;
                  &lt;span&gt;int&lt;/span&gt; blockSize,   &lt;span&gt;//&lt;/span&gt;&lt;span&gt;滑块窗口的尺寸、邻域的大小&lt;/span&gt;
                  &lt;span&gt;int&lt;/span&gt; ksize,        &lt;span&gt;//&lt;/span&gt;&lt;span&gt;Sobel边缘检测滤波器大小&lt;/span&gt;
                  &lt;span&gt;double&lt;/span&gt; k,        &lt;span&gt;//&lt;/span&gt;&lt;span&gt;Harris中间参数，经验值0.04~0.06&lt;/span&gt;
                  &lt;span&gt;int&lt;/span&gt; borderType=BORDER_DEFAULT  &lt;span&gt;//&lt;/span&gt;&lt;span&gt;插值类型&lt;/span&gt;
                  );
&lt;/pre&gt;&lt;/div&gt;
&lt;p align=&quot;left&quot;&gt;测试实例：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;79&quot;&gt;
&lt;pre&gt;
&lt;span&gt;int&lt;/span&gt; threshod_val = &lt;span&gt;30&lt;/span&gt;&lt;span&gt;; 
&lt;/span&gt;&lt;span&gt;int&lt;/span&gt; max_threshod_val = &lt;span&gt;150&lt;/span&gt;&lt;span&gt;;
Mat src_img;

&lt;/span&gt;&lt;span&gt;void&lt;/span&gt; call_back(&lt;span&gt;int&lt;/span&gt;, &lt;span&gt;void&lt;/span&gt;*&lt;span&gt;)
{
    Mat normImage, scaledImage;
    Mat Img_scr1 &lt;/span&gt;=&lt;span&gt; src_img.clone();
    Mat Img_dst &lt;/span&gt;=&lt;span&gt; Mat::zeros(src_img.size(), CV_32FC1);

    cornerHarris(src_img, Img_dst, &lt;/span&gt;&lt;span&gt;2&lt;/span&gt;, &lt;span&gt;3&lt;/span&gt;, &lt;span&gt;0.04&lt;/span&gt;, BORDER_DEFAULT); &lt;span&gt;//&lt;/span&gt;&lt;span&gt;进行角点检测  &lt;/span&gt;
    normalize(Img_dst, normImage, &lt;span&gt;0&lt;/span&gt;, &lt;span&gt;255&lt;/span&gt;, NORM_MINMAX, CV_32FC1, Mat()); &lt;span&gt;//&lt;/span&gt;&lt;span&gt; 归一化&lt;/span&gt;
    convertScaleAbs(normImage, scaledImage);&lt;span&gt;//&lt;/span&gt;&lt;span&gt;将归一化后的图线性变换成8位无符号整型&lt;/span&gt;
 
    &lt;span&gt;for&lt;/span&gt; (&lt;span&gt;int&lt;/span&gt; i = &lt;span&gt;0&lt;/span&gt;; i &amp;lt; normImage.rows; i++&lt;span&gt;)
    {
        &lt;/span&gt;&lt;span&gt;for&lt;/span&gt; (&lt;span&gt;int&lt;/span&gt; j = &lt;span&gt;0&lt;/span&gt;; j &amp;lt; normImage.cols; j++&lt;span&gt;)
        {
            &lt;/span&gt;&lt;span&gt;if&lt;/span&gt; ((&lt;span&gt;int&lt;/span&gt;)normImage.at&amp;lt;&lt;span&gt;float&lt;/span&gt;&amp;gt;(i, j) &amp;gt; threshod_val + &lt;span&gt;100&lt;/span&gt;&lt;span&gt;)
            {  
                circle(Img_scr1, Point(j, i), &lt;/span&gt;&lt;span&gt;3&lt;/span&gt;, Scalar(&lt;span&gt;0&lt;/span&gt;, &lt;span&gt;0&lt;/span&gt;, &lt;span&gt;255&lt;/span&gt;), &lt;span&gt;2&lt;/span&gt;, &lt;span&gt;8&lt;/span&gt;, &lt;span&gt;0&lt;/span&gt;&lt;span&gt;);
                circle(scaledImage, Point(j, i), &lt;/span&gt;&lt;span&gt;3&lt;/span&gt;, Scalar(&lt;span&gt;0&lt;/span&gt;, &lt;span&gt;0&lt;/span&gt;, &lt;span&gt;255&lt;/span&gt;), &lt;span&gt;2&lt;/span&gt;, &lt;span&gt;8&lt;/span&gt;, &lt;span&gt;0&lt;/span&gt;&lt;span&gt;);
            }
        }

    }

    imshow(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;corner&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;, Img_scr1);
    imshow(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;scaledImage&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;, scaledImage);
}

&lt;/span&gt;&lt;span&gt;int&lt;/span&gt;&lt;span&gt; main() {
    src_img &lt;/span&gt;= imread(&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;D:\\WORK\\5.OpenCV\\LeanOpenCV\\pic_src\\checkerboard.png&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;);
    imshow(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;原图&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;, src_img);

    cvtColor(src_img, src_img, COLOR_BGR2GRAY);
    namedWindow(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;corner&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;);
    createTrackbar(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;thresh&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;, &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;corner&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;, &amp;amp;&lt;span&gt;threshod_val, max_threshod_val, call_back);
    call_back(threshod_val, &lt;/span&gt;&lt;span&gt;0&lt;/span&gt;&lt;span&gt;);

    waitKey(&lt;/span&gt;&lt;span&gt;0&lt;/span&gt;&lt;span&gt;);
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p align=&quot;left&quot;&gt;输出结果如下图：&lt;/p&gt;
&lt;p align=&quot;left&quot;&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/743748/202003/743748-20200305235147638-691504904.png&quot; alt=&quot;&quot; width=&quot;779&quot; height=&quot;324&quot;/&gt;&lt;/p&gt;
&lt;p align=&quot;left&quot;&gt;测试2：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/743748/202003/743748-20200305235156584-15320186.png&quot; alt=&quot;&quot; width=&quot;776&quot; height=&quot;310&quot;/&gt;&lt;/p&gt;
&lt;h2&gt;4、参考文献&lt;/h2&gt;
&lt;p&gt;1、A COMBINED CORNER AND EDGE DETECTOR，Chris Harris，Mike Stephens，1988&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://www.bmva.org/bmvc/1988/avc-88-023.pdf&quot;&gt;http://www.bmva.org/bmvc/1988/avc-88-023.pdf&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;2、Harris Corner Detection&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_feature2d/py_features_harris/py_features_harris.html&quot;&gt;https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_feature2d/py_features_harris/py_features_harris.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;3、Harris 角点检测子&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://www.opencv.org.cn/opencvdoc/2.3.2/html/doc/tutorials/features2d/trackingmotion/harris_detector/harris_detector.html&quot;&gt;http://www.opencv.org.cn/opencvdoc/2.3.2/html/doc/tutorials/features2d/trackingmotion/harris_detector/harris_detector.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;4、【OpenCV入门教程之十六】OpenCV角点检测之Harris角点检测&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://blog.csdn.net/poem_qianmo/article/details/29356187&quot;&gt;https://blog.csdn.net/poem_qianmo/article/details/29356187&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;5、(四)OpenCV中的特征检测之Harris Corner检测&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://blog.csdn.net/u014403318/article/details/80562785&quot;&gt;https://blog.csdn.net/u014403318/article/details/80562785&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;6、OpenCV学习笔记（八）——Harris角度特征从原理到实现详解&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://blog.csdn.net/weixin_41695564/article/details/79962401&quot;&gt;https://blog.csdn.net/weixin_41695564/article/details/79962401&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;7、《OpenCV3 编程入门》，电子工业出版社，毛星雨著&lt;/p&gt;
&lt;p&gt;8、《学习OpenCV》，清华大学出版社，Gary Bradski， Adrian kaehler著&lt;/p&gt;
</description>
<pubDate>Thu, 05 Mar 2020 15:56:00 +0000</pubDate>
<dc:creator>啊哈彭</dc:creator>
<og:description>OpenCV3入门（十二）角点检测</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/pingwen/p/12423976.html</dc:identifier>
</item>
<item>
<title>AWS EC2+Docker+JMeter构建分布式负载测试基础架构 - 软测小生</title>
<link>http://www.cnblogs.com/PeterZhang1520389703/p/12423950.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/PeterZhang1520389703/p/12423950.html</guid>
<description>&lt;p&gt;本文介绍有关如何使用AWS EC2+Docker+JMeter创建分布式负载测试基础架构。&lt;/p&gt;&lt;div id=&quot;cnblogs_post_body&quot; readability=&quot;271.48754630221&quot;&gt;

&lt;p&gt;&lt;a href=&quot;https://medium.com/@DragosCampean/how-to-build-a-distributed-load-testing-infrastructure-with-aws-docker-and-jmeter-accf3c2aa3a3&quot;&gt;原文链接&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;@&lt;/p&gt;
&lt;h3 id=&quot;概述及范围&quot;&gt;概述及范围&lt;/h3&gt;
&lt;p&gt;本文介绍有关如何使用AWS EC2+Docker+JMeter创建分布式负载测试基础架构。&lt;br/&gt;完成所有步骤后，得到的基础结构如下:&lt;br/&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/2020022917094142.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3piajE4MzE0NDY5Mzk1,size_1,color_FFFFFF,t_70&quot; alt=&quot;AWS EC2+Docker+JMeter基础架构&quot;/&gt;&lt;/p&gt;
&lt;p&gt;在&lt;strong&gt;Part 1&lt;/strong&gt;中，我们将按照所需的步骤进行操作，以创建适合你需求的自定义JMeter Dockerfiles和映像。&lt;br/&gt;然后，在&lt;strong&gt;Part 2&lt;/strong&gt;中，我们将在AWS EC2设置中使用这些元素。&lt;br/&gt;接下来开始第一步：&lt;/p&gt;
&lt;h3 id=&quot;前提条件&quot;&gt;前提条件&lt;/h3&gt;
&lt;p&gt;为了能够顺利的逐步进行配置和操作，你需要上述每个系统（EC2，Docker和JMeter）的一些基本知识。&lt;br/&gt;此外，还需要一个活动的AWS账户才能执行所有步骤。&lt;/p&gt;
&lt;h3 id=&quot;part-1-local-setup本地配置&quot;&gt;Part 1: Local setup—本地配置&lt;/h3&gt;
&lt;h4 id=&quot;step-1-从dockerfile创建映像&quot;&gt;Step 1: 从Dockerfile创建映像&lt;/h4&gt;
&lt;p&gt;&lt;a href=&quot;https://conetix.com.au/blog/what-is-a-dockerfile/&quot;&gt;dockerfile&lt;/a&gt;是开始使用docker所需的基本元素或“ cookbook”，因此我们将从此开始。&lt;br/&gt;我们需要建立2层:&lt;br/&gt;1、一是基础层，该层创建运行JMeter实例所需的基本设置；&lt;br/&gt;2、二是逻辑层，它是一个JMeter实例，可以是主节点或从节点；&lt;/p&gt;
&lt;p&gt;JMeter base映像的Dockerfile和entrypoint.sh脚本如下所示：&lt;br/&gt;&lt;strong&gt;Dockerfile:&lt;/strong&gt;&lt;/p&gt;
&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;# Use Java 11 JDK Oracle Linux
FROM openjdk:11-jdk-oracle
MAINTAINER Dragos
# Set the JMeter version you want to use
ARG JMETER_VERSION=&quot;5.1.1&quot;
# Set JMeter related environment variables
ENV JMETER_HOME /opt/apache-jmeter-${JMETER_VERSION}
ENV JMETER_BIN ${JMETER_HOME}/bin
ENV JMETER_DOWNLOAD_URL https://archive.apache.org/dist/jmeter/binaries/apache-jmeter-${JMETER_VERSION}.tgz
# Set default values for allocation of system resources (memory) which will be used by JMeter
ENV Xms 256m
ENV Xmx 512m
ENV MaxMetaspaceSize 1024m
# Change timezone to local time
ENV TZ=&quot;Europe/Bucharest&quot;
RUN export TZ=$TZ
# Install jmeter
RUN yum -y install curl \
&amp;amp;&amp;amp; mkdir -p /tmp/dependencies \
&amp;amp;&amp;amp; curl -L --silent ${JMETER_DOWNLOAD_URL} &amp;gt;  /tmp/dependencies/apache-jmeter-${JMETER_VERSION}.tgz \
&amp;amp;&amp;amp; mkdir -p /opt \
&amp;amp;&amp;amp; tar -xzf /tmp/dependencies/apache-jmeter-${JMETER_VERSION}.tgz -C /opt \
&amp;amp;&amp;amp; rm -rf /tmp/dependencies
# Set JMeter home
ENV PATH $PATH:$JMETER_BIN
# copy our entrypoint
COPY entrypoint.sh /
RUN chmod +x ./entrypoint.sh
# Run command to allocate the default system resources to JMeter at 'docker run'
ENTRYPOINT [&quot;/entrypoint.sh&quot;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Entrypoint.sh:&lt;/strong&gt;&lt;/p&gt;
&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;#!/bin/bash
# Run command to allocate the default or custom system resources (memory) to JMeter at 'docker run'
sed -i 's/\(&quot;${HEAP:=&quot;\)\(.*\)\(&quot;}&quot;\)/\1-Xms'${Xms}' -Xmx'${Xmx}' -XX:MaxMetaspaceSize='${MaxMetaspaceSize}'\3/' ${JMETER_BIN}/jmeter
exec &quot;$@&quot;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;在基础层之上，可以创建一个Master层和一个Slave层。这些Dockerfile可以根据你的特定要求进行自定义。&lt;br/&gt;现在让我们看一下我们的逻辑层：&lt;br/&gt;&lt;strong&gt;Master层的Dockerfile：&lt;/strong&gt;&lt;/p&gt;
&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;# Use my custom base image defined above
FROM dragoscampean/testrepo:jmetrubase
MAINTAINER Dragos
# Expose port for JMeter Master
EXPOSE 60000&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Slave层的Dockerfile:&lt;/strong&gt;&lt;/p&gt;
&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;
# Use my custom base image defined above
FROM dragoscampean/testrepo:jmetrubase
MAINTAINER Dragos
# Expose ports for JMeter Slave
EXPOSE 1099 50000
COPY entrypoint.sh /
RUN chmod +x ./entrypoint.sh
# Run command to allocate the default system resources to JMeter at 'docker run' and start jmeter-server with all required parameters
ENTRYPOINT [&quot;/entrypoint.sh&quot;]&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Slave层的Entrypoint.sh:&lt;/strong&gt;&lt;/p&gt;
&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;#!/bin/bash
# Run command to allocate the default system resources to JMeter at 'docker run'
sed -i 's/\(&quot;${HEAP:=&quot;\)\(.*\)\(&quot;}&quot;\)/\1-Xms'${Xms}' -Xmx'${Xmx}' -XX:MaxMetaspaceSize='${MaxMetaspaceSize}'\3/' ${JMETER_BIN}/jmeter &amp;amp;&amp;amp;
$JMETER_HOME/bin/jmeter-server \
-Dserver.rmi.localport=50000 \
-Dserver_port=1099 \
-Dserver.rmi.ssl.disable=true \
-Djava.rmi.server.hostname=$HostIP
exec &quot;$@&quot;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;我们不会详细讨论dockerfiles中的所有内容的含义，在网上有很多这样的文档。不过值得一提的是与Dockerfiles绑定在一起的&lt;strong&gt;entrypoint shell&lt;/strong&gt;脚本。&lt;/p&gt;
&lt;p&gt;docker entrypoints的作用是在运行时将数据初始化或者配置到容器中。在我们的例子中，我们需要它们来指定JMeter允许使用多少内存，并使用一些自定义配置来启动JMeter服务器，这些配置是基础设施工作所必需的。这将在“&lt;strong&gt;Step 2&lt;/strong&gt;”部分中举例说明。&lt;/p&gt;
&lt;p&gt;现在，让我们看一下创建Docker映像所需的命令。顺便说一下，Docker图像表示一组很好地集成在一起的层，是我们需要的环境的稳定快照。&lt;br/&gt;从这样一个映像开始，我们可以生成N个容器，这正是我们在这个特定场景中所需要的，这取决于我们想要模拟的负载。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;创建一个简单的docker映像的命令:&lt;/strong&gt;&lt;br/&gt;&lt;code&gt;docker build /path/to/dockerfile&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;为docker映像创建一个标签:&lt;/strong&gt;&lt;br/&gt;&lt;code&gt;docker tag imageId username/reponame:imageTag&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;同时创建docker映像和标签：&lt;/strong&gt;&lt;br/&gt;&lt;code&gt;docker build -t username/reponame:imageTag /path/to/dockerfile&lt;/code&gt;&lt;/p&gt;
&lt;h4 id=&quot;step-2-从一个映像创建一个容器&quot;&gt;Step 2: 从一个映像创建一个容器&lt;/h4&gt;
&lt;p&gt;现在我们已经准备好映像，可以开始从中创建容器，在其中可以实际运行性能测试脚本。&lt;br/&gt;&lt;strong&gt;创建一个新的容器:&lt;/strong&gt;&lt;br/&gt;&lt;code&gt;sudo docker run -dit --name containername repository:tag or imageId /bin/bash&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;启动/停止容器：&lt;/strong&gt;&lt;br/&gt;&lt;code&gt;docker start containerId&lt;/code&gt;&lt;br/&gt;&lt;code&gt;docker stop containerId&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;访问正在运行的容器：&lt;/strong&gt;&lt;br/&gt;&lt;code&gt;docker exec -it containerId or containerName /bin/bash&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;到目前为止，如果你一直使用类似于&lt;strong&gt;Step 1&lt;/strong&gt;中提供的Dockerfile，那么您应该拥有一个完全可用的Java + JMeter容器。 你可以通过检查工具版本来测试它，看看是否有任何错误，甚至可以尝试运行你计划在AWS中扩展的脚本(所有这些都应该在运行的容器中完成):&lt;br/&gt;&lt;code&gt;Jmeter -v&lt;/code&gt;&lt;br/&gt;&lt;code&gt;Java -version&lt;/code&gt;&lt;br/&gt;&lt;code&gt;Jmeter -n -t -J numberOfThreads=1 /path/to/script.jmx -l /path/to/logfile.jtl&lt;/code&gt;&lt;/p&gt;
&lt;h4 id=&quot;step-3-将映像pushpull到dockerhub或任何私有的docker仓库docker登录cli后&quot;&gt;Step 3: 将映像Push/Pull到Dockerhub或任何私有的Docker仓库(docker登录CLI后)&lt;/h4&gt;
&lt;p&gt;测试创建的图像是否符合要求的标准（容器内的所有内容）,通常，最好将此图像保存到存储库中。然后，你可以在后续随时从那里提取它，而不必每次都从Dockerfile构建它。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;code&gt;Push&lt;/code&gt;映像到dockerhub：&lt;/strong&gt;&lt;br/&gt;&lt;code&gt;docker push username/reponame:imageTag&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;从dockerhub中&lt;code&gt;Pull&lt;/code&gt;已存在的映像(例如jdk映像)：&lt;/strong&gt;&lt;br/&gt;&lt;code&gt;docker pull openjdk:version&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;到此为止，这意味着您已经为cloud setup准备好了一组功能强大的JMeter从属映像和主映像。&lt;/p&gt;
&lt;h3 id=&quot;part-2-cloud端基础架构infrastructure&quot;&gt;Part 2: Cloud端基础架构——Infrastructure&lt;/h3&gt;
&lt;p&gt;可以使用&lt;a href=&quot;https://aws.amazon.com/cn/ec2/&quot;&gt;&lt;strong&gt;EC2免费层&lt;/strong&gt;&lt;/a&gt;实例，最多750小时/月，持续1年，因此有很多时间进行试验。&lt;br/&gt;&lt;strong&gt;&lt;code&gt;注意：&lt;/code&gt;&lt;/strong&gt;&lt;code&gt;对于下面提供的示例，我使用了&lt;/code&gt;&lt;strong&gt;&lt;code&gt;Ubuntu Server 18.04 LTS&lt;/code&gt;&lt;/strong&gt;&lt;code&gt;实例，因此提供的命令可能无法在其他Linux发行版上使用。&lt;/code&gt;&lt;/p&gt;
&lt;h4 id=&quot;step-4-创建安全组security-group&quot;&gt;Step 4: 创建安全组——Security Group&lt;/h4&gt;
&lt;p&gt;使容器内的JMeter实例(master实例或slave实例)能够通信，&lt;a href=&quot;https://docs.aws.amazon.com/zh_cn/AWSEC2/latest/UserGuide/ec2-security-groups.html&quot;&gt;&lt;strong&gt;自定义安全组&lt;/strong&gt;&lt;/a&gt;已定义并将其附加到每个主机：&lt;/p&gt;
&lt;p&gt;入站规则(Inbound rules)：&lt;br/&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20200229180536299.png&quot; alt=&quot;Security group inbound rules&quot;/&gt;&lt;br/&gt;出站规则(Outbound rules)：&lt;br/&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20200229181109466.png&quot; alt=&quot;Security group outbound rules&quot;/&gt;&lt;br/&gt;&lt;strong&gt;注意&lt;/strong&gt;：确保将要成为负载测试基础结构部分的所有实例分配给此安全组，否则它们可能无法相互通信。&lt;/p&gt;
&lt;h4 id=&quot;step-5-创建一个iam策略可选&quot;&gt;Step 5: 创建一个&lt;a href=&quot;https://docs.aws.amazon.com/zh_cn/IAM/latest/UserGuide/introduction.html&quot;&gt;IAM策略&lt;/a&gt;（可选）&lt;/h4&gt;
&lt;p&gt;假设您只需要一个由1个JMeter主节点和2个从节点组成的基础架构。在这种情况下，访问每个实例并对其进行配置（安装docker +启动容器）相对容易。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;code&gt;但是，如果需要处理的实例超过3个，会发生什么情况呢?&lt;/code&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;手动逐个配置变得极其乏味，手动并不是一个好主意。&lt;br/&gt;这时，你将需要一个系统，能够管理你正在使用的大量容器。一些著名的工具，如谷歌的&lt;a href=&quot;https://www.infoworld.com/article/3268073/what-is-kubernetes-your-next-application-platform.html&quot;&gt;&lt;strong&gt;&lt;code&gt;Kubernetes&lt;/code&gt;&lt;/strong&gt;&lt;/a&gt;，或者&lt;a href=&quot;http://www.testautomationguru.com/jmeter-distributed-load-testing-using-docker-rancheros-in-cloud/&quot;&gt;&lt;strong&gt;&lt;code&gt;Rancher&lt;/code&gt;&lt;/strong&gt;&lt;/a&gt;等工具。&lt;/p&gt;
&lt;p&gt;由于当前使用的是AWS，因此这两种解决方案似乎过于庞大了，因为亚马逊针对这一点提供了一个开箱即用的解决方案：&lt;br/&gt;“&lt;a href=&quot;https://aws.amazon.com/cn/blogs/aws/new-ec2-run-command-remote-instance-management-at-scale/&quot;&gt;&lt;strong&gt;&lt;code&gt;Run Command&lt;/code&gt;&lt;/strong&gt;&lt;/a&gt;”功能使我们可以同时在多个EC2实例上执行Shell脚本。因此，我们不必访问每个实例，安装docker并一次一个实例地启动容器。&lt;/p&gt;
&lt;p&gt;能够通过“&lt;strong&gt;&lt;code&gt;Run Command&lt;/code&gt;&lt;/strong&gt;”功能在EC2实例上执行命令的唯一要求是，适当的IAM角色已与该实例相关联。我将IAM策略命名为“ &lt;strong&gt;EC2Command&lt;/strong&gt;”，并为每个新创建的实例选择了该策略（但是稍后可以通过“attach/replace role”功能将该角色分配给该实例）：&lt;br/&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20200229182906271.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3piajE4MzE0NDY5Mzk1,size_1,color_FFFFFF,t_70&quot; alt=&quot;为现有实例设置IAM策略&quot;/&gt;&lt;br/&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/2020022919090035.png&quot; alt=&quot;在实例创建时关联IAM策略&quot;/&gt;&lt;br/&gt;当您创建角色时，请确保将“&lt;strong&gt;AmazonEC2RoleforSSM&lt;/strong&gt;”策略附加到您的角色上，这样就可以了。&lt;br/&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/2020022919094119.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3piajE4MzE0NDY5Mzk1,size_1,color_FFFFFF,t_70&quot; alt=&quot;将权限关联到IAM角色&quot;/&gt;&lt;br/&gt;现在您可以使用“Run command”功能对多个实例批量执行脚本。&lt;br/&gt;这将我们带入流程的下一步。&lt;/p&gt;
&lt;h4 id=&quot;step-6-在测试机器上安装docker&quot;&gt;Step 6: 在测试机器上安装Docker&lt;/h4&gt;
&lt;p&gt;现在，你需要在EC2主机上安装docker，以便可以启动容器并将它们连接在一起以进行分布式负载测试。&lt;br/&gt;&lt;strong&gt;直接使用命令（直接在Ubuntu上的实例终端中执行）：&lt;/strong&gt;&lt;/p&gt;
&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;sudo apt-get install  curl  apt-transport-https ca-certificates software-properties-common \
&amp;amp;&amp;amp; curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add \
&amp;amp;&amp;amp; sudo add-apt-repository &quot;deb [arch=amd64] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable&quot; \
&amp;amp;&amp;amp; sudo apt-get update \
&amp;amp;&amp;amp; sudo apt-get install -y docker-ce \
&amp;amp;&amp;amp; sudo usermod -aG docker $USER \
&amp;amp;&amp;amp; sudo curl -L &quot;https://github.com/docker/compose/releases/download/1.23.2/docker-compose-$(uname -s)-$(uname -m)&quot; -o /usr/local/bin/docker-compose \
&amp;amp;&amp;amp; sudo chmod +x /usr/local/bin/docker-compose \
&amp;amp;&amp;amp; sudo ln -s /usr/local/bin/docker-compose /usr/bin/docker-compose&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;通过“Run command”执行的Shell脚本：&lt;/strong&gt;&lt;/p&gt;
&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;#!/bin/bash
sudo apt-get install  curl  apt-transport-https ca-certificates software-properties-common
curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add
sudo add-apt-repository &quot;deb [arch=amd64] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable&quot;
sudo apt-get update
sudo apt-get install -y docker-ce
USER_DOCKER=$(getent passwd {1000..60000} | grep &quot;/bin/bash&quot; | awk -F: '{ print $1}')
sudo usermod -aG docker $USER_DOCKER&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;理想情况下，您将在多个EC2实例上运行第二个脚本，之后它们都将具有可用的Docker版本。&lt;br/&gt;下一步是配置主节点和从属节点：&lt;/p&gt;
&lt;h4 id=&quot;step-7-配置主节点master-node&quot;&gt;Step 7: 配置主节点——Master Node&lt;/h4&gt;
&lt;p&gt;在某些情况下，你甚至不需要多个从属节点来分布式运行测试，比如，当你有一台功能强大的主机并且该计算机能够生成目标的负载量时，对于这种特定情况，不需要Step 8和Step 9。对于这种情况，你甚至不想使用容器并直接在主机上安装JMeter。&lt;/p&gt;
&lt;p&gt;但是，假设你确实需要一个Master + Slaves系统，然后继续启动Master容器：&lt;br/&gt;&lt;strong&gt;直接使用命令（直接在Ubuntu上的实例终端中执行）：&lt;/strong&gt;&lt;/p&gt;
&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;HostIP=$(ip route show | awk '/default/ {print $9}') \
&amp;amp;&amp;amp; docker pull dragoscampean/testrepo:jmetrumaster \
&amp;amp;&amp;amp; docker run -dit --name master --network host -e HostIP=$HostIP -e Xms=256m -e Xmx=512m -e MaxMetaspaceSize=512m -v /opt/Sharedvolume:/opt/Sharedvolume dragoscampean/testrepo:jmetrumaster /bin/bash&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;通过“Run command”执行的Shell脚本：&lt;/strong&gt;&lt;/p&gt;
&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;#!/bin/bash
HostIP=$(ip route show | awk '/default/ {print $9}')
docker pull dragoscampean/testrepo:jmetrumaster
docker run -dit --name master --network host -e HostIP=$HostIP -e Xms=256m -e Xmx=512m -e MaxMetaspaceSize=512m -v /opt/Sharedvolume:/opt/Sharedvolume dragoscampean/testrepo:jmetrumaster /bin/bash&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;脚本的第一行将机器的私有IP存储在变量“&lt;strong&gt;HostIP&lt;/strong&gt;”中。主的HostIP不用于任何目的，仅使用从属节点的HostIP。我们将在Step 9看到具体要做什么。现在，请记住，你可以快速访问每个容器中主机的专用IP地址。&lt;/p&gt;
&lt;p&gt;第二行很简单，只是从适当的仓库中获取图像。&lt;/p&gt;
&lt;p&gt;最后一行创建我们将要使用的容器。此命令中有一些要点：&lt;br/&gt;1、'&lt;strong&gt;--network host&lt;/strong&gt; '命令启用主机连网，这意味着容器内的应用程序(JMeter)，将在‘entrypoint.sh’脚本公开的端口上可用。如果没有它，我就无法进行设置。问题是，即使脚本是在从节点上执行的，由于错误(&lt;strong&gt;java.rmi.ConnectException: Connection refused to host:masterPrivateIP&lt;/strong&gt;)，主节点上也没有聚集任何结果。注意，我在较老版本的JMeter(如3.x.x)中没有遇到这个问题&lt;/p&gt;
&lt;p&gt;2、&lt;strong&gt;‘- e Xms=256m -e Xmx=512m -e MaxMetaspaceSize=512m’&lt;/strong&gt; 是Xms和Xmx的参数化，&lt;strong&gt;MaxMetaspaceSize&lt;/strong&gt;决定了允许使用JMeter的内存量。这是通过首先在容器内设置一些环境变量来完成的。然后，在“ entrypoint.sh”脚本中运行命令，将更改JMeter的“ / bin”文件夹中的“JMeter”文件。如果未指定这些值，则使用默认值。&lt;/p&gt;
&lt;p&gt;要进一步了解这些变量代表什么以及如何设置它们，请阅读以下内容：&lt;br/&gt;Xmx计算如下：&lt;strong&gt;系统总内存-(OS使用的内存+ JVM使用的内存+在计算机上运行所需的任何其他脚本)&lt;/strong&gt;&lt;br/&gt;如果您有一台专用的测试机器，为避免在测试运行时重新分配Xms，请从一开始就设置&lt;strong&gt;Xms = Xmx&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;MaxMetaspaceSize&lt;/strong&gt;跟踪所有加载的类元数据和静态内容（静态方法，原始变量和对象引用）&lt;/p&gt;
&lt;p&gt;例如：&lt;br/&gt;一台专用机器上64 GB RAM&lt;br/&gt;&lt;strong&gt;Xmx&lt;/strong&gt; = 56G&lt;br/&gt;&lt;strong&gt;Xms&lt;/strong&gt; = 56G&lt;br/&gt;&lt;strong&gt;MaxMetaspaceSize&lt;/strong&gt; = 4096 MB&lt;br/&gt;这为操作系统和其他进程留下了将近4GB的空间，这绰绰有余。&lt;/p&gt;
&lt;p&gt;3、&lt;strong&gt;-v /opt/Sharedvolume:/opt/Sharedvolume userName/repoName:imageTag&lt;/strong&gt; 该命令只是将主机上的文件夹映射到容器内的文件夹，你将在其中保存脚本文件和生成的日志。我们将不做进一步详细介绍，但是如果您想了解有关卷映射的更多信息，请参阅&lt;a href=&quot;https://www.digitalocean.com/community/tutorials/how-to-share-data-between-the-docker-container-and-the-host&quot;&gt;本文和迷你教程&lt;/a&gt;。&lt;/p&gt;
&lt;h4 id=&quot;step-8-配置从节点slave-nodes&quot;&gt;Step 8: 配置从节点——Slave Nodes&lt;/h4&gt;
&lt;p&gt;“ &lt;strong&gt;HostIP&lt;/strong&gt;”变量仅在“&lt;strong&gt;entrypoint.sh&lt;/strong&gt;”脚本中用于此处，以启用从master服务器到slave服务器的远程访问（“&lt;strong&gt;-Djava.rmi。server.hostname = $ HostIP&lt;/strong&gt;”）。&lt;br/&gt;&lt;strong&gt;直接使用命令（直接在Ubuntu上的实例终端中执行）：&lt;/strong&gt;&lt;/p&gt;
&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;HostIP=$(ip route show | awk '/default/ {print $9}') \
&amp;amp;&amp;amp; docker pull dragoscampean/testrepo:jmetruslave \
&amp;amp;&amp;amp; docker run -dit --name slave --network host -e HostIP=$HostIP -e HostIP=$HostIP -e Xms=256m -e Xmx=512m -e MaxMetaspaceSize=512m dragoscampean/testrepo:jmetruslave /bin/bash&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;通过“Run command”执行的Shell脚本：&lt;/strong&gt;&lt;/p&gt;
&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;#!/bin/bash
HostIP=$(ip route show | awk '/default/ {print $9}')
docker pull dragoscampean/testrepo:jmetruslave
docker run -dit --name slave --network host -e HostIP=$HostIP -e Xms=256m -e Xmx=512m -e MaxMetaspaceSize=512m dragoscampean/testrepo:jmetruslave /bin/bash&lt;/code&gt;
&lt;/pre&gt;
&lt;h4 id=&quot;step-9-分布式模式下运行脚本&quot;&gt;Step 9: 分布式模式下运行脚本&lt;/h4&gt;
&lt;p&gt;到此，准备就绪，可以开始运行测试了。这是我们需要在master主节点上运行以开始运行分布式测试的命令：&lt;/p&gt;
&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;jmeter -n -t /path/to/scriptFile.jmx -Dserver.rmi.ssl.disable=true -R host1PrivateIP, host2PrivateIP,..., hostNPrivateIP -l /path/to/logfile.jtl&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;总结&quot;&gt;总结:&lt;/h3&gt;
&lt;p&gt;按照上面的操作步骤，可以实现AWS EC2+Jmeter+Docker的分布式性能测试，可能会遇到一些问题，完全没问题那是不可能的。&lt;br/&gt;比如：&lt;br/&gt;&lt;a href=&quot;https://dzone.com/articles/stop-hoping-for-the-best-and-load-performing-tests&quot;&gt;该文&lt;/a&gt;提到了一个EC2实例中有太多Websocket连接时可能遇到的问题。&lt;br/&gt;另一个例子是我的一位同事在对Apa​​che服务器进行负载测试时遇到的情况，他会在JMeter中遇到各种连接错误，我们最初认为这是来自被测试的服务器。解决这个问题的方法来自&lt;a href=&quot;http://www.linuxbrigade.com/reduce-time_wait-socket-connections/&quot;&gt;这篇简短的文章。&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;我在一个项目中偶然发现的一个问题是，在尝试从一台计算机执行大约20000个线程时，进行了一些数据驱动的测试。如果在Linux / MacOS终端中键入“ &lt;strong&gt;ulimit -a&lt;/strong&gt;”，则会看到名为“ open files”的行。问题在于该属性在测试计算机上设置为1024。使用JMeter运行数据驱动的测试时，此工具将为每个启动的线程打开.csv文件或描述符，一旦并行线程数超过1024，我将收到错误消息。&lt;br/&gt;&lt;strong&gt;解决方案：&lt;/strong&gt; 是从'&lt;strong&gt;/etc/security/limits&lt;/strong&gt;'文件中编辑'&lt;strong&gt;open files&lt;/strong&gt;'的最大值，并设置为'&lt;strong&gt;unlimited&lt;/strong&gt;'。&lt;/p&gt;
&lt;/div&gt;</description>
<pubDate>Thu, 05 Mar 2020 15:50:00 +0000</pubDate>
<dc:creator>软测小生</dc:creator>
<og:description>本文介绍有关如何使用AWS EC2+Docker+JMeter创建分布式负载测试基础架构。</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/PeterZhang1520389703/p/12423950.html</dc:identifier>
</item>
<item>
<title>Nginx之反向代理配置（一） - Linux-1874</title>
<link>http://www.cnblogs.com/qiuhom-1874/p/12417130.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/qiuhom-1874/p/12417130.html</guid>
<description>&lt;p&gt;　　前文我们聊了下Nginx作为web服务器配置https、日志模块的常用配置、rewrite模块重写用户请求的url，回顾请参考&lt;a href=&quot;https://www.cnblogs.com/qiuhom-1874/p/12398242.html&quot; target=&quot;_blank&quot;&gt;https://www.cnblogs.com/qiuhom-1874/p/12398242.html&lt;/a&gt;；今天来聊一聊Nginx是怎么反向代理，怎么防盗链；前文的最后我们提到了防盗链，到底什么是防盗链呢？在我们平时上网相信很多人都遇到过这样的情况，我们打开一个网页，在里面可以看到很多裂图，看不到图片，或者看到此图片仅某某网站网友交流使用之类的，这就是防盗链；我们知道在一个网页里面，里面的资源不一定都是来自一个服务器的，比如图片很可能来自图片服务器，js、css很可能来自其他静态资源服务器上；所以稍微懂点的人就知道如何将别人网站上的图片、js文件呀链接到自己的网站使用，这种行为就叫盗用别人家的资源，简称盗链；这里就不过多阐述了；我们来说说nginx的referer模块吧。&lt;/p&gt;
&lt;p&gt;　　一、ngx_http_referer_module：此模块用于阻止对“Referer”头字段中包含无效值的请求的站点访问；&lt;/p&gt;
&lt;p&gt;　　通常一次http事务就是客户端请求服务端，服务端响应客户端的一个流程；客户端请求服务端，会在请求头部添加一些信息，比如用什么方法请求服务端的资源呀，资源的路径是什么，用的http协议版本是多少，请求的host主机上什么等等；其中如果客户端是直接从浏览器上介入域名直接访问web服务器，其头部是没有referer这个信息的；referer是什么？referer是记录客户端从哪里来访问我们客户端的，如果客户端是通过某个网站点击访问到我们的服务器时，它发过来的请求头部就有对应网站的域名；防盗链就是利用referer这个头部的信息来做控制的；&lt;/p&gt;
&lt;p&gt;　　1、valid_referers none | blocked | server_names | string ...;定义合法referer合法值；这里解释下，none表示请求头部没有referer字段，通常情况下没有referer字段都是从浏览器（web客户端）介入域名访问的；blocked表示请求头部有referer字段，但是没有值，像这种请求我们是无法判断客户端是从哪里访问我们服务器的，通常情况我们把这类请求时允许访问的；server_name表示请求头部有referer字段和信息，其值就是对方主机名；我们在定义一个合法的referer时，是可以用通配或正则去匹配server_name；&lt;/p&gt;
&lt;p&gt;　　示例：&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;33&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
valid_referers none blocked server_names
               *.example.com example.* www.example.org/galleries/
               ~\.google\.;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　提示：以上配置表示合法的referer有 ，请求报文里没有referer字段的请求，有referer字段但是没有值的，以任何内容开头结尾是.example.com的主机名或者是以example开头的主机，或者referer是www.example.org/galleries/或者是包含google的都是合法的，意思是客户端请求报文的referer信息满足我们定义的合法信息，或者说能够被我们定义的合法referer匹配到，我们就说该用户是一个合法的请求，理所当然的是应该允许被访问的；当然我们定义了合法referer，如果客户端请求报文里的referer信息不配我们定义的合法referer匹配，我们就说这里客户端的referer是非法的，是不被允许的，理所当然的就应该做其他处理；这个是ngxin里内部的机制，不被合法referer所匹配的referer都是非法的referer，通常是用$invalid_referer保留这些不合法referer;或者我们这样理解，不被合法referer所匹配的请求报文就会被$invalid_referer所匹配；有了这种机制我们就可以明确定义那些请求时合法的，相对的那些请求是不合法的，对于不合法的我们可以这么处理；如下&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/i-beta/1503305/202003/1503305-20200304220350862-1644313429.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt; 　　提示：以上配置表示如果客户端请求报文的referer信息不是.ilinux.com结尾或者不是以www.ilinux.开头 或者 不是www.ilinux.io 或者不包含.baidu.或者.google. 我们都响应该客户端请求响应码为403；&lt;/p&gt;
&lt;p&gt;　　二、ngx_http_proxy_module：此模块允许将请求传递到另一个服务器。&lt;/p&gt;
&lt;p&gt;　　1、proxy_pass URL;该指令主要作用是用来设置被代理服务器地址的，可以说主机名称，IP地址加端口的形式；其中URL表示被代理服务器的地址，包含协议、主机名或IP加端口、URI等。传输协议通常是“http”或者&quot;https&quot;；如果我们被代理的是一个本地unix-domain套接字时，也支持以http://或https://加unix套接字路径的形式；如果我们代理的是一组服务器时，我们可以用upstream指令把该组服务器同一归并为一个名称的组服务器组，当然这是我们后面要聊的nginx作为负载均衡的配置；这里特别要说明的是URL中是否包含URI，什么意思呢，就是URL不包含URI的意思就是 被代理的URL没有URI，就只有协议IP地址或域名或主机名，这种就叫不带URI；带URI就表示除了协议主机名或域名或IP地址外，后面还有RUI；对于这两种情况Nginx处理逻辑上不一样的，如果RUL不包含URI 那么nginx服务器不会改变源地址的URI；如果URL包含URI，nginx服务器将会使用新的URI替换原来的URI；&lt;/p&gt;
&lt;p&gt;　　示例：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/i-beta/1503305/202003/1503305-20200304225326005-1937697636.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt; 　　提示：以上配置就是我们所的URL不包含URI的情况，用户请求www.test.com/en/docs/将会被该location匹配到，然后将访问www.test.com/en/docs/将会被代理到http://nginx.org/en/docs/；我们可以理解为被代理的URL不包含URI时，Nginx服务器会把用户请求的URI当作被代理服务器的URI；所以以上配置就表示，用户访问www.test.com/en/docs/将被代理至http://nginx.org/en/docs/&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1503305/202003/1503305-20200304230124247-1601986371.gif&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　提示：在做以上实验时，需要在Windows上做好解析www.test.com；Windows上需要在C:\Windows\System32\drivers\etc\hosts文件中添加一条解析记录，语法同Linux里的hosts一样192.168.0.30 www.ilinux.io www.test.com；&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/i-beta/1503305/202003/1503305-20200304230523868-343451386.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt; 　　提示：以上配置就是URL包含URI的情况，这种情况Nginx服务器会把用户请求的URI替换成被代理的URI；以上面的配置示例，如果用户请求www.test.com/test/那么这个请求到了nginx服务器时，nginx会把用户原有的URI/test/替换成/en/docs/,所以用户请求www.test.com/test/就会被代理至http://nginx.org/en/docs/;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1503305/202003/1503305-20200304231232551-2098799536.gif&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　提示：通过上面的演示，我们可以总结为，如果我们不想改变源请求的URI，那么我们在后端代理时就不带URI，如果我们想更改源请求URI，那么我们在后端代理时，就带上URI即可&lt;/p&gt;
&lt;p&gt;　　理解了上面我们所的URL包含或不包含URI，我们就不难理解下面的例子&lt;/p&gt;
&lt;p&gt;　　示例：proxy_pass URL末尾是否带“/”问题&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/i-beta/1503305/202003/1503305-20200304232726065-1298059217.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt; 　　提示：以上配置和我们之前的第一个示例就只多了一个“/”；多一个“/”在我们看来是不要紧，但它对nginx来说，意思却变了，就以我们上面说的，这种就是URL包含URI的情况，nginx会把后面的“/”认为是URI，不是认为，它本来就是一个URI；当客户端请求www.test.com/en/docs/时，nginx会把该请求代理至http://nginx.org/；当然这样处理后的结果肯定和我们之前的结果是完全不一样的，http://nginx.org/就表示请求nginx.org的主页；&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1503305/202003/1503305-20200304234219205-516227499.gif&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　提示：和第一个示例一样的URL，对于proxy_pass URL后面没有&quot;/&quot;和有“/”被代理响应的结果是不一样的；&lt;/p&gt;
&lt;p&gt;　　除了上面URL包含或不包含URI问题需要我们特别注意外，我们还要注意，如果location定义URI时使用了正则，或在if语句或在limit_execept中使用了proxy_pass指令，则proxy_pass 之后不能使用URI；用户请求时传递的URI将直接附加代理到的服务器之后；意思就是URL包含URI的情况不能在location 使用了正则匹配URL，或者URL包含URI的情况不允许用在if语句中  或limit_except中&lt;/p&gt;
&lt;p&gt;　　示例：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/i-beta/1503305/202003/1503305-20200304235259239-750500906.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt; 　　提示：这种配置我们在语法检查的时候就通不过，要想被通过，我们只需要把proxy_pass指令后面的URI去掉即可&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/i-beta/1503305/202003/1503305-20200304235521629-896859356.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt; 　　提示：总结一点就是location中使用了正则匹配 URL时，后面代理是不能有URI的，否则语法错误；&lt;/p&gt;
&lt;p&gt; 　　2、proxy_set_header field value;设定发往后端主机的请求报文的请求首部的值；可用在http,server,location配置段中&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;33&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
proxy_set_header X-Real-IP  $remote_addr;
proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　提示：以上配置表示在用户请求通过代理发送给后端主机时，在其请求头部加上X-Real-IP这个字段，并且这个字段的值是$remote_addr（客户端IP地址）和X-Forwarded-For字段，其值为$proxy_add_x_forwarded_for；$proxy_add_x_forwarded_for 这个变量是也是记录IP地址的，不同的是，这个变量它记录了客户端IP和代理服务端ip，两个IP分别用逗号隔开，如果没有代理服务器的场景，这个变量的意义同$remote_addr是一样的，都是记录客户端客户端IP&lt;/p&gt;
&lt;p&gt;　　3、proxy_cache_path：定义可用于proxy功能的缓存，此指令只可配置在http配置段；&lt;/p&gt;
&lt;p&gt;　　语法：&lt;/p&gt;
&lt;p&gt;　　　　proxy_cache_path path [levels=levels] [use_temp_path=on|off] keys_zone=name:size [inactive=time] [max_size=size] [manager_files=number] [manager_sleep=time] [manager_threshold=time] [loader_files=number] [loader_sleep=time] [loader_threshold=time] [purger=on|off] [purger_files=number] [purger_sleep=time] [purger_threshold=time];&lt;/p&gt;
&lt;p&gt;　　　　path：表示设置缓存数据存放路径，该路径必须事先存在；&lt;/p&gt;
&lt;p&gt;　　　　levels;表示设置存放缓存数据的目录级别，这个和前面说的nginx缓存目录一样。levels=1:2表示两级目录，且一级目录是一个字符哈希目录，二级目录是两个字符的哈希目录，目录名称是基于URL哈希算法获取到的；&lt;/p&gt;
&lt;p&gt;　　　　keys_zone=name:size 表示设置缓存索引在内存区域的名称和大小；&lt;/p&gt;
&lt;p&gt;　　　　inactive=time设置非活动缓存时间，在指定的时间内如果该缓存项没有被命中，nginx就会强制把该缓存从磁盘上删除，如果下次有人访问时在缓存，依次循环；默认10分钟;&lt;/p&gt;
&lt;p&gt;　　　　max_size=size:设置磁盘中缓存数据的大小限制，当缓存数据超过我们设定的大小时，就是用LRU算法来删除缓存；&lt;/p&gt;
&lt;p&gt;　　　　loader_files=number:设置缓存索引重建进程每次加载的数据元素的数量上限；&lt;/p&gt;
&lt;p&gt;　　　　loader_sleep=time:设置缓存索引重建进程在一次遍历结束、下次遍历开始之间的暂停时长，默认是50ms&lt;/p&gt;
&lt;p&gt;　　　　loader_threshold=time:设置遍历一次磁盘缓存源数据的时间上限，默认设置为200ms&lt;/p&gt;
&lt;p&gt;　　通常情况下我们不需要设置这么多选项，只需要把前三个选项设置好就行了，没有特殊的要求后面的选项我们用默认值就可以&lt;/p&gt;
&lt;p&gt;　　示例：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/i-beta/1503305/202003/1503305-20200305221706868-926971043.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt; 　　提示：以上配置表示定义代理缓存路径是/cache/proxy/nginx 目录级别是1：2：1  缓存索引重建进程内存区域名称为proxy_cache,大小为10M 对于磁盘上的/cache/proxy/nginx/目录最大缓存空间为2g；这样设置后，我们就可以在各个server或location中来调用此缓存定义&lt;/p&gt;
&lt;p&gt;　　4、proxy_cache zone | off;指明要调用的缓存，或关闭缓存机制；此指令可用于http,server,location配置段中；&lt;/p&gt;
&lt;p&gt;　　示例&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/i-beta/1503305/202003/1503305-20200305221913967-155189989.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt; 　　提示：这样去调用缓存空间进行缓存是不能够缓存的，因为我们调用缓存空间是有条件的，比如我们要对那些请求方法的请求进行缓存？对不同响应码的资源缓存多久？是否在后端服务器出现错误时，我们继续使用缓存来响应？所以我们现在虽然配置了调用缓存空间，但是我们服务器还是不知道怎么去缓存客户访问的内容；所以它干脆就不给缓存；&lt;/p&gt;
&lt;p&gt;　　示例：我们只调用了缓存空间，没有配置其他配置，用户访问的数据是否能够缓存下来呢？&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1503305/202003/1503305-20200305223910722-299377774.gif&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　提示：可以看到我们只配置缓存空间然后调用是不行的，我们还需要指定缓存的key是什么 ，对客户端使用的那些方法进行缓存，对不同的响应码的资源缓存多久，这是调用缓存空间的几个必要的配置，我们需要加上才行；&lt;/p&gt;
&lt;p&gt;　　5、proxy_cache_key:定义缓存key，默认是$scheme$proxy_host$request_uri，它这个默认就是缓存的key是协议加代理主机地址或主机名或FQDN和用户请求的uri当作缓存的KEY；也就是说服务端怎么去找缓存的方式，对应key的定义；&lt;/p&gt;
&lt;p&gt;　　6、proxy_cache_methods METHODS：定义缓存用户的请求方式，也就是说那些请求方法的资源我们要进行缓存，默认是GET HEAD；&lt;/p&gt;
&lt;p&gt;　　7、proxy_cache_valid [code] time:定义不同的响应码的资源缓存时长；&lt;/p&gt;
&lt;p&gt;　　8、proxy_cache_use_stale error |timeout|……：定义后端服务器基于那种状态使用缓存，默认是不基于后端服务器状态使用缓存；比如后端服务器发生错误，是否用缓存中的内容响应客户端？如果我们定义 proxy_cache_use_stale http 403就表示后端服务器如果响应代理服务器403，我们代理服务器就是用之前的缓存，响应客户端；&lt;/p&gt;
&lt;p&gt;　　示例:&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/i-beta/1503305/202003/1503305-20200305225917725-1953141286.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt; 　　提示：以上配置表示使用proxy_cache缓存空间，缓存key是用户请求的uri进行缓存，对用户使用GET 和HEAD方法请求的资源进行缓存，对响应码是200 302的资源缓存15分钟，对响应码是404的资源缓存1分钟，后端服务器出现500 或502的错误，代理服务器使用以前的缓存响应客户端；&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1503305/202003/1503305-20200305231624314-778362155.gif&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt; 　　提示：可看到浏览器请求了两个uri，在对应的缓存目录里就存在两个缓存项；这里面每一个缓存项就是对应一个用户请求过多URI;通常情况我们启用了Nginx代理缓存功能时，用户第一次访问就会很慢，但是只要把数据缓存下来后，后续的用户在访问相同的URI时，这个速度就会有明显的提升；&lt;/p&gt;
&lt;p&gt; 　　总结对于nginx的缓存，我们首先在http配置段定义一个缓存空间，然后在各server或location中调用我们定义的缓存空间，并明确说明各种响应码的资源缓存多长时间，对于proxy_cache_key 和 proxy_cache_methods是可以不指定的，不指定就代表使用默认值，从上面的配置我们其实就只定义响应码是多少的资源缓存多久，其他的按照默认来，它也是可以进行缓存的；&lt;/p&gt;
</description>
<pubDate>Thu, 05 Mar 2020 15:42:00 +0000</pubDate>
<dc:creator>Linux-1874</dc:creator>
<og:description>前文我们聊了下Nginx作为web服务器配置https、日志模块的常用配置、rewrite模块重写用户请求的url，回顾请参考https://www.cnblogs.com/qiuhom-1874/p</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/qiuhom-1874/p/12417130.html</dc:identifier>
</item>
<item>
<title> 0308 软件系统的非功能需求 - 李福春</title>
<link>http://www.cnblogs.com/snidget/p/12423824.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/snidget/p/12423824.html</guid>
<description>&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/268922/202003/268922-20200305232605454-1247497152.png&quot; alt=&quot;image.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;故事开始。&lt;/p&gt;
&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;小李是一个一线的java程序员，做软件开发多年，有一天，被邀请去参加一个大厂的面试，面试前他做了各种准备，有软件原理方面的，软件设计方面的，还有软件架构方面的知识。并不断总结提炼成了一张知识图谱。想着即使不成功，也是一次不错的技术交流，至少可以知道目前大厂需要的程序员具备的技能深度和广度，给自己定定位。下面是技术一面。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;小李：你好，我是李x,今年y岁，做一线开发z年，我来面试。&lt;/p&gt;
&lt;p&gt;大厂牛逼架构师：你好，小李。我是a厂的面试官b,我来给你面试。直接开门见山了。&lt;strong&gt;问题1，简单说一下软件研发的过程？&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;小李：按照软件工程的瀑布模型.&lt;/p&gt;
&lt;p&gt;软件研发分为可行性分析，需求分析，概要设计，详细设计，编码，测试，发布，交付，维护，下线等节点。但是这些流程比较重，往往当软件开发完成交付的时候，客户的需求已经发生了变更，软件需要重新打回需求分析和概要设计阶段开始，导致软件的工期远远超出预期，而且开发方耗时间耗人力，客户方并不满意。&lt;/p&gt;
&lt;p&gt;那么怎么破呢？&lt;/p&gt;
&lt;p&gt;按照当下流行的敏捷研发模式，软件在需求分析阶段，按照优先级别分批次设定发布计划，然后基于发布计划规划迭代，针对单个小迭代，开发，测试同一时间点参与，研发完成立马发布交付客户验收，客户快速反馈，针对反馈的问题，及时调整规划的需求，这样小步快跑，快速迭代的而方式去管理软件的研发过程，解决研发方研发的时间和人力成本高，客户还不满意的难题。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/268922/202003/268922-20200305232608858-1314539652.png&quot; alt=&quot;image.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;大厂牛逼架构师：&lt;strong&gt;问题2：系统概要设计阶段的非功能需求有哪几种？&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;小李：软件除了实现客户的基本功能需求之外，还要满足预设的非功能性需求，好比冰山下的庞大底座，看不见的东西往往最耗费和考验软件工程师的功力，对架构能力，编码能力要求比较高。主要包含高性能，安全，高可用等。&lt;/p&gt;
&lt;p&gt;&lt;embed src=&quot;https://img2020.cnblogs.com/blog/268922/202003/268922-20200305232609369-1602160547.webp&quot;/&gt;&lt;/p&gt;

&lt;p&gt;大厂牛逼架构师：&lt;strong&gt;问题3：简单介绍一下高性能的指标？你使用过的性能调优方法？以及你的一个性能调优经历？&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;小李：高性能是软件系统的核心非功能需求，性能调优是软件架构师的核心职责，一般由高并发引起性能问题。要进行系统的性能优化，必须先进行性能测试。&lt;/p&gt;
&lt;p&gt;软件系统的性能指标如下。&lt;/p&gt;
&lt;p&gt;第一，响应时间，即用户发出请求到获得响应的总时间；&lt;/p&gt;
&lt;p&gt;第二，并发数，即软件系统可以同时处理的请求数量,即HPS；&lt;/p&gt;
&lt;p&gt;第三，吞吐量，有两个个基本指标，TPS（每秒处理事物数）,QPS(每秒处理查询数)；&lt;/p&gt;
&lt;p&gt;第四，操作系统的性能计数器，比如CPU,内存的使用率，磁盘IO，系统负载，对象数和线程数量；&lt;/p&gt;
&lt;p&gt;性能调优的原动力是提升用户体验，比如在异步显示资源，等待的时候可以转菊花；&lt;/p&gt;
&lt;p&gt;性能调优的客观方法分为7种：&lt;/p&gt;
&lt;p&gt;从软件系统的范围由大到小分别说明。&lt;/p&gt;
&lt;p&gt;1，多数据中心，让用户访问离他最近的数据中心，可以显著降低响应时间。&lt;/p&gt;
&lt;p&gt;2，使用高配置的硬件，比如更高的cpu，内存，对系统进行垂直扩展。&lt;/p&gt;
&lt;p&gt;3，操作系统的参数调优，比如调大TCP的连接数，调小TCP的默认等待时间等；&lt;/p&gt;
&lt;p&gt;4，JVM调优，设置合适的jvm的存储参数，选择合适的垃圾回收算法等；&lt;/p&gt;
&lt;p&gt;5，软件系统的依赖组件调优，比如web服务器的配置调优，数据库的调优等；&lt;/p&gt;
&lt;p&gt;6，软件架构调优，比如可以引入集群，缓存，消息队列等；&lt;/p&gt;
&lt;p&gt;7，代码层面的优化，比如使用更优的数据结构，使用线程池连接池，sql语句调优，反应式框架，异步io，设计模式写出更简洁易读的代码等；&lt;/p&gt;
&lt;p&gt;性能调优的流程是：&lt;/p&gt;
&lt;p&gt;1，对要调优的软件系统进行性能测试，工具有很多比如jmeter,loadrunner等，使用多线程的方式模拟用户并发访问系统；&lt;/p&gt;
&lt;p&gt;2，观察软件系统的性能指标，分析得到产生性能的问题的瓶颈点，需要非常了解整个系统的结构，然后解决这个瓶颈点；&lt;/p&gt;
&lt;p&gt;3，然后继续跑性能测试，对比调优前后的性能指标。如果提高了则结束，没有提高则重复1步骤；&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/268922/202003/268922-20200305232614813-1556863796.png&quot; alt=&quot;image.png&quot;/&gt;&lt;/p&gt;

&lt;p&gt;大厂牛逼架构师：&lt;strong&gt;问题4：简单介绍一下数据加密的种类？以及常见的软件安全漏洞？最后讲讲实际工作中应该如何保证软件的系统安全？&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;小李：软件系统系统只有被攻击，数据泄漏之后才意识到安全的重要性。&lt;/p&gt;
&lt;p&gt;数据加密的种类有3种：&lt;/p&gt;
&lt;p&gt;1，单向加密，比如常用的md5,一般使用的时候还要加个salt,并增加输入的密码复杂性检查，防止彩虹表破解密码；&lt;/p&gt;
&lt;p&gt;2，对称加密，常见的比如RSA加密，通过一个秘钥进行加密和解密，只要秘钥不泄漏就是安全的；&lt;/p&gt;
&lt;p&gt;3，非对称加密，常见的比如公钥私钥对，数字签名是非对称加密的应用，使用私钥加密获得密文，发送出去，只有配对的公钥才能解密，以此来验证数据来源的合法性。但是性能比较差。&lt;/p&gt;
&lt;p&gt;除了数据加密，还需要保证数据在传输过程加密，那就要说到https协议了，它是结合使用了对称加密和非对称加密，首先使用非对称加密，产生一个秘钥，客户端拿到秘钥之后，对数据进行对称加密，服务端根据生成的秘钥进行数据解密。充分保证了数据处理的性能和传输数据的安全。&lt;/p&gt;
&lt;p&gt;常见的安全漏洞：&lt;/p&gt;
&lt;p&gt;HTTP安全漏洞：&lt;/p&gt;
&lt;p&gt;1,  SQL注入，解决方法使用Preparestatement替代statement处理传输过来的参数；&lt;/p&gt;
&lt;p&gt;2，xss攻击，上传攻击脚本到服务器，别的用户获取数据的时候会解析这个攻击脚本，达成攻击目的，解决方式是字符串转义；&lt;/p&gt;
&lt;p&gt;可以通过在网关中增加web防火墙或者在代码中增加过滤器来处理。&lt;/p&gt;
&lt;p&gt;此外还有硬件和操作系统的安全漏洞，使用软件和组件的安全漏洞等。&lt;/p&gt;
&lt;p&gt;实际工作中，应该应该及时升级依赖的软件和组件的版本，&lt;/p&gt;
&lt;p&gt;升级版本一般修复了对应的安全漏洞，此外我们应该在程序中做好参数过滤，&lt;/p&gt;
&lt;p&gt;最后，应该对最终存储的数据和传输的数据进行加密，提高黑客攻击的难度。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/268922/202003/268922-20200305232615894-138497262.png&quot; alt=&quot;image.png&quot;/&gt;&lt;/p&gt;

&lt;p&gt;大厂牛逼架构师：&lt;strong&gt;问题5：简单说一下如何保证软件系统的高可用？&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;小李：高可用即要求软件系统在各种故障发生的时候做到可用或者大部分可用，软件系统的可用率一般采用N个9的方式来衡量。&lt;/p&gt;
&lt;p&gt;各种故障都可能影响软件系统的可用性，比如：&lt;/p&gt;
&lt;p&gt;1，自然灾害&lt;/p&gt;
&lt;p&gt;2，人为原因&lt;/p&gt;
&lt;p&gt;3，高并发访问&lt;/p&gt;
&lt;p&gt;4，硬件故障&lt;/p&gt;
&lt;p&gt;5，软件故障&lt;/p&gt;
&lt;p&gt;保证系统的高可用有5种方法：&lt;/p&gt;
&lt;p&gt;1，冗余备份，即多准备几个服务器，比如多个web服务器（故障转移），数据库服务器（多主模式集群）；&lt;/p&gt;
&lt;p&gt;2，异地多活，即通过域名的方式，把请求分发到多个地域的不同机房；&lt;/p&gt;
&lt;p&gt;3，限流降级，限流即限制HPS，降级即关闭非核心功能让出有限资源；&lt;/p&gt;
&lt;p&gt;4，失败隔离：消息队列削峰填谷，转移写压力，隔离失败；&lt;/p&gt;
&lt;p&gt;5，运维方法：自动测试，自动监控，灰度，预发布等；&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/268922/202003/268922-20200305232617325-1451864244.png&quot; alt=&quot;image.png&quot;/&gt;&lt;/p&gt;

&lt;p&gt;大厂牛逼架构师：&lt;/p&gt;
&lt;p&gt;小李架构功夫很扎实。简单的点评一下。&lt;/p&gt;
&lt;p&gt;1，不愧是多年的一线开发人员，软件研发流程非常熟悉，而且敏捷研发模式有一定经验；&lt;/p&gt;
&lt;p&gt;2，高性能是非常重要的非功能需求，调优方式7中都答的很到位；&lt;/p&gt;
&lt;p&gt;3，安全性也是非常重要的，数据加密分类清晰，http的攻击防护手段有所了解；&lt;/p&gt;
&lt;p&gt;4，高可用的手段总结的很到位；&lt;/p&gt;
&lt;p&gt;小李：感谢您的评价，希望有机会合作，为企业打造数字化产品帝国。&lt;/p&gt;
&lt;p&gt;故事讲完。&lt;/p&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;原创不易，转载请注明出处。&lt;/p&gt;
&lt;/blockquote&gt;
</description>
<pubDate>Thu, 05 Mar 2020 15:26:00 +0000</pubDate>
<dc:creator>李福春</dc:creator>
<og:description>故事开始。 小李是一个一线的java程序员，做软件开发多年，有一天，被邀请去参加一个大厂的面试，面试前他做了各种准备，有软件原理方面的，软件设计方面的，还有软件架构方面的知识。并不断总结提炼成了一张知</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/snidget/p/12423824.html</dc:identifier>
</item>
<item>
<title>JavaScript(5)--- 面向对象 + 原型 - 雨点的名字</title>
<link>http://www.cnblogs.com/qdhxhz/p/12181259.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/qdhxhz/p/12181259.html</guid>
<description>&lt;center&gt;

&lt;/center&gt;
&lt;p&gt;面向对象这个概念并不陌生,如 &lt;strong&gt;C++、Java&lt;/strong&gt; 都是面向对象语言。面向对象而言都会现有一个类的概念 ，先有类再有对象。类是实例的类型模板。&lt;/p&gt;
&lt;p&gt;比如人类 是一个类 张三 李四 就是一个个对象，他们都是人类创建出的对象 所以都有人类的共同特性，比如 人类都会吃饭 人类都会走路 所以张三李四也会吃饭和走路。&lt;/p&gt;
&lt;p&gt;JavaScript 没有类的概念，是&lt;strong&gt;基于原型的面向对象方式&lt;/strong&gt;。它们的区别在于：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;在基于类的面向对象方式中，对象（object）依靠类（class）来产生。
在基于原型的面向对象方式中，对象（object）则是依靠构造函数（constructor）和原型（prototype）构造出来的。&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;面向对象语言的第一个特性毫无疑问是封装，在 JS 中，封装的过程就是把一些 &lt;strong&gt;属性&lt;/strong&gt; 和 &lt;strong&gt;方法&lt;/strong&gt; 放到对象中“包裹”起来。&lt;/p&gt;
&lt;h2 id=&quot;一创建对象三种方式&quot;&gt;&lt;span&gt;一、创建对象三种方式&lt;/span&gt;&lt;/h2&gt;
&lt;h4 id=&quot;原始方式创建对象&quot;&gt;1、原始方式创建对象&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;1) 字面量的方式&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;示例&lt;/code&gt;&lt;/p&gt;
&lt;pre class=&quot;javascript&quot;&gt;
&lt;code&gt;        var per = {
            name: &quot;张三&quot;,
            age: 20,
            sex: &quot;男&quot;,
            say: function () {
                console.log(&quot;说话&quot;);
            }
        };&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;2) Object实例添加属性方法&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;示例&lt;/code&gt;&lt;/p&gt;
&lt;pre class=&quot;javascript&quot;&gt;
&lt;code&gt;           var per2=new Object();
           per2.name=&quot;李四&quot;;
           per2.age=30;
           per2.sex=&quot;男&quot;;
           per2.say=function () {
             console.log(&quot;说话&quot;);
           };&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;优点&lt;/strong&gt;：代码简单。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;缺点&lt;/strong&gt;： 创建多个对象会产生大量的代码，编写麻烦，且并没有实例与原型的概念。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;解决办法&lt;/strong&gt;：工厂模式。&lt;/p&gt;
&lt;h4 id=&quot;工厂模式&quot;&gt;2、工厂模式&lt;/h4&gt;
&lt;p&gt;&lt;code&gt;概念&lt;/code&gt; 工厂模式是非常常见的一种设计模式，它抽象了创建具体对象的过程。JS 中创建一个函数，把创建新对象、添加对象属性、返回对象的过程放到这个函数中，&lt;/p&gt;
&lt;p&gt;用户只需调用函数来生成对象而无需关注对象创建细节。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;示例&lt;/code&gt;&lt;/p&gt;
&lt;pre class=&quot;javascript&quot;&gt;
&lt;code&gt;    function createObject(name,age) {
      this.name=name;
      this.age=age;
      this.say=function () {
        console.log(&quot;说话&quot;);
      };
    }
    var per1=createObject(&quot;张三&quot;,20);
    var per2=createObject(&quot;李四&quot;,30);&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;优点&lt;/strong&gt;：工厂模式解决了对象字面量创建对象代码重复问题，创建相似对象可以使用同一API。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;缺点&lt;/strong&gt;：因为是调用函创建对象，无法识别对象的类型。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;解决办法&lt;/strong&gt;：构造函数&lt;/p&gt;
&lt;h4 id=&quot;构造函数&quot;&gt;3、构造函数&lt;/h4&gt;
&lt;p&gt;JS 中构造函数与其他函数的唯一区别，就在于调用它的方式不同。任何函数，只要通过&lt;code&gt;new&lt;/code&gt; 操作符来调用，那它就可以作为构造函数。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;示例&lt;/code&gt;&lt;/p&gt;
&lt;pre class=&quot;javascript&quot;&gt;
&lt;code&gt;   //自定义构造函数-----&amp;gt;实例化对象
    function Person(name,age,sex) {
      this.name=name;
      this.age=age;
      this.sex=sex;
      this.say=function () {
        console.log(&quot;说话&quot;);
      };
    }
    //构造函数----&amp;gt;创建对象
    var per1=new Person(&quot;张三&quot;,20,&quot;女&quot;);
    var per2=new Person(&quot;李四&quot;,30,&quot;女&quot;);&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;通过构造函数&lt;code&gt;new&lt;/code&gt;一个实例经历了四步：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;1. 创建一个新对象；
2. 将构造函数内的 this 绑定到新对象上；
3. 为新对象添加属性和方法；
4. 返回新对象（JS 引擎会默认添加 return this;）。&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;而通过构造函数创建的对象都有一个&lt;code&gt;constructor&lt;/code&gt;属性，它是一个指向构造函数本身的指针，因此就可以检测对象的类型。&lt;/p&gt;
&lt;pre class=&quot;javascript&quot;&gt;
&lt;code&gt;alert(per1.constructor === Person) //true
alert(per1 instanceof Person) // true&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;但是仍然存在问题：&lt;/p&gt;
&lt;pre class=&quot;javascript&quot;&gt;
&lt;code&gt;alert(per1.say == per2.say) //false&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;同一个构造函数中定义了&lt;code&gt;say()&lt;/code&gt;，而不同对象的同名函数却是不相等的，意味着这两个同名函数的内存空间不一致，也就是&lt;strong&gt;构造函数中的方法&lt;/strong&gt;要在每个实例上重新创建一次。&lt;/p&gt;
&lt;p&gt;这显然增加不必要内存空间。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;优点&lt;/strong&gt;：解决了类似对象创建问题，且可以检测对象类型。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;缺点&lt;/strong&gt;：构造函数方法要在每个实例上新建一次。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;解决办法&lt;/strong&gt;：原型模式。&lt;/p&gt;

&lt;h2 id=&quot;二原型模式&quot;&gt;&lt;span&gt;二、原型模式&lt;/span&gt;&lt;/h2&gt;
&lt;h4 id=&quot;概念&quot;&gt;1、概念&lt;/h4&gt;
&lt;p&gt;在JS中，创建对象的方式有工厂模式和构造函数模式等； 而构造函数模式最大的问题在于：&lt;code&gt;构造函数中的每个方法都需要在实例对象中重新创建一遍，不能复用&lt;/code&gt;，&lt;/p&gt;
&lt;p&gt;所以为了解决这一个问题，就需要使用原型模式来创建对象。原型模式是把所有实例共享的方法和属性放在一个叫做 &lt;code&gt;prototype(原型)&lt;/code&gt;的属性中 ，在创建一个函数&lt;/p&gt;
&lt;p&gt;时都会有个prototype属性， 这个属性是一个指针，指向一个对象，是通过调用构造函数而创建的那个对象实例的原型对象。&lt;/p&gt;
&lt;p&gt;如果你学习过java，我们可以简单理解原型就好比我们的静态方法,任何对象都可以共享这个静态方法。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;作用&lt;/code&gt; 共享数据,节省内存空间。&lt;/p&gt;
&lt;h4 id=&quot;举例&quot;&gt;2、举例&lt;/h4&gt;
&lt;p&gt;使用原型，就意味着我们可以把希望实例共享的属性和方法放到原型对象中去，而不是放在构造函数中，这样每一次通过构造函数&lt;code&gt;new&lt;/code&gt;一个实例，原型对象中定义&lt;/p&gt;
&lt;p&gt;的方法都不会重新创建一次。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;示例&lt;/code&gt;&lt;/p&gt;
&lt;pre class=&quot;javascript&quot;&gt;
&lt;code&gt;//原型的作用之一:共享数据,节省内存空间
function Person() {
}
//通过构造函数的原型添加属性和方法
Person.prototype.name = &quot;张三&quot;;
Person.prototype.age = &quot;20&quot;;
Person.prototype.say = function() {
  alert('通过原型创建吃饭方法');
};

var person1 = new Person();
var person2 = new Person();
alert(person1.name); //&quot;张三&quot;
alert(person2.name); //&quot;张三&quot;
alert(person1.say == person2.say); //true 通过原型创建的方法就为true&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;优点&lt;/strong&gt;：与单纯使用构造函数不一样，原型对象中的方法不会在实例中重新创建一次，节约内存。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;缺点&lt;/strong&gt;：使用空构造函数，实例 person1 和 person2 的 &lt;code&gt;name&lt;/code&gt;都一样了，我们显然不希望所有实例属性方法都一样，它们还是要有自己独有的属性方法。&lt;br/&gt;并且如果原型中对象中有引用类型值，实例中获得的都是该值的引用，意味着一个实例修改了这个值，其他实例中的值都会相应改变。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;解决办法&lt;/strong&gt;：构造函数+原型模式组合使用。&lt;/p&gt;

&lt;h2 id=&quot;三构造函数原型模式&quot;&gt;&lt;span&gt;三、构造函数+原型模式&lt;/span&gt;&lt;/h2&gt;
&lt;p&gt;最后一种方式就是组合使用构造函数和原型模式，构造函数用于定义实例属性，而共享属性和方法定义在原型对象中。这样每个实例都有自己独有的属性，&lt;/p&gt;
&lt;p&gt;同时又有对共享方法的引用，节省内存。&lt;/p&gt;
&lt;pre class=&quot;javascript&quot;&gt;
&lt;code&gt;    //原型的作用之一:共享数据,节省内存空间
    //构造函数
    function Person(age,sex) {
      this.age=age;
      this.sex=sex;
    }
    //通过构造函数的原型添加一个方法
    Person.prototype.eat=function () {
      console.log(&quot;通过原型创建吃饭方法&quot;);
    };

    var per1=new Person(20,&quot;男&quot;);
    var per2=new Person(20,&quot;女&quot;);
    alert(per1.eat == per2.eat); //通过原型创建的方法就为true&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;这种构造函数与原型模式混成的模式，是目前在 JS 中使用最为广泛的一种创建对象的方法。&lt;/p&gt;

&lt;h3 id=&quot;参考&quot;&gt;&lt;span&gt;参考&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;1、&lt;a href=&quot;https://segmentfault.com/a/1190000015843072&quot;&gt;JS面向对象编程之封装&lt;/a&gt; 基本上参考这篇写的，因为我认为它写的非常通俗易懂，不需要我再去整理了。非常感谢&lt;/p&gt;
&lt;p&gt;2、&lt;a href=&quot;https://zhuanlan.zhihu.com/p/41656666&quot;&gt;js面向对象编程&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;3、&lt;a href=&quot;https://www.jianshu.com/p/f9792fdd9915&quot;&gt;JavaScript面向对象&lt;/a&gt;&lt;/p&gt;


&lt;pre&gt;
&lt;code&gt;别人骂我胖，我会生气，因为我心里承认了我胖。别人说我矮，我就会觉得好笑，因为我心里知道我不可能矮。这就是我们为什么会对别人的攻击生气。
攻我盾者，乃我内心之矛(2)。&lt;/code&gt;
&lt;/pre&gt;</description>
<pubDate>Thu, 05 Mar 2020 15:03:00 +0000</pubDate>
<dc:creator>雨点的名字</dc:creator>
<og:description>面向对象 + 原型 面向对象这个概念并不陌生,如 C++、Java 都是面向对象语言。面向对象而言都会现有一个类的概念 ，先有类再有对象。类是实例的类型模板。 比如人类 是一个类 张三 李四 就是一个</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/qdhxhz/p/12181259.html</dc:identifier>
</item>
<item>
<title>沙雕与大婶 | Mock掉你的外部依赖吧 - EvanLeung</title>
<link>http://www.cnblogs.com/evan-liang/p/12423487.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/evan-liang/p/12423487.html</guid>
<description>&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;&lt;strong&gt;故事背景:&lt;/strong&gt;&lt;br/&gt;沙雕在公司负责API项目的开发，很认真负责，经常加班加点赶进度，却常常被老板吐槽说他开发效率太低，他自己也很委屈，因为他所负责的项目常常依赖大量外部系统，他只好等对方开发完才一个个对接，开发时间也很难把握，导致效率非常低，团队里的测试同学也很无奈，只能等他开发完才能测试。有一天，他咨询公司里一位大婶，寻求解决方案。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20200305215155615.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0V2YW5fTGV1bmc=,size_16,color_FFFFFF,t_70&quot;/&gt;&lt;/p&gt;

&lt;p&gt;假如你依赖下游系统一个API，它的Endpoint是&lt;code&gt;GET http://xxxx/accounts&lt;/code&gt;&lt;/p&gt;
&lt;h2 id=&quot;配置你的mock-server&quot;&gt;&lt;strong&gt;配置你的Mock Server&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;1.创建你的专属&lt;code&gt;Mock Server&lt;/code&gt;&lt;br/&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20200305220348923.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0V2YW5fTGV1bmc=,size_16,color_FFFFFF,t_70&quot;/&gt;&lt;br/&gt;2.定义你依赖的下游系统一系列API Endpoint，并且填入你想要的响应数据&lt;/p&gt;
&lt;p&gt;Requet Path:&lt;br/&gt;&lt;code&gt;/accounts&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Request Boday:&lt;/p&gt;
&lt;pre class=&quot;json&quot;&gt;
&lt;code&gt;{
    &quot;code&quot;: 200,
    &quot;message&quot;: &quot;Operation Successfully&quot;,
    &quot;data&quot;: [
        123456,
        654321
    ]
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20200305221306932.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0V2YW5fTGV1bmc=,size_16,color_FFFFFF,t_70&quot;/&gt;&lt;/p&gt;
&lt;p&gt;3.填入Mock Server名称，点击创建&lt;br/&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20200305221627398.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0V2YW5fTGV1bmc=,size_16,color_FFFFFF,t_70&quot;/&gt;&lt;br/&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20200305221754485.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0V2YW5fTGV1bmc=,size_16,color_FFFFFF,t_70&quot;/&gt;&lt;br/&gt;这就已经创建完成了&lt;/p&gt;
&lt;p&gt;4.获取Mock Server自动生成的域名&lt;br/&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20200305222202894.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0V2YW5fTGV1bmc=,size_16,color_FFFFFF,t_70&quot;/&gt;&lt;br/&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20200305222322328.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0V2YW5fTGV1bmc=,size_16,color_FFFFFF,t_70&quot;/&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20200305222438123.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0V2YW5fTGV1bmc=,size_16,color_FFFFFF,t_70&quot;/&gt;&lt;br/&gt;&lt;code&gt;https://36669d4e-1c55-448c-a380-c0a71d8b0ece.mock.pstmn.io&lt;/code&gt;这就是我们Mock Server自动生成的域名，后面我们只需要用该域名请求即可&lt;/p&gt;
&lt;p&gt;5.用浏览器代替你的应用，尝试通过Mock Server访问我们定义的API Endpoint&lt;br/&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20200305222728261.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0V2YW5fTGV1bmc=,size_16,color_FFFFFF,t_70&quot;/&gt;&lt;br/&gt;这样就成功啦，so easy!&lt;br/&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20200305223432166.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0V2YW5fTGV1bmc=,size_16,color_FFFFFF,t_70&quot;/&gt;&lt;/p&gt;
&lt;hr/&gt;
&lt;p&gt;&lt;strong&gt;官方文档&lt;/strong&gt;：&lt;a href=&quot;https://learning.postman.com/docs/postman/mock-servers/setting-up-mock/&quot;&gt;Mock Server配置&lt;/a&gt;&lt;/p&gt;
</description>
<pubDate>Thu, 05 Mar 2020 14:51:00 +0000</pubDate>
<dc:creator>EvanLeung</dc:creator>
<og:description>故事背景: 沙雕在公司负责API项目的开发，很认真负责，经常加班加点赶进度，却常常被老板吐槽说他开发效率太低，他自己也很委屈，因为他所负责的项目常常依赖大量外部系统，他只好等对方开发完才一个个对接，开</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/evan-liang/p/12423487.html</dc:identifier>
</item>
</channel>
</rss>