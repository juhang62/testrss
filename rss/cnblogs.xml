<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="css/feed.xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/" xmlns:og="http://ogp.me/ns#">
<channel>
<atom:link rel="self" href="http://192.168.1.4/fivefilters/makefulltextfeed.php?url=feed.cnblogs.com%2Fblog%2Fsitehome%2Frss&amp;max=10&amp;links=preserve&amp;exc=" />
<atom:link rel="alternate" title="Source URL" href="http://feed.cnblogs.com/blog/sitehome/rss" />
<atom:link rel="related" title="Subscribe to feed" href="http://www.subtome.com/#/subscribe?feeds=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed.cnblogs.com%252Fblog%252Fsitehome%252Frss%26max%3D10%26links%3Dpreserve%26exc%3D&amp;back=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed.cnblogs.com%252Fblog%252Fsitehome%252Frss%26max%3D10%26links%3Dpreserve%26exc%3D" />
<title>博客园_首页</title>
<link></link>
<description>代码改变世界</description>
<item>
<title>[ASP.NET Core 3框架揭秘] 配置[7]：多样化的配置源[中篇] - Artech</title>
<link>http://www.cnblogs.com/artech/p/inside-asp-net-core-05-07.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/artech/p/inside-asp-net-core-05-07.html</guid>
<description>&lt;p&gt;物理文件是我们最常用到的原始配置载体，而最佳的配置文件格式主要有三种，它们分别是JSON、XML和INI，对应的配置源类型分别是JsonConfigurationSource、XmlConfigurationSource和IniConfigurationSource，它们具有如下一个相同的基类FileConfigurationSource。&lt;/p&gt;

&lt;p&gt;FileConfigurationSource总是利用一个IFileProvider对象来读取配置文件，我们可以利用FileProvider属性来设置这个对象。配置文件的路径通过Path属性表示，一般来说这是一个针对IFileProvider对象根目录的相对路径。在读取配置文件的时候，这个路径将会作为参数调用IFileProvider对象的GetFileInfo方法得到描述配置文件的IFileInfo对象，该对象的CreateReadStream方法最终会被调用来读取文件内容。&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;35&quot;&gt;
&lt;pre&gt;
&lt;span&gt;public&lt;/span&gt; &lt;span&gt;abstract&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;&lt;span&gt; FileConfigurationSource : IConfigurationSource
{
    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; IFileProvider FileProvider { &lt;span&gt;get&lt;/span&gt;; &lt;span&gt;set&lt;/span&gt;&lt;span&gt;; }
    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;string&lt;/span&gt; Path { &lt;span&gt;get&lt;/span&gt;; &lt;span&gt;set&lt;/span&gt;&lt;span&gt;; }
    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;bool&lt;/span&gt; Optional { &lt;span&gt;get&lt;/span&gt;; &lt;span&gt;set&lt;/span&gt;&lt;span&gt;; }
    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;int&lt;/span&gt; ReloadDelay { &lt;span&gt;get&lt;/span&gt;; &lt;span&gt;set&lt;/span&gt;&lt;span&gt;; }
    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;bool&lt;/span&gt; ReloadOnChange { &lt;span&gt;get&lt;/span&gt;; &lt;span&gt;set&lt;/span&gt;&lt;span&gt;; }
    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; Action&amp;lt;FileLoadExceptionContext&amp;gt; OnLoadException { &lt;span&gt;get&lt;/span&gt;; &lt;span&gt;set&lt;/span&gt;&lt;span&gt;; }

    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;abstract&lt;/span&gt;&lt;span&gt; IConfigurationProvider Build(IConfigurationBuilder builder);
    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt;&lt;span&gt; EnsureDefaults(IConfigurationBuilder builder);
    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt;&lt;span&gt; ResolveFileProvider();
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;&lt;span&gt;ResolveFileProvider方法&lt;/span&gt;&lt;/h2&gt;
&lt;p&gt;如果FileProvider属性并没有被显式赋值，而我们指定的配置文件路径是一个绝对路径（比如“c:\app\appsettings.json”），那么一个针对配置文件所在目录（“c:\app”）的PhysicalFileProvider将会自动创建出来作为FileProvider的属性值，而Path属性将被设置成配置文件名。如果指定的仅仅是一个相对路径，FileProvider属性将不会被自动初始化。这个逻辑实现在ResolveFileProvider方法中，并体现在如下的测试程序中。&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;35&quot;&gt;
&lt;pre&gt;
&lt;span&gt;class&lt;/span&gt;&lt;span&gt; Program
{
    &lt;/span&gt;&lt;span&gt;static&lt;/span&gt; &lt;span&gt;void&lt;/span&gt;&lt;span&gt; Main()
    {
        &lt;/span&gt;&lt;span&gt;var&lt;/span&gt; source = &lt;span&gt;new&lt;/span&gt;&lt;span&gt; FakeConfigurationSource
        {
            Path &lt;/span&gt;= &lt;span&gt;@&quot;&lt;/span&gt;&lt;span&gt;C:\App\appsettings.json&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;
        };
        Debug.Assert(source.FileProvider &lt;/span&gt;== &lt;span&gt;null&lt;/span&gt;&lt;span&gt;);

        source.ResolveFileProvider();
        &lt;/span&gt;&lt;span&gt;var&lt;/span&gt; fileProvider =&lt;span&gt; (PhysicalFileProvider)source.FileProvider;
        Debug.Assert(fileProvider.Root &lt;/span&gt;== &lt;span&gt;@&quot;&lt;/span&gt;&lt;span&gt;C:\App\&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;);
        Debug.Assert(source.Path &lt;/span&gt;== &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;appsettings.json&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;);
    }

    &lt;/span&gt;&lt;span&gt;private&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;&lt;span&gt; FakeConfigurationSource : FileConfigurationSource
    {
        &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;override&lt;/span&gt; IConfigurationProvider Build(IConfigurationBuilder builder) =&amp;gt; &lt;span&gt;throw&lt;/span&gt; &lt;span&gt;new&lt;/span&gt;&lt;span&gt; NotImplementedException();
    }
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;&lt;span&gt;EnsureDefaults方法&lt;/span&gt;&lt;/h2&gt;
&lt;p&gt;除了ResolveFileProvider方法，FileConfigurationSource还定义了另一个名为EnsureDefaults的方法，该方法会确保FileConfigurationSource总是具有一个用于加载配置文件的IFileProvider对象。具体来说，&lt;a&gt;该方法&lt;/a&gt;最终会调用IConfigurationBuilder接口具有如下定义的扩展方法GetFileProvider来获取默认的IFileProvider对象。&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;36&quot;&gt;
&lt;pre&gt;
&lt;span&gt;public&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;&lt;span&gt; FileConfigurationExtensions
{    
    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; IFileProvider GetFileProvider(&lt;span&gt;this&lt;/span&gt;&lt;span&gt; IConfigurationBuilder builder)
    {
        &lt;/span&gt;&lt;span&gt;if&lt;/span&gt; (builder.Properties.TryGetValue(&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;FileProvider&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;, &lt;span&gt;out&lt;/span&gt; &lt;span&gt;object&lt;/span&gt;&lt;span&gt; provider))
        {
            &lt;/span&gt;&lt;span&gt;return&lt;/span&gt; builder.Properties[&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;FileProvider&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;] &lt;span&gt;as&lt;/span&gt;&lt;span&gt; IFileProvider;
        }
        &lt;/span&gt;&lt;span&gt;return&lt;/span&gt; &lt;span&gt;new&lt;/span&gt; PhysicalFileProvider(AppContext.BaseDirectory ?? &lt;span&gt;string&lt;/span&gt;&lt;span&gt;.Empty);
    }
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;从上面给出的代码片段可以看出，&lt;a&gt;这个扩展方法&lt;/a&gt; 实际上是将IConfigurationBuilder对象的Properties属性表示的字典作为了存放IFileProvider对象的容器（对应的Key为“FileProvider”）。如果这个容器中存在一个IFileProvider对象，那么它将作为方法的返回值。反之，该方法会根据当前应用的基础目录（默认为当前应用程序域的基础目录，也就是当前执行的.exe文件所在的目录）作为根目录创建一个PhysicalFileProvider对象。&lt;/p&gt;
&lt;h2&gt;&lt;span&gt;SetFileProvider和SetBasePath方法&lt;/span&gt;&lt;/h2&gt;
&lt;p&gt;既然默认情况下EnsureDefaults方法会从IConfigurationBuilder对象的属性字典中提取IFileProvider对象，那么我们可以在这个属性字典中存放一个默认的IFileProvider对象供所有注册在它上面的FileConfigurationSource对象共享。实际上IConfigurationBuilder接口提供了如下两个SetFileProvider和SetBasePath扩展方法实现了这个功能。&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;37&quot;&gt;
&lt;pre&gt;
&lt;span&gt;public&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;&lt;span&gt; FileConfigurationExtensions
{    
    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; IConfigurationBuilder SetFileProvider( &lt;span&gt;this&lt;/span&gt;&lt;span&gt; IConfigurationBuilder builder, IFileProvider fileProvider)
    {
        builder.Properties[&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;FileProvider&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;] =&lt;span&gt; fileProvider;
        &lt;/span&gt;&lt;span&gt;return&lt;/span&gt;&lt;span&gt; builder;
    }

    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; IConfigurationBuilder SetBasePath( &lt;span&gt;this&lt;/span&gt; IConfigurationBuilder builder, &lt;span&gt;string&lt;/span&gt;&lt;span&gt; basePath)
        &lt;/span&gt;=&amp;gt;builder.SetFileProvider(&lt;span&gt;new&lt;/span&gt;&lt;span&gt; PhysicalFileProvider(basePath));
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;&lt;span&gt;可缺省配置文件&lt;/span&gt;&lt;/h2&gt;
&lt;p&gt;FileConfigurationSource的Optional表示当前配置源是否可以缺省。如果该属性被设置成False，即使指定的配置文件不存在也不会抛出异常。可缺省的配置文件在支持多环境的场景中具有广泛的应用。正如前面实例演示的一样，我们可以按照如下的方式加载两个配置文件，基础配置文件&lt;span&gt;appsettings.json&lt;/span&gt;一般包含相对全面的配置，针对某个环境的差异化配置则定义在&lt;span&gt;appsettings.{environment}.json&lt;/span&gt;文件中。前者是必需的，后者则是可以缺省的，这保证了应用程序在缺少基于当前环境的差异化配置文件的情况下依然可以使用定义在基础配置文件中的默认配置。&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;36&quot;&gt;
&lt;pre&gt;
&lt;span&gt;var&lt;/span&gt; configuration = &lt;span&gt;new&lt;/span&gt;&lt;span&gt; ConfigurationBuilder()
    .SetBasePath(Directory.GetCurrentDirectory())
    .AddJsonFile(path: &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;appsettings.json&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;, optional: &lt;span&gt;false&lt;/span&gt;&lt;span&gt;)
    .AddJsonFile(path: $&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;appsettings.{environment}.json&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;, optional: &lt;span&gt;true&lt;/span&gt;&lt;span&gt;)
    .Build();&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;&lt;span&gt;配置数据的实时同步&lt;/span&gt;&lt;/h2&gt;
&lt;p&gt;FileConfigurationSource借助IFileProvider对象提供的文件系统监控功能实现了配置文件在更新后的自动实时加载功能，这个特性通过ReloadOnChange属性来开启或者关闭。默认情况下这个特性是关闭的，我们需要通过将这个属性设置为True来显式地开启该特性。如果开启了配置文件的重新加载功能，一旦配置文件发生变化，IFileProvider对象会在第一时间将通知发送给对应的FileConfigurationProvider对象，后者会调用Load方法重新加载配置文件。考虑到有可能针对配置文件的写入此时尚未结束，FileConfigurationSource采用了 “延时加载” 的方式来解决这个问题，具体的延时通过ReloadDelay属性来控制。该属性的单位是毫秒，默认设置的延时为250毫秒。&lt;/p&gt;
&lt;h2&gt;&lt;span&gt;异常处理&lt;/span&gt;&lt;/h2&gt;
&lt;p&gt;考虑到针对配置文件的加载不可能百分之百成功，所以FileConfigurationSource提供了相应的异常处理机制。具体来说，我们可以通过FileConfigurationSource对象的OnLoadException属性注册一个Action&amp;lt;FileLoadExceptionContext&amp;gt;类型的委托作为异常处理器。作为参数的FileLoadExceptionContext 对象代表FileConfigurationProvider在加载配置文件出错的情况下为异常处理器提供的执行上下文。&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;33&quot;&gt;
&lt;pre&gt;
&lt;span&gt;public&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;&lt;span&gt; FileLoadExceptionContext
{
    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; Exception Exception { &lt;span&gt;get&lt;/span&gt;; &lt;span&gt;set&lt;/span&gt;&lt;span&gt;; }
    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; FileConfigurationProvider Provider { &lt;span&gt;get&lt;/span&gt;; &lt;span&gt;set&lt;/span&gt;&lt;span&gt;; }
    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;bool&lt;/span&gt; Ignore { &lt;span&gt;get&lt;/span&gt;; &lt;span&gt;set&lt;/span&gt;&lt;span&gt;; }
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;如上面的代码片段所示，我们可以从FileLoadExceptionContext上下文中获取抛出的异常和当前FileConfigurationProvider对象。如果异常处理结束之后上下文对象的Ignore属性被设置为True，FileConfigurationProvider对象会认为目前的异常（可能是原来抛出的异常，也可能是异常处理器设置的异常）是可以被忽略的，此时程序会继续执行，否则异常还是会抛出来。顺便强调一下，最终抛出来的是原来的异常，所以我们不可以通过修改上下文的Exception属性来达到抛出另一个异常的目的。&lt;/p&gt;
&lt;p&gt;就像我们可以为注册到IConfigurationBuilder对象上的所有FileConfigurationSource注册一个共享的IFileProvider对象一样，我们也可以调用IConfigurationBuilder接口的SetFileLoadExceptionHandler扩展方法注册一个共享的异常处理器，该方法依然是利用IConfiguration&lt;br/&gt;Builder对象的属性字典来存放这个作为异常处理器的委托对象。注册的这个异常处理器通过对应的扩展方法GetFileLoadExceptionHandler来获取。&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;37&quot;&gt;
&lt;pre&gt;
&lt;span&gt;public&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;&lt;span&gt; FileConfigurationExtensions
{
    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; IConfigurationBuilder SetFileLoadExceptionHandler(&lt;span&gt;this&lt;/span&gt; IConfigurationBuilder builder, Action&amp;lt;FileLoadExceptionContext&amp;gt;&lt;span&gt; handler)
    {
        builder.Properties[&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;FileLoadExceptionHandler&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;] =&lt;span&gt; handler;
        &lt;/span&gt;&lt;span&gt;return&lt;/span&gt;&lt;span&gt; builder;
    }

    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; Action&amp;lt;FileLoadExceptionContext&amp;gt; GetFileLoadExceptionHandler(&lt;span&gt;this&lt;/span&gt;&lt;span&gt; IConfigurationBuilder builder)
        &lt;/span&gt;=&amp;gt; builder.Properties.TryGetValue(&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;FileLoadExceptionHandler&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;, &lt;span&gt;out&lt;/span&gt; &lt;span&gt;object&lt;/span&gt; handler) ? handler &lt;span&gt;as&lt;/span&gt; Action&amp;lt;FileLoadExceptionContext&amp;gt; : &lt;span&gt;null&lt;/span&gt;&lt;span&gt;;
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;前面我们提到FileConfigurationSource的EnsureDefaults方法，这个方法除了在IFileProvider对象没有被初始化的情况下调用IConfigurationBuilder的GetFileProvider扩展方法提供一个默认的IFileProvider对象之外，它还会在异常处理器没有初始化的情况下调用上面这个GetFileLoad&lt;br/&gt;ExceptionHandler扩展方法提供一个默认的异常处理器。&lt;/p&gt;

&lt;p&gt;对于配置系统默认提供的针对三种文件格式化的FileConfigurationSource类型来说，它们提供的IConfigurationProvider实现都派生于如下这个抽象基类FileConfigurationProvider。对于我们自定义的FileConfigurationSource，但我们也倾向于将这个抽象类作为对应IConfiguration&lt;br/&gt;Provider实现类型的基类。&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;34&quot;&gt;
&lt;pre&gt;
&lt;span&gt;public&lt;/span&gt; &lt;span&gt;abstract&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;&lt;span&gt; FileConfigurationProvider : ConfigurationProvider
{
    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; FileConfigurationSource Source { &lt;span&gt;get&lt;/span&gt;&lt;span&gt;; }
    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt;&lt;span&gt; FileConfigurationProvider(FileConfigurationSource source);

    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;override&lt;/span&gt; &lt;span&gt;void&lt;/span&gt;&lt;span&gt; Load();    
    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;abstract&lt;/span&gt; &lt;span&gt;void&lt;/span&gt;&lt;span&gt; Load(Stream stream);    
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;当我们创建一个FileConfigurationProvider对象的时候需要提供对应的FileConfigurationSource对象，它会赋值给Source属性。如果指定的FileConfigurationSource对象开启了配置文件更新监控和自动加载功能（其属性OnLoadException返回True），FileConfigurationProvider对象会利用FileConfigurationSource对象提供的IFileProvider对象对配置文件实施监控，并通过注册回调的方式在配置文件更新的时候调用Load方法重新加载配置。&lt;/p&gt;
&lt;p&gt;由于FileConfigurationSource对象提供了IFileProvider对象，所以FileConfigurationProvider对象可以调用其CreateReadStream方法获取读取配置文件内容的流对象，因此我们可以利用这个Stream对象来完成配置的加载。根据基于Stream加载配置的功能体现在抽象方法Load上，所以FileConfigurationProvider对象的派生类都需要重写这个方法。&lt;/p&gt;

&lt;p&gt;&lt;a&gt;JsonConfigurationSource&lt;/a&gt;代表针对通过JSON文件的配置源，该类型定义在NuGet包“Microsoft.Extensions.Configuration.Json”中。从如下给出的定义可以看出，JsonConfigurationSource重写的Build方法在提供对应的JsonConfigurationProvider对象之前会调用EnsureDefaults方法，这个方法确保用于读取配置文件的IFileProvider对象和处理配置文件加载异常的处理器被初始化。JsonConfigurationProvider&lt;strong&gt;对象&lt;/strong&gt;派生于抽象类FileConfigurationProvider，它利用重写的Load方法读取配置文件的内容并将其转换成配置字典。&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;35&quot;&gt;
&lt;pre&gt;
&lt;span&gt;public&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;&lt;span&gt; JsonConfigurationSource : FileConfigurationSource
{
    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;override&lt;/span&gt;&lt;span&gt; IConfigurationProvider Build(IConfigurationBuilder builder)
    {
        EnsureDefaults(builder);
        &lt;/span&gt;&lt;span&gt;return&lt;/span&gt; &lt;span&gt;new&lt;/span&gt; JsonConfigurationProvider(&lt;span&gt;this&lt;/span&gt;&lt;span&gt;);
    }
}

&lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;&lt;span&gt; JsonConfigurationProvider : FileConfigurationProvider
{
    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt;&lt;span&gt; JsonConfigurationProvider(JsonConfigurationSource source);
    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;override&lt;/span&gt; &lt;span&gt;void&lt;/span&gt;&lt;span&gt; Load(Stream stream);
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;IConfigurationBuilder接口具有如下几个名为AddJsonFile扩展方法来注册JsonConfigurationSource。如果调用第一个AddJsonFile方法重载，我们可以利用指定的Action&amp;lt;JsonConfigurationSource&amp;gt;对象对创建的JsonConfigurationSource进行初始化。至于其他AddJsonFile方法重载，实际上就是通过相应的参数初始化JsonConfigurationSource对象的Path、Optional和ReloadOnChange属性罢了。&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;46&quot;&gt;
&lt;pre&gt;
&lt;span&gt;public&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;&lt;span&gt; JsonConfigurationExtensions
{
    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; IConfigurationBuilder AddJsonFile(&lt;span&gt;this&lt;/span&gt; IConfigurationBuilder builder, Action&amp;lt;JsonConfigurationSource&amp;gt;&lt;span&gt; configureSource);
    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; IConfigurationBuilder AddJsonFile(&lt;span&gt;this&lt;/span&gt; IConfigurationBuilder builder, &lt;span&gt;string&lt;/span&gt;&lt;span&gt; path);
    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; IConfigurationBuilder AddJsonFile(&lt;span&gt;this&lt;/span&gt; IConfigurationBuilder builder, &lt;span&gt;string&lt;/span&gt; path, &lt;span&gt;bool&lt;/span&gt;&lt;span&gt; optional);
    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; IConfigurationBuilder AddJsonFile(&lt;span&gt;this&lt;/span&gt; IConfigurationBuilder builder, &lt;span&gt;string&lt;/span&gt; path, &lt;span&gt;bool&lt;/span&gt; optional, &lt;span&gt;bool&lt;/span&gt;&lt;span&gt; reloadOnChange);
    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; IConfigurationBuilder AddJsonFile(&lt;span&gt;this&lt;/span&gt; IConfigurationBuilder builder, IFileProvider provider, &lt;span&gt;string&lt;/span&gt; path, &lt;span&gt;bool&lt;/span&gt; optional, &lt;span&gt;bool&lt;/span&gt;&lt;span&gt; reloadOnChange);
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;当使用JSON文件来定义配置的时候，我们会发现不论对于何种数据结构（复杂对象、集合、数组和字典），我们都能通过JSON格式以一种简单而自然的方式来定义它们。同样以前面定义的Profile类型为例，我们可以利用如下所示的三个JSON文件分别定义一个完整的Profile对象、一个Profile对象的集合以及一个Key和Value类型分别为字符串和Profile的字典。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Profile&lt;/strong&gt;&lt;strong&gt;对象：&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;36&quot;&gt;
&lt;pre&gt;
&lt;span&gt;{
    &lt;/span&gt;&quot;profile&quot;&lt;span&gt;: {
        &lt;/span&gt;&quot;gender&quot; : &quot;Male&quot;&lt;span&gt;,
        &lt;/span&gt;&quot;age&quot; : &quot;18&quot;&lt;span&gt;,
        &lt;/span&gt;&quot;contactInfo&quot;&lt;span&gt;    : {
            &lt;/span&gt;&quot;email&quot; : &quot;foobar@outlook.com&quot;&lt;span&gt;,
            &lt;/span&gt;&quot;phoneNo&quot;: &quot;123456789&quot;&lt;span&gt;
        }
    }
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Profile&lt;/strong&gt;&lt;strong&gt;集合或者数组:&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;46&quot;&gt;
&lt;pre&gt;
&lt;span&gt;{
  &lt;/span&gt;&quot;profiles&quot;&lt;span&gt;: [
    {
      &lt;/span&gt;&quot;gender&quot;: &quot;Male&quot;&lt;span&gt;,
      &lt;/span&gt;&quot;age&quot;: &quot;18&quot;&lt;span&gt;,
      &lt;/span&gt;&quot;contactInfo&quot;&lt;span&gt;: {
        &lt;/span&gt;&quot;email&quot;: &quot;foo@outlook.com&quot;&lt;span&gt;,
        &lt;/span&gt;&quot;phoneNo&quot;: &quot;123&quot;&lt;span&gt;
      }
    },
    {
      &lt;/span&gt;&quot;gender&quot;: &quot;Male&quot;&lt;span&gt;,
      &lt;/span&gt;&quot;age&quot;: &quot;25&quot;&lt;span&gt;,
      &lt;/span&gt;&quot;contactInfo&quot;&lt;span&gt;: {
        &lt;/span&gt;&quot;email&quot;: &quot;bar@outlook.com&quot;&lt;span&gt;,
        &lt;/span&gt;&quot;phoneNo&quot;: &quot;456&quot;&lt;span&gt;
      }
    },
    {
      &lt;/span&gt;&quot;gender&quot;: &quot;Female&quot;&lt;span&gt;,
      &lt;/span&gt;&quot;age&quot;: &quot;40&quot;&lt;span&gt;,
      &lt;/span&gt;&quot;contactInfo&quot;&lt;span&gt;: {
        &lt;/span&gt;&quot;email&quot;: &quot;baz@outlook.com&quot;&lt;span&gt;,
        &lt;/span&gt;&quot;phoneNo&quot;: &quot;789&quot;&lt;span&gt;
      }
    }
  ]
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Profile&lt;/strong&gt;&lt;strong&gt;字典(Dictionary&amp;lt;string, Profile&amp;gt;):&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;46&quot;&gt;
&lt;pre&gt;
&lt;span&gt;{
  &lt;/span&gt;&quot;profiles&quot;&lt;span&gt;: {
    &lt;/span&gt;&quot;foo&quot;&lt;span&gt;: {
      &lt;/span&gt;&quot;gender&quot;: &quot;Male&quot;&lt;span&gt;,
      &lt;/span&gt;&quot;age&quot;: &quot;18&quot;&lt;span&gt;,
      &lt;/span&gt;&quot;contactInfo&quot;&lt;span&gt;: {
        &lt;/span&gt;&quot;email&quot;: &quot;foo@outlook.com&quot;&lt;span&gt;,
        &lt;/span&gt;&quot;phoneNo&quot;: &quot;123&quot;&lt;span&gt;
      }
    },
    &lt;/span&gt;&quot;bar&quot;&lt;span&gt;: {
      &lt;/span&gt;&quot;gender&quot;: &quot;Male&quot;&lt;span&gt;,
      &lt;/span&gt;&quot;age&quot;: &quot;25&quot;&lt;span&gt;,
      &lt;/span&gt;&quot;contactInfo&quot;&lt;span&gt;: {
        &lt;/span&gt;&quot;email&quot;: &quot;bar@outlook.com&quot;&lt;span&gt;,
        &lt;/span&gt;&quot;phoneNo&quot;: &quot;456&quot;&lt;span&gt;
      }
    },
    &lt;/span&gt;&quot;baz&quot;&lt;span&gt;: {
      &lt;/span&gt;&quot;gender&quot;: &quot;Female&quot;&lt;span&gt;,
      &lt;/span&gt;&quot;age&quot;: &quot;40&quot;&lt;span&gt;,
      &lt;/span&gt;&quot;contactInfo&quot;&lt;span&gt;: {
        &lt;/span&gt;&quot;email&quot;: &quot;baz@outlook.com&quot;&lt;span&gt;,
        &lt;/span&gt;&quot;phoneNo&quot;: &quot;789&quot;&lt;span&gt;
      }
    }
  }
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;XML也是一种常用的配置定义形式，它对数据的表达能力甚至强于JSON，几乎所有类型的数据结构都可以通过XML表示出来。当我们通过一个XML元素表示一个复杂对象的时候，对象的数据成员定义成当前XML元素的子元素。如果数据成员是一个简单数据类型，我们还可以选择将其定义成当前XML元素的属性（Attribute）。针对一个Profile对象，我们可以采用如下两种不同的形式来定义。&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;33&quot;&gt;
&lt;pre&gt;
&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;Profile&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
    &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;Gender&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;Male&lt;span&gt;&amp;lt;/&lt;/span&gt;&lt;span&gt;Gender&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
    &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;Age&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;18&lt;span&gt;&amp;lt;/&lt;/span&gt;&lt;span&gt;Age&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
    &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;ContactInfo&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
        &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;EmailAddress&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;foobar@outlook.com&lt;span&gt;&amp;lt;/&lt;/span&gt;&lt;span&gt;EmailAddress&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
        &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;PhoneNo&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;123456789&lt;span&gt;&amp;lt;/&lt;/span&gt;&lt;span&gt;PhoneNo&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
   &lt;span&gt;&amp;lt;/&lt;/span&gt;&lt;span&gt;ContactInfo&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
&lt;span&gt;&amp;lt;/&lt;/span&gt;&lt;span&gt;Profile&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;或者&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;33&quot;&gt;
&lt;pre&gt;
&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;Profile &lt;/span&gt;&lt;span&gt;Gender&lt;/span&gt;&lt;span&gt;=&quot;Male&quot;&lt;/span&gt;&lt;span&gt; Age&lt;/span&gt;&lt;span&gt;=&quot;18&quot;&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
  &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;ContactInfo &lt;/span&gt;&lt;span&gt;EmailAddress &lt;/span&gt;&lt;span&gt;=&quot;foobar@outlook.com&quot;&lt;/span&gt;&lt;span&gt; PhoneNo&lt;/span&gt;&lt;span&gt;=&quot;123456789&quot;&lt;/span&gt;&lt;span&gt;/&amp;gt;&lt;/span&gt;
&lt;span&gt;&amp;lt;/&lt;/span&gt;&lt;span&gt;Profile&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;虽然XML对数据结构的表达能力总体要强于JSON，但是作为配置模型的数据来源却有自己的局限性，比如它们对集合的表现形式有点不尽如人意。举个简单的例子，对于一个元素类型为Profile的集合，我们可以采用具有如下结构的XML来表现。&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;35&quot;&gt;
&lt;pre&gt;
&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;Profiles&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
    &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;Profile &lt;/span&gt;&lt;span&gt;Gender&lt;/span&gt;&lt;span&gt;=&quot;Male&quot;&lt;/span&gt;&lt;span&gt; Age&lt;/span&gt;&lt;span&gt;=&quot;18&quot;&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
        &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;ContactInfo &lt;/span&gt;&lt;span&gt;EmailAddress &lt;/span&gt;&lt;span&gt;=&quot;foo@outlook.com&quot;&lt;/span&gt;&lt;span&gt; PhoneNo&lt;/span&gt;&lt;span&gt;=&quot;123&quot;&lt;/span&gt;&lt;span&gt;/&amp;gt;&lt;/span&gt;
    &lt;span&gt;&amp;lt;/&lt;/span&gt;&lt;span&gt;Profile&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
    &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;Profile &lt;/span&gt;&lt;span&gt;Gender&lt;/span&gt;&lt;span&gt;=&quot;Male&quot;&lt;/span&gt;&lt;span&gt; Age&lt;/span&gt;&lt;span&gt;=&quot;25&quot;&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
        &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;ContactInfo &lt;/span&gt;&lt;span&gt;EmailAddress &lt;/span&gt;&lt;span&gt;=&quot;bar@outlook.com&quot;&lt;/span&gt;&lt;span&gt; PhoneNo&lt;/span&gt;&lt;span&gt;=&quot;456&quot;&lt;/span&gt;&lt;span&gt;/&amp;gt;&lt;/span&gt;
    &lt;span&gt;&amp;lt;/&lt;/span&gt;&lt;span&gt;Profile&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
    &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;Profile &lt;/span&gt;&lt;span&gt;Gender&lt;/span&gt;&lt;span&gt;=&quot;Male&quot;&lt;/span&gt;&lt;span&gt; Age&lt;/span&gt;&lt;span&gt;=&quot;36&quot;&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
        &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;ContactInfo &lt;/span&gt;&lt;span&gt;EmailAddress &lt;/span&gt;&lt;span&gt;=&quot;baz@outlook.com&quot;&lt;/span&gt;&lt;span&gt; PhoneNo&lt;/span&gt;&lt;span&gt;=&quot;789&quot;&lt;/span&gt;&lt;span&gt;/&amp;gt;&lt;/span&gt;
    &lt;span&gt;&amp;lt;/&lt;/span&gt;&lt;span&gt;Profile&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
&lt;span&gt;&amp;lt;/&lt;/span&gt;&lt;span&gt;Profiles&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;但是这段XML却不能正确地转换成配置字典，原因很简单，因为字典的&lt;span&gt;Key必须是唯一&lt;/span&gt;的，这必然要求最终构成配置树的每个节点必须具有不同的路径。上面这段XML很明显不满足这个基本的要求，因为表示一个Profile对象的三个XML元素（&amp;lt;Profile&amp;gt;...&amp;lt;/Profile&amp;gt;）是“同质”的，对于由它们表示的三个Profile对象来说，分别表示性别、年龄、电子邮箱地址和电话号码的四个叶子节点的路径是完全一样的，所以根本无法作为配置字典的Key。通过前面针对配置绑定的介绍我们知道，如果需要通过配置字典来表示一个Profile对象的集合，我们需要按照如下的方式为每个集合元素加上相应的索引（“foo”、“bar”和“baz”）。&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;34&quot;&gt;
&lt;pre&gt;
&lt;span&gt;foo:Gender
foo:Age
foo:ContactInfo:EmailAddress
foo:ContactInfo:PhoneNo

bar:Gender
bar:Age
bar:ContactInfo:EmailAddress
bar:ContactInfo:PhoneNo

baz:Gender
baz:Age
baz:ContactInfo:EmailAddress
baz:ContactInfo:PhoneNo&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;按照这样的结构，如果我们需要以XML的方式来表示一个Profile对象的集合，就不得不采用如下的结构。但是这样的定义方式从语义的角度来讲是不合理的，因为同一个集合的所有元素就应该是“同质”的，同质的XML元素采用不同的名称有点说不过去。根据配置绑定的规则，这样的结构同样可以表示一个由三个元素组成的Dictionary&amp;lt;string, Profile&amp;gt;对象，Key分别是“Foo”、“Bar”和“Baz”。如果用这样的XML来表示一个字典对象，语义上就完全没有问题了。&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;35&quot;&gt;
&lt;pre&gt;
&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;Profiles&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
  &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;Foo &lt;/span&gt;&lt;span&gt;Gender&lt;/span&gt;&lt;span&gt;=&quot;Male&quot;&lt;/span&gt;&lt;span&gt; Age&lt;/span&gt;&lt;span&gt;=&quot;18&quot;&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
    &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;ContactInfo &lt;/span&gt;&lt;span&gt;EmailAddress &lt;/span&gt;&lt;span&gt;=&quot;foobar@outlook.com&quot;&lt;/span&gt;&lt;span&gt; PhoneNo&lt;/span&gt;&lt;span&gt;=&quot;123&quot;&lt;/span&gt;&lt;span&gt;/&amp;gt;&lt;/span&gt;
  &lt;span&gt;&amp;lt;/&lt;/span&gt;&lt;span&gt;Foo&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
  &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;Bar &lt;/span&gt;&lt;span&gt;Gender&lt;/span&gt;&lt;span&gt;=&quot;Male&quot;&lt;/span&gt;&lt;span&gt; Age&lt;/span&gt;&lt;span&gt;=&quot;25&quot;&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
    &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;ContactInfo &lt;/span&gt;&lt;span&gt;EmailAddress &lt;/span&gt;&lt;span&gt;=&quot;foobar@outlook.com&quot;&lt;/span&gt;&lt;span&gt; PhoneNo&lt;/span&gt;&lt;span&gt;=&quot;123&quot;&lt;/span&gt;&lt;span&gt;/&amp;gt;&lt;/span&gt;
  &lt;span&gt;&amp;lt;/&lt;/span&gt;&lt;span&gt;Bar&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
  &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;Baz &lt;/span&gt;&lt;span&gt;Gender&lt;/span&gt;&lt;span&gt;=&quot;Male&quot;&lt;/span&gt;&lt;span&gt; Age&lt;/span&gt;&lt;span&gt;=&quot;18&quot;&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
    &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;ContactInfo &lt;/span&gt;&lt;span&gt;EmailAddress &lt;/span&gt;&lt;span&gt;=&quot;baz@outlook.com&quot;&lt;/span&gt;&lt;span&gt; PhoneNo&lt;/span&gt;&lt;span&gt;=&quot;789&quot;&lt;/span&gt;&lt;span&gt;/&amp;gt;&lt;/span&gt;
  &lt;span&gt;&amp;lt;/&lt;/span&gt;&lt;span&gt;Baz&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
&lt;span&gt;&amp;lt;/&lt;/span&gt;&lt;span&gt;Profiles&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;针对XML文件的配置源类型为XmlConfigurationSource，该类型定义在“Microsoft.Extensions.Configuration.Xml”这个NuGet包中。如下面的代码片段所示，XmlConfigurationSource通过重写的Build方法创建出对应的XmlConfigurationProvider对象。作为抽象类型FileConfigurationProvider的继承者，XmlConfigurationProvider通过重写的Load方法完成了针对XML文件的读取和配置字典的初始化。&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;35&quot;&gt;
&lt;pre&gt;
&lt;span&gt;public&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;&lt;span&gt; XmlConfigurationSource : FileConfigurationSource
{
    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;override&lt;/span&gt;&lt;span&gt; IConfigurationProvider Build(IConfigurationBuilder builder)
    {
        EnsureDefaults(builder);
        &lt;/span&gt;&lt;span&gt;return&lt;/span&gt; &lt;span&gt;new&lt;/span&gt; XmlConfigurationProvider(&lt;span&gt;this&lt;/span&gt;&lt;span&gt;);
    }
}

&lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;&lt;span&gt; XmlConfigurationProvider : FileConfigurationProvider
{   
    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt;&lt;span&gt; XmlConfigurationProvider(XmlConfigurationSource source);   
    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;override&lt;/span&gt; &lt;span&gt;void&lt;/span&gt;&lt;span&gt; Load(Stream stream);
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;JsonConfigurationSource的注册可以通过调用针对IConfigurationBuilder&lt;strong&gt;对象&lt;/strong&gt;的扩展方法AddJsonFile来完成。与之类似，IConfigurationBuilder接口同样具有如下一系列名为AddXmlFile的扩展方法，这些方法会帮助我们注册根据指定XML文件创建的XmlConfigurationSource对象。&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;45&quot;&gt;
&lt;pre&gt;
&lt;span&gt;public&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;&lt;span&gt; XmlConfigurationExtensions
{
    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; IConfigurationBuilder AddXmlFile(&lt;span&gt;this&lt;/span&gt; IConfigurationBuilder builder, &lt;span&gt;string&lt;/span&gt;&lt;span&gt; path);
    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; IConfigurationBuilder AddXmlFile(&lt;span&gt;this&lt;/span&gt; IConfigurationBuilder builder, &lt;span&gt;string&lt;/span&gt; path, &lt;span&gt;bool&lt;/span&gt;&lt;span&gt; optional);
    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; IConfigurationBuilder AddXmlFile(&lt;span&gt;this&lt;/span&gt; IConfigurationBuilder builder, &lt;span&gt;string&lt;/span&gt; path, &lt;span&gt;bool&lt;/span&gt; optional, &lt;span&gt;bool&lt;/span&gt;&lt;span&gt; reloadOnChange);
    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; IConfigurationBuilder AddXmlFile(&lt;span&gt;this&lt;/span&gt; IConfigurationBuilder builder, IFileProvider provider, &lt;span&gt;string&lt;/span&gt; path, &lt;span&gt;bool&lt;/span&gt; optional, &lt;span&gt;bool&lt;/span&gt;&lt;span&gt; reloadOnChange);
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;“INI”是“Initialization”的缩写，INI文件又被称为初始化文件，它是Windows系统普遍使用的配置文件，同时也被一些Linux和Unix系统所支持。INI文件直接以键值对的形式定义配置项，如下所示的代码片段体现了INI文件的基本格式。总的来说，INI文件以单纯的“{Key}={Value}”的形式定义配置项，{Value}可以定义在可选的双引号中（如果值的前后包括空白字符，必须使用双引号，否则会被忽略）。&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;32&quot;&gt;
&lt;pre&gt;
&lt;span&gt;[Section]
key1&lt;/span&gt;=&lt;span&gt;value1
key2 &lt;/span&gt;= &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt; value2 &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;
; comment
# comment
&lt;/span&gt;/ comment
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;除了以“{Key}={Value}”的形式定义的原子配置项外，我们还可以采用“[{SectionName}]”的形式定义配置节对它们进行分组。中括号（“[]”）作为下一个的配置节开始的标志和上一个配置节结束的标志，所以采用INI文件定义的配置节并不存在层次化的结构，即没有“子配置节”的概念。除此之外，我们可以在INI中定义相应的注释，注释行前置的字符可以采用“;”、“#”或者“/”。&lt;/p&gt;
&lt;p&gt;由于INI文件自身就体现为一个数据字典，所以我们可以采用“路径化”的Key来定义最终绑定为复杂对象、集合或者字典的配置数据。如果采用INI文件来定义一个Profile对象的基本信息，我们就可以采用如下的定义形式。&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;33&quot;&gt;
&lt;pre&gt;
Gender = &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;Male&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;
Age  &lt;/span&gt;= &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;18&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;
ContactInfo:EmailAddress &lt;/span&gt;= &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;foobar@outlook.com&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;
ContactInfo:PhoneNo &lt;/span&gt;= &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;123456789&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;由于Profile的配置信息具有两个层次（Profile&lt;a&gt;&amp;gt;&lt;/a&gt;ContactInfo），我们可以按照如下的形式将EmailAddress和PhoneNo定义在配置节“ContactInfo”中，这个INI文件在语义表达上和上面是完全等效的。&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;32&quot;&gt;
&lt;pre&gt;
Gender = &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;Male&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;
Age  &lt;/span&gt;= &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;18&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;

[ContactInfo]
EmailAddress &lt;/span&gt;= &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;foobar@outlook.com&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;
PhoneNo  &lt;/span&gt;= &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;123456789&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;针对INI文件类型的配置源类型通过如下所示的IniConfigurationSource来表示，该类型定义在“Microsoft.Extensions.Configuration.Ini”这个NuGet包中。IniConfigurationSource重写的Build方法创建的是一个IniConfigurationProvider对象。作为抽象类FileConfigurationProvider的继承者，IniConfigurationProvider利用重写的Load方法完成INI文件内容的读取和配置字典的初始化。&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;35&quot;&gt;
&lt;pre&gt;
&lt;span&gt;public&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;&lt;span&gt; IniConfigurationSource : FileConfigurationSource
{
    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;override&lt;/span&gt;&lt;span&gt; IConfigurationProvider Build(IConfigurationBuilder builder)
    {
        EnsureDefaults(builder);
        &lt;/span&gt;&lt;span&gt;return&lt;/span&gt; &lt;span&gt;new&lt;/span&gt; IniConfigurationProvider(&lt;span&gt;this&lt;/span&gt;&lt;span&gt;);
    }
 }

&lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;&lt;span&gt; IniConfigurationProvider : FileConfigurationProvider
{
    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt;&lt;span&gt; IniConfigurationProvider(IniConfigurationSource source);
    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;override&lt;/span&gt; &lt;span&gt;void&lt;/span&gt;&lt;span&gt; Load(Stream stream);
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;既然JsonConfigurationSource和XmlConfigurationSource的注册可以通过调用IConfigurationBuilder接口的扩展方法AddJsonFile和AddXmlFile来完成，“Microsoft.Extensions. Configuration.Ini”这个NuGet包会也会为IniConfigurationSource定义如下所示的AddIniFile扩展方法。&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;45&quot;&gt;
&lt;pre&gt;
&lt;span&gt;public&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;&lt;span&gt; IniConfigurationExtensions
{
    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; IConfigurationBuilder AddIniFile( &lt;span&gt;this&lt;/span&gt; IConfigurationBuilder builder, &lt;span&gt;string&lt;/span&gt;&lt;span&gt; path);
    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; IConfigurationBuilder AddIniFile( &lt;span&gt;this&lt;/span&gt; IConfigurationBuilder builder, &lt;span&gt;string&lt;/span&gt; path, &lt;span&gt;bool&lt;/span&gt;&lt;span&gt; optional);
    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; IConfigurationBuilder AddIniFile( &lt;span&gt;this&lt;/span&gt; IConfigurationBuilder builder, &lt;span&gt;string&lt;/span&gt; path, &lt;span&gt;bool&lt;/span&gt; optional,  &lt;span&gt;bool&lt;/span&gt;&lt;span&gt; reloadOnChange);
    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; IConfigurationBuilder AddIniFile( &lt;span&gt;this&lt;/span&gt; IConfigurationBuilder builder, IFileProvider provider, &lt;span&gt;string&lt;/span&gt; path,  &lt;span&gt;bool&lt;/span&gt; optional, &lt;span&gt;bool&lt;/span&gt;&lt;span&gt; reloadOnChange);
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;a href=&quot;https://www.cnblogs.com/artech/p/inside-asp-net-core-05-01.html&quot;&gt;[ASP.NET Core 3框架揭秘] 配置[1]：读取配置数据[上篇]&lt;/a&gt;&lt;br/&gt;&lt;a href=&quot;https://www.cnblogs.com/artech/p/inside-asp-net-core-05-02.html&quot;&gt;[ASP.NET Core 3框架揭秘] 配置[2]：读取配置数据[下篇]&lt;/a&gt;&lt;br/&gt;&lt;a href=&quot;https://www.cnblogs.com/artech/p/inside-asp-net-core-05-03.html&quot;&gt;[ASP.NET Core 3框架揭秘] 配置[3]：配置模型总体设计&lt;/a&gt;&lt;br/&gt;&lt;a href=&quot;https://www.cnblogs.com/artech/p/inside-asp-net-core-05-04.html&quot;&gt;[ASP.NET Core 3框架揭秘] 配置[4]：将配置绑定为对象&lt;/a&gt;&lt;br/&gt;&lt;a href=&quot;https://www.cnblogs.com/artech/p/inside-asp-net-core-05-05.html&quot;&gt;[ASP.NET Core 3框架揭秘] 配置[5]：配置数据与数据源的实时同步&lt;/a&gt;&lt;br/&gt;&lt;a href=&quot;https://www.cnblogs.com/artech/p/inside-asp-net-core-05-06.html&quot;&gt;[ASP.NET Core 3框架揭秘] 配置[6]：多样化的配置源[上篇]&lt;/a&gt;&lt;br/&gt;&lt;a href=&quot;https://www.cnblogs.com/artech/p/inside-asp-net-core-05-07.html&quot;&gt;[ASP.NET Core 3框架揭秘] 配置[7]：多样化的配置源[中篇]&lt;/a&gt;&lt;br/&gt;&lt;a href=&quot;https://www.cnblogs.com/artech/p/inside-asp-net-core-05-08.html&quot;&gt;[ASP.NET Core 3框架揭秘] 配置[8]：多样化的配置源[下篇]&lt;/a&gt;&lt;br/&gt;&lt;a href=&quot;https://www.cnblogs.com/artech/p/inside-asp-net-core-05-09.html&quot;&gt;[ASP.NET Core 3框架揭秘] 配置[9]：自定义配置源&lt;/a&gt;&lt;/p&gt;
</description>
<pubDate>Fri, 20 Dec 2019 00:19:00 +0000</pubDate>
<dc:creator>Artech</dc:creator>
<og:description>物理文件是我们最常用到的原始配置载体，而最佳的配置文件格式主要有三种，它们分别是JSON、XML和INI，对应的配置源类型分别是JsonConfigurationSource、XmlConfigura</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/artech/p/inside-asp-net-core-05-07.html</dc:identifier>
</item>
<item>
<title>软件设计的哲学： 第九章 合并还是分解 - peida</title>
<link>http://www.cnblogs.com/peida/p/12071197.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/peida/p/12071197.html</guid>
<description>&lt;p&gt;&lt;strong&gt;软件设计中最基本的问题之一是：给定两部分功能，它们应该在同一个地方一起实现，还是应该分开实现？ 这个问题适用于系统中的所有级别，比如函数、方法、类和服务。&lt;/strong&gt; 例如，缓冲应该包含在提供面向流的文件I/O的类中，还是应该包含在单独的类中?HTTP请求的解析应该完全在一个方法中实现，还是应该在多个方法(甚至多个类)中进行？本章讨论了做出这些决定时需要考虑的因素。这些因素中的一些已经在前几章中讨论过，但是为了完整起见，这里将重新讨论它们。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;在决定是合并还是分离时，目标是降低整个系统的复杂性并改进其模块化。实现这一目标的最佳方法似乎是将系统划分为大量的小组件：组件越小，每个单独的组件可能就越简单。&lt;/strong&gt; 然而，细分的行为产生了额外的复杂性，这在细分之前是不存在的：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;一些复杂性仅仅来自组件的数量：组件越多，就越难以跟踪它们，也就越难以在大型集合中找到所需的组件。细分通常会导致更多的接口，而且每个新接口都会增加复杂性。&lt;/li&gt;
&lt;li&gt;细分可能导致管理组件的额外代码。例如，在细分之前使用单个对象的一段代码现在可能必须管理多个对象。&lt;/li&gt;
&lt;li&gt;细分产生分离：细分后的组件将比细分前更加分离。例如，在细分之前在单个类中的方法可能在细分之后在不同的类中，也可能在不同的文件中。分离使得开发人员很难同时看到组件，甚至很难意识到它们的存在。如果组件是真正独立的，那么分离是好的:它允许开发人员一次只关注一个组件，而不会被其他组件分散注意力。另一方面，如果组件之间存在依赖关系，则分离是不好的:开发人员最终将在组件之间来回切换。更糟糕的是，他们可能没有意识到依赖关系，这可能会导致bug。&lt;/li&gt;
&lt;li&gt;细分可能导致重复：在细分之前存在于单个实例中的代码可能需要存在于每个细分的组件中。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;如果代码片段紧密相关，那么将它们组合在一起是最有益的。如果这些部分是不相关的，那么最好分开。&lt;/strong&gt; 这里有一些迹象表明，两段代码是相关的：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;他们分享信息；例如，这两段代码可能取决于特定类型文档的语法。&lt;/li&gt;
&lt;li&gt;它们一起使用:任何使用其中一段代码的人都可能使用另一段代码。这种形式的关系只有在双向的情况下才有吸引力。作为一个反例，磁盘块缓存几乎总是涉及到一个散列表，但是散列表可以在许多不涉及块缓存的情况下使用;因此，这些模块应该是独立的。&lt;/li&gt;
&lt;li&gt;它们在概念上是重叠的，因为有一个简单的更高级别的类别，其中包括这两段代码。例如，搜索子字符串和大小写转换都属于字符串操作的范畴；流量控制和可靠交付都属于网络通信的范畴。&lt;/li&gt;
&lt;li&gt;如果不看另一段代码，就很难理解其中一段代码。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;本章的其余部分将使用更具体的规则和示例来说明何时将代码片段放在一起是有意义的，以及何时将它们分开是有意义的。&lt;/p&gt;
&lt;h2 id=&quot;如果共享信息则将信息集合在一起&quot;&gt;9.1 如果共享信息，则将信息集合在一起&lt;/h2&gt;
&lt;p&gt;第5.4节在实现HTTP服务器的项目上下文中介绍了这一原则。在第一个实现中，该项目使用不同类中的两个不同方法来读入和解析HTTP请求。第一个方法读取来自网络套接字的传入请求的文本，并将其放在字符串对象中。第二个方法解析字符串以提取请求的各个组件。分解,最终的两个方法都有相当知识的HTTP请求的格式：第一种方法只是想读请求,解析它,但它不能识别的最后请求不做的大部分工作的解析(例如，它解析头线以识别包含整体请求的标题长度)。由于这种共享信息，最好在同一个位置读取和解析请求；当这两个类合并为一个类时，代码变得更短更简单。&lt;/p&gt;
&lt;h2 id=&quot;如果可以简化接口就一起使用&quot;&gt;9.2 如果可以简化接口，就一起使用&lt;/h2&gt;
&lt;p&gt;当两个或多个模块组合成一个模块时，可以为新模块定义一个比原来的接口更简单或更容易使用的接口。这种情况经常发生在原始模块实现问题解决方案的一部分时。在前一节的HTTP服务器示例中，原始方法需要一个接口来从第一个方法返回HTTP请求字符串并将其传递给第二个方法。当这些方法组合在一起时，这些接口就被消除了。&lt;/p&gt;
&lt;p&gt;此外，当两个或多个类的功能组合在一起时，可能会自动执行某些功能，因此大多数用户不需要知道它们。Java I/O库说明了这一机会。如果将FileInputStream和BufferedInputStream类组合在一起，并且默认提供了缓冲，那么绝大多数用户甚至都不需要知道缓冲的存在。组合的FileInputStream类可能提供禁用或替换默认缓冲机制的方法，但是大多数用户不需要了解这些方法。&lt;/p&gt;
&lt;h2 id=&quot;消除重复&quot;&gt;9.3 消除重复&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;如果您发现重复出现相同的代码模式，请尝试重新组织代码以消除重复。一种方法是将重复的代码分解成一个单独的方法，并将重复的代码片段替换为对该方法的调用。&lt;/strong&gt; 如果重复的代码段很长，并且替换方法有一个简单的签名，那么这种方法是最有效的。如果代码段只有一两行，那么用方法调用替换它可能没有什么好处。如果代码段以复杂的方式与它的环境交互(例如通过访问许多局部变量)，那么替换方法可能需要复杂的签名(例如许多引用传递参数)，这将降低它的值。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;消除重复的另一种方法是重构代码，使有问题的代码片段只需要在一个地方执行。&lt;/strong&gt; 假设您正在编写一个方法，该方法需要在几个不同的点上返回错误，并且在返回之前需要在这些点上执行相同的清理操作(参见图9.1中的示例)。如果编程语言支持goto，您可以将清理代码移动到方法的末尾，然后转到需要错误返回的每个点，如图9.2所示。Goto语句通常被认为是一个糟糕的想法，如果不加选择地使用它们，可能会导致无法破译的代码，但是在这种情况下它们是有用的，因为它们可以用来逃避嵌套的代码。&lt;/p&gt;
&lt;h2 id=&quot;通用代码和专用代码分开&quot;&gt;9.4 通用代码和专用代码分开&lt;/h2&gt;
&lt;p&gt;如果一个模块包含一个可以用于多个不同目的的机制，那么它应该只提供一个通用机制。它不应该包含专门用于特定用途的机制的代码，也不应该包含其他通用机制。与通用机制相关联的专用代码通常应该放在不同的模块中(通常是与特定用途相关联的模块)。第6章中的GUI编辑器讨论说明了这一原则:最佳设计是文本类提供通用的文本操作，而用户界面的特定操作(如删除选择)在用户界面模块中实现。这种方法消除了早期设计中出现的信息泄漏和额外的接口，在早期设计中，专门的用户界面操作是在text类中实现的。&lt;/p&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;&lt;strong&gt;危险信号：重复&lt;/strong&gt;&lt;br/&gt;如果同一段代码(或几乎相同的代码)反复出现，这是一个危险信号，说明您没有找到正确的抽象。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/34483/201912/34483-20191220075757196-1807209252.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;图9.1：此代码处理不同类型的入站网络数据包;对于每种类型，如果信息包太短而不适合该类型，则记录一条消息。在这个版本的代码中，日志语句被复制到几个不同的包类型中。&lt;br/&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/34483/201912/34483-20191220075653750-2115638508.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;图9.2：对图9.1中的代码进行重组，使日志语句只有一个副本。&lt;/p&gt;
&lt;p&gt;一般来说，系统的低层往往是通用的，而上层则是专用的。例如，应用程序的最顶层由完全特定于该应用程序的特性组成。将专用代码从通用代码中分离出来的方法是将专用代码向上拉到更高的层中，而将较低的层保留为通用代码。&lt;/p&gt;
&lt;p&gt;当你遇到一个类，包括通用和专用功能相同的抽象，看看类可以分为两个类，一个包含通用功能，其他之上提供专用功能。&lt;/p&gt;
&lt;h2 id=&quot;示例插入光标和选择&quot;&gt;9.5 示例：插入光标和选择&lt;/h2&gt;
&lt;p&gt;下一节将通过三个示例来说明上面讨论的原则。在两个例子中，最好的方法是分离相关的代码片段;在第三个例子中，最好将它们连接在一起。&lt;/p&gt;
&lt;p&gt;第一个例子由第6章的GUI编辑器项目中的插入游标和选择组成。编辑器显示一条闪烁的竖线，指示用户键入的文本将出现在文档中的何处。它还显示了一个高亮显示的字符范围，称为选择，用于复制或删除文本。插入光标总是可见的，但有时可能没有选择文本。如果选择项存在，则插入光标始终定位在选择项的一端。&lt;/p&gt;
&lt;p&gt;选择和插入游标在某些方面是相关的。例如,光标总是停留在一个选择，和光标选择往往是一起操作：点击并拖动鼠标设置他们两人，和文本插入第一个删除选中的文本，如果有任何,然后在光标位置插入新的文本。因此，使用单个对象来管理选择和游标似乎是合理的，一个项目团队采用了这种方法。该对象在文件中存储了两个位置，以及布尔值，布尔值指示哪一端是游标，以及选择是否存在。&lt;/p&gt;
&lt;p&gt;然而，组合的对象是尴尬的。它没有为高级代码提供任何好处，因为高级代码仍然需要知道选择和游标是不同的实体，并且需要分别操作它们(在文本插入期间，它首先调用组合对象上的一个方法来删除所选的文本；然后，它调用另一个方法来检索光标位置，以便插入新文本)。组合对象实际上比单独的对象更复杂。它避免将游标位置存储为单独的实体，而是必须存储一个布尔值，指示选择的哪一端是游标。为了检索光标位置，组合对象必须首先测试布尔值，然后选择适当的选择结束。&lt;/p&gt;
&lt;blockquote readability=&quot;9&quot;&gt;
&lt;p&gt;&lt;strong&gt;危险信号：特殊和一般的混合物&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;当通用机制还包含专门用于该机制特定用途的代码时，就会出现此警告。这使得机制更加复杂，并在机制和特定用例之间产生信息泄漏：未来对用例的修改可能也需要对底层机制进行更改。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;本例中，选择和游标之间的关系不够紧密，无法将它们组合在一起。当修改代码以将选择和游标分隔开时，使用和实现都变得更简单了。与必须从中提取选择和游标信息的组合对象相比，分离对象提供了更简单的接口。游标实现也变得更简单了，因为游标位置是直接表示的，而不是通过选择和布尔值间接表示的。事实上，在修订版本中，选择和游标都没有使用特殊的类。相反，引入了一个新的Position类来表示文件中的一个位置(行号和行中的字符)。选择用两个位置表示，游标用一个位置表示。这些职位在项目中还有其他用途。这个示例还演示了较低级但更通用的接口的好处，这在第6章中讨论过。&lt;/p&gt;
&lt;h2 id=&quot;示例日志记录的单独类&quot;&gt;9.6示例：日志记录的单独类&lt;/h2&gt;
&lt;p&gt;第二个例子涉及到学生项目中的错误日志记录。一个类包含如下代码序列：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;try {
      rpcConn = connectionPool.getConnection(dest);
} catch (IOException e) {
      NetworkErrorLogger.logRpcOpenError(req, dest, e);
      return null;
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;不是在错误被检测到的地方记录错误，而是调用一个特殊的错误日志类中的一个单独的方法。错误日志类是在同一个源文件的末尾定义的：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;private static class NetworkErrorLogger {
     /**
      *  Output information relevant to an error that occurs when trying
      *  to open a connection to send an RPC.
      *
      *  @param req 
                The RPC request that would have been sent through the connection
      *  @param dest
      *       The destination of the RPC
      *  @param e
      *       The caught error
      */
     public static void logRpcOpenError(RpcRequest req, AddrPortTuple dest, Exception e) {
         logger.log(Level.WARNING, &quot;Cannot send message: &quot; + req + &quot;. \n&quot; + &quot;Unable to find or open connection to &quot; + dest + &quot; :&quot; + e);
      }
...

}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;NetworkErrorLogger类包含几个方法，如logRpcSendError和logRpcReceiveError，每个方法都记录不同类型的错误。&lt;/p&gt;
&lt;p&gt;这种分离增加了复杂性，但没有带来任何好处。日志记录方法很简单：大多数都是由一行代码组成的，但是它们需要大量的文档。每个方法只在一个地方调用。日志记录方法高度依赖于它们的调用：读取调用的人很可能会切换到日志记录方法，以确保记录了正确的信息；类似地，阅读日志记录方法的人可能会转到调用站点以了解方法的用途。&lt;/p&gt;
&lt;p&gt;在本例中，最好消除日志记录方法，并将日志语句放置在检测到错误的位置。这将使代码更易于阅读，并消除日志方法所需的接口。&lt;/p&gt;
&lt;h2 id=&quot;示例编辑器撤销机制&quot;&gt;9.7示例：编辑器撤销机制&lt;/h2&gt;
&lt;p&gt;在6.2部分的GUI编辑器项目中，其中一个需求是支持多级撤销/重做，不仅是对文本本身的更改，还包括对选择、插入游标和视图的更改。例如，如果用户选择某个文本，删除它，滚动到文件中的另一个位置，然后调用undo，编辑器必须将其状态恢复到删除之前的状态。这包括恢复被删除的文本，再次选择它，并使选择的文本在窗口中可见。&lt;/p&gt;
&lt;p&gt;一些学生项目将整个撤销机制作为text类的一部分实现。text类维护了一个所有可撤销更改的列表。当文本被更改时，它会自动向这个列表添加条目。对于选择、插入游标和视图的更改，用户界面代码调用text类中的其他方法，然后这些方法将这些更改的条目添加到撤消列表中。当用户请求撤消或重做时，用户界面代码调用text类中的一个方法，然后由该方法处理撤消列表中的条目。对于与文本相关的条目，它更新了文本类的内部结构;对于与其他内容(如选择)相关的条目，文本类将调用回用户界面代码以执行撤消或重做。&lt;/p&gt;
&lt;p&gt;这种方法导致文本类中出现一组令人尴尬的特性。撤销/重做的核心是一种通用机制，用于管理已执行的操作列表，并在撤消和重做操作期间逐步执行这些操作。核心位于text类中，与特殊用途的处理程序一起，这些处理程序为特定的事情(比如文本和选择)实现撤销和重做。用于选择和游标的特殊用途的撤消处理程序与文本类中的任何其他内容无关;它们导致文本类和用户界面之间的信息泄漏，以及每个模块中来回传递撤消信息的额外方法。如果将来向系统中添加了一种新的可撤消实体，则需要对text类进行更改，包括特定于该实体的新方法。此外，通用撤销核心与类中的通用文本工具几乎没有什么关系。&lt;/p&gt;
&lt;p&gt;这些问题可以通过提取撤销/重做机制的通用核心并将其放在一个单独的类中来解决：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;public class History {
        public interface Action {
               public void redo();
                       public void undo();
        }

        History() {...}

        void addAction(Action action) {...}

        void addFence() {...}

        void undo() {...}

        void redo() {...}
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;在本设计中，History类管理实现接口History. action的对象集合。每一个历史。Action描述单个操作，例如文本插入或光标位置的更改，并提供可以撤消或重做操作的方法。History类不知道操作中存储的信息，也不知道它们如何实现撤销和重做方法。History维护一个历史列表，该列表描述了在应用程序的生命周期中执行的所有操作，它提供了undo和redo方法，这些方法在响应用户请求的undos和redos时来回遍历列表，调用History. actions中的undo和redo方法。&lt;/p&gt;
&lt;p&gt;历史。操作是特殊用途的对象:每个操作都理解一种特定的可撤消操作。它们在History类之外的模块中实现，这些模块理解特定类型的可撤销操作。text类可以实现UndoableInsert和UndoableDelete对象来描述文本插入和删除。每当插入文本时，text类都会创建一个新的UndoableInsert对象来描述插入并调用历史记录。addAction将其添加到历史记录列表。编辑器的用户界面代码可能创建UndoableSelection和UndoableCursor对象，它们描述对选择和插入游标的更改。&lt;/p&gt;
&lt;p&gt;History类还允许对操作进行分组，例如，来自用户的单个undo请求可以恢复已删除的文本、重新选择已删除的文本和重新定位插入光标。&lt;/p&gt;
&lt;p&gt;有很多方法来组织动作；History类使用fence，它是历史列表中的标记，用于分隔相关操作的组。每次遍历历史。redo向后遍历历史记录列表，撤消操作，直到到达下一个围栏。fence的位置由调用History.addFence的高级代码决定。&lt;/p&gt;
&lt;p&gt;这种方法将撤销的功能分为三类，分别在不同的地方实现：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;一种通用的机制，用于管理和分组操作以及调用undo/redo操作(由History类实现)。&lt;/li&gt;
&lt;li&gt;特定操作的细节(由各种类实现，每个类理解少量的操作类型)。&lt;/li&gt;
&lt;li&gt;分组操作的策略(由高级用户界面代码实现，以提供正确的整体应用程序行为)。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;这些类别中的每一个都可以在不了解其他类别的情况下实现。历史课不知道哪些行为被撤销了;它可以用于各种各样的应用。每个action类只理解一种action，而History类和action类都不需要知道分组action的策略。&lt;/p&gt;
&lt;p&gt;关键的设计决策是将撤消机制的通用部分与专用部分分离，并将通用部分单独放在类中。一旦完成了这一步，剩下的设计就自然而然地结束了。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;注意：&lt;/strong&gt; 将通用代码与专用代码分离的建议是指与特定机制相关的代码。例如，特殊用途的撤消代码(例如撤消文本插入的代码)应该与通用用途的撤消代码(例如管理历史记录列表的代码)分开。然而，将一种机制的专用代码与另一种机制的通用代码组合起来通常是有意义的。text类就是这样一个例子:它实现了管理文本的通用机制，但是它包含了与撤销相关的专用代码。撤消代码是专用的，因为它只处理文本修改的撤消操作。将这段代码与History类中通用的undo基础结构结合在一起是没有意义的，但是将它放在text类中是有意义的，因为它与其他文本函数密切相关。&lt;/p&gt;
&lt;h2 id=&quot;分解和连接方法&quot;&gt;9.8 分解和连接方法&lt;/h2&gt;
&lt;p&gt;何时细分的问题不分解仅适用于类，也适用于方法：是否存在将现有方法划分为多个较小的方法更好的时机?或者，两个较小的方法应该合并成一个较大的方法吗？长方法往往比短方法更难理解，因此许多人认为，长度本身就是分解方法的一个很好的理由。学生在课堂上经常被给予严格的标准，如“分解任何超过20行的方法!”&lt;/p&gt;
&lt;p&gt;但是，&lt;strong&gt;长度本身很少是拆分方法的好理由。&lt;/strong&gt; 一般来说，开发人员倾向于过多地分解方法。拆分方法会引入额外的接口，增加了复杂性。它还分离了原始方法的各个部分，如果这些部分实际上是相关的，就会使代码更难读取。你不应该破坏一个方法，除非它使整个系统更简单；我将在下面讨论这是如何发生的。&lt;/p&gt;
&lt;p&gt;长方法并不总是坏事。例如，假设一个方法包含五个按顺序执行的20行代码块。如果这些块是相对独立的，则可以一次读取和理解一个块；将每个块移动到一个单独的方法中没有什么好处。如果代码块具有复杂的交互，那么将它们放在一起更重要，这样读者就可以一次看到所有代码;如果每个块位于一个单独的方法中，读者将不得不在这些展开的方法之间来回切换，以了解它们是如何协同工作的。如果方法具有简单的签名并且易于阅读，那么包含数百行代码的方法就很好。这些方法很深奥(功能很多，接口简单)，这很好。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/34483/201912/34483-20191220075826356-496032733.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;图9.3:一个方法(A)可以通过提取一个子任务(b)或者通过将其功能划分为两个单独的方法(c)来分解。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;在设计方法时，最重要的目标是提供简洁而简单的抽象。 每一种方法都应该做一件事，而且要做得彻底。&lt;/strong&gt; 这个方法应该有一个干净简单的界面，这样用户就不需要在他们的头脑中有太多的信息来正确地使用它。&lt;strong&gt;方法应该是深度的：它的接口应该比它的实现简单得多。&lt;/strong&gt; 如果一个方法具有所有这些属性，那么它是否长可能并不重要。&lt;/p&gt;
&lt;p&gt;总的来说，&lt;strong&gt;分解方法只有在产生更清晰的抽象时才有意义&lt;/strong&gt;。有两种方法可以做到这一点，如图9.3所示。&lt;strong&gt;最好的方法是将一个子任务分解成单独的方法&lt;/strong&gt;，如图9.3(b)所示。细分产生包含子任务的子方法和包含原始方法其余部分的父方法;父调用子调用。新父方法的接口与原始方法相同。这种形式的细分有意义如果有干净地分离的子任务的原始方法,这意味着(a)有人阅读孩子的方法不需要知道任何关于父法和(b)有人阅读父法不需要理解孩子的实现方法。通常这意味着子方法是相对通用的:它可以被父方法之外的其他方法使用。如果您对这个表单进行拆分，然后发现自己在父类和子类之间来回切换，以了解它们是如何协同工作的，那么这就是一个危险信号(“联合方法”)，表明拆分可能不是一个好主意。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;分解一个方法的第二种方法是将它分解成两个单独的方法，每个方法对于原始方法的调用者都是可见的&lt;/strong&gt;，如图9.3(c)所示。如果原始方法有一个过于复杂的接口，这是有意义的，因为它试图做许多不密切相关的事情。如果是这种情况，可以将方法的功能划分为两个或多个更小的方法，每个方法只具有原始方法的一部分功能。如果像这样分解，每个结果方法的接口应该比原始方法的接口简单。理想情况下，大多数调用者应该只需要调用两个新方法中的一个；如果调用者必须同时调用这两个新方法，那么这就增加了复杂性，从而降低了拆分的可能性。新方法将更专注于它们所做的事情。如果新方法比原来的方法更通用，这是一个好迹象。你可以想象在其他情况下分别使用它们)。&lt;/p&gt;
&lt;p&gt;图9.3(c)中所示的表单分解通常没有意义，因为它们导致调用者必须处理多个方法，而不是一个。当您以这种方式进行划分时，您可能会得到几个浅层方法，如图9.3(d)所示。如果调用者必须调用每个单独的方法，在它们之间来回传递状态，那么分解不是一个好主意。如果您正在考虑类似图9.3(c)中的拆分，那么您应该根据它是否简化了调用者的工作来判断它。&lt;/p&gt;
&lt;p&gt;在某些情况下，&lt;strong&gt;可以通过将方法连接在一起来简化系统&lt;/strong&gt;。例如，连接方法可以用一个较深的方法代替两个较浅的方法；它可以消除重复的代码；它可以消除原始方法或中间数据结构之间的依赖关系；它可能导致更好的封装，因此以前在多个地方出现的知识现在被隔离在一个地方；或者，它可能导致一个更简单的接口，如9.2节中所讨论的那样。&lt;/p&gt;
&lt;blockquote readability=&quot;10&quot;&gt;
&lt;p&gt;&lt;strong&gt;危险信号：联合方法&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;应该能够独立地理解每种方法。如果你不能理解一个方法的实现而不理解另一个方法的实现，那就是一个危险信号。此微信型号也可以出现在其他上下文中：如果两段代码在物理上是分开的，但是每段代码只能通过查看另一段代码来理解，这就是危险信号。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;结论&quot;&gt;9.9 结论&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;拆分或联接模块的决策应该基于复杂性。选择能够隐藏最佳信息、最少依赖和最深接口的结构。&lt;/strong&gt;&lt;/p&gt;
</description>
<pubDate>Fri, 20 Dec 2019 00:00:00 +0000</pubDate>
<dc:creator>peida</dc:creator>
<og:description>拆分或联接模块的决策应该基于复杂性。选择能够隐藏最佳信息、最少依赖和最深接口的结构。</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/peida/p/12071197.html</dc:identifier>
</item>
<item>
<title>JavaEE基础(06)：Servlet整合C3P0数据库连接池 - 知了一笑</title>
<link>http://www.cnblogs.com/cicada-smile/p/12071198.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/cicada-smile/p/12071198.html</guid>
<description>&lt;blockquote readability=&quot;1.8269230769231&quot;&gt;
&lt;p&gt;本文源码：&lt;a href=&quot;https://github.com/cicadasmile/java-base-parent&quot;&gt;GitHub·点这里&lt;/a&gt; || &lt;a href=&quot;https://gitee.com/cicadasmile/java-base-parent&quot;&gt;GitEE·点这里&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;c3p0简介&quot;&gt;1、C3P0简介&lt;/h2&gt;
&lt;p&gt;C3P0是一个开源的JDBC连接池，应用程序根据C3P0配置来初始化数据库连接，可以自动回收空闲连接的功能。&lt;/p&gt;
&lt;h2 id=&quot;核心依赖&quot;&gt;2、核心依赖&lt;/h2&gt;
&lt;pre class=&quot;xml&quot;&gt;
&lt;code&gt;&amp;lt;dependency&amp;gt;
    &amp;lt;groupId&amp;gt;mysql&amp;lt;/groupId&amp;gt;
    &amp;lt;artifactId&amp;gt;mysql-connector-java&amp;lt;/artifactId&amp;gt;
    &amp;lt;version&amp;gt;${mysql.version}&amp;lt;/version&amp;gt;
&amp;lt;/dependency&amp;gt;
&amp;lt;dependency&amp;gt;
    &amp;lt;groupId&amp;gt;com.mchange&amp;lt;/groupId&amp;gt;
    &amp;lt;artifactId&amp;gt;c3p0&amp;lt;/artifactId&amp;gt;
    &amp;lt;version&amp;gt;${c3p0.version}&amp;lt;/version&amp;gt;
&amp;lt;/dependency&amp;gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;配置文件&quot;&gt;3、配置文件&lt;/h2&gt;
&lt;p&gt;配置文件位置：放在&lt;code&gt;resources&lt;/code&gt;目录下，这样C3P0组件会自动加载该配置。&lt;/p&gt;
&lt;pre class=&quot;xml&quot;&gt;
&lt;code&gt;&amp;lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&amp;gt;
&amp;lt;c3p0-config&amp;gt;
    &amp;lt;default-config&amp;gt;
        &amp;lt;!-- 核心参数配置 --&amp;gt;
        &amp;lt;property name=&quot;jdbcUrl&quot;&amp;gt;jdbc:mysql://localhost:3306/servlet-jdbc&amp;lt;/property&amp;gt;
        &amp;lt;property name=&quot;driverClass&quot;&amp;gt;com.mysql.jdbc.Driver&amp;lt;/property&amp;gt;
        &amp;lt;property name=&quot;user&quot;&amp;gt;root&amp;lt;/property&amp;gt;
        &amp;lt;property name=&quot;password&quot;&amp;gt;123&amp;lt;/property&amp;gt;
        &amp;lt;!-- 池参数配置 --&amp;gt;
        &amp;lt;property name=&quot;acquireIncrement&quot;&amp;gt;3&amp;lt;/property&amp;gt;
        &amp;lt;property name=&quot;initialPoolSize&quot;&amp;gt;10&amp;lt;/property&amp;gt;
        &amp;lt;property name=&quot;minPoolSize&quot;&amp;gt;2&amp;lt;/property&amp;gt;
        &amp;lt;property name=&quot;maxPoolSize&quot;&amp;gt;10&amp;lt;/property&amp;gt;
    &amp;lt;/default-config&amp;gt;
&amp;lt;/c3p0-config&amp;gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;编写工具类&quot;&gt;4、编写工具类&lt;/h2&gt;
&lt;p&gt;该工具类用来获取数据库连接，和释放相关连接。&lt;/p&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;public class C3P0Pool {
    private static DataSource dataSource = new ComboPooledDataSource();
    public static DataSource getDataSource() {
        return dataSource ;
    }
    /**
     * 获取连接
     */
    public static Connection getConnection() throws SQLException {
        return dataSource.getConnection();
    }
    /**
     * 释放连接
     */
    public static void close(ResultSet resultSet, PreparedStatement pst, Connection connection) {
        if (resultSet != null) {
            try {
                resultSet.close();
            } catch (SQLException e) {
                e.printStackTrace();
            }
        }
        if (pst != null) {
            try {
                pst.close();
            } catch (SQLException e) {
                e.printStackTrace();
            }
        }
        if (connection != null) {
            try {
                connection.close();
            } catch (SQLException e) {
                e.printStackTrace();
            }
        }
    }
}&lt;/code&gt;
&lt;/pre&gt;

&lt;h2 id=&quot;新增数据&quot;&gt;1、新增数据&lt;/h2&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;public class UserJdbcInsert {
    public static void insertUser (UserInfo userInfo){
        try {
            Connection connection = C3P0Pool.getConnection();
            String sql = &quot;INSERT INTO user_info (user_name,user_age) VALUES (?,?)&quot; ;
            PreparedStatement statement = connection.prepareStatement(sql);
            statement.setString(1,userInfo.getUserName());
            statement.setString(2,userInfo.getUserAge().toString());
            statement.execute() ;
            C3P0Pool.close(null, statement, connection);
        } catch (Exception e) {
            e.printStackTrace();
        }
    }
    public static void batchInsertUser (List&amp;lt;UserInfo&amp;gt; userInfoList){
        try {
            Connection connection = C3P0Pool.getConnection();
            String sql = &quot;INSERT INTO user_info (user_name,user_age) VALUES (?,?)&quot; ;
            PreparedStatement statement = connection.prepareStatement(sql);
            for (UserInfo userInfo:userInfoList){
                statement.setString(1,userInfo.getUserName());
                statement.setString(2,userInfo.getUserAge().toString());
                statement.addBatch();
            }
            statement.executeBatch() ;
            C3P0Pool.close(null, statement, connection);
        } catch (Exception e) {
            e.printStackTrace();
        }
    }
}&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;查询数据&quot;&gt;2、查询数据&lt;/h2&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;public class UserJdbcQuery {
    public static UserInfo queryUser (String userName){
        UserInfo userInfo = null ;
        try {
            Connection connection = C3P0Pool.getConnection();
            String sql = &quot;SELECT * FROM user_info WHERE user_name=?&quot; ;
            PreparedStatement statement = connection.prepareStatement(sql);
            statement.setString(1,userName);
            ResultSet resultSet = statement.executeQuery() ;
            while (resultSet.next()){
                int id = resultSet.getInt(&quot;id&quot;);
                String name = resultSet.getString(&quot;user_name&quot;);
                int age = resultSet.getInt(&quot;user_age&quot;);
                System.out.println(&quot;ID:&quot;+id+&quot;;name:&quot;+name+&quot;;age:&quot;+age);
                userInfo = new UserInfo(name,age) ;
            }
            C3P0Pool.close(resultSet, statement, connection);
        } catch (Exception e) {
            e.printStackTrace();
        }
        return userInfo ;
    }
}&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;更新数据&quot;&gt;3、更新数据&lt;/h2&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;public class UserJdbcUpdate {
    public static void updateUser (String name,Integer age,Integer id){
        try {
            Connection connection = C3P0Pool.getConnection();
            String sql = &quot;UPDATE user_info SET user_name=?,user_age=? WHERE id=?&quot; ;
            PreparedStatement statement = connection.prepareStatement(sql);
            statement.setString(1,name);
            statement.setInt(2,age);
            statement.setInt(3,id);
            statement.executeUpdate() ;
            C3P0Pool.close(null, statement, connection);
        } catch (Exception e) {
            e.printStackTrace();
        }
    }
}&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;删除数据&quot;&gt;4、删除数据&lt;/h2&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;public class UserJdbcDelete {
    public static void deleteUser (Integer id){
        try {
            Connection connection = C3P0Pool.getConnection();
            String sql = &quot;DELETE FROM user_info WHERE id=?&quot; ;
            PreparedStatement statement = connection.prepareStatement(sql);
            statement.setInt(1,id);
            statement.executeUpdate() ;
            C3P0Pool.close(null, statement, connection);
        } catch (Exception e) {
            e.printStackTrace();
        }
    }
}&lt;/code&gt;
&lt;/pre&gt;

&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;public class JdbcServletImpl extends HttpServlet {
    @Override
    protected void doGet(HttpServletRequest request, HttpServletResponse response)
            throws ServletException, IOException {
        String userName = request.getParameter(&quot;userName&quot;) ;
        UserInfo userInfo = UserJdbcQuery.queryUser(userName) ;
        response.setContentType(&quot;text/html;charset=utf-8&quot;);
        response.getWriter().print(&quot;用户信息:&quot;+userInfo);
    }
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;测试访问：&lt;/p&gt;
&lt;p&gt;&lt;code&gt;http://localhost:6003/jdbcServletImpl?userName=LiSi&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;页面打印：&lt;/p&gt;
&lt;p&gt;用户信息:&lt;code&gt;UserInfo{userName='LiSi', userAge=22}&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;
&lt;code&gt;GitHub·地址
https://github.com/cicadasmile/java-base-parent
GitEE·地址
https://gitee.com/cicadasmile/java-base-parent&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1691717/201908/1691717-20190823075428183-1996768914.png&quot;/&gt;&lt;/p&gt;
</description>
<pubDate>Fri, 20 Dec 2019 00:00:00 +0000</pubDate>
<dc:creator>知了一笑</dc:creator>
<og:description>本文源码： 'GitHub·点这里' || 'GitEE·点这里' 一、C3P0连接池 1、C3P0简介 C3P0是一个开源的JDBC连接池，应用程序根据C3P0配置来初始化数据库连接，可以自动回收空</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/cicada-smile/p/12071198.html</dc:identifier>
</item>
<item>
<title>Elasticsearch系列---初识搜索 - 清茶豆奶</title>
<link>http://www.cnblogs.com/huangying2124/p/12071185.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/huangying2124/p/12071185.html</guid>
<description>&lt;h3 id=&quot;概要&quot;&gt;概要&lt;/h3&gt;
&lt;p&gt;本篇主要介绍搜索的报文结构含义、搜索超时时间的处理过程，提及了一下多索引搜索和轻量搜索，最后将精确搜索与全文搜索做了简单的对比。&lt;/p&gt;
&lt;h3 id=&quot;空搜索&quot;&gt;空搜索&lt;/h3&gt;
&lt;p&gt;搜索API最简单的形式是不指定索引和类型的空搜索，它将返回集群下所有索引的所有文档（默认显示10条）：&lt;/p&gt;
&lt;p&gt;&lt;code&gt;GET /_search&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;响应的结果示例(有筛选，只取了一条document作为示例)：&lt;/p&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;{
  &quot;took&quot;: 2,
  &quot;timed_out&quot;: false,
  &quot;_shards&quot;: {
    &quot;total&quot;: 5,
    &quot;successful&quot;: 5,
    &quot;skipped&quot;: 0,
    &quot;failed&quot;: 0
  },
  &quot;hits&quot;: {
    &quot;total&quot;: 3,
    &quot;max_score&quot;: 1,
    &quot;hits&quot;: [
      {
        &quot;_index&quot;: &quot;music&quot;,
        &quot;_type&quot;: &quot;children&quot;,
        &quot;_id&quot;: &quot;2&quot;,
        &quot;_score&quot;: 1,
        &quot;_source&quot;: {
          &quot;name&quot;: &quot;wake me, shark me&quot;,
          &quot;content&quot;: &quot;don't let me sleep too late, gonna get up brightly early in the morning&quot;,
          &quot;language&quot;: &quot;english&quot;,
          &quot;length&quot;: &quot;55&quot;,
          &quot;likes&quot;: 9
        }
      }
    ]
  }
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;针对响应报文的字段，我们做一些简单解释:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;took：整个搜索请求花费了多少毫秒。&lt;/li&gt;
&lt;li&gt;time_out：查询是否超时。&lt;/li&gt;
&lt;li&gt;_shards：查询中参与分片的总数，其中成功的分片数量，失败的分片数量，以及跳过的分片数量。正常情况下不会有失败的分片数量，如果发生了灾难级别的故障，超过了容错的最大node数量，可能会同时丢失shard和replica，此时会报告这些分片是失败的，但还是会继续返回剩余可用分片的查询结果。&lt;/li&gt;
&lt;li&gt;hits：包含total表示匹配到的文档总数，max_score值是所有匹配文档中_score的最大值。&lt;/li&gt;
&lt;li&gt;hits.hits：数组内包含匹配的文档的完整信息，默认查询前10条数据，并且按_score降序排序。&lt;/li&gt;
&lt;/ul&gt;&lt;h4 id=&quot;timeout机制&quot;&gt;timeout机制&lt;/h4&gt;
&lt;p&gt;默认不使用timeout参数，如果某些场景下，低响应比搜索完整结果更重要，可以指定timeout为10ms或1s，在指定的超时时间内，Elasticsearch会把已经成功搜索到的文档返回。&lt;br/&gt;注意timeout不是停止执行查询，它只是告诉Coordinate Node返回到指定时间为止收集到的结果，并且关闭连接，在ES后台，其他node正在进行的查询并不会中断，只是结果没人要了。&lt;/p&gt;
&lt;p&gt;举个例子：某电商平台商品SKU品类300万条，输入某个关键字查询，有2000条记录匹配，但是要查15秒钟，一个搜索要等15秒才出结果，显得太不专业了，产品有SLA要求，必须1秒内出结果，最快的解决方案是查询使用参数timeout=1s，前端分页显示默认只展示20条，1秒内的查询结果要填满这20条还是比较容易的。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1834889/201912/1834889-20191220070706775-380079904.png&quot; alt=&quot;设置timeout的查询过程&quot;/&gt;&lt;/p&gt;
&lt;h3 id=&quot;多索引搜索&quot;&gt;多索引搜索&lt;/h3&gt;
&lt;p&gt;一个搜索请求，可以同时写多个索引名称，这叫做multi-index搜索模式。&lt;/p&gt;
&lt;p&gt;/_search：所有索引，所有type下的所有数据都搜索出来&lt;br/&gt;/index1,index2/_search：同时搜索两个index下的数据&lt;br/&gt;/&lt;em&gt;1,&lt;/em&gt;2/_search：按照通配符去匹配多个索引&lt;/p&gt;
&lt;p&gt;单一索引下搜索时，ES会转发请求到索引的每个分片中，shard或replica均可，然后收集结果返回。多索引时，原理相同，只是涉及的分片更多。另外搜索一个索引有5个分片和搜索5个索引各有一个分片，性能是等价的。&lt;/p&gt;
&lt;p&gt;顺带我们看一下搜索原理示意图：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1834889/201912/1834889-20191220070707143-1176518351.png&quot; alt=&quot;搜索原理示意图&quot;/&gt;&lt;/p&gt;
&lt;h3 id=&quot;轻量搜索&quot;&gt;轻量搜索&lt;/h3&gt;
&lt;p&gt;有两种形式的搜索API，一种是query string search，查询条件和排序规则写在request URI里，也叫轻量搜索；另一种是query DSL，查询条件等信息用JSON格式写在request body里。&lt;/p&gt;
&lt;p&gt;轻量搜索的示例：&lt;/p&gt;
&lt;p&gt;单个字段搜索，&quot;q=&quot;后面接的是查询条件&quot;field:text&quot;，field是字段名，text是搜索的关键词，有三种前缀修饰符：&lt;/p&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;GET /music/children/_search?q=content:friend
GET /music/children/_search?q=+content:friend
GET /music/children/_search?q=-content:friend&lt;/code&gt;
&lt;/pre&gt;
&lt;ul&gt;&lt;li&gt;&quot;+&quot;号前缀表示必须与查询条件匹配。&lt;/li&gt;
&lt;li&gt;&quot;-&quot;号前缀表示一定不与查询条件匹配。&lt;/li&gt;
&lt;li&gt;默认没写前缀表示条件可选&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;匹配的条件越多，文档就越相关。&lt;/p&gt;
&lt;p&gt;如果多个字段搜索，多个条件之间要有空格：&lt;/p&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;GET /music/children/_search?q=-content:friend +name:wake&lt;/code&gt;
&lt;/pre&gt;
&lt;h4 id=&quot;all元数据的原理-如果q后面没写field直接跟的是搜索关键词表示搜索指定索引下的所有字段如下&quot;&gt;_all元数据的原理&lt;br/&gt;如果&quot;q=&quot;后面没写field，直接跟的是搜索关键词，表示搜索指定索引下的所有字段，如下：&lt;/h4&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;GET /music/children/_search?q=friend&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;只要music索引下的document，任何一个字段包含friend，就能搜索出来。那_all是怎么来的？&lt;/p&gt;
&lt;p&gt;_all是Elasticsearch中的元数据，在建立索引的时候，新增一个document里面包含了多个field，此时，es会自动将多个field的值，全部用字符串的方式串联起来，变成一个长的字符串，作为_all field的值，同时建立索引。后面如果在搜索的时候，没有对某个field指定搜索，就默认搜索_all field。&lt;/p&gt;
&lt;p&gt;找个document示例：&lt;/p&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;&quot;name&quot;: &quot;wake me, shark me&quot;,
&quot;content&quot;: &quot;don't let me sleep too late, gonna get up brightly early in the morning&quot;,
&quot;language&quot;: &quot;english&quot;,
&quot;length&quot;: &quot;55&quot;,
&quot;likes&quot;: 9&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&quot;wake me, shark me don't let me sleep too late, gonna get up brightly early in the morning english 55 9&quot;，作为这一条document的_all field的值，同时进行分词后建立对应的倒排索引&lt;/p&gt;
&lt;h4 id=&quot;注意事项&quot;&gt;注意事项&lt;/h4&gt;
&lt;p&gt;轻量搜索在开发阶段会拿这些命令来做一些简单的查询，实际生产中用得比较少，语法复杂容易错，并且可阅读性低，遇到重量级查询，还有可能会把ES集群拖垮。&lt;/p&gt;
&lt;h3 id=&quot;精确搜索与全文搜索&quot;&gt;精确搜索与全文搜索&lt;/h3&gt;
&lt;p&gt;Elasticsearch的数据类型可以分成两类：精确值和全文。&lt;/p&gt;
&lt;ul readability=&quot;1&quot;&gt;&lt;li readability=&quot;2&quot;&gt;
&lt;p&gt;精确值（exact value）&lt;br/&gt;精确值如日期、ID，数值类型，有些文本类型也可以表示精确值，如邮箱、常用缩写等等。精确值的一个特点是必须完全相同、大小写敏感，很容易查询，hello与Hello是不相等的，日期为2019-11-20的字段值，输入2019是搜索不到的。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;全文（full text）&lt;br/&gt;全文数据就微妙得多，拿英文来说，各种词根变化、大小写转换、同义词、缩写，汉字方面各种分词、词库、网络词等，都希望匹配程度能高一些，能够理解我们的意图，举几个中文例子：&lt;/li&gt;
&lt;li&gt;南京市长江大桥，有一些分词器得到的结果：南京/市长/江大桥，完全不是我们想的结果，我们希望是：南京/南京市/长江/大桥/长江大桥。&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;长春市长春街长春药店，分词分得不对，搞成这样：长春/市长/春/街/长/春药/店，结果就很尴尬了。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;全文搜索方面，最基本的步骤是先分词，再索引，然后搜索时进行匹配，英文相对好办，中文方面有相像不到的难点要去克服。&lt;/p&gt;
&lt;h3 id=&quot;小结&quot;&gt;小结&lt;/h3&gt;
&lt;p&gt;本篇介绍搜索的基础知识，阐述搜索结果的含义，多索引搜索和轻量搜索的基本使用，最后对比了一下精确搜索与全文搜索，以及著名的中文分词大坑，谢谢。&lt;/p&gt;
&lt;p&gt;专注Java高并发、分布式架构，更多技术干货分享与心得，请关注公众号：Java架构社区&lt;br/&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1834889/201912/1834889-20191220070707376-260944835.jpg&quot; alt=&quot;Java架构社区&quot;/&gt;&lt;/p&gt;
</description>
<pubDate>Thu, 19 Dec 2019 23:07:00 +0000</pubDate>
<dc:creator>清茶豆奶</dc:creator>
<og:description>介绍搜索的报文结构含义、搜索超时时间的处理过程，提及了一下多索引搜索和轻量搜索，最后将精确搜索与全文搜索做了简单的对比</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/huangying2124/p/12071185.html</dc:identifier>
</item>
<item>
<title>React一键复制 - 一只菜鸟攻城狮啊</title>
<link>http://www.cnblogs.com/suihang/p/12071117.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/suihang/p/12071117.html</guid>
<description>&lt;p&gt;　　如题，我们怎么在React或者其他的框架中实现一键复制呢，实际上实现一键复制的代码与框架无关，因为他是用的是原生的API，下面我们用React来实现一下&lt;/p&gt;
&lt;p&gt; 　&lt;span&gt;&lt;strong&gt;   效果：&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;　　&lt;img src=&quot;https://img2018.cnblogs.com/i-beta/1459059/201912/1459059-20191220005351509-207324161.gif&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;



&lt;p&gt;　　&lt;span&gt;&lt;strong&gt;核心代码：&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;　　　　直接将红框处改为需要复制的元素类名。(获取元素时注意一下我用的是querySelector)&lt;/p&gt;
&lt;p&gt;　　　　将该事件绑定到元素上，即可。完整代码在最下方&lt;/p&gt;
&lt;p&gt;　　&lt;img src=&quot;https://img2018.cnblogs.com/i-beta/1459059/201912/1459059-20191220004421200-1939237735.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　&lt;span&gt;&lt;strong&gt;　完整代码：&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;　　　　&lt;span&gt;注意：Icon和message均是来自于antd组件库，如若没装antd，改成别的元素即可&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;36&quot;&gt;
&lt;pre&gt;
import React from 'react'&lt;span&gt;;
import &lt;/span&gt;'./App.css'&lt;span&gt;;
import {Icon, message} from &lt;/span&gt;'antd'&lt;span&gt;;
class App extends React.Component{
      &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;一键复制功能&lt;/span&gt;
&lt;span&gt;    copy() {
      const copyEle &lt;/span&gt;= document.querySelector('.contentText') &lt;span&gt;//&lt;/span&gt;&lt;span&gt; 获取要复制的节点&lt;/span&gt;
      const range = document.createRange(); &lt;span&gt;//&lt;/span&gt;&lt;span&gt; 创造range&lt;/span&gt;
      window.getSelection().removeAllRanges(); &lt;span&gt;//&lt;/span&gt;&lt;span&gt;清除页面中已有的selection&lt;/span&gt;
      range.selectNode(copyEle); &lt;span&gt;//&lt;/span&gt;&lt;span&gt; 选中需要复制的节点&lt;/span&gt;
      window.getSelection().addRange(range); &lt;span&gt;//&lt;/span&gt;&lt;span&gt; 执行选中元素&lt;/span&gt;
      const copyStatus = document.execCommand(&quot;Copy&quot;); &lt;span&gt;//&lt;/span&gt;&lt;span&gt; 执行copy操作&lt;/span&gt;
      &lt;span&gt;//&lt;/span&gt;&lt;span&gt; 对成功与否定进行提示&lt;/span&gt;
      &lt;span&gt;if&lt;/span&gt;&lt;span&gt; (copyStatus) {
        message.success(&lt;/span&gt;'复制成功'&lt;span&gt;);
      } &lt;/span&gt;&lt;span&gt;else&lt;/span&gt;&lt;span&gt; {
        message.fail(&lt;/span&gt;'复制失败'&lt;span&gt;);
      }
      window.getSelection().removeAllRanges(); &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;清除页面中已有的selection&lt;/span&gt;
&lt;span&gt;    }
  render() {
    &lt;/span&gt;&lt;span&gt;return&lt;/span&gt;&lt;span&gt; (
      &lt;/span&gt;&amp;lt;div className=&quot;App&quot;&amp;gt;
        &amp;lt;div className=&quot;content&quot;&amp;gt;
          &amp;lt;p className=&quot;contentTitle&quot;&amp;gt;
            &amp;lt;&lt;span&gt;Icon 
              type&lt;/span&gt;=&quot;copy&quot;&lt;span&gt; 
              onClick&lt;/span&gt;={&lt;span&gt;this&lt;/span&gt;.copy}/&amp;gt;
          &amp;lt;/p&amp;gt;
          &amp;lt;p className=&quot;contentText&quot;&amp;gt;&lt;span&gt;
            我是要被复制的内容啊！！！
          &lt;/span&gt;&amp;lt;/p&amp;gt;
        &amp;lt;/div&amp;gt;
      &amp;lt;/div&amp;gt;
&lt;span&gt;    );
  }
}

export &lt;/span&gt;&lt;span&gt;default&lt;/span&gt; App;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;　　&lt;span&gt;&lt;strong&gt;原理：&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　我们来看一下具体的步骤：（具体API使用可以查阅MDN）&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　1. &lt;/span&gt;document.querySelector('.contentText') 获取需要复制的节点&lt;/p&gt;
&lt;p&gt;　　2. document.createRange(); 创造一个区域&lt;/p&gt;
&lt;p&gt;　　3. window.getSelection().removeAllRanges(); 将所有选区都清除(即被按住鼠标划中选择的部分)&lt;/p&gt;
&lt;p&gt;　　4. range.selectNode(copyEle)； 选中区域要包含的对象&lt;/p&gt;
&lt;p&gt;　　5. document.execCommand(&quot;Copy&quot;); execCommand方法允许运行命令来操纵可编辑内容区域的元素。&lt;/p&gt;
&lt;p&gt;　　6.判断成功与否&lt;/p&gt;
&lt;p&gt;　　7.window.getSelection().removeAllRanges(); 将所有选区都清除(即被按住鼠标划中选择的部分)&lt;/p&gt;

&lt;p&gt;&lt;span&gt; &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;通过以上的步骤，一键复制就做好啦！！&lt;/span&gt;&lt;/p&gt;
</description>
<pubDate>Thu, 19 Dec 2019 17:13:00 +0000</pubDate>
<dc:creator>一只菜鸟攻城狮啊</dc:creator>
<og:description>如题，我们怎么在React或者其他的框架中实现一键复制呢，实际上实现一键复制的代码与框架无关，因为他是用的是原生的API，下面我们用React来实现一下 效果： 核心代码： 直接将红框处改为需要复制的</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/suihang/p/12071117.html</dc:identifier>
</item>
<item>
<title>RocketMQ 整合 DLedger(多副本)即主从切换实现平滑升级的设计技巧 - 中间件兴趣圈</title>
<link>http://www.cnblogs.com/dingwpmz/p/12070842.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/dingwpmz/p/12070842.html</guid>
<description>&lt;p&gt;源码分析 RocketMQ DLedger 多副本系列已经进行到第 8 篇了，前面的章节主要是介绍了基于 raft 协议的选主与日志复制，从本篇开始将开始关注如何将 DLedger 应用到 RocketMQ中。&lt;/p&gt;
&lt;p&gt;摘要：详细分析了RocketMQ DLedger 多副本(主从切换) 是如何整合到 RocketMQ中，本文的行文思路首先结合已掌握的DLedger 多副本相关的知识初步思考其实现思路，然后从 Broker启动流程、DLedgerCommitlog 核心类的讲解，再从消息发送(追加)与消息查找来进一步探讨 DLedger 是如何支持平滑升级的。&lt;/p&gt;
&lt;p&gt;@(本节目录)&lt;/p&gt;
&lt;h2 id=&quot;阅读源码之前的思考&quot;&gt;1、阅读源码之前的思考&lt;/h2&gt;
&lt;p&gt;RocketMQ 的消息存储文件主要包括 commitlog 文件、consumequeue 文件与 Index 文件。commitlog 文件存储全量的消息，consumequeue、index 文件都是基于 commitlog 文件构建的。要使用 DLedger 来实现消息存储的一致性，应该关键是要实现 commitlog 文件的一致性，即 DLedger 要整合的对象应该是 commitlog 文件，即只需保证 raft 协议的复制组内各个节点的 commitlog 文件一致即可。&lt;/p&gt;
&lt;p&gt;我们知道使用文件存储消息都会基于一定的存储格式，rocketmq 的 commitlog 一个条目就包含魔数、消息长度，消息属性、消息体等，而我们再来回顾一下 DLedger 日志的存储格式：&lt;br/&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20191003120527109.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70&quot; alt=&quot;在这里插入图片描述&quot;/&gt;&lt;br/&gt;DLedger 要整合 commitlog 文件，是不是可以把 rocketmq 消息，即一个个 commitlog 条目整体当成 DLedger 的 body 字段即可。&lt;/p&gt;
&lt;p&gt;还等什么，跟我一起来看源码吧！！！别急，再抛一个问题，DLedger 整合 RocketMQ commitlog，能不能做到平滑升级？&lt;/p&gt;
&lt;p&gt;带着这些思考和问题，一起来探究 DLedger 是如何整合 RocketMQ 的。&lt;/p&gt;
&lt;h2 id=&quot;从-broker-启动流程看-dledger&quot;&gt;2、从 Broker 启动流程看 DLedger&lt;/h2&gt;
&lt;blockquote readability=&quot;7&quot;&gt;
&lt;p&gt;温馨提示：本文不会详细介绍 Broker 端的启动流程，只会点出在启动过程中与 DLedger 相关的代码，如想详细了解 Broker 的启动流程，建议关注笔者的《RocketMQ技术内幕》一书。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Broker 涉及到 DLedger 相关关键点如下：&lt;br/&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20191003120628182.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70&quot; alt=&quot;在这里插入图片描述&quot;/&gt;&lt;/p&gt;
&lt;h3 id=&quot;构建-defaultmessagestore&quot;&gt;2.1 构建 DefaultMessageStore&lt;/h3&gt;
&lt;p&gt;DefaultMessageStore 构造方法&lt;/p&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;if(messageStoreConfig.isEnableDLegerCommitLog()) {  // @1
    this.commitLog = new DLedgerCommitLog(this);
 else {
    this.commitLog = new CommitLog(this);                    // @2
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;代码@1：如果开启 DLedger ，commitlog 的实现类为 DLedgerCommitLog，也是本文需要关注的关键所在。&lt;/p&gt;
&lt;p&gt;代码@2：如果未开启 DLedger，则使用旧版的 Commitlog实现类。&lt;/p&gt;
&lt;h3 id=&quot;增加节点状态变更事件监听器&quot;&gt;2.2 增加节点状态变更事件监听器&lt;/h3&gt;
&lt;p&gt;BrokerController#initialize&lt;/p&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;if (messageStoreConfig.isEnableDLegerCommitLog()) {
    DLedgerRoleChangeHandler roleChangeHandler = new DLedgerRoleChangeHandler(this, (DefaultMessageStore) messageStore);
    ((DLedgerCommitLog)((DefaultMessageStore) messageStore).getCommitLog()).getdLedgerServer().getdLedgerLeaderElector().addRoleChangeHandler(roleChangeHandler);
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;主要调用 LedgerLeaderElector 的 addRoleChanneHandler 方法增加 节点角色变更事件监听器，DLedgerRoleChangeHandler 是实现主从切换的另外一个关键点。&lt;/p&gt;
&lt;h3 id=&quot;调用-defaultmessagestore-的-load-方法&quot;&gt;2.3 调用 DefaultMessageStore 的 load 方法&lt;/h3&gt;
&lt;p&gt;DefaultMessageStore#load&lt;/p&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;// load Commit Log
result = result &amp;amp;&amp;amp; this.commitLog.load();   // @1
// load Consume Queue
result = result &amp;amp;&amp;amp; this.loadConsumeQueue();  
if (result) {
    this.storeCheckpoint =  new StoreCheckpoint(StorePathConfigHelper.getStoreCheckpoint(this.messageStoreConfig.getStorePathRootDir()));
    this.indexService.load(lastExitOK);
    this.recover(lastExitOK);                         // @2
    log.info(&quot;load over, and the max phy offset = {}&quot;, this.getMaxPhyOffset());
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;代码@1、@2 最终都是委托 commitlog 对象来执行，这里的关键又是如果开启了 DLedger，则最终调用的是 DLedgerCommitLog。&lt;/p&gt;
&lt;p&gt;经过上面的铺垫，主角 DLedgerCommitLog “闪亮登场“了。&lt;/p&gt;
&lt;h2 id=&quot;dledgercommitlog-详解&quot;&gt;3、DLedgerCommitLog 详解&lt;/h2&gt;
&lt;p&gt;温馨提示：由于 Commitlog 的绝大部分方法都已经在《RocketMQ技术内幕》一书中详细介绍了，并且 DLedgerCommitLog 的实现原理与 Commitlog 文件的实现原理类同，本文会一笔带过关于存储部分的实现细节。&lt;/p&gt;
&lt;h3 id=&quot;核心类图&quot;&gt;3.1 核心类图&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20191003120747775.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70&quot; alt=&quot;在这里插入图片描述&quot;/&gt;&lt;br/&gt;DLedgerCommitlog 继承自 Commitlog。让我们一一来看一下它的核心属性。&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;DLedgerServer dLedgerServer&lt;br/&gt;基于 raft 协议实现的集群内的一个节点，用 DLedgerServer 实例表示。&lt;/li&gt;
&lt;li&gt;DLedgerConfig dLedgerConfig&lt;br/&gt;DLedger 的配置信息。&lt;/li&gt;
&lt;li&gt;DLedgerMmapFileStore dLedgerFileStore&lt;br/&gt;DLedger 基于文件映射的存储实现。&lt;/li&gt;
&lt;li&gt;MmapFileList dLedgerFileList&lt;br/&gt;DLedger 所管理的存储文件集合，对比 RocketMQ 中的 MappedFileQueue。&lt;/li&gt;
&lt;li&gt;int id&lt;br/&gt;节点ID，0 表示主节点，非0表示从节点&lt;/li&gt;
&lt;li&gt;MessageSerializer messageSerializer&lt;br/&gt;消息序列器。&lt;/li&gt;
&lt;li&gt;long beginTimeInDledgerLock = 0&lt;br/&gt;用于记录 消息追加的时耗(日志追加所持有锁时间)。&lt;/li&gt;
&lt;li&gt;long dividedCommitlogOffset = -1&lt;br/&gt;记录的旧 commitlog 文件中的最大偏移量，如果访问的偏移量大于它，则访问 dledger 管理的文件。&lt;/li&gt;
&lt;li&gt;boolean isInrecoveringOldCommitlog = false&lt;br/&gt;是否正在恢复旧的 commitlog 文件。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;接下来我们将详细介绍 DLedgerCommitlog 各个核心方法及其实现要点。&lt;/p&gt;
&lt;h3 id=&quot;构造方法&quot;&gt;3.2 构造方法&lt;/h3&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;public DLedgerCommitLog(final DefaultMessageStore defaultMessageStore) {
    super(defaultMessageStore);                   // @1
    dLedgerConfig =  new DLedgerConfig();
    dLedgerConfig.setEnableDiskForceClean(defaultMessageStore.getMessageStoreConfig().isCleanFileForciblyEnable());
    dLedgerConfig.setStoreType(DLedgerConfig.FILE);
    dLedgerConfig.setSelfId(defaultMessageStore.getMessageStoreConfig().getdLegerSelfId());
    dLedgerConfig.setGroup(defaultMessageStore.getMessageStoreConfig().getdLegerGroup());
    dLedgerConfig.setPeers(defaultMessageStore.getMessageStoreConfig().getdLegerPeers());
    dLedgerConfig.setStoreBaseDir(defaultMessageStore.getMessageStoreConfig().getStorePathRootDir());
    dLedgerConfig.setMappedFileSizeForEntryData(defaultMessageStore.getMessageStoreConfig().getMapedFileSizeCommitLog());
    dLedgerConfig.setDeleteWhen(defaultMessageStore.getMessageStoreConfig().getDeleteWhen());
    dLedgerConfig.setFileReservedHours(defaultMessageStore.getMessageStoreConfig().getFileReservedTime() + 1);  
    id = Integer.valueOf(dLedgerConfig.getSelfId().substring(1)) + 1;            // @2
    dLedgerServer = new DLedgerServer(dLedgerConfig);                           // @3
    dLedgerFileStore = (DLedgerMmapFileStore) dLedgerServer.getdLedgerStore();
    DLedgerMmapFileStore.AppendHook appendHook = (entry, buffer, bodyOffset) -&amp;gt; {
            assert bodyOffset == DLedgerEntry.BODY_OFFSET;
            buffer.position(buffer.position() + bodyOffset + MessageDecoder.PHY_POS_POSITION);
            buffer.putLong(entry.getPos() + bodyOffset);
    };
    dLedgerFileStore.addAppendHook(appendHook);   // @4
    dLedgerFileList = dLedgerFileStore.getDataFileList();
    this.messageSerializer = new MessageSerializer(defaultMessageStore.getMessageStoreConfig().getMaxMessageSize());   // @5
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;代码@1：调用父类 即 CommitLog 的构造函数，加载 ${ROCKETMQ_HOME}/store/ comitlog 下的 commitlog 文件，以便兼容升级 DLedger 的消息。我们稍微看一下 CommitLog 的构造函数：&lt;br/&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20191003120936564.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70&quot; alt=&quot;在这里插入图片描述&quot;/&gt;&lt;br/&gt;代码@2：构建 DLedgerConfig 相关配置属性，其主要属性如下：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;enableDiskForceClean&lt;br/&gt;是否强制删除文件，取自 broker 配置属性 cleanFileForciblyEnable，默认为 true 。&lt;/li&gt;
&lt;li&gt;storeType&lt;br/&gt;DLedger 存储类型，固定为 基于文件的存储模式。&lt;/li&gt;
&lt;li&gt;dLegerSelfId&lt;br/&gt;leader 节点的 id 名称，示例配置：n0，其配置要求第二个字符后必须是数字。&lt;/li&gt;
&lt;li&gt;dLegerGroup&lt;br/&gt;DLeger group 的名称，建议与 broker 配置属性 brokerName 保持一致。&lt;/li&gt;
&lt;li&gt;dLegerPeers&lt;br/&gt;DLeger Group 中所有的节点信息，其配置示例 n0-127.0.0.1:40911;n1-127.0.0.1:40912;n2-127.0.0.1:40913。多个节点使用分号隔开。&lt;/li&gt;
&lt;li&gt;storeBaseDir&lt;br/&gt;设置 DLedger 的日志文件的根目录，取自 borker 配件文件中的 storePathRootDir ，即 RocketMQ 的数据存储根路径。&lt;/li&gt;
&lt;li&gt;mappedFileSizeForEntryData&lt;br/&gt;设置 DLedger 的单个日志文件的大小，取自 broker 配置文件中的 - mapedFileSizeCommitLog，即与 commitlog 文件的单个文件大小一致。&lt;/li&gt;
&lt;li&gt;deleteWhen&lt;br/&gt;DLedger 日志文件的删除时间，取自 broker 配置文件中的 deleteWhen，默认为凌晨 4点。&lt;/li&gt;
&lt;li&gt;fileReservedHours&lt;br/&gt;DLedger 日志文件保留时长，取自 broker 配置文件中的 fileReservedHours，默认为 72h。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;代码@3：根据 DLedger 配置信息创建 DLedgerServer，即创建 DLedger 集群节点，集群内各个节点启动后，就会触发选主。&lt;/p&gt;
&lt;p&gt;代码@4：构建 appendHook 追加钩子函数，这是兼容 Commitlog 文件很关键的一步，后面会详细介绍其作用。&lt;/p&gt;
&lt;p&gt;代码@5：构建消息序列化。&lt;/p&gt;
&lt;p&gt;根据上述的流程图，构建好 DefaultMessageStore 实现后，就是调用其 load 方法，在启用 DLedger 机制后，会依次调用 DLedgerCommitlog 的 load、recover 方法。&lt;/p&gt;
&lt;h3 id=&quot;load&quot;&gt;3.3 load&lt;/h3&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;public boolean load() {
    boolean result = super.load();
    if (!result) {
        return false;
    }
    return true;
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;DLedgerCommitLog 的 laod 方法实现比较简单，就是调用 其父类 Commitlog 的 load 方法，即这里也是为了启用 DLedger 时能够兼容以前的消息。&lt;/p&gt;
&lt;h3 id=&quot;recover&quot;&gt;3.4 recover&lt;/h3&gt;
&lt;p&gt;在 Broker 启动时会加载 commitlog、consumequeue等文件，需要恢复其相关是数据结构，特别是与写入、刷盘、提交等指针，其具体调用 recover 方法。&lt;br/&gt;DLedgerCommitLog#recover&lt;/p&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;public void recoverNormally(long maxPhyOffsetOfConsumeQueue) {  // @1
    recover(maxPhyOffsetOfConsumeQueue);
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;首先会先恢复 consumequeue，得出 consumequeue 中记录的最大有效物理偏移量，然后根据该物理偏移量进行恢复。&lt;br/&gt;接下来看一下该方法的处理流程与关键点。&lt;/p&gt;
&lt;p&gt;DLedgerCommitLog#recover&lt;/p&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;dLedgerFileStore.load();&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;Step1：加载 DLedger 相关的存储文件，并一一构建对应的 MmapFile，其初始化三个重要的指针 wrotePosition、flushedPosition、committedPosition 三个指针为文件的大小。&lt;/p&gt;
&lt;p&gt;DLedgerCommitLog#recover&lt;/p&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;if (dLedgerFileList.getMappedFiles().size() &amp;gt; 0) {   
    dLedgerFileStore.recover();   // @1
    dividedCommitlogOffset = dLedgerFileList.getFirstMappedFile().getFileFromOffset();     // @2
    MappedFile mappedFile = this.mappedFileQueue.getLastMappedFile();
    if (mappedFile != null) {                                                                                                       // @3
        disableDeleteDledger();
    }
    long maxPhyOffset = dLedgerFileList.getMaxWrotePosition();
    // Clear ConsumeQueue redundant data
    if (maxPhyOffsetOfConsumeQueue &amp;gt;= maxPhyOffset) {      // @4
        log.warn(&quot;[TruncateCQ]maxPhyOffsetOfConsumeQueue({}) &amp;gt;= processOffset({}), truncate dirty logic files&quot;, maxPhyOffsetOfConsumeQueue, maxPhyOffset);
        this.defaultMessageStore.truncateDirtyLogicFiles(maxPhyOffset);
    }
    return;
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;Step2：如果已存在 DLedger 的数据文件，则只需要恢复 DLedger 相关数据文建，因为在加载旧的 commitlog 文件时已经将其重要的数据指针设置为最大值。其关键实现点如下：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;首先调用 DLedger 文件存储实现类 DLedgerFileStore 的 recover 方法，恢复管辖的 MMapFile 对象(一个文件对应一个MMapFile实例)的相关指针，其实现方法与 RocketMQ 的 DefaultMessageStore 的恢复过程类似。&lt;/li&gt;
&lt;li&gt;设置 dividedCommitlogOffset 的值为 DLedger 中所有物理文件的最小偏移量。操作消息的物理偏移量小于该值，则从 commitlog 文件中查找；物理偏移量大于等于该值的话则从 DLedger 相关的文件中查找消息。&lt;/li&gt;
&lt;li&gt;如果存在旧的 commitlog 文件，则禁止删除 DLedger 文件，其具体做法就是禁止强制删除文件，并将文件的有效存储时间设置为 10 年。&lt;/li&gt;
&lt;li&gt;如果 consumequeue 中存储的最大物理偏移量大于 DLedger 中最大的物理偏移量，则删除多余的 consumequeue 文件。&lt;/li&gt;
&lt;/ul&gt;&lt;blockquote readability=&quot;11&quot;&gt;
&lt;p&gt;温馨提示：为什么当存在 commitlog 文件的情况下，不能删除 DLedger 相关的日志文件呢？&lt;/p&gt;
&lt;p&gt;因为在此种情况下，如果 DLedger 中的物理文件有删除，则物理偏移量会断层。&lt;br/&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20191003143959204.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70&quot; alt=&quot;在这里插入图片描述&quot;/&gt;&lt;br/&gt;正常情况下， maxCommitlogPhyOffset 与 dividedCommitlogOffset 是连续的，这样非常方便是访问 commitlog 还是 访问 DLedger ，但如果DLedger 部分文件删除后，这两个值就变的不连续，就会造成中间的文件空洞，无法被连续访问。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;DLedgerCommitLog#recover&lt;/p&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;isInrecoveringOldCommitlog = true;
super.recoverNormally(maxPhyOffsetOfConsumeQueue);
isInrecoveringOldCommitlog = false;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;Step3：如果启用了 DLedger 并且是初次启动(还未生成 DLedger 相关的日志文件)，则需要恢复 旧的 commitlog 文件。&lt;/p&gt;
&lt;p&gt;DLedgerCommitLog#recover&lt;/p&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;MappedFile mappedFile = this.mappedFileQueue.getLastMappedFile();
if (mappedFile == null) {           // @1
    return;
}
ByteBuffer byteBuffer =  mappedFile.sliceByteBuffer();
byteBuffer.position(mappedFile.getWrotePosition());
boolean needWriteMagicCode = true;
// 1 TOTAL SIZE
byteBuffer.getInt(); //size
int magicCode = byteBuffer.getInt();
if (magicCode == CommitLog.BLANK_MAGIC_CODE) {   // @2
    needWriteMagicCode = false;
} else {
    log.info(&quot;Recover old commitlog found a illegal magic code={}&quot;, magicCode);
}
dLedgerConfig.setEnableDiskForceClean(false);
dividedCommitlogOffset = mappedFile.getFileFromOffset() + mappedFile.getFileSize();   // @3
log.info(&quot;Recover old commitlog needWriteMagicCode={} pos={} file={} dividedCommitlogOffset={}&quot;, needWriteMagicCode, mappedFile.getFileFromOffset() + mappedFile.getWrotePosition(), mappedFile.getFileName(), dividedCommitlogOffset);
if (needWriteMagicCode) {  // @4
    byteBuffer.position(mappedFile.getWrotePosition());
    byteBuffer.putInt(mappedFile.getFileSize() - mappedFile.getWrotePosition());
    byteBuffer.putInt(BLANK_MAGIC_CODE);
    mappedFile.flush(0);
}
mappedFile.setWrotePosition(mappedFile.getFileSize());   // @5
mappedFile.setCommittedPosition(mappedFile.getFileSize());
mappedFile.setFlushedPosition(mappedFile.getFileSize());
dLedgerFileList.getLastMappedFile(dividedCommitlogOffset);
log.info(&quot;Will set the initial commitlog offset={} for dledger&quot;, dividedCommitlogOffset);
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;Step4：如果存在旧的 commitlog 文件，需要将最后的文件剩余部分全部填充，即不再接受新的数据写入，新的数据全部写入到 DLedger 的数据文件中。其关键实现点如下：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;尝试查找最后一个 commitlog 文件，如果未找到，则结束。&lt;/li&gt;
&lt;li&gt;从最后一个文件的最后写入点(原 commitlog 文件的 待写入位点)尝试去查找写入的魔数，如果存在魔数并等于 CommitLog.BLANK_MAGIC_CODE，则无需再写入魔数，在升级 DLedger 第一次启动时，魔数为空，故需要写入魔数。&lt;/li&gt;
&lt;li&gt;初始化 dividedCommitlogOffset ，等于最后一个文件的起始偏移量加上文件的大小，即该指针指向最后一个文件的结束位置。&lt;/li&gt;
&lt;li&gt;将最后一个 commitlog 未写满的数据全部写入，其方法为 设置消息体的 size 与 魔数即可。&lt;/li&gt;
&lt;li&gt;设置最后一个文件的 wrotePosition、flushedPosition、committedPosition 为文件的大小，同样有意味者最后一个文件已经写满，下一条消息将写入 DLedger 中。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;在启用 DLedger 机制时 Broker 的启动流程就介绍到这里了，相信大家已经了解 DLedger 在整合 RocketMQ 上做的努力，接下来我们从消息追加、消息读取两个方面再来探讨 DLedger 是如何无缝整合 RocketMQ 的，实现平滑升级的。&lt;/p&gt;
&lt;h2 id=&quot;从消息追加看-dledger-整合-rocketmq-如何实现无缝兼容&quot;&gt;4、从消息追加看 DLedger 整合 RocketMQ 如何实现无缝兼容&lt;/h2&gt;
&lt;blockquote readability=&quot;7&quot;&gt;
&lt;p&gt;温馨提示：本节同样也不会详细介绍整个消息追加(存储流程)，只是要点出与 DLedger(多副本、主从切换)相关的核心关键点。如果想详细了解消息追加的流程，可以阅读笔者所著的《RocketMQ技术内幕》一书。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;DLedgerCommitLog#putMessage&lt;/p&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;AppendEntryRequest request = new AppendEntryRequest();
request.setGroup(dLedgerConfig.getGroup());
request.setRemoteId(dLedgerServer.getMemberState().getSelfId());
request.setBody(encodeResult.data);
dledgerFuture = (AppendFuture&amp;lt;AppendEntryResponse&amp;gt;) dLedgerServer.handleAppend(request);
if (dledgerFuture.getPos() == -1) {
    return new PutMessageResult(PutMessageStatus.OS_PAGECACHE_BUSY, new AppendMessageResult(AppendMessageStatus.UNKNOWN_ERROR));
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;关键点一：消息追加时，则不再写入到原先的 commitlog 文件中，而是调用 DLedgerServer 的 handleAppend 进行消息追加，该方法会有集群内的 Leader 节点负责消息追加以及在消息复制，只有超过集群内的半数节点成功写入消息后，才会返回写入成功。如果追加成功，将会返回本次追加成功后的起始偏移量，即 pos 属性，即类似于 rocketmq 中 commitlog 的偏移量，即物理偏移量。&lt;/p&gt;
&lt;p&gt;DLedgerCommitLog#putMessage&lt;/p&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;long wroteOffset =  dledgerFuture.getPos() + DLedgerEntry.BODY_OFFSET;
ByteBuffer buffer = ByteBuffer.allocate(MessageDecoder.MSG_ID_LENGTH);
String msgId = MessageDecoder.createMessageId(buffer, msg.getStoreHostBytes(), wroteOffset);
eclipseTimeInLock = this.defaultMessageStore.getSystemClock().now() - beginTimeInDledgerLock;
appendResult = new AppendMessageResult(AppendMessageStatus.PUT_OK, wroteOffset, encodeResult.data.length, msgId, System.currentTimeMillis(), queueOffset, eclipseTimeInLock);&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;关键点二：根据 DLedger 的起始偏移量计算真正的消息的物理偏移量，从开头部分得知，DLedger 自身有其存储协议，其 body 字段存储真实的消息，即 commitlog 条目的存储结构，返回给客户端的消息偏移量为 body 字段的开始偏移量，即通过 putMessage 返回的物理偏移量与不使用Dledger 方式返回的物理偏移量的含义是一样的，即从开偏移量开始，可以正确读取消息，这样 DLedger 完美的兼容了 RocketMQ Commitlog。关于 pos 以及 wroteOffset 的图解如下：&lt;br/&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20191003152522946.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70&quot; alt=&quot;在这里插入图片描述&quot;/&gt;&lt;/p&gt;
&lt;h2 id=&quot;从消息读取看-dledger-整合-rocketmq-如何实现无缝兼容&quot;&gt;5、从消息读取看 DLedger 整合 RocketMQ 如何实现无缝兼容&lt;/h2&gt;
&lt;p&gt;DLedgerCommitLog#getMessage&lt;/p&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;public SelectMappedBufferResult getMessage(final long offset, final int size) {
    if (offset &amp;lt; dividedCommitlogOffset) {   // @1
        return super.getMessage(offset, size);
    }
    int mappedFileSize = this.dLedgerServer.getdLedgerConfig().getMappedFileSizeForEntryData();
    MmapFile mappedFile = this.dLedgerFileList.findMappedFileByOffset(offset, offset == 0);   // @2
    if (mappedFile != null) {
        int pos = (int) (offset % mappedFileSize);
        return  convertSbr(mappedFile.selectMappedBuffer(pos, size));                                       // @3
    }
    return null;
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;消息查找比较简单，因为返回给客户端消息，转发给 consumequeue 的消息物理偏移量并不是 DLedger 条目的偏移量，而是真实消息的起始偏移量。其实现关键点如下：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;如果查找的物理偏移量小于 dividedCommitlogOffset，则从原先的 commitlog 文件中查找。&lt;/li&gt;
&lt;li&gt;然后根据物理偏移量按照二分方找到具体的物理文件。&lt;/li&gt;
&lt;li&gt;对物理偏移量取模，得出在该物理文件中中的绝对偏移量，进行消息查找即可，因为只有知道其物理偏移量，从该处先将消息的长度读取出来，然后即可读出一条完整的消息。&lt;/li&gt;
&lt;/ul&gt;&lt;h2 id=&quot;总结&quot;&gt;5、总结&lt;/h2&gt;
&lt;p&gt;根据上面详细的介绍，我想读者朋友们应该不难得出如下结论：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;DLedger 在整合时，使用 DLedger 条目包裹 RocketMQ 中的 commitlog 条目，即在 DLedger 条目的 body 字段来存储整条 commitlog 条目。&lt;/li&gt;
&lt;li&gt;引入 dividedCommitlogOffset 变量，表示物理偏移量小于该值的消息存在于旧的 commitlog 文件中，实现 升级 DLedger 集群后能访问到旧的数据。&lt;/li&gt;
&lt;li&gt;新 DLedger 集群启动后，会将最后一个 commitlog 填充，即新的数据不会再写入到 原先的 commitlog 文件。&lt;/li&gt;
&lt;li&gt;消息追加到 DLedger 数据日志文件中，返回的偏移量不是 DLedger 条目的起始偏移量，而是DLedger 条目中 body 字段的起始偏移量，即真实消息的起始偏移量，保证消息物理偏移量的语义与 RocketMQ Commitlog一样。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;RocketMQ 整合 DLedger(多副本)实现平滑升级的设计技巧就介绍到这里了。&lt;/p&gt;
&lt;p&gt;如果本文对您有一定的帮助话，麻烦帮忙点个赞，非常感谢。&lt;/p&gt;
&lt;hr/&gt;&lt;p&gt;推荐阅读：源码分析 RocketMQ DLedger 多副本即主从切换系列文章：&lt;br/&gt;1、&lt;a href=&quot;https://blog.csdn.net/prestigeding/article/details/99101912&quot;&gt;RocketMQ 多副本前置篇：初探raft协议&lt;/a&gt;&lt;br/&gt;2、&lt;a href=&quot;https://blog.csdn.net/prestigeding/article/details/99697323&quot;&gt;源码分析 RocketMQ DLedger 多副本之 Leader 选主&lt;/a&gt;&lt;br/&gt;3、&lt;a href=&quot;https://blog.csdn.net/prestigeding/article/details/100177780&quot;&gt;源码分析 RocketMQ DLedger 多副本存储实现&lt;/a&gt;&lt;br/&gt;4、&lt;a href=&quot;https://blog.csdn.net/prestigeding/article/details/100835869&quot;&gt;源码分析 RocketMQ DLedger(多副本) 之日志追加流程&lt;/a&gt;&lt;br/&gt;5、&lt;a href=&quot;https://blog.csdn.net/prestigeding/article/details/100836389&quot;&gt;源码分析 RocketMQ DLedger(多副本) 之日志复制(传播)&lt;/a&gt;&lt;br/&gt;6、&lt;a href=&quot;https://blog.csdn.net/prestigeding/article/details/101629440&quot;&gt;基于 raft 协议的 RocketMQ DLedger 多副本日志复制设计原理&lt;/a&gt;&lt;/p&gt;
&lt;hr/&gt;&lt;blockquote readability=&quot;7.1544715447154&quot;&gt;
&lt;p&gt;作者介绍：丁威，《RocketMQ技术内幕》作者，RocketMQ 社区布道师，公众号：&lt;a href=&quot;https://mp.weixin.qq.com/s/LB7k8A06BgssXy9bxfZC3w&quot;&gt;中间件兴趣圈&lt;/a&gt; 维护者，目前已陆续发表源码分析Java集合、Java 并发包(JUC)、Netty、Mycat、Dubbo、RocketMQ、Mybatis等源码专栏。可以点击链接加入&lt;a href=&quot;https://t.zsxq.com/QbYNzZN&quot;&gt;中间件知识星球&lt;/a&gt; ，一起探讨高并发、分布式服务架构，交流源码。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&quot;https://user-gold-cdn.xitu.io/2019/10/4/16d96ea30af7333a?w=258&amp;amp;h=258&amp;amp;f=jpeg&amp;amp;s=27623&quot; alt=&quot;在这里插入图片描述&quot;/&gt;&lt;/p&gt;
</description>
<pubDate>Thu, 19 Dec 2019 15:10:00 +0000</pubDate>
<dc:creator>中间件兴趣圈</dc:creator>
<og:description>源码分析 RocketMQ DLedger 多副本系列已经进行到第 8 篇了，前面的章节主要是介绍了基于 raft 协议的选主与日志复制，从本篇开始将开始关注如何将 DLedger 应用到 Rocke</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/dingwpmz/p/12070842.html</dc:identifier>
</item>
<item>
<title>从多核CPU Cache一致性的应用到分布式系统一致性的概念迁移 - 奔跑的猪0101</title>
<link>http://www.cnblogs.com/king0101/p/12070822.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/king0101/p/12070822.html</guid>
<description>&lt;h2&gt;&lt;span&gt;&lt;strong&gt;概述&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;
&lt;p&gt;      现代多核CPU的cache模型基本都跟下图1所示一样，L1 L2 cache是每个核独占的，只有L3是共享的，当多个cpu读、写同一个变量时，就需要在多个cpu的cache之间同步数据，跟分布式系统一样，必然涉及到一致性的问题，只不过两者之间共享内容的方式不一样而已，一个通过共享内存来共享内容，另一个通过网络消息传递来共享内容。就像&lt;a href=&quot;https://en.wikipedia.org/wiki/CPU_cache&quot; target=&quot;_blank&quot;&gt;wiki&lt;/a&gt;所提及的：&lt;/p&gt;
&lt;p&gt;Interestingly enough, a shared-memory multiprocessor system really is a message-passing computer under the covers. This means that clusters of SMP machines that use distributed shared memory are using message passing to implement shared memory at two different levels of the system architecture.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/i-beta/1854600/201912/1854600-20191219220308925-1852956349.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt; 图1、现代cpu多级cache&lt;/p&gt;
&lt;h2&gt;&lt;span&gt;&lt;strong&gt;多核一致性与原子操作&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;
&lt;p&gt;        多核一致性最典型的应用场景是多线程的原子操作&lt;span lang=&quot;EN-US&quot;&gt;,其在多线程开发中经常用到，比如在计数器的生成，这类情况下数据有并发的危险，但是用锁去保护又显得有些浪费，所以原子类型操作十分的方便。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;        原子操作虽然用起来简单，但是其背景远比我们想象的要复杂。其主要在于现代计算系统过于的复杂：多处理器、多核处理器、处理器又有核心独有以及核心共享的多级缓存，在这种情况下，一个核心修改了某个变量，其他核心什么时候可见是一个十分严肃的问题。同时在极致最求性能的时代，处理器和编译器往往表现的很智能，进行极度的优化，比如什么乱序执行、指令重排等，虽然可以在当前上下文中做到很好的优化，但是放在多核环境下常常会引出新的问题来，这时候就必须提示编译器和处理器某种提示，告诉某些代码的执行顺序不能被优化。今天我们重点看一下处理器在多线程原子操作上的背景原理以及具体应用。&lt;/p&gt;
&lt;h2&gt;&lt;span&gt;CPU Cache与内存屏障&lt;/span&gt;&lt;/h2&gt;
&lt;p align=&quot;left&quot;&gt;     考虑下面典型的代码：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;33&quot;&gt;
&lt;pre&gt;
-Thread &lt;span&gt;1&lt;/span&gt;-
&lt;span&gt;void&lt;/span&gt; foo(&lt;span&gt;void&lt;/span&gt;&lt;span&gt;)
{
   a &lt;/span&gt;= &lt;span&gt;1&lt;/span&gt;&lt;span&gt;;
   b &lt;/span&gt;= &lt;span&gt;1&lt;/span&gt;&lt;span&gt;;
}
&lt;/span&gt;-Thread &lt;span&gt;2&lt;/span&gt;-
&lt;span&gt;void&lt;/span&gt; bar(&lt;span&gt;void&lt;/span&gt;&lt;span&gt;)
{
   &lt;/span&gt;&lt;span&gt;while&lt;/span&gt; (b == &lt;span&gt;0&lt;/span&gt;) &lt;span&gt;continue&lt;/span&gt;&lt;span&gt;;
   assert(a &lt;/span&gt;== &lt;span&gt;1&lt;/span&gt;&lt;span&gt;);
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;由于cpu cache的存在，thread 2在断言处可能会失败。具体的，由于各个CPU的cache是独立的，所以变量在他们各自的cache里面的顺序可能跟代码的顺序是不一致的，也就是说执行thread2的cpu可能会先看到变量b的变化，然后再看到变量a的变化，导致断言失败。就是我们常见的program order与process order的不一致的工程现象，这里就涉及到了memory consistency model的问题（类似于分布式系统的一致性）。&lt;/p&gt;
&lt;p&gt;       上述的代码如果要正确执行，则变量a、b之间需要有‘happen before’的语义来约束（这里就可以联想到分布式系统中因果一致性的概念）。但是对于这个语义上的需求，硬件设计者也爱莫能助，因为CPU无法知道变量之间的关联关系。所以硬件设计者提供了memory barrier指令，让软件可以通过这些指令来告诉CPU这类关系，实现program order与process order的顺序一致。类似于下面的代码：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;32&quot;&gt;
&lt;pre&gt;
-Thread 1-
&lt;span&gt;void&lt;/span&gt; foo(&lt;span&gt;void&lt;/span&gt;&lt;span&gt;)
{
    a &lt;/span&gt;= &lt;span&gt;1&lt;/span&gt;&lt;span&gt;;
    memory_barrier();
    b &lt;/span&gt;= &lt;span&gt;1&lt;/span&gt;&lt;span&gt;;
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;增加memory barrier之后，就可以保证在执行b=1的时候，cpu已经处理过'a=1'的操作了。也就是说通过硬件提供的memory barrier语义，使得软件能够保证其之前的内存访问操作先于其后的完成。memory barrier 常用的地方包括：实现内核的锁机制、应用层编写无锁代码、原子变量等。下面我们一起看下，c++11是怎样使用内存屏障来实现原子操作的。&lt;/p&gt;
&lt;h2&gt;&lt;span&gt;&lt;strong&gt;C++11的原子操作&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;
&lt;p align=&quot;left&quot;&gt;        在C++11标准出来之前，C++标准没有一个明确的内存模型，各个C++编译器实现者各自为政，随着多线程开发的普及解决这个问题变得越来越迫切。在标准出来之前，GCC的实现是根据Intel的开发手册搞出的一系列的__sync原子操作函数集合，具体如下：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;44&quot;&gt;
&lt;pre&gt;
type __sync_fetch_and_OP (type *&lt;span&gt;ptr, type value, ...)
type __sync_OP_and_fetch (type &lt;/span&gt;*&lt;span&gt;ptr, type value, ...)
bool__sync_bool_compare_and_swap (type &lt;/span&gt;*&lt;span&gt;ptr, type oldval, type newval, ...)
type __sync_val_compare_and_swap (type &lt;/span&gt;*&lt;span&gt;ptr, type oldval, type newval, ...)
__sync_synchronize (...)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p align=&quot;left&quot;&gt;       在C++11新标准中规定的内存模型(memory model)颗粒要比上述的内存模型细化很多，所以软件开发者就有很多的操作空间了，如果熟悉这些内存模型，在保证业务正确的同时可以将对性能的影响减弱到最低，在硬件资源吃紧的地方，这是我们优化程序的一个重要方向。&lt;/p&gt;
&lt;p align=&quot;left&quot;&gt;       我们以c++11的原子变量的保证来展开这些内存模型。原子变量的通用接口使用store()和load()方式进行存取，可以额外接受一个额外的memory order参数，这个参数就是对应了c++11的内存模型，根据执行线程之间对变量的同步需求强度，新标准下的内存模型可以分成如下几类：&lt;/p&gt;
&lt;p align=&quot;left&quot;&gt;&lt;strong&gt;Sequentially Consistent&lt;/strong&gt;&lt;/p&gt;
&lt;p align=&quot;left&quot;&gt;      该模型是最强的同步模式，参数表示为&lt;span lang=&quot;EN-US&quot;&gt;std::memory_order_seq_cst，同时也是默认的模型。&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;32&quot;&gt;
&lt;pre&gt;
-Thread &lt;span&gt;1&lt;/span&gt;-&lt;span&gt;
y &lt;/span&gt;= &lt;span&gt;1&lt;/span&gt;&lt;span&gt;
x.store (&lt;/span&gt;&lt;span&gt;2&lt;/span&gt;&lt;span&gt;); 

&lt;/span&gt;-Thread2-
&lt;span&gt;if&lt;/span&gt;(x.load() ==&lt;span&gt;2&lt;/span&gt;&lt;span&gt;)
assert (y &lt;/span&gt;==&lt;span&gt;1&lt;/span&gt;)
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;       对于上面的例子，即使x和y是不相关的，通常情况下处理器或者编译器可能会对其访问进行重排，但是在seq_cst模式下，x.store(2)之前的所有memory accesses都发生在store操作之前。同时，x.load()之后的所有memory accesses都发生在load()操作之后，也就是说seq_cst模式下，内存的&lt;span lang=&quot;EN-US&quot;&gt;限制是双向的。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Acquire/Release &lt;/strong&gt;&lt;strong&gt;&lt;span lang=&quot;EN-US&quot;&gt;Consistent&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;34&quot;&gt;
&lt;pre&gt;
std::atomic&amp;lt;&lt;span&gt;int&lt;/span&gt;&amp;gt; a{&lt;span&gt;0&lt;/span&gt;&lt;span&gt;};
intb &lt;/span&gt;=&lt;span&gt;0&lt;/span&gt;&lt;span&gt;;&lt;br/&gt;&lt;/span&gt;-Thread &lt;span&gt;1&lt;/span&gt;-&lt;span&gt;
b &lt;/span&gt;= &lt;span&gt;1&lt;/span&gt;&lt;span&gt;;
a.store(&lt;/span&gt;&lt;span&gt;1&lt;/span&gt;&lt;span&gt;, memory_order_release);
&lt;/span&gt;-Thread &lt;span&gt;2&lt;/span&gt;-
&lt;span&gt;while&lt;/span&gt;(a.load(memory_order_acquire) !=&lt;span&gt;1&lt;/span&gt;)&lt;span&gt;/*&lt;/span&gt;&lt;span&gt;waiting&lt;/span&gt;&lt;span&gt;*/&lt;/span&gt;&lt;span&gt;;
std::cout&lt;/span&gt;&amp;lt;&amp;lt; b &amp;lt;&amp;lt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;\n&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;       毫无疑问，如果是memory_order_seq_cst内存模型，那么上面的操作一定是成功的(打印变量b显示为1)。&lt;/p&gt;
&lt;p&gt;       1. memory_order_release保证在这个操作之前的memory accesses不会重排到这个操作之后去，但是这个操作之后的memory accesses可能会重排到这个操作之前去。通常这个主要是用于之前准备某些资源后，通过store+memory_order_release的方式”Release”给别的线程；&lt;/p&gt;
&lt;p&gt;       2. memory_order_acquire保证在这个操作之后的memory accesses不会重排到这个操作之前去，但是这个操作之前的memory accesses可能会重排到这个操作之后去。通常通过load+memory_order_acquire判断或者等待某个资源，一旦满足某个条件后就可以安全的“Acquire”消费这些资源了。&lt;/p&gt;
&lt;p&gt;      这个就是类似于分布式系统的因果一致性的概念。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Relaxed &lt;/strong&gt;&lt;strong&gt;&lt;span lang=&quot;EN-US&quot;&gt;Consistent&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;       这个是最宽松的模式，memory_order_relaxed没有happens-before的约束，编译器和处理器可以对memory access做任何的re-order，因此另外的线程不能对其做任何的假设，这种模式下能做的唯一保证，就是一旦线程读到了变量var的最新值，那么这个线程将再也见不到var修改之前的值了（这个类似于分布式系统单调读保证的概念）。&lt;/p&gt;
&lt;p&gt;       这种情况通常是在需要原子变量，但是不在线程间同步共享数据的时候会用，同时当relaxed存一个数据的时候，另外的线程将需要一个时间才能relaxed读到该值（也就是最终如果变量不再更改的话，所有的线程还是可以读取到变量最终的值的），在非缓存一致性的构架上需要刷新缓存。在开发的时候，如果你的上下文没有共享的变量需要在线程间同步，选用Relaxed就可以了。&lt;/p&gt;
&lt;p&gt;       这一点类似于分布式系统的最终一致性概念了。&lt;/p&gt;
&lt;h2&gt;&lt;strong&gt;&lt;span&gt;总结&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;      上述的过程体现的是强一致性、因果一致性、最终一致性等概念在c++11原子操作的使用，以及当前技术圈非常热门的话题分布式系统开发中分布式一致性概念的思考与迁移。从中我们可以看出技术在发展，但是很多概念其实是一脉相承的，只有深刻理解了概念背后的原理以及相关技术发展的背景，才能勉强跟上技术的发展浪潮。&lt;/p&gt;
</description>
<pubDate>Thu, 19 Dec 2019 15:06:00 +0000</pubDate>
<dc:creator>奔跑的猪0101</dc:creator>
<og:description>概述 现代多核CPU的cache模型基本都跟下图1所示一样，L1 L2 cache是每个核独占的，只有L3是共享的，当多个cpu读、写同一个变量时，就需要在多个cpu的cache之间同步数据，跟分布式</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/king0101/p/12070822.html</dc:identifier>
</item>
<item>
<title>AQS系列（三）- ReentrantReadWriteLock读写锁的加锁 - 张曾经</title>
<link>http://www.cnblogs.com/zzq6032010/p/12037854.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/zzq6032010/p/12037854.html</guid>
<description>&lt;p&gt;&lt;span&gt;&lt;strong&gt;前言&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;    前两篇我们讲述了ReentrantLock的加锁释放锁过程，相对而言比较简单，本篇进入深水区，看看ReentrantReadWriteLock-读写锁的加锁过程是如何实现的，继续拜读老Lea凌厉的代码风。&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;一、读写锁的类图&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;    读锁就是共享锁，而写锁是独占锁。读锁与写锁之间的互斥关系为：&lt;strong&gt;读读可同时执行(有条件的)；读写与写写均互斥执行&lt;/strong&gt;。注意此处读读可并行我用了有条件的并行，后文会对此做介绍。&lt;/p&gt;
&lt;p&gt;    继续奉上一张丑陋的类图：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/i-beta/1558028/201912/1558028-20191213234601770-1651404302.png&quot; alt=&quot;&quot; width=&quot;913&quot; height=&quot;431&quot;/&gt;&lt;/p&gt;
&lt;p&gt;     可以看到ReentrantReadWriteLock维护了五个内部类，ReentrantReadWriteLock中存放了Sync、ReadLock、WriteLock三个成员变量，如下截图所示：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/i-beta/1558028/201912/1558028-20191213234804896-742205633.png&quot; alt=&quot;&quot; width=&quot;744&quot; height=&quot;356&quot;/&gt;&lt;/p&gt;
&lt;p&gt;     而ReadLock和WriteLock中又存放了Sync变量，截图如下所示，这样一组合，有了四种锁，公平读锁、公平写锁、非公平读锁、非公平写锁。对于公平与非公平的实现区别，我们上一篇已经做过讲解，本文将着重关注读锁和写锁的实现区别。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/i-beta/1558028/201912/1558028-20191215111711296-1147175272.png&quot; alt=&quot;&quot; width=&quot;742&quot; height=&quot;305&quot;/&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;二、加锁源码&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;    在前文中我们知道，ReentrantLock中用state来判断当前锁是否被占用，而读写锁ReentrantReadWriteLock中由于同时存在两种锁，所以老Lea用state的高16位来存放读锁的占用状态以及重入次数，低16位存放写锁的占用状态和重入次数。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;1、读锁加锁，即共享锁加锁&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;32&quot;&gt;
&lt;pre&gt;
&lt;span&gt;1&lt;/span&gt; &lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt;&lt;span&gt; lock() {
&lt;/span&gt;&lt;span&gt;2&lt;/span&gt;             sync.acquireShared(1&lt;span&gt;); // 获取共享锁方法
&lt;/span&gt;&lt;span&gt;3&lt;/span&gt;         }
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;    上述lock方法中调用的获取共享锁方法是在AbstractQueuedSynchronizer中实现的，代码如下：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;33&quot;&gt;
&lt;pre&gt;
&lt;span&gt;1&lt;/span&gt; &lt;span&gt;public&lt;/span&gt; &lt;span&gt;final&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; acquireShared(&lt;span&gt;int&lt;/span&gt;&lt;span&gt; arg) {
&lt;/span&gt;&lt;span&gt;2&lt;/span&gt;         &lt;span&gt;if&lt;/span&gt; (tryAcquireShared(arg) &amp;lt; 0&lt;span&gt;)
&lt;/span&gt;&lt;span&gt;3&lt;/span&gt; &lt;span&gt;            doAcquireShared(arg);
&lt;/span&gt;&lt;span&gt;4&lt;/span&gt;     }
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;    可以看到获取共享锁分成了两步，第一步是尝试获取，如果获取不到再进入if里面执行doAcquireShared方法，下面分别追踪。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;1)、tryAcquireShared方法&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;36&quot;&gt;
&lt;pre&gt;
&lt;span&gt; 1&lt;/span&gt; &lt;span&gt;protected&lt;/span&gt; &lt;span&gt;final&lt;/span&gt; &lt;span&gt;int&lt;/span&gt; tryAcquireShared(&lt;span&gt;int&lt;/span&gt;&lt;span&gt; unused) {
&lt;/span&gt;&lt;span&gt; 2&lt;/span&gt;             Thread current =&lt;span&gt; Thread.currentThread();
&lt;/span&gt;&lt;span&gt; 3&lt;/span&gt;             &lt;span&gt;int&lt;/span&gt; c =&lt;span&gt; getState();
&lt;/span&gt;&lt;span&gt; 4&lt;/span&gt;             &lt;span&gt;//&lt;/span&gt;&lt;span&gt; 1.有写锁占用并且不是当前线程，则直接返回获取失败&lt;/span&gt;
&lt;span&gt; 5&lt;/span&gt;             &lt;span&gt;if&lt;/span&gt; (exclusiveCount(c) != 0 &amp;amp;&amp;amp;
&lt;span&gt; 6&lt;/span&gt;                 getExclusiveOwnerThread() !=&lt;span&gt; current)
&lt;/span&gt;&lt;span&gt; 7&lt;/span&gt;                 &lt;span&gt;return&lt;/span&gt; -1&lt;span&gt;;
&lt;/span&gt;&lt;span&gt; 8&lt;/span&gt;             &lt;span&gt;//&lt;/span&gt;&lt;span&gt; 执行到这里，有两种情况 没有写锁占用或者是当前线程&lt;/span&gt;
&lt;span&gt; 9&lt;/span&gt;             &lt;span&gt;int&lt;/span&gt; r = sharedCount(c); &lt;span&gt;//&lt;/span&gt;&lt;span&gt; 获取读锁次数
&lt;/span&gt;&lt;span&gt;10&lt;/span&gt;             &lt;span&gt;//&lt;/span&gt;&lt;span&gt; 2、不应该阻塞则获取锁  @此方法有点意思，需着重讲解，作用：判断读锁是否需要阻塞&lt;/span&gt;
&lt;span&gt;11&lt;/span&gt;             &lt;span&gt;if&lt;/span&gt; (!readerShouldBlock() &amp;amp;&amp;amp;
&lt;span&gt;12&lt;/span&gt;                 r &amp;lt; MAX_COUNT &amp;amp;&amp;amp;
&lt;span&gt;13&lt;/span&gt;                 compareAndSetState(c, c +&lt;span&gt; SHARED_UNIT)) {
&lt;/span&gt;&lt;span&gt;14&lt;/span&gt;                 &lt;span&gt;//&lt;/span&gt;&lt;span&gt; 如果CAS成功，则将当前线程对应的计数+1&lt;/span&gt;
&lt;span&gt;15&lt;/span&gt;                 &lt;span&gt;if&lt;/span&gt; (r == 0&lt;span&gt;) { // 如果读锁持有数为0，则说明当前线程是第一个reader，分别给firstReader和firstReaderHoldCount初始化
&lt;/span&gt;&lt;span&gt;16&lt;/span&gt;                     firstReader =&lt;span&gt; current;
&lt;/span&gt;&lt;span&gt;17&lt;/span&gt;                     firstReaderHoldCount = 1&lt;span&gt;;
&lt;/span&gt;&lt;span&gt;18&lt;/span&gt;                 } &lt;span&gt;else&lt;/span&gt; &lt;span&gt;if&lt;/span&gt; (firstReader ==&lt;span&gt; current) { // 如果读锁持有数不为0且当前线程就是firstReader，那么直接给firstReaderHoldCount+1，表示读锁重入
&lt;/span&gt;&lt;span&gt;19&lt;/span&gt;                     firstReaderHoldCount++&lt;span&gt;;
&lt;/span&gt;&lt;span&gt;20&lt;/span&gt;                 } &lt;span&gt;else&lt;/span&gt;&lt;span&gt; { // 其他情况，即当前线程不是firstReader且还有其他线程持有读锁，则要获取到当前线程对应的HoldCounter，然后给里面的计数+1
&lt;/span&gt;&lt;span&gt;21&lt;/span&gt;                     HoldCounter rh =&lt;span&gt; cachedHoldCounter;
&lt;/span&gt;&lt;span&gt;22&lt;/span&gt;                     &lt;span&gt;if&lt;/span&gt; (rh == &lt;span&gt;null&lt;/span&gt; || rh.tid !=&lt;span&gt; getThreadId(current))
&lt;/span&gt;&lt;span&gt;23&lt;/span&gt;                         cachedHoldCounter = rh =&lt;span&gt; readHolds.get();
&lt;/span&gt;&lt;span&gt;24&lt;/span&gt;                     &lt;span&gt;else&lt;/span&gt; &lt;span&gt;if&lt;/span&gt; (rh.count == 0&lt;span&gt;)
&lt;/span&gt;&lt;span&gt;25&lt;/span&gt; &lt;span&gt;                        readHolds.set(rh);
&lt;/span&gt;&lt;span&gt;26&lt;/span&gt;                     rh.count++&lt;span&gt;;
&lt;/span&gt;&lt;span&gt;27&lt;/span&gt; &lt;span&gt;                }
&lt;/span&gt;&lt;span&gt;28&lt;/span&gt;                 &lt;span&gt;return&lt;/span&gt; 1&lt;span&gt;;
&lt;/span&gt;&lt;span&gt;29&lt;/span&gt; &lt;span&gt;            }
&lt;/span&gt;&lt;span&gt;30&lt;/span&gt;             &lt;span&gt;//&lt;/span&gt; 3、应该阻塞或者CAS失败则进入此方法获取锁
&lt;span&gt;31&lt;/span&gt;             &lt;span&gt;return&lt;/span&gt;&lt;span&gt; fullTryAcquireShared(current);
&lt;/span&gt;&lt;span&gt;32&lt;/span&gt;         }
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;     结合上述代码中的注释，将逻辑分三部分，我们一步步分析此方法的逻辑。&lt;/p&gt;
&lt;p&gt;    首先第一步，判断如果有写锁并且当前线程不是写锁的线程，则直接退出获取读锁的尝试，因为读写是互斥的，退出此方法后就会进入doAcquireShared方法，后续逻辑见下面的2)。但此处还是要看一下写锁状态统计方法exclusiveCount和读锁状态统计方法sharedCount，方法源码如下截图所示：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/i-beta/1558028/201912/1558028-20191217221040529-1059568658.png&quot; alt=&quot;&quot; width=&quot;796&quot; height=&quot;235&quot;/&gt;&lt;/p&gt;
&lt;p&gt;    可以看到，exclusiveCount方法是将c和独占掩码进行与操作，独占掩码EXCLUSIVE_MASK高16位均为0，低16位均为1，按位与计算之后就剩下c的低16位，这就是第二部分一开始说的低16位存放写锁重入次数；同理看sharedCount方法，将c有符号右移16位，这样移位之后低16位就是原来的高16位，即读锁的加锁次数。老Lea通过这两个方法实现了用一个int类型的state存放写锁读锁两个加锁次数的结果，是不是看起来就很高端！&lt;/p&gt;
&lt;p&gt;    然后看第二步，判断读不应该阻塞（即readerShouldBlock方法返回false）且读锁持有次数小于最大值且CAS成功，则进入方法中尝试获取读锁。先看看重点方法readerShouldBlock什么时候会返回false（不阻塞）什么时候返回true（阻塞）。此方法在非公平模式和公平模式中有不同的实现，公平模式代码：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;32&quot;&gt;
&lt;pre&gt;
&lt;span&gt;1&lt;/span&gt; &lt;span&gt;final&lt;/span&gt; &lt;span&gt;boolean&lt;/span&gt;&lt;span&gt; readerShouldBlock() {
&lt;/span&gt;&lt;span&gt;2&lt;/span&gt;             &lt;span&gt;return&lt;/span&gt;&lt;span&gt; hasQueuedPredecessors();
&lt;/span&gt;&lt;span&gt;3&lt;/span&gt;         }
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;    看到了一个熟悉的身影，hashQueuedPredecessors方法，这不就是在ReentrantLock中公平锁加锁时的方法么？详细可看我的AQS系列（一）中的讲解，总结一下就是该方法判断队列前面是否有在排队的非当前线程，意思就是按排队顺序获取锁，不要争抢。&lt;/p&gt;
&lt;p&gt;    非公平模式代码：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;32&quot;&gt;
&lt;pre&gt;
&lt;span&gt;1&lt;/span&gt; &lt;span&gt;final&lt;/span&gt; &lt;span&gt;boolean&lt;/span&gt;&lt;span&gt; readerShouldBlock() {
&lt;/span&gt;&lt;span&gt;2&lt;/span&gt;             &lt;span&gt;return&lt;/span&gt;&lt;span&gt; apparentlyFirstQueuedIsExclusive();
&lt;/span&gt;&lt;span&gt;3&lt;/span&gt;         }
&lt;/pre&gt;&lt;/div&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;34&quot;&gt;
&lt;pre&gt;
&lt;span&gt;1&lt;/span&gt; &lt;span&gt;final&lt;/span&gt; &lt;span&gt;boolean&lt;/span&gt;&lt;span&gt; apparentlyFirstQueuedIsExclusive() {
&lt;/span&gt;&lt;span&gt;2&lt;/span&gt; &lt;span&gt;        Node h, s;
&lt;/span&gt;&lt;span&gt;3&lt;/span&gt;         &lt;span&gt;return&lt;/span&gt; (h = head) != &lt;span&gt;null&lt;/span&gt; &amp;amp;&amp;amp;
&lt;span&gt;4&lt;/span&gt;             (s = h.next)  != &lt;span&gt;null&lt;/span&gt; &amp;amp;&amp;amp;
&lt;span&gt;5&lt;/span&gt;             !s.isShared()         &amp;amp;&amp;amp;
&lt;span&gt;6&lt;/span&gt;             s.thread != &lt;span&gt;null&lt;/span&gt;&lt;span&gt;;
&lt;/span&gt;&lt;span&gt;7&lt;/span&gt;     }
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;    在后面的方法中，返回了一个四个条件组成的布尔值，逻辑为头节点不为空并且头节点后的第一个节点不为空并且这个节点是独占的并且线程不为空，此时返回true即当前这个读操作应该阻塞，不让它获取到锁。那么问题来了，为什么要有这个逻辑？此处是为了避免一种异常情况的发生，如果后面有一个排队的写锁在等待获取锁，而这时有一个读锁正在执行中，若在读锁执行完之前又来了一个读锁，因为读锁与读锁不阻塞所以后来的的读锁又获取到了锁，这时在队列第一个位置排队的写锁仍然在傻傻的等着，没办法，谁让你没关系。就这样，如果一直有读锁在当前正在执行的读锁执行完之前进来获取读锁，那么后面的写锁就会一直傻等在那，永远都没法获取锁。所以Lea就设计了这个方法来避免这种情况的发生，即如果判断队列第一位排队的是写锁，那么后面的读锁就先等一等，等这个写锁执行完了你们再执行。这也就是我在文章的开始讲的-读读同时执行是有条件的，这个条件就是指这里。&lt;/p&gt;
&lt;p&gt;    看第二步之前要先说说读锁的处理逻辑，因为是可重入的读锁，所以需要记录每个获取读锁线程的重入次数，即每个读的线程都有一个与其对应的重入次数。然后继续看第二步中读锁获取锁成功（即CAS成功）之后的逻辑：如果读锁持有数为0，则说明当前线程是第一个reader，分别给firstReader和firstReaderHoldCount初始化；如果读锁持有数不为0且当前线程就是firstReader，那么直接给firstReaderHoldCount+1，表示读锁重入；否则，即当前线程不是firstReader且还有其他线程持有读锁，则要获取到当前线程对应的HoldCounter，然后给里面的计数+1。&lt;/p&gt;
&lt;p&gt;    下面再一起看看【否则】中的逻辑，粘贴一下Sync中的部分代码&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;37&quot;&gt;
&lt;pre&gt;
&lt;span&gt; 1&lt;/span&gt; &lt;span&gt;abstract&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; &lt;span&gt;class&lt;/span&gt; Sync &lt;span&gt;extends&lt;/span&gt;&lt;span&gt; AbstractQueuedSynchronizer {
&lt;/span&gt;&lt;span&gt; 2&lt;/span&gt;        &lt;span&gt;//&lt;/span&gt;&lt;span&gt; ...&lt;/span&gt;
&lt;span&gt; 3&lt;/span&gt;        &lt;span&gt;static&lt;/span&gt; &lt;span&gt;final&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;&lt;span&gt; HoldCounter {
&lt;/span&gt;&lt;span&gt; 4&lt;/span&gt;             &lt;span&gt;int&lt;/span&gt; count = 0&lt;span&gt;;
&lt;/span&gt;&lt;span&gt; 5&lt;/span&gt;             &lt;span&gt;//&lt;/span&gt;&lt;span&gt; Use id, not reference, to avoid garbage retention&lt;/span&gt;
&lt;span&gt; 6&lt;/span&gt;             &lt;span&gt;final&lt;/span&gt; &lt;span&gt;long&lt;/span&gt; tid =&lt;span&gt; getThreadId(Thread.currentThread());
&lt;/span&gt;&lt;span&gt; 7&lt;/span&gt; &lt;span&gt;        }
&lt;/span&gt;&lt;span&gt; 8&lt;/span&gt; 
&lt;span&gt; 9&lt;/span&gt;         &lt;span&gt;static&lt;/span&gt; &lt;span&gt;final&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;&lt;span&gt; ThreadLocalHoldCounter
&lt;/span&gt;&lt;span&gt;10&lt;/span&gt;             &lt;span&gt;extends&lt;/span&gt; ThreadLocal&amp;lt;HoldCounter&amp;gt;&lt;span&gt; {
&lt;/span&gt;&lt;span&gt;11&lt;/span&gt;             &lt;span&gt;public&lt;/span&gt;&lt;span&gt; HoldCounter initialValue() {
&lt;/span&gt;&lt;span&gt;12&lt;/span&gt;                 &lt;span&gt;return&lt;/span&gt; &lt;span&gt;new&lt;/span&gt;&lt;span&gt; HoldCounter();
&lt;/span&gt;&lt;span&gt;13&lt;/span&gt; &lt;span&gt;            }
&lt;/span&gt;&lt;span&gt;14&lt;/span&gt; &lt;span&gt;        }
&lt;/span&gt;&lt;span&gt;15&lt;/span&gt; 
&lt;span&gt;16&lt;/span&gt;         &lt;span&gt;private&lt;/span&gt; &lt;span&gt;transient&lt;/span&gt;&lt;span&gt; ThreadLocalHoldCounter readHolds;
&lt;/span&gt;&lt;span&gt;17&lt;/span&gt; 
&lt;span&gt;18&lt;/span&gt;         &lt;span&gt;private&lt;/span&gt; &lt;span&gt;transient&lt;/span&gt;&lt;span&gt; HoldCounter cachedHoldCounter;
&lt;/span&gt;&lt;span&gt;19&lt;/span&gt; 
&lt;span&gt;20&lt;/span&gt;         &lt;span&gt;private&lt;/span&gt; &lt;span&gt;transient&lt;/span&gt; Thread firstReader = &lt;span&gt;null&lt;/span&gt;&lt;span&gt;;
&lt;/span&gt;&lt;span&gt;21&lt;/span&gt;         &lt;span&gt;private&lt;/span&gt; &lt;span&gt;transient&lt;/span&gt; &lt;span&gt;int&lt;/span&gt;&lt;span&gt; firstReaderHoldCount;
&lt;/span&gt;&lt;span&gt;22&lt;/span&gt; 
&lt;span&gt;23&lt;/span&gt; &lt;span&gt;        Sync() {
&lt;/span&gt;&lt;span&gt;24&lt;/span&gt;             readHolds = &lt;span&gt;new&lt;/span&gt;&lt;span&gt; ThreadLocalHoldCounter();
&lt;/span&gt;&lt;span&gt;25&lt;/span&gt;             setState(getState()); &lt;span&gt;//&lt;/span&gt;&lt;span&gt; ensures visibility of readHolds&lt;/span&gt;
&lt;span&gt;26&lt;/span&gt; &lt;span&gt;        }
&lt;/span&gt;&lt;span&gt;27&lt;/span&gt;         &lt;span&gt;//&lt;/span&gt;&lt;span&gt; ...&lt;/span&gt;
&lt;span&gt;28&lt;/span&gt; }
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;    可以看到，Sync中缓存了一个HoldCounter，存放的是最近一次读锁记录。而如果当前线程不是最近一次记录的HoldCounter，则去readHolds中取，readHolds是ThreadLocalHoldCounter类型，在Sync的无参构造器中初始化，它与HoldCounter都是Sync的内部类，ThreadLocalHoldCounter就是一个ThreadLocal，内部维护了一个线程与HoldCounter的键值对map，一个线程对应一个HoldCounter。所以【否则】中的逻辑加注释如下所示：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;35&quot;&gt;
&lt;pre&gt;
&lt;span&gt;1&lt;/span&gt;                     HoldCounter rh =&lt;span&gt; cachedHoldCounter; // 获取最近一次记录的HoldCounter，此缓存是为了提高效率，不用每次都去ThreadLocal中取
&lt;/span&gt;&lt;span&gt;2&lt;/span&gt;                     &lt;span&gt;if&lt;/span&gt; (rh == &lt;span&gt;null&lt;/span&gt; || rh.tid !=&lt;span&gt; getThreadId(current)) // 判断当前线程是不是最近一次记录的HoldCounter
&lt;/span&gt;&lt;span&gt;3&lt;/span&gt;                         cachedHoldCounter = rh =&lt;span&gt; readHolds.get(); // 如果不是，则去Sync中的ThreadLocal中获取，然后再放在缓存中
&lt;/span&gt;&lt;span&gt;4&lt;/span&gt;                     &lt;span&gt;else&lt;/span&gt; &lt;span&gt;if&lt;/span&gt; (rh.count == 0&lt;span&gt;) // 如果count计数为0，说明是第一次重入，则将HoldCounter加入ThreadLocal中
&lt;/span&gt;&lt;span&gt;5&lt;/span&gt; &lt;span&gt;                        readHolds.set(rh);
&lt;/span&gt;&lt;span&gt;6&lt;/span&gt;                     rh.count++; // 当前线程重入次数+1
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;    下面进入第三步，fullTryAcquireShared方法，进入此方法的前提条件是没有写锁且 (读应该阻塞或者读锁CAS失败)。看这个full方法的逻辑：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;36&quot;&gt;
&lt;pre&gt;
&lt;span&gt; 1&lt;/span&gt; &lt;span&gt;final&lt;/span&gt; &lt;span&gt;int&lt;/span&gt;&lt;span&gt; fullTryAcquireShared(Thread current) {
&lt;/span&gt;&lt;span&gt; 2&lt;/span&gt;             
&lt;span&gt; 3&lt;/span&gt;             HoldCounter rh = &lt;span&gt;null&lt;/span&gt;&lt;span&gt;;
&lt;/span&gt;&lt;span&gt; 4&lt;/span&gt;             &lt;span&gt;for&lt;/span&gt; (;;) { &lt;span&gt;//&lt;/span&gt;&lt;span&gt; 无限循环直到有确定的结果返回&lt;/span&gt;
&lt;span&gt; 5&lt;/span&gt;                 &lt;span&gt;int&lt;/span&gt; c =&lt;span&gt; getState();
&lt;/span&gt;&lt;span&gt; 6&lt;/span&gt;                 &lt;span&gt;if&lt;/span&gt; (exclusiveCount(c) != 0) { &lt;span&gt;//&lt;/span&gt;&lt;span&gt; 1、有独占锁且不是当前线程，直接返回读锁加锁失败&lt;/span&gt;
&lt;span&gt; 7&lt;/span&gt;                     &lt;span&gt;if&lt;/span&gt; (getExclusiveOwnerThread() !=&lt;span&gt; current)
&lt;/span&gt;&lt;span&gt; 8&lt;/span&gt;                         &lt;span&gt;return&lt;/span&gt; -1&lt;span&gt;;
&lt;/span&gt;&lt;span&gt; 9&lt;/span&gt;                     &lt;span&gt;//&lt;/span&gt;&lt;span&gt; else we hold the exclusive lock; blocking here
&lt;/span&gt;&lt;span&gt;10&lt;/span&gt;                     &lt;span&gt;//&lt;/span&gt;&lt;span&gt; would cause deadlock.&lt;/span&gt;
&lt;span&gt;11&lt;/span&gt;                 } &lt;span&gt;else&lt;/span&gt; &lt;span&gt;if&lt;/span&gt; (readerShouldBlock()) { &lt;span&gt;//&lt;/span&gt;&lt;span&gt; 2、判断读是否应该阻塞
&lt;/span&gt;&lt;span&gt;12&lt;/span&gt;                     &lt;span&gt;//&lt;/span&gt;&lt;span&gt; Make sure we're not acquiring read lock reentrantly&lt;/span&gt;
&lt;span&gt;13&lt;/span&gt;                     &lt;span&gt;if&lt;/span&gt; (firstReader ==&lt;span&gt; current) { // 判断如果当前线程就是firstReader，那么什么都不做，进入3中尝试获取锁，why？ 因为这说明当前线程之前就持有了锁还没释放，所以可以继续获取
&lt;/span&gt;&lt;span&gt;14&lt;/span&gt;                         &lt;span&gt;//&lt;/span&gt;&lt;span&gt; assert firstReaderHoldCount &amp;gt; 0;&lt;/span&gt;
&lt;span&gt;15&lt;/span&gt;                     } &lt;span&gt;else&lt;/span&gt;&lt;span&gt; { // 2.5 此处逻辑需要仔细研读，乍看时看的一头雾水
&lt;/span&gt;&lt;span&gt;16&lt;/span&gt;                         &lt;span&gt;if&lt;/span&gt; (rh == &lt;span&gt;null&lt;/span&gt;&lt;span&gt;) { // 第一次进来时rh肯定==null
&lt;/span&gt;&lt;span&gt;17&lt;/span&gt;                             rh =&lt;span&gt; cachedHoldCounter;
&lt;/span&gt;&lt;span&gt;18&lt;/span&gt;                             &lt;span&gt;if&lt;/span&gt; (rh == &lt;span&gt;null&lt;/span&gt; || rh.tid !=&lt;span&gt; getThreadId(current)) {
&lt;/span&gt;&lt;span&gt;19&lt;/span&gt;                                 rh =&lt;span&gt; readHolds.get();
&lt;/span&gt;&lt;span&gt;20&lt;/span&gt;                                 &lt;span&gt;if&lt;/span&gt; (rh.count == 0&lt;span&gt;) // 如果当前线程没获取到过读锁，则从本地线程变量中移除HoldCounter，因为下一步就要判定它获取锁失败先不让它获取了
&lt;/span&gt;&lt;span&gt;21&lt;/span&gt; &lt;span&gt;                                    readHolds.remove();
&lt;/span&gt;&lt;span&gt;22&lt;/span&gt; &lt;span&gt;                            }
&lt;/span&gt;&lt;span&gt;23&lt;/span&gt; &lt;span&gt;                        }// 能走到这里，说明当前读锁应该阻塞且不是firstReader
&lt;/span&gt;&lt;span&gt;24&lt;/span&gt;                         &lt;span&gt;if&lt;/span&gt; (rh.count == 0&lt;span&gt;) // 再加上当前线程没获取到过读锁，则先不让它尝试获取锁了，直接返回获取失败
&lt;/span&gt;&lt;span&gt;25&lt;/span&gt;                             &lt;span&gt;return&lt;/span&gt; -1&lt;span&gt;;
&lt;/span&gt;&lt;span&gt;26&lt;/span&gt; &lt;span&gt;                    }
&lt;/span&gt;&lt;span&gt;27&lt;/span&gt; &lt;span&gt;                }
&lt;/span&gt;&lt;span&gt;28&lt;/span&gt;                 &lt;span&gt;if&lt;/span&gt; (sharedCount(c) ==&lt;span&gt; MAX_COUNT)
&lt;/span&gt;&lt;span&gt;29&lt;/span&gt;                     &lt;span&gt;throw&lt;/span&gt; &lt;span&gt;new&lt;/span&gt; Error(&quot;Maximum lock count exceeded&quot;&lt;span&gt;);
&lt;/span&gt;&lt;span&gt;30&lt;/span&gt;                 &lt;span&gt;//&lt;/span&gt;&lt;span&gt; 3、再次尝试获取锁&lt;/span&gt;
&lt;span&gt;31&lt;/span&gt;                 &lt;span&gt;if&lt;/span&gt; (compareAndSetState(c, c +&lt;span&gt; SHARED_UNIT)) {
&lt;/span&gt;&lt;span&gt;32&lt;/span&gt;                     &lt;span&gt;if&lt;/span&gt; (sharedCount(c) == 0&lt;span&gt;) {
&lt;/span&gt;&lt;span&gt;33&lt;/span&gt;                         firstReader =&lt;span&gt; current;
&lt;/span&gt;&lt;span&gt;34&lt;/span&gt;                         firstReaderHoldCount = 1&lt;span&gt;;
&lt;/span&gt;&lt;span&gt;35&lt;/span&gt;                     } &lt;span&gt;else&lt;/span&gt; &lt;span&gt;if&lt;/span&gt; (firstReader ==&lt;span&gt; current) {
&lt;/span&gt;&lt;span&gt;36&lt;/span&gt;                         firstReaderHoldCount++&lt;span&gt;;
&lt;/span&gt;&lt;span&gt;37&lt;/span&gt;                     } &lt;span&gt;else&lt;/span&gt;&lt;span&gt; {
&lt;/span&gt;&lt;span&gt;38&lt;/span&gt;                         &lt;span&gt;if&lt;/span&gt; (rh == &lt;span&gt;null&lt;/span&gt;&lt;span&gt;)
&lt;/span&gt;&lt;span&gt;39&lt;/span&gt;                             rh =&lt;span&gt; cachedHoldCounter;
&lt;/span&gt;&lt;span&gt;40&lt;/span&gt;                         &lt;span&gt;if&lt;/span&gt; (rh == &lt;span&gt;null&lt;/span&gt; || rh.tid !=&lt;span&gt; getThreadId(current))
&lt;/span&gt;&lt;span&gt;41&lt;/span&gt;                             rh =&lt;span&gt; readHolds.get();
&lt;/span&gt;&lt;span&gt;42&lt;/span&gt;                         &lt;span&gt;else&lt;/span&gt; &lt;span&gt;if&lt;/span&gt; (rh.count == 0&lt;span&gt;)
&lt;/span&gt;&lt;span&gt;43&lt;/span&gt; &lt;span&gt;                            readHolds.set(rh);
&lt;/span&gt;&lt;span&gt;44&lt;/span&gt;                         rh.count++&lt;span&gt;;
&lt;/span&gt;&lt;span&gt;45&lt;/span&gt;                         cachedHoldCounter = rh; &lt;span&gt;//&lt;/span&gt;&lt;span&gt; cache for release&lt;/span&gt;
&lt;span&gt;46&lt;/span&gt; &lt;span&gt;                    }
&lt;/span&gt;&lt;span&gt;47&lt;/span&gt;                     &lt;span&gt;return&lt;/span&gt; 1&lt;span&gt;;
&lt;/span&gt;&lt;span&gt;48&lt;/span&gt; &lt;span&gt;                }
&lt;/span&gt;&lt;span&gt;49&lt;/span&gt; &lt;span&gt;            }
&lt;/span&gt;&lt;span&gt;50&lt;/span&gt;         }
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;    详细看看注解以及源代码注释、代码逻辑，相信能理解这个过程。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt; 2）、doAcquireShared方法&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;37&quot;&gt;
&lt;pre&gt;
&lt;span&gt; 1&lt;/span&gt; &lt;span&gt;private&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; doAcquireShared(&lt;span&gt;int&lt;/span&gt;&lt;span&gt; arg) {
&lt;/span&gt;&lt;span&gt; 2&lt;/span&gt;         &lt;span&gt;//&lt;/span&gt;&lt;span&gt; 将当前读锁加到队列后面&lt;/span&gt;
&lt;span&gt; 3&lt;/span&gt;         &lt;span&gt;final&lt;/span&gt; Node node =&lt;span&gt; addWaiter(Node.SHARED);
&lt;/span&gt;&lt;span&gt; 4&lt;/span&gt;         &lt;span&gt;boolean&lt;/span&gt; failed = &lt;span&gt;true&lt;/span&gt;&lt;span&gt;;
&lt;/span&gt;&lt;span&gt; 5&lt;/span&gt;         &lt;span&gt;try&lt;/span&gt;&lt;span&gt; {
&lt;/span&gt;&lt;span&gt; 6&lt;/span&gt;             &lt;span&gt;boolean&lt;/span&gt; interrupted = &lt;span&gt;false&lt;/span&gt;&lt;span&gt;;
&lt;/span&gt;&lt;span&gt; 7&lt;/span&gt;             &lt;span&gt;for&lt;/span&gt;&lt;span&gt; (;;) {
&lt;/span&gt;&lt;span&gt; 8&lt;/span&gt;                 &lt;span&gt;//&lt;/span&gt;&lt;span&gt; 得到前一个节点&lt;/span&gt;
&lt;span&gt; 9&lt;/span&gt;                 &lt;span&gt;final&lt;/span&gt; Node p =&lt;span&gt; node.predecessor();
&lt;/span&gt;&lt;span&gt;10&lt;/span&gt;                 &lt;span&gt;if&lt;/span&gt; (p == head) { &lt;span&gt;//&lt;/span&gt;&lt;span&gt; 如果前一个节点是头节点，则尝试获取锁&lt;/span&gt;
&lt;span&gt;11&lt;/span&gt;                     &lt;span&gt;int&lt;/span&gt; r =&lt;span&gt; tryAcquireShared(arg);
&lt;/span&gt;&lt;span&gt;12&lt;/span&gt;                     &lt;span&gt;if&lt;/span&gt; (r &amp;gt;= 0) { &lt;span&gt;//&lt;/span&gt;&lt;span&gt; 设置头节点并且激活后续的节点&lt;/span&gt;
&lt;span&gt;13&lt;/span&gt; &lt;span&gt;                        setHeadAndPropagate(node, r);
&lt;/span&gt;&lt;span&gt;14&lt;/span&gt;                         p.next = &lt;span&gt;null&lt;/span&gt;; &lt;span&gt;//&lt;/span&gt;&lt;span&gt; help GC&lt;/span&gt;
&lt;span&gt;15&lt;/span&gt;                         &lt;span&gt;if&lt;/span&gt;&lt;span&gt; (interrupted)
&lt;/span&gt;&lt;span&gt;16&lt;/span&gt; &lt;span&gt;                            selfInterrupt();
&lt;/span&gt;&lt;span&gt;17&lt;/span&gt;                         failed = &lt;span&gt;false&lt;/span&gt;&lt;span&gt;;
&lt;/span&gt;&lt;span&gt;18&lt;/span&gt;                         &lt;span&gt;return&lt;/span&gt;&lt;span&gt;;
&lt;/span&gt;&lt;span&gt;19&lt;/span&gt; &lt;span&gt;                    }
&lt;/span&gt;&lt;span&gt;20&lt;/span&gt;                 }&lt;span&gt;//&lt;/span&gt;&lt;span&gt; 判断应该挂起则挂起线程&lt;/span&gt;
&lt;span&gt;21&lt;/span&gt;                 &lt;span&gt;if&lt;/span&gt; (shouldParkAfterFailedAcquire(p, node) &amp;amp;&amp;amp;
&lt;span&gt;22&lt;/span&gt; &lt;span&gt;                    parkAndCheckInterrupt())
&lt;/span&gt;&lt;span&gt;23&lt;/span&gt;                     interrupted = &lt;span&gt;true&lt;/span&gt;&lt;span&gt;;
&lt;/span&gt;&lt;span&gt;24&lt;/span&gt; &lt;span&gt;            }
&lt;/span&gt;&lt;span&gt;25&lt;/span&gt;         } &lt;span&gt;finally&lt;/span&gt;&lt;span&gt; {
&lt;/span&gt;&lt;span&gt;26&lt;/span&gt;             &lt;span&gt;if&lt;/span&gt;&lt;span&gt; (failed)
&lt;/span&gt;&lt;span&gt;27&lt;/span&gt; &lt;span&gt;                cancelAcquire(node);
&lt;/span&gt;&lt;span&gt;28&lt;/span&gt; &lt;span&gt;        }
&lt;/span&gt;&lt;span&gt;29&lt;/span&gt;     }
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;    该方法跟之前系列中ReentrantLock的加锁过程类似，在此就不做过多的解释了，总之还是通过park来挂起。&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt; 2、写锁加锁，即独占锁加锁&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;    进入lock方法：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;32&quot;&gt;
&lt;pre&gt;
&lt;span&gt;1&lt;/span&gt; &lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt;&lt;span&gt; lock() {
&lt;/span&gt;&lt;span&gt;2&lt;/span&gt;             sync.acquire(1&lt;span&gt;);
&lt;/span&gt;&lt;span&gt;3&lt;/span&gt;         }
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;    熟悉的样子，继续 点进去：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;34&quot;&gt;
&lt;pre&gt;
&lt;span&gt;1&lt;/span&gt; &lt;span&gt;public&lt;/span&gt; &lt;span&gt;final&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; acquire(&lt;span&gt;int&lt;/span&gt;&lt;span&gt; arg) {
&lt;/span&gt;&lt;span&gt;2&lt;/span&gt;         &lt;span&gt;if&lt;/span&gt; (!tryAcquire(arg) &amp;amp;&amp;amp;
&lt;span&gt;3&lt;/span&gt; &lt;span&gt;            acquireQueued(addWaiter(Node.EXCLUSIVE), arg))
&lt;/span&gt;&lt;span&gt;4&lt;/span&gt; &lt;span&gt;            selfInterrupt();
&lt;/span&gt;&lt;span&gt;5&lt;/span&gt;     }
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;    还是原先的方法，但是各个方法的实现有区别了。先看第一个tryAcquire：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;36&quot;&gt;
&lt;pre&gt;
&lt;span&gt; 1&lt;/span&gt; &lt;span&gt;protected&lt;/span&gt; &lt;span&gt;final&lt;/span&gt; &lt;span&gt;boolean&lt;/span&gt; tryAcquire(&lt;span&gt;int&lt;/span&gt;&lt;span&gt; acquires) {
&lt;/span&gt;&lt;span&gt; 2&lt;/span&gt;             Thread current =&lt;span&gt; Thread.currentThread();
&lt;/span&gt;&lt;span&gt; 3&lt;/span&gt;             &lt;span&gt;int&lt;/span&gt; c =&lt;span&gt; getState();
&lt;/span&gt;&lt;span&gt; 4&lt;/span&gt;             &lt;span&gt;int&lt;/span&gt; w =&lt;span&gt; exclusiveCount(c);
&lt;/span&gt;&lt;span&gt; 5&lt;/span&gt;             &lt;span&gt;if&lt;/span&gt; (c != 0) { &lt;span&gt;//&lt;/span&gt;&lt;span&gt; 如果排它锁存在，则判断是不是当前线程，如果也不是当前线程，则直接返回获取失败
&lt;/span&gt;&lt;span&gt; 6&lt;/span&gt;                 &lt;span&gt;//&lt;/span&gt;&lt;span&gt; (Note: if c != 0 and w == 0 then shared count != 0)&lt;/span&gt;
&lt;span&gt; 7&lt;/span&gt;                 &lt;span&gt;if&lt;/span&gt; (w == 0 || current !=&lt;span&gt; getExclusiveOwnerThread())
&lt;/span&gt;&lt;span&gt; 8&lt;/span&gt;                     &lt;span&gt;return&lt;/span&gt; &lt;span&gt;false&lt;/span&gt;&lt;span&gt;;
&lt;/span&gt;&lt;span&gt; 9&lt;/span&gt;                 &lt;span&gt;if&lt;/span&gt; (w + exclusiveCount(acquires) &amp;gt;&lt;span&gt; MAX_COUNT)
&lt;/span&gt;&lt;span&gt;10&lt;/span&gt;                     &lt;span&gt;throw&lt;/span&gt; &lt;span&gt;new&lt;/span&gt; Error(&quot;Maximum lock count exceeded&quot;&lt;span&gt;);
&lt;/span&gt;&lt;span&gt;11&lt;/span&gt;                 &lt;span&gt;//&lt;/span&gt;&lt;span&gt; Reentrant acquire&lt;/span&gt;
&lt;span&gt;12&lt;/span&gt;                 setState(c +&lt;span&gt; acquires);
&lt;/span&gt;&lt;span&gt;13&lt;/span&gt;                 &lt;span&gt;return&lt;/span&gt; &lt;span&gt;true&lt;/span&gt;&lt;span&gt;;
&lt;/span&gt;&lt;span&gt;14&lt;/span&gt;             } &lt;span&gt;//&lt;/span&gt;&lt;span&gt; 判断读锁要不要阻塞，此处针对公平锁和非公平锁有不同的实现，对于非公平锁统一返回false表示不要阻塞，而公平锁则会查看前面还有没有锁来判断要不要阻塞&lt;/span&gt;
&lt;span&gt;15&lt;/span&gt;             &lt;span&gt;if&lt;/span&gt; (writerShouldBlock() ||
&lt;span&gt;16&lt;/span&gt;                 !compareAndSetState(c, c +&lt;span&gt; acquires))
&lt;/span&gt;&lt;span&gt;17&lt;/span&gt;                 &lt;span&gt;return&lt;/span&gt; &lt;span&gt;false&lt;/span&gt;&lt;span&gt;;
&lt;/span&gt;&lt;span&gt;18&lt;/span&gt; &lt;span&gt;            setExclusiveOwnerThread(current);
&lt;/span&gt;&lt;span&gt;19&lt;/span&gt;             &lt;span&gt;return&lt;/span&gt; &lt;span&gt;true&lt;/span&gt;&lt;span&gt;;
&lt;/span&gt;&lt;span&gt;20&lt;/span&gt;         }
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;    然后是addWaiter在队列末尾添加node节点排队，这个方法在AbstractQueuedSynchronizer中，同样是熟悉的方法了，此处略过不提。&lt;/p&gt;
&lt;p&gt;    最后是acquireQueued方法，如下所示，又是熟悉的代码，跟ReentrantLock中的加锁方法一毛一样，唯一的不同点是第7行调用的tryAcquire方法的实现，此处调的是ReentrantReadWriteLock类中Sync的方法，也就是上面的第一个方法。&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;37&quot;&gt;
&lt;pre&gt;
&lt;span&gt; 1&lt;/span&gt; &lt;span&gt;final&lt;/span&gt; &lt;span&gt;boolean&lt;/span&gt; acquireQueued(&lt;span&gt;final&lt;/span&gt; Node node, &lt;span&gt;int&lt;/span&gt;&lt;span&gt; arg) {
&lt;/span&gt;&lt;span&gt; 2&lt;/span&gt;         &lt;span&gt;boolean&lt;/span&gt; failed = &lt;span&gt;true&lt;/span&gt;&lt;span&gt;;
&lt;/span&gt;&lt;span&gt; 3&lt;/span&gt;         &lt;span&gt;try&lt;/span&gt;&lt;span&gt; {
&lt;/span&gt;&lt;span&gt; 4&lt;/span&gt;             &lt;span&gt;boolean&lt;/span&gt; interrupted = &lt;span&gt;false&lt;/span&gt;&lt;span&gt;;
&lt;/span&gt;&lt;span&gt; 5&lt;/span&gt;             &lt;span&gt;for&lt;/span&gt;&lt;span&gt; (;;) { 
&lt;/span&gt;&lt;span&gt; 6&lt;/span&gt;                 &lt;span&gt;final&lt;/span&gt; Node p =&lt;span&gt; node.predecessor();
&lt;/span&gt;&lt;span&gt; 7&lt;/span&gt;                 &lt;span&gt;if&lt;/span&gt; (p == head &amp;amp;&amp;amp;&lt;span&gt; tryAcquire(arg)) {
&lt;/span&gt;&lt;span&gt; 8&lt;/span&gt; &lt;span&gt;                    setHead(node);
&lt;/span&gt;&lt;span&gt; 9&lt;/span&gt;                     p.next = &lt;span&gt;null&lt;/span&gt;; &lt;span&gt;//&lt;/span&gt;&lt;span&gt; help GC&lt;/span&gt;
&lt;span&gt;10&lt;/span&gt;                     failed = &lt;span&gt;false&lt;/span&gt;&lt;span&gt;;
&lt;/span&gt;&lt;span&gt;11&lt;/span&gt;                     &lt;span&gt;return&lt;/span&gt;&lt;span&gt; interrupted;
&lt;/span&gt;&lt;span&gt;12&lt;/span&gt; &lt;span&gt;                }
&lt;/span&gt;&lt;span&gt;13&lt;/span&gt;                 &lt;span&gt;if&lt;/span&gt; (shouldParkAfterFailedAcquire(p, node) &amp;amp;&amp;amp;
&lt;span&gt;14&lt;/span&gt; &lt;span&gt;                    parkAndCheckInterrupt())
&lt;/span&gt;&lt;span&gt;15&lt;/span&gt;                     interrupted = &lt;span&gt;true&lt;/span&gt;&lt;span&gt;;
&lt;/span&gt;&lt;span&gt;16&lt;/span&gt; &lt;span&gt;            }
&lt;/span&gt;&lt;span&gt;17&lt;/span&gt;         } &lt;span&gt;finally&lt;/span&gt;&lt;span&gt; {
&lt;/span&gt;&lt;span&gt;18&lt;/span&gt;             &lt;span&gt;if&lt;/span&gt;&lt;span&gt; (failed)
&lt;/span&gt;&lt;span&gt;19&lt;/span&gt; &lt;span&gt;                cancelAcquire(node);
&lt;/span&gt;&lt;span&gt;20&lt;/span&gt; &lt;span&gt;        }
&lt;/span&gt;&lt;span&gt;21&lt;/span&gt;     }
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;    写锁的加锁过程基本就这些了，相对来说比读锁加锁容易了很多，因为大多都跟ReentrantLock中的实现相仿。&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;后记&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;    读写锁的加锁过程到此为止，最近每晚下班回来读一会，断断续续的四晚上才搞定，难受 &amp;gt;&amp;lt;&lt;/p&gt;
</description>
<pubDate>Thu, 19 Dec 2019 14:44:00 +0000</pubDate>
<dc:creator>张曾经</dc:creator>
<og:description>前言 前两篇我们讲述了ReentrantLock的加锁释放锁过程，相对而言比较简单，本篇进入深水区，看看ReentrantReadWriteLock-读写锁的加锁过程是如何实现的，继续拜读老Lea凌厉</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/zzq6032010/p/12037854.html</dc:identifier>
</item>
<item>
<title>曹工说Spring Boot源码（3）-- 手动注册Bean Definition不比游戏好玩吗，我们来试一下 - 三国梦回</title>
<link>http://www.cnblogs.com/grey-wolf/p/12070377.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/grey-wolf/p/12070377.html</guid>
<description>&lt;p&gt;相关背景及资源：&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.cnblogs.com/grey-wolf/p/12044199.html&quot;&gt;曹工说Spring Boot源码系列开讲了（1）-- Bean Definition到底是什么，附spring思维导图分享&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://gitee.com/ckl111/spring-boot-first-version-learn&quot;&gt;工程代码地址&lt;/a&gt; &lt;a href=&quot;https://www.processon.com/view/link/5deeefdee4b0e2c298aa5596&quot;&gt;思维导图地址&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;工程结构图：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/519126/201912/519126-20191215144930717-1919774390.png&quot;/&gt;&lt;/p&gt;

&lt;ol readability=&quot;-2&quot;&gt;&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;选择bean definition实现类，并实例化bean definition&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;注册bean definition&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;get bean查看是否work&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;这次，先说目的：我们要通过代码方式手动生成bean definition并注册到bean factory。&lt;/p&gt;
&lt;p&gt;我的思路是这样的，既然前面两节，分析了bean definition接口中的各个方法，也算对其有了基本的了解了。但&lt;/p&gt;
&lt;p&gt;&lt;code&gt;org.springframework.beans.factory.config.BeanDefinition&lt;/code&gt;只是一个接口，接口是不能实例化的，也无从谈起注册了。&lt;/p&gt;
&lt;p&gt;我们从bean definition的实现类中选一个吧：&lt;img src=&quot;https://img2018.cnblogs.com/blog/519126/201912/519126-20191215142445719-2047152320.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;非抽象的实现类主要有以下三个：&lt;/p&gt;
&lt;ol readability=&quot;9&quot;&gt;&lt;li readability=&quot;18.5&quot;&gt;
&lt;p&gt;&lt;code&gt;org.springframework.beans.factory.support.GenericBeanDefinition&lt;/code&gt;：幸运儿，被我们选中的，也是官方推荐的，注释里提到可以动态设置&lt;code&gt;GenericBeanDefinition&lt;/code&gt;的parent bean definition的名称；&lt;/p&gt;
&lt;p&gt;这个呢，&lt;code&gt;org.springframework.beans.factory.support.RootBeanDefinition&lt;/code&gt;和&lt;code&gt;org.springframework.beans.factory.support.ChildBeanDefinition&lt;/code&gt;也能实现bean的继承关系，但是可能这种预先定义一个bean为&lt;code&gt;child/parent&lt;/code&gt;的方式，太死了。&lt;/p&gt;
&lt;p&gt;官方自己在&lt;code&gt;ChildBeanDefinition&lt;/code&gt;的注释里写到：&lt;/p&gt;
&lt;blockquote readability=&quot;10&quot;&gt;
&lt;p&gt;NOTE: Since Spring 2.5, the preferred way to register bean definitions programmatically is the {@link GenericBeanDefinition} class, which allows to dynamically define parent dependencies through the* {@link GenericBeanDefinition#setParentName} method. This effectively supersedes the ChildBeanDefinition class for most use cases.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;注意最后那句话，supresede这个单词我还他么不太认识，专门查了下词典，意思是&lt;code&gt;取代、代替&lt;/code&gt;，那这句话意&lt;/p&gt;
&lt;p&gt;思就是，大部分时候，&lt;code&gt;GenericBeanDefinition&lt;/code&gt;取代了&lt;code&gt;ChildBeanDefinition&lt;/code&gt;的作用。&lt;/p&gt;
&lt;p&gt;这个下面有两个子类，之前也提过，主要是供那种通过注解方式，比如&lt;code&gt;@controller&lt;/code&gt;这种扫描进来的bean definition。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;&lt;code&gt;org.springframework.beans.factory.support.ChildBeanDefinition&lt;/code&gt;，官方都不建议用了，直接跳过吧；&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;&lt;code&gt;org.springframework.beans.factory.support.RootBeanDefinition&lt;/code&gt;，在&lt;code&gt;@configuration&lt;/code&gt;中有用，后面再讲&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;基于上面的思路，我们选了&lt;code&gt;GenericBeanDefinition&lt;/code&gt;，这个类可以直接new，new了之后再通过set方法设置beanClassName等。&lt;/p&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;public class GenericBeanDefinition extends AbstractBeanDefinition {

    private String parentName;


    /**
     * 无参构造函数，但是你看到下面那一堆set方法了吧，就是让你自己设
     * Create a new GenericBeanDefinition, to be configured through its bean
     * properties and configuration methods.
     * @see #setBeanClass
     * @see #setBeanClassName
     * @see #setScope
     * @see #setAutowireMode
     * @see #setDependencyCheck
     * @see #setConstructorArgumentValues
     * @see #setPropertyValues
     */
    public GenericBeanDefinition() {
        super();
    }
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;还有一个方式是，我们看看框架里怎么用的，经过我一番搜索，&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/519126/201912/519126-20191219211036606-1193006497.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;发现框架里，主要使用了&lt;code&gt;org.springframework.beans.factory.support.BeanDefinitionBuilder&lt;/code&gt;和&lt;/p&gt;
&lt;p&gt;&lt;code&gt;org.springframework.beans.factory.support.BeanDefinitionReaderUtils&lt;/code&gt;，而且，框架里，还是前者用的多，也比较方便（后面有示例代码）。&lt;/p&gt;

&lt;p&gt;然后，知道怎么构造&lt;code&gt;GenericBeanDefinition&lt;/code&gt;了，那么要怎么注册呢，这个也简单，我们看看&lt;code&gt;beanFactory&lt;/code&gt;，&lt;/p&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;public class DefaultListableBeanFactory extends AbstractAutowireCapableBeanFactory
        implements ConfigurableListableBeanFactory, BeanDefinitionRegistry, Serializable &lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;不只实现了&lt;code&gt;ConfigurableListableBeanFactory&lt;/code&gt;，还实现了&lt;code&gt;BeanDefinitionRegistry&lt;/code&gt;。&lt;/p&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;public interface BeanDefinitionRegistry extends AliasRegistry {

    /**
     * 注册beanDefinition，要自己指定beanName
     * Register a new bean definition with this registry.
     * Must support RootBeanDefinition and ChildBeanDefinition.
     * @param beanName the name of the bean instance to register
     * @param beanDefinition definition of the bean instance to register
     * @throws BeanDefinitionStoreException if the BeanDefinition is invalid
     * or if there is already a BeanDefinition for the specified bean name
     * (and we are not allowed to override it)
     * @see RootBeanDefinition
     * @see ChildBeanDefinition
     */
    void registerBeanDefinition(String beanName, BeanDefinition beanDefinition)
            throws BeanDefinitionStoreException;
    ...
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;所以，我们只要调用&lt;code&gt;org.springframework.beans.factory.support.DefaultListableBeanFactory&lt;/code&gt;的注册方法即可。&lt;/p&gt;
&lt;p&gt;这里说下&lt;code&gt;beanNameGenerator&lt;/code&gt;，一开始我用的&lt;code&gt;org.springframework.beans.factory.support.DefaultBeanNameGenerator&lt;/code&gt;，结果生成的bean的名称是这样的：&lt;/p&gt;
&lt;p&gt;&lt;code&gt;org.springframework.simple.TestService#0&lt;/code&gt;，这和我们平时使用autowired方式，生成的beanName不一样啊，不习惯。于是改成了&lt;code&gt;org.springframework.context.annotation.AnnotationBeanNameGenerator&lt;/code&gt;，就对了！&lt;/p&gt;

&lt;p&gt;这里先介绍两种方式，分别是构造器注入和property注入。对了，先不要和我提什么&lt;code&gt;autowired&lt;/code&gt;哈，那个是自动，这个呢，手动。也许，后面你会更懂&lt;code&gt;autowired&lt;/code&gt;，也更懂自动。&lt;/p&gt;
&lt;h2 id=&quot;构造器注入&quot;&gt;构造器注入&lt;/h2&gt;
&lt;p&gt;核心代码：&lt;/p&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;
@ToString
public class TestControllerByConstructor {

    TestService testService;

    /**
     * 基本类型依赖
     */
    private String name;


    public TestControllerByConstructor(TestService testService, String name) {
        this.testService = testService;
        this.name = name;
    }

    public TestService getTestService() {
        return testService;
    }

    public String getName() {
        return name;
    }
}&lt;/code&gt;
&lt;/pre&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;package org.springframework.simple;

import lombok.ToString;

@ToString
public class TestService implements ITestService{
}&lt;/code&gt;
&lt;/pre&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;/**
 * 2. 构造bean definition，并在bean definition中表达bean之间的依赖关系
 */
GenericBeanDefinition iTestServiceBeanDefinition = (GenericBeanDefinition) BeanDefinitionBuilder
                .genericBeanDefinition(TestService.class).getBeanDefinition();
log.info(&quot;iTestServiceBeanDefinition:{}&quot;,iTestServiceBeanDefinition);

GenericBeanDefinition iTestControllerBeanDefinition = (GenericBeanDefinition) BeanDefinitionBuilder
    .genericBeanDefinition(TestControllerByConstructor.class)
    // 这里，看这里，这里在表达依赖了
    .addConstructorArgReference(&quot;testService&quot;)
    .addConstructorArgValue(&quot;wire by constructor&quot;)
    .getBeanDefinition();&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;完整代码：&lt;/p&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;package org.springframework.simple.byconstructor;

import lombok.extern.slf4j.Slf4j;
import org.springframework.beans.factory.support.*;
import org.springframework.context.annotation.AnnotationBeanNameGenerator;
import org.springframework.simple.ITestService;
import org.springframework.simple.TestService;
import org.springframework.util.Assert;

@Slf4j
public class ManualRegisterBeanDefinitionDemoByConstructor {
    public static void main(String[] args) {
        wireDependencyByConstructor();
    }


    /**
     * 通过构造器的方式来注入依赖
     */
    private static void wireDependencyByConstructor() {
        /**
         * 1：生成bean factory
         */
        DefaultListableBeanFactory factory = new DefaultListableBeanFactory();
        /**
         * 2. 构造bean definition，并在bean definition中表达bean之间的依赖关系
         */
        GenericBeanDefinition iTestServiceBeanDefinition = (GenericBeanDefinition) BeanDefinitionBuilder
                .genericBeanDefinition(TestService.class).getBeanDefinition();
        log.info(&quot;iTestServiceBeanDefinition:{}&quot;,iTestServiceBeanDefinition);

        GenericBeanDefinition iTestControllerBeanDefinition = (GenericBeanDefinition) BeanDefinitionBuilder
                .genericBeanDefinition(TestControllerByConstructor.class)
                .addConstructorArgReference(&quot;testService&quot;)
                .addConstructorArgValue(&quot;wire by constructor&quot;)
                .getBeanDefinition();


        /**
         * 3. 注册bean definition
         */
//        DefaultBeanNameGenerator generator = new DefaultBeanNameGenerator();
        AnnotationBeanNameGenerator generator = new AnnotationBeanNameGenerator();
        String beanNameForTestService = generator.generateBeanName(iTestServiceBeanDefinition, factory);
        factory.registerBeanDefinition(beanNameForTestService, iTestServiceBeanDefinition);

        String beanNameForTestController = generator.generateBeanName(iTestControllerBeanDefinition, factory);
        factory.registerBeanDefinition(beanNameForTestController, TestControllerBeanDefinition);

        /**
         * 4. 获取bean
         */
        TestControllerByConstructor bean = factory.getBean(TestControllerByConstructor.class);
        log.info(&quot;TestControllerByConstructor：{}&quot;,bean);

        ITestService testService = factory.getBean(ITestService.class);
        log.info(&quot;testService bean:{}&quot;,testService);

        Assert.isTrue(bean.getTestService() == testService);
    }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;property注入&quot;&gt;property注入&lt;/h2&gt;
&lt;p&gt;原理类似，核心代码不同之处如下：&lt;/p&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;        GenericBeanDefinition iTestControllerBeanDefinition = (GenericBeanDefinition) BeanDefinitionBuilder
                .genericBeanDefinition(TestControllerWireByProperty.class)
                // 这里是调用的property相关方法
                .addPropertyReference(&quot;t&quot;,&quot;testService&quot;)
                .addPropertyValue(&quot;name&quot;,&quot;just test&quot;)
                .getBeanDefinition();&lt;/code&gt;
&lt;/pre&gt;

&lt;p&gt;今天就到这里，有问题请指出哈，欢迎大家和我一起阅读spring boot源码。&lt;/p&gt;
&lt;p&gt;源码地址：&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://gitee.com/ckl111/spring-boot-first-version-learn/tree/master/all-demo-in-spring-learning/spring-manual-register-bean-definition&quot; class=&quot;uri&quot;&gt;https://gitee.com/ckl111/spring-boot-first-version-learn/tree/master/all-demo-in-spring-learning/spring-manual-register-bean-definition&lt;/a&gt;&lt;/p&gt;
</description>
<pubDate>Thu, 19 Dec 2019 13:40:00 +0000</pubDate>
<dc:creator>三国梦回</dc:creator>
<og:description>写在前面的话 相关背景及资源： '曹工说Spring Boot源码系列开讲了（1） Bean Definition到底是什么，附spring思维导图分享' '工程代码地址' '思维导图地址' 工程结构</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/grey-wolf/p/12070377.html</dc:identifier>
</item>
<item>
<title>记一次 Kafka 集群线上扩容 - 后端进阶</title>
<link>http://www.cnblogs.com/objcoding/p/12070055.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/objcoding/p/12070055.html</guid>
<description>&lt;p&gt;前段时间收到某个 Kafka 集群的生产客户端反馈发送消息耗时很高，于是花了一段时间去排查这个问题，最后该集群进行扩容，由于某些主题的当前数据量实在太大，在对这些主题迁移过程中话费了很长一段时间，不过这个过程还算顺利，因为在迁移过程中也做足了各方面的调研，包括分区重平衡过程中对客户端的影响，以及对整个集群的性能影响等，特此将这个过程总结一下，也为双十一打了一剂强心剂。&lt;/p&gt;
&lt;h2 id=&quot;排查问题与分析&quot;&gt;排查问题与分析&lt;/h2&gt;
&lt;p&gt;接到用户的反馈后，我用脚本测试了一遍，并对比了另外一个正常的 Kafka 集群，发现耗时确实很高，接下来&lt;/p&gt;
&lt;p&gt;经过排查，发现有客户端在频繁断开与集群节点的连接，发现日志频繁打印如下内容：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;Attempting to send response via channel for which there is no open connection, connection id xxx(kafka.network.Processor)&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;定位到源码位置：&lt;/p&gt;
&lt;p&gt;kafka.network.Processor#sendResponse：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1860306/201912/1860306-20191219204012293-455150458.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;看源码注释，是远程连接关闭了或者空闲时间太长了的意思，找到具体客户端负责人，经询问后，这是大数据 Spark 集群的节点。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1860306/201912/1860306-20191219204013892-1980441001.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;从以上日志看出，Spark 集群的某个消费组 OrderDeliveryTypeCnt，竟然发生了近 4 万次重平衡操作，这显然就是一个不正常的事件，Kafka 消费组发生重平衡的条件有以下几个：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;消费组成员发生变更，有新消费者加入或者离开，或者有消费者崩溃；&lt;/li&gt;
&lt;li&gt;消费组订阅的主题数量发生变更；&lt;/li&gt;
&lt;li&gt;消费组订阅的分区数发生变更。&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;很显然第 2、3 点都没有发生，那么可以断定，这是 Spark集群节点频繁断开与kafka的连接导致消费组成员发生变更，导致消费组发生重平滑。&lt;/p&gt;
&lt;p&gt;那为什么 Spark 集群会产生频繁断开重连呢？&lt;/p&gt;
&lt;p&gt;查看 Spark 集群用的 Kafka 版本还是 0.10.1.1 版本，而 Kafka 集群的版本为 2.2.1，一开始以为是版本兼容问题，接着数据智能部的小伙伴将 Spark 集群连接到某个版本为 0.11.1.1 的 Kafka 集群，使用 8 个 Spark 任务消费进行消费，同样发现了连接断开的问题。说明此问题是由于 Spark 内部消费 Kafka 机制导致的，和 kafka 版本关系不大。&lt;/p&gt;
&lt;p&gt;经过几番跟大数据的人员讨论，这个频繁重平衡貌似是 Spark 2.3 版本内部机制导致的，Spark 2.4 版本没有这个问题存在。&lt;/p&gt;
&lt;p&gt;由于这个频繁断开重连，并不是开发人员开发过程中导致的，考虑到双十一临近，不能贸然升级改动项目，那么现在最好的方案就是对集群进行水平扩展，增加集群的负载能力，并对专门的主题进行分区重分配。&lt;/p&gt;
&lt;h2 id=&quot;分区重分配方案的分析&quot;&gt;分区重分配方案的分析&lt;/h2&gt;
&lt;p&gt;目前集群一共有 6 个节点，扩容以 50% 为基准，那么需要在准备 3 个节点，在运维准备好机器并且将其加入到集群中后，接下来就要准备对主题进行分区重分配的策略文件了。&lt;/p&gt;
&lt;p&gt;在执行分区重分配的过程中，对集群的影响主要有两点：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;分区重分配主要是对主题数据进行 Broker 间的迁移，因此会占用集群的带宽资源；&lt;/li&gt;
&lt;li&gt;分区重分配会改变分区 Leader 所在的 Broker，因此会影响客户端。&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;针对以上两点，第 1 点可以在晚间进行（太苦逼了，记得有个主题数据迁移进行了将近5小时），针对第二点，我想到了两个方案：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;整个分配方案分成两个步骤：1）手动生成分配方案，对原有的分区 Leader 位置不改变，只对副本进行分区重分配；2）等待数据迁移完成后，再手动更改分区分配方案，目的是均衡 Leader。&lt;/li&gt;
&lt;li&gt;直接用 Kafka 提供的 API 生成 分区重分配方案，直接执行分区重分配。&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;第一个方案理论上是对客户端影响最小的，把整个分配方案分成了两个步骤，也就是将对集群的带宽资源与客户端的影响分开了，对过程可控性更高了，但问题来了，集群中的某些主题，有 64 个分区，副本因子为 3，副本一共有 192 个，你需要保持原有分区 Leader 位置不变的情况下，去手动均衡其余副本，这个考验难度真的太大了，稍微有一点偏差，就会造成副本不均衡。&lt;/p&gt;
&lt;p&gt;因此我特意去看了分区重分配的源码，并对其过程进行了进一步分析，发现分配重分配的步骤是将分区原有的副本与新分配的副本的集合，组成一个分区副本集合，新分配的副本努力追上 Leader 的位移，最终加入 ISR，待全部副本都加入 ISR 之后，就会进行分区 Leader 选举，选举完后就会将原有的副本删除，具体细节我会单独写一篇文章。&lt;/p&gt;
&lt;p&gt;根据以上重分配的步骤，意味着在数据进行过程中不会发生客户端阻塞，因为期间 Leader 并没有发生变更，在数据迁移完成进行 Leader 选举时才会，但影响不大，针对这点影响我特意用脚本测试了一下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1860306/201912/1860306-20191219204022084-798977141.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;可以发现，在发送过程中，如果 Leader 发生了变更，生产者会及时拉取最新的元数据，并重新进行消息发送。&lt;/p&gt;
&lt;p&gt;针对以上的分析与测试，我们决定采取第二种方案，具体步骤如下：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;对每个主题生成分配分区分配策略：执行时间段（10:00-17:00），并对分配策略进行检查，并保存执行的 topic1_partition_reassignment.json 文件，并把原来的方案保存到topic1_partition_reassignment_rollback.json 文件中，以备后续的 rollback 操作；&lt;/li&gt;
&lt;li&gt;执行分配策略：执行时间段（00:30-02:30），准备好的 topic1_partition_reassignment.json 文件，执行完再验证并查看副本分配情况，每执行一个分配策略都要查看 ISR 收缩扩张状况、消息流转状况，确定没问题后再执行下一个分配策略；&lt;/li&gt;
&lt;li&gt;由于集群 broker 端的参数 &lt;code&gt;auto.leader.rebalance.enable=true&lt;/code&gt;，因此会自动执行 Preferred Leader 选举，默认时间间隔为 300 秒，期间需要观察 Preferred Leader 选举状况。&lt;/li&gt;
&lt;/ol&gt;&lt;h2 id=&quot;分区重分配&quot;&gt;分区重分配&lt;/h2&gt;
&lt;p&gt;对于新增的 Broker，Kafka 是不会自动地分配已有主题的负载，即不会将主题的分区分配到新增的 Broker，但我们可以通过 Kafka 提供的 API 对主题分区进行重分配操作，具体操作如下：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;生成需要执行分区重分配的主题列表 json 文件：&lt;/li&gt;
&lt;/ol&gt;&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;echo '{&quot;version&quot;:1,&quot;topics&quot;:[{&quot;topic&quot;:&quot;sjzn_spark_binlog_order_topic&quot;}]}' &amp;gt; sjzn_spark_binlog_order_topic.json&lt;/code&gt;
&lt;/pre&gt;
&lt;ol&gt;&lt;li&gt;生成主题的分配方案：&lt;/li&gt;
&lt;/ol&gt;&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;bin/kafka-reassign-partitions.sh  --zookeeper  --zookeeper xxx.xxx.xx.xxx:2181,xxx.xxx.xx.xxx:2181,xxx.xxx.xx.xxx:2181 --topics-to-move-json-file sjzn_spark_binlog_order_topic.json --broker-list &quot;0,1,2,3,4,5,6,7,8&quot; --generate&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;由于主题的有64个分区，每个分区3个副本，生成的分配数据还是挺大的，这里就不一一贴出来了&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;将分配方案保存到一个 json 文件中：&lt;/li&gt;
&lt;/ol&gt;&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;echo '{&quot;version&quot;:1,&quot;partitions&quot;:[{&quot;topic&quot;:&quot;sjzn_spark_binlog_order_topic&quot;,&quot;partition&quot;:59,&quot;replicas&quot;:[4,8,0],&quot;log_dirs&quot;:[&quot;any&quot;,&quot;any&quot;,&quot;any&quot;]} ......' &amp;gt; sjzn_spark_binlog_order_topic_reassignment.json&lt;/code&gt;
&lt;/pre&gt;
&lt;ol&gt;&lt;li&gt;执行分区重分配：&lt;/li&gt;
&lt;/ol&gt;&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt; bin/kafka-reassign-partitions.sh   --zookeeper xxx.xxx.xx.xxx:2181,xxx.xxx.xx.xxx:2181,xxx.xxx.xx.xxx:2181 --reassignment-json-file sjzn_spark_binlog_order_topic_reassignment.json --execute&lt;/code&gt;
&lt;/pre&gt;
&lt;ol&gt;&lt;li&gt;验证分区重分配是否执行成功：&lt;/li&gt;
&lt;/ol&gt;&lt;pre class=&quot;bash&quot;&gt;
&lt;code&gt;bin/kafka-reassign-partitions.sh  --zookeeper xxx.xxx.xx.xxx:2181,xxx.xxx.xx.xxx:2181,xxx.xxx.xx.xxx:2181 --reassignment-json-file sjzn_spark_order_unique_topic_resign.json --verify&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1860306/201912/1860306-20191219204030251-1861862243.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;由于该主题存在的数据量特别大，整个重分配过程需要维持了好几个小时：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1860306/201912/1860306-20191219204032904-282582165.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;在它进行数据迁移过程中，我特意去 kafka-manage 控制台观察了各分区数据的变动情况：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1860306/201912/1860306-20191219204034978-1666231889.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;从控制台可看出，各分区的副本数目基本都增加了，这也印证了分区当前的副本数等于原有的副本加上新分配的副本的集合，新分配的副本集合目前还没追上 Leader 的位移，因此没有加入 ISR 列表。&lt;/p&gt;
&lt;p&gt;有没有注意到一点，此时各分区的 Leader 都不在 Preferred Leader 中，因此后续等待新分配的副本追上 ISR 后，会进行新一轮的 Preferred Leader 选举，选举的细节实现我会单独写一篇文章去分析，敬请期待。&lt;/p&gt;
&lt;p&gt;过一段时间后，发现位移已经改变了：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1860306/201912/1860306-20191219204035683-502426116.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;从这点也印证了在分区重分配过程中，只要 Leader 没有发生变更，客户端是可以持续发送消息给分区 Leader 的。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1860306/201912/1860306-20191219204036134-1902859161.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;从上图可看出，新分配的副本追上 Leader 的位移后，就会加入 ISR 列表中。&lt;/p&gt;
&lt;p&gt;现在去看看集群带宽负载情况：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1860306/201912/1860306-20191219204037468-1601767287.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1860306/201912/1860306-20191219204039294-106896113.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;从上图中可看出，在迁移过程中，新分配的副本不断地从 Leader 拉取数据，占用了集群带宽。&lt;/p&gt;
&lt;p&gt;主题各分区重分配完成后的副本情况：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1860306/201912/1860306-20191219204041646-1008117238.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;从以上图中可看出，各分区的新分配的副本都已经全部在 ISR 列表中了，并且将旧分配的副本删除，经过 Preferred Leader 选举之后，各分区新分配副本的 Preferred Leader 大多数成为了该分区 leader。&lt;/p&gt;
&lt;blockquote readability=&quot;7&quot;&gt;
&lt;p&gt;更多精彩文章请关注作者维护的公众号「后端进阶」，这是一个专注后端相关技术的公众号。&lt;br/&gt;关注公众号并回复「后端」免费领取后端相关电子书籍。&lt;br/&gt;欢迎分享，转载请保留出处。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1860306/201912/1860306-20191219204042182-1296453700.jpg&quot; alt=&quot;公众号「后端进阶」，专注后端技术分享！&quot;/&gt;&lt;/p&gt;
</description>
<pubDate>Thu, 19 Dec 2019 12:41:00 +0000</pubDate>
<dc:creator>后端进阶</dc:creator>
<og:description>前段时间收到某个 Kafka 集群的生产客户端反馈发送消息耗时很高，于是花了一段时间去排查这个问题，最后该集群进行扩容，由于某些主题的当前数据量实在太大，在对这些主题迁移过程中话费了很长一段时间，不过</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/objcoding/p/12070055.html</dc:identifier>
</item>
</channel>
</rss>