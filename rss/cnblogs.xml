<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="css/feed.xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/" xmlns:og="http://ogp.me/ns#">
<channel>
<atom:link rel="self" href="http://192.168.1.4/fivefilters/makefulltextfeed.php?url=feed.cnblogs.com%2Fblog%2Fsitehome%2Frss&amp;max=10&amp;links=preserve&amp;exc=" />
<atom:link rel="alternate" title="Source URL" href="http://feed.cnblogs.com/blog/sitehome/rss" />
<atom:link rel="related" title="Subscribe to feed" href="http://www.subtome.com/#/subscribe?feeds=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed.cnblogs.com%252Fblog%252Fsitehome%252Frss%26max%3D10%26links%3Dpreserve%26exc%3D&amp;back=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed.cnblogs.com%252Fblog%252Fsitehome%252Frss%26max%3D10%26links%3Dpreserve%26exc%3D" />
<title>博客园_首页</title>
<link></link>
<description>代码改变世界</description>
<item>
<title>react高级特性 - 大~熊</title>
<link>http://www.cnblogs.com/floor/p/11626242.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/floor/p/11626242.html</guid>
<description>&lt;p&gt;用了那么久的react, 竟不知道到原来react有那么多高级特性. 假期没事干, 试用了下一些react高级特性. 下为试用记录.&lt;/p&gt;
&lt;h2 id=&quot;代码分割&quot;&gt;代码分割&lt;/h2&gt;
&lt;p&gt;将一个庞大的单页应用打包成一个庞大的js, 首屏加载可能会非常糟糕, 这时可能会考虑做代码分割, 即根据模块或者路由分开打包js, 异步按需加载组件.&lt;/p&gt;
&lt;p&gt;借助&lt;code&gt;webpack&lt;/code&gt;和一些异步组件库(比如&lt;a href=&quot;https://www.npmjs.com/package/react-loadable&quot;&gt;react-loadable&lt;/a&gt;, 也可以自己实现异步组件)就能很方便的实现这一点. 比如像下面这样:&lt;/p&gt;
&lt;pre class=&quot;javascript&quot;&gt;
&lt;code&gt;// router.js
import React from 'react';
import Loadable from 'react-loadable';

const Loading = () =&amp;gt; &amp;lt;div&amp;gt;Loading...&amp;lt;/div&amp;gt;;

///////////////页面路由配置////////////////

const Routers = {
    // 首页
    '/': Loadable({
        loader: () =&amp;gt; import(/* webpackChunkName: &quot;index&quot; */'./pages/Index.jsx'),
        loading: Loading,
      }),
    // 首页
    '/index': Loadable({
        loader: () =&amp;gt; import(/* webpackChunkName: &quot;index&quot; */'./pages/Index.jsx'),
        loading: Loading,
    }),
    '/404': Loadable({
        loader: () =&amp;gt; import(/* webpackChunkName: &quot;404&quot; */'./pages/404/index'),
        loading: Loading, 
    })
}

export default Routers;

// App.js
import React, { Component } from 'react';
import { BrowserRouter as Router, Route, Link, Switch } from &quot;react-router-dom&quot;;

import Routers from './router';

class App extends Component {
  componentDidMount() {

  }
  render() {
    return (
      &amp;lt;Router&amp;gt;
          &amp;lt;Switch&amp;gt;
            &amp;lt;Route path=&quot;/&quot; exact component={Routers[&quot;/&quot;]} /&amp;gt;
            &amp;lt;Route path=&quot;/index&quot; exact component={Routers[&quot;/index&quot;]} /&amp;gt;
            &amp;lt;Route component={Routers['/404']} /&amp;gt;
          &amp;lt;/Switch&amp;gt;
      &amp;lt;/Router&amp;gt;
    );
  }
}

export default App;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;我们直接使用&lt;code&gt;Loadable&lt;/code&gt;创建异步组件, 在合适的时候使用, &lt;code&gt;webpack&lt;/code&gt;会帮我做好代码分割, &lt;code&gt;Loadable&lt;/code&gt;可以帮我们维护好异步组件的状态, 并且能够支持定义加载中的组件. 上边demo完整版参见&lt;a href=&quot;https://github.com/yibingxiong/web-test&quot;&gt;web-test&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;其实, react已经原生提供了异步组件的支持, 其使用和&lt;code&gt;Loadable&lt;/code&gt;大体相同, 但是看起来会更加优雅.&lt;/p&gt;
&lt;pre class=&quot;javascript&quot;&gt;
&lt;code&gt;import { BrowserRouter as Router, Route, Switch } from 'react-router-dom';
import React, { Suspense, lazy } from 'react';

const Home = lazy(() =&amp;gt; import(/* webpackChunkName: &quot;home&quot; */'./pages/Home'));
const About = lazy(() =&amp;gt; import(/* webpackChunkName: &quot;about&quot; */'./pages/About'));

const App = () =&amp;gt; (
  &amp;lt;Router&amp;gt;
    &amp;lt;Suspense fallback={&amp;lt;div&amp;gt;Loading...&amp;lt;/div&amp;gt;}&amp;gt;
      &amp;lt;Switch&amp;gt;
        &amp;lt;Route exact path=&quot;/&quot; component={Home} /&amp;gt;
        &amp;lt;Route path=&quot;/about&quot; component={About} /&amp;gt;
      &amp;lt;/Switch&amp;gt;
    &amp;lt;/Suspense&amp;gt;
  &amp;lt;/Router&amp;gt;
);

export default App;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;这里我们使用&lt;code&gt;React.lazy&lt;/code&gt;方法创建异步组件, 和&lt;code&gt;Loadable&lt;/code&gt;类似, 也是使用了&lt;code&gt;import&lt;/code&gt;方法, webpack会帮我们处理好这个import. 不同的是他并不支持定义loading, loading的自定义可以使用&lt;code&gt;Suspense&lt;/code&gt;组件. 在其fallback中可以创建自定义的loading组件. 这个demo的完整版可参考&lt;a href=&quot;https://github.com/yibingxiong/source-code-analyse/tree/master/demos/react-demo&quot;&gt;react-demo&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&quot;context&quot;&gt;Context&lt;/h2&gt;
&lt;p&gt;第一次接触Context是看redux源码发现的, Context特性是redux实现的核心之一. Context可以让很深的props的传递变得简单优雅, 不再需要逐级传递.&lt;/p&gt;
&lt;p&gt;假设有如下组件, D组件需要拿A组件中数据, 可能需要从A通过props 传到B, 从B传到C, 从C 在通过props传到D. 非常麻烦.&lt;/p&gt;
&lt;pre class=&quot;javascript&quot;&gt;
&lt;code&gt;&amp;lt;A&amp;gt;
  &amp;lt;B&amp;gt;
    &amp;lt;C&amp;gt;
      &amp;lt;D&amp;gt;
      &amp;lt;/D&amp;gt;
    &amp;lt;/C&amp;gt;
  &amp;lt;/B&amp;gt;
&amp;lt;/A&amp;gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;看一下通过Context特性如何实现.&lt;/p&gt;
&lt;pre class=&quot;javascript&quot;&gt;
&lt;code&gt;// MyContext.js
import React from 'react';

const MyContext = React.createContext(&quot;我是来自A的默认值&quot;);
export default MyContext;

// A.js
import React from 'react';
import B from './B';
import MyContext from './MyContext';
export default class A extends React.Component {
    constructor(props) {
        super(props);
    }
    render() {
        return (
            &amp;lt;div&amp;gt;
                &amp;lt;MyContext.Provider value={'我是来自A的数据'}&amp;gt;
                    &amp;lt;B /&amp;gt;
                &amp;lt;/MyContext.Provider&amp;gt;
            &amp;lt;/div&amp;gt;
        )
    }
}

// B.js
import React from 'react';
import C from './C';
class B extends React.Component {
    render() {
        return (
            &amp;lt;div&amp;gt;
                &amp;lt;h3&amp;gt;我是B组件&amp;lt;/h3&amp;gt;
                &amp;lt;C /&amp;gt;
            &amp;lt;/div&amp;gt;
        );
    }
}
export default B;

// C.js
import React from 'react';
import MyContext from './MyContext';
import D from './D';

function C() {
    return (
        &amp;lt;MyContext.Consumer&amp;gt;
            {
                (value) =&amp;gt; (
                    &amp;lt;div&amp;gt;
                        &amp;lt;h3&amp;gt;我是C组件&amp;lt;/h3&amp;gt;
                        &amp;lt;div&amp;gt;我是来自A的数据: {value}&amp;lt;/div&amp;gt;
                        &amp;lt;D /&amp;gt;
                    &amp;lt;/div&amp;gt;
                )
            }
        &amp;lt;/MyContext.Consumer&amp;gt;
    )
}

export default C;

// D.js
import React from 'react';
import MyContext from './MyContext';

class D extends React.Component {
    render() {
        let context = this.context;
        return (
            &amp;lt;div&amp;gt;
                &amp;lt;h3&amp;gt;我是D组件&amp;lt;/h3&amp;gt;
                &amp;lt;div&amp;gt;我拿到了A中传递过来的数据&amp;lt;/div&amp;gt;
                {context}
            &amp;lt;/div&amp;gt;
        );
    }
}

D.contextType = MyContext;

export default D;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;可以看到在C组件和D组件没有通过任何props传递就拿到了A中的数据. 这个demo的完整版可参考&lt;a href=&quot;https://github.com/yibingxiong/source-code-analyse/tree/master/demos/react-demo&quot;&gt;react-demo&lt;/a&gt;. 这个例子可能看起来直接将需要共享的变量放到全局就可以了, 但是放到全局的当他变更后没法setState重新渲染, 而Context中的数据可以通过setState引起重新渲染.&lt;/p&gt;
&lt;p&gt;从上边的Demo来看, Context的使用非常简单&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;使用React.createContext()创建Context&lt;/li&gt;
&lt;li&gt;在父组件使用Context.Provider传值&lt;/li&gt;
&lt;li&gt;在子组件消费&lt;/li&gt;
&lt;/ol&gt;&lt;ul&gt;&lt;li&gt;对于class组件可以生命静态变量contextType消费, 见D&lt;/li&gt;
&lt;li&gt;对于函数是组件, 可以用Context.Consumer来消费, 见C&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;## 使用 PropTypes 进行类型检查&lt;/p&gt;
&lt;p&gt;一个被人调用的组件可以通过PropTypes对props参数类型进行校验, 将类型问题及早通知给调用方. 通过给组件指定静态属性propTypes并结合prop-types库可以很方便实现. prop-types需要单独安装.&lt;/p&gt;
&lt;p&gt;如下是prop-types提供的一些校验器, 来自&lt;a href=&quot;https://react-1251415695.cos-website.ap-chengdu.myqcloud.com/docs/typechecking-with-proptypes.html&quot;&gt;react中文文档&lt;/a&gt;&lt;/p&gt;
&lt;pre class=&quot;javascript&quot;&gt;
&lt;code&gt;import PropTypes from 'prop-types';

MyComponent.propTypes = {
  // 你可以将属性声明为 JS 原生类型，默认情况下
  // 这些属性都是可选的。
  optionalArray: PropTypes.array,
  optionalBool: PropTypes.bool,
  optionalFunc: PropTypes.func,
  optionalNumber: PropTypes.number,
  optionalObject: PropTypes.object,
  optionalString: PropTypes.string,
  optionalSymbol: PropTypes.symbol,

  // 任何可被渲染的元素（包括数字、字符串、元素或数组）
  // (或 Fragment) 也包含这些类型。
  optionalNode: PropTypes.node,

  // 一个 React 元素。
  optionalElement: PropTypes.element,

  // 一个 React 元素类型（即，MyComponent）。
  optionalElementType: PropTypes.elementType,

  // 你也可以声明 prop 为类的实例，这里使用
  // JS 的 instanceof 操作符。
  optionalMessage: PropTypes.instanceOf(Message),

  // 你可以让你的 prop 只能是特定的值，指定它为
  // 枚举类型。
  optionalEnum: PropTypes.oneOf(['News', 'Photos']),

  // 一个对象可以是几种类型中的任意一个类型
  optionalUnion: PropTypes.oneOfType([
    PropTypes.string,
    PropTypes.number,
    PropTypes.instanceOf(Message)
  ]),

  // 可以指定一个数组由某一类型的元素组成
  optionalArrayOf: PropTypes.arrayOf(PropTypes.number),

  // 可以指定一个对象由某一类型的值组成
  optionalObjectOf: PropTypes.objectOf(PropTypes.number),

  // 可以指定一个对象由特定的类型值组成
  optionalObjectWithShape: PropTypes.shape({
    color: PropTypes.string,
    fontSize: PropTypes.number
  }),
  
  // An object with warnings on extra properties
  optionalObjectWithStrictShape: PropTypes.exact({
    name: PropTypes.string,
    quantity: PropTypes.number
  }),   

  // 你可以在任何 PropTypes 属性后面加上 `isRequired` ，确保
  // 这个 prop 没有被提供时，会打印警告信息。
  requiredFunc: PropTypes.func.isRequired,

  // 任意类型的数据
  requiredAny: PropTypes.any.isRequired,

  // 你可以指定一个自定义验证器。它在验证失败时应返回一个 Error 对象。
  // 请不要使用 `console.warn` 或抛出异常，因为这在 `onOfType` 中不会起作用。
  customProp: function(props, propName, componentName) {
    if (!/matchme/.test(props[propName])) {
      return new Error(
        'Invalid prop `' + propName + '` supplied to' +
        ' `' + componentName + '`. Validation failed.'
      );
    }
  },

  // 你也可以提供一个自定义的 `arrayOf` 或 `objectOf` 验证器。
  // 它应该在验证失败时返回一个 Error 对象。
  // 验证器将验证数组或对象中的每个值。验证器的前两个参数
  // 第一个是数组或对象本身
  // 第二个是他们当前的键。
  customArrayProp: PropTypes.arrayOf(function(propValue, key, componentName, location, propFullName) {
    if (!/matchme/.test(propValue[key])) {
      return new Error(
        'Invalid prop `' + propFullName + '` supplied to' +
        ' `' + componentName + '`. Validation failed.'
      );
    }
  })
};&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;也可以给props指定默认值&lt;/p&gt;
&lt;pre class=&quot;javascript&quot;&gt;
&lt;code&gt;class Greeting extends React.Component {
  render() {
    return (
      &amp;lt;h1&amp;gt;Hello, {this.props.name}&amp;lt;/h1&amp;gt;
    );
  }
}

// 指定 props 的默认值：
Greeting.defaultProps = {
  name: 'Stranger'
};

// 渲染出 &quot;Hello, Stranger&quot;：
ReactDOM.render(
  &amp;lt;Greeting /&amp;gt;,
  document.getElementById('example')
);&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;检验和默认值也可以这样写&lt;/p&gt;
&lt;pre class=&quot;javascript&quot;&gt;
&lt;code&gt;class Greeting extends React.Component {
  static defaultProps = {
    name: 'stranger'
  }
  static propTypes = {
    name: PropTypes.string,
  }
  render() {
    return (
      &amp;lt;div&amp;gt;Hello, {this.props.name}&amp;lt;/div&amp;gt;
    )
  }
}&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;错误边界&quot;&gt;错误边界&lt;/h2&gt;
&lt;p&gt;错误边界是一种 React 组件，这种组件可以捕获并打印发生在其子组件树任何位置的 JavaScript 错误，并且，它会渲染出备用 UI，而不是渲染那些崩溃了的子组件树。错误边界在渲染期间、生命周期方法和整个组件树的构造函数中捕获错误。&lt;/p&gt;
&lt;p&gt;当子组件抛出错误时, 下边的两个生命周期会被触发, 可以在这里边处理错误, 显示降级UI, 向服务端上报错误.&lt;/p&gt;
&lt;p&gt;错误边界组件核心生命周期如下&lt;/p&gt;
&lt;pre class=&quot;javascript&quot;&gt;
&lt;code&gt;static getDerivedStateFromError()
componentDidCatch()&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;下面是个小demo&lt;/p&gt;
&lt;pre class=&quot;javascript&quot;&gt;
&lt;code&gt;// index.js

import React from 'react';
import ErrorComponent from './ErrorComponent';

export default class Home extends React.Component {
    constructor(props) {
        super(props);
        this.state = {
            hasError: false,
        }
    }

    static getDerivedStateFromError() {
        console.log('getDerivedStateFromError');
        return { hasError: true };
    }
    componentDidCatch (error, info) {
        console.log('componentDidCatch');
        console.log({
            error,
            info,
        })
    }
    render() {
        if (this.state.hasError) {
            return &amp;lt;div&amp;gt;发生了某种错误&amp;lt;/div&amp;gt;
        }
        return (
            &amp;lt;div&amp;gt;
                &amp;lt;h3&amp;gt;错误边界测试&amp;lt;/h3&amp;gt;
                &amp;lt;ErrorComponent /&amp;gt;
            &amp;lt;/div&amp;gt;
        )
    }
}

// ErrorComponent.js
import React from 'react';

export default class Home extends React.Component {
    state = {
        showError: false,
    }
    componentDidMount() {
    }
    click = () =&amp;gt; {
        this.setState({
            showError: true,
        })
    }
    render() {
        if (this.state.showError) {
            throw new Error(&quot;抛出错误&quot;);
        }
        return (
            &amp;lt;div onClick={this.click}&amp;gt;我是产生错误的组件&amp;lt;/div&amp;gt;
        )
    }
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;我们可以在componentDidCatch(error, info) 获取错误信息, 错误信息error.message, 错误堆栈error.stack, 组件堆栈info.componentStack, 这些信息可以显示给用户, 也可以上报到服务器. 可以在getDerivedStateFromError返回state, 渲染降级组件.&lt;/p&gt;
&lt;h2 id=&quot;fragments&quot;&gt;Fragments&lt;/h2&gt;
&lt;p&gt;Fragments解决了一个组件不能返回多个元素的问题, 没有Fragments时一个组件没法返回多个元素, 所以我们经常用个div包一下, 结果是增加了一个多余的dom节点, 甚至产生不合法的dom, 比如下边这样的.&lt;/p&gt;
&lt;pre class=&quot;javascript&quot;&gt;
&lt;code&gt;// 组件1
function Columns() {
    return (
        &amp;lt;div&amp;gt;
            &amp;lt;td&amp;gt;第一列&amp;lt;/td&amp;gt;
            &amp;lt;td&amp;gt;第二列&amp;lt;/td&amp;gt;
        &amp;lt;/div&amp;gt;
    )
}
// 组件2
function Table() {
  return (
    &amp;lt;table&amp;gt;
      &amp;lt;tr&amp;gt;
        &amp;lt;Columns/&amp;gt;
      &amp;lt;/tr&amp;gt;
    &amp;lt;/table&amp;gt;
  )
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;因为没法返回多个元素, 所以在Columns组件中使用了div包裹两个td, 然后在Table组件使用, 结果就产生了tr里边放td的错误结构. 使用Fragments特性可以很方便的解决这个问题. 如下. 只要用个&lt;code&gt;&amp;lt;React.Fragment&amp;gt;&lt;/code&gt;包装就可以了, 也可以写成&lt;code&gt;&amp;lt;&amp;gt;something&amp;lt;/&amp;gt;&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&quot;javascript&quot;&gt;
&lt;code&gt;function Columns() {
    return (
        &amp;lt;React.Fragment&amp;gt;
            &amp;lt;td&amp;gt;第一列&amp;lt;/td&amp;gt;
            &amp;lt;td&amp;gt;第二列&amp;lt;/td&amp;gt;
        &amp;lt;/React.Fragment&amp;gt;
    )
}&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;portals&quot;&gt;Portals&lt;/h2&gt;
&lt;p&gt;Portal 提供了一种将子节点渲染到存在于父组件以外的 DOM 节点的方案. portal 的典型使用场景是当父组件有 overflow: hidden 或 z-index 样式时，但你需要子组件能够在视觉上“跳出”其容器。例如，对话框、悬浮卡以及提示框.&lt;/p&gt;
&lt;p&gt;如下是一个toast组件 demo, 完整版参考&lt;a href=&quot;https://github.com/yibingxiong/source-code-analyse/tree/master/demos/react-demo&quot;&gt;react-demo&lt;/a&gt;&lt;/p&gt;
&lt;pre class=&quot;javascript&quot;&gt;
&lt;code&gt;// Toast.js
import React from 'react';
import ReactDOM from 'react-dom';
import './Toast.css';

export default class Toast extends React.Component {
  constructor(props) {
    super(props);
    this.el = document.querySelector('body');
  }

  render() {
    return ReactDOM.createPortal(
      (
          &amp;lt;div className=&quot;toast&quot;&amp;gt;
              &amp;lt;div className=&quot;toast-inner&quot;&amp;gt;
                {this.props.text}
              &amp;lt;/div&amp;gt;
          &amp;lt;/div&amp;gt;
      ),
      this.el,
    );
  }
}
// PortalTest.js
import React from 'react';
import Toast from './Toast';
export default class PortalTest extends React.Component {
    render() {
        return (
            &amp;lt;div&amp;gt;
                &amp;lt;h1&amp;gt;PortalTest&amp;lt;/h1&amp;gt;
                &amp;lt;Toast text=&quot;toast提示&quot;/&amp;gt;
            &amp;lt;/div&amp;gt;
        )
    }
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;结果如图&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1128201/201910/1128201-20191006001816015-248221883.png&quot; alt=&quot;Portals测试结果&quot;/&gt;&lt;/p&gt;
&lt;p&gt;可以发现Toast这个组件不是在其父元素中, 而是跑到了我们期望的body里边. 这样不管父组件写overflow:hidden;还是其他都不会影响到这个toast.&lt;/p&gt;
&lt;h2 id=&quot;forwardref&quot;&gt;forwardRef&lt;/h2&gt;
&lt;p&gt;forwardRef是一种将ref转移到子组件的方式.&lt;/p&gt;
&lt;p&gt;forwardRef 主要有两种使用场景&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;希望对基础组件做一些封装, 但是希望基础组件的实例的方法能被调用&lt;/li&gt;
&lt;li&gt;高阶组件中希望ref指向被包裹的组件而不是外层组件&lt;/li&gt;
&lt;/ul&gt;&lt;ol&gt;&lt;li&gt;关于第一种场景&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;之前做ReactNative时有个FlatList组件, 希望对他封装一层, 但是又希望调用方可以使用ref或则FlatList的实例, 方便调用上边的方法. 这时就可以用forwardRef. 下面举的是 input的例子, 我们希望封装一下, 但让调用方仍然可以通过ref获取dom调用focus.&lt;/p&gt;
&lt;pre class=&quot;javascript&quot;&gt;
&lt;code&gt;import React from 'react';

const LabelInput =
    React.forwardRef((props, ref) =&amp;gt; {
        return &amp;lt;div&amp;gt;
            &amp;lt;label&amp;gt;{props.label}&amp;lt;/label&amp;gt;
            &amp;lt;input ref={ref} className=&quot;input&quot; style={{ border: '1px solid red' }} /&amp;gt;
        &amp;lt;/div&amp;gt;
    })

export default class Home extends React.Component {
    constructor(props) {
        super(props);
        this.ref = React.createRef();
    }

    focus = () =&amp;gt; {
        try {
            this.ref.current.focus();
        } catch (e) {
            console.log(e);
        }
    }
    render() {
        return (
            &amp;lt;div&amp;gt;
                &amp;lt;h1&amp;gt;测试forwardRef&amp;lt;/h1&amp;gt;
                &amp;lt;LabelInput ref={this.ref} label=&quot;手机号&quot;/&amp;gt;
                &amp;lt;button onClick={this.focus}&amp;gt;点击input可以获取焦点&amp;lt;/button&amp;gt;
            &amp;lt;/div&amp;gt;
        )
    }
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;在LabelInput组件里边将ref转到了input上, 从而外边的调用方可以直接掉focus方法. 如果不做转发, 那么ref将指向div, 再要找到里边的input就比较麻烦了, 而且破坏了组件的封装性.&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;关于第二种场景&lt;/li&gt;
&lt;/ol&gt;&lt;pre class=&quot;javascript&quot;&gt;
&lt;code&gt;import React from 'react';

function logProps(Component) {
    class LogProps extends React.Component {
        componentDidUpdate(prevProps) {
            console.log('old props:', prevProps);
            console.log('new props:', this.props);
        }

        render() {
            const { forwardedRef, ...rest } = this.props;

            // 将自定义的 prop 属性 “forwardedRef” 定义为 ref
            return &amp;lt;Component ref={forwardedRef} {...rest} /&amp;gt;;
        }
    }

    // 注意 React.forwardRef 回调的第二个参数 “ref”。
    // 我们可以将其作为常规 prop 属性传递给 LogProps，例如 “forwardedRef”
    // 然后它就可以被挂载到被 LogPros 包裹的子组件上。
    return React.forwardRef((props, ref) =&amp;gt; {
        return &amp;lt;LogProps {...props} forwardedRef={ref} /&amp;gt;;
    });
}

class InnerComp extends React.Component {
    render() {
        return &amp;lt;div id=&quot;InnerComp&quot;&amp;gt;
            被包裹的组件-text={this.props.text}
        &amp;lt;/div&amp;gt;
    }
}

const Comp = logProps(InnerComp);

export default class Home extends React.Component {
    constructor(props) {
        super(props);
        this.ref = React.createRef();
    }
    click = () =&amp;gt; {
        console.log(this.ref.current);
    }
    render() {
        return (
            &amp;lt;div&amp;gt;
                &amp;lt;h1&amp;gt;测试forwardRef&amp;lt;/h1&amp;gt;
                &amp;lt;Comp ref={this.ref} text=&quot;测试&quot; /&amp;gt;
                &amp;lt;button onClick={this.click}&amp;gt;点击打印ref&amp;lt;/button&amp;gt;
            &amp;lt;/div&amp;gt;
        )
    }
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;这里点击打印的是InnerComp组件, 如果去掉forwardRef则打印LogProps组件. 可见通过forwardRef可以成功将ref传递到被包裹的组件.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;注意&lt;/strong&gt; 函数组件不能给ref, 只有class组件可以. 测试发现的.&lt;/p&gt;
&lt;h2 id=&quot;小结&quot;&gt;小结&lt;/h2&gt;
&lt;table&gt;&lt;thead/&gt;&lt;tbody readability=&quot;13&quot;&gt;&lt;tr class=&quot;odd&quot; readability=&quot;5&quot;&gt;&lt;td&gt;代码分割&lt;/td&gt;
&lt;td&gt;提供异步组件,实现拆包&lt;/td&gt;
&lt;td&gt;需要优化包体积时使用&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;even&quot; readability=&quot;2&quot;&gt;&lt;td&gt;Context&lt;/td&gt;
&lt;td&gt;跨层级传递数据&lt;/td&gt;
&lt;td&gt;优化多层级传递props问题&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;odd&quot; readability=&quot;6&quot;&gt;&lt;td&gt;PropTypes 进行类型检查&lt;/td&gt;
&lt;td&gt;可以对props的类型加上校验器&lt;/td&gt;
&lt;td&gt;希望及早暴露props类型错误&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;even&quot; readability=&quot;4&quot;&gt;&lt;td&gt;错误边界&lt;/td&gt;
&lt;td&gt;提供不过子组件错误和在错误返回指定state的生命周期&lt;/td&gt;
&lt;td&gt;希望在渲染错误时提供降级UI或上报错误&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;odd&quot; readability=&quot;4&quot;&gt;&lt;td&gt;Fragments&lt;/td&gt;
&lt;td&gt;提供在一个组件返回多个元素的能力&lt;/td&gt;
&lt;td&gt;希望在一个组件返回多个元素&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;even&quot; readability=&quot;2&quot;&gt;&lt;td&gt;Portals&lt;/td&gt;
&lt;td&gt;提供将元素渲染到父元素之外的能力&lt;/td&gt;
&lt;td&gt;Toast, Modal等&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;odd&quot; readability=&quot;3&quot;&gt;&lt;td&gt;forwardRef&lt;/td&gt;
&lt;td&gt;转发传进来的ref&lt;/td&gt;
&lt;td&gt;希望将外部传递的ref转移到别的元素上,而不是自己&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;</description>
<pubDate>Sat, 05 Oct 2019 16:19:00 +0000</pubDate>
<dc:creator>大~熊</dc:creator>
<og:description>用了那么久的react, 竟不知道到原来react有那么多高级特性. 假期没事干, 试用了下一些react高级特性. 下为试用记录.</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/floor/p/11626242.html</dc:identifier>
</item>
<item>
<title>【原创】（六）Linux内存管理 - zoned page frame allocator - 1 - LoyenWang</title>
<link>http://www.cnblogs.com/LoyenWang/p/11626237.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/LoyenWang/p/11626237.html</guid>
<description>&lt;ul&gt;&lt;li&gt;&lt;code&gt;Read the fucking source code!&lt;/code&gt; --By 鲁迅&lt;/li&gt;
&lt;li&gt;&lt;code&gt;A picture is worth a thousand words.&lt;/code&gt; --By 高尔基&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;说明：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;Kernel版本：4.14&lt;/li&gt;
&lt;li&gt;ARM64处理器，Contex-A53，双核&lt;/li&gt;
&lt;li&gt;使用工具：Source Insight 3.5， Visio&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;之前的系列内存管理文章基本上描述的是物理页面的初始化过程，以及虚拟页面到物理页面的映射建立过程，从这篇文章开始，真正要涉及到页面的分配了。接下来的文章会围绕着&lt;code&gt;分区页框分配器(zoned page frame allocator)&lt;/code&gt;来展开，其中会包含大家熟知的&lt;code&gt;Buddy System&lt;/code&gt;分析。&lt;/p&gt;
&lt;p&gt;本文会先围绕着涉及到的数据结构，以及大体的流程做一个整体的分析，后续会针对这个流程中的细节进行更详细的拆解，我已经迫不及待了。&lt;/p&gt;

&lt;h2 id=&quot;概述&quot;&gt;2.1 概述&lt;/h2&gt;
&lt;p&gt;先回顾一下&lt;a href=&quot;https://www.cnblogs.com/LoyenWang/p/11568481.html&quot;&gt;（五）Linux内存管理zone_sizes_init&lt;/a&gt;的数据结构图：&lt;br/&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1771657/201910/1771657-20191006001159739-501501770.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;上述的结构体，描述的是下面这张图：&lt;br/&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1771657/201910/1771657-20191006001219745-1992148860.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Node ---&amp;gt; ZONE ---&amp;gt; Page&lt;/code&gt;的组织关系，其中&lt;code&gt;Buddy System&lt;/code&gt;中，页面都是以2的次幂来组织成链表，比如&lt;code&gt;free_area[0]&lt;/code&gt;，对应的是&lt;code&gt;1个page&lt;/code&gt;链表，其中又根据不同的&lt;code&gt;MIGRATE_xxxx&lt;/code&gt;类型来组织，如下图：&lt;br/&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1771657/201910/1771657-20191006001229047-942884289.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;ARM64&lt;/code&gt;中&lt;code&gt;MAX_ORDER&lt;/code&gt;默认值为11，&lt;code&gt;PAGE_SIZE=4K&lt;/code&gt;，因此总共有&lt;code&gt;0 ~ 10&lt;/code&gt;11个链表数组，链表中的连续的页面为&lt;code&gt;2^0 ~ 2^10&lt;/code&gt;，对应大小为&lt;code&gt;4K ~ 4M&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;可以通过&lt;code&gt;cat /proc/pagetypeinfo&lt;/code&gt;来查看下系统的页面信息，如下图：&lt;br/&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1771657/201910/1771657-20191006001241627-1639848612.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;可以通过&lt;code&gt;cat /proc/zoneinfo&lt;/code&gt;来查看&lt;code&gt;Node&lt;/code&gt;的&lt;code&gt;ZONE&lt;/code&gt;计数信息：&lt;br/&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1771657/201910/1771657-20191006001251280-1153190066.png&quot;/&gt;&lt;/p&gt;
&lt;h2 id=&quot;migrate类型&quot;&gt;2.2 Migrate类型&lt;/h2&gt;
&lt;p&gt;从上边的图中可以看到&lt;code&gt;MIGRATE_xxx&lt;/code&gt;不同的迁移类型，表明页面的移动属性，并在可能的情况下通过将相同属性的页面分组在一起来抑制内存的连续碎片。&lt;/p&gt;
&lt;pre class=&quot;c&quot;&gt;
&lt;code&gt;enum migratetype {
    MIGRATE_UNMOVABLE,
    MIGRATE_MOVABLE,
    MIGRATE_RECLAIMABLE,
    MIGRATE_PCPTYPES,   /* the number of types on the pcp lists */
    MIGRATE_HIGHATOMIC = MIGRATE_PCPTYPES,
#ifdef CONFIG_CMA
    /*
     * MIGRATE_CMA migration type is designed to mimic the way
     * ZONE_MOVABLE works.  Only movable pages can be allocated
     * from MIGRATE_CMA pageblocks and page allocator never
     * implicitly change migration type of MIGRATE_CMA pageblock.
     *
     * The way to use it is to change migratetype of a range of
     * pageblocks to MIGRATE_CMA which can be done by
     * __free_pageblock_cma() function.  What is important though
     * is that a range of pageblocks must be aligned to
     * MAX_ORDER_NR_PAGES should biggest page be bigger then
     * a single pageblock.
     */
    MIGRATE_CMA,
#endif
#ifdef CONFIG_MEMORY_ISOLATION
    MIGRATE_ISOLATE,    /* can't allocate from here */
#endif
    MIGRATE_TYPES
};&lt;/code&gt;
&lt;/pre&gt;
&lt;ul&gt;&lt;li&gt;&lt;code&gt;MIGRATE_UNMOVABLE&lt;/code&gt;：无法移动和检索的类型，用于内核分配的页面，I/O缓冲区，内核堆栈等；&lt;/li&gt;
&lt;li&gt;&lt;code&gt;MIGRATE_MOVABLE&lt;/code&gt;：当需要大的连续内存时，通过移动当前使用的页面来尽可能防止碎片，用于分配用户内存；&lt;/li&gt;
&lt;li&gt;&lt;code&gt;MIGRATE_RECLAIMABLE&lt;/code&gt;：当没有可用内存时使用此类型；&lt;/li&gt;
&lt;li&gt;&lt;code&gt;MIGRATE_HIGHATOMIC&lt;/code&gt;：减少原子分配请求无法进行高阶页面分配的可能，内核会提前准备一个页面块；&lt;/li&gt;
&lt;li&gt;&lt;code&gt;MIGRATE_CMA&lt;/code&gt;：页面类型由CMA内存分配器单独管理；&lt;/li&gt;
&lt;li&gt;&lt;code&gt;MIGRATE_ISOLATE&lt;/code&gt;：内核会暂时更改为这种类型，以迁移使用中的系列活动页面；&lt;/li&gt;
&lt;/ul&gt;&lt;h2 id=&quot;gfp_xxx请求标志gfp_mask&quot;&gt;2.3 __GFP_xxx请求标志（gfp_mask）&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;__GFP_xxx&lt;/code&gt;为内部使用的标志，在&lt;code&gt;include/linux/gfp.h&lt;/code&gt;文件中，外部不应该使用这些Flag，这些标志在页面申请的时候使用，其中&lt;code&gt;GFP&lt;/code&gt;表示&lt;code&gt;get free page&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;罗列部分如下：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;code&gt;__GFP_DMA&lt;/code&gt;：请求在&lt;code&gt;ZONE_DMA&lt;/code&gt;区域中分配页面；&lt;/li&gt;
&lt;li&gt;&lt;code&gt;__GFP_HIGHMEM&lt;/code&gt;：请求在&lt;code&gt;ZONE_HIGHMEM&lt;/code&gt;区域中分配页面；&lt;/li&gt;
&lt;li&gt;&lt;code&gt;__GFP_MOVABLE&lt;/code&gt;：&lt;code&gt;ZONE_MOVALBE&lt;/code&gt;可用时在该区域分配页面，同时表示页面分配后可以在内存压缩时进行迁移，也能进行回收；&lt;/li&gt;
&lt;li&gt;&lt;code&gt;__GFP_RECLAIMABLE&lt;/code&gt;：请求分配到可恢复页面；&lt;/li&gt;
&lt;li&gt;&lt;code&gt;__GFP_HIGH&lt;/code&gt;：高优先级处理请求；&lt;/li&gt;
&lt;li&gt;&lt;code&gt;__GFP_IO&lt;/code&gt;：请求在分配期间进行I/O操作；&lt;/li&gt;
&lt;li&gt;&lt;code&gt;__GFP_FS&lt;/code&gt;：请求在分配期间进行文件系统调用；&lt;/li&gt;
&lt;li&gt;&lt;code&gt;__GFP_ZERO&lt;/code&gt;：请求将分配的区域初始化为0；&lt;/li&gt;
&lt;li&gt;&lt;code&gt;__GFP_NOFAIL&lt;/code&gt;：不允许请求失败，会无限重试；&lt;/li&gt;
&lt;li&gt;&lt;code&gt;__GFP_NORETRY&lt;/code&gt;：请求不重试内存分配请求；&lt;/li&gt;
&lt;/ul&gt;&lt;h2 id=&quot;alloc_xxxx分配标志alloc_flags&quot;&gt;2.4 ALLOC_xxxx分配标志（alloc_flags）&lt;/h2&gt;
&lt;p&gt;分配标志定义在&lt;code&gt;mm/internal.h&lt;/code&gt;文件中，在页面的分配函数中与&lt;code&gt;gfp_mask&lt;/code&gt;分开使用，这些标志时用于内部函数的分配。&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;code&gt;ALLOC_WMARK_MIN&lt;/code&gt;：仅在最小水位&lt;code&gt;water mark&lt;/code&gt;及以上限制页面分配；&lt;/li&gt;
&lt;li&gt;&lt;code&gt;ALLOC_WMARK_LOW&lt;/code&gt;：仅在低水位&lt;code&gt;water mark&lt;/code&gt;及以上限制页面分配；&lt;/li&gt;
&lt;li&gt;&lt;code&gt;ALLOC_WMARK_HIGH&lt;/code&gt;：仅在高水位&lt;code&gt;water mark&lt;/code&gt;及以上限制页面分配；&lt;/li&gt;
&lt;li&gt;&lt;code&gt;ALLOC_HARDER&lt;/code&gt;：努力分配，一般在&lt;code&gt;gfp_mask&lt;/code&gt;设置了&lt;code&gt;__GFP_ATOMIC&lt;/code&gt;时会使用；&lt;/li&gt;
&lt;li&gt;&lt;code&gt;ALLOC_HIGH&lt;/code&gt;：高优先级分配，一般在&lt;code&gt;gfp_mask&lt;/code&gt;设置了&lt;code&gt;__GFP_HIGH&lt;/code&gt;时使用；&lt;/li&gt;
&lt;li&gt;&lt;code&gt;ALLOC_CPUSET&lt;/code&gt;：检查是否为正确的cpuset；&lt;/li&gt;
&lt;li&gt;&lt;code&gt;ALLOC_CMA&lt;/code&gt;：允许从CMA区域进行分配；&lt;/li&gt;
&lt;/ul&gt;&lt;h2 id=&quot;struct-alloc_context&quot;&gt;2.5 &lt;code&gt;struct alloc_context&lt;/code&gt;&lt;/h2&gt;
&lt;p&gt;在页面分配的过程中，有一个结构叫&lt;code&gt;struct alloc_context&lt;/code&gt;，这个结构用于存储各个函数之间传递的参数。这种思想在平时的coding中是可以去借鉴的，比如有些人写代码很喜欢用全局变量，改成这种&lt;code&gt;context&lt;/code&gt;的形式，在各个函数之间传递显得更为优雅。直接看代码吧：&lt;/p&gt;
&lt;pre class=&quot;c&quot;&gt;
&lt;code&gt;/*
 * Structure for holding the mostly immutable allocation parameters passed
 * between functions involved in allocations, including the alloc_pages*
 * family of functions.
 *
 * nodemask, migratetype and high_zoneidx are initialized only once in
 * __alloc_pages_nodemask() and then never change.
 *
 * zonelist, preferred_zone and classzone_idx are set first in
 * __alloc_pages_nodemask() for the fast path, and might be later changed
 * in __alloc_pages_slowpath(). All other functions pass the whole strucure
 * by a const pointer.
 */
struct alloc_context {
    struct zonelist *zonelist;
    nodemask_t *nodemask;
    struct zoneref *preferred_zoneref;
    int migratetype;
    enum zone_type high_zoneidx;
    bool spread_dirty_pages;
};&lt;/code&gt;
&lt;/pre&gt;
&lt;ul&gt;&lt;li&gt;&lt;code&gt;zonelist&lt;/code&gt;：用于分配页面的区域列表；&lt;/li&gt;
&lt;li&gt;&lt;code&gt;nodemask&lt;/code&gt;：指定Node，如果没有指定，则在所有节点中进行分配；&lt;/li&gt;
&lt;li&gt;&lt;code&gt;preferred_zone&lt;/code&gt;：指定要在快速路径中首先分配的区域，在慢路径中指定了&lt;code&gt;zonelist&lt;/code&gt;中的第一个可用区域；&lt;/li&gt;
&lt;li&gt;&lt;code&gt;migratetype&lt;/code&gt;：要分配的迁移页面类型；&lt;/li&gt;
&lt;li&gt;&lt;code&gt;high_zoneidx&lt;/code&gt;：将分配限制为小于区域列表中指定的高区域；&lt;/li&gt;
&lt;li&gt;&lt;code&gt;spread_dirty_pages&lt;/code&gt;：脏区平衡相关；&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在上篇文章中描述到各个&lt;code&gt;zone&lt;/code&gt;，实际上各个&lt;code&gt;zone&lt;/code&gt;最终组织起来是在&lt;code&gt;build_all_zonelists&lt;/code&gt;函数中实现的：&lt;br/&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1771657/201910/1771657-20191006001313609-398829452.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;整体完成的工作也比较简单，将所有&lt;code&gt;Node&lt;/code&gt;中可用的&lt;code&gt;zone&lt;/code&gt;全部添加到各个&lt;code&gt;Node&lt;/code&gt;中的&lt;code&gt;zonelist&lt;/code&gt;中，也就是对应的&lt;code&gt;struct pglist_data&lt;/code&gt;结构体中的&lt;code&gt;struct zonelist node_zonelists&lt;/code&gt;字段。&lt;/p&gt;
&lt;p&gt;这一步之后，准备工作基本就绪，进行页面申请的工作就可以开始了。&lt;/p&gt;

&lt;p&gt;下面的流程开始真正的页面申请了，在内部的实现中通过&lt;code&gt;__alloc_pages&lt;/code&gt;来实现的：&lt;br/&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1771657/201910/1771657-20191006001326475-348220432.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;在页面分配时，有两种路径可以选择，如果在快速路径中分配成功了，则直接返回分配的页面；快速路径分配失败则选择慢速路径来进行分配。&lt;/p&gt;
&lt;h2 id=&quot;fast-path&quot;&gt;4.1 Fast Path&lt;/h2&gt;
&lt;p&gt;快速路径分配，是通过&lt;code&gt;get_page_from_freelist&lt;/code&gt;来完成的，具体的流程及分析如下图所示：&lt;br/&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1771657/201910/1771657-20191006001337263-1883106181.png&quot;/&gt;&lt;/p&gt;
&lt;h2 id=&quot;slow-path&quot;&gt;4.2 Slow Path&lt;/h2&gt;
&lt;p&gt;慢速路径分配，最终也会调用&lt;code&gt;get_page_from_freelist&lt;/code&gt;，流程分析如下：&lt;br/&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1771657/201910/1771657-20191006001359420-1831491364.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1771657/201910/1771657-20191006001411515-1462602436.jpg&quot;/&gt;&lt;/p&gt;
</description>
<pubDate>Sat, 05 Oct 2019 16:17:00 +0000</pubDate>
<dc:creator>LoyenWang</dc:creator>
<og:description>背景 By 鲁迅 By 高尔基 说明： 1. Kernel版本：4.14 2. ARM64处理器，Contex A53，双核 3. 使用工具：Source Insight 3.5， Visio 1.</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/LoyenWang/p/11626237.html</dc:identifier>
</item>
<item>
<title>冒泡排序深入理解 - Hs-black</title>
<link>http://www.cnblogs.com/Hs-black/p/11626111.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/Hs-black/p/11626111.html</guid>
<description>&lt;h3 id=&quot;对于冒泡排序有一个小性质-每一次都会把序列未排好序的最大数沉底-即推到序列尾部&quot;&gt;对于冒泡排序有一个小性质: 每一次都会把序列未排好序的最大数&quot;沉底&quot;, 即推到序列尾部&lt;/h3&gt;

&lt;blockquote readability=&quot;9&quot;&gt;
&lt;p&gt;留意着农场之外的长期职业生涯的可能性，奶牛Bessie开始在不同的在线编程网站上学习算法。&lt;/p&gt;
&lt;p&gt;她到目前为止最喜欢的算法是“冒泡排序”。这是Bessie的对长度为&lt;em&gt;N&lt;/em&gt;的数组&lt;em&gt;A&lt;/em&gt;进行排序的奶牛码实现。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;pre&gt;
&lt;code&gt;sorted = false
while (not sorted):
   sorted = true
   moo
   for i = 0 to N-2:
      if A[i+1] &amp;lt; A[i]:
         swap A[i], A[i+1]
         sorted = false&lt;/code&gt;
&lt;/pre&gt;
&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;显然，奶牛码中的“moo”指令的作用只是输出“moo”。奇怪的是，Bessie看上去执着于在她的代码中的不同位置使用这个语句。&lt;/p&gt;
&lt;p&gt;给定一个输入数组，请预测Bessie的代码会输出多少次“moo”。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;题意即进行多少次冒泡排序&lt;/p&gt;
&lt;h3 id=&quot;对于一个序列-我们称之为有序的-当且仅当对于任意一个位置前面没有比它大的数可以模拟一下&quot;&gt;对于一个序列, 我们称之为有序的, 当且仅当对于任意一个位置前面没有比它大的数(可以模拟一下)&lt;/h3&gt;
&lt;p&gt;比如:6 1 2 3 4 5 进行一次为 1 2 3 4 5 6&lt;/p&gt;
&lt;p&gt;那么对于位置i, 冒泡排序进行到i-1时, $a_{i-1}$为前i1个数中最大的一个, 如果它大于$a_i$那么它就会到$a_i$的后面&lt;/p&gt;
&lt;p&gt;由此可推知, 每一次位置i前都会将一个比$a_i$大的数推至其后, 直至没有比它大的&lt;/p&gt;
&lt;p&gt;那么我们对每位置求一下它前面有几个比它大就好啦(注意要将答案加一)&lt;/p&gt;
&lt;p&gt;具体来说先进行离散化, 再树状数组求解即可&lt;/p&gt;
&lt;p&gt;代码:&lt;/p&gt;
&lt;pre class=&quot;cpp&quot;&gt;
&lt;code&gt;#include&amp;lt;iostream&amp;gt;
#include&amp;lt;cstdio&amp;gt;
#include&amp;lt;cstring&amp;gt;
#include&amp;lt;algorithm&amp;gt;
using namespace std;
const int N = 100500;
int d[N], n;
int read(void) {
    int x = 0;
    char c = getchar();
    while (!isdigit(c)) c = getchar();
    while (isdigit(c)){
        x = (x &amp;lt;&amp;lt; 3) + (x &amp;lt;&amp;lt; 1) + c - '0';
        c = getchar();
    }
    return x;
}
struct node{
    int val, pos;
    bool operator &amp;lt; (const node &amp;amp;i) const{
        if (val == i.val) return pos &amp;lt; i.pos;
        return val &amp;lt; i.val;
    }
}p[N];
inline int low(int x) {
    return x &amp;amp; -x;
}
int get(int x) {
    int tmp = 0;
    for (;x;x -= low(x)) tmp += d[x];
    return tmp;
}
void add(int x) {
    for (;x &amp;lt;= n; x += low(x)) d[x]++;
}
bool cmp(node i,node j) {
    return i.pos &amp;lt; j.pos;
}
int main() {
    n = read();
    for (int i = 1;i &amp;lt;= n; i++) p[i] = (node){read(),i};
    sort(p + 1,p + n + 1);
    for (int i = 1;i &amp;lt;= n; i++) p[i].val = i;
    sort(p + 1,p + n + 1, cmp);
    int ans = 0;
    for (int i = 1;i &amp;lt;= n; i++) {
        add(p[i].val);
        ans = max(ans, i - get(p[i].val));
    }
    printf (&quot;%d\n&quot;, ans+1);
    return 0;
}&lt;/code&gt;
&lt;/pre&gt;

&lt;pre&gt;
&lt;code&gt;sorted = false
while (not sorted):
   sorted = true
   moo
   for i = 0 to N-2:
      if A[i+1] &amp;lt; A[i]:
         swap A[i], A[i+1]
   for i = N-2 downto 0:
      if A[i+1] &amp;lt; A[i]:
         swap A[i], A[i+1]
   for i = 0 to N-2:
      if A[i+1] &amp;lt; A[i]:
         sorted = false&lt;/code&gt;
&lt;/pre&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;给定一个输入数组，请预测Bessie的代码会输出多少次“moo”。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;题意:求双向冒泡排序的排序次数&lt;/p&gt;
&lt;h3 id=&quot;对于一个序列-我们称之为有序的-当且仅当对于任意一个位置前面没有比它大的数可以模拟一下-1&quot;&gt;对于一个序列, 我们称之为有序的, 当且仅当对于任意一个位置前面没有比它大的数(可以模拟一下)&lt;/h3&gt;
&lt;p&gt;我们暂且称它为平衡条件吧&lt;/p&gt;
&lt;p&gt;首先将序列离散化&lt;/p&gt;
&lt;p&gt;相比较于Out of Sorts S, 本题思路在于不动的位置, 结论为对于位置x, ans = max{ans, 前面有几个数的数值大于x}&lt;/p&gt;
&lt;p&gt;为什么呢&lt;/p&gt;
&lt;p&gt;在x不满足平衡条件的时候&lt;/p&gt;
&lt;h3 id=&quot;首先第一波操作的时候对于前x个位置一定会换出一个大于x的数&quot;&gt;首先第一波操作的时候,对于前x个位置一定会换出一个大于x的数&lt;/h3&gt;
&lt;p&gt;因为它不满足平衡条件&lt;/p&gt;
&lt;h3 id=&quot;第二波操作时-又会有一个小于等于x的数插回来&quot;&gt;第二波操作时, 又会有一个小于等于x的数插回来&lt;/h3&gt;
&lt;p&gt;因为回来的时候一定会冒泡出一个位置在x后的最小值, 因为x不满足平衡条件, 所以最小值小于等于x, 就又插了回来&lt;/p&gt;
&lt;p&gt;有人可能会问为什么Out of Sorts S不能用这个式子嘞, 因为每次换出的一定大于x, 但x+1位置上的数可能换过来, 而它有可能大于x&lt;/p&gt;
&lt;p&gt;由此可知, 求每个位置前大于其的数就行啦&lt;/p&gt;
&lt;p&gt;代码:&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;#include&amp;lt;iostream&amp;gt;
#include&amp;lt;cstdio&amp;gt;
#include&amp;lt;cstring&amp;gt;
#include&amp;lt;algorithm&amp;gt;
using namespace std;
const int N = 100500;
int d[N], n;
int read(void) {
    int x = 0;
    char c = getchar();
    while (!isdigit(c)) c = getchar();
    while (isdigit(c)){
        x = (x &amp;lt;&amp;lt; 3) + (x &amp;lt;&amp;lt; 1) + c - '0';
        c = getchar();
    }
    return x;
}
struct node{
    int val, pos;
    bool operator &amp;lt; (const node &amp;amp;i) const{
        if (val == i.val) return pos &amp;lt; i.pos;
        return val &amp;lt; i.val;
    }
}p[N];
inline int low(int x) {
    return x &amp;amp; -x;
}
int get(int x) {
    int tmp = 0;
    for (;x;x -= low(x)) tmp += d[x];
    return tmp;
}
void add(int x) {
    for (;x &amp;lt;= n; x += low(x)) d[x]++;
}
bool cmp(node i,node j) {
    return i.pos &amp;lt; j.pos;
}
int main() {
    n = read();
    for (int i = 1;i &amp;lt;= n; i++) p[i] = (node){read(),i};
    sort(p + 1,p + n + 1);
    for (int i = 1;i &amp;lt;= n; i++) p[i].val = i;
    sort(p + 1,p + n + 1, cmp);
    int ans = 1;
    for (int i = 1;i &amp;lt;= n; i++) {
        add(p[i].val);
        ans = max(ans, i - get(i));
    }
    printf (&quot;%d\n&quot;, ans);
    return 0;
}
/*
6
2 5 6 3 1 4

*/&lt;/code&gt;
&lt;/pre&gt;

&lt;blockquote readability=&quot;11&quot;&gt;
&lt;p&gt;留意着农场之外的长期职业生涯的可能性，奶牛Bessie开始在不同的在线编程网站上学习算法。她最喜欢的两个算法是“冒泡排序”和“快速排序”，但是不幸的是Bessie轻易地把它们搞混了，最后实现了一个奇怪的混合算法！ 如果数组&lt;em&gt;A&lt;/em&gt;中A[...i]的最大值不大于A[i+1…]的最小值，我们就称元素i和i+1之间的位置为一个“分隔点”。Bessie还记得快速排序包含对数组的重排，产生了一个分隔点，然后要递归对两侧的A[...i]和A[i+1…]排序。然而，尽管她正确地记下了数组中所有的分隔点都可以在线性时间内被求出，她却忘记快速排序应该怎么重排来快速构造一个分隔点了！在这个可能会被证明是排序算法的历史中最糟糕的算法性失误之下，她做出了一个不幸的决定，使用冒泡排序来完成这个任务。&lt;/p&gt;
&lt;p&gt;以下是Bessie最初的对数组A&lt;em&gt;A&lt;/em&gt;进行排序的实现的概要。她首先写了一个简单的函数，执行冒泡排序的一轮：&lt;/p&gt;
&lt;/blockquote&gt;
&lt;pre&gt;
&lt;code&gt;bubble_sort_pass (A) {
   for i = 0 to length(A)-2
      if A[i] &amp;gt; A[i+1], swap A[i] and A[i+1]
}&lt;/code&gt;
&lt;/pre&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;她的快速排序（相当快）函数的递归代码是按下面的样子构成的：&lt;/p&gt;
&lt;/blockquote&gt;
&lt;pre&gt;
&lt;code&gt;quickish_sort (A) {
   if length(A) = 1, return
   do { // Main loop
      work_counter = work_counter + length(A)
      bubble_sort_pass(A)
   } while (no partition points exist in A) 
   divide A at all partition points; recursively quickish_sort each piece
}&lt;/code&gt;
&lt;/pre&gt;
&lt;blockquote readability=&quot;10&quot;&gt;
&lt;p&gt;Bessie好奇于她的代码能够运行得多快。简单起见，她计算出她得主循环的每一轮都消耗线性时间，所以她相应增加一个全局变量work_counter的值，以此来跟踪整个算法总共完成的工作量。&lt;/p&gt;
&lt;p&gt;给定一个输入数组，请预测quickish_sort函数接收这个数组之后，变量work_counter的最终值。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&quot;这道题用到了一个套路-就是横向变纵向&quot;&gt;这道题用到了一个套路, 就是&quot;横向变纵向&quot;&lt;/h3&gt;
&lt;p&gt;求每一次冒泡排序的长度, 不如求每一个点被冒泡排序了几次&lt;/p&gt;
&lt;p&gt;定义分割点为i与i+1的分割线,不妨假设它就在i上吧&lt;/p&gt;
&lt;p&gt;再次定义序列排好序的标准&lt;/p&gt;
&lt;h3 id=&quot;我们称一个序列是有序的当且仅当所有点除了n都是分割点&quot;&gt;我们称一个序列是有序的当且仅当所有点(除了n)都是分割点&lt;/h3&gt;
&lt;p&gt;那么接下来我们要求分割点的出现时间t数组&lt;/p&gt;
&lt;h3 id=&quot;为什么求&quot;&gt;为什么求:&lt;/h3&gt;
&lt;p&gt;对于每个点它不用在进行冒泡排序了当且仅当两边都已成为分割点, 也就是两边出现时间的最大值&lt;/p&gt;
&lt;p&gt;依据t数组,我们可以求出每个点被排了几次&lt;/p&gt;
&lt;h3 id=&quot;怎么求敲重点&quot;&gt;怎么求(敲重点):&lt;/h3&gt;
&lt;p&gt;首先离散化&lt;/p&gt;
&lt;p&gt;对于一个点x来说, 所有小于它的数却在它后面的, 每一次都会向前走一次&lt;/p&gt;
&lt;p&gt;那么它出现的时间就是离它最远的小于它的点冒泡到它前面的时间&lt;/p&gt;
&lt;p&gt;即那个点到它的距离, 具体见代码&lt;/p&gt;
&lt;p&gt;所以单调队列或指针都可以维护&lt;/p&gt;
&lt;p&gt;代码:&lt;/p&gt;
&lt;pre class=&quot;cpp&quot;&gt;
&lt;code&gt;#include&amp;lt;iostream&amp;gt;
#include&amp;lt;cstdio&amp;gt;
#include&amp;lt;cstring&amp;gt;
#include&amp;lt;algorithm&amp;gt;
#include&amp;lt;queue&amp;gt;
using namespace std;
const int N = 100500;
int d[N], n;
int read(void) {
    int x = 0;
    char c = getchar();
    while (!isdigit(c)) c = getchar();
    while (isdigit(c)){
        x = (x &amp;lt;&amp;lt; 3) + (x &amp;lt;&amp;lt; 1) + c - '0';
        c = getchar();
    }
    return x;
}
struct node{
    int val, pos;
    bool operator &amp;lt; (const node &amp;amp;i) const{
        if (val == i.val) return pos &amp;lt; i.pos;
        return val &amp;lt; i.val;
    }
}p[N];
bool cmp(node i,node j) {
    return i.pos &amp;lt; j.pos;
}
int t[N], k;
int main() {
//  freopen(&quot;hs.in&quot;,&quot;r&quot;,stdin);
    n = read();
    for (int i = 1;i &amp;lt;= n; i++) p[i] = (node){read(),i};
    sort(p + 1,p + n + 1);
    for (int i = 1;i &amp;lt;= n; i++) p[i].val = i;
    sort(p + 1,p + n + 1, cmp);
    long long ans = 0;
    k = n;
    for (int i = n;i &amp;gt;= 1; i--) {
        while (p[k].val &amp;gt; i) k--;
        t[i] = max(p[k].pos - i, 1);
    }
    for (int i = 0;i &amp;lt; n; i++) ans += max(t[i], t[i+1]);
    printf (&quot;%lld\n&quot;, ans);
    return 0;
}
/*
6
2 5 6 3 1 4

*/&lt;/code&gt;
&lt;/pre&gt;

&lt;blockquote readability=&quot;13&quot;&gt;
&lt;p&gt;您有一个正整数序列, 您可以选择任意相邻的两个数$a_i,a_{i+1}$插入另两个数之间,或序列首和尾;&lt;br/&gt;假如序列为: 1 2 4 3 5 6&lt;br/&gt;可以选2 4&lt;br/&gt;插在序列首 2 3 4 3 5 6&lt;br/&gt;插到3后 1 3 2 4 5 6&lt;br/&gt;插到5后 4 3 5 1 2 6&lt;br/&gt;插在6后 1 3 5 6 2 4&lt;br/&gt;现在hs-black需要判断是否进行若干次操作能使序列变得有序(无论正序倒序), 蒟蒻hs-black当然不会啦, 请您帮帮他.....&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;这道题来源于一位数竞大佬提供的灵感&lt;/p&gt;
&lt;p&gt;再次定义一个序列有序&lt;/p&gt;
&lt;p&gt;我们称一个序列是有序的,当且仅当它的逆序对数为0或n*(n-1)/2;&lt;/p&gt;
&lt;p&gt;引理1: 交换序列中相邻的两个数会改变原序列逆序对个数的奇偶性&lt;/p&gt;
&lt;p&gt;引理2: 将序列相邻两个数插入别处不会改变原序列逆序对个数的奇偶性&lt;/p&gt;
&lt;p&gt;​ 证明: a~1~...a~i~a~j~...a~q~...a~n~ 不断将a~j~与它右边的数字交换直至正好换到a~q~ 即a~1~...a~j~a~i~...a~n~ 此时共交换了q - j 次&lt;/p&gt;
&lt;p&gt;​ 再将a~i~ 向右与相邻数字交换q-1-i次到$a_j$左侧 ,此时共交换2 * (q - j) 次,为偶数次,所以奇偶性不变&lt;/p&gt;
&lt;p&gt;那么说明逆序对数与排序好的逆序对数奇偶性不同时不能满足要求&lt;/p&gt;
&lt;p&gt;下面证明相同时可以满足要求&lt;/p&gt;
&lt;p&gt;以正序为例, 每次将序列最小的数和后面的数插到已排序部分的后面, 如果最小数在最后时就将后2,3个数插在它后面&lt;/p&gt;
&lt;p&gt;当未排序列只剩两个数时, 逆序对个数也一定是偶数, 只可能是0&lt;/p&gt;
&lt;p&gt;即序列有序, 证毕&lt;/p&gt;
&lt;p&gt;具体实现是讨论一下n*(n-1)/2的奇偶性, 并树状数组求出原序列逆序对个数&lt;/p&gt;
&lt;p&gt;代码:&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;#include&amp;lt;cstdio&amp;gt;
#include&amp;lt;cstring&amp;gt;
#include&amp;lt;algorithm&amp;gt;
#include&amp;lt;iostream&amp;gt;
const int M = 500005;
using namespace std;
int n, sum[M];
struct Num{
    int val,num;
    inline friend bool operator &amp;lt; (Num a,Num b){
        return a.val &amp;gt; b.val;
    }
}p[M];
inline int lowbit(int x){
    return x&amp;amp;-x;
}
void add(int k,int x){
    while(k&amp;lt;=n){
        sum[k]+=x;
        k+=lowbit(k);
    }
}
int getsum(int k){
    int tmp=0;
    while(k&amp;gt;0){
        tmp+=sum[k];
        k-=lowbit(k);
    }
    return tmp;
}
long long Ans=0;
char ss[1&amp;lt;&amp;lt;17],*A=ss,*B=ss;
inline char gc()
{if(A==B){B=(A=ss)+fread(ss,1,1&amp;lt;&amp;lt;17,stdin);if(A==B)return EOF;}return*A++;}
template&amp;lt;class T&amp;gt;inline void read(T&amp;amp;x){
    cin &amp;gt;&amp;gt; x ; 
}
int main(){
    int t;
    read(t);
    while(t--) {
        Ans = 0;
        memset(sum, 0, sizeof(sum));
        read(n);
        for(int i=1;i&amp;lt;=n;i++){
            read(p[i].val);
            p[i].num=i;
        }
        sort(p+1,p+n+1);
        for(int i=1;i&amp;lt;=n;i++){
            add(p[i].num,1);
            Ans+=getsum(p[i].num-1);
        }
//      printf (&quot;%lld\n&quot;, Ans);
        if (n % 4 &amp;gt; 1) 
            printf(&quot;Yes\n&quot;);
        else if (Ans % 2 == 1) 
            printf(&quot;No\n&quot;);
        else 
            printf(&quot;Yes\n&quot;);
    }
    return 0;
}&lt;/code&gt;
&lt;/pre&gt;</description>
<pubDate>Sat, 05 Oct 2019 15:11:00 +0000</pubDate>
<dc:creator>Hs-black</dc:creator>
<og:description>冒泡排序深入理解 对于冒泡排序有一个小性质: 每一次都会把序列未排好序的最大数'沉底', 即推到序列尾部 1. 'P4378 Out of Sorts S' 留意着农场之外的长期职业生涯的可能性，奶牛</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/Hs-black/p/11626111.html</dc:identifier>
</item>
<item>
<title>Java源码解析|String源码与常用方法 - fishers</title>
<link>http://www.cnblogs.com/fisherss/p/11626108.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/fisherss/p/11626108.html</guid>
<description>&lt;h2 id=&quot;栗子&quot;&gt;1.栗子&lt;/h2&gt;
&lt;p&gt;代码：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;public class JavaStringClass {
    
    public static void main(String[] args) {
        String s =&quot;hello&quot;;
        s = &quot;world&quot;; //内存地址已经修改 原来地址上的值还是不变的
        String s2 = &quot;hello&quot;; //从常量值中找到并引用
        String s4 = new String(&quot;hello&quot;); //new产生一个新的对象 不会从常量池中引用
        String s6 = &quot;hel&quot; + &quot;lo&quot;;
        String s7 = new String(&quot;hel&quot;) + new String(&quot;lo&quot;);
        System.out.println(s == s2); //引用相等
        System.out.println(s2 == s4); //引用不相等
        System.out.println(s2.equals(s4)); //值相等 分析equals方法源码
        System.out.println(s2 == s6); //引用相等 使用相 常量相加 也是从常量池中找到引用
        System.out.println(s2 == s7); //引用不相等
        
        //开头字母大写
        System.out.println(s2.substring(0,1).toUpperCase() + s2.substring(1));
        
        System.out.println(s2);
    }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;输出：&lt;br/&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1454456/201910/1454456-20191005224749664-1086959144.png&quot;/&gt;&lt;/p&gt;
&lt;h2 id=&quot;string的不变性&quot;&gt;2.String的不变性&lt;/h2&gt;
&lt;p&gt;2-1：字符串常量池&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;String s =&quot;hello&quot;;
String s2 = &quot;hello&quot;;
System.out.println(s == s2); //true  说明引用相等(地址相等)&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;`s与s2引用相等即地址相等，原因是：Java把字符串常量存入字符串常量池&lt;/p&gt;
&lt;p&gt;而 String s4 = new String(&quot;hello&quot;); s4和 s2的值不相等，是因为new会产生一个新的对象，不会从字符串常量池中找引用&lt;/p&gt;
&lt;p&gt;2-2：String的不变性&lt;/p&gt;
&lt;p&gt;`主要是因为 String 和保存数据的 char 数组,都被 final 关键字所修饰,所以是不可变的&lt;/p&gt;
&lt;p&gt;如下图所示：被final关键字修饰的变量(这里是字符数组)，值不可以改变&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1454456/201910/1454456-20191005225221679-1081472726.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;所以当 String s =&quot;hello&quot;; s = “world”时，s的内存地址(s的引用对象)已经改变了，&lt;br/&gt;说明产生了新的字符串对象，已经不再指向字符串常量池的“hello”，而是指向了“world”。&lt;/p&gt;
&lt;h2 id=&quot;string重写equal方法判断相等&quot;&gt;3.String重写equal方法，判断相等&lt;/h2&gt;
&lt;blockquote readability=&quot;7&quot;&gt;
&lt;p&gt;1.先判断 引用是否相等 this == object，地址引用相等说明指向同一个对象，那么值肯定也相等了&lt;br/&gt;2.再使用instanceof 判断类型是否与String类型相等&lt;br/&gt;3.最后逐个判断 底层字符数组中的每一个字符是否相等&lt;/p&gt;
&lt;/blockquote&gt;
&lt;pre&gt;
&lt;code&gt;public boolean equals(Object anObject) {
    // 判断内存地址是否相同
    if (this == anObject) {
        return true;
    }
    // 待比较的对象是否是 String，如果不是 String，直接返回不相等
    if (anObject instanceof String) {
        String anotherString = (String)anObject;
        int n = value.length;
        // 两个字符串的长度是否相等，不等则直接返回不相等
        if (n == anotherString.value.length) {
            char v1[] = value;
            char v2[] = anotherString.value;
            int i = 0;
            // 依次比较每个字符是否相等，若有一个不等，直接返回不相等
            while (n-- != 0) {
                if (v1[i] != v2[i])
                    return false;
                i++;
            }
            return true;
        }
    }
    return false;
}&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;string常用的操作方法&quot;&gt;4.String常用的操作方法&lt;/h2&gt;
&lt;p&gt;4-1：字符串截取：&lt;br/&gt;方法1：public String substring(int beginIndex, int endIndex) // beginIndex：开始位置，endIndex：结束位置；&lt;br/&gt;方法2：public String substring(int beginIndex) //beginIndex：开始位置一直到到字符串末尾结束位置&lt;br/&gt;截取原理：substring 方法的底层使用的是字符数组范围截取的方法 :Arrays.copyOfRange(字符数组,开始位置,结束位置)&lt;/p&gt;
&lt;p&gt;4-2：字符串大小写：&lt;br/&gt;小写方法：String.toLowerCase() //小写&lt;br/&gt;大写方法：String.toUpperCase()//大写&lt;/p&gt;
&lt;p&gt;上面两种常用方法的综合应用：将首字母小写&lt;br/&gt;有时候我们会通过 applicationContext.getBean(className); 这种方式得到 SpringBean，这时 className 必须是要满足首字母小写的&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;name.substring(0, 1).toLowerCase() name.substring(1);&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;4-3：字符串替换、删除&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;public void testReplace(){
  String str =&quot;hello word !!&quot;;
  log.info(&quot;替换之前 :{}&quot;,str);
  str = str.replace('l','d');
  log.info(&quot;替换所有字符 :{}&quot;,str);
  str = str.replaceAll(&quot;d&quot;,&quot;l&quot;);
  log.info(&quot;替换全部 :{}&quot;,str);
  str = str.replaceFirst(&quot;l&quot;,&quot;&quot;);
  log.info(&quot;替换第一个 l :{}&quot;,str);
}
//输出的结果是：
替换之前 :hello word !!
替换所有字符 :heddo word !!
替换全部 :hello worl !!
替换第一个 :helo worl !!&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;4-4：字符串拆分&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;String s =&quot;boo:and:foo&quot;;
// 我们对 s 进行了各种拆分，演示的代码和结果是：
s.split(&quot;:&quot;) 结果:[&quot;boo&quot;,&quot;and&quot;,&quot;foo&quot;]
s.split(&quot;:&quot;,2) 结果:[&quot;boo&quot;,&quot;and:foo&quot;]
s.split(&quot;:&quot;,5) 结果:[&quot;boo&quot;,&quot;and&quot;,&quot;foo&quot;]
s.split(&quot;:&quot;,-2) 结果:[&quot;boo&quot;,&quot;and&quot;,&quot;foo&quot;]
s.split(&quot;o&quot;) 结果:[&quot;b&quot;,&quot;&quot;,&quot;:and:f&quot;]
s.split(&quot;o&quot;,2) 结果:[&quot;b&quot;,&quot;o:and:foo&quot;]&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;但是会拆分出空值&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;String a =&quot;,a,,b,&quot;;
a.split(&quot;,&quot;) 结果:[&quot;&quot;,&quot;a&quot;,&quot;&quot;,&quot;b&quot;]&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;使用google的Guava快速去除空值&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;String a =&quot;,a, ,  b  c ,&quot;;
// Splitter 是 Guava 提供的 API 
List&amp;lt;String&amp;gt; list = Splitter.on(',')
    .trimResults()// 去掉空格
    .omitEmptyStrings()// 去掉空值
    .splitToList(a);
log.info(&quot;Guava 去掉空格的分割方法：{}&quot;,JSON.toJSONString(list));
// 打印出的结果为：
[&quot;a&quot;,&quot;b  c&quot;]&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;4-5：字符串合并&lt;/p&gt;
&lt;p&gt;合并我们使用 join 方法,此方法是静态的,我们可以直接使用。&lt;br/&gt;方法有两个入参,参数一是合并的分隔符,参数二是合并的数据源&lt;/p&gt;
&lt;p&gt;不足：join不能连续合并(不能链式合并)，无法过滤Join对象是List时的null值&lt;/p&gt;
&lt;p&gt;解决办法：使用Guava 提供的 API，Joiner快速合并&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;// 依次 join 多个字符串，Joiner 是 Guava 提供的 API
Joiner joiner = Joiner.on(&quot;,&quot;).skipNulls();
String result = joiner.join(&quot;hello&quot;,null,&quot;china&quot;);
log.info(&quot;依次 join 多个字符串:{}&quot;,result);

List&amp;lt;String&amp;gt; list = Lists.newArrayList(new String[]{&quot;hello&quot;,&quot;china&quot;,null});
log.info(&quot;自动删除 list 中空值:{}&quot;,joiner.join(list));

// 输出的结果为；
依次 join 多个字符串:hello,china
自动删除 list 中空值:hello,china&lt;/code&gt;
&lt;/pre&gt;</description>
<pubDate>Sat, 05 Oct 2019 15:09:00 +0000</pubDate>
<dc:creator>fishers</dc:creator>
<og:description>String源码与常用方法 1.栗子 代码： 输出： 2.String的不变性 2 1：字符串常量池 `s与s2引用相等即地址相等，原因是：Java把字符串常量存入字符串常量池 而 String s4</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/fisherss/p/11626108.html</dc:identifier>
</item>
<item>
<title>一条SQL查询语句是如何执行的？ - 武培轩</title>
<link>http://www.cnblogs.com/wupeixuan/p/11626024.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/wupeixuan/p/11626024.html</guid>
<description>&lt;p&gt;本篇文章将通过一条 SQL 的执行过程来介绍 MySQL 的基础架构。&lt;/p&gt;
&lt;p&gt;首先有一个 user_info 表，表里有一个 id 字段，执行下面这条查询语句：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;select * from user_info where id = 1;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;返回结果为：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;+----+----------+----------+--------+------+---------------------+---------------------+
| id | username | password | openid | role | create_time         | update_time         |
+----+----------+----------+--------+------+---------------------+---------------------+
| 1  | 武培轩   | 123      | 1      |    1 | 2019-08-29 00:29:08 | 2019-08-29 00:29:08 |
+----+----------+----------+--------+------+---------------------+---------------------+&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;下面给出 MySQL 的基本架构示意图，可以看出 SQL 语句在 MySQL 的各个模块中的执行过程。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1356806/201909/1356806-20190928025825417-1905239052.png&quot; alt=&quot;MySQL 基本架构示意图&quot;/&gt;&lt;/p&gt;
&lt;p&gt;大体上，MySQL 分为 Server 层和存储引擎层两部分。&lt;/p&gt;
&lt;p&gt;Server 层包括连接器、查询缓存、分析器、执行器等，以及所有的内置函数（如日期、时间、数学和加密函数等）和跨存储引擎的功能（如存储过程、触发器、视图）。&lt;/p&gt;
&lt;p&gt;存储引擎层负责数据的存储和提取，支持 InnoDB、MyISAM、Memory 等多个存储引擎。MySQL 5.5.5 版本后默认存储存储引擎是 InnoDB。&lt;/p&gt;
&lt;h2 id=&quot;连接器connector&quot;&gt;连接器（Connector）&lt;/h2&gt;
&lt;p&gt;在查询 SQL 语句前，肯定要先建立与 MySQL 的连接，这就是由连接器来完成的。连接器负责跟客户端建立连接、获取权限、维持和管理连接。连接命令为：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;mysql -h$ip -P$port -u$user -p        &lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;输入密码，验证通过后，连接器会到权限表里面查出你拥有的权限，之后这个连接里面的权限判断逻辑，都将依赖于此时读到的权限，一个用户成功建立连接后，即使管理员对这个用户的权限做了修改，也不会影响已经存在连接的权限，修改完后，只有再新建的连接才会使用新的权限设置。&lt;/p&gt;
&lt;p&gt;连接完成后，如果你没有后续的动作，这个连接就处于空闲状态，你可以在 &lt;code&gt;show processlist&lt;/code&gt; 命令中看到它。结果如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;+----+------+----------------+------------------+---------+------+----------+------------------+
| Id | User | Host           | db               | Command | Time | State    | Info             |
+----+------+----------------+------------------+---------+------+----------+------------------+
|  3 | root | localhost:2790 | NULL             | Sleep   | 5878 |          | NULL             |
|  4 | root | localhost:2791 | springcloud_sell | Sleep   | 5838 |          | NULL             |
|  7 | root | localhost:2900 | springcloud_sell | Sleep   | 5838 |          | NULL             |
| 10 | root | localhost:3627 | springcloud_sell | Query   |    0 | starting | show processlist |
+----+------+----------------+------------------+---------+------+----------+------------------+&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;客户端如果太长时间没动静，连接器就会自动将它断开；这个时间是由参数 wait_timeout 控制的，默认值是8小时。如果在连接被断开之后，客户端再次发送请求的话，就会收到一个错误提醒：&lt;code&gt;Lost connection to MySQL server during query&lt;/code&gt;。&lt;/p&gt;
&lt;h3 id=&quot;长连接和短连接&quot;&gt;长连接和短连接&lt;/h3&gt;
&lt;ul&gt;&lt;li&gt;数据库里面，长连接是指连接成功后，如果客户端持续有请求，则一直使用同一个连接。&lt;/li&gt;
&lt;li&gt;短连接则是指每次执行完很少的几次查询就断开连接，下次查询再重新建立一个。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;建立连接的过程通常是比较复杂的，建议在使用中要尽量减少建立连接的动作，尽量使用长连接。但是全部使用长连接后，有时候 MySQL 占用内存涨得特别快，这是因为 MySQL 在执行过程中临时使用的内存是管理在连接对象里面的。这些资源会在连接断&lt;br/&gt;开的时候才释放。所以如果长连接累积下来，可能导致内存占用太大，被系统强行杀掉（OOM），从现象看就是 MySQL 异常重启了。&lt;/p&gt;
&lt;p&gt;怎么解决这个问题呢？可以考虑以下两种方案：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;定期断开长连接。使用一段时间，或者程序里面判断执行过一个占用内存的大查询后，断开连接，之后要查询再重连。&lt;/li&gt;
&lt;li&gt;MySQL 5.7 以上版本，可以在每次执行一个比较大的操作后，通过执行 mysql_reset_connection 来重新初始化连接资源。这个过程不需要重连和重新做权限验证，但是会将连接恢复到刚刚创建完时的状态。&lt;/li&gt;
&lt;/ol&gt;&lt;h2 id=&quot;查询缓存query-cache&quot;&gt;查询缓存（Query Cache）&lt;/h2&gt;
&lt;p&gt;在建立连接后，就开始执行 select 语句了，执行前首先会查询缓存。&lt;/p&gt;
&lt;p&gt;MySQL 拿到查询请求后，会先查询缓存，看是不是执行过这条语句。执行过的语句及其结果会以 key-value 对的形式保存在一定的内存区域中。key 是查询的语句，value 是查询的结果。如果你的查询能够直接在这个缓存中找到 key，那么这个&lt;br/&gt;value 就会被直接返回给客户端。&lt;/p&gt;
&lt;p&gt;如果语句不在查询缓存中，就会继续后面的执行阶段。执行完成后，执行结果会被存入查询缓存中。如果查询命中缓存，MySQL 不需要执行后面的复杂操作，就可以直接返回结果，会提升效率。&lt;/p&gt;
&lt;p&gt;但是查询缓存的失效非常频繁，只要有对一个表的更新，这个表上所有的查询缓存都会被清空。对于更新压力大的数据库来说，查询缓存的命中率会非常低。如果业务中需要有一张静态表，很长时间才会更新一次。比如，一个系统配置表，那这张表上的查询才适合使用查询缓存。MySQL 提供了这种按需使用的方式。可以将参数 query_cache_type 设置成 DEMAND，对于默认的 SQL 语句都将不使用查询缓存。而对于你确定要使用查询缓存的语句，可以用 SQL_CACHE 显式指定，如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;mysql&amp;gt; select SQL_CACHE * from user_info where id = 1;&lt;/code&gt;
&lt;/pre&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;MySQL 8.0 版本将查询缓存的功能删除了。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;分析器analyzer&quot;&gt;分析器（Analyzer）&lt;/h2&gt;
&lt;p&gt;如果查询缓存未命中，就要开始执行语句了。首先，MySQL 需要对 SQL 语句进行解析。&lt;/p&gt;
&lt;p&gt;分析器先会做词法分析。SQL 语句是由多个字符串和空格组成的，MySQL 需要识别出里面的字符串分别是什么，代表什么。MySQL 从你输入的 select 这个关键字识别出来，这是查询语句。它也要把字符串 user_info 识别成表名，把字符串 id 识别成列名。之后就要做语法分析。根据词法分析的结果，语法分析器会根据语法规则，判断输入的 SQL 语句是否满足 MySQL 语法。&lt;/p&gt;
&lt;p&gt;如果你 SQL 语句不对，就会收到 &lt;code&gt;You have an error in your SQL syntax&lt;/code&gt; 的错误提醒，比如下面这个语句 from 写成了 form。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;mysql&amp;gt; select * form user_info  where id = 1;
1064 - You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near 'form user_info  where id = 1' at line 1&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;一般语法错误会提示第一个出现错误的位置，所以要关注的是紧接 &lt;code&gt;use near&lt;/code&gt; 的内容。&lt;/p&gt;
&lt;h2 id=&quot;优化器optimizer&quot;&gt;优化器（Optimizer）&lt;/h2&gt;
&lt;p&gt;经过分析器的词法分析和语法分析后，还要经过优化器的处理。&lt;/p&gt;
&lt;p&gt;优化器是在表里面有多个索引的时候，决定使用哪个索引；或者在一个语句有多表关联（join）的时候，决定各个表的连接顺序。比如你执行下面这样的语句，这个语句是执行两个表的 join：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;mysql&amp;gt; SELECT * FROM order_master JOIN order_detail USING (order_id) WHERE order_master.pay_status = 0 AND order_detail.detail_id = 1558963262141624521;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;既可以先从表 order_master 里面取出 pay_status = 0 的记录的 order_id 值，再根据 order_id 值关联到表 order_detail，再判断 order_detail 里面 detail_id 的值是否等于 1558963262141624521。&lt;/p&gt;
&lt;p&gt;也可以先从表 order_detail 里面取出 detail_id = 1558963262141624521 的记录的 order_id 值，再根据 order_id 值关联到 order_master，再判断 order_master 里面 pay_status 的值是否等于 0。&lt;/p&gt;
&lt;p&gt;这两种执行方法的逻辑结果是一样的，但是执行的效率会有不同，而优化器的作用就是决定选择使用哪一个方案。优化器阶段完成后，这个语句的执行方案就确定下来了，然后进入执行器阶段。&lt;/p&gt;
&lt;h2 id=&quot;执行器actuator&quot;&gt;执行器（Actuator）&lt;/h2&gt;
&lt;p&gt;MySQL 通过分析器知道了要做什么，通过优化器知道了该怎么做，于是就进入了执行器阶段，开始执行语句。&lt;/p&gt;
&lt;p&gt;开始执行的时候，要先判断一下你对这个表 user_info 有没有执行查询的权限，如果没有，就会返回没有权限的错误，如下所示 (如果命中查询缓存，会在查询缓存返回结果的时候，做权限验证。查询也会在优化器之前调用 precheck 验证权限)。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;mysql&amp;gt; select * from user_info where id = 1;
ERROR 1142 (42000): SELECT command denied to user 'wupx'@'localhost' for table 'user_info'&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;如果有权限，就打开表继续执行。打开表的时候，执行器就会根据表的引擎定义，去使用这个引擎提供的接口。比如我们这个例子中的表 user_info 中，id 字段没有索引，那么执行器的执行流程是这样的：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;调用 InnoDB 引擎接口取这个表的第一行，判断 id 值是不是 1，如果不是则跳过，如果是则将这行存在结果集中；&lt;/li&gt;
&lt;li&gt;调用引擎接口取下一行，重复相同的判断逻辑，直到取到这个表的最后一行。&lt;/li&gt;
&lt;li&gt;执行器将上述遍历过程中所有满足条件的行组成的记录集作为结果集返回给客户端。&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;对于有索引的表，第一次调用的是取满足条件的第一行这个接口，之后循环取满足条件的下一行这个接口。&lt;/p&gt;
&lt;p&gt;数据库的慢查询日志中有 rows_examined 字段，表示这个语句执行过程中扫描了多少行。这个值就是在执行器每次调用引擎获取数据行的时候累加的。在有些场景下，执行器调用一次，在引擎内部则扫描了多行，因此引擎扫描行数跟 rows_examined 并不是完全相同的。&lt;/p&gt;
&lt;h2 id=&quot;总结&quot;&gt;总结&lt;/h2&gt;
&lt;p&gt;主要通过对一个 SQL 语句完整执行过程进行讲解，介绍 MySQL 的逻辑架构，MySQL 主要包括连接器、查询缓存、分析器、优化器、执行器这几个模块。&lt;/p&gt;
</description>
<pubDate>Sat, 05 Oct 2019 14:37:00 +0000</pubDate>
<dc:creator>武培轩</dc:creator>
<og:description>本篇文章将通过一条 SQL 的执行过程来介绍 MySQL 的基础架构。 首先有一个 user_info 表，表里有一个 id 字段，执行下面这条查询语句： 返回结果为： 下面给出 MySQL 的基本架</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/wupeixuan/p/11626024.html</dc:identifier>
</item>
<item>
<title>Linux安装Kafka - 请叫我头头哥</title>
<link>http://www.cnblogs.com/toutou/p/linux_install_kafka.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/toutou/p/linux_install_kafka.html</guid>
<description>&lt;div class=&quot;bodyCustomClass&quot; readability=&quot;32.5&quot;&gt;
&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;kafka是一个分布式消息队列。具有高性能、持久化、多副本备份、横向扩展能力。生产者往队列里写消息，消费者从队列里取消息进行业务逻辑。一般在架构设计中起到解耦、削峰、异步处理的作用。kafka对外使用topic的概念，生产者往topic里写消息，消费者从读消息。为了做到水平扩展，一个topic实际是由多个partition组成的，遇到瓶颈时，可以通过增加partition的数量来进行横向扩容。单个parition内是保证消息有序。每新写一条消息，kafka就是在对应的文件append写，所以性能非常高。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;h2 id=&quot;_nav_00&quot; class=&quot;blogCustomTitleStyle&quot;&gt;&lt;span class=&quot;blogCustomTitleIco&quot;&gt;v&lt;/span&gt;基础知识&lt;/h2&gt;
&lt;p&gt;什么是消息队列（Message Queue）？&lt;/p&gt;
&lt;p&gt;消息(Message)&lt;/p&gt;
&lt;p&gt;网络中的两台计算机或者两个通讯设备之间传递的数据。例如说：文本、音乐、视频等内容。&lt;/p&gt;
&lt;p&gt;队列(Queue)&lt;/p&gt;
&lt;p&gt;一种特殊的线性表（数据元素首尾相接），特殊之处在于只允许在首部删除元素和在尾部追加元素。入队、出队。&lt;/p&gt;
&lt;p&gt;消息队列(MQ)&lt;/p&gt;
&lt;p&gt;消息+队列，保存消息的队列。消息的传输过程中的容器；主要提供生产、消费接口供外部调用做数据的存储和获取。&lt;/p&gt;
&lt;p&gt;MQ分类&lt;/p&gt;
&lt;p&gt;MQ主要分为两类：点对点(p2p)、发布订阅(Pub/Sub)&lt;/p&gt;
&lt;p&gt;共同点：&lt;/p&gt;
&lt;p&gt;消息生产者生产消息发送到queue中，然后消息消费者从queue中读取并且消费消息。&lt;/p&gt;
&lt;p&gt;不同点：&lt;/p&gt;
&lt;p&gt;p2p模型包括：消息队列(Queue)、发送者(Sender)、接收者(Receiver)&lt;/p&gt;
&lt;p&gt;一个生产者生产的消息只有一个消费者(Consumer)(即一旦被消费，消息就不在消息队列中)。比如说打电话。&lt;/p&gt;
&lt;p&gt;Pub/Sub包含：消息队列(Queue)、主题(Topic)、发布者(Publisher)、订阅者(Subscriber)。每个消息可以有多个消费者，彼此互不影响。比如我发布一个微博：关注我的人都能够看到。&lt;/p&gt;
&lt;p&gt;那么在大数据领域呢，为了满足日益增长的数据量，也有一款可以满足百万级别消息的生成和消费，分布式、持久稳定的产品——Kafka。&lt;/p&gt;
&lt;h2 id=&quot;_nav_0&quot; class=&quot;blogCustomTitleStyle&quot;&gt;&lt;span class=&quot;blogCustomTitleIco&quot;&gt;v&lt;/span&gt;Kafka概念&lt;/h2&gt;
&lt;p&gt;在要了解Kafka之前，必须先了解主题，经纪人，生产者和消费者等主要术语。 下图说明了主要术语，表格详细描述了图表组件。如已了解的可以跳过此部分。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/506684/201908/506684-20190814194207102-1235749145.jpg&quot; alt=&quot;Linux安装Kafka&quot;/&gt;&lt;/p&gt;
&lt;p&gt;在上图中，主题配置为三个分区。 分区1具有两个偏移因子0和1.分区2具有四个偏移因子0,1,2和3.分区3具有一个偏移因子0.副本的id与承载它的服务器的id相同。&lt;/p&gt;
&lt;p&gt;假设，如果主题的复制因子设置为3，那么Kafka将创建每个分区的3个相同的副本，并将它们放在集群中以使其可用于其所有操作。 为了平衡集群中的负载，每个代理都存储一个或多个这些分区。 多个生产者和消费者可以同时发布和检索消息。&lt;/p&gt;
&lt;p&gt;&lt;span&gt;Topics（主题）:&lt;/span&gt;每条发布到Kafka集群的消息都有一个类别，这个类别被称为topic。（物理上不同topic的消息分开存储，逻辑上一个topic的消息虽然保存于一个或多个broker上但用户只需指定消息的topic即可生产或消费数据而不必关心数据存于何处）&lt;/p&gt;
&lt;p&gt;&lt;span&gt;Partition（分区）:&lt;/span&gt;parition是物理上的概念，每个topic包含一个或多个partition，创建topic时可指定parition数量。每个partition对应于一个文件夹，该文件夹下存储该partition的数据和索引文件&lt;/p&gt;
&lt;p&gt;&lt;span&gt;Partition offset（分区偏移）:&lt;/span&gt;每个分区消息具有称为 offset 的唯一序列标识。&lt;/p&gt;
&lt;p&gt;&lt;span&gt;Replicas of partition（分区备份）:&lt;/span&gt;副本只是一个分区的备份。 副本从不读取或写入数据。 它们用于防止数据丢失。&lt;/p&gt;
&lt;p&gt;&lt;span&gt;Broker:&lt;/span&gt;Kafka集群包含一个或多个服务器，这种服务器被称为broker&lt;/p&gt;
&lt;p&gt;&lt;span&gt;Brokers（经纪人）:&lt;/span&gt;代理是负责维护发布数据的简单系统。 每个代理中的每个主题可以具有零个或多个分区。 假设，如果在一个主题和N个代理中有N个分区，每个代理将有一个分区。假设在一个主题中有N个分区并且多于N个代理(n + m)，则第一个N代理将具有一个分区，并且下一个M代理将不具有用于该特定主题的任何分区。假设在一个主题中有N个分区并且小于N个代理(n-m)，每个代理将在它们之间具有一个或多个分区共享。 由于代理之间的负载分布不相等，不推荐使用此方案。&lt;/p&gt;
&lt;p&gt;&lt;span&gt;Kafka Cluster（Kafka集群）:&lt;/span&gt;Kafka有多个代理被称为Kafka集群。 可以扩展Kafka集群，无需停机。 这些集群用于管理消息数据的持久性和复制。&lt;/p&gt;
&lt;p&gt;&lt;span&gt;Producers（生产者）:&lt;/span&gt;生产者是发送给一个或多个Kafka主题的消息的发布者。 生产者向Kafka经纪人发送数据。 每当生产者将消息发布给代理时，代理只需将消息附加到最后一个段文件。 实际上，该消息将被附加到分区。 生产者还可以向他们选择的分区发送消息。&lt;/p&gt;
&lt;p&gt;&lt;span&gt;Consumers（消费者）:&lt;/span&gt;消费消息。每个consumer属于一个特定的consumer group（可为每个consumer指定group name，若不指定group name则属于默认的group）。使用consumer high level API时，同一topic的一条消息只能被同一个consumer group内的一个consumer消费，但多个consumer group可同时消费这一消息。&lt;/p&gt;
&lt;p&gt;&lt;span&gt;Consumer Group(消费者组):&lt;/span&gt;是逻辑上的概念，是Kafka实现单播和广播两种消息模型的手段。同一个topic的数据，会广播给不同的group；同一个group中的worker，只有一个worker能拿到这个数据。换句话说，对于同一个topic，每个group都可以拿到同样的所有数据，但是数据进入group后只能被其中的一个worker消费。group内的worker可以使用多线程或多进程来实现，也可以将进程分散在多台机器上，worker的数量通常不超过partition的数量，且二者最好保持整数倍关系，因为Kafka在设计时假定了一个partition只能被一个worker消费（同一group内）。简单的理解就是，实现了队列的方式。同一个groupid 的 consumer 属于一个队列方式，消费了就完事了&lt;/p&gt;
&lt;p&gt;&lt;span&gt;Leader（领导者）:&lt;/span&gt; Leader 是负责给定分区的所有读取和写入的节点。 每个分区都有一个服务器充当Leader.&lt;/p&gt;
&lt;p&gt;&lt;span&gt;Follower（追随者）:&lt;/span&gt;跟随领导者指令的节点被称为Follower。 如果领导失败，一个追随者将自动成为新的领导者。 跟随者作为正常消费者，拉取消息并更新其自己的数据存储。&lt;/p&gt;
&lt;p&gt;Kafka的特性:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;可靠性：Kafka是分布式，分区，复制和容错的。&lt;/li&gt;
&lt;li&gt;可扩展性：Kafka消息传递系统轻松缩放，无需停机。&lt;/li&gt;
&lt;li&gt;耐用性/持久性：Kafka使用分布式提交日志，这意味着消息会尽可能快地保留在磁盘上，因此它是持久的。&lt;/li&gt;
&lt;li&gt;性能：Kafka对于发布和订阅消息都具有高吞吐量。 即使存储了许多TB的消息，它也保持稳定的性能。&lt;/li&gt;
&lt;li&gt;高并发：支持数千个客户端同时读写&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;使用场景:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;指标:Kafka通常用于操作监控数据。 这涉及聚合来自分布式应用程序的统计信息，以产生操作数据的集中馈送。&lt;/li&gt;
&lt;li&gt;运营指标：Kafka也经常用来记录运营监控数据。包括收集各种分布式应用的数据，生产各种操作的集中反馈，比如报警和报告。&lt;/li&gt;
&lt;li&gt;日志聚合解决方案:Kafka可用于跨组织从多个服务收集日志，并使它们以标准格式提供给多个服务器。&lt;/li&gt;
&lt;li&gt;消息系统：解耦和生产者和消费者、缓存消息等。&lt;/li&gt;
&lt;li&gt;流处理:流行的框架(如Storm和Spark Streaming)从主题中读取数据，对其进行处理，并将处理后的数据写入新主题，供用户和应用程序使用。 Kafka的强耐久性在流处理的上下文中也非常有用。&lt;/li&gt;
&lt;/ul&gt;&lt;blockquote readability=&quot;7.0416666666667&quot;&gt;
&lt;p&gt;安装Kafka之前，先确认是否已安装Java和Zookeeper&lt;/p&gt;
&lt;p&gt;没有安装Java JDK的朋友可以直接看这里。&lt;a title=&quot;请叫我头头哥&quot; href=&quot;https://www.cnblogs.com/toutou/p/9670395.html&quot; target=&quot;_blank&quot;&gt;《CentOS安装Java JDK》&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;没有安装Zookeeper的朋友可以直接看这里。&lt;a title=&quot;请叫我头头哥&quot; href=&quot;https://www.cnblogs.com/toutou/p/install_codis.html#install_zookeeper&quot; target=&quot;_blank&quot;&gt;《安装ZooKeeper》&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;_nav_1&quot; class=&quot;blogCustomTitleStyle&quot;&gt;&lt;span class=&quot;blogCustomTitleIco&quot;&gt;v&lt;/span&gt;安装Kafka&lt;/h2&gt;
&lt;p&gt;2.1 下载&lt;/p&gt;
&lt;p&gt;&lt;code&gt;wget http://mirrors.hust.edu.cn/apache/kafka/2.0.0/kafka_2.12-2.0.0.tgz&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;如果下载很慢或者不方便，也可以用这里已经下载好的压缩包。&lt;a title=&quot;请叫我头头哥&quot; href=&quot;%E9%93%BE%E6%8E%A5:%20https://pan.baidu.com/s/1u8mSfubwZupFqKtK6PH6Qw&quot; target=&quot;_blank&quot;&gt;链接: https://pan.baidu.com/s/1u8mSfubwZupFqKtK6PH6Qw&lt;/a&gt; 提取码: v5em&lt;/p&gt;
&lt;p&gt;2.2 解压&lt;/p&gt;
&lt;p&gt;&lt;code&gt;tar -xzf kafka_2.12-2.0.0.tgz&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;注意，kafka_2.12-2.0.0.tgz版本是已经编译好的版本，解压就能使用。&lt;/p&gt;
&lt;p id=&quot;server_properties&quot;&gt;2.3 配置server.properties&lt;/p&gt;
&lt;p&gt;默认配置 &lt;code&gt;advertised.listeners=PLAINTEXT://:your.host.name:9092&lt;/code&gt; 修改为 &lt;code&gt;advertised.listeners=PLAINTEXT://:ip:9092&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;ip为服务器ip。&lt;/p&gt;
&lt;p&gt;hostname和端口是用来建议给生产者和消费者使用的，如果没有设置，将会使用listeners的配置，如果listeners也没有配置，将使用java.net.InetAddress.getCanonicalHostName()来获取这个hostname和port，对于ipv4，基本就是localhost了。&lt;/p&gt;
&lt;p&gt;&quot;PLAINTEXT&quot;表示协议，可选的值有PLAINTEXT和SSL，hostname可以指定IP地址，也可以用&quot;0.0.0.0&quot;表示对所有的网络接口有效，如果hostname为空表示只对默认的网络接口有效。也就是说如果你没有配置advertised.listeners，就使用listeners的配置通告给消息的生产者和消费者，这个过程是在生产者和消费者获取源数据(metadata)。&lt;/p&gt;
&lt;p&gt;更多介绍：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;49&quot;&gt;
&lt;pre&gt;
&lt;span&gt;# Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the &quot;License&quot;); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# see kafka.server.KafkaConfig for additional details and defaults

############################# Server Basics #############################

##################################################################################
#  broker就是一个kafka的部署实例，在一个kafka集群中，每一台kafka都要有一个broker.id
#  并且，该id唯一，且必须为整数
##################################################################################
broker.id=10

############################# Socket Server Settings #############################

# The address the socket server listens on. It will get the value returned from 
# java.net.InetAddress.getCanonicalHostName() if not configured.
#   FORMAT:
#     listeners = security_protocol://host_name:port
#   EXAMPLE:
#     listeners = PLAINTEXT://your.host.name:9092
#listeners=PLAINTEXT://:9092

# Hostname and port the broker will advertise to producers and consumers. If not set, 
# it uses the value for &quot;listeners&quot; if configured.  Otherwise, it will use the value
# returned from java.net.InetAddress.getCanonicalHostName().
#advertised.listeners=PLAINTEXT://your.host.name:9092

##################################################################################
#The number of threads handling network requests
# 默认处理网络请求的线程个数 3个
##################################################################################
num.network.threads=3
##################################################################################
# The number of threads doing disk I/O
# 执行磁盘IO操作的默认线程个数 8
##################################################################################
num.io.threads=8

##################################################################################
# The send buffer (SO_SNDBUF) used by the socket server
# socket服务使用的进行发送数据的缓冲区大小，默认100kb
##################################################################################
socket.send.buffer.bytes=102400

##################################################################################
# The receive buffer (SO_SNDBUF) used by the socket server
# socket服务使用的进行接受数据的缓冲区大小，默认100kb
##################################################################################
socket.receive.buffer.bytes=102400

##################################################################################
# The maximum size of a request that the socket server will accept (protection against OOM)
# socket服务所能够接受的最大的请求量，防止出现OOM(Out of memory)内存溢出，默认值为：100m
# （应该是socker server所能接受的一个请求的最大大小，默认为100M）
##################################################################################
socket.request.max.bytes=104857600

############################# Log Basics （数据相关部分，kafka的数据称为log）#############################

##################################################################################
# A comma seperated list of directories under which to store log files
# 一个用逗号分隔的目录列表，用于存储kafka接受到的数据
##################################################################################
log.dirs=/home/uplooking/data/kafka

##################################################################################
# The default number of log partitions per topic. More partitions allow greater
# parallelism for consumption, but this will also result in more files across
# the brokers.
# 每一个topic所对应的log的partition分区数目，默认1个。更多的partition数目会提高消费
# 并行度，但是也会导致在kafka集群中有更多的文件进行传输
# （partition就是分布式存储，相当于是把一份数据分开几份来进行存储，即划分块、划分分区的意思）
##################################################################################
num.partitions=1

##################################################################################
# The number of threads per data directory to be used for log recovery at startup and flushing at shutdown.
# This value is recommended to be increased for installations with data dirs located in RAID array.
# 每一个数据目录用于在启动kafka时恢复数据和在关闭时刷新数据的线程个数。如果kafka数据存储在磁盘阵列中
# 建议此值可以调整更大。
##################################################################################
num.recovery.threads.per.data.dir=1

############################# Log Flush Policy （数据刷新策略）#############################

# Messages are immediately written to the filesystem but by default we only fsync() to sync
# the OS cache lazily. The following configurations control the flush of data to disk.
# There are a few important trade-offs（平衡） here:
#    1. Durability 持久性: Unflushed data may be lost if you are not using replication.
#    2. Latency 延时性: Very large flush intervals may lead to latency spikes when the flush does occur as there will be a lot of data to flush.
#    3. Throughput 吞吐量: The flush is generally the most expensive operation, and a small flush interval may lead to exceessive seeks.
# The settings below allow one to configure the flush policy to flush data after a period of time or
# every N messages (or both). This can be done globally and overridden on a per-topic basis.
# kafka中只有基于消息条数和时间间隔数来制定数据刷新策略，而没有大小的选项，这两个选项可以选择配置一个
# 当然也可以两个都配置，默认情况下两个都配置，配置如下。

# The number of messages to accept before forcing a flush of data to disk
# 消息刷新到磁盘中的消息条数阈值
#log.flush.interval.messages=10000

# The maximum amount of time a message can sit in a log before we force a flush
# 消息刷新到磁盘生成一个log数据文件的时间间隔
#log.flush.interval.ms=1000

############################# Log Retention Policy（数据保留策略） #############################

# The following configurations control the disposal（清理） of log segments（分片）. The policy can
# be set to delete segments after a period of time, or after a given size has accumulated（累积）.
# A segment will be deleted whenever（无论什么时间） *either* of these criteria（标准） are met. Deletion always happens
# from the end of the log.
# 下面的配置用于控制数据片段的清理，只要满足其中一个策略（基于时间或基于大小），分片就会被删除

# The minimum age of a log file to be eligible for deletion
# 基于时间的策略，删除日志数据的时间，默认保存7天
log.retention.hours=168

# A size-based retention policy for logs. Segments are pruned from the log as long as the remaining
# segments don't drop below log.retention.bytes. 1G
# 基于大小的策略，1G
#log.retention.bytes=1073741824

# The maximum size of a log segment file. When this size is reached a new log segment will be created.
# 数据分片策略
log.segment.bytes=1073741824

# The interval at which log segments are checked to see if they can be deleted according
# to the retention policies 5分钟
# 每隔多长时间检测数据是否达到删除条件
log.retention.check.interval.ms=300000

############################# Zookeeper #############################

# Zookeeper connection string (see zookeeper docs for details).
# This is a comma separated host:port pairs, each corresponding to a zk
# server. e.g. &quot;127.0.0.1:3000,127.0.0.1:3001,127.0.0.1:3002&quot;.
# You can also append an optional chroot string to the urls to specify the
# root directory for all kafka znodes.
zookeeper.connect=uplooking01:2181,uplooking02:2181,uplooking03:2181

# Timeout in ms for connecting to zookeeper
zookeeper.connection.timeout.ms=6000&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id=&quot;_nav_2&quot; class=&quot;blogCustomTitleStyle&quot;&gt;&lt;span class=&quot;blogCustomTitleIco&quot;&gt;v&lt;/span&gt;启动Kafka&lt;/h2&gt;
&lt;p&gt;3.1 启动ZooKeeper&lt;/p&gt;
&lt;p&gt;&lt;code&gt;/usr/local/zookeeper-3.4.13/bin/zkServer.sh start&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;注意，需要先启动ZooKeeper再启动kafka，不然会报错。如下图：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/506684/201908/506684-20190828152549544-60850082.png&quot; alt=&quot;Linux安装Kafka&quot;/&gt;&lt;/p&gt;
&lt;p&gt;3.2 启动kafka&lt;/p&gt;
&lt;p&gt;&lt;code&gt;bin/kafka-server-start.sh config/server.properties&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/506684/201908/506684-20190828152557067-1116255559.png&quot; alt=&quot;Linux安装Kafka&quot;/&gt;&lt;/p&gt;
&lt;p&gt;启动Kafka Broker后，在ZooKeeper终端上键入命令 jps,效果如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/506684/201908/506684-20190814194228711-1784983106.png&quot; alt=&quot;Linux安装Kafka&quot;/&gt;&lt;/p&gt;
&lt;p&gt;3.2 停止kafka&lt;/p&gt;
&lt;p&gt;&lt;code&gt;bin/kafka-server-stop.sh config/server.properties&lt;/code&gt;&lt;/p&gt;
&lt;h2 id=&quot;_nav_3&quot; class=&quot;blogCustomTitleStyle&quot;&gt;&lt;span class=&quot;blogCustomTitleIco&quot;&gt;v&lt;/span&gt;Kafka topic&lt;/h2&gt;
&lt;p&gt;4.1 创建topic&lt;/p&gt;
&lt;p&gt;&lt;code&gt;bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic demo&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;其中demo为创建的topic名称。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/506684/201908/506684-20190814194234866-1687470987.png&quot; alt=&quot;Linux安装Kafka&quot;/&gt;&lt;/p&gt;
&lt;p&gt;如上图，创建了一个名为 demo 的主题，其中包含一个分区和一个副本因子。 创建成功之后会输出： &lt;code&gt;Created topic &quot;demo&quot;.&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/506684/201908/506684-20190814194241529-507479854.png&quot; alt=&quot;Linux安装Kafka&quot;/&gt;&lt;/p&gt;
&lt;p&gt;如上图，创建主题后，系统会在config / server.properties文件中的&quot;/ tmp / kafka-logs /&quot;中指定的创建主题的日志。&lt;/p&gt;
&lt;p&gt;4.2 查询topic列表&lt;/p&gt;
&lt;p&gt;&lt;code&gt;bin/kafka-topics.sh --list --zookeeper localhost:2181&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;4.3 查看topic信息&lt;/p&gt;
&lt;p&gt;&lt;code&gt;bin/kafka-topics.sh --zookeeper localhost:2181 --describe --topic demo&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;4.3 删除topic&lt;/p&gt;
&lt;p&gt;&lt;code&gt;bin/kafka-topics.sh --zookeeper localhost:2181 --delete --topic demo&lt;/code&gt;&lt;/p&gt;
&lt;h2 id=&quot;_nav_4&quot; class=&quot;blogCustomTitleStyle&quot;&gt;&lt;span class=&quot;blogCustomTitleIco&quot;&gt;v&lt;/span&gt;Kafka 生产/消费&lt;/h2&gt;
&lt;p&gt;5.1 启动生产者&lt;/p&gt;
&lt;p&gt;&lt;code&gt;bin/kafka-console-producer.sh --broker-list localhost:9092 --topic demo&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;从上面的语法，生产者命令行客户端需要两个主要参数 -&lt;/p&gt;
&lt;p&gt;代理列表 - 我们要发送邮件的代理列表。 在这种情况下，我们只有一个代理。 Config / server.properties文件包含代理端口ID，因为我们知道我们的代理正在侦听端口9092，因此您可以直接指定它。主题名称:demo。&lt;/p&gt;
&lt;p&gt;5.2 启动消费者&lt;/p&gt;
&lt;p&gt;为了方便测试，另启一个sheel窗口 这样效果更明显。需要注意的是旧版本和新版本的命令是不一样的&lt;/p&gt;
&lt;p&gt;&lt;code&gt;bin/kafka-console-consumer.sh --zookeeper localhost:2181 --topic demo --from-beginning&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;报错提示： &lt;code&gt;zookeeper is not a recognized option&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;发现在启动的时候说使用 --zookeeper是一个过时的方法，最新的版本中命令如下：&lt;/p&gt;
&lt;p&gt;&lt;code&gt;bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic demo --from-beginning&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;可以开启两个终端，一个发送消息，一个接受消息。效果如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/506684/201908/506684-20190814194253294-1419407414.png&quot; alt=&quot;Linux安装Kafka&quot;/&gt;&lt;/p&gt;
&lt;h2 id=&quot;_nav_5&quot; class=&quot;blogCustomTitleStyle&quot;&gt;&lt;span class=&quot;blogCustomTitleIco&quot;&gt;v&lt;/span&gt;Kafka 博客总结&lt;/h2&gt;
&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;Kafka是一个统一的平台，用于处理所有实时数据Feed。 Kafka支持低延迟消息传递，并在出现机器故障时提供对容错的保证。 它具有处理大量不同消费者的能力。 Kafka非常快，执行2百万写/秒。 Kafka将所有数据保存到磁盘，这实质上意味着所有写入都会进入操作系统(RAM)的页面缓存。 这使得将数据从页面缓存传输到网络套接字非常有效。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;本文中部分内容翻译或借鉴于以下学习资料，特别鸣谢：&lt;/p&gt;
&lt;div id=&quot;MySignature&quot; readability=&quot;9.0030211480363&quot;&gt;
&lt;p id=&quot;PSignature&quot;&gt;&lt;br/&gt;作　　者：&lt;strong&gt;&lt;span&gt;&lt;a href=&quot;http://www.cnblogs.com/toutou/&quot; target=&quot;_blank&quot;&gt;请叫我头头哥&lt;/a&gt;&lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;出　　处：&lt;a href=&quot;http://www.cnblogs.com/toutou/&quot; target=&quot;_blank&quot;&gt;http://www.cnblogs.com/toutou/&lt;/a&gt;&lt;br/&gt;关于作者：专注于基础平台的项目开发。如有问题或建议，请多多赐教！&lt;br/&gt;版权声明：本文版权归作者和博客园共有，欢迎转载，但未经作者同意必须保留此段声明，且在文章页面明显位置给出原文链接。&lt;br/&gt;特此声明：所有评论和私信都会在第一时间回复。也欢迎园子的大大们指正错误，共同进步。或者&lt;a href=&quot;http://msg.cnblogs.com/msg/send/%E8%AF%B7%E5%8F%AB%E6%88%91%E5%A4%B4%E5%A4%B4%E5%93%A5&quot;&gt;直接私信&lt;/a&gt;我&lt;br/&gt;声援博主：如果您觉得文章对您有帮助，可以点击文章右下角&lt;strong&gt;&lt;span&gt;【&lt;a id=&quot;post-up&quot;&gt;推荐&lt;/a&gt;】&lt;/span&gt;&lt;/strong&gt;一下。您的鼓励是作者坚持原创和持续写作的最大动力！&lt;br/&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
<pubDate>Sat, 05 Oct 2019 14:27:00 +0000</pubDate>
<dc:creator>请叫我头头哥</dc:creator>
<og:description>kafka是一个分布式消息队列。具有高性能、持久化、多副本备份、横向扩展能力。生产者往队列里写消息，消费者从队列里取消息进行业务逻辑。一般在架构设计中起到解耦、削峰、异步处理的作用。kafka对外使用</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/toutou/p/linux_install_kafka.html</dc:identifier>
</item>
<item>
<title>WebGL简易教程(六)：第一个三维示例(使用模型视图投影变换) - charlee44</title>
<link>http://www.cnblogs.com/charlee44/p/11625869.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/charlee44/p/11625869.html</guid>
<description>&lt;p&gt;在上一篇教程&lt;a href=&quot;https://blog.csdn.net/charlee44/article/details/102063461&quot;&gt;《WebGL简易教程(五)：图形变换(模型、视图、投影变换)》&lt;/a&gt;中，详细讲解了OpenGL\WebGL关于绘制场景的模型变换、视图变换以及投影变换的过程。不过那篇教程是纯理论知识，这里就具体结合一个实际的例子，进一步理解WebGL中是如何通过图形变换让一个真正的三维场景显示出来。&lt;/p&gt;

&lt;p&gt;继续改进之前的代码，这次就更进一步，在一个场景中绘制了三个三角形。&lt;/p&gt;
&lt;h2 id=&quot;triangle_mvpmatrix.html&quot;&gt;2.1. Triangle_MVPMatrix.html&lt;/h2&gt;
&lt;pre class=&quot;html&quot;&gt;
&lt;code&gt;&amp;lt;!DOCTYPE html&amp;gt;
&amp;lt;html lang=&quot;en&quot;&amp;gt;
  &amp;lt;head&amp;gt;
    &amp;lt;meta charset=&quot;utf-8&quot; /&amp;gt;
    &amp;lt;title&amp;gt;Hello Triangle&amp;lt;/title&amp;gt;
  &amp;lt;/head&amp;gt;

  &amp;lt;body onload=&quot;main()&quot;&amp;gt;
    &amp;lt;canvas id=&quot;webgl&quot; width=&quot;400&quot; height=&quot;400&quot;&amp;gt;
    Please use a browser that supports &quot;canvas&quot;
    &amp;lt;/canvas&amp;gt;

    &amp;lt;script src=&quot;../lib/webgl-utils.js&quot;&amp;gt;&amp;lt;/script&amp;gt;
    &amp;lt;script src=&quot;../lib/webgl-debug.js&quot;&amp;gt;&amp;lt;/script&amp;gt;
    &amp;lt;script src=&quot;../lib/cuon-utils.js&quot;&amp;gt;&amp;lt;/script&amp;gt;
    &amp;lt;script src=&quot;../lib/cuon-matrix.js&quot;&amp;gt;&amp;lt;/script&amp;gt;
    &amp;lt;script src=&quot;Triangle_MVPMatrix.js&quot;&amp;gt;&amp;lt;/script&amp;gt;
  &amp;lt;/body&amp;gt;
&amp;lt;/html&amp;gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;与之间的代码相比，这段代码主要是引入了一个cuon-matrix.js，这个是一个图形矩阵的处理库，能够方便与GLSL进行交互。&lt;/p&gt;
&lt;h2 id=&quot;triangle_mvpmatrix.js&quot;&gt;2.2. Triangle_MVPMatrix.js&lt;/h2&gt;
&lt;pre class=&quot;javascript&quot;&gt;
&lt;code&gt;// 顶点着色器程序
var VSHADER_SOURCE =
  'attribute vec4 a_Position;\n' + // attribute variable
  'attribute vec4 a_Color;\n' +
  'uniform mat4 u_MvpMatrix;\n' +
  'varying vec4 v_Color;\n' +
  'void main() {\n' +
  '  gl_Position = u_MvpMatrix * a_Position;\n' + // Set the vertex coordinates of the point
  '  v_Color = a_Color;\n' +
  '}\n';

// 片元着色器程序
var FSHADER_SOURCE =
  'precision mediump float;\n' +
  'varying vec4 v_Color;\n' +
  'void main() {\n' +
  '  gl_FragColor = v_Color;\n' +
  '}\n';

function main() {
  // 获取 &amp;lt;canvas&amp;gt; 元素
  var canvas = document.getElementById('webgl');

  // 获取WebGL渲染上下文
  var gl = getWebGLContext(canvas);
  if (!gl) {
    console.log('Failed to get the rendering context for WebGL');
    return;
  }

  // 初始化着色器
  if (!initShaders(gl, VSHADER_SOURCE, FSHADER_SOURCE)) {
    console.log('Failed to intialize shaders.');
    return;
  }

  // 设置顶点位置
  var n = initVertexBuffers(gl);
  if (n &amp;lt; 0) {
    console.log('Failed to set the positions of the vertices');
    return;
  }

  //设置MVP矩阵
  setMVPMatrix(gl,canvas);

  // 指定清空&amp;lt;canvas&amp;gt;的颜色
  gl.clearColor(0.0, 0.0, 0.0, 1.0);

  // 开启深度测试
  gl.enable(gl.DEPTH_TEST);

  // 清空颜色和深度缓冲区
  gl.clear(gl.COLOR_BUFFER_BIT | gl.DEPTH_BUFFER_BIT);

  // 绘制三角形
  gl.drawArrays(gl.TRIANGLES, 0, n);
}

//设置MVP矩阵
function setMVPMatrix(gl,canvas) {
  // Get the storage location of u_MvpMatrix
  var u_MvpMatrix = gl.getUniformLocation(gl.program, 'u_MvpMatrix');
  if (!u_MvpMatrix) {
    console.log('Failed to get the storage location of u_MvpMatrix');
    return;
  }

  //模型矩阵
  var modelMatrix = new Matrix4();
  modelMatrix.setTranslate(0.75, 0, 0);

  //视图矩阵
  var viewMatrix = new Matrix4();  // View matrix
  viewMatrix.setLookAt(0, 0, 5, 0, 0, -100, 0, 1, 0);

  //投影矩阵
  var projMatrix = new Matrix4();  // Projection matrix
  projMatrix.setPerspective(30, canvas.width / canvas.height, 1, 100);

  //MVP矩阵
  var mvpMatrix = new Matrix4();
  mvpMatrix.set(projMatrix).multiply(viewMatrix).multiply(modelMatrix);

  //将MVP矩阵传输到着色器的uniform变量u_MvpMatrix
  gl.uniformMatrix4fv(u_MvpMatrix, false, mvpMatrix.elements);
}

//
function initVertexBuffers(gl) {
  // 顶点坐标和颜色
  var verticesColors = new Float32Array([
    0.0, 1.0, -4.0, 0.4, 1.0, 0.4,  //绿色在后
    -0.5, -1.0, -4.0, 0.4, 1.0, 0.4,
    0.5, -1.0, -4.0, 1.0, 0.4, 0.4,

    0.0, 1.0, -2.0, 1.0, 1.0, 0.4, //黄色在中
    -0.5, -1.0, -2.0, 1.0, 1.0, 0.4,
    0.5, -1.0, -2.0, 1.0, 0.4, 0.4,

    0.0, 1.0, 0.0, 0.4, 0.4, 1.0,  //蓝色在前
    -0.5, -1.0, 0.0, 0.4, 0.4, 1.0,
    0.5, -1.0, 0.0, 1.0, 0.4, 0.4,
  ]);

  //
  var n = 9; // 点的个数
  var FSIZE = verticesColors.BYTES_PER_ELEMENT;   //数组中每个元素的字节数

  // 创建缓冲区对象
  var vertexBuffer = gl.createBuffer();
  if (!vertexBuffer) {
    console.log('Failed to create the buffer object');
    return -1;
  }

  // 将缓冲区对象绑定到目标
  gl.bindBuffer(gl.ARRAY_BUFFER, vertexBuffer);
  // 向缓冲区对象写入数据
  gl.bufferData(gl.ARRAY_BUFFER, verticesColors, gl.STATIC_DRAW);

  //获取着色器中attribute变量a_Position的地址 
  var a_Position = gl.getAttribLocation(gl.program, 'a_Position');
  if (a_Position &amp;lt; 0) {
    console.log('Failed to get the storage location of a_Position');
    return -1;
  }
  // 将缓冲区对象分配给a_Position变量
  gl.vertexAttribPointer(a_Position, 3, gl.FLOAT, false, FSIZE * 6, 0);

  // 连接a_Position变量与分配给它的缓冲区对象
  gl.enableVertexAttribArray(a_Position);

  //获取着色器中attribute变量a_Color的地址 
  var a_Color = gl.getAttribLocation(gl.program, 'a_Color');
  if (a_Color &amp;lt; 0) {
    console.log('Failed to get the storage location of a_Color');
    return -1;
  }
  // 将缓冲区对象分配给a_Color变量
  gl.vertexAttribPointer(a_Color, 3, gl.FLOAT, false, FSIZE * 6, FSIZE * 3);
  // 连接a_Color变量与分配给它的缓冲区对象
  gl.enableVertexAttribArray(a_Color);

  // 解除绑定
  gl.bindBuffer(gl.ARRAY_BUFFER, null);

  return n;
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;相比之前的代码，主要做了3点改进:&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;数据加入Z值；&lt;/li&gt;
&lt;li&gt;加入了深度测试；&lt;/li&gt;
&lt;li&gt;MVP矩阵设置；&lt;/li&gt;
&lt;/ol&gt;&lt;h3 id=&quot;数据加入z值&quot;&gt;2.2.1. 数据加入Z值&lt;/h3&gt;
&lt;p&gt;之前绘制的三角形，只有X坐标和Y坐标，Z值坐标自动补足为默认为0的。在这里会绘制了3个三角形，每个三角形的深度不同。如下代码所示，定义了3个三角形9个点，每个点包含xyz信息和rgb信息：&lt;/p&gt;
&lt;pre class=&quot;javascript&quot;&gt;
&lt;code&gt;  // 顶点坐标和颜色
  var verticesColors = new Float32Array([
    0.0, 1.0, -4.0, 0.4, 1.0, 0.4,  //绿色在后
    -0.5, -1.0, -4.0, 0.4, 1.0, 0.4,
    0.5, -1.0, -4.0, 1.0, 0.4, 0.4,

    0.0, 1.0, -2.0, 1.0, 1.0, 0.4, //黄色在中
    -0.5, -1.0, -2.0, 1.0, 1.0, 0.4,
    0.5, -1.0, -2.0, 1.0, 0.4, 0.4,

    0.0, 1.0, 0.0, 0.4, 0.4, 1.0,  //蓝色在前
    -0.5, -1.0, 0.0, 0.4, 0.4, 1.0,
    0.5, -1.0, 0.0, 1.0, 0.4, 0.4,
  ]);&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;这意味着与着色器传输变量的函数gl.vertexAttribPointer()的参数也得相应的变化。注意要深入理解这个函数每个参数代表的含义：&lt;/p&gt;
&lt;pre class=&quot;javascript&quot;&gt;
&lt;code&gt;  // ...

  // 将缓冲区对象分配给a_Position变量
  gl.vertexAttribPointer(a_Position, 3, gl.FLOAT, false, FSIZE * 6, 0);

  // ...
  // 将缓冲区对象分配给a_Color变量
  gl.vertexAttribPointer(a_Color, 3, gl.FLOAT, false, FSIZE * 6, FSIZE * 3);&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;加入深度测试&quot;&gt;2.2.2. 加入深度测试&lt;/h3&gt;
&lt;p&gt;在默认情况下,WebGL是根据顶点在缓冲区的顺序来进行绘制的，后绘制的图形会覆盖已经绘制好的图形。但是这样往往与实际物体遮挡情况不同，造成一些很怪异的现象，比如远的物体反而遮挡了近的物体。所以WebGL提供了一种深度检测(DEPTH_TEST)的功能，启用该功能就会检测物体（实际是每个像素）的深度，来决定是否绘制。其启用函数为：&lt;br/&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1000410/201910/1000410-20191005213758803-984724372.png&quot; alt=&quot;2&quot;/&gt;&lt;br/&gt;除此之外，还应该注意在绘制每一帧之前都应该清除深度缓冲区（depth buffer）。WebGL有多种缓冲区。我们之前用到的与顶点着色器交互的缓冲区对象就是顶点缓冲区，每次重新绘制刷新的就是颜色缓冲区。深度缓冲区记录的就是每个几何图形的深度信息，每绘制一帧，都应清除深度缓冲区：&lt;br/&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1000410/201910/1000410-20191005213854070-1096350261.png&quot; alt=&quot;3&quot;/&gt;&lt;br/&gt;在本例中的相关代码为：&lt;/p&gt;
&lt;pre class=&quot;javascript&quot;&gt;
&lt;code&gt;  // ...

  // 开启深度测试
  gl.enable(gl.DEPTH_TEST);

  // 清空颜色和深度缓冲区
  gl.clear(gl.COLOR_BUFFER_BIT | gl.DEPTH_BUFFER_BIT);

  // ...&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;mvp矩阵设置&quot;&gt;2.2.3. MVP矩阵设置&lt;/h3&gt;
&lt;p&gt;在上一篇教程中提到过，WebGL的任何图形变换过程影响的都是物体的顶点，模型变换、视图变换、投影变换都是在顶点着色器中实现的。由于每个顶点都是要进行模型视图投影变换的，所以可以合并成一个MVP矩阵，将其传入到顶点着色器中的：&lt;/p&gt;
&lt;pre class=&quot;c&quot;&gt;
&lt;code&gt;  //...
  'uniform mat4 u_MvpMatrix;\n' +  
  'void main() {\n' +
  '  gl_Position = u_MvpMatrix * a_Position;\n' + // Set the vertex coordinates of the point 
  //...
  '}\n';&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;在函数setMVPMatrix()中，创建了MVP矩阵，并将其传入到着色器：&lt;/p&gt;
&lt;pre class=&quot;javascript&quot;&gt;
&lt;code&gt;//设置MVP矩阵
function setMVPMatrix(gl,canvas) {
  // Get the storage location of u_MvpMatrix
  var u_MvpMatrix = gl.getUniformLocation(gl.program, 'u_MvpMatrix');
  if (!u_MvpMatrix) {
    console.log('Failed to get the storage location of u_MvpMatrix');
    return;
  }

  //模型矩阵
  var modelMatrix = new Matrix4();
  modelMatrix.setTranslate(0.75, 0, 0);

  //视图矩阵
  var viewMatrix = new Matrix4();  // View matrix
  viewMatrix.setLookAt(0, 0, 5, 0, 0, -100, 0, 1, 0);

  //投影矩阵
  var projMatrix = new Matrix4();  // Projection matrix
  projMatrix.setPerspective(30, canvas.width / canvas.height, 1, 100);

  //MVP矩阵
  var mvpMatrix = new Matrix4();
  mvpMatrix.set(projMatrix).multiply(viewMatrix).multiply(modelMatrix);

  //将MVP矩阵传输到着色器的uniform变量u_MvpMatrix
  gl.uniformMatrix4fv(u_MvpMatrix, false, mvpMatrix.elements);
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;在上述代码中，依次分别设置了：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;模型矩阵：X方向上平移了0.75个单位。&lt;/li&gt;
&lt;li&gt;视图矩阵：视点为(0,0,5)，观察点为(0,0,-100)，上方向为(0,1,0)的观察视角。&lt;/li&gt;
&lt;li&gt;投影矩阵：垂直张角为30，画图视图的宽高比，近截面距离为1，远截面为100的视锥体。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;三者级联，得到MVP矩阵，将其传入到顶点着色器中。&lt;/p&gt;

&lt;p&gt;用浏览器打开Triangle_MVPMatrix.html，就会发现浏览器页面显示了一个由远及近，近大远小的三个三角形。如图所示：&lt;br/&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1000410/201910/1000410-20191005213747970-1799724770.png&quot; alt=&quot;1&quot;/&gt;&lt;/p&gt;

&lt;p&gt;本来部分代码和插图来自《WebGL编程指南》，源代码链接：&lt;a href=&quot;https://share.weiyun.com/5VjlUKo&quot; class=&quot;uri&quot;&gt;https://share.weiyun.com/5VjlUKo&lt;/a&gt; ，密码：sw0x2x。会在此共享目录中持续更新后续的内容。&lt;/p&gt;
</description>
<pubDate>Sat, 05 Oct 2019 13:41:00 +0000</pubDate>
<dc:creator>charlee44</dc:creator>
<og:description>通过使用模型视图投影变换，完成第一个真正三维场景的示例：显示一组由远及近的三角形。</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/charlee44/p/11625869.html</dc:identifier>
</item>
<item>
<title>基于C#的机器学习--机器学习建模的基础 - 王振耀</title>
<link>http://www.cnblogs.com/wangzhenyao1994/p/11625797.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/wangzhenyao1994/p/11625797.html</guid>
<description>&lt;h2&gt;构建ML模型的步骤&lt;/h2&gt;
&lt;p&gt;现在我们已经看了解到了一些ML应用程序的例子，问题是，我们如何构建这样的ML应用程序和系统?&lt;/p&gt;
&lt;p&gt;下图总结了我们使用ML开发应用程序的方法，我们将在下面更详细地讨论这个问题:&lt;/p&gt;
&lt;p&gt; &lt;img src=&quot;https://img2018.cnblogs.com/blog/912798/201910/912798-20191005211505798-389673122.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;如上图所示，建立学习模型的步骤如下:&lt;/p&gt;
&lt;p&gt;       &lt;strong&gt;问题定义&lt;/strong&gt;:任何项目的第一步不仅是理解我们想要解决的问题,也定义了我们如何使用ML来解决问题。这第一步无疑是构建有用的ML模型和应用程序中最重要的一步。在开始构建ML模型之前，我们至少应该回答以下四个问题:&lt;/p&gt;
&lt;p&gt;l  &lt;strong&gt;当前碰到了什么问题&lt;/strong&gt;&lt;strong&gt;?&lt;/strong&gt;这是我们描述和陈述我们试图解决的问题的地方。例如，一个问题描述可能是需要一个系统来评估小企业主偿还小企业贷款项目贷款的能力。&lt;/p&gt;
&lt;p&gt;l  &lt;strong&gt;为什么这是个问题&lt;/strong&gt;&lt;strong&gt;?&lt;/strong&gt;重要的是要定义为什么这样的问题实际上是一个问题，以及为什么新的ML模型将是有用的。也许我们已经有了一个可用的模型，但发现它的表现比以前差了;我们可能已经获得了新的数据源，可以用来构建新的预测模型;或者我们希望现有的模型能够更快地产生预测结果。认为这是一个问题，并且需要一个新模型的原因可能有多种。定义它为什么是一个问题，将帮助我们在构建新的ML模型时，保持在正确的轨道上。&lt;/p&gt;
&lt;p&gt;l  &lt;strong&gt;解决这个问题的方法有哪些&lt;/strong&gt;&lt;strong&gt;?&lt;/strong&gt;这是我们集思广益解决给定问题的方法的地方。我们应该考虑这个模型是如何使用的(需要这是一个实时系统还是会作为批处理运行?),它是什么类型的问题(这是一个分类问题,回归,聚类,还是其他东西?),和我们需要什么类型的数据模型。这将为构建我们的机器学习模型的接下来的步骤提供良好的基础。&lt;/p&gt;
&lt;p&gt;l  &lt;strong&gt;成功的标准是什么&lt;/strong&gt;&lt;strong&gt;?&lt;/strong&gt;这是我们定义检查点的地方。我们应该考虑我们将查看什么指标，以及我们的目标模型性能应该是什么样的。如果我们正在构建一个将在实时系统中使用的模型，那么我们还可以在运行时将目标执行速度和数据可用性设置为成功标准的一部分。设定这些成功的标准将帮助我们继续前进，而不会在某个特定的步骤上停滞不前。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;收集数据&lt;/strong&gt;&lt;strong&gt;:&lt;/strong&gt;拥有数据是构建ML模型最基本和最关键的部分，最好是拥有大量数据。没有数据，就没有模型。根据我们的项目，收集数据的方法可能有所不同。我们可以从其他供应商购买现有的数据源，可以抓取网站并提取数据，可以使用公共数据，也可以收集自己的数据。收集ML模型所需的数据有多种方法，但是在数据收集过程中需要记住这两个数据元素—目标变量和特征变量。目标变量是预测的答案，而特征变量是模型用来学习如何预测目标变量的因素。通常，目标变量不会以标记的形式出现。例如，当我处理微博数据以预测每条微博的情绪时，我们可能没有为每条微博标记情绪数据。在这种情况下，我们必须采取额外的步骤来标记目标变量。收集了数据之后，就可以进入准备数据步骤。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;数据准备&lt;/strong&gt;&lt;strong&gt;:&lt;/strong&gt;收集完所有输入数据后，需要准备一个可用的格式。这一步比想象的更重要。如果我们拥有杂乱的数据，而没有为我们的学习算法去清理它，那么我们的算法将不会从我们收集到的的数据集中很好地学习，也不会像预期的那样执行。此外，即使我们拥有高质量的数据，如果我们的数据不是我们的算法可以训练的格式，那么拥有高质量的数据是没有任何意义的。至少我们应该处理以下列出的一些常见问题，以便我们的数据为下一步做好准备:&lt;/p&gt;
&lt;p&gt;n  &lt;strong&gt;文件格式&lt;/strong&gt;&lt;strong&gt;:&lt;/strong&gt;如果我们从多个数据源获取数据，那么很可能会遇到每个数据源的不同格式问题。有些数据可能是CSV格式，而其他数据是JSON或XML格式。有些数据甚至可能存储在关系数据库中。为了训练我们的ML模型，我们首先需要将所有这些不同格式的数据源合并到一个标准格式中。&lt;/p&gt;
&lt;p&gt;n  &lt;strong&gt;数据格式&lt;/strong&gt;&lt;strong&gt;:&lt;/strong&gt;不同数据源之间的数据格式也可能不同。例如，一些数据可能将地址字段分解为街道地址、市区、省份和邮政编码，而另一些数据可能没有。有些数据的日期字段可能是美国日期格式(mm/dd/yyyy)，而有些数据可能是英国日期格式(dd/mm/yyyy)。在解析这些值时，数据源之间的这些数据格式差异可能会导致问题。为了训练我们的ML模型，我们需要为每个字段提供统一的数据格式。&lt;/p&gt;
&lt;p&gt;n  &lt;strong&gt;重复记录&lt;/strong&gt;&lt;strong&gt;:&lt;/strong&gt;我们经常会看到相同的记录在数据集中重复出现。此问题可能发生在数据收集过程中，在此过程中，我们不止一次地记录了一个数据点，或者在数据准备过程中合并不同的数据集。拥有重复的记录可能会对我们的模型产生负面影响，在进行下一步之前，最好检查数据集中的是否存在重复记录。&lt;/p&gt;
&lt;p&gt;n  &lt;strong&gt;缺失值&lt;/strong&gt;&lt;strong&gt;:&lt;/strong&gt;在数据中看到一些记录为空或缺失值也是很常见的。当我们在训练我们的ML模型时，这也会产生不利的影响。有很多种方法可以处理数据中缺失的值，但是我们必须非常小心并很好地理解我们的数据，因为这可能会极大地改变我们的模型性能。处理缺失值的一些方法包括用缺失值删除记录、用平均值或中位数替换缺失值、用常量替换缺失值等等方法。在处理缺失值之前，研究我们的数据将会是意见非常有用的事情。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;数据分析&lt;/strong&gt;&lt;strong&gt;:&lt;/strong&gt;现在我们的数据已经准备好了，是时候实际查看数据了，看看我们是否能够识别任何模式并从数据中获得一些见解。摘要统计和图表是描述和理解数据的两种最佳方法。对于连续变量，从最小值、最大值、平均值、中值和四分位数开始比较好。对于分类变量，我们可以查看类别的计数和百分比。在查看这些汇总统计信息时，还可以开始绘制图形来可视化数据结构。下图显示了一些常用的数据分析图表。直方图常用来显示和检查变量、离散值和偏差的基本分布。箱形图经常用于可视化五位数摘要、离散值和偏差。散点图经常被用来检测变量之间明显的两两相关关系:&lt;/p&gt;
&lt;p&gt; &lt;img src=&quot;https://img2018.cnblogs.com/blog/912798/201910/912798-20191005211522706-1433568237.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt; 数据分析和可视化。左上:房屋销售价格直方图，右上:房屋销售价格直方图，左下:地下室、一层、二层建筑面积分布的箱形图，右下:一层与二层建筑面积的散点图。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;构造特征&lt;/strong&gt;&lt;strong&gt;:&lt;/strong&gt;构造特征是应用ML中模型构建过程中最重要的部分，然而，这是许多教科书和ML课程中讨论最少的话题之一。构造特征是将原始输入数据转换为更有意义的数据，以供算法学习的过程。例如，对于我们将要构建的微博情绪预测模型，我们的原始输入数据可能仅在一列中包含文本列表，而在另一列中包含情绪目标列表。我们的ML模型可能不会学习如何用这些原始数据，来进行很好地预测每条博文的情绪。但是，如果我们转换这些数据，列出每条博文中每个单词出现的次数，那么我们的学习算法可以更容易地了解某些单词的存在与情绪之间的关系。我们还可以将每个单词与其相邻的单词(bigram)进行分组，并将每条博文中每个相邻的单词(bigram)的出现次数作为另一组特征。从这个例子中可以看出，构造特征是一种使原始数据更具有代表性和更能反映潜在问题的方法。构造特征是一门科学，也是一门艺术。构造特征需要良好的数据集领域知识，从原始输入数据构建新特征的创造力，以及多次迭代以获得更好的结果。在后面的文章中，我们将会学习一些具体的构造特征的方法。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;训练&lt;/strong&gt;&lt;strong&gt;/&lt;/strong&gt;&lt;strong&gt;测试算法&lt;/strong&gt;&lt;strong&gt;:&lt;/strong&gt;一旦我们创建了自己的特性，就该训练和测试一些ML算法了。在开始训练模型之前，最好考虑一下性能指标。根据我们正在解决的问题，对性能度量的选择将会有所不同。例如，如果我们正在构建一个价格预测模型，我们可能希望最小化我们的预测与实际价格之间的差异，并选择均方根误差(RMSE)作为性能度量。如果我们正在构建一个信用模型来预测一个人是否能够获得贷款批准，那么我们可能希望使用精确度作为性能度量，因为错误的贷款批准(假阳性)比错误的贷款不批准(假阴性)具有更大的负面影响。&lt;/p&gt;
&lt;p&gt;一旦我们的模型有了具体的性能度量，我们就可以训练和测试各种学习算法及其性能。根据我们的预测目标，我们对学习算法的选择也会有所不同。下图展示了一些常见的机器学习问题。如果我们正在解决分类问题，那么我们可能希望训练分类器，例如逻辑回归模型、朴素贝叶斯分类器或随机森林分类器。另一方面，如果我们有一个连续的目标变量，那么我们就需要训练回归量，比如线性回归模型，k近邻，或者支持向量机(SVM)。如果我们想通过无监督学习从数据中获得一些见解，你可以使用k-means聚类或mean shift算法:&lt;/p&gt;
&lt;p&gt; &lt;img src=&quot;https://img2018.cnblogs.com/blog/912798/201910/912798-20191005211548002-1232546441.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;左:分类，中:回归，右:聚类&lt;/p&gt;
&lt;p&gt;最后，我们必须考虑如何测试和评估我们尝试的学习算法的性能。将数据集分成训练集和测试集，并运行交叉验证是测试和比较ML模型最常用的两种方法。分裂成两个子集的数据集的目的,一个用于训练，一个用于测试。K-fold交叉验证是评估模型性能的另一种方法。它首先将数据集分割成大小相等的K个子集，并将其中一个子集留作测试，其余的进行训练。例如，在3倍交叉验证中，数据集将首先分成三个大小相等的子集。在第一次迭代中，我们将使用包#1和#2来训练我们的模型，并在包#3上进行测试。在第二个迭代中，我们将使用包#1和#3在包#2上训练和测试我们的模型，在第三个迭代中，我们将使用包#2和#3在包#1上训练和测试我们的模型。然后，我们将性能度量进行平均，以估计模型的性能:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;改进结果&lt;/strong&gt;&lt;strong&gt;:&lt;/strong&gt;到目前为止，我们已经有了一个或两个表现相当不错的候选模型，但是可能仍然存在一些改进的空间。也许我们的候选模型在某种程度上过度拟合了,他们可能不符合我们的目标,有多种方法可以帮助提高我们的模型和他们的性能如下:&lt;/p&gt;
&lt;p&gt;l  &lt;strong&gt;超参数调优&lt;/strong&gt;&lt;strong&gt;:&lt;/strong&gt;我们可以调优模型的配置，以潜在地提高性能结果。例如，对于随机森林模型，我们可以调整树的最大高度或森林中的树的数量。对于向量机，我们可以调整内核或成本值。&lt;/p&gt;
&lt;p&gt;l  &lt;strong&gt;集成&lt;/strong&gt;&lt;strong&gt;:&lt;/strong&gt;集成是将多个模型的结果结合起来以获得更好的效果。集成是同样的算法在不同数据集的子集进行训练,提高结合不同模型相同的训练集,进行训练和叠加,模型的输出作为输入的元模型,学习如何结合子模型的结果。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;部署&lt;/strong&gt;&lt;strong&gt;:&lt;/strong&gt;一旦准备好了我们的模型，就到了让它们在生产环境中运行的时候了。确保在我们的模型完全部署之前，已经进行了大量的测试。为我们的模型开发监控工具也是一个很好的方法，因为随着输入数据的发展，模型性能会随着时间的推移而下降。&lt;/p&gt;
&lt;h2&gt;总结&lt;/h2&gt;
&lt;p&gt;在本章中，我们学习了开发ML模型的步骤以及每个步骤中的常见挑战和任务。在接下来的章节中，我们将遵循这些步骤来完成我们的项目，我们将更详细地探索某些步骤，特别是在构造特征、模型选择和模型性能评估方面。我们将根据要解决的问题类型，讨论在每个步骤中可以应用的各种技术。&lt;/p&gt;
&lt;p&gt;在下一章中，我们将直接应用ML的基本原理来构建垃圾邮件过滤的ML模型。我们将按照本章讨论的构建ML模型的步骤，将原始电子邮件数据转换为结构化数据集，分析电子邮件文本数据以获得一些见解，最后构建预测电子邮件是否是垃圾邮件的分类模型。在下一章中，我们还将讨论一些常用的分类模型评估指标。&lt;/p&gt;
</description>
<pubDate>Sat, 05 Oct 2019 13:16:00 +0000</pubDate>
<dc:creator>王振耀</dc:creator>
<og:description>构建ML模型的步骤 现在我们已经看了解到了一些ML应用程序的例子，问题是，我们如何构建这样的ML应用程序和系统? 下图总结了我们使用ML开发应用程序的方法，我们将在下面更详细地讨论这个问题: 如上图所</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/wangzhenyao1994/p/11625797.html</dc:identifier>
</item>
<item>
<title>使用.NET Core创建Windows服务（二） -  使用Topshelf方式 - LamondLu</title>
<link>http://www.cnblogs.com/lwqlun/p/11625789.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/lwqlun/p/11625789.html</guid>
<description>&lt;blockquote readability=&quot;7&quot;&gt;
&lt;p&gt;原文：Creating Windows Services In .NET Core – Part 2 – The “Topshelf” Way&lt;br/&gt;作者：Dotnet Core Tutorials&lt;br/&gt;译者：Lamond Lu&lt;br/&gt;译文：使用.NET Core创建Windows服务（二） - 使用Topshelf方式&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/65831/201910/65831-20191005211343706-2050001309.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;使用.NET Core创建Windows服务&lt;/p&gt;
&lt;hr/&gt;&lt;p&gt;在前一篇文章中，我给大家介绍了，如何基于微软推荐方式使用.NET Core创建Windows服务。我们发现使用这种方式，我们很容易就可以搭建和运行一个Windows服务，但是问题是使用这种方式，代码调试将非常困难。&lt;/p&gt;
&lt;p&gt;那么现在就是&lt;code&gt;Topshelf&lt;/code&gt;出场的时候了。&lt;code&gt;Topshelf&lt;/code&gt;是一个.NET Standard库，它消除了在.NET Framework和.NET Core中创建Windows服务的那些麻烦。&lt;/p&gt;

&lt;p&gt;与微软推荐方式类似，这里Visual Studio并没有提供一个基于&lt;code&gt;Topshelf&lt;/code&gt;创建Windows服务的模板，所以我们依然需要通过创建普通控制台程序的方式，来创建一个Windows服务。&lt;/p&gt;
&lt;p&gt;然后，我们需要通过Package Manager Console, 运行以下命令，安装&lt;code&gt;Topshelf&lt;/code&gt;类库。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;Install-Package Topshelf&lt;/code&gt;
&lt;/pre&gt;

&lt;p&gt;下面我们就来使用&lt;code&gt;Topshelf&lt;/code&gt;重构之前的服务代码。&lt;/p&gt;
&lt;pre class=&quot;c#&quot;&gt;
&lt;code&gt;public class LoggingService : ServiceControl
{
    private const string _logFileLocation = @&quot;C:\temp\servicelog.txt&quot;;
 
    private void Log(string logMessage)
    {
        Directory.CreateDirectory(Path.GetDirectoryName(_logFileLocation));
        File.AppendAllText(_logFileLocation, 
            DateTime.UtcNow.ToString() + &quot; : &quot; + logMessage + Environment.NewLine);
    }
 
    public bool Start(HostControl hostControl)
    {
        Log(&quot;Starting&quot;);
        return true;
    }
 
    public bool Stop(HostControl hostControl)
    {
        Log(&quot;Stopping&quot;);
        return true;
    }
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;代码看起来是不是很简单？&lt;/p&gt;
&lt;p&gt;这里我们的服务类继承了&lt;code&gt;ServiceControl&lt;/code&gt;类（实际上并不需要，但是这可以为我们的工作打下良好的基础）。我们必须实现服务开始和服务结束两个方法，并且像以前一样记录日志。&lt;/p&gt;
&lt;p&gt;在&lt;code&gt;Program.cs&lt;/code&gt;文件的&lt;code&gt;Main&lt;/code&gt;方法中，我们要写的代码也非常的简单。我们可以直接使用&lt;code&gt;HostFactory.Run&lt;/code&gt;方法来启动服务。&lt;/p&gt;
&lt;pre class=&quot;c#&quot;&gt;
&lt;code&gt;static void Main(string[] args)
{
    HostFactory.Run(x =&amp;gt; x.Service&amp;lt;LoggingService&amp;gt;());
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;这看起来真是太简单了。但这并不是&lt;code&gt;HostFactory&lt;/code&gt;类的唯一功能。这里我们还可以设置&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;服务的名称&lt;/li&gt;
&lt;li&gt;服务是否自动启动&lt;/li&gt;
&lt;li&gt;服务崩溃之后的重启时间&lt;/li&gt;
&lt;/ul&gt;&lt;pre class=&quot;c#&quot;&gt;
&lt;code&gt;static void Main(string[] args)
{
    HostFactory.Run(x =&amp;gt;
        {
            x.Service&amp;lt;LoggingService&amp;gt;();
            x.EnableServiceRecovery(r =&amp;gt; r.RestartService(TimeSpan.FromSeconds(10)));
            x.SetServiceName(&quot;TestService&quot;);
            x.StartAutomatically();
         }
    );
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;这里其实能说的东西很多，但是我建议你还是自己去看看&lt;code&gt;Topshelf&lt;/code&gt;的文档，学习一下其他的配置选项。基本上你能使用Windows命令行完成的所有操作，都可以使用代码来设置： &lt;a href=&quot;https://topshelf.readthedocs.io/en/latest/configuration/config_api.html&quot; class=&quot;uri&quot;&gt;https://topshelf.readthedocs.io/en/latest/configuration/config_api.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;和之前一样，我们需要针对不同的Windows环境发布我们的服务。在Windows命令提示符下，我们可以在项目目录中执行以下命令：&lt;/p&gt;
&lt;pre class=&quot;powershell&quot;&gt;
&lt;code&gt;dotnet publish -r win-x64 -c Release&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;现在我们就可以查看一下&lt;code&gt;bin\Release\netcoreappX.X\win-x64\publish&lt;/code&gt;目录，我们会发现一个编译好的exe，下面我们就会使用这个文件来安装服务。&lt;/p&gt;
&lt;p&gt;在上一篇文章中，我们是使用&lt;code&gt;SC&lt;/code&gt;命令来安装Windows服务的。使用&lt;code&gt;Topshelf&lt;/code&gt;我们就不需要这么做了，&lt;code&gt;Topshelf&lt;/code&gt;提供了自己的命令行参数来安装服务。基本上使用代码能完成的配置，都可以使用命令行来完成。&lt;/p&gt;
&lt;p&gt;你可以查看相关的文档：&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://docs.topshelf-project.com/en/latest/overview/commandline.html&quot;&gt;&amp;lt;http://docs.topshelf-project.com/en/latest/overview/commandline.html&amp;gt;&lt;/a&gt;&lt;/p&gt;
&lt;pre class=&quot;powershell&quot;&gt;
&lt;code&gt;WindowsServiceExample.exe install&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;这里&lt;code&gt;WindowsServiceExample.exe&lt;/code&gt;是我发布之后的exe文件。运行以上命令之后，服务应该就正常安装了！这里有一个小问题，我经常发现，即使配置了服务自动启动，但是服务安装之后，并不会触发启动操作。所有在服务安装之后，我们还需要通过以下命令来启动服务。&lt;/p&gt;
&lt;pre class=&quot;c#&quot;&gt;
&lt;code&gt;WindowsServiceExample.exe start&lt;/code&gt;
&lt;/pre&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;在生产环境部署的时候，我的经验是在安装服务之后，等待10秒钟，再启动服务。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;当我们是使用微软推荐方式的时候，我们会遇到了调试困难的问题。大多数情况下，无论是否在服务内部运行，我们都不得不使用命令行标志、&lt;code&gt;#IF DEBUG&lt;/code&gt;指令或者配置值来实现调试。然后使用Hack的方式在控制台程序中模拟服务。&lt;/p&gt;
&lt;p&gt;因此，这就是为什么我们要使用&lt;code&gt;Topshelf&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;如果我们的服务代码已经在Visual Studio中打开了，我们就可以直接启动调试。&lt;code&gt;Topshelf&lt;/code&gt;会模拟在控制台中启动服务。我们应该能在控制台中看到以下的消息。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;The TestService service is now running, press Control+C to exit.&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;这确实符合了我们的需求。它启动了我们的服务，并像真正的Windows服务一样在后台运行。我们可以像往常一样设置断点，基本上它遵循的流程和正常安装的服务一样。&lt;/p&gt;
&lt;p&gt;我们可以通过ctrl+c, 来关闭我们的应用，但是在运行服务执行Stop方法之前，它是不能被关闭的，这使我们可以调试服务的关闭流程。与调试指令和配置标志相比，这要容易的多。&lt;/p&gt;
&lt;p&gt;这里需要注意一个问题。如果你收到的以下内容的消息：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;The TestService service is running and must be stopped before running via the console&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;这意味着你尝试调试的服务实际上已经作为Windows服务被安装在系统中了，你需要停止（不需要卸载）这个正在运行的服务，才可以正常调试。&lt;/p&gt;

&lt;p&gt;在上一篇中，有读者指出.NET Core中实际上已经提供了一种完全不同的方式运行Windows服务。它的实质是利用了ASP.NET Core中引入的“托管服务”模型，并允许它们作为Windows服务来运行，这真的是非常的棒。&lt;/p&gt;
</description>
<pubDate>Sat, 05 Oct 2019 13:16:00 +0000</pubDate>
<dc:creator>LamondLu</dc:creator>
<og:description>原文：Creating Windows Services In .NET Core – Part 2 – The “Topshelf” Way 作者：Dotnet Core Tutorials 译者：</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/lwqlun/p/11625789.html</dc:identifier>
</item>
<item>
<title>计算机图形学——区域填充算法 - 王陸</title>
<link>http://www.cnblogs.com/wkfvawl/p/11625712.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/wkfvawl/p/11625712.html</guid>
<description>&lt;h2&gt;一、区域填充概念&lt;/h2&gt;
&lt;p&gt;&lt;span&gt;区域：指已经表示成点阵形式的填充图形，是象素的集合。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;区域填充：将区域内的一点（常称&lt;span&gt;【种子点】）赋予给定颜色，然后将这种颜色&lt;span&gt;扩展到整个区域内的过程。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;区域填充算法要求区域是连通的，因为只有在连通区域中，才可能将种子点的颜色扩展到区域内的其它点。&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h3&gt;1、区域有两种表示形式&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1484107/201809/1484107-20180918163101038-602092055.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1）内点表示：枚举出区域内部的所有象素，内部所有象素着同一个颜色，边界像素着与内部象素不同的颜色。&lt;br/&gt;&lt;span&gt;2）边界表示：枚举出区域外部的所有象素，边界上的所有象素着同一个颜色，内部像素着与边界象素不同的颜色。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h3&gt;2、区域连通&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1358881/201910/1358881-20191005174403917-526310833.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;1）四向连通区域：从区域上一点出发可通过【上、下、左、右】四个方向移动的组合，在不越出区域的前提下，到达区域内的任意象素。&lt;br/&gt;&lt;span&gt;2）八向连通区域：从区域上一点出发可通过【上、下、左、右、左上、右上、左下、右下】八个方向移动的组合，在不越出区域的前提下，到达区域内的任意象素。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h2&gt;二、简单种子填充算法&lt;/h2&gt;
&lt;h3&gt;&lt;span&gt;&lt;strong&gt;基本思想&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;&lt;span&gt;给定区域G一种子点（x, y）,首先判断该点是否是区域内的一点，如果是，则将该点填充为新的颜色，然后将该点周围的四个点（四连通）或八个点（八连通）作为新的种子点进行同样的处理，通过这种扩散完成对整个区域的填充。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;这里给出一个&lt;strong&gt;&lt;span&gt;四连通的种子填充算法（区域填充递归算法）&lt;/span&gt;&lt;/strong&gt;，使用&lt;strong&gt;&lt;span&gt;【栈结构】&lt;/span&gt;&lt;/strong&gt;来实现&lt;br/&gt;&lt;span&gt;原理算法原理如下：种子像素入栈，当&lt;strong&gt;&lt;span&gt;【栈非空】&lt;/span&gt;&lt;/strong&gt;时重复如下三步：&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1358881/201910/1358881-20191005180217185-690539782.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;h3&gt;&lt;span&gt;算法代码&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;&lt;span&gt; 这里给出八&lt;strong&gt;&lt;span&gt;连通的种子填充算法&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;的代码：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;71&quot;&gt;
&lt;pre&gt;
&lt;span&gt;void flood_fill_8(&lt;span&gt;int[] pixels, &lt;span&gt;int x, &lt;span&gt;int y, &lt;span&gt;int old_color, &lt;span&gt;int&lt;span&gt; new_color)
{
    &lt;span&gt;if(x&amp;lt;w&amp;amp;&amp;amp;x&amp;gt;&lt;span&gt;0&amp;amp;&amp;amp;y&amp;lt;h&amp;amp;&amp;amp;y&amp;gt;&lt;span&gt;0&lt;span&gt;)
    {
        &lt;span&gt;if (pixels[y*w+x]==&lt;span&gt;old_color)
        {
            pixels[y*w+x]==&lt;span&gt; new_color);
            flood_fill_8(pixels, x,y+&lt;span&gt;1&lt;span&gt;,old_color,new_color);
            flood_fill_8(pixels, x,y-&lt;span&gt;1&lt;span&gt;,old_color,new_color);
            flood_fill_8(pixels, x-&lt;span&gt;1&lt;span&gt;,y,old_color,new_color);
            flood_fill_8(pixels, x+&lt;span&gt;1&lt;span&gt;,y,old_color,new_color);
            flood_fill_8(pixels, x+&lt;span&gt;1,y+&lt;span&gt;1&lt;span&gt;,old_color,new_color);
            flood_fill_8(pixels, x+&lt;span&gt;1,y-&lt;span&gt;1&lt;span&gt;,old_color,new_color);
            flood_fill_8(pixels, x-&lt;span&gt;1,y+&lt;span&gt;1&lt;span&gt;,old_color,new_color);
            flood_fill_8(pixels, x-&lt;span&gt;1,y-&lt;span&gt;1&lt;span&gt;,old_color,new_color);
        }
    }
}&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;&lt;strong&gt;简单种子填充算法的不足&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;&lt;span&gt; a)有些像素会多次入栈，降低算法效率，栈结构占空间&lt;br/&gt;&lt;span&gt; b)递归执行，算法简单，但效率不高，区域内每一像素都要进/出栈，费时费内存&lt;br/&gt;&lt;span&gt; c)改进算法，减少递归次数，提高效率&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h2&gt;三、扫描线种子填充算法&lt;/h2&gt;
&lt;h3&gt;&lt;strong&gt;基本思想&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;&lt;span&gt;从&lt;span&gt;&lt;strong&gt;给定的种子点&lt;/strong&gt;开始，&lt;strong&gt;&lt;span&gt;填充&lt;/span&gt;&lt;/strong&gt;当前扫描线上种子点所在的一&lt;strong&gt;&lt;span&gt;区段&lt;/span&gt;&lt;/strong&gt;，然后确定与这一段相邻的&lt;strong&gt;&lt;span&gt;上下两条扫描线&lt;/span&gt;&lt;/strong&gt;上位于区域内的区段（需要填充的区间），从这些区间上&lt;strong&gt;&lt;span&gt;各取一个种子点&lt;/span&gt;&lt;/strong&gt;依次把它们存起来，&lt;strong&gt;&lt;span&gt;作为下次填充的种子点&lt;/span&gt;&lt;/strong&gt;。反复进行这过程，直到所保存的各区段都填充完毕。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h3&gt;算法步骤&lt;/h3&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;步骤 1：&lt;/strong&gt;（初始化）将算法设置的堆栈置为空。将给定的种子点（x, y）压入堆栈&lt;br/&gt;&lt;span&gt;&lt;strong&gt;步骤 2：&lt;/strong&gt;（出栈）如果堆栈为空，算法结束；否则取栈顶元素（x, y）作为种子点&lt;br/&gt;&lt;span&gt;&lt;strong&gt;步骤 3：&lt;/strong&gt;（区段填充）从种子点（x, y）开始，沿纵坐标为y的当前扫描线&lt;strong&gt;&lt;span&gt;向左右两个方向&lt;/span&gt;&lt;/strong&gt;逐个像素用新的颜色值进行填充，直到边界为止即象素颜色等于边界色。设区间两边界的横坐标分别为&lt;strong&gt;&lt;span&gt;xleft&lt;/span&gt;&lt;/strong&gt; 和&lt;strong&gt;&lt;span&gt;xright&lt;/span&gt;&lt;/strong&gt;。&lt;br/&gt;&lt;span&gt;&lt;strong&gt;步骤4：&lt;/strong&gt;在与当前扫描线相邻的上下两条扫描线上，以区间[xleft, xright]为搜索范围，求出需要填充的各小区间，把各小区间中最右边的点并作为种子点压入堆栈，转到步骤2。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1358881/201910/1358881-20191005193825229-737858434.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;h3&gt;算法的关键原则&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;1）搜索原则：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;从前一个填充的区间（边界之间的范围xleft, xright）作为后一条扫描线种子点寻找的范围。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2）填充原则：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;从种子点往左，右填，填到边界&lt;/p&gt;
&lt;p&gt; &lt;img src=&quot;https://img2018.cnblogs.com/blog/1358881/201910/1358881-20191005194700084-678070179.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;h3&gt;实例&lt;/h3&gt;
&lt;p&gt;上述算法的描述过于抽象，直接看演示&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1358881/201910/1358881-20191005193347134-1438153927.gif&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;h3&gt;&lt;span&gt;算法代码&lt;/span&gt;&lt;/h3&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;37&quot;&gt;
&lt;pre&gt;
Stack stack=&lt;span&gt;new Stack();&lt;span&gt;//&lt;span&gt;堆栈 pixel_stack初始化
Stack.push (point)；    &lt;span&gt;//&lt;span&gt;(x,y)是给定的种子像素
&lt;span&gt;while (!&lt;span&gt;stack.empty())
{
    p=(Point)(stack.pop());&lt;span&gt;//&lt;span&gt;出栈，从堆栈中取一像素作种子像素
    x=&lt;span&gt;p.x;
    y=&lt;span&gt;p.y;
    savex=x;&lt;span&gt;//&lt;span&gt;保存种子点的横坐标x的值
    &lt;span&gt;while (pixels [y*w+x]!=&lt;span&gt; boundary_color)
    {
        pixels [y*w+x]=&lt;span&gt; new_color;
        x++&lt;span&gt;;
    } &lt;span&gt;//&lt;span&gt;从种子像素开始向右填充到边界
    xright=x–1; &lt;span&gt;//&lt;span&gt;保存线段的右端点
    x=savex–1;  &lt;span&gt;//&lt;span&gt;设定种子点往左填充的起点
    &lt;span&gt;while (pixels [y*w+x]!=&lt;span&gt; boundary_color)
    {
        pixels [y*w+x] =&lt;span&gt; new_color;
        x=x–1&lt;span&gt;;
    }
    &lt;span&gt;//&lt;span&gt;从种子像素开始向左填充到边界，以上两步完成区间填充。
    xleft=x+1； &lt;span&gt;//&lt;span&gt;保存线段的左端点，加1是因为前面 循环时多减一次
    x=xleft;     &lt;span&gt;//&lt;span&gt;起点是上次的左端点
    y=y+1;     &lt;span&gt;//&lt;span&gt;开始处理上一条扫描线
    &lt;span&gt;while(x&amp;lt;=xright)   &lt;span&gt;//&lt;span&gt;在上一条扫描线上检查是否需要填充
&lt;span&gt;    {
        span_need_fill=&lt;span&gt;false;   &lt;span&gt;//&lt;span&gt;先设定为不需要填充
        &lt;span&gt;while (pixels [y*w+x] ==old_color&amp;amp;&amp;amp;x&amp;lt;=&lt;span&gt;xright )
        {
            &lt;span&gt;//&lt;span&gt;待填充的线段
            span_need_fill=&lt;span&gt;true; &lt;span&gt;//&lt;span&gt;发现有旧象素，需要填充
            x=x+1&lt;span&gt;;
        } &lt;span&gt;//&lt;span&gt;待填充的线段处理完，即遇到边界色，!=old_color跳出

        &lt;span&gt;if (span_need_fill)   &lt;span&gt;//&lt;span&gt;如果区间需要填充，则将其右端点作为种子点压进堆栈
&lt;span&gt;        {
            p=&lt;span&gt;new Point(x-1&lt;span&gt;,y);
            stack.push (p); &lt;span&gt;//&lt;span&gt;进栈
            span_need_fill=&lt;span&gt;false&lt;span&gt;;
        }
        &lt;span&gt;//&lt;span&gt;继续向右检查以防有遗漏
        &lt;span&gt;while (pixels [y*w+x] !=old_color &amp;amp;&amp;amp;x&amp;lt;=&lt;span&gt;xright )
            x=x+1&lt;span&gt;;
    } &lt;span&gt;//&lt;span&gt;在上一条扫描线上检查完
&lt;span&gt;    x＝xleft；
    y=y–2; &lt;span&gt;//&lt;span&gt;形成下一条扫描线的y值
&lt;span&gt;//&lt;span&gt;在下一条扫描线上从左向右检查位于区间[xleft，xright]上的像素，其方法与在上一条扫描线上检查的情况完全一样，见书。
}&lt;span&gt;//&lt;span&gt;出栈完&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;四、多边形的扫描转换与区域填充算法小结&lt;/h2&gt;
&lt;p&gt;上一篇博客讲述了&lt;a href=&quot;https://www.cnblogs.com/wkfvawl/p/11622265.html&quot; target=&quot;_blank&quot;&gt;多边形的扫描转换&lt;/a&gt; ，这里将多边形扫描转换和区域填充算法进行比较总结。&lt;/p&gt;
&lt;h3&gt;基本思想不同&lt;/h3&gt;
&lt;p&gt;多边形扫描转换是指将多边形的顶点表示转化为点阵表示&lt;/p&gt;
&lt;p&gt;区域填充只改变填充颜色，不改变区域表示方式&lt;/p&gt;
&lt;h3&gt;基本条件不同&lt;/h3&gt;
&lt;p&gt;在区域填充算法中，要求给定区域内的一点作为种子点，然后从这一点根据连通性将新的颜色扩展到整个区域。&lt;/p&gt;
&lt;p&gt;扫描转换多边形是从多边形的边界（顶点）信息出发，利用多种形式的连贯性进行填充的。&lt;/p&gt;
&lt;p&gt;扫描转换区域填充的核心是知道多边形的&lt;span&gt;边界，&lt;span&gt;要得到多边形内部的像素集，有很多种办法。其中扫描线算法是利用一套&lt;span&gt;特殊的数据结构&lt;/span&gt;，&lt;span&gt;避免求交&lt;/span&gt;，然后一条条扫描线确定。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;span&gt;区域填充条件更强&lt;/span&gt;一些，不但要知道边界，而且要知道区域内的一点，可以利用四连通或八连通区域不断向外扩展。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;填充一个定义的区域的选择包括：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;a)选择实区域颜色或图案填充方式&lt;/p&gt;
&lt;p&gt;b)选择某种颜色和图案&lt;/p&gt;
&lt;p&gt;这些填充选择可以应用于多边形区域或用曲线边界定义的区域；此外，区域可用多种画笔、颜色和透明度参数来绘制&lt;/p&gt;

</description>
<pubDate>Sat, 05 Oct 2019 12:50:00 +0000</pubDate>
<dc:creator>王陸</dc:creator>
<og:description>一、区域填充概念 区域：指已经表示成点阵形式的填充图形，是象素的集合。 区域填充：将区域内的一点（常称【种子点】）赋予给定颜色，然后将这种颜色扩展到整个区域内的过程。 区域填充算法要求区域是连通的，因</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/wkfvawl/p/11625712.html</dc:identifier>
</item>
</channel>
</rss>