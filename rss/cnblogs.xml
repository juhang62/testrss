<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="css/feed.xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/" xmlns:og="http://ogp.me/ns#">
<channel>
<atom:link rel="self" href="http://192.168.1.4/fivefilters/makefulltextfeed.php?url=feed.cnblogs.com%2Fblog%2Fsitehome%2Frss&amp;max=10&amp;links=preserve&amp;exc=" />
<atom:link rel="alternate" title="Source URL" href="http://feed.cnblogs.com/blog/sitehome/rss" />
<atom:link rel="related" title="Subscribe to feed" href="http://www.subtome.com/#/subscribe?feeds=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed.cnblogs.com%252Fblog%252Fsitehome%252Frss%26max%3D10%26links%3Dpreserve%26exc%3D&amp;back=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed.cnblogs.com%252Fblog%252Fsitehome%252Frss%26max%3D10%26links%3Dpreserve%26exc%3D" />
<title>博客园_首页</title>
<link></link>
<description>代码改变世界</description>
<item>
<title>全方位认识HBase：一个值得拥有的NoSQL数据库（一） - 周蓬勃</title>
<link>http://www.cnblogs.com/zpb2016/p/12723939.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/zpb2016/p/12723939.html</guid>
<description>&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;&lt;strong&gt;前言：&lt;/strong&gt;说起HBase这门技术，在认知上对于稍微接触或使用过它的人来讲，可能只是百千数据库中一个很普通的库，大概就像我对Redis的认知一样：缓存嘛！可对于HBase，我确实是带着某些感情在的。今日突然萌生了一个生趣的想法，想抛开技术的视角，从情感的角度，像写小说一样，写写这位老朋友，这可能会有点滑稽吧，不过我觉得很放松。《全方位认识HBase：一个值得拥有的NoSQL数据库》：从今天起，我们就暂且认为这是一本小说的名字吧！哈哈~&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;其实我特别想做的一件事情，就是想让更多的人来认识并使用HBase这门地地道道的大数据栈技术，当然不为别的，主要原因还是HBase真的很棒很热，自己用着感觉真的好，不好的产品我怎么会推荐给你呢？毕竟HBase这家伙不会给我一分钱的广告费~&lt;/p&gt;
&lt;p&gt;那首先，我想给大家分享的内容就是：在我刚接触HBase这位老朋友的时候根本不想去看的一些觉得没用的东西。什么呢？其实就是特别无聊又深奥的好像还不得不问的灵魂三问：我是谁？我从哪里来？我要到哪里去？&lt;/p&gt;
&lt;p&gt;为什么想写写这个呢？真的好无聊啊~ 当然肯定不是我太无聊了，说实话，是因为对它真的有感情了，所以就想把它的前世今生全都介绍给你，可能算是一种情怀，也可能算是一种敬畏，也可能只是怕赶路的人忘了它是谁。&lt;/p&gt;
&lt;h3 id=&quot;我从哪里来？&quot;&gt;我从哪里来？&lt;/h3&gt;
&lt;p&gt;我们知道，HBase出现于大数据背景之下，那么谈到这个问题，我们不得不提一下当年奠定了大数据算法基础的风靡全球的Google三篇论文，也称为Google的三驾马车：Google FS[2003]、MapReduce[2004]、BigTable[2006]。三篇论文中文版链接这里提供给大家，闲来没事可以看一看。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;链接：https://pan.baidu.com/s/1EIhGR6gADm2BnEh5hW4KUA 
提取码：c1wb 
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;这三篇论文为何风靡全球呢？我们说随着大数据时代的到来，我们同样面临着大数据所带给我们的核心二问：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;1、海量数据如何存储？
2、海量数据如何计算？
3、海量结构化数据如何高效读写？
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;然而，而谷歌公司在2003年至2006年发布的三篇论文则为解决两个问题提供了思路。&lt;/p&gt;
&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;“ 我们设计并实现了 Google GFS 文件系统，一个面向大规模数据密集型应用的、可伸缩的分布式文件系统。&lt;br/&gt;GFS 虽然运行在廉价的普遍硬件设备上，但是它依然了提供灾难冗余的能力，为大量客户机提供了高性能的&lt;br/&gt;服务。&lt;br/&gt;...&lt;br/&gt;GFS 完全满足了我们对存储的需求。”&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Google GFS 文件系统超前的设计思想，为解决大数据时代海量数据的存储提出了解决思路，同时对今后的分布式系统设计都提供了宝贵的指导意义。而MapReduce框架则解决了大数据时代海量数据如何计算的问题，虽然现在的Spark很火，但吃水不能忘了挖井人。&lt;/p&gt;
&lt;p&gt;2006年，Google发布了第三篇重要论文。Bigtable 是一个分布式的结构化数据存储系统，它被设计用来处理海量数据：通常是分布在数千台普通服务器上的 PB 级的数据。Bigtable 的设计目的是可靠的处理 PB 级别的数据，并且能够部署到上千台机器上。用于解决Google内部海量结构化数据的存储以及高效读写问题。&lt;/p&gt;
&lt;p&gt;也正是因为这三篇论文的发表，才有了而后的HDFS、MapReduce 和 HBase，才有了2015大数据元年。下面我们详细看一下Hadoop 家族的编年史，这里你大概也可以看出HBase在Hadoop家族中的地位。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;*   2002年10月，Doug Cutting和Mike Cafarella创建了开源网页爬虫项目Nutch。

*   2003年10月，Google发表Google File System论文。

*   2004年7月，Doug Cutting和Mike Cafarella在Nutch中实现了类似GFS的功能，即后来HDFS的前身。

*   2004年10月，Google发表了MapReduce论文。

*   2005年2月，Mike Cafarella在Nutch中实现了MapReduce的最初版本。

*   2006年1月，Doug Cutting加入雅虎，Yahoo!提供一个专门的团队和资源将Hadoop发展成一个可在网络上运行的系统。

*   2006年2月，Apache Hadoop项目正式启动以支持MapReduce和HDFS的独立发展。

*   2006年3月，Yahoo!建设了第一个Hadoop集群用于开发。

*   2006年4月，第一个Apache Hadoop发布。

*   2006年11月，Google发表了Bigtable论文，这最终激发了HBase库的创建。

*   2007年10月，第一个可用的HBase发布了。

*   2008年1月，Hadoop成为Apache顶级项目。

*   2008年1月，HBase成为 Hadoop 的子项目。

*   2008年6月，Hadoop的第一个SQL框架——Hive成为了Hadoop的子项目。

*   2009年7月 ，MapReduce 和 HDFS成为Hadoop项目的独立子项目。

*   2009年7月 ，Avro 和 Chukwa 成为Hadoop新的子项目。

*   2009年10月，首届Hadoop World大会在纽约召开。

*   2010年5月 ，HBase脱离Hadoop项目，成为Apache顶级项目。

*   2010年9月，Hive 脱离Hadoop，成为Apache顶级项目。

*   2010年9月，Pig脱离Hadoop，成为Apache顶级项目。

*   2011年1月，ZooKeeper 脱离Hadoop，成为Apache顶级项目。

*   2012年8月，YARN成为Hadoop子项目。

*   2012年10月，第一个Hadoop原生MPP查询引擎Impala加入到了Hadoop生态圈。

*  2014年2月，Spark逐渐代替MapReduce成为Hadoop的缺省执行引擎，并成为Apache基金会顶级项目。

*   2015年10月，Cloudera公布继HBase以后的第一个Hadoop原生存储替代方案——Kudu。

*   2015年12月，Cloudera发起的Impala和Kudu项目加入Apache孵化器。
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;好了，一张图向大家道一声晚安吧，挺晚了，该睡了~ 下一章我们再追问“我是谁？”的灵魂思考吧~&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/1001353/202004/1001353-20200418083052927-144258929.png&quot; alt=&quot;我从哪里来？&quot;/&gt;&lt;/p&gt;
&lt;h3 id=&quot;参考文章&quot;&gt;参考文章&lt;/h3&gt;
&lt;p&gt;&lt;a href=&quot;https://blog.csdn.net/lfq1532632051/article/details/53219558&quot;&gt;https://blog.csdn.net/lfq1532632051/article/details/53219558&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/1001353/202004/1001353-20200418083104302-83676601.png&quot; alt=&quot;扫描二维码关注博主公众号&quot;/&gt;&lt;/p&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;转载请注明出处！欢迎关注本人微信公众号【HBase工作笔记】&lt;/p&gt;
&lt;/blockquote&gt;
</description>
<pubDate>Sat, 18 Apr 2020 00:31:00 +0000</pubDate>
<dc:creator>周蓬勃</dc:creator>
<og:description>前言： 说起HBase这门技术，在认知上对于稍微接触或使用过它的人来讲，可能只是百千数据库中一个很普通的库，大概就像我对Redis的认知一样：缓存嘛！可对于HBase，我确实是带着某些感情在的。今日突</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/zpb2016/p/12723939.html</dc:identifier>
</item>
<item>
<title>秒杀系统：如何打造并维护一个超大流量的秒杀系统？ - 北华老六</title>
<link>http://www.cnblogs.com/James-Harden/p/12723907.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/James-Harden/p/12723907.html</guid>
<description>&lt;p&gt;秒杀大家都不陌生。自2011年首次出现以来，无论是双十一购物还是 12306 抢票，秒杀场景已随处可见。简单来说，秒杀就是在同一时刻大量请求争抢购买同一商品并完成交易的过程。&lt;/p&gt;
&lt;p&gt;从架构视角来看，秒杀系统本质是一个高性能、高一致、高可用的三高系统。而打造并维护一个超大流量的秒杀系统需要进行哪些关注，就是本文讨论的话题。&lt;/p&gt;
&lt;h2&gt;&lt;strong&gt;整体思考&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;首先从高维度出发，整体思考问题。秒杀无外乎解决两个核心问题，一是并发读，一是并发写，对应到架构设计，就是高可用、一致性和高性能的要求。&lt;/p&gt;
&lt;p&gt;关于秒杀系统的设计思考，本文即基于此 3 层依次推进，简述如下：&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;strong&gt;高性能。&lt;/strong&gt;秒杀涉及高读和高写的支持，如何支撑高并发，如何抵抗高IOPS？核心优化理念其实是类似的：高读就尽量&quot;少读&quot;或&quot;读少&quot;，高写就数据拆分。本文将从动静分离、热点优化以及服务端性能优化 3 个方面展开&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;一致性。&lt;/strong&gt;秒杀的核心关注是商品库存，有限的商品在同一时间被多个请求同时扣减，而且要保证准确性，显而易见是一个难题。如何做到既不多又不少？本文将从业界通用的几种减库存方案切入，讨论一致性设计的核心逻辑&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;高可用。&lt;/strong&gt;大型分布式系统在实际运行过程中面对的工况是非常复杂的，业务流量的突增、依赖服务的不稳定、应用自身的瓶颈、物理资源的损坏等方方面面都会对系统的运行带来大大小小的的冲击。如何保障应用在复杂工况环境下还能高效稳定运行，如何预防和面对突发问题，系统设计时应该从哪些方面着手？本文将从架构落地的全景视角进行关注思考&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;h2&gt;&lt;strong&gt;高性能&lt;/strong&gt;&lt;/h2&gt;
&lt;h3&gt;&lt;strong&gt;1 动静分离&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;大家可能会注意到，秒杀过程中你是不需要刷新整个页面的，只有时间在不停跳动。这是因为一般都会对大流量的秒杀系统做系统的静态化改造，即数据意义上的动静分离。&lt;strong&gt;动静分离三步走：&lt;/strong&gt;&lt;strong&gt;1、数据拆分；&lt;/strong&gt;&lt;strong&gt;2、静态缓存；&lt;/strong&gt;&lt;strong&gt;3、数据整合。&lt;/strong&gt;&lt;/p&gt;
&lt;h4&gt;&lt;strong&gt;1.1 数据拆分&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;动静分离的首要目的是将动态页面改造成适合缓存的静态页面。因此第一步就是分离出动态数据，主要从以下 2 个方面进行：&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;strong&gt;用户。&lt;/strong&gt;用户身份信息包括登录状态以及登录画像等，相关要素可以单独拆分出来，通过动态请求进行获取；与之相关的广平推荐，如用户偏好、地域偏好等，同样可以通过异步方式进行加载&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;时间。&lt;/strong&gt;秒杀时间是由服务端统一管控的，可以通过动态请求进行获取&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;p&gt;这里你可以打开电商平台的一个秒杀页面，看看这个页面里都有哪些动静数据。&lt;/p&gt;
&lt;h4&gt;&lt;strong&gt;1.2 静态缓存&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;分离出动静态数据之后，第二步就是将静态数据进行合理的缓存，由此衍生出两个问题：1、怎么缓存；2、哪里缓存&lt;strong&gt;1.2.1 怎么缓存&lt;/strong&gt;静态化改造的一个特点是直接缓存整个 HTTP 连接而不是仅仅缓存静态数据，如此一来，Web 代理服务器根据请求 URL，可以直接取出对应的响应体然后直接返回，响应过程无需重组 HTTP 协议，也无需解析 HTTP 请求头。而作为缓存键，URL唯一化是必不可少的，只是对于商品系统，URL 天然是可以基于商品 ID 来进行唯一标识的，比如淘宝的&lt;code&gt;https://item.taobao.com/item.htm?id=xxxx &lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;1.2.2 哪里缓存&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;静态数据缓存到哪里呢？可以有三种方式：1、浏览器；2、CDN ；3、服务端。浏览器当然是第一选择，但用户的浏览器是不可控的，主要体现在如果用户不主动刷新，系统很难主动地把消息推送给用户（注意，当讨论静态数据时，潜台词是 “相对不变”，言外之意是 “可能会变”），如此可能会导致用户端在很长一段时间内看到的信息都是错误的。对于秒杀系统，保证缓存可以在秒级时间内失效是不可或缺的。服务端主要进行动态逻辑计算及加载，本身并不擅长处理大量连接，每个连接消耗内存较多，同时 Servlet 容器解析 HTTP 较慢，容易侵占逻辑计算资源；另外，静态数据下沉至此也会拉长请求路径。因此通常将静态数据缓存在 CDN，其本身更擅长处理大并发的静态文件请求，既可以做到主动失效，又离用户尽可能近，同时规避 Java 语言层面的弱点。需要注意的是，上 CDN 有以下几个问题需要解决：&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;strong&gt;失效问题。&lt;/strong&gt;任何一个缓存都应该是有时效的，尤其对于一个秒杀场景。所以，系统需要保证全国各地的 CDN 在秒级时间内失效掉缓存信息，这实际对 CDN 的失效系统要求是很高的&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;命中率问题。&lt;/strong&gt;高命中是缓存系统最为核心的性能要求，不然缓存就失去了意义。如果将数据放到全国各地的 CDN ，势必会导致请求命中同一个缓存的可能性降低，那么命中率就成为一个问题&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;p&gt;因此，将数据放到全国所有的 CDN 节点是不太现实的，失效问题、命中率问题都会面临比较大的挑战。更为可行的做法是选择若干 CDN 节点进行静态化改造，节点的选取通常需要满足以下几个条件：&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;临近访问量集中的地区&lt;/li&gt;
&lt;li&gt;距离主站较远的地区&lt;/li&gt;
&lt;li&gt;节点与主站间网络质量良好的地区&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;p&gt;基于以上因素，选择 CDN 的二级缓存比较合适，因为二级缓存数量偏少，容量也更大，访问量相对集中，这样就可以较好解决缓存的失效问题以及命中率问题，是当前比较理想的一种 CDN 化方案。部署方式如下图所示：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1985803/202004/1985803-20200418081230726-1893050646.png&quot; alt=&quot;&quot; width=&quot;627&quot; height=&quot;505&quot;/&gt;&lt;/p&gt;
&lt;h4&gt;&lt;strong&gt;1.3 数据整合&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;分离出动静态数据之后，前端如何组织数据页就是一个新的问题，主要在于动态数据的加载处理，通常有两种方案：ESI（Edge Side Includes）方案和 CSI（Client Side Include）方案。&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;strong&gt;ESI 方案：&lt;/strong&gt;Web 代理服务器上请求动态数据，并将动态数据插入到静态页面中，用户看到页面时已经是一个完整的页面。这种方式对服务端性能要求高，但用户体验较好&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;CSI 方案：&lt;/strong&gt;Web 代理服务器上只返回静态页面，前端单独发起一个异步 JS 请求动态数据。这种方式对服务端性能友好，但用户体验稍差&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;h4&gt;&lt;strong&gt;1.4 小结&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;动静分离对于性能的提升，抽象起来只有两点，一是数据要尽量少，以便减少没必要的请求，二是路径要尽量短，以便提高单次请求的效率。具体方法其实就是基于这个大方向进行的。&lt;/p&gt;
&lt;h3&gt;&lt;strong&gt;2 热点优化&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;热点分为热点操作和热点数据，以下分开进行讨论。&lt;/p&gt;
&lt;h4&gt;&lt;strong&gt;2.1 热点操作&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;零点刷新、零点下单、零点添加购物车等都属于热点操作。热点操作是用户的行为，不好改变，但可以做一些限制保护，比如用户频繁刷新页面时进行提示阻断。&lt;/p&gt;
&lt;h4&gt;&lt;strong&gt;2.2 热点数据&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;热点数据的处理三步走，一是热点识别，二是热点隔离，三是热点优化。&lt;strong&gt;2.2.1 热点识别&lt;/strong&gt;热点数据分为静态热点和动态热点，具体如下：&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;strong&gt;静态热点：&lt;/strong&gt;能够提前预测的热点数据。大促前夕，可以根据大促的行业特点、活动商家等纬度信息分析出热点商品，或者通过卖家报名的方式提前筛选；另外，还可以通过技术手段提前预测，例如对买家每天访问的商品进行大数据计算，然后统计出 TOP N 的商品，即可视为热点商品&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;动态热点：&lt;/strong&gt;无法提前预测的热点数据。冷热数据往往是随实际业务场景发生交替变化的，尤其是如今直播卖货模式的兴起——带货商临时做一个广告，就有可能导致一件商品在短时间内被大量购买。由于此类商品日常访问较少，即使在缓存系统中一段时间后也会被逐出或过期掉，甚至在db中也是冷数据。瞬时流量的涌入，往往导致缓存被击穿，请求直接到达DB，引发DB压力过大&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;p&gt;因此秒杀系统需要实现热点数据的动态发现能力，一个常见的实现思路是：&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;异步采集交易链路各个环节的热点 Key 信息，如 Nginx采集访问URL或 Agent 采集热点日志（一些中间件本身已具备热点发现能力），提前识别潜在的热点数据&lt;/li&gt;
&lt;li&gt;聚合分析热点数据，达到一定规则的热点数据，通过订阅分发推送到链路系统，各系统根据自身需求决定如何处理热点数据，或限流或缓存，从而实现热点保护&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;p&gt;需要注意的是：&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;strong&gt;热点数据采集最好采用异步方式&lt;/strong&gt;，一方面不会影响业务的核心交易链路，一方面可以保证采集方式的通用性&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;热点发现最好做到秒级实时&lt;/strong&gt;，这样动态发现才有意义，实际上也是对核心节点的数据采集和分析能力提出了较高的要求&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;2.2.2 热点隔离&lt;/strong&gt;热点数据识别出来之后，第一原则就是将热点数据隔离出来，不要让 1% 影响到另外的 99%，可以基于以下几个层次实现热点隔离：&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;strong&gt;业务隔离。&lt;/strong&gt;秒杀作为一种营销活动，卖家需要单独报名，从技术上来说，系统可以提前对已知热点做缓存预热&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;系统隔离。&lt;/strong&gt;系统隔离是运行时隔离，通过分组部署和另外 99% 进行分离，另外秒杀也可以申请单独的域名，入口层就让请求落到不同的集群中&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;数据隔离。&lt;/strong&gt;秒杀数据作为热点数据，可以启用单独的缓存集群或者DB服务组，从而更好的实现横向或纵向能力扩展&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;p&gt;当然，实现隔离还有很多种办法。比如，可以按照用户来区分，为不同的用户分配不同的 Cookie，入口层路由到不同的服务接口中；再比如，域名保持一致，但后端调用不同的服务接口；又或者在数据层给数据打标进行区分等等，这些措施的目的都是把已经识别的热点请求和普通请求区分开来。&lt;strong&gt;2.2.3 热点优化&lt;/strong&gt;热点数据隔离之后，也就方便对这 1% 的请求做针对性的优化，方式无外乎两种：&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;缓存：热点缓存是最为有效的办法。如果热点数据做了动静分离，那么可以长期缓存静态数据&lt;/li&gt;
&lt;li&gt;限流：流量限制更多是一种保护机制。需要注意的是，各服务要时刻关注请求是否触发限流并及时进行review&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;2.2.4 小结&lt;/strong&gt;数据的热点优化与动静分离是不一样的，热点优化是基于二八原则对数据进行了纵向拆分，以便进行针对性地处理。热点识别和隔离不仅对“秒杀”这个场景有意义，对其他的高性能分布式系统也非常有参考价值。&lt;/p&gt;
&lt;h3&gt;&lt;strong&gt;3 系统优化&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;对于一个软件系统，提高性能可以有很多种手段，如提升硬件水平、调优JVM 性能，这里主要关注代码层面的性能优化：&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;strong&gt;减少序列化：&lt;/strong&gt;减少 Java 中的序列化操作可以很好的提升系统性能。序列化大部分是在 RPC 阶段发生，因此应该尽量减少 RPC 调用，一种可行的方案是将多个关联性较强的应用进行 “合并部署”，从而减少不同应用之间的 RPC 调用（微服务设计规范）&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;直接输出流数据：&lt;/strong&gt;只要涉及字符串的I/O操作，无论是磁盘 I/O 还是网络 I/O，都比较耗费 CPU 资源，因为字符需要转换成字节，而这个转换又必须查表编码。所以对于常用数据，比如静态字符串，推荐提前编码成字节并缓存，具体到代码层面就是通过 OutputStream() 类函数从而减少数据的编码转换；另外，热点方法toString()不要直接调用ReflectionToString实现，推荐直接硬编码，并且只打印DO的基础要素和核心要素&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;裁剪日志异常堆栈：&lt;/strong&gt;无论是外部系统异常还是应用本身异常，都会有堆栈打出，超大流量下，频繁的输出完整堆栈，只会加剧系统当前负载。可以通过日志配置文件控制异常堆栈输出的深度&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;去组件框架：&lt;/strong&gt;极致优化要求下，可以去掉一些组件框架，比如去掉传统的 MVC 框架，直接使用 Servlet 处理请求。这样可以绕过一大堆复杂且用处不大的处理逻辑，节省毫秒级的时间，当然，需要合理评估你对框架的依赖程度&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;h3&gt;&lt;strong&gt;4 总结一下&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;性能优化需要一个基准值，所以系统还需要做好应用基线，比如性能基线（何时性能突然下降）、成本基线（去年大促用了多少机器）、链路基线（核心流程发生了哪些变化），通过基线持续关注系统性能，促使系统在代码层面持续提升编码质量、业务层面及时下掉不合理调用、架构层面不断优化改进。&lt;/p&gt;
&lt;h2&gt;&lt;strong&gt;一致性&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;秒杀系统中，库存是个关键数据，卖不出去是个问题，超卖更是个问题。秒杀场景下的一致性问题，主要就是库存扣减的准确性问题。&lt;/p&gt;
&lt;h3&gt;&lt;strong&gt;1 减库存的方式&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;电商场景下的购买过程一般分为两步：下单和付款。“提交订单”即为下单，“支付订单”即为付款。基于此设定，减库存一般有以下几个方式：&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;strong&gt;下单减库存。&lt;/strong&gt;买家下单后，扣减商品库存。下单减库存是最简单的减库存方式，也是控制最为精确的一种&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;付款减库存。&lt;/strong&gt;买家下单后，并不立即扣减库存，而是等到付款后才真正扣减库存。但因为付款时才减库存，如果并发比较高，可能出现买家下单后付不了款的情况，因为商品已经被其他人买走了&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;预扣库存。&lt;/strong&gt;这种方式相对复杂一些，买家下单后，库存为其保留一定的时间（如 15 分钟），超过这段时间，库存自动释放，释放后其他买家可以购买&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;p&gt;能够看到，减库存方式是基于购物过程的多阶段进行划分的，但无论是在下单阶段还是付款阶段，都会存在一些问题，下面进行具体分析。&lt;/p&gt;
&lt;h3&gt;&lt;strong&gt;2 减库存的问题&lt;/strong&gt;&lt;/h3&gt;
&lt;h4&gt;&lt;strong&gt;2.1 下单减库存&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;优势：&lt;/strong&gt;用户体验最好。下单减库存是最简单的减库存方式，也是控制最精确的一种。下单时可以直接通过数据库事务机制控制商品库存，所以一定不会出现已下单却付不了款的情况。&lt;strong&gt;劣势：&lt;/strong&gt;可能卖不出去。正常情况下，买家下单后付款概率很高，所以不会有太大问题。但有一种场景例外，就是当卖家参加某个促销活动时，竞争对手通过恶意下单的方式将该商品全部下单，导致库存清零，那么这就不能正常售卖了——要知道，恶意下单的人是不会真正付款的，这正是 “下单减库存” 的不足之处。&lt;/p&gt;
&lt;h4&gt;&lt;strong&gt;2.2 付款减库存&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;优势：&lt;/strong&gt;一定实际售卖。“下单减库存” 可能导致恶意下单，从而影响卖家的商品销售， “付款减库存” 由于需要付出真金白银，可以有效避免。&lt;strong&gt;劣势：&lt;/strong&gt;用户体验较差。用户下单后，不一定会实际付款，假设有 100 件商品，就可能出现 200 人下单成功的情况，因为下单时不会减库存，所以也就可能出现下单成功数远远超过真正库存数的情况，这尤其会发生在大促的热门商品上。如此一来就会导致很多买家下单成功后却付不了款，购物体验自然是比较差的。&lt;/p&gt;
&lt;h4&gt;&lt;strong&gt;2.3 预扣库存&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;优势：&lt;/strong&gt;缓解了以上两种方式的问题。预扣库存实际就是“下单减库存”和 “付款减库存”两种方式的结合，将两次操作进行了前后关联，下单时预扣库存，付款时释放库存。&lt;strong&gt;劣势：&lt;/strong&gt;并没有彻底解决以上问题。比如针对恶意下单的场景，虽然可以把有效付款时间设置为 10 分钟，但恶意买家完全可以在 10 分钟之后再次下单。&lt;/p&gt;
&lt;h4&gt;&lt;strong&gt;2.4 小结&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;减库存的问题主要体现在用户体验和商业诉求两方面，其本质原因在于购物过程存在两步甚至多步操作，在不同阶段减库存，容易存在被恶意利用的漏洞。&lt;/p&gt;
&lt;h3&gt;&lt;strong&gt;3 实际如何减库存&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;业界最为常见的是预扣库存。无论是外卖点餐还是电商购物，下单后一般都有个 “有效付款时间”，超过该时间订单自动释放，这就是典型的预扣库存方案。但如上所述，&lt;strong&gt;预扣库存还需要解决恶意下单的问题，保证商品卖的出去；&lt;/strong&gt;&lt;strong&gt;另一方面，如何避免超卖，也是一个痛点。&lt;/strong&gt;&lt;strong&gt;卖的出去：&lt;/strong&gt;恶意下单的解决方案主要还是结合安全和反作弊措施来制止。比如，识别频繁下单不付款的买家并进行打标，这样可以在打标买家下单时不减库存；再比如为大促商品设置单人最大购买件数，一人最多只能买 N 件商品；又或者对重复下单不付款的行为进行次数限制阻断等&lt;strong&gt;避免超卖：&lt;/strong&gt;库存超卖的情况实际分为两种。对于普通商品，秒杀只是一种大促手段，即使库存超卖，商家也可以通过补货来解决；而对于一些商品，秒杀作为一种营销手段，完全不允许库存为负，也就是在数据一致性上，需要保证大并发请求时数据库中的库存字段值不能为负，一般有多种方案：一是在通过事务来判断，即保证减后库存不能为负，否则就回滚；二是直接设置数据库字段类型为无符号整数，这样一旦库存为负就会在执行 SQL 时报错；三是使用 CASE WHEN 判断语句:&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;32&quot;&gt;
&lt;pre&gt;
&lt;span&gt;UPDATE&lt;/span&gt; item &lt;span&gt;SET&lt;/span&gt; inventory &lt;span&gt;=&lt;/span&gt; &lt;span&gt;CASE&lt;/span&gt; &lt;span&gt;WHEN&lt;/span&gt; inventory &lt;span&gt;&amp;gt;=&lt;/span&gt; xxx &lt;span&gt;THEN&lt;/span&gt; inventory&lt;span&gt;-&lt;/span&gt;xxx &lt;span&gt;ELSE&lt;/span&gt; inventory &lt;span&gt;END&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;业务手段保证商品卖的出去，技术手段保证商品不会超卖，库存问题从来就不是简单的技术难题，解决问题的视角是多种多样的。&lt;/p&gt;
&lt;h3&gt;&lt;strong&gt;4 一致性性能的优化&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;库存是个关键数据，更是个热点数据。对系统来说，热点的实际影响就是 “高读” 和 “高写”，也是秒杀场景下最为核心的一个技术难题。&lt;/p&gt;
&lt;h4&gt;&lt;strong&gt;4.1 高并发读&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;秒杀场景解决高并发读问题，关键词是“分层校验”。即在读链路时，只进行不影响性能的检查操作，如用户是否具有秒杀资格、商品状态是否正常、用户答题是否正确、秒杀是否已经结束、是否非法请求等，而不做一致性校验等容易引发瓶颈的检查操作；直到写链路时，才对库存做一致性检查，在数据层保证最终准确性。因此，在分层校验设定下，系统可以采用分布式缓存甚至LocalCache来抵抗高并发读。即允许读场景下一定的脏数据，这样只会导致少量原本无库存的下单请求被误认为是有库存的，等到真正写数据时再保证最终一致性，由此做到高可用和一致性之间的平衡。实际上，分层校验的核心思想是：&lt;strong&gt;不同层次尽可能过滤掉无效请求，只在“漏斗” 最末端进行有效处理，从而缩短系统瓶颈的影响路径。&lt;/strong&gt;&lt;/p&gt;
&lt;h4&gt;&lt;strong&gt;4.2 高并发写&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;高并发写的优化方式，&lt;strong&gt;一种是更换DB选型，一种是优化DB性能&lt;/strong&gt;，以下分别进行讨论。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;4.2.1 更换DB选型&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;秒杀商品和普通商品的减库存是有差异的，核心区别在数据量级小、交易时间短，因此能否把秒杀减库存直接放到缓存系统中实现呢，也就是直接在一个带有持久化功能的缓存中进行减库存操作，比如 Redis？如果减库存逻辑非常单一的话，比如没有复杂的 SKU 库存和总库存这种联动关系的话，个人认为是完全可以的。但如果有比较复杂的减库存逻辑，或者需要使用到事务，那就必须在数据库中完成减库存操作。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;4.2.2 优化DB&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;性能&lt;/strong&gt;库存数据落地到数据库实现其实是一行存储（MySQL），因此会有大量线程来竞争 InnoDB 行锁。但并发越高，等待线程就会越多，TPS 下降，RT 上升，吞吐量会受到严重影响——注意，这里假设数据库已基于上文【性能优化】完成数据隔离，以便于讨论聚焦 。解决并发锁的问题，有两种办法：&lt;em&gt;&lt;strong&gt;1、应用层排队。&lt;/strong&gt;&lt;/em&gt;通过缓存加入集群分布式锁，从而控制集群对数据库同一行记录进行操作的并发度，同时也能控制单个商品占用数据库连接的数量，防止热点商品占用过多的数据库连接&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;2、数据层排队。&lt;/strong&gt;&lt;/em&gt;应用层排队是有损性能的，数据层排队是最为理想的。业界中，阿里的数据库团队开发了针对InnoDB 层上的补丁程序（patch），可以基于DB层对单行记录做并发排队，从而实现秒杀场景下的定制优化——&lt;strong&gt;注意，排队和锁竞争是有区别的，如果熟悉 MySQL 的话，就会知道 InnoDB 内部的死锁检测，以及 MySQL Server 和 InnoDB 的切换都是比较消耗性能的。&lt;/strong&gt;另外阿里的数据库团队还做了很多其他方面的优化，如 &lt;code&gt;COMMIT_ON_SUCCESS&lt;/code&gt; 和 &lt;code&gt;ROLLBACK_ON_FAIL&lt;/code&gt;的补丁程序，通过在 SQL 里加入提示（hint），实现事务不需要等待实时提交，而是在数据执行完最后一条 SQL 后，直接根据 &lt;code&gt;TARGET_AFFECT_ROW&lt;/code&gt;的结果进行提交或回滚，减少网络等待的时间（毫秒级）。目前阿里已将包含这些补丁程序的 MySQL 开源：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;32&quot;&gt;
&lt;pre&gt;
https://github.com/alibaba/AliSQL?spm=a2c4e.10696291.0.0.34ba19a415ghm4
&lt;/pre&gt;&lt;/div&gt;

&lt;h4&gt;&lt;strong&gt;4.3 小结&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;高读和高写的两种处理方式大相径庭。读请求的优化空间要大一些，而写请求的瓶颈一般都在存储层，优化思路的本质还是基于 CAP 理论做平衡。&lt;/p&gt;
&lt;h3&gt;&lt;strong&gt;5 总结一下&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;当然，减库存还有很多细节问题，例如预扣的库存超时后如何进行回补，再比如第三方支付如何保证减库存和付款时的状态一致性，这些也是很大的挑战。&lt;/p&gt;
&lt;h2&gt;&lt;strong&gt;高可用&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;盯过秒杀流量监控的话，会发现它不是一条蜿蜒而起的曲线，而是一条挺拔的直线，这是因为秒杀请求高度集中于某一特定的时间点。这样一来就会造成一个特别高的零点峰值，而对资源的消耗也几乎是瞬时的。所以秒杀系统的可用性保护是不可或缺的。&lt;/p&gt;
&lt;h3&gt;&lt;strong&gt;1 流量削峰&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;对于秒杀的目标场景，最终能够抢到商品的人数是固定的，无论 100 人和 10000 人参加结果都是一样的，即有效请求额度是有限的。并发度越高，无效请求也就越多。但秒杀作为一种商业营销手段，活动开始之前是希望有更多的人来刷页面，只是真正开始后，秒杀请求不是越多越好。因此系统可以设计一些规则，人为的延缓秒杀请求，甚至可以过滤掉一些无效请求。&lt;/p&gt;
&lt;h4&gt;&lt;strong&gt;1.1 答题&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;早期秒杀只是简单的点击秒杀按钮，后来才增加了答题。为什么要增加答题呢？主要是通过提升购买的复杂度，达到两个目的：&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;strong&gt;防止作弊。&lt;/strong&gt;早期秒杀器比较猖獗，存在恶意买家或竞争对手使用秒杀器扫货的情况，商家没有达到营销的目的，所以增加答题来进行限制&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;延缓请求。&lt;/strong&gt;零点流量的起效时间是毫秒级的，答题可以人为拉长峰值下单的时长，由之前的 &amp;lt;1s 延长到 &amp;lt;10s。这个时间对于服务端非常重要，会大大减轻高峰期并发压力；另外，由于请求具有先后顺序，答题后置的请求到来时可能已经没有库存了，因此根本无法下单，此阶段落到数据层真正的写也就非常有限了&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;p&gt;需要注意的是，答题除了做正确性验证，还需要对提交时间做验证，比如&amp;lt;1s 人为操作的可能性就很小，可以进一步防止机器答题的情况。答题目前已经使用的非常普遍了，本质是通过在入口层削减流量，从而让系统更好地支撑瞬时峰值。&lt;/p&gt;
&lt;h4&gt;&lt;strong&gt;1.2 排队&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;最为常见的削峰方案是使用消息队列，通过把同步的直接调用转换成异步的间接推送缓冲瞬时流量。除了消息队列，类似的排队方案还有很多，例如：&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;线程池加锁等待&lt;/li&gt;
&lt;li&gt;本地内存蓄洪等待&lt;/li&gt;
&lt;li&gt;本地文件序列化写，再顺序读&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;p&gt;排队方式的弊端也是显而易见的，主要有两点：&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;strong&gt;请求积压。&lt;/strong&gt;流量高峰如果长时间持续，达到了队列的水位上限，队列同样会被压垮，这样虽然保护了下游系统，但是和请求直接丢弃也没多大区别&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;用户体验。&lt;/strong&gt;异步推送的实时性和有序性自然是比不上同步调用的，由此可能出现请求先发后至的情况，影响部分敏感用户的购物体验&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;p&gt;排队本质是在业务层将一步操作转变成两步操作，从而起到缓冲的作用，但鉴于此种方式的弊端，最终还是要基于业务量级和秒杀场景做出妥协和平衡。&lt;/p&gt;
&lt;h4&gt;&lt;strong&gt;1.3 过滤&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;过滤的核心结构在于分层，通过在不同层次过滤掉无效请求，达到数据读写的精准触发。常见的过滤主要有以下几层：&lt;/p&gt;
&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;&lt;strong&gt;1、读限流：&lt;/strong&gt;对读请求做限流保护，将超出系统承载能力的请求过滤掉&lt;br/&gt;&lt;strong&gt;2、读缓存：&lt;/strong&gt;对读请求做数据缓存，将重复的请求过滤掉&lt;br/&gt;&lt;strong&gt;3、写限流：&lt;/strong&gt;对写请求做限流保护，将超出系统承载能力的请求过滤掉&lt;br/&gt;&lt;strong&gt;4、写校验：&lt;/strong&gt;对写请求做一致性校验，只保留最终的有效数据&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;过滤的核心目的是通过减少无效请求的数据IO保障有效请求的IO性能。&lt;/p&gt;
&lt;h4&gt;&lt;strong&gt;1.4 小结&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;系统可以通过入口层的答题、业务层的排队、数据层的过滤达到流量削峰的目的，本质是在寻求商业诉求与架构性能之间的平衡。另外，新的削峰手段也层出不穷，以业务切入居多，比如零点大促时同步发放优惠券或发起抽奖活动，将一部分流量分散到其他系统，这样也能起到削峰的作用。&lt;/p&gt;
&lt;h3&gt;&lt;strong&gt;2 Plan B&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;当一个系统面临持续的高峰流量时，其实是很难单靠自身调整来恢复状态的，日常运维没有人能够预估所有情况，意外总是无法避免。尤其在秒杀这一场景下，为了保证系统的高可用，必须设计一个 Plan B 方案来进行兜底。高可用建设，其实是一个系统工程，贯穿在系统建设的整个生命周期。&lt;/p&gt;
&lt;p&gt; &lt;img src=&quot;https://img2020.cnblogs.com/blog/1985803/202004/1985803-20200418081733991-805609518.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;具体来说，系统的高可用建设涉及架构阶段、编码阶段、测试阶段、发布阶段、运行阶段，以及故障发生时，逐一进行分析：&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;strong&gt;架构阶段：&lt;/strong&gt;考虑系统的可扩展性和容错性，避免出现单点问题。例如多地单元化部署，即使某个IDC甚至地市出现故障，仍不会影响系统运转&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;编码阶段：&lt;/strong&gt;保证代码的健壮性，例如RPC调用时，设置合理的超时退出机制，防止被其他系统拖垮，同时也要对无法预料的返回错误进行默认的处理&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;测试阶段：&lt;/strong&gt;保证CI的覆盖度以及Sonar的容错率，对基础质量进行二次校验，并定期产出整体质量的趋势报告&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;发布阶段：&lt;/strong&gt;系统部署最容易暴露错误，因此要有前置的checklist模版、中置的上下游周知机制以及后置的回滚机制&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;运行阶段：&lt;/strong&gt;系统多数时间处于运行态，最重要的是运行时的实时监控，及时发现问题、准确报警并能提供详细数据，以便排查问题&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;故障发生：&lt;/strong&gt;首要目标是及时止损，防止影响面扩大，然后定位原因、解决问题，最后恢复服务&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;p&gt;对于日常运维而言，高可用更多是针对运行阶段而言的，此阶段需要额外进行加强建设，主要有以下几种手段：&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;strong&gt;预防：&lt;/strong&gt;建立常态压测体系，定期对服务进行单点压测以及全链路压测，摸排水位&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;管控：&lt;/strong&gt;做好线上运行的降级、限流和熔断保护。需要注意的是，无论是限流、降级还是熔断，对业务都是有损的，所以在进行操作前，一定要和上下游业务确认好再进行。就拿限流来说，哪些业务可以限、什么情况下限、限流时间多长、什么情况下进行恢复，都要和业务方反复确认&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;监控：&lt;/strong&gt;建立性能基线，记录性能的变化趋势；建立报警体系，发现问题及时预警&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;恢复：&lt;/strong&gt;遇到故障能够及时止损，并提供快速的数据订正工具，不一定要好，但一定要有&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;p&gt;在系统建设的整个生命周期中，每个环节中都可能犯错，甚至有些环节犯的错，后面是无法弥补的或者成本极高的。所以高可用是一个系统工程，必须放到整个生命周期中进行全面考虑。同时，考虑到服务的增长性，高可用更需要长期规划并进行体系化建设。&lt;/p&gt;
&lt;h3&gt;&lt;strong&gt;3 总结一下&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;高可用其实是在说 “稳定性”，稳定性是一个平时不重要，但出了问题就要命的事情，然而它的落地又是一个问题——平时业务发展良好，稳定性建设就会降级给业务让路。解决这个问题必须在组织上有所保障，比如让业务负责人背上稳定性绩效指标，同时在部门中建立稳定性建设小组，小组成员由每条线的核心力量兼任，绩效由稳定性负责人来打分，这样就可以把体系化的建设任务落实到具体的业务系统中了。&lt;/p&gt;
&lt;h2&gt;&lt;strong&gt;作者总结（我不是作者）&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;一个秒杀系统的设计，可以根据不同级别的流量，由简单到复杂打造出不同的架构，本质是各方面的取舍和权衡。当然，你可能注意到，本文并没有涉及具体的选型方案，因为这些对于架构来说并不重要，作为架构师，应该时刻提醒自己主线是什么。同时也在这里抽象、提炼一下，主要是个人对于秒杀设计的提纲式整理，方便各位同学进行参考!&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1985803/202004/1985803-20200418081839577-113024587.jpg&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
</description>
<pubDate>Sat, 18 Apr 2020 00:20:00 +0000</pubDate>
<dc:creator>北华老六</dc:creator>
<og:description>秒杀大家都不陌生。自2011年首次出现以来，无论是双十一购物还是 12306 抢票，秒杀场景已随处可见。简单来说，秒杀就是在同一时刻大量请求争抢购买同一商品并完成交易的过程。 从架构视角来看，秒杀系统</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/James-Harden/p/12723907.html</dc:identifier>
</item>
<item>
<title>[编译] 7、在Linux下搭建安卓APP的开发烧写环境（makefile版-gradle版）—— 在Linux上用命令行+VIM开发安卓APP - beautifulzzzz</title>
<link>http://www.cnblogs.com/zjutlitao/p/12723855.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/zjutlitao/p/12723855.html</guid>
<description>&lt;p&gt;April 18, 2020 6:54 AM - BEAUTIFULZZZZ&lt;/p&gt;


&lt;br/&gt;.
&lt;h3 id=&quot;0-前言&quot;&gt;0 前言&lt;/h3&gt;
&lt;p&gt;在上上篇《&lt;a href=&quot;https://www.cnblogs.com/zjutlitao/p/9672376.html&quot;&gt;[编译] 5、在Linux下搭建安卓APP的开发烧写环境（makefile版）—— 在Linux上用命令行+VIM开发安卓APP&lt;/a&gt;》中我写了一个基于VIM（记事本）开发安卓APP的介绍，并且用类似的方法开源了很多小DEMO：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;[01] HelloAndroid: hello world demo&lt;/li&gt;
&lt;li&gt;[02] BluetoorhScan: bluetooth scan + surface(canvas) + handler + bundle&lt;/li&gt;
&lt;li&gt;[03] FlyGame: surface(canvas) + fly game demo&lt;/li&gt;
&lt;li&gt;[04] ListView: ListView DIY demo&lt;/li&gt;
&lt;li&gt;[05] GridView: GridView DIY demo&lt;/li&gt;
&lt;li&gt;[06] TuyaMeshTest: ble scan(fast scan) + textview&lt;/li&gt;
&lt;li&gt;[07] SmartStepCounter: bluetooth scan connect read + line chart&lt;/li&gt;
&lt;li&gt;[08] SmartFan: bluetooth scan connect write&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;GitHub：&lt;a href=&quot;https://github.com/nbtool/android_app_linux_tool&quot;&gt;https://github.com/nbtool/android_app_linux_tool&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;但是随着工程越来越复杂，采用java、aapt去操作使全自动run.sh脚本越来越难写（特别是有些lib库很难找准，有些lib除了库之外还有资源文件，就更复杂了），因此，这里引入一个更先进的工具：gradle。&lt;/p&gt;
&lt;p&gt;本文主要介绍gradle的安装、命令行的用法、给出一个基于gradle的全自动脚本run.sh，以及一个小DEMO（这里的全自动是：全自动构建安卓开发环境，全自动编译安装运行到设备）&lt;/p&gt;
&lt;hr/&gt;&lt;h3 id=&quot;1-gradle-安装配置&quot;&gt;1 gradle 安装配置&lt;/h3&gt;
&lt;h4 id=&quot;11-卸载系统默认装的gradle&quot;&gt;1.1 卸载系统默认装的gradle&lt;/h4&gt;
&lt;pre&gt;
&lt;code&gt;sudo pacman -R gradle
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;.&lt;/p&gt;
&lt;h4 id=&quot;12-下载对应版本的二进制文件&quot;&gt;1.2 下载对应版本的二进制文件&lt;/h4&gt;
&lt;p&gt;gradle所有版本的下载地址：&lt;a href=&quot;https://gradle.org/releases/&quot;&gt;https://gradle.org/releases/&lt;/a&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-shell&quot;&gt;➜  Downloads wget https://downloads.gradle-dn.com/distributions/gradle-2.14.1-bin.zip
➜  Downloads unzip gradle-2.14.1-bin.zip
➜  Downloads cd gradle-2.14.1 
➜  gradle-2.14.1 pwd
/home/btfz/Downloads/gradle-2.14.1
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;.&lt;/p&gt;
&lt;h4 id=&quot;13-配置gradle：&quot;&gt;1.3 配置gradle：&lt;/h4&gt;
&lt;p&gt;注：看文件夹下的getting-started.html文件&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-shell&quot;&gt;export GRADLE_HOME=/home/btfz/Downloads/gradle-2.14.1
export PATH=$PATH:$GRADLE_HOME/bin
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;.&lt;/p&gt;
&lt;h4 id=&quot;14-检查配置&quot;&gt;1.4 检查配置&lt;/h4&gt;
&lt;p&gt;在工程根目录的 SDK Location 配置文件&lt;code&gt;local.properties&lt;/code&gt;中：&lt;br/&gt;将&lt;code&gt;sdk.dir=D\:\\develop\\AndroidSDK&lt;/code&gt;改为自己系统正确的样子：&lt;code&gt;sdk.dir=/home/btfz/Android/Sdk&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;在工程根目录的 Project 配置文件&lt;code&gt;build.gradle&lt;/code&gt;中：（暂不需要修改）&lt;/p&gt;
&lt;p&gt;在工程根目录向里进一层的目录的 Module 配置文件&lt;code&gt;build.gradle&lt;/code&gt;中：&lt;br/&gt;将诸如SDK和编译工具的版本写成对应的版本：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;android {
    compileSdkVersion 28
    buildToolsVersion &quot;28.0.3&quot;
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;对应关系如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://tuchuang.beautifulzzzz.com:3000/?path=/07/496fcbf0468c895e1305074e290893.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;.&lt;/p&gt;
&lt;h4 id=&quot;15-gradle-命令行操作&quot;&gt;1.5 gradle 命令行操作&lt;/h4&gt;
&lt;p&gt;&lt;code&gt;gradle -v&lt;/code&gt; 查看当前gradle版本&lt;br/&gt;&lt;code&gt;gradle clean&lt;/code&gt; 将会去下载gradle的一些依赖包&lt;br/&gt;&lt;code&gt;gradle build&lt;/code&gt; 编译生成apk&lt;/p&gt;
&lt;p&gt;注：有时候直接用build打包会报错，因为要配置一些打包相关的东西，如果调试用，可以先用：&lt;code&gt;gradle assembleDebug&lt;/code&gt; 编译并打Debug包，不要用&lt;code&gt;gradle assembleRelease&lt;/code&gt; 编译并打Release的包（后续会写为什么用build和打release不行）。&lt;/p&gt;
&lt;hr/&gt;&lt;h3 id=&quot;2-全自动脚本编写&quot;&gt;2 全自动脚本编写&lt;/h3&gt;
&lt;h4 id=&quot;21-自动构建安卓开发环境&quot;&gt;2.1 自动构建安卓开发环境&lt;/h4&gt;
&lt;p&gt;判断是否有android SDK，如果没有，则下载一个android SDK；&lt;br/&gt;下载好android SDK后，可以利用其中的SDKMANAGER工具，安装platforms和build-tools（这两个有很多个版本，找到适合自己的）；&lt;br/&gt;判断对应版本的gradle是否存在，如果不存在，则从远端下载对应版本；&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;function tool(){
    #export JAVA_OPTS='-XX:+IgnoreUnrecognizedVMOptions --add-modules java.se.ee'

    if [ ! -d $ANDROID_SDK_PATH ]; then 
        #download tool
        echo &quot;&amp;gt; download tool....&quot;
        wget https://dl.google.com/android/repository/sdk-tools-linux-3859397.zip
        mkdir -p $ANDROID_SDK_PATH
        unzip sdk-tools-linux-3859397.zip -d $ANDROID_SDK_PATH
        rm -rf sdk-tools-linux-3859397.zip
        sudo chmod 777 -R $ANDROID_SDK_PATH
    fi

    #install sdk build-tools platform
    echo &quot;&amp;gt; install sdk build-tools platform....&quot;
    echo $SDKMANAGER
    $SDKMANAGER &quot;platform-tools&quot; &quot;platforms;android-$ANDROID_PLATFORM_VERSION&quot;
    $SDKMANAGER &quot;platform-tools&quot; &quot;build-tools;$ANDROID_BUILD_TOOLS_VERSION&quot; 
    $SDKMANAGER --list

    if [ ! -d $GRADLE_PATH ];then
        #download gredle
        echo &quot;&amp;gt; download gredle...&quot;
        wget https://downloads.gradle-dn.com/distributions/gradle-$GRADLE_VERSION-bin.zip 
        unzip gradle-$GRADLE_VERSION-bin.zip -d $TOOL_PATH
        rm -rf gradle-$GRADLE_VERSION-bin.zip 
    fi
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;.&lt;/p&gt;
&lt;h4 id=&quot;22-编译、运行、清除&quot;&gt;2.2 编译、运行、清除&lt;/h4&gt;
&lt;p&gt;借助于gradle，实现编译、清除比较方便，写入设备还是用adb：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;function build(){
    export GRADLE_HOME=$GRADLE_PATH
    export PATH=$PATH:$GRADLE_HOME/bin
    gradle clean
    gradle assembleDebug
}

function clean(){
    echo &quot;Cleaning...&quot;
    rm -rf build
    rm -rf $PROJECT_ROOT/example/$PROJECT_NAME/$MODULE_NAME/build
}

function program(){
        echo &quot;Launching...&quot;
        adb install -r $APK_PATH/*.apk
    adb shell am start -n  com.telink.lt/.ui.AdvDeviceListActivity
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;hr/&gt;&lt;h3 id=&quot;3-效果展示&quot;&gt;3 效果展示&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;http://tuchuang.beautifulzzzz.com:3000/?path=/mp4/bky/2020-04-18_07-13-28.gif&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;hr/&gt;&lt;dl&gt;&lt;dt&gt;: &lt;span&gt;&lt;strong&gt;本项目的github关注起来https://github.com/nbtool/android_app_linux_tool～&lt;/strong&gt;&lt;/span&gt;&lt;/dt&gt;
&lt;dd&gt;&lt;span&gt;&lt;strong&gt;大家觉得不错，可以点推荐给更多人～&lt;/strong&gt;&lt;/span&gt;&lt;/dd&gt;
&lt;/dl&gt;&lt;hr/&gt;&lt;h3 id=&quot;links&quot;&gt;LINKS&lt;/h3&gt;
&lt;p&gt;&lt;a href=&quot;https://blog.csdn.net/nailsoul/article/details/81331505&quot;&gt;[1].Android Studio 命令行Gradle编译&lt;/a&gt;&lt;br/&gt;[[2].BLE_826X_Generic]]&lt;a href=&quot;http://forum.telink-semi.cn/viewtopic.php?f=7&amp;amp;t=55&quot;&gt;#2&lt;/a&gt;&lt;br/&gt;&lt;a href=&quot;https://www.cnblogs.com/zjutlitao/p/12723791.html&quot;&gt;[3].21、android studio 疑难杂症&lt;/a&gt;&lt;/p&gt;
</description>
<pubDate>Fri, 17 Apr 2020 23:20:00 +0000</pubDate>
<dc:creator>beautifulzzzz</dc:creator>
<og:description>April 18, 2020 6:54 AM BEAUTIFULZZZZ [TOC] . 0 前言 在上上篇《[[编译] 5、在Linux下搭建安卓APP的开发烧写环境（makefile版）—— 在L</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/zjutlitao/p/12723855.html</dc:identifier>
</item>
<item>
<title>Node.js 的事件循环机制 - forcheng</title>
<link>http://www.cnblogs.com/forcheng/p/12723854.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/forcheng/p/12723854.html</guid>
<description>&lt;p&gt;&lt;strong&gt;目录&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;微任务&lt;/li&gt;
&lt;li&gt;事件循环机制&lt;/li&gt;
&lt;li&gt;setImmediate、setTimeout/setInterval 和 process.nextTick 执行时机对比&lt;/li&gt;
&lt;li&gt;实例分析&lt;/li&gt;
&lt;li&gt;参考&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;1.微任务&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;在谈论Node的事件循环机制之前，先补充说明一下 Node 中的“微任务”。这里说的微任务(microtasks)其实是一个统称，包含了两部分：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;process.nextTick() 注册的回调 （nextTick task queue）&lt;/li&gt;
&lt;li&gt;promise.then() 注册的回调 （promise task queue）&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;Node 在执行微任务时， 会优先执行 nextTick task queue 中的任务，执行完之后会接着执行 promise task queue 中的任务。所以如果 process.nextTick 的回调与 promise.then 的回调都处于主线程或事件循环中的同一阶段， process.nextTick 的回调要优先于 promise.then 的回调执行。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2.事件循环机制&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/898684/202004/898684-20200418064231061-1148380902.png&quot; alt=&quot;Node事件循环&quot;/&gt;&lt;/p&gt;
&lt;p&gt;如图，表示Node执行的整个过程。如果执行了任何非阻塞异步代码（创建计时器、读写文件等），则会进入事件循环。其中事件循环分为六个阶段：&lt;/p&gt;
&lt;p&gt;由于Pending callbacks、Idle/Prepare 和 Close callbacks 阶段是 Node 内部使用的三个阶段，所以这里主要分析与开发者代码执行更为直接关联的Timers、Poll 和 Check 三个阶段。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Timers（计时器阶段）&lt;/strong&gt;：从图可见，初次进入事件循环，会从计时器阶段开始。此阶段会判断是否存在过期的计时器回调（包含 setTimeout 和 setInterval），如果存在则会执行所有过期的计时器回调，执行完毕后，如果回调中触发了相应的微任务，会接着执行所有微任务，执行完微任务后再进入 Pending callbacks 阶段。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Pending callbacks&lt;/strong&gt;：执行推迟到下一个循环迭代的I / O回调（系统调用相关的回调）。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Idle/Prepare&lt;/strong&gt;：仅供内部使用。（详略）&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Poll（轮询阶段）&lt;/strong&gt;：&lt;/p&gt;
&lt;p&gt;当回调队列不为空时：&lt;/p&gt;
&lt;p&gt;会执行回调，若回调中触发了相应的微任务，这里的微任务执行时机和其他地方有所不同，不会等到所有回调执行完毕后才执行，而是针对每一个回调执行完毕后，就执行相应微任务。执行完所有的回到后，变为下面的情况。&lt;/p&gt;
&lt;p&gt;当回调队列为空时（没有回调或所有回调执行完毕）：&lt;/p&gt;
&lt;p&gt;但如果存在有计时器（setTimeout、setInterval和setImmediate）没有执行，会结束轮询阶段，进入 Check 阶段。否则会阻塞并等待任何正在执行的I/O操作完成，并马上执行相应的回调，直到所有回调执行完毕。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Check（查询阶段）&lt;/strong&gt;：会检查是否存在 setImmediate 相关的回调，如果存在则执行所有回调，执行完毕后，如果回调中触发了相应的微任务，会接着执行所有微任务，执行完微任务后再进入 Close callbacks 阶段。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Close callbacks&lt;/strong&gt;：执行一些关闭回调，比如 &lt;code&gt;socket.on('close', ...)&lt;/code&gt;等。&lt;/p&gt;
&lt;p&gt;总结&amp;amp;注意：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;每一个阶段都会有一个FIFO回调队列，都会尽可能的执行完当前阶段中所有的回调或到达了系统相关限制，才会进入下一个阶段。&lt;/li&gt;
&lt;li&gt;Poll 阶段执行的微任务的时机和 Timers 阶段 &amp;amp; Check 阶段的时机不一样，前者是在每一个回调执行就会执行相应微任务，而后者是会在所有回调执行完之后，才统一执行相应微任务。&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;&lt;strong&gt;3.setImmediate、setTimeout/setInterval 和 process.nextTick 执行时机对比&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;setImmediate：触发一个异步回调，在事件循环的 Check 阶段立即执行。&lt;/p&gt;
&lt;p&gt;setTimeout：触发一个异步回调，当计时器过期后，在事件循环的 Timers 阶段执行，只执行一次（可用 clearTimeout 取消）。&lt;/p&gt;
&lt;p&gt;setInterval：触发一个异步回调，每次计时器过期后，都会在事件循环的 Timers 阶段执行一次回调（可用 clearInterval 取消）。&lt;/p&gt;
&lt;p&gt;process.nextTick：触发一个微任务（异步）回调，既可以在主线程（mainline）中执行，可以存在事件循序的某一个阶段中执行。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;4.实例分析&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;第一组：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;比较 setTimeout 与 setImmediate：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-js&quot;&gt;// test.js
setTimeout(() =&amp;gt; {
  console.log('setTimeout');
}, 0);

setImmediate(() =&amp;gt; {
  console.log('setImmediate');
});
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;结果：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/898684/202004/898684-20200418064411626-62072431.png&quot; alt=&quot;setTimeout vs setImmediate&quot;/&gt;&lt;/p&gt;
&lt;p&gt;分析：&lt;/p&gt;
&lt;p&gt;从输出结果来看，输出是不确定的，既可能 &quot;setTimeout&quot; 在前，也可能 &quot;setImmediate&quot; 在前。从事件循环的流程来分析，事件循环开始，会先进入 Timers 阶段，虽然 setTimeout 设置的 delay 是 0，但其实是1，因为 Node 中的 setTimeout 的 delay 取值范围必须是在 [1, 2^31-1] 这个范围内，否则默认为1，因此受进程性能的约束，执行到 Timers 阶段时，可能计时器还没有过期，所以继续向下一个流程进行，所以会偶尔出现 &quot;setImmediate&quot; 输出在前的情况。如果适当地调大 setTimeout 的 delay，比如10，则基本上必然是 &quot;setImmediate&quot; 输出在前面。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;第二组：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;比较主线程（mainline）、Timers 阶段、Poll 阶段和 Check 阶段的回调执行以及对应的微任务执行的顺序：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-js&quot;&gt; // test.js
 const fs = require('fs');

 console.log('mainline: start')
 process.nextTick(() =&amp;gt; {
   console.log('mainline: ', 'process.nextTick\n')
 })

let counter = 0;
const interval = setInterval(() =&amp;gt; {
  console.log('timers: setInterval.start ', counter)
  if(counter &amp;lt; 2) {
    setTimeout(() =&amp;gt; {
      console.log('timers: setInterval.setTimeout')
      process.nextTick(() =&amp;gt; {
        console.log('timers microtasks: ', 'setInterval.setTimeout.process.nextTick\n')
      })
    }, 0)

    fs.readdir('./', (err, files) =&amp;gt; {
      console.log('poll: setInterval.readdir1')
      process.nextTick(() =&amp;gt; {
        console.log('poll microtasks: ', 'setInterval.readdir1.process.nextTick')
        process.nextTick(() =&amp;gt; {
          console.log('poll microtasks: ', 'setInterval.readdir1.process.nextTick.process.nextTick')
        })
      })
    })

    fs.readdir('./', (err, files) =&amp;gt; {
      console.log('poll: setInterval.readdir2')
      process.nextTick(() =&amp;gt; {
        console.log('poll microtasks: ', 'setInterval.readdir2.process.nextTick')
        process.nextTick(() =&amp;gt; {
          console.log('poll microtasks: ', 'setInterval.readdir2.process.nextTick.process.nextTick\n')
        })
      })
    })

    setImmediate(() =&amp;gt; {
      console.log('check: setInterval.setImmediate1')
      process.nextTick(() =&amp;gt; {
        console.log('check microtasks: ', 'setInterval.setImmediate1.process.nextTick')
      })
    })

    setImmediate(() =&amp;gt; {
      console.log('check: setInterval.setImmediate2')
      process.nextTick(() =&amp;gt; {
        console.log('check microtasks: ', 'setInterval.setImmediate2.process.nextTick\n')
      })
    })
  } else {
    console.log('timers: setInterval.clearInterval')
    clearInterval(interval)
  }

  console.log('timers: setInterval.end ', counter)
  counter++;
}, 0);

 console.log('mainline: end')
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;结果：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/898684/202004/898684-20200418064455032-60988709.png&quot; alt=&quot;不同阶段的回调执行以及对应的微任务执行的顺序&quot;/&gt;&lt;/p&gt;
&lt;p&gt;分析：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;如图 mainline&lt;/strong&gt;：可以看到，主线程中的 process.nextTick 是在同步代码执行完之后以及在事件循环之前执行，符合预期。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;如图 第一次 timers&lt;/strong&gt;：此时事件循环第一次到 Timers 阶段，setInterval 的 delay 时间到了，所以执行回调，由于没有触发直接相应的微任务，所以直接进入后面的阶段。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;如图 第一次 poll&lt;/strong&gt;：此时事件循环第一次到 Poll 阶段，由于之前 Timers 阶段执行的回调中，触发了两个非阻塞的I/O操作（readdir），在这一阶段时I/O操作执行完毕，直接执行了对应的两个回调。从输出可以看出，针对每一个回调执行完毕后，就执行相应微任务，微任务中再次触发微任务也会继续执行，并不会等到所有回调执行完后再去触发微任务，符合预期。执行完毕所有回调之后，因为还有调度了计时器，所以 Poll 阶段结束，进入 Check 阶段。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;如图 第一次 check&lt;/strong&gt;：此时事件循环第一次到 Check 阶段，直接触发对应的两个 setImmediate 执行。从输出可以看出，微任务是在所有的回调执行完毕之后才触发执行的，符合预期。执行完微任务后，进入后面阶段。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;如图 第二次 timers&lt;/strong&gt;：此时事件循环第二次到 Timers 阶段，首先输出了 &quot;timers: setInterval.setTimeout&quot; ，这是为什么？不要忘了，之前第一次执行 setInterval 的回调时，其实已经执行了一次其内部的 setTimeout(..., 0)，但由于它并不能触发微任务，所以其回调没有被执行，而是进入到了后面的阶段，而是等到再次来到 Timers 阶段，根据FIFO，优先执行之前的 setTimeout 的回调，再执行 setInterval 的回调，而最后等所有回调执行完毕，再执行 setTimeout 的回调里面触发的微任务，最后输出的是 &quot;timers microtasks: setInterval.setTimeout.process.nextTick&quot;，符合预期（所有回调执行完毕后，再执行相应微任务）。&lt;/p&gt;
&lt;p&gt;后面的输出类似，所以不再做过多分析。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;5.参考&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.ibm.com/developerworks/cn/opensource/os-tutorials-learn-nodejs-the-event-loop/index.html&quot;&gt;学习 Node.js，第 5 单元：事件循环&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://nodejs.org/en/docs/guides/event-loop-timers-and-nexttick/&quot;&gt;事件循环、计时器和 process.nextTick()&lt;/a&gt;&lt;/p&gt;
</description>
<pubDate>Fri, 17 Apr 2020 22:56:00 +0000</pubDate>
<dc:creator>forcheng</dc:creator>
<og:description>目录 微任务 事件循环机制 setImmediate、setTimeout/setInterval 和 process.nextTick 执行时机对比 实例分析 参考 1.微任务 在谈论Node的事件</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/forcheng/p/12723854.html</dc:identifier>
</item>
<item>
<title>Netty：ChannelFuture - lingjiango</title>
<link>http://www.cnblogs.com/iou123lg/p/12723518.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/iou123lg/p/12723518.html</guid>
<description>&lt;p&gt;&lt;a href=&quot;https://www.cnblogs.com/iou123lg/p/12676413.html&quot; target=&quot;_blank&quot;&gt;上一篇&lt;/a&gt;我们完成了对Channel的学习，这一篇让我们来学习一下ChannelFuture。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ChannelFuture&lt;/strong&gt;&lt;strong&gt;的简介&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;ChannelFuture是Channel异步IO操作的结果。&lt;/p&gt;
&lt;p&gt;Netty中的所有IO操作都是异步的。这意味着任何IO调用都将立即返回，而不能保证所请求的IO操作在调用结束时完成。相反，将返回一个带有ChannelFuture的实例，该实例将提供有关IO操作的结果或状态的信息。&lt;/p&gt;
&lt;p&gt;ChannelFuture要么是未完成状态，要么是已完成状态。IO操作刚开始时，将创建一个新的Future对象。新的Future对象最初处于未完成的状态，因为IO操作尚未完成，所以既不会执行成功、执行失败，也不会取消执行。如果IO操作因为执行成功、执行失败或者执行取消导致操作完成，则将被标记为已完成的状态，并带有更多特定信息，例如失败原因。请注意，即使执行失败和取消执行也属于完成状态。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/289599/202004/289599-20200417235455814-2073778962.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;ChannelFuture提供了各种方法，可让您检查IO操作是否已完成，等待完成以及获取IO操作的结果。它还允许您添加ChannelFutureListener，以便在IO操作完成时得到通知。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Prefer addListener(GenericFutureListener) to await()&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;推荐使用addListener(GenericFutureListener)而不是await()，以便在完成IO操作并执行任何后续任务时得到通知。&lt;/p&gt;
&lt;p&gt;addListener(GenericFutureListener)是非阻塞的。它只是将指定的ChannelFutureListener添加到ChannelFuture，并且与将来关联的IO操作完成时，IO线程将通知监听器。ChannelFutureListener完全不阻塞，因此可产生最佳的性能和资源利用率，但是如果不习惯事件驱动的编程，则实现顺序逻辑可能会比较棘手。&lt;/p&gt;
&lt;p&gt;相反，await()是阻塞操作。一旦被调用，调用者线程将阻塞直到操作完成。使用await()实现顺序逻辑比较容易，但是调用者线程会不必要地阻塞直到完成IO操作为止，并且线程间通知的成本相对较高。此外，在特定情况下还可能出现死锁。 &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Do not call await() inside ChannelHandler&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;ChannelHandler中的事件处理程序方法通常由IO线程调用，如果await()是由IO线程调用的事件处理程序方法调用的，则它正在等待的IO操作可能永远不会完成，因为await()会阻塞它正在等待的IO操作，这是一个死锁。&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;35&quot;&gt;
&lt;pre&gt;
&lt;span&gt;//&lt;/span&gt;&lt;span&gt; BAD - NEVER DO THIS&lt;/span&gt;
&lt;span&gt;   @Override
   &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt;&lt;span&gt; channelRead(ChannelHandlerContext ctx, Object msg) {
       ChannelFuture future &lt;/span&gt;=&lt;span&gt; ctx.channel().close();
       future.awaitUninterruptibly();
       &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; Perform post-closure operation
       &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; ...&lt;/span&gt;
   }
&lt;/pre&gt;&lt;/div&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;35&quot;&gt;
&lt;pre&gt;
&lt;span&gt;//&lt;/span&gt;&lt;span&gt; GOOD&lt;/span&gt;
&lt;span&gt;   @Override
   &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt;&lt;span&gt; channelRead(ChannelHandlerContext ctx, Object msg) {
       ChannelFuture future &lt;/span&gt;=&lt;span&gt; ctx.channel().close();
       future.addListener(&lt;/span&gt;&lt;span&gt;new&lt;/span&gt;&lt;span&gt; ChannelFutureListener() {
           &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt;&lt;span&gt; operationComplete(ChannelFuture future) {
               &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; Perform post-closure operation
               &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; ...&lt;/span&gt;
&lt;span&gt;           }
       });
   }&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;尽管有上述缺点，但是在某些情况下，调用await()更方便。在这种情况下，请确保不要在IO线程中调用await()。 否则，将引发BlockingOperationException来防止死锁。&lt;/p&gt;
&lt;p&gt; &lt;strong&gt;Do not confuse I/O timeout and await timeout&lt;/strong&gt; &lt;/p&gt;
&lt;p&gt;使用await(long)，await(long，TimeUnit)，awaitUninterruptible(long)或awaitUninterruptible(long，TimeUnit)指定的timeout与IO超时根本不相关。 如果IO操作超时，则Future将被标记为“Completed with failure”，如上图所示。 例如，应通过特定于传输的选项配置连接超时：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;36&quot;&gt;
&lt;pre&gt;
&lt;span&gt;//&lt;/span&gt;&lt;span&gt; BAD - NEVER DO THIS&lt;/span&gt;
   Bootstrap b =&lt;span&gt; ...;
   ChannelFuture f &lt;/span&gt;=&lt;span&gt; b.connect(...);
   f.awaitUninterruptibly(&lt;/span&gt;10&lt;span&gt;, TimeUnit.SECONDS);
   &lt;/span&gt;&lt;span&gt;if&lt;/span&gt;&lt;span&gt; (f.isCancelled()) {
       &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; Connection attempt cancelled by user&lt;/span&gt;
   } &lt;span&gt;else&lt;/span&gt; &lt;span&gt;if&lt;/span&gt; (!&lt;span&gt;f.isSuccess()) {
       &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; You might get a NullPointerException here because the future
       &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; might not be completed yet.&lt;/span&gt;
&lt;span&gt;       f.cause().printStackTrace();
   } &lt;/span&gt;&lt;span&gt;else&lt;/span&gt;&lt;span&gt; {
       &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; Connection established successfully&lt;/span&gt;
&lt;span&gt;   }
  &lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;36&quot;&gt;
&lt;pre&gt;
   &lt;span&gt;//&lt;/span&gt;&lt;span&gt; GOOD&lt;/span&gt;
   Bootstrap b =&lt;span&gt; ...;
   &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; Configure the connect timeout option.&lt;/span&gt;
   b.option(ChannelOption.CONNECT_TIMEOUT_MILLIS, 10000&lt;span&gt;);
   ChannelFuture f &lt;/span&gt;=&lt;span&gt; b.connect(...);
   f.awaitUninterruptibly();
  
   &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; Now we are sure the future is completed.&lt;/span&gt;
   &lt;span&gt;assert&lt;/span&gt;&lt;span&gt; f.isDone();
  
   &lt;/span&gt;&lt;span&gt;if&lt;/span&gt;&lt;span&gt; (f.isCancelled()) {
       &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; Connection attempt cancelled by user&lt;/span&gt;
   } &lt;span&gt;else&lt;/span&gt; &lt;span&gt;if&lt;/span&gt; (!&lt;span&gt;f.isSuccess()) {
       f.cause().printStackTrace();
   } &lt;/span&gt;&lt;span&gt;else&lt;/span&gt;&lt;span&gt; {
       &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; Connection established successfully&lt;/span&gt;
   }
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;ChannelFuture&lt;/strong&gt;&lt;strong&gt;的方法&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/289599/202004/289599-20200417235906140-231530933.png&quot; alt=&quot;&quot;/&gt;&lt;/strong&gt;&lt;/p&gt;


&lt;p&gt;ChannelFuture的方法并不多，可以简单的看一下。&lt;/p&gt;
&lt;p&gt;channel()：返回ChannelFuture关联的Channel；&lt;/p&gt;
&lt;p&gt;addListener()：将指定的listener添加到Future。Future完成时，将通知指定的listener。如果Future已经完成，则立即通知指定的listener；&lt;/p&gt;
&lt;p&gt;addListeners()：和上述方法一样，只不过此方法可以新增一系列的listener；&lt;/p&gt;
&lt;p&gt;removeListener()：从Future中删除第一次出现的指定listener。完成Future时，不再通知指定的listener。如果指定的listener与此Future没有关联，则此方法不执行任何操作并以静默方式返回。&lt;/p&gt;
&lt;p&gt;removeListeners()：和上述方法一样，只不过此方法可以移除一系列的listener；&lt;/p&gt;
&lt;p&gt;sync()：等待Future直到其完成，如果这个Future失败，则抛出失败原因；&lt;/p&gt;
&lt;p&gt;syncUninterruptibly()：不会被中断的sync()；&lt;/p&gt;
&lt;p&gt;await()：等待Future完成；&lt;/p&gt;
&lt;p&gt;awaitUninterruptibly()：不会被中断的await ()；&lt;/p&gt;
&lt;p&gt;isVoid()：如果此ChannelFuture是void的Future，则返回true，因此不允许调用以下任何方法：&lt;/p&gt;
&lt;p&gt;addListener(GenericFutureListener)&lt;/p&gt;
&lt;p&gt;addListeners(GenericFutureListener[])&lt;/p&gt;
&lt;p&gt;await()&lt;/p&gt;
&lt;p&gt;await(long, TimeUnit) ()}&lt;/p&gt;
&lt;p&gt;await(long) ()}&lt;/p&gt;
&lt;p&gt;awaitUninterruptibly()&lt;/p&gt;
&lt;p&gt;sync()&lt;/p&gt;
&lt;p&gt;syncUninterruptibly()&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;为什么使用ChannelFuture？&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;从JDK1.5之后，J.U.C提供了Future类，它代表着异步计算的结果。Future类提供了如下方法：&lt;/p&gt;

&lt;table border=&quot;1&quot; cellspacing=&quot;0&quot; cellpadding=&quot;0&quot;&gt;&lt;tbody readability=&quot;9.5&quot;&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot; width=&quot;277&quot;&gt;
&lt;p&gt;方法&lt;/p&gt;
&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;277&quot;&gt;
&lt;p&gt;方法说明&lt;/p&gt;
&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;12&quot;&gt;&lt;td valign=&quot;top&quot; width=&quot;277&quot; readability=&quot;5&quot;&gt;
&lt;p&gt;boolean cancel(boolean mayInterruptIfRunning)&lt;/p&gt;
&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;277&quot; readability=&quot;11&quot;&gt;
&lt;p&gt;尝试取消执行此任务。如果任务已经完成，已经被取消或由于某些其他原因而无法取消，则此尝试将失败。如果成功，并且在调用cancel时此任务尚未启动，则该任务永远不要运行。如果任务已经启动，则mayInterruptIfRunning参数确定是否应中断执行该任务的线程以尝试停止该任务。&lt;/p&gt;
&lt;p&gt;此方法返回后，对isDone的后续调用将始终返回true。如果此方法返回true，则随后对isCancelled的调用将始终返回true。&lt;/p&gt;
&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;3&quot;&gt;&lt;td valign=&quot;top&quot; width=&quot;277&quot;&gt;
&lt;p&gt;boolean isCancelled()&lt;/p&gt;
&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;277&quot; readability=&quot;5&quot;&gt;
&lt;p&gt;如果此任务在正常完成之前被取消，则返回true。&lt;/p&gt;
&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;4.5&quot;&gt;&lt;td valign=&quot;top&quot; width=&quot;277&quot;&gt;
&lt;p&gt;boolean isDone()&lt;/p&gt;
&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;277&quot; readability=&quot;6&quot;&gt;
&lt;p&gt;如果此任务完成，则返回true。完成可能是由于正常终止，异常或取消引起的，在所有这些情况下，此方法都将返回true。&lt;/p&gt;
&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;3&quot;&gt;&lt;td valign=&quot;top&quot; width=&quot;277&quot;&gt;
&lt;p&gt;V get()&lt;/p&gt;
&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;277&quot; readability=&quot;5&quot;&gt;
&lt;p&gt;必要时等待计算完成，然后检索其结果。&lt;/p&gt;
&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;7.5&quot;&gt;&lt;td valign=&quot;top&quot; width=&quot;277&quot; readability=&quot;6&quot;&gt;
&lt;p&gt;V get(long timeout, TimeUnit unit)&lt;/p&gt;
&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;277&quot; readability=&quot;5&quot;&gt;
&lt;p&gt;必要时最多等待给定时间以完成计算，然后检索其结果。&lt;/p&gt;
&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;从这些方法中，可以看出Future类存在2大问题： &lt;/p&gt;
&lt;p&gt;1、isDone()的定义模糊不清，不管是失败、异常还是成功，isDone()返回的都是true；&lt;/p&gt;
&lt;p&gt;2、get()获取结果的方式是阻塞等待的方式。 &lt;/p&gt;
&lt;p&gt;所以Netty中的Future对JDK中的Future做了扩展，而ChannelFuture继承Future，固然也能充分利用这个扩展出的新特性。新特性主要体现在如下两方面：&lt;/p&gt;
&lt;p&gt;1、引入isSuccess()来表示执行成功，引入cause()来表示执行失败的原因；&lt;/p&gt;
&lt;p&gt;2、引入Future-Listener机制来替代主动get()阻塞等待的机制。 &lt;/p&gt;
&lt;p&gt;对于第1点，可以回到简介部分，该图表清晰的描述了这个异步调用的状态变化。当异步结果未完成时，isDone()、isSuccess()、isCancelled()均为false，同时cause()返回null，若是完成成功，则isDone()、isSuccess()均为true，若是完成失败，则isDone()为true，cause()返回not-null，若是取消完成，则&lt;/p&gt;
&lt;p&gt;isDone()、isCancelled()均为true。可以看到新引入的特性可以很清晰的表示常用的状态。&lt;/p&gt;
&lt;p&gt;对于第2点，Future-Listener机制本质上就是一种观察者模式，Netty中的Future通过提供addListener/addListeners方法来实现对Future执行结果的监听，一旦Future执行完成，就会触发GenericFutureListener的operationComplete方法，在该方法中就可以获取Future的执行结果，这种方式比起直接get()，能有效提升Netty的吞吐量。 &lt;/p&gt;

&lt;p&gt;至此，我们就学习完了ChannelFuture，最后总结一下：&lt;/p&gt;
&lt;p&gt;1、Netty中的所有IO操作都是异步的。这意味着任何IO调用都将立即返回，而不能保证所请求的IO操作在调用结束时完成。ChannelFuture是Channel异步IO操作的结果；&lt;/p&gt;
&lt;p&gt;2、ChannelFuture或者说是Future，通过引入新的特性解决了原生JDK中Future对于状态模糊不清及阻塞等待获取结果的方式，这个新特性就是引入isSuccess()、cause()方法，同时通过Future-Listener回调机制解决不知道何时能获取到Future结果的问题。&lt;/p&gt;
</description>
<pubDate>Fri, 17 Apr 2020 16:05:00 +0000</pubDate>
<dc:creator>lingjiango</dc:creator>
<og:description>上一篇我们完成了对Channel的学习，这一篇让我们来学习一下ChannelFuture。 ChannelFuture的简介 ChannelFuture是Channel异步IO操作的结果。 Netty</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/iou123lg/p/12723518.html</dc:identifier>
</item>
<item>
<title>[译]HAL-超文本应用语言 - 东溪陈姓少年</title>
<link>http://www.cnblogs.com/dongxishaonian/p/12723532.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/dongxishaonian/p/12723532.html</guid>
<description>&lt;p&gt;HAL 是一种简单的格式，它提供了一种一致且简便的方法在 API 的资源之间进行超链接。&lt;/p&gt;&lt;div id=&quot;cnblogs_post_body&quot; readability=&quot;194.81553956835&quot;&gt;

&lt;h2 id=&quot;精益超媒体类型&quot;&gt;精益超媒体类型&lt;/h2&gt;
&lt;h2 id=&quot;总结&quot;&gt;总结&lt;/h2&gt;
&lt;p&gt;HAL 是一种简单的格式，它提供了一种一致且简便的方法在 API 的资源之间进行超链接。&lt;/p&gt;
&lt;p&gt;采用 HAL 将使您的 API 易于探索，并且其文档很容易从 API 本身中发现。简而言之，这将使您的 API 更易于使用，因此对客户端开发人员更具吸引力。&lt;/p&gt;
&lt;p&gt;使用适用于大多数编程语言的开源库，可以轻松提供和使用采用HAL的API。它也很简单，您可以像处理其他JSON一样处理它。&lt;/p&gt;
&lt;h2 id=&quot;一般描述&quot;&gt;一般描述&lt;/h2&gt;
&lt;p&gt;HAL提供了一组约定以JSON或XML表示超链接。（&lt;strong&gt;HAL文档的其余部分只是普通的旧JSON或XML。&lt;/strong&gt;）&lt;/p&gt;
&lt;p&gt;不要使用临时结构，也不要花费宝贵的时间来设计自己的格式；您可以采用HAL的约定，并专注于构建和记录构成API的数据和转换。&lt;/p&gt;
&lt;p&gt;HAL 有点像计算机的 HTML，因为它是通用的，旨在通过超链接驱动许多不同类型的应用程序。不同的是，HTML 具有帮助&quot;人工参与者&quot;通过 Web 应用程序实现其目标的功能，而 HAL 旨在帮助&quot;自动参与者&quot;通过 Web API 实现其目标。&lt;/p&gt;
&lt;p&gt;话虽如此&lt;strong&gt;，HAL实际上也非常人性化&lt;/strong&gt;。其约定使 API 的文档可以从 API 消息本身发现。这使得开发人员能够直接进入基于 HAL 的 API 并探索其功能，而无需将一些外部文档映射到其旅程的认知开销。&lt;/p&gt;
&lt;h2 id=&quot;例子&quot;&gt;例子&lt;/h2&gt;
&lt;p&gt;下面的示例是如何使用 hal_json 表示订单集合。需要查找的事项：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;使用自链接(self)表示的主要资源的 URI（&quot;/orders&quot;）&lt;/li&gt;
&lt;li&gt;指向下一页订单的&quot;next&quot;链接&lt;/li&gt;
&lt;li&gt;名为&quot;ea:find&quot;的模板化链接，用于按 id 搜索订单&lt;/li&gt;
&lt;li&gt;数组中包含多个“ ea:admin”链接对象&lt;/li&gt;
&lt;li&gt;订单集合的两个属性； “currentlyProcessing（当前正在处理）”和“shippedToday（今天发货）”&lt;/li&gt;
&lt;li&gt;具有自己的链接和属性的嵌入式订单资源&lt;/li&gt;
&lt;li&gt;名为&quot;ea&quot;的紧凑型 URI （curie） 用于扩展指向其文档 URL 的链接的名称&lt;/li&gt;
&lt;/ul&gt;&lt;h3 id=&quot;applicationhaljson&quot;&gt;application/hal+json&lt;/h3&gt;
&lt;pre&gt;
&lt;code class=&quot;language-json&quot;&gt;{
    &quot;_links&quot;: {
        &quot;self&quot;: { &quot;href&quot;: &quot;/orders&quot; },
        &quot;curies&quot;: [{ &quot;name&quot;: &quot;ea&quot;, &quot;href&quot;: &quot;http://example.com/docs/rels/{rel}&quot;, &quot;templated&quot;: true }],
        &quot;next&quot;: { &quot;href&quot;: &quot;/orders?page=2&quot; },
        &quot;ea:find&quot;: {
            &quot;href&quot;: &quot;/orders{?id}&quot;,
            &quot;templated&quot;: true
        },
        &quot;ea:admin&quot;: [{
            &quot;href&quot;: &quot;/admins/2&quot;,
            &quot;title&quot;: &quot;Fred&quot;
        }, {
            &quot;href&quot;: &quot;/admins/5&quot;,
            &quot;title&quot;: &quot;Kate&quot;
        }]
    },
    &quot;currentlyProcessing&quot;: 14,
    &quot;shippedToday&quot;: 20,
    &quot;_embedded&quot;: {
        &quot;ea:order&quot;: [{
            &quot;_links&quot;: {
                &quot;self&quot;: { &quot;href&quot;: &quot;/orders/123&quot; },
                &quot;ea:basket&quot;: { &quot;href&quot;: &quot;/baskets/98712&quot; },
                &quot;ea:customer&quot;: { &quot;href&quot;: &quot;/customers/7809&quot; }
            },
            &quot;total&quot;: 30.00,
            &quot;currency&quot;: &quot;USD&quot;,
            &quot;status&quot;: &quot;shipped&quot;
        }, {
            &quot;_links&quot;: {
                &quot;self&quot;: { &quot;href&quot;: &quot;/orders/124&quot; },
                &quot;ea:basket&quot;: { &quot;href&quot;: &quot;/baskets/97213&quot; },
                &quot;ea:customer&quot;: { &quot;href&quot;: &quot;/customers/12369&quot; }
            },
            &quot;total&quot;: 20.00,
            &quot;currency&quot;: &quot;USD&quot;,
            &quot;status&quot;: &quot;processing&quot;
        }]
    }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;hal-型号&quot;&gt;HAL 型号&lt;/h2&gt;
&lt;p&gt;HAL约定围绕着代表两个简单的概念：资源和链接。&lt;/p&gt;
&lt;h3 id=&quot;资源&quot;&gt;资源&lt;/h3&gt;
&lt;p&gt;资源具有：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;链接（到 URI）&lt;/li&gt;
&lt;li&gt;嵌入式资源（即其中包含的其他资源）&lt;/li&gt;
&lt;li&gt;状态（沼点标准 JSON 或 XML 数据）&lt;/li&gt;
&lt;/ul&gt;&lt;h3 id=&quot;链接&quot;&gt;链接&lt;/h3&gt;
&lt;p&gt;链接有：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;目标（URI）&lt;/li&gt;
&lt;li&gt;关系，又名。&quot;rel&quot; （链接的名称）&lt;/li&gt;
&lt;li&gt;其他一些可选属性，以帮助弃用、内容协商等。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;下面的图像大致说明了HAL表示的结构：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://tva1.sinaimg.cn/large/007S8ZIlly1gdwwz2klywj30m80go0t4.jpg&quot; alt=&quot;https://tva1.sinaimg.cn/large/007S8ZIlly1gdwwz2klywj30m80go0t4.jpg&quot;/&gt;&lt;/p&gt;
&lt;h2 id=&quot;hal-在-api-中的使用方式&quot;&gt;HAL 在 API 中的使用方式&lt;/h2&gt;
&lt;p&gt;HAL 旨在构建 API，其中客户端通过以下链接围绕资源进行导航。&lt;/p&gt;
&lt;p&gt;链接通过链接关系标识。链接关系是超媒体 API 的命脉：它们是告诉客户端开发人员哪些可用资源以及如何与其交互的方式，它们就是它们编写的代码将如何选择要遍历的链接。&lt;/p&gt;
&lt;p&gt;但是，链接关系不仅仅是HAL中的标识字符串。 它们实际上是URL，开发人员可以遵循这些 URL 来读取给定链接的文档。 这就是所谓的“可发现性”。 这样的想法是，开发人员可以输入您的API，通读可用链接的文档，然后通过API进行操作。&lt;/p&gt;
&lt;p&gt;HAL鼓励将链接关系（rel）用于：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;识别表示中的链接和嵌入资源&lt;/li&gt;
&lt;li&gt;推断目标资源的预期结构和意义&lt;/li&gt;
&lt;li&gt;向目标资源发出哪些请求和表示信号&lt;/li&gt;
&lt;/ol&gt;&lt;h2 id=&quot;如何为-hal-服务&quot;&gt;如何为 HAL 服务&lt;/h2&gt;
&lt;p&gt;HAL 具有 JSON 和 XML 变体的介质类型，其名称是和分别。&lt;code&gt;application/hal+json和application/hal+xml&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;在 HTTP 上提供 HAL 时，响应应包含相关的媒体类型名称。&lt;code&gt;Content-Type&lt;/code&gt;&lt;/p&gt;
&lt;h2 id=&quot;hal-文档的结构&quot;&gt;HAL 文档的结构&lt;/h2&gt;
&lt;h3 id=&quot;最低有效文件&quot;&gt;最低有效文件&lt;/h3&gt;
&lt;p&gt;HAL 文档必须至少包含空资源。&lt;/p&gt;
&lt;p&gt;空的 JSON 对象：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-json&quot;&gt;{}
&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;资源-2&quot;&gt;资源&lt;/h3&gt;
&lt;p&gt;在大多数情况下，资源应具有自己的URI&lt;/p&gt;
&lt;p&gt;通过&quot;self&quot;链接表示：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-json&quot;&gt;{
    &quot;_links&quot;: {
        &quot;self&quot;: { &quot;href&quot;: &quot;/example_resource&quot; }
    }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;链接-2&quot;&gt;链接&lt;/h3&gt;
&lt;p&gt;链接必须直接包含在资源中：&lt;/p&gt;
&lt;p&gt;链接表示为包含在哈希中的 JSON 对象，该哈希必须是资源对象的直接属性：&lt;code&gt;_links&lt;/code&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;{
    &quot;_links&quot;: {
        &quot;next&quot;: { &quot;href&quot;: &quot;/page=2&quot; }
    }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;h4 id=&quot;链接关系&quot;&gt;链接关系&lt;/h4&gt;
&lt;p&gt;链接有关系（又名）。&quot;rel&quot;）。这表示特定链接的语义 - 含义。&lt;/p&gt;
&lt;p&gt;链接 rels 是区分资源链接的主要方法。&lt;/p&gt;
&lt;p&gt;它基本上只是哈希中的一个键，将链接含义（&quot;rel&quot;）与包含数据（如实际&quot;href&quot;值）的链接对象相关联：&lt;code&gt;_links&lt;/code&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-json&quot;&gt;{
    &quot;_links&quot;: {
        &quot;next&quot;: { &quot;href&quot;: &quot;/page=2&quot; }
    }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;h4 id=&quot;api-可发现性&quot;&gt;API 可发现性&lt;/h4&gt;
&lt;p&gt;链接关系rels 应该是显示有关给定链接的文档的 URL，使它们&quot;可发现&quot;。URL 通常相当长，并且有点讨厌用作密钥。为了绕过这一点，HAL 提供了&quot;CURIEs&quot;，它们基本上是名为令牌，您可以在文档中定义，并用于以更友好、更紧凑的方式表达链接关系 URI,例如&lt;code&gt;ex:widget&lt;/code&gt; 而不是&lt;code&gt;http://example.com/rels/widget&lt;/code&gt;。详细信息可在稍下一点的&quot;CURIEs&quot;部分中提供。&lt;/p&gt;
&lt;h3 id=&quot;表示具有相同关系的多个链接&quot;&gt;表示具有相同关系的多个链接&lt;/h3&gt;
&lt;p&gt;资源可能有多个共享同一链接关系的链接。&lt;/p&gt;
&lt;p&gt;对于可能具有多个链接的链接关系，我们使用链接数组。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-json&quot;&gt;{
    &quot;_links&quot;: {
      &quot;items&quot;: [{
          &quot;href&quot;: &quot;/first_item&quot;
      },{
          &quot;href&quot;: &quot;/second_item&quot;
      }]
    }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;注：&lt;/strong&gt;如果您不确定链接是否应是单数，则假定该链接是多个链接。如果选择单数并发现需要更改它，则需要创建新的链接关系或面对断开现有客户端。&lt;/p&gt;
&lt;h3 id=&quot;curies&quot;&gt;CURIEs&lt;/h3&gt;
&lt;p&gt;&quot;CURIEs&quot;帮助提供指向资源文档的链接。&lt;/p&gt;
&lt;p&gt;HAL 为您提供了一个保留的链接关系&quot;curies&quot;，您可以使用它来提示资源文档的位置。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-json&quot;&gt;&quot;_links&quot;: {
  &quot;curies&quot;: [
    {
      &quot;name&quot;: &quot;doc&quot;,
      &quot;href&quot;: &quot;http://haltalk.herokuapp.com/docs/{rel}&quot;,
      &quot;templated&quot;: true
    }
  ],

  &quot;doc:latest-posts&quot;: {
    &quot;href&quot;: &quot;/posts/latest&quot;
  }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&quot;curies&quot;部分中可以有多个链接。它们带有一个&quot;name&quot;和模板化的&quot;href&quot;，其中必须包含占位符。&lt;code&gt;{rel}&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;然后，链接可以在其“ rel”之前加上curies的名称。将latest-posts链接与doc文档curies关联，将导致链接“ rel”设置为doc:latest-posts。&lt;/p&gt;
&lt;p&gt;若要检索有关资源的文档，客户端将扩展关联的 curies 链接与实际链接的&quot;rel&quot;。这将导致一个 URL，该 URL 应返回有关此资源的文档latest-posts ： &lt;code&gt;http://haltalk.herokuapp.com/docs/latest-posts&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;原文地址：&lt;a href=&quot;http://stateless.co/hal_specification.html&quot;&gt;http://stateless.co/hal_specification.html&lt;/a&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;
&lt;hr/&gt;&lt;p&gt;&lt;strong&gt;关注笔者公众号，推送各类原创/优质技术文章 ⬇️&lt;/strong&gt;&lt;br/&gt;&lt;img src=&quot;https://tva1.sinaimg.cn/large/007S8ZIlly1gduii11hhhj31m40hc762.jpg&quot; alt=&quot;image-20200410104030284&quot;/&gt;&lt;/p&gt;
&lt;/div&gt;</description>
<pubDate>Fri, 17 Apr 2020 16:05:00 +0000</pubDate>
<dc:creator>东溪陈姓少年</dc:creator>
<og:description>HAL 是一种简单的格式，它提供了一种一致且简便的方法在 API 的资源之间进行超链接。</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/dongxishaonian/p/12723532.html</dc:identifier>
</item>
<item>
<title>【高并发】不废话，言简意赅介绍BlockingQueue - 冰河团队</title>
<link>http://www.cnblogs.com/binghe001/p/12723469.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/binghe001/p/12723469.html</guid>
<description>&lt;h2 id=&quot;写在前面&quot;&gt;写在前面&lt;/h2&gt;
&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;最近，有不少网友留言提问：在Java的并发编程中，有个BlockingQueue，它是个阻塞队列，为何要在并发编程里使用BlockingQueue呢？好吧，今天，就临时说一下BlockingQueue吧，不过今天说的不是很深入，后面咱们一起从源头上深入剖析这个类。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;blockingqueue概述&quot;&gt;BlockingQueue概述&lt;/h2&gt;
&lt;p&gt;阻塞队列，是线程安全的。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;被阻塞的情况如下：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;（1）当队列满时，进行入队列操作&lt;br/&gt;（2）当队列空时，进行出队列操作&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;使用场景如下：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;主要在生产者和消费者场景。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;BlockingQueue的方法&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;BlockingQueue 具有 4 组不同的方法用于插入、移除以及对队列中的元素进行检查。如果请求的操作不能得到立即执行的话，每个方法的表现也不同。这些方法如下：&lt;/p&gt;
&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th/&gt;
&lt;th&gt;抛出异常&lt;/th&gt;
&lt;th&gt;特殊值&lt;/th&gt;
&lt;th&gt;阻塞&lt;/th&gt;
&lt;th&gt;超时&lt;/th&gt;
&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;插入&lt;/td&gt;
&lt;td&gt;add(e)&lt;/td&gt;
&lt;td&gt;offer(e)&lt;/td&gt;
&lt;td&gt;put(e)&lt;/td&gt;
&lt;td&gt;offer(e, time, unit)&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;移除&lt;/td&gt;
&lt;td&gt;remove()&lt;/td&gt;
&lt;td&gt;poll()&lt;/td&gt;
&lt;td&gt;take()&lt;/td&gt;
&lt;td&gt;poll(time, unit)&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;检查&lt;/td&gt;
&lt;td&gt;element()&lt;/td&gt;
&lt;td&gt;peek()&lt;/td&gt;
&lt;td&gt;不可用&lt;/td&gt;
&lt;td&gt;不可用&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;​&lt;br/&gt;&lt;strong&gt;四组不同的行为方式解释&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;抛出异常&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;如果试图的操作无法立即执行，抛一个异常。&lt;/p&gt;
&lt;p&gt;如果试图的操作无法立即执行，返回一个特定的值(常常是 true / false)。&lt;/p&gt;
&lt;p&gt;如果试图的操作无法立即执行，该方法调用将会发生阻塞，直到能够执行。&lt;/p&gt;
&lt;p&gt;如果试图的操作无法立即执行，该方法调用将会发生阻塞，直到能够执行，但等待时间不会超过给定值。返回一个特定值以告知该操作是否成功(典型的是 true / false)。&lt;/p&gt;
&lt;h2 id=&quot;blockingqueue的实现类&quot;&gt;BlockingQueue的实现类&lt;/h2&gt;
&lt;ul&gt;&lt;li&gt;ArrayBlockingQueue：有界的阻塞队列（容量有限，必须在初始化的时候指定容量大小，容量大小指定后就不能再变化），内部实现是一个数组，以FIFO的方式存储数据，最新插入的对象是尾部，最新移除的对象是头部。&lt;/li&gt;
&lt;li&gt;DelayQueue：阻塞的是内部元素，DelayQueue中的元素必须实现一个接口——Delayed（存在于J.U.C下）。Delayed接口继承了Comparable接口，这是因为Delayed接口中的元素需要进行排序，一般情况下，都是按照Delayed接口中的元素过期时间的优先级进行排序。应用场景主要有：定时关闭连接、缓存对象、超时处理等。内部实现使用PriorityQueue和ReentrantLock。&lt;/li&gt;
&lt;li&gt;LinkedBlockingQueue：大小配置是可选的，如果初始化时指定了大小，则是有边界的；如果初始化时未指定大小，则是无边界的（其实默认大小是Integer类型的最大值）。内部实现时一个链表，以FIFO的方式存储数据，最新插入的对象是尾部，最新移除的对象是头部。&lt;/li&gt;
&lt;li&gt;PriorityBlockingQueue：带优先级的阻塞队列，无边界，但是有排序规则，允许插入空对象(也就是null)。所有插入的对象必须实现Comparable接口，队列优先级的排序规则就是按照对Comparable接口的实现来定义的。可以从PriorityBlockingQueue中获得一个迭代器Iterator，但这个迭代器并不保证按照优先级的顺序进行迭代。&lt;/li&gt;
&lt;li&gt;SynchronousQueue：队列内部仅允许容纳一个元素，当一个线程插入一个元素后，就会被阻塞，除非这个元素被另一个线程消费。因此，也称SynchronousQueue为同步队列。SynchronousQueue是一个无界非缓存的队列。准确的说，它不存储元素，放入元素只有等待取走元素之后，才能再次放入元素。&lt;/li&gt;
&lt;/ul&gt;&lt;h2 id=&quot;写在最后&quot;&gt;写在最后&lt;/h2&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;如果觉得文章对你有点帮助，请微信搜索并关注「 &lt;strong&gt;冰河技术&lt;/strong&gt; 」微信公众号，跟冰河学习高并发编程技术。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;最后，附上并发编程需要掌握的核心技能知识图，祝大家在学习并发编程时，少走弯路。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20200414200720706.jpg&quot; alt=&quot;sandahexin_20200322&quot;/&gt;&lt;/p&gt;
</description>
<pubDate>Fri, 17 Apr 2020 15:54:00 +0000</pubDate>
<dc:creator>冰河团队</dc:creator>
<og:description>写在前面 最近，有不少网友留言提问：在Java的并发编程中，有个BlockingQueue，它是个阻塞队列，为何要在并发编程里使用BlockingQueue呢？好吧，今天，就临时说一下Blocking</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/binghe001/p/12723469.html</dc:identifier>
</item>
<item>
<title>Java入门系列之线程池ThreadPoolExecutor原理分析思考（十五） - Jeffcky</title>
<link>http://www.cnblogs.com/CreateMyself/p/12639215.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/CreateMyself/p/12639215.html</guid>
<description>&lt;h2&gt;前言&lt;/h2&gt;
&lt;p&gt;关于线程池原理分析请参看《&lt;a title=&quot;从源码的角度解析线程池运行原理&quot; href=&quot;http://objcoding.com/2019/04/25/threadpool-running/&quot;&gt;http://objcoding.com/2019/04/25/threadpool-running/&lt;/a&gt;》，建议对原理不太了解的童鞋先看下此文然后再来看本文，这里通过对原理的学习我谈谈对线程池的理解，若有错误之处，还望批评指正。&lt;/p&gt;
&lt;h2&gt;线程池思考&lt;/h2&gt;
&lt;p&gt;线程池我们可认为是准备好执行应用程序级任务的预先实例化的备用线程集合，线程池通过同时运行多个任务来提高性能，同时防止线程创建过程中的时间和内存开销，例如，一个Web服务器在启动时实例化线程池，这样当客户端请求进入时，它就不会花时间创建线程，与为每个任务都创建线程相比，线程池通过避免一次无限创建线程来避免资源（处理器，内核，内存等）用尽，创建一定数量的线程后，通常将多余的任务放在等待队列中，直到有线程可用于新任务。下面我们通过一个简单的例子来概括线程池原理，如下：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;46&quot;&gt;
&lt;pre&gt;
    &lt;span&gt;public&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; &lt;span&gt;void&lt;/span&gt;&lt;span&gt; main(String[] args) {

        ArrayBlockingQueue&lt;/span&gt;&amp;lt;Runnable&amp;gt; arrayBlockingQueue = &lt;span&gt;new&lt;/span&gt; ArrayBlockingQueue&amp;lt;&amp;gt;(5&lt;span&gt;);

        ThreadPoolExecutor poolExecutor &lt;/span&gt;=
                &lt;span&gt;new&lt;/span&gt; ThreadPoolExecutor(2&lt;span&gt;,
                        &lt;/span&gt;5&lt;span&gt;, Long.MAX_VALUE, TimeUnit.NANOSECONDS, arrayBlockingQueue);

        &lt;/span&gt;&lt;span&gt;for&lt;/span&gt; (&lt;span&gt;int&lt;/span&gt; i = 0; i &amp;lt; 11; i++&lt;span&gt;) {
            &lt;/span&gt;&lt;span&gt;try&lt;/span&gt;&lt;span&gt; {
                poolExecutor.execute(&lt;/span&gt;&lt;span&gt;new&lt;/span&gt;&lt;span&gt; Task());
            } &lt;/span&gt;&lt;span&gt;catch&lt;/span&gt;&lt;span&gt; (RejectedExecutionException ex) {
                System.out.println(&lt;/span&gt;&quot;拒绝任务 = &quot; + (i + 1&lt;span&gt;));
            }
            printStatus(i &lt;/span&gt;+ 1&lt;span&gt;, poolExecutor);
        }
    }

    &lt;/span&gt;&lt;span&gt;static&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; printStatus(&lt;span&gt;int&lt;/span&gt;&lt;span&gt; taskSubmitted, ThreadPoolExecutor e) {
        StringBuilder s &lt;/span&gt;= &lt;span&gt;new&lt;/span&gt;&lt;span&gt; StringBuilder();
        s.append(&lt;/span&gt;&quot;工作池大小 = &quot;&lt;span&gt;)
                .append(e.getPoolSize())
                .append(&lt;/span&gt;&quot;, 核心池大小 = &quot;&lt;span&gt;)
                .append(e.getCorePoolSize())
                .append(&lt;/span&gt;&quot;, 队列大小 = &quot;&lt;span&gt;)
                .append(e.getQueue().size())
                .append(&lt;/span&gt;&quot;, 队列剩余容量 = &quot;&lt;span&gt;)
                .append(e.getQueue().remainingCapacity())
                .append(&lt;/span&gt;&quot;, 最大池大小 = &quot;&lt;span&gt;)
                .append(e.getMaximumPoolSize())
                .append(&lt;/span&gt;&quot;, 提交任务数 = &quot;&lt;span&gt;)
                .append(taskSubmitted);

        System.out.println(s.toString());
    }

    &lt;/span&gt;&lt;span&gt;static&lt;/span&gt; &lt;span&gt;class&lt;/span&gt; Task &lt;span&gt;implements&lt;/span&gt;&lt;span&gt; Runnable {

        @Override
        &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt;&lt;span&gt; run() {
            &lt;/span&gt;&lt;span&gt;while&lt;/span&gt; (&lt;span&gt;true&lt;/span&gt;&lt;span&gt;) {
                &lt;/span&gt;&lt;span&gt;try&lt;/span&gt;&lt;span&gt; {
                    Thread.sleep(&lt;/span&gt;1000000&lt;span&gt;);
                } &lt;/span&gt;&lt;span&gt;catch&lt;/span&gt;&lt;span&gt; (InterruptedException e) {
                    &lt;/span&gt;&lt;span&gt;break&lt;/span&gt;&lt;span&gt;;
                }
            }
        }
    }&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/589642/202004/589642-20200411211753795-380354087.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;如上例子很好的阐述了线程池基本原理，我们声明一个有界队列（容量为5），实例化线程池的核心池大小为2，最大池大小为10，创建线程没有自定义实现，默认通过线程池工厂创建，拒绝策略为默认，提交11个任务。&lt;span&gt;在启动线程池时，默认情况下它将以无线程启动，当我们提交第一个任务时，将产生第一个工作线程，并将任务移交给该线程，只要当前工作线程数小于配置的&lt;span class=&quot;hh il&quot;&gt;核心池大小，即使某些先前创建的核心线程可能处于空闲状态，也会为每个新提交的任务生成一个新的工作线程（注意：当工作线程池大小未超过核心池大小时以创建的Worker中的第一个任务执行即firstTask，而绕过了阻塞队列），若超过核心池大小会将任务放入阻塞队列，一旦阻塞队列满后将重新创建线程任务，若任务超过最大线程池大小将执行拒绝策略。当阻塞队列为无界队列（如LinkedBlockingQueue），很显然设置的最大池大小将无效。&lt;span&gt;我们再来阐述下，&lt;/span&gt;&lt;span&gt;当工作线程数达到核心池大小时，若此时提交的任务越来越多，线程池的具体表现行为是什么呢？&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;blockquote readability=&quot;11&quot;&gt;
&lt;p&gt;&lt;span&gt;&lt;span class=&quot;hh il&quot;&gt;&lt;span&gt;1、只要有任何空闲的核心线程（先前创建的工作线程，但已经完成分配的任务），它们将接管提交的新任务并执行。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;span class=&quot;hh il&quot;&gt;&lt;span&gt;2、&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;如果没有可用的空闲核心线程，则每个提交的新任务都将进入已定义的工作队列中，直到有一个核心线程可以处理它为止。如果工作队列已满，但仍然没有足够的空闲核心线程来处理任务，那么线程池将恢复而创建新的工作线程，新任务将由它们来执行。 一旦工作线程数达到最大池大小，线程池将再次停止创建新的工作线程，并且在此之后提交的所有任务都将被拒绝。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;由上述2我们知道，一旦达到核心线程大小就会进入阻塞队列（阻塞队列未满），我们可认为这是一种执行阻塞队列优先的机制，那我们是不是可以思考一个问题：何不创建非核心线程来扩展线程池大小而不是进入阻塞队列，当达到最大池大小时才进入阻塞队列进行排队，这种方式和默认实现方式在效率和性能上是不是可能会更好呢？ 但是从另外一个层面来讲，既然不想很快进入阻塞队列，那么何不将指定的核心池大小进行扩展大一些呢？我们知道线程数越多那么将导致明显的数据争用问题，也就是说在非峰值系统中的线程数会很多，所以在峰值系统中通过创建非核心线程理论上是不是能够比默认立即进入阻塞队列具有支撑规模化的任务更加具有性能上的优势呢？那么我们怎样才能修改默认操作呢？我们首先来看看在执行任务时的操作&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;38&quot;&gt;
&lt;pre&gt;
&lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt;&lt;span&gt; execute(Runnable command) {
    &lt;/span&gt;&lt;span&gt;if&lt;/span&gt; (command == &lt;span&gt;null&lt;/span&gt;&lt;span&gt;)
        &lt;/span&gt;&lt;span&gt;throw&lt;/span&gt; &lt;span&gt;new&lt;/span&gt;&lt;span&gt; NullPointerException();

    &lt;/span&gt;&lt;span&gt;int&lt;/span&gt; c =&lt;span&gt; ctl.get();
    &lt;/span&gt;&lt;span&gt;if&lt;/span&gt; (workerCountOf(c) &amp;lt;&lt;span&gt; corePoolSize) {
        &lt;/span&gt;&lt;span&gt;if&lt;/span&gt; (addWorker(command, &lt;span&gt;true&lt;/span&gt;&lt;span&gt;))
            &lt;/span&gt;&lt;span&gt;return&lt;/span&gt;&lt;span&gt;;
        c &lt;/span&gt;=&lt;span&gt; ctl.get();
    }
    &lt;/span&gt;&lt;span&gt;if&lt;/span&gt; (isRunning(c) &amp;amp;&amp;amp;&lt;span&gt; workQueue.offer(command)) {
        &lt;/span&gt;&lt;span&gt;int&lt;/span&gt; recheck =&lt;span&gt; ctl.get();
        &lt;/span&gt;&lt;span&gt;if&lt;/span&gt; (! isRunning(recheck) &amp;amp;&amp;amp;&lt;span&gt; remove(command))
            reject(command);
        &lt;/span&gt;&lt;span&gt;else&lt;/span&gt; &lt;span&gt;if&lt;/span&gt; (workerCountOf(recheck) == 0&lt;span&gt;)
            addWorker(&lt;/span&gt;&lt;span&gt;null&lt;/span&gt;, &lt;span&gt;false&lt;/span&gt;&lt;span&gt;);
    }
    &lt;/span&gt;&lt;span&gt;else&lt;/span&gt; &lt;span&gt;if&lt;/span&gt; (!addWorker(command, &lt;span&gt;false&lt;/span&gt;&lt;span&gt;))
        reject(command);
    }
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;第一步得到当前工作线程数若小于核心池大小，那么将创建基于核心池的线程然后执行任务，这一点我们没毛病，第二步若工作线程大小超过核心池大小，若当前线程正处于运行状态且将其任务放到阻塞队列中，若失败进行第三步创建非核心池线程，通过源码分析得知，若核心池中线程即使有空闲线程也会创建线程执行任务，那么我们是不是可以得到核心池中是否有空闲的线程呢，若有然后才尝试使其进入阻塞队列，所以我们需要重写阻塞队列中的offer方法，添加一个是否有空闲核心池的线程，让其接待任务。所以我们继承上述有界阻塞队列，如下：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;35&quot;&gt;
&lt;pre&gt;
&lt;span&gt;public&lt;/span&gt; &lt;span&gt;class&lt;/span&gt; CustomArrayBlockingQueue&amp;lt;E&amp;gt; &lt;span&gt;extends&lt;/span&gt;&lt;span&gt; ArrayBlockingQueue {

    &lt;/span&gt;&lt;span&gt;private&lt;/span&gt; &lt;span&gt;final&lt;/span&gt; AtomicInteger idleThreadCount = &lt;span&gt;new&lt;/span&gt;&lt;span&gt; AtomicInteger();

    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; CustomArrayBlockingQueue(&lt;span&gt;int&lt;/span&gt;&lt;span&gt; capacity) {
        &lt;/span&gt;&lt;span&gt;super&lt;/span&gt;&lt;span&gt;(capacity);
    }

    @Override
    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;boolean&lt;/span&gt;&lt;span&gt; offer(Object o) {
        &lt;/span&gt;&lt;span&gt;return&lt;/span&gt; idleThreadCount.get() &amp;gt; 0 &amp;amp;&amp;amp; &lt;span&gt;super&lt;/span&gt;&lt;span&gt;.offer(o);
    }
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;但是不幸的是，通过对线程池源码的分析，我们并不能够得到空闲的核心池的线程，但是我们可以跟踪核心池中的空闲线程，在获取任务方法中如下：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;36&quot;&gt;
&lt;pre&gt;
&lt;span&gt;boolean&lt;/span&gt; timed = &lt;span&gt;allowCoreThreadTimeOut || wc &amp;gt; corePoolSize;&lt;/span&gt;

&lt;span&gt;if&lt;/span&gt; ((wc &amp;gt; maximumPoolSize || (timed &amp;amp;&amp;amp;&lt;span&gt; timedOut))
    &lt;/span&gt;&amp;amp;&amp;amp; (wc &amp;gt; 1 ||&lt;span&gt; workQueue.isEmpty())) {
    &lt;/span&gt;&lt;span&gt;if&lt;/span&gt;&lt;span&gt; (compareAndDecrementWorkerCount(c))
        &lt;/span&gt;&lt;span&gt;return&lt;/span&gt; &lt;span&gt;null&lt;/span&gt;&lt;span&gt;;
    &lt;/span&gt;&lt;span&gt;continue&lt;/span&gt;&lt;span&gt;;
}

&lt;/span&gt;&lt;span&gt;try&lt;/span&gt;&lt;span&gt; {
    &lt;span&gt;Runnable r &lt;/span&gt;&lt;/span&gt;&lt;span&gt;= timed ?
        workQueue.poll(keepAliveTime, TimeUnit.NANOSECONDS) :
        workQueue.take();
    &lt;/span&gt;&lt;span&gt;if&lt;/span&gt; (r != &lt;span&gt;null&lt;/span&gt;&lt;span&gt;)
        &lt;/span&gt;&lt;span&gt;return&lt;/span&gt;&lt;span&gt; r;
    timedOut &lt;/span&gt;= &lt;span&gt;true&lt;/span&gt;&lt;span&gt;;
} &lt;/span&gt;&lt;span&gt;catch&lt;/span&gt;&lt;span&gt; (InterruptedException retry) {
    timedOut &lt;/span&gt;= &lt;span&gt;false&lt;/span&gt;&lt;span&gt;;
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;如上截取获取任务的核心，若工作线程大小大于核心池大小时，默认情况下会进入阻塞队列此时通过pool获取阻塞队列中的任务，若工作线程大小小于核心池大小时，此时会调用take方法获从阻塞队列中获取可用的任务，此时说明当前核心池线程处于空闲状态，&lt;span&gt;如果队列中没有任务，则线程将在此调用时会阻塞，直到有可用的任务为止，&lt;/span&gt;&lt;span&gt;因此核心池线程仍然处于空闲状态，所以我们增加上述计数器，否则&lt;/span&gt;&lt;span&gt;，调用方法返回，此时&lt;/span&gt;&lt;span&gt;该线程不再处于空闲状态，我们可以减少计数器，重写take方法，如下：&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;33&quot;&gt;
&lt;pre&gt;
&lt;span&gt;@Override
&lt;/span&gt;&lt;span&gt;public&lt;/span&gt; Object take() &lt;span&gt;throws&lt;/span&gt;&lt;span&gt; InterruptedException {
    idleThreadCount.incrementAndGet();
    Object take &lt;/span&gt;= &lt;span&gt;super&lt;/span&gt;&lt;span&gt;.take();
    idleThreadCount.decrementAndGet();
    &lt;/span&gt;&lt;span&gt;return&lt;/span&gt;&lt;span&gt; take;
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span&gt;&lt;span&gt;接下来我们再来考虑timed为true的情况，&lt;/span&gt;&lt;span&gt;在这种情况下，线程将&lt;/span&gt;&lt;span&gt;使用&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;hh il&quot;&gt;&lt;span&gt;&lt;span&gt;poll&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;方法，&lt;/span&gt;&lt;span&gt;很显然，进入&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;hh il&quot;&gt;&lt;span&gt;&lt;span&gt;poll&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;方法的&lt;/span&gt;&lt;span&gt;任何线程&lt;/span&gt;&lt;span&gt;当前都处于空闲状态，因此我们可以在工作队列中重写此方法的实现，&lt;/span&gt;&lt;span&gt;以在开始时&lt;/span&gt;&lt;span&gt;增加&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;hh il&quot;&gt;&lt;span&gt;&lt;span&gt;计数器，&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;然后，我们可以调用实际的&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;hh il&quot;&gt;&lt;span&gt;&lt;span&gt;poll&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;方法，这可能导致以下两种情况之，&lt;span&gt;如果队列中没有任务，则线程将等待此调用以提供所提供的超时，然后返回null。&lt;/span&gt;&lt;span&gt;到此时，线程将超时，并将很快从池中退出，从而将空闲线程数减少1，因此我们可以在此时减少计数器，&lt;/span&gt;&lt;span&gt;否则由方法调用返回，&lt;/span&gt;&lt;span&gt;因此该线程不再处于空闲状态，此时我们也可以减少计数器。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;36&quot;&gt;
&lt;pre&gt;
&lt;span&gt;@Override
&lt;/span&gt;&lt;span&gt;public&lt;/span&gt; Object poll(&lt;span&gt;long&lt;/span&gt; timeout, TimeUnit unit) &lt;span&gt;throws&lt;/span&gt;&lt;span&gt; InterruptedException {
    idleThreadCount.incrementAndGet();
    Object poll &lt;/span&gt;= &lt;span&gt;super&lt;/span&gt;&lt;span&gt;.poll(timeout, unit);
    idleThreadCount.decrementAndGet();
    &lt;/span&gt;&lt;span&gt;return&lt;/span&gt;&lt;span&gt; poll;
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;通过上述我们对offer、pool、take方法的重写，使得在没有基于核心池的空闲线程进行扩展非核心线程，还未结束，若达到了最大池大小，此时我们需要将其添加到阻塞队列中排队，所以最终使用我们自定义的阻塞队列，并使用自定义的拒绝策略，如下：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;43&quot;&gt;
&lt;pre&gt;
CustomArrayBlockingQueue&amp;lt;Runnable&amp;gt; arrayBlockingQueue = &lt;span&gt;new&lt;/span&gt; CustomArrayBlockingQueue&amp;lt;&amp;gt;(5&lt;span&gt;);

ThreadPoolExecutor poolExecutor &lt;/span&gt;=
        &lt;span&gt;new&lt;/span&gt; ThreadPoolExecutor(10&lt;span&gt;,
                &lt;/span&gt;100&lt;span&gt;, Long.MAX_VALUE, TimeUnit.NANOSECONDS, arrayBlockingQueue
                , Executors.defaultThreadFactory(), (r, executor) &lt;/span&gt;-&amp;gt;&lt;span&gt; {
            &lt;/span&gt;&lt;span&gt;if&lt;/span&gt; (!&lt;span&gt;executor.getQueue().add(r)) {
                System.out.println(&lt;/span&gt;&quot;拒绝任务&quot;&lt;span&gt;);
            }
        });

&lt;/span&gt;&lt;span&gt;for&lt;/span&gt; (&lt;span&gt;int&lt;/span&gt; i = 0; i &amp;lt; 150; i++&lt;span&gt;) {
    &lt;/span&gt;&lt;span&gt;try&lt;/span&gt;&lt;span&gt; {
        poolExecutor.execute(&lt;/span&gt;&lt;span&gt;new&lt;/span&gt;&lt;span&gt; Task());
    } &lt;/span&gt;&lt;span&gt;catch&lt;/span&gt;&lt;span&gt; (RejectedExecutionException ex) {
        System.out.println(&lt;/span&gt;&quot;拒绝任务 = &quot; + (i + 1&lt;span&gt;));
    }
    printStatus(i &lt;/span&gt;+ 1&lt;span&gt;, poolExecutor);
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;上述我们实现自定义的拒绝策略，将拒绝的任务放入到阻塞队列中，若阻塞队列已满而不能再接收新的任务，我们将调用默认的拒绝策略或者是其他处理程序，所以在将任务添加到阻塞队列中即调用add方法时，我们还需要重写add方法，如下：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;32&quot;&gt;
&lt;pre&gt;
&lt;span&gt;@Override
&lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;boolean&lt;/span&gt;&lt;span&gt; add(Object o) {
    &lt;/span&gt;&lt;span&gt;return&lt;/span&gt; &lt;span&gt;super&lt;/span&gt;&lt;span&gt;.offer(o);
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/589642/202004/589642-20200417233317888-463454837.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;h2&gt;总结&lt;/h2&gt;
&lt;p&gt;以上详细内容只是针对线程池的默认实现而引发的思考，通过如上方式是否能够对于规模化的任务处理起来在性能上有一定改善呢？可能也有思虑不周全的地方，暂且分析于此。&lt;/p&gt;
</description>
<pubDate>Fri, 17 Apr 2020 15:47:00 +0000</pubDate>
<dc:creator>Jeffcky</dc:creator>
<og:description>前言 关于线程池原理分析请参看《http://objcoding.com/2019/04/25/threadpool-running/》，建议对原理不太了解的童鞋先看下此文然后再来看本文，这里通过对原</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/CreateMyself/p/12639215.html</dc:identifier>
</item>
<item>
<title>深入探讨单例模式 - yxming</title>
<link>http://www.cnblogs.com/yxm2020/p/12723418.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/yxm2020/p/12723418.html</guid>
<description>&lt;blockquote readability=&quot;5.7081545064378&quot;&gt;
&lt;p&gt;最近学习了一下单例模式，看bilibili up主“狂神说Java”讲完后，发现大部分博客都少了一个很有趣的环节，不分享出来实在是太可惜了，原视频 &lt;a href=&quot;https://www.bilibili.com/video/BV1K54y197iS&quot;&gt;https://www.bilibili.com/video/BV1K54y197iS&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;1、了解单例&quot;&gt;1、了解单例&lt;/h2&gt;
&lt;pre&gt;
&lt;code&gt;这个部分小部分我相信很多博客都讲的很好，我就尽量精简了
&lt;/code&gt;
&lt;/pre&gt;
&lt;ol&gt;&lt;li&gt;注意：&lt;/li&gt;
&lt;/ol&gt;&lt;ul&gt;&lt;li&gt;单例类只能有一个实例&lt;/li&gt;
&lt;li&gt;这个实例由自己创建&lt;/li&gt;
&lt;li&gt;这个实例必须提供给外界&lt;/li&gt;
&lt;/ul&gt;&lt;ol start=&quot;2&quot;&gt;&lt;li&gt;关键：&lt;strong&gt;构造器私有化&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;创建方法:&lt;/li&gt;
&lt;/ol&gt;&lt;ul&gt;&lt;li&gt;饿汉式&lt;/li&gt;
&lt;li&gt;懒汉式&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;总结：我认为创建方法可以归根于两种，一种是饿汉式，我在类的加载的时候就创建；还有一种懒汉式，只有在我需要的时候才去创建&lt;/p&gt;
&lt;h2 id=&quot;2、思路及实现&quot;&gt;2、思路及实现&lt;/h2&gt;
&lt;p&gt;【饿汉模式最基本的实现】&lt;/p&gt;
&lt;p&gt;在类加载的时候就已经创建了，这个模式下，线程是安全的，不同的线程拿到的都是同一个实例，但是，这个也存在空间浪费的问题，我不需要的时候你也加载了。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;//饿汉模式
 public class HungerSingle {
    private static HungerSingle single = new HungerSingle();
    //构造器私有，外界不能通过构造方法new对象，保证唯一
    private HungerSingle() {
    }
    //提供外界获得该单例的方法,注意方法只能是static方法，因为没有类实例
    public static HungerSingle getInstance(){
        return single;
    }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;【懒汉模式最基本的实现】&lt;/p&gt;
&lt;p&gt;为了解决上述那个空间浪费问题，这时候懒汉模式就起作用了，你需要我的时候我再去创建这个实例&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;//懒汉模式
public class LazySingle {
    private static LazySingle single;
    //构造器私有化，禁止外部new生成对象
    private LazySingle(){
    }
    //外界获得该单例的方法
    public static LazySingle getInstance(){
        if(single == null){
            single = new LazySingle();
        }
        return single;
    }
 }
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;一位热心前辈的评论：“像你这样写单例，在我们公司是要被开除的。”&lt;br/&gt;趁我还是学生，怀着以后不被开除的心情，继续学习下去&lt;br/&gt;原来懒汉模式下，单例线程是不安全的。&lt;/p&gt;
&lt;p&gt;怎么测试呢？如下&lt;/p&gt;
&lt;p&gt;【测试懒汉模式线程不安全】&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;//1、构造器
private LazySingle(){
    System.out.println(Thread.currentThread().getName());
}

//创建十个线程
for (int i = 0; i &amp;lt; 10; i++) {
    new Thread(()-&amp;gt;{
         Singleton2.getInstance();
    }).start();
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;此时你会发现，构造方法调用了不止一次，说明没有实现预期的单例&lt;/p&gt;
&lt;p&gt;平时我们解决线程不安全的方法：不就是线程不安全嘛，那好办，加锁&lt;/p&gt;
&lt;p&gt;【双重检测锁/DCL】&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;public class DCLSingle {
    private static DCLSingle single;
    private DCLSingle(){
    }
    public static DCLSingle getInstance(){
        //第一次判断，没有这个对象才加锁
        if(single == null){
            //哪个需要保护，就锁哪个
            synchronized (DCLSingle.class){
                //第二次判断，没有就实例化
                if(single == null){
                    single = new DCLSingle();
                }
            }
        }
        return single;
    }

}

&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;仔细和别人代码一比对，发现我少了个volatile关键字，这是啥玩意？&lt;br/&gt;不懂就问。&lt;/p&gt;
&lt;p&gt;【volatile】&lt;br/&gt;为了避免指令重排&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;//上述代码声明上面加上volatile关键字
 private volatile static DCLSingle single;
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;啥是volatile ？&lt;/p&gt;
&lt;p&gt;引用自别人博客&lt;br/&gt;&lt;a href=&quot;https://www.cnblogs.com/YLsY/p/11295732.html&quot;&gt;https://www.cnblogs.com/YLsY/p/11295732.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;加volatile是为了出现脏读的出现，保证操作的原子性&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;1、原子性操作：不可再分割的操作
例如：single = new DCLSingle();
其实就是两步操作：
①new DCLSingle();//开辟堆内存
②singl指向对内存

2、脏读
Java内存模型规定所有的变量都是存在主存当中，每个线程都有自己的工作内存。
线程对变量的所有操作都必须在工作内存中进行，而不能直接对主存进行操作。
并且每个线程不能访问其他线程的工作内存。
变量的值何时从线程的工作内存写回主存，无法确定。

3、指令重排
single = new DCLSingle();
先执行②
后执行①
//先指向堆内存，还未完成构造


【模拟情况】
①线程1执行，在自己的工作内存定义引用，先指向堆内存，还未构造完成
②此时线程2执行，它进行判断，引用已经指向了内存，所以线程2，认为构造完成，实际还未构造完成
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;还有一种差点忘记说了，也是菜鸟教程说建议使用的方式&lt;/p&gt;
&lt;p&gt;【静态内部类实现单例】&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;public class Singleton {
    private Singleton(){}
    private static class SingletonHolder {
        private static final Singleton INSTANCE = new Singleton();
    }
    private Singleton getInstance(){
        return SingletonHolder .INSTANCE;
    }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;你会发现它和前面讲的普通饿汉式很像，我把它也归于饿汉式一类，因为它也是直接就new Singleton，但是它却有着懒加载的效果，而这种方式是 Singleton 类被装载了，INSTANCE不一定被初始化。因为 SingletonHolder 类没有被主动使用，只有通过显式调用 getInstance 方法时，才会显式装载 SingletonHolder 类，从而实例化 INSTANCE。&lt;/p&gt;
&lt;p&gt;【建议】建议使用静态内部类实现&lt;/p&gt;
&lt;br/&gt;&lt;h2 id=&quot;3、如何破化单例（其它大部分博客没有的内容）&quot;&gt;3、如何破化单例（其它大部分博客没有的内容）&lt;/h2&gt;
&lt;p&gt;在这里感谢b站up【狂神说java】&lt;/p&gt;
&lt;p&gt;在面试官面前装逼的时候来了&lt;/p&gt;
&lt;p&gt;java语言实现动态化的灵魂——反射，说：没有什么是我不能改变的，看我来如何操作。&lt;/p&gt;
&lt;p&gt;【反射破坏单例】&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;public class DCLSingle {
    private static DCLSingle single;
    private DCLSingle(){
    }
    public static DCLSingle getInstance(){
        //第一次判断，没有这个对象才加锁
        if(single == null){
            //哪个需要保护，就锁哪个
            synchronized (DCLSingle.class){
                //第二次判断，没有就实例化
                if(single == null){
                    single = new DCLSingle();
                }
            }
        }
        return single;
    }
    
    //通过反射破化单例
    public static void main(String[] args) throws Exception {
        LazySingle single = LazySingle.getInstance();
        Constructor&amp;lt;LazySingle&amp;gt; constructor = LazySingle.class.getDeclaredConstructor();
        constructor.setAccessible(true);
        LazySingle single1 = constructor.newInstance();
        System.out.println(single == single1);//false
    }

}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;得到单例类的构造器，然后通过newInstance的方法创建对象，很明显破化了单例&lt;/p&gt;
&lt;p&gt;【改进代码，防止你搞破化】&lt;/p&gt;
&lt;p&gt;既然这次你是通过得到构造器破化的，那我给构造器加个方法,如果你已经创建了实例，那就抛出异常&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;private LazySingle(){
    synchronized(LazySingle.class){
        if(single!=null){
            throw new RuntimeException(&quot;破坏失败&quot;);
        }
    }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;但是这个又有问题，这里的判断是private static DCLSingle single 是否有值，如果我们都不通过getInstance()方法创建对象，而是这样&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;public static void main(String[] args) throws Exception {
 //   LazySingle single = LazySingle.getInstance();
    Constructor&amp;lt;LazySingle&amp;gt; constructor = LazySingle.class.getDeclaredConstructor();
    constructor.setAccessible(true);
    
    //注意：这里的对象不是单例类中里面属性的那个对象
    LazySingle single = constructor.newInstance();
    LazySingle single1 = constructor.newInstance();
    System.out.println(single == single1);//false
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;这里根本不会抛出异常，而是又破坏了单例&lt;/p&gt;
&lt;p&gt;【继续改进代码，防止搞破化】&lt;br/&gt;简直就是相爱相杀呀，我们可以利用红路灯原理，防止破化&lt;br/&gt;改进构造方法&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;//加个标志
private static String sign = &quot;password&quot;;
private LazySingle(){
    synchronized(LazySingle.class){
        if(single!=null || !&quot;password&quot;.equals(sign)){
            throw new RuntimeException(&quot;破坏失败&quot;);
        }else{
            sign = &quot;no&quot;;
        }
    }
    
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;此刻你通过上述main()方法里面的内容测试，发现又会抛出异常。然而我们能通过反射获得构造方法，那我们同样也能通过反射获取对象的属性以及值吧&lt;/p&gt;
&lt;p&gt;【再度破化】&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;public static void main(String[] args) throws Exception {
    Constructor&amp;lt;LazySingle&amp;gt; constructor = LazySingle.class.getDeclaredConstructor();
    constructor.setAccessible(true);
    Field field = LazySingle.class.getDeclaredField(&quot;sign&quot;);
    //此处省略通过反射获取该属性的类型和方法....
    LazySingle single1 = constructor.newInstance();
    //重新变回原标志位
    field.set(&quot;sign&quot;,&quot;password&quot;);
    LazySingle single2 = constructor.newInstance();
    System.out.println(single2 == single1);//false
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;又被破化了&lt;/p&gt;
&lt;p&gt;【再次改进】&lt;/p&gt;
&lt;p&gt;我们将目光抛向枚举，&lt;br/&gt;jdk1.5之后，出现枚举&lt;br/&gt;利用枚举实现不仅能避免多线程同步问题，而且还自动支持序列化机制，防止反序列化重新创建新的对象，&lt;strong&gt;&lt;mark&gt;绝对防止多次实例化&lt;/mark&gt;&lt;/strong&gt;（菜鸟教程官方术语）&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;public enum Singleton {  
    INSTANCE;  
    public Singleton getInstance() {  
        return INSTANCE
    }  
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;【反射能破化枚举的单例吗？】&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;我们先要了解枚举是啥，它的底层是怎么实现的&lt;/li&gt;
&lt;li&gt;我们会发现枚举本身就是一个类&lt;/li&gt;
&lt;li&gt;通过反编译工具，查看枚举底层的构造方法&lt;/li&gt;
&lt;li&gt;通过反射获取构造方法&lt;/li&gt;
&lt;li&gt;重复上述反射测试&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;我们最终可以发现反射不能破化枚举的单例&lt;/p&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;这种实现方式还没有被广泛采用，但这是实现单例模式的最佳方法。它更简洁，自动支持序列化机制，绝对防止多次实例化。(菜鸟教程官方)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;【总结】太难了&lt;/p&gt;
</description>
<pubDate>Fri, 17 Apr 2020 15:40:00 +0000</pubDate>
<dc:creator>yxming</dc:creator>
<og:description>最近学习了一下单例模式，看bilibili up主“狂神说Java”讲完后，发现大部分博客都少了一个很有趣的环节，不分享出来实在是太可惜了，原视频 https://www.bilibili.com/v</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/yxm2020/p/12723418.html</dc:identifier>
</item>
<item>
<title>Netty是如何处理新连接接入事件的？ - dashuai的博客</title>
<link>http://www.cnblogs.com/kubixuesheng/p/12723391.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/kubixuesheng/p/12723391.html</guid>
<description>&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/682679/202004/682679-20200406115141856-666172333.png&quot; alt=&quot;&quot;/&gt; &lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://mmbiz.qpic.cn/mmbiz_png/PN8ICUJ8dHDmRjLkPglhLXZzdq024mCyxgorqM7Lq8R2TTiaSGicpaSamSW4V63XOwUMHJtKVZtgO2t4ef8kEfGw/640?wx_fmt=png&quot; alt=&quot;&quot; data-ratio=&quot;1&quot; data-type=&quot;png&quot; data-w=&quot;45&quot;/&gt;更多技术分享可关注我&lt;/p&gt;

&lt;p&gt;前面的分析从Netty服务端启动过程入手，一路走到了Netty的心脏——NioEventLoop，又总结了Netty的异步API和设计原理，现在回到Netty服务端本身，看看服务端对客户端新连接接入的处理是怎么样的过程。&lt;/p&gt;
&lt;p&gt;原文：​&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzU1NjY0NzI3OQ==&amp;amp;mid=2247484542&amp;amp;idx=1&amp;amp;sn=bfa8c7bf2dfb6c3edf19f6598a13ee77&amp;amp;chksm=fbc0927eccb71b68113a40c5b0d2ef955508ccc598465bb30daab6a70e56470af4f500250011#rd&quot; target=&quot;_blank&quot; data-itemshowtype=&quot;0&quot;&gt;Netty是如何处理新连接接入事件的？&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;首先，对于新连接接入，从NIO层面有一个宏观的印象：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;1、通过I/O多路复用器——Selector检测客户端新连接&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;对应到Netty，新连接通过服务端的NioServerSocketChannel（底层封装的JDK的ServerSocketChannel）绑定的I/O多路复用器（由NioEventLoop线程驱动）轮询OP_ACCEPT(=16)事件&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2、轮询到新连接，就创建客户端的Channel&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;对应到Netty就是NioSocketChannel（底层封装JDK的SocketChannel）&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;3、为新连接分配绑定新的Selector&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;对应到Netty，就是通过线程选择器，从它的第二个线程池——worker线程池中挑选一个NIO线，在这个线程中去执行将JDK的SocketChannel注册到新的Selector的流程，将Netty封装的NioSocketChannel作为附加对象也绑定到该Selector&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;4、向客户端Channel绑定的Selector注册I/O读、或者写事件&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;对应到Netty，就是默认注册读事件，因为Netty的设计理念是读优先。以后本条Channel的读写事件就由worker线程池中的NIO线程管理&lt;/p&gt;
&lt;p&gt;以上4步，其实就是对下面一段JDK NIO demo的抽象和封装，并解决了一些bug的过程，如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/682679/202004/682679-20200417232405321-575534649.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;接下来的几篇文章会逐步拆解每个步骤，并学习Netty的设计思路。&lt;/p&gt;

&lt;p&gt;前面分析过NioEventLoopGroup和线程池对应，NioEventLoop实例和NIO线程对应，一个EventLoop实例将由一个永远都不会改变的Thread驱动其内部的run方法（和Runnable的run不是一个）。&lt;/p&gt;
&lt;p&gt;简单说，Netty服务端创建的boss和worker就是两个线程池，对于一个服务器的端口，bossGroup里只会启动一个NIO线程用来处理该端口上的客户端新连接的检测和接入流程。&lt;/p&gt;
&lt;p&gt;具体的说，Netty会在服务端的Channel的pipeline上，默认创建一个新连接接入的handler，只用于服务端接入客户端新连接，而workerGroup里有多个NIO线程（默认2倍的CPU核数个），负责已建立的Channel上的读写事件的检测、注册或者处理，等操作。当boss线程池的那一个NIO线程检测到新连接后就可以稍做休息（或者继续检测处理新连接），此时worker线程池就开始忙碌，如下图所示：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/682679/202004/682679-20200417232558059-2023957936.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;细节回顾可以参考：&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzU1NjY0NzI3OQ==&amp;amp;mid=2247483814&amp;amp;idx=1&amp;amp;sn=46be72145789b08fdbbac8522a06bc5d&amp;amp;chksm=fbc097a6ccb71eb07c6c8bec5cc3bef8c3f4acd312c820a466de1ea1bf92123dedf9f94f97e1&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-itemshowtype=&quot;0&quot; data-linktype=&quot;2&quot;&gt;Netty的线程调度模型分析（1）&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;下面开始总结，boss线程和worker线程池之间是如何配合的。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;再看JDK的select方法&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;在总结之前，个人认为有必要先回顾JDK的select，必须正确理解I/O多路复用器——Selector上所谓的轮询一次，返回就绪的Channel数目的真正意义，即这个过程有一个前提是自从上次select后开始计算的。这样干巴巴的解释可能不太清楚，下面举个例子，比如有两个已经建立的Channel，分别是A和B，而且A和B分别注册到了一个Selector上，接着在该Selector调用select()：&lt;/p&gt;
&lt;ul class=&quot;list-paddingleft-2&quot; readability=&quot;0&quot;&gt;&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;第一次调用select()，发现只有A有I/O事件就绪，select会立即返回1，然后处理之&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;第二次调用select()，发现另一个通道B也有I/O事件就绪，此时select()还是返回1——即是自上次select后开始计算的&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;还有一点注意：如果第一次轮询后，对A没有做任何操作，那么就有两个就绪的Channel。&lt;/p&gt;
&lt;p&gt;另外还要知道，select返回后可通过其返回值判断有没有Channel就绪，如果有就绪的Channel，那么可以使用selectedKeys()方法拿到就绪的Channel及其一些属性。下面看selectedKeys()的使用：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;32&quot;&gt;
&lt;pre&gt;
Set&amp;lt;SelectionKey&amp;gt; selectedKeys = selector.selectedKeys();
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;当给Selector注册Channel时，调用的register()方法会返回一个SelectionKey对象，这个对象代表了注册到该Selector的Channel，可以遍历这个集合来访问就绪的通道。&lt;/p&gt;
&lt;p&gt;以上，前面的线程调度模型都分析过，回忆这个图：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/682679/202004/682679-20200417232723011-1588825585.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;细节回顾可以参考：&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzU1NjY0NzI3OQ==&amp;amp;mid=2247483840&amp;amp;idx=1&amp;amp;sn=d6e1e45f76ddf5b6aeb25b3cc7bc16c5&amp;amp;chksm=fbc097c0ccb71ed6c725878ac5bc85c9edb05c7944ec03c096eada9eca3c3b2b3cf1098468c9&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-itemshowtype=&quot;0&quot; data-linktype=&quot;2&quot;&gt;Netty的线程调度模型分析（2）&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzU1NjY0NzI3OQ==&amp;amp;mid=2247483884&amp;amp;idx=1&amp;amp;sn=170347e4d32a14952625dc7a23defd80&amp;amp;chksm=fbc097ecccb71efa7b6b45949c5d51e4288871d6a28fe9a4e2bbe5bf0a42b29f43d41741bb5b&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-itemshowtype=&quot;0&quot; data-linktype=&quot;2&quot;&gt;Netty的线程调度模型分析（3）&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;前面文章总结了NioEventLoopGroup实例化时，如果外部没有配置，那么会默认创建一个线程执行器——ThreadPerTaskExcutor，一个NioEventLoop组成的数组（线程池），还有一个线程选择器——chooser。&lt;/p&gt;
&lt;p&gt;又知道当实例化NioEventLoop并填充底层线程数组时，Netty会为每个NioEventLoop创建并绑定一个I/O多路复用器——Selector和一个异步任务队列——MPSCQ，接下来又总结了Netty的NioEventLoop线程启动的触发时机有两个：&lt;/p&gt;
&lt;ul class=&quot;list-paddingleft-2&quot; readability=&quot;1.5&quot;&gt;&lt;li readability=&quot;2&quot;&gt;
&lt;p&gt;宏观上，服务端绑定端口时会触发boss线程池里的一个NIO线程启动，即用户代码调用bind方法。如果深入bind方法内部，那么会发现NIO线程第一次启动的精确时机是为JDK的ServerSocketChannel注册I/O多路复用器的时候——Netty会封装这个注册逻辑为一个异步task，使用NIO线程驱动，如果没有启动，那么就启动之，以后的Channel绑定端口的逻辑也会被封装为异步task，复用已经启动的这个NIO线程&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;1&quot;&gt;
&lt;p&gt;新连接接入时会触发worker线程池里的NIO线程启动。线程池的线程选择器会为新连接绑定一个worker里的NIO线程，第一次接入或者线程池的线程还没完全启动完毕，就会顺势启动&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;总之，Netty服务端启动后，服务端的Channel已经绑定到了boss线程池的NIO线程中，并不断检测是否有OP_ACCEPT事件发生，直到检测出有该事件发生就处理之，即boss线程池里的NioEventLoop线程只做了两件事：&lt;/p&gt;
&lt;p&gt;1、轮询OP_ACCEPT事件&lt;/p&gt;
&lt;p&gt;2、检测到OP_ACCEPT事件后就处理该事件，处理过程其实就是客户端Channel（新连接）接入的过程&lt;/p&gt;
&lt;p&gt;下面继续回顾NioEventLoo线程的事件循环的核心方法——run，它在NIO线程启动时开始运行：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/682679/202004/682679-20200417232817094-1177272613.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;在这之前，先在run方法打断点：然后启动实验用的最小版Netty服务端的demo，之后分别在三个客户端使用telnet命令对其顺序发送3个请求，模拟客户端3个新连接接入的过程，下面进入run跟踪源码：&lt;/p&gt;
&lt;p&gt; &lt;img src=&quot;https://img2020.cnblogs.com/blog/682679/202004/682679-20200417232830793-731734254.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;1、首先调用Netty封装的select方法，前面分析过当有客户端新连接接入，即代表已经触发了OP_ACCEPT事件，Selector的select方法会立即返回1，如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/682679/202004/682679-20200417232846830-925975739.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;这里要理解JDK的select方法返回值到底是什么。select()方法会返回注册的interest的I/O事件已经就绪的那些通道的数目，抠字眼，首先得看是哪些Channel注册在了当前I/O多路复用器上，其次，看这些Channel上注册的interest的I/O事件是否就绪，如上代码的局部变量selectedKeys==1，但是我实验的客户端连接是3个，这里可能会有疑问，selectedKeys为何不是3呢？&lt;/p&gt;
&lt;p&gt;因为当前绑定在boss线程上的I/O多路复用器只注册了服务端的Channel，即底层只有一个ServerSocketChannel，且当前注册的interest的I/O事件只有OP_ACCEPT，故无论多少个新连接接入，这里都只会返回1。&lt;/p&gt;
&lt;p&gt;还有一个误区：不要认为Selector的select返回值是已准备就绪的Channel的总数，其实它返回的是从上一个select()调用后进入就绪状态的Channel的数量。&lt;/p&gt;
&lt;p&gt;继续分析：轮询出有感兴趣的I/O事件就绪的Channel后，会break循环，回到外部的run方法，开始处理这个I/O事件，这里就是处理新连接的接入事件,核心方法之前也分析过，就是processSelectedKeys：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/682679/202004/682679-20200417232854727-1680609703.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;在详细的细节可以参考：&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzU1NjY0NzI3OQ==&amp;amp;mid=2247484112&amp;amp;idx=1&amp;amp;sn=038b34862969e6627047607a886c9dcf&amp;amp;chksm=fbc094d0ccb71dc6df74a719391a00e95f3ffcf51b5d112f6ffdf8bbe74d981339e07c226725&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-itemshowtype=&quot;0&quot; data-linktype=&quot;2&quot;&gt;Netty的线程调度模型分析（7）&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzU1NjY0NzI3OQ==&amp;amp;mid=2247484140&amp;amp;idx=1&amp;amp;sn=585de89da3f596f99f20ad41211dee20&amp;amp;chksm=fbc094ecccb71dfa4b62ea460ffc44a1149fed52986bed58eacbd2e17a117468c35dbe62371b&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-itemshowtype=&quot;0&quot; data-linktype=&quot;2&quot;&gt;Netty的线程调度模型分析（8）&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;这个方法有两个变体，前面文章也分析过原因，我选择有代表性的processSelectedKeysOptimized，看里面的processSelectedKey(key,channel)方法，这才真正到了Netty处理I/O事件的方法入口，如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/682679/202004/682679-20200417232939613-1727252079.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt; 如下是processSelectedKey方法的实现：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/682679/202004/682679-20200417232947672-896790993.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;首先看黄色1处，取出ServerSocketChannel的unsafe对象，前面也总结过，Netty封装的Channel的底层都会有一个Unsafe对象与之绑定，Unsafe是个内部接口，聚合在Channel接口内部，作用是协助Channel进行网络I/O的操作，因为它的设计初衷就是Channel的内部辅助类，不应该被Netty的使用者调用，所以被命名为Unsafe，而不是说这个类的API都是不安全的。&lt;/p&gt;
&lt;p&gt;继续执行到黄色2处，会判断当前Channel是否打开，其实就是判断的ServerSocketChannel。一切顺利继续执行黄色3处，看到了熟悉的NIO API，下面专门看黄色3处后面的一堆代码：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/682679/202004/682679-20200417232958030-738468933.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;在黄色3处，k内部的readyOps集合是该Channel已经准备就绪的I/O操作的集合，OP_ACCEPT这个宏是16，所以这里的readyOps变量为16。 &lt;/p&gt;
&lt;p&gt;接着马上会执行到黄色4处的if判断逻辑，由于readyOps为16，这里通过判断，进入if内部，执行黄色5处的代码。该处逻辑是一个read操作，很好理解。当NioEventLoop的run方法里轮询到ServerSocketChannel的accept事件后，服务端第一步就是对其执行读操作，这是很自然的想法。因为这是服务端，所以下面会进入到NioMessageUnsafe实例的read方法：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/682679/202004/682679-20200417233020331-1142777744.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;在黄色1处，首先保证是NioEventLoop线程在执行，如果是外部线程执行的，那么无效。接下来，会获取服务端Channel的Config和默认创建的服务端Channel的pipeline。在黄色2处有一个RecvByteBufAllocator.Handle allocHandle变量，它获取了RecvByteBuf分配器Handle，顾名思义就是设置接收的缓冲区大小，简单说是通过二分算法获取一个不会浪费空间，但是又足够大小的缓冲区，是一种性能优化的策略，以后分析Netty内存图像时在深入。&lt;/p&gt;
&lt;p&gt;接着在黄色2处的下一行是一个重置配置的方法，目的是重置已累积的所有计数器，并为下一个读取循环读取多少消息/字节数据提供建议。Netty默认一次读取16个新连接，如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/682679/202004/682679-20200417233041231-2008910222.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;然后继续看NioMessageUnsafe实例的read方法，在黄色3处，进入一个do-while循环：&lt;/p&gt;
&lt;p&gt; &lt;img src=&quot;https://img2020.cnblogs.com/blog/682679/202004/682679-20200417233053595-370208442.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;首先调用doReadMessages方法，在do—while循环中读取一个个的客户端新连接，并将读取到的新连接用readBuf这个集合存储，readBuf就是NioMessageUnsafe类内部的一个普通的ArrayList。&lt;/p&gt;
&lt;p&gt;下面进入doReadMessages方法，如下该方法内部逻辑似曾相识。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/682679/202004/682679-20200417233108196-1265241813.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;首先，在黄色1处封装了JDK的NIO API，即获取客户端的socket——NIO对应的是SocketChannel，完成该操作意味着TCP/IP协议栈完成了TCP的三次握手，TCP的逻辑链路正式建立，然后，在黄色2处，Netty将客户端Channel封装为自己的客户端channel——NioSocketChannel。因为这里明确了是服务端在处理accept事件，故不需要反射创建NioSocketChannel，直接实例化即可，后续在详细分析Netty的客户端channel创建过程。最后，封装的Channel保存到readBuf这个ArrayList中，doReadMessages方法返回1。 &lt;/p&gt;
&lt;p&gt;回到上层的do-while循环：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/682679/202004/682679-20200417233128410-918193367.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;doReadMessages返回的localRead==1，说明本次读取新连接成功，do-while的一次循环读新连接完毕，会继续读下一个新连接，直到全部读完，或者达到阈值。也就是说Netty在读取新连接时也权衡了性能，如果连接太多，那么Netty不会一直卡在这里处理，它默认do-while循环处理16个，这个逻辑在黄色5处的判断条件里，超过阈值就退出do-while。&lt;/p&gt;
&lt;p&gt;下面看黄色5处的判断逻辑——即continueReading()方法，简单看下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/682679/202004/682679-20200417233144634-940721889.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;Netty设计理念是读优先，会给服务端Channel自动注册OP_READ事件——也就是isAutoRead()方法会返回true，那个maxMessagePerRead默认配置的是16，即每一次集中处理accept事件时，最多读取的连接数为16个，是权衡了性能而设计的，这个可以由用户配置。&lt;/p&gt;
&lt;p&gt;继续回看NioMessageUnsafe实例的read方法，如果有新连接，那么继续do-while循环，直到发生异常，或者读取的新连接数量达到了阈值，或者已经没有新连接可读，doReadMessages返回0，退出do-while循环。这里说明一下，正常情况doReadMessages里的accept一定不会阻塞，因为只有当Channel里有就绪的I/O事件，换句话说，有数据可以读，才会进入accept环节，本质是因为Netty服务端为NIO模型配置的是非阻塞I/O，即Netty会自动对各个Channel有如下的配置：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/682679/202004/682679-20200417233159465-2075479259.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;而且，如果服务端Channel有就绪的I/O事件，那么accept()一定会返回客户端Channel，除非实例化Netty的客户端Channel——NioSocketChannel时出现异常。&lt;/p&gt;
&lt;p&gt;如果doReadMessages返回0，那么就会break出do-while循环，接下来大动脉——Netty的pipeline就该干活了，如下NioMessageUnsafe实例的read方法的后面的源码：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/682679/202004/682679-20200417233214061-840330660.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;在黄色6处，遍历保存客户端新Channel的集合——readBuf，然后将每个新连接传播出去——调用pipeline.fireChannelRead()，将每条新连接沿着服务端Channel的pipeline传递，交给Channel后续的入站handler，而黄色7处，会传播一个读操作完成的事件——fireChannelReadComplete();后续会逐渐的拆解并详细分析pipeline的设计，这里知道即可。&lt;/p&gt;
&lt;p&gt;至此，Netty服务端检测处理客户端新连接的过程分析完毕。&lt;/p&gt;

&lt;p&gt;1、权衡性能，NIO线程一次处理的新连接不能太多，Netty默认是一次最多处理16个&lt;/p&gt;
&lt;p&gt;2、Netty的pipeline机制和读取新连接后的衔接过程——触发和传递&lt;/p&gt;
&lt;p&gt;3、Selector的select返回值的理解&lt;/p&gt;
&lt;p&gt;4、深刻理解同步非阻塞，即NIO模式下，accept方法为什么不会阻塞&lt;/p&gt;
</description>
<pubDate>Fri, 17 Apr 2020 15:38:00 +0000</pubDate>
<dc:creator>dashuai的博客</dc:creator>
<og:description>更多技术分享可关注我 前言 前面的分析从Netty服务端启动过程入手，一路走到了Netty的心脏——NioEventLoop，又总结了Netty的异步API和设计原理，现在回到Netty服务端本身，看</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/kubixuesheng/p/12723391.html</dc:identifier>
</item>
</channel>
</rss>