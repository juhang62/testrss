<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="css/feed.xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/" xmlns:og="http://ogp.me/ns#">
<channel>
<atom:link rel="self" href="http://192.168.1.4/fivefilters/makefulltextfeed.php?url=feed.cnblogs.com%2Fblog%2Fsitehome%2Frss&amp;max=10&amp;links=preserve&amp;exc=" />
<atom:link rel="alternate" title="Source URL" href="http://feed.cnblogs.com/blog/sitehome/rss" />
<atom:link rel="related" title="Subscribe to feed" href="http://www.subtome.com/#/subscribe?feeds=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed.cnblogs.com%252Fblog%252Fsitehome%252Frss%26max%3D10%26links%3Dpreserve%26exc%3D&amp;back=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed.cnblogs.com%252Fblog%252Fsitehome%252Frss%26max%3D10%26links%3Dpreserve%26exc%3D" />
<title>博客园_首页</title>
<link></link>
<description>代码改变世界</description>
<item>
<title>maven setting 配置仓库，pom.xml中repository不起作用 - 猿起缘灭</title>
<link>http://www.cnblogs.com/gunduzi/p/11715726.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/gunduzi/p/11715726.html</guid>
<description>&lt;p&gt;&lt;span&gt;&lt;strong&gt;问题描述&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;最近做java项目，需要使用公司自己搭建的maven仓库，但是有些包公司的仓库中没有，导致下载失败。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;项目环境&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;jdk:1.8&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;maven:3.5&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;问题原因分析&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;maven的setting文件配置信息如下：&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;35&quot;&gt;
&lt;pre class=&quot;brush:java;gutter:true;&quot;&gt;
&amp;lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&amp;gt;
&amp;lt;settings&amp;gt;
    &amp;lt;localRepository&amp;gt;/data/repository&amp;lt;/localRepository&amp;gt;
    &amp;lt;servers&amp;gt;
        &amp;lt;server&amp;gt;
            &amp;lt;id&amp;gt;releases&amp;lt;/id&amp;gt;
            &amp;lt;username&amp;gt;123&amp;lt;/username&amp;gt;
            &amp;lt;password&amp;gt;123&amp;lt;/password&amp;gt;
        &amp;lt;/server&amp;gt;
        &amp;lt;server&amp;gt;
            &amp;lt;id&amp;gt;snapshots&amp;lt;/id&amp;gt;
            &amp;lt;username&amp;gt;123&amp;lt;/username&amp;gt;
            &amp;lt;password&amp;gt;123&amp;lt;/password&amp;gt;
        &amp;lt;/server&amp;gt;
    &amp;lt;/servers&amp;gt;
    &amp;lt;mirrors&amp;gt;
        &amp;lt;!--注意标红的部分--&amp;gt;
   &lt;span&gt;     &amp;lt;mirror&amp;gt;
            &amp;lt;id&amp;gt;nexus&amp;lt;/id&amp;gt;
            &amp;lt;mirrorOf&amp;gt;*&amp;lt;/mirrorOf&amp;gt;
            &amp;lt;url&amp;gt;http://server.dev.****.com:8000/nexus/content/groups/public/&amp;lt;/url&amp;gt;
        &amp;lt;/mirror&amp;gt;&lt;/span&gt;
    &amp;lt;/mirrors&amp;gt;
    &amp;lt;profiles&amp;gt;
        &amp;lt;profile&amp;gt;
            &amp;lt;id&amp;gt;nexus&amp;lt;/id&amp;gt;
            &amp;lt;repositories&amp;gt;
                &amp;lt;repository&amp;gt;
                    &amp;lt;id&amp;gt;central&amp;lt;/id&amp;gt;
                    &amp;lt;url&amp;gt;http://central&amp;lt;/url&amp;gt;
                    &amp;lt;releases&amp;gt;&amp;lt;enabled&amp;gt;true&amp;lt;/enabled&amp;gt;&amp;lt;/releases&amp;gt;
                    &amp;lt;snapshots&amp;gt;&amp;lt;enabled&amp;gt;true&amp;lt;/enabled&amp;gt;&amp;lt;/snapshots&amp;gt;
                &amp;lt;/repository&amp;gt;
            &amp;lt;/repositories&amp;gt;
            &amp;lt;pluginRepositories&amp;gt;
                &amp;lt;pluginRepository&amp;gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;pom.xml中的配置：&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;35&quot;&gt;
&lt;pre class=&quot;brush:java;gutter:true;&quot;&gt;
&amp;lt;repositories&amp;gt;
                        &amp;lt;repository&amp;gt;
                        &amp;lt;id&amp;gt;aliyun-repos&amp;lt;/id&amp;gt;
                        &amp;lt;url&amp;gt;https://maven.aliyun.com/repository/public&amp;lt;/url&amp;gt;
                        &amp;lt;releases&amp;gt;&amp;lt;enabled&amp;gt;true&amp;lt;/enabled&amp;gt;&amp;lt;/releases&amp;gt;
                        &amp;lt;snapshots&amp;gt;&amp;lt;enabled&amp;gt;false&amp;lt;/enabled&amp;gt;&amp;lt;/snapshots&amp;gt;
                &amp;lt;/repository&amp;gt;
        &amp;lt;repository&amp;gt;
                    &amp;lt;id&amp;gt;sonatype-repos-s&amp;lt;/id&amp;gt;
                        &amp;lt;name&amp;gt;Sonatype Repository&amp;lt;/name&amp;gt;
                        &amp;lt;url&amp;gt;https://oss.sonatype.org/content/repositories/snapshots&amp;lt;/url&amp;gt;
                        &amp;lt;releases&amp;gt;&amp;lt;enabled&amp;gt;false&amp;lt;/enabled&amp;gt;&amp;lt;updatePolicy&amp;gt;always&amp;lt;/updatePolicy&amp;gt;&amp;lt;/releases&amp;gt;
                        &amp;lt;snapshots&amp;gt;&amp;lt;enabled&amp;gt;true&amp;lt;/enabled&amp;gt;&amp;lt;updatePolicy&amp;gt;always&amp;lt;/updatePolicy&amp;gt;&amp;lt;/snapshots&amp;gt;
                &amp;lt;/repository&amp;gt;
        &amp;lt;/repositories&amp;gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;我需要下载的包的仓库地址在pom文件中配置了，就是 https://oss.sonatype.org/content/repositories/snapshots，这个仓库，&lt;/p&gt;
&lt;p&gt;但是为什么下载的时候没有起作用呢？问题就出在setting中如下部分：&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;33&quot;&gt;
&lt;pre class=&quot;brush:java;gutter:true;&quot;&gt;
&amp;lt;mirror&amp;gt;
      &amp;lt;id&amp;gt;nexus&amp;lt;/id&amp;gt;
      &amp;lt;mirrorOf&amp;gt;*&amp;lt;/mirrorOf&amp;gt;
      &amp;lt;url&amp;gt;http://server.dev.****.com:8081/nexus/content/groups/public/&amp;lt;/url&amp;gt;
&amp;lt;/mirror&amp;gt;　
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;mirrorof标签，这个标签如果设置为*，就说明整个工程只能使用settings中配置的地址，这个就是问题的根源。&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;解决办法&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;span&gt;　　在settings文件的mirrorof标签中内容改成（!&lt;/span&gt;&lt;/span&gt;sonatype-repos-s，*&lt;span&gt;&lt;span&gt;），括号里面的内容，不包括括号，这样做的意思是，&lt;/span&gt;&lt;/span&gt;!sonatype-repos-s意思是&lt;span&gt;&lt;span&gt;把&lt;/span&gt;&lt;/span&gt;sonatype-repos-s这个仓库排除在外，依然把公司的仓库作为唯一仓库，这样就可以使用settings文件中配置的仓库和pom.xml配置的仓库都生效。&lt;/p&gt;

&lt;p&gt;-------------------------------------------------------------分割线---------------------------------------------------------------&lt;/p&gt;
&lt;p&gt;番外话：上面的问题产生的根本原因是，我们平时做项目时一般都是复制粘贴，根本不知道有些配置项什么意思，出了问题就百度，但是有时百度查不到时，还是要老老实实的从原理入手。&lt;/p&gt;

</description>
<pubDate>Wed, 23 Oct 2019 00:42:00 +0000</pubDate>
<dc:creator>猿起缘灭</dc:creator>
<og:description>问题描述 最近做java项目，需要使用公司自己搭建的maven仓库，但是有些包公司的仓库中没有，导致下载失败。 项目环境 jdk:1.8 maven:3.5 问题原因分析 maven的setting文</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/gunduzi/p/11715726.html</dc:identifier>
</item>
<item>
<title>使用Git Bash在码云上上传和下载代码 - 执偕</title>
<link>http://www.cnblogs.com/zhixie/p/11723915.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/zhixie/p/11723915.html</guid>
<description>&lt;div id=&quot;cnblogs_post_body&quot; readability=&quot;110&quot;&gt;
&lt;p&gt;前提是在码云上已经新建一个空的项目&lt;/p&gt;
&lt;p&gt;1、新建一个目录，存放下载下来的项目，我在D盘新建了一个“gitspace”文件夹，用来存放下载下来的项目&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2017.cnblogs.com/blog/611890/201708/611890-20170802161411146-11701551.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;2、进入刚刚新建的文件夹，即进入“gitspace”，点击鼠标右键，选择&quot;Git Bash Here&quot;,如下图：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2017.cnblogs.com/blog/611890/201708/611890-20170802161532115-1493041134.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;点击“Git Bash Here”之后，可以看到下面界面，否则，可能是你的Git Bash安装有问题&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2017.cnblogs.com/blog/611890/201708/611890-20170802161616443-1117876150.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;3、进行基础配置，作为 git 的基础配置，作用是告诉 git 你是谁，你输入的信息将出现在你创建的提交中，使用下面两条命令：&lt;/p&gt;
&lt;p&gt;　　git config --&lt;span class=&quot;hljs-keyword&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;global user.name &lt;span class=&quot;hljs-string&quot;&gt;&lt;span class=&quot;hljs-string&quot;&gt;&quot;你的名字或昵称&quot;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;&lt;span class=&quot;hljs-string&quot;&gt;&lt;span class=&quot;hljs-string&quot;&gt;　　git config --&lt;span class=&quot;hljs-keyword&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;global user.email &lt;span class=&quot;hljs-string&quot;&gt;&lt;span class=&quot;hljs-string&quot;&gt;&quot;你的邮箱&quot;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;&lt;span class=&quot;hljs-string&quot;&gt;&lt;span class=&quot;hljs-string&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;&lt;span class=&quot;hljs-string&quot;&gt;&lt;span class=&quot;hljs-string&quot;&gt;       &lt;img src=&quot;https://images2017.cnblogs.com/blog/611890/201708/611890-20170802162341818-546435687.png&quot; alt=&quot;&quot;/&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;4、在gitspace文件夹中执行下面命令，完成初始化&lt;/p&gt;
&lt;p&gt;      git init&lt;/p&gt;
&lt;p&gt;      git remote add origin &amp;lt;你的项目地址&amp;gt; &lt;span class=&quot;hljs-regexp&quot;&gt;&lt;span class=&quot;hljs-regexp&quot;&gt;//注&lt;span class=&quot;hljs-symbol&quot;&gt;&lt;span class=&quot;hljs-symbol&quot;&gt;:项目地址形式为&lt;span class=&quot;hljs-symbol&quot;&gt;&lt;span class=&quot;hljs-symbol&quot;&gt;:https&lt;span class=&quot;hljs-symbol&quot;&gt;&lt;span class=&quot;hljs-symbol&quot;&gt;://gitee.com/xxx/xxx.git或者 git&lt;span class=&quot;hljs-variable&quot;&gt;&lt;span class=&quot;hljs-variable&quot;&gt;@gitee.&lt;span class=&quot;hljs-symbol&quot;&gt;&lt;span class=&quot;hljs-symbol&quot;&gt;com:xxx/xxx.git&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt; 　&lt;img src=&quot;https://images2017.cnblogs.com/blog/611890/201708/611890-20170802162700365-424518879.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;5、如果你想克隆，只需要执行命令&lt;/p&gt;
&lt;p&gt;     git clone &lt;span class=&quot;hljs-tag&quot;&gt;&lt;span class=&quot;hljs-tag&quot;&gt;&amp;lt;&lt;span class=&quot;hljs-title&quot;&gt;&lt;span class=&quot;hljs-tag&quot;&gt;&lt;span class=&quot;hljs-title&quot;&gt;项目地址&lt;span class=&quot;hljs-tag&quot;&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;hljs-tag&quot;&gt;&lt;span class=&quot;hljs-tag&quot;&gt;&lt;span class=&quot;hljs-title&quot;&gt;&lt;span class=&quot;hljs-tag&quot;&gt;&lt;span class=&quot;hljs-title&quot;&gt;&lt;span class=&quot;hljs-tag&quot;&gt;     &lt;img src=&quot;https://images2017.cnblogs.com/blog/611890/201708/611890-20170802162852333-694609789.png&quot; alt=&quot;&quot;/&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;     弹出窗口，输入码云的账户名、密码&lt;/p&gt;
&lt;p&gt;     &lt;img src=&quot;https://images2017.cnblogs.com/blog/611890/201708/611890-20170802162938583-1344881107.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;     点击“确定”&lt;/p&gt;
&lt;p&gt;     &lt;img src=&quot;https://images2017.cnblogs.com/blog/611890/201708/611890-20170802163102693-924409543.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　 再看gitspace文件夹下，已经下载下来了&lt;/p&gt;
&lt;p&gt;     &lt;img src=&quot;https://images2017.cnblogs.com/blog/611890/201708/611890-20170802163125177-1486121647.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;hljs-tag&quot;&gt;&lt;span class=&quot;hljs-tag&quot;&gt;&lt;span class=&quot;hljs-title&quot;&gt;&lt;span class=&quot;hljs-tag&quot;&gt;&lt;span class=&quot;hljs-title&quot;&gt;&lt;span class=&quot;hljs-tag&quot;&gt;6、&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;进入你已经初始化好的或者克隆项目的目录,然后执行：&lt;/p&gt;
&lt;p&gt;    从服务器下更新项目，因为已经clone过，所以不需要再更新&lt;/p&gt;
&lt;p&gt;    git pull origin master &lt;/p&gt;
&lt;p&gt;7、做一些修改，比如添加一个&quot;说明.txt&quot;文件&lt;/p&gt;
&lt;p&gt;     &lt;img src=&quot;https://images2017.cnblogs.com/blog/611890/201708/611890-20170802163839380-168066009.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;      执行下面命令，完成第一次提交&lt;/p&gt;
&lt;p&gt;      git add .&lt;/p&gt;
&lt;p&gt;      git commit -m “安装教程测试”&lt;/p&gt;
&lt;p&gt;      git push origin master  &lt;/p&gt;
&lt;p&gt;注意：提交命令有两个，git push origin master（正常提交）和git push origin master -f（强制提交，强制提交可能会把之前的commit注释信息，不会改变修改的代码，慎用），都是提交到master分支&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2017.cnblogs.com/blog/611890/201708/611890-20170802165326349-1322110622.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2017.cnblogs.com/blog/611890/201708/611890-20170802173007333-79021995.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt; 这样就完成了使用git bash从码云上下载和上传代码。&lt;/p&gt;
&lt;/div&gt;&lt;div id=&quot;blog_post_info_block&quot; readability=&quot;33.5&quot;&gt;
&lt;p&gt;原文链接：https://www.cnblogs.com/babysbreath/p/7274195.html&lt;/p&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;如果文章对您有帮助，请记得点赞关注哟~&lt;br/&gt;欢迎大家关注我的公众号&amp;lt;情系IT&amp;gt;，每日技术推送文章供大家学习参考。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;</description>
<pubDate>Wed, 23 Oct 2019 00:42:00 +0000</pubDate>
<dc:creator>执偕</dc:creator>
<og:description>前提是在码云上已经新建一个空的项目 1、新建一个目录，存放下载下来的项目，我在D盘新建了一个“gitspace”文件夹，用来存放下载下来的项目 &amp;nbsp; 2、进入刚刚新建的文件夹，即进入“gits</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/zhixie/p/11723915.html</dc:identifier>
</item>
<item>
<title>牛掰！我是这么把个人博客粉丝转到公众号的 - 沉默王二</title>
<link>http://www.cnblogs.com/qing-gee/p/11723904.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/qing-gee/p/11723904.html</guid>
<description>&lt;h3 id=&quot;前言&quot;&gt;01、前言&lt;/h3&gt;
&lt;p&gt;纯洁的微笑推荐了一篇文章，题目没有任何特色，叫做《我是怎么把博客粉丝转到公众号的》，但读完后，我震惊了——原来还有这种骚操作啊！&lt;/p&gt;
&lt;p&gt;惊叹于作者的思路和动手能力，我也决定试一把。&lt;strong&gt;毕竟在这个互联网时代，拥有流量就仿佛拥有了一切&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;没想到的是，我这一把试了整整一个星期（有好几天都是折腾到半夜两三点，眼皮一直打架），今天才终于搞定。期间踩了无数次的坑，感慨颇多。于是就想从技术的角度，来回顾一下这次的历程，给大家一些参照。&lt;/p&gt;
&lt;p&gt;《我是怎么把博客粉丝转到公众号的》的作者叫崔庆才，加了好友聊了几句，感觉非常的有才。借此机会，我们再来一起回顾一下他的思路。&lt;/p&gt;
&lt;p&gt;1）读者通过谷歌或者 Robin 李的搜索引擎检索到了博客。&lt;/p&gt;
&lt;p&gt;2）博客的部分内容是隐藏的，需要读者关注公众号并回复口令解锁。&lt;/p&gt;
&lt;p&gt;3）解锁后，读者就可以无碍地浏览全站所有文章了。&lt;/p&gt;
&lt;p&gt;大家看到这可能会产生一个疑问：作者的思路是非常清晰的，但读者的用户体验怎么保证呢？&lt;/p&gt;
&lt;p&gt;首先，读者只需要解锁一次，全站的所有文章就全都解锁了。其次，操作起来非常简便，扫一下二维码，发送一个口令就完事了。最后，读者关注公众号的动作，在一定程度上为作者注入了源源不断的写作动力，这样的话，读者就可以看到更多更优质的文章了。&lt;/p&gt;
&lt;p&gt;真的是两全其美啊！&lt;/p&gt;
&lt;p&gt;既然方案大佬已经提供了，那我们就动手开干吧！&lt;strong&gt;人嘛，你可以缺少想法，但不能缺少执行力啊——干就对了&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;接下来，我们就从前端到后端，细细致致地过一遍。前端是通过 HTML + CSS + JavaScript 实现的，后端是通过 JFinal + 微信 SDK + MySql 实现的。用到的技术栈还包括 jQuery、Nginx、Maven 等等。&lt;/p&gt;
&lt;h3 id=&quot;前端&quot;&gt;02、前端&lt;/h3&gt;
&lt;p&gt;前端主要完成的工作包括隐藏文章、提醒用户扫码关注公众号并发送口令，还有解锁文章。怎么实现的呢？我们一步步来看。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;1）找到文章所在的容器&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;怎么找到文章所在的容器呢？很简单，F12 打开谷歌浏览器的开发者模式，通过【Elements】面板的选择器进行定位。&lt;/p&gt;
&lt;p&gt;比如说，&lt;a href=&quot;https://www.cnblogs.com/qing-gee/p/itmind.net&quot;&gt;小白学堂&lt;/a&gt;这个博客的文章容器是 &lt;code&gt;article.article-content&lt;/code&gt;。截图如下。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://www.itwanger.com/assets/images/2019/10/boke-gongzhonghao-1.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2）把文章所在容器的高度缩小&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;怎么缩小文章所在容器的高度呢？使用 jQuery 是最快捷的方法，比如说 &lt;code&gt;$seletor.css('height', '100px');&lt;/code&gt; 可以将容器的高度设置为 100 像素。&lt;/p&gt;
&lt;p&gt;具体的代码的如下所示。&lt;/p&gt;
&lt;pre class=&quot;js&quot;&gt;
&lt;code&gt;// DOM 完全就绪时执行
$(function() {
// 找到文章所在的容器
var $article = $(&quot;article.article-content&quot;);
if ($article.length &amp;gt; 0) {
// 文章的实际高度
var article = $article[0], height = article.clientHeight;
// 文章隐藏后的高度
var halfHeight = height * 0.3;

$article.css('height', halfHeight + 'px');
$article.addClass('lock');
}
});&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;执行完这段代码后，文章呈现出来的样子如下图所示。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://www.itwanger.com/assets/images/2019/10/boke-gongzhonghao-2.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;页面有点乱，对不对？这是因为文章的容器高度缩小了，但文章的内容因为容纳不下躲在了其他页面元素的下方。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;3）真正地隐藏起来&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;上图中呈现出来的页面效果读者肯定是接受不了的，怎么办呢？一行 CSS 代码就能搞定。&lt;/p&gt;
&lt;pre class=&quot;css&quot;&gt;
&lt;code&gt;.lock {
position: relative;
overflow: hidden;
padding-bottom: 30px;
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;不知道你注意到了没之前的 JavaScript 代码，里面有一行是：&lt;/p&gt;
&lt;pre class=&quot;js&quot;&gt;
&lt;code&gt;$article.addClass('lock');&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;这行代码可以在文章容器上额外加上一个 CSS 样式，于是文章的部分内容就真的隐藏了起来，就像下面这样。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://www.itwanger.com/assets/images/2019/10/boke-gongzhonghao-3.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;4）增加点渐变效果&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;部分文章虽然被隐藏了，但缺少点渐变效果，给读者的感受就像是一刀两断——这种感觉太过唐突，应该缓冲一下，于是我们再来点 CSS 修饰一下。&lt;/p&gt;
&lt;pre class=&quot;css&quot;&gt;
&lt;code&gt;.asb-post-01 {
position: absolute;
left: 0;
bottom: 0;
width: 100%;
display: block;
z-index: 10000;
margin-bottom: 0;
}

.asb-post-01 .mask {
height: 240px;
width: 100%;
background: -webkit-gradient(linear, 0 top, 0 bottom, from(rgba(255, 255, 255, 0)), to(#fff));
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;.asb-post-01&lt;/code&gt; 和 &lt;code&gt;.mask&lt;/code&gt; 从哪里跑出来的？在这里呢，看下图。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://www.itwanger.com/assets/images/2019/10/boke-gongzhonghao-4.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;上面的 CSS 代码稍微解释一下。&lt;code&gt;position: absolute;&lt;/code&gt; 是绝对定位，&lt;code&gt;bottom: 0;&lt;/code&gt; 可以使 &lt;code&gt;.asb-post-01&lt;/code&gt; 定位在文章容器的最底部。&lt;code&gt;.asb-post-01 .mask&lt;/code&gt; 就像一张幕布，呈现出了隐隐约约的渐变效果，效果图如下所示。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://www.itwanger.com/assets/images/2019/10/boke-gongzhonghao-5.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;5）提醒读者关注公众号&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;好了，文章已经隐藏了起来，并且渐变效果也有了，是时候提醒读者关注公众号了。在 &lt;code&gt;&amp;lt;div class=&quot;mask&quot;&amp;gt;&amp;lt;/div&amp;gt;&lt;/code&gt; 元素的下方加入以下代码。&lt;/p&gt;
&lt;pre class=&quot;html&quot;&gt;
&lt;code&gt;&amp;lt;div class=&quot;info&quot;&amp;gt;
&amp;lt;div&amp;gt;扫码或搜索：&amp;lt;span style=&quot;color: #E9405A; font-weight: bold;&quot;&amp;gt;沉默王二&amp;lt;/span&amp;gt;&amp;lt;/div&amp;gt;
&amp;lt;div&amp;gt;
&amp;lt;span&amp;gt;发送 &amp;lt;/span&amp;gt;&amp;lt;span class=&quot;token&quot; style=&quot;color: #e9415a; font-weight: bold; font-size: 17px; margin-bottom: 45px;&quot;&amp;gt;290992&amp;lt;/span&amp;gt;
&amp;lt;/div&amp;gt;
&amp;lt;div&amp;gt;
即可&amp;lt;span style=&quot;color: #e9415a; font-weight: bold;&quot;&amp;gt;立即永久&amp;lt;/span&amp;gt;解锁本站全部文章
&amp;lt;/div&amp;gt;
&amp;lt;div&amp;gt;
&amp;lt;img class=&quot;code-img&quot; style=&quot;width: 300px;display:unset&quot; src=&quot;http://www.itmind.net/wp-content/uploads/2019/09/cmower.jpg&quot;&amp;gt;
&amp;lt;/div&amp;gt;
&amp;lt;/div&amp;gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;再来两行 CSS 代码，设置扫码区域的高度和背景。&lt;/p&gt;
&lt;pre class=&quot;css&quot;&gt;
&lt;code&gt;.asb-post-01 .info {
background: white;
height: 370px;
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;呈现出来的页面效果图如下所示，是不是感觉很完美了？简直天衣无缝好不好，忍不住给自己点个赞。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://www.itwanger.com/assets/images/2019/10/boke-gongzhonghao-6.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;6）生成口令&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;页面效果已经搞定了。接下来就很关键了，怎么确定读者的身份标识呢？&lt;/p&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;当然是 Cookies，Cookies 里面保存了浏览网页时自动生成的 Session ID，而且每一个用户都是不一样的，这样不就可以来唯一标识一台浏览设备了吗？&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;这是崔庆才大佬给出的解决方案，我举双手赞同。怎么获取呢？代码如下所示。&lt;/p&gt;
&lt;pre class=&quot;js&quot;&gt;
&lt;code&gt;function getCookie(name) {
var value = &quot;; &quot; + document.cookie;
var parts = value.split(&quot;; &quot; + name + &quot;=&quot;);
if (parts.length == 2)
return parts.pop().split(&quot;;&quot;).shift();
}

function getToken() {
let value = getCookie('UM_distinctid');
if (!value) {
return defaultToken;
}
return value.substring(value.length - 6).toUpperCase();
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;7）轮循监听解锁或者隐藏文章&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;前端还有最后一个工作要做，就是轮循监听，每隔一段时间向后端发送一个查询，查询读者的口令是否已经保存到数据库，如果保存过了，隐藏的文章就要重现江湖了；如果没有保存，文章当然要继续隐藏着。&lt;/p&gt;
&lt;p&gt;具体的代码如下所示。&lt;/p&gt;
&lt;pre class=&quot;js&quot;&gt;
&lt;code&gt;var _lock = function() {
$article.css('height', halfHeight + 'px');
$article.addClass('lock');
$('.asb-post-01').css('display', 'block');
}

var _unlock = function() {
$article.css('height', 'initial');
$article.removeClass('lock');
$('.asb-post-01').css('display', 'none');
}

// 查询后端的结果
var _detect = function() {
console.log('Detecting Token', token);
$.ajax({
url : 'http://qingmiaokeji.cn/jfinal/wx/',
method : 'GET',
data : {
token : token
},
success : function(data) {
console.log('locked', data.locked);

if (data.locked === true) {
_lock();
} else {
_unlock();
}
},
error : function(data) {
_unlock();
}
})
}

_detect();
setInterval(function() {
_detect();
}, 5000);&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;①、_lock 方法的作用是隐藏文章。&lt;/p&gt;
&lt;p&gt;②、_unlock 方法的作用是显示文章。&lt;/p&gt;
&lt;p&gt;③、_detect 方法的作用是查询口令有没有保存，如果保存就解锁文章，如果没有就隐藏文章。&lt;/p&gt;
&lt;p&gt;④、setInterval 是一个定时器，每隔 5 秒执行一次 _detect 方法。&lt;/p&gt;
&lt;h3 id=&quot;后端&quot;&gt;03、后端&lt;/h3&gt;
&lt;p&gt;前端的工作已经完成了。那后端的工作都包括哪一些呢？&lt;/p&gt;
&lt;p&gt;1）将读者发送的口令保存到数据库。&lt;/p&gt;
&lt;p&gt;2）响应前端的定时查询，把要解锁还是继续锁定的结果返回。&lt;/p&gt;
&lt;p&gt;这两个工作看起来平淡无奇，但如果从零开发的话，还是非常耗时耗力的。我们应该珍惜站在巨人肩膀上的机会，不是吗？&lt;/p&gt;
&lt;p&gt;这次我采用的后端框架是 JFinal，配合其微信开发 SDK，省时省力省心。简单介绍一下 JFinal，它是基于 Java 语言的极速 WEB + ORM 框架，其核心设计目标是开发迅速、代码量少、学习简单、功能强大、轻量级、易扩展、Restful——非常适合我们这次的开发任务。&lt;/p&gt;
&lt;p&gt;为了减轻大家的开发成本，我已经将项目开源到了 GitHub 上，地址如下所示：&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/qinggee/jfinal_weixin_demo_for_maven&quot; class=&quot;uri&quot;&gt;https://github.com/qinggee/jfinal_weixin_demo_for_maven&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;大家可以直接将项目导出到 IDE 中，只需要把数据库链接地址、用户名和密码，以及微信订阅号相关配置修改一下&lt;/strong&gt;就行了。截个图大家参照一下。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://www.itwanger.com/assets/images/2019/10/boke-gongzhonghao-7.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;为了方便大家的实操，我把关键的内容详细地说明一下。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;1）创建数据库和表&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;创建数据库就不再赘述了，就说创建表吧，SQL 如下所示。&lt;/p&gt;
&lt;pre class=&quot;sql&quot;&gt;
&lt;code&gt;DROP TABLE IF EXISTS `weixin`;
CREATE TABLE `weixin` (
`id` int(11) NOT NULL AUTO_INCREMENT,
`openid` varchar(255) NOT NULL,
`token` varchar(255) NOT NULL,
PRIMARY KEY (`id`)
) ENGINE=InnoDB AUTO_INCREMENT=1 DEFAULT CHARSET=utf8;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;weixin 表有三个字段：&lt;/p&gt;
&lt;p&gt;①、id 为主键；&lt;/p&gt;
&lt;p&gt;②、openid 为微信用户的关键标识。当用户取消关注订阅后，可根据该字段删除记录。&lt;/p&gt;
&lt;p&gt;③、token 为博客读者的唯一标识。当用户关注订阅号后，可根据该字段判定博客是否需要解锁。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2）读者关注订阅号后，保存口令&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;WeixinMsgController&lt;/code&gt; 类的 &lt;code&gt;processInTextMsg()&lt;/code&gt; 方法用来处理接收到的文本消息，我们可以在这个方法里保存 openid 和 token，成功后提示读者：恭喜您已经解锁博客全部文章~&lt;/p&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;protected void processInTextMsg(InTextMsg inTextMsg) {
String msgContent = inTextMsg.getContent().trim();

if (&quot;2048&quot;.equals(msgContent)) {

} else if (msgContent.length() == 6) {
Weixin param = new Weixin();
param.setOpenid(inTextMsg.getFromUserName());
param.setToken(msgContent);
param.save();

OutTextMsg outMsg = new OutTextMsg(inTextMsg);
outMsg.setContent(&quot;恭喜您已经解锁博客全部文章~&quot;);
render(outMsg);
} else {
renderDefault();
}
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;3）响应前端的定时查询&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;WeixinController&lt;/code&gt; 类的 &lt;code&gt;index()&lt;/code&gt; 方法用来响应前端的定时查询。&lt;/p&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;public void index() {
// 跨域
getResponse().addHeader(&quot;Access-Control-Allow-Origin&quot;, &quot;*&quot;);

String token = getPara(&quot;token&quot;);
String openid = service.findByToken(token);
if (openid == null || &quot;&quot;.equals(openid)) {
renderJson(&quot;locked&quot;, true);
} else {
renderJson(&quot;locked&quot;, false);
}
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;①、&lt;code&gt;getResponse().addHeader(&quot;Access-Control-Allow-Origin&quot;, &quot;*&quot;)&lt;/code&gt; 这行代码可以解决跨域的问题。&lt;/p&gt;
&lt;p&gt;②、根据 token 查询读者是否已经关注了公众号，关注过的话返回 false，否则返回 true。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;4）读者取消关注订阅号后删除记录&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;WeixinMsgController&lt;/code&gt; 类的 &lt;code&gt;processInFollowEvent()&lt;/code&gt; 方法用来处理接收到的关注/取消关注事件，如果取消关注的话，根据 openid 删除记录。&lt;/p&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;protected void processInFollowEvent(InFollowEvent inFollowEvent) {
if (InFollowEvent.EVENT_INFOLLOW_SUBSCRIBE.equals(inFollowEvent.getEvent())) {

else if (InFollowEvent.EVENT_INFOLLOW_UNSUBSCRIBE.equals(inFollowEvent.getEvent())) {
log.debug(&quot;取消关注：&quot; + inFollowEvent.getFromUserName());
service.deleteByOpenid(inFollowEvent.getFromUserName());
}
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;04、注意事项&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;后端的工作完成后，就需要将其打包运行到服务器上了。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;1）打包项目&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;命令行进入项目根目录，然后运行 &lt;code&gt;mvn clean package&lt;/code&gt; 即可打包。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://www.itwanger.com/assets/images/2019/10/boke-gongzhonghao-8.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;打包完成后，可以在 target 目录下看到以下内容。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://www.itwanger.com/assets/images/2019/10/boke-gongzhonghao-9.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;tar.gz 文件为 &lt;code&gt;target/jfinal_weixin_demo_for_maven-release/jfinal_weixin_demo_for_maven&lt;/code&gt; 目录的压缩包，方便上传至服务器。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2）将 tar.gz 文件上传至服务器，并启动服务&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;上传工具可以使用 FileZilla，上传成功后可以通过 &lt;code&gt;tar -xzvf xxx.tar.gz&lt;/code&gt; 命令进行解压。然后进入 &lt;code&gt;jfinal_weixin_demo_for_maven&lt;/code&gt; 目录下，输入 &lt;code&gt;./jfinal.sh start&lt;/code&gt; 即可启动服务。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;3）配置 Nginx&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;由于服务器上 80 端口已经被占用，所以我们需要 Nginx 反向代理一下。简单介绍一下 Nginx（发音同 engine x），它是异步框架的网页服务器，也可以用作反向代理、负载平衡器和 HTTP 缓存。&lt;/p&gt;
&lt;p&gt;打开 nginx.conf 文件，增加以下内容。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;location ^~ /jfinal/ {
proxy_pass http://127.0.0.1:8089/;
rewrite http://127.0.0.1:8089/ last;
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;配置之前，假如域名是 itwanger.com，访问该服务的地址为：&lt;a href=&quot;http://itwanger.com:8089%E3%80%82%E9%85%8D%E7%BD%AE%E4%B9%8B%E5%90%8E%EF%BC%8C%E8%AE%BF%E9%97%AE%E8%AF%A5%E6%9C%8D%E5%8A%A1%E7%9A%84%E5%9C%B0%E5%9D%80%E5%B0%B1%E5%8F%AF%E4%BB%A5%E6%98%AF%EF%BC%9Ahttp://itwanger.com/jfinal%E3%80%82%E8%BF%99%E6%A0%B7%E8%AF%B7%E6%B1%82%E7%9A%84&quot; class=&quot;uri&quot;&gt;http://itwanger.com:8089。配置之后，访问该服务的地址就可以是：http://itwanger.com/jfinal。这样请求的&lt;/a&gt; URL 中就不需要指定端口了——有没有感觉到 Nginx 的一丝牛逼之处？&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;4）启用微信订阅号服务器配置&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;一切准备就绪后，就可以进入微信订阅号后台，填写服务器地址、令牌，然后启用服务器配置了。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://www.itwanger.com/assets/images/2019/10/boke-gongzhonghao-10.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;5）实际效果&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;可能大家想知道效果如何，这里截几张图大家看看。这个功能已经在&lt;strong&gt;小白学堂&lt;/strong&gt;（itmind.net）上线了，感兴趣的可以进去体验一把，测到 bug 有奖励哟。&lt;/p&gt;
&lt;p&gt;首先进去文章是这个样子的：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://www.itwanger.com/assets/images/2019/10/boke-gongzhonghao-11.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;然后关注了订阅号，发送了口令：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://www.itwanger.com/assets/images/2019/10/boke-gongzhonghao-12.jpg&quot;/&gt;&lt;/p&gt;
&lt;p&gt;于是同时，博客上的文章也解锁了！&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://www.itwanger.com/assets/images/2019/10/boke-gongzhonghao-13.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;牛掰！&lt;/p&gt;
&lt;h3 id=&quot;后记&quot;&gt;05、后记&lt;/h3&gt;
&lt;p&gt;一周时间，我几乎把所有的事情都滞后了，但总算是把这个方案落地了！内心还是非常激动的。再次感谢崔庆才大佬的思路，也为自己顽强的斗志点个赞！&lt;/p&gt;
&lt;p&gt;谢谢大家的阅读，希望能给你在技术的实现上提供一些思路。&lt;/p&gt;
</description>
<pubDate>Wed, 23 Oct 2019 00:39:00 +0000</pubDate>
<dc:creator>沉默王二</dc:creator>
<og:description>01、前言 纯洁的微笑推荐了一篇文章，题目没有任何特色，叫做《我是怎么把博客粉丝转到公众号的》，但读完后，我震惊了——原来还有这种骚操作啊！ 惊叹于作者的思路和动手能力，我也决定试一把。 毕竟在这个互</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/qing-gee/p/11723904.html</dc:identifier>
</item>
<item>
<title>超级好用的 Java 数据可视化库：Tablesaw - 削微寒</title>
<link>http://www.cnblogs.com/xueweihan/p/11721955.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/xueweihan/p/11721955.html</guid>
<description>&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;本文适合刚学习完 Java 语言基础的人群，跟着本文可了解和使用 Tablesaw 项目。示例均在 Windows 操作系统下演示&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/759200/201910/759200-20191022192820887-966740520.png&quot;/&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;本文作者：HelloGitHub-&lt;strong&gt;秦人&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;HelloGitHub 推出的&lt;a href=&quot;https://github.com/HelloGitHub-Team/Article&quot;&gt;《讲解开源项目》&lt;/a&gt;系列，今天给大家带来一款基于 Java 语言的数据可视化库开源项目——&lt;strong&gt;Tablesaw&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Tablesaw是一款 Java 的数据可视化库。它主要包括两部分：一部分是数据解析库，另一部分是数据可视化库。数据解析库主要是加载数据，对数据进行操作（转化，过滤，汇总等）。数据可视化库就是将目标数据转化为可视化的图表。&lt;/p&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;项目源码地址：https://github.com/jtablesaw/tablesaw&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/759200/201910/759200-20191022192846386-902800232.png&quot;/&gt;&lt;/p&gt;
&lt;h2 id=&quot;一项目结构&quot;&gt;一、项目结构&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/759200/201910/759200-20191022192902965-1593228368.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;目录说明：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;aggregate：maven 的项目父级项目，主要定义项目打包的配置。&lt;/li&gt;
&lt;li&gt;beakerx：tablesaw 库的注册中心，主要注册表和列。&lt;/li&gt;
&lt;li&gt;core：tablesaw 库的核心代码，主要是数据的加工处理操作：数据的追加，排序，分组，查询等。&lt;/li&gt;
&lt;li&gt;data：项目测试数据目录。&lt;/li&gt;
&lt;li&gt;docs：项目 MarkDown 文档目录。&lt;/li&gt;
&lt;li&gt;docs-src：项目文档源码目录，主要作用是生成 MarkDown 文档。&lt;/li&gt;
&lt;li&gt;excel：解析 excel 文件数据的子项目。&lt;/li&gt;
&lt;li&gt;html：解析 html 文件数据的子项目。&lt;/li&gt;
&lt;li&gt;json：解析 json 文件数据的子项目。&lt;/li&gt;
&lt;li&gt;jsplot：数据可视化的子项目，主要作用加载数据生成可视化图表。&lt;/li&gt;
&lt;li&gt;saw：tablesaw 读写图表数据的子项目。&lt;/li&gt;
&lt;/ol&gt;&lt;h2 id=&quot;二实战操作&quot;&gt;二、实战操作&lt;/h2&gt;
&lt;h3 id=&quot;准备工作&quot;&gt;2.1 准备工作&lt;/h3&gt;
&lt;p&gt;项目中引入 Tablesaw 依赖包&lt;/p&gt;
&lt;pre class=&quot;xml&quot;&gt;
&lt;code&gt;&amp;lt;dependency&amp;gt;
    &amp;lt;groupId&amp;gt;tech.tablesaw&amp;lt;/groupId&amp;gt;
    &amp;lt;artifactId&amp;gt;tablesaw-core&amp;lt;/artifactId&amp;gt;
    &amp;lt;version&amp;gt;LATEST&amp;lt;/version&amp;gt;
&amp;lt;/dependency&amp;gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;数据解析&quot;&gt;2.2 数据解析&lt;/h3&gt;
&lt;h4 id=&quot;内部数据制作数据表格&quot;&gt;2.2.1 内部数据制作数据表格&lt;/h4&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;@Test
public void tableSawTest6() {
    String[] students = {&quot;小明&quot;, &quot;李雷&quot;, &quot;小二&quot;};
    double[] scores = {90.1, 84.3, 99.7};
    Table table = Table.create(&quot;学生分数统计表&quot;).addColumns(
                    StringColumn.create(&quot;姓名&quot;, students),
                    DoubleColumn.create(&quot;分数&quot;, scores));
    System.out.println(table.print());
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;代码超级简单，首先定义要展示列数据 students 和 scores。然后创建数据展示的 table 定义表格名称，添加表格列数据即可。&lt;/p&gt;
&lt;p&gt;效果展示如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/759200/201910/759200-20191022192928063-337338777.png&quot;/&gt;&lt;/p&gt;
&lt;h4 id=&quot;加载数据文件制作数据表格&quot;&gt;2.2.2 加载数据文件制作数据表格&lt;/h4&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;@Test
public void tableSawTest10() throws Exception{
    Table table = Table.read().csv(&quot;/data/bush.csv&quot;);
    Table whoPercents = table.xTabPercents(&quot;who&quot;);
    whoPercents.columnsOfType(ColumnType.DOUBLE)
    .forEach(x -&amp;gt; ((NumberColumn) x).setPrintFormatter(
        NumberColumnFormatter.percent(0)));
    System.out.println(whoPercents.toString());
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;首先 &lt;code&gt;Table.read&lt;/code&gt; 加载数据文件，加载数据支持 csv、数据库结果集、文件、URL 等&lt;/p&gt;
&lt;p&gt;指定表格 x 轴的字段，并对 数据进行百分比数据的转化。&lt;/p&gt;
&lt;p&gt;bash.csv 文件内容如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/759200/201910/759200-20191022192946287-1968738437.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;运行效果如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/759200/201910/759200-20191022192958000-1283263162.png&quot;/&gt;&lt;/p&gt;
&lt;h3 id=&quot;数据可视化&quot;&gt;2.3 数据可视化&lt;/h3&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;Table robberies = Table.read().csv(&quot;./data/boston-robberies.csv&quot;);
Plot.show(
    AreaPlot.create(
        &quot;Boston Robberies by month: Jan 1966-Oct 1975&quot;, 
        robberies, &quot;Record&quot;, &quot;Robberies&quot;));&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;首先加载数据 &lt;code&gt;Table.read&lt;/code&gt;，绘制图表 &lt;code&gt;AreaPlot.create&lt;/code&gt; ，然后 &lt;code&gt;Plot.show&lt;/code&gt; 在本地生成图表的 html 页面，自动打开浏览器显示。&lt;/p&gt;
&lt;p&gt;boston-robberies.csv 文件内容如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/759200/201910/759200-20191022193017929-306080420.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;运行效果如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/759200/201910/759200-20191022193039844-2131189533.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;Tablesaw 还可以绘制出很多种类的图表，期待你的发掘。&lt;/p&gt;
&lt;h2 id=&quot;三最后&quot;&gt;三、最后&lt;/h2&gt;
&lt;p&gt;教程至此，你应该对 Tablesaw 有一个简单的了解。这里告诉大家一个方法，可以快速掌握开源库：&lt;strong&gt;在源码中找项目的单元测试代码。然后，我们再将项目导入开发工具，直接运行项目中的单元测试。&lt;/strong&gt; 这是可能是最快捷、有效的掌握、上手开源库的方法。&lt;/p&gt;
&lt;p&gt;本教程是针对有一定 Java 编程基础，如果你的项目正好需要数据可视化的库，Tablesaw 库是个不错的选择！&lt;/p&gt;
&lt;hr/&gt;&lt;p&gt;&lt;strong&gt;『讲解开源项目系列』&lt;/strong&gt;——让对开源项目感兴趣的人不再畏惧、让开源项目的发起者不再孤单。跟着我们的文章，你会发现编程的乐趣、使用和发现参与开源项目如此简单。欢迎留言联系我们、加入我们，让更多人爱上开源、贡献开源～&lt;/p&gt;
</description>
<pubDate>Wed, 23 Oct 2019 00:34:00 +0000</pubDate>
<dc:creator>削微寒</dc:creator>
<og:description>本文适合刚学习完 Java 语言基础的人群，跟着本文可了解和使用 Tablesaw 项目。示例均在 Windows 操作系统下演示 本文作者：HelloGitHub 秦人 HelloGitHub 推出</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/xueweihan/p/11721955.html</dc:identifier>
</item>
<item>
<title>Redis分布式篇 - 哒哒网络</title>
<link>http://www.cnblogs.com/sundaboke/p/11723893.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/sundaboke/p/11723893.html</guid>
<description>&lt;h2 id=&quot;为什么-需要-redis-集群&quot;&gt;1 为什么 需要 Redis 集群&lt;/h2&gt;
&lt;h3 id=&quot;为什么需要集群&quot;&gt;1.1 为什么需要集群?&lt;/h3&gt;
&lt;h4 id=&quot;性能&quot;&gt;1.1.1 性能&lt;/h4&gt;
&lt;p&gt;​ Redis 本身的 QPS 已经很高了，但是如果在一些并发量非常高的情况下，性能还是会受到影响。这个时候我们希望有更多的 Redis 服务来完成工作。&lt;/p&gt;
&lt;h4 id=&quot;扩展&quot;&gt;1.1.2 扩展&lt;/h4&gt;
&lt;p&gt;​ 第二个是出于存储的考虑。因为 Redis 所有的数据都放在内存中，如果数据量大，很容易受到硬件的限制。升级硬件收效和成本比太低，所以我们需要有一种横向扩展的方法&lt;/p&gt;
&lt;h4 id=&quot;可用性&quot;&gt;1.1.3 可用性&lt;/h4&gt;
&lt;p&gt;​ 第三个是可用性和安全的问题。如果只有一个 Redis 服务，一旦服务宕机，那么所有的客户端都无法访问，会对业务造成很大的影响。另一个，如果硬件发生故障，而单机的数据无法恢复的话，带来的影响也是灾难性的。&lt;/p&gt;
&lt;p&gt;​ 可用性、数据安全、性能都可以通过搭建多个 Reids 服务实现。其中有一个是主节点（master），可以有多个从节点(slave)。主从之间通过数据同步，存储完全相同的数据。如果主节点发生故障，则把某个从节点改成主节点，访问新的主节点。&lt;/p&gt;
&lt;h2 id=&quot;redis-主从-复制-replication&quot;&gt;2 Redis 主从 复制 （ replication ）&lt;/h2&gt;
&lt;h3 id=&quot;主从-复制配置&quot;&gt;2.1 主从 复制配置&lt;/h3&gt;
&lt;p&gt;例如一主多从,203 是主节点，在每个 slave 节点的 redis.conf 配置文件增加一行&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;slaveof 192.168.8.203 6379&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;在主从切换的时候，这个配置会被重写成：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;# Generated by CONFIG REWRITE
replicaof 192.168.8.203 6379&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;或者在启动服务时通过参数指定 master 节点&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;./redis-server --slaveof 192.168.8.203 637&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;或在客户端直接执行 slaveof xx xx，使该 Redis 实例成为从节点。&lt;br/&gt;启动后，查看集群状态：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;redis&amp;gt; info replication&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;从节点不能写入数据（只读），只能从 master 节点同步数据。get 成功，set 失败。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;127.0.0.1:6379&amp;gt; set sunda 666
(error) READONLY You can't write against a read only replica.&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;主节点写入后，slave 会自动从 master 同步数据。&lt;br/&gt;断开复制：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;redis&amp;gt; slaveof no one&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;此时从节点会变成自己的主节点，不再复制数据。&lt;/p&gt;
&lt;h3 id=&quot;主从复制原理&quot;&gt;2.2 主从复制原理&lt;/h3&gt;
&lt;h4 id=&quot;连接-阶段&quot;&gt;2.2.1 连接 阶段&lt;/h4&gt;
&lt;p&gt;​ 1、slave node 启动时（执行 slaveof 命令），会在自己本地保存 master node 的信息，包括 master node 的 host 和 ip。&lt;br/&gt;​ 2、slave node 内部有个定时任务 replicationCron（源码 replication.c），每隔 1秒钟检查是否有新的 master node 要连接和复制，如果发现，就跟 master node 建立socket 网络连接，如果连接成功，从节点为该 socket 建立一个专门处理复制工作的文件事件处理器，负责后续的复制工作，如接收 RDB 文件、接收命令传播等。当从节点变成了主节点的一个客户端之后，会给主节点发送 ping 请求。&lt;/p&gt;
&lt;h4 id=&quot;数据-同步阶段&quot;&gt;2.2.2 数据 同步阶段&lt;/h4&gt;
&lt;p&gt;​ 3、master node 第一次执行全量复制，通过 bgsave 命令在本地生成一份 RDB 快照，将 RDB 快照文件发给 slave node（如果超时会重连，可以调大 repl-timeout 的值）。slave node 首先清除自己的旧数据，然后用 RDB 文件加载数据。&lt;/p&gt;
&lt;p&gt;问题：生成 RDB 期间，master 接收到的命令怎么处理？&lt;/p&gt;
&lt;p&gt;开始生成 RDB 文件时，master 会把所有新的写命令缓存在内存中。在 slave node保存了 RDB 之后，再将新的写命令复制给 slave node。&lt;/p&gt;
&lt;h4 id=&quot;命令传播阶段&quot;&gt;2.2.3 命令传播阶段&lt;/h4&gt;
&lt;p&gt;​ 4、master node 持续将写命令，异步复制给 slave node&lt;/p&gt;
&lt;p&gt;​ 延迟是不可避免的，只能通过优化网络。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;repl-disable-tcp-nodelay no&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;当设置为 yes 时，TCP 会对包进行合并从而减少带宽，但是发送的频率会降低，从节点数据延迟增加，一致性变差；具体发送频率与 Linux 内核的配置有关，默认配置为40ms。当设置为 no 时，TCP 会立马将主节点的数据发送给从节点，带宽增加但延迟变小。&lt;/p&gt;
&lt;p&gt;一般来说，只有当应用对 Redis 数据不一致的容忍度较高，且主从节点之间网络状况不好时，才会设置为 yes；多数情况使用默认值 no。&lt;/p&gt;
&lt;p&gt;问题：如果从节点有一段时间断开了与主节点的连接是不是要重新全量复制一遍？如果可以增量复制，怎么知道上次复制到哪里？&lt;/p&gt;
&lt;p&gt;通过 master_repl_offset 记录的偏移量&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;redis&amp;gt; info replication&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;img src=&quot;https://www.sundablog.com/usr/uploads/2019/10/193177277.png&quot; alt=&quot;1571747119946.png&quot;/&gt;&lt;/p&gt;
&lt;h3 id=&quot;主从复制的-不足&quot;&gt;2.3 主从复制的 不足&lt;/h3&gt;
&lt;p&gt;主从模式解决了数据备份和性能（通过读写分离）的问题，但是还是存在一些不足：&lt;/p&gt;
&lt;p&gt;​ 1、RDB 文件过大的情况下，同步非常耗时。&lt;br/&gt;​ 2、在一主一从或者一主多从的情况下，如果主服务器挂了，对外提供的服务就不可用了，单点问题没有得到解决。如果每次都是手动把之前的从服务器切换成主服务器，这个比较费时费力，还会造成一定时间的服务不可用。&lt;/p&gt;
&lt;h2 id=&quot;可用性保证之-sentinel&quot;&gt;3 可用性保证之 Sentinel&lt;/h2&gt;
&lt;h3 id=&quot;sentinel-原理&quot;&gt;3.1 Sentinel 原理&lt;/h3&gt;
&lt;p&gt;​ 如何实现主从的自动切换？我们的思路：&lt;br/&gt;​ 创建一台监控服务器来监控所有 Redis 服务节点的状态，比如，master 节点超过一定时间没有给监控服务器发送心跳报文，就把 master 标记为下线，然后把某一个 slave变成 master。应用每一次都是从这个监控服务器拿到 master 的地址。&lt;/p&gt;
&lt;p&gt;问题是：如果监控服务器本身出问题了怎么办？那我们就拿不到 master 的地址了，应用也没有办法访问。&lt;br/&gt;那我们再创建一个监控服务器，来监控监控服务器……似乎陷入死循环了，这个问题怎么解决？这个问题先放着。&lt;br/&gt;Redis 的 Sentinel 就是这种思路：通过运行监控服务器来保证服务的可用性。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;官网：&lt;/strong&gt;&lt;br/&gt;https://redis.io/topics/sentinel&lt;/p&gt;
&lt;p&gt;​ 从 Redis2.8 版本起，提供了一个稳定版本的 Sentinel（哨兵），用来解决高可用的问题。它是一个特殊状态的 redis 实例。&lt;br/&gt;​ 我们会启动一个或者多个 Sentinel 的服务（通过 src/redis-sentinel），它本质上只是一个运行在特殊模式之下的 Redis，Sentinel 通过 info 命令得到被监听 Redis 机器的master，slave 等信息。&lt;br/&gt;&lt;img src=&quot;https://www.sundablog.com/usr/uploads/2019/10/2831746561.png&quot; alt=&quot;1571747203355.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;为了保证监控服务器的可用性，我们会对 Sentinel 做集群的部署。Sentinel 既监控所有的 Redis 服务，&lt;strong&gt;Sentinel 之间也相互监控。&lt;/strong&gt;&lt;br/&gt;注意：Sentinel 本身没有主从之分，只有 Redis 服务节点有主从之分。&lt;br/&gt;概念梳理：master，slave（redis group），sentinel，sentinel 集合&lt;/p&gt;
&lt;h4 id=&quot;服务-下线&quot;&gt;3.1.1 服务 下线&lt;/h4&gt;
&lt;p&gt;​ Sentinel 默认以每秒钟 1 次的频率向 Redis 服务节点发送 PING 命令。如果在down-after-milliseconds 内都没有收到有效回复，Sentinel 会将该服务器标记为下线（&lt;strong&gt;主观下线&lt;/strong&gt;）。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;# sentinel.conf
sentinel down-after-milliseconds &amp;lt;master-name&amp;gt; &amp;lt;milliseconds&amp;gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;​ 这个时候 Sentinel 节点会继续询问其他的 Sentinel 节点，确认这个节点是否下线，如果多数 Sentinel 节点都认为 master 下线，master 才真正确认被下线（客观下线），这个时候就需要重新选举 master。&lt;/p&gt;
&lt;h4 id=&quot;故障-转移&quot;&gt;3.1.2 故障 转移&lt;/h4&gt;
&lt;p&gt;​ 如果 master 被标记为下线，就会开始故障转移流程。&lt;br/&gt;​ 既然有这么多的 Sentinel 节点，由谁来做故障转移的事情呢？&lt;br/&gt;​ 故障转移流程的第一步就是在 Sentinel 集群选择一个 Leader，由 Leader 完成故障转移流程。Sentinle 通过 Raft 算法，实现 Sentinel 选举。&lt;/p&gt;
&lt;h5 id=&quot;ratf-算法&quot;&gt;3.1.2.1 Ratf 算法&lt;/h5&gt;
&lt;p&gt;​ 在分布式存储系统中，通常通过维护多个副本来提高系统的可用性，那么多个节点之间必须要面对数据一致性的问题。Raft 的目的就是通过复制的方式，使所有节点达成一致，但是这么多节点，以哪个节点的数据为准呢？所以必须选出一个 Leader&lt;/p&gt;
&lt;p&gt;​ 大体上有两个步骤：领导选举，数据复制。&lt;br/&gt;​ Raft 是一个共识算法（consensus algorithm）。比如比特币之类的加密货币，就需要共识算法。Spring Cloud 的注册中心解决方案 Consul 也用到了 Raft 协议。&lt;br/&gt;​ Raft 的核心思想：先到先得，少数服从多数。&lt;br/&gt;​ Raft 算法演示：&lt;/p&gt;
&lt;p&gt;http://thesecretlivesofdata.com/raft/&lt;br/&gt;&lt;strong&gt;总结：&lt;/strong&gt;&lt;br/&gt;Sentinle 的 Raft 算法和 Raft 论文略有不同。&lt;br/&gt;1、master 客观下线触发选举，而不是过了 election timeout 时间开始选举。&lt;br/&gt;2、Leader 并不会把自己成为 Leader 的消息发给其他 Sentinel。其他 Sentinel 等待 Leader 从 slave 选出 master 后，检测到新的 master 正常工作后，就会去掉客观下线的标识，从而不需要进入故障转移流程。&lt;/p&gt;
&lt;h5 id=&quot;故障转移&quot;&gt;3.1.2.2 故障转移&lt;/h5&gt;
&lt;p&gt;​ 问题：怎么让一个原来的 slave 节点成为主节点？&lt;br/&gt;​ 1、选出 Sentinel Leader 之后，由 Sentinel Leader 向某个节点发送 slaveof no one命令，让它成为独立节点。&lt;br/&gt;​ 2、然后向其他节点发送 slaveof x.x.x.x xxxx（本机服务），让它们成为这个节点的子节点，故障转移完成。&lt;br/&gt;​ 问题：这么多从节点，选谁成为主节点？&lt;br/&gt;​ 关于从节点选举，一共有四个因素影响选举的结果，分别是断开连接时长、优先级排序、复制数量、进程 id。&lt;br/&gt;​ 如果与哨兵连接断开的比较久，超过了某个阈值，就直接失去了选举权。如果拥有选举权，那就看谁的优先级高，这个在配置文件里可以设置（replica-priority 100），数值越小优先级越高。&lt;br/&gt;​ 如果优先级相同，就看谁从 master 中复制的数据最多（复制偏移量最大），选最多的那个，如果复制数量也相同，就选择进程 id 最小的那个。&lt;/p&gt;
&lt;h3 id=&quot;sentinel-的功能总结&quot;&gt;3.2 Sentinel 的功能总结&lt;/h3&gt;
&lt;ul&gt;&lt;li&gt;Monitoring. Sentinel constantly checks if your master and slave instances are working as expected.&lt;/li&gt;
&lt;li&gt;Notification. Sentinel can notify the system administrator, another computer programs, via an API, that something iswrong with one of the monitored Redis instances.&lt;/li&gt;
&lt;li&gt;Automatic failover. If a master is not working as expected, Sentinel can start a failover process where a slave is promoted to master, the other additional slaves are reconfigured to use the new master, and the applications using the Redis server informed about the new address to use when connecting.&lt;/li&gt;
&lt;li&gt;Configuration provider. Sentinel acts as a source of authority for clients service discovery:clients connect to Sentinels in order to ask for the address of the current Redis master responsible for a given service. If a failover occurs, Sentinels will report the new address.&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;​ 监控：Sentinel 会不断检查主服务器和从服务器是否正常运行。&lt;br/&gt;​ 通知：如果某一个被监控的实例出现问题，Sentinel 可以通过 API 发出通知。&lt;br/&gt;​ 自动故障转移（failover）：如果主服务器发生故障，Sentinel 可以启动故障转移过程。把某台服务器升级为主服务器，并发出通知。&lt;br/&gt;​ 配置管理：客户端连接到 Sentinel，获取当前的 Redis 主服务器的地址。&lt;/p&gt;
&lt;h3 id=&quot;sentinel-实战&quot;&gt;3.3 Sentinel 实战&lt;/h3&gt;
&lt;h4 id=&quot;sentinel-配置&quot;&gt;3.3.1 Sentinel 配置&lt;/h4&gt;
&lt;p&gt;为了保证 Sentinel 的高可用，Sentinel 也需要做集群部署，集群中至少需要三个Sentinel 实例（推荐奇数个，防止脑裂）。&lt;/p&gt;
&lt;table&gt;&lt;thead/&gt;&lt;tbody readability=&quot;3&quot;&gt;&lt;tr class=&quot;odd&quot; readability=&quot;2&quot;&gt;&lt;td&gt;master&lt;/td&gt;
&lt;td&gt;192.168.8.203&lt;/td&gt;
&lt;td&gt;Master：6379 / Sentinel : 26379&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;even&quot; readability=&quot;2&quot;&gt;&lt;td&gt;slave1&lt;/td&gt;
&lt;td&gt;192.168.8.204&lt;/td&gt;
&lt;td&gt;Slave ：6379 / Sentinel : 26379&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;odd&quot; readability=&quot;2&quot;&gt;&lt;td&gt;slave2&lt;/td&gt;
&lt;td&gt;192.168.8.205&lt;/td&gt;
&lt;td&gt;Slave ：6379 / Sentinel : 26379&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;以 Redis 安装路径/usr/local/soft/redis-5.0.5/为例。&lt;br/&gt;在 204 和 205 的 src/redis.conf 配置文件中添加&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;slaveof 192.168.8.203 6379&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;在 203、204、205 创建 sentinel 配置文件（安装后根目录下默认有 sentinel.conf）：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;cd /usr/local/soft/redis-5.0.5
mkdir logs
mkdir rdbs
mkdir sentinel-tmp
vim sentinel.conf&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;三台服务器内容相同：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;daemonize yes
port 26379
protected-mode no
dir &quot;/usr/local/soft/redis-5.0.5/sentinel-tmp&quot;
sentinel monitor redis-master 192.168.2.203 6379 2
sentinel down-after-milliseconds redis-master 30000
sentinel failover-timeout redis-master 180000
sentinel parallel-syncs redis-master 1&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;​ 上面出现了 4 个'redis-master'，这个名称要统一，并且使用客户端（比如 Jedis）连接的时候名称要正确。&lt;/p&gt;
&lt;table&gt;&lt;thead/&gt;&lt;tbody readability=&quot;10&quot;&gt;&lt;tr class=&quot;odd&quot; readability=&quot;2&quot;&gt;&lt;td&gt;protected-mode&lt;/td&gt;
&lt;td&gt;是否允许外部网络访问&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;even&quot;&gt;&lt;td&gt;dir&lt;/td&gt;
&lt;td&gt;sentinel 的工作目录&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;odd&quot; readability=&quot;2&quot;&gt;&lt;td&gt;sentinel monitor&lt;/td&gt;
&lt;td&gt;sentinel 监控的 redis 主节点&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;even&quot; readability=&quot;4&quot;&gt;&lt;td&gt;down-after-milliseconds（毫秒）&lt;/td&gt;
&lt;td&gt;master 宕机多久，才会被 Sentinel 主观认为下线&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;odd&quot; readability=&quot;7&quot;&gt;&lt;td&gt;sentinel failover-timeout（毫秒&lt;/td&gt;
&lt;td&gt;1 同一个 sentinel 对同一个 master 两次 failover 之间的间隔时间。&lt;br/&gt;2. 当一个 slave 从一个错误的 master 那里同步数据开始计算时间。直到&lt;br/&gt;slave 被纠正为向正确的 master 那里同步数据时。&lt;br/&gt;3.当想要取消一个正在进行的 failover 所需要的时间。&lt;br/&gt;4.当进行 failover 时，配置所有 slaves 指向新的 master 所需的最大时间。&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;even&quot; readability=&quot;5&quot;&gt;&lt;td&gt;parallel-syncs&lt;/td&gt;
&lt;td&gt;这个配置项指定了在发生 failover 主备切换时最多可以有多少个 slave 同时对新的 master 进行 同步，这个数字越小，完成 failover 所需的时间就越长，但是如果这个数字越大，就意味着越 多的 slave 因为 replication 而不可用。可以通过将这个值设为 1 来保证每次只有一个 slave 处于不能处理命令请求的状态&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;h4 id=&quot;sentinel-验证&quot;&gt;3.3.2 Sentinel 验证&lt;/h4&gt;
&lt;p&gt;启动 Redis 服务和 Sentinel&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;cd /usr/local/soft/redis-5.0.5/src
# 启动 Redis 节点
./redis-server ../redis.conf
# 启动 Sentinel 节点
./redis-sentinel ../sentinel.conf
# 或者
./redis-server ../sentinel.conf --sentinel&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;查看集群状态：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;redis&amp;gt; info replication&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;203&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://www.sundablog.com/usr/uploads/2019/10/4111577095.png&quot; alt=&quot;1571747818355.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;204 和 205&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://www.sundablog.com/usr/uploads/2019/10/3266191507.png&quot; alt=&quot;1571747829582.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;模拟 master 宕机，在 203 执行：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;redis&amp;gt; shutdown&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;205 被选为新的 Master，只有一个 Slave 节点。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://www.sundablog.com/usr/uploads/2019/10/1808563502.png&quot; alt=&quot;1571747852515.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;注意看 sentinel.conf 里面的 redis-master 被修改了！&lt;br/&gt;模拟原 master 恢复，在 203 启动 redis-server。它还是 slave，但是 master 又有两个 slave 了。&lt;/p&gt;
&lt;p&gt;slave 宕机和恢复省略.&lt;/p&gt;
&lt;h4 id=&quot;sentinel-连接使用&quot;&gt;3.3.3 Sentinel 连接使用&lt;/h4&gt;
&lt;p&gt;Jedis 连接 Sentinel&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;package sentinel;

import redis.clients.jedis.JedisSentinelPool;

import java.util.HashSet;
import java.util.Properties;
import java.util.Set;


public class JedisSentinelTest {
    private static JedisSentinelPool pool;

    private static JedisSentinelPool createJedisPool() {
        // master的名字是sentinel.conf配置文件里面的名称
        String masterName = &quot;redis-master&quot;;
        Set&amp;lt;String&amp;gt; sentinels = new HashSet&amp;lt;String&amp;gt;();
        sentinels.add(&quot;192.168.8.203:26379&quot;);
        sentinels.add(&quot;192.168.8.204:26379&quot;);
        sentinels.add(&quot;192.168.8.205:26379&quot;);
        pool = new JedisSentinelPool(masterName, sentinels);
        return pool;
    }

    public static void main(String[] args) {
        JedisSentinelPool pool = createJedisPool();
        pool.getResource().set(&quot;qingshan&quot;, &quot;qq&quot;+System.currentTimeMillis());
        System.out.println(pool.getResource().get(&quot;qingshan&quot;));
    }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;master name 来自于 sentinel.conf 的配置&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;private static JedisSentinelPool createJedisPool() {
String masterName = &quot;redis-master&quot;;
Set&amp;lt;String&amp;gt; sentinels = new HashSet&amp;lt;String&amp;gt;();
sentinels.add(&quot;192.168.8.203:26379&quot;);
sentinels.add(&quot;192.168.8.204:26379&quot;);
sentinels.add(&quot;192.168.8.205:26379&quot;);
pool = new JedisSentinelPool(masterName, sentinels);
return pool;
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;Spring Boot 连接 Sentinel&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;
import com.gupaoedu.util.RedisUtil;
import org.junit.Test;
import org.junit.runner.RunWith;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.boot.test.context.SpringBootTest;
import org.springframework.test.context.junit4.SpringRunner;

@RunWith(SpringRunner.class)
@SpringBootTest
public class RedisAppTests {

    @Autowired
    RedisUtil util;

    @Test
    public void contextLoads() {
        util.set(&quot;boot&quot;, &quot;2673--&quot; +System.currentTimeMillis());
        System.out.println(util.get(&quot;boot&quot;));
    }

}
&lt;/code&gt;
&lt;/pre&gt;
&lt;pre&gt;
&lt;code&gt;spring.redis.sentinel.master=redis-master
spring.redis.sentinel.nodes=192.168.8.203:26379,192.168.8.204:26379,192.168.8.205:26379&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;​ 无论是 Jedis 还是 Spring Boot（2.x 版本默认是 Lettuce），都只需要配置全部哨兵的地址，由哨兵返回当前的 master 节点地址。&lt;/p&gt;
&lt;h3 id=&quot;哨兵机制的不足&quot;&gt;3.4 哨兵机制的不足&lt;/h3&gt;
&lt;p&gt;​ 主从切换的过程中会丢失数据，因为只有一个 master。&lt;br/&gt;​ 只能单点写，没有解决水平扩容的问题。&lt;br/&gt;​ 如果数据量非常大，这个时候我们需要多个 master-slave 的 group，把数据分布到不同的 group 中。&lt;br/&gt;​ 问题来了，数据怎么分片？分片之后，怎么实现路由？&lt;/p&gt;
&lt;h2 id=&quot;redis-分布式方案&quot;&gt;4 Redis 分布式方案&lt;/h2&gt;
&lt;p&gt;​ 如果要实现 Redis 数据的分片，我们有三种方案。第一种是在客户端实现相关的逻辑，例如用取模或者一致性哈希对 key 进行分片，查询和修改都先判断 key 的路由。&lt;br/&gt;​ 第二种是把做分片处理的逻辑抽取出来，运行一个独立的代理服务，客户端连接到这个代理服务，代理服务做请求的转发。&lt;br/&gt;​ 第三种就是基于服务端实现。&lt;/p&gt;
&lt;h3 id=&quot;客户端-sharding&quot;&gt;4.1 客户端 Sharding&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;https://www.sundablog.com/usr/uploads/2019/10/2531838701.png&quot; alt=&quot;1571748107273.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;Jedis 客户端提供了 Redis Sharding 的方案，并且支持连接池。&lt;/p&gt;
&lt;h4 id=&quot;shardedjedis&quot;&gt;4.1.1 ShardedJedis&lt;/h4&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;public class ShardingTest {
    public static void main(String[] args) {
        JedisPoolConfig poolConfig = new JedisPoolConfig();
​
        // Redis 服务器
        JedisShardInfo shardInfo1 = new JedisShardInfo(&quot;127.0.0.1&quot;, 6379);
        JedisShardInfo shardInfo2 = new JedisShardInfo(&quot;192.168.8.205&quot;, 6379);
​
        // 连接池
        List&amp;lt;JedisShardInfo&amp;gt; infoList = Arrays.asList(shardInfo1, shardInfo2);
        ShardedJedisPool jedisPool = new ShardedJedisPool(poolConfig, infoList);
        ShardedJedis jedis = null;
        try{
            jedis = jedisPool.getResource();
            for(int i=0; i&amp;lt;100; i++){
            jedis.set(&quot;k&quot;+i, &quot;&quot;+i);
        }
        for(int i=0; i&amp;lt;100; i++){
            System.out.println(jedis.get(&quot;k&quot;+i));
        }
        ​
        }finally{
            if(jedis!=null) {
            jedis.close();
            }
        }
    }
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;​ 使用 ShardedJedis 之类的客户端分片代码的优势是配置简单，不依赖于其他中间件，分区的逻辑可以自定义，比较灵活。但是基于客户端的方案，不能实现动态的服务增减，每个客户端需要自行维护分片策略，存在重复代码。&lt;br/&gt;​ 第二种思路就是把分片的代码抽取出来，做成一个公共服务，所有的客户端都连接到这个代理层。由代理层来实现请求和转发。&lt;/p&gt;
&lt;h3 id=&quot;代理-proxy&quot;&gt;4.2 代理 Proxy&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;https://www.sundablog.com/usr/uploads/2019/10/4121238828.png&quot; alt=&quot;1571748259203.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;典型的代理分区方案有 Twitter 开源的 Twemproxy 和国内的豌豆荚开源的 Codis。&lt;/p&gt;
&lt;h4 id=&quot;twemproxy&quot;&gt;4.2.1 Twemproxy&lt;/h4&gt;
&lt;p&gt;two-em-proxy&lt;br/&gt;https://github.com/twitter/twemproxy&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://www.sundablog.com/usr/uploads/2019/10/1173921951.png&quot; alt=&quot;1571748281722.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;Twemproxy 的优点：比较稳定，可用性高。&lt;/p&gt;
&lt;p&gt;不足：&lt;br/&gt;1、出现故障不能自动转移，架构复杂，需要借助其他组件（LVS/HAProxy +&lt;br/&gt;Keepalived）实现 HA&lt;br/&gt;2、扩缩容需要修改配置，不能实现平滑地扩缩容（需要重新分布数据）。&lt;/p&gt;
&lt;h4 id=&quot;codis&quot;&gt;4.2.2 Codis&lt;/h4&gt;
&lt;p&gt;https://github.com/CodisLabs/codis&lt;br/&gt;Codis 是一个代理中间件，用 Go 语言开发的。&lt;br/&gt;功能：客户端连接 Codis 跟连接 Redis 没有区别。&lt;/p&gt;
&lt;table&gt;&lt;thead/&gt;&lt;tbody readability=&quot;4&quot;&gt;&lt;tr class=&quot;odd&quot; readability=&quot;2&quot;&gt;&lt;td&gt;重新分片不需要重启&lt;/td&gt;
&lt;td&gt;Yes&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;td&gt;Yes&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;even&quot;&gt;&lt;td&gt;pipeline&lt;/td&gt;
&lt;td&gt;Yes&lt;/td&gt;
&lt;td&gt;Yes&lt;/td&gt;
&lt;td/&gt;
&lt;/tr&gt;&lt;tr class=&quot;odd&quot; readability=&quot;2&quot;&gt;&lt;td&gt;多 key 操作的 hash tags {}&lt;/td&gt;
&lt;td&gt;Yes&lt;/td&gt;
&lt;td&gt;Yes&lt;/td&gt;
&lt;td&gt;Yes&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;even&quot; readability=&quot;2&quot;&gt;&lt;td&gt;重新分片时的多 key 操作&lt;/td&gt;
&lt;td&gt;Yes&lt;/td&gt;
&lt;td/&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;odd&quot; readability=&quot;2&quot;&gt;&lt;td&gt;客户端支持&lt;/td&gt;
&lt;td&gt;所有&lt;/td&gt;
&lt;td&gt;所有&lt;/td&gt;
&lt;td&gt;支持 cluster 协议的客户端&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;&lt;img src=&quot;https://www.sundablog.com/usr/uploads/2019/10/3338271183.png&quot; alt=&quot;1571748437326.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;​ 分片原理：Codis 把所有的 key 分成了 N 个槽（例如 1024），每个槽对应一个分组，一个分组对应于一个或者一组 Redis 实例。Codis 对 key 进行 CRC32 运算，得到一个32 位的数字，然后模以 N（槽的个数），得到余数，这个就是 key 对应的槽，槽后面就是 Redis 的实例。比如 4 个槽：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://www.sundablog.com/usr/uploads/2019/10/2709501905.png&quot; alt=&quot;1571748485305.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;​ Codis 的槽位映射关系是保存在 Proxy 中的，如果要解决单点的问题，Codis 也要做集群部署，多个 Codis 节点怎么同步槽和实例的关系呢？需要运行一个 Zookeeper （或者 etcd/本地文件）。&lt;/p&gt;
&lt;p&gt;​ 在新增节点的时候，可以为节点指定特定的槽位。Codis 也提供了自动均衡策略。Codis 不支持事务，其他的一些命令也不支持。&lt;/p&gt;
&lt;p&gt;不支持的命令&lt;br/&gt;https://github.com/CodisLabs/codis/blob/release3.2/doc/unsupported_cmds.md&lt;br/&gt;获取数据原理（mget）：在 Redis 中的各个实例里获取到符合的 key，然后再汇总到 Codis 中。&lt;br/&gt;Codis 是第三方提供的分布式解决方案，在官方的集群功能稳定之前，Codis 也得到了大量的应用。&lt;/p&gt;
&lt;h3 id=&quot;redis-cluster&quot;&gt;4.3 Redis Cluster&lt;/h3&gt;
&lt;p&gt;https://redis.io/topics/cluster-tutorial/&lt;br/&gt;Redis Cluster 是在 Redis 3.0 的版本正式推出的，用来解决分布式的需求，同时也可以实现高可用。跟 Codis 不一样，它是去中心化的，客户端可以连接到任意一个可用节点。&lt;br/&gt;数据分片有几个关键的问题需要解决：&lt;br/&gt;1、数据怎么相对均匀地分片&lt;br/&gt;2、客户端怎么访问到相应的节点和数据&lt;br/&gt;3、重新分片的过程，怎么保证正常服务&lt;/p&gt;
&lt;h4 id=&quot;架构&quot;&gt;4.3.1 架构&lt;/h4&gt;
&lt;p&gt;​ Redis Cluster 可以看成是由多个 Redis 实例组成的数据集合。客户端不需要关注数据的子集到底存储在哪个节点，只需要关注这个集合整体。&lt;br/&gt;​ 以 3 主 3 从为例，节点之间两两交互，共享数据分片、节点状态等信息。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://www.sundablog.com/usr/uploads/2019/10/1932944897.png&quot; alt=&quot;1571748577107.png&quot;/&gt;&lt;/p&gt;
&lt;h4 id=&quot;搭建&quot;&gt;4.3.2 搭建&lt;/h4&gt;
&lt;p&gt;首先，本篇要基于单实例的安装，你的机器上已经有一个Redis&lt;br/&gt;博客 www.sundablog.com&lt;/p&gt;
&lt;p&gt;为了节省机器，我们直接把6个Redis实例安装在同一台机器上（3主3从），只是使用不同的端口号。&lt;br/&gt;机器IP 192.168.8.207&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;cd /usr/local/soft/redis-5.0.5
mkdir redis-cluster
cd redis-cluster
mkdir 7291 7292 7293 7294 7295 7296&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;复制redis配置文件到7291目录&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;cp /usr/local/soft/redis-5.0.5/redis.conf /usr/local/soft/redis-5.0.5/redis-cluster/7291&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;修改7291的配置文件&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;port 7291
dir /usr/local/soft/redis-5.0.5/redis-cluster/7291/
cluster-enabled yes
cluster-config-file nodes-7291.conf
cluster-node-timeout 5000
appendonly yes
pidfile /var/run/redis_7291.pid&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;把7291下的redis.conf复制到其他5个目录。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;cd /usr/local/soft/redis-5.0.5/redis-cluster/7291
cp redis.conf ../7292
cp redis.conf ../7293
cp redis.conf ../7294
cp redis.conf ../7295
cp redis.conf ../7296&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;批量替换内容&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;cd /usr/local/soft/redis-5.0.5/redis-cluster
sed -i 's/7291/7292/g' 7292/redis.conf
sed -i 's/7291/7293/g' 7293/redis.conf
sed -i 's/7291/7294/g' 7294/redis.conf
sed -i 's/7291/7295/g' 7295/redis.conf
sed -i 's/7291/7296/g' 7296/redis.conf&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;安装ruby依赖、rubygems依赖、gem-redis依赖&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;yum install ruby -y
yum install rubygems -y
gem install redis -v 3.0.7&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;启动6个Redis节点&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;cd /usr/local/soft/redis-5.0.5/
./src/redis-server redis-cluster/7291/redis.conf
./src/redis-server redis-cluster/7292/redis.conf
./src/redis-server redis-cluster/7293/redis.conf
./src/redis-server redis-cluster/7294/redis.conf
./src/redis-server redis-cluster/7295/redis.conf
./src/redis-server redis-cluster/7296/redis.conf&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;是否启动了6个进程&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;ps -ef|grep redis&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;创建集群&lt;br/&gt;旧版本中的redis-trib.rb已经废弃了，直接用–cluster命令&lt;br/&gt;注意用绝对IP，不要用127.0.0.1&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;cd /usr/local/soft/redis-5.0.5/src/
redis-cli --cluster create 192.168.8.207:7291 192.168.8.207:7292 192.168.8.207:7293 192.168.8.207:7294 192.168.8.207:7295 192.168.8.207:7296 --cluster-replicas 1&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;Redis会给出一个预计的方案，对6个节点分配3主3从，如果认为没有问题，输入yes确认&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;&amp;gt;&amp;gt;&amp;gt; Performing hash slots allocation on 6 nodes...
Master[0] -&amp;gt; Slots 0 - 5460
Master[1] -&amp;gt; Slots 5461 - 10922
Master[2] -&amp;gt; Slots 10923 - 16383
Adding replica 127.0.0.1:7295 to 127.0.0.1:7291
Adding replica 127.0.0.1:7296 to 127.0.0.1:7292
Adding replica 127.0.0.1:7294 to 127.0.0.1:7293
&amp;gt;&amp;gt;&amp;gt; Trying to optimize slaves allocation for anti-affinity
[WARNING] Some slaves are in the same host as their master
M: dfdc9c0589219f727e4fd0ad8dafaf7e0cfb4f1c 127.0.0.1:7291
   slots:[0-5460] (5461 slots) master
M: 8c878b45905bba3d7366c89ec51bd0cd7ce959f8 127.0.0.1:7292
   slots:[5461-10922] (5462 slots) master
M: aeeb7d7076d9b25a7805ac6f508497b43887e599 127.0.0.1:7293
   slots:[10923-16383] (5461 slots) master
S: ebc479e609ff8f6ca9283947530919c559a08f80 127.0.0.1:7294
   replicates aeeb7d7076d9b25a7805ac6f508497b43887e599
S: 49385ed6e58469ef900ec48e5912e5f7b7505f6e 127.0.0.1:7295
   replicates dfdc9c0589219f727e4fd0ad8dafaf7e0cfb4f1c
S: 8d6227aefc4830065624ff6c1dd795d2d5ad094a 127.0.0.1:7296
   replicates 8c878b45905bba3d7366c89ec51bd0cd7ce959f8
Can I set the above configuration? (type 'yes' to accept): &lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;注意看slot的分布&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;7291  [0-5460] (5461个槽) 
7292  [5461-10922] (5462个槽) 
7293  [10923-16383] (5461个槽)&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;集群创建完成&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;&amp;gt;&amp;gt;&amp;gt; Nodes configuration updated
&amp;gt;&amp;gt;&amp;gt; Assign a different config epoch to each node
&amp;gt;&amp;gt;&amp;gt; Sending CLUSTER MEET messages to join the cluster
Waiting for the cluster to join
....
&amp;gt;&amp;gt;&amp;gt; Performing Cluster Check (using node 127.0.0.1:7291)
M: dfdc9c0589219f727e4fd0ad8dafaf7e0cfb4f1c 127.0.0.1:7291
   slots:[0-5460] (5461 slots) master
   1 additional replica(s)
M: 8c878b45905bba3d7366c89ec51bd0cd7ce959f8 127.0.0.1:7292
   slots:[5461-10922] (5462 slots) master
   1 additional replica(s)
M: aeeb7d7076d9b25a7805ac6f508497b43887e599 127.0.0.1:7293
   slots:[10923-16383] (5461 slots) master
   1 additional replica(s)
S: 8d6227aefc4830065624ff6c1dd795d2d5ad094a 127.0.0.1:7296
   slots: (0 slots) slave
   replicates aeeb7d7076d9b25a7805ac6f508497b43887e599
S: ebc479e609ff8f6ca9283947530919c559a08f80 127.0.0.1:7294
   slots: (0 slots) slave
   replicates dfdc9c0589219f727e4fd0ad8dafaf7e0cfb4f1c
S: 49385ed6e58469ef900ec48e5912e5f7b7505f6e 127.0.0.1:7295
   slots: (0 slots) slave
   replicates 8c878b45905bba3d7366c89ec51bd0cd7ce959f8
[OK] All nodes agree about slots configuration.
&amp;gt;&amp;gt;&amp;gt; Check for open slots...
&amp;gt;&amp;gt;&amp;gt; Check slots coverage...
[OK] All 16384 slots covered&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;重置集群的方式是在每个节点上个执行&lt;code&gt;cluster reset&lt;/code&gt;，然后重新创建集群&lt;/p&gt;
&lt;p&gt;连接到客户端&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;redis-cli -p 7291
redis-cli -p 7292
redis-cli -p 7293&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;批量写入值&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;cd /usr/local/soft/redis-5.0.5/redis-cluster/
vim setkey.sh&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;脚本内容&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;#!/bin/bash
for ((i=0;i&amp;lt;20000;i++))
do
echo -en &quot;helloworld&quot; | redis-cli -h 192.168.8.207 -p 7291 -c -x set name$i &amp;gt;&amp;gt;redis.log
done&lt;/code&gt;
&lt;/pre&gt;
&lt;pre&gt;
&lt;code&gt;chmod +x setkey.sh
./setkey.sh
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;每个节点分布的数据&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;127.0.0.1:7292&amp;gt; dbsize
(integer) 6683
127.0.0.1:7293&amp;gt; dbsize
(integer) 6665
127.0.0.1:7291&amp;gt; dbsize
(integer) 6652&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;其他命令，比如添加节点、删除节点，重新分布数据：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;redis-cli --cluster help&lt;/code&gt;
&lt;/pre&gt;
&lt;pre&gt;
&lt;code&gt;Cluster Manager Commands:
  create         host1:port1 ... hostN:portN
                 --cluster-replicas &amp;lt;arg&amp;gt;
  check          host:port
                 --cluster-search-multiple-owners
  info           host:port
  fix            host:port
                 --cluster-search-multiple-owners
  reshard        host:port
                 --cluster-from &amp;lt;arg&amp;gt;
                 --cluster-to &amp;lt;arg&amp;gt;
                 --cluster-slots &amp;lt;arg&amp;gt;
                 --cluster-yes
                 --cluster-timeout &amp;lt;arg&amp;gt;
                 --cluster-pipeline &amp;lt;arg&amp;gt;
                 --cluster-replace
  rebalance      host:port
                 --cluster-weight &amp;lt;node1=w1...nodeN=wN&amp;gt;
                 --cluster-use-empty-masters
                 --cluster-timeout &amp;lt;arg&amp;gt;
                 --cluster-simulate
                 --cluster-pipeline &amp;lt;arg&amp;gt;
                 --cluster-threshold &amp;lt;arg&amp;gt;
                 --cluster-replace
  add-node       new_host:new_port existing_host:existing_port
                 --cluster-slave
                 --cluster-master-id &amp;lt;arg&amp;gt;
  del-node       host:port node_id
  call           host:port command arg arg .. arg
  set-timeout    host:port milliseconds
  import         host:port
                 --cluster-from &amp;lt;arg&amp;gt;
                 --cluster-copy
                 --cluster-replace
  help           

For check, fix, reshard, del-node, set-timeout you can specify the host and port of any working node in the cluster.&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;附录：&lt;/p&gt;
&lt;h3 id=&quot;集群命令&quot;&gt;集群命令&lt;/h3&gt;
&lt;p&gt;cluster info ：打印集群的信息&lt;br/&gt;cluster nodes ：列出集群当前已知的所有节点（node），以及这些节点的相关信息。&lt;br/&gt;cluster meet ：将 ip 和 port 所指定的节点添加到集群当中，让它成为集群的一份子。&lt;br/&gt;cluster forget ：从集群中移除 node_id 指定的节点(保证空槽道)。&lt;br/&gt;cluster replicate ：将当前节点设置为 node_id 指定的节点的从节点。&lt;br/&gt;cluster saveconfig ：将节点的配置文件保存到硬盘里面。&lt;/p&gt;
&lt;h3 id=&quot;槽slot命令&quot;&gt;槽slot命令&lt;/h3&gt;
&lt;p&gt;cluster addslots [slot …] ：将一个或多个槽（slot）指派（assign）给当前节点。&lt;br/&gt;cluster delslots [slot …] ：移除一个或多个槽对当前节点的指派。&lt;br/&gt;cluster flushslots ：移除指派给当前节点的所有槽，让当前节点变成一个没有指派任何槽的节点。&lt;br/&gt;cluster setslot node ：将槽 slot 指派给 node_id 指定的节点，如果槽已经指派给另一个节点，那么先让另一个节点删除该槽&amp;gt;，然后再进行指派。&lt;br/&gt;cluster setslot migrating ：将本节点的槽 slot 迁移到 node_id 指定的节点中。&lt;br/&gt;cluster setslot importing ：从 node_id 指定的节点中导入槽 slot 到本节点。&lt;br/&gt;cluster setslot stable ：取消对槽 slot 的导入（import）或者迁移（migrate）。&lt;/p&gt;
&lt;h3 id=&quot;键命令&quot;&gt;键命令&lt;/h3&gt;
&lt;p&gt;cluster keyslot ：计算键 key 应该被放置在哪个槽上。&lt;br/&gt;cluster countkeysinslot ：返回槽 slot 目前包含的键值对数量。&lt;br/&gt;cluster getkeysinslot ：返回 count 个 slot 槽中的键&lt;/p&gt;
&lt;h4 id=&quot;数据分布&quot;&gt;4.3.3 数据分布&lt;/h4&gt;
&lt;p&gt;​ 如果是希望数据分布相对均匀的话，我们首先可以考虑哈希后取模。&lt;/p&gt;
&lt;h5 id=&quot;哈希后-取模&quot;&gt;4.3.3.1 哈希后 取模&lt;/h5&gt;
&lt;p&gt;​ 例如，hash(key)%N，根据余数，决定映射到那一个节点。这种方式比较简单，属于静态的分片规则。但是一旦节点数量变化，新增或者减少，由于取模的 N 发生变化，数据需要重新分布。&lt;br/&gt;​ 为了解决这个问题，我们又有了一致性哈希算法。&lt;/p&gt;
&lt;h5 id=&quot;一致性&quot;&gt;4.3.3.2 一致性&lt;/h5&gt;
&lt;p&gt;​ 一致性哈希的原理：&lt;br/&gt;​ 把所有的哈希值空间组织成一个虚拟的圆环（哈希环），整个空间按顺时针方向组织。因为是环形空间，0 和 2^32-1 是重叠的。&lt;br/&gt;​ 假设我们有四台机器要哈希环来实现映射（分布数据），我们先根据机器的名称或者 IP 计算哈希值，然后分布到哈希环中（红色圆圈）。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://www.sundablog.com/usr/uploads/2019/10/4146683270.png&quot; alt=&quot;1571749016225.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;现在有 4 条数据或者 4 个访问请求，对 key 计算后，得到哈希环中的位置（绿色圆圈）。沿哈希环顺时针找到的第一个 Node，就是数据存储的节点。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://www.sundablog.com/usr/uploads/2019/10/699651623.png&quot; alt=&quot;1571749032547.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;在这种情况下，新增了一个 Node5 节点，不影响数据的分布。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://www.sundablog.com/usr/uploads/2019/10/2062785271.png&quot; alt=&quot;1571749046917.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;删除了一个节点 Node4，只影响相邻的一个节点&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://www.sundablog.com/usr/uploads/2019/10/936403857.png&quot; alt=&quot;1571749059910.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;​ 谷歌的 MurmurHash 就是一致性哈希算法。在分布式系统中，负载均衡、分库分表等场景中都有应用。&lt;/p&gt;
&lt;p&gt;​ 一致性哈希解决了动态增减节点时，所有数据都需要重新分布的问题，它只会影响到下一个相邻的节点，对其他节点没有影响。&lt;br/&gt;​ 但是这样的一致性哈希算法有一个缺点，因为节点不一定是均匀地分布的，特别是在节点数比较少的情况下，所以数据不能得到均匀分布。解决这个问题的办法是引入虚拟节点（Virtual Node）。&lt;br/&gt;​ 比如：2 个节点，5 条数据，只有 1 条分布到 Node2，4 条分布到 Node1，不均匀。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://www.sundablog.com/usr/uploads/2019/10/3952963077.png&quot; alt=&quot;1571749095499.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;Node1 设置了两个虚拟节点，Node2 也设置了两个虚拟节点（虚线圆圈）。&lt;br/&gt;这时候有 3 条数据分布到 Node1，1 条数据分布到 Node2。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://www.sundablog.com/usr/uploads/2019/10/363414605.png&quot; alt=&quot;1571749105882.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;​ Redis 虚拟槽分区&lt;/p&gt;
&lt;p&gt;​ Redis 既没有用哈希取模，也没有用一致性哈希，而是用虚拟槽来实现的。&lt;br/&gt;​ Redis 创建了 16384 个槽（slot），每个节点负责一定区间的 slot。比如 Node1 负责 0-5460，Node2 负责 5461-10922，Node3 负责 10923-16383。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://www.sundablog.com/usr/uploads/2019/10/3533150185.png&quot; alt=&quot;1571749129064.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;​ Redis 的每个 master 节点维护一个 16384 位（2048bytes=2KB）的位序列，比如：序列的第 0 位是 1，就代表第一个 slot 是它负责；序列的第 1 位是 0，代表第二个 slot不归它负责。&lt;/p&gt;
&lt;p&gt;​ 对象分布到 Redis 节点上时，对 key 用 CRC16 算法计算再%16384，得到一个 slot的值，数据落到负责这个 slot 的 Redis 节点上。&lt;/p&gt;
&lt;p&gt;​ 查看 key 属于哪个 slot：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;redis&amp;gt; cluster keyslot sunda&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;注意：key 与 slot 的关系是永远不会变的，会变的只有 slot 和 Redis 节点的关系。&lt;/p&gt;
&lt;p&gt;问题：怎么让相关的数据落到同一个节点上？&lt;/p&gt;
&lt;p&gt;比如有些 multi key 操作是不能跨节点的，如果要让某些数据分布到一个节点上，例如用户 2673 的基本信息和金融信息，怎么办？&lt;/p&gt;
&lt;p&gt;在 key 里面加入{hash tag}即可。Redis 在计算槽编号的时候只会获取{}之间的字符串进行槽编号计算，这样由于上面两个不同的键，{}里面的字符串是相同的，因此他们可以被计算出相同的槽。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;user{2673}base=…
user{2673}fin=…
127.0.0.1:7293&amp;gt; set a{qs}a 1
OK
127.0.0.1:7293&amp;gt; set a{qs}b 1
OK
127.0.0.1:7293&amp;gt; set a{qs}c 1
OK
127.0.0.1:7293&amp;gt; set a{qs}d 1
OK
127.0.0.1:7293&amp;gt; set a{qs}e 1
OK&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;问题：客户端连接到哪一台服务器？访问的数据不在当前节点上，怎么办？&lt;/p&gt;
&lt;h4 id=&quot;客户端-重定向&quot;&gt;4.3.4 客户端 重定向&lt;/h4&gt;
&lt;p&gt;比如在 7291 端口的 Redis 的 redis-cli 客户端操作：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;127.0.0.1:7291&amp;gt; set qs 1
(error) MOVED 13724 127.0.0.1:7293&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;​ 服务端返回 MOVED，也就是根据 key 计算出来的 slot 不归 7191 端口管理，而是归 7293 端口管理，服务端返回 MOVED 告诉客户端去 7293 端口操作。&lt;br/&gt;​ 这个时候更换端口，用 redis-cli –p 7293 操作，才会返回 OK。或者用./redis-cli -c -p port 的命令（c 代表 cluster）。这样客户端需要连接两次。&lt;br/&gt;​ Jedis 等客户端会在本地维护一份 slot——node 的映射关系，大部分时候不需要重定向，所以叫做 smart jedis（需要客户端支持）。&lt;br/&gt;问题：新增或下线了 Master 节点，数据怎么迁移（重新分配）？&lt;/p&gt;
&lt;h4 id=&quot;数据迁移&quot;&gt;4.3.5 数据迁移&lt;/h4&gt;
&lt;p&gt;因为 key 和 slot 的关系是永远不会变的，当新增了节点的时候，需要把原有的 slot&lt;br/&gt;分配给新的节点负责，并且把相关的数据迁移过来。&lt;/p&gt;
&lt;p&gt;添加新节点（新增一个 7297）：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;redis-cli --cluster add-node 127.0.0.1:7291 127.0.0.1:7297&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;新增的节点没有哈希槽，不能分布数据，在原来的任意一个节点上执行：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;redis-cli --cluster reshard 127.0.0.1:7291&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;输入需要分配的哈希槽的数量（比如 500），和哈希槽的来源节点（可以输入 all 或者 id）。&lt;/p&gt;
&lt;p&gt;问题：只有主节点可以写，一个主节点挂了，从节点怎么变成主节点？&lt;/p&gt;
&lt;h4 id=&quot;高可用-和主-从-切换原理&quot;&gt;4.3.6 高可用 和主 从 切换原理&lt;/h4&gt;
&lt;p&gt;​ 当 slave 发现自己的 master 变为 FAIL 状态时，便尝试进行 Failover，以期成为新的master。由于挂掉的master可能会有多个slave，从而存在多个slave竞争成为master节点的过程， 其过程如下：&lt;br/&gt;​ 1.slave 发现自己的 master 变为 FAIL&lt;br/&gt;​ 2.将自己记录的集群 currentEpoch 加 1，并广播 FAILOVER_AUTH_REQUEST 信息&lt;br/&gt;​ 3.其他节点收到该信息，只有 master 响应，判断请求者的合法性，并发送FAILOVER_AUTH_ACK，对每一个 epoch 只发送一次 ack&lt;br/&gt;​ 4.尝试 failover 的 slave 收集 FAILOVER_AUTH_ACK&lt;br/&gt;​ 5.超过半数后变成新 Master、&lt;br/&gt;​ 6.广播 Pong 通知其他集群节点。&lt;/p&gt;
&lt;p&gt;Redis Cluster 既能够实现主从的角色分配，又能够实现主从切换，相当于集成了Replication 和 Sentinal 的功能&lt;/p&gt;
&lt;h4 id=&quot;总结&quot;&gt;4.3.7 总结&lt;/h4&gt;
&lt;p&gt;优势&lt;br/&gt;1. 无中心架构。&lt;br/&gt;2. 数据按照 slot 存储分布在多个节点，节点间数据共享，可动态调整数据分布。&lt;br/&gt;3. 可扩展性，可线性扩展到 1000 个节点（官方推荐不超过 1000 个），节点可动态添加或删除。&lt;br/&gt;4. 高可用性，部分节点不可用时，集群仍可用。通过增加 Slave 做 standby 数据副本，能够实现故障自动 failover，节点之间通过 gossip 协议交换状态信息，用投票机制完成 Slave 到 Master 的角色提升。&lt;br/&gt;5. 降低运维成本，提高系统的扩展性和可用性。&lt;/p&gt;
&lt;p&gt;不足&lt;br/&gt;1. Client 实现复杂，驱动要求实现 Smart Client，缓存 slots mapping 信息并及时更新，提高了开发难度，客户端的不成熟影响业务的稳定性。&lt;br/&gt;2. 节点会因为某些原因发生阻塞（阻塞时间大于 clutser-node-timeout），被判断下线，这种 failover 是没有必要的。&lt;br/&gt;3. 数据通过异步复制，不保证数据的强一致性。&lt;br/&gt;4. 多个业务使用同一套集群时，无法根据统计区分冷热数据，资源隔离性较差，容易出现相互影响的情况。&lt;/p&gt;

&lt;p&gt;如果大家想要实时关注我更新的文章以及分享的干货的话，可以关注我的公众号。&lt;br/&gt;&lt;img src=&quot;https://www.sundablog.com/usr/uploads/2019/10/3181442442.png&quot; alt=&quot;QQ图片20191012084332.png&quot;/&gt;&lt;/p&gt;
</description>
<pubDate>Wed, 23 Oct 2019 00:33:00 +0000</pubDate>
<dc:creator>哒哒网络</dc:creator>
<og:description>Redis分布式篇 1 为什么 需要 Redis 集群 1.1 为什么需要集群? 1.1.1 性能 ​	Redis 本身的 QPS 已经很高了，但是如果在一些并发量非常高的情况下，性能还是会受到影响。</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/sundaboke/p/11723893.html</dc:identifier>
</item>
<item>
<title>【译】ASP.NET Core在 .NET Core 3.1 Preview 1中的更新 - 芝麻麻雀</title>
<link>http://www.cnblogs.com/sesametech-netcore/p/11723840.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/sesametech-netcore/p/11723840.html</guid>
<description>&lt;p&gt;.NET Core 3.1 Preview 1现在可用。此版本主要侧重于错误修复，但同时也包含一些新功能。&lt;br/&gt;这是此版本的ASP.NET Core的新增功能：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;对Razor components的部分类支持&lt;/li&gt;
&lt;li&gt;将参数传递给顶级组件&lt;/li&gt;
&lt;li&gt;在HttpSysServer中支持共享队列&lt;/li&gt;
&lt;li&gt;在SameSite cookies的重大更改&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;除了.NET Core 3.1 Preview版本发布之外，我们还发布了Blazor WebAssembly的更新，现在要求.NET Core 3.1. 若要使用Blazor WebAssembly，您需要安装.NET Core 3.1 Preview 1以及Visual Studio的最新预览版。&lt;/p&gt;
&lt;p&gt;有关其他详细信息和已知问题，请参见&lt;a href=&quot;https://github.com/dotnet/core/tree/master/release-notes/3.1&quot;&gt;发行说明&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;开始吧&lt;/h2&gt;
&lt;p&gt;要在.NET Core 3.1 Preview 1 中使用ASP.NET Core，需要安装&lt;a href=&quot;https://dotnet.microsoft.com/download/dotnet-core/3.1&quot;&gt;.NET Core Preview 1 SDK&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;如果你是在Windows上使用的Visual Studio，为获得最佳体验，建议你安装Visual Studio 2019 16.4 的最新预览版。安装Visual Studio 2019 16.4 还将安装上.NET Core 3.1 Preview 1，因此你无需单独安装它。为在.NET Core 3.1 中使用Blazor 开发，Visual Studio 2019 16.4是必须的。&lt;/p&gt;
&lt;p&gt;要安装最新的Blazor WebAssembly模板，请运行以下命令：&lt;/p&gt;
&lt;p&gt;&lt;code data-backticks=&quot;1&quot;&gt;dotnet new -i Microsoft.AspNetCore.Blazor.Templates::3.1.0-preview1.19508.20&lt;/code&gt;&lt;/p&gt;
&lt;h2&gt;升级现有项目&lt;/h2&gt;
&lt;p&gt;要将现有的ASP.NET Core 3.0项目升级到3.1 Preview 1：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;将所有针对netcoreapp3.0的项目更新为netcoreapp3.1&lt;/li&gt;
&lt;li&gt;将所有Microsoft.AspNetCore.*软件包引用更新为3.1.0-preview1.19506.1&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;另请参阅ASP.NET Core 3.1中&lt;a href=&quot;https://github.com/aspnet/announcements/issues?utf8=%E2%9C%93&amp;amp;q=is%3Aissue+label%3A3.1.0+label%3A%22Breaking+change%22&quot;&gt;重大更改&lt;/a&gt;的完成列表。&lt;/p&gt;
&lt;p&gt;现在，您应该都已准备好使用.NET Core 3.1 Preview 1！&lt;/p&gt;
&lt;h2&gt;对Razor components的部分类支持&lt;/h2&gt;
&lt;p&gt;Razor components现在作为分布类生成。你可以使用定义为局部类的代码隐藏文件编写Razor components的代码，而不用在单个文件中定义该组件的所有代码。&lt;/p&gt;
&lt;p&gt;例如，不是用&lt;code data-backticks=&quot;1&quot;&gt;@code&lt;/code&gt;块定义默认的Counter component,而是这样：&lt;br/&gt;Counter.razor&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;@page &quot;/counter&quot;

&amp;lt;h1&amp;gt;Counter&amp;lt;/h1&amp;gt;

&amp;lt;p&amp;gt;Current count: @currentCount&amp;lt;/p&amp;gt;

&amp;lt;button class=&quot;btn btn-primary&quot; @onclick=&quot;IncrementCount&quot;&amp;gt;Click me&amp;lt;/button&amp;gt;

@code {
   int currentCount = 0;

   void IncrementCount()
   {
       currentCount++;
   }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;现在，你可以使用部分类将代码分离为代码隐藏文件：&lt;br/&gt;Counter.razor&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;@page &quot;/counter&quot;

&amp;lt;h1&amp;gt;Counter&amp;lt;/h1&amp;gt;

&amp;lt;p&amp;gt;Current count: @currentCount&amp;lt;/p&amp;gt;

&amp;lt;button class=&quot;btn btn-primary&quot; @onclick=&quot;IncrementCount&quot;&amp;gt;Click me&amp;lt;/button&amp;gt;
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;Counter.razor.cs&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;namespace BlazorApp1.Pages
{
   public partial class Counter
   {
       int currentCount = 0;

       void IncrementCount()
       {
           currentCount++;
       }
   }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;h2&gt;将参数传递给顶级组件&lt;/h2&gt;
&lt;p&gt;现在，Blazor Server应用程序可以在初始渲染期间将参数传递给顶级组件（top-level components）。以前，你只能使用&lt;code data-backticks=&quot;1&quot;&gt;RenderMode.Static&lt;/code&gt;将参数传递给顶级组件。在此次发布的版本中，同时支持&lt;code data-backticks=&quot;1&quot;&gt;RenderMode.Server&lt;/code&gt;和&lt;code data-backticks=&quot;1&quot;&gt;RenderModel.ServerPrerendered&lt;/code&gt;。任何指定的参数值都将序列化为JSON，并包含在初始响应中。&lt;/p&gt;
&lt;p&gt;例如，你可以使用特定的当前计数来渲染Counter组件，如下所示&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;@(await Html.RenderComponentAsync&amp;lt;Counter&amp;gt;(RenderMode.ServerPrerendered, new { CurrentCount = 123 }))
&lt;/code&gt;
&lt;/pre&gt;
&lt;h2&gt;在HttpSysServer中支持共享队列&lt;/h2&gt;
&lt;p&gt;除了HttpSysServer创建匿名请求队列的现有行为外，我们还添加了创建或附加到现有命名HTTP.sys 请求队列的功能。&lt;br/&gt;这应该启用一下方案：拥有队列的HTTP.Sys控制器进程独立于侦听器进程，从而可以在跨多个侦听器进程重新启动之间保留现有的连接和排队的请求。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;public static IHostBuilder CreateHostBuilder(string[] args) =&amp;gt;
    Host.CreateDefaultBuilder(args)
        .ConfigureWebHostDefaults(webBuilder =&amp;gt;
        {
            // ...
            webBuilder.UseHttpSys(options =&amp;gt;
            {
                options.RequestQueueName = &quot;MyExistingQueue&quot;,
                options.RequestQueueMode = RequestQueueMode.CreateOrAttach
            })
        });
&lt;/code&gt;
&lt;/pre&gt;
&lt;h2&gt;在SameSite cookies的重大更改&lt;/h2&gt;
&lt;p&gt;此版本更新了ASP.NET Core中SameSite cookie的行为，以符合浏览器强制执行的最新标准。有关这些更改及其对现有应用程序的影响的详细信息，请参见https://github.com/aspnet/Announcements/issues/390。&lt;/p&gt;
&lt;h2&gt;给予反馈&lt;/h2&gt;
&lt;p&gt;我们希望您喜欢此ASP.NET Core预览版中的新功能！通过在&lt;a href=&quot;https://github.com/aspnet/aspnetcore/issues&quot;&gt;GitHub&lt;/a&gt;上提交问题，请让我们知道您的想法。&lt;/p&gt;
&lt;p&gt;感谢您试用ASP.NET Core！&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1746998/201910/1746998-20191023081612544-2019225360.jpg&quot;/&gt;&lt;/p&gt;
</description>
<pubDate>Wed, 23 Oct 2019 00:11:00 +0000</pubDate>
<dc:creator>芝麻麻雀</dc:creator>
<og:description>.NET Core 3.1 Preview 1现在可用。此版本主要侧重于错误修复，但同时也包含一些新功能。 这是此版本的ASP.NET Core的新增功能： 对Razor components的部分类</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/sesametech-netcore/p/11723840.html</dc:identifier>
</item>
<item>
<title>AOP框架Dora.Interception 3.0 [3]: 拦截器设计 - Artech</title>
<link>http://www.cnblogs.com/artech/p/dora-interception-3-03.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/artech/p/dora-interception-3-03.html</guid>
<description>&lt;p&gt;对于所有的AOP框架来说，多个拦截器最终会应用到某个方法上。这些拦截器按照指定的顺序构成一个管道，管道的另一端就是针对目标方法的调用。从设计角度来将，拦截器和中间件本质是一样的，那么我们可以按照类似的模式来设计拦截器。&lt;/p&gt;

&lt;p&gt;我们为整个拦截器管道定义了一个统一的执行上下文，并将其命名为InvocationContext。如下面的代码片段所示，我们可以利用InvocationContext对象得到方法调用上下文的相关信息，其中包括两个方法（定义在接口和实现类型），目标对象、参数列表（含输入和输出参数）、返回值（可读写）。Properties 属性提供了一个自定义的属性容器，我们可以利用它来存放任意与当前方法调用上下文相关的信息。如果需要调用后续的拦截器或者目标方法（如果当前为最后一个拦截器），我们只需要直接调用&lt;strong&gt;ProceedAsync&lt;/strong&gt;方法即可。&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;36&quot;&gt;
&lt;pre&gt;
&lt;span&gt;public&lt;/span&gt; &lt;span&gt;abstract&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;&lt;span&gt; InvocationContext
{    
    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;abstract&lt;/span&gt; MethodInfo Method { &lt;span&gt;get&lt;/span&gt;&lt;span&gt;; }
    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; MethodInfo TargetMethod { &lt;span&gt;get&lt;/span&gt;&lt;span&gt;; }
    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;abstract&lt;/span&gt; &lt;span&gt;object&lt;/span&gt; Target { &lt;span&gt;get&lt;/span&gt;&lt;span&gt;; }
    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;abstract&lt;/span&gt; &lt;span&gt;object&lt;/span&gt;[] Arguments { &lt;span&gt;get&lt;/span&gt;&lt;span&gt;; }
    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;abstract&lt;/span&gt; &lt;span&gt;object&lt;/span&gt; ReturnValue { &lt;span&gt;get&lt;/span&gt;; &lt;span&gt;set&lt;/span&gt;&lt;span&gt;; }  
    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;abstract&lt;/span&gt; IDictionary&amp;lt;&lt;span&gt;string&lt;/span&gt;, &lt;span&gt;object&lt;/span&gt;&amp;gt; Properties { &lt;span&gt;get&lt;/span&gt;&lt;span&gt;; }
    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt;&lt;span&gt; Task ProceedAsync();
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;既然所有的拦截器都是在同一个InvocationContext上下文中执行的，那么我们可以将任意的拦截操作定义成一个&lt;strong&gt;Func&amp;lt;InvocationContext, Task&amp;gt;&lt;/strong&gt;对象。Func&amp;lt;InvocationContext, Task&amp;gt;对象不仅可以表示某项单一的拦截操作，实际上包括目标方法调用在内的整个拦截器管道都可以表示成一个Func&amp;lt;InvocationContext, Task&amp;gt;对象。由于这个委托的重要性，我们将它定义成如下这个InterceptDelegate类型。&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;32&quot;&gt;
&lt;pre&gt;
&lt;span&gt;public&lt;/span&gt; &lt;span&gt;delegate&lt;/span&gt; Task InterceptDelegate(InvocationContext context);
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;如果以ASP.NET Core框架的请求处理管道作为类比，那么InvocationContext相当于HttpContext，而InterceptDelegate自然对应的就是RequestDelegate。我们知道ASP.NET Core框架将中间件表示成Func&amp;lt;RequestDelegate, RequestDelegate&amp;gt;对象，那么拦截器自然就可以表示成一个&lt;strong&gt;Func&amp;lt;InterceptDelegate, InterceptDelegate&amp;gt;&lt;/strong&gt;。如果读者朋友对此不太理解，可以参阅我的文章《&lt;a href=&quot;https://www.cnblogs.com/artech/p/inside-asp-net-core-framework.html&quot;&gt;200行代码，7个对象——让你了解ASP.NET Core框架的本质&lt;/a&gt;》。由于拦截器的重要性，我们也将它定义成如下这个单独的InterceptorDelegate类型。&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;32&quot;&gt;
&lt;pre&gt;
&lt;span&gt;public&lt;/span&gt; &lt;span&gt;delegate&lt;/span&gt; InterceptDelegate InterceptorDelegate(InterceptDelegate next);
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Dora.Interception和ASP.NET Core采用几乎一致的设计。对于ASP.NET Core来说，虽然中间件最终是通过Func&amp;lt;InterceptDelegate, InterceptDelegate&amp;gt;表示的，但是我们可以将中间件定义成一个按照约定定义的类型。Dora.Interception同样支持基于约定的拦截器类型定义。&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;37&quot;&gt;
&lt;pre&gt;
&lt;span&gt;public&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;&lt;span&gt; FoobarInterceptor
{
    &lt;/span&gt;&lt;span&gt;private&lt;/span&gt; &lt;span&gt;readonly&lt;/span&gt;&lt;span&gt; IFoo _foo;
    &lt;/span&gt;&lt;span&gt;private&lt;/span&gt; &lt;span&gt;readonly&lt;/span&gt;&lt;span&gt; IBar _bar;
    &lt;/span&gt;&lt;span&gt;private&lt;/span&gt; &lt;span&gt;readonly&lt;/span&gt; &lt;span&gt;string&lt;/span&gt;&lt;span&gt; _baz;

    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; FoobarInterceptor(IFoo foo, IBar bar, &lt;span&gt;string&lt;/span&gt;&lt;span&gt; baz)
    {
        _foo &lt;/span&gt;=&lt;span&gt; foo;
        _bar &lt;/span&gt;=&lt;span&gt; bar;
        _baz &lt;/span&gt;=&lt;span&gt; baz;
    }

    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;async&lt;/span&gt;&lt;span&gt; InvokeAsync(InvocationContext context)
    {
        &lt;/span&gt;&lt;span&gt;await&lt;/span&gt;&lt;span&gt; PreInvokeAsync();
        &lt;/span&gt;&lt;span&gt;await&lt;/span&gt;&lt;span&gt; context.ProceedAsync();
        &lt;/span&gt;&lt;span&gt;await&lt;/span&gt;&lt;span&gt; PostInvokeAsync();
    }
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;如上定义的FoobarInterceptor展现了一个典型的基于约定定义的拦截器类型，它体现了如下的约定：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;拦截器类型是一个实例类型（不能定义成静态类型）；&lt;/li&gt;
&lt;li&gt;必须具有一个公共构造函数，其中可以定义任意参数。&lt;/li&gt;
&lt;li&gt;拦截操作定义在一个名为InvokeAsync的方法中，该方法的返回类型为Task，其中包含一个&lt;strong&gt;InvocationContext&lt;/strong&gt;类型的参数。如果需要调用后续拦截器管道，需要显式调用InvocationContext上下文的&lt;strong&gt;ProceedAsync&lt;/strong&gt;方法。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;由于拦截器最终是利用.NET Core的依赖注入框架提供的，所以依赖服务可以直接注入拦截器的构造函数中。但是就服务的生命周期来讲，拦截器本质上是一个&lt;strong&gt;Singleton&lt;/strong&gt;服务，我们不应该将&lt;strong&gt;Scoped&lt;/strong&gt;服务注入到它的构造函数中。如果具有针对Scoped服务注入的需要，我们应该将它注入到InvokeAsync方法中。&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;36&quot;&gt;
&lt;pre&gt;
&lt;span&gt;public&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;&lt;span&gt; FoobarInterceptor
{
    &lt;/span&gt;&lt;span&gt;private&lt;/span&gt; &lt;span&gt;readonly&lt;/span&gt; &lt;span&gt;string&lt;/span&gt;&lt;span&gt; _baz;

    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; FoobarInterceptor(&lt;span&gt;string&lt;/span&gt;&lt;span&gt; baz)
    {
        _baz &lt;/span&gt;=&lt;span&gt; baz;
    }

    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;async&lt;/span&gt;&lt;span&gt; InvokeAsync(InvocationContext context, IFoo foo, IBar bar)
    {
        &lt;/span&gt;&lt;span&gt;await&lt;/span&gt;&lt;span&gt; PreInvokeAsync();
        &lt;/span&gt;&lt;span&gt;await&lt;/span&gt;&lt;span&gt; context.ProceedAsync();
        &lt;/span&gt;&lt;span&gt;await&lt;/span&gt;&lt;span&gt; PostInvokeAsync();
    }
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;当Dora.Interception在调用InvokeAsync方法的时候，它会利用&lt;strong&gt;当前Scope的IServiceProvider对象&lt;/strong&gt;来提供其参数。对于ASP.NET Core应用来说，如果拦截器的执行在整个请求处理的调用链中，这个IServiceProvider对象就是当前HttpContext的RequestServices属性。如果当前IServiceProvider不存在，作为根的IServiceProvider对象会被使用。&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.cnblogs.com/artech/p/dora-interception-3-01.html&quot;&gt;AOP框架Dora.Interception 3.0 [1]: 编程体验&lt;/a&gt;&lt;br/&gt;&lt;a href=&quot;https://www.cnblogs.com/artech/p/dora-interception-3-2.html&quot;&gt;AOP框架Dora.Interception 3.0 [2]: 实现原理&lt;/a&gt;&lt;br/&gt;&lt;a href=&quot;https://www.cnblogs.com/artech/p/dora-interception-3-03.html&quot;&gt;AOP框架Dora.Interception 3.0 [3]: 拦截器设计&lt;/a&gt;&lt;br/&gt;&lt;a href=&quot;https://www.cnblogs.com/artech/p/dora-interception-3-04.html&quot;&gt;AOP框架Dora.Interception 3.0 [4]: 基于特性的拦截器注册&lt;/a&gt;&lt;br/&gt;&lt;a href=&quot;https://www.cnblogs.com/artech/p/dora-interception-3-05.html&quot;&gt;AOP框架Dora.Interception 3.0 [5]: 基于策略的拦截器注册&lt;/a&gt;&lt;br/&gt;&lt;a href=&quot;https://www.cnblogs.com/artech/p/dora-interception-3-06.html&quot;&gt;AOP框架Dora.Interception 3.0 [6]: 自定义拦截器注册方式&lt;/a&gt;&lt;/p&gt;
</description>
<pubDate>Tue, 22 Oct 2019 23:26:00 +0000</pubDate>
<dc:creator>Artech</dc:creator>
<og:description>对于所有的AOP框架来说，多个拦截器最终会应用到某个方法上。这些拦截器按照指定的顺序构成一个管道，管道的另一端就是针对目标方法的调用。从设计角度来将，拦截器和中间件本质是一样的，那么我们可以按照类似的</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/artech/p/dora-interception-3-03.html</dc:identifier>
</item>
<item>
<title>PHP7源码之array_unique函数分析 - 鹿呦呦</title>
<link>http://www.cnblogs.com/sunshineliulu/p/11723624.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/sunshineliulu/p/11723624.html</guid>
<description>&lt;p&gt;以下源码基于 PHP 7.3.8&lt;/p&gt;
&lt;blockquote readability=&quot;14&quot;&gt;
&lt;p&gt;array array_unique ( array $array [, int $sort_flags = SORT_STRING ] )&lt;br/&gt;(PHP 4 &amp;gt;= 4.0.1, PHP 5, PHP 7)&lt;br/&gt;array_unique — 移除数组中重复的值&lt;/p&gt;
&lt;p&gt;参数说明：&lt;br/&gt;array：输入的数组。&lt;br/&gt;sort_flag：（可选）排序类型标记，用于修改排序行为，主要有以下值：&lt;/p&gt;
&lt;blockquote readability=&quot;7&quot;&gt;
&lt;p&gt;&lt;strong&gt;SORT_REGULAR&lt;/strong&gt; - 按照通常方法比较（不修改类型）&lt;br/&gt;&lt;strong&gt;SORT_NUMERIC&lt;/strong&gt; - 按照数字形式比较&lt;br/&gt;&lt;strong&gt;SORT_STRING&lt;/strong&gt; - 按照字符串形式比较&lt;br/&gt;&lt;strong&gt;SORT_LOCALE_STRING&lt;/strong&gt; - 根据当前的本地化设置，按照字符串比较。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;code&gt;array_unique&lt;/code&gt; 函数的源代码在 /ext/standard/array.c 文件中。由于&lt;/p&gt;
&lt;pre class=&quot;c&quot;&gt;
&lt;code&gt;PHP_FUNCTION(array_unique){ 
    // code...
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;篇幅过长，完整代码不在这里贴出来了，可以参见 &lt;a href=&quot;https://github.com/php/php-src/blob/PHP-7.3.8/ext/standard/array.c&quot;&gt;GitHub&lt;/a&gt; 贴出的源代码。&lt;/p&gt;
&lt;h4 id=&quot;定义变量&quot;&gt;定义变量&lt;/h4&gt;
&lt;pre class=&quot;c&quot;&gt;
&lt;code&gt;    zval *array;
    uint32_t idx;
    Bucket *p;
    struct bucketindex *arTmp, *cmpdata, *lastkept;
    unsigned int i;
    zend_long sort_type = PHP_SORT_STRING; // 默认的排序规则
    compare_func_t cmp;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;首先是定义变量，&lt;code&gt;array_unique&lt;/code&gt; 函数默认使用 &lt;code&gt;PHP_SORT_STRING&lt;/code&gt; 排序，&lt;code&gt;PHP_SORT_STRING&lt;/code&gt; 在 /ext/standard/php_array.h 头文件中定义。&lt;/p&gt;
&lt;pre class=&quot;c&quot;&gt;
&lt;code&gt;#define PHP_SORT_STRING             2&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;可以看到和开头PHP函数的 &lt;code&gt;sort_flag&lt;/code&gt; 参数默认的预定义常量 &lt;code&gt;SORT_STRING&lt;/code&gt; 很像。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;compare_func_t cmp&lt;/code&gt; 这行代码没看懂，不清楚是做什么的。&lt;code&gt;compare_func_t&lt;/code&gt; 在 /Zend/zend_types.h 中定义：&lt;/p&gt;
&lt;pre class=&quot;c&quot;&gt;
&lt;code&gt;typedef int  (*compare_func_t)(const void *, const void *);&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;应该是定义了一个指向 &lt;code&gt;int&lt;/code&gt; 型返回值且带有两个指针常量参数的函数指针类型，没有查到相关资料，先搁着，继续往下看。&lt;/p&gt;
&lt;h4 id=&quot;参数解析&quot;&gt;参数解析&lt;/h4&gt;
&lt;pre class=&quot;c&quot;&gt;
&lt;code&gt;    ZEND_PARSE_PARAMETERS_START(1, 2)
        Z_PARAM_ARRAY(array)
        Z_PARAM_OPTIONAL
        Z_PARAM_LONG(sort_type)
    ZEND_PARSE_PARAMETERS_END();&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;ZEND_PARSE_PARAMETERS_START(1, 2)&lt;/code&gt;，第一个参数表示必传参数个数，第二个参数表示最多参数个数，即该函数参数范围是 1-2 个。&lt;/p&gt;
&lt;h4 id=&quot;数组元素个数判断&quot;&gt;数组元素个数判断&lt;/h4&gt;
&lt;pre class=&quot;c&quot;&gt;
&lt;code&gt;    if (Z_ARRVAL_P(array)-&amp;gt;nNumOfElements &amp;lt;= 1) {  /* nothing to do */
        ZVAL_COPY(return_value, array);
        return;
    }&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;这段代码很容易看懂，当数组为空或只有 1 个元素时，无需去重操作，直接将 &lt;code&gt;array&lt;/code&gt; 拷贝到新数组 &lt;code&gt;return_value&lt;/code&gt;来返回即可。&lt;/p&gt;
&lt;h4 id=&quot;分配持久化内存&quot;&gt;分配持久化内存&lt;/h4&gt;
&lt;p&gt;这一步只有当 &lt;code&gt;sort_type&lt;/code&gt; 为 &lt;code&gt;PHP_SORT_STRING&lt;/code&gt; 时才执行。在下面可以看到调用 &lt;code&gt;zend_hash_init&lt;/code&gt; 初始化了 &lt;code&gt;array&lt;/code&gt;，调用 &lt;code&gt;zend_hash_destroy&lt;/code&gt; 释放持久化的 内存。&lt;/p&gt;
&lt;pre class=&quot;c&quot;&gt;
&lt;code&gt;    if (sort_type == PHP_SORT_STRING) {
        HashTable seen;
        zend_long num_key;
        zend_string *str_key;
        zval *val;
        // 初始化HashTable
        zend_hash_init(&amp;amp;seen, zend_hash_num_elements(Z_ARRVAL_P(array)), NULL, NULL, 0);
        // 初始化数组
        array_init(return_value);
        // 遍历数组
        ZEND_HASH_FOREACH_KEY_VAL_IND(Z_ARRVAL_P(array), num_key, str_key, val) {
            zval *retval;
            // 如果数组元素值是字符串
            if (Z_TYPE_P(val) == IS_STRING) {
                retval = zend_hash_add_empty_element(&amp;amp;seen, Z_STR_P(val));
            } else {
                zend_string *tmp_str_val;
                zend_string *str_val = zval_get_tmp_string(val, &amp;amp;tmp_str_val);
                retval = zend_hash_add_empty_element(&amp;amp;seen, str_val);
                zend_tmp_string_release(tmp_str_val);
            }
            if (retval) {
                /* First occurrence of the value */
                if (UNEXPECTED(Z_ISREF_P(val) &amp;amp;&amp;amp; Z_REFCOUNT_P(val) == 1)) {
                    ZVAL_DEREF(val);
                }
                Z_TRY_ADDREF_P(val);
                if (str_key) {
                    zend_hash_add_new(Z_ARRVAL_P(return_value), str_key, val);
                } else {
                    zend_hash_index_add_new(Z_ARRVAL_P(return_value), num_key, val);
                }
            }
        } ZEND_HASH_FOREACH_END();
        // 释放哈希内存
        zend_hash_destroy(&amp;amp;seen);
        return;
    }&lt;/code&gt;
&lt;/pre&gt;
&lt;h4 id=&quot;设置比较函数&quot;&gt;设置比较函数&lt;/h4&gt;
&lt;pre class=&quot;c&quot;&gt;
&lt;code&gt;    cmp = php_get_data_compare_func(sort_type, 0);
    // 将数组拷贝到返回数组中
    RETVAL_ARR(zend_array_dup(Z_ARRVAL_P(array)));&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;进行具体比较顺序控制的函数指针是 &lt;code&gt;cmp&lt;/code&gt;，是通过向 &lt;code&gt;php_get_data_compare_func&lt;/code&gt; 传入 &lt;code&gt;sort_type&lt;/code&gt; 和 &lt;code&gt;0&lt;/code&gt; 得到的，&lt;code&gt;sort_type&lt;/code&gt; 也就是 &lt;code&gt;SORT_STRING&lt;/code&gt; 这样的标记。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;php_get_data_compare_func&lt;/code&gt; 在 &lt;code&gt;array.c&lt;/code&gt; 文件中定义（即与 &lt;code&gt;array_unique&lt;/code&gt; 函数同一文件），代码过长，这里只贴出默认标记为 &lt;code&gt;SORT_STRING&lt;/code&gt; 的代码：&lt;/p&gt;
&lt;pre class=&quot;c&quot;&gt;
&lt;code&gt;static compare_func_t php_get_data_compare_func(zend_long sort_type, int reverse) /* {{{ */
{
    switch (sort_type &amp;amp; ~PHP_SORT_FLAG_CASE) {
        case PHP_SORT_NUMERIC:
            // code...
        case PHP_SORT_STRING:
            if (sort_type &amp;amp; PHP_SORT_FLAG_CASE) {
                if (reverse) {
                    return php_array_reverse_data_compare_string_case;
                } else {
                    return php_array_data_compare_string_case;
                }
            } else {
                if (reverse) {
                    return php_array_reverse_data_compare_string;
                } else {
                    return php_array_data_compare_string;
                }
            }
            break;
    // code...&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;在前面的代码中，我们可以看到，&lt;code&gt;cmp = php_get_data_compare_func(sort_type, 0);&lt;/code&gt; 的第二个参数，即参数 &lt;code&gt;reverse&lt;/code&gt; 的值为 0，也就是当 &lt;code&gt;sort_type&lt;/code&gt; 为 &lt;code&gt;PHP_SORT_STRING&lt;/code&gt; 时，调用的是 &lt;code&gt;php_array_data_compare_string&lt;/code&gt; 函数，即 &lt;code&gt;SORT_STRING&lt;/code&gt; 采用 &lt;code&gt;php_array_data_compare_string&lt;/code&gt; 进行比较。继续展开 &lt;code&gt;php_array_data_compare_string&lt;/code&gt; 函数：&lt;/p&gt;
&lt;pre class=&quot;c&quot;&gt;
&lt;code&gt;static int php_array_data_compare_string(const void *a, const void *b) /* {{{ */
{
    Bucket *f;
    Bucket *s;
    zval *first;
    zval *second;
    f = (Bucket *) a;
    s = (Bucket *) b;
    first = &amp;amp;f-&amp;gt;val;
    second = &amp;amp;s-&amp;gt;val;
    if (UNEXPECTED(Z_TYPE_P(first) == IS_INDIRECT)) {
        first = Z_INDIRECT_P(first);
    }
    if (UNEXPECTED(Z_TYPE_P(second) == IS_INDIRECT)) {
        second = Z_INDIRECT_P(second);
    }
    return string_compare_function(first, second);
}
/* }}} */&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;可以得到这样一条调用链：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;SORT_STRING -&amp;gt; php_get_data_compare_func -&amp;gt; php_array_data_compare_string -&amp;gt; string_compare_function;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;string_compare_function&lt;/code&gt; 是一个 ZEND API，在 /Zend/zend_operators.c 中定义：&lt;/p&gt;
&lt;pre class=&quot;c&quot;&gt;
&lt;code&gt;ZEND_API int ZEND_FASTCALL string_compare_function(zval *op1, zval *op2) /* {{{ */
{
    if (EXPECTED(Z_TYPE_P(op1) == IS_STRING) &amp;amp;&amp;amp;
        EXPECTED(Z_TYPE_P(op2) == IS_STRING)) {
        if (Z_STR_P(op1) == Z_STR_P(op2)) {
            return 0;
        } else {
            return zend_binary_strcmp(Z_STRVAL_P(op1), Z_STRLEN_P(op1), Z_STRVAL_P(op2), Z_STRLEN_P(op2));
        }
    } else {
        zend_string *tmp_str1, *tmp_str2;
        zend_string *str1 = zval_get_tmp_string(op1, &amp;amp;tmp_str1);
        zend_string *str2 = zval_get_tmp_string(op2, &amp;amp;tmp_str2);
        int ret = zend_binary_strcmp(ZSTR_VAL(str1), ZSTR_LEN(str1), ZSTR_VAL(str2), ZSTR_LEN(str2));
        zend_tmp_string_release(tmp_str1);
        zend_tmp_string_release(tmp_str2);
        return ret;
    }
}
/* }}} */&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;可以看到，&lt;code&gt;SORT_STRING&lt;/code&gt; 使用 &lt;code&gt;zend_binary_strcmp&lt;/code&gt; 函数进行字符串比较。下面的代码是 &lt;code&gt;zend_binary_strcmp&lt;/code&gt; 的实现（也在 /Zend/zend_operators.c 中）：&lt;/p&gt;
&lt;pre class=&quot;c&quot;&gt;
&lt;code&gt;ZEND_API int ZEND_FASTCALL zend_binary_strcmp(const char *s1, size_t len1, const char *s2, size_t len2) /* {{{ */
{
    int retval;
    if (s1 == s2) {
        return 0;
    }
    retval = memcmp(s1, s2, MIN(len1, len2));
    if (!retval) {
        return (int)(len1 - len2);
    } else {
        return retval;
    }
}
/* }}} */&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;上面的代码是比较两个字符串。也就是 &lt;code&gt;SORT_STRING&lt;/code&gt; 排序方式的底层实现是 C 语言的 &lt;code&gt;memcmp&lt;/code&gt;，即它对两个字符串从前往后，按照逐个字节比较，一旦字节有差异，就终止并比较出大小。&lt;/p&gt;
&lt;h4 id=&quot;数组排序&quot;&gt;数组排序&lt;/h4&gt;
&lt;pre class=&quot;c&quot;&gt;
&lt;code&gt;    /* create and sort array with pointers to the target_hash buckets */
    // 根据 target_hash buckets 的指针创建数组并排序
    arTmp = (struct bucketindex *) pemalloc((Z_ARRVAL_P(array)-&amp;gt;nNumOfElements + 1) * sizeof(struct bucketindex), GC_FLAGS(Z_ARRVAL_P(array)) &amp;amp; IS_ARRAY_PERSISTENT);
    for (i = 0, idx = 0; idx &amp;lt; Z_ARRVAL_P(array)-&amp;gt;nNumUsed; idx++) {
        p = Z_ARRVAL_P(array)-&amp;gt;arData + idx;
        if (Z_TYPE(p-&amp;gt;val) == IS_UNDEF) continue;
        if (Z_TYPE(p-&amp;gt;val) == IS_INDIRECT &amp;amp;&amp;amp; Z_TYPE_P(Z_INDIRECT(p-&amp;gt;val)) == IS_UNDEF) continue;
        arTmp[i].b = *p;
        arTmp[i].i = i;
        i++;
    }
    ZVAL_UNDEF(&amp;amp;arTmp[i].b.val);
    zend_sort((void *) arTmp, i, sizeof(struct bucketindex),
            cmp, (swap_func_t)array_bucketindex_swap);&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;这段代码初始化一个新的数组，然后将值拷贝到新数组，然后调用 &lt;code&gt;zend_sort&lt;/code&gt; 排序函数对数组进行排序。排序算法在 /Zend/zend_sort.c 中实现，备注有这样一句话：&lt;/p&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;Derived from LLVM's libc++ implementation of std::sort.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;这个排序算法是基于 &lt;code&gt;LLVM&lt;/code&gt; 的 &lt;code&gt;libc++&lt;/code&gt; 中的 &lt;code&gt;std::sort&lt;/code&gt; 实现的，算是&lt;strong&gt;快排&lt;/strong&gt;的优化版，当元素数小于等于16时有特殊的优化，当元素数小于等于 5 时直接通过 &lt;code&gt;if else&lt;/code&gt; 嵌套判断排序。代码就不贴出来了。&lt;/p&gt;
&lt;h4 id=&quot;数组去重&quot;&gt;数组去重&lt;/h4&gt;
&lt;p&gt;回到 &lt;code&gt;array_unique&lt;/code&gt; 上，继续看代码：&lt;/p&gt;
&lt;pre class=&quot;c&quot;&gt;
&lt;code&gt;/* go through the sorted array and delete duplicates from the copy */
    lastkept = arTmp;
    for (cmpdata = arTmp + 1; Z_TYPE(cmpdata-&amp;gt;b.val) != IS_UNDEF; cmpdata++) {
        if (cmp(lastkept, cmpdata)) {
            lastkept = cmpdata;
        } else {
            if (lastkept-&amp;gt;i &amp;gt; cmpdata-&amp;gt;i) {
                p = &amp;amp;lastkept-&amp;gt;b;
                lastkept = cmpdata;
            } else {
                p = &amp;amp;cmpdata-&amp;gt;b;
            }
            if (p-&amp;gt;key == NULL) {
                zend_hash_index_del(Z_ARRVAL_P(return_value), p-&amp;gt;h);
            } else {
                if (Z_ARRVAL_P(return_value) == &amp;amp;EG(symbol_table)) {
                    zend_delete_global_variable(p-&amp;gt;key);
                } else {
                    zend_hash_del(Z_ARRVAL_P(return_value), p-&amp;gt;key);
                }
            }
        }
    }
    pefree(arTmp, GC_FLAGS(Z_ARRVAL_P(array)) &amp;amp; IS_ARRAY_PERSISTENT);&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;遍历排序好的数组，然后删除重复的元素。&lt;/p&gt;
&lt;p&gt;众周所知，快排的时间复杂度是O(nlogn)，因此，&lt;code&gt;array_unique&lt;/code&gt; 函数的时间复杂度是O(nlogn)。&lt;code&gt;array_unique&lt;/code&gt; 底层调用了快排算法，加大了函数运行的时间开销，当数据量很大时，会导致整个函数的运行较慢。&lt;/p&gt;
</description>
<pubDate>Tue, 22 Oct 2019 16:25:00 +0000</pubDate>
<dc:creator>鹿呦呦</dc:creator>
<og:description>PHP7源码之array_unique函数分析</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/sunshineliulu/p/11723624.html</dc:identifier>
</item>
<item>
<title>你真的知道并发问题产生的源头吗？ - 浪人~</title>
<link>http://www.cnblogs.com/liqiangchn/p/11723602.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/liqiangchn/p/11723602.html</guid>
<description>&lt;p&gt;本文从计算机系统层面来讲述在提升性能的过程中，引发的一系列问题。读完本文你将get到并发编程过程中的原子性，可见性，有序性三大问题的来源。&lt;/p&gt;
&lt;p&gt;随着硬件发展速度的放缓，摩尔定律已经不在生效，各个硬件似乎已经到了瓶颈；然而随着互联网的普及，网民数量不断增加，对系统的性能带来了巨大的挑战。因此我们要通过各种方式来压榨硬件的性能，从而提高系统的性能进而提升用户体验，提升企业的竞争力。&lt;/p&gt;
&lt;p&gt;由于CPU，内存，IO三者之间速度差异，为了提高系统性能，计算机系统对这三者速度进行平衡。&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;CPU 增加了缓存，以均衡与内存的速度差异；&lt;/li&gt;
&lt;li&gt;操作系统增加了进程、线程，以分时复用 CPU，进而均衡 CPU 与 I/O 设备的速度差异；&lt;/li&gt;
&lt;li&gt;编译程序优化指令执行次序，使得缓存能够得到更加合理地利用。&lt;/li&gt;
&lt;/ul&gt;&lt;h2 id=&quot;缓存导致得可见性的问题&quot;&gt;缓存导致得可见性的问题&lt;/h2&gt;
&lt;p&gt;一个线程对共享变量的修改，另外一个线程能够立刻看到，我们称为可见性。&lt;br/&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1055780/201910/1055780-20191023000834943-558470608.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;多核时代，每颗 CPU 都有自己的缓存，这时 CPU 缓存与内存的数据一致性就没那么容易解决了，当多个线程在不同的 CPU 上执行时，这些线程操作的是不同的 CPU 缓存。 &lt;img src=&quot;https://img2018.cnblogs.com/blog/1055780/201910/1055780-20191023000854763-1901893708.png&quot;/&gt;&lt;/p&gt;
&lt;h2 id=&quot;线程切换带来的原子性问题&quot;&gt;线程切换带来的原子性问题&lt;/h2&gt;
&lt;p&gt;由于IO和cpu执行速度的差别巨大，所以在早期操作系统中就发明的多线程，即使在单核的cpu上我们也可以一遍听着歌，一边写着bug，这就是多线程。&lt;/p&gt;
&lt;p&gt;早期操作系统基于进程来调度cpu， &lt;strong&gt;不同进程间是不共享内存空间&lt;/strong&gt;的，所以进程要做任务切换要切换内存映射地址，而一个进程创建的所有线程都是共享一个内存空间，所以线程做任务切换成本很低。现代操作系统都基于更轻量级的线程来调度，现在我们提到的“任务切换”都是指“线程切换”。&lt;/p&gt;
&lt;p&gt;因为式单核cpu，所以同一时刻只能执行一个任务，所以多线程通常使用抢占的方式来获取操作系统的时间片。&lt;br/&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1055780/201910/1055780-20191023000940568-1341063032.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;Java的并发编程中都是基于多线程，线程的切换时机通常在一条cpu指令执行完毕之后，而Java作为一门高级编程语言，通常一条语句可能由多个cpu指令来完成。例如：count += 1, 至少需要三条指令。&lt;/p&gt;
&lt;ul readability=&quot;1.5&quot;&gt;&lt;li&gt;指令1：首先，需要把变量count从该内存加载到cpu的寄存器&lt;/li&gt;
&lt;li&gt;指令2：之后，在寄存器中执行+1操作&lt;/li&gt;
&lt;li readability=&quot;6&quot;&gt;
&lt;p&gt;指令3： 最后，将结果写入内存（忽略缓存机制）&lt;br/&gt;假设count = 0， 有2个线程同时执行count+=1这段代码。线程A执行完指令1将count = 0加载到cpu寄存器，进行了任务切换到了线程B执行，线程B执行完之后将count = 1写入到内存，然后再切换到线程A执行，此时线程A获取寄存器中的count=0进行+1操作得到结果也是1，所以最终内存中的count = 1，而我们所期望的是2. &lt;img src=&quot;https://img2018.cnblogs.com/blog/1055780/201910/1055780-20191023000957601-247990927.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;CPU层面的原子操作仅仅是在指令级别的，既一条cpu指令不可中断。在高级语言中，我们为了避免以上情况发生，&lt;strong&gt;我们把一个或多个操作在cpu执行过程中不被中断的特性称为原子性&lt;/strong&gt;。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;h2 id=&quot;编译优化带来的有序性问题&quot;&gt;编译优化带来的有序性问题&lt;/h2&gt;
&lt;p&gt;为了提高程序的执行效率，编译器有时会在编译过程中对程序的进行优化，从而改变程序的执行顺序。如程序“a = 4； b = 5”，在优化后执行顺序可能变成“b = 5； a = 4”。通常进行一项优化过程中可能会带来另一项问题，改变程序的执行顺序通常也会导致让人意想不到的bug。&lt;/p&gt;
&lt;p&gt;Java领域中一个经典的案例就是利用双重检查创建单例对象，代码如下：在获取实例getInstance()方法中，我们首先判断instance是否为空，如果为空则锁住Singleton.class对象并再次检查instance是否为空，如果仍然为空则创建Singleton的一个实例。&lt;/p&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;public class Singleton {
static Singleton instance;
/**
  * 获取Singleton对象
  */
public static Singleton getInstance(){
    if (instance == null) {
        synchronized(Singleton.class) {
            if (instance == null)
                instance = new Singleton();
            }
        }
    return instance;
    }
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;假设有两个线程 A、B 同时调用 getInstance() 方法，他们会同时发现 instance == null，于是同时对 Singleton.class 加锁，此时 JVM 保证只有一个线程能够加锁成功（假设是线程 A），另外一个线程则会处于等待状态（假设是线程 B）；线程 A 会创建一个 Singleton 实例，之后释放锁，锁释放后，线程 B 被唤醒，线程 B 再次尝试加锁，此时是可以加锁成功的，加锁成功后，线程 B 检查 instance == null 时会发现，已经创建过 Singleton 实例了，所以线程 B 不会再创建一个 Singleton 实例。&lt;/p&gt;
&lt;p&gt;以上过程仅仅是我们的理想情况下，但是实际过程中往往会创建多次Singleton实例。原因是创建一个对象需要多条cpu指令，且编译器可能对这几条指令进行了排序。在执行new语句创建一个对象时，通常会包含一下三个步骤（此处进行了简化，实际实现过程会比此过程复杂）：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;在堆内存为对象分配一块内存M&lt;/li&gt;
&lt;li&gt;在内存M区域进行Singleton对象的初始化&lt;/li&gt;
&lt;li&gt;将内存M地址赋值给instance变量。&lt;br/&gt;但是实际优化后的执行顺序可能时以下这种情况：&lt;/li&gt;
&lt;li&gt;在堆内存为对象分配一块内存M&lt;/li&gt;
&lt;li&gt;将内存M地址赋值给instance变量。&lt;/li&gt;
&lt;li&gt;在内存M区域进行Singleton对象的初始化&lt;br/&gt;假设A，B线程同时执行到了getInstance()方法，线程A执行完instance = $M（将内存M地址赋值给instance变量，但是未将对象进行初始化）后切换到B线程，当B线程执行到instance == null时，由于instance已经指向了内存M的地址，所以会返回false，直接返回instance，如果我们这是访问instance中的成员变量或者方法时就可能会出现NullPointException。&lt;br/&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1055780/201910/1055780-20191023001006382-349952632.png&quot;/&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;在操作系统平衡CPU，内存，IO三者速度差异过程中进行了一系列的优化。&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;CPU 增加了缓存，以均衡与内存的速度差异；&lt;/li&gt;
&lt;li&gt;操作系统增加了进程、线程，以分时复用 CPU，进而均衡 CPU 与 I/O 设备的速度差异；&lt;/li&gt;
&lt;li&gt;编译程序优化指令执行次序，使得缓存能够得到更加合理地利用。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;这三个不同方面的优化也带来了可见性，原子性，有序性等问题，他们通常是并发程序的bug的源头。&lt;br/&gt;&lt;a href=&quot;http://www.mycookies.cn&quot;&gt;笔者的个人博客网站&lt;/a&gt;&lt;/p&gt;
</description>
<pubDate>Tue, 22 Oct 2019 16:12:00 +0000</pubDate>
<dc:creator>浪人~</dc:creator>
<og:description>从计算机系统角度揭秘并发编程bug的根本来源，原子性，可见性以及顺序性。</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/liqiangchn/p/11723602.html</dc:identifier>
</item>
<item>
<title>XGBoost: 你不能不知的机器学习算法 - samlam</title>
<link>http://www.cnblogs.com/samshare/p/11723364.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/samshare/p/11723364.html</guid>
<description>&lt;p&gt;XGBoost作为一个非常常用的算法，我觉得很有必要了解一下它的来龙去脉，于是抽空找了一些资料，主要包括陈天奇大佬的论文以及演讲PPT，以及网络上的一些博客文章，今天在这里对这些知识点进行整理归纳，论文中的一些专业术语尽可能保留不翻译，但会在下面写出自己的理解与解释。&lt;/p&gt;
&lt;p&gt;资料下载：公众号（SAMshare）回复&quot;xgb&quot;获取&lt;/p&gt;
&lt;h2 id=&quot;index&quot;&gt;🚗 Index&lt;/h2&gt;
&lt;ul&gt;&lt;li&gt;XGBoost介绍&lt;/li&gt;
&lt;li&gt;XGBoost亮点&lt;/li&gt;
&lt;li&gt;梯度增强树算法介绍
&lt;ul&gt;&lt;li&gt;Regularized Learning Objective&lt;/li&gt;
&lt;li&gt;Gradient Tree Boosting&lt;/li&gt;
&lt;li&gt;Shrinkage and Column Subsampling&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;分裂查找算法介绍
&lt;ul&gt;&lt;li&gt;Basic Exact Greedy Algorithm&lt;/li&gt;
&lt;li&gt;Approximate Algorithm&lt;/li&gt;
&lt;li&gt;Weighted Quantile Sketch&lt;/li&gt;
&lt;li&gt;Sparsity-aware Split Finding&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;XGBoost的系统设计
&lt;ul&gt;&lt;li&gt;Column Block for Parallel Learning&lt;/li&gt;
&lt;li&gt;Cache-aware Access&lt;/li&gt;
&lt;li&gt;Blocks for Out-of-core Computation&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;h2 id=&quot;xgboost介绍&quot;&gt;🙊 XGBoost介绍&lt;/h2&gt;
&lt;p&gt;在Paper中，作者定义XGBoost：&lt;/p&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;a scalable machine learning system for tree boosting.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;XGBoost为“Extreme Gradient Boosting”的缩写，里面包含了关键字'Boosting'，意味着它是一个boosting集成算法，所以它的主要思路是将成百上千个树模型组合起来成为一个准确率很高的模型，此模型通过不断迭代生成新的树。&lt;/p&gt;
&lt;p&gt;XGBoost我们常用于监督学习，即建立一个数据模型，输入相关特征从而预测出目标，而这一过程，需要我们找到训练数据最好的参数，所以我们需要定义一个目标函数，通常由训练损失（traning loss）和正则项（regularization term）组成。&lt;/p&gt;
&lt;p&gt;训练损失评估了预测模型的效果，例如常用的训练损失指标是均方误差或是逻辑回归的logistic loss。正则项则是控制着模型的复杂度，避免模型不被过度拟合。这两个互相博弈（tradeoff）的指标保证了模型的预测效果以及简洁程度。&lt;/p&gt;
&lt;h2 id=&quot;xgboost亮点&quot;&gt;💫 XGBoost亮点&lt;/h2&gt;
&lt;ul&gt;&lt;li&gt;We design and build a highly scalable end-to-end tree boosting system.&lt;/li&gt;
&lt;li&gt;We propose a theoretically justified weighted quantile sketch for efficient proposal calculation.&lt;/li&gt;
&lt;li&gt;We introduce a novel sparsity-aware algorithm for par- allel tree learning.&lt;/li&gt;
&lt;li&gt;We propose an effective cache-aware block structure for out-of-core tree learning.&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;翻译来说，就是它设计并构建了适用于大规模的 end-to-end 的Boosting系统（end-to-end指的是端到端，就是只关心输入和输出，中间过程都不care），而且实现特征选择的并行处理，正则使用L2的稀疏感知算法，而且也提出了有效的缓存结构，加大训练效率&lt;/p&gt;
&lt;p&gt;另外，其他博文也有一些总结：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;相对GBDT来说，XGB在增加二阶梯度有更高的精度；&lt;/li&gt;
&lt;li&gt;XGB的节点划分策略带有进行预排序，利用样本在损失函数上面的二阶梯度作为权值；&lt;/li&gt;
&lt;li&gt;XGB对稀疏的特征划分方式；&lt;/li&gt;
&lt;li&gt;在处理特征的粒度上进行多线程的优化；&lt;/li&gt;
&lt;li&gt;使用近似算法替代每个样本逐个判断最佳分裂点的Exact Greedy Algorithm算法。&lt;/li&gt;
&lt;/ul&gt;&lt;h2 id=&quot;梯度增强树算法介绍&quot;&gt;🌲 梯度增强树算法介绍&lt;/h2&gt;
&lt;p&gt;XGBoost还是采用属于gradient tree boosting algorithms，推导过程和已有的算法理论类似，但这里有了一些创新，比如正则化学习目标、样本子采样、特征子采样、近似算法等等。&lt;/p&gt;
&lt;h3 id=&quot;regularized-learning-objective&quot;&gt;3.1 Regularized Learning Objective&lt;/h3&gt;
&lt;p&gt;给定一个n X m维的数据集D，通过训练D，得到K棵树，而这K棵树累加的值作为我们的预测值。&lt;br/&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/812632/201910/812632-20191022231828759-1583899107.jpg&quot; alt=&quot;file&quot;/&gt;&lt;/p&gt;
&lt;p&gt;其中，&lt;img src=&quot;https://img2018.cnblogs.com/blog/812632/201910/812632-20191022231829066-620885637.jpg&quot; alt=&quot;file&quot;/&gt;&lt;br/&gt;是CART的空间，q表示每个树的结构，其可以将每个样本映射到对应的叶节点中，T是树中叶子节点的个数。&lt;/p&gt;
&lt;p&gt;有了上面的预测值，我们可以代入loss function，得到我们的损失函数：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/812632/201910/812632-20191022231829304-1851753949.jpg&quot; alt=&quot;file&quot;/&gt;&lt;/p&gt;
&lt;p&gt;可以看出损失函数由两部分组成，Training Loss和Regularization。&lt;/p&gt;
&lt;h3 id=&quot;gradient-tree-boosting&quot;&gt;3.2 Gradient Tree Boosting&lt;/h3&gt;
&lt;p&gt;这一节是对损失函数的推导求解，这里不是采取传统的优化方法进行优化，而是采用了Additive Training训练，我们将Training Loss部分，展开成K棵树叠加的形式，开始于一个常数，每次增加一个新的函数学习当前的树，贪婪地利用误差函数改善当前模型，而这里创新的点在于对误差函数进行二阶泰勒近似展开。&lt;/p&gt;
&lt;p&gt;具体公式推导就不展开了，建议查阅：&lt;/p&gt;
&lt;p&gt;XGBoost原理介绍：&lt;a href=&quot;https://blog.csdn.net/yinyu19950811/article/details/81079192&quot; class=&quot;uri&quot;&gt;https://blog.csdn.net/yinyu19950811/article/details/81079192&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&quot;shrinkage-and-column-subsampling&quot;&gt;3.3 Shrinkage and Column Subsampling&lt;/h3&gt;
&lt;p&gt;这一节讲到了两种防止过拟合的tricks，Shrinkage和Column Subsampling。&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;Shrinkage：权值收缩，主要针对叶子节点，在每一次的Tree Boosting后，收缩叶子节点的权重，降低了每棵独立树的影响，为将来的优化留出一些空间。&lt;/li&gt;
&lt;li&gt;Column Subsampling：这种技术出现在RF中，这种做法不仅可以防止过拟合，还能提升一部分训练效率。&lt;/li&gt;
&lt;/ul&gt;&lt;h2 id=&quot;分裂查找算法介绍&quot;&gt;分裂查找算法介绍&lt;/h2&gt;
&lt;h3 id=&quot;basic-exact-greedy-algorithm&quot;&gt;4.1 Basic Exact Greedy Algorithm&lt;/h3&gt;
&lt;p&gt;这个是常见的基础贪心算法，即对所有的特征进行遍历处理，这就要求对计算资源要求比较高，因为需要对每个特征计算其信息增益，选择增益最大的作为分裂点，当然是需要比较多的时间和算力。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/812632/201910/812632-20191022231829634-120456477.jpg&quot; alt=&quot;file&quot;/&gt;&lt;/p&gt;
&lt;h3 id=&quot;approximate-algorithm&quot;&gt;4.2 Approximate Algorithm&lt;/h3&gt;
&lt;p&gt;顾名思义，近似算法就是可能效果或者原理和Exact Greedy Algorithm差不多的算法，它的原理是根据特征分布的百分位数进行采样，选择待分裂点，然后，该算法将连续特征映射到由这些候选点分割的桶中，汇总统计信息并根据汇总的信息找到最佳解决方案，这里选择分裂点的方式有global和local：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;global：在树构建的初始状态阶段选出所有候选分裂点，后面每层都使用相同的策略选择分裂点。&lt;/li&gt;
&lt;li&gt;local：每次分裂后重新选出候选分裂点，适合深度较大的树，因为不需要提前准备过多的候选分裂点。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/812632/201910/812632-20191022231829941-2018325079.jpg&quot; alt=&quot;file&quot;/&gt;&lt;/p&gt;
&lt;h3 id=&quot;weighted-quantile-sketch&quot;&gt;4.3 Weighted Quantile Sketch&lt;/h3&gt;
&lt;p&gt;分布式加权直方图算法是XGBoost提出的一种可并行的算法，树节点在进行分裂时，需要计算特征的信息增益，该算法用于高效地生成候选分裂点，对于大型的数据集，如果每个实例具有相等权重时，quantile sketch算法可以解决，但对于加权数据集来说，则不适用，为了解决该问题，XGBoost提出了分布式加权quantile sketch算法。&lt;/p&gt;
&lt;h3 id=&quot;sparsity-aware-split-finding&quot;&gt;4.4 Sparsity-aware Split Finding&lt;/h3&gt;
&lt;p&gt;稀疏感知分裂发现，在现实生活中，特征往往都是稀疏的，有几种可能的原因导致特征稀疏：&lt;/p&gt;
&lt;p&gt;1）presence of missing values in the data;&lt;/p&gt;
&lt;p&gt;2）frequent zero entries in the statistics;&lt;/p&gt;
&lt;p&gt;3）artifacts of feature engineering such as one-hot encoding&lt;/p&gt;
&lt;p&gt;XGBoost以统一的方式处理缺失的情况，分裂中只选择没有缺失的数据去进行节点分支，然后缺失情况默认指定一个方向，其效率paper里说了是提升了50倍。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/812632/201910/812632-20191022231830274-1583080027.jpg&quot; alt=&quot;file&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/812632/201910/812632-20191022231830716-1986162437.jpg&quot; alt=&quot;file&quot;/&gt;&lt;/p&gt;
&lt;h2 id=&quot;xgboost的系统设计&quot;&gt;📚 XGBoost的系统设计&lt;/h2&gt;
&lt;h3 id=&quot;column-block-for-parallel-learning&quot;&gt;5.1 Column Block for Parallel Learning&lt;/h3&gt;
&lt;p&gt;即按列分块并行化学习，XGBoost会对每个特征的值进行排序，使用CSC结构存储到块（block）中，训练过程对特征分枝点计算采用并行处理，寻找合适的分裂点。所以我们常说的XGBoost的并行计算指的是不是树的学习上，而是在特征上的并行处理。&lt;/p&gt;
&lt;p&gt;所以，这里XGBoost在设计系统的时候，预留额外的空间（Block）赖储存排序好的数据，这里的排序，是按照每列的值排序，所以索引在不同特征之间是不一样的。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/812632/201910/812632-20191022231830948-410806452.jpg&quot; alt=&quot;file&quot;/&gt;&lt;/p&gt;
&lt;p&gt;所以，特征预排序只需要在开始的时候做一次即可，后续可以重复调用，大大减少了每次排序的耗时，所以也可以实现并行化学习，计算每个特征的信息增益。&lt;/p&gt;
&lt;h3 id=&quot;cache-aware-access&quot;&gt;5.2 Cache-aware Access&lt;/h3&gt;
&lt;p&gt;即缓存感知访问，对于有大量数据或者说分布式系统来说，我们不可能将所有的数据都放进内存里面。因此我们都需要将其放在外存上或者分布式存储。但是这有一个问题，这样做每次都要从外存上读取数据到内存，这将会是十分耗时的操作。&lt;/p&gt;
&lt;p&gt;因此我们使用预读取（prefetching）将下一块将要读取的数据预先放进内存里面。其实就是多开一个线程，该线程与训练的线程独立并负责数据读取。此外，还要考虑Block的大小问题。如果我们设置最大的block来存储所有样本在k特征上的值和梯度的话，cache未必能一次性处理如此多的梯度做统计。如果我们设置过少block size，这样不能充分利用的多线程的优势，也就是训练线程已经训练完数据，但是prefetching thread还没把数据放入内存或者cache中。&lt;/p&gt;
&lt;p&gt;经过测试，作者发现block size设置为2^16个examples最好。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/812632/201910/812632-20191022231831799-1841144901.jpg&quot; alt=&quot;file&quot;/&gt;&lt;/p&gt;
&lt;h3 id=&quot;blocks-for-out-of-core-computation&quot;&gt;5.3 Blocks for Out-of-core Computation&lt;/h3&gt;
&lt;p&gt;因为XGBoost是要设计一个高效使用资源的系统，所以各种机器资源都要用上，除了CPU和内存之外，磁盘空间也可以利用来处理数据。为了实现这个功能，我们可以将数据分成多个块并将每个块储存在磁盘上。&lt;/p&gt;
&lt;p&gt;在计算过程中，使用独立的线程将Block预提取到主内存缓冲区，这样子数据计算和磁盘读取可以同步进行，但由于IO非常耗时，所以还有2种技术来改善这种核外计算：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Block Compression：&lt;/strong&gt; 块压缩，并当加载到主内存时由独立线程动态解压缩；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Block Sharding：&lt;/strong&gt; 块分片，即将数据分片到多个磁盘，为每个磁盘分配一个线程，将数据提取到内存缓冲区，然后每次训练线程的时候交替地从每个缓冲区读取数据，有助于在多个磁盘可用时，增加读取的吞吐量。&lt;/li&gt;
&lt;/ul&gt;&lt;h2 id=&quot;references&quot;&gt;📖 References&lt;/h2&gt;
</description>
<pubDate>Tue, 22 Oct 2019 15:19:00 +0000</pubDate>
<dc:creator>samlam</dc:creator>
<og:description>XGBoost作为一个非常常用的算法，我觉得很有必要了解一下它的来龙去脉，于是抽空找了一些资料，主要包括陈天奇大佬的论文以及演讲PPT，以及网络上的一些博客文章，今天在这里对这些知识点进行整理归纳，论</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/samshare/p/11723364.html</dc:identifier>
</item>
</channel>
</rss>