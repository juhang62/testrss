<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="css/feed.xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/" xmlns:og="http://ogp.me/ns#">
<channel>
<atom:link rel="self" href="http://192.168.1.4/fivefilters/makefulltextfeed.php?url=feed.cnblogs.com%2Fblog%2Fsitehome%2Frss&amp;max=10&amp;links=preserve&amp;exc=" />
<atom:link rel="alternate" title="Source URL" href="http://feed.cnblogs.com/blog/sitehome/rss" />
<atom:link rel="related" title="Subscribe to feed" href="http://www.subtome.com/#/subscribe?feeds=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed.cnblogs.com%252Fblog%252Fsitehome%252Frss%26max%3D10%26links%3Dpreserve%26exc%3D&amp;back=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed.cnblogs.com%252Fblog%252Fsitehome%252Frss%26max%3D10%26links%3Dpreserve%26exc%3D" />
<title>博客园_首页</title>
<link></link>
<description>代码改变世界</description>
<item>
<title>nginx分布式实例入门操作 - 小王子的博客</title>
<link>http://www.cnblogs.com/xiaowangzi1987/p/10802372.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/xiaowangzi1987/p/10802372.html</guid>
<description>&lt;h3&gt; 本文目的&lt;/h3&gt;
&lt;p&gt;前段时间学习WCF已经渐入佳境，完成了既定学习目标，转入分布式系统学习。本文技术路线是：&lt;/p&gt;
&lt;p&gt;                                                   &lt;img src=&quot;https://img2018.cnblogs.com/blog/1096235/201905/1096235-20190502204220962-505067158.png&quot; alt=&quot;&quot; width=&quot;777&quot; height=&quot;143&quot;/&gt;&lt;/p&gt;
&lt;p&gt;采用wcf实现分布式服务端和客户端，客户端部署于本地主机，nginx和WCF部署于虚拟机端（分别是三个虚拟机）&lt;/p&gt;
&lt;p&gt;此文验证：当其中一个服务端断线后，另一个服务端可以继续支撑整个会话的完成。&lt;/p&gt;
&lt;h3&gt;技术关键词&lt;/h3&gt;
&lt;p&gt;wcf，nginx，虚拟机&lt;/p&gt;
&lt;p&gt; （如果wcf基础知识还不是很熟，建议先学习wcf技术知识。虚拟机采用vmware，虚拟机建立的系统是Win7.&lt;/p&gt;
&lt;p&gt;    提前准备好虚拟机，并建立三个虚拟机，每个虚拟机建立Win7系统，每个Win7系统安装.NET4.6平台。&lt;/p&gt;
&lt;p&gt;   下载nginx程序包。）&lt;/p&gt;
&lt;h3&gt;准备工作：虚拟机与主机建立局域网&lt;/h3&gt;
&lt;p&gt;为了保障本文的测试成功，主机与三个虚拟机之间组成局域网。三个虚拟机完成下图设置&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1096235/201905/1096235-20190502160247976-1657007800.png&quot; alt=&quot;&quot; width=&quot;481&quot; height=&quot;280&quot;/&gt;&lt;/p&gt;
&lt;p&gt;三个虚拟机完成虚拟网路设置：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1096235/201905/1096235-20190502160341965-2108101116.png&quot; alt=&quot;&quot; width=&quot;171&quot; height=&quot;119&quot;/&gt;&lt;/p&gt;
&lt;p&gt;选择VMnet8（因为此项外部连接是NAT模式），然后点击NAT设置。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1096235/201905/1096235-20190502160541332-1272373167.png&quot; alt=&quot;&quot; width=&quot;432&quot; height=&quot;376&quot;/&gt;&lt;/p&gt;
&lt;p&gt;设置NAT网关设置&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1096235/201905/1096235-20190502160641373-1612302746.png&quot; alt=&quot;&quot; width=&quot;375&quot; height=&quot;357&quot;/&gt;&lt;/p&gt;
&lt;p&gt;三个虚拟机还需要关闭防火墙和修改入站规则&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1096235/201905/1096235-20190502160740236-1224283148.png&quot; alt=&quot;&quot; width=&quot;465&quot; height=&quot;414&quot;/&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1096235/201905/1096235-20190502160854207-988440027.png&quot; alt=&quot;&quot; width=&quot;720&quot; height=&quot;456&quot;/&gt;&lt;/p&gt;
&lt;p&gt;我们来从自己本地主机ping虚拟机进行验证。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1096235/201905/1096235-20190502161045420-938502660.png&quot; alt=&quot;&quot; width=&quot;361&quot; height=&quot;263&quot;/&gt;&lt;/p&gt;
&lt;p&gt;我们从虚拟机向本地主机ping&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1096235/201905/1096235-20190502202253217-1670932638.png&quot; alt=&quot;&quot; width=&quot;361&quot; height=&quot;287&quot;/&gt;&lt;/p&gt;
&lt;p&gt;以上就实现了每个虚拟机与主机的局域网建立。&lt;/p&gt;
&lt;h3&gt;wcf契约与Service&lt;/h3&gt;
&lt;p&gt;本文的wcf服务代码没有很特殊的地方，贴代码&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; onclick=&quot;cnblogs_code_show('aaf15ae8-6a9d-4b0b-ba00-722947d0fe1d')&quot; readability=&quot;32&quot;&gt;&lt;img id=&quot;code_img_closed_aaf15ae8-6a9d-4b0b-ba00-722947d0fe1d&quot; class=&quot;code_img_closed&quot; src=&quot;https://images.cnblogs.com/OutliningIndicators/ContractedBlock.gif&quot; alt=&quot;&quot;/&gt;&lt;img id=&quot;code_img_opened_aaf15ae8-6a9d-4b0b-ba00-722947d0fe1d&quot; class=&quot;code_img_opened&quot; onclick=&quot;cnblogs_code_hide('aaf15ae8-6a9d-4b0b-ba00-722947d0fe1d',event)&quot; src=&quot;https://images.cnblogs.com/OutliningIndicators/ExpandedBlockStart.gif&quot; alt=&quot;&quot;/&gt;&lt;div id=&quot;cnblogs_code_open_aaf15ae8-6a9d-4b0b-ba00-722947d0fe1d&quot; class=&quot;cnblogs_code_hide&quot; readability=&quot;59&quot;&gt;
&lt;pre&gt;
&lt;span&gt; 1&lt;/span&gt; &lt;span&gt;namespace&lt;/span&gt;&lt;span&gt; NginxWCFTest_Contract
&lt;/span&gt;&lt;span&gt; 2&lt;/span&gt; &lt;span&gt;{
&lt;/span&gt;&lt;span&gt; 3&lt;/span&gt; &lt;span&gt;    [ServiceContract]
&lt;/span&gt;&lt;span&gt; 4&lt;/span&gt;     &lt;span&gt;public&lt;/span&gt; &lt;span&gt;interface&lt;/span&gt;&lt;span&gt; IOutputSomething
&lt;/span&gt;&lt;span&gt; 5&lt;/span&gt; &lt;span&gt;    {
&lt;/span&gt;&lt;span&gt; 6&lt;/span&gt; &lt;span&gt;        [OperationContract]
&lt;/span&gt;&lt;span&gt; 7&lt;/span&gt;         &lt;span&gt;string&lt;/span&gt; GetContentData(&lt;span&gt;int&lt;/span&gt;&lt;span&gt; i);
&lt;/span&gt;&lt;span&gt; 8&lt;/span&gt; &lt;span&gt;        [OperationContract]
&lt;/span&gt;&lt;span&gt; 9&lt;/span&gt;         &lt;span&gt;string&lt;/span&gt;&lt;span&gt; GetIpAddress();
&lt;/span&gt;&lt;span&gt;10&lt;/span&gt; &lt;span&gt;    }
&lt;/span&gt;&lt;span&gt;11&lt;/span&gt; }
&lt;/pre&gt;&lt;/div&gt;
&lt;span class=&quot;cnblogs_code_collapse&quot;&gt;View Code&lt;/span&gt;&lt;/div&gt;
&lt;div class=&quot;cnblogs_code&quot; onclick=&quot;cnblogs_code_show('03e00b9f-c0ee-4b19-bf9d-2f9ee6e35636')&quot; readability=&quot;34&quot;&gt;&lt;img id=&quot;code_img_closed_03e00b9f-c0ee-4b19-bf9d-2f9ee6e35636&quot; class=&quot;code_img_closed&quot; src=&quot;https://images.cnblogs.com/OutliningIndicators/ContractedBlock.gif&quot; alt=&quot;&quot;/&gt;&lt;img id=&quot;code_img_opened_03e00b9f-c0ee-4b19-bf9d-2f9ee6e35636&quot; class=&quot;code_img_opened&quot; onclick=&quot;cnblogs_code_hide('03e00b9f-c0ee-4b19-bf9d-2f9ee6e35636',event)&quot; src=&quot;https://images.cnblogs.com/OutliningIndicators/ExpandedBlockStart.gif&quot; alt=&quot;&quot;/&gt;&lt;div id=&quot;cnblogs_code_open_03e00b9f-c0ee-4b19-bf9d-2f9ee6e35636&quot; class=&quot;cnblogs_code_hide&quot; readability=&quot;63&quot;&gt;
&lt;pre&gt;
&lt;span&gt; 1&lt;/span&gt; &lt;span&gt;namespace&lt;/span&gt;&lt;span&gt; NginxWCFTest_Service
&lt;/span&gt;&lt;span&gt; 2&lt;/span&gt; &lt;span&gt;{
&lt;/span&gt;&lt;span&gt; 3&lt;/span&gt;     &lt;span&gt;public&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;&lt;span&gt; OutputSomethingService:IOutputSomething
&lt;/span&gt;&lt;span&gt; 4&lt;/span&gt; &lt;span&gt;    {
&lt;/span&gt;&lt;span&gt; 5&lt;/span&gt;         &lt;span&gt;string&lt;/span&gt;&lt;span&gt; threadName;
&lt;/span&gt;&lt;span&gt; 6&lt;/span&gt;         &lt;span&gt;readonly&lt;/span&gt; &lt;span&gt;object&lt;/span&gt; lockObject = &lt;span&gt;new&lt;/span&gt; &lt;span&gt;object&lt;/span&gt;&lt;span&gt;();
&lt;/span&gt;&lt;span&gt; 7&lt;/span&gt; 
&lt;span&gt; 8&lt;/span&gt;         &lt;span&gt;public&lt;/span&gt; &lt;span&gt;string&lt;/span&gt; GetContentData(&lt;span&gt;int&lt;/span&gt;&lt;span&gt; i)
&lt;/span&gt;&lt;span&gt; 9&lt;/span&gt; &lt;span&gt;        {
&lt;/span&gt;&lt;span&gt;10&lt;/span&gt;             &lt;span&gt;lock&lt;/span&gt;&lt;span&gt; (lockObject)
&lt;/span&gt;&lt;span&gt;11&lt;/span&gt; &lt;span&gt;            {
&lt;/span&gt;&lt;span&gt;12&lt;/span&gt;                 threadName = i.ToString(&lt;span&gt;0&lt;/span&gt; + &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;-&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; + &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;我是主机:&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; +&lt;span&gt; GetIpAddress());
&lt;/span&gt;&lt;span&gt;13&lt;/span&gt; &lt;span&gt;            }
&lt;/span&gt;&lt;span&gt;14&lt;/span&gt;             &lt;span&gt;return&lt;/span&gt; &lt;span&gt;string&lt;/span&gt;.Format(&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;序列号:{0},线程号:{1}&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;, i, threadName);
&lt;/span&gt;&lt;span&gt;15&lt;/span&gt; &lt;span&gt;        }
&lt;/span&gt;&lt;span&gt;16&lt;/span&gt;         &lt;span&gt;public&lt;/span&gt; &lt;span&gt;string&lt;/span&gt;&lt;span&gt; GetIpAddress()
&lt;/span&gt;&lt;span&gt;17&lt;/span&gt; &lt;span&gt;        {
&lt;/span&gt;&lt;span&gt;18&lt;/span&gt;             &lt;span&gt;string&lt;/span&gt; AddressIP = &lt;span&gt;string&lt;/span&gt;&lt;span&gt;.Empty;
&lt;/span&gt;&lt;span&gt;19&lt;/span&gt;             &lt;span&gt;foreach&lt;/span&gt; (IPAddress _IPAddress &lt;span&gt;in&lt;/span&gt;&lt;span&gt; Dns.GetHostEntry(Dns.GetHostName()).AddressList)
&lt;/span&gt;&lt;span&gt;20&lt;/span&gt; &lt;span&gt;            {
&lt;/span&gt;&lt;span&gt;21&lt;/span&gt;                 &lt;span&gt;if&lt;/span&gt; (_IPAddress.AddressFamily.ToString() == &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;InterNetwork&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;)
&lt;/span&gt;&lt;span&gt;22&lt;/span&gt; &lt;span&gt;                {
&lt;/span&gt;&lt;span&gt;23&lt;/span&gt;                     AddressIP =&lt;span&gt; _IPAddress.ToString();
&lt;/span&gt;&lt;span&gt;24&lt;/span&gt; &lt;span&gt;                }
&lt;/span&gt;&lt;span&gt;25&lt;/span&gt; &lt;span&gt;            }
&lt;/span&gt;&lt;span&gt;26&lt;/span&gt;             &lt;span&gt;return&lt;/span&gt;&lt;span&gt; AddressIP;
&lt;/span&gt;&lt;span&gt;27&lt;/span&gt; &lt;span&gt;        }
&lt;/span&gt;&lt;span&gt;28&lt;/span&gt; &lt;span&gt;    }
&lt;/span&gt;&lt;span&gt;29&lt;/span&gt; }
&lt;/pre&gt;&lt;/div&gt;
&lt;span class=&quot;cnblogs_code_collapse&quot;&gt;View Code&lt;/span&gt;&lt;/div&gt;
&lt;h3&gt;wcf服务端宿主（部署于192.168.21.129和192.168.21.130）&lt;/h3&gt;
&lt;div class=&quot;cnblogs_code&quot; onclick=&quot;cnblogs_code_show('31882072-4478-4905-8723-0c377d42647b')&quot; readability=&quot;32.5&quot;&gt;&lt;img id=&quot;code_img_closed_31882072-4478-4905-8723-0c377d42647b&quot; class=&quot;code_img_closed&quot; src=&quot;https://images.cnblogs.com/OutliningIndicators/ContractedBlock.gif&quot; alt=&quot;&quot;/&gt;&lt;img id=&quot;code_img_opened_31882072-4478-4905-8723-0c377d42647b&quot; class=&quot;code_img_opened&quot; onclick=&quot;cnblogs_code_hide('31882072-4478-4905-8723-0c377d42647b',event)&quot; src=&quot;https://images.cnblogs.com/OutliningIndicators/ExpandedBlockStart.gif&quot; alt=&quot;&quot;/&gt;&lt;div id=&quot;cnblogs_code_open_31882072-4478-4905-8723-0c377d42647b&quot; class=&quot;cnblogs_code_hide&quot; readability=&quot;60&quot;&gt;
&lt;pre&gt;
&lt;span&gt; 1&lt;/span&gt; &lt;span&gt;namespace&lt;/span&gt;&lt;span&gt; NginxWCFTest_Hosting
&lt;/span&gt;&lt;span&gt; 2&lt;/span&gt; &lt;span&gt;{
&lt;/span&gt;&lt;span&gt; 3&lt;/span&gt;     &lt;span&gt;class&lt;/span&gt;&lt;span&gt; Program
&lt;/span&gt;&lt;span&gt; 4&lt;/span&gt; &lt;span&gt;    {
&lt;/span&gt;&lt;span&gt; 5&lt;/span&gt;         &lt;span&gt;static&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; Main(&lt;span&gt;string&lt;/span&gt;&lt;span&gt;[] args)
&lt;/span&gt;&lt;span&gt; 6&lt;/span&gt; &lt;span&gt;        {
&lt;/span&gt;&lt;span&gt; 7&lt;/span&gt;             ServiceHost host = &lt;span&gt;new&lt;/span&gt; ServiceHost(&lt;span&gt;typeof&lt;/span&gt;&lt;span&gt;(OutputSomethingService));
&lt;/span&gt;&lt;span&gt; 8&lt;/span&gt; &lt;span&gt;            host.Open();
&lt;/span&gt;&lt;span&gt; 9&lt;/span&gt;             &lt;span&gt;//&lt;/span&gt;&lt;span&gt;host.Opened += delegate
&lt;/span&gt;&lt;span&gt;10&lt;/span&gt;             &lt;span&gt;//&lt;/span&gt;&lt;span&gt;{
&lt;/span&gt;&lt;span&gt;11&lt;/span&gt;             &lt;span&gt;//&lt;/span&gt;&lt;span&gt;    Console.WriteLine(host.Description.Endpoints[0].Address.Uri + &quot;已经启动，按任意键终止服务！&quot;);
&lt;/span&gt;&lt;span&gt;12&lt;/span&gt;             &lt;span&gt;//&lt;/span&gt;&lt;span&gt;};&lt;/span&gt;
&lt;span&gt;13&lt;/span&gt; &lt;span&gt;            Console.Read();
&lt;/span&gt;&lt;span&gt;14&lt;/span&gt; &lt;span&gt;        }
&lt;/span&gt;&lt;span&gt;15&lt;/span&gt; &lt;span&gt;    }
&lt;/span&gt;&lt;span&gt;16&lt;/span&gt; }
&lt;/pre&gt;&lt;/div&gt;
&lt;span class=&quot;cnblogs_code_collapse&quot;&gt;View Code&lt;/span&gt;&lt;/div&gt;
&lt;p&gt; 如果wcf基础知识扎实的话， 宿主的代码很easy，我们重点需要关注的是配置信息&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; onclick=&quot;cnblogs_code_show('ade64fed-51db-4c45-8e3b-744dfd2c77e3')&quot; readability=&quot;32.5&quot;&gt;&lt;img id=&quot;code_img_closed_ade64fed-51db-4c45-8e3b-744dfd2c77e3&quot; class=&quot;code_img_closed&quot; src=&quot;https://images.cnblogs.com/OutliningIndicators/ContractedBlock.gif&quot; alt=&quot;&quot;/&gt;&lt;img id=&quot;code_img_opened_ade64fed-51db-4c45-8e3b-744dfd2c77e3&quot; class=&quot;code_img_opened&quot; onclick=&quot;cnblogs_code_hide('ade64fed-51db-4c45-8e3b-744dfd2c77e3',event)&quot; src=&quot;https://images.cnblogs.com/OutliningIndicators/ExpandedBlockStart.gif&quot; alt=&quot;&quot;/&gt;&lt;div id=&quot;cnblogs_code_open_ade64fed-51db-4c45-8e3b-744dfd2c77e3&quot; class=&quot;cnblogs_code_hide&quot; readability=&quot;60&quot;&gt;
&lt;pre&gt;
&amp;lt;system.serviceModel&amp;gt;
    &amp;lt;behaviors&amp;gt;
      &amp;lt;serviceBehaviors&amp;gt;
        &amp;lt;behavior name=&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;metaBehavior&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&amp;gt;
          &amp;lt;!--&lt;span&gt; 为避免泄漏元数据信息，
          请在部署前将以下值设置为 &lt;/span&gt;&lt;span&gt;false&lt;/span&gt; --&amp;gt;
          &amp;lt;serviceMetadata httpGetEnabled=&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;True&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; httpsGetEnabled=&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;True&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt; 
                           httpGetUrl&lt;/span&gt;=&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;http://192.168.21.129:80/OutputSomethingService/meta&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;/&amp;gt;
          &amp;lt;!--&lt;span&gt; 要接收故障异常详细信息以进行调试，
          请将以下值设置为 &lt;/span&gt;&lt;span&gt;true&lt;/span&gt;。在部署前设置为 &lt;span&gt;false&lt;/span&gt;&lt;span&gt; 
          以避免泄漏异常信息 &lt;/span&gt;--&amp;gt;
          &amp;lt;serviceDebug includeExceptionDetailInFaults=&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;False&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; /&amp;gt;
        &amp;lt;/behavior&amp;gt;
      &amp;lt;/serviceBehaviors&amp;gt;
    &amp;lt;/behaviors&amp;gt;

    &amp;lt;services&amp;gt;
      &amp;lt;service name=&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;NginxWCFTest_Service.OutputSomethingService&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; behaviorConfiguration=&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;metaBehavior&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&amp;gt;
        &amp;lt;!--修改Binding为webHttpBinding--&amp;gt;
        &amp;lt;endpoint address=&lt;span&gt;&quot;&quot;&lt;/span&gt; binding=&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;basicHttpBinding&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;
                  contract&lt;/span&gt;=&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;NginxWCFTest_Contract.IOutputSomething&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; &amp;gt;
          &amp;lt;identity&amp;gt;

          &amp;lt;/identity&amp;gt;
        &amp;lt;/endpoint&amp;gt;
        &amp;lt;endpoint address=&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;mex&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; binding=&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;mexHttpBinding&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; contract=&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;IMetadataExchange&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; /&amp;gt;

        &amp;lt;host&amp;gt;
          &amp;lt;baseAddresses&amp;gt;
            &amp;lt;add baseAddress=&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;http://192.168.21.129:80/OutputSomethingService/&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; /&amp;gt;
          &amp;lt;/baseAddresses&amp;gt;
        &amp;lt;/host&amp;gt;
      &amp;lt;/service&amp;gt;
    &amp;lt;/services&amp;gt;

  &amp;lt;/system.serviceModel&amp;gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;span class=&quot;cnblogs_code_collapse&quot;&gt;View Code&lt;/span&gt;&lt;/div&gt;
&lt;p&gt;可以看得到服务端宿主的url端口是80，因为80是系统自带的默认端口。一般80作为网页服务器的访问端口，比如一个网站的ip地址是123.123.123.123，我们访问的是123.123.123.123:80  只是80是默认端口可以省略。&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1096235/201905/1096235-20190502151847407-573955187.png&quot; alt=&quot;&quot;/&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;后面针对为什么用80端口会再一次介绍。&lt;/p&gt;
&lt;h3&gt;wcf客户端宿主（部署于192.168.21.3）&lt;/h3&gt;
&lt;p&gt;客户端宿主代码跟普通没有区别，唯一需要注意的是配置代码&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; onclick=&quot;cnblogs_code_show('f563e861-159a-4501-a9c3-1cb3c77725fb')&quot; readability=&quot;32.5&quot;&gt;&lt;img id=&quot;code_img_closed_f563e861-159a-4501-a9c3-1cb3c77725fb&quot; class=&quot;code_img_closed&quot; src=&quot;https://images.cnblogs.com/OutliningIndicators/ContractedBlock.gif&quot; alt=&quot;&quot;/&gt;&lt;img id=&quot;code_img_opened_f563e861-159a-4501-a9c3-1cb3c77725fb&quot; class=&quot;code_img_opened&quot; onclick=&quot;cnblogs_code_hide('f563e861-159a-4501-a9c3-1cb3c77725fb',event)&quot; src=&quot;https://images.cnblogs.com/OutliningIndicators/ExpandedBlockStart.gif&quot; alt=&quot;&quot;/&gt;&lt;div id=&quot;cnblogs_code_open_f563e861-159a-4501-a9c3-1cb3c77725fb&quot; class=&quot;cnblogs_code_hide&quot; readability=&quot;60&quot;&gt;
&lt;pre&gt;
&lt;span&gt;namespace&lt;/span&gt;&lt;span&gt; NginxWCFTest_Client
{
    &lt;/span&gt;&lt;span&gt;class&lt;/span&gt;&lt;span&gt; Program
    {
        &lt;/span&gt;&lt;span&gt;static&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; Main(&lt;span&gt;string&lt;/span&gt;&lt;span&gt;[] args)
        {
            &lt;/span&gt;&lt;span&gt;string&lt;/span&gt; AddressIP = &lt;span&gt;string&lt;/span&gt;&lt;span&gt;.Empty;
            &lt;/span&gt;&lt;span&gt;foreach&lt;/span&gt; (IPAddress _IPAddress &lt;span&gt;in&lt;/span&gt;&lt;span&gt; Dns.GetHostEntry(Dns.GetHostName()).AddressList)
            {
                &lt;/span&gt;&lt;span&gt;if&lt;/span&gt; (_IPAddress.AddressFamily.ToString() == &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;InterNetwork&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;)
                {
                    AddressIP &lt;/span&gt;=&lt;span&gt; _IPAddress.ToString();
                }
            }
            Console.WriteLine(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;本机IP是：&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; +&lt;span&gt; AddressIP);




            &lt;/span&gt;&lt;span&gt;using&lt;/span&gt; (ChannelFactory&amp;lt;IOutputSomething&amp;gt; channelFactory = &lt;span&gt;new&lt;/span&gt; ChannelFactory&amp;lt;IOutputSomething&amp;gt;(&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;OutputSomethingService&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;))
            {
                &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;ChannelFactory:一个创建不同类型通道的工厂，客户端使用这些通道将消息发送到不同配置的服务终结点
                &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;创建通道&lt;/span&gt;
                IOutputSomething proxy =&lt;span&gt; channelFactory.CreateChannel();
                &lt;/span&gt;&lt;span&gt;for&lt;/span&gt; (&lt;span&gt;int&lt;/span&gt; i = &lt;span&gt;0&lt;/span&gt;; i &amp;lt; &lt;span&gt;20&lt;/span&gt;; i++&lt;span&gt;)
                {
                    Console.WriteLine(proxy.GetContentData(i));
                }
                Console.Read();
            }



           
        }
    }&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;span class=&quot;cnblogs_code_collapse&quot;&gt;View Code&lt;/span&gt;&lt;/div&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1096235/201905/1096235-20190502152711241-276191037.png&quot; alt=&quot;&quot; width=&quot;788&quot; height=&quot;128&quot;/&gt;&lt;/p&gt;
&lt;p&gt;大家可以看到客户端指向的地址是jackchen.com地址。这个地址是nginx虚拟机的域名。为此，我们需要做以下事情。&lt;/p&gt;
&lt;h3&gt;主机域名处理&lt;/h3&gt;
&lt;p&gt;nginx虚拟机主机域名处理：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1096235/201905/1096235-20190502153058311-873860873.png&quot; alt=&quot;&quot; width=&quot;576&quot; height=&quot;553&quot;/&gt;&lt;/p&gt;
&lt;p&gt;主机域名的文件路径地址在“C:\Windows\System32\drivers\etc\hosts&quot; 上图红箭头为新增加域名，如果IE浏览器中输入jackchen.com即相当于输入http://192.168.21.128&lt;/p&gt;
&lt;p&gt;WCF服务端主机域名处理&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1096235/201905/1096235-20190502153359978-485368057.png&quot; alt=&quot;&quot; width=&quot;370&quot; height=&quot;279&quot;/&gt;&lt;/p&gt;
&lt;p&gt;192.168.21.130与上图类似，配置为192.168.21.130  jackchen.com。&lt;/p&gt;
&lt;p&gt;wcf客户端域名配置如下&lt;/p&gt;
&lt;p&gt;          &lt;img src=&quot;https://img2018.cnblogs.com/blog/1096235/201905/1096235-20190502162034562-1520777403.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;h3&gt;nginx应用&lt;/h3&gt;
&lt;p&gt;上面讲了WCF分布式服务的客户端和服务端，也讲了主机域名的处理。现在讲讲Nginx的作用和为什么要做域名处理&lt;/p&gt;
&lt;p&gt;nginx的基础知识我就多讲了，此处链接&lt;a href=&quot;http://tengine.taobao.org/book/chapter_09.html&quot;&gt;http://tengine.taobao.org/book/chapter_09.html&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;从上一步的主机域名解析就可以知道，WCF客户端指向的是ngnix的虚拟机（192.168.21.128），然后由nginx做均衡负载和备份机制管理，&lt;/p&gt;
&lt;p&gt;                        未使用nginx&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1096235/201905/1096235-20190502211654461-650541664.png&quot; alt=&quot;&quot; width=&quot;412&quot; height=&quot;196&quot;/&gt;&lt;/p&gt;
&lt;p&gt;使用nginx&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1096235/201905/1096235-20190502211725735-1216243891.png&quot; alt=&quot;&quot; width=&quot;532&quot; height=&quot;213&quot;/&gt;&lt;/p&gt;
&lt;p&gt;nginx部署于192.168.21.128，需要对nginx文件夹中config文件进行配置。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1096235/201905/1096235-20190502212020971-86950303.png&quot; alt=&quot;&quot; width=&quot;615&quot; height=&quot;217&quot;/&gt;&lt;/p&gt;
&lt;p&gt;配置信息为：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; onclick=&quot;cnblogs_code_show('e3137de1-2ec7-4a74-b917-827fac230e3f')&quot; readability=&quot;34&quot;&gt;&lt;img id=&quot;code_img_closed_e3137de1-2ec7-4a74-b917-827fac230e3f&quot; class=&quot;code_img_closed&quot; src=&quot;https://images.cnblogs.com/OutliningIndicators/ContractedBlock.gif&quot; alt=&quot;&quot;/&gt;&lt;img id=&quot;code_img_opened_e3137de1-2ec7-4a74-b917-827fac230e3f&quot; class=&quot;code_img_opened&quot; onclick=&quot;cnblogs_code_hide('e3137de1-2ec7-4a74-b917-827fac230e3f',event)&quot; src=&quot;https://images.cnblogs.com/OutliningIndicators/ExpandedBlockStart.gif&quot; alt=&quot;&quot;/&gt;&lt;div id=&quot;cnblogs_code_open_e3137de1-2ec7-4a74-b917-827fac230e3f&quot; class=&quot;cnblogs_code_hide&quot; readability=&quot;63&quot;&gt;
&lt;pre&gt;
&lt;span&gt;#user  nobody;
worker_processes  &lt;/span&gt;&lt;span&gt;1&lt;/span&gt;&lt;span&gt;;

#error_log  logs&lt;/span&gt;/&lt;span&gt;error.log;
#error_log  logs&lt;/span&gt;/&lt;span&gt;error.log  notice;
#error_log  logs&lt;/span&gt;/&lt;span&gt;error.log  info;

pid        logs&lt;/span&gt;/&lt;span&gt;nginx.pid;



events {
    worker_connections  &lt;/span&gt;&lt;span&gt;1024&lt;/span&gt;&lt;span&gt;;
}


http {
    include       mime.types;
    default_type  application&lt;/span&gt;/octet-&lt;span&gt;stream;

    #log_format  main  &lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;
    #                  &lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;$status $body_bytes_sent &quot;$http_referer&quot; &lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;
    #                  &lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;;

    #access_log  logs&lt;/span&gt;/&lt;span&gt;access.log  main;

    sendfile        on;
    #tcp_nopush     on;

    #keepalive_timeout  &lt;/span&gt;&lt;span&gt;0&lt;/span&gt;&lt;span&gt;;
    keepalive_timeout  &lt;/span&gt;&lt;span&gt;65&lt;/span&gt;&lt;span&gt;;

    #gzip  on;

    server {
        listen       &lt;/span&gt;&lt;span&gt;80&lt;/span&gt;&lt;span&gt;;
        server_name  jackchen.com;

        #charset koi8&lt;/span&gt;-&lt;span&gt;r;

        #access_log  logs&lt;/span&gt;/&lt;span&gt;host.access.log  main;

        location &lt;/span&gt;/&lt;span&gt; {
            autoindex  off;#是否打开目录浏览
            root   \html\Views\Home;#默认主页目录在nginx安装目录的html子目录。
            index  Index.cshtml index.html index.htm;#起始页
            proxy_pass http:&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;jackchen.com; &lt;/span&gt;
&lt;span&gt;        }
 
        #error_page  &lt;/span&gt;&lt;span&gt;404&lt;/span&gt;              /&lt;span&gt;404&lt;/span&gt;&lt;span&gt;.html;

        # redirect server error pages to the &lt;/span&gt;&lt;span&gt;static&lt;/span&gt; page /&lt;span&gt;50x.html
        #
        error_page   &lt;/span&gt;&lt;span&gt;500&lt;/span&gt; &lt;span&gt;502&lt;/span&gt; &lt;span&gt;503&lt;/span&gt; &lt;span&gt;504&lt;/span&gt;  /&lt;span&gt;50x.html;
        location &lt;/span&gt;= /&lt;span&gt;50x.html {
            root   html;
        }

        # proxy the PHP scripts to Apache listening on &lt;/span&gt;&lt;span&gt;127.0&lt;/span&gt;.&lt;span&gt;0.1&lt;/span&gt;:&lt;span&gt;80&lt;/span&gt;&lt;span&gt;
        #
        #location &lt;/span&gt;~&lt;span&gt; \.php$ {
        #    proxy_pass   http:&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;127.0.0.1;&lt;/span&gt;
&lt;span&gt;        #}

        # pass the PHP scripts to FastCGI server listening on &lt;/span&gt;&lt;span&gt;127.0&lt;/span&gt;.&lt;span&gt;0.1&lt;/span&gt;:&lt;span&gt;9000&lt;/span&gt;&lt;span&gt;
        #
        #location &lt;/span&gt;~&lt;span&gt; \.php$ {
        #    root           html;
        #    fastcgi_pass   &lt;/span&gt;&lt;span&gt;127.0&lt;/span&gt;.&lt;span&gt;0.1&lt;/span&gt;:&lt;span&gt;9000&lt;/span&gt;&lt;span&gt;;
        #    fastcgi_index  index.php;
        #    fastcgi_param  SCRIPT_FILENAME  &lt;/span&gt;/&lt;span&gt;scripts$fastcgi_script_name;
        #    include        fastcgi_params;
        #}

        # deny access to .htaccess files, &lt;/span&gt;&lt;span&gt;if&lt;/span&gt; Apache&lt;span&gt;'&lt;/span&gt;&lt;span&gt;s document root&lt;/span&gt;
        # concurs with nginx&lt;span&gt;'&lt;/span&gt;&lt;span&gt;s one&lt;/span&gt;
&lt;span&gt;        #
        #location &lt;/span&gt;~ /&lt;span&gt;\.ht {
        #    deny  all;
        #}
    }

upstream linuxidc { 
      server &lt;/span&gt;&lt;span&gt;127.0&lt;/span&gt;.&lt;span&gt;0.1&lt;/span&gt;:&lt;span&gt;8001&lt;/span&gt;&lt;span&gt;; 
      server &lt;/span&gt;&lt;span&gt;127.0&lt;/span&gt;.&lt;span&gt;0.1&lt;/span&gt;:&lt;span&gt;8002&lt;/span&gt;&lt;span&gt;;
      server &lt;/span&gt;&lt;span&gt;127.0&lt;/span&gt;.&lt;span&gt;0.1&lt;/span&gt;:&lt;span&gt;8003&lt;/span&gt;&lt;span&gt;;
}
upstream jackchen.com { 
          server &lt;/span&gt;&lt;span&gt;192.168&lt;/span&gt;.&lt;span&gt;21.129&lt;/span&gt;:&lt;span&gt;80&lt;/span&gt;&lt;span&gt;; 
      server &lt;/span&gt;&lt;span&gt;192.168&lt;/span&gt;.&lt;span&gt;21.130&lt;/span&gt;:&lt;span&gt;80&lt;/span&gt;&lt;span&gt;; 
}
    # another &lt;/span&gt;&lt;span&gt;virtual&lt;/span&gt; host &lt;span&gt;using&lt;/span&gt; mix of IP-, name-, and port-&lt;span&gt;based configuration
    #
    #server {
    #    listen       &lt;/span&gt;&lt;span&gt;8000&lt;/span&gt;&lt;span&gt;;
    #    listen       somename:&lt;/span&gt;&lt;span&gt;8080&lt;/span&gt;&lt;span&gt;;
    #    server_name  somename  alias  another.alias;

    #    location &lt;/span&gt;/&lt;span&gt; {
    #        root   html;
    #        index  index.html index.htm;
    #    }
    #}


    # HTTPS server
    #
    #server {
    #    listen       &lt;/span&gt;&lt;span&gt;443&lt;/span&gt;&lt;span&gt; ssl;
    #    server_name  localhost;

    #    ssl_certificate      cert.pem;
    #    ssl_certificate_key  cert.key;

    #    ssl_session_cache    shared:SSL:1m;
    #    ssl_session_timeout  5m;

    #    ssl_ciphers  HIGH:&lt;/span&gt;!aNULL:!&lt;span&gt;MD5;
    #    ssl_prefer_server_ciphers  on;

    #    location &lt;/span&gt;/&lt;span&gt; {
    #        root   html;
    #        index  index.html index.htm;
    #    }
    #}
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;span class=&quot;cnblogs_code_collapse&quot;&gt;View Code&lt;/span&gt;&lt;/div&gt;
&lt;p&gt;      其中的修改点为：&lt;/p&gt;
&lt;p&gt;              &lt;img src=&quot;https://img2018.cnblogs.com/blog/1096235/201905/1096235-20190502212253471-1450181178.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;upstream是配置集群，集群由192.168.21.129   和192.168.21.130组成&lt;/p&gt;
&lt;p&gt;修改完了之后准备开启nginx，下图是进入nginx.exe所在的文件夹&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1096235/201905/1096235-20190502220053460-1664220069.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;                接着输入 start nginx可以启动nginx，输入nginx -s stop可以停止nginx，输入nginx -s reload可以重启nginx &lt;/p&gt;
&lt;h3&gt;效果展示&lt;/h3&gt;
&lt;p&gt;启动两个服务端和nginx，同时启动客户端，效果图如下&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1096235/201905/1096235-20190502213754938-986936554.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;关闭192.168.21.130效果图如下&lt;/p&gt;
&lt;p&gt;        &lt;img src=&quot;https://img2018.cnblogs.com/blog/1096235/201905/1096235-20190502215657220-545550410.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

</description>
<pubDate>Thu, 02 May 2019 14:03:00 +0000</pubDate>
<dc:creator>小王子的博客</dc:creator>
<og:description>本文目的 前段时间学习WCF已经渐入佳境，完成了既定学习目标，转入分布式系统学习。本文技术路线是： 采用wcf实现分布式服务端和客户端，客户端部署于本地主机，nginx和WCF部署于虚拟机端（分别是三</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/xiaowangzi1987/p/10802372.html</dc:identifier>
</item>
<item>
<title>Node.js学习（第二章：node核心模块--fs） - pubdreamcc</title>
<link>http://www.cnblogs.com/dreamcc/p/10803559.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/dreamcc/p/10803559.html</guid>
<description>&lt;h2 id=&quot;前言&quot;&gt;前言&lt;/h2&gt;
&lt;p&gt;Node.js中赋予了JavaScript很多在浏览器中没有的能力，譬如：文件读写，创建http服务器等等，今天我们就来看看在node中怎样用JavaScript进行文件的读写操作。&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;
&lt;p&gt;读文件&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;我们在data文件夹下新建一个&lt;code&gt;hello.txt&lt;/code&gt;，并且在里面写入：&lt;code&gt;hello， node.js!!&lt;/code&gt; ，如图：&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1632878/201905/1632878-20190502215643734-998004844.png&quot;/&gt;&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;我们在&lt;code&gt;hello.txt&lt;/code&gt;同级目录下创建一个&lt;code&gt;hello.js&lt;/code&gt;文件，我们在这个js文件中利用Node提供的文件操作API, 读取&lt;code&gt;hello.txt&lt;/code&gt;文件中的内容。&lt;/li&gt;
&lt;/ol&gt;&lt;ul&gt;&lt;li&gt;node中对文件相关的操作需要依赖fs模块，这个是node中内置模块之一，我们需要引入。fs--file system。&lt;/li&gt;
&lt;/ul&gt;&lt;pre&gt;
&lt;code&gt;let fs = require('fs')
fs.readFile() 

 // 读文件。 readFile函数接受两个参数：读取文件路径，回调函数（error，data两个参数），
读取文件成功：data为文件内容，error为null，读取失败：error为错误对象，data为undefined&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;最后我们&lt;code&gt;hello.js&lt;/code&gt;中的代码如下:&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;   let fs = require('fs')
fs.readFile('./hello.txt', (error, data) =&amp;gt; {
  console.log(data.toString())
})
   &lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;在这里可以说一下，我们读取回来的默认是二进制的内容，所以需要调用toString()方法进行转换。最后，终端可以看到结果如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1632878/201905/1632878-20190502215658971-1769418037.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;可以看到我们刚才在&lt;code&gt;hello.txt&lt;/code&gt;中写入的文本&lt;code&gt;hello, node.js!!&lt;/code&gt;已经打印出来。看到这里是不是觉得很牛叉，JavaScript居然可以用来读取文件内容，完全颠覆了我们以前对JavaScript的理解，然而这一切都得归功于Node.js。&lt;/p&gt;
&lt;ol readability=&quot;-2&quot;&gt;&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;写文件&lt;/p&gt;
&lt;p&gt;我们在刚才的&lt;code&gt;hello.js&lt;/code&gt;中写入下面这行代码：&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;&lt;pre&gt;
&lt;code&gt;    fs.writeFile('./hello.md', '你好，node.js!', (error) =&amp;gt; {
          if (!error) {
            console.log('创建成功了。。')
          }
    }) 
    
// 写文件。writeFile接受三个参数：写入文件路径，写入内容，回调函数。

    写入成功时候：error为null，写入失败时候：error为错误对象&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;最后我们看到在同级目录下出现了一个&lt;code&gt;hello.md&lt;/code&gt;文件，并且里面的内容为&lt;code&gt;你好，node.js&lt;/code&gt;. 如图：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1632878/201905/1632878-20190502215758800-39239621.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1632878/201905/1632878-20190502215814271-12946875.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;其实我们对文件的操作不仅仅只局限在读和写上，还有很多的操作，具体详情可以关注我后续的博客或者GitHub，大家也可以提前了解下node.js中文API。 &lt;a href=&quot;http://nodejs.cn/api/fs.html#fs_file_paths&quot;&gt;中文API&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;后话&quot;&gt;后话&lt;/h2&gt;
&lt;p&gt;到了这里，我们是不是对node有了一个基本的了解，知道node是干什么的，而且知道正是由于node.js，我们的JavaScript才有了无限的可能，使得JavaScript不单单局限在浏览器窗口，俗话说得好：‘能用JavaScript来实现的，最终都会用JavaScript来实现’。&lt;/p&gt;
&lt;h2 id=&quot;说明&quot;&gt;说明&lt;/h2&gt;
&lt;p&gt;本仓库是自己Node.js学习过程的真实记录，以后会每天更新一些新的知识点，希望可以对想要学Node.js的同学有一些帮助，欢迎star，你们的点赞是我更新的持久动力。同时如果你觉得本仓库中的一些知识点有错误也可以issue我，方便后期我订正！&lt;/p&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;本仓库同时在博客园和掘金更新，欢迎写博客的朋友一起学习交流。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;博客园&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.cnblogs.com/dreamcc/&quot;&gt;找我&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;掘金&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://juejin.im/user/5ca1d53451882543f252db97/posts&quot;&gt;找我&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;GitHub&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/pubdreamcc/Node.js&quot;&gt;找我&lt;/a&gt;&lt;/p&gt;
</description>
<pubDate>Thu, 02 May 2019 14:00:00 +0000</pubDate>
<dc:creator>pubdreamcc</dc:creator>
<og:description>前言 Node.js中赋予了JavaScript很多在浏览器中没有的能力，譬如：文件读写，创建http服务器等等，今天我们就来看看在node中怎样用JavaScript进行文件的读写操作。 1. 读文</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/dreamcc/p/10803559.html</dc:identifier>
</item>
<item>
<title>降维之奇异值分解(SVD) - Luv_GEM</title>
<link>http://www.cnblogs.com/Luv-GEM/p/10801212.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/Luv-GEM/p/10801212.html</guid>
<description>&lt;p&gt;&lt;span&gt;看了几篇关于奇异值分解(S&lt;span class=&quot;fontstyle0&quot;&gt;ingular Value Decomposition，SVD&lt;/span&gt;)的博客，大部分都是从坐标变换（线性变换）的角度来阐述，讲了一堆坐标变换的东西，整了一大堆图，试图“通俗易懂”地向读者解释清楚这个矩阵分解方法。然而这个“通俗易懂”到我这就变成了“似懂非懂”，这些漂亮的图可把我整懵了。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;就像《没想到吧》里王祖蓝对一个碎碎念的观众说的，“我问你的问题是，你是很熟悉邓紫棋的歌吗，我只问了你一个问题，你回我这么多干嘛”（上B站忍不住又看了邓紫棋3个视频，差点回不来）。我就想知道这个奇异值分解的数学公式是什么，然后明白它是怎么一步步推导出来的，以及怎么推导出奇异值分解和主成分分析法的关系，咋就要整这么多图呢？&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;如果你也有这种感觉，那这篇博客就带着你，以数学推导为主，一步步搞清楚奇异值分解是什么。这篇博客反其道而行之，全是数学推导，没有一个图，就是这么任性。当然相信我，这些推导并不难。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;这篇博客整理如下的内容：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;span&gt;1、奇异值分解的数学公式；&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;span&gt;2、奇异值分解的流程总结和案例；&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;span&gt;3、用奇异值分解进行降维；&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;span&gt;4、特征分解、奇异值分解和主成分分析法的关系；&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;span&gt;5、奇异值分解在词向量降维中的应用。&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;span&gt;一、奇异值分解的数学公式&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;我们直接抛出相关结论，不推导也不证明。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;一个n×m的矩阵X的奇异值分解定义为：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1630478/201905/1630478-20190501205937548-110751949.png&quot; alt=&quot;&quot; width=&quot;82&quot; height=&quot;21&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;其中U称为左奇异矩阵，是一个n×n的正交矩阵，即满足U&lt;sup&gt;T&lt;/sup&gt;U=E，U&lt;sup&gt;T&lt;/sup&gt;=U&lt;sup&gt;-1&lt;/sup&gt;；而V称为右奇异矩阵，是一个m×m的正交矩阵。Σ为n×m的对角矩阵，对角线上的非零元素是奇异值（Singular Value）。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;span&gt;1、求奇异值&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;首先看Σ或者说奇异值是什么。如果矩阵X的秩rank(A)=r，那么实对称矩阵X&lt;sup&gt;T&lt;/sup&gt;X与X的秩相等，X&lt;sup&gt;T&lt;/sup&gt;X有r个非零的特征值和m-r个零特征值：λ&lt;sub&gt;1&lt;/sub&gt;≥λ&lt;sub&gt;2&lt;/sub&gt;≥ λ&lt;sub&gt;3&lt;/sub&gt;...≥λ&lt;sub&gt;r&lt;/sub&gt;&amp;gt;λ&lt;sub&gt;r+1&lt;/sub&gt;=...=λ&lt;sub&gt;m&lt;/sub&gt;=0。奇异值σ为：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1630478/201905/1630478-20190501213724724-1600531596.png&quot; alt=&quot;&quot; width=&quot;151&quot; height=&quot;81&quot;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;矩阵Σ可以表示为：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1630478/201905/1630478-20190501214015998-2085420257.png&quot; alt=&quot;&quot; width=&quot;173&quot; height=&quot;87&quot;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;span&gt;2、求右奇异矩阵V&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;然后看右奇异矩阵V是什么。将V写成列向量的形式（v&lt;sub&gt;1&lt;/sub&gt;, v&lt;sub&gt;2&lt;/sub&gt;, ...v&lt;sub&gt;r&lt;/sub&gt;,.. v&lt;sub&gt;m&lt;/sub&gt;），那么V的列向量是实对称矩阵X&lt;sup&gt;T&lt;/sup&gt;X的&lt;strong&gt;单位特征向量&lt;/strong&gt;，也就是有：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1630478/201905/1630478-20190501221803732-2131478971.png&quot; alt=&quot;&quot; width=&quot;255&quot; height=&quot;79&quot;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;span&gt;3、求左奇异矩阵U&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;span&gt;（1）第一种做法&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;第一种做法更多是为了与右奇异矩阵V的求法相对应，实际计算时会采用另外的方法。前面说了实对称矩阵X&lt;sup&gt;T&lt;/sup&gt;X与X的秩相等，有r个非零特征值，那么另一个实对称矩阵XX&lt;sup&gt;T&lt;/sup&gt;与X&lt;sup&gt;T&lt;/sup&gt;X的秩相等，同样有r个非零特征值，且这两个矩阵的非零特征值相等。将U也写成列向量的形式（u&lt;sub&gt;1&lt;/sub&gt;, u&lt;sub&gt;2&lt;/sub&gt;, ...u&lt;sub&gt;r&lt;/sub&gt;,.. u&lt;sub&gt;n&lt;/sub&gt;），那么U的列向量是实对称矩阵XX&lt;sup&gt;T&lt;/sup&gt;的单位特征向量，也就是有：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1630478/201905/1630478-20190501222009568-938783587.png&quot; alt=&quot;&quot; width=&quot;255&quot; height=&quot;79&quot;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;看到这里，虽然不知道这是怎么推导过来的，但是感受到了一种强烈的数学之美，有没有！&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;（2）第二种做法&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;在第二种做法中，我们会充分利用实对称矩阵X&lt;sup&gt;T&lt;/sup&gt;X与右奇异矩阵V，来求得左奇异矩阵U，而不用另外去求XX&lt;sup&gt;T&lt;/sup&gt;的单位特征向量。我们首先把X&lt;sup&gt;T&lt;/sup&gt;X的特征值分为两组：特征值大于零的一组（r个），特征值等于零的一组（m-r个），相应的把右奇异矩阵的列向量分为两组：前r个非零特征值对应的单位特征向量为V&lt;sub&gt;1&lt;/sub&gt;=(v&lt;sub&gt;1&lt;/sub&gt;, v&lt;sub&gt;2&lt;/sub&gt;, ...v&lt;sub&gt;r&lt;/sub&gt;)，而零特征值对应的单位特征向量为V&lt;sub&gt;2&lt;/sub&gt;=(v&lt;sub&gt;r+1&lt;/sub&gt;,.. v&lt;sub&gt;m&lt;/sub&gt;)。再把左奇异矩阵U的列向量也分为两组，尽管我们还不知道具体的元素值，但是我们知道它有n个列向量：前r个列向量U&lt;sub&gt;1&lt;/sub&gt;=(u&lt;sub&gt;1&lt;/sub&gt;, u&lt;sub&gt;2&lt;/sub&gt;, ...u&lt;sub&gt;r&lt;/sub&gt;)，后n-r个列向量U&lt;sub&gt;2&lt;/sub&gt;=(u&lt;sub&gt;r+1&lt;/sub&gt;, u&lt;sub&gt;r+2&lt;/sub&gt;, ...u&lt;sub&gt;n&lt;/sub&gt;)。那么我们可以用X、V&lt;sub&gt;1&lt;/sub&gt;和奇异值构成的对角阵方阵S来求出U&lt;sub&gt;1&lt;/sub&gt;。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1630478/201905/1630478-20190501230858445-1032316717.png&quot; alt=&quot;&quot; width=&quot;275&quot; height=&quot;136&quot;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;由第一种做法我们已知U&lt;sub&gt;1&lt;/sub&gt;是XX&lt;sup&gt;T&lt;/sup&gt;非零特征值的单位特征向量，那么U&lt;sub&gt;2&lt;/sub&gt;就是零特征值的单位特征向量了。我们不用去求U&lt;sub&gt;2&lt;/sub&gt;，只要构造n-r个列向量，每一个列向量满足：与其他n-1个列向量正交，且是单位向量——这通常是比较容易构造的。于是我们就得到了左奇异矩阵U=(U&lt;sub&gt;1&lt;/sub&gt;, U&lt;sub&gt;2&lt;/sub&gt;)。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;我们还可以证明一下，由XV&lt;sub&gt;1&lt;/sub&gt;S&lt;sup&gt;-1&lt;/sup&gt;所得到的U&lt;sub&gt;1&lt;/sub&gt;的确满足：列向量相互正交且为单位向量。这个证明很有用，并不复杂。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1630478/201905/1630478-20190502053443108-64313812.png&quot; alt=&quot;&quot; width=&quot;352&quot; height=&quot;302&quot;/&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;span&gt;二、奇异值分解的流程和案例&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;好，有了第一部分的内容，那尽管我们不知道怎么推导出来的，我们也已经知道如何进行奇异值分解了。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;span&gt;1、奇异值分解的计算过程&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;如果有一个n×m的矩阵X，秩为r，那么对X进行奇异值分解的一种做法是：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;sup&gt;&lt;span&gt;（1）求出实对称矩阵X&lt;sup&gt;T&lt;/sup&gt;X的m个特征值λ&lt;sub&gt;i&lt;/sub&gt;（其中非零的有r个）和m个单位特征向量v&lt;sub&gt;i&lt;/sub&gt;，&lt;/span&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;（2）把m个特征值λ&lt;sub&gt;i&lt;/sub&gt;从大到小排序，求出奇异值σ&lt;sub&gt;i&lt;/sub&gt;=√λ&lt;sub&gt;i&lt;/sub&gt;（i=1,...,r），并得到S=diag(σ&lt;sub&gt;1&lt;/sub&gt;,σ&lt;sub&gt;2&lt;/sub&gt;,...,σ&lt;sub&gt;r&lt;/sub&gt;)；&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;（3）相应地把m个特征向量v&lt;sub&gt;i&lt;/sub&gt;进行排列，就可以得到右奇异矩阵V=（v&lt;sub&gt;1&lt;/sub&gt;, v&lt;sub&gt;2&lt;/sub&gt;, ...v&lt;sub&gt;r&lt;/sub&gt;,.. v&lt;sub&gt;m&lt;/sub&gt;），同时得到非零特征值的特征向量矩阵V&lt;sub&gt;1&lt;/sub&gt;=(v&lt;sub&gt;1&lt;/sub&gt;, v&lt;sub&gt;2&lt;/sub&gt;, ...v&lt;sub&gt;r&lt;/sub&gt;)；&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;（4）由XV&lt;sub&gt;1&lt;/sub&gt;S&lt;sup&gt;-1&lt;/sup&gt;求出n×r的矩阵U&lt;sub&gt;1&lt;/sub&gt;，写成U&lt;sub&gt;1&lt;/sub&gt;=(u&lt;sub&gt;1&lt;/sub&gt;, u&lt;sub&gt;2&lt;/sub&gt;, ...u&lt;sub&gt;r&lt;/sub&gt;)；&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;（5）构造n-r个列向量u&lt;sub&gt;i&lt;/sub&gt;，每个都满足与其他n-1个列向量正交且是单位向量的条件，写成U&lt;sub&gt;2&lt;/sub&gt;=(u&lt;sub&gt;r+1&lt;/sub&gt;, u&lt;sub&gt;r+2&lt;/sub&gt;, ...u&lt;sub&gt;n&lt;/sub&gt;)，于是得到左奇异矩阵U=(U&lt;sub&gt;1&lt;/sub&gt;, U&lt;sub&gt;2&lt;/sub&gt;)=(u&lt;sub&gt;1&lt;/sub&gt;, u&lt;sub&gt;2&lt;/sub&gt;, ... u&lt;sub&gt;r&lt;/sub&gt;, ..., u&lt;sub&gt;n&lt;/sub&gt;)；&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;（6）得到X的奇异值分解：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1630478/201905/1630478-20190502061014747-1615065502.png&quot; alt=&quot;&quot; width=&quot;187&quot; height=&quot;53&quot;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;接下来我们就举一个简单的例子，按这个流程走一遍。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;span&gt;2、奇异值分解的小案例&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;span&gt;问题：&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;span&gt;对以下的矩阵X进行奇异值分解。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1630478/201905/1630478-20190502061450711-1565581832.png&quot; alt=&quot;&quot; width=&quot;118&quot; height=&quot;85&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;求解：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1630478/201905/1630478-20190502072308735-1839634601.png&quot; alt=&quot;&quot; width=&quot;718&quot; height=&quot;374&quot;/&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;span&gt;三、用奇异值分解做降维&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;用奇异值分解做降维，主要用到了线性代数里的分块矩阵理论。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;1、简化奇异值分解&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;我们可以看到矩阵Σ由奇异值和很多0元素构成，这些0看着很多余很难受对不对？尤其是对角线上的！所幸我们可以用分块矩阵的理论，把Σ中为0的对角元素抛弃掉。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;span&gt;和之前一样，X是n×m的矩阵，右奇异矩阵V中的前r个列向量为V&lt;sub&gt;1&lt;/sub&gt;=(v&lt;sub&gt;1&lt;/sub&gt;, v&lt;sub&gt;2&lt;/sub&gt;, ...v&lt;sub&gt;r&lt;/sub&gt;)，左奇异矩阵U中的前r个列向量为U&lt;sub&gt;1&lt;/sub&gt;=(u&lt;sub&gt;1&lt;/sub&gt;, u&lt;sub&gt;2&lt;/sub&gt;, ...u&lt;sub&gt;r&lt;/sub&gt;)，S=diag(σ&lt;sub&gt;1&lt;/sub&gt;,σ&lt;sub&gt;2&lt;/sub&gt;,...,σ&lt;sub&gt;r&lt;/sub&gt;)是奇异值构成的对角矩阵。则可以将奇异值分解的形式化简为X=U&lt;sub&gt;1&lt;/sub&gt;SV&lt;sub&gt;1&lt;/sub&gt;&lt;sup&gt;T&lt;/sup&gt;。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1630478/201905/1630478-20190502091733756-1719912258.png&quot; alt=&quot;&quot; width=&quot;369&quot; height=&quot;342&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;span&gt;2、用奇异值分解降维&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;我们是用分块矩阵对原来的奇异值分解形式进行化简的，现在让我们分块到底！&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;我们知道U&lt;sub&gt;1&lt;/sub&gt;中有r个列向量，我们再将其分块，比如我们想把维度降到d维（d&amp;lt;r），那么把U&lt;sub&gt;1&lt;/sub&gt;分块为两个子矩阵U&lt;sub&gt;1&lt;/sub&gt;=[U&lt;sub&gt;11&lt;/sub&gt;, U&lt;sub&gt;12&lt;/sub&gt;]，有U&lt;sub&gt;11&lt;/sub&gt;=[u&lt;sub&gt;1&lt;/sub&gt;,u&lt;sub&gt;2&lt;/sub&gt;,...,u&lt;sub&gt;d&lt;/sub&gt;]，U&lt;sub&gt;12&lt;/sub&gt;=[u&lt;sub&gt;d+1&lt;/sub&gt;,u&lt;sub&gt;d+2&lt;/sub&gt;,...,u&lt;sub&gt;r&lt;/sub&gt;]。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;同样把V&lt;sub&gt;1&lt;/sub&gt;进行分块，得到V&lt;sub&gt;1&lt;/sub&gt;=[V&lt;sub&gt;11&lt;/sub&gt;, V&lt;sub&gt;12&lt;/sub&gt;]，V&lt;sub&gt;11&lt;/sub&gt;=[v&lt;sub&gt;1&lt;/sub&gt;,v&lt;sub&gt;2&lt;/sub&gt;,...,v&lt;sub&gt;d&lt;/sub&gt;]，V&lt;sub&gt;12&lt;/sub&gt;=[v&lt;sub&gt;d+1&lt;/sub&gt;,v&lt;sub&gt;d+2&lt;/sub&gt;,...,v&lt;sub&gt;r&lt;/sub&gt;]。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1630478/201905/1630478-20190502094002792-1088032569.png&quot; alt=&quot;&quot; width=&quot;523&quot; height=&quot;78&quot;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;于是我们可以把X=U&lt;sub&gt;1&lt;/sub&gt;SV&lt;sub&gt;1&lt;/sub&gt;&lt;sup&gt;T&lt;/sup&gt;也分块成：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1630478/201905/1630478-20190502213534269-1574999910.png&quot; alt=&quot;&quot; width=&quot;352&quot; height=&quot;87&quot;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;因此如果我们想把维度降到d维，那么就让X≈U&lt;sub&gt;11&lt;/sub&gt;S&lt;sub&gt;1&lt;/sub&gt;V&lt;sub&gt;11&lt;/sub&gt;&lt;sup&gt;T&lt;/sup&gt;。这样我们就舍弃了r-d维的信息U&lt;sub&gt;12&lt;/sub&gt;S&lt;sub&gt;2&lt;/sub&gt;V&lt;sub&gt;12&lt;/sub&gt;&lt;sup&gt;T&lt;/sup&gt;，那不免让人担心，信息是否会损失太多。那如何计算损失的信息量呢？&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;span&gt;3、度量降维后的信息量&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;在主成分分析法的文章中，提到了可以用数据集的方差来衡量数据所包含的信息量，方差越大，包含的信息越多。而方差又和特征值密切相关，在某些特殊情况下方差就等于特征值。于是我们隐约感觉到可以用我们求出来的奇异值或者特征值来度量矩阵的信息量。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;是的，矩阵X的信息量就定义为所有奇异值的平方和，也就是X&lt;sup&gt;T&lt;/sup&gt;X的特征值之和：F=λ&lt;sub&gt;1&lt;/sub&gt;+λ&lt;sub&gt;2&lt;/sub&gt;+…+λ&lt;sub&gt;r&lt;/sub&gt;。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;那么降维后的矩阵U&lt;sub&gt;11&lt;/sub&gt;S&lt;sub&gt;1&lt;/sub&gt;V&lt;sub&gt;11&lt;/sub&gt;&lt;sup&gt;T&lt;/sup&gt;的信息量为：F&lt;sub&gt;1&lt;/sub&gt;=λ&lt;sub&gt;1&lt;/sub&gt;+λ&lt;sub&gt;2&lt;/sub&gt;+…+λ&lt;sub&gt;d&lt;/sub&gt;，而损失的信息为矩阵U&lt;sub&gt;12&lt;/sub&gt;S&lt;sub&gt;2&lt;/sub&gt;V&lt;sub&gt;12&lt;/sub&gt;&lt;sup&gt;T&lt;/sup&gt;的信息量：F&lt;sub&gt;2&lt;/sub&gt;=λ&lt;sub&gt;d+1&lt;/sub&gt;+λ&lt;sub&gt;d+2&lt;/sub&gt;+…+λ&lt;sub&gt;r。&lt;/sub&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;于是损失的信息量占总信息量的比例为：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1630478/201905/1630478-20190502101156248-894427685.png&quot; alt=&quot;&quot; width=&quot;172&quot; height=&quot;54&quot;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;这样我们就可以清晰地看到降到d维后，信息量是否损失太大，是否让我们无法承受。不过好在S中的奇异值是从大到小进行排列的，而且一般下降得特别快，前面少数几个奇异值的平方占总信息量的比例一般就已经很大了，剩下的舍弃了影响也不会很大。&lt;/span&gt;&lt;sub&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/sub&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;好，到这里我们就明白了怎么度量降维后的矩阵所包含的信息量了。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;然后，作为好奇宝宝的你也许会问，为什么矩阵X的信息量就是所有奇异值的平方和呢？好的，邓紫棋已经听到你的呼唤了，返场唱最后一首歌。&lt;/span&gt;&lt;strong&gt;&lt;span&gt;这里是用矩阵X的F范数的平方来度量信息量。&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;什么是矩阵的F范数呢？矩阵的F范数定义为矩阵中每个元素平方之和的平方根，那么F范数的平方就是每个元素的平方和。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1630478/201905/1630478-20190502113621199-350475293.png&quot; alt=&quot;&quot; width=&quot;147&quot; height=&quot;96&quot;/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;因为矩阵X每个元素的平方和（F范数的平方）是方阵X&lt;sup&gt;T&lt;/sup&gt;X的对角线元素之和（迹），于是我们进行证明：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1630478/201905/1630478-20190502114824108-1346891226.png&quot; alt=&quot;&quot; width=&quot;558&quot; height=&quot;140&quot;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;其实不证明我们也知道方阵X&lt;sup&gt;T&lt;/sup&gt;X的对角线元素之和（迹）就是其特征值之和，哈哈哈，被我带偏了。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;span&gt;四、特征分解、奇异值值分解与主成分分析法&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;1、由特征分解到奇异值分解&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;span&gt;（1）什么是特征分解&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;一个n×n的方阵A的特征分解（E&lt;span class=&quot;fontstyle0&quot;&gt;igenvalue Decomposition )定义为：&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;span class=&quot;fontstyle0&quot;&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1630478/201905/1630478-20190502151037862-394490830.png&quot; alt=&quot;&quot; width=&quot;90&quot; height=&quot;23&quot;/&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;其中V是n×n的方阵，其中每一列都是A的特征向量，∧是对角阵，其中每一个元素是A的特征值。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;如果A是对称矩阵，那么A的特征分解就变成了：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1630478/201905/1630478-20190502151409943-1304174861.png&quot; alt=&quot;&quot; width=&quot;90&quot; height=&quot;24&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;span&gt;其中V是正交矩阵，即V&lt;/span&gt;&lt;sup&gt;-1&lt;/sup&gt;=V&lt;sup&gt;T&lt;/sup&gt;。&lt;/span&gt;&lt;strong&gt;&lt;span&gt;注意是方阵才可以进行特征分解哦。&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;（2）推导奇异值分解&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;如果有一个&lt;/span&gt;&lt;span&gt;n×m的矩阵X，我们是没法对X进行特征分解的，那么怎么由特征分解推导出奇异值分解呢？&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;我们注意到X&lt;sup&gt;T&lt;/sup&gt;X是m×m实对称矩阵，于是先对X&lt;sup&gt;T&lt;/sup&gt;X进行特征分解：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1630478/201905/1630478-20190502152005790-934740771.png&quot; alt=&quot;&quot; width=&quot;120&quot; height=&quot;24&quot;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;V的列向量是单位特征向量，对角阵∧中的对角元素是特征值，且我们对特征值进行降序排列。假设X的秩为r，那么非零的特征值有r个。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;V中的列向量（v&lt;sub&gt;1&lt;/sub&gt;, v&lt;sub&gt;2&lt;/sub&gt;, ...v&lt;sub&gt;r&lt;/sub&gt;,.. v&lt;sub&gt;m&lt;/sub&gt;）可以看成是m维空间中的m个标准正交基。X&lt;sup&gt;T&lt;/sup&gt;X特征分解就相当于一个线性变换，用标准正交基构成的矩阵V对对角矩阵进行线性变换，得到X&lt;sup&gt;T&lt;/sup&gt;X。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;那么n×m的矩阵X应该也可以由一个n维空间中的n个标准正交基和一个m维空间中的m个标准正交基，对某个矩阵进行线性变换得到。我们想办法来找到这些标准正交基。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;我们就让X&lt;sup&gt;T&lt;/sup&gt;X的单位特征向量V=（v&lt;sub&gt;1&lt;/sub&gt;, v&lt;sub&gt;2&lt;/sub&gt;, ...v&lt;sub&gt;r&lt;/sub&gt;,.. v&lt;sub&gt;m&lt;/sub&gt;）作为m个标准正交基，再找另外n个标准正交基。瞎折腾了一阵后，突然发现Xv&lt;sub&gt;i&lt;/sub&gt;与Xv&lt;sub&gt;j&lt;/sub&gt;是正交的！&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1630478/201905/1630478-20190502155255254-683924916.png&quot; alt=&quot;&quot; width=&quot;429&quot; height=&quot;57&quot;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;太好了！这意味着只要我们把（Xv&lt;sub&gt;1&lt;/sub&gt;,Xv&lt;sub&gt;2&lt;/sub&gt;,..., Xv&lt;sub&gt;m&lt;/sub&gt;）中的非零列向量进行标准化，就可以得到另一组标准正交基了！如果X的秩为r，那么非零列向量是（Xv&lt;sub&gt;1&lt;/sub&gt;,Xv&lt;sub&gt;2&lt;/sub&gt;,..., Xv&lt;sub&gt;r&lt;/sub&gt;）（我不知道这怎么来的，装逼失败），且满足：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1630478/201905/1630478-20190502163319398-1602646273.png&quot; alt=&quot;&quot; width=&quot;263&quot; height=&quot;62&quot;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;于是我们对Xv&lt;/span&gt;&lt;span&gt;&lt;sub&gt;i&lt;/sub&gt;&lt;/span&gt;&lt;span&gt;进行标准化：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1630478/201905/1630478-20190502162917974-454640115.png&quot; alt=&quot;&quot; width=&quot;197&quot; height=&quot;130&quot;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;得到了r个标准正交基(u&lt;sub&gt;1&lt;/sub&gt;, u&lt;sub&gt;2&lt;/sub&gt;, ... u&lt;sub&gt;r&lt;/sub&gt;)，可是我们需要n个，还少了n-r个。没关系，我们直接找任意n-r个列向量，填补上去，使得U=(u&lt;sub&gt;1&lt;/sub&gt;, u&lt;sub&gt;2&lt;/sub&gt;, ... u&lt;sub&gt;r&lt;/sub&gt;, ..., u&lt;sub&gt;n&lt;/sub&gt;)是一组标准正交基。σ&lt;sub&gt;i&lt;/sub&gt;是奇异值，我们用σ&lt;sub&gt;i&lt;/sub&gt;&lt;/span&gt;&lt;span&gt;作为对角元素来构造一个n×m维的矩阵Σ，那么X就可以用U和V这两个标准正交基组对Σ进行线性变换得到，也就是奇异值分解：X=UΣV&lt;/span&gt;&lt;span&gt;&lt;sup&gt;T&lt;/sup&gt;&lt;/span&gt;&lt;span&gt;。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;span&gt;2、奇异值分解与主成分分析法&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;奇异值分解是主成分分析法的一种常用的解决方案。如果数据集X是一个n×m的矩阵，n是变量的个数，m是样本的数量，那么进行主成分分析，也就是用奇异值分解的左奇异矩阵或者右奇异矩阵的装置作为主成分分析法中的转换矩阵，去乘以数据集X，从而得到主成分矩阵Y。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;span&gt;（1）为什么用奇异值分解&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;可是在《&lt;a id=&quot;cb_post_title_url&quot; class=&quot;postTitle2&quot; href=&quot;https://www.cnblogs.com/Luv-GEM/p/10765574.html&quot;&gt;降维之主成分分析法（PCA）&lt;/a&gt;》中，我们明白了，可以求出X的协方差矩阵&lt;img src=&quot;https://img2018.cnblogs.com/blog/1630478/201905/1630478-20190502182422415-909703453.png&quot; alt=&quot;&quot; width=&quot;57&quot; height=&quot;30&quot;/&gt;的单位特征向量矩阵E，用E的转置E&lt;sup&gt;T&lt;/sup&gt;作为转换矩阵P，然后由PX=Y得到主成分矩阵，再挑出前k主成分就可以做到降维。那我们直接去求E不就好了吗？干嘛还要把奇异值分解拉扯进来？&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;这是因为求解n维矩阵XX&lt;sup&gt;T&lt;/sup&gt;的特征值和特征向量的算法复杂度为O(n&lt;sup&gt;3&lt;/sup&gt;)，因此如果X是高维的数据，也就是n非常大时，进行主成分分析就要计算超大矩阵的特征值。这就出现了算法复杂度过高，计算效率太低的问题。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;可是奇异值分解也要对矩阵X&lt;sup&gt;T&lt;/sup&gt;X进行特征分解来求右奇异矩阵V啊，算法复杂度不也是O(n&lt;sup&gt;3&lt;/sup&gt;)？是这样的，不过对高维矩阵进行奇异值分解时，有一些更高效的算法，不用采取暴力特征分解的方式。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;span&gt;（2）奇异值分解与主成分分析法等价&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;我们先按照主成分分析法的步骤，对XX&lt;sup&gt;T&lt;/sup&gt;进行特征分解，得到：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1630478/201905/1630478-20190502192445707-480592706.png&quot; alt=&quot;&quot; width=&quot;108&quot; height=&quot;22&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;然后对X进行奇异值分解，沿用前面的符号体系，得到X=UΣV&lt;sup&gt;T&lt;/sup&gt;，把X的奇异值分解代入到上面的特征分解式中：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1630478/201905/1630478-20190502192959076-1166015991.png&quot; alt=&quot;&quot; width=&quot;516&quot; height=&quot;30&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;由于在主成分分析法中我们用E&lt;/span&gt;&lt;span&gt;&lt;sup&gt;T&lt;/sup&gt;&lt;/span&gt;&lt;span&gt;作为转换矩阵P，那么从上面的推导可知，&lt;/span&gt;&lt;span&gt;可以用X的左奇异矩阵U的转置U&lt;/span&gt;&lt;span&gt;&lt;sup&gt;T&lt;/sup&gt;&lt;/span&gt;&lt;span&gt;作为转换矩阵P，来求出主成分矩阵Y，U&lt;/span&gt;&lt;span&gt;&lt;sup&gt;T&lt;/sup&gt;&lt;/span&gt;&lt;span&gt;X=Y。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;span&gt;（3）用奇异值分解做主成分降维&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;X的奇异值分解还可以简化地写成X=U&lt;sub&gt;1&lt;/sub&gt;SV&lt;sub&gt;1&lt;/sub&gt;&lt;sup&gt;T&lt;/sup&gt;，同样代入XX&lt;sup&gt;T&lt;/sup&gt;的特征分解中，得到：XX&lt;sup&gt;T&lt;/sup&gt;=U&lt;sub&gt;1&lt;/sub&gt;SS&lt;sup&gt;T&lt;/sup&gt;U&lt;sub&gt;1&lt;/sub&gt;&lt;sup&gt;T&lt;/sup&gt;。U&lt;sub&gt;1&lt;/sub&gt;=(u&lt;sub&gt;1&lt;/sub&gt;, u&lt;sub&gt;2&lt;/sub&gt;, ...u&lt;sub&gt;r&lt;/sub&gt;)是n×r的矩阵，那么U&lt;sub&gt;1&lt;/sub&gt;&lt;sup&gt;T&lt;/sup&gt;是一个r×n的矩阵，U&lt;sub&gt;1&lt;/sub&gt;&lt;sup&gt;T&lt;/sup&gt;X就把X的特征从n维降至了r维。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;进一步，我们在前面用分块矩阵的思想，把U&lt;sub&gt;1&lt;/sub&gt;分块为U&lt;sub&gt;1&lt;/sub&gt;=[U&lt;sub&gt;11&lt;/sub&gt;, U&lt;sub&gt;12&lt;/sub&gt;]，U&lt;sub&gt;11&lt;/sub&gt;&lt;sup&gt;T&lt;/sup&gt;是一个d×n维的矩阵，那么用U&lt;sub&gt;11&lt;/sub&gt;&lt;sup&gt;T&lt;/sup&gt;作为转换矩阵，就可以把X的特征进一步压缩至d维。&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt; &lt;strong&gt;&lt;span&gt;（4）其他补充&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;如果你看了其他博主写的博客，会发现有些是用右奇异矩阵V的转置V&lt;/span&gt;&lt;span&gt;&lt;sup&gt;T&lt;/sup&gt;&lt;/span&gt;&lt;span&gt;来作为特征压缩的转换矩阵，和本文不一样。这是因为那些博客把有m个样本，n维特征的数据集写成了m×n的矩阵X，而本文把数据集写成n×m的矩阵，所以那些博客是用右奇异矩阵V，而本文是用左奇异矩阵U。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;span&gt;五、奇异值分解与词向量降维&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;我们来看怎么把奇异值分解用在词向量降维上。如果我们手头有一份文本数据集，里头有m篇文档，总共有n个不重复的词，那么我们可以通过统计文档中所有词出现的次数，整理成一个矩阵X，来构造词向量。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;一般有两种方法来构造词向量矩阵：一是TF-IDF，词向量矩阵是n×m维的，行向量是每个词的词向量；二是基于窗口的共现矩阵，如果窗口是1，那么词向量矩阵是n×n维的，行向量是每个词的词向量。这两种词向量的表示方法存在很大的问题，那就是数据稀疏和词表维度过高。想象一下，如果文档有10万篇，词有5万个，那会是多么恐怖的一个场景。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;因此我们非常有必要运用奇异值分解，对词向量矩阵进行降维。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;span&gt;1、对TF-IDF词向量矩阵进行降维&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;span&gt;TF-IDF不用多解释了，由每个词的词频和逆文档频率两部分计算得到每个词的TF-IDF，然后所有词的TF-IDF构成词向量矩阵X&lt;/span&gt;&lt;sup&gt;n×m&lt;/sup&gt;&lt;span&gt;。这个矩阵太大了，我们对这个矩阵X进行奇异值分解得到U&lt;sub&gt;1&lt;/sub&gt;SV&lt;sub&gt;1&lt;/sub&gt;&lt;sup&gt;T&lt;/sup&gt;，U&lt;sub&gt;1&lt;/sub&gt;是n×r的矩阵，我们用U&lt;sub&gt;1&lt;/sub&gt;的行向量作为n个词的词向量，就实现了对文档数量维度的压缩。&lt;/span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;span&gt;如果还嫌词表维度太高，那么我们可以继续降维，从U&lt;sub&gt;1&lt;/sub&gt;中拿出前d个列向量，组成新的n×d维的词向量矩阵U&lt;sub&gt;11&lt;/sub&gt;，行向量作为降到d维后每个词的词向量。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;span&gt;d取多少合适呢？我们可以用奇异值的平方和计算降到d维后的剩余的信息量。如果我们希望保留85%的信息，那么就取以下公式大于或等于85%时的d值，作为降维后的维度。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1630478/201905/1630478-20190502210222599-652626867.png&quot; alt=&quot;&quot; width=&quot;157&quot; height=&quot;56&quot;/&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;span&gt;2、对基于窗口的共现矩阵进行降维&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;这种方法是用一个相关性矩阵来构造词向量矩阵，叫做共现矩阵。 假设有3个句子（看成三篇文档也没毛病），一共8个不重复的词（把标点也算上），窗口设定为1，也就是把句子拆成一个个的词。&lt;/span&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;span&gt;I enjoy flying.&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span&gt;I like NLP.&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span&gt;I like deep learning&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;span&gt; 那么共现矩阵就是一个8维的方阵X：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1630478/201905/1630478-20190502210956550-1184113737.png&quot; alt=&quot;&quot; width=&quot;500&quot; height=&quot;228&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;同样用奇异值分解，把X分解为X=U&lt;sub&gt;1&lt;/sub&gt;SV&lt;sub&gt;1&lt;/sub&gt;&lt;sup&gt;T&lt;/sup&gt;，然后用U&lt;sub&gt;1&lt;/sub&gt;的行向量作为每次词的词向量，就把词向量的维度从n维降到了r维。如果觉得还太高了，那么可以按照TF-IDF中的做法，继续进行降维。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;span&gt; &lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;&lt;span&gt;参考资料：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;1、《A Tutorial on Principal Component Analysis. Derivation, Discussion and Singular Value Decomposition》&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;2、《&lt;span class=&quot;fontstyle0&quot;&gt;A Singularly Valuable Decomposition: The SVD of a Matrix&lt;/span&gt; 》&lt;/span&gt;&lt;/p&gt;
</description>
<pubDate>Thu, 02 May 2019 13:57:00 +0000</pubDate>
<dc:creator>Luv_GEM</dc:creator>
<og:description>看了几篇关于奇异值分解(Singular Value Decomposition，SVD)的博客，大部分都是从坐标变换（线性变换）的角度来阐述，讲了一堆坐标变换的东西，整了一大堆图，试图“通俗易懂”地</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/Luv-GEM/p/10801212.html</dc:identifier>
</item>
<item>
<title>【动态规划】完全背包问题 - 弗兰克的猫</title>
<link>http://www.cnblogs.com/mfrank/p/10803417.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/mfrank/p/10803417.html</guid>
<description>&lt;h2 id=&quot;说明&quot;&gt;说明&lt;/h2&gt;
&lt;p&gt;在上一篇中，我们对01背包问题进行了比较深入的研究，这一篇里，我们来聊聊另一个背包问题：完全背包。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://i.loli.net/2019/05/02/5ccaec8a22bb9.png&quot;/&gt;&lt;/p&gt;
&lt;h2 id=&quot;完全背包&quot;&gt;完全背包&lt;/h2&gt;
&lt;p&gt;有N种物品和一个容量为T的背包，每种物品都就可以选择任意多个，第i种物品的价值为P[i]，体积为V[i]，求解：选哪些物品放入背包，可卡因使得这些物品的价值最大，并且体积总和不超过背包容量。&lt;/p&gt;
&lt;p&gt;跟01背包一样，完全背包也是一个很经典的动态规划问题，不同的地方在于01背包问题中，每件物品最多选择一件，而在完全背包问题中，只要背包装得下，每件物品可以选择任意多件。从每件物品的角度来说，与之相关的策略已经不再是选或者不选了，而是有取0件、取1件、取2件...直到取⌊T/Vi⌋（向下取整）件。&lt;/p&gt;
&lt;h2 id=&quot;贪心算法&quot;&gt;贪心算法&lt;/h2&gt;
&lt;p&gt;看到可以选择任意多件，你也许会想，那还不容易，选性价比最高的就好了。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://i.loli.net/2019/03/14/5c8a564a63265.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;于是开启贪婪模式，把每种物品的价格除以体积来算出它们各自的性价比，然后只选择性价比最高的物品放入背包中。&lt;/p&gt;
&lt;p&gt;嗯，听起来好像没什么毛病，但仍旧有一个问题，那就是同一种物品虽然可以选择任意多件，但仍旧只能以件为单位，也就是说单个物品是无法拆分的，不能选择半件，只能多选一件或者少选一件。这样就造成了一个问题，往往无法用性价比最高的物品来装满整个背包，比如背包空间为10，性价比最高的物品占用空间为7，那么剩下的空间该如何填充呢？&lt;/p&gt;
&lt;p&gt;你当然会想到用性价比第二高的物品填充，如果仍旧无法填满，那就依次用第三、第四性价比物品来填充。&lt;/p&gt;
&lt;p&gt;听起来似乎可行，但我只需要举一个反例便能证明这个策略行不通。&lt;/p&gt;
&lt;p&gt;想要举反例很简单，比如只有两个物品：物品A：价值5，体积5，物品B：价值8：体积7，背包容量为10，物品B的性价比显然要比物品A高，那么用贪心算法必然会选择放入一个物品B，此时，剩余的空间已无法装下A或者B，所以得到的最高价值为8，而实际上，选择放入两个物品A即可得到更高的价值10。所以这里贪心算法并不适用。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://i.loli.net/2019/03/14/5c8a56a150bc1.png&quot;/&gt;&lt;/p&gt;
&lt;h2 id=&quot;递归法&quot;&gt;递归法&lt;/h2&gt;
&lt;p&gt;像上一篇中的那样，我们只需要找到递推关系式，就很容易使用递归解法来求解了。&lt;/p&gt;
&lt;p&gt;用ks(i,t)表示前i种物品放入一个容量为t的背包获得的最大价值，那么对于第i种物品，我们有k种选择，0 &amp;lt;= k * V[i] &amp;lt;= t，即可以选择0、1、2...k个第i种物品，所以递推表达式为：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;ks(i,t) = max{ks(i-1, t - V[i] * k) + P[i] * k}; （0 &amp;lt;= k * V[i] &amp;lt;= t）&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;同时，ks(0,t)=0;ks(i,0)=0;&lt;/p&gt;
&lt;p&gt;使用上面的栗子，我们可以先用递归来求解：&lt;/p&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;public static class Knapsack {
    private static int[] P={0,5,8};
    private static int[] V={0,5,7};
    private static int T = 10;

    @Test
    public void soleve1() {
        int result = ks(P.length - 1,10);
        System.out.println(&quot;最大价值为：&quot; + result);
    }

    private int ks(int i, int t){
        int result = 0;
        if (i == 0 || t == 0){
            // 初始条件
            result = 0;
        } else if(V[i] &amp;gt; t){
            // 装不下该珠宝
            result = ks(i-1, t);
        } else {
            // 可以装下
            // 取k个物品i，取其中使得总价值最大的k
            for (int k = 0; k * V[i] &amp;lt;= t; k++){
                int tmp2 = ks(i-1, t - V[i] * k) + P[i] * k;
                if (tmp2 &amp;gt; result){
                    result = tmp2;
                }
            }
        }
        return result;
    }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;同样，这里的数组P和V分别添加了一个元素0，是为了减少越界判断而做的简单处理，运行如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;最大价值为：11&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;如果你对比一下01背包问题中的递归解法，就会发现唯一的区别便是这里多了一层循环，因为01背包中，对于第i个物品只有选和不选两种情况，只需要从这两种选择中选出最优的即可，而完全背包问题则需要在k种选择中选出最优解，这便是最内层循环在做的事情。&lt;/p&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;for (int k = 0; k * V[i] &amp;lt;= t; k++){
    // 选取k个第i件商品的最优价值为tmp2
    int tmp2 = ks(i-1, t - V[i] * k) + P[i] * k;
    if (tmp2 &amp;gt; result){
        // 从中拿出最大的值即为最优解
        result = tmp2;
    }
}&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;最优化原理和无后效性&quot;&gt;最优化原理和无后效性&lt;/h2&gt;
&lt;p&gt;那这个问题可以不可以像01背包问题一样使用动态规划来求解呢？来证明一下即可。&lt;/p&gt;
&lt;p&gt;首先，先用反证法证明最优化原理：&lt;/p&gt;
&lt;p&gt;假设完全背包的解为F(n1,n2,...,nN)（n1，n2 分别代表第1、第2件物品的选取数量），完全背包的子问题为，将前i种物品放入容量为t的背包并取得最大价值，其对应的解为：F(n1,n2,...,ni)，假设该解不是子问题的最优解，即存在另一组解F(m1,m2,...,mi)，使得F(m1,m2,...,mi) &amp;gt; F(n1,n2,...,ni)，那么F(m1,m2,...,mi,...,nN) 必然大于 F(n1,n2,...,nN)，因此 F(n1,n2,...,nN) 不是原问题的最优解，与原假设不符，所以F(n1,n2,...,ni)必然是子问题的最优解。&lt;/p&gt;
&lt;p&gt;再来看看无后效性：&lt;/p&gt;
&lt;p&gt;对于子问题的任意解，都不会影响后续子问题的解，也就是说，前i种物品如何选择，只要最终的剩余背包空间不变，就不会影响后面物品的选择。即满足无后效性。&lt;/p&gt;
&lt;p&gt;因此，完全背包问题也可以使用动态规划来解决。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://i.loli.net/2019/05/02/5ccaece849f09.png&quot;/&gt;&lt;/p&gt;
&lt;h2 id=&quot;动态规划&quot;&gt;动态规划&lt;/h2&gt;
&lt;p&gt;既然知道了可以使用动态规划求解，接下来就是要找到这个问题的状态转移方程。&lt;/p&gt;
&lt;p&gt;其实前面的递推法中，已经找到了递推关系式，它便已经是我们需要的状态转移方程。&lt;/p&gt;
&lt;h3 id=&quot;自上而下记忆法&quot;&gt;自上而下记忆法&lt;/h3&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;ks(i,t) = max{ks(i-1, t - V[i] * k) + P[i] * k}; （0 &amp;lt;= k * V[i] &amp;lt;= t）&lt;/code&gt;
&lt;/pre&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;public static class Knapsack {
    private static int[] P={0,5,8};
    private static int[] V={0,5,7};
    private static int T = 10;

    private Integer[][] results = new Integer[P.length + 1][T + 1];

    @Test
    public void solve2() {
        int result = ks2(P.length - 1,10);
        System.out.println(&quot;最大价值为：&quot; + result);
    }

    private int ks2(int i, int t){
        // 如果该结果已经被计算，那么直接返回
        if (results[i][t] != null) return results[i][t];
        int result = 0;
        if (i == 0 || t == 0){
            // 初始条件
            result = 0;
        } else if(V[i] &amp;gt; t){
            // 装不下该珠宝
            result = ks2(i-1, t);
        } else {
            // 可以装下
            // 取k个物品，取其中使得价值最大的
            for (int k = 0; k * V[i] &amp;lt;= t; k++){
                int tmp2 = ks2(i-1, t - V[i] * k) + P[i] * k;
                if (tmp2 &amp;gt; result){
                    result = tmp2;
                }
            }
        }
        results[i][t] = result;
        return result;
    }
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;找出递归解法后，动态规划的解法其实就很简单了，只是多使用了一个二维数组来存储中间的解。&lt;/p&gt;
&lt;h3 id=&quot;自下而上填表法&quot;&gt;自下而上填表法&lt;/h3&gt;
&lt;p&gt;最后，还可以使用填表法来解决，此时需要将数组P和V额外添加的元素0去掉。&lt;/p&gt;
&lt;p&gt;为了方便理解，还是再画一个图吧：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1043143/201905/1043143-20190502211558406-2126017646.jpg&quot;/&gt;&lt;/p&gt;
&lt;p&gt;对于第i种物品，我们可以选择的目标其实是从上一层中的某几个位置挑选出价值最高的一个。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1043143/201905/1043143-20190502211545752-1539873502.jpg&quot;/&gt;&lt;/p&gt;
&lt;p&gt;这里当t=10时，因为最多只能放得下1个i2物品，所以只需要将两个数值进行比较，如果t=14，那么就需要将取0个、1个和两个i2物品的情况进行比较，然后选出最大值。&lt;/p&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;public static class Knapsack {
    private static int[] P={5,8};
    private static int[] V={5,7};
    private static int T = 10;

    private int[][] dp = new int[P.length + 1][T + 1];

    @Test
    public void solve3() {
        for (int i = 0; i &amp;lt; P.length; i++){
            for (int j = 0; j &amp;lt;= T; j++){
                for (int k = 0; k * V[i] &amp;lt;= j; k++){
                    dp[i+1][j] = Math.max(dp[i+1][j], dp[i][j-k * V[i]] + k * P[i]);
                }
            }
        }
        System.out.println(&quot;最大价值为：&quot; + dp[P.length][T]);
    }
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;跟01背包问题一样，完全背包的空间复杂度也可以进行优化，具体思路这里就不重复介绍了，可以翻看前面的01背包问题优化篇。&lt;/p&gt;
&lt;p&gt;优化后的状态转移方程为：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;ks(t) = max{ks(t), ks(t - Vi) + Pi}&lt;/code&gt;
&lt;/pre&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;public static class Knapsack {
    private static int[] P={0,5,8};
    private static int[] V={0,5,7};
    private static int T = 10;

    private int[] newResults = new int[T + 1];

    @Test
    public void resolve4() {
        int result = ksp(P.length,T);
        System.out.println(result);
    }

    private int ksp(int i, int t){
        // 开始填表
        for (int m = 0; m &amp;lt; i; m++){
            for (int n = V[m]; n &amp;lt;= t; n++){
                newResults[n] = Math.max(newResults[n] , newResults[n - V[m]] + P[m]);
            }
            // 可以在这里输出中间结果
            System.out.println(JSON.toJSONString(newResults));
        }
        return newResults[newResults.length - 1];
    }
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;输出如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;[0,0,0,0,0,0,0,0,0,0,0]
[0,0,0,0,0,5,5,5,5,5,10]
[0,0,0,0,0,5,5,8,8,8,10]
10&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;其实完全背包问题也可以转化成01背包问题来求解，因为第i件物品最多选 ⌊T/Vi⌋(向下取整) 件，于是可以把第i种物品转化为⌊T/Vi⌋件体积和价值相同的物品，然后再来求解这个01背包问题。具体方法这里就不多说了，留给大家自行解决。如果遇到问题，可以翻开前面关于01背包问题的两篇文章。&lt;/p&gt;
&lt;h2 id=&quot;总结&quot;&gt;总结&lt;/h2&gt;
&lt;p&gt;完全背包问题跟01背包有很多相似之处，比较一下他们的状态转移方程以及各种解法，就会发现他们其实是异父异母的亲兄弟。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://i.loli.net/2019/05/02/5ccaee9d39578.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;这两个背包问题的关键都在于状态转移方程的寻找，如果对于类似的问题没有思路，可以先尝试找出递归解法，然后自上而下的记忆法便水到渠成了。&lt;/p&gt;
&lt;p&gt;当然，最重要的还是解题思路，理解记忆法和填表法的精髓，有助于之后举一反三，去解决类似的延伸问题。&lt;/p&gt;
&lt;p&gt;关于完全背包问题的解析到此就结束了，祝大家五一愉快！&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://i.loli.net/2019/03/14/5c8a580b1789e.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;如果有疑问或者有什么想法，也欢迎关注我的公众号进行留言交流：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://i.loli.net/2019/03/14/5c8a58ba229ca.png&quot;/&gt;&lt;/p&gt;
</description>
<pubDate>Thu, 02 May 2019 13:22:00 +0000</pubDate>
<dc:creator>弗兰克的猫</dc:creator>
<og:description>说明 在上一篇中，我们对01背包问题进行了比较深入的研究，这一篇里，我们来聊聊另一个背包问题：完全背包。 完全背包 有N种物品和一个容量为T的背包，每种物品都就可以选择任意多个，第i种物品的价值为P[</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/mfrank/p/10803417.html</dc:identifier>
</item>
<item>
<title>详解Redis Cluster集群 - 请叫我头头哥</title>
<link>http://www.cnblogs.com/toutou/p/redis_cluster.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/toutou/p/redis_cluster.html</guid>
<description>&lt;div class=&quot;bodyCustomClass&quot; readability=&quot;32.5&quot;&gt;
&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;Redis Cluster是Redis的分布式解决方案，在Redis 3.0版本正式推出的，有效解决了Redis分布式方面的需求。当遇到单机内存、并发、流量等瓶颈时，可以采用Cluster架构达到负载均衡的目的。分布式集群首要解决把整个数据集按照分区规则映射到多个节点的问题，即把数据集划分到多个节点上，每个节点负责整个数据的一个子集。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;h2 id=&quot;_nav_0&quot; class=&quot;blogCustomTitleStyle&quot;&gt;&lt;span class=&quot;blogCustomTitleIco&quot;&gt;v&lt;/span&gt;功能介绍&lt;/h2&gt;
&lt;p&gt;1.0 数据自动分片&lt;/p&gt;
&lt;p&gt;集群中每个节点都会负责一定数量的slot，每个key会映射到一个具体的slot，通过这种方式就可能找到key具体保存在哪个节点上了。&lt;/p&gt;
&lt;p&gt;1.1 提供hash tags功能&lt;/p&gt;
&lt;p&gt;通过hash tag功能可以将多个不同key映射到同一个slot上，这样就能够提供multi-key操作，hash tag的使用的方式是在key中包含“{}”，这样只有在“{...}”中字串被用于hash计算。&lt;/p&gt;
&lt;p&gt;1.2 自动失效转移和手动失效转移&lt;/p&gt;
&lt;p&gt;1.3 减少硬件成本和运维成本。&lt;/p&gt;
&lt;h2 id=&quot;_nav_1&quot; class=&quot;blogCustomTitleStyle&quot;&gt;&lt;span class=&quot;blogCustomTitleIco&quot;&gt;v&lt;/span&gt;Redis Cluster目标&lt;/h2&gt;
&lt;p&gt;高性能&lt;/p&gt;
&lt;p&gt;高可用&lt;/p&gt;
&lt;p&gt;线性扩容&lt;/p&gt;
&lt;h2 id=&quot;_nav_2&quot; class=&quot;blogCustomTitleStyle&quot;&gt;&lt;span class=&quot;blogCustomTitleIco&quot;&gt;v&lt;/span&gt;配置Redis Cluster&lt;/h2&gt;
&lt;p&gt;创建目录cluster，并为6个实例创建各自的目录，这6个目录用来存放6个实例，后面将使用这6个实例组成集群。3个Master和3个Slave&lt;/p&gt;
&lt;p&gt;1.0 创建目录&lt;/p&gt;
&lt;p&gt;&lt;code&gt;mkdir redis-cluster&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;mkdir 900{1,2,3,4,5,6}&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/506684/201904/506684-20190423193328346-1086200685.png&quot; alt=&quot;详解Redis Cluster集群&quot;/&gt;&lt;/p&gt;
&lt;p&gt;1.1 拷贝6个实例&lt;/p&gt;
&lt;p&gt;&lt;code&gt;cp /root/redis-5.0.2/redis.conf /usr/local/bin/redis-cluster/9001&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/506684/201904/506684-20190423193334115-292697772.png&quot; alt=&quot;详解Redis Cluster集群&quot;/&gt;&lt;/p&gt;
&lt;p&gt;1.2 更新实例配置文件&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/506684/201904/506684-20190423193340662-576564194.png&quot; alt=&quot;详解Redis Cluster集群&quot;/&gt;&lt;/p&gt;
&lt;p&gt;具体来说，需要注意下：由于在一台机器上，因此每个实例应该有不同的端口；同时，每个实例显然会有自己的存放数据的地方；开启AOF模式；开启集群配置；开启后台模式；&lt;/p&gt;
&lt;p&gt;1.3 Redis集群的操作在后文是通过Ruby脚本来完成的，因此需要安装Ruby相关的RPM包，以及Redis和Ruby的接口包。&lt;/p&gt;
&lt;p&gt;1.3.1 安装ruby&lt;/p&gt;
&lt;p&gt;&lt;code&gt;yum install ruby&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;1.3.1 安装rubygems&lt;/p&gt;
&lt;p&gt;&lt;code&gt;yum install rubygems&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;1.4 启动Redis cluster实例&lt;/p&gt;
&lt;p&gt;&lt;code&gt;/root/redis-5.0.2/src/redis-server /usr/local/bin/redis-cluster/9001/redis.conf&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/506684/201904/506684-20190423193348276-459535066.png&quot; alt=&quot;详解Redis Cluster集群&quot;/&gt;&lt;/p&gt;
&lt;p&gt;通过&lt;code&gt;netstat -tnulp | grep redis&lt;/code&gt;和&lt;code&gt;ps -aux | grep redis&lt;/code&gt;查看是否启动成功。&lt;/p&gt;
&lt;p&gt;1.5 redis-cli创建集群&lt;/p&gt;
&lt;p&gt;&lt;code&gt;./redis-cli --cluster create 10.168.11.116:9001 10.168.11.116:9002 10.168.11.116:9003 10.168.11.116:9004 10.168.11.116:9005 10.168.11.116:9006&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/506684/201904/506684-20190423193355188-729235446.png&quot; alt=&quot;详解Redis Cluster集群&quot;/&gt;&lt;/p&gt;
&lt;p&gt;注意，redis5.0使用redis-cli作为创建集群的命令，使用c语言实现，不再使用ruby语言。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/506684/201904/506684-20190423193401338-2010927774.png&quot; alt=&quot;详解Redis Cluster集群&quot;/&gt;&lt;/p&gt;
&lt;p&gt;1.6 检查集群&lt;/p&gt;
&lt;p&gt;&lt;code&gt;./redis-cli --cluster check 10.168.11.116:9001&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/506684/201904/506684-20190423193407400-1559199129.png&quot; alt=&quot;详解Redis Cluster集群&quot;/&gt;&lt;/p&gt;
&lt;p&gt;1.7 查看集群key、slot、slave分布信息&lt;/p&gt;
&lt;p&gt;&lt;code&gt;./redis-cli --cluster info 10.168.11.116:9001&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/506684/201904/506684-20190423193413996-1947144457.png&quot; alt=&quot;详解Redis Cluster集群&quot;/&gt;&lt;/p&gt;
&lt;p&gt;1.8 集群相关命令&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;35&quot;&gt;
&lt;pre&gt;
&lt;span&gt;CLUSTER INFO 打印集群的信息
CLUSTER NODES 列出集群当前已知的所有节点（node），以及这些节点的相关信息。 
CLUSTER MEET &lt;/span&gt;&amp;lt;ip&amp;gt; &amp;lt;port&amp;gt;&lt;span&gt; 将 ip 和 port 所指定的节点添加到集群当中，让它成为集群的一份子。
CLUSTER FORGET &lt;/span&gt;&amp;lt;node_id&amp;gt;&lt;span&gt; 从集群中移除 node_id 指定的节点。
CLUSTER REPLICATE &lt;/span&gt;&amp;lt;node_id&amp;gt;&lt;span&gt; 将当前节点设置为 node_id 指定的节点的从节点。
CLUSTER SAVECONFIG 将节点的配置文件保存到硬盘里面。
CLUSTER ADDSLOTS &lt;/span&gt;&amp;lt;slot&amp;gt;&lt;span&gt; [slot ...] 将一个或多个槽（slot）指派（assign）给当前节点。
CLUSTER DELSLOTS &lt;/span&gt;&amp;lt;slot&amp;gt;&lt;span&gt; [slot ...] 移除一个或多个槽对当前节点的指派。
CLUSTER FLUSHSLOTS 移除指派给当前节点的所有槽，让当前节点变成一个没有指派任何槽的节点。
CLUSTER SETSLOT &lt;/span&gt;&amp;lt;slot&amp;gt; NODE &amp;lt;node_id&amp;gt;&lt;span&gt; 将槽 slot 指派给 node_id 指定的节点。
CLUSTER SETSLOT &lt;/span&gt;&amp;lt;slot&amp;gt; MIGRATING &amp;lt;node_id&amp;gt;&lt;span&gt; 将本节点的槽 slot 迁移到 node_id 指定的节点中。
CLUSTER SETSLOT &lt;/span&gt;&amp;lt;slot&amp;gt; IMPORTING &amp;lt;node_id&amp;gt;&lt;span&gt; 从 node_id 指定的节点中导入槽 slot 到本节点。
CLUSTER SETSLOT &lt;/span&gt;&amp;lt;slot&amp;gt; STABLE 取消对槽 slot 的导入（&lt;span&gt;import&lt;/span&gt;&lt;span&gt;）或者迁移（migrate）。 
CLUSTER KEYSLOT &lt;/span&gt;&amp;lt;key&amp;gt;&lt;span&gt; 计算键 key 应该被放置在哪个槽上。
CLUSTER COUNTKEYSINSLOT &lt;/span&gt;&amp;lt;slot&amp;gt;&lt;span&gt; 返回槽 slot 目前包含的键值对数量。
CLUSTER GETKEYSINSLOT &lt;/span&gt;&amp;lt;slot&amp;gt; &amp;lt;count&amp;gt;&lt;span&gt; 返回 count 个 slot 槽中的键。 
CLUSTER SLAVES node&lt;/span&gt;-id 返回一个master节点的slaves 列表
&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id=&quot;_nav_2&quot; class=&quot;blogCustomTitleStyle&quot;&gt;&lt;span class=&quot;blogCustomTitleIco&quot;&gt;v&lt;/span&gt;Cluster测试效果&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;./redis-cli -c -h 10.168.11.116 -p 9001&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/506684/201904/506684-20190423200314838-1152384198.png&quot; alt=&quot;详解Redis Cluster集群&quot;/&gt;&lt;/p&gt;
&lt;p&gt;其他参考资料：&lt;/p&gt;
&lt;div id=&quot;MySignature&quot; readability=&quot;9.0030211480363&quot;&gt;
&lt;p id=&quot;PSignature&quot;&gt;&lt;br/&gt;作　　者：&lt;strong&gt;&lt;span&gt;&lt;a href=&quot;http://www.cnblogs.com/toutou/&quot; target=&quot;_blank&quot;&gt;请叫我头头哥&lt;/a&gt;&lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;出　　处：&lt;a href=&quot;http://www.cnblogs.com/toutou/&quot; target=&quot;_blank&quot;&gt;http://www.cnblogs.com/toutou/&lt;/a&gt;&lt;br/&gt;关于作者：专注于基础平台的项目开发。如有问题或建议，请多多赐教！&lt;br/&gt;版权声明：本文版权归作者和博客园共有，欢迎转载，但未经作者同意必须保留此段声明，且在文章页面明显位置给出原文链接。&lt;br/&gt;特此声明：所有评论和私信都会在第一时间回复。也欢迎园子的大大们指正错误，共同进步。或者&lt;a href=&quot;http://msg.cnblogs.com/msg/send/%E8%AF%B7%E5%8F%AB%E6%88%91%E5%A4%B4%E5%A4%B4%E5%93%A5&quot;&gt;直接私信&lt;/a&gt;我&lt;br/&gt;声援博主：如果您觉得文章对您有帮助，可以点击文章右下角&lt;strong&gt;&lt;span&gt;【&lt;a id=&quot;post-up&quot; href=&quot;javascript:void(0);&quot;&gt;推荐&lt;/a&gt;】&lt;/span&gt;&lt;/strong&gt;一下。您的鼓励是作者坚持原创和持续写作的最大动力！&lt;br/&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
<pubDate>Thu, 02 May 2019 13:09:00 +0000</pubDate>
<dc:creator>请叫我头头哥</dc:creator>
<og:description>Redis Cluster是Redis的分布式解决方案，在Redis 3.0版本正式推出的，有效解决了Redis分布式方面的需求。当遇到单机内存、并发、流量等瓶颈时，可以采用Cluster架构达到负载</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/toutou/p/redis_cluster.html</dc:identifier>
</item>
<item>
<title>听说苏州是互联网的荒漠，真的吗？ - 豌豆花下猫</title>
<link>http://www.cnblogs.com/pythonista/p/10803387.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/pythonista/p/10803387.html</guid>
<description>&lt;p&gt;&lt;img src=&quot;http://ww1.sinaimg.cn/large/68b02e3bgy1g2n92xyxiwj21g80yt41f.jpg&quot;/&gt;&lt;/p&gt;
&lt;p&gt;我国互联网存在着巨大的地域性偏差，除了北上广深杭外，其它省市的互联网都很弱小。去年 8 月，某个公众号发布了一篇《上海不相信互联网》的文章，引起了多方的讨论。CSDN 公众号以此为契机，陆续发布了关于南京、东北、西安、甚至德国等地的互联网发展情况的文章。&lt;/p&gt;
&lt;p&gt;作为一个“苏漂”程序员，我有幸得到了 CSDN 编辑的约稿，因此也给苏州写了一篇。这篇文章并不是专业的行业观察，有些观点缺乏客观的数据支撑，还有一些理应关注的内容因为资料不足而被迫删除，所以整体而言，这篇文章只是&lt;strong&gt;个人之见&lt;/strong&gt; 。它是一个开端吧，今后我会持续关注苏州互联网的发展，再分享我的见闻与思考。&lt;/p&gt;
&lt;p&gt;该文已授权给 CSDN 公众号发布原创，我转载于此，主要是调整了排版。欢迎就文中内容与我交流。如需转载，请联系 CSDN 公众号（当然也可找我，代为联系）。&lt;/p&gt;
&lt;hr/&gt;&lt;p&gt;本文首发于 CSDN 公众号&lt;/p&gt;
&lt;p&gt;发布标题：《苏州到底有没有互联网？》&lt;/p&gt;
&lt;p&gt;原文：&lt;a href=&quot;https://mp.weixin.qq.com/s/wpUcD5EHdiHz97pnXMKveQ&quot; class=&quot;uri&quot;&gt;https://mp.weixin.qq.com/s/wpUcD5EHdiHz97pnXMKveQ&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;苏州印象&quot;&gt;01 苏州印象&lt;/h2&gt;
&lt;p&gt;说起苏州，你的第一印象是什么？&lt;/p&gt;
&lt;p&gt;是“上有天堂，下有苏杭”、“苏湖熟，天下足”，是烟雨楼台中的江南古城吧？&lt;/p&gt;
&lt;p&gt;是“姑苏城外寒山寺，夜半钟声到客船”，是文人墨客游园林品昆曲哼评弹，是传续历史文化底蕴的代表吧？&lt;/p&gt;
&lt;p&gt;是背靠上海、独占江苏鳌头的现代大都市，是 GDP 排行全国第七名，是非省会或直辖市的城市中的领头羊吧？&lt;/p&gt;
&lt;p&gt;没错，这些都是苏州印象，复古与现代相融合，文化与经济共繁荣。&lt;/p&gt;
&lt;p&gt;它有近 2500 年历史，是中国首批国家历史文化名城之一，它的园林被联合国教科文组织列为世界文化遗产，它的大运河区段也入选了世界遗产名录。&lt;/p&gt;
&lt;p&gt;它的工业总产值居全国第一，进出口总额排全国前三，城市总人口超过 1000 万，是国内第二大的移民城市。&lt;/p&gt;
&lt;p&gt;2018 年 8 月，英国经济学人智库（EIU）发布了年度《全球宜居城市排行榜》，苏州市蝉联成为中国内地最宜居城市，再次超越北上广！&lt;/p&gt;
&lt;p&gt;2018 年 11 月，福布斯中国发布了《创新力最强的30城市》，苏州市排名第 3 ，超越上海和广州！&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://ww1.sinaimg.cn/large/68b02e3bgy1g2ha6gio7vj20sq0b8jrn.jpg&quot;/&gt;&lt;/p&gt;
&lt;p&gt;这就是苏州。苏州就是这样。&lt;/p&gt;
&lt;p&gt;然而，在这一连串的光鲜亮丽背后，苏州也有自己的痛——它从未培育过一家互联网独角兽，甚至不及苏北的宿迁，后者至少养育出了一位互联网巨头“大强子”。&lt;/p&gt;
&lt;p&gt;苏州拥有庞大的经济体量，但它的存在感并不强，互联网的实力与自身并不匹配。坊间传言，苏州是互联网的荒漠，这是真的么？&lt;/p&gt;
&lt;h2 id=&quot;互联网荒漠&quot;&gt;02 互联网荒漠&lt;/h2&gt;
&lt;p&gt;南京是苏州终生的劲敌/兄弟，CSDN 曾发布过一篇《“南京才不相信互联网呢”》，介绍了它的互联网状况。&lt;/p&gt;
&lt;p&gt;该文把南京比作是“互联网沙漠之城”，我完全不认同——说是沙漠就太过分啦，南京远不到贫瘠无力的地步，说得那么苦寒兮兮的，把混得更惨的其它城市置于何地呢？&lt;/p&gt;
&lt;p&gt;如果要把北上广深杭，比作互联网的几片树林的话，南京大概是一圈草地吧，苏州反而才是绿植更加稀疏的荒漠。&lt;/p&gt;
&lt;p&gt;在那篇文章的留言区，有读者这样留言：&lt;/p&gt;
&lt;blockquote readability=&quot;7&quot;&gt;
&lt;p&gt;比起南京，苏州更是寸草不生。&lt;/p&gt;
&lt;p&gt;苏州的互联网还是婴儿。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;苏州和南京，千年古城也，一省两强，明争暗斗，不分伯仲。&lt;/p&gt;
&lt;p&gt;而在当今的互联网浪潮中，它们距离第一梯队都太远，终于落后成了一对难兄难弟。&lt;/p&gt;
&lt;p&gt;数一数本地知名的互联网公司吧。南京有苏宁、途牛旅游、西祠胡同，苏州有同程旅游、蜗牛游戏、聚合数据。什么？这里有你不知道的？别抱怨了，再多数几家，你很可能也不认识（而我也数不出来）。&lt;/p&gt;
&lt;p&gt;这就是它们惨淡的互联网环境：没有巨头，小头公司不成气候，有的据说甚至遭到了 BAT 的嫌弃。&lt;/p&gt;
&lt;p&gt;哦，差点忘了。苏州还有一张突然空降来的王牌呢——360 安全公司，就是周鸿祎的那家呢。去年，经过一番眼花缭乱的操作，它竟变成了一家苏州的企业！&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://ww1.sinaimg.cn/large/68b02e3bgy1g2ha62b6zxj20xn0cawfm.jpg&quot;/&gt;&lt;/p&gt;
&lt;p&gt;不过，这就是个空壳罢了，像什么“ 霍尔果斯XXX影视公司 ”一样，资本面具而已。&lt;/p&gt;
&lt;p&gt;当然，有一些互联网巨头是真的入驻了苏州的，例如华为、阿里巴巴、百度、微软、IBM，初来时可能还提出过“打造 xxx，提升 xxx”的响亮口号。&lt;/p&gt;
&lt;p&gt;然而，它们派来的都不是互联网核心的业务，本着精明的商人心计，它们当然是来捞取政策红利与人才储备的，可不是来播撒互联网种子的。&lt;/p&gt;
&lt;p&gt;可话说回来，即便是有大资本来苏州吹出一个风口，它就能站对位置，就能被吹得起来么？&lt;/p&gt;
&lt;p&gt;苏州是否容得下互联网，能否发展好互联网呢？&lt;/p&gt;
&lt;h2 id=&quot;一座古城&quot;&gt;03 一座古城&lt;/h2&gt;
&lt;p&gt;从诸多方面来看，苏州都只是一座慢节奏的古城。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;它对互联网的很多新鲜事物都免疫。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;例如近两三年，共享单车群雄并起，但即便是在它们最激进的攻城略地时期，苏州也始终置身事外，不受战火纷扰。就我所见，只有极稀少的几辆小黄车，我一度怀疑它们是从周边城市偷渡进来的......&lt;/p&gt;
&lt;p&gt;苏州是最早实行“禁车令”的极少数大城市之一，当时我初来乍到，作为一个“苏漂”新人，我给苏州的评价是：&lt;strong&gt;不够开放包容，缺少冒险精神。&lt;/strong&gt; 这恰恰就是“互联网精神”的内核之一。&lt;/p&gt;
&lt;p&gt;但是如今再看，风光褪去的共享单车仿佛一场考验市民公德与揭露资本嘴脸的闹剧。苏州虽然没有感受到新物种的红利，却也躲过了它的反噬。&lt;/p&gt;
&lt;p&gt;实际上，苏州有自己的“公共自行车”系统，自 2010 年启动，有桩停车点覆盖了很多生活小区、交通站点、商业体和其它场所。政府投入了巨大的成本来推动 &lt;strong&gt;有序的&lt;/strong&gt; 绿色出行，成果显著，这大概也是“禁车令”的主要考虑吧。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://ww1.sinaimg.cn/large/68b02e3bgy1g2lxmize8uj20f00b9mz4.jpg&quot;/&gt;&lt;/p&gt;
&lt;p&gt;这座古城自有自己的发展规划，面对热闹的互联网诱惑，她倒是能“守身如玉”。&lt;/p&gt;
&lt;p&gt;共享单车或许还不够“互联网”，但其它的互联网风口也吹不动苏州。&lt;/p&gt;
&lt;p&gt;就看最近几年的大事件吧，在团购网站的“千团大战”、网约车的大战、以及直播与短视频的大战中，牌桌上可有苏州本土的企业呢？好像没有吧！这些可没有碰上“禁 X 令”。&lt;/p&gt;
&lt;p&gt;苏州严重依赖于第二产业，一直是上海制造业的转移地，但同时，金融与科技等第三产业想要在大上海的“黑洞”边发展，就太难了。&lt;/p&gt;
&lt;p&gt;苏州的高等教育严重落后，综合性大学仅有一家苏州大学（211，非985）。在最新发布的《武书连 2019 中国大学排行榜》中，苏州大学取得历史性最好排名 24 名，其它本地高校排名在 300 开外。&lt;/p&gt;
&lt;p&gt;造血能力不足，能少点被上海、南京和杭州吸血，就很不错了。&lt;/p&gt;
&lt;p&gt;苏州本地人喜欢安逸，享受着城市扩张的红利，持有多套房产坐收房租的大有人在。本地年轻人早早婚嫁，靠着啃老支付房贷车贷，拿着一份入不敷出的工资，也活得毫无压力。最后高房价不知吓软了多少外地人的腿。&lt;/p&gt;
&lt;p&gt;在地理空间上，苏州也是相对封闭的。坐拥 8000 多平方公里的土地以及 1000 万人口，它竟然没有建成一个机场。苏州与浙江省之间至今也没有直通的铁路，唯一相通的高速公路还是两车道的，阻碍了高效的跨省域协作。&lt;/p&gt;
&lt;p&gt;苏州就是这样一座古城，养老有余，拼搏不足，家底殷实，环境封闭。&lt;/p&gt;
&lt;p&gt;外地的互联网企业能走进来已然不错，本地互联网企业若想壮大走出去，则举步维艰。&lt;/p&gt;
&lt;p&gt;苏州本地成长起来最大的互联网公司是同程网，它于 2003 年上线，主营在线旅游代理业务，到 2010 年，其综合实力排名全国第三。然而到 2013 年，携程发起猛烈的价格战，同程被迫迎战，一个季度就烧掉了十年的利润，元气大伤。&lt;/p&gt;
&lt;p&gt;此后，BAT 纷纷入局，万达也成立万达旅业想分一杯羹，同程顿时陷入了危机重重的局面。&lt;/p&gt;
&lt;p&gt;最后它被资本招安，与艺龙合并。2018 年 11 月，同程艺龙在港股上市，如今第一大股东是腾讯，第二大股东是携程，公司注册地也变为了北京。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://ww1.sinaimg.cn/large/68b02e3bgy1g2lxorsaacj217o0kjnpd.jpg&quot;/&gt;&lt;/p&gt;
&lt;p&gt;苏州互联网企业发展之路的艰难，在同程的身上能看到一个缩影。&lt;/p&gt;
&lt;p&gt;苏州是互联网的荒漠，事实不容争辩。那么，它的未来出路在哪呢？&lt;/p&gt;
&lt;h2 id=&quot;苏州互联网的未来&quot;&gt;04 苏州互联网的未来&lt;/h2&gt;
&lt;p&gt;互联网已经深切地改变了我们的生活，智能手机的普及降低了人们“触网”的门槛。&lt;/p&gt;
&lt;p&gt;对于广大用户来说，互联网没有地域之分，人们根本不关心提供服务的是哪个地方的企业。&lt;/p&gt;
&lt;p&gt;不像购买手机时，有人会选择支持国产，互联网用户更在乎的是服务本身，而不在乎谁是提供者——哪家打车平台折扣大就用哪家、哪家外卖平台做活动就选哪家、哪家短视频更抓眼球就用哪家。平台间的迁移成本几乎为零，用户没有忠诚度可言。&lt;/p&gt;
&lt;p&gt;互联网公司相互比拼谁的市场占有率高，谁构建的护城河高，以规模优势打压和吞并竞争对手。强者更强，剩者为王。&lt;/p&gt;
&lt;p&gt;近年来兴风作浪的资本教育了大众两个词汇：烧钱与割韭菜。&lt;/p&gt;
&lt;p&gt;从这个视角来看，苏州是幸运的。用户要的是优质的互联网服务，至于它是不是由本地企业提供的，又有何区别的？把节省下来的钱用在实业上，不是更有意义么？&lt;/p&gt;
&lt;p&gt;寸有所长，尺有所短，苏州互联网的未来出路应该是：&lt;strong&gt;扬长补短，走出一条特色的苏州互联网道路。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;根据中国互联网络信息中心最新发布的《第43次中国互联网络发展状况统计报告》，网信独角兽企业出现极端的“贫富分化”——北上广浙占去 92.1%，其它省市仅有 7.9%。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://ww1.sinaimg.cn/large/68b02e3bgy1g2ltrjmiszj20ol0a8776.jpg&quot;/&gt;&lt;/p&gt;
&lt;p&gt;这说明了什么？除了这四地，&lt;strong&gt;全国其它地方都是互联网的荒漠啊！&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;苏州不是互联网强市，这没啥可否认的，但也不值得妄自菲薄。并不是非要夺得某个领域的互联网头把交椅，才有自尊与荣耀。&lt;/p&gt;
&lt;p&gt;都说现在是“互联网下半场”，人工智能、大数据、物联网、5G是未来的大趋势。怎么把这些技术与现有的工业基础相结合，这才是苏州最迫切的研究课题。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;消费互联网的红利将尽，工业互联网的时代即将来临。&lt;/strong&gt; 苏州的未来不是消费互联网，而是工业互联网。我国为了甩掉低端制造业的身份，逐年加码推动工业互联网的发展，这对苏州来说是极大的利好。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://ww1.sinaimg.cn/large/68b02e3bgy1g2lvbzlifyj21180byn4y.jpg&quot;/&gt;&lt;/p&gt;
&lt;p&gt;通过政策引导、资金补贴、规范标准、政府部署等一系列动作，苏州加快了工业互联网的建设。&lt;/p&gt;
&lt;p&gt;2016 年，由工业 4.0 俱乐部、中国工控网等单位主办，苏州召开了第一届“中国工业服务产业互联网大会”。2018 年，苏州成立了苏州市工业互联网产业联盟。&lt;/p&gt;
&lt;p&gt;苏州也开始跑起来了。也许不要几年，它的互联网局面将改善起来，像遍地的小绿车，在这片荒漠上长出一个活力四射的春天。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://ww1.sinaimg.cn/large/68b02e3bly1g2aiq1kpa8j21hc0nmgs4.jpg&quot;/&gt;&lt;/p&gt;
&lt;p&gt;公众号【&lt;strong&gt;Python猫&lt;/strong&gt;】， 本号连载优质的系列文章，有喵星哲学猫系列、Python进阶系列、好书推荐系列、技术写作、优质英文推荐与翻译等等，欢迎关注哦。后台回复“&lt;strong&gt;爱学习&lt;/strong&gt;”，免费获得一份学习大礼包。&lt;/p&gt;
</description>
<pubDate>Thu, 02 May 2019 13:05:00 +0000</pubDate>
<dc:creator>豌豆花下猫</dc:creator>
<og:description>我国互联网存在着巨大的地域性偏差，除了北上广深杭外，其它省市的互联网都很弱小。去年 8 月，某个公众号发布了一篇《上海不相信互联网》的文章，引起了多方的讨论。CSDN 公众号以此为契机，陆续发布了关于</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/pythonista/p/10803387.html</dc:identifier>
</item>
<item>
<title>基于.net core微服务（Consul、Ocelot、Docker、App.Metrics+InfluxDB+Grafana、Exceptionless、数据一致性、Jenkins） - 进击的辣条</title>
<link>http://www.cnblogs.com/wyt007/p/10631109.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/wyt007/p/10631109.html</guid>
<description>&lt;h2&gt;1、微服务简介&lt;/h2&gt;
&lt;p&gt;一种架构模式，提倡将单一应用程序划分成一组小的服务，服务之间互相协调、互相配合，为用户提供最终价值。每个服务运行在其独立的进程中，服务与服务间采用轻量级的通信机制互相沟通（RESTful API）。每个服务都围绕着具体的业务进行构建，并且能够被独立地部署到生产环境、类生产环境等。应尽量避免统一的、集中式的服管理机制，对具体的一个服务而言，应根据业务上下文，选择合适的语言、工具对其进行构建。 　　　　　　　　　　　　　　　　　　　　——马丁•福勒&lt;/p&gt;
&lt;h3&gt;1.1、.net core下的微服务构件&lt;/h3&gt;
&lt;ul&gt;&lt;li&gt;服务治理：Consul&lt;/li&gt;
&lt;li&gt;API网关：Ocelot&lt;/li&gt;
&lt;li&gt;作业调度：Quartz.NET,Hangfire&lt;/li&gt;
&lt;li&gt;分布式日志：Exceptionless&lt;/li&gt;
&lt;li&gt;ESB：Masstransit(RabbitMQ)&lt;/li&gt;
&lt;li&gt;APM：Metrac.App,Buttfly&lt;/li&gt;
&lt;/ul&gt;&lt;h3&gt;1.2、微架构&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/991704/201903/991704-20190331113046831-1623413271.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;h2&gt;2、Consul&lt;/h2&gt;
&lt;p&gt;http api官方文档地址：&lt;a href=&quot;https://www.consul.io/api/index.html&quot; target=&quot;_blank&quot;&gt;https://www.consul.io/api/index.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Api本地url: &lt;a href=&quot;http://localhost:8500/v1/agent/services&quot; target=&quot;_blank&quot;&gt;http://localhost:8500/v1/agent/services&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;2.1、Consul是什么&lt;/h3&gt;
&lt;p&gt;是一个服务管理软件。支持多数据中心下，分布式高可用的，服务发现和配置共享。consul支持&lt;strong&gt;健康检查&lt;/strong&gt;，&lt;strong&gt;允许存储键值对&lt;/strong&gt;。一致性协议采用 Raft 算法,用来保证服务的高可用。成员管理和消息广播 采用GOSSIP协议，支持ACL访问控制。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;服务注册&lt;/strong&gt;：一个服务将其位置信息在“中心注册节点”注册的过程。该服务一般会将它的主机IP地址以及端口号进行注册，有时也会有服务访问的认证信息，使用协议，版本号，以及关于环境的一些细节信息。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;服务发现&lt;/strong&gt;：服务发现可以让一个应用或者组件发现其运行环境以及其它应用或组件的信息。用户配置一个服务发现工具就可以将实际容器跟运行配置分离开。常见配置信息包括：ip、端口号、名称等。&lt;/p&gt;
&lt;h3&gt;2.2、述语&lt;/h3&gt;
&lt;ul readability=&quot;-0.5&quot;&gt;&lt;li readability=&quot;2&quot;&gt;Agent&lt;p&gt;&lt;span lang=&quot;EN-US&quot;&gt;Agent&lt;/span&gt;&lt;span&gt;是长期运行在每个&lt;span lang=&quot;EN-US&quot;&gt;consul&lt;/span&gt;集群成员节点上守护进程。通过命令&lt;span lang=&quot;EN-US&quot;&gt;consul agent&lt;/span&gt;启动。&lt;span lang=&quot;EN-US&quot;&gt;Agent&lt;/span&gt;有&lt;span lang=&quot;EN-US&quot;&gt;client&lt;/span&gt;和&lt;span lang=&quot;EN-US&quot;&gt;server&lt;/span&gt;两种模式。由于每个节点都必须运行&lt;span lang=&quot;EN-US&quot;&gt;agent&lt;/span&gt;，所有节点要么是&lt;span lang=&quot;EN-US&quot;&gt;client&lt;/span&gt;要么是&lt;span lang=&quot;EN-US&quot;&gt;server&lt;/span&gt;。所有的&lt;span lang=&quot;EN-US&quot;&gt;Agent&lt;/span&gt;都可以调用&lt;span lang=&quot;EN-US&quot;&gt;DNS&lt;/span&gt;或&lt;span lang=&quot;EN-US&quot;&gt;HTTP API&lt;/span&gt;，并负责检查和维护服务同步。&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;client&lt;br/&gt;　　运行client模式的Agent，将所有的RPCs转发到Server。Client是相对无状态的。Client唯一所做的是在后台参与LAN gossip pool。只消耗少量的资源，少量的网络带宽。&lt;/li&gt;
&lt;li&gt;Server&lt;br/&gt;　　运行Server模式的Agent，参与Raft quorum，维护集群的状态，响应RPC查询，与其他数据中心交互WAN gossip，转发查询到Leader或远程数据中心。&lt;/li&gt;
&lt;li&gt;Datacenter&lt;br/&gt;　　数据中心的定义似乎是显而易见的，有一些细节是必须考虑的。例如，在EC2，多个可用性区域是否被认为组成了单一的数据中心？我们定义数据中心是在同一个网络环境中——私有的，低延迟，高带宽。这不包括基于公共互联网环境，但是对于我们而言，在同一个EC2的多个可用性区域会被认为是一个的数据中心。&lt;/li&gt;
&lt;li&gt;Consensus&lt;br/&gt;　　当本系列文档中，consensus，意味着leader election协议，以及事务的顺序。由于这些事务是基于一个有限状态机，consensus的定义意味着复制状态机的一致性。&lt;/li&gt;
&lt;li&gt;Gossip&lt;br/&gt;　　consul是建立在Serf之上，提供了完成的Gossip协议，用于成员维护故障检测、事件广播。详细细节参见gossip documentation。这足以知道gossip是基于UDP协议实现随机的节点到节点的通信，主要是在UDP。&lt;/li&gt;
&lt;li&gt;LAN Gossip&lt;br/&gt;　　指的是LAN gossip pool，包含位于同一个局域网或者数据中心的节点。&lt;/li&gt;
&lt;li&gt;WAN Gossip&lt;br/&gt;　　指的是WAN gossip pool，只包含server节点，这些server主要分布在不同的数据中心或者通信是基于互联网或广域网的。&lt;/li&gt;
&lt;li&gt;RPC&lt;br/&gt;　　远程过程调用。是允许client请求服务器的请求/响应机制。&lt;/li&gt;
&lt;/ul&gt;&lt;h3&gt;2.3、部署结构图&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/991704/201903/991704-20190331120434947-1335806623.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;h3&gt;2.4、命令&lt;/h3&gt;
&lt;ul&gt;&lt;li&gt; -advertise&lt;br/&gt;通知展现地址用来改变我们给集群中的其他节点展现的地址，一般情况下-bind地址就是展现地址&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;-bootstrap&lt;/strong&gt;&lt;br/&gt;用来控制一个server是否在bootstrap模式，在一个datacenter中只能有一个server处于bootstrap模式，当一个server处于bootstrap模式时，可以自己选举为raft leader。  &lt;/li&gt;
&lt;li&gt;-bootstrap-expect&lt;br/&gt;在一个datacenter中期望提供的server节点数目，当该值提供的时候，consul一直等到达到指定sever数目的时候才会引导整个集群，该标记不能和bootstrap公用&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;-bind&lt;/strong&gt;&lt;br/&gt;该地址用来在集群内部的通讯，集群内的所有节点到地址都必须是可达的，默认是0.0.0.0&lt;/li&gt;
&lt;li&gt;-client&lt;br/&gt;consul绑定在哪个client地址上，这个地址提供HTTP、DNS、RPC等服务，默认是127.0.0.1&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;-config-file&lt;/strong&gt;&lt;br/&gt;明确的指定要加载哪个配置文件&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;-config-dir&lt;/strong&gt;&lt;br/&gt;配置文件目录，里面所有以.json结尾的文件都会被加载&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;-data-dir&lt;/strong&gt;&lt;br/&gt;提供一个目录用来存放agent的状态，所有的agent允许都需要该目录，该目录必须是稳定的，系统重启后都继续存在&lt;/li&gt;
&lt;li&gt;-datacenter&lt;br/&gt;该标记控制agent允许的datacenter的名称，默认是dc1&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;-encrypt&lt;/strong&gt;&lt;br/&gt;指定secret key，使consul在通讯时进行加密，key可以通过consul keygen生成，同一个集群中的节点必须使用相同的key&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;-join&lt;/strong&gt;&lt;br/&gt;加入一个已经启动的agent的ip地址，可以多次指定多个agent的地址。如果consul不能加入任何指定的地址中，则agent会启动失败，默认agent启动时不会加入任何节点。&lt;/li&gt;
&lt;li&gt;-retry-join&lt;br/&gt;和join类似，但是允许你在第一次失败后进行尝试。&lt;/li&gt;
&lt;li&gt;-retry-interval&lt;br/&gt;两次join之间的时间间隔，默认是30s&lt;/li&gt;
&lt;li&gt;-retry-max&lt;br/&gt;尝试重复join的次数，默认是0，也就是无限次尝试&lt;/li&gt;
&lt;li&gt;-log-level&lt;br/&gt;consul agent启动后显示的日志信息级别。默认是info，可选：trace、debug、info、warn、err。&lt;/li&gt;
&lt;li&gt;-node&lt;br/&gt;节点在集群中的名称，在一个集群中必须是唯一的，默认是该节点的主机名&lt;/li&gt;
&lt;li&gt;-protocol&lt;br/&gt;consul使用的协议版本&lt;/li&gt;
&lt;li&gt;-rejoin&lt;br/&gt;使consul忽略先前的离开，在再次启动后仍旧尝试加入集群中。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;-server&lt;/strong&gt;&lt;br/&gt;定义agent运行在server模式，每个集群至少有一个server，建议每个集群的server不要超过5个&lt;/li&gt;
&lt;li&gt;-syslog&lt;br/&gt;开启系统日志功能，只在linux/osx上生效&lt;/li&gt;
&lt;li&gt;-ui-dir&lt;br/&gt;提供存放web ui资源的路径，该目录必须是可读的&lt;/li&gt;
&lt;li&gt;-pid-file&lt;br/&gt;提供一个路径来存放pid文件，可以使用该文件进行SIGINT/SIGHUP(关闭/更新)agent&lt;/li&gt;
&lt;/ul&gt;&lt;h3&gt;2.5、常用API&lt;/h3&gt;
&lt;p&gt;consul的主要接口是RESTful HTTP API，该API可以用来增删查改nodes、services、checks、configguration。所有的endpoints主要分为以下类别：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;kv&lt;/strong&gt; - Key/Value存储&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;agent&lt;/strong&gt; - Agent控制&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;catalog&lt;/strong&gt; - 管理nodes和services&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;health&lt;/strong&gt; - 管理健康监测&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;session&lt;/strong&gt; - Session操作&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;acl&lt;/strong&gt; - ACL创建和管理&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;event&lt;/strong&gt; - 用户Events&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;status&lt;/strong&gt; - Consul系统状态&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;&lt;li readability=&quot;-0.5&quot;&gt;&lt;strong&gt;agent endpoints&lt;/strong&gt;：agent endpoints用来和本地agent进行交互，一般用来服务注册和检查注册，支持以下接口&lt;br/&gt;&lt;div class=&quot;cnblogs_code&quot; readability=&quot;35&quot;&gt;
&lt;pre&gt;
/v1/agent/&lt;span&gt;checks : 返回本地agent注册的所有检查(包括配置文件和HTTP接口)
&lt;/span&gt;/v1/agent/&lt;span&gt;services : 返回本地agent注册的所有 服务
&lt;/span&gt;/v1/agent/&lt;span&gt;members : 返回agent在集群的gossip pool中看到的成员
&lt;/span&gt;/v1/agent/&lt;span&gt;self : 返回本地agent的配置和成员信息
&lt;/span&gt;/v1/agent/join/&amp;lt;address&amp;gt;&lt;span&gt; : 触发本地agent加入node
&lt;/span&gt;/v1/agent/force-leave/&amp;lt;node&amp;gt;&amp;gt;&lt;span&gt;: 强制删除node
&lt;/span&gt;/v1/agent/check/&lt;span&gt;register : 在本地agent增加一个检查项，使用PUT方法传输一个json格式的数据
&lt;/span&gt;/v1/agent/check/deregister/&amp;lt;checkID&amp;gt;&lt;span&gt; : 注销一个本地agent的检查项
&lt;/span&gt;/v1/agent/check/pass/&amp;lt;checkID&amp;gt;&lt;span&gt; : 设置一个本地检查项的状态为passing
&lt;/span&gt;/v1/agent/check/warn/&amp;lt;checkID&amp;gt;&lt;span&gt; : 设置一个本地检查项的状态为warning
&lt;/span&gt;/v1/agent/check/fail/&amp;lt;checkID&amp;gt;&lt;span&gt; : 设置一个本地检查项的状态为critical
&lt;/span&gt;/v1/agent/service/&lt;span&gt;register : 在本地agent增加一个新的服务项，使用PUT方法传输一个json格式的数据
&lt;/span&gt;/v1/agent/service/deregister/&amp;lt;serviceID&amp;gt; : 注销一个本地agent的服务项
&lt;/pre&gt;&lt;/div&gt;
&lt;/li&gt;
&lt;li readability=&quot;1.5&quot;&gt;&lt;strong&gt;catalog endpoints&lt;/strong&gt;：catalog endpoints用来注册/注销nodes、services、checks&lt;br/&gt;&lt;div class=&quot;cnblogs_code&quot; readability=&quot;39&quot;&gt;
&lt;pre&gt;
/v1/catalog/register : Registers a &lt;span&gt;new&lt;/span&gt;&lt;span&gt; node, service, or check
&lt;/span&gt;/v1/catalog/&lt;span&gt;deregister : Deregisters a node, service, or check
&lt;/span&gt;/v1/catalog/&lt;span&gt;datacenters : Lists known datacenters
&lt;/span&gt;/v1/catalog/nodes : Lists nodes &lt;span&gt;in&lt;/span&gt;&lt;span&gt; a given DC
&lt;/span&gt;/v1/catalog/services : Lists services &lt;span&gt;in&lt;/span&gt;&lt;span&gt; a given DC
&lt;/span&gt;/v1/catalog/service/&amp;lt;service&amp;gt; : Lists the nodes &lt;span&gt;in&lt;/span&gt;&lt;span&gt; a given service
&lt;/span&gt;/v1/catalog/node/&amp;lt;node&amp;gt; : Lists the services provided by a node
&lt;/pre&gt;&lt;/div&gt;
&lt;/li&gt;
&lt;li readability=&quot;1.5&quot;&gt;&lt;strong&gt;health endpoints&lt;/strong&gt;：health endpoints用来查询健康状况相关信息，该功能从catalog中单独分离出来&lt;br/&gt;&lt;div class=&quot;cnblogs_code&quot; readability=&quot;39&quot;&gt;
&lt;pre&gt;
/v1/healt/node/&amp;lt;node&amp;gt;: 返回node所定义的检查，可用参数?dc=
/v1/health/checks/&amp;lt;service&amp;gt;: 返回和服务相关联的检查，可用参数?dc=
/v1/health/service/&amp;lt;service&amp;gt;&lt;span&gt;: 返回给定datacenter中给定node中service
&lt;/span&gt;/v1/health/state/&amp;lt;state&amp;gt;: 返回给定datacenter中指定状态的服务，state可以是&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;any&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;, &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;unknown&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;, &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;passing&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;, &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;warning&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;, or &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;critical&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;，可用参数?dc=
&lt;/pre&gt;&lt;/div&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;&lt;strong&gt;session endpoints&lt;/strong&gt;：session endpoints用来create、update、destory、query sessions&lt;br/&gt;&lt;div class=&quot;cnblogs_code&quot; readability=&quot;34&quot;&gt;
&lt;pre&gt;
/v1/session/create: Creates a &lt;span&gt;new&lt;/span&gt;&lt;span&gt; session
&lt;/span&gt;/v1/session/destroy/&amp;lt;session&amp;gt;&lt;span&gt;: Destroys a given session
&lt;/span&gt;/v1/session/info/&amp;lt;session&amp;gt;&lt;span&gt;: Queries a given session
&lt;/span&gt;/v1/session/node/&amp;lt;node&amp;gt;&lt;span&gt;: Lists sessions belonging to a node
&lt;/span&gt;/v1/session/list: Lists all the active sessions
&lt;/pre&gt;&lt;/div&gt;
&lt;/li&gt;
&lt;li readability=&quot;-0.5&quot;&gt;&lt;strong&gt;acl endpoints&lt;/strong&gt;：acl endpoints用来create、update、destory、query acl&lt;br/&gt;&lt;div class=&quot;cnblogs_code&quot; readability=&quot;35&quot;&gt;
&lt;pre&gt;
/v1/acl/create: Creates a &lt;span&gt;new&lt;/span&gt;&lt;span&gt; token with policy
&lt;/span&gt;/v1/acl/&lt;span&gt;update: Update the policy of a token
&lt;/span&gt;/v1/acl/destroy/&amp;lt;id&amp;gt;&lt;span&gt;: Destroys a given token
&lt;/span&gt;/v1/acl/info/&amp;lt;id&amp;gt;&lt;span&gt;: Queries the policy of a given token
&lt;/span&gt;/v1/acl/clone/&amp;lt;id&amp;gt;: Creates a &lt;span&gt;new&lt;/span&gt;&lt;span&gt; token by cloning an existing token
&lt;/span&gt;/v1/acl/list: Lists all the active tokens
&lt;/pre&gt;&lt;/div&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1.5&quot;&gt;&lt;strong&gt;event endpoints&lt;/strong&gt;：event endpoints用来fire新的events、查询已有的events&lt;br/&gt;&lt;div class=&quot;cnblogs_code&quot; readability=&quot;33&quot;&gt;
&lt;pre&gt;
/v1/&lt;span&gt;event&lt;/span&gt;/fire/&amp;lt;name&amp;gt;&lt;span&gt;: 触发一个新的event，用户event需要name和其他可选的参数，使用PUT方法
&lt;/span&gt;/v1/&lt;span&gt;event&lt;/span&gt;/list: 返回agent知道的events
&lt;/pre&gt;&lt;/div&gt;
&lt;/li&gt;
&lt;li readability=&quot;-2&quot;&gt;&lt;strong&gt;status endpoints&lt;/strong&gt;：status endpoints用来或者consul 集群的信息&lt;br/&gt;&lt;div class=&quot;cnblogs_code&quot; readability=&quot;32&quot;&gt;
&lt;pre&gt;
/v1/status/&lt;span&gt;leader : 返回当前集群的Raft leader
&lt;/span&gt;/v1/status/peers : 返回当前集群中同事
&lt;/pre&gt;&lt;/div&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;h3&gt;2.6、使用consul&lt;/h3&gt;
&lt;ul&gt;&lt;li readability=&quot;2&quot;&gt;启动&lt;br/&gt;语法：&lt;br/&gt;&lt;div class=&quot;cnblogs_code&quot; readability=&quot;33&quot;&gt;
&lt;pre&gt;
consul agent -server -datacenter=数据中心名称 -bootstrap -data-dir 数据存放路径 -config-file 配置文件路径 -ui-dir UI存放路径 -node=n1 -bind 本机IP
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;注册成Windows服务&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;34&quot;&gt;
&lt;pre&gt;
sc.exe create &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;Consul&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; binPath= &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;&lt;strong&gt;E:\Consul\consule.exe&lt;/strong&gt; agent -server -datacenter=数据中心名称 -bootstrap -data-dir 数据存放路径 -config-file 配置文件路径 -ui-dir UI存放路径 -node=n1 -bind 本机IP&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;示例：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;33&quot;&gt;
&lt;pre&gt;
consul agent -server -datacenter=dc1 -bootstrap -data-dir /tmp/consul -config-file ./conf -ui-dir ./dist -node=n1 -bind &lt;span&gt;127.0&lt;/span&gt;.&lt;span&gt;0.1&lt;/span&gt; 
&lt;/pre&gt;&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;查看集群成员&lt;br/&gt;&lt;div class=&quot;cnblogs_code&quot;&gt;
&lt;pre&gt;
consul members
&lt;/pre&gt;&lt;/div&gt;
&lt;/li&gt;
&lt;li readability=&quot;-2&quot;&gt;把192.168.1.126加入集群&lt;br/&gt;&lt;div class=&quot;cnblogs_code&quot; readability=&quot;32&quot;&gt;
&lt;pre&gt;
consul join &lt;span&gt;192.168&lt;/span&gt;.&lt;span&gt;1.126&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/li&gt;
&lt;li readability=&quot;-2&quot;&gt;查看节点raft信息&lt;br/&gt;&lt;div class=&quot;cnblogs_code&quot; readability=&quot;32&quot;&gt;
&lt;pre&gt;
consul &lt;span&gt;operator&lt;/span&gt; raft list-peers
&lt;/pre&gt;&lt;/div&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;h3&gt;2.7、项目实例&lt;/h3&gt;
&lt;ul readability=&quot;1.96699669967&quot;&gt;&lt;li&gt;项目准备&lt;br/&gt;项目地址：&lt;a href=&quot;https://github.com/786744873/HisMicroserviceSample&quot; target=&quot;_blank&quot;&gt;https://github.com/786744873/HisMicroserviceSample&lt;/a&gt;&lt;br/&gt;项目部署说明：分别部署 &lt;span class=&quot;cnblogs_code&quot;&gt;&lt;span&gt;192.168&lt;/span&gt;.&lt;span&gt;103.203&lt;/span&gt;&lt;/span&gt; 、 &lt;span class=&quot;cnblogs_code&quot;&gt;&lt;span&gt;192.168&lt;/span&gt;.&lt;span&gt;103.207&lt;/span&gt;&lt;/span&gt; 两台服务器&lt;br/&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/991704/201903/991704-20190331124446523-1276330235.png&quot; alt=&quot;&quot;/&gt;&lt;/li&gt;
&lt;li readability=&quot;22.5&quot;&gt;配置consul配置文件&lt;br/&gt;文件结构：&lt;br/&gt;&lt;div class=&quot;cnblogs_code&quot; readability=&quot;33&quot;&gt;
&lt;pre&gt;
&lt;span&gt;│  consul.exe
│  
├─conf
│      service.json
│      watchs.json
│      xacl.json
│      
├─data
├─dist&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;
&lt;span&gt;service.json（服务发现配置）：&lt;br/&gt;&lt;/span&gt;
&lt;/pre&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;59&quot;&gt;
&lt;pre&gt;
&lt;span&gt;{
    &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;encrypt&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;7TnJPB4lKtjEcCWWjN6jSA==&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;,    &lt;span&gt;//&lt;/span&gt;&lt;span&gt;加密秘钥&lt;/span&gt;
    &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;services&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;: [{
            &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;id&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;BasicsService&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;,    &lt;span&gt;//&lt;/span&gt;&lt;span&gt;服务id&lt;/span&gt;
            &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;name&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;BasicsService&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;,    &lt;span&gt;//&lt;/span&gt;&lt;span&gt;服务名称&lt;/span&gt;
            &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;tags&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: [&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;BasicsService&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;],    &lt;span&gt;//&lt;/span&gt;&lt;span&gt;服务标签&lt;/span&gt;
            &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;address&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: &lt;span&gt;&quot;&lt;/span&gt;&lt;strong&gt;&lt;span&gt;192.168.103.203&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&quot;&lt;/span&gt;,    &lt;span&gt;//&lt;/span&gt;&lt;span&gt;服务地址&lt;/span&gt;
            &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;port&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: &lt;span&gt;6801&lt;/span&gt;,    &lt;span&gt;//&lt;/span&gt;&lt;span&gt;端口&lt;/span&gt;
            &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;checks&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;: [{
                &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;id&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;BasicsServiceCheck&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;,    &lt;span&gt;//&lt;/span&gt;&lt;span&gt;检查id&lt;/span&gt;
                &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;name&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;BasicsServiceCheck&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;,    &lt;span&gt;//&lt;/span&gt;&lt;span&gt;检查名称&lt;/span&gt;
                &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;http&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;http://192.168.103.203:6801/health&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;,    &lt;span&gt;//&lt;/span&gt;&lt;span&gt;检车接口地址&lt;/span&gt;
                &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;interval&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;10s&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;,    &lt;span&gt;//&lt;/span&gt;&lt;span&gt;检查周期&lt;/span&gt;
                &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;tls_skip_verify&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: &lt;span&gt;false&lt;/span&gt;,    &lt;span&gt;//&lt;/span&gt;&lt;span&gt;跳过验证&lt;/span&gt;
                &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;method&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;GET&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;,    &lt;span&gt;//&lt;/span&gt;&lt;span&gt;检查请求方法&lt;/span&gt;
                &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;timeout&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;1s&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;    &lt;span&gt;//&lt;/span&gt;&lt;span&gt;请求超时时间&lt;/span&gt;
&lt;span&gt;            }]
        },
        {
            &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;id&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;InvoicingService&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;,    &lt;span&gt;//&lt;/span&gt;&lt;span&gt;服务id&lt;/span&gt;
            &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;name&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;InvoicingService&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;,    &lt;span&gt;//&lt;/span&gt;&lt;span&gt;服务名称&lt;/span&gt;
            &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;tags&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: [&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;InvoicingService&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;],    &lt;span&gt;//&lt;/span&gt;&lt;span&gt;服务标签&lt;/span&gt;
            &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;address&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: &lt;span&gt;&quot;&lt;/span&gt;&lt;strong&gt;&lt;span&gt;192.168.103.203&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&quot;&lt;/span&gt;,    &lt;span&gt;//&lt;/span&gt;&lt;span&gt;服务地址&lt;/span&gt;
            &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;port&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: &lt;span&gt;6802&lt;/span&gt;,    &lt;span&gt;//&lt;/span&gt;&lt;span&gt;端口&lt;/span&gt;
            &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;checks&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;: [{
                &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;id&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;InvoicingServiceCheck&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;,    &lt;span&gt;//&lt;/span&gt;&lt;span&gt;检查id&lt;/span&gt;
                &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;name&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;InvoicingServiceCheck&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;,    &lt;span&gt;//&lt;/span&gt;&lt;span&gt;检查名称&lt;/span&gt;
                &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;http&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;http://&lt;strong&gt;192.168.103.203&lt;/strong&gt;:6802/health&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;,    &lt;span&gt;//&lt;/span&gt;&lt;span&gt;检车接口地址&lt;/span&gt;
                &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;interval&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;10s&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;,    &lt;span&gt;//&lt;/span&gt;&lt;span&gt;检查周期&lt;/span&gt;
                &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;tls_skip_verify&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: &lt;span&gt;false&lt;/span&gt;,    &lt;span&gt;//&lt;/span&gt;&lt;span&gt;跳过验证&lt;/span&gt;
                &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;method&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;GET&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;,    &lt;span&gt;//&lt;/span&gt;&lt;span&gt;检查请求方法&lt;/span&gt;
                &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;timeout&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;1s&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;    &lt;span&gt;//&lt;/span&gt;&lt;span&gt;请求超时时间&lt;/span&gt;
&lt;span&gt;            }]
        }
    ]
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;
&lt;span&gt;watchs.json（服务监控配置）：&lt;br/&gt;&lt;/span&gt;
&lt;/pre&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;41&quot;&gt;
&lt;pre&gt;
&lt;span&gt;{
    &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;watches&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;: [{
        &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;type&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;checks&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;,    &lt;span&gt;//&lt;/span&gt;&lt;span&gt;监控触发类型&lt;/span&gt;
        &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;handler_type&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;http&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;,    &lt;span&gt;//&lt;/span&gt;&lt;span&gt;异常通知类型&lt;/span&gt;
        &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;state&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;critical&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;,    &lt;span&gt;//&lt;/span&gt;&lt;span&gt;监控触发状态&lt;/span&gt;
        &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;http_handler_config&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;: {
            &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;path&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;http://localhost:6801/notice&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;,    &lt;span&gt;//&lt;/span&gt;&lt;span&gt;通知地址&lt;/span&gt;
            &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;method&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;POST&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;,    &lt;span&gt;//&lt;/span&gt;&lt;span&gt;通知请求方式&lt;/span&gt;
            &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;timeout&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;10s&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;,    &lt;span&gt;//&lt;/span&gt;&lt;span&gt;通知超时时间&lt;/span&gt;
            &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;header&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;: {
                &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;Authorization&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: [&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJodHRwOi8vc2NoZW1hcy54bWxzb2FwLm9yZy93cy8yMDA1LzA1L2lkZW50aXR5L2NsYWltcy9uYW1lIjoiZ3N3IiwiaHR0cDovL3NjaGVtYXMubWljcm9zb2Z0LmNvbS93cy8yMDA4LzA2L2lkZW50aXR5L2NsYWltcy9yb2xlIjoiYWRtaW4iLCJodHRwOi8vc2NoZW1hcy5taWNyb3NvZnQuY29tL3dzLzIwMDgvMDYvaWRlbnRpdHkvY2xhaW1zL2V4cGlyYXRpb24iOiIyMDIyLzEyLzMxIDEyOjM2OjEyIiwibmJmIjoxNTE0Njk0OTcyLCJleHAiOjE1MTQ3MzA5NzIsImlzcyI6ImdzdyIsImF1ZCI6ImdzdyJ9.jPu1yZ8jORN5QgCuPV50sYOKvX88GLSDiRX_0fpEzU4&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;]
            }    &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;请求头&lt;/span&gt;
&lt;span&gt;        }
    }]
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/li&gt;
&lt;li readability=&quot;4&quot;&gt;分别启动 &lt;span class=&quot;cnblogs_code&quot;&gt;&lt;span&gt;192.168&lt;/span&gt;.&lt;span&gt;103.203&lt;/span&gt;&lt;/span&gt; 、 &lt;span class=&quot;cnblogs_code&quot;&gt;&lt;span&gt;192.168&lt;/span&gt;.&lt;span&gt;103.207&lt;/span&gt;&lt;/span&gt; 上的应用基础和进销存服务，然后再启动Consul，我们让 &lt;span class=&quot;cnblogs_code&quot;&gt;&lt;span&gt;192.168&lt;/span&gt;.&lt;span&gt;103.203&lt;/span&gt;&lt;/span&gt; 作为主Consul&lt;br/&gt;第一台service（192.168.103.203）：&lt;br/&gt;&lt;div class=&quot;cnblogs_code&quot; readability=&quot;33&quot;&gt;
&lt;pre&gt;
consul agent -server -datacenter=dc1 &lt;strong&gt;-bootstrap&lt;/strong&gt; -data-dir ./data -config-file ./conf -ui-dir ./dist -node=n1 -bind &lt;strong&gt;&lt;span&gt;192.168&lt;/span&gt;.&lt;span&gt;103.203&lt;/span&gt;&lt;/strong&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;第二台service（192.168.103.207）：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;33&quot;&gt;
&lt;pre&gt;
consul agent -server -datacenter=dc1 -data-dir ./data -config-file ./conf -ui-dir ./dist -node=n2 -bind &lt;strong&gt;&lt;span&gt;192.168&lt;/span&gt;.&lt;span&gt;103.207&lt;/span&gt;&lt;/strong&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;然后可以通过访问192.168.103.203:8500进入UI页面查看信息&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;1&quot;&gt;client&lt;br/&gt;&lt;div class=&quot;cnblogs_code&quot; readability=&quot;32&quot;&gt;
&lt;pre&gt;
consul agent -datacenter=dc1 -data-dir /tmp/consul -node cn1
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Mac OX系统，进入consul所在目录执行：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;32&quot;&gt;
&lt;pre&gt;
Sudo scp consul /usr/local/bin/
&lt;/pre&gt;&lt;/div&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;h3&gt;2.8、Consul DNS&lt;/h3&gt;
&lt;p&gt;DnsAgent.exe作为DNS工具&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;36&quot;&gt;
&lt;pre&gt;
&lt;span&gt;[
  {
  &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;Pattern&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;^.*\\.consul$&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;,
  &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;NameServer&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;127.0.0.1:8600&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;,
  &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;QueryTimeout&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: &lt;span&gt;1000&lt;/span&gt;&lt;span&gt;,
  &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;CompressionMutation&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: &lt;span&gt;false&lt;/span&gt;&lt;span&gt;
  }
]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;访问地址：http://服务名称.service.consul&lt;/p&gt;
&lt;h2&gt;3、Ocelot&lt;/h2&gt;
&lt;p&gt;github地址：&lt;a href=&quot;https://github.com/TomPallister/Ocelot&quot; target=&quot;_blank&quot;&gt;https://github.com/TomPallister/Ocelot&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Ocelot的目标是使用.NET运行微服务/面向服务架构，我们需要一个统一的入口进入我们的服务，提供监控、鉴权、负载均衡等机制，也可以通过编写中间件的形式，来扩展Ocelot的功能。  Ocelot是一堆特定顺序的中间件。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/991704/201903/991704-20190331134909278-11044504.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;h3&gt;3.1、Ocelot使用&lt;/h3&gt;
&lt;ul&gt;&lt;li&gt;安装Ocelot&lt;br/&gt;&lt;div class=&quot;cnblogs_code&quot;&gt;
&lt;pre&gt;
Install-Package Ocelot
&lt;/pre&gt;&lt;/div&gt;
&lt;/li&gt;
&lt;li readability=&quot;-0.5&quot;&gt;引入在Program.cs中加载配置文件&lt;br/&gt;&lt;div class=&quot;cnblogs_code&quot; readability=&quot;35&quot;&gt;
&lt;pre&gt;
&lt;span&gt;public&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; IWebHost BuildWebHost(&lt;span&gt;string&lt;/span&gt;&lt;span&gt;[] args)
{

    IWebHostBuilder builder &lt;/span&gt;= &lt;span&gt;new&lt;/span&gt;&lt;span&gt; WebHostBuilder();
    &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;注入WebHostBuilder&lt;/span&gt;
    &lt;span&gt;return&lt;/span&gt; builder.ConfigureServices(service =&amp;gt;&lt;span&gt;
    {
        service.AddSingleton(builder);
    })
        &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;加载configuration配置文人年&lt;/span&gt;
        .ConfigureAppConfiguration(conbuilder =&amp;gt;&lt;span&gt;
        {
            conbuilder.AddJsonFile(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;appsettings.json&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;);
            &lt;strong&gt;conbuilder.AddJsonFile(&lt;/strong&gt;&lt;/span&gt;&lt;strong&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;configuration.json&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;strong&gt;);&lt;/strong&gt;
        })
        .UseContentRoot(Directory.GetCurrentDirectory())
        .UseKestrel()
        .UseUrls(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;http://*:6800&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;)
        .UseStartup&lt;/span&gt;&amp;lt;Startup&amp;gt;&lt;span&gt;()
        .Build();
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/li&gt;
&lt;li readability=&quot;-0.5&quot;&gt;修改Startup.cs&lt;br/&gt;&lt;div class=&quot;cnblogs_code&quot; readability=&quot;35&quot;&gt;
&lt;pre&gt;
&lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt;&lt;span&gt; ConfigureServices(IServiceCollection services)
{       
    &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;注入配置文件&lt;/span&gt;
&lt;span&gt;    services.AddOcelot(Configuration);
}
&lt;/span&gt;&lt;span&gt;public&lt;/span&gt;  &lt;span&gt;void&lt;/span&gt;&lt;span&gt; Configure(IApplicationBuilder app, IHostingEnvironment env)
{
    &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;添加中间件&lt;/span&gt;
&lt;span&gt;    app.UseOcelot().Wait();
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/li&gt;
&lt;li readability=&quot;42.5&quot;&gt;创建配置文件（configuration.json）&lt;br/&gt;&lt;div class=&quot;cnblogs_code&quot; readability=&quot;121&quot;&gt;
&lt;pre&gt;
&lt;span&gt;{
  &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;ReRoutes&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: [    &lt;span&gt;//&lt;/span&gt;&lt;span&gt;路由配置&lt;/span&gt;
&lt;span&gt;    {
      &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;DownstreamPathTemplate&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;/{url}&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;,    &lt;span&gt;//&lt;/span&gt;&lt;span&gt;下游请求路由&lt;/span&gt;
      &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;DownstreamScheme&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;http&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;,    &lt;span&gt;//&lt;/span&gt;&lt;span&gt;下游请求方式，有http或https&lt;/span&gt;
      &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;DownstreamHostAndPorts&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: [    &lt;span&gt;//&lt;/span&gt;&lt;span&gt;下游请求的host和端口，为了配合负载均衡，可以配置多项&lt;/span&gt;
&lt;span&gt;        {
          &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;Host&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;localhost&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;,
          &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;Port&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: &lt;span&gt;6801&lt;/span&gt;&lt;span&gt;
        }
      ],
      &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;UpstreamPathTemplate&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;/basics/{url}&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;,    &lt;span&gt;//&lt;/span&gt;&lt;span&gt;上游请求路由&lt;/span&gt;
      &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;UpstreamHttpMethod&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: [ &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;Get&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;, &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;Post&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;, &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;Delete&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;, &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;Put&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; ],    &lt;span&gt;//&lt;/span&gt;&lt;span&gt;上游请求谓词
      &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;&quot;ServiceName&quot;: &quot;BasicsService&quot;,    &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;Consul中注册服务的名称
      &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;&quot;LoadBalancer&quot;: &quot;RoundRobin&quot;,    &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;负载均衡（可选）LeastConnection –请求空闲的Url  RoundRobin – 轮询请求  NoLoadBalance – 无负载均衡
      &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;&quot;UseServiceDiscovery&quot;: true,    &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;是否启用负载均衡&lt;/span&gt;
      &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;ReRouteIsCaseSensitive&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: &lt;span&gt;false&lt;/span&gt;,    &lt;span&gt;//
&lt;/span&gt;      &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;QoSOptions&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: {    &lt;span&gt;//&lt;/span&gt;&lt;span&gt;熔断设置（可选）&lt;/span&gt;
        &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;ExceptionsAllowedBeforeBreaking&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: &lt;span&gt;3&lt;/span&gt;,    &lt;span&gt;//&lt;/span&gt;&lt;span&gt;允许异常请求数&lt;/span&gt;
        &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;DurationOfBreak&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: &lt;span&gt;10&lt;/span&gt;,    &lt;span&gt;//&lt;/span&gt;&lt;span&gt;熔断时间，以秒为单位&lt;/span&gt;
        &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;TimeoutValue&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: &lt;span&gt;5000&lt;/span&gt;    &lt;span&gt;//&lt;/span&gt;&lt;span&gt;请求超时数，以毫秒为单位&lt;/span&gt;
&lt;span&gt;      },
      &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;HttpHandlerOptions&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: {    &lt;span&gt;//
&lt;/span&gt;        &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;AllowAutoRedirect&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: &lt;span&gt;false&lt;/span&gt;,    &lt;span&gt;//
&lt;/span&gt;        &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;UseCookieContainer&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: &lt;span&gt;false&lt;/span&gt;,    &lt;span&gt;//
&lt;/span&gt;        &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;UseTracing&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: &lt;span&gt;false&lt;/span&gt;    &lt;span&gt;//
&lt;/span&gt;&lt;span&gt;      },
      &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;AuthenticationOptions&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: {    &lt;span&gt;//
&lt;/span&gt;        &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;AuthenticationProviderKey&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: &lt;span&gt;&quot;&quot;&lt;/span&gt;,    &lt;span&gt;//
&lt;/span&gt;        &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;AllowedScopes&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: []    &lt;span&gt;//
&lt;/span&gt;&lt;span&gt;      },
      &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;RateLimitOptions&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: {    &lt;span&gt;//&lt;/span&gt;&lt;span&gt;限流设置（可选）&lt;/span&gt;
        &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;ClientWhitelist&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: [ &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;admin&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; ],    &lt;span&gt;//&lt;/span&gt;&lt;span&gt;白名单，不受限流控制的&lt;/span&gt;
        &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;EnableRateLimiting&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: &lt;span&gt;true&lt;/span&gt;,    &lt;span&gt;//&lt;/span&gt;&lt;span&gt;是否启用限流&lt;/span&gt;
        &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;Period&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;1m&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;,    &lt;span&gt;//&lt;/span&gt;&lt;span&gt;统计时间段：1s, 2m, 3h, 4d&lt;/span&gt;
        &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;PeriodTimespan&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: &lt;span&gt;15&lt;/span&gt;,    &lt;span&gt;//&lt;/span&gt;&lt;span&gt;间隔多少秒后可以重试&lt;/span&gt;
        &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;Limit&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: &lt;span&gt;100&lt;/span&gt;    &lt;span&gt;//&lt;/span&gt;&lt;span&gt;设定时间段内允许的最大请求数&lt;/span&gt;
&lt;span&gt;      }
    },
    {
      &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;DownstreamPathTemplate&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;/{url}&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;,
      &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;DownstreamScheme&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;http&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;,
      &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;DownstreamHostAndPorts&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;: [
        {
          &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;Host&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;localhost&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;,
          &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;Port&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: &lt;span&gt;6802&lt;/span&gt;&lt;span&gt;
        }
      ],
      &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;UpstreamPathTemplate&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;/invoicing/{url}&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;,
      &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;UpstreamHttpMethod&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: [ &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;Get&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;, &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;Post&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;, &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;Delete&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;, &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;Put&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt; ],
      &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;&quot;ServiceName&quot;: &quot;InvoicingService&quot;,
      &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;&quot;LoadBalancer&quot;: &quot;RoundRobin&quot;,
      &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;&quot;UseServiceDiscovery&quot;: true,&lt;/span&gt;
      &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;ReRouteIsCaseSensitive&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: &lt;span&gt;false&lt;/span&gt;&lt;span&gt;,
      &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;QoSOptions&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;: {
        &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;ExceptionsAllowedBeforeBreaking&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: &lt;span&gt;3&lt;/span&gt;&lt;span&gt;,
        &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;DurationOfBreak&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: &lt;span&gt;10&lt;/span&gt;&lt;span&gt;,
        &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;TimeoutValue&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: &lt;span&gt;5000&lt;/span&gt;&lt;span&gt;
      },
      &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;HttpHandlerOptions&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;: {
        &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;AllowAutoRedirect&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: &lt;span&gt;false&lt;/span&gt;&lt;span&gt;,
        &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;UseCookieContainer&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: &lt;span&gt;false&lt;/span&gt;&lt;span&gt;,
        &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;UseTracing&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: &lt;span&gt;false&lt;/span&gt;&lt;span&gt;
      },
      &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;AuthenticationOptions&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;: {
        &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;AuthenticationProviderKey&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: &lt;span&gt;&quot;&quot;&lt;/span&gt;&lt;span&gt;,
        &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;AllowedScopes&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;: []
      },
      &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;RateLimitOptions&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;: {
        &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;ClientWhitelist&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: [ &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;admin&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt; ],
        &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;EnableRateLimiting&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: &lt;span&gt;true&lt;/span&gt;&lt;span&gt;,
        &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;Period&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;1m&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;,
        &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;PeriodTimespan&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: &lt;span&gt;15&lt;/span&gt;&lt;span&gt;,
        &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;Limit&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: &lt;span&gt;100&lt;/span&gt;&lt;span&gt;
      }
    },
    {
      &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;DownstreamPathTemplate&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;/{url}&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;,
      &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;DownstreamScheme&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;http&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;,
      &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;DownstreamHostAndPorts&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;: [
        {
          &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;Host&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;localhost&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;,
          &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;Port&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: &lt;span&gt;6806&lt;/span&gt;&lt;span&gt;
        }
      ],
      &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;UpstreamPathTemplate&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;/authentication/{url}&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;,
      &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;UpstreamHttpMethod&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: [ &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;Get&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;, &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;Post&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;, &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;Delete&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;, &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;Put&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt; ],
      &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;&quot;ServiceName&quot;: &quot;AuthenticationService&quot;,
      &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;&quot;LoadBalancer&quot;: &quot;RoundRobin&quot;,
      &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;&quot;UseServiceDiscovery&quot;: true,&lt;/span&gt;
      &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;ReRouteIsCaseSensitive&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: &lt;span&gt;false&lt;/span&gt;&lt;span&gt;,
      &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;QoSOptions&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;: {
        &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;ExceptionsAllowedBeforeBreaking&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: &lt;span&gt;3&lt;/span&gt;&lt;span&gt;,
        &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;DurationOfBreak&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: &lt;span&gt;10&lt;/span&gt;&lt;span&gt;,
        &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;TimeoutValue&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: &lt;span&gt;5000&lt;/span&gt;&lt;span&gt;
      },
      &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;HttpHandlerOptions&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;: {
        &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;AllowAutoRedirect&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: &lt;span&gt;false&lt;/span&gt;&lt;span&gt;,
        &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;UseCookieContainer&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: &lt;span&gt;false&lt;/span&gt;&lt;span&gt;,
        &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;UseTracing&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: &lt;span&gt;false&lt;/span&gt;&lt;span&gt;
      },
      &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;AuthenticationOptions&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;: {
        &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;AuthenticationProviderKey&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: &lt;span&gt;&quot;&quot;&lt;/span&gt;&lt;span&gt;,
        &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;AllowedScopes&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;: []
      },
      &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;RateLimitOptions&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;: {
        &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;ClientWhitelist&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: [ &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;admin&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt; ],
        &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;EnableRateLimiting&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: &lt;span&gt;true&lt;/span&gt;&lt;span&gt;,
        &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;Period&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;1m&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;,
        &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;PeriodTimespan&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: &lt;span&gt;15&lt;/span&gt;&lt;span&gt;,
        &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;Limit&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: &lt;span&gt;100&lt;/span&gt;&lt;span&gt;
      }
    }

  ],
  &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;GlobalConfiguration&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: {    &lt;span&gt;//&lt;/span&gt;&lt;span&gt;全局设置&lt;/span&gt;
    &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;ServiceDiscoveryProvider&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: {&lt;span&gt;//Consul服务地址，用于上方的服务发现&lt;/span&gt;
      &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;Host&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;localhost&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;,
      &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;Port&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: &lt;span&gt;8500&lt;/span&gt;&lt;span&gt;
    },
    &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;RateLimitOptions&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: {    &lt;span&gt;//&lt;/span&gt;&lt;span&gt;全局限流设置（可选）&lt;/span&gt;
      &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;ClientIdHeader&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;clientid&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;,    &lt;span&gt;//&lt;/span&gt;&lt;span&gt;识别请求头，默认是 ClientId&lt;/span&gt;
      &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;QuotaExceededMessage&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;access is denied&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;,    &lt;span&gt;//&lt;/span&gt;&lt;span&gt;被限流后，当请求过载时返回的提示消息&lt;/span&gt;
      &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;HttpStatusCode&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;:     &lt;span&gt;//&lt;/span&gt;&lt;span&gt;600,当请求过载时返回的http状态码&lt;/span&gt;
      &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;DisableRateLimitHeaders&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: &lt;span&gt;false&lt;/span&gt;    &lt;span&gt;//&lt;/span&gt;&lt;span&gt;此值指定是否禁用X-Rate-Limit和Rety-After标头&lt;/span&gt;
&lt;span&gt;    }
  }
}&lt;/span&gt; 
&lt;/pre&gt;&lt;/div&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;h2&gt;4、Docker&lt;/h2&gt;
&lt;p&gt;容器是一个打包了应用服务的环境。它是一个轻量级的虚拟机，每一个容器由一组特定的应用和必要的依赖库组成。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/991704/201904/991704-20190407123203718-156144231.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;h3&gt;4.1、Docker-镜像常用命令 &lt;/h3&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;35&quot;&gt;
&lt;pre&gt;
docker images:查看本地镜像，docker images ubu*&lt;span&gt;，通配符查看
docker inspect ubuntu:查看镜像详细信息
docker search aspnetcore:搜索docker hub上符合要求的镜像
docker pull microsoft&lt;/span&gt;/&lt;span&gt;aspnetcore:拉取镜像，在run时不用从docker hub拉取
docker rmi 镜像ID1 镜像ID2：删除镜像ID1和ID2，如果强制删除加&lt;/span&gt;-f
&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;4.2、Docker-容器常用命令&lt;/h3&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;35&quot;&gt;
&lt;pre&gt;
docker create ubuntu:&lt;span&gt;14.04&lt;/span&gt;&lt;span&gt;：创建容器，处于停止状态
docker ps：查看运行的容器，加&lt;/span&gt;-a查看所有容器。加-l查询出最后创建的容器，加-n=&lt;span&gt;3查看最后创建的3个容器
docker start 容器名：运行已存在的容器
docker stop 容器名：停止容器
docker rm 容器名：删除容器，docker rm $(docker ps &lt;/span&gt;-a -&lt;span&gt;q)删除所有容器
docker run &lt;/span&gt;-i -t --name ubuntu14 ubuntu:&lt;span&gt;14.04&lt;/span&gt; /bin/bash：运行一个ubuntu14.04的，带终端的容器，名字叫ubuntu14 ，-i用于打开容器的标准输入，-&lt;span&gt;t让容器建立一个命令行终端
docker run &lt;/span&gt;--name back_ubuntu14 -d ubuntu:&lt;span&gt;14.04&lt;/span&gt; /bin/sh -c &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;while true;do echo hello world;sleep 1;done&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;：-&lt;span&gt;d是后台开容器
docker attach 容器名：依附容器
docker logs &lt;/span&gt;-f --tail=&lt;span&gt;5&lt;/span&gt;&lt;span&gt;  back_ubuntu14：查看最近的5条日志
docker top 容器名：查看容器进程 
docker inspect 容器名：查看容器信息，查看具体子项docker inspect &lt;/span&gt;--format=&lt;span&gt;'&lt;/span&gt;&lt;span&gt;{{.NetworkSettings.IPAddress}}&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;  back_ubuntu14
docker export 容器名 &lt;/span&gt;&amp;gt;&lt;span&gt;容器存储名称.tar：导出容器
win powershell下  docker export 容器ID &lt;/span&gt;-&lt;span&gt;o 名字.tar
docker import 容器存储名称.tar：导入镜像
docker commit &lt;/span&gt;-m=&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;abc&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; --author=&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;gsw&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; 容器ID  镜像名称：提交容器到本地镜像
&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;4.4、Docker-Dockerfile&lt;/h3&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;35&quot;&gt;
&lt;pre&gt;
&lt;span&gt;FROM：指定待扩展的父级镜像。除了注释外，在文件开头必须是一个FROM指令，接下来的指令便在这个父级镜像的环境中运行，直到遇到下一个FROM指令。通过添加多个FROM指令，可以在同一个Dockerfile文件中创建多个镜像。
MAINTAINER：用来声明创建的镜像的作都信息。非必需
RUN：用来修改镜像命令，常用来安装库、程序 以及配置程序。一条RUN指令执行完毕后，会在当前镜像上创建一个新的镜像层，接下来的指令会在新的镜像上继续执行。
EXPOSE：用来指明容器内进程对外开放的端口，多个端口之间使用空格隔开。运行容器时，通过参数&lt;/span&gt;-P(大写)即可将EXPOSE里所指定的端口映射到主机上国外的坠机端口，其队容器或主机就可以通过映射后的端口与此容器通信。同时，我们也可以通过-&lt;span&gt;p(小写)参数将Dockerfile中EXPOSE中没有的端口设置成公开的。
ADD：向新镜像中添加文件，这个文件可以是一个主机文件，也可以是一个网络文件，也可以是一个文件夹。
VOLUME：在镜像里创建一个指定路径的挂载点，这个路径可以来自主机或都其他容器。多个容器可以通过同一个挂载点共享数据，即便其中一个容器已经停止，挂载点也仍然可以访问，只有当挂载点的容器引用全部消失时，挂载点才会自动删除。
WORKDIR：为接下来执行的指令指定一个新的工作目录，这个目录可以是绝对目录，也可以是相对目录。
ENV：设置容器运行的环境变量。在运行容器的时候，通过&lt;/span&gt;-&lt;span&gt;e参数可以修改这个环境变量值 ，也可以添加新的环境变量
CMD：用来设置启动容器时默认运行的命令。
ENTRYPOINT：与CMD类似，它也是用来指定容器启动时默认运行的命令。
USER：为容器的运行及接下来RUN、CMD、ENTRYPOINT等指令的运行指定用户或UID
ONBUILD：触发指令。构建镜像的时候，Docker的镜像构建器会将所有的ONBUILD指令指定的命令保存到镜像的元数据中，这些命令在当前镜像的构建的构建过程中并不会执行。只有新的镜像用用FRMO指令指定父镜像为这个镜像时，便会触发。&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;4.5、Docker生成asp.net core镜像和运行&lt;/h3&gt;
&lt;p&gt;发布asp.net core项目，并在发布文件夹下创建Dockerfile文件，复制下面内容&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;35&quot;&gt;
&lt;pre&gt;
&lt;span&gt;#父镜像
FROM microsoft&lt;/span&gt;/&lt;span&gt;aspnetcore

#设置工作目录
WORKDIR &lt;/span&gt;/&lt;span&gt;app

#复制发布文件到&lt;/span&gt;/&lt;span&gt;app下
COPY . &lt;/span&gt;/&lt;span&gt;app

#设置端口
EXPOSE &lt;/span&gt;&lt;span&gt;80&lt;/span&gt;&lt;span&gt;

#使用dotnet XXXXXXXXX.dll来运行asp.net core项目，注意大小写
ENTRYPOINT [&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;dotnet&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;, “XXXXXXXXX.dll&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h4&gt;4.6、Docker生成asp.net core镜像和运行&lt;/h4&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;32&quot;&gt;
&lt;pre&gt;
docker build -&lt;span&gt;t xxxxxxxxxxx:latest .
docker run &lt;/span&gt;-it -p &lt;span&gt;6801&lt;/span&gt;:&lt;span&gt;6801&lt;/span&gt;  xxxxxxxxxxx:latest
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;注意：&lt;/strong&gt;docker内部web的端口， 上述命令中，第二个端口为docker内web的端口。&lt;/p&gt;
&lt;h2&gt;5、App.Metrics+InfluxDB+Grafana&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;建议：建议在网关上进行监控，因为网关上监控可以监控所有&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;App.Metrics：&lt;a href=&quot;https://www.app-metrics.io&quot; target=&quot;_blank&quot;&gt;https://www.app-metrics.io&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;InfluxDB1.5.1-1：&lt;a href=&quot;https://portal.influxdata.com&quot; target=&quot;_blank&quot;&gt;https://portal.influxdata.com&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Grafana-5.0.4：&lt;a href=&quot;https://grafana.com/get&quot; target=&quot;_blank&quot;&gt;https://grafana.com/get&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;5.1、安装使用&lt;/h3&gt;
&lt;ul&gt;&lt;li&gt;下载 influxdb&lt;br/&gt;&lt;a href=&quot;https://portal.influxdata.com&quot; target=&quot;_blank&quot;&gt;https://portal.influxdata.com&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;下载  Grafana&lt;br/&gt;&lt;a href=&quot;https://grafana.com/get&quot; target=&quot;_blank&quot;&gt;https://grafana.com/get&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;运行influxdb-版本号下的influxd.exe&lt;/li&gt;
&lt;li&gt;运行grafana-版本号下，bin目录下grafana-server.exe&lt;/li&gt;
&lt;li&gt;运行influxdb-版本号下的influx.exe，输入 &lt;span class=&quot;cnblogs_code&quot;&gt;create database influxdbtest&lt;/span&gt; 创建数据库，同时 &lt;span class=&quot;cnblogs_code&quot;&gt;create user &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;user1&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; with password &lt;span&gt;'&lt;/span&gt;&lt;span&gt;123456&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;/span&gt;  创建用户&lt;/li&gt;
&lt;li&gt;配置Grafana，然后启动网关程序，登录localhost:3000查看监控信息，用户名密码是：admin&lt;/li&gt;
&lt;/ul&gt;&lt;h3&gt;5.2、配置Grafana&lt;/h3&gt;
&lt;h4&gt;5.2.1、配置数据源&lt;/h4&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/991704/201904/991704-20190407153452671-33241260.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;h4&gt;5.2.2、配置Dashboard&lt;/h4&gt;
&lt;p&gt;我们采用模板导入模式，将项目引用 &lt;span class=&quot;cnblogs_code&quot;&gt;App.Metrics&lt;/span&gt; 并访问 &lt;span class=&quot;cnblogs_code&quot;&gt;App.Metrics&lt;/span&gt; 源地址：&lt;a href=&quot;https://www.app-metrics.io/&quot; target=&quot;_blank&quot;&gt;https://www.app-metrics.io/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/991704/201904/991704-20190407154203826-1001444478.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;获取到InfluxDB对应的仪表盘编号2125，然后输入使用该模板&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/991704/201904/991704-20190407154329933-1762067431.png&quot; alt=&quot;&quot; width=&quot;771&quot; height=&quot;429&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/991704/201904/991704-20190407154429651-705168606.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;导入成功后&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/991704/201904/991704-20190407154621267-575876501.png&quot; alt=&quot;&quot; width=&quot;787&quot; height=&quot;383&quot;/&gt;&lt;/p&gt;
&lt;h3&gt;5.3、App.Metrics监控数据采集&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/991704/201904/991704-20190407162117108-599766977.png&quot; alt=&quot;&quot; width=&quot;1369&quot; height=&quot;673&quot;/&gt;&lt;/p&gt;
&lt;h3&gt;5.4、APM-Grafana告警&lt;/h3&gt;
&lt;h2&gt;6、Exceptionless&lt;/h2&gt;
&lt;ul readability=&quot;2.7436708860759&quot;&gt;&lt;li&gt;在线方式&lt;br/&gt;&lt;a href=&quot;https://exceptionless.com/&quot; target=&quot;_blank&quot;&gt;https://exceptionless.com/&lt;/a&gt;注册用户，新建Organizations和Project，并选项目类型。&lt;/li&gt;
&lt;li readability=&quot;8.4114149821641&quot;&gt;离线方式&lt;p&gt;下载地址：&lt;a href=&quot;https://github.com/exceptionless/Exceptionless/releases&quot; target=&quot;_blank&quot;&gt;https://github.com/exceptionless/Exceptionless/releases&lt;/a&gt;&lt;br/&gt;解压压缩包，运行Start.bat&lt;br/&gt;系统会自动下载elasticsearch和kibana&lt;/p&gt;
&lt;p&gt;ElasticSearch是一个基于Lucene的搜索服务器。它提供了一个分布式多用户能力的全文搜索引擎，基于RESTful web接口。Elasticsearch是用Java开发的，并作为Apache许可条款下的开放源码发布，是当前流行的企业级搜索引擎。设计用于云计算中，能够达到实时搜索，稳定，可靠，快速，安装使用方便。&lt;/p&gt;
&lt;p&gt;Kibana是一个开源的分析与可视化平台，设计出来用于和Elasticsearch一起使用的。你可以用kibana搜索、查看、交互存放在Elasticsearch索引里的数据，使用各种不同的图表、表格、地图等kibana能够很轻易地展示高级数据分析与可视化。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;h3&gt;6.1、创建组织&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/991704/201904/991704-20190407220454363-1596043274.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;h3&gt;6.2、创建项目&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/991704/201904/991704-20190407220533665-1150476865.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;h3&gt;6.3、集成Exceptionless 客户端&lt;/h3&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;32&quot;&gt;
&lt;pre&gt;
Install-Package Exceptionless.AspNetCore
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;通过 API 密钥执行  &lt;span class=&quot;cnblogs_code&quot;&gt;app.UseExceptionless(&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;Qa3OzvEJC9FXo9SdwwFBv6bAkVbjWQKbV6hhtYEM&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;)&lt;/span&gt;  方法&lt;/p&gt;
&lt;h3&gt;6.4、示例代码&lt;/h3&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;53&quot;&gt;
&lt;pre&gt;
&lt;span&gt;#region&lt;/span&gt; Exceptionless测试
&lt;span&gt;try&lt;/span&gt;&lt;span&gt;
{
    ExceptionlessClient.Default.SubmitLog(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;调试Exceptionless.Logging.LogLevel.Debu&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;, Exceptionless.Logging.LogLevel.Debug);
    ExceptionlessClient.Default.SubmitLog(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;错误Exceptionless.Logging.LogLevel.Error&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;, Exceptionless.Logging.LogLevel.Error);
    ExceptionlessClient.Default.SubmitLog(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;大错Exceptionless.Logging.LogLevel.fatal&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;, Exceptionless.Logging.LogLevel.Fatal);
    ExceptionlessClient.Default.SubmitLog(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt; Exceptionless.Logging.LogLevel.Info&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;, Exceptionless.Logging.LogLevel.Info);
    ExceptionlessClient.Default.SubmitLog(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt; Exceptionless.Logging.LogLevel.Off&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;, Exceptionless.Logging.LogLevel.Off);
    ExceptionlessClient.Default.SubmitLog(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt; Exceptionless.Logging.LogLevel.Other&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;, Exceptionless.Logging.LogLevel.Other);
    ExceptionlessClient.Default.SubmitLog(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt; Exceptionless.Logging.LogLevel.Trace&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;, Exceptionless.Logging.LogLevel.Trace);
    ExceptionlessClient.Default.SubmitLog(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;Exceptionless.Logging.LogLevel.Warn&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;, Exceptionless.Logging.LogLevel.Warn);


    &lt;/span&gt;&lt;span&gt;var&lt;/span&gt; data = &lt;span&gt;new&lt;/span&gt;&lt;span&gt; Exceptionless.Models.DataDictionary();
    data.Add(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;data1key&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;, &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;data1value&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;);
    ExceptionlessClient.Default.SubmitEvent(&lt;/span&gt;&lt;span&gt;new&lt;/span&gt;&lt;span&gt; Exceptionless.Models.Event {
        Count &lt;/span&gt;= &lt;span&gt;1&lt;/span&gt;&lt;span&gt;,
        Date &lt;/span&gt;=&lt;span&gt; DateTime.Now,
        Data &lt;/span&gt;= data, Geo = &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;geo&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;,
        Message &lt;/span&gt;= &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;message&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;,
        ReferenceId &lt;/span&gt;= &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;referencelId&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;,
        Source &lt;/span&gt;= &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;source&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;,
        Tags &lt;/span&gt;= &lt;span&gt;new&lt;/span&gt; Exceptionless.Models.TagSet() { &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;tags&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt; },
        Type &lt;/span&gt;= &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;type&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;,
        Value &lt;/span&gt;= &lt;span&gt;1.2m&lt;/span&gt;&lt;span&gt; });
    ExceptionlessClient.Default.SubmitFeatureUsage(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;feature&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;);
    ExceptionlessClient.Default.SubmitNotFound(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;404 not found&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;);
    ExceptionlessClient.Default.SubmitException(&lt;/span&gt;&lt;span&gt;new&lt;/span&gt; Exception(&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;自定义异常&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;));

    &lt;/span&gt;&lt;span&gt;throw&lt;/span&gt; &lt;span&gt;new&lt;/span&gt; DivideByZeroException(&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;throw DivideByZeroException的异常：&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; +&lt;span&gt; DateTime.Now);
}
&lt;/span&gt;&lt;span&gt;catch&lt;/span&gt;&lt;span&gt; (Exception exc)
{
    exc.ToExceptionless().Submit();
}
&lt;/span&gt;&lt;span&gt;#endregion&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;6.5、本地部署&lt;/h3&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/exceptionless/Exceptionless/wiki/Self-Hosting&quot; target=&quot;_blank&quot;&gt;本地部署官方wiki&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;下载&lt;a href=&quot;https://github.com/exceptionless/Exceptionless/releases/download/v4.1.0/Exceptionless.4.1.2861.zip&quot; target=&quot;_blank&quot;&gt;Windows版本安装包&lt;/a&gt;，并进行解压，然后双击运行Start.bat即可&lt;/p&gt;
&lt;p&gt;需要环境：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;.NET 4.6&lt;/li&gt;
&lt;li&gt;Java 1.8+ (The JAVA_HOME environment variable must also be configured when using Windows.)&lt;/li&gt;
&lt;li&gt;IIS Express 8+&lt;/li&gt;
&lt;li&gt;PowerShell 3+&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/991704/201904/991704-20190408005959475-301678242.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;h3&gt;6.6、项目集成&lt;/h3&gt;
&lt;p&gt;注意：本地化不能再使用 &lt;span class=&quot;cnblogs_code&quot;&gt;app.UseExceptionless(apiKey: &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;tJxBWkCbgDLCMoKKqWII3Eyw4aJOsyOCgX26Yurm&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;);&lt;/span&gt; 形式来上传日志数据，应采用另外的方式：配置文件方式&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;38&quot;&gt;
&lt;pre&gt;
&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;Exceptionless&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;: {
  &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;ApiKey&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;tJxBWkCbgDLCMoKKqWII3Eyw4aJOsyOCgX26Yurm&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;,
  &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;ServerUrl&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;http://localhost:50000&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;,
  &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;DefaultData&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;: {
  },
  &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;DefaultTags&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: [ &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;xplat&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt; ],
  &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;Settings&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;: {
    &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;FeatureXYZEnabled&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: &lt;span&gt;false&lt;/span&gt;&lt;span&gt;
  }
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;然后修改 &lt;span class=&quot;cnblogs_code&quot;&gt;Startup.cs&lt;/span&gt; &lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;35&quot;&gt;
&lt;pre&gt;
&lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt;&lt;span&gt; Configure(IApplicationBuilder app, IHostingEnvironment env)
{
    ...
    &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;app.UseExceptionless(apiKey: &quot;tJxBWkCbgDLCMoKKqWII3Eyw4aJOsyOCgX26Yurm&quot;);
    &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;上方的方法本地化不适用&lt;/span&gt;
&lt;span&gt;    app.UseExceptionless(Configuration);
    ...
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;搞定&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/991704/201904/991704-20190408011048372-1289756004.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;h3&gt;6.7、查询语法&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/991704/201904/991704-20190408011210325-1643925285.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;示例&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/991704/201904/991704-20190408011304850-2139966505.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;h3&gt;6.8、常见问题&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/991704/201904/991704-20190408004614966-1563274955.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;Invoke-WebRequest : 请求被中止: 未能创建 SSL/TLS 安全通道。&lt;/p&gt;
&lt;p&gt;elasticsearch-XXX”，因为该路径不存在。&lt;/p&gt;
&lt;p&gt;解决方案：编辑Start-ElasticSearch.ps1，将所需的文件全部下载下来，然后解压进行拷贝，如下图，然后在双击运行Start.bat即可&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/991704/201904/991704-20190408004748705-118175774.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;帮助类：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; onclick=&quot;cnblogs_code_show('1e657255-c762-4929-89f1-731f5be44d66')&quot; readability=&quot;38.5&quot;&gt;&lt;img id=&quot;code_img_closed_1e657255-c762-4929-89f1-731f5be44d66&quot; class=&quot;code_img_closed&quot; src=&quot;https://images.cnblogs.com/OutliningIndicators/ContractedBlock.gif&quot; alt=&quot;&quot;/&gt;&lt;img id=&quot;code_img_opened_1e657255-c762-4929-89f1-731f5be44d66&quot; class=&quot;code_img_opened&quot; onclick=&quot;cnblogs_code_hide('1e657255-c762-4929-89f1-731f5be44d66',event)&quot; src=&quot;https://images.cnblogs.com/OutliningIndicators/ExpandedBlockStart.gif&quot; alt=&quot;&quot;/&gt;&lt;div id=&quot;cnblogs_code_open_1e657255-c762-4929-89f1-731f5be44d66&quot; class=&quot;cnblogs_code_hide&quot; readability=&quot;72&quot;&gt;
&lt;pre&gt;
&lt;span&gt;///&lt;/span&gt; &lt;span&gt;&amp;lt;summary&amp;gt;&lt;/span&gt;
&lt;span&gt;///&lt;/span&gt; 
&lt;span&gt;///&lt;/span&gt; &lt;span&gt;&amp;lt;/summary&amp;gt;&lt;/span&gt;
&lt;span&gt;public&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;&lt;span&gt; ExceptionLessLog
{
    &lt;/span&gt;&lt;span&gt;static&lt;/span&gt; &lt;span&gt;bool&lt;/span&gt; IsInit = &lt;span&gt;false&lt;/span&gt;&lt;span&gt;;

    &lt;/span&gt;&lt;span&gt;static&lt;/span&gt;&lt;span&gt; ExceptionLessLog()
    {
        &lt;/span&gt;&lt;span&gt;if&lt;/span&gt; (!&lt;span&gt;IsInit)
        {
            &lt;/span&gt;&lt;span&gt;#region&lt;/span&gt; Exceptionless配置&lt;span&gt;
            ExceptionlessClient.Default.Configuration.ApiKey &lt;/span&gt;= &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;KwqNUJ5njrnOehQTSYY6yXXXXXXXXXXXXXXX&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;;
            ExceptionlessClient.Default.Configuration.ServerUrl &lt;/span&gt;= &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;http://XXX.XXX.XXX.XXX:50000&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;;
            ExceptionlessClient.Default.Startup();
            &lt;/span&gt;&lt;span&gt;#endregion&lt;/span&gt;&lt;span&gt;
        }
    }

    &lt;/span&gt;&lt;span&gt;#region&lt;/span&gt; 日志功能
    &lt;span&gt;///&lt;/span&gt; &lt;span&gt;&amp;lt;summary&amp;gt;&lt;/span&gt;
    &lt;span&gt;///&lt;/span&gt;&lt;span&gt; 跟踪
    &lt;/span&gt;&lt;span&gt;///&lt;/span&gt; &lt;span&gt;&amp;lt;/summary&amp;gt;&lt;/span&gt;
    &lt;span&gt;public&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; Trace(&lt;span&gt;string&lt;/span&gt; message, &lt;span&gt;params&lt;/span&gt; &lt;span&gt;string&lt;/span&gt;&lt;span&gt;[] tags)
    {
        ExceptionlessClient.Default.CreateLog(message, LogLevel.Trace).AddTags(tags).Submit();
    }

    &lt;/span&gt;&lt;span&gt;///&lt;/span&gt; &lt;span&gt;&amp;lt;summary&amp;gt;&lt;/span&gt;
    &lt;span&gt;///&lt;/span&gt;&lt;span&gt; 调试
    &lt;/span&gt;&lt;span&gt;///&lt;/span&gt; &lt;span&gt;&amp;lt;/summary&amp;gt;&lt;/span&gt;
    &lt;span&gt;public&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; Debug(&lt;span&gt;string&lt;/span&gt; message, &lt;span&gt;params&lt;/span&gt; &lt;span&gt;string&lt;/span&gt;&lt;span&gt;[] tags)
    {
        ExceptionlessClient.Default.CreateLog(message, LogLevel.Debug).AddTags(tags).Submit();
    }

    &lt;/span&gt;&lt;span&gt;///&lt;/span&gt; &lt;span&gt;&amp;lt;summary&amp;gt;&lt;/span&gt;
    &lt;span&gt;///&lt;/span&gt;&lt;span&gt; 信息
    &lt;/span&gt;&lt;span&gt;///&lt;/span&gt; &lt;span&gt;&amp;lt;/summary&amp;gt;&lt;/span&gt;
    &lt;span&gt;public&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; Info(&lt;span&gt;string&lt;/span&gt; message, &lt;span&gt;params&lt;/span&gt; &lt;span&gt;string&lt;/span&gt;&lt;span&gt;[] tags)
    {
        ExceptionlessClient.Default.CreateLog(message, LogLevel.Info).AddTags(tags).Submit();
    }

    &lt;/span&gt;&lt;span&gt;///&lt;/span&gt; &lt;span&gt;&amp;lt;summary&amp;gt;&lt;/span&gt;
    &lt;span&gt;///&lt;/span&gt;&lt;span&gt; 警告
    &lt;/span&gt;&lt;span&gt;///&lt;/span&gt; &lt;span&gt;&amp;lt;/summary&amp;gt;&lt;/span&gt;
    &lt;span&gt;public&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; Warn(&lt;span&gt;string&lt;/span&gt; message, &lt;span&gt;params&lt;/span&gt; &lt;span&gt;string&lt;/span&gt;&lt;span&gt;[] tags)
    {
        ExceptionlessClient.Default.CreateLog(message, LogLevel.Warn).AddTags(tags).Submit();
    }

    &lt;/span&gt;&lt;span&gt;///&lt;/span&gt; &lt;span&gt;&amp;lt;summary&amp;gt;&lt;/span&gt;
    &lt;span&gt;///&lt;/span&gt;&lt;span&gt; 错误
    &lt;/span&gt;&lt;span&gt;///&lt;/span&gt; &lt;span&gt;&amp;lt;/summary&amp;gt;&lt;/span&gt;
    &lt;span&gt;public&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; Error(&lt;span&gt;string&lt;/span&gt; message, &lt;span&gt;params&lt;/span&gt; &lt;span&gt;string&lt;/span&gt;&lt;span&gt;[] tags)
    {
        ExceptionlessClient.Default.CreateLog(message, LogLevel.Error).AddTags(tags).Submit();
    }
    &lt;/span&gt;&lt;span&gt;#endregion&lt;/span&gt;

    &lt;span&gt;///&lt;/span&gt; &lt;span&gt;&amp;lt;summary&amp;gt;&lt;/span&gt;
    &lt;span&gt;///&lt;/span&gt;&lt;span&gt; 异常捕获提交
    &lt;/span&gt;&lt;span&gt;///&lt;/span&gt; &lt;span&gt;&amp;lt;/summary&amp;gt;&lt;/span&gt;
    &lt;span&gt;///&lt;/span&gt; &lt;span&gt;&amp;lt;param name=&quot;exception&quot;&amp;gt;&amp;lt;/param&amp;gt;&lt;/span&gt;
    &lt;span&gt;///&lt;/span&gt; &lt;span&gt;&amp;lt;param name=&quot;pluginContextData&quot;&amp;gt;&amp;lt;/param&amp;gt;&lt;/span&gt;
    &lt;span&gt;///&lt;/span&gt; &lt;span&gt;&amp;lt;param name=&quot;client&quot;&amp;gt;&amp;lt;/param&amp;gt;&lt;/span&gt;
    &lt;span&gt;public&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; Submit(&lt;span&gt;this&lt;/span&gt; Exception exception, ContextData pluginContextData = &lt;span&gt;null&lt;/span&gt;, ExceptionlessClient client = &lt;span&gt;null&lt;/span&gt;&lt;span&gt;)
    {
        exception.ToExceptionless().Submit();
    }
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;span class=&quot;cnblogs_code_collapse&quot;&gt;View Code&lt;/span&gt;&lt;/div&gt;
&lt;h2&gt;7、数据一致性&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/991704/201904/991704-20190408011528008-666282001.png&quot; alt=&quot;&quot; width=&quot;213&quot; height=&quot;204&quot;/&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;Ｃ：数据一致性(consistency)：如果系统对一个写操作返回成功，那么之后的读请求都必须读到这个新数据；如果返回失败，那么所有读操作都不能读到这个数据，对调用者而言数据具有强一致性(strong consistency) (又叫原子性 atomic、线性一致性 linearizable consistency)&lt;/li&gt;
&lt;li&gt;A：服务可用性(availability)：所有读写请求在一定时间内得到响应，可终止、不会一直等待&lt;/li&gt;
&lt;li&gt;P：分区容错性(partition-tolerance)：在网络分区的情况下，被分隔的节点仍能正常对外服务&lt;/li&gt;
&lt;/ul&gt;&lt;h3&gt;7.1、最终一致性&lt;/h3&gt;
&lt;ul&gt;&lt;li&gt;可用性，可靠性，&lt;/li&gt;
&lt;li&gt;最终一致性：在微服务之间使用事件驱动通信和发布订阅系统实现最终一致性&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/991704/201904/991704-20190408012540894-5823289.png&quot; alt=&quot;&quot; width=&quot;694&quot; height=&quot;243&quot;/&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;强一致性&lt;/strong&gt;：当更新操作完成之后，任何多个后续进程或者线程的访问都会返回最新的更新过的值。这种是对用户最友好的，就是用户上一次写什么，下一次就保证能读到什么。根据 CAP 理论，这种实现需要牺牲可用性。=&amp;gt; 在传统单体式应用中，大部分都是强一致性的应用，想想我们写过多少工作单元模式的Code？&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;弱一致性&lt;/strong&gt;：系统并不保证续进程或者线程的访问都会返回最新的更新过的值。系统在数据写入成功之后，不承诺立即可以读到最新写入的值，也不会具体的承诺多久之后可以读到。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;最终一致性&lt;/strong&gt;：弱一致性的特定形式。系统保证在没有后续更新的前提下，系统&lt;strong&gt;最终&lt;/strong&gt;返回上一次更新操作的值。在没有故障发生的前提下，不一致窗口的时间主要受通信延迟，系统负载和复制副本的个数影响。&lt;/li&gt;
&lt;li&gt;为保证可用性，互联网分布式架构中经常将&lt;strong&gt;强一致性需求&lt;/strong&gt;转换成&lt;strong&gt;最终一致性&lt;/strong&gt;的需求，并通过系统执行&lt;strong&gt;幂等性&lt;/strong&gt;的保证，保证数据的&lt;strong&gt;最终一致性&lt;/strong&gt;。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;　　在微服务架构中，各个微服务之间通常会使用事件驱动通信和发布订阅系统实现最终一致性。&lt;/p&gt;
&lt;h3&gt;7.2、最终一致性-补偿机制&lt;/h3&gt;
&lt;ul&gt;&lt;li&gt;Polly：实现重试，熔断机制&lt;/li&gt;
&lt;li&gt;或提供后台任务调度实现补偿&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/991704/201904/991704-20190408012651593-790150137.png&quot; alt=&quot;&quot; width=&quot;728&quot; height=&quot;216&quot;/&gt;&lt;/p&gt;
&lt;h3&gt;7.3、幂等和防重&lt;/h3&gt;
&lt;ul&gt;&lt;li&gt;其任意多次执行对资源本身所产生的影响均与一次执行的影响相同。&lt;/li&gt;
&lt;li&gt;对重复删除或返回成功结果；防重可以在数据库级别处理也以以在MQ级别&lt;/li&gt;
&lt;/ul&gt;&lt;h3&gt;7.4、MassTransit&lt;/h3&gt;
&lt;p&gt;MassTransit 是一个自由、开源、轻量级的消息总线, 用于使用. NET 框架创建分布式应用程序。MassTransit 在现有消息传输上提供了一组广泛的功能, 从而使开发人员能够友好地使用基于消息的会话模式异步连接服务。基于消息的通信是实现面向服务的体系结构的可靠和可扩展的方式。&lt;/p&gt;
&lt;p&gt;　　官网地址：&lt;a title=&quot;http://masstransit-project.com/&quot; href=&quot;http://masstransit-project.com/&quot; target=&quot;_blank&quot;&gt;http://masstransit-project.com/&lt;/a&gt;，GitHub地址：&lt;a href=&quot;https://github.com/MassTransit/MassTransit&quot; target=&quot;_blank&quot;&gt;https://github.com/MassTransit/MassTransit&lt;/a&gt; （目前：1590Star，719Fork）&lt;/p&gt;
&lt;p&gt;　　类似的国外开源组件还有&lt;a href=&quot;http://particular.net/&quot; target=&quot;_blank&quot;&gt;NServiceBus&lt;/a&gt;，没有用过，据说MassTransit比NServiceBus更加轻量级，并且在开发之初就选用了RabbitMQ作为消息传输组件，当然MassTransit还支持Azure Service Bus。类似的国内开源组件则有园友savorboard（杨晓东）的&lt;a href=&quot;https://www.cnblogs.com/savorboard/p/cap.html&quot; target=&quot;_blank&quot;&gt;CAP&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;7.5、最简单的发送/接收实例&lt;/h3&gt;
&lt;p&gt;这里以MassTransit + RabbitMQ为例子，首先请确保安装了RabbitMQ，如果没有安装，可以阅读我的&lt;a id=&quot;cb_post_title_url&quot; href=&quot;https://www.cnblogs.com/wyt007/p/9054608.html&quot;&gt;RabbitMQ在Windows环境下的安装与使用&lt;/a&gt;去把RabbitMQ先安装到你的电脑上。另外，RabbitMQ的背景知识也有一堆，有机会也还是要了解下Exchange，Channel、Queue等内容。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/991704/201904/991704-20190409000439976-316452160.png&quot; alt=&quot;&quot; width=&quot;476&quot; height=&quot;264&quot;/&gt;&lt;/p&gt;
&lt;h3&gt;7.6、一对一的发布/订阅实例（类似于RabbitMQ的工作模式）&lt;/h3&gt;
&lt;p&gt;除了简单的发送/接收模式外，我们用的更多的是发布/订阅这种模式。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;注意：发布方如果发布时没有订阅方，发布的数据将会丢失&lt;/strong&gt;&lt;/p&gt;
&lt;h3&gt;7.6、一对多的发布/订阅实例（队列名不同即可）&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/991704/201904/991704-20190409013202053-1315548363.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li readability=&quot;-1&quot;&gt; &lt;span class=&quot;cnblogs_code&quot;&gt;PSDemo_Entity&lt;/span&gt; 类库：准备需要传输的实体类信息&lt;br/&gt;&lt;div class=&quot;cnblogs_code&quot; readability=&quot;34&quot;&gt;
&lt;pre&gt;
&lt;span&gt;public&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;&lt;span&gt; EntityA
{
    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;string&lt;/span&gt; Name { &lt;span&gt;get&lt;/span&gt;; &lt;span&gt;set&lt;/span&gt;&lt;span&gt;; }

    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; DateTime Time { &lt;span&gt;get&lt;/span&gt;; &lt;span&gt;set&lt;/span&gt;&lt;span&gt;; }
}
&lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;&lt;span&gt; EntityB
{
    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;string&lt;/span&gt; Name { &lt;span&gt;get&lt;/span&gt;; &lt;span&gt;set&lt;/span&gt;&lt;span&gt;; }
    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; DateTime Time { &lt;span&gt;get&lt;/span&gt;; &lt;span&gt;set&lt;/span&gt;&lt;span&gt;; }
    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;int&lt;/span&gt; Age { &lt;span&gt;get&lt;/span&gt;; &lt;span&gt;set&lt;/span&gt;&lt;span&gt;; }
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/li&gt;
&lt;li readability=&quot;2&quot;&gt; &lt;span class=&quot;cnblogs_code&quot;&gt;PSDemo_Publisher&lt;/span&gt; ：发布消息&lt;br/&gt;&lt;div class=&quot;cnblogs_code&quot; readability=&quot;40&quot;&gt;
&lt;pre&gt;
&lt;span&gt;class&lt;/span&gt;&lt;span&gt; Program
{
    &lt;/span&gt;&lt;span&gt;static&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; Main(&lt;span&gt;string&lt;/span&gt;&lt;span&gt;[] args)
    {
       &lt;/span&gt;&lt;span&gt;var&lt;/span&gt; bus= Bus.Factory.CreateUsingRabbitMq(cfg =&amp;gt;&lt;span&gt;
        {
            &lt;/span&gt;&lt;span&gt;var&lt;/span&gt; host = cfg.Host(&lt;span&gt;new&lt;/span&gt; Uri(&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;rabbitmq://localhost/&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;), hst =&amp;gt;&lt;span&gt;
            {
                hst.Username(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;guest&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;);
                hst.Password(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;guest&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;);
            });               
        });
        &lt;/span&gt;&lt;span&gt;do&lt;/span&gt;&lt;span&gt;
        {
            Console.WriteLine(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;请出请按q,否则请按其他键！&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;);
            &lt;/span&gt;&lt;span&gt;string&lt;/span&gt; value =&lt;span&gt; Console.ReadLine();
            &lt;/span&gt;&lt;span&gt;if&lt;/span&gt; (value.ToLower() == &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;q&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;)
            {
                &lt;/span&gt;&lt;span&gt;break&lt;/span&gt;&lt;span&gt;;
            }

            bus.Publish(&lt;/span&gt;&lt;span&gt;new&lt;/span&gt; PSDemo_Entity.&lt;strong&gt;EntityA&lt;/strong&gt;() { Name=&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;张三&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;, Time =&lt;span&gt; DateTime.Now });
            bus.Publish(&lt;/span&gt;&lt;span&gt;new&lt;/span&gt; PSDemo_Entity.&lt;strong&gt;EntityB&lt;/strong&gt;() { Name = &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;李四&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;, Time = DateTime.Now,Age=&lt;span&gt;22&lt;/span&gt;&lt;span&gt; });
        }
        &lt;/span&gt;&lt;span&gt;while&lt;/span&gt; (&lt;span&gt;true&lt;/span&gt;&lt;span&gt;);        

        bus.Stop();
    }
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/li&gt;
&lt;li readability=&quot;1&quot;&gt; &lt;span class=&quot;cnblogs_code&quot;&gt;PSDemo_SubscriberA&lt;/span&gt; ：订阅EntityA和EntityB&lt;br/&gt;&lt;div class=&quot;cnblogs_code&quot; readability=&quot;38&quot;&gt;
&lt;pre&gt;
&lt;span&gt;class&lt;/span&gt;&lt;span&gt; Program
{
    &lt;/span&gt;&lt;span&gt;static&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; Main(&lt;span&gt;string&lt;/span&gt;&lt;span&gt;[] args)
    {
        Console.Title&lt;/span&gt;=&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;订阅者A&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;;

        &lt;/span&gt;&lt;span&gt;var&lt;/span&gt; bus= Bus.Factory.CreateUsingRabbitMq(cfg =&amp;gt;&lt;span&gt;
        {
            &lt;/span&gt;&lt;span&gt;var&lt;/span&gt; host = cfg.Host(&lt;span&gt;new&lt;/span&gt; Uri(&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;rabbitmq://localhost/&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;), hst =&amp;gt;&lt;span&gt;
            {
                hst.Username(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;guest&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;);
                hst.Password(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;guest&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;);
            });

            cfg.ReceiveEndpoint(host, &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;wytPSA&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;, e =&amp;gt;&lt;span&gt;
            {
                e.Consumer&lt;/span&gt;&amp;lt;&lt;span&gt;ConsumerA&lt;/span&gt;&amp;gt;&lt;span&gt;();
                e.Consumer&lt;/span&gt;&amp;lt;&lt;span&gt;ConsumerB&lt;/span&gt;&amp;gt;&lt;span&gt;();
            });
        });        

        bus.Start();        
        Console.ReadLine();
        bus.Stop();
    }
}
&lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;class&lt;/span&gt; ConsumerA : IConsumer&amp;lt;PSDemo_Entity.EntityA&amp;gt;&lt;span&gt;
{
    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;async&lt;/span&gt; Task Consume(ConsumeContext&amp;lt;PSDemo_Entity.EntityA&amp;gt;&lt;span&gt; context)
    {
        &lt;/span&gt;&lt;span&gt;await&lt;/span&gt; Console.Out.WriteLineAsync($&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;订阅者A  ConsumerA收到信息: {context.Message.Name}  {context.Message.Time} 类型：{context.Message.GetType()}&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;);
    }
}
&lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;class&lt;/span&gt; ConsumerB : IConsumer&amp;lt;PSDemo_Entity.EntityB&amp;gt;&lt;span&gt;
{
    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;async&lt;/span&gt; Task Consume(ConsumeContext&amp;lt;PSDemo_Entity.EntityB&amp;gt;&lt;span&gt; context)
    {
        &lt;/span&gt;&lt;span&gt;await&lt;/span&gt; Console.Out.WriteLineAsync($&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;订阅者A  ConsumerB收到信息: {context.Message.Name}  {context.Message.Time} 类型：{context.Message.GetType()}&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;);
    }
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/li&gt;
&lt;li readability=&quot;1&quot;&gt; &lt;span class=&quot;cnblogs_code&quot;&gt;PSDemo_SubscriberB&lt;/span&gt; ：订阅EntityA&lt;br/&gt;&lt;div class=&quot;cnblogs_code&quot; readability=&quot;38&quot;&gt;
&lt;pre&gt;
&lt;span&gt;class&lt;/span&gt;&lt;span&gt; Program
{
    &lt;/span&gt;&lt;span&gt;static&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; Main(&lt;span&gt;string&lt;/span&gt;&lt;span&gt;[] args)
    {
        Console.Title&lt;/span&gt;=&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;订阅者B&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;;

        &lt;/span&gt;&lt;span&gt;var&lt;/span&gt; bus = Bus.Factory.CreateUsingRabbitMq(cfg =&amp;gt;&lt;span&gt;
        {
            &lt;/span&gt;&lt;span&gt;var&lt;/span&gt; host = cfg.Host(&lt;span&gt;new&lt;/span&gt; Uri(&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;rabbitmq://localhost/&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;), hst =&amp;gt;&lt;span&gt;
            {
                hst.Username(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;guest&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;);
                hst.Password(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;guest&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;);
            });

            cfg.ReceiveEndpoint(host, &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;wytPSB&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;, e =&amp;gt;&lt;span&gt;
            {
                e.Consumer&lt;/span&gt;&amp;lt;&lt;span&gt;ConsumerA&lt;/span&gt;&amp;gt;&lt;span&gt;();
            });
        });

        bus.Start();     
        Console.ReadLine();
        bus.Stop();
    }
}
&lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;class&lt;/span&gt; ConsumerA : IConsumer&amp;lt;PSDemo_Entity.EntityA&amp;gt;&lt;span&gt;
{
    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;async&lt;/span&gt; Task Consume(ConsumeContext&amp;lt;PSDemo_Entity.EntityA&amp;gt;&lt;span&gt; context)
    {
        &lt;/span&gt;&lt;span&gt;await&lt;/span&gt; Console.Out.WriteLineAsync($&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;订阅者B  ConsumerA收到信息:  {context.Message.Name}  {context.Message.Time}  类型：{context.Message.GetType()}&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;);
    }
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;测试一下：启动PSDemo_SubscriberA和PSDemo_SubscriberB，一个PSDemo_Publisher&lt;br/&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/991704/201904/991704-20190409013808759-1749814257.png&quot; alt=&quot;&quot;/&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;h3&gt;7.7、带返回状态消息的示例&lt;/h3&gt;
&lt;p&gt;之前的例子都是发布之后，不管订阅者有没有收到以及收到后有没有处理成功（即有没有返回消息，类似于HTTP请求和响应），在MassTransit中提供了这样的一种模式，并且还可以结合GreenPipes的一些扩展方法实现重试、限流以及熔断机制。这一部分详见官方文档：&lt;a href=&quot;http://masstransit-project.com/MassTransit/usage/request-response.html&quot; target=&quot;_blank&quot;&gt;http://masstransit-project.com/MassTransit/usage/request-response.html&lt;/a&gt;&lt;/p&gt;
&lt;ol readability=&quot;-2&quot;&gt;&lt;li&gt;准备下图所示的三个项目：通过NuGet安装MassTransit以及MassTransit.RabbitMQ&lt;br/&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/991704/201905/991704-20190501131654874-1966926968.png&quot; alt=&quot;&quot;/&gt;&lt;/li&gt;
&lt;li readability=&quot;-0.5&quot;&gt;  &lt;span class=&quot;cnblogs_code&quot;&gt;RRDemo_Entity.Entity&lt;/span&gt; ：准备请求和响应的消息传输类型&lt;br/&gt;&lt;div class=&quot;cnblogs_code&quot; readability=&quot;35&quot;&gt;
&lt;pre&gt;
&lt;span&gt;public&lt;/span&gt; &lt;span&gt;interface&lt;/span&gt;&lt;span&gt; IRequestEntity
{
    &lt;/span&gt;&lt;span&gt;int&lt;/span&gt; ID { &lt;span&gt;get&lt;/span&gt;; &lt;span&gt;set&lt;/span&gt;&lt;span&gt;; }
    &lt;/span&gt;&lt;span&gt;string&lt;/span&gt; Name { &lt;span&gt;get&lt;/span&gt;; &lt;span&gt;set&lt;/span&gt;&lt;span&gt;; }
}
&lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;&lt;span&gt; RequestEntity : IRequestEntity
{
    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;int&lt;/span&gt; ID { &lt;span&gt;get&lt;/span&gt;; &lt;span&gt;set&lt;/span&gt;&lt;span&gt;; }
    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;string&lt;/span&gt; Name { &lt;span&gt;get&lt;/span&gt;; &lt;span&gt;set&lt;/span&gt;&lt;span&gt;; }
}

&lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;interface&lt;/span&gt;&lt;span&gt; IResponseEntity
{
    &lt;/span&gt;&lt;span&gt;int&lt;/span&gt; ID { &lt;span&gt;get&lt;/span&gt;; &lt;span&gt;set&lt;/span&gt;&lt;span&gt;; }
    &lt;/span&gt;&lt;span&gt;string&lt;/span&gt; Name { &lt;span&gt;get&lt;/span&gt;; &lt;span&gt;set&lt;/span&gt;&lt;span&gt;; }

    &lt;/span&gt;&lt;span&gt;int&lt;/span&gt; RequestID { &lt;span&gt;get&lt;/span&gt;; &lt;span&gt;set&lt;/span&gt;&lt;span&gt;; }
}
&lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;&lt;span&gt; ResponseEntity : IResponseEntity
{
    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;int&lt;/span&gt; ID { &lt;span&gt;get&lt;/span&gt;; &lt;span&gt;set&lt;/span&gt;&lt;span&gt;; }
    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;string&lt;/span&gt; Name { &lt;span&gt;get&lt;/span&gt;; &lt;span&gt;set&lt;/span&gt;&lt;span&gt;; }

    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;int&lt;/span&gt; RequestID { &lt;span&gt;get&lt;/span&gt;; &lt;span&gt;set&lt;/span&gt;&lt;span&gt;; }
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/li&gt;
&lt;li readability=&quot;3&quot;&gt; &lt;span class=&quot;cnblogs_code&quot;&gt;RRDemo_Server.Program&lt;/span&gt; 请求接收端&lt;br/&gt;&lt;div class=&quot;cnblogs_code&quot; readability=&quot;42&quot;&gt;
&lt;pre&gt;
&lt;span&gt;class&lt;/span&gt;&lt;span&gt; Program
{
    &lt;/span&gt;&lt;span&gt;static&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; Main(&lt;span&gt;string&lt;/span&gt;&lt;span&gt;[] args)
    {
        Console.Title &lt;/span&gt;= &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;应答方&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;;
        &lt;/span&gt;&lt;span&gt;var&lt;/span&gt; bus = Bus.Factory.CreateUsingRabbitMq(cfg =&amp;gt;&lt;span&gt;
        {
            &lt;/span&gt;&lt;span&gt;var&lt;/span&gt; host = cfg.Host(&lt;span&gt;new&lt;/span&gt; Uri(&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;rabbitmq://localhost/&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;), hst =&amp;gt;&lt;span&gt;
            {
                hst.Username(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;guest&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;);
                hst.Password(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;guest&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;);
            });
            cfg.ReceiveEndpoint(host, &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;request_response_wyt&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;, e =&amp;gt;&lt;span&gt;
            {
                e.Consumer&lt;/span&gt;&amp;lt;RequestConsumer&amp;gt;&lt;span&gt;();
            });
        });
        bus.Start();     
        Console.ReadLine();
        bus.Stop();
    }
}

&lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;class&lt;/span&gt; RequestConsumer : IConsumer&amp;lt;IRequestEntity&amp;gt;&lt;span&gt;
{
    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;async&lt;/span&gt; Task Consume(ConsumeContext&amp;lt;IRequestEntity&amp;gt;&lt;span&gt; context)
    {
        Console.ForegroundColor &lt;/span&gt;=&lt;span&gt; ConsoleColor.Red;
        &lt;/span&gt;&lt;span&gt;await&lt;/span&gt; Console.Out.WriteLineAsync($&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;收到请求id={context.Message.ID} name={context.Message.Name}&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;);
        Console.ResetColor();
        &lt;/span&gt;&lt;span&gt;var&lt;/span&gt; response = &lt;span&gt;new&lt;/span&gt;&lt;span&gt; ResponseEntity
        {
            ID &lt;/span&gt;= &lt;span&gt;22&lt;/span&gt;&lt;span&gt;,
            Name &lt;/span&gt;= $&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;李四&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;,
            RequestID &lt;/span&gt;=&lt;span&gt; context.Message.ID
        };
        Console.ForegroundColor &lt;/span&gt;=&lt;span&gt; ConsoleColor.Green;
        Console.WriteLine($&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;应答ID={response.ID},Name={response.Name},RequestID={response.RequestID}&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;);
        Console.ResetColor();
        context.Respond(response);
    }
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/li&gt;
&lt;li readability=&quot;4.5&quot;&gt; &lt;span class=&quot;cnblogs_code&quot;&gt;RRDemo_Client.Program&lt;/span&gt; 请求发送端&lt;br/&gt;&lt;div class=&quot;cnblogs_code&quot; readability=&quot;45&quot;&gt;
&lt;pre&gt;
&lt;span&gt;static&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; Main(&lt;span&gt;string&lt;/span&gt;&lt;span&gt;[] args)
{
    Console.Title &lt;/span&gt;= &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;请求方&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;;

    &lt;/span&gt;&lt;span&gt;var&lt;/span&gt; bus = Bus.Factory.CreateUsingRabbitMq(cfg =&amp;gt;&lt;span&gt;
    {
        &lt;/span&gt;&lt;span&gt;var&lt;/span&gt; host = cfg.Host(&lt;span&gt;new&lt;/span&gt; Uri(&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;rabbitmq://localhost/&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;), hst =&amp;gt;&lt;span&gt;
        {
            hst.Username(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;guest&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;);
            hst.Password(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;guest&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;);
        });
        &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;重试&lt;/span&gt;
        cfg.UseRetry(ret =&amp;gt;&lt;span&gt;
        {
            ret.Interval(&lt;/span&gt;&lt;span&gt;3&lt;/span&gt;, &lt;span&gt;10&lt;/span&gt;);&lt;span&gt;//&lt;/span&gt;&lt;span&gt; 消费失败后重试3次，每次间隔10s&lt;/span&gt;
&lt;span&gt;        });
        &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;限流&lt;/span&gt;
        cfg.UseRateLimit(&lt;span&gt;1000&lt;/span&gt;, TimeSpan.FromSeconds(&lt;span&gt;100&lt;/span&gt;));&lt;span&gt;//&lt;/span&gt;&lt;span&gt; 1分钟以内最多1000次调用访问
        &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;熔断&lt;/span&gt;
        cfg.UseCircuitBreaker(cb =&amp;gt;&lt;span&gt;
        {
            cb.TrackingPeriod &lt;/span&gt;= TimeSpan.FromSeconds(&lt;span&gt;60&lt;/span&gt;);&lt;span&gt;//&lt;/span&gt;&lt;span&gt;1分钟&lt;/span&gt;
            cb.TripThreshold = &lt;span&gt;15&lt;/span&gt;;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; 当失败的比例至少达到15%才会启动熔断&lt;/span&gt;
            cb.ActiveThreshold = &lt;span&gt;10&lt;/span&gt;;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; 当失败次数至少达到10次才会启动熔断&lt;/span&gt;
            cb.ResetInterval = TimeSpan.FromMinutes(&lt;span&gt;5&lt;/span&gt;);&lt;span&gt;//&lt;/span&gt;&lt;span&gt; 当在1分钟内消费失败率达到15%或调用了10次还是失败时，暂停5分钟的服务访问&lt;/span&gt;
&lt;span&gt;
        });
    });
    bus.Start();

    &lt;/span&gt;&lt;span&gt;var&lt;/span&gt; serviceAddress = &lt;span&gt;new&lt;/span&gt; Uri($&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;rabbitmq://localhost/request_response_wyt&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;);
    &lt;/span&gt;&lt;span&gt;var&lt;/span&gt; client = bus.CreateRequestClient&amp;lt;IRequestEntity, IResponseEntity&amp;gt;(serviceAddress, TimeSpan.FromHours(&lt;span&gt;10&lt;/span&gt;&lt;span&gt;));
    &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; 创建请求客户端，10H之内木有回馈则认为是超时(Timeout)&lt;/span&gt;

    &lt;span&gt;while&lt;/span&gt; (&lt;span&gt;true&lt;/span&gt;&lt;span&gt;)
    {
        Console.WriteLine(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;请出请按q,否则请按其他键！&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;);
        &lt;/span&gt;&lt;span&gt;string&lt;/span&gt; value =&lt;span&gt; Console.ReadLine();
        &lt;/span&gt;&lt;span&gt;if&lt;/span&gt; (value.ToLower() == &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;q&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;)
        {
            &lt;/span&gt;&lt;span&gt;break&lt;/span&gt;&lt;span&gt;;
        }

        Task.Run(&lt;/span&gt;&lt;span&gt;async&lt;/span&gt; () =&amp;gt;&lt;span&gt;
        {
            &lt;/span&gt;&lt;span&gt;var&lt;/span&gt; request = &lt;span&gt;new&lt;/span&gt; RequestEntity() { ID = &lt;span&gt;1&lt;/span&gt;, Name = &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;张三&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt; };
            &lt;/span&gt;&lt;span&gt;var&lt;/span&gt; response = &lt;span&gt;await&lt;/span&gt;&lt;span&gt; client.Request(request);

            Console.WriteLine($&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;请求ID={request.ID},Name={request.Name}&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;);
            Console.WriteLine($&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;应签ID={response.ID},Name={response.Name},RequestID={response.RequestID}&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;);
        }).Wait();
    }

}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;效果展示&lt;br/&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/991704/201905/991704-20190501133231897-1780492713.png&quot; alt=&quot;&quot;/&gt;&lt;p&gt;&lt;strong&gt;注意&lt;/strong&gt;：这里的请求方关闭后应答方则无法将应答再回复给请求方，会丢失&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;&lt;h3&gt;7.8、带Observer模式的发布/订阅示例&lt;/h3&gt;
&lt;p&gt;在某些场景中，我们需要针对一个消息进行类似于AoP（面向切面编程）或者监控的操作，比如在发送消息之前和结束后记日志等操作，我们可以借助MassTransit中的Observer模式来实现。（在MassTransit的消息接收中，可以通过两种模式来实现：一种是基于实现IConsumer接口，另一种就是基于实现IObserver接口）关于这一部分，详见官方文档：&lt;a href=&quot;http://masstransit-project.com/MassTransit/usage/observers.html&quot; target=&quot;_blank&quot;&gt;http://masstransit-project.com/MassTransit/usage/observers.html&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;准备以下图所示的项目：&lt;br/&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/991704/201905/991704-20190502121321435-190168354.png&quot; alt=&quot;&quot;/&gt;&lt;/li&gt;
&lt;li readability=&quot;6&quot;&gt; &lt;span class=&quot;cnblogs_code&quot;&gt;ObserverSubscriber&lt;/span&gt; &lt;br/&gt;&lt;div class=&quot;cnblogs_code&quot; readability=&quot;48&quot;&gt;
&lt;pre&gt;
&lt;span&gt;class&lt;/span&gt;&lt;span&gt; Program
{
    &lt;/span&gt;&lt;span&gt;static&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; Main(&lt;span&gt;string&lt;/span&gt;&lt;span&gt;[] args)
    {
        Console.Title &lt;/span&gt;= &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;订阅方&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;;
        &lt;/span&gt;&lt;span&gt;var&lt;/span&gt; bus = Bus.Factory.CreateUsingRabbitMq(cfg =&amp;gt;&lt;span&gt;
        {
            &lt;/span&gt;&lt;span&gt;var&lt;/span&gt; host = cfg.Host(&lt;span&gt;new&lt;/span&gt; Uri(&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;rabbitmq://localhost/&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;), hst =&amp;gt;&lt;span&gt;
            {
                hst.Username(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;guest&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;);
                hst.Password(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;guest&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;);
            });
            cfg.ReceiveEndpoint(host, &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;ObserverTest&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;, e =&amp;gt;&lt;span&gt;
            {
                e.Consumer&lt;/span&gt;&amp;lt;EntityConsumer&amp;gt;&lt;span&gt;();
            });
        });
        &lt;/span&gt;&lt;span&gt;var&lt;/span&gt; observer = &lt;span&gt;new&lt;/span&gt;&lt;span&gt; ReceiveObserver();
        &lt;/span&gt;&lt;span&gt;var&lt;/span&gt; handle =&lt;span&gt; bus.ConnectReceiveObserver(observer);
        bus.Start();
        Console.ReadLine();
        bus.Stop();
    }
}
&lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;&lt;span&gt; ReceiveObserver : IReceiveObserver
{
    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt;&lt;span&gt; Task PreReceive(ReceiveContext context)
    {

        Console.WriteLine(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;------------------PreReceive--------------------&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;);
        Console.WriteLine(Encoding.Default.GetString(context.GetBody()));
        Console.WriteLine(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;--------------------------------------&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;);
        &lt;/span&gt;&lt;span&gt;return&lt;/span&gt;&lt;span&gt; Task.CompletedTask;
    }

    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt;&lt;span&gt; Task PostReceive(ReceiveContext context)
    {
    
        Console.WriteLine(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;-----------------PostReceive---------------------&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;);
        Console.WriteLine(Encoding.Default.GetString(context.GetBody()));
        Console.WriteLine(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;--------------------------------------&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;);
        &lt;/span&gt;&lt;span&gt;return&lt;/span&gt;&lt;span&gt; Task.CompletedTask;
    }

    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; Task PostConsume&amp;lt;T&amp;gt;(ConsumeContext&amp;lt;T&amp;gt; context, TimeSpan duration, &lt;span&gt;string&lt;/span&gt;&lt;span&gt; consumerType)
        &lt;/span&gt;&lt;span&gt;where&lt;/span&gt; T : &lt;span&gt;class&lt;/span&gt;&lt;span&gt;
    {
   
        Console.WriteLine(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;------------------PostConsume--------------------&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;);
        Console.WriteLine($&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;ID={ (context.Message as Entity).ID},Name={(context.Message as Entity).Name},Time={(context.Message as Entity).Time}&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;);
        Console.WriteLine(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;--------------------------------------&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;);
        &lt;/span&gt;&lt;span&gt;return&lt;/span&gt;&lt;span&gt; Task.CompletedTask;
    }

    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; Task ConsumeFault&amp;lt;T&amp;gt;(ConsumeContext&amp;lt;T&amp;gt; context, TimeSpan elapsed, &lt;span&gt;string&lt;/span&gt; consumerType, Exception exception) &lt;span&gt;where&lt;/span&gt; T : &lt;span&gt;class&lt;/span&gt;&lt;span&gt;
    {
     
        Console.WriteLine(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;-----------------ConsumeFault---------------------&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;);
        Console.WriteLine($&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;ID={ (context.Message as Entity).ID},Name={(context.Message as Entity).Name},Time={(context.Message as Entity).Time}&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;);
        Console.WriteLine(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;--------------------------------------&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;);
        &lt;/span&gt;&lt;span&gt;return&lt;/span&gt;&lt;span&gt; Task.CompletedTask;
    }

    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt;&lt;span&gt; Task ReceiveFault(ReceiveContext context, Exception exception)
    {            
        Console.WriteLine(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;----------------ReceiveFault----------------------&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;);
        Console.WriteLine(Encoding.Default.GetString(context.GetBody()));
        Console.WriteLine(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;--------------------------------------&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;);
        &lt;/span&gt;&lt;span&gt;return&lt;/span&gt;&lt;span&gt; Task.CompletedTask;
    }
}


&lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;class&lt;/span&gt; EntityConsumer : IConsumer&amp;lt;Entity&amp;gt;&lt;span&gt;
{
    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;async&lt;/span&gt; Task Consume(ConsumeContext&amp;lt;Entity&amp;gt;&lt;span&gt; context)
    {
        &lt;/span&gt;&lt;span&gt;await&lt;/span&gt; Console.Out.WriteLineAsync($&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;IEntityConsumer 类型 {context.Message.GetType()} {context.Message.ID} {context.Message.Age} {context.Message.Name} {context.Message.Time}&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;);

    }
}

&lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;&lt;span&gt; Entity
{
    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;int&lt;/span&gt; ID { &lt;span&gt;get&lt;/span&gt;; &lt;span&gt;set&lt;/span&gt;&lt;span&gt;; }

    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;int&lt;/span&gt; Age { &lt;span&gt;get&lt;/span&gt;; &lt;span&gt;set&lt;/span&gt;&lt;span&gt;; }
    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;string&lt;/span&gt; Name { &lt;span&gt;get&lt;/span&gt;; &lt;span&gt;set&lt;/span&gt;&lt;span&gt;; }
    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; DateTime Time { &lt;span&gt;get&lt;/span&gt;; &lt;span&gt;set&lt;/span&gt;&lt;span&gt;; }

}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/li&gt;
&lt;li readability=&quot;9&quot;&gt; &lt;span class=&quot;cnblogs_code&quot;&gt;ObserverPublish&lt;/span&gt; &lt;br/&gt;&lt;div class=&quot;cnblogs_code&quot; readability=&quot;54&quot;&gt;
&lt;pre&gt;
&lt;span&gt;class&lt;/span&gt;&lt;span&gt; Program
{
    &lt;/span&gt;&lt;span&gt;static&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; Main(&lt;span&gt;string&lt;/span&gt;&lt;span&gt;[] args)
    {
        Console.Title &lt;/span&gt;= &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;发布方&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;;

        &lt;/span&gt;&lt;span&gt;var&lt;/span&gt; bus = Bus.Factory.CreateUsingRabbitMq(cfg =&amp;gt;&lt;span&gt;
        {
            &lt;/span&gt;&lt;span&gt;var&lt;/span&gt; host = cfg.Host(&lt;span&gt;new&lt;/span&gt; Uri(&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;rabbitmq://localhost&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;), hst =&amp;gt;&lt;span&gt;
            {
                hst.Username(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;guest&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;);
                hst.Password(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;guest&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;);
            });

        });
        &lt;/span&gt;&lt;span&gt;var&lt;/span&gt; observer = &lt;span&gt;new&lt;/span&gt;&lt;span&gt; SendObserver();
        &lt;/span&gt;&lt;span&gt;var&lt;/span&gt; handle =&lt;span&gt; bus.ConnectSendObserver(observer);

        &lt;/span&gt;&lt;span&gt;var&lt;/span&gt; observer1 = &lt;span&gt;new&lt;/span&gt;&lt;span&gt; PublishObserver();
        &lt;/span&gt;&lt;span&gt;var&lt;/span&gt; handle1 =&lt;span&gt; bus.ConnectPublishObserver(observer1);
        bus.Start();
        &lt;/span&gt;&lt;span&gt;do&lt;/span&gt;&lt;span&gt;
        {
            Console.WriteLine(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;请出请按q,否则请按其他键！&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;);

            &lt;/span&gt;&lt;span&gt;string&lt;/span&gt; value =&lt;span&gt; Console.ReadLine();

            &lt;/span&gt;&lt;span&gt;if&lt;/span&gt; (value.ToLower() == &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;q&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;)
            {
                &lt;/span&gt;&lt;span&gt;break&lt;/span&gt;&lt;span&gt;;
            }

            bus.Publish(&lt;/span&gt;&lt;span&gt;new&lt;/span&gt; Entity() { ID = &lt;span&gt;1&lt;/span&gt;, Age = &lt;span&gt;10&lt;/span&gt;, Name = &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;张三&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;, Time =&lt;span&gt; DateTime.Now });
        }
        &lt;/span&gt;&lt;span&gt;while&lt;/span&gt; (&lt;span&gt;true&lt;/span&gt;&lt;span&gt;);

        bus.Stop();
    }
}

&lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;&lt;span&gt; PublishObserver : IPublishObserver
{
    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; Task PrePublish&amp;lt;T&amp;gt;(PublishContext&amp;lt;T&amp;gt;&lt;span&gt; context)
        &lt;/span&gt;&lt;span&gt;where&lt;/span&gt; T : &lt;span&gt;class&lt;/span&gt;&lt;span&gt;
    {
        Console.WriteLine(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;------------------PrePublish--------------------&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;);
        Console.WriteLine($&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;ID={ (context.Message as Entity).ID},Name={(context.Message as Entity).Name},Time={(context.Message as Entity).Time}&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;);
        Console.WriteLine(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;--------------------------------------&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;);
        &lt;/span&gt;&lt;span&gt;return&lt;/span&gt;&lt;span&gt; Task.CompletedTask;
    }

    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; Task PostPublish&amp;lt;T&amp;gt;(PublishContext&amp;lt;T&amp;gt;&lt;span&gt; context)
        &lt;/span&gt;&lt;span&gt;where&lt;/span&gt; T : &lt;span&gt;class&lt;/span&gt;&lt;span&gt;
    {
        Console.WriteLine(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;------------------PostPublish--------------------&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;);
        Console.WriteLine($&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;ID={ (context.Message as Entity).ID},Name={(context.Message as Entity).Name},Time={(context.Message as Entity).Time}&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;);
        Console.WriteLine(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;--------------------------------------&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;);
        &lt;/span&gt;&lt;span&gt;return&lt;/span&gt;&lt;span&gt; Task.CompletedTask;
    }

    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; Task PublishFault&amp;lt;T&amp;gt;(PublishContext&amp;lt;T&amp;gt;&lt;span&gt; context, Exception exception)
        &lt;/span&gt;&lt;span&gt;where&lt;/span&gt; T : &lt;span&gt;class&lt;/span&gt;&lt;span&gt;
    {
        Console.WriteLine(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;------------------PublishFault--------------------&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;);
        Console.WriteLine($&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;ID={ (context.Message as Entity).ID},Name={(context.Message as Entity).Name},Time={(context.Message as Entity).Time}&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;);
        Console.WriteLine(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;--------------------------------------&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;);
        &lt;/span&gt;&lt;span&gt;return&lt;/span&gt;&lt;span&gt; Task.CompletedTask;
    }
}

&lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;&lt;span&gt; SendObserver : ISendObserver
{
    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; Task PreSend&amp;lt;T&amp;gt;(SendContext&amp;lt;T&amp;gt;&lt;span&gt; context)
        &lt;/span&gt;&lt;span&gt;where&lt;/span&gt; T : &lt;span&gt;class&lt;/span&gt;&lt;span&gt;
    {
        Console.WriteLine(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;------------------PreSend--------------------&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;);
        Console.WriteLine($&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;ID={ (context.Message as Entity).ID},Name={(context.Message as Entity).Name},Time={(context.Message as Entity).Time}&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;);
        Console.WriteLine(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;--------------------------------------&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;);
        &lt;/span&gt;&lt;span&gt;return&lt;/span&gt;&lt;span&gt; Task.CompletedTask;
    }

    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; Task PostSend&amp;lt;T&amp;gt;(SendContext&amp;lt;T&amp;gt;&lt;span&gt; context)
        &lt;/span&gt;&lt;span&gt;where&lt;/span&gt; T : &lt;span&gt;class&lt;/span&gt;&lt;span&gt;
    {
        Console.WriteLine(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;------------------PostSend--------------------&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;);
        Console.WriteLine($&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;ID={ (context.Message as Entity).ID},Name={(context.Message as Entity).Name},Time={(context.Message as Entity).Time}&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;);
        Console.WriteLine(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;--------------------------------------&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;);
        &lt;/span&gt;&lt;span&gt;return&lt;/span&gt;&lt;span&gt; Task.CompletedTask;
    }

    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; Task SendFault&amp;lt;T&amp;gt;(SendContext&amp;lt;T&amp;gt;&lt;span&gt; context, Exception exception)
        &lt;/span&gt;&lt;span&gt;where&lt;/span&gt; T : &lt;span&gt;class&lt;/span&gt;&lt;span&gt;
    {
        Console.WriteLine(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;------------------SendFault--------------------&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;);
        Console.WriteLine($&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;ID={ (context.Message as Entity).ID},Name={(context.Message as Entity).Name},Time={(context.Message as Entity).Time}&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;);
        Console.WriteLine(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;--------------------------------------&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;);
        &lt;/span&gt;&lt;span&gt;return&lt;/span&gt;&lt;span&gt; Task.CompletedTask;
    }
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;效果展示&lt;br/&gt;Publish:&lt;br/&gt;&lt;div class=&quot;cnblogs_code&quot; onclick=&quot;cnblogs_code_show('9c4dfe94-168b-48c5-9c19-d909f2923a79')&quot; readability=&quot;37.5&quot;&gt;&lt;img id=&quot;code_img_closed_9c4dfe94-168b-48c5-9c19-d909f2923a79&quot; class=&quot;code_img_closed&quot; src=&quot;https://images.cnblogs.com/OutliningIndicators/ContractedBlock.gif&quot; alt=&quot;&quot;/&gt;&lt;img id=&quot;code_img_opened_9c4dfe94-168b-48c5-9c19-d909f2923a79&quot; class=&quot;code_img_opened&quot; onclick=&quot;cnblogs_code_hide('9c4dfe94-168b-48c5-9c19-d909f2923a79',event)&quot; src=&quot;https://images.cnblogs.com/OutliningIndicators/ExpandedBlockStart.gif&quot; alt=&quot;&quot;/&gt;&lt;div id=&quot;cnblogs_code_open_9c4dfe94-168b-48c5-9c19-d909f2923a79&quot; class=&quot;cnblogs_code_hide&quot; readability=&quot;70&quot;&gt;
&lt;pre&gt;
&lt;span&gt;请出请按q,否则请按其他键！
&lt;/span&gt;&lt;span&gt;111111&lt;/span&gt;&lt;span&gt;
请出请按q,否则请按其他键！
&lt;/span&gt;------------------PrePublish--------------------&lt;span&gt;
ID&lt;/span&gt;=&lt;span&gt;1&lt;/span&gt;,Name=张三,Time=&lt;span&gt;2019&lt;/span&gt;/&lt;span&gt;5&lt;/span&gt;/&lt;span&gt;2&lt;/span&gt; &lt;span&gt;12&lt;/span&gt;:&lt;span&gt;23&lt;/span&gt;:&lt;span&gt;23&lt;/span&gt;
--------------------------------------
------------------PreSend--------------------&lt;span&gt;
ID&lt;/span&gt;=&lt;span&gt;1&lt;/span&gt;,Name=张三,Time=&lt;span&gt;2019&lt;/span&gt;/&lt;span&gt;5&lt;/span&gt;/&lt;span&gt;2&lt;/span&gt; &lt;span&gt;12&lt;/span&gt;:&lt;span&gt;23&lt;/span&gt;:&lt;span&gt;23&lt;/span&gt;
--------------------------------------
------------------PostSend--------------------&lt;span&gt;
ID&lt;/span&gt;=&lt;span&gt;1&lt;/span&gt;,Name=张三,Time=&lt;span&gt;2019&lt;/span&gt;/&lt;span&gt;5&lt;/span&gt;/&lt;span&gt;2&lt;/span&gt; &lt;span&gt;12&lt;/span&gt;:&lt;span&gt;23&lt;/span&gt;:&lt;span&gt;23&lt;/span&gt;
--------------------------------------
------------------PostPublish--------------------&lt;span&gt;
ID&lt;/span&gt;=&lt;span&gt;1&lt;/span&gt;,Name=张三,Time=&lt;span&gt;2019&lt;/span&gt;/&lt;span&gt;5&lt;/span&gt;/&lt;span&gt;2&lt;/span&gt; &lt;span&gt;12&lt;/span&gt;:&lt;span&gt;23&lt;/span&gt;:&lt;span&gt;23&lt;/span&gt;
--------------------------------------
&lt;/pre&gt;&lt;/div&gt;
&lt;span class=&quot;cnblogs_code_collapse&quot;&gt;View Code&lt;/span&gt;&lt;/div&gt;
Subscribe:&lt;br/&gt;&lt;div class=&quot;cnblogs_code&quot; onclick=&quot;cnblogs_code_show('32ba736c-3126-43e4-ae3f-ea63ab5a83ab')&quot; readability=&quot;51.5&quot;&gt;&lt;img id=&quot;code_img_closed_32ba736c-3126-43e4-ae3f-ea63ab5a83ab&quot; class=&quot;code_img_closed&quot; src=&quot;https://images.cnblogs.com/OutliningIndicators/ContractedBlock.gif&quot; alt=&quot;&quot;/&gt;&lt;img id=&quot;code_img_opened_32ba736c-3126-43e4-ae3f-ea63ab5a83ab&quot; class=&quot;code_img_opened&quot; onclick=&quot;cnblogs_code_hide('32ba736c-3126-43e4-ae3f-ea63ab5a83ab',event)&quot; src=&quot;https://images.cnblogs.com/OutliningIndicators/ExpandedBlockStart.gif&quot; alt=&quot;&quot;/&gt;&lt;div id=&quot;cnblogs_code_open_32ba736c-3126-43e4-ae3f-ea63ab5a83ab&quot; class=&quot;cnblogs_code_hide&quot; readability=&quot;98&quot;&gt;
&lt;pre&gt;
------------------PreReceive--------------------&lt;span&gt;
{
  &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;messageId&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;36500000-a632-9828-3029-08d6ceb5ea32&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;,
  &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;conversationId&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;36500000-a632-9828-ef7f-08d6ceb5ea37&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;,
  &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;sourceAddress&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;rabbitmq://localhost/bus-DESKTOP-PUOA6D7-dotnet-g3eyyyfggkcnt4wdbdmc7pxgn4?durable=false&amp;amp;autodelete=true&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;,
  &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;destinationAddress&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;rabbitmq://localhost/ObserverSubscriber:Entity&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;,
  &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;messageType&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;: [
    &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;urn:message:ObserverSubscriber:Entity&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;
  ],
  &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;message&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;: {
    &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;id&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: &lt;span&gt;1&lt;/span&gt;&lt;span&gt;,
    &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;age&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: &lt;span&gt;10&lt;/span&gt;&lt;span&gt;,
    &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;name&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;张三&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;,
    &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;time&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;2019-05-02T12:23:23.2223222+08:00&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;
  },
  &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;sentTime&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;2019-05-02T04:23:23.3522586Z&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;,
  &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;headers&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;: {},
  &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;host&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;: {
    &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;machineName&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;DESKTOP-PUOA6D7&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;,
    &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;processName&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;dotnet&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;,
    &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;processId&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: &lt;span&gt;25668&lt;/span&gt;&lt;span&gt;,
    &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;assembly&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;ObserverPublish&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;,
    &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;assemblyVersion&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;1.0.0.0&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;,
    &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;frameworkVersion&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;4.0.30319.42000&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;,
    &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;massTransitVersion&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;4.1.0.1470&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;,
    &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;operatingSystemVersion&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;Microsoft Windows NT 6.2.9200.0&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;
  }
}
&lt;/span&gt;--------------------------------------&lt;span&gt;
IEntityConsumer 类型 ObserverSubscriber.Entity &lt;/span&gt;&lt;span&gt;1&lt;/span&gt; &lt;span&gt;10&lt;/span&gt; 张三 &lt;span&gt;2019&lt;/span&gt;/&lt;span&gt;5&lt;/span&gt;/&lt;span&gt;2&lt;/span&gt; &lt;span&gt;12&lt;/span&gt;:&lt;span&gt;23&lt;/span&gt;:&lt;span&gt;23&lt;/span&gt;
------------------PostConsume--------------------&lt;span&gt;
ID&lt;/span&gt;=&lt;span&gt;1&lt;/span&gt;,Name=张三,Time=&lt;span&gt;2019&lt;/span&gt;/&lt;span&gt;5&lt;/span&gt;/&lt;span&gt;2&lt;/span&gt; &lt;span&gt;12&lt;/span&gt;:&lt;span&gt;23&lt;/span&gt;:&lt;span&gt;23&lt;/span&gt;
--------------------------------------
-----------------PostReceive---------------------&lt;span&gt;
{
  &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;messageId&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;36500000-a632-9828-3029-08d6ceb5ea32&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;,
  &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;conversationId&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;36500000-a632-9828-ef7f-08d6ceb5ea37&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;,
  &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;sourceAddress&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;rabbitmq://localhost/bus-DESKTOP-PUOA6D7-dotnet-g3eyyyfggkcnt4wdbdmc7pxgn4?durable=false&amp;amp;autodelete=true&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;,
  &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;destinationAddress&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;rabbitmq://localhost/ObserverSubscriber:Entity&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;,
  &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;messageType&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;: [
    &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;urn:message:ObserverSubscriber:Entity&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;
  ],
  &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;message&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;: {
    &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;id&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: &lt;span&gt;1&lt;/span&gt;&lt;span&gt;,
    &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;age&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: &lt;span&gt;10&lt;/span&gt;&lt;span&gt;,
    &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;name&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;张三&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;,
    &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;time&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;2019-05-02T12:23:23.2223222+08:00&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;
  },
  &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;sentTime&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;2019-05-02T04:23:23.3522586Z&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;,
  &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;headers&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;: {},
  &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;host&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;: {
    &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;machineName&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;DESKTOP-PUOA6D7&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;,
    &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;processName&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;dotnet&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;,
    &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;processId&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: &lt;span&gt;25668&lt;/span&gt;&lt;span&gt;,
    &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;assembly&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;ObserverPublish&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;,
    &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;assemblyVersion&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;1.0.0.0&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;,
    &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;frameworkVersion&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;4.0.30319.42000&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;,
    &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;massTransitVersion&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;4.1.0.1470&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;,
    &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;operatingSystemVersion&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;: &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;Microsoft Windows NT 6.2.9200.0&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;
  }
}
&lt;/span&gt;--------------------------------------
&lt;/pre&gt;&lt;/div&gt;
&lt;span class=&quot;cnblogs_code_collapse&quot;&gt;View Code&lt;/span&gt;&lt;/div&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;h3&gt;7.9、数据一致性示例&lt;/h3&gt;
&lt;p&gt;详见：&lt;a href=&quot;https://github.com/786744873/DataConsistentSample&quot; target=&quot;_blank&quot;&gt;https://github.com/786744873/DataConsistentSample&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/991704/201905/991704-20190502150820093-1882337153.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;h2&gt;8、Jenkins&lt;/h2&gt;
&lt;p&gt;官方地址：&lt;a href=&quot;https://jenkins.io/&quot; target=&quot;_blank&quot;&gt;https://jenkins.io/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Jenkins 是一款流行的开源持续集成（CI）与持续部署（CD）工具，广泛用于项目开发，具有自动化构建、测试和部署等功能。&lt;/p&gt;
&lt;p&gt;　　使用Jenkins的目的在于：&lt;/p&gt;
&lt;p&gt;　　（1）持续、自动地构建/测试软件项目。 &lt;br/&gt;　　（2）监控软件开放流程，快速问题定位及处理，提升开发效率。&lt;/p&gt;
&lt;h3&gt;8.1、Jenkins下载与安装&lt;/h3&gt;
&lt;p&gt;这里我们下载Windows版本的&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/991704/201905/991704-20190502144039416-1787127423.png&quot; alt=&quot;&quot; width=&quot;279&quot; height=&quot;348&quot;/&gt;&lt;/p&gt;
&lt;p&gt;安装完成后会提示我们解锁 Jenkins&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/991704/201905/991704-20190502144129350-812381050.png&quot; alt=&quot;&quot; width=&quot;600&quot; height=&quot;227&quot;/&gt;&lt;/p&gt;
&lt;p&gt;这里选择&lt;strong&gt;安装推荐的插件&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/991704/201905/991704-20190502144630958-1135438208.png&quot; alt=&quot;&quot; width=&quot;623&quot; height=&quot;347&quot;/&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;创建管理账户 =&amp;gt; 也可以直接使用admin账户继续&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/991704/201905/991704-20190502144924052-807312107.png&quot; alt=&quot;&quot; width=&quot;477&quot; height=&quot;261&quot;/&gt;&lt;/p&gt;
&lt;p&gt;配置Jenkins端口，默认8080，最好不要使用8080端口&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/991704/201905/991704-20190502145056594-1826837638.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;修改Jenkins服务端口，改为8080--&amp;gt;8081&lt;/p&gt;
&lt;p&gt;修改安装目录下 &lt;span class=&quot;cnblogs_code&quot;&gt;jenkins.xml&lt;/span&gt; 文件&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/991704/201905/991704-20190502150113989-1735383372.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;然后重启Jenkins服务&lt;/p&gt;
&lt;h3&gt;8.2、持续集成Asp.Net Core项目&lt;/h3&gt;
&lt;ol&gt;&lt;li&gt;我们以Github上面的项目为例，github项目地址：&lt;a href=&quot;https://github.com/786744873/first.git&quot; target=&quot;_blank&quot;&gt;https://github.com/786744873/first.git&lt;br/&gt;&lt;/a&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/991704/201905/991704-20190502150348868-767818407.png&quot; alt=&quot;&quot; width=&quot;672&quot; height=&quot;629&quot;/&gt;&lt;/li&gt;
&lt;li&gt;配置源代码&lt;br/&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/991704/201905/991704-20190502151219544-1190187689.png&quot; alt=&quot;&quot;/&gt;&lt;/li&gt;
&lt;li&gt;构建触发器（这里每半小时轮询一次）&lt;br/&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/991704/201905/991704-20190502151319994-2032373751.png&quot; alt=&quot;&quot;/&gt;&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;构建&lt;br/&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/991704/201905/991704-20190502151408267-770870170.png&quot; alt=&quot;&quot;/&gt;&lt;br/&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/991704/201905/991704-20190502151819149-1933047932.png&quot; alt=&quot;&quot;/&gt;&lt;div class=&quot;cnblogs_code&quot; readability=&quot;34&quot;&gt;
&lt;pre&gt;
&lt;span&gt;cd CITest
cd CITest
dotnet restore
dotnet build
dotnet publish &lt;/span&gt;-o &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;bin\Debug\netcoreapp2.0\publish&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;
cd bin\Debug\netcoreapp2.&lt;/span&gt;&lt;span&gt;0&lt;/span&gt;&lt;span&gt;\publish
docker rm clitest &lt;/span&gt;-&lt;span&gt;f
docker rmi clitest &lt;/span&gt;-&lt;span&gt;f
docker build &lt;/span&gt;-&lt;span&gt;t clitest:latest .
docker run &lt;/span&gt;-p &lt;span&gt;4555&lt;/span&gt;:&lt;span&gt;4555&lt;/span&gt; -d --name clitest clitest:latest
&lt;/pre&gt;&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;保存，然后去配置构建邮件发送&lt;br/&gt;Jenkins-&amp;gt;系统管理-&amp;gt;系统设置&lt;br/&gt;设置系统管理员收件地址(实际上这边配置的是发件人的邮箱地址)：&lt;br/&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/991704/201905/991704-20190502201459459-2052889206.png&quot; alt=&quot;&quot;/&gt;&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/991704/201905/991704-20190502201613057-1867497362.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;继续进行项目配置&lt;br/&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/991704/201905/991704-20190502202158887-1381426956.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/991704/201905/991704-20190502202234050-1793733017.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;构建项目&lt;br/&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/991704/201905/991704-20190502204128092-427450230.png&quot; alt=&quot;&quot;/&gt;&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/991704/201905/991704-20190502204354741-604278101.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;/li&gt;
&lt;/ol&gt;
</description>
<pubDate>Thu, 02 May 2019 13:02:00 +0000</pubDate>
<dc:creator>进击的辣条</dc:creator>
<og:description>1、微服务简介 一种架构模式，提倡将单一应用程序划分成一组小的服务，服务之间互相协调、互相配合，为用户提供最终价值。每个服务运行在其独立的进程中，服务与服务间采用轻量级的通信机制互相沟通（RESTfu</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/wyt007/p/10631109.html</dc:identifier>
</item>
<item>
<title>ES6 - let &amp; const - xing.org1^</title>
<link>http://www.cnblogs.com/padding1015/p/10803267.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/padding1015/p/10803267.html</guid>
<description>&lt;p&gt;js是弱类型语言，语法很松散，这是一个缺点。&lt;/p&gt;
&lt;p&gt;之前，在js中变量声明：var。&lt;/p&gt;

&lt;p&gt;为了解决这个缺点，js中声明变量新增两个语法：let、const&lt;/p&gt;


&lt;p&gt;特点有三：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;变量声明提升、&lt;/li&gt;
&lt;li&gt;可重复定义同一个名字的变量不报错、&lt;/li&gt;
&lt;li&gt;全局变量挂载到window&lt;/li&gt;
&lt;/ul&gt;

&lt;ul type=&quot;disc&quot;&gt;&lt;li&gt;没有变量声明提升&lt;/li&gt;
&lt;li&gt;不能重复声明同一个变量，即使是var过的变量，甚至是行参也不行。&lt;/li&gt;
&lt;li&gt;声明的变量不会挂载到window上&lt;/li&gt;
&lt;li&gt;有块级作用域的特点&lt;/li&gt;
&lt;li&gt;&lt;span lang=&quot;zh-CN&quot;&gt;在大括号&lt;span lang=&quot;en-US&quot;&gt;{}里边会形成临时死区&lt;/span&gt;&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span lang=&quot;en-US&quot;&gt;可解决闭包问题&lt;span lang=&quot;zh-CN&quot;&gt;。&lt;/span&gt;&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;[const特殊] var和let定义变量，const定义常量&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;span lang=&quot;en-US&quot;&gt;&lt;span lang=&quot;zh-CN&quot;&gt;let和const的特性详解&lt;/span&gt;&lt;/span&gt;&lt;span lang=&quot;en-US&quot;&gt;&lt;span lang=&quot;zh-CN&quot;&gt;：&lt;/span&gt;&lt;/span&gt;&lt;/h2&gt;

&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span lang=&quot;zh-CN&quot;&gt;let&lt;span lang=&quot;en-US&quot;&gt;/const&lt;span lang=&quot;zh-CN&quot;&gt;声明的变量不会进行变量声明提升：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span lang=&quot;zh-CN&quot;&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/956663/201905/956663-20190502195150989-2071974377.png&quot; alt=&quot;&quot; width=&quot;462&quot; height=&quot;235&quot;/&gt;&lt;/span&gt;&lt;/p&gt;


&lt;p&gt;&lt;span lang=&quot;en-US&quot;&gt;&lt;span&gt;&lt;strong&gt;let/const重复声明一个变量报错&lt;/strong&gt;&lt;/span&gt;&lt;span lang=&quot;zh-CN&quot;&gt;&lt;span&gt;&lt;strong&gt;。&lt;/strong&gt;&lt;/span&gt; &lt;span lang=&quot;en-US&quot;&gt;&lt;span&gt;&lt;strong&gt;如果这个变量已经被var过了&lt;/strong&gt;&lt;/span&gt;&lt;span lang=&quot;zh-CN&quot;&gt;&lt;span&gt;&lt;strong&gt;，也不能再继续let&lt;/strong&gt;&lt;/span&gt;&lt;span lang=&quot;en-US&quot;&gt;&lt;span&gt;&lt;strong&gt;/const定义了&lt;/strong&gt;&lt;/span&gt;&lt;span lang=&quot;zh-CN&quot;&gt;&lt;span&gt;&lt;strong&gt;：&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span lang=&quot;en-US&quot;&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/956663/201905/956663-20190502195255719-1008705768.png&quot; alt=&quot;&quot; width=&quot;463&quot; height=&quot;171&quot;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/956663/201905/956663-20190502195305089-532049223.png&quot; alt=&quot;&quot; width=&quot;462&quot; height=&quot;205&quot;/&gt;&lt;/p&gt;


&lt;p&gt;&lt;strong&gt;&lt;span lang=&quot;en-US&quot;&gt;延伸到函数的行参上&lt;span lang=&quot;zh-CN&quot;&gt;：&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;函数行参在函数内部也是相当于var了一个变量的存在。&lt;/p&gt;
&lt;p&gt;用var定义变量覆盖行参：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/956663/201905/956663-20190502195338359-1964662433.png&quot; alt=&quot;&quot; width=&quot;465&quot; height=&quot;333&quot;/&gt;&lt;/p&gt;


&lt;p&gt;&lt;strong&gt;但是如果在函数内部用let声明一个和行参同名的变量，就会报错：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/956663/201905/956663-20190502195351569-1971249963.png&quot; alt=&quot;&quot; width=&quot;468&quot; height=&quot;285&quot;/&gt;&lt;/p&gt;


&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span lang=&quot;en-US&quot;&gt;let/const声明的变量不会挂在到window上&lt;span lang=&quot;zh-CN&quot;&gt;，var会（容易造成混乱和冲突，window上的原有属性不能随便改）。&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt; &lt;img src=&quot;https://img2018.cnblogs.com/blog/956663/201905/956663-20190502195545430-2047921709.png&quot; alt=&quot;&quot; width=&quot;466&quot; height=&quot;346&quot;/&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span lang=&quot;en-US&quot;&gt;let/const加强对作用域的控制&lt;span lang=&quot;zh-CN&quot;&gt;：&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;作用域就是变量的生命周期，或者说变量在哪里能够被使用。&lt;/p&gt;
&lt;p&gt;&lt;span lang=&quot;en-US&quot;&gt;也就说let/const能让变量的生命周期更精准&lt;span lang=&quot;zh-CN&quot;&gt;、更规范。（具体如何控制？）&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span lang=&quot;zh-CN&quot;&gt;当let&lt;span lang=&quot;en-US&quot;&gt;/const&lt;span lang=&quot;zh-CN&quot;&gt;配合&lt;span lang=&quot;en-US&quot;&gt;{}使用时能产生块级作用域&lt;span lang=&quot;zh-CN&quot;&gt;。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span lang=&quot;en-US&quot;&gt;换句话说&lt;span lang=&quot;zh-CN&quot;&gt;，只要有大括号，在大括号中let&lt;span lang=&quot;en-US&quot;&gt;/const&lt;span lang=&quot;zh-CN&quot;&gt;一个变量，该变量的生命周期就是这个大括号。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt; &lt;img src=&quot;https://img2018.cnblogs.com/blog/956663/201905/956663-20190502195631268-231560169.png&quot; alt=&quot;&quot; width=&quot;469&quot; height=&quot;242&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/956663/201905/956663-20190502195635664-22538651.png&quot; alt=&quot;&quot; width=&quot;474&quot; height=&quot;137&quot;/&gt;&lt;/p&gt;

&lt;p&gt;&lt;span lang=&quot;zh-CN&quot;&gt;对比var &lt;span lang=&quot;en-US&quot;&gt;的效果&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/956663/201905/956663-20190502195708188-1323810316.png&quot; alt=&quot;&quot; width=&quot;474&quot; height=&quot;242&quot;/&gt;&lt;/p&gt;


&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span lang=&quot;en-US&quot;&gt;块级作用域嵌套&lt;span lang=&quot;zh-CN&quot;&gt;：&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span lang=&quot;en-US&quot;&gt;外部父块级作用域定义的变量&lt;span lang=&quot;zh-CN&quot;&gt;，内部子块级里能获取到。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span lang=&quot;zh-CN&quot;&gt;也就是说虽然产生块级作用域，但是在里边还是能看到外边的，在块级里能看到全局，在子块级里能看到父块级。这就是&lt;span&gt;&lt;strong&gt;&lt;span lang=&quot;zh-CN&quot;&gt;临时死区【&lt;span lang=&quot;en-US&quot;&gt;Temporal Dead Zone&lt;span lang=&quot;zh-CN&quot;&gt;】&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt; &lt;img src=&quot;https://img2018.cnblogs.com/blog/956663/201905/956663-20190502195740003-1460497128.png&quot; alt=&quot;&quot; width=&quot;457&quot; height=&quot;425&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;临时死区【Temporal Dead Zone】&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;只要一个变量在大括号内用let/const声明了，那这个let/const声明就在整个块级里边称霸了，&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/956663/201905/956663-20190502195855574-1228215249.png&quot; alt=&quot;&quot; width=&quot;468&quot; height=&quot;307&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/956663/201905/956663-20190502195909928-845364035.png&quot; alt=&quot;&quot; width=&quot;466&quot; height=&quot;277&quot;/&gt;&lt;/p&gt;

&lt;p&gt;&lt;span lang=&quot;zh-CN&quot;&gt;以上，如果子块里边没有let&lt;span lang=&quot;en-US&quot;&gt;/const声明一个和父级同名的变量&lt;span lang=&quot;zh-CN&quot;&gt;，那将相安无事。子块级的变量使用还是会去父块级或全局中去找。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span lang=&quot;zh-CN&quot;&gt;如果给子块级“胆子”，声明了和父级中已有的同名变量，那他就敢“造反”，整个子块中的这个同名变量他说了算。此时&lt;/span&gt;&lt;span lang=&quot;zh-CN&quot;&gt;如果在子块范围内、let&lt;span lang=&quot;en-US&quot;&gt;/const&lt;span lang=&quot;zh-CN&quot;&gt;声明之前使用这个变量，就会报错。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span lang=&quot;zh-CN&quot;&gt;let&lt;span lang=&quot;en-US&quot;&gt;/const&lt;span lang=&quot;zh-CN&quot;&gt;声明其他和父块级或全局变量不重名的变量倒没有关系。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/956663/201905/956663-20190502200000474-1698129595.png&quot; alt=&quot;&quot; width=&quot;461&quot; height=&quot;320&quot;/&gt;&lt;/p&gt;


&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span lang=&quot;zh-CN&quot;&gt;【const特殊】&lt;span lang=&quot;en-US&quot;&gt;const定义的常量不能修改&lt;span lang=&quot;zh-CN&quot;&gt;，let和var可以。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span lang=&quot;zh-CN&quot;&gt;&lt;span lang=&quot;en-US&quot;&gt;&lt;span lang=&quot;zh-CN&quot;&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/956663/201905/956663-20190502201252074-1003283007.png&quot; alt=&quot;&quot; width=&quot;465&quot; height=&quot;348&quot;/&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;

&lt;h2&gt;总结特性：&lt;/h2&gt;
&lt;p&gt;他其实跟var还是挺像的，只不过var的是局部函数作用域、let和const是局部块级作用域；var的变量声明提升，let和const的变量声明不提升且报错而已。&lt;/p&gt;

&lt;h2&gt;例题：&lt;/h2&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;32&quot;&gt;
&lt;pre&gt;
&lt;span&gt;{
    let test &lt;/span&gt;= 1&lt;span&gt;;
    console.log(test);
    {
        console.log(test);
        let test &lt;/span&gt;= 2&lt;span&gt;;
        {
            let test &lt;/span&gt;= 3&lt;span&gt;;
        }
    }
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/956663/201905/956663-20190502200137709-93737635.png&quot; alt=&quot;&quot; width=&quot;467&quot; height=&quot;372&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/956663/201905/956663-20190502200148205-1212657040.png&quot; alt=&quot;&quot; width=&quot;454&quot; height=&quot;367&quot;/&gt;&lt;/p&gt;



&lt;p&gt;CONST：常量声明。定义一个常量。这个常量不能被改变。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;有以下特点需要注意&lt;/strong&gt;&lt;/p&gt;
&lt;ul type=&quot;disc&quot;&gt;&lt;li&gt;&lt;span lang=&quot;zh-CN&quot;&gt;const &lt;span lang=&quot;en-US&quot;&gt;变量名 时&lt;span lang=&quot;zh-CN&quot;&gt;，后边必须要赋值。否则之后再怎么操作都会报错。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;const定义的常量不能修改，表面上看是原始值不能修改，引用类型值可以修改。但实际上指的是常量地址不能修改。&lt;/li&gt;
&lt;li&gt;CONST拥有let拥有的一切特性。所以在实际应用中第一位的要用const，第二位再用let。&lt;/li&gt;
&lt;li&gt;&lt;span lang=&quot;zh-CN&quot;&gt;const还有性能上的优点，声明常量后 &lt;span lang=&quot;en-US&quot;&gt;&lt;span lang=&quot;zh-CN&quot;&gt;，浏览器就不用追踪变量的变化，节省性能。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;对于开发人员来说，如果修改常量或者命名冲突会被报错而不是直接覆盖，减少出错率。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;const特点详解 ：&lt;/h2&gt;
&lt;p&gt;&lt;span lang=&quot;en-US&quot;&gt;&lt;span&gt;&lt;strong&gt;const声明变量时&lt;/strong&gt;&lt;/span&gt;&lt;span lang=&quot;zh-CN&quot;&gt;&lt;span&gt;&lt;strong&gt;，必须立即赋值：&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt; &lt;img src=&quot;https://img2018.cnblogs.com/blog/956663/201905/956663-20190502200421733-759766971.png&quot; alt=&quot;&quot; width=&quot;356&quot; height=&quot;271&quot;/&gt;&lt;/p&gt;

&lt;p&gt;所以，需要先实现声明一个空变量，且后期会动态改变此变量的情况，就得考虑用let声明。&lt;/p&gt;

&lt;p&gt;&lt;span&gt;&lt;strong&gt;const定义的常量，不能再做修改：&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/956663/201905/956663-20190502200450524-1139309367.png&quot; alt=&quot;&quot; width=&quot;460&quot; height=&quot;190&quot;/&gt;&lt;/p&gt;


&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span lang=&quot;en-US&quot;&gt;const定义的常量&lt;span lang=&quot;zh-CN&quot;&gt;，在栈内存的&lt;span lang=&quot;en-US&quot;&gt;地址不能修改&lt;span lang=&quot;zh-CN&quot;&gt;。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;但是const定义的引用类型值的常量，其属性值或项还是能改：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/956663/201905/956663-20190502200503200-1531272055.png&quot; alt=&quot;&quot; width=&quot;382&quot; height=&quot;320&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;span lang=&quot;en-US&quot;&gt;不过&lt;span lang=&quot;zh-CN&quot;&gt;，略微修改结果又变得和原始值一样：&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span lang=&quot;en-US&quot;&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/956663/201905/956663-20190502200524133-829495715.png&quot; alt=&quot;&quot; width=&quot;384&quot; height=&quot;279&quot;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;修改const常量的指针会报错。但是修改堆空间的属性值却没有关系。&lt;/p&gt;
&lt;p&gt;&lt;span lang=&quot;en-US&quot;&gt;存储常量的空间里边的值不能发生改变&lt;span lang=&quot;zh-CN&quot;&gt;。存储常量的空间在栈空间，也就是栈里边存放的值不能改变。不代表堆内存里边的值不能改变。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;&lt;strong&gt;const定义的常量让浏览器很省心、让开发人员也很省心：&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;const的效率可能比var和let就高一点，因为很多业界大牛猜测，浏览器中会对const变量少了一些追踪，&lt;/p&gt;
&lt;p&gt;不像let和var要时刻去检测它有没有变化。一旦监控就需要一些算力。但是const声明后就不用去检测了，&lt;/p&gt;
&lt;p&gt;所以无论从提升效率还是降低bug出现概率上看，都应该先使用const。&lt;/p&gt;


&lt;p&gt;&lt;strong&gt;const结语：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;能用const就用const。虽然babel转换后他还是var。&lt;/p&gt;





&lt;p&gt;&lt;span&gt;&lt;strong&gt;在声明后重新赋值这方面观察：&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt; &lt;img src=&quot;https://img2018.cnblogs.com/blog/956663/201905/956663-20190502200711839-326035697.png&quot; alt=&quot;&quot; width=&quot;542&quot; height=&quot;195&quot;/&gt;&lt;/p&gt;

&lt;p&gt;可以看到，let和const都被转换成了var。但是他们的特点还是被曲线救国的招式给保留了：&lt;/p&gt;
&lt;p&gt;let声明的变量，在此修改，没有问题。转换成var以后作用一致。&lt;/p&gt;
&lt;p&gt;&lt;span lang=&quot;zh-CN&quot;&gt;但是const就不一样了，const声明的是常量，转成var后不会有这个功能，但是babel创建了一个&lt;span lang=&quot;en-US&quot;&gt;_readOnlyError的内部报错对象&lt;span lang=&quot;zh-CN&quot;&gt;，监测到const常量被重新赋值后就调用该函数向控制台抛出了一个错误以提示开发者。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;


&lt;p&gt;&lt;span&gt;&lt;strong&gt;在变量声明提升的方面观察：&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/956663/201905/956663-20190502200739548-1941623051.png&quot; alt=&quot;&quot; width=&quot;682&quot; height=&quot;60&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;遗憾&lt;/strong&gt;的是，let转换后变成var，有了变量提升，转换前（左边）直接运行是肯定会报错的，转换后打印undefined，说明变量提升生效了。babel没有对这一点进行处理。&lt;/p&gt;

&lt;p&gt;&lt;span&gt;&lt;strong&gt;在暂时死区（块级作用域）方面观察：&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/956663/201905/956663-20190502200832849-1246196093.png&quot; alt=&quot;&quot; width=&quot;665&quot; height=&quot;107&quot;/&gt;&lt;/p&gt;
&lt;p&gt;在块级里边的引用也被处理了（console部分）。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/956663/201905/956663-20190502200839103-615775072.png&quot; alt=&quot;&quot; width=&quot;665&quot; height=&quot;124&quot;/&gt;&lt;/p&gt;

&lt;p&gt;这一次babel确实处理了，是将大括号里边用let声明的变量名加了个下划线，以和块级外边做了区分，一样达到了在外边变量会报错的结果。&lt;/p&gt;

&lt;p&gt;&lt;span&gt;&lt;strong&gt;但同样遗憾的是，对于全局作用域内声明的变量会挂在到window上这一点，依旧没有做防御工作。&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;babel编译后的变量还是会挂在到window对象上。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/956663/201905/956663-20190502201003445-1873091531.png&quot; alt=&quot;&quot; width=&quot;850&quot; height=&quot;171&quot;/&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;&lt;strong&gt;最后对于经典题的观察：&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/956663/201905/956663-20190502201013434-436023056.png&quot; alt=&quot;&quot; width=&quot;593&quot; height=&quot;159&quot;/&gt; &lt;/p&gt;
&lt;p&gt;可见，利用let解决的异步回调里引用循环后的全局变量问题，同样也是闭包的原理实现的。&lt;/p&gt;



&lt;p&gt;&lt;span&gt;2019-05-02 20:10:52&lt;/span&gt; &lt;/p&gt;
&lt;p&gt;&lt;span lang=&quot;zh-CN&quot;&gt; &lt;/span&gt;&lt;/p&gt;

</description>
<pubDate>Thu, 02 May 2019 12:15:00 +0000</pubDate>
<dc:creator>xing.org1^</dc:creator>
<og:description>js是弱类型语言，语法很松散，这是一个缺点。let、const很好的弥补了这个缺点。</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/padding1015/p/10803267.html</dc:identifier>
</item>
<item>
<title>5G浪潮来袭，程序员在风口中有何机遇 - 了不起的厂长</title>
<link>http://www.cnblogs.com/enochzzg/p/10803253.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/enochzzg/p/10803253.html</guid>
<description>&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;导读：本文共2894字，预计阅读时间为9分钟。通过阅读本文，你将了解到5G的优势、即将燃爆的领域以及程序员在快速发展的5G产业中所需关注的技术。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&quot;g时代已经来临&quot;&gt;5G时代已经来临&lt;/h3&gt;
&lt;p&gt;随着中美5G主导权之战的持续发酵，5G时代正式拉开了序幕。最近，5G妖股频现，有的甚至在四个月内暴涨了九倍，令人咂舌，而“5G”迅速成为了人尽皆知的热词，广大网民茶余饭后的谈资。&lt;/p&gt;
&lt;p&gt;其实无论2G到3G，还是3G到4G，每次网络的革新换代总是给网速带来极大的提升，5G也不例外，根据高通之前在旧金山的网络测速的数据表明，5G的网络下载速度可以达到每秒1.4Gbps，这意味着一部电影或一款游戏可以在短短几秒钟内下载完成。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://upload-images.jianshu.io/upload_images/13711841-ea2c3ed2fc5ae74d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240&quot; alt=&quot;未标题-2画板-1 2.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;除此之外，5G另一个主要特征是“低延迟”，低延迟不仅意味着上下行速度更快，响应时间也将大幅缩短，5G的理想延迟为1ms，等同于实时反应，非常适合于工业自动化、无人汽车等延迟要求严格的领域。当然，和朋友开黑时网络卡顿再也不能成为送人头的借口了。&lt;/p&gt;
&lt;p&gt;5G还有一个非常重要的特点就是“高容量”，在人口非常密集的热点地区，特别是上下班高峰期，经常会出现打不开网页的情况。&lt;/p&gt;
&lt;p&gt;其实这与基站的承载能力有关，4G基站只有十几根天线，支持的连接数有限，而5G基站多达上百根，这些天线可以通过Massive MIMO技术形成大规模天线阵列，这就意味着基站可以同时从更多用户发送和接收信号，从而将移动网络的容量提升数十倍或更大。&lt;/p&gt;
&lt;h3 id=&quot;g即将燃爆的领域&quot;&gt;5G即将燃爆的领域&lt;/h3&gt;
&lt;p&gt;由于5G具备高速率、低延迟、高容量的特性，随着技术体系的完善与成熟，将会加速万物在线、物物互联的进程。预计2024年，联网设备的数量将超过220亿台，所以物联网的爆发指日可待。但是物联网所涉及的范围非常广泛，下面我们来说一下物联网的细分领域。&lt;/p&gt;
&lt;h4 id=&quot;车联网&quot;&gt;车联网&lt;/h4&gt;
&lt;p&gt;车联网是由车辆位置、速度和路线等信息构成的巨大交互网络。现在道路上行驶的车辆都是一个个独立的点，车、路、人之间没有很好的互动，全程靠驾驶员来判断，而车联网呢，可以使车和车、车和路以及车和人建立良好的互动，以实现智能化的交通管理、智能动态信息服务和车辆智能化控制的一体化网络。&lt;/p&gt;
&lt;p&gt;由于5G的时延比人类大脑低得多，经过专业训练的人的反应速度至少也要100ms，而5G可以将其减至个位数，所以它的出现可以更好的为车联网、自动驾驶技术服务，大幅降低安全风险系数。&lt;/p&gt;
&lt;p&gt;车联网是物联网技术在交通系统领域的典型应用，5G技术是其强有力的助推器。在没有堵车、醉驾、疲劳驾驶、女性乘车等安全问题的未来，这将是极大的福利。&lt;/p&gt;
&lt;h4 id=&quot;智能家居&quot;&gt;智能家居&lt;/h4&gt;
&lt;p&gt;智能家居通过物联网技术将家中的各种设备（如音视频设备、照明系统、窗帘控制、空调控制、安防系统、数字影院系统、网络家电等）连接到一起，为家庭自动化提供全方位的信息交互功能，甚至为各种能源费用节约资金。&lt;/p&gt;
&lt;p&gt;而高容量的5G能承载更多联网的终端，真正实现家中一切尽在掌控，若有AI技术的支撑，便可使用户拥有帝王般的体验，想象一下在下班回家的路上，AI管家老王早已为你调节好了空调温度、煮上了粥、扫完了地、泡上了一壶好茶并为你打开了最爱的电视频道，如此贴心的服务，如果还在单身的你，已经大可不必再去寻找灵魂的伴侣了。&lt;/p&gt;
&lt;h4 id=&quot;无人机&quot;&gt;无人机&lt;/h4&gt;
&lt;p&gt;早在2018年，中国电信便成功实现了国内首个无人机360度全景4K高清视频的5G实时传输。5G搭配无人机可以充分发挥其机动性、飞行轨迹灵活的特点，可以实现大范围的地毯式搜救和受灾人群的快速定位，打通空中急救通道。除此之外，还可以实现自动化无人巡检、物流运输、农田喷洒、激光测绘、移动的面部识别安防等应用，另外，与VR眼镜搭配的无人机也将别有一番风味。&lt;/p&gt;
&lt;h4 id=&quot;智慧农业&quot;&gt;智慧农业&lt;/h4&gt;
&lt;p&gt;农业是我国第一产业，它涉及到耕地、播种、施肥、杀虫、收割、存储、育种等环节，过去农民总是凭借个人经验进行种植，效率非常低下。而5G的出现，更多的感知端设备加入到网络中来，可以利用它们采集生产、管理、经营等各类信息到系统中，为大数据奠定基础，再结合云计算、数据挖掘等多重信息技术，达到自动调控农业终端，实现真正的农业自动化、智能化。&lt;/p&gt;
&lt;h4 id=&quot;虚拟现实与增强现实&quot;&gt;虚拟现实与增强现实&lt;/h4&gt;
&lt;p&gt;虚拟现实即VR，通过佩戴VR眼镜，可以虚拟出一个真实的环境，从而获得沉浸式的体验，它适用于教育、娱乐、航空航天、室内设计等领域。而增强现实(AR)与虚拟现实不同的是增强现实可以在现实世界叠加虚拟的物体，比如在墙上挂一台虚拟电视、冰箱挂上虚拟日历、厨房灶台旁放置烹饪教学的窗口，除此之外，孩子们可以在草坪上与卡通人物玩耍、在桌面或地板上玩《我的世界》等等，在社交方面甚至可以与千里之外的朋友面对面交流。&lt;/p&gt;
&lt;p&gt;但是无论VR还是AR，都存在因延迟导致用户眩晕的问题，所以很多头戴设备会连接多条导线来降低延迟。除延迟问题外，用户对沉浸感的要求也在逐步提升，因此头戴设备不得不整天上传下载大量的数据，现有的无线网络已经无法满足需求，但是5G的出现可能会彻底拯救VR与AR，这也是众多相关从业者所翘首以盼的。&lt;/p&gt;
&lt;h4 id=&quot;云游戏&quot;&gt;云游戏&lt;/h4&gt;
&lt;p&gt;面对层出不穷的游戏，玩家对游戏的要求也在提高，酷炫的特效、细腻的纹理相伴而来的也是价格昂贵的高配置硬件，我们需要高性能显卡、大内存、超强的CPU才能支撑起逼真的3D游戏，当然钞票也伴随着我们的快乐渺无踪迹。此外，一款好玩的游戏要高达几个G，网络稍弱一点可能就此错过了欢乐的开黑时光。&lt;/p&gt;
&lt;p&gt;但是5G给我们带来了新的可能，它高速率、低延迟的特性完全可以做到将游戏运行在云端，游戏数据实时传输，玩家不必下载，甚至只需要一块能上网有屏幕的终端即可，这就是云游戏的概念。当然，云操作系统也可以使用同样的原理来极简设备的零部件，提升续航能力。仔细想想好像这就是我们平时所使用的“远程桌面”功能。&lt;/p&gt;
&lt;h3 id=&quot;程序员需关注的技能&quot;&gt;程序员需关注的技能&lt;/h3&gt;
&lt;p&gt;回归到本质，面对这么多细分领域的崛起，作为程序员应该关注哪些技术呢？因为5G的出现会导致联网终端数量大幅上涨，海量连接涌入系统，会产生庞大的数据量，所以大数据是5G时代的最大受益，通过对大数据的挖掘，能造就无限的可能。&lt;/p&gt;
&lt;h4 id=&quot;机器学习&quot;&gt;机器学习&lt;/h4&gt;
&lt;p&gt;大数据是机器学习的基础，它可以对数据进行过滤、整理以及深度分析，通过不断的自我算法改进来发掘出有用的信息。其处理的数据越多，越能体现其优势，以前用机器学习解决不了的问题，可以利用大数据去很好的解决，性能也会有大幅提升，主要应用场景有语音识别、图像识别、天气预测等等。常见的开源项目有：tensorflow、scikit-learn、predictionio、golearn等。&lt;/p&gt;
&lt;h4 id=&quot;云计算&quot;&gt;云计算&lt;/h4&gt;
&lt;p&gt;面对海量的数据，要对其进行统计分析，并非单台机器的运算能力所能企及的，所以必须采用分布式架构，集结多台机器进行运算，将运算能力最大化，云计算的特色就在于对海量的数据进行分布式数据挖掘。常见的云计算相关开源项目有Hadoop、Eucalyptus、Enomaly ECP、Nimbus等。&lt;/p&gt;
&lt;h4 id=&quot;边缘计算&quot;&gt;边缘计算&lt;/h4&gt;
&lt;p&gt;因为海量的数据连接，网络边缘侧会产生庞大的数据，虽然云计算有能力处理这些数据，但及时性、安全性以及成本会存在很大问题。因此边缘计算应运而生，它实现了资源和服务向边缘位置下沉，可以就近处理海量数据，大量设备可以实现高效协同工作，从而降低交互时延、减轻网络负担。边缘计算开源项目有Akraino Edge Stack、OpenEdge等。&lt;/p&gt;
&lt;h4 id=&quot;网络安全&quot;&gt;网络安全&lt;/h4&gt;
&lt;p&gt;在两会期间，周鸿祎表示5G时代下，线上线下的边界正在消失，网络空间的攻击将会穿透虚拟空间，直接映射到物理世界的安全。当前中国面临的网络攻击威胁，只有通过统一大数据来感知网络中未知的攻击才能解决。&lt;/p&gt;
&lt;p&gt;在万物联网的时代，网络安全不容小觑，黑客极有可能通过防线，攻击中控设备来控制家中一切可上网的终端，甚至可能会对用户造成人身伤害，所以网络安全不仅是现在更是未来非常重要的课题。&lt;/p&gt;
&lt;h4 id=&quot;其它&quot;&gt;其它&lt;/h4&gt;
&lt;p&gt;头戴设备的爆发极有可能会颠覆人们的娱乐方式，如电影《头号玩家》中所描述的那样，玩家沉浸于逼真的虚拟环境、拥有真实的体感触感，这将会把玩家带提升到一个新的娱乐高度。所以除了大数据相关的技术之外，3D建模、手势操控、体感技术、全息投影、图像识别、SLAM、LBS基站定位技术可能都是未来的热门技术。&lt;/p&gt;
&lt;p&gt;由于5G的杀手级应用还未浮出水面，所以5G产业如何发展还是一个未知数，未来可能会有更多蓄势待发的新技术出现，我们应该时刻准备迎接新的知识，拥抱变化、适应变化、才不会被时代浪潮冲向边缘。&lt;/p&gt;
</description>
<pubDate>Thu, 02 May 2019 12:14:00 +0000</pubDate>
<dc:creator>了不起的厂长</dc:creator>
<og:description>导读：本文共2894字，预计阅读时间为9分钟。通过阅读本文，你将了解到5G的优势、即将燃爆的领域以及程序员在快速发展的5G产业中所需关注的技术。 5G时代已经来临 随着中美5G主导权之战的持续发酵，5</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/enochzzg/p/10803253.html</dc:identifier>
</item>
<item>
<title>大数据技术之_19_Spark学习_06_Spark 源码解析 + Spark 通信架构、脚本解析、standalone 模式启动、提交流程 + Spark Shuffle 过程 + Spark 内存管理与分配 + Spark 部署模式 - 黑泽君</title>
<link>http://www.cnblogs.com/chenmingjun/p/10803261.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/chenmingjun/p/10803261.html</guid>
<description>&lt;p id=&quot;tocid_0&quot; class=&quot;toc&quot;&gt;&lt;span class=&quot;toc_item&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;a href=&quot;http://www.cnblogs.com/chenmingjun/p/10803261.html#h1spark&quot;&gt;第1章 Spark 整体概述&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;toc_item&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;a href=&quot;http://www.cnblogs.com/chenmingjun/p/10803261.html#h11&quot;&gt;1.1 整体概念&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;toc_item&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;a href=&quot;http://www.cnblogs.com/chenmingjun/p/10803261.html#h12rdd&quot;&gt;1.2 RDD 抽象&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;toc_item&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;a href=&quot;http://www.cnblogs.com/chenmingjun/p/10803261.html#h13&quot;&gt;1.3 计算抽象&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;toc_item&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;a href=&quot;http://www.cnblogs.com/chenmingjun/p/10803261.html#h14&quot;&gt;1.4 集群模式&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;toc_item&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;a href=&quot;http://www.cnblogs.com/chenmingjun/p/10803261.html#h15rpc&quot;&gt;1.5 RPC 网络通信抽象&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;toc_item&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;a href=&quot;http://www.cnblogs.com/chenmingjun/p/10803261.html#h16standalone&quot;&gt;1.6 启动 Standalone 集群&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;toc_item&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;a href=&quot;http://www.cnblogs.com/chenmingjun/p/10803261.html#h17&quot;&gt;1.7 核心组件&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;toc_item&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;a href=&quot;http://www.cnblogs.com/chenmingjun/p/10803261.html#h18&quot;&gt;1.8 核心组件交互流程&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;toc_item&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;a href=&quot;http://www.cnblogs.com/chenmingjun/p/10803261.html#h19block&quot;&gt;1.9 Block 管理&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;toc_item&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;a href=&quot;http://www.cnblogs.com/chenmingjun/p/10803261.html#h110&quot;&gt;1.10整体应用&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;toc_item&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;a href=&quot;http://www.cnblogs.com/chenmingjun/p/10803261.html#h2spark&quot;&gt;第2章 Spark 通信架构&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;toc_item&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;a href=&quot;http://www.cnblogs.com/chenmingjun/p/10803261.html#h21&quot;&gt;2.1 通信组件概览&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;toc_item&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;a href=&quot;http://www.cnblogs.com/chenmingjun/p/10803261.html#h22endpoint&quot;&gt;2.2 Endpoint 启动过程&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;toc_item&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;a href=&quot;http://www.cnblogs.com/chenmingjun/p/10803261.html#h23endpointsendask&quot;&gt;2.3 Endpoint Send&amp;amp;Ask 流程&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;toc_item&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;a href=&quot;http://www.cnblogs.com/chenmingjun/p/10803261.html#h24endpointreceive&quot;&gt;2.4 Endpoint Receive 流程&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;toc_item&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;a href=&quot;http://www.cnblogs.com/chenmingjun/p/10803261.html#h25endpointinbox&quot;&gt;2.5 Endpoint Inbox 处理流程&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;toc_item&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;a href=&quot;http://www.cnblogs.com/chenmingjun/p/10803261.html#h26endpoint&quot;&gt;2.6 Endpoint 画像&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;toc_item&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;a href=&quot;http://www.cnblogs.com/chenmingjun/p/10803261.html#h3&quot;&gt;第3章 脚本解析&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;toc_item&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;a href=&quot;http://www.cnblogs.com/chenmingjun/p/10803261.html#h31startdaemonsh&quot;&gt;3.1 start-daemon.sh&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;toc_item&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;a href=&quot;http://www.cnblogs.com/chenmingjun/p/10803261.html#h32sparkclass&quot;&gt;3.2 spark-class&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;toc_item&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;a href=&quot;http://www.cnblogs.com/chenmingjun/p/10803261.html#h33startmastersh&quot;&gt;3.3 start-master.sh&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;toc_item&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;a href=&quot;http://www.cnblogs.com/chenmingjun/p/10803261.html#h34startslavessh&quot;&gt;3.4 start-slaves.sh&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;toc_item&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;a href=&quot;http://www.cnblogs.com/chenmingjun/p/10803261.html#h35startallsh&quot;&gt;3.5 start-all.sh&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;toc_item&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;a href=&quot;http://www.cnblogs.com/chenmingjun/p/10803261.html#h36sparksubmit&quot;&gt;3.6 spark-submit&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;toc_item&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;a href=&quot;http://www.cnblogs.com/chenmingjun/p/10803261.html#h4master&quot;&gt;第4章 Master 节点启动&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;toc_item&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;a href=&quot;http://www.cnblogs.com/chenmingjun/p/10803261.html#h41&quot;&gt;4.1 脚本概览&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;toc_item&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;a href=&quot;http://www.cnblogs.com/chenmingjun/p/10803261.html#h42&quot;&gt;4.2 启动流程&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;toc_item&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;a href=&quot;http://www.cnblogs.com/chenmingjun/p/10803261.html#h43onstart&quot;&gt;4.3 OnStart 监听事件&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;toc_item&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;a href=&quot;http://www.cnblogs.com/chenmingjun/p/10803261.html#h44rpcmessagereceiveandreply&quot;&gt;4.4 RpcMessage 处理 (receiveAndReply)&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;toc_item&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;a href=&quot;http://www.cnblogs.com/chenmingjun/p/10803261.html#h45onewaymessagereceive&quot;&gt;4.5 OneWayMessage 处理 (receive)&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;toc_item&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;a href=&quot;http://www.cnblogs.com/chenmingjun/p/10803261.html#h46masterrpcmessageonewaymessage&quot;&gt;4.6 Master 对 RpcMessage/OneWayMessage 处理逻辑&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;toc_item&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;a href=&quot;http://www.cnblogs.com/chenmingjun/p/10803261.html#h5worker&quot;&gt;第5章 Worker 节点启动&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;toc_item&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;a href=&quot;http://www.cnblogs.com/chenmingjun/p/10803261.html#h51&quot;&gt;5.1 脚本概览&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;toc_item&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;a href=&quot;http://www.cnblogs.com/chenmingjun/p/10803261.html#h52&quot;&gt;5.2 启动流程&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;toc_item&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;a href=&quot;http://www.cnblogs.com/chenmingjun/p/10803261.html#h53onstart&quot;&gt;5.3 OnStart 监听事件&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;toc_item&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;a href=&quot;http://www.cnblogs.com/chenmingjun/p/10803261.html#h54rpcmessagereceiveandreply&quot;&gt;5.4 RpcMessage 处理 (receiveAndReply)&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;toc_item&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;a href=&quot;http://www.cnblogs.com/chenmingjun/p/10803261.html#h55onewaymessagereceive&quot;&gt;5.5 OneWayMessage 处理 (receive)&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;toc_item&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;a href=&quot;http://www.cnblogs.com/chenmingjun/p/10803261.html#h6client&quot;&gt;第6章 Client 启动流程&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;toc_item&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;a href=&quot;http://www.cnblogs.com/chenmingjun/p/10803261.html#h61&quot;&gt;6.1 脚本概览&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;toc_item&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;a href=&quot;http://www.cnblogs.com/chenmingjun/p/10803261.html#h62sparksubmit&quot;&gt;6.2 SparkSubmit 启动流程&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;toc_item&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;a href=&quot;http://www.cnblogs.com/chenmingjun/p/10803261.html#h63client&quot;&gt;6.3 Client 启动流程&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;toc_item&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;a href=&quot;http://www.cnblogs.com/chenmingjun/p/10803261.html#h64clientonstart&quot;&gt;6.4 Client 的 OnStart 监听事件&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;toc_item&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;a href=&quot;http://www.cnblogs.com/chenmingjun/p/10803261.html#h65rpcmessagereceiveandreply&quot;&gt;6.5 RpcMessage 处理 (receiveAndReply)&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;toc_item&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;a href=&quot;http://www.cnblogs.com/chenmingjun/p/10803261.html#h66onewaymessagereceive&quot;&gt;6.6 OneWayMessage 处理(receive)&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;toc_item&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;a href=&quot;http://www.cnblogs.com/chenmingjun/p/10803261.html#h7driverdriverrunner&quot;&gt;第7章 Driver 和 DriverRunner&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;toc_item&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;a href=&quot;http://www.cnblogs.com/chenmingjun/p/10803261.html#h71masterdriver&quot;&gt;7.1 Master 对 Driver 资源分配&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;toc_item&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;a href=&quot;http://www.cnblogs.com/chenmingjun/p/10803261.html#h72workerdriverrunner&quot;&gt;7.2 Worker 运行 DriverRunner&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;toc_item&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;a href=&quot;http://www.cnblogs.com/chenmingjun/p/10803261.html#h73driverrunnerdriverwrapper&quot;&gt;7.3 DriverRunner 创建并运行 DriverWrapper&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;toc_item&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;a href=&quot;http://www.cnblogs.com/chenmingjun/p/10803261.html#h8sparkcontext&quot;&gt;第8章 SparkContext 解析&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;toc_item&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;a href=&quot;http://www.cnblogs.com/chenmingjun/p/10803261.html#h81sparkcontext&quot;&gt;8.1 SparkContext 解析&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;toc_item&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;a href=&quot;http://www.cnblogs.com/chenmingjun/p/10803261.html#h82sparkcontext&quot;&gt;8.2 SparkContext 创建过程&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;toc_item&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;a href=&quot;http://www.cnblogs.com/chenmingjun/p/10803261.html#h83sparkcontext&quot;&gt;8.3 SparkContext 简易结构与交互关系&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;toc_item&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;a href=&quot;http://www.cnblogs.com/chenmingjun/p/10803261.html#h84masterapplication&quot;&gt;8.4 Master 对 Application 资源分配&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;toc_item&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;a href=&quot;http://www.cnblogs.com/chenmingjun/p/10803261.html#h85workerexecutor&quot;&gt;8.5 Worker 创建 Executor&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;toc_item&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;a href=&quot;http://www.cnblogs.com/chenmingjun/p/10803261.html#h9jobtask&quot;&gt;第9章 Job 提交和 Task 的拆分&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;toc_item&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;a href=&quot;http://www.cnblogs.com/chenmingjun/p/10803261.html#h91&quot;&gt;9.1 整体预览&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;toc_item&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;a href=&quot;http://www.cnblogs.com/chenmingjun/p/10803261.html#h92coderdds&quot;&gt;9.2 Code 转化为初始 RDDs&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;toc_item&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;a href=&quot;http://www.cnblogs.com/chenmingjun/p/10803261.html#h93rddtaskset&quot;&gt;9.3 RDD 分解为待执行任务集合（TaskSet）&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;toc_item&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;a href=&quot;http://www.cnblogs.com/chenmingjun/p/10803261.html#h94tasksettasksetmanagerdriver&quot;&gt;9.4 TaskSet 封装为 TaskSetManager 并提交至 Driver&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;toc_item&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;a href=&quot;http://www.cnblogs.com/chenmingjun/p/10803261.html#h95drivertasksetmanagertaskdescriptionsexecutor&quot;&gt;9.5 Driver 将 TaskSetManager 分解为 TaskDescriptions 并发布任务到 Executor&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;toc_item&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;a href=&quot;http://www.cnblogs.com/chenmingjun/p/10803261.html#h10task&quot;&gt;第10章 Task 执行和&lt;/a&gt;回馈&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;toc_item&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;a href=&quot;http://www.cnblogs.com/chenmingjun/p/10803261.html#h101task&quot;&gt;10.1 Task 的执行流程&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;toc_item&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;a href=&quot;http://www.cnblogs.com/chenmingjun/p/10803261.html#h102task&quot;&gt;10.2 Task 的回馈流程&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;toc_item&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;a href=&quot;http://www.cnblogs.com/chenmingjun/p/10803261.html#h103task&quot;&gt;10.3 Task 的迭代流程&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;toc_item&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;a href=&quot;http://www.cnblogs.com/chenmingjun/p/10803261.html#h104&quot;&gt;10.4 精彩图解&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;toc_item&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;a href=&quot;http://www.cnblogs.com/chenmingjun/p/10803261.html#h11spark&quot;&gt;第11章 Spark 的数据存储&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;toc_item&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;a href=&quot;http://www.cnblogs.com/chenmingjun/p/10803261.html#h111&quot;&gt;11.1 存储子系统概览&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;toc_item&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;a href=&quot;http://www.cnblogs.com/chenmingjun/p/10803261.html#h112&quot;&gt;11.2 启动过程分析&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;toc_item&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;a href=&quot;http://www.cnblogs.com/chenmingjun/p/10803261.html#h113&quot;&gt;11.3 通信层&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;toc_item&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;a href=&quot;http://www.cnblogs.com/chenmingjun/p/10803261.html#h114&quot;&gt;11.4 存储层&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;toc_item&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;a href=&quot;http://www.cnblogs.com/chenmingjun/p/10803261.html#h1141diskstore&quot;&gt;11.4.1 Disk Store&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;toc_item&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;a href=&quot;http://www.cnblogs.com/chenmingjun/p/10803261.html#h1142memorystore&quot;&gt;11.4.2 Memory Store&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;toc_item&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;a href=&quot;http://www.cnblogs.com/chenmingjun/p/10803261.html#h115&quot;&gt;11.5 数据写入过程分析&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;toc_item&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;a href=&quot;http://www.cnblogs.com/chenmingjun/p/10803261.html#h1151&quot;&gt;11.5.1 序列化与否&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;toc_item&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;a href=&quot;http://www.cnblogs.com/chenmingjun/p/10803261.html#h116&quot;&gt;11.6 数据读取过程分析&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;toc_item&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;a href=&quot;http://www.cnblogs.com/chenmingjun/p/10803261.html#h1161&quot;&gt;11.6.1 本地读取&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;toc_item&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;a href=&quot;http://www.cnblogs.com/chenmingjun/p/10803261.html#h1162&quot;&gt;11.6.2 远程读取&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;toc_item&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;a href=&quot;http://www.cnblogs.com/chenmingjun/p/10803261.html#h117partitionblock&quot;&gt;11.7 Partition 如何转化为 Block&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;toc_item&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;a href=&quot;http://www.cnblogs.com/chenmingjun/p/10803261.html#h118partitionblock&quot;&gt;11.8 partition 和 block 的对应关系&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;toc_item&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;a href=&quot;http://www.cnblogs.com/chenmingjun/p/10803261.html#h12sparkshuffle&quot;&gt;第12章 Spark Shuffle 过程&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;toc_item&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;a href=&quot;http://www.cnblogs.com/chenmingjun/p/10803261.html#h121mapreduceshuffle&quot;&gt;12.1 MapReduce 的 Shuffle 过程介绍&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;toc_item&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;a href=&quot;http://www.cnblogs.com/chenmingjun/p/10803261.html#h1211spill&quot;&gt;12.1.1 Spill 过程(刷写过程)&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;toc_item&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;a href=&quot;http://www.cnblogs.com/chenmingjun/p/10803261.html#h1212merge&quot;&gt;12.1.2 Merge&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;toc_item&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;a href=&quot;http://www.cnblogs.com/chenmingjun/p/10803261.html#h1213copy&quot;&gt;12.1.3 Copy&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;toc_item&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;a href=&quot;http://www.cnblogs.com/chenmingjun/p/10803261.html#h1214mergesort&quot;&gt;12.1.4 Merge Sort&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;toc_item&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;a href=&quot;http://www.cnblogs.com/chenmingjun/p/10803261.html#h122hashshuffle&quot;&gt;12.2 HashShuffle 过程介绍&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;toc_item&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;a href=&quot;http://www.cnblogs.com/chenmingjun/p/10803261.html#h123sortshuffle&quot;&gt;12.3 SortShuffle 过程介绍&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;toc_item&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;a href=&quot;http://www.cnblogs.com/chenmingjun/p/10803261.html#h124tungstenshuffle&quot;&gt;12.4 TungstenShuffle 过程介绍&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;toc_item&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;a href=&quot;http://www.cnblogs.com/chenmingjun/p/10803261.html#h125mapreducespark&quot;&gt;12.5 MapReduce 与 Spark 过程对比&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;toc_item&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;a href=&quot;http://www.cnblogs.com/chenmingjun/p/10803261.html#h13spark&quot;&gt;第13章 Spark 内存管理&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;toc_item&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;a href=&quot;http://www.cnblogs.com/chenmingjun/p/10803261.html#h131&quot;&gt;13.1 堆内和堆外内存规划&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;toc_item&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;a href=&quot;http://www.cnblogs.com/chenmingjun/p/10803261.html#h1311&quot;&gt;13.1.1 堆内内存&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;toc_item&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;a href=&quot;http://www.cnblogs.com/chenmingjun/p/10803261.html#h1312&quot;&gt;13.1.2 堆外内存&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;toc_item&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;a href=&quot;http://www.cnblogs.com/chenmingjun/p/10803261.html#h1313&quot;&gt;13.1.3 内存管理接口&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;toc_item&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;a href=&quot;http://www.cnblogs.com/chenmingjun/p/10803261.html#h132&quot;&gt;13.2 内存空间分配&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;toc_item&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;a href=&quot;http://www.cnblogs.com/chenmingjun/p/10803261.html#h1321&quot;&gt;13.2.1 静态内存管理&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;toc_item&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;a href=&quot;http://www.cnblogs.com/chenmingjun/p/10803261.html#h1322&quot;&gt;13.2.2 统一内存管理&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;toc_item&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;a href=&quot;http://www.cnblogs.com/chenmingjun/p/10803261.html#h133&quot;&gt;13.3 存储内存管理&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;toc_item&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;a href=&quot;http://www.cnblogs.com/chenmingjun/p/10803261.html#h1331rdd&quot;&gt;13.3.1 RDD 的持久化机制&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;toc_item&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;a href=&quot;http://www.cnblogs.com/chenmingjun/p/10803261.html#h1332rdd&quot;&gt;13.3.2 RDD 缓存的过程&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;toc_item&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;a href=&quot;http://www.cnblogs.com/chenmingjun/p/10803261.html#h1333&quot;&gt;13.3.3 淘汰和落盘&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;toc_item&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;a href=&quot;http://www.cnblogs.com/chenmingjun/p/10803261.html#h134&quot;&gt;13.4 执行内存管理&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;toc_item&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;a href=&quot;http://www.cnblogs.com/chenmingjun/p/10803261.html#h1341&quot;&gt;13.4.1 多任务间内存分配&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;toc_item&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;a href=&quot;http://www.cnblogs.com/chenmingjun/p/10803261.html#h1342shuffle&quot;&gt;13.4.2 Shuffle 的内存占用&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;toc_item&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;a href=&quot;http://www.cnblogs.com/chenmingjun/p/10803261.html#h14-1&quot;&gt;第14章 部署模式解析&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;toc_item&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;a href=&quot;http://www.cnblogs.com/chenmingjun/p/10803261.html#h141&quot;&gt;14.1 部署模式概述&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;toc_item&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;a href=&quot;http://www.cnblogs.com/chenmingjun/p/10803261.html#h142standalone&quot;&gt;14.2 standalone 框架&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;toc_item&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;a href=&quot;http://www.cnblogs.com/chenmingjun/p/10803261.html#h1421standalone&quot;&gt;14.2.1 Standalone 模式下任务运行过程&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;toc_item&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;a href=&quot;http://www.cnblogs.com/chenmingjun/p/10803261.html#h1422&quot;&gt;14.2.2 总结&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;toc_item&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;a href=&quot;http://www.cnblogs.com/chenmingjun/p/10803261.html#h143yarn&quot;&gt;14.3 yarn 集群模式&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;toc_item&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;a href=&quot;http://www.cnblogs.com/chenmingjun/p/10803261.html#h144mesos&quot;&gt;14.4 mesos 集群模式&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;toc_item&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;a href=&quot;http://www.cnblogs.com/chenmingjun/p/10803261.html#h145spark&quot;&gt;14.5 spark 三种部署模式的区别&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;toc_item&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;a href=&quot;http://www.cnblogs.com/chenmingjun/p/10803261.html#h146&quot;&gt;14.6 异常场景分析&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;toc_item&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;a href=&quot;http://www.cnblogs.com/chenmingjun/p/10803261.html#h14611worker&quot;&gt;14.6.1 异常分析1：Worker 异常退出&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;toc_item&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;a href=&quot;http://www.cnblogs.com/chenmingjun/p/10803261.html#h14622executor&quot;&gt;14.6.2 异常分析2：Executor 异常退出&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;toc_item&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;a href=&quot;http://www.cnblogs.com/chenmingjun/p/10803261.html#h14633master&quot;&gt;14.6.3 异常分析3：Master 异常退出&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;toc_item&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;a href=&quot;http://www.cnblogs.com/chenmingjun/p/10803261.html#h15wordcount&quot;&gt;第15章 wordcount 程序运行原理窥探&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;toc_item&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;a href=&quot;http://www.cnblogs.com/chenmingjun/p/10803261.html#h151sparkscalawordcount&quot;&gt;15.1 spark 之 scala 实现 wordcount&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;toc_item&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;span class=&quot;toc_left&quot;&gt;&lt;a href=&quot;http://www.cnblogs.com/chenmingjun/p/10803261.html#h152&quot;&gt;15.2 原理窥探&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;hr/&gt;&lt;h2 id=&quot;h1spark&quot;&gt;&lt;span&gt;&lt;strong&gt;第1章 Spark 整体概述&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;
&lt;img title=&quot;&quot; src=&quot;https://s2.ax1x.com/2019/05/02/EtCqr4.png&quot; alt=&quot;&quot;/&gt;&lt;h3 id=&quot;h11&quot;&gt;&lt;span&gt;&lt;strong&gt;1.1 整体概念&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;  Apache Spark 是一个开源的通用集群计算系统，它提供了 High-level 编程 API，支持 Scala、Java 和 Python 三种编程语言。Spark 内核使用 Scala 语言编写，通过基于 Scala 的函数式编程特性，在不同的计算层面进行抽象，&lt;code&gt;代码设计非常优秀&lt;/code&gt;。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&quot;h12rdd&quot;&gt;&lt;span&gt;&lt;strong&gt;1.2 RDD 抽象&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;  RDD（Resilient Distributed Datasets），弹性分布式数据集，它是对分布式数据集的一种内存抽象，通过受限的共享内存方式来提供容错性，同时这种内存模型使得计算比传统的数据流模型要高效。RDD 具有 5 个重要的特性，如下图所示：&lt;/p&gt;
&lt;img title=&quot;&quot; src=&quot;https://s2.ax1x.com/2019/05/02/EtCoGV.png&quot; alt=&quot;&quot;/&gt;&lt;br/&gt;上图展示了 2 个 RDD 进行 JOIN 操作，体现了 RDD 所具备的 5 个主要特性，如下所示：&lt;br/&gt;  • 1）一组分区&lt;br/&gt;  • 2）计算每一个数据分片的函数&lt;br/&gt;  • 3）RDD 上的一组依赖&lt;br/&gt;  • 4）可选，对于键值对 RDD，有一个 Partitioner（通常是 HashPartitioner）&lt;br/&gt;  • 5）可选，一组 Preferred location 信息（例如，HDFS 文件的 Block 所在 location 信息）&lt;br/&gt;有了上述特性，能够非常好地通过 RDD 来表达分布式数据集，并作为构建 DAG 图的基础：首先抽象一个分布式计算任务的逻辑表示，最终将任务在实际的物理计算环境中进行处理执行。

&lt;/blockquote&gt;
&lt;h3 id=&quot;h13&quot;&gt;&lt;span&gt;&lt;strong&gt;1.3 计算抽象&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;在描述 Spark 中的计算抽象，我们首先需要了解如下几个概念：&lt;br/&gt;1）Application&lt;br/&gt;  • 用户编写的 Spark 程序，完成一个计算任务的处理。它是由一个 Driver 程序和一组运行于 Spark 集群上的 Executor 组成。&lt;br/&gt;2）Job&lt;br/&gt;  • 用户程序中，每次调用 Action 时，逻辑上会生成一个 Job，一个 Job 包含了多个 Stage 。&lt;br/&gt;3）Stage&lt;br/&gt;  • Stage 包括两类：ShuffleMapStage 和 ResultStage，如果用户程序中调用了需要进行 Shuffle 计算的 Operator，如 groupByKey 等，就会以 Shuffle 为边界分成 ShuffleMapStage 和 ResultStage。&lt;br/&gt;4）TaskSet&lt;br/&gt;  • 基于 Stage 可以直接映射为 TaskSet，一个 TaskSet 封装了一次需要运算的、具有相同处理逻辑的 Task，这些 Task 可以并行计算，粗粒度的调度是以 TaskSet 为单位的。&lt;br/&gt;5）Task&lt;br/&gt;  • Task 是在物理节点上运行的基本单位，Task 包含两类：ShuffleMapTask 和 ResultTask，分别对应于 Stage 中 ShuffleMapStage 和 ResultStage 中的一个执行基本单元。&lt;br/&gt;下面，我们看一下，上面这些基本概念之间的关系，如下图所示：&lt;/p&gt;
&lt;img title=&quot;&quot; src=&quot;https://s2.ax1x.com/2019/05/02/EtC45q.png&quot; alt=&quot;&quot;/&gt;&lt;br/&gt;  上图，为了简单，每个 Job 假设都很简单，并且只需要进行一次 Shuffle 处理，所以都对应 2 个 Stage。实际应用中，一个 Job 可能包含若干个 Stage，或者是一个相对复杂的 Stage DAG。&lt;br/&gt;在 Standalone 模式下，默认使用的是 FIFO 这种简单的调度策略，在进行调度的过程中，大概流程如下图所示：&lt;br/&gt;&lt;img title=&quot;&quot; src=&quot;https://s2.ax1x.com/2019/05/02/EtCfVs.png&quot; alt=&quot;&quot;/&gt;&lt;br/&gt;  从用户提交 Spark 程序，最终生成 TaskSet，而在调度时，通过 TaskSetManager 来管理一个 TaskSet（包含一组可在物理节点上执行的 Task），这里面 TaskSet 必须要按照顺序执行才能保证计算结果的正确性，因为 TaskSet 之间是有序依赖的（上溯到 ShuffleMapStage 和 ResultStage），只有一个 TaskSet 中的所有 Task 都运行完成后，才能调度下一个 TaskSet 中的 Task 去执行。

&lt;/blockquote&gt;
&lt;h3 id=&quot;h14&quot;&gt;&lt;span&gt;&lt;strong&gt;1.4 集群模式&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;  Spark 集群在设计的时候，并没有在资源管理的设计上对外封闭，而是充分考虑了未来对接一些更强大的资源管理系统，如 YARN、Mesos 等，所以 Spark 架构设计将资源管理单独抽象出一层，通过这种抽象能够构建一种适合企业当前技术栈的插件式资源管理模块，从而为不同的计算场景提供不同的资源分配与调度策略。Spark 集群模式架构，如下图所示：&lt;/p&gt;
&lt;img title=&quot;&quot; src=&quot;https://s2.ax1x.com/2019/05/02/EtChan.png&quot; alt=&quot;&quot;/&gt;&lt;br/&gt;上图中，Spark集群Cluster Manager目前支持如下三种模式：&lt;br/&gt;1）Standalone 模式&lt;br/&gt;  • Standalone 模式是 Spark 内部默认实现的一种集群管理模式，这种模式是通过集群中的 Master 来统一管理资源，而与 Master 进行资源请求协商的是 Driver 内部的 StandaloneSchedulerBackend（实际上是其内部的 StandaloneAppClient 真正与 Master 通信），后面会详细说明。&lt;br/&gt;2）YARN 模式&lt;br/&gt;  • YARN 模式下，可以将资源的管理统一交给 YARN 集群的 ResourceManager 去管理，选择这种模式，可以更大限度的适应企业内部已有的技术栈，如果企业内部已经在使用 Hadoop 技术构建大数据处理平台。&lt;br/&gt;3）Mesos 模式&lt;br/&gt;  • 随着 Apache Mesos 的不断成熟，一些企业已经在尝试使用 Mesos 构建数据中心的操作系统（DCOS），Spark 构建在 Mesos 之上，能够支持细粒度、粗粒度的资源调度策略（Mesos 的优势），也可以更好地适应企业内部已有技术栈。&lt;br/&gt;  • 那么，Spark 中是怎么考虑满足这一重要的设计决策的呢？也就是说，如何能够保证 Spark 非常容易的让第三方资源管理系统轻松地接入进来。我们深入到类设计的层面看一下，如下类图所示：&lt;br/&gt;&lt;img title=&quot;&quot; src=&quot;https://s2.ax1x.com/2019/05/02/EtCvI1.png&quot; alt=&quot;&quot;/&gt;&lt;br/&gt;  • 可以看出，Task 调度直接依赖 SchedulerBackend，SchedulerBackend 与实际资源管理模块交互实现资源请求。这里面，CoarseGrainedSchedulerBackend 是 Spark 中与资源调度相关的最重要的抽象，它需要抽象出与 TaskScheduler 通信的逻辑，同时还要能够与各种不同的第三方资源管理系统无缝地交互。实际上，CoarseGrainedSchedulerBackend 内部采用了一种 ResourceOffer 的方式来处理资源请求。

&lt;/blockquote&gt;
&lt;h3 id=&quot;h15rpc&quot;&gt;&lt;span&gt;&lt;strong&gt;1.5 RPC 网络通信抽象&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;  Spark RPC 层是基于优秀的网络通信框架 Netty 设计开发的，但是 Spark 提供了一种很好地抽象方式，将底层的通信细节屏蔽起来，而且也能够基于此来设计满足扩展性，比如，如果有其他不基于 Netty 的网络通信框架的新的RPC接入需求，可以很好地扩展而不影响上层的设计。RPC 层设计，如下图类图所示：&lt;/p&gt;
&lt;img title=&quot;&quot; src=&quot;https://s2.ax1x.com/2019/05/02/EtCIP0.png&quot; alt=&quot;&quot;/&gt;&lt;br/&gt;  任何两个 Endpoint 只能通过消息进行通信，可以实现一个 RpcEndpoint 和一个 RpcEndpointRef。想要与 RpcEndpoint 通信，需要获取到该 RpcEndpoint 对应的 RpcEndpointRef 即可，而且管理 RpcEndpoint 和 RpcEndpointRef 创建及其通信的逻辑，统一在 RpcEnv 对象中管理。

&lt;/blockquote&gt;
&lt;h3 id=&quot;h16standalone&quot;&gt;&lt;span&gt;&lt;strong&gt;1.6 启动 Standalone 集群&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;blockquote readability=&quot;7&quot;&gt;
&lt;p&gt;  Standalone 模式下，Spark 集群采用了简单的 Master-Slave 架构模式，Master 统一管理所有的 Worker，这种模式很常见，我们简单地看下 Spark Standalone 集群启动的基本流程，如下图所示：&lt;/p&gt;
&lt;img title=&quot;&quot; src=&quot;https://s2.ax1x.com/2019/05/02/EtCT2T.png&quot; alt=&quot;&quot;/&gt;&lt;br/&gt;可以看到，Spark 集群采用的消息的模式进行通信，也就是 EDA 架构模式，借助于 RPC 层的优雅设计，任何两个 Endpoint 想要通信，发送消息并携带数据即可。上图的流程描述如下所示：&lt;br/&gt;  • 1）Master 启动时首先创一个 RpcEnv 对象，负责管理所有通信逻辑。&lt;br/&gt;  • 2）Master 通过 RpcEnv 对象创建一个 Endpoint，Master 就是一个 Endpoint，Worker 可以与其进行通信。&lt;br/&gt;  • 3）Worker 启动时也是创一个 RpcEnv 对象。&lt;br/&gt;  • 4）Worker 通过 RpcEnv 对象创建一个 Endpoint。&lt;br/&gt;  • 5）Worker 通过 RpcEnv 对，建立到 Master 的连接，获取到一个 RpcEndpointRef 对象，通过该对象可以与 Master 通信。&lt;br/&gt;  • 6）Worker 向 Master 注册，注册内容包括主机名、端口、CPU Core 数量、内存数量。&lt;br/&gt;  • 7）Master 接收到 Worker 的注册，将注册信息维护在内存中的 Table 中，其中还包含了一个到 Worker 的 RpcEndpointRef 对象引用。&lt;br/&gt;  • 8）Master 回复 Worker 已经接收到注册，告知 Worker 已经注册成功。&lt;br/&gt;  • 9）此时如果有用户提交 Spark 程序，Master 需要协调启动 Driver；而 Worker 端收到成功注册响应后，开始周期性向 Master 发送心跳。

&lt;/blockquote&gt;
&lt;h3 id=&quot;h17&quot;&gt;&lt;span&gt;&lt;strong&gt;1.7 核心组件&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;blockquote readability=&quot;7&quot;&gt;
&lt;p&gt;  集群处理计算任务的运行时（即用户提交了 Spark 程序），最核心的顶层组件就是 Driver 和 Executor，它们内部管理很多重要的组件来协同完成计算任务，核心组件栈如下图所示：&lt;/p&gt;
&lt;img title=&quot;&quot; src=&quot;https://s2.ax1x.com/2019/05/02/EtC7xU.png&quot; alt=&quot;&quot;/&gt;&lt;br/&gt;  Driver 和 Executor 都是运行时创建的组件，一旦用户程序运行结束，他们都会释放资源，等待下一个用户程序提交到集群而进行后续调度。上图，我们列出了大多数组件，其中 SparkEnv 是一个重量级组件，他们内部包含计算过程中需要的主要组件，而且，Driver 和 Executor 共同需要的组件在 SparkEnv 中也包含了很多。这里，我们不做过多详述，后面交互流程等处会说明大部分组件负责的功能。

&lt;/blockquote&gt;
&lt;h3 id=&quot;h18&quot;&gt;&lt;span&gt;&lt;strong&gt;1.8 核心组件交互流程&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;  在 Standalone 模式下，Spark 中各个组件之间交互还是比较复杂的，但是对于一个通用的分布式计算系统来说，这些都是非常重要而且比较基础的交互。首先，为了理解组件之间的主要交互流程，我们给出一些基本要点：&lt;br/&gt;  • 一个 Application 会启动一个 Driver&lt;br/&gt;  • 一个 Driver 负责跟踪管理该 Application 运行过程中所有的资源状态和任务状态&lt;br/&gt;  • 一个 Driver 会管理一组 Executor&lt;br/&gt;  • 一个 Executor 只执行属于一个 Driver 的 Task&lt;br/&gt;核心组件之间的主要交互流程，如下图所示：&lt;/p&gt;
&lt;img title=&quot;&quot; src=&quot;https://s2.ax1x.com/2019/05/02/EtCbMF.png&quot; alt=&quot;&quot;/&gt;&lt;br/&gt;上图中，通过不同颜色或类型的线条，给出了如下 6 个核心的交互流程，我们会详细说明：&lt;br/&gt;&lt;strong&gt;橙色：提交用户 Spark 程序&lt;/strong&gt;&lt;br/&gt;用户提交一个 Spark 程序，主要的流程如下所示：&lt;br/&gt;  •1）用户 spark-submit 脚本提交一个 Spark 程序，会创建一个 ClientEndpoint 对象，该对象负责与 Master 通信交互&lt;br/&gt;  •2）ClientEndpoint 向 Master 发送一个 RequestSubmitDriver 消息，表示提交用户程序&lt;br/&gt;  •3）Master 收到 RequestSubmitDriver 消息，向 ClientEndpoint 回复 SubmitDriverResponse，表示用户程序已经完成注册&lt;br/&gt;  •4）ClientEndpoint 向 Master 发送 RequestDriverStatus 消息，请求 Driver 状态&lt;br/&gt;  •5）如果当前用户程序对应的 Driver 已经启动，则 ClientEndpoint 直接退出，完成提交用户程序&lt;br/&gt;&lt;strong&gt;紫色：启动 Driver 进程&lt;/strong&gt;&lt;br/&gt;当用户提交用户 Spark 程序后，需要启动 Driver 来处理用户程序的计算逻辑，完成计算任务，这时 Master 协调需要启动一个 Driver，具体流程如下所示：&lt;br/&gt;  •1）Maser 内存中维护着用户提交计算的任务 Application，每次内存结构变更都会触发调度，向 Worker 发送 LaunchDriver 请求&lt;br/&gt;  •2）Worker 收到 LaunchDriver 消息，会启动一个 DriverRunner 线程去执行 LaunchDriver 的任务&lt;br/&gt;  •3）DriverRunner 线程在 Worker 上启动一个新的 JVM 实例，该 JVM 实例内运行一个 Driver 进程，该 Driver 会创建 SparkContext 对象&lt;br/&gt;&lt;strong&gt;红色：注册 Application&lt;/strong&gt;&lt;br/&gt;Dirver 启动以后，它会创建 SparkContext 对象，初始化计算过程中必需的基本组件，并向 Master 注册 Application，流程描述如下：&lt;br/&gt;  •1）创建 SparkEnv 对象，创建并管理一些数基本组件&lt;br/&gt;  •2）创建 TaskScheduler，负责 Task 调度&lt;br/&gt;  •3）创建 StandaloneSchedulerBackend，负责与 ClusterManager 进行资源协商&lt;br/&gt;  •4）创建 DriverEndpoint，其它组件可以与 Driver 进行通信&lt;br/&gt;  •5）在 StandaloneSchedulerBackend 内部创建一个 StandaloneAppClient，负责处理与 Master 的通信交互&lt;br/&gt;  •6）StandaloneAppClient 创建一个 ClientEndpoint，实际负责与 Master 通信&lt;br/&gt;  •7）ClientEndpoint 向 Master 发送 RegisterApplication 消息，注册 Application&lt;br/&gt;  •8）Master 收到 RegisterApplication 请求后，回复 ClientEndpoint 一个 RegisteredApplication 消息，表示已经注册成功&lt;br/&gt;&lt;strong&gt;蓝色：启动 Executor 进程&lt;/strong&gt;&lt;br/&gt;  •1）Master 向 Worker 发送 LaunchExecutor 消息，请求启动 Executor；同时 Master 会向 Driver 发送 ExecutorAdded 消息，表示 Master 已经新增了一个 Executor（此时还未启动）&lt;br/&gt;  •2）Worker 收到 LaunchExecutor 消息，会启动一个 ExecutorRunner 线程去执行 LaunchExecutor 的任务&lt;br/&gt;  •3）Worker 向 Master 发送 ExecutorStageChanged 消息，通知 Executor 状态已发生变化&lt;br/&gt;  •4）Master 向 Driver 发送 ExecutorUpdated 消息，此时 Executor 已经启动&lt;br/&gt;&lt;strong&gt;粉色：启动 Task 执行&lt;/strong&gt;&lt;br/&gt;  •1）StandaloneSchedulerBackend 启动一个 DriverEndpoint&lt;br/&gt;  •2）DriverEndpoint 启动后，会周期性地检查 Driver 维护的 Executor 的状态，如果有空闲的 Executor 便会调度任务执行&lt;br/&gt;  •3）DriverEndpoint 向 TaskScheduler 发送 Resource Offer 请求&lt;br/&gt;  •4）如果有可用资源启动 Task，则 DriverEndpoint 向 Executor 发送 LaunchTask 请求&lt;br/&gt;  •5）Executor 进程内部的 CoarseGrainedExecutorBackend 调用内部的 Executor 线程的 launchTask 方法启动 Task&lt;br/&gt;  •6）Executor 线程内部维护一个线程池，创建一个 TaskRunner 线程并提交到线程池执行&lt;br/&gt;&lt;strong&gt;绿色：Task 运行完成&lt;/strong&gt;&lt;br/&gt;  •1）Executor 进程内部的 Executor 线程通知 CoarseGrainedExecutorBackend，Task 运行完成&lt;br/&gt;  •2）CoarseGrainedExecutorBackend 向 DriverEndpoint 发送 StatusUpdated 消息，通知 Driver 运行的 Task 状态发生变更&lt;br/&gt;  •3）StandaloneSchedulerBackend 调用T askScheduler 的 updateStatus 方法更新 Task 状态&lt;br/&gt;  •4）StandaloneSchedulerBackend 继续调用 TaskScheduler 的 resourceOffers 方法，调度其他任务运行

&lt;/blockquote&gt;
&lt;h3 id=&quot;h19block&quot;&gt;&lt;span&gt;&lt;strong&gt;1.9 Block 管理&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;  Block 管理，主要是为 Spark 提供的 Broadcast 机制提供服务支撑的。Spark 中内置采用 TorrentBroadcast 实现，该 Broadcast 变量对应的数据（Task 数据）或数据集（如 RDD），默认会被切分成若干 4M 大小的 Block，Task 运行过程中读取到该 Broadcast 变量，会以 4M 为单位的 Block 为拉取数据的最小单位，最后将所有的 Block 合并成 Broadcast 变量对应的完整数据或数据集。将数据切分成 4M 大小的 Block，Task 从多个 Executor 拉取 Block，可以非常好地均衡网络传输负载，提高整个计算集群的稳定性。&lt;br/&gt;  通常，用户程序在编写过程中，会对某个变量进行 Broadcast，该变量称为 Broadcast 变量。在实际物理节点的 Executor 上执行 Task 时，需要读取 Broadcast 变量对应的数据集，那么此时会根据需要拉取 DAG 执行流上游已经生成的数据集。采用 Broadcast 机制，可以有效地降低数据在计算集群环境中传输的开销。具体地，如果一个用户对应的程序中的 Broadcast 变量，对应着一个数据集，它在计算过程中需要拉取对应的数据，如果在同一个物理节点上运行着多个 Task，多个 Task 都需要该数据，有了 Broadcast 机制，只需要拉取一份存储在本地物理机磁盘即可，供多个 Task 计算共享。&lt;br/&gt;  另外，用户程序在进行调度过程中，会根据调度策略将 Task 计算逻辑数据（代码）移动到对应的 Worker 节点上，最优情况是对本地数据进行处理，那么代码（序列化格式）也需要在网络上传输，也是通过 Broadcast 机制进行传输，不过这种方式是首先将代码序列化到 Driver 所在 Worker 节点，后续如果 Task 在其他 Worker 中执行，需要读取对应代码的 Broadcast 变量，首先就是从 Driver 上拉取代码数据，接着其他晚一些被调度的 Task 可能直接从其他 Worker 上的 Executor 中拉取代码数据。&lt;br/&gt;  我们通过以 Broadcast 变量 taskBinary 为例，说明 Block 是如何管理的，如下图所示：&lt;/p&gt;
&lt;img title=&quot;&quot; src=&quot;https://s2.ax1x.com/2019/05/02/EtCjaR.png&quot; alt=&quot;&quot;/&gt;&lt;br/&gt;  上图中，Driver 负责管理所有的 Broadcast 变量对应的数据所在的 Executor，即一个 Executor 维护一个 Block 列表。在 Executor 中运行一个 Task 时，执行到对应的 Broadcast 变量 taskBinary，如果本地没有对应的数据，则会向 Driver 请求获取 Broadcast 变量对应的数据，包括一个或多个 Block 所在的 Executor 列表，然后该 Executor 根据 Driver 返回的 Executor 列表，直接通过底层的 BlockTransferService 组件向对应 Executor 请求拉取 Block。Executor 拉取到的 Block 会缓存到本地，同时向 Driver 报告该 Executor 上存在的 Block 信息，以供其他 Executor 执行 Task 时获取 Broadcast 变量对应的数据。

&lt;/blockquote&gt;
&lt;h3 id=&quot;h110&quot;&gt;&lt;span&gt;&lt;strong&gt;1.10整体应用&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;blockquote readability=&quot;7&quot;&gt;
&lt;p&gt;  用户通过 spark-submit 提交或者运行 spark-shell REPL，集群创建 Driver，Driver 加载 Application，最后 Application 根据用户代码转化为 RDD，RDD 分解为 Tasks，Executor 执行 Task 等系列知识，整体交互蓝图如下：&lt;/p&gt;
&lt;img title=&quot;&quot; src=&quot;https://s2.ax1x.com/2019/05/02/EtCXZ9.png&quot; alt=&quot;&quot;/&gt;&lt;/blockquote&gt;
&lt;h2 id=&quot;h2spark&quot;&gt;&lt;span&gt;&lt;strong&gt;第2章 Spark 通信架构&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;
&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;  Spark作为分布式计算框架，多个节点的设计与相互通信模式是其重要的组成部分。Spark 一开始使用 Akka 作为内部通信部件。在 Spark 1.3 年代，为了解决大块数据（如 Shuffle）的传输问题，Spark 引入了 Netty 通信框架。到了 Spark 1.6，Spark 可以配置使用 Akka 或者 Netty 了，这意味着 Netty 可以完全替代 Akka了。再到 Spark 2，Spark 已经完全抛弃 Akka了，全部使用 Netty 了。&lt;br/&gt;  为什么呢？官方的解释是：&lt;br/&gt;  •1）很多 Spark 用户也使用 Akka，但是由于 Akka 不同版本之间无法互相通信，这就要求用户必须使用跟 Spark 完全一样的 Akka 版本，导致用户无法升级 Akka。&lt;br/&gt;  •2）Spark 的 Akka 配置是针对 Spark 自身来调优的，可能跟用户自己代码中的 Akka 配置冲突。&lt;br/&gt;  •3）Spark 用的 Akka 特性很少，这部分特性很容易自己实现。同时，这部分代码量相比 Akka 来说少很多，debug 比较容易。如果遇到什么 bug，也可以自己马上 fix，不需要等 Akka 上游发布新版本。而且，Spark 升级 Akka 本身又因为第一点会强制要求用户升级他们使用的 Akka，对于某些用户来说是不现实的。&lt;br/&gt;SPARK 的通信架构 - Actor 比较，如下图所示：&lt;/p&gt;
&lt;img title=&quot;&quot; src=&quot;https://s2.ax1x.com/2019/05/02/EtPSG6.png&quot; alt=&quot;&quot;/&gt;&lt;/blockquote&gt;
&lt;h3 id=&quot;h21&quot;&gt;&lt;span&gt;&lt;strong&gt;2.1 通信组件概览&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;对源码分析，对于设计思路理解如下：&lt;/p&gt;
&lt;img title=&quot;&quot; src=&quot;https://s2.ax1x.com/2019/05/02/EtCzPx.png&quot; alt=&quot;&quot;/&gt;&lt;br/&gt;  •1）RpcEndpoint：RPC 端点，Spark 针对于每个节点（Client/Master/Worker）都称之一个 Rpc 端点且都实现 RpcEndpoint 接口，内部根据不同端点的需求，设计不同的消息和不同的业务处理，如果需要发送（询问）则调用 Dispatcher。&lt;br/&gt;  •2）RpcEnv：RPC 上下文环境，每个 Rpc 端点运行时依赖的上下文环境称之为 RpcEnv。&lt;br/&gt;  •3）Dispatcher：消息分发器，针对于 RPC 端点需要发送消息或者从远程 RPC 接收到的消息，分发至对应的指令收件箱/发件箱。如果指令接收方是自己存入收件箱，如果指令接收方为非自身端点，则放入发件箱。&lt;br/&gt;  •4）Inbox：指令消息收件箱，一个本地端点对应一个收件箱，Dispatcher 在每次向 Inbox 存入消息时，都将对应 EndpointData 加入内部待 Receiver Queue中，另外 Dispatcher 创建时会启动一个单独线程进行轮询 Receiver Queue，进行收件箱消息消费。&lt;br/&gt;  •5）OutBox：指令消息发件箱，一个远程端点对应一个发件箱，当消息放入 Outbox 后，紧接着将消息通过 TransportClient 发送出去。消息放入发件箱以及发送过程是在同一个线程中进行，这样做的主要原因是远程消息分为 RpcOutboxMessage，OneWayOutboxMessage 两种消息，而针对于需要应答的消息直接发送且需要得到结果进行处理&lt;br/&gt;  •6）TransportClient：Netty 通信客户端，根据 OutBox 消息的 receiver 信息，请求对应远程 TransportServer。&lt;br/&gt;  •7）TransportServer：Netty 通信服务端，一个 RPC 端点一个 TransportServer，接受远程消息后调用 Dispatcher 分发消息至对应收发件箱。&lt;br/&gt;&lt;code&gt;注意&lt;/code&gt;：&lt;br/&gt;  TransportClient 与 TransportServer 通信虚线表示两个 RpcEnv 之间的通信，图示没有单独表达式。&lt;br/&gt;  一个 Outbox 一个 TransportClient，图示没有单独表达式。&lt;br/&gt;  一个 RpcEnv 中存在两个 RpcEndpoint，一个代表本身启动的 RPC 端点，另外一个为 RpcEndpointVerifier。&lt;br/&gt;Spark的通信架构 – 高层视图&lt;br/&gt;&lt;img title=&quot;&quot; src=&quot;https://s2.ax1x.com/2019/05/02/EtP9xO.png&quot; alt=&quot;&quot;/&gt;&lt;br/&gt;Spark 的通信架构 – 类图&lt;br/&gt;&lt;img title=&quot;&quot; src=&quot;https://s2.ax1x.com/2019/05/02/EtPise.png&quot; alt=&quot;&quot;/&gt;&lt;/blockquote&gt;
&lt;h3 id=&quot;h22endpoint&quot;&gt;&lt;span&gt;&lt;strong&gt;2.2 Endpoint 启动过程&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;启动的流程如下：&lt;/p&gt;
&lt;img title=&quot;&quot; src=&quot;https://s2.ax1x.com/2019/05/02/EtPVII.png&quot; alt=&quot;&quot;/&gt;&lt;br/&gt;Endpoint 启动后，默认会向 Inbox 中添加 OnStart 消息，不同的端点（Master/Worker/Client）消费 OnStart 指令时，进行相关端点的启动额外处理。&lt;br/&gt;Endpoint 启动时，会默认启动 TransportServer，且启动结束后会进行一次同步测试 rpc 可用性（askSync-BoundPortsRequest）。&lt;br/&gt;Dispatcher 作为一个分发器，内部存放了 Inbox，Outbox 的等相关句柄和存放了相关处理状态数据，结构大致如下：&lt;br/&gt;&lt;img title=&quot;&quot; src=&quot;https://s2.ax1x.com/2019/05/02/EtPpRK.png&quot; alt=&quot;&quot;/&gt;&lt;/blockquote&gt;
&lt;h3 id=&quot;h23endpointsendask&quot;&gt;&lt;span&gt;&lt;strong&gt;2.3 Endpoint Send&amp;amp;Ask 流程&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;Endpoint 的消息发送与请求流程，如下：&lt;/p&gt;
&lt;img title=&quot;&quot; src=&quot;https://s2.ax1x.com/2019/05/02/EtPPMD.png&quot; alt=&quot;&quot;/&gt;&lt;br/&gt;Endpoint 根据业务需要存入两个维度的消息组合：send/ask 某个消息，receiver 是自身与非自身&lt;br/&gt;  •1）OneWayMessage：send + 自身，直接存入收件箱&lt;br/&gt;  •2）OneWayOutboxMessage：send + 非自身，存入发件箱并直接发送&lt;br/&gt;  •3）RpcMessage：ask + 自身，直接存入收件箱，另外还需要存入 LocalNettyRpcCallContext，需要回调后再返回&lt;br/&gt;  •4）RpcOutboxMessage：ask + 非自身，存入发件箱并直接发送，需要回调后再返回

&lt;/blockquote&gt;
&lt;h3 id=&quot;h24endpointreceive&quot;&gt;&lt;span&gt;&lt;strong&gt;2.4 Endpoint Receive 流程&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;Endpoint 的消息的接收，流程如下：&lt;/p&gt;
&lt;img title=&quot;&quot; src=&quot;https://s2.ax1x.com/2019/05/02/EtPAZd.png&quot; alt=&quot;&quot;/&gt;&lt;br/&gt;上图 ServerBootstrap 为 Netty 启动服务，SocketChanel为Netty 数据通道。&lt;br/&gt;上述包含 TransportSever 启动与消息接收两个流程。

&lt;/blockquote&gt;
&lt;h3 id=&quot;h25endpointinbox&quot;&gt;&lt;span&gt;&lt;strong&gt;2.5 Endpoint Inbox 处理流程&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;Spark 在 Endpoint 的设计上核心设计即为 Inbox 与 Outbox，其中 Inbox 核心要点为：&lt;br/&gt;  •1）内部的处理流程拆分为多个消息指令（InboxMessage）存放入 Inbox。&lt;br/&gt;  •2）当 Dispatcher 启动最后，会启动一个名为【dispatcher-event-loop】的线程扫描 Inbox 待处理 InboxMessage，并调用 Endpoint 根据 InboxMessage 类型做相应处理&lt;br/&gt;  •3）当 Dispatcher 启动最后，默认会向 Inbox 存入 OnStart 类型的 InboxMessage，Endpoint 在根据 OnStart 指令做相关的额外启动工作，三端启动后所有的工作都是对 OnStart 指令处理衍生出来的，因此可以说 OnStart 指令是相互通信的源头。&lt;/p&gt;
&lt;img title=&quot;&quot; src=&quot;https://s2.ax1x.com/2019/05/02/EtPFqH.png&quot; alt=&quot;&quot;/&gt;&lt;br/&gt;消息指令类型大致如下三类：&lt;br/&gt;  •1）OnStart/OnStop&lt;br/&gt;  •2）RpcMessage/OneWayMessage&lt;br/&gt;  •3）RemoteProcessDisconnected/RemoteProcessConnected/RemoteProcessConnectionError&lt;/blockquote&gt;
&lt;h3 id=&quot;h26endpoint&quot;&gt;&lt;span&gt;&lt;strong&gt;2.6 Endpoint 画像&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;img title=&quot;&quot; src=&quot;https://s2.ax1x.com/2019/05/02/EtPEdA.png&quot; alt=&quot;&quot;/&gt;&lt;h2 id=&quot;h3&quot;&gt;&lt;span&gt;&lt;strong&gt;第3章 脚本解析&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;
&lt;p&gt;在看源码之前，我们一般会看相关脚本了解其初始化信息以及 Bootstrap 类，Spark 也不例外，而 Spark 中相关的脚本如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;shell language-shell hljs&quot;&gt;&lt;span class=&quot;hljs-meta&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;bash&quot;&gt;SPARK_HOME%/sbin/start-master.sh&lt;/span&gt;&lt;br/&gt;&lt;span class=&quot;hljs-meta&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;bash&quot;&gt;SPARK_HOME%/sbin/start-slaves.sh&lt;/span&gt;&lt;br/&gt;&lt;span class=&quot;hljs-meta&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;bash&quot;&gt;SPARK_HOME%/sbin/start-all.sh&lt;/span&gt;&lt;br/&gt;&lt;span class=&quot;hljs-meta&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;bash&quot;&gt;SPARK_HOME%/bin/spark-submit&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;启动脚本中对于公共处理部分进行抽取为独立的脚本，如下：&lt;/p&gt;
&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;脚本&lt;/th&gt;
&lt;th&gt;说明&lt;/th&gt;
&lt;/tr&gt;&lt;/thead&gt;&lt;tbody readability=&quot;3.5&quot;&gt;&lt;tr readability=&quot;3&quot;&gt;&lt;td&gt;sbin/spark-config.sh&lt;/td&gt;
&lt;td&gt;初始化环境变量 SPARK_CONF_DIR, PYTHONPATH&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;bin/load-spark-env.sh&lt;/td&gt;
&lt;td&gt;初始化环境变量 SPARK_SCALA_VERSION，调用 %SPARK_HOME%&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;conf/spark-env.sh&lt;/td&gt;
&lt;td&gt;加载用户自定义环境变量&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;h3 id=&quot;h31startdaemonsh&quot;&gt;&lt;span&gt;&lt;strong&gt;3.1 start-daemon.sh&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;主要完成进程相关基本信息初始化，然后调用 bin/spark-class 进行守护进程启动，该脚本是创建端点的通用脚本，三端各自脚本都会调用 spark-daemon.sh 脚本启动各自进程&lt;/p&gt;
&lt;img title=&quot;&quot; src=&quot;https://s2.ax1x.com/2019/05/02/EtPuz8.png&quot; alt=&quot;&quot;/&gt;&lt;p&gt;详解如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;java language-java hljs&quot;&gt;&lt;span class=&quot;hljs-number&quot;&gt;1&lt;/span&gt;）初始化 SPRK_HOME、SPARK_CONF_DIR、SPARK_IDENT_STRING、SPARK_LOG_DIR 环境变量 (如果不存在)&lt;br/&gt;&lt;span class=&quot;hljs-number&quot;&gt;2&lt;/span&gt;）初始化日志并测试日志文件夹读写权限，初始化 PID 目录并校验 PID 信息&lt;br/&gt;&lt;span class=&quot;hljs-number&quot;&gt;3&lt;/span&gt;）调用 /bin/spark-&lt;span class=&quot;hljs-class&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;class&lt;/span&gt; 脚本，/&lt;span class=&quot;hljs-title&quot;&gt;bin&lt;/span&gt;/&lt;span class=&quot;hljs-title&quot;&gt;spark&lt;/span&gt;-&lt;span class=&quot;hljs-title&quot;&gt;class&lt;/span&gt; 见下面&lt;br/&gt;&lt;/span&gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;h32sparkclass&quot;&gt;&lt;span&gt;&lt;strong&gt;3.2 spark-class&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;Master 调用举例：&lt;/p&gt;
&lt;pre readability=&quot;4&quot;&gt;
&lt;code class=&quot;java language-java hljs&quot; readability=&quot;5.5&quot;&gt;bin/spark-&lt;span class=&quot;hljs-class&quot; readability=&quot;7&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;class&lt;/span&gt; \&lt;br/&gt;--&lt;span class=&quot;hljs-title&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;hljs-title&quot;&gt;org&lt;/span&gt;.&lt;span class=&quot;hljs-title&quot;&gt;apache&lt;/span&gt;.&lt;span class=&quot;hljs-title&quot;&gt;spark&lt;/span&gt;.&lt;span class=&quot;hljs-title&quot;&gt;deploy&lt;/span&gt;.&lt;span class=&quot;hljs-title&quot;&gt;master&lt;/span&gt;.&lt;span class=&quot;hljs-title&quot;&gt;Master&lt;/span&gt; \&lt;br/&gt;--&lt;span class=&quot;hljs-title&quot;&gt;host&lt;/span&gt; $&lt;span class=&quot;hljs-title&quot;&gt;SPARK_MASTER_HOST&lt;/span&gt; \&lt;br/&gt;--&lt;span class=&quot;hljs-title&quot;&gt;port&lt;/span&gt; $&lt;span class=&quot;hljs-title&quot;&gt;SPARK_MASTER_PORT&lt;/span&gt; \&lt;br/&gt;--&lt;span class=&quot;hljs-title&quot;&gt;webui&lt;/span&gt;-&lt;span class=&quot;hljs-title&quot;&gt;port&lt;/span&gt; $&lt;span class=&quot;hljs-title&quot;&gt;SPARK_MASTER_WEBUI_PORT&lt;/span&gt; $&lt;span class=&quot;hljs-title&quot;&gt;ORIGINAL_ARGS&lt;/span&gt;&lt;p&gt;1）初始化 &lt;span class=&quot;hljs-title&quot;&gt;RUNNER&lt;/span&gt;(&lt;span class=&quot;hljs-title&quot;&gt;java&lt;/span&gt;)、&lt;span class=&quot;hljs-title&quot;&gt;SPARK_JARS_DIR&lt;/span&gt; (%&lt;span class=&quot;hljs-title&quot;&gt;SPARK_HOME&lt;/span&gt;%/&lt;span class=&quot;hljs-title&quot;&gt;jars&lt;/span&gt;)、&lt;span class=&quot;hljs-title&quot;&gt;LAUNCH_CLASSPATH&lt;/span&gt; 信息&lt;br/&gt;2）调用 (&quot;$&lt;span class=&quot;hljs-title&quot;&gt;RUNNER&lt;/span&gt;&quot; -&lt;span class=&quot;hljs-title&quot;&gt;Xmx128m&lt;/span&gt; -&lt;span class=&quot;hljs-title&quot;&gt;cp&lt;/span&gt; &quot;$&lt;span class=&quot;hljs-title&quot;&gt;LAUNCH_CLASSPATH&lt;/span&gt;&quot; &lt;span class=&quot;hljs-title&quot;&gt;org&lt;/span&gt;.&lt;span class=&quot;hljs-title&quot;&gt;apache&lt;/span&gt;.&lt;span class=&quot;hljs-title&quot;&gt;spark&lt;/span&gt;.&lt;span class=&quot;hljs-title&quot;&gt;launcher&lt;/span&gt;.&lt;span class=&quot;hljs-title&quot;&gt;Main&lt;/span&gt; &quot;$@&quot;) 获取最终执行的 &lt;span class=&quot;hljs-title&quot;&gt;shell&lt;/span&gt; 语句&lt;br/&gt;3）执行最终的 &lt;span class=&quot;hljs-title&quot;&gt;shell&lt;/span&gt; 语句，示例如下：&lt;/p&gt;&lt;p&gt;/&lt;span class=&quot;hljs-title&quot;&gt;opt&lt;/span&gt;/&lt;span class=&quot;hljs-title&quot;&gt;module&lt;/span&gt;/&lt;span class=&quot;hljs-title&quot;&gt;jdk1&lt;/span&gt;.8.0&lt;span class=&quot;hljs-title&quot;&gt;_144&lt;/span&gt; \&lt;br/&gt;-&lt;span class=&quot;hljs-title&quot;&gt;cp&lt;/span&gt; /&lt;span class=&quot;hljs-title&quot;&gt;opt&lt;/span&gt;/&lt;span class=&quot;hljs-title&quot;&gt;module&lt;/span&gt;/&lt;span class=&quot;hljs-title&quot;&gt;spark&lt;/span&gt;-2.1.1-&lt;span class=&quot;hljs-title&quot;&gt;bin&lt;/span&gt;-&lt;span class=&quot;hljs-title&quot;&gt;hadoop2&lt;/span&gt;.7/&lt;span class=&quot;hljs-title&quot;&gt;conf&lt;/span&gt;/:/&lt;span class=&quot;hljs-title&quot;&gt;opt&lt;/span&gt;/&lt;span class=&quot;hljs-title&quot;&gt;module&lt;/span&gt;/&lt;span class=&quot;hljs-title&quot;&gt;spark&lt;/span&gt;-2.1.1-&lt;span class=&quot;hljs-title&quot;&gt;bin&lt;/span&gt;-&lt;span class=&quot;hljs-title&quot;&gt;hadoop2&lt;/span&gt;.7/&lt;span class=&quot;hljs-title&quot;&gt;jars&lt;/span&gt;/*:/&lt;span class=&quot;hljs-title&quot;&gt;opt&lt;/span&gt;/&lt;span class=&quot;hljs-title&quot;&gt;module&lt;/span&gt;/&lt;span class=&quot;hljs-title&quot;&gt;hadoop&lt;/span&gt;-2.7.2/&lt;span class=&quot;hljs-title&quot;&gt;etc&lt;/span&gt;/&lt;span class=&quot;hljs-title&quot;&gt;hadoop&lt;/span&gt;/ \&lt;br/&gt;-&lt;span class=&quot;hljs-title&quot;&gt;Xmx1g&lt;/span&gt; \&lt;br/&gt;-&lt;span class=&quot;hljs-title&quot;&gt;XX&lt;/span&gt;:&lt;span class=&quot;hljs-title&quot;&gt;MaxPermSize&lt;/span&gt;&lt;/p&gt;&lt;/span&gt;=&lt;span class=&quot;hljs-number&quot;&gt;256&lt;/span&gt;m \&lt;br/&gt;org.apache.spark.deploy.master.Master \&lt;br/&gt;--host hadoop102 \&lt;br/&gt;--port &lt;span class=&quot;hljs-number&quot;&gt;7077&lt;/span&gt; \&lt;br/&gt;--webui-port &lt;span class=&quot;hljs-number&quot;&gt;8080&lt;/span&gt;&lt;p&gt;如果是 Client，那么可能为 r，或者 python 脚本。&lt;br/&gt;&lt;/p&gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;h33startmastersh&quot;&gt;&lt;span&gt;&lt;strong&gt;3.3 start-master.sh&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;启动 Master 的脚本，流程如下：&lt;/p&gt;
&lt;img title=&quot;&quot; src=&quot;https://s2.ax1x.com/2019/05/02/EtP3Zj.png&quot; alt=&quot;&quot;/&gt;&lt;p&gt;详解如下：&lt;/p&gt;
&lt;pre readability=&quot;4.5&quot;&gt;
&lt;code class=&quot;java language-java hljs&quot; readability=&quot;3&quot;&gt;&lt;span class=&quot;hljs-number&quot;&gt;1&lt;/span&gt;）用户执行 start-master.sh 脚本，初始化环境变量 SPARK_HOME (如果 PATH 不存在 SPARK_HOME，初始化脚本的上级目录为 SPARK_HOME)，调用 spark-config.sh，调用 load-spark-env.sh&lt;br/&gt;&lt;span class=&quot;hljs-number&quot;&gt;2&lt;/span&gt;）如果环境变量 SPARK_MASTER_HOST、SPARK_MASTER_PORT、SPARK_MASTER_WEBUI_PORT 不存在，进行初始化 &lt;span class=&quot;hljs-number&quot;&gt;7077&lt;/span&gt;，hostname -f，&lt;span class=&quot;hljs-number&quot;&gt;8080&lt;/span&gt;&lt;br/&gt;&lt;span class=&quot;hljs-number&quot;&gt;3&lt;/span&gt;）调用 spark-daemon.sh 脚本启动 master 进程，如下：&lt;p&gt;spark-daemon.sh start org.apache.spark.deploy.master.Master &lt;span class=&quot;hljs-number&quot;&gt;1&lt;/span&gt; \&lt;br/&gt;--host $SPARK_MASTER_HOST \&lt;br/&gt;--port $SPARK_MASTER_PORT \&lt;br/&gt;--webui-port $SPARK_MASTER_WEBUI_PORT $ORIGINAL_ARGS）&lt;br/&gt;&lt;/p&gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;h34startslavessh&quot;&gt;&lt;span&gt;&lt;strong&gt;3.4 start-slaves.sh&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;启动 Worker 的脚本，流程如下：&lt;/p&gt;
&lt;img title=&quot;&quot; src=&quot;https://s2.ax1x.com/2019/05/02/EtPmJP.png&quot; alt=&quot;&quot;/&gt;&lt;p&gt;详解如下：&lt;/p&gt;
&lt;pre readability=&quot;4.5&quot;&gt;
&lt;code class=&quot;java language-java hljs&quot; readability=&quot;3&quot;&gt;&lt;span class=&quot;hljs-number&quot;&gt;1&lt;/span&gt;）用户执行 start-slaves.sh 脚本，初始化环境变量 SPARK_HOME，调用 spark-config.sh，调用 load-spark-env.sh，初始化 Master host/port 信息&lt;br/&gt;&lt;span class=&quot;hljs-number&quot;&gt;2&lt;/span&gt;）调用 slaves.sh 脚本，读取 conf/slaves 文件并遍历，通过 ssh 连接到对应 slave 节点，启动 ${SPARK_HOME}/sbin/start-slave.sh spark:&lt;br/&gt;&lt;span class=&quot;hljs-number&quot;&gt;3&lt;/span&gt;）start-slave.sh 在各个节点中，初始化环境变量 SPARK_HOME，调用 spark-config.sh，调用 load-spark-env.sh，根据 $SPARK_WORKER_INSTANCES 计算 WEBUI_PORT 端口 (worker 端口号依次递增) 并启动 Worker 进程，如下：&lt;p&gt;${SPARK_HOME}/sbin/spark-daemon.sh \&lt;br/&gt;start org.apache.spark.deploy.worker.Worker $WORKER_NUM \&lt;br/&gt;--webui-port &lt;span class=&quot;hljs-string&quot;&gt;&quot;$WEBUI_PORT&quot;&lt;/span&gt; $PORT_FLAG $PORT_NUM $MASTER &lt;span class=&quot;hljs-string&quot;&gt;&quot;$@&quot;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;h35startallsh&quot;&gt;&lt;span&gt;&lt;strong&gt;3.5 start-all.sh&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;属于快捷脚本，内部调用 start-master.sh 与 start-slaves.sh 脚本，并无额外工作。&lt;/p&gt;
&lt;h3 id=&quot;h36sparksubmit&quot;&gt;&lt;span&gt;&lt;strong&gt;3.6 spark-submit&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;任务提交的基本脚本，流程如下：&lt;/p&gt;
&lt;img title=&quot;&quot; src=&quot;https://s2.ax1x.com/2019/05/02/EtPeit.png&quot; alt=&quot;&quot;/&gt;&lt;p&gt;详解如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;java language-java hljs&quot; readability=&quot;4.5&quot;&gt;&lt;span class=&quot;hljs-number&quot;&gt;1&lt;/span&gt;）直接调用 spark-&lt;span class=&quot;hljs-class&quot; readability=&quot;9&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;class&lt;/span&gt; 脚本进行进程创建，示例如下：&lt;p&gt;./&lt;span class=&quot;hljs-title&quot;&gt;spark&lt;/span&gt;-&lt;span class=&quot;hljs-title&quot;&gt;submit&lt;/span&gt; \&lt;br/&gt;--&lt;span class=&quot;hljs-title&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;hljs-title&quot;&gt;org&lt;/span&gt;.&lt;span class=&quot;hljs-title&quot;&gt;apache&lt;/span&gt;.&lt;span class=&quot;hljs-title&quot;&gt;spark&lt;/span&gt;.&lt;span class=&quot;hljs-title&quot;&gt;examples&lt;/span&gt;.&lt;span class=&quot;hljs-title&quot;&gt;SparkPi&lt;/span&gt; \&lt;br/&gt;--&lt;span class=&quot;hljs-title&quot;&gt;master&lt;/span&gt; &lt;span class=&quot;hljs-title&quot;&gt;spark&lt;/span&gt;://&lt;span class=&quot;hljs-title&quot;&gt;hadoop102&lt;/span&gt;:7077 \&lt;br/&gt;../&lt;span class=&quot;hljs-title&quot;&gt;examples&lt;/span&gt;/&lt;span class=&quot;hljs-title&quot;&gt;jars&lt;/span&gt;/&lt;span class=&quot;hljs-title&quot;&gt;spark&lt;/span&gt;-&lt;span class=&quot;hljs-title&quot;&gt;examples_2&lt;/span&gt;.11-2.1.0.&lt;span class=&quot;hljs-title&quot;&gt;jar&lt;/span&gt; 10&lt;/p&gt;&lt;p&gt;2）如果是 &lt;span class=&quot;hljs-title&quot;&gt;java&lt;/span&gt;/&lt;span class=&quot;hljs-title&quot;&gt;scala&lt;/span&gt; 任务，那么最终调用 &lt;span class=&quot;hljs-title&quot;&gt;SparkSubmit&lt;/span&gt;.&lt;span class=&quot;hljs-title&quot;&gt;scala&lt;/span&gt; 进行任务处理，示例如下：&lt;/p&gt;&lt;p&gt;/&lt;span class=&quot;hljs-title&quot;&gt;opt&lt;/span&gt;/&lt;span class=&quot;hljs-title&quot;&gt;module&lt;/span&gt;/&lt;span class=&quot;hljs-title&quot;&gt;jdk1&lt;/span&gt;.8.0&lt;span class=&quot;hljs-title&quot;&gt;_144&lt;/span&gt; -&lt;span class=&quot;hljs-title&quot;&gt;cp&lt;/span&gt; \&lt;br/&gt;/&lt;span class=&quot;hljs-title&quot;&gt;opt&lt;/span&gt;/&lt;span class=&quot;hljs-title&quot;&gt;module&lt;/span&gt;/&lt;span class=&quot;hljs-title&quot;&gt;spark&lt;/span&gt;-2.1.1-&lt;span class=&quot;hljs-title&quot;&gt;bin&lt;/span&gt;-&lt;span class=&quot;hljs-title&quot;&gt;hadoop2&lt;/span&gt;.7/&lt;span class=&quot;hljs-title&quot;&gt;conf&lt;/span&gt;/:/&lt;span class=&quot;hljs-title&quot;&gt;opt&lt;/span&gt;/&lt;span class=&quot;hljs-title&quot;&gt;module&lt;/span&gt;/&lt;span class=&quot;hljs-title&quot;&gt;spark&lt;/span&gt;-2.1.1-&lt;span class=&quot;hljs-title&quot;&gt;bin&lt;/span&gt;-&lt;span class=&quot;hljs-title&quot;&gt;hadoop2&lt;/span&gt;.7/&lt;span class=&quot;hljs-title&quot;&gt;jars&lt;/span&gt;/*:/&lt;span class=&quot;hljs-title&quot;&gt;opt&lt;/span&gt;/&lt;span class=&quot;hljs-title&quot;&gt;module&lt;/span&gt;/&lt;span class=&quot;hljs-title&quot;&gt;hadoop&lt;/span&gt;-2.7.2/&lt;span class=&quot;hljs-title&quot;&gt;etc&lt;/span&gt;/&lt;span class=&quot;hljs-title&quot;&gt;hadoop&lt;/span&gt;/ \&lt;br/&gt;-&lt;span class=&quot;hljs-title&quot;&gt;Xmx1g&lt;/span&gt; -&lt;span class=&quot;hljs-title&quot;&gt;XX&lt;/span&gt;:&lt;span class=&quot;hljs-title&quot;&gt;MaxPermSize&lt;/span&gt;&lt;/p&gt;&lt;/span&gt;=&lt;span class=&quot;hljs-number&quot;&gt;256&lt;/span&gt;m \&lt;br/&gt;org.apache.spark.deploy.SparkSubmit \&lt;br/&gt;--master spark:&lt;br/&gt;--&lt;span class=&quot;hljs-class&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;hljs-title&quot;&gt;org&lt;/span&gt;.&lt;span class=&quot;hljs-title&quot;&gt;apache&lt;/span&gt;.&lt;span class=&quot;hljs-title&quot;&gt;spark&lt;/span&gt;.&lt;span class=&quot;hljs-title&quot;&gt;examples&lt;/span&gt;.&lt;span class=&quot;hljs-title&quot;&gt;SparkPi&lt;/span&gt; \&lt;br/&gt;../&lt;span class=&quot;hljs-title&quot;&gt;examples&lt;/span&gt;/&lt;span class=&quot;hljs-title&quot;&gt;jars&lt;/span&gt;/&lt;span class=&quot;hljs-title&quot;&gt;spark&lt;/span&gt;-&lt;span class=&quot;hljs-title&quot;&gt;examples_2&lt;/span&gt;.11-2.1.0.&lt;span class=&quot;hljs-title&quot;&gt;jar&lt;/span&gt; 10&lt;br/&gt;&lt;/span&gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;h4master&quot;&gt;&lt;span&gt;&lt;strong&gt;第4章 Master 节点启动&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;
&lt;p&gt;Master 作为 Endpoint 的具体实例，下面我们介绍一下 Master 启动以及 OnStart 指令后的相关工作。&lt;/p&gt;
&lt;h3 id=&quot;h41&quot;&gt;&lt;span&gt;&lt;strong&gt;4.1 脚本概览&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;下面是一个举例：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;java language-java hljs&quot;&gt;/opt/&lt;span class=&quot;hljs-keyword&quot;&gt;module&lt;/span&gt;/jdk1.8.0_144 \&lt;br/&gt;-cp /opt/&lt;span class=&quot;hljs-keyword&quot;&gt;module&lt;/span&gt;/spark-&lt;span class=&quot;hljs-number&quot;&gt;2.1&lt;/span&gt;.1-bin-hadoop2.7/conf/:/opt/&lt;span class=&quot;hljs-keyword&quot;&gt;module&lt;/span&gt;/spark-&lt;span class=&quot;hljs-number&quot;&gt;2.1&lt;/span&gt;.1-bin-hadoop2.7/jars&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;h42&quot;&gt;&lt;span&gt;&lt;strong&gt;4.2 启动流程&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;Master 的启动流程如下：&lt;/p&gt;
&lt;img title=&quot;&quot; src=&quot;https://s2.ax1x.com/2019/05/02/EtPQsg.png&quot; alt=&quot;&quot;/&gt;&lt;p&gt;详解如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;java language-java hljs&quot;&gt;&lt;span class=&quot;hljs-number&quot;&gt;1&lt;/span&gt;）SparkConf：加载 key 以 spark. 开头的系统属性 (Utils.getSystemProperties)。&lt;br/&gt;&lt;span class=&quot;hljs-number&quot;&gt;2&lt;/span&gt;）MasterArguments：&lt;br/&gt;a) 解析 Master 启动的参数：&lt;br/&gt;--ip -i --host -h --port -p --webui-port --properties-file&lt;br/&gt;b)将 --properties-file (没有配置默认为 conf/spark-defaults.conf) 中以 spark. 开头的配置存入 SparkConf。&lt;br/&gt;&lt;span class=&quot;hljs-number&quot;&gt;3&lt;/span&gt;）NettyRpcEnv 中的内部处理遵循 RpcEndpoint 统一处理，这里不再赘述。&lt;br/&gt;&lt;span class=&quot;hljs-number&quot;&gt;4&lt;/span&gt;）BoundPortsResponse 返回 rpcEndpointPort、webUIPort、restPort 真实端口。&lt;br/&gt;&lt;span class=&quot;hljs-number&quot;&gt;5&lt;/span&gt;）最终守护进程会一直存在等待结束信 awaitTermination。&lt;br/&gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;h43onstart&quot;&gt;&lt;span&gt;&lt;strong&gt;4.3 OnStart 监听事件&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;Master 的启动完成后异步执行工作如下：&lt;/p&gt;
&lt;img title=&quot;&quot; src=&quot;https://s2.ax1x.com/2019/05/02/EtPnRf.png&quot; alt=&quot;&quot;/&gt;&lt;p&gt;详解如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;java language-java hljs&quot;&gt;&lt;span class=&quot;hljs-number&quot;&gt;1&lt;/span&gt;）【dispatcher-event-loop】线程扫描到 OnStart 指令后会启动相关 MasterWebUI (默认端口 &lt;span class=&quot;hljs-number&quot;&gt;8080&lt;/span&gt;），根据配置选择安装 ResetServer (默认端口 &lt;span class=&quot;hljs-number&quot;&gt;6066&lt;/span&gt;)。&lt;br/&gt;&lt;span class=&quot;hljs-number&quot;&gt;2&lt;/span&gt;）另外新起【master-forward-message-thread】线程定期检查 Worker 心跳是否超时。&lt;br/&gt;&lt;span class=&quot;hljs-number&quot;&gt;3&lt;/span&gt;）如果 Worker 心跳检测超时，那么对 Worker 下的发布的所有任务所属 Driver 进行 ExecutorUpdated 发送，同时自己再重新 LaunchDriver。&lt;br/&gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;h44rpcmessagereceiveandreply&quot;&gt;&lt;span&gt;&lt;strong&gt;4.4 RpcMessage 处理 (receiveAndReply)&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;img title=&quot;&quot; src=&quot;https://s2.ax1x.com/2019/05/02/EtPMQS.png&quot; alt=&quot;&quot;/&gt;&lt;h3 id=&quot;h45onewaymessagereceive&quot;&gt;&lt;span&gt;&lt;strong&gt;4.5 OneWayMessage 处理 (receive)&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;img title=&quot;&quot; src=&quot;https://s2.ax1x.com/2019/05/02/EtPlLQ.png&quot; alt=&quot;&quot;/&gt;&lt;h3 id=&quot;h46masterrpcmessageonewaymessage&quot;&gt;&lt;span&gt;&lt;strong&gt;4.6 Master 对 RpcMessage/OneWayMessage 处理逻辑&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;这部分对整体 Master 理解作用不是很大且理解比较抽象，可以先读后续内容，回头再考虑看这部分内容，或者不读。&lt;/p&gt;
&lt;img title=&quot;&quot; src=&quot;https://s2.ax1x.com/2019/05/02/EtPGon.png&quot; alt=&quot;&quot;/&gt;&lt;h2 id=&quot;h5worker&quot;&gt;&lt;span&gt;&lt;strong&gt;第5章 Worker 节点启动&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;
&lt;p&gt;Worker 作为 Endpoint 的具体实例，下面我们介绍一下 Worker 启动以及 OnStart 指令后的额外工作。&lt;/p&gt;
&lt;h3 id=&quot;h51&quot;&gt;&lt;span&gt;&lt;strong&gt;5.1 脚本概览&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;下面是一个举例：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;java language-java hljs&quot;&gt;/opt/&lt;span class=&quot;hljs-keyword&quot;&gt;module&lt;/span&gt;/jdk1.8.0_144 \&lt;br/&gt;-cp /opt/&lt;span class=&quot;hljs-keyword&quot;&gt;module&lt;/span&gt;/spark-&lt;span class=&quot;hljs-number&quot;&gt;2.1&lt;/span&gt;.1-bin-hadoop2.7/conf/:/opt/&lt;span class=&quot;hljs-keyword&quot;&gt;module&lt;/span&gt;/spark-&lt;span class=&quot;hljs-number&quot;&gt;2.1&lt;/span&gt;.1-bin-hadoop2.7/jars&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;h52&quot;&gt;&lt;span&gt;&lt;strong&gt;5.2 启动流程&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;Worker 的启动流程如下：&lt;/p&gt;
&lt;img title=&quot;&quot; src=&quot;https://s2.ax1x.com/2019/05/02/EtPYiq.png&quot; alt=&quot;&quot;/&gt;&lt;p&gt;详解如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;java language-java hljs&quot;&gt;&lt;span class=&quot;hljs-number&quot;&gt;1&lt;/span&gt;）SparkConf：加载 key 以 spark. 开头的系统属性 (Utils.getSystemProperties)。&lt;br/&gt;&lt;span class=&quot;hljs-number&quot;&gt;2&lt;/span&gt;）WorkerArguments：&lt;br/&gt;a) 解析 Master 启动的参数：&lt;br/&gt;--ip -i --host -h --port -p --cores -c --memory -m --work-dir --webui-port --properties-file&lt;br/&gt;b) 将 --properties-file (没有配置默认为conf/spark-defaults.conf) 中以 spark. 开头的配置存入 SparkConf。&lt;br/&gt;c) 在没有配置情况下，cores 默认为服务器 CPU 核数。&lt;br/&gt;d) 在没有配置情况下，memory 默认为服务器内存减 &lt;span class=&quot;hljs-number&quot;&gt;1&lt;/span&gt;G，如果低于 &lt;span class=&quot;hljs-number&quot;&gt;1&lt;/span&gt;G 取 &lt;span class=&quot;hljs-number&quot;&gt;1&lt;/span&gt;G。&lt;br/&gt;e) webUiPort 默认为 &lt;span class=&quot;hljs-number&quot;&gt;8081&lt;/span&gt;。&lt;br/&gt;&lt;span class=&quot;hljs-number&quot;&gt;3&lt;/span&gt;）NettyRpcEnv 中的内部处理遵循 RpcEndpoint 统一处理，这里不再赘述。&lt;br/&gt;&lt;span class=&quot;hljs-number&quot;&gt;4&lt;/span&gt;）最终守护进程会一直存在等待结束信 awaitTermination。&lt;br/&gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;h53onstart&quot;&gt;&lt;span&gt;&lt;strong&gt;5.3 OnStart 监听事件&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;Worker 的启动完成后异步执行工作如下：&lt;/p&gt;
&lt;img title=&quot;&quot; src=&quot;https://s2.ax1x.com/2019/05/02/EtP8ds.png&quot; alt=&quot;&quot;/&gt;&lt;p&gt;详解如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;java language-java hljs&quot;&gt;&lt;span class=&quot;hljs-number&quot;&gt;1&lt;/span&gt;）【dispatcher-event-loop】线程扫描到 OnStart 指令后会启动相关 WorkerWebUI (默认端口 &lt;span class=&quot;hljs-number&quot;&gt;8081&lt;/span&gt;)。&lt;br/&gt;&lt;span class=&quot;hljs-number&quot;&gt;2&lt;/span&gt;）Worker 向 Master 发起一次 RegisterWorker 指令。&lt;br/&gt;&lt;span class=&quot;hljs-number&quot;&gt;3&lt;/span&gt;）另起【master-forward-message-thread】线程定期执行 ReregisterWithMaster 任务，如果注册成功 (RegisteredWorker) 则跳过，否则再次向 Master 发起 RegisterWorker 指令，直到超过最大次数报错 (默认&lt;span class=&quot;hljs-number&quot;&gt;16&lt;/span&gt;次)。&lt;br/&gt;&lt;span class=&quot;hljs-number&quot;&gt;4&lt;/span&gt;）Master 如果可以注册，则维护对应的 WorkerInfo 对象并持久化，完成后向 Worker 发起一条 RegisteredWorker 指令，如果 Master 为 standby 状态，则向 Worker 发起一条 MasterInStandby 指令。&lt;br/&gt;&lt;span class=&quot;hljs-number&quot;&gt;5&lt;/span&gt;）Worker 接受 RegisteredWorker 后，提交【master-forward-message-thread】线程定期执行 SendHeartbeat 任务，完成后向 Worker 发起一条 WorkerLatestState 指令。&lt;br/&gt;&lt;span class=&quot;hljs-number&quot;&gt;6&lt;/span&gt;）Worker 发心跳检测，会触发更新 Master 对应 WorkerInfo 对象，如果 Master 检测到异常，则发起 ReconnectWorker 指令至 Worker，Worker 则再次执行 ReregisterWithMaster 工作。&lt;br/&gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;h54rpcmessagereceiveandreply&quot;&gt;&lt;span&gt;&lt;strong&gt;5.4 RpcMessage 处理 (receiveAndReply)&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;img title=&quot;&quot; src=&quot;https://s2.ax1x.com/2019/05/02/EtPtJ0.png&quot; alt=&quot;&quot;/&gt;&lt;h3 id=&quot;h55onewaymessagereceive&quot;&gt;&lt;span&gt;&lt;strong&gt;5.5 OneWayMessage 处理 (receive)&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;img title=&quot;&quot; src=&quot;https://s2.ax1x.com/2019/05/02/EtPdQU.png&quot; alt=&quot;&quot;/&gt;&lt;h2 id=&quot;h6client&quot;&gt;&lt;span&gt;&lt;strong&gt;第6章 Client 启动流程&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;
&lt;p&gt;Client 作为 Endpoint 的具体实例，下面我们介绍一下 Client 启动以及 OnStart 指令后的额外工作。&lt;/p&gt;
&lt;h3 id=&quot;h61&quot;&gt;&lt;span&gt;&lt;strong&gt;6.1 脚本概览&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;下面是一个举例：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;java language-java hljs&quot;&gt;/opt/&lt;span class=&quot;hljs-keyword&quot;&gt;module&lt;/span&gt;/jdk1.8.0_144 \&lt;br/&gt;-cp /opt/&lt;span class=&quot;hljs-keyword&quot;&gt;module&lt;/span&gt;/spark-&lt;span class=&quot;hljs-number&quot;&gt;2.1&lt;/span&gt;.1-bin-hadoop2.7/conf/:/opt/&lt;span class=&quot;hljs-keyword&quot;&gt;module&lt;/span&gt;/spark-&lt;span class=&quot;hljs-number&quot;&gt;2.1&lt;/span&gt;.1-bin-hadoop2.7/jars&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;h62sparksubmit&quot;&gt;&lt;span&gt;&lt;strong&gt;6.2 SparkSubmit 启动流程&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;SparkSubmit 的启动流程如下：&lt;/p&gt;
&lt;img title=&quot;&quot; src=&quot;https://s2.ax1x.com/2019/05/02/EtPNWV.png&quot; alt=&quot;&quot;/&gt;&lt;p&gt;详解如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;java language-java hljs&quot; readability=&quot;1&quot;&gt;&lt;span class=&quot;hljs-number&quot;&gt;1&lt;/span&gt;）SparkSubmitArguments：&lt;br/&gt;a) 解析 Client 启动的参数&lt;br/&gt;--name --master --&lt;span class=&quot;hljs-class&quot; readability=&quot;2&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;class&lt;/span&gt; --&lt;span class=&quot;hljs-title&quot;&gt;deploy&lt;/span&gt;-&lt;span class=&quot;hljs-title&quot;&gt;mode&lt;/span&gt;&lt;br/&gt;--&lt;span class=&quot;hljs-title&quot;&gt;num&lt;/span&gt;-&lt;span class=&quot;hljs-title&quot;&gt;executors&lt;/span&gt; --&lt;span class=&quot;hljs-title&quot;&gt;executor&lt;/span&gt;-&lt;span class=&quot;hljs-title&quot;&gt;cores&lt;/span&gt; --&lt;span class=&quot;hljs-title&quot;&gt;total&lt;/span&gt;-&lt;span class=&quot;hljs-title&quot;&gt;executor&lt;/span&gt;-&lt;span class=&quot;hljs-title&quot;&gt;cores&lt;/span&gt; --&lt;span class=&quot;hljs-title&quot;&gt;executor&lt;/span&gt;-&lt;span class=&quot;hljs-title&quot;&gt;memory&lt;/span&gt;&lt;br/&gt;--&lt;span class=&quot;hljs-title&quot;&gt;driver&lt;/span&gt;-&lt;span class=&quot;hljs-title&quot;&gt;memory&lt;/span&gt; --&lt;span class=&quot;hljs-title&quot;&gt;driver&lt;/span&gt;-&lt;span class=&quot;hljs-title&quot;&gt;cores&lt;/span&gt; --&lt;span class=&quot;hljs-title&quot;&gt;driver&lt;/span&gt;-&lt;span class=&quot;hljs-title&quot;&gt;class&lt;/span&gt;-&lt;span class=&quot;hljs-title&quot;&gt;path&lt;/span&gt; --&lt;span class=&quot;hljs-title&quot;&gt;driver&lt;/span&gt;-&lt;span class=&quot;hljs-title&quot;&gt;java&lt;/span&gt;-&lt;span class=&quot;hljs-title&quot;&gt;options&lt;/span&gt; --&lt;span class=&quot;hljs-title&quot;&gt;driver&lt;/span&gt;-&lt;span class=&quot;hljs-title&quot;&gt;library&lt;/span&gt;-&lt;span class=&quot;hljs-title&quot;&gt;path&lt;/span&gt;&lt;br/&gt;--&lt;span class=&quot;hljs-title&quot;&gt;properties&lt;/span&gt;-&lt;span class=&quot;hljs-title&quot;&gt;file&lt;/span&gt;&lt;br/&gt;--&lt;span class=&quot;hljs-title&quot;&gt;kill&lt;/span&gt; --&lt;span class=&quot;hljs-title&quot;&gt;status&lt;/span&gt; --&lt;span class=&quot;hljs-title&quot;&gt;supervise&lt;/span&gt; --&lt;span class=&quot;hljs-title&quot;&gt;queue&lt;/span&gt;&lt;br/&gt;--&lt;span class=&quot;hljs-title&quot;&gt;files&lt;/span&gt; --&lt;span class=&quot;hljs-title&quot;&gt;py&lt;/span&gt;-&lt;span class=&quot;hljs-title&quot;&gt;files&lt;/span&gt;&lt;br/&gt;--&lt;span class=&quot;hljs-title&quot;&gt;archives&lt;/span&gt; --&lt;span class=&quot;hljs-title&quot;&gt;jars&lt;/span&gt; --&lt;span class=&quot;hljs-title&quot;&gt;packages&lt;/span&gt; --&lt;span class=&quot;hljs-title&quot;&gt;exclude&lt;/span&gt;-&lt;span class=&quot;hljs-title&quot;&gt;packages&lt;/span&gt; --&lt;span class=&quot;hljs-title&quot;&gt;repositories&lt;/span&gt;&lt;br/&gt;--&lt;span class=&quot;hljs-title&quot;&gt;conf&lt;/span&gt; (解析存入 &lt;span class=&quot;hljs-title&quot;&gt;Map&lt;/span&gt;：&lt;span class=&quot;hljs-title&quot;&gt;sparkProperties&lt;/span&gt; 中)&lt;br/&gt;--&lt;span class=&quot;hljs-title&quot;&gt;proxy&lt;/span&gt;-&lt;span class=&quot;hljs-title&quot;&gt;user&lt;/span&gt; --&lt;span class=&quot;hljs-title&quot;&gt;principal&lt;/span&gt; --&lt;span class=&quot;hljs-title&quot;&gt;keytab&lt;/span&gt; --&lt;span class=&quot;hljs-title&quot;&gt;help&lt;/span&gt; --&lt;span class=&quot;hljs-title&quot;&gt;verbose&lt;/span&gt; --&lt;span class=&quot;hljs-title&quot;&gt;version&lt;/span&gt; --&lt;span class=&quot;hljs-title&quot;&gt;usage&lt;/span&gt;-&lt;span class=&quot;hljs-title&quot;&gt;error&lt;/span&gt;&lt;br/&gt;&lt;span class=&quot;hljs-title&quot;&gt;b&lt;/span&gt;) 合并 --&lt;span class=&quot;hljs-title&quot;&gt;properties&lt;/span&gt;-&lt;span class=&quot;hljs-title&quot;&gt;file&lt;/span&gt; (没有配置默认为 &lt;span class=&quot;hljs-title&quot;&gt;conf&lt;/span&gt;/&lt;span class=&quot;hljs-title&quot;&gt;spark&lt;/span&gt;-&lt;span class=&quot;hljs-title&quot;&gt;defaults&lt;/span&gt;.&lt;span class=&quot;hljs-title&quot;&gt;conf&lt;/span&gt;) 文件配置项 (不在 --&lt;span class=&quot;hljs-title&quot;&gt;conf&lt;/span&gt; 中的配置 ) 至 &lt;span class=&quot;hljs-title&quot;&gt;sparkProperties&lt;/span&gt;&lt;br/&gt;&lt;span class=&quot;hljs-title&quot;&gt;c&lt;/span&gt;) 删除 &lt;span class=&quot;hljs-title&quot;&gt;sparkProperties&lt;/span&gt; 中不以 &lt;span class=&quot;hljs-title&quot;&gt;spark&lt;/span&gt;. 开头的配置项目&lt;br/&gt;&lt;span class=&quot;hljs-title&quot;&gt;d&lt;/span&gt;) 启动参数为空的配置项从 &lt;span class=&quot;hljs-title&quot;&gt;sparkProperties&lt;/span&gt; 中合并&lt;br/&gt;&lt;span class=&quot;hljs-title&quot;&gt;e&lt;/span&gt;) 根据 &lt;span class=&quot;hljs-title&quot;&gt;action&lt;/span&gt; (&lt;span class=&quot;hljs-title&quot;&gt;SUBMIT&lt;/span&gt;、&lt;span class=&quot;hljs-title&quot;&gt;KILL&lt;/span&gt;、&lt;span class=&quot;hljs-title&quot;&gt;REQUEST_STATUS&lt;/span&gt;) 校验各自必需参数是否有值&lt;p&gt;2）&lt;span class=&quot;hljs-title&quot;&gt;Case&lt;/span&gt; &lt;span class=&quot;hljs-title&quot;&gt;Submit&lt;/span&gt;：&lt;br/&gt;&lt;span class=&quot;hljs-title&quot;&gt;a&lt;/span&gt;) 获取&lt;span class=&quot;hljs-title&quot;&gt;childMainClass&lt;/span&gt;&lt;br/&gt;[--&lt;span class=&quot;hljs-title&quot;&gt;deploy&lt;/span&gt;-&lt;span class=&quot;hljs-title&quot;&gt;mode&lt;/span&gt;] &lt;/p&gt;&lt;/span&gt;= clent(默认)：用户任务启动类 mainClass (--&lt;span class=&quot;hljs-class&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;class&lt;/span&gt;)&lt;br/&gt;[--&lt;span class=&quot;hljs-title&quot;&gt;deploy&lt;/span&gt;-&lt;span class=&quot;hljs-title&quot;&gt;mode&lt;/span&gt;] &lt;/span&gt;= cluster &amp;amp;  [--master] = spark:* &amp;amp; useRest     org.apache.spark.deploy.rest.RestSubmissionClient&lt;br/&gt;[--deploy-mode] = cluster &amp;amp;  [--master] = spark:* &amp;amp; !useRest    org.apache.spark.deploy.Client&lt;br/&gt;[--deploy-mode] = cluster &amp;amp;  [--master] = yarn                  org.apache.spark.deploy.yarn.Client&lt;br/&gt;[--deploy-mode] = cluster &amp;amp;  [--master] = mesos:*               org.apache.spark.deploy.rest.RestSubmissionClient&lt;br/&gt;b) 获取 childArgs (子运行时对应命令行组装参数)&lt;br/&gt;[--deploy-mode] = cluster &amp;amp;  [--master] = spark:* &amp;amp; useRest     包含 primaryResource 与 mainClass&lt;br/&gt;[--deploy-mode] = cluster &amp;amp;  [--master] = spark:* &amp;amp; !useRest    包含 --supervise --memory --cores  launch childArg, primaryResource, mainClass&lt;br/&gt;[--deploy-mode] = cluster &amp;amp;  [--master] = yarn                  --&lt;span class=&quot;hljs-class&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;class&lt;/span&gt; --&lt;span class=&quot;hljs-title&quot;&gt;arg&lt;/span&gt; --&lt;span class=&quot;hljs-title&quot;&gt;jar&lt;/span&gt;/--&lt;span class=&quot;hljs-title&quot;&gt;primary&lt;/span&gt;-&lt;span class=&quot;hljs-title&quot;&gt;py&lt;/span&gt;-&lt;span class=&quot;hljs-title&quot;&gt;file&lt;/span&gt;/--&lt;span class=&quot;hljs-title&quot;&gt;primary&lt;/span&gt;-&lt;span class=&quot;hljs-title&quot;&gt;r&lt;/span&gt;-&lt;span class=&quot;hljs-title&quot;&gt;file&lt;/span&gt;&lt;br/&gt;[--&lt;span class=&quot;hljs-title&quot;&gt;deploy&lt;/span&gt;-&lt;span class=&quot;hljs-title&quot;&gt;mode&lt;/span&gt;] &lt;/span&gt;= cluster &amp;amp;  [--master] = mesos:*               primaryResource&lt;br/&gt;c) 获取 childClasspath&lt;br/&gt;[--deploy-mode] = clent     读取 --jars 配置，与 primaryResource 信息 (../examples/jars/spark-examples_2.11-&lt;span class=&quot;hljs-number&quot;&gt;2.1&lt;/span&gt;.0.jar)&lt;br/&gt;d) 获取 sysProps&lt;br/&gt;将 sparkPropertie 中的所有配置封装成新的 sysProps 对象，另外还增加了一下额外的配置项目&lt;br/&gt;e) 将 childClasspath 通过当前的类加载器加载中&lt;br/&gt;f) 将 sysProps 设置到当前 jvm 环境中&lt;br/&gt;g) 最终反射执行 childMainClass，传参为 childArgs&lt;br/&gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;h63client&quot;&gt;&lt;span&gt;&lt;strong&gt;6.3 Client 启动流程&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;Client 的启动流程如下：&lt;/p&gt;
&lt;img title=&quot;&quot; src=&quot;https://s2.ax1x.com/2019/05/02/EtPDeJ.png&quot; alt=&quot;&quot;/&gt;&lt;p&gt;详解如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;java language-java hljs&quot;&gt;&lt;span class=&quot;hljs-number&quot;&gt;1&lt;/span&gt;）SparkConf：加载 key 以 spark. 开头的系统属性 (Utils.getSystemProperties)。&lt;br/&gt;&lt;span class=&quot;hljs-number&quot;&gt;2&lt;/span&gt;）ClientArguments：&lt;br/&gt;a) 解析 Client 启动的参数：&lt;br/&gt;--cores -c --memory -m --supervise -s --verbose -v&lt;br/&gt;launch jarUrl master mainClass&lt;br/&gt;kill master driverId&lt;br/&gt;b) 将 --properties-file (没有配置默认为 conf/spark-defaults.conf) 中以 spark. 开头的配置存入 SparkConf。&lt;br/&gt;c) 在没有配置情况下，cores 默认为 &lt;span class=&quot;hljs-number&quot;&gt;1&lt;/span&gt; 核。&lt;br/&gt;d) 在没有配置情况下，memory 默认为 &lt;span class=&quot;hljs-number&quot;&gt;1&lt;/span&gt;G。&lt;br/&gt;e) NettyRpcEnv 中的内部处理遵循 RpcEndpoint 统一处理，这里不再赘述。&lt;br/&gt;&lt;span class=&quot;hljs-number&quot;&gt;3&lt;/span&gt;）最终守护进程会一直存在等待结束信 awaitTermination。&lt;br/&gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;h64clientonstart&quot;&gt;&lt;span&gt;&lt;strong&gt;6.4 Client 的 OnStart 监听事件&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;Client 的启动完成后异步执行工作如下：　&lt;/p&gt;
&lt;img title=&quot;&quot; src=&quot;https://s2.ax1x.com/2019/05/02/EtP0L4.png&quot; alt=&quot;&quot;/&gt;&lt;p&gt;详解如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;java language-java hljs&quot;&gt;&lt;span class=&quot;hljs-number&quot;&gt;1&lt;/span&gt;）如果是发布任务(&lt;span class=&quot;hljs-keyword&quot;&gt;case&lt;/span&gt; launch)，Client 创建一个 DriverDescription，并向 Master 发起 RequestSubmitDriver 请求。&lt;br/&gt;a) Command 中的 mainClass 为： org.apache.spark.deploy.worker.DriverWrapper&lt;br/&gt;b) Command 中的 arguments 为： Seq(&lt;span class=&quot;hljs-string&quot;&gt;&quot;{{WORKER_URL}}&quot;&lt;/span&gt;, &lt;span class=&quot;hljs-string&quot;&gt;&quot;{{USER_JAR}}&quot;&lt;/span&gt;, driverArgs.mainClass)&lt;br/&gt;&lt;span class=&quot;hljs-number&quot;&gt;2&lt;/span&gt;）Master 接受 RequestSubmitDriver 请求后，将 DriverDescription 封装为 一个DriverInfo。&lt;br/&gt;a) startTime 与 submitDate 都为当前时间&lt;br/&gt;b) driverId 格式为：driver-yyyyMMddHHmmss-nextId，nextId 是全局唯一的&lt;br/&gt;&lt;span class=&quot;hljs-number&quot;&gt;3&lt;/span&gt;）Master 持久化 DriverInfo，并加入待调度列表中 (waitingDrivers)，触发公共资源调度逻辑。&lt;br/&gt;&lt;span class=&quot;hljs-number&quot;&gt;4&lt;/span&gt;）Master 公共资源调度结束后，返回 SubmitDriverResponse给Client。&lt;br/&gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;h65rpcmessagereceiveandreply&quot;&gt;&lt;span&gt;&lt;strong&gt;6.5 RpcMessage 处理 (receiveAndReply)&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;无。&lt;/p&gt;
&lt;h3 id=&quot;h66onewaymessagereceive&quot;&gt;&lt;span&gt;&lt;strong&gt;6.6 OneWayMessage 处理(receive)&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;img title=&quot;&quot; src=&quot;https://s2.ax1x.com/2019/05/02/EtPUzT.png&quot; alt=&quot;&quot;/&gt;&lt;h2 id=&quot;h7driverdriverrunner&quot;&gt;&lt;span&gt;&lt;strong&gt;第7章 Driver 和 DriverRunner&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;
&lt;p&gt;Client 向 Master 发起 RequestSubmitDriver 请求，Master 将 DriverInfo 添加待调度列表中 (waitingDrivers)，下面针对于 Driver 进一步梳理。&lt;/p&gt;
&lt;h3 id=&quot;h71masterdriver&quot;&gt;&lt;span&gt;&lt;strong&gt;7.1 Master 对 Driver 资源分配&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;大致流程如下：&lt;/p&gt;
&lt;img title=&quot;&quot; src=&quot;https://s2.ax1x.com/2019/05/02/EtPrw9.png&quot; alt=&quot;&quot;/&gt;&lt;p&gt;详解如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;java language-java hljs&quot;&gt;waitingDrivers 与 aliveWorkers 进行资源匹配：&lt;br/&gt;&lt;span class=&quot;hljs-number&quot;&gt;1&lt;/span&gt;）在 waitingDrivers 循环内，轮询所有 aliveWorker。&lt;br/&gt;&lt;span class=&quot;hljs-number&quot;&gt;2&lt;/span&gt;）如果 aliveWorker 满足当前 waitingDriver 资源要求，给 Worker 发送 LaunchDriver 指令并将 waitingDriver 移除 waitingDrivers，则进行下一次 waitingDriver 的轮询工作。&lt;br/&gt;&lt;span class=&quot;hljs-number&quot;&gt;3&lt;/span&gt;）如果轮询完所有 aliveWorker 都不满足 waitingDriver 资源要求，则进行下一次 waitingDriver 的轮询工作。&lt;br/&gt;&lt;span class=&quot;hljs-number&quot;&gt;4&lt;/span&gt;）所有发起的轮询开始点都上次轮询结束点的下一个点位开始。&lt;br/&gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;h72workerdriverrunner&quot;&gt;&lt;span&gt;&lt;strong&gt;7.2 Worker 运行 DriverRunner&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;Driver 的启动，流程如下：&lt;/p&gt;
&lt;img title=&quot;&quot; src=&quot;https://s2.ax1x.com/2019/05/02/EtP6F1.png&quot; alt=&quot;&quot;/&gt;&lt;p&gt;详解如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;java language-java hljs&quot;&gt;&lt;span class=&quot;hljs-number&quot;&gt;1&lt;/span&gt;）当 Worker 遇到 LaunchDriver 指令时，创建并启动一个 DriverRunner。&lt;br/&gt;&lt;span class=&quot;hljs-number&quot;&gt;2&lt;/span&gt;）DriverRunner 启动一个线程 DriverRunner &lt;span class=&quot;hljs-keyword&quot;&gt;for&lt;/span&gt; [driverId] 处理 Driver 启动工作。&lt;br/&gt;&lt;span class=&quot;hljs-number&quot;&gt;3&lt;/span&gt;）DriverRunner &lt;span class=&quot;hljs-keyword&quot;&gt;for&lt;/span&gt; [driverId]：&lt;br/&gt;a) 添加 JVM 钩子，针对于每个 diriverId 创建一个临时目录。&lt;br/&gt;b) 将 DriverDesc.jarUrl 通过 Netty 从 Driver 机器远程拷贝过来。&lt;br/&gt;c) 根据 DriverDesc.command 模板构建本地执行的 command 命令，并启动该 command 对应的 Process 进程。&lt;br/&gt;d) 将 Process 的输出流输出到文件 stdout/stderror，如果 Process 启动失败，进行 &lt;span class=&quot;hljs-number&quot;&gt;1&lt;/span&gt;-&lt;span class=&quot;hljs-number&quot;&gt;5&lt;/span&gt; 的秒的反复启动工作，直到启动成功，在释放 Worker 节点的 DriverRunner 的资源。&lt;br/&gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;h73driverrunnerdriverwrapper&quot;&gt;&lt;span&gt;&lt;strong&gt;7.3 DriverRunner 创建并运行 DriverWrapper&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;DriverWrapper 的运行，流程如下：&lt;/p&gt;
&lt;img title=&quot;&quot; src=&quot;https://s2.ax1x.com/2019/05/02/EtPsoR.png&quot; alt=&quot;&quot;/&gt;&lt;p&gt;详解如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;java language-java hljs&quot;&gt;&lt;span class=&quot;hljs-number&quot;&gt;1&lt;/span&gt;）DriverWapper 创建了一个 RpcEndpoint 与 RpcEnv。&lt;br/&gt;&lt;span class=&quot;hljs-number&quot;&gt;2&lt;/span&gt;）RpcEndpoint 为 WorkerWatcher，主要目的为监控 Worker 节点是否正常，如果出现异常就直接退出。&lt;br/&gt;&lt;span class=&quot;hljs-number&quot;&gt;3&lt;/span&gt;）然后当前的 ClassLoader 加载 userJar，同时执行 userMainClass。&lt;br/&gt;&lt;span class=&quot;hljs-number&quot;&gt;4&lt;/span&gt;）执行用户的 main 方法后关闭 workerWatcher。&lt;br/&gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;h8sparkcontext&quot;&gt;&lt;span&gt;&lt;strong&gt;第8章 SparkContext 解析&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;
&lt;h3 id=&quot;h81sparkcontext&quot;&gt;&lt;span&gt;&lt;strong&gt;8.1 SparkContext 解析&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;SparkContext 是用户通往 Spark 集群的唯一入口，任何需要使用 Spark 的地方都需要先创建 SparkContext，那么 SparkContext 做了什么？&lt;br/&gt;首先 SparkContext 是在 Driver 程序里面启动的，可以看做 Driver 程序和 Spark 集群的一个连接，SparkContext 在初始化的时候，创建了很多对象，如下图所示：&lt;/p&gt;
&lt;img title=&quot;&quot; src=&quot;https://s2.ax1x.com/2019/05/02/EtPcJx.png&quot; alt=&quot;&quot;/&gt;&lt;br/&gt;上图列出了 SparkContext 在初始化创建的时候的一些主要组件的构建。
&lt;h3 id=&quot;h82sparkcontext&quot;&gt;&lt;span&gt;&lt;strong&gt;8.2 SparkContext 创建过程&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;img title=&quot;&quot; src=&quot;https://s2.ax1x.com/2019/05/02/EtPhOe.png&quot; alt=&quot;&quot;/&gt;&lt;p&gt;详解如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;java language-java hljs&quot;&gt;SparkContext 在新建时：&lt;br/&gt;&lt;span class=&quot;hljs-number&quot;&gt;1&lt;/span&gt;）内部创建一个 SparkEnv，SparkEnv 内部创建一个 RpcEnv。&lt;br/&gt;a) RpcEnv 内部创建并注册一个 MapOutputTrackerMasterEndpoint(该 Endpoint 暂不介绍)&lt;br/&gt;&lt;span class=&quot;hljs-number&quot;&gt;2&lt;/span&gt;）接着创建 DAGScheduler、TaskSchedulerImpl、SchedulerBackend。&lt;br/&gt;a) TaskSchedulerImpl 创建时创建 SchedulableBuilder，SchedulableBuilder 根据类型分为 FIFOSchedulableBuilder、FairSchedulableBuilder 两类&lt;br/&gt;&lt;span class=&quot;hljs-number&quot;&gt;3&lt;/span&gt;）最后启动 TaskSchedulerImpl，TaskSchedulerImpl 启动 SchedulerBackend。&lt;br/&gt;a) SchedulerBackend 启动时创建 ApplicationDescription、DriverEndpoint、StandloneAppClient&lt;br/&gt;b) StandloneAppClient 内部包括一个 ClientEndpoint&lt;br/&gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;h83sparkcontext&quot;&gt;&lt;span&gt;&lt;strong&gt;8.3 SparkContext 简易结构与交互关系&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;img title=&quot;&quot; src=&quot;https://s2.ax1x.com/2019/05/02/EtPgW6.png&quot; alt=&quot;&quot;/&gt;&lt;p&gt;详解如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;java language-java hljs&quot;&gt;&lt;span class=&quot;hljs-number&quot;&gt;1&lt;/span&gt;）SparkContext：是用户 Spark 执行任务的上下文，用户程序内部使用 Spark 提供的 Api 直接或间接创建一个 SparkContext。&lt;br/&gt;&lt;span class=&quot;hljs-number&quot;&gt;2&lt;/span&gt;）SparkEnv：用户执行的环境信息，包括通信相关的端点。&lt;br/&gt;&lt;span class=&quot;hljs-number&quot;&gt;3&lt;/span&gt;）RpcEnv：SparkContext 中远程通信环境。&lt;br/&gt;&lt;span class=&quot;hljs-number&quot;&gt;4&lt;/span&gt;）ApplicationDescription：应用程序描述信息，主要包含 appName、maxCores、memoryPerExecutorMB、coresPerExecutor、Command (CoarseGrainedExecutorBackend)、appUiUrl 等。&lt;br/&gt;&lt;span class=&quot;hljs-number&quot;&gt;5&lt;/span&gt;）ClientEndpoint：客户端端点，启动后向 Master 发起注册 RegisterApplication 请求。&lt;br/&gt;&lt;span class=&quot;hljs-number&quot;&gt;6&lt;/span&gt;）Master：接受 RegisterApplication 请求后，进行 Worker 资源分配，并向分配的资源发起 LaunchExecutor 指令。&lt;br/&gt;&lt;span class=&quot;hljs-number&quot;&gt;7&lt;/span&gt;）Worker：接受 LaunchExecutor 指令后，运行 ExecutorRunner。&lt;br/&gt;&lt;span class=&quot;hljs-number&quot;&gt;8&lt;/span&gt;）ExecutorRunner：运行 applicationDescription 的 Command 命令，最终 Executor，同时向 DriverEndpoint 注册 Executor 信息。&lt;br/&gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;h84masterapplication&quot;&gt;&lt;span&gt;&lt;strong&gt;8.4 Master 对 Application 资源分配&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;当 Master 接受 Driver 的 RegisterApplication 请求后，放入 waitingDrivers 队列中，在同一调度中进行资源分配，分配过程如下：&lt;/p&gt;
&lt;img title=&quot;&quot; src=&quot;https://s2.ax1x.com/2019/05/02/EtPRSK.png&quot; alt=&quot;&quot;/&gt;&lt;p&gt;详解如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;java language-java hljs&quot;&gt;waitingApps 与 aliveWorkers 进行资源匹配：&lt;br/&gt;&lt;span class=&quot;hljs-number&quot;&gt;1&lt;/span&gt;）如果 waitingApp 配置了 app.desc.coresPerExecutor：&lt;br/&gt;a) 轮询所有有效可分配的 worker，每次分配一个 executor，executor 的核数为 minCoresPerExecutor(app.desc.coresPerExecutor)，直到不存在有效可分配资源或者 app 依赖的资源已全部被分配。&lt;br/&gt;&lt;span class=&quot;hljs-number&quot;&gt;2&lt;/span&gt;）如果 waitingApp 没有配置 app.desc.coresPerExecutor：&lt;br/&gt;a) 轮询所有有效可分配的 worker，每个 worker 分配一个 executor，executor 的核数为从 minCoresPerExecutor(为固定值&lt;span class=&quot;hljs-number&quot;&gt;1&lt;/span&gt;) 开始递增，直到不存在有效可分配资源或者 app 依赖的资源已全部被分配。&lt;br/&gt;&lt;span class=&quot;hljs-number&quot;&gt;3&lt;/span&gt;）其中有效可分配 worker 定义为满足一次资源分配的 worker：&lt;br/&gt;a) cores 满足：usableWorkers(pos).coresFree - assignedCores(pos) &amp;gt;= minCoresPerExecutor&lt;br/&gt;b) memory 满足(如果是新的 Executor)：usableWorkers(pos).memoryFree - assignedExecutors(pos) * memoryPerExecutor &amp;gt;= memoryPerExecutor&lt;br/&gt;注意：Master 针对于 applicationInfo 进行资源分配时，只有存在有效可用的资源就直接分配，而分配剩余的 app.coresLeft 则等下一次再进行分配。&lt;br/&gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;h85workerexecutor&quot;&gt;&lt;span&gt;&lt;strong&gt;8.5 Worker 创建 Executor&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;img title=&quot;&quot; src=&quot;https://s2.ax1x.com/2019/05/02/EtP7FI.png&quot; alt=&quot;&quot;/&gt;&lt;br/&gt;（图解：橙色组件是 Endpoint 组件）
&lt;p&gt;详解如下：&lt;/p&gt;
&lt;pre readability=&quot;9&quot;&gt;
&lt;code class=&quot;java language-java hljs&quot; readability=&quot;12&quot;&gt;Worker 启动 Executor&lt;br/&gt;&lt;span class=&quot;hljs-number&quot;&gt;1&lt;/span&gt;）在 Worker 的 tempDir 下面创建 application 以及 executor 的目录，并 chmod &lt;span class=&quot;hljs-number&quot;&gt;700&lt;/span&gt; 操作权限。&lt;br/&gt;&lt;span class=&quot;hljs-number&quot;&gt;2&lt;/span&gt;）创建并启动 ExecutorRunner 进行 Executor 的创建。&lt;br/&gt;&lt;span class=&quot;hljs-number&quot;&gt;3&lt;/span&gt;）向 Master 发送 Executor 的状态情况。&lt;p&gt;ExecutorRnner&lt;br/&gt;&lt;span class=&quot;hljs-number&quot;&gt;1&lt;/span&gt;）新线程【ExecutorRunner &lt;span class=&quot;hljs-keyword&quot;&gt;for&lt;/span&gt; [executorId]】读取 ApplicationDescription 将其中 Command 转化为本地的 Command 命令。&lt;br/&gt;&lt;span class=&quot;hljs-number&quot;&gt;2&lt;/span&gt;）调用 Command 并将日志输出至 executor 目录下的 stdout 和 stderr 日志文件中，Command 对应的 java 类为 CoarseGrainedExecutorBackend。&lt;/p&gt;&lt;p&gt;CoarseGrainedExecutorBackend&lt;br/&gt;&lt;span class=&quot;hljs-number&quot;&gt;1&lt;/span&gt;）创建一个 SparkEnv，创建 ExecutorEndpoint(CoarseGrainedExecutorBackend)以及 WorkerWatcher。&lt;br/&gt;&lt;span class=&quot;hljs-number&quot;&gt;2&lt;/span&gt;）ExecutorEndpoint 创建并启动后，向 DriverEndpoint 发送 RegisterExecutor 请求并等待返回。&lt;br/&gt;&lt;span class=&quot;hljs-number&quot;&gt;3&lt;/span&gt;）DriverEndpoint 处理 RegisterExecutor 请求，返回 ExecutorEndpointRegister 的结果。&lt;br/&gt;&lt;span class=&quot;hljs-number&quot;&gt;4&lt;/span&gt;）如果注册成功，ExecutorEndpoint 内部再创建 Executor 的处理对象。&lt;/p&gt;&lt;p&gt;至此，Spark 运行任务的容器框架就搭建完成。&lt;br/&gt;&lt;/p&gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;h9jobtask&quot;&gt;&lt;span&gt;&lt;strong&gt;第9章 Job 提交和 Task 的拆分&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;
&lt;p&gt;在前面的章节 Client 的加载中，Spark 的 DriverRunner 已开始执行用户任务类（比如：org.apache.spark.examples.SparkPi），下面我们开始针对于用户任务类（或者任务代码）进行分析：&lt;/p&gt;
&lt;h3 id=&quot;h91&quot;&gt;&lt;span&gt;&lt;strong&gt;9.1 整体预览&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;img title=&quot;&quot; src=&quot;https://s2.ax1x.com/2019/05/02/EtPWQO.png&quot; alt=&quot;&quot;/&gt;&lt;p&gt;详解如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;java language-java hljs&quot;&gt;&lt;span class=&quot;hljs-number&quot;&gt;1&lt;/span&gt;）Code：指的用户编写的代码&lt;br/&gt;&lt;span class=&quot;hljs-number&quot;&gt;2&lt;/span&gt;）RDD：弹性分布式数据集，用户编码根据 SparkContext 与 RDD 的 api 能够很好的将 Code 转化为 RDD 数据结构(下文将做转化细节介绍)。&lt;br/&gt;&lt;span class=&quot;hljs-number&quot;&gt;3&lt;/span&gt;）DAGScheduler：有向无环图调度器，将 RDD 封装为 JobSubmitted 对象存入 EventLoop (实现类DAGSchedulerEventProcessLoop) 队列中。&lt;br/&gt;&lt;span class=&quot;hljs-number&quot;&gt;4&lt;/span&gt;）EventLoop： 定时扫描未处理 JobSubmitted 对象，将 JobSubmitted 对象提交给 DAGScheduler。&lt;br/&gt;&lt;span class=&quot;hljs-number&quot;&gt;5&lt;/span&gt;）DAGScheduler：针对于 JobSubmitted 进行处理，最终将 RDD 转化为执行 TaskSet，并将 TaskSet 提交至 TaskScheduler。&lt;br/&gt;&lt;span class=&quot;hljs-number&quot;&gt;6&lt;/span&gt;）TaskScheduler： 根据 TaskSet 创建 TaskSetManager 对象存入 SchedulableBuilder 的数据池(Pool)中，并调用 DriverEndpoint 唤起消费(ReviveOffers)操作。&lt;br/&gt;&lt;span class=&quot;hljs-number&quot;&gt;7&lt;/span&gt;）DriverEndpoint：接受 ReviveOffers 指令后将 TaskSet 中的 Tasks 根据相关规则均匀分配给Executor。&lt;br/&gt;&lt;span class=&quot;hljs-number&quot;&gt;8&lt;/span&gt;）Executor：启动一个 TaskRunner 执行一个 Task。&lt;br/&gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;h92coderdds&quot;&gt;&lt;span&gt;&lt;strong&gt;9.2 Code 转化为初始 RDDs&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;我们的用户代码通过调用 Spark 的 Api（比如：SparkSession.builder.appName(&quot;Spark Pi&quot;).getOrCreate()），该 Api 会创建 Spark 的上下文（SparkContext），当我们调用 transform 类方法（如：parallelize(),map()）都会创建（或者装饰已有的）Spark 数据结构（RDD），如果是 action 类操作（如：reduce()），那么将最后封装的 RDD 作为一次 Job 提交，存入待调度队列中（DAGSchedulerEventProcessLoop ）待后续异步处理。&lt;br/&gt;如果多次调用 action 类操作，那么封装的多个 RDD 作为多个 Job 提交。&lt;br/&gt;流程如下：&lt;/p&gt;
&lt;img title=&quot;&quot; src=&quot;https://s2.ax1x.com/2019/05/02/EtPfyD.png&quot; alt=&quot;&quot;/&gt;&lt;p&gt;详解如下：&lt;/p&gt;
&lt;pre readability=&quot;10&quot;&gt;
&lt;code class=&quot;java language-java hljs&quot; readability=&quot;14&quot;&gt;ExecuteEnv（执行环境）&lt;br/&gt;&lt;span class=&quot;hljs-number&quot;&gt;1&lt;/span&gt;）这里可以是通过 spark-submit 提交的 MainClass，也可以是 spark-shell 脚本。&lt;br/&gt;&lt;span class=&quot;hljs-number&quot;&gt;2&lt;/span&gt;）MainClass：代码中必定会创建或者获取一个 SparkContext。&lt;br/&gt;&lt;span class=&quot;hljs-number&quot;&gt;3&lt;/span&gt;）spark-shell：默认会创建一个 SparkContext。&lt;p&gt;RDD（弹性分布式数据集）&lt;/p&gt;&lt;p&gt;&lt;span class=&quot;hljs-number&quot;&gt;1&lt;/span&gt;）create：可以直接创建（如：sc.parallelize(&lt;span class=&quot;hljs-number&quot;&gt;1&lt;/span&gt; until n, slices) ），也可以在其他地方读取（如：sc.textFile(&lt;span class=&quot;hljs-string&quot;&gt;&quot;README.md&quot;&lt;/span&gt;)）等。&lt;br/&gt;&lt;span class=&quot;hljs-number&quot;&gt;2&lt;/span&gt;）transformation：rdd 提供了一组 api 可以进行对已有 RDD 进行反复封装成为新的 RDD，这里采用的是`装饰者设计模式`，下面为部分装饰器类图。&lt;br/&gt;&lt;span class=&quot;hljs-number&quot;&gt;3&lt;/span&gt;）action：当调用 RDD 的 action 类操作方法时（collect、reduce、lookup、save ），这触发 DAGScheduler 的 Job 提交。&lt;br/&gt;&lt;span class=&quot;hljs-number&quot;&gt;4&lt;/span&gt;）DAGScheduler：创建一个名为 JobSubmitted 的消息至 DAGSchedulerEventProcessLoop 阻塞消息队列（LinkedBlockingDeque）中。&lt;br/&gt;&lt;span class=&quot;hljs-number&quot;&gt;5&lt;/span&gt;）DAGSchedulerEventProcessLoop：启动名为【dag-scheduler-event-loop】的线程实时消费消息队列。&lt;br/&gt;&lt;span class=&quot;hljs-number&quot;&gt;6&lt;/span&gt;）【dag-scheduler-event-loop】处理完成后回调 JobWaiter。&lt;br/&gt;&lt;span class=&quot;hljs-number&quot;&gt;7&lt;/span&gt;）DAGScheduler：打印 Job 执行结果。&lt;br/&gt;&lt;span class=&quot;hljs-number&quot;&gt;8&lt;/span&gt;）JobSubmitted：相关代码如下（其中 jobId 为 DAGScheduler 全局递增 Id）。&lt;br/&gt;eventProcessLoop.post(JobSubmitted(&lt;br/&gt;jobId, rdd, func2, partitions.toArray, callSite, waiter,&lt;br/&gt;SerializationUtils.clone(properties)))&lt;br/&gt;&lt;/p&gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;部分装饰器类图&lt;/p&gt;
&lt;img title=&quot;&quot; src=&quot;https://s2.ax1x.com/2019/05/02/EtP5eH.png&quot; alt=&quot;&quot;/&gt;&lt;br/&gt;最终示例：&lt;br/&gt;&lt;img title=&quot;&quot; src=&quot;https://s2.ax1x.com/2019/05/02/EtPoTA.png&quot; alt=&quot;&quot;/&gt;&lt;br/&gt;最终转化的 RDD 分为四层，每层都依赖于上层 RDD，将 ShffleRDD 封装为一个 Job 存入 DAGSchedulerEventProcessLoop 待处理，如果我们的代码中存在几段上面示例代码，那么就会创建对应对的几个 ShffleRDD 分别存入 DAGSchedulerEventProcessLoop 中。
&lt;h3 id=&quot;h93rddtaskset&quot;&gt;&lt;span&gt;&lt;strong&gt;9.3 RDD 分解为待执行任务集合（TaskSet）&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;Job 提交后，DAGScheduler 根据 RDD 层次关系解析为对应的 Stages，同时维护 Job 与 Stage 的关系。&lt;br/&gt;将最上层的 Stage 根据并发关系（findMissingPartitions）分解为多个 Task，将这个多个 Task 封装为 TaskSet 提交给 TaskScheduler。非最上层的 Stage 的存入处理的列表中（waitingStages += stage）&lt;br/&gt;流程如下：&lt;/p&gt;
&lt;img title=&quot;&quot; src=&quot;https://s2.ax1x.com/2019/05/02/EtPIwd.png&quot; alt=&quot;&quot;/&gt;&lt;p&gt;详解如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;java language-java hljs&quot;&gt;&lt;span class=&quot;hljs-number&quot;&gt;1&lt;/span&gt;）DAGSchedulerEventProcessLoop中，线程【dag-scheduler-event-loop】处理到 JobSubmitted&lt;br/&gt;&lt;span class=&quot;hljs-number&quot;&gt;2&lt;/span&gt;）调用 DAGScheduler 进行 handleJobSubmitted&lt;br/&gt;a) 首先根据 RDD 依赖关系依次创建 Stage 族，Stage 分为 ShuffleMapStage、ResultStage 两类，如下图所示：&lt;br/&gt;b) 更新 jobId 与 StageId 关系 Map&lt;br/&gt;c) 创建 ActiveJob，调用 LiveListenerBug，发送 SparkListenerJobStart 指令&lt;br/&gt;d) 找到最上层 Stage 进行提交，下层 Stage 存入 waitingStage 中待后续处理&lt;br/&gt;&lt;span class=&quot;hljs-number&quot;&gt;1&lt;/span&gt;) 调用 OutputCommitCoordinator 进行 stageStart() 处理&lt;br/&gt;&lt;span class=&quot;hljs-number&quot;&gt;2&lt;/span&gt;) 调用 LiveListenerBug，发送 SparkListenerStageSubmitted 指令&lt;br/&gt;&lt;span class=&quot;hljs-number&quot;&gt;3&lt;/span&gt;) 调用 SparkContext的broadcast 方法获取 Broadcast 对象，根据 Stage 类型创建对应多个 Task，一个 Stage 根据 findMissingPartitions 分为多个对应的 Task，Task 分为 ShuffleMapTask、ResultTask&lt;br/&gt;&lt;span class=&quot;hljs-number&quot;&gt;4&lt;/span&gt;) 将 Task 封装为 TaskSet，调用 TaskScheduler.submitTasks(taskSet) 进行 Task 调度，关键代码如下：&lt;br/&gt;taskScheduler.submitTasks(&lt;span class=&quot;hljs-keyword&quot;&gt;new&lt;/span&gt; TaskSet(&lt;br/&gt;tasks.toArray, stage.id, stage.latestInfo.attemptId, jobId, properties))&lt;br/&gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;ShuffleMapStage、ResultStage 两类&lt;/p&gt;
&lt;img title=&quot;&quot; src=&quot;https://s2.ax1x.com/2019/05/02/ENpVtx.png&quot; alt=&quot;&quot;/&gt;&lt;h3 id=&quot;h94tasksettasksetmanagerdriver&quot;&gt;&lt;span&gt;&lt;strong&gt;9.4 TaskSet 封装为 TaskSetManager 并提交至 Driver&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;TaskScheduler 将 TaskSet 封装为 TaskSetManager(new TaskSetManager(this, taskSet, maxTaskFailures, blacklistTrackerOpt))，存入待处理任务池（Pool）中，发送 DriverEndpoint 唤起消费（ReviveOffers）指令。&lt;/p&gt;
&lt;img title=&quot;&quot; src=&quot;https://s2.ax1x.com/2019/05/02/EtPbfP.png&quot; alt=&quot;&quot;/&gt;&lt;p&gt;详解如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;java language-java hljs&quot;&gt;&lt;span class=&quot;hljs-number&quot;&gt;1&lt;/span&gt;）DAGSheduler 将 TaskSet 提交给 TaskScheduler 的实现类，这里是 TaskChedulerImpl。&lt;br/&gt;&lt;span class=&quot;hljs-number&quot;&gt;2&lt;/span&gt;）TaskSchedulerImpl 创建一个 TaskSetManager 管理 TaskSet，关键代码如下：&lt;br/&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;new&lt;/span&gt; TaskSetManager(&lt;span class=&quot;hljs-keyword&quot;&gt;this&lt;/span&gt;, taskSet, maxTaskFailures, blacklistTrackerOpt)&lt;br/&gt;&lt;span class=&quot;hljs-number&quot;&gt;3&lt;/span&gt;）同时将 TaskSetManager 添加 SchedduableBuilder 的任务池 Poll 中。&lt;br/&gt;&lt;span class=&quot;hljs-number&quot;&gt;4&lt;/span&gt;）调用 SchedulerBackend 的实现类进行 reviveOffers，这里是 standlone 模式的实现类 StandaloneSchedulerBackend。&lt;br/&gt;&lt;span class=&quot;hljs-number&quot;&gt;5&lt;/span&gt;）SchedulerBackend 发送 ReviveOffers 指令至 DriverEndpoint。&lt;br/&gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;h95drivertasksetmanagertaskdescriptionsexecutor&quot;&gt;&lt;span&gt;&lt;strong&gt;9.5 Driver 将 TaskSetManager 分解为 TaskDescriptions 并发布任务到 Executor&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;Driver 接受唤起消费指令后，将所有待处理的 TaskSetManager 与 Driver 中注册的 Executor 资源进行匹配，最终一个 TaskSetManager 得到多个 TaskDescription 对象，按照 TaskDescription 相对应的 Executor 发送 LaunchTask 指令。&lt;/p&gt;
&lt;img title=&quot;&quot; src=&quot;https://s2.ax1x.com/2019/05/02/EtPxmQ.png&quot; alt=&quot;&quot;/&gt;&lt;p&gt;详解如下：&lt;/p&gt;
&lt;pre readability=&quot;13&quot;&gt;
&lt;code class=&quot;java language-java hljs&quot; readability=&quot;20&quot;&gt;当 Driver 获取到 ReviveOffers（请求消费）指令时&lt;br/&gt;&lt;span class=&quot;hljs-number&quot;&gt;1&lt;/span&gt;）首先根据 executorDataMap 缓存信息得到可用的 Executor 资源信息（WorkerOffer），关键代码如下：&lt;br/&gt;val activeExecutors = executorDataMap.filterKeys(executorIsAlive)&lt;br/&gt;val workOffers = activeExecutors.map { &lt;span class=&quot;hljs-keyword&quot;&gt;case&lt;/span&gt; (id, executorData) =&amp;gt;&lt;br/&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;new&lt;/span&gt; WorkerOffer(id, executorData.executorHost, executorData.freeCores)&lt;br/&gt;}.toIndexedSeq&lt;p&gt;&lt;span class=&quot;hljs-number&quot;&gt;2&lt;/span&gt;）接着调用 TaskScheduler 进行资源匹配，方法定义如下：&lt;br/&gt;&lt;span class=&quot;hljs-function&quot;&gt;def &lt;span class=&quot;hljs-title&quot;&gt;resourceOffers&lt;/span&gt;&lt;span class=&quot;hljs-params&quot;&gt;(offers: IndexedSeq[WorkerOffer])&lt;/span&gt;: Seq[Seq[TaskDescription]] &lt;/span&gt;= &lt;span class=&quot;hljs-keyword&quot;&gt;synchronized&lt;/span&gt; {..}&lt;br/&gt;a) 将 WorkerOffer 资源打乱，如：val shuffledOffers = Random.shuffle(offers)&lt;br/&gt;b) 将 Pool 中待处理的 TaskSetManager 取出，如：val sortedTaskSets = rootPool.getSortedTaskSetQueue&lt;br/&gt;c) 并循环处理 sortedTaskSets 并与 shuffledOffers 循环匹配，如果 shuffledOffers(i) 有足够的 CPU 资源（ &lt;span class=&quot;hljs-keyword&quot;&gt;if&lt;/span&gt; (availableCpus(i) &amp;gt;= CPUS_PER_TASK)），调用 TaskSetManager 创建 TaskDescription 对象（taskSet.resourceOffer(execId, host, maxLocality)），最终创建了多个 TaskDescription，TaskDescription 定义如下：&lt;br/&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;new&lt;/span&gt; TaskDescription(&lt;br/&gt;taskId,&lt;br/&gt;attemptNum,&lt;br/&gt;execId,&lt;br/&gt;taskName,&lt;br/&gt;index,&lt;br/&gt;sched.sc.addedFiles,&lt;br/&gt;sched.sc.addedJars,&lt;br/&gt;task.localProperties,&lt;br/&gt;serializedTask)&lt;/p&gt;&lt;p&gt;&lt;span class=&quot;hljs-number&quot;&gt;3&lt;/span&gt;）如果 TaskDescriptions 不为空，循环 TaskDescriptions，序列化 TaskDescription 对象，并向 ExecutorEndpoint 发送 LaunchTask 指令，关键代码如下：&lt;br/&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;for&lt;/span&gt; (task &amp;lt;- taskDescriptions.flatten) {&lt;br/&gt;val serializedTask = TaskDescription.encode(task)&lt;br/&gt;val executorData = executorDataMap(task.executorId)&lt;br/&gt;executorData.freeCores -= scheduler.CPUS_PER_TASK&lt;br/&gt;executorData.executorEndpoint.send(LaunchTask(&lt;span class=&quot;hljs-keyword&quot;&gt;new&lt;/span&gt; SerializableBuffer(serializedTask)))&lt;br/&gt;}&lt;br/&gt;&lt;/p&gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;h10task&quot;&gt;&lt;span&gt;&lt;strong&gt;第10章 Task 执行和回馈&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;
&lt;p&gt;DriverEndpoint 最终生成多个可执行的 TaskDescription 对象，并向各个 ExecutorEndpoint 发送 LaunchTask 指令，本节内容将关注 ExecutorEndpoint 如何处理 LaunchTask 指令，处理完成后如何回馈给 DriverEndpoint，以及整个 job 最终如何多次调度直至结束。&lt;/p&gt;
&lt;h3 id=&quot;h101task&quot;&gt;&lt;span&gt;&lt;strong&gt;10.1 Task 的执行流程&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;Executor 接受 LaunchTask 指令后，开启一个新线程 TaskRunner 解析 RDD，并调用 RDD 的 compute 方法，归并函数得到最终任务执行结果。&lt;/p&gt;
&lt;img title=&quot;&quot; src=&quot;https://s2.ax1x.com/2019/05/02/EtPX6S.png&quot; alt=&quot;&quot;/&gt;&lt;p&gt;详解如下：&lt;/p&gt;
&lt;pre readability=&quot;8.5&quot;&gt;
&lt;code class=&quot;java language-java hljs&quot; readability=&quot;11&quot;&gt;&lt;span class=&quot;hljs-number&quot;&gt;1&lt;/span&gt;）ExecutorEndpoint 接受到 LaunchTask 指令后，解码出 TaskDescription，调用 Executor 的 launchTask 方法。&lt;br/&gt;&lt;span class=&quot;hljs-number&quot;&gt;2&lt;/span&gt;）Executor 创建一个 TaskRunner 线程，并启动线程，同时将改线程添加到 Executor 的成员对象中，代码如下：&lt;br/&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;private&lt;/span&gt; val runningTasks = &lt;span class=&quot;hljs-keyword&quot;&gt;new&lt;/span&gt; ConcurrentHashMap[Long, TaskRunner]&lt;br/&gt;runningTasks.put(taskDescription.taskId, taskRunner)&lt;p&gt;TaskRunner&lt;br/&gt;&lt;span class=&quot;hljs-number&quot;&gt;1&lt;/span&gt;）首先向 DriverEndpoint 发送任务最新状态为 RUNNING。&lt;br/&gt;&lt;span class=&quot;hljs-number&quot;&gt;2&lt;/span&gt;）从 TaskDescription 解析出 Task，并调用 Task 的 run 方法。&lt;/p&gt;&lt;p&gt;Task&lt;br/&gt;&lt;span class=&quot;hljs-number&quot;&gt;1&lt;/span&gt;）创建 TaskContext 以及 CallerContext (与 HDFS 交互的上下文对象)。&lt;br/&gt;&lt;span class=&quot;hljs-number&quot;&gt;2&lt;/span&gt;）执行 Task 的 runTask 方法：&lt;br/&gt;a) 如果 Task 实例为 ShuffleMapTask：解析出 RDD 以及 ShuffleDependency 信息，调用 RDD 的 compute() 方法将结果写 Writer 中（Writer 这里不介绍，可以作为黑盒理解，比如写入一个文件中），返回 MapStatus 对象。&lt;br/&gt;b) 如果 Task 实例为 ResultTask：解析出 RDD 以及合并函数信息，调用函数将调用后的结果返回。&lt;/p&gt;&lt;p&gt;TaskRunner 将 Task 执行的结果序列化，再次向 DriverEndpoint 发送任务最新状态为 FINISHED。&lt;br/&gt;&lt;/p&gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;h102task&quot;&gt;&lt;span&gt;&lt;strong&gt;10.2 Task 的回馈流程&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;TaskRunner 执行结束后，都将执行状态发送至 DriverEndpoint，DriverEndpoint 最终反馈指令 CompletionEvent 发送至 DAGSchedulerEventProcessLoop 中。&lt;/p&gt;
&lt;img title=&quot;&quot; src=&quot;https://s2.ax1x.com/2019/05/02/EtPLSf.png&quot; alt=&quot;&quot;/&gt;&lt;p&gt;详解如下：&lt;/p&gt;
&lt;pre readability=&quot;21&quot;&gt;
&lt;code class=&quot;java language-java hljs&quot; readability=&quot;36&quot;&gt;&lt;span class=&quot;hljs-number&quot;&gt;1&lt;/span&gt;）DriverEndpoint 接收到 StatusUpdate 消息后，调用 TaskScheduler 的 statusUpdate(taskId, state, result) 方法&lt;br/&gt;&lt;span class=&quot;hljs-number&quot;&gt;2&lt;/span&gt;）TaskScheduler 如果任务结果是完成，那么清除该任务处理中的状态，并调动 TaskResultGetter 相关方法，关键代码如下：&lt;br/&gt;val taskSet = taskIdToTaskSetManager.get(tid)&lt;p&gt;taskIdToTaskSetManager.remove(tid)&lt;br/&gt;taskIdToExecutorId.remove(tid).foreach { executorId =&amp;gt;&lt;br/&gt;executorIdToRunningTaskIds.get(executorId).foreach { _.remove(tid) }&lt;br/&gt;}&lt;br/&gt;taskSet.removeRunningTask(tid)&lt;br/&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;if&lt;/span&gt; (state == TaskState.FINISHED) {&lt;br/&gt;taskResultGetter.enqueueSuccessfulTask(taskSet, tid, serializedData)&lt;br/&gt;} &lt;span class=&quot;hljs-keyword&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;hljs-keyword&quot;&gt;if&lt;/span&gt; (Set(TaskState.FAILED, TaskState.KILLED, TaskState.LOST).contains(state)) {&lt;br/&gt;taskResultGetter.enqueueFailedTask(taskSet, tid, state, serializedData)&lt;br/&gt;}&lt;/p&gt;&lt;p&gt;TaskResultGetter 启动线程启动线程【task-result-getter】进行相关处理：&lt;br/&gt;&lt;span class=&quot;hljs-number&quot;&gt;1&lt;/span&gt;）通过解析或者远程获取得到 Task 的 TaskResult 对象。&lt;br/&gt;&lt;span class=&quot;hljs-number&quot;&gt;2&lt;/span&gt;）调用 TaskSet 的 handleSuccessfulTask 方法，TaskSet 的 handleSuccessfulTask 方法直接调用 TaskSetManager 的 handleSuccessfulTask 方法。&lt;/p&gt;&lt;p&gt;TaskSetManager&lt;br/&gt;&lt;span class=&quot;hljs-number&quot;&gt;1&lt;/span&gt;）更新内部 TaskInfo 对象状态，并将该 Task 从运行中 Task 的集合删除，代码如下：&lt;br/&gt;val info = taskInfos(tid)&lt;br/&gt;info.markFinished(TaskState.FINISHED, clock.getTimeMillis())&lt;br/&gt;removeRunningTask(tid)&lt;br/&gt;&lt;span class=&quot;hljs-number&quot;&gt;2&lt;/span&gt;）调用 DAGScheduler 的 taskEnded 方法，关键代码如下：&lt;br/&gt;sched.dagScheduler.taskEnded(tasks(index), Success, result.value(), result.accumUpdates, info)&lt;/p&gt;&lt;p&gt;DAGScheduler 向 DAGSchedulerEventProcessLoop 存入 CompletionEvent 指令，CompletionEvent 对象定义如下：&lt;br/&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;private&lt;/span&gt;[scheduler] &lt;span class=&quot;hljs-function&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;case&lt;/span&gt; class &lt;span class=&quot;hljs-title&quot;&gt;CompletionEvent&lt;/span&gt;&lt;span class=&quot;hljs-params&quot;&gt;(&lt;br/&gt;task: Task[_],&lt;br/&gt;reason: TaskEndReason,&lt;br/&gt;result: Any,&lt;br/&gt;accumUpdates: Seq[AccumulatorV2[_, _]],&lt;br/&gt;taskInfo: TaskInfo)&lt;/span&gt; extends DAGSchedulerEvent&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;h103task&quot;&gt;&lt;span&gt;&lt;strong&gt;10.3 Task 的迭代流程&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;DAGSchedulerEventProcessLoop 中针对于 CompletionEvent 指令，调用 DAGScheduler 进行处理，DAGScheduler 更新 Stage 与该 Task 的关系状态，如果 Stage 下 Task 都返回，则做下一层 Stage 的任务拆解与运算工作，直至 Job 被执行完毕：&lt;/p&gt;
&lt;img title=&quot;&quot; src=&quot;https://s2.ax1x.com/2019/05/02/EtPzwj.png&quot; alt=&quot;&quot;/&gt;&lt;p&gt;详解如下：&lt;/p&gt;
&lt;pre readability=&quot;4&quot;&gt;
&lt;code class=&quot;java language-java hljs&quot; readability=&quot;2&quot;&gt;&lt;span class=&quot;hljs-number&quot;&gt;1&lt;/span&gt;）DAGSchedulerEventProcessLoop 接收到 CompletionEvent 指令后，调用 DAGScheduler 的 handleTaskCompletion 方法。&lt;br/&gt;&lt;span class=&quot;hljs-number&quot;&gt;2&lt;/span&gt;）DAGScheduler 根据 Task 的类型分别处理。&lt;br/&gt;&lt;span class=&quot;hljs-number&quot;&gt;3&lt;/span&gt;）如果 Task 为 ShuffleMapTask&lt;br/&gt;a) 等待回馈的 Partitions 减去当前 partitionId&lt;br/&gt;b) 如果所有 task 都返回，则 markStageAsFinished(shuffleStage)，同时向 MapOutputTrackerMaster 注册 MapOutputs 信息，且 markMapStageJobAsFinished&lt;br/&gt;c) 调用 submitWaitingChildStages(shuffleStage) 进行下层 Stages 的处理，从而迭代处理，最终处理到 ResultTask，job 结束，关键代码如下：&lt;br/&gt;&lt;span class=&quot;hljs-function&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;private&lt;/span&gt; def &lt;span class=&quot;hljs-title&quot;&gt;submitWaitingChildStages&lt;/span&gt;&lt;span class=&quot;hljs-params&quot;&gt;(parent: Stage)&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;...&lt;br/&gt;val childStages = waitingStages.filter(_.parents.contains(parent)).toArray&lt;br/&gt;waitingStages --= &lt;span class=&quot;hljs-function&quot;&gt;childStages&lt;br/&gt;&lt;span class=&quot;hljs-title&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;hljs-params&quot;&gt;(stage &amp;lt;- childStages.sortBy(_.firstJobId)&lt;/span&gt;) &lt;/span&gt;{&lt;br/&gt;submitStage(stage)&lt;br/&gt;}&lt;br/&gt;}&lt;br/&gt;&lt;span class=&quot;hljs-number&quot;&gt;4&lt;/span&gt;）如果 Task 为 ResultTask&lt;br/&gt;a) 该 job 的 partitions 都已返回，则 markStageAsFinished(resultStage)，并 cleanupStateForJobAndIndependentStages(job)，关键代码如下：&lt;br/&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;for&lt;/span&gt; (stage &amp;lt;- stageIdToStage.get(stageId)) {&lt;br/&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;if&lt;/span&gt; (runningStages.contains(stage)) {&lt;br/&gt;logDebug(&lt;span class=&quot;hljs-string&quot;&gt;&quot;Removing running stage %d&quot;&lt;/span&gt;.format(stageId))&lt;br/&gt;runningStages -= stage&lt;br/&gt;}&lt;br/&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;for&lt;/span&gt; ((k, v) &amp;lt;- shuffleIdToMapStage.find(_._2 == stage)) {&lt;br/&gt;shuffleIdToMapStage.remove(k)&lt;br/&gt;}&lt;br/&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;if&lt;/span&gt; (waitingStages.contains(stage)) {&lt;br/&gt;logDebug(&lt;span class=&quot;hljs-string&quot;&gt;&quot;Removing stage %d from waiting set.&quot;&lt;/span&gt;.format(stageId))&lt;br/&gt;waitingStages -= stage&lt;br/&gt;}&lt;br/&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;if&lt;/span&gt; (failedStages.contains(stage)) {&lt;br/&gt;logDebug(&lt;span class=&quot;hljs-string&quot;&gt;&quot;Removing stage %d from failed set.&quot;&lt;/span&gt;.format(stageId))&lt;br/&gt;failedStages -= stage&lt;br/&gt;}&lt;br/&gt;}&lt;br/&gt;stageIdToStage -= stageId&lt;br/&gt;jobIdToStageIds -= job.jobId&lt;br/&gt;jobIdToActiveJob -= job.jobId&lt;br/&gt;activeJobs -= job&lt;p&gt;至此，用户编写的代码最终调用 Spark 分布式计算完毕。&lt;br/&gt;&lt;/p&gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;h104&quot;&gt;&lt;span&gt;&lt;strong&gt;10.4 精彩图解&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;Spark的交互流程 – 节点启动&lt;/p&gt;
&lt;img title=&quot;&quot; src=&quot;https://s2.ax1x.com/2019/05/02/EtPOl8.png&quot; alt=&quot;&quot;/&gt;&lt;br/&gt;Spark的交互流程 – 应用提交&lt;br/&gt;&lt;img title=&quot;&quot; src=&quot;https://s2.ax1x.com/2019/05/02/EtPjOg.png&quot; alt=&quot;&quot;/&gt;&lt;br/&gt;Spark的交互流程 – 任务运行&lt;br/&gt;&lt;img title=&quot;&quot; src=&quot;https://s2.ax1x.com/2019/05/02/EtjLi8.png&quot; alt=&quot;&quot;/&gt;&lt;br/&gt;Spark的交互流程 – 任务运行&lt;br/&gt;&lt;img title=&quot;&quot; src=&quot;https://s2.ax1x.com/2019/05/02/Etj7Zt.png&quot; alt=&quot;&quot;/&gt;&lt;h2 id=&quot;h11spark&quot;&gt;&lt;span&gt;&lt;strong&gt;第11章 Spark 的数据存储&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;
&lt;p&gt;Spark 计算速度远胜于 Hadoop 的原因之一就在于中间结果是缓存在内存而不是直接写入到 disk，本文尝试分析 Spark 中存储子系统的构成，并以数据写入和数据读取为例，讲述清楚存储子系统中各部件的交互关系。&lt;/p&gt;
&lt;h3 id=&quot;h111&quot;&gt;&lt;span&gt;&lt;strong&gt;11.1 存储子系统概览&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;Storage 模块主要分为两层：&lt;br/&gt;  1) 通信层：storage 模块采用的是 master-slave 结构来实现通信层，master 和 slave 之间传输控制信息、状态信息，这些都是通过通信层来实现的。&lt;br/&gt;  2) 存储层：storage 模块需要把数据存储到 disk 或是 memory 上面，有可能还需 replicate(复制) 到远端，这都是由存储层来实现和提供相应接口。&lt;br/&gt;而其他模块若要和 storage 模块进行交互，storage 模块提供了统一的操作类 BlockManager，外部类与 storage 模块打交道都需要通过调用 BlockManager 相应接口来实现。&lt;/p&gt;
&lt;img title=&quot;&quot; src=&quot;https://s2.ax1x.com/2019/05/02/EtjbIf.png&quot; alt=&quot;&quot;/&gt;&lt;br/&gt;上图是Spark存储子系统中几个主要模块的关系示意图，现简要说明如下：
&lt;pre&gt;
&lt;code class=&quot;java language-java hljs&quot;&gt;&lt;span class=&quot;hljs-number&quot;&gt;1&lt;/span&gt;）CacheManager         RDD 在进行计算的时候，通过 CacheManager 来获取数据，并通过 CacheManager 来存储计算结果。&lt;br/&gt;&lt;span class=&quot;hljs-number&quot;&gt;2&lt;/span&gt;）BlockManager         CacheManager 在进行数据读取和存取的时候主要是依赖 BlockManager 接口来操作，BlockManager 决定数据是从内存(MemoryStore) 还是从磁盘(DiskStore) 中获取。&lt;br/&gt;&lt;span class=&quot;hljs-number&quot;&gt;3&lt;/span&gt;）MemoryStore          负责将数据保存在内存或从内存读取。&lt;br/&gt;&lt;span class=&quot;hljs-number&quot;&gt;4&lt;/span&gt;）DiskStore            负责将数据写入磁盘或从磁盘读入。&lt;br/&gt;&lt;span class=&quot;hljs-number&quot;&gt;5&lt;/span&gt;）BlockManagerWorker   数据写入本地的 MemoryStore 或 DiskStore 是一个同步操作，为了容错还需要将数据复制到别的计算结点，以防止数据丢失的时候还能够恢复，数据复制的操作是异步完成，由 BlockManagerWorker 来处理这一部分事情。&lt;br/&gt;&lt;span class=&quot;hljs-number&quot;&gt;6&lt;/span&gt;）ConnectionManager    负责与其它计算结点建立连接，并负责数据的发送和接收。&lt;br/&gt;&lt;span class=&quot;hljs-number&quot;&gt;7&lt;/span&gt;）BlockManagerMaster   注意该模块只运行在 Driver Application 所在的 Executor，功能是负责记录下所有 BlockIds 存储在哪个 SlaveWorker 上，比如 RDD Task 运行在机器 A，所需要的 BlockId 为 &lt;span class=&quot;hljs-number&quot;&gt;3&lt;/span&gt;，但在机器 A 上没有 BlockId 为 &lt;span class=&quot;hljs-number&quot;&gt;3&lt;/span&gt; 的数值，这个时候 Slave worker 需要通过 BlockManager 向 BlockManagerMaster 询问数据存储的位置，然后再通过 ConnectionManager 去获取。&lt;br/&gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;h112&quot;&gt;&lt;span&gt;&lt;strong&gt;11.2 启动过程分析&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;上述的各个模块由 SparkEnv 来创建，创建过程在 SparkEnv.create 中完成，代码如下：&lt;/p&gt;
&lt;pre readability=&quot;5&quot;&gt;
&lt;code class=&quot;java language-java hljs&quot; readability=&quot;4&quot;&gt;val blockManagerMaster = &lt;span class=&quot;hljs-keyword&quot;&gt;new&lt;/span&gt; BlockManagerMaster(registerOrLookup(&lt;br/&gt;&lt;span class=&quot;hljs-string&quot;&gt;&quot;BlockManagerMaster&quot;&lt;/span&gt;,&lt;br/&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;new&lt;/span&gt; BlockManagerMasterActor(isLocal, conf)), conf)&lt;br/&gt;val blockManager = &lt;span class=&quot;hljs-keyword&quot;&gt;new&lt;/span&gt; BlockManager(executorId, actorSystem, blockManagerMaster, serializer, conf)&lt;p&gt;val connectionManager = blockManager.connectionManager&lt;br/&gt;val broadcastManager = &lt;span class=&quot;hljs-keyword&quot;&gt;new&lt;/span&gt; BroadcastManager(isDriver, conf)&lt;br/&gt;val cacheManager = &lt;span class=&quot;hljs-keyword&quot;&gt;new&lt;/span&gt; CacheManager(blockManager)&lt;br/&gt;&lt;/p&gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;下面这段代码容易让人疑惑，看起来像是在所有的 cluster node 上都创建了 BlockManagerMasterActor，其实不然，仔细看 registerOrLookup 函数的实现。如果当前节点是 driver 则创建这个 actor，否则建立到 driver 的连接。代码如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;java language-java hljs&quot;&gt;&lt;span class=&quot;hljs-function&quot;&gt;def &lt;span class=&quot;hljs-title&quot;&gt;registerOrLookup&lt;/span&gt;&lt;span class=&quot;hljs-params&quot;&gt;(name: String, newActor: =&amp;gt; Actor)&lt;/span&gt;: ActorRef &lt;/span&gt;= {&lt;br/&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;if&lt;/span&gt; (isDriver) {&lt;br/&gt;logInfo(&lt;span class=&quot;hljs-string&quot;&gt;&quot;Registering &quot;&lt;/span&gt; + name)&lt;br/&gt;actorSystem.actorOf(Props(newActor), name = name)&lt;br/&gt;} &lt;span class=&quot;hljs-keyword&quot;&gt;else&lt;/span&gt; {&lt;br/&gt;val driverHost: String = conf.get(&lt;span class=&quot;hljs-string&quot;&gt;&quot;spark.driver.host&quot;&lt;/span&gt;, &lt;span class=&quot;hljs-string&quot;&gt;&quot;localhost&quot;&lt;/span&gt;)&lt;br/&gt;val driverPort: Int = conf.getInt(&lt;span class=&quot;hljs-string&quot;&gt;&quot;spark.driver.port&quot;&lt;/span&gt;, &lt;span class=&quot;hljs-number&quot;&gt;7077&lt;/span&gt;)&lt;br/&gt;Utils.checkHost(driverHost, &lt;span class=&quot;hljs-string&quot;&gt;&quot;Expected hostname&quot;&lt;/span&gt;)&lt;br/&gt;val url = s&lt;span class=&quot;hljs-string&quot;&gt;&quot;akka.tcp://spark@$driverHost:$driverPort/user/$name&quot;&lt;/span&gt;&lt;br/&gt;val timeout = AkkaUtils.lookupTimeout(conf)&lt;br/&gt;logInfo(s&lt;span class=&quot;hljs-string&quot;&gt;&quot;Connecting to $name: $url&quot;&lt;/span&gt;)&lt;br/&gt;Await.result(actorSystem.actorSelection(url).resolveOne(timeout), timeout)&lt;br/&gt;}&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;初始化过程中一个主要的动作就是 BlockManager 需要向 BlockManagerMaster 发起注册。&lt;/p&gt;
&lt;h3 id=&quot;h113&quot;&gt;&lt;span&gt;&lt;strong&gt;11.3 通信层&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;img title=&quot;&quot; src=&quot;https://s2.ax1x.com/2019/05/02/EtjXRg.png&quot; alt=&quot;&quot;/&gt;&lt;br/&gt;BlockManager 包装了 BlockManagerMaster，发送信息包装成 BlockManagerInfo。Spark 在 Driver 和 Worker 端都创建各自的 BlockManager，并通过 BlockManagerMaster 进行通信，通过 BlockManager 对 Storage 模块进行操作。&lt;br/&gt;BlockManager 对象在 SparkEnv.create 函数中进行创建，代码如下：
&lt;pre readability=&quot;9&quot;&gt;
&lt;code class=&quot;java language-java hljs&quot; readability=&quot;12&quot;&gt;&lt;span class=&quot;hljs-function&quot;&gt;def &lt;span class=&quot;hljs-title&quot;&gt;registerOrLookupEndpoint&lt;/span&gt;&lt;span class=&quot;hljs-params&quot;&gt;(&lt;br/&gt;name: String, endpointCreator: =&amp;gt; RpcEndpoint)&lt;/span&gt;:&lt;br/&gt;RpcEndpointRef &lt;/span&gt;= {&lt;br/&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;if&lt;/span&gt; (isDriver) {&lt;br/&gt;logInfo(&lt;span class=&quot;hljs-string&quot;&gt;&quot;Registering &quot;&lt;/span&gt; + name)&lt;br/&gt;rpcEnv.setupEndpoint(name, endpointCreator)&lt;br/&gt;} &lt;span class=&quot;hljs-keyword&quot;&gt;else&lt;/span&gt; {&lt;br/&gt;RpcUtils.makeDriverRef(name, conf, rpcEnv)&lt;br/&gt;}&lt;br/&gt;}&lt;br/&gt;......&lt;br/&gt;val blockManagerMaster = &lt;span class=&quot;hljs-keyword&quot;&gt;new&lt;/span&gt; BlockManagerMaster(registerOrLookupEndpoint(&lt;br/&gt;BlockManagerMaster.DRIVER_ENDPOINT_NAME,&lt;br/&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;new&lt;/span&gt; BlockManagerMasterEndpoint(rpcEnv, isLocal, conf, listenerBus)),&lt;br/&gt;conf, isDriver)&lt;p&gt;&lt;br/&gt;val blockManager = &lt;span class=&quot;hljs-keyword&quot;&gt;new&lt;/span&gt; BlockManager(executorId, rpcEnv, blockManagerMaster,&lt;br/&gt;serializer, conf, mapOutputTracker, shuffleManager, blockTransferService, securityManager,numUsableCores)&lt;br/&gt;&lt;/p&gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;并且在创建之前对当前节点是否是 Driver 进行了判断。如果是，则创建这个 Endpoint；否则，创建 Driver 的连接。&lt;/p&gt;
&lt;p&gt;在创建 BlockManager 之后，BlockManager 会调用 initialize 方法初始化自己。并且初始化的时候，会调用 BlockManagerMaster 向 Driver 注册自己，同时，在注册时也启动了Slave Endpoint。另外，向本地 shuffle 服务器注册 Executor 配置，如果存在的话。代码如下：&lt;/p&gt;
&lt;pre readability=&quot;4.5&quot;&gt;
&lt;code class=&quot;java language-java hljs&quot; readability=&quot;3&quot;&gt;&lt;span class=&quot;hljs-function&quot;&gt;def &lt;span class=&quot;hljs-title&quot;&gt;initialize&lt;/span&gt;&lt;span class=&quot;hljs-params&quot;&gt;(appId: String)&lt;/span&gt;: Unit &lt;/span&gt;= {&lt;br/&gt;......&lt;br/&gt;master.registerBlockManager(blockManagerId, maxMemory, slaveEndpoint)&lt;p&gt;&lt;br/&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;if&lt;/span&gt; (externalShuffleServiceEnabled &amp;amp;&amp;amp; !blockManagerId.isDriver) {&lt;br/&gt;registerWithExternalShuffleServer()&lt;br/&gt;}&lt;br/&gt;}&lt;br/&gt;&lt;/p&gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;而 BlockManagerMaster 将注册请求包装成 RegisterBlockManager 注册到 Driver。Driver 的 BlockManagerMasterEndpoint 会调用 register 方法，通过对消息 BlockManagerInfo 检查，向 Driver 注册，代码如下：&lt;/p&gt;
&lt;pre readability=&quot;8&quot;&gt;
&lt;code class=&quot;java language-java hljs&quot; readability=&quot;10&quot;&gt;&lt;span class=&quot;hljs-function&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;private&lt;/span&gt; def &lt;span class=&quot;hljs-title&quot;&gt;register&lt;/span&gt;&lt;span class=&quot;hljs-params&quot;&gt;(id: BlockManagerId, maxMemSize: Long, slaveEndpoint: RpcEndpointRef)&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;val time = System.currentTimeMillis()&lt;br/&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;if&lt;/span&gt; (!blockManagerInfo.contains(id)) {&lt;br/&gt;blockManagerIdByExecutor.get(id.executorId) match {&lt;br/&gt;&lt;span class=&quot;hljs-function&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;hljs-title&quot;&gt;Some&lt;/span&gt;&lt;span class=&quot;hljs-params&quot;&gt;(oldId)&lt;/span&gt; &lt;/span&gt;=&amp;gt;&lt;br/&gt;logError(&lt;span class=&quot;hljs-string&quot;&gt;&quot;Got two different block manager registrations on same executor - &quot;&lt;/span&gt;&lt;br/&gt;+ s&lt;span class=&quot;hljs-string&quot;&gt;&quot; will replace old one $oldId with new one $id&quot;&lt;/span&gt;)&lt;br/&gt;removeExecutor(id.executorId)&lt;br/&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;case&lt;/span&gt; None =&amp;gt;&lt;br/&gt;}&lt;br/&gt;logInfo(&lt;span class=&quot;hljs-string&quot;&gt;&quot;Registering block manager %s with %s RAM, %s&quot;&lt;/span&gt;.format(&lt;br/&gt;id.hostPort, Utils.bytesToString(maxMemSize), id))&lt;p&gt;blockManagerIdByExecutor(id.executorId) = &lt;span class=&quot;hljs-function&quot;&gt;id&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span class=&quot;hljs-title&quot;&gt;blockManagerInfo&lt;/span&gt;&lt;span class=&quot;hljs-params&quot;&gt;(id)&lt;/span&gt; = &lt;span class=&quot;hljs-keyword&quot;&gt;new&lt;/span&gt; BlockManagerInfo(&lt;br/&gt;id, System.currentTimeMillis(), maxMemSize, slaveEndpoint)&lt;br/&gt;}&lt;br/&gt;listenerBus.post(SparkListenerBlockManagerAdded(time, id, maxMemSize))&lt;br/&gt;}&lt;br/&gt;&lt;/p&gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;不难发现 BlockManagerInfo 对象被保存到 Map 映射中。在通信层中 BlockManagerMaster 控制着消息的流向，这里采用了模式匹配，所有的消息模式都在 BlockManagerMessage 中。&lt;/p&gt;
&lt;h3 id=&quot;h114&quot;&gt;&lt;span&gt;&lt;strong&gt;11.4 存储层&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;img title=&quot;&quot; src=&quot;https://s2.ax1x.com/2019/05/02/EtjoqI.png&quot; alt=&quot;&quot;/&gt;&lt;br/&gt;Spark Storage 的最小存储单位是 block，所有的操作都是以 block 为单位进行的。&lt;br/&gt;在 BlockManager 被创建的时候 MemoryStore 和 DiskStore 对象就被创建出来了。代码如下：
&lt;pre&gt;
&lt;code class=&quot;java language-java hljs&quot;&gt;val diskBlockManager = &lt;span class=&quot;hljs-keyword&quot;&gt;new&lt;/span&gt; DiskBlockManager(&lt;span class=&quot;hljs-keyword&quot;&gt;this&lt;/span&gt;, conf)&lt;br/&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;private&lt;/span&gt;[spark] val memoryStore = &lt;span class=&quot;hljs-keyword&quot;&gt;new&lt;/span&gt; MemoryStore(&lt;span class=&quot;hljs-keyword&quot;&gt;this&lt;/span&gt;, maxMemory)&lt;br/&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;private&lt;/span&gt;[spark] val diskStore = &lt;span class=&quot;hljs-keyword&quot;&gt;new&lt;/span&gt; DiskStore(&lt;span class=&quot;hljs-keyword&quot;&gt;this&lt;/span&gt;, diskBlockManager)&lt;br/&gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;h4 id=&quot;h1141diskstore&quot;&gt;&lt;span&gt;&lt;strong&gt;11.4.1 Disk Store&lt;/strong&gt;&lt;/span&gt;&lt;/h4&gt;
&lt;p&gt;由于当前的 Spark 版本对 Disk Store 进行了更细粒度的分工，把对文件的操作提取出来放到了 DiskBlockManager 中，DiskStore 仅仅负责数据的存储和读取。&lt;br/&gt;Disk Store 会配置多个文件目录，Spark 会在不同的文件目录下创建文件夹，其中文件夹的命名方式是：spark-UUID（随机UUID码）。Disk Store 在存储的时候创建文件夹。并且根据【高内聚，低耦合】原则，这种服务型的工具代码就放到了 Utils 中（调用路径：DiskStore.putBytes —&amp;gt; DiskBlockManager.createLocalDirs —&amp;gt; Utils.createDirectory），代码如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;java language-java hljs&quot;&gt;&lt;span class=&quot;hljs-function&quot;&gt;def &lt;span class=&quot;hljs-title&quot;&gt;createDirectory&lt;/span&gt;&lt;span class=&quot;hljs-params&quot;&gt;(root: String, namePrefix: String = &lt;span class=&quot;hljs-string&quot;&gt;&quot;spark&quot;&lt;/span&gt;)&lt;/span&gt;: File &lt;/span&gt;= {&lt;br/&gt;var attempts = &lt;span class=&quot;hljs-number&quot;&gt;0&lt;/span&gt;&lt;br/&gt;val maxAttempts = MAX_DIR_CREATION_ATTEMPTS&lt;br/&gt;var dir: File = &lt;span class=&quot;hljs-function&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;null&lt;/span&gt;&lt;br/&gt;&lt;span class=&quot;hljs-title&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;hljs-params&quot;&gt;(dir == &lt;span class=&quot;hljs-keyword&quot;&gt;null&lt;/span&gt;)&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;attempts += &lt;span class=&quot;hljs-number&quot;&gt;1&lt;/span&gt;&lt;br/&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;if&lt;/span&gt; (attempts &amp;gt; maxAttempts) {&lt;br/&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;throw&lt;/span&gt; &lt;span class=&quot;hljs-keyword&quot;&gt;new&lt;/span&gt; IOException(&lt;span class=&quot;hljs-string&quot;&gt;&quot;Failed to create a temp directory (under &quot;&lt;/span&gt; + root + &lt;span class=&quot;hljs-string&quot;&gt;&quot;) after &quot;&lt;/span&gt; +&lt;br/&gt;maxAttempts + &lt;span class=&quot;hljs-string&quot;&gt;&quot; attempts!&quot;&lt;/span&gt;)&lt;br/&gt;}&lt;br/&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;try&lt;/span&gt; {&lt;br/&gt;dir = &lt;span class=&quot;hljs-keyword&quot;&gt;new&lt;/span&gt; File(root, namePrefix + &lt;span class=&quot;hljs-string&quot;&gt;&quot;-&quot;&lt;/span&gt; + UUID.randomUUID.toString)&lt;br/&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;if&lt;/span&gt; (dir.exists() || !dir.mkdirs()) {&lt;br/&gt;dir = &lt;span class=&quot;hljs-keyword&quot;&gt;null&lt;/span&gt;&lt;br/&gt;}&lt;br/&gt;} &lt;span class=&quot;hljs-keyword&quot;&gt;catch&lt;/span&gt; { &lt;span class=&quot;hljs-keyword&quot;&gt;case&lt;/span&gt; e: SecurityException =&amp;gt; dir = &lt;span class=&quot;hljs-keyword&quot;&gt;null&lt;/span&gt;; }&lt;br/&gt;}&lt;p&gt;dir.getCanonicalFile&lt;br/&gt;}&lt;br/&gt;&lt;/p&gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;在 DiskBlockManager 里，每个 block 都被存储为一个 file，通过计算 blockId 的 hash 值，将 block 映射到文件中。&lt;/p&gt;
&lt;pre readability=&quot;8.5&quot;&gt;
&lt;code class=&quot;java language-java hljs&quot; readability=&quot;11&quot;&gt;&lt;span class=&quot;hljs-function&quot;&gt;def &lt;span class=&quot;hljs-title&quot;&gt;getFile&lt;/span&gt;&lt;span class=&quot;hljs-params&quot;&gt;(filename: String)&lt;/span&gt;: File &lt;/span&gt;= {&lt;br/&gt;val hash = Utils.nonNegativeHash(filename)&lt;br/&gt;val dirId = hash % localDirs.length&lt;br/&gt;val subDirId = (hash / localDirs.length) % subDirsPerLocalDir&lt;p&gt;&lt;br/&gt;val subDir = subDirs(dirId).&lt;span class=&quot;hljs-keyword&quot;&gt;synchronized&lt;/span&gt; {&lt;br/&gt;val old = subDirs(dirId)(subDirId)&lt;br/&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;if&lt;/span&gt; (old != &lt;span class=&quot;hljs-keyword&quot;&gt;null&lt;/span&gt;) {&lt;br/&gt;old&lt;br/&gt;} &lt;span class=&quot;hljs-keyword&quot;&gt;else&lt;/span&gt; {&lt;br/&gt;val newDir = &lt;span class=&quot;hljs-keyword&quot;&gt;new&lt;/span&gt; File(localDirs(dirId), &lt;span class=&quot;hljs-string&quot;&gt;&quot;%02x&quot;&lt;/span&gt;.format(subDirId))&lt;br/&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;if&lt;/span&gt; (!newDir.exists() &amp;amp;&amp;amp; !newDir.mkdir()) {&lt;br/&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;throw&lt;/span&gt; &lt;span class=&quot;hljs-keyword&quot;&gt;new&lt;/span&gt; IOException(s&lt;span class=&quot;hljs-string&quot;&gt;&quot;Failed to create local dir in $newDir.&quot;&lt;/span&gt;)&lt;br/&gt;}&lt;br/&gt;subDirs(dirId)(subDirId) = newDir&lt;br/&gt;newDir&lt;br/&gt;}&lt;br/&gt;}&lt;/p&gt;&lt;p&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;new&lt;/span&gt; File(subDir, filename)&lt;br/&gt;}&lt;/p&gt;&lt;p&gt;&lt;span class=&quot;hljs-function&quot;&gt;def &lt;span class=&quot;hljs-title&quot;&gt;getFile&lt;/span&gt;&lt;span class=&quot;hljs-params&quot;&gt;(blockId: BlockId)&lt;/span&gt;: File &lt;/span&gt;= getFile(blockId.name)&lt;br/&gt;&lt;/p&gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;通过 hash 值的取模运算，求出 dirId 和 subDirId。然后，在从 subDirs 中找到 subDir，如果 subDir 不存在，则创建一个新 subDir。最后，以 subDir 为路径，blockId 的 name 属性为文件名，新建该文件。&lt;br/&gt;文件创建完之后，那么 Spark 就会在 DiskStore 中向文件写与之映射的 block，代码如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;java language-java hljs&quot;&gt;&lt;span class=&quot;hljs-function&quot;&gt;override def &lt;span class=&quot;hljs-title&quot;&gt;putBytes&lt;/span&gt;&lt;span class=&quot;hljs-params&quot;&gt;(blockId: BlockId, _bytes: ByteBuffer, level: StorageLevel)&lt;/span&gt;: PutResult &lt;/span&gt;= {&lt;br/&gt;val bytes = _bytes.duplicate()&lt;br/&gt;logDebug(s&lt;span class=&quot;hljs-string&quot;&gt;&quot;Attempting to put block $blockId&quot;&lt;/span&gt;)&lt;br/&gt;val startTime = System.currentTimeMillis&lt;br/&gt;val file = diskManager.getFile(blockId)&lt;br/&gt;val channel = &lt;span class=&quot;hljs-keyword&quot;&gt;new&lt;/span&gt; FileOutputStream(file).getChannel&lt;br/&gt;Utils.tryWithSafeFinally {&lt;br/&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;while&lt;/span&gt; (bytes.remaining &amp;gt; &lt;span class=&quot;hljs-number&quot;&gt;0&lt;/span&gt;) {&lt;br/&gt;channel.write(bytes)&lt;br/&gt;}&lt;br/&gt;} {&lt;br/&gt;channel.close()&lt;br/&gt;}&lt;br/&gt;val finishTime = System.&lt;span class=&quot;hljs-function&quot;&gt;currentTimeMillis&lt;br/&gt;&lt;span class=&quot;hljs-title&quot;&gt;logDebug&lt;/span&gt;&lt;span class=&quot;hljs-params&quot;&gt;(&lt;span class=&quot;hljs-string&quot;&gt;&quot;Block %s stored as %s file on disk in %d ms&quot;&lt;/span&gt;.format(&lt;br/&gt;file.getName, Utils.bytesToString(bytes.limit)&lt;/span&gt;, finishTime - startTime))&lt;br/&gt;&lt;span class=&quot;hljs-title&quot;&gt;PutResult&lt;/span&gt;&lt;span class=&quot;hljs-params&quot;&gt;(bytes.limit()&lt;/span&gt;, &lt;span class=&quot;hljs-title&quot;&gt;Right&lt;/span&gt;&lt;span class=&quot;hljs-params&quot;&gt;(bytes.duplicate()&lt;/span&gt;))&lt;br/&gt;}&lt;br/&gt;&lt;/span&gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;读取过程就简单了，DiskStore 根据 blockId 读取与之映射的 file 内容，当然，这中间需要从 DiskBlockManager 中得到文件信息。代码如下：&lt;/p&gt;
&lt;pre readability=&quot;5.5&quot;&gt;
&lt;code class=&quot;java language-java hljs&quot; readability=&quot;5&quot;&gt;&lt;span class=&quot;hljs-function&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;private&lt;/span&gt; def &lt;span class=&quot;hljs-title&quot;&gt;getBytes&lt;/span&gt;&lt;span class=&quot;hljs-params&quot;&gt;(file: File, offset: Long, length: Long)&lt;/span&gt;: Option[ByteBuffer] &lt;/span&gt;= {&lt;br/&gt;val channel = &lt;span class=&quot;hljs-keyword&quot;&gt;new&lt;/span&gt; RandomAccessFile(file, &lt;span class=&quot;hljs-string&quot;&gt;&quot;r&quot;&lt;/span&gt;).getChannel&lt;br/&gt;Utils.tryWithSafeFinally {&lt;br/&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;if&lt;/span&gt; (length &amp;lt; minMemoryMapBytes) {&lt;br/&gt;val buf = ByteBuffer.allocate(length.toInt)&lt;br/&gt;channel.position(offset)&lt;br/&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;while&lt;/span&gt; (buf.remaining() != &lt;span class=&quot;hljs-number&quot;&gt;0&lt;/span&gt;) {&lt;br/&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;if&lt;/span&gt; (channel.read(buf) == -&lt;span class=&quot;hljs-number&quot;&gt;1&lt;/span&gt;) {&lt;br/&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;throw&lt;/span&gt; &lt;span class=&quot;hljs-keyword&quot;&gt;new&lt;/span&gt; IOException(&lt;span class=&quot;hljs-string&quot;&gt;&quot;Reached EOF before filling buffer\n&quot;&lt;/span&gt; +&lt;br/&gt;s&lt;span class=&quot;hljs-string&quot;&gt;&quot;offset=$offset\nfile=${file.getAbsolutePath}\nbuf.remaining=${buf.remaining}&quot;&lt;/span&gt;)&lt;br/&gt;}&lt;br/&gt;}&lt;br/&gt;buf.flip()&lt;br/&gt;Some(buf)&lt;br/&gt;} &lt;span class=&quot;hljs-keyword&quot;&gt;else&lt;/span&gt; {&lt;br/&gt;Some(channel.map(MapMode.READ_ONLY, offset, length))&lt;br/&gt;}&lt;br/&gt;} {&lt;br/&gt;channel.close()&lt;br/&gt;}&lt;br/&gt;}&lt;p&gt;&lt;span class=&quot;hljs-function&quot;&gt;override def &lt;span class=&quot;hljs-title&quot;&gt;getBytes&lt;/span&gt;&lt;span class=&quot;hljs-params&quot;&gt;(blockId: BlockId)&lt;/span&gt;: Option[ByteBuffer] &lt;/span&gt;= {&lt;br/&gt;val file = diskManager.getFile(blockId.name)&lt;br/&gt;getBytes(file, &lt;span class=&quot;hljs-number&quot;&gt;0&lt;/span&gt;, file.length)&lt;br/&gt;}&lt;br/&gt;&lt;/p&gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;h4 id=&quot;h1142memorystore&quot;&gt;&lt;span&gt;&lt;strong&gt;11.4.2 Memory Store&lt;/strong&gt;&lt;/span&gt;&lt;/h4&gt;
&lt;p&gt;相对 Disk Store，Memory Store 就显得容易很多。Memory Store 用一个 LinkedHashMap 来管理，其中 Key 是 blockId，Value 是 MemoryEntry 样例类，MemoryEntry 存储着数据信息。代码如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;java language-java hljs&quot;&gt;&lt;span class=&quot;hljs-function&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;hljs-keyword&quot;&gt;case&lt;/span&gt; class &lt;span class=&quot;hljs-title&quot;&gt;MemoryEntry&lt;/span&gt;&lt;span class=&quot;hljs-params&quot;&gt;(value: Any, size: Long, deserialized: Boolean)&lt;/span&gt;&lt;br/&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;private&lt;/span&gt; val entries &lt;/span&gt;= &lt;span class=&quot;hljs-keyword&quot;&gt;new&lt;/span&gt; LinkedHashMap[BlockId, MemoryEntry](&lt;span class=&quot;hljs-number&quot;&gt;32&lt;/span&gt;, &lt;span class=&quot;hljs-number&quot;&gt;0.75f&lt;/span&gt;, &lt;span class=&quot;hljs-keyword&quot;&gt;true&lt;/span&gt;)&lt;br/&gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;在 MemoryStore 中存储 block 的前提是当前内存有足够的空间存放。通过对 tryToPut 函数的调用对内存空间进行判断。代码如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;java language-java hljs&quot;&gt;&lt;span class=&quot;hljs-function&quot;&gt;def &lt;span class=&quot;hljs-title&quot;&gt;putBytes&lt;/span&gt;&lt;span class=&quot;hljs-params&quot;&gt;(blockId: BlockId, size: Long, _bytes: ()&lt;/span&gt; &lt;/span&gt;=&amp;gt; ByteBuffer): PutResult = {&lt;br/&gt;lazy val bytes = _bytes().duplicate().rewind().asInstanceOf[ByteBuffer]&lt;br/&gt;val putAttempt = tryToPut(blockId, () =&amp;gt; bytes, size, deserialized = &lt;span class=&quot;hljs-keyword&quot;&gt;false&lt;/span&gt;)&lt;br/&gt;val data =&lt;br/&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;if&lt;/span&gt; (putAttempt.success) {&lt;br/&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;assert&lt;/span&gt;(bytes.limit == size)&lt;br/&gt;Right(bytes.duplicate())&lt;br/&gt;} &lt;span class=&quot;hljs-keyword&quot;&gt;else&lt;/span&gt; {&lt;br/&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;null&lt;/span&gt;&lt;br/&gt;}&lt;br/&gt;PutResult(size, data, putAttempt.droppedBlocks)&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;在 tryToPut 函数中，通过调用 enoughFreeSpace 函数判断内存空间。如果内存空间足够，那么就把 block 放到 LinkedHashMap 中；如果内存不足，那么就告诉 BlockManager 内存不足，如果允许 Disk Store，那么就把该 block 放到 disk 上。代码如下：&lt;/p&gt;
&lt;pre readability=&quot;12.5&quot;&gt;
&lt;code class=&quot;java language-java hljs&quot; readability=&quot;19&quot;&gt;&lt;span class=&quot;hljs-function&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;private&lt;/span&gt; def &lt;span class=&quot;hljs-title&quot;&gt;tryToPut&lt;/span&gt;&lt;span class=&quot;hljs-params&quot;&gt;(blockId: BlockId, value: ()&lt;/span&gt; &lt;/span&gt;=&amp;gt; Any, size: Long, deserialized: Boolean): ResultWithDroppedBlocks = {&lt;br/&gt;var putSuccess = &lt;span class=&quot;hljs-keyword&quot;&gt;false&lt;/span&gt;&lt;br/&gt;val droppedBlocks = &lt;span class=&quot;hljs-keyword&quot;&gt;new&lt;/span&gt; ArrayBuffer[(BlockId, BlockStatus)]&lt;p&gt;accountingLock.&lt;span class=&quot;hljs-keyword&quot;&gt;synchronized&lt;/span&gt; {&lt;br/&gt;val freeSpaceResult = ensureFreeSpace(blockId, size)&lt;br/&gt;val enoughFreeSpace = freeSpaceResult.success&lt;br/&gt;droppedBlocks ++= freeSpaceResult.&lt;span class=&quot;hljs-function&quot;&gt;droppedBlocks&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span class=&quot;hljs-title&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;hljs-params&quot;&gt;(enoughFreeSpace)&lt;/span&gt; {&lt;br/&gt;val entry = &lt;span class=&quot;hljs-keyword&quot;&gt;new&lt;/span&gt; MemoryEntry(value(), size, deserialized)&lt;br/&gt;entries.&lt;span class=&quot;hljs-keyword&quot;&gt;synchronized&lt;/span&gt; {&lt;br/&gt;entries.put(blockId, entry)&lt;br/&gt;currentMemory += size&lt;br/&gt;}&lt;br/&gt;val valuesOrBytes = &lt;span class=&quot;hljs-keyword&quot;&gt;if&lt;/span&gt; (deserialized) &lt;span class=&quot;hljs-string&quot;&gt;&quot;values&quot;&lt;/span&gt; &lt;span class=&quot;hljs-keyword&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;hljs-string&quot;&gt;&quot;bytes&quot;&lt;/span&gt;&lt;br/&gt;logInfo(&lt;span class=&quot;hljs-string&quot;&gt;&quot;Block %s stored as %s in memory (estimated size %s, free %s)&quot;&lt;/span&gt;.format(&lt;br/&gt;blockId, valuesOrBytes, Utils.bytesToString(size), Utils.bytesToString(freeMemory)))&lt;br/&gt;putSuccess = &lt;span class=&quot;hljs-keyword&quot;&gt;true&lt;/span&gt;&lt;br/&gt;} &lt;span class=&quot;hljs-keyword&quot;&gt;else&lt;/span&gt; {&lt;br/&gt;lazy val data = &lt;span class=&quot;hljs-keyword&quot;&gt;if&lt;/span&gt; (deserialized) {&lt;br/&gt;Left(value().asInstanceOf[Array[Any]])&lt;br/&gt;} &lt;span class=&quot;hljs-keyword&quot;&gt;else&lt;/span&gt; {&lt;br/&gt;Right(value().asInstanceOf[ByteBuffer].duplicate())&lt;br/&gt;}&lt;br/&gt;val droppedBlockStatus = blockManager.dropFromMemory(blockId, () =&amp;gt; data)&lt;br/&gt;droppedBlockStatus.foreach { status =&amp;gt; droppedBlocks += ((blockId, status)) }&lt;br/&gt;}&lt;br/&gt;releasePendingUnrollMemoryForThisTask()&lt;br/&gt;}&lt;br/&gt;ResultWithDroppedBlocks(putSuccess, droppedBlocks)&lt;br/&gt;}&lt;br/&gt;&lt;/p&gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;Memory Store 读取 block 也很简单，只需要从 LinkedHashMap 中取出 blockId 的 Value 即可。代码如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;java language-java hljs&quot;&gt;&lt;span class=&quot;hljs-function&quot;&gt;override def &lt;span class=&quot;hljs-title&quot;&gt;getValues&lt;/span&gt;&lt;span class=&quot;hljs-params&quot;&gt;(blockId: BlockId)&lt;/span&gt;: Option[Iterator[Any]] &lt;/span&gt;= {&lt;br/&gt;val entry = entries.&lt;span class=&quot;hljs-keyword&quot;&gt;synchronized&lt;/span&gt; {&lt;br/&gt;entries.get(blockId)&lt;br/&gt;}&lt;br/&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;if&lt;/span&gt; (entry == &lt;span class=&quot;hljs-keyword&quot;&gt;null&lt;/span&gt;) {&lt;br/&gt;None&lt;br/&gt;} &lt;span class=&quot;hljs-keyword&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;hljs-keyword&quot;&gt;if&lt;/span&gt; (entry.deserialized) {&lt;br/&gt;Some(entry.value.asInstanceOf[Array[Any]].iterator)&lt;br/&gt;} &lt;span class=&quot;hljs-keyword&quot;&gt;else&lt;/span&gt; {&lt;br/&gt;val buffer = entry.value.asInstanceOf[ByteBuffer].duplicate() &lt;br/&gt;Some(blockManager.dataDeserialize(blockId, buffer))&lt;br/&gt;}&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;h115&quot;&gt;&lt;span&gt;&lt;strong&gt;11.5 数据写入过程分析&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;img title=&quot;&quot; src=&quot;https://s2.ax1x.com/2019/05/02/ENp9cF.png&quot; alt=&quot;&quot;/&gt;&lt;br/&gt;数据写入的简要流程：
&lt;pre&gt;
&lt;code class=&quot;java language-java hljs&quot;&gt;&lt;span class=&quot;hljs-number&quot;&gt;1&lt;/span&gt;）RDD.iterator 是与 storage 子系统交互的入口。&lt;br/&gt;&lt;span class=&quot;hljs-number&quot;&gt;2&lt;/span&gt;）CacheManager.getOrCompute 调用 BlockManager 的 put 接口来写入数据。&lt;br/&gt;&lt;span class=&quot;hljs-number&quot;&gt;3&lt;/span&gt;）数据优先写入到 MemoryStore 即内存，如果 MemoryStore 中的数据已满则将最近使用次数不频繁的数据写入到磁盘。&lt;br/&gt;&lt;span class=&quot;hljs-number&quot;&gt;4&lt;/span&gt;）通知 BlockManagerMaster 有新的数据写入，在 BlockManagerMaster 中保存元数据。&lt;br/&gt;&lt;span class=&quot;hljs-number&quot;&gt;5&lt;/span&gt;）将写入的数据与其它 slave worker 进行同步，一般来说在本机写入的数据，都会另先一台机器来进行数据的备份，即 replicanumber=&lt;span class=&quot;hljs-number&quot;&gt;1&lt;/span&gt;。&lt;br/&gt;其实，我们在 put 和 get block 的时候并没有那么复杂，前面的细节 BlockManager 都包装好了，我们只需要调用 BlockManager 中的 put 和 get 函数即可。&lt;br/&gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;代码如下：&lt;/p&gt;
&lt;pre readability=&quot;47&quot;&gt;
&lt;code class=&quot;java language-java hljs&quot; readability=&quot;88&quot;&gt;&lt;span class=&quot;hljs-function&quot;&gt;def &lt;span class=&quot;hljs-title&quot;&gt;putBytes&lt;/span&gt;&lt;span class=&quot;hljs-params&quot;&gt;(&lt;br/&gt;blockId: BlockId,&lt;br/&gt;bytes: ByteBuffer,&lt;br/&gt;level: StorageLevel,&lt;br/&gt;tellMaster: Boolean = &lt;span class=&quot;hljs-keyword&quot;&gt;true&lt;/span&gt;,&lt;br/&gt;effectiveStorageLevel: Option[StorageLevel] = None)&lt;/span&gt;: Seq[&lt;span class=&quot;hljs-params&quot;&gt;(BlockId, BlockStatus)&lt;/span&gt;] &lt;/span&gt;= {&lt;br/&gt;require(bytes != &lt;span class=&quot;hljs-keyword&quot;&gt;null&lt;/span&gt;, &lt;span class=&quot;hljs-string&quot;&gt;&quot;Bytes is null&quot;&lt;/span&gt;)&lt;br/&gt;doPut(blockId, ByteBufferValues(bytes), level, tellMaster, effectiveStorageLevel)&lt;br/&gt;}&lt;br/&gt;&lt;span class=&quot;hljs-function&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;private&lt;/span&gt; def &lt;span class=&quot;hljs-title&quot;&gt;doPut&lt;/span&gt;&lt;span class=&quot;hljs-params&quot;&gt;(&lt;br/&gt;blockId: BlockId,&lt;br/&gt;data: BlockValues,&lt;br/&gt;level: StorageLevel,&lt;br/&gt;tellMaster: Boolean = &lt;span class=&quot;hljs-keyword&quot;&gt;true&lt;/span&gt;,&lt;br/&gt;effectiveStorageLevel: Option[StorageLevel] = None)&lt;/span&gt;&lt;br/&gt;: Seq[&lt;span class=&quot;hljs-params&quot;&gt;(BlockId, BlockStatus)&lt;/span&gt;] &lt;/span&gt;= {&lt;p&gt;require(blockId != &lt;span class=&quot;hljs-keyword&quot;&gt;null&lt;/span&gt;, &lt;span class=&quot;hljs-string&quot;&gt;&quot;BlockId is null&quot;&lt;/span&gt;)&lt;br/&gt;require(level != &lt;span class=&quot;hljs-keyword&quot;&gt;null&lt;/span&gt; &amp;amp;&amp;amp; level.isValid, &lt;span class=&quot;hljs-string&quot;&gt;&quot;StorageLevel is null or invalid&quot;&lt;/span&gt;)&lt;br/&gt;effectiveStorageLevel.foreach { level =&amp;gt;&lt;br/&gt;require(level != &lt;span class=&quot;hljs-keyword&quot;&gt;null&lt;/span&gt; &amp;amp;&amp;amp; level.isValid, &lt;span class=&quot;hljs-string&quot;&gt;&quot;Effective StorageLevel is null or invalid&quot;&lt;/span&gt;)&lt;br/&gt;}&lt;/p&gt;&lt;p&gt;val updatedBlocks = &lt;span class=&quot;hljs-keyword&quot;&gt;new&lt;/span&gt; ArrayBuffer[(BlockId, BlockStatus)]&lt;/p&gt;&lt;p&gt;val putBlockInfo = {&lt;br/&gt;val tinfo = &lt;span class=&quot;hljs-keyword&quot;&gt;new&lt;/span&gt; BlockInfo(level, tellMaster)&lt;br/&gt;val oldBlockOpt = blockInfo.putIfAbsent(blockId, tinfo)&lt;br/&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;if&lt;/span&gt; (oldBlockOpt.isDefined) {&lt;br/&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;if&lt;/span&gt; (oldBlockOpt.get.waitForReady()) {&lt;br/&gt;logWarning(s&lt;span class=&quot;hljs-string&quot;&gt;&quot;Block $blockId already exists on this machine; not re-adding it&quot;&lt;/span&gt;)&lt;br/&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;return&lt;/span&gt; updatedBlocks&lt;br/&gt;}&lt;br/&gt;oldBlockOpt.get&lt;br/&gt;} &lt;span class=&quot;hljs-keyword&quot;&gt;else&lt;/span&gt; {&lt;br/&gt;tinfo&lt;br/&gt;}&lt;br/&gt;}&lt;/p&gt;&lt;p&gt;val startTimeMs = System.currentTimeMillis&lt;/p&gt;&lt;p&gt;var valuesAfterPut: Iterator[Any] = &lt;span class=&quot;hljs-keyword&quot;&gt;null&lt;/span&gt;&lt;/p&gt;&lt;p&gt;var bytesAfterPut: ByteBuffer = &lt;span class=&quot;hljs-keyword&quot;&gt;null&lt;/span&gt;&lt;/p&gt;&lt;p&gt;var size = &lt;span class=&quot;hljs-number&quot;&gt;0L&lt;/span&gt;&lt;/p&gt;&lt;p&gt;val putLevel = effectiveStorageLevel.getOrElse(level)&lt;/p&gt;&lt;p&gt;val replicationFuture = data match {&lt;br/&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;case&lt;/span&gt; b: ByteBufferValues &lt;span class=&quot;hljs-keyword&quot;&gt;if&lt;/span&gt; putLevel.replication &amp;gt; &lt;span class=&quot;hljs-number&quot;&gt;1&lt;/span&gt; =&amp;gt;&lt;br/&gt;val bufferView = b.buffer.duplicate()&lt;br/&gt;Future {&lt;br/&gt;replicate(blockId, bufferView, putLevel)&lt;br/&gt;}(futureExecutionContext)&lt;br/&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;case&lt;/span&gt; _ =&amp;gt; &lt;span class=&quot;hljs-keyword&quot;&gt;null&lt;/span&gt;&lt;br/&gt;}&lt;/p&gt;&lt;p&gt;putBlockInfo.&lt;span class=&quot;hljs-keyword&quot;&gt;synchronized&lt;/span&gt; {&lt;br/&gt;logTrace(&lt;span class=&quot;hljs-string&quot;&gt;&quot;Put for block %s took %s to get into synchronized block&quot;&lt;/span&gt;&lt;br/&gt;.format(blockId, Utils.getUsedTimeMs(startTimeMs)))&lt;/p&gt;&lt;p&gt;var marked = &lt;span class=&quot;hljs-keyword&quot;&gt;false&lt;/span&gt;&lt;br/&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;try&lt;/span&gt; {&lt;br/&gt;val (returnValues, blockStore: BlockStore) = {&lt;br/&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;if&lt;/span&gt; (putLevel.useMemory) {&lt;br/&gt;(&lt;span class=&quot;hljs-keyword&quot;&gt;true&lt;/span&gt;, memoryStore)&lt;br/&gt;} &lt;span class=&quot;hljs-keyword&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;hljs-keyword&quot;&gt;if&lt;/span&gt; (putLevel.useOffHeap) {&lt;br/&gt;(&lt;span class=&quot;hljs-keyword&quot;&gt;false&lt;/span&gt;, externalBlockStore)&lt;br/&gt;} &lt;span class=&quot;hljs-keyword&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;hljs-keyword&quot;&gt;if&lt;/span&gt; (putLevel.useDisk) {&lt;br/&gt;(putLevel.replication &amp;gt; &lt;span class=&quot;hljs-number&quot;&gt;1&lt;/span&gt;, diskStore)&lt;br/&gt;} &lt;span class=&quot;hljs-keyword&quot;&gt;else&lt;/span&gt; {&lt;br/&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;assert&lt;/span&gt;(putLevel == StorageLevel.NONE)&lt;br/&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;throw&lt;/span&gt; &lt;span class=&quot;hljs-keyword&quot;&gt;new&lt;/span&gt; BlockException(&lt;br/&gt;blockId, s&lt;span class=&quot;hljs-string&quot;&gt;&quot;Attempted to put block $blockId without specifying storage level!&quot;&lt;/span&gt;)&lt;br/&gt;}&lt;br/&gt;}&lt;/p&gt;&lt;p&gt;val result = data match {&lt;br/&gt;&lt;span class=&quot;hljs-function&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;hljs-title&quot;&gt;IteratorValues&lt;/span&gt;&lt;span class=&quot;hljs-params&quot;&gt;(iterator)&lt;/span&gt; &lt;/span&gt;=&amp;gt;&lt;br/&gt;blockStore.putIterator(blockId, iterator, putLevel, returnValues)&lt;br/&gt;&lt;span class=&quot;hljs-function&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;hljs-title&quot;&gt;ArrayValues&lt;/span&gt;&lt;span class=&quot;hljs-params&quot;&gt;(array)&lt;/span&gt; &lt;/span&gt;=&amp;gt;&lt;br/&gt;blockStore.putArray(blockId, array, putLevel, returnValues)&lt;br/&gt;&lt;span class=&quot;hljs-function&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;hljs-title&quot;&gt;ByteBufferValues&lt;/span&gt;&lt;span class=&quot;hljs-params&quot;&gt;(bytes)&lt;/span&gt; &lt;/span&gt;=&amp;gt;&lt;br/&gt;bytes.rewind()&lt;br/&gt;blockStore.putBytes(blockId, bytes, putLevel)&lt;br/&gt;}&lt;br/&gt;size = result.size&lt;br/&gt;result.data match {&lt;br/&gt;&lt;span class=&quot;hljs-function&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;hljs-title&quot;&gt;Left&lt;/span&gt; &lt;span class=&quot;hljs-params&quot;&gt;(newIterator)&lt;/span&gt; &lt;span class=&quot;hljs-keyword&quot;&gt;if&lt;/span&gt; putLevel.useMemory &lt;/span&gt;=&amp;gt; valuesAfterPut = &lt;span class=&quot;hljs-function&quot;&gt;newIterator&lt;br/&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;hljs-title&quot;&gt;Right&lt;/span&gt; &lt;span class=&quot;hljs-params&quot;&gt;(newBytes)&lt;/span&gt; &lt;/span&gt;=&amp;gt; bytesAfterPut = newBytes&lt;br/&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;case&lt;/span&gt; _ =&amp;gt;&lt;br/&gt;}&lt;/p&gt;&lt;p&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;if&lt;/span&gt; (putLevel.useMemory) {&lt;br/&gt;result.droppedBlocks.foreach { updatedBlocks += _ }&lt;br/&gt;}&lt;/p&gt;&lt;p&gt;val putBlockStatus = getCurrentBlockStatus(blockId, putBlockInfo)&lt;br/&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;if&lt;/span&gt; (putBlockStatus.storageLevel != StorageLevel.NONE) {&lt;br/&gt;marked = &lt;span class=&quot;hljs-keyword&quot;&gt;true&lt;/span&gt;&lt;br/&gt;putBlockInfo.markReady(size)&lt;br/&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;if&lt;/span&gt; (tellMaster) {&lt;br/&gt;reportBlockStatus(blockId, putBlockInfo, putBlockStatus)&lt;br/&gt;}&lt;br/&gt;updatedBlocks += ((blockId, putBlockStatus))&lt;br/&gt;}&lt;br/&gt;} &lt;span class=&quot;hljs-keyword&quot;&gt;finally&lt;/span&gt; {&lt;br/&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;if&lt;/span&gt; (!marked) {&lt;br/&gt;blockInfo.remove(blockId)&lt;br/&gt;putBlockInfo.markFailure()&lt;br/&gt;logWarning(s&lt;span class=&quot;hljs-string&quot;&gt;&quot;Putting block $blockId failed&quot;&lt;/span&gt;)&lt;br/&gt;}&lt;br/&gt;}&lt;br/&gt;}&lt;br/&gt;logDebug(&lt;span class=&quot;hljs-string&quot;&gt;&quot;Put block %s locally took %s&quot;&lt;/span&gt;.format(blockId, Utils.getUsedTimeMs(startTimeMs)))&lt;/p&gt;&lt;p&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;if&lt;/span&gt; (putLevel.replication &amp;gt; &lt;span class=&quot;hljs-number&quot;&gt;1&lt;/span&gt;) {&lt;br/&gt;data match {&lt;br/&gt;&lt;span class=&quot;hljs-function&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;hljs-title&quot;&gt;ByteBufferValues&lt;/span&gt;&lt;span class=&quot;hljs-params&quot;&gt;(bytes)&lt;/span&gt; &lt;/span&gt;=&amp;gt;&lt;br/&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;if&lt;/span&gt; (replicationFuture != &lt;span class=&quot;hljs-keyword&quot;&gt;null&lt;/span&gt;) {&lt;br/&gt;Await.ready(replicationFuture, Duration.Inf)&lt;br/&gt;}&lt;br/&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;case&lt;/span&gt; _ =&amp;gt;&lt;br/&gt;val remoteStartTime = System.&lt;span class=&quot;hljs-function&quot;&gt;currentTimeMillis&lt;br/&gt;&lt;span class=&quot;hljs-title&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;hljs-params&quot;&gt;(bytesAfterPut == &lt;span class=&quot;hljs-keyword&quot;&gt;null&lt;/span&gt;)&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;if&lt;/span&gt; (valuesAfterPut == &lt;span class=&quot;hljs-keyword&quot;&gt;null&lt;/span&gt;) {&lt;br/&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;throw&lt;/span&gt; &lt;span class=&quot;hljs-keyword&quot;&gt;new&lt;/span&gt; SparkException(&lt;br/&gt;&lt;span class=&quot;hljs-string&quot;&gt;&quot;Underlying put returned neither an Iterator nor bytes! This shouldn't happen.&quot;&lt;/span&gt;)&lt;br/&gt;}&lt;br/&gt;bytesAfterPut = dataSerialize(blockId, valuesAfterPut)&lt;br/&gt;}&lt;br/&gt;replicate(blockId, bytesAfterPut, putLevel)&lt;br/&gt;logDebug(&lt;span class=&quot;hljs-string&quot;&gt;&quot;Put block %s remotely took %s&quot;&lt;/span&gt;&lt;br/&gt;.format(blockId, Utils.getUsedTimeMs(remoteStartTime)))&lt;br/&gt;}&lt;br/&gt;}&lt;/p&gt;&lt;p&gt;BlockManager.dispose(bytesAfterPut)&lt;/p&gt;&lt;p&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;if&lt;/span&gt; (putLevel.replication &amp;gt; &lt;span class=&quot;hljs-number&quot;&gt;1&lt;/span&gt;) {&lt;br/&gt;logDebug(&lt;span class=&quot;hljs-string&quot;&gt;&quot;Putting block %s with replication took %s&quot;&lt;/span&gt;&lt;br/&gt;.format(blockId, Utils.getUsedTimeMs(startTimeMs)))&lt;br/&gt;} &lt;span class=&quot;hljs-keyword&quot;&gt;else&lt;/span&gt; {&lt;br/&gt;logDebug(&lt;span class=&quot;hljs-string&quot;&gt;&quot;Putting block %s without replication took %s&quot;&lt;/span&gt;&lt;br/&gt;.format(blockId, Utils.getUsedTimeMs(startTimeMs)))&lt;br/&gt;}&lt;/p&gt;&lt;p&gt;updatedBlocks&lt;br/&gt;}&lt;br/&gt;&lt;/p&gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;对于 doPut 函数，主要做了以下几个操作：&lt;br/&gt;  1）创建 BlockInfo 对象存储 block 信息。&lt;br/&gt;  2）将 BlockInfo 加锁，然后根据 Storage Level 判断存储到 Memory 还是 Disk。同时，对于已经准备好读的 BlockInfo 要进行解锁。&lt;br/&gt;  3）根据 block 的副本数量决定是否向远程发送副本。&lt;/p&gt;
&lt;h4 id=&quot;h1151&quot;&gt;&lt;span&gt;&lt;strong&gt;11.5.1 序列化与否&lt;/strong&gt;&lt;/span&gt;&lt;/h4&gt;
&lt;p&gt;写入的具体内容可以是序列化之后的 bytes 也可以是没有序列化的 value. 此处有一个对 scala 的语法中 Either, Left, Right 关键字的理解。&lt;/p&gt;
&lt;h3 id=&quot;h116&quot;&gt;&lt;span&gt;&lt;strong&gt;11.6 数据读取过程分析&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;pre&gt;
&lt;code class=&quot;java language-java hljs&quot;&gt;&lt;span class=&quot;hljs-function&quot;&gt;def &lt;span class=&quot;hljs-title&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;hljs-params&quot;&gt;(blockId: BlockId)&lt;/span&gt;: Option[Iterator[Any]] &lt;/span&gt;= {&lt;br/&gt;val local = getLocal(blockId)&lt;br/&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;if&lt;/span&gt; (local.isDefined) {&lt;br/&gt;logInfo(&lt;span class=&quot;hljs-string&quot;&gt;&quot;Found block %s locally&quot;&lt;/span&gt;.format(blockId))&lt;br/&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;return&lt;/span&gt; local&lt;br/&gt;}&lt;br/&gt;val remote = getRemote(blockId)&lt;br/&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;if&lt;/span&gt; (remote.isDefined) {&lt;br/&gt;logInfo(&lt;span class=&quot;hljs-string&quot;&gt;&quot;Found block %s remotely&quot;&lt;/span&gt;.format(blockId))&lt;br/&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;return&lt;/span&gt; remote&lt;br/&gt;}&lt;br/&gt;None&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;h4 id=&quot;h1161&quot;&gt;&lt;span&gt;&lt;strong&gt;11.6.1 本地读取&lt;/strong&gt;&lt;/span&gt;&lt;/h4&gt;
&lt;p&gt;首先在查询本机的 MemoryStore 和 DiskStore 中是否有所需要的 block 数据存在，如果没有则发起远程数据获取。&lt;/p&gt;
&lt;h4 id=&quot;h1162&quot;&gt;&lt;span&gt;&lt;strong&gt;11.6.2 远程读取&lt;/strong&gt;&lt;/span&gt;&lt;/h4&gt;
&lt;p&gt;远程获取调用路径， getRemote --&amp;gt; doGetRemote, 在 doGetRemote 中最主要的就是调用 BlockManagerWorker.syncGetBlock 来从远程获得数据。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;java language-java hljs&quot;&gt;&lt;span class=&quot;hljs-function&quot;&gt;def &lt;span class=&quot;hljs-title&quot;&gt;syncGetBlock&lt;/span&gt;&lt;span class=&quot;hljs-params&quot;&gt;(msg: GetBlock, toConnManagerId: ConnectionManagerId)&lt;/span&gt;: ByteBuffer &lt;/span&gt;= {&lt;br/&gt;val blockManager = blockManagerWorker.blockManager&lt;br/&gt;val connectionManager = blockManager.connectionManager&lt;br/&gt;val blockMessage = BlockMessage.fromGetBlock(msg)&lt;br/&gt;val blockMessageArray = &lt;span class=&quot;hljs-keyword&quot;&gt;new&lt;/span&gt; BlockMessageArray(blockMessage)&lt;br/&gt;val responseMessage = connectionManager.sendMessageReliablySync(&lt;br/&gt;toConnManagerId, blockMessageArray.toBufferMessage)&lt;br/&gt;responseMessage match {&lt;br/&gt;&lt;span class=&quot;hljs-function&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;hljs-title&quot;&gt;Some&lt;/span&gt;&lt;span class=&quot;hljs-params&quot;&gt;(message)&lt;/span&gt; &lt;/span&gt;=&amp;gt; {&lt;br/&gt;val bufferMessage = message.asInstanceOf[BufferMessage]&lt;br/&gt;logDebug(&lt;span class=&quot;hljs-string&quot;&gt;&quot;Response message received &quot;&lt;/span&gt; + bufferMessage)&lt;br/&gt;BlockMessageArray.fromBufferMessage(bufferMessage).foreach(blockMessage =&amp;gt; {&lt;br/&gt;logDebug(&lt;span class=&quot;hljs-string&quot;&gt;&quot;Found &quot;&lt;/span&gt; + blockMessage)&lt;br/&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;return&lt;/span&gt; blockMessage.getData&lt;br/&gt;})&lt;br/&gt;}&lt;br/&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;case&lt;/span&gt; None =&amp;gt; logDebug(&lt;span class=&quot;hljs-string&quot;&gt;&quot;No response message received&quot;&lt;/span&gt;)&lt;br/&gt;}&lt;br/&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;null&lt;/span&gt;&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;上述这段代码中最有意思的莫过于 sendMessageReliablySync，远程数据读取毫无疑问是一个异步 i/o 操作，这里的代码怎么写起来就像是在进行同步的操作一样呢。也就是说如何知道对方发送回来响应的呢？&lt;br/&gt;别急，继续去看看 sendMessageReliablySync 的定义：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;java language-java hljs&quot;&gt;&lt;span class=&quot;hljs-function&quot;&gt;def &lt;span class=&quot;hljs-title&quot;&gt;sendMessageReliably&lt;/span&gt;&lt;span class=&quot;hljs-params&quot;&gt;(connectionManagerId: ConnectionManagerId, message: Message)&lt;/span&gt;&lt;br/&gt;: Future[Option[Message]] &lt;/span&gt;= {&lt;br/&gt;val promise = Promise[Option[Message]]&lt;br/&gt;val status = &lt;span class=&quot;hljs-keyword&quot;&gt;new&lt;/span&gt; MessageStatus(&lt;br/&gt;message, connectionManagerId, s =&amp;gt; promise.success(s.ackMessage))&lt;br/&gt;messageStatuses.&lt;span class=&quot;hljs-keyword&quot;&gt;synchronized&lt;/span&gt; {&lt;br/&gt;messageStatuses += ((message.id, status))&lt;br/&gt;}&lt;br/&gt;sendMessage(connectionManagerId, message)&lt;br/&gt;promise.future&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;要是我说秘密在这里，你肯定会说我在扯淡，但确实在此处。注意到关键字 Promise 和 Future 没？&lt;br/&gt;如果这个 future 执行完毕，返回 s.ackMessage。我们再看看这个 ackMessage 是在什么地方被写入的呢。看一看 ConnectionManager.handleMessage 中的代码片段：&lt;/p&gt;
&lt;pre readability=&quot;6.5&quot;&gt;
&lt;code class=&quot;java language-java hljs&quot; readability=&quot;7&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;case&lt;/span&gt; bufferMessage: BufferMessage =&amp;gt;&lt;p&gt;{&lt;br/&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;if&lt;/span&gt; (authEnabled) {&lt;br/&gt;val res = handleAuthentication(connection, bufferMessage)&lt;br/&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;if&lt;/span&gt; (res == &lt;span class=&quot;hljs-keyword&quot;&gt;true&lt;/span&gt;) {&lt;br/&gt;logDebug(&lt;span class=&quot;hljs-string&quot;&gt;&quot;After handleAuth result was true, returning&quot;&lt;/span&gt;)&lt;br/&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;return&lt;/span&gt;&lt;br/&gt;}&lt;br/&gt;}&lt;br/&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;if&lt;/span&gt; (bufferMessage.hasAckId) {&lt;br/&gt;val sentMessageStatus = messageStatuses. &lt;span class=&quot;hljs-keyword&quot;&gt;synchronized&lt;/span&gt; {&lt;br/&gt;messageStatuses.get(bufferMessage.ackId) match {&lt;br/&gt;&lt;span class=&quot;hljs-function&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;hljs-title&quot;&gt;Some&lt;/span&gt;&lt;span class=&quot;hljs-params&quot;&gt;(status)&lt;/span&gt; &lt;/span&gt;=&amp;gt;{&lt;br/&gt;messageStatuses -= bufferMessage.ackId&lt;br/&gt;status&lt;br/&gt;}&lt;br/&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;case&lt;/span&gt; None =&amp;gt;{&lt;br/&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;throw&lt;/span&gt; &lt;span class=&quot;hljs-keyword&quot;&gt;new&lt;/span&gt; Exception(&lt;span class=&quot;hljs-string&quot;&gt;&quot;Could not find reference for received ack message &quot;&lt;/span&gt; +&lt;br/&gt;message.id)&lt;br/&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;null&lt;/span&gt;&lt;br/&gt;}&lt;br/&gt;}&lt;br/&gt;}&lt;br/&gt;sentMessageStatus. &lt;span class=&quot;hljs-keyword&quot;&gt;synchronized&lt;/span&gt; {&lt;br/&gt;sentMessageStatus.ackMessage = Some(message)&lt;br/&gt;sentMessageStatus.attempted = &lt;span class=&quot;hljs-keyword&quot;&gt;true&lt;/span&gt;&lt;br/&gt;sentMessageStatus.acked = &lt;span class=&quot;hljs-keyword&quot;&gt;true&lt;/span&gt;&lt;br/&gt;sentMessageStaus.markDone()&lt;br/&gt;}&lt;br/&gt;}&lt;br/&gt;}&lt;br/&gt;&lt;/p&gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;注意&lt;/code&gt;：此处的所调用的 sentMessageStatus.markDone 就会调用在 sendMessageReliablySync 中定义的 promise.Success，不妨看看 MessageStatus 的定义。&lt;/p&gt;
&lt;pre readability=&quot;5&quot;&gt;
&lt;code class=&quot;java language-java hljs&quot; readability=&quot;4&quot;&gt;&lt;span class=&quot;hljs-class&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;hljs-title&quot;&gt;MessageStatus&lt;/span&gt;(&lt;br/&gt;&lt;span class=&quot;hljs-title&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;hljs-title&quot;&gt;message&lt;/span&gt;: &lt;span class=&quot;hljs-title&quot;&gt;Message&lt;/span&gt;,&lt;br/&gt;&lt;span class=&quot;hljs-title&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;hljs-title&quot;&gt;connectionManagerId&lt;/span&gt;: &lt;span class=&quot;hljs-title&quot;&gt;ConnectionManagerId&lt;/span&gt;,&lt;br/&gt;&lt;span class=&quot;hljs-title&quot;&gt;completionHandler&lt;/span&gt;: &lt;span class=&quot;hljs-title&quot;&gt;MessageStatus&lt;/span&gt; &lt;/span&gt;=&amp;gt; Unit) {&lt;p&gt;var ackMessage: Option[Message] = None&lt;br/&gt;var attempted = &lt;span class=&quot;hljs-keyword&quot;&gt;false&lt;/span&gt;&lt;br/&gt;var acked = &lt;span class=&quot;hljs-function&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;false&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;def &lt;span class=&quot;hljs-title&quot;&gt;markDone&lt;/span&gt;&lt;span class=&quot;hljs-params&quot;&gt;()&lt;/span&gt; { completionHandler(&lt;span class=&quot;hljs-keyword&quot;&gt;this&lt;/span&gt;) }&lt;br/&gt;}&lt;br/&gt;&lt;/p&gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;h117partitionblock&quot;&gt;&lt;span&gt;&lt;strong&gt;11.7 Partition 如何转化为 Block&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;在 storage 模块里面所有的操作都是和 block 相关的，但是在 RDD 里面所有的运算都是基于 partition 的，那么 partition 是如何与 block 对应上的呢？&lt;br/&gt;RDD 计算的核心函数是 iterator() 函数：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;java language-java hljs&quot;&gt;&lt;span class=&quot;hljs-function&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;final&lt;/span&gt; def &lt;span class=&quot;hljs-title&quot;&gt;iterator&lt;/span&gt;&lt;span class=&quot;hljs-params&quot;&gt;(split: Partition, context: TaskContext)&lt;/span&gt;: Iterator[T] &lt;/span&gt;= {&lt;br/&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;if&lt;/span&gt; (storageLevel != StorageLevel.NONE) {&lt;br/&gt;SparkEnv.get.cacheManager.getOrCompute(&lt;span class=&quot;hljs-keyword&quot;&gt;this&lt;/span&gt;, split, context, storageLevel)&lt;br/&gt;} &lt;span class=&quot;hljs-keyword&quot;&gt;else&lt;/span&gt; {&lt;br/&gt;computeOrReadCheckpoint(split, context)&lt;br/&gt;}&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;如果当前 RDD 的 storage level 不是 NONE 的话，表示该 RDD 在 BlockManager 中有存储，那么调用 CacheManager 中的 getOrCompute() 函数计算 RDD，在这个函数中 partition 和 block 发生了关系：&lt;br/&gt;首先根据 RDD id 和 partition index 构造出 block id (rdd_xx_xx)，接着从 BlockManager 中取出相应的 block。&lt;br/&gt;  如果该 block 存在，表示此 RDD 在之前已经被计算过和存储在 BlockManager 中，因此取出即可，无需再重新计算。&lt;br/&gt;  如果该 block 不存在则需要调用 RDD 的 computeOrReadCheckpoint() 函数计算出新的 block，并将其存储到 BlockManager 中。&lt;br/&gt;需要注意的是 block 的计算和存储是阻塞的，若另一线程也需要用到此 block 则需等到该线程 block 的 loading 结束。&lt;/p&gt;
&lt;pre readability=&quot;8.5&quot;&gt;
&lt;code class=&quot;java language-java hljs&quot; readability=&quot;11&quot;&gt;def getOrCompute[T](rdd:RDD[T],split:Partition,context:TaskContext,storageLevel:StorageLevel):Iterator[T]=&lt;br/&gt;{&lt;br/&gt;val key = &lt;span class=&quot;hljs-string&quot;&gt;&quot;rdd_%d_%d&quot;&lt;/span&gt;.format(rdd.id, split.index)&lt;br/&gt;logDebug(&lt;span class=&quot;hljs-string&quot;&gt;&quot;Looking for partition &quot;&lt;/span&gt; + key)&lt;br/&gt;blockManager.get(key) match {&lt;br/&gt;&lt;span class=&quot;hljs-function&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;hljs-title&quot;&gt;Some&lt;/span&gt;&lt;span class=&quot;hljs-params&quot;&gt;(values)&lt;/span&gt; &lt;/span&gt;=&amp;gt;&lt;br/&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;return&lt;/span&gt; values.asInstanceOf[Iterator[T]]&lt;p&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;case&lt;/span&gt; None =&amp;gt;&lt;br/&gt;loading. &lt;span class=&quot;hljs-keyword&quot;&gt;synchronized&lt;/span&gt; {&lt;br/&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;if&lt;/span&gt; (loading.contains(key)) {&lt;br/&gt;logInfo(&lt;span class=&quot;hljs-string&quot;&gt;&quot;Another thread is loading %s, waiting for it to finish...&quot;&lt;/span&gt;.format(key))&lt;br/&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;while&lt;/span&gt; (loading.contains(key)) {&lt;br/&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;try&lt;/span&gt; {&lt;br/&gt;loading.wait()&lt;br/&gt;} &lt;span class=&quot;hljs-keyword&quot;&gt;catch&lt;/span&gt; {&lt;br/&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;case&lt;/span&gt; _:&lt;br/&gt;Throwable =&amp;gt;}&lt;br/&gt;}&lt;br/&gt;logInfo(&lt;span class=&quot;hljs-string&quot;&gt;&quot;Finished waiting for %s&quot;&lt;/span&gt;.format(key))&lt;br/&gt;blockManager.get(key) match {&lt;br/&gt;&lt;span class=&quot;hljs-function&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;hljs-title&quot;&gt;Some&lt;/span&gt;&lt;span class=&quot;hljs-params&quot;&gt;(values)&lt;/span&gt; &lt;/span&gt;=&amp;gt;&lt;br/&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;return&lt;/span&gt; values.asInstanceOf[Iterator[T]]&lt;br/&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;case&lt;/span&gt; None =&amp;gt;&lt;br/&gt;logInfo(&lt;span class=&quot;hljs-string&quot;&gt;&quot;Whoever was loading %s failed; we'll try it ourselves&quot;&lt;/span&gt;.format(key))&lt;br/&gt;loading.add(key)&lt;br/&gt;}&lt;br/&gt;} &lt;span class=&quot;hljs-keyword&quot;&gt;else&lt;/span&gt; {&lt;br/&gt;loading.add(key)&lt;br/&gt;}&lt;br/&gt;}&lt;br/&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;try&lt;/span&gt; {&lt;br/&gt;logInfo(&lt;span class=&quot;hljs-string&quot;&gt;&quot;Partition %s not found, computing it&quot;&lt;/span&gt;.format(key))&lt;br/&gt;val computedValues = rdd.computeOrReadCheckpoint(split, context)&lt;br/&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;if&lt;/span&gt; (context.runningLocally) {&lt;br/&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;return&lt;/span&gt; computedValues&lt;br/&gt;}&lt;br/&gt;val elements = &lt;span class=&quot;hljs-keyword&quot;&gt;new&lt;/span&gt; ArrayBuffer[Any]&lt;br/&gt;elements++ = computedValues&lt;br/&gt;blockManager.put(key, elements, storageLevel, &lt;span class=&quot;hljs-keyword&quot;&gt;true&lt;/span&gt;)&lt;br/&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;return&lt;/span&gt; elements.iterator.asInstanceOf[Iterator[T]]&lt;br/&gt;} &lt;span class=&quot;hljs-keyword&quot;&gt;finally&lt;/span&gt; {&lt;br/&gt;loading. &lt;span class=&quot;hljs-keyword&quot;&gt;synchronized&lt;/span&gt; {&lt;br/&gt;loading.remove(key)&lt;br/&gt;loading.notifyAll()&lt;br/&gt;}&lt;br/&gt;}&lt;br/&gt;}&lt;br/&gt;&lt;/p&gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;这样 RDD 的 transformation、action 就和 block 数据建立了联系，虽然抽象上我们的操作是在 partition 层面上进行的，但是 partitio n最终还是被映射成为 block，因此实际上我们的所有操作都是对 block 的处理和存取。&lt;/p&gt;
&lt;h3 id=&quot;h118partitionblock&quot;&gt;&lt;span&gt;&lt;strong&gt;11.8 partition 和 block 的对应关系&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;在 RDD 中，核心的函数是 iterator：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;java language-java hljs&quot;&gt;&lt;span class=&quot;hljs-function&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;final&lt;/span&gt; def &lt;span class=&quot;hljs-title&quot;&gt;iterator&lt;/span&gt;&lt;span class=&quot;hljs-params&quot;&gt;(split: Partition, context: TaskContext)&lt;/span&gt;: Iterator[T] &lt;/span&gt;= {&lt;br/&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;if&lt;/span&gt; (storageLevel != StorageLevel.NONE) {&lt;br/&gt;SparkEnv.get.cacheManager.getOrCompute(&lt;span class=&quot;hljs-keyword&quot;&gt;this&lt;/span&gt;, split, context, storageLevel)&lt;br/&gt;} &lt;span class=&quot;hljs-keyword&quot;&gt;else&lt;/span&gt; {&lt;br/&gt;computeOrReadCheckpoint(split, context)&lt;br/&gt;}&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;如果当前 RDD 的 storage level 不是 NONE 的话，表示该 RDD 在 BlockManager 中有存储，那么调用 CacheManager 中的 getOrCompute 函数计算 RDD，在这个函数中 partition 和 block 就对应起来了：&lt;br/&gt;  getOrCompute 函数会先构造 RDDBlockId，其中 RDDBlockId 就把 block 和 partition 联系起来了，RDDBlockId 产生的 name 就是 BlockId 的 name 属性，形式是：rdd_rdd.id_partition.index。&lt;/p&gt;
&lt;pre readability=&quot;19&quot;&gt;
&lt;code class=&quot;java language-java hljs&quot; readability=&quot;32&quot;&gt;def getOrCompute[T](&lt;br/&gt;rdd: RDD[T],&lt;br/&gt;partition: Partition,&lt;br/&gt;context: TaskContext,&lt;br/&gt;storageLevel: StorageLevel): Iterator[T] = {&lt;p&gt;val key = RDDBlockId(rdd.id, partition.index)&lt;br/&gt;logDebug(s&lt;span class=&quot;hljs-string&quot;&gt;&quot;Looking for partition $key&quot;&lt;/span&gt;)&lt;br/&gt;blockManager.get(key) match {&lt;br/&gt;&lt;span class=&quot;hljs-function&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;hljs-title&quot;&gt;Some&lt;/span&gt;&lt;span class=&quot;hljs-params&quot;&gt;(blockResult)&lt;/span&gt; &lt;/span&gt;=&amp;gt;&lt;br/&gt;val existingMetrics = context.taskMetrics&lt;br/&gt;.getInputMetricsForReadMethod(blockResult.readMethod)&lt;br/&gt;existingMetrics.incBytesRead(blockResult.bytes)&lt;/p&gt;&lt;p&gt;val iter = blockResult.data.asInstanceOf[Iterator[T]]&lt;br/&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;new&lt;/span&gt; InterruptibleIterator[T](context, iter) {&lt;br/&gt;&lt;span class=&quot;hljs-function&quot;&gt;override def &lt;span class=&quot;hljs-title&quot;&gt;next&lt;/span&gt;&lt;span class=&quot;hljs-params&quot;&gt;()&lt;/span&gt;: T &lt;/span&gt;= {&lt;br/&gt;existingMetrics.incRecordsRead(&lt;span class=&quot;hljs-number&quot;&gt;1&lt;/span&gt;)&lt;br/&gt;delegate.next()&lt;br/&gt;}&lt;br/&gt;}&lt;br/&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;case&lt;/span&gt; None =&amp;gt;&lt;br/&gt;val storedValues = acquireLockForPartition[T](key)&lt;br/&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;if&lt;/span&gt; (storedValues.isDefined) {&lt;br/&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;hljs-keyword&quot;&gt;new&lt;/span&gt; InterruptibleIterator[T](context, storedValues.get)&lt;br/&gt;}&lt;/p&gt;&lt;p&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;try&lt;/span&gt; {&lt;br/&gt;logInfo(s&lt;span class=&quot;hljs-string&quot;&gt;&quot;Partition $key not found, computing it&quot;&lt;/span&gt;)&lt;br/&gt;val computedValues = rdd.computeOrReadCheckpoint(partition, context)&lt;/p&gt;&lt;p&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;if&lt;/span&gt; (context.isRunningLocally) {&lt;br/&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;return&lt;/span&gt; computedValues&lt;br/&gt;}&lt;/p&gt;&lt;p&gt;val updatedBlocks = &lt;span class=&quot;hljs-keyword&quot;&gt;new&lt;/span&gt; ArrayBuffer[(BlockId, BlockStatus)]&lt;br/&gt;val cachedValues = putInBlockManager(key, computedValues, storageLevel, updatedBlocks)&lt;br/&gt;val metrics = context.taskMetrics&lt;br/&gt;val lastUpdatedBlocks = metrics.updatedBlocks.getOrElse(Seq[(BlockId, BlockStatus)]())&lt;br/&gt;metrics.updatedBlocks = Some(lastUpdatedBlocks ++ updatedBlocks.toSeq)&lt;br/&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;new&lt;/span&gt; InterruptibleIterator(context, cachedValues)&lt;/p&gt;&lt;p&gt;} &lt;span class=&quot;hljs-keyword&quot;&gt;finally&lt;/span&gt; {&lt;br/&gt;loading.&lt;span class=&quot;hljs-keyword&quot;&gt;synchronized&lt;/span&gt; {&lt;br/&gt;loading.remove(key)&lt;br/&gt;loading.notifyAll()&lt;br/&gt;}&lt;br/&gt;}&lt;br/&gt;}&lt;br/&gt;}&lt;br/&gt;&lt;/p&gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;同时 getOrCompute 函数会对 block 进行判断：&lt;br/&gt;  如果该 block 存在，表示此 RDD 在之前已经被计算过和存储在 BlockManager 中，因此取出即可，无需再重新计算。&lt;br/&gt;  如果该 block 不存在则需要调用 RDD 的 computeOrReadCheckpoint() 函数计算出新的block，并将其存储到 BlockManager 中。&lt;br/&gt;  需要注意的是 block 的计算和存储是阻塞的，若另一线程也需要用到此 block 则需等到该线程 block 的 loading 结束。&lt;/p&gt;
&lt;h2 id=&quot;h12sparkshuffle&quot;&gt;&lt;span&gt;&lt;strong&gt;第12章 Spark Shuffle 过程&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;
&lt;h3 id=&quot;h121mapreduceshuffle&quot;&gt;&lt;span&gt;&lt;strong&gt;12.1 MapReduce 的 Shuffle 过程介绍&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;  Shuffle 的本义是洗牌、混洗，把一组有一定规则的数据尽量转换成一组无规则的数据，越随机越好。MapReduce 中的 Shuffle 更像是洗牌的逆过程，把一组无规则的数据尽量转换成一组具有一定规则的数据。&lt;br/&gt;  为什么 MapReduce 计算模型需要 Shuffle 过程？我们都知道 MapReduce 计算模型一般包括两个重要的阶段：Map 是映射，负责数据的过滤分发；Reduce 是规约，负责数据的计算归并。Reduce 的数据来源于 Map，Map 的输出即是 Reduce 的输入，Reduce 需要通过 Shuffle来 获取数据。&lt;br/&gt;  从 Map 输出到 Reduce 输入的整个过程可以广义地称为 Shuffle。Shuffle 横跨 Map 端和 Reduce 端，在 Map 端包括 Spill 过程，在 Reduce 端包括 copy 和 sort 过程，如图所示：&lt;br/&gt;  &lt;/p&gt;
&lt;img title=&quot;&quot; src=&quot;https://s2.ax1x.com/2019/05/02/EtjOJS.png&quot; alt=&quot;&quot;/&gt;&lt;/blockquote&gt;
&lt;h4 id=&quot;h1211spill&quot;&gt;&lt;span&gt;&lt;strong&gt;12.1.1 Spill 过程(刷写过程)&lt;/strong&gt;&lt;/span&gt;&lt;/h4&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;  Spill 过程包括输出、排序、溢写、合并等步骤，如图所示：&lt;br/&gt;  &lt;/p&gt;
&lt;img title=&quot;&quot; src=&quot;https://s2.ax1x.com/2019/05/02/EtjxMj.png&quot; alt=&quot;&quot;/&gt;&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;Collect&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote readability=&quot;35&quot;&gt;
&lt;p&gt;  每个 Map 任务不断地以 &lt;code&gt;&amp;lt;key, value&amp;gt;&lt;/code&gt; 对的形式把数据输出到内存中构造的一个环形数据结构中。使用环形数据结构是为了更有效地使用内存空间，在内存中放置尽可能多的数据。&lt;br/&gt;  这个数据结构其实就是个字节数组，叫 kvbuffer，名如其义，但是这里面不光放置了 &lt;code&gt;&amp;lt;key, value&amp;gt;&lt;/code&gt; 数据，还放置了一些索引数据，给放置索引数据的区域起了一个 kvmeta 的别名，在 kvbuffer 的一块区域上穿了一个 IntBuffer（字节序采用的是平台自身的字节序）的马甲。&lt;code&gt;&amp;lt;key, value&amp;gt;&lt;/code&gt; 数据区域和索引数据区域在 kvbuffer 中是相邻不重叠的两个区域，用一个分界点来划分两者，分界点不是亘古不变的，而是每次 Spill 之后都会更新一次。初始的分界点是 0，&lt;code&gt;&amp;lt;key, value&amp;gt;&lt;/code&gt; 数据的存储方向是向上增长，索引数据的存储方向是向下增长，如图所示：&lt;br/&gt;  &lt;/p&gt;
&lt;img title=&quot;&quot; src=&quot;https://s2.ax1x.com/2019/05/02/EtvEz4.png&quot; alt=&quot;&quot;/&gt;&lt;p&gt;  kvbuffer 的存放指针 bufindex 是一直闷着头地向上增长，比如 bufindex 初始值为 0，一个 Int 型的 key 写完之后，bufindex 增长为 4，一个 Int 型的 value 写完之后，bufindex 增长为 8。&lt;br/&gt;  索引是对 &lt;code&gt;&amp;lt;key, value&amp;gt;&lt;/code&gt; 在 kvbuffer 中的索引，是个四元组，包括：value 的起始位置、key 的起始位置、partition 值、value 的长度，占用四个 Int 长度，kvmeta 的存放指针 kvindex 每次都是向下跳四个“格子”，然后再向上一个格子一个格子地填充四元组的数据。比如 Kvindex 初始位置是 -4，当第一个 &lt;code&gt;&amp;lt;key, value&amp;gt;&lt;/code&gt; 写完之后，(kvindex+0) 的位置存放 value 的起始位置、(kvindex+1) 的位置存放 key 的起始位置、(kvindex+2) 的位置存放 partition 的值、(kvindex+3) 的位置存放 value 的长度，然后 kvindex 跳到 -8 位置，等第二个 &lt;code&gt;&amp;lt;key, value&amp;gt;&lt;/code&gt; 和索引写完之后，kvindex 跳到-32 位置。&lt;/p&gt;
&lt;p&gt;  kvbuffer 的大小虽然可以通过参数设置，但是总共就那么大，&lt;code&gt;&amp;lt;key, value&amp;gt;&lt;/code&gt; 和索引不断地增加，加着加着，kvbuffer 总有不够用的那天，那怎么办？把数据从内存刷到磁盘上再接着往内存写数据，&lt;code&gt;把 kvbuffer 中的数据刷到磁盘上的过程就叫 Spill&lt;/code&gt;，多么明了的叫法，内存中的数据满了就自动地 spill 到具有更大空间的磁盘。&lt;/p&gt;
&lt;p&gt;  关于 Spill 触发的条件，也就是 kvbuffer 用到什么程度开始 Spill，还是要讲究一下的。如果把 kvbuffer 用得死死得，一点缝都不剩的时候再开始 Spill，那 Map 任务就需要等 Spill 完成腾出空间之后才能继续写数据；如果 kvbuffer 只是满到一定程度，比如 80% 的时候就开始 Spill，那在 Spill 的同时，Map 任务还能继续写数据，如果 Spill 够快，Map 可能都不需要为空闲空间而发愁。两利相衡取其大，一般选择后者。&lt;/p&gt;
&lt;p&gt;  Spill 这个重要的过程是由 Spill 线程承担，Spill 线程从 Map 任务接到“命令”之后就开始正式干活，干的活叫 SortAndSpill，原来不仅仅是 Spill，在 Spill 之前还有个颇具争议性的 Sort。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;Sort&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote readability=&quot;7&quot;&gt;
&lt;p&gt;  先把 kvbuffer 中的数据按照 partition 值和 key 两个关键字升序排序，移动的只是索引数据，排序结果是 kvmeta 中数据按照 partition 为单位聚集在一起，同一 partition 内的按照 key 有序。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;Spill&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote readability=&quot;24&quot;&gt;
&lt;p&gt;  Spill 线程为这次 Spill 过程创建一个磁盘文件：从所有的本地目录中轮询查找能存储这么大空间的目录，找到之后在其中创建一个类似于 “spill12.out” 的文件。Spill 线程根据排过序的 kvmeta 挨个 partition 的把 &lt;code&gt;&amp;lt;key, value&amp;gt;&lt;/code&gt; 数据吐到这个文件中，一个 partition 对应的数据吐完之后顺序地吐下个 partition，直到把所有的 partition 遍历完。一个 partition 在文件中对应的数据也叫段 (segment)。&lt;/p&gt;
&lt;p&gt;  所有的 partition 对应的数据都放在这个文件里，虽然是顺序存放的，但是怎么直接知道某个 partition 在这个文件中存放的起始位置呢？强大的索引又出场了。有一个三元组记录某个 partition 对应的数据在这个文件中的索引：起始位置、原始数据长度、压缩之后的数据长度，一个 partition 对应一个三元组。然后把这些索引信息存放在内存中，如果内存中放不下了，后续的索引信息就需要写到磁盘文件中了：从所有的本地目录中轮训查找能存储这么大空间的目录，找到之后在其中创建一个类似于 “spill12.out.index” 的文件，文件中不光存储了索引数据，还存储了 crc32 的校验数据。(spill12.out.index 不一定在磁盘上创建，如果内存（默认 1M 空间）中能放得下就放在内存中，即使在磁盘上创建了，和 spill12.out 文件也不一定在同一个目录下。)&lt;/p&gt;
&lt;p&gt;  每一次 Spill 过程就会最少生成一个 out 文件，有时还会生成 index 文件，Spill 的次数也烙印在文件名中。索引文件和数据文件的对应关系如下图所示：&lt;br/&gt;  &lt;/p&gt;
&lt;img title=&quot;&quot; src=&quot;https://s2.ax1x.com/2019/05/02/Etjzss.png&quot; alt=&quot;&quot;/&gt;&lt;p&gt;  在 Spill 线程如火如荼的进行 SortAndSpill 工作的同时，Map 任务不会因此而停歇，而是一无既往地进行着数据输出。Map 还是把数据写到 kvbuffer 中，那问题就来了：&lt;code&gt;&amp;lt;key, value&amp;gt;&lt;/code&gt; 只顾着闷头按照 bufindex 指针向上增长，kvmeta 只顾着按照 kvindex 向下增长，是保持指针起始位置不变继续跑呢，还是另谋它路？如果保持指针起始位置不变，很快 bufindex 和 kvindex 就碰头了，碰头之后再重新开始或者移动内存都比较麻烦，不可取。Map 取 kvbuffer 中剩余空间的中间位置，用这个位置设置为新的分界点，bufindex 指针移动到这个分界点，kvindex 移动到这个分界点的 -16 位置，然后两者就可以和谐地按照自己既定的轨迹放置数据了，当 Spill 完成，空间腾出之后，不需要做任何改动继续前进。分界点的转换如下图所示：&lt;br/&gt;  &lt;/p&gt;
&lt;img title=&quot;&quot; src=&quot;https://s2.ax1x.com/2019/05/02/EtjjzQ.png&quot; alt=&quot;&quot;/&gt;&lt;br/&gt;  Map 任务总要把输出的数据写到磁盘上，即使输出数据量很小在内存中全部能装得下，在最后也会把数据刷到磁盘上。

&lt;/blockquote&gt;
&lt;h4 id=&quot;h1212merge&quot;&gt;&lt;span&gt;&lt;strong&gt;12.1.2 Merge&lt;/strong&gt;&lt;/span&gt;&lt;/h4&gt;
&lt;blockquote readability=&quot;9&quot;&gt;

&lt;img title=&quot;&quot; src=&quot;https://s2.ax1x.com/2019/05/02/EtvSLn.png&quot; alt=&quot;&quot;/&gt;&lt;br/&gt;  Map 任务如果输出数据量很大，可能会进行好几次 Spill，out 文件和 Index 文件会产生很多，分布在不同的磁盘上。最后把这些文件进行合并的 merge 过程闪亮登场。&lt;br/&gt;  Merge 过程怎么知道产生的 Spill 文件都在哪了呢？从所有的本地目录上扫描得到产生的 Spill 文件，然后把路径存储在一个数组里。Merge 过程又怎么知道 Spill 的索引信息呢？没错，也是从所有的本地目录上扫描得到 Index 文件，然后把索引信息存储在一个列表里。到这里，又遇到了一个值得纳闷的地方。在之前 Spill 过程中的时候为什么不直接把这些信息存储在内存中呢，何必又多了这步扫描的操作？特别是 Spill 的索引数据，之前当内存超限之后就把数据写到磁盘，现在又要从磁盘把这些数据读出来，还是需要装到更多的内存中。之所以多此一举，是因为这时 kvbuffer 这个内存大户已经不再使用可以回收，有内存空间来装这些数据了。（对于内存空间较大的土豪来说，用内存来省却这两个 io 步骤还是值得考虑的。）

&lt;p&gt;  然后为 merge 过程创建一个叫 file.out 的文件和一个叫 file.out.Index 的文件用来存储最终的输出和索引。&lt;br/&gt;  一个 partition 一个 partition 的进行合并输出。对于某个 partition 来说，从索引列表中查询这个 partition 对应的所有索引信息，每个对应一个段插入到段列表中。也就是这个 partition 对应一个段列表，记录所有的 Spill 文件中对应的这个 partition 那段数据的文件名、起始位置、长度等等。&lt;br/&gt;  然后对这个 partition 对应的所有的 segment 进行合并，目标是合并成一个 segment。当这个 partition 对应很多个 segment 时，会分批地进行合并：先从 segment 列表中把第一批取出来，以 key 为关键字放置成最小堆，然后从最小堆中每次取出最小的 &lt;code&gt;&amp;lt;key, value&amp;gt;&lt;/code&gt; 输出到一个临时文件中，这样就把这一批段合并成一个临时的段，把它加回到 segment 列表中；再从 segment 列表中把第二批取出来合并输出到一个临时 segment，把其加入到列表中；这样往复执行，直到剩下的段是一批，输出到最终的文件中。&lt;br/&gt;  最终的索引数据仍然输出到 Index 文件中。&lt;br/&gt;  Map 端的 Shuffle 过程到此结束。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4 id=&quot;h1213copy&quot;&gt;&lt;span&gt;&lt;strong&gt;12.1.3 Copy&lt;/strong&gt;&lt;/span&gt;&lt;/h4&gt;
&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;  Reduce 任务通过 HTTP 向各个 Map 任务拖取它所需要的数据。每个节点都会启动一个常驻的 HTTP server，其中一项服务就是响应 Reduce 拖取 Map 数据。当有 MapOutput 的 HTTP 请求过来的时候，HTTP server 就读取相应的 Map 输出文件中对应这个 Reduce 部分的数据通过网络流输出给 Reduce。&lt;br/&gt;  Reduce 任务拖取某个 Map 对应的数据，如果在内存中能放得下这次数据的话就直接把数据写到内存中。Reduce 要向每个 Map 去拖取数据，在内存中每个 Map 对应一块数据，当内存中存储的 Map 数据占用空间达到一定程度的时候，开始启动内存中 merge，把内存中的数据 merge 输出到磁盘上一个文件中。&lt;br/&gt;  如果在内存中不能放得下这个 Map 的数据的话，直接把 Map 数据写到磁盘上，在本地目录创建一个文件，从 HTTP 流中读取数据然后写到磁盘，使用的缓存区大小是 64K。拖一个 Map 数据过来就会创建一个文件，当文件数量达到一定阈值时，开始启动磁盘文件 merge，把这些文件合并输出到一个文件。&lt;br/&gt;  有些 Map 的数据较小是可以放在内存中的，有些 Map 的数据较大需要放在磁盘上，这样最后 Reduce 任务拖过来的数据有些放在内存中了有些放在磁盘上，最后会对这些来一个全局合并。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4 id=&quot;h1214mergesort&quot;&gt;&lt;span&gt;&lt;strong&gt;12.1.4 Merge Sort&lt;/strong&gt;&lt;/span&gt;&lt;/h4&gt;
&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;  这里使用的 Merge 和 Map 端使用的 Merge 过程一样。Map 的输出数据已经是有序的，Merge 进行一次合并排序，所谓 Reduce 端的 sort 过程就是这个合并的过程。一般 Reduce 是一边 copy 一边 sort，即 copy 和 sort 两个阶段是重叠而不是完全分开的。&lt;br/&gt;  Reduce 端的 Shuffle 过程至此结束。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&quot;h122hashshuffle&quot;&gt;&lt;span&gt;&lt;strong&gt;12.2 HashShuffle 过程介绍&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;blockquote readability=&quot;27&quot;&gt;
&lt;p&gt;  Spark 丰富了任务类型，有些任务之间数据流转不需要通过 Shuffle，但是有些任务之间还是需要通过 Shuffle 来传递数据，比如 wide dependency 的 group by key。&lt;br/&gt;  Spark 中需要 Shuffle 输出的 Map 任务会为每个 Reduce 创建对应的 bucket，Map 产生的结果会根据设置的 partitioner 得到对应的 bucketId，然后填充到相应的 bucket 中去。每个 Map 的输出结果可能包含所有的 Reduce 所需要的数据，所以每个 Map 会创建 R 个 bucket（R 是 reduce 的个数），M 个 Map 总共会创建 M*R 个 bucket。&lt;br/&gt;  Map 创建的 bucket 其实对应磁盘上的一个文件，Map 的结果写到每个 bucket 中其实就是写到那个磁盘文件中，这个文件也被称为 blockFile，是 Disk Block Manager 管理器通过文件名的 Hash 值对应到本地目录的子目录中创建的。每个 Map 要在节点上创建 R 个磁盘文件用于结果输出，Map 的结果是直接输出到磁盘文件上的，100KB 的内存缓冲是用来创建 Fast Buffered OutputStream 输出流。这种方式一个问题就是 Shuffle 文件过多。&lt;br/&gt;  &lt;/p&gt;
&lt;img title=&quot;&quot; src=&quot;https://s2.ax1x.com/2019/05/02/Etv9Zq.png&quot; alt=&quot;&quot;/&gt;&lt;br/&gt;  1）每一个 Mapper 创建出和 Reducer 数目相同的 bucket，bucket 实际上是一个 buffer，其大小为 spark.shuffle.file.buffer.kb（默认 32KB）。&lt;br/&gt;  2）Mapper 产生的结果会根据设置的 partition 算法填充到每个 bucket 中去，然后再写入到磁盘文件。&lt;br/&gt;  3）Reducer 从远端或是本地的 block manager 中找到相应的文件读取数据。

&lt;p&gt;  针对上述 Shuffle 过程产生的文件过多问题，Spark 有另外一种改进的 Shuffle 过程：&lt;code&gt;consolidation Shuffle&lt;/code&gt;，以期显著减少 Shuffle 文件的数量。在 consolidation Shuffle 中每个 bucket 并非对应一个文件，而是对应文件中的一个 segment 部分。Job 的 map 在某个节点上第一次执行，为每个 reduce 创建 bucke 对应的输出文件，把这些文件组织成 &lt;code&gt;ShuffleFileGroup&lt;/code&gt;，当这次 map 执行完之后，这个 ShuffleFileGroup 可以释放为下次循环利用；当又有 map 在这个节点上执行时，不需要创建新的 bucket 文件，而是在上次的 ShuffleFileGroup 中取得已经创建的文件继续追加写一个 segment；当前次 map 还没执行完，ShuffleFileGroup 还没有释放，这时如果有新的 map 在这个节点上执行，无法循环利用这个 ShuffleFileGroup，而是只能创建新的 bucket 文件组成新的 ShuffleFileGroup 来写输出。&lt;br/&gt;  &lt;/p&gt;
&lt;img title=&quot;&quot; src=&quot;https://s2.ax1x.com/2019/05/02/EtvCd0.png&quot; alt=&quot;&quot;/&gt;&lt;p&gt;  比如一个 Job 有 3 个 Map 和 2 个 reduce：&lt;br/&gt;  (1) 如果此时集群有 3 个节点有空槽，每个节点空闲了一个 core，则 3 个 Map 会调度到这 3 个节点上执行，每个 Map 都会创建 2 个 Shuffle 文件，总共创建 6 个 Shuffle 文件；&lt;br/&gt;  (2) 如果此时集群有 2 个节点有空槽，每个节点空闲了一个 core，则 2 个 Map 先调度到这 2 个节点上执行，每个 Map 都会创建 2 个 Shuffle 文件，然后其中一个节点执行完 Map 之后又调度执行另一个 Map，则这个 Map 不会创建新的 Shuffle 文件，而是把结果输出追加到之前 Map 创建的 Shuffle 文件中；总共创建 4 个 Shuffle 文件；&lt;br/&gt;  (3) 如果此时集群有 2 个节点有空槽，一个节点有 2 个空 core 一个节点有 1 个空 core，则一个节点调度 2 个 Map 一个节点调度 1 个 Map，调度 2 个 Map 的节点上，一个 Map 创建了 Shuffle 文件，后面的 Map 还是会创建新的 Shuffle 文件，因为上一个 Map 还正在写，它创建的 ShuffleFileGroup 还没有释放；总共创建 6 个 Shuffle 文件。&lt;br/&gt;&lt;strong&gt;优点&lt;/strong&gt;：&lt;br/&gt;  1）快-不需要排序，也不需要维持 hash 表&lt;br/&gt;  2）不需要额外空间用作排序&lt;br/&gt;  3）不需要额外IO-数据写入磁盘只需一次，读取也只需一次&lt;br/&gt;&lt;strong&gt;缺点&lt;/strong&gt;：&lt;br/&gt;  1）当 partitions 大时，输出大量的文件（cores * R），性能开始降低&lt;br/&gt;  2）大量的文件写入，使文件系统开始变为随机写，性能比顺序写要降低 100 倍&lt;br/&gt;  3）缓存空间占用比较大&lt;br/&gt;  Reduce 去拖 Map 的输出数据，Spark 提供了两套不同的拉取数据框架：通过 socket 连接去取数据；使用n etty 框架去取数据。&lt;br/&gt;  每个节点的 Executor 会创建一个 BlockManager，其中会创建一个 BlockManagerWorker 用于响应请求。当 Reduce 的 GET_BLOCK 的请求过来时，读取本地文件将这个 blockId 的数据返回给 Reduce。如果使用的是 Netty 框架，BlockManager 会创建 ShuffleSender 用于发送 Shuffle 数据。&lt;/p&gt;
&lt;p&gt;  并不是所有的数据都是通过网络读取，对于在本节点的 Map 数据，Reduce 直接去磁盘上读取而不再通过网络框架。&lt;br/&gt;  Reduce 拖过来数据之后以什么方式存储呢？Spark Map 输出的数据没有经过排序，Spark Shuffle 过来的数据也不会进行排序，&lt;code&gt;Spark 认为 Shuffle 过程中的排序不是必须的&lt;/code&gt;，并不是所有类型的 Reduce 需要的数据都需要排序，强制地进行排序只会增加 Shuffle 的负担。Reduce 拖过来的数据会放在一个 HashMap 中，HashMap 中存储的也是 &lt;code&gt;&amp;lt;key, value&amp;gt;&lt;/code&gt; 对，key 是 Map 输出的 key，Map 输出对应这个 key 的所有 value 组成 HashMap 的 value。Spark 将 Shuffle 取过来的每一个 &lt;code&gt;&amp;lt;key, value&amp;gt;&lt;/code&gt; 对插入或者更新到 HashMap 中，来一个处理一个。HashMap 全部放在内存中。&lt;br/&gt;  Shuffle 取过来的数据全部存放在内存中，对于数据量比较小或者已经在 Map 端做过合并处理的 Shuffle 数据，占用内存空间不会太大，但是对于比如 group by key 这样的操作，Reduce 需要得到 key 对应的所有 value，并将这些 value 组一个数组放在内存中，这样当数据量较大时，就需要较多内存。&lt;br/&gt;  当内存不够时，要不就失败，要不就用老办法把内存中的数据移到磁盘上放着。Spark 意识到在处理数据规模远远大于内存空间时所带来的不足，引入了一个具有外部排序的方案。Shuffle 过来的数据先放在内存中，当内存中存储的 &lt;code&gt;&amp;lt;key, value&amp;gt;&lt;/code&gt; 对超过 1000 并且内存使用超过 70% 时，判断节点上可用内存如果还足够，则把内存缓冲区大小翻倍，如果可用内存不再够了，则把内存中的 &lt;code&gt;&amp;lt;key, value&amp;gt;&lt;/code&gt; 对排序然后写到磁盘文件中。最后把内存缓冲区中的数据排序之后和那些磁盘文件组成一个最小堆，每次从最小堆中读取最小的数据，这个和 MapReduce 中的 merge 过程类似。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&quot;h123sortshuffle&quot;&gt;&lt;span&gt;&lt;strong&gt;12.3 SortShuffle 过程介绍&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;blockquote readability=&quot;18&quot;&gt;
&lt;p&gt;  从 1.2.0 开始默认为 sort shuffle(spark.shuffle.manager = sort)，实现逻辑类似于 Hadoop MapReduce，Hash Shuffle 每一个 reducers 产生一个文件，但是 Sort Shuffle 只是产生一个按照 reducer id 排序可索引的文件，这样，只需获取有关文件中的相关数据块的位置信息，并 fseek 就可以读取指定 reducer 的数据。但对于 rueducer 数比较少的情况，Hash Shuffle 明显要比 Sort Shuffle 快，因此 Sort Shuffle 有个 “fallback” 计划，对于 reducers 数少于 “spark.shuffle.sort.bypassMergeThreshold” (200 by default)，我们使用 fallback 计划，hashing 相关数据到分开的文件，然后合并这些文件为一个，具体实现为 BypassMergeSortShuffleWriter。&lt;br/&gt;  &lt;/p&gt;
&lt;img title=&quot;&quot; src=&quot;https://s2.ax1x.com/2019/05/02/EtvFiT.png&quot; alt=&quot;&quot;/&gt;&lt;p&gt;  在 map 进行排序，在 reduce 端应用 Timsort[1] 进行合并。map 端是否容许 spill，通过 spark.shuffle.spill 来设置，默认是 true。设置为 false，如果没有足够的内存来存储 map 的输出，那么就会导致 OOM 错误，因此要慎用。&lt;br/&gt;  用于存储 map 输出的内存为：“JVM Heap Size” * spark.shuffle.memoryFraction * spark.shuffle.safetyFraction，默认为： “JVM Heap Size” * 0.2 * 0.8 = “JVM Heap Size” * 0.16。如果你在同一个执行程序中运行多个线程（设定 spark.executor.cores/ spark.task.cpus 超过 1），每个 map 任务存储的空间为 “JVM Heap Size” * spark.shuffle.memoryFraction * spark.shuffle.safetyFraction / spark.executor.cores * spark.task.cpus，默认 2 个 cores，那么为 0.08 * “JVM Heap Size”。&lt;br/&gt;  &lt;/p&gt;
&lt;img title=&quot;&quot; src=&quot;https://s2.ax1x.com/2019/05/02/EtvPoV.png&quot; alt=&quot;&quot;/&gt;&lt;p&gt;  spark 使用 AppendOnlyMap 存储 map 输出的数据，利用开源 hash 函数 MurmurHash3 和平方探测法把 key 和 value 保存在相同的 array 中。这种保存方法可以是 spark 进行 combine。如果 spill 为 true，会在 spill 前 sort。&lt;br/&gt;  与 hash shuffle 相比，sort shuffle 中每个 Mapper 只产生一个数据文件和一个索引文件，数据文件中的数据按照 Reducer 排序，但属于同一个 Reducer 的数据不排序。Mapper 产生的数据先放到 AppendOnlyMap 这个数据结构中，如果内存不够，数据则会 spill 到磁盘，最后合并成一个文件。&lt;br/&gt;  与 Hash shuffle 相比，shuffle 文件数量减少，内存使用更加可控。但排序会影响速度。&lt;br/&gt;&lt;strong&gt;优点&lt;/strong&gt;：&lt;br/&gt;  1）map 创建文件量较少。&lt;br/&gt;  2）少量的 IO 随机操作，大部分是顺序读写。&lt;br/&gt;&lt;strong&gt;缺点&lt;/strong&gt;：&lt;br/&gt;  1）要比 Hash Shuffle 要慢，需要自己通过 spark.shuffle.sort.bypassMergeThreshold 来设置合适的值。&lt;br/&gt;  2）如果使用 SSD 盘存储 shuffle 数据，那么 Hash Shuffle 可能更合适。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&quot;h124tungstenshuffle&quot;&gt;&lt;span&gt;&lt;strong&gt;12.4 TungstenShuffle 过程介绍&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;blockquote readability=&quot;41&quot;&gt;
&lt;p&gt;  Tungsten-sort 算不得一个全新的 shuffle 方案，它在&lt;code&gt;特定场景下&lt;/code&gt;基于类似现有的 Sort Based Shuffle 处理流程，对内存 /CPU/Cache 使用做了非常大的优化。带来高效的同时，也就限定了自己的使用场景。如果 Tungsten-sort 发现自己无法处理，则会自动使用 Sort Based Shuffle 进行处理。Tungsten 中文是钨丝的意思。 Tungsten Project 是 Databricks 公司提出的对 Spark 优化内存和 CPU 使用的计划，该计划初期似乎对 Spark SQL 优化的最多。不过部分 RDD API 还有 Shuffle 也因此受益。&lt;br/&gt;&lt;strong&gt;Tungsten-sort 优化点主要在三个方面&lt;/strong&gt;:&lt;br/&gt;  1）直接在 serialized binary data 上 sort 而不是 java objects，减少了 memory 的开销和 GC 的 overhead。&lt;br/&gt;  2）提供 cache-efficient sorter，使用一个 8bytes 的指针，把排序转化成了一个指针数组的排序。&lt;br/&gt;  3）spill 的 merge 过程也无需反序列化即可完成。&lt;/p&gt;
&lt;p&gt;  这些优化的实现导致引入了一个新的内存管理模型，类似 OS 的 Page，对应的实际数据结构为 MemoryBlock，支持 off-heap 以及 in-heap 两种模式。为了能够对 Record 在这些 MemoryBlock 进行定位，引入了 Pointer（指针）的概念。&lt;br/&gt;如果你还记得 Sort Based Shuffle 里存储数据的对象 PartitionedAppendOnlyMap，这是一个放在 JVM heap 里普通对象，在 Tungsten-sort 中，他被替换成了类似操作系统内存页的对象。如果你无法申请到新的 Page，这个时候就要执行 spill 操作，也就是写入到磁盘的操作。具体触发条件，和 Sort Based Shuffle 也是类似的。&lt;br/&gt;  Spark 默认开启的是 Sort Based Shuffle，想要打开 Tungsten-sort，请设置&lt;br/&gt;  spark.shuffle.manager=tungsten-sort&lt;br/&gt;  对应的实现类是：org.apache.spark.shuffle.unsafe.UnsafeShuffleManager&lt;br/&gt;  名字的来源是因为使用了大量 JDK Sun Unsafe API。&lt;/p&gt;
&lt;p&gt;当且仅当下面条件都满足时，才会使用新的 Shuffle 方式：&lt;br/&gt;  1）Shuffle dependency 不能带有 aggregation 或者输出需要排序&lt;br/&gt;  2）Shuffle 的序列化器需要是 KryoSerializer 或者 Spark SQL's 自定义的一些序列化方式.&lt;br/&gt;  3）Shuffle 文件的数量不能大于 16777216。&lt;br/&gt;  4）序列化时，单条记录不能大于 128 MB。&lt;br/&gt;可以看到，能使用的条件还是挺苛刻的。&lt;br/&gt;这些限制来源于哪里&lt;br/&gt;参看如下代码，page 的大小：&lt;br/&gt;  this.pageSizeBytes = (int) Math.min(PackedRecordPointer.MAXIMUM_PAGE_SIZE_BYTES,shuffleMemoryManager.pageSizeBytes());&lt;br/&gt;这就保证了页大小不超过 PackedRecordPointer.MAXIMUM_PAGE_SIZE_BYTES 的值，该值就被定义成了 128M。&lt;br/&gt;而产生这个限制的具体设计原因，我们还要仔细分析下 Tungsten 的内存模型，如下图所示：&lt;br/&gt;  &lt;/p&gt;
&lt;img title=&quot;&quot; src=&quot;https://s2.ax1x.com/2019/05/02/EtvAWF.png&quot; alt=&quot;&quot;/&gt;&lt;p&gt;这张图其实画的是 on-heap 的内存逻辑图，其中 #Page 部分为 13bit，Offset 为 51bit，你会发现 2^51 &amp;gt;&amp;gt; 128M 的。但是在 Shuffle 的过程中，对 51bit 做了压缩，使用了 27bit，具体如下：&lt;br/&gt;  [24 bit partition number][13 bit memory page number][27 bit offset in page]&lt;br/&gt;这里预留出的 24bi t给了 partition number，为了后面的排序用。上面的好几个限制其实都是因为这个指针引起的：&lt;br/&gt;  第一个是 partition 的限制，前面的数字 16777216 就是来源于 partition number 使用 24bit 表示的。&lt;br/&gt;  第二个是 page number。&lt;br/&gt;  第三个是偏移量，最大能表示到 2^27=128M。那一个 Task 能管理到的内存是受限于这个指针的，最多是 2^13 * 128M 也就是 1TB 左右。&lt;/p&gt;
&lt;p&gt;有了这个指针，我们就可以定位和管理到 off-heap 或者 on-heap 里的内存了。这个模型还是很漂亮的，内存管理也非常高效，记得之前的预估 PartitionedAppendOnlyMap 的内存是非常困难的，但是通过现在的内存管理机制，是非常快速并且精确的。&lt;br/&gt;对于第一个限制，那是因为后续 Shuffle Write 的 sort 部分，只对前面 24bit 的 partiton number 进行排序，key 的值没有被编码到这个指针，所以没办法进行 ordering。&lt;br/&gt;同时，因为整个过程是追求不反序列化的，所以不能做 aggregation。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Shuffle Write&lt;/strong&gt;&lt;br/&gt;核心类：&lt;br/&gt;  org.apache.spark.shuffle.unsafe.UnsafeShuffleWriter&lt;br/&gt;数据会通过 UnsafeShuffleExternalSorter.insertRecordIntoSorter 一条一条写入到 serOutputStream 序列化输出流。&lt;br/&gt;这里消耗内存的地方是&lt;br/&gt;  serBuffer = new MyByteArrayOutputStream(1024 * 1024)&lt;br/&gt;默认是 1M，类似于 Sort Based Shuffle 中的 ExternalSorter，在 Tungsten Sort 对应的为 UnsafeShuffleExternalSorter，记录序列化后就通过 sorter.insertRecord 方法放到 sorter 里去了。&lt;br/&gt;这里 sorter 负责申请 Page，释放 Page，判断是否要进行 spill 都这个类里完成。代码的架子其实和 Sort Based 是一样的。&lt;br/&gt;  &lt;/p&gt;
&lt;img title=&quot;&quot; src=&quot;https://s2.ax1x.com/2019/05/02/EtvkJU.png&quot; alt=&quot;&quot;/&gt;&lt;p&gt;(另外，值得注意的是，这张图里进行 spill 操作的同时检查内存可用而导致的 Exeception 的 bug 已经在 1.5.1 版本被修复了，忽略那条路径)&lt;br/&gt;内存是否充足的条件依然 shuffleMemoryManager 来决定，也就是所有 Task Shuffle 申请的 Page 内存总和不能大于下面的值：&lt;br/&gt;  ExecutorHeapMemeory * 0.2 * 0.8&lt;br/&gt;上面的数字可通过下面两个配置来更改：&lt;br/&gt;  spark.shuffle.memoryFraction=0.2&lt;br/&gt;  spark.shuffle.safetyFraction=0.8&lt;br/&gt;UnsafeShuffleExternalSorter 负责申请内存，并且会生成该条记录最后的逻辑地址，也就前面提到的 Pointer。&lt;br/&gt;接着 Record 会继续流转到 UnsafeShuffleInMemorySorter 中，这个对象维护了一个指针数组：&lt;br/&gt;  private long[] pointerArray;&lt;br/&gt;数组的初始大小为 4096，后续如果不够了，则按每次两倍大小进行扩充。&lt;br/&gt;假设 100 万条记录，那么该数组大约是 8M 左右，所以其实还是很小的。一旦 spill 后该 UnsafeShuffleInMemorySorter 就会被赋为 null，被回收掉。&lt;br/&gt;我们回过头来看 spill，其实逻辑上也异常简单了，UnsafeShuffleInMemorySorter 会返回一个迭代器，该迭代器粒度每个元素就是一个指针，然后到根据该指针可以拿到真实的 record，然后写入到磁盘，因为这些 record 在一开始进入 UnsafeShuffleExternalSorter 就已经被序列化了，所以在这里就纯粹变成写字节数组了。形成的结构依然和 Sort Based Shuffle 一致，一个文件里不同的 partiton 的数据用 fileSegment 来表示，对应的信息存在一个 index 文件里。&lt;br/&gt;另外写文件的时候也需要一个 buffer：&lt;br/&gt;  spark.shuffle.file.buffer=32k&lt;br/&gt;另外从内存里拿到数据放到 DiskWriter，这中间还要有个中转，是通过：&lt;br/&gt;  final byte[] writeBuffer = new byte[DISK_WRITE_BUFFER_SIZE=1024 * 1024];&lt;br/&gt;来完成的，都是内存，所以很快。&lt;br/&gt;Task 结束前，我们要做一次 mergeSpills 操作，然后形成一个 shuffle 文件。这里面其实也挺复杂的，&lt;br/&gt;如果开启了&lt;br/&gt;  spark.shuffle.unsafe.fastMergeEnabled=true&lt;br/&gt;并且没有开启&lt;br/&gt;  spark.shuffle.compress=true&lt;br/&gt;或者压缩方式为：&lt;br/&gt;  LZFCompressionCodec&lt;br/&gt;则可以非常高效的进行合并，叫做 transferTo。不过无论是什么合并，都不需要进行反序列化。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Shuffle Read&lt;/strong&gt;&lt;br/&gt;Shuffle Read 完全复用 HashShuffleReader，具体参看 Sort-Based Shuffle。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&quot;h125mapreducespark&quot;&gt;&lt;span&gt;&lt;strong&gt;12.5 MapReduce 与 Spark 过程对比&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;MapReduce 和 Spark 的 Shuffle 过程对比如下：&lt;/p&gt;
&lt;img title=&quot;&quot; src=&quot;https://s2.ax1x.com/2019/05/02/EtvmLR.png&quot; alt=&quot;&quot;/&gt;&lt;h2 id=&quot;h13spark&quot;&gt;&lt;span&gt;&lt;strong&gt;第13章 Spark 内存管理&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;
&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;  Spark 作为一个基于内存的分布式计算引擎，其内存管理模块在整个系统中扮演着非常重要的角色。理解 Spark 内存管理的基本原理，有助于更好地开发 Spark 应用程序和进行性能调优。本文中阐述的原理基于 Spark 2.1 版本。&lt;br/&gt;  在执行 Spark 的应用程序时，Spark 集群会启动 Driver 和 Executor 两种 JVM 进程，前者为主控进程，负责创建 Spark 上下文，提交 Spark 作业（Job），并将作业转化为计算任务（Task），在各个 Executor 进程间协调任务的调度，后者负责在工作节点上执行具体的计算任务，并将结果返回给 Driver，同时为需要持久化的 RDD 提供存储功能。由于 Driver 的内存管理相对来说较为简单，本文主要对 Executor 的内存管理进行分析，&lt;code&gt;下文中的 Spark 内存均特指 Executor 的内存&lt;/code&gt;。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&quot;h131&quot;&gt;&lt;span&gt;&lt;strong&gt;13.1 堆内和堆外内存规划&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;  作为一个 JVM 进程，Executor 的内存管理建立在 JVM 的内存管理之上，Spark 对 JVM 的堆内（On-heap）空间进行了更为详细的分配，以充分利用内存。同时，Spark 引入了堆外（Off-heap）内存，使之可以直接在工作节点的系统内存中开辟空间，进一步优化了内存的使用。堆内和堆外内存示意图如下：&lt;/p&gt;
&lt;img title=&quot;&quot; src=&quot;https://s2.ax1x.com/2019/05/02/EtvZQJ.png&quot; alt=&quot;&quot;/&gt;&lt;/blockquote&gt;
&lt;h4 id=&quot;h1311&quot;&gt;&lt;span&gt;&lt;strong&gt;13.1.1 堆内内存&lt;/strong&gt;&lt;/span&gt;&lt;/h4&gt;
&lt;blockquote readability=&quot;14&quot;&gt;
&lt;p&gt;  堆内内存的大小，由 Spark 应用程序启动时的 &lt;code&gt;-executor-memory&lt;/code&gt; 或 &lt;code&gt;spark.executor.memory&lt;/code&gt; 参数配置。Executor 内运行的并发任务共享 JVM 堆内内存，这些任务在缓存 RDD 数据和广播（Broadcast）数据时占用的内存被规划为&lt;code&gt;存储（Storage）内存&lt;/code&gt;，而这些任务在执行 Shuffle 时占用的内存被规划为&lt;code&gt;执行（Execution）内存&lt;/code&gt;，剩余的部分不做特殊规划，那些 Spark 内部的对象实例，或者用户定义的 Spark 应用程序中的对象实例，均占用剩余的空间。不同的管理模式下，这三部分占用的空间大小各不相同（下面第 2 小节会进行介绍）。&lt;br/&gt;  Spark 对堆内内存的管理是一种逻辑上的&lt;code&gt;规划式的管理&lt;/code&gt;，因为对象实例占用内存的申请和释放都由 JVM 完成，Spark 只能在申请后和释放前记录这些内存，我们来看其具体流程：&lt;br/&gt;&lt;strong&gt;申请内存&lt;/strong&gt;：&lt;br/&gt;  1）Spark 在代码中 new 一个对象实例&lt;br/&gt;  2）JVM 从堆内内存分配空间，创建对象并返回对象引用&lt;br/&gt;  3）Spark 保存该对象的引用，记录该对象占用的内存&lt;br/&gt;&lt;strong&gt;释放内存&lt;/strong&gt;：&lt;br/&gt;  1）Spark 记录该对象释放的内存，删除该对象的引用&lt;br/&gt;  2）等待 JVM 的垃圾回收机制释放该对象占用的堆内内存&lt;/p&gt;
&lt;p&gt;  我们知道，&lt;code&gt;JVM 的对象可以以序列化的方式存储&lt;/code&gt;，序列化的过程是将对象转换为二进制字节流，本质上可以理解为&lt;code&gt;将非连续空间的链式存储转化为连续空间或块存储&lt;/code&gt;，在访问时则需要进行序列化的逆过程--反序列化，将字节流转化为对象，序列化的方式可以节省存储空间，但增加了存储和读取时候的计算开销。&lt;br/&gt;  对于 Spark 中序列化的对象，由于是字节流的形式，其占用的内存大小可直接计算，而对于非序列化的对象，其占用的内存是通过周期性地采样近似估算而得，即并不是每次新增的数据项都会计算一次占用的内存大小，这种方法降低了时间开销但是有可能误差较大，导致某一时刻的实际内存有可能远远超出预期。此外，在被 Spark 标记为释放的对象实例，很有可能在实际上并没有被 JVM 回收，导致实际可用的内存小于 Spark 记录的可用内存。所以 Spark 并不能准确记录实际可用的堆内内存，从而也就无法完全避免内存溢出（OOM, Out of Memory）的异常。&lt;br/&gt;  虽然不能精准控制堆内内存的申请和释放，但 Spark 通过对存储内存和执行内存各自独立的规划管理，可以决定是否要在存储内存里缓存新的 RDD，以及是否为新的任务分配执行内存，在一定程度上可以提升内存的利用率，减少异常的出现。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4 id=&quot;h1312&quot;&gt;&lt;span&gt;&lt;strong&gt;13.1.2 堆外内存&lt;/strong&gt;&lt;/span&gt;&lt;/h4&gt;
&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;  为了进一步优化内存的使用以及提高 Shuffle 时排序的效率，Spark 引入了&lt;code&gt;堆外（Off-heap）内存&lt;/code&gt;，使之&lt;code&gt;可以直接在工作节点的系统内存中开辟空间&lt;/code&gt;，存储经过序列化的二进制数据。利用 JDK Unsafe API（从 Spark 2.0 开始，在管理堆外的存储内存时不再基于 Tachyon，而是与堆外的执行内存一样，基于 JDK Unsafe API 实现），Spark 可以直接操作系统堆外内存，减少了不必要的内存开销，以及频繁的 GC 扫描和回收，提升了处理性能。&lt;code&gt;堆外内存可以被精确地申请和释放&lt;/code&gt;，而且序列化的数据占用的空间可以被精确计算，所以相比堆内内存来说降低了管理的难度，也降低了误差。&lt;br/&gt;  在默认情况下堆外内存并不启用，可通过配置 &lt;code&gt;spark.memory.offHeap.enabled&lt;/code&gt; 参数启用，并由 &lt;code&gt;spark.memory.offHeap.size&lt;/code&gt; 参数设定堆外空间的大小。除了没有 other 空间，堆外内存与堆内内存的划分方式相同，所有运行中的并发任务共享存储内存和执行内存。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4 id=&quot;h1313&quot;&gt;&lt;span&gt;&lt;strong&gt;13.1.3 内存管理接口&lt;/strong&gt;&lt;/span&gt;&lt;/h4&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;  Spark 为存储内存和执行内存的管理提供了统一的接口--MemoryManager，同一个 Executor 内的任务都调用这个接口的方法来申请或释放内存:&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;内存管理接口的主要方法：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;java language-java hljs&quot;&gt;&lt;br/&gt;&lt;span class=&quot;hljs-function&quot;&gt;def &lt;span class=&quot;hljs-title&quot;&gt;acquireStorageMemory&lt;/span&gt;&lt;span class=&quot;hljs-params&quot;&gt;(blockId: BlockId, numBytes: Long, memoryMode: MemoryMode)&lt;/span&gt;: Boolean&lt;br/&gt;def &lt;span class=&quot;hljs-title&quot;&gt;acquireUnrollMemory&lt;/span&gt;&lt;span class=&quot;hljs-params&quot;&gt;(blockId: BlockId, numBytes: Long, memoryMode: MemoryMode)&lt;/span&gt;: Boolean&lt;br/&gt;def &lt;span class=&quot;hljs-title&quot;&gt;acquireExecutionMemory&lt;/span&gt;&lt;span class=&quot;hljs-params&quot;&gt;(numBytes: Long, taskAttemptId: Long, memoryMode: MemoryMode)&lt;/span&gt;: Long&lt;br/&gt;def &lt;span class=&quot;hljs-title&quot;&gt;releaseStorageMemory&lt;/span&gt;&lt;span class=&quot;hljs-params&quot;&gt;(numBytes: Long, memoryMode: MemoryMode)&lt;/span&gt;: Unit&lt;br/&gt;def &lt;span class=&quot;hljs-title&quot;&gt;releaseExecutionMemory&lt;/span&gt;&lt;span class=&quot;hljs-params&quot;&gt;(numBytes: Long, taskAttemptId: Long, memoryMode: MemoryMode)&lt;/span&gt;: Unit&lt;br/&gt;def &lt;span class=&quot;hljs-title&quot;&gt;releaseUnrollMemory&lt;/span&gt;&lt;span class=&quot;hljs-params&quot;&gt;(numBytes: Long, memoryMode: MemoryMode)&lt;/span&gt;: Unit&lt;br/&gt;&lt;/span&gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;Spark的内存管理 – 内存管理接口&lt;/p&gt;
&lt;img title=&quot;&quot; src=&quot;https://s2.ax1x.com/2019/05/02/Etvey9.png&quot; alt=&quot;&quot;/&gt;&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;  我们看到，在调用这些方法时都需要指定其内存模式（MemoryMode），这个参数决定了是在堆内还是堆外完成这次操作。MemoryManager 的具体实现上，Spark 1.6 之后默认为统一管理（Unified Memory Manager）方式，1.6 之前采用的静态管理（Static Memory Manager）方式仍被保留，可通过配置 &lt;code&gt;spark.memory.useLegacyMode&lt;/code&gt; 参数启用。两种方式的区别在于对空间分配的方式，下面的第 2 小节会分别对这两种方式进行介绍。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&quot;h132&quot;&gt;&lt;span&gt;&lt;strong&gt;13.2 内存空间分配&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;h4 id=&quot;h1321&quot;&gt;&lt;span&gt;&lt;strong&gt;13.2.1 静态内存管理&lt;/strong&gt;&lt;/span&gt;&lt;/h4&gt;
&lt;blockquote readability=&quot;7&quot;&gt;
&lt;p&gt;  在 Spark 最初采用的静态内存管理机制下，存储内存、执行内存和其他内存的大小在 Spark 应用程序运行期间均为固定的，但用户可以应用程序启动前进行配置。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;静态内存管理图示--堆内&lt;/p&gt;
&lt;img title=&quot;&quot; src=&quot;https://s2.ax1x.com/2019/05/02/EtvKdx.png&quot; alt=&quot;&quot;/&gt;&lt;br/&gt;可以看到，可用的堆内内存的大小需要按照下面的方式计算：
&lt;p&gt;可用堆内内存空间：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;hljs markdown&quot;&gt;可用的存储内存 = systemMaxMemory &lt;span class=&quot;hljs-bullet&quot;&gt;* spark.storage.memoryFraction *&lt;/span&gt; spark.storage.safetyFraction&lt;br/&gt;可用的执行内存 = systemMaxMemory &lt;span class=&quot;hljs-bullet&quot;&gt;* spark.shuffle.memoryFraction *&lt;/span&gt; spark.shuffle.safetyFraction&lt;br/&gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;blockquote readability=&quot;13&quot;&gt;
&lt;p&gt;  其中 systemMaxMemory 取决于当前 JVM 堆内内存的大小，最后可用的执行内存或者存储内存要在此基础上与各自的 memoryFraction 参数和 safetyFraction 参数相乘得出。上述计算公式中的两个 safetyFraction 参数，其意义在于在逻辑上预留出 1-safetyFraction 这么一块保险区域，降低因实际内存超出当前预设范围而导致 OOM 的风险（上文提到，对于非序列化对象的内存采样估算会产生误差）。值得注意的是，这个预留的保险区域仅仅是一种逻辑上的规划，在具体使用时 Spark 并没有区别对待，和 “其它内存” 一样交给了 JVM 去管理。&lt;/p&gt;
&lt;p&gt;  堆外的空间分配较为简单，只有存储内存和执行内存，如下图所示。可用的执行内存和存储内存占用的空间大小直接由参数 &lt;code&gt;spark.memory.storageFraction&lt;/code&gt; 决定，由于堆外内存占用的空间可以被精确计算，所以无需再设定保险区域。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;静态内存管理图示--堆外&lt;/p&gt;
&lt;img title=&quot;&quot; src=&quot;https://s2.ax1x.com/2019/05/02/Etvue1.png&quot; alt=&quot;&quot;/&gt;&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;  静态内存管理机制实现起来较为简单，但如果用户不熟悉 Spark 的存储机制，或没有根据具体的数据规模和计算任务或做相应的配置，很容易造成 “一半海水，一半火焰” 的局面，即存储内存和执行内存中的一方剩余大量的空间，而另一方却早早被占满，不得不淘汰或移出旧的内容以存储新的内容。由于新的内存管理机制的出现，这种方式目前已经很少有开发者使用，出于兼容旧版本的应用程序的目的，Spark 仍然保留了它的实现。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4 id=&quot;h1322&quot;&gt;&lt;span&gt;&lt;strong&gt;13.2.2 统一内存管理&lt;/strong&gt;&lt;/span&gt;&lt;/h4&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;  Spark 1.6 之后引入的统一内存管理机制，与静态内存管理的区别在于存储内存和执行内存共享同一块空间，可以动态占用对方的空闲区域。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;统一内存管理图示--堆内&lt;/p&gt;
&lt;img title=&quot;&quot; src=&quot;https://s2.ax1x.com/2019/05/02/EtvMo6.png&quot; alt=&quot;&quot;/&gt;&lt;p&gt;统一内存管理图示--堆外&lt;/p&gt;
&lt;img title=&quot;&quot; src=&quot;https://s2.ax1x.com/2019/05/02/EtvJQH.png&quot; alt=&quot;&quot;/&gt;&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;其中最重要的优化在于&lt;code&gt;动态占用机制&lt;/code&gt;，其规则如下：&lt;br/&gt;  1）设定基本的存储内存和执行内存区域（&lt;code&gt;spark.storage.storageFraction&lt;/code&gt; 参数），该设定确定了双方各自拥有的空间的范围。&lt;br/&gt;  2）双方的空间都不足时，则存储到硬盘；若己方空间不足而对方空余时，可借用对方的空间;（存储空间不足是指不足以放下一个完整的 Block）。&lt;br/&gt;  3）执行内存的空间被对方占用后，可让对方将占用的部分转存到硬盘，然后 “归还” 借用的空间。&lt;br/&gt;  4）存储内存的空间被对方占用后，无法让对方 “归还”，因为需要考虑 Shuffle 过程中的很多因素，实现起来较为复杂。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;动态占用机制图示&lt;/p&gt;
&lt;img title=&quot;&quot; src=&quot;https://s2.ax1x.com/2019/05/02/Etv3WD.png&quot; alt=&quot;&quot;/&gt;&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;  凭借统一内存管理机制，Spark 在一定程度上提高了堆内和堆外内存资源的利用率，降低了开发者维护 Spark 内存的难度，但并不意味着开发者可以高枕无忧。譬如，所以如果存储内存的空间太大或者说缓存的数据过多，反而会导致频繁的全量垃圾回收，降低任务执行时的性能，因为缓存的 RDD 数据通常都是长期驻留内存的。所以要想充分发挥 Spark 的性能，需要开发者进一步了解存储内存和执行内存各自的管理方式和实现原理。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&quot;h133&quot;&gt;&lt;span&gt;&lt;strong&gt;13.3 存储内存管理&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;h4 id=&quot;h1331rdd&quot;&gt;&lt;span&gt;&lt;strong&gt;13.3.1 RDD 的持久化机制&lt;/strong&gt;&lt;/span&gt;&lt;/h4&gt;
&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;  弹性分布式数据集（RDD）作为 Spark 最根本的数据抽象，是只读的分区记录（Partition）的集合，只能基于在稳定物理存储中的数据集上创建，或者在其他已有的 RDD 上执行转换（Transformation）操作产生一个新的 RDD。转换后的 RDD 与原始的 RDD 之间产生的依赖关系，构成了血统（Lineage）。凭借血统，Spark 保证了每一个 RDD 都可以被重新恢复。但 RDD 的所有转换都是惰性的，即只有当一个返回结果给 Driver 的行动（Action）发生时，Spark 才会创建任务读取 RDD，然后真正触发转换的执行。&lt;br/&gt;  Task 在启动之初读取一个分区时，会先判断这个分区是否已经被持久化，如果没有则需要检查 Checkpoint 或按照血统重新计算。所以如果一个 RDD 上要执行多次行动，可以在第一次行动中使用 persist 或 cache 方法，在内存或磁盘中持久化或缓存这个 RDD，从而在后面的行动时提升计算速度。事实上，cache 方法是使用默认的 MEMORY_ONLY 的存储级别将 RDD 持久化到内存，故缓存是一种特殊的持久化。&lt;code&gt;堆内和堆外存储内存的设计，便可以对缓存 RDD 时使用的内存做统一的规划和管理&lt;/code&gt;（存储内存的其他应用场景，如缓存 broadcast 数据，暂时不在本文的讨论范围之内）。&lt;br/&gt;  RDD 的持久化由 Spark 的 Storage 模块负责，实现了 RDD 与物理存储的解耦合。Storage 模块负责管理 Spark 在计算过程中产生的数据，将那些在内存或磁盘、在本地或远程存取数据的功能封装了起来。在具体实现时 Driver 端和 Executor 端的 Storage 模块构成了主从式的架构，即 Driver 端的 BlockManager 为 Master，Executor 端的 BlockManager 为 Slave。Storage 模块在逻辑上以 Block 为基本存储单位，RDD 的每个 Partition 经过处理后唯一对应一个 Block（BlockId 的格式为 rdd_RDD-ID_PARTITION-ID ）。Master 负责整个 Spark 应用程序的 Block 的元数据信息的管理和维护，而 Slave 需要将 Block 的更新等状态上报到 Master，同时接收 Master 的命令，例如新增或删除一个 RDD。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Storage 模块示意图&lt;/p&gt;
&lt;img title=&quot;&quot; src=&quot;https://s2.ax1x.com/2019/05/02/Etv1JO.png&quot; alt=&quot;&quot;/&gt;&lt;p&gt;在对 RDD 持久化时，Spark 规定了 MEMORY_ONLY、MEMORY_AND_DISK 等 7 种不同的 存储级别，而存储级别是以下 5 个变量的组合：&lt;br/&gt;存储级别&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;java language-java hljs&quot;&gt;&lt;span class=&quot;hljs-class&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;hljs-title&quot;&gt;StorageLevel&lt;/span&gt; &lt;span class=&quot;hljs-title&quot;&gt;private&lt;/span&gt;(&lt;br/&gt;&lt;span class=&quot;hljs-title&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;hljs-title&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;hljs-title&quot;&gt;_useDisk&lt;/span&gt;: &lt;span class=&quot;hljs-title&quot;&gt;Boolean&lt;/span&gt;,        // 磁盘&lt;br/&gt;&lt;span class=&quot;hljs-title&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;hljs-title&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;hljs-title&quot;&gt;_useMemory&lt;/span&gt;: &lt;span class=&quot;hljs-title&quot;&gt;Boolean&lt;/span&gt;,      // 这里其实是指堆内内存&lt;br/&gt;&lt;span class=&quot;hljs-title&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;hljs-title&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;hljs-title&quot;&gt;_useOffHeap&lt;/span&gt;: &lt;span class=&quot;hljs-title&quot;&gt;Boolean&lt;/span&gt;,     // 堆外内存&lt;br/&gt;&lt;span class=&quot;hljs-title&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;hljs-title&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;hljs-title&quot;&gt;_deserialized&lt;/span&gt;: &lt;span class=&quot;hljs-title&quot;&gt;Boolean&lt;/span&gt;,   // 是否为非序列化&lt;br/&gt;&lt;span class=&quot;hljs-title&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;hljs-title&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;hljs-title&quot;&gt;_replication&lt;/span&gt;: &lt;span class=&quot;hljs-title&quot;&gt;Int&lt;/span&gt; &lt;/span&gt;= &lt;span class=&quot;hljs-number&quot;&gt;1&lt;/span&gt;     &lt;br/&gt;)&lt;br/&gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;通过对数据结构的分析，可以看出存储级别从三个维度定义了 RDD 的 Partition（同时也就是 Block）的存储方式：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;java language-java hljs&quot;&gt;    &lt;span class=&quot;hljs-number&quot;&gt;1&lt;/span&gt;）存储位置：磁盘／堆内内存／堆外内存。如 MEMORY_AND_DISK 是同时在磁盘和堆内内存上存储，实现了冗余备份。OFF_HEAP 则是只在堆外内存存储，目前选择堆外内存时不能同时存储到其他位置。&lt;br/&gt;&lt;span class=&quot;hljs-number&quot;&gt;2&lt;/span&gt;）存储形式：Block 缓存到存储内存后，是否为非序列化的形式。如 MEMORY_ONLY 是非序列化方式存储，OFF_HEAP 是序列化方式存储。&lt;br/&gt;&lt;span class=&quot;hljs-number&quot;&gt;3&lt;/span&gt;）副本数量：大于 &lt;span class=&quot;hljs-number&quot;&gt;1&lt;/span&gt; 时需要远程冗余备份到其他节点。如 DISK_ONLY_2 需要远程备份 &lt;span class=&quot;hljs-number&quot;&gt;1&lt;/span&gt; 个副本。&lt;br/&gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;h4 id=&quot;h1332rdd&quot;&gt;&lt;span&gt;&lt;strong&gt;13.3.2 RDD 缓存的过程&lt;/strong&gt;&lt;/span&gt;&lt;/h4&gt;
&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;  RDD 在缓存到存储内存之前，Partition 中的数据一般以迭代器（Iterator）的数据结构来访问，这是 Scala 语言中一种遍历数据集合的方法。通过 Iterator 可以获取分区中每一条序列化或者非序列化的数据项 (Record)，这些 Record 的对象实例在逻辑上占用了 JVM 堆内内存的 other 部分的空间，同一 Partition 的不同 Record 的空间并不连续。&lt;br/&gt;  RDD 在缓存到存储内存之后，Partition 被转换成 Block，Record 在堆内或堆外存储内存中占用一块连续的空间。&lt;code&gt;将 Partition 由不连续的存储空间转换为连续存储空间的过程，Spark 称之为 “展开”（Unroll）&lt;/code&gt;。Block 有序列化和非序列化两种存储格式，具体以哪种方式取决于该 RDD 的存储级别。非序列化的 Block 以一种 DeserializedMemoryEntry 的数据结构定义，用一个数组存储所有的对象实例，序列化的 Block 则以 SerializedMemoryEntry 的数据结构定义，用字节缓冲区（ByteBuffer）来存储二进制数据。每个 Executor 的 Storage 模块用一个链式 Map 结构（LinkedHashMap）来管理堆内和堆外存储内存中所有的 Block 对象的实例，对这个 LinkedHashMap 新增和删除间接记录了内存的申请和释放。&lt;br/&gt;  因为不能保证存储空间可以一次容纳 Iterator 中的所有数据，当前的计算任务在 Unroll 时要向 MemoryManager 申请足够的 Unroll 空间来临时占位，空间不足则 Unroll 失败，空间足够时可以继续进行。对于序列化的 Partition，其所需的 Unroll 空间可以直接累加计算，一次申请。而非序列化的 Partition 则要在遍历 Record 的过程中依次申请，即每读取一条 Record，采样估算其所需的 Unroll 空间并进行申请，空间不足时可以中断，释放已占用的 Unroll 空间。如果最终 Unroll 成功，当前 Partition 所占用的 Unroll 空间被转换为正常的缓存 RDD 的存储空间，如下图所示。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Spark Unroll 示意图&lt;/p&gt;
&lt;img title=&quot;&quot; src=&quot;https://s2.ax1x.com/2019/05/02/EtvlFK.png&quot; alt=&quot;&quot;/&gt;&lt;blockquote readability=&quot;7&quot;&gt;
&lt;p&gt;  在静态内存管理时，Spark 在存储内存中专门划分了一块 Unroll 空间，其大小是固定的，统一内存管理时则没有对 Unroll 空间进行特别区分，当存储空间不足时会根据动态占用机制进行处理。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4 id=&quot;h1333&quot;&gt;&lt;span&gt;&lt;strong&gt;13.3.3 淘汰和落盘&lt;/strong&gt;&lt;/span&gt;&lt;/h4&gt;
&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;  由于同一个 Executor 的所有的计算任务共享有限的存储内存空间，当有新的 Block 需要缓存但是剩余空间不足且无法动态占用时，就要对 LinkedHashMap 中的旧 Block 进行淘汰（Eviction），而被淘汰的 Block 如果其存储级别中同时包含存储到磁盘的要求，则要对其进行落盘（Drop），否则直接删除该 Block。&lt;br/&gt;  存储内存的淘汰规则为：&lt;br/&gt;  1）被淘汰的旧 Block 要与新 Block 的 MemoryMode 相同，即同属于堆外或堆内内存。&lt;br/&gt;  2）新旧 Block 不能属于同一个 RDD，避免循环淘汰。&lt;br/&gt;  3）旧 Block 所属 RDD 不能处于被读状态，避免引发一致性问题。&lt;br/&gt;  4）遍历 LinkedHashMap 中 Block，按照最近最少使用（LRU）的顺序淘汰，直到满足新 Block 所需的空间。其中 LRU 是 LinkedHashMap 的特性。&lt;br/&gt;  落盘的流程则比较简单，如果其存储级别符合&lt;code&gt;_useDisk 为 true&lt;/code&gt; 的条件，再根据其 &lt;code&gt;_deserialized&lt;/code&gt; 判断是否是非序列化的形式，若是则对其进行序列化，最后将数据存储到磁盘，在 Storage 模块中更新其信息。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&quot;h134&quot;&gt;&lt;span&gt;&lt;strong&gt;13.4 执行内存管理&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;h4 id=&quot;h1341&quot;&gt;&lt;span&gt;&lt;strong&gt;13.4.1 多任务间内存分配&lt;/strong&gt;&lt;/span&gt;&lt;/h4&gt;
&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;  Executor 内运行的任务同样共享执行内存，Spark 用一个 HashMap 结构保存了任务到内存耗费的映射。每个任务可占用的执行内存大小的范围为 1/2N ~ 1/N，其中 N 为当前 Executor 内正在运行的任务的个数。每个任务在启动之时，要向 MemoryManager 请求申请最少为 1/2N 的执行内存，如果不能被满足要求则该任务被阻塞，直到有其他任务释放了足够的执行内存，该任务才可以被唤醒。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4 id=&quot;h1342shuffle&quot;&gt;&lt;span&gt;&lt;strong&gt;13.4.2 Shuffle 的内存占用&lt;/strong&gt;&lt;/span&gt;&lt;/h4&gt;
&lt;blockquote readability=&quot;23&quot;&gt;
&lt;p&gt;  执行内存主要用来存储任务在执行 Shuffle 时占用的内存，Shuffle 是按照一定规则对 RDD 数据重新分区的过程，我们来看 Shuffle 的 Write 和 Read 两阶段对执行内存的使用：&lt;br/&gt;&lt;strong&gt;Shuffle Write&lt;/strong&gt;&lt;br/&gt;  1）若在 map 端选择普通的排序方式，会采用 ExternalSorter 进行外排，在内存中存储数据时主要占用堆内执行空间。&lt;br/&gt;  2）若在 map 端选择 Tungsten 的排序方式，则采用 ShuffleExternalSorter 直接对以序列化形式存储的数据排序，在内存中存储数据时可以占用堆外或堆内执行空间，取决于用户是否开启了堆外内存以及堆外执行内存是否足够。&lt;br/&gt;&lt;strong&gt;Shuffle Read&lt;/strong&gt;&lt;br/&gt;  1）在对 reduce 端的数据进行聚合时，要将数据交给 Aggregator 处理，在内存中存储数据时占用堆内执行空间。&lt;br/&gt;  2）如果需要进行最终结果排序，则要将再次将数据交给 ExternalSorter 处理，占用堆内执行空间。&lt;/p&gt;
&lt;p&gt;  在 ExternalSorter 和 Aggregator 中，Spark 会使用一种叫 AppendOnlyMap 的哈希表在堆内执行内存中存储数据，但在 Shuffle 过程中所有数据并不能都保存到该哈希表中，当这个哈希表占用的内存会进行周期性地采样估算，当其大到一定程度，无法再从 MemoryManager 申请到新的执行内存时，Spark 就会将其全部内容存储到磁盘文件中，这个过程被称为溢存(Spill)，溢存到磁盘的文件最后会被归并(Merge)。&lt;br/&gt;  Shuffle Write 阶段中用到的 Tungsten 是 Databricks 公司提出的对 Spark 优化内存和 CPU 使用的计划，解决了一些 JVM 在性能上的限制和弊端。Spark 会根据 Shuffle 的情况来自动选择是否采用 Tungsten 排序。Tungsten 采用的页式内存管理机制建立在 MemoryManager 之上，即 Tungsten 对执行内存的使用进行了一步的抽象，这样在 Shuffle 过程中无需关心数据具体存储在堆内还是堆外。每个内存页用一个 MemoryBlock 来定义，并用 Object obj 和 long offset 这两个变量统一标识一个内存页在系统内存中的地址。堆内的 MemoryBlock 是以 long 型数组的形式分配的内存，其 obj 的值为是这个数组的对象引用，offset 是 long 型数组的在 JVM 中的初始偏移地址，两者配合使用可以定位这个数组在堆内的绝对地址；堆外的 MemoryBlock 是直接申请到的内存块，其 obj 为 null，offset 是这个内存块在系统内存中的 64 位绝对地址。Spark 用 MemoryBlock 巧妙地将堆内和堆外内存页统一抽象封装，并用页表(pageTable)管理每个 Task 申请到的内存页。&lt;/p&gt;
&lt;p&gt;  Tungsten 页式管理下的所有内存用 64 位的逻辑地址表示，由页号和页内偏移量组成：&lt;br/&gt;  页号：占 13 位，唯一标识一个内存页，Spark 在申请内存页之前要先申请空闲页号。&lt;br/&gt;  页内偏移量：占 51 位，是在使用内存页存储数据时，数据在页内的偏移地址。&lt;br/&gt;  有了统一的寻址方式，Spark 可以用 64 位逻辑地址的指针定位到堆内或堆外的内存，整个 Shuffle Write 排序的过程只需要对指针进行排序，并且无需反序列化，整个过程非常高效，对于内存访问效率和 CPU 使用效率带来了明显的提升。&lt;/p&gt;
&lt;p&gt;  Spark 的存储内存和执行内存有着截然不同的管理方式：对于存储内存来说，Spark 用一个 LinkedHashMap 来集中管理所有的 Block，Block 由需要缓存的 RDD 的 Partition 转化而成；而对于执行内存，Spark 用 AppendOnlyMap 来存储 Shuffle 过程中的数据，在 Tungsten 排序中甚至抽象成为页式内存管理，开辟了全新的 JVM 内存管理机制。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;h14-1&quot;&gt;&lt;span&gt;&lt;strong&gt;第14章 部署模式解析&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;
&lt;h3 id=&quot;h141&quot;&gt;&lt;span&gt;&lt;strong&gt;14.1 部署模式概述&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;  Spark 支持的主要的三种分布式部署方式分别是 standalone、spark on mesos 和 spark on YARN。standalone 模式，即独立模式，自带完整的服务，可单独部署到一个集群中，无需依赖任何其他资源管理系统。它是 Spark 实现的资源调度框架，其主要的节点有 Client 节点、Master 节点和 Worker 节点。而 yarn 是统一的资源管理机制，在上面可以运行多套计算框架，如 map reduce、storm 等根据 driver 在集群中的位置不同，分为 yarn client 和 yarn cluster。而 mesos 是一个更强大的分布式资源管理框架，它允许多种不同的框架部署在其上，包括 yarn。基本上，Spark 的运行模式取决于传递给 SparkContext 的 MASTER 环境变量的值，个别模式还需要辅助的程序接口来配合使用，目前支持的 Master 字符串及 URL 包括：&lt;br/&gt;  &lt;/p&gt;
&lt;img title=&quot;&quot; src=&quot;https://s2.ax1x.com/2019/05/02/EtvYyd.png&quot; alt=&quot;&quot;/&gt;&lt;br/&gt;  用户在提交任务给 Spark 处理时，以下两个参数共同决定了 Spark 的运行方式：&lt;br/&gt;  • --master MASTER_URL ：决定了 Spark 任务提交给哪种集群处理。&lt;br/&gt;  • --deploy-mode DEPLOY_MODE ：决定了 Driver 的运行方式，可选值为 Client 或者 Cluster。

&lt;/blockquote&gt;
&lt;h3 id=&quot;h142standalone&quot;&gt;&lt;span&gt;&lt;strong&gt;14.2 standalone 框架&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;blockquote readability=&quot;13&quot;&gt;
&lt;p&gt;  standalone 集群由三个不同级别的节点组成，分别是：&lt;br/&gt;  1）Master 主控节点，可以类比为董事长或总舵主，在整个集群之中，最多只有一个 Master 处在 Active 状态。&lt;br/&gt;  2）Worker 工作节点，这个是 manager，是分舵主， 在整个集群中，可以有多个 Worker，如果 Worker 为零，什么事也做不了。&lt;br/&gt;  3）Executor 干苦力活的，直接受 Worker 掌控，一个 Worker 可以启动多个 executor，启动的个数受限于机器中的 cpu 核数。&lt;br/&gt;  &lt;strong&gt;这三种不同类型的节点各自运行于自己的JVM进程之中。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;  Standalone 模式下，集群启动时包括 Master 与 Worker，其中 Master 负责接收客户端提交的作业，管理 Worker。根据作业提交的方式不同，分为 driver on client 和 drvier on worker。如下图所示，上图为 driver on client 模式，下图为 driver on work 模式。两种模式的主要不同点在于 driver 所在的位置。&lt;br/&gt;  在 standalone 部署模式下又分为 client 模式和 cluster 模式。&lt;br/&gt;  在client 模式下，driver 和 client 运行于同一 JVM 中，不由 worker 启动，该 JVM 进程直到 spark application 计算完成返回结果后才退出。如下图所示：&lt;br/&gt;  &lt;/p&gt;
&lt;img title=&quot;&quot; src=&quot;https://s2.ax1x.com/2019/05/02/EtvGSe.png&quot; alt=&quot;&quot;/&gt;&lt;br/&gt;  而在 cluster 模式下，driver 由 worker 启动，client 在确认 spark application 成功提交给 cluster 后直接退出，并不等待 spark application 运行结果返回。如下图所示：&lt;br/&gt;  &lt;img title=&quot;&quot; src=&quot;https://s2.ax1x.com/2019/05/02/EtvtOA.png&quot; alt=&quot;&quot;/&gt;&lt;/blockquote&gt;
&lt;hr/&gt;&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;从部署图来进行分析，每个 JVM 进程在启动时的文件依赖如何得到满足。&lt;br/&gt;  1）Master 进程最为简单，除了 spark jar 包之外，不存在第三方库依赖。&lt;br/&gt;  2）Driver 和 Executor 在运行的时候都有可能存在第三方包依赖，分开来讲。&lt;br/&gt;  3）Driver 比较简单，spark-submit 在提交的时候会指定所要依赖的 jar 文件从哪里读取。&lt;br/&gt;  4）Executor 由 Worker 来启动，Worker 需要下载 Executor 启动时所需要的 jar 文件，那么从哪里下载呢？&lt;/p&gt;
&lt;img title=&quot;&quot; src=&quot;https://s2.ax1x.com/2019/05/02/Etv0Ff.png&quot; alt=&quot;&quot;/&gt;&lt;br/&gt;  Spark Standalone 模式，即独立模式，自带完整的服务，可单独部署到一个集群中，无需依赖其他资源管理系统。在该模式下，用户可以通过手动启动 Master 和 Worker 来启动一个独立的集群。其中，Master 充当了资源管理的角色，Workder 充当了计算节点的角色。在该模式下，Spark Driver 程序在客户端(Client)运行，而 Executor 则在 Worker 节点上运行。以下是一个运行在 Standalone 模式下，包含一个 Master 节点，两个 Worker 节点的 Spark 任务调度交互部署架构图。&lt;br/&gt;&lt;img title=&quot;&quot; src=&quot;https://s2.ax1x.com/2019/05/02/Etvawt.png&quot; alt=&quot;&quot;/&gt;&lt;br/&gt;从上面的 Spark 任务调度过程可以看到：&lt;br/&gt;  1）整个集群分为 Master 节点和 Worker 节点，其 Driver 程序运行在客户端。Master 节点负责为任务分配 Worker 节点上的计算资源，两者会通过相互通信来同步资源状态，见途中红色双向箭头。&lt;br/&gt;  2）客户端启动任务后会运行 Driver 程序，Driver 程序中会完成 SparkContext 对象的初始化，并向 Master 进行注册。&lt;br/&gt;  3）每个 Workder 节点上会存在一个或者多个 ExecutorBackend 进程。每个进程包含一个 Executor 对象，该对象持有一个线程池，每个线程池可以执行一个任务(Task)。ExecutorBackend 进程还负责跟客户端节点上的 Driver 程序进行通信，上报任务状态。

&lt;/blockquote&gt;
&lt;h4 id=&quot;h1421standalone&quot;&gt;&lt;span&gt;&lt;strong&gt;14.2.1 Standalone 模式下任务运行过程&lt;/strong&gt;&lt;/span&gt;&lt;/h4&gt;
&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;  上面的过程反映了 Spark 在 standalone 模式下，整体上客户端、Master 和 Workder 节点之间的交互。对于一个任务的具体运行过程需要更细致的分解，分解运行过程见图中的小字。&lt;br/&gt;&lt;strong&gt;1）&lt;/strong&gt; 用户通过 bin/spark-submit 部署工具或者 bin/spark-class 启动应用程序的 Driver 进程，Driver 进程会初始化 SparkContext 对象，并向 Master 节点进行注册。&lt;br/&gt;  • 1、Master 节点接受 Driver 程序的注册，检查它所管理的 Worker 节点，为该 Driver 程序分配需要的计算资源 Executor。Worker 节点完成 Executor 的分配后，向 Master 报告 Executor 的状态。&lt;br/&gt;  • 2、Worker 节点上的 ExecutorBackend 进程启动后，向 Driver 进程注册。&lt;br/&gt;&lt;strong&gt;2）&lt;/strong&gt; Driver 进程内部通过 DAG Schaduler、Stage Schaduler、Task Schaduler 等过程完成任务的划分后，向 Worker 节点上的 ExecutorBackend 分配 TASK。&lt;br/&gt;  • 1、ExecutorBackend 进行 TASK 计算，并向 Driver 报告 TASK 状态，直至结束。&lt;br/&gt;  • 2、Driver 进程在所有 TASK 都处理完成后，向 Master 注销。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4 id=&quot;h1422&quot;&gt;&lt;span&gt;&lt;strong&gt;14.2.2 总结&lt;/strong&gt;&lt;/span&gt;&lt;/h4&gt;
&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;  Spark 能够以 standalone 模式运行，这是 Spark 自身提供的运行模式，用户可以通过手动启动 master 和 worker 进程来启动一个独立的集群，也可以在一台机器上运行这些守护进程进行测试。standalone 模式可以用在生产环境，它有效的降低了用户学习、测试 Spark 框架的成本。&lt;br/&gt;  standalone 模式目前只支持跨应用程序的简单 FIFO 调度。然而，为了允许多个并发用户，你可以控制每个应用使用的资源的最大数。默认情况下，它会请求使用集群的全部 CUP 内核。&lt;br/&gt;  缺省情况下，standalone 任务调度允许 worker 的失败（在这种情况下它可以将失败的任务转移给其他的 worker）。但是，调度器使用 master 来做调度，这会产生一个&lt;code&gt;单点问题&lt;/code&gt;：如果 master 崩溃，新的应用不会被创建。为了解决这个问题，可以通过 zookeeper 的选举机制在集群中启动多个 master，也可以使用本地文件实现单节点恢复。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&quot;h143yarn&quot;&gt;&lt;span&gt;&lt;strong&gt;14.3 yarn 集群模式&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;  Apache yarn 是 apache Hadoop 开源项目的一部分。设计之初是为了解决 mapreduce 计算框架资源管理的问题。到 haodoop 2.0 使用 yarn 将 mapreduce 的分布式计算和资源管理区分开来。它的引入使得 Hadoop 分布式计算系统进入了平台化时代，即&lt;code&gt;各种计算框架可以运行在一个集群中&lt;/code&gt;，由资源管理系统 YRAN 进行统一的管理和调度，从而共享整个集群资源、提高资源利用率。&lt;br/&gt;  YARN 总体上也 Master/Slave 架构--ResourceManager/NodeManager。前者(RM)负责对各个 NodeManager(NM) 上的资源进行统一管理和调度。而 Container 是资源分配和调度的基本单位，其中封装了机器资源，如内存、CPU、磁盘和网络等，每个任务会被分配一个 Container，该任务只能在该 Container 中执行，并使用该 Container 封装的资源。NodeManager 的作用则是负责接收并启动应用的 Container、而向 RM 回报本节点上的应用 Container 运行状态和资源使用情况。ApplicationMaster 与具体的 Application 相关，主要负责同 ResourceManager 协商以获取合适的 Container，并跟踪这些 Container 的状态和监控其进度。如下图所示为 yarn 集群的一般模型。&lt;br/&gt;简单架构图如下：&lt;br/&gt;  &lt;/p&gt;
&lt;img title=&quot;&quot; src=&quot;https://s2.ax1x.com/2019/05/02/ENSR0A.png&quot; alt=&quot;&quot;/&gt;&lt;br/&gt;详细架构图如下：&lt;br/&gt;  &lt;img title=&quot;&quot; src=&quot;https://s2.ax1x.com/2019/05/02/EtvBY8.png&quot; alt=&quot;&quot;/&gt;&lt;/blockquote&gt;
&lt;hr/&gt;&lt;blockquote readability=&quot;7&quot;&gt;
&lt;p&gt;  Spark 在 yarn 集群上的部署方式分为两种，yarn cluster（driver 运行在 master 上）和 yarn client（driver 运行在 client 上）。&lt;br/&gt;  &lt;strong&gt;driver on master&lt;/strong&gt; 如下图所示：&lt;br/&gt;  &lt;/p&gt;
&lt;img title=&quot;&quot; src=&quot;https://s2.ax1x.com/2019/05/02/EtvcOs.png&quot; alt=&quot;&quot;/&gt;&lt;br/&gt;  • (1) Spark Yarn Client 向 YARN 中提交应用程序，包括 Application Master 程序、启动 Application Master 的命令、需要在 Executor 中运行的程序等。&lt;br/&gt;  • (2) Resource manager 收到请求后，在其中一个 Node Manager 中为应用程序分配一个 Container，要求它在 Container 中启动应用程序的 Application Master，Application Master 初始化 sparkContext 以及创建 DAG Scheduler 和 Task Scheduler。&lt;br/&gt;  • (3) Application Master 根据 SparkContext 中的配置，向 Resource Manager 申请 Container，同时，Application Master 向 Resource Manager 注册，这样用户可通过 Resource Manager 查看应用程序的运行状态。&lt;br/&gt;  • (4) Resource Manager 在集群中寻找符合条件的 Node Manager，在 Node Manager 启动 Container，要求 Container 启动 Executor。&lt;br/&gt;  • (5) Executor 启动后向 Application Master 注册，并接收 Application Master 分配的 Task。&lt;br/&gt;  • (6) 应用程序运行完成后，Application Master 向 Resource Manager 申请注销并关闭自己。&lt;br/&gt;  &lt;strong&gt;driver on client&lt;/strong&gt; 如下图所示：&lt;br/&gt;  &lt;img title=&quot;&quot; src=&quot;https://s2.ax1x.com/2019/05/02/EtvdTP.png&quot; alt=&quot;&quot;/&gt;&lt;br/&gt;  • (1) Spark Yarn Client 向 YARN 的 Resource Manager 申请启动 Application Master。同时在 SparkContent 初始化中将创建 DAG Scheduler 和 Task Scheduler 等。&lt;br/&gt;  • (2) ResourceManager 收到请求后，在集群中选择一个 NodeManager，为该应用程序分配第一个 Container，要求它在这个 Container 中启动应用程序的 ApplicationMaster，与 YARN-Cluster 区别的是在该 ApplicationMaster 不运行 SparkContext，只与 SparkContext 进行联系进行资源的分派。&lt;br/&gt;  • (3) Client 中的 SparkContext 初始化完毕后，与 Application Master 建立通讯，向 Resource Manager 注册，根据任务信息向 Resource Manager 申请资源 (Container)。&lt;br/&gt;  • (4) 当 Application Master 申请到资源后，便与 Node Manager 通信，要求它启动 Container。&lt;br/&gt;  • (5) Container 启动后向 Driver 中的 SparkContext 注册，并申请 Task。&lt;br/&gt;  • (6) 应用程序运行完成后，Client 的 SparkContext 向 ResourceManage r申请注销并关闭自己。

&lt;/blockquote&gt;
&lt;hr/&gt;&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;  Yarn-client 和Yarn cluster 模式对比可以看出，在 Yarn-client（Driver on client）中，Application Master 仅仅从 Yarn 中申请资源给 Executor，之后 client 会跟 container 通信进行作业的调度。如果 client 离集群距离较远，建议不要采用此方式，不过此方式有利于交互式的作业。　　&lt;br/&gt;  &lt;/p&gt;
&lt;img title=&quot;&quot; src=&quot;https://s2.ax1x.com/2019/05/02/EtvylQ.png&quot; alt=&quot;&quot;/&gt;&lt;br/&gt;  Spark 能够以集群的形式运行，可用的集群管理系统有 Yarn、Mesos 等。集群管理器的核心功能是资源管理和任务调度。以 Yarn 为例，Yarn 以 Master/Slave 模式工作，在 Master 节点运行的是 Resource Manager(RM)，负责管理整个集群的资源和资源分配。在 Slave 节点运行的 Node Manager(NM)，是集群中实际拥有资源的工作节点。我们提交 Job 以后，会将组成 Job 的多个 Task 调度到对应的 Node Manager 上进行执行。另外，在 Node Manager 上将资源以 Container 的形式进行抽象，Container 包括两种资源 内存 和 CPU。&lt;br/&gt;  以下是一个运行在 Yarn 集群上，包含一个 Resource Manager 节点，三个 Node Manager 节点(其中，两个是 Worker 节点，一个 Master 节点)的 Spark 任务调度交换部署架构图。　&lt;br/&gt;&lt;img title=&quot;&quot; src=&quot;https://s2.ax1x.com/2019/05/02/EtvDfS.png&quot; alt=&quot;&quot;/&gt;&lt;br/&gt;从上面的Spark任务调度过程图可以看到:&lt;br/&gt;  1）整个集群分为 Master 节点和 Worker 节点，它们都存在于 Node Manager 节点上，在客户端提交任务时由 Resource Manager 统一分配，运行 Driver 程序的节点被称为 Master 节点，执行具体任务的节点被称为 Worder 节点。Node Manager 节点上资源的变化都需要及时更新给 Resource Manager，见图中红色双向箭头。&lt;br/&gt;  2）Master 节点上常驻 Master 守护进程 -- Driver 程序，Driver 程序中会创建 SparkContext对 象，并负责跟各个 Worker 节点上的 ExecutorBackend 进程进行通信，管理 Worker 节点上的任务，同步任务进度。实际上，在 Yarn 中 Node Manager 之间的关系是平等的，因此 Driver 程序会被调度到任何一个 Node Manager 节点。&lt;br/&gt;  3）每个 Worker 节点上会存在一个或者多个 ExecutorBackend 进程。每个进程包含一个 Executor 对象，该对象持有一个线程池，每个线程池可以执行一个任务(Task)。ExecutorBackend 进程还负责跟 Master 节点上的 Driver 程序进行通信，上报任务状态。　　

&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;集群下任务运行过程&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;  上面的过程反映出了 Spark 在集群模式下，整体上 Resource Manager 和 Node Manager 节点间的交互，Master 和 Worker 之间的交互。对于一个任务的具体运行过程需要更细致的分解，分解运行过程见图中的小字。&lt;br/&gt;  • 1) 用户通过 bin/spark-submit 部署工具或者 bin/spark-class 向 Yarn 集群提交应用程序。&lt;br/&gt;  • 2) Yarn 集群的 Resource Manager 为提交的应用程序选择一个 Node Manager 节点并分配第一个 Container，并在该节点的 Container 上启动 SparkContext 对象。&lt;br/&gt;  • 3) SparkContext 对象向 Yarn 集群的 Resource Manager 申请资源以运行 Executor。&lt;br/&gt;  • 4) Yarn 集群的 Resource Manager 分配 Container 给 SparkContext 对象，SparkContext 和相关的 Node Manager 通讯，在获得的 Container 上启动 ExecutorBackend 守护进程，ExecutorBackend 启动后开始向 SparkContext 注册并申请 Task。&lt;br/&gt;  • 5) SparkContext 分配 Task 给 ExecutorBackend 执行。&lt;br/&gt;  • 6) ExecutorBackend 开始执行 Task，并及时向 SparkContext 汇报运行状况。Task 运行完毕，SparkContext 归还资源给 Node Manager，并注销退。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&quot;h144mesos&quot;&gt;&lt;span&gt;&lt;strong&gt;14.4 mesos 集群模式&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;  Mesos 是 apache 下的开源分布式资源管理框架。起源于&lt;code&gt;加州大学伯克利分校&lt;/code&gt;，后被 Twitter 推广使用。Mesos 上可以部署多种分布式框架，Mesos 的架构图如下图所示，其中 Framework 是指外部的计算框架，如 Hadoop、Mesos 等，这些计算框架可通过注册的方式接入 Mesos，以便 Mesos 进行统一管理和资源分配。&lt;br/&gt;  &lt;/p&gt;
&lt;img title=&quot;&quot; src=&quot;https://s2.ax1x.com/2019/05/02/EtvWT0.png&quot; alt=&quot;&quot;/&gt;&lt;br/&gt;  在 Mesos 上运行的 Framework 由两部分组成：一个是 scheduler ，通过注册到 Master 来获取集群资源。另一个是在 Slave 节点上运行的 executor 进程，它可以执行 Framework 的 task 。 Master 决定为每个 Framework 提供多少资源，Framework 的 scheduler 来选择其中提供的资源。当 Framework 同意了提供的资源，它通过 Master 将 task 发送到提供资源的 Slaves 上运行。Mesos c的资源分配图如下图所示：&lt;br/&gt;  &lt;img title=&quot;&quot; src=&quot;https://s2.ax1x.com/2019/05/02/EtvsSg.png&quot; alt=&quot;&quot;/&gt;&lt;br/&gt;  (1) Slave1 向 Master 报告，有 4 个 CPU 和 4 GB 内存可用。&lt;br/&gt;  (2) Master 发送一个 Resource Offer 给 Framework1 来描述 Slave1 有多少可用资源。&lt;br/&gt;  (3) FrameWork1 中的 FW Scheduler 会答复 Master，我有两个 Task 需要运行在 Slave1，一个 Task 需要 &lt;code&gt;&amp;lt;2个CPU，1 GB内存=&quot;&quot;&amp;gt;&lt;/code&gt;，另外一个 Task 需要 &lt;code&gt;&amp;lt;1个CPU，2 GB内存=&quot;&quot;&amp;gt;&lt;/code&gt;。&lt;br/&gt;  (4) 最后，Master 发送这些 Tasks 给 Slave1。然后，Slave1 还有 1 个 CPU 和 1GB 内存没有使用，所以分配模块可以把这些资源提供给 Framework2。

&lt;/blockquote&gt;
&lt;hr/&gt;&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;  Spark 可作为其中一个分布式框架部署在 mesos 上，部署图与 mesos 的一般框架部署图类似，如下图所示，这里不再重述。&lt;/p&gt;
&lt;img title=&quot;&quot; src=&quot;https://s2.ax1x.com/2019/05/02/EtvhkV.png&quot; alt=&quot;&quot;/&gt;&lt;/blockquote&gt;
&lt;h3 id=&quot;h145spark&quot;&gt;&lt;span&gt;&lt;strong&gt;14.5 spark 三种部署模式的区别&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;  在这三种部署模式中，standalone 作为 spark 自带的分布式部署模式，是最简单也是最基本的 spark 应用程序部署模式，这里就不再赘述。这里就讲一下 yarn 和 mesos 的区别：&lt;br/&gt;  (1) 就两种框架本身而言，mesos上可部署 yarn 框架。而 yarn 是更通用的一种部署框架，而且技术较成熟。&lt;br/&gt;  (2) mesos 双层调度机制，能支持多种调度模式，而 yarn 通过 Resource　Mananger 管理集群资源，只能使用一种调度模式。Mesos 的双层调度机制为：mesos 可接入如 yarn 一般的分布式部署框架，但 Mesos 要求可接入的框架必须有一个调度器模块，该调度器负责框架内部的任务调度。当一个 Framework 想要接入 mesos 时，需要修改自己的调度器，以便向 mesos 注册，并获取 mesos 分配给自己的资源，这样再由自己的调度器将这些资源分配给框架中的任务，也就是说，整个 mesos 系统采用了双层调度框架：第一层，由 mesos 将资源分配给框架；第二层，框架自己的调度器将资源分配给自己内部的任务。&lt;br/&gt;  (3) mesos 可实现粗、细粒度资源调度，可动态分配资源，而 yarn 只能实现静态资源分配。其中粗粒度和细粒度调度定义如下：&lt;br/&gt;  粗粒度模式（Coarse-grained Mode）：程序运行之前就要把所需要的各种资源（每个 executor 占用多少资源，内部可运行多少个 executor）申请好，运行过程中不能改变。&lt;br/&gt;  细粒度模式（Fine-grained Mode）：为了防止资源浪费，对资源进行按需分配。与粗粒度模式一样，应用程序启动时，先会启动 executor，但每个 executor 占用资源仅仅是自己运行所需的资源，不需要考虑将来要运行的任务，之后，mesos 会为每个 executor 动态分配资源，每分配一些，便可以运行一个新任务，单个 Task 运行完之后可以马上释放对应的资源。每个 Task 会汇报状态给 Mesos Slave 和 Mesos Master，便于更加细粒度管理和容错，这种调度模式类似于 MapReduce 调度模式，每个 Task 完全独立，优点是便于资源控制和隔离，但缺点也很明显，短作业运行延迟大。&lt;br/&gt;  从 yarn 和 mesos 的区别可看出，它们各自有优缺点。因此实际使用中，选择哪种框架，要根据本公司的实际需要而定，可考虑现有的大数据生态环境。如我司采用 yarn 部署 spark，原因是，我司早已有较成熟的 hadoop 的框架，考虑到使用的方便性，采用了 yarn 模式的部署。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&quot;h146&quot;&gt;&lt;span&gt;&lt;strong&gt;14.6 异常场景分析&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;上面说明的是正常情况下，各节点的消息分发细节。那么如果在运行中，集群中的某些节点出现了问题，整个集群是否还能够正常处理 Application 中的任务呢？&lt;/p&gt;
&lt;h4 id=&quot;h14611worker&quot;&gt;&lt;span&gt;&lt;strong&gt;14.6.1 异常分析1：Worker 异常退出&lt;/strong&gt;&lt;/span&gt;&lt;/h4&gt;
&lt;img title=&quot;&quot; src=&quot;https://s2.ax1x.com/2019/05/02/Etv6yj.png&quot; alt=&quot;&quot;/&gt;&lt;br/&gt;在 Spark 运行过程中，经常碰到的问题就是 Worker 异常退出，当 Worker 退出时，整个集群会有哪些故事发生呢？请看下面的具体描述：&lt;br/&gt;  1）Worker 异常退出，比如说有意识的通过 kill 指令将 Worker 杀死。&lt;br/&gt;  2）Worker 在退出之前，会将自己所管控的所有小弟 Executor 全干掉。&lt;br/&gt;  3）Worker 需要定期向 Master 改善心跳消息的，现在 Worker 进程都已经玩完了，哪有心跳消息，所以 Master 会在超时处理中意识到有一个 “分舵” 离开了。&lt;br/&gt;  4）Master 非常伤心，伤心的 Master 将情况汇报给了相应的 Driver。&lt;br/&gt;Driver 通过两方面确认分配给自己的 Executor 不幸离开了，一是 Master 发送过来的通知，二是 Driver 没有在规定时间内收到 Executor 的 StatusUpdate，于是 Driver 会将注册的 Executor 移除。
&lt;p&gt;&lt;strong&gt;后果分析&lt;/strong&gt;&lt;br/&gt;Worker 异常退出会带来哪些影响：&lt;br/&gt;  1）Executor 退出导致提交的 Task 无法正常结束，会被再一次提交运行。&lt;br/&gt;  2）如果所有的 Worker 都异常退出，则整个集群不可用。&lt;br/&gt;  3）需要有相应的程序来重启 Worker 进程，比如使用 supervisord 或 runit。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;测试步骤&lt;/strong&gt;&lt;br/&gt;  1）启动 Master。&lt;br/&gt;  2）启动 Worker。&lt;br/&gt;  3）启动 spark-shell。&lt;br/&gt;  4）手工 kill 掉 Worker 进程。&lt;br/&gt;  5）用 jps 或 ps -ef | grep -i java 来查看启动着的 java 进程。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;异常退出的代码处理&lt;/strong&gt;&lt;br/&gt;定义 ExecutorRunner.scala 的 start 函数&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;java language-java hljs&quot;&gt;&lt;span class=&quot;hljs-function&quot;&gt;def &lt;span class=&quot;hljs-title&quot;&gt;start&lt;/span&gt;&lt;span class=&quot;hljs-params&quot;&gt;()&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;workerThread = &lt;span class=&quot;hljs-keyword&quot;&gt;new&lt;/span&gt; Thread(&lt;span class=&quot;hljs-string&quot;&gt;&quot;ExecutorRunner for &quot;&lt;/span&gt; + fullId) {&lt;br/&gt;&lt;span class=&quot;hljs-function&quot;&gt;override def &lt;span class=&quot;hljs-title&quot;&gt;run&lt;/span&gt;&lt;span class=&quot;hljs-params&quot;&gt;()&lt;/span&gt; &lt;/span&gt;{ fetchAndRunExecutor() }&lt;br/&gt;}&lt;br/&gt;workerThread.start()&lt;br/&gt;shutdownHook = &lt;span class=&quot;hljs-keyword&quot;&gt;new&lt;/span&gt; Thread() {&lt;br/&gt;&lt;span class=&quot;hljs-function&quot;&gt;override def &lt;span class=&quot;hljs-title&quot;&gt;run&lt;/span&gt;&lt;span class=&quot;hljs-params&quot;&gt;()&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;killProcess(Some(&lt;span class=&quot;hljs-string&quot;&gt;&quot;Worker shutting down&quot;&lt;/span&gt;))&lt;br/&gt;}&lt;br/&gt;}&lt;br/&gt;Runtime.getRuntime.addShutdownHook(shutdownHook)&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;killProcess 的过程就是停止相应 CoarseGrainedExecutorBackend 的过程。&lt;br/&gt;Worker 停止的时候，一定要先将自己启动的 Executor 停止掉。这是不是很像水浒中宋江的手段，李逵就是这样不明不白的把命给丢了。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;小结&lt;/strong&gt;&lt;br/&gt;  需要特别指出的是，当 Worker 在启动 Executor 的时候，是通过 ExecutorRunner 来完成的，ExecutorRunner 是一个独立的线程，和 Executor 是一对一的关系，这很重要。Executor 作为一个独立的进程在运行，但会受到 ExecutorRunner 的严密监控。&lt;/p&gt;
&lt;h4 id=&quot;h14622executor&quot;&gt;&lt;span&gt;&lt;strong&gt;14.6.2 异常分析2：Executor 异常退出&lt;/strong&gt;&lt;/span&gt;&lt;/h4&gt;
&lt;img title=&quot;&quot; src=&quot;https://s2.ax1x.com/2019/05/02/EtvRwq.png&quot; alt=&quot;&quot;/&gt;&lt;p&gt;&lt;strong&gt;后果分析&lt;/strong&gt;&lt;br/&gt;Executor 作为 Standalone 集群部署方式下的最底层员工，一旦异常退出，其后果会是什么呢？&lt;br/&gt;  1）Executor 异常退出，ExecutorRunner 注意到异常，将情况通过 ExecutorStateChanged 汇报给 Master。&lt;br/&gt;  2）Master 收到通知之后，非常不高兴，尽然有小弟要跑路，那还了得，要求 Executor 所属的 Worker 再次启动。&lt;br/&gt;  3）Worker 收到 LaunchExecutor 指令，再次启动 Executor。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;测试步骤&lt;/strong&gt;&lt;br/&gt;  1）启动 Master&lt;br/&gt;  2）启动 Worker&lt;br/&gt;  3）启动 spark-shell&lt;br/&gt;  4）手工 kill 掉 CoarseGrainedExecutorBackend&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;fetchAndRunExecutor&lt;/strong&gt;&lt;br/&gt;fetchAndRunExecutor 负责启动具体的 Executor，并监控其运行状态，具体代码逻辑如下所示&lt;/p&gt;
&lt;pre readability=&quot;7.5&quot;&gt;
&lt;code class=&quot;java language-java hljs&quot; readability=&quot;9&quot;&gt;&lt;span class=&quot;hljs-function&quot;&gt;def &lt;span class=&quot;hljs-title&quot;&gt;fetchAndRunExecutor&lt;/span&gt;&lt;span class=&quot;hljs-params&quot;&gt;()&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;try&lt;/span&gt; {&lt;br/&gt;val executorDir = &lt;span class=&quot;hljs-keyword&quot;&gt;new&lt;/span&gt; File(workDir, appId + &lt;span class=&quot;hljs-string&quot;&gt;&quot;/&quot;&lt;/span&gt; + execId)&lt;br/&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;if&lt;/span&gt; (!executorDir.mkdirs()) {&lt;br/&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;throw&lt;/span&gt; &lt;span class=&quot;hljs-keyword&quot;&gt;new&lt;/span&gt; IOException(&lt;span class=&quot;hljs-string&quot;&gt;&quot;Failed to create directory &quot;&lt;/span&gt; + executorDir)&lt;br/&gt;}&lt;p&gt;&lt;br/&gt;val command = &lt;span class=&quot;hljs-function&quot;&gt;getCommandSeq&lt;br/&gt;&lt;span class=&quot;hljs-title&quot;&gt;logInfo&lt;/span&gt;&lt;span class=&quot;hljs-params&quot;&gt;(&lt;span class=&quot;hljs-string&quot;&gt;&quot;Launch command: &quot;&lt;/span&gt; + command.mkString(&lt;span class=&quot;hljs-string&quot;&gt;&quot;\&quot;&quot;&lt;/span&gt;, &lt;span class=&quot;hljs-string&quot;&gt;&quot;\&quot; \&quot;&quot;&lt;/span&gt;, &lt;span class=&quot;hljs-string&quot;&gt;&quot;\&quot;&quot;&lt;/span&gt;)&lt;/span&gt;)&lt;br/&gt;val builder &lt;/span&gt;= &lt;span class=&quot;hljs-keyword&quot;&gt;new&lt;/span&gt; ProcessBuilder(command: _*).directory(executorDir)&lt;br/&gt;val env = builder.environment()&lt;br/&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;for&lt;/span&gt; ((key, value)  {&lt;br/&gt;logInfo(&lt;span class=&quot;hljs-string&quot;&gt;&quot;Runner thread for executor &quot;&lt;/span&gt; + fullId + &lt;span class=&quot;hljs-string&quot;&gt;&quot; interrupted&quot;&lt;/span&gt;)&lt;br/&gt;state = ExecutorState.&lt;span class=&quot;hljs-function&quot;&gt;KILLED&lt;br/&gt;&lt;span class=&quot;hljs-title&quot;&gt;killProcess&lt;/span&gt;&lt;span class=&quot;hljs-params&quot;&gt;(None)&lt;/span&gt;&lt;br/&gt;}&lt;br/&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;case&lt;/span&gt; e: Exception &lt;/span&gt;=&amp;gt; {&lt;br/&gt;logError(&lt;span class=&quot;hljs-string&quot;&gt;&quot;Error running executor&quot;&lt;/span&gt;, e)&lt;br/&gt;state = ExecutorState.&lt;span class=&quot;hljs-function&quot;&gt;FAILED&lt;br/&gt;&lt;span class=&quot;hljs-title&quot;&gt;killProcess&lt;/span&gt;&lt;span class=&quot;hljs-params&quot;&gt;(Some(e.toString)&lt;/span&gt;)&lt;br/&gt;}&lt;br/&gt;}&lt;br/&gt;}&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;h4 id=&quot;h14633master&quot;&gt;&lt;span&gt;&lt;strong&gt;14.6.3 异常分析3：Master 异常退出&lt;/strong&gt;&lt;/span&gt;&lt;/h4&gt;
&lt;img title=&quot;&quot; src=&quot;https://s2.ax1x.com/2019/05/02/Etv2mn.png&quot; alt=&quot;&quot;/&gt;&lt;br/&gt;Worker 和 Executor 异常退出的场景都讲到了，我们剩下最后一种情况了，Master 挂掉了怎么办？
&lt;p&gt;&lt;strong&gt;后果分析&lt;/strong&gt;&lt;br/&gt;带头大哥如果不在了，会是什么后果呢？&lt;br/&gt;  1）Worker 没有汇报的对象了，也就是如果 Executor 再次跑飞，Worker 是不会将 Executor 启动起来的，大哥没给指令。&lt;br/&gt;  2）无法向集群提交新的任务。&lt;br/&gt;  3）老的任务即便结束了，占用的资源也无法清除，因为资源清除的指令是 Master 发出的。&lt;/p&gt;
&lt;h2 id=&quot;h15wordcount&quot;&gt;&lt;span&gt;&lt;strong&gt;第15章 wordcount 程序运行原理窥探&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;
&lt;h3 id=&quot;h151sparkscalawordcount&quot;&gt;&lt;span&gt;&lt;strong&gt;15.1 spark 之 scala 实现 wordcount&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;在 spark 中使用 scala 来实现 wordcount（统计单词出现次数模型）更加简单，相对 java 代码上更加简洁，其函数式编程的思维逻辑也更加直观。&lt;/p&gt;
&lt;pre readability=&quot;8.5&quot;&gt;
&lt;code class=&quot;java language-java hljs&quot; readability=&quot;11&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;package&lt;/span&gt; com.spark.firstApp&lt;p&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;import&lt;/span&gt; org.apache.spark.{SparkContext, SparkConf}&lt;/p&gt;&lt;p&gt;&lt;br/&gt;object WordCount1 {&lt;br/&gt;&lt;span class=&quot;hljs-function&quot;&gt;def &lt;span class=&quot;hljs-title&quot;&gt;main&lt;/span&gt;&lt;span class=&quot;hljs-params&quot;&gt;(args: Array[String])&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;if&lt;/span&gt; (args.length == &lt;span class=&quot;hljs-number&quot;&gt;0&lt;/span&gt;) {&lt;br/&gt;System.err.println(&lt;span class=&quot;hljs-string&quot;&gt;&quot;Usage: WordCount1 &amp;lt;file1&amp;gt;&quot;&lt;/span&gt;)&lt;br/&gt;System.exit(&lt;span class=&quot;hljs-number&quot;&gt;1&lt;/span&gt;)&lt;br/&gt;}&lt;br/&gt;val conf = &lt;span class=&quot;hljs-keyword&quot;&gt;new&lt;/span&gt; SparkConf().setAppName(&lt;span class=&quot;hljs-string&quot;&gt;&quot;WordCount1&quot;&lt;/span&gt;).setMaster(&lt;span class=&quot;hljs-string&quot;&gt;&quot;local&quot;&lt;/span&gt;)&lt;br/&gt;val sc = &lt;span class=&quot;hljs-keyword&quot;&gt;new&lt;/span&gt; SparkContext(conf)&lt;/p&gt;&lt;p&gt;&lt;br/&gt;sc.textFile(args(&lt;span class=&quot;hljs-number&quot;&gt;0&lt;/span&gt;)).flatMap(_.split(&lt;span class=&quot;hljs-string&quot;&gt;&quot; &quot;&lt;/span&gt;)).map(x =&amp;gt; (x, &lt;span class=&quot;hljs-number&quot;&gt;1&lt;/span&gt;)).reduceByKey(_ + _).take(&lt;span class=&quot;hljs-number&quot;&gt;10&lt;/span&gt;).foreach(println)&lt;br/&gt;sc.stop()&lt;br/&gt;}&lt;br/&gt;}&lt;br/&gt;&lt;/p&gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;h152&quot;&gt;&lt;span&gt;&lt;strong&gt;15.2 原理窥探&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;在 spark 集群中运行 wordcount 程序其主要业务逻辑比较简单，涵盖一下 3 个过程：&lt;br/&gt;  1）读取存储介质上的文本文件（一般存储在 hdfs 上）；&lt;br/&gt;  2）对文本文件内容进行解析，按照单词进行分组统计汇总；&lt;br/&gt;  3）将过程 2 的分组结果保存到存储介质上。（一般存储在 hdfs 或者 RMDB 上）&lt;br/&gt;虽然 wordcount 的业务逻辑非常简单，但其应用程序在 spark 中的运行过程却巧妙得体现了 spark 的核心精髓--&lt;code&gt;分布式弹性数据集&lt;/code&gt;、&lt;code&gt;内存迭代&lt;/code&gt;以及&lt;code&gt;函数式编程&lt;/code&gt;等特点。下图对 spark 集群中 wordcount 的运行过程进行剖析，加深对 spark 技术原理窥探。&lt;/p&gt;
&lt;img title=&quot;&quot; src=&quot;https://s2.ax1x.com/2019/05/02/Etv4YT.png&quot; alt=&quot;&quot;/&gt;&lt;br/&gt;  该图横向分割下面给出了 wordcount 的 scala 核心程序实现，该程序在 spark 集群的运行过程涉及几个核心的 RDD，主要有 textFileRDD、flatMapRDD、mapToPairRDD、shuffleRDD（reduceByKey）等。&lt;br/&gt;  应用程序通过 textFile 方法读取 hdfs 上的文本文件，数据分片的形式以 RDD 为统一模式将数据加载到不同的物理节点上，如上图所示的节点 1、节点 2 到节点 n；并通过一系列的数据转换，如利用 flatMap 将文本文件中对应每行数据进行拆分（文本文件中单词以空格为分割符号），形成一个以每个单词为核心新的数据集合 RDD；之后通过 MapRDD 继续转换形成形成 (K,V) 对 数据形式，以便进一步使用 reduceByKey 方法，该方法会触发 shuffle 行为，促使不同的单词到对应的节点上进行汇聚统计（实际上在夸节点进行数据 shuffle 之前会在本地先对相同单词进行合并累加），形成 wordcount 的统计结果；最终通过 saveAsTextFile 方法将数据保存到 hdfs 上。具体的运行逻辑原理以及过程上图给出了详细的示意说明。</description>
<pubDate>Thu, 02 May 2019 12:12:00 +0000</pubDate>
<dc:creator>黑泽君</dc:creator>
<og:description>第1章 Spark 整体概述1.1 整体概念1.2 RDD 抽象1.3 计算抽象1.4 集群模式1.5 RPC 网络通信抽象1.6 启动 Standalone 集群1.7 核心组件1.8 核心组件交互</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/chenmingjun/p/10803261.html</dc:identifier>
</item>
</channel>
</rss>