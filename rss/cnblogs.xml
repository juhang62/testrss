<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="css/feed.xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/" xmlns:og="http://ogp.me/ns#">
<channel>
<atom:link rel="self" href="http://192.168.1.4/fivefilters/makefulltextfeed.php?url=feed.cnblogs.com%2Fblog%2Fsitehome%2Frss&amp;max=10&amp;links=preserve&amp;exc=" />
<atom:link rel="alternate" title="Source URL" href="http://feed.cnblogs.com/blog/sitehome/rss" />
<atom:link rel="related" title="Subscribe to feed" href="http://www.subtome.com/#/subscribe?feeds=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed.cnblogs.com%252Fblog%252Fsitehome%252Frss%26max%3D10%26links%3Dpreserve%26exc%3D&amp;back=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed.cnblogs.com%252Fblog%252Fsitehome%252Frss%26max%3D10%26links%3Dpreserve%26exc%3D" />
<title>博客园_首页</title>
<link></link>
<description>代码改变世界</description>
<item>
<title>DRF类视图让你的代码DRY起来 - dongfanger</title>
<link>http://www.cnblogs.com/df888/p/14155609.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/df888/p/14155609.html</guid>
<description>&lt;p&gt;刚开始写&lt;code&gt;views.py&lt;/code&gt;模块的代码，一般都是用&lt;code&gt;def&lt;/code&gt;定义的函数视图，不过DRF更推荐使用&lt;code&gt;class&lt;/code&gt;定义的类视图，这能让我们的代码更符合DRY（Don't Repeat Yourself）设计原则：&lt;/p&gt;
&lt;center&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1629545/202012/1629545-20201218162600339-634705503.png&quot;/&gt;&lt;/center&gt;

&lt;p&gt;&lt;code&gt;rest_framework.views.APIView&lt;/code&gt;是DRF封装的API视图，继承了&lt;code&gt;django.views.generic.base.View&lt;/code&gt;：&lt;/p&gt;
&lt;center&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1629545/202012/1629545-20201218162600883-1761270922.png&quot;/&gt;&lt;/center&gt;
&lt;p&gt;我们用它把函数视图改写成类视图，编辑&lt;code&gt;snippets/views.py&lt;/code&gt;：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-python&quot;&gt;from snippets.models import Snippet
from snippets.serializers import SnippetSerializer
from django.http import Http404
from rest_framework.views import APIView
from rest_framework.response import Response
from rest_framework import status


class SnippetList(APIView):
    &quot;&quot;&quot;
    List all snippets, or create a new snippet.
    &quot;&quot;&quot;
    def get(self, request, format=None):
        snippets = Snippet.objects.all()
        serializer = SnippetSerializer(snippets, many=True)
        return Response(serializer.data)

    def post(self, request, format=None):
        serializer = SnippetSerializer(data=request.data)
        if serializer.is_valid():
            serializer.save()
            return Response(serializer.data, status=status.HTTP_201_CREATED)
        return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST)
    
    
class SnippetDetail(APIView):
    &quot;&quot;&quot;
    Retrieve, update or delete a snippet instance.
    &quot;&quot;&quot;
    def get_object(self, pk):
        try:
            return Snippet.objects.get(pk=pk)
        except Snippet.DoesNotExist:
            raise Http404

    def get(self, request, pk, format=None):
        snippet = self.get_object(pk)
        serializer = SnippetSerializer(snippet)
        return Response(serializer.data)

    def put(self, request, pk, format=None):
        snippet = self.get_object(pk)
        serializer = SnippetSerializer(snippet, data=request.data)
        if serializer.is_valid():
            serializer.save()
            return Response(serializer.data)
        return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST)

    def delete(self, request, pk, format=None):
        snippet = self.get_object(pk)
        snippet.delete()
        return Response(status=status.HTTP_204_NO_CONTENT)
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;类视图的代码跟函数视图是非常类似的，区别在于&lt;code&gt;GET&lt;/code&gt;、&lt;code&gt;POST&lt;/code&gt;等方法是用的函数而不是&lt;code&gt;if&lt;/code&gt;语句，可以更好的解耦代码。&lt;/p&gt;
&lt;p&gt;改了&lt;code&gt;views.py&lt;/code&gt;代码后，需要同时修改&lt;code&gt;snippets/urls.py&lt;/code&gt;：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-python&quot;&gt;from django.urls import path
from rest_framework.urlpatterns import format_suffix_patterns
from snippets import views

urlpatterns = [
    path('snippets/', views.SnippetList.as_view()),
    path('snippets/&amp;lt;int:pk&amp;gt;/', views.SnippetDetail.as_view()),
]

urlpatterns = format_suffix_patterns(urlpatterns)
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;为什么要加个&lt;code&gt;as_view()&lt;/code&gt;方法？&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;因为&lt;code&gt;path()&lt;/code&gt;的参数必须是可调用的，在源码中能看到&lt;code&gt;elif callable(view)&lt;/code&gt;：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-python&quot;&gt;def _path(route, view, kwargs=None, name=None, Pattern=None):
    if isinstance(view, (list, tuple)):
        # For include(...) processing.
        pattern = Pattern(route, is_endpoint=False)
        urlconf_module, app_name, namespace = view
        return URLResolver(
            pattern,
            urlconf_module,
            kwargs,
            app_name=app_name,
            namespace=namespace,
        )
    # callable判断
    elif callable(view):
        pattern = Pattern(route, name=name, is_endpoint=True)
        return URLPattern(pattern, view, kwargs, name)
    else:
        raise TypeError('view must be a callable or a list/tuple in the case of include().')
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;as_view()&lt;/code&gt;方法返回了一个内部定义的可调用函数：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-python&quot;&gt;@classonlymethod
def as_view(cls, **initkwargs):
    &quot;&quot;&quot;Main entry point for a request-response process.&quot;&quot;&quot;
    for key in initkwargs:
        if key in cls.http_method_names:
            raise TypeError(
                'The method name %s is not accepted as a keyword argument '
                'to %s().' % (key, cls.__name__)
            )
        if not hasattr(cls, key):
            raise TypeError(&quot;%s() received an invalid keyword %r. as_view &quot;
                            &quot;only accepts arguments that are already &quot;
                            &quot;attributes of the class.&quot; % (cls.__name__, key))

    # 内部定义了可调用函数
    def view(request, *args, **kwargs):
        self = cls(**initkwargs)
        self.setup(request, *args, **kwargs)
        if not hasattr(self, 'request'):
            raise AttributeError(
                &quot;%s instance has no 'request' attribute. Did you override &quot;
                &quot;setup() and forget to call super()?&quot; % cls.__name__
            )
        return self.dispatch(request, *args, **kwargs)
    view.view_class = cls
    view.view_initkwargs = initkwargs

    # take name and docstring from class
    update_wrapper(view, cls, updated=())

    # and possible attributes set by decorators
    # like csrf_exempt from dispatch
    update_wrapper(view, cls.dispatch, assigned=())
    return view
&lt;/code&gt;
&lt;/pre&gt;

&lt;p&gt;DRF提供了&lt;code&gt;rest_framework.mixins&lt;/code&gt;模块，封装了类视图常用的增删改查方法：&lt;/p&gt;
&lt;center&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1629545/202012/1629545-20201218162601804-1283150994.png&quot;/&gt;&lt;/center&gt;
&lt;p&gt;比如新增&lt;code&gt;CreateModelMixin&lt;/code&gt;：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-python&quot;&gt;class CreateModelMixin:
    &quot;&quot;&quot;
    Create a model instance.
    &quot;&quot;&quot;
    def create(self, request, *args, **kwargs):
        serializer = self.get_serializer(data=request.data)
        serializer.is_valid(raise_exception=True)
        self.perform_create(serializer)
        headers = self.get_success_headers(serializer.data)
        return Response(serializer.data, status=status.HTTP_201_CREATED, headers=headers)

    def perform_create(self, serializer):
        serializer.save()

    def get_success_headers(self, data):
        try:
            return {'Location': str(data[api_settings.URL_FIELD_NAME])}
        except (TypeError, KeyError):
            return {}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;类视图继承了Mixin后，可以直接使用它的&lt;code&gt;.create()&lt;/code&gt;方法，类似的还有&lt;code&gt;.list()&lt;/code&gt;、&lt;code&gt;.retrieve()&lt;/code&gt;、&lt;code&gt;.update()&lt;/code&gt;和&lt;code&gt;.destroy()&lt;/code&gt;。我们按照这个思路来简化&lt;code&gt;snippets/views.py&lt;/code&gt;代码：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-python&quot;&gt;from snippets.models import Snippet
from snippets.serializers import SnippetSerializer
from rest_framework import mixins
from rest_framework import generics

class SnippetList(mixins.ListModelMixin,
                  mixins.CreateModelMixin,
                  generics.GenericAPIView):
    queryset = Snippet.objects.all()
    serializer_class = SnippetSerializer

    def get(self, request, *args, **kwargs):
        return self.list(request, *args, **kwargs)

    def post(self, request, *args, **kwargs):
        return self.create(request, *args, **kwargs)


class SnippetDetail(mixins.RetrieveModelMixin,
                    mixins.UpdateModelMixin,
                    mixins.DestroyModelMixin,
                    generics.GenericAPIView):
    queryset = Snippet.objects.all()
    serializer_class = SnippetSerializer

    def get(self, request, *args, **kwargs):
        return self.retrieve(request, *args, **kwargs)

    def put(self, request, *args, **kwargs):
        return self.update(request, *args, **kwargs)

    def delete(self, request, *args, **kwargs):
        return self.destroy(request, *args, **kwargs)
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;瞬间少了好多代码，真够DRY的。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;什么是mixin？&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;维基百科的解释：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;In object-oriented programming languages, a mixin (or mix-in) is a class that contains methods for use by other classes without having to be the parent class of those other classes.
&lt;/code&gt;
&lt;/pre&gt;
&lt;blockquote&gt;
&lt;p&gt;不太好理解。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;换句话说，mixin类提供了一些方法，我们不会直接用这些方法，而是把它添加到其他类来使用。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;还是有点抽象。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;再简单点说，mixin只不过是实现多重继承的一个技巧而已。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;这下应该清楚了。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;如果仔细看&lt;code&gt;snippets/views.py&lt;/code&gt;的代码，就会发现我们用到了&lt;code&gt;from rest_framework import generics&lt;/code&gt;：&lt;/p&gt;
&lt;center&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1629545/202012/1629545-20201218162601294-909547195.png&quot;/&gt;&lt;/center&gt;
&lt;p&gt;和&lt;code&gt;generics.GenericAPIView&lt;/code&gt;：&lt;/p&gt;
&lt;center&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1629545/202012/1629545-20201218162601578-326241897.png&quot;/&gt;&lt;/center&gt;
&lt;p&gt;这是DRF提供的通用API类视图，&lt;code&gt;mixins&lt;/code&gt;只提供了处理方法，&lt;code&gt;views.py&lt;/code&gt;中的类要成为视图，还需要继承&lt;code&gt;GenericAPIView&lt;/code&gt;，&lt;code&gt;GenericAPIView&lt;/code&gt;继承了本文第一小节提到的&lt;code&gt;rest_framework.views.APIView&lt;/code&gt;。除了&lt;code&gt;GenericAPIView&lt;/code&gt;，我们还可以用其他的类视图进一步简化代码：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-python&quot;&gt;from snippets.models import Snippet
from snippets.serializers import SnippetSerializer
from rest_framework import generics


class SnippetList(generics.ListCreateAPIView):
    queryset = Snippet.objects.all()
    serializer_class = SnippetSerializer


class SnippetDetail(generics.RetrieveUpdateDestroyAPIView):
    queryset = Snippet.objects.all()
    serializer_class = SnippetSerializer
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;看看&lt;code&gt;ListCreateAPIView&lt;/code&gt;的源码：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-python&quot;&gt;class ListCreateAPIView(mixins.ListModelMixin,
                        mixins.CreateModelMixin,
                        GenericAPIView):
    &quot;&quot;&quot;
    Concrete view for listing a queryset or creating a model instance.
    &quot;&quot;&quot;
    def get(self, request, *args, **kwargs):
        return self.list(request, *args, **kwargs)

    def post(self, request, *args, **kwargs):
        return self.create(request, *args, **kwargs)
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;真DRY！&lt;/p&gt;

&lt;p&gt;学到这里，已经开始感受到了Django REST framework的强大之处了，我觉得学一个框架，不仅要看如何使用，还需要了解它的设计思路和底层实现，这样才能更好的总结为自己的编程思想，写出更漂亮的代码。&lt;/p&gt;
&lt;blockquote readability=&quot;0.68936170212766&quot;&gt;
&lt;p&gt;参考资料：&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.django-rest-framework.org/tutorial/3-class-based-views/#tutorial-3-class-based-views&quot; target=&quot;_blank&quot;&gt;https://www.django-rest-framework.org/tutorial/3-class-based-views/#tutorial-3-class-based-views&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://stackoverflow.com/questions/533631/what-is-a-mixin-and-why-are-they-useful&quot; target=&quot;_blank&quot;&gt;https://stackoverflow.com/questions/533631/what-is-a-mixin-and-why-are-they-useful&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.zhihu.com/question/20778853&quot; target=&quot;_blank&quot;&gt;https://www.zhihu.com/question/20778853&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
</description>
<pubDate>Sat, 19 Dec 2020 00:29:00 +0000</pubDate>
<dc:creator>dongfanger</dc:creator>
<og:description>刚开始写views.py模块的代码，一般都是用def定义的函数视图，不过DRF更推荐使用class定义的类视图，这能让我们的代码更符合DRY（Don&amp;amp;#39;t Repeat Yourself</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/df888/p/14155609.html</dc:identifier>
</item>
<item>
<title>[从源码学设计]蚂蚁金服SOFARegistry 之 自动调节间隔周期性任务 - 罗西的思考</title>
<link>http://www.cnblogs.com/rossiXYZ/p/14157976.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/rossiXYZ/p/14157976.html</guid>
<description>&lt;p&gt;SOFARegistry 是蚂蚁金服开源的一个生产级、高时效、高可用的服务注册中心。本系列文章重点在于分析设计和架构，即利用多篇文章，从多个角度反推总结 DataServer 或者 SOFARegistry 的实现机制和架构思路，让大家借以学习阿里如何设计。本文为第九篇，介绍SOFARegistry自动调节间隔周期性任务的实现。&lt;/p&gt;&lt;div id=&quot;cnblogs_post_body&quot; readability=&quot;241.1356466877&quot;&gt;


&lt;h2 id=&quot;0x00-摘要&quot;&gt;0x00 摘要&lt;/h2&gt;
&lt;p&gt;SOFARegistry 是蚂蚁金服开源的一个生产级、高时效、高可用的服务注册中心。&lt;/p&gt;
&lt;p&gt;本系列文章重点在于分析设计和架构，即利用多篇文章，从多个角度反推总结 DataServer 或者 SOFARegistry 的实现机制和架构思路，让大家借以学习阿里如何设计。&lt;/p&gt;
&lt;p&gt;本文为第九篇，介绍SOFARegistry自动调节间隔周期性任务的实现。&lt;/p&gt;
&lt;h2 id=&quot;0x01-业务领域&quot;&gt;0x01 业务领域&lt;/h2&gt;
&lt;p&gt;蚂蚁金服这里的业务需求主要是：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;启动一个无限循环任务，不定期执行任务；&lt;/li&gt;
&lt;li&gt;启动若干周期性延时任务；&lt;/li&gt;
&lt;li&gt;某些周期性任务需要实现&lt;u&gt;自动调节间隔&lt;/u&gt;功能：程序一旦遇到发生超时异常，就将间隔时间调大，如果连续超时，那么每次间隔时间都会增大一倍，一直到达外部参数设定的上限为止，一旦新任务不再发生超时异常，间隔时间又会自动恢复为初始值&lt;/li&gt;
&lt;/ul&gt;&lt;h2 id=&quot;0x02-阿里方案&quot;&gt;0x02 阿里方案&lt;/h2&gt;
&lt;p&gt;阿里采用了：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;ExecutorService实现了无限循环任务；&lt;/li&gt;
&lt;li&gt;ScheduledExecutorService 实现了周期性任务；&lt;/li&gt;
&lt;li&gt;TimedSupervisorTask 实现了自动调节间隔的周期性任务；&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;我们在设计延时/周期性任务时就可以参考TimedSupervisorTask的实现&lt;/p&gt;
&lt;h2 id=&quot;0x03-scheduler&quot;&gt;0x03 Scheduler&lt;/h2&gt;
&lt;p&gt;Scheduler类中就是这个方案的体现。&lt;/p&gt;
&lt;p&gt;首先，我们需要看看 Scheduler的代码。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;public class Scheduler {

    private final ScheduledExecutorService scheduler;
    public final ExecutorService           versionCheckExecutor;
    private final ThreadPoolExecutor       expireCheckExecutor;

    @Autowired
    private AcceptorStore                  localAcceptorStore;

    public Scheduler() {
        scheduler = new ScheduledThreadPoolExecutor(4, new NamedThreadFactory(&quot;SyncDataScheduler&quot;));

        expireCheckExecutor = new ThreadPoolExecutor(1, 3, 0, TimeUnit.SECONDS,
            new SynchronousQueue&amp;lt;&amp;gt;(), new NamedThreadFactory(&quot;SyncDataScheduler-expireChangeCheck&quot;));

        versionCheckExecutor = new ThreadPoolExecutor(2, 2, 0L, TimeUnit.MILLISECONDS,
            new LinkedBlockingQueue&amp;lt;&amp;gt;(), new NamedThreadFactory(
                &quot;SyncDataScheduler-versionChangeCheck&quot;));

    }

    public void startScheduler() {
        scheduler.schedule(
                new TimedSupervisorTask(&quot;FetchDataLocal&quot;, scheduler, expireCheckExecutor, 3,
                        TimeUnit.SECONDS, 10, () -&amp;gt; localAcceptorStore.checkAcceptorsChangAndExpired()),
                30, TimeUnit.SECONDS);

        versionCheckExecutor.execute(() -&amp;gt; localAcceptorStore.changeDataCheck());
    }

    public void stopScheduler() {
        if (scheduler != null &amp;amp;&amp;amp; !scheduler.isShutdown()) {
            scheduler.shutdown();
        }
        if (versionCheckExecutor != null &amp;amp;&amp;amp; !versionCheckExecutor.isShutdown()) {
            versionCheckExecutor.shutdown();
        }
    }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;接下来我们就逐一分析下其实现或者说是设计选择。&lt;/p&gt;
&lt;h2 id=&quot;0x04-无限循环任务&quot;&gt;0x04 无限循环任务&lt;/h2&gt;
&lt;p&gt;阿里这里采用ExecutorService实现了无限循环任务，不定期完成业务。&lt;/p&gt;
&lt;h3 id=&quot;41-executorservice&quot;&gt;4.1 ExecutorService&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Executor&lt;/strong&gt;：一个JAVA接口，其定义了一个接收Runnable对象的方法executor，其方法签名为executor(Runnable command)，该方法接收一个Runable实例，用来执行一个实现了Runnable接口的类。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ExecutorService&lt;/strong&gt;：是一个比Executor使用更广泛的子类接口。&lt;/p&gt;
&lt;p&gt;其提供了生命周期管理的方法，返回 Future 对象，以及可跟踪一个或多个异步任务执行状况返回Future的方法；&lt;/p&gt;
&lt;p&gt;当所有已经提交的任务执行完毕后将会关闭ExecutorService。因此我们一般用该接口来实现和管理多线程。&lt;/p&gt;
&lt;p&gt;这里ExecutorService虽然其不能提供周期性功能，但是&lt;code&gt;localAcceptorStore.changeDataCheck&lt;/code&gt;本身就是&lt;u&gt;一个while (true) loop，其可以依靠DelayQueue来完成类似周期功能&lt;/u&gt;。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;versionCheckExecutor = new ThreadPoolExecutor(2, 2, 0L, TimeUnit.MILLISECONDS,
            new LinkedBlockingQueue&amp;lt;&amp;gt;(), new NamedThreadFactory(
                &quot;SyncDataScheduler-versionChangeCheck&quot;));

versionCheckExecutor.execute(() -&amp;gt; localAcceptorStore.changeDataCheck());

public void changeDataCheck() {
        while (true) {
            try {
                DelayItem&amp;lt;Acceptor&amp;gt; delayItem = delayQueue.take();
                Acceptor acceptor = delayItem.getItem();
                removeCache(acceptor); // compare and remove
            } catch (InterruptedException e) {
                break;
            } catch (Throwable e) {
                LOGGER.error(e.getMessage(), e);
            }
        }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;0x05-周期任务&quot;&gt;0x05 周期任务&lt;/h2&gt;
&lt;p&gt;阿里这里采用了 ScheduledExecutorService 实现了周期性任务。&lt;/p&gt;
&lt;h3 id=&quot;51-scheduledexecutorservice&quot;&gt;5.1 ScheduledExecutorService&lt;/h3&gt;
&lt;p&gt;ScheduledExecutorService是一种线程池，ScheduledExecutorService在ExecutorService提供的功能之上再增加了延迟和定期执行任务的功能。&lt;/p&gt;
&lt;p&gt;其schedule方法创建具有各种延迟的任务，并返回可用于取消或检查执行的任务对象。&lt;/p&gt;
&lt;p&gt;寻常的Timer的内部只有一个线程，如果有多个任务的话就会顺序执行，这样我们的延迟时间和循环时间就会出现问题，而且异常未检查会中止线程。&lt;/p&gt;
&lt;p&gt;ScheduledExecutorService是线程池，并且线程池对异常做了处理，使得任务之间不会有影响。在对延迟任务和循环任务要求严格的时候，就需要考虑使用ScheduledExecutorService了。&lt;/p&gt;
&lt;h2 id=&quot;0x06-queue的选择&quot;&gt;0x06 Queue的选择&lt;/h2&gt;
&lt;h3 id=&quot;61-threadpoolexecutor的queue&quot;&gt;6.1 ThreadPoolExecutor的queue&lt;/h3&gt;
&lt;p&gt;ThreadPoolExecutor的完整构造方法的签名如下&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;ThreadPoolExecutor
(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&amp;lt;Runnable&amp;gt; workQueue, ThreadFactory threadFactory,RejectedExecutionHandler handler)12
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;其中，workQueue参数介绍如下：&lt;/p&gt;
&lt;p&gt;workQueue任务队列）：用于保存等待执行的任务的阻塞队列。可以选择以下几个阻塞队列。&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;ArrayBlockingQueue：是一个基于数组结构的&lt;strong&gt;有界阻塞队列&lt;/strong&gt;，此队列按 FIFO（先进先出）原则对元素进行排序；&lt;/li&gt;
&lt;li&gt;LinkedBlockingQueue：一个基于&lt;strong&gt;链表结构&lt;/strong&gt;的阻塞队列，此队列按FIFO （先进先出） 排序元素，吞吐量通常要高于ArrayBlockingQueue。静态工厂方法Executors.newFixedThreadPool()使用了这个队列；&lt;/li&gt;
&lt;li&gt;SynchronousQueue：一个&lt;strong&gt;不存储元素的阻塞队列&lt;/strong&gt;。每个插入操作必须等到另一个线程调用移除操作，否则插入操作一直处于&lt;strong&gt;阻塞状态&lt;/strong&gt;，吞吐量通常要高于LinkedBlockingQueue，静态工厂方法Executors.newCachedThreadPool使用了这个队列；&lt;/li&gt;
&lt;li&gt;PriorityBlockingQueue：一个具有&lt;strong&gt;优先级的无限阻塞队列&lt;/strong&gt;；&lt;/li&gt;
&lt;/ul&gt;&lt;h3 id=&quot;62-sofaregistry选择&quot;&gt;6.2 SOFARegistry选择&lt;/h3&gt;
&lt;p&gt;这里采用了两种Queue。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;expireCheckExecutor = new ThreadPoolExecutor(1, 3, 0, TimeUnit.SECONDS,
    new SynchronousQueue&amp;lt;&amp;gt;(), new NamedThreadFactory(&quot;SyncDataScheduler-expireChangeCheck&quot;));

versionCheckExecutor = new ThreadPoolExecutor(2, 2, 0L, TimeUnit.MILLISECONDS,
    new LinkedBlockingQueue&amp;lt;&amp;gt;(), new NamedThreadFactory(
        &quot;SyncDataScheduler-versionChangeCheck&quot;));
&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;63-linkedblockingqueue&quot;&gt;6.3 LinkedBlockingQueue&lt;/h3&gt;
&lt;p&gt;LinkedBlockingQueue是一种阻塞队列。&lt;/p&gt;
&lt;p&gt;LinkedBlockingQueue内部由&lt;strong&gt;单链表实现&lt;/strong&gt;了BlockingQueue接口，只能从head取元素，从tail添加元素。&lt;/p&gt;
&lt;p&gt;LinkedBlockingQueue内部分别使用了takeLock 和 putLock 对并发进行控制，也就是说&lt;strong&gt;LinkedBlockingQueue是读写分离的&lt;/strong&gt;，添加和删除操作并不是互斥操作，可以并行进行，这样也就可以大大提高吞吐量。&lt;/p&gt;
&lt;p&gt;LinkedBlockingQueue不同于ArrayBlockingQueue，它如果不指定容量，默认为&lt;code&gt;Integer.MAX_VALUE&lt;/code&gt;，也就是无界队列。如果存在添加速度大于删除速度时候，有可能会内存溢出，所以为了避免队列过大造成机器负载或者内存爆满的情况出现，我们在使用的时候建议手动传一个队列的大小。&lt;/p&gt;
&lt;p&gt;另外，LinkedBlockingQueue对每一个lock锁都提供了一个Condition用来挂起和唤醒其他线程。&lt;/p&gt;
&lt;h3 id=&quot;64-synchronousqueue&quot;&gt;6.4 SynchronousQueue&lt;/h3&gt;
&lt;p&gt;不像ArrayBlockingQueue或LinkedListBlockingQueue，SynchronousQueue内部并没有数据缓存空间。&lt;/p&gt;
&lt;p&gt;你不能调用peek()方法来看队列中是否有数据元素，因为数据元素只有当你试着取走的时候才可能存在，不取走而只想偷窥一下是不行的，当然遍历这个队列的操作也是不允许的。队列头元素是第一个排队要插入数据的&lt;strong&gt;线程&lt;/strong&gt;，而不是要交换的数据。&lt;/p&gt;
&lt;p&gt;数据是在配对的生产者和消费者线程之间直接传递的，并不会将数据缓冲数据到队列中。可以这样来理解：生产者和消费者互相等待对方，握手，然后&lt;strong&gt;一起&lt;/strong&gt;离开。&lt;/p&gt;
&lt;p&gt;SynchronousQueue的一个使用场景是在线程池里。Executors.newCachedThreadPool()就使用了SynchronousQueue，这个线程池根据需要（新任务到来时）创建新的线程，如果有空闲线程则会重复使用，线程空闲了60秒后会被回收。&lt;/p&gt;
&lt;h2 id=&quot;0x07-自动调节间隔的周期性任务&quot;&gt;0x07 自动调节间隔的周期性任务&lt;/h2&gt;
&lt;p&gt;TimedSupervisorTask 是一个自动调节间隔的周期性任务。这里&lt;u&gt;基本是借鉴了Eureka的同名实现，但是SOFA这里去除了“部分异常处理逻辑”&lt;/u&gt;。&lt;/p&gt;
&lt;p&gt;从整体上看，TimedSupervisorTask是固定间隔的周期性任务，一旦遇到超时就会将下一个周期的间隔时间调大，如果连续超时，那么每次间隔时间都会增大一倍，一直到达外部参数设定的上限为止，一旦新任务不再超时，间隔时间又会自动恢复为初始值，另外还有CAS来控制多线程同步。&lt;/p&gt;
&lt;p&gt;主要逻辑如下：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;执行submit()方法提交任务；&lt;/li&gt;
&lt;li&gt;执行future.get()方法，如果没有在规定的时间得到返回值或者任务出现异常，则进入异常处理catch代码块；&lt;/li&gt;
&lt;li&gt;如果没有发生异常，则再设置一次延时任务时间timeoutMillis；&lt;/li&gt;
&lt;li&gt;如果发生异常：
&lt;ul&gt;&lt;li&gt;发生TimeoutException异常，则执行&lt;code&gt;Math.min(maxDelay, currentDelay x 2)&lt;/code&gt;得到任务延时时间 x 2 和 最大延时时间的最小值，然后改变任务的延时时间timeoutMillis；&lt;/li&gt;
&lt;li&gt;发生RejectedExecutionException异常，SOFA只是打印log。Eureka则将rejectedCounter值+1；&lt;/li&gt;
&lt;li&gt;发生Throwable异常，SOFA只是打印log。Eureka则将throwableCounter值+1；&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;进入finally代码块
&lt;ul&gt;&lt;li&gt;.如果future不为null，则执行future.cancel(true)，中断线程停止任务；&lt;/li&gt;
&lt;li&gt;如果线程池没有shutdown，则创建一个新的定时任务；最关键就在上面的最后一行代码中：&lt;code&gt;scheduler.schedule(this, delay.get(), TimeUnit.MILLISECONDS)&lt;/code&gt;：执行完任务后，会再次调用schedule方法，在指定的时间之后执行一次相同的任务，这个间隔时间和最近一次任务是否超时有关，如果超时了就间隔时间就会变大；&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;其实现如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;public class TimedSupervisorTask extends TimerTask {
    private final ScheduledExecutorService scheduler;
    private final ThreadPoolExecutor       executor;
    private final long                     timeoutMillis;
    private final Runnable                 task;
    private String                         name;
    private final AtomicLong               delay;
    private final long                     maxDelay;

    public TimedSupervisorTask(String name, ScheduledExecutorService scheduler,
                               ThreadPoolExecutor executor, int timeout, TimeUnit timeUnit,
                               int expBackOffBound, Runnable task) {
        this.name = name;
        this.scheduler = scheduler;
        this.executor = executor;
        this.timeoutMillis = timeUnit.toMillis(timeout);
        this.task = task;
        this.delay = new AtomicLong(timeoutMillis);
        this.maxDelay = timeoutMillis * expBackOffBound;

    }

    @Override
    public void run() {
        Future future = null;
        try {
            //使用Future，可以设定子线程的超时时间，这样当前线程就不用无限等待了
            future = executor.submit(task);
            //指定等待子线程的最长时间
            // block until done or timeout
            future.get(timeoutMillis, TimeUnit.MILLISECONDS);
            // 每次执行任务成功都会将delay重置
            delay.set(timeoutMillis);
        } catch (TimeoutException e) {

            long currentDelay = delay.get();
            // 如果出现异常，则将时间*2，然后取 定时时间 和 最长定时时间 中最小的为下次任务执行的延时时间
            long newDelay = Math.min(maxDelay, currentDelay * 2);
            // 设置为最新的值，考虑到多线程，所以用了CAS
            delay.compareAndSet(currentDelay, newDelay);

        } catch (RejectedExecutionException e) {
            // 线程池的阻塞队列中放满了待处理任务，触发了拒绝策略
            LOGGER.error(&quot;{} task supervisor rejected the task: {}&quot;, name, task, e);
        } catch (Throwable e) {
           // 出现未知的异常
            LOGGER.error(&quot;{} task supervisor threw an exception&quot;, name, e);
        } finally {
           //这里任务要么执行完毕，要么发生异常，都用cancel方法来清理任务；
            if (future != null) {
                future.cancel(true);
            }
            //这里就是周期性任务的原因：只要没有停止调度器，就再创建一次性任务，执行时间时dealy的值，
            //假设外部调用时传入的超时时间为30秒（构造方法的入参timeout），最大间隔时间为50秒(构造方法的入参expBackOffBound)
            //如果最近一次任务没有超时，那么就在30秒后开始新任务，
            //如果最近一次任务超时了，那么就在50秒后开始新任务（异常处理中有个乘以二的操作，乘以二后的60秒超过了最大间隔50秒）
            scheduler.schedule(this, delay.get(), TimeUnit.MILLISECONDS);
        }
    }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;0xff-参考&quot;&gt;0xFF 参考&lt;/h2&gt;
&lt;p&gt;&lt;a href=&quot;https://www.cnblogs.com/liujunj/p/13401809.html&quot; target=&quot;_blank&quot;&gt;Eureka系列(六) TimedSupervisorTask类解析&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://blog.csdn.net/boling_cavalry/article/details/82795825&quot; target=&quot;_blank&quot;&gt;Eureka的TimedSupervisorTask类（自动调节间隔的周期性任务）&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.cnblogs.com/dafanjoy/p/9729358.html&quot; target=&quot;_blank&quot;&gt;java线程池ThreadPoolExecutor类使用详解&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.cnblogs.com/rossiXYZ/p/dockone.io/article/8284&quot; target=&quot;_blank&quot;&gt;Java线程池ThreadPoolExecutor实现原理剖析&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.cnblogs.com/liuzhihu/p/8177371.html&quot; target=&quot;_blank&quot;&gt;深入理解Java线程池：ThreadPoolExecutor&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://ifeve.com/java%E4%B8%AD%E7%BA%BF%E7%A8%8B%E6%B1%A0threadpoolexecutor%E5%8E%9F%E7%90%86%E6%8E%A2%E7%A9%B6/&quot; target=&quot;_blank&quot;&gt;Java中线程池ThreadPoolExecutor原理探究&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.cnblogs.com/faunjoe88/p/7929757.html&quot; target=&quot;_blank&quot;&gt;java并发之SynchronousQueue实现原理&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://blog.csdn.net/wangxueqing52/article/details/80099670&quot; target=&quot;_blank&quot;&gt;ScheduledExecutorService 和 Timer 的区别&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://ifeve.com/java-synchronousqueue/&quot; target=&quot;_blank&quot;&gt;Java并发包中的同步队列SynchronousQueue实现原理&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://blog.csdn.net/a837199685/article/details/50619311&quot; target=&quot;_blank&quot;&gt;ThreadPoolExecutor线程池解析与BlockingQueue的三种实现&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://benjaminwhx.com/2018/05/11/%5B%E7%BB%86%E8%B0%88Java%E5%B9%B6%E5%8F%91%5D%E8%B0%88%E8%B0%88LinkedBlockingQueue/&quot; target=&quot;_blank&quot;&gt;【细谈Java并发】谈谈LinkedBlockingQueue&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.cnblogs.com/duodushuduokanbao/p/9556555.html&quot; target=&quot;_blank&quot;&gt;阻塞队列之LinkedBlockingQueue&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;</description>
<pubDate>Sat, 19 Dec 2020 00:24:00 +0000</pubDate>
<dc:creator>罗西的思考</dc:creator>
<og:description>SOFARegistry 是蚂蚁金服开源的一个生产级、高时效、高可用的服务注册中心。本系列文章重点在于分析设计和架构，即利用多篇文章，从多个角度反推总结 DataServer 或者 SOFARegis</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/rossiXYZ/p/14157976.html</dc:identifier>
</item>
<item>
<title>Python读写EXCEL文件常用方法大全 - Huny</title>
<link>http://www.cnblogs.com/huny/p/14154763.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/huny/p/14154763.html</guid>
<description>&lt;h2 id=&quot;前言&quot;&gt;前言&lt;/h2&gt;
&lt;p&gt;python读写excel的方式有很多，不同的模块在读写的讲法上稍有区别，这里我主要介绍几个常用的方式。&lt;/p&gt;
&lt;h2 id=&quot;数据准备&quot;&gt;数据准备&lt;/h2&gt;
&lt;p&gt;为了方便演示，我这里新建了一个data.xls和data.xlsx文件，第一个工作表sheet1区域“A1:E5”的内容如下，用于测试读写excel的代码：&lt;br/&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1510016/202012/1510016-20201218143436193-1221406152.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h2 id=&quot;xlrd和xlwt&quot;&gt;xlrd和xlwt&lt;/h2&gt;
&lt;p&gt;xlrd是一个库，用于从Excel文件中以.xls格式读取数据和格式化信息&lt;br/&gt;xlwt是一个库，用于将数据和格式化信息写入较旧的Excel文件(例如:.xls)。&lt;/p&gt;
&lt;h3 id=&quot;示例&quot;&gt;示例&lt;/h3&gt;
&lt;pre&gt;
&lt;code&gt;pip install xlrd
pip install xlwt
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1510016/202012/1510016-20201218143943275-1583030811.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;br/&gt;我们开始来读取文件的内容&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;import xlrd
import os

file_path = os.path.dirname(os.path.abspath(__file__))
base_path = os.path.join(file_path, 'data.xlsx')
book = xlrd.open_workbook(base_path)
sheet1 = book.sheets()[0]
nrows = sheet1.nrows
print('表格总行数', nrows)
ncols = sheet1.ncols
print('表格总列数', ncols)
row3_values = sheet1.row_values(2)
print('第3行值', row3_values)
col3_values = sheet1.col_values(2)
print('第3列值', col3_values)
cell_3_3 = sheet1.cell(2, 2).value
print('第3行第3列的单元格的值：', cell_3_3)

&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1510016/202012/1510016-20201218205354003-1752928566.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;br/&gt;接下来我们来进行写入，写入可以进行的操作太多了，我这里只列举了常用的的操作。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-import&quot;&gt;import datetime
# 创建一个workbook 设置编码
workbook = xlwt.Workbook(encoding='utf-8')
# 创建一个worksheet
worksheet = workbook.add_sheet('Worksheet')
# 写入excel参数对应 行, 列, 值
worksheet.write(0, 0, label='测试')
# 设置单元格宽度
worksheet.col(0).width = 3333

# 设置单元格高度
tall_style = xlwt.easyxf('font:height 520;')
worksheet.row(0).set_style(tall_style)

# 设置对齐方式
alignment = xlwt.Alignment()  # Create Alignment
# May be: HORZ_GENERAL, HORZ_LEFT, HORZ_CENTER, HORZ_RIGHT, HORZ_FILLED, HORZ_JUSTIFIED, HORZ_CENTER_ACROSS_SEL, HORZ_DISTRIBUTED
alignment.horz = xlwt.Alignment.HORZ_CENTER
# May be: VERT_TOP, VERT_CENTER, VERT_BOTTOM, VERT_JUSTIFIED, VERT_DISTRIBUTED
alignment.vert = xlwt.Alignment.VERT_CENTER
style = xlwt.XFStyle()  # Create Style
style.alignment = alignment  # Add Alignment to Style
worksheet.write(2, 0, '居中', style)

# 写入带颜色背景的数据
pattern = xlwt.Pattern()  # Create the Pattern
# May be: NO_PATTERN, SOLID_PATTERN, or 0x00 through 0x12
pattern.pattern = xlwt.Pattern.SOLID_PATTERN
pattern.pattern_fore_colour = 5  # May be: 8 through 63. 0 = Black, 1 = White, 2 = Red, 3 = Green, 4 = Blue, 5 = Yellow, 6 = Magenta, 7 = Cyan, 16 = Maroon, 17 = Dark Green, 18 = Dark Blue, 19 = Dark Yellow , almost brown), 20 = Dark Magenta, 21 = Teal, 22 = Light Gray, 23 = Dark Gray, the list goes on...
style = xlwt.XFStyle()  # Create the Pattern
style.pattern = pattern  # Add Pattern to Style
worksheet.write(0, 1, '颜色', style)

# 写入日期
style = xlwt.XFStyle()
# Other options: D-MMM-YY, D-MMM, MMM-YY, h:mm, h:mm:ss, h:mm, h:mm:ss, M/D/YY h:mm, mm:ss, [h]:mm:ss, mm:ss.0
style.num_format_str = 'M/D/YY'
worksheet.write(0, 2, datetime.datetime.now(), style)

# 写入公式
worksheet.write(0, 3, 5)  # Outputs 5
worksheet.write(0, 4, 2)  # Outputs 2
# Should output &quot;10&quot; (A1[5] * A2[2])
worksheet.write(1, 3, xlwt.Formula('D1*E1'))
# Should output &quot;7&quot; (A1[5] + A2[2])
worksheet.write(1, 4, xlwt.Formula('SUM(D1,E1)'))

# 写入超链接
worksheet.write(1, 0, xlwt.Formula('HYPERLINK(&quot;http://www.baidu.com&quot;;&quot;百度一下&quot;)'))
# 保存
workbook.save('Excel_test.xls')

&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;需要注意的是最好在当前路径下通过命令行执行，否则无法生成文件。&lt;br/&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1510016/202012/1510016-20201218215057917-1247576735.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;br/&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1510016/202012/1510016-20201218215146046-1837181270.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h2 id=&quot;openpyxl&quot;&gt;openpyxl&lt;/h2&gt;
&lt;p&gt;openpyxl是一个Python库，用于读取/写入Excel 2010 xlsx/xlsm/xltx/xltm文件。&lt;br/&gt;安装包&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;pip install openpyx
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;安装完成可以开始进行读取数据&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;import openpyxl
import os
file_path = os.path.dirname(os.path.abspath(__file__))
base_path = os.path.join(file_path, 'data.xlsx')
workbook = openpyxl.load_workbook(base_path)
worksheet = workbook.get_sheet_by_name('Sheet1')
row3=[item.value for item in list(worksheet.rows)[2]]
print('第3行值',row3)
col3=[item.value for item in list(worksheet.columns)[2]]
print('第3行值',col3)
cell_2_3=worksheet.cell(row=2,column=3).value
print('第2行第3列值',cell_2_3)
max_row=worksheet.max_row
print('最大行',max_row)
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1510016/202012/1510016-20201218221428377-765335747.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;br/&gt;现在我们来开始写入数据&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;import openpyxl
import datetime
from openpyxl.styles import Font, colors, Alignment
#实例化
workbook = openpyxl.Workbook()
# 激活 worksheet
sheet=workbook.active
#写入数据
sheet['A1']='python'
sheet['B1']='javascript'
#写入时间
sheet['A2'] = datetime.datetime.now().strftime(&quot;%Y-%m-%d&quot;)
# 第2行行高
sheet.row_dimensions[2].height = 40
# B列列宽
sheet.column_dimensions['B'].width = 30
# 设置A1中的数据垂直居中和水平居中
sheet['A1'].alignment = Alignment(horizontal='center', vertical='center')
# 下面的代码指定了等线24号，加粗斜体，字体颜色黄色。直接使用cell的font属性，将Font对象赋值给它。
bold_itatic_24_font = Font(name='等线', size=24, italic=True, color='00FFBB00', bold=True)
sheet['B1'].font = bold_itatic_24_font
# 合并单元格， 往左上角写入数据即可
sheet.merge_cells('A2:B2') # 合并一行中的几个单元格
# 拆分单元格
# sheet.unmerge_cells('A2:B2')
#保存
workbook.save('new.xlsx')

&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1510016/202012/1510016-20201218230027342-1468577012.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;br/&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1510016/202012/1510016-20201218230052963-1206153945.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h2 id=&quot;pandas&quot;&gt;pandas&lt;/h2&gt;
&lt;p&gt;pandas支持xls, xlsx, xlsm, xlsb, odf, ods和odt文件扩展名从本地文件系统或URL读取。支持读取单个工作表或工作表列表的选项。&lt;br/&gt;首先依然是安装包&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;pip install pandas
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;语法：&lt;br/&gt;pd.read_excel(io, sheet_name=0, header=0, names=None, index_col=None, usecols=None, squeeze=False,dtype=None, engine=None, converters=None, true_values=None, false_values=None, skiprows=None, nrows=None, na_values=None, parse_dates=False, date_parser=None, thousands=None, comment=None, skipfooter=0, convert_float=True, **kwds)&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;io，Excel的存储路径&lt;/li&gt;
&lt;li&gt;sheet_name，要读取的工作表名称&lt;/li&gt;
&lt;li&gt;header， 用哪一行作列名&lt;/li&gt;
&lt;li&gt;names， 自定义最终的列名&lt;/li&gt;
&lt;li&gt;index_col， 用作索引的列&lt;/li&gt;
&lt;li&gt;usecols，需要读取哪些列&lt;/li&gt;
&lt;li&gt;squeeze，当数据仅包含一列&lt;/li&gt;
&lt;li&gt;converters ，强制规定列数据类型&lt;/li&gt;
&lt;li&gt;skiprows，跳过特定行&lt;/li&gt;
&lt;li&gt;nrows ，需要读取的行数&lt;/li&gt;
&lt;li&gt;skipfooter ， 跳过末尾n行&lt;/li&gt;
&lt;/ul&gt;&lt;pre&gt;
&lt;code&gt;import pandas as pd 
import os

file_path = os.path.dirname(os.path.abspath(__file__))
base_path = os.path.join(file_path, 'data.xlsx')
df = pd.read_excel(base_path)
print(df)
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1510016/202012/1510016-20201218234534858-1447531711.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;br/&gt;写入数据&lt;br/&gt;语法：&lt;br/&gt;DataFrame.to_excel(excel_writer, sheet_name='Sheet1', na_rep='', float_format=None, columns=None, header=True, index=True, index_label=None, startrow=0, startcol=0, engine=None, merge_cells=True, encoding=None, inf_rep='inf', verbose=True, freeze_panes=None)&lt;br/&gt;参数说明：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;excel_writer：文件路径或现有的ExcelWriter&lt;/li&gt;
&lt;li&gt;sheet_name：将包含数据文件的工作表的名称&lt;/li&gt;
&lt;li&gt;na_rep：缺失的数据表示&lt;/li&gt;
&lt;li&gt;float_format：格式化浮点数的字符串。例如float_format = &quot; %。2f&quot;格式为0.1234到0.12。&lt;/li&gt;
&lt;li&gt;columns：列&lt;/li&gt;
&lt;li&gt;header：写出列名。如果给定一个字符串列表，则假定它是列名的别名。&lt;/li&gt;
&lt;li&gt;index：写入行名称(索引)&lt;/li&gt;
&lt;li&gt;index_label：如果需要，索引列的列标签。如果未指定，并且标头和索引为真，则使用索引名。如果DataFrame使用多索引，应该给出一个序列。&lt;/li&gt;
&lt;li&gt;startrow：左上角的单元格行转储数据帧。&lt;/li&gt;
&lt;li&gt;startcol：左上角单元格列转储数据帧。&lt;/li&gt;
&lt;li&gt;engine：编写要使用的引擎“ openpyxl”或“ xlsxwriter”。 您还可以通过选项io.excel.xlsx.writer，io.excel.xls.writer和io.excel.xlsm.writer进行设置。&lt;/li&gt;
&lt;li&gt;merge_cells：将多索引和层次结构行写入合并单元格。&lt;/li&gt;
&lt;li&gt;encoding：对生成的excel文件进行编码。仅对xlwt有必要，其他编写器本身支持unicode。&lt;/li&gt;
&lt;li&gt;inf_rep：表示无穷大。&lt;/li&gt;
&lt;li&gt;verbose：在错误日志中显示更多信息。&lt;/li&gt;
&lt;li&gt;freeze_panes：指定要冻结的最底部的行和最右边的列&lt;/li&gt;
&lt;/ul&gt;&lt;pre&gt;
&lt;code&gt;from pandas import DataFrame

data = {'name': ['张三', '李四', '王五'],'age': [11, 12, 13],'sex': ['男', '女', '男']}

df = DataFrame(data)

df.to_excel('file.xlsx')

&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1510016/202012/1510016-20201219002104090-1199874386.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;br/&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1510016/202012/1510016-20201219002118866-172019186.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
</description>
<pubDate>Sat, 19 Dec 2020 00:15:00 +0000</pubDate>
<dc:creator>Huny</dc:creator>
<og:description>##前言 python读写excel的方式有很多，不同的模块在读写的讲法上稍有区别，这里我主要介绍几个常用的方式。 用xlrd和xlwt进行excel读写； 用openpyxl进行excel读写； 用</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/huny/p/14154763.html</dc:identifier>
</item>
<item>
<title>群晖DS218+部署Harbor(1.10.3) - 程序员欣宸</title>
<link>http://www.cnblogs.com/bolingcavalry/p/14157932.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/bolingcavalry/p/14157932.html</guid>
<description>&lt;h3 id=&quot;欢迎访问我的github&quot;&gt;欢迎访问我的GitHub&lt;/h3&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/zq2599/blog_demos&quot; target=&quot;_blank&quot;&gt;https://github.com/zq2599/blog_demos&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;内容：所有原创文章分类汇总及配套源码，涉及Java、Docker、Kubernetes、DevOPS等；&lt;/p&gt;
&lt;h3 id=&quot;起因是懒&quot;&gt;起因是懒&lt;/h3&gt;
&lt;p&gt;最近在家折腾docker，需要一个私有镜像仓库harbor，通常做法是打开电脑，启动harbor，用完再关闭电脑，总觉得这些操作挺麻烦（您想骂我懒么？您骂得对.....）&lt;/p&gt;
&lt;h3 id=&quot;群晖解决烦恼&quot;&gt;群晖解决烦恼&lt;/h3&gt;
&lt;ol&gt;&lt;li&gt;家里有台群晖DS218+，从不关机，为全家提供稳定的图片和视频服务，之前已在上面部署了maven私服、MySQL，运行得很稳定，今天就把harbor也部署在上面吧，今后可以随时想用就用，算得上懒人救星了。&lt;/li&gt;
&lt;li&gt;下图是DS218+刚买来的样子，两块NAS硬盘，一直在稳定服务：&lt;br/&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/485422/202012/485422-20201219075623377-863737016.png&quot; alt=&quot;在这里插入图片描述&quot; loading=&quot;lazy&quot;/&gt;&lt;/li&gt;
&lt;li&gt;下图是网购的内存条，现在一共2+8=10G内存，内存充足才是敢折腾的底气：&lt;br/&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/485422/202012/485422-20201219075625220-1461565894.png&quot; alt=&quot;在这里插入图片描述&quot; loading=&quot;lazy&quot;/&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;h3 id=&quot;前文链接&quot;&gt;前文链接&lt;/h3&gt;
&lt;p&gt;之前折腾群晖的记录：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;&lt;a href=&quot;https://blog.csdn.net/boling_cavalry/article/details/105460567&quot; target=&quot;_blank&quot;&gt;群晖DS218+部署mysql&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://blog.csdn.net/boling_cavalry/article/details/105462692&quot; target=&quot;_blank&quot;&gt;群晖DS218+部署kafka&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://blog.csdn.net/boling_cavalry/article/details/105458466&quot; target=&quot;_blank&quot;&gt;群晖DS218+做maven私服(nexus3)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://blog.csdn.net/boling_cavalry/article/details/105465233&quot; target=&quot;_blank&quot;&gt;K8S使用群晖DS218+的NFS&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;h3 id=&quot;思路&quot;&gt;思路&lt;/h3&gt;
&lt;p&gt;其实操作很简单：harbor的部署是基于docker-compose的，群晖已带有docker-compose了，按照官方的部署指南操作即可，以下几处是要注意的地方：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;部署脚本中需要管理员权限，所以不在网页上操作了，而是SSH登录后台进行操作；&lt;/li&gt;
&lt;li&gt;自己在家使用，就不用https了，直接用http即可；&lt;/li&gt;
&lt;/ol&gt;&lt;h3 id=&quot;环境信息&quot;&gt;环境信息&lt;/h3&gt;
&lt;ol&gt;&lt;li&gt;群晖系统：DSM 6.2.2-24922 Update 4&lt;/li&gt;
&lt;li&gt;harbor：1.10.3&lt;/li&gt;
&lt;/ol&gt;&lt;h3 id=&quot;允许ssh登录&quot;&gt;允许SSH登录&lt;/h3&gt;
&lt;p&gt;先要设置允许SSH后台登录：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;如下图红框的操作：&lt;br/&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/485422/202012/485422-20201219075626431-2017347072.png&quot; alt=&quot;在这里插入图片描述&quot; loading=&quot;lazy&quot;/&gt;&lt;/li&gt;
&lt;li&gt;如下图，勾选启用SSH功能，端口就用22：&lt;br/&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/485422/202012/485422-20201219075626935-1708004350.png&quot; alt=&quot;在这里插入图片描述&quot; loading=&quot;lazy&quot;/&gt;&lt;/li&gt;
&lt;li&gt;现在用SSH终端即可登录群晖了，我这里是在windows电脑上用Xshell6登录的，您可以选用任意SSH终端工具，账号密码就是能登录群晖的账号密码，如下图，登录后，就可以使用日常的linux命令了：&lt;br/&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/485422/202012/485422-20201219075627609-2136802331.png&quot; alt=&quot;在这里插入图片描述&quot; loading=&quot;lazy&quot;/&gt;&lt;/li&gt;
&lt;li&gt;注意上图的红框，登录账号的home目录是&lt;span&gt;/var/services/homes/zq2599&lt;/span&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;h3 id=&quot;部署harbor&quot;&gt;部署harbor&lt;/h3&gt;
&lt;ol&gt;&lt;li&gt;执行以下脚本，创建必要目录并且下载和解压harbor安装包：&lt;/li&gt;
&lt;/ol&gt;&lt;pre&gt;
&lt;code class=&quot;language-shell&quot;&gt;mkdir ~/harbor-1.10.3 \
&amp;amp;&amp;amp; mkdir ~/harbor-1.10.3/log \
&amp;amp;&amp;amp; mkdir ~/harbor-1.10.3/data \
&amp;amp;&amp;amp; mkdir ~/harbor-1.10.3/data/secret \
&amp;amp;&amp;amp; cd ~/harbor-1.10.3 \
&amp;amp;&amp;amp; wget https://github.com/goharbor/harbor/releases/download/v1.10.3/harbor-online-installer-v1.10.3.tgz \
&amp;amp;&amp;amp; tar -zxvf harbor-online-installer-v1.10.3.tgz \
&amp;amp;&amp;amp; mkdir -p ~/harbor-1.10.3/harbor/common/config
&lt;/code&gt;
&lt;/pre&gt;
&lt;ol start=&quot;2&quot;&gt;&lt;li&gt;打开文件&lt;span&gt;~/harbor-1.10.3/harbor/harbor.yml&lt;/span&gt;，有以下几处需要修改；&lt;/li&gt;
&lt;li&gt;修改&lt;span&gt;hostname&lt;/span&gt;，如果有域名就用域名，否则改成IP地址：&lt;br/&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/485422/202012/485422-20201219075627953-2061683425.png&quot; alt=&quot;在这里插入图片描述&quot; loading=&quot;lazy&quot;/&gt;&lt;/li&gt;
&lt;li&gt;选一个没有占用的端口作为http端口，这里我用的是&lt;span&gt;5888&lt;/span&gt;&lt;br/&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/485422/202012/485422-20201219075628304-2022013833.png&quot; alt=&quot;在这里插入图片描述&quot; loading=&quot;lazy&quot;/&gt;&lt;/li&gt;
&lt;li&gt;如果不打算使用https，就要注释所有https的配置：&lt;br/&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/485422/202012/485422-20201219075629449-1702912593.png&quot; alt=&quot;在这里插入图片描述&quot; loading=&quot;lazy&quot;/&gt;&lt;/li&gt;
&lt;li&gt;修改存储数据的位置，注意&lt;span&gt;/var/services/homes/zq2599&lt;/span&gt;是当前账号的home目录：&lt;br/&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/485422/202012/485422-20201219075629973-435153107.png&quot; alt=&quot;在这里插入图片描述&quot; loading=&quot;lazy&quot;/&gt;&lt;/li&gt;
&lt;li&gt;修改日志存储路径，这个文件夹之前就创建好了：&lt;br/&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/485422/202012/485422-20201219075630872-1234967061.png&quot; alt=&quot;在这里插入图片描述&quot; loading=&quot;lazy&quot;/&gt;&lt;/li&gt;
&lt;li&gt;修改配置完毕，保存；&lt;/li&gt;
&lt;li&gt;执行准备命令：&lt;/li&gt;
&lt;/ol&gt;&lt;pre&gt;
&lt;code class=&quot;language-shell&quot;&gt;cd ~/harbor-1.10.3/harbor \
&amp;amp;&amp;amp; sudo ./prepare
&lt;/code&gt;
&lt;/pre&gt;
&lt;ol start=&quot;10&quot;&gt;&lt;li&gt;开始安装：&lt;/li&gt;
&lt;/ol&gt;&lt;pre&gt;
&lt;code class=&quot;language-shell&quot;&gt;cd ~/harbor-1.10.3/harbor \
&amp;amp;&amp;amp; sudo ./install.sh
&lt;/code&gt;
&lt;/pre&gt;
&lt;ol start=&quot;11&quot;&gt;&lt;li&gt;操作成功的控制台输出如下：&lt;br/&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/485422/202012/485422-20201219075631698-950533533.png&quot; alt=&quot;在这里插入图片描述&quot; loading=&quot;lazy&quot;/&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;h3 id=&quot;浏览器登录harbor&quot;&gt;浏览器登录harbor&lt;/h3&gt;
&lt;ol&gt;&lt;li&gt;打开浏览器，访问地址&lt;a href=&quot;http://192.168.50.43:5888&quot; target=&quot;_blank&quot;&gt;&lt;span&gt;http://192.168.50.43:5888&lt;/span&gt;&lt;/a&gt; ，账号&lt;span&gt;admin&lt;/span&gt;，密码&lt;span&gt;Harbor12345&lt;/span&gt;&lt;br/&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/485422/202012/485422-20201219075632153-1229996217.png&quot; alt=&quot;在这里插入图片描述&quot; loading=&quot;lazy&quot;/&gt;&lt;/li&gt;
&lt;li&gt;登录成功如下图，群晖空间还是很充裕的：&lt;br/&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/485422/202012/485422-20201219075632719-998088409.png&quot; alt=&quot;在这里插入图片描述&quot; loading=&quot;lazy&quot;/&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;h3 id=&quot;使用harbor&quot;&gt;使用harbor&lt;/h3&gt;
&lt;ol&gt;&lt;li&gt;接下来的操作是从另一台Linux电脑（下面称之为A电脑）远程推送镜像到harbor机器；&lt;/li&gt;
&lt;li&gt;如果要从A电脑连接harbor服务器，那么要对A电脑做设置，我这里A电脑是Linux操作系统；&lt;/li&gt;
&lt;li&gt;编辑A电脑的&lt;span&gt;/etc/docker/daemon.json&lt;/span&gt;文件(如果不存在就新建)，增加下图红框中的内容，&lt;span&gt;192.168.50.43&lt;/span&gt;是harbor服务器的IP地址，&lt;span&gt;5888&lt;/span&gt;是前面配置的http端口：&lt;br/&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/485422/202012/485422-20201219075633473-1348468280.png&quot; alt=&quot;在这里插入图片描述&quot; loading=&quot;lazy&quot;/&gt;&lt;/li&gt;
&lt;li&gt;重启docker服务使配置生效：&lt;/li&gt;
&lt;/ol&gt;&lt;pre&gt;
&lt;code class=&quot;language-shell&quot;&gt;systemctl daemon-reload \
&amp;amp;&amp;amp; systemctl restart docker
&lt;/code&gt;
&lt;/pre&gt;
&lt;ol start=&quot;5&quot;&gt;&lt;li&gt;再次提醒：&lt;span&gt;这里修改是远程连接Harbor服务的机器的配置，而不是Harbor服务器的配置&lt;/span&gt;；&lt;/li&gt;
&lt;li&gt;在A电脑上，有个nginx镜像，id是&lt;span&gt;2622e6cca7eb&lt;/span&gt;，如下图所示：&lt;br/&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/485422/202012/485422-20201219075633860-1839445682.png&quot; alt=&quot;在这里插入图片描述&quot; loading=&quot;lazy&quot;/&gt;&lt;/li&gt;
&lt;li&gt;按照dockr镜像仓库规则给镜像打tag：&lt;/li&gt;
&lt;/ol&gt;&lt;pre&gt;
&lt;code class=&quot;language-shell&quot;&gt;docker tag 2622e6cca7eb 192.168.50.43:5888/library/nginx:latest
&lt;/code&gt;
&lt;/pre&gt;
&lt;ol start=&quot;8&quot;&gt;&lt;li&gt;现在是同一个ID的镜像，但是有两个tag：&lt;br/&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/485422/202012/485422-20201219075634466-14053185.png&quot; alt=&quot;在这里插入图片描述&quot; loading=&quot;lazy&quot;/&gt;&lt;/li&gt;
&lt;li&gt;登录harbor：&lt;/li&gt;
&lt;/ol&gt;&lt;pre&gt;
&lt;code class=&quot;language-shell&quot;&gt;docker login 192.168.50.43:5888 -u admin -p Harbor12345
&lt;/code&gt;
&lt;/pre&gt;
&lt;ol start=&quot;10&quot;&gt;&lt;li&gt;推送镜像到harbor：&lt;/li&gt;
&lt;/ol&gt;&lt;pre&gt;
&lt;code class=&quot;language-shell&quot;&gt;docker push 192.168.50.43:5888/library/nginx:latest
&lt;/code&gt;
&lt;/pre&gt;
&lt;ol start=&quot;11&quot;&gt;&lt;li&gt;操作成功：&lt;br/&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/485422/202012/485422-20201219075635173-489017882.png&quot; alt=&quot;在这里插入图片描述&quot; loading=&quot;lazy&quot;/&gt;&lt;/li&gt;
&lt;li&gt;推送成功后，在浏览器页面可见此镜像：&lt;br/&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/485422/202012/485422-20201219075635629-864979713.png&quot; alt=&quot;在这里插入图片描述&quot; loading=&quot;lazy&quot;/&gt;&lt;/li&gt;
&lt;li&gt;新建仓库的操作如下所示：&lt;br/&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/485422/202012/485422-20201219075635931-1346377493.png&quot; alt=&quot;在这里插入图片描述&quot; loading=&quot;lazy&quot;/&gt;&lt;/li&gt;
&lt;li&gt;创建成功：&lt;br/&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/485422/202012/485422-20201219075636205-625308722.png&quot; alt=&quot;在这里插入图片描述&quot; loading=&quot;lazy&quot;/&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;h3 id=&quot;卸载harbor&quot;&gt;卸载harbor&lt;/h3&gt;
&lt;ol&gt;&lt;li&gt;如果您不需要harbor了，执行以下命令即可：&lt;/li&gt;
&lt;/ol&gt;&lt;pre&gt;
&lt;code class=&quot;language-shell&quot;&gt;cd ~/harbor-1.10.3/harbor \
&amp;amp;&amp;amp; sudo docker-compose down
&lt;/code&gt;
&lt;/pre&gt;
&lt;ol start=&quot;2&quot;&gt;&lt;li&gt;再删除整个~/harbor-1.10.3目录即可，注意&lt;span&gt;所有数据都会清除掉&lt;/span&gt;；&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;至此，群晖DS218+部署和验证harbor的操作就完成了，希望能带给您一些参考；&lt;/p&gt;
&lt;h3 id=&quot;你不孤单，欣宸原创一路相伴&quot;&gt;你不孤单，欣宸原创一路相伴&lt;/h3&gt;
&lt;ol&gt;&lt;li&gt;&lt;a href=&quot;https://xinchen.blog.csdn.net/article/details/105068742&quot; target=&quot;_blank&quot;&gt;Java系列&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://xinchen.blog.csdn.net/article/details/105086498&quot; target=&quot;_blank&quot;&gt;Spring系列&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://xinchen.blog.csdn.net/article/details/105086732&quot; target=&quot;_blank&quot;&gt;Docker系列&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://xinchen.blog.csdn.net/article/details/105086794&quot; target=&quot;_blank&quot;&gt;kubernetes系列&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://xinchen.blog.csdn.net/article/details/105086850&quot; target=&quot;_blank&quot;&gt;数据库+中间件系列&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://xinchen.blog.csdn.net/article/details/105086920&quot; target=&quot;_blank&quot;&gt;DevOps系列&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;h3 id=&quot;欢迎关注公众号：程序员欣宸&quot;&gt;欢迎关注公众号：程序员欣宸&lt;/h3&gt;
&lt;blockquote readability=&quot;4.258064516129&quot;&gt;
&lt;p&gt;微信搜索「程序员欣宸」，我是欣宸，期待与您一同畅游Java世界...&lt;br/&gt;&lt;a href=&quot;https://github.com/zq2599/blog_demos&quot; target=&quot;_blank&quot;&gt;https://github.com/zq2599/blog_demos&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
</description>
<pubDate>Fri, 18 Dec 2020 23:57:00 +0000</pubDate>
<dc:creator>程序员欣宸</dc:creator>
<og:description>欢迎访问我的GitHub https://github.com/zq2599/blog_demos 内容：所有原创文章分类汇总及配套源码，涉及Java、Docker、Kubernetes、DevOPS</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/bolingcavalry/p/14157932.html</dc:identifier>
</item>
<item>
<title>冰河，能不能讲讲如何实现MySQL数据存储的无限扩容？ - 冰河团队</title>
<link>http://www.cnblogs.com/binghe001/p/14157880.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/binghe001/p/14157880.html</guid>
<description>&lt;h2 id=&quot;写在前面&quot;&gt;写在前面&lt;/h2&gt;
&lt;blockquote readability=&quot;9.4164086687307&quot;&gt;
&lt;p&gt;随着互联网的高速发展，企业中沉淀的数据也越来越多，这就对数据存储层的扩展性要求越来越高。当今互联网企业中，大部分企业使用的是MySQL来存储关系型数据。如何实现MySQL数据存储层的高度可扩展性成为了互联网企业必须要解决的问题。那么，如何实现真正意义上的MySQL无限扩容呢？今天，冰河就来以实战的角度为大家讲讲如何实现MySQL数据库的无限扩容。&lt;/p&gt;
&lt;p&gt;文章已收录到：&lt;a href=&quot;https://github.com/sunshinelyz/technology-binghe&quot; target=&quot;_blank&quot;&gt;https://github.com/sunshinelyz/technology-binghe&lt;/a&gt; 和 &lt;a href=&quot;https://gitee.com/binghe001/technology-binghe&quot; target=&quot;_blank&quot;&gt;https://gitee.com/binghe001/technology-binghe&lt;/a&gt;，小伙伴们别忘记给个小星星哦~~&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;概述&quot;&gt;概述&lt;/h2&gt;
&lt;p&gt;本文是在《&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=Mzg4MjU0OTM1OA==&amp;amp;mid=2247489096&amp;amp;idx=1&amp;amp;sn=1be285069a2153f494a81dc5f9aef708&amp;amp;chksm=cf55a149f822285f487b47a0bc5a0b421a14cf2dfd4ebdd8ae817167b5ffabe4f45676f65dca&amp;amp;token=420299024&amp;amp;lang=zh_CN#rd&quot; target=&quot;_blank&quot;&gt;海量数据架构下如何保证Mycat的高可用？&lt;/a&gt;》一文的基础上进一步扩展，从而实现数据存储层每一个环节的高可用，从而实现MySQL的无限扩容。&lt;/p&gt;
&lt;h2 id=&quot;要解决的问题&quot;&gt;要解决的问题&lt;/h2&gt;
&lt;p&gt;在《&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=Mzg4MjU0OTM1OA==&amp;amp;mid=2247489096&amp;amp;idx=1&amp;amp;sn=1be285069a2153f494a81dc5f9aef708&amp;amp;chksm=cf55a149f822285f487b47a0bc5a0b421a14cf2dfd4ebdd8ae817167b5ffabe4f45676f65dca&amp;amp;token=420299024&amp;amp;lang=zh_CN#rd&quot; target=&quot;_blank&quot;&gt;海量数据架构下如何保证Mycat的高可用？&lt;/a&gt;》一文中，我们的架构图如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20201219015335645.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;由上图可以看出，HAProxy存在单点隐患，一旦这个HAProxy服务宕机，那么整个服务架构将不可用。那么，如何解决HAProxy存在的单点隐患问题呢？这就是这篇博文要解决的问题。&lt;/p&gt;
&lt;h2 id=&quot;软件版本&quot;&gt;软件版本&lt;/h2&gt;
&lt;ul&gt;&lt;li&gt;操作系统：CentOS-6.8-x86_64&lt;/li&gt;
&lt;li&gt;JDK版本：jdk1.8&lt;/li&gt;
&lt;li&gt;HAProxy版本：haproxy-1.5.19.tar.gz&lt;/li&gt;
&lt;li&gt;Mycat版本：Mycat-server-1.6(自行下载源码编译)&lt;/li&gt;
&lt;li&gt;keepalived版本:keepalived-1.2.18.tar.gz&lt;/li&gt;
&lt;li&gt;MySQL版本：mysql-5.7.tar.gz&lt;/li&gt;
&lt;/ul&gt;&lt;h2 id=&quot;部署规划&quot;&gt;部署规划&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20201219015350478.png#pic_center&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h2 id=&quot;高可用负载均衡集群部署架构&quot;&gt;高可用负载均衡集群部署架构&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20201219015401828.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;上图中简化了数据存储部分的架构细节。例如，其中对于架构中的每一个部分，我们都可以单独进行扩展，独立成集群对外提供服务，而不会存在单点故障的问题。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;图解说明：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;(1) HAProxy 实现了 Mycat 多节点的集群高可用和负载均衡， 而 HAProxy 自身的高可用则可以通过Keepalived 来实现。 因此， HAProxy 主机上要同时安装 HAProxy 和 Keepalived， Keepalived 负责为该服务器抢占 vip（虚拟 ip，图中的 192.168.209.130），抢占到 vip 后，对该主机的访问可以通过原来的 ip（192.168.209.135）访问，也可以直接通过 vip（192.168.209.130）访问。&lt;/p&gt;
&lt;p&gt;(2) Keepalived 抢占 vip 有优先级， 在 keepalived.conf 配置中的 priority 属性决定。但是一般哪台主机上的 Keepalived服务先启动就会抢占到 vip，即使是 slave，只要先启动也能抢到（要注意避免 Keepalived的资源抢占问题）。&lt;/p&gt;
&lt;p&gt;(3) HAProxy 负责将对 vip 的请求分发到 Mycat 集群节点上， 起到负载均衡的作用。 同时 HAProxy 也能检测到 Mycat 是否存活， HAProxy 只会将请求转发到存活的 Mycat 上。&lt;/p&gt;
&lt;p&gt;(4) 如果 Keepalived+HAProxy 高可用集群中的一台服务器宕机， 集群中另外一台服务器上的 Keepalived会立刻抢占 vip 并接管服务， 此时抢占了 vip 的 HAProxy 节点可以继续提供服务。&lt;/p&gt;
&lt;p&gt;(5) 如果一台 Mycat 服务器宕机， HAPorxy 转发请求时不会转发到宕机的 Mycat 上，所以 Mycat 依然可用。&lt;/p&gt;
&lt;p&gt;综上： Mycat 的高可用及负载均衡由 HAProxy 来实现，而 HAProxy 的高可用，由 Keepalived 来实现。&lt;/p&gt;
&lt;h2 id=&quot;haproxy-节点-2-的部署&quot;&gt;HAProxy 节点 2 的部署&lt;/h2&gt;
&lt;p&gt;HAProxy 主机 2（liuyazhuang136, 192.168.209.136）的安装部署请参考博文《&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=Mzg4MjU0OTM1OA==&amp;amp;mid=2247489096&amp;amp;idx=1&amp;amp;sn=1be285069a2153f494a81dc5f9aef708&amp;amp;chksm=cf55a149f822285f487b47a0bc5a0b421a14cf2dfd4ebdd8ae817167b5ffabe4f45676f65dca&amp;amp;token=420299024&amp;amp;lang=zh_CN#rd&quot; target=&quot;_blank&quot;&gt;海量数据架构下如何保证Mycat的高可用？&lt;/a&gt;》，注意配置文件的调整：多节点部署时 haproxy.cfg 配置文件中的 node 、 description 配置的值要做相应调整。&lt;/p&gt;
&lt;p&gt;HAProxy 主机 2（liuyazhuang136, 192.168.209.136）上的HAProxy配置如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;## global配置中的参数为进程级别的参数，通常与其运行的操作系统有关

global

log 127.0.0.1 local0 info ## 定义全局的syslog服务器，最多可以定义2个

### local0是日志设备，对应于/etc/rsyslog.conf中的配置，默认回收info的日志级别

#log 127.0.0.1 local1 info

chroot /usr/share/haproxy ## 修改HAProxy的工作目录至指定的目录并在放弃权限之前执行

### chroot() 操作，可以提升 haproxy 的安全级别

group haproxy ## 同gid，不过这里为指定的用户组名

user haproxy ## 同uid，但这里使用的为用户名

daemon ## 设置haproxy后台守护进程形式运行

nbproc 1 ## 指定启动的haproxy进程个数，

### 只能用于守护进程模式的haproxy；默认为止启动1个进程，

### 一般只在单进程仅能打开少数文件描述符的场中中才使用多进程模式

maxconn 4096 ## 设定每个haproxy进程所接受的最大并发连接数，

### 其等同于命令行选项&quot;-n&quot;，&quot;ulimit-n&quot;自动计算的结果正式参照从参数设定的

# pidfile /var/run/haproxy.pid ## 进程文件（默认路径 /var/run/haproxy.pid）

node liuyazhuang136 ## 定义当前节点的名称，用于HA场景中多haproxy进程共享同一个IP地址时

description liuyazhuang136 ## 当前实例的描述信息

## defaults：用于为所有其他配置段提供默认参数，这默认配置参数可由下一个&quot;defaults&quot;所重新设定

defaults

log global ## 继承global中log的定义

mode http ## mode:所处理的模式 (tcp:四层 , http:七层 , health:状态检查,只会返回OK)

### tcp: 实例运行于纯tcp模式，在客户端和服务器端之间将建立一个全双工的连接，

#### 且不会对7层报文做任何类型的检查，此为默认模式

### http:实例运行于http模式，客户端请求在转发至后端服务器之前将被深度分析，

#### 所有不与RFC模式兼容的请求都会被拒绝

### health：实例运行于health模式，其对入站请求仅响应“OK”信息并关闭连接，

#### 且不会记录任何日志信息 ，此模式将用于相应外部组件的监控状态检测请求

option httplog

retries 3

option redispatch ## serverId对应的服务器挂掉后,强制定向到其他健康的服务器

maxconn 2000 ## 前端的最大并发连接数（默认为2000）

### 其不能用于backend区段，对于大型站点来说，可以尽可能提高此值以便让haproxy管理连接队列，

### 从而避免无法应答用户请求。当然，此最大值不能超过“global”段中的定义。

### 此外，需要留心的是，haproxy会为每个连接维持两个缓冲，每个缓存的大小为8KB，

### 再加上其他的数据，每个连接将大约占用17KB的RAM空间，这意味着经过适当优化后 ，

### 有着1GB的可用RAM空间时将维护40000-50000并发连接。

### 如果指定了一个过大值，极端场景中，其最终所占据的空间可能会超过当前主机的可用内存，

### 这可能会带来意想不到的结果，因此，将其设定一个可接受值放为明智绝对，其默认为2000

timeout connect 5000ms ## 连接超时(默认是毫秒,单位可以设置us,ms,s,m,h,d)

timeout client 50000ms ## 客户端超时

timeout server 50000ms ## 服务器超时

## HAProxy的状态信息统计页面

listen admin_stats

bind :48800 ## 绑定端口

stats uri /admin-status ##统计页面

stats auth admin:admin ## 设置统计页面认证的用户和密码，如果要设置多个，另起一行写入即可

mode http

option httplog ## 启用日志记录HTTP请求

## listen: 用于定义通过关联“前端”和“后端”一个完整的代理，通常只对TCP流量有用

listen mycat_servers

bind :3307 ## 绑定端口

mode tcp

option tcplog ## 记录TCP请求日志

option tcpka ## 是否允许向server和client发送keepalive

option httpchk OPTIONS * HTTP/1.1\r\nHost:\ www ## 后端服务状态检测

### 向后端服务器的48700端口（端口值在后端服务器上通过xinetd配置）发送 OPTIONS 请求

### (原理请参考HTTP协议) ，HAProxy会根据返回内容来判断后端服务是否可用.

### 2xx 和 3xx 的响应码表示健康状态，其他响应码或无响应表示服务器故障。

balance roundrobin ## 定义负载均衡算法，可用于&quot;defaults&quot;、&quot;listen&quot;和&quot;backend&quot;中,默认为轮询方式

server mycat_01 192.168.209.133:8066 check port 48700 inter 2000ms rise 2 fall 3 weight 10

server mycat_02 192.168.209.134:8066 check port 48700 inter 2000ms rise 2 fall 3 weight 10

## 格式：server &amp;lt;name&amp;gt; &amp;lt;address&amp;gt;[:[port]] [param*]

### serser 在后端声明一个server，只能用于listen和backend区段。

### &amp;lt;name&amp;gt;为此服务器指定的内部名称，其将会出现在日志及警告信息中

### &amp;lt;address&amp;gt;此服务器的IPv4地址，也支持使用可解析的主机名，但要在启动时需要解析主机名至响应的IPV4地址

### [:[port]]指定将客户端连接请求发往此服务器时的目标端口，此为可选项

### [param*]为此server设定的一系列参数，均为可选项，参数比较多，下面仅说明几个常用的参数：

#### weight:权重，默认为1，最大值为256，0表示不参与负载均衡

#### backup:设定为备用服务器，仅在负载均衡场景中的其他server均不可以启用此server

#### check:启动对此server执行监控状态检查，其可以借助于额外的其他参数完成更精细的设定

#### inter:设定监控状态检查的时间间隔，单位为毫秒，默认为2000，

##### 也可以使用fastinter和downinter来根据服务器端专题优化此事件延迟

#### rise:设置server从离线状态转换至正常状态需要检查的次数（不设置的情况下，默认值为2）

#### fall:设置server从正常状态转换至离线状态需要检查的次数（不设置的情况下，默认值为3）

#### cookie:为指定server设定cookie值，此处指定的值将会在请求入站时被检查，

##### 第一次为此值挑选的server将会被后续的请求所选中，其目的在于实现持久连接的功能

#### maxconn:指定此服务器接受的最大并发连接数，如果发往此服务器的连接数目高于此处指定的值，

#####其将被放置于请求队列，以等待其他连接被释放
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;HAProxy 节点 1 的状态信息页：&lt;a href=&quot;http://192.168.209.135:48800/admin-status&quot; target=&quot;_blank&quot;&gt;http://192.168.209.135:48800/admin-status&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20201219015441597.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;HAProxy 节点 2 的状态信息页：&lt;a href=&quot;http://192.168.209.136:48800/admin-status&quot; target=&quot;_blank&quot;&gt;http://192.168.209.136:48800/admin-status&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20201219015454795.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h2 id=&quot;keepalived-介绍&quot;&gt;Keepalived 介绍&lt;/h2&gt;
&lt;p&gt;官网： &lt;a href=&quot;http://www.keepalived.org/&quot; target=&quot;_blank&quot;&gt;http://www.keepalived.org/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Keepalived 是一种高性能的服务器高可用或热备解决方案， Keepalived 可以用来防止服务器单点故障的发生，通过配合 Haproxy 可以实现 web 前端服务的高可用。Keepalived 以 VRRP 协议为实现基础，用 VRRP 协议来实现高可用性(HA)。 VRRP(Virtual Router Redundancy Protocol)协议是用于实现路由器冗余的协议， VRRP 协议将两台或多台路由器设备虚拟成一个设备，对外提供虚拟路由器 IP(一个或多个)，而在路由器组内部，如果实际拥有这个对外 IP 的路由器如果工作正常的话就是 MASTER，或者是通过算法选举产生。 MASTER 实现针对虚拟路由器 IP 的各种网络功能，如 ARP 请求， ICMP，以及数据的转发等；其他设备不拥有该虚拟 IP，状态是 BACKUP，除了接收 MASTER 的VRRP 状态通告信息外，不执行对外的网络功能。当主机失效时， BACKUP 将接管原先 MASTER 的网络功能。VRRP 协议使用多播数据来传输 VRRP 数据， VRRP 数据使用特殊的虚拟源 MAC 地址发送数据而不是自身网卡的 MAC 地址， VRRP 运行时只有 MASTER 路由器定时发送 VRRP 通告信息，表示 MASTER 工作正常以及虚拟路由器 IP(组)， BACKUP 只接收 VRRP 数据，不发送数据，如果一定时间内没有接收到 MASTER 的通告信息，各 BACKUP 将宣告自己成为 MASTER，发送通告信息，重新进行 MASTER 选举状态。&lt;/p&gt;
&lt;h2 id=&quot;keepalived-的安装&quot;&gt;Keepalived 的安装&lt;/h2&gt;
&lt;p&gt;注意：需要在192.168.209.135、 192.168.209.136两台服务器上安装Keepalived。&lt;/p&gt;
&lt;p&gt;Keepalived （&lt;a href=&quot;http://www.keepalived.org/download.html&quot; target=&quot;_blank&quot;&gt;http://www.keepalived.org/download.html&lt;/a&gt; ）&lt;/p&gt;
&lt;h3 id=&quot;上传或下载-keepalived&quot;&gt;上传或下载 keepalived&lt;/h3&gt;
&lt;p&gt;上传或下载 keepalived（keepalived-1.2.18.tar.gz） 到 /usr/local/src 目录&lt;/p&gt;
&lt;h3 id=&quot;解压安装&quot;&gt;解压安装&lt;/h3&gt;
&lt;p&gt;安装 keepalived 需要用到 openssl&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;# yum install gcc gcc-c++ openssl openssl-devel
# cd /usr/local/src
# tar -zxvf keepalived-1.2.18.tar.gz
# cd keepalived-1.2.18
# ./configure --prefix=/usr/local/keepalived
# make &amp;amp;&amp;amp; make install
&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;将-keepalived-安装成-linux-系统服务&quot;&gt;将 keepalived 安装成 Linux 系统服务&lt;/h3&gt;
&lt;p&gt;因为没有使用 keepalived 的默认路径安装（默认是/usr/local） ,安装完成之后，需要做一些工作&lt;br/&gt;复制默认配置文件到默认路径&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;# mkdir /etc/keepalived
# cp /usr/local/keepalived/etc/keepalived/keepalived.conf /etc/keepalived/
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;复制 keepalived 服务脚本到默认的地址&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;# cp /usr/local/keepalived/etc/rc.d/init.d/keepalived /etc/init.d/
# cp /usr/local/keepalived/etc/sysconfig/keepalived /etc/sysconfig/
# ln -s /usr/local/keepalived/sbin/keepalived /usr/sbin/
# ln -s /usr/local/keepalived/sbin/keepalived /sbin/
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;设置 keepalived 服务开机启动&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;# chkconfig keepalived on
&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;修改-keepalived-配置文件&quot;&gt;修改 Keepalived 配置文件&lt;/h3&gt;
&lt;p&gt;(1) MASTER 节点配置文件（192.168.209.135）&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;! Configuration File for keepalived
global_defs {
## keepalived 自带的邮件提醒需要开启 sendmail 服务。建议用独立的监控或第三方 SMTP
        router_id liuyazhuang135 ## 标识本节点的字条串，通常为 hostname
}
## keepalived 会定时执行脚本并对脚本执行的结果进行分析，动态调整 vrrp_instance 的优先级。
## 如果脚本执行结果为 0，并且 weight 配置的值大于 0，则优先级相应的增加。
## 如果脚本执行结果非 0，并且 weight 配置的值小于 0，则优先级相应的减少。
## 其他情况，维持原本配置的优先级，即配置文件中 priority 对应的值。
vrrp_script chk_haproxy {
        script &quot;/etc/keepalived/haproxy_check.sh&quot; ## 检测 haproxy 状态的脚本路径
        interval 2 ## 检测时间间隔
        weight 2 ## 如果条件成立，权重+2
}
## 定义虚拟路由， VI_1 为虚拟路由的标示符，自己定义名称
vrrp_instance VI_1 {
        state BACKUP ## 默认主设备（priority 值大的）和备用设备（priority 值小的）都设置为 BACKUP，
        ## 由 priority 来控制同时启动情况下的默认主备，否则先启动的为主设备
        interface eth3 ## 绑定虚拟 IP 的网络接口，与本机 IP 地址所在的网络接口相同，我的是 eth3
        virtual_router_id 35 ## 虚拟路由的 ID 号，两个节点设置必须一样，可选 IP 最后一段使用,
        ## 相同的 VRID 为一个组，他将决定多播的 MAC 地址
        priority 120 ## 节点优先级，值范围 0-254， MASTER 要比 BACKUP 高
        nopreempt ## 主设备（priority 值大的）配置一定要加上 nopreempt，否则非抢占也不起作用
        advert_int 1 ## 组播信息发送间隔，两个节点设置必须一样，默认 1s
        ## 设置验证信息，两个节点必须一致
        authentication {
                auth_type PASS
                auth_pass 1111 ## 真实生产，按需求对应该过来
        }
        ## 将 track_script 块加入 instance 配置块
        track_script {
                chk_haproxy ## 检查 HAProxy 服务是否存活
        }
        ## 虚拟 IP 池, 两个节点设置必须一样
        virtual_ipaddress {
                192.168.209.130 ## 虚拟 ip，可以定义多个，每行一个
        }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;(2)BACKUP 节点配置文件（192.168.209.136）&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;! Configuration File for keepalived
global_defs {
        router_id liuyazhuang136
}
vrrp_script chk_haproxy {
        script &quot;/etc/keepalived/haproxy_check.sh&quot;
        interval 2
        weight 2
}
vrrp_instance VI_1 {
        state BACKUP
        interface eth3
        virtual_router_id 35
        priority 110
        advert_int 1
        authentication {
                auth_type PASS
                auth_pass 1111
        }
        track_script {
                chk_haproxy
        }
        virtual_ipaddress {
                192.168.209.130
        }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;特别注意： 如果非抢占模式不生效， 在 Keepalived 的故障节点恢复后会再次导抢占 vip，从而因 vip 切换而闪断带来的风险（视频解说）。 按以上配置，配置了 Keepalived 非抢占模式， 配置及注意点如下：&lt;br/&gt;(1) 主设备、 从设备中的 state 都设置为 BACKUP&lt;br/&gt;(2) 主设备、从设备中都不要配置 mcast_src_ip （本机 IP 地址）&lt;br/&gt;(3) 默认主设备（priority 值大的 Keepalived 节点） 配置一定要加上 nopreempt，否则非抢占不起作用&lt;br/&gt;(4) 防火墙配置允许组播（主、备两台设备上都需要配置， keepalived 使用 224.0.0.18 作为 Master 和Backup 健康检查的通信 IP）&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;# iptables -I INPUT -i eth3 -d 224.0.0.0/8 -p vrrp -j ACCEPT
# iptables -I OUTPUT -o eth3 -d 224.0.0.0/8 -p vrrp -j ACCEPT
（eth3 为主机的网卡设备名称，生产环境服务器可以用独立网卡来处理组播和心跳检测等）
# service iptables save
重启防火墙：
# service iptables restart
&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;编写-haproxy-状态检测脚本&quot;&gt;编写 Haproxy 状态检测脚本&lt;/h3&gt;
&lt;p&gt;我们编写的脚本为/etc/keepalived/haproxy_check.sh (已在 keepalived.conf 中配置)&lt;br/&gt;脚本要求：如果 haproxy 停止运行，尝试启动，如果无法启动则杀死本机的 keepalived 进程，keepalied将虚拟 ip 绑定到 BACKUP 机器上。&lt;/p&gt;
&lt;p&gt;内容如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;# mkdir -p /usr/local/keepalived/log
# vi /etc/keepalived/haproxy_check.sh
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;haproxy_check.sh脚本内容如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;#!/bin/bash
START_HAPROXY=&quot;/etc/rc.d/init.d/haproxy start&quot;
STOP_HAPROXY=&quot;/etc/rc.d/init.d/haproxy stop&quot;
LOG_FILE=&quot;/usr/local/keepalived/log/haproxy-check.log&quot;
HAPS=`ps -C haproxy --no-header |wc -l`
date &quot;+%Y-%m-%d %H:%M:%S&quot; &amp;gt;&amp;gt; $LOG_FILE
echo &quot;check haproxy status&quot; &amp;gt;&amp;gt; $LOG_FILE
if [ $HAPS -eq 0 ];then
echo $START_HAPROXY &amp;gt;&amp;gt; $LOG_FILE
$START_HAPROXY &amp;gt;&amp;gt; $LOG_FILE 2&amp;gt;&amp;amp;1
sleep 3
if [ `ps -C haproxy --no-header |wc -l` -eq 0 ];then
echo &quot;start haproxy failed, killall keepalived&quot; &amp;gt;&amp;gt; $LOG_FILE
killall keepalived
fi
fi
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;保存后，给脚本赋执行权限：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;# chmod +x /etc/keepalived/haproxy_check.sh
&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;启动-keepalived&quot;&gt;启动 Keepalived&lt;/h3&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;# service keepalived start
Starting keepalived: [ OK ]
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;Keepalived 服务管理命令：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;停止： service keepalived stop
启动： service keepalived start
重启： service keepalived restart
查看状态： service keepalived status
&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;高可用测试&quot;&gt;高可用测试&lt;/h2&gt;
&lt;p&gt;（1）关闭 192.168.209.135 中的 Haproxy， Keepalived 会将它重新启动&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;# service haproxy stop
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/2020121901550868.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;（2）关闭 192.168.209.135 中的 Keepalived， VIP（192.168.209.130） 会被 192.168.209.136 抢占&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;# service keepalived stop
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20201219015521467.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;由上图可知：Keepalived 停止后， 192.168.209.135 节点的网络接口中的 VIP（192.168.209.130） 将消失&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20201219015530977.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;此时，由上图可知：在192.168.209.136节点的网络接口中会出现 VIP（192.168.209.130）。&lt;/p&gt;
&lt;p&gt;查看此时 VIP 对应的 MAC， Windows 下使用 CMD 命令查看：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20201219015542336.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;说明此时 VIP 已经漂移到物理主机 192.168.209.136上了&lt;/p&gt;
&lt;p&gt;再通过 VIP(192.168.209.130) 来访问 Haproxy 集群， 访问到的也是 192.168.209.136&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20201219015554588.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20201219015606235.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;（3）重新启动 192.168.209.135 中的 Keepalived&lt;/p&gt;
&lt;p&gt;重新启动 192.168.209.135 中的 Keepalived， vip（192.168.209.130）保留在 192.168.209.136 主机上， 不会出现 135 启动抢占 vip 的情况。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;# service keepalived start
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/2020121901561860.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;（4）模拟抢占了 vip 的节点（192.168.209.136） 中的 HAProxy 故障或启动失败&lt;/p&gt;
&lt;p&gt;方式：把 192 节点中的 haproxy.cfg 文件重命名为 haproxy.cfg_bak， 并把 haproxy 服务进行 kill 掉，此时 keepalived 会尝试去启动 haproxy，会由于找不到配置文件而启动失败，此时就会进行 haproxy_check.sh脚本中的 killall keepalived 命令，结束 keepalived 进行。随后就是 192.168.209.135 节点重新抢占 vip&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/2020121901562941.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;说明此时 VIP 已经漂移到物理主机 192.168.209.135上了&lt;/p&gt;
&lt;p&gt;再通过 VIP(192.168.209.130) 来访问 Haproxy 集群， 访问到的也是 192.168.209.135&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20201219015642146.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/2020121901565499.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h2 id=&quot;验证数据库访问&quot;&gt;验证数据库访问&lt;/h2&gt;
&lt;p&gt;通过 vip 访问数据库、验证 vip 切换后的数据库访问&lt;/p&gt;
&lt;p&gt;（1）命令行访问数据库&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20201219015704330.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;（2）Navicat访问数据库&lt;br/&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20201219015714448.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/2020121901572468.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;至此，Mycat高可用负载均衡集群的实现（HAProxy + Keepalived + Mycat）搭建完毕&lt;/p&gt;
&lt;p&gt;大家可以到链接&lt;a href=&quot;http://download.csdn.net/detail/l1028386804/9915621&quot; target=&quot;_blank&quot;&gt;http://download.csdn.net/detail/l1028386804/9915621&lt;/a&gt;下载搭建Mycat高可用负载均衡集群的实现（HAProxy + Keepalived + Mycat）使用的Keepalived&lt;/p&gt;
&lt;h2 id=&quot;其他推荐文章&quot;&gt;其他推荐文章&lt;/h2&gt;
&lt;h2 id=&quot;重磅福利&quot;&gt;重磅福利&lt;/h2&gt;
&lt;p&gt;微信搜一搜【冰河技术】微信公众号，关注这个有深度的程序员，每天阅读超硬核技术干货，公众号内回复【PDF】有我准备的一线大厂面试资料和我原创的超硬核PDF技术文档，以及我为大家精心准备的多套简历模板（不断更新中），希望大家都能找到心仪的工作，学习是一条时而郁郁寡欢，时而开怀大笑的路，加油。如果你通过努力成功进入到了心仪的公司，一定不要懈怠放松，职场成长和新技术学习一样，不进则退。如果有幸我们江湖再见！&lt;/p&gt;
&lt;p&gt;另外，我开源的各个PDF，后续我都会持续更新和维护，感谢大家长期以来对冰河的支持！！&lt;/p&gt;
</description>
<pubDate>Fri, 18 Dec 2020 18:04:00 +0000</pubDate>
<dc:creator>冰河团队</dc:creator>
<og:description>写在前面 随着互联网的高速发展，企业中沉淀的数据也越来越多，这就对数据存储层的扩展性要求越来越高。当今互联网企业中，大部分企业使用的是MySQL来存储关系型数据。如何实现MySQL数据存储层的高度可扩</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/binghe001/p/14157880.html</dc:identifier>
</item>
<item>
<title>防卒指南：996+健身≈猝死 - CaiYongji</title>
<link>http://www.cnblogs.com/takeurhand/p/14157861.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/takeurhand/p/14157861.html</guid>
<description>&lt;p&gt;刚刚看了条新闻，像聊家常似的说两句。希望程序员的心脏能永远“&lt;strong&gt;跳动&lt;/strong&gt;”，指尖的“&lt;strong&gt;字节&lt;/strong&gt;”能永远流淌。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;聊聊猝死。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;我试着在中文语境下找一些资料来佐证我标题的观点，“运动能锻炼身体的原理”。可惜只能搜到各种健身指南、健身技巧。显然，健身市场很红火， 这些关键字都被买断了。我只能做一些不那么严谨的论证。&lt;/p&gt;
&lt;p&gt;在我看来，&lt;strong&gt;锻炼是对身体的适当惩罚以达到身体机能补偿的过程。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;人类在自然界中生存，物竞天择，我们的身体已经做出了选择。当你总是在奔跑，就奖励你腿部发达的肌肉。当你总是在举重，就奖励你手臂发达的肌肉。但这里有一个借和还的过程。你消耗一定的身体机能再通过自身的调节收获更强大的机能的过程。有借有还，连本带利。&lt;/p&gt;
&lt;p&gt;这很公平。但如果你借不出了呢？我是说，你的身体无法承受一次&lt;strong&gt;惩罚&lt;/strong&gt;来获得更大的收益。你的机能无法再&lt;strong&gt;透支&lt;/strong&gt;以获得更多肌肉增长。&lt;/p&gt;
&lt;p&gt;我想，这就是猝死的根本。&lt;/p&gt;
&lt;p&gt;有人是这样证明世界上没有最大的数的。假设一个最大的数为M，那么，M+1一定大于M。前后矛盾，所以不存在最大的数。这是数学上的真理，但是，有一个词叫”枯竭“，有一个词叫”耗尽“，有一个词叫”绝迹“。它们的意思是，一点点都没有，一点点都不剩。我们总是以为我们有无数个明天，总以为自己再熬一熬，挺一挺什么都会过去。&lt;/p&gt;
&lt;p&gt;可是，总有人没有明天。总有人再多一分的钱都拿不出来。总有人再多一分力气都使不出来。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;这时就耗尽了！就榨干了！&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;一丝不剩的那种。&lt;/p&gt;
&lt;p&gt;我刚看了三篇文章，《为什么睡眠是让身体更好的第一要务》、《劳累时应该运动吗？》、《精疲力竭时应该运动吗？》，分别对应下面三个链接。&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.shape.com/lifestyle/mind-and-body/why-sleep-no-1-most-important-thing-better-body&quot; target=&quot;_blank&quot;&gt;Why Sleep Is the No. 1 Most Important Thing for a Better Body&lt;/a&gt;&lt;br/&gt;&lt;a href=&quot;https://www.sparkpeople.com/resource/fitness_articles.asp?id=2298&quot; target=&quot;_blank&quot;&gt;Should You Exercise When You're Tired?&lt;/a&gt;&lt;br/&gt;&lt;a href=&quot;https://www.livestrong.com/article/466754-should-i-exercise-when-im-exhausted/&quot; target=&quot;_blank&quot;&gt;Should I Exercise When I'm Exhausted?&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;其中提到，&lt;strong&gt;精疲力尽时锻炼是很危险的，因为身体机能的下降，你会因反应慢而受伤并且会损伤免疫系统。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;所以，当我们疲惫时就必须休息。这是现代人类文明早就约定了的。就算别人忘了，自己也不能忘。&lt;/p&gt;
&lt;blockquote&gt;
&lt;h4 id=&quot;当你疲倦时，你要休息，不要锻炼！健身要在睡眠充足，休息充分时进行。&quot;&gt;当你疲倦时，你要休息，不要锻炼！健身要在睡眠充足，休息充分时进行。&lt;/h4&gt;
&lt;/blockquote&gt;
&lt;p&gt;大家加班就加班，加完班就回家睡觉。这时候睡觉是对你身体最好的选择。既然选择了996就别在加完班后挑战身体的极限了。当你成功挑战了自己身体的极限，你也就看不见第二天的太阳了。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;有时候没时间就是没时间，挤也挤不出来！&lt;/strong&gt; 你挤出来的时间也是靠透支身体的休息换来的，你还要继续透支你的身体来”&lt;strong&gt;锻炼&lt;/strong&gt;“，就有点对自己太狠了。年纪轻时也许没事，但哪有人能一直年轻呢？&lt;/p&gt;
&lt;p&gt;不要总跟自己的身体较劲，人的精力终究是有限的。假设你一生的精力总值是M，你永远无法透支M+1。这个世界不是冷冰冰的数学驱动的，再NB的数学也是为我们这些朴素的屁民服务的。爱自己，爱生活。&lt;strong&gt;在你的家人眼里，你不是一颗小草，不是一朵浪花，你是永不倒下的山峰！&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;当996和健身不可兼得，就不要强求了。&lt;/p&gt;
&lt;p&gt;欢迎大家关注我【caiyongji】，同时本文同步更新于我的个人博客&lt;a href=&quot;http://blog.caiyongji.com/&quot; target=&quot;_blank&quot;&gt;http://blog.caiyongji.com/&lt;/a&gt;&lt;/p&gt;
</description>
<pubDate>Fri, 18 Dec 2020 17:30:00 +0000</pubDate>
<dc:creator>CaiYongji</dc:creator>
<og:description>刚刚看了条新闻，像聊家常似的说两句。希望程序员的心脏能永远“跳动”，指尖的“字节”能永远流淌。 聊聊猝死。 我试着在中文语境下找一些资料来佐证我标题的观点，“运动能锻炼身体的原理”。可惜只能搜到各种健</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/takeurhand/p/14157861.html</dc:identifier>
</item>
<item>
<title>图像处理论文详解 | Deformable Convolutional Networks | CVPR | 2017 - 忽逢桃林</title>
<link>http://www.cnblogs.com/PythonLearner/p/14157773.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/PythonLearner/p/14157773.html</guid>
<description>&lt;p&gt;文章转自同一作者的微信公众号：【机器学习炼丹术】&lt;/p&gt;
&lt;h2 id=&quot;0-前言&quot;&gt;0 前言&lt;/h2&gt;
&lt;p&gt;首先理解：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;deformable Convolution可变卷积针对的对象是卷积本身，因此膨胀卷积，3D卷积都可以用可变卷积的形式&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;本篇文章讲解理论和论文，我还没有用上这个可变卷积测试效果，因为PyTorch好像还没有封装这个卷积方式，有点麻烦。所以我计划下一篇文章结合github上已经有的pytorch复现的可变卷积来做一个简单的测试。&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;本来我是在学轮廓检测算法的，看到了一个SOTA的算法叫做deep snake，然后看了半天代码，发现里面嵌套了DCN，DLA等多个算法，所以就从头开始学了。&lt;/li&gt;
&lt;/ul&gt;&lt;h2 id=&quot;1-论文概述&quot;&gt;1 论文概述&lt;/h2&gt;
&lt;p&gt;论文中作者最大的贡献为：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;提出了可变卷积，可变卷积网络为Deformable ConvNet（DCN）。&lt;/li&gt;
&lt;li&gt;用同样的原理提出了可变池化层，叫做deformable ROI pooling。&lt;/li&gt;
&lt;li&gt;这两个模块可以非常简单的用在其他网络结构中，并且不会增加很多的参数，但是效果还是不错的。（论文把这个方法用在了主流模型中）。&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;&lt;strong&gt;这个核心贡献在于，为什么卷积过程中卷积核一定要是正方形的？我的检测目标各种形状都有，为什么卷积核一定要是正方形的呢？&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;因此，这里的卷积核不再是正方形了，而是可以通过梯度下降更新的参数了：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/img_convert/013b2a852f96e9cc629b19dda770b245.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;a图就是最基本的卷积核，b就是可变卷积的卷积核，c和d是可变卷积的特殊情况。听起来不难吧，原理确实非常的简单。&lt;/p&gt;
&lt;h2 id=&quot;2-实现原理&quot;&gt;2 实现原理&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/img_convert/ac245ae7c3b3aef10ef781b99d104249.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;上图是表示可变卷积过程的。大概看一眼这个图，不难发现这种结构似乎和SEnet有点类似。在下一篇的代码实战中再考虑如何实现这个过程把。&lt;/p&gt;
&lt;p&gt;泛泛地说的话，就是这个特征图，再额外的经过一个卷积层，生成一个offset的结果，然后把这个offset和这个特征图融合。&lt;/p&gt;
&lt;h2 id=&quot;3-实验结果&quot;&gt;3 实验结果&lt;/h2&gt;
&lt;p&gt;论文中提到，在特征提取网络的后面3层使用可变卷积的效果比较好。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/img_convert/a087d5a145966b36e63b049543bcdfa6.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;上图是在实际任务中，deformable convnets学习到的采样点，我认为这是一种非常有意思的可解释性的体现。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/img_convert/8916180e43e236f8a5c733fa9f8e736d.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;上表中最后三行体现了这个可变卷积的效果，确实是不错，确实有一定提升，那么这种可变卷积对与参数量的影响大吗？&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/img_convert/8a38dd295bcfe51248d77a571103c71e.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;可以看到，这个参数的影戏那个微乎其微，运行时间也基本差不多。我决定等我复现了这个可变卷积之后，我在以后的模型中都要用这个试试能不能有提升。（奇怪的奇技淫巧又增加了）。&lt;/p&gt;
&lt;p&gt;大概就这么多，从理论上看，这个deformable convolution不难，关键是如何实现，希望我在复现的过程上不会太坎坷。&lt;/p&gt;
&lt;p&gt;参考文章：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1703.06211&quot; target=&quot;_blank&quot;&gt;https://arxiv.org/abs/1703.06211&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://littletomatodonkey.github.io/2018/12/02/2018-12-02-Deformable%20ConvNets/&quot; target=&quot;_blank&quot;&gt;https://littletomatodonkey.github.io/2018/12/02/2018-12-02-Deformable ConvNets/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/52476083&quot; target=&quot;_blank&quot;&gt;https://zhuanlan.zhihu.com/p/52476083&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;</description>
<pubDate>Fri, 18 Dec 2020 16:31:00 +0000</pubDate>
<dc:creator>忽逢桃林</dc:creator>
<og:description>文章转自同一作者的微信公众号：【机器学习炼丹术】 论文名称：“Deformable Convolutional Networks” 论文链接：https://arxiv.org/abs/1703.06</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/PythonLearner/p/14157773.html</dc:identifier>
</item>
<item>
<title>容器编排系统之DaemonSet、Job和CronJob控制器 - Linux-1874</title>
<link>http://www.cnblogs.com/qiuhom-1874/p/14157306.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/qiuhom-1874/p/14157306.html</guid>
<description>&lt;p&gt;　　前文我们了解了k8s上的pod控制器中的常用的两种控制器ReplicaSet和Deployment控制器的相关话题，回顾请参考：&lt;a href=&quot;https://www.cnblogs.com/qiuhom-1874/p/14149042.html&quot; target=&quot;_blank&quot;&gt;https://www.cnblogs.com/qiuhom-1874/p/14149042.html&lt;/a&gt;；今天我们来了解下DaemonSet、Job和CronJob控制器相关话题；&lt;/p&gt;
&lt;p&gt;　　1、DaemonSet控制&lt;/p&gt;
&lt;p&gt;　　从名字上就可以看出这个控制器是管理守护进程类的pod；DaemonSet控制器的主要作用是管理守护进程类的Pod，通常用于在每个节点需要运行一个这样的Pod场景；比如我们要收集日志到es中，我们就可以使用这种控制器在每个节点上运行一个Pod；DaemonSet控制器和Deployment控制器很类似，不同的是ds(DaemonSet的简写)控制器不需要我们手动指定其运行的pod数量，它会根据k8s集群节点数量的变化而变化，如果新加入一个节点它会自动扩展对应pod数量，减少节点时，它也不会把之前运行在该节点上的pod调度到其他节点，总之一个节点上只能运行同类型Pod1个；除此之外ds它还支持通过节点选择器来做选择性的调度；比如，在某个拥有对应标签的节点就运行对应pod，没有就不运行；其他的更新操作和deployment差不多；&lt;/p&gt;
&lt;p&gt;　　示例：创建DaemonSet控制器&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;35&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
[root@master01 ~]# cat ds-demo-nginx-1.14.yaml
apiVersion: apps/v1
kind: DaemonSet
metadata: 
  name: ds-demo
  namespace: default
spec:
  selector: 
    matchLabels:
      app: ngx-ds
  template:
    metadata:
      labels:
        app: ngx-ds
    spec:
      containers:
      - name: nginx
        image: nginx:1.14-alpine
        ports:
        - name: http
          containerPort: 80
  minReadySeconds: 5
[root@master01 ~]# 
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　提示：对于ds控制器来说，它在spec中最主要定义选择器和pod模板，这个定义和deploy控制器一样；上述配置文件主要使用ds控制器运行一个nginx pod，其标签名为ngx-ds；&lt;/p&gt;
&lt;p&gt;　　应用配置清单&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;34&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
[root@master01 ~]# kubectl apply -f ds-demo-nginx-1.14.yaml
daemonset.apps/ds-demo created
[root@master01 ~]# kubectl get ds -o wide
NAME      DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR   AGE   CONTAINERS   IMAGES              SELECTOR
ds-demo   3         3         3       3            3           &amp;lt;none&amp;gt;          14s   nginx        nginx:1.14-alpine   app=ngx-ds
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　提示：可以看到我们并没有指定pod数量，对应控制器它会根据节点数量在每个node节点上创建pod；&lt;/p&gt;
&lt;p&gt;　　验证：查看pod情况，看看是不是每个节点都被调度运行了一个pod?&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;35&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
[root@master01 ~]# kubectl get pod -o wide
NAME            READY   STATUS    RESTARTS   AGE   IP            NODE             NOMINATED NODE   READINESS GATES
ds-demo-fm9cb   1/1     Running   0          27s   10.244.1.57   node01.k8s.org   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
ds-demo-pspbk   1/1     Running   0          27s   10.244.3.57   node03.k8s.org   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
ds-demo-zvpbb   1/1     Running   0          27s   10.244.2.69   node02.k8s.org   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
[root@master01 ~]#
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　提示：可以看到对应pod在每个node节点都仅跑了一个pod；&lt;/p&gt;
&lt;p&gt;　　定义节点选择器&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;35&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
[root@master01 ~]# cat ds-demo-nginx-1.14.yaml
apiVersion: apps/v1
kind: DaemonSet
metadata: 
  name: ds-demo
  namespace: default
spec:
  selector: 
    matchLabels:
      app: ngx-ds
  template:
    metadata:
      labels:
        app: ngx-ds
    spec:
      containers:
      - name: nginx
        image: nginx:1.14-alpine
        ports:
        - name: http
          containerPort: 80
      nodeSelector:
        app: nginx-1.14-alpine
  minReadySeconds: 5
[root@master01 ~]# 
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　提示：定义节点选择器需要在pod模板中的spec字段下使用nodeSelector字段来定义，这个字段的值为一个字典；以上配置定义了只有节点标签为app=nginx-1.14-alpine才会在对应节点上创建pod，否则就不予创建；&lt;/p&gt;
&lt;p&gt;　　应用配置清单&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;35&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
[root@master01 ~]# kubectl get ds
NAME      DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR   AGE
ds-demo   3         3         3       3            3           &amp;lt;none&amp;gt;          14m
[root@master01 ~]# kubectl apply -f ds-demo-nginx-1.14.yaml
daemonset.apps/ds-demo configured
[root@master01 ~]# kubectl get ds
NAME      DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR           AGE
ds-demo   0         0         0       0            0           app=nginx-1.14-alpine   14m
[root@master01 ~]# kubectl get pod
NAME            READY   STATUS        RESTARTS   AGE
ds-demo-pspbk   0/1     Terminating   0          14m
[root@master01 ~]# kubectl get pod
No resources found in default namespace.
[root@master01 ~]# 
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　提示：可以看到加上了节点选择器以后，对应pod都被删除了，原因是在k8s节点上没有任何一个节点拥有对应节点选择器中的标签，所以都不满足调度条件，当然对应pod就被控制器删除了；&lt;/p&gt;
&lt;p&gt;　　测试：给node01.k8s.org节点添加一个节点标签，其名为app=nginx-1.14-alpine，看看对应节点是否会创建pod？&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;35&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
[root@master01 ~]# kubectl label node node01.k8s.org app=nginx-1.14-alpine
node/node01.k8s.org labeled
[root@master01 ~]# kubectl get ds -o wide
NAME      DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR           AGE   CONTAINERS   IMAGES              SELECTOR
ds-demo   1         1         1       1            1           app=nginx-1.14-alpine   20m   nginx        nginx:1.14-alpine   app=ngx-ds
[root@master01 ~]# kubectl get pod -o wide
NAME            READY   STATUS    RESTARTS   AGE   IP            NODE             NOMINATED NODE   READINESS GATES
ds-demo-8hfnq   1/1     Running   0          18s   10.244.1.58   node01.k8s.org   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
[root@master01 ~]# 
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　提示：可以看到只要k8snode节点拥有对应node选择器匹配的标签时，对应pod就会精准调度到对应节点上运行；&lt;/p&gt;
&lt;p&gt;　　删除节点选择器，应用资源配置清单，然后再新加一个节点，看看新加的节点是否会自动创建对应pod?&lt;/p&gt;
&lt;p&gt;　　删除节点选择器，应用资源配置清单&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;35&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
[root@master01 ~]# cat ds-demo-nginx-1.14.yaml
apiVersion: apps/v1
kind: DaemonSet
metadata: 
  name: ds-demo
  namespace: default
spec:
  selector: 
    matchLabels:
      app: ngx-ds
  template:
    metadata:
      labels:
        app: ngx-ds
    spec:
      containers:
      - name: nginx
        image: nginx:1.14-alpine
        ports:
        - name: http
          containerPort: 80
  minReadySeconds: 5
[root@master01 ~]# kubectl apply -f ds-demo-nginx-1.14.yaml
daemonset.apps/ds-demo configured
[root@master01 ~]# kubectl get ds -o wide
NAME      DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR   AGE   CONTAINERS   IMAGES              SELECTOR
ds-demo   3         3         3       3            3           &amp;lt;none&amp;gt;          26m   nginx        nginx:1.14-alpine   app=ngx-ds
[root@master01 ~]# 
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　准备一台node节点，其主机名为node04.k8s.org，准备步骤请参考&lt;a href=&quot;https://www.cnblogs.com/qiuhom-1874/p/14126750.html&quot; target=&quot;_blank&quot;&gt;https://www.cnblogs.com/qiuhom-1874/p/14126750.html&lt;/a&gt;；&lt;/p&gt;
&lt;p&gt;　　在master节点上创建节点加入集群的命令&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;34&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
[root@master01 ~]# kubeadm token create --print-join-command 
kubeadm join 192.168.0.41:6443 --token 8rdaut.qeeyf9cw5e1dur8f     --discovery-token-ca-cert-hash sha256:330db1e5abff4d0e62150596f3e989cde40e61bdc73d6477170d786fcc1cfc67 
[root@master01 ~]# 
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　复制命令在node04上执行&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;36&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
[root@node04 ~]# kubeadm join 192.168.0.41:6443 --token 8rdaut.qeeyf9cw5e1dur8f     --discovery-token-ca-cert-hash sha256:330db1e5abff4d0e62150596f3e989cde40e61bdc73d6477170d786fcc1cfc67 --ignore-preflight-errors=Swap
[preflight] Running pre-flight checks
        [WARNING IsDockerSystemdCheck]: detected &quot;cgroupfs&quot; as the Docker cgroup driver. The recommended driver is &quot;systemd&quot;. Please follow the guide at https://kubernetes.io/docs/setup/cri/
        [WARNING Swap]: running with swap on is not supported. Please disable swap
        [WARNING SystemVerification]: this Docker version is not on the list of validated versions: 20.10.1. Latest validated version: 19.03
        [WARNING Service-Kubelet]: kubelet service is not enabled, please run 'systemctl enable kubelet.service'
[preflight] Reading configuration from the cluster...
[preflight] FYI: You can look at this config file with 'kubectl -n kube-system get cm kubeadm-config -o yaml'
[kubelet-start] Writing kubelet configuration to file &quot;/var/lib/kubelet/config.yaml&quot;
[kubelet-start] Writing kubelet environment file with flags to file &quot;/var/lib/kubelet/kubeadm-flags.env&quot;
[kubelet-start] Starting the kubelet
[kubelet-start] Waiting for the kubelet to perform the TLS Bootstrap...

This node has joined the cluster:
* Certificate signing request was sent to apiserver and a response was received.
* The Kubelet was informed of the new secure connection details.

Run 'kubectl get nodes' on the control-plane to see this node join the cluster.

[root@node04 ~]# 
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　提示：如果开启了Swap，需要在命令后面加上--ignore-preflight-errors=Swap选项；&lt;/p&gt;
&lt;p&gt;　　在master节点上查看node状态，看看node04是否加入到k8s集群&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;36&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
[root@master01 ~]# kubectl get node
NAME               STATUS     ROLES                  AGE    VERSION
master01.k8s.org   Ready      control-plane,master   10d    v1.20.0
node01.k8s.org     Ready      &amp;lt;none&amp;gt;                 10d    v1.20.0
node02.k8s.org     Ready      &amp;lt;none&amp;gt;                 10d    v1.20.0
node03.k8s.org     Ready      &amp;lt;none&amp;gt;                 10d    v1.20.0
node04.k8s.org     NotReady   &amp;lt;none&amp;gt;                 117s   v1.20.0
[root@master01 ~]# 
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　提示：能够看到node04已经加入节点，只是状态还未准备好，待节点准备就绪后，再看看dspod数量是否增加，是否自动在node04上运行了nginx pod；&lt;/p&gt;
&lt;p&gt;　　查看ds控制器，看看现在运行了几个pod&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;36&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
[root@master01 ~]# kubectl get node
NAME               STATUS   ROLES                  AGE     VERSION
master01.k8s.org   Ready    control-plane,master   10d     v1.20.0
node01.k8s.org     Ready    &amp;lt;none&amp;gt;                 10d     v1.20.0
node02.k8s.org     Ready    &amp;lt;none&amp;gt;                 10d     v1.20.0
node03.k8s.org     Ready    &amp;lt;none&amp;gt;                 10d     v1.20.0
node04.k8s.org     Ready    &amp;lt;none&amp;gt;                 8m10s   v1.20.0
[root@master01 ~]# kubectl get ds
NAME      DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR   AGE
ds-demo   4         4         4       4            4           &amp;lt;none&amp;gt;          53m
[root@master01 ~]# kubectl get pod -o wide
NAME            READY   STATUS    RESTARTS   AGE   IP            NODE             NOMINATED NODE   READINESS GATES
ds-demo-g74s8   1/1     Running   0          72s   10.244.4.2    node04.k8s.org   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
ds-demo-h4b77   1/1     Running   0          27m   10.244.2.70   node02.k8s.org   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
ds-demo-hpmrg   1/1     Running   0          27m   10.244.3.58   node03.k8s.org   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
ds-demo-kjf6f   1/1     Running   0          27m   10.244.1.59   node01.k8s.org   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
[root@master01 ~]# 
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　提示：可以看到新加的节点准备就绪以后，对应pod会自动在新加的节点上创建pod；&lt;/p&gt;
&lt;p&gt;　　更新pod版本&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;35&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
[root@master01 ~]# cat ds-demo-nginx-1.14.yaml
apiVersion: apps/v1
kind: DaemonSet
metadata: 
  name: ds-demo
  namespace: default
spec:
  selector: 
    matchLabels:
      app: ngx-ds
  template:
    metadata:
      labels:
        app: ngx-ds
    spec:
      containers:
      - name: nginx
        image: nginx:1.16-alpine
        ports:
        - name: http
          containerPort: 80
  minReadySeconds: 5
[root@master01 ~]# kubectl get ds -o wide
NAME      DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR   AGE   CONTAINERS   IMAGES              SELECTOR
ds-demo   4         4         4       4            4           &amp;lt;none&amp;gt;          55m   nginx        nginx:1.14-alpine   app=ngx-ds
[root@master01 ~]# kubectl get pod -o wide
NAME            READY   STATUS    RESTARTS   AGE     IP            NODE             NOMINATED NODE   READINESS GATES
ds-demo-g74s8   1/1     Running   0          3m31s   10.244.4.2    node04.k8s.org   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
ds-demo-h4b77   1/1     Running   0          30m     10.244.2.70   node02.k8s.org   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
ds-demo-hpmrg   1/1     Running   0          30m     10.244.3.58   node03.k8s.org   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
ds-demo-kjf6f   1/1     Running   0          30m     10.244.1.59   node01.k8s.org   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
[root@master01 ~]# kubectl apply -f ds-demo-nginx-1.14.yaml
daemonset.apps/ds-demo configured
[root@master01 ~]# kubectl get ds -o wide                  
NAME      DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR   AGE   CONTAINERS   IMAGES              SELECTOR
ds-demo   4         4         3       0            3           &amp;lt;none&amp;gt;          56m   nginx        nginx:1.16-alpine   app=ngx-ds
[root@master01 ~]#kubectl get pod -o wide
NAME            READY   STATUS              RESTARTS   AGE   IP            NODE             NOMINATED NODE   READINESS GATES
ds-demo-47gtq   0/1     ContainerCreating   0          7s    &amp;lt;none&amp;gt;        node04.k8s.org   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
ds-demo-h4b77   1/1     Running             0          31m   10.244.2.70   node02.k8s.org   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
ds-demo-jp9dz   1/1     Running             0          38s   10.244.1.60   node01.k8s.org   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
ds-demo-t4njt   1/1     Running             0          21s   10.244.3.59   node03.k8s.org   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
[root@master01 ~]# kubectl get pod -o wide
NAME            READY   STATUS    RESTARTS   AGE   IP            NODE             NOMINATED NODE   READINESS GATES
ds-demo-47gtq   1/1     Running   0          37s   10.244.4.3    node04.k8s.org   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
ds-demo-8txr9   1/1     Running   0          14s   10.244.2.71   node02.k8s.org   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
ds-demo-jp9dz   1/1     Running   0          68s   10.244.1.60   node01.k8s.org   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
ds-demo-t4njt   1/1     Running   0          51s   10.244.3.59   node03.k8s.org   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
[root@master01 ~]# 
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　提示：可以看到我们修改了pod模板中镜像的版本，应用以后，对应pod会一一更新；&lt;/p&gt;
&lt;p&gt;　　查看ds详细信息&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;35&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
[root@master01 ~]# kubectl describe ds ds-demo
Name:           ds-demo
Selector:       app=ngx-ds
Node-Selector:  &amp;lt;none&amp;gt;
Labels:         &amp;lt;none&amp;gt;
Annotations:    deprecated.daemonset.template.generation: 4
Desired Number of Nodes Scheduled: 4
Current Number of Nodes Scheduled: 4
Number of Nodes Scheduled with Up-to-date Pods: 4
Number of Nodes Scheduled with Available Pods: 4
Number of Nodes Misscheduled: 0
Pods Status:  4 Running / 0 Waiting / 0 Succeeded / 0 Failed
Pod Template:
  Labels:  app=ngx-ds
  Containers:
   nginx:
    Image:        nginx:1.16-alpine
    Port:         80/TCP
    Host Port:    0/TCP
    Environment:  &amp;lt;none&amp;gt;
    Mounts:       &amp;lt;none&amp;gt;
  Volumes:        &amp;lt;none&amp;gt;
Events:
  Type    Reason            Age                From                  Message
  ----    ------            ----               ----                  -------
  Normal  SuccessfulCreate  59m                daemonset-controller  Created pod: ds-demo-fm9cb
  Normal  SuccessfulCreate  59m                daemonset-controller  Created pod: ds-demo-zvpbb
  Normal  SuccessfulCreate  59m                daemonset-controller  Created pod: ds-demo-pspbk
  Normal  SuccessfulDelete  44m (x2 over 44m)  daemonset-controller  Deleted pod: ds-demo-fm9cb
  Normal  SuccessfulDelete  44m (x2 over 44m)  daemonset-controller  Deleted pod: ds-demo-pspbk
  Normal  SuccessfulDelete  44m (x2 over 44m)  daemonset-controller  Deleted pod: ds-demo-zvpbb
  Normal  SuccessfulCreate  38m                daemonset-controller  Created pod: ds-demo-8hfnq
  Normal  SuccessfulCreate  33m                daemonset-controller  Created pod: ds-demo-h4b77
  Normal  SuccessfulCreate  33m                daemonset-controller  Created pod: ds-demo-hpmrg
  Normal  SuccessfulDelete  33m                daemonset-controller  Deleted pod: ds-demo-8hfnq
  Normal  SuccessfulCreate  33m                daemonset-controller  Created pod: ds-demo-kjf6f
  Normal  SuccessfulCreate  6m57s              daemonset-controller  Created pod: ds-demo-g74s8
  Normal  SuccessfulDelete  3m8s               daemonset-controller  Deleted pod: ds-demo-kjf6f
  Normal  SuccessfulCreate  2m58s              daemonset-controller  Created pod: ds-demo-jp9dz
  Normal  SuccessfulDelete  2m52s              daemonset-controller  Deleted pod: ds-demo-hpmrg
  Normal  SuccessfulCreate  2m41s              daemonset-controller  Created pod: ds-demo-t4njt
  Normal  SuccessfulDelete  2m35s              daemonset-controller  Deleted pod: ds-demo-g74s8
  Normal  SuccessfulCreate  2m27s              daemonset-controller  Created pod: ds-demo-47gtq
  Normal  SuccessfulDelete  2m13s              daemonset-controller  Deleted pod: ds-demo-h4b77
  Normal  SuccessfulCreate  2m4s               daemonset-controller  Created pod: ds-demo-8txr9
[root@master01 ~]# 
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　使用命令更新pod版本&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;35&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
[root@master01 ~]# kubectl set image ds ds-demo nginx=nginx:1.18-alpine --record
daemonset.apps/ds-demo image updated
[root@master01 ~]# kubectl get ds -o wide
NAME      DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR   AGE   CONTAINERS   IMAGES              SELECTOR
ds-demo   4         4         3       0            3           &amp;lt;none&amp;gt;          84m   nginx        nginx:1.18-alpine   app=ngx-ds
[root@master01 ~]# kubectl rollout status ds/ds-demo
Waiting for daemon set &quot;ds-demo&quot; rollout to finish: 1 out of 4 new pods have been updated...
Waiting for daemon set &quot;ds-demo&quot; rollout to finish: 2 out of 4 new pods have been updated...
Waiting for daemon set &quot;ds-demo&quot; rollout to finish: 2 out of 4 new pods have been updated...
Waiting for daemon set &quot;ds-demo&quot; rollout to finish: 2 out of 4 new pods have been updated...
Waiting for daemon set &quot;ds-demo&quot; rollout to finish: 2 out of 4 new pods have been updated...
Waiting for daemon set &quot;ds-demo&quot; rollout to finish: 3 out of 4 new pods have been updated...
Waiting for daemon set &quot;ds-demo&quot; rollout to finish: 3 out of 4 new pods have been updated...
Waiting for daemon set &quot;ds-demo&quot; rollout to finish: 3 out of 4 new pods have been updated...
Waiting for daemon set &quot;ds-demo&quot; rollout to finish: 3 out of 4 new pods have been updated...
Waiting for daemon set &quot;ds-demo&quot; rollout to finish: 3 of 4 updated pods are available...
Waiting for daemon set &quot;ds-demo&quot; rollout to finish: 3 of 4 updated pods are available...
daemon set &quot;ds-demo&quot; successfully rolled out
[root@master01 ~]# kubectl get pod -o wide
NAME            READY   STATUS    RESTARTS   AGE   IP            NODE             NOMINATED NODE   READINESS GATES
ds-demo-6qr6g   1/1     Running   0          70s   10.244.2.77   node02.k8s.org   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
ds-demo-7gnxd   1/1     Running   0          57s   10.244.3.66   node03.k8s.org   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
ds-demo-g44bd   1/1     Running   0          24s   10.244.1.66   node01.k8s.org   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
ds-demo-hb8vl   1/1     Running   0          43s   10.244.4.10   node04.k8s.org   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
[root@master01 ~]# kubectl describe pod/ds-demo-6qr6g |grep Image
    Image:          nginx:1.18-alpine
    Image ID:       docker-pullable://nginx@sha256:a7bdf9e789a40bf112c87672a2495fc49de7c89f184a252d59061c1ae800ee52
[root@master01 ~]# 
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　提示：默认更新策略是删除一个pod，然后再新建一个pod；&lt;/p&gt;
&lt;p&gt;　　定义更新策略&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;35&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
[root@master01 ~]# cat ds-demo-nginx-1.14.yaml
apiVersion: apps/v1
kind: DaemonSet
metadata: 
  name: ds-demo
  namespace: default
spec:
  selector: 
    matchLabels:
      app: ngx-ds
  template:
    metadata:
      labels:
        app: ngx-ds
    spec:
      containers:
      - name: nginx
        image: nginx:1.16-alpine
        ports:
        - name: http
          containerPort: 80
  minReadySeconds: 5
  updateStrategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 2
[root@master01 ~]# 
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　提示：定义ds的更新策略需要在spec字段下使用updateStrategy字段，该字段的值为一个对象，其中type是更新类型，该类型有两个值，一个是OnDelete，一个是RollingUpdate；rollingUpdate字段用于指定更新策略，只有当type的值为RollingUpdate时，定义rollingUpdate字段才有意义，其中maxUnavaiable是用来定义一次删除几个pod（最大允许不可用的pod数量）；ds更新只能先删除再创建，不能先创建再删除，因为它只允许一个node上运行一个pod，所以只有删除pod后再创建；默认情况是删除一个，新建一个；上述配置定义更新策略为一次删除两个；&lt;/p&gt;
&lt;p&gt;　　应用配置，查看更新过程&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;35&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
[root@master01 ~]# kubectl apply -f ds-demo-nginx-1.14.yaml &amp;amp;&amp;amp; kubectl get pod -w
daemonset.apps/ds-demo configured
NAME            READY   STATUS        RESTARTS   AGE
ds-demo-4k2x7   1/1     Terminating   0          15m
ds-demo-b9djn   1/1     Running       0          16m
ds-demo-bxkj7   1/1     Running       0          15m
ds-demo-cg49r   1/1     Terminating   0          16m
ds-demo-cg49r   0/1     Terminating   0          16m
ds-demo-4k2x7   0/1     Terminating   0          15m
ds-demo-cg49r   0/1     Terminating   0          16m
ds-demo-cg49r   0/1     Terminating   0          16m
ds-demo-dtsgc   0/1     Pending       0          0s
ds-demo-dtsgc   0/1     Pending       0          0s
ds-demo-dtsgc   0/1     ContainerCreating   0          0s
ds-demo-dtsgc   1/1     Running             0          2s
ds-demo-4k2x7   0/1     Terminating         0          15m
ds-demo-4k2x7   0/1     Terminating         0          15m
ds-demo-8d7g9   0/1     Pending             0          0s
ds-demo-8d7g9   0/1     Pending             0          0s
ds-demo-8d7g9   0/1     ContainerCreating   0          0s
ds-demo-8d7g9   1/1     Running             0          1s
ds-demo-b9djn   1/1     Terminating         0          16m
ds-demo-b9djn   0/1     Terminating         0          16m
ds-demo-bxkj7   1/1     Terminating         0          16m
ds-demo-bxkj7   0/1     Terminating         0          16m
ds-demo-b9djn   0/1     Terminating         0          16m
ds-demo-b9djn   0/1     Terminating         0          16m
ds-demo-dkxfs   0/1     Pending             0          0s
ds-demo-dkxfs   0/1     Pending             0          0s
ds-demo-dkxfs   0/1     ContainerCreating   0          0s
ds-demo-dkxfs   1/1     Running             0          2s
ds-demo-bxkj7   0/1     Terminating         0          16m
ds-demo-bxkj7   0/1     Terminating         0          16m
ds-demo-q6b5f   0/1     Pending             0          0s
ds-demo-q6b5f   0/1     Pending             0          0s
ds-demo-q6b5f   0/1     ContainerCreating   0          0s
ds-demo-q6b5f   1/1     Running             0          1s
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　提示：可以看到现在更新pod版本就是一次删除两个pod，然后新建两个pod；&lt;/p&gt;
&lt;p&gt; 　　2、Job控制器&lt;/p&gt;
&lt;p&gt;　　job控制器主要作用是用来运行一个或多个pod来执行任务，当任务执行完成后，自动退出，如果在执行任务过程中pod故障了，job控制器会根据重启策略将其进行重启，直到任务完成pod正常退出；如果重启策略为Never，则pod异常后将不再重启，它会重新创建一个新pod再次执行任务，最后直到任务完成正常退出；&lt;/p&gt;
&lt;p&gt;　　Job控制器pod状态&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1503305/202012/1503305-20201218222436014-456417835.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　提示：上图主要描述了对于job控制器创建的pod的状态，正常情况pod执行完任务正常退出，其状态为completed；如果pod非正常退出（即退出码非0），并且重启策略为never，表示不重启pod，此时pod的状态就为Failure：虽然不重启pod，但是对应的任务还是在，所以重启策略为never时，pod非正常退出，job控制器会重新创建一个pod再次执行任务；如果pod非正常退出且重启策略为OnFailure时，pod会被重启，然后再次执行任务，直到最后任务执行完成pod正常退出，此时pod的状态为completed;&lt;/p&gt;
&lt;p&gt;　　任务作业方式&lt;/p&gt;
&lt;p&gt;　　串行作业&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1503305/202012/1503305-20201218225318416-480474750.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　提示：串行作业一次只有一个pod被创建，只有当pod任务执行完成后，第二个pod才会被创建；&lt;/p&gt;
&lt;p&gt;　　并行作业&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1503305/202012/1503305-20201218225538251-637655028.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　提示：并行作业可以并行启动多个pod同时作业；&lt;/p&gt;
&lt;p&gt; 　　示例：定义job控制器&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;36&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
[root@master01 ~]# cat job-demo.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: job-demo
spec:
  template:
    metadata:
      labels:
        app: myjob
    spec:
      containers:
      - name: myjob
        image: alpine
        command: [&quot;/bin/sh&quot;,  &quot;-c&quot;, &quot;sleep 10&quot;]
      restartPolicy: Never
[root@master01 ~]# 
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　提示：创建job控制最主要是定义对应pod模板；定义方式和pod其他控制器定义方式相同；在spec字段下使用template指定来定义pod模板；&lt;/p&gt;
&lt;p&gt;　　应用配置清单&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;35&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
[root@master01 ~]# kubectl apply -f job-demo.yaml
job.batch/job-demo created
[root@master01 ~]# kubectl get jobs -o wide
NAME       COMPLETIONS   DURATION   AGE   CONTAINERS   IMAGES   SELECTOR
job-demo   0/1           7s         7s    myjob        alpine   controller-uid=4ded17a8-fc39-480e-8f37-6bb2bd328997
[root@master01 ~]# kubectl get pod 
NAME             READY   STATUS    RESTARTS   AGE
ds-demo-8d7g9    1/1     Running   0          91m
ds-demo-dkxfs    1/1     Running   0          91m
ds-demo-dtsgc    1/1     Running   0          91m
ds-demo-q6b5f    1/1     Running   0          91m
job-demo-4h9gb   1/1     Running   0          16s
[root@master01 ~]# kubectl get pod 
NAME             READY   STATUS      RESTARTS   AGE
ds-demo-8d7g9    1/1     Running     0          91m
ds-demo-dkxfs    1/1     Running     0          91m
ds-demo-dtsgc    1/1     Running     0          91m
ds-demo-q6b5f    1/1     Running     0          91m
job-demo-4h9gb   0/1     Completed   0          30s
[root@master01 ~]# 
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　提示：可以看到创建job控制后，对应启动pod执行完任务后就正常退出，此时pod的状态为completed；&lt;/p&gt;
&lt;p&gt;　　定义并行job控制器&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;36&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
[root@master01 ~]# cat job-multi.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: job-multi-demo
spec:
  completions: 6
  template:
    metadata:
      labels:
        app: myjob
    spec:
      containers:
      - name: myjob
        image: alpine
        command: [&quot;/bin/sh&quot;,  &quot;-c&quot;, &quot;sleep 10&quot;]
      restartPolicy: Never
[root@master01 ~]# 
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　提示：定义多路并行pod需要在spec字段下使用completions来指定执行任务需要的对应pod的数量；以上配置表示job-multi-demo这个job控制器执行任务需要启动6个pod；&lt;/p&gt;
&lt;p&gt;　　应用配置清单&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;35&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
[root@master01 ~]# kubectl apply -f job-multi.yaml
job.batch/job-multi-demo created
[root@master01 ~]# kubectl get jobs -o wide
NAME             COMPLETIONS   DURATION   AGE     CONTAINERS   IMAGES   SELECTOR
job-demo         1/1           18s        9m49s   myjob        alpine   controller-uid=4ded17a8-fc39-480e-8f37-6bb2bd328997
job-multi-demo   0/6           6s         6s      myjob        alpine   controller-uid=80f44cbd-f7e5-4eb4-a286-39bfcfc9fe39
[root@master01 ~]# kubectl get pods -o wide
NAME                   READY   STATUS      RESTARTS   AGE    IP            NODE             NOMINATED NODE   READINESS GATES
ds-demo-8d7g9          1/1     Running     0          101m   10.244.3.69   node03.k8s.org   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
ds-demo-dkxfs          1/1     Running     0          101m   10.244.1.69   node01.k8s.org   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
ds-demo-dtsgc          1/1     Running     0          101m   10.244.4.13   node04.k8s.org   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
ds-demo-q6b5f          1/1     Running     0          100m   10.244.2.80   node02.k8s.org   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
job-demo-4h9gb         0/1     Completed   0          10m    10.244.3.70   node03.k8s.org   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
job-multi-demo-rbw7d   1/1     Running     0          21s    10.244.1.70   node01.k8s.org   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
[root@master01 ~]# kubectl get pods -o wide
NAME                   READY   STATUS      RESTARTS   AGE    IP            NODE             NOMINATED NODE   READINESS GATES
ds-demo-8d7g9          1/1     Running     0          101m   10.244.3.69   node03.k8s.org   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
ds-demo-dkxfs          1/1     Running     0          101m   10.244.1.69   node01.k8s.org   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
ds-demo-dtsgc          1/1     Running     0          101m   10.244.4.13   node04.k8s.org   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
ds-demo-q6b5f          1/1     Running     0          101m   10.244.2.80   node02.k8s.org   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
job-demo-4h9gb         0/1     Completed   0          10m    10.244.3.70   node03.k8s.org   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
job-multi-demo-f7rz4   1/1     Running     0          21s    10.244.3.71   node03.k8s.org   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
job-multi-demo-rbw7d   0/1     Completed   0          43s    10.244.1.70   node01.k8s.org   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
[root@master01 ~]#
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　提示：默认情况没有指定并行度，其并行度为1,即pod和pod之间就是串行执行任务；&lt;/p&gt;
&lt;p&gt;　　定义并行度&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;37&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
[root@master01 ~]# cat job-multi.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: job-multi-demo2
spec:
  completions: 6
  parallelism: 2
  template:
    metadata:
      labels:
        app: myjob
    spec:
      containers:
      - name: myjob
        image: alpine
        command: [&quot;/bin/sh&quot;,  &quot;-c&quot;, &quot;sleep 10&quot;]
      restartPolicy: Never
[root@master01 ~]# 
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　提示：定义并行度需要在spec字段下使用parallelism字段来指定，所谓并行度指一次并行运行几个pod，上述配置表示一次运行2个pod；即2个pod同时作业；&lt;/p&gt;
&lt;p&gt;　　应用配置清单&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;35&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
[root@master01 ~]# kubectl apply -f job-multi.yaml
job.batch/job-multi-demo2 created
[root@master01 ~]# kubectl get jobs -o wide
NAME              COMPLETIONS   DURATION   AGE     CONTAINERS   IMAGES   SELECTOR
job-demo          1/1           18s        18m     myjob        alpine   controller-uid=4ded17a8-fc39-480e-8f37-6bb2bd328997
job-multi-demo    6/6           116s       8m49s   myjob        alpine   controller-uid=80f44cbd-f7e5-4eb4-a286-39bfcfc9fe39
job-multi-demo2   0/6           8s         8s      myjob        alpine   controller-uid=d40f47ea-e58d-4424-97bd-7fda6bdf4e43
[root@master01 ~]# kubectl get pod -o wide
NAME                    READY   STATUS      RESTARTS   AGE     IP            NODE             NOMINATED NODE   READINESS GATES
ds-demo-8d7g9           1/1     Running     0          109m    10.244.3.69   node03.k8s.org   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
ds-demo-dkxfs           1/1     Running     0          109m    10.244.1.69   node01.k8s.org   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
ds-demo-dtsgc           1/1     Running     0          110m    10.244.4.13   node04.k8s.org   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
ds-demo-q6b5f           1/1     Running     0          109m    10.244.2.80   node02.k8s.org   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
job-demo-4h9gb          0/1     Completed   0          18m     10.244.3.70   node03.k8s.org   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
job-multi-demo-f7rz4    0/1     Completed   0          8m44s   10.244.3.71   node03.k8s.org   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
job-multi-demo-hhcrm    0/1     Completed   0          7m23s   10.244.3.72   node03.k8s.org   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
job-multi-demo-kjmld    0/1     Completed   0          8m20s   10.244.2.81   node02.k8s.org   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
job-multi-demo-lfzrj    0/1     Completed   0          8m1s    10.244.2.82   node02.k8s.org   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
job-multi-demo-rbw7d    0/1     Completed   0          9m6s    10.244.1.70   node01.k8s.org   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
job-multi-demo-vdkrm    0/1     Completed   0          7m41s   10.244.2.83   node02.k8s.org   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
job-multi-demo2-66tdd   0/1     Completed   0          25s     10.244.2.84   node02.k8s.org   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
job-multi-demo2-fsl9r   0/1     Completed   0          25s     10.244.3.73   node03.k8s.org   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
job-multi-demo2-js7qs   1/1     Running     0          9s      10.244.2.85   node02.k8s.org   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
job-multi-demo2-nqmps   1/1     Running     0          12s     10.244.1.71   node01.k8s.org   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
[root@master01 ~]# kubectl get pod -o wide
NAME                    READY   STATUS      RESTARTS   AGE     IP            NODE             NOMINATED NODE   READINESS GATES
ds-demo-8d7g9           1/1     Running     0          110m    10.244.3.69   node03.k8s.org   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
ds-demo-dkxfs           1/1     Running     0          109m    10.244.1.69   node01.k8s.org   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
ds-demo-dtsgc           1/1     Running     0          110m    10.244.4.13   node04.k8s.org   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
ds-demo-q6b5f           1/1     Running     0          109m    10.244.2.80   node02.k8s.org   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
job-demo-4h9gb          0/1     Completed   0          19m     10.244.3.70   node03.k8s.org   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
job-multi-demo-f7rz4    0/1     Completed   0          8m57s   10.244.3.71   node03.k8s.org   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
job-multi-demo-hhcrm    0/1     Completed   0          7m36s   10.244.3.72   node03.k8s.org   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
job-multi-demo-kjmld    0/1     Completed   0          8m33s   10.244.2.81   node02.k8s.org   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
job-multi-demo-lfzrj    0/1     Completed   0          8m14s   10.244.2.82   node02.k8s.org   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
job-multi-demo-rbw7d    0/1     Completed   0          9m19s   10.244.1.70   node01.k8s.org   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
job-multi-demo-vdkrm    0/1     Completed   0          7m54s   10.244.2.83   node02.k8s.org   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
job-multi-demo2-5f5tn   1/1     Running     0          9s      10.244.1.72   node01.k8s.org   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
job-multi-demo2-66tdd   0/1     Completed   0          38s     10.244.2.84   node02.k8s.org   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
job-multi-demo2-fsl9r   0/1     Completed   0          38s     10.244.3.73   node03.k8s.org   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
job-multi-demo2-js7qs   0/1     Completed   0          22s     10.244.2.85   node02.k8s.org   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
job-multi-demo2-md84p   1/1     Running     0          9s      10.244.3.74   node03.k8s.org   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
job-multi-demo2-nqmps   0/1     Completed   0          25s     10.244.1.71   node01.k8s.org   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
[root@master01 ~]# 
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　提示：可以看到现在pod就一次运行两个；&lt;/p&gt;
&lt;p&gt;　　3、CronJob控制器&lt;/p&gt;
&lt;p&gt;　　这种类型的控制器主要用来创建周期性任务pod；&lt;/p&gt;
&lt;p&gt;　　示例：定义CronJob控制器&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;35&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
[root@master01 ~]# cat cronjob-demo.yaml
apiVersion: batch/v1beta1
kind: CronJob
metadata:
  name: cronjob-demo
  labels:
    app: mycronjob
spec:
  schedule: &quot;*/2 * * * *&quot;
  jobTemplate:
    metadata:
      labels:
        app: mycronjob-jobs
    spec:
      parallelism: 2
      template:
        spec:
          containers:
          - name: myjob
            image: alpine
            command:
            - /bin/sh
            - -c
            - date; echo Hello from the Kubernetes cluster; sleep 10
          restartPolicy: OnFailure
[root@master01 ~]# 
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　提示：定义cronjob控制器，最主要是定义job模板；其实cronjob控制器是通过job控制器来管理pod，这个逻辑有点类似deploy控制器通过rs来控制pod；其中schedule字段用来指定周期性调度时间策略，这个定义和我们在linux上定义周期性任务一样；对于job模板和我们定义job一样；以上配置表示每2分钟执行一次job模板中的定义的job任务；其每次并行运行2个pod；&lt;/p&gt;
&lt;p&gt;　　执行配置清单&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;35&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
[root@master01 ~]# kubectl apply -f cronjob-demo.yaml
cronjob.batch/cronjob-demo created
[root@master01 ~]# kubectl get cronjob -o wide
NAME           SCHEDULE      SUSPEND   ACTIVE   LAST SCHEDULE   AGE   CONTAINERS   IMAGES   SELECTOR
cronjob-demo   */2 * * * *   False     0        &amp;lt;none&amp;gt;          12s   myjob        alpine   &amp;lt;none&amp;gt;
[root@master01 ~]# kubectl get pod 
NAME                            READY   STATUS      RESTARTS   AGE
cronjob-demo-1608307560-5hwmb   1/1     Running     0          9s
cronjob-demo-1608307560-rgkkr   1/1     Running     0          9s
ds-demo-8d7g9                   1/1     Running     0          125m
ds-demo-dkxfs                   1/1     Running     0          125m
ds-demo-dtsgc                   1/1     Running     0          125m
ds-demo-q6b5f                   1/1     Running     0          125m
job-demo-4h9gb                  0/1     Completed   0          34m
job-multi-demo-f7rz4            0/1     Completed   0          24m
job-multi-demo-hhcrm            0/1     Completed   0          23m
job-multi-demo-kjmld            0/1     Completed   0          24m
job-multi-demo-lfzrj            0/1     Completed   0          23m
job-multi-demo-rbw7d            0/1     Completed   0          25m
job-multi-demo-vdkrm            0/1     Completed   0          23m
job-multi-demo2-5f5tn           0/1     Completed   0          15m
job-multi-demo2-66tdd           0/1     Completed   0          16m
job-multi-demo2-fsl9r           0/1     Completed   0          16m
job-multi-demo2-js7qs           0/1     Completed   0          16m
job-multi-demo2-md84p           0/1     Completed   0          15m
job-multi-demo2-nqmps           0/1     Completed   0          16m
[root@master01 ~]#
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　提示：可以看到对应就有两个pod正在运行；&lt;/p&gt;
&lt;p&gt;　　查看是否创建的有job控制器呢？&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;35&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
[root@master01 ~]# kubectl get job -o wide
NAME                      COMPLETIONS   DURATION   AGE     CONTAINERS   IMAGES   SELECTOR
cronjob-demo-1608307560   2/1 of 2      15s        3m18s   myjob        alpine   controller-uid=4a84b474-b890-4dd2-80d4-a6115130785a
cronjob-demo-1608307680   2/1 of 2      17s        77s     myjob        alpine   controller-uid=affecad9-03e6-430c-8c58-c845773c8ff7
job-demo                  1/1           18s        37m     myjob        alpine   controller-uid=4ded17a8-fc39-480e-8f37-6bb2bd328997
job-multi-demo            6/6           116s       28m     myjob        alpine   controller-uid=80f44cbd-f7e5-4eb4-a286-39bfcfc9fe39
job-multi-demo2           6/6           46s        19m     myjob        alpine   controller-uid=d40f47ea-e58d-4424-97bd-7fda6bdf4e43
[root@master01 ~]# 
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　提示：有两个job控制器，名字都一样；从上面显示的结果，不难理解，cronjob每执行一次，它都会调用对应的job控制来创建新pod；&lt;/p&gt;
</description>
<pubDate>Fri, 18 Dec 2020 16:23:00 +0000</pubDate>
<dc:creator>Linux-1874</dc:creator>
<og:description>前文我们了解了k8s上的pod控制器中的常用的两种控制器ReplicaSet和Deployment控制器的相关话题，回顾请参考：https://www.cnblogs.com/qiuhom-1874/</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/qiuhom-1874/p/14157306.html</dc:identifier>
</item>
<item>
<title>多图详解Go的互斥锁Mutex - luozhiyun</title>
<link>http://www.cnblogs.com/luozhiyun/p/14157542.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/luozhiyun/p/14157542.html</guid>
<description>&lt;blockquote readability=&quot;5.6434108527132&quot;&gt;
&lt;p&gt;转载请声明出处哦~，本篇文章发布于luozhiyun的博客：&lt;a href=&quot;https://www.luozhiyun.com&quot; target=&quot;_blank&quot;&gt;https://www.luozhiyun.com&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;本文使用的go的源码时14.4&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;mutex介绍&quot;&gt;Mutex介绍&lt;/h2&gt;
&lt;p&gt;Mutex 结构体包含两个字段：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-go&quot;&gt;type Mutex struct {
        state int32
        sema  uint32
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;在Go的1.9版本中，为了解决等待中的 goroutine 可能会一直获取不到锁，增加了饥饿模式，让锁变得更公平，不公平的等待时间限制在 1 毫秒。&lt;/p&gt;
&lt;p&gt;state状态字段所表示的含义较为复杂，如下图所示，最低三位分别表示mutexLocked、mutexWoken、mutexStarving，state总共是32位长度，所以剩下的位置，用来表示可以有1&amp;lt;&amp;lt;(32-3)个Goroutine 等待互斥锁的释放：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img.luozhiyun.com/20201218225206.png&quot; alt=&quot;Group 1&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;代码表示如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-go&quot;&gt;const (
        mutexLocked = 1 &amp;lt;&amp;lt; iota // mutex is locked
        mutexWoken
        mutexStarving
)
&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;加锁流程&quot;&gt;加锁流程&lt;/h2&gt;
&lt;h3 id=&quot;fast-path&quot;&gt;fast path&lt;/h3&gt;
&lt;pre&gt;
&lt;code class=&quot;language-go&quot;&gt;func (m *Mutex) Lock() { 
        if atomic.CompareAndSwapInt32(&amp;amp;m.state, 0, mutexLocked) {
                if race.Enabled {
                        race.Acquire(unsafe.Pointer(m))
                }
                return
        } 
        m.lockSlow()
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;加锁的时候，一开始会通过CAS看一下能不能直接获取锁，如果可以的话，那么直接获取锁成功。&lt;/p&gt;
&lt;h3 id=&quot;lockslow&quot;&gt;lockSlow&lt;/h3&gt;
&lt;pre&gt;
&lt;code class=&quot;language-go&quot;&gt;// 等待时间
var waitStartTime int64
// 饥饿标记
starving := false
// 唤醒标记
awoke := false
// 自旋次数
iter := 0
// 当前的锁的状态
old := m.state
for { 
    // 锁是非饥饿状态，锁还没被释放，尝试自旋
        if old&amp;amp;(mutexLocked|mutexStarving) == mutexLocked &amp;amp;&amp;amp; runtime_canSpin(iter) {
                if !awoke &amp;amp;&amp;amp; old&amp;amp;mutexWoken == 0 &amp;amp;&amp;amp; old&amp;gt;&amp;gt;mutexWaiterShift != 0 &amp;amp;&amp;amp;
                        atomic.CompareAndSwapInt32(&amp;amp;m.state, old, old|mutexWoken) {
                        awoke = true
                }
                // 自旋
                runtime_doSpin()
                // 自旋次数加1
                iter++
                // 设置当前锁的状态
                old = m.state
                continue
        }
        ...
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;进入到lockSlow方法之后首先会判断以下能否可以自旋，判断依据就是通过计算：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;old&amp;amp;(mutexLocked|mutexStarving) == mutexLocked
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;可以知道当前锁的状态必须是上锁，并且不能处于饥饿状态，这个判断才为true，然后再看看iter是否满足次数的限制，如果都为true，那么则往下继续。&lt;/p&gt;
&lt;p&gt;内层if包含了四个判断：&lt;/p&gt;
&lt;ul readability=&quot;1&quot;&gt;&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;首先判断了awoke是不是唤醒状态；&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;&lt;code&gt;old&amp;amp;mutexWoken == 0&lt;/code&gt;为真表示没有其他正在唤醒的节点；&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;&lt;code&gt;old&amp;gt;&amp;gt;mutexWaiterShift != 0&lt;/code&gt;表明当前有正在等待的goroutine；&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;CAS将state的mutexWoken状态位设置为&lt;code&gt;old|mutexWoken&lt;/code&gt;，即为1是否成功。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;如果都满足，那么将awoke状态设置为真，然后将自旋次数加一，并重新设置状态。&lt;/p&gt;
&lt;p&gt;继续往下看：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-go&quot;&gt;new := old
if old&amp;amp;mutexStarving == 0 {
        // 如果当前不是饥饿模式，那么将mutexLocked状态位设置1，表示加锁
        new |= mutexLocked
}
if old&amp;amp;(mutexLocked|mutexStarving) != 0 {
        // 如果当前被锁定或者处于饥饿模式，则waiter加一，表示等待一个等待计数
        new += 1 &amp;lt;&amp;lt; mutexWaiterShift
}
// 如果是饥饿状态，并且已经上锁了，那么mutexStarving状态位设置为1，设置为饥饿状态
if starving &amp;amp;&amp;amp; old&amp;amp;mutexLocked != 0 {
        new |= mutexStarving
}
// awoke为true则表明当前线程在上面自旋的时候，修改mutexWoken状态成功
if awoke { 
        if new&amp;amp;mutexWoken == 0 {
                throw(&quot;sync: inconsistent mutex state&quot;)
        }
        // 清除唤醒标志位
        new &amp;amp;^= mutexWoken
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;走到这里有两种情况：1. 自旋超过了次数；2. 目前锁没有被持有。&lt;/p&gt;
&lt;p&gt;所以第一个判断，如果当前加了锁，但是没有处于饥饿状态，也会重复设置&lt;code&gt;new |= mutexLocked&lt;/code&gt;，即将mutexLocked状态设置为1；&lt;/p&gt;
&lt;p&gt;如果是old已经是饥饿状态或者已经被上锁了，那么需要设置Waiter加一，表示这个goroutine下面不会获取锁，会等待；&lt;/p&gt;
&lt;p&gt;如果starving为真，表示当前goroutine是饥饿状态，并且old已经被上锁了，那么设置&lt;code&gt;new |= mutexStarving&lt;/code&gt;，即将mutexStarving状态位设置为1；&lt;/p&gt;
&lt;p&gt;awoke如果在自旋时设置成功，那么在这里要&lt;code&gt;new &amp;amp;^= mutexWoken&lt;/code&gt;消除mutexWoken标志位。因为后续流程很有可能当前线程会被挂起,就需要等待其他释放锁的goroutine来唤醒，如果unlock的时候发现mutexWoken的位置不是0，则就不会去唤醒，则该线程就无法再醒来加锁。&lt;/p&gt;
&lt;p&gt;继续往下：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-go&quot;&gt;if atomic.CompareAndSwapInt32(&amp;amp;m.state, old, new) {
        // 1.如果原来状态没有上锁，也没有饥饿，那么直接返回，表示获取到锁
        if old&amp;amp;(mutexLocked|mutexStarving) == 0 {
                break // locked the mutex with CAS
        }
        // 2.到这里是没有获取到锁，判断一下等待时长是否不为0
        // 如果不为0，那么加入到队列头部
        queueLifo := waitStartTime != 0
        // 3.如果等待时间为0，那么初始化等待时间
        if waitStartTime == 0 {
                waitStartTime = runtime_nanotime()
        }
        // 4.阻塞等待
        runtime_SemacquireMutex(&amp;amp;m.sema, queueLifo, 1)
        // 5.唤醒之后检查锁是否应该处于饥饿状态
        starving = starving || runtime_nanotime()-waitStartTime &amp;gt; starvationThresholdNs
        old = m.state
        // 6.判断是否已经处于饥饿状态
        if old&amp;amp;mutexStarving != 0 { 
                if old&amp;amp;(mutexLocked|mutexWoken) != 0 || old&amp;gt;&amp;gt;mutexWaiterShift == 0 {
                        throw(&quot;sync: inconsistent mutex state&quot;)
                }
                // 7.加锁并且将waiter数减1
                delta := int32(mutexLocked - 1&amp;lt;&amp;lt;mutexWaiterShift)
                if !starving || old&amp;gt;&amp;gt;mutexWaiterShift == 1 { 
                        // 8.如果当前goroutine不是饥饿状态，就从饥饿模式切换会正常模式
                        delta -= mutexStarving
                }
                // 9.设置状态
                atomic.AddInt32(&amp;amp;m.state, delta)
                break
        }
        awoke = true
        iter = 0
} else {
        old = m.state
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;到这里，首先会CAS设置新的状态，如果设置成功则往下走，否则返回之后循环设置状态。设置成功之后：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;首先会判断old状态，如果没有饥饿，也没有获取到锁，那么直接返回，因为这种情况在进入到这段代码之前会将new状态设置为mutexLocked，表示已经获取到锁。这里还判断了一下old状态不能为饥饿状态，否则也不能获取到锁；&lt;/li&gt;
&lt;li&gt;判断waitStartTime是否已经初始化过了，如果是新的goroutine来抢占锁，那么queueLifo会返回false；如果不是新的goroutine来抢占锁，那么加入到等待队列头部，这样等待最久的 goroutine 优先能够获取到锁；&lt;/li&gt;
&lt;li&gt;如果等待时间为0，那么初始化等待时间；&lt;/li&gt;
&lt;li&gt;阻塞等待，当前goroutine进行休眠；&lt;/li&gt;
&lt;li&gt;唤醒之后检查锁是否应该处于饥饿状态，并设置starving变量值；&lt;/li&gt;
&lt;li&gt;判断是否已经处于饥饿状态，如果不处于饥饿状态，那么这里直接进入到下一个for循环中获取锁；&lt;/li&gt;
&lt;li&gt;加锁并且将waiter数减1，这里我看了一会，没用懂什么意思，其实需要分两步来理解，相当于state+mutexLocked，然后state再将waiter部分的数减一；&lt;/li&gt;
&lt;li&gt;如果当前goroutine不是饥饿状态或者waiter只有一个，就从饥饿模式切换会正常模式；&lt;/li&gt;
&lt;li&gt;设置状态；&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;下面用图例来解释：&lt;/p&gt;
&lt;p&gt;这部分的图解是休眠前的操作，休眠前会根据old的状态来判断能不能直接获取到锁，如果old状态没有上锁，也没有饥饿，那么直接break返回，因为这种情况会在CAS中设置加上锁；&lt;/p&gt;
&lt;p&gt;接着往下判断，waitStartTime是否等于0，如果不等于，说明不是第一次来了，而是被唤醒后来到这里，那么就不能直接放到队尾再休眠了，而是要放到队首，防止长时间抢不到锁；&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img.luozhiyun.com/20201218225213.png&quot; alt=&quot;Group 5&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;下面这张图是处于唤醒后的示意图，如何被唤醒的可以直接到跳到解锁部分看完再回来。&lt;/p&gt;
&lt;p&gt;被唤醒一开始是需要判断一下当前的starving状态以及等待的时间如果超过了1ms，那么会将starving设置为true；&lt;/p&gt;
&lt;p&gt;接下来会有一个if判断， 这里有个细节，因为是被唤醒的，所以判断前需要重新获取一下锁，如果当前不是饥饿模式，那么会直接返回，然后重新进入到for循环中；&lt;/p&gt;
&lt;p&gt;如果当前是处于饥饿模式，那么会计算一下delta为加锁，并且当前的goroutine是可以直接抢占锁的，所以需要将waiter减一，如果starving不为饥饿，或者等待时间没有超过1ms，或者waiter只有一个了，那么还需要将delta减去mutexStarving，表示退出饥饿模式；&lt;/p&gt;
&lt;p&gt;最后通过AddInt32将state加上delta，这里之所以可以直接加上，因为这时候state的mutexLocked值肯定为0，并且mutexStarving位肯定为1，并且在获取锁之前至少还有当前一个goroutine在等待队列中，所以waiter可以直接减1。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img.luozhiyun.com/20201218225217.png&quot; alt=&quot;Group 6&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h2 id=&quot;解锁流程&quot;&gt;解锁流程&lt;/h2&gt;
&lt;h3 id=&quot;fast-path-1&quot;&gt;fast path&lt;/h3&gt;
&lt;pre&gt;
&lt;code class=&quot;language-go&quot;&gt;func (m *Mutex) Unlock() {
        if race.Enabled {
                _ = m.state
                race.Release(unsafe.Pointer(m))
        }
        //返回一个state被减后的值        
        new := atomic.AddInt32(&amp;amp;m.state, -mutexLocked)
        if new != 0 { 
        //如果返回的state值不为0，那么进入到unlockSlow中
                m.unlockSlow(new)
        }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;这里主要就是AddInt32重新设置state的mutexLocked位为0，然后判断新的state值是否不为0，不为0则调用unlockSlow方法。&lt;/p&gt;
&lt;h3 id=&quot;unlockslow&quot;&gt;unlockSlow&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;https://img.luozhiyun.com/20201218225221.png&quot; alt=&quot;Group 7&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;unlockSlow方法里面也分为正常模式和饥饿模式下的解锁：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-go&quot;&gt;func (m *Mutex) unlockSlow(new int32) {
        if (new+mutexLocked)&amp;amp;mutexLocked == 0 {
                throw(&quot;sync: unlock of unlocked mutex&quot;)
        }
    // 正常模式
        if new&amp;amp;mutexStarving == 0 {
                old := new
                for { 
                        // 如果没有 waiter，或者已经有在处理的情况，直接返回
                        if old&amp;gt;&amp;gt;mutexWaiterShift == 0 || old&amp;amp;(mutexLocked|mutexWoken|mutexStarving) != 0 {
                                return
                        } 
                        // waiter 数减 1，mutexWoken 标志设置上，通过 CAS 更新 state 的值
                        new = (old - 1&amp;lt;&amp;lt;mutexWaiterShift) | mutexWoken
                        if atomic.CompareAndSwapInt32(&amp;amp;m.state, old, new) {
                                // 直接唤醒等待队列中的 waiter
                                runtime_Semrelease(&amp;amp;m.sema, false, 1)
                                return
                        }
                        old = m.state
                }
        } else { // 饥饿模式
                // 直接唤醒等待队列中的 waiter
                runtime_Semrelease(&amp;amp;m.sema, true, 1)
        }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;在正常模式下，如果没有 waiter，或者mutexLocked、mutexStarving、mutexWoken有一个不为零说明已经有其他goroutine在处理了，直接返回；如果互斥锁存在等待者，那么通过runtime_Semrelease直接唤醒等待队列中的 waiter；&lt;/p&gt;
&lt;p&gt;在饥饿模式，直接调用runtime_Semrelease方法将当前锁交给下一个正在尝试获取锁的等待者，等待者被唤醒后会得到锁。&lt;/p&gt;
&lt;h2 id=&quot;总结&quot;&gt;总结&lt;/h2&gt;
&lt;p&gt;Mutex的设计非常的简洁的，从代码可以看出为了设计出这么简洁的代码state一个字段可以当4个字段使用。并且为了解决goroutine饥饿问题，在1.9 中 Mutex 增加了饥饿模式让锁变得更公平，不公平的等待时间限制在 1 毫秒，但同时，代码也变得越来越难懂了，所以要理解它上面的思想需要慢慢的废些时间细细的体会一下了。&lt;/p&gt;
</description>
<pubDate>Fri, 18 Dec 2020 14:53:00 +0000</pubDate>
<dc:creator>luozhiyun</dc:creator>
<og:description>转载请声明出处哦~，本篇文章发布于luozhiyun的博客：https://www.luozhiyun.com 本文使用的go的源码时14.4 Mutex介绍 Mutex 结构体包含两个字段： 字段s</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/luozhiyun/p/14157542.html</dc:identifier>
</item>
<item>
<title>听说特斯拉花了4个月研发出新ERP，然后很多人都疯了 - SAP梦心</title>
<link>http://www.cnblogs.com/saper/p/14157419.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/saper/p/14157419.html</guid>
<description>&lt;p&gt;&lt;span&gt;&lt;strong&gt;欢迎关注微信公众号：sap_gui （ERP咨询顾问之家）&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt; &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;最近这件事儿在SAP圈里炒的挺火的，最主要是因为这几个关键词：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;放弃SAP、4个月、自研ERP；&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;这则新闻一出来，很多人都兴高采烈，都要疯了，到处疾呼：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;“ &lt;strong&gt;你看SAP这么牛逼，不也被替换了么？&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;谁说自研ERP没出路，人家不也成功了？&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;这是SAP的分水岭，从此开始走下坡路了，国产ERP可以趁此弯道超车！&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;...... ”&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;img src=&quot;https://pic3.zhimg.com/80/v2-ada2d43439892418bfedba5c970374ca_1440w.jpg&quot; width=&quot;613&quot; height=&quot;334&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;780&quot; data-rawheight=&quot;425&quot; data-original=&quot;https://pic3.zhimg.com/v2-ada2d43439892418bfedba5c970374ca_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-ada2d43439892418bfedba5c970374ca_b.jpg&quot; data-lazy-status=&quot;ok&quot;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;span&gt; &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;几个月前本公众号发的文章：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;a class=&quot; wrap external&quot; href=&quot;https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzAwODA2MjA2Mg%3D%3D%26mid%3D2247484923%26idx%3D1%26sn%3D478ac12698fc88f32a404f902d025825%26chksm%3D9b75d0faac0259ec39022ff62974b4674095b721fe6a8c773066dd9b26f91e45280054047603%26scene%3D21%23wechat_redirect&quot; rel=&quot;nofollow noreferrer&quot; target=&quot;_blank&quot; data-za-detail-view-id=&quot;1043&quot;&gt;《为什么会有人傻到想自己开发ERP来替换SAP？》&lt;/a&gt;(点击阅读)，这热乎劲儿早已经凉透了，如今又被很多人给挖出来鞭尸，狠狠嘲讽了一番。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;一直奉行“自研ERP很傻”准则的我好奇心特别强，仔细看了一下相关的新闻，也从中挖出了几个特别有意思的关键点：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;1、特斯拉早期直接使用了当时最好的&lt;span&gt;低代码开发平台Mendix&lt;/span&gt;，系统于2012年7月上线；&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;2、两年前，西门子&lt;span&gt;花了8亿美金&lt;/span&gt;收购了Mendix；&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;3、经过8年的迭代，Tesla核心的数字化系统，已经完全由自主开发，并且全公司遵循统一的软件开发管理准则；&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;4、这套系统的内部名称叫Warp Drive（“Warp”），包括了所需要使用的供应链、产品规划、库存、销售订单管理、资产、财务、潜在客户管理等绝大部分业务流程；&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;5、维护这套系统现在需要&lt;span&gt;超过250个工程师&lt;/span&gt;；&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;img src=&quot;https://pic4.zhimg.com/80/v2-9342c3c66f69f59c3eec63ffd58a83cf_1440w.jpg&quot; width=&quot;741&quot; height=&quot;333&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1084&quot; data-rawheight=&quot;487&quot; data-original=&quot;https://pic4.zhimg.com/v2-9342c3c66f69f59c3eec63ffd58a83cf_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-9342c3c66f69f59c3eec63ffd58a83cf_b.jpg&quot; data-lazy-status=&quot;ok&quot;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;通过以上几个关键地方，稍微有点语文水平的人应该都能总结出几个结论来。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;特斯拉的ERP实际上是建立在一套名为Warp大平台上面，经过这么多年的迭代已经超越了ERP的所有功能范畴，像售后，CRM，SRM等都集成在里面，甚至用户在车机系统上的求助和报修等，都会直接连接到Warp系统中。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;我不是特斯拉的员工，相信以特斯拉的实力和风格，自研ERP并大获成功应该不是难事儿。但&lt;span&gt;作为普通大众和广大制造业，看个乐呵就完事儿了&lt;/span&gt;，千万不要因此疯狂，竞相模仿，千万不要觉得人家能干咱也能干。&lt;span&gt;投多少钱干多少事儿，你先数数你们企业维护ERP有几个编制工程师再站出来说话&lt;/span&gt;。别老是想着什么“弯道超车”或者“几条枪”就能成事儿，这其中付出的代价，财力物力已经大大超越所有企业所能承受的范围了。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;span&gt;我还是那句话：非专业领域勿行专业之事&lt;/span&gt;。自研ERP或许可以成功上线，但使用效果就一定能够比外购来得好吗？一些制造企业自研ERP最终沦落为普通进销存（订单管理系统），账务都是人工收集加工再手工导入外购的财务系统中，这种做法真的很爽吗？不过是在外死鸭子嘴硬，在内忍气吞声罢了。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;没有起到管理作用的“ERP”，就是一套普通的应用+数据库而已；&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;img src=&quot;https://pic4.zhimg.com/80/v2-d3631d793ad5590aa0cd0a67bc743d4f_1440w.jpg&quot; width=&quot;774&quot; height=&quot;484&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1285&quot; data-rawheight=&quot;804&quot; data-original=&quot;https://pic4.zhimg.com/v2-d3631d793ad5590aa0cd0a67bc743d4f_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-d3631d793ad5590aa0cd0a67bc743d4f_b.jpg&quot; data-lazy-status=&quot;ok&quot;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;span&gt; &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;--------------&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;题外话，不少企业和国人特别注重和吹捧一些极小概率的事件，并轻易得出很奇怪的结论。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;比如：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;某个初中毕业的人成为大老板 -- 读书无用，读书再多不也是给文盲打工；&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;某个人好吃懒做，只花了2块钱就中了五百万 -- 朝九晚五不如两块买彩；&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;特斯拉花了4个月自研ERP成功替换SAP并上线 -- SAP走下坡路了；&lt;/span&gt;&lt;/p&gt;
&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;span&gt; &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;有了这种奇怪的结论之后，一些企业和管理者可能就开始模仿了，&lt;span&gt;开口闭口学标杆企业，甚至规章制度一字不动全抄过来；模仿华为和小米；仿照格力的管理；也不想想华为1998年都干了什么，现在自己都在干什么。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;由此，我想起那年不少企业学格力，把办公室垃圾桶都没收掉，好像这样做就变得高大上起来一样；也想起一些公司学标杆企业，将自家收费食堂的饭菜从8个减为4个，而对标杆企业工作餐免费制视而不见~&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;span&gt;没有人家超强的管理模式和理念，没有人家完善的业务规范，没有人家雄厚的财力物力和资金投入，没有人家对信息化建设的重视，没有人家对人才的培养和激励，就不要轻易谈什么模仿和学习，否则抄过来的都是一些表面上的旧芝麻烂事儿&lt;/span&gt;，贻笑大方~&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;img src=&quot;https://pic1.zhimg.com/80/v2-a40bf8b54c7e85054c4e40675659db80_1440w.jpg&quot; width=&quot;545&quot; height=&quot;373&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;800&quot; data-rawheight=&quot;548&quot; data-original=&quot;https://pic1.zhimg.com/v2-a40bf8b54c7e85054c4e40675659db80_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-a40bf8b54c7e85054c4e40675659db80_b.jpg&quot; data-lazy-status=&quot;ok&quot;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;span&gt; &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;以上说了这么多，想以特斯拉为标杆，要模仿人家自研ERP的，还请自重！&lt;/span&gt;&lt;/p&gt;

</description>
<pubDate>Fri, 18 Dec 2020 14:25:00 +0000</pubDate>
<dc:creator>SAP梦心</dc:creator>
<og:description>欢迎关注微信公众号：sap_gui （ERP咨询顾问之家） 最近这件事儿在SAP圈里炒的挺火的，最主要是因为这几个关键词： 放弃SAP、4个月、自研ERP； 这则新闻一出来，很多人都兴高采烈，都要疯了</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/saper/p/14157419.html</dc:identifier>
</item>
</channel>
</rss>