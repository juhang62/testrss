<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="css/feed.xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/" xmlns:og="http://ogp.me/ns#">
<channel>
<atom:link rel="self" href="http://192.168.1.4/fivefilters/makefulltextfeed.php?url=feed.cnblogs.com%2Fblog%2Fsitehome%2Frss&amp;max=10&amp;links=preserve&amp;exc=" />
<atom:link rel="alternate" title="Source URL" href="http://feed.cnblogs.com/blog/sitehome/rss" />
<atom:link rel="related" title="Subscribe to feed" href="http://www.subtome.com/#/subscribe?feeds=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed.cnblogs.com%252Fblog%252Fsitehome%252Frss%26max%3D10%26links%3Dpreserve%26exc%3D&amp;back=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed.cnblogs.com%252Fblog%252Fsitehome%252Frss%26max%3D10%26links%3Dpreserve%26exc%3D" />
<title>博客园_首页</title>
<link></link>
<description>代码改变世界</description>
<item>
<title>SpringBoot第二十二篇：应用监控之Actuator - 追梦1819</title>
<link>http://www.cnblogs.com/yanfei1819/p/11226397.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/yanfei1819/p/11226397.html</guid>
<description>&lt;p&gt;作者：追梦1819&lt;br/&gt;原文：https://www.cnblogs.com/yanfei1819/p/11226397.html&lt;br/&gt;版权声明：本文为博主原创文章，转载请附上博文链接！&lt;/p&gt;
&lt;h2 id=&quot;引言&quot;&gt;引言&lt;/h2&gt;
&lt;p&gt;  很多文章都将 SpringBoot Actuator 的 Endpoint 翻译为 &quot;端点&quot;。不过我认为这这翻译失去了原有的意思。故本文中的 endpoint 依旧是 endpoint，不翻译为&quot;端点&quot;。&lt;/p&gt;
&lt;p&gt;  通过引入 &lt;code&gt;spring-boot-starter-actuator&lt;/code&gt; ，可以使用 SpringBoot 为我们提供的准生产环境下的应用监控和管理功能。我们可以通过 HTTP、JMX、SSH协议进行操作。自动得到审计、监控和指标操作。&lt;/p&gt;

&lt;p&gt;步骤：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;引入maven依赖；&lt;/li&gt;
&lt;li&gt;通过 HTTP 方式访问监控端点；&lt;/li&gt;
&lt;li&gt;可进行 shutdown（post提交，此端点默认关闭）。&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&quot;原生endpoint&quot;&gt;原生endpoint&lt;/h2&gt;
&lt;p&gt;  SpringBoot 的 Actuator 有很多原生的端点，详细查看&lt;a href=&quot;https://docs.spring.io/spring-boot/docs/current/reference/htmlsingle/#production-ready&quot;&gt;官网&lt;/a&gt;。Spring Boot 2.0 中的端点和之前的版本有较大不同,使用时需注意。启动时不是可以直接访问，需要先将其暴露出来。&lt;/p&gt;
&lt;p&gt;本文中，我们讲述几个常用的端点。&lt;/p&gt;
&lt;ol readability=&quot;12.5&quot;&gt;&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;health&lt;/p&gt;
&lt;p&gt;主要用来检查应用的运行状态。如果应用有异常，同时给我们反馈异常原因。比如数据库连接异常，磁盘空间过小等异常。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;11&quot;&gt;
&lt;p&gt;info&lt;/p&gt;
&lt;p&gt;自定义应用程序的配置信息。&lt;/p&gt;
&lt;p&gt;例如，在配置文件中配置如下信息：&lt;/p&gt;
&lt;pre class=&quot;properties&quot;&gt;
&lt;code&gt;info.app.name=actuator
info.app.versoin=1.0.0
info.app.data=2019-06-25 12:00:00
info.app.author=yanfei1819&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;启动项目，访问&lt;code&gt;http://localhost:8080/actuator/info&lt;/code&gt;，可以得到如下响应：&lt;/p&gt;
&lt;pre class=&quot;json&quot;&gt;
&lt;code&gt;{&quot;app&quot;:{&quot;name&quot;:&quot;actuator&quot;,&quot;versoin&quot;:&quot;1.0.0&quot;,&quot;data&quot;:&quot;2019-06-25 12:00:00&quot;,&quot;author&quot;:&quot;yanfei1819&quot;}}&lt;/code&gt;
&lt;/pre&gt;&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;beans&lt;/p&gt;
&lt;p&gt;该 endpoint 展示了 bean 的别名、类型、是否单例、类的地址、依赖等信息。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;1&quot;&gt;
&lt;p&gt;conditions&lt;/p&gt;
&lt;p&gt;Spring Boot 的自动配置功能非常便利，但有时候也意味着出问题比较难找出具体的原因。使用 conditions 可以在应用运行时查看代码了某个配置在什么条件下生效，或者某个自动配置为什么没有生效。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;heapdump&lt;/p&gt;
&lt;p&gt;展示Jvm 的堆文件 heapdump。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;shutdown&lt;/p&gt;
&lt;p&gt;远程关闭应用的端点，不过需要注意两点：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;需要在配置文件中配置 &lt;code&gt;management.endpoint.shutdown.enabled=true&lt;/code&gt;；&lt;/li&gt;
&lt;li&gt;只支持 POST 请求。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;mappings&lt;/p&gt;
&lt;p&gt;程序中所有的 URI 路径，以及与控制器的关系。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;threaddump&lt;/p&gt;
&lt;p&gt;查看线程信息，例如线程名、线程ID、线程的状态、是否等待锁资源等。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&quot;使用&quot;&gt;使用&lt;/h2&gt;
&lt;p&gt;创建项目，引入 maven 依赖：&lt;/p&gt;
&lt;pre class=&quot;xml&quot;&gt;
&lt;code&gt;&amp;lt;dependency&amp;gt;
    &amp;lt;groupId&amp;gt;org.springframework.boot&amp;lt;/groupId&amp;gt;
    &amp;lt;artifactId&amp;gt;spring-boot-starter-actuator&amp;lt;/artifactId&amp;gt;
&amp;lt;/dependency&amp;gt;
&amp;lt;dependency&amp;gt;
    &amp;lt;groupId&amp;gt;org.springframework.boot&amp;lt;/groupId&amp;gt;
    &amp;lt;artifactId&amp;gt;spring-boot-starter-web&amp;lt;/artifactId&amp;gt;
&amp;lt;/dependency&amp;gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;启动项目，控制台打印信息：&lt;br/&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1183871/201907/1183871-20190722155759518-1813884823.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;可以看出此时只暴露了两个 endpoint。&lt;/p&gt;
&lt;p&gt;访问 &lt;code&gt;http://localhost:8080/actuator&lt;/code&gt; ，可以看到两个端点是：&lt;/p&gt;
&lt;pre class=&quot;json&quot;&gt;
&lt;code&gt;{
    &quot;_links&quot;: {
        &quot;self&quot;: {
            &quot;href&quot;: &quot;http://localhost:8080/actuator&quot;,
            &quot;templated&quot;: false
        },
        &quot;health&quot;: {
            &quot;href&quot;: &quot;http://localhost:8080/actuator/health&quot;,
            &quot;templated&quot;: false
        },
        &quot;health-component&quot;: {
            &quot;href&quot;: &quot;http://localhost:8080/actuator/health/{component}&quot;,
            &quot;templated&quot;: true
        },
        &quot;health-component-instance&quot;: {
            &quot;href&quot;: &quot;http://localhost:8080/actuator/health/{component}/{instance}&quot;,
            &quot;templated&quot;: true
        },
        &quot;info&quot;: {
            &quot;href&quot;: &quot;http://localhost:8080/actuator/info&quot;,
            &quot;templated&quot;: false
        }
    }
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;如果我们需要访问所有的原生 endpoint，需要在配置文件中加入：&lt;code&gt;management.endpoints.web.exposure.include=*&lt;/code&gt; 。&lt;/p&gt;
&lt;p&gt;重新启动项目，控制台日志是：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1183871/201907/1183871-20190722155808279-812505431.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;访问 &lt;code&gt;http://localhost:8080/actuator&lt;/code&gt; ，可以看到所有端点是：&lt;/p&gt;
&lt;pre class=&quot;json&quot;&gt;
&lt;code&gt;{
    &quot;_links&quot;: {
        &quot;self&quot;: {
            &quot;href&quot;: &quot;http://localhost:8080/actuator&quot;,
            &quot;templated&quot;: false
        },
        &quot;auditevents&quot;: {
            &quot;href&quot;: &quot;http://localhost:8080/actuator/auditevents&quot;,
            &quot;templated&quot;: false
        },
        &quot;beans&quot;: {
            &quot;href&quot;: &quot;http://localhost:8080/actuator/beans&quot;,
            &quot;templated&quot;: false
        },
        &quot;caches-cache&quot;: {
            &quot;href&quot;: &quot;http://localhost:8080/actuator/caches/{cache}&quot;,
            &quot;templated&quot;: true
        },
        &quot;caches&quot;: {
            &quot;href&quot;: &quot;http://localhost:8080/actuator/caches&quot;,
            &quot;templated&quot;: false
        },
        &quot;health&quot;: {
            &quot;href&quot;: &quot;http://localhost:8080/actuator/health&quot;,
            &quot;templated&quot;: false
        },
        &quot;health-component&quot;: {
            &quot;href&quot;: &quot;http://localhost:8080/actuator/health/{component}&quot;,
            &quot;templated&quot;: true
        },
        &quot;health-component-instance&quot;: {
            &quot;href&quot;: &quot;http://localhost:8080/actuator/health/{component}/{instance}&quot;,
            &quot;templated&quot;: true
        },
        &quot;conditions&quot;: {
            &quot;href&quot;: &quot;http://localhost:8080/actuator/conditions&quot;,
            &quot;templated&quot;: false
        },
        &quot;configprops&quot;: {
            &quot;href&quot;: &quot;http://localhost:8080/actuator/configprops&quot;,
            &quot;templated&quot;: false
        },
        &quot;env&quot;: {
            &quot;href&quot;: &quot;http://localhost:8080/actuator/env&quot;,
            &quot;templated&quot;: false
        },
        &quot;env-toMatch&quot;: {
            &quot;href&quot;: &quot;http://localhost:8080/actuator/env/{toMatch}&quot;,
            &quot;templated&quot;: true
        },
        &quot;info&quot;: {
            &quot;href&quot;: &quot;http://localhost:8080/actuator/info&quot;,
            &quot;templated&quot;: false
        },
        &quot;loggers&quot;: {
            &quot;href&quot;: &quot;http://localhost:8080/actuator/loggers&quot;,
            &quot;templated&quot;: false
        },
        &quot;loggers-name&quot;: {
            &quot;href&quot;: &quot;http://localhost:8080/actuator/loggers/{name}&quot;,
            &quot;templated&quot;: true
        },
        &quot;heapdump&quot;: {
            &quot;href&quot;: &quot;http://localhost:8080/actuator/heapdump&quot;,
            &quot;templated&quot;: false
        },
        &quot;threaddump&quot;: {
            &quot;href&quot;: &quot;http://localhost:8080/actuator/threaddump&quot;,
            &quot;templated&quot;: false
        },
        &quot;metrics&quot;: {
            &quot;href&quot;: &quot;http://localhost:8080/actuator/metrics&quot;,
            &quot;templated&quot;: false
        },
        &quot;metrics-requiredMetricName&quot;: {
            &quot;href&quot;: &quot;http://localhost:8080/actuator/metrics/{requiredMetricName}&quot;,
            &quot;templated&quot;: true
        },
        &quot;scheduledtasks&quot;: {
            &quot;href&quot;: &quot;http://localhost:8080/actuator/scheduledtasks&quot;,
            &quot;templated&quot;: false
        },
        &quot;httptrace&quot;: {
            &quot;href&quot;: &quot;http://localhost:8080/actuator/httptrace&quot;,
            &quot;templated&quot;: false
        },
        &quot;mappings&quot;: {
            &quot;href&quot;: &quot;http://localhost:8080/actuator/mappings&quot;,
            &quot;templated&quot;: false
        }
    }
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;  读者可以逐个访问，查看对应的返回信息。&lt;/p&gt;
&lt;p&gt;  当然，也可以通过配置 &lt;code&gt;management.endpoints.web.exposure.exclude=info,trace&lt;/code&gt; 选择部分 endpoint 暴露。&lt;/p&gt;
&lt;p&gt;  同时，Actuator 默认所有的监控点路径都在&lt;code&gt;/actuator/*&lt;/code&gt;，当然如果有需要这个路径也支持定制。&lt;code&gt;management.endpoints.web.base-path=/manage&lt;/code&gt;。&lt;/p&gt;

&lt;h2 id=&quot;自定义endpoint&quot;&gt;自定义endpoint&lt;/h2&gt;
&lt;p&gt;以下：&lt;/p&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;package com.yanfei1819.actuator.endpoint;

import org.springframework.boot.actuate.endpoint.annotation.Endpoint;
import org.springframework.boot.actuate.endpoint.annotation.ReadOperation;
import org.springframework.context.annotation.Configuration;
import java.util.HashMap;
import java.util.Map;

/**
 * Created by 追梦1819 on 2019-06-25.
 */
@Configuration
@Endpoint(id = &quot;customize-endpoint&quot;) // 构建 rest api 的唯一路径
public class CustomizeEndPoint {
    @ReadOperation
    public Map&amp;lt;String, Object&amp;gt; endpoint() {
        Map&amp;lt;String, Object&amp;gt; map = new HashMap&amp;lt;&amp;gt;(16);
        map.put(&quot;message&quot;, &quot;this is customize endpoint&quot;);
        return map;
    }
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;在配置文件中使其暴露：&lt;/p&gt;
&lt;pre class=&quot;properties&quot;&gt;
&lt;code&gt;management.endpoints.web.exposure.include=customize-endpoint&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;启动程序，访问 &lt;code&gt;management.endpoints.web.exposure.include=customize-endpoint&lt;/code&gt; ，可以得到endpoint：&lt;/p&gt;
&lt;pre class=&quot;json&quot;&gt;
&lt;code&gt;{
    &quot;_links&quot;: {
        &quot;self&quot;: {
            &quot;href&quot;: &quot;http://localhost:8080/actuator&quot;,
            &quot;templated&quot;: false
        },
        &quot;customize-endpoint&quot;: {
            &quot;href&quot;: &quot;http://localhost:8080/actuator/customize-endpoint&quot;,
            &quot;templated&quot;: false
        }
    }
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;再访问返回的endpoint地址，得到相应：&lt;/p&gt;
&lt;pre class=&quot;json&quot;&gt;
&lt;code&gt;{&quot;message&quot;:&quot;this is customize endpoint&quot;}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;可验证自定义 endpoint 成功。&lt;/p&gt;

&lt;h2 id=&quot;总结&quot;&gt;总结&lt;/h2&gt;
&lt;p&gt;  对于作者来说，这个功能核心是对 endpoints 的理解（我对该功能的使用总结，大部分时间也是耗在了这个上面）。理解了每一个 endpoint ，基本大的方向就掌握了。剩下的就是细节问题了（细节问题无非就是&quot;慢工出细活&quot;，简单）。&lt;/p&gt;
&lt;p&gt;  另一个问题， Actuctor 的功能是实现了，可是大家有没有觉得用起来很别扭？查看一个监控信息，就访问一个路径，得到的就一连串的JSON，繁琐、复杂、不够直观。这实属让运维同学抓狂的问题。有没有好的解决方案呢？且听下回分解。&lt;/p&gt;

&lt;h2 id=&quot;参考&quot;&gt;参考&lt;/h2&gt;
&lt;p&gt;&lt;a href=&quot;https://docs.spring.io/spring-boot/docs/current/reference/htmlsingle/#production-ready&quot;&gt;SpringBoot官网&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1183871/201907/1183871-20190722155821232-374443563.png&quot;/&gt;&lt;/p&gt;
</description>
<pubDate>Tue, 23 Jul 2019 00:38:00 +0000</pubDate>
<dc:creator>追梦1819</dc:creator>
<og:description>作者：追梦1819 原文：https://www.cnblogs.com/yanfei1819/p/11226397.html 版权声明：本文为博主原创文章，转载请附上博文链接！ 引言  &amp;</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/yanfei1819/p/11226397.html</dc:identifier>
</item>
<item>
<title>前端手势控制图片插件书写二 - 前端++</title>
<link>http://www.cnblogs.com/qdcnbj/p/11229563.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/qdcnbj/p/11229563.html</guid>
<description>&lt;p&gt;上次解释了如何使用代码识别双指和单指操作及放大和旋转拖动操作。这次解释下css3的transform原理&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;一、transform矩阵原理&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;transform: matrix(a,b,c,d,e,f)&lt;/p&gt;
&lt;div&gt;&lt;img src=&quot;https://note.youdao.com/src/E181DF862B86406D8B52401583010328&quot; alt=&quot;&quot; data-media-type=&quot;image&quot;/&gt;&lt;/div&gt;
&lt;div&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1300379/201907/1300379-20190723082352718-1663199958.png&quot; alt=&quot;&quot; width=&quot;726&quot; height=&quot;166&quot;/&gt;&lt;/div&gt;
&lt;p&gt;ax+cy+e为变换后的水平坐标，bx+dy+f表示变换后的垂直&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;二、Transform的原理即是坐标系基向量的变换。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;默认的基向量为&lt;/p&gt;
&lt;div&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1300379/201907/1300379-20190723082530971-440318570.png&quot; alt=&quot;&quot; width=&quot;302&quot; height=&quot;305&quot;/&gt;&lt;/div&gt;
&lt;div&gt;&lt;img src=&quot;https://note.youdao.com/src/A4997D4820DB4CF0AC614228A3D82AB1&quot; alt=&quot;&quot; data-media-type=&quot;image&quot;/&gt;&lt;/div&gt;
&lt;p&gt;如本文第一张图所示，公式中第一个矩阵即为基向量的变化。(a,b)和(c,d)分别为x轴和y轴基向量。所以图一和图二经对比可得。&lt;/p&gt;
&lt;p&gt;a表示x轴坐标放大倍数，d为y轴坐标放大倍数。&lt;/p&gt;
&lt;p&gt;而如果旋转基向量呢？&lt;/p&gt;
&lt;div&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1300379/201907/1300379-20190723082634888-1510476087.png&quot; alt=&quot;&quot; width=&quot;455&quot; height=&quot;296&quot;/&gt;&lt;/div&gt;
&lt;div&gt;&lt;img src=&quot;https://note.youdao.com/src/721B513A15954920AC613B3AE9993756&quot; alt=&quot;&quot; data-media-type=&quot;image&quot;/&gt;&lt;/div&gt;
&lt;p&gt;假设基向量如上图旋转θ角度，基向量坐标变为(cosθ,sinθ)和(-sinθ,cosθ)。&lt;/p&gt;

&lt;p&gt;而e,f即为基向量平移的距离。&lt;/p&gt;

&lt;p&gt;由此可知矩阵中a,b,c,d,e,f各代表的含义。到此我们就可以通过矩阵来计算出实际图片旋转的角度和放大的倍数及平移的距离。&lt;/p&gt;
&lt;p&gt;或者我们换一种角度来理解矩阵，假设矩阵旋转了θ角度，如何使用θ来标识新的向量的坐标。如下图所示。&lt;/p&gt;
&lt;div&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1300379/201907/1300379-20190723082754627-31055750.png&quot; alt=&quot;&quot; width=&quot;354&quot; height=&quot;473&quot;/&gt;&lt;/div&gt;
&lt;div&gt;&lt;img src=&quot;https://note.youdao.com/src/8424EF669DE544DB8A4F89758728C1BB&quot; alt=&quot;&quot; data-media-type=&quot;image&quot;/&gt;&lt;/div&gt;
&lt;p&gt;所以：假设已知θ，旋转后的x和y&lt;/p&gt;
&lt;p&gt;X’ = x*cosθ-y*sinθ+0 = x*cosθ-y*sinθ&lt;/p&gt;
&lt;p&gt;y' = x*sinθ+y*cosθ+0 = x*sinθ+y*cosθ&lt;/p&gt;
&lt;p&gt;将这个公式和本文一开始的公式进行对比，所以可得&lt;/p&gt;
&lt;p&gt;matrix(cosθ,sinθ,-sinθ,cosθ,0,0)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt; 三、所以可以由a,b,c,d,e,f和θ角度的对应关系，从矩阵中求得tranform变换，即由矩阵求得图片的位移，缩放及旋转角度。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;下面为实例代码：&lt;/p&gt;
&lt;div readability=&quot;18&quot;&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;50&quot;&gt;
&lt;pre&gt;
console.log('matrix'&lt;span&gt;, matrix)
        let arr &lt;/span&gt;= (matrix.replace('matrix(', '').replace(')', '')).split(','&lt;span&gt;);
        console.log(&lt;/span&gt;'arr'&lt;span&gt;, arr)
        let cos &lt;/span&gt;= arr[0&lt;span&gt;],
            sin &lt;/span&gt;= arr[1&lt;span&gt;],
            tan &lt;/span&gt;= sin /&lt;span&gt; cos,
            rotate &lt;/span&gt;= Math.atan(tan) * 180 /&lt;span&gt; Math.PI,
            scale &lt;/span&gt;= cos / (Math.cos(Math.PI / 180 *&lt;span&gt; rotate)),
            trans;
        trans &lt;/span&gt;=&lt;span&gt; {
            x: parseInt(arr[&lt;/span&gt;4&lt;span&gt;]),
            y: parseInt(arr[&lt;/span&gt;5&lt;span&gt;]),
            scale: scale,
            rotate: rotate,
        };
        console.log(&lt;/span&gt;'trans'&lt;span&gt;, trans)
        &lt;/span&gt;&lt;span&gt;this&lt;/span&gt;.dragTrans =&lt;span&gt; trans;
        &lt;/span&gt;&lt;span&gt;return&lt;/span&gt; trans;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;注意:scale为当前经过变换后的a的值比上如果未经缩放的a的值即为缩放倍数。&lt;/p&gt;
&lt;/div&gt;


</description>
<pubDate>Tue, 23 Jul 2019 00:29:00 +0000</pubDate>
<dc:creator>前端++</dc:creator>
<og:description>上次解释了如何使用代码识别双指和单指操作及放大和旋转拖动操作。这次解释下css3的transform原理 一、transform矩阵原理 transform: matrix(a,b,c,d,e,f)</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/qdcnbj/p/11229563.html</dc:identifier>
</item>
<item>
<title>.net持续集成sonarqube篇之sonarqube安装与基本配置 - 周国通</title>
<link>http://www.cnblogs.com/tylerzhou/p/11229548.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/tylerzhou/p/11229548.html</guid>
<description>&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&quot;https://www.cnblogs.com/tylerzhou/p/11204826.html&quot;&gt;系列目录&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;sonarqube下载与安装&quot;&gt;Sonarqube下载与安装&lt;/h2&gt;
&lt;p&gt;Sonarqube下载地址是:&lt;code&gt;https://www.sonarqube.org/downloads/&lt;/code&gt;下载版本有两个,一个是长期支持版,另一个是最新版,此处安装的是最新版,目前版本是7.3,下载的时候点击醒目的蓝色按钮即可(此时下载的是社区版),下面有三个无底色按钮下载链接,分别对应的是开发者版,企业版和数据中心版,这些版本都不是免费版,需要获取Licence key方可使用.目前起步阶段,使用社区版就Ok了.&lt;/p&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;注意 Sonarqube是基于java语言开发的,因此运行之前必须先安装Jre&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote readability=&quot;10&quot;&gt;
&lt;p&gt;Sonarqube支持Windows,mac和linux,但是安装包并不区分平台,也就是这三个平台下载包是一样的,只是启动方式不同.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;下载完成全将下载的压缩包解压,进入bin目录,可以看到这个目录下有数个文件夹,从文件夹的名称很容易看出它们对应的是windows,mac,linux平台下的启动目录,由于我们是在windows平台下运行的,因此进入windows-x86-64目录(当然,如果你的电脑是32位系统,则进入windows-x86-32目录)此目录下面有很多脚本文件,我们双击&lt;code&gt;StartSonar.bat&lt;/code&gt;这个批处理文件来运行windows下的sonarqube,启动需要数十秒时间,请耐心等等.当看到控制台最后一句是&lt;code&gt;SonarQube is up&lt;/code&gt;说明sonarqube已经成功启动.此时在浏览器地址栏输入&lt;code&gt;localhost:9000&lt;/code&gt;就可以进入Sonarqube web管理页面.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/811801/201907/811801-20190723082057266-1363064548.png&quot; alt=&quot;avatar&quot;/&gt;&lt;/p&gt;
&lt;p&gt;这个页面是一个关于Sonarqube的介绍页面,从这里可以很清析地看到Sonarqube支持的语言,点击&lt;code&gt;Read Documentation&lt;/code&gt;按钮可以进入Sonarqube的帮助文档页面.&lt;/p&gt;
&lt;h2 id=&quot;sonarqube基本配置&quot;&gt;Sonarqube基本配置&lt;/h2&gt;
&lt;p&gt;上一节我们已经成功启动Sonarqube,然而仅仅把Sonarqube启动起来并没有什么作用,我们还需要进行数据库配置和扫描器(Sonarqube对特定语言的扫描工具称为扫描器)配置才能把数据接入Sonarqube管理平台.&lt;/p&gt;
&lt;h3 id=&quot;数据库配置&quot;&gt;&lt;code&gt;数据库配置&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;Sonarqube支持内嵌数据库,mysql,oracle 11g/12c,sql server 2014/2016,postgresql 9.3+,由于oracle需要提供单独的驱动比较麻烦,这里就以mysql为例讲解.&lt;/p&gt;
&lt;p&gt;我们进入Sonarqube目录下的conf目录,下面有一个&lt;code&gt;sonar.properties&lt;/code&gt;文件,我们用记录本打开它,我们进入mysql栏把&lt;code&gt;sonar.jdbc.url&lt;/code&gt;注释取消掉,并加上以下代码&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;sonar.jdbc.username=root
sonar.jdbc.password=
sonar.sorceEncoding=UTF-8
sonar.login=root
sonar.password=&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;Sonarqube默认的数据库名为sonar,需要我们&lt;code&gt;手动创建&lt;/code&gt;,我们在自己常用的mysql管理工具里新建即可.&lt;/p&gt;
&lt;p&gt;以上是关于sonarqube mysql连接字符串的配置.用户名和密码读者根据实际情况填写&lt;/p&gt;
&lt;blockquote readability=&quot;11&quot;&gt;
&lt;p&gt;以上笔者使用的是Xampp带的mysql的默认配置,用户名为root,密码为空,注意这里的password不能写为&quot;&quot;,而是什么都不写留空,当然如果有密码就填写实际密码.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;Sonarqube 7.3仅支持mysql 5.6及以上8.0以下版本,也就是说不支持8.0版本,需要特别注意.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;Sonarqube也支持内嵌数据库,然而内嵌数据库不便于管理和迁移,强烈不建议在生产环境使用内嵌数据库.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;我们重新启动Sonarqube,然后进入web管理界面,此时我们打开mysql管理工具,可以看到sonarqube在sonarqube库下创建了很多表.&lt;/p&gt;
&lt;h3 id=&quot;安装配置msbuild-scanner&quot;&gt;&lt;code&gt;安装配置Msbuild Scanner&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;上一节我们说过,Sonarqube需要使用Scanner来扫描代码数据以供Sonarqube管理平台使用,这里我们下载 msbuild scanner扫描工具对c#代码进行扫描.&lt;/p&gt;
&lt;p&gt;我们把Sonarqube web管理界面往下拉到最底,会看到一拍图标&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/811801/201907/811801-20190723082143527-1483439390.png&quot; alt=&quot;avatar&quot;/&gt;&lt;/p&gt;
&lt;p&gt;我们点击第一个图标,也就是Visual Studio图标,会进入一个页面&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/811801/201907/811801-20190723082137745-2068665911.png&quot; alt=&quot;avatar&quot;/&gt;&lt;br/&gt;图示部分为下载链接,我们选择.net framework 4.6+&lt;/p&gt;
&lt;blockquote readability=&quot;9&quot;&gt;
&lt;p&gt;注意,这里下载链接的名称虽然是for .net framework 4.6+,实际上仍然支持.net 4.0及以上版本,并不是只支持.net 4.6以上版本.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;下载完成后,我们把压缩包解压到一个目录,并把&lt;em&gt;&lt;code&gt;目录地址添加到系统环境变量里&lt;/code&gt;&lt;/em&gt;.&lt;/p&gt;
&lt;blockquote readability=&quot;11&quot;&gt;
&lt;p&gt;同样,为了方便使用,我们也需要把msbuild.exe添加到环境变量中,如果你的系统中安装的visual Studio开发工具,则Visual studio中会自动包含一个msbuild.exe我们找到它的路径添加到系统环境变量path中.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&quot;配置sonarqube.analysis.xml文件&quot;&gt;&lt;code&gt;配置SonarQube.Analysis.xml文件&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;由于Scanner要通过rest api方式向服务器提交数据,这里需要对Sonarqube web服务器地址和用户名进行配置才能正常提交数据,我们打开刚解压的目录,找到&lt;code&gt;SonarQube.Analysis.xml&lt;/code&gt;文件,添加以下三行配置即可&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;&amp;lt;Property Name=&quot;sonar.host.url&quot;&amp;gt;http://localhost:9000&amp;lt;/Property&amp;gt;

  &amp;lt;Property Name=&quot;sonar.login&quot;&amp;gt;admin&amp;lt;/Property&amp;gt;
  &amp;lt;Property Name=&quot;sonar.password&quot;&amp;gt;admin&amp;lt;/Property&amp;gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;以上配置很容易理解,url为Sonarqube服务器地址,下面为登陆名和密码(Sonarqube默认带一个管理员账号,用户名为admin密码也是admin,后面我们会讲在生产环境中如何更改admin密码)&lt;/p&gt;
&lt;p&gt;再次回到刚才的下载页面,定位到usage栏,可以看到有一个简短的示例代码如下&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;SonarScanner.MSBuild.exe begin /k:&quot;project-key&quot;
MSBuild.exe /t:Rebuild
SonarScanner.MSBuild.exe end&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;我们依照这段代码的结构,对本地的一个项目进行编译(可以是任意c#项目),进入项目sln或者csproj所在的文件夹下&lt;code&gt;依次&lt;/code&gt;执行以下代码&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;SonarScanner.MSBuild.exe begin /k:&quot;mygetdata&quot; /v:&quot;1.0&quot;
MSBuild.exe /t:Rebuild
SonarScanner.MSBuild.exe end&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;第二段是执行msbuild,第三段是一个结束标志,没有什么需要详细说明的,关于msbuild构建的详细信息可以查看微软官网,也可以参照本教程其它章节.这里简要介绍下第一段的/k和/v参数,/k为key的缩写,Sonarqube每一个项目都要有一个惟一key,key的规则可以自己定,但是需要方便管理,/v为version,如果两个构建的key相同,verison不同,Sonarqube会生成一个对比以便直观看到两次构建的差异,这样方便管理员查看问题的解决情况.&lt;/p&gt;
&lt;p&gt;执行完以上命令后,我们再进入Sonarqube首页,这时候我们点击Login按钮登陆,&lt;code&gt;只有登陆以后才可以看到与项目相关的内容&lt;/code&gt;,点击例如后用户名为admin,密码也是admin(前面说过Sonarqube默认会带一个用户名和密码都是admin的账户,后面我们会讲如何更改密码以及如何为不同的开发者分配账户)&lt;/p&gt;
&lt;p&gt;登陆以后,就会看到一个如下图所示的界面&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/811801/201907/811801-20190723082132744-1986274153.png&quot; alt=&quot;avatar&quot;/&gt;&lt;/p&gt;
&lt;p&gt;从图中我们可以看到我们刚才创建的key 为&lt;code&gt;mygetdata&lt;/code&gt;的构建了,从图中可以简要的看到此项目的严重bug,一般bug,代码不规范,代码单元测试覆盖率,代码重复度,代码最后一次分析时间等.&lt;/p&gt;
&lt;p&gt;我们点击&lt;code&gt;mygetdata&lt;/code&gt;这个标题,便会进去关于这个构建任务的更为详细信息&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/811801/201907/811801-20190723082126339-647200475.png&quot; alt=&quot;avatar&quot;/&gt;&lt;/p&gt;
&lt;p&gt;可以看到信息更为详细,切换上面的导航栏可以看到关于某一个维度的更为详细的信息.&lt;/p&gt;
&lt;blockquote readability=&quot;7&quot;&gt;
&lt;p&gt;图标中的数字大都是可以点击的链接,比如页面中显示bugs为10我们点击&lt;code&gt;10&lt;/code&gt;这个数字可以进入这10个bug的代码详情&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/811801/201907/811801-20190723082120559-1786407431.png&quot; alt=&quot;avatar&quot;/&gt;&lt;/p&gt;
</description>
<pubDate>Tue, 23 Jul 2019 00:24:00 +0000</pubDate>
<dc:creator>周国通</dc:creator>
<og:description>'系列目录' Sonarqube下载与安装 Sonarqube下载地址是: 下载版本有两个,一个是长期支持版,另一个是最新版,此处安装的是最新版,目前版本是7.3,下载的时候点击醒目的蓝色按钮即可(此</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/tylerzhou/p/11229548.html</dc:identifier>
</item>
<item>
<title>机器学习-层次聚类（划分聚类） - Timcode</title>
<link>http://www.cnblogs.com/TimVerion/p/11229542.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/TimVerion/p/11229542.html</guid>
<description>&lt;p&gt;&lt;span class=&quot;md-line md-end-block&quot;&gt;&lt;span&gt;&lt;strong&gt;聚类&lt;/strong&gt;&lt;span&gt;就是对大量未知标注的数据集，按照数据内部存在的数据特征将数据集划分为多个不同的类别，使类别内的数据比较相似，类别之间的数据相似度比较小；&lt;span class=&quot;md-line md-end-block&quot;&gt;&lt;span&gt;属于无监督学习。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;md-line md-end-block&quot;&gt;&lt;span&gt;&lt;strong&gt;算法步骤&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;md-line md-end-block&quot;&gt;&lt;span&gt;1.初始化的k个中心点&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;md-line md-end-block&quot;&gt;&lt;span&gt;&lt;span class=&quot;md-line md-end-block&quot;&gt;&lt;span&gt;2.为每个样本根据距离分配类别&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;md-line md-end-block&quot;&gt;&lt;span&gt;&lt;span class=&quot;md-line md-end-block&quot;&gt;&lt;span&gt;&lt;span class=&quot;md-line md-end-block&quot;&gt;&lt;span&gt;3.更新每个类别的中心点（更新为该类别的所有样本的均值）&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;md-line md-end-block&quot;&gt;&lt;span&gt;&lt;span class=&quot;md-line md-end-block&quot;&gt;&lt;span&gt;&lt;span class=&quot;md-line md-end-block&quot;&gt;&lt;span&gt;&lt;span class=&quot;md-line md-end-block&quot;&gt;&lt;span&gt;4.重复上面两步操作，直到达到某个中止条件&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span class=&quot;md-line md-end-block&quot;&gt;&lt;span&gt;层次聚类方法对给定的数据集进行层次的分解，直到满足某种条件为止，传统的层次聚类算法主要分为两大类算法：&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h2 class=&quot;md-end-block md-heading&quot;&gt;&lt;span&gt;凝聚的层次聚类&lt;/span&gt;&lt;/h2&gt;
&lt;p&gt;&lt;span class=&quot;md-line md-end-block&quot;&gt;&lt;span&gt;&lt;strong&gt;AGNES算法&lt;/strong&gt;&lt;span&gt;==&amp;gt;采用自底向上的策略。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;&lt;span class=&quot;md-line md-end-block&quot;&gt;&lt;span&gt;agglomerative（凝聚） nesting（嵌套）&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;span class=&quot;md-line md-end-block&quot;&gt;&lt;span&gt;最初将每个对象作为一个簇，然后这些簇根据&lt;span&gt;&lt;strong&gt;某些准则&lt;/strong&gt;&lt;span&gt;（两个簇之间的相似度度量方式）被一步一步合并，两个簇间的距离可以由这两个不同簇中距离最近的数据点的相似度来确定；聚类的合并过程反复进行直到所有的对象满足簇数目。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span class=&quot;md-line md-end-block&quot;&gt;&lt;span&gt;&lt;strong&gt;AGNES就是把每个水果当成一个类别，然后再进行聚类。&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;md-line md-end-block&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1507784/201907/1507784-20190723072745392-2015409232.jpg&quot; alt=&quot;&quot;/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span class=&quot;md-line md-end-block&quot;&gt;&lt;span class=&quot;md-image md-img-loaded&quot; data-src=&quot;C:/Users/Tim/Desktop/pic/c5/u=675507662,1540251729&amp;amp;fm=26&amp;amp;gp=0.jpg&quot;&gt;&lt;img src=&quot;file://c/Users/Tim/Desktop/pic/c5/u=675507662,1540251729&amp;amp;fm=26&amp;amp;gp=0.jpg?lastModify=1563837997&quot; alt=&quot;&quot;/&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;md-line md-end-block&quot;&gt;&lt;span&gt;&lt;strong&gt;合并点的选择：&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;ul class=&quot;ul-list&quot; data-mark=&quot;-&quot; readability=&quot;0&quot;&gt;&lt;li class=&quot;md-list-item&quot; readability=&quot;-1&quot;&gt;
&lt;p&gt;&lt;span class=&quot;md-line md-end-block&quot;&gt;&lt;span&gt;两个簇间的最大距离（complete）&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li class=&quot;md-list-item&quot; readability=&quot;-1&quot;&gt;
&lt;p&gt;&lt;span class=&quot;md-line md-end-block&quot;&gt;&lt;span&gt;两个簇间的最小距离（word）&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li class=&quot;md-list-item&quot; readability=&quot;-1&quot;&gt;
&lt;p&gt;&lt;span class=&quot;md-line md-end-block&quot;&gt;&lt;span&gt;两个簇间的平均距离（average）&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;span class=&quot;md-line md-end-block&quot;&gt;&lt;span&gt;&lt;strong&gt;适合链式的聚类，条状的就比较适合。&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;md-line md-end-block&quot;&gt;&lt;span&gt;代码：&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;md-line md-end-block&quot;&gt;&lt;span&gt;linkages ：complete,word,average&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;135&quot;&gt;
&lt;pre&gt;
&lt;span&gt;import&lt;/span&gt;&lt;span&gt; numpy as np
&lt;/span&gt;&lt;span&gt;import&lt;/span&gt;&lt;span&gt; matplotlib as mpl
&lt;/span&gt;&lt;span&gt;import&lt;/span&gt;&lt;span&gt; matplotlib.pyplot as plt
&lt;/span&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt; 调用AGNES&lt;/span&gt;
&lt;span&gt;from&lt;/span&gt; sklearn.cluster &lt;span&gt;import&lt;/span&gt;&lt;span&gt; AgglomerativeClustering
&lt;/span&gt;&lt;span&gt;from&lt;/span&gt; sklearn.neighbors &lt;span&gt;import&lt;/span&gt; kneighbors_graph  &lt;span&gt;#&lt;/span&gt;&lt;span&gt;# KNN的K近邻计算&lt;/span&gt;
&lt;span&gt;import&lt;/span&gt;&lt;span&gt; sklearn.datasets as ds
&lt;/span&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt; 拦截异常信息&lt;/span&gt;
&lt;span&gt;import&lt;/span&gt;&lt;span&gt; warnings
​
warnings.filterwarnings(&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;ignore&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;)
&lt;/span&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt; 设置属性防止中文乱码&lt;/span&gt;
mpl.rcParams[&lt;span&gt;'&lt;/span&gt;&lt;span&gt;font.sans-serif&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;] = [u&lt;span&gt;'&lt;/span&gt;&lt;span&gt;SimHei&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;]
mpl.rcParams[&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;axes.unicode_minus&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;] =&lt;span&gt; False
&lt;/span&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt; 模拟数据产生: 产生600条数据&lt;/span&gt;
&lt;span&gt;np.random.seed(0)
n_clusters &lt;/span&gt;= 4&lt;span&gt;
N &lt;/span&gt;= 1000&lt;span&gt;
data1, y1 &lt;/span&gt;= ds.make_blobs(n_samples=N, n_features=2, centers=((-1, 1), (1, 1), (1, -1), (-1, -1)), random_state=&lt;span&gt;0)
​
n_noise &lt;/span&gt;= int(0.1 *&lt;span&gt; N)
r &lt;/span&gt;= np.random.rand(n_noise, 2&lt;span&gt;)
min1, min2 &lt;/span&gt;= np.min(data1, axis=&lt;span&gt;0)
max1, max2 &lt;/span&gt;= np.max(data1, axis=&lt;span&gt;0)
r[:, 0] &lt;/span&gt;= r[:, 0] * (max1 - min1) +&lt;span&gt; min1
r[:, &lt;/span&gt;1] = r[:, 1] * (max2 - min2) +&lt;span&gt; min2
​
data1_noise &lt;/span&gt;= np.concatenate((data1, r), axis=&lt;span&gt;0)
y1_noise &lt;/span&gt;= np.concatenate((y1, [4] *&lt;span&gt; n_noise))
&lt;/span&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt; 拟合月牙形数据&lt;/span&gt;
data2, y2 = ds.make_moons(n_samples=N, noise=.05&lt;span&gt;)
data2 &lt;/span&gt;=&lt;span&gt; np.array(data2)
n_noise &lt;/span&gt;= int(0.1 *&lt;span&gt; N)
r &lt;/span&gt;= np.random.rand(n_noise, 2&lt;span&gt;)
min1, min2 &lt;/span&gt;= np.min(data2, axis=&lt;span&gt;0)
max1, max2 &lt;/span&gt;= np.max(data2, axis=&lt;span&gt;0)
r[:, 0] &lt;/span&gt;= r[:, 0] * (max1 - min1) +&lt;span&gt; min1
r[:, &lt;/span&gt;1] = r[:, 1] * (max2 - min2) +&lt;span&gt; min2
data2_noise &lt;/span&gt;= np.concatenate((data2, r), axis=&lt;span&gt;0)
y2_noise &lt;/span&gt;= np.concatenate((y2, [3] *&lt;span&gt; n_noise))
​
​
&lt;/span&gt;&lt;span&gt;def&lt;/span&gt;&lt;span&gt; expandBorder(a, b):
    d &lt;/span&gt;= (b - a) * 0.1
    &lt;span&gt;return&lt;/span&gt; a - d, b +&lt;span&gt; d
​
​
&lt;/span&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt;# 画图&lt;/span&gt;&lt;span&gt;
#&lt;/span&gt;&lt;span&gt; 给定画图的颜色&lt;/span&gt;
cm = mpl.colors.ListedColormap([&lt;span&gt;'&lt;/span&gt;&lt;span&gt;#FF0000&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;, &lt;span&gt;'&lt;/span&gt;&lt;span&gt;#00FF00&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;, &lt;span&gt;'&lt;/span&gt;&lt;span&gt;#0000FF&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;, &lt;span&gt;'&lt;/span&gt;&lt;span&gt;#d8e507&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;, &lt;span&gt;'&lt;/span&gt;&lt;span&gt;#F0F0F0&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;])
plt.figure(figsize&lt;/span&gt;=(14, 12), facecolor=&lt;span&gt;'&lt;/span&gt;&lt;span&gt;w&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;)
linkages &lt;/span&gt;= (&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;ward&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;, &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;complete&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;, &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;average&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;)  &lt;span&gt;#&lt;/span&gt;&lt;span&gt; 把几种距离方法，放到list里，后面直接循环取值&lt;/span&gt;
&lt;span&gt;for&lt;/span&gt; index, (n_clusters, data, y) &lt;span&gt;in&lt;/span&gt; enumerate(((4, data1, y1), (4&lt;span&gt;, data1_noise, y1_noise),
                                               (&lt;/span&gt;2, data2, y2), (2&lt;span&gt;, data2_noise, y2_noise))):
    &lt;/span&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt; 前面的两个4表示几行几列，第三个参数表示第几个子图(从1开始，从左往右数)&lt;/span&gt;
    plt.subplot(4, 4, 4 * index + 1&lt;span&gt;)
    plt.scatter(data[:, 0], data[:, &lt;/span&gt;1], c=y, cmap=&lt;span&gt;cm)
    plt.title(u&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;原始数据&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;, fontsize=17&lt;span&gt;)
    plt.grid(b&lt;/span&gt;=True, ls=&lt;span&gt;'&lt;/span&gt;&lt;span&gt;:&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;)
    min1, min2 &lt;/span&gt;= np.min(data, axis=&lt;span&gt;0)
    max1, max2 &lt;/span&gt;= np.max(data, axis=&lt;span&gt;0)
    plt.xlim(expandBorder(min1, max1))
    plt.ylim(expandBorder(min2, max2))
​
    &lt;/span&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt; 计算类别与类别的距离(只计算最接近的七个样本的距离) -- 希望在agens算法中，在计算过程中不需要重复性的计算点与点之间的距离&lt;/span&gt;
    connectivity = kneighbors_graph(data, n_neighbors=7, mode=&lt;span&gt;'&lt;/span&gt;&lt;span&gt;distance&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;, metric=&lt;span&gt;'&lt;/span&gt;&lt;span&gt;minkowski&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;, p=2, include_self=&lt;span&gt;True)
    connectivity &lt;/span&gt;= (connectivity +&lt;span&gt; connectivity.T)
    &lt;/span&gt;&lt;span&gt;for&lt;/span&gt; i, linkage &lt;span&gt;in&lt;/span&gt;&lt;span&gt; enumerate(linkages):
        &lt;/span&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt;#进行建模，并传值&lt;/span&gt;
        ac = AgglomerativeClustering(n_clusters=n_clusters, affinity=&lt;span&gt;'&lt;/span&gt;&lt;span&gt;euclidean&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;,
                                     connectivity&lt;/span&gt;=connectivity, linkage=&lt;span&gt;linkage)
        ac.fit(data)
        y &lt;/span&gt;=&lt;span&gt; ac.labels_
​
        plt.subplot(&lt;/span&gt;4, 4, i + 2 + 4 *&lt;span&gt; index)
        plt.scatter(data[:, 0], data[:, &lt;/span&gt;1], c=y, cmap=&lt;span&gt;cm)
        plt.title(linkage, fontsize&lt;/span&gt;=17&lt;span&gt;)
        plt.grid(b&lt;/span&gt;=True, ls=&lt;span&gt;'&lt;/span&gt;&lt;span&gt;:&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;)
        plt.xlim(expandBorder(min1, max1))
        plt.ylim(expandBorder(min2, max2))
​
plt.tight_layout(&lt;/span&gt;0.5, rect=(0, 0, 1, 0.95&lt;span&gt;))
plt.show()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span class=&quot;md-line md-end-block&quot;&gt;&lt;span&gt;AGNES使用不同合并方式的结果：&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;md-line md-end-block&quot;&gt;&lt;span class=&quot;md-image md-img-loaded&quot; data-src=&quot;C:/Users/Tim/Desktop/pic/c5/2019-07-22_203003.png&quot;&gt;&lt;img src=&quot;file://c/Users/Tim/Desktop/pic/c5/2019-07-22_203003.png?lastModify=1563837997&quot; alt=&quot;&quot;/&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt; &lt;img src=&quot;https://img2018.cnblogs.com/blog/1507784/201907/1507784-20190723072905339-1694078291.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;h2 class=&quot;md-end-block md-heading&quot;&gt;&lt;span&gt;分裂的层次聚类（类似于决策树）&lt;/span&gt;&lt;/h2&gt;
&lt;p&gt;&lt;span class=&quot;md-line md-end-block&quot;&gt;&lt;span&gt;&lt;strong&gt;DIANA算法&lt;/strong&gt;&lt;span&gt;==&amp;gt;采用自顶向下的策略。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;&lt;span class=&quot;md-line md-end-block&quot;&gt;&lt;span&gt;divisive(分裂) analysis(分析)&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;span class=&quot;md-line md-end-block&quot;&gt;&lt;span&gt;首先将所有对象置于一个簇中，然后按照某种既定的规则&lt;span&gt;&lt;strong&gt;逐渐细分&lt;/strong&gt;&lt;span&gt;为越来越小的簇(比如利用kmeans)，直到达到某个终结条件(簇数目或者簇距离达到阈值)。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;md-line md-end-block&quot;&gt;&lt;span&gt;1，将所有样本数据作为一个簇放到一个队列中&lt;span class=&quot;md-line md-end-block&quot;&gt;&lt;span&gt;2，划分为两个子簇(初始化两个中心点进行聚类)，并将子簇添加到队列中&lt;span class=&quot;md-line md-end-block&quot;&gt;&lt;span&gt;3，循环迭代第二步操作，直到中止条件达到(&lt;span&gt;&lt;strong&gt;聚簇数量&lt;/strong&gt;&lt;span&gt;、&lt;span&gt;&lt;strong&gt;最小平方误差&lt;/strong&gt;&lt;span&gt;、&lt;span&gt;&lt;strong&gt;迭代次数&lt;/strong&gt;&lt;span&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;md-line md-end-block&quot;&gt;&lt;span&gt;&lt;strong&gt;分割点的选择：&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;md-line md-end-block&quot;&gt;&lt;span&gt;&lt;strong&gt;DIANA类似于分面包&lt;/strong&gt;&lt;span class=&quot;md-image md-img-loaded&quot; data-src=&quot;C:/Users/Tim/Desktop/pic/c5/u=330113520,501582089&amp;amp;fm=26&amp;amp;gp=0.jpg&quot;&gt;&lt;img src=&quot;file://c/Users/Tim/Desktop/pic/c5/u=330113520,501582089&amp;amp;fm=26&amp;amp;gp=0.jpg?lastModify=1563837997&quot; alt=&quot;&quot;/&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt; &lt;img src=&quot;https://img2018.cnblogs.com/blog/1507784/201907/1507784-20190723072919401-529519776.jpg&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;h2 class=&quot;md-end-block md-heading&quot;&gt;&lt;span&gt;AGNES和DIANA&lt;/span&gt;&lt;/h2&gt;
&lt;ul class=&quot;ul-list&quot; data-mark=&quot;-&quot; readability=&quot;0&quot;&gt;&lt;li class=&quot;md-list-item&quot;&gt;
&lt;p&gt;&lt;span class=&quot;md-line md-end-block&quot;&gt;&lt;span&gt;简单，理解容易&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li class=&quot;md-list-item&quot; readability=&quot;-1&quot;&gt;
&lt;p&gt;&lt;span class=&quot;md-line md-end-block&quot;&gt;&lt;span&gt;合并点/分裂点选择不太容易&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li class=&quot;md-list-item&quot; readability=&quot;-1&quot;&gt;
&lt;p&gt;&lt;span class=&quot;md-line md-end-block&quot;&gt;&lt;span&gt;合并/分类的操作不能进行撤销（面包切开就合不上了）&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li class=&quot;md-list-item&quot;&gt;
&lt;p&gt;&lt;span class=&quot;md-line md-end-block&quot;&gt;&lt;span&gt;大数据集不太适合&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li class=&quot;md-list-item&quot; readability=&quot;-1&quot;&gt;
&lt;p&gt;&lt;span class=&quot;md-line md-end-block&quot;&gt;&lt;span&gt;执行效率较低O(t*n2)，t为迭代次数，n为样本点数&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;h2 class=&quot;md-end-block md-heading&quot;&gt;&lt;span&gt;AGNES的优化&lt;/span&gt;&lt;/h2&gt;
&lt;h3 class=&quot;md-end-block md-heading&quot;&gt;&lt;span&gt;BIRCH(掌握)&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;&lt;span class=&quot;md-line md-end-block&quot;&gt;&lt;span&gt;BIRCH算法(平衡迭代削减聚类法)：&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;md-line md-end-block&quot;&gt;&lt;span&gt;聚类特征使用&lt;span&gt;&lt;strong&gt;3元组&lt;/strong&gt;&lt;span&gt;进行一个簇的相关信息，通过构建满足分枝因子和簇直径限制的聚类特征树来求聚类，聚类特征树其实是一个具有两个参数分枝因子和类直径的高度平衡树；分枝因子规定了树的每个节点的子女的最多个数，而类直径体现了对这一类点的距离范围；非叶子节点为它子女的最大特征值；&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;&lt;span class=&quot;md-line md-end-block&quot;&gt;&lt;span&gt;聚类特征树的构建可以是动态过程的，可以随时根据数据对模型进行更新操作。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;span class=&quot;md-line md-end-block&quot;&gt;&lt;span class=&quot;md-image md-img-loaded&quot; data-src=&quot;C:/Users/Tim/Desktop/pic/c5/BIRCH%E7%AE%97%E6%B3%95.png&quot;&gt;&lt;img src=&quot;file://c/Users/Tim/Desktop/pic/c5/BIRCH算法.png?lastModify=1563837997&quot; alt=&quot;&quot;/&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt; &lt;strong&gt;&lt;span class=&quot;md-expand&quot;&gt;三元组&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1507784/201907/1507784-20190723081841994-1406459038.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;span class=&quot;md-expand&quot;&gt;BIRCH的构造&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt; &lt;img src=&quot;https://img2018.cnblogs.com/blog/1507784/201907/1507784-20190723081847267-190221160.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;&lt;span class=&quot;md-line md-end-block&quot;&gt;&lt;span&gt;从根节点到叶子节点一层一层的取判断，&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;md-line md-end-block&quot;&gt;&lt;span&gt;优缺点：&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;ul class=&quot;ul-list&quot; data-mark=&quot;-&quot; readability=&quot;-0.5&quot;&gt;&lt;li class=&quot;md-list-item&quot; readability=&quot;-1&quot;&gt;
&lt;p&gt;&lt;span class=&quot;md-line md-end-block&quot;&gt;&lt;span&gt;适合大规模数据集，线性效率；&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li class=&quot;md-list-item&quot; readability=&quot;0&quot;&gt;
&lt;p&gt;&lt;span class=&quot;md-line md-end-block&quot;&gt;&lt;span&gt;只适合分布呈凸形或者球形的数据集、需要给定聚类个数和簇之间的相关参数&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;span class=&quot;md-line md-end-block&quot;&gt;&lt;span&gt;代码实现：&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;md-line md-end-block&quot;&gt;&lt;span&gt;库参数：&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;ol class=&quot;ol-list&quot; start=&quot;&quot; readability=&quot;-2&quot;&gt;&lt;li class=&quot;md-list-item&quot;&gt;
&lt;p&gt;&lt;span class=&quot;md-line md-end-block&quot;&gt;&lt;span&gt;threshold 类直径&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li class=&quot;md-list-item&quot; readability=&quot;-1&quot;&gt;
&lt;p&gt;&lt;span class=&quot;md-line md-end-block&quot;&gt;&lt;span&gt;branshing_factor 分支因子&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li class=&quot;md-list-item&quot;&gt;
&lt;p&gt;&lt;span class=&quot;md-line md-end-block&quot;&gt;&lt;span&gt;n_clusters 簇个数&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;&lt;pre class=&quot;md-fences md-end-block&quot;&gt;
&lt;/pre&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;93&quot;&gt;
&lt;pre&gt;
&lt;span&gt;from&lt;/span&gt; itertools &lt;span&gt;import&lt;/span&gt;&lt;span&gt; cycle
&lt;/span&gt;&lt;span&gt;from&lt;/span&gt; time &lt;span&gt;import&lt;/span&gt;&lt;span&gt; time
&lt;/span&gt;&lt;span&gt;import&lt;/span&gt;&lt;span&gt; numpy as np
&lt;/span&gt;&lt;span&gt;import&lt;/span&gt;&lt;span&gt; matplotlib as mpl
&lt;/span&gt;&lt;span&gt;import&lt;/span&gt;&lt;span&gt; matplotlib.pyplot as plt
&lt;/span&gt;&lt;span&gt;import&lt;/span&gt;&lt;span&gt; matplotlib.colors as colors
​
&lt;/span&gt;&lt;span&gt;from&lt;/span&gt; sklearn.cluster &lt;span&gt;import&lt;/span&gt;&lt;span&gt; Birch
&lt;/span&gt;&lt;span&gt;from&lt;/span&gt; sklearn.datasets.samples_generator &lt;span&gt;import&lt;/span&gt;&lt;span&gt; make_blobs
​
&lt;/span&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt;# 设置属性防止中文乱码&lt;/span&gt;
mpl.rcParams[&lt;span&gt;'&lt;/span&gt;&lt;span&gt;font.sans-serif&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;] = [u&lt;span&gt;'&lt;/span&gt;&lt;span&gt;SimHei&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;]
mpl.rcParams[&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;axes.unicode_minus&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;] =&lt;span&gt; False
&lt;/span&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt;# 产生模拟数据&lt;/span&gt;
xx = np.linspace(-22, 22, 10&lt;span&gt;)
yy &lt;/span&gt;= np.linspace(-22, 22, 10&lt;span&gt;)
xx, yy &lt;/span&gt;=&lt;span&gt; np.meshgrid(xx, yy)
n_centres &lt;/span&gt;=&lt;span&gt; np.hstack((np.ravel(xx)[:, np.newaxis],
                       np.ravel(yy)[:, np.newaxis]))
&lt;/span&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt; 产生10万条特征属性是2，类别是100,符合高斯分布的数据集&lt;/span&gt;
X, y = make_blobs(n_samples=100000, n_features=2, centers=n_centres, random_state=28&lt;span&gt;)
&lt;/span&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt; 创建不同的参数（簇直径）Birch层次聚类&lt;/span&gt;
birch_models =&lt;span&gt; [
    Birch(threshold&lt;/span&gt;=1.7, n_clusters=&lt;span&gt;None),
    Birch(threshold&lt;/span&gt;=0.5, n_clusters=&lt;span&gt;None),
    Birch(threshold&lt;/span&gt;=1.7, n_clusters=100&lt;span&gt;)
]
&lt;/span&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt; threshold：簇直径的阈值，    branching_factor：大叶子个数&lt;/span&gt;
&lt;span&gt;​
&lt;/span&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt; 我们也可以加参数来试一下效果，比如加入分支因子branching_factor，给定不同的参数值，看聚类的结果&lt;/span&gt;&lt;span&gt;
#&lt;/span&gt;&lt;span&gt;# 画图&lt;/span&gt;
final_step = [u&lt;span&gt;'&lt;/span&gt;&lt;span&gt;直径=1.7;n_lusters=None&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;, u&lt;span&gt;'&lt;/span&gt;&lt;span&gt;直径=0.5;n_clusters=None&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;, u&lt;span&gt;'&lt;/span&gt;&lt;span&gt;直径=1.7;n_lusters=100&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;]
​
plt.figure(figsize&lt;/span&gt;=(12, 8), facecolor=&lt;span&gt;'&lt;/span&gt;&lt;span&gt;w&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;)
plt.subplots_adjust(left&lt;/span&gt;=0.02, right=0.98, bottom=0.1, top=0.9&lt;span&gt;)
colors_ &lt;/span&gt;=&lt;span&gt; cycle(colors.cnames.keys())
cm &lt;/span&gt;=&lt;span&gt; mpl.colors.ListedColormap(colors.cnames.keys())
​
&lt;/span&gt;&lt;span&gt;for&lt;/span&gt; ind, (birch_model, info) &lt;span&gt;in&lt;/span&gt;&lt;span&gt; enumerate(zip(birch_models, final_step)):
    t &lt;/span&gt;=&lt;span&gt; time()
    birch_model.fit(X)
    time_ &lt;/span&gt;= time() -&lt;span&gt; t
    &lt;/span&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt; 获取模型结果（label和中心点）&lt;/span&gt;
    labels =&lt;span&gt; birch_model.labels_
    centroids &lt;/span&gt;=&lt;span&gt; birch_model.subcluster_centers_
    n_clusters &lt;/span&gt;=&lt;span&gt; len(np.unique(centroids))
    &lt;/span&gt;&lt;span&gt;print&lt;/span&gt;(&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;Birch算法，参数信息为：%s；模型构建消耗时间为:%.3f秒；聚类中心数目:%d&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; %&lt;span&gt; (info, time_, len(np.unique(labels))))
​
    &lt;/span&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt; 画图&lt;/span&gt;
    subinx = 221 +&lt;span&gt; ind
    plt.subplot(subinx)
    &lt;/span&gt;&lt;span&gt;for&lt;/span&gt; this_centroid, k, col &lt;span&gt;in&lt;/span&gt;&lt;span&gt; zip(centroids, range(n_clusters), colors_):
        mask &lt;/span&gt;= labels ==&lt;span&gt; k
        plt.plot(X[mask, 0], X[mask, &lt;/span&gt;1], &lt;span&gt;'&lt;/span&gt;&lt;span&gt;w&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;, markerfacecolor=col, marker=&lt;span&gt;'&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;)
        &lt;/span&gt;&lt;span&gt;if&lt;/span&gt; birch_model.n_clusters &lt;span&gt;is&lt;/span&gt;&lt;span&gt; None:
            plt.plot(this_centroid[0], this_centroid[&lt;/span&gt;1], &lt;span&gt;'&lt;/span&gt;&lt;span&gt;*&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;, markerfacecolor=col, markeredgecolor=&lt;span&gt;'&lt;/span&gt;&lt;span&gt;k&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;, markersize=2&lt;span&gt;)
    plt.ylim([&lt;/span&gt;-25, 25&lt;span&gt;])
    plt.xlim([&lt;/span&gt;-25, 25&lt;span&gt;])
    plt.title(u&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;Birch算法%s，耗时%.3fs&lt;/span&gt;&lt;span&gt;'&lt;/span&gt; %&lt;span&gt; (info, time_))
    plt.grid(False)
​
&lt;/span&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt; 原始数据集显示&lt;/span&gt;
plt.subplot(224&lt;span&gt;)
plt.scatter(X[:, 0], X[:, &lt;/span&gt;1], c=y, s=1, cmap=cm, edgecolors=&lt;span&gt;'&lt;/span&gt;&lt;span&gt;none&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;)
plt.ylim([&lt;/span&gt;-25, 25&lt;span&gt;])
plt.xlim([&lt;/span&gt;-25, 25&lt;span&gt;])
plt.title(u&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;原始数据&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;)
plt.grid(False)
​
plt.show()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span class=&quot;md-line md-end-block&quot;&gt;&lt;span&gt;运行结果：&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;blockquote readability=&quot;10&quot;&gt;
&lt;p&gt;&lt;span class=&quot;md-line md-end-block&quot;&gt;&lt;span&gt;Birch算法，参数信息为：直径=1.7;n_lusters=None；模型构建消耗时间为:2.510秒；聚类中心数目:171&lt;span class=&quot;md-line md-end-block&quot;&gt;&lt;span&gt;Birch算法，参数信息为：直径=0.5;n_clusters=None；模型构建消耗时间为:6.689秒；聚类中心数目:3205&lt;span class=&quot;md-line md-end-block&quot;&gt;&lt;span&gt;Birch算法，参数信息为：直径=1.7;n_lusters=100；模型构建消耗时间为:3.013秒；聚类中心数目:100&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;md-line md-end-block&quot;&gt;&lt;span&gt;Process finished with exit code 0&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;span class=&quot;md-line md-end-block&quot;&gt;&lt;span class=&quot;md-image md-img-loaded&quot; data-src=&quot;C:/Users/Tim/AppData/Local/Temp/1563798992552.png&quot;&gt;&lt;img src=&quot;file://c/Users/Tim/AppData/Local/Temp/1563798992552.png?lastModify=1563837997&quot; alt=&quot;&quot;/&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h3 class=&quot;md-end-block md-heading&quot;&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1507784/201907/1507784-20190723073342988-1501691085.png&quot; alt=&quot;&quot;/&gt;&lt;/h3&gt;

&lt;h3 class=&quot;md-end-block md-heading&quot;&gt;&lt;span&gt;CURE(没人用)&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;&lt;span class=&quot;md-line md-end-block&quot;&gt;&lt;span&gt;CURE算法(使用代表点的聚类法)：&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;md-line md-end-block&quot;&gt;&lt;span&gt;该算法先把每个数据点看成一类，然后合并距离最近的类直至类个数为所要求的个数为止。但是和AGNES算法的区别是：&lt;span&gt;&lt;strong&gt;取消了使用所有点或用中心点+距离来表示一个类&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;md-line md-end-block&quot;&gt;&lt;span&gt;而是从每个类中抽取&lt;span&gt;&lt;strong&gt;固定数量、分布较好&lt;/strong&gt;&lt;span&gt;的点作为此类的代表点，并将这些代表点乘以一个适当的收缩因子，使它们更加靠近类中心点。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;md-line md-end-block&quot;&gt;&lt;span&gt;代表点的收缩特性可以调整模型可以匹配那些非球形的场景，而且收缩因子的使用可以减少噪音对聚类的影响。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;md-line md-end-block&quot;&gt;&lt;span&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1507784/201907/1507784-20190723073333584-1358843218.png&quot; alt=&quot;&quot;/&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span class=&quot;md-line md-end-block&quot;&gt;&lt;span class=&quot;md-image md-img-loaded&quot; data-src=&quot;C:/Users/Tim/Desktop/pic/c5/2019-07-22_220143.png&quot;&gt;&lt;img src=&quot;file://c/Users/Tim/Desktop/pic/c5/2019-07-22_220143.png?lastModify=1563837997&quot; alt=&quot;&quot;/&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;md-line md-end-block&quot;&gt;&lt;span&gt;找几个特殊的点来代替整个类别中的样本&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;md-line md-end-block&quot;&gt;&lt;span&gt;优缺点：&lt;span class=&quot;md-line md-end-block&quot;&gt;&lt;span&gt;能够处理非球形分布的应用场景&lt;span class=&quot;md-line md-end-block&quot;&gt;&lt;span&gt;采用随机抽样和分区的方式可以提高算法的执行效率&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
</description>
<pubDate>Tue, 23 Jul 2019 00:19:00 +0000</pubDate>
<dc:creator>Timcode</dc:creator>
<og:description>层次聚类（划分聚类） 聚类就是对大量未知标注的数据集，按照数据内部存在的数据特征将数据集划分为多个不同的类别，使类别内的数据比较相似，类别之间的数据相似度比较小；属于无监督学习。 算法步骤 1.初始化</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/TimVerion/p/11229542.html</dc:identifier>
</item>
<item>
<title>小代学Spring Boot之自定义Starter - 代码无止境</title>
<link>http://www.cnblogs.com/endless-code/p/11229526.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/endless-code/p/11229526.html</guid>
<description>&lt;blockquote readability=&quot;3.943661971831&quot;&gt;
&lt;p&gt;想要获取更多文章可以访问我的博客 - &lt;a href=&quot;https://itweknow.cn&quot;&gt;代码无止境&lt;/a&gt;。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;使用Spring Boot框架一段时间之后的小代同学，发现在Spring Boot项目中经常会引入各种各样的Starter，例如Web项目的&lt;code&gt;spring-boot-starter-web&lt;/code&gt;以及集成MyBatis时的&lt;code&gt;mybatis-spring-boot-starter&lt;/code&gt;。那么这个Starter到底是些什么呢？&lt;/p&gt;
&lt;h3 id=&quot;什么是starter&quot;&gt;什么是Starter&lt;/h3&gt;
&lt;p&gt;经过一番研究，小代同学了解到&lt;code&gt;Starter&lt;/code&gt;主要是Spring Boot用来简化项目依赖的一种形式，比如&lt;code&gt;spring-boot-starter-web&lt;/code&gt;中包含了一个Web项目通常所需要的依赖，这样我们就只需要依赖一个&lt;code&gt;Starter&lt;/code&gt;即可，无需一个一个的添加所有的Web项目所需的Jar包，而且我们还可以通过&lt;code&gt;Starter&lt;/code&gt;来做一些自动配置。&lt;/p&gt;
&lt;p&gt;作为一个喜欢研究的程序员，小代同学就想能不能将之前连接MyBatis的过程封装成一个&lt;code&gt;Starter&lt;/code&gt;，这样以后其他项目集成MyBatis就会简单许多了。如果你想了解Spring Boot集成MyBatis相关的内容，可以查看之前的文章&lt;a href=&quot;https://itweknow.cn/blog-site/posts/87120304.html&quot;&gt;《小代学Spring Boot之集成MyBatis》&lt;/a&gt;。在开始实现之前，小代同学查询了一下&lt;code&gt;Starter&lt;/code&gt;的命名规范。&lt;/p&gt;
&lt;h3 id=&quot;starter的命名规范&quot;&gt;Starter的命名规范&lt;/h3&gt;
&lt;p&gt;1.Spring Boot自己提供的一些Starter的命名一般以&lt;code&gt;spring-boot-starter-xxx&lt;/code&gt;命名，例如&lt;code&gt;spring-boot-starter-web&lt;/code&gt;。&lt;br/&gt;2.我们自己定义的&lt;code&gt;Starter&lt;/code&gt;通常情况下以&lt;code&gt;xxx-spring-boot-starter&lt;/code&gt;的形式命名。&lt;/p&gt;
&lt;h3 id=&quot;自定义starter&quot;&gt;自定义Starter&lt;/h3&gt;
&lt;p&gt;知道如何命名一个自定义&lt;code&gt;Starter&lt;/code&gt;之后，小代同学根据命名的建议新建了一个&lt;code&gt;mybatis-config-spring-boot-starter&lt;/code&gt;的项目。并且将之前集成MyBatis时候添加的依赖全部添加进来了。&lt;br/&gt;添加完依赖之后，我们还需要一个配置类用来在项目启动时自动配置连接池以及扫描Mapper文件。所以小代同学新建了一个&lt;code&gt;MyBatisAutoConfiguration&lt;/code&gt;类来做这些东西。&lt;/p&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;@Configuration
@EnableConfigurationProperties({MyBatisProperties.class, DruidDataSourceProperties.class})
public class MyBatisAutoConfiguration {

    @Autowired
    private MyBatisProperties myBatisProperties;

    @Autowired
    private DruidDataSourceProperties druidDataSourceProperties;

    ...此处省略若干代码。

    @Bean(name = &quot;sqlSessionFactory&quot;)
    @ConditionalOnMissingBean(name = &quot;sqlSessionFactory&quot;)
    public SqlSessionFactory sqlSessionFactory(@Qualifier(&quot;druidDataSource&quot;) DruidDataSource druidDataSource) throws Exception {
        final SqlSessionFactoryBean sessionFactory = new SqlSessionFactoryBean();
        sessionFactory.setDataSource(druidDataSource);
        sessionFactory.setMapperLocations(new PathMatchingResourcePatternResolver()
                .getResources(myBatisProperties.getMapperXmlLocation()));
        return sessionFactory.getObject();
    }

}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;由于与之前集成MyBatis的配置大体一致，所以上面粘贴的代码有很多被省略的部分，您可以在&lt;a href=&quot;https://github.com/ganchaoyang/spring-tutorial/tree/master/starter&quot;&gt;源码&lt;/a&gt;中找到。其实也就是将之前集成MyBatis的配置Copy过来然后稍作修改，主要有以下几点修改：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;定义了&lt;code&gt;MyBatisProperties&lt;/code&gt;类，这个类主要是从配置文件中读取Mapper.xml的地址。配置会话工厂&lt;code&gt;sqlSessionFactory&lt;/code&gt;的时候设置的MapperLocation的路径就是从这里获取的。&lt;/li&gt;
&lt;li&gt;去除了之前配置类上的&lt;code&gt;@MapperScan&lt;/code&gt;注解，去掉的原因是我没有找到在注解中如何获取配置文件中的值，所以将它挪到了使用这个&lt;code&gt;Starter&lt;/code&gt;的项目的启动类上。&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;编写完上面的自动配置类后，我们需要做的是让Spring Boot知道在启动的时候需要执行这个配置类中的代码，实现的方式是在&lt;code&gt;resources&lt;/code&gt;文件夹下新建&lt;code&gt;META-INF/spring.factories&lt;/code&gt;文件，里面的内容如下所示。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;org.springframework.boot.autoconfigure.EnableAutoConfiguration=\
cn.itweknow.mybatisconfigspringbootstarter.config.MyBatisAutoConfiguration&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;好了，到这一步我们集成MyBatis的&lt;code&gt;Starter&lt;/code&gt;就已经完工了，接下来我们就来准备一个项目来测试一下吧。&lt;/p&gt;
&lt;h3 id=&quot;starter的使用&quot;&gt;Starter的使用&lt;/h3&gt;
&lt;p&gt;小代同学为了测试自己定义的&lt;code&gt;Starter&lt;/code&gt;，特地新建了一个项目&lt;code&gt;starter-test&lt;/code&gt;。然后小代同学充满信心地将上面定义的&lt;code&gt;Starter&lt;/code&gt;添加到了测试项目中。&lt;/p&gt;
&lt;pre class=&quot;xml&quot;&gt;
&lt;code&gt;&amp;lt;dependency&amp;gt;
    &amp;lt;groupId&amp;gt;cn.itweknow&amp;lt;/groupId&amp;gt;
    &amp;lt;artifactId&amp;gt;mybatis-config-spring-boot-starter&amp;lt;/artifactId&amp;gt;
    &amp;lt;version&amp;gt;0.0.1-SNAPSHOT&amp;lt;/version&amp;gt;
&amp;lt;/dependency&amp;gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;添加了依赖之后，小代同学编写了一些简单的测试代码，具体的测试代码在这里就不贴出来了，大家可以在&lt;a href=&quot;https://github.com/ganchaoyang/spring-tutorial/tree/master/starter&quot;&gt;源码&lt;/a&gt;中找到。但是第一次测试不幸的失败了，失败的原因是Mapper类都没有被初始化，原来是忘了在启动类上添加&lt;code&gt;@MapperScan&lt;/code&gt;注解，加上之后就可以完成测试了。&lt;/p&gt;
&lt;h3 id=&quot;结束语&quot;&gt;结束语&lt;/h3&gt;
&lt;p&gt;本文主要以Spring Boot集成MyBatis为例带大家一起了解了一下如何实现一个Spring Boot项目的&lt;code&gt;Starter&lt;/code&gt;。但是在实现过程中有一点点遗憾，就是没有找到在&lt;code&gt;@MapperScan&lt;/code&gt;里使用配置文件中配置的包路径的方法，如果您知道的话欢迎提交&lt;code&gt;Pull Request&lt;/code&gt;。本文的&lt;a href=&quot;https://github.com/ganchaoyang/spring-tutorial/tree/master/starter&quot;&gt;完整实现&lt;/a&gt;您可以在Github上找到，如果您喜欢这篇文章的话可以给个Star哦。&lt;/p&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;PS:学习不止，码不停蹄！如果您喜欢我的文章，就关注我吧！&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div align=&quot;center&quot;&gt;&lt;img src=&quot;https://g-blog.oss-cn-beijing.aliyuncs.com/image/qrcode_for_gh_526c6f450b21_258.jpg&quot; alt=&quot;扫码关注“代码无止境”&quot;/&gt;&lt;/div&gt;
</description>
<pubDate>Tue, 23 Jul 2019 00:12:00 +0000</pubDate>
<dc:creator>代码无止境</dc:creator>
<og:description>想要获取更多文章可以访问我的博客 '代码无止境' 。 使用Spring Boot框架一段时间之后的小代同学，发现在Spring Boot项目中经常会引入各种各样的Starter，例如Web项目的 以及</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/endless-code/p/11229526.html</dc:identifier>
</item>
<item>
<title>JAVA面试题 线程的生命周期包括哪几个阶段？ - Java蚂蚁</title>
<link>http://www.cnblogs.com/marsitman/p/11228684.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/marsitman/p/11228684.html</guid>
<description>&lt;p&gt;&lt;strong&gt;面试官：您知道线程的生命周期包括哪几个阶段？&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;应聘者：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;线程的生命周期包含5个阶段，包括：新建、就绪、运行、阻塞、销毁。&lt;/p&gt;
&lt;ul class=&quot;list-paddingleft-2&quot; readability=&quot;5&quot;&gt;&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;新建：就是刚使用new方法，new出来的线程；&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;就绪：就是调用的线程的start()方法后，这时候线程处于等待CPU分配资源阶段，谁先抢的CPU资源，谁开始执行;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;运行：当就绪的线程被调度并获得CPU资源时，便进入运行状态，run方法定义了线程的操作和功能;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;2&quot;&gt;
&lt;p&gt;阻塞：在运行状态的时候，可能因为某些原因导致运行状态的线程变成了阻塞状态，比如sleep()、wait()之后线程就处于了阻塞状态，这个时候需要其他机制将处于阻塞状态的线程唤醒，比如调用notify或者notifyAll()方法。唤醒的线程不会立刻执行run方法，它们要再次等待CPU分配资源进入运行状态;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;销毁：如果线程正常执行完毕后或线程被提前强制性的终止或出现异常导致结束，那么线程就要被销毁，释放资源;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;完整的生命周期图如下：&lt;/p&gt;
&lt;p&gt;                                &lt;img src=&quot;https://img2018.cnblogs.com/blog/1223046/201907/1223046-20190722214114154-276488899.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;新建状态&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;我们来看下面一段代码：&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;32&quot;&gt;
&lt;pre class=&quot;brush:java;gutter:true;&quot;&gt;
Thread t1 = new Thread();
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;这里的创建，仅仅是在JAVA的这种编程语言层面被创建，而在操作系统层面，真正的线程还没有被创建。只有当我们调用了 start() 方法之后，该线程才会被创建出来，进入Runnable状态。只有当我们调用了 start() 方法之后，该线程才会被创建出来&lt;/p&gt;
&lt;p&gt;                                                                                      &lt;img src=&quot;https://img2018.cnblogs.com/blog/1223046/201907/1223046-20190722214216437-864622217.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;就绪状态&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;调用start()方法后，JVM 进程会去创建一个新的线程，而此线程不会马上被 CPU 调度运行，进入Running状态，这里会有一个中间状态，就是Runnable状态，你可以理解为等待被 CPU 调度的状态&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot;&gt;
&lt;pre class=&quot;brush:java;gutter:true;&quot;&gt;
t1.start()
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;用一张图表示如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1223046/201907/1223046-20190722214334481-1436365111.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;那么处于Runnable状态的线程能发生哪些状态转变？&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1223046/201907/1223046-20190722214414952-1788624892.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;Runnable状态的线程无法直接进入Blocked状态和Terminated状态的。只有处在Running状态的线程，换句话说，只有获得CPU调度执行权的线程才有资格进入Blocked状态和Terminated状态，Runnable状态的线程要么能被转换成Running状态，要么被意外终止。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;运行状态&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;当CPU调度发生，并从任务队列中选中了某个Runnable线程时，该线程会进入Running执行状态，并且开始调用run()方法中逻辑代码。&lt;/p&gt;
&lt;p&gt;那么处于Running状态的线程能发生哪些状态转变？&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1223046/201907/1223046-20190722214456212-734896654.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;ul class=&quot;list-paddingleft-2&quot; readability=&quot;4&quot;&gt;&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;被转换成Terminated状态，比如调用 stop() 方法;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;被转换成Blocked状态，比如调用了sleep, wait 方法被加入 waitSet 中；&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;被转换成Blocked状态，如进行 IO 阻塞操作，如查询数据库进入阻塞状态；&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;被转换成Blocked状态，比如获取某个锁的释放，而被加入该锁的阻塞队列中；&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;该线程的时间片用完，CPU 再次调度，进入Runnable状态；&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;线程主动调用 yield 方法，让出 CPU 资源，进入Runnable状态&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;阻塞状态&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Blocked状态的线程能够发生哪些状态改变？&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1223046/201907/1223046-20190722214547127-782461177.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;ul class=&quot;list-paddingleft-2&quot; readability=&quot;4&quot;&gt;&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;被转换成Terminated状态，比如调用 stop() 方法，或者是 JVM 意外 Crash;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;被转换成Runnable状态，阻塞时间结束，比如读取到了数据库的数据后；&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;完成了指定时间的休眠，进入到Runnable状态；&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;正在wait中的线程，被其他线程调用notify/notifyAll方法唤醒，进入到Runnable状态；&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;线程获取到了想要的锁资源，进入Runnable状态；&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;线程在阻塞状态下被打断，如其他线程调用了interrupt方法，进入到Runnable状态；&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;终止状态&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;一旦线程进入了Terminated状态，就意味着这个线程生命的终结，哪些情况下，线程会进入到Terminated状态呢？&lt;/p&gt;
&lt;ul class=&quot;list-paddingleft-2&quot; readability=&quot;0&quot;&gt;&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;线程正常运行结束，生命周期结束；&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;线程运行过程中出现意外错误；&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;JVM 异常结束，所有的线程生命周期均被结束。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者：&lt;a href=&quot;https://www.cnblogs.com/marsitman/&quot; target=&quot;_blank&quot;&gt;&lt;span&gt;Java蚂蚁&lt;/span&gt;&lt;/a&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;出处：&lt;a href=&quot;https://www.cnblogs.com/marsitman/p/11228684.html&quot; target=&quot;_blank&quot;&gt;&lt;span&gt;https://www.cnblogs.com/marsitman/p/11228684.html&lt;/span&gt;&lt;/a&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;版权：转载请在文章明显位置注明作者及出处。&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;

</description>
<pubDate>Mon, 22 Jul 2019 23:01:00 +0000</pubDate>
<dc:creator>Java蚂蚁</dc:creator>
<og:description>面试官：您知道线程的生命周期包括哪几个阶段？ 应聘者： 线程的生命周期包含5个阶段，包括：新建、就绪、运行、阻塞、销毁。 新建：就是刚使用new方法，new出来的线程； 就绪：就是调用的线程的</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/marsitman/p/11228684.html</dc:identifier>
</item>
<item>
<title>基于SpringBoot+Redis的Session共享与单点登录 - 蜜友工作室</title>
<link>http://www.cnblogs.com/askmiw/p/11229437.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/askmiw/p/11229437.html</guid>
<description>&lt;hr/&gt;&lt;p&gt;title: 基于SpringBoot+Redis的Session共享与单点登录&lt;br/&gt;date: 2019-07-23 02:55:52&lt;br/&gt;categories:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;架构&lt;br/&gt;author: mrzhou&lt;br/&gt;tags:&lt;/li&gt;
&lt;li&gt;SpringBoot&lt;/li&gt;
&lt;li&gt;redis&lt;/li&gt;
&lt;li&gt;session&lt;/li&gt;
&lt;li&gt;
&lt;h2 id=&quot;单点登录&quot;&gt;单点登录&lt;/h2&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;h2 id=&quot;基于springbootredis的session共享与单点登录&quot;&gt;基于SpringBoot+Redis的Session共享与单点登录&lt;/h2&gt;
&lt;h3 id=&quot;前言&quot;&gt;前言&lt;/h3&gt;
&lt;p&gt;使用Redis来实现Session共享，其实网上已经有很多例子了，这是确保在集群部署中最典型的redis使用场景。在SpringBoot项目中，其实可以一行运行代码都不用写，只需要简单添加添加依赖和一行注解就可以实现（当然配置信息还是需要的）。&lt;br/&gt;然后简单地把该项目部署到不同的tomcat下，比如不同的端口(A、B)，但项目访问路径是相同的。此时在A中使用set方法，然后在B中使用get方法，就可以发现B中可以获取A中设置的内容。&lt;/p&gt;
&lt;p&gt;但如果就把这样的一个项目在多个tomcat中的部署说实现了单点登录，那就不对了。&lt;/p&gt;
&lt;p&gt;所谓单点登录是指在不同的项目中，只需要任何一个项目登录了，其他项目不需要登录。&lt;/p&gt;
&lt;p&gt;同样是上面的例子，我们把set和get两个方法分别放到两个项目(set、get)中，并且以集群方式把两个项目都部署到服务器A和B中，然后分别访问A服务器的set和B服务器的get，你就会发现完全得不到你想要的结果。&lt;/p&gt;
&lt;h3 id=&quot;同一项目中的setget&quot;&gt;同一项目中的set/get&lt;/h3&gt;
&lt;p&gt;依赖添加就不说了，直接使用最简单的方式&lt;/p&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;@SpringBootApplication
@EnableRedisHttpSession
@RestController
public class SessionShareApplication {

    public static void main(String[] args) {
        SpringApplication.run(SessionShareApplication.class, args);
    }

    @Autowired
    HttpSession session;
    @Autowired
    HttpServletRequest req;
    
    @GetMapping(&quot;/set&quot;)
    public Object set() {
        session.setAttribute(&quot;state&quot;, &quot;state was setted.&quot;);
        Map&amp;lt;String, Object&amp;gt; map = new TreeMap&amp;lt;&amp;gt;();
        map.put(&quot;msg&quot;, session.getAttribute(&quot;state&quot;));
        map.put(&quot;serverPort&quot;, req.getLocalPort());
        return map;
    }
    @GetMapping(&quot;/get&quot;)
    public Object get() {
        Map&amp;lt;String, Object&amp;gt; map = new TreeMap&amp;lt;&amp;gt;();
        map.put(&quot;msg&quot;, session.getAttribute(&quot;state&quot;));
        map.put(&quot;serverPort&quot;, req.getLocalPort());
        return map;
    }
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;将该项目打war包，分别部署在tomcatA(端口8080)，tomcatB(端口8081)，然后通过tomcatA/set 方法设置session,再使用 tomcatB/get 方法即可获得session的值。但这只是实现了同一项目session的共享。并不是单点登录。&lt;/p&gt;
&lt;p&gt;为了验证，我们不仿将set/get方法拆分为两个项目。&lt;/p&gt;
&lt;h3 id=&quot;拆分setget为两个项目&quot;&gt;拆分set/get为两个项目&lt;/h3&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;@SpringBootApplication
@EnableRedisHttpSession
@RestController
public class SetApplication {

    public static void main(String[] args) {
        SpringApplication.run(SetApplication.class, args);
    }

    @Autowired
    HttpSession session;
    @Autowired
    HttpServletRequest req;
    
    @GetMapping(&quot;/&quot;)
    public Object set() {
        session.setAttribute(&quot;state&quot;, &quot;state was setted.&quot;);
        Map&amp;lt;String, Object&amp;gt; map = new TreeMap&amp;lt;&amp;gt;();
        map.put(&quot;msg&quot;, session.getAttribute(&quot;state&quot;));
        map.put(&quot;serverPort&quot;, req.getLocalPort());
        return map;
    }
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;将该项目打包为set.war&lt;/p&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;@SpringBootApplication
@EnableRedisHttpSession
@RestController
public class GetApplication {

    public static void main(String[] args) {
        SpringApplication.run(GetApplication.class, args);
    }

    @Autowired
    HttpSession session;
    @Autowired
    HttpServletRequest req;
    
    @GetMapping(&quot;/&quot;)
    public Object get() {
        Map&amp;lt;String, Object&amp;gt; map = new TreeMap&amp;lt;&amp;gt;();
        map.put(&quot;msg&quot;, session.getAttribute(&quot;state&quot;));
        map.put(&quot;serverPort&quot;, req.getLocalPort());
        return map;
    }
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;将该项目打包为get.war&lt;br/&gt;再分别将set.war,get.war部署在tomcatA和tomcatB,再通过 tomcatA/set 设置session内容, 然后通过 tomcatB/get 就发现无法获得session的值。&lt;/p&gt;
&lt;h3 id=&quot;问题分析&quot;&gt;问题分析&lt;/h3&gt;
&lt;p&gt;尽管我们使用的路径都是一样的，但其实是两个项目，与前面的一个项目是完全不同的，问题就在于 session和cookie在默认情况下是与项目路径相关的，在同一个项目的情况下两个方法所需要的cookie依赖的项目路径是相同的，所以获取session的值就没有问题，但在后一种情况下，cookie的路径是分别属于不同的项目的，所以第二个项目就无法获得第一个项目中设置的session内容了。&lt;/p&gt;
&lt;h3 id=&quot;解决方法&quot;&gt;解决方法&lt;/h3&gt;
&lt;p&gt;解决方法在springboot项目中其实也非常简单。既然cookie路径发生了变化，那我们让它配置为相同的路径就解决了。&lt;br/&gt;在每个子项目中都添加一个配置类或者直接设置cookie的路径，如果有域名还可以设置域名的限制，比如 set.xxx.com 与 get.xxx.com 这种情况与我们就需要设置cookie的域名为 xxx.com，以确保无法在哪个项目下都能够获取 xxx.com 这个域名下的cookie值。这样就确保能够正常获得共享的session值了。&lt;/p&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;@Configuration
public class CookieConfig {

    @Bean
    public static DefaultCookieSerializer defaultCookieSerializer() {
        DefaultCookieSerializer serializer = new DefaultCookieSerializer();
        serializer.setCookiePath(&quot;/&quot;);
        //serializer.setDomainName(&quot;xxx.com&quot;); //如果使用域名访问，建议对这一句进行设置    
        return serializer;
    }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;以上才是正直的redis实现单点登录的正确打开方式。&lt;/p&gt;
</description>
<pubDate>Mon, 22 Jul 2019 18:14:00 +0000</pubDate>
<dc:creator>蜜友工作室</dc:creator>
<og:description>title: 基于SpringBoot+Redis的Session共享与单点登录 date: 2019 07 23 02:55:52 categories: 架构 author: mrzhou tag</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/askmiw/p/11229437.html</dc:identifier>
</item>
<item>
<title>写了一个性能比AtomicLong性能还高的计数器 - 付威的网络博客</title>
<link>http://www.cnblogs.com/OceanHeaven/p/11229361.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/OceanHeaven/p/11229361.html</guid>
<description>[unable to retrieve full-text content]今天在学习CAS的时候，想手写一个CAS的计数器，与JDK中的Atomic(AtomicLong，AtomicInteger等)系列的做个比较，本想性能应该能比JDK要差一丢丢，但却加了一个让线程让出时间片的代码，性能反而更高。 由于使用java中的Unsafe类，存在安全问题,直接使用会抛出Sec</description>
<pubDate>Mon, 22 Jul 2019 16:21:00 +0000</pubDate>
<dc:creator>付威的网络博客</dc:creator>
<dc:language>zh</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://account.cnblogs.com/signin?ReturnUrl=https%3a%2f%2fwww.cnblogs.com%2fOceanHeaven%2fp%2f11229361.html</dc:identifier>
</item>
<item>
<title>《ElasticSearch6.x实战教程》之复杂搜索、Java客户端（下） - OKevin</title>
<link>http://www.cnblogs.com/yulinfeng/p/11229352.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/yulinfeng/p/11229352.html</guid>
<description>&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;黑夜给了我黑色的眼睛，我却用它寻找光明。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;经过了解简单的API和简单搜索，已经基本上能应付大部分的使用场景。可是非关系型数据库数据的文档数据往往又多又杂，各种各样冗余的字段，组成了一条&quot;记录&quot;。复杂的数据结构，带来的就是复杂的搜索。所以在进入本章节前，我们要构建一个尽可能&quot;复杂&quot;的数据结构。&lt;/p&gt;
&lt;p&gt;下面分为两个场景，场景1偏向数据结构上的复杂并且介绍&lt;strong&gt;聚合查询&lt;/strong&gt;、&lt;strong&gt;指定字段返回&lt;/strong&gt;、&lt;strong&gt;深分页&lt;/strong&gt;，场景2偏向搜索精度上的复杂。&lt;/p&gt;
&lt;h2 id=&quot;场景1&quot;&gt;场景1&lt;/h2&gt;
&lt;p&gt;存储一个公司的员工，员工信息包含姓名、工号、性别、出生年月日、岗位、上级、下级、所在部门、进入公司时间、修改时间、创建时间。其中员工工号作为主键ID全局唯一，员工只有一个直属上级，但有多个下级，可以通过父子文档实现。员工有可能属于多个部门（特别是领导可能兼任多个部门的负责人）。&lt;/p&gt;
&lt;h3 id=&quot;数据结构&quot;&gt;数据结构&lt;/h3&gt;
&lt;p&gt;创建索引并定义映射结构：&lt;/p&gt;
&lt;pre class=&quot;json&quot;&gt;
&lt;code&gt;PUT http://localhost:9200/company
{
    &quot;mappings&quot;:{
        &quot;employee&quot;:{
            &quot;properties&quot;:{
                &quot;id&quot;:{
                    &quot;type&quot;:&quot;keyword&quot;
                },
                &quot;name&quot;:{
                    &quot;type&quot;:&quot;text&quot;,
                    &quot;analyzer&quot;:&quot;ik_smart&quot;,
                    &quot;fields&quot;:{
                        &quot;keyword&quot;:{
                            &quot;type&quot;:&quot;keyword&quot;,
                            &quot;ignore_above&quot;:256
                        }
                    }
                },
                &quot;sex&quot;:{
                    &quot;type&quot;:&quot;keyword&quot;
                },
        &quot;age&quot;:{
          &quot;type&quot;:&quot;integer&quot;
                },
                &quot;birthday&quot;:{
                    &quot;type&quot;:&quot;date&quot;
                },
                &quot;position&quot;:{
                    &quot;type&quot;:&quot;text&quot;,
                    &quot;analyzer&quot;:&quot;ik_smart&quot;,
                    &quot;fields&quot;:{
                        &quot;keyword&quot;:{
                            &quot;type&quot;:&quot;keyword&quot;,
                            &quot;ignore_above&quot;:256
                        }
                    }
                },
                &quot;level&quot;:{
                    &quot;type&quot;:&quot;join&quot;,
                    &quot;relations&quot;:{
                        &quot;superior&quot;:&quot;staff&quot;,
            &quot;staff&quot;:&quot;junior&quot;
                    }
                },
                &quot;departments&quot;:{
                    &quot;type&quot;:&quot;text&quot;,
                    &quot;analyzer&quot;:&quot;ik_smart&quot;,
                    &quot;fields&quot;:{
                        &quot;keyword&quot;:{
                            &quot;type&quot;:&quot;keyword&quot;,
                            &quot;ignore_above&quot;:256
                        }
                    }
                },
                &quot;joinTime&quot;:{
                    &quot;type&quot;:&quot;date&quot;
                },
                &quot;modified&quot;:{
                    &quot;type&quot;:&quot;date&quot;
                },
                &quot;created&quot;:{
                    &quot;type&quot;:&quot;date&quot;
                }
            }
        }
    }
}&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;数据&quot;&gt;数据&lt;/h3&gt;
&lt;p&gt;接下来是构造数据，我们构造几条关键数据。&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;张三是公司的董事长，他是最大的领导，不属于任何部门。&lt;/li&gt;
&lt;li&gt;李四的上级是张三，他的下级是王五、赵六、孙七、周八，他同时是市场部和研发部的负责人，也就是隶属于市场部和研发部。&lt;/li&gt;
&lt;li&gt;王五、赵六的上级是张三，他没有下级，他隶属于市场部。&lt;/li&gt;
&lt;li&gt;孙七、周八的上级是李四，他没有下级，他隶属于研发部。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;更为全面直观的数据如下表所示：&lt;/p&gt;
&lt;table&gt;&lt;thead/&gt;&lt;tbody readability=&quot;1&quot;&gt;&lt;tr class=&quot;odd&quot;&gt;&lt;td&gt;张三&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;男&lt;/td&gt;
&lt;td&gt;49&lt;/td&gt;
&lt;td&gt;1970-01-01&lt;/td&gt;
&lt;td&gt;董事长&lt;/td&gt;
&lt;td&gt;/&lt;/td&gt;
&lt;td&gt;李四&lt;/td&gt;
&lt;td&gt;/&lt;/td&gt;
&lt;td&gt;1990-01-01&lt;/td&gt;
&lt;td&gt;1562167817000&lt;/td&gt;
&lt;td&gt;1562167817000&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;even&quot; readability=&quot;2&quot;&gt;&lt;td&gt;李四&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;男&lt;/td&gt;
&lt;td&gt;39&lt;/td&gt;
&lt;td&gt;1980-04-03&lt;/td&gt;
&lt;td&gt;总经理&lt;/td&gt;
&lt;td&gt;张三&lt;/td&gt;
&lt;td&gt;王五、赵六、孙七、周八&lt;/td&gt;
&lt;td&gt;市场部、研发部&lt;/td&gt;
&lt;td&gt;2001-02-02&lt;/td&gt;
&lt;td&gt;1562167817000&lt;/td&gt;
&lt;td&gt;1562167817000&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;odd&quot;&gt;&lt;td&gt;王五&lt;/td&gt;
&lt;td&gt;3&lt;/td&gt;
&lt;td&gt;女&lt;/td&gt;
&lt;td&gt;27&lt;/td&gt;
&lt;td&gt;1992-09-01&lt;/td&gt;
&lt;td&gt;销售&lt;/td&gt;
&lt;td&gt;李四&lt;/td&gt;
&lt;td&gt;/&lt;/td&gt;
&lt;td&gt;市场部&lt;/td&gt;
&lt;td&gt;2010-07-01&lt;/td&gt;
&lt;td&gt;1562167817000&lt;/td&gt;
&lt;td&gt;1562167817000&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;even&quot;&gt;&lt;td&gt;赵六&lt;/td&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;男&lt;/td&gt;
&lt;td&gt;29&lt;/td&gt;
&lt;td&gt;1990-10-10&lt;/td&gt;
&lt;td&gt;销售&lt;/td&gt;
&lt;td&gt;李四&lt;/td&gt;
&lt;td&gt;/&lt;/td&gt;
&lt;td&gt;市场部&lt;/td&gt;
&lt;td&gt;2010-08-08&lt;/td&gt;
&lt;td&gt;1562167817000&lt;/td&gt;
&lt;td&gt;1562167817000&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;odd&quot;&gt;&lt;td&gt;孙七&lt;/td&gt;
&lt;td&gt;5&lt;/td&gt;
&lt;td&gt;男&lt;/td&gt;
&lt;td&gt;26&lt;/td&gt;
&lt;td&gt;1993-12-10&lt;/td&gt;
&lt;td&gt;前端工程师&lt;/td&gt;
&lt;td&gt;李四&lt;/td&gt;
&lt;td&gt;/&lt;/td&gt;
&lt;td&gt;研发部&lt;/td&gt;
&lt;td&gt;2016-07-01&lt;/td&gt;
&lt;td&gt;1562167817000&lt;/td&gt;
&lt;td&gt;1562167817000&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;even&quot;&gt;&lt;td&gt;周八&lt;/td&gt;
&lt;td&gt;6&lt;/td&gt;
&lt;td&gt;男&lt;/td&gt;
&lt;td&gt;25&lt;/td&gt;
&lt;td&gt;1994-05-11&lt;/td&gt;
&lt;td&gt;Java工程师&lt;/td&gt;
&lt;td&gt;李四&lt;/td&gt;
&lt;td&gt;/&lt;/td&gt;
&lt;td&gt;研发部&lt;/td&gt;
&lt;td&gt;2018-03-10&lt;/td&gt;
&lt;td&gt;1562167817000&lt;/td&gt;
&lt;td&gt;1562167817000&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;插入6条数据：&lt;/p&gt;
&lt;pre class=&quot;json&quot;&gt;
&lt;code&gt;POST http://localhost:9200/company/employee/1?routing=1
{
    &quot;id&quot;:&quot;1&quot;,
    &quot;name&quot;:&quot;张三&quot;,
    &quot;sex&quot;:&quot;男&quot;,
  &quot;age&quot;:49,
    &quot;birthday&quot;:&quot;1970-01-01&quot;,
    &quot;position&quot;:&quot;董事长&quot;,
    &quot;level&quot;:{
    &quot;name&quot;:&quot;superior&quot;
  },
    &quot;joinTime&quot;:&quot;1990-01-01&quot;,
    &quot;modified&quot;:&quot;1562167817000&quot;,
    &quot;created&quot;:&quot;1562167817000&quot;
}&lt;/code&gt;
&lt;/pre&gt;
&lt;pre class=&quot;json&quot;&gt;
&lt;code&gt;POST http://localhost:9200/company/employee/2?routing=1
{
    &quot;id&quot;:&quot;2&quot;,
    &quot;name&quot;:&quot;李四&quot;,
    &quot;sex&quot;:&quot;男&quot;,
  &quot;age&quot;:39,
    &quot;birthday&quot;:&quot;1980-04-03&quot;,
    &quot;position&quot;:&quot;总经理&quot;,
    &quot;level&quot;:{
    &quot;name&quot;:&quot;staff&quot;,
    &quot;parent&quot;:&quot;1&quot;
  },
  &quot;departments&quot;:[&quot;市场部&quot;,&quot;研发部&quot;],
    &quot;joinTime&quot;:&quot;2001-02-02&quot;,
    &quot;modified&quot;:&quot;1562167817000&quot;,
    &quot;created&quot;:&quot;1562167817000&quot;
}&lt;/code&gt;
&lt;/pre&gt;
&lt;pre class=&quot;json&quot;&gt;
&lt;code&gt;POST http://localhost:9200/company/employee/3?routing=1
{
    &quot;id&quot;:&quot;3&quot;,
    &quot;name&quot;:&quot;王五&quot;,
    &quot;sex&quot;:&quot;女&quot;,
  &quot;age&quot;:27,
    &quot;birthday&quot;:&quot;1992-09-01&quot;,
    &quot;position&quot;:&quot;销售&quot;,
    &quot;level&quot;:{
    &quot;name&quot;:&quot;junior&quot;,
    &quot;parent&quot;:&quot;2&quot;
  },
  &quot;departments&quot;:[&quot;市场部&quot;],
    &quot;joinTime&quot;:&quot;2010-07-01&quot;,
    &quot;modified&quot;:&quot;1562167817000&quot;,
    &quot;created&quot;:&quot;1562167817000&quot;
}&lt;/code&gt;
&lt;/pre&gt;
&lt;pre class=&quot;json&quot;&gt;
&lt;code&gt;POST http://localhost:9200/company/employee/4?routing=1
{
    &quot;id&quot;:&quot;4&quot;,
    &quot;name&quot;:&quot;赵六&quot;,
    &quot;sex&quot;:&quot;男&quot;,
  &quot;age&quot;:29,
    &quot;birthday&quot;:&quot;1990-10-10&quot;,
    &quot;position&quot;:&quot;销售&quot;,
    &quot;level&quot;:{
    &quot;name&quot;:&quot;junior&quot;,
    &quot;parent&quot;:&quot;2&quot;
  },
  &quot;departments&quot;:[&quot;市场部&quot;],
    &quot;joinTime&quot;:&quot;2010-08-08&quot;,
    &quot;modified&quot;:&quot;1562167817000&quot;,
    &quot;created&quot;:&quot;1562167817000&quot;
}&lt;/code&gt;
&lt;/pre&gt;
&lt;pre class=&quot;json&quot;&gt;
&lt;code&gt;POST http://localhost:9200/company/employee/5?routing=1
{
    &quot;id&quot;:&quot;5&quot;,
    &quot;name&quot;:&quot;孙七&quot;,
    &quot;sex&quot;:&quot;男&quot;,
  &quot;age&quot;:26,
    &quot;birthday&quot;:&quot;1993-12-10&quot;,
    &quot;position&quot;:&quot;前端工程师&quot;,
    &quot;level&quot;:{
    &quot;name&quot;:&quot;junior&quot;,
    &quot;parent&quot;:&quot;2&quot;
  },
  &quot;departments&quot;:[&quot;研发部&quot;],
    &quot;joinTime&quot;:&quot;2016-07-01&quot;,
    &quot;modified&quot;:&quot;1562167817000&quot;,
    &quot;created&quot;:&quot;1562167817000&quot;
}&lt;/code&gt;
&lt;/pre&gt;
&lt;pre class=&quot;json&quot;&gt;
&lt;code&gt;POST http://localhost:9200/company/employee/6?routing=1
{
    &quot;id&quot;:&quot;6&quot;,
    &quot;name&quot;:&quot;周八&quot;,
    &quot;sex&quot;:&quot;男&quot;,
  &quot;age&quot;:28,
    &quot;birthday&quot;:&quot;1994-05-11&quot;,
    &quot;position&quot;:&quot;Java工程师&quot;,
    &quot;level&quot;:{
    &quot;name&quot;:&quot;junior&quot;,
    &quot;parent&quot;:&quot;2&quot;
  },
  &quot;departments&quot;:[&quot;研发部&quot;],
    &quot;joinTime&quot;:&quot;2018-03-10&quot;,
    &quot;modified&quot;:&quot;1562167817000&quot;,
    &quot;created&quot;:&quot;1562167817000&quot;
}&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;搜索&quot;&gt;搜索&lt;/h3&gt;
&lt;ol&gt;&lt;li&gt;查询研发部的员工&lt;/li&gt;
&lt;/ol&gt;&lt;pre class=&quot;json&quot;&gt;
&lt;code&gt;GET http://localhost:9200/company/employee/_search
{
    &quot;query&quot;:{
        &quot;match&quot;:{
            &quot;departments&quot;:&quot;研发部&quot;
        }
    }
}&lt;/code&gt;
&lt;/pre&gt;
&lt;ol&gt;&lt;li&gt;查询在研发部且在市场部的员工&lt;/li&gt;
&lt;/ol&gt;&lt;pre class=&quot;json&quot;&gt;
&lt;code&gt;GET http://localhost:9200/company/employee/_search
{
    &quot;query&quot;: {
        &quot;bool&quot;:{
            &quot;must&quot;:[{
                &quot;match&quot;:{
                    &quot;departments&quot;:&quot;市场部&quot;
                }
            },{
                &quot;match&quot;:{
                    &quot;departments&quot;:&quot;研发部&quot;
                }
            }]
        }
    }
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;*被搜索的字段是一个数组类型，但对查询语句并没有特殊的要求。&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;查询name=&quot;张三&quot;的直接下属。&lt;/li&gt;
&lt;/ol&gt;&lt;pre class=&quot;json&quot;&gt;
&lt;code&gt;GET http://localhost:9200/company/employee/_search
{
    &quot;query&quot;: {
        &quot;has_parent&quot;:{
            &quot;parent_type&quot;:&quot;superior&quot;,
            &quot;query&quot;:{
                &quot;match&quot;:{
                    &quot;name&quot;:&quot;张三&quot;
                }
            }
        }
    }
}&lt;/code&gt;
&lt;/pre&gt;
&lt;ol&gt;&lt;li&gt;查询name=&quot;李四&quot;的直接下属。&lt;/li&gt;
&lt;/ol&gt;&lt;pre class=&quot;json&quot;&gt;
&lt;code&gt;GET http://localhost:9200/company/employee/_search

{
    &quot;query&quot;: {
        &quot;has_parent&quot;:{
            &quot;parent_type&quot;:&quot;staff&quot;,
            &quot;query&quot;:{
                &quot;match&quot;:{
                    &quot;name&quot;:&quot;李四&quot;
                }
            }
        }
    }
}&lt;/code&gt;
&lt;/pre&gt;
&lt;ol&gt;&lt;li&gt;查询name=&quot;王五&quot;的直接上级。&lt;/li&gt;
&lt;/ol&gt;&lt;pre class=&quot;json&quot;&gt;
&lt;code&gt;GET http://localhost:9200/company/employee/_search
{
    &quot;query&quot;: {
        &quot;has_child&quot;:{
            &quot;type&quot;:&quot;junior&quot;,
            &quot;query&quot;:{
                &quot;match&quot;:{
                    &quot;name&quot;:&quot;王五&quot;
                }
            }
        }
    }
}&lt;/code&gt;
&lt;/pre&gt;
&lt;h4 id=&quot;聚合查询&quot;&gt;聚合查询&lt;/h4&gt;
&lt;p&gt;ES中的聚合查询类似MySQL中的聚合函数(avg、max等)，例如计算员工的平均年龄。&lt;/p&gt;
&lt;pre class=&quot;json&quot;&gt;
&lt;code&gt;GET http://localhost:9200/company/employee/_search?pretty
{
    &quot;size&quot;: 0,
    &quot;aggs&quot;: {
        &quot;avg_age&quot;: {
            &quot;avg&quot;: {
                &quot;field&quot;: &quot;age&quot;
            }
        }
    }
}&lt;/code&gt;
&lt;/pre&gt;
&lt;h4 id=&quot;指定字段查询&quot;&gt;指定字段查询&lt;/h4&gt;
&lt;p&gt;指定字段返回值在查询结果中指定需要返回的字段。例如只查询张三的生日。&lt;/p&gt;
&lt;pre class=&quot;json&quot;&gt;
&lt;code&gt;GET http://localhost:9200/company/employee/_search?pretty
{
    &quot;_source&quot;:[&quot;name&quot;,&quot;birthday&quot;],
    &quot;query&quot;:{
        &quot;match&quot;:{
            &quot;name&quot;:&quot;张三&quot;
        }
    }
}&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;深分页&quot;&gt;深分页&lt;/h3&gt;
&lt;p&gt;ES的深分页是一个老生常谈的问题。用过ES的都知道，ES默认查询深度不能超过10000条，也就是page * pageSize &amp;lt; 10000。如果需要查询超过1万条的数据，要么通过设置最大深度，要么通过&lt;code&gt;scroll&lt;/code&gt;滚动查询。如果调整配置，即使能查出来，性能也会很差。但通过&lt;code&gt;scroll&lt;/code&gt;滚动查询的方式带来的问题就是只能进行&quot;上一页&quot;、&quot;下一页&quot;的操作，而不能进行页码跳转。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;scroll&lt;/code&gt;原理简单来讲，就是一批一批的查，上一批的最后一个数据，作为下一批的第一个数据，直到查完所有的数据。&lt;/p&gt;
&lt;p&gt;首先需要初始化查询&lt;/p&gt;
&lt;pre class=&quot;json&quot;&gt;
&lt;code&gt;GET http://localhost:9200/company/employee/_search?scroll=1m
{
    &quot;query&quot;:{
        &quot;match_all&quot;:{}
    },
    &quot;size&quot;:1,
    &quot;_source&quot;: [&quot;id&quot;]
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;像普通查询结果一样进行查询，url中的scroll=1m指的是游标查询的过期时间为1分钟，每次查询就会更新，设置过长占会用过多的时间。&lt;/p&gt;
&lt;p&gt;接下来就可以通过上述API返回的&lt;code&gt;_scroll_id&lt;/code&gt;进行滚动查询，假设上面的结果返回&lt;code&gt;&quot;_scroll_id&quot;: &quot;DnF1ZXJ5VGhlbkZldGNoBQAAAAAAAAFBFk1pNzdFUVhDU3hxX3VtSVFUdDJBWlEAAAAAAAABQhZNaTc3RVFYQ1N4cV91bUlRVHQyQVpRAAAAAAAAAUMWTWk3N0VRWENTeHFfdW1JUVR0MkFaUQAAAAAAAAFEFk1pNzdFUVhDU3hxX3VtSVFUdDJBWlEAAAAAAAABRRZNaTc3RVFYQ1N4cV91bUlRVHQyQVpR&quot;&lt;/code&gt;。&lt;/p&gt;
&lt;pre class=&quot;json&quot;&gt;
&lt;code&gt;GET http://localhost:9200/_search/scroll
{
    &quot;scroll&quot;:&quot;1m&quot;,
    &quot;scroll_id&quot;: &quot;DnF1ZXJ5VGhlbkZldGNoBQAAAAAAAAFBFk1pNzdFUVhDU3hxX3VtSVFUdDJBWlEAAAAAAAABQhZNaTc3RVFYQ1N4cV91bUlRVHQyQVpRAAAAAAAAAUMWTWk3N0VRWENTeHFfdW1JUVR0MkFaUQAAAAAAAAFEFk1pNzdFUVhDU3hxX3VtSVFUdDJBWlEAAAAAAAABRRZNaTc3RVFYQ1N4cV91bUlRVHQyQVpR&quot;
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;这种方式有一个小小的弊端，如果超过过期时间就不能继续往下查询，这种查询适合一次全量查询所有数据。但现实情况有可能是用户在一个页面停留很长时间，再点击上一页或者下一页，此时超过过期时间页面不能再进行查询。所以还有另外一种方式，范围查询。&lt;/p&gt;
&lt;h4 id=&quot;另一种深分页&quot;&gt;另一种深分页&lt;/h4&gt;
&lt;p&gt;假设员工数据中的工号ID是按递增且唯一的顺序，那么我们可以通过范围查询进行分页。&lt;/p&gt;
&lt;p&gt;例如，按ID递增排序，第一查询ID&amp;gt;0的数据，数据量为1。&lt;/p&gt;
&lt;pre class=&quot;json&quot;&gt;
&lt;code&gt;GET http://localhost:9200/company/employee/_search
{
    &quot;query&quot;:{
        &quot;range&quot;:{
            &quot;id&quot;:{
                &quot;gt&quot;:0
            }
        }
    },
    &quot;size&quot;:1,
    &quot;sort&quot;:{
        &quot;id&quot;:{
            &quot;order&quot;:&quot;asc&quot;
        }
    }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;此时返回ID=1的1条数据，我们再继续查询ID&amp;gt;1的数据，数据量仍然是1。&lt;/p&gt;
&lt;pre class=&quot;json&quot;&gt;
&lt;code&gt;GET http://localhost:9200/company/employee/_search
{
    &quot;query&quot;:{
        &quot;range&quot;:{
            &quot;id&quot;:{
                &quot;gt&quot;:1
            }
        }
    },
    &quot;size&quot;:1,
    &quot;sort&quot;:{
        &quot;id&quot;:{
            &quot;order&quot;:&quot;asc&quot;
        }
    }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;这样我们同样做到了深分页的查询，并且没有过期时间的限制。&lt;/p&gt;
&lt;h2 id=&quot;场景2&quot;&gt;场景2&lt;/h2&gt;
&lt;p&gt;存储商品数据，根据商品名称搜索商品，要求准确度高，不能搜索洗面奶结果出现面粉。&lt;/p&gt;
&lt;p&gt;由于这个场景主要涉及的是搜索的精度问题，所以并不会有复杂的数据结构，只有一个title字段。&lt;/p&gt;
&lt;p&gt;定义一个只包含title字段且分词器默认为&lt;code&gt;standard&lt;/code&gt;的索引：&lt;/p&gt;
&lt;pre class=&quot;json&quot;&gt;
&lt;code&gt;PUT http://localhost:9200/ware_index
{
    &quot;mappings&quot;: {
        &quot;ware&quot;: {
            &quot;properties&quot;: {
                &quot;title&quot;:{
                    &quot;type&quot;:&quot;text&quot;
                }
            }
        }
    }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;插入两条数据：&lt;/p&gt;
&lt;pre class=&quot;json&quot;&gt;
&lt;code&gt;POST http://localhost:9200/ware_index/ware
{
    &quot;title&quot;:&quot;洗面奶&quot;
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;pre class=&quot;json&quot;&gt;
&lt;code&gt;POST http://localhost:9200/ware_index/ware
{
    &quot;title&quot;:&quot;面粉&quot;
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;搜索关键字&quot;洗面奶&quot;：&lt;/p&gt;
&lt;pre class=&quot;json&quot;&gt;
&lt;code&gt;POST http://localhost:9200/ware_index/ware/_search
{
    &quot;query&quot;:{
        &quot;match&quot;:{
            &quot;title&quot;:&quot;洗面奶&quot;
        }
    }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;搜索结果出现了&quot;洗面奶&quot;和&quot;面粉&quot;两个风马牛不相及的结果，这显然不符合我们的预期。&lt;/p&gt;
&lt;p&gt;原因在&lt;strong&gt;分词&lt;/strong&gt;一章中已经说明，&lt;code&gt;text&lt;/code&gt;类型默认分词器为&lt;code&gt;standard&lt;/code&gt;，它会将中文字符串一个字一个字拆分，也就是将&quot;洗面奶&quot;拆分成了&quot;洗&quot;、&quot;面&quot;、&quot;奶&quot;，将&quot;面粉&quot;拆分成了&quot;面&quot;、&quot;粉&quot;。而&lt;code&gt;match&lt;/code&gt;会将搜索的关键词拆分，也就拆分成了&quot;洗&quot;、&quot;面&quot;、&quot;奶&quot;，最后两个&quot;面&quot;都能匹配上，也就出现了上述结果。所以对于中文的字符串搜索我们需要指定分词器，而常用的分词器是&lt;code&gt;ik_smart&lt;/code&gt;，它会按照最大粒度拆分，如果采用&lt;code&gt;ik_max_word&lt;/code&gt;它会将词按照最小粒度拆分，也有可能造成上述结果。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;DELETE http://localhost:9200/ware_index&lt;/code&gt;删除索引，重新创建并指定title字段的分词器为&lt;code&gt;ik_smart&lt;/code&gt;。&lt;/p&gt;
&lt;pre class=&quot;json&quot;&gt;
&lt;code&gt;PUT http://localhost:9200/ware_index
{
    &quot;mappings&quot;:{
        &quot;ware&quot;:{
            &quot;properties&quot;:{
        &quot;id&quot;:{
          &quot;type&quot;:&quot;keyword&quot;
        },
                &quot;title&quot;:{
                    &quot;type&quot;:&quot;text&quot;,
                    &quot;analyzer&quot;:&quot;ik_smart&quot;
                }
            }
        }
    }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;这时如果插入“洗面奶”和“面粉”，搜索“洗面奶”是结果就只有一条。但此时我们插入以下两条数据：&lt;/p&gt;
&lt;pre class=&quot;json&quot;&gt;
&lt;code&gt;POST http://localhost:9200/ware_index/ware
{
    &quot;id&quot;:&quot;1&quot;,
    &quot;title&quot;:&quot;新希望牛奶&quot;
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;pre class=&quot;json&quot;&gt;
&lt;code&gt;POST http://localhost:9200/ware_index/ware
{
    &quot;id&quot;:&quot;2&quot;,
    &quot;title&quot;:&quot;春秋上新短袖&quot;
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;搜索关键字”新希望牛奶“：&lt;/p&gt;
&lt;pre class=&quot;json&quot;&gt;
&lt;code&gt;POST http://localhost:9200/ware_index/ware/_search
{
    &quot;query&quot;:{
        &quot;match&quot;:{
            &quot;title&quot;:&quot;新希望牛奶&quot;
        }
    }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;搜索结果出现了刚插入的2条，显然第二条”春秋上新短袖“并不是我们想要的结果。出现这种问题的原因同样是因为分词的问题，在&lt;code&gt;ik&lt;/code&gt;插件的词库中并没有&quot;新希望&quot;一词，所以它会把搜索的关键词&quot;新希望&quot;拆分为&quot;新&quot;和&quot;希望&quot;，同样在&quot;春秋上新短袖&quot;中&quot;新&quot;也并没有组合成其它词语，它也被单独拆成了&quot;新&quot;，这就造成了上述结果。解决这个问题的办法当然可以在&lt;code&gt;ik&lt;/code&gt;插件中新增&quot;新希望&quot;词语，如果我们在&lt;strong&gt;分词&lt;/strong&gt;中所做的那样，但也有其它的办法。&lt;/p&gt;
&lt;h3 id=&quot;短语查询&quot;&gt;短语查询&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;match_phrase&lt;/code&gt;，短语查询，它会将搜索关键字&quot;新希望牛奶&quot;拆分成一个词项列表&quot;新 希望 牛奶&quot;，对于搜索的结果需要&lt;strong&gt;完全匹配这些词项，且位置对应&lt;/strong&gt;，本例中的&quot;新希望牛奶&quot;文档数据从词项和位置上完全对应，故通过&lt;code&gt;match_phrase&lt;/code&gt;短语查询可搜索出结果，且只有一条数据。&lt;/p&gt;
&lt;pre class=&quot;json&quot;&gt;
&lt;code&gt;POST http://localhost:9200/ware_index/ware/_search
{
    &quot;query&quot;:{
        &quot;match_phrase&quot;:{
            &quot;title&quot;:&quot;新希望牛奶&quot;
        }
    }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;尽管这能满足我们的搜索结果，但是用户实际在搜索中常常可能是&quot;牛奶 新希望&quot;这样的顺序，但遗憾的是根据&lt;code&gt;match_phrase&lt;/code&gt;短语匹配的要求是需要被搜索的文档需要&lt;strong&gt;完全匹配词项且位置对应&lt;/strong&gt;，关键字&quot;牛奶 新希望&quot;被解析成了&quot;牛奶 新 希望&quot;，尽管它与&quot;新希望牛奶&quot;词项匹配但位置没有对应，所以并不能搜索出任何结果。同理，此时如果我们插入&quot;新希望的牛奶&quot;数据时，无论是搜索&quot;新希望牛奶&quot;还是&quot;牛奶新希望&quot;均不能搜索出&quot;新希望的牛奶&quot;结果，前者的关键字是因为&lt;strong&gt;词项没有完全匹配&lt;/strong&gt;，后者的关键字是因为&lt;strong&gt;词项和位置没有完全匹配&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;所以&lt;code&gt;match_phrase&lt;/code&gt;也没有达到完美的效果。&lt;/p&gt;
&lt;h3 id=&quot;短语前缀查询&quot;&gt;短语前缀查询&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;match_phrase_prefix&lt;/code&gt;，短语前缀查询，类似MySQL中的&lt;code&gt;like &quot;新希望%&quot;&lt;/code&gt;，它大体上和&lt;code&gt;match_phrase_prefix&lt;/code&gt;一致，也是需要满足文档数据和搜索关键字在词项和位置上保持一致，同样如果搜索&quot;牛奶新希望&quot;也不会出现任何结果。它也并没有达到我们想要的结果。&lt;/p&gt;
&lt;h3 id=&quot;最低匹配度&quot;&gt;最低匹配度&lt;/h3&gt;
&lt;p&gt;前面两种查询中虽然能通过&quot;新希望牛奶&quot;搜索到我们想要的结果，但是对于&quot;牛奶 新希望&quot;却无能为力。接下来的这种查询方式能&quot;完美&quot;的达到我们想要的效果。&lt;/p&gt;
&lt;p&gt;先来看最低匹配度的查询示例：&lt;/p&gt;
&lt;pre class=&quot;json&quot;&gt;
&lt;code&gt;POST http://localhost:9200/ware_index/ware/_search
{
    &quot;query&quot;: {
        &quot;match&quot;: {
            &quot;title&quot;: {
                &quot;query&quot;: &quot;新希望牛奶&quot;,
                &quot;minimum_should_match&quot;: &quot;80%&quot;
            }
        }
    }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;minimum_should_match&lt;/code&gt;即最低匹配度。&quot;80%&quot;代表什么意思呢？还是要从关键字&quot;新希望牛奶&quot;被解析成哪几个词项说起，前面说到&quot;新希望牛奶&quot;被解析成&quot;新 希望 牛奶&quot;三个词项，如果通过&lt;code&gt;match&lt;/code&gt;搜索，则含有&quot;新&quot;的数据同样出现在搜索结果中。&quot;80%&quot;的含义则是3个词项必须至少匹配80% * 3 = 2.4个词项才会出现在搜索结果中，向下取整为2，即搜索的数据中需要至少包含2个词项。显然，&quot;春秋上新短袖&quot;只有1个词项，不满足&lt;strong&gt;最低匹配度&lt;/strong&gt;2个词项的要求，故不会出现在搜索结果中。&lt;/p&gt;
&lt;p&gt;同样，如果搜索&quot;牛奶 新希望&quot;也是上述的结果，它并不是短语匹配，所以并不会要求词项所匹配的位置相同。&lt;/p&gt;
&lt;p&gt;可以推出，如果&lt;code&gt;&quot;minimum_should_match&quot;:&quot;100%&quot;&lt;/code&gt;也就是要求完全匹配，此时要求数据中&lt;strong&gt;包含所有的词项&lt;/strong&gt;，这样会出现较少的搜索结果；如果&lt;code&gt;&quot;minimun_should_match:0&quot;&lt;/code&gt;此时并不代表一个词项都可以不包含，而是只需要有一个词项就能出现在搜索结果，实际上就是默认的&lt;code&gt;match&lt;/code&gt;搜索，这样会出现较多的搜索结果。&lt;/p&gt;
&lt;p&gt;找到一个合适的值，就能有一个较好的体验，根据二八原则，以及实践表明，设置为&quot;80%&quot;能满足大部分场景，既不会多出无用的搜索结果，也不会少。&lt;/p&gt;

&lt;p&gt;基于&lt;a href=&quot;https://www.cnblogs.com/yulinfeng/p/minimum_should_match&quot;&gt;Java客户端（上）&lt;/a&gt;，本文不再赘述如何创建一个Spring Data ElasticSearch工程，也不再做过多文字叙述。更多的请一定配合源码使用，源码地址&lt;a href=&quot;(https://github.com/yu-linfeng/elasticsearch6.x_tutorial/tree/master/code/spring-data-elasticsearch)&quot;&gt;https://github.com/yu-linfeng/elasticsearch6.x_tutorial/tree/master/code/spring-data-elasticsearch&lt;/a&gt;，具体代码目录在&lt;code&gt;complex&lt;/code&gt;包。&lt;/p&gt;
&lt;p&gt;本章请一定结合代码重点关注如何如何通过Java API进行&lt;strong&gt;父子文档的数据插入，以及查询。&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&quot;父子文档的数据插入&quot;&gt;父子文档的数据插入&lt;/h3&gt;
&lt;p&gt;父子文档在ES中存储的格式实际上是以&lt;strong&gt;键值对&lt;/strong&gt;方式存在，例如在定义映射Mapping时，我们将子文档定义为：&lt;/p&gt;
&lt;pre class=&quot;json&quot;&gt;
&lt;code&gt;{
    ......
    &quot;level&quot;:{
        &quot;type&quot;:&quot;join&quot;,
        &quot;relations&quot;:{
                    &quot;superior&quot;:&quot;staff&quot;,
            &quot;staff&quot;:&quot;junior&quot;
        }
    }
    ......
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;在写入一条数据时：&lt;/p&gt;
&lt;pre class=&quot;json&quot;&gt;
&lt;code&gt;{
    ......
    &quot;level&quot;:{
        &quot;name&quot;:&quot;staff&quot;,
        &quot;parent&quot;:&quot;1&quot;
    }
    ......
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;对于于Java实体，我们可以把&lt;code&gt;level&lt;/code&gt;字段设置为&lt;code&gt;Map&amp;lt;String, Object&amp;gt;&lt;/code&gt;类型。关键注意的是，在使用Spring Data ElasticSearch时，我们不能直接调用&lt;code&gt;sava&lt;/code&gt;或者&lt;code&gt;saveAll&lt;/code&gt;方法。ES规定&lt;strong&gt;父子文档必须属于同一分片&lt;/strong&gt;，也就是说在写入子文档时，需要定义&lt;code&gt;routing&lt;/code&gt;参数。下面是代码节选：&lt;/p&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;BulkRequestBuilder bulkRequestBuilder = client.prepareBulk();
bulkRequestBuilder.add(client.prepareIndex(&quot;company&quot;, &quot;employee&quot;, employeePO.getId()).setRouting(routing).setSource(mapper.writeValueAsString(employeePO), XContentType.JSON)).execute().actionGet();&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;一定参考源码一起使用。&lt;/p&gt;
&lt;p&gt;ES实在是一个非常强大的搜索引擎。能力有限，实在不能将所有的Java API一一举例讲解，如果你在编写代码时，遇到困难也请联系作者邮箱&lt;strong&gt;hellobug at outlook.com&lt;/strong&gt;，或者通过公众号&lt;strong&gt;coderbuff&lt;/strong&gt;，解答得了的一定解答，解答不了的一起解答。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;关注公众号：CoderBuff，回复“es”获取《ElasticSearch6.x实战教程》完整版PDF。&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;
&lt;p&gt;这是一个能给程序员加buff的公众号 （CoderBuff）&lt;/p&gt;
&lt;br/&gt;&lt;div align=&quot;center&quot;&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/630246/201907/630246-20190717223740465-1981496921.png&quot;/&gt;&lt;/div&gt;
</description>
<pubDate>Mon, 22 Jul 2019 16:14:00 +0000</pubDate>
<dc:creator>OKevin</dc:creator>
<og:description>第八章 复杂搜索 黑夜给了我黑色的眼睛，我却用它寻找光明。 经过了解简单的API和简单搜索，已经基本上能应付大部分的使用场景。可是非关系型数据库数据的文档数据往往又多又杂，各种各样冗余的字段，组成了一</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/yulinfeng/p/11229352.html</dc:identifier>
</item>
<item>
<title>Redis持久化背后的故事 - Tu9oh0st</title>
<link>http://www.cnblogs.com/Tu9oh0st/p/11229317.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/Tu9oh0st/p/11229317.html</guid>
<description>&lt;p&gt;Redis提供了不同的持久化选项：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;RDB持久化&lt;/strong&gt;以指定的时间间隔保存那个时间点的数据快照。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;AOF持久化&lt;/strong&gt;方法则会记录每一个服务器收到的写操作。在服务器启动时，这些记录的操作会逐条执行从而重建出原来的数据。写操作命令记录的格式跟Redis协议一致，以追加的方式进行保存。&lt;/li&gt;
&lt;li&gt;Redis的持久化时可以禁用的，就是说你可以让数据的生命周期只存在服务器的运行时间里。&lt;/li&gt;
&lt;li&gt;两种方式的持久化是可以同时存在的，但是当Redis重启时，AOF文件会被&lt;code&gt;优先&lt;/code&gt;用于重建数据。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;最重要的是要理解RDB和AOF持久化之间的不同区别。&lt;/p&gt;

&lt;h2 id=&quot;rdb文件的创建和载入&quot;&gt;RDB文件的创建和载入&lt;/h2&gt;
&lt;p&gt;有两个Redis命令可以用于生成RDB文件，一个是&lt;strong&gt;SAVE&lt;/strong&gt;，另一个是&lt;strong&gt;BGSAVE&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;SAVE&lt;/strong&gt;命令会阻塞Redis服务器进程，直到RDB文件创建完毕为止，在服务器进程阻塞期间，服务器不能处理任何命令请求：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1330447/201907/1330447-20190722235849978-182570685.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;和&lt;strong&gt;SAVE&lt;/strong&gt;命令直接阻塞服务器进程的做法不同，BGSAVE命令会去派生出一个子进程，然后由紫禁城负责创建RDB文件，服务器进程（父进程）继续处理命令请求：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1330447/201907/1330447-20190722235859423-2116630635.png&quot;/&gt;&lt;/p&gt;
&lt;h2 id=&quot;rdb的优势&quot;&gt;RDB的优势&lt;/h2&gt;
&lt;ul&gt;&lt;li&gt;RDB文件是一个经过压缩的二进制文件，保存着某个时间点的Redis数据。RDB文件非常适合备份。你可以设定一个时间点对RDB文件进行归档，这样就能在需要的时候很轻易的把数据恢复到不同的版本。&lt;/li&gt;
&lt;li&gt;RDB非常适用于&lt;strong&gt;灾备&lt;/strong&gt;。单文件很方便传输到远程的服务器上。&lt;/li&gt;
&lt;li&gt;RDB的性能很好，需要进行持久化时，主进程会fork一个子进程出来，然后把持久化工作交给子进程，自己不会有相关的I/O操作，也就是上面说是的&lt;strong&gt;BGSAVE&lt;/strong&gt;。&lt;/li&gt;
&lt;li&gt;比起AOF，在数据量比较大的情况下，RDB的启动速度更快。&lt;/li&gt;
&lt;/ul&gt;&lt;h2 id=&quot;rdb的缺点&quot;&gt;RDB的缺点&lt;/h2&gt;
&lt;ul&gt;&lt;li&gt;RDB容易造成数据的丢失。假设每5分钟保存一次快照，如果Redis因为某些原因不能工作，那么从上次产生快照到Redis出现问题这段时间的数据就会丢失了。上述的&lt;strong&gt;SAVE&lt;/strong&gt;缺点。&lt;/li&gt;
&lt;li&gt;RDB使用&lt;strong&gt;fork()&lt;/strong&gt;产生子进程进行数据的持久化，如果数据比较大可能就会花费点时间，造成Redis停止服务几毫秒。如果数据很大且CPU性能不是很好的时候，停止服务的时间甚至更多。上述的&lt;strong&gt;BGSAVE&lt;/strong&gt;缺点。&lt;/li&gt;
&lt;/ul&gt;&lt;h2 id=&quot;文件路径和名称&quot;&gt;文件路径和名称&lt;/h2&gt;
&lt;p&gt;默认Redis会把快照文件存储为当前目录下一个名为&lt;code&gt;dump.rdb&lt;/code&gt;的文件。要修改文件的存储路径和名称，可以通过修改配置文件&lt;code&gt;redis.conf&lt;/code&gt;实现：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;# RDB文件名，默认为dump.rdb。
dbfilename dump.rdb

# 文件存放的目录，AOF文件同样存放在此目录下。默认为当前工作目录。
dir ./&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1330447/201907/1330447-20190722235912349-1017999183.png&quot;/&gt;&lt;/p&gt;
&lt;h2 id=&quot;保存点rdb的启用和禁用&quot;&gt;保存点（RDB的启用和禁用）&lt;/h2&gt;
&lt;p&gt;你可以配置保存点，使Redis如果在每N秒后数据发生了M次改变就保存快照文件。例如下面这个保存点配置表示每60秒，如果数据发生了1000次以上的变动，Redis就会自动保存快照文件：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;save 60 1000&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;保存点可以设置多个，Redis的配置文件就默认设置了3个保存点：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;# 格式为：save &amp;lt;seconds&amp;gt; &amp;lt;changes&amp;gt;
# 可以设置多个。
save 900 1 #900秒后至少1个key有变动
save 300 10 #300秒后至少10个key有变动
save 60 10000 #60秒后至少10000个key有变动&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;如果想禁用快照保存的功能，可以通过注释掉所有&quot;save&quot;配置达到，或者在最后一条&quot;save&quot;配置后添加如下的配置：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;save &quot;&quot;&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;错误处理&quot;&gt;错误处理&lt;/h2&gt;
&lt;p&gt;默认情况下，如果Redis在后台生成快照的时候失败，那么就会停止接收数据，目的是让用户能知道数据没有持久化成功。但是如果你有其他的方式可以监控到Redis及其持久化的状态，那么可以把这个功能禁止掉。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;stop-writes-on-bgsave-error yes&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;数据压缩&quot;&gt;数据压缩&lt;/h2&gt;
&lt;p&gt;默认Redis会采用&lt;code&gt;LZF&lt;/code&gt;对数据进行压缩。如果你想节省点CPU的性能，你可以把压缩功能禁用掉，但是数据集就会比没压缩的时候要打。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;rdbcompression yes&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;数据校验&quot;&gt;数据校验&lt;/h2&gt;
&lt;p&gt;从版本5的RDB的开始，一个&lt;code&gt;CRC64&lt;/code&gt;的校验码会放在文件的末尾。这样更能保证文件的完整性，但是在保存或者加载文件时会损失一定的性能（大概10%）。如果想追求更高的性能，可以把它禁用掉，这样文件在写入校验码时会用&lt;code&gt;0&lt;/code&gt;替代，加载的时候看到&lt;code&gt;0&lt;/code&gt;就会直接跳过校验。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;rdbchecksum yes&lt;/code&gt;
&lt;/pre&gt;

&lt;p&gt;快照并不是很可靠。如果你的电脑突然宕机了，或者电源断了，又或者不小心杀掉了进程，那么最新的数据就会丢失。而AOF文件则提供了一种更为可靠的持久化方式。每当Redis接受到会修改数据集的命令时，就会把命令追加到AOF文件里，当你重启Redis时，AOF里的命令会被重新执行一次，重建数据。&lt;/p&gt;
&lt;p&gt;使用AOF持久化需要设置同步选项，从而确保命令同步到磁盘文件上的时机。这是因为文件进行写入b并不会马上将内容同步到磁盘上，而是先存储到缓冲区，然后由操作系统决定什么时候同步到磁盘。有以下同步选项：&lt;/p&gt;
&lt;table&gt;&lt;thead/&gt;&lt;tbody readability=&quot;1&quot;&gt;&lt;tr class=&quot;odd&quot;&gt;&lt;td&gt;always&lt;/td&gt;
&lt;td&gt;每个写命令都同步&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;even&quot;&gt;&lt;td&gt;everysec&lt;/td&gt;
&lt;td&gt;每秒同步一次&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;odd&quot; readability=&quot;2&quot;&gt;&lt;td&gt;no&lt;/td&gt;
&lt;td&gt;让操作系统来决定何时同步&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;h2 id=&quot;优点&quot;&gt;优点&lt;/h2&gt;
&lt;ul&gt;&lt;li&gt;比RDB可靠。你可以制定不同的fsync策略：不进行fsync、每秒fsync一次和每次查询进行fsync。默认是每秒fsync一次。这意味着你最多丢失一秒钟的数据。&lt;/li&gt;
&lt;li&gt;AOF日志文件是一个纯追加的文件。就算是遇到突然停电的情况，也不会出现日志的定位或者损坏问题。甚至如果因为某些原因（例如磁盘满了）命令只写了一半到日志文件里，我们也可以用&lt;code&gt;redis-check-aof&lt;/code&gt;这个工具很简单的进行修复。&lt;/li&gt;
&lt;li&gt;当AOF文件太大时，Redis会自动在后台进行重写。重写很安全，因为重写是在一个新的文件上进行，同时Redis会继续往旧的文件追加数据。新文件上会写入能重建当前数据集的最小操作命令的集合。当新文件重写完，Redis会把新旧文件进行切换，然后开始把数据写到新文件上。&lt;/li&gt;
&lt;li&gt;AOF把操作命令以简单易懂的格式一条接一条的保存在文件里，很容易导出来用于恢复数据。例如我们不小心用&lt;code&gt;FLUSHALL&lt;/code&gt;命令把所有数据刷掉了，只要文件没有被重写，我们可以把服务停掉，把最后那条命令删掉，然后重启服务，这样就能把被刷掉的数据恢复回来。&lt;/li&gt;
&lt;/ul&gt;&lt;h2 id=&quot;缺点&quot;&gt;缺点&lt;/h2&gt;
&lt;ul&gt;&lt;li&gt;在相同的数据集下，AOF文件的大小一般会比RDB文件大。&lt;/li&gt;
&lt;li&gt;在某些fsync策略下，AOF的速度会比RDB慢。通常fsync设置为每秒一次就能获得比较高的性能，而在禁止fsync的情况下速度可以达到RDB的水平。&lt;/li&gt;
&lt;li&gt;在过去曾经发现一些很罕见的BUG导致使用AOF重建的数据跟原数据不一致的问题。&lt;/li&gt;
&lt;/ul&gt;&lt;h2 id=&quot;启用aof&quot;&gt;启用AOF&lt;/h2&gt;
&lt;p&gt;把配置项&lt;code&gt;appendonly&lt;/code&gt;设为&lt;code&gt;yes&lt;/code&gt;：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;appendonly yes&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1330447/201907/1330447-20190722235927525-779949467.png&quot;/&gt;&lt;/p&gt;
&lt;h2 id=&quot;文件路径和名称-1&quot;&gt;文件路径和名称&lt;/h2&gt;
&lt;pre&gt;
&lt;code&gt;# 文件存放目录，与RDB共用。默认为当前工作目录。
dir ./

# 默认文件名为appendonly.aof
appendfilename &quot;appendonly.aof&quot;&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;可靠性&quot;&gt;可靠性&lt;/h2&gt;
&lt;p&gt;你可以配置Redis调用fsync的频率，有三个选项：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;每当有新命令追加到AOF的时候调用fsync。速度最慢，但是最安全。&lt;/li&gt;
&lt;li&gt;每秒fsync一次。速度快（2.4版本跟快照方式速度差不多），安全性不错（最多丢失1秒的数据）。&lt;/li&gt;
&lt;li&gt;从不fsync，交由系统去处理。这个方式速度最快，但是安全性一般。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;推荐使用每秒fsync一次的方式（默认的方式），因为它速度快，安全性也不错。相关配置如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;# appendfsync always
appendfsync everysec
# appendfsync no&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1330447/201907/1330447-20190722235937919-1184472518.png&quot;/&gt;&lt;/p&gt;
&lt;h2 id=&quot;日志重写&quot;&gt;日志重写&lt;/h2&gt;
&lt;p&gt;随着写操作的不断增加，AOF文件会越来越大。例如你递增一个计数器100次，那么最终结果就是数据集里的计数器的值为最终的递增结果，但是AOF文件里却会把这100次操作完整的记录下来。而事实上要恢复这个记录，只需要1个命令就行了，也就是说AOF文件里那100条命令其实可以精简为1条。所以Redis支持这样一个功能：在不中断服务的情况下在后台重建AOF文件。&lt;/p&gt;
&lt;p&gt;工作原理如下：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;Redis调用fork()，产生一个子进程。&lt;/li&gt;
&lt;li&gt;子进程把新的AOF写到一个临时文件里。&lt;/li&gt;
&lt;li&gt;主进程持续把新的变动写到内存里的buffer，同时也会把这些新的变动写到旧的AOF里，这样即使重写失败也能保证数据的安全。&lt;/li&gt;
&lt;li&gt;当子进程完成文件的重写后，主进程会获得一个信号，然后把内存里的buffer追加到子进程生成的那个新AOF里。&lt;/li&gt;
&lt;li&gt;Redis&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;我们可以通过配置设置日志重写的条件：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;# Redis会记住自从上一次重写后AOF文件的大小（如果自Redis启动后还没重写过，则记住启动时使用的AOF文件的大小）。
# 如果当前的文件大小比起记住的那个大小超过指定的百分比，则会触发重写。
# 同时需要设置一个文件大小最小值，只有大于这个值文件才会重写，以防文件很小，但是已经达到百分比的情况。

auto-aof-rewrite-percentage 100
auto-aof-rewrite-min-size 64mb&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1330447/201907/1330447-20190722235946806-45288719.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;要禁用自动的日志重写功能，我们可以把百分比设置为0：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;auto-aof-rewrite-percentage 0&lt;/code&gt;
&lt;/pre&gt;
&lt;blockquote readability=&quot;5.3513513513514&quot;&gt;
&lt;p&gt;Redis 2.4以上才可以自动进行日志重写，之前的版本需要手动运行&lt;a href=&quot;http://redis.io/commands/bgrewriteaof&quot;&gt;BGREWRITEAOF&lt;/a&gt;这个命令。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;数据损坏修复&quot;&gt;数据损坏修复&lt;/h2&gt;
&lt;p&gt;如果因为某些原因（例如服务器崩溃）AOF文件损坏了，导致Redis加载不了，可以通过以下方式进行修复：&lt;/p&gt;
&lt;ul readability=&quot;0&quot;&gt;&lt;li&gt;
&lt;p&gt;备份AOF文件。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;使用&lt;code&gt;redis-check-aof&lt;/code&gt;命令修复原始的AOF文件：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;$ redis-check-aof --fix&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1330447/201907/1330447-20190723000004252-565712059.png&quot;/&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;可以使用&lt;code&gt;diff -u&lt;/code&gt;命令看下两个文件的差异。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;使用修复过的文件重启Redis服务。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;h2 id=&quot;从rdb切换到aof&quot;&gt;从RDB切换到AOF&lt;/h2&gt;
&lt;p&gt;这里只说Redis &amp;gt;= 2.2版本的方式：&lt;/p&gt;
&lt;ul readability=&quot;2&quot;&gt;&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;备份一个最新的&lt;code&gt;dump.rdb&lt;/code&gt;的文件，并把备份文件放在一个安全的地方。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;1&quot;&gt;
&lt;p&gt;运行以下两条命令：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;$ redis-cli config set appendonly yes
$ redis-cli config set save &quot;&quot;&lt;/code&gt;
&lt;/pre&gt;&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;确保数据跟切换前一致。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;确保数据正确的写到AOF文件里。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;第二条命令是用来禁用RDB的持久化方式，但是这不是必须的，因为你可以同时启用两种持久化方式。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;记得对配置文件&lt;code&gt;redis.conf&lt;/code&gt;进行编辑启用AOF，因为命令行方式修改配置在重启Redis后就会失效。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;建议的备份方法&quot;&gt;建议的备份方法：&lt;/h2&gt;
&lt;ul&gt;&lt;li&gt;创建一个定时任务，每小时和每天创建一个快照，保存在不同的文件夹里。&lt;/li&gt;
&lt;li&gt;定时任务运行时，把太旧的文件进行删除。例如只保留48小时的按小时创建的快照和一到两个月的按天创建的快照。&lt;/li&gt;
&lt;li&gt;每天确保一次把快照文件传输到数据中心外的地方进行保存，至少不能保存在Redis服务所在的服务器。&lt;/li&gt;
&lt;/ul&gt;
</description>
<pubDate>Mon, 22 Jul 2019 16:00:00 +0000</pubDate>
<dc:creator>Tu9oh0st</dc:creator>
<og:description>Redis持久化 Redis提供了不同的持久化选项： RDB持久化 以指定的时间间隔保存那个时间点的数据快照。 AOF持久化 方法则会记录每一个服务器收到的写操作。在服务器启动时，这些记录的操作会逐条</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/Tu9oh0st/p/11229317.html</dc:identifier>
</item>
</channel>
</rss>