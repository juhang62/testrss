<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="css/feed.xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/" xmlns:og="http://ogp.me/ns#">
<channel>
<atom:link rel="self" href="http://192.168.1.4/fivefilters/makefulltextfeed.php?url=feed.cnblogs.com%2Fblog%2Fsitehome%2Frss&amp;max=10&amp;links=preserve&amp;exc=" />
<atom:link rel="alternate" title="Source URL" href="http://feed.cnblogs.com/blog/sitehome/rss" />
<atom:link rel="related" title="Subscribe to feed" href="http://www.subtome.com/#/subscribe?feeds=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed.cnblogs.com%252Fblog%252Fsitehome%252Frss%26max%3D10%26links%3Dpreserve%26exc%3D&amp;back=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed.cnblogs.com%252Fblog%252Fsitehome%252Frss%26max%3D10%26links%3Dpreserve%26exc%3D" />
<title>博客园_首页</title>
<link></link>
<description>代码改变世界</description>
<item>
<title>Java入门教程十(抽象类接口内部类匿名类) - 韭菜Java</title>
<link>http://www.cnblogs.com/lilinfeng/p/10995743.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/lilinfeng/p/10995743.html</guid>
<description>&lt;p&gt;一个类只定义了一个为所有子类共享的一般形式，至于细节则交给每一个子类去实现，这种类没有任何具体的实例，只具有一些抽象的概念，那么这样的类称为抽象类。&lt;/p&gt;
&lt;p&gt;在面向对象领域，抽象类主要用来进行类型隐藏。比如，如果我们进行一个图形编辑软件的开发，就会发现问题领域存在着圆、三角形这样一些具体概念，它们是不同的，但是它们都属于形状这样一个概念，形状这个概念在问题领域是不存在的，它就是一个抽象概念。正是因为抽象概念在问题领域没有对应的具体概念，所以用以表征抽象概念的抽象类是不能够实例化的。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;abstract class class_name
{
    abstract type method_name(parameter);
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;abstract 表示该类或该方法是抽象的；class_name 表示抽象类的名称；method_name 表示抽象方法名称，如果在一个方法之前使用 abstract 来修饰，则说明该方法是抽象方法，不能有方法体；parameter 表示方法参数列表。&lt;/p&gt;
&lt;p&gt;abstract 关键字只能用于普通方法，不能用于 static 方法或者构造方法中。在抽象类中必须包含至少一个抽象方法，并且所有抽象方法不能有具体的实现，而应在它们的子类中实现所有的抽象方法（要有方法体），包含一个或多个抽象方法的类必须通过在其 class 声明前添加 abstract 关键字将其声明为抽象类。因为一个抽象类不定义完整的实现，所以抽象类也就没有自己的对象。因此，任何使用 new 创建抽象类对象的尝试都会导致编译时错误。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;public abstract class Shape
{
    public int width;     //几何图形的长
    public int height;    //几何图形的宽
    public Shape(int width,int height)
    {
        this.width=width;
        this.height=height;
    }
    public abstract double area();    //定义抽象方法，计算面积
}
public class Square extends Shape
{
    public Square(int width,int height)
    {
        super(width,height);
    }
    @Override
    public double area()//重写父类中的抽象方法，实现计算正方形面积的功能
    {
        return width*height;
    }
}
public static void main(String[] args)
{
    Square square=new Square(5,4);
    System.out.println(&quot;面积为：&quot;+square.area());//输出：面积为：20
}&lt;/code&gt;
&lt;/pre&gt;

&lt;p&gt;接口类似于类，但接口的成员没有执行体，它只是方法、属性、事件和索引符的组合而已。接口不能被实例化，接口没有构造方法，没有字段。在应用程序中，接口就是一种规范，它封装了可以被多个类继承的公共部分。&lt;/p&gt;
&lt;p&gt;接口继承和实现继承的规则不同，一个类只有一个直接父类，但可以实现多个接口。Java 接口本身没有任何实现，只描述 public 行为，因此 Java 接口比 Java 抽象类更抽象化。Java 接口的方法只能是抽象的和公开的，Java 接口不能有构造方法，Java 接口可以有 public、Static 和 final 属性。&lt;/p&gt;
&lt;p&gt;接口把方法的特征和方法的实现分隔开来，这种分隔体现在接口常常代表一个角色，它包装与该角色相关的操作和属性，而实现这个接口的类便是扮演这个角色的演员。一个角色由不同的演员来演，而不同的演员之间除了扮演一个共同的角色之外，并不要求其他的共同之处。&lt;/p&gt;
&lt;p&gt;接口对于其声明、变量和方法都做了许多限制，这些限制作为接口的特征归纳如下：&lt;br/&gt;具有 public 访问控制符的接口，允许任何类使用；没有指定 public 的接口，其访问将局限于所属的包。&lt;br/&gt;方法的声明不需要其他修饰符，在接口中声明的方法，将隐式地声明为公有的（public）和抽象的（abstract）。&lt;br/&gt;在 Java 接口中声明的变量其实都是常量，接口中的变量声明，将隐式地声明为 public、static 和 final，即常量，所以接口中定义的变量必须初始化。接口没有构造方法，不能被实例化。&lt;/p&gt;
&lt;h2 id=&quot;定义&quot;&gt;定义&lt;/h2&gt;
&lt;pre&gt;
&lt;code&gt;public interface interfaceName{
}
//例如
public interface Personlnterface{    
    String name;    //不合法，变量name必须初始化
    int age=20;     //合法，等同于 public static final int age=20;
    void getInfo(); //方法声明，等同于 public abstract void getInfo();
}&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;实现&quot;&gt;实现&lt;/h2&gt;
&lt;p&gt;在实现类中，所有的方法都使用了 public 访问修饰符声明。无论何时实现一个由接口定义的方法，它都必须实现为 public，因为接口中的所有成员都显式声明为 public&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;public class Person implements Personlnterface
{
    public void getInfo(){
        return &quot;Hello World&quot;;
    }
}&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;使用&quot;&gt;使用&lt;/h2&gt;
&lt;pre&gt;
&lt;code&gt;public static void main(String[] args){
    Personlnterface person = new Person();
    person.getInfo();//返回 HelloWorld
}&lt;/code&gt;
&lt;/pre&gt;

&lt;p&gt;在面向对象的设计思想中，所有的对象都是通过类来描绘的，但是反过来，并不是所有的类都是用来描绘对象的，如果一个类中没有描绘一个具体的对象，那么这样的类就是抽象类，抽象类是对那些看上去不同，但是本质上相同的具体概念的抽象，正是因为抽象的概念在问题领域没有对应的具体概念，所以抽象类是不能够实例化的&lt;/p&gt;
&lt;h2 id=&quot;语法不同&quot;&gt;语法不同&lt;/h2&gt;
&lt;p&gt;接口内只能是功能的定义，而抽象类中则可以包括功能的定义和功能的实现。在接口中，所有的属性肯定是 public、static 和 final，所有的方法都是 abstract，所以可以默认不写上述标识符；在抽象类中，既可以包含抽象的定义，也可以包含具体的实现方法&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;public interface Animal
{
    public void eat();
    public String fly();
}
public abstract class Animal
{
    public abstract void eat();
    public String fly(){
        return &quot;我会飞&quot;;
    };
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;接口的实现类中使用 implements 关键字；而在抽象类的实现类中，则使用 extends 关键字。一个接口的实现类可以实现多个接口，而一个抽象类的实现类则只能实现一个抽象类。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;//接口
public class concreteAnimal implements Animal
{
    public void eat(){}
    public void fly(){}
}
//抽象类
public class concreteAnimal extends Animal
{
    public void eat(){}
    public void fly(){}
}&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;设计思想不同&quot;&gt;设计思想不同&lt;/h2&gt;
&lt;p&gt;从前面抽象类的具体实现类的实现方式可以看出，其实在 Java 中，抽象类和具体实现类之间是一种继承关系，也就是说如果釆用抽象类的方式，则父类和子类在概念上应该是相同的。接口却不一样，如果采用接口的方式，则父类和子类在概念上不要求相同。接口只是抽取相互之间没有关系的类的共同特征，而不用关注类之间的关系，它可以使没有层次关系的类具有相同的行为。因此，可以这样说：抽象类是对一组具有相同属性和方法的逻辑上有关系的事物的一种抽象，而接口则是对一组具有相同属性和方法的逻辑上不相关的事物的一种抽象。&lt;/p&gt;
&lt;p&gt;强列的is a 使用抽象类，has a 使用接口。如：鸟是一种动物。鸟有一个功能会飞。猫也是一种动物，但是猫不会飞。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;//接口
public interface Fly
{
    public void flyUp();
}
//抽象类
public abstract class Animal
{
    public abstract void eat();
}
//猫是一种动物
public class Cat extends Animal{
}
//鸟是一种动物，同时会飞
public class Bird extends Animal implements Run {
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;抽象类是对一组具有相同属性和方法的逻辑上有关系的事物的一种抽象，而接口则是对一组具有相同属性和方法的逻辑上不相关的事物的一种抽象，因此抽象类表示的是“is a”关系，接口表示的是“has a”关系。&lt;/p&gt;

&lt;p&gt;在一个类内部的类，我们称之为内部类。内部类可以很好地实现隐藏，一般的非内部类是不允许有 private 与 protected 权限的，但内部类可以。内部类拥有外围类的所有元素的访问权限。&lt;/p&gt;
&lt;p&gt;内部类可以分为：实例内部类、静态内部类和成员内部类，每种内部类都有它特定的一些特点，本节先详细介绍一些和内部类相关的知识。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/93372/201906/93372-20190610074910198-2075585816.jpg&quot;/&gt;&lt;/p&gt;
&lt;p&gt;内部类的特点如下：&lt;br/&gt;内部类仍然是一个独立的类，在编译之后内部类会被编译成独立的 .class 文件，但是前面冠以外部类的类名和 $ 符号。&lt;br/&gt;内部类不能用普通的方式访问。内部类是外部类的一个成员，因此内部类可以自由地访问外部类的成员变量，无论是否为 private 的。&lt;br/&gt;内部类声明成静态的，就不能随便访问外部类的成员变量，仍然是只能访问外部类的静态成员变量。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;public class Test
{
    public class InnerClass
    {
        public int getSum(int x,int y)
        {
            return x+y;
        }
    }
    public static void main(String[] args)
    {
        Test.InnerClass testInner =new Test().new InnerClass();
        int i = testInner.getSum(2/3);
        System.out.println(i); //输出5
    }
}&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;实例内部类&quot;&gt;实例内部类&lt;/h2&gt;
&lt;p&gt;实例内部类是指没有用 static 修饰的内部类&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;public class Outer
{
    class Inner
    {
        //实例内部类
    }
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;在外部类的静态方法和外部类以外的其他类中，必须通过外部类的实例创建内部类的实例，如果有多层嵌套，则内部类可以访问所有外部类的成员&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;public class Outer
{
    class Inner{}
    Inner i=new Inner();    //类内部不需要创建外部类实例
    public void method0()
    {
        Inner j=new Inner();    //类内部不需要创建外部类实例
    }
    public static void method1()
    {
        Inner r=new Outer().new inner();    //静态方法需要创建外部类实例
    }
    class Inner1
    {
        Inner k=new Inner();    //不需要创建外部类实例
    }
}
class OtherClass
{
    Outer.Inner i=new Outer().new Inner();    //其他类使用时需要创建外部类实例
}&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;静态内部类&quot;&gt;静态内部类&lt;/h2&gt;
&lt;p&gt;静态内部类是指使用 static 修饰的内部类&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;public class Outer
{
    static class Inner
    {
        //静态内部类
    }
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;在创建静态内部类的实例时，不需要创建外部类的实例&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;public class Outer
{
    static class Inner{}
}
class OtherClass
{
    Outer.Inner oi=new Outer.Inner();
}&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;局部内部类&quot;&gt;局部内部类&lt;/h2&gt;
&lt;p&gt;局部内部类是指在一个方法中定义的内部类&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;public class Test
{
    public void method()
    {
        class Inner
        {
            //局部内部类
        }
    }
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;局部内部类与局部变量一样，不能使用访问控制修饰符（public、private 和 protected）和 static 修饰符修饰，局部内部类只在当前方法中有效，局部内部类中可以访问外部类的所有成员&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;public class Test
{
    Inner i=new Inner();    //编译出错
    Test.Inner ti=new Test.Inner();    //编译出错
    Test.Inner ti2=new Test().new Inner();    //编译出错
    public void method()
    {
        class Inner{}
        Inner i=new Inner();
    }
}&lt;/code&gt;
&lt;/pre&gt;

&lt;p&gt;匿名类是指没有类名的内部类，必须在创建时使用 new 语句来声明类&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;new&amp;lt;类或接口&amp;gt;()
{
    //类的主体
};&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;这种形式的 new 语句声明一个新的匿名类，它对一个给定的类进行扩展，或者实现一个给定的接口。使用匿名类可使代码更加简洁、紧凑，模块化程度更高&lt;br/&gt;匿名类有两种实现方式：&lt;br/&gt;继承一个类，重写其方法。&lt;br/&gt;实现一个接口（可以是多个），实现其方法。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;public class Out
{
    void show()
    {
        System.out.println(&quot;调用 Out 类的 show() 方法&quot;);
    }
}
public class TestAnonymousInterClass
{
    //在这个方法中构造一个匿名内部类
    private void show()
    {
        Out anonyInter=new Out()
        {
            //获取匿名内部类的实例
            void show()
            {
                System.out.println(&quot;调用匿名类中的 show() 方法&quot;);
            }
        };
        anonyInter.show();
    }
    public static void main(String[] args)
    {
        TestAnonymousInterClass test=new TestAnonymousInterClass();
        test.show();
    }
}&lt;/code&gt;
&lt;/pre&gt;</description>
<pubDate>Mon, 10 Jun 2019 00:02:00 +0000</pubDate>
<dc:creator>韭菜Java</dc:creator>
<og:description>抽象类（abstract） 一个类只定义了一个为所有子类共享的一般形式，至于细节则交给每一个子类去实现，这种类没有任何具体的实例，只具有一些抽象的概念，那么这样的类称为抽象类。 在面向对象领域，抽象类</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/lilinfeng/p/10995743.html</dc:identifier>
</item>
<item>
<title>多维扩展点的思考与设计——解决渠道、产品增加引发的腐化问题 - YOYO&amp;#</title>
<link>http://www.cnblogs.com/skyesx/p/10995730.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/skyesx/p/10995730.html</guid>
<description>&lt;p&gt;随着业务渠道及产品的增加，你的代码是否开始陷入IF-ELSE组成的泥潭，难以脱身？&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://note.youdao.com/yws/public/resource/fe3e61373c5484141b5544338800b63a/xmlnote/WEBRESOURCE31c162542e7be684341c583f43a2fbde/40530&quot; alt=&quot;image&quot;/&gt;&lt;/p&gt;
&lt;h3 id=&quot;持续增加的渠道特性&quot;&gt;持续增加的渠道特性&lt;/h3&gt;
&lt;p&gt;小码同学一来到新公司，就负责起了一个新开始，但具有无限想象空间的后台开发项目。就像所有的互联网项目一样，业务变化极其迅速，为了减少初期试错成本，小码同学选用了流行、便捷的贫血模型，也就是Service+DAO/RPC结构，做了简单的关注点分离——业务以及基础设施（存储/远程服务）的分离。&lt;/p&gt;
&lt;p&gt;业务很给力，主要流程模式已逐渐成型，同时也增加了很多的营销渠道，有公司内部的 App、有公众号、小程序、H5，也有各类外部的合作伙伴的渠道，小码同学一直都在高负荷地工作着，完全来不及思考要怎么优雅地解决这些渠道增加带来的问题。然而，每个渠道会有一个渠道相关的小特性，这意味着在 登录、注册、做业务等等各个Service里，每增加一个渠道时，都要增加一段关于渠道判断的IF-ELSE判断语句。量变引起质变，当渠道加到近十个时，小码懵逼了，理清代码逻辑脉络变得极为困难，因为看一遍代码，需要将要受到近十个不同渠道分支代码的干扰。同时代码也变得难以并行开发，多个渠道的拓展会因为同一个Service的修改而更容易发生冲突。&lt;br/&gt;&lt;img src=&quot;https://note.youdao.com/yws/public/resource/fe3e61373c5484141b5544338800b63a/xmlnote/91C411490BDA4190B86802742441AB9D/40238&quot; alt=&quot;image&quot;/&gt;&lt;/p&gt;
&lt;p&gt;其实这里小码可能会采取另外一种做法，陷入另外一种困境，小码同学每增加一个渠道就将原来的代码复制一份，然后针对渠道进行简单的修改，然后就可以安全高效地完成业务需求了。然而复制代码一时爽，&lt;del&gt;一直复制一直爽&lt;/del&gt;，当我们需要修改一些渠道公共实现，理清不同渠道实现的区别并修改时，近十个渠道就会让我们就变得痛不欲生了。&lt;br/&gt;&lt;img src=&quot;https://note.youdao.com/yws/public/resource/fe3e61373c5484141b5544338800b63a/xmlnote/914C8E255E0F4D8C8676BC1C5962FC25/40242&quot; alt=&quot;image&quot;/&gt;&lt;/p&gt;
&lt;h3 id=&quot;公用逻辑下沉解决方案&quot;&gt;公用逻辑下沉解决方案&lt;/h3&gt;
&lt;p&gt;小码同学想了下，无论多忙都要从这个困境中破局，于是他想出了以下方案：&lt;br/&gt;&lt;img src=&quot;https://note.youdao.com/yws/public/resource/fe3e61373c5484141b5544338800b63a/xmlnote/6D08B64F02BA4F3AA19390CD3C174A36/40230&quot; alt=&quot;image&quot;/&gt;&lt;/p&gt;
&lt;p&gt;将公共的逻辑下沉，将各个渠道特有的判断及逻辑都上提。如此一来我们可以从代码中分离渠道和公用业务逻辑——要理解渠道特性，我们可以从渠道所在模块(微服务/package/service)的代码得知，如果要理解通用的信息，则到公共&lt;br/&gt;业务逻辑层查看对应的实现。&lt;/p&gt;
&lt;p&gt;但若要使用本解决方案解决目前系统的问题，则需要引入大量的重构，因为该实现需要将大量已有存在的渠道逻辑变更其发生的逻辑时间点，这需要大量的开发及测试人力支持。&lt;/p&gt;
&lt;h3 id=&quot;扩展点解决方案&quot;&gt;扩展点解决方案&lt;/h3&gt;
&lt;p&gt;于是小码同学开始在网上搜索相关的解决方案，了解到阿里有个可以解决类似问题的框架实现COLA，并以此为参考开展了自己的扩展点设计&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;https://github.com/alibaba/COLA&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;其引入了一种名为 扩展点/插件 的机制（扩展点是一个Interface,扩展点实现为interface的一个特定实现），让我们可以达到以下效果：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://note.youdao.com/yws/public/resource/fe3e61373c5484141b5544338800b63a/xmlnote/212C9190F49A4531823E04326A811979/40280&quot; alt=&quot;image&quot;/&gt;&lt;/p&gt;
&lt;p&gt;要实现这个效果，强制我们把相关业务语义显式化，例如 通用业务逻辑Service在没有引入扩展点前，写的校验身份的代码为&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;if(is渠道B) {
    渠道B的一大堆代码进行身份校验
} else {
    默认实现的一大堆代码进行身份校验
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;而引入扩展点后，在通用业务逻辑Service写的则是&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;校验身份扩展点.执行校验();&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;其显式化了业务语义，并像 公用逻辑下沉 的解决方案一样 分离了主干的代码逻辑和特定实现的代码逻辑，还能保证原有特定渠道逻辑执行的相对位置不变。&lt;/p&gt;
&lt;p&gt;在扩展点机制的支持下我们只需要定下规范——在通用业务逻辑层不能出现任何关于Channel渠道的IF-ELSE判断，这样就可收获大量有基础抽象的通用业务逻辑代码，提高识别基础抽象的能力。&lt;/p&gt;
&lt;h3 id=&quot;扩展点解决方案的本质&quot;&gt;扩展点解决方案的本质&lt;/h3&gt;
&lt;p&gt;扩展点本质上就是个带有自动路由功能的策略模式，其根据业务上下文信息，自动推断出应该选用哪个具体的扩展点实现。&lt;br/&gt;&lt;img src=&quot;https://note.youdao.com/yws/public/resource/fe3e61373c5484141b5544338800b63a/xmlnote/FF5A42C158CB4524BB3136A3BBC6CF37/40371&quot; alt=&quot;image&quot;/&gt;&lt;/p&gt;
&lt;p&gt;扩展点的机制和原理简单，使用也很简单，但其给业务系统代码带来却是变革性的。&lt;/p&gt;
&lt;h3 id=&quot;多维扩展问题的出现&quot;&gt;多维扩展问题的出现&lt;/h3&gt;
&lt;p&gt;小码同学利用扩展点已经阻止了渠道增加带来的代码腐化加剧问题，小码以保守起见：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;对于没有任何业务变化的代码保持不变&lt;/li&gt;
&lt;li&gt;对于新增的渠道使用扩展点来防止代码进一步腐化&lt;/li&gt;
&lt;li&gt;对于存在业务变动的代码，在测试资源的支持下，利用扩展点重构原有代码，令代码变得新鲜&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;但新的问题出现了，项目中也有一个与渠道类似的，会不断扩展实现的概念——产品。&lt;/p&gt;
&lt;p&gt;在小码的系统中，每增加一个产品也是按照类似先前增加渠道的形式，以IF-ELSE完成扩展。于是，小码希望直接套用之前的扩展点机制，然而事情并没有这么顺利。&lt;/p&gt;
&lt;p&gt;在上一幅图中，contextCode为&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;companyY.channelB&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;其表征的是渠道维度的身份信息，我们以该信息为依据，来匹配最适合的渠道相关的实现。与此类似，我们需要引入产品维度的身份信息，同时也要将不同维度的contextCode加以区分，然而COLA的实现中并不支持此类多维扩展实现，于是小码开始设计了自己的ConextCode及ImplementCode规范，增加了维度标识符：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;channel:companyY.channelB
product:companyY.ProductO.subProductE&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;通过维度标志，小码分开了不同维度的扩展点以及其对应的实现，解决了大部分的问题。&lt;/p&gt;
&lt;h3 id=&quot;多维扩展点冲突问题&quot;&gt;多维扩展点冲突问题&lt;/h3&gt;
&lt;p&gt;引入多维扩展点后，大多数扩展实现都在各自的维度良好运行，井水不犯河水。然而，有少数扩展点却出现了需要多维同时决定实现的场景，如：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;当前若是渠道A且是产品X的情况下需要使用特定的扩展实现。&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;目前基于维度隔离的扩展点感觉无法支持此类需求，于是，小码继续查找相关资料，了解到了阿里TMF2.0框架的实现：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;https://segmentfault.com/a/1190000012541958&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;TMF2.0按文中介绍，其为一个二维的扩展点实现，这两维分别是：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;行业维度
&lt;ul&gt;&lt;li&gt;一个行业维度的代码即为TMF2.0的业务身份&lt;/li&gt;
&lt;li&gt;其等价于小码之前设计的没带维度标志的contextCode&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;产品维度
&lt;ul&gt;&lt;li&gt;与本文中的产品设定完全不同，请勿套入理解&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;与小码之前设计的维度隔离扩展点不同，TMF2.0中行业维度与产品维度会共享扩展点，然而当出现扩展点冲突时，TMF2.0会以业务身份为线索，通过可视化界面配置特定业务身份在遇到扩展实现冲突时应该选择哪一个扩展实现，并将其固化成配置，运行时依据配置选择最终扩展实现。&lt;/p&gt;
&lt;p&gt;然而该设定并不符合项目的现状，相关UI的开发设计也是一个巨大的工程，因此小码设计了另外一种折中的设定：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;扩展点依然按维度隔离&lt;/li&gt;
&lt;li&gt;当出现扩展点路由需要多维信息决策时，采用嵌套形式&lt;/li&gt;
&lt;li&gt;不同扩展点不同维度的嵌套的次序，都按照固定的次序进行&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;如下图所示&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://note.youdao.com/yws/public/resource/fe3e61373c5484141b5544338800b63a/xmlnote/00DF5E8FACD248BB8A974AF61D744388/40466&quot; alt=&quot;image&quot;/&gt;&lt;/p&gt;
&lt;p&gt;这个设定的实现虽然繁琐，但是实际情况下，出现多维共同干预扩展实现选择的情况应该相对少，相对于扩展点维度隔离得到的好处，其应该可以接受。&lt;/p&gt;
&lt;h3 id=&quot;舒心的小码&quot;&gt;舒心的小码&lt;/h3&gt;
&lt;p&gt;扩展点的理论简单易用，其使得&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;业务主流程代码拥有基础抽象，使得脉络清晰明了&lt;/li&gt;
&lt;li&gt;各个渠道、产品的特性高度内聚于各自的package中&lt;/li&gt;
&lt;li&gt;业务主流程成熟后，新增的产品、渠道再也不需要动业务主流程代码，只需增加新的渠道包及产品包
&lt;ul&gt;&lt;li&gt;业务主流程代码没变动，减少了全局风险，减少了测试量&lt;/li&gt;
&lt;li&gt;扩展只涉及对应的渠道、产品的增加，这天然隔离了不同开发组的工作，提高了并行度&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;从此小码和他的小伙伴们从此摆脱了996，与基友们过上了幸福快乐的生活。&lt;/p&gt;
&lt;h3 id=&quot;作者简介&quot;&gt;作者简介&lt;/h3&gt;
&lt;p&gt;多年金融行业经验，现为某Top2民营银行高级搬砖工，曾在两家TOP3股份制商业银行及一家互金创业公司工作（架构、核心业务主程），EasyTransaction作者，欢迎关注个人公众号，在这里我会分享日常工作、生活中对于架构、编码和业务的思考&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://github.com/QNJR-GROUP/ImageHub/blob/master/easytrans/wechat_public_account.jpg?raw=true&quot; alt=&quot;image&quot;/&gt;&lt;/p&gt;
</description>
<pubDate>Sun, 09 Jun 2019 23:26:00 +0000</pubDate>
<dc:creator>YOYO&amp;amp;#</dc:creator>
<og:description>随着业务渠道及产品的增加，你的代码是否开始陷入IF ELSE组成的泥潭，难以脱身？ 持续增加的渠道特性 小码同学一来到新公司，就负责起了一个新开始，但具有无限想象空间的后台开发项目。就像所有的互联网项</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/skyesx/p/10995730.html</dc:identifier>
</item>
<item>
<title>十年风雨，一个普通程序员的成长之路（五） - 妖生</title>
<link>http://www.cnblogs.com/yaoshen/p/10995613.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/yaoshen/p/10995613.html</guid>
<description>&lt;h2 id=&quot;十年风雨一个普通程序员的成长之路五&quot;&gt;十年风雨，一个普通程序员的成长之路（五）&lt;/h2&gt;
&lt;blockquote readability=&quot;3.9655172413793&quot;&gt;
&lt;p&gt;author &lt;a href=&quot;https://www.cnblogs.com/yaoshen/&quot;&gt;妖生&lt;/a&gt;&lt;br/&gt;date 2019.06.09&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;成长抉择与失去上&quot;&gt;成长、抉择与失去（上）&lt;/h2&gt;
&lt;h3 id=&quot;一前言生活的演变&quot;&gt;一、前言：生活的演变&lt;/h3&gt;
&lt;p&gt;在14年到18年间，我的生活中经历了喜乐悲丧，结婚、生子，爷爷的去世，老赵的病逝。&lt;br/&gt;在个人职位上，则从开发组长到项目经理，惭愧的是，是老赵因病离职才给了我这个机会。&lt;br/&gt;项目经历上，在这几年里，历经核心征管、管理决策、金三改造、数据迁移、大数据开发、税警交换等各种项目。&lt;br/&gt;项目类型有OLTP、OLAP，有接手维护的，有重构的，还有从零开始的。&lt;/p&gt;
&lt;p&gt;其中涉及的技术栈则让我见证了公司从远古到近代的演变：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;ORM从datawindown、ormap到ibatis、Mybaits&lt;/li&gt;
&lt;li&gt;framework从自研的sm@rtFrame到spring、springboot&lt;/li&gt;
&lt;li&gt;打包工具从ant到maven、gradle&lt;/li&gt;
&lt;li&gt;前端渲染从HTC到freemark、jQuery+layui、antdesign&lt;/li&gt;
&lt;li&gt;数据存储从Oracle11g到12c、mpp、noSql、hadoop、elasticsearch&lt;/li&gt;
&lt;li&gt;数据处理从kettle、ogg到sqlloader、kafka、flum、mapreduce、storm、spark&lt;/li&gt;
&lt;li&gt;系统架构从SOA的垂直分离到集成服务又到微服务&lt;/li&gt;
&lt;li&gt;服务管理从ESB到API网关&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;那么，在这些年里，主要做了些什么？又学到了些什么呢？&lt;/p&gt;
&lt;p&gt;现在想想，好像大多都记不得了。只挑印象最深的几件事来说吧。&lt;br/&gt;有正面，也有反例。&lt;br/&gt;总结一下，便是得到与教训吧。&lt;/p&gt;
&lt;h3 id=&quot;二成长得到与教训&quot;&gt;二、成长：得到与教训&lt;/h3&gt;
&lt;h4 id=&quot;计划制定与执行&quot;&gt;2.1 计划制定与执行&lt;/h4&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;有意识地参与工作计划的制定，分解里程碑计划与每周计划，正确认识团队协作中每个人能力的不同，合理安排人员计划，并&lt;code&gt;跟踪执行&lt;/code&gt;a。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h5 id=&quot;为什么推荐周计划&quot;&gt;为什么推荐周计划？&lt;/h5&gt;
&lt;p&gt;这里说说为什么是周计划，而不是天计划、月计划？按天的计划太有压迫性，&lt;em&gt;容易让开发人员思维紧张&lt;/em&gt;，每日跟踪也太浪费时间；而超过一周的计划则太过宽松，会在中途导致不可预估的风险，增加调整难度。&lt;/p&gt;
&lt;h5 id=&quot;怎样为不同的成员分配合理的工作量&quot;&gt;怎样为不同的成员分配合理的工作量？&lt;/h5&gt;
&lt;p&gt;在工作计划的制定中，很多技术人员在做team leader 后有一个通病，总是以自己的能力来衡量他人，导致产生不可预知的风险。&lt;/p&gt;
&lt;h5 id=&quot;为什么一定要跟踪计划&quot;&gt;为什么一定要跟踪计划？&lt;/h5&gt;
&lt;p&gt;计划制定后，对于计划的执行则需要随时跟踪，监控前后变化，预估风险。计划在周五晚汇总，但并不意味着中途不予过问，最好的时间应该在周三时跟踪下计划执行情况，对于开发人员没有比较大的压迫感，又能及时沟通不能按时完成的风险，进行调整。&lt;/p&gt;
&lt;h5 id=&quot;吐槽&quot;&gt;吐槽&lt;/h5&gt;
&lt;ul readability=&quot;0.5&quot;&gt;&lt;li readability=&quot;1&quot;&gt;
&lt;p&gt;站立会&lt;br/&gt;在有些公司的最佳实践中，还包含了早（晚）站立会，实际上我是有些看不起的，因为一个teamleader连十人内的人员进度情况都不能随时掌握，有点脱离群众了。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;屁股与脑袋&lt;br/&gt;在职位晋升后，有些人的脑袋似乎便被屁股所掌握，忘记了曾经在所吐槽的人和制度。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;h5 id=&quot;得到&quot;&gt;得到&lt;/h5&gt;
&lt;p&gt;在每次周计划的跟踪中，摸清团队成员的能力上限，给团队人员多一点点但不要超过太多的工作量。&lt;br/&gt;在里程碑的进度跟踪上，需要在项目进度与人员成长、工作强度（加班）之间作平衡，考验team leader的内部带团能力。&lt;br/&gt;在位置调换后，你有时会理解以前吐槽段子中的领导为何有这样那样的安排。&lt;br/&gt;只是，不忘初心，砥砺前行。&lt;/p&gt;
&lt;h5 id=&quot;教训&quot;&gt;教训&lt;/h5&gt;
&lt;p&gt;如果有资源缺失的情况，千万不要自己背，例如这个成员能力差了点、那个技术路线有点风险，特别涉及到外部资源协调的情况，要及时上报，争取资源。&lt;/p&gt;
&lt;p&gt;不要觉得这算什么，我自己加班搞两个小时就搞定了。一是把自己累死，二是有苦劳没功劳。&lt;/p&gt;
&lt;p&gt;事情压在手里万一没解决的情况下，导致进度受挫，损失的是公司的钱、领导的信任、团队的士气。&lt;/p&gt;
&lt;h4 id=&quot;个人能力提升&quot;&gt;2.2 个人能力提升&lt;/h4&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;从前端到后端，从业务系统的开发到服务部署，从需求沟通到数据模型设计，从项目售前到项目立项。不知不觉就成了所谓的全栈工程师。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h5 id=&quot;得到-1&quot;&gt;得到&lt;/h5&gt;
&lt;h6 id=&quot;专业技能上的广度与深度有什么提升&quot;&gt;专业技能上的广度与深度有什么提升？&lt;/h6&gt;
&lt;p&gt;&lt;em&gt;广度&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;语言&lt;br/&gt;JavaScript、java、python&lt;/li&gt;
&lt;li&gt;前端&lt;br/&gt;中台web、移动H5、小程序；&lt;/li&gt;
&lt;li&gt;交付&lt;br/&gt;CI/CD概念及工具、ant/maven/gradle&lt;/li&gt;
&lt;li&gt;服务容器&lt;br/&gt;weblogic、tomcat、nginx；&lt;/li&gt;
&lt;li&gt;linux系统&lt;br/&gt;redhat、centOS、Ubuntu&lt;/li&gt;
&lt;li&gt;虚拟化&lt;br/&gt;OpenStack、KVM、VMware、docker&lt;/li&gt;
&lt;li&gt;测试&lt;br/&gt;用例、计划与报告，冒烟、覆盖与回归，人工、自动化，功能、安全与性能&lt;/li&gt;
&lt;li&gt;性能&lt;br/&gt;CPU、内存与IO，进程、线程与管道，QPS、TPS与PV，压力、负载、稳定性&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;em&gt;深度&lt;/em&gt;&lt;br/&gt;而深度上，对我提升最大的应该是Oracle，这也是得益于老赵对我们的技术分享，记得那次分享还推荐了一本书——《收货，不只是oracle》。&lt;br/&gt;掌握了实例、表空间、用户、表结构设计、索引优化、系统表、redo、flush、DBF文件及IMPDP/EXPDP、AWR报告等oracle的理论及相关工具并予以实践，此时再去看诸如mysql等其他结构及非结构化的数据库，easy。&lt;/p&gt;
&lt;h6 id=&quot;掌握了哪些业务能力&quot;&gt;掌握了哪些业务能力？&lt;/h6&gt;
&lt;p&gt;历经申报、征收、登记、发票、文书等核心征管业务，又掌握了些元数据、数据仓库、数据处理、数据质量、数据分析的理念设计以及相关的一些工具。&lt;br/&gt;与客户沟通的时候什么都能说上一点吧。&lt;/p&gt;
&lt;h6 id=&quot;项目管理的一些软技能&quot;&gt;项目管理的一些软技能&lt;/h6&gt;
&lt;p&gt;参与并主导项目售前、投标、立项到项目启动、执行、上线、运维等一系列项目活动。&lt;br/&gt;从一开始的项目意向沟通，原始需求的收集、分析到编写需求规格说明书，设计界面原型，然后是投标书中的技术指标编写与审核，项目立项与公司流程的审核，项目中途的代码与文档审计，项目上线前的等保评测、安全加固等等，不一而足。&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;效率工具&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;这里用到的几个专业工具倒是可以说下，office2016套装且不说了。&lt;br/&gt;界面原型设计推荐Axure + antDesign，&lt;br/&gt;流程及架构设计则推荐在线工具ProcessOn（本地则是visio、PPT），&lt;br/&gt;思维导图及团队协作也可以使用ProcessOn（本地则是xmind + excel），&lt;br/&gt;数据模型设计我也用的是ProcessOn（本地则可以用powerdesign）。&lt;/p&gt;
&lt;p&gt;原谅我，成了ProcessOn脑残粉，好用上瘾（笑）。&lt;/p&gt;
&lt;h5 id=&quot;吐槽-1&quot;&gt;吐槽&lt;/h5&gt;
&lt;p&gt;有时候转到管理岗很难再有精力继续做技术，如果还有颗做技术的心，关注开源，保持技术敏感性。&lt;/p&gt;
&lt;h5 id=&quot;教训-1&quot;&gt;教训&lt;/h5&gt;
&lt;ul&gt;&lt;li&gt;原型设计&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;原型很重要！&lt;br/&gt;原型很重要！&lt;br/&gt;原型很重要！&lt;/p&gt;
&lt;p&gt;所谓一图胜千言，有时候客户自己都不明白自己想要什么，总是说“你先做一版出来看看吧”。&lt;br/&gt;懵逼了吗？&lt;/p&gt;
&lt;p&gt;在跟客户确认三轮需求之前，不要做，不要做，不要做！&lt;br/&gt;压力再大都不要真正地投入人力开始干。&lt;br/&gt;除非，你是政治任务。&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;协调管理&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;对于客户、上级、第三方要善于管理，及时同步相关信息，务必不要让项目干系人产生信息差，导致目标与进度的偏离。&lt;/p&gt;
&lt;p&gt;对于客户，如有进度偏差，及时取得沟通谅解。有问题不上报，出了事就是个炸弹，为什么不被叼？心里没点数吗？&lt;br/&gt;但是沟通又要有技巧，我在这方面乏善可陈，所以经常因为说话不够艺术，而被叼。&lt;br/&gt;而且每周都应该跟客户碰面，对于进度中的业务需求演示与确认，让客户有参与感。特别涉及企事业多部门单位的协作项目时，客户没有参与感，是不会主动去帮你解决问题的。你拿钱办事，不应该吗？&lt;/p&gt;
&lt;p&gt;对于上级，及时汇报进度与风险，有一些问题无法解决时，不要给上级做填空题，而是选择题。甚至在没问题的时候，也要从项目中找一些选择题给领导做一下，让领导有参与感。&lt;br/&gt;但是在项目之内的事情，其实作为上级应该尽量做到不要越级插手。老蒋就是这么丢的江山，不是吗？&lt;br/&gt;任正非都说了，&lt;em&gt;砍掉高层的手脚，砍掉中层的屁股，&lt;/em&gt;砍掉基层的脑袋。&lt;br/&gt;这说的什么意思？高级领导不要亲力亲为、指手画脚、越级干活。&lt;br/&gt;在我之前的公司中，有个总监什么都好，就是做事太过亲力亲为、巨细无遗，导致下属的项目经理直接变成了项目助理，毫无动力。多做多错，听命令就好了嘛，对不对？&lt;br/&gt;中层不要为了自己的小团体做打算、不顾公司利益。&lt;br/&gt;在我经历的几个项目中，有些研发、测试、运维的leader都打着自己的一套小算盘，不以项目目标为导向，而是以自己不背锅为导向。这样能把事做好吗？&lt;/p&gt;
&lt;p&gt;对于第三方，上游公司且不说，在多数为协作外包方的公司，应及时盯紧进度，需要对方按照里程碑计划提供项目交付物，并在中途予以真实系统演示。否则，你作为总包方，客户叼的不是分包方，而是你。毕竟，投标、收钱的都是你啊。&lt;/p&gt;
&lt;h4 id=&quot;团队能力培养&quot;&gt;2.3 团队能力培养&lt;/h4&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;每周一次的技术分享，两周一次的代码检查，每月一次的项目总结。良好的工作氛围，友善的同事关系，愉快的工作心情。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;实际上在工作的几年中，最自豪的并非是完成了多少项目，而是可以在自己学会某些东西后，能分享给团队里的兄弟，在将某个项目掌握好后，能很快丢给兄弟们，并让他们也可以独当一面。&lt;/p&gt;
&lt;p&gt;从来不想做什么不可替代，如果某个人不可替代，那么意味着公司的大风险。&lt;/p&gt;
&lt;p&gt;也不想用公司的条条框框把人养废，那样哪天从公司出去了就会毫无竞争力。&lt;/p&gt;
&lt;h5 id=&quot;得到-2&quot;&gt;得到&lt;/h5&gt;
&lt;p&gt;我自豪的是，从我们项目组出去的，不管是去公司总部还是其他地方项目组，都能很快独当一面，成为核心骨干。&lt;/p&gt;
&lt;p&gt;我自豪的是，在我任项目经理期间，大家成长飞快，并且感情甚笃。在18年，大家都陆陆续续从公司离开后（我也在17下半年离任了项目经理），我们都各自成为了不同公司的团队leader，还是会偶尔聚会，吹牛喝酒，怀念当年。&lt;/p&gt;
&lt;h5 id=&quot;教训-2&quot;&gt;教训&lt;/h5&gt;
&lt;p&gt;实际上技术分享 代码检查 项目总结这些没有能很好地执行下去。除了项目经理外没有拥有足够威望的人监督执行。有些事情一拖，便不了了之。&lt;/p&gt;
&lt;p&gt;在成员关系上，每个同事也都有自己的棱角，能保证质量的完成任务就行了，没必要去要求相亲相爱。强行弥合，反而更不痛快。&lt;/p&gt;
&lt;h3 id=&quot;三抉择管理与技术&quot;&gt;三、抉择：管理与技术&lt;/h3&gt;
&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;在一个公司/团队/项目组中，有了一定资历后，是继续做技术岗还是转为管理岗？&lt;br/&gt;有时候被迫或被动地转为管理岗怎么办？&lt;br/&gt;到了一定年龄，还能不能继续做技术？&lt;br/&gt;还是要受项目经理的指手画脚吗？&lt;br/&gt;技术研发、技术管理、项目管理，怎么选？哪个适合自己？&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;12点多了，今天写不完了，下篇写吧。&lt;/p&gt;
&lt;h3 id=&quot;四失去生活与生存&quot;&gt;四、失去：生活与生存&lt;/h3&gt;
&lt;p&gt;同上。&lt;/p&gt;
</description>
<pubDate>Sun, 09 Jun 2019 16:44:00 +0000</pubDate>
<dc:creator>妖生</dc:creator>
<og:description>十年风雨，一个普通程序员的成长之路（五） author '妖生' date 2019.06.09 [TOC] 成长、抉择与失去（上） 一、前言：生活的演变 在14年到18年间，我的生活中经历了喜乐悲丧</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/yaoshen/p/10995613.html</dc:identifier>
</item>
<item>
<title>spark的存储系统--BlockManager源码分析 - _朱葛</title>
<link>http://www.cnblogs.com/zhuge134/p/10995585.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/zhuge134/p/10995585.html</guid>
<description>&lt;p&gt;根据之前的一系列分析，我们对spark作业从创建到调度分发，到执行，最后结果回传driver的过程有了一个大概的了解。但是在分析源码的过程中也留下了大量的问题，最主要的就是涉及到的spark中重要的几个基础模块，我们对这些基础设施的内部细节并不是很了解，之前走读源码时基本只是大概了解每个模块的作用以及对外的主要接口，这些重要的模块包括BlockMananger, MemoryMananger, ShuffleManager, MapOutputTracker, rpc模块NettyRPCEnv，以及BroadcastManager。 而对于调度系统涉及到的几个类包括DAGSchedulerManager, TaskSchedulerManager, CoarseGrainedSchedulerBackend, CoarseGrainedExecutorBackend, Executor, TaskRunner，我们之前已经做了较为详细的分析，因此这几个模块暂告一段落。&lt;br/&gt;本篇，我们来看一下spark中最基础的一个的模块--存储系统BlockManager的内部实现。&lt;/p&gt;
&lt;h2 id=&quot;blockmanager调用时机&quot;&gt;BlockManager调用时机&lt;/h2&gt;
&lt;p&gt;首先，我们来整理一下在一个作业的运行过程中都有哪些地方使用到了BlockManager。&lt;/p&gt;
&lt;ul readability=&quot;11&quot;&gt;&lt;li readability=&quot;4&quot;&gt;
&lt;p&gt;DAGScheduler.getCacheLocs。这个方法的调用是在提交一个stage时，需要获取分区的偏向位置时会调用该方法。我们知道rdd是可以缓存的，而rdd的缓存就是通过blockManager来管理的，有一个专门的RDDBlockId用来表示一个RDD缓存块的唯一标识。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;  最终调用的方法是：blockManagerMaster.getLocations(blockIds)&lt;/code&gt;
&lt;/pre&gt;&lt;/li&gt;
&lt;li readability=&quot;4&quot;&gt;
&lt;p&gt;广播变量。在DAGscheduler中提交stage时需要把rdd和ShuffleDependency（对于ResultStage则是一个函数）对象序列化用于网络传输，实际上序列化后的字节数组是通过broadcastManager组件进行网络传输的，而broadcastManager实际又是通过BlockMananger来将要广播的数据存储成block，并在executor端发送rpc请求向BlockManangerMaster请求数据。每个广播变量会对应一个TorrentBroadcast对象，TorrentBroadcast对象内的writeBlocks和readBlocks是读写广播变量的方法，&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;  最终调用的方法是：blockManager.putSingle和blockManager.putBytes&lt;/code&gt;
&lt;/pre&gt;&lt;/li&gt;
&lt;li readability=&quot;4&quot;&gt;
&lt;p&gt;Shuffle的map阶段输出。如果我们没有启动外部shuffle服务及ExternalShuffle，那么就会用spark自己的shuffle机制，在map阶段输出时通过blockManager对输出的文件进行管理。shuffle这部分主要使用的是DiskBlockManager组件。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;  最终调用的是：DiskBlockManager相关方法包括createTempShuffleBlock，getDiskWriter，
  DiskBlockObjectWriter相关方法，包括write方法和commitAndGet方法&lt;/code&gt;
&lt;/pre&gt;&lt;/li&gt;
&lt;li readability=&quot;4&quot;&gt;
&lt;p&gt;任务运行结果序列化后传回driver。这里分为两种情况，如果结果序列化后体积较小，小于maxDirectResultSize，则直接通过rpc接口传回，如果体积较大，就需要先通过blockManager写入executor几点的内存和磁盘中，然后在driver端进行拉取。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;  最终调用的是：blockManager.putBytes&lt;/code&gt;
&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;此外，我们还注意到，以上几种情形中使用的BlockId都是不同的，具体可以看一下BlockId.scala文件中关于各种BlockId的定义。&lt;br/&gt;所以，接下来，我们的思路就很清晰了，以上面提到的对BlockManager的方法调用为切入点进行分析。&lt;/p&gt;
&lt;h3 id=&quot;blockmanagermaster.getlocations&quot;&gt;BlockManagerMaster.getLocations&lt;/h3&gt;
&lt;p&gt;这个方法用于获取指定的blockId对应的块所在存储位置。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;def getLocations(blockIds: Array[BlockId]): IndexedSeq[Seq[BlockManagerId]] = {
driverEndpoint.askSync[IndexedSeq[Seq[BlockManagerId]]](
  GetLocationsMultipleBlockIds(blockIds))&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;}&lt;/p&gt;
&lt;p&gt;这里向driverEndpoint发送了一个GetLocations消息，注意这里的driverEndpoint并不是DriverEndpoint的端点引用，在SparkEnv的构造过程我们可以看到，这是一个BlockManagerMasterEndpoint端点的引用。所以我们需要在BlockManagerMasterEndpoint中寻找对于该消息的处理。注意，由于这里调用了ask方法，所以在服务端是由receiveAndReply方法来处理并响应的。&lt;/p&gt;
&lt;h4 id=&quot;blockmanagermasterendpoint.receiveandreply&quot;&gt;BlockManagerMasterEndpoint.receiveAndReply&lt;/h4&gt;
&lt;p&gt;我们截取了对GetLocations处理的部分代码&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;case GetLocationsMultipleBlockIds(blockIds) =&amp;gt;
  context.reply(getLocationsMultipleBlockIds(blockIds))&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;调用的是getLocations方法：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;private def getLocations(blockId: BlockId): Seq[BlockManagerId] = {
  if (blockLocations.containsKey(blockId)) blockLocations.get(blockId).toSeq else Seq.empty
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;这个方法很简单，就是直接从缓存中查找blockId对应的位置，位置信息用BlockManagerId封装。那么缓存中的信息什么时候加进去呢？当然是写入新的block并更新block位置信息的时候，后面的会分析到。&lt;/p&gt;
&lt;h4 id=&quot;blockmanager.putsingle&quot;&gt;BlockManager.putSingle&lt;/h4&gt;
&lt;p&gt;这个方法写入一个有单个对象组成的块，&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;def putSingle[T: ClassTag](
  blockId: BlockId,
  value: T,
  level: StorageLevel,
  tellMaster: Boolean = true): Boolean = {
putIterator(blockId, Iterator(value), level, tellMaster)
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;可以看到，把对象包装成了一个只有一个元素的迭代器，然后调用putIterator方法，最后调用doPutIterator方法&lt;/p&gt;
&lt;h4 id=&quot;blockmanager.doputiterator&quot;&gt;BlockManager.doPutIterator&lt;/h4&gt;
&lt;p&gt;上面的方法，最终调用了doPutIterator方法。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;private def doPutIterator[T](
  blockId: BlockId,
  iterator: () =&amp;gt; Iterator[T],
  level: StorageLevel,
  classTag: ClassTag[T],
  tellMaster: Boolean = true,
  keepReadLock: Boolean = false): Option[PartiallyUnrolledIterator[T]] = {
//
doPut(blockId, level, classTag, tellMaster = tellMaster, keepReadLock = keepReadLock) { info =&amp;gt;
  val startTimeMs = System.currentTimeMillis
  var iteratorFromFailedMemoryStorePut: Option[PartiallyUnrolledIterator[T]] = None
  // Size of the block in bytes
  var size = 0L
  // 如果存储等级中包含内存级别，那么我们优先写入内存中
  if (level.useMemory) {
    // Put it in memory first, even if it also has useDisk set to true;
    // We will drop it to disk later if the memory store can't hold it.
    // 对于不进行序列化的情况，只能存储内存中
    if (level.deserialized) {
      memoryStore.putIteratorAsValues(blockId, iterator(), classTag) match {
        case Right(s) =&amp;gt;
          size = s
        case Left(iter) =&amp;gt;
          // Not enough space to unroll this block; drop to disk if applicable
          // 内存空间不够时，如果存储等级允许磁盘，则存储到磁盘中
          if (level.useDisk) {
            logWarning(s&quot;Persisting block $blockId to disk instead.&quot;)
            diskStore.put(blockId) { channel =&amp;gt;
              val out = Channels.newOutputStream(channel)
              // 注意对于存储到磁盘的情况一定是要序列化的
              serializerManager.dataSerializeStream(blockId, out, iter)(classTag)
            }
            size = diskStore.getSize(blockId)
          } else {
            iteratorFromFailedMemoryStorePut = Some(iter)
          }
      }
    } else { // !level.deserialized
      // 以序列化的形式进行存储
      memoryStore.putIteratorAsBytes(blockId, iterator(), classTag, level.memoryMode) match {
        case Right(s) =&amp;gt;
          size = s
        case Left(partiallySerializedValues) =&amp;gt;
          // Not enough space to unroll this block; drop to disk if applicable
          if (level.useDisk) {
            logWarning(s&quot;Persisting block $blockId to disk instead.&quot;)
            diskStore.put(blockId) { channel =&amp;gt;
              val out = Channels.newOutputStream(channel)
              partiallySerializedValues.finishWritingToStream(out)
            }
            size = diskStore.getSize(blockId)
          } else {
            iteratorFromFailedMemoryStorePut = Some(partiallySerializedValues.valuesIterator)
          }
      }
    }
  } else if (level.useDisk) {// 对于存储级别不允许存入内存的情况，我们只能选择存入磁盘
    diskStore.put(blockId) { channel =&amp;gt;
      val out = Channels.newOutputStream(channel)
      // 存储到磁盘是一定要序列化的
      serializerManager.dataSerializeStream(blockId, out, iterator())(classTag)
    }
    size = diskStore.getSize(blockId)
  }

  // 获取刚刚刚刚写入的块的状态信息
  val putBlockStatus = getCurrentBlockStatus(blockId, info)
  val blockWasSuccessfullyStored = putBlockStatus.storageLevel.isValid
  // 如果块存储成功，那么进行接下来的动作
  if (blockWasSuccessfullyStored) {
    // Now that the block is in either the memory or disk store, tell the master about it.
    info.size = size
    // 向driver汇报块信息
    if (tellMaster &amp;amp;&amp;amp; info.tellMaster) {
      reportBlockStatus(blockId, putBlockStatus)
    }
    // 更新任务度量系统中关于块信息的相关统计值
    addUpdatedBlockStatusToTaskMetrics(blockId, putBlockStatus)
    logDebug(&quot;Put block %s locally took %s&quot;.format(blockId, Utils.getUsedTimeMs(startTimeMs)))
    // 如果副本数大于1，那么需要进行额外的复制
    if (level.replication &amp;gt; 1) {
      val remoteStartTime = System.currentTimeMillis
      val bytesToReplicate = doGetLocalBytes(blockId, info)
      // [SPARK-16550] Erase the typed classTag when using default serialization, since
      // NettyBlockRpcServer crashes when deserializing repl-defined classes.
      // TODO(ekl) remove this once the classloader issue on the remote end is fixed.
      val remoteClassTag = if (!serializerManager.canUseKryo(classTag)) {
        scala.reflect.classTag[Any]
      } else {
        classTag
      }
      try {
        replicate(blockId, bytesToReplicate, level, remoteClassTag)
      } finally {
        bytesToReplicate.dispose()
      }
      logDebug(&quot;Put block %s remotely took %s&quot;
        .format(blockId, Utils.getUsedTimeMs(remoteStartTime)))
    }
  }
  assert(blockWasSuccessfullyStored == iteratorFromFailedMemoryStorePut.isEmpty)
  iteratorFromFailedMemoryStorePut
}
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;总结一下这段代码的主要逻辑：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;如果存储等级允许存入内存，那么优先存入内存中。根据存储的数据是否需要序列化分别选择调用memoryStore的不同方法。&lt;/li&gt;
&lt;li&gt;如果存储等级不允许内存，那么只能存入磁盘中，存入磁盘中的数据一定是经过序列化的，这点要注意。&lt;/li&gt;
&lt;li&gt;向BlockManagerMaster汇报刚写入的块的位置信息&lt;/li&gt;
&lt;li&gt;更新任务度量系统中关于块信息的相关统计值&lt;/li&gt;
&lt;li&gt;如果副本数大于1，那么需要进行额外的复制&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;从上面的步骤可以看到，在完成数据写入后，会通过rpc调用向BlockManagerMaster汇报块的信息，这也解答了blockManagerMaster.getLocations方法从内存的map结构中查询块的位置信息的来源。&lt;/p&gt;
&lt;p&gt;单纯就存储数据来说，最重要的无疑是内存管理器MemoryStore和磁盘管理器DiskStore。&lt;br/&gt;对于MemoryStore和DiskStore调用的存储方法有：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;memoryStore.putIteratorAsValues
memoryStore.putIteratorAsBytes
diskStore.put(blockId: BlockId)(writeFunc: WritableByteChannel =&amp;gt; Unit): Unit 
diskStore.getSize(blockId)&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;blockmanager.putbytes&quot;&gt;blockManager.putBytes&lt;/h3&gt;
&lt;p&gt;我们再来接着看另一个写入方法，putBytes，即写入字节数组数据。它的实际写入的逻辑在doPutBytes方法中，我们看一下这个方法：&lt;/p&gt;
&lt;h3 id=&quot;blockmanager.doputbytes&quot;&gt;blockManager.doPutBytes&lt;/h3&gt;
&lt;p&gt;这个方法的主要步骤与doPutIterator方法差不多。只不过doPutIterator方法插入的是java对象，如果存储级别要求序列化或者存储到磁盘时，需要将对象序列化。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;private def doPutBytes[T](
  blockId: BlockId,
  bytes: ChunkedByteBuffer,
  level: StorageLevel,
  classTag: ClassTag[T],
  tellMaster: Boolean = true,
  keepReadLock: Boolean = false): Boolean = {
doPut(blockId, level, classTag, tellMaster = tellMaster, keepReadLock = keepReadLock) { info =&amp;gt;
  val startTimeMs = System.currentTimeMillis
  // Since we're storing bytes, initiate the replication before storing them locally.
  // This is faster as data is already serialized and ready to send.
  // 启动副本复制
  val replicationFuture = if (level.replication &amp;gt; 1) {
    Future {
      // This is a blocking action and should run in futureExecutionContext which is a cached
      // thread pool. The ByteBufferBlockData wrapper is not disposed of to avoid releasing
      // buffers that are owned by the caller.
      replicate(blockId, new ByteBufferBlockData(bytes, false), level, classTag)
    }(futureExecutionContext)
  } else {
    null
  }

  val size = bytes.size

  // 如果缓存级别中包含内存，优先写入内存中
  if (level.useMemory) {
    // Put it in memory first, even if it also has useDisk set to true;
    // We will drop it to disk later if the memory store can't hold it.
    // 是否以序列化形式存储
    val putSucceeded = if (level.deserialized) {
      val values =
        serializerManager.dataDeserializeStream(blockId, bytes.toInputStream())(classTag)
      memoryStore.putIteratorAsValues(blockId, values, classTag) match {
        case Right(_) =&amp;gt; true
        case Left(iter) =&amp;gt;
          // If putting deserialized values in memory failed, we will put the bytes directly to
          // disk, so we don't need this iterator and can close it to free resources earlier.
          iter.close()
          false
      }
    } else {
      // 如果以序列化格式存储，则不需要反序列化
      val memoryMode = level.memoryMode
      memoryStore.putBytes(blockId, size, memoryMode, () =&amp;gt; {
        // 如果存在非直接内存，那么需要将数据拷贝一份到直接内存中
        if (memoryMode == MemoryMode.OFF_HEAP &amp;amp;&amp;amp;
            bytes.chunks.exists(buffer =&amp;gt; !buffer.isDirect)) {
          bytes.copy(Platform.allocateDirectBuffer)
        } else {
          bytes
        }
      })
    }
    // 如果插入内存失败，并且允许写入磁盘的话，就将数据写入磁盘
    // 插入内存失败一般是因为内存不够引起
    if (!putSucceeded &amp;amp;&amp;amp; level.useDisk) {
      logWarning(s&quot;Persisting block $blockId to disk instead.&quot;)
      diskStore.putBytes(blockId, bytes)
    }
  } else if (level.useDisk) {// 如果只允许存储到磁盘，那就只能存到磁盘了
    // 存储到磁盘的数据一定是序列化的
    diskStore.putBytes(blockId, bytes)
  }

  // 刚刚插入的块的信息
  val putBlockStatus = getCurrentBlockStatus(blockId, info)
  val blockWasSuccessfullyStored = putBlockStatus.storageLevel.isValid
  if (blockWasSuccessfullyStored) {
    // Now that the block is in either the memory or disk store,
    // tell the master about it.
    info.size = size
    // 向driver端的BlockManagerMaster组件汇报块信息
    if (tellMaster &amp;amp;&amp;amp; info.tellMaster) {
      reportBlockStatus(blockId, putBlockStatus)
    }
    // 更新任务度量值
    addUpdatedBlockStatusToTaskMetrics(blockId, putBlockStatus)
  }
  logDebug(&quot;Put block %s locally took %s&quot;.format(blockId, Utils.getUsedTimeMs(startTimeMs)))
  if (level.replication &amp;gt; 1) {
    // Wait for asynchronous replication to finish
    // 等待之前启动的副本复制线程完成
    // 注意这里的超时被设成了无穷大
    try {
      ThreadUtils.awaitReady(replicationFuture, Duration.Inf)
    } catch {
      case NonFatal(t) =&amp;gt;
        throw new Exception(&quot;Error occurred while waiting for replication to finish&quot;, t)
    }
  }
  if (blockWasSuccessfullyStored) {
    None
  } else {
    Some(bytes)
  }
}.isEmpty
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;对于MemoryStore和DiskStore调用的方法有：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;memoryStore.putBytes
diskStore.putBytes(blockId, bytes)&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;总结&quot;&gt;总结&lt;/h2&gt;
&lt;p&gt;综上，我们把一个spark作业运行过程中需要调用到BlockManager的时机以及调用的BlockManager的一些写入数据的方法大致整理了一下。BlockManager主要是通过内部的两个组件MemoryStore和DiskStore来管理数据向内存或磁盘写入的。此外DiskBlockManager组件主要是用来管理Block和磁盘文件之间的对应关系，分配文件路径，管理本地文件系统路径等作用。对于MemoryStore和DiskStore的调用主要有如下几个方法：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;memoryStore.putIteratorAsValues
memoryStore.putIteratorAsBytes
diskStore.put(blockId: BlockId)(writeFunc: WritableByteChannel =&amp;gt; Unit): Unit 
diskStore.getSize(blockId)
memoryStore.putBytes
diskStore.putBytes(blockId, bytes)&lt;/code&gt;
&lt;/pre&gt;</description>
<pubDate>Sun, 09 Jun 2019 16:26:00 +0000</pubDate>
<dc:creator>_朱葛</dc:creator>
<og:description>spark的存储系统 BlockManager源码分析 根据之前的一系列分析，我们对spark作业从创建到调度分发，到执行，最后结果回传driver的过程有了一个大概的了解。但是在分析源码的过程中也留</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/zhuge134/p/10995585.html</dc:identifier>
</item>
<item>
<title>batch normalization学习理解笔记 - 碌碌无为的人</title>
<link>http://www.cnblogs.com/hello-ai/p/10995468.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/hello-ai/p/10995468.html</guid>
<description>&lt;h2 id=&quot;batch-normalization学习理解笔记&quot;&gt;batch normalization学习理解笔记&lt;/h2&gt;
&lt;p&gt;最近在Andrew Ng课程中学到了Batch Normalization相关内容,通过查阅资料和原始paper,基本上弄懂了一些算法的细节部分,现在总结一下.&lt;/p&gt;
&lt;h3 id=&quot;batch-normalization算法思想的来源&quot;&gt;1. batch normalization算法思想的来源&lt;/h3&gt;
&lt;p&gt;不妨先看看原文的标题:Batch normalization:acclerating deep network training by reducing internal covariate shift.字面意思即:Batch Normalization算法是通过减小内部协变量偏移来加速深度神经网络训练.不难看出,作者明确指出Batch Normalization是一种加速深度神经网络训练的方法.什么原理呢,就是通过减小内部协变量偏移.原文中明确给出变量的定义:we refer to change in the distributions of internal nodes of a deep networks,in the course of training, as Internal Covariate Shift.其实意思就是神经网络内部layer的输入(即上一layer的输出)分布的变化.&lt;/p&gt;
&lt;p&gt;Internal Covariate Shift的定义是相对于Covariate Shift而言的,Covariate Shift是指神经网络输入(X)分布发生改变的现象.大家都知道神经网络之所以具有泛化能力,一个基本的假设就是训练样本集与测试样本集是独立同分布的(iid),如果两者分布不同(或者说两者分布之间存在Covariate Shift现象),则网络的性能就没有了保证.而Internal Covariate Shift是将这一概念进行了扩展,神经网络内部上一层的输出传递给下一层作为输入,每一层的输入是否存在Covariate Shift现象呢,答案是显而易见的.因为在神经网络训练过程中,w,b等参数是一直进行调整的,导致网络的输出也是不断变化的,而这一层的输出将作为下一层的输入,即输入也是不断变化的,即神经网络内部也存在着Covariate Shift现象,这种神经网络内部的Covariate Shift现象,就称为Internal Covariate Shift.&lt;/p&gt;
&lt;p&gt;Batch normalization的想法来源正式通过减小Internal Covariate Shift来加速网络训练.因为对于Covariate Shift现象,通过白化操作能起到改善作用,以此类推,将相似的操作引入神经网络内部,也能起到加速每一层训练的效果.&lt;/p&gt;
&lt;h3 id=&quot;如何进行batch-normalization&quot;&gt;2. 如何进行Batch Normalization&lt;/h3&gt;
&lt;p&gt;首先想到了是同样在每层使用白化操作,但是白化操作有两个缺点:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;一是白化计算量很大,因为白化过程中要计算随机向量的协方差矩阵,然后求逆运算(要使得输入向量各维度不相关),而且还要在每层中计算,这在深度神经网络中是十分费时的;&lt;/li&gt;
&lt;li&gt;二是白化结果不能保证处处可微,不能保证后向梯度下降法的顺利进行.&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;因此文中进行了两个简化:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;一是对输入向量的各个维度单独进行均值为0,方差为1的标准化处理,不进行去相关操作,这样就避免了协方差矩阵和矩阵求逆运算,这一操作也能起到加速训练的效果,已有文献作证.&lt;br/&gt;&lt;/li&gt;
&lt;li&gt;二是结合深度神经网络训练常用的mini-batch,在计算均值和方差时利用一个mini-batch中的样本,而不是整个训练集中的样本.&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;同时,为了保证进行了归一化后的输入能够包含处理前的输入(即不会损失前层网络的训练成果),又添加了一个仿射变换,引入了两个网络学习的参数&lt;span class=&quot;math inline&quot;&gt;\(\gamma\)&lt;/span&gt;和&lt;span class=&quot;math inline&quot;&gt;\(\beta\)&lt;/span&gt;.Batch Normalization的计算过程如下:&lt;br/&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1690633/201906/1690633-20190609233748774-228499984.jpg&quot;/&gt;&lt;/p&gt;
&lt;p&gt;当&lt;span class=&quot;math inline&quot;&gt;\(\beta = \mu_B\)&lt;/span&gt;,&lt;span class=&quot;math inline&quot;&gt;\(\gamma = \sqrt{\sigma^{2}_B+\varepsilon}\)&lt;/span&gt;时,&lt;span class=&quot;math inline&quot;&gt;\(y_i=x_i\)&lt;/span&gt;,即Batch Normalization进行了恒等变换.&lt;/p&gt;
&lt;p&gt;注意在测试过程中,当测试单个样本时,无法估计均值和方差,文中给出的解决办法是利用训练过程中mini-batch得到的均值和方差,求均值(指数加权平均)得到.具体的实现过程请参考原文献,此处不在累述.&lt;/p&gt;
&lt;h3 id=&quot;batch-normalization有那些作用&quot;&gt;3. Batch Normalization有那些作用&lt;/h3&gt;
&lt;p&gt;最主要的一点,也是原文中多次出现的就是加速网络训练,即达到相同的误差率,使用Batch Normalization可以大大减小所需要的迭代次数.&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;在原文试验中证实了,在原有网络结构中仅仅添加Batch Normalization,就可以大大加速网络的训练过程.个人认为有两点原因.一方面是因为经过Batch Normalization各层网络输入的均值和方差保持固定,因此后面的网络有了一个相对稳定的基础(Andrew Ng的观点),后面的网络减少了不断调整的过程;另外一点,经过归一化,输入向量各个维度保持了相同的尺度,这样也能加速后续网络的训练过程(类似于将原本椭圆状的损失函数变换为接近圆形的函数,即黑塞矩阵的条件数减小了)&lt;/li&gt;
&lt;li&gt;另外,因为Batch Nomalization能够有效抑制梯度爆炸/消失问题,因此可以使用更大的学习率,用以加快训练.原文中对于使用更大的学习率进行了专门介绍:一般情况下,大的学习率会增加模型参数(W,b)的尺度,这在反向传播过程中会放大梯度,然后导致梯度爆炸问题.但是由于Batch Normalization能够使反向传播过程中梯度不受参数尺度的影响,因此可以有效防止这种问题的发生.对于一个尺度a,Batch Normalization过程具有以下特性:&lt;span class=&quot;math display&quot;&gt;\[BN(Wu)=BN((aW)u)\]&lt;/span&gt;&lt;br/&gt;其中W为模型参数,u为模型输入.上式的结果说明,Batch Normalization的结果不受模型参数尺度的影响,因为BN会对线性运算的输出进行归一化,即均值为0,方差为1,该过程会抵消掉a的影响.同时,对于传播过程,具有如下特性:&lt;span class=&quot;math display&quot;&gt;\[\frac{\partial BN((aW)u)}{\partial u} = \frac{\partial BN(Wu)}{\partial u}\]&lt;/span&gt;&lt;br/&gt;&lt;span class=&quot;math display&quot;&gt;\[\frac{\partial BN((aW)u)}{\partial aW} = \frac{1}{a}\cdot\frac{\partial BN(Wu)}{\partial W}\]&lt;/span&gt;&lt;br/&gt;上面第一个式子表明(用本节第一个等式替换即可得到),在反向传播过程中,梯度由本层向前一层传递时,梯度的大小不受模型参数尺度的影响.第二个式子表明,反向传播过程中,参数的尺度越大,其梯度越小,这可以抑制梯度增长过大.&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;其实,对于抑制深度神经网络中梯度消失/爆炸问题,采用的方法主要有使用relu激活函数,小心初始化模型参数等,BN同样提供了一种有力的工具.&lt;/p&gt;
&lt;p&gt;原文中通过实验证明了BN可以有效防止非线性饱和问题,对于sigmoid激活函数,由于BN操作,可以避免输入落入梯度很小的两端范围内.&lt;/p&gt;
&lt;p&gt;文中同样提到了BN自带一定的regularization作用,可以替代/减弱dropout的使用.这主要是因为平均是和方差为模型引入了随机误差,从而增添了不确定性.Andrew Ng认为,应该将BN的regulatization作用作为一种副作用,真正的正则化还是应该使用L2,dropout等通用方法.&lt;/p&gt;
</description>
<pubDate>Sun, 09 Jun 2019 15:39:00 +0000</pubDate>
<dc:creator>碌碌无为的人</dc:creator>
<og:description>batch normalization学习理解笔记 最近在Andrew Ng课程中学到了Batch Normalization相关内容,通过查阅资料和原始paper,基本上弄懂了一些算法的细节部分,现</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/hello-ai/p/10995468.html</dc:identifier>
</item>
<item>
<title>浅谈从搜索到动归 - lidasu</title>
<link>http://www.cnblogs.com/lidasu/p/10995418.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/lidasu/p/10995418.html</guid>
<description>&lt;h2 id=&quot;搜索&quot;&gt;搜索&lt;/h2&gt;
&lt;p&gt;搜索的思路其实就是暴力破解（枚举每种可能的情况）&lt;br/&gt;一般用dfs的相对较多，dfs是递归的代码结构，简洁明了，思路清晰&lt;br/&gt;搜索的时候会形成一颗搜索树，整个搜索过程相当于在遍历这个搜索树&lt;/p&gt;
&lt;p&gt;搜索树可通过剪枝来优化，可以理解为把这棵树上多余的枝叶剪去，更快的找到所需的答案&lt;/p&gt;
&lt;p&gt;这里依然以01背包为例&lt;/p&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;题目概述：在n件物品取出若干件放在空间为c的背包里，每件物品的体积为w1 w2...wn，与之相对应的价值为v1 v2...vn，最终使背包所装物品的总价值最高&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;用普通的搜索来写，就是在选取每个物品的时候，有&lt;strong&gt;两种选择 拿or不拿&lt;/strong&gt;&lt;br/&gt;时间复杂度为O(2^n)&lt;/p&gt;
&lt;pre class=&quot;cpp&quot;&gt;
&lt;code&gt;int w[105],v[105];
int n,c,res=0;
void dfs(int idx,int c,int val){
    if(c&amp;lt;0) return;
    if(idx==n){
        res=max(res,val);
        return;
    }
    dfs(idx+1,c-w[idx],val+v[idx]); //拿这个物品
    dfs(idx+1,c,val); //不拿这个物品
}
int main(){
    cin&amp;gt;&amp;gt;c&amp;gt;&amp;gt;n;
    for(int i=0;i&amp;lt;n;++i) cin&amp;gt;&amp;gt;w[i]&amp;gt;&amp;gt;v[i];
    dfs(0,c,0);
    cout&amp;lt;&amp;lt;res;
    return 0;
}&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;记忆化搜索&quot;&gt;记忆化搜索&lt;/h3&gt;
&lt;p&gt;搜索过程中，往往包含着很多&lt;strong&gt;重复的计算&lt;/strong&gt;&lt;br/&gt;dfs递归参数中相同的idx和c，返回值一样，这样可以通过一个二维数组来记录&lt;br/&gt;遇到相同的idx和c时，直接返回记忆化数组中之前算好的值即可&lt;/p&gt;
&lt;pre class=&quot;cpp&quot;&gt;
&lt;code&gt;int w[105],v[105];
int mem[105][1005]; //记忆化数组
int n,c,res=0;
int dfs(int idx,int c){
    if(mem[idx][c]!=-1) return mem[idx][c]; //之前已经算好了，直接返回
    if(idx==n) return mem[idx][c]=0;
    int t1=0,t2=0;
    if(c&amp;gt;=w[idx]) t1=dfs(idx+1,c-w[idx])+v[idx]; //拿这个物品
    t2=dfs(idx+1,c); //不拿这个物品
    return mem[idx][c]=max(t1,t2);
}
int main(){
    cin&amp;gt;&amp;gt;c&amp;gt;&amp;gt;n;
    for(int i=0;i&amp;lt;n;++i) cin&amp;gt;&amp;gt;w[i]&amp;gt;&amp;gt;v[i];
    memset(mem,-1,sizeof(mem));
    cout&amp;lt;&amp;lt;dfs(0,c);
    return 0;
}&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;动态规划&quot;&gt;动态规划&lt;/h2&gt;
&lt;p&gt;动态规划关键是在于：&lt;strong&gt;状态转移&lt;/strong&gt;&lt;br/&gt;从一个已求解的状态转移到一个新的状态&lt;/p&gt;
&lt;p&gt;记忆化搜索是建立一个&lt;strong&gt;记忆化数组&lt;/strong&gt;存储dfs递归函数不同参数的返回值&lt;br/&gt;而动态规划也是建立一个&lt;strong&gt;状态转移数组&lt;/strong&gt;存储已求解的状态&lt;br/&gt;int dfs(int idx, int c) 中的&lt;strong&gt;参数idx和c&lt;/strong&gt; 对应着 dp[i][j] 中的&lt;strong&gt;数组下标i和j&lt;/strong&gt;&lt;/p&gt;
&lt;pre class=&quot;cpp&quot;&gt;
&lt;code&gt;int n,c;
int w[105],v[105];
int dp[105][1005]; //dp[i][j] 表示取到第i个物品时，背包容量为j
int main(){
    cin&amp;gt;&amp;gt;c&amp;gt;&amp;gt;n;
    for(int i=1;i&amp;lt;=n;++i) cin&amp;gt;&amp;gt;w[i]&amp;gt;&amp;gt;v[i];
    for(int i=1;i&amp;lt;=n;++i)
        for(int j=1;j&amp;lt;=c;++j){
            if(w[i]&amp;gt;j) dp[i][j]=dp[i-1][j];
            else dp[i][j]=max(dp[i-1][j],dp[i-1][j-w[i]]+v[i]);
        }
    cout&amp;lt;&amp;lt;dp[n][c];
    return 0;
}&lt;/code&gt;
&lt;/pre&gt;</description>
<pubDate>Sun, 09 Jun 2019 15:26:00 +0000</pubDate>
<dc:creator>lidasu</dc:creator>
<og:description>浅谈从搜索到动归 搜索 搜索的思路其实就是暴力破解（枚举每种可能的情况） 一般用dfs的相对较多，dfs是递归的代码结构，简洁明了，思路清晰 搜索的时候会形成一颗搜索树，整个搜索过程相当于在遍历这个搜</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/lidasu/p/10995418.html</dc:identifier>
</item>
<item>
<title>F#周报2019年第23期 - Ken.W</title>
<link>http://www.cnblogs.com/kenwoo/p/10993297.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/kenwoo/p/10993297.html</guid>
<description>[unable to retrieve full-text content]新闻 &quot;支持社区的WF与WCF开源项目&quot; 视频及幻灯片 &quot;F MonoGame平台游戏系列：摄像头&quot; &quot;Xamarin.Forms的F 与Fabulous&quot; &quot;ML.NET端到端之二:构建Web API&quot; &quot;使用F 的全栈Web开发&quot; 博客 家用IoT &quot;序言&quot; &quot;方案设计&quot; &quot;数据&quot; &quot;在F 中仅</description>
<pubDate>Sun, 09 Jun 2019 15:20:00 +0000</pubDate>
<dc:creator>Ken.W</dc:creator>
<og:description>新闻 '支持社区的WF与WCF开源项目' 视频及幻灯片 'F MonoGame平台游戏系列：摄像头' 'Xamarin.Forms的F 与Fabulous' 'ML.NET端到端之二:构建Web AP</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/kenwoo/p/10993297.html</dc:identifier>
</item>
<item>
<title>最近学习了Http连接池 - 五月的仓颉</title>
<link>http://www.cnblogs.com/xrq730/p/10963689.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/xrq730/p/10963689.html</guid>
<description>&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;起因&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;6.1大促值班发现的一个问题，一个rpc接口在0~2点用户下单高峰的时候表现rt高（超过1s，实际上针对性优化过的接口rt超过这个值也是有问题的，通常rpc接口里面即使逻辑复杂，300ms应该也搞定了），可以理解，但是在4~5点的时候接口的tps已经不高了，耗时依然在600ms~700ms之间就不能理解了。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;查了一下，里面有段调用支付宝http接口的逻辑，但是每次都new一个HttpClient出来发起调用，调用时长大概在300ms+，所以导致即使在非高峰期接口耗时依然非常高。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;问题不难，写篇文章系统性地对这块进行一下总结。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;span&gt;用不用线程池的差别&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;span&gt;本文主要写的是“池”对于系统性能的影响，因此开始连接池之前，可以以线程池的例子作为一个引子开始本文，简单看下使不使用池的一个效果差别，代码如下：&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;39&quot;&gt;
&lt;pre&gt;
&lt;span&gt;/**&lt;/span&gt;&lt;span&gt;
 * 线程池测试
 * 
 * &lt;/span&gt;&lt;span&gt;@author&lt;/span&gt;&lt;span&gt; 五月的仓颉https://www.cnblogs.com/xrq730/p/10963689.html
 &lt;/span&gt;&lt;span&gt;*/&lt;/span&gt;
&lt;span&gt;public&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;&lt;span&gt; ThreadPoolTest {

    &lt;/span&gt;&lt;span&gt;private&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; &lt;span&gt;final&lt;/span&gt; AtomicInteger FINISH_COUNT = &lt;span&gt;new&lt;/span&gt; AtomicInteger(0&lt;span&gt;);
    
    &lt;/span&gt;&lt;span&gt;private&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; &lt;span&gt;final&lt;/span&gt; AtomicLong COST = &lt;span&gt;new&lt;/span&gt; AtomicLong(0&lt;span&gt;);
    
    &lt;/span&gt;&lt;span&gt;private&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; &lt;span&gt;final&lt;/span&gt; Integer INCREASE_COUNT = 1000000&lt;span&gt;;
    
    &lt;/span&gt;&lt;span&gt;private&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; &lt;span&gt;final&lt;/span&gt; Integer TASK_COUNT = 1000&lt;span&gt;;
    
    @Test
    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt;&lt;span&gt; testRunWithoutThreadPool() {
        List&lt;/span&gt;&amp;lt;Thread&amp;gt; tList = &lt;span&gt;new&lt;/span&gt; ArrayList&amp;lt;Thread&amp;gt;&lt;span&gt;(TASK_COUNT);
        
        &lt;/span&gt;&lt;span&gt;for&lt;/span&gt; (&lt;span&gt;int&lt;/span&gt; i = 0; i &amp;lt; TASK_COUNT; i++&lt;span&gt;) {
            tList.add(&lt;/span&gt;&lt;span&gt;new&lt;/span&gt; Thread(&lt;span&gt;new&lt;/span&gt;&lt;span&gt; IncreaseThread()));
        }
        
        &lt;/span&gt;&lt;span&gt;for&lt;/span&gt;&lt;span&gt; (Thread t : tList) {
            t.start();
        }
        
        &lt;/span&gt;&lt;span&gt;for&lt;/span&gt;&lt;span&gt; (;;);
    }
    
    @Test
    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt;&lt;span&gt; testRunWithThreadPool() {
        ThreadPoolExecutor executor &lt;/span&gt;= &lt;span&gt;new&lt;/span&gt; ThreadPoolExecutor(100, 100, 0&lt;span&gt;, TimeUnit.MILLISECONDS, 
                &lt;/span&gt;&lt;span&gt;new&lt;/span&gt; LinkedBlockingQueue&amp;lt;&amp;gt;&lt;span&gt;());
        
        &lt;/span&gt;&lt;span&gt;for&lt;/span&gt; (&lt;span&gt;int&lt;/span&gt; i = 0; i &amp;lt; TASK_COUNT; i++&lt;span&gt;) {
            executor.submit(&lt;/span&gt;&lt;span&gt;new&lt;/span&gt;&lt;span&gt; IncreaseThread());
        }
        
        &lt;/span&gt;&lt;span&gt;for&lt;/span&gt;&lt;span&gt; (;;);
    }
    
    &lt;/span&gt;&lt;span&gt;private&lt;/span&gt; &lt;span&gt;class&lt;/span&gt; IncreaseThread &lt;span&gt;implements&lt;/span&gt;&lt;span&gt; Runnable {
        
        @Override
        &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt;&lt;span&gt; run() {
            &lt;/span&gt;&lt;span&gt;long&lt;/span&gt; startTime =&lt;span&gt; System.currentTimeMillis();
            
            AtomicInteger counter &lt;/span&gt;= &lt;span&gt;new&lt;/span&gt; AtomicInteger(0&lt;span&gt;);
            &lt;/span&gt;&lt;span&gt;for&lt;/span&gt; (&lt;span&gt;int&lt;/span&gt; i = 0; i &amp;lt; INCREASE_COUNT; i++&lt;span&gt;) {
                counter.incrementAndGet();
            }
            &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; 累加执行时间&lt;/span&gt;
            COST.addAndGet(System.currentTimeMillis() -&lt;span&gt; startTime);
            &lt;/span&gt;&lt;span&gt;if&lt;/span&gt; (FINISH_COUNT.incrementAndGet() ==&lt;span&gt; TASK_COUNT) {
                System.out.println(&lt;/span&gt;&quot;cost: &quot; + COST.get() + &quot;ms&quot;&lt;span&gt;);
            }
        }
        
    }
    
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span&gt;逻辑比较简单：1000个任务，每个任务做的事情都是使用AtomicInteger从0累加到100W。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;每个Test方法运行12次，排除一个最低的和一个最高的，对中间的10次取一个平均数，当不使用线程池的时候，任务总耗时为&lt;span&gt;&lt;strong&gt;16693s&lt;/strong&gt;&lt;/span&gt;；而当使用线程池的时候，任务平均执行时间为&lt;span&gt;&lt;strong&gt;1073s，&lt;/strong&gt;&lt;/span&gt;超过15倍，差别是非常明显的。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;究其原因比较简单，相信大家都知道，主要是两点：&lt;/span&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;span&gt;减少线程创建、销毁的开销&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span&gt;控制线程的数量，避免来一个任务创建一个线程，最终内存的暴增甚至耗尽&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;span&gt;当然，前面也说了，这只是一个引子引出本文，当我们使用HTTP连接池的时候，任务处理效率提升的原因不止于此。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;span&gt;用哪个httpclient&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;容易搞错的一个点，大家特别注意一下。HttpClient可以搜到两个类似的工具包，一个是commons-httpclient：&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;33&quot;&gt;
&lt;pre&gt;
&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;dependency&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
    &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;groupId&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;commons-httpclient&lt;span&gt;&amp;lt;/&lt;/span&gt;&lt;span&gt;groupId&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
    &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;artifactId&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;commons-httpclient&lt;span&gt;&amp;lt;/&lt;/span&gt;&lt;span&gt;artifactId&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
    &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;version&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;3.1&lt;span&gt;&amp;lt;/&lt;/span&gt;&lt;span&gt;version&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
&lt;span&gt;&amp;lt;/&lt;/span&gt;&lt;span&gt;dependency&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span&gt;一个是httpclient：&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;33&quot;&gt;
&lt;pre&gt;
&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;dependency&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
    &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;groupId&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;org.apache.httpcomponents&lt;span&gt;&amp;lt;/&lt;/span&gt;&lt;span&gt;groupId&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
    &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;artifactId&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;httpclient&lt;span&gt;&amp;lt;/&lt;/span&gt;&lt;span&gt;artifactId&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
    &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;version&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;4.5.8&lt;span&gt;&amp;lt;/&lt;/span&gt;&lt;span&gt;version&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
&lt;span&gt;&amp;lt;/&lt;/span&gt;&lt;span&gt;dependency&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span&gt;选第二个用，不要搞错了，他们的区别在stackoverflow上有解答：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/801753/201906/801753-20190606192714645-1706026725.png&quot; alt=&quot;&quot; width=&quot;664&quot; height=&quot;108&quot;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;即commons-httpclient是一个HttpClient老版本的项目，到3.1版本为止，此后项目被废弃不再更新（3.1版本，07年8.21发布），它已经被归入了一个更大的Apache HttpComponents项目中，这个项目版本号是HttpClient 4.x（4.5.8最新版本，19年5.30发布）。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;随着不断更新，HttpClient底层针对代码细节、性能上都有持续的优化，因此切记选择&lt;span&gt;&lt;strong&gt;org.apache.httpcomponents&lt;/strong&gt;&lt;/span&gt;这个groupId。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;&lt;strong&gt;不使用连接池的运行效果&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;有了工具类，就可以写代码来验证一下了。首先定义一个测试基类，等下使用连接池的代码演示的时候可以共用：&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;35&quot;&gt;
&lt;pre&gt;
&lt;span&gt;/**&lt;/span&gt;&lt;span&gt;
 * 连接池基类
 * 
 * &lt;/span&gt;&lt;span&gt;@author&lt;/span&gt;&lt;span&gt; 五月的仓颉https://www.cnblogs.com/xrq730/p/10963689.html
 &lt;/span&gt;&lt;span&gt;*/&lt;/span&gt;
&lt;span&gt;public&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;&lt;span&gt; BaseHttpClientTest {

    &lt;/span&gt;&lt;span&gt;protected&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; &lt;span&gt;final&lt;/span&gt; &lt;span&gt;int&lt;/span&gt; REQUEST_COUNT = 5&lt;span&gt;;

    &lt;/span&gt;&lt;span&gt;protected&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; &lt;span&gt;final&lt;/span&gt; String SEPERATOR = &quot;   &quot;&lt;span&gt;;
    
    &lt;/span&gt;&lt;span&gt;protected&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; &lt;span&gt;final&lt;/span&gt; AtomicInteger NOW_COUNT = &lt;span&gt;new&lt;/span&gt; AtomicInteger(0&lt;span&gt;);
    
    &lt;/span&gt;&lt;span&gt;protected&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; &lt;span&gt;final&lt;/span&gt; StringBuilder EVERY_REQ_COST = &lt;span&gt;new&lt;/span&gt; StringBuilder(200&lt;span&gt;);
    
    &lt;/span&gt;&lt;span&gt;/**&lt;/span&gt;&lt;span&gt;
     * 获取待运行的线程
     &lt;/span&gt;&lt;span&gt;*/&lt;/span&gt;
    &lt;span&gt;protected&lt;/span&gt; List&amp;lt;Thread&amp;gt;&lt;span&gt; getRunThreads(Runnable runnable) {
        List&lt;/span&gt;&amp;lt;Thread&amp;gt; tList = &lt;span&gt;new&lt;/span&gt; ArrayList&amp;lt;Thread&amp;gt;&lt;span&gt;(REQUEST_COUNT);
        
        &lt;/span&gt;&lt;span&gt;for&lt;/span&gt; (&lt;span&gt;int&lt;/span&gt; i = 0; i &amp;lt; REQUEST_COUNT; i++&lt;span&gt;) {
            tList.add(&lt;/span&gt;&lt;span&gt;new&lt;/span&gt;&lt;span&gt; Thread(runnable));
        }
        
        &lt;/span&gt;&lt;span&gt;return&lt;/span&gt;&lt;span&gt; tList;
    }
    
    &lt;/span&gt;&lt;span&gt;/**&lt;/span&gt;&lt;span&gt;
     * 启动所有线程
     &lt;/span&gt;&lt;span&gt;*/&lt;/span&gt;
    &lt;span&gt;protected&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; startUpAllThreads(List&amp;lt;Thread&amp;gt;&lt;span&gt; tList) {
        &lt;/span&gt;&lt;span&gt;for&lt;/span&gt;&lt;span&gt; (Thread t : tList) {
            t.start();
            &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; 这里需要加一点延迟，保证请求按顺序发出去&lt;/span&gt;
            &lt;span&gt;try&lt;/span&gt;&lt;span&gt; {
                Thread.sleep(&lt;/span&gt;300&lt;span&gt;);
            } &lt;/span&gt;&lt;span&gt;catch&lt;/span&gt;&lt;span&gt; (InterruptedException e) {
                e.printStackTrace();
            }
        }
    }
    
    &lt;/span&gt;&lt;span&gt;protected&lt;/span&gt; &lt;span&gt;synchronized&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; addCost(&lt;span&gt;long&lt;/span&gt;&lt;span&gt; cost) {
        EVERY_REQ_COST.append(cost);
        EVERY_REQ_COST.append(&lt;/span&gt;&quot;ms&quot;&lt;span&gt;);
        EVERY_REQ_COST.append(SEPERATOR);
    }
    
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span&gt;接着看一下测试代码：&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;35&quot;&gt;
&lt;pre&gt;
&lt;span&gt;/**&lt;/span&gt;&lt;span&gt;
 * 不使用连接池测试
 * 
 * &lt;/span&gt;&lt;span&gt;@author&lt;/span&gt;&lt;span&gt; 五月的仓颉https://www.cnblogs.com/xrq730/p/10963689.html
 &lt;/span&gt;&lt;span&gt;*/&lt;/span&gt;
&lt;span&gt;public&lt;/span&gt; &lt;span&gt;class&lt;/span&gt; HttpClientWithoutPoolTest &lt;span&gt;extends&lt;/span&gt;&lt;span&gt; BaseHttpClientTest {

    @Test
    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; test() &lt;span&gt;throws&lt;/span&gt;&lt;span&gt; Exception {
        startUpAllThreads(getRunThreads(&lt;/span&gt;&lt;span&gt;new&lt;/span&gt;&lt;span&gt; HttpThread()));
        &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; 等待线程运行&lt;/span&gt;
        &lt;span&gt;for&lt;/span&gt;&lt;span&gt; (;;);
    }
    
    &lt;/span&gt;&lt;span&gt;private&lt;/span&gt; &lt;span&gt;class&lt;/span&gt; HttpThread &lt;span&gt;implements&lt;/span&gt;&lt;span&gt; Runnable {

        @Override
        &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt;&lt;span&gt; run() {
            &lt;/span&gt;&lt;span&gt;/**&lt;/span&gt;&lt;span&gt;
             * HttpClient是线程安全的，因此HttpClient正常使用应当做成全局变量，但是一旦全局共用一个，HttpClient内部构建的时候会new一个连接池
             * 出来，这样就体现不出使用连接池的效果，因此这里每次new一个HttpClient，保证每次都不通过连接池请求对端
             &lt;/span&gt;&lt;span&gt;*/&lt;/span&gt;&lt;span&gt;
            CloseableHttpClient httpClient &lt;/span&gt;=&lt;span&gt; HttpClients.custom().build();
            HttpGet httpGet &lt;/span&gt;= &lt;span&gt;new&lt;/span&gt; HttpGet(&quot;https://www.baidu.com/&quot;&lt;span&gt;);
            
            &lt;/span&gt;&lt;span&gt;long&lt;/span&gt; startTime =&lt;span&gt; System.currentTimeMillis();
            &lt;/span&gt;&lt;span&gt;try&lt;/span&gt;&lt;span&gt; {
                CloseableHttpResponse response &lt;/span&gt;=&lt;span&gt; httpClient.execute(httpGet);
                &lt;/span&gt;&lt;span&gt;if&lt;/span&gt; (response != &lt;span&gt;null&lt;/span&gt;&lt;span&gt;) {
                    response.close();
                }
            } &lt;/span&gt;&lt;span&gt;catch&lt;/span&gt;&lt;span&gt; (Exception e) {
                e.printStackTrace();
            } &lt;/span&gt;&lt;span&gt;finally&lt;/span&gt;&lt;span&gt; {
                addCost(System.currentTimeMillis() &lt;/span&gt;-&lt;span&gt; startTime);
                
                &lt;/span&gt;&lt;span&gt;if&lt;/span&gt; (NOW_COUNT.incrementAndGet() ==&lt;span&gt; REQUEST_COUNT) {
                    System.out.println(EVERY_REQ_COST.toString());
                }
            }
        }
        
    }
    
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span&gt;注意这里如注释所说，HttpClient是线程安全的，但是一旦做成全局的就失去了测试效果，因为HttpClient在初始化的时候默认会new一个连接池出来。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;看一下代码运行效果：&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;32&quot;&gt;
&lt;pre&gt;
&lt;span&gt;324ms   324ms   220ms   324ms   324ms&lt;br/&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span&gt;每个请求几乎都是独立的，所以执行时间都在200ms以上，接着我们看一下使用连接池的效果。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;&lt;strong&gt;使用连接池的运行结果&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;BaseHttpClientTest这个类保持不变，写一个使用连接池的测试类：&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;40&quot;&gt;
&lt;pre&gt;
&lt;span&gt;/**&lt;/span&gt;&lt;span&gt;
 * 使用连接池测试
 * 
 * &lt;/span&gt;&lt;span&gt;@author&lt;/span&gt;&lt;span&gt; 五月的仓颉https://www.cnblogs.com/xrq730/p/10963689.html
 &lt;/span&gt;&lt;span&gt;*/&lt;/span&gt;
&lt;span&gt;public&lt;/span&gt; &lt;span&gt;class&lt;/span&gt; HttpclientWithPoolTest &lt;span&gt;extends&lt;/span&gt;&lt;span&gt; BaseHttpClientTest {

    &lt;/span&gt;&lt;span&gt;private&lt;/span&gt; CloseableHttpClient httpClient = &lt;span&gt;null&lt;/span&gt;&lt;span&gt;;
    
    @Before
    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt;&lt;span&gt; before() {
        initHttpClient();
    }
    
    @Test
    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; test() &lt;span&gt;throws&lt;/span&gt;&lt;span&gt; Exception {
        startUpAllThreads(getRunThreads(&lt;/span&gt;&lt;span&gt;new&lt;/span&gt;&lt;span&gt; HttpThread()));
        &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; 等待线程运行&lt;/span&gt;
        &lt;span&gt;for&lt;/span&gt;&lt;span&gt; (;;);
    }
    
    &lt;/span&gt;&lt;span&gt;private&lt;/span&gt; &lt;span&gt;class&lt;/span&gt; HttpThread &lt;span&gt;implements&lt;/span&gt;&lt;span&gt; Runnable {

        @Override
        &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt;&lt;span&gt; run() {
            HttpGet httpGet &lt;/span&gt;= &lt;span&gt;new&lt;/span&gt; HttpGet(&quot;https://www.baidu.com/&quot;&lt;span&gt;);
            &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; 长连接标识，不加也没事，HTTP1.1默认都是Connection: keep-alive的&lt;/span&gt;
            httpGet.addHeader(&quot;Connection&quot;, &quot;keep-alive&quot;&lt;span&gt;);
            
            &lt;/span&gt;&lt;span&gt;long&lt;/span&gt; startTime =&lt;span&gt; System.currentTimeMillis();
            &lt;/span&gt;&lt;span&gt;try&lt;/span&gt;&lt;span&gt; {
                CloseableHttpResponse response &lt;/span&gt;=&lt;span&gt; httpClient.execute(httpGet);
                &lt;/span&gt;&lt;span&gt;if&lt;/span&gt; (response != &lt;span&gt;null&lt;/span&gt;&lt;span&gt;) {
                    response.close();
                }
            } &lt;/span&gt;&lt;span&gt;catch&lt;/span&gt;&lt;span&gt; (Exception e) {
                e.printStackTrace();
            } &lt;/span&gt;&lt;span&gt;finally&lt;/span&gt;&lt;span&gt; {
                addCost(System.currentTimeMillis() &lt;/span&gt;-&lt;span&gt; startTime);
                
                &lt;/span&gt;&lt;span&gt;if&lt;/span&gt; (NOW_COUNT.incrementAndGet() ==&lt;span&gt; REQUEST_COUNT) {
                    System.out.println(EVERY_REQ_COST.toString());
                }
            }
        }
        
    }
    
    &lt;/span&gt;&lt;span&gt;private&lt;/span&gt; &lt;span&gt;void&lt;/span&gt;&lt;span&gt; initHttpClient() {
        PoolingHttpClientConnectionManager connectionManager &lt;/span&gt;= &lt;span&gt;new&lt;/span&gt;&lt;span&gt; PoolingHttpClientConnectionManager();
        &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; 总连接池数量&lt;/span&gt;
        connectionManager.setMaxTotal(1&lt;span&gt;);
        &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; 可为每个域名设置单独的连接池数量&lt;/span&gt;
        connectionManager.setMaxPerRoute(&lt;span&gt;new&lt;/span&gt; HttpRoute(&lt;span&gt;new&lt;/span&gt; HttpHost(&quot;www.baidu.com&quot;)), 1&lt;span&gt;);
        &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; setConnectTimeout表示设置建立连接的超时时间
        &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; setConnectionRequestTimeout表示从连接池中拿连接的等待超时时间
        &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; setSocketTimeout表示发出请求后等待对端应答的超时时间&lt;/span&gt;
        RequestConfig requestConfig = RequestConfig.custom().setConnectTimeout(1000).setConnectionRequestTimeout(2000&lt;span&gt;)
                .setSocketTimeout(&lt;/span&gt;3000&lt;span&gt;).build();
        &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; 重试处理器，StandardHttpRequestRetryHandler这个是官方提供的，看了下感觉比较挫，很多错误不能重试，可自己实现HttpRequestRetryHandler接口去做&lt;/span&gt;
        HttpRequestRetryHandler retryHandler = &lt;span&gt;new&lt;/span&gt;&lt;span&gt; StandardHttpRequestRetryHandler();
        
        httpClient &lt;/span&gt;=&lt;span&gt; HttpClients.custom().setConnectionManager(connectionManager).setDefaultRequestConfig(requestConfig)
                .setRetryHandler(retryHandler).build();
        
        &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; 服务端假设关闭了连接，对客户端是不透明的，HttpClient为了缓解这一问题，在某个连接使用前会检测这个连接是否过时，如果过时则连接失效，但是这种做法会为每个请求
        &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; 增加一定额外开销，因此有一个定时任务专门回收长时间不活动而被判定为失效的连接，可以某种程度上解决这个问题&lt;/span&gt;
        Timer timer = &lt;span&gt;new&lt;/span&gt;&lt;span&gt; Timer();
        timer.schedule(&lt;/span&gt;&lt;span&gt;new&lt;/span&gt;&lt;span&gt; TimerTask() {
            @Override
            &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt;&lt;span&gt; run() {
                &lt;/span&gt;&lt;span&gt;try&lt;/span&gt;&lt;span&gt; {
                    &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; 关闭失效连接并从连接池中移除&lt;/span&gt;
&lt;span&gt;                    connectionManager.closeExpiredConnections();
                    &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; 关闭30秒钟内不活动的连接并从连接池中移除，空闲时间从交还给连接管理器时开始&lt;/span&gt;
                    connectionManager.closeIdleConnections(20&lt;span&gt;, TimeUnit.SECONDS);
                } &lt;/span&gt;&lt;span&gt;catch&lt;/span&gt;&lt;span&gt; (Throwable t) {
                    t.printStackTrace();
                }
            }
        }, &lt;/span&gt;0 , 1000 * 5&lt;span&gt;);
    }
    
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span&gt;这个类详细地演示了HttpClient的用法，相关注意点都写了注释，就不讲了。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;和上面一样，看一下代码执行效果：&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;32&quot;&gt;
&lt;pre&gt;
&lt;span&gt;309ms   83ms   57ms   53ms   46ms&lt;br/&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span&gt;看到除开第一次调用的309ms以外，后续四次调用整体执行时间大大提升，这就是使用了连接池的好处，接着，就探究一下使用连接池提升整体性能的原因。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;span&gt;绕不开的长短连接&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;说起HTTP，必然绕不开的一个话题就是长短连接，这个话题之前的文章已经写了好多次了，这里再写一次。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;我们知道，从客户端发起一个HTTP请求到服务端响应HTTP请求之间，大致有以下几个步骤：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/801753/201906/801753-20190608135840004-805871484.png&quot; alt=&quot;&quot; width=&quot;598&quot; height=&quot;201&quot;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;HTTP1.0最早在网页中使用是1996年，那个时候只是使用一些较为简单的网页和网络的请求，&lt;span&gt;&lt;strong&gt;每次请求都需要建立一个单独的连接&lt;/strong&gt;&lt;/span&gt;，上一次和下一次请求完全分离。这种做法，即使每次的请求量都很小，但是客户端和服务端每次建立TCP连接和关闭TCP连接都是相对比较费时的过程，严重影响客户端和服务端的性能。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;基于以上的问题，HTTP1.1在1999年广泛应用于现在的各大浏览器网络请求中，同时HTTP1.1也是当前使用最为广泛的HTTP协议（2015年诞生了HTTP2，但是还未大规模应用），这里不详细对比HTTP1.1针对HTTP1.0改进了什么，只是在连接这块，&lt;span&gt;&lt;strong&gt;HTTP1.1支持在一个TCP连接上传送多个HTTP请求和响应，减少了建立和关闭连接的消耗延迟&lt;/strong&gt;&lt;/span&gt;，一定程度上弥补了HTTP1.0每次请求都要创建连接的缺点，这就是长连接，HTTP1.1默认使用长连接。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;那么，长连接是如何工作的呢？首先，我们要明确一下，&lt;span&gt;&lt;strong&gt;长短连接是通信层（TCP）的概念&lt;/strong&gt;&lt;/span&gt;，HTTP是应用层协议，它只能说告诉通信层我打算一段时间内复用TCP通道而没有自己去建立、释放TCP通道的能力。那么HTTP是如何告诉通信层复用TCP通道的呢？看下图：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/801753/201906/801753-20190608135102444-810463763.png&quot; alt=&quot;&quot; width=&quot;465&quot; height=&quot;301&quot;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;分为以下几个步骤：&lt;/span&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;span&gt;客户端发送一个Connection: keep-alive的header，表示需要保持连接&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span&gt;客户端可以顺带Keep-Alive: timeout=5,max=100这个header给服务端，表示tcp连接最多保持5秒，长连接接受100次请求就断开，不过浏览器看了一些请求貌似没看到带这个参数的&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span&gt;服务端必须能识别Connection: keep-alive这个header，并且通过Response Header带同样的Connection: keep-alive，告诉客户端我可以保持连接&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span&gt;客户端和服务端之间通过保持的通道收发数据&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span&gt;最后一次请求数据，客户端带Connection：close这个header，表示连接关闭&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;span&gt;至此在一个通道上交换数据的过程结束，在默认的情况下：&lt;/span&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;span&gt;长连接的请求数量限定是最多连续发送100个请求，超过限制即关闭这条连接&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span&gt;长连接连续两个请求之间的超时时间是15秒（存在1~2秒误差），超时后会关闭TCP连接，因此使用长连接应当尽量保持在13秒之内发送一个请求&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;span&gt;这些的限制都是在重用长连接与长连接过多之间做的一个折衷，因为长连接虽好，但是长时间的TCP连接容易导致系统资源无效占用，浪费系统资源。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;最后这个地方多说一句http的keep-alive和tcp的keep-alive的区别，一个经常讲的问题，顺便记录一下：&lt;/span&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;span&gt;http的keep-alive是为了&lt;span&gt;&lt;strong&gt;复用已有连接&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span&gt;tcp的keep-alive是为了&lt;span&gt;&lt;strong&gt;保活&lt;/strong&gt;&lt;/span&gt;，即保证对端还存活，不然对端已经不在了我这边还占着和对端的这个连接，浪费服务器资源，做法是隔一段时间发送一个心跳包到对端服务器，一旦长时间没有接收到应答，就主动关闭连接&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;性能提升的原因&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;通过前面的分析，很显而易见的，使用HTTP连接池提升性能最重要的原因就是省去了大量连接建立与释放的时间，除此之外还想说一点。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;TCP建立连接的时候有如下流程：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;img src=&quot;https://images2015.cnblogs.com/blog/801753/201705/801753-20170530165016352-2127690583.jpg&quot; alt=&quot;&quot; width=&quot;623&quot; height=&quot;454&quot;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;如图所示，这里面有两个队列，分别为syns queue（半连接队列）与accept queue（全连接队列），这里面的流程就不细讲了，之前我有文章&lt;a href=&quot;https://www.cnblogs.com/xrq730/p/6910719.html&quot;&gt;https://www.cnblogs.com/xrq730/p/6910719.html&lt;/a&gt;专门写过这个话题。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;一旦不使用长连接而每次连接都重新握手的话，队列一满服务端将会发送一个ECONNREFUSED错误信息给到客户端，相当于这次请求就失效了，即使不失效，后来的请求需要等待前面的请求处理，排队也会增加响应的时间。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;By the way，基于上面的分析，不仅仅是HTTP，所有应用层协议，例如数据库有数据库连接池、hsf提供了hsf接口连接池，使用连接池的方式对于接口性能都是有非常大的提升的，都是同一个道理。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;&lt;strong&gt;TLS层的优化&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;上面讲的都是针对应用层协议使用连接池提升性能的原因，但是对于HTTP请求，我们知道目前大多数网站都运行在HTTPS协议之上，即在通信层和应用层之间多了一层TLS：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/801753/201906/801753-20190609170001997-1371774529.png&quot; alt=&quot;&quot; width=&quot;353&quot; height=&quot;194&quot;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;通过TLS层对报文进行了加密，保证数据安全，其实在HTTPS这个层面上，使用连接池对性能有提升，TLS层的优化也是一个非常重要的原因。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;HTTPS原理不细讲了，反正大致上就是一个证书交换--&amp;gt;服务端加密--&amp;gt;客户端解密的过程，整个过程中反复地客户端+服务端交换数据是一个耗时的过程，且数据的加解密是一个计算密集型的操作消耗CPU资源，因此如果相同的请求能省去加解密这一套就能在HTTPS协议下对整个性能有很大提升了，实际上这种优化是有的，这里用到了一种&lt;span&gt;&lt;strong&gt;会话复用&lt;/strong&gt;&lt;/span&gt;的技术。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;TLS的握手由客户端发送&lt;span&gt;&lt;strong&gt;Client Hello&lt;/strong&gt;&lt;/span&gt;消息开始，服务端返回&lt;span&gt;&lt;strong&gt;Server Hello&lt;/strong&gt;&lt;/span&gt;结束，整个流程中提供了2种不同的会话复用机制，这个地方就简单看一下，知道有这么一回事：&lt;/span&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;session id&lt;/strong&gt;&lt;/span&gt;会话复用----对于已建立的TLS会话，使用session id为key（来自第一次请求的Server Hello中的session id），主密钥为value组成一对键值对保存在服务端和客户端的本地。当第二次握手时，客户端如果想复用会话，则发起的Client Hello中带上session id，服务端收到这个session id检查本地是否存在，有则允许会话复用，进行后续操作&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;session ticket&lt;/strong&gt;&lt;/span&gt;会话复用----一个session ticket是一个加密的数据blob，其中包含需要重用的TLS连接信息如session key等，它一般使用ticket key加密，因为ticket key服务端也知道，在初始化握手中服务端发送一个session ticket到客户端并存储到客户端本地，当会话重用时，客户端发送session ticket到服务端，服务端解密成功即可复用会话&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;span&gt;session id的方式缺点是比较明显的，主要原因是负载均衡中，多机之间不同步session，如果两次请求不落在同一台机器上就无法找到匹配信息，另外服务端存储大量的session id又需要消耗很多资源，而session ticket是比较好解决这个问题的，但是最终使用的是哪种方式还是有浏览器决定。关于session ticket，在网上找了一张图，展示的是客户端第二次发起请求，携带session ticket的过程：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/801753/201906/801753-20190609182538127-1835650457.png&quot; alt=&quot;&quot; width=&quot;656&quot; height=&quot;502&quot;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;一个session ticket超时时间默认为300s，TLS层的证书交换+非对称加密作为性能消耗大户，通过会话复用技术可以大大提升性能。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;span&gt;使用连接池的注意点&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;使用连接池，切记&lt;span&gt;&lt;strong&gt;每个任务的执行时间不要太长&lt;/strong&gt;&lt;/span&gt;。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;因为HTTP请求也好、数据库请求也好、hsf请求也好都是有超时时间的，比如连接池中有10个线程，并发来了100个请求，一旦任务执行时间非常长，连接都被先来的10个任务占着，后面90个请求迟迟得不到连接去处理，就会导致这次的请求响应慢甚至超时。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;当然每个任务的业务不一样，但是按照我的经验，尽量把任务的执行时间控制在50ms最多100ms之内，如果超出的，可以考虑以下三种方案：&lt;/span&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;span&gt;优化任务执行逻辑，比如引入缓存&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span&gt;适当增大连接池中的连接数量&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span&gt;任务拆分，将任务拆分为若干小任务&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;连接池中的连接数量如何设置&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;有些朋友可能会问，我知道需要使用连接池，那么一般连接池数量设置为多少比较合适？有没有经验值呢？首先我们需要明确一个点，连接池中的连接数量太多不好、太少也不好：&lt;/span&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;span&gt;比如qps=100，因为上游请求速率不可能是恒定不变的100个请求/秒，可能前1秒900个请求，后9秒100个请求，平均下来qps=100，当连接数太多的时候，可能出现的场景是&lt;span&gt;&lt;strong&gt;高流量下建立连接---&amp;gt;低流量下释放部分连接---&amp;gt;高流量下重新建立连接&lt;/strong&gt;&lt;/span&gt;的情况，相当于虽然使用了连接池，但是因为流量不均匀反复建立连接、释放链接&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span&gt;线程数太少当然也是不好的，任务多而连接少，导致很多任务一直在排队等待前面的执行完才可以拿到连接去处理，降低了处理速度&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;span&gt;那针对连接池中的连接数量如何设置的这个问题，答案是没有固定的，但是可以通过估算得到一个预估值。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;首先开发同学对于一个任务每天的调用量心中需要有数，假设一天1000W次好了，线上有10台服务器，那么平均到每台服务器每天的调用量在100W，100W平均到1天的86400秒，每秒的调用量1000000 / 86400 ≈ 11.574次，根据接口的一个平均响应时长适当加一点余量，差不多设置在15~30比较合适，根据线上运行的实际情况再做调整。&lt;/span&gt;&lt;/p&gt;

</description>
<pubDate>Sun, 09 Jun 2019 15:14:00 +0000</pubDate>
<dc:creator>五月的仓颉</dc:creator>
<og:description>起因 6.1大促值班发现的一个问题，一个rpc接口在0~2点用户下单高峰的时候表现rt高（超过1s，实际上针对性优化过的接口rt超过这个值也是有问题的，通常rpc接口里面即使逻辑复杂，300ms应该也</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/xrq730/p/10963689.html</dc:identifier>
</item>
<item>
<title>开源一个golang小程序商城后台系统（moshopserver） - HarlanC</title>
<link>http://www.cnblogs.com/harlanc/p/10995253.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/harlanc/p/10995253.html</guid>
<description>&lt;p&gt;golang和c/c++比起来是一门新的语言，一直想学，网上搜集了一些资料，有些人说很容易上手，确实是这样，和C/C++比起来，少了很多乱七八糟的语法。学一门新的语言，最好的方法就是动手写一些东西，最近小程序也比较火，也想学一下，网络上搜索的一些开源项目，基本上没有golang实现的，大部分都是nodejs和java写的，那么我就来实现一个golang版的吧，一石二鸟。&lt;/p&gt;
&lt;p&gt;开发小程序前后端都需要开发，自己的前端经验很少，搜索了一些开源代码，有一个小程序项目让人眼前一亮，&lt;a href=&quot;https://github.com/tumobi/nideshop&quot;&gt;Nideshop&lt;/a&gt;，界面做的不错，代码结构也清晰，而且前后端都实现了，自己的目标是学习golang和小程序，干脆用golang重写nideshop吧。&lt;/p&gt;
&lt;h2 id=&quot;web框架的选择&quot;&gt;Web框架的选择&lt;/h2&gt;
&lt;p&gt;nodejs和java已经一些很成熟的框架了，比如nodejs的thinkjs，java的spring框架。golang最近几年才火起来，有一些web框架也比较新，有下面一些框架：&lt;/p&gt;
&lt;h5 id=&quot;beego开源的高性能-go-语言-web-框架&quot;&gt;Beego：开源的高性能 Go 语言 Web 框架。&lt;/h5&gt;
&lt;h5 id=&quot;buffalo使用-go-语言快速构建-web-应用&quot;&gt;Buffalo：使用 Go 语言快速构建 Web 应用。&lt;/h5&gt;
&lt;h5 id=&quot;echo简约的高性能-go-语言-web-框架&quot;&gt;Echo：简约的高性能 Go 语言 Web 框架。&lt;/h5&gt;
&lt;h5 id=&quot;gingo-语言编写的-web-框架以更好的性能实现类似-martini-框架的-api&quot;&gt;Gin：Go 语言编写的 Web 框架，以更好的性能实现类似 Martini 框架的 API。&lt;/h5&gt;
&lt;h5 id=&quot;iris全宇宙最快的-go-语言-web-框架完备-mvc-支持未来尽在掌握&quot;&gt;Iris：全宇宙最快的 Go 语言 Web 框架。完备 MVC 支持，未来尽在掌握。&lt;/h5&gt;
&lt;h5 id=&quot;revelgo-语言的高效全栈-web-框架&quot;&gt;Revel：Go 语言的高效、全栈 Web 框架。&lt;/h5&gt;
&lt;p&gt;Beego是国人写的框架，文档很全，例子也不少，用的人也多，最后决定用这个框架。&lt;/p&gt;
&lt;h2 id=&quot;使用xorm生成数据库model&quot;&gt;使用xorm生成数据库model&lt;/h2&gt;
&lt;p&gt;数据库采用的是mysql，使用golang读写mysql beego已经实现了orm框架。但是数据库表需要生成对应的struct，beego的orm貌似没有自动生成的功能。采用了一个开源库&lt;a href=&quot;https://github.com/go-xorm/cmd&quot;&gt;go-xorm/cmd&lt;/a&gt;,最后生成的数据库表像下面这样，奇怪的是没有json标签，而且这个xorm标签，最后golang不认报了错。还有一个问题是有些字段类型xorm生成错了。比如，数据库中的DECIMAL字段，xorm生成的结构体中的字段类型为string，这个显然是错误的。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;type NideshopAd struct {
AdPositionId int    `xorm:&quot;not null default 0 index SMALLINT(5)&quot;`
Content      string `xorm:&quot;not null default '' VARCHAR(255)&quot;`
Enabled      int    `xorm:&quot;not null default 1 index TINYINT(3)&quot;`
EndTime      int    `xorm:&quot;not null default 0 INT(11)&quot;`
Id           int    `xorm:&quot;not null pk autoincr SMALLINT(5)&quot;`
ImageUrl     string `xorm:&quot;not null TEXT&quot;`
Link         string `xorm:&quot;not null default '' VARCHAR(255)&quot;`
MediaType    int    `xorm:&quot;not null default 0 TINYINT(3)&quot;`
Name         string `xorm:&quot;not null default '' VARCHAR(60)&quot;`
}&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;moshopserver框架结构&quot;&gt;moshopserver框架结构&lt;/h2&gt;
&lt;p&gt;moshopserver的框架结构很清晰也很简单。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http:/qiniu.harlanc.vip/6.9.2019_10:06:29.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;前端小程序发起HTTP请求到Router(router转发请求的各个阶段能做一些过滤,这个后面要说一下)，router识别出请求链接，将其转发到相应的controller上面。还有三个底层的package：&lt;/p&gt;
&lt;ul readability=&quot;-0.5&quot;&gt;&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;models&lt;/p&gt;
&lt;p&gt;单纯和数据库打交道的接口都放在这个package下面。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;services&lt;/p&gt;
&lt;p&gt;主要实现了三类功能，和微信交互的接口，快递查询接口和token生成，检测接口。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Utils&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;一些基本的功能函数放在这个package下面。&lt;/p&gt;
&lt;h2 id=&quot;token验证&quot;&gt;Token验证&lt;/h2&gt;
&lt;p&gt;token的生成验证使用了&lt;a href=&quot;https://github.com/dgrijalva/jwt-go&quot;&gt;jwt-go&lt;/a&gt;这个第三方库,使用这个库通过token来解析出userID，创建和验证token是否过期，整个交互流程是下面这样子：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;小程序打开的时候默认不登录，调用后台接口，因为没有token，解析不出来userid，返回小程序段提示用户登录。&lt;/li&gt;
&lt;li&gt;小程序调用微信后台服务获取userinfo，调用moshopserver后台登录接口。&lt;/li&gt;
&lt;li&gt;后台接口调用微信后台，解密userInfo中的相关字段，生成一条用户信息插入moshopserver数据库中。然后从数据库中取出userid，生成带过期时间的token。返回给小程序。&lt;/li&gt;
&lt;li&gt;小程序调用微信后台接口，将token存储到微信服务端。接下来每次调用moshopserver后台，都要从微信后台取出token，然后传递到moshopsever后台。&lt;/li&gt;
&lt;li&gt;如果token过期或者无效，后端解析不出userid，返回给小程序，让其再次登录。生成新的token。如此反复。&lt;/li&gt;
&lt;/ol&gt;&lt;h2 id=&quot;router过滤器&quot;&gt;Router过滤器&lt;/h2&gt;
&lt;p&gt;Nideshop中做了一些设计，有些接口即使token过期也能访问，不需要提示用户再次登录。moshopserver中也实现了这个功能。采用了beego中的过滤器：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;    beego.InsertFilter(&quot;/api/*&quot;, beego.BeforeExec, services.FilterFunc, true, true)&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;使用的是BeforeExec参数，这个阶段Router已经识别出了Controller和Action的具体类型，我们可以自己加判断，到底哪些Controller和Action需要用户登录权限，这些Controller和action放在了配置文件api.conf中：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;[controller]
publicController= {'index','catalog','topic','auth','goods','brand','search','region'}
[action]
publicAction={'comment/list','comment/count','cart/index','cart/add','cart/checked','cart/update','cart/delete','cart/goodscount','pay/notify'}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;如果HTTP请求链接的Controller和Action都不在配置文件中，则跳过接口调用，直接返回小程序提示其进行重新登录。&lt;/p&gt;
&lt;h2 id=&quot;问题&quot;&gt;问题&lt;/h2&gt;
&lt;p&gt;moshopserver还是有一些bug，因为测试不够充分，应该也还存在一些未知的bug，以后慢慢修复。&lt;/p&gt;
&lt;p&gt;已经问题：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;订单列表中商品信息不显示。&lt;/li&gt;
&lt;li&gt;用户登录后没有显示登录（头像和用户名不显示）&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;欢迎Star,欢迎提问题。&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/harlanc/moshopserver&quot; class=&quot;uri&quot;&gt;https://github.com/harlanc/moshopserver&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;客户端小程序界面截图&quot;&gt;客户端小程序界面截图&lt;/h2&gt;
&lt;p&gt;最后附几张截图&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://qiniu.harlanc.vip/6.9.2019_5:41:56.png&quot; alt=&quot;首页&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://qiniu.harlanc.vip/6.9.2019_5:43:3.png&quot; alt=&quot;专题&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://qiniu.harlanc.vip/6.9.2019_5:43:41.png&quot; alt=&quot;分类&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://qiniu.harlanc.vip/6.9.2019_5:45:9.png&quot; alt=&quot;商品列表&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://qiniu.harlanc.vip/6.9.2019_5:45:53.png&quot; alt=&quot;商品详情&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://qiniu.harlanc.vip/6.9.2019_5:46:26.png&quot; alt=&quot;购物车&quot;/&gt;&lt;/p&gt;
</description>
<pubDate>Sun, 09 Jun 2019 14:50:00 +0000</pubDate>
<dc:creator>HarlanC</dc:creator>
<og:description>开源一个golang小程序商城后台（moshopserver） golang和c/c++比起来是一门新的语言，一直想学，网上搜集了一些资料，有些人说很容易上手，确实是这样，和C/C++比起来，少了很多</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/harlanc/p/10995253.html</dc:identifier>
</item>
<item>
<title>基于log4net的日志组件扩展分装，实现自动记录交互日志 XYH.Log4Net.Extend - 猴子哥</title>
<link>http://www.cnblogs.com/xiaoXuZhi/p/XYH_Log4Net_Extend.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/xiaoXuZhi/p/XYH_Log4Net_Extend.html</guid>
<description>&lt;p&gt;&lt;strong&gt;背景：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;　　随着公司的项目不断的完善，功能越来越复杂，服务也越来越多（微服务），公司迫切需要对整个系统的每一个程序的运行情况进行监控，并且能够实现对自动记录不同服务间的程序调用的交互日志，以及通一个服务或者项目中某一次执行情况的跟踪监控&lt;/p&gt;
&lt;p&gt;       根据log4net的现有功能满足不了实际需求，所以需要以log4net为基础进行分装完善，现在分装出了一个基础的版本，如有不妥之处，多多指点&lt;br/&gt;&lt;strong&gt;功能简介：&lt;/strong&gt;&lt;br/&gt;　　该组件是在log4net的基础上，进行了一定的扩展封装实现的自动记录交互日志功能&lt;br/&gt;　　该组件的封装的目的是解决一下几个工作中的实际问题&lt;br/&gt;　　1、对记录的日志内容格式完善&lt;br/&gt;　　2、微服务项目中，程序自动记录不同服务间的调用关系，以及出参、入参、执行时间等&lt;br/&gt;　　3、同一项目中，不同方法及其层之间的调用关系等信息&lt;br/&gt;　　4、其最终目的就是，实现对系统的一个整体监控&lt;/p&gt;&lt;p&gt;&lt;strong&gt;主要封装扩展功能点：&lt;/strong&gt;&lt;br/&gt;1、通过对log4net进行扩展，能够自定义了一些日志格式颜色内容等&lt;br/&gt;2、通过代理+特性的方式，实现程序自动记录不同服务间，以及同一程序间的相互调用的交互日志&lt;br/&gt;3、采用队列的方式实现异步落地日志到磁盘文件&lt;/p&gt;

&lt;p&gt;主要核心代码示例，具体的详细代码，我已经上传至githut开源项目中，如有需要可以下载了解&lt;/p&gt;
&lt;p&gt;github源码地址：&lt;a title=&quot;https://github.com/xuyuanhong0902/XYH.Log4Net.Extend.git&quot; href=&quot;https://github.com/xuyuanhong0902/XYH.Log4Net.Extend.git&quot; target=&quot;_blank&quot;&gt;https://github.com/xuyuanhong0902/XYH.Log4Net.Extend.git&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;代理实现自动记录方法调用的详细日志&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;54&quot;&gt;
&lt;pre class=&quot;brush:csharp;gutter:true;&quot;&gt;
   /// &amp;lt;summary&amp;gt;
    /// XYH代理实现类.
    /// &amp;lt;/summary&amp;gt;
    public class XYHAopProxy : RealProxy
    {
        /// &amp;lt;summary&amp;gt;
        /// 构造函数.
        /// &amp;lt;/summary&amp;gt;
        /// &amp;lt;param name=&quot;target&quot;&amp;gt;目标类型.&amp;lt;/param&amp;gt;
        public XYHAopProxy(Type target)
            : base(target)
        {
        }

        /// &amp;lt;summary&amp;gt;
        /// 重写代理实现.
        /// &amp;lt;/summary&amp;gt;
        /// &amp;lt;param name=&quot;msg&quot;&amp;gt;代理函数&amp;lt;/param&amp;gt;
        /// &amp;lt;returns&amp;gt;返回结果&amp;lt;/returns&amp;gt;
        public override IMessage Invoke(IMessage methodInvoke)
        {
            //// 方法开始执行时间
            DateTime executeStartTime = System.DateTime.Now;

            //// 方法执行结束时间
            DateTime executeEndTime = System.DateTime.Now;

            IMessage message = null;
            IMethodCallMessage call = methodInvoke as IMethodCallMessage;
            object[] customAttributeArray = call.MethodBase.GetCustomAttributes(false);
            call.MethodBase.GetCustomAttributes(false);

            try
            {
                // 前处理.
                List&amp;lt;IAopAction&amp;gt; proActionList = this.InitAopAction(customAttributeArray, AdviceType.Before);

                //// 方法执行开始记录日志
                if (proActionList != null &amp;amp;&amp;amp; proActionList.Count &amp;gt; 0  )
                {
                    foreach (IAopAction item in proActionList)
                    {
                        IMessage preMessage = item.PreProcess(methodInvoke, base.GetUnwrappedServer());
                        if (preMessage != null)
                        {
                            message = preMessage;
                        }
                    }

                    if (message != null)
                    {
                        return message;
                    }
                }

                message = Proessed(methodInvoke);

                // 后处理.
                proActionList = this.InitAopAction(customAttributeArray, AdviceType.Around);

                //// 方法执行结束时间
                executeEndTime = System.DateTime.Now;

                //// 方法执行结束记录日志
                if (proActionList != null &amp;amp;&amp;amp; proActionList.Count &amp;gt; 0)
                {
                    foreach (IAopAction item in proActionList)
                    {
                        item.PostProcess(methodInvoke, message, base.GetUnwrappedServer(), executeStartTime, executeEndTime);
                    }
                }
            }
            catch (Exception ex)
            {
                //// 方法执行结束时间
                executeEndTime = System.DateTime.Now;

                // 异常处理.吃掉异常，不影响主业务
                List&amp;lt;IAopAction&amp;gt; proActionList = this.InitAopAction(customAttributeArray, AdviceType.Around);
                if (proActionList != null &amp;amp;&amp;amp; proActionList.Count &amp;gt; 0)
                {
                    foreach (IAopAction item in proActionList)
                    {
                        item.ExceptionProcess(ex, methodInvoke, base.GetUnwrappedServer(), executeStartTime, executeEndTime);
                    }
                }
            }

            return message;
        }

        /// &amp;lt;summary&amp;gt;
        /// 处理方法执行.
        /// &amp;lt;/summary&amp;gt;
        /// &amp;lt;param name=&quot;methodInvoke&quot;&amp;gt;代理目标方法&amp;lt;/param&amp;gt;
        /// &amp;lt;returns&amp;gt;代理结果&amp;lt;/returns&amp;gt;
        public virtual IMessage Proessed(IMessage methodInvoke)
        {
            IMessage message;
            if (methodInvoke is IConstructionCallMessage)
            {
                message = this.ProcessConstruct(methodInvoke);
            }
            else
            {
                message = this.ProcessInvoke(methodInvoke);
            }
            return message;
        }

        /// &amp;lt;summary&amp;gt;
        /// 普通代理方法执行.
        /// &amp;lt;/summary&amp;gt;
        /// &amp;lt;param name=&quot;methodInvoke&quot;&amp;gt;代理目标方法&amp;lt;/param&amp;gt;
        /// &amp;lt;returns&amp;gt;代理结果&amp;lt;/returns&amp;gt;
        public virtual IMessage ProcessInvoke(IMessage methodInvoke)
        {
            IMethodCallMessage callMsg = methodInvoke as IMethodCallMessage;
            object[] args = callMsg.Args;   //方法参数                 
            object o = callMsg.MethodBase.Invoke(base.GetUnwrappedServer(), args);  //调用 原型类的 方法       

            return new ReturnMessage(o, args, args.Length, callMsg.LogicalCallContext, callMsg);   // 返回类型 Message
        }

        /// &amp;lt;summary&amp;gt;
        /// 构造函数代理方法执行.
        /// &amp;lt;/summary&amp;gt;
        /// &amp;lt;param name=&quot;methodInvoke&quot;&amp;gt;代理目标方法&amp;lt;/param&amp;gt;
        /// &amp;lt;returns&amp;gt;代理结果&amp;lt;/returns&amp;gt;
        public virtual IMessage ProcessConstruct(IMessage methodInvoke)
        {
            IConstructionCallMessage constructCallMsg = methodInvoke as IConstructionCallMessage;
            IConstructionReturnMessage constructionReturnMessage = this.InitializeServerObject((IConstructionCallMessage)methodInvoke);
            RealProxy.SetStubData(this, constructionReturnMessage.ReturnValue);

            return constructionReturnMessage;
        }

        /// &amp;lt;summary&amp;gt;
        /// 代理包装业务处理.
        /// &amp;lt;/summary&amp;gt;
        /// &amp;lt;param name=&quot;customAttributeArray&quot;&amp;gt;代理属性&amp;lt;/param&amp;gt;
        /// &amp;lt;param name=&quot;adviceType&quot;&amp;gt;处理类型&amp;lt;/param&amp;gt;
        /// &amp;lt;returns&amp;gt;结果.&amp;lt;/returns&amp;gt;
        public virtual List&amp;lt;IAopAction&amp;gt; InitAopAction(object[] customAttributeArray, AdviceType adviceType)
        {
            List&amp;lt;IAopAction&amp;gt; actionList = new List&amp;lt;IAopAction&amp;gt;();
            if (customAttributeArray != null &amp;amp;&amp;amp; customAttributeArray.Length &amp;gt; 0)
            {
                foreach (Attribute item in customAttributeArray)
                {
                    XYHMethodAttribute methodAdviceAttribute = item as XYHMethodAttribute;
                    if (methodAdviceAttribute != null &amp;amp;&amp;amp; (methodAdviceAttribute.AdviceType == adviceType))
                    {
                        if (methodAdviceAttribute.ProcessType == ProcessType.None)
                        {
                            continue;
                        }

                        if (methodAdviceAttribute.ProcessType == ProcessType.Log)
                        {
                            actionList.Add(new LogAopActionImpl());
                            continue;
                        }
                    }
                }
            }

            return actionList;
        }
    }
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　类注解&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;36&quot;&gt;
&lt;pre class=&quot;brush:csharp;gutter:true;&quot;&gt;
  /// &amp;lt;summary&amp;gt;
    /// XYH代理属性[作用于类].
    /// ************************************
    /// [DecorateSymbol] Class ClassName
    /// ************************************
    /// &amp;lt;/summary&amp;gt;
    [AttributeUsage(AttributeTargets.Class, AllowMultiple = false)]
    public class XYHAopAttribute : ProxyAttribute
    {
        public XYHAopAttribute()
        {
        }

        public override MarshalByRefObject CreateInstance(Type serverType)
        {
            XYHAopProxy realProxy = new XYHAopProxy(serverType);
            return realProxy.GetTransparentProxy() as MarshalByRefObject;
        }
    }
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　队列实现异步日志落地到磁盘文件&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;35&quot;&gt;
&lt;pre class=&quot;brush:csharp;gutter:true;&quot;&gt;
namespace XYH.Log4Net.Extend
{
    /// &amp;lt;summary&amp;gt;
    /// 通过队列的方式实现异步记录日志
    /// &amp;lt;/summary&amp;gt;
    public sealed class ExtendLogQueue
    {
        /// &amp;lt;summary&amp;gt;
        /// 记录消息 队列
        /// &amp;lt;/summary&amp;gt;
        private readonly ConcurrentQueue&amp;lt;LogMessage&amp;gt; extendLogQue;

        /// &amp;lt;summary&amp;gt;
        /// 信号
        /// &amp;lt;/summary&amp;gt;
        private readonly ManualResetEvent extendLogMre;

        /// &amp;lt;summary&amp;gt;
        /// 日志
        /// &amp;lt;/summary&amp;gt;
        private static ExtendLogQueue _flashLog = new ExtendLogQueue();

        /// &amp;lt;summary&amp;gt;
        /// 构造函数
        /// &amp;lt;/summary&amp;gt;
        private ExtendLogQueue()
        {
            extendLogQue = new ConcurrentQueue&amp;lt;LogMessage&amp;gt;();
            extendLogMre = new ManualResetEvent(false);
        }

        /// &amp;lt;summary&amp;gt;
        /// 单例实例
        /// &amp;lt;/summary&amp;gt;
        /// &amp;lt;returns&amp;gt;&amp;lt;/returns&amp;gt;
        public static ExtendLogQueue Instance()
        {
            return _flashLog;
        }

        /// &amp;lt;summary&amp;gt;
        /// 另一个线程记录日志，只在程序初始化时调用一次
        /// &amp;lt;/summary&amp;gt;
        public void Register()
        {
            Thread t = new Thread(new ThreadStart(WriteLogDispatch));
            t.IsBackground = false;
            t.Start();
        }

        /// &amp;lt;summary&amp;gt;
        /// 从队列中写日志至磁盘
        /// &amp;lt;/summary&amp;gt;
        private void WriteLogDispatch()
        {
            while (true)
            {

                //// 如果队列中还有待写日志，那么直接调用写日志
                if (extendLogQue.Count &amp;gt; 0)
                {
                    //// 根据队列写日志
                    WriteLog();

                    // 重新设置信号
                    extendLogMre.Reset();
                }

                //// 如果没有，那么等待信号通知
                extendLogMre.WaitOne();
            }
        }

        /// &amp;lt;summary&amp;gt;
        /// 具体调用log4日志组件实现
        /// &amp;lt;/summary&amp;gt;
        private void WriteLog()
        {
            LogMessage msg;
            // 判断是否有内容需要如磁盘 从列队中获取内容，并删除列队中的内容
            while (extendLogQue.Count &amp;gt; 0 &amp;amp;&amp;amp; extendLogQue.TryDequeue(out msg))
            {
                new LogHandlerImpl(LogHandlerManager.GetILogger(msg.LogSerialNumber)).WriteLog(msg);
            }
        }

        /// &amp;lt;summary&amp;gt;
        /// 日志入队列
        /// &amp;lt;/summary&amp;gt;
        /// &amp;lt;param name=&quot;message&quot;&amp;gt;日志文本&amp;lt;/param&amp;gt;
        /// &amp;lt;param name=&quot;level&quot;&amp;gt;等级&amp;lt;/param&amp;gt;
        /// &amp;lt;param name=&quot;ex&quot;&amp;gt;Exception&amp;lt;/param&amp;gt;
        public  void EnqueueMessage(LogMessage logMessage)
        {
            //// 日志入队列
            extendLogQue.Enqueue(logMessage);

            // 通知线程往磁盘中写日志
            extendLogMre.Set();
        }
    }
}
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　自定义扩展log4net日志格式内容&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;47&quot;&gt;
&lt;pre class=&quot;brush:csharp;gutter:true;&quot;&gt;
namespace XYH.Log4Net.Extend
{
    /// &amp;lt;summary&amp;gt;
    /// 自定义布局（对log2net日志组件的布局自定义扩展）.
    /// &amp;lt;/summary&amp;gt;
    public class HandlerPatternLayout : PatternLayout
    {
        /// &amp;lt;summary&amp;gt;
        /// 构造函数.
        /// &amp;lt;/summary&amp;gt;
        public HandlerPatternLayout()
        {
            ///// 机器名称
            this.AddConverter(&quot;LogMachineCode&quot;, typeof(LogMachineCodePatternConvert));

            //// 方法名称
            this.AddConverter(&quot;MethodName&quot;, typeof(LogMethodNamePatternConvert));

            //// 方法入参
            this.AddConverter(&quot;MethodParam&quot;, typeof(LogMethodParamConvert));

            //// 方法出参
            this.AddConverter(&quot;MethodResult&quot;, typeof(LogMethodResultConvert));

            //// 程序名称
            this.AddConverter(&quot;LogProjectName&quot;, typeof(LogProjectNamePatternConvert));

            //// IP 地 址
            this.AddConverter(&quot;LogIpAddress&quot;, typeof(LogServiceIpPatternConvert));

            //// 日志编号
            this.AddConverter(&quot;LogUniqueCode&quot;, typeof(LogUniquePatternConvert));

            //// 日志序列号
            this.AddConverter(&quot;LogSerialNumber&quot;, typeof(LogSerialNumberPatternConvert));

            //// 调用路径
            this.AddConverter(&quot;InvokeName&quot;, typeof(LogInvokeNamePatternConvert));

            //// 执行开始时间
            this.AddConverter(&quot;ExecuteStartTime&quot;, typeof(ExecuteStartTimePatternConvert));

            //// 执行结束时间
            this.AddConverter(&quot;ExecuteEndTime&quot;, typeof(ExecuteEndTimePatternConvert));

            //// 执行时间
            this.AddConverter(&quot;ExecuteTime&quot;, typeof(ExecuteTimePatternConvert));
        }
    }
}
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;使用说明：&lt;/strong&gt;&lt;br/&gt;第一步：需要dll文件引用&lt;br/&gt;需要引用两个dell文件：&lt;br/&gt;jeson序列化：Newtonsoft.Json.dll&lt;br/&gt;log4net组件：log4net.dll&lt;br/&gt;log3net扩展组件：XYH.Log4Net.Extend.dll&lt;/p&gt;&lt;p&gt;第二步：log4配置文件配置&lt;br/&gt;主要配置日志的存储地址，日志文件存储格式、内容等&lt;br/&gt;下面，给一个参考配置文件，具体的配置可以根据实际需要自由配置，其配置方式很log4net本身的配置文件一样，在此不多说&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;41&quot;&gt;
&lt;pre class=&quot;brush:csharp;gutter:true;&quot;&gt;
&amp;lt;log4net&amp;gt;
  &amp;lt;root&amp;gt;
    &amp;lt;!-- 定义记录的日志级别[None、Fatal、ERROR、WARN、DEBUG、INFO、ALL]--&amp;gt;
    &amp;lt;level value=&quot;ALL&quot;/&amp;gt;
    &amp;lt;!-- 记录到什么介质中--&amp;gt;
    &amp;lt;appender-ref ref=&quot;LogInfoFileAppender&quot;/&amp;gt;
    &amp;lt;appender-ref ref=&quot;LogErrorFileAppender&quot;/&amp;gt;
  &amp;lt;/root&amp;gt;
  &amp;lt;!-- name属性指定其名称,type则是log4net.Appender命名空间的一个类的名称,意思是,指定使用哪种介质--&amp;gt;
  &amp;lt;appender name=&quot;LogInfoFileAppender&quot; type=&quot;log4net.Appender.RollingFileAppender&quot;&amp;gt;
    &amp;lt;!-- 输出到什么目录--&amp;gt;
    &amp;lt;param name=&quot;File&quot; value=&quot;Log\\LogInfo\\&quot;/&amp;gt;
    &amp;lt;!-- 是否覆写到文件中--&amp;gt;
    &amp;lt;param name=&quot;AppendToFile&quot; value=&quot;true&quot;/&amp;gt;
    &amp;lt;!-- 单个日志文件最大的大小--&amp;gt;
    &amp;lt;param name=&quot;MaxFileSize&quot; value=&quot;10240&quot;/&amp;gt;
    &amp;lt;!-- 备份文件的个数--&amp;gt;
    &amp;lt;param name=&quot;MaxSizeRollBackups&quot; value=&quot;100&quot;/&amp;gt;
    &amp;lt;!-- 是否使用静态文件名--&amp;gt;
    &amp;lt;param name=&quot;StaticLogFileName&quot; value=&quot;false&quot;/&amp;gt;
    &amp;lt;!-- 日志文件名--&amp;gt;
    &amp;lt;param name=&quot;DatePattern&quot; value=&quot;yyyyMMdd&quot;.html&quot;&quot;/&amp;gt;
    &amp;lt;param name=&quot;RollingStyle&quot; value=&quot;Date&quot;/&amp;gt;
    &amp;lt;!--布局--&amp;gt;
    &amp;lt;layout type=&quot;XYH.Log4Net.Extend.HandlerPatternLayout&quot;&amp;gt;
      &amp;lt;param name=&quot;ConversionPattern&quot; value=&quot;&amp;lt;HR COLOR=blue&amp;gt;%n%n
                                             日志编号：%property{LogUniqueCode}  &amp;lt;BR &amp;gt;%n
                                             日志序列：%property{LogSerialNumber} &amp;lt;BR&amp;gt;%n
                                             机器名称：%property{LogMachineCode} &amp;lt;BR&amp;gt;%n
                                             IP 地 址：%property{LogIpAddress} &amp;lt;BR&amp;gt;%n
                                             开始时间：%property{ExecuteStartTime} &amp;lt;BR&amp;gt;%n
                                             结束时间：%property{ExecuteEndTime} &amp;lt;BR&amp;gt;%n
                                             执行时间：%property{ExecuteTime} &amp;lt;BR&amp;gt;%n
                                             程序名称：%property{LogProjectName} &amp;lt;BR&amp;gt;%n
                                             方法名称：%property{MethodName} &amp;lt;BR&amp;gt;%n
                                             方法入参：%property{MethodParam} &amp;lt;BR&amp;gt;%n
                                             方法出参：%property{MethodResult} &amp;lt;BR&amp;gt;%n
                                             日志信息：%m &amp;lt;BR &amp;gt;%n
                                             日志时间：%d &amp;lt;BR &amp;gt;%n
                                             日志级别：%-5p &amp;lt;BR &amp;gt;%n
                                             异常堆栈：%exception &amp;lt;BR &amp;gt;%n
                                             &amp;lt;HR Size=1 &amp;gt;&quot;/&amp;gt;
    &amp;lt;/layout&amp;gt;
  &amp;lt;/appender&amp;gt;
  &amp;lt;!-- name属性指定其名称,type则是log4net.Appender命名空间的一个类的名称,意思是,指定使用哪种介质--&amp;gt;
  &amp;lt;appender name=&quot;LogErrorFileAppender&quot; type=&quot;log4net.Appender.RollingFileAppender&quot;&amp;gt;
    &amp;lt;!-- 输出到什么目录--&amp;gt;
    &amp;lt;param name=&quot;File&quot; value=&quot;Log\\LogError\\&quot;/&amp;gt;
    &amp;lt;!-- 是否覆写到文件中--&amp;gt;
    &amp;lt;param name=&quot;AppendToFile&quot; value=&quot;true&quot;/&amp;gt;
    &amp;lt;!-- 备份文件的个数--&amp;gt;
    &amp;lt;param name=&quot;MaxSizeRollBackups&quot; value=&quot;100&quot;/&amp;gt;
    &amp;lt;!-- 单个日志文件最大的大小--&amp;gt;
    &amp;lt;param name=&quot;MaxFileSize&quot; value=&quot;10240&quot;/&amp;gt;
    &amp;lt;!-- 是否使用静态文件名--&amp;gt;
    &amp;lt;param name=&quot;StaticLogFileName&quot; value=&quot;false&quot;/&amp;gt;
    &amp;lt;!-- 日志文件名--&amp;gt;
    &amp;lt;param name=&quot;DatePattern&quot; value=&quot;yyyyMMdd&quot;.html&quot;&quot;/&amp;gt;
    &amp;lt;param name=&quot;RollingStyle&quot; value=&quot;Date&quot;/&amp;gt;
    &amp;lt;!--布局--&amp;gt;
    &amp;lt;layout type=&quot;XYH.Log4Net.Extend.HandlerPatternLayout&quot;&amp;gt;
      &amp;lt;param name=&quot;ConversionPattern&quot; value=&quot;&amp;lt;HR COLOR=red&amp;gt;%n
                                             日志编号：%property{LogUniqueCode}  &amp;lt;BR &amp;gt;%n
                                             日志序列：%property{LogSerialNumber} &amp;lt;BR&amp;gt;%n
                                             机器名称：%property{LogMachineCode} &amp;lt;BR&amp;gt;%n
                                             IP 地 址: %property{LogIpAddress} &amp;lt;BR&amp;gt;%n
                                             程序名称：%property{LogProjectName} &amp;lt;BR&amp;gt;%n
                                             方法名称：%property{MethodName}&amp;lt;BR&amp;gt;%n
                                             方法入参：%property{MethodParam} &amp;lt;BR&amp;gt;%n
                                             方法出参：%property{MethodResult} &amp;lt;BR&amp;gt;%n
                                             日志信息：%m &amp;lt;BR &amp;gt;%n
                                             日志时间：%d &amp;lt;BR &amp;gt;%n
                                             日志级别：%-5p &amp;lt;BR &amp;gt;%n
                                             异常堆栈：%exception &amp;lt;BR &amp;gt;%n
                                             &amp;lt;HR Size=1 &amp;gt;&quot;/&amp;gt;
    &amp;lt;/layout&amp;gt;
    &amp;lt;filter type=&quot;log4net.Filter.LevelRangeFilter&quot;&amp;gt;
      &amp;lt;levelMin value=&quot;ERROR&quot;/&amp;gt;
      &amp;lt;levelMax value=&quot;FATAL&quot;/&amp;gt;
    &amp;lt;/filter&amp;gt;
  &amp;lt;/appender&amp;gt;
&amp;lt;/log4net&amp;gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;br/&gt;第三步：在Global.asax文件中注册消息队列&lt;br/&gt;protected void Application_Start()&lt;br/&gt;{&lt;br/&gt;AreaRegistration.RegisterAllAreas();&lt;br/&gt;FilterConfig.RegisterGlobalFilters(GlobalFilters.Filters);&lt;br/&gt;RouteConfig.RegisterRoutes(RouteTable.Routes);&lt;br/&gt;BundleConfig.RegisterBundles(BundleTable.Bundles);&lt;/p&gt;
&lt;p&gt;////注册日志队列&lt;br/&gt;ExtendLogQueue.Instance().Register();&lt;br/&gt;}&lt;/p&gt;&lt;p&gt;第四步：在Global.asax文件中生成处理日志序列号&lt;br/&gt;/// &amp;lt;summary&amp;gt;&lt;br/&gt;/// 每一个请求执行开始&lt;br/&gt;/// &amp;lt;/summary&amp;gt;&lt;br/&gt;protected void Session_Start() {&lt;br/&gt;//// 记录获取创建每一个请求的序列号&lt;br/&gt;/// 如果调用放传递了序列号，那么就直接去调用放传递的序列号&lt;br/&gt;/// 如果调用放未传递，那么则生成一个序列号&lt;br/&gt;/// 这样，在一次请求的头部传递一个该请求的唯一序列号，并在以后的每一个请求都一直传递下去&lt;br/&gt;/// 这样，就能够通过这个序列号把每一次请求之间的服务或者方法调用关系串联起来&lt;br/&gt;String[] serialNumber = Request.Headers.GetValues(&quot;serialNumber&quot;);&lt;br/&gt;if (serialNumber!=null &amp;amp;&amp;amp; serialNumber.Length&amp;gt;0 &amp;amp;&amp;amp; !string.IsNullOrEmpty(serialNumber[0]))&lt;br/&gt;{&lt;br/&gt;Session[&quot;LogSerialNumber&quot;] = serialNumber[0];&lt;br/&gt;}&lt;br/&gt;else&lt;br/&gt;{&lt;br/&gt;Session[&quot;LogSerialNumber&quot;] = Guid.NewGuid().ToString().Replace(&quot;-&quot;, &quot;&quot;).ToUpper();&lt;br/&gt;}&lt;br/&gt;}&lt;/p&gt;&lt;p&gt;第五步：在需要自动记录日志的方法类上加上对应的注解&lt;/p&gt;&lt;p&gt;//// 在需要自动记录日志的类上加上 XYHAop注解&lt;br/&gt;[XYHAop]&lt;br/&gt;public class Class2: calssAdd&lt;br/&gt;{&lt;br/&gt;//// 需要记录自动记录交互日志的方法注解 ProcessType.Log&lt;/p&gt;
&lt;p&gt;//// 同时该类还必须继承ContextBoundObject&lt;/p&gt;
&lt;p&gt;&lt;em id=&quot;__mceDel&quot;&gt;[XYHMethod(ProcessType.Log)]&lt;br/&gt;public int AddNum(int num1, int num2)&lt;br/&gt;{&lt;br/&gt;}&lt;br/&gt;//// 需要记录自动记录交互日志的方法注解 ProcessType.None，其实不加注解也不会记录日志&lt;br/&gt;[XYHMethod(ProcessType.None)]&lt;br/&gt;public int SubNum(int num1, int num2)&lt;br/&gt;{&lt;br/&gt;}&lt;br/&gt;}&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;第六步：完成上面五步已经能够实现自动记录交互日志了，&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt; 但是在实际使用中我们也会手动记录一些日志，本插件也支持手动记录日志的同样扩展效果&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;目前支持以下6中手动记录日志的重载方法基于log4net的日志组件扩展分装，实现自动记录交互日志 XYH.Log4Net.Extend&lt;/em&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;53&quot;&gt;
&lt;pre class=&quot;brush:csharp;gutter:true;&quot;&gt;
 /// &amp;lt;summary&amp;gt;
    /// 记录日志扩展入口
    /// &amp;lt;/summary&amp;gt;
    public class XYHLogOperator
    {
        /// &amp;lt;summary&amp;gt;
        /// 添加日志.
        /// &amp;lt;/summary&amp;gt;
        /// &amp;lt;param name=&quot;message&quot;&amp;gt;日志信息对象&amp;lt;/param&amp;gt;
        public static void WriteLog(object message)
        {
            new MessageIntoQueue().WriteLog(message);
        }

        /// &amp;lt;summary&amp;gt;
        /// 添加日志.
        /// &amp;lt;/summary&amp;gt;
        /// &amp;lt;param name=&quot;message&quot;&amp;gt;日志信息对象&amp;lt;/param&amp;gt;
        /// &amp;lt;param name=&quot;level&quot;&amp;gt;日志信息级别&amp;lt;/param&amp;gt;
        public static void WriteLog(object message, LogLevel level)
        {
            new MessageIntoQueue().WriteLog(message, level);
        }

        /// &amp;lt;summary&amp;gt;
        /// 添加日志.
        /// &amp;lt;/summary&amp;gt;
        /// &amp;lt;param name=&quot;message&quot;&amp;gt;日志信息对象&amp;lt;/param&amp;gt;
        /// &amp;lt;param name=&quot;level&quot;&amp;gt;日志信息级别&amp;lt;/param&amp;gt;
        /// &amp;lt;param name=&quot;exception&quot;&amp;gt;异常信息对象&amp;lt;/param&amp;gt;
        public static void WriteLog(object message, Exception exception)
        {
            new MessageIntoQueue().WriteLog(message, exception);
        }

        /// &amp;lt;summary&amp;gt;
        /// 添加日志.
        /// &amp;lt;/summary&amp;gt;
        /// &amp;lt;param name=&quot;message&quot;&amp;gt;日志信息对象&amp;lt;/param&amp;gt;
        /// &amp;lt;param name=&quot;methodName&quot;&amp;gt;方法名&amp;lt;/param&amp;gt;
        /// &amp;lt;param name=&quot;methodParam&quot;&amp;gt;方法入参&amp;lt;/param&amp;gt;
        /// &amp;lt;param name=&quot;methodResult&quot;&amp;gt;方法请求结果&amp;lt;/param&amp;gt;
        public static void WriteLog(object message, string methodName, object methodParam, object methodResult)
        {
            new MessageIntoQueue().WriteLog(message, methodName, methodParam, methodResult);
        }

        /// &amp;lt;summary&amp;gt;
        /// 添加日志.
        /// &amp;lt;/summary&amp;gt;
        /// &amp;lt;param name=&quot;message&quot;&amp;gt;日志信息对象&amp;lt;/param&amp;gt;
        /// &amp;lt;param name=&quot;methodName&quot;&amp;gt;方法名&amp;lt;/param&amp;gt;
        /// &amp;lt;param name=&quot;methodParam&quot;&amp;gt;方法入参&amp;lt;/param&amp;gt;
        /// &amp;lt;param name=&quot;methodResult&quot;&amp;gt;方法请求结果&amp;lt;/param&amp;gt;
        /// &amp;lt;param name=&quot;level&quot;&amp;gt;日志记录级别&amp;lt;/param&amp;gt;
        public static void WriteLog(object message, string methodName, object methodParam, object methodResult, LogLevel level)
        {
            new MessageIntoQueue().WriteLog(message, methodName, methodParam, methodResult, level);
        }

        /// &amp;lt;summary&amp;gt;
        /// 添加日志
        /// &amp;lt;/summary&amp;gt;
        /// &amp;lt;param name=&quot;extendLogInfor&quot;&amp;gt;具体的日志消息model&amp;lt;/param&amp;gt;
        public static void WriteLog(LogMessage extendLogInfor)
        {
            new MessageIntoQueue().WriteLog(extendLogInfor);
        }
    }
}
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;手动记录日志示例：&lt;/p&gt;
&lt;p&gt;object message = &quot;一个参数日志记录单元测试&quot;; // TODO: 初始化为适当的值&lt;br/&gt;XYHLogOperator.WriteLog(message);&lt;/p&gt;
&lt;p&gt;如有问题，欢迎QQ随时交流&lt;br/&gt;QQ：1315597862&lt;/p&gt;
&lt;p&gt;&lt;em&gt;github源码地址：&lt;a title=&quot;https://github.com/xuyuanhong0902/XYH.Log4Net.Extend.git&quot; href=&quot;https://github.com/xuyuanhong0902/XYH.Log4Net.Extend.git&quot; target=&quot;_blank&quot;&gt;https://github.com/xuyuanhong0902/XYH.Log4Net.Extend.git&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
</description>
<pubDate>Sun, 09 Jun 2019 14:39:00 +0000</pubDate>
<dc:creator>猴子哥</dc:creator>
<og:description>基于Log4Net日志组件的扩展，实现微服务的监控日志组件，主要内容包括：不同服务间的调用交互日志，同一个程序内不同方法调用日志。在实现上：在log4net的基础上，通过代理的方式实现自动记日志，通过</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/xiaoXuZhi/p/XYH_Log4Net_Extend.html</dc:identifier>
</item>
</channel>
</rss>