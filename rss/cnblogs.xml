<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="css/feed.xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/" xmlns:og="http://ogp.me/ns#">
<channel>
<atom:link rel="self" href="http://192.168.1.4/fivefilters/makefulltextfeed.php?url=feed.cnblogs.com%2Fblog%2Fsitehome%2Frss&amp;max=10&amp;links=preserve&amp;exc=" />
<atom:link rel="alternate" title="Source URL" href="http://feed.cnblogs.com/blog/sitehome/rss" />
<atom:link rel="related" title="Subscribe to feed" href="http://www.subtome.com/#/subscribe?feeds=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed.cnblogs.com%252Fblog%252Fsitehome%252Frss%26max%3D10%26links%3Dpreserve%26exc%3D&amp;back=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed.cnblogs.com%252Fblog%252Fsitehome%252Frss%26max%3D10%26links%3Dpreserve%26exc%3D" />
<title>博客园_首页</title>
<link></link>
<description>代码改变世界</description>
<item>
<title>Inlook - 你的私人工作助理 V1.0.0.2 - 云远·笨小孩</title>
<link>http://www.cnblogs.com/charleechan/p/14306152.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/charleechan/p/14306152.html</guid>
<description>&lt;p&gt;中文版|&lt;a href=&quot;https://github.com/charleechan/Inlook&quot; target=&quot;_blank&quot;&gt;English version&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Inlook是为在桌面上直观地提醒用户收到未读邮件和日程安排而开发的软件。本发布版仅限Windows 10. 开发者可基于此项目自由开发其他平台的版本。&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1153181/202101/1153181-20210121084433539-232597950.png&quot;/&gt;&lt;/div&gt;
&lt;p&gt;使用截图&lt;/p&gt;
&lt;h2 id=&quot;release&quot;&gt;Release&lt;/h2&gt;
&lt;h2 id=&quot;features&quot;&gt;Features&lt;/h2&gt;
&lt;ul&gt;&lt;li&gt;新邮件到达时自动弹窗提醒.&lt;/li&gt;
&lt;li&gt;列出从昨天到未来6天的日程.&lt;/li&gt;
&lt;li&gt;支持解锁、锁定窗口大小和位置.&lt;/li&gt;
&lt;li&gt;窗口放在桌面最底层,不影响游戏和工作.&lt;/li&gt;
&lt;li&gt;网速和占用RAM监控.&lt;/li&gt;
&lt;li&gt;支持鼠标穿透,提高工作效率.&lt;/li&gt;
&lt;li&gt;智能缩放,根据邮箱数目和日程项数自动规划窗口大小.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;支持中文界面!&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;h2 id=&quot;change-log&quot;&gt;Change log&lt;/h2&gt;
&lt;ul&gt;&lt;li&gt;2020.12.29 初始版本发布&lt;/li&gt;
&lt;li&gt;2021.01.15 增加对中文界面的支持.&lt;/li&gt;
&lt;li&gt;2021.01.19 增加用户登录账户验证功能, 修复Bug: 第二次网络中断后连接造成崩溃&lt;/li&gt;
&lt;/ul&gt;&lt;h2 id=&quot;declaration-of-interest&quot;&gt;Declaration of interest&lt;/h2&gt;
&lt;p&gt;[GNU General Public License v3.0]&lt;/p&gt;
&lt;h2 id=&quot;usage&quot;&gt;Usage&lt;/h2&gt;
&lt;ul readability=&quot;7&quot;&gt;&lt;li readability=&quot;1&quot;&gt;
&lt;p&gt;添加你的邮箱账户可以实现&lt;strong&gt;新邮件提醒&lt;/strong&gt;, 你需要提前获取你的邮箱的IMAP的服务器信息，部分邮箱如&lt;strong&gt;163，QQ邮箱登录时需要授权码而不是密码&lt;/strong&gt;。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;2&quot;&gt;
&lt;p&gt;在本软件和手机自带的日历中添加同一个&lt;code&gt;Exchange&lt;/code&gt;账户(我自己测试的是Outlook),可以实现&lt;strong&gt;日程多端自动同步, 日程提醒&lt;/strong&gt;。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;任何时候可以直接在托盘修改语言,无需重启软件.&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;5&quot;&gt;
&lt;p&gt;自1.0.0.1发布版之后,去除了快捷方式的&lt;strong&gt;开机启动&lt;/strong&gt;,如有需要,请自行生成指向&lt;strong&gt;start.bat&lt;/strong&gt;的快捷方式,并拖放到&lt;code&gt;C:\Users\[username]\AppData\Roaming\Microsoft\Windows\Start Menu\Programs\Startup&lt;/code&gt;目录.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;h2 id=&quot;其他&quot;&gt;其他&lt;/h2&gt;
&lt;ol readability=&quot;7.5&quot;&gt;&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;自己为了自己用写的软件，代码全部开源，你可以下载后直接修改作为自己喜欢的版本；&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;因使用本软件产生的问题，后果自负；&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;1&quot;&gt;
&lt;p&gt;本软件中用到了&lt;code&gt;PyQt&lt;/code&gt;,&lt;code&gt;exchangelib&lt;/code&gt;,需自觉遵守开源协议，禁止商用；&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;1&quot;&gt;
&lt;p&gt;自己的Win10上用的很好,可能不自动适配你的电脑屏幕，请自行修改，也希望能帮我改，可以一块合作。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;后续可能会添加&lt;code&gt;Launcher&lt;/code&gt;面板，可以放几个小工具。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;支持请发热心和好评，欢迎一起Debug.&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;1&quot;&gt;
&lt;p&gt;为了一些人的使用方便，添加了&lt;strong&gt;桌面快捷方式&lt;/strong&gt;,如果需要去除，请到系统文件夹内删除快捷方式即可。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;</description>
<pubDate>Thu, 21 Jan 2021 00:46:00 +0000</pubDate>
<dc:creator>云远·笨小孩</dc:creator>
<og:description>Inlook - Your personal assistant 中文版|English version Introduction Inlook是为在桌面上直观地提醒用户收到未读邮件和日程安排而开发的</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/charleechan/p/14306152.html</dc:identifier>
</item>
<item>
<title>定时任务应该这么玩 - 说故事的五公子</title>
<link>http://www.cnblogs.com/wugongzi/p/14306143.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/wugongzi/p/14306143.html</guid>
<description>&lt;h2 id=&quot;1场景&quot;&gt;1.场景&lt;/h2&gt;
&lt;p&gt;在电商系统中会经常遇到这样一种场景，就是商品的定时上下架功能，总不能每次都手动执行吧，这个时候我们首先想到的就是利用定时任务来实现这个功能。&lt;/p&gt;
&lt;p&gt;目前实现定时任务主要有以下几种方式：&lt;/p&gt;
&lt;ul readability=&quot;0.5&quot;&gt;&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;&lt;strong&gt;JDK自带&lt;/strong&gt; ：JDK自带的Timer以及JDK1.5+ 新增的ScheduledExecutorService；&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;&lt;strong&gt;第三方框架&lt;/strong&gt; ：使用 Quartz、elastic-job、xxl-job 等开源第三方定时任务框架，适合分布式项目应用。该方式的缺点是配置复杂。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;&lt;strong&gt;Spring&lt;/strong&gt; ：使用 Spring 提供的一个注解 &lt;code&gt;@Schedule&lt;/code&gt;，开发简单，使用比较方便。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;本文博主主要向大家介绍Quartz框架和Spring定时任务的使用。&lt;/p&gt;
&lt;h2 id=&quot;2什么是quartz&quot;&gt;2.什么是Quartz&lt;/h2&gt;
&lt;blockquote readability=&quot;12.871921182266&quot;&gt;
&lt;p&gt;Quartz 是一个完全由 Java 编写的开源作业调度框架，为在 Java 应用程序中进行作业调度提供了简单却强大的机制。&lt;/p&gt;
&lt;p&gt;Quartz 可以与 &lt;a href=&quot;https://www.w3cschool.cn/java_interview_question/java_interview_question-wvr326ra.html&quot; target=&quot;_blank&quot;&gt;J2EE&lt;/a&gt; 与 J2SE 应用程序相结合也可以单独使用。&lt;/p&gt;
&lt;p&gt;Quartz 允许程序开发人员根据时间的间隔来调度作业。&lt;/p&gt;
&lt;p&gt;Quartz 实现了作业和触发器的多对多的关系，还能把多个作业与不同的触发器关联。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;3quartz几个核心概念&quot;&gt;3.Quartz几个核心概念&lt;/h2&gt;
&lt;p&gt;在正式学习使用Quartz之前，我们需要了解几个有关Quartz的核心概念，方便我们后面学习&lt;/p&gt;
&lt;ol readability=&quot;3.5&quot;&gt;&lt;li readability=&quot;2&quot;&gt;
&lt;p&gt;&lt;strong&gt;Job&lt;/strong&gt; 表示一个工作，要执行的具体内容。此接口中只有一个方法，如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;void execute(JobExecutionContext context) 
// context是重要的上下文，可以访问到关联的JobDetail对象和本次触发的Trigger对象，以及在此之上设定的数据。
&lt;/code&gt;
&lt;/pre&gt;&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;&lt;strong&gt;JobDetail&lt;/strong&gt; 表示一个具体的可执行的调度程序，Job 是这个可执行程调度程序所要执行的内容，另外 JobDetail 还包含了这个任务调度的方案和策略。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;&lt;strong&gt;Trigger&lt;/strong&gt; 代表一个调度参数的配置，什么时候去调。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;&lt;strong&gt;Scheduler&lt;/strong&gt; 代表一个调度容器，一个调度容器中可以注册多个 JobDetail 和 Trigger。当 Trigger 与 JobDetail 组合，就可以被 Scheduler 容器调度了。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;&lt;h2 id=&quot;4quartz初体验&quot;&gt;4.Quartz初体验&lt;/h2&gt;
&lt;p&gt;一、创建一个SpringBoot项目，pom.xml配置如下&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-xml&quot;&gt;&amp;lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&amp;gt;
&amp;lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot;
         xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;
         xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&amp;gt;
    &amp;lt;modelVersion&amp;gt;4.0.0&amp;lt;/modelVersion&amp;gt;

    &amp;lt;groupId&amp;gt;com.songguoliang&amp;lt;/groupId&amp;gt;
    &amp;lt;artifactId&amp;gt;spring-boot-quartz&amp;lt;/artifactId&amp;gt;
    &amp;lt;version&amp;gt;1.0-SNAPSHOT&amp;lt;/version&amp;gt;

    &amp;lt;name&amp;gt;spring-boot-quartz&amp;lt;/name&amp;gt;
    &amp;lt;description&amp;gt;Spring Boot使用Quartz定时任务&amp;lt;/description&amp;gt;

    &amp;lt;!-- Spring Boot启动器父类 --&amp;gt;
    &amp;lt;parent&amp;gt;
        &amp;lt;groupId&amp;gt;org.springframework.boot&amp;lt;/groupId&amp;gt;
        &amp;lt;artifactId&amp;gt;spring-boot-starter-parent&amp;lt;/artifactId&amp;gt;
        &amp;lt;version&amp;gt;2.0.1.RELEASE&amp;lt;/version&amp;gt;
        &amp;lt;relativePath/&amp;gt; &amp;lt;!-- lookup parent from repository --&amp;gt;
    &amp;lt;/parent&amp;gt;

    &amp;lt;properties&amp;gt;
        &amp;lt;project.build.sourceEncoding&amp;gt;UTF-8&amp;lt;/project.build.sourceEncoding&amp;gt;
        &amp;lt;project.reporting.outputEncoding&amp;gt;UTF-8&amp;lt;/project.reporting.outputEncoding&amp;gt;
        &amp;lt;java.version&amp;gt;1.8&amp;lt;/java.version&amp;gt;
    &amp;lt;/properties&amp;gt;

    &amp;lt;dependencies&amp;gt;
        &amp;lt;!-- Spring Boot web启动器 --&amp;gt;
        &amp;lt;dependency&amp;gt;
            &amp;lt;groupId&amp;gt;org.springframework.boot&amp;lt;/groupId&amp;gt;
            &amp;lt;artifactId&amp;gt;spring-boot-starter-web&amp;lt;/artifactId&amp;gt;
        &amp;lt;/dependency&amp;gt;
        &amp;lt;!-- quartz --&amp;gt;
        &amp;lt;dependency&amp;gt;
            &amp;lt;groupId&amp;gt;org.springframework.boot&amp;lt;/groupId&amp;gt;
            &amp;lt;artifactId&amp;gt;spring-boot-starter-quartz&amp;lt;/artifactId&amp;gt;
        &amp;lt;/dependency&amp;gt;

    &amp;lt;/dependencies&amp;gt;

    &amp;lt;build&amp;gt;
        &amp;lt;plugins&amp;gt;
            &amp;lt;plugin&amp;gt;
                &amp;lt;groupId&amp;gt;org.springframework.boot&amp;lt;/groupId&amp;gt;
                &amp;lt;artifactId&amp;gt;spring-boot-maven-plugin&amp;lt;/artifactId&amp;gt;
            &amp;lt;/plugin&amp;gt;
        &amp;lt;/plugins&amp;gt;
    &amp;lt;/build&amp;gt;
&amp;lt;/project&amp;gt;
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;二、创建一个Job（Job里面是要执行的具体内容）&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;package com.example.quartz;

import org.quartz.Job;
import org.quartz.JobExecutionContext;
import org.quartz.JobExecutionException;
import org.quartz.SchedulerException;

import java.time.LocalDateTime;

public class TestJob implements Job {

    @Override
    public void execute(JobExecutionContext context) throws JobExecutionException {
        // 通过context获取trigger中的数据
        Object tv1 = context.getTrigger().getJobDataMap().get(&quot;t1&quot;);
        Object tv2 = context.getTrigger().getJobDataMap().get(&quot;t2&quot;);
        // 通过context获取JobDetail中的数据
        Object jv1 = context.getJobDetail().getJobDataMap().get(&quot;j1&quot;);
        Object jv2 = context.getJobDetail().getJobDataMap().get(&quot;j2&quot;);
        Object sv = null;
        try {
            sv = context.getScheduler().getContext().get(&quot;skey&quot;);
        } catch (SchedulerException e) {
            e.printStackTrace();
        }
        System.out.println(tv1+&quot;:&quot;+tv2);
        System.out.println(jv1+&quot;:&quot;+jv2);
        System.out.println(sv);
        System.out.println(&quot;date:&quot;+ LocalDateTime.now());
    }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;三、执行Job&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;package com.example.quartz;

import org.quartz.*;
import org.quartz.impl.StdSchedulerFactory;

public class QuartzTest {
    public static void main(String[] args)  {
        try {
            //创建一个scheduler
            Scheduler scheduler = StdSchedulerFactory.getDefaultScheduler();
            //向scheduler中put值
            scheduler.getContext().put(&quot;skey&quot;, &quot;svalue&quot;);

            //创建一个Trigger
            Trigger trigger = TriggerBuilder.newTrigger()
                    //给该Trigger起一个id
                    .withIdentity(&quot;trigger1&quot;)
                    //以Key-Value形式关联数据
                    .usingJobData(&quot;t1&quot;, &quot;tv1&quot;)
                    //每3秒触发一次，无限循环
                    .withSchedule(SimpleScheduleBuilder.simpleSchedule().withIntervalInSeconds(3)
                            .repeatForever()).build();
            trigger.getJobDataMap().put(&quot;t2&quot;,&quot;tv2&quot;);

            //创建一个JobDetail
            JobDetail jobDetail = JobBuilder.newJob(TestJob.class)
                    //给该JobDetail起一个id
                    .withIdentity(&quot;myJob&quot;, &quot;myGroup&quot;)
                    .usingJobData(&quot;j1&quot;, &quot;jv1&quot;)
                    .build();
            jobDetail.getJobDataMap().put(&quot;j2&quot;, &quot;jv2&quot;);

            //注册trigger并启动scheduler
            scheduler.scheduleJob(jobDetail, trigger);
            scheduler.start();
            //如果想要停止这个Job，可以调用shutdown方法
            //scheduler.shutdown();

        } catch (SchedulerException e) {
            e.printStackTrace();
        }
    }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;控制台输出&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;10:46:54.075 [main] INFO org.quartz.impl.StdSchedulerFactory - Using default implementation for ThreadExecutor
10:46:54.079 [main] INFO org.quartz.simpl.SimpleThreadPool - Job execution threads will use class loader of thread: main
10:46:54.089 [main] INFO org.quartz.core.SchedulerSignalerImpl - Initialized Scheduler Signaller of type: class org.quartz.core.SchedulerSignalerImpl
10:46:54.089 [main] INFO org.quartz.core.QuartzScheduler - Quartz Scheduler v.2.3.2 created.
10:46:54.090 [main] INFO org.quartz.simpl.RAMJobStore - RAMJobStore initialized.
10:46:54.091 [main] INFO org.quartz.core.QuartzScheduler - Scheduler meta-data: Quartz Scheduler (v2.3.2) 'DefaultQuartzScheduler' with instanceId 'NON_CLUSTERED'
  Scheduler class: 'org.quartz.core.QuartzScheduler' - running locally.
  NOT STARTED.
  Currently in standby mode.
  Number of jobs executed: 0
  Using thread pool 'org.quartz.simpl.SimpleThreadPool' - with 10 threads.
  Using job-store 'org.quartz.simpl.RAMJobStore' - which does not support persistence. and is not clustered.

10:46:54.091 [main] INFO org.quartz.impl.StdSchedulerFactory - Quartz scheduler 'DefaultQuartzScheduler' initialized from default resource file in Quartz package: 'quartz.properties'
10:46:54.091 [main] INFO org.quartz.impl.StdSchedulerFactory - Quartz scheduler version: 2.3.2
10:46:54.104 [main] INFO org.quartz.core.QuartzScheduler - Scheduler DefaultQuartzScheduler_$_NON_CLUSTERED started.
10:46:54.104 [DefaultQuartzScheduler_QuartzSchedulerThread] DEBUG org.quartz.core.QuartzSchedulerThread - batch acquisition of 1 triggers
10:46:54.106 [DefaultQuartzScheduler_QuartzSchedulerThread] DEBUG org.quartz.simpl.PropertySettingJobFactory - Producing instance of Job 'myGroup.myJob', class=com.example.quartz.TestJob
10:46:54.110 [DefaultQuartzScheduler_QuartzSchedulerThread] DEBUG org.quartz.core.QuartzSchedulerThread - batch acquisition of 1 triggers
10:46:54.110 [DefaultQuartzScheduler_Worker-1] DEBUG org.quartz.core.JobRunShell - Calling execute on job myGroup.myJob
tv1:tv2
jv1:jv2
svalue
date:2020-12-19T10:46:54.144
10:46:57.092 [DefaultQuartzScheduler_QuartzSchedulerThread] DEBUG org.quartz.simpl.PropertySettingJobFactory - Producing instance of Job 'myGroup.myJob', class=com.example.quartz.TestJob
10:46:57.092 [DefaultQuartzScheduler_QuartzSchedulerThread] DEBUG org.quartz.core.QuartzSchedulerThread - batch acquisition of 1 triggers
10:46:57.092 [DefaultQuartzScheduler_Worker-2] DEBUG org.quartz.core.JobRunShell - Calling execute on job myGroup.myJob
tv1:tv2
jv1:jv2
svalue
date:2020-12-19T10:46:57.092
10:47:00.101 [DefaultQuartzScheduler_QuartzSchedulerThread] DEBUG org.quartz.simpl.PropertySettingJobFactory - Producing instance of Job 'myGroup.myJob', class=com.example.quartz.TestJob
10:47:00.101 [DefaultQuartzScheduler_QuartzSchedulerThread] DEBUG org.quartz.core.QuartzSchedulerThread - batch acquisition of 1 triggers
10:47:00.101 [DefaultQuartzScheduler_Worker-3] DEBUG org.quartz.core.JobRunShell - Calling execute on job myGroup.myJob
tv1:tv2
jv1:jv2
svalue
date:2020-12-19T10:47:00.101
10:47:03.096 [DefaultQuartzScheduler_QuartzSchedulerThread] DEBUG org.quartz.simpl.PropertySettingJobFactory - Producing instance of Job 'myGroup.myJob', class=com.example.quartz.TestJob
10:47:03.096 [DefaultQuartzScheduler_QuartzSchedulerThread] DEBUG org.quartz.core.QuartzSchedulerThread - batch acquisition of 1 triggers
10:47:03.096 [DefaultQuartzScheduler_Worker-4] DEBUG org.quartz.core.JobRunShell - Calling execute on job myGroup.myJob
tv1:tv2
jv1:jv2
svalue
date:2020-12-19T10:47:03.096

&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;从输出结果我们可以看到此Job每隔3秒执行一次&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;有关概念&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;1、Job&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;job的一个 trigger 被触发后（稍后会讲到），execute() 方法会被 scheduler 的一个工作线程调用；传递给 execute() 方法的 JobExecutionContext 对象中保存着该 job 运行时的一些信息 ，执行 job 的 scheduler 的引用，触发 job 的 trigger 的引用，JobDetail 对象引用，以及一些其它信息。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2、JobDetail&lt;/strong&gt; ：&lt;/p&gt;
&lt;p&gt;JobDetail 对象是在将 job 加入 scheduler 时，由客户端程序（你的程序）创建的。它包含 job 的各种属性设置，以及用于存储 job 实例状态信息的 JobDataMap&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;3、Trigger&lt;/strong&gt;：&lt;/p&gt;
&lt;p&gt;Trigger 用于触发 Job 的执行。当你准备调度一个 job 时，你创建一个 Trigger 的实例，然后设置调度相关的属性。Trigger 也有一个相关联的 JobDataMap，用于给 Job 传递一些触发相关的参数。Quartz 自带了各种不同类型的 Trigger，最常用的主要是 SimpleTrigger 和 CronTrigger。SimpleTrigger 主要用于一次性执行的 Job（只在某个特定的时间点执行一次），或者 Job 在特定的时间点执行，重复执行 N 次，每次执行间隔T个时间单位。CronTrigger 在基于日历的调度上非常有用，如“每个星期五的正午”，或者“每月的第十天的上午 10:15”等。&lt;/p&gt;
&lt;h2 id=&quot;5jobdetail详解&quot;&gt;5.JobDetail详解&lt;/h2&gt;
&lt;p&gt;在定义一个Job时，我们需要实现Job接口，该接口只有一个&lt;code&gt;execute&lt;/code&gt;方法。&lt;/p&gt;
&lt;p&gt;从上一节的案例中我们可以发现，我们通过Scheduler去执行Job，我们传给scheduler一个JobDetail实例，因为我们在创建JobDetail时，将要执行的job的类名传给了JobDetail，所以scheduler就知道了要执行何种类型的job。（这里利用了Java中的反射创建实例对象）每次当scheduler执行job时，在调用其execute(…)方法之前会创建该类的一个新的实例；执行完毕，对该实例的引用就被丢弃了，实例会被垃圾回收；这种执行策略带来的一个后果是，job必须有一个无参的构造函数（当使用默认的JobFactory时）；另一个后果是，在job类中，不应该定义有状态的数据属性，因为在job的多次执行中，这些属性的值不会保留。&lt;/p&gt;
&lt;p&gt;那么我们该如何给Job配置相关属性呢？答案就是通过JobDetail&lt;/p&gt;
&lt;h3 id=&quot;jobdatamap&quot;&gt;JobDataMap&lt;/h3&gt;
&lt;p&gt;JobDataMap实现了Map接口，可以存放键值对数据，在Job执行的时候，我们就可以通过JobExecutionContext获取到JobDataMap中的数据，如下&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;JobDetail jobDetail = JobBuilder.newJob(TestJob.class)
                    .withIdentity(&quot;myJob&quot;, &quot;myGroup&quot;)
                    .usingJobData(&quot;j1&quot;, &quot;jv1&quot;)
                    .usingJobData(&quot;j2&quot;,&quot;jv2&quot;)
                    .build();
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;在job的执行过程中，可以从JobDataMap中取出数据，如下示例：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;Object jv1 = context.getJobDetail().getJobDataMap().get(&quot;j1&quot;);
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;当然，如果你希望实现属性的自动注入，那么你可以使用下面的方法&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;package com.example.quartz;

import org.quartz.*;
import org.quartz.impl.StdSchedulerFactory;

public class QuartzTest2 {
    public static void main(String[] args)  {
        try {

            Scheduler scheduler = StdSchedulerFactory.getDefaultScheduler();

            Trigger trigger = TriggerBuilder.newTrigger()
                    .withIdentity(&quot;trigger1&quot;)
                    .usingJobData(&quot;t1&quot;, &quot;tv1&quot;)
                    .withSchedule(SimpleScheduleBuilder.simpleSchedule().withIntervalInSeconds(3)
                            .repeatForever())
                    .build();

            JobDetail jobDetail = JobBuilder.newJob(TestJob2.class)
                    .withIdentity(&quot;jd&quot;)
                    .usingJobData(&quot;name&quot;, &quot;张三&quot;)
                    .usingJobData(&quot;age&quot;, 12)
                    .build();

            scheduler.scheduleJob(jobDetail, trigger);
            scheduler.start();

        } catch (SchedulerException e) {
            e.printStackTrace();
        }
    }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;package com.example.quartz;

import org.quartz.*;

public class TestJob2 implements Job {

    private String name;
    private Integer age;

    public String getName() {
        return name;
    }

    public void setName(String name) {
        this.name = name;
    }

    public Integer getAge() {
        return age;
    }

    public void setAge(Integer age) {
        this.age = age;
    }

    @Override
    public void execute(JobExecutionContext context) throws JobExecutionException {
        JobKey jobKey = context.getJobDetail().getKey();

        JobDataMap jobDataMap = context.getJobDetail().getJobDataMap();

        System.out.println(&quot;name:&quot; + name + &quot;age:&quot; +age);
    }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;给Job类加上get和set方法（属性名称要和JobDataMap中的key相同），那么JobDataMap中的值就是自动注入到Job中，不需要手动获取&lt;/p&gt;
&lt;h2 id=&quot;6triggers详解&quot;&gt;6.Triggers详解&lt;/h2&gt;
&lt;p&gt;Trigger 用于触发 Job 的执行。当你准备调度一个 job 时，你创建一个 Trigger 的实例，然后设置调度相关的属性。所有类型的trigger都有TriggerKey这个属性，表示trigger的身份；除此之外，trigger还有很多其它的公共属性。这些属性，在构建trigger的时候可以通过TriggerBuilder设置。&lt;/p&gt;
&lt;h3 id=&quot;triggers公共属性&quot;&gt;triggers公共属性&lt;/h3&gt;
&lt;ul&gt;&lt;li&gt;jobKey属性：当trigger触发时被执行的job的身份；&lt;/li&gt;
&lt;li&gt;startTime属性：设置trigger第一次触发的时间；该属性的值是java.util.Date类型，表示某个指定的时间点；有些类型的trigger，会在设置的startTime时立即触发，有些类型的trigger，表示其触发是在startTime之后开始生效。比如，现在是1月份，你设置了一个trigger–“在每个月的第5天执行”，然后你将startTime属性设置为4月1号，则该trigger第一次触发会是在几个月以后了(即4月5号)。&lt;/li&gt;
&lt;li&gt;endTime属性：表示trigger失效的时间点。比如，”每月第5天执行”的trigger，如果其endTime是7月1号，则其最后一次执行时间是6月5号。&lt;/li&gt;
&lt;/ul&gt;&lt;h3 id=&quot;优先级priority&quot;&gt;优先级(priority)&lt;/h3&gt;
&lt;p&gt;如果你的trigger很多(或者Quartz线程池的工作线程太少)，Quartz可能没有足够的资源同时触发所有的trigger；这种情况下，你可能希望控制哪些trigger优先使用Quartz的工作线程，要达到该目的，可以在trigger上设置priority属性。比如，你有N个trigger需要同时触发，但只有Z个工作线程，优先级最高的Z个trigger会被首先触发。如果没有为trigger设置优先级，trigger使用默认优先级，值为5；priority属性的值可以是任意整数，正数、负数都可以。&lt;/p&gt;
&lt;p&gt;注意：只有同时触发的trigger之间才会比较优先级。10:59触发的trigger总是在11:00触发的trigger之前执行。&lt;/p&gt;
&lt;p&gt;注意：如果trigger是可恢复的，在恢复后再调度时，优先级与原trigger是一样的。&lt;/p&gt;
&lt;h3 id=&quot;错过触发misfire-instructions&quot;&gt;错过触发(misfire Instructions)&lt;/h3&gt;
&lt;p&gt;trigger还有一个重要的属性misfire；如果scheduler关闭了，或者Quartz线程池中没有可用的线程来执行job，此时持久性的trigger就会错过(miss)其触发时间，即错过触发(misfire)。不同类型的trigger，有不同的misfire机制。它们默认都使用“智能机制(smart policy)”，即根据trigger的类型和配置动态调整行为&lt;/p&gt;
&lt;h3 id=&quot;simple-trigger&quot;&gt;Simple Trigger&lt;/h3&gt;
&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;SimpleTrigger简单点说，就是在具体的时间点执行一次，或者在具体的时间点执行，并且以指定的间隔重复执行若干次。类似于闹钟，你定了一个周末早晨7点的闹钟，这个闹钟会在周末早上7点准时响起。闹钟还有个功能就是过5分钟之后再响一次，这对应着指定的间隔重复执行若干次。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;1、指定时间开始触发，不重复：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;SimpleTrigger trigger = (SimpleTrigger) TriggerBuilder.newTrigger()
                    .withIdentity(&quot;st1&quot;, &quot;group1&quot;)
                    .startAt(new Date()) // 从当前时间开始执行一次，不重复
                    .build();
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;2、指定时间触发，每隔2秒执行一次，重复5次：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;SimpleTrigger trigger = (SimpleTrigger) TriggerBuilder.newTrigger()
        .withIdentity(&quot;st2&quot;, &quot;group1&quot;)
        .startAt(new Date())
        .withSchedule(SimpleScheduleBuilder.simpleSchedule()
                .withIntervalInSeconds(2) // 2秒
                .withRepeatCount(5)// 5次
        )
        .build();
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;3、1分钟以后开始触发，仅执行一次：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;long time = 1 * 60 * 1000;
Date now = new Date();
SimpleTrigger trigger = (SimpleTrigger) TriggerBuilder.newTrigger()
        .withIdentity(&quot;st3&quot;, &quot;group1&quot;)
        .startAt(new Date(now.getTime() + time))
        .build();
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;4、立即触发，每隔2秒钟执行一次，直到2020-12-19 13:20:00&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;String dateStr=&quot;2020-12-19 13:20:00&quot;;
String pattern=&quot;yyyy-MM-dd HH:mm:ss&quot;;
SimpleDateFormat dateFormat=new SimpleDateFormat(pattern);
Date date = dateFormat.parse(dateStr);
SimpleTrigger trigger = (SimpleTrigger) TriggerBuilder.newTrigger()
        .withIdentity(&quot;st4&quot;, &quot;group1&quot;)
        .withSchedule(SimpleScheduleBuilder.simpleSchedule()
        .withIntervalInSeconds(2)
        .repeatForever())
        .endAt(date)
        .build();
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;5、在13:00触发，然后每2小时重复一次：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;String dateStr=&quot;2020-12-19 13:00:00&quot;;
String pattern=&quot;yyyy-MM-dd HH:mm:ss&quot;;
SimpleDateFormat dateFormat=new SimpleDateFormat(pattern);
Date date = dateFormat.parse(dateStr);
SimpleTrigger trigger = (SimpleTrigger) TriggerBuilder.newTrigger()
        .withIdentity(&quot;st2&quot;, &quot;group1&quot;)
        .withSchedule(SimpleScheduleBuilder.simpleSchedule()
        .withIntervalInHours(2)
        .repeatForever())
        .build();
&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;simpletrigger--misfire&quot;&gt;SimpleTrigger Misfire&lt;/h3&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;misfire：被错过的执行任务策略&lt;/p&gt;
&lt;/blockquote&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;SimpleTrigger trigger = (SimpleTrigger) TriggerBuilder.newTrigger()
        .withIdentity(&quot;st6&quot;)
        .withSchedule(
                SimpleScheduleBuilder.simpleSchedule()
                        .withIntervalInMinutes(5)
                        .repeatForever()
                        .withMisfireHandlingInstructionNextWithExistingCount()
        )
        .build();
&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;crontrigger&quot;&gt;CronTrigger&lt;/h3&gt;
&lt;blockquote readability=&quot;7&quot;&gt;
&lt;p&gt;CronTrigger通常比Simple Trigger更有用，如果你需要在指定日期执行某项任务，使用CronTrigger就非常方便，比如如果你想在每月的15号给会员发放优惠券，或者每周五中午12点统计用户本周使用产品时长。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;code&gt;cron&lt;/code&gt; 表达式是一个字符串，该字符串由 6 个空格分为 7 个域，每一个域代表一个时间含义。 通常定义 “年” 的部分可以省略，实际常用的 Cron 表达式由前 6 部分组成。格式如下&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt; [秒] [分] [时] [日] [月] [周] [年]
 Seconds  Minutes  Hours   Day-of-Month  Month   Day-of-Week    Year (optional field)
&lt;/code&gt;
&lt;/pre&gt;
&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;域&lt;/th&gt;
&lt;th&gt;是否必填&lt;/th&gt;
&lt;th&gt;值以及范围&lt;/th&gt;
&lt;th&gt;通配符&lt;/th&gt;
&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;秒&lt;/td&gt;
&lt;td&gt;是&lt;/td&gt;
&lt;td&gt;0-59&lt;/td&gt;
&lt;td&gt;, - * /&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;分&lt;/td&gt;
&lt;td&gt;是&lt;/td&gt;
&lt;td&gt;0-59&lt;/td&gt;
&lt;td&gt;, - * /&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;时&lt;/td&gt;
&lt;td&gt;是&lt;/td&gt;
&lt;td&gt;0-23&lt;/td&gt;
&lt;td&gt;, - * /&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;日&lt;/td&gt;
&lt;td&gt;是&lt;/td&gt;
&lt;td&gt;1-31&lt;/td&gt;
&lt;td&gt;, - * ? / L W&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;月&lt;/td&gt;
&lt;td&gt;是&lt;/td&gt;
&lt;td&gt;1-12 或 JAN-DEC&lt;/td&gt;
&lt;td&gt;, - * /&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;周&lt;/td&gt;
&lt;td&gt;是&lt;/td&gt;
&lt;td&gt;1-7 或 SUN-SAT&lt;/td&gt;
&lt;td&gt;, - * ? / L #&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;年&lt;/td&gt;
&lt;td&gt;否&lt;/td&gt;
&lt;td&gt;1970-2099&lt;/td&gt;
&lt;td&gt;, - * /&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;需要说明的是，Cron 表达式中，“周” 是从周日开始计算的。“周” 域上的 &lt;code&gt;1&lt;/code&gt; 表示的是周日，&lt;code&gt;7&lt;/code&gt; 表示周六。&lt;/p&gt;
&lt;blockquote readability=&quot;16&quot;&gt;
&lt;p&gt;每天晚上12点触发任务：&lt;code&gt;0 0 0 * * ?&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;每隔 1 分钟执行一次：&lt;code&gt;0 */1 * * * ?&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;每月 1 号凌晨 1 点执行一次：&lt;code&gt;0 0 1 1 * ?&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;每月最后一天 23 点执行一次：&lt;code&gt;0 0 23 L * ?&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;每周周六凌晨 3 点实行一次：&lt;code&gt;0 0 3 ? * L&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;在24分，30分执行一次：&lt;code&gt;0 24,30 * * * ?&lt;/code&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;是不是有点没看懂，没关系，我们可以使用&lt;a href=&quot;https://www.bejson.com/othertools/cron&quot; target=&quot;_blank&quot;&gt;Cron表达式生成器&lt;/a&gt;帮助我们生成Cron表达式&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;SimpleTrigger trigger = (SimpleTrigger) TriggerBuilder.newTrigger()
        .withSchedule(CronScheduleBuilder.cronSchedule(&quot;0 0/2 8-17 * * ?&quot;))
        .build();
&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;7schedule实现定时任务&quot;&gt;7.@Schedule实现定时任务&lt;/h2&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;很多时候我们都需要为系统建立一个定时任务来帮我们做一些事情，SpringBoot 已经帮我们实现好了一个，我们只需要直接使用即可&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;一、引入依赖&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-xml&quot;&gt;&amp;lt;dependencies&amp;gt;

 &amp;lt;dependency&amp;gt;
   &amp;lt;groupId&amp;gt;org.springframework.boot&amp;lt;/groupId&amp;gt;
   &amp;lt;artifactId&amp;gt;spring-boot-starter-web&amp;lt;/artifactId&amp;gt;
 &amp;lt;/dependency&amp;gt;

 &amp;lt;dependency&amp;gt;
   &amp;lt;groupId&amp;gt;org.springframework.boot&amp;lt;/groupId&amp;gt;
   &amp;lt;artifactId&amp;gt;spring-boot-starter&amp;lt;/artifactId&amp;gt;
 &amp;lt;/dependency&amp;gt;

 &amp;lt;dependency&amp;gt;
   &amp;lt;groupId&amp;gt;org.projectlombok&amp;lt;/groupId&amp;gt;
   &amp;lt;artifactId&amp;gt;lombok&amp;lt;/artifactId&amp;gt;
   &amp;lt;optional&amp;gt;true&amp;lt;/optional&amp;gt;
 &amp;lt;/dependency&amp;gt;

 &amp;lt;dependency&amp;gt;
   &amp;lt;groupId&amp;gt;org.springframework.boot&amp;lt;/groupId&amp;gt;
   &amp;lt;artifactId&amp;gt;spring-boot-starter-test&amp;lt;/artifactId&amp;gt;
   &amp;lt;scope&amp;gt;test&amp;lt;/scope&amp;gt;
 &amp;lt;/dependency&amp;gt;

&amp;lt;/dependencies&amp;gt;
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;二、开启注解&lt;/p&gt;
&lt;p&gt;在 SpringBoot 中我们只需要在启动类上加上&lt;code&gt;@EnableScheduling&lt;/code&gt;便可以启动定时任务了。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;@SpringBootApplication
@EnableScheduling
public class TaskApplication {

    public static void main(String[] args) {
        SpringApplication.run(DemoApplication.class, args);
    }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;三、创建scheduled task&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import org.springframework.scheduling.annotation.Scheduled;
import org.springframework.stereotype.Component;

import java.text.SimpleDateFormat;
import java.util.Date;
import java.util.concurrent.TimeUnit;

/**
 * @author wugongzi
 */
@Component
public class ScheduledTasks {
    private static final Logger log = LoggerFactory.getLogger(ScheduledTasks.class);
    private static final SimpleDateFormat dateFormat = new SimpleDateFormat(&quot;HH:mm:ss&quot;);

    /**
     * fixedRate：固定速率执行。每5秒执行一次。
     */
    @Scheduled(fixedRate = 5000)
    public void reportCurrentTimeWithFixedRate() {
        log.info(&quot;Current Thread : {}&quot;, Thread.currentThread().getName());
        log.info(&quot;Fixed Rate Task : The time is now {}&quot;, dateFormat.format(new Date()));
    }

    /**
     * fixedDelay：固定延迟执行。距离上一次调用成功后2秒才执。
     */
    @Scheduled(fixedDelay = 2000)
    public void reportCurrentTimeWithFixedDelay() {
        try {
            TimeUnit.SECONDS.sleep(3);
            log.info(&quot;Fixed Delay Task : The time is now {}&quot;, dateFormat.format(new Date()));
        } catch (InterruptedException e) {
            e.printStackTrace();
        }
    }

    /**
     * initialDelay:初始延迟。任务的第一次执行将延迟5秒，然后将以5秒的固定间隔执行。
     */
    @Scheduled(initialDelay = 5000, fixedRate = 5000)
    public void reportCurrentTimeWithInitialDelay() {
        log.info(&quot;Fixed Rate Task with Initial Delay : The time is now {}&quot;, dateFormat.format(new Date()));
    }

    /**
     * cron：使用Cron表达式。　每分钟的1，2秒运行
     */
    @Scheduled(cron = &quot;1-2 * * * * ? &quot;)
    public void reportCurrentTimeWithCronExpression() {
        log.info(&quot;Cron Expression: The time is now {}&quot;, dateFormat.format(new Date()));
    }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;启动项目便可以看到效果。&lt;/p&gt;
</description>
<pubDate>Thu, 21 Jan 2021 00:39:00 +0000</pubDate>
<dc:creator>说故事的五公子</dc:creator>
<og:description>1.场景 在电商系统中会经常遇到这样一种场景，就是商品的定时上下架功能，总不能每次都手动执行吧，这个时候我们首先想到的就是利用定时任务来实现这个功能。 目前实现定时任务主要有以下几种方式： JDK自带</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/wugongzi/p/14306143.html</dc:identifier>
</item>
<item>
<title>【小菜学网络】交换机与MAC地址学习 - fasionchan</title>
<link>http://www.cnblogs.com/fasionchan/p/switch-mac-address-learning.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/fasionchan/p/switch-mac-address-learning.html</guid>
<description>&lt;p&gt;为了解决集线器工作效率低下的尴尬，我们需要设计一种更高级的网络设备。新设备根据以太网帧的目的 MAC 地址，将它精准地转发到正确端。&lt;/p&gt;&lt;div id=&quot;cnblogs_post_body&quot; readability=&quot;110.44351604278&quot;&gt;
&lt;p&gt;上一小节介绍了 &lt;strong&gt;集线器&lt;/strong&gt; ，一种工作于物理层的简单网络设备。由于集线器采用广播的方式中继、转发物理信号，传输效率受到极大制约。&lt;/p&gt;
&lt;h2 id=&quot;精准转发&quot;&gt;精准转发&lt;/h2&gt;
&lt;p&gt;为了解决集线器工作效率低下的尴尬，我们需要设计一种更高级的网络设备。新设备根据以太网帧的目的 &lt;em&gt;MAC&lt;/em&gt; 地址，将它精准地转发到正确端口：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://cdn.fasionchan.com/p/4f8cfcc7704f3a7e634bb37a8c4228ae3be83583.png#width=412px&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;注释：这里 &lt;strong&gt;端口&lt;/strong&gt; ( &lt;em&gt;port&lt;/em&gt; )指的是转发设备的插口，也可叫做网口。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;如上图，中间节点是转发设备，它在内部维护着一张主机 &lt;em&gt;MAC&lt;/em&gt; 地址与对应端口的映射表，现与 &lt;em&gt;3&lt;/em&gt; 台主机相连。这样一来， 当转发设备接到主机 &lt;em&gt;A&lt;/em&gt; 发给主机 &lt;em&gt;C&lt;/em&gt; 的数据后，根据目的 &lt;em&gt;MAC&lt;/em&gt; 地址搜索映射表，便可将数据准确地转发到对应的端口 &lt;em&gt;3&lt;/em&gt; 。&lt;/p&gt;
&lt;p&gt;现在，传输模式变得更有针对性了——数据帧被精准转发到正确的端口，其他端口不再收到多余的数据：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://cdn.fasionchan.com/p/3fe963220b2e39bb6dac958d4fc8035afb0a9192.png?x-oss-process=image/resize,w_340&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;不仅如此，主机 &lt;em&gt;A&lt;/em&gt; 与 &lt;em&gt;B&lt;/em&gt; 通讯的同时，其他计算机也可通讯，互不干扰。转发设备每个端口是一个独立的冲突域，带宽也是独立的。&lt;/p&gt;
&lt;p&gt;集线器的缺陷全部避免了！&lt;/p&gt;
&lt;h2 id=&quot;交换机&quot;&gt;交换机&lt;/h2&gt;
&lt;p&gt;能够根据以太网帧目的地址转发数据的网络设备就是 &lt;strong&gt;以太网交换机&lt;/strong&gt; ( &lt;em&gt;ethernet switch&lt;/em&gt; )：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://cdn.fasionchan.com/p/0ed02724a1ab5c184fd3106b12a6e6d699f99206.png?x-oss-process=image/resize,w_360&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;交换机长相跟集线器没啥区别嘛。当然了，大部分网络设备都是一个布满端口的盒子，关键在于内部构造。&lt;/p&gt;
&lt;p&gt;再看看现实中的交换机长啥样：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://cdn.fasionchan.com/p/19d5e5116be0582bfecb9c6b830a064aa6d9f99a.jpg?x-oss-process=image/resize,w_450&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;总结起来，以太网交换机属于 &lt;strong&gt;二层网络设备&lt;/strong&gt; ，特点如下：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;根据目的地址转发以太网帧；&lt;/li&gt;
&lt;li&gt;每个端口是独立冲突域；&lt;/li&gt;
&lt;li&gt;每个端口带宽独立；&lt;/li&gt;
&lt;/ul&gt;&lt;h2 id=&quot;mac地址学习&quot;&gt;Mac地址学习&lt;/h2&gt;
&lt;p&gt;交换机完美地解决集线器的缺点，但新问题又来了，映射表如何获得呢？&lt;/p&gt;
&lt;p&gt;最原始的方式是：维护一张静态映射表。当新设备接入，向映射表添加一条记录；当设备移除，从映射表删除对应记录。然而，纯手工操作方式多少有些烦躁。&lt;/p&gt;
&lt;p&gt;好在计算机领域可以实现各种花样的自动化——通过算法自动学习映射表。我们先来看看大致思路：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://cdn.fasionchan.com/p/0018212e4156ba3b03c50b8669d4e17702baad2d.png#width=372px&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;初始状态下，映射表是空的。现在，主机 &lt;em&gt;A&lt;/em&gt; 向 &lt;em&gt;B&lt;/em&gt; 发送一个数据帧 &lt;em&gt;FRAME1&lt;/em&gt; 。因为映射表中没有地址 &lt;em&gt;B&lt;/em&gt; 的记录，交换机便将数据帧广播到其他所有端口。&lt;/p&gt;
&lt;p&gt;由于交换机是从 &lt;code&gt;Fa0/1&lt;/code&gt; 端口收到数据帧的，便知道 &lt;em&gt;A&lt;/em&gt; 连接 &lt;code&gt;Fa0/1&lt;/code&gt; 端口，而数据帧的源地址就是 &lt;em&gt;A&lt;/em&gt; 的地址！此时，交换机可以将 &lt;em&gt;A&lt;/em&gt; 的地址和端口 &lt;code&gt;Fa0/1&lt;/code&gt; 作为一条记录加入映射表。交换机学习到 &lt;em&gt;A&lt;/em&gt; 的地址！&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://cdn.fasionchan.com/p/978d91349c17ca0c04a88d05bf5b2df9c089f521.png#width=372px&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;接着，主机 &lt;em&gt;B&lt;/em&gt; 向 &lt;em&gt;A&lt;/em&gt; 回复一个数据帧 &lt;em&gt;FRAME2&lt;/em&gt;  。由于映射表中已经存在地址 &lt;em&gt;A&lt;/em&gt; 的记录了，因此交换机将数据帧精准转发到端口 &lt;code&gt;Fa0/1&lt;/code&gt; 。同理，交换机学习到主机 &lt;em&gt;B&lt;/em&gt; 的地址。&lt;/p&gt;
&lt;p&gt;当主机 &lt;em&gt;C&lt;/em&gt; 开始发送数据时，交换机同样学到其地址，学习过程完成！&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://cdn.fasionchan.com/p/742e3a4ce47f0928da014869e33bc752db1bf7cb.png#width=372px&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;这就是 &lt;strong&gt;MAC地址自动学习&lt;/strong&gt; 的基本原理。&lt;/p&gt;
&lt;p&gt;【&lt;a href=&quot;https://fasionchan.com/network/&quot; target=&quot;_blank&quot;&gt;小菜学网络&lt;/a&gt;】系列文章首发于公众号【小菜学编程】，敬请关注：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://cdn.fasionchan.com/coding-fan-wechat-soso.png?x-oss-process=image/resize,w_359&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;/div&gt;</description>
<pubDate>Thu, 21 Jan 2021 00:36:00 +0000</pubDate>
<dc:creator>fasionchan</dc:creator>
<og:description>为了解决集线器工作效率低下的尴尬，我们需要设计一种更高级的网络设备。新设备根据以太网帧的目的 MAC 地址，将它精准地转发到正确端。</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/fasionchan/p/switch-mac-address-learning.html</dc:identifier>
</item>
<item>
<title>MyBatis初级实战之五：一对一关联查询 - 程序员欣宸</title>
<link>http://www.cnblogs.com/bolingcavalry/p/14306122.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/bolingcavalry/p/14306122.html</guid>
<description>&lt;h3 id=&quot;欢迎访问我的github&quot;&gt;欢迎访问我的GitHub&lt;/h3&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/zq2599/blog_demos&quot; target=&quot;_blank&quot;&gt;https://github.com/zq2599/blog_demos&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;内容：所有原创文章分类汇总及配套源码，涉及Java、Docker、Kubernetes、DevOPS等；&lt;/p&gt;
&lt;h3 id=&quot;本篇概览&quot;&gt;本篇概览&lt;/h3&gt;
&lt;ul&gt;&lt;li&gt;本文是《MyBatis初级实战》系列的第五篇，从多表获取数据是个常见的场景，一般有以下两种方式：&lt;/li&gt;
&lt;li&gt;联表查询：join操作，一次查询完成&lt;/li&gt;
&lt;li&gt;多次查询：用第一次查询的结果作为条件，再做查询（MyBatis中叫做嵌套查询）&lt;/li&gt;
&lt;li&gt;本篇的内容就是学习MyBatis对上述两种查询的支持，全文由以下章节组成：&lt;/li&gt;
&lt;/ul&gt;&lt;ol&gt;&lt;li&gt;准备数据；&lt;/li&gt;
&lt;li&gt;本次实战的java工程&lt;/li&gt;
&lt;li&gt;最简单的联表(两个表的数据保存在一个实体类的不同字段)；&lt;/li&gt;
&lt;li&gt;一对一联表查询(两个表的数据分别保存在不同实体类，假设是A和B，A是B的成员变量)&lt;/li&gt;
&lt;li&gt;一对一嵌套查询(两个表的数据分别保存在不同实体类，假设是A和B，A是B的成员变量)&lt;/li&gt;
&lt;/ol&gt;&lt;h3 id=&quot;源码下载&quot;&gt;源码下载&lt;/h3&gt;
&lt;ol&gt;&lt;li&gt;如果您不想编码，可以在GitHub下载所有源码，地址和链接信息如下表所示(&lt;a href=&quot;https://github.com/zq2599/blog_demos&quot; target=&quot;_blank&quot;&gt;https://github.com/zq2599/blog_demos&lt;/a&gt;)：&lt;/li&gt;
&lt;/ol&gt;&lt;ol start=&quot;2&quot;&gt;&lt;li&gt;这个git项目中有多个文件夹，本章的应用在&lt;span&gt;mybatis&lt;/span&gt;文件夹下，如下图红框所示：&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/485422/202101/485422-20210121082516339-304561694.png&quot; alt=&quot;在这里插入图片描述&quot; loading=&quot;lazy&quot;/&gt;&lt;br/&gt;3. mybatis是个父工程，里面有数个子工程，本篇的源码在&lt;span&gt;relatedoperation&lt;/span&gt;子工程中，如下图红框所示：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/485422/202101/485422-20210121082519889-1247316723.jpg&quot; alt=&quot;在这里插入图片描述&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h3 id=&quot;准备数据&quot;&gt;准备数据&lt;/h3&gt;
&lt;ol&gt;&lt;li&gt;本次实战，在名为mybatis的数据库中建立两个表(和前面几篇文章中的表结构一模一样)：user和log表；&lt;/li&gt;
&lt;li&gt;user表记录用户信息，非常简单，只有三个字段：主键、名称、年龄&lt;/li&gt;
&lt;li&gt;log表记录用户行为，四个字段：主键、用户id、行为描述、行为时间&lt;/li&gt;
&lt;li&gt;user和log的关系如下图：&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/485422/202101/485422-20210121082520138-74316177.jpg&quot; alt=&quot;在这里插入图片描述&quot; loading=&quot;lazy&quot;/&gt;&lt;br/&gt;5. 建表和添加数据的语句如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-sql&quot;&gt;use mybatis;

DROP TABLE IF EXISTS `user`;

CREATE TABLE `user` (
  `id` int(32) NOT NULL AUTO_INCREMENT,
  `name` varchar(32) NOT NULL,
  `age` int(32) NOT NULL,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB AUTO_INCREMENT=3 DEFAULT CHARSET=utf8;

DROP TABLE IF EXISTS `log`;

CREATE TABLE `log` (
  `id` int(32) NOT NULL AUTO_INCREMENT,
  `user_id` int(32),
  `action` varchar(255) NOT NULL,
  `create_time` datetime not null,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB AUTO_INCREMENT=3 DEFAULT CHARSET=utf8;

INSERT INTO mybatis.user (id, name, age) VALUES (3, 'tom', 11);

INSERT INTO mybatis.log (id, user_id, action, create_time) VALUES (3, 3, 'read book', '2020-08-07 08:18:16');
INSERT INTO mybatis.log (id, user_id, action, create_time) VALUES (4, 3, 'go to the cinema', '2020-09-02 20:00:00');
INSERT INTO mybatis.log (id, user_id, action, create_time) VALUES (5, 3, 'have a meal', '2020-10-05 12:03:36');
INSERT INTO mybatis.log (id, user_id, action, create_time) VALUES (6, 3, 'have a sleep', '2020-10-06 13:00:12');
INSERT INTO mybatis.log (id, user_id, action, create_time) VALUES (7, 3, 'write', '2020-10-08 09:21:11');
&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;本次实战的java工程&quot;&gt;本次实战的java工程&lt;/h3&gt;
&lt;ol&gt;&lt;li&gt;在父工程mybatis下新建子工程&lt;span&gt;relatedoperation&lt;/span&gt;，pom.xml如下：&lt;/li&gt;
&lt;/ol&gt;&lt;pre&gt;
&lt;code class=&quot;language-xml&quot;&gt;&amp;lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&amp;gt;
&amp;lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;
         xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&amp;gt;
    &amp;lt;modelVersion&amp;gt;4.0.0&amp;lt;/modelVersion&amp;gt;
    &amp;lt;parent&amp;gt;
        &amp;lt;groupId&amp;gt;com.bolingcavalry&amp;lt;/groupId&amp;gt;
        &amp;lt;artifactId&amp;gt;mybatis&amp;lt;/artifactId&amp;gt;
        &amp;lt;version&amp;gt;1.0-SNAPSHOT&amp;lt;/version&amp;gt;
        &amp;lt;relativePath&amp;gt;../pom.xml&amp;lt;/relativePath&amp;gt;
    &amp;lt;/parent&amp;gt;

    &amp;lt;groupId&amp;gt;com.bolingcavalry&amp;lt;/groupId&amp;gt;
    &amp;lt;artifactId&amp;gt;relatedoperation&amp;lt;/artifactId&amp;gt;
    &amp;lt;version&amp;gt;0.0.1-SNAPSHOT&amp;lt;/version&amp;gt;
    &amp;lt;name&amp;gt;relatedoperation&amp;lt;/name&amp;gt;
    &amp;lt;description&amp;gt;Demo project for Mybatis related operation in Spring Boot&amp;lt;/description&amp;gt;
    &amp;lt;properties&amp;gt;
        &amp;lt;java.version&amp;gt;1.8&amp;lt;/java.version&amp;gt;
    &amp;lt;/properties&amp;gt;
    &amp;lt;dependencies&amp;gt;
        &amp;lt;dependency&amp;gt;
            &amp;lt;groupId&amp;gt;org.projectlombok&amp;lt;/groupId&amp;gt;
            &amp;lt;artifactId&amp;gt;lombok&amp;lt;/artifactId&amp;gt;
        &amp;lt;/dependency&amp;gt;
        &amp;lt;dependency&amp;gt;
            &amp;lt;groupId&amp;gt;org.springframework.boot&amp;lt;/groupId&amp;gt;
            &amp;lt;artifactId&amp;gt;spring-boot-starter-web&amp;lt;/artifactId&amp;gt;
        &amp;lt;/dependency&amp;gt;
        &amp;lt;dependency&amp;gt;
            &amp;lt;groupId&amp;gt;org.mybatis.spring.boot&amp;lt;/groupId&amp;gt;
            &amp;lt;artifactId&amp;gt;mybatis-spring-boot-starter&amp;lt;/artifactId&amp;gt;
        &amp;lt;/dependency&amp;gt;
        &amp;lt;dependency&amp;gt;
            &amp;lt;groupId&amp;gt;mysql&amp;lt;/groupId&amp;gt;
            &amp;lt;artifactId&amp;gt;mysql-connector-java&amp;lt;/artifactId&amp;gt;
            &amp;lt;scope&amp;gt;runtime&amp;lt;/scope&amp;gt;
        &amp;lt;/dependency&amp;gt;
        &amp;lt;dependency&amp;gt;
            &amp;lt;groupId&amp;gt;org.springframework.boot&amp;lt;/groupId&amp;gt;
            &amp;lt;artifactId&amp;gt;spring-boot-starter-test&amp;lt;/artifactId&amp;gt;
            &amp;lt;scope&amp;gt;test&amp;lt;/scope&amp;gt;
        &amp;lt;/dependency&amp;gt;
        &amp;lt;dependency&amp;gt;
            &amp;lt;groupId&amp;gt;io.springfox&amp;lt;/groupId&amp;gt;
            &amp;lt;artifactId&amp;gt;springfox-swagger2&amp;lt;/artifactId&amp;gt;
        &amp;lt;/dependency&amp;gt;
        &amp;lt;!-- swagger-ui --&amp;gt;
        &amp;lt;dependency&amp;gt;
            &amp;lt;groupId&amp;gt;io.springfox&amp;lt;/groupId&amp;gt;
            &amp;lt;artifactId&amp;gt;springfox-swagger-ui&amp;lt;/artifactId&amp;gt;
        &amp;lt;/dependency&amp;gt;
        &amp;lt;dependency&amp;gt;
            &amp;lt;groupId&amp;gt;com.alibaba&amp;lt;/groupId&amp;gt;
            &amp;lt;artifactId&amp;gt;druid-spring-boot-starter&amp;lt;/artifactId&amp;gt;
        &amp;lt;/dependency&amp;gt;
        &amp;lt;dependency&amp;gt;
            &amp;lt;groupId&amp;gt;junit&amp;lt;/groupId&amp;gt;
            &amp;lt;artifactId&amp;gt;junit&amp;lt;/artifactId&amp;gt;
            &amp;lt;scope&amp;gt;test&amp;lt;/scope&amp;gt;
        &amp;lt;/dependency&amp;gt;
    &amp;lt;/dependencies&amp;gt;

    &amp;lt;build&amp;gt;
        &amp;lt;plugins&amp;gt;
            &amp;lt;plugin&amp;gt;
                &amp;lt;groupId&amp;gt;org.springframework.boot&amp;lt;/groupId&amp;gt;
                &amp;lt;artifactId&amp;gt;spring-boot-maven-plugin&amp;lt;/artifactId&amp;gt;
            &amp;lt;/plugin&amp;gt;
        &amp;lt;/plugins&amp;gt;
    &amp;lt;/build&amp;gt;
&amp;lt;/project&amp;gt;
&lt;/code&gt;
&lt;/pre&gt;
&lt;ol start=&quot;2&quot;&gt;&lt;li&gt;基本配置文件application.yml：&lt;/li&gt;
&lt;/ol&gt;&lt;pre&gt;
&lt;code class=&quot;language-yml&quot;&gt;server:
  port: 8080

spring:
  #1.JDBC数据源
  datasource:
    username: root
    password: 123456
    url: jdbc:mysql://192.168.50.43:3306/mybatis?useUnicode=true&amp;amp;characterEncoding=utf-8&amp;amp;useSSL=true&amp;amp;serverTimezone=UTC
    driver-class-name: com.mysql.cj.jdbc.Driver
    #2.连接池配置
    druid:
      #初始化连接池的连接数量 大小，最小，最大
      initial-size: 5
      min-idle: 5
      max-active: 20
      #配置获取连接等待超时的时间
      max-wait: 60000
      #配置间隔多久才进行一次检测，检测需要关闭的空闲连接，单位是毫秒
      time-between-eviction-runs-millis: 60000
      # 配置一个连接在池中最小生存的时间，单位是毫秒
      min-evictable-idle-time-millis: 30000
      # 配置一个连接在池中最大生存的时间，单位是毫秒
      max-evictable-idle-time-millis: 300000
      validation-query: SELECT 1 FROM user
      test-while-idle: true
      test-on-borrow: true
      test-on-return: false
      # 是否缓存preparedStatement，也就是PSCache  官方建议MySQL下建议关闭   个人建议如果想用SQL防火墙 建议打开
      pool-prepared-statements: true
      max-pool-prepared-statement-per-connection-size: 20
      # 配置监控统计拦截的filters，去掉后监控界面sql无法统计，'wall'用于防火墙
      filters: stat,wall,slf4j
      filter:
        stat:
          merge-sql: true
          slow-sql-millis: 5000
      #3.基础监控配置
      web-stat-filter:
        enabled: true
        url-pattern: /*
        #设置不统计哪些URL
        exclusions: &quot;*.js,*.gif,*.jpg,*.png,*.css,*.ico,/druid/*&quot;
        session-stat-enable: true
        session-stat-max-count: 100
      stat-view-servlet:
        enabled: true
        url-pattern: /druid/*
        reset-enable: true
        #设置监控页面的登录名和密码
        login-username: admin
        login-password: admin
        allow: 127.0.0.1
        #deny: 192.168.1.100

# mybatis配置
mybatis:
  # 配置文件所在位置
  config-location: classpath:mybatis-config.xml
  # 映射文件所在位置
  mapper-locations: classpath:mappers/*Mapper.xml

# 日志配置
logging:
  level:
    root: INFO
    com:
      bolingcavalry:
        relatedoperation:
          mapper: debug
&lt;/code&gt;
&lt;/pre&gt;
&lt;ol start=&quot;3&quot;&gt;&lt;li&gt;再准备名为&lt;span&gt;application-test.yml&lt;/span&gt;的配置文件，这是执行单元测试时用到的，和application.yml的不同之处是&lt;span&gt;spring.datasource.druid.web-stat-filter.enabled&lt;/span&gt;配置设置成&lt;span&gt;false&lt;/span&gt;；&lt;/li&gt;
&lt;li&gt;mybatis的配置文件mybatis-config.xml如下：&lt;/li&gt;
&lt;/ol&gt;&lt;pre&gt;
&lt;code class=&quot;language-xml&quot;&gt;&amp;lt;!DOCTYPE configuration
        PUBLIC &quot;-//mybatis.org//DTD Config 3.0//EN&quot;
        &quot;http://mybatis.org/dtd/mybatis-3-config.dtd&quot;&amp;gt;
&amp;lt;configuration&amp;gt;
    &amp;lt;typeAliases&amp;gt;
        &amp;lt;!-- 映射文件中的类不用写全路径了--&amp;gt;
        &amp;lt;package name=&quot;com.bolingcavalry.relatedoperation.entity&quot;/&amp;gt;
    &amp;lt;/typeAliases&amp;gt;
&amp;lt;/configuration&amp;gt;
&lt;/code&gt;
&lt;/pre&gt;
&lt;ol start=&quot;5&quot;&gt;&lt;li&gt;数据源配置类DruidConfig.java：&lt;/li&gt;
&lt;/ol&gt;&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;package com.bolingcavalry.relatedoperation;

import com.alibaba.druid.pool.DruidDataSource;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import org.springframework.beans.factory.annotation.Value;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;

@Configuration
public class DruidConfig {

    private static final Logger logger = LoggerFactory.getLogger(DruidConfig.class);

    @Value(&quot;${spring.datasource.url}&quot;)
    private String dbUrl;
    @Value(&quot;${spring.datasource.username}&quot;)
    private String username;
    @Value(&quot;${spring.datasource.password}&quot;)
    private String password;
    @Value(&quot;${spring.datasource.driver-class-name}&quot;)
    private String driverClassName;
    @Value(&quot;${spring.datasource.druid.initial-size}&quot;)
    private int initialSize;
    @Value(&quot;${spring.datasource.druid.max-active}&quot;)
    private int maxActive;
    @Value(&quot;${spring.datasource.druid.min-idle}&quot;)
    private int minIdle;
    @Value(&quot;${spring.datasource.druid.max-wait}&quot;)
    private int maxWait;
    @Value(&quot;${spring.datasource.druid.pool-prepared-statements}&quot;)
    private boolean poolPreparedStatements;
    @Value(&quot;${spring.datasource.druid.max-pool-prepared-statement-per-connection-size}&quot;)
    private int maxPoolPreparedStatementPerConnectionSize;
    @Value(&quot;${spring.datasource.druid.time-between-eviction-runs-millis}&quot;)
    private int timeBetweenEvictionRunsMillis;
    @Value(&quot;${spring.datasource.druid.min-evictable-idle-time-millis}&quot;)
    private int minEvictableIdleTimeMillis;
    @Value(&quot;${spring.datasource.druid.max-evictable-idle-time-millis}&quot;)
    private int maxEvictableIdleTimeMillis;
    @Value(&quot;${spring.datasource.druid.validation-query}&quot;)
    private String validationQuery;
    @Value(&quot;${spring.datasource.druid.test-while-idle}&quot;)
    private boolean testWhileIdle;
    @Value(&quot;${spring.datasource.druid.test-on-borrow}&quot;)
    private boolean testOnBorrow;
    @Value(&quot;${spring.datasource.druid.test-on-return}&quot;)
    private boolean testOnReturn;
    @Value(&quot;${spring.datasource.druid.filters}&quot;)
    private String filters;
    @Value(&quot;{spring.datasource.druid.connection-properties}&quot;)
    private String connectionProperties;

    /**
     * Druid 连接池配置
     */
    @Bean
    public DruidDataSource dataSource() {
        DruidDataSource datasource = new DruidDataSource();
        datasource.setUrl(dbUrl);
        datasource.setUsername(username);
        datasource.setPassword(password);
        datasource.setDriverClassName(driverClassName);
        datasource.setInitialSize(initialSize);
        datasource.setMinIdle(minIdle);
        datasource.setMaxActive(maxActive);
        datasource.setMaxWait(maxWait);
        datasource.setTimeBetweenEvictionRunsMillis(timeBetweenEvictionRunsMillis);
        datasource.setMinEvictableIdleTimeMillis(minEvictableIdleTimeMillis);
        datasource.setMaxEvictableIdleTimeMillis(minEvictableIdleTimeMillis);
        datasource.setValidationQuery(validationQuery);
        datasource.setTestWhileIdle(testWhileIdle);
        datasource.setTestOnBorrow(testOnBorrow);
        datasource.setTestOnReturn(testOnReturn);
        datasource.setPoolPreparedStatements(poolPreparedStatements);
        datasource.setMaxPoolPreparedStatementPerConnectionSize(maxPoolPreparedStatementPerConnectionSize);
        try {
            datasource.setFilters(filters);
        } catch (Exception e) {
            logger.error(&quot;druid configuration initialization filter&quot;, e);
        }
        datasource.setConnectionProperties(connectionProperties);
        return datasource;
    }

}
&lt;/code&gt;
&lt;/pre&gt;
&lt;ol start=&quot;6&quot;&gt;&lt;li&gt;swagger配置类：&lt;/li&gt;
&lt;/ol&gt;&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;package com.bolingcavalry.relatedoperation;

import springfox.documentation.service.Contact;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import springfox.documentation.builders.ApiInfoBuilder;
import springfox.documentation.builders.PathSelectors;
import springfox.documentation.builders.RequestHandlerSelectors;
import springfox.documentation.service.ApiInfo;
import springfox.documentation.service.Tag;
import springfox.documentation.spi.DocumentationType;
import springfox.documentation.spring.web.plugins.Docket;
import springfox.documentation.swagger2.annotations.EnableSwagger2;

@Configuration
@EnableSwagger2
public class SwaggerConfig {

    @Bean
    public Docket createRestApi() {
        return new Docket(DocumentationType.SWAGGER_2)
                .apiInfo(apiInfo())
                .tags(new Tag(&quot;UserController&quot;, &quot;用户服务&quot;), new Tag(&quot;LogController&quot;, &quot;日志服务&quot;))
                .select()
                // 当前包路径
                .apis(RequestHandlerSelectors.basePackage(&quot;com.bolingcavalry.relatedoperation.controller&quot;))
                .paths(PathSelectors.any())
                .build();
    }

    //构建 api文档的详细信息函数,注意这里的注解引用的是哪个
    private ApiInfo apiInfo() {
        return new ApiInfoBuilder()
                //页面标题
                .title(&quot;MyBatis CURD操作&quot;)
                //创建人
                .contact(new Contact(&quot;程序员欣宸&quot;, &quot;https://github.com/zq2599/blog_demos&quot;, &quot;zq2599@gmail.com&quot;))
                //版本号
                .version(&quot;1.0&quot;)
                //描述
                .description(&quot;API 描述&quot;)
                .build();
    }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;ol start=&quot;7&quot;&gt;&lt;li&gt;springboot引导类：&lt;/li&gt;
&lt;/ol&gt;&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;package com.bolingcavalry.relatedoperation;

import org.mybatis.spring.annotation.MapperScan;
import org.springframework.boot.SpringApplication;
import org.springframework.boot.autoconfigure.SpringBootApplication;

@SpringBootApplication
@MapperScan(&quot;com.bolingcavalry.relatedoperation.mapper&quot;)
public class RelatedOperationApplication {

    public static void main(String[] args) {
        SpringApplication.run(RelatedOperationApplication.class, args);
    }

}
&lt;/code&gt;
&lt;/pre&gt;
&lt;ol start=&quot;8&quot;&gt;&lt;li&gt;用户表的实体类：&lt;/li&gt;
&lt;/ol&gt;&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;package com.bolingcavalry.relatedoperation.entity;

import io.swagger.annotations.ApiModel;
import io.swagger.annotations.ApiModelProperty;
import lombok.Data;
import lombok.NoArgsConstructor;

@Data
@NoArgsConstructor
@ApiModel(description = &quot;用户实体类&quot;)
public class User {

    @ApiModelProperty(value = &quot;用户ID&quot;)
    private Integer id;

    @ApiModelProperty(value = &quot;用户名&quot;, required = true)
    private String name;

    @ApiModelProperty(value = &quot;用户地址&quot;, required = false)
    private Integer age;
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;ol start=&quot;9&quot;&gt;&lt;li&gt;日志表的实体类：&lt;/li&gt;
&lt;/ol&gt;&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;package com.bolingcavalry.relatedoperation.entity;

import io.swagger.annotations.ApiModel;
import io.swagger.annotations.ApiModelProperty;
import lombok.Data;
import lombok.NoArgsConstructor;
import java.sql.Date;

@Data
@NoArgsConstructor
@ApiModel(description = &quot;日志实体类&quot;)
public class Log {
    @ApiModelProperty(value = &quot;日志ID&quot;)
    private Integer id;

    @ApiModelProperty(value = &quot;用户ID&quot;)
    private Integer userId;

    @ApiModelProperty(value = &quot;日志内容&quot;)
    private String action;

    @ApiModelProperty(value = &quot;创建时间&quot;)
    private Date createTime;
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;ul&gt;&lt;li&gt;以上就是本篇的准备代码，接下来在此基础上实现各种多表关联查询&lt;/li&gt;
&lt;/ul&gt;&lt;h3 id=&quot;最简单的联表&quot;&gt;最简单的联表&lt;/h3&gt;
&lt;ul&gt;&lt;li&gt;先实战的是最普通的联表，如下图所示，查询结果是名为LogExtend的实体类，这个类有5个字段，其中四个来自日志表log，一个来自用户表user：&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/485422/202101/485422-20210121082520332-1934786433.jpg&quot; alt=&quot;在这里插入图片描述&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;下图是开发步骤：&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/485422/202101/485422-20210121082520518-1632391366.jpg&quot; alt=&quot;在这里插入图片描述&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;实体类LogExtend的源码如下，可见和Log相比多了个&lt;span&gt;userName&lt;/span&gt;字段：&lt;/li&gt;
&lt;/ol&gt;&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;package com.bolingcavalry.relatedoperation.entity;

import io.swagger.annotations.ApiModel;
import io.swagger.annotations.ApiModelProperty;
import lombok.Data;
import lombok.NoArgsConstructor;

@Data
@NoArgsConstructor
@ApiModel(description = &quot;日志实体类(含用户表的字段)&quot;)
public class LogExtend extends Log {

    @ApiModelProperty(value = &quot;用户名&quot;)
    private String userName;
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;ol start=&quot;2&quot;&gt;&lt;li&gt;新建log表对应的映射文件&lt;span&gt;LogMapper.xml&lt;/span&gt;，如下所示，里面是通过&lt;span&gt;left join&lt;/span&gt;语法执行的简单的联表查询，以及查询结果对应的resultMap定义：&lt;/li&gt;
&lt;/ol&gt;&lt;pre&gt;
&lt;code class=&quot;language-xml&quot;&gt;&amp;lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&amp;gt;
&amp;lt;!DOCTYPE mapper PUBLIC &quot;-//mybatis.org//DTD Mapper 3.0//EN&quot; &quot;http://mybatis.org/dtd/mybatis-3-mapper.dtd&quot;&amp;gt;
&amp;lt;mapper namespace=&quot;com.bolingcavalry.relatedoperation.mapper.LogMapper&quot;&amp;gt;

    &amp;lt;!--联表查询，返回log对象，该对象有个userName字段，值是user表的user_name字段--&amp;gt;
    &amp;lt;select id=&quot;oneObjectSel&quot; parameterType=&quot;int&quot; resultMap=&quot;logExtendResultMap&quot;&amp;gt;
        select l.id as id,
               l.user_id as user_id,
               l.action as action,
               l.create_time as create_time,
               u.name as user_name
        from log as l
                 left join user as u
                           on l.user_id = u.id
        where l.id = #{id}
    &amp;lt;/select&amp;gt;

    &amp;lt;resultMap id=&quot;logExtendResultMap&quot; type=&quot;logExtend&quot;&amp;gt;
        &amp;lt;id property=&quot;id&quot; column=&quot;id&quot;/&amp;gt;
        &amp;lt;result column=&quot;user_id&quot; jdbcType=&quot;INTEGER&quot; property=&quot;userId&quot;/&amp;gt;
        &amp;lt;result column=&quot;action&quot; jdbcType=&quot;VARCHAR&quot; property=&quot;action&quot;/&amp;gt;
        &amp;lt;result column=&quot;create_time&quot; jdbcType=&quot;TIMESTAMP&quot; property=&quot;createTime&quot;/&amp;gt;
        &amp;lt;result column=&quot;user_name&quot; jdbcType=&quot;VARCHAR&quot; property=&quot;userName&quot;/&amp;gt;
    &amp;lt;/resultMap&amp;gt;
&amp;lt;/mapper&amp;gt;
&lt;/code&gt;
&lt;/pre&gt;
&lt;ol start=&quot;3&quot;&gt;&lt;li&gt;mapper接口代码：&lt;/li&gt;
&lt;/ol&gt;&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;package com.bolingcavalry.relatedoperation.mapper;

import com.bolingcavalry.relatedoperation.entity.LogAssociateUser;
import com.bolingcavalry.relatedoperation.entity.LogExtend;
import org.springframework.stereotype.Repository;

@Repository
public interface LogMapper {

    LogExtend oneObjectSel(int id);
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;ol start=&quot;4&quot;&gt;&lt;li&gt;service层的代码在LogService.java文件中：&lt;/li&gt;
&lt;/ol&gt;&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;package com.bolingcavalry.relatedoperation.service;

import com.bolingcavalry.relatedoperation.entity.LogAssociateUser;
import com.bolingcavalry.relatedoperation.entity.LogExtend;
import com.bolingcavalry.relatedoperation.mapper.LogMapper;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.stereotype.Service;

@Service
public class LogService {
    @Autowired
    LogMapper logMapper;

    public LogExtend oneObjectSel(int id){
        return logMapper.oneObjectSel(id);
    }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;ol start=&quot;5&quot;&gt;&lt;li&gt;controller层的代码在LogController.java文件中：&lt;/li&gt;
&lt;/ol&gt;&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;@RestController
@RequestMapping(&quot;/log&quot;)
@Api(tags = {&quot;LogController&quot;})
public class LogController {
    @Autowired
    private LogService logService;

    @ApiOperation(value = &quot;根据ID查找日志记录，带userName字段，该字段通过联表查询实现&quot;, notes=&quot;根据ID查找日志记录，带userName字段，该字段通过联表查询实现&quot;)
    @ApiImplicitParam(name = &quot;id&quot;, value = &quot;日志ID&quot;, paramType = &quot;path&quot;, required = true, dataType = &quot;Integer&quot;)
    @RequestMapping(value = &quot;/aggregate/{id}&quot;, method = RequestMethod.GET)
    public LogExtend oneObjectSel(@PathVariable int id){
        return logService.oneObjectSel(id);
    }
&lt;/code&gt;
&lt;/pre&gt;
&lt;ol start=&quot;6&quot;&gt;&lt;li&gt;编写单元测试的代码ControllerTest.java，由于今天的测试涉及到user和log两个表，因此在测试类ControllerTest的内部准备了两个内部类，分别用于测试user和log表：&lt;/li&gt;
&lt;/ol&gt;&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;package com.bolingcavalry.relatedoperation.controller;

import lombok.extern.slf4j.Slf4j;
import org.junit.jupiter.api.*;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.boot.test.autoconfigure.web.servlet.AutoConfigureMockMvc;
import org.springframework.boot.test.context.SpringBootTest;
import org.springframework.http.MediaType;
import org.springframework.test.context.ActiveProfiles;
import org.springframework.test.web.servlet.MockMvc;
import org.springframework.test.web.servlet.request.MockMvcRequestBuilders;

import static org.springframework.test.web.servlet.result.MockMvcResultHandlers.print;
import static org.springframework.test.web.servlet.result.MockMvcResultMatchers.jsonPath;
import static org.springframework.test.web.servlet.result.MockMvcResultMatchers.status;

@SpringBootTest
@DisplayName(&quot;Web接口的单元测试&quot;)
@AutoConfigureMockMvc
@ActiveProfiles(&quot;test&quot;)
@Slf4j
public class ControllerTest {
    /**
     * 查询方式：联表
     */
    final static String SEARCH_TYPE_LEFT_JOIN = &quot;leftjoin&quot;;

    /**
     * 查询方式：嵌套
     */
    final static String SEARCH_TYPE_NESTED = &quot;nested&quot;;

    final static int TEST_USER_ID = 3;

    final static String TEST_USER_NAME = &quot;tom&quot;;

    @Autowired MockMvc mvc;

    @Nested
    @TestMethodOrder(MethodOrderer.OrderAnnotation.class)
    @DisplayName(&quot;用户服务&quot;)
    class User {
    
    }
    
    @Nested
    @TestMethodOrder(MethodOrderer.OrderAnnotation.class)
    @DisplayName(&quot;日志服务&quot;)
    class Log {
        final static int TEST_LOG_ID = 5;

        @Test
        @DisplayName(&quot;通过日志ID获取日志信息,带userName字段，该字段通过联表查询实现&quot;)
        @Order(1)
        void oneObjectSel() throws Exception {
            mvc.perform(MockMvcRequestBuilders.get(&quot;/log/aggregate/&quot; + TEST_LOG_ID)
                    .accept(MediaType.APPLICATION_JSON))
                    .andExpect(status().isOk())
                    .andExpect(jsonPath(&quot;$.id&quot;).value(TEST_LOG_ID))
                    .andExpect(jsonPath(&quot;$.userName&quot;).value(TEST_USER_NAME))
                    .andDo(print());
        }
    }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;ol start=&quot;7&quot;&gt;&lt;li&gt;执行上述单元测试方法，结果如下图，红框中就是controller层返回的数据，可见已通过Mybatis成功取得LogExtend实例：&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/485422/202101/485422-20210121082520874-337907740.jpg&quot; alt=&quot;在这里插入图片描述&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;下一站是一对一联表查询；&lt;/li&gt;
&lt;/ul&gt;&lt;h3 id=&quot;关于一对一关联的两种方式&quot;&gt;关于一对一关联的两种方式&lt;/h3&gt;
&lt;ul&gt;&lt;li&gt;前面的查询有个特点：尽管查询了两个表，但结果都在同一实体类的不同字段，而更符合业务逻辑的关系应该是log类中有个user类的成员变量，即如下形式：&lt;/li&gt;
&lt;/ul&gt;&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;@Data
@NoArgsConstructor
@ApiModel(description = &quot;日志实体类&quot;)
public class LogAssociateUser {
    @ApiModelProperty(value = &quot;日志ID&quot;)
    private Integer id;

    @ApiModelProperty(value = &quot;用户对象&quot;)
    private User user;

    @ApiModelProperty(value = &quot;日志内容&quot;)
    private String action;

    @ApiModelProperty(value = &quot;创建时间&quot;)
    private Date createTime;
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;ul&gt;&lt;li&gt;接下来的实战就是如何用MyBatis查询得到上述&lt;span&gt;LogAssociateUser&lt;/span&gt; 类型的结果；&lt;/li&gt;
&lt;li&gt;一对一关联的实现有&lt;span&gt;联表&lt;/span&gt;和&lt;span&gt;嵌套查询&lt;/span&gt;两种，它们的差异在Mybatis中体现在association的子节点上：&lt;/li&gt;
&lt;/ul&gt;&lt;ol&gt;&lt;li&gt;联表时，association内使用&lt;span&gt;result&lt;/span&gt;子节点，将联表查询的结果映射到关联对象；&lt;/li&gt;
&lt;li&gt;嵌套时，association内使用&lt;span&gt;select&lt;/span&gt;子节点，触发一次新的查询；&lt;/li&gt;
&lt;/ol&gt;&lt;h3 id=&quot;一对一（联表）&quot;&gt;一对一（联表）&lt;/h3&gt;
&lt;p&gt;所谓一对一，就是一个对象关联了另一个对象，例如一条log记录中，带有对应的user信息；&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;下面是新的实体类LogAssociateUser，该类对应的是log表记录，有个user字段，类型是User对象：&lt;/li&gt;
&lt;/ol&gt;&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;@Data
@NoArgsConstructor
@ApiModel(description = &quot;日志实体类&quot;)
public class LogAssociateUser {
    @ApiModelProperty(value = &quot;日志ID&quot;)
    private Integer id;

    @ApiModelProperty(value = &quot;用户对象&quot;)
    private User user;

    @ApiModelProperty(value = &quot;日志内容&quot;)
    private String action;

    @ApiModelProperty(value = &quot;创建时间&quot;)
    private Date createTime;
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;ol start=&quot;2&quot;&gt;&lt;li&gt;映射文件&lt;span&gt;LogMapper.xml&lt;/span&gt;中，sql和resultMap如下，可见查询的时候将user表的字段都查出来了，然后在resultMap中用association节点去处理sql中查出的user表的数据，通过&lt;span&gt;javaType&lt;/span&gt;属性转为User类的实例：&lt;/li&gt;
&lt;/ol&gt;&lt;pre&gt;
&lt;code class=&quot;language-xml&quot;&gt;    &amp;lt;!--联表查询，返回log对象，它的成员变量中有user对象--&amp;gt;
    &amp;lt;select id=&quot;leftJoinSel&quot; parameterType=&quot;int&quot; resultMap=&quot;leftJoinResultMap&quot;&amp;gt;
        select l.id as log_id,
               l.action as log_action,
               l.create_time as log_create_time,
               u.id as user_id,
               u.name as user_name,
               u.age as user_age
        from log as l
               left join user as u
               on l.user_id = u.id
        where l.id = #{id}
    &amp;lt;/select&amp;gt;

    &amp;lt;resultMap id=&quot;leftJoinResultMap&quot; type=&quot;LogAssociateUser&quot;&amp;gt;
        &amp;lt;id property=&quot;id&quot; column=&quot;log_id&quot;/&amp;gt;

        &amp;lt;result  property=&quot;action&quot; column=&quot;log_action&quot; jdbcType=&quot;VARCHAR&quot;/&amp;gt;

        &amp;lt;result property=&quot;createTime&quot; column=&quot;log_create_time&quot; jdbcType=&quot;TIMESTAMP&quot; /&amp;gt;

        &amp;lt;association property=&quot;user&quot; javaType=&quot;User&quot;&amp;gt;
            &amp;lt;id property=&quot;id&quot; column=&quot;user_id&quot;/&amp;gt;
            &amp;lt;result property=&quot;name&quot; column=&quot;user_name&quot;/&amp;gt;
            &amp;lt;result property=&quot;age&quot; column=&quot;user_age&quot;/&amp;gt;
        &amp;lt;/association&amp;gt;
    &amp;lt;/resultMap&amp;gt;
&lt;/code&gt;
&lt;/pre&gt;
&lt;ol start=&quot;3&quot;&gt;&lt;li&gt;以上就是一对一（联表）的关键点，接下来按部就班的在LogMapper、LogService、LogController中添加方法即可，下面是LogController中对应的web接口，稍后会在单元测试中调用这个接口进行验证：&lt;/li&gt;
&lt;/ol&gt;&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;    @ApiOperation(value = &quot;根据ID查找日志记录，带用户对象，联表查询实现&quot;, notes=&quot;根据ID查找日志记录，带用户对象，联表查询实现&quot;)
    @ApiImplicitParam(name = &quot;id&quot;, value = &quot;日志ID&quot;, paramType = &quot;path&quot;, required = true, dataType = &quot;Integer&quot;)
    @RequestMapping(value = &quot;/leftjoin/{id}&quot;, method = RequestMethod.GET)
    public LogAssociateUser leftJoinSel(@PathVariable int id){
        return logService.leftJoinSel(id);
    }
&lt;/code&gt;
&lt;/pre&gt;
&lt;ol start=&quot;4&quot;&gt;&lt;li&gt;最后是单元测试的代码（ControllerTest.java文件），用来测试上述代码是否有效，注意下面的&lt;span&gt;queryAndCheck&lt;/span&gt;私有方法，该方法中发起请求并验证结果：&lt;/li&gt;
&lt;/ol&gt;&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;        /**
         * 通过日志ID获取日志信息有两种方式：联表和嵌套查询，
         * 从客户端来看，仅一部分path不同，因此将请求和检查封装到一个通用方法中，
         * 调用方法只需要指定不同的那一段path
         * @param subPath
         * @throws Exception
         */
        private void queryAndCheck(String subPath) throws Exception {
            String queryPath = &quot;/log/&quot; + subPath + &quot;/&quot; + TEST_LOG_ID;

            log.info(&quot;query path [{}]&quot;, queryPath);

            mvc.perform(MockMvcRequestBuilders.get(queryPath)
                    .accept(MediaType.APPLICATION_JSON))
                    .andExpect(status().isOk())
                    .andExpect(jsonPath(&quot;$.id&quot;).value(TEST_LOG_ID))
                    .andExpect(jsonPath(&quot;$.user.id&quot;).value(TEST_USER_ID))
                    .andDo(print());
        }

        @Test
        @DisplayName(&quot;通过日志ID获取日志信息（关联了用户），联表查询&quot;)
        @Order(2)
        void leftJoinSel() throws Exception {
            queryAndCheck(SEARCH_TYPE_LEFT_JOIN);
        }
&lt;/code&gt;
&lt;/pre&gt;
&lt;ol start=&quot;5&quot;&gt;&lt;li&gt;执行单元测试结果如下，可见：内部嵌套了一个json对象，就是user表的数据：&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/485422/202101/485422-20210121082522389-99862093.jpg&quot; alt=&quot;在这里插入图片描述&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h3 id=&quot;一对一（嵌套）&quot;&gt;一对一（嵌套）&lt;/h3&gt;
&lt;ol&gt;&lt;li&gt;接下来试试嵌套的方式；&lt;/li&gt;
&lt;li&gt;LogMapper.xml中对应的sql：&lt;/li&gt;
&lt;/ol&gt;&lt;pre&gt;
&lt;code class=&quot;language-xml&quot;&gt;    &amp;lt;!--嵌套--&amp;gt;
    &amp;lt;select id=&quot;nestedSel&quot; parameterType=&quot;int&quot; resultMap=&quot;nestedResultMap&quot;&amp;gt;
        select
            l.id as log_id,
            l.user_id as log_user_id,
            l.action as log_action,
            l.create_time as log_create_time
        from mybatis.log as l
        where l.id = #{id}
    &amp;lt;/select&amp;gt;
&lt;/code&gt;
&lt;/pre&gt;
&lt;ol start=&quot;3&quot;&gt;&lt;li&gt;上述sql对应的resultMap如下，可见association节点中有个&lt;span&gt;select&lt;/span&gt;属性，这就是MyBatis支持嵌套查询的关键，该属性的值是个select节点：&lt;/li&gt;
&lt;/ol&gt;&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;    &amp;lt;!-- association节点的select属性会触发嵌套查询--&amp;gt;
    &amp;lt;resultMap id=&quot;nestedResultMap&quot; type=&quot;LogAssociateUser&quot;&amp;gt;
        &amp;lt;!-- column属性中的log_id，来自前面查询时的&quot;l.id as log_id&quot; --&amp;gt;
        &amp;lt;id property=&quot;id&quot; column=&quot;log_id&quot;/&amp;gt;
        &amp;lt;!-- column属性中的log_action，来自前面查询时的&quot;l.action as log_action&quot; --&amp;gt;
        &amp;lt;result  property=&quot;action&quot; column=&quot;log_action&quot; jdbcType=&quot;VARCHAR&quot;/&amp;gt;
        &amp;lt;!-- column属性中的log_create_time，来自前面查询时的&quot;l.create_time as log_create_time&quot; --&amp;gt;
        &amp;lt;result property=&quot;createTime&quot; column=&quot;log_create_time&quot; jdbcType=&quot;TIMESTAMP&quot; /&amp;gt;
        &amp;lt;!-- select属性，表示这里要执行嵌套查询，将log_user_id传给嵌套的查询 --&amp;gt;
        &amp;lt;association property=&quot;user&quot; column=&quot;log_user_id&quot; select=&quot;selectUserByUserId&quot;&amp;gt;&amp;lt;/association&amp;gt;
    &amp;lt;/resultMap&amp;gt;
&lt;/code&gt;
&lt;/pre&gt;
&lt;ol start=&quot;4&quot;&gt;&lt;li&gt;上述节点中select属性的值，对应一个select节点，如下：&lt;/li&gt;
&lt;/ol&gt;&lt;pre&gt;
&lt;code class=&quot;language-xml&quot;&gt;    &amp;lt;select id=&quot;selectUserByUserId&quot; parameterType=&quot;int&quot; resultType=&quot;User&quot;&amp;gt;
        select
            u.id,
            u.name,
            u.age
        from mybatis.user as u
        where u.id = #{log_user_id}
    &amp;lt;/select&amp;gt;
&lt;/code&gt;
&lt;/pre&gt;
&lt;ol start=&quot;5&quot;&gt;&lt;li&gt;以上就是一对一（嵌套）的关键点，接下来按部就班的在LogMapper、LogService、LogController中添加方法即可，下面是LogController中对应的web接口，稍后会在单元测试中调用这个接口进行验证：&lt;/li&gt;
&lt;/ol&gt;&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;    @ApiOperation(value = &quot;根据ID查找日志记录，带用户对象，嵌套查询实现&quot;, notes=&quot;根据ID查找日志记录，带用户对象，嵌套查询实现&quot;)
    @ApiImplicitParam(name = &quot;id&quot;, value = &quot;日志ID&quot;, paramType = &quot;path&quot;, required = true, dataType = &quot;Integer&quot;)
    @RequestMapping(value = &quot;/nested/{id}&quot;, method = RequestMethod.GET)
    public LogAssociateUser nestedSel(@PathVariable int id){
        return logService.nestedSel(id);
    }
&lt;/code&gt;
&lt;/pre&gt;
&lt;ol start=&quot;6&quot;&gt;&lt;li&gt;最后是单元测试的代码（ControllerTest.java文件），用来测试上述代码是否有效，如下可见，直接调用了前面的&lt;span&gt;queryAndCheck&lt;/span&gt;来验证：&lt;/li&gt;
&lt;/ol&gt;&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;        @Test
        @DisplayName(&quot;通过日志ID获取日志信息（关联了用户），嵌套查询&quot;)
        @Order(3)
        void nestedSel() throws Exception {
            queryAndCheck(SEARCH_TYPE_NESTED);
        }
&lt;/code&gt;
&lt;/pre&gt;
&lt;ol start=&quot;7&quot;&gt;&lt;li&gt;执行上述单元测试代码，结果如下，可见嵌套查询的方式也能将user表的数据成功获取，放入log实例的成员变量中：&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/485422/202101/485422-20210121082522846-909187286.jpg&quot; alt=&quot;在这里插入图片描述&quot; loading=&quot;lazy&quot;/&gt;&lt;br/&gt;8. 最后是对比联表和嵌套查询的差异，先看联表查询的MyBatis日志，如下图红框所示，只有一次sql查询：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/485422/202101/485422-20210121082523338-2029184207.jpg&quot; alt=&quot;在这里插入图片描述&quot; loading=&quot;lazy&quot;/&gt;&lt;br/&gt;9. 再看嵌套查询的日志，如下图，红框是第一次查询，结果中的userid作为绿框中的第二次查询的条件：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/485422/202101/485422-20210121082523873-399309500.jpg&quot; alt=&quot;在这里插入图片描述&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;至此，一对一的多表查询实战就完成了，本篇的逻辑是一条log记录关联一条user记录，下一篇文章，咱们学习一对多关联，即一个user有多条log记录；&lt;/li&gt;
&lt;/ul&gt;&lt;h3 id=&quot;你不孤单，欣宸原创一路相伴&quot;&gt;你不孤单，欣宸原创一路相伴&lt;/h3&gt;
&lt;ol&gt;&lt;li&gt;&lt;a href=&quot;https://xinchen.blog.csdn.net/article/details/105068742&quot; target=&quot;_blank&quot;&gt;Java系列&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://xinchen.blog.csdn.net/article/details/105086498&quot; target=&quot;_blank&quot;&gt;Spring系列&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://xinchen.blog.csdn.net/article/details/105086732&quot; target=&quot;_blank&quot;&gt;Docker系列&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://xinchen.blog.csdn.net/article/details/105086794&quot; target=&quot;_blank&quot;&gt;kubernetes系列&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://xinchen.blog.csdn.net/article/details/105086850&quot; target=&quot;_blank&quot;&gt;数据库+中间件系列&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://xinchen.blog.csdn.net/article/details/105086920&quot; target=&quot;_blank&quot;&gt;DevOps系列&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;h3 id=&quot;欢迎关注公众号：程序员欣宸&quot;&gt;欢迎关注公众号：程序员欣宸&lt;/h3&gt;
&lt;blockquote readability=&quot;4.258064516129&quot;&gt;
&lt;p&gt;微信搜索「程序员欣宸」，我是欣宸，期待与您一同畅游Java世界...&lt;br/&gt;&lt;a href=&quot;https://github.com/zq2599/blog_demos&quot; target=&quot;_blank&quot;&gt;https://github.com/zq2599/blog_demos&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
</description>
<pubDate>Thu, 21 Jan 2021 00:25:00 +0000</pubDate>
<dc:creator>程序员欣宸</dc:creator>
<og:description>欢迎访问我的GitHub https://github.com/zq2599/blog_demos 内容：所有原创文章分类汇总及配套源码，涉及Java、Docker、Kubernetes、DevOPS</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/bolingcavalry/p/14306122.html</dc:identifier>
</item>
<item>
<title>面试时通过volatile关键字，全面展示线程内存模型的能力 - hsm_computer</title>
<link>http://www.cnblogs.com/JavaArchitect/p/14306111.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/JavaArchitect/p/14306111.html</guid>
<description>&lt;p&gt;    面试时，面试官经常会通过volatile关键字来考核候选人在多线程方面的能力，一旦被问题此类问题，大家可以通过如下的步骤全面这方面的能力。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;    1 首先通过内存模型说明volatile关键字的作用&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;    先说明，用volatile修饰的变量，能直接修改内存内容，修改后的变量对其他线程是可见的。然后展开说明如下的内容。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;    &lt;/strong&gt;多线程并发操作同一资源时，可能会出现最终结果和预期不同的情况，刚才我们也已经通过线程安全和不安全相关的案例，直观地看到了这一情况，这里我们将通过线程的内存结构来详细分析下造成“最终结果不一致”的原因。&lt;/p&gt;
&lt;p&gt;    如果某个线程要操作data变量，该线程会先把data变量装载到线程内部的内存中做个副本，之后线程就不再和在主内存中的data变量有任何关系，而是会操作副本变量的值，操作完成后，再把这个副本回写到主内存（也就是堆内存）中，这个过程如下图所示。&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;cke_widget_wrapper cke_widget_inline cke_widget_image cke_image_nocaption cke_widget_selected&quot; data-cke-widget-wrapper=&quot;1&quot; data-cke-filter=&quot;off&quot; data-cke-display-name=&quot;图像&quot; data-cke-widget-id=&quot;4&quot;&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20210121075742283.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3N4ZXJpYw==,size_16,color_FFFFFF,t_70&quot; alt=&quot;&quot; width=&quot;559&quot; height=&quot;309&quot; class=&quot;cke_widget_element&quot; data-cke-saved-src=&quot;https://img-blog.csdnimg.cn/20210121075742283.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3N4ZXJpYw==,size_16,color_FFFFFF,t_70&quot; data-cke-widget-data=&quot;{&amp;amp;quot;hasCaption&amp;amp;quot;:false,&amp;amp;quot;src&amp;amp;quot;:&amp;amp;quot;https://img-blog.csdnimg.cn/20210121075742283.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3N4ZXJpYw==,size_16,color_FFFFFF,t_70&amp;amp;quot;,&amp;amp;quot;alt&amp;amp;quot;:&amp;amp;quot;&amp;amp;quot;,&amp;amp;quot;width&amp;amp;quot;:&amp;amp;quot;559&amp;amp;quot;,&amp;amp;quot;height&amp;amp;quot;:&amp;amp;quot;309&amp;amp;quot;,&amp;amp;quot;lock&amp;amp;quot;:true,&amp;amp;quot;align&amp;amp;quot;:&amp;amp;quot;none&amp;amp;quot;,&amp;amp;quot;classes&amp;amp;quot;:[]}&quot; data-cke-widget-upcasted=&quot;1&quot; data-cke-widget-keep-attr=&quot;0&quot; data-widget=&quot;image&quot;/&gt;&lt;span class=&quot;cke_reset cke_widget_drag_handler_container&quot;&gt;&lt;img src=&quot;data:image/gif;base64,R0lGODlhAQABAPABAP///wAAACH5BAEKAAAALAAAAAABAAEAAAICRAEAOw==&quot; width=&quot;15&quot; height=&quot;15&quot; class=&quot;cke_reset cke_widget_drag_handler&quot; title=&quot;点击并拖拽以移动&quot; data-cke-widget-drag-handler=&quot;1&quot;/&gt;&lt;span class=&quot;cke_image_resizer&quot; title=&quot;点击并拖拽以改变尺寸&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;    假设data的初始值是0，有100个线程并发地对它进行加1操作，预期的运行结果是100。但在实际的操作过程中，假设A线程和B线程并发地data，其中A读到的值是0，B读到的是1。当B在它的线程内部内存中完成加1操作（data变成2），会把data回写到主内存里，这时主内存里的data也是2。&lt;/p&gt;
&lt;p&gt;    但之后，A线程也完成了加1操作（此时A内部线程中的data副本是1），在之后的回写过程中，会把主内存中的data变量从2设置成1，这样就造成数据不一致的问题了。&lt;/p&gt;
&lt;p&gt;    但是，如果data变量被volatile变量修饰，那么A线程修改好的data变量，无需等到“”回写“”阶段，能直接写回到主内存里，这就能导致该变量对其它线程“立即可见”。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2 同时说明，volatile不能解决数据不一致的问题&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;如果某个变量之前加了volatile，线程在每次使用该变量时，都会从主内存中读取该变量最新的值，而且，某线程一旦修改了该变量，这个修改会立即回写到主内存里。&lt;/p&gt;
&lt;p&gt;既然是在操作前会从主内存中读取变量最新的值，而且每次修改后都会立即回写到主内存，这样的话是否能解决多线程中数据不一致的问题呢？通过下面的VolilateDemo.java代码，我们来看下这个问题的答案。&lt;/p&gt;

&lt;p&gt;    在main函数的第12行里，通过for循环启动1000个线程。从第13到16行里，我们通过了Runnable类定义了线程的动作，每个线程启动后，会调用第15行的add方法对用volatile修饰的cnt变量进行加1操作。&lt;/p&gt;
&lt;p&gt;    多次运行的结果可能不一样，但在大多数情况下，最终cnt的值会小于1000，也就是说，用volatile修饰的变量不能保证数据一致性，换句话说，volatile不能当锁来用，因为它不能保证主内存的变量在同一时间段里只被一个线程操作。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;3 然后说下volatile的作用&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;     那么volatile有什么用呢？被volatile修饰的变量每次在使用时，不是从各线程的内部内存中拿，而是从主内存中拿。这样就能避免“创建副本”到“把副本回写到主内存中”等的操作，从而能提升效率。&lt;/p&gt;
&lt;p&gt;    但请注意，如果我们在多线程环境下，针对某个变量有读和写的操作，那么别把它修饰成volatile，因为为了解决数据不一致的问题，我们会给该变量加锁，这样该变量在一个时间段里只会有一个线程进行操作，这样就无法发挥出volatile的优势了。&lt;/p&gt;
&lt;p&gt;    请记住这个结论，如果某个变量在多线程环境下只有读或者是只有写的操作，建议把它设置成volatile，这样能提升多线程并发时的效率。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;4 如果可以，再扩展到ConcurrentHashMap的底层代码&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;    说好上述内容以后，其实大家已经可以能充分展示内存方面的技能了，不过大家还可以多说一句：我还看过ConcurrentHashMap的底层源码，其中用到了volatile关键字。&lt;/p&gt;
&lt;p&gt;    ConcurrentHashMap是支持并发的HashMap，说白了就当多个线程同时读写ConcurrentHashMap对象时，不会有问题。&lt;/p&gt;
&lt;p&gt;    该对象存储键值对的Node对象定义如下，其中表示值的val变量被volatile修饰，也就是说，A线程对该ConcurrentHashMap的操作，能立即回写到主内存，所以其它线程也能立即可见，所以能支持并发。&lt;/p&gt;

&lt;p&gt;    当大家从volatile关键字引申到ConcurrentHashmap底层源码后，面试官就会认识你很资深。我记得当初，我去面试一家比较大的互联网公司，就这样说了一通，然后就直接通过这轮技术面试了（不过还有后继部门经理的技术面试）。&lt;span class=&quot;cke_widget_wrapper cke_widget_inline cke_widget_image cke_image_nocaption cke_widget_selected&quot; data-cke-widget-wrapper=&quot;1&quot; data-cke-filter=&quot;off&quot; data-cke-display-name=&quot;图像&quot; data-cke-widget-id=&quot;1&quot;&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/img_convert/1fa676f54bef2ea7b16c291322a17b68.png&quot; alt=&quot;&quot; class=&quot;cke_widget_element&quot; data-cke-saved-src=&quot;https://img-blog.csdnimg.cn/img_convert/1fa676f54bef2ea7b16c291322a17b68.png&quot; data-cke-widget-data=&quot;{&amp;amp;quot;hasCaption&amp;amp;quot;:false,&amp;amp;quot;src&amp;amp;quot;:&amp;amp;quot;https://img-blog.csdnimg.cn/img_convert/1fa676f54bef2ea7b16c291322a17b68.png&amp;amp;quot;,&amp;amp;quot;alt&amp;amp;quot;:&amp;amp;quot;&amp;amp;quot;,&amp;amp;quot;width&amp;amp;quot;:&amp;amp;quot;&amp;amp;quot;,&amp;amp;quot;height&amp;amp;quot;:&amp;amp;quot;&amp;amp;quot;,&amp;amp;quot;lock&amp;amp;quot;:true,&amp;amp;quot;align&amp;amp;quot;:&amp;amp;quot;none&amp;amp;quot;,&amp;amp;quot;classes&amp;amp;quot;:[]}&quot; data-cke-widget-upcasted=&quot;1&quot; data-cke-widget-keep-attr=&quot;0&quot; data-widget=&quot;image&quot;/&gt;&lt;span class=&quot;cke_reset cke_widget_drag_handler_container&quot;&gt;&lt;img src=&quot;data:image/gif;base64,R0lGODlhAQABAPABAP///wAAACH5BAEKAAAALAAAAAABAAEAAAICRAEAOw==&quot; width=&quot;15&quot; height=&quot;15&quot; class=&quot;cke_reset cke_widget_drag_handler&quot; title=&quot;点击并拖拽以移动&quot; data-cke-widget-drag-handler=&quot;1&quot;/&gt;&lt;span class=&quot;cke_image_resizer&quot; title=&quot;点击并拖拽以改变尺寸&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;请大家关注我的公众号：一起进步，一起挣钱，在本公众号里，会有很多精彩的面试文章。&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;cke_widget_wrapper cke_widget_inline cke_widget_image cke_image_nocaption cke_widget_selected&quot; data-cke-widget-wrapper=&quot;1&quot; data-cke-filter=&quot;off&quot; data-cke-display-name=&quot;图像&quot; data-cke-widget-id=&quot;0&quot;&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/img_convert/94ca48546154bf9739a4ede0b441d180.png&quot; alt=&quot;&quot; class=&quot;cke_widget_element&quot; data-cke-saved-src=&quot;https://img-blog.csdnimg.cn/img_convert/94ca48546154bf9739a4ede0b441d180.png&quot; data-cke-widget-data=&quot;{&amp;amp;quot;hasCaption&amp;amp;quot;:false,&amp;amp;quot;src&amp;amp;quot;:&amp;amp;quot;https://img-blog.csdnimg.cn/img_convert/94ca48546154bf9739a4ede0b441d180.png&amp;amp;quot;,&amp;amp;quot;alt&amp;amp;quot;:&amp;amp;quot;&amp;amp;quot;,&amp;amp;quot;width&amp;amp;quot;:&amp;amp;quot;&amp;amp;quot;,&amp;amp;quot;height&amp;amp;quot;:&amp;amp;quot;&amp;amp;quot;,&amp;amp;quot;lock&amp;amp;quot;:true,&amp;amp;quot;align&amp;amp;quot;:&amp;amp;quot;none&amp;amp;quot;,&amp;amp;quot;classes&amp;amp;quot;:[]}&quot; data-cke-widget-upcasted=&quot;1&quot; data-cke-widget-keep-attr=&quot;0&quot; data-widget=&quot;image&quot;/&gt;&lt;span class=&quot;cke_reset cke_widget_drag_handler_container&quot;&gt;&lt;img src=&quot;data:image/gif;base64,R0lGODlhAQABAPABAP///wAAACH5BAEKAAAALAAAAAABAAEAAAICRAEAOw==&quot; width=&quot;15&quot; height=&quot;15&quot; class=&quot;cke_reset cke_widget_drag_handler&quot; title=&quot;点击并拖拽以移动&quot; data-cke-widget-drag-handler=&quot;1&quot;/&gt;&lt;span class=&quot;cke_image_resizer&quot; title=&quot;点击并拖拽以改变尺寸&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

</description>
<pubDate>Thu, 21 Jan 2021 00:19:00 +0000</pubDate>
<dc:creator>hsm_computer</dc:creator>
<og:description>面试时，面试官经常会通过volatile关键字来考核候选人在多线程方面的能力，一旦被问题此类问题，大家可以通过如下的步骤全面这方面的能力。 1&amp;#160;首先通过内存模型说明volatile关键字的作</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/JavaArchitect/p/14306111.html</dc:identifier>
</item>
<item>
<title>蓝绿红黑灰|常用的发布方式 - 老於`</title>
<link>http://www.cnblogs.com/hunternet/p/14306105.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/hunternet/p/14306105.html</guid>
<description>&lt;h2 id=&quot;1-发布之痛&quot;&gt;1 发布之痛&lt;/h2&gt;
&lt;p&gt;相信每个程序员都曾经经历过，或正在经历过发布的痛苦，每个发布日的夜晚通常是灯火通明。在现在互联网公司较高的发布频率之下更是放大了这种痛苦，多少正值青春年华的程序员为此白了发、秃了头！让程序员经历发布痛苦的原因有很多，其中之一就是发布方式。&lt;br/&gt;发布造成系统故障影响系统可用性的最大原因之一。因此大多数的公司会选择在用户量最小的深夜进行发布，这就造成了每到发布日就有一大堆黑眼圈的程序员熬夜坐等发布，但其实有了一些好的发布方式也许就不必如此。&lt;br/&gt;我曾经带过两家公司，这两家公司团队的对于发布时间的看法则孑然不同，第一家公司的总是担心发布会对用用户造成影响，因此每次发布都会选择深夜进行发布。而另一家公司则认为应该在用户流量最大的时候进行发布，这样系统问题则可以尽早的暴露出来。造成这两种的结果我分析有很多原因。开发人员信心、交付质量、资源工具、发布方式......我们今天就来看看一些常用的发布方式。&lt;/p&gt;
&lt;h2 id=&quot;2-常用的发布方式&quot;&gt;2 常用的发布方式&lt;/h2&gt;
&lt;h3 id=&quot;21-蛮力发布&quot;&gt;2.1 蛮力发布&lt;/h3&gt;
&lt;p&gt;顾名思义，这种方式简单而粗暴！直接将新的版本覆盖掉老的版本。其优点就是简单而且成本较低，但缺点同样很明显，就是发布过程中通常会导致服务中断进而导致用户受到影响，这种方式比较适应于开发环境或者测试环境或者是公司内部系统这种对可用性要求不高的场景，有些小的公司资源稀缺(服务器资源，基础设施等)的时候也会采用这种方式。比如我的第一家公司一开始的规模较小的时候，通常会选择一个夜深人静、访问量小的时候，悄悄地发布。&lt;br/&gt;&lt;img src=&quot;https://hunter-image.oss-cn-beijing.aliyuncs.com/%E5%8F%AF%E9%9D%A0%E6%80%A7%E7%B3%BB%E7%BB%9F%E5%AE%9E%E8%B7%B5/%E5%B8%B8%E7%94%A8%E7%9A%84%E5%8F%91%E5%B8%83%E6%96%B9%E5%BC%8F/%E8%9B%AE%E5%8A%9B%E5%8F%91%E5%B8%83.png&quot; alt=&quot;蛮力发布&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h3 id=&quot;22-金丝雀发布&quot;&gt;2.2 金丝雀发布&lt;/h3&gt;
&lt;p&gt;金丝雀发布是灰度发布的一种。灰度发布是指在黑与白之间，能够平滑过渡的一种发布方式。即在发布过程中一部分用户继续使用老版本，一部分用户使用新版本，不断地扩大新版本的访问流量。最终实现老版本到新版本的过度。由于金丝雀对瓦斯极其敏感，因此以前旷工开矿下矿洞前，先会放一只金丝雀进去探是否有有毒气体，看金丝雀能否活下来，金丝雀发布由此得名。&lt;br/&gt;&lt;img src=&quot;https://hunter-image.oss-cn-beijing.aliyuncs.com/%E5%8F%AF%E9%9D%A0%E6%80%A7%E7%B3%BB%E7%BB%9F%E5%AE%9E%E8%B7%B5/%E5%B8%B8%E7%94%A8%E7%9A%84%E5%8F%91%E5%B8%83%E6%96%B9%E5%BC%8F/%E9%87%91%E4%B8%9D%E9%9B%80%E5%8F%91%E5%B8%83.png&quot; alt=&quot;金丝雀发布&quot; loading=&quot;lazy&quot;/&gt;&lt;br/&gt;发布过程中，先发一台或者一小部分比例的机器作为金丝雀，用于流量验证。如果金丝雀验证通过则把剩余机器全部发掉。如果金丝雀验证失败，则直接回退金丝雀。金丝雀发布的优势在于可以用少量用户来验证新版本功能，这样即使有问题所影响的也是很小的一部分客户。如果对新版本功能或性能缺乏足够信心那么就可以采用这种方式。这种方式也有其缺点，金丝雀发布本质上仍然是一次性的全量发布，发布过程中用户体验并不平滑，有些隐藏深处的bug少量用户可能并不能验证出来问题，需要逐步扩大流量才可以。&lt;/p&gt;
&lt;h3 id=&quot;23-滚动发布&quot;&gt;2.3 滚动发布&lt;/h3&gt;
&lt;p&gt;滚动发布是在金丝雀发布基础上进行改进的一种发布方式。相比于金丝雀发布，先发金丝雀，然后全发的方式，滚动发布则是整个发布过程中按批次进行发布。每个批次拉入后都可作为金丝雀进行验证，这样流量逐步放大直至结束。&lt;img src=&quot;https://hunter-image.oss-cn-beijing.aliyuncs.com/%E5%8F%AF%E9%9D%A0%E6%80%A7%E7%B3%BB%E7%BB%9F%E5%AE%9E%E8%B7%B5/%E5%B8%B8%E7%94%A8%E7%9A%84%E5%8F%91%E5%B8%83%E6%96%B9%E5%BC%8F/%E6%BB%9A%E5%8A%A8%E5%8F%91%E5%B8%83.png&quot; alt=&quot;滚动发布&quot; loading=&quot;lazy&quot;/&gt;&lt;br/&gt;这种方式的优点就是对用户的影响小，体验平滑，但同样也有很多缺点，首先就是发布和回退时间慢，其次发布工具复杂，负载均衡设备需要具有平滑的拉入拉出能力，一般公司并没有资源投入研发这种复杂的发布工具。再者&lt;br/&gt;发布过程中新老版本同时运行，需要注意兼容性问题。&lt;/p&gt;
&lt;h3 id=&quot;24-蓝绿部署&quot;&gt;2.4 蓝绿部署&lt;/h3&gt;
&lt;p&gt;蓝绿部署，是采用两个分开的集群对软件版本进行升级的一种方式。它的部署模型中包括一个蓝色集群 Group1 和一个绿色集群 Group2，在没有新版本上线的情况下，两个集群上运行的版本是一致的，同时对外提供服务。&lt;img src=&quot;https://hunter-image.oss-cn-beijing.aliyuncs.com/%E5%8F%AF%E9%9D%A0%E6%80%A7%E7%B3%BB%E7%BB%9F%E5%AE%9E%E8%B7%B5/%E5%B8%B8%E7%94%A8%E7%9A%84%E5%8F%91%E5%B8%83%E6%96%B9%E5%BC%8F/%E8%93%9D%E7%BB%BF%E9%83%A8%E7%BD%B2.png&quot; alt=&quot;蓝绿部署&quot; loading=&quot;lazy&quot;/&gt;&lt;br/&gt;系统升级时，蓝绿部署的流程是：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;从负载均衡器列表中删除集群Group1，让集群 Group2 单独提供服务。&lt;/li&gt;
&lt;li&gt;在集群 Group1 上部署新版本。&lt;/li&gt;
&lt;li&gt;集群 Group1 升级完毕后，把负载均衡列表全部指向 Group1，并删除集群 Group2 ，由 Group1 单独提供服务。&lt;/li&gt;
&lt;li&gt;在集群 Group2 上部署完新版本后，再把它添加回负载均衡列表中。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;这样，就完成了两个集群上所有机器的版本升级。&lt;br/&gt;蓝绿部署的优点是升级和回退速度非常快，缺点是全量升级，如果V2版本有问题，对用户影响大再者由于升级过程中会服务器资源会减少一半，有可能产生服务器过载问题，因此这种发布方式也不适用于在业务高峰期使用。&lt;/p&gt;
&lt;h3 id=&quot;25-红黑发布&quot;&gt;2.5 红黑发布&lt;/h3&gt;
&lt;p&gt;与蓝绿部署类似，红黑部署也是通过两个集群完成软件版本的升级。当前提供服务的所有机器都运行在红色集群 Group1 中，当需要发布新版本的时候，具体流程是这样的：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;先申请一个黑色集群 Group2 ，在 Group2 上部署新版本的服务；&lt;/li&gt;
&lt;li&gt;等到 Group2 升级完成后，我们一次性地把负载均衡全部指向 Group2 ；&lt;/li&gt;
&lt;li&gt;把 Group1 集群从负载均衡列表中删除，并释放集群 Group1 中所有机器。这&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;这样就完成了一个版本的升级。可以看到，与蓝绿部署相比，红黑部署获得了两个收益：一是，简化了流程；二是，避免了在升级的过程中，由于只有一半的服务器提供服务，而可能导致的系统过载问题。但同样也存在全量升级对用户的影响问题，也带来了一个新的问题，就是发布过程中需要两倍的服务器资源。&lt;br/&gt;&lt;img src=&quot;https://hunter-image.oss-cn-beijing.aliyuncs.com/%E5%8F%AF%E9%9D%A0%E6%80%A7%E7%B3%BB%E7%BB%9F%E5%AE%9E%E8%B7%B5/%E5%B8%B8%E7%94%A8%E7%9A%84%E5%8F%91%E5%B8%83%E6%96%B9%E5%BC%8F/%E7%BA%A2%E9%BB%91%E5%8F%91%E5%B8%83.png&quot; alt=&quot;红黑发布.png&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h3 id=&quot;26-功能开关&quot;&gt;2.6 功能开关&lt;/h3&gt;
&lt;p&gt;这种发布方式是利用代码中的功能开关来控制发布逻辑，是一种相对比较低成本和简单的发布方式。研发人员可以灵活定制和自助完成的发布方式。这种方式通常依赖于一个配置中心系统，当然如果没有，可以使用简单的配置文件。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://hunter-image.oss-cn-beijing.aliyuncs.com/%E5%8F%AF%E9%9D%A0%E6%80%A7%E7%B3%BB%E7%BB%9F%E5%AE%9E%E8%B7%B5/%E5%B8%B8%E7%94%A8%E7%9A%84%E5%8F%91%E5%B8%83%E6%96%B9%E5%BC%8F/%E5%8A%9F%E8%83%BD%E5%BC%80%E5%85%B3.png&quot; alt=&quot;功能开关.png&quot; loading=&quot;lazy&quot;/&gt;&lt;br/&gt;应用上线后，开关先不打开，只待一声令下，可以全量打开开关，也可以按照某种维度(公司ID，用户ID等)分批打开开关进行流量验证，如果有问题，则随时关闭开关。&lt;br/&gt;这种方式的优势在于升级切换和回退速度非常快，而且相对于复杂的发布工具，成本较为低廉。但是也有很大的不足之处，就是开关本身也是代码，而且是与业务无关的代码，对代码的侵入性较高，也必须定期清理老版本的逻辑，使得维护成本增加。&lt;/p&gt;
&lt;h2 id=&quot;3-小结&quot;&gt;3 小结&lt;/h2&gt;
&lt;p&gt;这篇文章介绍了目前常用的一些发布方式，每种发布方式各有其优缺点。但其实在真正实践过程中这些发布方式往往是根据具体的情况来结合使用的。主要可以通过升级回退速度、成本、对用户影响三个方面来考虑。&lt;br/&gt;比如在我最开始的小型公司里，公司业务小，服务器资源也不足，甚至连最基础的负载均衡服务器都没有，这个时候我们的发布通常是选择一个流量小的时候进行蛮力发布的，这个时候也许会对用户造成短暂的影响，但那个时候的我们是没有人力物力财力......去搞后面那些复杂的方式的。&lt;br/&gt;而后来的某厂里有着充足的资源，我们有着多服务器群组，各种强大的发布工具......，通常我们是结合具体场景来选择合适的发布方式的。最常用的其中就是金丝雀发布和滚动发布。而在有些时候由于集群中的请求是随机分发的你并不能保证同一个用户的上一个请求和下一个请求还在同一个服务器上，这时如果旧的版本不能兼容新的版本的时候，如果是在业务流量低的时候，我们会考虑采用蓝绿部署的方式，如果在流量高峰期则会采用红黑发布的方式来避免服务器过载。&lt;br/&gt;而针对一些特殊的功能也经常会采用滚动发布+功能功能开关的方式。新版本发上去之后，逐步打开开关验证。&lt;br/&gt;总之，各种发布方式的本质目的都是为了提高我们的发布效率，保持系统可用性，减少对用户的影响能够让用户平滑的过渡到新的版本。&lt;/p&gt;
</description>
<pubDate>Thu, 21 Jan 2021 00:18:00 +0000</pubDate>
<dc:creator>老於`</dc:creator>
<og:description>1 发布之痛 相信每个程序员都曾经经历过，或正在经历过发布的痛苦，每个发布日的夜晚通常是灯火通明。在现在互联网公司较高的发布频率之下更是放大了这种痛苦，多少正值青春年华的程序员为此白了发、秃了头！让程</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/hunternet/p/14306105.html</dc:identifier>
</item>
<item>
<title>Golang应用性能问题排查分析 - 单行线的旋律</title>
<link>http://www.cnblogs.com/mycodingworld/p/golang_profiler.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/mycodingworld/p/golang_profiler.html</guid>
<description>&lt;h2 id=&quot;背景&quot;&gt;背景&lt;/h2&gt;
&lt;p&gt;公司有一个使用golang开发的采集模块，负责调用多个外部系统采集数据；最近做了一次架构上的调整，将采集模块分成api、job两个子模块，并部署到容器中，拆分前部署在虚机上。&lt;/p&gt;
&lt;h2 id=&quot;现象&quot;&gt;现象&lt;/h2&gt;
&lt;p&gt;部分采集任务在容器中的执行时间比虚机中执行时间要长，8倍左右，本地测试无异常&lt;/p&gt;
&lt;h2 id=&quot;排查思路&quot;&gt;排查思路&lt;/h2&gt;
&lt;h3 id=&quot;调用外部接口耗时过长？&quot;&gt;调用外部接口耗时过长？&lt;/h3&gt;
&lt;p&gt;只有部分任务执行时间长，怀疑容器调用那部分系统接口比较慢，于是在容器中curl外部接口接口，发现并不慢，排除这个可能。&lt;/p&gt;
&lt;h3 id=&quot;程序问题？&quot;&gt;程序问题？&lt;/h3&gt;
&lt;p&gt;将现有部署在虚机中的正常运行的应用，部署到容器中发现部分任务也会慢； 将部署在容器中的应用部署到虚机后恢复了正常；怀疑是容器本身或容器网络的问题，一时想不到是什么原因，于是开始了漫长的定位&lt;/p&gt;
&lt;h3 id=&quot;pprof&quot;&gt;pprof&lt;/h3&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;pprof是golang提供的性能分析工具之一，采集模块已经引入pprof，首先使用它进行排查;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;(1). 在容器中安装pprof/flamegraph&lt;sup&gt;1&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;(2). 在容器中执行如下命令,开启pprof的http服务&lt;br/&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1352870/202101/1352870-20210120220133610-789115542.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;(3).输入上述http地址&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;查看cpu profiler&lt;br/&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1352870/202101/1352870-20210120220142242-909155082.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;没有什么太大异常，只有少许执行逻辑消耗一秒多&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;&lt;li&gt;查看了top/flame graph都没有查看到什么异常&lt;br/&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1352870/202101/1352870-20210120220147657-1478735766.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1352870/202101/1352870-20210120220151609-1264039031.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;pprof中可以查看以下几类信息&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;cpu（CPU Profiling): $HOST/debug/pprof/profile，默认进行 30s 的 CPU Profiling，得到一个分析用的 profile 文件&lt;/li&gt;
&lt;li&gt;block（Block Profiling）：$HOST/debug/pprof/block，查看导致阻塞同步的堆栈跟踪&lt;/li&gt;
&lt;li&gt;goroutine：$HOST/debug/pprof/goroutine，查看当前所有运行的 goroutines 堆栈跟踪&lt;/li&gt;
&lt;li&gt;heap（Memory Profiling）: $HOST/debug/pprof/heap，查看活动对象的内存分配情况&lt;/li&gt;
&lt;li&gt;mutex（Mutex Profiling）：$HOST/debug/pprof/mutex，查看导致互斥锁的竞争持有者的堆栈跟踪&lt;/li&gt;
&lt;li&gt;threadcreate：$HOST/debug/pprof/threadcreate，查看创建新OS线程的堆栈跟踪&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;p&gt;由于跟网络有关系，所以想查看下io耗时，pprof无法实现我的需求，想到可以使用trace观察&lt;/p&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;期间又使用go-torch采集火焰图数据并查看，与pprof类似，感兴趣的同学可自行尝试&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&quot;trace&quot;&gt;trace&lt;/h3&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;trace也是go tool性能问题分析工具之一&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;(1) 打开trace&lt;br/&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1352870/202101/1352870-20210120220212474-415373834.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;br/&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1352870/202101/1352870-20210120220243927-710451425.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;主要有以下几块：Goroutine、网络阻塞、同步锁、同步阻塞等&lt;br/&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1352870/202101/1352870-20210120223052691-1729711601.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;(2) 观察网络IO&lt;br/&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1352870/202101/1352870-20210120220250768-387145236.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;一下子看到了60多秒，心里一阵窃喜，但从第一个节点开始已经是50多秒了，仍然不知道是什么原因造成的。又看了gorouting部分&lt;br/&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1352870/202101/1352870-20210120220304276-1003371504.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;看到network wait那一列耗时占比非常大，心里又是一阵窃喜，基本确定是网络的问题了，点击某一个gorouting进入grouting页面，再根据慢的任务名称找到相应gorouting，点击进入到trace页面&lt;br/&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1352870/202101/1352870-20210120220316596-124478263.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;由于network占用大多数时间，连续点了靠后的几个绿条，发现最后一条语句一样，到代码中查看，发现是调用redis的代码，于是在容器中ping redis服务器，又在虚机中ping,发现容器ping的响应时间是虚机的26倍左右；想到公司的服务器分多地部署，于是又查虚机、redis、容器的部署地域，发现虚机和redis在同一地域，而容器和redis服务器不在同一地域，这时才恍然大悟，后面的解决办法就简单了，不在此赘述了；&lt;/p&gt;
&lt;h2 id=&quot;总结&quot;&gt;总结&lt;/h2&gt;
&lt;p&gt;分析问题要从大到小，逐渐缩小范围，不能一上来就进入细节，这样会耗时较长。开始我怀疑是虚机网络问题，排查了外部系统接口，但遗漏了redis，造成后面花了几个小时仔细排查。其实也是情有可原吧，这个采集模块代码细节我并不熟悉，我的语言技术栈主要是Java,对golang语言不太熟悉，只因负责这个模块开发的同学束手无策，我是这个项目的负责人，只能赶鸭子上架了😃。一遇到问题，我就有一种莫名的小激动，因为遇到了我未知的领域，又有机会对技术有更深入的了解了。喜欢我文章的同学欢迎关注公众号哦，不定期分享干货！&lt;/p&gt;
&lt;h2 id=&quot;参考&quot;&gt;参考&lt;/h2&gt;
</description>
<pubDate>Thu, 21 Jan 2021 00:03:00 +0000</pubDate>
<dc:creator>单行线的旋律</dc:creator>
<og:description>背景 公司有一个使用golang开发的采集模块，负责调用多个外部系统采集数据；最近做了一次架构上的调整，将采集模块分成api、job两个子模块，并部署到容器中，拆分前部署在虚机上。 现象 部分采集任务</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/mycodingworld/p/golang_profiler.html</dc:identifier>
</item>
<item>
<title>【老孟Flutter】如何提高Flutter应用程序的性能 - 老孟Flutter</title>
<link>http://www.cnblogs.com/mengqd/p/14306082.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/mengqd/p/14306082.html</guid>
<description>&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/467322/202101/467322-20210121074423741-1450799829.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;首先 Flutter 是一个非常高性能的框架，因此大多时候不需要开发者做出特殊的处理，只需要避免常见的性能问题即可获得高性能的应用程序。&lt;/p&gt;
&lt;h4 id=&quot;重建最小化原则&quot;&gt;重建最小化原则&lt;/h4&gt;
&lt;p&gt;在调用 &lt;strong&gt;setState()&lt;/strong&gt; 方法重建组件时，一定要最小化重建组件，没有变化的组件不要重建，看下面的Demo，这是一个设置页面，&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-dart&quot;&gt;import 'package:flutter/material.dart';

class SettingDemo extends StatefulWidget {
  @override
  _SettingDemoState createState() =&amp;gt; _SettingDemoState();
}

class _SettingDemoState extends State&amp;lt;SettingDemo&amp;gt; {

  Widget _item(
      {IconData iconData, Color iconColor, String title, Widget suffix}) {
    return Container(
      height: 45,
      child: Row(
        children: &amp;lt;Widget&amp;gt;[
          SizedBox(
            width: 30,
          ),
          Icon(
            iconData,
            color: iconColor,
          ),
          SizedBox(
            width: 30,
          ),
          Expanded(
            child: Text('$title'),
          ),
          suffix,
          SizedBox(
            width: 15,
          ),
        ],
      ),
    );
  }

  bool _switchValue = false;

  @override
  Widget build(BuildContext context) {
    return Column(
      children: &amp;lt;Widget&amp;gt;[
        _item(
          iconData: Icons.notifications,
          iconColor: Colors.blue,
          title: '是否允许4G网络下载',
          suffix: Switch(
              value: _switchValue,
              onChanged: (value) {
                setState(() {
                  _switchValue = value;
                });
              }),
        ),
        Divider(),
        _item(
          iconData: Icons.notifications,
          iconColor: Colors.blue,
          title: '消息中心',
          suffix: Text(
            '12条',
            style: TextStyle(color: Colors.grey.withOpacity(.5)),
          ),
        ),
        Divider(),
        _item(
          iconData: Icons.thumb_up,
          iconColor: Colors.green,
          title: '我赞过的',
          suffix: Text(
            '121篇',
            style: TextStyle(color: Colors.grey.withOpacity(.5)),
          ),
        ),
        Divider(),
        _item(
          iconData: Icons.grade,
          iconColor: Colors.yellow,
          title: '收藏集',
          suffix: Text(
            '2个',
            style: TextStyle(color: Colors.grey.withOpacity(.5)),
          ),
        ),
        Divider(),
        _item(
          iconData: Icons.account_balance_wallet,
          iconColor: Colors.blue,
          title: '我的钱包',
          suffix: Text(
            '10万',
            style: TextStyle(color: Colors.grey.withOpacity(.5)),
          ),
        ),
      ],
    );
  }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/467322/202101/467322-20210121074425976-1229449527.gif&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;注意看上图右边下半部分，点击切换&lt;strong&gt;开关&lt;/strong&gt;的时候，所有的组件全部重建了，理想情况下，应该只是 &lt;strong&gt;Switch&lt;/strong&gt; 组件进行切换，因此将 &lt;strong&gt;Switch&lt;/strong&gt; 组件进行封装：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-dart&quot;&gt;class _SwitchWidget extends StatefulWidget {
  final bool value;

  const _SwitchWidget({Key key, this.value}) : super(key: key);

  @override
  __SwitchWidgetState createState() =&amp;gt; __SwitchWidgetState();
}

class __SwitchWidgetState extends State&amp;lt;_SwitchWidget&amp;gt; {
  bool _value;

  @override
  void initState() {
    _value = widget.value;
    super.initState();
  }

  @override
  Widget build(BuildContext context) {
    return Switch(
      value: _value,
      onChanged: (value) {
        setState(() {
          _value = value;
        });
      },
    );
  }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;使用：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-dart&quot;&gt;_item(
  iconData: Icons.notifications,
  iconColor: Colors.blue,
  title: '是否允许4G网络下载',
  suffix: _SwitchWidget(
    value: false,
  ),
)
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/467322/202101/467322-20210121074428097-1326617972.gif&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;此时看到重建的组件只有 &lt;strong&gt;_SwitchWidget&lt;/strong&gt; 和 &lt;strong&gt;Switch&lt;/strong&gt; 组件，提高了性能。&lt;/p&gt;
&lt;p&gt;如果 &lt;strong&gt;Switch&lt;/strong&gt; 组件的状态改变也会改变其它组件的状态，这是典型的组件间通信，这种情况下可以使用 &lt;strong&gt;InheritedWidget&lt;/strong&gt;，但更建议使用状态管理框架（比如 &lt;strong&gt;Provider&lt;/strong&gt; 等），而不是将其父组件改变为StatefulWidget。&lt;/p&gt;
&lt;p&gt;尽量不要将整个页面定义为 &lt;strong&gt;StatefulWidget&lt;/strong&gt; 组件，因为一旦重建将重建此页面下所有的组件，尤其是 Switch 、Radio等组件状态的改变导致的重建，强烈建议对其进行封装。&lt;/p&gt;
&lt;p&gt;这里有一个误区，有些人认为，将组件拆分为方法可以减少重建，就比如上面的例子，将 &lt;strong&gt;_SwitchWidget&lt;/strong&gt; 组件改变为方法，该方法返回 Switch 组件，这是错误的，此种方式并不能减少重建， 但是将一个组件拆分为多个小组件是可以减少重建的，就像上面的例子，将需要重建的 Switch 封装为一个单独的 &lt;strong&gt;StatefulWidget&lt;/strong&gt; 组件，避免了其他不必要的重建。&lt;/p&gt;
&lt;h4 id=&quot;强烈建议：在组件前加上-const&quot;&gt;强烈建议：在组件前加上 const&lt;/h4&gt;
&lt;p&gt;在组件前加上 &lt;strong&gt;const&lt;/strong&gt; ，相当于对此组件进行了缓存，下面是未加 &lt;strong&gt;const&lt;/strong&gt; 的代码：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-dart&quot;&gt;class ConstDemo extends StatefulWidget {
  @override
  _ConstDemoState createState() =&amp;gt; _ConstDemoState();
}

class _ConstDemoState extends State&amp;lt;ConstDemo&amp;gt; {
  @override
  Widget build(BuildContext context) {
    return Center(
      child: Column(
        children: [
          Text('老孟'),
          RaisedButton(onPressed: (){
            setState(() {

            });
          })
        ],
      ),
    );
  }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/467322/202101/467322-20210121074430248-1018427599.gif&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;给 &lt;strong&gt;Text('老孟')&lt;/strong&gt; 组件加上 &lt;strong&gt;const&lt;/strong&gt;：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-dart&quot;&gt;const Text('老孟'),
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/467322/202101/467322-20210121074431439-1598568676.gif&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;对比两次 &lt;strong&gt;Text&lt;/strong&gt; 组件的重建情况，加上 &lt;strong&gt;const&lt;/strong&gt; 后，未重建。&lt;/p&gt;
&lt;h4 id=&quot;避免更改组件树的结构和组件的类型&quot;&gt;避免更改组件树的结构和组件的类型&lt;/h4&gt;
&lt;p&gt;有如下场景，有一个 &lt;strong&gt;Text&lt;/strong&gt; 组件有可见和不可见两种状态，代码如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-dart&quot;&gt;bool _visible = true;

@override
Widget build(BuildContext context) {
  return Center(
    child: Column(
      children: [
        if(_visible)
          Text('可见'),
        Container(),
      ],
    ),
  );
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;可见时的组件树：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/467322/202101/467322-20210121074431751-959928878.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;不可见时的组件树：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/467322/202101/467322-20210121074431975-453218468.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;两种状态组件树结构发生变化，应该避免发生此种情况，优化如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-dart&quot;&gt;Center(
  child: Column(
    children: [
      Visibility(
        visible: _visible,
        child: Text('可见'),
      ),
      Container(),
    ],
  ),
)
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;此时不管是可见还是不可见状态，组件树都不会发生变化，如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/467322/202101/467322-20210121074432251-1843834505.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;还有一种情况是根据不同的条件构建不同的组件，如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-dart&quot;&gt;bool _showButton = true;

@override
Widget build(BuildContext context) {
  return Center(
    child: Column(
      children: [
        _showButton ? RaisedButton(onPressed: null) : Text('不显示'),
        Container(),
      ],
    ),
  );
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;设置为 &lt;strong&gt;true&lt;/strong&gt; 时的组件树结构：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/467322/202101/467322-20210121074432447-1736630653.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;设置为 &lt;strong&gt;false&lt;/strong&gt; 时的组件树结构：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/467322/202101/467322-20210121074432661-716495055.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;看到左侧子节点由 &lt;strong&gt;RaisedButton&lt;/strong&gt; 变为了 &lt;strong&gt;Text&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;上面的情况组件树发生了更改，不管是类型发生更改，还是深度发生更改，如果无法避免，那么就将变化的组件树封装为一个 &lt;strong&gt;StatefulWidget&lt;/strong&gt; 组件，且设置 &lt;strong&gt;GlobalKey&lt;/strong&gt;，如下：&lt;/p&gt;
&lt;p&gt;封装变化的部分：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-dart&quot;&gt;class ChildWidget extends StatefulWidget {
  const ChildWidget({Key key}) : super(key: key);

  @override
  _ChildWidgetState createState() =&amp;gt; _ChildWidgetState();
}

class _ChildWidgetState extends State&amp;lt;ChildWidget&amp;gt; {
  bool _showButton = true;

  @override
  Widget build(BuildContext context) {
    return _showButton ? RaisedButton(onPressed: null) : Text('不显示');
  }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;构建：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-dart&quot;&gt;class ConstDemo extends StatefulWidget {
  @override
  _ConstDemoState createState() =&amp;gt; _ConstDemoState();
}

class _ConstDemoState extends State&amp;lt;ConstDemo&amp;gt; {
  @override
  Widget build(BuildContext context) {
    return Center(
      child: Column(
        children: [
          ChildWidget(key: GlobalKey(),),
          Container(),
        ],
      ),
    );
  }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;虽然通过 &lt;strong&gt;GlobalKey&lt;/strong&gt; 提高了上面案例的性能，但我们千万不要乱用 &lt;strong&gt;GlobalKey&lt;/strong&gt;，因为管理 &lt;strong&gt;GlobalKey&lt;/strong&gt; 的成本很高，所以其他需要使用 &lt;strong&gt;Key&lt;/strong&gt; 的地方建议考虑使用 &lt;strong&gt;Key, ValueKey, ObjectKey, 和 UniqueKey&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;关于 &lt;strong&gt;GlobalKey&lt;/strong&gt; 的相关说明参考：&lt;a href=&quot;https://api.flutter.dev/flutter/widgets/GlobalKey-class.html&quot; target=&quot;_blank&quot;&gt;https://api.flutter.dev/flutter/widgets/GlobalKey-class.html&lt;/a&gt;&lt;/p&gt;
&lt;h4 id=&quot;关于listview-的优化&quot;&gt;关于ListView 的优化&lt;/h4&gt;
&lt;p&gt;ListView是我们最常用的组件之一，用于展示大量数据的列表。如果展示大量数据请使用 &lt;strong&gt;ListView.builder&lt;/strong&gt; 或者 &lt;strong&gt;ListView.separated&lt;/strong&gt;，千万不要直接使用如下方式：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-dart&quot;&gt;ListView(
  children: &amp;lt;Widget&amp;gt;[
    item,item1,item2,...
  ],
)
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;这种方式一次加载所有的组件，没有“懒加载”，消耗极大的性能。&lt;/p&gt;
&lt;p&gt;ListView 中 &lt;strong&gt;itemExtent&lt;/strong&gt; 属性对动态滚动到性能提升非常大，比如，有2000条数据展示，点击按钮滚动到最后，代码如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-dart&quot;&gt;class ListViewDemo extends StatefulWidget {
  @override
  _ListViewDemoState createState() =&amp;gt; _ListViewDemoState();
}

class _ListViewDemoState extends State&amp;lt;ListViewDemo&amp;gt; {
  ScrollController _controller;

  @override
  void initState() {
    super.initState();
    _controller = ScrollController();
  }

  @override
  Widget build(BuildContext context) {
    return Stack(
      children: [
        ListView.builder(
          controller: _controller,
          itemBuilder: (context, index) {
            return Container(
              height: 80,
              alignment: Alignment.center,
              color: Colors.primaries[index % Colors.primaries.length],
              child: Text('$index',style: TextStyle(color: Colors.white,fontSize: 20),),
            );
          },
          itemCount: 2000,
        ),
        Positioned(
            child: RaisedButton(
          child: Text('滚动到最后'),
          onPressed: () {
            _controller.jumpTo(_controller.position.maxScrollExtent);
          },
        ))
      ],
    );
  }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/467322/202101/467322-20210121074433135-246466498.gif&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;耗时在&lt;strong&gt;2秒&lt;/strong&gt;左右，加上 &lt;strong&gt;itemExtent&lt;/strong&gt; 属性，修改如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-dart&quot;&gt;ListView.builder(
  controller: _controller,
  itemBuilder: (context, index) {
    return Container(
      height: 80,
      alignment: Alignment.center,
      color: Colors.primaries[index % Colors.primaries.length],
      child: Text('$index',style: TextStyle(color: Colors.white,fontSize: 20),),
    );
  },
  itemExtent: 80,
  itemCount: 2000,
)
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/467322/202101/467322-20210121074433668-1239532096.gif&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;优化后瞬间跳转到底部。&lt;/p&gt;
&lt;p&gt;这是因为不设置 &lt;strong&gt;itemExtent&lt;/strong&gt; 属性，将会由子组件自己决定大小，大量的计算导致UI堵塞。&lt;/p&gt;
&lt;h4 id=&quot;关于-animatedbuilder-tweenanimationbuilder-的优化&quot;&gt;关于 AnimatedBuilder TweenAnimationBuilder 的优化&lt;/h4&gt;
&lt;p&gt;这里说的是向AnimatedBuilder 、TweenAnimationBuilder 等一类的组件的问题，这些组件都有一个共同点，带有 &lt;strong&gt;builder&lt;/strong&gt; 且其参数重有 &lt;strong&gt;child&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;以 AnimatedBuilder 为例，如果 &lt;strong&gt;builder&lt;/strong&gt; 中构建的树中包含与动画无关的组件，将这些无关的组件当作 &lt;strong&gt;child&lt;/strong&gt; 传递到 &lt;strong&gt;builder&lt;/strong&gt; 中比直接在 &lt;strong&gt;builder&lt;/strong&gt; 中构建更加有效。&lt;/p&gt;
&lt;p&gt;比如下面的代码，直接在 &lt;strong&gt;builder&lt;/strong&gt; 中构建子组件：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;AnimatedBuilder(
    animation: animation,
    builder: (BuildContext context, Widget child) {
      return Transform.rotate(
        angle: animation.value,
        child: FlutterLogo(size: 60,),
      );
    },
  )
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;优化后的代码：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-dart&quot;&gt;AnimatedBuilder(
    animation: animation,
    builder: (BuildContext context, Widget child) {
      return Transform.rotate(
        angle: animation.value,
        child: child,
      );
    },
    child: FlutterLogo(size: 60,),
  )
&lt;/code&gt;
&lt;/pre&gt;
&lt;h4 id=&quot;谨慎的使用一些组件&quot;&gt;谨慎的使用一些组件&lt;/h4&gt;
&lt;p&gt;部分组件一定要谨慎使用，因为这些组件包含一些昂贵的操作，比如 &lt;strong&gt;saveLayer()&lt;/strong&gt; 方法。&lt;/p&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;调用saveLayer（）会分配一个屏幕外缓冲区。 将内容绘制到屏幕外缓冲区中可能会触发渲染目标切换，这在较早的GPU中特别慢。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;另外虽然下面这些组件比较消耗性能，但并不是禁止大家使用，而是谨慎使用，如果有替代方案，考虑使用替代方法。&lt;/p&gt;
&lt;p&gt;尤其注意，如果这些组件频繁重建（比如动画的过程），要重点优化。&lt;/p&gt;
&lt;h5 id=&quot;clip-类组件&quot;&gt;Clip 类组件&lt;/h5&gt;
&lt;p&gt;Clip 类组件是常用的裁剪类组件，比如：ClipOval、ClipPath、ClipRRect、ClipRect、CustomClipper。这些组件中都有 &lt;strong&gt;clipBehavior&lt;/strong&gt; 属性，不同的值性能是不同的，&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-dart&quot;&gt;///  * [hardEdge], which is the fastest clipping, but with lower fidelity.
///  * [antiAlias], which is a little slower than [hardEdge], but with smoothed edges.
///  * [antiAliasWithSaveLayer], which is much slower than [antiAlias], and should
///    rarely be used.
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;越往下，速度越慢。&lt;/p&gt;
&lt;p&gt;一些简单的圆角组件的设置可以使用 Container 实现：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-dart&quot;&gt;Container(
      height: 200,
      width: 200,
      decoration: BoxDecoration(
        image:  DecorationImage(
          image: NetworkImage(
              'https://flutter.github.io/assets-for-api-docs/assets/widgets/owl-2.jpg'),
          fit: BoxFit.cover,
        ),
        border: Border.all(
          color: Colors.blue,
          width: 2,
        ),
        borderRadius: BorderRadius.circular(12),
      ),
    )
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/467322/202101/467322-20210121074434064-374994635.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h5 id=&quot;opacity&quot;&gt;Opacity&lt;/h5&gt;
&lt;p&gt;&lt;strong&gt;Opacity&lt;/strong&gt; 组件的功能是使子组件透明。此类将其子级绘制到中间缓冲区中，然后将子级混合回到部分透明的场景中。&lt;/p&gt;
&lt;p&gt;对于除0.0和1.0之外的不透明度值，此类相对昂贵，因为它需要将子级绘制到中间缓冲区中。 对于值0.0，根本不绘制子级。 对于值1.0，将立即绘制没有中间缓冲区的子对象。&lt;/p&gt;
&lt;p&gt;如果仅仅是对单个 Image 或者 Color 增加透明度，直接使用比 &lt;strong&gt;Opacity&lt;/strong&gt; 组件更快：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-dart&quot;&gt; Container(color: Color.fromRGBO(255, 0, 0, 0.5))
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;比使用 &lt;strong&gt;Opacity&lt;/strong&gt; 组件更快：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-dart&quot;&gt;Opacity(opacity: 0.5, child: Container(color: Colors.red))
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;如果对组件的透明度进行动画操作，建议使用 &lt;strong&gt;AnimatedOpacity&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;还有一些组件也要慎重使用，比如：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;ShaderMask&lt;/li&gt;
&lt;li&gt;ColorFilter&lt;/li&gt;
&lt;li&gt;BackdropFilter&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;文中如果有不完善或者不正确的地方欢迎提出意见，后面如果优化的补充将会在我的博客中进行补充，地址：&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://laomengit.com/blog/20201227/improve_performance.html&quot; target=&quot;_blank&quot;&gt;http://laomengit.com/blog/20201227/improve_performance.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;参考链接：&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://flutter.dev/docs/perf/rendering/best-practices&quot; target=&quot;_blank&quot;&gt;https://flutter.dev/docs/perf/rendering/best-practices&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://api.flutter.dev/flutter/widgets/Opacity-class.html#transparent-image&quot; target=&quot;_blank&quot;&gt;https://api.flutter.dev/flutter/widgets/Opacity-class.html#transparent-image&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://api.flutter.dev/flutter/widgets/StatefulWidget-class.html#performance-considerations&quot; target=&quot;_blank&quot;&gt;https://api.flutter.dev/flutter/widgets/StatefulWidget-class.html#performance-considerations&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;交流&quot;&gt;交流&lt;/h2&gt;
&lt;p&gt;老孟Flutter博客（330个控件用法+实战入门系列文章）：&lt;a href=&quot;http://laomengit.com&quot; target=&quot;_blank&quot;&gt;http://laomengit.com&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;添加微信或者公众号领取 《330个控件大全》和 《Flutter 实战》PDF。&lt;/p&gt;
&lt;p&gt;欢迎加入Flutter交流群（微信：laomengit）、关注公众号【老孟Flutter】：&lt;/p&gt;
&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th/&gt;
&lt;th/&gt;
&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/467322/202101/467322-20210121074434411-1181138324.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/td&gt;
&lt;td&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/467322/202101/467322-20210121074434736-1274201145.jpg&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;</description>
<pubDate>Wed, 20 Jan 2021 23:45:00 +0000</pubDate>
<dc:creator>老孟Flutter</dc:creator>
<og:description>首先 Flutter 是一个非常高性能的框架，因此大多时候不需要开发者做出特殊的处理，只需要避免常见的性能问题即可获得高性能的应用程序。 重建最小化原则 在调用 setState() 方法重建组件时，</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/mengqd/p/14306082.html</dc:identifier>
</item>
<item>
<title>容器编排系统K8s之包管理器Helm基础使用 - Linux-1874</title>
<link>http://www.cnblogs.com/qiuhom-1874/p/14305902.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/qiuhom-1874/p/14305902.html</guid>
<description>&lt;p&gt;　　前文我们了解了k8s上的hpa资源的使用，回顾请参考：&lt;a href=&quot;https://www.cnblogs.com/qiuhom-1874/p/14293237.html&quot; target=&quot;_blank&quot;&gt;https://www.cnblogs.com/qiuhom-1874/p/14293237.html&lt;/a&gt;；今天我们来聊一下k8s包管理器helm的相关话题；&lt;/p&gt;
&lt;p&gt;　　helm是什么？&lt;/p&gt;
&lt;p&gt;　　如果我们把k8s的资源清单类比成centos上的rpm包，那么helm的作用就如同yum；简单讲helm就是类似yum这样的包管理器，它能够让我们在k8s上部署应用变得简单，我们需要部署某些应用到k8s上，我们直接使用helm就可以完成一键部署；有了helm工具，我们甚至都不需要再写什么资源清单了；对于helm来说，它只是把对应应用需要的资源清单通过模板引擎，将对应资模板源清单赋值以后，发送给k8s进行应用，从而实现把应用部署到k8s上；我们把部署到k8s上的应用称为release；即把模板资源清单通过模板引擎渲染以后，部署到k8s上的就称为一个release；模板文件是从哪里来呢？如同rpm仓库，这里的模板文件也是从仓库来，简单讲helm仓库就是用来存放各种应用的模板清单打包文件，我们把这个打包文件称为chart，即helm仓库也叫chart仓库，主要用来存放各种应用的打包文件；一个打包文件最主要的有chart.yaml,README.md，templates目录，values.yaml；其中chart.yaml文件主要用来对应应用的元数据信息；README.md主要是用来自述该chart怎么使用，部署等等说明；templates目录使用来存放各种资源模板文件；templates目录中有一个比较重要的文件NOTES.txt，该文件也是一个模板文件，主要作用是把对应chart安装成功的信息通过模板引擎渲染以后输出给用户，告诉用户如何使用对应chart；vlues.yaml文件主要用来存放该chart的模板的默认值，用户不指定，其内部模板中的值就是对应values.yaml的值；正是因为chart中存放的都是模板资源清单，使得用户可以自定义value.yaml文件，通过指定自定义value.yaml来实现自定义chart的目的；&lt;/p&gt;
&lt;p&gt;　　helm的工具安装&lt;/p&gt;
&lt;p&gt;　　helm 2的部署稍微有点麻烦，早期helm2是由两个组件组成，第一个是命令行工具helm，第二个是k8s上的tiller Pod；tiller是服务端，主要接受helm发送到chart，然后由tiller联系apiserver进行对应chart的部署；现在helm的版本是3.0+，对于之前helm2的方式，helm3进行了简化，即helm不再依赖tiller这个组件，它可以直接同apiserver进行交互，将对应chart部署到k8s上；使用helm3的前提是对应主机能够正常连接k8s的apiserver，并且对应主机上有kubectl命令，即对应主机必须能使用kubectl命令来管理对应k8s集群；这其中的原因是helm它会使用kubectl工具的认证信息到apiserver进行交互；&lt;/p&gt;
&lt;p&gt;　　一、helm3的安装&lt;/p&gt;
&lt;p&gt;　　下载二进制包&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;39&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
[root@master01 ~]# mkdir helm
[root@master01 ~]# cd helm/
[root@master01 helm]# wget https://get.helm.sh/helm-v3.5.0-linux-amd64.tar.gz
--2021-01-20 21:10:33--  https://get.helm.sh/helm-v3.5.0-linux-amd64.tar.gz
Resolving get.helm.sh (get.helm.sh)... 152.195.19.97, 2606:2800:11f:1cb7:261b:1f9c:2074:3c
Connecting to get.helm.sh (get.helm.sh)|152.195.19.97|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: 12327633 (12M) [application/x-tar]
Saving to: ‘helm-v3.5.0-linux-amd64.tar.gz’

100%[==================================================================================================================================&amp;gt;] 12,327,633  9.17MB/s   in 1.3s   

2021-01-20 21:10:35 (9.17 MB/s) - ‘helm-v3.5.0-linux-amd64.tar.gz’ saved [12327633/12327633]
[root@master01 helm]#ls
helm-v3.5.0-linux-amd64.tar.gz
[root@master01 helm]
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　解压包&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;34&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
[root@master01 helm]# tar xf helm-v3.5.0-linux-amd64.tar.gz 
[root@master01 helm]# ls
helm-v3.5.0-linux-amd64.tar.gz  linux-amd64
[root@master01 helm]# cd linux-amd64/
[root@master01 linux-amd64]# ls
helm  LICENSE  README.md
[root@master01 linux-amd64]# 
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　复制helm二进制文件到path环境变量目录下&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;33&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
[root@master01 linux-amd64]# cp helm /usr/bin/
[root@master01 linux-amd64]# hel
helm  help  
[root@master01 linux-amd64]# hel
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　二、helm的使用&lt;/p&gt;
&lt;p&gt;　　查看helm版本&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;36&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
[root@master01 ~]# helm version
version.BuildInfo{Version:&quot;v3.5.0&quot;, GitCommit:&quot;32c22239423b3b4ba6706d450bd044baffdcf9e6&quot;, GitTreeState:&quot;clean&quot;, GoVersion:&quot;go1.15.6&quot;}
[root@master01 ~]# 
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　查看helm帮助&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;53&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
[root@master01 ~]# helm -h
The Kubernetes package manager

Common actions for Helm:

- helm search:    search for charts
- helm pull:      download a chart to your local directory to view
- helm install:   upload the chart to Kubernetes
- helm list:      list releases of charts

Environment variables:

| Name                               | Description                                                                       |
|------------------------------------|-----------------------------------------------------------------------------------|
| $HELM_CACHE_HOME                   | set an alternative location for storing cached files.                             |
| $HELM_CONFIG_HOME                  | set an alternative location for storing Helm configuration.                       |
| $HELM_DATA_HOME                    | set an alternative location for storing Helm data.                                |
| $HELM_DEBUG                        | indicate whether or not Helm is running in Debug mode                             |
| $HELM_DRIVER                       | set the backend storage driver. Values are: configmap, secret, memory, postgres   |
| $HELM_DRIVER_SQL_CONNECTION_STRING | set the connection string the SQL storage driver should use.                      |
| $HELM_MAX_HISTORY                  | set the maximum number of helm release history.                                   |
| $HELM_NAMESPACE                    | set the namespace used for the helm operations.                                   |
| $HELM_NO_PLUGINS                   | disable plugins. Set HELM_NO_PLUGINS=1 to disable plugins.                        |
| $HELM_PLUGINS                      | set the path to the plugins directory                                             |
| $HELM_REGISTRY_CONFIG              | set the path to the registry config file.                                         |
| $HELM_REPOSITORY_CACHE             | set the path to the repository cache directory                                    |
| $HELM_REPOSITORY_CONFIG            | set the path to the repositories file.                                            |
| $KUBECONFIG                        | set an alternative Kubernetes configuration file (default &quot;~/.kube/config&quot;)       |
| $HELM_KUBEAPISERVER                | set the Kubernetes API Server Endpoint for authentication                         |
| $HELM_KUBECAFILE                   | set the Kubernetes certificate authority file.                                    |
| $HELM_KUBEASGROUPS                 | set the Groups to use for impersonation using a comma-separated list.             |
| $HELM_KUBEASUSER                   | set the Username to impersonate for the operation.                                |
| $HELM_KUBECONTEXT                  | set the name of the kubeconfig context.                                           |
| $HELM_KUBETOKEN                    | set the Bearer KubeToken used for authentication.                                 |

Helm stores cache, configuration, and data based on the following configuration order:

- If a HELM_*_HOME environment variable is set, it will be used
- Otherwise, on systems supporting the XDG base directory specification, the XDG variables will be used
- When no other location is set a default location will be used based on the operating system

By default, the default directories depend on the Operating System. The defaults are listed below:

| Operating System | Cache Path                | Configuration Path             | Data Path               |
|------------------|---------------------------|--------------------------------|-------------------------|
| Linux            | $HOME/.cache/helm         | $HOME/.config/helm             | $HOME/.local/share/helm |
| macOS            | $HOME/Library/Caches/helm | $HOME/Library/Preferences/helm | $HOME/Library/helm      |
| Windows          | %TEMP%\helm               | %APPDATA%\helm                 | %APPDATA%\helm          |

Usage:
  helm [command]

Available Commands:
  completion  generate autocompletion scripts for the specified shell
  create      create a new chart with the given name
  dependency  manage a chart's dependencies
  env         helm client environment information
  get         download extended information of a named release
  help        Help about any command
  history     fetch release history
  install     install a chart
  lint        examine a chart for possible issues
  list        list releases
  package     package a chart directory into a chart archive
  plugin      install, list, or uninstall Helm plugins
  pull        download a chart from a repository and (optionally) unpack it in local directory
  repo        add, list, remove, update, and index chart repositories
  rollback    roll back a release to a previous revision
  search      search for a keyword in charts
  show        show information of a chart
  status      display the status of the named release
  template    locally render templates
  test        run tests for a release
  uninstall   uninstall a release
  upgrade     upgrade a release
  verify      verify that a chart at the given path has been signed and is valid
  version     print the client version information

Flags:
      --debug                       enable verbose output
  -h, --help                        help for helm
      --kube-apiserver string       the address and the port for the Kubernetes API server
      --kube-as-group stringArray   group to impersonate for the operation, this flag can be repeated to specify multiple groups.
      --kube-as-user string         username to impersonate for the operation
      --kube-ca-file string         the certificate authority file for the Kubernetes API server connection
      --kube-context string         name of the kubeconfig context to use
      --kube-token string           bearer token used for authentication
      --kubeconfig string           path to the kubeconfig file
  -n, --namespace string            namespace scope for this request
      --registry-config string      path to the registry config file (default &quot;/root/.config/helm/registry.json&quot;)
      --repository-cache string     path to the file containing cached repository indexes (default &quot;/root/.cache/helm/repository&quot;)
      --repository-config string    path to the file containing repository names and URLs (default &quot;/root/.config/helm/repositories.yaml&quot;)

Use &quot;helm [command] --help&quot; for more information about a command.
[root@master01 ~]# 
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　查看仓库列表&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;41&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
[root@master01 ~]# helm repo -h

This command consists of multiple subcommands to interact with chart repositories.

It can be used to add, remove, list, and index chart repositories.

Usage:
  helm repo [command]

Available Commands:
  add         add a chart repository
  index       generate an index file given a directory containing packaged charts
  list        list chart repositories
  remove      remove one or more chart repositories
  update      update information of available charts locally from chart repositories

Flags:
  -h, --help   help for repo

Global Flags:
      --debug                       enable verbose output
      --kube-apiserver string       the address and the port for the Kubernetes API server
      --kube-as-group stringArray   group to impersonate for the operation, this flag can be repeated to specify multiple groups.
      --kube-as-user string         username to impersonate for the operation
      --kube-ca-file string         the certificate authority file for the Kubernetes API server connection
      --kube-context string         name of the kubeconfig context to use
      --kube-token string           bearer token used for authentication
      --kubeconfig string           path to the kubeconfig file
  -n, --namespace string            namespace scope for this request
      --registry-config string      path to the registry config file (default &quot;/root/.config/helm/registry.json&quot;)
      --repository-cache string     path to the file containing cached repository indexes (default &quot;/root/.cache/helm/repository&quot;)
      --repository-config string    path to the file containing repository names and URLs (default &quot;/root/.config/helm/repositories.yaml&quot;)

Use &quot;helm repo [command] --help&quot; for more information about a command.
[root@master01 ~]# helm repo list
Error: no repositories to show
[root@master01 ~]# 
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　提示：这里提示我们没有仓库；&lt;/p&gt;
&lt;p&gt;　　添加仓库&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;34&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
[root@master01 ~]# helm repo add stable https://charts.helm.sh/stable
&quot;stable&quot; has been added to your repositories
[root@master01 ~]# helm repo list
NAME    URL                          
stable  https://charts.helm.sh/stable
[root@master01 ~]# 
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　提示：添加仓库需要连接到对应仓库，如果你的服务器无法正常连接到对应仓库，请使用代理，具体代理方式就是在对应shell终端使用HTTPS_PROXY环境变量赋予一个可以用的代理地址；如HTTPS_PROXY=&quot;http://www.ik8s.io:10080&quot;，使用代理环境变量的同时需要注意把对应不需要代理的地址给出来，比如本地地址不需要代理可以使用NO_PROXY=&quot;127.0.0.0/8,192.168.0.0/24&quot;；否则我们使用kubectl它都会代理到我们给定的代理地址上；&lt;/p&gt;
&lt;p&gt;　　搜索chart&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1503305/202101/1503305-20210120220228773-862786670.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　提示：helm search repo表示列出已经添加的仓库中所有chart；&lt;/p&gt;
&lt;p&gt;　　在仓库中搜索redis&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;36&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
[root@master01 ~]# helm search repo redis
NAME                                    CHART VERSION   APP VERSION     DESCRIPTION                                       
stable/prometheus-redis-exporter        3.5.1           1.3.4           DEPRECATED Prometheus exporter for Redis metrics  
stable/redis                            10.5.7          5.0.7           DEPRECATED Open source, advanced key-value stor...
stable/redis-ha                         4.4.6           5.0.6           DEPRECATED - Highly available Kubernetes implem...
stable/sensu                            0.2.5           0.28            DEPRECATED Sensu monitoring framework backed by...
[root@master01 ~]# 
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　安装stable/redis&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;40&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
[root@master01 ~]# helm install redis-demo stable/redis
WARNING: This chart is deprecated
NAME: redis-demo
LAST DEPLOYED: Wed Jan 20 22:27:18 2021
NAMESPACE: default
STATUS: deployed
REVISION: 1
TEST SUITE: None
NOTES:
This Helm chart is deprecated

Given the `stable` deprecation timeline (https://github.com/helm/charts#deprecation-timeline), the Bitnami maintained Redis Helm chart is now located at bitnami/charts (https://github.com/bitnami/charts/).

The Bitnami repository is already included in the Hubs and we will continue providing the same cadence of updates, support, etc that we've been keeping here these years. Installation instructions are very similar, just adding the _bitnami_ repo and using it during the installation (`bitnami/&amp;lt;chart&amp;gt;` instead of `stable/&amp;lt;chart&amp;gt;`)

```bash
$ helm repo add bitnami https://charts.bitnami.com/bitnami
$ helm install my-release bitnami/&amp;lt;chart&amp;gt;           # Helm 3
$ helm install --name my-release bitnami/&amp;lt;chart&amp;gt;    # Helm 2
```

To update an exisiting _stable_ deployment with a chart hosted in the bitnami repository you can execute
 ```bash                                                                                                                                                                                                                                                                                                                                                                    $ helm
 repo add bitnami https://charts.bitnami.com/bitnami
  $ helm upgrade my-release bitnami/&amp;lt;chart&amp;gt;
  ```

  Issues and PRs related to the chart itself will be redirected to `bitnami/charts` GitHub repository. In the same way, we'll be happy to answer questions related to this migration process in this issue (https://github.com/helm/charts/issues/20969) created as a common place for discussion.

** Please be patient while the chart is being deployed **
Redis can be accessed via port 6379 on the following DNS names from within your cluster:

redis-demo-master.default.svc.cluster.local for read/write operations
redis-demo-slave.default.svc.cluster.local for read-only operations


To get your password run:

    export REDIS_PASSWORD=$(kubectl get secret --namespace default redis-demo -o jsonpath=&quot;{.data.redis-password}&quot; | base64 --decode)

To connect to your Redis server:

1. Run a Redis pod that you can use as a client:

   kubectl run --namespace default redis-demo-client --rm --tty -i --restart='Never' \
    --env REDIS_PASSWORD=$REDIS_PASSWORD \
   --image docker.io/bitnami/redis:5.0.7-debian-10-r32 -- bash

2. Connect using the Redis CLI:
   redis-cli -h redis-demo-master -a $REDIS_PASSWORD
   redis-cli -h redis-demo-slave -a $REDIS_PASSWORD

To connect to your database from outside the cluster execute the following commands:

    kubectl port-forward --namespace default svc/redis-demo-master 6379:6379 &amp;amp;
    redis-cli -h 127.0.0.1 -p 6379 -a $REDIS_PASSWORD
[root@master01 ~]#
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　查看release&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;33&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
[root@master01 ~]# helm list
NAME            NAMESPACE       REVISION        UPDATED                                 STATUS          CHART           APP VERSION
redis-demo      default         1               2021-01-20 22:27:18.635916075 +0800 CST deployed        redis-10.5.7    5.0.7      
[root@master01 ~]# 
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　验证：用kubectl工具查看k8s集群上对应的redis-demo 是否运行？&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;35&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
[root@master01 ~]# kubectl get pods
NAME                       READY   STATUS    RESTARTS   AGE
myapp-779867bcfc-57zw7     1/1     Running   1          2d7h
myapp-779867bcfc-657qr     1/1     Running   1          2d7h
podinfo-56874dc7f8-5rb9q   1/1     Running   1          2d2h
podinfo-56874dc7f8-t6jgn   1/1     Running   1          2d2h
[root@master01 ~]# kubectl get svc
NAME                  TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)          AGE
kubernetes            ClusterIP   10.96.0.1       &amp;lt;none&amp;gt;        443/TCP          11d
myapp-svc             NodePort    10.111.14.219   &amp;lt;none&amp;gt;        80:31154/TCP     2d7h
podinfo               NodePort    10.111.10.211   &amp;lt;none&amp;gt;        9898:31198/TCP   2d2h
redis-demo-headless   ClusterIP   None            &amp;lt;none&amp;gt;        6379/TCP         18m
redis-demo-master     ClusterIP   10.100.228.32   &amp;lt;none&amp;gt;        6379/TCP         18m
redis-demo-slave      ClusterIP   10.109.46.121   &amp;lt;none&amp;gt;        6379/TCP         18m
[root@master01 ~]# kubectl get sts
NAME                READY   AGE
redis-demo-master   0/1     18m
redis-demo-slave    0/2     18m
[root@master01 ~]# 
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　提示：用kubectl工具查看pod列表，并没有发现对应pod运行，但是对应的svc和sts都正常创建；&lt;/p&gt;
&lt;p&gt;　　查看pod没有创建的原因&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;47&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
[root@master01 ~]# kubectl describe sts/redis-demo-master|grep -A 10 Events
Events:
  Type     Reason        Age                   From                    Message
  ----     ------        ----                  ----                    -------
  Warning  FailedCreate  14m (x12 over 14m)    statefulset-controller  create Pod redis-demo-master-0 in StatefulSet redis-demo-master failed error: failed to create PVC redis-data-redis-demo-master-0: persistentvolumeclaims &quot;redis-data-redis-demo-master-0&quot; is forbidden: exceeded quota: quota-storage-demo, requested: requests.storage=8Gi, used: requests.storage=0, limited: requests.storage=5Gi
  Warning  FailedCreate  3m40s (x18 over 14m)  statefulset-controller  create Claim redis-data-redis-demo-master-0 for Pod redis-demo-master-0 in StatefulSet redis-demo-master failed error: persistentvolumeclaims &quot;redis-data-redis-demo-master-0&quot; is forbidden: exceeded quota: quota-storage-demo, requested: requests.storage=8Gi, used: requests.storage=0, limited: requests.storage=5Gi
[root@master01 ~]# kubectl describe sts/redis-demo-slave|grep -A 10 Events 
Events:
  Type     Reason        Age                   From                    Message
  ----     ------        ----                  ----                    -------
  Warning  FailedCreate  14m (x12 over 14m)    statefulset-controller  create Pod redis-demo-slave-0 in StatefulSet redis-demo-slave failed error: failed to create PVC redis-data-redis-demo-slave-0: persistentvolumeclaims &quot;redis-data-redis-demo-slave-0&quot; is forbidden: exceeded quota: quota-storage-demo, requested: requests.storage=8Gi, used: requests.storage=0, limited: requests.storage=5Gi
  Warning  FailedCreate  3m41s (x18 over 14m)  statefulset-controller  create Claim redis-data-redis-demo-slave-0 for Pod redis-demo-slave-0 in StatefulSet redis-demo-slave failed error: persistentvolumeclaims &quot;redis-data-redis-demo-slave-0&quot; is forbidden: exceeded quota: quota-storage-demo, requested: requests.storage=8Gi, used: requests.storage=0, limited: requests.storage=5Gi
[root@master01 ~]# 
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　提示：这里提示我们没有权限创建，原因是quota-storage-demo禁止了；&lt;/p&gt;
&lt;p&gt;　　查看resourcequota准入控制规则&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;37&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
[root@master01 ~]# kubectl get resourcequota
NAME                 AGE   REQUEST                                                                                   LIMIT
quota-storage-demo   19d   persistentvolumeclaims: 0/5, requests.ephemeral-storage: 0/1Gi, requests.storage: 0/5Gi   limits.ephemeral-storage: 0/2Gi
[root@master01 ~]# kubectl describe resourcequota quota-storage-demo
Name:                       quota-storage-demo
Namespace:                  default
Resource                    Used  Hard
--------                    ----  ----
limits.ephemeral-storage    0     2Gi
persistentvolumeclaims      0     5
requests.ephemeral-storage  0     1Gi
requests.storage            0     5Gi
[root@master01 ~]# 
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　提示：resourcequota准入控制明确限制了创建pvc最低下限总和是5G，上面创建redis需要8G所以不满足对应准入控制规则所以创建pvc就被拒绝了，导致pod没能正常创建；&lt;/p&gt;
&lt;p&gt;　　卸载redis-demo&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;35&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
[root@master01 ~]# helm list
NAME            NAMESPACE       REVISION        UPDATED                                 STATUS          CHART           APP VERSION
redis-demo      default         1               2021-01-20 22:27:18.635916075 +0800 CST deployed        redis-10.5.7    5.0.7      
[root@master01 ~]# helm uninstall redis-demo
release &quot;redis-demo&quot; uninstalled
[root@master01 ~]# helm list
NAME    NAMESPACE       REVISION        UPDATED STATUS  CHART   APP VERSION
[root@master01 ~]# 
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　删除resourcequota准入控制&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;37&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
[root@master01 ~]# kubectl get resourcequota                        
NAME                 AGE   REQUEST                                                                                   LIMIT
quota-storage-demo   19d   persistentvolumeclaims: 0/5, requests.ephemeral-storage: 0/1Gi, requests.storage: 0/5Gi   limits.ephemeral-storage: 0/2Gi
[root@master01 ~]# kubectl delete resourcequota/quota-storage-demo
resourcequota &quot;quota-storage-demo&quot; deleted
[root@master01 ~]# kubectl get resourcequota
No resources found in default namespace.
[root@master01 ~]# 
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　检查pv，是否有足量的pv？&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;41&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
[root@master01 ~]# kubectl get pv
NAME        CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS      CLAIM                                      STORAGECLASS   REASON   AGE
nfs-pv-v1   5Gi        RWO,ROX,RWX    Retain           Bound       kube-system/alertmanager                                           3d22h
nfs-pv-v2   5Gi        RWO,ROX,RWX    Retain           Bound       kube-system/prometheus-data-prometheus-0                           3d22h
nfs-pv-v3   5Gi        RWO,ROX,RWX    Retain           Available                                                                      3d22h
[root@master01 ~]# 
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　提示：上述还有一个pv没有使用，但大小只有5g不够redis使用；&lt;/p&gt;
&lt;p&gt;　　创建pv&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;53&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
[root@master01 ~]# cat pv-demo.yaml 
apiVersion: v1
kind: PersistentVolume
metadata:
  name: nfs-pv-v4
spec:
  capacity:
    storage: 10Gi
  volumeMode: Filesystem
  accessModes: [&quot;ReadWriteOnce&quot;,&quot;ReadWriteMany&quot;,&quot;ReadOnlyMany&quot;]
  persistentVolumeReclaimPolicy: Retain
  mountOptions:
  - hard
  - nfsvers=4.1
  nfs:
    path: /data/v4
    server: 192.168.0.99
---
apiVersion: v1
kind: PersistentVolume
metadata:
  name: nfs-pv-v5
spec:
  capacity:
    storage: 10Gi
  volumeMode: Filesystem
  accessModes: [&quot;ReadWriteOnce&quot;,&quot;ReadWriteMany&quot;,&quot;ReadOnlyMany&quot;]
  persistentVolumeReclaimPolicy: Retain
  mountOptions:
  - hard
  - nfsvers=4.1
  nfs:
    path: /data/v5
    server: 192.168.0.99
---

apiVersion: v1
kind: PersistentVolume
metadata:
  name: nfs-pv-v6
spec:
  capacity:
    storage: 10Gi
  volumeMode: Filesystem
  accessModes: [&quot;ReadWriteOnce&quot;,&quot;ReadWriteMany&quot;,&quot;ReadOnlyMany&quot;]
  persistentVolumeReclaimPolicy: Retain
  mountOptions:
  - hard
  - nfsvers=4.1
  nfs:
    path: /data/v6
    server: 192.168.0.99
[root@master01 ~]# kubectl apply -f pv-demo.yaml
persistentvolume/nfs-pv-v4 created
persistentvolume/nfs-pv-v5 created
persistentvolume/nfs-pv-v6 created
[root@master01 ~]# kubectl get pv
NAME        CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS      CLAIM                                      STORAGECLASS   REASON   AGE
nfs-pv-v1   5Gi        RWO,ROX,RWX    Retain           Bound       kube-system/alertmanager                                           3d22h
nfs-pv-v2   5Gi        RWO,ROX,RWX    Retain           Bound       kube-system/prometheus-data-prometheus-0                           3d22h
nfs-pv-v3   5Gi        RWO,ROX,RWX    Retain           Available                                                                      3d22h
nfs-pv-v4   10Gi       RWO,ROX,RWX    Retain           Available                                                                      3s
nfs-pv-v5   10Gi       RWO,ROX,RWX    Retain           Available                                                                      3s
nfs-pv-v6   10Gi       RWO,ROX,RWX    Retain           Available                                                                      3s
[root@master01 ~]# 
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　重新安装redis&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;40&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
[root@master01 ~]# helm install redis-demo stable/redis
WARNING: This chart is deprecated
NAME: redis-demo
LAST DEPLOYED: Wed Jan 20 22:54:30 2021
NAMESPACE: default
STATUS: deployed
REVISION: 1
TEST SUITE: None
NOTES:
This Helm chart is deprecated

Given the `stable` deprecation timeline (https://github.com/helm/charts#deprecation-timeline), the Bitnami maintained Redis Helm chart is now located at bitnami/charts (https://github.com/bitnami/charts/).

The Bitnami repository is already included in the Hubs and we will continue providing the same cadence of updates, support, etc that we've been keeping here these years. Installation instructions are very similar, just adding the _bitnami_ repo and using it during the installation (`bitnami/&amp;lt;chart&amp;gt;` instead of `stable/&amp;lt;chart&amp;gt;`)

```bash
$ helm repo add bitnami https://charts.bitnami.com/bitnami
$ helm install my-release bitnami/&amp;lt;chart&amp;gt;           # Helm 3
$ helm install --name my-release bitnami/&amp;lt;chart&amp;gt;    # Helm 2
```

To update an exisiting _stable_ deployment with a chart hosted in the bitnami repository you can execute
 ```bash                                                                                                                                                                                                                                                                                                                                                                    $ helm
 repo add bitnami https://charts.bitnami.com/bitnami
  $ helm upgrade my-release bitnami/&amp;lt;chart&amp;gt;
  ```

  Issues and PRs related to the chart itself will be redirected to `bitnami/charts` GitHub repository. In the same way, we'll be happy to answer questions related to this migration process in this issue (https://github.com/helm/charts/issues/20969) created as a common place for discussion.

** Please be patient while the chart is being deployed **
Redis can be accessed via port 6379 on the following DNS names from within your cluster:

redis-demo-master.default.svc.cluster.local for read/write operations
redis-demo-slave.default.svc.cluster.local for read-only operations


To get your password run:

    export REDIS_PASSWORD=$(kubectl get secret --namespace default redis-demo -o jsonpath=&quot;{.data.redis-password}&quot; | base64 --decode)

To connect to your Redis server:

1. Run a Redis pod that you can use as a client:

   kubectl run --namespace default redis-demo-client --rm --tty -i --restart='Never' \
    --env REDIS_PASSWORD=$REDIS_PASSWORD \
   --image docker.io/bitnami/redis:5.0.7-debian-10-r32 -- bash

2. Connect using the Redis CLI:
   redis-cli -h redis-demo-master -a $REDIS_PASSWORD
   redis-cli -h redis-demo-slave -a $REDIS_PASSWORD

To connect to your database from outside the cluster execute the following commands:

    kubectl port-forward --namespace default svc/redis-demo-master 6379:6379 &amp;amp;
    redis-cli -h 127.0.0.1 -p 6379 -a $REDIS_PASSWORD
[root@master01 ~]# 
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　再次使用kubectl工具查看对应pod是否正常运行？&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;39&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
[root@master01 ~]# kubectl get pods 
NAME                       READY   STATUS             RESTARTS   AGE
myapp-779867bcfc-57zw7     1/1     Running            1          2d7h
myapp-779867bcfc-657qr     1/1     Running            1          2d7h
podinfo-56874dc7f8-5rb9q   1/1     Running            1          2d2h
podinfo-56874dc7f8-t6jgn   1/1     Running            1          2d2h
redis-demo-master-0        0/1     CrashLoopBackOff   4          2m33s
redis-demo-slave-0         0/1     CrashLoopBackOff   4          2m33s
[root@master01 ~]# kubectl get pvc
NAME                             STATUS   VOLUME      CAPACITY   ACCESS MODES   STORAGECLASS   AGE
redis-data-redis-demo-master-0   Bound    nfs-pv-v4   10Gi       RWO,ROX,RWX                   2m39s
redis-data-redis-demo-slave-0    Bound    nfs-pv-v6   10Gi       RWO,ROX,RWX                   2m39s
[root@master01 ~]#
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　提示：这里pvc自动创建成功，但是对应pod能正常启动；&lt;/p&gt;
&lt;p&gt;　　查看pod详情&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;35&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
[root@master01 ~]# kubectl describe pod/redis-demo-master-0|grep -A 10 Events
Events:
  Type     Reason     Age                    From               Message
  ----     ------     ----                   ----               -------
  Normal   Scheduled  6m53s                  default-scheduler  Successfully assigned default/redis-demo-master-0 to node01.k8s.org
  Normal   Pulling    6m51s                  kubelet            Pulling image &quot;docker.io/bitnami/redis:5.0.7-debian-10-r32&quot;
  Normal   Pulled     6m33s                  kubelet            Successfully pulled image &quot;docker.io/bitnami/redis:5.0.7-debian-10-r32&quot; in 18.056248477s
  Normal   Started    5m47s (x4 over 6m33s)  kubelet            Started container redis-demo
  Normal   Created    5m1s (x5 over 6m33s)   kubelet            Created container redis-demo
  Normal   Pulled     5m1s (x4 over 6m32s)   kubelet            Container image &quot;docker.io/bitnami/redis:5.0.7-debian-10-r32&quot; already present on machine
  Warning  BackOff    100s (x28 over 6m31s)  kubelet            Back-off restarting failed container
[root@master01 ~]# kubectl describe pod/redis-demo-slave-0|grep -A 10 Events      
Events:
  Type     Reason            Age                    From               Message
  ----     ------            ----                   ----               -------
  Warning  FailedScheduling  6m58s (x2 over 6m58s)  default-scheduler  0/5 nodes are available: 5 pod has unbound immediate PersistentVolumeClaims.
  Normal   Scheduled         6m55s                  default-scheduler  Successfully assigned default/redis-demo-slave-0 to node01.k8s.org
  Normal   Pulling           6m55s                  kubelet            Pulling image &quot;docker.io/bitnami/redis:5.0.7-debian-10-r32&quot;
  Normal   Pulled            6m37s                  kubelet            Successfully pulled image &quot;docker.io/bitnami/redis:5.0.7-debian-10-r32&quot; in 17.603521415s
  Normal   Created           5m12s (x5 over 6m37s)  kubelet            Created container redis-demo
  Normal   Started           5m12s (x5 over 6m37s)  kubelet            Started container redis-demo
  Normal   Pulled            5m12s (x4 over 6m36s)  kubelet            Container image &quot;docker.io/bitnami/redis:5.0.7-debian-10-r32&quot; already present on machine
  Warning  BackOff           106s (x27 over 6m35s)  kubelet            Back-off restarting failed container
[root@master01 ~]# 
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　提示：这里查看对应pod详细信息也没有明确提示什么错误；总之pod没能正常运行（估计和对应的镜像启动有关系）；通过上述实验虽然pod没能正常运行起来，但是helm能够将对应的chart提交给k8s运行；helm的使命是成功的；&lt;/p&gt;
&lt;p&gt;　　卸载redis-demo，重新找chart安装试试&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1503305/202101/1503305-20210120230713594-713344556.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　提示：这里搜索stable仓库中的redis，该仓库中redis的chart都是废弃的版本；&lt;/p&gt;
&lt;p&gt;　　删除仓库，重新添加仓库&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;35&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
[root@master01 ~]# helm repo list
NAME    URL                          
stable  https://charts.helm.sh/stable
[root@master01 ~]# helm repo remove stable
&quot;stable&quot; has been removed from your repositories
[root@master01 ~]# helm repo add bitnami https://charts.bitnami.com/bitnami
&quot;bitnami&quot; has been added to your repositories
[root@master01 ~]# helm repo list
NAME    URL                               
bitnami https://charts.bitnami.com/bitnami
[root@master01 ~]# 
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　搜索redis chart&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;36&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
[root@master01 ~]# helm search repo redis
NAME                    CHART VERSION   APP VERSION     DESCRIPTION                                       
bitnami/redis           12.6.2          6.0.10          Open source, advanced key-value store. It is of...
bitnami/redis-cluster   4.2.6           6.0.10          Open source, advanced key-value store. It is of...
[root@master01 ~]# 
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　安装bitnami/redis&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;35&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
[root@master01 ~]# helm install redis-demo bitnami/redis
NAME: redis-demo
LAST DEPLOYED: Thu Jan 21 01:58:18 2021
NAMESPACE: default
STATUS: deployed
REVISION: 1
TEST SUITE: None
NOTES:
** Please be patient while the chart is being deployed **
Redis can be accessed via port 6379 on the following DNS names from within your cluster:

redis-demo-master.default.svc.cluster.local for read/write operations
redis-demo-slave.default.svc.cluster.local for read-only operations


To get your password run:

    export REDIS_PASSWORD=$(kubectl get secret --namespace default redis-demo -o jsonpath=&quot;{.data.redis-password}&quot; | base64 --decode)

To connect to your Redis(TM) server:

1. Run a Redis(TM) pod that you can use as a client:
   kubectl run --namespace default redis-demo-client --rm --tty -i --restart='Never' \
    --env REDIS_PASSWORD=$REDIS_PASSWORD \
   --image docker.io/bitnami/redis:6.0.10-debian-10-r1 -- bash

2. Connect using the Redis(TM) CLI:
   redis-cli -h redis-demo-master -a $REDIS_PASSWORD
   redis-cli -h redis-demo-slave -a $REDIS_PASSWORD

To connect to your database from outside the cluster execute the following commands:

    kubectl port-forward --namespace default svc/redis-demo-master 6379:6379 &amp;amp;
    redis-cli -h 127.0.0.1 -p 6379 -a $REDIS_PASSWORD
[root@master01 ~]# 
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　查看pod运行情况&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1503305/202101/1503305-20210121020050150-1027885671.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　提示：这里提示我们append-only file 没有打开的权限，说明我们挂载的对应存储没有写权限；&lt;/p&gt;
&lt;p&gt;　　在后端存储上加上写权限&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1503305/202101/1503305-20210121020746965-1706306030.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　提示：这里加上写的权限对应pod还是没能正常跑起来；删除pod试试，看看对应pod重建以后是否会正常运行？&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;35&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
[root@master01 ~]# kubectl delete pod --all
pod &quot;redis-demo-master-0&quot; deleted
pod &quot;redis-demo-slave-0&quot; deleted
[root@master01 ~]# kubectl get pods        
NAME                  READY   STATUS              RESTARTS   AGE
redis-demo-master-0   0/1     ContainerCreating   0          3s
redis-demo-slave-0    0/1     Running             0          3s
[root@master01 ~]# kubectl get pods 
NAME                  READY   STATUS    RESTARTS   AGE
redis-demo-master-0   0/1     Running   0          5s
redis-demo-slave-0    0/1     Running   0          5s
[root@master01 ~]# kubectl get pods 
NAME                  READY   STATUS             RESTARTS   AGE
redis-demo-master-0   1/1     Running            0          62s
redis-demo-slave-0    1/1     Running            0          62s
redis-demo-slave-1    0/1     CrashLoopBackOff   2          26s
[root@master01 ~]# 
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　提示：这里删除pod以后，新建的pod就能够正常运行；但是还有一个slave运行失败，应该是后端存储没有写权限造成的；&lt;/p&gt;
&lt;p&gt;　　再次给后端存储加写权限&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1503305/202101/1503305-20210121021459956-1698118744.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　提示：可以看到给对应目录加上写权限，对应pod正常启动了；&lt;/p&gt;
&lt;p&gt;　　进入redis主从复制集群&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1503305/202101/1503305-20210121021738801-2053690212.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　提示：可以看到在master节点上，能够看到对应两个从节点的信息；&lt;/p&gt;
&lt;p&gt;　　验证：在主节点上写数据，看看对应从节点上是否能够同步数据？&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1503305/202101/1503305-20210121021942762-703855475.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　提示：可以看到在master端写数据，slave端能够正常将对应数据同步过来，在slave端能够正常对取到对应数据，说明主从复制集群工作是正常的；&lt;/p&gt;
&lt;p&gt;　　更新仓库&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;34&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
[root@master01 ~]# helm repo update
Hang tight while we grab the latest from your chart repositories...
...Successfully got an update from the &quot;bitnami&quot; chart repository
Update Complete. ⎈Happy Helming!⎈
[root@master01 ~]# 
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　提示：建议每次部署新的应用都先更新下仓库，然后在部署应用；&lt;/p&gt;
&lt;p&gt;　　使用自定义信息部署应用&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1503305/202101/1503305-20210121022814406-1662299791.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　提示：上述命令用--set选项可以将自定义信息传入对应的chart中，用于替换对应模板文件中的值；上述命令表示设置redis密码为admin123.com，master和slave都不开启持久存储功能（生产环境不建议）；当然简单的设置个别参数可以使用--set来指定，如果过于复杂的参数，建议使用value.yaml文件来替换，使用--value选项来指定对应的值文件即可；&lt;/p&gt;
</description>
<pubDate>Wed, 20 Jan 2021 18:45:00 +0000</pubDate>
<dc:creator>Linux-1874</dc:creator>
<og:description>前文我们了解了k8s上的hpa资源的使用，回顾请参考：https://www.cnblogs.com/qiuhom-1874/p/14293237.html；今天我们来聊一下k8s包管理器helm的相</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/qiuhom-1874/p/14305902.html</dc:identifier>
</item>
<item>
<title>浅谈踢人下线的设计思路！（附代码实现方案） - 省长来了</title>
<link>http://www.cnblogs.com/shengzhang/p/14306000.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/shengzhang/p/14306000.html</guid>
<description>&lt;h2 id=&quot;前言&quot;&gt;前言&lt;/h2&gt;
&lt;p&gt;前两天写了一篇文章，主要讲了下java中如何实现踢人下线，原文链接：&lt;a href=&quot;https://juejin.cn/post/6919342604987727885&quot; target=&quot;_blank&quot;&gt;java中如何踢人下线？封禁某个账号后使其会话立即掉线！&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;本来只是简单阐述一下踢人下线的业务场景和实现方案，没想到引出那么多大佬把小弟喷的睁不开眼睛，为了避免大家继续喷我，特再写下此篇文章，彻底讲清楚各种场景下踢人下线的设计思路，如有不足之处还请各位大佬轻喷！&lt;/p&gt;
&lt;p&gt;好了废话不多说，正文开始&lt;/p&gt;
&lt;h2 id=&quot;正文&quot;&gt;正文&lt;/h2&gt;
&lt;p&gt;如果把踢人下线比喻成拆房子，那么在学会拆房之前，我们必须要了解这座房子是怎么盖起来的，不同的盖法对应不同的拆法，不能混为一谈&lt;/p&gt;
&lt;p&gt;对于目前大多数系统来讲，登录主要有两种方式，一是传统&lt;code&gt;Session&lt;/code&gt;模式，二是&lt;code&gt;jwt令牌&lt;/code&gt;模式&lt;/p&gt;
&lt;h4 id=&quot;传统session模式&quot;&gt;传统Session模式&lt;/h4&gt;
&lt;p&gt;我们先以&lt;code&gt;Session模式&lt;/code&gt;为例，这种模式是怎么登录的呢？&lt;/p&gt;
&lt;p&gt;(注：此处的&lt;code&gt;Session&lt;/code&gt;不单指&lt;code&gt;HttpSession&lt;/code&gt;，指一切使用服务端控制会话的手段)&lt;/p&gt;
&lt;p&gt;这里我们不使用任何框架，从底层逻辑开始说起。&lt;/p&gt;
&lt;p&gt;首先，你需要一个全局拦截器，拦截所有会话请求，如果此会话已经登录，那么拦截器放行，如果未登录，直接将此会话强制重定向到登录接口&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;在登录接口，我们需要接受两个参数：&lt;code&gt;username + password&lt;/code&gt;, 拿这两个参数去数据库中获取数据&lt;/li&gt;
&lt;li&gt;如果查不到数据，直接返回&lt;code&gt;用户名或密码错误&lt;/code&gt;，如果可以查找到数据，那么开始登录&lt;/li&gt;
&lt;li&gt;利用一定的算法(例如uuid)，生成一个随机字符串，就像这样子：&lt;code&gt;623368f0-ae5e-4475-a53f-93e4225f16ae&lt;/code&gt;, 这就是我们的token&lt;/li&gt;
&lt;li&gt;现在我们需要做两件事，一是建立此&lt;code&gt;token&lt;/code&gt;与&lt;code&gt;UserId&lt;/code&gt;的映射关系，二是把这个&lt;code&gt;token&lt;/code&gt;返回给前端
&lt;ol&gt;&lt;li&gt;建立映射：在&lt;code&gt;Redis&lt;/code&gt;中添加一条数据，假如&lt;code&gt;userId=10001&lt;/code&gt;，那么我们需要&lt;code&gt;RedisUtil.set(&quot;623368f0-ae5e-4475-a53f-93e4225f16ae&quot;, 10001)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;将&lt;code&gt;token&lt;/code&gt;传递给前台，你可以放到&lt;code&gt;Cookie&lt;/code&gt;里，或者直接放到&lt;code&gt;返回体body&lt;/code&gt;里&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;li&gt;大工告成，会话登录完毕！在全局拦截器里，我们不认userId只认token，谁持有&lt;code&gt;623368f0-ae5e-4475-a53f-93e4225f16ae&lt;/code&gt;这个令牌，谁就是&lt;code&gt;用户10001&lt;/code&gt;！&lt;/li&gt;
&lt;li&gt;一个会话访问进来，有&lt;code&gt;token&lt;/code&gt;且token有效，那么会话放行！没有？乖乖滚去登录！&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;此时不难看出，一个客户端要保持会话登录的两个必要条件：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;此客户端持有&lt;code&gt;token&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;这个&lt;code&gt;token&lt;/code&gt;是一个有效&lt;code&gt;token&lt;/code&gt;，即：可以从&lt;code&gt;Redis&lt;/code&gt;中找到对应的&lt;code&gt;UserId&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;&lt;strong&gt;而我们要做踢人下线，就必须从这两点至少选择其一开始下手&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;首先我们先明确一点：除非客户端主动注销，否则我们是无法清除一个已经颁发到客户端的token的。&lt;/p&gt;
&lt;p&gt;（除了&lt;code&gt;Cookie清除技术&lt;/code&gt;和&lt;code&gt;WebSocket实时推送技术&lt;/code&gt;可以做到，但是这两种技术都需要客户端主动配合，我们现在的假设是客户端拒不配合，我们需要将它强制清退下线。）&lt;/p&gt;
&lt;p&gt;现在，我们只能从第二点下手，即：清除此&lt;code&gt;token&lt;/code&gt;与&lt;code&gt;UserId&lt;/code&gt;的映射关系&lt;/p&gt;
&lt;p&gt;你可能会想，这不简单？&lt;code&gt;Redis&lt;/code&gt;清除一个键值，还不是一行代码就能解决的事情？&lt;/p&gt;
&lt;p&gt;此时你可能漏掉了关键的一点，那就是，我们只在&lt;code&gt;Redis&lt;/code&gt;中存储了&lt;code&gt;token -&amp;gt; UserId&lt;/code&gt;的映射关系，如果我们要踢出用户&lt;code&gt;10001&lt;/code&gt;，正常情况下，我们无法只根据&lt;code&gt;10001&lt;/code&gt;找到它对应的&lt;code&gt;token&lt;/code&gt;是哪个键值&lt;/p&gt;
&lt;p&gt;要解决这个问题，我们就必须把&lt;code&gt;UserId -&amp;gt; token&lt;/code&gt;的映射关系也存储一份，你可以存储在数据库中，也可以存储在&lt;code&gt;Redis&lt;/code&gt;中，为了性能考虑，我们使用Redis&lt;/p&gt;
&lt;p&gt;现在事情变得简单起来，要踢人下线，我们只需要两步：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;找到&lt;code&gt;账号10001&lt;/code&gt;对应的&lt;code&gt;token&lt;/code&gt;键值&lt;/li&gt;
&lt;li&gt;删除这个键值&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;OK，踢出成功，待到此账号下一次访问系统时，虽然他携带了&lt;code&gt;token&lt;/code&gt;，但是此&lt;code&gt;token&lt;/code&gt;已成为&lt;code&gt;无效token&lt;/code&gt;，乖乖去登陆吧！&lt;/p&gt;
&lt;p&gt;此时你可能会说：&lt;/p&gt;
&lt;p&gt;就这？我创建个集合保存所有要踢出下线的账号，每次拦截器里判断这个会话是否在这个集合中不就OK了？&lt;/p&gt;
&lt;p&gt;大佬请慢喷！这就是我要说的第二种模式————黑名单机制，且往下看&lt;/p&gt;
&lt;h4 id=&quot;jwt模式&quot;&gt;jwt模式&lt;/h4&gt;
&lt;p&gt;&lt;code&gt;jwt模式&lt;/code&gt;的登陆步骤与&lt;code&gt;传统Session模式&lt;/code&gt;区别不大，在此暂不赘述&lt;/p&gt;
&lt;p&gt;不同点在于，&lt;code&gt;jwt&lt;/code&gt;登陆时，不会在服务器保存任何会话信息，所有的用户参数都被写进了jwt生成的token中&lt;/p&gt;
&lt;p&gt;（所以&lt;code&gt;jwt&lt;/code&gt;的&lt;code&gt;token&lt;/code&gt;才会长的那么长！通常两三百字符长度起步）&lt;/p&gt;
&lt;p&gt;一个会话是否有效，只看这个会话携带的&lt;code&gt;token&lt;/code&gt;能不能正常解析出数据！&lt;/p&gt;
&lt;p&gt;这也就意味着令牌的合法性是令牌自解释的，而不是服务器说了算！&lt;/p&gt;
&lt;p&gt;所以，相比于&lt;code&gt;传统Session模式&lt;/code&gt;，&lt;code&gt;jwt&lt;/code&gt;对令牌的可控性就弱了很多，无法做到主动清除&lt;code&gt;token -&amp;gt; UserId&lt;/code&gt; 映射关系的操作&lt;/p&gt;
&lt;p&gt;除非你手动更换&lt;code&gt;jwt&lt;/code&gt;令牌生成的算法秘钥，但是这样会造成系统中所有令牌全部失效，全部用户集体下线！这是万万不行的。&lt;/p&gt;
&lt;p&gt;那怎么办？难道我就不能做到踢人下线的操作吗？&lt;/p&gt;
&lt;p&gt;其实办法肯定是有的，只要思想不滑坡，方法总比困难多！&lt;/p&gt;
&lt;p&gt;那就是利用黑名单机制：我们要踢出哪个用户，只需要将他的&lt;code&gt;UserId&lt;/code&gt;或者&lt;code&gt;jwt-token&lt;/code&gt;放进一个黑名单里，然后我们在拦截器里检查每个请求的&lt;code&gt;token&lt;/code&gt;或者&lt;code&gt;UserId&lt;/code&gt;是否存在于这个黑名单里即可！&lt;/p&gt;
&lt;p&gt;这种方式和传统Session模式孰优孰劣呢？只能说各有千秋！&lt;/p&gt;
&lt;p&gt;黑名单机制在存储时节省性能，在拦截器里多了一步黑名单检测的步骤，浪费性能！&lt;/p&gt;
&lt;p&gt;不过坦白了讲，这丁点的性能的浪费对于现在的CPU来说都是毛毛雨，可以直接忽略！&lt;/p&gt;
&lt;h4 id=&quot;题外话&quot;&gt;题外话&lt;/h4&gt;
&lt;p&gt;在我一位同事的项目中，给我提供了jwt踢人下线的另一种实现思路：&lt;/p&gt;
&lt;p&gt;那就是在生成jwt令牌时，加入一个固定的参数当做令牌&lt;code&gt;生成因子&lt;/code&gt;，如果要将一个用户踢出下线，只需要修改一下这个因子的值，然后在拦截器里每次校验这个因子生成的令牌是否与客户端传递的令牌一致!即可判断出这个token是否已被拉黑！&lt;/p&gt;
&lt;p&gt;这种模式提供了一个比较新颖的逻辑算法，但是严格来讲，还是借助服务器存储一定的数据完成的会话验证，仍然属于&lt;code&gt;Session模式&lt;/code&gt;。在此暂不展开细讲。&lt;/p&gt;
&lt;h4 id=&quot;代码实现方案？&quot;&gt;代码实现方案？&lt;/h4&gt;
&lt;p&gt;说了这么多理论，总归是要上代码的，由于笔者除了&lt;code&gt;sa-token框架&lt;/code&gt;以外没有找到任何一个框架对踢人下线有直接现成的解决方案，所以在此暂以&lt;code&gt;sa-token框架&lt;/code&gt;为例&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;首先添加pom.xml依赖&lt;/li&gt;
&lt;/ol&gt;&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;&amp;lt;!-- sa-token 权限认证, 在线文档：http://sa-token.dev33.cn/ --&amp;gt;
&amp;lt;dependency&amp;gt;
        &amp;lt;groupId&amp;gt;cn.dev33&amp;lt;/groupId&amp;gt;
        &amp;lt;artifactId&amp;gt;sa-token-spring-boot-starter&amp;lt;/artifactId&amp;gt;
        &amp;lt;version&amp;gt;1.12.1&amp;lt;/version&amp;gt;
&amp;lt;/dependency&amp;gt;
&lt;/code&gt;
&lt;/pre&gt;
&lt;ol start=&quot;2&quot;&gt;&lt;li&gt;在用户登录时将账号id写入会话中&lt;/li&gt;
&lt;/ol&gt;&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;@RestController
@RequestMapping(&quot;user&quot;)
public class UserController {
        @RequestMapping(&quot;doLogin&quot;)
        public String doLogin(String username, String password) {
                // 此处仅作示例模拟，真实项目需要从数据库中查询数据进行比对 
                if(&quot;zhang&quot;.equals(username) &amp;amp;&amp;amp; &quot;123456&quot;.equals(password)) {
                        StpUtil.setLoginId(10001);
                        return &quot;登录成功&quot;;
                }
                return &quot;登录失败&quot;;
        }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;ol start=&quot;3&quot;&gt;&lt;li&gt;将指定id的账号踢出在线&lt;/li&gt;
&lt;/ol&gt;&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;// 使指定id账号的会话注销登录，对方再次访问系统时会抛出`NotLoginException`异常，场景值为-5
@RequestMapping(&quot;kickout&quot;)
public String kickout(long userId) {
        StpUtil.logoutByLoginId(userId);
        return &quot;踢出成功&quot;;
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;对框架感兴趣的同学可以查看官网：&lt;a href=&quot;http://sa-token.dev33.cn/&quot; target=&quot;_blank&quot;&gt;sa-token 一个java轻量级权限认证框架&lt;/a&gt;&lt;/p&gt;
&lt;h4 id=&quot;后话&quot;&gt;后话&lt;/h4&gt;
&lt;p&gt;文章写的再详细也难免会有遗漏之处，在此还求大家轻喷，可以在评论出留言指出不足之处&lt;/p&gt;
&lt;p&gt;如果觉得文章写得不错还请大家不要吝惜为文章点个赞，您的支持是我更新的最大动力！&lt;/p&gt;

</description>
<pubDate>Wed, 20 Jan 2021 17:50:00 +0000</pubDate>
<dc:creator>省长来了</dc:creator>
<og:description>前言 前两天写了一篇文章，主要讲了下java中如何实现踢人下线，原文链接：java中如何踢人下线？封禁某个账号后使其会话立即掉线！ 本来只是简单阐述一下踢人下线的业务场景和实现方案，没想到引出那么多大</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/shengzhang/p/14306000.html</dc:identifier>
</item>
</channel>
</rss>