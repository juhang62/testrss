<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="css/feed.xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/" xmlns:og="http://ogp.me/ns#">
<channel>
<atom:link rel="self" href="http://192.168.1.4/fivefilters/makefulltextfeed.php?url=feed.cnblogs.com%2Fblog%2Fsitehome%2Frss&amp;max=10&amp;links=preserve&amp;exc=" />
<atom:link rel="alternate" title="Source URL" href="http://feed.cnblogs.com/blog/sitehome/rss" />
<atom:link rel="related" title="Subscribe to feed" href="http://www.subtome.com/#/subscribe?feeds=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed.cnblogs.com%252Fblog%252Fsitehome%252Frss%26max%3D10%26links%3Dpreserve%26exc%3D&amp;back=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed.cnblogs.com%252Fblog%252Fsitehome%252Frss%26max%3D10%26links%3Dpreserve%26exc%3D" />
<title>博客园_首页</title>
<link></link>
<description>代码改变世界</description>
<item>
<title>Deno会在短期内取代Node吗？ - 葡萄城技术团队</title>
<link>http://www.cnblogs.com/powertoolsteam/p/12935115.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/powertoolsteam/p/12935115.html</guid>
<description>&lt;blockquote readability=&quot;7.4690265486726&quot;&gt;
&lt;p&gt;转载请注明出处：&lt;a href=&quot;https://www.grapecity.com.cn/&quot; target=&quot;_blank&quot;&gt;葡萄城官网&lt;/a&gt;，葡萄城为开发者提供专业的开发工具、解决方案和服务，赋能开发者。&lt;/p&gt;
&lt;p&gt;原文出处：https://blog.bitsrc.io/what-is-deno-and-will-it-replace-nodejs-a13aa1734a74&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div readability=&quot;102&quot;&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/139239/202005/139239-20200522085338207-1610429505.png&quot; alt=&quot;&quot;/&gt; &lt;/p&gt;
&lt;h3&gt;Deno是什么？&lt;/h3&gt;
&lt;p&gt;Deno v1.0.0已于5月13日正式发布。&lt;/p&gt;
&lt;p&gt;其开发者为Ryan Dahl，他的上一个项目是Node，相信我们大部分人都了解。&lt;/p&gt;
&lt;p&gt;作为Node之父，Ryan Dahl认为Node自从他把项目移交出去后，Node的走向越来越背离了他的初衷，并且存在着很多无法解决的问题，所以他决心重新开发一个新的项目去解决这些问题，这个项目就名为Deno。目标则是&lt;strong&gt;De&lt;/strong&gt;stroy-&lt;strong&gt;no&lt;/strong&gt;de。&lt;/p&gt;
&lt;p&gt;那么，这样是不是就意味着Deno即将替代Node，成为Node的下一代产品？我们应不应该从现在就开始放弃Node开始使用Deno呢？ 让我们一起看看。&lt;/p&gt;
&lt;h3&gt;起源&lt;/h3&gt;
&lt;p class=&quot;ht&quot;&gt;在2018年，Ryan在柏林进行了一次演讲，这是他第二次关于JS的公开演讲，第一次再2009，那次是宣布Node项目的诞生。&lt;/p&gt;
&lt;p class=&quot;ht&quot;&gt;在这次演讲中，除了主要介绍他认为Node.js的几大问题和不可避免的许多Bug外，在演讲快结束时，他揭开了当时还是个小项目名为Deno的面纱，因为和node命名有着千丝万缕的联系，那时大家认为这个项目就是Node.js v2，它将会解决和完善ry提到那些问题。&lt;/p&gt;
&lt;p class=&quot;ht&quot;&gt;两年后的5月13日， Deno 1.0终于正式发布了，它是一个全新的服务端JavaScript运行时，使用Rust而不是C++开发，由于Rust原生支持WebAssembly，所以它也能直接运行WebAssembly。基于Tokio平台(它提供了所有JavaScript所需的异步操作)，内置V8和tsc引擎，可直接解释JavaScript和TypeScript。&lt;/p&gt;
&lt;h3&gt;安全集成&lt;/h3&gt;
&lt;p&gt;默认情况下，Node.js给你的访问权限比较高，这意味着你拥有读写文件系统、对外发出请求、访问环境变量等行为。虽然作为开发人员，拥有这种级别的访问权限对开发过程非常好，但如果你在开发过程中有一点疏漏，将来对你的应用也会产生安全风险。&lt;/p&gt;
&lt;p&gt;而在Deno这，默认情况下脚本不具有读写权限，必须显式通过命令行参数来启用或禁用对不同安全功能的访问。因此，如果需要脚本能够访问/etc文件夹，可以通过下面命令行执行：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;32&quot;&gt;
&lt;pre&gt;
deno --allow-read = / etc myscript.ts
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;这就类似于其他平台处理安全性的方式。如果你是Android用户，那么肯定有很多应用程序要求你允许它们访问你手机内的不同资源，例如联系人、电话、文件夹等，同样的概念也可以在这里应用。通过将这些标志用作执行脚本的命令行的一部分，你可以提供代码所需的权限。&lt;/p&gt;
&lt;h3&gt;更完整的标准库&lt;/h3&gt;
&lt;p&gt;自从Node的第一个版本发布以来，JavaScript已经改进了它的标准库，但与其他语言相比，它仍有相当长的路要走。Deno也试图改进这一点，它声称拥有一个非常完整的标准库，允许开发人员使用官方工具执行基本任务，而只需要对复杂任务使用外部库(ala NPM)。&lt;/p&gt;
&lt;p&gt;本质上，Deno开箱即用工具为终端文本添加颜色，处理外部数据结构(如Binary、CSV、YAML和其他)，生成UUID，甚至编写WebSocket。还可以使用其他更基本的模块，例如文件系统访问、日期助手函数、http相关函数等等。&lt;/p&gt;
&lt;h3&gt;集成TypeScript&lt;/h3&gt;
&lt;p&gt;如果你对TypeScript非常熟悉，那么使用Deno将会更加容易上手，因为它原生可以直接运行TS。&lt;/p&gt;
&lt;p&gt;另外，Deno不需要任何外部工具去支持多语言，它内部会根据文件后缀自动判断其使用的语言解释引擎。&lt;/p&gt;
&lt;p&gt;虽然默认情况下Deno会处理很多事情，但您可以使用自己的tsconfig.json文件覆盖配置：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;32&quot;&gt;
&lt;pre&gt;
deno run -c tsconfig.json [your-script.ts]
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;默认配置使用的是严格模式，因此如果发现任何不合格的代码都会立即得到提示。&lt;/p&gt;
&lt;h3&gt;放弃NPM和node_modules&lt;/h3&gt;
&lt;p&gt;Deno决定完全放弃NPM和node_modules， 因为npm逻辑越来越复杂，node.js对外部模块几乎没有任何安全验证措施，另外node_modules也越来越臃肿且难以管理。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/139239/202005/139239-20200522085504752-612539459.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;那么，Deno是如何处理依赖关系呢？它是通过url加载所有模块的：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;32&quot;&gt;
&lt;pre&gt;
import * as log from &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;https://deno.land/std/log/mod.ts&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;所以，Deno不再需要拥有一个集中的存储库，之前的package.json也不再需要了，现在通过在名为deps.ts的文件中包含了模块列表及其各自的URL，简化了依赖管理。但版本管理控制怎么办呢？作者已经想到了，可在URL上指定包的版本，deps.ts的文件示意：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;34&quot;&gt;
&lt;pre&gt;
export { assert } from &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;https://deno.land/std@v0.39.0/testing/asserts.ts&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;;
export { green, bold } from &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;https://deno.land/std@v0.39.0/fmt/colors.ts&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;;
&lt;/pre&gt;&lt;/div&gt;
&lt;p class=&quot;ht&quot;&gt;由于这个文件的存在，在内部运行时，依赖项将被重新导出，这就能让应用程序的不同模块都引用相同的源。&lt;/p&gt;
&lt;p class=&quot;ht&quot;&gt;如果您想更新任何模块的版本，可以通过修改deps.ts中URL的版本信息。另外，虽然没有了node_modeules目录，但依赖项仍然会下载并隐藏在你的硬盘中，供你离线使用，如通过需要重新下载，只需在命令中添加—reload命令即可。&lt;/p&gt;

&lt;h3&gt;还有什么？&lt;/h3&gt;
&lt;p&gt;Deno还包括其他特性，比如自动测试器、调试器、文件监视器等开箱即用的工具。但其中一些只是语言提供的API，您需要编写自己的工具才能使用它们。&lt;/p&gt;
&lt;p&gt;以Deno.watchFS向您提供的文件监视器API为例，如果你正在寻找类似于nodemon的解决方案，那么你可以自己构建它。下面是一个解决类似问题的23行脚本：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/139239/202005/139239-20200522085544155-1503453216.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;h3&gt;最后，它会在短期内取代Node.js吗？&lt;/h3&gt;
&lt;p&gt;虽然Deno的很多想法和理念非常好，也确实解决了很多问题。但作为一个从Node发布之初就开始用的团队，我认为PHP、Python甚至Ruby(更不用说Java或.NET)都不能与在后端拥有JavaScript和异步I/O模型相提并论。这些年来，Node(和JavaScript)不断发展，以满足业界的需求。&lt;/p&gt;
&lt;p&gt;在我看来，虽然Deno是以Destroy-node为己任而开发的，但就目前来讲，Deno取代Node仍不可能，Node的占有率太高了，生态也足够完善，基本属于想要什么功能都能在社区中找到，所以基本无需担心。而Deno还在孵化初期，企业很难去放弃已经成熟的技术转而投入更大的精力使用它。但它未来的前景还是令人期待的， 也许在越来越多的行业头部企业分享过它们的使用经验后，Deno的存在也会越来越为人所知。&lt;/p&gt;

&lt;/div&gt;
</description>
<pubDate>Fri, 22 May 2020 00:57:00 +0000</pubDate>
<dc:creator>葡萄城技术团队</dc:creator>
<og:description>转载请注明出处：葡萄城官网，葡萄城为开发者提供专业的开发工具、解决方案和服务，赋能开发者。 原文出处：https://blog.bitsrc.io/what-is-deno-and-will-it-r</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/powertoolsteam/p/12935115.html</dc:identifier>
</item>
<item>
<title>第 6 篇：分页接口 - 削微寒</title>
<link>http://www.cnblogs.com/xueweihan/p/12930845.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/xueweihan/p/12930845.html</guid>
<description>&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/759200/202004/759200-20200415161158343-1662112908.jpg&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;作者：&lt;a href=&quot;https://www.zmrenwu.com&quot;&gt;HelloGitHub-追梦人物&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;如果没有设置分页，django-rest-framework 会将所有资源类表序列化后返回，如果资源很多，就会对网站性能造成影响。为此，我们来给博客文章列表 API 添加分页功能。&lt;/p&gt;
&lt;p&gt;django-rest-framework 为分页功能提供了多个辅助类，常用的有：&lt;/p&gt;
&lt;ul readability=&quot;0.5&quot;&gt;&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;&lt;code&gt;PageNumberPagination&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;将资源分为第 1 页、第 2 页...第 n 页，使用页码号请求分页结果。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;2&quot;&gt;
&lt;p&gt;&lt;code&gt;LimitOffsetPagination&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;通过 &lt;code&gt;limit&lt;/code&gt; 和 &lt;code&gt;offset&lt;/code&gt; 两个参数来控制请求的资源。例如通过发送 API 请求：/posts/?offset=20&amp;amp;limit=5，将获取文章资源列表第 20 篇后的 5 篇文章。如果 offset 以等差数列递增，limit 保持不变，则等价于按页码分页。但 offset 和 limit 可以为任意值，因此这种分页比 &lt;code&gt;PageNumberPagination&lt;/code&gt; 更加灵活。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;要使用分页功能非常简单，只需在项目的配置文件中配置好分页选项，即可全局启用分页功能。打开 config/common.py 配置文件，写入如下的分页配置：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-python&quot;&gt;REST_FRAMEWORK = {
    # 设置 DEFAULT_PAGINATION_CLASS 后，将全局启用分页，所有 List 接口的返回结果都会被分页。
    # 如果想单独控制每个接口的分页情况，可不设置这个选项，而是在视图函数中进行配置
    &quot;DEFAULT_PAGINATION_CLASS&quot;: &quot;rest_framework.pagination.PageNumberPagination&quot;,
    # 这个选项控制分页后每页的资源个数
    &quot;PAGE_SIZE&quot;: 10,
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;配置完成之后，所有通用视图函数或者视图集生成的资源列表 API，返回的资源列表都会被分页。配置文件中的分页设置将作用于全局，如果某个视图函数或者视图集不想使用全局配置怎么办呢？可以在视图函数或者视图集中设置 pagination_class 属性，指定需要使用的分页辅助类即可。例如将博客文章列表分页替换为 limit offset 的分页方式，可以这样设置：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-python&quot;&gt;from rest_framewrok.pagination import PageNumberPagination

class PostViewSet(viewsets.GenericViewSet):
    pagination_class = LimitOffsetPagination
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;这样，&lt;code&gt;PostViewSet&lt;/code&gt; 视图集将返回 limit offset 分页形式的文章列表，而其他视图或者视图集仍将使用全局的分页配置。&lt;/p&gt;
&lt;p&gt;请求文章 api，返回结果如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://blog-1253812787.cos.ap-chengdu.myqcloud.com/page_number_pagination.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;对返回结果的解释：&lt;/p&gt;
&lt;p&gt;count：总资源数目&lt;/p&gt;
&lt;p&gt;next：下一页资源的链接&lt;/p&gt;
&lt;p&gt;previous：上一页资源的链接&lt;/p&gt;
&lt;p&gt;results：当前页的资源列表&lt;/p&gt;
&lt;hr/&gt;&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/759200/202002/759200-20200213201956024-782757549.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;关注公众号加入交流群&lt;/strong&gt;&lt;/p&gt;
</description>
<pubDate>Fri, 22 May 2020 00:48:00 +0000</pubDate>
<dc:creator>削微寒</dc:creator>
<og:description>作者： &amp;quot;HelloGitHub 追梦人物&amp;quot; 如果没有设置分页，django rest framework 会将所有资源类表序列化后返回，如果资源很多，就会对网站性能造成影响。为此</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/xueweihan/p/12930845.html</dc:identifier>
</item>
<item>
<title>React Native 架构演进 - 梦烬</title>
<link>http://www.cnblogs.com/ayqy/p/react-native-new-architecture.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/ayqy/p/react-native-new-architecture.html</guid>
<description>&lt;p&gt;上一篇（&lt;a href=&quot;http://www.ayqy.net/blog/react-native-architecture-overview/&quot;&gt;React Native 架构一览&lt;/a&gt;）从设计、线程模型等方面介绍了 React Native 的现有架构，本篇将分析这种架构的局限性，以及 React Native 正在进行的架构升级计划&lt;/p&gt;
&lt;p class=&quot;sync-line&quot; data-line=&quot;4&quot;&gt; &lt;/p&gt;

&lt;p&gt;最初的设计也带来了一些限制：&lt;/p&gt;
&lt;ul readability=&quot;0&quot;&gt;&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;异步：无法将 JavaScript 逻辑直接与许多需要同步答案的 Native API 集成&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;批处理：很难让 React Native 应用调用 Native 实现的函数&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;可序列化：存在不必要的 copy，而不是直接共享内存&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;这些问题在 Native + React Native 的混合应用中尤其突出：&lt;/p&gt;
&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;For apps that are entirely built in React Native, these restrictions are usually bearable. But for apps with complex integration between React Native and existing app code, they are frustrating.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p class=&quot;sync-line&quot; data-line=&quot;18&quot;&gt; &lt;/p&gt;

&lt;p&gt;因此，2018 年 6 月提出大规模重构的计划，目的是更好地支持混合应用：&lt;/p&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;We're working on a large-scale rearchitecture of React Native to make the framework more flexible and integrate better with native infrastructure in hybrid JavaScript/native apps.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p class=&quot;sync-line&quot; data-line=&quot;24&quot;&gt; &lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://miro.medium.com/max/1600/1*mSGPH9SIopScxnpF7Wimdg.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p class=&quot;sync-line&quot; data-line=&quot;25&quot;&gt; &lt;/p&gt;
&lt;p&gt;具体的，有 3 点重大改动：&lt;/p&gt;
&lt;ul readability=&quot;0.47491638795987&quot;&gt;&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;线程模型：允许&lt;strong&gt;在任意线程中同步调用 JavaScript&lt;/strong&gt;执行高优先级的更新，UI 更新不再非要跨 3 个线程才能进行&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-0.81927710843373&quot;&gt;
&lt;p&gt;React：支持 React 16+的新特性，包括&lt;a href=&quot;https://reactjs.org/blog/2018/03/01/sneak-peek-beyond-react-16.html&quot;&gt;async rendering&lt;/a&gt;、Data Fetching 等等&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;Bridge：精简优化，允许 Native 与 JavaScript 之间的直接调用&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;支持同步调用让之前很难实现的一些东西成为了可能，例如跨语言的调用栈追踪&lt;/p&gt;
&lt;p&gt;对应到架构图中，相当于对每一层进行单独优化：&lt;/p&gt;
&lt;ul readability=&quot;1.5&quot;&gt;&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;React 层：增强 JavaScript 类型安全，并支持 React 16+新特性&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;JavaScript 层：引入 JSI，允许替换不同的 JavaScript 引擎&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;Bridge 层：划分成 Fabric 和 TurboModules 两部分，分别负责 UI 渲染与 Native 模块&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;Native 层：精简核心模块，将非核心部分拆分出去作为社区模块独立更新维护&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;初步估计，这些重构工作预期在 2019 年底或 2020 年初完成：&lt;/p&gt;
&lt;blockquote readability=&quot;7&quot;&gt;
&lt;p&gt;It’s likely this massive piece of work will reach its conclusion around Q4 2019 or Q1 2020, but there are no confirmed dates.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;P.S.目前（2019/9/8）除已完成的 JSI 外，其余重构计划仍在进行中，具体见&lt;a href=&quot;https://formidable.com/blog/2019/lean-core-part-4/&quot;&gt;The New React Native Architecture Explained: Part Four&lt;/a&gt;&lt;/p&gt;
&lt;p class=&quot;sync-line&quot; data-line=&quot;52&quot;&gt; &lt;/p&gt;

&lt;p class=&quot;sync-line&quot; data-line=&quot;54&quot;&gt; &lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://formidable.com/uploads/new-1.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p class=&quot;sync-line&quot; data-line=&quot;55&quot;&gt; &lt;/p&gt;
&lt;p&gt;主要变化在于，提供 CodeGen 工具来保证消息通信的类型安全，以解决 JavaScript 与 Native 通信中被广为诟病的 Bridge API 数据类型问题：&lt;/p&gt;
&lt;blockquote readability=&quot;10&quot;&gt;
&lt;p&gt;We also experienced many issues in which the types coming from JavaScript were unexpected. For example, integers were often wrapped by strings, an issue that isn’t realized until it is passed over a bridge. To make matters worse, sometimes iOS will fail silently while Android will crash.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;（摘自&lt;a href=&quot;https://medium.com/airbnb-engineering/react-native-at-airbnb-the-technology-dafd0b43838#992a&quot;&gt;React Native at Airbnb: The Technology&lt;/a&gt;）&lt;/p&gt;
&lt;p&gt;另一方面，类型约束对通信性能也有一定帮助：&lt;/p&gt;
&lt;blockquote readability=&quot;7&quot;&gt;
&lt;p&gt;This automation will speed up the communication too, as it’s not necessary to validate the data every time.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p class=&quot;sync-line&quot; data-line=&quot;66&quot;&gt; &lt;/p&gt;

&lt;p class=&quot;sync-line&quot; data-line=&quot;68&quot;&gt; &lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://formidable.com/uploads/new-2.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p class=&quot;sync-line&quot; data-line=&quot;69&quot;&gt; &lt;/p&gt;
&lt;p&gt;上层 JavaScript 代码需要一个运行时环境，在 React Native 中这个环境是 JSC（JavaScriptCore）。不同于之前直接将 JavaScript 代码输入给 JSC，新的架构中引入了一层 JSI（JavaScript Interface），作为 JSC 之上的抽象，&lt;em&gt;用来屏蔽 JavaScript 引擎的差异，允许换用不同的 JavaScript 引擎&lt;/em&gt;（如最近推出的&lt;a href=&quot;https://engineering.fb.com/android/hermes/&quot;&gt;Hermes&lt;/a&gt;）&lt;/p&gt;
&lt;p&gt;更重要的，有了 JSI 之后，JavaScript 还能持有 C++对象的引用，并调用其方法：&lt;/p&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;By using JSI, JavaScript can hold reference to C++ Host Objects and invoke methods on them.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;从而允许 JavaScript 与 Native 的直接调用，而不必通过跨线程消息通信，省去序列化/反序列化的成本，还能减轻 Bridge 的通信压力（如大量消息排队堵车）&lt;/p&gt;
&lt;p&gt;同时&lt;strong&gt;JSI 所在的 C++层也可以作为复用 Native 代码的一种方式&lt;/strong&gt;，拥有 Native 的天然支持：&lt;/p&gt;
&lt;p class=&quot;sync-line&quot; data-line=&quot;84&quot;&gt; &lt;/p&gt;

&lt;p class=&quot;sync-line&quot; data-line=&quot;86&quot;&gt; &lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://formidable.com/uploads/new-5.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p class=&quot;sync-line&quot; data-line=&quot;87&quot;&gt; &lt;/p&gt;
&lt;p&gt;新的 Bridge 层被划分成 Fabric 和 TurboModules 两部分：&lt;/p&gt;
&lt;p&gt;Fabric 期望以更现代化的方式去实现 React Native 的渲染层，简化之前渲染流程中复杂跨线程交互（React -&amp;gt; Native -&amp;gt; Shadow Tree -&amp;gt; Native UI）。具体的，直接在 C++层创建 JavaScript 与 Native 共享的 Shadow Tree，并通过 JSI 层将 UI 操作接口暴露给 JavaScript，允许 JavaScript 直接控制高优先级的 UI 操作，甚至允许同步调用（应对列表快速滚动、页面切换、手势处理等场景）&lt;/p&gt;
&lt;p&gt;之前所有 Native Modules（无论是否需要用到）都要在应用启动时进行初始化，因为 Native 不知道 JavaScript 将会调用哪些功能模块。而新的&lt;strong&gt;TurboModules 允许按需加载 Native 模块&lt;/strong&gt;，并在模块初始化之后直接持有其引用，不再依靠消息通信来调用模块功能。因此，应用的启动时间也会有所提升&lt;/p&gt;
&lt;p class=&quot;sync-line&quot; data-line=&quot;98&quot;&gt; &lt;/p&gt;

&lt;p class=&quot;sync-line&quot; data-line=&quot;100&quot;&gt; &lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://formidable.com/uploads/new-diagram-full.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p class=&quot;sync-line&quot; data-line=&quot;101&quot;&gt; &lt;/p&gt;
&lt;p&gt;理论上，React Native 应该是通用的，对平台无感知，这是能够支持&lt;a href=&quot;https://github.com/necolas/react-native-web&quot;&gt;Web&lt;/a&gt;、&lt;a href=&quot;https://github.com/Microsoft/react-native-windows&quot;&gt;Windows&lt;/a&gt;等不同平台的关键&lt;/p&gt;
&lt;p&gt;虽然 Native 不在 React Native 的掌控中，无法垂直地深入优化，但可以进行横向的精简，将非核心的部分代码拆分出去作为社区模块，如 AsyncStorage、ImageStore、MaskedViewIOS、NetInfo 等等。一方面缩减包体积，另一方面也有利于这些模块的独立更新维护&lt;/p&gt;
&lt;p class=&quot;sync-line&quot; data-line=&quot;106&quot;&gt; &lt;/p&gt;

</description>
<pubDate>Fri, 22 May 2020 00:48:00 +0000</pubDate>
<dc:creator>梦烬</dc:creator>
<og:description>React Native 最初的设计存在什么问题，打算怎样改进？</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/ayqy/p/react-native-new-architecture.html</dc:identifier>
</item>
<item>
<title>[翻译]用于.NET Core的Windows窗体设计器发布 - 开发者精选资讯</title>
<link>http://www.cnblogs.com/MrHuo/p/windows-forms-designer-for-net-core-released.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/MrHuo/p/windows-forms-designer-for-net-core-released.html</guid>
<description>&lt;div id=&quot;cnblogs_post_description&quot; readability=&quot;34&quot;&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/316520/202005/316520-20200522025457062-1963045946.png&quot; class=&quot;desc_img&quot;/&gt;今天我们很高兴地宣布，.NET Core项目的Windows窗体设计器现在可以在 Visual Studio 2019 16.6 版中作为预览使用！我们在Visual Studio 16.7 预览版1中也提供了更新的设计器版本！&lt;/div&gt;&lt;div id=&quot;cnblogs_post_body&quot; readability=&quot;85.331898800209&quot;&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;本文由微信公众号《开发者精选资讯》翻译首发，转载请注明来源&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;今天我们很高兴地宣布，.NET Core项目的Windows窗体设计器现在可以在 Visual Studio 2019 16.6 版中作为预览使用！我们在Visual Studio 16.7 预览版1中也提供了更新的设计器版本！&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/316520/202005/316520-20200522025457062-1963045946.png&quot; alt=&quot;Visual Studio中的.NET Core Windows窗体设计器&quot;/&gt;&lt;/p&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;不要忘记在“工具” &amp;gt; “选项” &amp;gt; “环境” &amp;gt; “预览功能”中启用设计器 。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;许多人可能还记得我们在 &lt;a href=&quot;https://blogs.windows.com/windowsdeveloper/2018/12/04/announcing-open-source-of-wpf-windows-forms-and-winui-at-microsoft-connect-2018/&quot;&gt;开源Windows窗体&lt;/a&gt; 并将其移植到.NET Core 3.0的.NET Core中。从那时起，我们一直 &lt;a href=&quot;https://devblogs.microsoft.com/dotnet/updates-to-net-core-windows-forms-designer-in-visual-studio-16-5-preview-1/#under-the-hood&quot;&gt;在努力&lt;/a&gt; 将Windows 窗体设计器的引入.NET Core。当我们接近完成时，我们继续设计器开发，并计划在不久的将来带来更多的功能和性能改进。&lt;/p&gt;
&lt;h2 id=&quot;如何使用窗体设计器&quot;&gt;如何使用窗体设计器&lt;/h2&gt;
&lt;p&gt;安装 &lt;a href=&quot;https://visualstudio.microsoft.com/downloads/&quot;&gt;Visual Studio 2019版本16.6&lt;/a&gt; 或 Visual Studio 2019版本16.7预览版1。&lt;br/&gt;要在Visual Studio中启用设计器，请转到“工具” &amp;gt; “选项” &amp;gt; “环境” &amp;gt; “预览功能”， 然后选择 “将Windows Forms预览设计器用于.NET Core应用程序” 选项。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/316520/202005/316520-20200522025543379-1940373521.png&quot; alt=&quot;在Visual Studio设置中启用.NET Core Windows窗体设计器&quot;/&gt;&lt;/p&gt;
&lt;p&gt;完成这些步骤后，在解决方案资源管理器中双击窗体后，设计器将自动以与.NET Framework应用程序相同的方式打开。&lt;/p&gt;
&lt;p&gt;完成功能工作后，提高性能是我们的下一个目标，因此，如果设计者预览时的速度不如您想象的那么快，请不要感到烦恼，这是我们将来会改进的。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;当前，新的Windows窗体设计器仅在Windows 10上有效。&lt;/strong&gt;&lt;/p&gt;
&lt;h2 id=&quot;设计器中可用的功能&quot;&gt;设计器中可用的功能&lt;/h2&gt;
&lt;ul readability=&quot;4.8034274193548&quot;&gt;&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;除了 DataGridView 和 ToolStripContainer 之外的所有Windows窗体控件（即将推出）&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;UserControl和自定义控件基础结构（仅Visual Studio 16.7 Preview 1版本可用）&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;所有设计器功能，例如&lt;br/&gt;· 拖放&lt;br/&gt;· 选择，移动和调整大小&lt;br/&gt;· 剪切/复制/粘贴/删除&lt;br/&gt;· 与属性窗口集成&lt;br/&gt;· 事件生成等&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;1.7745664739884&quot;&gt;
&lt;p&gt;新增 WebView2 控件&lt;br/&gt;基于chromium的嵌入式浏览器控件，允许呈现.NET应用程序的Web内容（HTML / CSS / JavaScript）。Windows窗体和WPF应用程序的.NET Core和.NET Framework平台均支持。您可以 &lt;a href=&quot;https://docs.microsoft.com/microsoft-edge/webview2/gettingstarted/winforms&quot;&gt;在Microsoft入门指南文档中找到&lt;/a&gt;，我们将在不久的将来发布专门针对WebView2控件的博客文章。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;本地资源&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;1&quot;&gt;
&lt;p&gt;对本地化的部分支持&lt;br/&gt;· 控件和UserControl的可本地化属性可以序列化为Resx文件（通过将Localizable 属性设置 为 true）。&lt;br/&gt;· 通过更改Language 属性支持不同的语言。&lt;br/&gt;· 根据Unicode标准国际组件（ICU）在.NET 5的预览中添加了其他功能。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;h2 id=&quot;接下来会发生什么&quot;&gt;接下来会发生什么&lt;/h2&gt;
&lt;ul&gt;&lt;li&gt;项目资源&lt;/li&gt;
&lt;li&gt;完全本地化&lt;/li&gt;
&lt;li&gt;可继承的对话框支持&lt;/li&gt;
&lt;li&gt;数据绑定方案&lt;br/&gt;这项工作正在进行中，您已经可以在Visual Studio 16.7 Preview 1设计器中看到这些结果。&lt;/li&gt;
&lt;li&gt;第三方控件供应商支持&lt;br/&gt;我们正在与Progress Telerik，DevExpress和GrapeCity等控件供应商紧密合作，以在不久的将来为.NET Core和.NET 5项目在Windows Forms设计器中支持其控件。我们还与ActiPro，Infragistics和SyncFusion合作。在下图上，您可以看到Windows窗体应用程序中针对.NET 5的Progress Telerik控件。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/316520/202005/316520-20200522025606884-1731903990.png&quot; alt=&quot;在.NET 5中使用Progress Telerik RadGridView控件&quot;/&gt;&lt;/p&gt;
&lt;h2 id=&quot;166-ga版本中的新功能&quot;&gt;16.6 GA版本中的新功能&lt;/h2&gt;
&lt;p&gt;在16.6版本中，进行了以下控件支持和改进。&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;所有对话框控件&lt;/li&gt;
&lt;li&gt;PropertyGrid&lt;/li&gt;
&lt;li&gt;HScrollBar&lt;/li&gt;
&lt;li&gt;VScrollBar&lt;/li&gt;
&lt;li&gt;DomainUpDown&lt;/li&gt;
&lt;li&gt;TrackBar&lt;/li&gt;
&lt;li&gt;拖放改进&lt;/li&gt;
&lt;li&gt;选中改进&lt;/li&gt;
&lt;li&gt;稳定性和错误修复&lt;/li&gt;
&lt;/ul&gt;&lt;h2 id=&quot;167-preview-1版本中的新功能&quot;&gt;16.7 Preview 1版本中的新功能&lt;/h2&gt;
&lt;p&gt;在 16.7 Preview 1发行版中进行了以下控件支持和改进。&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;UserControl 和自定义控件基础结构&lt;/li&gt;
&lt;li&gt;TableLayoutPanel&lt;/li&gt;
&lt;li&gt;第三方控件支持基础&lt;/li&gt;
&lt;li&gt;数据绑定支持基础&lt;/li&gt;
&lt;li&gt;使用 TableLayoutPanel 改进的设计器&lt;/li&gt;
&lt;/ul&gt;&lt;h2 id=&quot;给我们提交反馈&quot;&gt;给我们提交反馈&lt;/h2&gt;
&lt;p&gt;您的反馈意见对我们很重要！请报告问题并通过Visual Studio反馈通道发送功能请求。如下图所示，使用Visual Studio右上角的“发送反馈”图标，并指定它与“ WinForms .NET Core”区域。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/316520/202005/316520-20200522031601809-534190903.png&quot; alt=&quot;直接从Visual Studio提供反馈&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/316520/202005/316520-20200522031918924-278182228.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;关注微信公众号《开发者精选资讯》&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;</description>
<pubDate>Fri, 22 May 2020 00:42:00 +0000</pubDate>
<dc:creator>开发者精选资讯</dc:creator>
<og:description>本文由微信公众号《开发者精选资讯》翻译首发，转载请注明来源 今天我们很高兴地宣布，.NET Core项目的Windows窗体设计器现在可以在 Visual Studio 2019 16.6 版中作为预</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/MrHuo/p/windows-forms-designer-for-net-core-released.html</dc:identifier>
</item>
<item>
<title>C# 数据操作系列 - 12 NHibernate的增删改查 - 月影西下</title>
<link>http://www.cnblogs.com/c7jie/p/12934996.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/c7jie/p/12934996.html</guid>
<description>&lt;p&gt;上一篇《C# 数据操作系列 - 11 NHibernate 配置和结构介绍》 介绍了Nhibernate里的配置内容。这一篇将带领大家了解一下如何使用NHIbernate。之前提到NHibernate继承了Hibernate的一些传统：使用XML文件进行配置，这一点也是备受争议。不过，有社区爱好者开发了一个名为《Fluent NHibernate》的项目，用来支持NHibernate的流式配置。当然，NHibernate本身也提供了&lt;code&gt;NHibernate.Mapping.ByCode&lt;/code&gt;模式。不过这一篇暂且略过，留待下文。&lt;/p&gt;

&lt;p&gt;对于NHibernate的映射文件有个约定的名字：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&amp;lt;类名&amp;gt;.hbm.xml&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;这里先为大家介绍一下映射文件的格式：&lt;/p&gt;
&lt;h2 id=&quot;11-hibernate-mapping-的说明&quot;&gt;1.1 hibernate-mapping 的说明&lt;/h2&gt;
&lt;pre&gt;
&lt;code class=&quot;language-xml&quot;&gt;&amp;lt;hibernate-mapping
schema=&quot;schemaName&quot;                                                                   (1)
default-cascade=&quot;none|save-update&quot;                                            (2)
auto-import=&quot;true|false&quot;                                                              (3)
assembly=&quot;Eg&quot;                                                                                         (4)
namespace=&quot;Eg&quot;                                                                                        (5)
default-access=&quot;field|property|field.camecase...&quot;             (6)
default-lazy=&quot;true|false&quot;                                                             (7)
/&amp;gt;
&lt;/code&gt;
&lt;/pre&gt;
&lt;ol&gt;&lt;li&gt;schema: 数据库schema的名称&lt;/li&gt;
&lt;li&gt;default-cascade：可选项，默认是none，一种默认的级联风格&lt;/li&gt;
&lt;li&gt;auto-import：明确是否可以在查询中使用非限定类名。&lt;/li&gt;
&lt;li&gt;assembly：指定映射对象所在的assembly，一般情况指的是项目名称&lt;/li&gt;
&lt;li&gt;namespace：所在命名空间&lt;/li&gt;
&lt;li&gt;default-access：可选的，默认是property，表示NHibernate的读取数据列的策略，默认情况从Property 中读取&lt;/li&gt;
&lt;li&gt;default-lazy：可选的，默认是true，是否启动延迟加载&lt;/li&gt;
&lt;/ol&gt;&lt;h2 id=&quot;12-class的配置&quot;&gt;1.2 class的配置&lt;/h2&gt;
&lt;p&gt;一般情况下，class节点只需要指定name和table就可以了。接下来，让我们探索class如何映射成的。&lt;/p&gt;
&lt;h3 id=&quot;121-id&quot;&gt;1.2.1 id&lt;/h3&gt;
&lt;p&gt;任何一个映射都必须声明一个数据表的主键，大多数类也必须有一个唯一标示字段用来区分不同的实例。&lt;/p&gt;
&lt;p&gt;这里介绍一下 id 节点的配置：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-xml&quot;&gt;&amp;lt;id 
    name=&quot;PropertyName&quot;
    type=&quot;typename&quot;
    column=&quot;column_name&quot;&amp;gt;
    &amp;lt;generator class=&quot;generatorClass&quot;/&amp;gt;
&amp;lt;/id&amp;gt;
&lt;/code&gt;
&lt;/pre&gt;
&lt;ul&gt;&lt;li&gt;name : 对应的属性名&lt;/li&gt;
&lt;li&gt;type：对应的NHibernate类型&lt;/li&gt;
&lt;li&gt;column：列名&lt;/li&gt;
&lt;li&gt;generator：主键生成器，如果不需要参数可以直接在 id节点处添加，最常用的是native。&lt;/li&gt;
&lt;/ul&gt;&lt;h3 id=&quot;122-property&quot;&gt;1.2.2 property&lt;/h3&gt;
&lt;p&gt;映射一个普通属性就简单多了，只需要进行以下配置即可：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-xml&quot;&gt;&amp;lt;property
          name=&quot;propertyName&quot;
          column=&quot;column_name&quot;
          type=&quot;typename&quot;
/&amp;gt;
&lt;/code&gt;
&lt;/pre&gt;
&lt;ul&gt;&lt;li&gt;name ：类里的属性名&lt;/li&gt;
&lt;li&gt;column：对应数据表的列名&lt;/li&gt;
&lt;li&gt;type：数据库中的类型&lt;/li&gt;
&lt;/ul&gt;&lt;h3 id=&quot;123-many-to-one&quot;&gt;1.2.3 many-to-one&lt;/h3&gt;
&lt;p&gt;在Nhibernate中，多对一的配置是在一的一端，表示该类有一个外键导航。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-xml&quot;&gt;&amp;lt;many-to-one
             name=&quot;PropertyInOne&quot;
             class=&quot;ManyClass&quot;
             column=&quot;Column&quot;
             &amp;gt;&amp;lt;/many-to-one&amp;gt;
&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;124-one-to-one&quot;&gt;1.2.4 one-to-one&lt;/h3&gt;
&lt;p&gt;一对一的关系与多对一的关系比较相似，不同的地方在于一对一需要在双方的映射关系里均要维护，在有外键的表/实体中 添加 constrained=“true”。&lt;/p&gt;
&lt;p&gt;示例如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-xml&quot;&gt;&amp;lt;one-to-one name=&quot;Person&quot; class=&quot;Person&quot;/&amp;gt;
&amp;lt;one-to-one name=&quot;Employee&quot; class=&quot;Employee&quot; constrained=&quot;true&quot;/&amp;gt;
&lt;/code&gt;
&lt;/pre&gt;

&lt;p&gt;Nhibernate的每次操作都基于一个Session，所以我们在操作数据库的时候最好先持有一个可用的Session。接下来，我们就一个通用数据库操作类为基础，向大家分享一下我的想法。&lt;/p&gt;
&lt;p&gt;首先，创建一个泛型模板类，并约束泛型为类：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-c#&quot;&gt;public class Repository&amp;lt;T&amp;gt; where T: class
{

}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;添加一个ISession属性，用来后续访问操作，并由构造方法赋值：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-c#&quot;&gt;public Repository(ISession session)
{
    Session = session;
}

public ISession Session { get; }
&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;21-新增&quot;&gt;2.1 新增&lt;/h2&gt;
&lt;p&gt;现在我们写一下新增方法：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-c#&quot;&gt;public object Add(T entity)
{
    var key= Session.Save(entity);
    return key;
}

public void Add(params T[] entities)
{
    foreach (var entity in entities)
    {
        Session.Save(entity);
    }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;查了下，Save会返回当前持久化对象插入时生成的主键。&lt;/p&gt;
&lt;h2 id=&quot;22-修改&quot;&gt;2.2 修改&lt;/h2&gt;
&lt;p&gt;NHibernate的修改与EF类似，也是由ISession监控了修改，不用做过多的操作。&lt;/p&gt;
&lt;h2 id=&quot;23-删除&quot;&gt;2.3 删除&lt;/h2&gt;
&lt;p&gt;NHibernate的删除也十分简单，直接通知ISession删除某个持久化对象。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-c#&quot;&gt;public void Delete(T entity)
{
    Session.Delete(entity);
}
public void Delete(params T[] entities)
{
    foreach (var entity in entities)
    {
        Session.Delete(entity);
    }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;24-查询&quot;&gt;2.4 查询&lt;/h2&gt;
&lt;p&gt;通常情况下，查询需要结合实际业务来进行开发，当然为了通用，我在这里选择给调用方开放一个查询对象：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-c#&quot;&gt;public IQueryable&amp;lt;T&amp;gt; IqQueryable()
{
    return Session.Query&amp;lt;T&amp;gt;();
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;其中 IQueryable是一个接口，表示这是一个可查询对象，通过Linq可以快捷的查询。&lt;/p&gt;

&lt;p&gt;嗯，NHibernate基础使用篇到这里可以暂告一段落了。后续的内容有机会再深挖，当然并不代表EF Core就没有了。嗯嗯，没毛病。下一篇就让我来先替大伙看看SugarSQL是什么情况吧。&lt;/p&gt;
&lt;p&gt;不过在本篇内容完结之前，先补充一个NHibernate的SqlDialect选值：&lt;/p&gt;
&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;数据库&lt;/th&gt;
&lt;th&gt;Dialect&lt;/th&gt;
&lt;th&gt;备注&lt;/th&gt;
&lt;/tr&gt;&lt;/thead&gt;&lt;tbody readability=&quot;48&quot;&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;DB2&lt;/td&gt;
&lt;td&gt;NHibernate.Dialect.DB2Dialect&lt;/td&gt;
&lt;td/&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;DB2 for iSeries(OS/400)&lt;/td&gt;
&lt;td&gt;NHibernate.Dialect.DB2400Dialect&lt;/td&gt;
&lt;td/&gt;
&lt;/tr&gt;&lt;tr readability=&quot;4&quot;&gt;&lt;td&gt;Firebird&lt;/td&gt;
&lt;td&gt;NHibernate.Dialect.FirebirdDialect&lt;/td&gt;
&lt;td&gt;需要设置driver_class为NHibernate.Driver.FirebirdClientDriver&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;Informix&lt;/td&gt;
&lt;td&gt;NHibernate.Dialect.InformixDialect&lt;/td&gt;
&lt;td/&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;Informix 9.40&lt;/td&gt;
&lt;td&gt;NHibernate.Dialect.InformixDialect0940&lt;/td&gt;
&lt;td/&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;Informix 10.00&lt;/td&gt;
&lt;td&gt;NHibernate.Dialect.InformixDialect1000&lt;/td&gt;
&lt;td/&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;Ingres&lt;/td&gt;
&lt;td&gt;NHibernate.Dialect.IngresDialect&lt;/td&gt;
&lt;td/&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;Ingres 9&lt;/td&gt;
&lt;td&gt;NHibernate.Dialect.Ingres9Dialect&lt;/td&gt;
&lt;td/&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;Microsoft SQL Server 7&lt;/td&gt;
&lt;td&gt;NHibernate.Dialect.MsSql7Dialect&lt;/td&gt;
&lt;td/&gt;
&lt;/tr&gt;&lt;tr readability=&quot;4&quot;&gt;&lt;td&gt;Microsoft SQL Server 2000&lt;/td&gt;
&lt;td&gt;NHibernate.Dialect.MsSql2000Dialect&lt;/td&gt;
&lt;td/&gt;
&lt;/tr&gt;&lt;tr readability=&quot;4&quot;&gt;&lt;td&gt;Microsoft SQL Server 2005&lt;/td&gt;
&lt;td&gt;NHibernate.Dialect.MsSql2005Dialect&lt;/td&gt;
&lt;td/&gt;
&lt;/tr&gt;&lt;tr readability=&quot;4&quot;&gt;&lt;td&gt;Microsoft SQL Server 2008&lt;/td&gt;
&lt;td&gt;NHibernate.Dialect.MsSql2008Dialect&lt;/td&gt;
&lt;td/&gt;
&lt;/tr&gt;&lt;tr readability=&quot;4&quot;&gt;&lt;td&gt;Microsoft SQL Azure Server 2008&lt;/td&gt;
&lt;td&gt;NHibernate.Dialect.MsSqlAzure2008Dialect&lt;/td&gt;
&lt;td/&gt;
&lt;/tr&gt;&lt;tr readability=&quot;4&quot;&gt;&lt;td&gt;Microsoft SQL Server 2012&lt;/td&gt;
&lt;td&gt;Hibernate.Dialect.MsSql2012Dialect&lt;/td&gt;
&lt;td/&gt;
&lt;/tr&gt;&lt;tr readability=&quot;4&quot;&gt;&lt;td&gt;Microsoft SQL Server Compact Edition&lt;/td&gt;
&lt;td&gt;NHibernate.Dialect.MsSqlCeDialect&lt;/td&gt;
&lt;td/&gt;
&lt;/tr&gt;&lt;tr readability=&quot;4&quot;&gt;&lt;td&gt;Microsoft SQL Server Compact Edition 4.0&lt;/td&gt;
&lt;td&gt;NHibernate.Dialect.MsSqlCe40Dialect&lt;/td&gt;
&lt;td/&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;MySQL 3 or 4&lt;/td&gt;
&lt;td&gt;NHibernate.Dialect.MySQLDialect&lt;/td&gt;
&lt;td/&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;MySQL 5&lt;/td&gt;
&lt;td&gt;NHibernate.Dialect.MySQL5Dialect&lt;/td&gt;
&lt;td/&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;MySQL 5 InnoDB&lt;/td&gt;
&lt;td&gt;NHibernate.Dialect.MySQL5InnoDBDialect&lt;/td&gt;
&lt;td/&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;MySQL 5.5&lt;/td&gt;
&lt;td&gt;NHibernate.Dialect.MySQL55Dialect&lt;/td&gt;
&lt;td/&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;MySQL 5.5 Inno DB&lt;/td&gt;
&lt;td&gt;NHibernate.Dialect.MySQL55InnoDBDialect&lt;/td&gt;
&lt;td/&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;Oracle&lt;/td&gt;
&lt;td&gt;NHibernate.Dialect.Oracle8iDialect&lt;/td&gt;
&lt;td/&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;Oracle 9i&lt;/td&gt;
&lt;td&gt;NHibernate.Dialect.Oracle9iDialect&lt;/td&gt;
&lt;td/&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;Oracle 10g, Oracle 11g&lt;/td&gt;
&lt;td&gt;NHibernate.Dialect.Oracle10gDialect&lt;/td&gt;
&lt;td/&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;Oracle 12c&lt;/td&gt;
&lt;td&gt;NHibernate.Dialect.Oracle12cDialect&lt;/td&gt;
&lt;td/&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;PostgreSQL&lt;/td&gt;
&lt;td&gt;NHibernate.Dialect.PostgreSQLDialect&lt;/td&gt;
&lt;td/&gt;
&lt;/tr&gt;&lt;tr readability=&quot;4&quot;&gt;&lt;td&gt;PostgreSQL 8.1&lt;/td&gt;
&lt;td&gt;NHibernate.Dialect.PostgreSQL81Dialect&lt;/td&gt;
&lt;td&gt;支持8.1 的 FOR UPDATE NOWAIT&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;4&quot;&gt;&lt;td&gt;PostgreSQL 8.2&lt;/td&gt;
&lt;td&gt;NHibernate.Dialect.PostgreSQL82Dialect&lt;/td&gt;
&lt;td&gt;在DROP TABLE和DROP SEQUENCE 语句中支持 IF EXISTS关键字&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;PostgreSQL 8.3&lt;/td&gt;
&lt;td&gt;NHibernate.Dialect.PostgreSQL83Dialect&lt;/td&gt;
&lt;td&gt;支持XML类型&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;4&quot;&gt;&lt;td&gt;SQLite&lt;/td&gt;
&lt;td&gt;NHibernate.Dialect.SQLiteDialect&lt;/td&gt;
&lt;td&gt;设置driver_class为NHibernate.Driver.SQLite20Driver&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;4&quot;&gt;&lt;td&gt;Sybase Adaptive Server Anywhere 9&lt;/td&gt;
&lt;td&gt;NHibernate.Dialect.SybaseASA9Dialect&lt;/td&gt;
&lt;td/&gt;
&lt;/tr&gt;&lt;tr readability=&quot;4&quot;&gt;&lt;td&gt;Sybase Adaptive Server Enterprise 15&lt;/td&gt;
&lt;td&gt;NHibernate.Dialect.SybaseASE15Dialect&lt;/td&gt;
&lt;td/&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;Sybase SQL Anywhere 10&lt;/td&gt;
&lt;td&gt;NHibernate.Dialect.SybaseSQLAnywhere10Dialect&lt;/td&gt;
&lt;td/&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;Sybase SQL Anywhere 11&lt;/td&gt;
&lt;td&gt;NHibernate.Dialect.SybaseSQLAnywhere11Dialect&lt;/td&gt;
&lt;td/&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;Sybase SQL Anywhere 12&lt;/td&gt;
&lt;td&gt;NHibernate.Dialect.SybaseSQLAnywhere12Dialect&lt;/td&gt;
&lt;td/&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;blockquote readability=&quot;2.1052631578947&quot;&gt;
&lt;p&gt;更多内容烦请关注&lt;a href=&quot;https://www.attachie.club&quot;&gt;我的博客《高先生小屋》&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/1266612/202005/1266612-20200522080656380-1887334291.png&quot; alt=&quot;file&quot;/&gt;&lt;/p&gt;
</description>
<pubDate>Fri, 22 May 2020 00:07:00 +0000</pubDate>
<dc:creator>月影西下</dc:creator>
<og:description>0. 前言 上一篇《C 数据操作系列 11 NHibernate 配置和结构介绍》 介绍了Nhibernate里的配置内容。这一篇将带领大家了解一下如何使用NHIbernate。之前提到NHibern</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/c7jie/p/12934996.html</dc:identifier>
</item>
<item>
<title>BitArray虽好，但请不要滥用，又一次线上内存暴增排查 - 一线码农</title>
<link>http://www.cnblogs.com/huangxincheng/p/12934975.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/huangxincheng/p/12934975.html</guid>
<description>&lt;h2 id=&quot;一：背景&quot;&gt;一：背景&lt;/h2&gt;
&lt;h3 id=&quot;1-讲故事&quot;&gt;1. 讲故事&lt;/h3&gt;
&lt;p&gt;前天写了一篇大内存排查在园子里挺火，这是做自媒体最开心的事拉，干脆再来一篇满足大家胃口，上个月我写了一篇博客提到过使用&lt;code&gt;bitmap&lt;/code&gt;对原来的&lt;code&gt;List&amp;lt;CustomerID&amp;gt;&lt;/code&gt;进行高强度压缩，将原来的List内存压缩了将近106倍，但是bitmap不是一味的好，你必须在正确的场景中使用，而不是闭着眼睛滥用，bitmap在C#中对应的集合是BitArray。&lt;/p&gt;
&lt;p&gt;好像剧透了😄😄😄，结果就是BitArray的滥用导致内存小10G的涨跌，不过这种东西重点还是看解决思路，写给以后的自己，可不能让这难得的实践经验蒸发啦~~~&lt;/p&gt;
&lt;h2 id=&quot;二：解决思路&quot;&gt;二：解决思路&lt;/h2&gt;
&lt;h3 id=&quot;1-一看托管堆&quot;&gt;1. 一看托管堆&lt;/h3&gt;
&lt;p&gt;看托管堆虽然是一个好主意，但也不是每次都凑效，毕竟造成内存暴涨暴跌的原因各种各样，就像人感冒有风寒，风热和病毒性，对吧😁，还是使用老命令： &lt;code&gt;!dumpheap -stat -min 102400&lt;/code&gt; ，在托管堆上找大于&lt;code&gt;100M&lt;/code&gt;的对象。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-C#&quot;&gt;
0:030&amp;gt; !dumpheap -stat -min 102400
Statistics:
              MT    Count    TotalSize Class Name
00007ffe094ec988        1      1438413 System.Byte[]
00007ffdab934c48        1      1810368 System.Collections.Generic.Dictionary`2+Entry[[System.Int32, mscorlib],[System.Collections.Generic.HashSet`1[[System.Int64, mscorlib]], System.Core]][]
00007ffe094e6948        1      2527996 System.String
00007ffdab9ace78        4     29499552 System.Collections.Generic.Dictionary`2+Entry[[System.Int64, mscorlib],[System.DateTime, mscorlib]][]
00007ffe094e4078        4    267342240 System.String[]
00007ffe094e9220      135    452683336 System.Int32[]
00007ffdab8cd620      123   1207931808 System.Collections.Generic.HashSet`1+Slot[[System.Int64, mscorlib]][]
00007ffe094c8510      185   1579292760 System.Int64[]
00007ffdab9516b0      154   1934622720 System.Linq.Set`1+Slot[[System.Int64, mscorlib]][]
000001cc882de970      347   3660623866      Free
Total 1371 objects

&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;去掉一些敏感类后，再观察好像没有特别显眼的集合，像 &lt;code&gt;System.Int64[] ,System.Linq.Set1+Slot[[System.Int64, mscorlib]][]&lt;/code&gt; 一般都是用作其他集合的内存存储，很多时候用&lt;code&gt;!gcroort&lt;/code&gt; 抓不出来，最大的反而是Free列，有347个碎片，高达 &lt;code&gt;3.5G&lt;/code&gt;，说明此时的大对象堆是一塌糊涂啊，要是GC能帮忙压缩一下该多好😄。&lt;/p&gt;
&lt;h3 id=&quot;2-查看每一个线程的调用栈&quot;&gt;2. 查看每一个线程的调用栈&lt;/h3&gt;
&lt;p&gt;先惯性的偷窥一下程序中有多少个线程。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-C#&quot;&gt;
0:000&amp;gt; !threads
ThreadCount:      74
UnstartedThread:  0
BackgroundThread: 72
PendingThread:    0
DeadThread:       0
Hosted Runtime:   no
                                                                                                        Lock  
       ID OSID ThreadOBJ           State GC Mode     GC Alloc Context                  Domain           Count Apt Exception
   0    1 2958 000001cc882e5a40    2a020 Preemptive  0000000000000000:0000000000000000 000001cc882d8db0 1     MTA 
   2    2 2358 000001cc883122c0    2b220 Preemptive  000001D41B132930:000001D41B1348A0 000001cc882d8db0 0     MTA (Finalizer) 
   3    4 2204 000001cc883ae5d0  102a220 Preemptive  0000000000000000:0000000000000000 000001cc882d8db0 0     MTA (Threadpool Worker) 
   5    7 278c 000001cca29d8ef0  202b220 Preemptive  000001D41AB53A98:000001D41AB55A58 000001cc882d8db0 1     MTA 
   6   40 2a64 000001cca3048f10  1020220 Preemptive  0000000000000000:0000000000000000 000001cc882d8db0 0     Ukn (Threadpool Worker) 
   7   46  e34 000001cca311c390  202b220 Preemptive  0000000000000000:0000000000000000 000001cc882d8db0 0     MTA 
   8   47 27d8 000001cca3115e00    2b220 Preemptive  0000000000000000:0000000000000000 000001cc882d8db0 0     MTA 

...

&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;可以看到当前有74个线程，后台线程有72个，接下来用 &lt;code&gt;~*e !clrstack&lt;/code&gt; 查看每个托管线程都在做什么，由于内容太多，我就节选一下了哈。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-C#&quot;&gt;0:000&amp;gt; ~*e !clrstack
OS Thread Id: 0x2d64 (29)
        Child SP               IP Call Site
000000d908cfe698 00007ffe28646bf4 [GCFrame: 000000d908cfe698] 
000000d908cfe768 00007ffe28646bf4 [HelperMethodFrame_1OBJ: 000000d908cfe768] System.Threading.Monitor.ObjWait(Boolean, Int32, System.Object)

OS Thread Id: 0x214c (30)
        Child SP               IP Call Site
000000d90957e6e8 00007ffe28646bf4 [GCFrame: 000000d90957e6e8] 
000000d90957e7b8 00007ffe28646bf4 [HelperMethodFrame_1OBJ: 000000d90957e7b8] System.Threading.Monitor.ObjWait(Boolean, Int32, System.Object)

OS Thread Id: 0x1dc0 (40)
        Child SP               IP Call Site
000000d950ebe878 00007ffe28646bf4 [GCFrame: 000000d950ebe878] 
000000d950ebe948 00007ffe28646bf4 [HelperMethodFrame_1OBJ: 000000d950ebe948] System.Threading.Monitor.ObjWait(Boolean, Int32, System.Object)

OS Thread Id: 0x274c (53)
        Child SP               IP Call Site
000000d9693fe518 00007ffe28646bf4 [GCFrame: 000000d9693fe518] 
000000d9693fe5e8 00007ffe28646bf4 [HelperMethodFrame_1OBJ: 000000d9693fe5e8] System.Threading.Monitor.ObjWait(Boolean, Int32, System.Object)
000000d9693fe700 00007ffe09314d05 System.Threading.ManualResetEventSlim.Wait(Int32, System.Threading.CancellationToken)
000000d9693fe790 00007ffe0930d996 System.Threading.Tasks.Task.SpinThenBlockingWait(Int32, System.Threading.CancellationToken)
000000d9693fe800 00007ffe09c9b7a1 System.Threading.Tasks.Task.InternalWait(Int32, System.Threading.CancellationToken)

&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/214741/202005/214741-20200522075313044-2048452876.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;发现一个奇怪的现象，有4个线程 &lt;code&gt;29,30,40,53&lt;/code&gt; 在 &lt;code&gt;Monitor.ObjWait&lt;/code&gt; 处卡住了，从调用栈来看这四个家伙正在准备向Mongodb批量插入数据[InsertBatch]，此时应该有其他的一个线程先行获取到了lock正在做InsertBatch，这四个线程在等待，如何觉得抽象了，我画一张图：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/214741/202005/214741-20200522075313346-61488258.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;h3 id=&quot;3-寻找insertbatch处的集合&quot;&gt;3. 寻找insertbatch处的集合&lt;/h3&gt;
&lt;p&gt;这里我就拿 &lt;code&gt;30&lt;/code&gt;号线程说事，从上图调用栈中你应该看到一个&lt;code&gt;System.Collections.Generic.IEnumerable1&amp;lt;System.__Canon&amp;gt;&lt;/code&gt;，从IEnumerable中可以猜测实现类应该是List或者HashSet这样的集合，接下来用 &lt;code&gt;!dso&lt;/code&gt; 把30号线程栈上的对象全部dump出来。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/214741/202005/214741-20200522075313563-1688657449.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;从图中看应该就是这个 &lt;code&gt;List&amp;lt;xxx.Common.GroupConditionCustomerIDCacheModel&amp;gt;&lt;/code&gt;，然后用&lt;code&gt;!objsize&lt;/code&gt; ➕&lt;code&gt;!do&lt;/code&gt; 给List量个尺寸并且dump一下。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-C#&quot;&gt;
0:030&amp;gt; !objsize 000001d3fa581518 
sizeof(000001d3fa581518) = 1487587080 (0x58aac708) bytes (System.Collections.Generic.List`1[[DataMipCRM.Common.GroupConditionCustomerIDCacheModel, DataMipCRM.Common]])
0:030&amp;gt; !do 000001d3fa581518
Name:        System.Collections.Generic.List`1[[DataMipCRM.Common.GroupConditionCustomerIDCacheModel, DataMipCRM.Common]]
MethodTable: 00007ffdab9557d0
EEClass:     00007ffe08eb22a0
Size:        40(0x28) bytes
File:        C:\Windows\Microsoft.Net\assembly\GAC_64\mscorlib\v4.0_4.0.0.0__b77a5c561934e089\mscorlib.dll
Fields:
              MT    Field   Offset                 Type VT     Attr            Value Name
00007ffe09478740  4001871        8     System.__Canon[]  0 instance 000001d3fa5b9bf8 _items
00007ffe094e9288  4001872       18         System.Int32  1 instance             1520 _size
00007ffe094e9288  4001873       1c         System.Int32  1 instance             1520 _version
00007ffe094e6f28  4001874       10        System.Object  0 instance 0000000000000000 _syncRoot
00007ffe09478740  4001875        8     System.__Canon[]  0   static  &amp;lt;no information&amp;gt;


&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;可以看出list占用 &lt;code&gt;1487587080/1024/1024=1.4G&lt;/code&gt;，尼玛这么大，吓人哈，从&lt;code&gt;_size&lt;/code&gt;看也就1520个，说明重点都在 &lt;code&gt;_items&lt;/code&gt; 数组里啦，接下里用 &lt;code&gt;da&lt;/code&gt; 把第一个item拿出来解剖下。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-C#&quot;&gt;
0:030&amp;gt; !da -length 1 -details 000001d3fa5b9bf8
Name:        DataMipCRM.Common.GroupConditionCustomerIDCacheModel[]
MethodTable: 00007ffdab955e10
EEClass:     00007ffe08eaaa00
Size:        16408(0x4018) bytes
Array:       Rank 1, Number of elements 2048, Type CLASS
Element Methodtable: 00007ffdab955740
[0] 000001d3fa581540
    Name:        DataMipCRM.Common.GroupConditionCustomerIDCacheModel
    MethodTable: 00007ffdab955740
    EEClass:     00007ffdab94b9e8
    Size:        64(0x40) bytes
    File:        D:\LuneceService\DataMipCRM.Common.dll
    Fields:
                      MT    Field   Offset                 Type VT     Attr            Value Name
        00007ffdaac69258  4000589       28     ...oDB.Bson.ObjectId      1     instance     000001d3fa581568     &amp;lt;_id&amp;gt;k__BackingField
        00007ffe094e9288  400058a       20             System.Int32      1     instance                 1901     &amp;lt;ShopId&amp;gt;k__BackingField
        00007ffe094e6948  400058b        8            System.String      0     instance     000001d3f7154070     &amp;lt;GroupConditionHasCode&amp;gt;k__BackingField
        00007ffe094e6948  400058c       10            System.String      0     instance     000001cca7b46ac0     &amp;lt;unit&amp;gt;k__BackingField
        00007ffe094f1cb0  400058d       18     ...lections.BitArray      0     instance     000001d3fa581580     &amp;lt;customeridArray&amp;gt;k__BackingField

&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;从最后一行的Type列可以看到有一个 &lt;code&gt;BitArray&lt;/code&gt; 类，还是一样，先量个尺寸再打出来。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-C#&quot;&gt;
0:030&amp;gt; !objsize 000001d3fa581580     
sizeof(000001d3fa581580) = 956008 (0xe9668) bytes (System.Collections.BitArray)
0:030&amp;gt; !do 000001d3fa581580     
Name:        System.Collections.BitArray
MethodTable: 00007ffe094f1cb0
EEClass:     00007ffe08ead968
Size:        40(0x28) bytes
File:        C:\Windows\Microsoft.Net\assembly\GAC_64\mscorlib\v4.0_4.0.0.0__b77a5c561934e089\mscorlib.dll
Fields:
              MT    Field   Offset                 Type VT     Attr            Value Name
00007ffe094e9220  40017e2        8       System.Int32[]  0 instance 000001d5320c6d18 m_array
00007ffe094e9288  40017e3       18         System.Int32  1 instance          7647524 m_length
00007ffe094e9288  40017e4       1c         System.Int32  1 instance                2 _version
00007ffe094e6f28  40017e5       10        System.Object  0 instance 0000000000000000 _syncRoot

&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;从output中看，这个bitarray占用 &lt;code&gt;956008/1024/1024 = 0.91M&lt;/code&gt;，真tmd的大，看bit位有 &lt;code&gt;764w&lt;/code&gt; 个，说明有一个CustomerID=7647524-1放在这里面，问题基本上就算找到了，现在终于知道内存为什么这么大，算一下就出来了。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/214741/202005/214741-20200522075313780-45571140.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;h2 id=&quot;四：总结&quot;&gt;四：总结&lt;/h2&gt;
&lt;p&gt;最后去问了下搬砖的为什么这么写，是因为给客户展示的一张报表，为了加速。。。将每一个点上的人群保存起来放在BitArray上然后进入Monogdb缓存，这样客户后续选择某一个点进行 下钻 操作的话，可以直接从mongodb中将BitArray的人群复原出来，免去程序重复计算之苦，因为每个点的人群具有排他性，落在每个点上的人可能只有几十，几百，几千，而偏偏这家客户有800w之多，自然这个CustomerID就特别大了，更不巧的就用了bitArray存少量的大数字，这些赶在一起之后，就是一个典型的滥用bitarray，您说的？&lt;/p&gt;
&lt;hr/&gt;&lt;h3 id=&quot;如您有更多问题与我互动，扫描下方进来吧&quot;&gt;如您有更多问题与我互动，扫描下方进来吧~&lt;/h3&gt;
&lt;hr/&gt;&lt;p&gt;&lt;img src=&quot;https://images.cnblogs.com/cnblogs_com/huangxincheng/345039/o_200414062434170x170.jpg&quot; alt=&quot;&quot;/&gt;&lt;img src=&quot;https://images.cnblogs.com/cnblogs_com/huangxincheng/345039/o_200414065053baijiahao.jpg&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
</description>
<pubDate>Thu, 21 May 2020 23:53:00 +0000</pubDate>
<dc:creator>一线码农</dc:creator>
<og:description>一：背景 1. 讲故事 前天写了一篇大内存排查在园子里挺火，这是做自媒体最开心的事拉，干脆再来一篇满足大家胃口，上个月我写了一篇博客提到过使用 对原来的 进行高强度压缩，将原来的List内存压缩了将近</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/huangxincheng/p/12934975.html</dc:identifier>
</item>
<item>
<title>用了这么多年的 Java 泛型，你对它到底有多了解？ - 楼下小黑哥</title>
<link>http://www.cnblogs.com/goodAndyxublog/p/12934938.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/goodAndyxublog/p/12934938.html</guid>
<description>&lt;blockquote readability=&quot;5.9039301310044&quot;&gt;
&lt;p&gt;本篇文章 idea 来自&lt;a href=&quot;https://www.cnblogs.com/huangxincheng/p/12764925.html&quot;&gt;用了这么多年的泛型，你对它到底有多了解？&lt;/a&gt;,恰好当时看了「深入 Java 虚拟机的第三版」了解泛型的一些历史，感觉挺有意思的，就写了写 Java 版的泛型。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;作为一个 Java 程序员，日常编程早就离不开泛型。泛型自从 JDK1.5 引进之后，真的非常提高生产力。一个简单的泛型 &lt;strong&gt;T&lt;/strong&gt;，寥寥几行代码， 就可以让我们在使用过程中动态替换成任何想要的类型，再也不用实现繁琐的类型转换方法。&lt;/p&gt;
&lt;p&gt;虽然我们每天都在用，但是还有很多同学可能并不了解其中的实现原理。今天这篇我们从以下几点聊聊 Java 泛型：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;Java 泛型实现方式&lt;/li&gt;
&lt;li&gt;类型擦除带来的缺陷&lt;/li&gt;
&lt;li&gt;Java 泛型发展史&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/1419561/202005/1419561-20200522071801220-685847296.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;blockquote readability=&quot;3.3870967741935&quot;&gt;
&lt;p&gt;点赞再看，养成习惯，微信搜索『程序通事』。&lt;br/&gt;&lt;a href=&quot;https://sourl.cn/WhjNLb&quot;&gt;点击查看更多相关文章&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;java-泛型实现方式&quot;&gt;Java 泛型实现方式&lt;/h2&gt;
&lt;p&gt;Java 采用&lt;strong&gt;类型擦除（Type erasure generics）&lt;/strong&gt;的方式实现泛型。用大白话讲就是这个泛型只存在源码中，编译器将源码编译成字节码之时，就会把泛型『&lt;strong&gt;擦除&lt;/strong&gt;』，所以字节码中并不存在泛型。&lt;/p&gt;
&lt;p&gt;对于下面这段代码，编译之后，我们使用 &lt;code&gt;javap -s class&lt;/code&gt; 查看字节码。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/1419561/202005/1419561-20200522071801441-336325336.jpg&quot; alt=&quot;方法源码&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/1419561/202005/1419561-20200522071801646-1183272088.jpg&quot; alt=&quot;字节码&quot;/&gt;&lt;/p&gt;
&lt;p&gt;观察&lt;code&gt;setParam&lt;/code&gt; 部分的字节码，从 &lt;code&gt;descriptor&lt;/code&gt; 可以看到，泛型 &lt;strong&gt;T&lt;/strong&gt; 已被擦除，最终替换成了 &lt;code&gt;Object&lt;/code&gt;。&lt;/p&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;ps:并不是每一个泛型参数被擦除类型后都会变成 Object 类，如果泛型类型为 T extends String 这种方式，最终泛型擦除之后将会变成 String。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;同理&lt;code&gt;getParam&lt;/code&gt; 方法，泛型返回值也被替换成了 &lt;code&gt;Object&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;为了保证 &lt;code&gt;String param = genericType.getParam();&lt;/code&gt; 代码的正确性，编译器还得在这里插入类型转换。&lt;/p&gt;
&lt;p&gt;除此之外，编译器还会对泛型安全性防御，如果我们往 &lt;code&gt;ArrayList&amp;lt;String&amp;gt;&lt;/code&gt; 添加 &lt;code&gt;Integer&lt;/code&gt;,程序编译期间就会报错。&lt;/p&gt;
&lt;p&gt;最终类型擦除后的代码等同与如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/1419561/202005/1419561-20200522071801872-436022436.jpg&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;h2 id=&quot;类型擦除带来的缺陷&quot;&gt;类型擦除带来的缺陷&lt;/h2&gt;
&lt;p&gt;作为对比，我们再来简单聊下 &lt;strong&gt;C#&lt;/strong&gt; 泛型的实现方式。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;C#&lt;/strong&gt;泛型实现方式为「&lt;strong&gt;具现化式泛型（Reifiable generics）&lt;/strong&gt;」，不熟悉的 &lt;strong&gt;C#&lt;/strong&gt;小伙伴可以不用纠结&lt;strong&gt;具现化&lt;/strong&gt;技术概念，我也不了解这些特性--！&lt;/p&gt;
&lt;p&gt;简单点来讲，&lt;strong&gt;C#&lt;/strong&gt;实现的泛型，无论是在程序源码，还是在编译之后的，甚至是运行期间都是切实存在的。&lt;/p&gt;
&lt;p&gt;相对比与 &lt;strong&gt;C#&lt;/strong&gt; 泛型，Java 泛型看起来就像是个「&lt;strong&gt;伪&lt;/strong&gt;」泛型。Java 泛型只存在程序源码中，编译之后就被擦除，这种缺陷相应的会带来一些问题。&lt;/p&gt;
&lt;h3 id=&quot;不支持基本数据类型&quot;&gt;不支持基本数据类型&lt;/h3&gt;
&lt;p&gt;泛型参数被擦除之后，强制变成了 &lt;code&gt;Object&lt;/code&gt; 类型。这么做对于引用类型来说没有什么问题，毕竟 &lt;code&gt;Object&lt;/code&gt; 是所有类型的父类型。但是对于 &lt;code&gt;int/long&lt;/code&gt; 等八个基本数据类型说，这就难办了。因为 Java 没办法做到&lt;code&gt;int/long&lt;/code&gt; 与 &lt;code&gt;Object&lt;/code&gt; 的强制转换。&lt;/p&gt;
&lt;p&gt;如果要实现这种转换，需要进行一系列改造，改动难度还不小。所以当时 Java 给出一个简单粗暴的解决方案：既然没办法做到转换，那就索性不支持原始类型泛型了。&lt;/p&gt;
&lt;p&gt;如果需要使用，那就规定使用相关包装类的泛型，比如 &lt;code&gt;ArrayList&amp;lt;Integer&amp;gt;&lt;/code&gt;。另外为了开发人员方便，顺便增加了原生数据类型的&lt;strong&gt;自动拆箱/装箱&lt;/strong&gt;的特性。&lt;/p&gt;
&lt;p&gt;正是这种「偷懒」的做法，导致现在我们没办法使用原始类型泛型，又要忍受包装类装箱/拆箱带来的开销，从而又带来运行效率的问题。&lt;/p&gt;
&lt;h3 id=&quot;运行效率&quot;&gt;运行效率&lt;/h3&gt;
&lt;p&gt;上面字节码例子我们已经看到，泛型擦除之后类型将会变成 &lt;code&gt;Object&lt;/code&gt;。当泛型出现在方法输入位置的时候，由于 Java 是可以向上转型的，这里并不需要强制类型转换，所以没有什么问题。&lt;/p&gt;
&lt;p&gt;但是当泛型参数出现在方法的输出位置（返回值）的时候，调用该方法的地方就需要进行向下转换，将 &lt;code&gt;Object&lt;/code&gt; 强制转换成所需类型,所以编译器会插入一句 &lt;code&gt;checkcast&lt;/code&gt; 字节码。&lt;/p&gt;
&lt;p&gt;除了这个，上面我们还说到原始基本数据类型，编译器还需帮助我们进行装箱/拆箱。&lt;/p&gt;
&lt;p&gt;所以对于下面这段代码来说：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;List&amp;lt;Integer&amp;gt; list = new ArrayList&amp;lt;Integer&amp;gt;();
list.add(66); // 1
int num = list.get(0); // 2
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;对于①处，编译器要做就是增加基本类型的装箱即可。但是对于第二步来说，编译器首先需要将 &lt;code&gt;Object&lt;/code&gt; 强制转换成 &lt;code&gt;Integer&lt;/code&gt;，接着编译器还需要进行拆箱。&lt;/p&gt;
&lt;p&gt;类型擦除之后，上面代码等同于：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;List list = new ArrayList();
list.add(Integer.valueOf(66));
int num = ((Integer) list.get(0)).intValue();
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;如果上面泛型代码在 C# 实现，就不会有这么多额外步骤。所以 Java 这种类型擦除式泛型实现方式无论使用效果与运行效率，还是全面落后于 C# 的具现化式泛型。&lt;/p&gt;
&lt;h3 id=&quot;运行期间无法获取泛型实际类型&quot;&gt;运行期间无法获取泛型实际类型&lt;/h3&gt;
&lt;p&gt;由于编译之后，泛型就被擦除，所以在代码运行期间，Java 虚拟机无法获取泛型的实际类型。&lt;/p&gt;
&lt;p&gt;下面这段代码，从源码上两个 List 看起来是不同类型的集合，但是经过泛型擦除之后，集合都变为 &lt;code&gt;ArrayList&lt;/code&gt;。所以 &lt;code&gt;if&lt;/code&gt;语句中代码将会被执行。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;ArrayList&amp;lt;Integer&amp;gt; li = new ArrayList&amp;lt;Integer&amp;gt;();
ArrayList&amp;lt;Float&amp;gt; lf = new ArrayList&amp;lt;Float&amp;gt;();
if (li.getClass() == lf.getClass()) { // 泛型擦除，两个 List 类型是一样的
    System.out.println(&quot;6666&quot;);
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;这样代码看起来就有点反直觉，这对新手来说不是很友好。&lt;/p&gt;
&lt;p&gt;另外还会给我们在实际使用中带来一些限制，比如说我们没办法直接实现以下代码：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/1419561/202005/1419561-20200522071802013-650189725.jpg&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;最后再举个例子，比如说我们需要实现一个泛型 &lt;code&gt;List&lt;/code&gt; 转换成数组的方法，我们就没办法直接从 List 去获取泛型实际类型，所以我们不得不额外再传入一个 Class 类型，指定数组的类型：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;public static &amp;lt;E&amp;gt; E[] convert(List&amp;lt;E&amp;gt; list, Class&amp;lt;E&amp;gt; componentType) {
    E[] array = (E[]) Array.newInstance(componentType, list.size());
    ....
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;从上面的例子我们可以看到，Java 采用类型擦除式实现泛型，缺陷很多。那为什么 Java 不采用 C# 的那种泛型实现方式？或者说采用一种更好实现方式？&lt;/p&gt;
&lt;p&gt;这个问题等我们了解 Java 泛型机制的历史，以及当时 Java 语言的现状，我们才能切身体会到当时 Java 采用这种泛型实现方式的原因。&lt;/p&gt;
&lt;h2 id=&quot;java-泛型历史背景&quot;&gt;Java 泛型历史背景&lt;/h2&gt;
&lt;p&gt;Java 泛型最早是在 JDK5 的时候才被引入，但是泛型思想最早来自来自 C++ 模板（template）。1996 年 Martin Odersky（Scala 语言缔造者） 在刚发布的 Java 的基础上扩展了泛型、函数式编程等功能，形成一门新的语言-「&lt;strong&gt;Pizza&lt;/strong&gt;」。&lt;/p&gt;
&lt;p&gt;后来，Java 核心开发团队对 &lt;strong&gt;Pizza&lt;/strong&gt; 的泛型设计深感兴趣，与 Martin 合作，一起合作开发的一个新的项目「&lt;strong&gt;Generic Java&lt;/strong&gt;」。这个项目的目的是为了给 Java 增加泛型支持，但是不引入函数式编程等功能。最终成功在 Java5 中正式引入泛型支持。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/1419561/202005/1419561-20200522071802173-1703805257.jpg&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;泛型移植过程，一开始并不是朝着类型擦除的方向前进，事实 &lt;strong&gt;Pizza&lt;/strong&gt; 中泛型更加类似于 &lt;strong&gt;C#&lt;/strong&gt; 中的泛型。&lt;/p&gt;
&lt;p&gt;但是由于 Java 自身特性，自带严格的约束，让 Martin 在&lt;strong&gt;Generic Java&lt;/strong&gt; 开发过程中，不得不放弃了 Pizza 中泛型设计。&lt;/p&gt;
&lt;p&gt;这个特性就是，Java 需要做到&lt;strong&gt;严格的向后兼容性&lt;/strong&gt;。也就是说一个在 JDK1.2 编译出来 Class 文件，不仅能在 JDK 1.2 能正常运行，还得必须保证在后续 JDK，比如 JDK12 中也能保证正常的运行。&lt;/p&gt;
&lt;p&gt;这种特性是明确写入 Java 语言规范的，这是一个对 Java 使用者的一个严肃承诺。&lt;/p&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;这里强调一下，这里的向后兼容性指的是二进制兼容性，并不是源码兼容性。也不保证高版本的 Class 文件能够运行在低版本的 JDK 上。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;现在困难点在于，Java 1.4.2 之前都没有支持泛型，而 Java5 之后突然要支持泛型，还要让 JDK1.4 之前编译的程序能在新版本中正常运行，这就意味着以前没有的限制，就不能突然增加。&lt;/p&gt;
&lt;p&gt;举个例子：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;ArrayList arrayList=new ArrayList();
arrayList.add(&quot;6666&quot;);
arrayList.add(Integer.valueOf(666));
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;没有泛型之前， List 集合是可以存储不同类型的数据，那么引入泛型之后，这段代码必须的能正确运行。&lt;/p&gt;
&lt;p&gt;为了保证这些旧的 Clas 文件能在 Java5 之后正常运行，设计者基本有两条路：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;需要泛型化的容器（主要是容器类型），以前有的保持不变，平行增加一套新的泛型化的版本。&lt;/li&gt;
&lt;li&gt;直接把已有的类型原地泛型化，不增加任何新的已有类型的泛型版本。&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;如果 Java 采用第一条路实现方式，那么现在我们可能就会有两套集合类型。以 &lt;code&gt;ArrayList&lt;/code&gt; 为例,一套为普通的 &lt;code&gt;java.util.ArrayList&lt;/code&gt;，一套可能为 &lt;code&gt;java.util.generic.ArrayList&amp;lt;T&amp;gt;&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;采用这种方案之后，如果开发中需要使用泛型特性，那么直接使用新的类型。另外旧的代码不改动，也可以直接运行在新版本 JDK 中。&lt;/p&gt;
&lt;p&gt;这套方案看起来没什么问题，实际上C# 就是采用这套方案。但是为什么 Java 却没有使用这套方案那?&lt;/p&gt;
&lt;p&gt;这是因为当时 C# 才发布两年，历史代码并不多，如果旧代码需要使用泛型特性，改造起来也很快。但是 Java 不一样，当时 Java 已经发布十年了，已经有很多程序已经运行部署在生产环境，可以想象历史代码非常多。&lt;/p&gt;
&lt;p&gt;如果这些应用在新版本 Java 需要使用泛型，那就需要做大量源码改动，可以想象这个开发工作量。&lt;/p&gt;
&lt;p&gt;另外 Java 5 之前，其实我们就已经有了两套集合容器，一套为 &lt;code&gt;Vector/Hashtable&lt;/code&gt; 等容器，一套为 &lt;code&gt;ArrayList/ HashMap&lt;/code&gt;。这两套容器的存在，其实已经引来一些不便，对于新接触的 Java 的开发人员来说，还得学习这两者的区别。&lt;/p&gt;
&lt;p&gt;如果此时为了泛型再引入新类型，那么就会有四套容器同时并存。想想这个画面，一个新接触开发人员，面对四套容器，完全不知道如何下手选择。如何 Java 真的这么实现了，想必会有更多人吐槽 Java。&lt;/p&gt;
&lt;p&gt;所以 Java 选择第二条路，采用类型擦除，只需要改动 Javac 编译器，不需要改动字节码，不需要改动虚拟机，也保证了之前历史没有泛型的代码还可以在新的 JDK 中运行。&lt;/p&gt;
&lt;p&gt;但是第二条路，并不代表一定需要使用类型擦除实现，如果有足够时间好好设计，也许会有更好的方案。&lt;/p&gt;
&lt;p&gt;当年留下的技术债，现在只能靠 &lt;strong&gt;Valhalla&lt;/strong&gt; 项目来还了。这个项目从2014 年开始立项，原本计划在 JDK10 中解决现有语言的各种缺陷。但是结果我们也知道了，现在都 JDK14 了，还只是完成少部分木目标，并没有解决核心目标，可见这个改动的难度啊。&lt;/p&gt;
&lt;h2 id=&quot;总结&quot;&gt;总结&lt;/h2&gt;
&lt;p&gt;本文我们先从 Java 泛型底层实现方式开始聊起，接着举了几个例子，让大家了解现在泛型实现方式存在一些缺陷。&lt;/p&gt;
&lt;p&gt;然后我们带入 Java 泛型历史背景，站在 Java 核心开发者的角度，才能了解 Java 泛型这么现实无奈原因。&lt;/p&gt;
&lt;p&gt;最后作为 Java 开发者，让我们对于现在 Java 一些不足，少些抱怨，多一些理解吧。相信之后 Java 核心开发人员肯定会解决泛型现有的缺陷，让我们拭目以待。&lt;/p&gt;
&lt;h2 id=&quot;帮助资料&quot;&gt;帮助资料&lt;/h2&gt;
&lt;ol&gt;&lt;li&gt;&lt;a href=&quot;https://www.zhihu.com/question/38940308&quot;&gt;https://www.zhihu.com/question/38940308&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://www.zhihu.com/question/28665443&quot;&gt;https://www.zhihu.com/question/28665443&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://hllvm-group.iteye.com/group/topic/25910&quot;&gt;https://hllvm-group.iteye.com/group/topic/25910&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://blog.zhaojie.me/2010/05/why-java-sucks-and-csharp-rocks-4-generics.html&quot;&gt;http://blog.zhaojie.me/2010/05/why-java-sucks-and-csharp-rocks-4-generics.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://blog.zhaojie.me/2010/04/why-java-sucks-and-csharp-rocks-2-primitive-types-and-object-orientation.html&quot;&gt;http://blog.zhaojie.me/2010/04/why-java-sucks-and-csharp-rocks-2-primitive-types-and-object-orientation.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Generics_in_Java&quot;&gt;https://en.wikipedia.org/wiki/Generics_in_Java&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://www.zhihu.com/question/34621277/answer/59440954&quot;&gt;https://www.zhihu.com/question/34621277/answer/59440954&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://www.artima.com/scalazine/articles/origins_of_scala.html&quot;&gt;https://www.artima.com/scalazine/articles/origins_of_scala.html&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;h2 id=&quot;最后（求关注，求点赞，求转发）&quot;&gt;最后（求关注，求点赞，求转发）&lt;/h2&gt;
&lt;p&gt;本文是在看了『深入 Java虚拟机（第三版）』之后，知道 Java 泛型这些故事，才有本篇文章。&lt;/p&gt;
&lt;p&gt;首先感谢一下机械工业出版社的小哥哥的赠书。&lt;/p&gt;
&lt;p&gt;刚开始知道『深入 Java虚拟机（第三版）』发布的时候，本来以为只是对第二版稍微补充而已。等收到这本书的时候，才发现自己错了。两本书放在一起，完全就不是一个量级的。&lt;/p&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;ps:盗取一张 Why 神的图&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/1419561/202005/1419561-20200522071802463-1715665335.jpg&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;第三本在第二版的基础增加大量补充，也解决了第二版留下一些没解释的问题。所以没买的同学，推荐直接购买第三版。&lt;/p&gt;
&lt;p&gt;两个版本的具体区别，大家可以看下 Why 神的的文章，这篇文章还被本书的作者打赏过哦。&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s/rYVDgttWw9WQA1IF3KJjUQ&quot;&gt;深入 Java虚拟机两版比较&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;我是楼下小黑哥，一个还未秃的程序猿，我们下周三见~&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/1419561/202005/1419561-20200522071802698-675131007.jpg&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;blockquote readability=&quot;5.5384615384615&quot;&gt;
&lt;p&gt;欢迎关注我的公众号：程序通事，获得日常干货推送。如果您对我的专题内容感兴趣，也可以关注我的博客：&lt;a href=&quot;https://studyidea.cn&quot;&gt;studyidea.cn&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
</description>
<pubDate>Thu, 21 May 2020 23:18:00 +0000</pubDate>
<dc:creator>楼下小黑哥</dc:creator>
<og:description>本篇文章 idea 来自 &amp;quot;用了这么多年的泛型，你对它到底有多了解？&amp;quot; ,恰好当时看了「深入 Java 虚拟机的第三版」了解泛型的一些历史，感觉挺有意思的，就写了写 Java 版的</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/goodAndyxublog/p/12934938.html</dc:identifier>
</item>
<item>
<title>Redis学习笔记（十三） 复制（下） - 温暖如太阳</title>
<link>http://www.cnblogs.com/xtt321/p/12934441.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/xtt321/p/12934441.html</guid>
<description>&lt;p&gt;上一篇写了Redis复制功能的简单应用，下面我们看下Redis复制功能的实现过程。下面基本上是理论部分，枯燥乏味，但希望大家能看看，毕竟知识不都是感兴趣的.&lt;br/&gt;&lt;strong&gt;耐得住寂寞,经得起诱惑,方能守得住繁华 ~.~&lt;/strong&gt;&lt;br/&gt;&lt;strong&gt;旧版复制功能的实现&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Redis的复制功能分为同步和命令传播两个操作：&lt;/p&gt;
&lt;p&gt;1、同步操作用于将从服务器的数据库状态更新至主服务器当前所处的数据库状态。&lt;/p&gt;
&lt;p&gt;2、命令传播操作则用于在主服务器 的数据库状态被修改，导致从服务器的数据库状态出现不一致时，让主服务器的数据库重新回到一致状态。&lt;/p&gt;
&lt;p&gt;从服务器对主服务器的同步操作需要通过向主服务发送sync命令来完成，以下是sync命令的执行步骤：&lt;/p&gt;
&lt;p&gt;（1）从服务器向主服务器发送SYNC命令&lt;/p&gt;
&lt;p&gt;（2）收到SYNC命令的主服务器执行BGSAVE命令，在后台生成一个RDB文件，并使用一个缓冲区记录现在开始执行的所有写命令。&lt;/p&gt;
&lt;p&gt;（3）当主服务器的BGSAVE命令执行完毕时，主服务器会BGSAVE命令生成的RDB文件发送给从服务器，从服务器接收并载入这个RDB文件，将自己的数据库状态更新至主服务器执行BGSAVE命令时的数据库状态。&lt;/p&gt;
&lt;p&gt;（4）主服务器将记录在缓冲区的所有写命令发送给从服务器，从服务器执行这些写命令，将自己的数据库状态更新至主服务器数据库当前所处的状态。&lt;/p&gt;
&lt;p&gt;命令传播：当主服务器执行客户端写命令时，主服务器的数据库就有可能被修改，并导致主从不一致。此时主服务器会将自己执行的写命令发送给从服务器执行，当从服务器执行了相同的写命令后，主从服务器再次回到一致状态。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;缺陷&lt;/strong&gt;：&lt;/p&gt;
&lt;p&gt;1、初始复制从服务器从来没有复制过任何主服务器或者从服务器当前要复制的主服务器和上次复制的主服务器不同。&lt;/p&gt;
&lt;p&gt;2、断线后重复制：处于命令传播阶段的主从服务器因为网络原因而中断了复制，但从服务器通过自动连接从新连上主服务器，并继续复制。&lt;/p&gt;
&lt;p&gt;&lt;br/&gt;&lt;strong&gt;新版复制功能的实现（PSYNC代替SYNC）&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;PSYNC命令具有完整重同步和部分重同步两种模式：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;（1）完整重同步用于处理初次复制功能，与SYNC功能基本一致；&lt;/p&gt;
&lt;p&gt;（2）部分重同步用于处理断线后重复值的情况，解决旧版效率低的问题。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;部分重同步的实现：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;（1）主服务器与从服务器都会维护一个复制偏移量&lt;/p&gt;
&lt;p&gt;（2）复制积压缓冲区是由主服务器维护的一个固定长度先进先出的队列默认（1MB），发生断线从连时，但从服务器重连上主服务器，从服务器会通过PSYNC命令将自己的复制偏移量offset发送给主服务器，主服务器根据这个复制偏移量来决定对从服务器执行何种同步操作：如果offset偏移量之后的数据仍然存在于复制积压缓冲区里面，那么主服务器将对从服务器执行部分重同步,反之，执行完整重同步操作。除了复制偏移量和复制积压缓冲之外，实现部分重同步还需要用到服务器运行ID：每个Redis服务器都有自己启动时生成的由40个随机16进制字符组成的运行ID。当服务器对主服务器进行初次复制时，主服务器会将自己的运行ID传送给从服务器，而从服务器则会将这个运行ID保存起来。当服务器断线重连时，从服务器向主服务器发送保存的运行ID，如果ID一样，则主服务器尝试部分重同步操作，如果不同，则执行完整重同步操作。&lt;/p&gt;
&lt;p&gt;&lt;em id=&quot;__mceDel&quot;&gt;&lt;strong&gt;PSYNC命令的实现&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em id=&quot;__mceDel&quot;&gt;PSYNC命令的实现方法有两种：&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em id=&quot;__mceDel&quot;&gt;（&lt;/em&gt;1）如果从服务器以前没有复制过任何主服务器，或者之前执行过SLAVEOF no one命令，那么从服务器在开始新的复制时将向主服务器发送PSYNC? -1 命令，主动请求进行完整重同步。&lt;/p&gt;
&lt;p&gt;（2）如果之前复制过某个主服务器，那么从服务在开始一次新的复制时向主服务器发送PSYNC &amp;lt;runid&amp;gt; &amp;lt;offset&amp;gt;。由主服务器来判断该用那种方式同步。&lt;/p&gt;
&lt;p&gt;（3）如果主服务器返回+FULLRESYNC回复，则表示主服务器将与从服务器执行完整重同步。&lt;/p&gt;
&lt;p&gt;（4）如果主服务器返回+CONTINUE回复，则表示部分重同步，从服务器只需等待接收数据即可。&lt;/p&gt;
&lt;p&gt;（5）主服务器返回-ERR回复，则表示主服务器版本低于2.8不识别PSYNC命令从服务器将向主服务器发送SYNC命令完成同步操作。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;复制的实现&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;1、执行SLAVEOF ip port命令，此时从服务器首先将ip与端口保存到服务器状态的masterhost属性与masterport属性里面，并向客户端返回“OK”，表示命令已经被接收。&lt;/p&gt;
&lt;p&gt;2、建立套接字连接&lt;/p&gt;
&lt;p&gt;从服务器根据ip与端口创建连向主服务器的套接字，如果套接字连接到主服务器，那么从服务器将为这个套接字关联一个 专门用于处理复制工作的文件事件处理器，这个事件处理器负责执行后续复制工作。主服务器在接受从服务器的套接字连接后，将为该套接字创建相应的客户端状态，并将从服务器看作一个连接到主服务器的客户端对待，&lt;/p&gt;
&lt;p&gt;3、发送PING命令&lt;/p&gt;
&lt;p&gt;作用：&lt;/p&gt;
&lt;p&gt;（1）虽然与主服务器建立套接字连接，但双方并未使用该套接字进行任何通信，检查套接字读写是否正常。&lt;/p&gt;
&lt;p&gt;（2）检查主服务器是否能够正常处理命令请求。&lt;/p&gt;
&lt;p&gt;发送命令后可能遇到的三种情况：&lt;/p&gt;
&lt;p&gt;（1）超时，在规定的时间限制内从服务器未收到回复内容，此时从服务器断线重连。&lt;/p&gt;
&lt;p&gt;（2）如果主服务器向从服务器回复一个错误，表示主服务器暂时无法处理从服务器的命令请求，从服务器断线重连。&lt;/p&gt;
&lt;p&gt;（3）收到正常回复内容，则可以进行下一步操作。&lt;/p&gt;
&lt;p&gt;4、身份验证（如果从服务器设置了masterauth选项）&lt;/p&gt;
&lt;p&gt;从服务器向主服务器发送一条AUTH命令，此时从服务器可能遇到的情况有：&lt;/p&gt;
&lt;p&gt;（1）主服务器没有设置requirepass选项，并且从服务器没有设置master选项，那么从服务器将继续执行从服务发送的命令，复制操作继续。&lt;/p&gt;
&lt;p&gt;（2）如果从服务器通过AUTH命令发送的密码与主服务器requirepass设置的密码相同，那么主服务器将继续执行从服务器发送的命令，如果不同则主服务器返回一个invalid password错误。&lt;/p&gt;
&lt;p&gt;（3）如果主服务器设置了requirepass选项，但从服务器没有设置masterauth选项，那么主服务器将返回一个NOAUTH选项。另一方面如果主服务器没有设置requirepass选项，但服务器设置了masterauth选项，那么主服务器将返回一个no password is set 错误。&lt;/p&gt;
&lt;p&gt;5、发送端口信息，从服务器将执行REPLCONF listening-port port命令，向主服务器发送从服务器的监听端口号，主服务器将端口号保存在对应的客户端状态slave_listening_port属性中。&lt;/p&gt;
&lt;p&gt;6、同步&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/404258/202005/404258-20200521233802524-1405066771.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;7、命令传播&lt;/p&gt;
&lt;p&gt;主服务器将自己执行的写命令发送给从服务器，从服务器只要一直执行主服务器发来的命令即可。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;心跳检测&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;在命令传播阶段，从服务器默认以每秒一次的频率向主服务器发送命令：&lt;/p&gt;
&lt;p&gt;REPLCONF ACK &amp;lt;replication_offset&amp;gt;&lt;/p&gt;
&lt;p&gt;作用：检测主服务器的网络连接状态；辅助实现min-slaves选项；检测命令丢失。&lt;/p&gt;
&lt;p&gt;Redis的min-slaves-to-write和min-slaves-max-lag两个选项防止主服务器在不安全的情况下执行写命令。&lt;/p&gt;
&lt;p&gt;当从服务器小于min-slaves-to-write或者min-slaves-to-write个数量的服务器延迟lag值都大于等于min-slaves-max-lag时，主服务器将拒绝执行写命令。&lt;/p&gt;
&lt;p&gt;如果因为网络故障，主服务器传播给从服务器的写命令半路丢失，那么当从服务器向主服务器发送REPLCONF ACK命令时，主服务器将发觉从服务器当前的复制偏移量少于自己的偏移量，主服务器就会根据从服务器提交的复制偏移量，在复制积压缓冲区里面找到从服务器缺少的数据，并将这些数据重新发送给从服务器。&lt;/p&gt;

&lt;hr/&gt;

&lt;p&gt;每天学一点，总会有收获。&lt;/p&gt;

&lt;p&gt;下一步我们看下Redis的Sentinel(哨兵)&lt;/p&gt;

&lt;p&gt;说明：尊重作者知识产权，文中内容参考《Redis设计与实现》，仅在此做学习与大家分享。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/404258/202005/404258-20200521233901856-252437475.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

</description>
<pubDate>Thu, 21 May 2020 22:37:00 +0000</pubDate>
<dc:creator>温暖如太阳</dc:creator>
<og:description>上一篇写了Redis复制功能的简单应用，下面我们看下Redis复制功能的实现过程。下面基本上是理论部分，枯燥乏味，但希望大家能看看，毕竟知识不都是感兴趣的.耐得住寂寞,经得起诱惑,方能守得住繁华 ~.</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/xtt321/p/12934441.html</dc:identifier>
</item>
<item>
<title>拥抱并行流，提高程序执行速度 - 后青春期的Keats</title>
<link>http://www.cnblogs.com/keatsCoder/p/12934394.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/keatsCoder/p/12934394.html</guid>
<description>&lt;h2 id=&quot;前言&quot;&gt;前言&lt;/h2&gt;
&lt;p&gt;在 Java7 之前，如果想要并行处理一个集合，我们需要以下几步 1. 手动分成几部分 2. 为每部分创建线程 3. 在适当的时候合并。并且还需要关注多个线程之间共享变量的修改问题。而 Java8 为我们提供了并行流，可以一键开启并行模式。是不是很酷呢？让我们来看看吧&lt;/p&gt;
&lt;p&gt;&lt;span&gt;声明：本文首发于博客园，作者：后青春期的Keats；地址：&lt;a href=&quot;https://www.cnblogs.com/keatsCoder/&quot;&gt;https://www.cnblogs.com/keatsCoder/&lt;/a&gt; 转载请注明，谢谢！&lt;/span&gt;&lt;/p&gt;
&lt;h2 id=&quot;并行流&quot;&gt;并行流&lt;/h2&gt;
&lt;h3 id=&quot;认识和开启并行流&quot;&gt;认识和开启并行流&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;什么是并行流：&lt;/strong&gt;并行流就是将一个流的内容分成多个数据块，并用不同的线程分别处理每个不同数据块的流。例如有这么一个需求：&lt;/p&gt;
&lt;p&gt;有一个 List 集合，而 list 中每个 apple 对象只有重量，我们也知道 apple 的单价是 5元/kg，现在需要计算出每个 apple 的单价，传统的方式是这样：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;List&amp;lt;Apple&amp;gt; appleList = new ArrayList&amp;lt;&amp;gt;(); // 假装数据是从库里查出来的

for (Apple apple : appleList) {
    apple.setPrice(5.0 * apple.getWeight() / 1000);
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;我们通过迭代器遍历 list 中的 apple 对象，完成了每个 apple 价格的计算。而这个算法的时间复杂度是 O(list.size()) 随着 list 大小的增加，耗时也会跟着线性增加。并行流&lt;/p&gt;
&lt;p&gt;可以大大缩短这个时间。并行流处理该集合的方法如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;appleList.parallelStream().forEach(apple -&amp;gt; apple.setPrice(5.0 * apple.getWeight() / 1000));
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;和普通流的区别是这里调用的 &lt;code&gt;parallelStream()&lt;/code&gt; 方法。当然也可以通过 stream.parallel() 将普通流转换成并行流。并行流也能通过 sequential() 方法转换为顺序流，但要注意：&lt;strong&gt;流的并行和顺序转换不会对流本身做任何实际的变化，仅仅是打了个标记而已。并且在一条流水线上对流进行多次并行 / 顺序的转换，生效的是最后一次的方法调用&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;并行流如此方便，它的线程从那里来呢？有多少个？怎么配置呢？&lt;/p&gt;
&lt;p&gt;并行流内部使用了默认的 ForkJoinPool 线程池。&lt;strong&gt;默认的线程数量就是处理器的核心数&lt;/strong&gt;，而配置系统核心属性： java.util.concurrent.ForkJoinPool.common.parallelism 可以改变线程池大小。不过该值是全局变量。改变他会影响所有并行流。目前还无法为每个流配置专属的线程数。一般来说采用处理器核心数是不错的选择&lt;/p&gt;
&lt;h3 id=&quot;测试并行流的性能&quot;&gt;测试并行流的性能&lt;/h3&gt;
&lt;p&gt;为了更容易的测试性能，我们在每次计算完苹果价格后，让线程睡 1s，表示在这期间执行了其他 IO 相关的操作，并输出程序执行耗时,顺序执行的耗时：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;public static void main(String[] args) throws InterruptedException {
    List&amp;lt;Apple&amp;gt; appleList = initAppleList();

    Date begin = new Date();
    for (Apple apple : appleList) {
        apple.setPrice(5.0 * apple.getWeight() / 1000);
        Thread.sleep(1000);
    }
    Date end = new Date();
    log.info(&quot;苹果数量：{}个, 耗时：{}s&quot;, appleList.size(), (end.getTime() - begin.getTime()) /1000);
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1654189/202005/1654189-20200521232706449-1060282129.jpg&quot; alt=&quot;Snipaste_2020-05-21_21-49-44&quot;/&gt;&lt;/p&gt;
&lt;p&gt;并行版本&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;List&amp;lt;Apple&amp;gt; appleList = initAppleList();

Date begin = new Date();
appleList.parallelStream().forEach(apple -&amp;gt;
                                   {
                                       apple.setPrice(5.0 * apple.getWeight() / 1000);
                                       try {
                                           Thread.sleep(1000);
                                       } catch (InterruptedException e) {
                                           e.printStackTrace();
                                       }
                                   }
                                  );
Date end = new Date();
log.info(&quot;苹果数量：{}个, 耗时：{}s&quot;, appleList.size(), (end.getTime() - begin.getTime()) /1000);
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;耗时情况&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1654189/202005/1654189-20200521232706020-1662215086.jpg&quot; alt=&quot;Snipaste_2020-05-21_22-16-08&quot;/&gt;&lt;/p&gt;
&lt;p&gt;跟我们的预测一致，我的电脑是 四核I5 处理器，开启并行后四个处理器每人执行一个线程，最后 1s 完成了任务！&lt;/p&gt;
&lt;h3 id=&quot;并行流可以随便用吗？&quot;&gt;并行流可以随便用吗？&lt;/h3&gt;
&lt;h4 id=&quot;可拆分性影响流的速度&quot;&gt;可拆分性影响流的速度&lt;/h4&gt;
&lt;p&gt;通过上面的测试，有的人会轻易得到一个结论：并行流很快，我们可以完全放弃 foreach/fori/iter 外部迭代，使用 Stream 提供的内部迭代来实现了。事实真的是这样吗？并行流真的如此完美吗？答案当然是否定的。大家可以复制下面的代码，在自己的电脑上测试。测试完后可以发现，并行流并不总是最快的处理方式。&lt;/p&gt;
&lt;ol readability=&quot;1.5&quot;&gt;&lt;li readability=&quot;1&quot;&gt;
&lt;p&gt;对于 iterate 方法来处理的前 n 个数字来说，不管并行与否，它总是慢于循环的，非并行版本可以理解为流化操作没有循环更偏向底层导致的慢。可并行版本是为什么慢呢？这里有两个需要注意的点：&lt;/p&gt;
&lt;ol readability=&quot;1.5&quot;&gt;&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;iterate 生成的是装箱的对象，必须拆箱成数字才能求和&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;4&quot;&gt;
&lt;p&gt;我们很难把 iterate 分成多个独立的块来并行执行&lt;/p&gt;
&lt;p&gt;这个问题很有意思，我们必须意识到某些流操作比其他操作更容易并行化。对于 iterate 来说，每次应用这个函数都要依赖于前一次应用的结果。因此在这种情况下，我们不仅不能有效的将流划分成小块处理。反而还因为并行化再次增加了开支。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;li readability=&quot;2&quot;&gt;
&lt;p&gt;而对于 LongStream.rangeClosed() 方法来说，就不存在 iterate 的第两个痛点了。它生成的是基本类型的值，不用拆装箱操作，另外它可以直接将要生成的数字 1 - n 拆分成 1 - n/4， 1n/4 - 2n/4， ... 3n/4 - n 这样四部分。因此并行状态下的 rangeClosed() 是快于 for 循环外部迭代的&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;package lambdasinaction.chap7;

import java.util.stream.*;

public class ParallelStreams {

    public static long iterativeSum(long n) {
        long result = 0;
        for (long i = 0; i &amp;lt;= n; i++) {
            result += i;
        }
        return result;
    }

    public static long sequentialSum(long n) {
        return Stream.iterate(1L, i -&amp;gt; i + 1).limit(n).reduce(Long::sum).get();
    }

    public static long parallelSum(long n) {
        return Stream.iterate(1L, i -&amp;gt; i + 1).limit(n).parallel().reduce(Long::sum).get();
    }

    public static long rangedSum(long n) {
        return LongStream.rangeClosed(1, n).reduce(Long::sum).getAsLong();
    }

    public static long parallelRangedSum(long n) {
        return LongStream.rangeClosed(1, n).parallel().reduce(Long::sum).getAsLong();
    }

}

&lt;/code&gt;
&lt;/pre&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;package lambdasinaction.chap7;

import java.util.concurrent.*;
import java.util.function.*;

public class ParallelStreamsHarness {

    public static final ForkJoinPool FORK_JOIN_POOL = new ForkJoinPool();

    public static void main(String[] args) {
        System.out.println(&quot;Iterative Sum done in: &quot; + measurePerf(ParallelStreams::iterativeSum, 10_000_000L) + &quot; msecs&quot;);
        System.out.println(&quot;Sequential Sum done in: &quot; + measurePerf(ParallelStreams::sequentialSum, 10_000_000L) + &quot; msecs&quot;);
        System.out.println(&quot;Parallel forkJoinSum done in: &quot; + measurePerf(ParallelStreams::parallelSum, 10_000_000L) + &quot; msecs&quot; );
        System.out.println(&quot;Range forkJoinSum done in: &quot; + measurePerf(ParallelStreams::rangedSum, 10_000_000L) + &quot; msecs&quot;);
        System.out.println(&quot;Parallel range forkJoinSum done in: &quot; + measurePerf(ParallelStreams::parallelRangedSum, 10_000_000L) + &quot; msecs&quot; );
    }

    public static &amp;lt;T, R&amp;gt; long measurePerf(Function&amp;lt;T, R&amp;gt; f, T input) {
        long fastest = Long.MAX_VALUE;
        for (int i = 0; i &amp;lt; 10; i++) {
            long start = System.nanoTime();
            R result = f.apply(input);
            long duration = (System.nanoTime() - start) / 1_000_000;
            System.out.println(&quot;Result: &quot; + result);
            if (duration &amp;lt; fastest) fastest = duration;
        }
        return fastest;
    }
}

&lt;/code&gt;
&lt;/pre&gt;
&lt;h4 id=&quot;共享变量修改的问题&quot;&gt;共享变量修改的问题&lt;/h4&gt;
&lt;p&gt;并行流虽然轻易的实现了多线程，但是仍未解决多线程中共享变量的修改问题。下面代码中存在共享变量 total，分别使用顺序流和并行流计算前n个自然数的和&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;public static long sideEffectSum(long n) {
    Accumulator accumulator = new Accumulator();
    LongStream.rangeClosed(1, n).forEach(accumulator::add);
    return accumulator.total;
}

public static long sideEffectParallelSum(long n) {
    Accumulator accumulator = new Accumulator();
    LongStream.rangeClosed(1, n).parallel().forEach(accumulator::add);
    return accumulator.total;
}

public static class Accumulator {
    private long total = 0;

    public void add(long value) {
        total += value;
    }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;顺序执行每次输出的结果都是：50000005000000，而并行执行的结果却五花八门了。这是因为每次访问 totle 都会存在数据竞争，关于数据竞争的原因，大家可以看看关于 volatile 的博客。因此当代码中存在修改共享变量的操作时，是不建议使用并行流的。&lt;/p&gt;
&lt;h4 id=&quot;并行流的使用注意&quot;&gt;并行流的使用注意&lt;/h4&gt;
&lt;p&gt;在并行流的使用上有下面几点需要注意：&lt;/p&gt;
&lt;ul readability=&quot;5&quot;&gt;&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;尽量使用 LongStream / IntStream / DoubleStream 等原始数据流代替 Stream 来处理数字，以避免频繁拆装箱带来的额外开销&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;6&quot;&gt;
&lt;p&gt;要考虑流的操作流水线的总计算成本，假设 N 是要操作的任务总数，Q 是每次操作的时间。N * Q 就是操作的总时间，Q 值越大就意味着使用并行流带来收益的可能性越大&lt;/p&gt;
&lt;p&gt;例如：前端传来几种类型的资源，需要存储到数据库。每种资源对应不同的表。我们可以视作类型数为 N，存储数据库的网络耗时 + 插入操作耗时为 Q。一般情况下网络耗时都是比较大的。因此该操作就比较适合并行处理。当然当类型数目大于核心数时，该操作的性能提升就会打一定的折扣了。更好的优化方法在日后的博客会为大家奉上&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;对于较少的数据量，不建议使用并行流&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;容易拆分成块的流数据，建议使用并行流&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;以下是一些常见的集合框架对应流的可拆分性能表&lt;/p&gt;
&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;源&lt;/th&gt;
&lt;th&gt;可拆分性&lt;/th&gt;
&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;ArrayList&lt;/td&gt;
&lt;td&gt;极佳&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;LinkedList&lt;/td&gt;
&lt;td&gt;差&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;IntStream.range&lt;/td&gt;
&lt;td&gt;极佳&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Stream.iterate&lt;/td&gt;
&lt;td&gt;差&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;HashSet&lt;/td&gt;
&lt;td&gt;好&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;TreeSet&lt;/td&gt;
&lt;td&gt;好&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;&lt;span&gt;码字不易，如果你觉得读完以后有收获，不妨点个推荐让更多的人看到吧！&lt;/span&gt;&lt;/p&gt;
</description>
<pubDate>Thu, 21 May 2020 15:28:00 +0000</pubDate>
<dc:creator>后青春期的Keats</dc:creator>
<og:description>前言 在 Java7 之前，如果想要并行处理一个集合，我们需要以下几步 1. 手动分成几部分 2. 为每部分创建线程 3. 在适当的时候合并。并且还需要关注多个线程之间共享变量的修改问题。而 Java</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/keatsCoder/p/12934394.html</dc:identifier>
</item>
<item>
<title>【K8S】基于Docker+K8S+GitLab/SVN+Jenkins+Harbor搭建持续集成交付环境（环境搭建篇） - 冰河团队</title>
<link>http://www.cnblogs.com/binghe001/p/12934192.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/binghe001/p/12934192.html</guid>
<description>&lt;h2 id=&quot;写在前面&quot;&gt;写在前面&lt;/h2&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;最近在 K8S 1.18.2 版本的集群上搭建DevOps环境，期间遇到了各种坑。目前，搭建环境的过程中出现的各种坑均已被填平，特此记录，并分享给大家！&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;服务器规划&quot;&gt;服务器规划&lt;/h2&gt;
&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;IP&lt;/th&gt;
&lt;th&gt;主机名&lt;/th&gt;
&lt;th&gt;节点&lt;/th&gt;
&lt;th&gt;操作系统&lt;/th&gt;
&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;192.168.175.101&lt;/td&gt;
&lt;td&gt;binghe101&lt;/td&gt;
&lt;td&gt;K8S Master&lt;/td&gt;
&lt;td&gt;CentOS 8.0.1905&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;192.168.175.102&lt;/td&gt;
&lt;td&gt;binghe102&lt;/td&gt;
&lt;td&gt;K8S Worker&lt;/td&gt;
&lt;td&gt;CentOS 8.0.1905&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;192.168.175.103&lt;/td&gt;
&lt;td&gt;binghe103&lt;/td&gt;
&lt;td&gt;K8S Worker&lt;/td&gt;
&lt;td&gt;CentOS 8.0.1905&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;h2 id=&quot;安装环境版本&quot;&gt;安装环境版本&lt;/h2&gt;
&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;软件名称&lt;/th&gt;
&lt;th&gt;软件版本&lt;/th&gt;
&lt;th&gt;说明&lt;/th&gt;
&lt;/tr&gt;&lt;/thead&gt;&lt;tbody readability=&quot;6.5&quot;&gt;&lt;tr&gt;&lt;td&gt;Docker&lt;/td&gt;
&lt;td&gt;19.03.8&lt;/td&gt;
&lt;td&gt;提供容器环境&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;docker-compose&lt;/td&gt;
&lt;td&gt;1.25.5&lt;/td&gt;
&lt;td&gt;定义和运行由多个容器组成的应用&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;5&quot;&gt;&lt;td&gt;K8S&lt;/td&gt;
&lt;td&gt;1.8.12&lt;/td&gt;
&lt;td&gt;是一个开源的，用于管理云平台中多个主机上的容器化的应用，Kubernetes的目标是让部署容器化的应用简单并且高效（powerful）,Kubernetes提供了应用部署，规划，更新，维护的一种机制。&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;GitLab&lt;/td&gt;
&lt;td&gt;12.1.6&lt;/td&gt;
&lt;td&gt;代码仓库（与SVN安装一个即可）&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Harbor&lt;/td&gt;
&lt;td&gt;1.10.2&lt;/td&gt;
&lt;td&gt;私有镜像仓库&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Jenkins&lt;/td&gt;
&lt;td&gt;2.89.3&lt;/td&gt;
&lt;td&gt;持续集成交付&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;SVN&lt;/td&gt;
&lt;td&gt;1.10.2&lt;/td&gt;
&lt;td&gt;代码仓库（与GitLab安装一个即可）&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;JDK&lt;/td&gt;
&lt;td&gt;1.8.0_202&lt;/td&gt;
&lt;td&gt;Java运行基础环境&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;maven&lt;/td&gt;
&lt;td&gt;3.6.3&lt;/td&gt;
&lt;td&gt;构建项目的基础插件&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;h2 id=&quot;服务器免密码登录&quot;&gt;服务器免密码登录&lt;/h2&gt;
&lt;p&gt;在各服务器执行如下命令。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;ssh-keygen -t rsa
cat ~/.ssh/id_rsa.pub &amp;gt;&amp;gt; ~/.ssh/authorized_keys 
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;将binghe102和binghe103服务器上的id_rsa.pub文件复制到binghe101服务器。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;[root@binghe102 ~]# scp .ssh/id_rsa.pub binghe101:/root/.ssh/102
[root@binghe103 ~]# scp .ssh/id_rsa.pub binghe101:/root/.ssh/103
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;在binghe101服务器上执行如下命令。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;cat ~/.ssh/102 &amp;gt;&amp;gt; ~/.ssh/authorized_keys
cat ~/.ssh/103 &amp;gt;&amp;gt; ~/.ssh/authorized_keys
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;然后将authorized_keys文件分别复制到binghe102、binghe103服务器。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;[root@binghe101 ~]# scp .ssh/authorized_keys binghe102:/root/.ssh/authorized_keys
[root@binghe101 ~]# scp .ssh/authorized_keys binghe103:/root/.ssh/authorized_keys
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;删除binghe101节点上~/.ssh下的102和103文件。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;rm ~/.ssh/102
rm ~/.ssh/103
&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;安装jdk&quot;&gt;安装JDK&lt;/h2&gt;
&lt;p&gt;需要在每台服务器上安装JDK环境。到Oracle官方下载JDK，我这里下的JDK版本为1.8.0_202，下载后解压并配置系统环境变量。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;tar -zxvf jdk1.8.0_212.tar.gz
mv jdk1.8.0_212 /usr/local
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;接下来，配置系统环境变量。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;vim /etc/profile
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;配置项内容如下所示。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;JAVA_HOME=/usr/local/jdk1.8.0_212
CLASS_PATH=.:$JAVA_HOME/lib
PATH=$JAVA_HOME/bin:$PATH
export JAVA_HOME CLASS_PATH PATH
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;接下来执行如下命令使系统环境变量生效。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;source /etc/profile
&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;安装maven&quot;&gt;安装Maven&lt;/h2&gt;
&lt;p&gt;到Apache官方下载Maven，我这里下载的Maven版本为3.6.3。下载后直接解压并配置系统环境变量。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;tar -zxvf apache-maven-3.6.3-bin.tar.gz
mv apache-maven-3.6.3-bin /usr/local
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;接下来，就是配置系统环境变量。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;vim /etc/profile
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;配置项内容如下所示。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;JAVA_HOME=/usr/local/jdk1.8.0_212
MAVEN_HOME=/usr/local/apache-maven-3.6.3-bin
CLASS_PATH=.:$JAVA_HOME/lib
PATH=$MAVEN_HOME/bin:$JAVA_HOME/bin:$PATH
export JAVA_HOME CLASS_PATH MAVEN_HOME PATH
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;接下来执行如下命令使系统环境变量生效。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;source /etc/profile
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;接下来，修改Maven的配置文件，如下所示。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-xml&quot;&gt;&amp;lt;localRepository&amp;gt;/home/repository&amp;lt;/localRepository&amp;gt;
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;将Maven下载的Jar包存储到/home/repository目录下。&lt;/p&gt;
&lt;h2 id=&quot;安装docker环境&quot;&gt;安装Docker环境&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;本文档基于Docker 19.03.8 版本搭建Docker环境。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;在所有服务器上创建install_docker.sh脚本，脚本内容如下所示。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;export REGISTRY_MIRROR=https://registry.cn-hangzhou.aliyuncs.com
dnf install yum*
yum install -y yum-utils device-mapper-persistent-data lvm2
yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo
dnf install https://mirrors.aliyun.com/docker-ce/linux/centos/7/x86_64/stable/Packages/containerd.io-1.2.13-3.1.el7.x86_64.rpm
yum install -y docker-ce-19.03.8 docker-ce-cli-19.03.8
systemctl enable docker.service
systemctl start docker.service
docker version
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;在每台服务器上为install_docker.sh脚本赋予可执行权限，并执行脚本即可。&lt;/p&gt;
&lt;h2 id=&quot;安装docker-compose&quot;&gt;安装docker-compose&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;注意：在每台服务器上安装docker-compose&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;1.下载docker-compose文件&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;curl -L https://github.com/docker/compose/releases/download/1.25.5/docker-compose-`uname -s`-`uname -m` -o /usr/local/bin/docker-compose 
&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;2为docker-compose文件赋予可执行权限&quot;&gt;2.为docker-compose文件赋予可执行权限&lt;/h3&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;chmod a+x /usr/local/bin/docker-compose
&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;3查看docker-compose版本&quot;&gt;3.查看docker-compose版本&lt;/h3&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;[root@binghe ~]# docker-compose version
docker-compose version 1.25.5, build 8a1c60f6
docker-py version: 4.1.0
CPython version: 3.7.5
OpenSSL version: OpenSSL 1.1.0l  10 Sep 2019
&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;安装k8s集群环境&quot;&gt;安装K8S集群环境&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;本文档基于K8S 1.8.12版本来搭建K8S集群&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&quot;安装k8s基础环境&quot;&gt;安装K8S基础环境&lt;/h3&gt;
&lt;p&gt;在所有服务器上创建install_k8s.sh脚本文件，脚本文件的内容如下所示。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;#配置阿里云镜像加速器
mkdir -p /etc/docker
tee /etc/docker/daemon.json &amp;lt;&amp;lt;-'EOF'
{
  &quot;registry-mirrors&quot;: [&quot;https://zz3sblpi.mirror.aliyuncs.com&quot;]
}
EOF
systemctl daemon-reload
systemctl restart docker

#安装nfs-utils
yum install -y nfs-utils
yum install -y wget

#启动nfs-server
systemctl start nfs-server
systemctl enable nfs-server

#关闭防火墙
systemctl stop firewalld
systemctl disable firewalld

#关闭SeLinux
setenforce 0
sed -i &quot;s/SELINUX=enforcing/SELINUX=disabled/g&quot; /etc/selinux/config

# 关闭 swap
swapoff -a
yes | cp /etc/fstab /etc/fstab_bak
cat /etc/fstab_bak |grep -v swap &amp;gt; /etc/fstab

#修改 /etc/sysctl.conf
# 如果有配置，则修改
sed -i &quot;s#^net.ipv4.ip_forward.*#net.ipv4.ip_forward=1#g&quot;  /etc/sysctl.conf
sed -i &quot;s#^net.bridge.bridge-nf-call-ip6tables.*#net.bridge.bridge-nf-call-ip6tables=1#g&quot;  /etc/sysctl.conf
sed -i &quot;s#^net.bridge.bridge-nf-call-iptables.*#net.bridge.bridge-nf-call-iptables=1#g&quot;  /etc/sysctl.conf
sed -i &quot;s#^net.ipv6.conf.all.disable_ipv6.*#net.ipv6.conf.all.disable_ipv6=1#g&quot;  /etc/sysctl.conf
sed -i &quot;s#^net.ipv6.conf.default.disable_ipv6.*#net.ipv6.conf.default.disable_ipv6=1#g&quot;  /etc/sysctl.conf
sed -i &quot;s#^net.ipv6.conf.lo.disable_ipv6.*#net.ipv6.conf.lo.disable_ipv6=1#g&quot;  /etc/sysctl.conf
sed -i &quot;s#^net.ipv6.conf.all.forwarding.*#net.ipv6.conf.all.forwarding=1#g&quot;  /etc/sysctl.conf
# 可能没有，追加
echo &quot;net.ipv4.ip_forward = 1&quot; &amp;gt;&amp;gt; /etc/sysctl.conf
echo &quot;net.bridge.bridge-nf-call-ip6tables = 1&quot; &amp;gt;&amp;gt; /etc/sysctl.conf
echo &quot;net.bridge.bridge-nf-call-iptables = 1&quot; &amp;gt;&amp;gt; /etc/sysctl.conf
echo &quot;net.ipv6.conf.all.disable_ipv6 = 1&quot; &amp;gt;&amp;gt; /etc/sysctl.conf
echo &quot;net.ipv6.conf.default.disable_ipv6 = 1&quot; &amp;gt;&amp;gt; /etc/sysctl.conf
echo &quot;net.ipv6.conf.lo.disable_ipv6 = 1&quot; &amp;gt;&amp;gt; /etc/sysctl.conf
echo &quot;net.ipv6.conf.all.forwarding = 1&quot;  &amp;gt;&amp;gt; /etc/sysctl.conf
# 执行命令以应用
sysctl -p

# 配置K8S的yum源
cat &amp;lt;&amp;lt;EOF &amp;gt; /etc/yum.repos.d/kubernetes.repo
[kubernetes]
name=Kubernetes
baseurl=http://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64
enabled=1
gpgcheck=0
repo_gpgcheck=0
gpgkey=http://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg
       http://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg
EOF

# 卸载旧版本K8S
yum remove -y kubelet kubeadm kubectl

# 安装kubelet、kubeadm、kubectl，这里我安装的是1.18.2版本，你也可以安装1.17.2版本
yum install -y kubelet-1.18.2 kubeadm-1.18.2 kubectl-1.18.2

# 修改docker Cgroup Driver为systemd
# # 将/usr/lib/systemd/system/docker.service文件中的这一行 ExecStart=/usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock
# # 修改为 ExecStart=/usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock --exec-opt native.cgroupdriver=systemd
# 如果不修改，在添加 worker 节点时可能会碰到如下错误
# [WARNING IsDockerSystemdCheck]: detected &quot;cgroupfs&quot; as the Docker cgroup driver. The recommended driver is &quot;systemd&quot;. 
# Please follow the guide at https://kubernetes.io/docs/setup/cri/
sed -i &quot;s#^ExecStart=/usr/bin/dockerd.*#ExecStart=/usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock --exec-opt native.cgroupdriver=systemd#g&quot; /usr/lib/systemd/system/docker.service

# 设置 docker 镜像，提高 docker 镜像下载速度和稳定性
# 如果访问 https://hub.docker.io 速度非常稳定，亦可以跳过这个步骤
# curl -sSL https://kuboard.cn/install-script/set_mirror.sh | sh -s ${REGISTRY_MIRROR}

# 重启 docker，并启动 kubelet
systemctl daemon-reload
systemctl restart docker
systemctl enable kubelet &amp;amp;&amp;amp; systemctl start kubelet

docker version
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;在每台服务器上为install_k8s.sh脚本赋予可执行权限，并执行脚本即可。&lt;/p&gt;
&lt;h3 id=&quot;初始化master节点&quot;&gt;初始化Master节点&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;只在binghe101服务器上执行的操作。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;1.初始化Master节点的网络环境&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;注意：下面的命令需要在命令行手动执行。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;# 只在 master 节点执行
# export 命令只在当前 shell 会话中有效，开启新的 shell 窗口后，如果要继续安装过程，请重新执行此处的 export 命令
export MASTER_IP=192.168.175.101
# 替换 k8s.master 为 您想要的 dnsName
export APISERVER_NAME=k8s.master
# Kubernetes 容器组所在的网段，该网段安装完成后，由 kubernetes 创建，事先并不存在于物理网络中
export POD_SUBNET=172.18.0.1/16
echo &quot;${MASTER_IP}    ${APISERVER_NAME}&quot; &amp;gt;&amp;gt; /etc/hosts
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;2.初始化Master节点&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;在binghe101服务器上创建init_master.sh脚本文件，文件内容如下所示。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;#!/bin/bash
# 脚本出错时终止执行
set -e

if [ ${#POD_SUBNET} -eq 0 ] || [ ${#APISERVER_NAME} -eq 0 ]; then
  echo -e &quot;\033[31;1m请确保您已经设置了环境变量 POD_SUBNET 和 APISERVER_NAME \033[0m&quot;
  echo 当前POD_SUBNET=$POD_SUBNET
  echo 当前APISERVER_NAME=$APISERVER_NAME
  exit 1
fi


# 查看完整配置选项 https://godoc.org/k8s.io/kubernetes/cmd/kubeadm/app/apis/kubeadm/v1beta2
rm -f ./kubeadm-config.yaml
cat &amp;lt;&amp;lt;EOF &amp;gt; ./kubeadm-config.yaml
apiVersion: kubeadm.k8s.io/v1beta2
kind: ClusterConfiguration
kubernetesVersion: v1.18.2
imageRepository: registry.cn-hangzhou.aliyuncs.com/google_containers
controlPlaneEndpoint: &quot;${APISERVER_NAME}:6443&quot;
networking:
  serviceSubnet: &quot;10.96.0.0/16&quot;
  podSubnet: &quot;${POD_SUBNET}&quot;
  dnsDomain: &quot;cluster.local&quot;
EOF

# kubeadm init
# 根据服务器网速的情况，您需要等候 3 - 10 分钟
kubeadm init --config=kubeadm-config.yaml --upload-certs

# 配置 kubectl
rm -rf /root/.kube/
mkdir /root/.kube/
cp -i /etc/kubernetes/admin.conf /root/.kube/config

# 安装 calico 网络插件
# 参考文档 https://docs.projectcalico.org/v3.13/getting-started/kubernetes/self-managed-onprem/onpremises
echo &quot;安装calico-3.13.1&quot;
rm -f calico-3.13.1.yaml
wget https://kuboard.cn/install-script/calico/calico-3.13.1.yaml
kubectl apply -f calico-3.13.1.yaml
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;赋予init_master.sh脚本文件可执行权限并执行脚本。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;3.查看Master节点的初始化结果&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;（1）确保所有容器组处于Running状态&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;# 执行如下命令，等待 3-10 分钟，直到所有的容器组处于 Running 状态
watch kubectl get pod -n kube-system -o wide
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;具体执行如下所示。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;[root@binghe101 ~]# watch kubectl get pod -n kube-system -o wide
Every 2.0s: kubectl get pod -n kube-system -o wide                                                                                                                          binghe101: Sun May 10 11:01:32 2020

NAME                                       READY   STATUS    RESTARTS   AGE    IP                NODE        NOMINATED NODE   READINESS GATES          
calico-kube-controllers-5b8b769fcd-5dtlp   1/1     Running   0          118s   172.18.203.66     binghe101   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;          
calico-node-fnv8g                          1/1     Running   0          118s   192.168.175.101   binghe101   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;          
coredns-546565776c-27t7h                   1/1     Running   0          2m1s   172.18.203.67     binghe101   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;          
coredns-546565776c-hjb8z                   1/1     Running   0          2m1s   172.18.203.65     binghe101   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;          
etcd-binghe101                             1/1     Running   0          2m7s   192.168.175.101   binghe101   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;          
kube-apiserver-binghe101                   1/1     Running   0          2m7s   192.168.175.101   binghe101   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;          
kube-controller-manager-binghe101          1/1     Running   0          2m7s   192.168.175.101   binghe101   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;          
kube-proxy-dvgsr                           1/1     Running   0          2m1s   192.168.175.101   binghe101   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;          
kube-scheduler-binghe101                   1/1     Running   0          2m7s   192.168.175.101   binghe101   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;（2） 查看 Master 节点初始化结果&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;kubectl get nodes -o wide
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;具体执行如下所示。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;[root@binghe101 ~]# kubectl get nodes -o wide
NAME        STATUS   ROLES    AGE     VERSION   INTERNAL-IP       EXTERNAL-IP   OS-IMAGE                KERNEL-VERSION         CONTAINER-RUNTIME
binghe101   Ready    master   3m28s   v1.18.2   192.168.175.101   &amp;lt;none&amp;gt;        CentOS Linux 8 (Core)   4.18.0-80.el8.x86_64   docker://19.3.8
&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;初始化worker节点&quot;&gt;初始化Worker节点&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;1.获取join命令参数&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;在Master节点（binghe101服务器）上执行如下命令获取join命令参数。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;kubeadm token create --print-join-command
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;具体执行如下所示。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;[root@binghe101 ~]# kubeadm token create --print-join-command
W0510 11:04:34.828126   56132 configset.go:202] WARNING: kubeadm cannot validate component configs for API groups [kubelet.config.k8s.io kubeproxy.config.k8s.io]
kubeadm join k8s.master:6443 --token 8nblts.62xytoqufwsqzko2     --discovery-token-ca-cert-hash sha256:1717cc3e34f6a56b642b5751796530e367aa73f4113d09994ac3455e33047c0d 
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;其中，有如下一行输出。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;kubeadm join k8s.master:6443 --token 8nblts.62xytoqufwsqzko2     --discovery-token-ca-cert-hash sha256:1717cc3e34f6a56b642b5751796530e367aa73f4113d09994ac3455e33047c0d 
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;这行代码就是获取到的join命令。&lt;/p&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;注意：join命令中的token的有效时间为 2 个小时，2小时内，可以使用此 token 初始化任意数量的 worker 节点。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;2.初始化Worker节点&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;针对所有的 worker 节点执行，在这里，就是在binghe102服务器和binghe103服务器上执行。&lt;/p&gt;
&lt;p&gt;在命令分别手动执行如下命令。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;# 只在 worker 节点执行
# 192.168.175.101 为 master 节点的内网 IP
export MASTER_IP=192.168.175.101
# 替换 k8s.master 为初始化 master 节点时所使用的 APISERVER_NAME
export APISERVER_NAME=k8s.master
echo &quot;${MASTER_IP}    ${APISERVER_NAME}&quot; &amp;gt;&amp;gt; /etc/hosts

# 替换为 master 节点上 kubeadm token create 命令输出的join
kubeadm join k8s.master:6443 --token 8nblts.62xytoqufwsqzko2     --discovery-token-ca-cert-hash sha256:1717cc3e34f6a56b642b5751796530e367aa73f4113d09994ac3455e33047c0d 
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;具体执行如下所示。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;[root@binghe102 ~]# export MASTER_IP=192.168.175.101
[root@binghe102 ~]# export APISERVER_NAME=k8s.master
[root@binghe102 ~]# echo &quot;${MASTER_IP}    ${APISERVER_NAME}&quot; &amp;gt;&amp;gt; /etc/hosts
[root@binghe102 ~]# kubeadm join k8s.master:6443 --token 8nblts.62xytoqufwsqzko2     --discovery-token-ca-cert-hash sha256:1717cc3e34f6a56b642b5751796530e367aa73f4113d09994ac3455e33047c0d 
W0510 11:08:27.709263   42795 join.go:346] [preflight] WARNING: JoinControlPane.controlPlane settings will be ignored when control-plane flag is not set.
[preflight] Running pre-flight checks
        [WARNING FileExisting-tc]: tc not found in system path
[preflight] Reading configuration from the cluster...
[preflight] FYI: You can look at this config file with 'kubectl -n kube-system get cm kubeadm-config -oyaml'
[kubelet-start] Downloading configuration for the kubelet from the &quot;kubelet-config-1.18&quot; ConfigMap in the kube-system namespace
[kubelet-start] Writing kubelet configuration to file &quot;/var/lib/kubelet/config.yaml&quot;
[kubelet-start] Writing kubelet environment file with flags to file &quot;/var/lib/kubelet/kubeadm-flags.env&quot;
[kubelet-start] Starting the kubelet
[kubelet-start] Waiting for the kubelet to perform the TLS Bootstrap...

This node has joined the cluster:
* Certificate signing request was sent to apiserver and a response was received.
* The Kubelet was informed of the new secure connection details.

Run 'kubectl get nodes' on the control-plane to see this node join the cluster.
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;根据输出结果可以看出，Worker节点加入了K8S集群。&lt;/p&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;注意：kubeadm join…就是master 节点上 kubeadm token create 命令输出的join。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;3.查看初始化结果&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;在Master节点（binghe101服务器）执行如下命令查看初始化结果。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;kubectl get nodes -o wide
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;具体执行如下所示。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;[root@binghe101 ~]# kubectl get nodes
NAME        STATUS   ROLES    AGE     VERSION
binghe101   Ready    master   20m     v1.18.2
binghe102   Ready    &amp;lt;none&amp;gt;   2m46s   v1.18.2
binghe103   Ready    &amp;lt;none&amp;gt;   2m46s   v1.18.2
&lt;/code&gt;
&lt;/pre&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;注意：kubectl get nodes命令后面加上-o wide参数可以输出更多的信息。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;重启k8s集群引起的问题&quot;&gt;重启K8S集群引起的问题&lt;/h2&gt;
&lt;h3 id=&quot;1worker节点故障不能启动&quot;&gt;1.Worker节点故障不能启动&lt;/h3&gt;
&lt;p&gt;Master 节点的 IP 地址发生变化，导致 worker 节点不能启动。需要重新安装K8S集群，并确保所有节点都有固定的内网 IP 地址。&lt;/p&gt;
&lt;h3 id=&quot;2pod崩溃或不能正常访问&quot;&gt;2.Pod崩溃或不能正常访问&lt;/h3&gt;
&lt;p&gt;重启服务器后使用如下命令查看Pod的运行状态。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;kubectl get pods --all-namespaces
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;发现很多 Pod 不在 Running 状态，此时，需要使用如下命令删除运行不正常的Pod。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;kubectl delete pod &amp;lt;pod-name&amp;gt; -n &amp;lt;pod-namespece&amp;gt;
&lt;/code&gt;
&lt;/pre&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;注意：如果Pod 是使用 Deployment、StatefulSet 等控制器创建的，K8S 将创建新的 Pod 作为替代，重新启动的 Pod 通常能够正常工作。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;k8s安装ingress-nginx&quot;&gt;K8S安装ingress-nginx&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;注意：在Master节点（binghe101服务器上执行）&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&quot;1创建ingress-nginx命名空间&quot;&gt;1.创建ingress-nginx命名空间&lt;/h3&gt;
&lt;p&gt;创建ingress-nginx-namespace.yaml文件，文件内容如下所示。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-yaml&quot;&gt;apiVersion: v1
kind: Namespace
metadata:
  name: ingress-nginx
  labels:
    name: ingress-nginx
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;执行如下命令创建ingress-nginx命名空间。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;kubectl apply -f ingress-nginx-namespace.yaml
&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;2安装ingress-controller&quot;&gt;2.安装ingress controller&lt;/h3&gt;
&lt;p&gt;创建ingress-nginx-mandatory.yaml文件，文件内容如下所示。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-yaml&quot;&gt;apiVersion: v1
kind: Namespace
metadata:
  name: ingress-nginx

---

apiVersion: apps/v1
kind: Deployment
metadata:
  name: default-http-backend
  labels:
    app.kubernetes.io/name: default-http-backend
    app.kubernetes.io/part-of: ingress-nginx
  namespace: ingress-nginx
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: default-http-backend
      app.kubernetes.io/part-of: ingress-nginx
  template:
    metadata:
      labels:
        app.kubernetes.io/name: default-http-backend
        app.kubernetes.io/part-of: ingress-nginx
    spec:
      terminationGracePeriodSeconds: 60
      containers:
        - name: default-http-backend
          # Any image is permissible as long as:
          # 1. It serves a 404 page at /
          # 2. It serves 200 on a /healthz endpoint
          image: registry.cn-qingdao.aliyuncs.com/kubernetes_xingej/defaultbackend-amd64:1.5
          livenessProbe:
            httpGet:
              path: /healthz
              port: 8080
              scheme: HTTP
            initialDelaySeconds: 30
            timeoutSeconds: 5
          ports:
            - containerPort: 8080
          resources:
            limits:
              cpu: 10m
              memory: 20Mi
            requests:
              cpu: 10m
              memory: 20Mi

---
apiVersion: v1
kind: Service
metadata:
  name: default-http-backend
  namespace: ingress-nginx
  labels:
    app.kubernetes.io/name: default-http-backend
    app.kubernetes.io/part-of: ingress-nginx
spec:
  ports:
    - port: 80
      targetPort: 8080
  selector:
    app.kubernetes.io/name: default-http-backend
    app.kubernetes.io/part-of: ingress-nginx

---

kind: ConfigMap
apiVersion: v1
metadata:
  name: nginx-configuration
  namespace: ingress-nginx
  labels:
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/part-of: ingress-nginx

---

kind: ConfigMap
apiVersion: v1
metadata:
  name: tcp-services
  namespace: ingress-nginx
  labels:
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/part-of: ingress-nginx

---

kind: ConfigMap
apiVersion: v1
metadata:
  name: udp-services
  namespace: ingress-nginx
  labels:
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/part-of: ingress-nginx

---

apiVersion: v1
kind: ServiceAccount
metadata:
  name: nginx-ingress-serviceaccount
  namespace: ingress-nginx
  labels:
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/part-of: ingress-nginx

---
apiVersion: rbac.authorization.k8s.io/v1beta1
kind: ClusterRole
metadata:
  name: nginx-ingress-clusterrole
  labels:
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/part-of: ingress-nginx
rules:
  - apiGroups:
      - &quot;&quot;
    resources:
      - configmaps
      - endpoints
      - nodes
      - pods
      - secrets
    verbs:
      - list
      - watch
  - apiGroups:
      - &quot;&quot;
    resources:
      - nodes
    verbs:
      - get
  - apiGroups:
      - &quot;&quot;
    resources:
      - services
    verbs:
      - get
      - list
      - watch
  - apiGroups:
      - &quot;extensions&quot;
    resources:
      - ingresses
    verbs:
      - get
      - list
      - watch
  - apiGroups:
      - &quot;&quot;
    resources:
      - events
    verbs:
      - create
      - patch
  - apiGroups:
      - &quot;extensions&quot;
    resources:
      - ingresses/status
    verbs:
      - update

---
apiVersion: rbac.authorization.k8s.io/v1beta1
kind: Role
metadata:
  name: nginx-ingress-role
  namespace: ingress-nginx
  labels:
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/part-of: ingress-nginx
rules:
  - apiGroups:
      - &quot;&quot;
    resources:
      - configmaps
      - pods
      - secrets
      - namespaces
    verbs:
      - get
  - apiGroups:
      - &quot;&quot;
    resources:
      - configmaps
    resourceNames:
      # Defaults to &quot;&amp;lt;election-id&amp;gt;-&amp;lt;ingress-class&amp;gt;&quot;
      # Here: &quot;&amp;lt;ingress-controller-leader&amp;gt;-&amp;lt;nginx&amp;gt;&quot;
      # This has to be adapted if you change either parameter
      # when launching the nginx-ingress-controller.
      - &quot;ingress-controller-leader-nginx&quot;
    verbs:
      - get
      - update
  - apiGroups:
      - &quot;&quot;
    resources:
      - configmaps
    verbs:
      - create
  - apiGroups:
      - &quot;&quot;
    resources:
      - endpoints
    verbs:
      - get

---
apiVersion: rbac.authorization.k8s.io/v1beta1
kind: RoleBinding
metadata:
  name: nginx-ingress-role-nisa-binding
  namespace: ingress-nginx
  labels:
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/part-of: ingress-nginx
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: nginx-ingress-role
subjects:
  - kind: ServiceAccount
    name: nginx-ingress-serviceaccount
    namespace: ingress-nginx

---
apiVersion: rbac.authorization.k8s.io/v1beta1
kind: ClusterRoleBinding
metadata:
  name: nginx-ingress-clusterrole-nisa-binding
  labels:
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/part-of: ingress-nginx
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: nginx-ingress-clusterrole
subjects:
  - kind: ServiceAccount
    name: nginx-ingress-serviceaccount
    namespace: ingress-nginx

---

apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-ingress-controller
  namespace: ingress-nginx
  labels:
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/part-of: ingress-nginx
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: ingress-nginx
      app.kubernetes.io/part-of: ingress-nginx
  template:
    metadata:
      labels:
        app.kubernetes.io/name: ingress-nginx
        app.kubernetes.io/part-of: ingress-nginx
      annotations:
        prometheus.io/port: &quot;10254&quot;
        prometheus.io/scrape: &quot;true&quot;
    spec:
      serviceAccountName: nginx-ingress-serviceaccount
      containers:
        - name: nginx-ingress-controller
          image: registry.cn-qingdao.aliyuncs.com/kubernetes_xingej/nginx-ingress-controller:0.20.0
          args:
            - /nginx-ingress-controller
            - --default-backend-service=$(POD_NAMESPACE)/default-http-backend
            - --configmap=$(POD_NAMESPACE)/nginx-configuration
            - --tcp-services-configmap=$(POD_NAMESPACE)/tcp-services
            - --udp-services-configmap=$(POD_NAMESPACE)/udp-services
            - --publish-service=$(POD_NAMESPACE)/ingress-nginx
            - --annotations-prefix=nginx.ingress.kubernetes.io
          securityContext:
            capabilities:
              drop:
                - ALL
              add:
                - NET_BIND_SERVICE
            # www-data -&amp;gt; 33
            runAsUser: 33
          env:
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: POD_NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
          ports:
            - name: http
              containerPort: 80
            - name: https
              containerPort: 443
          livenessProbe:
            failureThreshold: 3
            httpGet:
              path: /healthz
              port: 10254
              scheme: HTTP
            initialDelaySeconds: 10
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /healthz
              port: 10254
              scheme: HTTP
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1

---
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;执行如下命令安装ingress controller。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;kubectl apply -f ingress-nginx-mandatory.yaml
&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;3安装k8s-svc：ingress-nginx&quot;&gt;3.安装K8S SVC：ingress-nginx&lt;/h3&gt;
&lt;p&gt;主要是用来用于暴露pod：nginx-ingress-controller。&lt;/p&gt;
&lt;p&gt;创建service-nodeport.yaml文件，文件内容如下所示。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-yaml&quot;&gt;apiVersion: v1
kind: Service
metadata:
  name: ingress-nginx
  namespace: ingress-nginx
  labels:
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/part-of: ingress-nginx
spec:
  type: NodePort
  ports:
    - name: http
      port: 80
      targetPort: 80
      protocol: TCP
      nodePort: 30080
    - name: https
      port: 443
      targetPort: 443
      protocol: TCP
      nodePort: 30443
  selector:
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/part-of: ingress-nginx
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;执行如下命令安装。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;kubectl apply -f service-nodeport.yaml
&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;4访问k8s-svc：ingress-nginx&quot;&gt;4.访问K8S SVC：ingress-nginx&lt;/h3&gt;
&lt;p&gt;查看ingress-nginx命名空间的部署情况，如下所示。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;[root@binghe101 k8s]# kubectl get pod -n ingress-nginx
NAME                                        READY   STATUS    RESTARTS   AGE
default-http-backend-796ddcd9b-vfmgn        1/1     Running   1          10h
nginx-ingress-controller-58985cc996-87754   1/1     Running   2          10h
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;在命令行服务器命令行输入如下命令查看ingress-nginx的端口映射情况。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;kubectl get svc -n ingress-nginx 
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;具体如下所示。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;[root@binghe101 k8s]# kubectl get svc -n ingress-nginx 
NAME                   TYPE        CLUSTER-IP    EXTERNAL-IP   PORT(S)                      AGE
default-http-backend   ClusterIP   10.96.247.2   &amp;lt;none&amp;gt;        80/TCP                       7m3s
ingress-nginx          NodePort    10.96.40.6    &amp;lt;none&amp;gt;        80:30080/TCP,443:30443/TCP   4m35s
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;所以，可以通过Master节点（binghe101服务器）的IP地址和30080端口号来访问ingress-nginx，如下所示。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;[root@binghe101 k8s]# curl 192.168.175.101:30080       
default backend - 404
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;也可以在浏览器打开http://192.168.175.101:30080 来访问ingress-nginx，如下所示。&lt;br/&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20200521003920255.jpg#pic_center&quot; alt=&quot;在这里插入图片描述&quot;/&gt;&lt;/p&gt;
&lt;h2 id=&quot;k8s安装gitlab代码仓库&quot;&gt;K8S安装gitlab代码仓库&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;注意：在Master节点（binghe101服务器上执行）&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&quot;1创建k8s-ops命名空间&quot;&gt;1.创建k8s-ops命名空间&lt;/h3&gt;
&lt;p&gt;创建k8s-ops-namespace.yaml文件，文件内容如下所示。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-yaml&quot;&gt;apiVersion: v1
kind: Namespace
metadata:
  name: k8s-ops
  labels:
    name: k8s-ops
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;执行如下命令创建命名空间。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;kubectl apply -f k8s-ops-namespace.yaml 
&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;2安装gitlab-redis&quot;&gt;2.安装gitlab-redis&lt;/h3&gt;
&lt;p&gt;创建gitlab-redis.yaml文件，文件的内容如下所示。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-yaml&quot;&gt;apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis
  namespace: k8s-ops
  labels:
    name: redis
spec:
  selector:
    matchLabels:
      name: redis
  template:
    metadata:
      name: redis
      labels:
        name: redis
    spec:
      containers:
      - name: redis
        image: sameersbn/redis
        imagePullPolicy: IfNotPresent
        ports:
        - name: redis
          containerPort: 6379
        volumeMounts:
        - mountPath: /var/lib/redis
          name: data
        livenessProbe:
          exec:
            command:
            - redis-cli
            - ping
          initialDelaySeconds: 30
          timeoutSeconds: 5
        readinessProbe:
          exec:
            command:
            - redis-cli
            - ping
          initialDelaySeconds: 10
          timeoutSeconds: 5
      volumes:
      - name: data
        hostPath:
          path: /data1/docker/xinsrv/redis

---
apiVersion: v1
kind: Service
metadata:
  name: redis
  namespace: k8s-ops
  labels:
    name: redis
spec:
  ports:
    - name: redis
      port: 6379
      targetPort: redis
  selector:
    name: redis
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;首先，在命令行执行如下命令创建/data1/docker/xinsrv/redis目录。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;mkdir -p /data1/docker/xinsrv/redis
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;执行如下命令安装gitlab-redis。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;kubectl apply -f gitlab-redis.yaml 
&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;3安装gitlab-postgresql&quot;&gt;3.安装gitlab-postgresql&lt;/h3&gt;
&lt;p&gt;创建gitlab-postgresql.yaml，文件内容如下所示。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;apiVersion: apps/v1
kind: Deployment
metadata:
  name: postgresql
  namespace: k8s-ops
  labels:
    name: postgresql
spec:
  selector:
    matchLabels:
      name: postgresql
  template:
    metadata:
      name: postgresql
      labels:
        name: postgresql
    spec:
      containers:
      - name: postgresql
        image: sameersbn/postgresql
        imagePullPolicy: IfNotPresent
        env:
        - name: DB_USER
          value: gitlab
        - name: DB_PASS
          value: passw0rd
        - name: DB_NAME
          value: gitlab_production
        - name: DB_EXTENSION
          value: pg_trgm
        ports:
        - name: postgres
          containerPort: 5432
        volumeMounts:
        - mountPath: /var/lib/postgresql
          name: data
        livenessProbe:
          exec:
            command:
            - pg_isready
            - -h
            - localhost
            - -U
            - postgres
          initialDelaySeconds: 30
          timeoutSeconds: 5
        readinessProbe:
          exec:
            command:
            - pg_isready
            - -h
            - localhost
            - -U
            - postgres
          initialDelaySeconds: 5
          timeoutSeconds: 1
      volumes:
      - name: data
        hostPath:
          path: /data1/docker/xinsrv/postgresql
---
apiVersion: v1
kind: Service
metadata:
  name: postgresql
  namespace: k8s-ops
  labels:
    name: postgresql
spec:
  ports:
    - name: postgres
      port: 5432
      targetPort: postgres
  selector:
    name: postgresql
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;首先，执行如下命令创建/data1/docker/xinsrv/postgresql目录。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;mkdir -p /data1/docker/xinsrv/postgresql
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;接下来，安装gitlab-postgresql，如下所示。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;kubectl apply -f gitlab-postgresql.yaml
&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;4安装gitlab&quot;&gt;4.安装gitlab&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;（1）配置用户名和密码&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;首先，在命令行使用base64编码为用户名和密码进行转码，本示例中，使用的用户名为admin，密码为admin.1231&lt;/p&gt;
&lt;p&gt;转码情况如下所示。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;[root@binghe101 k8s]# echo -n 'admin' | base64 
YWRtaW4=
[root@binghe101 k8s]# echo -n 'admin.1231' | base64 
YWRtaW4uMTIzMQ==
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;转码后的用户名为：YWRtaW4= 密码为：YWRtaW4uMTIzMQ==&lt;/p&gt;
&lt;p&gt;也可以对base64编码后的字符串解码，例如，对密码字符串解码，如下所示。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;[root@binghe101 k8s]# echo 'YWRtaW4uMTIzMQ==' | base64 --decode 
admin.1231
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;接下来，创建secret-gitlab.yaml文件，主要是用户来配置GitLab的用户名和密码，文件内容如下所示。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;apiVersion: v1
kind: Secret
metadata:
  namespace: k8s-ops
  name: git-user-pass
type: Opaque
data:
  username: YWRtaW4=
  password: YWRtaW4uMTIzMQ==
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;执行配置文件的内容，如下所示。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;kubectl create -f ./secret-gitlab.yaml
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;（2）安装GitLab&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;创建gitlab.yaml文件，文件的内容如下所示。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-yaml&quot;&gt;apiVersion: apps/v1
kind: Deployment
metadata:
  name: gitlab
  namespace: k8s-ops
  labels:
    name: gitlab
spec:
  selector:
    matchLabels:
      name: gitlab
  template:
    metadata:
      name: gitlab
      labels:
        name: gitlab
    spec:
      containers:
      - name: gitlab
        image: sameersbn/gitlab:12.1.6
        imagePullPolicy: IfNotPresent
        env:
        - name: TZ
          value: Asia/Shanghai
        - name: GITLAB_TIMEZONE
          value: Beijing
        - name: GITLAB_SECRETS_DB_KEY_BASE
          value: long-and-random-alpha-numeric-string
        - name: GITLAB_SECRETS_SECRET_KEY_BASE
          value: long-and-random-alpha-numeric-string
        - name: GITLAB_SECRETS_OTP_KEY_BASE
          value: long-and-random-alpha-numeric-string
        - name: GITLAB_ROOT_PASSWORD
          valueFrom:
            secretKeyRef:
              name: git-user-pass
              key: password
        - name: GITLAB_ROOT_EMAIL
          value: 12345678@qq.com
        - name: GITLAB_HOST
          value: gitlab.binghe.com
        - name: GITLAB_PORT
          value: &quot;80&quot;
        - name: GITLAB_SSH_PORT
          value: &quot;30022&quot;
        - name: GITLAB_NOTIFY_ON_BROKEN_BUILDS
          value: &quot;true&quot;
        - name: GITLAB_NOTIFY_PUSHER
          value: &quot;false&quot;
        - name: GITLAB_BACKUP_SCHEDULE
          value: daily
        - name: GITLAB_BACKUP_TIME
          value: 01:00
        - name: DB_TYPE
          value: postgres
        - name: DB_HOST
          value: postgresql
        - name: DB_PORT
          value: &quot;5432&quot;
        - name: DB_USER
          value: gitlab
        - name: DB_PASS
          value: passw0rd
        - name: DB_NAME
          value: gitlab_production
        - name: REDIS_HOST
          value: redis
        - name: REDIS_PORT
          value: &quot;6379&quot;
        ports:
        - name: http
          containerPort: 80
        - name: ssh
          containerPort: 22
        volumeMounts:
        - mountPath: /home/git/data
          name: data
        livenessProbe:
          httpGet:
            path: /
            port: 80
          initialDelaySeconds: 180
          timeoutSeconds: 5
        readinessProbe:
          httpGet:
            path: /
            port: 80
          initialDelaySeconds: 5
          timeoutSeconds: 1
      volumes:
      - name: data
        hostPath:
          path: /data1/docker/xinsrv/gitlab
---
apiVersion: v1
kind: Service
metadata:
  name: gitlab
  namespace: k8s-ops
  labels:
    name: gitlab
spec:
  ports:
    - name: http
      port: 80
      nodePort: 30088
    - name: ssh
      port: 22
      targetPort: ssh
      nodePort: 30022
  type: NodePort
  selector:
    name: gitlab

---
apiVersion: extensions/v1beta1
kind: Ingress
metadata:
  name: gitlab
  namespace: k8s-ops
  annotations:
    kubernetes.io/ingress.class: traefik
spec:
  rules:
  - host: gitlab.binghe.com
    http:
      paths:
      - backend:
          serviceName: gitlab
          servicePort: http
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;注意：在配置GitLab时，监听主机时，不能使用IP地址，需要使用主机名或者域名，上述配置中，我使用的是gitlab.binghe.com主机名。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;在命令行执行如下命令创建/data1/docker/xinsrv/gitlab目录。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;mkdir -p /data1/docker/xinsrv/gitlab
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;安装GitLab，如下所示。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;kubectl apply -f gitlab.yaml
&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;5安装完成&quot;&gt;5.安装完成&lt;/h3&gt;
&lt;p&gt;查看k8s-ops命名空间部署情况，如下所示。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;[root@binghe101 k8s]# kubectl get pod -n k8s-ops
NAME                          READY   STATUS    RESTARTS   AGE
gitlab-7b459db47c-5vk6t       0/1     Running   0          11s
postgresql-79567459d7-x52vx   1/1     Running   0          30m
redis-67f4cdc96c-h5ckz        1/1     Running   1          10h
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;也可以使用如下命令查看。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;[root@binghe101 k8s]# kubectl get pod --namespace=k8s-ops
NAME                          READY   STATUS    RESTARTS   AGE
gitlab-7b459db47c-5vk6t       0/1     Running   0          36s
postgresql-79567459d7-x52vx   1/1     Running   0          30m
redis-67f4cdc96c-h5ckz        1/1     Running   1          10h
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;二者效果一样。&lt;/p&gt;
&lt;p&gt;接下来，查看GitLab的端口映射，如下所示。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;[root@binghe101 k8s]# kubectl get svc -n k8s-ops
NAME         TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)                     AGE
gitlab       NodePort    10.96.153.100   &amp;lt;none&amp;gt;        80:30088/TCP,22:30022/TCP   2m42s
postgresql   ClusterIP   10.96.203.119   &amp;lt;none&amp;gt;        5432/TCP                    32m
redis        ClusterIP   10.96.107.150   &amp;lt;none&amp;gt;        6379/TCP                    10h
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;此时，可以看到，可以通过Master节点（binghe101）的主机名gitlab.binghe.com和端口30088就能够访问GitLab。由于我这里使用的是虚拟机来搭建相关的环境，在本机访问虚拟机映射的gitlab.binghe.com时，需要配置本机的hosts文件，在本机的hosts文件中加入如下配置项。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;192.168.175.101 gitlab.binghe.com
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;注意：在Windows操作系统中，hosts文件所在的目录如下。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;C:\Windows\System32\drivers\etc
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;接下来，就可以在浏览器中通过链接：&lt;a href=&quot;http://gitlab.binghe.com:30088&quot;&gt;http://gitlab.binghe.com:30088&lt;/a&gt; 来访问GitLab了，如下所示。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20200521004033845.jpg&quot; alt=&quot;在这里插入图片描述&quot;/&gt;&lt;/p&gt;
&lt;p&gt;此时，可以通过用户名root和密码admin.1231来登录GitLab了。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;注意：这里的用户名是root而不是admin，因为root是GitLab默认的超级用户。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20200521004046470.jpg&quot; alt=&quot;在这里插入图片描述&quot;/&gt;&lt;/p&gt;
&lt;p&gt;登录后的界面如下所示。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/2020052100410037.jpg&quot; alt=&quot;在这里插入图片描述&quot;/&gt;&lt;/p&gt;
&lt;p&gt;到此，K8S安装gitlab完成。&lt;/p&gt;
&lt;h2 id=&quot;安装harbor私有仓库&quot;&gt;安装Harbor私有仓库&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;注意：这里将Harbor私有仓库安装在Master节点（binghe101服务器）上，实际生产环境中建议安装在其他服务器。&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&quot;1下载harbor的离线安装版本&quot;&gt;1.下载Harbor的离线安装版本&lt;/h3&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;wget https://github.com/goharbor/harbor/releases/download/v1.10.2/harbor-offline-installer-v1.10.2.tgz
&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;2解压harbor的安装包&quot;&gt;2.解压Harbor的安装包&lt;/h3&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;tar -zxvf harbor-offline-installer-v1.10.2.tgz
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;解压成功后，会在服务器当前目录生成一个harbor目录。&lt;/p&gt;
&lt;h3 id=&quot;3配置harbor&quot;&gt;3.配置Harbor&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;注意：这里，我将Harbor的端口修改成了1180，如果不修改Harbor的端口，默认的端口是80。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;（1）修改harbor.yml文件&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;cd harbor
vim harbor.yml
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;修改的配置项如下所示。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;hostname: 192.168.175.101
http:
  port: 1180
harbor_admin_password: binghe123
###并把https注释掉，不然在安装的时候会报错：ERROR:root:Error: The protocol is https but attribute ssl_cert is not set
#https:
  #port: 443
  #certificate: /your/certificate/path
  #private_key: /your/private/key/path
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;（2）修改daemon.json文件&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;修改/etc/docker/daemon.json文件，没有的话就创建，在/etc/docker/daemon.json文件中添加如下内容。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;[root@binghe~]# cat /etc/docker/daemon.json
{
  &quot;registry-mirrors&quot;: [&quot;https://zz3sblpi.mirror.aliyuncs.com&quot;],
  &quot;insecure-registries&quot;:[&quot;192.168.175.101:1180&quot;]
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;也可以在服务器上使用 &lt;strong&gt;ip addr&lt;/strong&gt; 命令查看本机所有的IP地址段，将其配置到/etc/docker/daemon.json文件中。这里，我配置后的文件内容如下所示。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;{
    &quot;registry-mirrors&quot;: [&quot;https://zz3sblpi.mirror.aliyuncs.com&quot;],
    &quot;insecure-registries&quot;:[&quot;192.168.175.0/16&quot;,&quot;172.17.0.0/16&quot;, &quot;172.18.0.0/16&quot;, &quot;172.16.29.0/16&quot;, &quot;192.168.175.101:1180&quot;]
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;4安装并启动harbor&quot;&gt;4.安装并启动harbor&lt;/h3&gt;
&lt;p&gt;配置完成后，输入如下命令即可安装并启动Harbor&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;[root@binghe harbor]# ./install.sh 
&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;5登录harbor并添加账户&quot;&gt;5.登录Harbor并添加账户&lt;/h3&gt;
&lt;p&gt;安装成功后，在浏览器地址栏输入http://192.168.175.101:1180打开链接，如下图所示。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20200521004111497.jpg&quot; alt=&quot;在这里插入图片描述&quot;/&gt;&lt;/p&gt;
&lt;p&gt;输入用户名admin和密码binghe123，登录系统，如下图所示&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20200521004122673.jpg&quot; alt=&quot;在这里插入图片描述&quot;/&gt;&lt;/p&gt;
&lt;p&gt;接下来，我们选择用户管理，添加一个管理员账户，为后续打包Docker镜像和上传Docker镜像做准备。添加账户的步骤如下所示。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20200521004138579.jpg&quot; alt=&quot;在这里插入图片描述&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20200521004149568.jpg&quot; alt=&quot;在这里插入图片描述&quot;/&gt;&lt;/p&gt;
&lt;p&gt;此处填写的密码为Binghe123。&lt;/p&gt;
&lt;p&gt;点击确定后，如下所示。&lt;br/&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20200521004202656.jpg&quot; alt=&quot;在这里插入图片描述&quot;/&gt;&lt;/p&gt;
&lt;p&gt;此时，账户binghe还不是管理员，此时选中binghe账户，点击“设置为管理员”。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20200521004213623.jpg&quot; alt=&quot;在这里插入图片描述&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20200521004223621.jpg&quot; alt=&quot;在这里插入图片描述&quot;/&gt;&lt;/p&gt;
&lt;p&gt;此时，binghe账户就被设置为管理员了。到此，Harbor的安装就完成了。&lt;/p&gt;
&lt;h3 id=&quot;6修改harbor端口&quot;&gt;6.修改Harbor端口&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;如果安装Harbor后，大家需要修改Harbor的端口，可以按照如下步骤修改Harbor的端口，这里，我以将80端口修改为1180端口为例&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;（1）修改harbor.yml文件&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;cd harbor
vim harbor.yml
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;修改的配置项如下所示。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;hostname: 192.168.175.101
http:
  port: 1180
harbor_admin_password: binghe123
###并把https注释掉，不然在安装的时候会报错：ERROR:root:Error: The protocol is https but attribute ssl_cert is not set
#https:
  #port: 443
  #certificate: /your/certificate/path
  #private_key: /your/private/key/path
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;（2）修改docker-compose.yml文件&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;vim docker-compose.yml
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;修改的配置项如下所示。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;ports:
      - 1180:80
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;（3）修改config.yml文件&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;cd common/config/registry
vim config.yml
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;修改的配置项如下所示。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;realm: http://192.168.175.101:1180/service/token
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;（4）重启Docker&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;systemctl daemon-reload
systemctl restart docker.service
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;（5）重启Harbor&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;[root@binghe harbor]# docker-compose down
Stopping harbor-log ... done
Removing nginx             ... done
Removing harbor-portal     ... done
Removing harbor-jobservice ... done
Removing harbor-core       ... done
Removing redis             ... done
Removing registry          ... done
Removing registryctl       ... done
Removing harbor-db         ... done
Removing harbor-log        ... done
Removing network harbor_harbor
 
[root@binghe harbor]# ./prepare
prepare base dir is set to /mnt/harbor
Clearing the configuration file: /config/log/logrotate.conf
Clearing the configuration file: /config/nginx/nginx.conf
Clearing the configuration file: /config/core/env
Clearing the configuration file: /config/core/app.conf
Clearing the configuration file: /config/registry/root.crt
Clearing the configuration file: /config/registry/config.yml
Clearing the configuration file: /config/registryctl/env
Clearing the configuration file: /config/registryctl/config.yml
Clearing the configuration file: /config/db/env
Clearing the configuration file: /config/jobservice/env
Clearing the configuration file: /config/jobservice/config.yml
Generated configuration file: /config/log/logrotate.conf
Generated configuration file: /config/nginx/nginx.conf
Generated configuration file: /config/core/env
Generated configuration file: /config/core/app.conf
Generated configuration file: /config/registry/config.yml
Generated configuration file: /config/registryctl/env
Generated configuration file: /config/db/env
Generated configuration file: /config/jobservice/env
Generated configuration file: /config/jobservice/config.yml
loaded secret from file: /secret/keys/secretkey
Generated configuration file: /compose_location/docker-compose.yml
Clean up the input dir
 
[root@binghe harbor]# docker-compose up -d
Creating network &quot;harbor_harbor&quot; with the default driver
Creating harbor-log ... done
Creating harbor-db   ... done
Creating redis       ... done
Creating registry    ... done
Creating registryctl ... done
Creating harbor-core ... done
Creating harbor-jobservice ... done
Creating harbor-portal     ... done
Creating nginx             ... done
 
[root@binghe harbor]# docker ps -a
CONTAINER ID        IMAGE                                               COMMAND                  CREATED             STATUS                             PORTS
&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;安装jenkins（一般的做法）&quot;&gt;安装Jenkins（一般的做法）&lt;/h2&gt;
&lt;h3 id=&quot;1安装nfs（之前安装过的话，可以省略此步）&quot;&gt;1.安装nfs（之前安装过的话，可以省略此步）&lt;/h3&gt;
&lt;p&gt;使用 nfs 最大的问题就是写权限，可以使用 kubernetes 的 securityContext/runAsUser 指定 jenkins 容器中运行 jenkins 的用户 uid，以此来指定 nfs 目录的权限，让 jenkins 容器可写；也可以不限制，让所有用户都可以写。这里为了简单，就让所有用户可写了。&lt;/p&gt;
&lt;p&gt;如果之前已经安装过nfs，则这一步可以省略。找一台主机，安装 nfs，这里，我以在Master节点（binghe101服务器）上安装nfs为例。&lt;/p&gt;
&lt;p&gt;在命令行输入如下命令安装并启动nfs。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;yum install nfs-utils -y
systemctl start nfs-server
systemctl enable nfs-server
&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;2创建nfs共享目录&quot;&gt;2.创建nfs共享目录&lt;/h3&gt;
&lt;p&gt;在Master节点（binghe101服务器）上创建 &lt;code&gt;/opt/nfs/jenkins-data&lt;/code&gt;目录作为nfs的共享目录，如下所示。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;mkdir -p /opt/nfs/jenkins-data
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;接下来，编辑/etc/exports文件，如下所示。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;vim /etc/exports
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;在/etc/exports文件文件中添加如下一行配置。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;/opt/nfs/jenkins-data 192.168.175.0/24(rw,all_squash)
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;这里的 ip 使用 kubernetes node 节点的 ip 范围，后面的 &lt;code&gt;all_squash&lt;/code&gt; 选项会将所有访问的用户都映射成 nfsnobody 用户，不管你是什么用户访问，最终都会压缩成 nfsnobody，所以只要将 &lt;code&gt;/opt/nfs/jenkins-data&lt;/code&gt; 的属主改为 nfsnobody，那么无论什么用户来访问都具有写权限。&lt;/p&gt;
&lt;p&gt;这个选项在很多机器上由于用户 uid 不规范导致启动进程的用户不同，但是同时要对一个共享目录具有写权限时很有效。&lt;/p&gt;
&lt;p&gt;接下来，为 &lt;code&gt;/opt/nfs/jenkins-data&lt;/code&gt;目录授权，并重新加载nfs，如下所示。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;chown -R 1000 /opt/nfs/jenkins-data/
systemctl reload nfs-server
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;在K8S集群中任意一个节点上使用如下命令进行验证：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;showmount -e NFS_IP
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;如果能够看到 /opt/nfs/jenkins-data 就表示 ok 了。&lt;/p&gt;
&lt;p&gt;具体如下所示。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;[root@binghe101 ~]# showmount -e 192.168.175.101
Export list for 192.168.175.101:
/opt/nfs/jenkins-data 192.168.175.0/24

[root@binghe102 ~]# showmount -e 192.168.175.101
Export list for 192.168.175.101:
/opt/nfs/jenkins-data 192.168.175.0/24
&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;3创建pv&quot;&gt;3.创建PV&lt;/h3&gt;
&lt;p&gt;Jenkins 其实只要加载对应的目录就可以读取之前的数据，但是由于 deployment 无法定义存储卷，因此我们只能使用 StatefulSet。&lt;/p&gt;
&lt;p&gt;首先创建 pv，pv 是给 StatefulSet 使用的，每次 StatefulSet 启动都会通过 volumeClaimTemplates 这个模板去创建 pvc，因此必须得有 pv，才能供 pvc 绑定。&lt;/p&gt;
&lt;p&gt;创建jenkins-pv.yaml文件，文件内容如下所示。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-yaml&quot;&gt;apiVersion: v1
kind: PersistentVolume
metadata:
  name: jenkins
spec:
  nfs:
    path: /opt/nfs/jenkins-data
    server: 192.168.175.101
  accessModes: [&quot;ReadWriteOnce&quot;]
  capacity:
    storage: 1Ti
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;我这里给了 1T存储空间，可以根据实际配置。&lt;/p&gt;
&lt;p&gt;执行如下命令创建pv。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;kubectl apply -f jenkins-pv.yaml 
&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;4创建serviceaccount&quot;&gt;4.创建serviceAccount&lt;/h3&gt;
&lt;p&gt;创建service account，因为 jenkins 后面需要能够动态创建 slave，因此它必须具备一些权限。&lt;/p&gt;
&lt;p&gt;创建jenkins-service-account.yaml文件，文件内容如下所示。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-yaml&quot;&gt;apiVersion: v1
kind: ServiceAccount
metadata:
  name: jenkins

---
kind: Role
apiVersion: rbac.authorization.k8s.io/v1beta1
metadata:
  name: jenkins
rules:
  - apiGroups: [&quot;&quot;]
    resources: [&quot;pods&quot;]
    verbs: [&quot;create&quot;, &quot;delete&quot;, &quot;get&quot;, &quot;list&quot;, &quot;patch&quot;, &quot;update&quot;, &quot;watch&quot;]
  - apiGroups: [&quot;&quot;]
    resources: [&quot;pods/exec&quot;]
    verbs: [&quot;create&quot;, &quot;delete&quot;, &quot;get&quot;, &quot;list&quot;, &quot;patch&quot;, &quot;update&quot;, &quot;watch&quot;]
  - apiGroups: [&quot;&quot;]
    resources: [&quot;pods/log&quot;]
    verbs: [&quot;get&quot;, &quot;list&quot;, &quot;watch&quot;]
  - apiGroups: [&quot;&quot;]
    resources: [&quot;secrets&quot;]
    verbs: [&quot;get&quot;]

---
apiVersion: rbac.authorization.k8s.io/v1beta1
kind: RoleBinding
metadata:
  name: jenkins
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: jenkins
subjects:
  - kind: ServiceAccount
    name: jenkins
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;上述配置中，创建了一个 RoleBinding 和一个 ServiceAccount，并且将 RoleBinding 的权限绑定到这个用户上。所以，jenkins 容器必须使用这个 ServiceAccount 运行才行，不然 RoleBinding 的权限它将不具备。&lt;/p&gt;
&lt;p&gt;RoleBinding 的权限很容易就看懂了，因为 jenkins 需要创建和删除 slave，所以才需要上面这些权限。至于 secrets 权限，则是 https 证书。&lt;/p&gt;
&lt;p&gt;执行如下命令创建serviceAccount。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;kubectl apply -f jenkins-service-account.yaml 
&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;5安装jenkins&quot;&gt;5.安装Jenkins&lt;/h3&gt;
&lt;p&gt;创建jenkins-statefulset.yaml文件，文件内容如下所示。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-yaml&quot;&gt;apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: jenkins
  labels:
    name: jenkins
spec:
  selector:
    matchLabels:
      name: jenkins
  serviceName: jenkins
  replicas: 1
  updateStrategy:
    type: RollingUpdate
  template:
    metadata:
      name: jenkins
      labels:
        name: jenkins
    spec:
      terminationGracePeriodSeconds: 10
      serviceAccountName: jenkins
      containers:
        - name: jenkins
          image: docker.io/jenkins/jenkins:lts
          imagePullPolicy: IfNotPresent
          ports:
            - containerPort: 8080
            - containerPort: 32100
          resources:
            limits:
              cpu: 4
              memory: 4Gi
            requests:
              cpu: 4
              memory: 4Gi
          env:
            - name: LIMITS_MEMORY
              valueFrom:
                resourceFieldRef:
                  resource: limits.memory
                  divisor: 1Mi
            - name: JAVA_OPTS
              # value: -XX:+UnlockExperimentalVMOptions -XX:+UseCGroupMemoryLimitForHeap -XX:MaxRAMFraction=1 -XshowSettings:vm -Dhudson.slaves.NodeProvisioner.initialDelay=0 -Dhudson.slaves.NodeProvisioner.MARGIN=50 -Dhudson.slaves.NodeProvisioner.MARGIN0=0.85
              value: -Xmx$(LIMITS_MEMORY)m -XshowSettings:vm -Dhudson.slaves.NodeProvisioner.initialDelay=0 -Dhudson.slaves.NodeProvisioner.MARGIN=50 -Dhudson.slaves.NodeProvisioner.MARGIN0=0.85
          volumeMounts:
            - name: jenkins-home
              mountPath: /var/jenkins_home
          livenessProbe:
            httpGet:
              path: /login
              port: 8080
            initialDelaySeconds: 60
            timeoutSeconds: 5
            failureThreshold: 12 # ~2 minutes
          readinessProbe:
            httpGet:
              path: /login
              port: 8080
            initialDelaySeconds: 60
            timeoutSeconds: 5
            failureThreshold: 12 # ~2 minutes
  # pvc 模板，对应之前的 pv
  volumeClaimTemplates:
    - metadata:
        name: jenkins-home
      spec:
        accessModes: [&quot;ReadWriteOnce&quot;]
        resources:
          requests:
            storage: 1Ti
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;jenkins 部署时需要注意它的副本数，你的副本数有多少就要有多少个 pv，同样，存储会有多倍消耗。这里我只使用了一个副本，因此前面也只创建了一个 pv。&lt;/p&gt;
&lt;p&gt;使用如下命令安装Jenkins。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;kubectl apply -f jenkins-statefulset.yaml 
&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;6创建service&quot;&gt;6.创建Service&lt;/h3&gt;
&lt;p&gt;创建jenkins-service.yaml文件，文件内容如下所示。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-yaml&quot;&gt;apiVersion: v1
kind: Service
metadata:
  name: jenkins
spec:
  # type: LoadBalancer
  selector:
    name: jenkins
  # ensure the client ip is propagated to avoid the invalid crumb issue when using LoadBalancer (k8s &amp;gt;=1.7)
  #externalTrafficPolicy: Local
  ports:
    - name: http
      port: 80
      nodePort: 31888
      targetPort: 8080
      protocol: TCP
    - name: jenkins-agent
      port: 32100
      nodePort: 32100
      targetPort: 32100
      protocol: TCP
  type: NodePort
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;使用如下命令安装Service。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;kubectl apply -f jenkins-service.yaml 
&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;7安装-ingress&quot;&gt;7.安装 ingress&lt;/h3&gt;
&lt;p&gt;jenkins 的 web 界面需要从集群外访问，这里我们选择的是使用 ingress。创建jenkins-ingress.yaml文件，文件内容如下所示。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-yaml&quot;&gt;apiVersion: extensions/v1beta1
kind: Ingress
metadata:
  name: jenkins
spec:
  rules:
    - http:
        paths:
          - path: /
            backend:
              serviceName: jenkins
              servicePort: 31888
      host: jekins.binghe.com
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;这里，需要注意的是host必须配置为域名或者主机名，否则会报错，如下所示。&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;The Ingress &quot;jenkins&quot; is invalid: spec.rules[0].host: Invalid value: &quot;192.168.175.101&quot;: must be a DNS name, not an IP address
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;使用如下命令安装ingress。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;kubectl apply -f jenkins-ingress.yaml 
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;最后，由于我这里使用的是虚拟机来搭建相关的环境，在本机访问虚拟机映射的jekins.binghe.com时，需要配置本机的hosts文件，在本机的hosts文件中加入如下配置项。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;192.168.175.101 jekins.binghe.com
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;注意：在Windows操作系统中，hosts文件所在的目录如下。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;C:\Windows\System32\drivers\etc
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;接下来，就可以在浏览器中通过链接：&lt;a href=&quot;http://jekins.binghe.com:31888&quot;&gt;http://jekins.binghe.com:31888&lt;/a&gt; 来访问Jekins了。&lt;/p&gt;
&lt;h2 id=&quot;物理机安装svn&quot;&gt;物理机安装SVN&lt;/h2&gt;
&lt;p&gt;这里，以在Master节点（binghe101服务器）上安装SVN为例。&lt;/p&gt;
&lt;h3 id=&quot;1使用yum安装svn&quot;&gt;1.使用yum安装SVN&lt;/h3&gt;
&lt;p&gt;在命令行执行如下命令安装SVN。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;yum -y install subversion 
&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;2创建svn库&quot;&gt;2.创建SVN库&lt;/h3&gt;
&lt;p&gt;依次执行如下命令。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;#创建/data/svn
mkdir -p /data/svn 
#初始化svn
svnserve -d -r /data/svn
#创建代码仓库
svnadmin create /data/svn/test
&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;3配置svn&quot;&gt;3.配置SVN&lt;/h3&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;mkdir /data/svn/conf
cp /data/svn/test/conf/* /data/svn/conf/
cd /data/svn/conf/
[root@binghe101 conf]# ll
总用量 20
-rw-r--r-- 1 root root 1080 5月  12 02:17 authz
-rw-r--r-- 1 root root  885 5月  12 02:17 hooks-env.tmpl
-rw-r--r-- 1 root root  309 5月  12 02:17 passwd
-rw-r--r-- 1 root root 4375 5月  12 02:17 svnserve.conf
&lt;/code&gt;
&lt;/pre&gt;
&lt;ul&gt;&lt;li&gt;配置authz文件，&lt;/li&gt;
&lt;/ul&gt;&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;vim authz
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;配置后的内容如下所示。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;[aliases]
# joe = /C=XZ/ST=Dessert/L=Snake City/O=Snake Oil, Ltd./OU=Research Institute/CN=Joe Average

[groups]
# harry_and_sally = harry,sally
# harry_sally_and_joe = harry,sally,&amp;amp;joe
SuperAdmin = admin
binghe = admin,binghe

# [/foo/bar]
# harry = rw
# &amp;amp;joe = r
# * =

# [repository:/baz/fuz]
# @harry_and_sally = rw
# * = r

[test:/]
@SuperAdmin=rw
@binghe=rw
&lt;/code&gt;
&lt;/pre&gt;
&lt;ul&gt;&lt;li&gt;配置passwd文件&lt;/li&gt;
&lt;/ul&gt;&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;vim passwd
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;配置后的内容如下所示。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;[users]
# harry = harryssecret
# sally = sallyssecret
admin = admin123
binghe = binghe123
&lt;/code&gt;
&lt;/pre&gt;
&lt;ul&gt;&lt;li&gt;配置 svnserve.conf&lt;/li&gt;
&lt;/ul&gt;&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;vim svnserve.conf
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;配置后的文件如下所示。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;### This file controls the configuration of the svnserve daemon, if you
### use it to allow access to this repository.  (If you only allow
### access through http: and/or file: URLs, then this file is
### irrelevant.)

### Visit http://subversion.apache.org/ for more information.

[general]
### The anon-access and auth-access options control access to the
### repository for unauthenticated (a.k.a. anonymous) users and
### authenticated users, respectively.
### Valid values are &quot;write&quot;, &quot;read&quot;, and &quot;none&quot;.
### Setting the value to &quot;none&quot; prohibits both reading and writing;
### &quot;read&quot; allows read-only access, and &quot;write&quot; allows complete 
### read/write access to the repository.
### The sample settings below are the defaults and specify that anonymous
### users have read-only access to the repository, while authenticated
### users have read and write access to the repository.
anon-access = none
auth-access = write
### The password-db option controls the location of the password
### database file.  Unless you specify a path starting with a /,
### the file's location is relative to the directory containing
### this configuration file.
### If SASL is enabled (see below), this file will NOT be used.
### Uncomment the line below to use the default password file.
password-db = /data/svn/conf/passwd
### The authz-db option controls the location of the authorization
### rules for path-based access control.  Unless you specify a path
### starting with a /, the file's location is relative to the
### directory containing this file.  The specified path may be a
### repository relative URL (^/) or an absolute file:// URL to a text
### file in a Subversion repository.  If you don't specify an authz-db,
### no path-based access control is done.
### Uncomment the line below to use the default authorization file.
authz-db = /data/svn/conf/authz
### The groups-db option controls the location of the file with the
### group definitions and allows maintaining groups separately from the
### authorization rules.  The groups-db file is of the same format as the
### authz-db file and should contain a single [groups] section with the
### group definitions.  If the option is enabled, the authz-db file cannot
### contain a [groups] section.  Unless you specify a path starting with
### a /, the file's location is relative to the directory containing this
### file.  The specified path may be a repository relative URL (^/) or an
### absolute file:// URL to a text file in a Subversion repository.
### This option is not being used by default.
# groups-db = groups
### This option specifies the authentication realm of the repository.
### If two repositories have the same authentication realm, they should
### have the same password database, and vice versa.  The default realm
### is repository's uuid.
realm = svn
### The force-username-case option causes svnserve to case-normalize
### usernames before comparing them against the authorization rules in the
### authz-db file configured above.  Valid values are &quot;upper&quot; (to upper-
### case the usernames), &quot;lower&quot; (to lowercase the usernames), and
### &quot;none&quot; (to compare usernames as-is without case conversion, which
### is the default behavior).
# force-username-case = none
### The hooks-env options specifies a path to the hook script environment 
### configuration file. This option overrides the per-repository default
### and can be used to configure the hook script environment for multiple 
### repositories in a single file, if an absolute path is specified.
### Unless you specify an absolute path, the file's location is relative
### to the directory containing this file.
# hooks-env = hooks-env

[sasl]
### This option specifies whether you want to use the Cyrus SASL
### library for authentication. Default is false.
### Enabling this option requires svnserve to have been built with Cyrus
### SASL support; to check, run 'svnserve --version' and look for a line
### reading 'Cyrus SASL authentication is available.'
# use-sasl = true
### These options specify the desired strength of the security layer
### that you want SASL to provide. 0 means no encryption, 1 means
### integrity-checking only, values larger than 1 are correlated
### to the effective key length for encryption (e.g. 128 means 128-bit
### encryption). The values below are the defaults.
# min-encryption = 0
# max-encryption = 256
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;接下来，将/data/svn/conf目录下的svnserve.conf文件复制到/data/svn/test/conf/目录下。如下所示。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;[root@binghe101 conf]# cp /data/svn/conf/svnserve.conf /data/svn/test/conf/
cp：是否覆盖'/data/svn/test/conf/svnserve.conf'？ y
&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;4启动svn服务&quot;&gt;4.启动SVN服务&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;（1）创建svnserve.service服务&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;创建svnserve.service文件&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;vim /usr/lib/systemd/system/svnserve.service
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;文件的内容如下所示。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;[Unit]
Description=Subversion protocol daemon
After=syslog.target network.target
Documentation=man:svnserve(8)

[Service]
Type=forking
EnvironmentFile=/etc/sysconfig/svnserve
#ExecStart=/usr/bin/svnserve --daemon --pid-file=/run/svnserve/svnserve.pid $OPTIONS
ExecStart=/usr/bin/svnserve --daemon $OPTIONS
PrivateTmp=yes

[Install]
WantedBy=multi-user.target
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;接下来执行如下命令使配置生效。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;systemctl daemon-reload
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;命令执行成功后，修改 /etc/sysconfig/svnserve 文件。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;vim /etc/sysconfig/svnserve 
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;修改后的文件内容如下所示。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;# OPTIONS is used to pass command-line arguments to svnserve.
# 
# Specify the repository location in -r parameter:
OPTIONS=&quot;-r /data/svn&quot;
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;（2）启动SVN&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;首先查看SVN状态，如下所示。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;[root@itence10 conf]# systemctl status svnserve.service
● svnserve.service - Subversion protocol daemon
   Loaded: loaded (/usr/lib/systemd/system/svnserve.service; disabled; vendor preset: disabled)
   Active: inactive (dead)
     Docs: man:svnserve(8)
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;可以看到，此时SVN并没有启动，接下来，需要启动SVN。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;systemctl start svnserve.service
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;设置SVN服务开机自启动。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;systemctl enable svnserve.service
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;接下来，就可以下载安装TortoiseSVN，输入链接svn://192.168.0.10/test 并输入用户名binghe，密码binghe123来连接SVN了。&lt;/p&gt;
&lt;h2 id=&quot;物理机安装jenkins&quot;&gt;物理机安装Jenkins&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;注意：安装Jenkins之前需要安装JDK和Maven，我这里同样将Jenkins安装在Master节点（binghe101服务器）。&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&quot;1启用jenkins库&quot;&gt;1.启用Jenkins库&lt;/h3&gt;
&lt;p&gt;运行以下命令以下载repo文件并导入GPG密钥：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;wget -O /etc/yum.repos.d/jenkins.repo http://pkg.jenkins-ci.org/redhat-stable/jenkins.repo
rpm --import https://jenkins-ci.org/redhat/jenkins-ci.org.key
&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;2安装jenkins&quot;&gt;2.安装Jenkins&lt;/h3&gt;
&lt;p&gt;执行如下命令安装Jenkis。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;yum install jenkins
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;接下来，修改Jenkins默认端口，如下所示。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;vim /etc/sysconfig/jenkins
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;修改后的两项配置如下所示。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;JENKINS_JAVA_CMD=&quot;/usr/local/jdk1.8.0_212/bin/java&quot;
JENKINS_PORT=&quot;18080&quot;
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;此时，已经将Jenkins的端口由8080修改为18080&lt;/p&gt;
&lt;h3 id=&quot;3启动jenkins&quot;&gt;3.启动Jenkins&lt;/h3&gt;
&lt;p&gt;在命令行输入如下命令启动Jenkins。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;systemctl start jenkins
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;配置Jenkins开机自启动。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;systemctl enable jenkins
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;查看Jenkins的运行状态。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;[root@itence10 ~]# systemctl status jenkins
● jenkins.service - LSB: Jenkins Automation Server
   Loaded: loaded (/etc/rc.d/init.d/jenkins; generated)
   Active: active (running) since Tue 2020-05-12 04:33:40 EDT; 28s ago
     Docs: man:systemd-sysv-generator(8)
    Tasks: 71 (limit: 26213)
   Memory: 550.8M
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;说明，Jenkins启动成功。&lt;/p&gt;
&lt;h2 id=&quot;配置jenkins运行环境&quot;&gt;配置Jenkins运行环境&lt;/h2&gt;
&lt;h3 id=&quot;1登录jenkins&quot;&gt;1.登录Jenkins&lt;/h3&gt;
&lt;p&gt;首次安装后，需要配置Jenkins的运行环境。首先，在浏览器地址栏访问链接http://192.168.0.10:18080，打开Jenkins界面。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20200521004241581.jpg&quot; alt=&quot;在这里插入图片描述&quot;/&gt;&lt;/p&gt;
&lt;p&gt;根据提示使用如下命令到服务器上找密码值，如下所示。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;[root@binghe101 ~]# cat /var/lib/jenkins/secrets/initialAdminPassword
71af861c2ab948a1b6efc9f7dde90776
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;将密码71af861c2ab948a1b6efc9f7dde90776复制到文本框，点击继续。会跳转到自定义Jenkins页面，如下所示。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20200521004255645.jpg&quot; alt=&quot;在这里插入图片描述&quot;/&gt;&lt;/p&gt;
&lt;p&gt;这里，可以直接选择“安装推荐的插件”。之后会跳转到一个安装插件的页面，如下所示。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20200521004304953.jpg&quot; alt=&quot;在这里插入图片描述&quot;/&gt;&lt;/p&gt;
&lt;p&gt;此步骤可能有下载失败的情况，可直接忽略。&lt;/p&gt;
&lt;h3 id=&quot;2安装插件&quot;&gt;2.安装插件&lt;/h3&gt;
&lt;p&gt;需要安装的插件&lt;/p&gt;
&lt;ul readability=&quot;0&quot;&gt;&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;Kubernetes Cli Plugin：该插件可直接在Jenkins中使用kubernetes命令行进行操作。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;Kubernetes plugin： 使用kubernetes则需要安装该插件&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;Kubernetes Continuous Deploy Plugin：kubernetes部署插件，可根据需要使用&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;还有更多的插件可供选择，可点击 系统管理-&amp;gt;管理插件进行管理和添加，安装相应的Docker插件、SSH插件、Maven插件。其他的插件可以根据需要进行安装。如下图所示。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/2020052100431619.jpg&quot; alt=&quot;在这里插入图片描述&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20200521004326575.jpg&quot; alt=&quot;在这里插入图片描述&quot;/&gt;&lt;/p&gt;
&lt;h3 id=&quot;3配置jenkins&quot;&gt;3.配置Jenkins&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;（1）配置JDK和Maven&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;在Global Tool Configuration中配置JDK和Maven，如下所示，打开Global Tool Configuration界面。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20200521004340563.jpg&quot; alt=&quot;在这里插入图片描述&quot;/&gt;&lt;/p&gt;
&lt;p&gt;接下来就开始配置JDK和Maven了。&lt;/p&gt;
&lt;p&gt;由于我在服务器上将Maven安装在/usr/local/maven-3.6.3目录下，所以，需要在“Maven 配置”中进行配置，如下图所示。&lt;br/&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20200521004351904.jpg&quot; alt=&quot;在这里插入图片描述&quot;/&gt;&lt;/p&gt;
&lt;p&gt;接下来，配置JDK，如下所示。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/2020052100440247.jpg&quot; alt=&quot;在这里插入图片描述&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;注意：不要勾选“Install automatically”&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;接下来，配置Maven，如下所示。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20200521004411716.jpg&quot; alt=&quot;在这里插入图片描述&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;注意：不要勾选“Install automatically”&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;（2）配置SSH&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;进入Jenkins的Configure System界面配置SSH，如下所示。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20200521004422607.jpg&quot; alt=&quot;在这里插入图片描述&quot;/&gt;&lt;/p&gt;
&lt;p&gt;找到 SSH remote hosts 进行配置。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20200521004432606.jpg&quot; alt=&quot;在这里插入图片描述&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20200521004445781.jpg&quot; alt=&quot;在这里插入图片描述&quot;/&gt;&lt;/p&gt;
&lt;p&gt;配置完成后，点击Check connection按钮，会显示 Successfull connection。如下所示。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/202005210044581.jpg&quot; alt=&quot;在这里插入图片描述&quot;/&gt;&lt;/p&gt;
&lt;p&gt;至此，Jenkins的基本配置就完成了。&lt;/p&gt;
&lt;h2 id=&quot;写在最后&quot;&gt;写在最后&lt;/h2&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;如果觉得文章对你有点帮助，请微信搜索并关注「 冰河技术 」微信公众号，跟冰河学习各种编程技术。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;最后附上K8S最全知识图谱链接：&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.processon.com/view/link/5ac64532e4b00dc8a02f05eb?spm=a2c4e.10696291.0.0.6ec019a4bYSFIw#map&quot;&gt;https://www.processon.com/view/link/5ac64532e4b00dc8a02f05eb?spm=a2c4e.10696291.0.0.6ec019a4bYSFIw#map&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;祝大家在学习K8S时，少走弯路。&lt;/p&gt;
</description>
<pubDate>Thu, 21 May 2020 14:53:00 +0000</pubDate>
<dc:creator>冰河团队</dc:creator>
<og:description>写在前面 最近在 K8S 1.18.2 版本的集群上搭建DevOps环境，期间遇到了各种坑。目前，搭建环境的过程中出现的各种坑均已被填平，特此记录，并分享给大家！ 服务器规划 | IP | 主机名 |</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/binghe001/p/12934192.html</dc:identifier>
</item>
</channel>
</rss>