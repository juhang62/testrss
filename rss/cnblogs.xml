<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="css/feed.xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/" xmlns:og="http://ogp.me/ns#">
<channel>
<atom:link rel="self" href="http://192.168.1.4/fivefilters/makefulltextfeed.php?url=feed.cnblogs.com%2Fblog%2Fsitehome%2Frss&amp;max=10&amp;links=preserve&amp;exc=" />
<atom:link rel="alternate" title="Source URL" href="http://feed.cnblogs.com/blog/sitehome/rss" />
<atom:link rel="related" title="Subscribe to feed" href="http://www.subtome.com/#/subscribe?feeds=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed.cnblogs.com%252Fblog%252Fsitehome%252Frss%26max%3D10%26links%3Dpreserve%26exc%3D&amp;back=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed.cnblogs.com%252Fblog%252Fsitehome%252Frss%26max%3D10%26links%3Dpreserve%26exc%3D" />
<title>博客园_首页</title>
<link></link>
<description>代码改变世界</description>
<item>
<title>Js~对键值对操作 - 张占岭</title>
<link>http://www.cnblogs.com/lori/p/13488618.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/lori/p/13488618.html</guid>
<description>&lt;p&gt;键值对主要是面向对象语言里的字典，或者叫哈希表，它通过键(key)可以直接访问到值(value)，所以它查找的时间复杂度是O(1)，即一次查找即可找到目标；在.net里有Dictionary，而在java里有HashMap等结构来实现，而在NoSQL里也有redis为代表的键值存储数据库；而在js里好像没有一种哈希的数据结构，不过我们可以借助对象的概念来实现，键相当于对象里的属性，而值相当于属性的值。&lt;/p&gt;

&lt;pre&gt;
&lt;code&gt;var color={};
//动态添加键值对象
color[&quot;red&quot;]=1;
color[&quot;blue&quot;]=2;
&lt;/code&gt;
&lt;/pre&gt;

&lt;pre&gt;
&lt;code&gt;console.log(color.red);
console.log(color[&quot;blue&quot;]);
&lt;/code&gt;
&lt;/pre&gt;

&lt;pre&gt;
&lt;code&gt;Object.keys(color).forEach(function(key){
     console.log(key,obj[key]);
});
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/118538/202008/118538-20200812084219012-213865261.png&quot; alt=&quot;pic&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
</description>
<pubDate>Wed, 12 Aug 2020 00:42:00 +0000</pubDate>
<dc:creator>张占岭</dc:creator>
<og:description>键值对主要是面向对象语言里的字典，或者叫哈希表，它通过键(key)可以直接访问到值(value)，所以它查找的时间复杂度是O(1)，即一次查找即可找到目标；在.net里有Dictionary，而在ja</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/lori/p/13488618.html</dc:identifier>
</item>
<item>
<title>PowerJob 的自实现高可用方案，妙妙妙！ - 削微寒</title>
<link>http://www.cnblogs.com/xueweihan/p/13477189.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/xueweihan/p/13477189.html</guid>
<description>&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;本文适合有 Java 基础知识的人群&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/759200/202008/759200-20200811174153483-2110529700.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;作者：HelloGitHub-&lt;strong&gt;Salieri&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;HelloGitHub 推出的&lt;a href=&quot;https://github.com/HelloGitHub-Team/Article&quot; title=&quot;《讲解开源项目》&quot;&gt;《讲解开源项目》&lt;/a&gt;系列。&lt;/p&gt;
&lt;h2 id=&quot;碎碎念&quot;&gt;碎碎念&lt;/h2&gt;
&lt;p&gt;高可用放到今天已经不是一个新颖的词汇了，怎么实现高可用大家也已经了然于心。多实例部署 + 服务注册 + 服务发现这一套组合拳打下来，实现高可用那还不是分分钟的事情。所以很多人看到 PowerJob 的介绍页面中写了&lt;strong&gt;任意组件支持集群部署以实现高可用&lt;/strong&gt;，想当然的以为也是走了上述的那套流程。然后看到系统依赖组件时，发现......emmm...... Zookeeper 呢？没看着。那找找 Nacos ？emmm......也没找着......不仅没找着，还发现文档中明明白白的写着，&lt;strong&gt;最小依赖仅为关系型数据库&lt;/strong&gt;。许多用户看到这里就有点百思不得其解了，正常来讲都会有两个疑惑。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/759200/202008/759200-20200811174206230-461704799.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;首先，为什么不用注册中心呢？&lt;/p&gt;
&lt;p&gt;要做到分布式环境下的高可用，肯定是需要服务注册、服务发现这样的概念的。没有外部注册中心，说白了就是自己去实现了一套类似的机制。那为什么要怎么做呢？&lt;/p&gt;
&lt;p&gt;其实答案很简单——成本。这个成本指的是用户的接入成本。对于一个需要部署的重型开源项目来说，每少一个外部依赖，就多一份潜在的用户。额外的系统依赖代表着额外的技术栈和额外的维护成本，如果企业本身没有这一套技术体系（比如没用到 zookeeper），而 PowerJob 又强依赖 zookeeper，那大概率只能说再见喽～&lt;/p&gt;
&lt;p&gt;第一个问题解决了，接下来进入第二个问题～&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/759200/202008/759200-20200811174212090-1262721412.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h2 id=&quot;简单高可用&quot;&gt;简单高“可用”&lt;/h2&gt;
&lt;p&gt;PowerJob 系统中的基础组件为调度服务器 server 和执行器 worker，server 负责调度定时任务，并派发到 worker 执行，是一个典型的 C/S 架构。&lt;/p&gt;
&lt;p&gt;C/S 架构下，如果目标是 server 和 client 可以相互联通的“高可用”，那么实现起来其实非常容易。&lt;/p&gt;
&lt;p&gt;首先，启动多个 server 应用实例，集群部署。然后将多个 server 的 IP 地址统统填入 worker 的配置文件中，worker 启动时，随机找一个 IP 进行连接，失败则重试。一旦成功连接到某一台 server，就开始上报自己的地址信息。server 通过持有这个信息也可以和 worker 进行通讯。如此一来，一个最简单版本的“高可用”集群就搭建完成了。但是......它真的可用吗？&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/759200/202008/759200-20200811174218071-918137946.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;答案显然是否定的（否则也不会有这篇文章了是不是～）。以上方案主要存在两个问题：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;任务调度需要保证唯一性，即某个任务在某一个时刻只能被一台机器调度，否则就会导致重复执行。而前文提及的方案中，每一台 server 都是完全等价的，因此只能依靠分布式锁来保证唯一性，即抢到锁的 server 执行调度，其他 server 只能充当战地记者，默默地边缘 OB。这种方案下，无论部署多少台 server，系统整体的调度性能其实是固定的，多实例部署只能做到高可用，而不能做到高性能。&lt;/li&gt;
&lt;li&gt;server 无法持有完整的 worker 集群信息。PowerJob 的定位是&lt;strong&gt;任务调度中间件&lt;/strong&gt;，旨在为企业下各部门各业务线提供精准的调度和分布式计算能力。因此肯定会有集群分组的概念，就像 RocketMQ 中存在 ProducerGroup 和 ConsumerGroup 一样，PowerJob 有着 AppName 的概念。一个 AppName 逻辑上对应了某个应用下的一组任务，物理上对应了这个应用所部署的集群。为了便于 server 统一管理以及一些额外功能的实现（分布式计算），server 持有某一个 AppName 下完整的集群信息是一个强诉求，而前文提及的“瞎猫撞上死耗子”式方案，显然没办法做到这一点。&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;基于以上两点，征途是星辰大海的 PowerJob 需要探索出一种更合理、更强大的高可用架构。&lt;/p&gt;
&lt;h2 id=&quot;分组隔离&quot;&gt;分组隔离&lt;/h2&gt;
&lt;p&gt;其实根据前面遇到的问题，这一套机制的雏形也差不多出来了。&lt;/p&gt;
&lt;p&gt;server 既然需要持有某一个分组下完整的集群信息，那么可以顺其自然的想到，能不能让某一个分组的所有 worker 都连接到某一台 server 呢？一旦某个分组下所有机器全部连接到了某一台 server，那么其实这就形成了一个小型的子系统。虽然整个 PowerJob 系统中存在着多台 server 和多个 worker 集群，但是对于这个分组的运行来说，只要有这个分组对应的 worker 集群以及它们连接的那一台 server 就够了。那么在这个小型“子系统”内部，只存在着一台 server，也就不存在重复调度问题了（server 只调度连接到它的 AppName 下面的任务就能实现这一点）。&lt;/p&gt;
&lt;p&gt;所以，经过一层层的剥丝抽茧，问题已经转化为了：&lt;strong&gt;如何让某个分组下的所有机器都连接到同一台 server 上去呢？&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;看到这个问题的时候，相信很多人会有和我当时一样的想法，那就是：就这？&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/759200/202008/759200-20200811174228020-98463098.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;“让所有机器都连接到同一台 server 上去，那也太简单了吧，你只配置一个 IP 不就行了吗？”&lt;/p&gt;
&lt;p&gt;“配置一个 IP 怎么做高可用，怎么利用多台 server 资源？”&lt;/p&gt;
&lt;p&gt;“🤔好像有点道理，那就 hash(appName) 取余作为下标，这样就能保证同一个同一个分组下所有机器的初始 IP 相同，不同分组也能连接到不同的 server”&lt;/p&gt;
&lt;p&gt;“那，万一连接的 server 挂了怎么办？”&lt;/p&gt;
&lt;p&gt;“这好办，可以采取类似于解决哈希冲突的那个什么开放定址法，从挂掉的 server 下标开始，依次向后重试就行了，同一个分组集群内所有的机器都从某个下标依次向后重试，还是能连接到同一台 server 的”&lt;/p&gt;
&lt;p&gt;“🤔好像很有道理，哼，worker 选主也就不过如此，方案搞定，英雄联盟 启动！”&lt;/p&gt;
&lt;p&gt;正当我浴血奋战直指敌将首级时，画面...永远定格在了见血前的那一瞬。“正在尝试重新连接”几个大字映入眼帘，也把我带入了深深的沉思。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/759200/202008/759200-20200811174236046-1342870927.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;虽说每次玩游戏必骂腾讯那***的土豆服务器，但骂归骂，心里其实还是明白，大部分情况下都是自己网络波动导致游戏掉线（&lt;s&gt;谁叫我贪便宜办了个移动宽带呢，哎，雷电法王杨永信也就图一乐，真要戒网瘾还得看移动宽带&lt;/s&gt;）。&lt;/p&gt;
&lt;p&gt;嗯？自己的原因？网络波动？掉线？重连？这一连串词汇，把我拉回了刚刚设计的方案之中，然后给我当头一棒。一旦 worker 因为自己的网络波动导致它以为 server 不可用，而重新连接另一台 server，就会导致所有 worker 都连接同一台 server 这个约束被破坏......因此，这个方案自然也就是一个充满漏洞的不可行方案。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/759200/202008/759200-20200811174241896-611866715.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;在这之后的一周，可以说是支离破碎的一周。为了解决这个问题，我设计了无数个堪称“奇珍异兽”的方案，然后再一个个否定和枪毙。&lt;/p&gt;
&lt;p&gt;其实这段经历现在回过头来想特别搞笑，也有被自己蠢到。那无数个方案的失败原因其实都是同一个，也就是&lt;strong&gt;出发点错了&lt;/strong&gt;。我一直在尝试让 worker 决定连接哪台 server，却一而再再而三忽略 worker 永远不可能获取 server 真正的存活信息（比如心跳无法传达，可能是 worker 本身的网络故障），因此 &lt;strong&gt;worker 不应该决定连接哪台 server，这应该由 server 来决定。worker 能做的，只有服务发现&lt;/strong&gt;。想明白了这点，具体的方案也就应运而生了。&lt;/p&gt;
&lt;p&gt;PS：这个方案的诞生，我大概付出了1斤脑细胞的代价（不得不说这个减肥方法还蛮好的）...脑细胞不能白死，尽管那些奇奇怪怪得方案没有活到正式版本，但没有他们就无法通往真理的大门。为了表达纪念和“哀悼”之情，我将最终的设计命名为——V4：丧钟为谁鸣。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/759200/202008/759200-20200811174247553-1789021703.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h2 id=&quot;v4：丧钟为谁鸣&quot;&gt;V4：丧钟为谁鸣&lt;/h2&gt;
&lt;blockquote readability=&quot;7&quot;&gt;
&lt;p&gt;想明白了不能由 Worker 发起 Server 的重新选举，这个问题就基本上解决了......由于篇幅原因以及网上已经有小伙伴写了这一块源码分析的博客，我这里就不重复“造轮子”了，在这里主要讲一下设计思路。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;就像前面说的那样，worker 因为没办法获取 server 的准确状态，所以不能由 worker 来决定连接哪一台 server。因此，worker 需要做的，只是&lt;strong&gt;服务发现&lt;/strong&gt;。即定时使用 HTTP 请求任意一台 server，请求获取当前该分组（appName）对应的 server。&lt;/p&gt;
&lt;p&gt;而 server 收到来自 worker 的服务发现请求后，其实就是进行了一场小型的分布式选主：server 依赖的数据库中存在着 server_info 表，其中记录了每一个分组（appName）所对应的 server 信息。如果该 server 发现表中存在记录，那就说明该 worker 集群中已经有别的 worker 事先请求 server 进行选举，那么此时只需要发送 PING 请求检测该 server 是否存活。如果发现该 server 存活，那么直接返回该 server 的信息作为该分组的 server。否则就完成篡位，将自己的信息写入数据库表中，成为该分组的 server。&lt;/p&gt;
&lt;p&gt;细心的小伙伴可能又要问了？发送 PING 请求检测该 server 是否存活，不还是有和刚才一样的问题吗？请求不同，发送方和接收方都有可能出问题，凭什么认为是原先的 server 挂了呢？&lt;/p&gt;
&lt;p&gt;确实，在这个方案下，依旧没办法解决 server 到底挂没挂这个堪比“真假美猴王”的玄学问题。但是，这还重要吗？我们的目标是某个分组下所有的 worker 都连接到同一台 server，因此，即便产生那种误打误撞篡位的情况，在服务发现机制的加持下，整个集群最终还是会连接到同一台 server，完美实现我们的需求。&lt;/p&gt;
&lt;p&gt;至此，耗时 6 天，从原来的怀疑人生，到完美方案的落地实现，真是曲折～&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/759200/202008/759200-20200811174253681-370079560.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h2 id=&quot;最后&quot;&gt;最后&lt;/h2&gt;
&lt;p&gt;最后，贴上两位小伙伴贡献的源码分析文章，我亲自 check 过，没有质量问题（&lt;s&gt;这话说的我感觉自己好飘哈哈哈&lt;/s&gt;），请各位观众老爷放心查看～&lt;/p&gt;
&lt;p&gt;那么以上就是本篇文章全部的内容了～相信通过这篇文章和上篇文章，大家已经对 PowerJob 的调度层和高可用高性能架构有了一定的了解了。接下来就是下期预告环节了～&lt;/p&gt;
&lt;p&gt;为了保留神秘感，这次就选择不预告了（&lt;s&gt;才不会告诉你是我还没想好具体写什么&lt;/s&gt;）～&lt;/p&gt;
&lt;p&gt;所有惊喜，下期再见～&lt;/p&gt;
&lt;blockquote readability=&quot;1.5686274509804&quot;&gt;
&lt;p&gt;项目地址：&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/KFCFans/PowerJob&quot;&gt;https://github.com/KFCFans/PowerJob&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr/&gt;&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/759200/202008/759200-20200811174133674-930116231.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;关注公众号加入交流群（作者在 Java 群）&lt;/p&gt;
</description>
<pubDate>Wed, 12 Aug 2020 00:33:00 +0000</pubDate>
<dc:creator>削微寒</dc:creator>
<og:description>本文适合有 Java 基础知识的人群 作者：HelloGitHub-Salieri HelloGitHub 推出的《讲解开源项目》系列。 碎碎念 高可用放到今天已经不是一个新颖的词汇了，怎么实现高可用</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/xueweihan/p/13477189.html</dc:identifier>
</item>
<item>
<title>Aspnet Zero中使用Windows service (Topshelf)来承载Quartz.net任务 - Thinking110</title>
<link>http://www.cnblogs.com/FocusNet/p/13474785.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/FocusNet/p/13474785.html</guid>
<description>&lt;p&gt;网上有很多关于如何使用Topshelf创建ABP的Quartz windows服务，但很少(没有)有介绍如何配合Aspnet Zero使用的文章，本文记录集成过程，以供参考。&lt;/p&gt;
&lt;ol readability=&quot;19&quot;&gt;&lt;li readability=&quot;2&quot;&gt;
&lt;p&gt;在官方Aspnet Zero模板解决方案中建立Console类型的项目，并安装以下buget package:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Topshelf&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Abp.Quartz&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Abp.Castle.Log4Net&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Abp.AspnetCore&lt;/code&gt; (后面有用到)&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;添加引用&lt;code&gt;MyCompanyName.AbpZeroTemplate.Core&lt;/code&gt;和&lt;code&gt;MyCompanyName.AbpZeroTemplate.Core&lt;/code&gt;项目&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;最终引用如图：&lt;br/&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/28427/202008/28427-20200811115713876-1347830211.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;5&quot;&gt;
&lt;p&gt;创建Module文件,&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;添加相关DependsOn属性;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;abpZeroTemplateEntityFrameworkCoreModule.SkipDbSeed = true;&lt;/code&gt; 这里我们需要禁用数据库初始化动作，因为所有的初始化动作都在Host端完成;&lt;/li&gt;
&lt;li&gt;设置数据库连接字符串&lt;code&gt;Configuration.DefaultNameOrConnectionString = _appConfiguration.GetConnectionString( AbpZeroTemplateConsts.ConnectionStringName );&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;最终文件如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-csharp&quot;&gt;namespace MyCompanyName.AbpZeroTemplate.WinService
{
    [DependsOn(typeof(AbpZeroTemplateCoreModule),
        typeof(AbpZeroTemplateEntityFrameworkCoreModule),
        typeof(AbpQuartzModule)
        )]
    public class AbpZeroWinServiceModule : AbpModule
    {
        private readonly IConfigurationRoot _appConfiguration;

        public AbpZeroWinServiceModule(AbpZeroTemplateEntityFrameworkCoreModule abpZeroTemplateEntityFrameworkCoreModule)
        {
            abpZeroTemplateEntityFrameworkCoreModule.SkipDbSeed = true;

            _appConfiguration = AppConfigurations.Get(
                typeof(AbpZeroWinServiceModule).GetAssembly().GetDirectoryPathOrNull(),
                addUserSecrets: true
            );
        }

        public override void PreInitialize()
        {
            //Set default connection string
            Configuration.DefaultNameOrConnectionString = _appConfiguration.GetConnectionString(
                AbpZeroTemplateConsts.ConnectionStringName
            );
        }

        public override void Initialize()
        {
            this.IocManager.RegisterAssemblyByConvention(Assembly.GetExecutingAssembly());

        }
    }
}
&lt;/code&gt;
&lt;/pre&gt;&lt;/li&gt;
&lt;li readability=&quot;10&quot;&gt;
&lt;p&gt;修改Program.cs文件&lt;/p&gt;
&lt;ul readability=&quot;1&quot;&gt;&lt;li&gt;设置工作目录 &lt;code&gt;Directory.SetCurrentDirectory(currentDirectory);&lt;/code&gt;, 目的是为了保证工作在windows service时log文件存放目录正确，如果不设置, 工作在windows service时log文件将会存放在system32目录中&lt;/li&gt;
&lt;li readability=&quot;5&quot;&gt;&lt;strong&gt;注册IdentityRegistrar以及添加abp依赖&lt;/strong&gt;，这一步是必须的，否则会出现依赖错误：&lt;br/&gt;&lt;code&gt;Castle.MicroKernel.Handlers.HandlerException: 'Can't create component 'Portal.Authorization.Users.UserManager' as it has dependencies to be satisfied.&lt;/code&gt;&lt;br/&gt;添加abp依赖的同时我们同时添加log4net和插件支持.(注意路径)
&lt;pre&gt;
&lt;code class=&quot;language-csharp&quot;&gt;var services = new ServiceCollection();
IdentityRegistrar.Register(services);

services.AddAbp&amp;lt;AbpZeroWinServiceModule&amp;gt;(options =&amp;gt;
{
    //Configure Log4Net logging
    options.IocManager.IocContainer.AddFacility&amp;lt;LoggingFacility&amp;gt;(
        f =&amp;gt; f.UseAbpLog4Net().WithConfig(Path.Combine(currentDirectory, $&quot;log4net.config&quot;))
    );

    options.PlugInSources.AddFolder(Path.Combine(currentDirectory, &quot;Plugins&quot;), SearchOption.AllDirectories);
});
&lt;/code&gt;
&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;完整Program.cs代码如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-csharp&quot;&gt;class Program
{
    static void Main(string[] args)
    {
        var currentDirectory = typeof(Program).GetAssembly().GetDirectoryPathOrNull();
        // 设置工作目录. 保证工作在windows service时log文件存放目录正确
        // 如果不设置, 工作在windows service时log文件将会存放在system32目录中
        Directory.SetCurrentDirectory(currentDirectory);

        var services = new ServiceCollection();
        IdentityRegistrar.Register(services);
        
        services.AddAbp&amp;lt;AbpZeroWinServiceModule&amp;gt;(options =&amp;gt;
        {
            //Configure Log4Net logging
            options.IocManager.IocContainer.AddFacility&amp;lt;LoggingFacility&amp;gt;(
                f =&amp;gt; f.UseAbpLog4Net().WithConfig(Path.Combine(currentDirectory, $&quot;log4net.config&quot;))
            );

            options.PlugInSources.AddFolder(Path.Combine(currentDirectory, &quot;Plugins&quot;), SearchOption.AllDirectories);
        });

        HostFactory.Run(x =&amp;gt;
        {
            x.Service&amp;lt;AbpZeroWinService&amp;gt;(s =&amp;gt;
            {
                s.ConstructUsing(name =&amp;gt; new AbpZeroWinService());
                s.WhenStarted((tc, hostControl) =&amp;gt; tc.Start(hostControl));
                s.WhenStopped((tc, hostControl) =&amp;gt; tc.Stop(hostControl));
            });

            x.RunAsLocalSystem();
            x.StartAutomatically();

            x.SetDescription(&quot;ABP服务测试&quot;);
            x.SetDisplayName(&quot;ABPTestService&quot;);
            x.SetServiceName(&quot;ABPTestService&quot;);
        });
    }
}
&lt;/code&gt;
&lt;/pre&gt;&lt;/li&gt;
&lt;li readability=&quot;6&quot;&gt;
&lt;p&gt;启动ABP. Windows service启动时会调用&lt;code&gt;s.ConstructUsing(name =&amp;gt; new AbpZeroWinService());&lt;/code&gt;, 因此我们在&lt;code&gt;AbpZeroWinService&lt;/code&gt;中启动ABP.&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;创建&lt;code&gt;AbpZeroWinService&lt;/code&gt;类继承自&lt;code&gt;ServiceControl&lt;/code&gt;, 在&lt;code&gt;Start&lt;/code&gt;中初始化&lt;code&gt;AbpBootstrapper&lt;/code&gt;, 同时在停止&lt;code&gt;Stop&lt;/code&gt;中销毁&lt;code&gt;AbpBootstrapper&lt;/code&gt;. 代码如下：&lt;/li&gt;
&lt;/ul&gt;&lt;pre&gt;
&lt;code class=&quot;language-c#&quot;&gt;public class AbpZeroWinService : ServiceControl
{
    private AbpBootstrapper _bootstrapper;
    public bool Start(HostControl hostControl)
    {
        _bootstrapper = IocManager.Instance.Resolve&amp;lt;AbpBootstrapper&amp;gt;();
        _bootstrapper.Initialize();
        return true;
    }

    public bool Stop(HostControl hostControl)
    {
        _bootstrapper.Dispose();
        return true;
    }
}
&lt;/code&gt;
&lt;/pre&gt;&lt;/li&gt;
&lt;li readability=&quot;2&quot;&gt;
&lt;p&gt;quartz.net的配置&lt;code&gt;quartz.config&lt;/code&gt;中必须使用&lt;code&gt;AdoJobStore&lt;/code&gt;类型，并且使用和Host一样的Quartz数据库连接，这样才能实现在host上添加任务，最终由windows service来执行任务。&lt;br/&gt;(&lt;strong&gt;请在HostModule的&lt;code&gt;PreInitialize&lt;/code&gt;方法中禁用Job执行&lt;code&gt;Configuration.BackgroundJobs.IsJobExecutionEnabled = false;&lt;/code&gt;&lt;/strong&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;运行前确保Quartz.net数据库已建立，如何建立请参考Quartz.net官方文档&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;以上如有错误的地方请大家指正！ 如果更好的实现方式，也请分享一下。&lt;br/&gt;最后给出WindowService项目的源码，Aspnet Zero的项目自行解决。&lt;br/&gt;&lt;a href=&quot;https://files.cnblogs.com/files/FocusNet/MyCompanyName.AbpZeroTemplate.WinService.zip&quot;&gt;source code&lt;/a&gt;&lt;/p&gt;
</description>
<pubDate>Wed, 12 Aug 2020 00:01:00 +0000</pubDate>
<dc:creator>Thinking110</dc:creator>
<og:description>Aspnet Zero使用Windows service (Topshelf)来承载Quartz.net任务 网上有很多关于如何使用Topshelf创建ABP的Quartz windows服务，但很少</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/FocusNet/p/13474785.html</dc:identifier>
</item>
<item>
<title>数据源管理 | 分布式NoSQL系统，Cassandra集群管理 - 知了一笑</title>
<link>http://www.cnblogs.com/cicada-smile/p/13488035.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/cicada-smile/p/13488035.html</guid>
<description>&lt;p&gt;本文源码：&lt;a href=&quot;https://github.com/cicadasmile/data-manage-parent&quot;&gt;GitHub·点这里&lt;/a&gt; || &lt;a href=&quot;https://gitee.com/cicadasmile/data-manage-parent&quot;&gt;GitEE·点这里&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;1、基础描述&quot;&gt;1、基础描述&lt;/h2&gt;
&lt;p&gt;Cassandra是一套开源分布式NoSQL数据库系统。它最初由Facebook开发，用于储存收件箱等简单格式数据，此后，由于Cassandra良好的可扩展性，逐渐发展成为了一种流行的分布式结构化数据存储方案。&lt;/p&gt;
&lt;h2 id=&quot;2、特点分析&quot;&gt;2、特点分析&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;弹性可扩展性&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Cassandra是高度可扩展的;它允许添加更多的硬件以适应更多的客户和更多的数据根据要求，可以根据业务的数据流量轻松扩展集群规模。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;架构特点&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Cassandra可以基于分布式运行，并采用了许多容错机制。由于去中心化无主的策略，所以没有单点故障。可以做到不停服滚动升级。这是因为Cassandra可以支持多个节点的临时失效（取决于群集大小），对群集的整体性能影响可以忽略不计。并且Cassandra提供多地域容灾。Cassandra允许将数据复制到其他数据中心，并在多个地域保留多副本，十分适用于不能承担故障的关键业务，必须持续提供服务的应用程序。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;数据存储机制&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Cassandra适应所有可能的数据格式，包括：结构化，半结构化和非结构化。可以根据业务的需要动态地适应变化的数据结构，并且通过在多个数据中心之间复制数据，可以灵活地在需要时分发数据。有许多案例证明Cassandra可以在金融，医疗，物联网等领域使用。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;资源整合能力&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Cassandra可以很容易的跟其他开源组件做集成，其中包括Hadoop，Spark，Kafka，Solr等系列组件，成为大数据业务处理里面重要的一个角色。&lt;/p&gt;

&lt;h2 id=&quot;1、环境概览&quot;&gt;1、环境概览&lt;/h2&gt;
&lt;ul&gt;&lt;li&gt;jdk1.8&lt;/li&gt;
&lt;li&gt;apache-cassandra-3.11.7-bin.tar.gz&lt;/li&gt;
&lt;li&gt;centos7&lt;/li&gt;
&lt;li&gt;三台服务：hop01、hop02、hop03节点&lt;/li&gt;
&lt;/ul&gt;&lt;h2 id=&quot;2、安装包处理&quot;&gt;2、安装包处理&lt;/h2&gt;
&lt;pre&gt;
&lt;code&gt;tar -zxvf apache-cassandra-3.11.7-bin.tar.gz
mv apache-cassandra-3.11.7 cassandra3.11
&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;3、环境变量&quot;&gt;3、环境变量&lt;/h2&gt;
&lt;pre&gt;
&lt;code&gt;[root@hop01 opt]# vim /etc/profile

export CASSANDRA_HOME=/opt/cassandra3.11
export PATH=$PATH:$CASSANDRA_HOME/bin

[root@hop01 opt]# source /etc/profile
&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;4、创建目录&quot;&gt;4、创建目录&lt;/h2&gt;
&lt;pre&gt;
&lt;code&gt;# 数据目录
mkdir -p /data/cassandra/data
# 日志目录
mkdir -p /data/cassandra/log
&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;5、集群配置&quot;&gt;5、集群配置&lt;/h2&gt;
&lt;pre&gt;
&lt;code&gt;vim /opt/cassandra3.11/conf/cassandra.yaml

# 配置集群名称
cluster_name: 'CasCluster'
# 配置数据目录
data_file_directories:
     - /data/cassandra/data
# 配置日志目录
commitlog_directory: /data/cassandra/log
# 设置监听地址，当前服务IP
listen_address: 192.168.72.132
# 配置RPC服务
start_rpc: true
rpc_address: 192.168.72.132
# 配置集群节点
seed_provider:
    - class_name: org.apache.cassandra.locator.SimpleSeedProvider
      parameters:
          - seeds: &quot;192.168.72.132,192.168.72.138,192.168.72.139&quot;
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;将该配置分发到集群的每个节点，注意listen_address和rpc_address是节点自己的IP地址即可。&lt;/p&gt;
&lt;h2 id=&quot;6、启动集群&quot;&gt;6、启动集群&lt;/h2&gt;
&lt;pre&gt;
&lt;code&gt;# 集群下节点依次执行启动命令
cassandra -R
# 查看节点状态
nodetool status
&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;7、基础操作&quot;&gt;7、基础操作&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;进入命令行&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;cqlsh hop01
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;创建keyspace,并选择&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;CREATE KEYSPACE IF NOT EXISTS castest WITH REPLICATION = {'class': 'SimpleStrategy','replication_factor':3};

use castest ;
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;创建表，写入数据&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;CREATE TABLE user_info (id int, user_name varchar, PRIMARY KEY (id) );
INSERT INTO user_info (id,user_name) VALUES (1,'user01');
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;查询数据&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;select * from user_info ;
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;基于其他服务查看数据，可以看到数据已经在集群间做了同步过程:&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1691717/202008/1691717-20200811232054862-717716414.jpg&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;

&lt;h2 id=&quot;1、核心依赖&quot;&gt;1、核心依赖&lt;/h2&gt;
&lt;pre&gt;
&lt;code class=&quot;language-xml&quot;&gt;&amp;lt;dependency&amp;gt;
    &amp;lt;groupId&amp;gt;org.springframework.boot&amp;lt;/groupId&amp;gt;
    &amp;lt;artifactId&amp;gt;spring-boot-starter-web&amp;lt;/artifactId&amp;gt;
    &amp;lt;version&amp;gt;${spring.boot.version}&amp;lt;/version&amp;gt;
&amp;lt;/dependency&amp;gt;
&amp;lt;dependency&amp;gt;
    &amp;lt;groupId&amp;gt;org.springframework.boot&amp;lt;/groupId&amp;gt;
    &amp;lt;artifactId&amp;gt;spring-boot-starter-data-cassandra&amp;lt;/artifactId&amp;gt;
    &amp;lt;version&amp;gt;${spring.boot.version}&amp;lt;/version&amp;gt;
&amp;lt;/dependency&amp;gt;
&amp;lt;dependency&amp;gt;
    &amp;lt;groupId&amp;gt;org.springframework.boot&amp;lt;/groupId&amp;gt;
    &amp;lt;artifactId&amp;gt;spring-boot-starter-data-jpa&amp;lt;/artifactId&amp;gt;
    &amp;lt;version&amp;gt;${spring.boot.version}&amp;lt;/version&amp;gt;
&amp;lt;/dependency&amp;gt;
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;这里核心需要cassandra依赖和操作的API依赖。&lt;/p&gt;
&lt;h2 id=&quot;2、核心配置&quot;&gt;2、核心配置&lt;/h2&gt;
&lt;pre&gt;
&lt;code&gt;spring:
  data:
    cassandra:
      keyspace-name: castest
      contact-points: 192.168.72.138,192.168.72.132,192.168.72.139
      port: 9042
      cluster-name: CasCluster
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;keyspace-name&lt;/strong&gt;：类似关系型数据库的名称；&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;contact-points&lt;/strong&gt;：集群下节点的IP地址；&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;port&lt;/strong&gt;：默认端口；&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;cluster-name&lt;/strong&gt;：上述配置的集群名称；&lt;/p&gt;
&lt;h2 id=&quot;3、基于template命令&quot;&gt;3、基于Template命令&lt;/h2&gt;
&lt;p&gt;CassandraTemplate模板类，实现了一系列操作Cassandra数据库的基本方法，直接注入即可使用。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;@Repository
public class UserInfoTemplate {

    @Resource
    private CassandraTemplate cassandraTemplate ;

    // 查询全部数据
    public List&amp;lt;UserInfo&amp;gt; getList (){
        return cassandraTemplate.select(&quot;SELECT * FROM user_info&quot;,UserInfo.class) ;
    }

    // 添加数据
    public UserInfo insert (UserInfo userInfo){
        return cassandraTemplate.insert(userInfo) ;
    }

    // 根据主键查询
    public UserInfo selectOneById (Integer id){
        return cassandraTemplate.selectOneById(id,UserInfo.class) ;
    }

    // 修改数据
    public UserInfo update (UserInfo userInfo){
        return cassandraTemplate.update(userInfo) ;
    }

    // 删除数据
    public Boolean deleteById (Integer id){
        return cassandraTemplate.deleteById(id,UserInfo.class) ;
    }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;4、基于repository接口&quot;&gt;4、基于Repository接口&lt;/h2&gt;
&lt;p&gt;SpringBoot框架中定义的数据库访问核心接口。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;接口实现&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;import com.cassand.cluster.entity.UserInfo;
import org.springframework.data.repository.CrudRepository;

public interface UserInfoRepository extends CrudRepository&amp;lt;UserInfo,Integer&amp;gt; {

}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;接口用法&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;@Service
public class RepositoryService {

    @Resource
    private UserInfoRepository userInfoRepository ;

    // 保存
    public UserInfo save (UserInfo userInfo){
        return userInfoRepository.save(userInfo) ;
    }

    // 查询
    public UserInfo getById (Integer id){
        return userInfoRepository.findById(id).get() ;
    }

    // 修改
    public UserInfo update (UserInfo userInfo){
        // 主键ID存在的情况即为修改
        return userInfoRepository.save(userInfo);
    }

    // 删除
    public void deleteById (Integer id){
        userInfoRepository.deleteById(id);
    }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;5、实体表结构&quot;&gt;5、实体表结构&lt;/h2&gt;
&lt;p&gt;注意这里的注解是基于cassandra特定的一套。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;import org.springframework.data.cassandra.core.mapping.Column;
import org.springframework.data.cassandra.core.mapping.PrimaryKey;
import org.springframework.data.cassandra.core.mapping.Table;

@Table(&quot;user_info&quot;)
public class UserInfo {

    public UserInfo(Integer id, String userName) {
        this.id = id;
        this.userName = userName;
    }

    @PrimaryKey
    private Integer id ;

    @Column(value = &quot;user_name&quot;)
    private String userName ;
}
&lt;/code&gt;
&lt;/pre&gt;

&lt;pre&gt;
&lt;code&gt;GitHub·地址
https://github.com/cicadasmile/data-manage-parent
GitEE·地址
https://gitee.com/cicadasmile/data-manage-parent
&lt;/code&gt;
&lt;/pre&gt;
&lt;img width=&quot;100%&quot; height=&quot;400px&quot; src=&quot;https://img2020.cnblogs.com/blog/1691717/202008/1691717-20200811231321146-174169065.png&quot;/&gt;&lt;p&gt;&lt;strong&gt;推荐阅读：数据源管理系列&lt;/strong&gt;&lt;/p&gt;
</description>
<pubDate>Wed, 12 Aug 2020 00:01:00 +0000</pubDate>
<dc:creator>知了一笑</dc:creator>
<og:description>本文源码：GitHub&amp;amp;#183;点这里 || GitEE&amp;amp;#183;点这里 一、Cassandra简介 1、基础描述 Cassandra是一套开源分布式NoSQL数据库系统。它最初由</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/cicada-smile/p/13488035.html</dc:identifier>
</item>
<item>
<title>[源码解析] Flink UDAF 背后做了什么 - 罗西的思考</title>
<link>http://www.cnblogs.com/rossiXYZ/p/13460408.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/rossiXYZ/p/13460408.html</guid>
<description>&lt;p&gt;本文涉及到Flink SQL UDAF，Window 状态管理等部分，希望能起到抛砖引玉的作用，让大家可以借此深入了解这个领域。&lt;/p&gt;&lt;div id=&quot;cnblogs_post_body&quot; readability=&quot;292.61059965165&quot;&gt;


&lt;h2 id=&quot;0x00-摘要&quot;&gt;0x00 摘要&lt;/h2&gt;
&lt;p&gt;本文涉及到Flink SQL UDAF，Window 状态管理等部分，希望能起到抛砖引玉的作用，让大家可以借此深入了解这个领域。&lt;/p&gt;
&lt;h2 id=&quot;0x01-概念&quot;&gt;0x01 概念&lt;/h2&gt;
&lt;h3 id=&quot;11-概念&quot;&gt;1.1 概念&lt;/h3&gt;
&lt;p&gt;大家知道，Flink的自定义聚合函数（UDAF）可以将多条记录聚合成1条记录，这功能是通过accumulate方法来完成的，官方参考指出：&lt;/p&gt;
&lt;blockquote readability=&quot;7&quot;&gt;
&lt;p&gt;在系统运行过程中，底层runtime代码会把历史状态accumulator，和您指定的上游数据（支持任意数量，任意类型的数据）作为参数，一起发送给accumulate计算。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;但是实时计算还有一些特殊的场景，在此场景下，还需要提供merge方法才能完成。&lt;/p&gt;
&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;在实时计算中一些场景需要merge，例如session window。 由于实时计算具有out of order的特性，后输入的数据有可能位于2个原本分开的session中间，这样就把2个session合为1个session。此时，需要使用merge方法把多个accumulator合为1个accumulator。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&quot;12-疑问&quot;&gt;1.2 疑问&lt;/h3&gt;
&lt;p&gt;之前因为没亲身操作，所以一直忽略merge的特殊性。最近无意中看到了一个UDAF的实现，突然觉得有一个地方很奇怪，即 accumulate 和 merge 这两个函数不应该定义在一个类中。因为这是两个完全不同的处理方法。应该定义在两个不同的类中。&lt;/p&gt;
&lt;p&gt;比如用UDAF做word count，则：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;accumulate 是在一个task中累积数字，其实就相当于 map；&lt;/li&gt;
&lt;li&gt;merge 是把很多task的结果再次累积起来，就相当于 reduce；&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;然后又想出了一个问题：Flink是如何管理 UDAF的accumulator？其状态存在哪里？&lt;/p&gt;
&lt;p&gt;看起来应该是Flink在背后做了一些黑魔法，把这两个函数从一个类中拆分了。为了验证我们的推测，让我们从源码入手来看看这些问题：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;Flink SQL转换/执行计划生成阶段，如何处理在 &quot;同一个类中&quot; 的不同类型功能函数 accumulate 和 merge？&lt;/li&gt;
&lt;li&gt;Flink runtime 如何处理 merge？&lt;/li&gt;
&lt;li&gt;Flink runtime 如何处理 UDAF的accumulator的历史状态？&lt;/li&gt;
&lt;/ul&gt;&lt;h3 id=&quot;13-udaf示例代码&quot;&gt;1.3 UDAF示例代码&lt;/h3&gt;
&lt;p&gt;示例代码摘要如下 ：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;public class CountUdaf extends AggregateFunction&amp;lt;Long, CountUdaf.CountAccum&amp;gt; {
    //定义存放count UDAF状态的accumulator的数据的结构。
    public static class CountAccum {
        public long total;
    }
  
    //初始化count UDAF的accumulator。
    public CountAccum createAccumulator() {
        CountAccum acc = new CountAccum();
        acc.total = 0;
        return acc;
    }
  
    //accumulate提供了，如何根据输入的数据，更新count UDAF存放状态的accumulator。
    public void accumulate(CountAccum accumulator, Object iValue) {
        accumulator.total++;
    }

    public void merge(CountAccum accumulator, Iterable&amp;lt;CountAccum&amp;gt; its) {
        for (CountAccum other : its) {
            accumulator.total += other.total;
        }
    }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;0x02-批处理&quot;&gt;0x02 批处理&lt;/h2&gt;
&lt;p&gt;批处理相对简单，因为数据是有边界的，其逻辑比较清晰。&lt;/p&gt;
&lt;h3 id=&quot;21-代码&quot;&gt;2.1 代码&lt;/h3&gt;
&lt;p&gt;首先给出测试代码&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-scala&quot;&gt;val input = env.fromElements(WC(&quot;hello&quot;, 1), WC(&quot;hello&quot;, 1), WC(&quot;ciao&quot;, 1))

// register the DataSet as a view &quot;WordCount&quot;
tEnv.createTemporaryView(&quot;WordCount&quot;, input, 'word, 'frequency)
tEnv.registerFunction(&quot;countUdaf&quot;, new CountUdaf())

// run a SQL query on the Table and retrieve the result as a new Table
val table = tEnv.sqlQuery(&quot;SELECT word, countUdaf(frequency), SUM(frequency) FROM WordCount GROUP BY word&quot;)

case class WC(word: String, frequency: Long)
&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;22-计划生成&quot;&gt;2.2 计划生成&lt;/h3&gt;
&lt;p&gt;在 &lt;code&gt;DataSetAggregate.translateToPlan&lt;/code&gt; 中生成了执行计划。原来Flink把 SQL 语句分割成两个阶段：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;combineGroup&lt;/li&gt;
&lt;li&gt;reduceGroup&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;于是我们推断，&lt;u&gt;这很有可能就是 combineGroup 调用accumulate，reduceGroup 调用 merge&lt;/u&gt;。&lt;/p&gt;
&lt;p&gt;关于combineGroup，如果有兴趣，可以看看我之前文章 &lt;a href=&quot;https://www.cnblogs.com/rossiXYZ/p/13080429.html&quot;&gt;[源码解析] Flink的groupBy和reduce究竟做了什么&lt;/a&gt; 以及 &lt;a href=&quot;https://www.cnblogs.com/rossiXYZ/p/13148695.html&quot;&gt;源码解析] GroupReduce，GroupCombine 和 Flink SQL group by&lt;/a&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;override def translateToPlan(tableEnv: BatchTableEnvImpl,
    queryConfig: BatchQueryConfig): DataSet[Row] = {
    if (grouping.length &amp;gt; 0) {
      // grouped aggregation

      if (preAgg.isDefined) {
        // 执行到这里
        inputDS
          // pre-aggregation
          .groupBy(grouping: _*)
          .combineGroup(preAgg.get) // 第一阶段
          .returns(preAggType.get)
          .name(aggOpName)
          
          // final aggregation
          .groupBy(grouping.indices: _*)
          .reduceGroup(finalAgg.right.get) // 第二阶段
          .returns(rowTypeInfo)
          .name(aggOpName)
      }
    }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;SQL语句对应的执行计划大致为：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1850883/202008/1850883-20200808212536018-1739987680.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h3 id=&quot;23-执行&quot;&gt;2.3 执行&lt;/h3&gt;
&lt;p&gt;在执行看，确实对应了两个阶段。&lt;/p&gt;
&lt;p&gt;阶段 1 确实是 GroupReduceCombineDriver 调用到了 accumulate。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;//堆栈如下
accumulate:25, CountUdaf (mytest)
accumulate:-1, DataSetAggregatePrepareMapHelper$5
combine:71, DataSetPreAggFunction (org.apache.flink.table.runtime.aggregate)
sortAndCombine:213, GroupReduceCombineDriver (org.apache.flink.runtime.operators)
run:188, GroupReduceCombineDriver (org.apache.flink.runtime.operators)
  
//SQL UDAF生成的代码如下  
function = {DataSetAggregatePrepareMapHelper$5@10085} 
 function_mytest$CountUdaf$5ae272a09e5f36214da5c4e5436c4c48 = {CountUdaf@10079} &quot;CountUdaf&quot;
 function_org$apache$flink$table$functions$aggfunctions$LongSumAggFunction$a5214701531789b3139223681d = {LongSumAggFunction@10087} &quot;LongSumAggFunction&quot;  
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;阶段 2 中 GroupReduceDriver 调用到了 merge&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;//堆栈如下
merge:29, CountUdaf (mytest)
mergeAccumulatorsPair:-1, DataSetAggregateFinalHelper$6
reduce:71, DataSetFinalAggFunction (org.apache.flink.table.runtime.aggregate)
run:131, GroupReduceDriver (org.apache.flink.runtime.operators)
  
//SQL UDAF生成的代码如下   
function = {DataSetAggregateFinalHelper$6@10245} 
 function_mytest$CountUdaf$5ae272a09e5f36214da5c4e5436c4c48 = {CountUdaf@10238} &quot;CountUdaf&quot;
 function_org$apache$flink$table$functions$aggfunctions$LongSumAggFunction$a5214701531789b3139223681d = {LongSumAggFunction@10247} &quot;LongSumAggFunction&quot;  
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;u&gt;Flink对用户定义的UDAF代码分别生成了两个不同的功能类&lt;/u&gt;：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;DataSetAggregatePrepareMapHelper ： 用于Combine阶段，调用了accumulate&lt;/li&gt;
&lt;li&gt;DataSetAggregateFinalHelper ：用于Reduce阶段，调用了merge&lt;/li&gt;
&lt;/ul&gt;&lt;h3 id=&quot;24-状态管理&quot;&gt;2.4 状态管理&lt;/h3&gt;
&lt;p&gt;UDAF有一个accumulator，这个会在程序运行过程中始终存在，Flink是如何管理这个accumulator呢？&lt;/p&gt;
&lt;p&gt;GroupReduceCombineDriver类有一个成员变量 combiner，&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;public class GroupReduceCombineDriver&amp;lt;IN, OUT&amp;gt; implements Driver&amp;lt;GroupCombineFunction&amp;lt;IN, OUT&amp;gt;, OUT&amp;gt; {
        private GroupCombineFunction&amp;lt;IN, OUT&amp;gt; combiner;
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;而 combiner 被赋予了 DataSetPreAggFunction 类的一个实例。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;class DataSetPreAggFunction(genAggregations: GeneratedAggregationsFunction)
  extends AbstractRichFunction{
  private var accumulators: Row = _ //这里存储历史状态
  private var function: GeneratedAggregations = _
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;Flink就是把 UDAF的accumulator 存储在 &lt;code&gt;combiner.accumulators&lt;/code&gt; 中，我们可以看到，&lt;u&gt;无论用户定义了什么类型作为 accumulator，Flink都用万能类型 Row 搞定&lt;/u&gt;。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;combiner = {DataSetPreAggFunction@10063} 
 genAggregations = {GeneratedAggregationsFunction@10070} 
 accumulators = {Row@10117} &quot;mytest.CountUdaf$CountAccum@1e343db7,(0,false)&quot;
 function = {DataSetAggregatePrepareMapHelper$5@10066}  // function是包含用户代码的功能类。
  function_mytest$CountUdaf$5ae272a09e5f36214da5c4e5436c4c48 = {CountUdaf@10076} &quot;CountUdaf&quot; 
&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;25-总结&quot;&gt;2.5 总结&lt;/h3&gt;
&lt;p&gt;让我们总结一下，批处理被分成两个阶段：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;combineGroup ：根据用户UDAF代码生成功能类 DataSetAggregatePrepareMapHelper，用于Combine阶段，调用了accumulate；&lt;/li&gt;
&lt;li&gt;reduceGroup ：根据用户UDAF代码生成功能类 DataSetAggregateFinalHelper，用于Reduce阶段，调用了 merge；&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;Flink在GroupReduceCombineDriver类的成员变量 combiner 中存储 accumulator历史状态。&lt;/p&gt;
&lt;h2 id=&quot;0x03-流处理&quot;&gt;0x03 流处理&lt;/h2&gt;
&lt;p&gt;流处理则是和批处理完全不同的世界，下面我们看看流处理背后有什么奥秘。&lt;/p&gt;
&lt;p&gt;在流计算场景中，数据没有边界源源不断的流入的，每条数据流入都可能会触发计算，比如在进行count或sum这些操作是如何计算的呢？&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;是选择每次触发计算将所有流入的历史数据重新计算一遍？&lt;/li&gt;
&lt;li&gt;还是每次计算都基于上次计算结果进行增量计算呢？&lt;/li&gt;
&lt;li&gt;如果选择增量计算，那么上一次的中间计算结果保存在哪里？内存？&lt;/li&gt;
&lt;/ul&gt;&lt;h3 id=&quot;31-示例代码&quot;&gt;3.1 示例代码&lt;/h3&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;val query: Table = tableEnv.sqlQuery(
  &quot;&quot;&quot;
    |SELECT
    |countUdaf(num)
    |FROM tb_num
    |GROUP BY TUMBLE(proctime, INTERVAL '10' SECOND)
   &quot;&quot;&quot;.stripMargin)
&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;32-计划生成&quot;&gt;3.2 计划生成&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;DataStreamGroupWindowAggregateBase.translateToPlan&lt;/code&gt; 函数中完成了计划生成。根据Stream的类型（是否有key），会走不同的逻辑业务。&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;code&gt;WindowedStream&lt;/code&gt;代表了&lt;u&gt;根据key分组&lt;/u&gt;，并且基于&lt;code&gt;WindowAssigner&lt;/code&gt;切分窗口的数据流。所以&lt;code&gt;WindowedStream&lt;/code&gt;都是从&lt;code&gt;KeyedStream&lt;/code&gt;衍生而来的。在key分组的流上进行窗口切分是比较常用的场景，也能够很好地并行化（不同的key上的窗口聚合可以分配到不同的task去处理）。&lt;/li&gt;
&lt;li&gt;当在普通流（没有key）上进行窗口操作时，就要用到 &lt;code&gt;AllWindowedStream&lt;/code&gt;。&lt;code&gt;AllWindowedStream&lt;/code&gt;是直接在&lt;code&gt;DataStream&lt;/code&gt;上进行&lt;code&gt;windowAll(...)&lt;/code&gt;操作。在普通流上进行窗口操作，就势必需要将所有分区的流都汇集到单个的Task中，而这个单个的Task很显然就会成为整个Job的瓶颈。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;我们的示例代码是基于Key的，所以走 &lt;code&gt;WindowedStream&lt;/code&gt; 分支，&lt;u&gt;即一个 window 中即做accumulate，又做merge&lt;/u&gt;。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-scala&quot;&gt;// grouped / keyed aggregation
if (grouping.length &amp;gt; 0) {
      // 有key，所以是 WindowedStream，我们示例走这里
      val windowFunction = AggregateUtil.createAggregationGroupWindowFunction(...)

      val keySelector = new CRowKeySelector(grouping, inputSchema.projectedTypeInfo(grouping))
      val keyedStream = timestampedInput.keyBy(keySelector)
      val windowedStream =
        createKeyedWindowedStream(queryConfig, window, keyedStream)
          .asInstanceOf[WindowedStream[CRow, Row, DataStreamWindow]]

      val (aggFunction, accumulatorRowType) =
        AggregateUtil.createDataStreamGroupWindowAggregateFunction(...)

      windowedStream
        .aggregate(aggFunction, windowFunction, accumulatorRowType, outRowType)
        .name(keyedAggOpName)
}
// global / non-keyed aggregation
else {
      // 没有key，所以是AllWindowedStream 
      val windowFunction = AggregateUtil.createAggregationAllWindowFunction(...)

      val windowedStream =
        createNonKeyedWindowedStream(queryConfig, window, timestampedInput)
          .asInstanceOf[AllWindowedStream[CRow, DataStreamWindow]]

      val (aggFunction, accumulatorRowType) =
        AggregateUtil.createDataStreamGroupWindowAggregateFunction(...)

      windowedStream
        .aggregate(aggFunction, windowFunction, accumulatorRowType, outRowType)
        .name(nonKeyedAggOpName)
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;SQL语句对应的执行计划大致如下，我们能看出来 accumulate &amp;amp; merge 都在 Window 中处理。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1850883/202008/1850883-20200808212611349-1697751025.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h3 id=&quot;33-执行--状态管理&quot;&gt;3.3 执行 &amp;amp; 状态管理&lt;/h3&gt;
&lt;p&gt;可以看到，流处理对UDAF的管理，就完全是进入了Window的地盘，而UDAF历史状态管理其实就是&lt;u&gt;Flink Window状态管理的领域&lt;/u&gt;了。&lt;/p&gt;
&lt;p&gt;我们以基于key的WindowedStream为例继续进行研究。&lt;/p&gt;
&lt;h4 id=&quot;331-接受到一个新输入&quot;&gt;3.3.1 接受到一个新输入&lt;/h4&gt;
&lt;p&gt;当Window接受到一个输入item时候，item会被分配到一个key，由KeySelector完成。WindowOperator 类首先使用用户选择的 windowAssigner 将流入的数据分配到响应的window中，有可能是1个，0个甚至多个window。&lt;u&gt;这里就会做accumulate&lt;/u&gt;。&lt;/p&gt;
&lt;p&gt;本例 &lt;code&gt;windowAssigner = {TumblingProcessingTimeWindows}&lt;/code&gt; ，进入到processElement函数的 &lt;u&gt;&lt;strong&gt;非 MergingWindow部分&lt;/strong&gt;&lt;/u&gt;，具体流程如下：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;遍历elementWindows，进行业务处理
&lt;ul&gt;&lt;li&gt;1)判断该window是否已过期，isWindowLate(window)&lt;/li&gt;
&lt;li&gt;2)获取该window的context，windowState.setCurrentNamespace(window); 这里是 HeapAggregatingState。&lt;/li&gt;
&lt;li&gt;3)将数据加入，&lt;strong&gt;windowState.add&lt;/strong&gt;(element.getValue());
&lt;ul&gt;&lt;li&gt;3.1)调用 &lt;strong&gt;stateTable.transform&lt;/strong&gt;();处理输入
&lt;ul&gt;&lt;li&gt;3.1.1)StateMap&amp;lt;K, N, S&amp;gt; stateMap = getMapForKeyGroup(keyGroup); 这里获取到CopyOnWriteStateMap&lt;/li&gt;
&lt;li&gt;3.1.2)stateMap.transform(key, namespace, value, transformation);
&lt;ul&gt;&lt;li&gt;3.1.2.1)调用 AggregateTransformation.apply，其又调用 aggFunction.add(value, accumulator);
&lt;ul&gt;&lt;li&gt;3.1.2.1.1)调用 GroupingWindowAggregateHelper.accumulate(accumulatorRow, value.row)，&lt;u&gt;其又调用 用户定义的 accumulate&lt;/u&gt;；&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;可以看到，是 &lt;u&gt;windowState 添加元素时候，调用到State的API，然后间接调用到了UDAF&lt;/u&gt;。&lt;/p&gt;
&lt;h4 id=&quot;332-windowstate--udaf执行&quot;&gt;3.3.2 windowState &amp;amp; UDAF执行&lt;/h4&gt;
&lt;p&gt;windowState 以 window 为 namespace，以隔离不同的window的context。这里虽然叫做 windowState 。但是可以发现，该类存储的是不同window中的对应的原始数据（processWindowFunction情况）或结果（ReduceFunction/AggregateFunction情况）。&lt;u&gt;我们此例中，存储的是执行结果&lt;/u&gt;。&lt;/p&gt;
&lt;p&gt;本例用到的 window process 是 Incremental Aggregation Functions。即 ReduceFunction 与 AggregateFunction ，其特点是无需保存 window 中的所有数据，一旦新数据进入，便可与之前的中间结果进行计算，因此这种 window 中其状态仅需保存一个结果便可。&lt;/p&gt;
&lt;p&gt;因此这里我们拿到的是 HeapReducingState， HeapAggregatingState，当执行到 &lt;code&gt;windowState.add(element.getValue());&lt;/code&gt;语句时，&lt;u&gt;便调用UDAF得出结果&lt;/u&gt;。&lt;/p&gt;
&lt;h4 id=&quot;333-state--结果存储&quot;&gt;3.3.3 State &amp;amp; 结果存储&lt;/h4&gt;
&lt;p&gt;&lt;u&gt;在flink中state用来存放计算过程的节点中间结果或元数据&lt;/u&gt;。在flink内部提供三种state存储实现&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;内存HeapStateBackend：存放数据量小，用于开发测试使用；生产不建议使用&lt;/li&gt;
&lt;li&gt;HDFS的FsStateBackend ：分布式文件持久化，每次都会产生网络io，可用于大state，不支持增量；可用于生产&lt;/li&gt;
&lt;li&gt;RocksDB的RocksDBStateBackend：本地文件 + 异步hdfs持久化，也可用于大state数据量，唯一支持增量，可用于生产；&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;u&gt;我们这里拿到的是 HeapAggregatingState&lt;/u&gt;。&lt;/p&gt;
&lt;h4 id=&quot;334-state-存储结构&quot;&gt;3.3.4 State 存储结构&lt;/h4&gt;
&lt;p&gt;&lt;u&gt;以三元组的形式存储保存数据，即 key, namespace, value&lt;/u&gt;。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;public abstract class StateTable&amp;lt;K, N, S&amp;gt;
        implements StateSnapshotRestore, Iterable&amp;lt;StateEntry&amp;lt;K, N, S&amp;gt;&amp;gt; {
   /**
   * Map for holding the actual state objects. The outer array represents the key-groups.
   * All array positions will be initialized with an empty state map.
   */
        protected final StateMap&amp;lt;K, N, S&amp;gt;[] keyGroupedStateMaps;
}

// 真实中变量摘录如下
keyGroupedStateMaps = {StateMap[1]@9266} 
 0 = {CopyOnWriteStateMap@9262} // 这里就是将要保存用户accumulator的地方
  stateSerializer = {RowSerializer@9254} 
  snapshotVersions = {TreeSet@9277}  size = 0
  primaryTable = {CopyOnWriteStateMap$StateMapEntry[128]@9278} 
  incrementalRehashTable = {CopyOnWriteStateMap$StateMapEntry[2]@9280} 
  lastNamespace = {TimeWindow@9239} &quot;TimeWindow{start=1593934200000, end=1593934210000}&quot;
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;在上面提及的 &lt;code&gt;3.1.2)stateMap.transform(key, namespace, value, transformation);&lt;/code&gt; 中&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;@Override
public &amp;lt;T&amp;gt; void transform(
   K key,
   N namespace,
   T value,
   StateTransformationFunction&amp;lt;S, T&amp;gt; transformation) throws Exception {

   final StateMapEntry&amp;lt;K, N, S&amp;gt; entry = putEntry(key, namespace);

   // copy-on-write check for state
   entry.state = transformation.apply(
      (entry.stateVersion &amp;lt; highestRequiredSnapshotVersion) ?
         getStateSerializer().copy(entry.state) : entry.state,
         value); 
   // 当执行完用户代码之后，数据会存储在这里，这个就是CopyOnWriteStateMap的一个Entry
   entry.stateVersion = stateMapVersion;
&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;34-总结&quot;&gt;3.4 总结&lt;/h3&gt;
&lt;p&gt;流处理对UDAF的管理，就完全是进入了Window的地盘，而UDAF历史状态管理其实就是&lt;u&gt;Flink Window状态管理的领域&lt;/u&gt;了。&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;window接受到新输入，就会往 windowState 添加元素。&lt;/li&gt;
&lt;li&gt;windowState 添加元素时候，调用到State的API，然后间接调用到了UDAF&lt;/li&gt;
&lt;li&gt;windowState 在本例存储的是UDAF执行结果。具体存储是在HeapAggregatingState中完成。&lt;/li&gt;
&lt;/ul&gt;&lt;h2 id=&quot;0xff-参考&quot;&gt;0xFF 参考&lt;/h2&gt;
&lt;p&gt;&lt;a href=&quot;https://www.jianshu.com/p/b9b23a7cb880&quot;&gt;Flink - 当数据流入window时，会发生什么&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.jianshu.com/p/f283cf30508c&quot;&gt;Flink SQL 自定义UDAF&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://help.aliyun.com/document_detail/69553.html&quot;&gt;自定义聚合函数（UDAF）&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.cnblogs.com/ooffff/p/9522440.html&quot;&gt;Apache Flink - 常见数据流类型&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://blog.csdn.net/weixin_38499215/article/details/99709265&quot;&gt;Flink-SQL源码解读（一）window算子的创建的源码分析&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.cnblogs.com/lighten/p/13195042.html&quot;&gt;从udaf谈flink的state&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.cnblogs.com/ooffff/p/9522440.html&quot;&gt;Apache Flink - 常见数据流类型&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://blog.csdn.net/xianzhen376/article/details/89889728&quot;&gt;Flink状态管理（二）状态数据结构和注册流程&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;</description>
<pubDate>Tue, 11 Aug 2020 23:50:00 +0000</pubDate>
<dc:creator>罗西的思考</dc:creator>
<og:description>本文涉及到Flink SQL UDAF，Window 状态管理等部分，希望能起到抛砖引玉的作用，让大家可以借此深入了解这个领域。</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/rossiXYZ/p/13460408.html</dc:identifier>
</item>
<item>
<title>《T-GCN: A Temporal Graph Convolutional Network for Trafﬁc Prediction》 代码解读 - 那不太可能</title>
<link>http://www.cnblogs.com/missouter/p/13488342.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/missouter/p/13488342.html</guid>
<description>&lt;p&gt;论文链接：&lt;a href=&quot;https://arxiv.org/abs/1811.05320&quot;&gt;https://arxiv.org/abs/1811.05320&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;博客原作者Missouter，博客链接&lt;a href=&quot;https://www.cnblogs.com/missouter/&quot;&gt;https://www.cnblogs.com/missouter/&lt;/a&gt;，欢迎交流。&lt;/p&gt;
&lt;p&gt;解读了一下这篇论文github上关于T-GCN的代码，主要分为main文件与TGCN文件两部分，后续有空将会更新其他部分作为baseline代码的解读（鸽）。&lt;/p&gt;
&lt;p&gt;1、main.py&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;57&quot;&gt;
&lt;pre&gt;
&lt;span&gt;#&lt;/span&gt;&lt;span&gt; -*- coding: utf-8 -*-&lt;/span&gt;
&lt;span&gt;import&lt;/span&gt;&lt;span&gt; pickle as pkl
&lt;/span&gt;&lt;span&gt;import&lt;/span&gt;&lt;span&gt; tensorflow as tf
&lt;/span&gt;&lt;span&gt;import&lt;/span&gt;&lt;span&gt; pandas as pd
&lt;/span&gt;&lt;span&gt;import&lt;/span&gt;&lt;span&gt; numpy as np
&lt;/span&gt;&lt;span&gt;import&lt;/span&gt;&lt;span&gt; math
&lt;/span&gt;&lt;span&gt;import&lt;/span&gt;&lt;span&gt; os
&lt;/span&gt;&lt;span&gt;import&lt;/span&gt;&lt;span&gt; numpy.linalg as la
&lt;/span&gt;&lt;span&gt;from&lt;/span&gt; input_data &lt;span&gt;import&lt;/span&gt;&lt;span&gt; preprocess_data,load_sz_data,load_los_data
&lt;/span&gt;&lt;span&gt;from&lt;/span&gt; tgcn &lt;span&gt;import&lt;/span&gt;&lt;span&gt; tgcnCell
&lt;/span&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt;from gru import GRUCell &lt;/span&gt;

&lt;span&gt;from&lt;/span&gt; visualization &lt;span&gt;import&lt;/span&gt;&lt;span&gt; plot_result,plot_error
&lt;/span&gt;&lt;span&gt;from&lt;/span&gt; sklearn.metrics &lt;span&gt;import&lt;/span&gt;&lt;span&gt; mean_squared_error,mean_absolute_error
&lt;/span&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt;import matplotlib.pyplot as plt&lt;/span&gt;
&lt;span&gt;import&lt;/span&gt;&lt;span&gt; time

time_start &lt;/span&gt;=&lt;span&gt; time.time()
&lt;/span&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt;##### Settings ######&lt;/span&gt;
flags =&lt;span&gt; tf.app.flags
FLAGS &lt;/span&gt;=&lt;span&gt; flags.FLAGS
flags.DEFINE_float(&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;learning_rate&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;, 0.001, &lt;span&gt;'&lt;/span&gt;&lt;span&gt;Initial learning rate.&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;)
flags.DEFINE_integer(&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;training_epoch&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;, 1, &lt;span&gt;'&lt;/span&gt;&lt;span&gt;Number of epochs to train.&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;)
flags.DEFINE_integer(&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;gru_units&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;, 64, &lt;span&gt;'&lt;/span&gt;&lt;span&gt;hidden units of gru.&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;)
flags.DEFINE_integer(&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;seq_len&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;,12 , &lt;span&gt;'&lt;/span&gt;&lt;span&gt;  time length of inputs.&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;)
flags.DEFINE_integer(&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;pre_len&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;, 3, &lt;span&gt;'&lt;/span&gt;&lt;span&gt;time length of prediction.&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;)
flags.DEFINE_float(&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;train_rate&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;, 0.8, &lt;span&gt;'&lt;/span&gt;&lt;span&gt;rate of training set.&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;)
flags.DEFINE_integer(&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;batch_size&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;, 32, &lt;span&gt;'&lt;/span&gt;&lt;span&gt;batch size.&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;)
flags.DEFINE_string(&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;dataset&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;, &lt;span&gt;'&lt;/span&gt;&lt;span&gt;los&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;, &lt;span&gt;'&lt;/span&gt;&lt;span&gt;sz or los.&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;)
flags.DEFINE_string(&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;model_name&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;, &lt;span&gt;'&lt;/span&gt;&lt;span&gt;tgcn&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;, &lt;span&gt;'&lt;/span&gt;&lt;span&gt;tgcn&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;)
model_name &lt;/span&gt;=&lt;span&gt; FLAGS.model_name
data_name &lt;/span&gt;=&lt;span&gt; FLAGS.dataset
train_rate &lt;/span&gt;=&lt;span&gt;  FLAGS.train_rate
seq_len &lt;/span&gt;=&lt;span&gt; FLAGS.seq_len
output_dim &lt;/span&gt;= pre_len =&lt;span&gt; FLAGS.pre_len
batch_size &lt;/span&gt;=&lt;span&gt; FLAGS.batch_size
lr &lt;/span&gt;=&lt;span&gt; FLAGS.learning_rate
training_epoch &lt;/span&gt;=&lt;span&gt; FLAGS.training_epoch
gru_units &lt;/span&gt;= FLAGS.gru_units
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;开头部分用于设置训练基本参数；使用flag对参数进行设置与说明。&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;45&quot;&gt;
&lt;pre&gt;
&lt;span&gt;if&lt;/span&gt; data_name == &lt;span&gt;'&lt;/span&gt;&lt;span&gt;sz&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;:
    data, adj &lt;/span&gt;= load_sz_data(&lt;span&gt;'&lt;/span&gt;&lt;span&gt;sz&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;)
&lt;/span&gt;&lt;span&gt;if&lt;/span&gt; data_name == &lt;span&gt;'&lt;/span&gt;&lt;span&gt;los&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;:
    data, adj &lt;/span&gt;= load_los_data(&lt;span&gt;'&lt;/span&gt;&lt;span&gt;los&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;)

time_len &lt;/span&gt;=&lt;span&gt; data.shape[0]
num_nodes &lt;/span&gt;= data.shape[1&lt;span&gt;]
data1 &lt;/span&gt;=np.mat(data,dtype=&lt;span&gt;np.float32)

&lt;/span&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt;### normalization&lt;/span&gt;
max_value =&lt;span&gt; np.max(data1)
data1  &lt;/span&gt;= data1/max_value
trainX, trainY, testX, testY =&lt;span&gt; preprocess_data(data1, time_len, train_rate, seq_len, pre_len)

totalbatch &lt;/span&gt;= int(trainX.shape[0]/&lt;span&gt;batch_size)
training_data_count &lt;/span&gt;= len(trainX)
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;这部分导入数据集并对数据进行归一化，input_data文件中导入函数如下：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;39&quot;&gt;
&lt;pre&gt;
&lt;span&gt;def&lt;/span&gt;&lt;span&gt; load_sz_data(dataset):
    sz_adj &lt;/span&gt;= pd.read_csv(r&lt;span&gt;'&lt;/span&gt;&lt;span&gt;data/sz_adj.csv&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;,header=&lt;span&gt;None)
    adj &lt;/span&gt;=&lt;span&gt; np.mat(sz_adj)
    sz_tf &lt;/span&gt;= pd.read_csv(r&lt;span&gt;'&lt;/span&gt;&lt;span&gt;data/sz_speed.csv&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;)
    &lt;/span&gt;&lt;span&gt;return&lt;/span&gt;&lt;span&gt; sz_tf, adj

&lt;/span&gt;&lt;span&gt;def&lt;/span&gt;&lt;span&gt; load_los_data(dataset):
    los_adj &lt;/span&gt;= pd.read_csv(r&lt;span&gt;'&lt;/span&gt;&lt;span&gt;data/los_adj.csv&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;,header=&lt;span&gt;None)
    adj &lt;/span&gt;=&lt;span&gt; np.mat(los_adj)
    los_tf &lt;/span&gt;= pd.read_csv(r&lt;span&gt;'&lt;/span&gt;&lt;span&gt;data/los_speed.csv&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;)
    &lt;/span&gt;&lt;span&gt;return&lt;/span&gt; los_tf, adj
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;其中preprocess_data函数根据main函数开头设置的训练集、测试集比例对数据集进行分割：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;48&quot;&gt;
&lt;pre&gt;
&lt;span&gt;def&lt;/span&gt;&lt;span&gt; preprocess_data(data, time_len, rate, seq_len, pre_len):
    train_size &lt;/span&gt;= int(time_len *&lt;span&gt; rate)
    train_data &lt;/span&gt;=&lt;span&gt; data[0:train_size]
    test_data &lt;/span&gt;=&lt;span&gt; data[train_size:time_len]
    
    trainX, trainY, testX, testY &lt;/span&gt;=&lt;span&gt; [], [], [], []
    &lt;/span&gt;&lt;span&gt;for&lt;/span&gt; i &lt;span&gt;in&lt;/span&gt; range(len(train_data) - seq_len -&lt;span&gt; pre_len):
        a &lt;/span&gt;= train_data[i: i + seq_len +&lt;span&gt; pre_len]
        trainX.append(a[0 : seq_len])
        trainY.append(a[seq_len : seq_len &lt;/span&gt;+&lt;span&gt; pre_len])
    &lt;/span&gt;&lt;span&gt;for&lt;/span&gt; i &lt;span&gt;in&lt;/span&gt; range(len(test_data) - seq_len -&lt;span&gt;pre_len):
        b &lt;/span&gt;= test_data[i: i + seq_len +&lt;span&gt; pre_len]
        testX.append(b[0 : seq_len])
        testY.append(b[seq_len : seq_len &lt;/span&gt;+&lt;span&gt; pre_len])
      
    trainX1 &lt;/span&gt;=&lt;span&gt; np.array(trainX)
    trainY1 &lt;/span&gt;=&lt;span&gt; np.array(trainY)
    testX1 &lt;/span&gt;=&lt;span&gt; np.array(testX)
    testY1 &lt;/span&gt;=&lt;span&gt; np.array(testY)
    &lt;/span&gt;&lt;span&gt;return&lt;/span&gt; trainX1, trainY1, testX1, testY1
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;接着定义了TGCN函数：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;60&quot;&gt;
&lt;pre&gt;
&lt;span&gt;def&lt;/span&gt;&lt;span&gt; TGCN(_X, _weights, _biases):
    &lt;/span&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt;##&lt;/span&gt;
    cell_1 = tgcnCell(gru_units, adj, num_nodes=&lt;span&gt;num_nodes)
    cell &lt;/span&gt;= tf.nn.rnn_cell.MultiRNNCell([cell_1], state_is_tuple=&lt;span&gt;True)
    _X &lt;/span&gt;= tf.unstack(_X, axis=1&lt;span&gt;)
    outputs, states &lt;/span&gt;= tf.nn.static_rnn(cell, _X, dtype=&lt;span&gt;tf.float32)
    m &lt;/span&gt;=&lt;span&gt; []
    &lt;/span&gt;&lt;span&gt;for&lt;/span&gt; i &lt;span&gt;in&lt;/span&gt;&lt;span&gt; outputs:
        o &lt;/span&gt;= tf.reshape(i,shape=[-1&lt;span&gt;,num_nodes,gru_units])
        o &lt;/span&gt;= tf.reshape(o,shape=[-1&lt;span&gt;,gru_units])
        m.append(o)
    last_output &lt;/span&gt;= m[-1&lt;span&gt;]
    output &lt;/span&gt;= tf.matmul(last_output, _weights[&lt;span&gt;'&lt;/span&gt;&lt;span&gt;out&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;]) + _biases[&lt;span&gt;'&lt;/span&gt;&lt;span&gt;out&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;]
    output &lt;/span&gt;= tf.reshape(output,shape=[-1&lt;span&gt;,num_nodes,pre_len])
    output &lt;/span&gt;= tf.transpose(output, perm=[0,2,1&lt;span&gt;])
    output &lt;/span&gt;= tf.reshape(output, shape=[-1&lt;span&gt;,num_nodes])
    &lt;/span&gt;&lt;span&gt;return&lt;/span&gt; output, m, states
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;函数开头首先引入了TGCN的计算单元，tgcnCell的解读将在后文进行；使用tf.nn.rnn_cell.MultiRNNCell实现多层神经网络；对输入数据进行处理，创建由RNNCell指定的循环神经网络。接着对每个循环神经网络的输出进行处理，首先重塑结果张量，tf.reshape中参数-1表示计算该维度的大小,以使总大小保持不变；第二维为点的数量，第三维为GRU单元的数量，再紧接上一层张量重塑的结果继续进行重塑，得到由长度为GRU数量列表组成的列表，使用tf.matmul将输出矩阵乘以权重矩阵，biases为偏差，接着重塑输出张量为第二维为数据点的数量，第三维为预测长度的矩阵，再置换输出矩阵,使用transpose按照[0,2,1]重新排列尺寸，进一步重塑为由数据点数目长度列表组成的列表，得到最终输出结果。&lt;/p&gt;
&lt;p&gt;紧接着下一段使用占位符定义输入与标签，随机初始化权重与偏差：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;45&quot;&gt;
&lt;pre&gt;
inputs = tf.placeholder(tf.float32, shape=&lt;span&gt;[None, seq_len, num_nodes])
labels &lt;/span&gt;= tf.placeholder(tf.float32, shape=&lt;span&gt;[None, pre_len, num_nodes])

weights &lt;/span&gt;=&lt;span&gt; {
    &lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;out&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;: tf.Variable(tf.random_normal([gru_units, pre_len], mean=1.0), name=&lt;span&gt;'&lt;/span&gt;&lt;span&gt;weight_o&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;)}
biases &lt;/span&gt;=&lt;span&gt; {
    &lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;out&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;: tf.Variable(tf.random_normal([pre_len]),name=&lt;span&gt;'&lt;/span&gt;&lt;span&gt;bias_o&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;)}
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;调用TGCN模型，得到最终输出、每层输出与最终状态：&lt;/p&gt;
&lt;div readability=&quot;10&quot;&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;36&quot;&gt;
&lt;pre&gt;
&lt;span&gt;if&lt;/span&gt; model_name == &lt;span&gt;'&lt;/span&gt;&lt;span&gt;tgcn&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;:
    pred,ttts,ttto &lt;/span&gt;=&lt;span&gt; TGCN(inputs, weights, biases)

y_pred &lt;/span&gt;= pred
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;定义优化器，根据训练数据方差设置偏差：&lt;/p&gt;
&lt;div readability=&quot;9.5&quot;&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;35&quot;&gt;
&lt;pre&gt;
lambda_loss = 0.0015&lt;span&gt;
Lreg &lt;/span&gt;= lambda_loss * sum(tf.nn.l2_loss(tf_var) &lt;span&gt;for&lt;/span&gt; tf_var &lt;span&gt;in&lt;/span&gt;&lt;span&gt; tf.trainable_variables())
label &lt;/span&gt;= tf.reshape(labels, [-1,num_nodes])
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;定义损失函数：&lt;/p&gt;
&lt;div readability=&quot;26.5&quot;&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;32&quot;&gt;
&lt;pre&gt;
loss = tf.reduce_mean(tf.nn.l2_loss(y_pred-label) + Lreg)
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;对应论文公式（详见上篇博客）：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1829854/202008/1829854-20200812003532034-1388116081.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;

&lt;p&gt; 定义均方根误差：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;32&quot;&gt;
&lt;pre&gt;
error = tf.sqrt(tf.reduce_mean(tf.square(y_pred-label)))
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;定义优化迭代器：&lt;/p&gt;
&lt;div readability=&quot;100.5&quot;&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;32&quot;&gt;
&lt;pre&gt;
optimizer = tf.train.AdamOptimizer(lr).minimize(loss)
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;对迭代训练过程进行初始化：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;44&quot;&gt;
&lt;pre&gt;
variables =&lt;span&gt; tf.global_variables()
saver &lt;/span&gt;= tf.train.Saver(tf.global_variables()) &lt;span&gt;#
#&lt;/span&gt;&lt;span&gt;sess = tf.Session()&lt;/span&gt;
gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.333&lt;span&gt;)
sess &lt;/span&gt;= tf.Session(config=tf.ConfigProto(gpu_options=&lt;span&gt;gpu_options))
sess.run(tf.global_variables_initializer())
out &lt;/span&gt;= &lt;span&gt;'&lt;/span&gt;&lt;span&gt;out/%s&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;%&lt;span&gt;(model_name)
&lt;/span&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt;out = 'out/%s_%s'%(model_name,'perturbation')&lt;/span&gt;
path1 = &lt;span&gt;'&lt;/span&gt;&lt;span&gt;%s_%s_lr%r_batch%r_unit%r_seq%r_pre%r_epoch%r&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;%&lt;span&gt;(model_name,data_name,lr,batch_size,gru_units,seq_len,pre_len,training_epoch)
path &lt;/span&gt;=&lt;span&gt; os.path.join(out,path1)
&lt;/span&gt;&lt;span&gt;if&lt;/span&gt; &lt;span&gt;not&lt;/span&gt;&lt;span&gt; os.path.exists(path):
    os.makedirs(path)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;其中global_variables用于获取程序中的变量，配合train.Saver将训练好的模型参数保存起来，以便以后进行验证或测试。tf.GPUOptions用于限制GPU资源的使用，不过为什么要限制使用三分之一的显存尚不清楚，算训练小技巧嘛？初始化模型的参数后设置输出路径与文件名，不详细讨论。&lt;/p&gt;
&lt;p&gt;文件中的评估模块定义了论文实验部分的指标：均方根误差、平均绝对误差、准确率、确定系数与可方差值。&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;43&quot;&gt;
&lt;pre&gt;
&lt;span&gt;def&lt;/span&gt;&lt;span&gt; evaluation(a,b):
    rmse &lt;/span&gt;=&lt;span&gt; math.sqrt(mean_squared_error(a,b))
    mae &lt;/span&gt;=&lt;span&gt; mean_absolute_error(a, b)
    F_norm &lt;/span&gt;= la.norm(a-b,&lt;span&gt;'&lt;/span&gt;&lt;span&gt;fro&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;)/la.norm(a,&lt;span&gt;'&lt;/span&gt;&lt;span&gt;fro&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;)
    r2 &lt;/span&gt;= 1-((a-b)**2).sum()/((a-a.mean())**2&lt;span&gt;).sum()
    var &lt;/span&gt;= 1-(np.var(a-b))/&lt;span&gt;np.var(a)
    &lt;/span&gt;&lt;span&gt;return&lt;/span&gt; rmse, mae, 1-F_norm, r2, var
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;接下来就是常见的训练部分：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;63&quot;&gt;
&lt;pre&gt;
&lt;span&gt;for&lt;/span&gt; epoch &lt;span&gt;in&lt;/span&gt;&lt;span&gt; range(training_epoch):
    &lt;/span&gt;&lt;span&gt;for&lt;/span&gt; m &lt;span&gt;in&lt;/span&gt;&lt;span&gt; range(totalbatch):
        mini_batch &lt;/span&gt;= trainX[m * batch_size : (m+1) *&lt;span&gt; batch_size]
        mini_label &lt;/span&gt;= trainY[m * batch_size : (m+1) *&lt;span&gt; batch_size]
        _, loss1, rmse1, train_output &lt;/span&gt;=&lt;span&gt; sess.run([optimizer, loss, error, y_pred],
                                                 feed_dict &lt;/span&gt;=&lt;span&gt; {inputs:mini_batch, labels:mini_label})
        batch_loss.append(loss1)
        batch_rmse.append(rmse1 &lt;/span&gt;*&lt;span&gt; max_value)

     &lt;/span&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt; Test completely at every epoch&lt;/span&gt;
    loss2, rmse2, test_output =&lt;span&gt; sess.run([loss, error, y_pred],
                                         feed_dict &lt;/span&gt;=&lt;span&gt; {inputs:testX, labels:testY})
    test_label &lt;/span&gt;= np.reshape(testY,[-1&lt;span&gt;,num_nodes])
    rmse, mae, acc, r2_score, var_score &lt;/span&gt;=&lt;span&gt; evaluation(test_label, test_output)
    test_label1 &lt;/span&gt;= test_label * max_value&lt;span&gt;#&lt;/span&gt;&lt;span&gt;反归一化&lt;/span&gt;
    test_output1 = test_output *&lt;span&gt; max_value
    test_loss.append(loss2)
    test_rmse.append(rmse &lt;/span&gt;*&lt;span&gt; max_value)
    test_mae.append(mae &lt;/span&gt;*&lt;span&gt; max_value)
    test_acc.append(acc)
    test_r2.append(r2_score)
    test_var.append(var_score)
    test_pred.append(test_output1)
    
    &lt;/span&gt;&lt;span&gt;print&lt;/span&gt;(&lt;span&gt;'&lt;/span&gt;&lt;span&gt;Iter:{}&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;.format(epoch),
          &lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;train_rmse:{:.4}&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;.format(batch_rmse[-1&lt;span&gt;]),
          &lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;test_loss:{:.4}&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;.format(loss2),
          &lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;test_rmse:{:.4}&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;.format(rmse),
          &lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;test_acc:{:.4}&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;.format(acc))&lt;/span&gt;
    &lt;span&gt;if&lt;/span&gt; (epoch % 500 ==&lt;span&gt; 0):        
        saver.save(sess, path&lt;/span&gt;+&lt;span&gt;'&lt;/span&gt;&lt;span&gt;/model_100/TGCN_pre_%r&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;%epoch, global_step =&lt;span&gt; epoch)
        
time_end &lt;/span&gt;=&lt;span&gt; time.time()
&lt;/span&gt;&lt;span&gt;print&lt;/span&gt;(time_end-time_start,&lt;span&gt;'&lt;/span&gt;&lt;span&gt;s&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;)
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;附带对每个周期训练结果的测试、对结果的反归一化，训练设置为每训练500层保存一次模型，并对训练得到的参数指标进行打印与保存。代码最后还给出了可视化数据指标的方法，即将数据指标写入csv文件中：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;48&quot;&gt;
&lt;pre&gt;
b = int(len(batch_rmse)/&lt;span&gt;totalbatch)
batch_rmse1 &lt;/span&gt;= [i &lt;span&gt;for&lt;/span&gt; i &lt;span&gt;in&lt;/span&gt;&lt;span&gt; batch_rmse]
train_rmse &lt;/span&gt;= [(sum(batch_rmse1[i*totalbatch:(i+1)*totalbatch])/totalbatch) &lt;span&gt;for&lt;/span&gt; i &lt;span&gt;in&lt;/span&gt;&lt;span&gt; range(b)]
batch_loss1 &lt;/span&gt;= [i &lt;span&gt;for&lt;/span&gt; i &lt;span&gt;in&lt;/span&gt;&lt;span&gt; batch_loss]
train_loss &lt;/span&gt;= [(sum(batch_loss1[i*totalbatch:(i+1)*totalbatch])/totalbatch) &lt;span&gt;for&lt;/span&gt; i &lt;span&gt;in&lt;/span&gt;&lt;span&gt; range(b)]

index &lt;/span&gt;=&lt;span&gt; test_rmse.index(np.min(test_rmse))
test_result &lt;/span&gt;=&lt;span&gt; test_pred[index]
var &lt;/span&gt;=&lt;span&gt; pd.DataFrame(test_result)
var.to_csv(path&lt;/span&gt;+&lt;span&gt;'&lt;/span&gt;&lt;span&gt;/test_result.csv&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;,index = False,header =&lt;span&gt; False)
&lt;/span&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt;plot_result(test_result,test_label1,path)&lt;/span&gt;&lt;span&gt;
#&lt;/span&gt;&lt;span&gt;plot_error(train_rmse,train_loss,test_rmse,test_acc,test_mae,path)&lt;/span&gt;

&lt;span&gt;print&lt;/span&gt;(&lt;span&gt;'&lt;/span&gt;&lt;span&gt;min_rmse:%r&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;%&lt;span&gt;(np.min(test_rmse)),
      &lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;min_mae:%r&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;%&lt;span&gt;(test_mae[index]),
      &lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;max_acc:%r&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;%&lt;span&gt;(test_acc[index]),
      &lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;r2:%r&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;%&lt;span&gt;(test_r2[index]),
      &lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;var:%r&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;%test_var[index])
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;至此对论文对应代码main文件的解读就结束了。&lt;/p&gt;
&lt;p&gt;2、tgcn.py&lt;/p&gt;
&lt;p&gt;此文件只定义了一个TGCN计算单元的类，初始化部分不作详谈：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;44&quot;&gt;
&lt;pre&gt;
&lt;span&gt;#&lt;/span&gt;&lt;span&gt; -*- coding: utf-8 -*-&lt;/span&gt;

&lt;span&gt;#&lt;/span&gt;&lt;span&gt;import numpy as np&lt;/span&gt;
&lt;span&gt;import&lt;/span&gt;&lt;span&gt; tensorflow as tf
&lt;/span&gt;&lt;span&gt;from&lt;/span&gt; tensorflow.contrib.rnn &lt;span&gt;import&lt;/span&gt;&lt;span&gt; RNNCell
&lt;/span&gt;&lt;span&gt;from&lt;/span&gt; utils &lt;span&gt;import&lt;/span&gt;&lt;span&gt; calculate_laplacian

&lt;/span&gt;&lt;span&gt;class&lt;/span&gt;&lt;span&gt; tgcnCell(RNNCell):
    &lt;/span&gt;&lt;span&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span&gt;Temporal Graph Convolutional Network &lt;/span&gt;&lt;span&gt;&quot;&quot;&quot;&lt;/span&gt;

    &lt;span&gt;def&lt;/span&gt; call(self, inputs, **&lt;span&gt;kwargs):
        &lt;/span&gt;&lt;span&gt;pass&lt;/span&gt;
-
    &lt;span&gt;def&lt;/span&gt; &lt;span&gt;__init__&lt;/span&gt;(self, num_units, adj, num_nodes, input_size=&lt;span&gt;None,
                 act&lt;/span&gt;=tf.nn.tanh, reuse=&lt;span&gt;None):


        super(tgcnCell, self).&lt;/span&gt;&lt;span&gt;__init__&lt;/span&gt;(_reuse=&lt;span&gt;reuse)
        self._act &lt;/span&gt;=&lt;span&gt; act
        self._nodes &lt;/span&gt;=&lt;span&gt; num_nodes
        self._units &lt;/span&gt;=&lt;span&gt; num_units
        self._adj &lt;/span&gt;=&lt;span&gt; []
        self._adj.append(calculate_laplacian(adj))


    @property
    &lt;/span&gt;&lt;span&gt;def&lt;/span&gt;&lt;span&gt; state_size(self):
        &lt;/span&gt;&lt;span&gt;return&lt;/span&gt; self._nodes *&lt;span&gt; self._units

    @property
    &lt;/span&gt;&lt;span&gt;def&lt;/span&gt;&lt;span&gt; output_size(self):
        &lt;/span&gt;&lt;span&gt;return&lt;/span&gt; self._units
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;重点之一在于对GRU单元的定义：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;49&quot;&gt;
&lt;pre&gt;
&lt;span&gt;def&lt;/span&gt; &lt;span&gt;__call__&lt;/span&gt;(self, inputs, state, scope=&lt;span&gt;None):
        with tf.variable_scope(scope &lt;/span&gt;&lt;span&gt;or&lt;/span&gt; &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;tgcn&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;):
            with tf.variable_scope(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;gates&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;):  
                value &lt;/span&gt;=&lt;span&gt; tf.nn.sigmoid(
                    self._gc(inputs, state, &lt;/span&gt;2 * self._units, bias=1.0, scope=&lt;span&gt;scope))
                r, u &lt;/span&gt;= tf.split(value=value, num_or_size_splits=2, axis=1&lt;span&gt;)
            with tf.variable_scope(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;candidate&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;):
                r_state &lt;/span&gt;= r *&lt;span&gt; state
                c &lt;/span&gt;= self._act(self._gc(inputs, r_state, self._units, scope=&lt;span&gt;scope))
            new_h &lt;/span&gt;= u * state + (1 - u) *&lt;span&gt; c
        &lt;/span&gt;&lt;span&gt;return&lt;/span&gt; new_h, new_h
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;代码还原论文中tgcn单元的计算过程（详见上一篇博客）：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1829854/202008/1829854-20200812010330549-328720828.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;


&lt;p&gt;参数中state对应论文中上一时刻的状态，即h&lt;sub&gt;t-1。&lt;/sub&gt;variable_scope使得多个变量得以有相同的命名；上述代码中tf.nn.sigmoid语句为激活函数，用于进行图卷积GC；tf.split语句用于&lt;/p&gt;
&lt;p&gt;分割卷积后的张量，重置门r用于控制先前时刻状态信息的度量，上传门u用于控制上传到下一状态的信息度量； candidate部分的c对应公式：&lt;/p&gt;
&lt;div readability=&quot;45.5&quot;&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1829854/202008/1829854-20200812011938473-740273465.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;
&lt;p&gt; 函数最后返回最新状态h&lt;sub&gt;t&lt;/sub&gt;。&lt;/p&gt;
&lt;p&gt;图卷积过程最后被定义：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;79&quot;&gt;
&lt;pre&gt;
    &lt;span&gt;def&lt;/span&gt; _gc(self, inputs, state, output_size, bias=0.0, scope=&lt;span&gt;None):
        &lt;/span&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt;# inputs:(-1,num_nodes)&lt;/span&gt;
&lt;span&gt;        
        inputs &lt;/span&gt;= tf.expand_dims(inputs, 2&lt;span&gt;)
        &lt;/span&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt;# state:(batch,num_node,gru_units)&lt;/span&gt;
        state = tf.reshape(state, (-1&lt;span&gt;, self._nodes, self._units))
        &lt;/span&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt;# concat&lt;/span&gt;
        x_s = tf.concat([inputs, state], axis=2&lt;span&gt;)
        input_size &lt;/span&gt;= x_s.get_shape()[2&lt;span&gt;].value
        &lt;/span&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt;# (num_node,input_size,-1)&lt;/span&gt;
        x0 = tf.transpose(x_s, perm=[1, 2&lt;span&gt;, 0])  
        x0 &lt;/span&gt;= tf.reshape(x0, shape=[self._nodes, -1&lt;span&gt;])
  
        scope &lt;/span&gt;=&lt;span&gt; tf.get_variable_scope()
        with tf.variable_scope(scope):
            &lt;/span&gt;&lt;span&gt;for&lt;/span&gt; m &lt;span&gt;in&lt;/span&gt;&lt;span&gt; self._adj:
                x1 &lt;/span&gt;=&lt;span&gt; tf.sparse_tensor_dense_matmul(m, x0)
&lt;/span&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt;                print(x1)&lt;/span&gt;
            x = tf.reshape(x1, shape=[self._nodes, input_size,-1&lt;span&gt;])
            x &lt;/span&gt;= tf.transpose(x,perm=[2,0,1&lt;span&gt;])
            x &lt;/span&gt;= tf.reshape(x, shape=[-1&lt;span&gt;, input_size])
            weights &lt;/span&gt;=&lt;span&gt; tf.get_variable(
                &lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;weights&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;, [input_size, output_size], initializer=&lt;span&gt;tf.contrib.layers.xavier_initializer())
            x &lt;/span&gt;= tf.matmul(x, weights)  &lt;span&gt;#&lt;/span&gt;&lt;span&gt; (batch_size * self._nodes, output_size)&lt;/span&gt;
            biases =&lt;span&gt; tf.get_variable(
                &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;biases&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;, [output_size], initializer=tf.constant_initializer(bias, dtype=&lt;span&gt;tf.float32))
            x &lt;/span&gt;=&lt;span&gt; tf.nn.bias_add(x, biases)
            x &lt;/span&gt;= tf.reshape(x, shape=[-1&lt;span&gt;, self._nodes, output_size])
            x &lt;/span&gt;= tf.reshape(x, shape=[-1, self._nodes *&lt;span&gt; output_size])
        &lt;/span&gt;&lt;span&gt;return&lt;/span&gt; x
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;函数开头对特征矩阵进行构建：使用expand_dims增加输入维度，再使用将当前状态转化为第二维为数据点数量，第三维为gru单元数量的列表，使用concat在第二个维度拼接张量，最后得到一个长度为数据点数量的列表。get_variable_scope获取变量后，将得到的特征矩阵与邻接矩阵相乘。在tf.nn.bias_add处激活得到两层GCN，对应公式：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1829854/202008/1829854-20200812013536560-354778843.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;


&lt;p&gt;最终返回输出值x。此函数经历了很多张量的形式转换，对应论文空间关系建模过程。&lt;/p&gt;
&lt;p&gt;关于论文中TGCN部分代码的解读结束了，模块化的编程对于学习实验手法有很多值得学习的地方，对于TGCN本身的实现、涉及张量的处理变换也有很多可以借鉴的地方。&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
<pubDate>Tue, 11 Aug 2020 17:38:00 +0000</pubDate>
<dc:creator>那不太可能</dc:creator>
<og:description>论文链接：https://arxiv.org/abs/1811.05320 博客原作者Missouter，博客链接https://www.cnblogs.com/missouter/，欢迎交流。 解读</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/missouter/p/13488342.html</dc:identifier>
</item>
<item>
<title>DRF内置认证组件之自定义认证系统 - 嗨，阿良</title>
<link>http://www.cnblogs.com/fengting0913/p/13488205.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/fengting0913/p/13488205.html</guid>
<description>&lt;p&gt;文中详细记录了DRF内置认证组件的认证业务，在此基础上如何自定义认证系统的流程&lt;/p&gt;&lt;div id=&quot;cnblogs_post_body&quot; readability=&quot;197.5&quot;&gt;
&lt;h2 id=&quot;自定义token认证&quot;&gt;自定义token认证&lt;/h2&gt;
&lt;p&gt;我们知道，在django项目中不管路由以及对应的视图类是如何写的，都会走到 &lt;code&gt;dispatch&lt;/code&gt; 方法，进行路由分发，&lt;/p&gt;
&lt;p&gt;在阅读 &lt;code&gt;APIView类中的dispatch&lt;/code&gt; 方法的源码中，有个 &lt;code&gt;self.initial(request, *args, **kwargs)&lt;/code&gt;，可以发现认证、权限、频率这三个默认组件都在这个方法里面，如果我们自己没有定义这三个组件的配置，那么就会使用源码中默认的一些配置。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;源码：&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-python&quot;&gt;# Ensure that the incoming request is permitted

#实现认证
self.perform_authentication(request)

#权限判断
self.check_permissions(request)

#控制访问频率
elf.check_throttles(request)
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;目前为止大家知道的认证机制是不是有cookie、session啊，session更安全一些，但是你会发现session的信息都存到咱们的服务器上了，如果用户量很大的话，服务器压力是比较大的，并且django的session存到了django_session表中，不是很好操作，但是一般的场景都是没有啥问题的，现在生产中使用的一个叫做token机制的方式比较多，现在我们是不是就知道个csrf_token啊，其实token有很多种写法，如何加密，你是hashlib啊还是base64啊还是hmac啊等，是不是加上过期时间啊，是不是要加上一个secret_key(客户端与服务端协商好的一个字符串，作为双方的认证依据)，是不是要持续刷新啊(有效时间要短，不断的更新token，如果在这么短的时间内还是被别人拿走了token，模拟了用户状态，那这个基本是没有办法的，但是你可以在网络或者网络设备中加安全，存客户的ip地址等，防黑客)等等。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;大致流程图解：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;　　　　　　&lt;img src=&quot;https://img2018.cnblogs.com/blog/988061/201904/988061-20190418154106265-841821011.png&quot; alt=&quot;img&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;

&lt;p&gt;首先我们需要创建一个表，用户表，里面放一个token字段，其实一般我都是放到两个表里面，和用户表是一个一对一关系的表，看代码：&lt;/p&gt;
&lt;p&gt;models.py内容如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-python&quot;&gt;################################# user表 ###############################
class User(models.Model):
    user = models.CharField(max_length=32)
    pwd = models.CharField(max_length=32)
    type_choice=((1,&quot;VIP&quot;),(2,&quot;SVIP&quot;),(3,&quot;SSVIP&quot;))
    user_type = models.IntegerField(choices=type_choice)

    
class UserToken(models.Model):
    user = models.OneToOneField(to=User) #一对一到用户表
    token = models.CharField(max_length=128) #设置的长度大一些
    # expire_time = models.DateTimeField() #如果做超时时间限制，可以在这里加个字段
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;urls.py内容如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-python&quot;&gt;#登陆认证接口
url(r'^login/$', views.LoginView.as_view(),), #别忘了$符号结尾
&lt;/code&gt;
&lt;/pre&gt;

&lt;p&gt;views.py内容如下：&lt;strong&gt;每次登陆成功之后刷新token值&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-python&quot;&gt;###################login逻辑接口#######################
#关于逻辑接口而不是提供数据的接口，我们不用ModelViewSet，而是直接写个类，继承APIView，然后在类里面直接写咱的逻辑

import uuid
import os
import json


class LoginView(APIView):
    
    
    #从前后端分离的项目来讲，get请求不需要写，因为get就是个要登陆页面的操作，vue就搞定了，所以我们这里直接写post请求就可以了
    def post(self,request):
        # 一般，请求过来之后，我们后端做出的响应，都是个字典，不仅包含错误信息，还有要状态码等，让客户端明白到底发生了什么事情
        # 'code'的值，1表示成功，0表示失败,2表示其他错误(自己可以做更细致的错误代码昂)
        res = {'code': 1, 'msg': None, 'user': None,'token':None}
        print(request.data)
        try:
            user = request.data.get('user')
            pwd = request.data.get('pwd')
            # 数据库中查询
            user_obj = models.User.objects.filter(user=user, pwd=pwd).first()
            if user_obj:
                res['user'] = user_obj.user
                # 添加token，用到咱们usertoken表
                # models.UserToken.objects.create(user=user,token='123456')
                # 创建token随机字符串，我写了两个方式，简写的昂，最好再加密一下
                random_str = uuid.uuid4()
                # random_str = os.urandom(16) bytes类型的16位的随机字符串
                models.UserToken.objects.update_or_create(
                    user=user_obj,  # 查找筛选条件
                    defaults={  # 添加或者更新的数据
                        &quot;token&quot;: random_str,
                    }
                )
                res['token'] = random_str
                res['msg'] = '登陆成功'
            else:
                res['code'] = 0
                res['msg'] = '用户名或者密码错误'
                return Response(res)
        except Exception as e:
            res['code'] = 2
            res['msg'] = str(e)

        return Response(res)
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;通过上面的代码我们将token返回给了用户，那么以后用户不管发送什么请求，都要带着我给它的token值来访问，认证token通过才行，并且更新token。&lt;/p&gt;
&lt;p&gt;将来有些数据接口是必须要求用户登陆之后才能获取到数据，所以将来用户登陆完成之后，每次再过来请求，都要带着token来，作为身份认证的依据。&lt;/p&gt;
&lt;h2 id=&quot;drf内置的认证组件&quot;&gt;DRF内置的认证组件&lt;/h2&gt;
&lt;p&gt;在DRF的全局配置信息中，有DRF内置组件的相关配置 ：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-python&quot;&gt;# 基于django基础配置信息上的drf框架的配置信息

REST_FRAMEWORK = {
    
    ...
    
    'DEFAULT_AUTHENTICATION_CLASSES': (
        'rest_framework.authentication.SessionAuthentication',
    ),
    
    ...
    
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;补充：&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote readability=&quot;12&quot;&gt;
&lt;p&gt;django项目的request对象中有一个user属性，是一个默认的假用户 &lt;code&gt;AnonymousUser&lt;/code&gt; ，当用户未登录admin后台管理系统时，&lt;code&gt;request.user = AnonymousUser&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;若登录了admin后台，在django内置的认证系统中，request.user = 当前登录用户&lt;/p&gt;
&lt;p&gt;DRF中内置的认证系统 &lt;code&gt;'rest_framework.authentication.SessionAuthentication'&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;跟django中的认证系统挂钩的，使用的也是admin后台的用户信息&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;DRF内置组件依据session信息做认证，根据上面的叙述，session不适合做大型项目的认证载体，太重了！所以我们可以借助DRF内置的认证系统进行自定义认证系统。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;以下是其认证机制的部分源码实现：&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-python&quot;&gt;def _authenticate(self):
        &quot;&quot;&quot;
        Attempt to authenticate the request using each authentication instance
        in turn.
        &quot;&quot;&quot;
        for authenticator in self.authenticators:
            try:
                user_auth_tuple = authenticator.authenticate(self) 
            except exceptions.APIException:
                self._not_authenticated()
                raise

            if user_auth_tuple is not None:
                self._authenticator = authenticator
                #值得注意的是，self是APIView封装的新的request对象
                self.user, self.auth = user_auth_tuple 
                return   #退出了这个函数，函数就不会执行了，不会再循环了，所以如果你的第一个认证类有返回值，那么第二个认证类就不会执行了，所以别忘了return是结束函数的意思，所以如果你有多个认证类，那么返回值放到最后一个类里面
&lt;/code&gt;
&lt;/pre&gt;
&lt;pre&gt;
&lt;code class=&quot;language-python&quot;&gt;from rest_framework.authentication import BaseAuthentication

# 'BaseAuthentication'这个类源码实现中有个'authenticate'方法，我们可以重写这个类进行自定制咱们的认证系统。
&quot;&quot;&quot;
    def authenticate(self, request):
        &quot;&quot;&quot;
        Authenticate the request and return a two-tuple of (user, token).
        &quot;&quot;&quot;
        raise NotImplementedError(&quot;.authenticate() must be overridden.&quot;)
&quot;&quot;&quot;  
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;一、基于drf提供的认证类BaseAuthentication进行自定制认证系统&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;1、自定义认证类MyAuthentication，继承自BaseAuthentication类且重写其authenticate方法&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-python&quot;&gt;# utils.auth.py

from rest_framework.authentication import BaseAuthentication
from rest_framework.exceptions import AuthenticationFailed


class MyAuthentication(BaseAuthentication):
    
    def authenticate(self, request):
        
        if 1:
            return &quot;aliang&quot;, &quot;fengting007&quot;
        
        else:
            return AuthenticationFailed(&quot;认证失败！&quot;)
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;2、全局配置&lt;/p&gt;
&lt;p&gt;对自定义的认证类MyAuthentication中的认证流程进行全局配置，即在访问每个url时都要经过自定义的认证逻辑&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;在settings.py配置文件中进行配置&lt;/li&gt;
&lt;/ul&gt;&lt;pre&gt;
&lt;code class=&quot;language-python&quot;&gt;# 基于django基础配置信息上的drf框架的配置信息

REST_FRAMEWORK = {
    
    ...
    
    'DEFAULT_AUTHENTICATION_CLASSES': (
        
        # 自定义认证类的路径
        'four.utils.auth.MyAuthentication',
        
        # 注释掉drf内置的session认证系统，使用自己定制的！
        # 'rest_framework.authentication.SessionAuthentication',
    ),
    
    ...
    
}

&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;3、局部配置&lt;/p&gt;
&lt;p&gt;即在访问某个指定的url时，需要认证后才可以获取到响应页面，而不是访问所有url都需要认证，这就要在指定的url所映射的类视图中进行定制&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-python&quot;&gt;from rest_framework.views import APIView
from rest_framework.response import Response
from four.utils.auth import MyAuthentication

class AuthAPIView(APIView):
    
    # 访问AuthAPIView类视图所对应的url请求响应页面时，要经过自定制的MyAuthentication类的认证逻辑！
    authentication_classes = [MyAuthentication,]
    
    def get(self, request):
        
        print(request.user)  # 'aliang'
        print(request.auth)  # 'fengting007'
        
        return Response({'msg':'嗨，man!'})
    

&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;二、不继承drf提供的认证类BaseAuthentication自定制认证类&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-python&quot;&gt;class MyAuthentication():
    
    def authenticate_header(self,request):
         pass
    
    # authenticate方法是固定的,并且必须有个参数，这个参数是新的request对象
    def authenticate(self, request):
        
        if 1:
            
            # 源码中会发现，这个方法会有两个返回值，并且这两个返回值封装到了新的request对象中了，request.user--&amp;gt;用户名 和 request.auth--&amp;gt;token值，这两个值作为认证结束后的返回结果
                
            # 如下操作即：
                # request.user = 'aliang'
                # request.auth = 'fengting007'
                
            return &quot;aliang&quot;, &quot;fengting007&quot;
 
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;至于此自定义认证类的全局配置以及局部配置的方法与上面的流程是一致的。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-python&quot;&gt;# 局部配置示例：
from app01.serializer import BookSerializers
from four.utils.auth import MyAuthentication


class BookView(APIView):
    
    #认证组件肯定是在get、post等方法执行之前执行的，源码中这个组件是在dispatch的地方调用的
    authentication_classes = [MyAuthentication,] #认证类可以写多个，一个一个的顺序验证
    
    def get(self,request):
 
        #这样就拿到了上面MyAuthentication类的authenticate方法的两个返回值
        print(request.user)  
        print(request.auth)
        
        book_obj_list = models.Book.objects.all()
        s_books = BookSerializers(book_obj_list,many=True)
        return Response(s_books.data)

&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;</description>
<pubDate>Tue, 11 Aug 2020 16:08:00 +0000</pubDate>
<dc:creator>嗨，阿良</dc:creator>
<og:description>文中详细记录了DRF内置认证组件的认证业务，在此基础上如何自定义认证系统的流程</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/fengting0913/p/13488205.html</dc:identifier>
</item>
<item>
<title>ROS 八叉树地图构建 - 给 octomap_server 增加半径滤波器！ - 登龙</title>
<link>http://www.cnblogs.com/dlonng/p/13488150.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/dlonng/p/13488150.html</guid>
<description>&lt;p&gt;为了在每帧点云中滤除噪声点，选择了半径滤波器，也用高斯滤波器测试过，但是没有半径效果好，这里记录下在 octomap_server 中增加半径滤波器的步骤，并在 launch 中配置滤波器参数。&lt;/p&gt;
&lt;h2 id=&quot;一、半径滤波器基本原理&quot;&gt;一、半径滤波器基本原理&lt;/h2&gt;
&lt;p&gt;放一张汇报用的 PPT 截图：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://dlonng.oss-cn-shenzhen.aliyuncs.com/blog/banjing_filter.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;原理很简单就是判断一个点云周围（半径 R）有没有足够多（K）的邻居点，如果没有就删除这个点，否则就保留。&lt;/p&gt;
&lt;h2 id=&quot;二、基本用法&quot;&gt;二、基本用法&lt;/h2&gt;
&lt;p&gt;我一般学习技术喜欢到官网看最原始的教程：&lt;a href=&quot;https://pcl.readthedocs.io/projects/tutorials/en/latest/remove_outliers.html#remove-outliers&quot;&gt;Removing outliers using a Conditional or RadiusOutlier removal&lt;/a&gt;，这个教程介绍了半径滤波器（我不清楚中文名到底叫什么滤波器）的基本用法：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-cpp&quot;&gt;#include &amp;lt;pcl/point_types.h&amp;gt;
#include &amp;lt;pcl/filters/radius_outlier_removal.h&amp;gt;

// 输入待滤波的原始点云指针
pcl::PointCloud&amp;lt;pcl::PointXYZ&amp;gt;::Ptr cloud (new pcl::PointCloud&amp;lt;pcl::PointXYZ&amp;gt;);

// 保存滤波后的点云指针
pcl::PointCloud&amp;lt;pcl::PointXYZ&amp;gt;::Ptr cloud_filtered (new pcl::PointCloud&amp;lt;pcl::PointXYZ&amp;gt;);

// 创建滤波器对象
pcl::RadiusOutlierRemoval&amp;lt;pcl::PointXYZ&amp;gt; outrem;

// 设置要滤波的点云
outrem.setInputCloud(cloud);

// 设置滤波半径
outrem.setRadiusSearch(0.8);

// 设置滤波最少近邻数
outrem.setMinNeighborsInRadius (2);

// 执行半径滤波
outrem.filter (*cloud_filtered);
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;如果第一次使用 PCL 的滤波器，可以把这个教程自己运行一遍，我之前运行过了，这次就不贴代码了，下面分享下我在实际项目中如果使用这个半径滤波器对我的 octomap_server 构建的八叉树地图进行滤波。&lt;/p&gt;
&lt;h2 id=&quot;三、给我的地图滤波&quot;&gt;三、给我的地图滤波&lt;/h2&gt;
&lt;h3 id=&quot;31-定义半径滤波器参数&quot;&gt;3.1 定义半径滤波器参数&lt;/h3&gt;
&lt;p&gt;半径滤波器有 2 个参数：滤波半径和半径内部邻居数，注意数据类型&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-cpp&quot;&gt;// 滤波半径
double m_outrem_radius;

// 半径内的邻居数
int m_outrem_neighbors;
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;在构造函数初始化列表中初始化：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-cpp&quot;&gt;OctomapServer::OctomapServer(const ros::NodeHandle private_nh_, const ros::NodeHandle &amp;amp;nh_)
: ...,
  m_outrem_radius(-std::numeric_limits&amp;lt;double&amp;gt;::max()),
  m_outrem_neighbors(-std::numeric_limits&amp;lt;int&amp;gt;::max()),
  ...
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;从 launch 中读取启动参数：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-cpp&quot;&gt;// add outrem filter
m_nh_private.param(&quot;outrem_radius&quot;, m_outrem_radius, m_outrem_radius);
m_nh_private.param(&quot;outrem_neighbors&quot;, m_outrem_neighbors, m_outrem_neighbors);
&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;32-执行半径滤波&quot;&gt;3.2 执行半径滤波&lt;/h3&gt;
&lt;p&gt;在 InsertPointCloudCallBack 函数的 PassThough 前执行半径滤波，即对每一帧点云在构建八叉树地图前进行滤波，主要是为了去掉单独的离群点：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-cpp&quot;&gt;// 对一帧 pc 点云进行半径滤波
pcl::RadiusOutlierRemoval&amp;lt;pcl::PointXYZRGB&amp;gt; outrem;

// 这里需要传递指针，因为我的 pc 不是指针，所以这里做了 makeShared
outrem.setInputCloud(pc.makeShared());

// 设置滤波半径，这里设置为 1m
outrem.setRadiusSearch(m_outrem_radius); 

// 设置滤波近邻数，这里设置为 10 个
outrem.setMinNeighborsInRadius (m_outrem_neighbors);

// 执行滤波
outrem.filter(pc);
&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;33-在-launch-中配置半径滤波器参数&quot;&gt;3.3 在 launch 中配置半径滤波器参数&lt;/h3&gt;
&lt;pre&gt;
&lt;code class=&quot;language-xml&quot;&gt;&amp;lt;param name = &quot;outrem_radius&quot; type = &quot;double&quot; value = &quot;1.0&quot;&amp;gt;
&amp;lt;param name = &quot;outrem_neighbors&quot; type = &quot;int&quot; value = &quot;10&quot;&amp;gt;
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;这样以后就可以从 launch 中直接配置滤波器的参数了，不用每次修改再重新编译，这样调试起来非常方便。&lt;/p&gt;
&lt;h3 id=&quot;34-滤波结果&quot;&gt;3.4 滤波结果&lt;/h3&gt;
&lt;p&gt;这是原始地图，15cm 分辨率，红框内部有很多单个的点：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://dlonng.oss-cn-shenzhen.aliyuncs.com/blog/banjing_filter_before.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;这是滤波后的效果，滤波半径 1m，近邻点 10 个：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://dlonng.oss-cn-shenzhen.aliyuncs.com/blog/banjing_filter_after.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;效果还是可以的，希望能对你有帮助，如果使用其他的滤波器，按照官方的教程来就行了，掌握学习方法才是最重要的：）&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://dlonng.oss-cn-shenzhen.aliyuncs.com/yingliu_code/yinliu_code.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
</description>
<pubDate>Tue, 11 Aug 2020 15:51:00 +0000</pubDate>
<dc:creator>登龙</dc:creator>
<og:description>为了在每帧点云中滤除噪声点，选择了半径滤波器，也用高斯滤波器测试过，但是没有半径效果好，这里记录下在 octomap_server 中增加半径滤波器的步骤，并在 launch 中配置滤波器参数。 一、</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/dlonng/p/13488150.html</dc:identifier>
</item>
<item>
<title>go微服务系列(四) - gRPC入门 - 宝树呐</title>
<link>http://www.cnblogs.com/baoshu/p/13488106.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/baoshu/p/13488106.html</guid>
<description>&lt;h2 id=&quot;1-前言&quot;&gt;&lt;span id=&quot;head1&quot;&gt;1. 前言&lt;/span&gt;&lt;/h2&gt;
&lt;p&gt;之前学习的go的微服务之间还是通过&lt;code&gt;REST API&lt;/code&gt;的方式互相调用的，但既然要学习微服务，&lt;code&gt;gRPC&lt;/code&gt;肯定是一个绕不过去的需要学习的技术, 所以就开搞吧&lt;/p&gt;
&lt;h2 id=&quot;2-grpc与protobuf简介&quot;&gt;&lt;span id=&quot;head2&quot;&gt;2. gRPC与Protobuf简介&lt;/span&gt;&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;gRPC&lt;/code&gt;是一款&lt;strong&gt;语言中立&lt;/strong&gt;、&lt;strong&gt;平台中立&lt;/strong&gt;、开源的远程过程调用系统&lt;/p&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;即：&lt;code&gt;gRPC&lt;/code&gt;客户端和服务端可以在多种环境中运行和交互，例如用&lt;code&gt;java&lt;/code&gt;写一个服务端，可以用go语言写客户端调用&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;微服务架构中，由于每个服务对应的代码库是独立运行的，无法直接调用，彼此间的通信就是个大问题.&lt;/p&gt;
&lt;p&gt;gRPC可以实现将大的项目拆分为多个小且独立的业务模块，也就是服务。各服务间使用高效的&lt;code&gt;protobuf&lt;/code&gt;协议进行RPC调用，gRPC默认使用&lt;code&gt;protocol buffers&lt;/code&gt;，这是google开源的一套成熟的结构数据序列化机制&lt;/p&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;当然也可以使用其他数据格式如JSON&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;可以用proto files创建gRPC服务，用message类型来定义方法参数和返回类型&lt;/p&gt;
&lt;h2 id=&quot;3-安装&quot;&gt;&lt;span id=&quot;head3&quot;&gt;3. 安装&lt;/span&gt;&lt;/h2&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;第一步：下载grpc通用编译器&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;如下图，解压出来因平台而异会是一个&lt;code&gt;protoc&lt;/code&gt;或者&lt;code&gt;protoc.exe&lt;/code&gt;&lt;/p&gt;
&lt;blockquote readability=&quot;0&quot;&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/protocolbuffers/protobuf/releases&quot;&gt;https://github.com/protocolbuffers/protobuf/releases&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&quot;https://tva1.sinaimg.cn/large/007S8ZIlgy1ghn71b14sxj312l0g0di1.jpg&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;第二步：把下载的二进制文件路径添加到环境变量中&lt;/strong&gt;(为了能全局访问protoc)
&lt;ul&gt;&lt;li&gt;这里以为mac为例子&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;pre&gt;
&lt;code class=&quot;language-shell&quot;&gt;# 打开存放环境变量的文件
vim ~/.bash_profile

# 添加如下，后面是路径
alias protoc=&quot;/Users/emm/others/protoc-3.12.4-osx-x86_64/bin/protoc&quot;

# 刷新环境变量
source ./.bash_profile
&lt;/code&gt;
&lt;/pre&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;第三步: 安装go专用的protoc的生成器&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;go get github.com/golang/protobuf/protoc-gen-go&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;安装后会在&lt;code&gt;GOPATH&lt;/code&gt;目录下生成可执行文件，protobuf的编译器插件&lt;code&gt;protoc-gen-go&lt;/code&gt;，等下执行&lt;code&gt;protoc&lt;/code&gt;命令会自动调用这个插件&lt;/p&gt;
&lt;h2 id=&quot;4-中间文件演示&quot;&gt;&lt;span id=&quot;head4&quot;&gt;4. 中间文件演示&lt;/span&gt;&lt;/h2&gt;
&lt;h3 id=&quot;41-编写中间文件&quot;&gt;&lt;span id=&quot;head5&quot;&gt;4.1 编写中间文件&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;这里新建一个pbfiles文件夹用于存放&lt;code&gt;protoc&lt;/code&gt;文件&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-protoc&quot;&gt;// 这个就是protobuf的中间文件

// 指定的当前proto语法的版本，有2和3
syntax = &quot;proto3&quot;;

// 指定等会文件生成出来的package
package service;

// 定义request
message ProductRequest{
  int32 prod_id = 1; // 1代表顺序
}

// 定义response
message ProductResponse{
  int32 prod_stock = 1; // 1代表顺序
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;img src=&quot;https://tva1.sinaimg.cn/large/007S8ZIlgy1ghn8eityngj30me0cp0uu.jpg&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h3 id=&quot;42-运行protoc命令编译成go中间文件&quot;&gt;&lt;span id=&quot;head6&quot;&gt;4.2 运行protoc命令编译成go中间文件&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;然后运行以下的命令来生成&lt;code&gt;.go&lt;/code&gt;结尾的文件&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;下面的命令就是我们刚刚下的&lt;code&gt;protoc&lt;/code&gt;包以及&lt;code&gt;protoc-gen-go&lt;/code&gt;插件的作用&lt;/li&gt;
&lt;/ul&gt;&lt;pre&gt;
&lt;code class=&quot;language-shell&quot;&gt;# 编译Product.proto之后输出到service文件夹
protoc --go_out=../service Product.proto
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;如下就在service文件夹自动生成了一个go文件，并且它提示我们不要去修改它&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://tva1.sinaimg.cn/large/007S8ZIlgy1ghn8jpg8uzj31gk0k50wx.jpg&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h2 id=&quot;5-创建grpc服务端&quot;&gt;&lt;span id=&quot;head7&quot;&gt;5. 创建gRPC服务端&lt;/span&gt;&lt;/h2&gt;
&lt;h3 id=&quot;51-新建productprotoc&quot;&gt;&lt;span id=&quot;head8&quot;&gt;5.1 新建Product.protoc&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;这个protoc文件比上面的多出了一个service的定义和里面的一个方法的定义&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-protoc&quot;&gt;// 这个就是protobuf的中间文件

// 指定的当前proto语法的版本，有2和3
syntax = &quot;proto3&quot;;

// 指定等会文件生成出来的package
package service;

// 定义request model
message ProductRequest{
  int32 prod_id = 1; // 1代表顺序
}

// 定义response model
message ProductResponse{
  int32 prod_stock = 1; // 1代表顺序
}

// 定义服务主体
service ProdService{
  // 定义方法
  rpc GetProductStock(ProductRequest) returns(ProductResponse);
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;52-运行protoc命令&quot;&gt;&lt;span id=&quot;head9&quot;&gt;5.2 运行protoc命令&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;注意&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;这里的protoc命令和之前的命令相比有点不一样&lt;/li&gt;
&lt;/ul&gt;&lt;pre&gt;
&lt;code&gt;protoc --go_out=plugins=grpc:../service Product.proto
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;然后还是会在service文件夹下生成一个&lt;code&gt;.go&lt;/code&gt;的文件&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;有两个比较需要注意的&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;RegisterProdServiceServer&lt;/li&gt;
&lt;/ol&gt;&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;后面需要在server中调用这个来注册&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&quot;https://tva1.sinaimg.cn/large/007S8ZIlgy1ghn9mmp3j2j30nd0d776h.jpg&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;ol start=&quot;2&quot;&gt;&lt;li&gt;ProdServiceServer的接口定义&lt;/li&gt;
&lt;/ol&gt;&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;我们需要继承这个接口，即实现它所有的方法&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&quot;https://tva1.sinaimg.cn/large/007S8ZIlgy1ghn9nq5pd4j30p50ccmyx.jpg&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h3 id=&quot;53-实现registerprodserviceserver接口&quot;&gt;&lt;span id=&quot;head10&quot;&gt;5.3 实现RegisterProdServiceServer接口&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;上面我们在&lt;code&gt;protoc&lt;/code&gt;文件中定义了一个&lt;code&gt;ProdService&lt;/code&gt;中包含了一个&lt;code&gt;GetProductStock&lt;/code&gt;的方法&lt;/p&gt;
&lt;p&gt;这里我们要实现自动生成的go文件中的接口&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-go&quot;&gt;package service

import &quot;context&quot;

type ProdService struct {
}

func (ps *ProdService) GetProductStock(ctx context.Context, request *ProductRequest) (*ProductResponse, error) {
        return &amp;amp;ProductResponse{ProdStock: request.ProdId}, nil
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;img src=&quot;https://tva1.sinaimg.cn/large/007S8ZIlgy1ghn9q844nuj30zn0efjtz.jpg&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h3 id=&quot;54-准备工作完成，创建main函数将服务端跑起来&quot;&gt;&lt;span id=&quot;head11&quot;&gt;5.4 准备工作完成，创建main函数将服务端跑起来&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;前面的都是准备工作，这里是真正把服务端跑起来的操作&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;下面是服务端代码：&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-go&quot;&gt;package main

import (
        &quot;gomicro-quickstart/grpc_demo/service&quot;
        &quot;google.golang.org/grpc&quot;
        &quot;log&quot;
        &quot;net&quot;
)

func main() {
        // 1. new一个grpc的server
        rpcServer := grpc.NewServer()

        // 2. 将刚刚我们新建的ProdService注册进去
        service.RegisterProdServiceServer(rpcServer, new(service.ProdService))

        // 3. 新建一个listener，以tcp方式监听8082端口
        listener, err := net.Listen(&quot;tcp&quot;, &quot;:8082&quot;)
        if err != nil {
                log.Fatal(&quot;服务监听端口失败&quot;, err)
        }

        // 4. 运行rpcServer，传入listener
        _ = rpcServer.Serve(listener)
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;排坑&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;如果遇见类似&lt;code&gt;undefined: grpc.SupportPackageIsVersion6&lt;/code&gt;和&lt;code&gt;undefined: grpc.ClientConnInterface&lt;/code&gt;的错误，可以修改go.mod将grpc版本改到1.27.0&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;img src=&quot;https://tva1.sinaimg.cn/large/007S8ZIlgy1ghn9v5g03mj30ni0aw0ua.jpg&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;hr/&gt;&lt;h2 id=&quot;6-创建grpc客户端&quot;&gt;&lt;span id=&quot;head12&quot;&gt;6. 创建gRPC客户端&lt;/span&gt;&lt;/h2&gt;
&lt;ul&gt;&lt;li&gt;新建一个&lt;code&gt;grpc_client&lt;/code&gt;文件夹存放客户端相关的&lt;/li&gt;
&lt;li&gt;并在&lt;code&gt;grpc_client&lt;/code&gt;文件夹下再新建一个&lt;code&gt;service&lt;/code&gt;文件夹&lt;/li&gt;
&lt;/ul&gt;&lt;h3 id=&quot;61-拷贝productpbgo到客户端service文件夹下&quot;&gt;&lt;span id=&quot;head13&quot;&gt;6.1 拷贝Product.pb.go到客户端service文件夹下&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;https://tva1.sinaimg.cn/large/007S8ZIlgy1ghna79yhtbj308g02owef.jpg&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h3 id=&quot;62-编写client的main函数&quot;&gt;&lt;span id=&quot;head14&quot;&gt;6.2 编写client的main函数&lt;/span&gt;&lt;/h3&gt;
&lt;pre&gt;
&lt;code class=&quot;language-go&quot;&gt;package main

import (
        &quot;context&quot;
        &quot;fmt&quot;
        &quot;gomicro-quickstart/grpc_client/service&quot;
        &quot;google.golang.org/grpc&quot;
        &quot;log&quot;
)

func main() {
        // 1. 新建连接，端口是服务端开放的8082端口
        // 并且添加grpc.WithInsecure()，不然没有证书会报错
        conn, err := grpc.Dial(&quot;:8082&quot;, grpc.WithInsecure())
        if err != nil {
                log.Fatal(err)
        }

        // 退出时关闭链接
        defer conn.Close()

        // 2. 调用Product.pb.go中的NewProdServiceClient方法
        productServiceClient := service.NewProdServiceClient(conn)

        // 3. 直接像调用本地方法一样调用GetProductStock方法
        resp, err := productServiceClient.GetProductStock(context.Background(), &amp;amp;service.ProductRequest{ProdId: 233})
        if err != nil {
                log.Fatal(&quot;调用gRPC方法错误: &quot;, err)
        }

        fmt.Println(&quot;调用gRPC方法成功，ProdStock = &quot;, resp.ProdStock)
}

&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;63-运行并显示结果&quot;&gt;&lt;span id=&quot;head15&quot;&gt;6.3 运行并显示结果&lt;/span&gt;&lt;/h3&gt;
&lt;ul&gt;&lt;li&gt;先把服务端运行起来&lt;/li&gt;
&lt;li&gt;再把客户端运行起来&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;然后客户端输出正确的结果，第一个go的gRPC调用运行成功&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://tva1.sinaimg.cn/large/007S8ZIlgy1ghnalvrgw4j31c10pzgqu.jpg&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
</description>
<pubDate>Tue, 11 Aug 2020 15:39:00 +0000</pubDate>
<dc:creator>宝树呐</dc:creator>
<og:description>1. 前言 2. gRPC与Protobuf简介 3. 安装 4. 中间文件演示 4.1 编写中间文件 4.2 运行protoc命令编译成go中间文件 5. 创建gRPC服务端 5.1 新建Produ</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/baoshu/p/13488106.html</dc:identifier>
</item>
<item>
<title>.NET或.NET Core Web APi基于tus协议实现断点续传 - Jeffcky</title>
<link>http://www.cnblogs.com/CreateMyself/p/13466457.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/CreateMyself/p/13466457.html</guid>
<description>&lt;h2&gt;前言&lt;/h2&gt;
&lt;p&gt;前两天我采用技巧式方案基本实现大文件分片上传，这里只是重点在于个人思路和亲身实践，若在实际生产环境要求比较高的话肯定不行，仍存在一些问题需要深入处理，本文继续在之前基础上给出基于tus协议的轮子方案，本打算再次尝试利用.NET Core实现此协议，但在github上一搜索早在2016年就已有此协议对应的.NET和.NET Core方案，并且一直更新到最近的.NET Core 3.x版本，完全满足各位所需，本文是我写出的一点demo。&lt;/p&gt;
&lt;h2&gt;基于tus协议实现断点续传演示&lt;/h2&gt;
&lt;p&gt; &lt;img src=&quot;https://img2020.cnblogs.com/blog/589642/202008/589642-20200811232109725-1158285860.gif&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h2&gt;基于tus协议tusdotnet方案基本demo&lt;/h2&gt;
&lt;p&gt;关于此协议实现原理这里不做阐述，请参照上述github地址自行了解，本文只是给出.NET Core方案下的基本demo，我们上传一个大文件然后通过进度显示上传进度以及对上传可暂停可继续，专业点讲就是断点续传，首先肯定是引入tus脚本和需要用到的bootstrap样式，我们将进度条默认隐藏，当上传时才显示，所以我们给出如下HTML。&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;35&quot;&gt;
&lt;pre&gt;
&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;div &lt;/span&gt;&lt;span&gt;class&lt;/span&gt;&lt;span&gt;=&quot;form-horizontal&quot;&lt;/span&gt;&lt;span&gt; style&lt;/span&gt;&lt;span&gt;=&quot;margin-top:80px;&quot;&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
    &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;div &lt;/span&gt;&lt;span&gt;class&lt;/span&gt;&lt;span&gt;=&quot;form-group&quot;&lt;/span&gt;&lt;span&gt; id&lt;/span&gt;&lt;span&gt;=&quot;progress-group&quot;&lt;/span&gt;&lt;span&gt; style&lt;/span&gt;&lt;span&gt;=&quot;display:none;&quot;&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
        &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;div &lt;/span&gt;&lt;span&gt;id&lt;/span&gt;&lt;span&gt;=&quot;size&quot;&lt;/span&gt;&lt;span&gt;&amp;gt;&amp;lt;/&lt;/span&gt;&lt;span&gt;div&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
        &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;div &lt;/span&gt;&lt;span&gt;class&lt;/span&gt;&lt;span&gt;=&quot;progress&quot;&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
            &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;div &lt;/span&gt;&lt;span&gt;id&lt;/span&gt;&lt;span&gt;=&quot;progress&quot;&lt;/span&gt;&lt;span&gt; class&lt;/span&gt;&lt;span&gt;=&quot;progress-bar progress-bar-success progress-bar-animated progress-bar-striped&quot;&lt;/span&gt;&lt;span&gt; role&lt;/span&gt;&lt;span&gt;=&quot;progressbar&quot;&lt;/span&gt;&lt;span&gt;
                 aria-valuemin&lt;/span&gt;&lt;span&gt;=&quot;0&quot;&lt;/span&gt;&lt;span&gt; aria-valuemax&lt;/span&gt;&lt;span&gt;=&quot;100&quot;&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
                &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;span &lt;/span&gt;&lt;span&gt;id&lt;/span&gt;&lt;span&gt;=&quot;percentage&quot;&lt;/span&gt;&lt;span&gt;&amp;gt;&amp;lt;/&lt;/span&gt;&lt;span&gt;span&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
            &lt;span&gt;&amp;lt;/&lt;/span&gt;&lt;span&gt;div&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
        &lt;span&gt;&amp;lt;/&lt;/span&gt;&lt;span&gt;div&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
    &lt;span&gt;&amp;lt;/&lt;/span&gt;&lt;span&gt;div&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
    &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;div &lt;/span&gt;&lt;span&gt;class&lt;/span&gt;&lt;span&gt;=&quot;form-group&quot;&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
        &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;div &lt;/span&gt;&lt;span&gt;class&lt;/span&gt;&lt;span&gt;=&quot;col-md-10&quot;&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
            &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;input &lt;/span&gt;&lt;span&gt;name&lt;/span&gt;&lt;span&gt;=&quot;file&quot;&lt;/span&gt;&lt;span&gt; id&lt;/span&gt;&lt;span&gt;=&quot;file&quot;&lt;/span&gt;&lt;span&gt; type&lt;/span&gt;&lt;span&gt;=&quot;file&quot;&lt;/span&gt; &lt;span&gt;/&amp;gt;&lt;/span&gt;
        &lt;span&gt;&amp;lt;/&lt;/span&gt;&lt;span&gt;div&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
    &lt;span&gt;&amp;lt;/&lt;/span&gt;&lt;span&gt;div&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
    &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;div &lt;/span&gt;&lt;span&gt;class&lt;/span&gt;&lt;span&gt;=&quot;form-group&quot;&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
        &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;div &lt;/span&gt;&lt;span&gt;class&lt;/span&gt;&lt;span&gt;=&quot;col-md-offset-2 col-md-10&quot;&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
            &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;input &lt;/span&gt;&lt;span&gt;type&lt;/span&gt;&lt;span&gt;=&quot;submit&quot;&lt;/span&gt;&lt;span&gt; id&lt;/span&gt;&lt;span&gt;=&quot;submit&quot;&lt;/span&gt;&lt;span&gt; value&lt;/span&gt;&lt;span&gt;=&quot;上传&quot;&lt;/span&gt;&lt;span&gt; class&lt;/span&gt;&lt;span&gt;=&quot;btn btn-success&quot;&lt;/span&gt; &lt;span&gt;/&amp;gt;&lt;/span&gt;
            &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;input &lt;/span&gt;&lt;span&gt;type&lt;/span&gt;&lt;span&gt;=&quot;button&quot;&lt;/span&gt;&lt;span&gt; id&lt;/span&gt;&lt;span&gt;=&quot;pause&quot;&lt;/span&gt;&lt;span&gt; value&lt;/span&gt;&lt;span&gt;=&quot;暂停&quot;&lt;/span&gt;&lt;span&gt; class&lt;/span&gt;&lt;span&gt;=&quot;btn btn-danger&quot;&lt;/span&gt; &lt;span&gt;/&amp;gt;&lt;/span&gt;
            &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;input &lt;/span&gt;&lt;span&gt;type&lt;/span&gt;&lt;span&gt;=&quot;button&quot;&lt;/span&gt;&lt;span&gt; id&lt;/span&gt;&lt;span&gt;=&quot;continue&quot;&lt;/span&gt;&lt;span&gt; value&lt;/span&gt;&lt;span&gt;=&quot;继续&quot;&lt;/span&gt;&lt;span&gt; class&lt;/span&gt;&lt;span&gt;=&quot;btn btn-info&quot;&lt;/span&gt; &lt;span&gt;/&amp;gt;&lt;/span&gt;
        &lt;span&gt;&amp;lt;/&lt;/span&gt;&lt;span&gt;div&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
    &lt;span&gt;&amp;lt;/&lt;/span&gt;&lt;span&gt;div&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
&lt;span&gt;&amp;lt;/&lt;/span&gt;&lt;span&gt;div&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/589642/202008/589642-20200811222352317-1894875198.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;接下来就是使用引入的tus脚本，也没什么太多要讲解的，直接上代码，这里稍微注意的是在如下元数据（metadata）属性对象定义给出实际文件名，便于在后台最终将上传的文件转换为目标文件，至少得知道文件扩展名，对吧。&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;60&quot;&gt;
&lt;pre&gt;
&amp;lt;script type=&quot;text/javascript&quot;&amp;gt;&lt;span&gt;
    $(&lt;/span&gt;&lt;span&gt;function&lt;/span&gt;&lt;span&gt; () {
        &lt;/span&gt;&lt;span&gt;var&lt;/span&gt;&lt;span&gt; upload;

        &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;上传&lt;/span&gt;
        $('#submit').click(&lt;span&gt;function&lt;/span&gt;&lt;span&gt; () {

            $(&lt;/span&gt;'#progress-group'&lt;span&gt;).show();

            &lt;/span&gt;&lt;span&gt;var&lt;/span&gt; file = $('#file')[0].files[0&lt;span&gt;];

            &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; 创建tus上传对象&lt;/span&gt;
            upload = &lt;span&gt;new&lt;/span&gt;&lt;span&gt; tus.Upload(file, {
                &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; 文件服务器上传终结点地址设置&lt;/span&gt;
                endpoint: &quot;files/&quot;&lt;span&gt;,
                &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; 重试延迟设置&lt;/span&gt;
                retryDelays: [0, 3000, 5000, 10000, 20000&lt;span&gt;],
                &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; 附件服务器所需的元数据&lt;/span&gt;
&lt;span&gt;                metadata: {
                    name: file.name,
                    contentType: file.type &lt;/span&gt;|| 'application/octet-stream'&lt;span&gt;,
                    emptyMetaKey: &lt;/span&gt;''&lt;span&gt;
                },
                &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; 回调无法通过重试解决的错误&lt;/span&gt;
                onError: &lt;span&gt;function&lt;/span&gt;&lt;span&gt; (error) {
                    console.log(&lt;/span&gt;&quot;Failed because: &quot; +&lt;span&gt; error)
                },
                &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; 上传进度回调&lt;/span&gt;
&lt;span&gt;                onProgress: onProgress,
                &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; 上传完成后回调&lt;/span&gt;
                onSuccess: &lt;span&gt;function&lt;/span&gt;&lt;span&gt; () {
                    console.log(&lt;/span&gt;&quot;Download %s from %s&quot;&lt;span&gt;, upload.file.name, upload.url)
                }
            })

            upload.start()
        });

        &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;暂停&lt;/span&gt;
        $('#pause').click(&lt;span&gt;function&lt;/span&gt;&lt;span&gt; () {
            upload.abort()
        });

        &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;继续&lt;/span&gt;
        $('#continue').click(&lt;span&gt;function&lt;/span&gt;&lt;span&gt; () {
            upload.start()
        });

        &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;上传进度展示&lt;/span&gt;
        &lt;span&gt;function&lt;/span&gt;&lt;span&gt; onProgress(bytesUploaded, bytesTotal) {
            &lt;/span&gt;&lt;span&gt;var&lt;/span&gt; percentage = (bytesUploaded / bytesTotal * 100).toFixed(2&lt;span&gt;);
            $(&lt;/span&gt;'#progress').attr('aria-valuenow'&lt;span&gt;, percentage);
            $(&lt;/span&gt;'#progress').css('width', percentage + '%'&lt;span&gt;);

            $(&lt;/span&gt;'#percentage').html(percentage + '%'&lt;span&gt;);

            &lt;/span&gt;&lt;span&gt;var&lt;/span&gt; uploadBytes =&lt;span&gt; byteToSize(bytesUploaded);
            &lt;/span&gt;&lt;span&gt;var&lt;/span&gt; totalBytes =&lt;span&gt; byteToSize(bytesTotal);

            $(&lt;/span&gt;'#size').html(uploadBytes + '/' +&lt;span&gt; totalBytes);
        }

        &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;将字节转换为Byte、KB、MB等&lt;/span&gt;
        &lt;span&gt;function&lt;/span&gt; byteToSize(bytes, separator = '', postFix = ''&lt;span&gt;) {
            &lt;/span&gt;&lt;span&gt;if&lt;/span&gt;&lt;span&gt; (bytes) {
                const sizes &lt;/span&gt;= ['Bytes', 'KB', 'MB', 'GB', 'TB'&lt;span&gt;];
                const i &lt;/span&gt;= Math.min(parseInt(Math.floor(Math.log(bytes) / Math.log(1024)).toString(), 10), sizes.length - 1&lt;span&gt;);
                &lt;/span&gt;&lt;span&gt;return&lt;/span&gt; `${(bytes / (1024 ** i)).toFixed(i ? 1 : 0&lt;span&gt;)}${separator}${sizes[i]}${postFix}`;
            }
            &lt;/span&gt;&lt;span&gt;return&lt;/span&gt; 'n/a'&lt;span&gt;;
        }
    });

&lt;/span&gt;&amp;lt;/script&amp;gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;接下来进入后台，首先安装对应tus协议实现包，如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/589642/202008/589642-20200811223327609-243814895.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;接下来则是添加tus中间件，说白了就是对tus的配置，各种配置都可满足你所需，这里我只实现了文件上传完成后将上传文件转换为目标文件的处理，紧接着将如下实现tus配置以单例形式注入即可&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;43&quot;&gt;
&lt;pre&gt;
&lt;span&gt;private&lt;/span&gt;&lt;span&gt; DefaultTusConfiguration CreateTusConfiguration(IServiceProvider serviceProvider)
{
    &lt;/span&gt;&lt;span&gt;var&lt;/span&gt; env = (IWebHostEnvironment)serviceProvider.GetRequiredService(&lt;span&gt;typeof&lt;/span&gt;&lt;span&gt;(IWebHostEnvironment));

    &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;文件上传路径&lt;/span&gt;
    &lt;span&gt;var&lt;/span&gt; tusFiles = Path.Combine(env.WebRootPath, &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;tusfiles&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;);

    &lt;/span&gt;&lt;span&gt;return&lt;/span&gt; &lt;span&gt;new&lt;/span&gt;&lt;span&gt; DefaultTusConfiguration
    {
        UrlPath &lt;/span&gt;= &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;/files&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;,
        &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;文件存储路径&lt;/span&gt;
        Store = &lt;span&gt;new&lt;/span&gt;&lt;span&gt; TusDiskStore(tusFiles),
        &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;元数据是否允许空值&lt;/span&gt;
        MetadataParsingStrategy =&lt;span&gt; MetadataParsingStrategy.AllowEmptyValues,
        &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;文件过期后不再更新&lt;/span&gt;
        Expiration = &lt;span&gt;new&lt;/span&gt; AbsoluteExpiration(TimeSpan.FromMinutes(&lt;span&gt;5&lt;/span&gt;&lt;span&gt;)),
        &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;事件处理（各种事件，满足你所需）&lt;/span&gt;
        Events = &lt;span&gt;new&lt;/span&gt;&lt;span&gt; Events
        {
            &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;上传完成事件回调&lt;/span&gt;
            OnFileCompleteAsync = &lt;span&gt;async&lt;/span&gt; ctx =&amp;gt;&lt;span&gt;
            {
                &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;获取上传文件&lt;/span&gt;
                &lt;span&gt;var&lt;/span&gt; file = &lt;span&gt;await&lt;/span&gt;&lt;span&gt; ctx.GetFileAsync();

                &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;获取上传文件元数据&lt;/span&gt;
                &lt;span&gt;var&lt;/span&gt; metadatas = &lt;span&gt;await&lt;/span&gt;&lt;span&gt; file.GetMetadataAsync(ctx.CancellationToken);
                
                &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;获取上述文件元数据中的目标文件名称&lt;/span&gt;
                &lt;span&gt;var&lt;/span&gt; fileNameMetadata = metadatas[&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;name&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;];

                &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;目标文件名以base64编码，所以这里需要解码&lt;/span&gt;
                &lt;span&gt;var&lt;/span&gt; fileName =&lt;span&gt; fileNameMetadata.GetString(Encoding.UTF8);

                &lt;/span&gt;&lt;span&gt;var&lt;/span&gt; extensionName =&lt;span&gt; Path.GetExtension(fileName);

                &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;将上传文件转换为实际目标文件&lt;/span&gt;
                File.Move(Path.Combine(tusFiles, ctx.FileId), Path.Combine(tusFiles, $&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;{ctx.FileId}{extensionName}&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;));
            }
        }
    };
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;然后获取并使用上述添加的tus配置服务&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;33&quot;&gt;
&lt;pre&gt;
app.UseTus(httpContext =&amp;gt; Task.FromResult(httpContext.RequestServices.GetService&amp;lt;DefaultTusConfiguration&amp;gt;()));
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;在脚本中我们看到有个endpoint属性，此属性表示上传到服务器的上传结点地址，因为在上到服务器时我们可能需对此请求进行额外处理，比如元数据中的文件名是否已提供等等，所以我们在使用结点映射时，添加对上述结点名称的映射，如下：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;33&quot;&gt;
&lt;pre&gt;
endpoints.MapGet(&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;/files/{fileId}&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;, DownloadFileEndpoint.HandleRoute);
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;该映射第二个参数为RequestDelegate，这个参数用过.NET Core的童鞋都知道，这里我是直接拷贝该包的路由实现，如下：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;43&quot;&gt;
&lt;pre&gt;
&lt;span&gt;public&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;&lt;span&gt; DownloadFileEndpoint
{
    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; &lt;span&gt;async&lt;/span&gt;&lt;span&gt; Task HandleRoute(HttpContext context)
    {
        &lt;/span&gt;&lt;span&gt;var&lt;/span&gt; config = context.RequestServices.GetRequiredService&amp;lt;DefaultTusConfiguration&amp;gt;&lt;span&gt;();

        &lt;/span&gt;&lt;span&gt;if&lt;/span&gt; (!(config.Store &lt;span&gt;is&lt;/span&gt;&lt;span&gt; ITusReadableStore store))
        {
            &lt;/span&gt;&lt;span&gt;return&lt;/span&gt;&lt;span&gt;;
        }

        &lt;/span&gt;&lt;span&gt;var&lt;/span&gt; fileId = (&lt;span&gt;string&lt;/span&gt;)context.Request.RouteValues[&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;fileId&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;];
        &lt;/span&gt;&lt;span&gt;var&lt;/span&gt; file = &lt;span&gt;await&lt;/span&gt;&lt;span&gt; store.GetFileAsync(fileId, context.RequestAborted);

        &lt;/span&gt;&lt;span&gt;if&lt;/span&gt; (file == &lt;span&gt;null&lt;/span&gt;&lt;span&gt;)
        {
            context.Response.StatusCode &lt;/span&gt;= &lt;span&gt;404&lt;/span&gt;&lt;span&gt;;
            &lt;/span&gt;&lt;span&gt;await&lt;/span&gt; context.Response.WriteAsync($&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;File with id {fileId} was not found.&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;, context.RequestAborted);
            &lt;/span&gt;&lt;span&gt;return&lt;/span&gt;&lt;span&gt;;
        }

        &lt;/span&gt;&lt;span&gt;var&lt;/span&gt; fileStream = &lt;span&gt;await&lt;/span&gt;&lt;span&gt; file.GetContentAsync(context.RequestAborted);
        &lt;/span&gt;&lt;span&gt;var&lt;/span&gt; metadata = &lt;span&gt;await&lt;/span&gt;&lt;span&gt; file.GetMetadataAsync(context.RequestAborted);

        context.Response.ContentType &lt;/span&gt;=&lt;span&gt; GetContentTypeOrDefault(metadata);
        context.Response.ContentLength &lt;/span&gt;=&lt;span&gt; fileStream.Length;

        &lt;/span&gt;&lt;span&gt;if&lt;/span&gt; (metadata.TryGetValue(&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;name&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;, &lt;span&gt;out&lt;/span&gt; &lt;span&gt;var&lt;/span&gt;&lt;span&gt; nameMeta))
        {
            context.Response.Headers.Add(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;Content-Disposition&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;,
                &lt;/span&gt;&lt;span&gt;new&lt;/span&gt;[] { $&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;attachment; filename=\&quot;{nameMeta.GetString(Encoding.UTF8)}\&quot;&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt; });
        }

        &lt;/span&gt;&lt;span&gt;using&lt;/span&gt;&lt;span&gt; (fileStream)
        {
            &lt;/span&gt;&lt;span&gt;await&lt;/span&gt; fileStream.CopyToAsync(context.Response.Body, &lt;span&gt;81920&lt;/span&gt;&lt;span&gt;, context.RequestAborted);
        }
    }

    &lt;/span&gt;&lt;span&gt;private&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; &lt;span&gt;string&lt;/span&gt; GetContentTypeOrDefault(Dictionary&amp;lt;&lt;span&gt;string&lt;/span&gt;, Metadata&amp;gt;&lt;span&gt; metadata)
    {
        &lt;/span&gt;&lt;span&gt;if&lt;/span&gt; (metadata.TryGetValue(&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;contentType&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;, &lt;span&gt;out&lt;/span&gt; &lt;span&gt;var&lt;/span&gt;&lt;span&gt; contentType))
        {
            &lt;/span&gt;&lt;span&gt;return&lt;/span&gt;&lt;span&gt; contentType.GetString(Encoding.UTF8);
        }

        &lt;/span&gt;&lt;span&gt;return&lt;/span&gt; &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;application/octet-stream&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;;
    }
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;文件上传大小限制说明&lt;/h2&gt;
&lt;p&gt;我们知道无论是.NET还是.NET Core对于文件上传大小都有默认限制大小，这里对.NET Core中文件大小各种环境配置做一个统一说明，如果你将.NET Core寄宿在IIS上运行，那么请修改web.config配置文件大小限制&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;33&quot;&gt;
&lt;pre&gt;
&amp;lt;system.webServer&amp;gt;
  &amp;lt;security&amp;gt;
    &amp;lt;requestFiltering&amp;gt;
      &lt;span&gt;//&lt;/span&gt;&lt;span&gt;若不配置，默认是28.6兆&lt;/span&gt;
      &amp;lt;requestLimits maxAllowedContentLength=&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;1073741824&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; /&amp;gt;
    &amp;lt;/requestFiltering&amp;gt;
  &amp;lt;/security&amp;gt;
&amp;lt;/system.webServer&amp;gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;如果在开发环境默认使用IIS运行应用程序，请通过如下根据实际情况配置文件上传大小&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;32&quot;&gt;
&lt;pre&gt;
services.Configure&amp;lt;IISServerOptions&amp;gt;(options =&amp;gt;&lt;span&gt;
 {
      options.MaxRequestBodySize &lt;/span&gt;= &lt;span&gt;int&lt;/span&gt;&lt;span&gt;.MaxValue;
 });&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;如果程序运行在Kestrel服务器，那么请通过如下根据实际情况配置文件上传大小&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;33&quot;&gt;
&lt;pre&gt;
services.Configure&amp;lt;KestrelServerOptions&amp;gt;(options =&amp;gt;&lt;span&gt;
{
     &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;若不配置，默认是30兆（没记错的话）&lt;/span&gt;
     options.Limits.MaxRequestBodySize = &lt;span&gt;int&lt;/span&gt;&lt;span&gt;.MaxValue; 
});&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;如果是通过表单上传文件，那么请通过如下根据实际情况配置文件上传大小&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;34&quot;&gt;
&lt;pre&gt;
services.Configure&amp;lt;FormOptions&amp;gt;(x =&amp;gt;&lt;span&gt;
{
     x.ValueLengthLimit &lt;/span&gt;= &lt;span&gt;int&lt;/span&gt;&lt;span&gt;.MaxValue;
    &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;如果不配置，默认是128兆（没记错的话）&lt;/span&gt;
     x.MultipartBodyLengthLimit = &lt;span&gt;int&lt;/span&gt;&lt;span&gt;.MaxValue; 
     x.MultipartHeadersLengthLimit &lt;/span&gt;= &lt;span&gt;int&lt;/span&gt;&lt;span&gt;.MaxValue;
});&lt;/span&gt; 
&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;总结 &lt;/h2&gt;
&lt;p&gt;为了更好体验可以再加上当前网络宽带情况或剩余多少分钟，更详细内容请参考：&lt;a title=&quot;https://github.com/tusdotnet/tusdotnet&quot; href=&quot;https://github.com/tusdotnet/tusdotnet&quot; target=&quot;_blank&quot;&gt;https://github.com/tusdotnet/tusdotnet &lt;/a&gt;、&lt;a title=&quot;https://github.com/tus/tus-js-client&quot; href=&quot;https://github.com/tus/tus-js-client&quot; target=&quot;_blank&quot;&gt;https://github.com/tus/tus-js-client&lt;/a&gt;，关于大文件上传处理到此结束，希望对那些苦苦寻找最终解决方案而无助的童鞋们提供最佳轮子，谢谢。&lt;/p&gt;
</description>
<pubDate>Tue, 11 Aug 2020 15:38:00 +0000</pubDate>
<dc:creator>Jeffcky</dc:creator>
<og:description>前言 前两天我采用技巧式方案基本实现大文件分片上传，这里只是重点在于个人思路和亲身实践，若在实际生产环境要求比较高的话肯定不行，仍存在一些问题需要深入处理，本文继续在之前基础上给出基于tus协议的轮子</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/CreateMyself/p/13466457.html</dc:identifier>
</item>
</channel>
</rss>