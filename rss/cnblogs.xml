<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="css/feed.xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/" xmlns:og="http://ogp.me/ns#">
<channel>
<atom:link rel="self" href="http://192.168.1.4/fivefilters/makefulltextfeed.php?url=feed.cnblogs.com%2Fblog%2Fsitehome%2Frss&amp;max=10&amp;links=preserve&amp;exc=" />
<atom:link rel="alternate" title="Source URL" href="http://feed.cnblogs.com/blog/sitehome/rss" />
<atom:link rel="related" title="Subscribe to feed" href="http://www.subtome.com/#/subscribe?feeds=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed.cnblogs.com%252Fblog%252Fsitehome%252Frss%26max%3D10%26links%3Dpreserve%26exc%3D&amp;back=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed.cnblogs.com%252Fblog%252Fsitehome%252Frss%26max%3D10%26links%3Dpreserve%26exc%3D" />
<title>博客园_首页</title>
<link></link>
<description>代码改变世界</description>
<item>
<title>Redis的批量操作是什么？怎么实现的延时队列？以及订阅模式、LRU。 - 纪莫</title>
<link>http://www.cnblogs.com/jimoer/p/14227467.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/jimoer/p/14227467.html</guid>
<description>&lt;h2 id=&quot;前言&quot;&gt;前言&lt;/h2&gt;
&lt;p&gt;这次的内容是我自己为了总结Redis知识而扩充的，上一篇其实已经总结了几点知识了，但是Redis的强大，以及适用范围之广可不是单单一篇博文就能总结清的。所以这次准备继续总结，因为第一个问题，Redis的批量操作，是我在面试过程中被真实问到的，当时没答上来，也是因为确实没了解过Redis的批量操作。&lt;/p&gt;
&lt;p&gt;当时的问题，我还记得比较清晰：Redis执行批量操作的功能是什么？使用场景就是搞促销活动时，会做预缓存，会往缓存里放大批数据，如果直接放的话那么会很慢，怎么能提高效率呢？&lt;/p&gt;
&lt;h2 id=&quot;redis的批量操作-管道（pipeline）&quot;&gt;Redis的批量操作-管道（pipeline）&lt;/h2&gt;
&lt;p&gt;首先Redis的管道（pipeline）并不是Redis服务端提供的功能，而是Redis客户端为了减少网络交互而提供的一种功能。&lt;/p&gt;
&lt;p&gt;正常的一次Redis网络交互如下：&lt;br/&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20201231231918737.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_SmlNb2Vy,size_30,color_c8cae6,t_70&quot; alt=&quot;在这里插入图片描述&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;pipeline&lt;/strong&gt;主要就是将多个请求合并，进行一次提交给Redis服务器，Redis服务器将所有请求处理完成之后，再一次性返回给客户端。&lt;br/&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20201231233247603.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_SmlNb2Vy,size_30,color_c8cae6,t_70&quot; alt=&quot;在这里插入图片描述&quot; loading=&quot;lazy&quot;/&gt;&lt;br/&gt;下面我们分析一下&lt;strong&gt;pipeline&lt;/strong&gt;的原理&lt;br/&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20210101093316355.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_SmlNb2Vy,size_60,color_c8cae6,t_70&quot; alt=&quot;在这里插入图片描述&quot; loading=&quot;lazy&quot;/&gt;&lt;br/&gt;&lt;strong&gt;pipeline&lt;/strong&gt;的一个交互过程是这样的：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;客户端进程调用&lt;code&gt;write&lt;/code&gt;命令将消息写入到操作系统内核为套接字分配的&lt;strong&gt;发送缓冲区send buffer&lt;/strong&gt;。&lt;/li&gt;
&lt;li&gt;客户端操作系统通过网络路由，将&lt;strong&gt;send buffer&lt;/strong&gt;中的数据发送给服务器操作系统为套接字分配的接&lt;strong&gt;收缓冲区 receive buffer&lt;/strong&gt;。&lt;/li&gt;
&lt;li&gt;服务端进程调用&lt;code&gt;read&lt;/code&gt;命令从&lt;strong&gt;receive buffer&lt;/strong&gt;中取出数据进行处理，然后调用&lt;code&gt;write&lt;/code&gt;命令将相应信息写入到服务端的&lt;strong&gt;send buffer&lt;/strong&gt;中。&lt;/li&gt;
&lt;li&gt;服务端操作系统通过网络路由，将&lt;strong&gt;send buffer&lt;/strong&gt;中的数据发送给客户端操作系统的&lt;strong&gt;receive buffer&lt;/strong&gt;。&lt;/li&gt;
&lt;li&gt;客户端进程调用read命令将数据从&lt;strong&gt;receive buffer&lt;/strong&gt;中取出进行业务处理。&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;在使用&lt;strong&gt;pipeline&lt;/strong&gt;时需要注意：&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;pipeline执行的操作，和mget，mset，hmget这样的操作不同，pipeline的操作是不具备原子性的。&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;还有在集群模式下因为数据是被分散在不同的slot里面的，因此在进行批量操作的时候，不能保证操作的数据都在同一台服务器的slot上，所以集群模式下是禁止执行像mget、mset、pipeline等批量操作的，如果非要使用批量操作，需要自己维护key与slot的关系。&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;pipeline也不能保证批量操作中有命令执行失败了而中断，也不能让下一个指令依赖上一个指令，如果非要这样的复杂逻辑，建议使用lua脚本来完成操作。&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;h2 id=&quot;redis实现消息队列和延时队列&quot;&gt;Redis实现消息队列和延时队列&lt;/h2&gt;
&lt;h3 id=&quot;消息队列&quot;&gt;消息队列&lt;/h3&gt;
&lt;p&gt;Redis的实现消息队列可以用list来实现，通过lpush与rpop或者rpush与lpop结合来实现消息队列。&lt;br/&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20210101184213391.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_SmlNb2Vy,size_30,color_c8cae6,t_70&quot; alt=&quot;在这里插入图片描述&quot; loading=&quot;lazy&quot;/&gt;&lt;br/&gt;但是若是list为空后，无论是lpop还是rpop都会持续的获取list中的数据，若list一直为空，持续的拉取数据，一是会增加客户端的cpu利用率，二是也增高了Redis的QPS，解决方案是使用&lt;strong&gt;blpop&lt;/strong&gt;或&lt;strong&gt;brpop&lt;/strong&gt;来代替lpop或rpop。&lt;br/&gt;其实blpop和brpop的作用是bloking pop，就是阻塞拉取数据，当消息队列中为空时就会停止拉取，有数据后立即恢复拉取。&lt;/p&gt;
&lt;p&gt;但是当没有数据的时候，&lt;strong&gt;阻塞拉取&lt;/strong&gt;，就会一直阻塞在那里，时间久了就成了空闲连接，那么Redis服务器一般会将时间闲置过久的连接直接断掉，以减少连接资源。所以还要检测&lt;strong&gt;阻塞拉取&lt;/strong&gt;抛出的异常然后进行重试。&lt;/p&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;另外一点，就是Redis实现的消息队列，没有ACK机制，所以想要实现消息的可靠性，还要自己实现当消息处理失败后，能继续抛回队列。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&quot;延时队列&quot;&gt;延时队列&lt;/h3&gt;
&lt;p&gt;用Redis实现延时队列，其实就是使用zset来实现，将消息序列化成一个字符串（可以是json格式），作为为&lt;code&gt;value&lt;/code&gt;，消息的到期处理时间做为&lt;code&gt;score&lt;/code&gt;，然后用多线程去轮询zset来获取到期消息进行处理。&lt;/p&gt;
&lt;p&gt;多线程轮询处理，保证了可用性，但是要做幂等或锁处理，保证不要重复处理消息。&lt;/p&gt;
&lt;p&gt;主要的实现代码如下。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;/**
 * 放入延时队列
 * @param queueMsg
 */
private void delay(QueueMsg queueMsg){

    String msg = JSON.toJSONString(queueMsg);

    jedis.zadd(queueKey,System.currentTimeMillis()+5000,msg);

}

/**
 * 处理队列中从消息
 */
private void lpop(){
    while (!Thread.interrupted()){
        // 从队列中取出，权重为0到当前时间的数据，并且数量只取一个
        Set&amp;lt;String&amp;gt; strings = jedis.zrangeByScore(queueKey, 0, System.currentTimeMillis(), 0, 1);
                // 如果消息为空，就歇会儿再取。
        if(strings.isEmpty()){
            try {
                //休息一会儿
                Thread.sleep(500);
            } catch (InterruptedException e) {
                e.printStackTrace();
                break;
            }
            continue;
        }
        String next = strings.iterator().next();
        // 如果抢到了消息
        if(jedis.zrem(queueKey,next)&amp;gt;0){
            // 反序列化后获取到消息
            QueueMsg queueMsg = JSON.parseObject(next, QueueMsg.class);
            // 进行消息处理
            handleMsg(queueMsg);
        }
    }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;订阅模式&quot;&gt;订阅模式&lt;/h2&gt;
&lt;p&gt;Redis的主题订阅模式，其实并不想过多总结，因为由于它本身的一些缺点，导致它的应用场景比较窄。&lt;/p&gt;
&lt;p&gt;前面总结的用Redis的list实现的消息队列，虽然可以使用，但是并不支持消息多播的场景，即一个生产者，将消息放入到多个队列中，然后多个消费者进行消费。&lt;br/&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20210102103013272.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_SmlNb2Vy,size_30,color_c8cae6,t_70&quot; alt=&quot;在这里插入图片描述&quot; loading=&quot;lazy&quot;/&gt;&lt;br/&gt;这种消息多播的场景常用来做分布式系统中的解耦。用哦&lt;code&gt;publish&lt;/code&gt;进行生产者发送消息，消费者使用&lt;code&gt;subscribe&lt;/code&gt;进行获取消息。&lt;/p&gt;
&lt;p&gt;例如：我向jimoerChannel发送了一条消息 &lt;code&gt;b-tree&lt;/code&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-powershell&quot;&gt;127.0.0.1:6379&amp;gt; publish jimoerChannel b-tree
(integer) 1
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;订阅这个渠道的消费者立马收到了一条b-tree的消息。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-powershell&quot;&gt;127.0.0.1:6379&amp;gt; subscribe jimoerChannel
Reading messages... (press Ctrl-C to quit)
1) &quot;subscribe&quot;
2) &quot;jimoerChannel&quot;
3) (integer) 1
1) &quot;message&quot;
2) &quot;jimoerChannel&quot;
3) &quot;b-tree&quot;
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;我前面也说到了，Redis的pub/sub订阅模式，其实最大的缺点就是，消息不能持久化，这样就导致，若是消费者挂了或是没有消费者，那么消息就会被直接丢弃。因为这个原因，所以导致他的使用场景比较少。&lt;/p&gt;
&lt;h2 id=&quot;io模型&quot;&gt;IO模型&lt;/h2&gt;
&lt;h2 id=&quot;redis的过期策略&quot;&gt;Redis的过期策略&lt;/h2&gt;
&lt;p&gt;Redis的过期策略是适用于所有数据结构的。数据一到过期时间就自动删除，Redis会将设置了过期时间的key 放置在一个字典表里。&lt;/p&gt;
&lt;h3 id=&quot;定期删除&quot;&gt;定期删除&lt;/h3&gt;
&lt;p&gt;Redis会定期遍历字典表里面数据来删除过期的Key。&lt;br/&gt;&lt;strong&gt;Redis默认的定期删除策略是每秒进行10次过期扫描，即每100ms扫描一次。并不是扫描全部设置了过期时间的key，而是随机扫描20个key，删除掉已经过期的key，如果过期的比率超过25%，那么就继续进行扫描。&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&quot;惰性删除&quot;&gt;惰性删除&lt;/h3&gt;
&lt;p&gt;因为定期删除是随机抽取一些key来进行过期删除，所以如果key并没有被定期扫描到，那么过期的key就不会被删除。所以Redis还提供了惰性删除的策略，&lt;strong&gt;就是当去查询某些key的时候，若是key已经过期了，那么就会删除key，然后返回null。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;另外一点当在集群条件下，主从同步情况中，主节点中的key过期后，会在aof中生成一条删除指令，然后同步到从节点，这样的从节点在接收到aof的删除指令后，删除掉从节点的key，因为主从同步的时候是异步的所以，短暂的会出现主节点已经没有数据了，但是从节点还存在。&lt;/p&gt;
&lt;p&gt;但是若是定期删除也没有扫描到key，而且好长时间也没去去使用key，那么这部分过期的key就会一直占用的内存。&lt;br/&gt;所以Redis又提供了内存淘汰机制。&lt;/p&gt;
&lt;h3 id=&quot;内存淘汰机制&quot;&gt;内存淘汰机制&lt;/h3&gt;
&lt;p&gt;当Redis的内存出现不足时，就会持续的和磁盘进行交互，这样就会导致Redis卡顿，效率降低等情况。这在线上是不允许发生的，所以Redis提供了配置参数 &lt;code&gt;maxmemory&lt;/code&gt; 来限制内存超出期望大小。&lt;/p&gt;
&lt;p&gt;当内存使用情况超过maxmemory的值时，Redis提供了以下几种策略，来让使用者通过配置决定该如何腾出内存空间来继续提供服务。&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;&lt;code&gt;noeviction&lt;/code&gt;&lt;/strong&gt; 不会继续提供写请求（del请求可以），读请求可以，写请求会报错，这样保证的数据不会丢失，但是业务不可用，这是默认的策略。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;code&gt;volatile-lru&lt;/code&gt;&lt;/strong&gt; 会将设置了过期时间的key中，淘汰掉最近最少使用的key。没有设置过期时间的key不会被淘汰，保证了需要持久化的数据不丢。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;code&gt;volatile-ttl&lt;/code&gt;&lt;/strong&gt; 尝试将设置了过期时间的key中，剩余生命周期越短，越容易被淘汰。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;code&gt;volatile-random&lt;/code&gt;&lt;/strong&gt; 尝试将从设置了过期时间的key中，随机选择一些key进行淘汰。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;code&gt;allkeys-lru&lt;/code&gt;&lt;/strong&gt; 从所有key中，淘汰掉最近最少使用的key。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;code&gt;allkeys-random&lt;/code&gt;&lt;/strong&gt; 从所有key中，随机淘汰一部分key。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;那么具体设置成哪种淘汰策略呢？&lt;br/&gt;&lt;strong&gt;这就是要看在使用Redis时的具体场景了，如果只是用Redis做缓存的话，那么可以配置allkeys-lru或allkey-random，客户端在写缓存的时候并不用携带着过期时间。若是还想要用持久化的功能，那么就应该使用volatile-开头的策略，这样可以保证每月设置过期时间的key不会被淘汰。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;内存淘汰策略的配置如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-powershell&quot;&gt;# 最大使用内存
 maxmemory 5m
# 内存淘汰策略 The default is:noeviction
 maxmemory-policy allkeys-lru
&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;lru算法&quot;&gt;LRU算法&lt;/h3&gt;
&lt;p&gt;LRU算法的实现，其实可以靠一个链表。链表按照使用情况来进行排序，当空间不足时，会剔除掉尾部的数据。当某个元素被访问时它会被移动到链表头。&lt;/p&gt;
&lt;p&gt;在真实的面试中，若是让写出LRU算法，我认为可以使用Java中的LikedHashMap来实现，因为LikedHashMap已经实现了基本的LRU功能，我只需要封装一下就改造成了自己的了。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;/**
 * @author Jimoer
 * @description
 */
public class MyLRUCache&amp;lt;K,V&amp;gt; {
    // lru容量
    private int lruCapacity;
    // 数据容器（内存）
    private Map&amp;lt;K,V&amp;gt; dataMap;

    public MyLRUCache(int capacity){
        
        this.lruCapacity = capacity;
        // 设置LinkedHashMap的初始容量为LRU的最大容量，
        // 扩容因子为默认的0.75，第三个参数是否将数据按照访问顺序排序。
        dataMap = new LinkedHashMap&amp;lt;K, V&amp;gt;(capacity, 0.75f, true){
            @Override
            protected boolean removeEldestEntry(Map.Entry&amp;lt;K, V&amp;gt; eldest) {
                // 当数据量大于lruCapacity时，移除掉最老使用的数据。
                return super.size()&amp;gt;lruCapacity;
            }
        };
    }

    public V get(K k){
        return dataMap.get(k);
    }

    public void put(K key, V value){
        dataMap.put(key,value);
    }

    public int getLruCapacity() {
        return lruCapacity;
    }

    public Map&amp;lt;K, V&amp;gt; getDataMap() {
        return dataMap;
    }

}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;测试代码：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;@Test
public void lruTest(){
    // 内存容量为3，即存储3条数据后，再放入数据，就会将最老使用的数据删除
    MyLRUCache myLRUCache = new MyLRUCache(3);

    myLRUCache.put(&quot;1k&quot;,&quot;张三&quot;);
    myLRUCache.put(&quot;2k&quot;,&quot;李四&quot;);
    myLRUCache.put(&quot;3k&quot;,&quot;王五&quot;);
    // 容量已满
    System.out.println(&quot;myLRUCache:&quot;+JSON.toJSONString(myLRUCache.getDataMap()));
    // 继续放入数据，该删除第一条数据为第四条数据腾出空间了
    myLRUCache.put(&quot;4k&quot;,&quot;赵六&quot;);
    // 打印出结果
    System.out.println(&quot;myLRUCache:&quot;+JSON.toJSONString(myLRUCache.getDataMap()));
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;运行结果：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;myLRUCache:{&quot;1k&quot;:&quot;张三&quot;,&quot;2k&quot;:&quot;李四&quot;,&quot;3k&quot;:&quot;王五&quot;}
myLRUCache:{&quot;2k&quot;:&quot;李四&quot;,&quot;3k&quot;:&quot;王五&quot;,&quot;4k&quot;:&quot;赵六&quot;}
&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;总结&quot;&gt;总结&lt;/h2&gt;
&lt;p&gt;好了，Redis的相关知识，就总结到这里了，算上前面两篇博文（&lt;a href=&quot;https://blog.csdn.net/qq_35165000/article/details/109524499&quot; target=&quot;_blank&quot;&gt;Redis基础数据结构总结&lt;/a&gt;、&lt;a href=&quot;https://www.cnblogs.com/jimoer/p/14204650.html&quot; target=&quot;_blank&quot;&gt;你说一下Redis为什么快吧，怎么实现高可用，还有持久化怎么做的&lt;/a&gt;），这是Redis的第三篇了，这一篇博文也是新年的第一篇，元旦假期在家花了两天时间，自己学习自己总结。元旦假期结束后，我要继续面试了，后面我会继续将我面试中遇到的各种问题，总结出来，一是增加自己的知识面，二也将知识进行的传播。&lt;br/&gt;毕竟独乐乐不众乐乐😏。&lt;/p&gt;
</description>
<pubDate>Mon, 04 Jan 2021 00:33:00 +0000</pubDate>
<dc:creator>纪莫</dc:creator>
<og:description>前言 这次的内容是我自己为了总结Redis知识而扩充的，上一篇其实已经总结了几点知识了，但是Redis的强大，以及适用范围之广可不是单单一篇博文就能总结清的。所以这次准备继续总结，因为第一个问题，Re</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/jimoer/p/14227467.html</dc:identifier>
</item>
<item>
<title>死磕以太坊源码分析之MPT树-上 - mindcarver</title>
<link>http://www.cnblogs.com/1314xf/p/14227781.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/1314xf/p/14227781.html</guid>
<description>&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;死磕以太坊源码分析之MPT树-上&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;前缀树trie&quot;&gt;前缀树Trie&lt;/h2&gt;
&lt;p&gt;前缀树（又称字典树），通常来说，一个前缀树是用来&lt;code&gt;存储字符串&lt;/code&gt;的。前缀树的每一个节点代表一个&lt;code&gt;字符串&lt;/code&gt;（&lt;code&gt;前缀&lt;/code&gt;）。每一个节点会有多个子节点，通往不同子节点的路径上有着不同的字符。子节点代表的字符串是由节点本身的&lt;code&gt;原始字符串&lt;/code&gt;，以及&lt;code&gt;通往该子节点路径上所有的字符&lt;/code&gt;组成的。如下图所示：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://tva1.sinaimg.cn/large/0081Kckwgy1gm73i6xursj31820qq789.jpg&quot; alt=&quot;image-20201231160000592&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;Trie的结点看上去是这样子的：&lt;/p&gt;
&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;[ [Ia, Ib, … I*], value]&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;其中 &lt;code&gt;[Ia, Ib, ... I*]&lt;/code&gt; 在本文中我们将其称为结点的 &lt;em&gt;索引数组&lt;/em&gt; ，它以 key 中的下一个字符为索引，每个元素&lt;code&gt;I*&lt;/code&gt;指向对应的子结点。 &lt;code&gt;value&lt;/code&gt; 则代表从根节点到当前结点的路径组成的key所对应的值。如果不存在这样一个 key，则 value 的值为空。&lt;/p&gt;
&lt;p&gt;前缀树的性质：&lt;/p&gt;
&lt;ol readability=&quot;3.5&quot;&gt;&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;每一层节点上面的值都不相同；&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;根节点不存储值；除根节点外每一个节点都&lt;strong&gt;只包含一个字符&lt;/strong&gt;，代表的字符串是由节点本身的&lt;code&gt;原始字符串&lt;/code&gt;，以及&lt;code&gt;通往该子节点路径上所有的字符&lt;/code&gt;。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;1&quot;&gt;
&lt;p&gt;前缀树的查找效率是$O(m)$，$m$为所查找节点的长度，而哈希表的查找效率为$O(1)$。且一次查找会有 m 次 &lt;code&gt;IO&lt;/code&gt;开销，相比于直接查找，无论是速率、还是对磁盘的压力都比较大。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;1&quot;&gt;
&lt;p&gt;当存在一个节点，其内容很长（如一串很长的字符串），当树中没有与他相同前缀的分支时，为了存储该节点，需要创建许多非叶子节点来构建根节点到该节点间的路径，造成了存储空间的浪费。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;&lt;h2 id=&quot;压缩前缀树patricia-tree&quot;&gt;压缩前缀树Patricia Tree&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;基数树&lt;/strong&gt;（也叫&lt;strong&gt;基数特里树&lt;/strong&gt;或&lt;strong&gt;压缩前缀树&lt;/strong&gt;）是一种数据结构，是一种更节省空间的&lt;strong&gt;前缀树&lt;/strong&gt;，其中作为唯一子节点的每个节点都与其父节点合并，边既可以表示为元素序列又可以表示为单个元素。 因此每个内部节点的子节点数最多为基数树的基数 &lt;em&gt;r&lt;/em&gt; ，其中 &lt;em&gt;r&lt;/em&gt; 为正整数， &lt;em&gt;x&lt;/em&gt; 为 2 的幂， &lt;em&gt;x&lt;/em&gt;≥1 ，这使得基数树更适用于对于较小的集合（尤其是字符串很长的情况下）和有很长相同前缀的字符串集合。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://tva1.sinaimg.cn/large/0081Kckwgy1gm70dwcmgdj31780kkqae.jpg&quot; alt=&quot;image-20201231133805927&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;图中可以很容易看出数中所存储的键值对：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;6c0a5c71ec20bq3w =&amp;gt; 5&lt;/li&gt;
&lt;li&gt;6c0a5c71ec20CX7j =&amp;gt; 27&lt;/li&gt;
&lt;li&gt;6c0a5c71781a1FXq =&amp;gt; 18&lt;/li&gt;
&lt;li&gt;6c0a5c71781a9Dog =&amp;gt; 64&lt;/li&gt;
&lt;li&gt;6c0a8f743b95zUfe =&amp;gt; 30&lt;/li&gt;
&lt;li&gt;6c0a8f743b95jx5R =&amp;gt; 2&lt;/li&gt;
&lt;li&gt;6c0a8f740d16y03G =&amp;gt; 43&lt;/li&gt;
&lt;li&gt;6c0a8f740d16vcc1 =&amp;gt; 48&lt;/li&gt;
&lt;/ul&gt;&lt;h2 id=&quot;默克尔树merkle-tree&quot;&gt;默克尔树Merkle Tree&lt;/h2&gt;
&lt;p&gt;Merkle树看起来非常像二叉树，其叶子节点上的值通常为数据块的哈希值，而非叶子节点上的值，所以有时候Merkle tree也表示为Hash tree，如下图所示：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://tva1.sinaimg.cn/large/0081Kckwgy1gm69qu5vh8j31ba0ragpn.jpg&quot; alt=&quot;image-20201230225028932&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;在构造&lt;code&gt;Merkle&lt;/code&gt;树时，首先要计算数据块的哈希值，通常，选用&lt;code&gt;SHA-256&lt;/code&gt;等哈希算法。但如果仅仅防止数据不是蓄意的损坏或篡改，可以改用一些安全性低但效率高的校验和算法，如&lt;code&gt;CRC&lt;/code&gt;。然后将数据块计算的哈希值两两配对（如果是奇数个数，最后一个自己与自己配对），计算上一层哈希，再重复这个步骤，一直到计算出根哈希值。&lt;/p&gt;
&lt;p&gt;所以我们可以简单总结出&lt;strong&gt;merkle Tree&lt;/strong&gt; 有以下几个性质：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;校验整体数据的正确性&lt;/li&gt;
&lt;li&gt;快速定位错误&lt;/li&gt;
&lt;li&gt;快速校验部分数据是否在原始的数据中&lt;/li&gt;
&lt;li&gt;存储空间开销大（&lt;strong&gt;大量中间哈希&lt;/strong&gt;）&lt;/li&gt;
&lt;/ul&gt;&lt;h2 id=&quot;以太坊的改进方案&quot;&gt;以太坊的改进方案&lt;/h2&gt;
&lt;h3 id=&quot;使用byte作为key类型&quot;&gt;使用[]byte作为key类型&lt;/h3&gt;
&lt;p&gt;在以太坊的Trie模块中，key和value都是[]byte类型。如果要使用其它类型，需要将其转换成[]byte类型（比如使用&lt;strong&gt;rlp&lt;/strong&gt;进行转换）。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Nibble&lt;/strong&gt; ：是 key 的基本单元，是一个四元组（四个 bit 位的组合例如二进制表达的 0010 就是一个四元组）&lt;/p&gt;
&lt;p&gt;在Trie模块对外提供的接口中，key类型是[]byte。但在内部实现里，将key中的每个字节按高4位和低4位拆分成了两个字节。比如你传入的key是：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;[0x1a, 0x2b, 0x3c, 0x4d]&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Trie内部将这个key拆分成：&lt;/p&gt;
&lt;blockquote readability=&quot;12&quot;&gt;
&lt;p&gt;[0x1, 0xa, 0x2, 0xb, 0x3, 0xc, 0x4, 0xd]&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Trie内部的编码中将拆分后的&lt;strong&gt;每一个字节&lt;/strong&gt;称为 &lt;strong&gt;nibble&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;如果使用一个完整的 byte 作为 key 的最小单位，那么前文提到的索引数组的大小应该是 256（byte作为数组的索引，最大值为255，最小值为0）。而索引数组的每个元素都是一个 32 字节的哈希,这样每个结点要占用大量的空间。并且索引数组中的元素多数情况下是空的，不指向任何结点。因此这种实现方法占用大量空间而不使用。以太坊的改进方法，可以将索引数组的大小降为 16（4个bit的最大值为0xF，最小值为 0），因此大大减少空间的浪费。&lt;/p&gt;
&lt;h3 id=&quot;新增类型节点&quot;&gt;新增类型节点&lt;/h3&gt;
&lt;p&gt;前缀树和merkle树存在明显的局限性，所以以太坊为MPT树新增了几种不同类型的树节点，通过针对不同节点不同操作来解决效率以及存储上的问题。&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;&lt;strong&gt;空白节点&lt;/strong&gt; ：简单的表示空，在代码中是一个空串&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;分支节点&lt;/strong&gt; ：分支节点有 17 个元素，回到 Nibble，四元组是 key 的基本单元，&lt;strong&gt;四元组最多有 16 个值&lt;/strong&gt;。所以前 16 个必将落入到在其遍历中的键的十六个可能的半字节值中的每一个。第 17 个是存储那些在当前结点&lt;strong&gt;结束了&lt;/strong&gt;的节点(例如， 有三个 key,分别是 (abc ,abd, ab) 第 17 个字段储存了 ab 节点的值)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;叶子节点&lt;/strong&gt;：只有两个元素，分别为 key 和 value&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;扩展节点&lt;/strong&gt; ：有两个元素，一个是 key 值，还有一个是 hash 值，这个 hash 值指向下一个节点&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;此外，为了将 MPT 树存储到数据库中，同时还可以把 MPT 树从数据库中恢复出来，&lt;strong&gt;对于 Extension 和 Leaf 的节点类型做了特殊的定义&lt;/strong&gt;：如果是一个扩展节点，那么前缀为 0，这个 0 加在 key 前面。如果是一个叶子节点，那么前缀就是 1。同时对&lt;strong&gt;key 的长度就奇偶类型也做了设定&lt;/strong&gt;，如果是奇数长度则标示 1，如果是偶数长度则标示 0。&lt;/p&gt;
&lt;h3 id=&quot;以太坊中使用到的mpt树结构&quot;&gt;以太坊中使用到的MPT树结构&lt;/h3&gt;
&lt;ul&gt;&lt;li&gt;&lt;code&gt;State Trie&lt;/code&gt; 区块头中的状态树
&lt;ul&gt;&lt;li&gt;key =&amp;gt; sha3(以太坊账户地址 address)&lt;/li&gt;
&lt;li&gt;value =&amp;gt; rlp(账号内容信息 account)&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Transactions Trie 区块头中的交易树
&lt;ul&gt;&lt;li&gt;key =&amp;gt; rlp(交易的偏移量 transaction index)&lt;/li&gt;
&lt;li&gt;每个块都有各自的交易树，且不可更改&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Receipts Trie&lt;/code&gt; 区块头中的收据树
&lt;ul&gt;&lt;li&gt;key = rlp(交易的偏移量 transaction index)&lt;/li&gt;
&lt;li&gt;每个块都有各自的交易树，且不可更改&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Storage Trie&lt;/code&gt; 存储树
&lt;ul&gt;&lt;li&gt;存储只能合约状态&lt;/li&gt;
&lt;li&gt;每个账号有自己的 Storage Trie&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;img src=&quot;https://tva1.sinaimg.cn/large/0081Kckwgy1gm70f77s2dj319g0lymyz.jpg&quot; alt=&quot;image-20201231141329137&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;这两个区块头中，&lt;code&gt;state root&lt;/code&gt;、&lt;code&gt;tx root&lt;/code&gt;、 &lt;code&gt;receipt root&lt;/code&gt;分别存储了这三棵树的树根，第二个区块显示了当账号 17 5的数据变更(&lt;strong&gt;27 -&amp;gt; 45&lt;/strong&gt;)的时候，只需要存储跟这个账号相关的部分数据，而且老的区块中的数据还是可以正常访问。&lt;/p&gt;
&lt;h3 id=&quot;key编码规则&quot;&gt;key编码规则&lt;/h3&gt;
&lt;p&gt;三种编码方式分别为：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;&lt;strong&gt;Raw&lt;/strong&gt;编码（原生的字符）；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Hex&lt;/strong&gt;编码（扩展的16进制编码）；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Hex-Prefix&lt;/strong&gt;编码（16进制前缀编码）；&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;&lt;strong&gt;Raw编码&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Raw&lt;/strong&gt;编码就是原生的&lt;strong&gt;key&lt;/strong&gt;值，不做任何改变。这种编码方式的&lt;strong&gt;key&lt;/strong&gt;，&lt;em&gt;是&lt;strong&gt;MPT&lt;/strong&gt;对外提供接口的默认编码方式&lt;/em&gt;。&lt;/p&gt;
&lt;blockquote readability=&quot;10&quot;&gt;
&lt;p&gt;例如一条key为“cat”，value为“dog”的数据项，其Raw编码就是['c', 'a', 't']，换成ASCII表示方式就是[63, 61, 74]&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;Hex编码&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Hex编码用于对内存中MPT树节点key进行编码&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;为了减少分支节点孩子的个数，将数据 key 进行半字节拆解而成。即依次将 key[0],key[1],…,key[n] 分别进行半字节拆分成两个数，再依次存放在长度为 len(key)+1 的数组中。 并在数组末尾写入终止符 &lt;code&gt;16&lt;/code&gt;。算法如下：&lt;/p&gt;
&lt;blockquote readability=&quot;7&quot;&gt;
&lt;p&gt;半字节，在计算机中，通常将8位二进制数称为字节，而把4位二进制数称为半字节。 高四位和低四位，这里的“位”是针对二进制来说的。比如数字 250 的二进制数为 11111010，则高四位是左边的 1111，低四位是右边的 1010。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;从&lt;strong&gt;Raw&lt;/strong&gt;编码向&lt;strong&gt;Hex&lt;/strong&gt;编码的转换规则是：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Raw&lt;/strong&gt;编码输入的每个字符分解为高 4 位和低 4 位&lt;/li&gt;
&lt;li&gt;如果是叶子节点，则在最后加上&lt;strong&gt;Hex&lt;/strong&gt;值&lt;code&gt;0x10&lt;/code&gt;表示结束&lt;/li&gt;
&lt;li&gt;如果是分支节点不附加任何&lt;strong&gt;Hex&lt;/strong&gt;值&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;例如：字符串 “romane” 的 bytes 是 &lt;code&gt;[114 111 109 97 110 101]&lt;/code&gt;，在 HEX 编码时将其依次处理：&lt;/p&gt;
&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;i&lt;/th&gt;
&lt;th&gt;key[i]&lt;/th&gt;
&lt;th&gt;key[i]二进制&lt;/th&gt;
&lt;th&gt;nibbles[i*2]=高四位&lt;/th&gt;
&lt;th&gt;nibbles[i*2+1]=低四位&lt;/th&gt;
&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;114&lt;/td&gt;
&lt;td&gt;01110010&lt;/td&gt;
&lt;td&gt;0111= 7&lt;/td&gt;
&lt;td&gt;0010= 2&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;111&lt;/td&gt;
&lt;td&gt;01101111&lt;/td&gt;
&lt;td&gt;0110=6&lt;/td&gt;
&lt;td&gt;1111=15&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;109&lt;/td&gt;
&lt;td&gt;01101101&lt;/td&gt;
&lt;td&gt;0110=6&lt;/td&gt;
&lt;td&gt;1101=13&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;3&lt;/td&gt;
&lt;td&gt;97&lt;/td&gt;
&lt;td&gt;01100001&lt;/td&gt;
&lt;td&gt;0110=6&lt;/td&gt;
&lt;td&gt;0001=1&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;110&lt;/td&gt;
&lt;td&gt;01101110&lt;/td&gt;
&lt;td&gt;0110=6&lt;/td&gt;
&lt;td&gt;1110=14&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;5&lt;/td&gt;
&lt;td&gt;101&lt;/td&gt;
&lt;td&gt;01100101&lt;/td&gt;
&lt;td&gt;0110=6&lt;/td&gt;
&lt;td&gt;0101=5&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;最终得到 Hex(“romane”) = &lt;code&gt;[7 2 6 15 6 13 6 1 6 14 6 5 16]&lt;/code&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-GO&quot;&gt;// 源码实现
func keybytesToHex(str []byte) []byte {
        l := len(str)*2 + 1
        var nibbles = make([]byte, l)
        for i, b := range str {
                nibbles[i*2] = b / 16   // 高四位
                nibbles[i*2+1] = b % 16 // 低四位
        }
        nibbles[l-1] = 16 // 最后一位存入标示符 代表是hex编码
        return nibbles
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Hex-Prefix&lt;/strong&gt;编码&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;数学公式定义：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://tva1.sinaimg.cn/large/0081Kckwgy1gm75cvok4yj318s07iwfg.jpg&quot; alt=&quot;image-20201231170415071&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;Hex-Prefix 编码是一种任意量的半字节转换为数组的有效方式，还可以在存入一个标识符来区分不同节点类型。 因此 HP 编码是在由一个标识符前缀和半字节转换为数组的两部分组成。存入到数据库中存在节点 Key 的只有扩展节点和叶子节点，因此 HP 只用于区分扩展节点和叶子节点，不涉及无节点 key 的分支节点。其编码规则如下图：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://tva1.sinaimg.cn/large/0081Kckwgy1gm74pxxc7yj31ju0cm41o.jpg&quot; alt=&quot;image-20201231164209626&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;前缀标识符由两部分组成：节点类型和奇偶标识，并存储在编码后字节的第一个半字节中。 0 表示扩展节点类型，1 表示叶子节点，偶为 0，奇为 1。最终可以得到唯一标识的前缀标识：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;0：偶长度的扩展节点&lt;/li&gt;
&lt;li&gt;1：奇长度的扩展节点&lt;/li&gt;
&lt;li&gt;2：偶长度的叶子节点&lt;/li&gt;
&lt;li&gt;3：奇长度的叶子节点&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;当偶长度时，第一个字节的低四位用&lt;code&gt;0&lt;/code&gt;填充，当是奇长度时，则将 key[0] 存放在第一个字节的低四位中，这样 HP 编码结果始终是偶长度。 这里为什么要区分节点 key 长度的奇偶呢？这是因为，半字节 &lt;code&gt;1&lt;/code&gt; 和 &lt;code&gt;01&lt;/code&gt; 在转换为 bytes 格式时都成为&lt;code&gt;&amp;lt;01&amp;gt;&lt;/code&gt;，无法区分两者。&lt;/p&gt;
&lt;p&gt;例如，上图 “以太坊 MPT 树的哈希计算”中的控制节点1的key 为 &lt;code&gt;[ 7 2 6 f 6 d]&lt;/code&gt;，因为是偶长度，则 HP[0]= (00000000) =0，H[1:]= 解码半字节(key)。 而节点 3 的 key 为 &lt;code&gt;[1 6 e 6 5]&lt;/code&gt;，为奇长度，则 HP[0]= (0001 0001)=17。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;HP&lt;/strong&gt;编码的规则如下：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;key结尾为&lt;strong&gt;0x10&lt;/strong&gt;，则去掉这个终止符&lt;/li&gt;
&lt;li&gt;key之前补一个四元组这个Byte第0位区分奇偶信息，第 1 位区分节点类型&lt;/li&gt;
&lt;li&gt;如果输入&lt;strong&gt;key&lt;/strong&gt;的长度是偶数，则再添加一个四元组0x0在flag四元组后&lt;/li&gt;
&lt;li&gt;将原来的key内容压缩，将分离的两个byte以高四位低四位进行合并&lt;/li&gt;
&lt;/ul&gt;&lt;blockquote readability=&quot;14&quot;&gt;
&lt;p&gt;十六进制前缀编码相当于一个逆向的过程，比如输入的是[6 2 6 15 6 2 16]，&lt;/p&gt;
&lt;p&gt;根据第一个规则去掉终止符16。根据第二个规则key前补一个四元组，从右往左第一位为1表示叶子节点，&lt;/p&gt;
&lt;p&gt;从右往左第0位如果后面key的长度为偶数设置为0，奇数长度设置为1，那么四元组0010就是2。&lt;/p&gt;
&lt;p&gt;根据第三个规则，添加一个全0的补在后面，那么就是20.根据第三个规则内容压缩合并，那么结果就是[0x20 0x62 0x6f 0x62]&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;HP 编码源码实现:&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-go&quot;&gt;func hexToCompact(hex []byte) []byte {
        terminator := byte(0) //初始化一个值为0的byte，它就是我们上面公式中提到的t
        if hasTerm(hex) {     //验证hex有后缀编码，
                terminator = 1         //hex编码有后缀，则t=1
                hex = hex[:len(hex)-1] //此处只是去掉后缀部分的hex编码
        }
        ////Compact开辟的空间长度为hex编码的一半再加1，这个1对应的空间是Compact的前缀
        buf := make([]byte, len(hex)/2+1)
        ////这一阶段的buf[0]可以理解为公式中的16*f(t)
        buf[0] = terminator &amp;lt;&amp;lt; 5 // the flag byte
        if len(hex)&amp;amp;1 == 1 {     //hex 长度为奇数，则逻辑上说明hex有前缀
                buf[0] |= 1 &amp;lt;&amp;lt; 4 ////这一阶段的buf[0]可以理解为公式中的16*（f(t)+1）
                buf[0] |= hex[0] // first nibble is contained in the first byte
                hex = hex[1:]    //此时获取的hex编码无前缀无后缀
        }
        decodeNibbles(hex, buf[1:]) //将hex编码映射到compact编码中
        return buf                  //返回compact编码
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;以上三种编码方式的转换关系为：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;Raw编码：原生的key编码，是MPT对外提供接口中使用的编码方式，当数据项被插入到树中时，Raw编码被转换成Hex编码；&lt;/li&gt;
&lt;li&gt;Hex编码：16进制扩展编码，用于对内存中树节点key进行编码，当树节点被持久化到数据库时，Hex编码被转换成HP编码；&lt;/li&gt;
&lt;li&gt;HP编码：16进制前缀编码，用于对数据库中树节点key进行编码，当树节点被加载到内存时，HP编码被转换成Hex编码；&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;如下图：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://tva1.sinaimg.cn/large/0081Kckwgy1gm71rsyyekj319w05ygml.jpg&quot; alt=&quot;image-20201231150011417&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;以上介绍的MPT树，可以用来存储内容为任何长度的&lt;code&gt;key-value&lt;/code&gt;数据项。倘若数据项的&lt;code&gt;key&lt;/code&gt;长度没有限制时，当树中维护的数据量较大时，仍然会造成整棵树的深度变得越来越深，会造成以下影响：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;查询一个节点可能会需要许多次 IO 读取，效率低下；&lt;/li&gt;
&lt;li&gt;系统易遭受 Dos 攻击，攻击者可以通过在合约中存储特定的数据，“构造”一棵拥有一条很长路径的树，然后不断地调用&lt;code&gt;SLOAD&lt;/code&gt;指令读取该树节点的内容，造成系统执行效率极度下降；&lt;/li&gt;
&lt;li&gt;所有的 key 其实是一种明文的形式进行存储；&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;为了解决以上问题，以太坊对&lt;strong&gt;MPT&lt;/strong&gt;再进行了一次封装，对数据项的&lt;strong&gt;key&lt;/strong&gt;进行了一次哈希计算，因此最终作为参数传入到MPT接口的数据项其实是&lt;code&gt;(sha3(key), value)&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;优势&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;传入MPT接口的 key 是固定长度的（32字节），可以避免出现树中出现长度很长的路径；&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;劣势&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;每次树操作需要增加一次哈希计算；&lt;/li&gt;
&lt;li&gt;需要在数据库中存储额外的&lt;code&gt;sha3(key)&lt;/code&gt;与&lt;code&gt;key&lt;/code&gt;之间的对应关系；&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;完整的编码流程如图：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://tva1.sinaimg.cn/large/0081Kckwgy1gm71x5i5djj31by07275g.jpg&quot; alt=&quot;image-20201231150520220&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h2 id=&quot;mpt轻节点&quot;&gt;MPT轻节点&lt;/h2&gt;
&lt;p&gt;上面的MPT树，有两个问题：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;每个节点都包含有大量信息，并且叶子节点中还包含有完整的数据信息。如果该MPT树并没有发生任何变化，并且没有被使用，则会白白占用一大片空间，想象一个以太坊，有多少个MPT树，都在内存中，那还了得。&lt;/li&gt;
&lt;li&gt;并不是任何的客户端都对所有的MPT树都感兴趣，若每次都把完整的节点信息都下载下，下载时间长不说，并且会占用大量的磁盘空间。&lt;/li&gt;
&lt;/ul&gt;&lt;h3 id=&quot;解决方式&quot;&gt;解决方式&lt;/h3&gt;
&lt;p&gt;为了解决上述问题，以太坊使用了一种缓存机制，可以称为是轻节点机制，大体如下：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;若某节点数据一直没有发生变化，则仅仅保留该节点的32位hash值，剩下的内容全部释放&lt;/li&gt;
&lt;li&gt;若需要插入或者删除某节点，先通过该hash值db中查找对应的节点，并加载到内存，之后再进行删除插入操作&lt;/li&gt;
&lt;/ul&gt;&lt;h4 id=&quot;轻节点中添加数据&quot;&gt;轻节点中添加数据&lt;/h4&gt;
&lt;p&gt;内存中只有这么一个轻节点，但是我要添加一个数据，也就是要给完整的MPT树中添加一个叶子节点，怎么添加？大体如下图所示：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://tva1.sinaimg.cn/large/0081Kckwgy1gm8hgf9f3ij319a0pcgqh.jpg&quot; alt=&quot;image-20210101204824090&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;到此以太坊的MPT树的基础讲解结束。&lt;/p&gt;
&lt;h2 id=&quot;参考&quot;&gt;参考&lt;/h2&gt;
&lt;blockquote readability=&quot;1.5740740740741&quot;&gt;
&lt;p&gt;&lt;a href=&quot;https://mindcarver.cn&quot; target=&quot;_blank&quot;&gt;https://mindcarver.cn&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/blockchainGuide&quot; target=&quot;_blank&quot;&gt;https://github.com/blockchainGuide&lt;/a&gt; 文章及视频学习资料&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://eth.wiki/en/fundamentals/patricia-tree&quot; target=&quot;_blank&quot;&gt;https://eth.wiki/en/fundamentals/patricia-tree&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://ethereum.github.io/yellowpaper/paper.pdf#appendix.D&quot; target=&quot;_blank&quot;&gt;https://ethereum.github.io/yellowpaper/paper.pdf#appendix.D&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://ethfans.org/toya/articles/588&quot; target=&quot;_blank&quot;&gt;https://ethfans.org/toya/articles/588&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://learnblockchain.cn/books/geth/part3/mpt.html&quot; target=&quot;_blank&quot;&gt;https://learnblockchain.cn/books/geth/part3/mpt.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://blog.ethereum.org/2015/11/15/merkling-in-ethereum/&quot; target=&quot;_blank&quot;&gt;https://blog.ethereum.org/2015/11/15/merkling-in-ethereum/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1909.11590.pdf&quot; target=&quot;_blank&quot;&gt;https://arxiv.org/pdf/1909.11590.pdf&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
</description>
<pubDate>Mon, 04 Jan 2021 00:24:00 +0000</pubDate>
<dc:creator>mindcarver</dc:creator>
<og:description>死磕以太坊源码分析之MPT树-上</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/1314xf/p/14227781.html</dc:identifier>
</item>
<item>
<title>数据仓库组件：Hive环境搭建和基础用法 - 知了一笑</title>
<link>http://www.cnblogs.com/cicada-smile/p/14227369.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/cicada-smile/p/14227369.html</guid>
<description>&lt;p&gt;Hive是基于Hadoop的一个数据仓库工具，用来进行数据提取、转化、加载，是一个可以对Hadoop中的大规模存储的数据进行查询和分析存储的组件，Hive数据仓库工具能将结构化的数据文件映射为一张数据库表，并提供SQL查询功能，能将SQL语句转变成MapReduce任务来执行，使用成本低，可以通过类似SQL语句实现快速MapReduce统计，使MapReduce变得更加简单，而不必开发专门的MapReduce应用程序。hive十分适合对数据仓库进行统计分析。&lt;/p&gt;&lt;div id=&quot;cnblogs_post_body&quot; readability=&quot;163.83976808539&quot;&gt;
&lt;p&gt;本文源码：&lt;a href=&quot;https://github.com/cicadasmile/big-data-parent&quot; target=&quot;_blank&quot;&gt;GitHub&lt;/a&gt; || &lt;a href=&quot;https://gitee.com/cicadasmile/big-data-parent&quot; target=&quot;_blank&quot;&gt;GitEE&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;1、基础描述&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Hive是基于Hadoop的一个数据仓库工具，用来进行数据提取、转化、加载，是一个可以对Hadoop中的大规模存储的数据进行查询和分析存储的组件，Hive数据仓库工具能将结构化的数据文件映射为一张数据库表，并提供SQL查询功能，能将SQL语句转变成MapReduce任务来执行，使用成本低，可以通过类似SQL语句实现快速MapReduce统计，使MapReduce变得更加简单，而不必开发专门的MapReduce应用程序。hive十分适合对数据仓库进行统计分析。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2、组成与架构&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1691717/202101/1691717-20210103225539496-461576247.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;用户接口&lt;/strong&gt;：ClientCLI、JDBC访问Hive、WEBUI浏览器访问Hive。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;元数据&lt;/strong&gt;：Hive将元数据存储在数据库中，如mysql、derby。Hive中的元数据包括表的名字，表的列和分区以及属性，表的属性（是否为外部表等），表的数据所在目录等。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;驱动器&lt;/strong&gt;：基于解释器、编辑器、优化器完成HQL查询语句从词法分析、语法分析、编译、优化以及查询计划的生成。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;执行器引擎&lt;/strong&gt;：ExecutionEngine把逻辑执行计划转换成可以运行的物理计划。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Hadoop底层&lt;/strong&gt;：基于HDFS进行存储，使用MapReduce进行计算，基于Yarn的调度机制。&lt;/p&gt;
&lt;p&gt;Hive收到给客户端发送的交互请求，接收到操作指令(SQL)，并将指令翻译成MapReduce，提交到Hadoop中执行，最后将执行结果输出到客户端。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;1、准备安装包&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;hive-1.2，依赖Hadoop集群环境，位置放在hop01服务上。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2、解压重命名&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;tar -zxvf apache-hive-1.2.1-bin.tar.gz
mv apache-hive-1.2.1-bin/ hive1.2
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;3、修改配置文件&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;创建配置文件&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;[root@hop01 conf]# pwd
/opt/hive1.2/conf
[root@hop01 conf]# mv hive-env.sh.template hive-env.sh
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;添加内容&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;[root@hop01 conf]# vim hive-env.sh
export HADOOP_HOME=/opt/hadoop2.7
export HIVE_CONF_DIR=/opt/hive1.2/conf
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;配置内容一个是Hadoop路径，和hive配置文件路径。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;4、Hadoop配置&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;首先启动hdfs和yarn；然后在HDFS上创建/tmp和/user/hive/warehouse两个目录并修改赋予权限。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;bin/hadoop fs -mkdir /tmp
bin/hadoop fs -mkdir -p /user/hive/warehouse
bin/hadoop fs -chmod g+w /tmp
bin/hadoop fs -chmod g+w /user/hive/warehouse
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;5、启动Hive&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;[root@hop01 hive1.2]# bin/hive
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;6、基础操作&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;查看数据库&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;hive&amp;gt; show databases ;
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;选择数据库&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;hive&amp;gt; use default;
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;查看数据表&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;hive&amp;gt; show tables;
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;创建数据库使用&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;hive&amp;gt; create database mytestdb;
hive&amp;gt; show databases ;
default
mytestdb
hive&amp;gt; use mytestdb;
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;创建表&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;create table hv_user (id int, name string, age int);
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;查看表结构&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;hive&amp;gt; desc hv_user;
id                      int                                         
name                    string                                      
age                     int 
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;添加表数据&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;insert into hv_user values (1, &quot;test-user&quot;, 23);
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;查询表数据&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;hive&amp;gt; select * from hv_user ;
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;注意：这里通过对查询日志的观察，明显看出Hive执行的流程。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;删除表&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;hive&amp;gt; drop table hv_user ;
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;退出Hive&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;hive&amp;gt; quit;
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;查看Hadoop目录&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;# hadoop fs -ls /user/hive/warehouse       
/user/hive/warehouse/mytestdb.db
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;通过Hive创建的数据库和数据存储在HDFS上。&lt;/p&gt;

&lt;p&gt;这里默认安装好MySQL5.7的版本，并配置好相关登录账号，配置root用户的Host为%模式。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;1、上传MySQL驱动包&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;将MySQL驱动依赖包上传到hive安装目录的lib目录下。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;[root@hop01 lib]# pwd
/opt/hive1.2/lib
[root@hop01 lib]# ll
mysql-connector-java-5.1.27-bin.jar
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;2、创建hive-site配置&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;[root@hop01 conf]# pwd
/opt/hive1.2/conf
[root@hop01 conf]# touch hive-site.xml
[root@hop01 conf]# vim hive-site.xml
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;3、配置MySQL存储&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-xml&quot;&gt;&amp;lt;?xml version=&quot;1.0&quot;?&amp;gt;
&amp;lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&amp;gt;
&amp;lt;configuration&amp;gt;
        &amp;lt;property&amp;gt;
          &amp;lt;name&amp;gt;javax.jdo.option.ConnectionURL&amp;lt;/name&amp;gt;
          &amp;lt;value&amp;gt;jdbc:mysql://hop01:3306/metastore?createDatabaseIfNotExist=true&amp;lt;/value&amp;gt;
          &amp;lt;description&amp;gt;JDBC connect string for a JDBC metastore&amp;lt;/description&amp;gt;
        &amp;lt;/property&amp;gt;

        &amp;lt;property&amp;gt;
          &amp;lt;name&amp;gt;javax.jdo.option.ConnectionDriverName&amp;lt;/name&amp;gt;
          &amp;lt;value&amp;gt;com.mysql.jdbc.Driver&amp;lt;/value&amp;gt;
          &amp;lt;description&amp;gt;Driver class name for a JDBC metastore&amp;lt;/description&amp;gt;
        &amp;lt;/property&amp;gt;

        &amp;lt;property&amp;gt;
          &amp;lt;name&amp;gt;javax.jdo.option.ConnectionUserName&amp;lt;/name&amp;gt;
          &amp;lt;value&amp;gt;root&amp;lt;/value&amp;gt;
          &amp;lt;description&amp;gt;username to use against metastore database&amp;lt;/description&amp;gt;
        &amp;lt;/property&amp;gt;

        &amp;lt;property&amp;gt;
          &amp;lt;name&amp;gt;javax.jdo.option.ConnectionPassword&amp;lt;/name&amp;gt;
          &amp;lt;value&amp;gt;123456&amp;lt;/value&amp;gt;
          &amp;lt;description&amp;gt;password to use against metastore database&amp;lt;/description&amp;gt;
        &amp;lt;/property&amp;gt;
&amp;lt;/configuration&amp;gt;
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;配置完成后，依次重启MySQL、hadoop、hive环境，查看MySQL数据库信息，多了metastore数据库和相关表。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;4、后台启动hiveserver2&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;[root@hop01 hive1.2]# bin/hiveserver2 &amp;amp;
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;5、Jdbc连接测试&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;[root@hop01 hive1.2]# bin/beeline
Beeline version 1.2.1 by Apache Hive
beeline&amp;gt; !connect jdbc:hive2://hop01:10000
Connecting to jdbc:hive2://hop01:10000
Enter username for jdbc:hive2://hop01:10000: hiveroot (账户回车)
Enter password for jdbc:hive2://hop01:10000: ******   (密码123456回车)
Connected to: Apache Hive (version 1.2.1)
Driver: Hive JDBC (version 1.2.1)
0: jdbc:hive2://hop01:10000&amp;gt; show databases;
+----------------+--+
| database_name  |
+----------------+--+
| default        |
+----------------+--+
&lt;/code&gt;
&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;1、基础函数&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-sql&quot;&gt;select count(*) count_user from hv_user;
select sum(age) sum_age from hv_user;
select min(age) min_age,max(age) max_age from hv_user;
+----------+----------+--+
| min_age  | max_age  |
+----------+----------+--+
| 23       | 25       |
+----------+----------+--+
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;2、条件查询语句&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-sql&quot;&gt;select * from hv_user where name='test-user' limit 1;
+-------------+---------------+--------------+--+
| hv_user.id  | hv_user.name  | hv_user.age  |
+-------------+---------------+--------------+--+
| 1           | test-user     | 23           |
+-------------+---------------+--------------+--+

select * from hv_user where id&amp;gt;1 AND name like 'dev%';
+-------------+---------------+--------------+--+
| hv_user.id  | hv_user.name  | hv_user.age  |
+-------------+---------------+--------------+--+
| 2           | dev-user      | 25           |
+-------------+---------------+--------------+--+

select count(*) count_name,name from hv_user group by name;
+-------------+------------+--+
| count_name  |    name    |
+-------------+------------+--+
| 1           | dev-user   |
| 1           | test-user  |
+-------------+------------+--+
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;3、连接查询&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-sql&quot;&gt;select t1.*,t2.* from hv_user t1 join hv_dept t2 on t1.id=t2.dp_id;
+--------+------------+---------+-----------+-------------+--+
| t1.id  |  t1.name   | t1.age  | t2.dp_id  | t2.dp_name  |
+--------+------------+---------+-----------+-------------+--+
| 1      | test-user  | 23      | 1         | 技术部      |
+--------+------------+---------+-----------+-------------+--+
&lt;/code&gt;
&lt;/pre&gt;

&lt;pre&gt;
&lt;code&gt;GitHub·地址
https://github.com/cicadasmile/big-data-parent
GitEE·地址
https://gitee.com/cicadasmile/big-data-parent
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;推荐阅读：编程体系整理&lt;/strong&gt;&lt;/p&gt;
&lt;/div&gt;</description>
<pubDate>Mon, 04 Jan 2021 00:00:00 +0000</pubDate>
<dc:creator>知了一笑</dc:creator>
<og:description>Hive是基于Hadoop的一个数据仓库工具，用来进行数据提取、转化、加载，是一个可以对Hadoop中的大规模存储的数据进行查询和分析存储的组件，Hive数据仓库工具能将结构化的数据文件映射为一张数据</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/cicada-smile/p/14227369.html</dc:identifier>
</item>
<item>
<title>Kubernetes官方java客户端之二：序列化和反序列化问题 - 程序员欣宸</title>
<link>http://www.cnblogs.com/bolingcavalry/p/14227738.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/bolingcavalry/p/14227738.html</guid>
<description>&lt;h3 id=&quot;欢迎访问我的github&quot;&gt;欢迎访问我的GitHub&lt;/h3&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/zq2599/blog_demos&quot; target=&quot;_blank&quot;&gt;https://github.com/zq2599/blog_demos&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;内容：所有原创文章分类汇总及配套源码，涉及Java、Docker、Kubernetes、DevOPS等；&lt;/p&gt;
&lt;h3 id=&quot;问题场景&quot;&gt;问题场景&lt;/h3&gt;
&lt;p&gt;本文是《Kubernetes官方java客户端》的第二篇，在进入编码实战章节之前，有个问题需要大家有足够的了解，避免在后面的实战中耗费精力处理此类问题，来看看究竟是什么问题：&lt;/p&gt;
&lt;ol readability=&quot;4&quot;&gt;&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;SpringBoot是常用的应用框架，《Kubernetes官方java客户端》系列的应用都是基于SpringBoot-2.3.1版本的；&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;下图是SpringBoot-2.3.1.RELEASE的官方文档，红框表明默认的JSON处理库是Jackson：&lt;br/&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/485422/202101/485422-20210104074816720-1669097882.png&quot; alt=&quot;在这里插入图片描述&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;看到这里您是否有种不祥预感：K8S官方java客户端是谷歌的，涉及到JSON处理时会不会首选自家的Gson？&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;&lt;span&gt;V1HTTPGetAction.java&lt;/span&gt;是java客户端中常用到的数据结构，用来封装http请求相关的参数，来看看其源码，如下图，果然用上了Gson的注解：&lt;br/&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/485422/202101/485422-20210104074818382-947759646.png&quot; alt=&quot;在这里插入图片描述&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;上图提到的&lt;span&gt;IntOrString&lt;/span&gt;类要重点关注，用处广泛，打开其源码如下图，请记下红框2中的代码，后面提到的问题就来源于此：&lt;br/&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/485422/202101/485422-20210104074819707-157803312.png&quot; alt=&quot;在这里插入图片描述&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;&lt;ul&gt;&lt;li&gt;小结：SpringBoot默认的JSON处理类是Jackson，K8S官方java客户端内的Bean在涉及到JSON相关的序列化和反序列化处理时，使用了Gson注解，因此上述Bean实例在SpringBoot中涉及到JSON处理时，可能会有问题(这时只能说可能)，例如RestController返回对象，会被Jackson转为JSON；&lt;/li&gt;
&lt;/ul&gt;&lt;h3 id=&quot;复现问题&quot;&gt;复现问题&lt;/h3&gt;
&lt;ol&gt;&lt;li&gt;这里用一个SpringBoot工程来演示此问题（该工程名为OutsideclusterApplication，下一篇文章会详细说明），如下代码是个http接口响应，可见V1PodList实例作为接口返回时，会被SpringBoot用Jackson转为JSON返回给前端：&lt;/li&gt;
&lt;/ol&gt;&lt;pre&gt;
&lt;code class=&quot;language-shell&quot;&gt;@RequestMapping(value = &quot;/hello&quot;)
    public V1PodList hello() throws Exception {
        // 存放K8S的config文件的全路径
        String kubeConfigPath = &quot;/Users/zhaoqin/temp/202007/05/config&quot;;

        // 以config作为入参创建的client对象，可以访问到K8S的API Server
        ApiClient client = ClientBuilder
                .kubeconfig(KubeConfig.loadKubeConfig(new FileReader(kubeConfigPath)))
                .build();

        Configuration.setDefaultApiClient(client);

        CoreV1Api api = new CoreV1Api();

        // 调用客户端API取得所有pod信息
        V1PodList v1PodList = api.listPodForAllNamespaces(null, null, null, null, null, null, null, null, null);

        return v1PodList;
    }
&lt;/code&gt;
&lt;/pre&gt;
&lt;ol start=&quot;2&quot; readability=&quot;1.5&quot;&gt;&lt;li readability=&quot;1&quot;&gt;
&lt;p&gt;上述代码运行起来，在浏览器访问该接口时，控制台抛出以下错误，IntOrString.getStrValue方法，就是前面咱们看过的那段，IntOrString中实际上保存的是int数据，但是Jackson执行了其&lt;span&gt;getStrValue&lt;/span&gt;方法：&lt;br/&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/485422/202101/485422-20210104074821225-1443774302.png&quot; alt=&quot;在这里插入图片描述&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;2&quot;&gt;
&lt;p&gt;至于为什么Jackson会执行getStrValue方法，篇幅原因就不在此展开了，简单提一下，在java客户端的BeanPropertyWriter类中，选择方法的逻辑如下图，红框中展示了判定逻辑，此处getStrValue方法命中了该逻辑，如果您尝试用在红框处打上断点观察，会发现有很多方法都符合此条件：&lt;br/&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/485422/202101/485422-20210104074821962-585896793.png&quot; alt=&quot;在这里插入图片描述&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;&lt;h3 id=&quot;解决问题的思路&quot;&gt;解决问题的思路&lt;/h3&gt;
&lt;p&gt;我这里，解决问题的思路有两个：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;让Jackson在序列化的时候，能够调用正确的方法，以IntOrString为例，如果此时内部保存int型数据，就应该执行其getIntValue方法即可；&lt;/li&gt;
&lt;li&gt;Bean中使用了Gson注释，就是打算用Gson来处理序列化和反序列化操作的，因此序列化和反序列化的地方都改用Gson处理；&lt;/li&gt;
&lt;/ol&gt;&lt;ul&gt;&lt;li&gt;上述两个思路，我选择了第二种，毕竟第一种太难了...&lt;/li&gt;
&lt;/ul&gt;&lt;h3 id=&quot;解决问题&quot;&gt;解决问题&lt;/h3&gt;
&lt;ol readability=&quot;-1&quot;&gt;&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;问题解决起来并不难，先看SpringBoot-2.3.1.RELEASE官方文档：&lt;br/&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/485422/202101/485422-20210104074822663-837242560.png&quot; alt=&quot;在这里插入图片描述&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;结合官方文档，我们要做两件事情：&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;&lt;ul&gt;&lt;li&gt;首先，classpath中有Gson，这个已经有了，因为K8S官方java客户端会依赖Gson；&lt;/li&gt;
&lt;li&gt;其次，classpath中不要出现Jackson，为了达到这个目的我们需要做以下操作，排除spring-boot-starter-web的依赖(为什么不直接排除jackson的库呢？您可以执行mvn dependency:tree命令细看依赖树，会发现对jackson的依赖并非单一关系)：&lt;/li&gt;
&lt;/ul&gt;&lt;pre&gt;
&lt;code class=&quot;language-xml&quot;&gt;&amp;lt;dependency&amp;gt;
        &amp;lt;groupId&amp;gt;org.springframework.boot&amp;lt;/groupId&amp;gt;
        &amp;lt;artifactId&amp;gt;spring-boot-starter-web&amp;lt;/artifactId&amp;gt;
                &amp;lt;exclusions&amp;gt;
                        &amp;lt;exclusion&amp;gt;
                                &amp;lt;groupId&amp;gt;org.springframework.boot&amp;lt;/groupId&amp;gt;
                                &amp;lt;artifactId&amp;gt;spring-boot-starter-json&amp;lt;/artifactId&amp;gt;
                        &amp;lt;/exclusion&amp;gt;
                &amp;lt;/exclusions&amp;gt;
&amp;lt;/dependency&amp;gt;
&lt;/code&gt;
&lt;/pre&gt;
&lt;ol start=&quot;3&quot;&gt;&lt;li&gt;建议您执行mvn dependency:tree命令细看整个项目的依赖树，确保jackson依赖已经全部去掉；&lt;/li&gt;
&lt;li&gt;再次运行上述项目，如下图，服务端不再报错，页面上返回数据正常：&lt;br/&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/485422/202101/485422-20210104074823143-1547529755.png&quot; alt=&quot;在这里插入图片描述&quot; loading=&quot;lazy&quot;/&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;h3 id=&quot;使用jackson的场景&quot;&gt;使用Jackson的场景&lt;/h3&gt;
&lt;ul readability=&quot;1&quot;&gt;&lt;li readability=&quot;2&quot;&gt;
&lt;p&gt;上述方式虽然可行，但并非所有项目都能坚持使用Gson而放弃Jackson，对于使用Jackson的项目，请避免Jackson参与K8S官方java客户端bean的序列化和反序列化操作，以上面出现的Controller代码为例，不要直接将V1PodList实例返回，您可以选择先用Gson序列化成JSON字符串，再返回字符串给前端，也可以自己定义VO对象，将V1PodList实例转成VO对象再返回；&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;至此，使用K8S官方java客户端之前要注意的问题已经弄明白了，接下来的进入精彩的实战章节吧，一起体验kubernetes官方为java程序员精心准备的工具；&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;h3 id=&quot;你不孤单，欣宸原创一路相伴&quot;&gt;你不孤单，欣宸原创一路相伴&lt;/h3&gt;
&lt;ol&gt;&lt;li&gt;&lt;a href=&quot;https://xinchen.blog.csdn.net/article/details/105068742&quot; target=&quot;_blank&quot;&gt;Java系列&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://xinchen.blog.csdn.net/article/details/105086498&quot; target=&quot;_blank&quot;&gt;Spring系列&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://xinchen.blog.csdn.net/article/details/105086732&quot; target=&quot;_blank&quot;&gt;Docker系列&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://xinchen.blog.csdn.net/article/details/105086794&quot; target=&quot;_blank&quot;&gt;kubernetes系列&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://xinchen.blog.csdn.net/article/details/105086850&quot; target=&quot;_blank&quot;&gt;数据库+中间件系列&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://xinchen.blog.csdn.net/article/details/105086920&quot; target=&quot;_blank&quot;&gt;DevOps系列&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;h3 id=&quot;欢迎关注公众号：程序员欣宸&quot;&gt;欢迎关注公众号：程序员欣宸&lt;/h3&gt;
&lt;blockquote readability=&quot;4.258064516129&quot;&gt;
&lt;p&gt;微信搜索「程序员欣宸」，我是欣宸，期待与您一同畅游Java世界...&lt;br/&gt;&lt;a href=&quot;https://github.com/zq2599/blog_demos&quot; target=&quot;_blank&quot;&gt;https://github.com/zq2599/blog_demos&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
</description>
<pubDate>Sun, 03 Jan 2021 23:48:00 +0000</pubDate>
<dc:creator>程序员欣宸</dc:creator>
<og:description>欢迎访问我的GitHub https://github.com/zq2599/blog_demos 内容：所有原创文章分类汇总及配套源码，涉及Java、Docker、Kubernetes、DevOPS</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/bolingcavalry/p/14227738.html</dc:identifier>
</item>
<item>
<title>ASP.NET Core Controller与IOC的羁绊 - yi念之间</title>
<link>http://www.cnblogs.com/wucy/p/14222973.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/wucy/p/14222973.html</guid>
<description>&lt;h4 id=&quot;前言&quot;&gt;前言&lt;/h4&gt;
&lt;p&gt;    看到标题可能大家会有所疑问Controller和IOC能有啥羁绊，但是我还是拒绝当一个标题党的。相信有很大一部分人已经知道了这么一个结论，默认情况下ASP.NET Core的Controller并不会托管到IOC容器中，注意关键字我说的是&quot;默认&quot;，首先咱们不先说为什么，如果还有不知道这个结论的同学们可以自己验证一下，验证方式也很简单，大概可以通过以下几种方式。&lt;/p&gt;
&lt;h4 id=&quot;验证controller不在ioc中&quot;&gt;验证Controller不在IOC中&lt;/h4&gt;
&lt;p&gt;首先，我们可以尝试在ServiceProvider中获取某个Controller实例，比如&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-cs&quot;&gt;public void Configure(IApplicationBuilder app, IWebHostEnvironment env)
{
    var productController = app.ApplicationServices.GetService&amp;lt;ProductController&amp;gt;();
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;这是最直接的方式，可以在IOC容器中获取注册过的类型实例，很显然结果会为null。另一种方式，也是利用它的另一个特征，那就是通过构造注入的方式，如下所示我们在OrderController中注入ProductController,&lt;span&gt;显然这种方式是不合理的，但是为了求证一个结果，我们这里仅做演示，强烈不建议实际开发中这么写，这是不规范也是不合理的写法&lt;/span&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-cs&quot;&gt;public class OrderController : Controller
{
    private readonly ProductController _productController;
    public OrderController(ProductController productController)
    {
        _productController = productController;
    }

    public IActionResult Index()
    {
        return View();
    }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;结果显然是会报一个错InvalidOperationException: Unable to resolve service for type 'ProductController' while attempting to activate 'OrderController'。原因就是因为ProductController并不在IOC容器中,所以通过注入的方式会报错。还有一种方式，可能不太常用，这个是利用注入的一个特征，可能有些同学已经了解过了，那就是通过自带的DI，即使一个类中包含多个构造函数，它也会选择最优的一个，也就是说自带的DI允许类包含多个构造函数。利用这个特征，我们可以在Controller中验证一下&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-cs&quot;&gt;public class OrderController : Controller
{
    private readonly IOrderService _orderService;
    private readonly IPersonService _personService;

    public OrderController(IOrderService orderService)
    {
        _orderService = orderService;
    }

    public OrderController(IOrderService orderService, IPersonService personService)
    {
        _orderService = orderService;
        _personService = personService;
    }

    public IActionResult Index()
    {
        return View();
    }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;我们在Controller中编写了两个构造函数，理论上来说这是符合DI特征的，运行起来测试一下，依然会报错InvalidOperationException: Multiple constructors accepting all given argument types have been found in type 'OrderController'. There should only be one applicable constructor。以上种种都是为了证实一个结论，默认情况下Controller并不会托管到IOC当中。&lt;/p&gt;
&lt;h4 id=&quot;defaultcontrollerfactory源码探究&quot;&gt;DefaultControllerFactory源码探究&lt;/h4&gt;
&lt;p&gt;    上面虽然我们看到了一些现象，能说明Controller默认情况下并不在IOC中托管，但是还没有足够的说服力，接下来我们就来查看源码,这是最有说服力的。我们找到Controller工厂注册的地方，在MvcCoreServiceCollectionExtensions扩展类中[&lt;a href=&quot;https://github.com/dotnet/aspnetcore/blob/v5.0.1/src/Mvc/Mvc.Core/src/DependencyInjection/MvcCoreServiceCollectionExtensions.cs#L186&quot; target=&quot;_blank&quot;&gt;点击查看源码👈&lt;/a&gt;]的AddMvcCoreServices方法里&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-cs&quot;&gt;//给IControllerFactory注册默认的Controller工厂类DefaultControllerFactory
//也是Controller创建的入口
services.TryAddSingleton&amp;lt;IControllerFactory, DefaultControllerFactory&amp;gt;();
//真正创建Controller的工作类DefaultControllerActivator
services.TryAddTransient&amp;lt;IControllerActivator, DefaultControllerActivator&amp;gt;();
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;由此我们可以得出，默认的Controller创建工厂类为DefaultControllerFactory，那么我们直接找到源码位置[&lt;a href=&quot;https://github.com/dotnet/aspnetcore/blob/v5.0.1/src/Mvc/Mvc.Core/src/Controllers/DefaultControllerFactory.cs&quot; target=&quot;_blank&quot;&gt;点击查看源码👈&lt;/a&gt;],&lt;br/&gt;为了方便阅读，精简一下源码如下所示&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-cs&quot;&gt;internal class DefaultControllerFactory : IControllerFactory
{
    //真正创建Controller的工作者
    private readonly IControllerActivator _controllerActivator;
    private readonly IControllerPropertyActivator[] _propertyActivators;

    public DefaultControllerFactory(
        IControllerActivator controllerActivator,
        IEnumerable&amp;lt;IControllerPropertyActivator&amp;gt; propertyActivators)
    {
        _controllerActivator = controllerActivator;
        _propertyActivators = propertyActivators.ToArray();
    }

    /// &amp;lt;summary&amp;gt;
    /// 创建Controller实例的方法
    /// &amp;lt;/summary&amp;gt;
    public object CreateController(ControllerContext context)
    {
        //创建Controller实例的具体方法(这是关键方法)
        var controller = _controllerActivator.Create(context);
        foreach (var propertyActivator in _propertyActivators)
        {
            propertyActivator.Activate(context, controller);
        }
        return controller;
    }

    /// &amp;lt;summary&amp;gt;
    /// 释放Controller实例的方法
    /// &amp;lt;/summary&amp;gt;
    public void ReleaseController(ControllerContext context, object controller)
    {
        _controllerActivator.Release(context, controller);
    }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;用过上面的源码可知，真正创建Controller的地方在_controllerActivator.Create方法中，通过上面的源码可知为IControllerActivator默认注册的是DefaultControllerActivator类，直接找到源码位置[&lt;a href=&quot;https://github.com/dotnet/aspnetcore/blob/v5.0.1/src/Mvc/Mvc.Core/src/Controllers/DefaultControllerActivator.cs&quot; target=&quot;_blank&quot;&gt;点击查看源码👈&lt;/a&gt;],我们继续简化一下源码如下所示&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-cs&quot;&gt;internal class DefaultControllerActivator : IControllerActivator
{
    private readonly ITypeActivatorCache _typeActivatorCache;

    public DefaultControllerActivator(ITypeActivatorCache typeActivatorCache)
    {
        _typeActivatorCache = typeActivatorCache;
    }

    /// &amp;lt;summary&amp;gt;
    /// Controller实例的创建方法
    /// &amp;lt;/summary&amp;gt;
    public object Create(ControllerContext controllerContext)
    {
        //获取Controller类型信息
        var controllerTypeInfo = controllerContext.ActionDescriptor.ControllerTypeInfo;
        //获取ServiceProvider
        var serviceProvider = controllerContext.HttpContext.RequestServices;
        //创建controller实例
        return _typeActivatorCache.CreateInstance&amp;lt;object&amp;gt;(serviceProvider, controllerTypeInfo.AsType());
    }

    /// &amp;lt;summary&amp;gt;
    /// 释放Controller实例
    /// &amp;lt;/summary&amp;gt;
    public void Release(ControllerContext context, object controller)
    {
        //如果controller实现了IDisposable接口，那么Release的时候会自动调用Controller的Dispose方法
        //如果我们在Controller中存在需要释放或者关闭的操作，可以再Controller的Dispose方法中统一释放
        if (controller is IDisposable disposable)
        {
            disposable.Dispose();
        }
    }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;通过上面的代码我们依然要继续深入到ITypeActivatorCache实现中去寻找答案，通过查看MvcCoreServiceCollectionExtensions类的AddMvcCoreServices方法源码我们可以找到如下信息&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-cs&quot;&gt;services.TryAddSingleton&amp;lt;ITypeActivatorCache, TypeActivatorCache&amp;gt;();
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;有了这个信息，我们可以直接找到TypeActivatorCache类的源码[&lt;a href=&quot;https://github.com/dotnet/aspnetcore/blob/v5.0.1/src/Mvc/Mvc.Core/src/Infrastructure/TypeActivatorCache.cs&quot; target=&quot;_blank&quot;&gt;点击查看源码👈&lt;/a&gt;]代码并不多，大致如下所示&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-cs&quot;&gt;internal class TypeActivatorCache : ITypeActivatorCache
{
    //创建ObjectFactory的委托
    private readonly Func&amp;lt;Type, ObjectFactory&amp;gt; _createFactory =
        (type) =&amp;gt; ActivatorUtilities.CreateFactory(type, Type.EmptyTypes);
    //Controller类型和对应创建Controller实例的ObjectFactory实例的缓存
    private readonly ConcurrentDictionary&amp;lt;Type, ObjectFactory&amp;gt; _typeActivatorCache =
           new ConcurrentDictionary&amp;lt;Type, ObjectFactory&amp;gt;();

    /// &amp;lt;summary&amp;gt;
    /// 真正创建实例的地方
    /// &amp;lt;/summary&amp;gt;
    public TInstance CreateInstance&amp;lt;TInstance&amp;gt;(
        IServiceProvider serviceProvider,
        Type implementationType)
    {
        //真正创建的操作是createFactory
        //通过Controller类型在ConcurrentDictionary缓存中获得ObjectFactory
        //而ObjectFactory实例由ActivatorUtilities.CreateFactory方法创建的
        var createFactory = _typeActivatorCache.GetOrAdd(implementationType, _createFactory);
        //返回创建实例
        return (TInstance)createFactory(serviceProvider, arguments: null);
    }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;通过上面类的代码&lt;span&gt;我们可以清晰的得出一个结论，默认情况下Controller实例是由ObjectFactory创建出来的，而ObjectFactory实例是由ActivatorUtilities的CreateFactory创建出来,所以Controller实例每次都是由ObjectFactory创建而来，并非注册到IOC容器中。&lt;/span&gt;并且我们还可以得到一个结论ObjectFactory应该是一个委托，我们找到ObjectFactory定义的地方[&lt;a href=&quot;https://github.com/dotnet/aspnetcore/blob/v5.0.1/src/Shared/ActivatorUtilities/ObjectFactory.cs&quot; target=&quot;_blank&quot;&gt;点击查看源码👈&lt;/a&gt;]&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-cs&quot;&gt;delegate object ObjectFactory(IServiceProvider serviceProvider, object[] arguments);
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;这个确实如我们猜想的那般，这个委托会通过IServiceProvider实例去构建类型的实例，通过上述源码相关的描述我们会产生一个疑问，既然Controller实例并非由IOC容器托管，它由ObjectFactory创建而来，但是ObjectFactory实例又是由ActivatorUtilities构建的，那么生产对象的核心也就在ActivatorUtilities类中，接下来我们就来探究一下ActivatorUtilities的神秘面纱。&lt;/p&gt;
&lt;h4 id=&quot;activatorutilities类的探究&quot;&gt;ActivatorUtilities类的探究&lt;/h4&gt;
&lt;p&gt;    书接上面，我们知道了ActivatorUtilities类是创建Controller实例最底层的地方，那么ActivatorUtilities到底和容器是啥关系，因为我们看到了ActivatorUtilities创建实例需要依赖ServiceProvider,一切都要从找到ActivatorUtilities类的源码开始。我们最初接触这个类的地方在于它通过CreateFactory方法创建了ObjectFactory实例，那么我们就从这个地方开始，找到源码位置[&lt;a href=&quot;https://github.com/dotnet/aspnetcore/blob/v5.0.1/src/Shared/ActivatorUtilities/ActivatorUtilities.cs#L107&quot; target=&quot;_blank&quot;&gt;点击查看源码👈&lt;/a&gt;]实现如下&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-cs&quot;&gt;public static ObjectFactory CreateFactory(Type instanceType, Type[] argumentTypes)
{
    //查找instanceType的构造函数
    //找到构造信息ConstructorInfo
    //得到给定类型与查找类型instanceType构造函数的映射关系
    FindApplicableConstructor(instanceType, argumentTypes, out ConstructorInfo constructor, out int?[] parameterMap);
    //构建IServiceProvider类型参数
    var provider = Expression.Parameter(typeof(IServiceProvider), &quot;provider&quot;);
    //构建给定类型参数数组参数
    var argumentArray = Expression.Parameter(typeof(object[]), &quot;argumentArray&quot;);
    //通过构造信息、构造参数对应关系、容器和给定类型构建表达式树Body
    var factoryExpressionBody = BuildFactoryExpression(constructor, parameterMap, provider, argumentArray);
    //构建lambda
    var factoryLamda = Expression.Lambda&amp;lt;Func&amp;lt;IServiceProvider, object[], object&amp;gt;&amp;gt;(
        factoryExpressionBody, provider, argumentArray);
    var result = factoryLamda.Compile();
    //返回执行结果
    return result.Invoke;
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;ActivatorUtilities类的CreateFactory方法代码虽然比较简单，但是它涉及到调用了其他方法，由于嵌套的比较深代码比较多，而且不是本文讲述的重点，我们就不再这里细说了，我们可以大概的描述一下它的工作流程。&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;首先在给定的类型里查找到合适的构造函数，这里我们可以理解为查找Controller的构造函数。&lt;/li&gt;
&lt;li&gt;然后得到构造信息，并得到构造函数的参数与给定类型参数的对应关系&lt;/li&gt;
&lt;li&gt;通过构造信息和构造参数的对应关系，在IServiceProvider得到对应类型的实例为构造函数赋值&lt;/li&gt;
&lt;li&gt;最后经过上面的操作通过初始化指定的构造函数来创建给定Controller类型的实例&lt;br/&gt;综上述的相关步骤，我们可以得到一个结论，Controller实例的初始化是通过遍历Controller类型构造函数里的参数，然后根据构造函数每个参数的类型在IServiceProvider查找已经注册到容器中相关的类型实例，最终初始化得到的Controller实例。这就是在IServiceProvider得到需要的依赖关系，然后创建自己的实例，它内部是使用的表达式树来完成的这一切，可以理解为更高效的反射方式。&lt;br/&gt;关于ActivatorUtilities类还包含了其他比较实用的方法，比如CreateInstance方法&lt;/li&gt;
&lt;/ul&gt;&lt;pre&gt;
&lt;code class=&quot;language-cs&quot;&gt;public static T CreateInstance&amp;lt;T&amp;gt;(IServiceProvider provider, params object[] parameters)
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;它可以通过构造注入的方式创建指定类型T的实例，其中构造函数里具体的参数实例是通过在IServiceProvider实例里获取到的，比如我们我们有这么一个类&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-cs&quot;&gt;public class OrderController 
{
    private readonly IOrderService _orderService;
    private readonly IPersonService _personService;

    public OrderController(IOrderService orderService, IPersonService personService)
    {
        _orderService = orderService;
        _personService = personService;
    }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;其中它所依赖的IOrderService和IPersonService实例是注册到IOC容器中的&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-cs&quot;&gt;IServiceCollection services = new ServiceCollection()
 .AddScoped&amp;lt;IPersonService, PersonService&amp;gt;()
 .AddScoped&amp;lt;IOrderService, OrderService&amp;gt;();
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;然后你想获取到OrderController的实例，但是它只包含一个有参构造函数，但是构造函数的参数都以注册到IOC容器中。当存在这种场景你便可以通过以下方式得到你想要的类型实例，如下所示&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-cs&quot;&gt;IServiceProvider serviceProvider = services.BuildServiceProvider();
OrderController orderController = ActivatorUtilities.CreateInstance&amp;lt;OrderController&amp;gt;(serviceProvider);
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;即使你的类型OrderController并没有注册到IOC容器中，但是它的依赖都在容器中，你也可以通过构造注入的方式得到你想要的实例。总的来说ActivatorUtilities里的方法还是比较实用的，有兴趣的同学可以自行尝试一下，也可以通过查看&lt;a href=&quot;https://github.com/dotnet/aspnetcore/blob/v5.0.1/src/Shared/ActivatorUtilities/ActivatorUtilities.cs&quot; target=&quot;_blank&quot;&gt;ActivatorUtilities源码&lt;/a&gt;的方式了解它的工作原理。&lt;/p&gt;
&lt;h4 id=&quot;addcontrollersasservices方法&quot;&gt;AddControllersAsServices方法&lt;/h4&gt;
&lt;p&gt;    上面我们主要是讲解了默认情况下Controller并不是托管到IOC容器中的，它只是表现出来的让你以为它是在IOC容器中，因为它可以通过构造函数注入相关实例，这主要是ActivatorUtilities类的功劳。说了这么多Controller实例到底可不可以注册到IOC容器中，让它成为真正受到IOC容器的托管者。要解决这个，必须要满足两点条件&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;首先，需要将Controller注册到IOC容器中，但是仅仅这样还不够，因为Controller是由ControllerFactory创建而来&lt;/li&gt;
&lt;li&gt;其次，我们要改造ControllerFactory类中创建Controller实例的地方让它从容器中获取Controller实例，这样就解决了所有的问题&lt;br/&gt;如果我们自己去实现将Controller托管到IOC容器中，就需要满足以上两个操作一个是要将Controller放入容器，然后让创建Controller的地方从IOC容器中直接获取Controller实例。庆幸的是，微软帮我们封装了一个相关的方法，它可以帮我们解决将Controller托管到IOC容器的问题，它的使用方法如下所示&lt;/li&gt;
&lt;/ul&gt;&lt;pre&gt;
&lt;code class=&quot;language-cs&quot;&gt;services.AddMvc().AddControllersAsServices();
//或其他方式，这取决于你构建的Web项目的用途可以是WebApi、Mvc、RazorPage等
//services.AddMvcCore().AddControllersAsServices();
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;相信大家都看到了，玄机就在AddControllersAsServices方法中，但是它存在于MvcCoreMvcBuilderExtensions类和MvcCoreMvcCoreBuilderExtensions类中，不过问题不大，因为它们的代码是完全一样的。只是因为你可以通过多种方式构建Web项目比如AddMvc或者AddMvcCore，废话不多说直接上代码[&lt;a href=&quot;https://github.com/dotnet/aspnetcore/blob/v5.0.1/src/Mvc/Mvc.Core/src/DependencyInjection/MvcCoreMvcBuilderExtensions.cs#L155&quot; target=&quot;_blank&quot;&gt;点击查看源码👈&lt;/a&gt;]&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-cs&quot;&gt;public static IMvcBuilder AddControllersAsServices(this IMvcBuilder builder)
{
    if (builder == null)
    {
        throw new ArgumentNullException(nameof(builder));
    }
    var feature = new ControllerFeature();
    builder.PartManager.PopulateFeature(feature);
    //第一将Controller实例添加到IOC容器中
    foreach (var controller in feature.Controllers.Select(c =&amp;gt; c.AsType()))
    {
        //注册的声明周期是Transient
        builder.Services.TryAddTransient(controller, controller);
    }
    //第二替换掉原本DefaultControllerActivator的为ServiceBasedControllerActivator
    builder.Services.Replace(ServiceDescriptor.Transient&amp;lt;IControllerActivator, ServiceBasedControllerActivator&amp;gt;());
    return builder;
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;第一点没问题那就是将Controller实例添加到IOC容器中，第二点它替换掉了DefaultControllerActivator为为ServiceBasedControllerActivator。通过上面我们讲述的源码了解到DefaultControllerActivator是默认提供Controller实例的地方是获取Controller实例的核心所在，那么我们看看ServiceBasedControllerActivator与DefaultControllerActivator到底有何不同，直接贴出代码[&lt;a href=&quot;https://github.com/dotnet/aspnetcore/blob/v5.0.1/src/Mvc/Mvc.Core/src/Controllers/ServiceBasedControllerActivator.cs&quot; target=&quot;_blank&quot;&gt;点击查看源码👈&lt;/a&gt;]&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-cs&quot;&gt;public class ServiceBasedControllerActivator : IControllerActivator
{
    public object Create(ControllerContext actionContext)
    {
        if (actionContext == null)
        {
            throw new ArgumentNullException(nameof(actionContext));
        }
        //获取Controller类型
        var controllerType = actionContext.ActionDescriptor.ControllerTypeInfo.AsType();
        //通过Controller类型在容器中获取实例
        return actionContext.HttpContext.RequestServices.GetRequiredService(controllerType);
    }

    public virtual void Release(ControllerContext context, object controller)
    {
    }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;    相信大家对上面的代码一目了然了，和我们上面描述的一样，将创建Controller实例的地方改造了在容器中获取的方式。不知道大家有没有注意到ServiceBasedControllerActivator的Release的方法居然没有实现，这并不是我没有粘贴出来，确实是没有代码，之前我们看到的DefaultControllerActivator可是有调用Controller的Disposed的方法，这里却啥也没有。相信聪明的你已经想到了，因为Controller已经托管到了IOC容器中，所以他的生命及其相关释放都是由IOC容器完成的，所以这里不需要任何操作。&lt;br/&gt;    我们上面还看到了注册Controller实例的时候使用的是TryAddTransient方法，也就是说每次都会创建Controller实例，至于为什么，我想大概是因为每次请求都其实只会需要一个Controller实例，况且EFCore的注册方式官方建议也是Scope的，而这里的Scope正是对应的一次Controller请求。在加上自带的IOC会提升依赖类型的声明周期，如果将Controller注册为单例的话如果使用了EFCore那么它也会被提升为单例，这样会存在很大的问题。也许正是基于这个原因默认才将Controller注册为Transient类型的，当然这并不代表只能注册为Transient类型的，如果你不使用类似EFCore这种需要作用域为Scope的服务的时候，而且保证使用的主键都可以使用单例的话，完全可以将Controller注册为别的生命周期，当然这种方式个人不是很建议。&lt;/p&gt;
&lt;h4 id=&quot;controller结合autofac&quot;&gt;Controller结合Autofac&lt;/h4&gt;
&lt;p&gt;    有时候大家可能会结合Autofac一起使用，Autofac确实是一款非常优秀的IOC框架，它它支持属性和构造两种方式注入，关于Autofac托管自带IOC的原理咱们在之前的文章&lt;a href=&quot;https://www.cnblogs.com/wucy/p/13268296.html#%E5%85%B3%E4%BA%8Euseserviceproviderfactory&quot; target=&quot;_blank&quot;&gt;浅谈.Net Core DependencyInjection源码探究&lt;/a&gt;中曾详细的讲解过，这里咱们就不过多的描述了，咱们今天要说的是Autofac和Controller的结合。如果你想保持和原有的IOC一致的使用习惯，即只使用构造注入的话，你只需要完成两步即可&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;首先将默认的IOC容器替换为Autofac，具体操作也非常简单，如下所示&lt;/li&gt;
&lt;/ul&gt;&lt;pre&gt;
&lt;code class=&quot;language-cs&quot;&gt;public static IHostBuilder CreateHostBuilder(string[] args) =&amp;gt;
            Host.CreateDefaultBuilder(args)
              .ConfigureWebHostDefaults(webBuilder =&amp;gt;
              {
                  webBuilder.UseStartup&amp;lt;Startup&amp;gt;();
              })
              //只需要在这里设置ServiceProviderFactory为AutofacServiceProviderFactory即可
              .UseServiceProviderFactory(new AutofacServiceProviderFactory());
&lt;/code&gt;
&lt;/pre&gt;
&lt;ul&gt;&lt;li&gt;然后就是咱们之前说的，要将Controller放入容器中，然后修改生产Controller实例的ControllerFactory的操作为在容器中获取，当然这一步微软已经为我们封装了便捷的方法&lt;/li&gt;
&lt;/ul&gt;&lt;pre&gt;
&lt;code class=&quot;language-cs&quot;&gt;services.AddMvc().AddControllersAsServices();
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;只需要通过上面简单得两步，既可以将Controller托管到Autofac容器中。但是，我们说过了Autofac还支持属性注入，但是默认的方式只支持构造注入的方式，那么怎么让Controller支持属性注入呢？我们还得从最根本的出发，那就是解决Controller实例存和取的问题&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;首先为了让Controller托管到Autofac中并且支持属性注入，那么就只能使用Autofac的方式去注册Controller实例，具体操作是在Startup类中添加ConfigureContainer方法，然后注册Controller并声明支持属性注入&lt;/li&gt;
&lt;/ul&gt;&lt;pre&gt;
&lt;code class=&quot;language-cs&quot;&gt;public void ConfigureContainer(ContainerBuilder builder)
{
    var controllerBaseType = typeof(ControllerBase);
    //扫描Controller类
    builder.RegisterAssemblyTypes(typeof(Program).Assembly)
    .Where(t =&amp;gt; controllerBaseType.IsAssignableFrom(t) &amp;amp;&amp;amp; t != controllerBaseType)
    //属性注入
    .PropertiesAutowired();
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;ul&gt;&lt;li&gt;其次是解决取的问题，这里我们就不需要AddControllersAsServices方法了，因为AddControllersAsServices解决了Controller实例在IOC中存和取的问题，但是这里我们只需要解决Controller取得问题说只需要使用ServiceBasedControllerActivator即可，具体操作是&lt;/li&gt;
&lt;/ul&gt;&lt;pre&gt;
&lt;code class=&quot;language-cs&quot;&gt;services.Replace(ServiceDescriptor.Transient&amp;lt;IControllerActivator, ServiceBasedControllerActivator&amp;gt;());
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;仅需要在默认的状态下完成这两步，既可以解决Controller托管到Autofac中并支持属性注入的问题，这也是最合理的方式。当然如果你使用AddControllersAsServices可是可以实现相同的效果了，只不过是没必要将容器重复的放入容器中了。&lt;/p&gt;
&lt;h4 id=&quot;总结&quot;&gt;总结&lt;/h4&gt;
&lt;p&gt;    本文我们讲述了关于ASP.NET Core Controller与IOC结合的问题，我觉得这是有必要让每个人都有所了解的知识点，因为在日常的Web开发中Controller太常用了，知道这个问题可能会让大家在开发中少走一点弯路，接下来我们来总结一下本文大致讲解的内容&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;首先说明了一个现象，那就是默认情况下Controller并不在IOC容器中，我们也通过几个示例验证了一下。&lt;/li&gt;
&lt;li&gt;其次讲解了默认情况下创造Controller实例真正的类ActivatorUtilities，并大致讲解了ActivatorUtilities的用途。&lt;/li&gt;
&lt;li&gt;然后我们找到了将Controller托管到IOC容器中的办法AddControllersAsServices，并探究了它的源码，了解了它的工作方式。&lt;/li&gt;
&lt;li&gt;最后我们又演示了如何使用最合理的方式将Controller结合Autofac一起使用，并且支持属性注入。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;本次讲解到这里就差不多了，希望本来就知道的同学们能加深一点了解，不知道的同学能够给你们提供一点帮助，能够在日常开发中少走一点弯路。新的一年开始了，本篇文章是我2021年的第一篇文章，新的一年感谢大家的支持。&lt;/p&gt;
&lt;div align=&quot;center&quot;&gt;&lt;span&gt;👇欢迎扫码关注我的公众号👇&lt;/span&gt; &lt;img src=&quot;https://img2020.cnblogs.com/blog/2042116/202006/2042116-20200622133425514-1420050576.png&quot;/&gt;&lt;/div&gt;
</description>
<pubDate>Sun, 03 Jan 2021 23:29:00 +0000</pubDate>
<dc:creator>yi念之间</dc:creator>
<og:description>前言 看到标题可能大家会有所疑问Controller和IOC能有啥羁绊，但是我还是拒绝当一个标题党的。相信有很大一部分人已经知道了这么一个结论，默认情况下ASP.NET Core的Controller</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/wucy/p/14222973.html</dc:identifier>
</item>
<item>
<title>被自己以为的GZIP秀到了 - lulianqi15</title>
<link>http://www.cnblogs.com/lulianqi/p/14227682.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/lulianqi/p/14227682.html</guid>
<description>&lt;div class=&quot;wiki-content&quot; readability=&quot;76.78916172735&quot;&gt;

&lt;h2&gt;问题的开始&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/209007/202101/209007-20210104005325044-1918140857.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt; 我司某产品线有这么一个神奇接口 (&lt;span&gt;&lt;em&gt;https://host/path/customQuery&lt;/em&gt;&lt;/span&gt;)&lt;/p&gt;
&lt;p&gt;该接口在预发或线上缓存正常的情况下TTFB为150ms左右（可以认为服务处理时间差不多就是TTFB），不过相比150ms的TTFB，显然数据资源下载时间过长的问题会更引人注意需要100ms左右（当然这也是网络条优秀的情况下，网络一般的话这个下载时间会更夸张）&lt;br/&gt;customQuery请求一次请求的数据响应大概为2.7MB, 压缩后也有超过300KB&lt;br/&gt;下载时间过长看起来就是因为这个响应实体过大了（100Mb的带宽满速，300KB差不多也需要30ms），通过测试可以发现同样的网络条件同一个应用的其他接口，如果响应压缩后小于1KB，其ContentDownLoad时间可以忽略不计（通常都会小于2ms）&lt;br/&gt;因为代理默认开启了gzip，其实数据已经被压缩了近10倍，但是压缩后的数据还是过大。&lt;br/&gt;分析了customQuery响应实体的数据结构。&lt;br/&gt;发现数据每个list中fields节点大量重复出现。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/209007/202101/209007-20210104010608348-2045719318.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;如上图其中field的描述是完全一致的（按一页50条计算，这些数据重复了50遍）&lt;br/&gt;这些数据field描述数据单个都大小大概是50KB（重复50次可以看到2.7MB的数据几乎都是这些重复的数据）&lt;/p&gt;

&lt;h2&gt;开始秀了&lt;/h2&gt;
&lt;p&gt;既然已经明确了这些重复描述数据，服务端的同学很自然想到把这些field描述提取出来重新组装数据可以大幅度减小数据传输的大小。&lt;br/&gt;不过自己恰好曾经“看过”DEFLATE压缩（http的gzip正好使用的是DEFLATE）其中使用到的LZ77是会匹配前文相同短语后面的相同短语都会被替换成“标记”。&lt;br/&gt;那我“秀”的时候又到了，当即表示采用这种数据重组的方式并不会带来明显的实际提升，因为数据实际的信息量没有实际变化，只是手动去除了冗余，而之前冗余的数据其实已经被gzip处理过了，所以仅仅单纯去除重复描述数据片段并不能带来预期的收益。&lt;br/&gt;因为我秀的时候如此自信，对方马上就自己不自信了，表示要回去先验证效果后在做打算。&lt;/p&gt;

&lt;h2&gt;看起来是失败了&lt;/h2&gt;
&lt;p&gt;果然后面的结果“居然”是我被打脸了&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/209007/202101/209007-20210104012258247-1042083910.png&quot; alt=&quot;&quot; width=&quot;821&quot; height=&quot;472&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;


&lt;p&gt; customQuery接口返回的实体大小直接变成了25kb，解压后189kb（之前是327kb，解压后2.7Mb）&lt;/p&gt;
&lt;p&gt;那这差距太大了，实体大小减小到了之前的10%不到，当然下载速度ContentDownLoad也有了大幅度的降低。（基本上就是一个RTT的时间）&lt;br/&gt;不过这完全跟我之前的认知不一样啊，一定是哪里出现了问题。（毕竟是以为自己懂了系列）&lt;/p&gt;

&lt;h2&gt;试图抢救下&lt;/h2&gt;
&lt;p&gt;为了挽回颜面，我把这2组原始数据下载下来，本地压缩进行分析（还不想承认自己错了，试图找到产生这种结果的其他解释）&lt;/p&gt;
&lt;p&gt;如下图老的数据为customQuery_v1（2.7MB），新的为customQuery_v2（190KB）&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/209007/202101/209007-20210104011546777-1825946281.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;分别使用zip，gzip，rar对2组数据进行压缩 （gzip即为http默认使用的压缩算法，MAC上直接使用gzip命令可以对文件进行压缩）&lt;br/&gt;可以发现RAR的压缩结果就与我最开始的想法差不多（即使原始数据差了超过10倍，而压缩的结果是几乎一致的，v1为19kb ；v2为17kb）&lt;br/&gt;不过gzip对2组数据的压缩结果与在浏览器上看到的是一样的。（v1为329kb ；v2为25kb）&lt;br/&gt;既然本地压缩也得到了同样的结果，看来真的是自己Too young too naive （大意了，没有闪，秀的时候应该先在本地验证一下的）&lt;/p&gt;

&lt;h2&gt;默默面对错误分析原因&lt;/h2&gt;
&lt;p&gt;但是为什么会有这样的结果，按我的理解压缩结果应该与rar一致才对。要搞清楚还要从压缩的方式入手。&lt;br/&gt;一定是我以为的压缩行为与实际存在差异，&lt;a class=&quot;external-link&quot; href=&quot;https://zh.wikipedia.org/wiki/Gzip&quot; rel=&quot;nofollow&quot;&gt;gzip&lt;/a&gt;的基础是&lt;a class=&quot;external-link&quot; href=&quot;https://zh.wikipedia.org/wiki/DEFLATE&quot; rel=&quot;nofollow&quot;&gt;DEFLATE&lt;/a&gt;，DEFLATE是&lt;a class=&quot;external-link&quot; href=&quot;https://zh.wikipedia.org/wiki/LZ77%E4%B8%8ELZ78&quot; rel=&quot;nofollow&quot;&gt;LZ77&lt;/a&gt;与&lt;a class=&quot;external-link&quot; href=&quot;https://zh.wikipedia.org/wiki/%E5%93%88%E5%A4%AB%E6%9B%BC%E7%BC%96%E7%A0%81&quot; rel=&quot;nofollow&quot;&gt;哈夫曼编码&lt;/a&gt;的一个组合体（ &lt;a class=&quot;external-link&quot; href=&quot;https://tools.ietf.org/html/rfc1951&quot; rel=&quot;nofollow&quot;&gt;https://tools.ietf.org/html/rfc1951&lt;/a&gt;）&lt;br/&gt;Huffman Coding 只是单纯的字符编码，编码后的大小与编码前的大小直接正相关，肯定不是产生结果的原因。&lt;br/&gt;那剩下就只有是LZ77，只能是LZ77一开始没有把那些重复的fields压缩掉，而为什么LZ77没有把原始数据里大量重复的描述“标记”起来。&lt;br/&gt;LZ77整体是是使用已经出现过的相应匹配数据信息替换当前数据从而实现压缩功能，为了匹配数据需要用到了“滑动窗口”的概念&lt;br/&gt;细细一品，LZ77并不是全文匹配，数据为了可以边发送边压缩会进行分块压缩。通过查阅RFC文档，大概可以明确块的大小被限制在64k内，最大滑动窗口就是64k/2=32k，并且还要求“标记”的最大长度为256字节（当然标记长度这个问题不大，大不了不多用几个标记）。这里的问题在于使用滑动窗口就要求重复的数据必须要“相邻” 而块大小最大为64K，如果重复的2段数据不能出现在一个窗口内是不能被标记的。但是窗口最多是块大小的一半32Kb（实际也不会用这么大的窗口），而我们之前就计算过我们重复的单个field描述就有50Kb，要出现有2个重复的内容，即使2个描述相邻那也至少上100Kb（他们甚至都无法在同一个块里），实际上窗口最大32Kb，所以LZ77根本不能标记出这些重复的field。&lt;/p&gt;
&lt;p&gt;以下引至&lt;a class=&quot;external-link&quot; href=&quot;https://tools.ietf.org/html/rfc1951#section-2&quot; rel=&quot;nofollow&quot;&gt;https://tools.ietf.org/html/rfc1951#section-2&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;table-wrap&quot;&gt;
&lt;table class=&quot;confluenceTable&quot;&gt;&lt;colgroup&gt;&lt;col/&gt;&lt;/colgroup&gt;&lt;tbody readability=&quot;9.5&quot;&gt;&lt;tr readability=&quot;36&quot;&gt;&lt;td class=&quot;confluenceTd&quot; readability=&quot;37&quot;&gt;
&lt;p&gt;Compressed representation overview&lt;/p&gt;
&lt;p&gt;A compressed data set consists of a series of blocks, corresponding&lt;br/&gt;to successive blocks of input data. The block sizes are arbitrary,&lt;br/&gt;except that non-compressible blocks are limited to 65,535 bytes.&lt;/p&gt;
&lt;p&gt;Each block is compressed using a combination of the LZ77 algorithm&lt;br/&gt;and Huffman coding. The Huffman trees for each block are independent&lt;br/&gt;of those for previous or subsequent blocks; the LZ77 algorithm may&lt;br/&gt;use a reference to a duplicated string occurring in a previous block,&lt;br/&gt;up to 32K input bytes before.&lt;/p&gt;
&lt;p&gt;Each block consists of two parts: a pair of Huffman code trees that&lt;br/&gt;describe the representation of the compressed data part, and a&lt;br/&gt;compressed data part. (The Huffman trees themselves are compressed&lt;br/&gt;using Huffman encoding.) The compressed data consists of a series of&lt;br/&gt;elements of two types: literal bytes (of strings that have not been&lt;br/&gt;detected as duplicated within the previous 32K input bytes), and&lt;br/&gt;pointers to duplicated strings, where a pointer is represented as a&lt;br/&gt;pair &amp;lt;length, backward distance&amp;gt;. The representation used in the&lt;br/&gt;&quot;deflate&quot; format limits distances to 32K bytes and lengths to 258&lt;br/&gt;bytes, but does not limit the size of a block, except for&lt;br/&gt;uncompressible blocks, which are limited as noted above.&lt;/p&gt;
&lt;p&gt;Each type of value (literals, distances, and lengths) in the&lt;br/&gt;compressed data is represented using a Huffman code, using one code&lt;br/&gt;tree for literals and lengths and a separate code tree for distances.&lt;br/&gt;The code trees for each block appear in a compact form just before&lt;br/&gt;the compressed data for that block.&lt;/p&gt;
&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/div&gt;


&lt;h2&gt;总结&lt;/h2&gt;
&lt;p&gt;最终也还是自己错了，也没有什么好总结的&lt;/p&gt;
&lt;p&gt;要是什么都不知道也不出问题，要是知道的很清楚也不会出问题，就是在“以为自己知道”的情况下就各种问题。&lt;/p&gt;
&lt;/div&gt;
</description>
<pubDate>Sun, 03 Jan 2021 18:05:00 +0000</pubDate>
<dc:creator>lulianqi15</dc:creator>
<og:description>问题的开始 我司某产品线有这么一个神奇接口 (https://host/path/customQuery) 该接口在预发或线上缓存正常的情况下TTFB为150ms左右（可以认为服务处理时间差不多就是T</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/lulianqi/p/14227682.html</dc:identifier>
</item>
<item>
<title>JVM 常用命令行工具 - 低吟不作语</title>
<link>http://www.cnblogs.com/Yee-Q/p/14227666.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/Yee-Q/p/14227666.html</guid>
<description>&lt;br/&gt;&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;本文部分摘自《深入理解 Java 虚拟机第三版》&lt;/p&gt;
&lt;/blockquote&gt;&lt;br/&gt;&lt;h2 id=&quot;基础故障处理工具&quot;&gt;基础故障处理工具&lt;/h2&gt;
&lt;p&gt;Java 开发人员肯定都知道 JDK 的 bin 目录下有许多小工具，这些小工具除了用于编译和运行 Java 程序外，打包、部署、签名、调试、监控、运维等各种场景都可能会见到它们的影子&lt;/p&gt;
&lt;p&gt;本文主要介绍的是用于监视虚拟机运行状态和进行故障处理的工具，根据软件可用性和授权的不同，可以分成三类：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;商业授权工具：主要是 JMC（Java Mission Control）及它要使用到的 JFR（Java Flight Recorder）。JMC 在个人开发环境中使用是免费的，但在商业环境中使用则需付费&lt;/li&gt;
&lt;li&gt;正式支持工具：这一类工具属于长期被支持的工具&lt;/li&gt;
&lt;li&gt;实验性工具：这一类工具带有实验性质，日后可能会转正，也可能会在某个 JDK 版本中无声无息地消失&lt;/li&gt;
&lt;/ul&gt;&lt;br/&gt;&lt;h2 id=&quot;虚拟机进程状况工具&quot;&gt;虚拟机进程状况工具&lt;/h2&gt;
&lt;p&gt;使用 jps（JVM Process Status Tool）可以列出正在运行的虚拟机进程，并显示虚拟机执行主类（main 函数所在的类）名称以及这些进程的本地虚拟机唯一 ID（LVMID，Local Virtual Machine Identifier）&lt;/p&gt;
&lt;p&gt;该命令可以获取虚拟机进程的 LVMID，从而定位想要监控的程序，而 LVMID 一般与操作系统的进程 ID 一致&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;jps [options] [hostid]
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;jps 也可以通过 RMI 协议查询开启了 RMI 服务的远程 Java 虚拟机进程状态，参数 hostid 为 RMI 注册表中注册的主机名&lt;/p&gt;
&lt;p&gt;jps 的其他常用选项如表：&lt;/p&gt;
&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;选项&lt;/th&gt;
&lt;th&gt;作用&lt;/th&gt;
&lt;/tr&gt;&lt;/thead&gt;&lt;tbody readability=&quot;4&quot;&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;-q&lt;/td&gt;
&lt;td&gt;只输出 LVMID，省略主类的名称&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;-m&lt;/td&gt;
&lt;td&gt;输出虚拟机进程启动时传递给主类 main() 函数的参数&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;-l&lt;/td&gt;
&lt;td&gt;输出主类的全名，如果进程执行的是 JAR 包，则输出&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;-v&lt;/td&gt;
&lt;td&gt;输出虚拟机进程启动时的 JVM 参数&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;br/&gt;&lt;h2 id=&quot;虚拟机统计信息监视工具&quot;&gt;虚拟机统计信息监视工具&lt;/h2&gt;
&lt;p&gt;jstat（JVM Statistics Monitoring Tool）是用于监视虚拟机各种运行状态信息的命令行工具，可以显示本地或者远程虚拟机进程中的类加载、内存、垃圾收集、即时编译等运行时数据&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;jstat [ option vmid [interval[s|ms] [count]] ]
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;如果是本地虚拟机进程，VMID 与 LVMID 是一致的；如果是远程虚拟机进程，那 VMID 的格式应当是&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;[protocaol:][//]lvmid[@hostname[:port]/servername]
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;参数 interval 和 count 代表查询间隔和次数，如果省略这两个参数，说明只查询一次。假设需要每 250 毫秒查询一次进程 2764 的垃圾收集情况，一共查询 20 次，那命令应当是&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;jstat -gc 2764 250 20
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;选项 option 代表用户希望查询的虚拟机信息，主要分三类：类加载、垃圾收集、运行期编译状况等&lt;/p&gt;
&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;选项&lt;/th&gt;
&lt;th&gt;作用&lt;/th&gt;
&lt;/tr&gt;&lt;/thead&gt;&lt;tbody readability=&quot;13&quot;&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;-class&lt;/td&gt;
&lt;td&gt;监视类加载、卸载数量、总空间以及类装载所耗费的时间&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;3&quot;&gt;&lt;td&gt;-gc&lt;/td&gt;
&lt;td&gt;监视 Java 堆状况，包括 Eden 区、两个 Survivor 区、老年代、永久代等的容量、已用空间、垃圾收集时间合计等信息&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;3&quot;&gt;&lt;td&gt;-gccapacity&lt;/td&gt;
&lt;td&gt;监视内容与 -gc 基本相同，但输出主要关注 Java 堆各个区域使用到的最大、最小空间&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;-gcutil&lt;/td&gt;
&lt;td&gt;监视内容与 -gc 基本相同，但输出主要关注已使用空间占总空间的百分比&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;-gccause&lt;/td&gt;
&lt;td&gt;与 -gcutil 功能一样，但会额外输出导致上一次垃圾收集产生的原因&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;-gcnew&lt;/td&gt;
&lt;td&gt;监视新生代垃圾收集情况&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;-gcnewcapacity&lt;/td&gt;
&lt;td&gt;监视内容与 -gcnew 基本相同，但输出主要关注使用到的最大、最小空间&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;-gcold&lt;/td&gt;
&lt;td&gt;监视老年代垃圾收集情况&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;-gcoldcapacity&lt;/td&gt;
&lt;td&gt;监视内容与 -gcold 基本相同，但输出主要关注使用到的最大、最小空间&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;-gcpermcapacity&lt;/td&gt;
&lt;td&gt;输出永久代使用到的最大、最小空间&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;-compiler&lt;/td&gt;
&lt;td&gt;输出即时编译器编译过的方法、耗时等信息&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;-printcompilation&lt;/td&gt;
&lt;td&gt;输出已经被即时编译的方法&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;br/&gt;&lt;h2 id=&quot;java-配置信息工具&quot;&gt;Java 配置信息工具&lt;/h2&gt;
&lt;p&gt;jinfo（Configuration Info for Java）的作用是实时查看和调整虚拟机各项参数，使用 jps 命令的 -v 参数可以查看虚拟机启动时显示指定的参数列表，获取 pid&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;jinfo [option] pid
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;使用 -flag &amp;lt;name&amp;gt; 选项打印虚拟机标记参数的值，name 表示虚拟机标记参数的名称&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;jinfo -flag PrintGC 21768
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;使用 -flag [+|-]&amp;lt;name&amp;gt; 选项可以开启或关闭虚拟机表示参数，+ 表示开启，- 表示关闭&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;jinfo -flag +PrintGC 21768
jinfo -flag -PrintGC 21768
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;使用 -flag &amp;lt;name&amp;gt; = &amp;lt;value&amp;gt; 可以设置虚拟机标记参数的值，但并不是每个参数都可以被动态修改&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;jinfo -flag HeapDumpPath=C:\error.hprof 21768
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;剩下的常用选项如表&lt;/p&gt;
&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;选项&lt;/th&gt;
&lt;th&gt;作用&lt;/th&gt;
&lt;/tr&gt;&lt;/thead&gt;&lt;tbody readability=&quot;2&quot;&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;-flags&lt;/td&gt;
&lt;td&gt;打印虚拟机参数，如 -XX:NewSize&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;no option&lt;/td&gt;
&lt;td&gt;不带任何选项时，会同时打印虚拟机参数和系统参数&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;-sysprops&lt;/td&gt;
&lt;td&gt;打印系统参数&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;-h | -help&lt;/td&gt;
&lt;td&gt;打印帮助信息&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;br/&gt;&lt;h2 id=&quot;java-内存映射工具&quot;&gt;Java 内存映射工具&lt;/h2&gt;
&lt;p&gt;jmap（Memory Map for Java）命令用于生成堆转储快照，还可以查询 finalize 执行队列、Java 堆和方法区的详细信息，如空间使用率、当前用的是哪种收集器等&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;jmap [option] vmid
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;option 选项的合法值与具体含义&lt;/p&gt;
&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;选项&lt;/th&gt;
&lt;th&gt;作用&lt;/th&gt;
&lt;/tr&gt;&lt;/thead&gt;&lt;tbody readability=&quot;7.5&quot;&gt;&lt;tr readability=&quot;5&quot;&gt;&lt;td&gt;-dump&lt;/td&gt;
&lt;td&gt;生成 Java 堆转储快照，格式为 -dump:[live,]format=b,file=&amp;lt;filename&amp;gt;，其中 live 子参数说明是否只 dump 出存活的对象&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;-finalizerinfo&lt;/td&gt;
&lt;td&gt;显示在 F-Queue 中等待 Finalizer 线程执行 finalize 方法的对象&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;-heap&lt;/td&gt;
&lt;td&gt;显示 Java 堆详细信息，如使用哪种回收期、参数配置、分代状况&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;-histo&lt;/td&gt;
&lt;td&gt;显示堆中对象统计信息，包括类、实例数量、合计容量&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;-permstat&lt;/td&gt;
&lt;td&gt;以 ClassLoader 为统计口径显示永久代内存状态&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;-F&lt;/td&gt;
&lt;td&gt;当虚拟机进程对 -dump 选项没有响应时，可使用该选项强制生成 dump 快照&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;br/&gt;&lt;h2 id=&quot;虚拟机堆转储快照分析工具&quot;&gt;虚拟机堆转储快照分析工具&lt;/h2&gt;
&lt;p&gt;JDK 提供 jhat（JVM Heap Analysis Tool）命令和 jmap 搭配使用，用来分析 jmap 生成的堆转储快照。不过 jhat 的分析功能相等简陋，一般会使用其他功能更强大的分析工具&lt;/p&gt;
&lt;p&gt;jhat 内置一个简单的 web 服务器，此命令执行后，jhat 在命令行里显示分析结果的访问地址，可以用 -port 选项指定端口&lt;/p&gt;
&lt;p&gt;有时 dump 出来的堆很大，在启动时会报堆空间不足的错误，可以使用如下参数&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;jhat -J-Xmx512m &amp;lt;heap dump file&amp;gt;       # 这个内存大小可根据自己电脑进行设置
&lt;/code&gt;
&lt;/pre&gt;
&lt;br/&gt;&lt;h2 id=&quot;java-堆栈跟踪工具&quot;&gt;Java 堆栈跟踪工具&lt;/h2&gt;
&lt;p&gt;jstack（Stack Trace for Java）命令用于生成虚拟机当前时刻的线程快照（一般称为 threaddump 或 javacore 文件）。线程快照就是当前虚拟机内每一条线程正在执行的方法堆栈的集合，生成线程快照的目的通常是定位线程出现长时间停顿的原因，如线程间死锁、死循环、请求外部资源导致的长时间挂起等&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;jstack [option] vmid
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;option 选项的合法值与具体含义如表&lt;/p&gt;
&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;选项&lt;/th&gt;
&lt;th&gt;作用&lt;/th&gt;
&lt;/tr&gt;&lt;/thead&gt;&lt;tbody readability=&quot;3&quot;&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;-F&lt;/td&gt;
&lt;td&gt;当正常输出的请求不被响应时，强制输出线程堆栈&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;-l&lt;/td&gt;
&lt;td&gt;除堆栈外，显示关于锁的附加信息&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;-m&lt;/td&gt;
&lt;td&gt;如果调用到本地方法的话，可以显示 C/C++ 的堆栈&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;从 JDK5 开始，java.lang.Thread 类新增了一个 getAllStackTraces() 方法用于获取虚拟机中所有线程的 StackTraceElement 对象，使用这个方法可以完成 jstack 的大部分功能，在实际项目中可以调用这个方法做一个管理员页面，随时使用浏览器来查阅线程堆栈&lt;/p&gt;
&lt;br/&gt;</description>
<pubDate>Sun, 03 Jan 2021 17:06:00 +0000</pubDate>
<dc:creator>低吟不作语</dc:creator>
<og:description>本文部分摘自《深入理解 Java 虚拟机第三版》 基础故障处理工具 Java 开发人员肯定都知道 JDK 的 bin 目录下有许多小工具，这些小工具除了用于编译和运行 Java 程序外，打包、部署、签</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/Yee-Q/p/14227666.html</dc:identifier>
</item>
<item>
<title>Java8的Optional：如何干掉空指针？ - 天乔巴夏丶</title>
<link>http://www.cnblogs.com/summerday152/p/14227639.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/summerday152/p/14227639.html</guid>
<description>&lt;h2 id=&quot;optional概述&quot;&gt;Optional概述&lt;/h2&gt;
&lt;p&gt;Optional 是个容器：它可以保存类型T的value，或者仅仅保存null。Optional提供很多有用的方法，这样我们就不用显式进行空值检测，很好地解决了空指针异常处理的问题，比如可以使用&lt;code&gt;isPresent()&lt;/code&gt;方法判断value是否为null，使用&lt;code&gt;get()&lt;/code&gt;方法获取value值等等。&lt;/p&gt;
&lt;p&gt;Optional的构造方法是私有的，实例不能new，可以使用静态方法来创建：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;// 1、创建一个包装对象值为空的Optional对象
Optional&amp;lt;String&amp;gt; optStr = Optional.empty();
// 2、创建包装对象值非空的Optional对象
Optional&amp;lt;String&amp;gt; optStr1 = Optional.of(&quot;optional&quot;);
// 3、创建包装对象值允许为空的Optional对象
Optional&amp;lt;String&amp;gt; optStr2 = Optional.ofNullable(null);
&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;optional简单案例&quot;&gt;Optional简单案例&lt;/h2&gt;
&lt;p&gt;看完Optional的概述，我们用一个简单的例子说明一下：&lt;/p&gt;
&lt;p&gt;下面这段代码接收一个User对象，如果user为null，则抛出异常【这是一个非常常规的避免空指针异常的做法，如果没有这步，getName会NPE】，否则返回user的name。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;    public String getName1(User user) {
        if (user == null) {
            throw new RuntimeException(&quot;user不能为null!&quot;);
        }
        return user.getName();
    }
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;如果使用Optional，应该怎么去处理呢？&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;    public String getName2(User user) {
        return Optional.ofNullable(user) // 包装user对象，如果user为null，则返回空的Optional对象
                .map(User::getName)
                .orElseThrow(() -&amp;gt; new RuntimeException(&quot;user不能为null&quot;));// 如果有值则返回，没有则抛出异常。
    }
&lt;/code&gt;
&lt;/pre&gt;
&lt;ul&gt;&lt;li&gt;Optional使用静态的&lt;code&gt;ofNullable&lt;/code&gt;方法将user对象进行包装，将可能为null的user对象保护起来。&lt;/li&gt;
&lt;/ul&gt;&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;    public static &amp;lt;T&amp;gt; Optional&amp;lt;T&amp;gt; ofNullable(T value) {
        // empty() 方法 创建一个空的Optional对象， of对象在构造Optional的时候，value如果weinull，会引发NPE
        return value == null ? empty() : of(value);
    }
&lt;/code&gt;
&lt;/pre&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;    public &amp;lt;X extends Throwable&amp;gt; T orElseThrow(Supplier&amp;lt;? extends X&amp;gt; exceptionSupplier) throws X {
        // 如果有值，直接返回值
        if (value != null) {
            return value;
        } else {
            // 抛出异常，这个异常Supplier接口定义
            throw exceptionSupplier.get();
        }
    }
&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;optional的主要方法&quot;&gt;Optional的主要方法&lt;/h2&gt;
&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;方法&lt;/th&gt;
&lt;th&gt;描述&lt;/th&gt;
&lt;/tr&gt;&lt;/thead&gt;&lt;tbody readability=&quot;14.5&quot;&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;&lt;code&gt;empty&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;返回一个空的 Optional 实例&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;3&quot;&gt;&lt;td&gt;&lt;code&gt;filter&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;如果值存在并且满足提供的断言， 就返回包含该值的 Optional 对象；否则返回一个空的 Optional 对象&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;&lt;code&gt;map&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;如果值存在，就对该值执行提供的 mapping 函数调用&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;3&quot;&gt;&lt;td&gt;&lt;code&gt;flatMap&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;如果值存在，就对该值执行提供的 mapping 函数调用，返回一个 Optional 类型的值，否则就返 回一个空的 Optional 对象&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;3&quot;&gt;&lt;td&gt;&lt;code&gt;get&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;如果该值存在，将该值用 Optional 封装返回，否则抛出一个 NoSuchElementException 异常&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;&lt;code&gt;ifPresent&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;如果值存在，就执行使用该值的方法调用，否则什么也不做&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;&lt;code&gt;isPresent&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;如果值存在就返回 true，否则返回 false&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;3&quot;&gt;&lt;td&gt;&lt;code&gt;of&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;将指定值用 Optional 封装之后返回，如果该值为 null，则抛出一个 NullPointerException 异常&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;3&quot;&gt;&lt;td&gt;&lt;code&gt;ofNullable&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;将指定值用 Optional 封装之后返回，如果该值为 null，则返回一个空的 Optional 对象&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;&lt;code&gt;orElse&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;如果有值则将其返回，否则返回一个默认值&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;&lt;code&gt;orElseGet&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;如果有值则将其返回，否则返回一个由指定的 Supplier 接口生成的值&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;&lt;code&gt;orElseThrow&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;如果有值则将其返回，否则抛出一个由指定的 Supplier 接口生成的异常&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;h2 id=&quot;参考阅读&quot;&gt;参考阅读&lt;/h2&gt;
</description>
<pubDate>Sun, 03 Jan 2021 16:34:00 +0000</pubDate>
<dc:creator>天乔巴夏丶</dc:creator>
<og:description>Optional概述 Optional 是个容器：它可以保存类型T的value，或者仅仅保存null。Optional提供很多有用的方法，这样我们就不用显式进行空值检测，很好地解决了空指针异常处理的问</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/summerday152/p/14227639.html</dc:identifier>
</item>
<item>
<title>k8s之DNS服务器搭建 - Liusy01</title>
<link>http://www.cnblogs.com/liusy01/p/14227422.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/liusy01/p/14227422.html</guid>
<description>&lt;p&gt;&lt;br/&gt;一、导读&lt;/p&gt;
&lt;p&gt;在使用k8s部署springboot+redis简单应用这篇文章中，spring boot连接redis是直接使用的IP连接，那么可不可以直接使用服务名称进行连接呢？答案是可以的，这就是k8s集群范围内的DNS服务来完成服务名到ClusterIP的解析，接下来就一起看一下如何搭建DNS服务器。&lt;/p&gt;
&lt;p&gt;二、搭建DNS服务器&lt;/p&gt;
&lt;p&gt;（1）简介&lt;/p&gt;
&lt;p&gt;k8s提供的DNS服务是skydns，由四个组件组成&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;etcd：DNS信息存储&lt;/li&gt;
&lt;li&gt;kube2sky：监控k8s中Service资源的变化，根据Service的名称的IP地址信息生成DNS记录，并将其保存到etcd中&lt;/li&gt;
&lt;li&gt;skyDNS：从etcd中读取DNS信息，并提供DNS查询服务&lt;/li&gt;
&lt;li&gt;healthz：提供对skydns服务的健康检查功能&lt;/li&gt;
&lt;/ul&gt;&lt;div class=&quot;pgc-img&quot;&gt;&lt;img src=&quot;https://p6-tt-ipv6.byteimg.com/img/pgc-image/6fbea8add5ff4e1093da46490f9cde3f~tplv-tt-shrink:640:0.image&quot;/&gt;&lt;p class=&quot;pgc-img-caption&quot;&gt; &lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;（2）skydns配置文件说明&lt;/p&gt;
&lt;p&gt;skydns服务有一个RC和一个Service组成，分别由配置文件skydns-rc.yaml和skydns-svc.yaml定义。&lt;/p&gt;
&lt;p&gt;skydns-rc.yaml包含了四个容器的定义：&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;37&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
apiVersion: v1
kind: ReplicationController
metadata:
  name: kube-dns-v8
  namespace: kube-system
  labels:
    k8s-app: kube-dns
    version: v8
    kubernetes.io/cluster-service: &quot;true&quot;
spec:
  replicas: 1
  selector:
    k8s-app: kube-dns
    version: v8
  template:
    metadata:
      labels:
        k8s-app: kube-dns
        version: v8
        kubernetes.io/cluster-service: &quot;true&quot;
    spec:
      containers:
      - name: etcd
        image: empiregeneral/etcd-amd64:latest
        resources:
          limits:
            cpu: 100m
            memory: 50Mi
        command:
        - /usr/local/bin/etcd
        - -data-dir
        - /var/etcd/data
        - -listen-client-urls
        - http://127.0.0.1:2379,http://127.0.0.1:4001
        - -advertise-client-urls
        - http://127.0.0.1:2379,http://127.0.0.1:4001
        - -initial-cluster-token
        - skydns-etcd
        volumeMounts:
        - name: etcd-storage
          mountPath: /var/etcd/data
      - name: kube2sky
        image: syncgooglecontainers/kube2sky-amd64:1.15
        resources:
          limits:
            cpu: 100m
            memory: 50Mi
        args:
        - --domain=cluster.local
        - --kube_master_url=http://192.168.197.100:8080
      - name: skydns
        image: yaronr/skydns:latest
        resources:
          limits:
            cpu: 100m
            memory: 50Mi
        args:
        - -machines=http://localhost:4001
        - -addr=0.0.0.0:53
        - -domain=cluster.local
        ports:
        - containerPort: 53
          name: dns
          protocol: UDP
        - containerPort: 53
          name: dns-tcp
          protocol: TCP
        livenessProbe:
          httpGet:
            path: /healthz
            port: 8080
            scheme: HTTP
          initialDelaySeconds: 30
          timeoutSeconds: 5
      - name: healthz
        image: syncgooglecontainers/exechealthz:1.1
        resources:
          limits:
            cpu: 10m
            memory: 20Mi
        args:
        - -cmd=nslookup kubernetes.default.svc.cluster.local localhost &amp;gt;/dev/null
        - -port=8080
        ports:
        - containerPort: 8080
          protocol: TCP
      volumes:
      - name: etcd-storage
        emptyDir: {}
      dnsPolicy: Default  # Don't use cluster DNS.
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;上述需要注意的是，需要将&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;32&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
--kube_master_url=http://192.168.197.100:8080
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;改成集群中master的IP，镜像如果下载失败，可从docker hub里面找，我就是从docker hub里面找到相应的镜像。&lt;/p&gt;
&lt;p&gt;skydns-svc.yaml&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;35&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
apiVersion: v1
kind: Service
metadata:
  name: kube-dns
  namespace: kube-system
  labels:
    k8s-app: kube-dns
    kubernetes.io/cluster-service: &quot;true&quot;
    kubernetes.io/name: &quot;KubeDNS&quot;
spec:
  selector:
    k8s-app: kube-dns
  clusterIP: 10.96.0.10
  ports:
  - name: dns
    port: 53
    protocol: UDP
  - name: dns-tcp
    port: 53
    protocol: TCP
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;需要指定一个clusterIP，不能靠k8s自动分配，每个Node的kubelet都是用这个IP地址，另外，这个IP需要在kube-apiserver启动参数--service-cluster-ip-range指定的IP范围内&lt;/p&gt;
&lt;p&gt;kube-apiserver的配置文件在/etc/kubernetes/manifests目录下：&lt;/p&gt;
&lt;div class=&quot;pgc-img&quot;&gt;&lt;img src=&quot;https://p1-tt-ipv6.byteimg.com/img/pgc-image/a112fa9f99944c0abf4890d0b11303a1~tplv-tt-shrink:640:0.image&quot;/&gt;&lt;p class=&quot;pgc-img-caption&quot;&gt; &lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;（3）修改每台Node上的kubelet参数&lt;/p&gt;
&lt;p&gt;添加以下两个参数：&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;33&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
--cluster_dns=169.169.0.100: 为dns服务的clusterIP地址
--cluster_domain=cluster.local: 为dns服务中设置的域名
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;比如我这边的是这样：&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;33&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
vim /usr/lib/systemd/system/kubelet.service.d/10-kubeadm.conf
#添加如下一行
Environment=&quot;KUBELET_DNS_ARGS=--cluster-dns=10.96.0.10 --cluster-domain=cluster.local&quot;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;然后重启kubelet，使用ps -ef | grep kubelet查看是否生效&lt;/p&gt;
&lt;p&gt;重启kubelet&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;32&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
systemctl stop kubelet
systemctl daemon-reload
systemctl start kubelet
&lt;/pre&gt;&lt;/div&gt;

&lt;div class=&quot;pgc-img&quot;&gt;&lt;img src=&quot;https://p1-tt-ipv6.byteimg.com/img/pgc-image/2a6d154296fa485386ff329b93fb6eb7~tplv-tt-shrink:640:0.image&quot;/&gt;&lt;p class=&quot;pgc-img-caption&quot;&gt; &lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;修改完参数之后，启动dns&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;32&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
kubectl create -f skydns-rc.yaml
kubectl create -f skydns-svc.yaml
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;（4）验证&lt;/p&gt;
&lt;p&gt;启动一个busybox容器。&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;34&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
apiVersion: v1
kind: Pod
metadata:
  name: busybox
  labels:
    name: busybox
  namespace: default
spec:
  containers:
  - image: busybox
    imagePullPolicy: IfNotPresent
    command:
      - sleep
      - &quot;3600&quot;
    name: busybox
  restartPolicy: Always
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;启动之后进入容器内部：&lt;/p&gt;
&lt;pre class=&quot;syl-page-code hljs nginx&quot;&gt;
&lt;code&gt;&lt;span class=&quot;hljs-attribute&quot;&gt;nsloogup 服务名&lt;/span&gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;div class=&quot;pgc-img&quot;&gt;&lt;img src=&quot;https://p1-tt-ipv6.byteimg.com/img/pgc-image/52ee59e2c74d4b52a7e67c42c2691a92~tplv-tt-shrink:640:0.image&quot;/&gt;&lt;p class=&quot;pgc-img-caption&quot;&gt; &lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;可知解析后的ip是10.102.184.126。&lt;/p&gt;
&lt;p&gt;然后查找对应的redis 的Service的ip，可以看到，两个IP是对的上的。&lt;/p&gt;
&lt;div class=&quot;pgc-img&quot;&gt;&lt;img src=&quot;https://p6-tt-ipv6.byteimg.com/img/pgc-image/9bc3129ab3e84c59be3515e3ce3402b2~tplv-tt-shrink:640:0.image&quot;/&gt;&lt;p class=&quot;pgc-img-caption&quot;&gt; &lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;又例如之前的springboot连接redis：&lt;/p&gt;
&lt;p&gt;在构建镜像的时候直接使用ip，这次改为使用服务名：&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;35&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
FROM centos:7


LABEL author=lsy


ENV path=/usr/soft


RUN mkdir ${path}


WORKDIR ${path}


ADD jdk-8u191-linux-x64.tar.gz ${path}


ENV JAVA_HOME=${path}/jdk1.8.0_191
ENV CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar
ENV PATH=$JAVA_HOME/bin:$PATH


COPY k8s_demo-1.0.jar ${path}


EXPOSE 8080


CMD  java -jar -DredisIp=redis k8s_demo-1.0.jar
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;然后进行镜像构建：&lt;/p&gt;
&lt;div class=&quot;pgc-img&quot;&gt;&lt;img src=&quot;https://p1-tt-ipv6.byteimg.com/img/pgc-image/87e7876b043449cd8b1323dc3dbc3ff7~tplv-tt-shrink:640:0.image&quot;/&gt;&lt;p class=&quot;pgc-img-caption&quot;&gt; &lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;然后改为使用当前镜像进行容器的构建，之后创建容器&lt;/p&gt;
&lt;p&gt;测试：&lt;/p&gt;
&lt;p&gt;设置值：&lt;/p&gt;
&lt;div class=&quot;pgc-img&quot;&gt;&lt;img src=&quot;https://p26-tt.byteimg.com/img/pgc-image/93f2997621254d85bcf2af9c3371a90b~tplv-tt-shrink:640:0.image&quot;/&gt;&lt;p class=&quot;pgc-img-caption&quot;&gt; &lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;取值：&lt;/p&gt;
&lt;div class=&quot;pgc-img&quot;&gt;&lt;img src=&quot;https://p1-tt-ipv6.byteimg.com/img/pgc-image/be167c517a794d9194a667e31b7a02ef~tplv-tt-shrink:640:0.image&quot;/&gt;&lt;p class=&quot;pgc-img-caption&quot;&gt; &lt;/p&gt;
&lt;/div&gt;

&lt;p&gt;结尾：&lt;/p&gt;
&lt;p&gt;祝愿大家在新的一年里心想事成！！！&lt;/p&gt;
</description>
<pubDate>Sun, 03 Jan 2021 15:11:00 +0000</pubDate>
<dc:creator>Liusy01</dc:creator>
<og:description>一、导读 在使用k8s部署springboot+redis简单应用这篇文章中，spring boot连接redis是直接使用的IP连接，那么可不可以直接使用服务名称进行连接呢？答案是可以的，这就是k8</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/liusy01/p/14227422.html</dc:identifier>
</item>
<item>
<title>如何根据角色批量激活SAP Fiori服务 - SAP梦心</title>
<link>http://www.cnblogs.com/saper/p/14227421.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/saper/p/14227421.html</guid>
<description>&lt;p&gt;&lt;span&gt; 我们知道Fiori的角色跟ERP的角色是不通用的，即使你的账号有SAP_ALL的权限，但打开Fiori的时候一样是空的一片：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;img src=&quot;https://mmbiz.qpic.cn/mmbiz_png/A7bLdtJnUNU1gvBhXGicY0UfwK1uD0LbnKzptQyicURzf68TmhEw4AMcM6PcrKuyGGXibz4hjy43ITkNHibDHianSyg/640?wx_fmt=png&quot; width=&quot;760&quot; height=&quot;473&quot; class=&quot;rich_pages js_insertlocalimg&quot; data-ratio=&quot;0.62265625&quot; data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;只有给账号加上fiori需要的角色，并激活相关服务才能用fiori app，否则打开Fiori apps会报错，具体错误可以通过GUI事务代码：/n/iwfnd/error_log 查看具体的原因。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;首先打开fiori支持库网站：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;https://fioriappslibrary.hana.ondemand.com/sap/fix/externalViewer/#&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;在左侧选择：SAP Fiori apps for SAP S/4HANA&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;img src=&quot;https://mmbiz.qpic.cn/mmbiz_png/A7bLdtJnUNU1gvBhXGicY0UfwK1uD0LbnPtZKZiakZm7iavDQrYNIcb1eG3BWQ19soH47GBWlVceP3KGuDk5ZZjew/640?wx_fmt=png&quot; width=&quot;751&quot; height=&quot;385&quot; class=&quot;rich_pages js_insertlocalimg&quot; data-ratio=&quot;0.51328125&quot; data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;在这里面就可以根据多种方式查询出相关的Fiori apps，在这里我们选择通过角色by Roles来查询：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;img src=&quot;https://mmbiz.qpic.cn/mmbiz_png/A7bLdtJnUNU1gvBhXGicY0UfwK1uD0LbnNBDwu4SBTaZ24GPjmOwDVQAXUXTNicW03To4ZLyJFcSZDjoB1Bk9q0w/640?wx_fmt=png&quot; width=&quot;695&quot; height=&quot;357&quot; class=&quot;rich_pages js_insertlocalimg&quot; data-ratio=&quot;0.5140625&quot; data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;这样就可以通过名称查询出角色：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;img src=&quot;https://mmbiz.qpic.cn/mmbiz_png/A7bLdtJnUNU1gvBhXGicY0UfwK1uD0Lbncl4DOzUK71S1O90OU9GYt4d0YzGWSB03gJSLVQib9xgkxT7vyRjXsuw/640?wx_fmt=png&quot; width=&quot;676&quot; height=&quot;331&quot; class=&quot;rich_pages js_insertlocalimg&quot; data-ratio=&quot;0.48984375&quot; data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;当然你也可以通过其他方式，但最终的目的都是一样，获取我们需要的角色名称，有了这个角色名称，我们就可以通过它在GUI里面进行激活相关的ICF Services和OData Services：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;以角色：SAP_BR_CASH_MANAGER 为例：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;可以在网站上查询到相关的icf服务以及Odata服务名称：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;img src=&quot;https://mmbiz.qpic.cn/mmbiz_png/A7bLdtJnUNU1gvBhXGicY0UfwK1uD0LbngL85ItD3yLTEdTibJeiaicrwqRJc5C7alWsHTOaTH44BnkicNLErTgOe8Q/640?wx_fmt=png&quot; width=&quot;661&quot; height=&quot;378&quot; class=&quot;rich_pages js_insertlocalimg&quot; data-ratio=&quot;0.57265625&quot; data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;首先在GUI执行STC01，输入：SAP_FIORI_CONTENT_ACTIVATION&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;img src=&quot;https://mmbiz.qpic.cn/mmbiz_png/A7bLdtJnUNU1gvBhXGicY0UfwK1uD0LbneBIGIV1lkqwsMNqfcLfJzHANmrib6ibcsL7w3lFfEfppmAcDibjJ6XIvg/640?wx_fmt=png&quot; width=&quot;614&quot; height=&quot;228&quot; class=&quot;rich_pages js_insertlocalimg&quot; data-ratio=&quot;0.371713508612874&quot; data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-w=&quot;1103&quot;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;执行之后，选中第一个复选框，在点击输入参数按钮：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;img src=&quot;https://mmbiz.qpic.cn/mmbiz_png/A7bLdtJnUNU1gvBhXGicY0UfwK1uD0LbngEovxtYYA6wp08gRib8ZyI4ic4kKKCHicUA3qDYiaVyia0icH7MVM8L8HiaUw/640?wx_fmt=png&quot; width=&quot;650&quot; height=&quot;333&quot; class=&quot;rich_pages js_insertlocalimg&quot; data-ratio=&quot;0.5122838944494995&quot; data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-w=&quot;1099&quot;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;输入我们想要激活的角色，当然这里也可以输入多条角色，建议一次性不要超过100条：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;img src=&quot;https://mmbiz.qpic.cn/mmbiz_png/A7bLdtJnUNU1gvBhXGicY0UfwK1uD0Lbnias3csBoXg75MKB25lAcWhyko7Gd2XgGtf0JYp4qKvo4TseAAzgvd2g/640?wx_fmt=png&quot; width=&quot;709&quot; height=&quot;377&quot; class=&quot;rich_pages js_insertlocalimg&quot; data-ratio=&quot;0.5317604355716878&quot; data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-w=&quot;1102&quot;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;输入之后，点击“Job”按钮执行&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;img src=&quot;https://mmbiz.qpic.cn/mmbiz_png/A7bLdtJnUNU1gvBhXGicY0UfwK1uD0LbnHUtaA3DfVSxqZL38jcPh7B1icGibtrat6EibaKWnCEvCdYFotpu6VvOwg/640?wx_fmt=png&quot; width=&quot;680&quot; height=&quot;354&quot; class=&quot;rich_pages js_insertlocalimg&quot; data-ratio=&quot;0.5204359673024523&quot; data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-w=&quot;1101&quot;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;从执行任务列表里面可以看到系统会同步激活icf和odata服务：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;img src=&quot;https://mmbiz.qpic.cn/mmbiz_png/A7bLdtJnUNU1gvBhXGicY0UfwK1uD0Lbn3rf9Lm8JCBo4ArTuqPic18wiaO9RRMPnjQ8Xl5Gxouqr21j8rLb9eaiaQ/640?wx_fmt=png&quot; width=&quot;720&quot; height=&quot;424&quot; class=&quot;rich_pages js_insertlocalimg&quot; data-ratio=&quot;0.5892531876138434&quot; data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-w=&quot;1098&quot;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;执行完成：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;img src=&quot;https://mmbiz.qpic.cn/mmbiz_png/A7bLdtJnUNU1gvBhXGicY0UfwK1uD0LbnFiaCLdLYZl2GN5Tia7hib6cWyZhnNlV7icKZBoSSjNhUggLKjo6CJX1E3Q/640?wx_fmt=png&quot; width=&quot;712&quot; height=&quot;377&quot; class=&quot;rich_pages js_insertlocalimg&quot; data-ratio=&quot;0.529891304347826&quot; data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-w=&quot;1104&quot;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;在事务代码：/N/IWFND/MAINT_SERVICE 可以看到相关的Odata服务已经激活了：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;img src=&quot;https://mmbiz.qpic.cn/mmbiz_png/A7bLdtJnUNU1gvBhXGicY0UfwK1uD0LbnQlgQj3CrZEqeBjnOnHmVBPM5trXK3FkVHV85EpmG35dLtStL7uy8vw/640?wx_fmt=png&quot; width=&quot;763&quot; height=&quot;656&quot; class=&quot;rich_pages js_insertlocalimg&quot; data-ratio=&quot;0.8598553345388789&quot; data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-w=&quot;1106&quot;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;相关的ICF服务也处于激活状态：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;img src=&quot;https://mmbiz.qpic.cn/mmbiz_png/A7bLdtJnUNU1gvBhXGicY0UfwK1uD0LbnHkYF1Ub2TXExaATloYXzJw57JUqHic5ozWsrsvFc24B87iausTiagRRkA/640?wx_fmt=png&quot; width=&quot;752&quot; height=&quot;630&quot; class=&quot;rich_pages js_insertlocalimg&quot; data-ratio=&quot;0.8378623188405797&quot; data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-w=&quot;1104&quot;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;我们将这个角色赋给用户，就可以打开Fiori看到相关的Fiori apps了：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;img src=&quot;https://mmbiz.qpic.cn/mmbiz_png/A7bLdtJnUNU1gvBhXGicY0UfwK1uD0Lbnibpmd8QvXcSFOSxahxFDlrJTR9XrwRVD4Ciab6aJUQh3fWZToW1ZITSg/640?wx_fmt=png&quot; class=&quot;rich_pages js_insertlocalimg&quot; data-ratio=&quot;0.7535714285714286&quot; data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-w=&quot;840&quot;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;img src=&quot;https://mmbiz.qpic.cn/mmbiz_png/A7bLdtJnUNU1gvBhXGicY0UfwK1uD0LbndMD0TSsBOCqpO2hfdDQLu21OnFFgNfNgfC1pEG52Dicvdx6TNvV2bibw/640?wx_fmt=png&quot; width=&quot;750&quot; height=&quot;465&quot; class=&quot;rich_pages js_insertlocalimg&quot; data-ratio=&quot;0.6203125&quot; data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;img src=&quot;https://mmbiz.qpic.cn/mmbiz_png/A7bLdtJnUNU1gvBhXGicY0UfwK1uD0Lbn82pFXy5Rul6J88IMc1ysBuAeJ706qAnNuooziakBffRpoJgbTymBh2g/640?wx_fmt=png&quot; width=&quot;702&quot; height=&quot;436&quot; class=&quot;rich_pages js_insertlocalimg&quot; data-ratio=&quot;0.62109375&quot; data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;img src=&quot;https://mmbiz.qpic.cn/mmbiz_png/A7bLdtJnUNU1gvBhXGicY0UfwK1uD0Lbn6vT8aBD5m7EbLubdC8ibibkdQeQ96tE4Vrs5g1ibbItySRXqsTvmUIPgg/640?wx_fmt=png&quot; width=&quot;736&quot; height=&quot;579&quot; class=&quot;rich_pages js_insertlocalimg&quot; data-ratio=&quot;0.787109375&quot; data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-w=&quot;1024&quot;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;br/&gt;&lt;span&gt;以上这种方式是让系统帮我们搞定所需的服务，当然我们也可以手动去激活各项服务，结果都是一样的！&lt;/span&gt;&lt;/p&gt;
</description>
<pubDate>Sun, 03 Jan 2021 15:11:00 +0000</pubDate>
<dc:creator>SAP梦心</dc:creator>
<og:description>我们知道Fiori的角色跟ERP的角色是不通用的，即使你的账号有SAP_ALL的权限，但打开Fiori的时候一样是空的一片： 只有给账号加上fiori需要的角色，并激活相关服务才能用fiori app</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/saper/p/14227421.html</dc:identifier>
</item>
</channel>
</rss>