<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="css/feed.xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/" xmlns:og="http://ogp.me/ns#">
<channel>
<atom:link rel="self" href="http://192.168.1.4/fivefilters/makefulltextfeed.php?url=feed.cnblogs.com%2Fblog%2Fsitehome%2Frss&amp;max=10&amp;links=preserve&amp;exc=" />
<atom:link rel="alternate" title="Source URL" href="http://feed.cnblogs.com/blog/sitehome/rss" />
<atom:link rel="related" title="Subscribe to feed" href="http://www.subtome.com/#/subscribe?feeds=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed.cnblogs.com%252Fblog%252Fsitehome%252Frss%26max%3D10%26links%3Dpreserve%26exc%3D&amp;back=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed.cnblogs.com%252Fblog%252Fsitehome%252Frss%26max%3D10%26links%3Dpreserve%26exc%3D" />
<title>博客园_首页</title>
<link></link>
<description>代码改变世界</description>
<item>
<title>用Spark进行实时流计算 - 独孤风</title>
<link>http://www.cnblogs.com/tree1123/p/13431235.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/tree1123/p/13431235.html</guid>
<description>&lt;p&gt;Spark Streaming是Spark最初的流处理框架，使用了微批的形式来进行流处理。&lt;/p&gt;
&lt;p&gt;提供了基于RDDs的Dstream API，每个时间间隔内的数据为一个RDD，源源不断对RDD进行处理来实现流计算&lt;/p&gt;
&lt;p&gt;Apache Spark 在 2016 年的时候启动了 Structured Streaming 项目，一个基于 Spark SQL 的全新流计算引擎 Structured Streaming，让用户像编写批处理程序一样简单地编写高性能的流处理程序。&lt;/p&gt;
&lt;p&gt;Structured Streaming是Spark2.0版本提出的新的实时流框架（2.0和2.1是实验版本，从Spark2.2开始为稳定版本)&lt;/p&gt;
&lt;p&gt;从Spark-2.X版本后，Spark Streaming就进入维护模式，看见Spark已经将大部分精力投入到了全新的Structured Streaming中，而一些新特性也只有Structured Streaming才有，这样Spark才有了与Flink一战的能力。&lt;/p&gt;
&lt;h3 id=&quot;1、spark-streaming-不足&quot;&gt;1、Spark Streaming 不足&lt;/h3&gt;
&lt;ul readability=&quot;9&quot;&gt;&lt;li readability=&quot;4&quot;&gt;
&lt;p&gt;Processing Time 而不是 Event Time&lt;/p&gt;
&lt;p&gt;首先解释一下，Processing Time 是数据到达 Spark 被处理的时间，而 Event Time 是数据自带的属性，一般表示数据产生于数据源的时间。比如 IoT 中，传感器在 12:00:00 产生一条数据，然后在 12:00:05 数据传送到 Spark，那么 Event Time 就是 12:00:00，而 Processing Time 就是 12:00:05。我们知道 Spark Streaming 是基于 DStream 模型的 micro-batch 模式，简单来说就是将一个微小时间段，比如说 1s，的流数据当前批数据来处理。如果我们要统计某个时间段的一些数据统计，毫无疑问应该使用 Event Time，但是因为 Spark Streaming 的数据切割是基于 Processing Time，这样就导致使用 Event Time 特别的困难。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;2&quot;&gt;
&lt;p&gt;Complex, low-level api&lt;/p&gt;
&lt;p&gt;这点比较好理解，DStream （Spark Streaming 的数据模型）提供的 API 类似 RDD 的 API 的，非常的 low level。当我们编写 Spark Streaming 程序的时候，本质上就是要去构造 RDD 的 DAG 执行图，然后通过 Spark Engine 运行。这样导致一个问题是，DAG 可能会因为开发者的水平参差不齐而导致执行效率上的天壤之别。这样导致开发者的体验非常不好，也是任何一个基础框架不想看到的（基础框架的口号一般都是：你们专注于自己的业务逻辑就好，其他的交给我）。这也是很多基础系统强调 Declarative 的一个原因。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;4&quot;&gt;
&lt;p&gt;reason about end-to-end application&lt;/p&gt;
&lt;p&gt;这里的 end-to-end 指的是直接 input 到 out，比如 Kafka 接入 Spark Streaming 然后再导出到 HDFS 中。DStream 只能保证自己的一致性语义是 exactly-once 的，而 input 接入 Spark Streaming 和 Spark Straming 输出到外部存储的语义往往需要用户自己来保证。而这个语义保证写起来也是非常有挑战性，比如为了保证 output 的语义是 exactly-once 语义需要 output 的存储系统具有幂等的特性，或者支持事务性写入，这个对于开发者来说都不是一件容易的事情。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;2&quot;&gt;
&lt;p&gt;批流代码不统一&lt;/p&gt;
&lt;p&gt;尽管批流本是两套系统，但是这两套系统统一起来确实很有必要，我们有时候确实需要将我们的流处理逻辑运行到批数据上面。关于这一点，最早在 2014 年 Google 提出 Dataflow 计算服务的时候就批判了 streaming/batch 这种叫法，而是提出了 unbounded/bounded data 的说法。DStream 尽管是对 RDD 的封装，但是我们要将 DStream 代码完全转换成 RDD 还是有一点工作量的，更何况现在 Spark 的批处理都用 DataSet/DataFrame API 了。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;h3 id=&quot;2、structured-streaming-优势&quot;&gt;2.、Structured Streaming 优势&lt;/h3&gt;
&lt;p&gt;相对的，来看下Structured Streaming优势：&lt;/p&gt;
&lt;ul readability=&quot;16.5&quot;&gt;&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;简洁的模型。Structured Streaming 的模型很简洁，易于理解。用户可以直接把一个流想象成是无限增长的表格。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;1&quot;&gt;
&lt;p&gt;一致的 API。由于和 Spark SQL 共用大部分 API，对 Spaprk SQL 熟悉的用户很容易上手，代码也十分简洁。同时批处理和流处理程序还可以共用代码，不需要开发两套不同的代码，显著提高了开发效率。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;1&quot;&gt;
&lt;p&gt;卓越的性能。Structured Streaming 在与 Spark SQL 共用 API 的同时，也直接使用了 Spark SQL 的 Catalyst 优化器和 Tungsten，数据处理性能十分出色。此外，Structured Streaming 还可以直接从未来 Spark SQL 的各种性能优化中受益。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;多语言支持。Structured Streaming 直接支持目前 Spark SQL 支持的语言，包括 Scala，Java，Python，R 和 SQL。用户可以选择自己喜欢的语言进行开发。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;同样能支持多种数据源的输入和输出，Kafka、flume、Socket、Json。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;基于Event-Time，相比于Spark Streaming的Processing-Time更精确，更符合业务场景。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;&lt;strong&gt;Event time&lt;/strong&gt; 事件时间: 就是数据真正发生的时间，比如用户浏览了一个页面可能会产生一条用户的该时间点的浏览日志。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;&lt;strong&gt;Process time&lt;/strong&gt; 处理时间&lt;strong&gt;:&lt;/strong&gt; 则是这条日志数据真正到达计算框架中被处理的时间点，简单的说，就是你的Spark程序是什么时候读到这条日志的。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;2&quot;&gt;
&lt;p&gt;事件时间是嵌入在数据本身中的时间。对于许多应用程序，用户可能希望在此事件时间操作。例如，如果要获取IoT设备每分钟生成的事件数，则可能需要使用生成数据的时间（即数据中的事件时间），而不是Spark接收他们的时间。事件时间在此模型中非常自然地表示 - 来自设备的每个事件都是表中的一行，事件时间是该行中的一个列值。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;支持spark2的dataframe处理。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;解决了Spark Streaming存在的代码升级，DAG图变化引起的任务失败，无法断点续传的问题。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;基于SparkSQL构建的可扩展和容错的流式数据处理引擎，使得实时流式数据计算可以和离线计算采用相同的处理方式（DataFrame&amp;amp;SQL）。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;可以使用与静态数据批处理计算相同的方式来表达流计算。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;h2 id=&quot;底层原理完全不同&quot;&gt;底层原理完全不同&lt;/h2&gt;
&lt;p&gt;Spark Streaming采用&lt;strong&gt;微批&lt;/strong&gt;的处理方法。每一个批处理间隔的为一个批，也就是一个RDD，我们对RDD进行操作就可以源源不断的接收、处理数据。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1089984/202008/1089984-20200804084724589-1872622118.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;Structured Streaming将实时数据当做&lt;strong&gt;被连续追加的表&lt;/strong&gt;。流上的每一条数据都类似于将一行新数据添加到表中。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1089984/202008/1089984-20200804084731745-1954221369.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;Spark 3.0.0发布以后 全新的Structured Streaming UI诞生，可见未来的Structured Streaming将不断迎来进步。&lt;/p&gt;
&lt;p&gt;更多Flink，Kafka，Spark等相关技术博文，科技资讯，欢迎关注实时流式计算 公众号后台回复 “电子书” 下载300页Flink实战电子书&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1089984/202005/1089984-20200511083216576-1437389309.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
</description>
<pubDate>Tue, 04 Aug 2020 00:51:00 +0000</pubDate>
<dc:creator>独孤风</dc:creator>
<og:description>Spark Streaming VS Structured Streaming Spark Streaming是Spark最初的流处理框架，使用了微批的形式来进行流处理。 提供了基于RDDs的Dstr</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/tree1123/p/13431235.html</dc:identifier>
</item>
<item>
<title>MySql大表分页(附独门秘技) - trytocatch</title>
<link>http://www.cnblogs.com/trytocatch/p/mysql-page-query.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/trytocatch/p/mysql-page-query.html</guid>
<description>&lt;p&gt;本文通过三种方案，循序渐进地讲解了MySql中，InnoDB下的大表分页查询，借助原创技巧，实现高效查询&lt;/p&gt;&lt;div id=&quot;cnblogs_post_body&quot; readability=&quot;246.97015198682&quot;&gt;

&lt;h2&gt;问题背景&lt;/h2&gt;
&lt;p&gt;MySql(InnoDB)中的订单表需要按时间顺序分页查询，且主键不是时间维度递增，订单表在百万以上规模，此时如何高效地实现该需求？&lt;/p&gt;
&lt;p&gt;注：本文并非主要讲解如何建立索引，以下的分析均建立在有合适的索引的前提下&lt;/p&gt;
&lt;h2&gt;初步方案1&lt;/h2&gt;
&lt;p&gt;众所周知，MySql中，有一个limit offset, pageSize的用法，可以实现分页查询&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;35&quot;&gt;
&lt;pre&gt;
&lt;span&gt;select&lt;/span&gt; &lt;span&gt;*&lt;/span&gt; &lt;span&gt;from&lt;/span&gt; &lt;span&gt;order&lt;/span&gt; &lt;span&gt;where&lt;/span&gt; &lt;span&gt;user_id&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; xxx &lt;span&gt;and&lt;/span&gt; 【其它业务条件】 &lt;span&gt;order&lt;/span&gt; &lt;span&gt;by&lt;/span&gt; created_time, id limit offset, pageSize
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;因为created_time可能重复，所以order by时应加上id，保证顺序的确定性&lt;/p&gt;
&lt;h3&gt;点评&lt;/h3&gt;
&lt;p&gt;该方案在表规模较小的时候，不会暴露出问题，当order表增长到十万级，并且查询后面几页的时候，执行速度明显变慢，可能降到100ms的量级，如果数据量增长到百万级，则耗时达到秒级，如果增长到千万级，那耗时就变得完全不可接受了（曾排查过这样的线上慢SQL）&lt;/p&gt;

&lt;hr/&gt;&lt;h2&gt; 深入分析&lt;/h2&gt;
&lt;p&gt;方案1为啥在大表中表现这么差呢？我们可以来揣测一下MySql是怎么执行这个查询的&lt;/p&gt;
&lt;p&gt;假设我们在user_id，created_time，以及【其它业务条件】建立了联合索引，当我要查找第100000条到100049条的记录时，因为MySql的索引是b+ tree结构，不像数组可以随机定位到第N条记录，它需要花不小的成本去找到N的位置，N越大，成本越大&lt;/p&gt;
&lt;p&gt;抛开b+ tree的细节不讲，我们还可以借助统计表记录总数的SQL来理解&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;32&quot;&gt;
&lt;pre&gt;
&lt;span&gt;select&lt;/span&gt; &lt;span&gt;count&lt;/span&gt;(&lt;span&gt;1&lt;/span&gt;) &lt;span&gt;from&lt;/span&gt; &lt;span&gt;order&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;如果能非常高效地定位第N条记录，那么上述统计也能非常高效的执行，但实际上，在大表中统计记录总条数，也是非常慢的(本文是在InnoDB的场景下)&lt;/p&gt;
&lt;p&gt;方案1低效的根本原因在于：定位到offset的成本过高，未能充分利用索引的有序性&lt;/p&gt;

&lt;hr/&gt;&lt;h2&gt;方案2&lt;/h2&gt;
&lt;p&gt;索引(b+ tree)的特点在于，数据是有序的，虽然找到第N条记录的效率比较低，但找到某一条数据在索引中的位置，其效率是很高的（索引本来就是解决这个问题的）&lt;/p&gt;
&lt;p&gt;我们换一种思路，每次取50条记录，第一次取的时候，指定从上次结束的位置继续往后取50条，这样，我们便可以利用上索引的有序性了&lt;/p&gt;
&lt;p&gt;我们先看一个以id为序，进行分页查询的例子&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;32&quot;&gt;
&lt;pre&gt;
&lt;span&gt;select&lt;/span&gt; &lt;span&gt;*&lt;/span&gt; &lt;span&gt;from&lt;/span&gt; &lt;span&gt;order&lt;/span&gt; &lt;span&gt;where&lt;/span&gt; id &lt;span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;'&lt;/span&gt;&lt;span&gt;pre max id&lt;/span&gt;&lt;span&gt;'&lt;/span&gt; &lt;span&gt;order&lt;/span&gt; &lt;span&gt;by&lt;/span&gt; id limit &lt;span&gt;50&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;第一次查询不用带条件，后续查询则传入前一次查询的最大id，简单分析可知，MySql在执行时，先定位到pre max id的位置(id是有序的，定位非常快)，然后从这往后取50条记录即可，整个过程非常高效&lt;/p&gt;

&lt;p&gt;我们回到最开始的问题，“按时间顺序分页查询，且主键不是时间维度递增”，此时我们不能用id作为分页的条件，因为按它去分页，便不是按时间顺序了，但也不能直接把id换成时间，因为时间可能会重复，我们来分析一下&lt;/p&gt;
&lt;table border=&quot;0&quot; align=&quot;left&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;id&lt;/td&gt;
&lt;td&gt;username&lt;/td&gt;
&lt;td&gt;created_time&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;xxx&lt;/td&gt;
&lt;td&gt;zhangsan&lt;/td&gt;
&lt;td&gt;2019-01-01&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;ddd&lt;/td&gt;
&lt;td&gt;zhangsan&lt;/td&gt;
&lt;td&gt;2019-02-03&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;yyy&lt;/td&gt;
&lt;td&gt;zhangsan&lt;/td&gt;
&lt;td&gt;2019-02-03&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;abc&lt;/td&gt;
&lt;td&gt;zhangsan&lt;/td&gt;
&lt;td&gt;2019-02-05&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;aaa&lt;/td&gt;
&lt;td&gt;zhangsan&lt;/td&gt;
&lt;td&gt;2020-08-01&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;







&lt;p&gt;假如前一次分页的最后一条记录为id=ddd的这条（created_time为2019-02-03），下一次查询使用created_time&amp;gt;2019-02-03作为条件时，则会把id=yyy的这条记录漏掉，如果换成created_time&amp;gt;=2019-02-03也不行，id=ddd的这条记录就又被查出来了&lt;/p&gt;
&lt;p&gt;对于这个数据遗漏或重复的问题，我看到一种解决方案是这样的：&lt;/p&gt;
&lt;p&gt;分三种情况进行查询&lt;/p&gt;
&lt;ol&gt;&lt;li readability=&quot;-1&quot;&gt;首次查询，created_time&amp;gt;='xxxx-xx-xx'，如果不要求以某时间开始，则无条件
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;34&quot;&gt;
&lt;pre&gt;
&lt;span&gt;select&lt;/span&gt; &lt;span&gt;*&lt;/span&gt; &lt;span&gt;from&lt;/span&gt; &lt;span&gt;order&lt;/span&gt; &lt;span&gt;where&lt;/span&gt; &lt;span&gt;user_id&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; xxx &lt;span&gt;and&lt;/span&gt; 【其它业务条件】 &lt;span&gt;and&lt;/span&gt; created_time &lt;span&gt;&amp;gt;=&lt;/span&gt; &lt;span&gt;'&lt;/span&gt;&lt;span&gt;xxxx-xx-xx&lt;/span&gt;&lt;span&gt;'&lt;/span&gt; &lt;span&gt;order&lt;/span&gt; &lt;span&gt;by&lt;/span&gt; created_time, id limit pageSize
&lt;/pre&gt;&lt;/div&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;如果上次查询的记录条数等于pageSize，则用created_time和id的组合条件来查询，为了防止created_time在边界位置发生重复时漏掉数据
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;34&quot;&gt;
&lt;pre&gt;
&lt;span&gt;select&lt;/span&gt; &lt;span&gt;*&lt;/span&gt; &lt;span&gt;from&lt;/span&gt; &lt;span&gt;order&lt;/span&gt; &lt;span&gt;where&lt;/span&gt; &lt;span&gt;user_id&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; xxx &lt;span&gt;and&lt;/span&gt; 【其它业务条件】 &lt;span&gt;and&lt;/span&gt; created_time &lt;span&gt;=&lt;/span&gt; &lt;span&gt;'&lt;/span&gt;&lt;span&gt;created_time of latest recored&lt;/span&gt;&lt;span&gt;'&lt;/span&gt; &lt;span&gt;and&lt;/span&gt; id &lt;span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;'&lt;/span&gt;&lt;span&gt;id of latest recored&lt;/span&gt;&lt;span&gt;'&lt;/span&gt; &lt;span&gt;order&lt;/span&gt; &lt;span&gt;by&lt;/span&gt; created_time, id limit pageSize
&lt;/pre&gt;&lt;/div&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;如果上次查询的记录数小于pageSize，并且上次查询是第二种查询，则仅用created_time来查询，
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;34&quot;&gt;
&lt;pre&gt;
&lt;span&gt;select&lt;/span&gt; &lt;span&gt;*&lt;/span&gt; &lt;span&gt;from&lt;/span&gt; &lt;span&gt;order&lt;/span&gt; &lt;span&gt;where&lt;/span&gt; &lt;span&gt;user_id&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; xxx &lt;span&gt;and&lt;/span&gt; 【其它业务条件】 &lt;span&gt;and&lt;/span&gt; created_time &amp;gt; &lt;span&gt;'&lt;/span&gt;&lt;span&gt;created_time of latest recored&lt;/span&gt;&lt;span&gt;'&lt;/span&gt; &lt;span&gt;order&lt;/span&gt; &lt;span&gt;by&lt;/span&gt; created_time, id limit pageSize 
&lt;/pre&gt;&lt;/div&gt;
&lt;/li&gt;
&lt;/ol&gt;&lt;h5&gt;注意：&lt;/h5&gt;
&lt;p&gt;created_time不能为null，否=和&amp;gt;会返回null，导致对应结果查不出来，如果存在为null的情况，则需要对部分查询把=和&amp;gt;分别改为is null和is not null来查询&lt;/p&gt;
&lt;h3&gt;点评&lt;/h3&gt;
&lt;p&gt;上述方法确实可以解决漏掉数据或重复的问题，并且也有着不错的性能，但缺点也比较明显，查询过于复杂，得分情况执行不同的SQL，并且分页不稳定，中间查询出来的记录数可能小于pageSize（如果没有重复项，那会多出一倍的结果为空的查询），实际上后面还有数据&lt;/p&gt;

&lt;hr/&gt;&lt;h2&gt;进一步深入分析&lt;/h2&gt;
&lt;p&gt;我尝试在网上找过资料，只找到了以id为分页顺序，然后用id&amp;gt;'pre max id'这种方式来查，而我们要以可重复的created_time为分页顺序，如何写出简洁高效的SQL呢？&lt;/p&gt;

&lt;p&gt;如果要成为一个优秀的程序员，我觉得分析&amp;amp;解决新问题的能力，是必不可少的，即使在网上能找到解决方案，优秀的分析能力也有助于借鉴并结合自己的场景，优化出更好的个性化方案。&lt;/p&gt;

&lt;p&gt;我们在(user_id,created_time)建立了索引，并且我们知道InnoDB的辅助索引是包含了主键的，且主键一定不会重复，这意味着在索引上，每条记录的顺序是完全确定的，不存在重复的情况&lt;/p&gt;
&lt;p&gt;我们要分页的顺序跟此索引的顺序是吻合的，只需要沿着索引，一批一批地取数据就可以了，这是一个对索引很直接的利用，为什么现在我没办法做到？&lt;/p&gt;
&lt;p&gt;如果我是MySql的设计人员，针对这种很常见很直接的需求，我怎么去提供支持？还是说不支持？&lt;/p&gt;
&lt;p&gt;我举一个例子，像java中的基于排序的TreeSet，我猜它一定有floor和ceiling这样的方法(返回Set中，大于或小于指定元素的第一个元素)，这是基于排序的数据结构该有的东西，如果它没有，那早被人喷了然后加上去了&lt;/p&gt;
&lt;p&gt;回到索引的话题，这种直接的需求，它应该支持，否则说不过去，现在的问题变成了：用什么语法来，来实现在组合索引上，基于组合(user_id,created_time,id的组合)顺序的遍历？&lt;/p&gt;
&lt;p&gt;此时脑海里便回想起以前用过的(a,b) in ((1,2),(3,4),(7,4))这样的组合写法，然后猜测它也支持大于小于这类比较，跑去MySql中验证一下：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;46&quot;&gt;
&lt;pre&gt;
&lt;span&gt;select&lt;/span&gt; (&lt;span&gt;3&lt;/span&gt;,&lt;span&gt;7&lt;/span&gt;)&lt;span&gt;&amp;gt;&lt;/span&gt;(&lt;span&gt;3&lt;/span&gt;,&lt;span&gt;7&lt;/span&gt;),    (&lt;span&gt;3&lt;/span&gt;,&lt;span&gt;6&lt;/span&gt;)&lt;span&gt;&amp;gt;&lt;/span&gt;(&lt;span&gt;3&lt;/span&gt;,&lt;span&gt;7&lt;/span&gt;),    (&lt;span&gt;3&lt;/span&gt;,&lt;span&gt;8&lt;/span&gt;)&lt;span&gt;&amp;gt;&lt;/span&gt;(&lt;span&gt;3&lt;/span&gt;,&lt;span&gt;7&lt;/span&gt;),    (&lt;span&gt;4&lt;/span&gt;,&lt;span&gt;7&lt;/span&gt;)&lt;span&gt;&amp;gt;&lt;/span&gt;(&lt;span&gt;3&lt;/span&gt;,&lt;span&gt;7&lt;/span&gt;),    (&lt;span&gt;4&lt;/span&gt;,&lt;span&gt;2&lt;/span&gt;)&lt;span&gt;&amp;gt;&lt;/span&gt;(&lt;span&gt;3&lt;/span&gt;,&lt;span&gt;7&lt;/span&gt;&lt;span&gt;);
返回：
&lt;/span&gt;&lt;span&gt;0&lt;/span&gt;    &lt;span&gt;0&lt;/span&gt;    &lt;span&gt;1&lt;/span&gt;    &lt;span&gt;1&lt;/span&gt;    &lt;span&gt;1&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;如此一来，这问题就变得和id&amp;gt;'pre max id'这种一样简单了。&lt;/p&gt;
&lt;p&gt;这种写法在官方文档中也找到了对应的资料，官方称这类运算为“行比较”（row comparisons）&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://dev.mysql.com/doc/refman/5.7/en/comparison-operators.html#operator_greater-than&quot;&gt;https://dev.mysql.com/doc/refman/5.7/en/comparison-operators.html#operator_greater-than&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;看到这里，也许你跟我当时一样，即开心又兴奋，一个完美的方案就在眼前，然而MySql优化器没有我们想像的聪明，在“行比较”面前，就变成了二傻子，不能很好地使用索引了&lt;/p&gt;
&lt;p&gt;此时我又回过头去试验了一下“行比较”对应的等价写法&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;34&quot;&gt;
&lt;pre&gt;
(a,b)&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;span&gt;(x,y)
等价于
a&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;x &lt;span&gt;or&lt;/span&gt; (a&lt;span&gt;=&lt;/span&gt;x &lt;span&gt;and&lt;/span&gt; b&lt;span&gt;&amp;gt;&lt;/span&gt;y)
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;发现这种看似很复杂且还有or的写法，竟然能很好地使用索引，效率非常高，即使像(a,b,c)&amp;gt;(x,y,z)，改成很复杂的等价写法：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;32&quot;&gt;
&lt;pre&gt;
a&lt;span&gt;&amp;gt;&lt;/span&gt;x &lt;span&gt;or&lt;/span&gt; (a&lt;span&gt;=&lt;/span&gt;x &lt;span&gt;and&lt;/span&gt; (b&lt;span&gt;&amp;gt;&lt;/span&gt;y &lt;span&gt;or&lt;/span&gt; (b&lt;span&gt;=&lt;/span&gt;y &lt;span&gt;and&lt;/span&gt; c&lt;span&gt;&amp;gt;&lt;/span&gt;z)))
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;也能很好地使用索引，此时真不知道该夸它还是骂它，唉&lt;/p&gt;
&lt;p&gt;关于“行比较”的索引选择，在官网找到这样一份资料，文中说索引覆盖不到时，建议拆开成普通写法，这样看来，也许人家是有什么苦衷吧&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://dev.mysql.com/doc/refman/5.7/en/row-constructor-optimization.html&quot;&gt;https://dev.mysql.com/doc/refman/5.7/en/row-constructor-optimization.html&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt; 方案3&lt;/h2&gt;
&lt;p&gt;由于有了a&amp;gt;x or (a=x and b&amp;gt;y)这种等价于组合比较的语法，且能正确地使用索引，所以可以写出高效且还算简洁的SQL&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;38&quot;&gt;
&lt;pre readability=&quot;9&quot;&gt;
&lt;span&gt;select&lt;/span&gt; &lt;span&gt;*&lt;/span&gt; &lt;span&gt;from&lt;/span&gt; &lt;span&gt;order&lt;/span&gt; &lt;p&gt;&lt;span&gt;where&lt;/span&gt; &lt;span&gt;user_id&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; xxx &lt;span&gt;and&lt;/span&gt; 【其它业务条件】 &lt;span&gt;and&lt;/span&gt; (created_time &lt;span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;'&lt;/span&gt;&lt;span&gt;created_time of latest recode&lt;/span&gt;&lt;span&gt;'&lt;/span&gt; &lt;span&gt;or&lt;/span&gt; (created_time &lt;span&gt;=&lt;/span&gt; &lt;span&gt;'&lt;/span&gt;&lt;span&gt;created_time of latest recode&lt;/span&gt;&lt;span&gt;'&lt;/span&gt; &lt;span&gt;and&lt;/span&gt; id &lt;span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;'&lt;/span&gt;&lt;span&gt;id of latest recode&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;))  &lt;/p&gt;&lt;p&gt;&lt;span&gt;order&lt;/span&gt; &lt;span&gt;by&lt;/span&gt; created_time, id limit pageSize
&lt;/p&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;此方式跟以id为序的分页查询是一样的，首次查询去掉组合条件即可，代码略显复杂，好在可以利用上组合索引，十分高效，耗时稳定，不会因为遍历到末尾而性能降低&lt;/p&gt;
&lt;p&gt;遗憾地是，最优雅的方式却撞见个二傻子优化器，按理说用他们支持的特定语法(变化范围更小，模式更固定)去精确地表达查询需求，应该更容易被优化器识别出来并用最优方案去执行才说得通，结果却不如人意&lt;/p&gt;
&lt;p&gt;希望以后能MySql更好地支持“行比较”吧(8.0.19仍存在问题)&lt;/p&gt;
&lt;h5&gt; 注意：&lt;/h5&gt;
&lt;p&gt;这里也不允许created_time为null，因为null值参与&amp;gt;和=运算，结果一律为null，即条件不成立，相应结果查不出来。&lt;/p&gt;
&lt;p&gt;如果存在为null的情况，则要作一些调整，如果前一批数据的最后一条记录的created_time为null（null在索引中被视作极小值），则可以这样改：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;32&quot;&gt;
&lt;pre&gt;
(created_time &lt;span&gt;is&lt;/span&gt; &lt;span&gt;not&lt;/span&gt; &lt;span&gt;null&lt;/span&gt; &lt;span&gt;or&lt;/span&gt; (created_time &lt;span&gt;is&lt;/span&gt; &lt;span&gt;null&lt;/span&gt; &lt;span&gt;and&lt;/span&gt; id &lt;span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;'&lt;/span&gt;&lt;span&gt;id of latest recode&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;))
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;仍旧可以走索引，实现高效分页查询&lt;/p&gt;
&lt;hr/&gt;&lt;h2&gt;总结&lt;/h2&gt;
&lt;p&gt;方案1在小表的情况下，简单方便，只用传页码和页大小即可，还可以随机跳到指定页，具有一定优势&lt;/p&gt;
&lt;p&gt;方案2和方案3在大表的情况下，有着优异的性能，以及稳定性，缺点是不能随机地跳转页面，需要传入上一页的排序字段。这个弊端在一定程度上可以规避，比如现在很多分页都是一页一页地往下翻，比如微博、朋友圈动态等，或者是分批处理全表数据，不需要随机跳转&lt;/p&gt;
&lt;p&gt;细心的同学可能发现，where条件里还有【其它业务条件】，这样还能正常走索引吗？是否会发生全表扫描？这个问题其实是可以规避的，有空再写一篇执行计划并不完全可靠的案例。&lt;/p&gt;
&lt;p&gt;注：执行计划有时不能正确地反映实际执行效果，所以我没有贴执行计划；我使用的MySql版本为5.7.23和8.0.19&lt;/p&gt;
&lt;h5&gt;题外话&lt;/h5&gt;
&lt;p&gt;方案3的写法是我自己琢磨出来的，在网上也没找到类似的资料，算独门秘技吧，除此之外，我觉得同样很有价值的是【进一步深入分析】中的思考过程，如果养成这种思考习惯，有利于创新，去解决别人没遇到过的问题，在未知的领域，知道该从哪个方向去寻找答案；或者找到新的方法更好地去解决旧问题。&lt;/p&gt;
&lt;p&gt;如果本文有帮助到你，或者觉得有价值，麻烦点个赞，这样我会更有动力去更多地分享自己的经验&lt;/p&gt;

&lt;hr/&gt;&lt;p&gt;转载请注明出处及作者(&lt;a href=&quot;https://www.cnblogs.com/trytocatch/p/mysql-page-query.html&quot;&gt;https://www.cnblogs.com/trytocatch/p/mysql-page-query.html&lt;/a&gt; by trytocatch)&lt;/p&gt;

&lt;/div&gt;</description>
<pubDate>Tue, 04 Aug 2020 00:32:00 +0000</pubDate>
<dc:creator>trytocatch</dc:creator>
<og:description>本文通过三种方案，循序渐进地讲解了MySql中，InnoDB下的大表分页查询，借助原创技巧，实现高效查询</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/trytocatch/p/mysql-page-query.html</dc:identifier>
</item>
<item>
<title>十分钟搭建自己的私有NuGet服务器-BaGet - xhznl</title>
<link>http://www.cnblogs.com/xhznl/p/13426918.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/xhznl/p/13426918.html</guid>
<description>&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;NuGet是用于微软.NET（包括 .NET Core）开发平台的软件包管理器。NuGet能够令你在项目中添加、移除和更新引用的工作变得更加快捷方便。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;通常使用NuGet都是官方的服务，但你有没有想过搭建自己的NuGet呢？在私有的NuGet上托管一些自己的类库，公司内部的类库等。。。搭建私有NuGet的方法有很多，比如NuGet.Server、ProGet、MyGet等等。本文使用的是BaGet，搭建过程也非常简单，下面进入正题。&lt;/p&gt;

&lt;h2 id=&quot;搭建baget&quot;&gt;搭建BaGet&lt;/h2&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;BaGet是一个构建于ASP.NET Core 基础上的 NuGet V3 服务器的开源实现。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;github地址：&lt;a href=&quot;https://github.com/loic-sharma/BaGet&quot;&gt;https://github.com/loic-sharma/BaGet&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;下载release包，我下载的是最新预览版，你也可以选择其他版本：&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/loic-sharma/BaGet/releases/download/v0.3.0-preview4/BaGet.zip&quot;&gt;https://github.com/loic-sharma/BaGet/releases/download/v0.3.0-preview4/BaGet.zip&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/610959/202008/610959-20200803145835306-1464552057.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;你可以按需要修改一下端口配置，默认是5000：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/610959/202008/610959-20200803150039208-1901086530.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;在解压目录下打开命令行，执行：&lt;code&gt;dotnet BaGet.dll&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/610959/202008/610959-20200803150339570-1549904699.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;浏览器访问：&lt;code&gt;http://localhost:8020/&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/610959/202008/610959-20200803150445407-1803809948.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;这样，NuGet服务就搭建完成了，是不是很简单？&lt;/p&gt;
&lt;h2 id=&quot;上传程序包&quot;&gt;上传程序包&lt;/h2&gt;
&lt;p&gt;随便创建一个类库项目用于测试：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/610959/202008/610959-20200803151119353-1878230504.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;右键项目，选择打包：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/610959/202008/610959-20200803151310795-1560461889.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;打包完成会得到一个nupkg文件：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/610959/202008/610959-20200803151449410-2061280830.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;当然，你也可以选择Release模式：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/610959/202008/610959-20200803163209042-827415192.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;看一下Upload命令：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/610959/202008/610959-20200803151627897-403112516.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;在上面打包目录下打开命令行执行：&lt;code&gt;dotnet nuget push -s http://localhost:8020/v3/index.json MyTestLibrary.1.0.0.nupkg&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/610959/202008/610959-20200803151838316-1387320016.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;再次查看Packages：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/610959/202008/610959-20200803152049239-1394894748.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h2 id=&quot;在vs中使用&quot;&gt;在vs中使用&lt;/h2&gt;
&lt;p&gt;在vs2019中打开：工具-选项-NuGet包管理器-程序包源。添加一个源，输入名称，源：&lt;a href=&quot;http://localhost:8020/v3/index.json&quot;&gt;http://localhost:8020/v3/index.json&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/610959/202008/610959-20200803153959710-285473415.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;接下来就可以正常使用了：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/610959/202008/610959-20200803154615906-823903425.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h2 id=&quot;其他&quot;&gt;其他&lt;/h2&gt;
&lt;p&gt;程序包的作者，说明，版本号等信息可以在这里修改：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/610959/202008/610959-20200803155418572-1384622153.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;依赖项也完全不用担心：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/610959/202008/610959-20200803160040430-1047110919.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;

&lt;p&gt;因为BaGet是基于ASP.NET Core开发，所以天生跨平台，你可以在windows，mac，linux或者docker中轻松部署。另外，BaGet也没有复杂的环境依赖，数据库默认Sqlite，很轻量，部署起来非常容易。&lt;/p&gt;
&lt;p&gt;当然，本文一开始也提到，搭建私有NuGet的方式有很多，如有需要可以参考微软官方说明：&lt;a href=&quot;https://docs.microsoft.com/zh-cn/nuget/hosting-packages/overview&quot;&gt;https://docs.microsoft.com/zh-cn/nuget/hosting-packages/overview&lt;/a&gt;&lt;/p&gt;
</description>
<pubDate>Tue, 04 Aug 2020 00:24:00 +0000</pubDate>
<dc:creator>xhznl</dc:creator>
<og:description>前言 NuGet是用于微软.NET（包括 .NET Core）开发平台的软件包管理器。NuGet能够令你在项目中添加、移除和更新引用的工作变得更加快捷方便。 通常使用NuGet都是官方的服务，但你有没</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/xhznl/p/13426918.html</dc:identifier>
</item>
<item>
<title>GitHub 热点速览 Vol.31：在？跑个 GitHub 评分如何？ - 削微寒</title>
<link>http://www.cnblogs.com/xueweihan/p/13430479.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/xueweihan/p/13430479.html</guid>
<description>&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/759200/202008/759200-20200803224416768-1005495644.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;摘要：个性化的 GitHub README 自从 7 月上线之后一直风靡在各大技术平台，当中最有意思的莫过于代表你技术的 GitHub Readme Stats 了，除了能显示你提交的 pr、commit 数等等，还能给你的表现评个分，A++ 选手遍地走，不知道你的表现又如何呢？除了 GitHub 数值统计小工具之外，Awesome-Profile-README-templates 这个 5k+ star 的项目也收录了大量有趣实用的 Readme demo，如果你想个性化下你的 GitHub，不妨参考下哟~&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;以下内容摘录自微博&lt;a href=&quot;https://www.weibo.com/hellogithub/&quot;&gt;@HelloGitHub&lt;/a&gt; 的 GitHub Trending 及 Hacker News 热帖（简称 HN 热帖），选项标准：&lt;code&gt;新发布&lt;/code&gt; | &lt;code&gt;实用&lt;/code&gt; | &lt;code&gt;有趣&lt;/code&gt;，根据项目 release 时间分类，发布时间不超过 7 day 的项目会标注 &lt;code&gt;New&lt;/code&gt;，无该标志则说明项目 release 超过一周。由于本文篇幅有限，还有部分项目未能在本文展示，望周知 🌝&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;本文目录
&lt;ul&gt;&lt;li&gt;
&lt;ol&gt;&lt;li&gt;本周特推&lt;/li&gt;
&lt;/ol&gt;&lt;ul&gt;&lt;li&gt;1.1 你的 GitHub 评分：GitHub Readme Stats&lt;/li&gt;
&lt;li&gt;1.2 图解算法：hello-algorithm&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;
&lt;ol start=&quot;2&quot;&gt;&lt;li&gt;GitHub Trending 周榜&lt;/li&gt;
&lt;/ol&gt;&lt;ul&gt;&lt;li&gt;2.1 了不起的 Profile README：Awesome-Profile-README-templates&lt;/li&gt;
&lt;li&gt;2.2 开发环境：androidx&lt;/li&gt;
&lt;li&gt;2.3 机器学习路径：machine-learning-roadmap&lt;/li&gt;
&lt;li&gt;2.4 非英语母语的 Rust 教程：easy_rust&lt;/li&gt;
&lt;li&gt;2.5 测试平台：metersphere&lt;/li&gt;
&lt;li&gt;2.6 面试指南：Interviews&lt;/li&gt;
&lt;li&gt;2.7 GitHub 官方路线图：roadmap&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;
&lt;ol start=&quot;3&quot;&gt;&lt;li&gt;Emoji Time&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;li&gt;
&lt;ol start=&quot;4&quot;&gt;&lt;li&gt;推荐阅读&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/759200/202008/759200-20200803224444255-1277339351.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h2 id=&quot;1-本周特推&quot;&gt;1. 本周特推&lt;/h2&gt;
&lt;h3 id=&quot;11-你的-github-评分：github-readme-stats&quot;&gt;1.1 你的 GitHub 评分：GitHub Readme Stats&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;本周 star 增长数：2300+&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;New&lt;/code&gt; GitHub Readme Stats 是一个可在你的 README 中获取动态生成的 GitHub 统计信息的小工具。目前支持 dark、radical、merko、gruvbox、tokyonight、onedark、cobalt, synthwave、highcontrast、dracula 等多个主题。&lt;/p&gt;
&lt;p&gt;用法很简单将这行代码复制到你的 markdown 文件中，简单如此！更改 &lt;code&gt;?username=&lt;/code&gt; 的值为你的 GitHub 用户名。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;[![Anurag's github stats](https://github-readme-stats.vercel.app/api?username=anuraghazra)](https://github.com/anuraghazra/github-readme-stats)
&lt;/code&gt;
&lt;/pre&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;GitHub 地址→https://github.com/anuraghazra/github-readme-stats&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/759200/202008/759200-20200803224501034-1841415549.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h3 id=&quot;12-图解算法：hello-algorithm&quot;&gt;1.2 图解算法：hello-algorithm&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;本周 star 增长数：2050+&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;hello-algorithm，又名小浩算法是作者在疫情期间完成的一部图解算法题典！ 目前共完成 140+ 道高频面试算法题目，总计 30w 字，全部采用漫画图解的方式，简单易懂，适合初中级读者。&lt;/p&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;GitHub 地址→https://github.com/geekxh/hello-algorithm&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/759200/202008/759200-20200803224518113-652731798.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h2 id=&quot;2-github-trending-周榜&quot;&gt;2. GitHub Trending 周榜&lt;/h2&gt;
&lt;h3 id=&quot;21-了不起的-profile-readme：awesome-profile-readme-templates&quot;&gt;2.1 了不起的 Profile README：Awesome-Profile-README-templates&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;本周 star 增长数：1550+&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;New&lt;/code&gt; Awesome-Profile-README-templates 收录了全世界有意思的 README，如果你像要只做你的专属 GitHub 简介，不妨参考下。&lt;/p&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;GitHub 地址→https://github.com/kautukkundan/Awesome-Profile-README-templates&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/759200/202008/759200-20200803224531193-479508653.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h3 id=&quot;22-开发环境：androidx&quot;&gt;2.2 开发环境：androidx&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;本周 star 增长数：1000+&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;New&lt;/code&gt; Androidx 是 Jetpack Android 扩展库的开发环境。与 Jetpack 在 AOSP 上的主要开发分支同步。Androidx 官方 AARs 和 JARs 二进制文件通过谷歌 Maven 发布。&lt;/p&gt;
&lt;p&gt;Androidx 组件可帮你遵循最佳实践，免编写样板代码的烦恼，简化复杂的任务，让你专注关心代码事情。&lt;/p&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;GitHub 地址→https://github.com/androidx/androidx&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&quot;23-机器学习路径：machine-learning-roadmap&quot;&gt;2.3 机器学习路径：machine-learning-roadmap&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;本周 star 增长数：2300+&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;New&lt;/code&gt; machine-learning-roadmap 是一个路线图，它将机器学习中许多最重要的概念串联起来，并告知你如何学习它们以及使用什么工具来执行它们。项目主要分为 5 个方面：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;🤔机器学习问题：机器学习问题是什么样子?&lt;/li&gt;
&lt;li&gt;♻️机器学习过程：一旦你发现一个问题,你会采取什么步骤来解决吗?&lt;/li&gt;
&lt;li&gt;🛠工具：你该怎么使用机器学习工具来构建解决方案吗?&lt;/li&gt;
&lt;li&gt;🧮机器学习数学：你写的机器学习代码背后到底发生了什么？&lt;/li&gt;
&lt;li&gt;📚机器学习资源：如何学习机器学习呢？&lt;/li&gt;
&lt;/ul&gt;&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;GitHub 地址→https://github.com/mrdbourke/machine-learning-roadmap&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/759200/202008/759200-20200803224545640-1926332835.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h3 id=&quot;24-非英语母语的-rust-教程：easy_rust&quot;&gt;2.4 非英语母语的 Rust 教程：easy_rust&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;本周 star 增长数：1250+&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;easy_rust 是一个居住在韩国的加拿大人撰写的教科书，旨在降低人学习 Rust 的门槛——即便你不是英语为母语的人，可以通过本教程学习好 Rust。&lt;/p&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;GitHub 地址→https://github.com/Dhghomon/easy_rust&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/759200/202008/759200-20200803224557543-1303838767.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h3 id=&quot;25-测试平台：metersphere&quot;&gt;2.5 测试平台：Metersphere&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;本周 star 增长数：600+&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;MeterSphere 是一站式的开源企业级持续测试平台，涵盖测试跟踪、接口测试、性能测试、团队协作等功能，兼容JMeter 等开源标准，有效助力开发和测试团队充分利用云弹性进行高度可扩展的自动化测试，加速高质量软件的交付。&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;测试跟踪: 远超 TestLink 的使用体验；&lt;/li&gt;
&lt;li&gt;接口测试: 类似 Postman 的体验；&lt;/li&gt;
&lt;li&gt;性能测试: 兼容 JMeter，支持 Kubernetes 和云环境，轻松支持高并发、分布式的性能测试；&lt;/li&gt;
&lt;li&gt;团队协作: 两级租户体系，天然支持团队协作。&lt;/li&gt;
&lt;/ul&gt;&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;GitHub 地址→https://github.com/metersphere/metersphere&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/759200/202008/759200-20200803224611162-1477942066.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h3 id=&quot;26-面试指南：interviews&quot;&gt;2.6 面试指南：Interviews&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;本周 star 增长数：600+&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Interviews 是一份面试指南，有中文翻译版。项目目录&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;在线练习&lt;/li&gt;
&lt;li&gt;在线面试编程&lt;/li&gt;
&lt;li&gt;数据结构&lt;/li&gt;
&lt;li&gt;算法&lt;/li&gt;
&lt;li&gt;位运算&lt;/li&gt;
&lt;li&gt;算法复杂度分析&lt;/li&gt;
&lt;li&gt;视频教程&lt;/li&gt;
&lt;li&gt;面试书籍&lt;/li&gt;
&lt;li&gt;计算机科学与技术资讯&lt;/li&gt;
&lt;li&gt;文件结构&lt;/li&gt;
&lt;/ul&gt;&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;GitHub 地址→https://github.com/kdn251/interviews&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&quot;27-github-官方路线图：roadmap&quot;&gt;2.7 GitHub 官方路线图：roadmap&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;本周 star 增长数：2700+&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;New&lt;/code&gt; roadmap 是 GitHub 公布的产品路线图，你可以了解到 GitHub 官方正在开发什么功能。官方按照季度，罗列了 2020 Q3- 2021 年 Q1 GitHub Actions、GitHub Docs、GitHub Packages、GitHub Pages 的开发任务安排。&lt;/p&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;GitHub 地址→https://github.com/github/roadmap&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/759200/202008/759200-20200803224753488-1794834380.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h2 id=&quot;3-ttime&quot;&gt;3. TTime&lt;/h2&gt;
&lt;p&gt;Talk Time (&lt;sup&gt;o&lt;/sup&gt;)/ 本周小鱼干在多个平台看到了有意思的 GitHub Proflie README，#请在本文评论区留下让你印象深刻的 README 吧~#&lt;/p&gt;
&lt;h2 id=&quot;4-推荐阅读&quot;&gt;4. 推荐阅读&lt;/h2&gt;
&lt;p&gt;以上为 2020 年第 31 个工作周的 GitHub Trending 🎉如果你 Pick 其他好玩、实用的 GitHub 项目，记得来 &lt;a href=&quot;https://github.com/521xueweihan/HelloGitHub&quot;&gt;HelloGitHub&lt;/a&gt; issue 区和我们分享下哟 🌝&lt;/p&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;HelloGitHub 交流群现已全面开放，添加微信号：HelloGitHub 为好友入群，可同前端、Java、Go 等各界大佬谈笑风生、切磋技术~&lt;br/&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/759200/202008/759200-20200803224926596-928134078.jpg&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;/blockquote&gt;
</description>
<pubDate>Tue, 04 Aug 2020 00:18:00 +0000</pubDate>
<dc:creator>削微寒</dc:creator>
<og:description>摘要：个性化的 GitHub README 自从 7 月上线之后一直风靡在各大技术平台，当中最有意思的莫过于代表你技术的 GitHub Readme Stats 了，除了能显示你提交的 pr、comm</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/xueweihan/p/13430479.html</dc:identifier>
</item>
<item>
<title>云计算&amp;存储测试：FIO工具入门与实战 - 测试生财</title>
<link>http://www.cnblogs.com/qa-freeroad/p/13431131.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/qa-freeroad/p/13431131.html</guid>
<description>&lt;h2&gt;&lt;strong&gt;1.1 简介&lt;/strong&gt;&lt;/h2&gt;

&lt;blockquote readability=&quot;20&quot;&gt;
&lt;p&gt;FIO是一个开源的I/O压力测试工具，主要是用来测试磁盘的IO性能，也可测试cpu，nic的IO性能。它可以支持13种不同的I/O引擎，包括：sync,mmap, libaio, posixaio, SG v3, splice, network, syslet, guasi, solarisaio, I/Opriorities (针对新的Linux内核), rate I/O, forked or threaded jobs等。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;fio 官网地址：&lt;/em&gt;&lt;/strong&gt;&lt;a href=&quot;http://freshmeat.net/projects/fio/&quot; data-cke-saved-href=&quot;http://freshmeat.net/projects/fio/&quot;&gt;&lt;strong&gt;&lt;em&gt;http://freshmeat.net/projects/fio/&lt;/em&gt;&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;fio文档：&lt;/em&gt;&lt;/strong&gt;&lt;a href=&quot;https://fio.readthedocs.io/en/latest/index.html&quot; data-cke-saved-href=&quot;https://fio.readthedocs.io/en/latest/index.html&quot;&gt;&lt;strong&gt;&lt;em&gt;https://fio.readthedocs.io/en/latest/index.html&lt;/em&gt;&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2&gt;&lt;strong&gt;2.1 常用测试场景&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;FIO相关测试场景：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;顺序读写&lt;/strong&gt; （吞吐量，常用单位为MB/s）：文件在硬盘上存储位置是连续的。&lt;/p&gt;
&lt;p&gt;适用场景：大文件拷贝（比如视频音乐）。速度即使很高，对数据库性能也没有参考价值。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;4K随机读写&lt;/strong&gt; （IOPS，常用单位为次）：在硬盘上随机位置读写数据，每次4KB。&lt;/p&gt;
&lt;p&gt;适用场景：操作系统运行、软件运行、数据库。&lt;/p&gt;


&lt;p&gt;有三种安装方式&lt;/p&gt;
&lt;h2&gt;&lt;strong&gt;2.1 apt安装（Ubuntu）&lt;/strong&gt;&lt;/h2&gt;

&lt;h2&gt;&lt;strong&gt;2.2 使用yum安装（centos）&lt;/strong&gt;&lt;/h2&gt;

&lt;h2&gt;&lt;strong&gt;2.3 手动安装&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;&lt;em&gt;&lt;strong&gt;附上一个基本涵盖所有操作系统的FIO包下载地址的网址：&lt;a href=&quot;https://pkgs.org/download/fio&quot; data-cke-saved-href=&quot;https://pkgs.org/download/fio&quot;&gt;&lt;span&gt;&lt;span&gt;https://pkgs.org/download/fio&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;
&lt;h2&gt;&lt;strong&gt;2.4 验证是否安装成功&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;输入：&lt;em&gt;&lt;strong&gt;fio -h&lt;/strong&gt;&lt;/em&gt;，看是否安装成功&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;cke_widget_wrapper cke_widget_inline cke_widget_image cke_image_nocaption cke_widget_selected&quot; data-cke-widget-wrapper=&quot;1&quot; data-cke-filter=&quot;off&quot; data-cke-display-name=&quot;图像&quot; data-cke-widget-id=&quot;8&quot;&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20200804072811732.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2NjZ3NoaWdhbw==,size_16,color_FFFFFF,t_70&quot; alt=&quot;&quot; width=&quot;553&quot; height=&quot;646&quot; class=&quot;cke_widget_element&quot; data-cke-saved-src=&quot;https://img-blog.csdnimg.cn/20200804072811732.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2NjZ3NoaWdhbw==,size_16,color_FFFFFF,t_70&quot; data-cke-widget-data=&quot;{&amp;amp;quot;hasCaption&amp;amp;quot;:false,&amp;amp;quot;src&amp;amp;quot;:&amp;amp;quot;https://img-blog.csdnimg.cn/20200804072811732.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2NjZ3NoaWdhbw==,size_16,color_FFFFFF,t_70&amp;amp;quot;,&amp;amp;quot;alt&amp;amp;quot;:&amp;amp;quot;&amp;amp;quot;,&amp;amp;quot;width&amp;amp;quot;:&amp;amp;quot;553&amp;amp;quot;,&amp;amp;quot;height&amp;amp;quot;:&amp;amp;quot;646&amp;amp;quot;,&amp;amp;quot;lock&amp;amp;quot;:true,&amp;amp;quot;align&amp;amp;quot;:&amp;amp;quot;none&amp;amp;quot;,&amp;amp;quot;classes&amp;amp;quot;:[]}&quot; data-cke-widget-upcasted=&quot;1&quot; data-cke-widget-keep-attr=&quot;0&quot; data-widget=&quot;image&quot;/&gt;&lt;span class=&quot;cke_reset cke_widget_drag_handler_container&quot;&gt;&lt;img src=&quot;data:image/gif;base64,R0lGODlhAQABAPABAP///wAAACH5BAEKAAAALAAAAAABAAEAAAICRAEAOw==&quot; width=&quot;15&quot; height=&quot;15&quot; class=&quot;cke_reset cke_widget_drag_handler&quot; title=&quot;点击并拖拽以移动&quot; data-cke-widget-drag-handler=&quot;1&quot;/&gt;&lt;span class=&quot;cke_image_resizer&quot; title=&quot;点击并拖拽以改变尺寸&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;h2&gt;&lt;strong&gt;3.1 fio参数解释&lt;/strong&gt;&lt;/h2&gt;
&lt;blockquote readability=&quot;71&quot;&gt;
&lt;p&gt;可以使用fio -help查看每个参数，具体的参数左右可以在官网查看how to文档，如下为几个常见的参数描述&lt;/p&gt;
&lt;p&gt;filename=/dev/emcpowerb　 支持文件系统或者裸设备，--filename=/dev/sdc或者--filename=/mnt/ccg/test_data（挂载的目录下任意文件名）&lt;/p&gt;
&lt;p&gt;direct=1                                测试过程绕过机器自带的buffer，使测试结果更真实&lt;/p&gt;
&lt;p&gt;rw=randwread                      测试随机读的I/O&lt;/p&gt;
&lt;p&gt;rw=randwrite                        测试随机写的I/O&lt;/p&gt;
&lt;p&gt;rw=randrw                            测试随机混合写和读的I/O&lt;/p&gt;
&lt;p&gt;rw=read                                测试顺序读的I/O&lt;/p&gt;
&lt;p&gt;rw=write                                测试顺序写的I/O&lt;/p&gt;
&lt;p&gt;rw=rw                                    测试顺序混合写和读的I/O&lt;/p&gt;
&lt;p&gt;bs=4k                                    单次io的块文件大小为4k，如果是测试文件系统，建议和文件系统的块大小保持一致。&lt;/p&gt;
&lt;p&gt;bsrange=512-2048               同上，提定数据块的大小范围，这里是随机生成一个范围&lt;/p&gt;
&lt;p&gt;time_based                           如果设置的话，即使file已被完全读写或写完，也要执行完runtime规定的时间。它是通过循环执行相同的负载来实现的，与runtime相对应。&lt;/p&gt;
&lt;p&gt;ramp_time=time                   设定在记录任何性能信息之前要运行特定负载的时间。这个用来等性能稳定后，再记录日志&lt;/p&gt;
&lt;p&gt;size=5g                                本次的测试文件大小为5g，以每次4k的io进行测试，即生成读写的文件大小。&lt;/p&gt;
&lt;p&gt;fdatasync=int                       同fsync，但是采用fdatasync()来同步数据，但不同步元数据&lt;/p&gt;
&lt;p&gt;sync=bool                            使用sync来进行buffered写。对于多数引擎，这意味着使用O_SYNC&lt;/p&gt;
&lt;p&gt;numjobs=30                        本次的测试线程为30&lt;/p&gt;
&lt;p&gt;iodepth=1                            队列深度。默认是1，可以通过设置大于1的数来提升并发度。&lt;/p&gt;
&lt;p&gt;runtime=1000                     测试时间为1000秒，如果不写则一直将5g文件分4k每次写完为止&lt;/p&gt;
&lt;p&gt;ioengine=psync                  io引擎使用pync方式，如果要使用libaio引擎，需要yum install libaio-devel包&lt;/p&gt;
&lt;p&gt;randrepeat=true                 对于随机IO负载，配置生成器的种子，使得路径是可以预估的，使得每次重复执行生成的序列是一样的。&lt;/p&gt;
&lt;p&gt;rwmixwrite=30                   在混合读写的模式下，写占30%，推荐读写配比为7:3&lt;/p&gt;
&lt;p&gt;group_reporting=1             关于显示结果的，汇总每个进程的信息&lt;/p&gt;
&lt;p&gt;此外&lt;/p&gt;
&lt;p&gt;lockmem=1g                     只使用1g内存进行测试&lt;/p&gt;
&lt;p&gt;zero_buffers                     用0初始化系统buffer&lt;/p&gt;
&lt;p&gt;nrfiles=8                           每个进程生成文件的数量&lt;/p&gt;
&lt;/blockquote&gt;


&lt;h2&gt;&lt;strong&gt;3.2 fio测试场景及生成报告详解&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;1）测试变量：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;bs大小：（4k，16k，64k，1m)&lt;/li&gt;
&lt;li&gt;读写模式：（read，write，rw，randread，randwrite，randrw）&lt;/li&gt;
&lt;li&gt;使用libaio异步引擎，iodepth队列长度为128。&lt;/li&gt;
&lt;li&gt;运行时间为60s&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;第一种：4K，顺序写&lt;/p&gt;

&lt;p&gt;第二种：16K，顺序读&lt;/p&gt;

&lt;p&gt;第三种：16K，混合读写，70%读，30%写&lt;/p&gt;

&lt;p&gt;第四种：64k，随机写&lt;/p&gt;

&lt;p&gt;第五种：1m，随机读&lt;/p&gt;

&lt;p&gt;第六种：1m，随机读写，70%读，30%写&lt;/p&gt;

&lt;p&gt;2）执行测试&lt;/p&gt;


&lt;p&gt;&lt;strong&gt;报告详解&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote readability=&quot;173&quot;&gt;
&lt;p&gt;#这一行列出了执行的关键参数&lt;/p&gt;
&lt;p&gt;ccg_fio: (g=0): rw=write, bs=4K-4K/4K-4K/4K-4K, ioengine=libaio, iodepth=128&lt;/p&gt;
&lt;p&gt;...&lt;/p&gt;
&lt;p&gt;fio-2.2.10&lt;/p&gt;
&lt;p&gt;Starting 16 processes&lt;/p&gt;
&lt;p&gt;ccg_fio: Laying out IO file(s) (1 file(s) / 1024MB)&lt;/p&gt;
&lt;p&gt;Jobs: 16 (f=16): [W(16)] [100.0% done] [0KB/98.11MB/0KB /s] [0/25.2K/0 iops] [eta 00m:00s]&lt;/p&gt;
&lt;p&gt;ccg_fio: (groupid=0, jobs=16): err= 0: pid=77217: Mon Jul 27 17:42:01 2020&lt;/p&gt;
&lt;p&gt;  write: io=5662.2MB, bw=96631KB/s, iops=24157, runt= 60002msec              #io指的是读写的数据总量，iops是关键的测试指标，每秒io次数，runt是执行总时间&lt;/p&gt;
&lt;p&gt;    slat (usec): min=3, max=5087, avg=611.46, stdev=640.30                            #slat=提交延迟，代表IO提交到kernel做处理的过程&lt;/p&gt;
&lt;p&gt;    clat (usec): min=317, max=238746, avg=82794.77, stdev=24469.97            #clat=完成延迟，代表提交到kernel到IO做完之间的时间&lt;/p&gt;
&lt;p&gt;     lat (usec): min=500, max=238761, avg=83406.74, stdev=24540.97             #lat=响应时间，IO结构体创建时刻开始，直到紧接着clat完成&lt;/p&gt;
&lt;p&gt;    clat percentiles (msec):                                                                                   #分位分布图&lt;/p&gt;
&lt;p&gt;     |  1.00th=[   21],  5.00th=[   42], 10.00th=[   52], 20.00th=[   64],&lt;/p&gt;
&lt;p&gt;     | 30.00th=[   73], 40.00th=[   79], 50.00th=[   85], 60.00th=[   90],                 #50分位：85us&lt;/p&gt;
&lt;p&gt;     | 70.00th=[   95], 80.00th=[  101], 90.00th=[  110], 95.00th=[  120],              #90分位：110us，95分位：120us&lt;/p&gt;
&lt;p&gt;     | 99.00th=[  151], 99.50th=[  167], 99.90th=[  192], 99.95th=[  200],             #99分位：151us&lt;/p&gt;
&lt;p&gt;     | 99.99th=[  215]                                                                      &lt;/p&gt;
&lt;p&gt;    bw (KB  /s): min=    4, max=14296, per=6.30%, avg=6087.37, stdev=1207.17                #bandwidth，带宽&lt;/p&gt;
&lt;p&gt;    lat (usec) : 500=0.01%, 750=0.01%, 1000=0.01%                                                            #latency分布：&amp;lt;500us占0.01%, 500us~750us占0.01%, &amp;lt;1000us占0.01&lt;/p&gt;
&lt;p&gt;    lat (msec) : 2=0.01%, 4=0.03%, 10=0.19%, 20=0.71%, 50=8.30%                                  #latency分布：&amp;lt;2ms占0.01%, 2ms~4ms占0.03%, 4ms~10ms占0.19%, 10ms~20ms占0.71%，20ms~50ms占8.3%&lt;/p&gt;
&lt;p&gt;    lat (msec) : 100=69.79%, 250=20.97%                                                                             #latency分布：&amp;lt;100ms占69.79%，100ms~250ms占20.97%&lt;/p&gt;
&lt;p&gt;  cpu          : usr=0.76%, sys=5.97%, ctx=2862343, majf=0, minf=5759                               #cpu=利用率，和top命令中类似&lt;/p&gt;
&lt;p&gt;  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, &amp;gt;=64=99.9%        #IO depths=io队列&lt;/p&gt;
&lt;p&gt;     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, &amp;gt;=64=0.0%      #IO submit=单个IO提交要提交的IO数&lt;/p&gt;
&lt;p&gt;     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, &amp;gt;=64=0.1%       #IO complete=Like the above submit number, but for completions instead.&lt;/p&gt;
&lt;p&gt;     issued    : total=r=0/w=1449515/d=0, short=r=0/w=0/d=0, drop=r=0/w=0/d=0                  #IO issued=The number of read/write requests issued, and how many of them were short.&lt;/p&gt;
&lt;p&gt;     latency   : target=0, window=0, percentile=100.00%, depth=128                                     #IO latencies=IO完延迟的分布&lt;/p&gt;

&lt;p&gt;Run status group 0 (all jobs):&lt;/p&gt;
&lt;p&gt;  WRITE: io=5662.2MB, aggrb=96631KB/s, minb=96631KB/s, maxb=96631KB/s, mint=60002msec, maxt=60002msec&lt;/p&gt;
&lt;p&gt;  #io=表示总共完成的IO数量。基于时间的测试场景下，此值为变量（时间越长读写次数越多）；在基于容量的测试场景下，此值匹配size参数大小（最多只会读写文件大小的size）。&lt;/p&gt;
&lt;p&gt;  #aggrb是所有进程/设备的汇总带宽。&lt;/p&gt;
&lt;p&gt;  #minb/maxb表示测量到的最小/最大带宽。&lt;/p&gt;
&lt;p&gt;  #mint/maxt表示测试的最短和最长耗时。基于时间的测试场景下，匹配runtime参数（基本一致），基于容量的测试，是一个变量(随时间大小变化)。&lt;/p&gt;
&lt;/blockquote&gt;




&lt;h2&gt;&lt;strong&gt;3.3 fio的job文件格式&lt;/strong&gt;&lt;/h2&gt;
&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;job file格式采用经典的ini文件，[]中的值表示job name，可以采用任意的ASCII字符，‘global’除外，global有特殊的意义。Global section描述了job file中各个job的默认配置值。一个job section可以覆盖global section中的参数，一个job file可以包含几个global section.一个job只会受到它上面的global section的影响。‘;’和‘#’可以用作注释&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;例子1&lt;/strong&gt;：两个进程，分别从一个从128MB文件中，随机读的job file.&lt;/em&gt;&lt;/p&gt;
&lt;blockquote readability=&quot;7&quot;&gt;
&lt;p&gt;#global为全局配置，对每个job都生效&lt;/p&gt;
&lt;p&gt;[global]&lt;/p&gt;
&lt;p&gt;rw=randread&lt;/p&gt;
&lt;p&gt;size=128m&lt;/p&gt;

&lt;p&gt;[job1]&lt;/p&gt;
&lt;p&gt;#这里的job名为job1，如果job1里面也定义rw，则会覆盖global中的rw的值&lt;/p&gt;
&lt;p&gt;#rw=randwrite&lt;/p&gt;

&lt;p&gt;[job2]&lt;/p&gt;
&lt;p&gt;#rw=rw&lt;/p&gt;
&lt;p&gt;#–end job file–&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;job1和job2 section是空的，因为所有的描述参数是共享的。没有给出filename=选项，fio会为每一个job创建一个文件名，如果用命令写，则是：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;fio –name=global –rw=randread –size=128m –name=job1 –name=job2&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;&lt;strong&gt;例子2&lt;/strong&gt;：&lt;/em&gt;&lt;em&gt;多个进程随机写文件的实例&lt;/em&gt;&lt;/p&gt;

&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;;–start job file —&lt;/p&gt;
&lt;p&gt;[random-writers]&lt;/p&gt;
&lt;p&gt;ioengine=libaio&lt;/p&gt;
&lt;p&gt;iodepth=4&lt;/p&gt;
&lt;p&gt;rw=randwrite&lt;/p&gt;
&lt;p&gt;bs=32k&lt;/p&gt;
&lt;p&gt;direct=0&lt;/p&gt;
&lt;p&gt;size=64m&lt;/p&gt;
&lt;p&gt;numjobs=4&lt;/p&gt;
&lt;p&gt;;–end job file–&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;这个例子没有global section,只有一个job section.&lt;/p&gt;
&lt;p&gt;上一个实例的说明：采用async,每一个文件的队列长度为4，采用随机写，采用32k的块，采用非direct io，共有4个进程，每个进程随机写64M的文件。也可以采用下面的命令：&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;fio –name=random-writers –ioengine=libaio –iodepth=4 –rw=randwrite –bs=32k –direct=0 –size=64m –numjobs=4&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;

&lt;h2&gt;&lt;strong&gt;3.4 环境变量（参数化）&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;在job file中支持环境变量扩展。类似于${VARNAME}可以作为选项的值（在=号右边）&lt;/p&gt;
&lt;p&gt;例子：&lt;/p&gt;

&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;#如下是job配置文件&lt;/p&gt;
&lt;p&gt;;–start job files–&lt;/p&gt;
&lt;p&gt;[random-writers]&lt;/p&gt;
&lt;p&gt;rw=randwrite&lt;/p&gt;
&lt;p&gt;size=${SIZE}&lt;/p&gt;
&lt;p&gt;numjobs=${NUMJOBS}&lt;/p&gt;
&lt;p&gt;;–end job file–&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;如果执行：&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;export SIZE=64m  NUMJOBS=4 fio jobfile,fio&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;该文件将被扩展为&lt;/p&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;；–start job file–&lt;/p&gt;
&lt;p&gt;[random-writers]&lt;/p&gt;
&lt;p&gt;rw=randwrite&lt;/p&gt;
&lt;p&gt;size=64m&lt;/p&gt;
&lt;p&gt;numjobs=4&lt;/p&gt;
&lt;p&gt;;–end job file–&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Tips：&lt;/p&gt;
&lt;blockquote readability=&quot;14&quot;&gt;
&lt;p&gt;&lt;em&gt;fio&lt;/em&gt;&lt;em&gt;有一些保留&lt;/em&gt;&lt;em&gt;keywords&lt;/em&gt;&lt;em&gt;，在内部将其替换成合适的值，这些&lt;/em&gt;&lt;em&gt;keywords&lt;/em&gt;&lt;em&gt;是：&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;$pagesize   &lt;/em&gt;&lt;em&gt;当前系统的页大小&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;$mb_memory &lt;/em&gt;&lt;em&gt;系统的总内存的大小，以&lt;/em&gt;&lt;em&gt;MB&lt;/em&gt;&lt;em&gt;为单位&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;$ncpus &lt;/em&gt;&lt;em&gt;在线有效的&lt;/em&gt;&lt;em&gt;cpu&lt;/em&gt;&lt;em&gt;数&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;这引起在命令行中和&lt;/em&gt;&lt;em&gt;job file&lt;/em&gt;&lt;em&gt;中都可以用，当&lt;/em&gt;&lt;em&gt;job&lt;/em&gt;&lt;em&gt;运行的时候，会自动的用当前系统的徝进行替换。支持简单的数学计算，如：&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;size=8*$mb_memory&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;也就是说我们尽量不要用这些保留关键字进行变量命名&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;


&lt;h2&gt;&lt;strong&gt;3.5 FIO的JOB配置文件实例&lt;/strong&gt;&lt;/h2&gt;
&lt;blockquote readability=&quot;19&quot;&gt;
&lt;p&gt;[global]&lt;/p&gt;
&lt;p&gt;#定义了全局的默认配置，其中参数化了IODEPTH，NUMJOBS，SIZE，BS，MNT_POINT，RUNTIME，SIZE&lt;/p&gt;
&lt;p&gt;iodepth=${IODEPTH}&lt;/p&gt;
&lt;p&gt;numjobs=${NUMJOBS}&lt;/p&gt;
&lt;p&gt;size=${SIZE}&lt;/p&gt;
&lt;p&gt;bs=${BS}&lt;/p&gt;
&lt;p&gt;directory=${MNT_POINT}&lt;/p&gt;
&lt;p&gt;runtime=${RUNTIME}  ;e.g 10, 10m; default to seconds&lt;/p&gt;
&lt;p&gt;time_based=1&lt;/p&gt;
&lt;p&gt;randrepeat=1&lt;/p&gt;
&lt;p&gt;ioengine=libaio&lt;/p&gt;
&lt;p&gt;direct=1&lt;/p&gt;
&lt;p&gt;sync=0&lt;/p&gt;
&lt;p&gt;fdatasync=0&lt;/p&gt;
&lt;p&gt;group_reporting=1&lt;/p&gt;
&lt;p&gt;filename=qfs_fio_test_file_${SIZE}&lt;/p&gt;

&lt;p&gt;[write]&lt;/p&gt;
&lt;p&gt;#顺序写场景&lt;/p&gt;
&lt;p&gt;name=qfs_write_${SIZE}&lt;/p&gt;
&lt;p&gt;rw=write&lt;/p&gt;

&lt;p&gt;[read]&lt;/p&gt;
&lt;p&gt;#顺序读场景&lt;/p&gt;
&lt;p&gt;name=qfs_read_${SIZE}&lt;/p&gt;
&lt;p&gt;rw=read&lt;/p&gt;

&lt;p&gt;[randread]&lt;/p&gt;
&lt;p&gt;#随机读场景&lt;/p&gt;
&lt;p&gt;name=qfs_randread_${SIZE}&lt;/p&gt;
&lt;p&gt;rw=randread&lt;/p&gt;

&lt;p&gt;[randwrite]&lt;/p&gt;
&lt;p&gt;#随机写场景&lt;/p&gt;
&lt;p&gt;name=qfs_randwrite_${SIZE}&lt;/p&gt;
&lt;p&gt;rw=randwrite&lt;/p&gt;

&lt;p&gt;[rw]&lt;/p&gt;
&lt;p&gt;#混合读写场景，读写比为7:3，将读写结果最后合并统计（MIXED）&lt;/p&gt;
&lt;p&gt;name=qfs_rw_${SIZE}&lt;/p&gt;
&lt;p&gt;rw=rw&lt;/p&gt;
&lt;p&gt;rwmixread=70&lt;/p&gt;
&lt;p&gt;unified_rw_reporting=1&lt;/p&gt;

&lt;p&gt;[randrw]&lt;/p&gt;
&lt;p&gt;#随机读写场景，读写比为7:3，将读写结果最后合并统计（MIXED）&lt;/p&gt;
&lt;p&gt;name=qfs_randrw_${SIZE}&lt;/p&gt;
&lt;p&gt;rw=randrw&lt;/p&gt;
&lt;p&gt;rwmixread=70&lt;/p&gt;
&lt;p&gt;unified_rw_reporting=1&lt;/p&gt;
&lt;/blockquote&gt;



&lt;h2&gt;&lt;strong&gt;3.6 FIO脚本编写&lt;/strong&gt;&lt;/h2&gt;






</description>
<pubDate>Mon, 03 Aug 2020 23:47:00 +0000</pubDate>
<dc:creator>测试生财</dc:creator>
<og:description>一、关于FIO 1.1 简介 FIO是一个开源的I/O压力测试工具，主要是用来测试磁盘的IO性能，也可测试cpu，nic的IO性能。它可以支持13种不同的I/O引擎，包括：sync,mmap, lib</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/qa-freeroad/p/13431131.html</dc:identifier>
</item>
<item>
<title>Spring Cloud Data Flow用Shell来操作，方便建立CICD - 南瓜慢说</title>
<link>http://www.cnblogs.com/larrydpk/p/13431123.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/larrydpk/p/13431123.html</guid>
<description>&lt;blockquote readability=&quot;2.9545454545455&quot;&gt;
&lt;p&gt;欢迎访问&lt;a href=&quot;https://www.pkslow.com/&quot;&gt;南瓜慢说 www.pkslow.com&lt;/a&gt;获取更多精彩文章！&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;之前我们用两篇文章讲解了&lt;code&gt;Spring Cloud Data Flow&lt;/code&gt;，例子都是用&lt;code&gt;UI&lt;/code&gt;操作的，但我们在&lt;code&gt;Linux&lt;/code&gt;系统上经常是无法提供界面来操作，集成在&lt;code&gt;Jenkins&lt;/code&gt;上也无法使用&lt;code&gt;UI&lt;/code&gt;。好在官方提供了&lt;code&gt;Data Flow Shell&lt;/code&gt;工具，可以在命令行模式下进行操作，非常方便。&lt;/p&gt;
&lt;p&gt;相关文章可参考：&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.pkslow.com/archives/spring-cloud-data-flow&quot;&gt;Spring Cloud Data Flow初体验，以Local模式运行&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.pkslow.com/archives/spring-cloud-data-flow-on-kubernetes&quot;&gt;把Spring Cloud Data Flow部署在Kubernetes上，再跑个任务试试&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Spring Cloud Data Flow Server&lt;/code&gt;提供了可操作的&lt;code&gt;REST API&lt;/code&gt;，所以这个&lt;code&gt;Shell&lt;/code&gt;工具的本质还是通过调用&lt;code&gt;REST API&lt;/code&gt;来交互的。&lt;/p&gt;

&lt;h2 id=&quot;section-2&quot;&gt;2.1 启动&lt;/h2&gt;
&lt;p&gt;首先要确保我们已经安装有&lt;code&gt;Java&lt;/code&gt;环境和下载了可执行的&lt;code&gt;jar&lt;/code&gt;包：&lt;a href=&quot;https://repo.spring.io/release/org/springframework/cloud/spring-cloud-dataflow-shell/2.5.3.RELEASE/spring-cloud-dataflow-shell-2.5.3.RELEASE.jar&quot;&gt;spring-cloud-dataflow-shell-2.5.3.RELEASE.jar&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;然后启动如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;$ java -jar spring-cloud-dataflow-shell-2.5.3.RELEASE.jar
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/946674/202008/946674-20200804074133458-1377066004.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;默认是连接了&lt;code&gt;http://localhost:9393&lt;/code&gt;的&lt;code&gt;Server&lt;/code&gt;，可以通过&lt;code&gt;--dataflow.uri=地址&lt;/code&gt;来指定。如果需要认证信息，需要加上&lt;code&gt;--dataflow.username=用户 --dataflow.password=密码&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;比如我们连接之前安装在&lt;code&gt;Kubernetes&lt;/code&gt;上的&lt;code&gt;Server&lt;/code&gt;如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;$ java -jar spring-cloud-dataflow-shell-2.5.3.RELEASE.jar --dataflow.uri=http://localhost:30093
&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;application&quot;&gt;2.2 Application操作&lt;/h2&gt;
&lt;p&gt;介绍一下&lt;code&gt;Application&lt;/code&gt;相关操作：&lt;/p&gt;
&lt;p&gt;列出所有目前注册的&lt;code&gt;app&lt;/code&gt;：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;dataflow:&amp;gt;app list
╔═══╤══════╤═════════╤════╤════════════════════╗
║app│source│processor│sink│        task        ║
╠═══╪══════╪═════════╪════╪════════════════════╣
║   │      │         │    │composed-task-runner║
║   │      │         │    │timestamp-batch     ║
║   │      │         │    │timestamp           ║
╚═══╧══════╧═════════╧════╧════════════════════╝
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;查看某个&lt;code&gt;app&lt;/code&gt;的信息：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;dataflow:&amp;gt;app info --type task timestamp
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;清除&lt;code&gt;app&lt;/code&gt;注册信息：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;dataflow:&amp;gt;app unregister --type task timestamp
Successfully unregistered application 'timestamp' with type 'task'.
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;清除所有&lt;code&gt;app&lt;/code&gt;注册信息：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;dataflow:&amp;gt;app all unregister
Successfully unregistered applications.
dataflow:&amp;gt;app list 
No registered apps.
You can register new apps with the 'app register' and 'app import' commands.
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;注册一个&lt;code&gt;app&lt;/code&gt;：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;dataflow:&amp;gt;app register --name timestamp-pkslow --type task --uri docker:springcloudtask/timestamp-task:2.1.1.RELEASE
Successfully registered application 'task:timestamp-pkslow'
dataflow:&amp;gt;app list
╔═══╤══════╤═════════╤════╤════════════════╗
║app│source│processor│sink│      task      ║
╠═══╪══════╪═════════╪════╪════════════════╣
║   │      │         │    │timestamp-pkslow║
╚═══╧══════╧═════════╧════╧════════════════╝
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;批量导入&lt;code&gt;app&lt;/code&gt;，可以从一个&lt;code&gt;URL&lt;/code&gt;或一个&lt;code&gt;properties&lt;/code&gt;文件导入：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;dataflow:&amp;gt;app import https://dataflow.spring.io/task-docker-latest
Successfully registered 3 applications from [task.composed-task-runner, task.timestamp.metadata, task.composed-task-runner.metadata, task.timestamp-batch.metadata, task.timestamp-batch, task.timestamp]
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;需要注意的是，在注册或导入&lt;code&gt;app&lt;/code&gt;时，如果重复的话，默认是无法导入的，不会覆盖。如果想要覆盖，可以加参数&lt;code&gt;--force&lt;/code&gt;。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;dataflow:&amp;gt;app register --name timestamp-pkslow --type task --uri docker:springcloudtask/timestamp-task:2.1.1.RELEASE
Command failed org.springframework.cloud.dataflow.rest.client.DataFlowClientException: The 'task:timestamp-pkslow' application is already registered as docker:springcloudtask/timestamp-task:2.1.1.RELEASE
The 'task:timestamp-pkslow' application is already registered as docker:springcloudtask/timestamp-task:2.1.1.RELEASE

dataflow:&amp;gt;app register --name timestamp-pkslow --type task --uri docker:springcloudtask/timestamp-task:2.1.1.RELEASE --force
Successfully registered application 'task:timestamp-pkslow'
&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;task&quot;&gt;2.3 Task操作&lt;/h2&gt;
&lt;p&gt;列出&lt;code&gt;task&lt;/code&gt;：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;dataflow:&amp;gt;task list
╔════════════════╤════════════════════════════════╤═══════════╤═══════════╗
║   Task Name    │        Task Definition         │description│Task Status║
╠════════════════╪════════════════════════════════╪═══════════╪═══════════╣
║timestamp-pkslow│timestamp                       │           │COMPLETE   ║
║timestamp-two   │&amp;lt;t1: timestamp || t2: timestamp&amp;gt;│           │ERROR      ║
║timestamp-two-t1│timestamp                       │           │COMPLETE   ║
║timestamp-two-t2│timestamp                       │           │COMPLETE   ║
╚════════════════╧════════════════════════════════╧═══════════╧═══════════╝
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;删除一个&lt;code&gt;task&lt;/code&gt;，这里我们删除的是一个组合&lt;code&gt;task&lt;/code&gt;，所以会把子&lt;code&gt;task&lt;/code&gt;也一并删除了：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;dataflow:&amp;gt;task destroy timestamp-two
Destroyed task 'timestamp-two'
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;删除所有&lt;code&gt;task&lt;/code&gt;，会有风险提示：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;dataflow:&amp;gt;task all destroy 
Really destroy all tasks? [y, n]: y
All tasks destroyed

dataflow:&amp;gt;task list
╔═════════╤═══════════════╤═══════════╤═══════════╗
║Task Name│Task Definition│description│Task Status║
╚═════════╧═══════════════╧═══════════╧═══════════╝
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;创建一个&lt;code&gt;task&lt;/code&gt;：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;dataflow:&amp;gt;task create timestamp-pkslow-t1 --definition &quot;timestamp --format=\&quot;yyyy\&quot;&quot; --description &quot;pkslow timestamp task&quot;
Created new task 'timestamp-pkslow-t1'

&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;启动一个&lt;code&gt;task&lt;/code&gt;并查看状态，启动时需要记录执行ID，然后通过执行ID来查询状态：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;dataflow:&amp;gt;task launch timestamp-pkslow-t1
Launched task 'timestamp-pkslow-t1' with execution id 8
dataflow:&amp;gt;task execution status 8
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;查看所有&lt;code&gt;task&lt;/code&gt;执行并查看执行日志：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;dataflow:&amp;gt;task execution list 


dataflow:&amp;gt;task execution log 8

  .   ____          _            __ _ _
 /\\ / ___'_ __ _ _(_)_ __  __ _ \ \ \ \
( ( )\___ | '_ | '_| | '_ \/ _` | \ \ \ \
 \\/  ___)| |_)| | | | | || (_| |  ) ) ) )
  '  |____| .__|_| |_|_| |_\__, | / / / /
 =========|_|==============|___/=/_/_/_/
 :: Spring Boot ::       (v2.1.13.RELEASE)

2020-08-01 17:20:51.626  INFO 1 --- [       Thread-5] com.zaxxer.hikari.HikariDataSource       : HikariPool-1 - Shutdown initiated...
2020-08-01 17:20:51.633  INFO 1 --- [       Thread-5] com.zaxxer.hikari.HikariDataSource       : HikariPool-1 - Shutdown completed.
&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;http&quot;&gt;2.4 Http请求&lt;/h2&gt;
&lt;p&gt;可以进行&lt;code&gt;http&lt;/code&gt;请求：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;dataflow:&amp;gt;http get https://www.pkslow.com

dataflow:&amp;gt;http post --target https://www.pkslow.com --data &quot;data&quot;
&amp;gt; POST (text/plain) https://www.pkslow.com data
&amp;gt; 405 METHOD_NOT_ALLOWED

Error sending data 'data' to 'https://www.pkslow.com'
&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;section-3&quot;&gt;2.5 读取并执行文件&lt;/h2&gt;
&lt;p&gt;先准备一个脚本文件，用来放&lt;code&gt;Data Flow Shell&lt;/code&gt;命令，文件名为&lt;code&gt;pkslow.shell&lt;/code&gt;，内容如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;version
date
app list
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;执行与结果如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;dataflow:&amp;gt;script pkslow.shell
version
2.5.3.RELEASE
date
Sunday, August 2, 2020 1:59:34 AM CST
app list
╔═══╤══════╤═════════╤════╤════════════════════╗
║app│source│processor│sink│        task        ║
╠═══╪══════╪═════════╪════╪════════════════════╣
║   │      │         │    │timestamp-pkslow    ║
║   │      │         │    │composed-task-runner║
║   │      │         │    │timestamp-batch     ║
║   │      │         │    │timestamp           ║
╚═══╧══════╧═════════╧════╧════════════════════╝

Script required 0.045 seconds to execute
dataflow:&amp;gt;
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;但其实我们在&lt;code&gt;CI/CD&lt;/code&gt;的&lt;code&gt;pipeline&lt;/code&gt;中，并不想先启动一个&lt;code&gt;shell&lt;/code&gt;命令行，然后再执行一个脚本。我们想一步到位，直接执行，执行完毕后退出&lt;code&gt;shell&lt;/code&gt;命令行。这也是有办法的，可以在启动的时候通过 &lt;code&gt;--spring.shell.commandFile&lt;/code&gt;指定文件，如果有多个文件则用逗号&lt;code&gt;,&lt;/code&gt;分隔。如下所示：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;$ java -jar spring-cloud-dataflow-shell-2.5.3.RELEASE.jar --dataflow.uri=http://localhost:30093 --spring.shell.commandFile=pkslow.shell
Successfully targeted http://localhost:30093
2020-08-02T02:03:49+0800 INFO main o.s.c.d.s.DataflowJLineShellComponent:311 - 2.5.3.RELEASE
2020-08-02T02:03:49+0800 INFO main o.s.c.d.s.DataflowJLineShellComponent:311 - Sunday, August 2, 2020 2:03:49 AM CST
2020-08-02T02:03:49+0800 INFO main o.s.c.d.s.DataflowJLineShellComponent:309 - 
╔═══╤══════╤═════════╤════╤════════════════════╗
║app│source│processor│sink│        task        ║
╠═══╪══════╪═════════╪════╪════════════════════╣
║   │      │         │    │timestamp-pkslow    ║
║   │      │         │    │composed-task-runner║
║   │      │         │    │timestamp-batch     ║
║   │      │         │    │timestamp           ║
╚═══╧══════╧═════════╧════╧════════════════════╝
$
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;执行完毕后，不会在&lt;code&gt;shell&lt;/code&gt;命令行模式里，而是退回&lt;code&gt;linux&lt;/code&gt;的终端。这正是我们所需要的。&lt;/p&gt;
&lt;p&gt;我们来准备一个&lt;code&gt;注册应用——创建任务——执行任务&lt;/code&gt;的脚本试试：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;version
date
app register --name pkslow-app-1 --type task --uri docker:springcloudtask/timestamp-task:2.1.1.RELEASE
task create pkslow-task-1 --definition &quot;pkslow-app-1&quot;
task launch pkslow-task-1
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;执行与结果如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;$ java -jar spring-cloud-dataflow-shell-2.5.3.RELEASE.jar --dataflow.uri=http://localhost:30093 --spring.shell.commandFile=pkslow.shell
Successfully targeted http://localhost:30093
2020-08-02T02:06:41+0800 INFO main o.s.c.d.s.DataflowJLineShellComponent:311 - 2.5.3.RELEASE
2020-08-02T02:06:41+0800 INFO main o.s.c.d.s.DataflowJLineShellComponent:311 - Sunday, August 2, 2020 2:06:41 AM CST
2020-08-02T02:06:41+0800 INFO main o.s.c.d.s.DataflowJLineShellComponent:311 - Successfully registered application 'task:pkslow-app-1'
2020-08-02T02:06:42+0800 INFO main o.s.c.d.s.DataflowJLineShellComponent:311 - Created new task 'pkslow-task-1'
2020-08-02T02:06:51+0800 INFO main o.s.c.d.s.DataflowJLineShellComponent:311 - Launched task 'pkslow-task-1' with execution id 9
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;这样，我们就可以实现自动化打包与部署运行了。&lt;/p&gt;

&lt;p&gt;强大的&lt;code&gt;shell&lt;/code&gt;工具提供了许多命令，其实不用一一记住，可以通过&lt;code&gt;help&lt;/code&gt;命令查看所有命令：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;dataflow:&amp;gt;help
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;如果只对特定的一类命令感兴趣，可以通过&lt;code&gt;help xxx&lt;/code&gt;的方式获取帮助：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot;&gt;dataflow:&amp;gt;help version
* version - Displays shell version

dataflow:&amp;gt;help app
* app all unregister - Unregister all applications
* app default - Change the default application version
* app import - Register all applications listed in a properties file
* app info - Get information about an application
* app list - List all registered applications
* app register - Register a new application
* app unregister - Unregister an application
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;shell&lt;/code&gt;还支持&lt;code&gt;tab&lt;/code&gt;键补全命令。&lt;/p&gt;

&lt;p&gt;本文的命令比较多，不想造成冗长，部分执行结果就不贴出来了，原文可到官网参考。&lt;/p&gt;
&lt;hr/&gt;&lt;p&gt;欢迎关注微信公众号&amp;lt;&lt;strong&gt;南瓜慢说&lt;/strong&gt;&amp;gt;，将持续为你更新...&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/other/946674/202008/946674-20200804074134494-211670775.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;多读书，多分享；多写作，多整理。&lt;/strong&gt;&lt;/p&gt;
</description>
<pubDate>Mon, 03 Aug 2020 23:42:00 +0000</pubDate>
<dc:creator>南瓜慢说</dc:creator>
<og:description>1 前言 欢迎访问南瓜慢说 www.pkslow.com获取更多精彩文章！ 之前我们用两篇文章讲解了Spring Cloud Data Flow，例子都是用UI操作的，但我们在Linux系统上经常是无</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/larrydpk/p/13431123.html</dc:identifier>
</item>
<item>
<title>树状数组 - LaoYin</title>
<link>http://www.cnblogs.com/Srand-X/p/13418829.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/Srand-X/p/13418829.html</guid>
<description>&lt;p&gt;&lt;strong&gt;如果你在考提高组的前一天还对这有疑问，那你会与一等奖失之交臂;&lt;/strong&gt;&lt;br/&gt;&lt;strong&gt;如果你还在冲击普及组一等奖，那这篇博客会浪费你人生中宝贵的5～20分钟。&lt;/strong&gt;&lt;/p&gt;
&lt;p align=&quot;right&quot;&gt;（这句话摘自&lt;a href=&quot;https://www.cnblogs.com/jason2003/p/9676729.html&quot; target=&quot;_blank&quot;&gt;Dijkstra_Liu的blog&lt;/a&gt; ）&lt;/p&gt;

&lt;p&gt;树状数组(Binary Indexed Tree(B.I.T),Fenwick Tree)是一个查询和修改都为&lt;code&gt;log(n)&lt;/code&gt;的基于倍增思想数据结构（数组）。&lt;br/&gt;树状数组和线段树很像，但能用树状数组解决的问题，基本上都能用线段树解决，而线段树能解决的树状数组不一定能解决。&lt;br/&gt;但相比较而言，树状数组效率要高很多，所以在某些题来说，树状数组是不二之选。&lt;/p&gt;

&lt;p&gt;在oi-wiki上的图，&lt;br/&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1755834/202008/1755834-20200802212518888-601469600.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;br/&gt;思想和线段树有些类似：用一个大节点表示一些小节点的信息，进行查询的时候只需要查询一些大节点而不是更多的小节点。&lt;br/&gt;我们假设父亲节点表示它子子孙孙的节点。&lt;br/&gt;列表：&lt;/p&gt;
&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;点&lt;/th&gt;
&lt;th&gt;代表&lt;/th&gt;
&lt;th&gt;个数&lt;/th&gt;
&lt;/tr&gt;&lt;/thead&gt;&lt;tbody readability=&quot;1&quot;&gt;&lt;tr&gt;&lt;td&gt;1(0001)&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;2(0010)&lt;/td&gt;
&lt;td&gt;1 ， 2&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;3(0011)&lt;/td&gt;
&lt;td&gt;3&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;4(0100)&lt;/td&gt;
&lt;td&gt;1 ， 2 ， 3 ， 4&lt;/td&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;5(0101)&lt;/td&gt;
&lt;td&gt;5&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;6(0110)&lt;/td&gt;
&lt;td&gt;5 ， 6&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;7(0111)&lt;/td&gt;
&lt;td&gt;7&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;8(1000)&lt;/td&gt;
&lt;td&gt;1 ， 2 ， 3 ， 4 ， 5 ， 6 ， 7 ， 8&lt;/td&gt;
&lt;td&gt;8&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;这里引入一个新函数&lt;code&gt;lowbit(x)&lt;/code&gt;，即算出x二进制的从右往左出现第一个1以及这个1之后的那些0组成数的二进制对应的十进制的数。&lt;br/&gt;我们&lt;s&gt;不难&lt;/s&gt;发现，一个点的代表个数为&lt;code&gt;lowbit(x)&lt;/code&gt;。&lt;/p&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;证明：&lt;br/&gt;对于一个x个点，&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;\[x=a_0*2^0+a_1*2^1+\ldots+a_{upbit(x)}*2^{upbit(x)} \qquad (a_{n}=1 \mid a_{n}=0) \]&lt;/p&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;在第x个点之前，其必有&lt;code&gt;x-lowbit(x)&lt;/code&gt;个点被包含（如上图）。&lt;br/&gt;所以，第x个点包含&lt;code&gt;lowbit(x)&lt;/code&gt;个点。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;至于&lt;code&gt;lowbit()&lt;/code&gt;的实现，我们可以用&lt;code&gt;x&amp;amp;-x&lt;/code&gt;。&lt;/p&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;证明：&lt;br/&gt;你自己推去吧，这里给例子。&lt;br/&gt;例如22，x=10110，~x=01001，~x+1=01010=-x，x&amp;amp;-x=10110&amp;amp;01010=10&lt;br/&gt;lowbit(22)=2&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;有了&lt;code&gt;x&amp;amp;-x&lt;/code&gt;，我们就可以用&lt;code&gt;O(logn)&lt;/code&gt;的复杂度来查询整个数组。&lt;/p&gt;

&lt;h2 id=&quot;单点修改，区间查询&quot;&gt;单点修改，区间查询&lt;/h2&gt;
&lt;p&gt;\[sum[x]=\sum_{i=1}^{x}a[i] \]&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-c++&quot;&gt;/*O(logn)*/
int t[N];//树状数组

void Add(int x,int d)//在第x位加上d
{
      for(;x&amp;lt;=n;x+=(x&amp;amp;-x) t[x]+=d;
}

int Ask(int x)//询问前x项的和
{
      int ans=0;
      for(;x;x-=(x&amp;amp;-x)) ans+=t[x];
      return ans;
}

Ask(r)-Ask(l-1)//询问[l,r]
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;a href=&quot;https://www.luogu.com.cn/problem/P3374&quot;&gt;luogu模板&lt;/a&gt;&lt;/p&gt;
&lt;details readability=&quot;21&quot;&gt;AC code
&lt;pre&gt;
&lt;code class=&quot;language-c++ hljs&quot;&gt;P3374
#include &amp;lt;cstdio&amp;gt;
#include &amp;lt;algorithm&amp;gt;
#include &amp;lt;cstring&amp;gt;
#include &amp;lt;cmath&amp;gt;
using namespace std;
const int N=5e5+5;
int n,m,c[N];
void Add(int x,int d)
{
        for(;x&amp;lt;=n;x+=(x&amp;amp;-x)) c[x]+=d;
}
int Quest(int x)
{
        int re=0;
        for(;x;x-=(x&amp;amp;-x)) re+=c[x];
        return re;
}
void Solve()
{
        scanf(&quot;%d%d&quot;,&amp;amp;n,&amp;amp;m);
        for(int i=1;i&amp;lt;=n;++i)
        {       int a;scanf(&quot;%d&quot;,&amp;amp;a);Add(i,a); }
        for(int i=1;i&amp;lt;=m;++i)
        {
                int s,a,b;scanf(&quot;%d%d%d&quot;,&amp;amp;s,&amp;amp;a,&amp;amp;b);
                if(s==1)
                        Add(a,b);
                else
                        printf(&quot;%d\n&quot;,Quest(max(b,a))-Quest(min(a,b)-1));
        }
}
int main()
{
        Solve();
        return 0;
}
&lt;/code&gt;
&lt;/pre&gt;&lt;/details&gt;&lt;h2 id=&quot;区间修改，单点查询&quot;&gt;区间修改，单点查询&lt;/h2&gt;
&lt;p&gt;通过&lt;code&gt;差分&lt;/code&gt;（就是记录数组中每个元素与前一个元素的差），把问题转化为单点修改，区间查询。&lt;/p&gt;
&lt;p&gt;z[i]为i与i-1的差分&lt;br/&gt;查询&lt;span class=&quot;math inline&quot;&gt;\(a[x]=/sum_i=1^xz[i]\)&lt;/span&gt;&lt;br/&gt;修改[l,r]+d,即为z[l]+=d,z[r+1]-=d;&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;/*O(logn)*/
int t[N];

void Add(int x,int d)
{
      for(;x&amp;lt;=n;x+=(x&amp;amp;-x)) t[x]+=d;
}

int Ask(int x)
{
      int ans=0;
      for(;x;x-=(x&amp;amp;-x)) ans+=t[x];
      return ans;
}

Add(l,d),Add(r+1,-d);//修改[l,r]+d
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;a href=&quot;https://www.luogu.com.cn/problem/P3368&quot;&gt;luogu模板&lt;/a&gt;&lt;/p&gt;
&lt;details readability=&quot;23&quot;&gt;AC code
&lt;pre&gt;
&lt;code class=&quot;language-c++ hljs&quot;&gt;//P3368
#include &amp;lt;cstdio&amp;gt;
#include &amp;lt;algorithm&amp;gt;
#include &amp;lt;cstring&amp;gt;
#include &amp;lt;cmath&amp;gt;
using namespace std;
const int N=5e5+5;
int n,m,c[N],a[N];
void Add(int x,int d)
{
        for(;x&amp;lt;=n;x+=(x&amp;amp;-x)) c[x]+=d;
}
int Quest(int x)
{
        int re=0;
        for(;x;x-=(x&amp;amp;-x)) re+=c[x];
        return re;
}
void Solve()
{
        scanf(&quot;%d%d&quot;,&amp;amp;n,&amp;amp;m);
        for(int i=1;i&amp;lt;=n;++i)
        {       scanf(&quot;%d&quot;,a+i);Add(i,a[i]-a[i-1]);     }
        for(int i=1;i&amp;lt;=m;++i)
        {
                int s;scanf(&quot;%d&quot;,&amp;amp;s);
                if(s==1)
                {
                        int a,b,c;scanf(&quot;%d%d%d&quot;,&amp;amp;a,&amp;amp;b,&amp;amp;c);
                        Add(a,c);Add(b+1,-c);
                }
                else
                {
                        int a;scanf(&quot;%d&quot;,&amp;amp;a);
                        printf(&quot;%d\n&quot;,Quest(a));
                }
        }
}
int main()
{
        Solve();
        return 0;
}
&lt;/code&gt;
&lt;/pre&gt;&lt;/details&gt;&lt;h2 id=&quot;区间修改，区间查询&quot;&gt;区间修改，区间查询&lt;/h2&gt;
&lt;p&gt;基于区间修改，单点查询的差分，z[i]为i与i-1的差分。&lt;/p&gt;
&lt;p&gt;\[\begin{align*} &amp;amp; \sum_{i=1}^{x}a[i] \\ &amp;amp; = \sum_{i=1}^{x}\sum_{j=1}^{i}z[j] \\ &amp;amp; = \sum_{i=1}^{x}z[j]*(x-i+1) \\ &amp;amp; = (x+1)*\sum_{i=1}^{x}z[i]-\sum_{i=1}^{x}z[i]*i \\ \end{align*} \]&lt;/p&gt;
&lt;p&gt;然后，我们可以维护两个数组的前缀和：&lt;br/&gt;一个是&lt;span class=&quot;math inline&quot;&gt;\(t[i]=\sum_{j=1}^{i}z[j]\)&lt;/span&gt;&lt;br/&gt;另一个是&lt;span class=&quot;math inline&quot;&gt;\(tr[i]=\sum_{j=1}^{i}z[j]*j\)&lt;/span&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-c++&quot;&gt;/*O((logn)^2)*/
int t[N],tr[N];

void Add(int x,int d)
{
      for(int i=x;i&amp;lt;=n;i+=(i&amp;amp;-i))
            t[i]+=d,tr[i]+=d*x;
}

int Ask(int x)
{
      int ans=0;
      for(int i=x;i;i-=(i&amp;amp;-i))
            ans+=(x+1)*t[i]-tr[i];
      return ans;
}

Add(l,d),Add(r+1,d);//修改[l,r]+d;
Ask(r)-Ask(l-1);//查询[l,r];
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;a href=&quot;https://www.luogu.com.cn/problem/P2357&quot;&gt;luogu模板&lt;/a&gt;&lt;/p&gt;
&lt;details readability=&quot;36&quot;&gt;AC code
&lt;pre&gt;
&lt;code class=&quot;language-c++ hljs&quot;&gt;//P2357
#include &amp;lt;cstdio&amp;gt;
#include &amp;lt;algorithm&amp;gt;
#include &amp;lt;cstring&amp;gt;
#include &amp;lt;cmath&amp;gt;
using namespace std;
typedef long long ll;
const int N=2e5+5;
ll n,m,c[N],c0[N];
void Add(ll x,ll d)
{
        for(ll i=x;i&amp;lt;=n;i+=(i&amp;amp;-i))
                c[i]+=d,c0[i]+=x*d;
}
ll ask(ll x)
{
        ll re=0;
        for(ll i=x;i;i-=(i&amp;amp;-i))
                re+=(x+1)*c[i]-c0[i];
        return re;
}
void Solve()
{
        scanf(&quot;%lld%lld&quot;,&amp;amp;n,&amp;amp;m);
        int now,last=0;
        for(int i=1;i&amp;lt;=n;++i)
        {
                scanf(&quot;%d&quot;,&amp;amp;now);
                Add(i,now-last);
                last=now;
        }
        for(int i=1;i&amp;lt;=m;++i)
        {
                ll s;scanf(&quot;%lld&quot;,&amp;amp;s);
                if(s==1)
                {
                        ll a,b,c;scanf(&quot;%lld%lld%lld&quot;,&amp;amp;a,&amp;amp;b,&amp;amp;c);
                        Add(a,c);Add(b+1,-c);
                }
                else if(s==2) 
                {
                        ll a;scanf(&quot;%lld&quot;,&amp;amp;a);
                        Add(1,a);Add(2,-a);
                }
                else if(s==3)
                {
                        ll a;scanf(&quot;%lld&quot;,&amp;amp;a);
                        Add(1,-a);Add(2,a);
                }
                else if(s==4)
                {
                        ll a,b;scanf(&quot;%lld%lld&quot;,&amp;amp;a,&amp;amp;b);
                        printf(&quot;%lld\n&quot;,ask(max(a,b))-ask(min(a,b)-1));
                }
                else 
                {
                        printf(&quot;%lld\n&quot;,c[1]);
                }
        }
}
int main()
{
        Solve();
        return 0;
}
&lt;/code&gt;
&lt;/pre&gt;&lt;/details&gt;
&lt;h2 id=&quot;单点修改，区间查询-2&quot;&gt;单点修改，区间查询&lt;/h2&gt;
&lt;p&gt;\[sum[x][y]=\sum_{i=1}^{x}\sum_{j=1}^{y}a[i][j] \]&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-c++&quot;&gt;/*O(logn*longn)*/
int t[N][N];

void Add(int x,int y,int d)
{
      for(;x&amp;lt;=n;x+=(x&amp;amp;-x))
            for(int i=y;i&amp;lt;=n;i+=(i&amp;amp;-i))
                  t[x][i]+=d;
}

int Ask(int x,int y)
{
      int ans=0;
      for(;x;x-=(x&amp;amp;-x))
            for(int i=y;i&amp;lt;=n;i-=(i&amp;amp;-i)
                  ans+=t[i][j];
      return ans;
}

Ask(x,y)+Ask(a-1,b-1)-Ask(x,a-1)-Ask(b-1,y);//查询[a,b]~[x][y] (a&amp;lt;=x&amp;amp;&amp;amp;b&amp;lt;=y)
&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;区间修改，单点查询-2&quot;&gt;区间修改，单点查询&lt;/h2&gt;
&lt;p&gt;因为二维前缀和为&lt;/p&gt;
&lt;p&gt;\[sum[i][j]=sum[i-1][j]+sum[i][j-1]-sum[i-1][j-1]+a[i][j] \]&lt;/p&gt;
&lt;p&gt;所以设&lt;code&gt;z[i][j]&lt;/code&gt;为&lt;code&gt;a[i][j]&lt;/code&gt;与&lt;code&gt;a[i-1][j]+a[i][j-1]-a[i-1][j-1]&lt;/code&gt;的差。&lt;br/&gt;例如：&lt;/p&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;a[i][j]&lt;br/&gt;1 4 5 6 3&lt;br/&gt;2 5 3 7 8&lt;br/&gt;9 4 5 6 2&lt;br/&gt;1 4 7 6 9&lt;br/&gt;1 2 3 6 1&lt;br/&gt;z[i][j]&lt;br/&gt;1 3 1 1 -3&lt;br/&gt;1 0 -3 3 4&lt;br/&gt;7 -8 3 -3 -5&lt;br/&gt;-8 8 2 -2 7&lt;br/&gt;0 -2 -2 4 -8&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;当我们想把中间的3×3加上d时，差分变化为:&lt;/p&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;z[i][j]&lt;br/&gt;0 00 0 0 00&lt;br/&gt;0 +d 0 0 -d&lt;br/&gt;0 00 0 0 00&lt;br/&gt;0 00 0 0 00&lt;br/&gt;0 -d 0 0 +d&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;实际变化为:&lt;/p&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;a[i][j]&lt;br/&gt;0 0 0 0 0&lt;br/&gt;0 d d d 0&lt;br/&gt;0 d d d 0&lt;br/&gt;0 d d d 0&lt;br/&gt;0 0 0 0 0&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;查询&lt;span class=&quot;math inline&quot;&gt;\(\sum_{i=1}^{x}\sum_{j=1}^{y}z[i][j]\)&lt;/span&gt;&lt;br/&gt;修改&lt;code&gt;z[a][b]+=d,z[a][y+1]-=d,z[x+1][b]-=d,z[x+1][y+1]+=d; (a&amp;lt;=x&amp;amp;&amp;amp;b&amp;lt;=y)&lt;/code&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-c++&quot;&gt;/*O((logn)^2)*/
int t[N][N];

void Add(int x,int y,int d)
{
      for(;x&amp;lt;=n;x+=(x&amp;amp;-x))
            for(int i=y;i&amp;lt;=n;i+=(i&amp;amp;-i))
                  t[x][i]+=d;
}

void Ask(int x,int y)
{
      int ans=0;
      for(;x;x-=(x&amp;amp;-x))
            for(int i=y;i;i-=(i&amp;amp;-i))
                  ans+=t[x][i];
      return ans;
}

Add(a,b,d),Add(a,y+1,-d),Add(x+1,b,-d),Add(x+1,y+1,d);//修改[a,b]~[x,y]+d (a&amp;lt;=x&amp;amp;&amp;amp;b&amp;lt;=y)
&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;区间修改，区间查询-2&quot;&gt;区间修改，区间查询&lt;/h2&gt;
&lt;p&gt;\[\begin{align*} &amp;amp; \sum_{i=1}^{x}\sum_{j=1}^{y}\sum_{q=1}^{i}\sum_{w=1}^{j}z[q][w] \\ &amp;amp; = \sum_{i=1}^{x}\sum_{j=1}^{y}z[i][j]*(x-i+1)*(y-j+1) \\ &amp;amp; = \\ &amp;amp; (x+1)*(y+1)*\sum_{i=1}^{x}\sum_{j=1}^{y}z[i][j] \\ &amp;amp; -(y+1)*\sum_{i=1}^{x}\sum_{j=1}^{y}z[i][j]*i \\ &amp;amp; -(x+1)*\sum_{i=1}^{x}\sum_{j=1}^{y}z[i][j]*j \\ &amp;amp; +\sum_{i=1}^{x}\sum_{j=1}^{y}z[i][j]*i*j \end{align*} \]&lt;/p&gt;
&lt;p&gt;所以要开四个数组维护：&lt;br/&gt;&lt;code&gt;t[i][j]维护z[i][j]&lt;/code&gt;&lt;br/&gt;&lt;code&gt;ti[i][j]维护z[i][j]*i&lt;/code&gt;&lt;br/&gt;&lt;code&gt;tj[i][j]维护z[i][j]*j&lt;/code&gt;&lt;br/&gt;&lt;code&gt;tij[i][j]维护z[i][j]*i*j&lt;/code&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-c++&quot;&gt;/*O((logn)^2)*/
int t[N][N],ti[N][N],tj[N][N],tij[N][N];

void Add(int x,int y,int d)
{
      for(int i=x;i&amp;lt;=n;i+=(i&amp;amp;-i))
            for(int j=y;j&amp;lt;=n;j+=(j&amp;amp;-j))
                  t[i][j]+=d,ti[i][j]+=d*x,tj[i][j]+=d*y,tij[i][j]+=d*i*j;
}

int Ask(int x,int y)
{
      int ans=0;
      for(int i=x;i;i-=(i&amp;amp;-i))
            for(int j=y;j;j-=(j&amp;amp;-j))
                  ans+=(x+1)*(y+1)*t[i][j]-(y+1)*ti[i][j]-(x+1)*tj[i][j]+tij[i][j];
      return ans;
}

Add(a,b,d),Add(a,y+1,-d),Add(x+1,b,-d),Add(x+1,y+1,d);//修改[a,b]~[x,y]+d (a&amp;lt;=x&amp;amp;&amp;amp;b&amp;lt;=y)
Ask(x,y)+Ask(a-1,b-1)-Ask(x,a-1)-Ask(b-1,y);//查询[a,b]~[x][y] (a&amp;lt;=x&amp;amp;&amp;amp;b&amp;lt;=y)
&lt;/code&gt;
&lt;/pre&gt;

&lt;h2 id=&quot;不可修改，最大最小&quot;&gt;不可修改，最大最小&lt;/h2&gt;
&lt;p&gt;树状数组还可以求一个数组的区间中的最大最小。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-c++&quot;&gt;/*O(logn)*/
int tmax[N],tmin[N],a[N];

memset(tmax,0x80,sizeof(tmax));
memset(tmin,0x3f,sizeof(tmin));

void Add(int x,int d)
{
      for(;x&amp;lt;=n;x+=(x&amp;amp;-x)) 
            tmax[x]=max(tmax[x],d),tmin[x]=min(tmin[x],d);
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;递归版本&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-c++&quot;&gt;/*O(logn)*/
int Fmax(int l,int r)
{
      if(l&amp;gt;=r) return a[l];
      if(r-(r&amp;amp;-r)+1&amp;gt;=l) return max(tmax[r],Fmax(l,r-(r&amp;amp;-r)));
      else return max(a[r],Fmax(l,r-1)); 
}

int Fmin(int l,int r)
{
      if(l&amp;gt;=r) return a[l];
      if(r-(r&amp;amp;-r)+1&amp;gt;=l) return min(tmin[r],Fmin(l,r-(r&amp;amp;-r));
      else return min(a[r],Fmin(l,r-1));
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;递推版本&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-c++&quot;&gt;/*O(logn)*/
int Fmax(int l,int r)
{
      int ans=0;
      while(l&amp;lt;=r)
      {
            if(r-(r&amp;amp;-r)+1&amp;gt;=l) ans=max(ans,tmax[r]),r-=(r&amp;amp;-r);
            else ans=max(ans,a[r]),--r;
      }
      return ans;
}

int Fmin(int l,int r)
{
      int ans=0;
      while(l&amp;lt;=r)
      {
            if(r-(r&amp;amp;-r)+1&amp;gt;=l) ans=min(ans,tmin[r]),r-=(r&amp;amp;-r);
            else ans=min(ans,a[r]),--r;
      }
      return ans;
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;经验证明递推比递归快，不信可以试试&lt;a href=&quot;https://www.luogu.com.cn/problem/P3865&quot;&gt;这题&lt;/a&gt;，记得用树状数组写。&lt;/p&gt;
&lt;details readability=&quot;25&quot;&gt;AC code
&lt;pre&gt;
&lt;code class=&quot;language-c++ hljs&quot;&gt;//P3865
#include &amp;lt;cstdio&amp;gt;
#include &amp;lt;algorithm&amp;gt;
#include &amp;lt;cstring&amp;gt;
#include &amp;lt;cmath&amp;gt;
using namespace std;
const int N=1e5+5;
int n,m,a[N],cmax[N];
char S[1&amp;lt;&amp;lt;20], * p1, * p2;
char gc()
{
        if(p1==p2)
        {
                p1=S;
                p2=S+fread(S,1,1&amp;lt;&amp;lt;20,stdin);
        }
        return *p1++;
}
inline int read() 
{
        int s = 0, w = 1;
        char ch = gc();
        while(ch &amp;lt; '0' || ch &amp;gt; '9') {if(ch == '-') w = -1; ch = gc();}
        while(ch &amp;gt;= '0' &amp;amp;&amp;amp; ch &amp;lt;= '9') s = s * 10 + ch - '0', ch = gc();
        return s * w;
}
inline int Fmax(int l,int r)
{
    int ans=0;
    while(l&amp;lt;=r)
    {
        if(r-(r&amp;amp;-r)+1&amp;gt;=l) ans=max(ans,cmax[r]),r=r-(r&amp;amp;-r);
        else ans=max(ans,a[r]),r-=1;
    }
        return ans;
}
void Solve()
{
        n=read(),m=read();
        for(register int i=1;i&amp;lt;=n;++i)
        {
                a[i]=read();
                cmax[i]=max(cmax[i],a[i]);
                if(i+(i&amp;amp;-i)&amp;lt;=n)cmax[i+(i&amp;amp;-i)]=cmax[i+(i&amp;amp;-i)]&amp;gt;cmax[i] ? cmax[i+(i&amp;amp;-i)] : cmax[i];
        }
        for(register int i=1;i&amp;lt;=m;++i)
        {
                int a=read(),b=read();
                printf(&quot;%d&quot;,Fmax(a,b));
                printf(&quot;\n&quot;);
        }
}
int main()
{
        Solve();
        return 0;
}
&lt;/code&gt;
&lt;/pre&gt;&lt;/details&gt;&lt;h2 id=&quot;区间固定，第k大小&quot;&gt;区间固定，第k大小&lt;/h2&gt;
&lt;p&gt;将所有数字看成一个可重集合，即定义数组&lt;code&gt;t[]&lt;/code&gt;表示值为&lt;code&gt;x&lt;/code&gt;的元素在整个序列重出现了&lt;code&gt;t[x]&lt;/code&gt;次。找第k大就是找到最大的&lt;code&gt;x&lt;/code&gt;恰好满足&lt;span class=&quot;math inline&quot;&gt;\(\sum_{i=1}^xa[i]&amp;lt;k\)&lt;/span&gt;。&lt;br/&gt;因为在树状数组的结构中，节点是以2的幂的长度划分的，所以我们可以每次扩展2的幂的长度来化简复杂度。&lt;br/&gt;最后注意第k大小要加1。&lt;br/&gt;这里只列举第k小，因为第k大为第&lt;code&gt;n-k&lt;/code&gt;小。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-c++&quot;&gt;/*O(logn)*/
int t[N];

void Add(int x,int d)
{
      for(x&amp;lt;=n;x+=(x&amp;amp;-x))t[x]+=d;
}

int Findk(int k)
{
      int ans=0,now=0;
      for(int i=log2(maxn);i&amp;gt;=0;--i)
      {
            ans+=(1&amp;lt;&amp;lt;i);
            if(ans&amp;gt;tot||now+t[ans]&amp;gt;=k) ans-=(1&amp;lt;&amp;lt;i);//扩展失败
            else now+=t[ans];//扩展成功
      }
      return ans+1;
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;a href=&quot;https://www.luogu.com.cn/problem/P1168&quot;&gt;luogu例题&lt;/a&gt;&lt;/p&gt;
&lt;details readability=&quot;20&quot;&gt;AC code
&lt;pre&gt;
&lt;code class=&quot;language-c++ hljs&quot;&gt;//P1168
#include &amp;lt;cstdio&amp;gt;
#include &amp;lt;algorithm&amp;gt;
#include &amp;lt;cstring&amp;gt;
#include &amp;lt;cmath&amp;gt;
typedef long long ll;
using namespace std;
const int N=1e5+5;
int n,m,c[N],a[N],b[N],tot;
void Add(int x,int d)
{
        for(;x&amp;lt;=n;x+=(x&amp;amp;-x)) c[x]+=d;
}
int Findk(int k)
{
        int ans=0,now=0;
        for(int i=log2(n);i&amp;gt;=0;--i)
        {
                ans+=(1&amp;lt;&amp;lt;i);
                if(ans&amp;gt;tot||now+c[ans]&amp;gt;=k) ans-=(1&amp;lt;&amp;lt;i);
                else now+=c[ans];
        }
        return ans+1;
}
void Solve()
{
        scanf(&quot;%d&quot;,&amp;amp;n);
        for(int i=1;i&amp;lt;=n;++i)
        {       scanf(&quot;%d&quot;,&amp;amp;a[i]);b[i]=a[i];    }
        sort(a+1,a+n+1);
        tot=unique(a+1,a+n+1)-a-1;
        for(int i=1;i&amp;lt;=n;++i)b[i]=lower_bound(a+1,a+tot+1,b[i])-a;
        for(int i=1;i&amp;lt;=n;++i)
        {
                Add(b[i],1);
                if(i &amp;amp; 1) printf(&quot;%d\n&quot;,a[Findk((i+1)&amp;gt;&amp;gt;1)]);
        }
}
int main ()
{
        Solve();
        return 0;
}
&lt;/code&gt;
&lt;/pre&gt;&lt;/details&gt;&lt;h2 id=&quot;离散化后，带权数组&quot;&gt;离散化后，带权数组&lt;/h2&gt;
&lt;p&gt;有的时候，我们需要用数值做下标，解决这样的问题就是离散化，也就成了带权树状数组。&lt;br/&gt;这使空间复杂度由&lt;code&gt;T(maxn)&lt;/code&gt;变为&lt;code&gt;T(tot)&lt;/code&gt;。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-c++&quot;&gt;/*O(nlogn)*/
int n,tot,m[N],a[N];

scanf(&quot;%d&quot;,&amp;amp;n);
for(int i=1;i&amp;lt;=n;++i)
      scanf(&quot;%d&quot;,&amp;amp;a[i]),m[i]=a[i];
sort(a+1,a+1+n);
tot=unique(a+1,a+n+1)-a-1;//去重
for(int i=1;i&amp;lt;=n;++i) 
      m[i]=lower_bound(a+1,a+tot+1,m[i])-a;
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;例如：&lt;/p&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;a[]&lt;br/&gt;1 2 3 10000&lt;br/&gt;m[]&lt;br/&gt;1 2 3 4&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;a href=&quot;https://www.luogu.com.cn/problem/P1168&quot;&gt;luogu例题&lt;/a&gt;&lt;/p&gt;
&lt;details readability=&quot;2&quot;&gt;AC code
&lt;pre&gt;
&lt;code class=&quot;language-c++ hljs&quot;&gt;//P1168
以为没有？其实和上次是一个题。
&lt;/code&gt;
&lt;/pre&gt;&lt;/details&gt;&lt;h2 id=&quot;结合动规，数组优化&quot;&gt;结合动规，数组优化&lt;/h2&gt;
&lt;p&gt;树状数组给动规优化，可使&lt;code&gt;O(n)&lt;/code&gt;变为&lt;code&gt;O(logn)&lt;/code&gt;。&lt;br/&gt;以最长子序列为例：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-c++&quot;&gt;/*O(nlogn)*/
int f[N],a[N],t[N],maxans;

void Add(int x,int d)
{
      for(;x&amp;lt;=n;x+=(x&amp;amp;-x)) t[x]=max(t[x],d);
}

int Fmax(int x)
{
      int ans=0;
      while(l&amp;lt;=r)
      {
            if(r-(r&amp;amp;-r)+1&amp;lt;=l) ans=max(ans,t[r]),r-=(r&amp;amp;-r);
            else ans=max(ans,a[r]),--r;
      }
      return ans;
}

for(int i=1;i&amp;lt;=n;++i)
{
      f[i]=1+Fmax(i);
      Add(i,f[i]);
      maxans=max(maxans,f[i]);
}
printf(&quot;%d&quot;,maxans);
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;a href=&quot;https://www.luogu.com.cn/problem/P1637&quot;&gt;luogu例题&lt;/a&gt;&lt;/p&gt;
&lt;details readability=&quot;24&quot;&gt;AC code
&lt;pre&gt;
&lt;code class=&quot;language-c++ hljs&quot;&gt;//P1637
#include &amp;lt;cstdio&amp;gt;
#include &amp;lt;algorithm&amp;gt;
#include &amp;lt;cstring&amp;gt;
#include &amp;lt;cmath&amp;gt;
typedef long long ll;
using namespace std;
const int N=3e4+2;
long long n,a[N],ma[N],na,t[N],ans,f[4][N];
void Add(long long  x,long long d)
{
        for(;x&amp;lt;=na;x+=(x&amp;amp;-x)) t[x]+=d;
}
long long Quest(long long x)
{
        long long re=0;
        for(;x;x-=(x&amp;amp;-x)) re+=t[x];
        return re;
}
void Solve()
{
        scanf(&quot;%lld&quot;,&amp;amp;n);
        for(int i=1;i&amp;lt;=n;++i)
                scanf(&quot;%lld&quot;,&amp;amp;a[i]),ma[i]=a[i];
        sort(a+1,a+n+1);
        na=unique(a+1,a+n+1)-a-1;
        for(int i=1;i&amp;lt;=n;++i)
                f[1][i]=1,ma[i]=lower_bound(a+1,a+na+1,ma[i])-a;
        for(int i=2;i&amp;lt;=3;++i)
        {
                memset(t,0,sizeof(t));
                for(int j=1;j&amp;lt;=n;++j)
                {
                        f[i][j]=Quest(ma[j]-1);
                        Add(ma[j],f[i-1][j]);
                        if(i==3) ans+=f[i][j];
                }
        }
        printf(&quot;%lld&quot;,ans);
}
int main ()
{
        Solve();
        return 0;
}
&lt;/code&gt;
&lt;/pre&gt;&lt;/details&gt;
&lt;h2 id=&quot;建树&quot;&gt;建树&lt;/h2&gt;
&lt;p&gt;每一个节点的值是由所有与自己直接相连的儿子的值求和得到的。即每次确定完儿子的值后，用自己的值更新自己的直接父亲。&lt;br/&gt;这样可把&lt;code&gt;O(nlogn)&lt;/code&gt;变为&lt;code&gt;O(n)&lt;/code&gt;。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-c++&quot;&gt;/*O(n)*/
int a[N],t[N];

for(int i=1;i&amp;lt;=n;++i)
{
      scanf(&quot;%d&quot;,&amp;amp;a[i]);
      t[i]+=a[i];
      if(i+(i&amp;amp;-i)&amp;lt;=n) t[i+(i&amp;amp;-i)]+=t[i]
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;重建&quot;&gt;重建&lt;/h2&gt;
&lt;p&gt;对付多组数据很常见的技巧。如果每次输入新数据时，都&lt;code&gt;memset&lt;/code&gt;暴力清空树状数组，就可能会造成超时。因此使用&lt;code&gt;tag&lt;/code&gt;标记，存储当前节点上次使用时间（即最近一次是被第几组数据使用）。每次操作时判断这个位置&lt;code&gt;tag&lt;/code&gt;中的时间和当前时间是否相同，就可以判断这个位置应该是&lt;code&gt;0&lt;/code&gt;还是数组内的值。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-c++&quot;&gt;/*O(logn)*/
int tag[N],t[N],Tag;

void Add(int x,int d)
{
      for(x&amp;lt;=n;x+=(x&amp;amp;-x))
      {
            if(tag[x]!=Tag) t[x]=0,tag[x]=Tag;
            t[x]+=d;
      }
}

void Ask(int x)
{
      int ans=0;
      for(;x;x-=(x&amp;amp;-x))
            if(tag[x]==Tag) ans+=t[x];
      return ans;
}

++Tag;//重建
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;a href=&quot;https://www.luogu.com.cn/problem/P1637&quot;&gt;lougu例题&lt;/a&gt;&lt;/p&gt;
</description>
<pubDate>Mon, 03 Aug 2020 22:16:00 +0000</pubDate>
<dc:creator>LaoYin</dc:creator>
<og:description>#前言 如果你在考提高组的前一天还对这有疑问，那你会与一等奖失之交臂; 如果你还在冲击普及组一等奖，那这篇博客会浪费你人生中宝贵的5～20分钟。 （这句话摘自Dijkstra_Liu的blog ） #</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/Srand-X/p/13418829.html</dc:identifier>
</item>
<item>
<title>Redis服务之高可用组件sentinel - Linux-1874</title>
<link>http://www.cnblogs.com/qiuhom-1874/p/13429776.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/qiuhom-1874/p/13429776.html</guid>
<description>&lt;p&gt;　　前文我们了解了redis的常用数据类型相关命令的使用和说明，回顾请参考&lt;a href=&quot;https://www.cnblogs.com/qiuhom-1874/p/13419690.html&quot; target=&quot;_blank&quot;&gt;https://www.cnblogs.com/qiuhom-1874/p/13419690.html&lt;/a&gt;；今天我们来聊一下redis的高可用组件sentinel；首先来回顾下redis的主从同步，主从同步最主要的作用是让master的数据在其他服务器上实时存在副本，起到了备份的效果；对于redis的读写来说，主从架构能够让读的请求分散到多个从服务器上，从而降低了单台redis读请求的io压力，同时也提高了redis读请求的并发能力；通常为了数据的一致性，从服务器一旦成为某一台redis的slave，那么从服务器上之前有的数据会被清空，然后把master发送过来的数据应用到内存，从而实现和master数据一致；除此之外slave通常会是只读属性，也就说slave端只能执行读操作，写操作会被拒绝，所以写请求始终是由master来完成；那么问题来了，对于这种主从复制架构的环境中，如果master宕机了，master宕机意味着整个系统将不能够写数据到redis,很显然这种情况我们应该及时解决；怎么解决呢？有没有这样的一组件帮我们对master做实时的监控，一旦发现master宕机就提升一个slave当选新的master，如果原master还有其他slave，将其他slave都从属于新的master；除此之外它还应该让系统在发生切换master时触发报警通知，让管理员尽快把坏掉的master修复上线；对，sentinel就有我们上述的这些功能，它能够监控主从同步集群中的master节点，在master发生宕机后能够自动故障转移，将提升一台slave作为新的master，然后通知管理员；&lt;/p&gt;
&lt;p&gt;　　Sentinel是一个分布式系统，我们可以在一个架构中运行多个sentinel，这些sentinel进程使用流言协议（gossipprotocols）来接收关于 Master是否下线的信息，并使用投票协议(Agreement Protocols)来决定是否执行自动故障迁移,以及选择哪个 Slave 作为新的 Master。每个sentinel进程会向其他sentinel进程、master、slave定时发送消息，以确保对方是否”活”着，如果发现对方在指定配置时间(可配置的)内未得到回应，则暂时认为对方已掉线，也就是所谓的”主观认为宕机” ，英文名称：Subjective Down，简称 SDOWN。有主观宕机，肯定就有客观宕机。当多个sentinel进程中多数的sentinel进程在对 Master 做出 SDOWN 的判断，并且通过 SENTINEL is-master-down-by-addr 命令互相交流之后，得出的 Master Server 下线判断，这种方式就是“客观宕机”，英文名称是：Objectively Down， 简称 ODOWN。通过一定的 vote 算法，从剩下的 slave 从服务器节点中，选一台提升为 Master 服务器节点，然后自动修改相关配置，并开启故障转移（failover）。&lt;/p&gt;
&lt;p&gt;　　配置使用sentinel&lt;/p&gt;
&lt;p&gt;　　环境说明&lt;/p&gt;
&lt;table border=&quot;0&quot; align=&quot;left&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;角色&lt;/td&gt;
&lt;td&gt;ip地址&lt;/td&gt;
&lt;td&gt;端口&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;master&lt;/td&gt;
&lt;td&gt;192.168.0.41&lt;/td&gt;
&lt;td&gt;6379&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;slave01&lt;/td&gt;
&lt;td&gt;192.168.0.42&lt;/td&gt;
&lt;td&gt;6379&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;slave02&lt;/td&gt;
&lt;td&gt;192.168.0.43&lt;/td&gt;
&lt;td&gt;6379&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;sentinel01&lt;/td&gt;
&lt;td&gt;192.168.0.41&lt;/td&gt;
&lt;td&gt;26379&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;sentinel02&lt;/td&gt;
&lt;td&gt;192.168.0.42&lt;/td&gt;
&lt;td&gt;26379&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;sentinel03&lt;/td&gt;
&lt;td&gt;192.168.0.43&lt;/td&gt;
&lt;td&gt;26379&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;








&lt;p&gt;　　架构图&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1503305/202008/1503305-20200803230115724-536769606.bmp&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　提示：从上面的架构图可以知道，首先我们必须要有一个主从架构的集群，然后在部署sentinel 来对主从同步集群做监控；&lt;/p&gt;
&lt;p&gt;　　redis主从复制集群搭建&lt;/p&gt;
&lt;p&gt;　　1、在192.168.0.41/42/43上安装redis，可以使用yum安装，也可以使用编译安装，redis安装请参考&lt;a href=&quot;https://www.cnblogs.com/qiuhom-1874/p/13378138.html&quot; target=&quot;_blank&quot;&gt;https://www.cnblogs.com/qiuhom-1874/p/13378138.html&lt;/a&gt;；&lt;/p&gt;
&lt;p&gt;　　2、配置192.168.0.41/42/43上的redis监听在非本机127.0.0.1上并配置42/43上的redis从属于192.168.0.41&lt;/p&gt;
&lt;p&gt;　　master&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1503305/202008/1503305-20200803233307959-1119373434.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　slave01&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1503305/202008/1503305-20200803233521546-57311280.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　slave02&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1503305/202008/1503305-20200803233627008-1751238696.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　提示：redis支持在线修改配置，保存配置到配置文件；SLAVEOF 指令用于指定redismaster的ip地址和端口，表示把该redis配置成对应master的slave角色；CONFIG REWRITE是把我们的配置保存到配置文件；&lt;/p&gt;
&lt;p&gt;　　在master上查看是否有两个从节点连接到master&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1503305/202008/1503305-20200803234028824-66776288.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　验证：在master上写数据，看看是否能够及时同步到两个slave上？&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1503305/202008/1503305-20200803234218524-1996939838.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1503305/202008/1503305-20200803234333741-1279892521.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1503305/202008/1503305-20200803234352102-1697104899.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　提示：可以看到在主库上写数据，从库上能够及时的同步主库上的数据；到此redis的主从集群就搭建完毕了；&lt;/p&gt;
&lt;p&gt;　　配置sentinel，让其监控master&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1503305/202008/1503305-20200803235415252-909772577.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　提示：三个sentinel的配置都是一样的，这里需要明确指定监控主从同步集群的master的ip地址和端口，以及有效法定票数，有效法定票数指的是至少有多少个sentinel主观认为master down了，然后才触发选举新master操作；通常在这种流言协议中，一般都是大于集群半数，如果是3台sentinel，至少要2台主观认为master宕机，才开始触发选举新master；如果是5台，那至少要3台；如果master配置的有认证密码，我们还需要在sentinel中指定认证密码；&lt;/p&gt;
&lt;p&gt;　　sentinel配置文件说明&lt;/p&gt;
&lt;p&gt;　　bind：该指令和redis配置文件中的bind是同样的用法，用于指定sentinel的监听地址；默认不指定，监听本机所有可用地址；&lt;/p&gt;
&lt;p&gt;　　protected-mode：指定是否开启保护模式；&lt;/p&gt;
&lt;p&gt;　　port：用于指定sentinel的监听端口；默认是26379&lt;/p&gt;
&lt;p&gt;　　daemonize：用于指定sentinel是否运行为守护进程，yes表示运行为后台守护进程；no表示不运行为守护进程，直接在前台运行；&lt;/p&gt;
&lt;p&gt;　　pidfile：指定pid文件路径；&lt;/p&gt;
&lt;p&gt;　　logfile：指定日志文件路径；&lt;/p&gt;
&lt;p&gt;　　dir：指定sentinel的工作路径；&lt;/p&gt;
&lt;p&gt;　　sentinel monitor &amp;lt;master-name&amp;gt; &amp;lt;ip&amp;gt; &amp;lt;redis-port&amp;gt; &amp;lt;quorum&amp;gt;：用于指定监控master节点的ip地址和端口以及有效法定票数；其中&amp;lt;master-name&amp;gt;是给监控的master一个名称，可以随便写，起标识的作用；&amp;lt;quorum&amp;gt;表示sentinel集群的quorum机制，即至少有quorum个sentinel节点同时判定主节点故障时，才认为其真的故障；&lt;/p&gt;
&lt;p&gt;　　sentinel auth-pass &amp;lt;master-name&amp;gt; &amp;lt;password&amp;gt;：指定master认证密码；通常都需要设置密码，并且master的密码和slave的密码应该是一样；&lt;/p&gt;
&lt;p&gt;　　sentinel down-after-milliseconds &amp;lt;master-name&amp;gt; &amp;lt;milliseconds&amp;gt;：配置监控到指定的集群的主节点异常状态持续多久方才将标记为“故障”；&lt;/p&gt;
&lt;p&gt;　　sentinel parallel-syncs &amp;lt;master-name&amp;gt; &amp;lt;numslaves&amp;gt;：指在failover过程中，能够被sentinel并行配置的从节点的数量；&lt;/p&gt;
&lt;p&gt;　　sentinel failover-timeout &amp;lt;master-name&amp;gt; &amp;lt;milliseconds&amp;gt;：sentinel必须在此指定的时长内完成故障转移操作，否则，将视为故障转移操作失败；&lt;/p&gt;
&lt;p&gt;　　sentinel notification-script &amp;lt;master-name&amp;gt; &amp;lt;script-path&amp;gt;：通知脚本，此脚本被自动传递多个参数；&lt;/p&gt;
&lt;p&gt;　　了解了sentinel的配置文件，接下我们把3台sentinel都启动起来&lt;/p&gt;
&lt;p&gt;　　master&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1503305/202008/1503305-20200804003812879-1557355392.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　slave01&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1503305/202008/1503305-20200804003938334-218405244.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　slave02&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1503305/202008/1503305-20200804004039997-2028410571.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　提示：从上面的信息可以看到3个sentinel都监控master的ip地址和端口，其实他们3个的配置文件都是一样的；&lt;/p&gt;
&lt;p&gt;　　查看sentinel日志&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1503305/202008/1503305-20200804004540972-2011487811.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　提示：从上面的日志信息可以了解到sentinel监控的master是192.168.0.41：6379；并且有两个slave分别是192.168.0.42：6379和192.168.0.43：6379；&lt;/p&gt;
&lt;p&gt;　　查看sentinel状态&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1503305/202008/1503305-20200804005737566-1999022209.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　提示：它提示我们开启了保护模式；&lt;/p&gt;
&lt;p&gt;　　关闭保护模式&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1503305/202008/1503305-20200804005944007-1399465104.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　重启sentinel，再次查看sentinel状态&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;39&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
[root@master ~]# systemctl restart redis-sentinel.service 
[root@master ~]# ss -tnl
State      Recv-Q Send-Q        Local Address:Port                       Peer Address:Port              
LISTEN     0      511                       *:26379                                 *:*                  
LISTEN     0      511                       *:6379                                  *:*                  
LISTEN     0      128                       *:22                                    *:*                  
LISTEN     0      100               127.0.0.1:25                                    *:*                  
LISTEN     0      511                      :::26379                                :::*                  
LISTEN     0      128                      :::22                                   :::*                  
LISTEN     0      100                     ::1:25                                   :::*                  
[root@master ~]# redis-cli -h 192.168.0.41 -p 26379       
192.168.0.41:26379&amp;gt; info sentinel
# Sentinel
sentinel_masters:1
sentinel_tilt:0
sentinel_running_scripts:0
sentinel_scripts_queue_length:0
sentinel_simulate_failure_flags:0
master0:name=mymaster,status=ok,address=192.168.0.41:6379,slaves=2,sentinels=3
192.168.0.41:26379&amp;gt; info clients
# Clients
connected_clients:3
client_longest_output_list:0
client_biggest_input_buf:0
blocked_clients:0
192.168.0.41:26379&amp;gt; CLIENT LIST
id=2 addr=192.168.0.42:59048 fd=14 name=sentinel-f60b324b-cmd age=38 idle=0 flags=N db=0 sub=0 psub=0 multi=-1 qbuf=0 qbuf-free=0 obl=0 oll=0 omem=0 events=r cmd=ping
id=3 addr=192.168.0.43:37480 fd=15 name=sentinel-eada229c-cmd age=38 idle=1 flags=N db=0 sub=0 psub=0 multi=-1 qbuf=0 qbuf-free=0 obl=0 oll=0 omem=0 events=r cmd=publish
id=4 addr=192.168.0.41:36706 fd=16 name= age=32 idle=0 flags=N db=0 sub=0 psub=0 multi=-1 qbuf=0 qbuf-free=32768 obl=0 oll=0 omem=0 events=r cmd=client
192.168.0.41:26379&amp;gt; 
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　提示：从上面的状态信息可以看到当前sentinel监控的master是出于正常ok状态，有两个slave和3个sentinel；对于192.168.0.41：26379目前有3个客户端连接，二个是sentinel，一个本机；到此3台sentinel搭建启动完成；&lt;/p&gt;
&lt;p&gt;　　验证：把master宕机，看看sentinel是否将在两个从节点选举一个为新master？是否将另外一个slave重新指向新master？&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1503305/202008/1503305-20200804011512305-639658517.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　在slave01上查看主从同步信息&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1503305/202008/1503305-20200804011809722-1323491653.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　提示：第一次查看只是告诉我们master宕机了，第二次查看就告诉我们当前节点为master，并且拥有一个slave节点，这说明已经完成了故障转移，slave01已经被提升为新的master了；&lt;/p&gt;
&lt;p&gt;　　在192.168.0.43上查看主从信息，看看是否指向新的master？&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1503305/202008/1503305-20200804012030656-777161377.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　提示：在slave02上看主从同步信息，可以看到slave02已经从属新master了；&lt;/p&gt;
&lt;p&gt;　　查看故障转移时 sentinel日志&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1503305/202008/1503305-20200804012621547-176582890.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　提示：从上面的日志信息可以了解到，在从sdown到odown后，就会触发vote算法开始选举leader；然后将原master降级为slave，然后将选举出来的leader原salve属性去除（slaveof no one）;然后提升新master，然后将剩下的slave重新配置新master为主；最后是切换master，开始新的监控；&lt;/p&gt;
&lt;p&gt;　　查看故障 转移后的 redis 配置文件&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1503305/202008/1503305-20200804014505663-2037122861.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　提示：故障转移后 redis.conf 中的 slaveof 行的 master IP 会被修改，sentinel.conf 中的 sentinel monitor IP 会被修改。同时在sentinel配置文件的末尾还会有添加known-slave和known-sentinel等信息；&lt;/p&gt;
&lt;p&gt;　　修复旧master 让其重新上线&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1503305/202008/1503305-20200804015545124-758140653.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　提示：把原master启动后，它自动就成为了新主的slave；这主要是因为sentinel在故障转移时把其配置文件中的slaveof 修改成新的master地址了；&lt;/p&gt;
&lt;p&gt;　　在新master上查看主从同步信息&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/1503305/202008/1503305-20200804015951113-215611342.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　提示：在没有恢复原master时，在新master上查看主从同步信息，只能看到一个salve，启动原master后，在看就有两个slave是在线；&lt;/p&gt;
</description>
<pubDate>Mon, 03 Aug 2020 18:16:00 +0000</pubDate>
<dc:creator>Linux-1874</dc:creator>
<og:description>前文我们了解了redis的常用数据类型相关命令的使用和说明，回顾请参考https://www.cnblogs.com/qiuhom-1874/p/13419690.html；今天我们来聊一下redis</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/qiuhom-1874/p/13429776.html</dc:identifier>
</item>
<item>
<title>数据结构中的树(二叉树、二叉搜索树、AVL树) - JonPan</title>
<link>http://www.cnblogs.com/panlq/p/13430903.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/panlq/p/13430903.html</guid>
<description>&lt;blockquote readability=&quot;0&quot;&gt;
&lt;p&gt;&lt;a href=&quot;https://www.cs.usfca.edu/~galles/visualization/Algorithms.html&quot;&gt;数据结构动图展示网站&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&quot;树的概念&quot;&gt;树的概念&lt;/h3&gt;
&lt;p&gt;树（英语：tree）是一种抽象数据类型（ADT）或是实作这种抽象数据类型的数据结构，用来模拟具有树状结构性质的数据集合。它是由n（n&amp;gt;=1）个有限节点组成一个具有层次关系的集合。把它叫做“树”是因为它看起来像一棵倒挂的树，也就是说它是根朝上，而叶朝下的。它具有以下的特点：&lt;/p&gt;
&lt;ul readability=&quot;14&quot;&gt;&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;每个节点有零个或多个子节点；&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;没有父节点的节点称为根节点；&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;每一个非根节点有且只有一个父节点；&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;除了根节点外，每个子节点可以分为多个不相交的子树；&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;&lt;strong&gt;节点的度&lt;/strong&gt;：一个节点含有的子树的个数称为该节点的度；&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;&lt;strong&gt;树的度&lt;/strong&gt;：一棵树中，最大的节点的度称为树的度；&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;&lt;strong&gt;叶节点或终端节点&lt;/strong&gt;：度为零的节点；&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;&lt;strong&gt;父亲节点或父节点&lt;/strong&gt;：若一个节点含有子节点，则这个节点称为其子节点的父节点；&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;&lt;strong&gt;孩子节点或子节点&lt;/strong&gt;：一个节点含有的子树的根节点称为该节点的子节点；&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;&lt;strong&gt;兄弟节点&lt;/strong&gt;：具有相同父节点的节点互称为兄弟节点；&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;&lt;strong&gt;节点的层次&lt;/strong&gt;：从根开始定义起，根为第1层，根的子节点为第2层，以此类推；&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;&lt;strong&gt;树的高度或深度&lt;/strong&gt;：树中节点的最大层次；&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;&lt;strong&gt;堂兄弟节点&lt;/strong&gt;：父节点在同一层的节点互为堂兄弟；&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;&lt;strong&gt;节点的祖先&lt;/strong&gt;：从根到该节点所经分支上的所有节点；&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;&lt;strong&gt;子孙&lt;/strong&gt;：以某节点为根的子树中任一节点都称为该节点的子孙。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;&lt;strong&gt;森林&lt;/strong&gt;：由m（m&amp;gt;=0）棵互不相交的树的集合称为森林；&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;h3 id=&quot;二叉树&quot;&gt;二叉树&lt;/h3&gt;
&lt;p&gt;每个节点最多含有两个子树的树称为二叉树&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;平衡二叉树（AVG树）: 当且仅当任何节点的两棵子树的高度差不大于1的二叉树&lt;/li&gt;
&lt;li&gt;完全二叉树: 对于一颗二叉树，假设其深度为d(d&amp;gt;1)。除了第d层外，其它各层的节点数目均已达最大值，且第d层所有节点从左向右连续地紧密排列，这样的二叉树被称为完全二叉树，其中满二叉树的定义是所有叶节点都在最底层的完全二叉树;&lt;/li&gt;
&lt;li&gt;排序二叉树: (二叉查找数 Binary Search Tree), 也称二叉搜索树，有序二叉树，任意一个结点左边子节点的数据要比根结点的值小，右边子节点的数据要比根结点的值大。&lt;strong&gt;但是如果二叉树是单增的情况会退化成链表&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;h3 id=&quot;二叉树的遍历&quot;&gt;二叉树的遍历&lt;/h3&gt;
&lt;ol&gt;&lt;li&gt;深度优先遍历&lt;/li&gt;
&lt;/ol&gt;&lt;ul&gt;&lt;li&gt;先序遍历 preorder 在先序遍历中，我们先访问根节点，然后递归使用先序遍历访问左子树，再递归使用先序遍历访问右子树 根节点-&amp;gt;左子树-&amp;gt;右子树&lt;/li&gt;
&lt;li&gt;中序遍历 inorder 在中序遍历中，我们递归使用中序遍历访问左子树，然后访问根节点，最后再递归使用中序遍历访问右子树 左子树-&amp;gt;根节点-&amp;gt;右子树&lt;/li&gt;
&lt;li&gt;后序遍历 postorder 在后序遍历中，我们先递归使用后序遍历访问左子树和右子树，最后访问根节点 左子树-&amp;gt;右子树-&amp;gt;根节点&lt;br/&gt;&lt;img src=&quot;https://i.loli.net/2020/07/02/MSakJX4DvoEN2qF.png&quot; alt=&quot;image.png&quot; loading=&quot;lazy&quot;/&gt;)&lt;/li&gt;
&lt;/ul&gt;&lt;ol start=&quot;2&quot;&gt;&lt;li&gt;广度优先遍历（层次遍历）&lt;/li&gt;
&lt;/ol&gt;&lt;h3 id=&quot;二叉树反推&quot;&gt;二叉树反推&lt;/h3&gt;
&lt;p&gt;如果已知&lt;em&gt;&lt;strong&gt;中序和先序，或者中序和后序&lt;/strong&gt;&lt;/em&gt;，可以确定二叉树的结构&lt;/p&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;eg:&lt;br/&gt;先序：A B C D E F&lt;br/&gt;中序: C B A E D F&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;先序找根，中序定两边&lt;/strong&gt;&lt;br/&gt;先序遍历序列为ABCDEF，第一个字母是A被打印出来，就说明A是根结点的数据。&lt;br/&gt;再由中序遍历序列是CBAEDF，可以知道C和B是A的左子树的结点，&lt;br/&gt;E、D、F是A的右子树的结点&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://i.loli.net/2020/07/02/GYbw1ljUVigH9Cu.png&quot; alt=&quot;image.png&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;然后我们看先序中的C和B，它的顺序是A&lt;strong&gt;BC&lt;/strong&gt;DEF，B是在C的前面打印，所以B应该是A的左孩子，而C就只能是B的孩子，此时是左还是右孩子还不确定。再看中序序列是&lt;strong&gt;CB&lt;/strong&gt;AEDF，C是在B的前面打印，这就说明C是B的左孩子，否则就是右孩子了&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://i.loli.net/2020/07/02/EC51AthuW98Ymqf.png&quot; alt=&quot;image.png&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;再看先序中的E、D、F，它的顺序是ABC&lt;strong&gt;DEF&lt;/strong&gt;，那就意味着D是A结点的右孩子，E和F是D的子孙，注意，它们中有一个不一定是孩子，还有可能是孙子的。再来看中序序列是CBA&lt;strong&gt;EDF&lt;/strong&gt;，由于E在D的左侧，而F在右侧，所以可以确定E是D的左孩子，F是D的右孩子&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://i.loli.net/2020/07/02/vOMSEj2QyIdZAhb.png&quot; alt=&quot;image.png&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;注：如果已经先序和后序无法判断二叉树结构&lt;/p&gt;
&lt;p&gt;先序序列:ABC&lt;/p&gt;
&lt;p&gt;后序序列:CBA&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;我们可以确定A一定是根结点，但接下来，我们无法知道，哪个结点是左子树，哪个是右子树&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://i.loli.net/2020/07/02/UDL2t8PQ9hEsYNZ.png&quot; alt=&quot;image.png&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h3 id=&quot;二叉查找树二叉搜索树&quot;&gt;二叉查找树(二叉搜索树)&lt;/h3&gt;
&lt;p&gt;节点的左子树只包含小于当前节点的数。&lt;/p&gt;
&lt;p&gt;节点的右子树只包含大于当前节点的数。&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;所有左子树和右子树自身必须也是二叉搜索树&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/Panlq/NoteBook/blob/master/tree/binary-search-tree.py&quot;&gt;Python实现二叉查找树&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;参考以下两篇文章（&lt;strong&gt;最好是自己画图容易理解&lt;/strong&gt;）:&lt;/p&gt;
&lt;h3 id=&quot;二叉平衡树&quot;&gt;二叉平衡树&lt;/h3&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/Panlq/NoteBook/blob/master/tree/AVL-tree.py&quot;&gt;Python实现平衡二叉树&lt;/a&gt; 删除和添加调整的是最小不平衡子树&lt;/p&gt;
&lt;p&gt;平衡二叉树 （Height-Balanced Binary Search Tree） 是一种二叉排序树，&lt;/p&gt;
&lt;p&gt;其中&lt;strong&gt;每一个结点的左子树和右子树的高度差不超过1（小于等于1）&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;二叉树的平衡因子 （Balance Factor） 等于该结点的左子树深度减去右子树深度的值称为平衡因子。平衡因子只可能是[－1，0，1]。距离插入结点最近的，且平衡因子的绝对值大于1的结点为根的子树，称为最小不平衡子树&lt;/p&gt;
&lt;p&gt;平衡二叉树就是二叉树的构建过程中，每当插入一个结点，看是不是因为树的插入破坏了树的平衡性，若是，则找出最小不平衡树。在保持二叉树特性的前提下，&lt;strong&gt;调整最小不平衡子树中各个结点之间的链接关系&lt;/strong&gt;，进行相应的旋转，使之成为新的平衡子树。简记为： &lt;strong&gt;步步调整，步步平衡&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;参考以下两篇文章（&lt;strong&gt;最好是自己画图&lt;/strong&gt;）:&lt;/p&gt;
&lt;blockquote readability=&quot;7&quot;&gt;
&lt;p&gt;&lt;strong&gt;注：&lt;/strong&gt;第一篇文章中针对左右失衡和右左失衡的处理图片和代码中有误，但是主要是看个人理解，作者可以只对根节点进行失衡处理，而我这边是按照第二篇文章说的，&lt;strong&gt;调整最小不平衡子树&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;对于其中添加元素的递归代码的理解:&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/778496/202008/778496-20200804004427859-1887224367.jpg&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h3 id=&quot;霍夫曼树&quot;&gt;霍夫曼树&lt;/h3&gt;
&lt;p&gt;（用于信息编码）：带权路径最短的二叉树称为哈夫曼树或最优二叉树；&lt;br/&gt;应用: 压缩文件&lt;/p&gt;
&lt;h3 id=&quot;b树b-tree&quot;&gt;B树(B-Tree)&lt;/h3&gt;
&lt;p&gt;一种对读写操作进行优化的自平衡的二叉查找树，能够保持数据有序，拥有多余两个子树。B树是多路平衡查找树，2阶B树才是平衡二叉树&lt;br/&gt;应用: 数据库存储&lt;/p&gt;
&lt;p&gt;M阶的Btree的几个重要特性：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;节点最多含有m棵字树(指针), m-1个关键字(存的数据，空间)（m &amp;gt; 2）&lt;/li&gt;
&lt;li&gt;除根节点和叶子节点外，其他每个节点至少有ceil（m / 2）个子节点，（ceil为上取整）&lt;/li&gt;
&lt;li&gt;若根节点不是叶子节点，则至少有两棵子树&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;M阶: 这个由磁盘的页大小决定，页内存是4KB, 好处是一次性取数据就可以取出这个节点即这个页数据，不会造成IO读取的浪费。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://upload-images.jianshu.io/upload_images/3575048-49b083c1a49cd6de.png?imageMogr2/auto-orient/strip%7CimageView2/2/format/webp&quot; alt=&quot;img&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;h3 id=&quot;btree&quot;&gt;B+Tree&lt;/h3&gt;
&lt;ol&gt;&lt;li&gt;每个节点最多有m个子节点&lt;/li&gt;
&lt;li&gt;除根节点外，每个节点至少有m/2个子节点，注意如果结果除不尽，就取上蒸，如 5/2=3&lt;/li&gt;
&lt;li&gt;根节点要么是空，要么是独根，否则至少有2个子节点&lt;/li&gt;
&lt;li&gt;有k个子节点的节点必有k个关键字&lt;/li&gt;
&lt;li&gt;叶节点的高度一致&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;&lt;img src=&quot;https://i.loli.net/2020/07/02/OIiknK2oALMXWcT.png&quot; alt=&quot;image.png&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://upload-images.jianshu.io/upload_images/3575048-9e8f1e7ab7a3e729.png?imageMogr2/auto-orient/strip%7CimageView2/2/format/webp&quot; alt=&quot;img&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;适合大数据的磁盘索引，经典的MySQL，所有的数据都存在叶子节点，其他上层节点都是索引，增加了系统的稳定性以及遍历查找效率。叶子节点之间是双向指针，这一点就有利于范围查找。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;MyISAM存储引擎的数据结构（非聚集）&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;索引文件和数据文件是分离的，非聚集（非聚族）&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://i.loli.net/2020/07/02/Kuxp6tzA3qsP9EC.png&quot; alt=&quot;image.png&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;.MYD 存储数据的文件&lt;/p&gt;
&lt;p&gt;.MYI 存储索引的文件&lt;/p&gt;
&lt;p&gt;.FRM 表结构文件，管理索引和数据的框架&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;InnoDB索引的实现（聚集）&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;表数据本身就是按B+Tree组织的一个索引结构文件&lt;/li&gt;
&lt;li&gt;聚集索引-叶子节点包含了完整的数据记录，&lt;strong&gt;索引跟数据合并，MySQL默认节点大小为16KB，所以说高度为3的B+树就能够存储千万级别的数据。&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;为什么InnoDB表必须有主键，并且推荐使用整形的自增主键？
&lt;ul&gt;&lt;li&gt;整形存储占用比较少，且比较容易，如果是uuid字符串还需要进行转换且占用空间大&lt;/li&gt;
&lt;li&gt;使用自增是为了避免二叉树的频繁自平衡分裂，自增主键，只需要每次都忘后面增加即可，不会造成大范围的性能开销&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;为什么非主键索引结构叶子节点存储的是主键值？（一直性）&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;img src=&quot;https://i.loli.net/2020/07/02/CVhNTp9cRgSrsGa.png&quot; alt=&quot;image.png&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;联合索引的底层存储结构&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://i.loli.net/2020/07/02/cDp2sUWAaknjVCB.png&quot; alt=&quot;image.png&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;ol readability=&quot;0&quot;&gt;&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;&lt;a href=&quot;https://www.bilibili.com/video/BV1aE41117sk?p=5&quot;&gt;B站-100分钟讲透MySQL索引底层原理&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&quot;https://www.bilibili.com/video/BV1AE41117R5?p=8&quot;&gt;MySQL底层索引算法&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;&lt;a href=&quot;https://draveness.me/whys-the-design-mysql-b-plus-tree/&quot;&gt;为什么 MySQL 使用 B+ 树&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;&lt;a href=&quot;https://www.jianshu.com/p/486a514b0ded&quot;&gt;MYSQL-B+TREE索引原理-详细解释了SQL语句的执行过程&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;&lt;h3 id=&quot;常见树的应用场景&quot;&gt;常见树的应用场景&lt;/h3&gt;
&lt;ol&gt;&lt;li&gt;xml，html等，那么编写这些东西的解析器的时候，不可避免用到树&lt;/li&gt;
&lt;li&gt;路由协议就是使用了树的算法&lt;/li&gt;
&lt;li&gt;mysql数据库索引&lt;/li&gt;
&lt;li&gt;文件系统的目录结构&lt;/li&gt;
&lt;li&gt;所以很多经典的AI算法其实都是树搜索，此外机器学习中的decision tree也是树结构&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;&lt;img src=&quot;https://i.loli.net/2020/07/02/t8PM4ZyIi51EFuh.png&quot; alt=&quot;image.png&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
</description>
<pubDate>Mon, 03 Aug 2020 16:41:00 +0000</pubDate>
<dc:creator>JonPan</dc:creator>
<og:description>数据结构动图展示网站 树的概念 树（英语：tree）是一种抽象数据类型（ADT）或是实作这种抽象数据类型的数据结构，用来模拟具有树状结构性质的数据集合。它是由n（n&amp;amp;gt;=1）个有限节点组成</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/panlq/p/13430903.html</dc:identifier>
</item>
<item>
<title>可能是Asp.net Core On host、 docker、kubernetes(K8s) 配置读取的最佳实践 - 乔达摩</title>
<link>http://www.cnblogs.com/xiaxiaolu/p/13430776.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/xiaxiaolu/p/13430776.html</guid>
<description>&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/641760/202008/641760-20200803235106453-1133624102.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;

&lt;p&gt;为了不违反广告法，我竭尽全力，不过“最佳实践”确是标题党无疑，如果硬要说的话 只能是&lt;u&gt;个人&lt;/u&gt;最佳实践。&lt;/p&gt;

&lt;p&gt;​ 可能很多新手都会遇到同样的问题：我要我的Asp.net Core 应用传统方式直接部署(host)，docker部署(docker-compose)，kubernetes(以下称k8s)下部署，都用统一的方式读取配置，怎么实现呢？。&lt;/p&gt;
&lt;p&gt;​ 大家知道，我们默认平时配置文件以&lt;code&gt;appsettings.json&lt;/code&gt; 、&lt;code&gt;appsettings.{EnvironmentName}.json&lt;/code&gt; 形式存在，这样在host方式下面没有问题，但在docker下，如果直接把配置打包到镜像，那每次改一下下配置就需要重新打包，那成本太大了。另外在k8s下面又有Secret、ConfigMap等多种方式管理配置，如何把多种配置存储和读取，有机结合、同一份代码统一管理使用，是我们今天的主题。&lt;/p&gt;
&lt;p&gt;​ 下面我用一个Api网关Ocelot作为示例（&lt;a href=&quot;https://github.com/gebiWangshushu/Hei.Ocelot.ApiGateway&quot;&gt;demo&lt;/a&gt;），讲讲我处理的方式，希望能给大家带来一定启发。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;注：&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;其实不改为yml也可以的！！&lt;/p&gt;
&lt;p&gt;主要考虑到后面在docker、k8s等里面，更好管理，比如yaml的注释和json的注释语法不一致等等问题；&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;比如我原来的appsettings.json长这样：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;{
  &quot;Logging&quot;: {
    &quot;LogLevel&quot;: {
      &quot;Default&quot;: &quot;Information&quot;,
      &quot;Microsoft&quot;: &quot;Warning&quot;,
      &quot;Microsoft.Hosting.Lifetime&quot;: &quot;Information&quot;
    }
  },
  &quot;AllowedHosts&quot;: &quot;*&quot;,
  &quot;AddAdministration&quot;: {
    &quot;Path&quot;: &quot;/administration&quot;,
    &quot;IdentityServer&quot;: {
      &quot;Authority&quot;: &quot;http://172.16.3.117:5100&quot;, 
      &quot;ApiName&quot;: &quot;ocelot&quot;,
      &quot;RequireHttpsMetadata&quot;: false,
      &quot;ApiSecret&quot;: &quot;secret&quot;
    }
  }
}


&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;改成 appsettings.yml&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;Logging:
  LogLevel:
    Default: Information
    Microsoft: Warning
    Microsoft.Hosting.Lifetime: Information
AllowedHosts: '*'
AddAdministration:
  Path: /administration
  IdentityServer:
    Authority: 'http://172.16.3.117:5100'
    ApiName: ocelot
    RequireHttpsMetadata: false
    ApiSecret: secret
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;是不是看起来简单清晰了很多，其实我现在越来越喜欢用yml了&lt;/p&gt;
&lt;p&gt;既然配置源的格式变了，那读取配置的方法也肯定变了，起码config.AddJsonFile(“xx.json”) 要改为 config.AddYamlFile(“xx.yml”)&lt;/p&gt;
&lt;p&gt;新增引用的扩展：&lt;code&gt;NetEscapades.Configuration.Yaml&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;加载配置文件改写为：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-c#&quot;&gt; .AddYamlFile(&quot;appsettings.yml&quot;, optional: false, reloadOnChange: true)
 .AddYamlFile($&quot;appsettings.{env.EnvironmentName}.yml&quot;, optional: true, reloadOnChange: true)
&lt;/code&gt;
&lt;/pre&gt;

&lt;p&gt;“但在docker下，如果直接把配置打包到镜像，那每次改一下下配置就需要重新打包，那成本太大了”&lt;/p&gt;
&lt;p&gt;我前面提出了这个问题，如想不重新打包，Volume(挂载)就好了。&lt;/p&gt;
&lt;p&gt;把你的配置文件放到&lt;code&gt;/home/heidemo/config&lt;/code&gt;目录后，比如我们什么的示例配置文件： appsettings.yml&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;docker run --rm=true -v /home/heidemo/config:/config   gebiwangshushu/hei-ocelot-apigateway:1.0
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;这样就可以随性更新/home/heidemo/config下的配置信息而不需要每次都重新build镜像了，这样是支持热更新的，当然如果你修改的那个配置是需要重启程序才可以加载的，那还是要用docker-compose 重启下对应服务的；&lt;/p&gt;

&lt;p&gt;我们知道 Docker是 官方编排（Orchestration）项目之一，如果我们在Docker环境下挂载配置的话，那在docker-compose下面的配置也是挂载的，我们来看下我们掐头去尾后的 &lt;code&gt;docker-compose.yml&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;version: '3.4'

services:
  hei.ocelot.apigateway:
    ...
    
    volumes:
      - /home/heidemo/config:/app/config
    
    ...
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;没错，docker-compose 额挂载就这么定义，这样可以实现跟Docker一样的挂载效果;&lt;/p&gt;
&lt;p&gt;大家可以用以上配置 clone我的&lt;a href=&quot;https://github.com/gebiWangshushu/Hei.Ocelot.ApiGateway&quot;&gt;demo&lt;/a&gt;，然后 &lt;code&gt;docker-compose up&lt;/code&gt; 一下，看看效果；&lt;/p&gt;

&lt;p&gt;前面的docker、docker-compose 的方式还是非常容易理解的，就是挂载；那我们在k8s下面运行的时候，它的容器实例是动态的运行到集群的各台机器上的，那如果我们我们只用文件挂载很明显就不满足要求了，我们来看看怎么实现。&lt;/p&gt;
&lt;p&gt;先准备一个configMap，&lt;code&gt;hei-ocelot-config.yml&lt;/code&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;apiVersion: v1
kind: ConfigMap
metadata:
  name: hei-ocelot-apigateway
  namespace: dotnetcore
data:
  appsettings.yml: |
    Logging:
      LogLevel:
        Default: Information
        Microsoft: Warning
        Microsoft.Hosting.Lifetime: Information
    AllowedHosts: '*'
    AddAdministration:
      Path: /administration
      IdentityServer:
         Authority: 'http://172.16.1.30:31100' #这里的授权中心可以配置你自己的
        ApiName: ocelot
        RequireHttpsMetadata: false
        ApiSecret: secret
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;完整请看&lt;a href=&quot;https://github.com/gebiWangshushu/Hei.Ocelot.ApiGateway/blob/dev/deploy.yml&quot;&gt;这里&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;大家可以看到，我们的data节点是跟我们程序里面的&lt;code&gt;appsettings.json&lt;/code&gt;一样一样的，这也是我们比较喜欢不再用json的原因。&lt;/p&gt;
&lt;p&gt;创建configMap：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;kubectl apply -f hei-ocelot-config.yml
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;查看configMap：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;kubectl describe configmaps hei-ocelot-apigateway -n dotnetcore
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/641760/202008/641760-20200803000056540-844409082.png&quot; alt=&quot;1596101753461&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;使用configMap:&lt;/p&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;这里是使用示例，在我的demo根目录下面完整配置deploy.yml 是可以直接部署的。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;pre&gt;
&lt;code&gt;apiVersion: apps/v1
kind: Deployment
metadata:
 name: hei-ocelot-apigateway 
 namespace: dotnetcore
spec:
 replicas: 1
 selector:
  matchLabels:
   app: hei-ocelot-apigateway 
 template:
  metadata:
   labels:
    app: hei-ocelot-apigateway 
  spec:
   containers:
    - name: hei-ocelot-apigateway 
      image: gebiwangshushu/hei-ocelot-apigateway:1.1
      ports:
       - containerPort: 80
      volumeMounts:
       - name: hei-ocelot-apigateway
         mountPath: &quot;/app/config&quot;
         readOnly: true
   volumes:
    - name: hei-ocelot-apigateway
      configMap:
       name: hei-ocelot-apigateway
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;可以看到我们在k8s下面也是用volumes的方式使用我们的configMap的，其中挂载目录volumeMounts:mountPath是&quot;/app/config&quot;，我们进入运行中pod看下配置：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;kubectl exec -it hei-ocelot-apigateway-795495f7c8-vpmhb sh -n dotnetcore

cd /app/config 
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;我们可以看到我们的pod里面的/app/config ，确确实实有我们要的配置；&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/641760/202008/641760-20200803000055922-515957027.png&quot; alt=&quot;1596383131953&quot; loading=&quot;lazy&quot;/&gt;&lt;/p&gt;
&lt;p&gt;这里因为我们是volumes 的方式的，大家可以试着改下上面的configMap-- hei-ocelot-config.yml 再重新apply 一下，会看到这里的配置是几乎是即时更新的（有一点点延迟）；&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;PS：&lt;/strong&gt;有一个问题有些在startup使用的配置，即时更新了也需要重启下应用，这个我暂时还没想到什么办法好办法，各位老哥有什么思路的可以直接甩我一脸~&lt;/p&gt;

&lt;p&gt;其实写完我觉得也有点怪怪，说新手引导吧，不够保姆式、说经验分享，不够精简，下次我定好好想，认真写好点；&lt;/p&gt;
&lt;p&gt;然后我的主题，其实思考过同样问题的读者，全文就一句：volumes挂载配置做到各种环境下的配置统一；&lt;/p&gt;
&lt;p&gt;最后，&lt;strong&gt;我抛出了一个问题&lt;/strong&gt;：On K8s的时候， 程序启动使用的配置，如何在配置文件更新的情况后重启程序应用新配置（或者叫热加载配置？当然这里不是指配置文件的reloadOnChange=true）;&lt;/p&gt;
&lt;p&gt;github:&lt;a href=&quot;https://github.com/gebiWangshushu/Hei.Ocelot.ApiGateway&quot;&gt;https://github.com/gebiWangshushu/Hei.Ocelot.ApiGateway&lt;/a&gt;&lt;/p&gt;
</description>
<pubDate>Mon, 03 Aug 2020 15:56:00 +0000</pubDate>
<dc:creator>乔达摩</dc:creator>
<og:description>写在前面 为了不违反广告法，我竭尽全力，不过“最佳实践”确是标题党无疑，如果硬要说的话 只能是个人最佳实践。 问题引出 ​ 可能很多新手都会遇到同样的问题：我要我的Asp.net Core 应用传统方</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnblogs.com/xiaxiaolu/p/13430776.html</dc:identifier>
</item>
</channel>
</rss>