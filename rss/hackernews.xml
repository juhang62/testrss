<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="css/feed.xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/" xmlns:og="http://ogp.me/ns#">
<channel>
<atom:link rel="self" href="http://192.168.1.4/fivefilters/makefulltextfeed.php?url=hnrss.org%2Fnewest%3Fpoints%3D200&amp;max=10&amp;links=preserve&amp;exc=" />
<atom:link rel="alternate" title="Source URL" href="http://hnrss.org/newest?points=200" />
<atom:link rel="related" title="Subscribe to feed" href="http://www.subtome.com/#/subscribe?feeds=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dhnrss.org%252Fnewest%253Fpoints%253D200%26max%3D10%26links%3Dpreserve%26exc%3D&amp;back=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dhnrss.org%252Fnewest%253Fpoints%253D200%26max%3D10%26links%3Dpreserve%26exc%3D" />
<title>Hacker News: Newest</title>
<link>https://news.ycombinator.com/newest</link>
<description>Hacker News RSS</description>
<item>
<title>Palo Alto Networks sends cease-and-desist letter to take down review videos</title>
<link>https://orca.security/cybersecurity-community-transparency/</link>
<guid isPermaLink="true" >https://orca.security/cybersecurity-community-transparency/</guid>
<description>&lt;p&gt;&lt;em&gt;Abstract: A few weeks ago, Orca Security published a comparison between the Orca Cloud Security Platform and a few other cloud security tools—including a &lt;a href=&quot;https://orca.security/prisma-cloud-security/&quot;&gt;comparison with Palo Alto Networks Prisma&lt;/a&gt;. In response, Palo Alto Networks sent a &lt;a href=&quot;https://orca.security/wp-content/uploads/PANW-Legal-Letter-Cease-Desist.pdf&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;cease and desist letter&lt;/a&gt;, demanding the comparison be removed immediately. Here is my response. I urge you to see &lt;a href=&quot;https://www.youtube.com/playlist?list=PLDnqJTEi6ynvsGkSJHYeEmhz6_NfzKgbf&quot;&gt;the videos in question&lt;/a&gt; and if you, like me, believe the cybersecurity community deserves transparency and vendors shouldn’t be allowed to prevent publishing reviews or benchmarks via legal threats, then please share this post. You can also leave your own comments down below.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;To: Palo Alto Networks&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;CC: The cybersecurity community&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Subject: The Cybersecurity community demands transparency, not legal threats &lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Security has always been about transparency. The concept of security by obscurity was frowned upon as early as 1851—even before the invention of electricity—when &lt;a href=&quot;https://en.wikipedia.org/wiki/Alfred_Charles_Hobbs&quot;&gt;Alfred Hobbs&lt;/a&gt;, a Massachusetts-based locksmith, demonstrated how then state-of-the-art locks could be picked. He explained that exposing the information would make the public more secure, as rogues already knew the deficiencies. The public needed to be educated, and he’d pursue better locks. Today’s locks are more advanced, but the principle is the same.&lt;/p&gt;
&lt;p&gt;The cybersecurity community preaches about many products. All come with their own advantages and disadvantages, capabilities, and limitations. I believe that the only way practitioners can choose the tools that fit their environments best is by viewing factual evidence—not by relying solely on marketing materials. This is why we launched our &lt;a href=&quot;https://orca.security/cloud-security-solutions/&quot;&gt;Cloud Security Punch-Out! Series&lt;/a&gt;, where we deploy a few tools—including Orca Security—on the exact same environment and share the results with viewers who deserve to see them. I urge you to take &lt;a href=&quot;https://orca.security/prisma-cloud-security/&quot;&gt;a look at the one we did with Palo Alto Networks;&lt;/a&gt; as you’ll see we don’t hide those areas where Palo Alto Networks shines.&lt;/p&gt;
&lt;p&gt;Unfortunately, Palo Alto Networks is now trying to use legal threats to prevent us from publishing these video reviews. In &lt;a href=&quot;https://orca.security/wp-content/uploads/PANW-Legal-Letter-Cease-Desist.pdf&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;its letter&lt;/a&gt;, Palo Alto Networks does not point to any factual inaccuracies in the reviews of its products’ performance. Instead, it premises its threats on flimsy, boilerplate contract terms that prohibit reviews and comparisons of its products and hollow trademark allegations purporting that Palo Alto Networks is sponsoring the videos.&lt;/p&gt;
&lt;p&gt;It’s outrageous that the world’s largest cybersecurity vendor (its products being used by over 65,000 organizations according to its website), believes that its users aren’t entitled to share any benchmark or performance comparison of its products. According to its boilerplate contract terms that prohibit “disclosing, publishing, or otherwise making publicly available any benchmark, performance, or comparison tests” of its products, you’re in violation even if you publish the results of an internal comparison of Palo Alto Networks against other products as part of your procurement process. The same goes for the hundreds of Palo Alto Networks reviews on various sites that include G2 Crowd, Capterra, and Gartner Peer Insights. It means that only benchmarks approved by Palo Alto Networks can be published.&lt;/p&gt;
&lt;p&gt;Palo Alto Networks appears oblivious to the fact that the New York Attorney General’s office &lt;a href=&quot;https://www.leagle.com/decision/2003579195misc2d3841519&quot;&gt;sued and won an injunction&lt;/a&gt; against McAfee from enforcing its contractual restrictions against publishing reviews or comparisons of its products without its consent more than 17 years ago. In enacting the &lt;a href=&quot;https://www.law.cornell.edu/uscode/text/15/45b&quot;&gt;Consumer Review Fairness Act&lt;/a&gt;, Congress has also prohibited businesses from including contract terms that prohibit consumers from reviewing products or services they purchase.&lt;/p&gt;
&lt;blockquote readability=&quot;12&quot;&gt;
&lt;p&gt;Palo Alto Networks, do you think your products are flawless or that the bad guys will follow along, not openly talking about products’ deficiencies? If the answer is no to both, then why resort to legal threats to remove such benchmarks and comparisons? I refuse to accept a world where any vendor believes it has the right to prevent the free flow of information, and control which product reviews are made publicly available.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;I urge you to make your products better and focus your marketing efforts on demonstrating that, rather than throwing away money on ill-conceived gag efforts. Such action doesn’t benefit anyone. If you believe we missed something in our test, then tell us so we can make adjustments—we’ll happily integrate your comments and suggestions.&lt;/p&gt;
&lt;p&gt;We could contract an objective third party to conduct additional tests. You could conduct your own tests with Palo Alto Networks and Orca Security’s products, then let the audience see and decide for themselves. All such actions would be far more beneficial to the industry, permitting both companies to learn and improve our products for the sake of customers.&lt;/p&gt;
&lt;p&gt;As we all recently learned too well, &lt;a href=&quot;https://www.contagionlive.com/news/sunlight-inactivates-the-airborne-virus-that-causes-covid19&quot;&gt;sunlight is the best disinfectant&lt;/a&gt;. The cybersecurity community deserves better than a vendor’s lack of transparency while wielding dubious legal methods. Palo Alto Networks is the worlds’ largest cybersecurity vendor; with great power comes great responsibility. Your products are great—but nothing is perfect, and the public should have free access to all of the facts.&lt;/p&gt;
&lt;p&gt;Yours faithfully,&lt;br/&gt;Avi Shua, CEO and Co-Founder&lt;br/&gt;Orca Security&lt;/p&gt;
</description>
<pubDate>Tue, 20 Oct 2020 17:31:11 +0000</pubDate>
<dc:creator>bonfire</dc:creator>
<og:type>article</og:type>
<og:title>The Cybersecurity Community Demands Transparency, Not Legal Threats | Orca Security</og:title>
<og:description>In response to our Cloud Security Punch-Out! videos, Palo Alto Networks sent this cease and desist letter, demanding the comparison be removed. Here is my response.</og:description>
<og:url>https://orca.security/cybersecurity-community-transparency/</og:url>
<og:image>https://orca.security/wp-content/uploads/PaloAlto.png</og:image>
<dc:language>en-US</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://orca.security/cybersecurity-community-transparency/</dc:identifier>
</item>
<item>
<title>My Eight-Year Quest to Digitize 45 Videotapes</title>
<link>https://mtlynch.io/digitizing-1/#</link>
<guid isPermaLink="true" >https://mtlynch.io/digitizing-1/#</guid>
<description>&lt;p&gt;For the last eight years, I’ve carried around this box of videotapes through four different apartments and one house. They’re family home videos from my childhood.&lt;/p&gt;
&lt;div class=&quot;img&quot;&gt;&lt;a href=&quot;https://mtlynch.io/digitizing-1/videotapes.jpg&quot;&gt;&lt;img sizes=&quot;(min-width: 768px) 500px, 98vw&quot; srcset=&quot;/digitizing-1/videotapes_hu4d6a8eb758ebd6e50ef8eab36994793b_250232_300x0_resize_q90_lanczos.jpg 300w, /digitizing-1/videotapes_hu4d6a8eb758ebd6e50ef8eab36994793b_250232_600x0_resize_q90_lanczos.jpg 600w, /digitizing-1/videotapes_hu4d6a8eb758ebd6e50ef8eab36994793b_250232_800x0_resize_q90_lanczos.jpg 800w, /digitizing-1/videotapes_hu4d6a8eb758ebd6e50ef8eab36994793b_250232_1200x0_resize_q90_lanczos.jpg 1200w, /digitizing-1/videotapes.jpg 1200w&quot; src=&quot;https://mtlynch.io/digitizing-1/videotapes.jpg&quot; alt=&quot;All of my family's old home videos&quot; loading=&quot;lazy&quot;/&gt;&lt;/a&gt;&lt;/div&gt;
&lt;p&gt;After 600+ hours of work, I finally digitized and organized them well enough to throw away the original tapes. Here’s what the footage looks like now:&lt;/p&gt;
&lt;div class=&quot;img-container&quot;&gt;
&lt;div class=&quot;img&quot;&gt;&lt;a href=&quot;https://mtlynch.io/digitizing-1/mediagoblin-home.png&quot;&gt;&lt;img sizes=&quot;(min-width: 768px) 440px, 98vw&quot; srcset=&quot; /digitizing-1/mediagoblin-home_hu1c0530097ea46c2a062d8cdcdf1be994_681277_300x0_resize_lanczos_2.png 300w, /digitizing-1/mediagoblin-home_hu1c0530097ea46c2a062d8cdcdf1be994_681277_600x0_resize_lanczos_2.png 600w, /digitizing-1/mediagoblin-home_hu1c0530097ea46c2a062d8cdcdf1be994_681277_800x0_resize_lanczos_2.png 800w, /digitizing-1/mediagoblin-home.png 1000w&quot; src=&quot;https://mtlynch.io/digitizing-1/mediagoblin-home.png&quot; alt=&quot;MediaGoblin browse screen&quot; loading=&quot;lazy&quot;/&gt;&lt;/a&gt;&lt;/div&gt;
&lt;div class=&quot;img&quot;&gt;&lt;a href=&quot;https://mtlynch.io/digitizing-1/mediagoblin-single-video.jpg&quot;&gt;&lt;img sizes=&quot;(min-width: 768px) 413px, 98vw&quot; srcset=&quot; /digitizing-1/mediagoblin-single-video_hu47ebb6bba750fc5f935679e2dbc60862_101011_300x0_resize_q90_lanczos.jpg 300w, /digitizing-1/mediagoblin-single-video_hu47ebb6bba750fc5f935679e2dbc60862_101011_600x0_resize_q90_lanczos.jpg 600w, /digitizing-1/mediagoblin-single-video_hu47ebb6bba750fc5f935679e2dbc60862_101011_800x0_resize_q90_lanczos.jpg 800w, /digitizing-1/mediagoblin-single-video.jpg 1016w&quot; src=&quot;https://mtlynch.io/digitizing-1/mediagoblin-single-video.jpg&quot; alt=&quot;Screenshot of MediaGoblin displaying a video&quot; loading=&quot;lazy&quot;/&gt;&lt;/a&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;All of my home videos, digitized and watchable from a private media sharing server&lt;/p&gt;
&lt;p&gt;There are 513 separate clips, each with a title, description, a recording date, tags for everyone in the video, and everyone’s ages at the time of the recording. I host everything on a private media-sharing website that only my family can access, and it costs less than $1 per month to keep it running.&lt;/p&gt;
&lt;p&gt;This post explains how I did it, why it took me eight years, and how you can achieve the same thing with slightly less effort.&lt;/p&gt;
&lt;h2 id=&quot;my-naïve-first-try&quot;&gt;My naïve first try &lt;a href=&quot;https://mtlynch.io/digitizing-1/#my-naïve-first-try&quot; class=&quot;hanchor&quot; arialabel=&quot;Anchor&quot;&gt;🔗︎&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Around 2010, my mom bought some sort of VHS to DVD converter and ran all of our home videos through it.&lt;/p&gt;
&lt;a href=&quot;https://mtlynch.io/digitizing-1/original-dvds.jpg&quot;&gt;&lt;img sizes=&quot;(min-width: 768px) 600px, 98vw&quot; srcset=&quot; /digitizing-1/original-dvds_hub861c26b54005ce9f42e509c609132f6_272742_300x0_resize_q90_lanczos.jpg 300w, /digitizing-1/original-dvds_hub861c26b54005ce9f42e509c609132f6_272742_600x0_resize_q90_lanczos.jpg 600w, /digitizing-1/original-dvds_hub861c26b54005ce9f42e509c609132f6_272742_800x0_resize_q90_lanczos.jpg 800w, /digitizing-1/original-dvds_hub861c26b54005ce9f42e509c609132f6_272742_1200x0_resize_q90_lanczos.jpg 1200w, /digitizing-1/original-dvds.jpg 1500w&quot; src=&quot;https://mtlynch.io/digitizing-1/original-dvds.jpg&quot; alt=&quot;Photo of rewritable DVDs labeled by letter&quot; loading=&quot;lazy&quot;/&gt;&lt;/a&gt;
&lt;p&gt;The original DVD copies of the tapes my mom made (I’m not sure what happened to the missing letters)&lt;/p&gt;
&lt;p&gt;The problem was that there was only one set of DVDs. Everyone in my family lived in a different state, which made it inconvenient to pass discs around.&lt;/p&gt;
&lt;p&gt;In 2012, my sister gave me the DVDs. I ripped them to video files and threw them all up on cloud storage. Problem solved!&lt;/p&gt;
&lt;a href=&quot;https://mtlynch.io/digitizing-1/gcs-files.jpg&quot;&gt;&lt;img class=&quot;img-border&quot; sizes=&quot;(min-width: 768px) 900px, 98vw&quot; srcset=&quot; /digitizing-1/gcs-files_hu34511ef68f5f01c6eb6cd745f9d5b88b_97488_300x0_resize_q90_lanczos.jpg 300w, /digitizing-1/gcs-files_hu34511ef68f5f01c6eb6cd745f9d5b88b_97488_600x0_resize_q90_lanczos.jpg 600w, /digitizing-1/gcs-files_hu34511ef68f5f01c6eb6cd745f9d5b88b_97488_800x0_resize_q90_lanczos.jpg 800w, /digitizing-1/gcs-files_hu34511ef68f5f01c6eb6cd745f9d5b88b_97488_1200x0_resize_q90_lanczos.jpg 1200w, /digitizing-1/gcs-files.jpg 1414w&quot; src=&quot;https://mtlynch.io/digitizing-1/gcs-files.jpg&quot; alt=&quot;Screenshot of my converted DVD files on Google Cloud Storage&quot; loading=&quot;lazy&quot;/&gt;&lt;/a&gt;
&lt;p&gt;Sharing DVD rips of my family’s home videos on Google Cloud Storage&lt;/p&gt;
&lt;p&gt;A few weeks later, I asked if anyone had watched the tapes. Nobody had. I hadn’t either. In the age of YouTube, it seemed so boring to download a 3-hour mystery file in search of interesting footage.&lt;/p&gt;
&lt;p&gt;The only one excited was my mom. “Okay, great,” she said, “Now, can I &lt;em&gt;finally&lt;/em&gt; throw out all these tapes?”&lt;/p&gt;
&lt;p&gt;Uh oh. That was a scary question. What if there were tapes that we missed? What if we could digitize at a higher quality? What if there was interesting information on the VHS tape labels?&lt;/p&gt;
&lt;p&gt;I’d never feel comfortable throwing away the original tapes until I was confident that we had a comprehensive capture of all the videos at the highest possible quality. That meant doing the work myself.&lt;/p&gt;
&lt;p&gt;Little did I know what I was getting myself into.&lt;/p&gt;
&lt;h2 id=&quot;that-doesnt-sound-so-hard&quot;&gt;That doesn’t sound so hard &lt;a href=&quot;https://mtlynch.io/digitizing-1/#that-doesnt-sound-so-hard&quot; class=&quot;hanchor&quot; arialabel=&quot;Anchor&quot;&gt;🔗︎&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;If you’re wondering why this took me eight years and hundreds of hours, I don’t blame you. I thought it would be an easy project too.&lt;/p&gt;
&lt;p&gt;Here’s what the digitization process looks like from start to finish:&lt;/p&gt;
&lt;div class=&quot;img&quot;&gt;&lt;a href=&quot;https://mtlynch.io/digitizing-1/digitizing-process.jpg&quot;&gt;&lt;img class=&quot;img-border&quot; sizes=&quot;(min-width: 768px) 800px, 98vw&quot; srcset=&quot; /digitizing-1/digitizing-process_huba4d6be0932b8ab7d91e0131ca5652ef_164784_300x0_resize_q90_lanczos.jpg 300w, /digitizing-1/digitizing-process_huba4d6be0932b8ab7d91e0131ca5652ef_164784_600x0_resize_q90_lanczos.jpg 600w, /digitizing-1/digitizing-process_huba4d6be0932b8ab7d91e0131ca5652ef_164784_800x0_resize_q90_lanczos.jpg 800w, /digitizing-1/digitizing-process_huba4d6be0932b8ab7d91e0131ca5652ef_164784_1200x0_resize_q90_lanczos.jpg 1200w, /digitizing-1/digitizing-process.jpg 1200w&quot; src=&quot;https://mtlynch.io/digitizing-1/digitizing-process.jpg&quot; alt=&quot;TODO&quot; loading=&quot;lazy&quot;/&gt;&lt;/a&gt;&lt;/div&gt;
&lt;p&gt;Or rather, that’s what the digitization process looks like in theory. Here’s what it looked like in practice:&lt;/p&gt;
&lt;div class=&quot;img&quot;&gt;&lt;a href=&quot;https://mtlynch.io/digitizing-1/digitizing-process-reality.jpg&quot;&gt;&lt;img class=&quot;img-border&quot; sizes=&quot;(min-width: 768px) 800px, 98vw&quot; srcset=&quot; /digitizing-1/digitizing-process-reality_hu0db9c2048284249e55d75008c9b12853_233149_300x0_resize_q90_lanczos.jpg 300w, /digitizing-1/digitizing-process-reality_hu0db9c2048284249e55d75008c9b12853_233149_600x0_resize_q90_lanczos.jpg 600w, /digitizing-1/digitizing-process-reality_hu0db9c2048284249e55d75008c9b12853_233149_800x0_resize_q90_lanczos.jpg 800w, /digitizing-1/digitizing-process-reality_hu0db9c2048284249e55d75008c9b12853_233149_1200x0_resize_q90_lanczos.jpg 1200w, /digitizing-1/digitizing-process-reality.jpg 1200w&quot; src=&quot;https://mtlynch.io/digitizing-1/digitizing-process-reality.jpg&quot; alt=&quot;TODO&quot; loading=&quot;lazy&quot;/&gt;&lt;/a&gt;&lt;/div&gt;
&lt;p&gt;Most of the time I spent was in re-work. I’d complete a stage only to discover a flaw in my technique one or two steps later. For example, I captured video from 20 tapes before realizing that the audio was slightly out of sync. Or I discovered after weeks of editing that I’d been exporting video in a format that doesn’t support online streaming.&lt;/p&gt;
&lt;p&gt;For the sake of everyone’s sanity, I’m explaining the process as if it had continual forward motion instead of constantly forcing my readers to jump backward and restart along with me.&lt;/p&gt;
&lt;h2 id=&quot;step-1-video-capture&quot;&gt;Step 1: Video capture &lt;a href=&quot;https://mtlynch.io/digitizing-1/#step-1-video-capture&quot; class=&quot;hanchor&quot; arialabel=&quot;Anchor&quot;&gt;🔗︎&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Okay, back to 2012. My mom was eager to end her 20-year custodianship of the family home videos, so the next time I saw her, she handed me a huge cardboard box of videotapes. My digitization adventure had begun.&lt;/p&gt;
&lt;p&gt;The obvious solution would be to outsource it to a professional. There are plenty of digitization companies, including businesses that specialize in processing old home videos.&lt;/p&gt;
&lt;p&gt;I’m reasonably privacy-sensitive, so I felt uncomfortable handing strangers footage that includes me potty training (at the appropriate age; nothing weird!). Besides, I thought, how hard could it be to digitize video?&lt;/p&gt;
&lt;p&gt;Spoiler alert: really hard.&lt;/p&gt;
&lt;h3 id=&quot;my-first-attempt-at-video-capture&quot;&gt;My first attempt at video capture &lt;a href=&quot;https://mtlynch.io/digitizing-1/#my-first-attempt-at-video-capture&quot; class=&quot;hanchor&quot; arialabel=&quot;Anchor&quot;&gt;🔗︎&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;The old family VCR was still in my dad’s basement, so I asked him to dig it out next time we met for lunch. I bought a &lt;a href=&quot;https://amzn.to/36AaH4b&quot;&gt;cheap RCA to USB adaptor&lt;/a&gt; from Amazon, and I was off to the races.&lt;/p&gt;
&lt;a href=&quot;https://mtlynch.io/digitizing-1/totmc-adaptor.jpg&quot;&gt;&lt;img class=&quot;img-border&quot; sizes=&quot;(min-width: 768px) 400px, 98vw&quot; srcset=&quot; /digitizing-1/totmc-adaptor_hu5d95ed141fe7b8e70599063346232eec_57676_300x0_resize_q90_lanczos.jpg 300w, /digitizing-1/totmc-adaptor_hu5d95ed141fe7b8e70599063346232eec_57676_600x0_resize_q90_lanczos.jpg 600w, /digitizing-1/totmc-adaptor_hu5d95ed141fe7b8e70599063346232eec_57676_800x0_resize_q90_lanczos.jpg 800w, /digitizing-1/totmc-adaptor.jpg 1144w&quot; src=&quot;https://mtlynch.io/digitizing-1/totmc-adaptor.jpg&quot; alt=&quot;Picture of TOTMC RCA to USB adaptor&quot; loading=&quot;lazy&quot;/&gt;&lt;/a&gt;
&lt;p&gt;The &lt;a href=&quot;https://amzn.to/36AaH4b&quot;&gt;TOTMC video capture device&lt;/a&gt;, the first of many A/V devices I purchased throughout this process.&lt;/p&gt;
&lt;p&gt;To process the video from the USB capture device, I used VirtualDub, which was a bit dated in 2012, but not &lt;em&gt;that&lt;/em&gt; dated.&lt;/p&gt;
&lt;a href=&quot;https://mtlynch.io/digitizing-1/virtualdub-capture.jpg&quot;&gt;&lt;img class=&quot;img-border&quot; sizes=&quot;(min-width: 768px) 650px, 98vw&quot; srcset=&quot; /digitizing-1/virtualdub-capture_hu6a5e485ebb048288002f1204db60d6eb_109909_300x0_resize_q90_lanczos.jpg 300w, /digitizing-1/virtualdub-capture_hu6a5e485ebb048288002f1204db60d6eb_109909_600x0_resize_q90_lanczos.jpg 600w, /digitizing-1/virtualdub-capture_hu6a5e485ebb048288002f1204db60d6eb_109909_800x0_resize_q90_lanczos.jpg 800w, /digitizing-1/virtualdub-capture.jpg 800w&quot; src=&quot;https://mtlynch.io/digitizing-1/virtualdub-capture.jpg&quot; alt=&quot;Capturing video in [VirtualDub](http://www.virtualdub.org)&quot; loading=&quot;lazy&quot;/&gt;&lt;/a&gt;
&lt;p&gt;Using VirtualDub to capture raw footage of me reading to my dad at age 4&lt;/p&gt;
&lt;h3 id=&quot;the-pernicious-plague-of-audio-skew&quot;&gt;The pernicious plague of audio skew &lt;a href=&quot;https://mtlynch.io/digitizing-1/#the-pernicious-plague-of-audio-skew&quot; class=&quot;hanchor&quot; arialabel=&quot;Anchor&quot;&gt;🔗︎&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;As I started the editing process, I realized that the audio and video were slightly out of sync. Okay, no problem. I can shift the audio a little bit.&lt;/p&gt;
&lt;p&gt;Ten minutes later, it was out of sync again. Did I not shift it enough the first time?&lt;/p&gt;
&lt;p&gt;It slowly dawned on me that the audio and video weren’t simply offset — they captured at different rates. They diverged more and more throughout the tape. To keep them in sync, I’d repeatedly have to adjust the audio manually every few minutes of tape.&lt;/p&gt;
&lt;a href=&quot;https://mtlynch.io/digitizing-1/audio-skew.jpg&quot;&gt;&lt;img class=&quot;img-border&quot; sizes=&quot;(min-width: 768px) 800px, 98vw&quot; srcset=&quot; /digitizing-1/audio-skew_hub1cf6bff7b18f80d15d8a4a278d4529c_130022_300x0_resize_q90_lanczos.jpg 300w, /digitizing-1/audio-skew_hub1cf6bff7b18f80d15d8a4a278d4529c_130022_600x0_resize_q90_lanczos.jpg 600w, /digitizing-1/audio-skew_hub1cf6bff7b18f80d15d8a4a278d4529c_130022_800x0_resize_q90_lanczos.jpg 800w, /digitizing-1/audio-skew_hub1cf6bff7b18f80d15d8a4a278d4529c_130022_1200x0_resize_q90_lanczos.jpg 1200w, /digitizing-1/audio-skew.jpg 1200w&quot; src=&quot;https://mtlynch.io/digitizing-1/audio-skew.jpg&quot; alt=&quot;Diagram of audio skew with and without correction&quot; loading=&quot;lazy&quot;/&gt;&lt;/a&gt;
&lt;p&gt;If your video setup captures audio and video at different rates, the only solution is to correct the audio by hand every few minutes.&lt;/p&gt;
&lt;p&gt;Do you know how difficult it is to distinguish between a sound that occurs 10 milliseconds too early or 10 milliseconds too late? It’s tough! Judge for yourself.&lt;/p&gt;
&lt;p&gt;Here’s a video of me playing with my poor, patient kitten Black Magic. The audio is slightly out of sync with the video. Is the audio ahead of the video or behind it?&lt;/p&gt;
&lt;div class=&quot;video-inner&quot; readability=&quot;9&quot;&gt;Your browser does not support the video tag.
&lt;p&gt;Example of a video clip with audio and video out of sync&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Here’s the part where Magic jumps, slowed to 1/5th speed:&lt;/p&gt;
&lt;div class=&quot;video-inner&quot; readability=&quot;10&quot;&gt;Your browser does not support the video tag.
&lt;p&gt;Audio and video out of sync, slowed to 1/5th speed&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Answer&lt;/strong&gt;: The audio is coming in a few milliseconds late.&lt;/p&gt;

&lt;p&gt;Audio correction alone took hours of tedious, maddening work. It finally occurred to me that I might avoid this headache if I chose something other than Amazon’s cheapest video capture device. After a bit more research, I bought a new one:&lt;/p&gt;
&lt;a href=&quot;https://mtlynch.io/digitizing-1/s-video-capture.jpg&quot;&gt;&lt;img sizes=&quot;(min-width: 768px) 300px, 98vw&quot; srcset=&quot; /digitizing-1/s-video-capture_hub6e51c1d0ac16cde6ab88c99d13c1224_376361_300x0_resize_q90_lanczos.jpg 300w, /digitizing-1/s-video-capture_hub6e51c1d0ac16cde6ab88c99d13c1224_376361_600x0_resize_q90_lanczos.jpg 600w, /digitizing-1/s-video-capture_hub6e51c1d0ac16cde6ab88c99d13c1224_376361_800x0_resize_q90_lanczos.jpg 800w, /digitizing-1/s-video-capture_hub6e51c1d0ac16cde6ab88c99d13c1224_376361_1200x0_resize_q90_lanczos.jpg 1200w, /digitizing-1/s-video-capture.jpg 1200w&quot; src=&quot;https://mtlynch.io/digitizing-1/s-video-capture.jpg&quot; alt=&quot;GV-USB2 video capture device&quot; loading=&quot;lazy&quot;/&gt;&lt;/a&gt;
&lt;p&gt;My second attempt at &lt;a href=&quot;https://amzn.to/2X41Fth&quot;&gt;purchasing a video capture device&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Even with the new device, there was still audio skew.&lt;/p&gt;
&lt;h3 id=&quot;going-super&quot;&gt;Going super &lt;a href=&quot;https://mtlynch.io/digitizing-1/#going-super&quot; class=&quot;hanchor&quot; arialabel=&quot;Anchor&quot;&gt;🔗︎&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Maybe it was the VCR. &lt;a href=&quot;http://www.digitalfaq.com/guides/video/capture-playback-hardware.htm&quot;&gt;Digitization forums&lt;/a&gt; said audio skew wouldn’t happen with a VCR that had a “time-based corrector” (TBC), a common feature on Super VHS (S-VHS) VCRs.&lt;/p&gt;
&lt;p&gt;Of course! What was I doing messing around with my dumb &lt;em&gt;regular&lt;/em&gt; VCR when there was a &lt;strong&gt;super&lt;/strong&gt; VCR that could solve my problem?&lt;/p&gt;
&lt;p&gt;Nobody makes S-VHS VCRs anymore, but they’re still available on eBay. I spent $179 on a JVC SR-V10U, a VCR model that’s supposedly well-suited to VHS digitization:&lt;/p&gt;
&lt;a href=&quot;https://mtlynch.io/digitizing-1/jvc-vcr.jpg&quot;&gt;&lt;img sizes=&quot;(min-width: 768px) 650px, 98vw&quot; srcset=&quot; /digitizing-1/jvc-vcr_hu4e03ace8b9113a3143152bb894388190_325072_300x0_resize_q90_lanczos.jpg 300w, /digitizing-1/jvc-vcr_hu4e03ace8b9113a3143152bb894388190_325072_600x0_resize_q90_lanczos.jpg 600w, /digitizing-1/jvc-vcr_hu4e03ace8b9113a3143152bb894388190_325072_800x0_resize_q90_lanczos.jpg 800w, /digitizing-1/jvc-vcr_hu4e03ace8b9113a3143152bb894388190_325072_1200x0_resize_q90_lanczos.jpg 1200w, /digitizing-1/jvc-vcr.jpg 2000w&quot; src=&quot;https://mtlynch.io/digitizing-1/jvc-vcr.jpg&quot; alt=&quot;Photo of expensive VCR with S-VHS support&quot; loading=&quot;lazy&quot;/&gt;&lt;/a&gt;
&lt;p&gt;The vintage JVC SR-V10U VCR that I bought on eBay for $179&lt;/p&gt;
&lt;p&gt;The super VCR arrived in the mail. After months of struggling with mismatched sound, I was overjoyed to have right in my hands the equipment that promised to solve all my problems.&lt;/p&gt;
&lt;p&gt;I opened the box, hooked everything up, and the audio was still out of sync. Sigh.&lt;/p&gt;
&lt;h3 id=&quot;tedious-troubleshooting-and-the-multi-year-rut&quot;&gt;Tedious troubleshooting and the multi-year rut &lt;a href=&quot;https://mtlynch.io/digitizing-1/#tedious-troubleshooting-and-the-multi-year-rut&quot; class=&quot;hanchor&quot; arialabel=&quot;Anchor&quot;&gt;🔗︎&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Troubleshooting my hardware was miserable. I’d haul all the equipment out of my closet, crawl behind my desktop to plug everything in, try a capture, and see that it didn’t work.&lt;/p&gt;
&lt;p&gt;Oh, a random forum post from 2008 says to install some sketchy, unsigned Chinese device driver? It’s a terrible idea, but I’m desperate. It doesn’t fix the problem.&lt;/p&gt;
&lt;p&gt;I tried different capturing software. I bought a &lt;a href=&quot;https://smile.amazon.com/gp/product/B000001ON6&quot;&gt;special VHS tape&lt;/a&gt; to clean the magnetic heads of my VCR. I bought a &lt;a href=&quot;https://amzn.to/36wyIsU&quot;&gt;third capture device&lt;/a&gt;. The results were always the same.&lt;/p&gt;
&lt;p&gt;Invariably, I’d give up, disconnect everything, and banish the equipment to my closet for another few months.&lt;/p&gt;
&lt;h3 id=&quot;surrendering-to-digitization-professionals&quot;&gt;Surrendering to digitization professionals &lt;a href=&quot;https://mtlynch.io/digitizing-1/#surrendering-to-digitization-professionals&quot; class=&quot;hanchor&quot; arialabel=&quot;Anchor&quot;&gt;🔗︎&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Fast forward to 2018. I had dragged these videotapes and tons of equipment to four different apartments, and I was preparing to &lt;a href=&quot;https://mtlynch.io/solo-developer-year-1/#so-i-bought-a-house&quot;&gt;move from New York City to Massachusetts&lt;/a&gt;. I couldn’t justify moving this stuff again when it had become clear that I’d never finish the project on my own.&lt;/p&gt;
&lt;p&gt;I asked my family if they’d be comfortable with me sending the tapes to a digitization company. Fortunately, nobody minded — they were all much more interested in seeing the footage again.&lt;/p&gt;
&lt;blockquote readability=&quot;9&quot;&gt;
&lt;p&gt;&lt;strong&gt;Me&lt;/strong&gt;: But it means some company has access to all of our home videos. You’re okay with that?&lt;br/&gt;&lt;strong&gt;My sister&lt;/strong&gt;: Yeah, I don’t care. You’re the only one who worries about that. Wait, you could have just paid someone to do that from the start?&lt;br/&gt;&lt;strong&gt;Me&lt;/strong&gt;: Uh…&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;It cost $750 to digitize all 45 tapes. That may sound expensive, but by that point, I would have paid anything to avoid another minute of troubleshooting video equipment.&lt;/p&gt;
&lt;p&gt;When the files came back, the quality was undisputably better. My captures always had “tearing” around the edges, but the specialists digitized everything without any distortion. Best of all, the audio and video synced up perfectly.&lt;/p&gt;
&lt;p&gt;Here’s a video that compares the digitization company’s capture with one of my own:&lt;/p&gt;
&lt;div class=&quot;video-inner&quot; readability=&quot;10&quot;&gt;Your browser does not support the video tag.
&lt;p&gt;A comparison of professional video capture vs. my own on a tape of my mom recording my first experience writing code&lt;/p&gt;
&lt;/div&gt;
&lt;h2 id=&quot;step-2-editing&quot;&gt;Step 2: Editing &lt;a href=&quot;https://mtlynch.io/digitizing-1/#step-2-editing&quot; class=&quot;hanchor&quot; arialabel=&quot;Anchor&quot;&gt;🔗︎&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;With home videos, about 90% of the footage is boring, 8% is entertaining, and 2% is amazing. After you digitize the tapes, there’s still lots of work to do.&lt;/p&gt;
&lt;h3 id=&quot;editing-with-adobe-premiere&quot;&gt;Editing with Adobe Premiere &lt;a href=&quot;https://mtlynch.io/digitizing-1/#editing-with-adobe-premiere&quot; class=&quot;hanchor&quot; arialabel=&quot;Anchor&quot;&gt;🔗︎&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;VHS tapes contain a long stream of video clips mixed with dead air. To edit a tape, you have to identify where each clip starts and ends.&lt;/p&gt;
&lt;p&gt;For my editing, I used &lt;a href=&quot;https://www.adobe.com/products/premiere-elements.html&quot;&gt;Adobe Premiere Elements&lt;/a&gt;, which costs less than $100 for a lifetime license. Its crucial feature for editing VHS tapes is the zoomable timeline. It allows you to find rough scene boundaries quickly and then zoom in to find the exact video frame where a clip starts or ends.&lt;/p&gt;
&lt;a href=&quot;https://mtlynch.io/digitizing-1/premiere-elements-timeline.jpg&quot;&gt;&lt;img class=&quot;img-border&quot; sizes=&quot;(min-width: 768px) 1000px, 98vw&quot; srcset=&quot; /digitizing-1/premiere-elements-timeline_hu061142667662e20fe82ac18e5c90ace1_187372_300x0_resize_q90_lanczos.jpg 300w, /digitizing-1/premiere-elements-timeline_hu061142667662e20fe82ac18e5c90ace1_187372_600x0_resize_q90_lanczos.jpg 600w, /digitizing-1/premiere-elements-timeline_hu061142667662e20fe82ac18e5c90ace1_187372_800x0_resize_q90_lanczos.jpg 800w, /digitizing-1/premiere-elements-timeline_hu061142667662e20fe82ac18e5c90ace1_187372_1200x0_resize_q90_lanczos.jpg 1200w, /digitizing-1/premiere-elements-timeline.jpg 1250w&quot; src=&quot;https://mtlynch.io/digitizing-1/premiere-elements-timeline.jpg&quot; alt=&quot;Screenshot of Adobe Premiere Elements' zoomable edit feature&quot; loading=&quot;lazy&quot;/&gt;&lt;/a&gt;
&lt;p&gt;The invaluable zoomable edit timeline in Adobe Premiere Elements&lt;/p&gt;
&lt;p&gt;The problem with Premiere is that it requires frequent starting and stopping. My process was:&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;Open a raw capture file containing 30-120 minutes of video.&lt;/li&gt;
&lt;li&gt;Mark the boundaries of an individual clip.&lt;/li&gt;
&lt;li&gt;Export the clip.&lt;/li&gt;
&lt;li&gt;Wait 2-15 minutes until the export completes.&lt;/li&gt;
&lt;li&gt;Repeat steps 2-4 until the tape ends.&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;The long waits meant that I was constantly context-switching between video editing and some other task, scrambling my focus for hours&lt;/p&gt;
&lt;p&gt;The other drawback was non-reproducibility. Fixing a small error was almost as hard as doing the entire thing from scratch. That bit me hard when I reached the video-sharing stage. Only then did I realize I should have been exporting the videos in a format that web browsers could stream natively. My options were to restart the tedious process of exporting hundreds of clips or to re-encode the exported videos to another format, degrading their quality.&lt;/p&gt;
&lt;h3 id=&quot;robo-editing&quot;&gt;Robo-editing &lt;a href=&quot;https://mtlynch.io/digitizing-1/#robo-editing&quot; class=&quot;hanchor&quot; arialabel=&quot;Anchor&quot;&gt;🔗︎&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;After an embarrassing number of hours doing everything by hand, I wondered if I could simply throw artificial intelligence at the problem. Identifying clip boundaries seemed like a suitable machine learning task. I knew that accuracy would be less than perfect, but maybe it could do 80% of the work, and I’d fix the last 20% manually.&lt;/p&gt;
&lt;p&gt;I experimented with a tool called &lt;a href=&quot;https://pyscenedetect.readthedocs.io/en/latest/&quot;&gt;pyscenedetect&lt;/a&gt;, which analyzes video files and prints out the timecodes where scene changes occur:&lt;/p&gt;
&lt;div class=&quot;highlight&quot; readability=&quot;14&quot;&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt; $ docker run &lt;span&gt;\
&lt;/span&gt;    --volume &lt;span&gt;&quot;/videos:/opt&quot;&lt;/span&gt; &lt;span&gt;\
&lt;/span&gt;    handflucht/pyscenedetect &lt;span&gt;\
&lt;/span&gt;    --input /opt/test.mp4 &lt;span&gt;\
&lt;/span&gt;    --output /opt &lt;span&gt;\
&lt;/span&gt;    detect-content --threshold &lt;span&gt;80&lt;/span&gt; &lt;span&gt;\
&lt;/span&gt;    list-scenes
[PySceneDetect] Output directory set:
  /opt
[PySceneDetect] Loaded &lt;span&gt;1&lt;/span&gt; video, framerate: 29.97 FPS, resolution: &lt;span&gt;720&lt;/span&gt; x &lt;span&gt;480&lt;/span&gt;
[PySceneDetect] Downscale factor &lt;span&gt;set&lt;/span&gt; to 3, effective resolution: &lt;span&gt;240&lt;/span&gt; x &lt;span&gt;160&lt;/span&gt;
[PySceneDetect] Scene list CSV file name format:
  &lt;span&gt;$VIDEO_NAME&lt;/span&gt;-Scenes.csv
[PySceneDetect] Detecting scenes...
[PySceneDetect] Processed &lt;span&gt;55135&lt;/span&gt; frames in 117.6 seconds (average 468.96 FPS).
[PySceneDetect] Detected &lt;span&gt;33&lt;/span&gt; scenes, average shot length 55.7 seconds.
[PySceneDetect] Writing scene list to CSV file:
  /opt/test-Scenes.csv
[PySceneDetect] Scene List:
-----------------------------------------------------------------------
 | Scene &lt;span&gt;# | Start Frame |  Start Time  |  End Frame  |   End Time   |&lt;/span&gt;
-----------------------------------------------------------------------
 |      &lt;span&gt;1&lt;/span&gt;  |           &lt;span&gt;0&lt;/span&gt; | 00:00:00.000 |        &lt;span&gt;1011&lt;/span&gt; | 00:00:33.734 |
 |      &lt;span&gt;2&lt;/span&gt;  |        &lt;span&gt;1011&lt;/span&gt; | 00:00:33.734 |        &lt;span&gt;1292&lt;/span&gt; | 00:00:43.110 |
 |      &lt;span&gt;3&lt;/span&gt;  |        &lt;span&gt;1292&lt;/span&gt; | 00:00:43.110 |        &lt;span&gt;1878&lt;/span&gt; | 00:01:02.663 |
 |      &lt;span&gt;4&lt;/span&gt;  |        &lt;span&gt;1878&lt;/span&gt; | 00:01:02.663 |        &lt;span&gt;2027&lt;/span&gt; | 00:01:07.634 |
 ...
&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;It was indeed about 80% accurate, but checking the tool’s work took more time than it saved me. Nevertheless, pyscenedetect sparked one of my most important realizations of this entire project: identifying scene boundaries and exporting clips are separate tasks.&lt;/p&gt;
&lt;h3 id=&quot;i-remembered-that-im-a-programmer&quot;&gt;I remembered that I’m a programmer &lt;a href=&quot;https://mtlynch.io/digitizing-1/#i-remembered-that-im-a-programmer&quot; class=&quot;hanchor&quot; arialabel=&quot;Anchor&quot;&gt;🔗︎&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Until that point, I had thought of “editing” as everything I was doing in Adobe Premiere. Chopping out subclips of raw footage felt inextricably tied to finding clip boundaries because that’s how Premiere presented it. When pyscenedetect printed out its table of metadata, it made me realize I could decouple scene finding from video exporting. That was a gamechanger.&lt;/p&gt;
&lt;p&gt;The reason that editing was so tedious and time-consuming was that I had to keep waiting for Premiere to export each clip. If I recorded the metadata in a spreadsheet and wrote a script that exported videos automatically, the editing process would fly by.&lt;/p&gt;
&lt;p&gt;What’s more, spreadsheets dramatically expanded the type of information I captured. Initially, I stuffed metadata into the filename, but that’s limiting and inflexible. Having an entire spreadsheet allowed me to catalog so much more about the clip like who’s in it, when it was recorded, and any other data I want to present alongside the video when people watch it.&lt;/p&gt;
&lt;a href=&quot;https://mtlynch.io/digitizing-1/spreadsheet.png&quot;&gt;&lt;img class=&quot;img-border&quot; sizes=&quot;(min-width: 768px) 750px, 98vw&quot; srcset=&quot; /digitizing-1/spreadsheet_hu2de0e06f0b4fdcfe6c4513935ac1f755_41409_300x0_resize_lanczos_2.png 300w, /digitizing-1/spreadsheet_hu2de0e06f0b4fdcfe6c4513935ac1f755_41409_600x0_resize_lanczos_2.png 600w, /digitizing-1/spreadsheet_hu2de0e06f0b4fdcfe6c4513935ac1f755_41409_800x0_resize_lanczos_2.png 800w, /digitizing-1/spreadsheet_hu2de0e06f0b4fdcfe6c4513935ac1f755_41409_1200x0_resize_lanczos_2.png 1200w, /digitizing-1/spreadsheet.png 1208w&quot; src=&quot;https://mtlynch.io/digitizing-1/spreadsheet.png&quot; alt=&quot;Spreadsheet of home video metadata&quot; loading=&quot;lazy&quot;/&gt;&lt;/a&gt;
&lt;p&gt;Capturing metadata about my home videos in a giant spreadsheet&lt;/p&gt;
&lt;p&gt;Later, I was able to use that metadata to add information to the clips like how old we all were and a detailed description of what’s going on in the clip.&lt;/p&gt;
&lt;a href=&quot;https://mtlynch.io/digitizing-1/spreadsheet-to-meta.png&quot;&gt;&lt;img sizes=&quot;(min-width: 768px) 800px, 98vw&quot; srcset=&quot; /digitizing-1/spreadsheet-to-meta_hu86386b4ec2a726db80f82583534bea5d_504137_300x0_resize_lanczos_2.png 300w, /digitizing-1/spreadsheet-to-meta_hu86386b4ec2a726db80f82583534bea5d_504137_600x0_resize_lanczos_2.png 600w, /digitizing-1/spreadsheet-to-meta_hu86386b4ec2a726db80f82583534bea5d_504137_800x0_resize_lanczos_2.png 800w, /digitizing-1/spreadsheet-to-meta_hu86386b4ec2a726db80f82583534bea5d_504137_1200x0_resize_lanczos_2.png 1200w, /digitizing-1/spreadsheet-to-meta.png 1524w&quot; src=&quot;https://mtlynch.io/digitizing-1/spreadsheet-to-meta.png&quot; alt=&quot;Visualization of how items in my spreadsheet translate to metadata in my media sharing solution&quot; loading=&quot;lazy&quot;/&gt;&lt;/a&gt;
&lt;p&gt;With the added flexibility of a spreadsheet, I can record metadata that gives more information about the clips and makes them easier to browse.&lt;/p&gt;
&lt;h3 id=&quot;the-glory-of-an-automated-solution&quot;&gt;The glory of an automated solution &lt;a href=&quot;https://mtlynch.io/digitizing-1/#the-glory-of-an-automated-solution&quot; class=&quot;hanchor&quot; arialabel=&quot;Anchor&quot;&gt;🔗︎&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;With the spreadsheet in hand, I &lt;a href=&quot;https://github.com/mtlynch/process-home-videos&quot;&gt;wrote a script&lt;/a&gt; that chopped my raw videos into smaller clips based on a CSV input.&lt;/p&gt;
&lt;p&gt;Here’s a screen capture of what it looks like in action:&lt;/p&gt;
&lt;p&gt;At this point, I’d spent &lt;strong&gt;hundreds&lt;/strong&gt; of hours tediously selecting clip boundaries in Premiere, hitting export, waiting a few minutes for it to complete, then starting over. Not only that, I had repeated this process several times on the same footage after discovering quality problems later on.&lt;/p&gt;
&lt;p&gt;Once I automated the clip slicing part, it was a massive weight off my shoulders. I didn’t have to worry about forgetting metadata or picking the wrong output format. If I discovered a mistake after the fact, I could just tweak my script and rerun everything.&lt;/p&gt;

&lt;p&gt;Capturing and editing the clips was only half the battle. I still needed a way to share everything with my family in a way that was fun, secure, and affordable.&lt;/p&gt;
&lt;p&gt;In &lt;a href=&quot;https://mtlynch.io/digitizing-2/&quot;&gt;part two&lt;/a&gt; of this post, I describe the open source media server I used to share these clips with my family for only $0.77/month.&lt;/p&gt;
&lt;hr/&gt;&lt;p&gt;&lt;em&gt;Illustrations by &lt;a href=&quot;https://www.linkedin.com/in/lolo-ology/&quot;&gt;Loraine Yow&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Special thanks to my family for allowing me to share a selection of these clips and stills, for recording everything in the first place, and for being so supportive throughout this process.&lt;/em&gt;&lt;/p&gt;
</description>
<pubDate>Tue, 20 Oct 2020 17:08:21 +0000</pubDate>
<dc:creator>mtlynch</dc:creator>
<og:title>My Eight-Year Quest to Digitize 45 Videotapes (Part One)</og:title>
<og:description>My journey to create a YouTube of memories from my family's old home videos.</og:description>
<og:type>article</og:type>
<og:url>https://mtlynch.io/digitizing-1/</og:url>
<og:image>https://mtlynch.io/digitizing-1/cover.jpg</og:image>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://mtlynch.io/digitizing-1/</dc:identifier>
</item>
<item>
<title>The Accelerating Adoption of Julia</title>
<link>https://lwn.net/SubscriberLink/834571/e8d7adc0d9b669bc/</link>
<guid isPermaLink="true" >https://lwn.net/SubscriberLink/834571/e8d7adc0d9b669bc/</guid>
<description>&lt;center&gt;
&lt;table width=&quot;90%&quot; cellspacing=&quot;5&quot; readability=&quot;4.1829745596869&quot;&gt;&lt;tr readability=&quot;11.154598825832&quot;&gt;&lt;td valign=&quot;top&quot; readability=&quot;9&quot;&gt;
&lt;h3&gt;Welcome to LWN.net&lt;/h3&gt;
&lt;p&gt;The following subscription-only content has been made available to you by an LWN subscriber. Thousands of subscribers depend on LWN for the best news from the Linux and free software communities. If you enjoy this article, please consider accepting the trial offer on the right. Thank you for visiting LWN.net!&lt;/p&gt;
&lt;/td&gt;
&lt;td valign=&quot;top&quot;&gt;
&lt;table class=&quot;Form&quot; width=&quot;100%&quot; readability=&quot;1.2016574585635&quot;&gt;&lt;tr readability=&quot;3.6049723756906&quot;&gt;&lt;td readability=&quot;4.8066298342541&quot;&gt;
&lt;h3&gt;Free trial subscription&lt;/h3&gt;
&lt;p&gt;Try LWN for free for 1 month: no payment or credit card required. &lt;a href=&quot;https://lwn.net/Promo/slink-trial2-3/claim&quot;&gt;Activate your trial subscription now&lt;/a&gt; and see why thousands of readers subscribe to LWN.net.&lt;/p&gt;
&lt;/td&gt;
&lt;/tr&gt;&lt;/table&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/table&gt;&lt;/center&gt;
&lt;div class=&quot;GAByline&quot; readability=&quot;7&quot;&gt;
&lt;p&gt;October 20, 2020&lt;/p&gt;
&lt;p&gt;This article was contributed by Lee Phillips&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;The &lt;a href=&quot;http://julialang.org/&quot;&gt;Julia&lt;/a&gt; programming language has seen a major increase in its use and popularity over the last few years. We last &lt;a href=&quot;https://lwn.net/Articles/763626/&quot;&gt;looked at it&lt;/a&gt; two years ago, around the time of the &lt;a href=&quot;https://julialang.org/blog/2018/08/one-point-zero/&quot;&gt;Julia 1.0 release&lt;/a&gt;. Here, we will look at some of the changes since that release, none of which are major, as well as some newer resources for learning the language, but the main focus of this article is a case study that is meant to help show why the language has been taking off. A follow-up article will introduce a new computational notebook for Julia, called &lt;a href=&quot;https://github.com/fonsp/Pluto.jl&quot;&gt;Pluto&lt;/a&gt;, that is akin to &lt;a href=&quot;https://lwn.net/Articles/746386/&quot;&gt;Jupyter notebooks&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Julia is a programming language that was first released in 2012; its implementation is released under the MIT license. It is a general-purpose language, but with a particular suitability for scientific programming and numerical work. Julia is a dynamic language, with an interactive mode and easy-to-learn syntax that is simple for novice programmers; it also has deeper layers of sophistication for the expert. The language allows introspection and &lt;a href=&quot;https://en.wikipedia.org/wiki/Metaprogramming&quot;&gt;metaprogramming&lt;/a&gt;, with Lisp-like macros, an optional Lisp syntax, and access to syntax-tree and assembly-language views of functions. It features a rich type system with performant user-defined types, &lt;a href=&quot;https://en.wikipedia.org/wiki/Multiple_dispatch&quot;&gt;multiple dispatch&lt;/a&gt; of functions, and several flavors of concurrent programming built in.&lt;/p&gt;
&lt;p&gt;Julia recently passed a kind of popularity milestone, breaking into the top 20 in the IEEE Spectrum &lt;a href=&quot;https://www.hpcwire.com/2020/07/22/python-again-tops-ieee-spectrums-programming-language-list/&quot;&gt;list of programming languages&lt;/a&gt;. Beyond that, the language is being adopted in many new research projects, such as: the &lt;a href=&quot;https://github.com/CliMA/ClimateMachine.jl&quot;&gt;Climate Machine&lt;/a&gt;, the computational engine used by the Caltech Climate Modeling Alliance; a new &lt;a href=&quot;https://news.mit.edu/2020/mit-led-team-will-develop-software-forecast-space-storms-0910&quot;&gt;space weather forecasting&lt;/a&gt; initiative, funded by the NSF; &lt;a href=&quot;https://www.nature.com/articles/s41534-017-0017-3?linkId=37249498&quot;&gt;quantum machine learning&lt;/a&gt;; &lt;a href=&quot;https://juliacomputing.com/products/pumas/&quot;&gt;drug development&lt;/a&gt;; and a computational collaboration called &lt;a href=&quot;https://www.nersc.gov/news-publications/nersc-news/science-news/2015/celeste-a-new-model-for-cataloging-the-universe/&quot;&gt;Celeste&lt;/a&gt; to create a massive star map of the universe.&lt;/p&gt;
&lt;p&gt;Professor &lt;a href=&quot;https://mykel.kochenderfer.com/&quot;&gt;Mykel Kochenderfer&lt;/a&gt; is the creator of an international standard aircraft collision avoidance system, ACAS X. In an email interview, he told me that the Julia version of his system runs as fast as a previous version he wrote in highly optimized C++. Since he wrote the Julia version intending it to merely document the algorithm, this was a surprise. He was able to replace the C++ version with the easier to read and maintain Julia code.&lt;/p&gt;
&lt;p&gt;The recently concluded annual Julia conference, online this year, naturally, was a good indicator of the audience that Julia is attracting. The presentations (&lt;a href=&quot;https://www.youtube.com/playlist?list=PLP8iPy9hna6StY9tIJIUN3F_co9A0zh0H&quot;&gt;YouTube videos&lt;/a&gt;) that one would expect of various computer science topics were outweighed by talks about applications to scientific research in an impressive variety of fields. A recurring theme was the way that the language &lt;a href=&quot;https://arstechnica.com/science/2020/10/the-unreasonable-effectiveness-of-the-julia-programming-language/&quot;&gt;facilitated collaboration&lt;/a&gt; and code reuse, giving scientists an opportunity to take advantage of the packages and algorithms of others.&lt;/p&gt;
&lt;h4&gt;Case study: the power of combining libraries&lt;/h4&gt;
&lt;p&gt;Julia's organization around the concept of multiple dispatch (described in &lt;a href=&quot;https://lwn.net/Articles/764001/&quot;&gt;part two&lt;/a&gt; of our Julia introduction), combined with a certain care taken by package authors to write extensible code, creates an environment where it is unusually easy to combine the features of several packages. Multiple dispatch means that a function can be defined with a variety of available methods, each one operating on a different set of argument types; the particular method used is chosen at run time, based on the types of all of the arguments. Crucially, the user of a library can &lt;a href=&quot;https://white.ucc.asn.au/2020/02/09/whycompositionaljulia.html&quot;&gt;define new methods for functions in the library&lt;/a&gt;, without having to modify the existing library code.&lt;/p&gt;
&lt;p&gt;Our case study involves an activity fundamental to most computational science: the numerical solution to a &lt;a href=&quot;https://www.mathsisfun.com/calculus/differential-equations.html&quot;&gt;differential equation&lt;/a&gt;. The Julia package &lt;a href=&quot;https://github.com/SciML/DifferentialEquations.jl&quot;&gt;&lt;tt&gt;DifferentialEquations&lt;/tt&gt;&lt;/a&gt; has become the standard for this purpose in the ecosystem. Packages can be added to Julia from the the read-eval-print loop (REPL) using the language's package manager. It will &lt;a href=&quot;https://towardsdatascience.com/julias-package-manager-is-awesome-23b9c02e3a0b&quot;&gt;download the package from GitHub&lt;/a&gt;, along with any dependencies, and store the result in the user's &lt;tt&gt;.julia&lt;/tt&gt; directory.&lt;/p&gt;
&lt;p&gt;Once it is installed, we need to import the functions provided by &lt;tt&gt;DifferentialEquations&lt;/tt&gt;, so that we can use them in calculations. In a program, we would use an &lt;tt&gt;import&lt;/tt&gt; statement to pull in just what we need to use, and keep everything namespaced. But, for convenience in the REPL, we'll use the command:&lt;/p&gt;
&lt;pre&gt;
    julia&amp;gt; using DifferentialEquations
&lt;/pre&gt;
&lt;p&gt;That will import everything into the top level and allow us to use the package's functions as bare names. The first time this command is issued on a previously unseen package, it will lead to a spate of pre-compiling. For a complex and large package such as &lt;tt&gt;DifferentialEquations&lt;/tt&gt;, this could take significant time. True story: I entered this command and went to take a shower. When I returned, it was still working. After a total of about 20 minutes, the pre-compilation was complete. The compiled code is stored on disk, however, so starting up the REPL and using &lt;tt&gt;DifferentialEquations&lt;/tt&gt; in future sessions does not incur this delay.&lt;/p&gt;
&lt;p&gt;We will want to use the packages &lt;a href=&quot;http://docs.juliaplots.org/latest/&quot;&gt;&lt;tt&gt;Plots&lt;/tt&gt;&lt;/a&gt; and &lt;a href=&quot;https://juliaphysics.github.io/Measurements.jl/stable/&quot;&gt;&lt;tt&gt;Measurements&lt;/tt&gt;&lt;/a&gt; in our demonstration as well, so we install them and repeat the &lt;tt&gt;using&lt;/tt&gt; commands on them.&lt;/p&gt;
&lt;p&gt;Our example will involve the numerical solution to the differential equation:&lt;/p&gt;
&lt;pre&gt;
    f' = f - f²
&lt;/pre&gt;
&lt;p&gt;where &lt;tt&gt;f'&lt;/tt&gt; is the time derivative of &lt;tt&gt;f&lt;/tt&gt;. This is sometimes called the logistic equation; it represents the initial exponential growth of a population, followed by its saturation, as space or food becomes scarce.&lt;/p&gt;
&lt;p&gt;We begin by defining the differential equation in a form that can be used by the numerical solver:&lt;/p&gt;
&lt;pre&gt;
    julia&amp;gt; r(f,p,t) = f - f^2
&lt;/pre&gt;
&lt;p&gt;This uses Julia's concise notation for defining a function on one line. To use the differential equation solver, we need to create a function of three arguments, whose value is the derivative of the function, which appears as the first argument. The second, &lt;tt&gt;p&lt;/tt&gt;, is for optional parameters that we are not using here, and the third is the independent variable, which we are calling time. The function, which will be passed to the solver, can be named anything.&lt;/p&gt;
&lt;p&gt;Next, we need to define a time interval (&lt;tt&gt;tint&lt;/tt&gt;) over which we want the solution, and an initial value (&lt;tt&gt;r0&lt;/tt&gt;), to nail down a particular solution from the infinitely many possible solutions to the equation:&lt;/p&gt;
&lt;pre&gt;
    julia&amp;gt; tint = (0.0, 8.0)
    julia&amp;gt; r0 = 0.05
&lt;/pre&gt;
&lt;p&gt;Now we give this information to a constructor that creates a &quot;problem&quot;. This is a convenience, because it is often the case that we will want to experiment with, for example, different numerical methods, while the definition of the problem itself doesn't change. The constructor, called &lt;tt&gt;ODEProblem()&lt;/tt&gt; (ODE stands for ordinary differential equation), is provided by the &lt;tt&gt;DifferentialEquations&lt;/tt&gt; package:&lt;/p&gt;
&lt;pre&gt;
    julia&amp;gt; prob = ODEProblem(r, r0, tint)
&lt;/pre&gt;
&lt;p&gt;Now to calculate a solution:&lt;/p&gt;
&lt;pre&gt;
    julia&amp;gt; sol = solve(prob)
&lt;/pre&gt;
&lt;p&gt;That's all there is to it. Julia will respond with some numbers summarizing the numerical solution that it found. The &lt;tt&gt;solve()&lt;/tt&gt; function is also provided by &lt;tt&gt;DifferentialEquations&lt;/tt&gt;; a &lt;a href=&quot;https://diffeq.sciml.ai/stable/tutorials/ode_example/#ode_example&quot;&gt;detailed tutorial&lt;/a&gt; is worth looking at for another example of solving a differential equation using &lt;tt&gt;ODEProblem()&lt;/tt&gt; and &lt;tt&gt;solve()&lt;/tt&gt;. The &lt;tt&gt;solve()&lt;/tt&gt; function accepts many optional arguments, including one that selects from a myriad of available approximation methods; but I am making this example as streamlined as possible, and the default, in this case, does an excellent job. I know this, because this differential equation has an analytic solution, so I was able to check Julia's work.&lt;/p&gt;
&lt;p&gt;The &lt;tt&gt;Plots&lt;/tt&gt; package is already imported, so we can have a look at the solution:&lt;/p&gt;
&lt;pre&gt;
    julia&amp;gt; plot(sol.t, sol.u, key=false)
&lt;/pre&gt;
&lt;p&gt;This command immediately pops up a plot window:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&quot;https://static.lwn.net/images/2020/julia-fig1.svg&quot; alt=&quot;[Numerical solution plot]&quot; title=&quot;Numerical solution plot&quot; /&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Note that &lt;tt&gt;sol&lt;/tt&gt; is a data type with various bits of information packed into it about the solution; in order to plot it, we passed arrays of the independent (&lt;tt&gt;sol.t&lt;/tt&gt;) and dependent (&lt;tt&gt;sol.u&lt;/tt&gt;) variables.&lt;/p&gt;
&lt;p&gt;Above I mentioned that we also wanted to import a package called &lt;tt&gt;Measurements&lt;/tt&gt;. This library, among other things, extends floating-point numbers to include errors, or uncertainties in their values. Once you have imported it, you can write a number as, for example:&lt;/p&gt;
&lt;pre&gt;
    1.0 ± 0.1
&lt;/pre&gt;
&lt;p&gt;That attaches an error value to it, which makes nice use of Julia's embrace of Unicode. These numbers behave as normal floats, except that they carry along error ranges with them. Arithmetic with these types treats the error ranges according to &lt;a href=&quot;https://en.wikipedia.org/wiki/Propagation_of_uncertainty&quot;&gt;linear error propagation theory&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Suppose there was some uncertainty attached to our knowledge of the initial condition in the above problem. We could then write the initial value as:&lt;/p&gt;
&lt;pre&gt;
    julia&amp;gt; r0m = 0.05 ± 0.01
&lt;/pre&gt;
&lt;p&gt;Now, logically, there would be some uncertainty in the solution, and to be consistent, in everything else. So everywhere where we had exact numbers, we replace them with uncertain numbers, even if we assume the errors to be zero:&lt;/p&gt;
&lt;pre&gt;
    julia&amp;gt; rm(f,p,t) = (1 ± 0.0)*(f - f^2)
    julia&amp;gt; tintm = (0.0*1 ± 0, 8.0*1 ± 0)
&lt;/pre&gt;
&lt;p&gt;Can we use the &lt;tt&gt;DifferentialEquations&lt;/tt&gt; package to solve this equation? It may seem unreasonable to expect this to work. &lt;tt&gt;DifferentialEquations&lt;/tt&gt; only claims to deal with floating-point numbers for initial values and time intervals, and it is a package for solving for functions that map numbers to numbers. Different people created the &lt;tt&gt;Measurements&lt;/tt&gt; package, and &lt;tt&gt;DifferentialEquations&lt;/tt&gt; knows nothing of this exotic new data type. Let's ignore all of this and forge ahead:&lt;/p&gt;
&lt;pre&gt;
    julia&amp;gt; probm = ODEProblem(rm,r0m,tintm)
    julia&amp;gt; solm = solve(probm)
&lt;/pre&gt;
&lt;p&gt;Julia not only proceeds without complaining, but it prints out the solution in the form of numbers with ± values appended. If &lt;tt&gt;DifferentialEquations&lt;/tt&gt; can somehow handle this data type, can we push our luck with Plots?&lt;/p&gt;
&lt;pre&gt;
    julia&amp;gt; plot(solm.t, solm.u, key=false)
&lt;/pre&gt;
&lt;p&gt;Typing that in the REPL gets us this figure:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&quot;https://static.lwn.net/images/2020/julia-fig2.svg&quot; alt=&quot;[Plot with error bars]&quot; title=&quot;Plot with error bars&quot; /&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;We see here the same solution plotted as before, but this time with the uncertainties rendered as error bars. I've verified that the errors were propagated correctly, and that they are plotted accurately.&lt;/p&gt;
&lt;p&gt;We had no right to expect that any of this would work, yet by some magic, it all does. Chris Rackauckas, the MIT professor who is the chief author of the &lt;tt&gt;DifferentialEquations&lt;/tt&gt; package, and who suggested that I look at combining it with &lt;tt&gt;Measurements&lt;/tt&gt; data types, tells me that his package was written with no knowledge of these data types. It was a delightful surprise for him when he discovered that his code handles numbers with error intervals in the correct way. It works because these libraries are written in a generic fashion, with functions that can be extended to work on new data types. This is made possible by Julia's type system and its organization around multiple dispatch. This is Julia's solution to the &lt;a href=&quot;https://en.wikipedia.org/wiki/Expression_problem&quot;&gt;expression problem&lt;/a&gt;, allowing one to extend and combine existing libraries without having to modify those libraries, or even having to look at their source code.&lt;/p&gt;
&lt;p&gt;Another example is the &lt;tt&gt;plot()&lt;/tt&gt; function. It is designed to plot arrays of floating-point numbers, yet is able to produce sensible renderings of other data types, such as the uncertain numbers used in the example. This is because the &lt;tt&gt;Measurements&lt;/tt&gt; package comes with a simple recipe that tells the plotting routines what to do when they encounter this data type; and &lt;em&gt;that&lt;/em&gt;, again, is only possible because of Julia's multiple function dispatch.&lt;/p&gt;
&lt;p&gt;One can, for example, use &lt;a href=&quot;https://encyclopediaofmath.org/wiki/Quaternion&quot;&gt;quaternions&lt;/a&gt; instead of floating-point numbers. These are like complex numbers, but with four components instead of two, and there is a Julia &lt;a href=&quot;https://www.juliaobserver.com/packages/Quaternions&quot;&gt;package&lt;/a&gt; that defines the data type. &lt;tt&gt;DifferentialEquations&lt;/tt&gt; will happily solve equations for quaternion-valued functions (although, again, it knows nothing about them). They can be combined with &lt;tt&gt;Measurements&lt;/tt&gt; to produce quaternions with error intervals attached to the components, and &lt;tt&gt;DifferentialEquations&lt;/tt&gt; will propagate all of the errors correctly. A plot of the solution using the &lt;tt&gt;Plots&lt;/tt&gt; package will display four lines, one for each component, and each one will have its own error bars.&lt;/p&gt;
&lt;h4 id=&quot;language-changes&quot;&gt;Language changes&lt;/h4&gt;
&lt;p&gt;There have been no major breaking changes since version 1.0. There are some minor tweaks to the syntax, which generally make things more convenient, that are detailed in the the &lt;a href=&quot;https://docs.julialang.org/en/v1/NEWS/&quot;&gt;release notes for v1.5&lt;/a&gt;, &lt;a href=&quot;https://github.com/JuliaLang/julia/blob/v1.4.0/NEWS.md&quot;&gt;v1.4&lt;/a&gt;, and &lt;a href=&quot;https://github.com/JuliaLang/julia/blob/v1.3.0/NEWS.md&quot;&gt;v1.3&lt;/a&gt;. Here I'll describe several more significant changes.&lt;/p&gt;
&lt;p&gt;The latest release brings a substantial change to scoping rules when using the REPL. In Julia, blocks such as &lt;tt&gt;for&lt;/tt&gt; loops create their own lexical scopes. Variables that appear in such blocks are local to the block, unless explicitly declared to be global. In Julia 1.5, when using the REPL, an assignment inside a block to an undeclared variable that already exists in global scope will use that global variable. For code in files, the same code will get you a warning, because it is ambiguous; this change does not break any code in files. This was thought to be more convenient for interactive use in the REPL, where it can be tedious, and surprising for new users, to have to track global variables. Nevertheless, this change generated some controversy, because now the same code in a file and in the REPL will behave differently; that returns to the behavior of pre-1.0 Julia versions.&lt;/p&gt;
&lt;p&gt;This version also introduces a syntax option that reduces visual noise and typing when using keyword arguments. If one's local variables have the same name as a function's named parameters, which is often the case, then a function call winds up looking like &lt;tt&gt;function(var1=var1, var2=var2)&lt;/tt&gt;; this is the normal syntax in Python and previous versions of Julia. Now this can be streamlined to &lt;tt&gt;function(; var1, var2)&lt;/tt&gt;.&lt;/p&gt;
&lt;p&gt;The most common perennial complaint about Julia is the long startup time when pre-compiling a package. The latest version introduces an experimental module-level setting for the compiler optimization level. Turning off optimizations for code that is not crucial for performance can significantly reduce compilation time and, thus, latency.&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://julialang.org/blog/2019/07/multithreading/&quot;&gt;Task-based parallelism&lt;/a&gt;, introduced in v1.3, is a convenient way to fire off long-running processes. Briefly, a simple &lt;tt&gt;@spawn&lt;/tt&gt; macro allows the programmer to execute a function in a separate thread. The calls can be nested, with the function using &lt;tt&gt;@spawn&lt;/tt&gt; to run other functions, while the language runtime coordinates everything.&lt;/p&gt;
&lt;h4 id=&quot;learning-resources&quot;&gt;Learning resources&lt;/h4&gt;
&lt;p&gt;In the last few years, some new books and useful websites have appeared, which makes it easier to get started with the language.&lt;/p&gt;
&lt;p&gt;A few of the notable books are: &lt;a href=&quot;https://www.packtpub.com/product/hands-on-design-patterns-and-best-practices-with-julia/9781838648817&quot;&gt;&lt;em&gt;Hands-On Design Patterns and Best Practices with Julia&lt;/em&gt;&lt;/a&gt;; &lt;a href=&quot;https://www.oreilly.com/library/view/think-julia/9781492045021/&quot;&gt;&lt;em&gt;Think Julia&lt;/em&gt;&lt;/a&gt;; &lt;a href=&quot;https://www.amazon.com/Little-Book-Julia-Algorithms-programming/dp/1838173609/&quot;&gt;&lt;em&gt;The Little Book of Julia Algorithms&lt;/em&gt;&lt;/a&gt;, which is unusual in that it is aimed at middle- and high-school students; and &lt;a href=&quot;https://www.packtpub.com/product/julia-programming-projects/9781788292740&quot;&gt;&lt;em&gt;Julia Programming Projects&lt;/em&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The official, online &lt;a href=&quot;https://docs.julialang.org/en/v1.5/&quot;&gt;documentation&lt;/a&gt; is quite comprehensive, and may be all that an experienced programmer will require. But it mixes deep discussions of advanced topics together with introductory sections in a way that would be likely to bewilder a relative beginner.&lt;/p&gt;
&lt;p&gt;Some websites and online resources that provide a gentler approach are &lt;a href=&quot;https://juliabyexample.helpmanual.io/&quot;&gt;Julia By Example&lt;/a&gt;, a &lt;a href=&quot;https://en.wikibooks.org/wiki/Introducing_Julia&quot;&gt;Wikibook introduction to Julia&lt;/a&gt;, a series of classes at the &lt;a href=&quot;https://juliaacademy.com/courses&quot;&gt;JuliaAcademy&lt;/a&gt;, a &lt;a href=&quot;https://exercism.io/tracks/julia&quot;&gt;set of Julia exercises&lt;/a&gt;, a &lt;a href=&quot;https://www.coursera.org/learn/julia-programming&quot;&gt;Coursera course&lt;/a&gt; on Julia for scientists, and an &lt;a href=&quot;https://www.analyticsvidhya.com/blog/2017/10/comprehensive-tutorial-learn-data-science-julia-from-scratch/&quot;&gt;introduction to the language for data scientists&lt;/a&gt;. There has been an explosion of learning resources—this is just a tiny sample.&lt;/p&gt;
&lt;p&gt;I hope that the small example above helps demonstrate, in miniature, what's special about Julia, and why it is making such a splash in the scientific community. Julia is not the first language to make a multiple dispatch system available to programmers; Common Lisp included this 40 years ago. But it was a breakthrough to combine this with Fortran-class numerical performance and with a syntax as easy to pick up and read as Python's.&lt;/p&gt;
&lt;p&gt;Julia is certainly worth considering for a scientist or engineer who is beginning a new project. Although it still doesn't have the vast coverage of the Python libraries, it is particularly easy to call Python (and Fortran or C) functions from Julia code—and the Julia code will, generally, run fast. For everyone else, I can recommend Julia simply as an interesting, fun, and instructive language to play around in.&lt;/p&gt;
&lt;br clear=&quot;all&quot; /&gt;&lt;br clear=&quot;all&quot; /&gt;
&lt;br clear=&quot;all&quot; /&gt;&lt;blockquote&gt;
&lt;table class=&quot;Form&quot; readability=&quot;1.2534246575342&quot;&gt;&lt;tr readability=&quot;2.5068493150685&quot;&gt;&lt;td&gt;&lt;strong&gt;Did you like this article?&lt;/strong&gt; Please accept our &lt;a href=&quot;https://lwn.net/Promo/slink-trial2-3/claim&quot;&gt;trial subscription offer&lt;/a&gt; to be able to see more content like it and to participate in the discussion.&lt;/td&gt;
&lt;/tr&gt;&lt;/table&gt;&lt;/blockquote&gt;
&lt;hr width=&quot;60%&quot; align=&quot;left&quot; /&gt;
(&lt;a href=&quot;https://lwn.net/Login/?target=/Articles/834571/&quot;&gt;Log in&lt;/a&gt; to post comments)</description>
<pubDate>Tue, 20 Oct 2020 17:00:58 +0000</pubDate>
<dc:creator>chmaynard</dc:creator>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://lwn.net/SubscriberLink/834571/e8d7adc0d9b669bc/</dc:identifier>
</item>
<item>
<title>Apple&amp;#039;s apps bypass firewalls like LittleSnitch and LuLu on macOS Big Sur</title>
<link>https://twitter.com/patrickwardle/status/1318465421796782082</link>
<guid isPermaLink="true" >https://twitter.com/patrickwardle/status/1318465421796782082</guid>
<description>&lt;p&gt;I tried to accomplish this but basically you end up with a broken installation of macOS bc XProtect signatures CRL updates etc are also affected by this - IRL Apple created a whole productportfolio of blackboxes, topnotch!nobody knows the purpose if certain systemprocesses etc 🤪&lt;/p&gt;
</description>
<pubDate>Tue, 20 Oct 2020 15:51:18 +0000</pubDate>
<dc:creator>robenkleene</dc:creator>
<dc:format>text/html</dc:format>
<dc:identifier>https://mobile.twitter.com/patrickwardle/status/1318465421796782082</dc:identifier>
</item>
<item>
<title>Backblaze Hard Drive Stats Q3 2020</title>
<link>https://www.backblaze.com/blog/backblaze-hard-drive-stats-q3-2020/</link>
<guid isPermaLink="true" >https://www.backblaze.com/blog/backblaze-hard-drive-stats-q3-2020/</guid>
<description>&lt;p&gt;&lt;img loading=&quot;lazy&quot; src=&quot;https://www.backblaze.com/blog/wp-content/uploads/2020/10/bb-hard-drive-stats-Q3.2020.jpg&quot; alt=&quot;&quot; width=&quot;1440&quot; height=&quot;820&quot; class=&quot;alignnone size-full wp-image-96446&quot; srcset=&quot;https://www.backblaze.com/blog/wp-content/uploads/2020/10/bb-hard-drive-stats-Q3.2020.jpg 1440w, https://www.backblaze.com/blog/wp-content/uploads/2020/10/bb-hard-drive-stats-Q3.2020-300x171.jpg 300w, https://www.backblaze.com/blog/wp-content/uploads/2020/10/bb-hard-drive-stats-Q3.2020-1024x583.jpg 1024w, https://www.backblaze.com/blog/wp-content/uploads/2020/10/bb-hard-drive-stats-Q3.2020-768x437.jpg 768w, https://www.backblaze.com/blog/wp-content/uploads/2020/10/bb-hard-drive-stats-Q3.2020-560x319.jpg 560w&quot; sizes=&quot;(max-width: 1440px) 100vw, 1440px&quot;/&gt;&lt;/p&gt;
&lt;p id=&quot;bzdropcap&quot;&gt;As of September 30, 2020, Backblaze had 153,727 spinning hard drives in our cloud storage ecosystem spread across four data centers. Of that number, there were 2,780 boot drives and 150,947 data drives. This review looks at the Q3 2020 and lifetime hard drive failure rates of the data drive models currently in operation in our data centers and provides a handful of insights and observations along the way. As always, we look forward to your comments.&lt;/p&gt;
&lt;h2&gt;Quarterly Hard Drive Failure Stats for Q3 2020&lt;/h2&gt;
&lt;p&gt;At the end of Q3 2020, Backblaze was using 150,974 hard drives to store customer data. For our evaluation we remove from consideration those drive models for which we did not have at least 60 drives (more on that later). This leaves us with 150,757 hard drives in our review. The table below covers what happened in Q3 2020.&lt;/p&gt;
&lt;p&gt;&lt;img loading=&quot;lazy&quot; src=&quot;https://www.backblaze.com/blog/wp-content/uploads/2020/10/AFR-Q3-2020.png&quot; alt=&quot;&quot; width=&quot;780&quot; height=&quot;780&quot; class=&quot;alignnone size-full wp-image-96501&quot; srcset=&quot;https://www.backblaze.com/blog/wp-content/uploads/2020/10/AFR-Q3-2020.png 780w, https://www.backblaze.com/blog/wp-content/uploads/2020/10/AFR-Q3-2020-300x300.png 300w, https://www.backblaze.com/blog/wp-content/uploads/2020/10/AFR-Q3-2020-150x150.png 150w, https://www.backblaze.com/blog/wp-content/uploads/2020/10/AFR-Q3-2020-768x768.png 768w, https://www.backblaze.com/blog/wp-content/uploads/2020/10/AFR-Q3-2020-80x80.png 80w, https://www.backblaze.com/blog/wp-content/uploads/2020/10/AFR-Q3-2020-560x560.png 560w&quot; sizes=&quot;(max-width: 780px) 100vw, 780px&quot;/&gt;&lt;/p&gt;
&lt;h3&gt;Observations on the Q3 Stats&lt;/h3&gt;
&lt;p&gt;There are several models with zero drive failures in the quarter. That’s great, but when we dig in a little we get different stories for each of the drives.&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;The 18TB Seagate model (ST18000NM000J) has 300 drive days and they’ve been in service for about 12 days. There were no out of the box failures which is a good start, but that’s all you can say.&lt;/li&gt;
&lt;li&gt;The 16TB Seagate model (ST16000NM001G) has 5,428 drive days which is low, but they’ve been around for nearly 10 months on average. Still, I wouldn’t try to draw any conclusions yet, but a quarter or two more like this and we might have something to say.&lt;/li&gt;
&lt;li&gt;The 4TB Toshiba model (MD04ABA400V) has only 9,108 drive days, but they have been putting up zeros for seven quarters straight. That has to count for something.&lt;/li&gt;
&lt;li&gt;The 14TB Seagate model (ST14000NM001G) has 21,120 drive days with 2,400 drives, but they have only been operational for less than one month. Next quarter will give us a better picture.&lt;/li&gt;
&lt;li&gt;The 4TB HGST (model: HMS5C4040ALE640) has 274,923 drive days with no failures this quarter. Everything else is awesome, but hold on before you run out and buy one. Why? You’re probably not going to get a new one and if you do, it will really be at least three years old, as HGST/WDC hasn’t made these drives in at least that long. If someone from HGST/WDC can confirm or deny that for us in the comments that would be great. There are stories dating back to 2016 where folks tried to order this drive and got a refurbished drive instead. If you want to give a refurbished drive a try, that’s fine, but that’s not what our numbers are based on.&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;The Q3 2020 annualized failure rate (AFR) of 0.89% is slightly higher than last quarter at 0.81%, but significantly lower than the 2.07% from a year ago. Even with the lower drive failure rates, our data center techs are not bored. In this quarter they added nearly 11,000 new drives totaling over 150PB of storage, all while operating under strict Covid-19 protocols. We’ll cover how they did that in a future post, but let’s just say they were busy.&lt;/p&gt;
&lt;h3&gt;The Island of Misfit Drives&lt;/h3&gt;
&lt;p&gt;There were 190 drives (150,947 minus 150,757) that were not included in the Q3 2020 Quarterly Chart above because we did not have at least 60 drives of a given model. Here’s a breakdown:&lt;/p&gt;
&lt;p&gt;&lt;img loading=&quot;lazy&quot; src=&quot;https://www.backblaze.com/blog/wp-content/uploads/2020/10/Island-of-Misfit-Drives-1024x650.png&quot; alt=&quot;&quot; width=&quot;1024&quot; height=&quot;650&quot; class=&quot;alignnone size-large wp-image-96499&quot; srcset=&quot;https://www.backblaze.com/blog/wp-content/uploads/2020/10/Island-of-Misfit-Drives-1024x650.png 1024w, https://www.backblaze.com/blog/wp-content/uploads/2020/10/Island-of-Misfit-Drives-300x190.png 300w, https://www.backblaze.com/blog/wp-content/uploads/2020/10/Island-of-Misfit-Drives-768x487.png 768w, https://www.backblaze.com/blog/wp-content/uploads/2020/10/Island-of-Misfit-Drives-560x355.png 560w&quot; sizes=&quot;(max-width: 1024px) 100vw, 1024px&quot;/&gt;&lt;/p&gt;
&lt;p&gt;Nearly all of these drives were used as replacement drives. This happens when a given drive model is no longer available for purchase, but we have many in operation and we need a replacement. For example, we still have three WDC 6TB drives in use; they are installed in three different Storage Pods, along with 6TB drives from Seagate and HGST. Most of these drives were new when they were installed, but sometimes we reuse a drive that was removed from service, typically via a migration. Such drives are, of course, reformatted, wiped, and then must pass our qualification process to be reinstalled.&lt;/p&gt;
&lt;p&gt;There are two “new” drives on our list. These are drives that are qualified for use in our data centers, but we haven’t deployed in quantity yet. In the case of the 10TB HGST drive, the availability and qualification of multiple 12TB models has reduced the likelihood that we would use more of this drive model. The 16TB Toshiba drive model is more likely to be deployed going forward as we get ready to deploy the next wave of big drives.&lt;/p&gt;
&lt;h3&gt;The Big Drives Are Here&lt;/h3&gt;
&lt;p&gt;When we first started collecting hard drive data back in 2013, a big drive was 4TB, with 5TB and 6TB drives just coming to market. Today, we’ll define big drives as 14TB, 16TB, and 18TB drives. The table below summarizes our current utilization of these drives.&lt;/p&gt;
&lt;p&gt;&lt;img loading=&quot;lazy&quot; src=&quot;https://www.backblaze.com/blog/wp-content/uploads/2020/10/Drives-Deployed-by-Backblaze-Q3-2020-1024x704.png&quot; alt=&quot;&quot; width=&quot;1024&quot; height=&quot;704&quot; class=&quot;alignnone size-large wp-image-96500&quot; srcset=&quot;https://www.backblaze.com/blog/wp-content/uploads/2020/10/Drives-Deployed-by-Backblaze-Q3-2020-1024x704.png 1024w, https://www.backblaze.com/blog/wp-content/uploads/2020/10/Drives-Deployed-by-Backblaze-Q3-2020-300x206.png 300w, https://www.backblaze.com/blog/wp-content/uploads/2020/10/Drives-Deployed-by-Backblaze-Q3-2020-768x528.png 768w, https://www.backblaze.com/blog/wp-content/uploads/2020/10/Drives-Deployed-by-Backblaze-Q3-2020-560x385.png 560w&quot; sizes=&quot;(max-width: 1024px) 100vw, 1024px&quot;/&gt;&lt;/p&gt;
&lt;p&gt;The total of 19,878 represents 13.2% of our operational data drives. While most of these are the 14TB Toshiba drives, all of the above have been qualified for use in our data centers.&lt;/p&gt;
&lt;p&gt;For all of the drive models besides the Toshiba 14TB drive, the number of drive days is still too small to conclude anything, although the Seagate 14TB model, the Toshiba 16TB model, and the Seagate 18TB model have experienced no failures to date.&lt;/p&gt;
&lt;p&gt;We will continue to add these large drives over the coming quarters and track them along the way. As of Q3 2020, the lifetime AFR for this group of drives is 1.04%, which as we’ll see, is below the lifetime AFR for all of the drive models in operation.&lt;/p&gt;
&lt;h3&gt;Lifetime Hard Drive Failure Rates&lt;/h3&gt;
&lt;p&gt;The table below shows the lifetime AFR for the hard drive models we had in service as of September 30, 2020. All of the drive models listed were in operation during this timeframe.&lt;br/&gt;The lifetime AFR as of Q3 2020 was 1.58%, the lowest since we started keeping track in 2013. That is down from 1.73% one year ago, and down from 1.64% last quarter.&lt;/p&gt;
&lt;p&gt;&lt;img loading=&quot;lazy&quot; src=&quot;https://www.backblaze.com/blog/wp-content/uploads/2020/10/Lifetime-AFR-Q3-2020.png&quot; alt=&quot;&quot; width=&quot;740&quot; height=&quot;760&quot; class=&quot;alignnone size-full wp-image-96496&quot; srcset=&quot;https://www.backblaze.com/blog/wp-content/uploads/2020/10/Lifetime-AFR-Q3-2020.png 740w, https://www.backblaze.com/blog/wp-content/uploads/2020/10/Lifetime-AFR-Q3-2020-292x300.png 292w, https://www.backblaze.com/blog/wp-content/uploads/2020/10/Lifetime-AFR-Q3-2020-560x575.png 560w&quot; sizes=&quot;(max-width: 740px) 100vw, 740px&quot;/&gt;&lt;/p&gt;
&lt;p&gt;We added back the average age column as “Avg Age.” This is in months and is the average age of the drives used to compute the data in the table and is based on the amount of time they have been in operation. One thing to remember is that our environment is very dynamic with drives being added, being migrated, and leaving on a regular basis and this could impact the average age. For example, we could retire a Storage Pod with mostly older drives and that could lower the average age of the remaining drives of that model while those remaining drives got older.&lt;/p&gt;
&lt;p&gt;Looking at the average age, the 6TB Seagate drives are the oldest cohort, averaging nearly five and a half years of service each. These drives have actually gotten better over the last couple years and are aging well with a current lifetime AFR of 1.0%.&lt;/p&gt;
&lt;div class=&quot;abstract&quot; readability=&quot;11.940740740741&quot;&gt;If you’d like to learn more, join us for a &lt;a href=&quot;https://www.brighttalk.com/webcast/14807/446738?utm_source=Bzwebsite&amp;amp;utm_medium=Blog&amp;amp;utm_campaign=webinar_general&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;webinar Q&amp;amp;A&lt;/a&gt; with the author of Hard Drive Stats, Andy Klein, on October 22, 10:00 a.m. PT.&lt;/div&gt;
&lt;h2&gt;The Hard Drive Stats Data&lt;/h2&gt;
&lt;p&gt;The complete data set used to create the information used in this review is available on our &lt;a href=&quot;https://www.backblaze.com/b2/hard-drive-test-data.html&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;Hard Drive Test Data webpage&lt;/a&gt;. You can download and use this data for free for your own purpose. All we ask are three things: 1) You cite Backblaze as the source if you use the data, 2) You accept that you are solely responsible for how you use the data, and 3) You do not sell this data to anyone—it is free.&lt;/p&gt;
&lt;p&gt;If you just want the summarized data used to create the tables and charts in this blog post, you can &lt;a href=&quot;https://f001.backblazeb2.com/file/Backblaze_Blog/Q3_2020_Drive_Stats_Tables.zip&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;download the ZIP file&lt;/a&gt; containing the MS Excel spreadsheet.&lt;/p&gt;
&lt;p&gt;Good luck and let us know if you find anything interesting.&lt;/p&gt;


</description>
<pubDate>Tue, 20 Oct 2020 15:01:25 +0000</pubDate>
<dc:creator>LaSombra</dc:creator>
<og:type>article</og:type>
<og:title>Backblaze Hard Drive Stats Q3 2020</og:title>
<og:description>This review looks at the Q3 2020 and lifetime hard drive failure rates of the data drive models currently in operation in our data centers. We also share a handful of insights and observations along the way.</og:description>
<og:url>https://www.backblaze.com/blog/backblaze-hard-drive-stats-q3-2020/</og:url>
<og:image>https://www.backblaze.com/blog/wp-content/uploads/2020/10/bb-hard-drive-stats-Q3.2020.jpg</og:image>
<dc:language>en-US</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.backblaze.com/blog/backblaze-hard-drive-stats-q3-2020/</dc:identifier>
</item>
<item>
<title>Nokia selected by NASA to build cellular network on the moon</title>
<link>https://www.reuters.com/article/nokia-nasa-moon-idUSKBN2741JR</link>
<guid isPermaLink="true" >https://www.reuters.com/article/nokia-nasa-moon-idUSKBN2741JR</guid>
<description>&lt;div class=&quot;ArticleBody-byline-container-3H6dy&quot;&gt;
&lt;p class=&quot;Byline-byline-1sVmo ArticleBody-byline-10B7D&quot;&gt;By &lt;a class=&quot;TextLabel__text-label___3oCVw TextLabel__black-to-orange___23uc0 TextLabel__serif___3lOpX Byline-author-2BSir&quot; href=&quot;https://www.reuters.com/journalists/anne-kauranen&quot; target=&quot;_blank&quot;&gt;Anne Kauranen&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;ArticleBody-read-time-and-social-2VOIr&quot;&gt;
&lt;p class=&quot;TextLabel__text-label___3oCVw TextLabel__gray___1V4fk TextLabel__small-all-caps-spaced-out___3O9H4 ReadTime-read-time-1s3CG ArticleBody-read-time-29pGN&quot;&gt;2 Min Read&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;p class=&quot;Paragraph-paragraph-2Bgue ArticleBody-para-TD_9x&quot;&gt;HELSINKI (Reuters) - Struggling to get a phone signal at home on planet Earth? Perhaps you’ll have better luck on the moon.&lt;/p&gt;
&lt;p class=&quot;Paragraph-paragraph-2Bgue ArticleBody-para-TD_9x&quot;&gt;Nokia has been selected by NASA to build the first cellular network on the moon, the Finnish company said on Monday, as the U.S. space agency plans for a future where humans return there and establish lunar settlements.&lt;/p&gt;
&lt;p class=&quot;Paragraph-paragraph-2Bgue ArticleBody-para-TD_9x&quot;&gt;NASA aims to return humans to the moon by 2024 and dig in for a long-term presence there under its Artemis programme.&lt;/p&gt;

&lt;p class=&quot;Paragraph-paragraph-2Bgue ArticleBody-para-TD_9x&quot;&gt;Nokia said the first wireless broadband communications system in space would be built on the lunar surface in late 2022, before humans make it back there.&lt;/p&gt;
&lt;p class=&quot;Paragraph-paragraph-2Bgue ArticleBody-para-TD_9x&quot;&gt;It will partner with a Texas-based private space craft design company, Intuitive Machines, to deliver the equipment to the moon on their lunar lander. The network will configure itself and establish a 4G/LTE communications system on the moon, Nokia said, though the aim would be to eventually switch to 5G&lt;/p&gt;
&lt;p class=&quot;Paragraph-paragraph-2Bgue ArticleBody-para-TD_9x&quot;&gt;The network will give astronauts voice and video communications capabilities, and allow telemetry and biometric data exchange, as well as the deployment and remote control of lunar rovers and other robotic devices, according to the company.&lt;/p&gt;

&lt;p class=&quot;Paragraph-paragraph-2Bgue ArticleBody-para-TD_9x&quot;&gt;The network will be designed to withstand the extreme conditions of the launch and lunar landing, and to operate in space. It will have to be sent to the moon in an extremely compact form to meet the stringent size, weight and power constraints of space payloads.&lt;/p&gt;
&lt;p class=&quot;Paragraph-paragraph-2Bgue ArticleBody-para-TD_9x&quot;&gt;Nokia said the network would be using 4G/LTE, in use worldwide for the last decade, instead of the latest 5G technology, because the former was a more known quantity with proven reliability. The company would also “pursue space applications of LTE’s successor technology, 5G”.&lt;/p&gt;
&lt;div readability=&quot;4.8416666666667&quot;&gt;
&lt;div class=&quot;Attribution-attribution-Y5JpY&quot; readability=&quot;7&quot;&gt;
&lt;p&gt;Reporting by Anne Kauranen; Editing by Edmund Blair and Pravin Char&lt;/p&gt;
&lt;/div&gt;

&lt;/div&gt;
</description>
<pubDate>Tue, 20 Oct 2020 14:10:33 +0000</pubDate>
<dc:creator>kungfudoi</dc:creator>
<og:title>Got any signal up here? Nokia to build mobile network on the moon</og:title>
<og:description>Struggling to get a phone signal at home on planet Earth? Perhaps you'll have better luck on the moon.</og:description>
<og:image>https://static.reuters.com/resources/r/?m=02&amp;d=20201019&amp;t=2&amp;i=1538026721&amp;r=LYNXMPEG9I0Z8&amp;w=800</og:image>
<og:url>https://www.reuters.com/article/nokia-nasa-moon-idUSKBN2741JR</og:url>
<og:type>article</og:type>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.reuters.com/article/nokia-nasa-moon-idUSKBN2741JR</dc:identifier>
</item>
<item>
<title>Firefox 82</title>
<link>https://www.mozilla.org/en-US/firefox/82.0/releasenotes/</link>
<guid isPermaLink="true" >https://www.mozilla.org/en-US/firefox/82.0/releasenotes/</guid>
<description>[unable to retrieve full-text content]
&lt;p&gt;Article URL: &lt;a href=&quot;https://www.mozilla.org/en-US/firefox/82.0/releasenotes/&quot;&gt;https://www.mozilla.org/en-US/firefox/82.0/releasenotes/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Comments URL: &lt;a href=&quot;https://news.ycombinator.com/item?id=24837433&quot;&gt;https://news.ycombinator.com/item?id=24837433&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Points: 314&lt;/p&gt;
&lt;p&gt;# Comments: 211&lt;/p&gt;
</description>
<pubDate>Tue, 20 Oct 2020 14:08:02 +0000</pubDate>
<dc:creator>agurk</dc:creator>
<og:type>website</og:type>
<og:url>https://www.mozilla.org/en-US/firefox/82.0/releasenotes/</og:url>
<og:image>https://www.mozilla.org/media/protocol/img/logos/firefox/browser/og.4ad05d4125a5.png</og:image>
<og:title>Firefox  82.0, See All New Features, Updates and Fixes</og:title>
<og:description></og:description>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.mozilla.org/en-US/firefox/82.0/releasenotes/</dc:identifier>
</item>
<item>
<title>When you tell Chrome to wipe private data it spares Google.com and YouTube</title>
<link>https://www.theregister.com/2020/10/19/google_cookie_wipe/</link>
<guid isPermaLink="true" >https://www.theregister.com/2020/10/19/google_cookie_wipe/</guid>
<description>&lt;p&gt;&lt;strong class=&quot;trailer&quot;&gt;Updated&lt;/strong&gt; Google exempts its own websites from Chrome's automatic data-scrubbing feature, allowing the ads giant to potentially track you even when you've told it not to.&lt;/p&gt;
&lt;p&gt;Programmer Jeff Johnson noticed the unusual behavior, and this month &lt;a target=&quot;_blank&quot; href=&quot;https://lapcatsoftware.com/articles/chrome-google.html&quot;&gt;documented&lt;/a&gt; the issue with screenshots. In his assessment of the situation, he noted that if you set up Chrome, on desktop at least, to automatically delete all cookies and so-called site data when you quit the browser, it deletes it all as expected – except your site data for Google.com and YouTube.com.&lt;/p&gt;
&lt;p&gt;While cookies are typically used to identify you and store some of your online preferences when visiting websites, site data is on another level: it includes, among other things, a &lt;a target=&quot;_blank&quot; rel=&quot;nofollow&quot; href=&quot;https://developer.mozilla.org/en-US/docs/Web/API/Window/localStorage&quot;&gt;storage database&lt;/a&gt; in which a site can &lt;a target=&quot;_blank&quot; rel=&quot;nofollow&quot; href=&quot;https://dev.to/rdegges/please-stop-using-local-storage-1i04&quot;&gt;store personal information&lt;/a&gt; about you, on your computer, that can be accessed again by the site the next time you visit. Thus, while your Google and YouTube cookies may be wiped by Chrome, their site data remains on your computer, and it could, in future, be used to identify you.&lt;/p&gt;
&lt;p&gt;Johnson noted that after he configured Chrome to wipe all cookies and site data when the application closed, everything was cleared as expected for sites like apple.com. Yet, the main Google search site and video service YouTube were allowed to keep their site data, though the cookies were gone. If Google chooses at some point to stash the equivalent of your Google cookies in the Google.com site data storage, they could be retrieved next time you visit Google, and identify you, even though you thought you'd told Chrome not to let that happen.&lt;/p&gt;
&lt;div class=&quot;promo_article&quot;&gt;&lt;img src=&quot;https://regmedia.co.uk/2020/02/05/shutterstock_google_chrome.jpg?x=174&amp;amp;y=115&amp;amp;crop=1&quot; width=&quot;174&quot; height=&quot;115&quot; alt=&quot;Google Chrome logo&quot;/&gt;&lt;h2 title=&quot;Browser quitters say they'll return if web goliath lives up to privacy promises&quot;&gt;We're suing Google for harvesting our personal info even though we opted out of Chrome sync – netizens&lt;/h2&gt;
&lt;a href=&quot;https://www.theregister.com/2020/07/28/google_chrome_privacy_lawsuit/&quot;&gt;&lt;span&gt;READ MORE&lt;/span&gt;&lt;/a&gt;&lt;/div&gt;
&lt;p&gt;Ultimately, it potentially allows Google, and only Google, to continue tracking Chrome users who opted for some more privacy; something that is enormously valuable to the internet goliath in delivering ads. Many users set Chrome to automatically delete cookies-and-site-data on exit for that reason – to prevent being stalked around the web – even though it often requires them to log back into websites the next time they visit due to their per-session cookies being wiped.&lt;/p&gt;
&lt;p&gt;Yet Google appears to have granted itself an exception. The situation recalls a similar issue over location tracking, where Google &lt;a target=&quot;_blank&quot; href=&quot;https://www.theregister.com/2018/08/13/google_location_tracking/&quot;&gt;continued to track&lt;/a&gt; people’s location through their apps even when users actively selected the option to prevent that. Google had put the real option to start location tracking under a different setting that didn’t even include the word “location.”&lt;/p&gt;
&lt;p&gt;In this case, “Clear cookies and site data when you quit Chrome” doesn’t actually mean what it says, at least not for Google.&lt;/p&gt;
&lt;p&gt;There is a workaround: you can manually add “Google.com” and “YouTube.com” within the browser to a list of “Sites that can never use cookies.” In that case, no information, not even site data, is saved from those sites, which is all in all a little confusing.&lt;/p&gt;
&lt;h3 class=&quot;crosshead&quot;&gt;&lt;span&gt;Just a bug?&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;Johnson tried to give Google the benefit of the doubt, and suggested “perhaps this is just a Google Chrome bug, not intentional behavior” though noted: “The question is why it only affects Google sites, not non-Google sites.” Site data can include cached files, we note.&lt;/p&gt;
&lt;p&gt;This is very far from the first time that Google has been accused of storing personal information despite clear user intent. In July, it was &lt;a target=&quot;_blank&quot; href=&quot;https://www.theregister.com/2020/07/28/google_chrome_privacy_lawsuit/&quot;&gt;sued&lt;/a&gt; by Chrome users who accusing the mega-corp of collecting personal information despite their decision not to sync data stored in Chrome with a Google Account.&lt;/p&gt;
&lt;p&gt;&quot;Google intentionally and unlawfully causes Chrome to record and send users’ personal information to Google regardless of whether a user elects to Sync or even has a Google account,&quot; the lawsuit stated.&lt;/p&gt;
&lt;p&gt;And in February, it was &lt;a target=&quot;_blank&quot; href=&quot;https://www.theregister.com/2020/02/05/google_chrome_id_numbers/&quot;&gt;accused&lt;/a&gt; of sending what looked like per-installation ID numbers to Google, which developers said could also be used to track people across the web, and which may violate Europe's General Data Protection Regulation, because the identifier could be considered to be personally identifiable data.&lt;/p&gt;
&lt;p&gt;In response, Google insisted the numbers only included information about the variation of Chrome being used, rather than a unique fingerprint. However, shortly afterward it &lt;a target=&quot;_blank&quot; href=&quot;https://www.theregister.com/2020/03/11/google_personally_identifiable_info/&quot;&gt;changed the description&lt;/a&gt; of the identifier and removed a section that said it “will not contain any personally identifiable information, and will only describe the state of the installation of Chrome itself,” rewriting it in impenetrable language to say instead “a subset of low entropy variations are included in network requests sent to Google. The combined state of these variations is non-identifying, since it is based on a 13-bit low entropy value.”&lt;/p&gt;
&lt;h3 class=&quot;crosshead&quot;&gt;&lt;span&gt;Investigations&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;Google is being investigated by the US government and European Union for operating services without following its own rules and unfairly promoting its own services over those of competitors.&lt;/p&gt;
&lt;p&gt;The search giant also announced earlier this year it was planning to kill off all third-party cookies by the end of 2021, as has already been done by Safari and Firefox. Though it will still retain first-party cookies and, it seems, give its own sites special preference in Chrome.&lt;/p&gt;
&lt;p&gt;We asked Google for an explanation. We will update this story if it gets back to us. ®&lt;/p&gt;
&lt;h3 class=&quot;crosshead&quot;&gt;&lt;span&gt;Updated to add&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;A Google spokesperson has been in touch to say the issue is a programming error, and will be fixed: &quot;We are aware of a bug in Chrome that is impacting how cookies are cleared on some first-party Google websites. We are investigating the issue, and plan to roll out a fix in the coming days.&quot;&lt;/p&gt;

</description>
<pubDate>Tue, 20 Oct 2020 14:04:50 +0000</pubDate>
<dc:creator>maltalex</dc:creator>
<og:image>https://regmedia.co.uk/2016/05/19/google_photo_by_lightpoet_via_shutterstock.jpg</og:image>
<og:type>article</og:type>
<og:url>https://www.theregister.com/2020/10/19/google_cookie_wipe/</og:url>
<og:title>When you tell Chrome to wipe private data about you, it spares two websites from the purge: Google.com, YouTube</og:title>
<og:description>Is this another case of one rule for the Chocolate Factory and one for everyone else?</og:description>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.theregister.com/2020/10/19/google_cookie_wipe/</dc:identifier>
</item>
<item>
<title>Combating abuse in Matrix – without backdoors</title>
<link>https://www.matrix.org/blog/2020/10/19/combating-abuse-in-matrix-without-backdoors</link>
<guid isPermaLink="true" >https://www.matrix.org/blog/2020/10/19/combating-abuse-in-matrix-without-backdoors</guid>
<description>&lt;p&gt;Hi all,&lt;/p&gt;
&lt;p&gt;Last Sunday, the UK Government published an &lt;a href=&quot;https://www.gov.uk/government/publications/international-statement-end-to-end-encryption-and-public-safety&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;international statement on end-to-end encryption and public safety&lt;/a&gt;, co-signed by representatives from the US, Australia, New Zealand, Canada, India and Japan. The statement is well written and well worth a read in full, but the central point is this:&lt;/p&gt;
&lt;blockquote readability=&quot;9&quot;&gt;
&lt;p&gt;We call on technology companies to [...] enable law enforcement access to content in a readable and usable format where an authorisation is lawfully issued, is necessary and proportionate, and is subject to strong safeguards and oversight.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;In other words, this is an explicit request from seven of the biggest governments in the world to mandate a backdoor in end-to-end encrypted (E2EE) communication services: a backdoor to which the authorities have a secret key, letting them view communication on demand. This is big news, and is of direct relevance to Matrix as an end-to-end encrypted communication protocol whose core team is currently centred in the UK.&lt;/p&gt;
&lt;p&gt;Now, we sympathise with the authorities’ predicament here: we utterly abhor child abuse, terrorism, fascism and similar - and we did not build Matrix to enable it. However, trying to mitigate abuse with backdoors is, unfortunately, &lt;strong&gt;fundamentally flawed&lt;/strong&gt;.&lt;/p&gt;
&lt;ul readability=&quot;16.306930693069&quot;&gt;&lt;li readability=&quot;8.6598837209302&quot;&gt;
&lt;p&gt;Backdoors necessarily introduce a fatal weak point into encryption for &lt;em&gt;everyone&lt;/em&gt;, which then becomes the ultimate high value target for attackers. Anyone who can determine the secret needed to break the encryption will gain full access, and you can be absolutely sure &lt;strong&gt;&lt;a href=&quot;https://techcrunch.com/2016/07/27/security-experts-have-cloned-all-seven-tsa-master-keys/&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;the backdoor key will leak&lt;/a&gt;&lt;/strong&gt; - whether that’s via intrusion, social engineering, brute-force attacks, or accident. And even if you unilaterally trust your current government to be responsible with the keys to the backdoor, is it wise to unilaterally trust their successors? Computer security is only ever a matter of degree, and the only safe way to keep a secret like this safe is for it not to exist in the first place.&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;6&quot;&gt;
&lt;p&gt;End-to-end encryption is nowadays a completely ubiquitous technology; &lt;strong&gt;an attempt to legislate against it is like trying to turn back the tide&lt;/strong&gt; or declare a branch of mathematics illegal. Even if Matrix did compromise its encryption, users could easily use any number of other approaches to additionally secure their conversations - from PGP, to OTR, to using one-time pads, to sharing content in password-protected ZIP files. Or they could just switch to a E2EE chat system operating from a jurisdiction without backdoors.&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;5&quot;&gt;
&lt;p&gt;Governments protect their own data using end-to-end encryption, precisely because they do not want other governments being able to snoop on them. So not only is it hypocritical for governments to argue for backdoors, &lt;strong&gt;it immediately puts their own governmental data at risk of being compromised&lt;/strong&gt;. Moreover, creating infrastructure for backdoors sets an incredibly bad precedent to the rest of the world - where less salubrious governments will inevitably use the same technology to the massive detriment of their citizens’ human rights.&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;7&quot;&gt;
&lt;p&gt;Finally, in Matrix’s specific case: Matrix is an encrypted decentralised open network powered by open source software, where anyone can run a server. Even if the Matrix core team were obligated to add a backdoor, this would be visible to the wider world - and &lt;strong&gt;there would be no way to make the wider network adopt it&lt;/strong&gt;. It would just damage the credibility of the core team, push encryption development to other countries, and the wider network would move on irrespectively.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;In short, we need to keep E2EE as it is so that it benefits the 99.9% of people who are good actors. If we enforce backdoors and undermine it, then the bad 0.1% percent simply will switch to non-backdoored systems while the 99.9% are left vulnerable.&lt;/p&gt;
&lt;p&gt;We’re not alone in thinking this either: the GDPR (the world-leading regulation towards data protection and privacy) explicitly calls out robust encryption as a necessary information security measure. In fact, the risk of US governmental backdoors explicitly caused the &lt;a href=&quot;http://curia.europa.eu/juris/document/document.jsf?docid=228677&amp;amp;doclang=EN&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;European Court of Justice to invalidate the Privacy Shield&lt;/a&gt; for EU-&amp;gt;US data. The position of the seven governments here (alongside &lt;a href=&quot;https://ec.europa.eu/home-affairs/sites/homeaffairs/files/what-we-do/policies/european-agenda-security/20200724_com-2020-607-commission-communication_en.pdf&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;recent communications by the EU commissioner&lt;/a&gt; on the ‘problem’ of encryption) is a significant step back on the protection of the fundamental right of privacy.&lt;/p&gt;
&lt;p&gt;So, how do we solve this predicament for Matrix?&lt;/p&gt;
&lt;p&gt;Thankfully: &lt;strong&gt;there is another way.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;This statement from the seven governments aims to protect the general public from bad actors, but it clearly undermines the good ones. What we &lt;em&gt;really&lt;/em&gt; need is something that empowers users and administrators to identify and protect themselves from bad actors, without undermining privacy.&lt;/p&gt;
&lt;p&gt;What if we had a standard way to let users themselves build up and share their own views of whether other users, messages, rooms, servers etc. are obnoxious or not? What if you could visualise and choose which filters to apply to your view of Matrix?&lt;/p&gt;
&lt;p&gt;Just like the Web, Email or the Internet as a whole, there is literally no way to unilaterally censor or block content in Matrix. But what we &lt;em&gt;can&lt;/em&gt; do is provide first-class infrastructure to let users (and room/community moderators and server admins) make up their own mind about who to trust, and what content to allow. This would also provide a means for authorities to publish reputation data about illegal content, providing a privacy-respecting mechanism that admins/mods/users can use to keep illegal content away from their servers/clients.&lt;/p&gt;
&lt;p&gt;The model we currently have in mind is:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;Anyone can gather reputation data about Matrix rooms / users / servers / communities / content, and publish it to as wide or narrow an audience as they like - providing their subjective score on whether something in Matrix is positive or negative in a given context.&lt;/li&gt;
&lt;li&gt;This reputation data is published in a privacy preserving fashion - i.e. you can look up reputation data if you know the ID being queried, but the data is stored pseudonymised (e.g. indexed by a hashed ID).&lt;/li&gt;
&lt;li&gt;Anyone can subscribe to reputation feeds and blend them together in order to inform how they filter their content. The feeds might be their own data, or from their friends, or from trusted sources (e.g. a fact-checking company). Their blended feed can be republished as their own.&lt;/li&gt;
&lt;li&gt;To prevent users getting trapped in a factional filter bubble of their own devising, we’ll provide UI to visualise and warn about the extent of their filtering - and make it easy and fun to shift their viewpoint as needed.&lt;/li&gt;
&lt;li&gt;Admins running servers in particular jurisdictions then have the option to enforce whatever rules they need on their servers (e.g. they might want to subscribe to reputation feeds from a trusted source such as &lt;a href=&quot;https://www.iwf.org.uk/&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;the IWF&lt;/a&gt;, identifying child sexual abuse content, and use it to block it from their server).&lt;/li&gt;
&lt;li&gt;This isn’t just about combating abuse - but the same system can also be used to empower users to filter out spam, propaganda, unwanted NSFW content, etc on their own terms.&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;This forms a &lt;em&gt;relative&lt;/em&gt; reputation system. As uncomfortable as it may be, one man’s terrorist is another man’s freedom fighter, and different jurisdictions have different laws - and it’s not up to the Matrix.org Foundation to play God and adjudicate. Each user/moderator/admin should be free to make up their own mind and decide which reputation feeds to align themselves with. That is not to say that this system would help users locate extreme content - the privacy-preserving nature of the reputation data means that it’s only useful to filter &lt;em&gt;out&lt;/em&gt; material which would otherwise already be visible to you - not to locate new content.&lt;/p&gt;
&lt;p&gt;In terms of how this interacts with end-to-end-encryption and mitigating abuse: the reality is that the vast majority of abuse in public networks like Matrix, the Web or Email is visible from the public unencrypted domain. Abusive communities generally want to attract/recruit/groom users - and that means providing a public front door, which would be flagged by a reputation system such as the one proposed above. Meanwhile, communities which are entirely private and entirely encrypted typically still have touch-points with the rest of the world - and even then, the chances are extremely high that they will avoid any hypothetical backdoored servers. In short, investigating such communities requires traditional infiltration and surveillance by the authorities rather than an ineffective backdoor.&lt;/p&gt;
&lt;p&gt;Now, this approach may sound completely sci-fi and implausibly overambitious (our speciality!) - but we’ve actually started successfully building this already, having been refining the idea over the last few years. &lt;a href=&quot;https://github.com/matrix-org/matrix-doc/blob/msc2313/proposals/2313-moderation-policy-rooms.md&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;MSC2313&lt;/a&gt; is a first cut at the idea of publishing and subscribing to reputation data - starting off with simple binary ban rules. It’s been implemented and in production for over a year now, and is used to maintain shared banlists used by both matrix.org and mozilla.org communities. The next step is to expand this to support a blendable continuum of reputation data (rather than just binary banlists), make it privacy preserving, and get working on the client UX for configuring and visualising them.&lt;/p&gt;
&lt;p&gt;Finally: we are continuing to hire a dedicated Reputation Team to work full time on building this (kindly funded by Element). This is a major investment in the future of Matrix, and frankly is spending money that we don’t really have - but it’s critical to the long-term success of the project, and perhaps the health of the Internet as a whole. There’s nothing about a good relative reputation system which is particularly specific to Matrix, after all, and many other folks (decentralised and otherwise) are clearly in desperate need of one too. We are actively looking for funding to support this work, so if you’re feeling rich and philanthropic (or a government wanting to support a more enlightened approach) we would &lt;em&gt;love&lt;/em&gt; to hear from you at &lt;a href=&quot;https://www.matrix.org/cdn-cgi/l/email-protection#8fe9fae1ebe6e1e8cfe2eefbfde6f7a1e0fde8&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;&lt;span class=&quot;__cf_email__&quot; data-cfemail=&quot;6f091a010b0601082f020e1b1d061741001d08&quot;&gt;[email protected]&lt;/span&gt;&lt;/a&gt;!&lt;/p&gt;
&lt;p&gt;Here’s to a world where users have excellent tools to protect themselves online - and a world where their safety is not compromised by encryption backdoors.&lt;/p&gt;
&lt;p&gt;-- The Matrix.org Core Team&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Comments scattered over &lt;a href=&quot;https://news.ycombinator.com/item?id=24826951&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;HN&lt;/a&gt;, &lt;a href=&quot;https://lobste.rs/s/ntyvtw/combating_abuse_matrix_without&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;lobste.rs&lt;/a&gt;, and &lt;a href=&quot;https://www.reddit.com/r/linux/comments/je8s7x/combating_abuse_in_matrix_without_backdoors/&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;r/linux&lt;/a&gt;... and &lt;a href=&quot;https://news.ycombinator.com/item?id=24836987&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;HN again&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
</description>
<pubDate>Tue, 20 Oct 2020 13:27:29 +0000</pubDate>
<dc:creator>jeltz</dc:creator>
<og:url>https://matrix.org/blog/2020/10/19/combating-abuse-in-matrix-without-backdoors</og:url>
<og:type>article</og:type>
<og:title>Combating abuse in Matrix - without backdoors. | Matrix.org</og:title>
<og:image>https://matrix.org/blog/img/matrix-logo.png</og:image>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.matrix.org/blog/2020/10/19/combating-abuse-in-matrix-without-backdoors/</dc:identifier>
</item>
<item>
<title>Pitch: Collaborative presentation software for teams</title>
<link>https://pitch.com/blog/pitch-launches</link>
<guid isPermaLink="true" >https://pitch.com/blog/pitch-launches</guid>
<description>&lt;p&gt;After two years of immense effort and a year-long beta that included more than 25,000 teams, including those at Intercom, Grammarly, and Notion, we’re finally ready to open Pitch up to everyone. While today’s launch is a massive milestone, it’s also just the first step toward our ultimate goal of transforming how the world shapes and shares information.&lt;/p&gt;
&lt;p&gt;Many of us have been using presentation software for the better part of our lives. Why build another one? It’s simple: The tools we’ve grown up with haven’t grown up with us. Legacy presentation tools force you into workarounds and compromises that slow you down and limit what you can do.&lt;/p&gt;
&lt;p&gt;We’ve built Pitch to be &lt;strong&gt;uncompromisingly good&lt;/strong&gt; presentation software — purpose-built for the needs of power users and teams like yours. Now you can get everything done, together, in one place. Without sacrificing on collaboration, aesthetics, or speed.&lt;/p&gt;
&lt;p&gt;Along with today’s launch, we’re also introducing live video collaboration, a first-of-its-kind feature that builds on the seamless collaboration experience our customers already love.&lt;/p&gt;
&lt;h4&gt;Create together with live video collaboration&lt;/h4&gt;
&lt;p&gt;When we started Pitch, we set out to build the fastest and most collaborative way to create beautiful presentations. From the very beginning, we enabled teams to discuss ideas, co-create, delegate work, and track progress — all in one place.&lt;/p&gt;
&lt;p&gt;The only thing you couldn’t do was chat face to face in Pitch. Until now.&lt;/p&gt;
&lt;p&gt;Today, we’re introducing live video collaboration. Start a video call directly in a presentation and work together in real-time. Use it to discuss a deck, hold a team meeting, or simply have an informal chat. Live video collaboration generates the kind of spontaneous collaboration and free flow of ideas that many of us took advantage of when working in a shared space with our team.&lt;/p&gt;
&lt;h4&gt;Design beautiful decks in record time&lt;/h4&gt;
&lt;p&gt;Throughout our beta, customers raved about Pitch’s ease of use and the time they saved when creating new presentations. Every part of Pitch was crafted to help teams move quickly while improving the end result of their work, in particular:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Stylish and flexible templates&lt;/strong&gt;: We pride ourselves on creating templates that are beautiful, informative, and practical. Our template gallery now has more than 40 custom-crafted templates built around visual themes and real-world use cases. With presentation styles, it takes literal seconds to customize our templates to make them look like yours.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;A powerfully simple editing experience&lt;/strong&gt;: We designed our editor to be the fastest, most intuitive way to create presentations, no matter your design skills. And then we redesigned it to be even better. Working with Pitch feels new and unique while being familiar in all of the best ways. There’s no learning curve — just point, click, create.&lt;/p&gt;
&lt;h4&gt;Bring slides to life with powerful integrations&lt;/h4&gt;
&lt;p&gt;Pitch connects seamlessly with a variety of sources to help every deck look its best. In addition to our current integrations, like Unsplash, Giphy, YouTube, and Loom, we’ve recently introduced support for Google Analytics and Google Sheets. Now you can easily create charts that are up-to-date and accurate without having to manually copy and paste information.&lt;/p&gt;&lt;p&gt;This is just the beginning. We’re already working on our next batch of integrations — Stripe, Typeform, and Mailchimp — and in 2021, we plan to open Pitch up to developers and partners who can build on top of Pitch.&lt;/p&gt;
&lt;h4&gt;Make next-level decks with Pitch Pro&lt;/h4&gt;
&lt;p&gt;With our launch, we’re officially introducing a free plan as well as our premium plan, Pitch Pro.&lt;/p&gt;
&lt;img alt=&quot;&quot; src=&quot;https://res.cloudinary.com/pitch-software/image/upload/v1603114261/blog/launch_pro_pricing.jpg&quot;/&gt;&lt;p&gt;Ideal for individuals and small teams, our Starter plan is and will always be free. We don’t want to limit your team’s ability to make beautiful, on-brand decks; therefore each workspace comes with unlimited users, presentations, templates, and font uploads.&lt;/p&gt;
&lt;p&gt;Pitch Pro is for power users and fast-growing teams that use presentations as a way to build their business. Core features include additional permissions, video uploads, and unbranded PDF exports. Pitch Pro costs $10 per user, per month. You can take a closer look at each plan &lt;a href=&quot;http://pitch.com/pricing&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;h4&gt;Looking back on the past year&lt;/h4&gt;
&lt;p&gt;We’ve learned a lot about building a product, scaling our team, and processing customer feedback. We literally have thousands of entries on our product roadmap. There's still plenty we need and want to build, but we’ve made remarkable progress, &lt;a href=&quot;https://pitch.com/whats-new&quot;&gt;shipping 72 new features, 210 improvements, and 260 bug fixes&lt;/a&gt; throughout the course of our beta.&lt;/p&gt;
&lt;p&gt;Our team grew an incredible amount this year — from 60 to 90 while being fully remote. Our own product has become an essential tool for onboarding new hires and keeping teams connected. We have big ambitions for 2021 and beyond. If you’re ready for your next adventure, we’d love to hear from you! &lt;a href=&quot;https://pitch.com/about#hiring&quot;&gt;Browse our jobs page&lt;/a&gt; to see all available positions.&lt;/p&gt;
&lt;p&gt;Hands down, the most rewarding part of this journey has been working with customers, who have been unbelievably generous with their time and attention. Knowing that our product is already helping teams work faster and more collaboratively has been unbelievably motivating. It gets us even more excited for everything we’re building. Here are a few examples of how Pitch is supporting teams of all sizes.&lt;/p&gt;
&lt;img alt=&quot;&quot; src=&quot;https://res.cloudinary.com/pitch-software/image/upload/v1602854526/blog/launch_reviews.jpg&quot;/&gt;&lt;h4&gt;What’s next for Pitch?&lt;/h4&gt;
&lt;p&gt;Building presentation software from the ground up is no easy feat. Since starting out, we’ve worked to balance laying the foundation with pushing the envelope for what modern presentation software can and should do. Over the next year, we’ll continue that approach while we work to:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Support every device you create on&lt;/strong&gt;: Our iOS app is already in beta and will launch soon; Android will follow soon after.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Help you connect any type of idea&lt;/strong&gt;: We’re doubling down on media and data integrations to help bring your presentations to life.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Close the loop on receiving feedback&lt;/strong&gt;: Upcoming features like presentation analytics will make it easy to optimize your work without having to upload your decks to yet another piece of software.&lt;/p&gt;
&lt;p&gt;Today’s launch is the result of thousands of hours of conversations, brainstorming sessions, and meetings with presentation creators. We’ve worked to create something that can unlock your team’s best thinking and help you share that knowledge anywhere. But it’s just the start. As we continue building Pitch, we want to hear from you. We’re on this journey together, and we can’t wait to show you what’s next.&lt;/p&gt;
</description>
<pubDate>Tue, 20 Oct 2020 12:49:54 +0000</pubDate>
<dc:creator>zcam</dc:creator>
<og:title>Don’t just present. Pitch.</og:title>
<og:image>https://res.cloudinary.com/pitch-software/image/upload/v1603120737/blog/Social_share.jpg</og:image>
<og:description>Today, we’re launching Pitch to the world. Learn how we’re modernizing presentation software to help teams stay connected and do their best work.</og:description>
<og:type>website</og:type>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://pitch.com/blog/pitch-launches</dc:identifier>
</item>
</channel>
</rss>