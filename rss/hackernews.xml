<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="css/feed.xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/" xmlns:og="http://ogp.me/ns#">
<channel>
<atom:link rel="self" href="http://192.168.1.4/fivefilters/makefulltextfeed.php?url=hnrss.org%2Fnewest%3Fpoints%3D200&amp;max=10&amp;links=preserve&amp;exc=" />
<atom:link rel="alternate" title="Source URL" href="http://hnrss.org/newest?points=200" />
<atom:link rel="related" title="Subscribe to feed" href="http://www.subtome.com/#/subscribe?feeds=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dhnrss.org%252Fnewest%253Fpoints%253D200%26max%3D10%26links%3Dpreserve%26exc%3D&amp;back=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dhnrss.org%252Fnewest%253Fpoints%253D200%26max%3D10%26links%3Dpreserve%26exc%3D" />
<title>Hacker News: Newest</title>
<link>https://news.ycombinator.com/newest</link>
<description>Hacker News RSS</description>
<item>
<title>Verizon/Yahoo Blocking All Attempts to Archive.org Groups. Deletion: Dec.14</title>
<link>https://modsandmembersblog.wordpress.com/2019/12/08/verizon-yahoo-bad-form/</link>
<guid isPermaLink="true" >https://modsandmembersblog.wordpress.com/2019/12/08/verizon-yahoo-bad-form/</guid>
<description>&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://modsandmembersblog.files.wordpress.com/2013/10/strsshoot.jpg&quot;&gt;&lt;img data-attachment-id=&quot;101&quot; data-permalink=&quot;https://modsandmembersblog.wordpress.com/?attachment_id=101&quot; data-orig-file=&quot;https://modsandmembersblog.files.wordpress.com/2013/10/strsshoot.jpg&quot; data-orig-size=&quot;802,962&quot; data-comments-opened=&quot;1&quot; data-image-meta=&quot;{&amp;quot;aperture&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;credit&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;camera&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;caption&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;created_timestamp&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;copyright&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;focal_length&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;iso&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;shutter_speed&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;title&amp;quot;:&amp;quot;&amp;quot;}&quot; data-image-title=&quot;strsshoot&quot; data-image-description=&quot;&quot; data-medium-file=&quot;https://modsandmembersblog.files.wordpress.com/2013/10/strsshoot.jpg?w=250&quot; data-large-file=&quot;https://modsandmembersblog.files.wordpress.com/2013/10/strsshoot.jpg?w=440&quot; class=&quot;wp-image-101 alignleft&quot; src=&quot;https://modsandmembersblog.files.wordpress.com/2013/10/strsshoot.jpg?w=349&amp;amp;h=419&quot; alt=&quot;&quot; width=&quot;349&quot; height=&quot;419&quot; srcset=&quot;https://modsandmembersblog.files.wordpress.com/2013/10/strsshoot.jpg?w=349&amp;amp;h=419 349w, https://modsandmembersblog.files.wordpress.com/2013/10/strsshoot.jpg?w=698&amp;amp;h=838 698w, https://modsandmembersblog.files.wordpress.com/2013/10/strsshoot.jpg?w=125&amp;amp;h=150 125w, https://modsandmembersblog.files.wordpress.com/2013/10/strsshoot.jpg?w=250&amp;amp;h=300 250w&quot; sizes=&quot;(max-width: 349px) 100vw, 349px&quot;/&gt;&lt;/a&gt;&lt;/strong&gt;&lt;strong&gt;Well, as of sometime on December 5th a huge number of the archivists that were scrambling to rescue archives from Yahoo Groups, had their {e-mail addresses} apparently banned  so they can no longer rescue the archives anymore of the groups they had set up operations to do so.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;So that means that for me anyway, Verizon has lost all benefit of the doubt, and is likely at least aware of what Yahoo is doing to groups, or is at worst, complicit.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;We are receiving comments and messages from the frustrated and angry groups archivists, and some of those are posted below. You can send in your own if you e-mail it to &lt;a href=&quot;mailto:owlsy@yahoo.com&quot;&gt;owlsy@yahoo.com&lt;/a&gt; . I won’t put up threatening, nasty or vitriolic messages however, so you can be angry, but be angry in a controlled way that makes us better than them.&lt;br/&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&quot;gmail_attr&quot; dir=&quot;ltr&quot;&gt;
&lt;p&gt;&lt;strong&gt;From some of our archivists, dated Wednesday, December 4th:&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Just a quick (and sad) update…&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;The Archive Team (who is working with to save content to upload to the Internet Archive) was again blocked by Yahoo The block is wiping out the past month of work done by hundreds of volunteers.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;This info was reported on their &lt;a href=&quot;http://chat.efnet.org:9090/?channels=pythons-attack-y!&quot;&gt;IRC channel&lt;/a&gt;.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Yahoo banned all the email addresses that the Archive Team volunteers had been using to join Yahoo Groups in order to download data. Verizon has also made it impossible for the Archive Team to continue using semi-automated scripts to join Yahoo Groups – which means each group must be re-joined one by one, an impossible task (redo the work of the past 4 weeks over the next 10 days)&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;On top of that, something Yahoo did has killed the last third party tool that users and owners have been using to access their messages, photos and files. (PGOlffine).. Note: not everyone who paid for the PGOffline license is being impacted by the problem. but the developer does not have a workaround. Here is their &lt;a href=&quot;http://personalgroupware.com/smf/index.php?topic=1318.msg6484#msg6484&quot;&gt;post about it&lt;/a&gt;.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Yahoo’s own data tools do not provide Group Photos and, as in my case, for two IDs I keep getting the data from another Yahoo account.&lt;/strong&gt;&lt;/p&gt;
&lt;h3&gt;The Internet Archive/Archive Team Faces 80% Loss of Data Due To Verizon Blocking&lt;/h3&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;@betamax meedee+: we’ve lost the access to the vast majority of the groups we joined [because Verizon blocked access to our accounts]&lt;/strong&gt;&lt;/span&gt;&lt;br/&gt;&lt;span&gt;&lt;strong&gt; …. the effect is that some percentage…..of the signed up groups can no longer be fetched from ….”&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;They are working to get a final number but the Archive Team estimates that is a 80% loss of the Groups they and their volunteers spent the last month joining in preparation for archiving.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;For our community, this is a 100% loss of the Groups we submitted to the Archive Team for? archiving?(30,000).&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;–&lt;a href=&quot;https://yahoo-geddon.tumblr.com/&quot;&gt;Morgan Dawn&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr/&gt;&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Hello Brenda,&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Thanks for reaching out. It would be really great if you could both forward it to Verizon and publish it on the blog. We had a lot of ‘external’ (non Archive Team) volunteers helping out, with the expectation that the groups they were joining would be saved, and it is important to communicate to them that Yahoo have basically destroyed most of our progress and work will now need to begin from scratch. I want to avoid a situation where someone comes along in six months time, asking for a group they expected to be saved because they joined it, and having to tell them we didn’t manage to save it.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;It would also be good to communicate to Yahoo our disappointment that they decided to block our archival efforts without opening a dialogue with us. We’ve always said we’d be happy to work with Yahoo to archive Groups in a way that minimizes disruption to their services. Realistically the only way we’re going to get anywhere near the number of groups we had joined prior to their mass-banning of our accounts is with an extension to the deletion date, which I know you’ve been pushing strongly for. (The ‘best’ solution would be for Verizon to un-ban our accounts, but I doubt that is going to happen).&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Many thanks for your fantastic work so far in keeping the spotlight and pressure on Yahoo / Verizon.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Kind regards,&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Andrew&lt;/strong&gt;&lt;br/&gt;&lt;strong&gt;&lt;a href=&quot;https://www.archiveteam.org/index.php?title=Yahoo!_Groups&quot;&gt;The Archive Team&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;FROM NIGHTOWL:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Today I received another response from Verizon:&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Hi Brenda:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;I hope to address your concerns and add some clarity on the issues you’re referencing.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Regarding the 128 people that joined Yahoo Groups with the goal to archive them – are those people from Archiveteam.org? If so, their actions violated our &lt;a href=&quot;https://www.verizonmedia.com/policies/us/en/verizonmedia/terms/otos/index.html&quot;&gt;Terms of Service&lt;/a&gt;. Because of this violation, we are unable reauthorize them. Also, moderators of Groups can ban users if they violate their Groups’ terms, so previously banned members will be unable to download content from that Group. If you can send the user information, we can investigate the cause of lack of access.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;The Groups Download Manager will download any content an individual posted to Yahoo Groups. However, it will not download attachments and photos uploaded to the Group by other members. For those that are having difficulty with the files delivered, &lt;a href=&quot;https://help.yahoo.com/kb/SLN35066.html&quot;&gt;this help article&lt;/a&gt; explains the types of files within the .zip file sent and how to find third party applications that open them. This is the only way that we can deliver data to our users.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;While users will no longer be able to post or upload content to the site, the email functionality exists. If you are having issues with this feature, please reach out to &lt;a href=&quot;mailto:YahooGroupsEscalations@verizonmedia.com&quot;&gt;YahooGroupsEscalations@verizonmedia.com&lt;/a&gt; and we will work to fix the problem with any delay.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;I understand your usage of groups is different from the majority of our users, and we understand your frustration. However, the resources needed to maintain historical content from Yahoo Groups pages is cost-prohibitive, as they’re largely unused.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Regarding your concern around timeline, on 10/16, we posted &lt;a href=&quot;https://help.yahoo.com/kb/SLN31010.html?impressions=true&quot;&gt;this help page&lt;/a&gt; and began sending emails to Groups users explaining the changes to come, including the 12/14 deadline for download request.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;On 11/12 and 11/19, we confirmed in email to you that so long as a request to download was put in by December 14th, we will ensure your download is complete before any deletion. This is the case for all Groups users and step-by-step instructions are being sent now to users to support them through the process.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;We recognize this transition may be difficult, and we’d like to provide as much assistance and clarity as we can.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Best,&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;(name omitted).&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;From there, I sent two replies — one when I was angrier, and one when I calmed down&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;To: (name omitted)&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;VERIZON/YAHOO does NOT understand our frustration.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;THE GROUPS ARE BROKEN.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;THE ACCESS IS OFF AND ON.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;THE MAIL IS A MESS.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;YAHOO has mistreated us and abused us all for 6 years, and it’s all coming out this weekend. VERIZON owns Yahoo now, and is the one who should clean up their mess.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;If we are allowed to have our archives from Verizon/Yahoo, then we should be able to get them ourselves any way we wish. All Verizon plans to do is throw it away. The stuff you send us is messed up, broken, incomplete, and virus ridden. It is UNACCEPTABLE as a solution.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;The 128 people you banned were REQUESTED by the group owners to get their stuff.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Verizon refuses to give us more time to get it. We can’t do it in 7 days.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;So, we will continue to press public opinion about this issue, in every arena that we can with all that we have to make this deletion stop and give us more time, and work something out with Verizon to get our stuff, which is costly to store, and go away.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Bottom line. Give us our archives and we’ll leave and never come back.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Thank you sincerely,&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Brenda&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt; &lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;……And this is the second e-mail I sent when I calmed down:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Good evening (name omitted)&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Please relay this to Verizon/Yahoo.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;This is the unfairness that Verizon has shown to Yahoo Groups Users.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;First of all, the initial letter said that Verizon had researched the use of Yahoo Groups. This is a complete falsehood. You know how I know it is? Because if you had truly researched the use of Yahoo Groups, you’d have found the 30,000 active groups that are used often, many on a daily basis, despite them being broken in many areas. But Verizon did not do that. If they had, they would have found:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;A police cooperative in Washington DC that was using them as a network to communicate with their respective neighborhoods with over 17,000 members.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;A phone company in the UK that assigns phone numbers using the groups and now will lose all those phone designations when it’s deleted.&lt;br/&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;A Birding group in new Delhi with 2,000 members that has collected data and research on birds for TWO DECADES.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;An Adoption group in France, that has been using it for&lt;/strong&gt; &lt;strong&gt;years and years to communicate and share history and photos and more.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;They also would have found:&lt;/strong&gt;&lt;br/&gt;&lt;strong&gt;Numerous support groups for people who are suicidal or depressed.&lt;br/&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Numerous medical groups for people to communicate more effectively with their doctors.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Numerous Vet groups with 24 hr care advice for sick pets.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Numerous support and help groups for the Elderly.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Numerous Historical groups for WW2 Veterans, Vietnam Veterans, and etc.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Numerous science groups that have used them for years and have all their research there.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Numerous fan fiction groups or arts groups that have shared their work for years.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;No Verizon, these groups are NOT largely unused. You just didn’t do your homework. You didn’t find us, who could have told you they were used all the time. You didn’t make an effort to understand what groups were, and how they were used. You just decided they weren’t being used, and weren’t important and decided, “Hey, let’s just delete them!”&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;So not researching thoroughly, and probably listening to Yahoo’s telling you they weren’t being used was your first mistake.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;The second mistake, when the intial plan to delete our archives was hatched, some people learned it on October 17th. Not everyone did. That’s because it was very quiet and low key, and not everyone goes to the website all the time. Many use it when they need to search for something, or check out a photo. The point is it’s a mail list with an archive.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Some e-mails were sent to members, and perhaps maybe all were sent, but believe me, all did not arrive on that date. People began finding out by receiving letters days, weeks, and even a full month later. This is because Groups e-mail is unreliable. Period. It has been unreliable since Mayer broke it in 2013.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Even those learning it on October 17th, had a very small window of time to save their group. It was a period of 58 days, less than 2 months. That was never going to be enough time for over 30,000 groups to save their archives.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;As you said, photos were not downloaded from the groups as a group. So anyone who wanted them had to manually save them by hand. And there are groups with thousands or hundreds of thousands of photos, especially art groups and photography groups. It couldn’t be done in the time we were given.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;This delay in us finding out, left barely weeks for some people to act. Thus the panic all over the Internet, which Verizon would see if they would just look, was immediate and furious. They came to me, because I stopped the destruction of Yahoo Groups in 2010, and have been crusading against Yahoo for their unethical treatment of us, and fighting to protect our archives for 6 years.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;So, as I had kept the Crusade blog up and the Crusade groups open, they all fled back to me. And this time, it wasn’t that we couldn’t get them [our archives] and leave, and it wasn’t that they had broken access. This time Verizon planned total destruction. This time it was for keeps. So of course, I had to start the Crusade again and take it to high gear.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;So the best thing Verizon could do, since they are just going to throw us all into the trash anyway, as we aren’t important to them, is let us get our archives any way we can.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;The terms of service really should not apply to people who have been told, we’re gonna delete you from existence. If it’s lawful for us to get them from you, in broken buggy and virus ridden state, it’s just as lawful for us to get them ourselves.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Yahoo made a huge mess of us. I tried to warn Verizon even before they purchased it. They did not listen. Now they have the mess on their hands, and we will not be silent. Even if Verizon really does delete us out of existence, we will never stop telling the world what they and Yahoo did. Because it’s high time Yahoo Groups Users start being treated as human beings again.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Bottom line. Verizon is being unfair to a group of people using a property they purchased, they are being unethical in the manner in which they announced it, and unreasonable in the time that they gave us to accomplish it.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;So we demand fair and equal treatment, and will stand up for it until we get it.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Sincerely,&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Brenda Fowler&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Ooohkay-then.  Thats how they want to be. As you know, &lt;a href=&quot;https://modsandmembersblog.wordpress.com/2019/12/05/same-ol-yahoo-just-by-another-name/&quot;&gt;the Owl’s gloves are off&lt;/a&gt; and this really nails it home how complicit Verizon is going to be.  At the same time, press has &lt;a href=&quot;https://www.fastcompany.com/90418939/deleting-yahoo-groups-will-leave-a-permanent-stain-on-yahoos-legacy&quot;&gt;become aware&lt;/a&gt; of Verizon/Yahoo’s choice to become another statistic for bad PR over the matter.  We too have this power, and some articles about our cause are already pending over this weekend. &lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;It is time that we take this up a notch.  Archiving is still going on through the various teams, but we can begin the fight on another side of this scenario.  &lt;a href=&quot;https://modsandmembersblog.wordpress.com/taking-action/&quot;&gt;Won’t you join us?&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;


&lt;div id=&quot;jp-post-flair&quot; class=&quot;sharedaddy sd-like-enabled sd-sharing-enabled&quot;&gt;
&lt;div class=&quot;sharedaddy sd-sharing-enabled&quot;&gt;
&lt;div class=&quot;robots-nocontent sd-block sd-social sd-social-icon-text sd-sharing&quot;&gt;
&lt;h3 class=&quot;sd-title&quot;&gt;Share this:&lt;/h3&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sharedaddy sd-block sd-like jetpack-likes-widget-wrapper jetpack-likes-widget-unloaded&quot; id=&quot;like-post-wrapper-59052216-2677-5ded9c785b3e8&quot; data-src=&quot;//widgets.wp.com/likes/index.html?ver=20190321#blog_id=59052216&amp;amp;post_id=2677&amp;amp;origin=modsandmembersblog.wordpress.com&amp;amp;obj_id=59052216-2677-5ded9c785b3e8&quot; data-name=&quot;like-post-frame-59052216-2677-5ded9c785b3e8&quot;&gt;
&lt;h3 class=&quot;sd-title&quot;&gt;Like this:&lt;/h3&gt;
&lt;div class=&quot;likes-widget-placeholder post-likes-widget-placeholder&quot;&gt;&lt;span class=&quot;button&quot;&gt;&lt;span&gt;Like&lt;/span&gt;&lt;/span&gt; &lt;span class=&quot;loading&quot;&gt;Loading...&lt;/span&gt;&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
</description>
<pubDate>Sun, 08 Dec 2019 19:31:13 +0000</pubDate>
<dc:creator>Diagon</dc:creator>
<og:type>article</og:type>
<og:title>VERIZON / YAHOO! BAD FORM!</og:title>
<og:url>https://modsandmembersblog.wordpress.com/2019/12/08/verizon-yahoo-bad-form/</og:url>
<og:description>Well, as of sometime on December 5th a huge number of the archivists that were scrambling to rescue archives from Yahoo Groups, had their {e-mail addresses} apparently banned  so they can no longer…</og:description>
<og:image>https://modsandmembersblog.files.wordpress.com/2013/10/strsshoot.jpg?w=250</og:image>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://modsandmembersblog.wordpress.com/2019/12/08/verizon-yahoo-bad-form/</dc:identifier>
</item>
<item>
<title>The Go runtime scheduler&amp;#039;s way of dealing with system calls</title>
<link>https://utcc.utoronto.ca/~cks/space/blog/programming/GoSchedulerAndSyscalls</link>
<guid isPermaLink="true" >https://utcc.utoronto.ca/~cks/space/blog/programming/GoSchedulerAndSyscalls</guid>
<description>&lt;p&gt;One of Go's signature features is &lt;a href=&quot;https://tour.golang.org/concurrency/1&quot;&gt;goroutines&lt;/a&gt;, which are lightweight threads that are managed by the Go runtime. The Go runtime implements goroutines using &lt;a href=&quot;https://rakyll.org/scheduler/&quot;&gt;a M:N work stealing scheduler&lt;/a&gt; to multiplex goroutines on to operating system threads. The scheduler has special terminology for three important entities; a G is a goroutine, an M is an OS thread (a 'machine'), and a P is a 'processor', which at its core is a limited resource that must be claimed by an M in order to run Go code. Having a limited supply of Ps is how Go limits how many things it will do at once, so as to not overload the overall system; generally there is one P per actual CPU that the OS reports (the number of Ps is &lt;a href=&quot;https://golang.org/pkg/runtime/&quot;&gt;&lt;code&gt;GOMAXPROCS&lt;/code&gt;&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;When a goroutine performs network IO or any system call operation that can definitely be done asynchronously, Go has an entire runtime subsystem, &lt;a href=&quot;https://morsmachine.dk/netpoller&quot;&gt;the netpoller&lt;/a&gt;, that converts what looks like multiple separate synchronous operations into a single wait (using operating system mechanisms like &lt;a href=&quot;https://medium.com/@copyconstruct/the-method-to-epolls-madness-d9d2d6378642&quot;&gt;&lt;code&gt;epoll&lt;/code&gt;&lt;/a&gt;). Rather than actually making a blocking system call, your goroutine goes to sleep waiting for its network socket, just as if it was waiting for a channel to become ready. This is all conceptually straightforward, if tricky to implement efficiently.&lt;/p&gt;
&lt;p&gt;However, network IO and similar things are far from the only system calls that Go programs can make, so Go has to deal with blocking system calls as well. The straightforward way to handle blocking system calls is for your goroutine's M to release its P just before it makes the system call and then try to re-acquire a P after the system call resumes. If there's no free P at that time, your goroutine gets parked in the scheduler along with everything else that's waiting to run.&lt;/p&gt;
&lt;p&gt;While all system calls are blocking in theory, not all are expected to be blocking in practice. For example, on modern systems the 'system call' to get the current time may not even enter the kernel (see &lt;a href=&quot;http://man7.org/linux/man-pages/man7/vdso.7.html&quot;&gt;vdso(7)&lt;/a&gt; on Linux). Having goroutines go through the full work of releasing their current P and then re-acquiring one for these system calls has two problems. First, there's a bunch of overhead involved in locking (and releasing) all of the data structures involved. Second, if there's more runnable goroutines than Ps, a goroutine that makes this sort of system call won't be able to re-acquire a P and will have to park itself; the moment it released the P, something else was scheduled onto it. This is extra runtime overhead, is sort of unfair, and kind of defeats the purpose of having fast system calls (especially ones that don't go into the kernel).&lt;/p&gt;
&lt;p&gt;So the Go runtime and scheduler actually have two ways of handling blocking system calls, a pessimistic way for system calls that are expected to be slow and an optimistic way for ones that are expected to be fast. The pessimistic system call path implements the straightforward approach where the runtime actively releases the P before the system call, attempts to get it back afterward, and parks itself if it can't. The optimistic system call path doesn't release the P; instead, it sets a special P state flag and just makes the system call. A special internal goroutine, the sysmon goroutine, then comes along periodically and looks for P's that have been sitting in this 'making a system call' state for too long and steals them away from the goroutine making the system call. When the system call returns, the runtime code checks to see if its P has been stolen out from underneath it, and if it hasn't it can just go on (if the P has been stolen, the runtime tries to get another P and then may have to park your goroutine).&lt;/p&gt;
&lt;p&gt;If everything works out, the optimistic system call path has very low overhead (mostly it requires a couple of &lt;a href=&quot;https://en.wikipedia.org/wiki/Compare-and-swap&quot;&gt;atomic compare and swap&lt;/a&gt; operations). If things don't work out and there's more runnable goroutines than there are Ps, then one P will be unnecessarily idle for what is probably generally a few tens of microseconds (the sysmon goroutine runs at most once every 20 microseconds, but can run less frequently if there seems to be no need for it). There are probably worst case scenarios possible, but in general this seems to be a worthwhile tradeoff on the part of the Go runtime.&lt;/p&gt;
</description>
<pubDate>Sun, 08 Dec 2019 15:30:20 +0000</pubDate>
<dc:creator>todotask</dc:creator>
<dc:format>text/html</dc:format>
<dc:identifier>https://utcc.utoronto.ca/~cks/space/blog/programming/GoSchedulerAndSyscalls</dc:identifier>
</item>
<item>
<title>Learning to code vs. learning to automate</title>
<link>https://daedtech.com/dont-learn-to-code-learn-to-automate/</link>
<guid isPermaLink="true" >https://daedtech.com/dont-learn-to-code-learn-to-automate/</guid>
<description>&lt;p&gt;Does anyone remember a few years ago, when &lt;a href=&quot;http://www.bbc.com/news/technology-16440126&quot;&gt;the mayor of New York decided to learn to program&lt;/a&gt;? It was a heady time, because it wasn’t just him. I remember these surreal commercials where Miami Heat forward Chris Bosh was encouraging children to learn to code for the good of humanity or something. There was this sudden, overwhelming sentiment that humanity should abandon the folly of any non-programming pursuit and learn them some Ruby or whatever. Andy Warhol, were he alive in 2012, no doubt would have said, “in the future, everyone will write code for 15 minutes.”&lt;/p&gt;
&lt;p&gt;Jeff Atwood wrote an interesting rebuttal to this zeitgeist, entitled, “&lt;a href=&quot;http://blog.codinghorror.com/please-dont-learn-to-code/&quot;&gt;Please Don’t Learn to Code.&lt;/a&gt;” The covers a good bit of ground and makes some interesting points, but the overarching thesis seems to be, “avoid thinking of writing code as the goal and learn to solve problems.” I think this is an excellent, philosophical point, but I’d like to add a bit of nuance.&lt;/p&gt;
&lt;p&gt;I’ve written in the past about how important I think that it is to be a problem solver, to the point where I &lt;a href=&quot;https://www.daedtech.com/job-titles-be-like-the-wolf&quot;&gt;wrote a post about liking the title “problem solver.”&lt;/a&gt; So please don’t think I disagree with his take that a lot of programmers get too hung up with the particulars of code. I don’t — I think that’s a very common issue. But, at the same time, I think the mayor of New York and Chris Bosh and others have a point that Jeff doesn’t really address, per se. Specifically, the world is getting dramatically more technical, which means that a lot of pursuits are being automated out of existence, while other pursuits require an increasing degree of technical savvy. My fiancee, a professional copy editor, is finding aspects of her job to be easier if she knows a bit of HTML and CSS.&lt;/p&gt;
&lt;p&gt;So while I wince alongside Jeff at the thought of people randomly learning programming languages because they think it’ll make them rich or because they want to be a person that writes lots of code, I don’t think we can simply say, “stay out unless you’re serious and willing to spend years getting good.” The rapidly evolving technical landscape has created this black hole of technical savvy that’s sucking in even people well past the event horizon.&lt;/p&gt;
&lt;p&gt;The advice that I’d offer on this subject creates a pretty fine distinction. I don’t think that everyone needs to learn to code by any stretch. What I think that everyone needs to start learning about and understanding is how to &lt;em&gt;automate&lt;/em&gt;. Or, if not how to do it themselves, at least how to recognize things that could be automated and have meaningful discussions about whether the effort is worth it or not.&lt;span id=&quot;more-4889&quot;/&gt;&lt;/p&gt;
&lt;h3&gt;Automation in Real Life&lt;/h3&gt;
&lt;p&gt;It might be best to offer an example here. Tonight, I was working with a friend on some course materials to be communicated via Power Point. We were making slides that were largely images with a few large-font words scattered here and there. We’d paste the pictures into the slide deck, resize a little and then use my Mac’s trackpad laboriously to center the images. At one point, he said, “there should be some shortcut key in Power Point that you can hit and it just auto-centers the thing vertically and horizontally.”&lt;/p&gt;
&lt;p&gt;That, my friends, is automation at the moment of conception. Centering something on a Power Point is just the kind of brainless, maddening, time-consuming task that makes a good candidate for automation. You know what I’m talking about, where you drag the thing around using movements as microscopic as possible, hoping to see that line appear that indicates that it’s in the middle. It’s so hard to find and you’ve got to go so — wait, there! Crap! Missed it. Back up, try it again.&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.daedtech.com/rip-rtfm/cryingdev&quot; rel=&quot;attachment wp-att-4452&quot;&gt;&lt;img alt=&quot;CryingDev&quot; width=&quot;300&quot; height=&quot;213&quot; data-srcset=&quot;https://daedtech.com/wp-content/uploads/2014/11/CryingDev-300x213.jpg 300w, https://daedtech.com/wp-content/uploads/2014/11/CryingDev.jpg 366w&quot; sizes=&quot;(max-width: 300px) 100vw, 300px&quot; data-src=&quot;https://www.daedtech.com/wp-content/uploads/2014/11/CryingDev-300x213.jpg&quot; class=&quot;aligncenter size-medium wp-image-4452 lazyload&quot; src=&quot;data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==&quot;/&gt;&lt;noscript&gt;
&lt;p&gt;&lt;img class=&quot;aligncenter size-medium wp-image-4452&quot; src=&quot;https://www.daedtech.com/wp-content/uploads/2014/11/CryingDev-300x213.jpg&quot; alt=&quot;CryingDev&quot; width=&quot;300&quot; height=&quot;213&quot; srcset=&quot;https://daedtech.com/wp-content/uploads/2014/11/CryingDev-300x213.jpg 300w, https://daedtech.com/wp-content/uploads/2014/11/CryingDev.jpg 366w&quot; sizes=&quot;(max-width: 300px) 100vw, 300px&quot;/&gt;&lt;/p&gt;
&lt;/noscript&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Of course, the conversation doesn’t end here, by any stretch. The talent for which I’m advocating — the talent of savvy automation — involves an assessment like the following, and a &lt;em&gt;potential&lt;/em&gt; automation at the end.&lt;/p&gt;
&lt;h4&gt;Does Power Point already provide this capability and we just don’t know about it?&lt;/h4&gt;
&lt;p&gt;Doesn’t seem like it after a bit of quick googling. If it did, a &lt;a href=&quot;https://pptcrafter.wordpress.com/2013/05/15/powerpoint-secrets-alignment/&quot;&gt;blog about Power Point secrets&lt;/a&gt; would probably just need two lines to describe it “Step 1: hit magic key sequence. Step 2: there is no step 2.” But still, it might exist.&lt;/p&gt;
&lt;h4&gt;Is it worth doing more research?&lt;/h4&gt;
&lt;p&gt;Not right now. We’re almost done with the slide deck. On a broader scale, it might be worth doing.&lt;/p&gt;
&lt;h4&gt;Would it be worth it to us over the long haul?&lt;/h4&gt;
&lt;p&gt;Hard to say. I’m not entirely sure how much time in my life is wasted to this problem. It’s probably some but I’m not the most avid Power Point user, so you figure it might take years for it to add up to hours of my time. And who knows how long fixing this problem would take?&lt;/p&gt;
&lt;h4&gt;Would it be worth it &lt;em&gt;for humanity&lt;/em&gt; over the long haul?&lt;/h4&gt;
&lt;p&gt;Hmmm… almost certainly. Even if I waste hours on this only after years of Power Point use, &lt;em&gt;humanity&lt;/em&gt; probably wastes hours on this after microseconds go by. Lots of people somewhere are swearing at Power Point right this very instant.&lt;/p&gt;
&lt;h4&gt;Could we sell it if we made it?&lt;/h4&gt;
&lt;p&gt;Meh, doubtful. But maybe for a pittance here and there. Or maybe we could just do it, donate it to the greater good, and reap a reputation benefit.&lt;/p&gt;
&lt;h4&gt;Okay, so what’s the next action?&lt;/h4&gt;
&lt;p&gt;Let’s set aside a time box of an hour to research this at a good time for low priority tasks, such as sitting in an airport. A nice interim goal might be to see if we can get it going in a limited scenario. On just a blank slide, does the “ctrl-E” shortcut do the job for horizontal centering? If so, can we find a way to do vertical centering and then somehow chain those shortcuts? If yes, then, bam, problem solved with just a bit of configuration. We’ll know we’ve succeeded when we can hit a single shortcut and have horizontal and vertical center of a single image on a blank slide. If that little test works, we can write a blog post, bask in some win, and then move on to more scenarios.&lt;/p&gt;
&lt;h3&gt;Poor Man’s Coding?&lt;/h3&gt;
&lt;p&gt;Okay, so that was a little hokey, but I’d like to point some things out here. First up was identification of a crappy task and the recognition of an automation candidate. Figuring out the exact coordinates for centering something is the perfect job for a computer. After that came a sequence of questions contemplating the possibility that there might be an existing solution, that coming up with a new one might not be worth it, or that coming up with a new one might be time consuming enough as to offset any gains. In the world of software development, that goes by various names such as “discovery,” “requirements analysis,” and “sprint 0.”&lt;/p&gt;
&lt;p&gt;After that came a tentative plan of action along with some risk mitigation. Let’s invest a bit of effort in seeing what we can do, but let’s cap that amount of effort so that we don’t run off tilting at windmills. And then there was a concrete strategy that involved carving a larger potential effort down into the smallest slice that might provide some incremental value. This is known in the software development biz as an agile (or, if you want, “lean”) approach to a software project. And then, finally, in spite of the lack of writing of actual code, came implementation and a clear, verifiable description of what success looks like. In the biz, that’s called “Acceptance Test Driven Development” (ATDD).&lt;/p&gt;
&lt;p&gt;But forget the terms and the parallels to programmer shop-talk. The more important point is that successful software development projects — projects that involve code and IDEs and compilers and whatnot — are just a special case of successful automation projects. You can automate all manner of things, even some very non-trivial things, without actually writing any code. In this vein, Jeff’s point is absolutely spot on. Coders like to code, but writing code ought not to be a first class goal when there are problems to be solved.&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.daedtech.com/what-your-job-descriptions-are-saying-to-developers-about-your-company/workharder&quot; rel=&quot;attachment wp-att-2791&quot;&gt;&lt;img alt=&quot;WorkHarder&quot; width=&quot;614&quot; height=&quot;253&quot; data-src=&quot;https://www.daedtech.com/wp-content/uploads/2013/03/WorkHarder.jpg&quot; class=&quot;aligncenter wp-image-2791 lazyload&quot; src=&quot;data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==&quot;/&gt;&lt;noscript&gt;
&lt;p&gt;&lt;img class=&quot;aligncenter wp-image-2791&quot; src=&quot;https://www.daedtech.com/wp-content/uploads/2013/03/WorkHarder.jpg&quot; alt=&quot;WorkHarder&quot; width=&quot;614&quot; height=&quot;253&quot;/&gt;&lt;/p&gt;
&lt;/noscript&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Throughout human history, there’s been a sort of “pain is gain” approach to the repetitive. There was value in putting your head down, getting into a rhythm, and working hard at menial tasks. But throughout most of that human history, we didn’t have computers. It turns out that computers are really, really good at doing repetitive, menial tasks — tasks that involve precision and not judgment. They’re far better at them than we are, so it makes sense to let computers do them.&lt;/p&gt;
&lt;p&gt;It’s obtuse to suppose that a prerequisite for every job in the future will be the ability to implement sophisticated, specialized computer applications. But it’s not at all obtuse to suppose that, given the ubiquity of computing, a prerequisite for every job in the future will be the ability to recognize which tasks are better suited for humans and which for computers. Learn at least to recognize which parts of your job are a poor use of your time. After that, perhaps learn to use your ingenuity and creativity to automate using the tools that you know (such as googling for solutions, leveraging apps, etc). And, if you’ve come that far, maybe it’s time to roll up your sleeves and take the plunge into learning to code a little bit to help you along. Because, while there’s no need for the mayor of New York to write any code, it couldn’t hurt him to be ready to jump if something opens up in the city’s IT department.&lt;/p&gt;
&lt;span id=&quot;tve_leads_end_content&quot;/&gt;</description>
<pubDate>Sun, 08 Dec 2019 12:37:58 +0000</pubDate>
<dc:creator>sharacane</dc:creator>
<og:title>Don’t Learn to Code — Learn to Automate</og:title>
<og:type>article</og:type>
<og:url>https://daedtech.com/dont-learn-to-code-learn-to-automate/</og:url>
<og:image>https://daedtech.com/wp-content/uploads/2013/03/WorkHarder.jpg</og:image>
<dc:language>en-US</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://daedtech.com/dont-learn-to-code-learn-to-automate/</dc:identifier>
</item>
<item>
<title>Cairo Desktop Environment</title>
<link>https://cairoshell.com/</link>
<guid isPermaLink="true" >https://cairoshell.com/</guid>
<description>&lt;p&gt;With Cairo, your desktop is browse-able, meaning that you never need to open a file explorer to find your things. The handy pop-up navigation makes it easy to move forward or backward and completely transforms your desktop into a more friendly, convenient space.&lt;/p&gt;
</description>
<pubDate>Sun, 08 Dec 2019 08:27:40 +0000</pubDate>
<dc:creator>Rerarom</dc:creator>
<og:title>Cairo Desktop Environment</og:title>
<og:description>Enjoy a brand new Windows desktop experience with Cairo.</og:description>
<og:image>http://cairodesktop.com/img/ss_cairo.jpg</og:image>
<og:url>http://cairodesktop.com</og:url>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://cairoshell.com/</dc:identifier>
</item>
<item>
<title>Far Cry</title>
<link>http://ceasarbautista.com/essays/far_cry.html</link>
<guid isPermaLink="true" >http://ceasarbautista.com/essays/far_cry.html</guid>
<description>&lt;p&gt;Every theory of aesthetics must be able to explain what is commonly known as &quot;The Paradox of Tragedy&quot;. The paradox goes as follows: if tragedy causes an unpleasant response in a subject, how is it that we ultimately derive pleasure? Several theories have been posited by philosophers ranging from Aristotle to Hume, but few stand up to serious scrutiny.&lt;/p&gt;
&lt;p&gt;However, an essay&lt;a href=&quot;http://www.jstor.org/stable/20013989&quot; title=&quot;The Pleasures of Tragedy&quot;&gt;1&lt;/a&gt; from 1983 published by Susan Feagin entitled &lt;em&gt;The Pleasures of Tragedy&lt;/em&gt; introduces a theory which appears to unravel the paradox.&lt;/p&gt;
&lt;p&gt;This paper explores how Feagin's theory is useful in understanding unscripted tragic narratives through a critical examination of Ubisoft's 2008 open-world shooter, &lt;em&gt;Far Cry 2&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;Feagin thinks that when we interact with art we experience a 'direct response' and sometimes a 'meta-response'.&lt;/p&gt;
&lt;p&gt;A direct response is a response to the qualities and content of an artistic work. For instance, we might laugh at a funny movie or cry at a sad one.&lt;/p&gt;
&lt;p&gt;A meta-response is a response to a direct response. For instance, we might feel bad for laughing at a lewd joke or feel virtuous for feeling disgust at the sight of a drunkard.&lt;/p&gt;
&lt;p&gt;Assuming we are not callous, Feagin solves the Paradox of Tragedy by positing that though direct responses to unpleasant works are unpleasant, we derive pleasure from a meta-response which &quot;aris[es] from our awareness of, and in response to, the fact that we do have unpleasant direct responses to unpleasant events as they occur.&quot; This discovery or reminder is pleasurable because it confirms our sympathy for human beings, our hate for evil, and our common humanity, which also suggests that the aesthetic value of tragedy lies on its moral foundations.&lt;/p&gt;
&lt;p&gt;In that light, Feagin's theory can explain why tragedy is commonly considered more significant than comedy: tragedy necessarily deals with serious matters that recognize the importance of morality to human life. If the matters were made less serious, the work would be labeled a comedy and its significance would diminish.&lt;/p&gt;
&lt;p&gt;As a brief, but important aside, Feagin acknowledges that her theory relies on the belief that fiction can cause emotional responses. In this respect, she adopts the position of Ralph Clark, who posits that &quot;emotional responses are the result of entertaining counterfactual conditionals&quot;. In other words, a subject can feel an emotional response from fiction by suspending disbelief. If a subject cannot suspend disbelief, there can be no meta-response, which can explain why highly moral people might remain unmoved by poorly performed tragedy and vice-versa.&lt;/p&gt;
&lt;h2 id=&quot;tragedy-and-video-games&quot;&gt;Tragedy and Video Games&lt;/h2&gt;
&lt;p&gt;When Feagin published her essay in 1983, Nintendo has only just published &lt;em&gt;Mario Bros.&lt;/em&gt;. Do modern video games reveal anything new about the usefulness or limits of Feagin's theory of tragedy?&lt;/p&gt;
&lt;p&gt;If we limit our discussion to conventional video games, the answer is mostly &quot;no&quot;. Like most new mediums, video games have largely emulated their predecessors and failed to make use of their unique interactive nature. Narrative in video games is almost always either absent or it is strictly separated from gameplay through the use of non-interactive sequences (typically cutscenes).&lt;/p&gt;
&lt;p&gt;However, there are a number of games today that have been exploring how the video games can be used to create new forms of narrative and meaning. &lt;em&gt;Far Cry 2&lt;/em&gt; is one such title.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://images.wikia.com/farcry/images/9/97/Far_Cry_2_cover_art.jpg&quot; /&gt;&lt;/p&gt;
&lt;p&gt;Led by the creative vision of Clint Hocking&lt;a href=&quot;http://www.clicknothing.com/&quot;&gt;5&lt;/a&gt;, the man responsible for the creative success of &lt;em&gt;Splinter Cell&lt;/em&gt; and &lt;em&gt;Splinter Cell: Chaos Theory&lt;/em&gt;, the developers of &lt;em&gt;Far Cry 2&lt;/em&gt; diverged from the traditional route of making a game supported by narrative and instead they attempted to create a narrative supported by gameplay.&lt;/p&gt;
&lt;p&gt;To this end, they attempted to construct a highly immersive make-believe universe that would lead the player to commit heinous acts in the service of a greater good. The goal was to encourage the player to explore themes similar to those present in Joseph Conrad's &lt;em&gt;The Heart of Darkness&lt;/em&gt; interactively.&lt;/p&gt;
&lt;p&gt;What makes &lt;em&gt;Far Cry 2&lt;/em&gt; interesting to us is that, though it explores significant moral themes, there is little narrative to speak of nor tragic hero to pity. Can Feagin's theory still help us understand it?&lt;/p&gt;
&lt;p&gt;Before we answer that question directly, we need to establish that, in fact, &lt;em&gt;Far Cry 2&lt;/em&gt; evokes emotional responses from its players. If it cannot or does not do so, then it does not meet the criteria for Feagin's theory to apply.&lt;/p&gt;
&lt;h2 id=&quot;immersion&quot;&gt;Immersion&lt;/h2&gt;
&lt;p&gt;Feagin adopts the position of Ralph Clark when explaining how fiction can evoke emotional responses. She assumes that &quot;emotional responses are the result of entertaining counterfactal conditionals&quot;. In other words, fiction must &lt;em&gt;immerse&lt;/em&gt; the subject to evoke an emotional response.&lt;/p&gt;
&lt;p&gt;Can video games immerse their subject? If so, how?&lt;/p&gt;
&lt;p&gt;As a matter of brevity, the question of whether or not video games &lt;em&gt;can&lt;/em&gt; immerse their subjects I will consider self-evident. On the other hand, the question of &lt;em&gt;how&lt;/em&gt; to create an immersive experience is still a subject of research. Nevertheless there are generally accepted techniques for immersion that are useful to point out in order to understand how and to what degree &lt;em&gt;Far Cry 2&lt;/em&gt; immerses the player.&lt;/p&gt;
&lt;p&gt;In theory, a perfect simulation of reality would be perfectly immersive. But faced with limited computational resources, designers must remove inessential aspects of the simulation and request a certain amount of imagination on the part of the player. Will Wright, creator of &lt;em&gt;The Sims&lt;/em&gt;, describes the problem as such:&lt;/p&gt;
&lt;blockquote readability=&quot;12&quot;&gt;
&lt;p&gt;Especially right now with current technology, there are a lot of limitations in terms of what we can do with character simulation. So, to me that seemed like a really good use of the abstraction because there are certain things we just cannot simulate on a computer, but on the other hand that people are very good at simulating in their heads. So we just take that part of the simulation and offload it from the computer into the player's head... So you know, it's parallel processing of a sort.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;If we accept Wright's statement, then we conclude that the more abstract a game is, the more &quot;processing&quot; it must ask of the player. In that sense, we might conclude that games that want to be highly immersive games should depict highly accurate depictions of reality.&lt;/p&gt;
&lt;p&gt;In that sense, we note that few games try to be immersive: most deliberately involve elements of the supernatural or science fiction, gratuitous violence, or abstract game interfaces.&lt;/p&gt;
&lt;p&gt;&lt;img title=&quot;Halo 2&quot; src=&quot;http://upload.wikimedia.org/wikipedia/en/5/51/Halo2_widescreen.jpg&quot; /&gt;&lt;/p&gt;
&lt;p&gt;Far Cry 2, on the other hand, makes an exceptional effort to be immersive.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://www.gamasutra.com/db_area/images/feature/3727/redding_farcry24.jpg&quot; /&gt;&lt;/p&gt;
&lt;h2 id=&quot;realism-in-far-cry-2&quot;&gt;Realism in Far Cry 2&lt;/h2&gt;
&lt;p&gt;Along with the game, the developers of &lt;em&gt;Far Cry 2&lt;/em&gt; built an entirely new game engine&lt;a href=&quot;http://www.gamasutra.com/php-bin/news_index.php?story=19344&quot; title=&quot;In-Depth: Far Cry 2's Guay Talks Dunia Engine, State Of PC&quot;&gt;2&lt;/a&gt; to animate the player's world. To fully appreciate its complexity is practically impossible through playing alone. Many details are hard to notice statically, and many require complex interactions between game elements. Though there is no explicit division in the engine, for clarity, I will divide the simulation of the universe into three parts: simulation of the world, simulation of others, and simulation of the avatar.&lt;/p&gt;
&lt;h3 id=&quot;simulating-the-world&quot;&gt;Simulating the world&lt;/h3&gt;
&lt;p&gt;There is much evidence to suggest that simulating the world realistically was an important goal in the development of &lt;em&gt;Far Cry 2&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;For one, we know a significant amount of effort was spent on enhancing the &quot;Dunia Engine&quot; which animates the game world. One developer, Jean-Francois Levesque,&lt;a href=&quot;http://www.gamasutra.com/php-bin/news_index.php?story=20901&quot;&gt;6&lt;/a&gt; spent a year making fire burn realistically.&lt;a href=&quot;http://jflevesque.com/2012/12/06/far-cry-how-the-fire-burns-and-spreads/&quot;&gt;7&lt;/a&gt; Another developer spent three years on the vegetation system.&lt;a href=&quot;http://www.gamasutra.com/php-bin/news_index.php?story=20901&quot;&gt;6&lt;/a&gt; And a group of the developers traveled to Kenya to compare their simulation with the real thing.&lt;/p&gt;
&lt;p&gt;Second, we note how believably the game world manifests itself: the ambient sounds, the dynamic weather, the visible degradation of guns over time and with use, the presence of wildlife, and the passage of time from day to night. Tree branches and grass sway in the wind and in response to explosions.&lt;/p&gt;
&lt;iframe width=&quot;420&quot; height=&quot;315&quot; src=&quot;http://www.youtube.com/embed/GXXUUAAnuE8&quot; frameborder=&quot;0&quot; allowfullscreen=&quot;&quot;&gt;[embedded content]&lt;/iframe&gt;
&lt;p&gt;Furthermore most of the world is highly destructible. Besides the explosive barrels littered around and most things being flammable, the ability to destroy things extends to individual tree branches which can be split off from trees via bullets or explosions.&lt;a href=&quot;http://www.eurogamer.net/videos/far-cry-2_vegetation-growth&quot;&gt;8&lt;/a&gt;&lt;/p&gt;
&lt;h4 id=&quot;fire&quot;&gt;Fire&lt;/h4&gt;
&lt;p&gt;One aspect of &lt;em&gt;Far Cry 2&lt;/em&gt;'s game world that draws considerable attention is its realistic propagation of fire.&lt;a href=&quot;http://www.youtube.com/embed/WMKmhg90K9s&quot;&gt;9&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;It's hard to know all of the details, but from interviews we know that it's spread is affected by a number of conditions, including the direction of the wind, the humidity of the environment (which is affected by the fauna and whether or not it has rained recently), and the slope of the ground (fire burns faster going uphill than downhill). Furthermore, we notice that objects on fire burn in sections, and that if a burning object falls into water, only the submerged part of the object will extinguish.&lt;/p&gt;
&lt;h3 id=&quot;simulating-others&quot;&gt;Simulating others&lt;/h3&gt;
&lt;p&gt;Another impressive aspect of the world of Far Cry is the believable behavior of its inhabitants.&lt;/p&gt;
&lt;p&gt;For instance, enemies have noticeable relationships with each other. They talk casually, yell commands at each other, and hurl taunts at the player. (There are some 100,000 words of dialog such that hearing repeated dialog in a single playthrough is highly unlikely.&lt;a href=&quot;http://www.gamasutra.com/view/feature/132124/redefining_game_narrative_.php?print=1&quot; title=&quot;Redefining Game Narrative: Ubisoft's Patrick Redding On Far Cry 2&quot;&gt;4&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;Tactically, enemies behave believably as well. Against sniper attacks, they dash to find cover and hide indefinitely. If the player incapacitates an enemy non-lethally, his companions will try to rescue him and take him to cover. If the enemies lose track of the player, they will spread out and procedurally comb the area they last saw the player. And, when attacking, enemies coordinate to constantly expose the player's cover.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://www.gamasutra.com/db_area/images/feature/3727/redding_farcry23.jpg&quot; /&gt;&lt;/p&gt;
&lt;p&gt;If an enemy notices a startled animal, he will investigate to see what startled it (which can often foil a stealthy approach). Other times, an enemy will leave his post to stalk and kill an animal himself.&lt;/p&gt;
&lt;p&gt;Enemy behavior is also noticeably different depending on the environment. For instance, during the night enemies tend to be more alert and during the day they tend to be more relaxed. If the player attacks with fire, enemies will largely ignore fighting the player until they ensure their own safety.&lt;/p&gt;
&lt;h3 id=&quot;simulating-the-avatar&quot;&gt;Simulating the Avatar&lt;/h3&gt;
&lt;p&gt;In most games, when the player takes an action, like opening a door, the action completes without the avatar animating to take it. The player must imagine that the action does not happen on its own. In the case of doors, the player must imagine it doesn't open on its own.&lt;a href=&quot;http://www.youtube.com/embed/XGehcQ0Uax8&quot;&gt;10&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;In Far Cry 2, this is not the case. When the player take an action, his avatar animates to take it in the game world. In the case of doors, the avatar physically turns the knob and opens it.&lt;/p&gt;
&lt;p&gt;It's not just doors though. When entering or exiting vehicles, the avatar physically climbs in or out-- there is no teleporting the camera.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://i.telegraph.co.uk/multimedia/archive/01111/farcry2_1111668c.jpg&quot; /&gt;&lt;/p&gt;
&lt;p&gt;When the player wants to consult a map, the avatar uses an in-game paper map, rather than some kind of menu. To scout, the avatar uses a compass and monocular.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://www.ps3trophies.org/images/guides/FC2_SQ6.jpg&quot; /&gt;&lt;/p&gt;
&lt;p&gt;When aiming, there is no aiming reticule to guide the player. Instead, he must shoot from the hip or look down the sights.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://assets1.ignimgs.com/2008/07/16/far-cry-2--20080715051148062-2474707_640w.jpg&quot; /&gt;&lt;/p&gt;
&lt;p&gt;When the avatar heals himself, he physically fixes his wound. For small wounds, the avatar might use a small syringe or a bandage, but for more grievous wounds the avatar might dig shrapnel out of his knee or pop a dislocated limb back into location.&lt;a href=&quot;http://www.youtube.com/embed/PKmdcZk-ZrQ&quot;&gt;11&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The lack of cutscenes, the minimal interface, and the heavy use of animation is not accidental. The avatar purposefully never speaks. The healing animations are deliberately shocking. The designers intentionally tried to create a close bond between the avatar and the game world reasoning that it would result in an equally visceral connection between the player and the game world.&lt;/p&gt;
&lt;h3 id=&quot;measuring-success&quot;&gt;Measuring Success&lt;/h3&gt;
&lt;p&gt;While it is of course impossible to guarantee that the player, the subject, will suspend his disbelief, it is at least evident that immersion was an important goal.&lt;a href=&quot;http://www.gamasutra.com/db_area/images/feature/3727/redding_farcry23.jpg&quot;&gt;12&lt;/a&gt; To what extent can we say the developers were successful?&lt;/p&gt;
&lt;p&gt;There is of course no way to measure how deeply a player is immersed. Nevertheless, we can make some guesses from the anecdotal responses that appeared after the game was published.&lt;/p&gt;
&lt;p&gt;One man was so moved that he replayed the game and wrote a 300 page diary of his experience.&lt;/p&gt;
&lt;p&gt;Another, Trent Polack, a senior game designer, calls &lt;em&gt;Far Cry 2&lt;/em&gt; his &quot;Game of the Decade&quot; for compelling him &quot;to write about it in ways that I simply don't for most games&quot; after telling a story&lt;a href=&quot;http://www.polycat.net/1934/awakened-in-africa/&quot; title=&quot;Awakened in Africa&quot;&gt;3&lt;/a&gt; from the perspective of himself in the game world.&lt;/p&gt;
&lt;p&gt;Another, Tom Bissel, author of &lt;em&gt;Extra Lives: Why Video Games Matter&lt;/em&gt;, describes a particular gripping emotional moment in his book:&lt;/p&gt;
&lt;blockquote readability=&quot;20&quot;&gt;
&lt;p&gt;At one point in &lt;em&gt;Far Cry 2&lt;/em&gt;, I was running along the savanna when I was spotted by two militiamen. I turned and shot, and, I thought, killed them both. When I waded into the waist-deep grass to picuk up their ammo, it transpired that one of the men was still alive. He proceeded to plug me with his side arm. Frantic, and low on health, I looked around trying to find the groaning, dying man, but the grass was too dense. I sprinted away only to be hit by a few more of his potshots. When I had put enough distance between us, I lobbed a Molotov cocktail into the general area where the supine, dying man lay. Within seconds I could hear him screaming amid the twiggy crackle of the grass catching fire. Sitting before my television, I felt a kind of horridly unreciprocated intimacy with the man I had just burned to death.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;from-comedy-to-tragedy&quot;&gt;From Comedy to Tragedy&lt;/h2&gt;
&lt;p&gt;According to Feagin, the difference between comedy and tragedy is that while both deal with unpleasant subject matter, comedy only evokes a direct response because it deals with subject matters that are judged insignificant. Feagin goes on to say that if it were the case that the matters were judged of great significance, it would be &quot;saddening rather than amusing that people were subject to such flaws&quot;.&lt;/p&gt;
&lt;p&gt;In this respect, &lt;em&gt;Far Cry 2&lt;/em&gt; faces some difficult obstacles. At least in American culture, video games are deemed insignificant (and therefore, unintuitively, comedies), even if they deal with significant matters like death.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://i.imgur.com/hN7GEdO.jpg&quot; /&gt;&lt;/p&gt;
&lt;p&gt;The problem is only made more difficult when we consider that the scripted narrative exists only to encourage the player to write his own, in which, unusually, the player is both the author and the protagonist. To establish its significance, &lt;em&gt;Far Cry 2&lt;/em&gt; needs to make the player tell a story where &lt;em&gt;he&lt;/em&gt; is the tragic hero.&lt;/p&gt;
&lt;h2 id=&quot;emergent-tragedy&quot;&gt;Emergent Tragedy&lt;/h2&gt;
&lt;p&gt;The developers solved this problem in an incredibly clever way. &lt;em&gt;Far Cry 2&lt;/em&gt; gives the player a variety of morally-abhorrent authorial blocks, a morally upright purpose, and then proceeds to slowly undermine that purpose. If and when it succeeds, like Othello just after killing Desdemona, the player will discover his tragic fault.&lt;/p&gt;
&lt;h3 id=&quot;exposition&quot;&gt;Exposition&lt;/h3&gt;
&lt;p&gt;At first, &lt;em&gt;Far Cry 2&lt;/em&gt; may seem like a stereotypical shooter.&lt;a href=&quot;http://www.youtube.com/embed/JgWlnoJcgTg&quot;&gt;13&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The game takes place in a imaginary central African country that is in a state of anarchy and civil war. Two factions, the United Front for Liberation and Labour (UFLL) and the Alliance for Popular Resistance (APR), battle for control, fueled on by an elusive arms dealer known as 'the Jackal'.&lt;/p&gt;
&lt;p&gt;The player enters the universe as a mercenary with no backstory.&lt;a href=&quot;http://www.youtube.com/embed/BaONaraCU-c&quot;&gt;14&lt;/a&gt; All we know is that he has recently arrived with orders to find and kill the Jackal:&lt;/p&gt;
&lt;blockquote readability=&quot;7&quot;&gt;
&lt;p&gt;The target's presence in the state continues to be a destabilizing influence. He is largely responsible for the recent influx of weapons into the country in clear violation of the Joint Signatory Framework. His reputation as a dangerous arms dealer is well-deserved. Orders are to terminate.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The player meets the Jackal at the beginning of the game after passing out from malaria. Waking up in a hotel and unable to move, the Jackal, revealed as an older American man, reads aloud the player's orders and recites some lines from Nietzsche in his disgust. He spares the player's life, but not long after he leaves, explosions rock the player from his bed and the game begins.&lt;/p&gt;
&lt;h3 id=&quot;rising-action&quot;&gt;Rising Action&lt;/h3&gt;
&lt;p&gt;After escaping to safety, what the player does is largely up to him.&lt;/p&gt;
&lt;p&gt;To be sure, there are a number of sub-tasks that the player must do. All are generic and uninteresting. They invariably involve taking contracts from local militia, weapons vendors, mercenary &quot;buddies&quot;, or anonymous voices behind cellphones, and then killing some person or destroying some thing.&lt;/p&gt;
&lt;p&gt;How the player completes these quests is entirely left to the player. And each time the player must surmount a number of obstacles posed by the world and his enemies.&lt;/p&gt;
&lt;h4 id=&quot;man-versus-environment&quot;&gt;Man versus environment&lt;/h4&gt;
&lt;p&gt;The conflict between man versus environment is always present.&lt;/p&gt;
&lt;p&gt;Much of the game is actually not spent fighting despite its nature as a shooter. Instead, much of the game involves running, swimming, driving, and boating to the next target or the next contract. Between the extremely violent conflicts, the game is unusually peaceful.&lt;a href=&quot;http://www.youtube.com/embed/mPpkadQlTpM&quot;&gt;15&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://uk.playstation.com/media/116330/far_cry_2_hero.jpg&quot; /&gt;&lt;/p&gt;
&lt;p&gt;However, while the game world frequently evokes a sense of awe, it is stained with a certain amount of grit and terror. Alex Amancio, the art director of &lt;em&gt;Far Cry 2&lt;/em&gt; sums it up cleanly:&lt;/p&gt;
&lt;blockquote readability=&quot;16&quot;&gt;
&lt;p&gt;While Crysis went for a hyper realistic style, a tropical island setting and an obvious sci-fi feel, Far Cry 2 plunges into something grittier and more primal. Our game changes the setting drastically and leads the player to a stylized, gritty, low tech universe where the player is forced to get down and dirty. Everything in the game is built around this principle and the universe is ever evolving on all fronts; from the destructibility, to the dynamic time of day and weather system, to the vehicles that you drive and the guns that you shoot that get dirtier, older and end up malfunctioning, Far Cry 2 is built around a living universe.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;And indeed, it shows. While in most games, everything &quot;just works&quot;, in &lt;em&gt;Far Cry 2&lt;/em&gt;, almost nothing does. Guns are unreliable and misfire at the worst moments (and if it's a rocket, you had better run). Vehicles move slowly and frequently break down. Fires suddenly change speed and direction with the wind. Malaria can bring the avatar to his knees at any moment.&lt;/p&gt;
&lt;p&gt;The in-game objects are similarly dull. There are no fancy cars or alien weapons. You use a rotting jeep to get around. A machete, a rusty assault rifle, and an RPG do your dirty work. Everything has its purpose and there is no pleasure from using them.&lt;/p&gt;
&lt;p&gt;The summed effect is a mix of aloneness, self-reliance, frustration, and estrangement.&lt;/p&gt;
&lt;h4 id=&quot;man-versus-man&quot;&gt;Man versus man&lt;/h4&gt;
&lt;p&gt;Man versus man is no less brutal. Again, there are no fantastic aliens or magic creatures to battle-- your enemies are men like yourself.&lt;/p&gt;
&lt;p&gt;As the player progresses, the game gets increasingly difficult, resulting in only more brutality. As enemies increase in number and acquire better equipment, the player's ability to experiment is reduced, his actions take on significance, and he is forced to become efficient and ruthless.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://jflevesque.com/wp-content/uploads/2012/12/Far-Cry-3-man-on-fire.jpg&quot; /&gt;&lt;/p&gt;
&lt;p&gt;The player adapts by learning guerrilla tactics. He trades his machine gun for a sniper rifle and his grenades for IEDs. He learns to scout using his map and monocular. He learns how to move without being detected and how to attack at night. He learns to control fire. He learns to shoot to wound. Killing becomes second nature.&lt;a href=&quot;http://www.youtube.com/embed/tsOSs1ZFrno&quot;&gt;16&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&quot;climax&quot;&gt;Climax&lt;/h3&gt;
&lt;p&gt;As all of this is happening, the game steadily works to undermine the player's moral purpose. This is done through a reputation system, called Infamy, which tracks the player's cruelty.&lt;/p&gt;
&lt;blockquote readability=&quot;10&quot;&gt;
&lt;p&gt;There's this notion that Infamy is this sort of the big counter under the hood that's driving the story to unfold in different ways. And the way I build my Infamy is by pulling the trigger. And by choosing to pull the trigger in a certain way, I can accelerate my growth of my Infamy. I can be a more cruel human being. - Patrick Redding, Narrative Designer of &lt;em&gt;Far Cry 2&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;As the player becomes increasingly violent, the world around him changes. The men in the ceasefire zones, once rowdy and loud, begin to whisper when the player gets close and apologize if the player bumps into them. When under attack, enemy shouts, once taunting the player, take on a tint of genuine fear.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://i.imgur.com/8gp0Gpt.jpg&quot; /&gt;&lt;/p&gt;
&lt;p&gt;It's not just the setting though. Infamy has meaningful consequences.&lt;/p&gt;
&lt;blockquote readability=&quot;10&quot;&gt;
&lt;p&gt;Eventually - depending on how you play - your infamy will become so apparent that the Underground will stop trusting you and will refuse to provide you with medicine. At that point, your health will start to fall and your malaria will start to worsen, and you will be forced to be even more ruthless and cold-blooded in order to press your advantage and complete your mission before you succumb completely to your disease.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;It is of course impossible to guarantee that the player will notice these changes. (And many reviewers did not.) But if and when he does, the tragic irony of the atrocities he has committed in the name of killing a villain manifests itself to the player. The player, once taking pleasure in the efficiency with which he conquered his enemies, suddenly feels ashamed. The narrative reaches its climax, and &lt;em&gt;Far Cry 2&lt;/em&gt; completes its transformation from comedy to tragedy, revealing itself as a modern-day Trojan Horse.&lt;/p&gt;
&lt;h3 id=&quot;denouement&quot;&gt;Denouement&lt;/h3&gt;
&lt;p&gt;The rest of the game is comparatively lackluster. The player resumes his hunt for the Jackal until the final act, which mandatorily ends with the betrayals, murders, and suicides involving every major character.&lt;/p&gt;
&lt;h2 id=&quot;analysis&quot;&gt;Analysis&lt;/h2&gt;
&lt;p&gt;Now we can return to our original question: does Feagin's theory still hold?&lt;/p&gt;
&lt;p&gt;For the most part, yes.&lt;/p&gt;
&lt;p&gt;At the moment the player realizes his mistake, he feels an immediate sense of shame. He looks at the pleasure he derived from his violence and he feels disgust. At the same time, he transforms into the tragic hero. He &lt;em&gt;does&lt;/em&gt; take disgust with himself for his actions, and in that sense he feels a certain amount of pleasure. There is, at least for a split-second, a meta-meta-response.&lt;/p&gt;
&lt;p&gt;Where Feagin's theory does not work so well though is in attempting to understand a game like &lt;em&gt;Far Cry 2&lt;/em&gt; as a moral or immoral work.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Far Cry 2&lt;/em&gt;, despite exploring moral themes, is ultimately amoral. Though it may &lt;em&gt;seem&lt;/em&gt; immoral in many respects--it does after all reward the player with diamonds for causing chaos--it never approves nor disapproves of the player's actions. The only moral influences that we might detect lie in obscure references to Nietzche and Joseph Conrad's 1899 novel &lt;em&gt;The Heart of Darkness&lt;/em&gt;. But like &lt;em&gt;Far Cry 2&lt;/em&gt;, neither have a moral message. Judgment is left to the player.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://www.gamasutra.com/db_area/images/feature/3727/redding_farcry21a.jpg&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Far Cry 2&lt;/em&gt; is really just a giant sandbox with moral elements that can be used to construct a morally significant narrative. Patrick Redding expresses the point clearly:&lt;a href=&quot;http://www.gamasutra.com/view/feature/132124/redefining_game_narrative_.php?print=1&quot; title=&quot;Redefining Game Narrative: Ubisoft's Patrick Redding On Far Cry 2&quot;&gt;4&lt;/a&gt;&lt;/p&gt;
&lt;blockquote readability=&quot;51&quot;&gt;
&lt;p&gt;So when we say, yeah, we want to make a game that's about one man's journey down the proverbial river into the heart of darkness, into the mind of a madman, what are the things that we can put in the game, what are the ingredients we can put in the game that support that? What are the kinds of characters, the kinds of environments that we want to try to create that will help support that?&lt;/p&gt;
&lt;p&gt;Ultimately at a certain point we have to be willing to let those things go and kind of give control over those things to the player. But I think one of the things we did is we said, &quot;Well, one kind of overriding question we want the player to be asking themselves is, 'How far are you willing to go in order to do the right thing?'&quot; In other words, how much bad stuff are you willing to do, how much of your soul are you willing to sacrifice, in the pursuit of a larger good?&lt;/p&gt;
&lt;p&gt;And it's important to say that we're not trying to take a position on that. We're not trying to say, &quot;Oh, the trouble with people today is they're not willing to do really terrible, evil, monstrous things in order to accomplish the greater good.&quot; This isn't like some neocon wet dream, right? The idea is that we don't pretend like we know the answer.&lt;/p&gt;
&lt;p&gt;We just say, let's take the player as close as we can - or an analog of the player - put him into this really, really difficult position, a terrible situation that probably most of us would like to avoid if we could, and try to get him to make decisions in a way that will help him survive, that will help him pursue his larger goals, that will allow him to potentially change those larger goals if he decides that he doesn't believe in them anymore, and to be able to deal with characters and situations on a case by case basis. In other words, give him the freedom to fuck up, give him the freedom to have a moment of triumph, or a moment of weakness, or moments of regret.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;amoral-art&quot;&gt;Amoral Art&lt;/h2&gt;
&lt;p&gt;As a brief aside, the role of amoral art is an interesting one. If we accept the premise that art has a role in moral education, it would seem that &lt;em&gt;Far Cry 2&lt;/em&gt; has done something entirely novel: letting its subject derive his morality from first-hand experience.&lt;/p&gt;
&lt;p&gt;Unlike a horror movie, where one may feel disgust for empathizing with the killer as he kills his victim, &lt;em&gt;Far Cry 2&lt;/em&gt; lets us feel the emotion directly, requiring &lt;em&gt;us&lt;/em&gt; to pull the trigger. Resulting feelings are not only different, but they require less imagination and can be more real.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://www.gamasutra.com/db_area/images/feature/3727/redding_farcry22.jpg&quot; /&gt;&lt;/p&gt;
&lt;p&gt;Furthermore, if we accept that &lt;em&gt;Far Cry 2&lt;/em&gt; truly immerses the player, that the subject does in fact believe he is the character he portrays, then we can see that video games have the potential to evoke emotions in players that other artworks cannot, namely, shame and its opposite, pride. Arguably, &lt;em&gt;Far Cry 2&lt;/em&gt; has pioneered what could become a new method of moral education.&lt;/p&gt;
&lt;p&gt;And despite being an amoral work, we nevertheless can see that it leads to proper moral education. Assuming morality is defined objectively, one can be taught by simply being given the opportunity to experiment in a safe environment.&lt;/p&gt;
&lt;h2 id=&quot;summary&quot;&gt;Summary&lt;/h2&gt;
&lt;p&gt;Susan Feagin's solution to the Tragedy of Paradox still appears useful despite the emergence of entirely new forms of narrative. We have seen this by exploring a modern work by Ubisoft called &lt;em&gt;Far Cry 2&lt;/em&gt;, which uniquely sets its subject up to create a tragedy where the subject is the tragic hero. Though Feagin would be unable to classify the work as either moral or immoral, it is undeniable that &lt;em&gt;Far Cry 2&lt;/em&gt; has demonstrated video games can have a unique role in future moral education.&lt;/p&gt;
</description>
<pubDate>Sun, 08 Dec 2019 06:42:33 +0000</pubDate>
<dc:creator>luu</dc:creator>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://ceasarbautista.com/essays/far_cry.html</dc:identifier>
</item>
<item>
<title>GCC-Rust: Rust frontend for GCC</title>
<link>https://github.com/sapir/gcc-rust/tree/rust</link>
<guid isPermaLink="true" >https://github.com/sapir/gcc-rust/tree/rust</guid>
<description>&lt;div class=&quot;Box-body&quot;&gt;
&lt;article class=&quot;markdown-body entry-content p-5&quot; itemprop=&quot;text&quot;&gt;
&lt;p&gt;This is currently at a very early stage. At the time of writing, it can compile trivial functions, like:&lt;/p&gt;
&lt;div class=&quot;highlight highlight-source-rust&quot;&gt;
&lt;pre&gt;
&lt;span class=&quot;pl-k&quot;&gt;fn&lt;/span&gt; &lt;span class=&quot;pl-en&quot;&gt;my_function&lt;/span&gt;(x: &lt;span class=&quot;pl-k&quot;&gt;i32&lt;/span&gt;) -&amp;gt; &lt;span class=&quot;pl-k&quot;&gt;i32&lt;/span&gt; { x }
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;But e.g. control flow doesn't work yet.&lt;/p&gt;
&lt;h2&gt;How does it work?&lt;/h2&gt;
&lt;p&gt;The &lt;code&gt;gcc/rust&lt;/code&gt; directory contains a frontend with some boilerplate that links to a Rust crate in &lt;code&gt;gcc/rust/gcc_rust&lt;/code&gt;. The Rust code runs rustc up to the MIR stage, then generates a GENERIC tree (a GCC IR) and passes it back to the C code. Access to GCC's internal APIs (especially macros) is handled by C wrapper functions in &lt;code&gt;gcc/rust/rust1.cc&lt;/code&gt;.&lt;/p&gt;
&lt;h2&gt;Build instructions&lt;/h2&gt;
&lt;p&gt;(Be warned, these are currently rather rough.)&lt;/p&gt;
&lt;p&gt;Build Rust with this patch: &lt;a href=&quot;https://github.com/rust-lang/rust/pull/67126&quot;&gt;https://github.com/rust-lang/rust/pull/67126&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;highlight highlight-source-shell&quot;&gt;
&lt;pre&gt;
mkdir gcc
&lt;span class=&quot;pl-c1&quot;&gt;cd&lt;/span&gt; gcc
git clone --depth 50 -b rust https://github.com/sapir/gcc-rust/ gcc-src
(cd gcc-src/gcc/rust/gcc-rust&lt;span class=&quot;pl-k&quot;&gt;;&lt;/span&gt; cargo build)

mkdir gcc-build
&lt;span class=&quot;pl-c1&quot;&gt;cd&lt;/span&gt; gcc-build
../gcc-src/configure \
    --prefix=&lt;span class=&quot;pl-s&quot;&gt;&lt;span class=&quot;pl-pds&quot;&gt;$(&lt;/span&gt;pwd&lt;span class=&quot;pl-pds&quot;&gt;)&lt;/span&gt;&lt;/span&gt;/../gcc-install \
    --enable-languages=c,c++,rust \
    --disable-multilib \
    --disable-bootstrap
make
make install

&lt;span class=&quot;pl-c1&quot;&gt;cd&lt;/span&gt; ..
gcc-install/bin/gcc whatever.rs -o whatever.so -shared
&lt;/pre&gt;&lt;/div&gt;
&lt;/article&gt;&lt;/div&gt;
</description>
<pubDate>Sun, 08 Dec 2019 05:47:41 +0000</pubDate>
<dc:creator>pcr910303</dc:creator>
<og:image>https://avatars1.githubusercontent.com/u/896766?s=400&amp;v=4</og:image>
<og:type>object</og:type>
<og:title>sapir/gcc-rust</og:title>
<og:url>https://github.com/sapir/gcc-rust</og:url>
<og:description>a (WIP) Rust frontend for gcc. Contribute to sapir/gcc-rust development by creating an account on GitHub.</og:description>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://github.com/sapir/gcc-rust/tree/rust</dc:identifier>
</item>
<item>
<title>Reducing the Performance Gap of Intel&amp;#039;s MKL on AMD Threadripper</title>
<link>https://www.pugetsystems.com/labs/hpc/How-To-Use-MKL-with-AMD-Ryzen-and-Threadripper-CPU-s-Effectively-for-Python-Numpy-And-Other-Applications-1637/</link>
<guid isPermaLink="true" >https://www.pugetsystems.com/labs/hpc/How-To-Use-MKL-with-AMD-Ryzen-and-Threadripper-CPU-s-Effectively-for-Python-Numpy-And-Other-Applications-1637/</guid>
<description>&lt;div readability=&quot;6.4298642533937&quot;&gt;
&lt;p&gt;&lt;strong&gt;Read this article at https://www.pugetsystems.com/guides/1637&lt;/strong&gt;&lt;/p&gt;

&lt;/div&gt;&lt;p&gt;&lt;span class=&quot;hidden-print&quot;&gt;&lt;strong&gt;Share:&lt;/strong&gt;&lt;input type=&quot;hidden&quot; id=&quot;puget_social_share_url&quot; value=&quot;https://www.pugetsystems.com/labs/hpc/How-To-Use-MKL-with-AMD-Ryzen-and-Threadripper-CPU-s-Effectively-for-Python-Numpy-And-Other-Applications-1637/&quot;/&gt;&lt;input type=&quot;hidden&quot; id=&quot;puget_social_share_text&quot; value=&quot;How To Use MKL with AMD Ryzen and Threadripper CPU\'s (Effectively) for Python Numpy (And Other Applications) &quot;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;puget-panel-box panel panel-default hidden-print&quot;&gt;
&lt;p&gt;&lt;strong&gt;Table of Contents&lt;/strong&gt;&lt;/p&gt;

&lt;/div&gt;
&lt;div class=&quot;clearfix&quot; readability=&quot;38.884331419196&quot;&gt;
&lt;h3 id=&quot;Introduction&quot;&gt;Introduction&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;In this post I'm going to show you a simple way to significantly speedup Python numpy compute performance on AMD CPU's when using Anaconda Python&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;We will set a DEBUG environment variable for Intel MKL that forces it to use the AVX2 vector unit on AMD CPU's (this will work for other applications too, like MATLAB for example.) ... but please see &quot;BIG Caveat!&quot; at the end of this post.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;You may be wondering why this is an issue. In a recent post &lt;a href=&quot;https://www.pugetsystems.com/labs/hpc/AMD-Ryzen-3900X-vs-Intel-Xeon-2175W-Python-numpy---MKL-vs-OpenBLAS-1560/&quot;&gt;&quot;AMD Ryzen 3900X vs Intel Xeon 2175W Python numpy - MKL vs OpenBLAS&quot;&lt;/a&gt; I showed how to do the first method using OpenBLAS and how bad performance was with AMD when using MKL. I also gave a bit of an history lesson explaining the long running &quot;Optimization&quot; issue between AMD and Intel. The short story is that Intel checks for &quot;Genuine Intel&quot; CPU's when it's numerical library MKL starts executing code. If it find an Intel CPU then it will follow an optimal code path for maximum performance on hardware. If it finds and AMD processor is takes a code path that only optimizes to the old (ancient) SSE2 instruction level i.e it doesn't take advantage of the performance features on AMD and the performance will be several times slower than it &quot;need&quot; to be.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;The following paragraph is one of the most regretted things I've written ...&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Maybe you're thinking that it's not &quot;fair&quot; for Intel to do that, but ... Intel has every right to do that! It IS their stuff. They worked hard utilized a lot of resources to develope it. And, there IS some incompatibility at the highest (or lowest) levels of optimization for the hardware. MKL is insanely well optimized for Intel CPU's ... as it should be!&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;I honestly don't feel that way!&lt;/strong&gt; This came up years ago when Intel first started marketing their compilers. I was outraged then and really, I still am. &lt;strong&gt;I think I was trying to &quot;justify&quot; it because I couldn't change it then and I can't change it now. The only thing I can do now is show people how to get around it!&lt;/strong&gt; For everyone that takes offense to that paragraph, I understand and I regret saying it. Collectively we should continue the fight against that sort of corporate tactic. --dbk&lt;/p&gt;
&lt;p&gt;Read the post listed above if you are interested in this old and ongoing issue.&lt;/p&gt;
&lt;p&gt;In the next sections we'll look at performance results from a simple numpy matrix algebra problem. There will be results from the post that was linked above along with new results using the 24-core AMD Threadripper 3960x.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;clearfix&quot;&gt;
&lt;h3 id=&quot;TestsystemsAMDThreadripper3960x,Ryzen3900XandIntelXeon2175W&quot;&gt;Test systems: AMD Threadripper 3960x, Ryzen 3900X and Intel Xeon 2175W&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;AMD Hardware&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;AMD Threadripper 3960x 24-core AVX2&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Motherboard Gigabyte TRX40 AORUS EXTREME&lt;/li&gt;
&lt;li&gt;Memory 8x DDR4-2933 16GB (128GB total)&lt;/li&gt;
&lt;li&gt;1TB Samsung 960 EVO NVMe M.2&lt;/li&gt;
&lt;li&gt;NVIDIA RTX 2080Ti GPU&lt;/li&gt;
&lt;/ul&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;AMD Ryzen 3900X 12-core AVX2&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Motherboard Gigabyte X570 AORUS ULTRA&lt;/li&gt;
&lt;li&gt;Memory 4x DDR4-3200 16GB (64GB total)&lt;/li&gt;
&lt;li&gt;2TB Intel 660p NVMe M.2&lt;/li&gt;
&lt;li&gt;NVIDIA 2080Ti GPU&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;Intel Hardware&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Intel Xeon-W 2175 14-core AVX512&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;ASUS C422 Pro SE (My personal workstation )&lt;/li&gt;
&lt;li&gt;128GB DDR4 2400 MHz Reg ECC memory&lt;/li&gt;
&lt;li&gt;Samsung 960 EVO 1TB NVMe M.2&lt;/li&gt;
&lt;li&gt;NVIDIA Titan V GPU&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;Software&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;Ubuntu 18.04&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://www.anaconda.com/distribution/&quot;&gt;Anaconda Python&lt;/a&gt; build Anaconda3-2019.07-Linux-x86_64&lt;/li&gt;
&lt;li&gt;numpy 1.16.4&lt;/li&gt;
&lt;li&gt;mkl 2019.4&lt;/li&gt;
&lt;li&gt;libopenblas 0.3.6&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;Notes:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;OpenBLAS is an excellent open source BLAS library based on the, highly regarded, work originally done by &lt;a href=&quot;https://en.wikipedia.org/wiki/Kazushige_Goto&quot;&gt;Kazushige Goto&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;OpenBLAS does not currently have optimizations for AVX512 (It does include AVX2 optimizations)&lt;/li&gt;
&lt;/ul&gt;&lt;/div&gt;
&lt;div class=&quot;clearfix&quot; readability=&quot;36&quot;&gt;
&lt;h3 id=&quot;UsingMKL_DEBUG_CPU_TYPE=5withAMDCPU\'s&quot;&gt;Using MKL_DEBUG_CPU_TYPE=5 with AMD CPU's&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;The environment variable above is the &quot;new secret way&quot; to fool MKL into using an AVX2 optimization level on AMD CPU's.&lt;/strong&gt; This environment variable has been available for years but it is not documented. &lt;strong&gt;PLEASE SEE THE CAVEAT IN THE CONCLUSION!&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;I seem to remember this from long ago with Opteron?? In any case it has been making the rounds on forums recently as a solution for getting MATLAB to perform better on AMD CPU's (other use cases too). This should work for any application that is making calls to the MKL runtime library. I believe it is forcing MKL to take the Haswell/Broadwell code path which gives an optimization level that includes AVX2. By default, MKL looks for &quot;Genuine Intel&quot; and if it doesn't find that it drops to a code path only optimized to SSE2 instruction level i.e. no modern hardware optimizations.&lt;/p&gt;
&lt;p&gt;On Linux you would set this environment variable in your working shell or add it to .bashrc&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;export MKL_DEBUG_CPU_TYPE=5&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;In a Jupyter notebook cell you could use (!),&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;!export MKL_DEBUG_CPU_TYPE=5&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;On Windows 10 you could set this in (Anaconda) Powershell as,&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;$Env:MKL_DEBUG_CPU_TYPE=5 &lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;or, you could set it in a Jupyter notebook cell using (!) the same as in Linux.&lt;/p&gt;
&lt;p&gt;You can also set this in System in Control Panel (Advanced tab or the Advanced System Settings item),&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;clearfix&quot;&gt;
&lt;p&gt;&lt;a href=&quot;https://www.pugetsystems.com/pic_disp.php?id=58487&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://www.pugetsystems.com/pic_disp.php?id=58487&amp;amp;width=800&quot; class=&quot;img-responsive center-block&quot; alt=&quot;System control panel Env&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;clearfix&quot; readability=&quot;10&quot;&gt;
&lt;h3 id=&quot;Threadripper3960x,Ryzen3900XandXeon2175WperformanceusingMKL,MKL_DEBUG_CPU_TYPE=5andOpenBLASforaPythonnumpy\&quot;&gt;Threadripper 3960x, Ryzen 3900X and Xeon 2175W performance using MKL, MKL_DEBUG_CPU_TYPE=5 and OpenBLAS for a Python numpy &quot;norm of matrix product&quot; calculation&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;numpy&lt;/strong&gt; is the most commonly used numerical computing package in Python. The calculation presented in this testing is very simple but computationally intensive. It will take advantage of the BLAS library that gives numpy it's great performance. In this case we will use Anaconda Python with &quot;envs&quot; setup for numpy linked with Intel MKL (the default) and with OpenBLAS (described in the next section).&lt;/p&gt;
&lt;hr/&gt;&lt;/div&gt;
&lt;div class=&quot;clearfix&quot;&gt;
&lt;p&gt;&lt;a href=&quot;https://www.pugetsystems.com/pic_disp.php?id=58488&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://www.pugetsystems.com/pic_disp.php?id=58488&amp;amp;width=800&quot; class=&quot;img-responsive center-block&quot; alt=&quot;numpy Ryzen 3900X vs Xeon 2175W MKL vs OpenBLAS&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;clearfix&quot; readability=&quot;15.834789515488&quot;&gt;
&lt;p&gt;Look at those results and think about it for awhile ... The standout features are,&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;The best result in the chart is for the TR 3960x using MKL with the environment var MKL_DEBUG_CPU_TYPE=5. AND it is significantly better than the low optimization code path from MKL alone. AND,OpenBLAS does nearly as well as MKL with MKL_DEBUG_CPU_TYPE=5 set.&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;MKL provides tremendous performance optimization on Intel CPU's The test job is definitely benefiting from AVX512 optimizations which are not available in this OpenBLAS version.&lt;/li&gt;
&lt;li&gt;OpenBLAS levels the performance difference considerably by providing good optimization up to the level of AVX2. (keep in mind that the 2175W is 14-core vs 12-cores on the Ryzen 3900X and 24 cores on the TR 3960x)&lt;/li&gt;
&lt;li&gt;The low optimization code-path used for AMD CPU's by MKL is devastating to performance.&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;This test clearly shows the effect of hardware specific code optimization. It is also pretty synthetic! In the real world programs are more complicated and are usually not anywhere near fully optimized especially in regards to vectorization that takes advantage of AVX. There are also common numerical libraries that are not so heavily targeted to specific architectures. For example, the popular, and very good, C++ &lt;a href=&quot;https://www.boost.org/&quot;&gt;boost library&lt;/a&gt; suite.&lt;/p&gt;
&lt;/div&gt;

&lt;div class=&quot;clearfix&quot; readability=&quot;19.046692607004&quot;&gt;
&lt;h3 id=&quot;Conclusion(BIGCaveat!)&quot;&gt;Conclusion (BIG Caveat!)&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;I have to reiterate, MKL_DEBUG_CPU_TYPE is an undocumented environment variable. That means that Intel can remove it at any time without warning.&lt;/strong&gt; And, they have every right to do that! It is obviously intended for internal debugging, not for running with better performance on AMD hardware. It is also possible that the resulting code path has some precision loss or other problems on AMD hardware. I have not tested for that!&lt;/p&gt;
&lt;p&gt;The best solution for running numerical intensive code on AMD CPU's is to try working with AMD's BLIS library if you can. Version 2.0 of BLIS gave very good performance in &lt;a href=&quot;https://www.pugetsystems.com/labs/hpc/AMD-Threadripper-3970x-Compute-Performance-Linpack-and-NAMD-1631/&quot;&gt;my recent testing on the new 3rd gen Threadripper&lt;/a&gt;. For the numpy testing above it would be great to be able to use the BLIS v2.0 library with Anaconda Python the same way that I used OpenBLAS. Someone just needs to setup the conda package with the proper hooks to set it as default BLAS. I don't have the time or expertise to do this myself, so, if you can do it then please do! and let me know about it!&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;clearfix&quot; readability=&quot;7&quot;&gt;
&lt;p&gt;&lt;strong&gt;Happy computing! --dbk @dbkinghorn&lt;/strong&gt;&lt;/p&gt;
&lt;hr/&gt;&lt;/div&gt;
&lt;div class=&quot;clearfix&quot;&gt;
&lt;div class=&quot;puget-box-grid panel panel-default&quot;&gt;
&lt;div class=&quot;row&quot; readability=&quot;6.5506756756757&quot;&gt;
&lt;div class=&quot;col-sm-4&quot;&gt;&lt;a href=&quot;https://www.pugetsystems.com/peak.php&quot; target=&quot;_self&quot;&gt;&lt;img class=&quot;img-responsive center-block&quot; src=&quot;https://www.pugetsystems.com/pic_disp.php?id=51090&amp;amp;height=200&quot;/&gt;&lt;/a&gt;&lt;/div&gt;
&lt;div class=&quot;col-sm-8&quot; readability=&quot;8.4222972972973&quot;&gt;
&lt;h3&gt;Looking for a GPU Accelerated Workstation?&lt;/h3&gt;
&lt;p&gt;Puget Systems offers a range of workstations that are tailor-made for your unique workflow. Our goal is to provide the most effective and reliable system possible so you can concentrate on your work and not worry about your computer.&lt;/p&gt;
&lt;p&gt;&lt;a class=&quot;btn btn-lg btn-primary&quot; href=&quot;https://www.pugetsystems.com/peak.php&quot;&gt;Configure a System!&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;puget-box-grid panel panel-default&quot;&gt;
&lt;div class=&quot;row&quot;&gt;
&lt;div class=&quot;col-sm-6&quot;&gt;
&lt;h3&gt;Related Content&lt;/h3&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;clearfix&quot; readability=&quot;6.0690537084399&quot;&gt;
&lt;h2&gt;Why Choose Puget Systems?&lt;/h2&gt;
&lt;p&gt;Click &lt;a href=&quot;https://www.pugetsystems.com/included.php&quot;&gt;here&lt;/a&gt; for even more reasons!&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;clearfix&quot;&gt;
&lt;h2&gt;Puget Systems Hardware Partners&lt;/h2&gt;

&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Tags:&lt;/strong&gt; Ryzen, Python, Scientific Computing, AMD, numpy, BLAS, Threadripper&lt;/p&gt;
</description>
<pubDate>Sat, 07 Dec 2019 22:10:50 +0000</pubDate>
<dc:creator>smartmic</dc:creator>
<og:url>https://www.pugetsystems.com/labs/hpc/How-To-Use-MKL-with-AMD-Ryzen-and-Threadripper-CPU-s-Effectively-for-Python-Numpy-And-Other-Applications-1637/</og:url>
<og:title>How To Use MKL with AMD Ryzen and Threadripper CPU's (Effectively) for Python Numpy (And Other Applications)</og:title>
<og:description>In this post I'm going to show you a simple way to significantly speedup Python numpy compute performance on AMD CPU's when using Anaconda Python.</og:description>
<og:image>https://cdn.pugetsystems.com/legacy/gfx/logo_square.jpg</og:image>
<og:type>article</og:type>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.pugetsystems.com/labs/hpc/How-To-Use-MKL-with-AMD-Ryzen-and-Threadripper-CPU-s-Effectively-for-Python-Numpy-And-Other-Applications-1637/</dc:identifier>
</item>
<item>
<title>The Product-Minded Software Engineer</title>
<link>https://blog.pragmaticengineer.com/the-product-minded-engineer/</link>
<guid isPermaLink="true" >https://blog.pragmaticengineer.com/the-product-minded-engineer/</guid>
<description>&lt;p&gt;Product-minded engineers are developers with lots of interest in the product itself. They want to understand why decisions are made, how people use the product, and love to be involved in making product decisions. They're someone who would likely make a good product manager if they ever decide to give up the joy of engineering. I've worked with many great product-minded engineers and consider myself to be this kind of developer. At companies building world-class products, product-minded engineers take teams to a new level of impact.&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://twitter.com/sherifmansour&quot;&gt;Sherif Mansour&lt;/a&gt;, PM at Atlassian wrote &lt;a href=&quot;https://medium.com/@sherifmansour/product-engineers-f424da766871&quot;&gt;an excellent article&lt;/a&gt; on product engineers, and how product managers can identify these people and work well with them. His takeaway is similar:&lt;/p&gt;
&lt;blockquote readability=&quot;9&quot;&gt;
&lt;p&gt;&lt;em&gt;Over my last ten years of product management, &lt;strong&gt;I’ve come to conclude that product engineers are a critical ingredient to helping you build a successful product&lt;/strong&gt;, scale yourself and become a better product manager.&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;He also quotes &lt;a href=&quot;https://twitter.com/jmwind&quot;&gt;Jean-Michel Lemieux&lt;/a&gt;, head of engineering at Shopify who defines product engineers like this:&lt;/p&gt;
&lt;blockquote readability=&quot;10&quot;&gt;
&lt;p&gt;&lt;em&gt;Once you have the product foundations, you need devs who engage with the 'why', actively. Engineers who have the thirst for using technologies to leapfrog human/user problems. Those with empathy to reach for magical experiences. That is what defined a product engineer in my books. Bad ones cut too many corners. &lt;strong&gt;Great product engineers know that minimum lovable products need the right depth&lt;/strong&gt; to be considered during the build phase.&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Teams who are working on user-facing features, collaborating with product managers are environments where product-minded engineers can have a huge impact. They often become key contributors, the goto people for product managers and frequently advance to being team leads. &lt;strong&gt;So, what are the key traits of product-minded engineers, and how can you work on becoming more product-minded?&lt;/strong&gt; This article summarizes 9 traits I've observed these kinds of people share, and &lt;a href=&quot;https://blog.pragmaticengineer.com/the-product-minded-engineer/#tips-to-become-a-more-product-minded-engineer&quot;&gt;my suggestions for any engineer to grow their product-minded muscle&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&quot;1-proactive-with-product-ideas-opinions&quot;&gt;1. Proactive with product ideas/opinions&lt;/h2&gt;
&lt;p&gt;Product-minded engineers don’t settle for getting a specification and jumping to implement it. They think about other ideas and approach the product manager with these. They often challenge existing specifications, suggesting alternative product approaches, that might work better.&lt;/p&gt;
&lt;h2 id=&quot;2-interest-in-the-business-user-behavior-and-data-on-this&quot;&gt;2. Interest in the business, user behavior and data on this&lt;/h2&gt;
&lt;p&gt;When coming with ideas, product-minded engineers don't just get these from thin air. They take the time to understand how the business works, how the product fits in, and what its goals are. They are also empathetic about how the product makes users feel and how those users benefit from using this product. They often dive straight to data about business and user metrics, getting their hands on this data however they can. They might access it directly - if this is possible - or approach the product manager or data scientists to get this kind of information. They do this because of their curious nature. This is the next trait I've observed.&lt;/p&gt;
&lt;h2 id=&quot;3-curiosity-and-a-keen-interest-in-why&quot;&gt;3. Curiosity and a keen interest in &quot;why?&quot;&lt;/h2&gt;
&lt;p&gt;Product-minded engineers like to understand the &quot;why?&quot; behind all things. Why build this feature for the product, why not the other one? Why ship this first milestone, instead of choosing another one, that's a lot simpler to build? How will things be measured - why don't we choose a more thorough way to measure things?&lt;/p&gt;
&lt;p&gt;They are autonomous in finding answers they can, by themselves. They turn to the product manager and other people in the business for other, product-related questions. Even though they ask many questions, doing this frequently, they manage not to annoy people, as they've built up strong relationships with them.&lt;/p&gt;
&lt;h2 id=&quot;4-strong-communicators-and-great-relationships-with-non-engineers&quot;&gt;4. Strong communicators and great relationships with non-engineers&lt;/h2&gt;
&lt;p&gt;Product-minded engineers like talking with people outside engineering, learning about what and why they do. They are smooth communicators, making it clear they're interested in learning more about how other disciplines work. I frequently see them grabbing coffee, lunch, or doing a hallway chat with non-engineers.&lt;/p&gt;
&lt;h2 id=&quot;5-offering-product-engineering-tradeoffs-upfront&quot;&gt;5. Offering product/engineering tradeoffs upfront&lt;/h2&gt;
&lt;p&gt;Because they have a strong understanding of the product &quot;why,&quot; as well as the engineering side of things, they can bring suggestions that few other people can. For example, when scoping the effort to build the product, the engineering effort to build a key feature might be significant. Many engineers would start to look for ways to reduce the effort and try to figure out what the impact of the reduced effort would mean for the feature itself.&lt;/p&gt;
&lt;p&gt;Product-minded engineers attack this problem from both angles: both looking for engineering tradeoffs and what the product impact is. They also start making product tradeoffs, evaluating the engineering impact. They often go back to the product manager, suggesting a completely different feature to be built, given the product impact would be similar, but the engineering effort vastly smaller.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Juggling both the product and engineering tradeoffs and the impact of each is a unique strength product-minded engineers have.&lt;/strong&gt; They can quickly go back-and-forth between the two sides of the same coin: product features and engineering effort and tradeoffs. Because they do it all in their head, using their engineering and product insights, they get to valuable conclusions remarkably quickly.&lt;/p&gt;
&lt;h2 id=&quot;6-pragmatic-handling-of-edge-cases&quot;&gt;6. Pragmatic handling of edge cases&lt;/h2&gt;
&lt;p&gt;Edge cases are a funny thing. On one extreme, engineers often forget about many of these, having to come back to addressing them, after getting feedback from people testing the product or end users. On the other hand, handling all possible edge cases in a new product or feature can take a lot of time.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Product-minded engineers quickly map out edge cases and think of ways to reduce work on them: often bringing solutions that require no engineering work.&lt;/strong&gt; They are focused on the &quot;minimum lovable product concept&quot; and evaluate the impact of an edge case and the effort of handling it. They come with good middle-ground suggestions: mapping out most things that can go wrong and bring suggestions on what edge cases need to be addressed, before shipping even an early version.&lt;/p&gt;
&lt;p&gt;For example, if one in a thousand users might be hit by an error, they will consider the effort to fix it and think about what happens if they don't do anything. Can customer support help the person in this case, during validation? Can the user just retry and succeed the next time? Can the product be slightly modified, so this edge case won't occur?&lt;/p&gt;
&lt;h2 id=&quot;7-quick-product-validation-cycles&quot;&gt;7. Quick product validation cycles&lt;/h2&gt;
&lt;p&gt;Even before the feature they are working on is production-ready, product-minded engineers find creative ways to get early feedback. This could be doing hallway testing with colleagues, showing the work-in-progress feature to the product manager, organizing a team bug bash on the beta build, and many other, creative ways. They are continuously thinking:&quot;how can we validate that people will use this feature, the way we think they will?&quot;&lt;/p&gt;
&lt;h2 id=&quot;8-end-to-end-product-feature-ownership&quot;&gt;8. End-to-end product feature ownership&lt;/h2&gt;
&lt;p&gt;Most experienced engineers own their work end-to-end: from getting the specification, through implementing it, all the way to rolling it out and validating that it works correctly. Product-minded engineers often go a step beyond this.&lt;/p&gt;
&lt;p&gt;They consider their work done only after getting results on user behavior and business metrics. After rollout, they still actively engage with product managers, data scientists, and customer support channels, to learn how the feature is being used in the real world. It can take weeks to get enough reliable data to draw conclusions. Even though they might be working on a new project, they make checking on the results one of their top priorities. It's not a time-consuming activity, but it needs that additional persistence from someone wanting to know: how is my work &lt;em&gt;really&lt;/em&gt; doing?&lt;/p&gt;
&lt;p&gt;When a feature performs worse than expected, they are curious to understand where the mismatch was. They are just as interested in finding the root cause between the product plan and the real world result, as they are to debug a hard-to-reproduce bug in the codebase. They'll often spend a good amount of time debating hypothesizes and learnings with the product manager and data scientists.&lt;/p&gt;
&lt;h2 id=&quot;9-strong-product-instincts-through-repeated-cycles-of-learning&quot;&gt;9. Strong product instincts through repeated cycles of learning&lt;/h2&gt;
&lt;p&gt;A typical project for a product-minded engineer usually goes like this:&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;They ask a lot of questions to understand exactly why the product feature is being built.&lt;/li&gt;
&lt;li&gt;They bring suggestions and tradeoffs to the table, some of which are included in the revised spec.&lt;/li&gt;
&lt;li&gt;They build the feature quickly, getting early feedback, as they do.&lt;/li&gt;
&lt;li&gt;After shipping the feature, they actively follow up to understand if the feature lives up to the expectation.&lt;/li&gt;
&lt;li&gt;When it does not, they dig deep, to understand why it did not and learn something new about product usage in the real world.&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;After each project, their product understanding deepens, and they start to develop better and better product instincts. The next time, they'll bring even more relevant suggestions to the table. Over time, they become a goto person for product managers, their advice being sought well before projects are kicked off. They build a strong reputation outside the team, opening more doors for their continued career growth.&lt;/p&gt;
&lt;h2 id=&quot;tips-to-become-a-more-product-minded-engineer&quot;&gt;Tips to become a more product-minded engineer&lt;/h2&gt;
&lt;p&gt;If you work on a user-facing product, here are a few tips I've seen work well, to growing your product-minded muscle.&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Understand how and why your company is successful&lt;/strong&gt;. What is the business model? How is money made? What parts are most profitable, what parts of the company are expanding the most? Why? How does your team fit into all of this?&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Build a strong relationship with your product manager&lt;/strong&gt;. Most product managers jump on the opportunity to mentor engineers. Having engineers be interested in product means they can scale themselves more. Before coming in, asking a lot of product questions, take time to build this relationship and make it clear to your product manager, that you'd like to get more involved in product topics.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Engage in user research, customer support&lt;/strong&gt;, and other activities, where you can learn more about how the product works. Pair with designers, UX people, data scientists, operations people and others, who frequently interact with users.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Bring well-backed product suggestions to the table.&lt;/strong&gt; After you have a good understanding of the business, the product and stakeholders: take initiative. You could bring small suggestions to a project you are working on. Or you could suggest a larger effort, outlining the engineering effort and the product effort, making this easy to prioritize in the backlog.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Offer product/engineering tradeoffs&lt;/strong&gt; for the projects you work on. Think of not only making engineering tradeoffs for the product feature your team is building but suggest product tradeoffs that result in less engineering effort. Be open to the feedback on these from others.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Ask for frequent feedback from your product manager.&lt;/strong&gt; Being a great product-minded engineer means you have built up good product skills, on top of your existing engineering skillset. The best person to give you feedback on how you're doing on the product skillset is your product manager. Reach out for feedback on how valuable they see your product suggestions and ask for thoughts on areas for further growth.&lt;/li&gt;
&lt;/ul&gt;</description>
<pubDate>Sat, 07 Dec 2019 19:22:29 +0000</pubDate>
<dc:creator>turingbook</dc:creator>
<og:type>article</og:type>
<og:title>The Product-Minded Software Engineer</og:title>
<og:description>Product-minded engineers are developers with lots of interest in the product itself. They want to understand why decisions are made, how people use the product, and love to be involved in making product decisions. They're someone who would likely make a good product manager if they ever decide to give</og:description>
<og:url>https://blog.pragmaticengineer.com/the-product-minded-engineer/</og:url>
<og:image>https://blog.pragmaticengineer.com/content/images/2019/09/william-iven-gcsNOsPEXfs-unsplash.jpg</og:image>
<dc:format>text/html</dc:format>
<dc:identifier>https://blog.pragmaticengineer.com/the-product-minded-engineer/</dc:identifier>
</item>
<item>
<title>The rise and fall of the PlayStation supercomputers</title>
<link>https://www.theverge.com/2019/12/3/20984028/playstation-supercomputer-ps3-umass-dartmouth-astrophysics-25th-anniversary</link>
<guid isPermaLink="true" >https://www.theverge.com/2019/12/3/20984028/playstation-supercomputer-ps3-umass-dartmouth-astrophysics-25th-anniversary</guid>
<description>&lt;p id=&quot;Jq3VWy&quot;&gt;Dozens of PlayStation 3s sit in a refrigerated shipping container on the University of Massachusetts Dartmouth’s campus, sucking up energy and investigating astrophysics. It’s a popular stop for tours trying to sell the school to prospective first-year students and their parents, and it’s one of the few living legacies of a weird science chapter in PlayStation’s history.&lt;/p&gt;
&lt;p id=&quot;zAG69Y&quot;&gt;Those squat boxes, hulking on entertainment systems or dust-covered in the back of a closet, were once coveted by researchers who used the consoles to build supercomputers. With the racks of machines, the scientists were suddenly capable of contemplating the physics of black holes, processing drone footage, or winning &lt;a href=&quot;https://www.umassd.edu/feature-stories/2014/ps3-supercomputer-cryptography-contest.html&quot;&gt;cryptography contests&lt;/a&gt;. It only lasted a few years before tech moved on, becoming smaller and more efficient. But for that short moment, some of the most powerful computers in the world could be hacked together with code, wire, and gaming consoles.&lt;/p&gt;
&lt;div class=&quot;c-float-right&quot;&gt;
&lt;aside id=&quot;ppEXvZ&quot;&gt;&lt;q&gt;some of the most powerful computers in the world could be hacked together with code, wire, and gaming consoles&lt;/q&gt;&lt;/aside&gt;&lt;/div&gt;
&lt;p id=&quot;2QnqB8&quot;&gt;Researchers had been messing with the idea of using graphics processors to boost their computing power for years. The idea is that the same power that made it possible to render &lt;em&gt;Shadow of the Colossus’&lt;/em&gt; grim storytelling was also capable of doing massive calculations — if researchers could configure the machines the right way. If they could link them together, suddenly, those consoles or computers started to be far more than the sum of their parts. This was cluster computing, and it wasn’t unique to PlayStations; plenty of researchers were trying to harness computers to work as a team, trying to get them to solve increasingly complicated problems.&lt;/p&gt;
&lt;p id=&quot;UUprOU&quot;&gt;The game consoles entered the supercomputing scene in 2002 when Sony released a kit called Linux for the PlayStation 2. “It made it accessible,” Craig Steffen said. “They built the bridges, so that you could write the code, and it would work.” Steffen is now a senior research scientist at the National Center for Supercomputing Applications (NCSA). In 2002, he had just joined the group and started working on a project with the goal of buying a bunch of PS2s and using the Linux kits to hook them (and their Emotion Engine central processing units) together into something resembling a supercomputer.&lt;/p&gt;
&lt;p id=&quot;MUb8Zj&quot;&gt;They hooked up between 60 and 70 PlayStation 2s, wrote some code, and built out a library. “It worked okay, it didn’t work superbly well,” Steffen said. There were technical issues with the memory — two specific bugs that his team had no control over.&lt;/p&gt;
&lt;div class=&quot;c-float-right&quot;&gt;
&lt;aside id=&quot;dyryYa&quot;&gt;&lt;q&gt;“it would have to be rebooted, which was a bummer.”&lt;/q&gt;&lt;/aside&gt;&lt;/div&gt;
&lt;p id=&quot;do7GQh&quot;&gt;“Every time you ran this thing, it would cause the kernel on whatever machine you ran it on to kind of go into this weird unstable state and it would have to be rebooted, which was a bummer,” Steffen said.&lt;/p&gt;
&lt;p id=&quot;t0NJjD&quot;&gt;They shut the project down relatively quickly and moved on to other questions at the NCSA. Steffen still keeps one of the old PS2s on his desk as a memento of the program.&lt;/p&gt;
&lt;p id=&quot;Hlrx2g&quot;&gt;But that’s not where PlayStation’s supercomputing adventures met their end. The PS3 entered the scene in late 2006 with powerful hardware and an easier way to load Linux onto the devices. Researchers would still need to link the systems together, but suddenly, it was possible for them to imagine linking together all of those devices into something that was a game-changer instead of just a proof-of-concept prototype.&lt;/p&gt;
&lt;span class=&quot;e-image__inner&quot;&gt;&lt;span class=&quot;e-image__image&quot; data-original=&quot;https://cdn.vox-cdn.com/uploads/chorus_asset/file/19410993/DSC_0140.jpg&quot;&gt; &lt;img srcset=&quot;https://cdn.vox-cdn.com/thumbor/dTY7b2d2rLCxbUTsbu5HaW8xStQ=/0x0:534x800/320x0/filters:focal(0x0:534x800):no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/19410993/DSC_0140.jpg 320w, https://cdn.vox-cdn.com/thumbor/VLrM3I3WxOjU3KMRsrch6MGCOH8=/0x0:534x800/520x0/filters:focal(0x0:534x800):no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/19410993/DSC_0140.jpg 520w, https://cdn.vox-cdn.com/thumbor/vf3ZMX8No894WwqS9YoLL5kxehA=/0x0:534x800/720x0/filters:focal(0x0:534x800):no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/19410993/DSC_0140.jpg 720w, https://cdn.vox-cdn.com/thumbor/ztGea_1Vwvsr_U63vU-8bNZ08qg=/0x0:534x800/920x0/filters:focal(0x0:534x800):no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/19410993/DSC_0140.jpg 920w, https://cdn.vox-cdn.com/thumbor/rUXSHdBkowlsga5ORzmrSDLPnIU=/0x0:534x800/1120x0/filters:focal(0x0:534x800):no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/19410993/DSC_0140.jpg 1120w, https://cdn.vox-cdn.com/thumbor/Vc6stqMWNAxIbLZVXmd6JbP0b0A=/0x0:534x800/1320x0/filters:focal(0x0:534x800):no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/19410993/DSC_0140.jpg 1320w, https://cdn.vox-cdn.com/thumbor/t-PzCp1iZ203iebPX0aN8BEHuwA=/0x0:534x800/1520x0/filters:focal(0x0:534x800):no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/19410993/DSC_0140.jpg 1520w, https://cdn.vox-cdn.com/thumbor/JjbYUaKMC1GYh73Bb5TEmSl7bpc=/0x0:534x800/1720x0/filters:focal(0x0:534x800):no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/19410993/DSC_0140.jpg 1720w, https://cdn.vox-cdn.com/thumbor/r5xmhT8wboj0PXjNf-RAE3_-LVo=/0x0:534x800/1920x0/filters:focal(0x0:534x800):no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/19410993/DSC_0140.jpg 1920w&quot; sizes=&quot;(min-width: 1221px) 846px, (min-width: 880px) calc(100vw - 334px), 100vw&quot; alt=&quot;3 metal racks, each with 24 PS3s neatly arrayed on them in a room. the PS3s are connected with green wires&quot; data-upload-width=&quot;534&quot; src=&quot;https://cdn.vox-cdn.com/thumbor/yo2qKKmguTmk9JVqCY2gnfSrbq0=/0x0:534x800/1200x0/filters:focal(0x0:534x800):no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/19410993/DSC_0140.jpg&quot;/&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class=&quot;e-image__meta&quot;&gt;&lt;em&gt;A PS3 supercomputer at UMass Dartmouth.&lt;/em&gt; &lt;cite&gt;Photo by Gaurav Khanna / UMass Dartmouth&lt;/cite&gt;&lt;/span&gt;
&lt;p id=&quot;dbiMqj&quot;&gt;That’s certainly what black hole researcher Gaurav Khanna was imagining over at UMass Dartmouth. “Doing pure period simulation work on black holes doesn’t really typically attract a lot of funding, it’s just because it doesn’t have too much relevance to society,” Khanna said.&lt;/p&gt;
&lt;p id=&quot;f9loIF&quot;&gt;Money was tight, and it was getting tighter. So Khanna and his colleagues were brainstorming, trying to think of solutions. One of the people in his department was an avid gamer and mentioned the PS3’s Cell processor, which was made by IBM. A similar kind of chip &lt;a href=&quot;https://www.extremetech.com/computing/152191-worlds-first-petaflop-supercomputer-is-obsolete-after-just-five-years-will-be-shut-down&quot;&gt;was being used to build advanced supercomputers&lt;/a&gt;. “So we got kind of interested in it, you know, is this something interesting that we could &lt;em&gt;misuse&lt;/em&gt; to do science?” Khanna says.&lt;/p&gt;
&lt;div class=&quot;c-float-right&quot;&gt;
&lt;aside id=&quot;GFS20F&quot;&gt;&lt;q&gt;“is this something interesting that we could &lt;em&gt;misuse&lt;/em&gt; to do science?”&lt;/q&gt;&lt;/aside&gt;&lt;/div&gt;
&lt;p id=&quot;UhpMmn&quot;&gt;Inspired by the specs of Sony’s new machine, the astrophysicist started buying up PS3s and building his own supercomputer. It took Khanna several months to get the code into shape and months more to clean up his program into a working order. He started with eight, but by the time he was done, he had his own supercomputer, pieced together out of 176 consoles and ready to run his experiments — no jockeying for space or paying other researchers to run his simulations of black holes. Suddenly, he could run complex computer models or win cryptography competitions at a fraction of the cost of a more typical supercomputer.&lt;/p&gt;
&lt;p id=&quot;KdOdii&quot;&gt;Around the same time, other researchers were having similar ideas. A group in North Carolina also &lt;a href=&quot;https://arcb.csc.ncsu.edu/~mueller/cluster/ps3/coe.html&quot;&gt;built a PS3 supercomputer in 2007&lt;/a&gt;, and a few years later, at the Air Force Research Laboratory in New York, computer scientist Mark Barnell started working on a similar project called the Condor Cluster.&lt;/p&gt;
&lt;p id=&quot;0irl8q&quot;&gt;The timing wasn’t great. Barnell’s team proposed the project in 2009, just as Sony was shifting toward the pared-back PS3 slim, which didn’t have the capability to run Linux, unlike the original PS3. After a hack, Sony even issued a firmware update that pulled OpenOS, the system that allowed people to run Linux, from existing PS3 systems. That made finding useful consoles even harder. The Air Force had to convince Sony to sell it the un-updated PS3s that the company was pulling from shelves, which, at the time, were sitting in a warehouse outside Chicago. It took many meetings, but eventually, the Air Force got what it was looking for, and in 2010, the project had its big debut.&lt;/p&gt;
&lt;div class=&quot;c-float-right&quot;&gt;
&lt;aside id=&quot;Kz51Yj&quot;&gt;&lt;q&gt;more than 1,700 PS3s connected by five miles of wire&lt;/q&gt;&lt;/aside&gt;&lt;/div&gt;
&lt;p id=&quot;vcaF4z&quot;&gt;Running on more than 1,700 PS3s that were connected by five miles of wire, the Condor Cluster was huge, dwarfing Khanna’s project, and it used to process images from surveillance drones. During its heyday, it was the &lt;a href=&quot;https://gcn.com/Articles/2010/12/14/Condor-Cluster-Spreads-its-Wings.aspx?Page=1&amp;amp;m=1&quot;&gt;35th fastest supercomputer in the world&lt;/a&gt;.&lt;/p&gt;
&lt;p id=&quot;6zox3u&quot;&gt;But none of this lasted long. Even while these projects were being built, supercomputers were advancing, becoming more powerful. At the same time, gaming consoles were simplifying, making them less useful to science. The PlayStation 4 &lt;a href=&quot;https://www.theverge.com/2019/10/30/20939639/ps4-lifetime-sales-vs-ps1-wii-sony&quot;&gt;outsold both the original PlayStation and the Wii&lt;/a&gt; nearing the best-selling status currently held by the PS2. But for researchers, it was nearly useless. Like the slimmer version of the PlayStation 3 released before it, the PS4 can’t easily be turned into a cog for a supercomputing machine. “There’s nothing novel about the PlayStation 4, it’s just a regular old PC,” Khanna says. “We weren’t really motivated to do anything with the PlayStation 4.”&lt;/p&gt;
&lt;p id=&quot;kdNQTs&quot;&gt;The era of the PlayStation supercomputer was over.&lt;/p&gt;
&lt;span class=&quot;e-image__inner&quot;&gt;&lt;span class=&quot;e-image__image&quot; data-original=&quot;https://cdn.vox-cdn.com/uploads/chorus_asset/file/19434211/vpavic_191205_untitled_0014_Edit.jpg&quot;&gt; &lt;img srcset=&quot;https://cdn.vox-cdn.com/thumbor/HzehSNtnchCv2Kwe4_exHqT852o=/0x0:2040x1360/320x0/filters:focal(0x0:2040x1360):no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/19434211/vpavic_191205_untitled_0014_Edit.jpg 320w, https://cdn.vox-cdn.com/thumbor/nw2AeWD3VxyztMrh2Bs7heps0vk=/0x0:2040x1360/520x0/filters:focal(0x0:2040x1360):no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/19434211/vpavic_191205_untitled_0014_Edit.jpg 520w, https://cdn.vox-cdn.com/thumbor/_kM6sQPK--uSEYoChMiWXHMkrx0=/0x0:2040x1360/720x0/filters:focal(0x0:2040x1360):no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/19434211/vpavic_191205_untitled_0014_Edit.jpg 720w, https://cdn.vox-cdn.com/thumbor/aSeRtauUbGlK-mN9vxCjjbwqw8s=/0x0:2040x1360/920x0/filters:focal(0x0:2040x1360):no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/19434211/vpavic_191205_untitled_0014_Edit.jpg 920w, https://cdn.vox-cdn.com/thumbor/DYncX7HrEvBGFnGZzAHle2v3e_I=/0x0:2040x1360/1120x0/filters:focal(0x0:2040x1360):no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/19434211/vpavic_191205_untitled_0014_Edit.jpg 1120w, https://cdn.vox-cdn.com/thumbor/jMAD6GGn8H5VqFnwezsSosk5BMU=/0x0:2040x1360/1320x0/filters:focal(0x0:2040x1360):no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/19434211/vpavic_191205_untitled_0014_Edit.jpg 1320w, https://cdn.vox-cdn.com/thumbor/LXcbWtLFJyopGTm0m_3B-JKwqzY=/0x0:2040x1360/1520x0/filters:focal(0x0:2040x1360):no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/19434211/vpavic_191205_untitled_0014_Edit.jpg 1520w, https://cdn.vox-cdn.com/thumbor/INemsQslSwaC_sIpnf3g5LrtorI=/0x0:2040x1360/1720x0/filters:focal(0x0:2040x1360):no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/19434211/vpavic_191205_untitled_0014_Edit.jpg 1720w, https://cdn.vox-cdn.com/thumbor/Z4UZOdwk1Q_8zhXHO7c6qYrSAJU=/0x0:2040x1360/1920x0/filters:focal(0x0:2040x1360):no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/19434211/vpavic_191205_untitled_0014_Edit.jpg 1920w&quot; sizes=&quot;(min-width: 1221px) 846px, (min-width: 880px) calc(100vw - 334px), 100vw&quot; alt=&quot;PS3&quot; data-upload-width=&quot;2040&quot; src=&quot;https://cdn.vox-cdn.com/thumbor/-l3lLBsV4H0WWEsZaXfR0f6vxWs=/0x0:2040x1360/1200x0/filters:focal(0x0:2040x1360):no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/19434211/vpavic_191205_untitled_0014_Edit.jpg&quot;/&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class=&quot;e-image__meta&quot;&gt;&lt;cite&gt;Photo by Vjeran Pavic / The Verge&lt;/cite&gt;&lt;/span&gt;
&lt;p id=&quot;x3e42t&quot;&gt;The one at UMass Dartmouth is still working, humming with life in that refrigerated shipping container on campus. The UMass Dartmouth machine is smaller than it used to be at its peak power of about 400 PlayStation 3s. Parts of it have been cut out and repurposed. Some are still working together in smaller supercomputers at other schools; others have broken down or been lost to time. Khanna has since moved on to trying to link smaller, more efficient devices together into his next-generation supercomputer. He says the &lt;a href=&quot;https://go.redirectingat.com?id=66960X1514734&amp;amp;xs=1&amp;amp;url=https%3A%2F%2Fwww.nvidia.com%2Fen-us%2Fshield%2F&amp;amp;referrer=theverge.com&amp;amp;sref=https%3A%2F%2Fwww.theverge.com%2F2019%2F12%2F3%2F20984028%2Fplaystation-supercomputer-ps3-umass-dartmouth-astrophysics-25th-anniversary&quot; rel=&quot;nofollow noopener&quot; target=&quot;_blank&quot;&gt;Nvidia Shield devices&lt;/a&gt; he’s working with now are about 50 times more efficient than the already-efficient PS3.&lt;/p&gt;
&lt;div class=&quot;c-float-right&quot;&gt;
&lt;aside id=&quot;4p7oMY&quot;&gt;&lt;q&gt;“It’s all Hollywood.”&lt;/q&gt;&lt;/aside&gt;&lt;/div&gt;
&lt;p id=&quot;XVHOXW&quot;&gt;It’s the Air Force’s supercluster of super consoles that had the most star-studded afterlife. When the program ended about four years ago, some consoles were donated to other programs, including Khanna’s. But many of the old consoles were sold off as old inventory, and a few hundred were snapped up by people working with the TV show &lt;em&gt;Person of Interest.&lt;/em&gt; In a ripped-from-the-headlines move, the consoles made their silver screen debut in the show’s &lt;a href=&quot;https://tay.kinja.com/thanks-for-making-me-miss-my-80gb-playstation-3-person-1774689896&quot;&gt;season 5 premiere&lt;/a&gt;, playing — wait for it — a supercomputer made of PlayStation 3s.&lt;/p&gt;
&lt;p id=&quot;TBcrIR&quot;&gt;“It’s all Hollywood,” Barnell said of the script, “but the hardware is actually our equipment.”&lt;/p&gt;
&lt;p id=&quot;CdsmG9&quot;&gt;&lt;em&gt;&lt;strong&gt;Correction, 7:05 PM ET:&lt;/strong&gt;&lt;/em&gt; &lt;em&gt;Supercomputer projects needed the original PS3, not the PS3 Slim, because Sony had removed Linux support from the console in response to hacks — which later led to&lt;/em&gt; &lt;a href=&quot;https://www.theverge.com/2016/6/22/12008286/sony-ps3-linux-otheros-agreement-settlement&quot;&gt;&lt;em&gt;a class-action settlement&lt;/em&gt;&lt;/a&gt;&lt;em&gt;. This article originally stated that it was because the PS3 Slim was less powerful. We regret the error.&lt;/em&gt;&lt;/p&gt;
</description>
<pubDate>Sat, 07 Dec 2019 17:27:17 +0000</pubDate>
<dc:creator>lelf</dc:creator>
<og:description>For one short moment, some of the most powerful computers in the world could be hacked together with code, wire, and PS3s.</og:description>
<og:image>https://cdn.vox-cdn.com/thumbor/2iZmALZ17HJA84iYlMxqTvChb7E=/0x97:2040x1165/fit-in/1200x630/cdn.vox-cdn.com/uploads/chorus_asset/file/19434204/vpavic_191205_untitled_0018_Edit.jpg</og:image>
<og:title>The rise and fall of the PlayStation supercomputers</og:title>
<og:type>article</og:type>
<og:url>https://www.theverge.com/2019/12/3/20984028/playstation-supercomputer-ps3-umass-dartmouth-astrophysics-25th-anniversary</og:url>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.theverge.com/2019/12/3/20984028/playstation-supercomputer-ps3-umass-dartmouth-astrophysics-25th-anniversary</dc:identifier>
</item>
<item>
<title>Indexing Billions of Text Vectors</title>
<link>https://0x65.dev/blog/2019-12-07/indexing-billions-of-text-vectors.html</link>
<guid isPermaLink="true" >https://0x65.dev/blog/2019-12-07/indexing-billions-of-text-vectors.html</guid>
<description>&lt;p&gt;A frequently occurring problem within information retrieval is the one of finding &lt;em&gt;similar&lt;/em&gt; pieces of text. As described in our previous posts (&lt;a href=&quot;https://0x65.dev/blog/2019-12-05/a-new-search-engine.html&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;A New Search Engine&lt;/a&gt; and &lt;a href=&quot;https://0x65.dev/blog/2019-12-06/building-a-search-engine-from-scratch.html&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;Building a Search Engine from Scratch&lt;/a&gt;), queries are an important building block at Cliqz. A query in this context can either be a user-generated one, (i.e. the piece of text that a user enters into a &lt;a href=&quot;https://beta.cliqz.com/#channel=blog&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;search engine&lt;/a&gt;), or a synthetic one generated by us. A common use case is that we want to match an input query with other queries already in our index. In this post we will see how we are able to build a system that solves this task at scale using billions of queries without spending a fortune (which we do not have) on server infrastructure.&lt;/p&gt;
&lt;p&gt;Let us first formally define the problem:&lt;/p&gt;
&lt;blockquote readability=&quot;20&quot;&gt;
&lt;p&gt;Given a fixed set of queries &lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;QQ&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;Q&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;, an input query &lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;qq&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;q&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; and an integer &lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;kk&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;k&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;, find a subset of queries &lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;R={q0,q1,...,qk}⊂QR = \{q_0, q_1, ..., q_k\} \subset Q&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;R&lt;/span&gt;&lt;span class=&quot;mrel&quot;&gt;=&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;mopen&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;q&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot;&gt;&lt;span&gt;&lt;span class=&quot;mtight sizing reset-size6 size3&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;0&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mpunct&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;q&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot;&gt;&lt;span&gt;&lt;span class=&quot;mtight sizing reset-size6 size3&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mpunct&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mpunct&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;q&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot;&gt;&lt;span&gt;&lt;span class=&quot;mtight sizing reset-size6 size3&quot;&gt;&lt;span class=&quot;mord mtight mathdefault&quot;&gt;k&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mclose&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;mrel&quot;&gt;⊂&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;Q&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;, such that each query &lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;qi∈Rq_i \in R&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;q&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot;&gt;&lt;span&gt;&lt;span class=&quot;mtight sizing reset-size6 size3&quot;&gt;&lt;span class=&quot;mord mtight mathdefault&quot;&gt;i&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mrel&quot;&gt;∈&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;R&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; is more &lt;strong&gt;similar&lt;/strong&gt; to &lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;qq&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;q&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; than every other query in &lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;Q∖RQ \setminus R&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;Q&lt;/span&gt;&lt;span class=&quot;mbin&quot;&gt;∖&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;R&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;For example, with the following set of queries &lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;QQ&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;Q&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;:&lt;/p&gt;
&lt;table class=&quot;table&quot;&gt;&lt;thead&gt;&lt;tr&gt;&lt;th/&gt;
&lt;/tr&gt;&lt;/thead&gt;&lt;tbody readability=&quot;5.5&quot;&gt;&lt;tr readability=&quot;11&quot;&gt;&lt;td&gt;&lt;span class=&quot;katex-error&quot; title=&quot;ParseError: KaTeX parse error: Expected '}', got 'EOF' at end of input: {&quot;&gt;{&lt;/span&gt;&lt;code&gt;tesla cybertruck&lt;/code&gt;, &lt;code&gt;beginner bicycle gear&lt;/code&gt;, &lt;code&gt;eggplant dishes&lt;/code&gt;, &lt;code&gt;tesla new car&lt;/code&gt;, &lt;code&gt;how expensive is cybertruck&lt;/code&gt;, &lt;code&gt;vegetarian food&lt;/code&gt;, &lt;code&gt;shimano 105 vs ultegra&lt;/code&gt;, &lt;code&gt;building a carbon bike&lt;/code&gt;, &lt;code&gt;zucchini recipes&lt;/code&gt;&lt;span class=&quot;katex-error&quot; title=&quot;ParseError: KaTeX parse error: Expected 'EOF', got '}' at position 1: }̲&quot;&gt;}&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;and &lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;k=3k = 3&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;mrel&quot;&gt;=&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;mord&quot;&gt;3&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;, we might expect the following results:&lt;/p&gt;
&lt;table class=&quot;table&quot;&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;Input query &lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;qq&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;q&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/th&gt;
&lt;th&gt;Similar queries &lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;RR&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;R&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/th&gt;
&lt;/tr&gt;&lt;/thead&gt;&lt;tbody readability=&quot;6&quot;&gt;&lt;tr readability=&quot;4&quot;&gt;&lt;td&gt;&lt;code&gt;tesla pickup&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;span class=&quot;katex-error&quot; title=&quot;ParseError: KaTeX parse error: Expected '}', got 'EOF' at end of input: {&quot;&gt;{&lt;/span&gt;&lt;code&gt;tesla cybertruck&lt;/code&gt;, &lt;code&gt;tesla new car&lt;/code&gt;, &lt;code&gt;how expensive is cybertruck&lt;/code&gt;&lt;span class=&quot;katex-error&quot; title=&quot;ParseError: KaTeX parse error: Expected 'EOF', got '}' at position 1: }̲&quot;&gt;}&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;4&quot;&gt;&lt;td&gt;&lt;code&gt;best bike 2019&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;span class=&quot;katex-error&quot; title=&quot;ParseError: KaTeX parse error: Expected '}', got 'EOF' at end of input: {&quot;&gt;{&lt;/span&gt;&lt;code&gt;shimano 105 vs ultegra&lt;/code&gt;, &lt;code&gt;are carbon bikes better&lt;/code&gt;, &lt;code&gt;bicycle gearing&lt;/code&gt;&lt;span class=&quot;katex-error&quot; title=&quot;ParseError: KaTeX parse error: Expected 'EOF', got '}' at position 1: }̲&quot;&gt;}&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;4&quot;&gt;&lt;td&gt;&lt;code&gt;cooking with vegetables&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;span class=&quot;katex-error&quot; title=&quot;ParseError: KaTeX parse error: Expected '}', got 'EOF' at end of input: {&quot;&gt;{&lt;/span&gt;&lt;code&gt;eggplant dishes&lt;/code&gt;, &lt;code&gt;zucchini recipes&lt;/code&gt;, &lt;code&gt;vegetarian food&lt;/code&gt;&lt;span class=&quot;katex-error&quot; title=&quot;ParseError: KaTeX parse error: Expected 'EOF', got '}' at position 1: }̲&quot;&gt;}&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;Note that we have not yet defined &lt;em&gt;similar&lt;/em&gt;. In this context, it can mean almost anything, but it usually boils down to some form of keyword or vector based similarity. With keyword based similarity we can consider two queries similar if they have enough words in common. For example, the queries &lt;code&gt;opening a restaurant in munich&lt;/code&gt; and &lt;code&gt;best restaurant of munich&lt;/code&gt; are similar because they share the words &lt;code&gt;restaurant&lt;/code&gt; and &lt;code&gt;munich&lt;/code&gt;, whereas &lt;code&gt;best restaurant of munich&lt;/code&gt; and &lt;code&gt;where to eat in munich&lt;/code&gt; are less similar because they only share a single word. Someone looking for a restaurant in Munich will however likely be better served by considering the second pair of queries to be similar. This is where vector based matching comes into play.&lt;/p&gt;

&lt;p&gt;Word embedding is a machine-learning technique in Natural Language Processing for mapping text or words to vectors. By moving the problem into a vector space we can use mathematical operations, such as summing or computing distances, on the vectors. We can even use conventional vector clustering techniques to link together similar words. It is not necessarily obvious what these operations &lt;em&gt;mean&lt;/em&gt; in the original space of words but the benefit is that we now have a rich set of mathematical tools available to us. The interested reader may want to have a look at e.g. &lt;em&gt;word2vec&lt;/em&gt;&lt;sup class=&quot;footnote-ref&quot;&gt;&lt;a href=&quot;https://0x65.dev/blog/2019-12-07/indexing-billions-of-text-vectors.html#fn1&quot; id=&quot;fnref1&quot;&gt;[1]&lt;/a&gt;&lt;/sup&gt; or &lt;em&gt;GloVe&lt;/em&gt;&lt;sup class=&quot;footnote-ref&quot;&gt;&lt;a href=&quot;https://0x65.dev/blog/2019-12-07/indexing-billions-of-text-vectors.html#fn2&quot; id=&quot;fnref2&quot;&gt;[2]&lt;/a&gt;&lt;/sup&gt; for more information about word vectors and their applications.&lt;/p&gt;
&lt;p&gt;Once we have a way of generating vectors from words, the next step is to combine them into text vectors (also known as document or sentence vectors). A simple and common way of doing this is to sum (or average) the vectors for all the words in the text together.&lt;/p&gt;
&lt;a href=&quot;https://0x65.dev/static/img/posts/granne/vectors.png&quot;&gt;&lt;img alt=&quot;Figure 1: Query vectors&quot; loading=&quot;lazy&quot; src=&quot;https://0x65.dev/static/img/posts/granne/vectors.png&quot;/&gt;&lt;/a&gt;Figure 1: Query vectors
&lt;p&gt;We can decide how similar two snippets of text (or queries) are by mapping them both into a vector space and computing a distance between the vectors. A common choice is to use the angular distance.&lt;/p&gt;
&lt;p&gt;All in all, word embedding allows us to do a different kind of text matching that complements the keyword-based matching mentioned above. We are able to explore the semantic similarity between queries (e.g. &lt;code&gt;best restaurant of munich&lt;/code&gt; and &lt;code&gt;where to eat in munich&lt;/code&gt;) in a way that was not possible before.&lt;/p&gt;

&lt;p&gt;We are now ready to reduce our initial query matching problem into the following:&lt;/p&gt;
&lt;blockquote readability=&quot;20&quot;&gt;
&lt;p&gt;Given a fixed set of query &lt;strong&gt;vectors&lt;/strong&gt; &lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;QQ&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;Q&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;, an input &lt;strong&gt;vector&lt;/strong&gt; &lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;qq&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;q&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; and an integer &lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;kk&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;k&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;, find a subset of &lt;strong&gt;vectors&lt;/strong&gt; &lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;R={q0,q1,...,qk}⊂QR = \{q_0, q_1, ..., q_k\} \subset Q&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;R&lt;/span&gt;&lt;span class=&quot;mrel&quot;&gt;=&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;mopen&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;q&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot;&gt;&lt;span&gt;&lt;span class=&quot;mtight sizing reset-size6 size3&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;0&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mpunct&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;q&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot;&gt;&lt;span&gt;&lt;span class=&quot;mtight sizing reset-size6 size3&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mpunct&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mpunct&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;q&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot;&gt;&lt;span&gt;&lt;span class=&quot;mtight sizing reset-size6 size3&quot;&gt;&lt;span class=&quot;mord mtight mathdefault&quot;&gt;k&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mclose&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;mrel&quot;&gt;⊂&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;Q&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;, such that the &lt;strong&gt;angular distance&lt;/strong&gt; from &lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;qq&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;q&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; to each vector &lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;qi∈Rq_i \in R&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;q&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot;&gt;&lt;span&gt;&lt;span class=&quot;mtight sizing reset-size6 size3&quot;&gt;&lt;span class=&quot;mord mtight mathdefault&quot;&gt;i&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mrel&quot;&gt;∈&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;R&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; is smaller than to every other &lt;strong&gt;vector&lt;/strong&gt; in &lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;Q∖RQ \setminus R&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;Q&lt;/span&gt;&lt;span class=&quot;mbin&quot;&gt;∖&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;R&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This is called the nearest neighbor problem and plenty of algorithms&lt;sup class=&quot;footnote-ref&quot;&gt;&lt;a href=&quot;https://0x65.dev/blog/2019-12-07/indexing-billions-of-text-vectors.html#fn3&quot; id=&quot;fnref3&quot;&gt;[3]&lt;/a&gt;&lt;/sup&gt; exist that can solve it quickly for low dimensional spaces. With word embeddings on the other hand, we are normally working with high-dimensional vectors (100-1000 dimensions). In this case, exact methods break down.&lt;/p&gt;
&lt;p&gt;There is no feasible way of quickly obtaining the nearest neighbors in high-dimensionsional spaces. In order to overcome this, we will make the problem simpler by allowing for approximate results, i.e. instead of requiring the algorithm to always return &lt;em&gt;exactly&lt;/em&gt; the closest vectors, we accept getting only some of the closest neighbors or &lt;em&gt;somewhat&lt;/em&gt; close neighbors. We call this the approximate nearest neighbor (ANN) problem and it is an active area of research.&lt;/p&gt;
&lt;h3&gt;Hierarchical Navigable Small-World Graph&lt;/h3&gt;
&lt;p&gt;Hierarchical Navigable Small-World graph&lt;sup class=&quot;footnote-ref&quot;&gt;&lt;a href=&quot;https://0x65.dev/blog/2019-12-07/indexing-billions-of-text-vectors.html#fn4&quot; id=&quot;fnref4&quot;&gt;[4]&lt;/a&gt;&lt;/sup&gt;, or HNSW for short, is one of the faster approximate nearest neighbor search algorithms. The search index in HNSW is a multi-layered structure where each layer is a proximity graph. Each node in the graph corresponds to one of our query vectors.&lt;/p&gt;
&lt;a href=&quot;https://0x65.dev/static/img/posts/granne/hnsw.png&quot;&gt;&lt;img alt=&quot;Figure 2: Multi-layered proximity graph&quot; loading=&quot;lazy&quot; src=&quot;https://0x65.dev/static/img/posts/granne/hnsw.png&quot;/&gt;&lt;/a&gt;Figure 2: Multi-layered proximity graph
&lt;p&gt;A nearest neighbor search in HNSW uses a zooming-in approach. It starts at an entrypoint node in the uppermost layer and recursively performs a greedy graph traversal in each layer until it reaches a local minimum in the bottommost one.&lt;/p&gt;
&lt;p&gt;Details about the inner-workings of the algorithm and how the search index is constructed is well described in the paper&lt;sup class=&quot;footnote-ref&quot;&gt;&lt;a href=&quot;https://0x65.dev/blog/2019-12-07/indexing-billions-of-text-vectors.html#fn4&quot; id=&quot;fnref4:1&quot;&gt;[4:1]&lt;/a&gt;&lt;/sup&gt; itself. The important take-away is that each nearest neighbor search consists in performing a graph traversal, where nodes in the graph are visited and distances are computed between vectors. The following sections will outline the steps taken in order to be able to use this method for building a large scale index at Cliqz.&lt;/p&gt;

&lt;p&gt;Let us assume that the goal is to index 4 billion 200-dimensional query vectors where each dimension is represented by a 4 byte floating-point number&lt;sup class=&quot;footnote-ref&quot;&gt;&lt;a href=&quot;https://0x65.dev/blog/2019-12-07/indexing-billions-of-text-vectors.html#fn5&quot; id=&quot;fnref5&quot;&gt;[5]&lt;/a&gt;&lt;/sup&gt;. A back-of-the-envelope calculation tells us that the size of the vectors alone is around 3 TB. Since many of the existing ANN libraries are memory-based, this means that we would need a very large server in order to fit just the vectors into RAM. Note that this is the size excluding the additional search index required in most of the methods.&lt;/p&gt;
&lt;p&gt;Throughout the history of our search engine, we have had a few different approaches addressing this size problem. Let us revisit a couple of them.&lt;/p&gt;
&lt;h3&gt;A Subset of the Data&lt;/h3&gt;
&lt;p&gt;The first and simplest approach, which did not really solve the problem, was to limit the number of vectors in the index. By using only one tenth of all the available data, we could, unsurprisingly, build an index requiring only 10% of the memory as compared to one containing all of data. The drawback of this approach is that search quality suffers, since we have fewer queries to match against.&lt;/p&gt;
&lt;h3&gt;Quantization&lt;/h3&gt;
&lt;p&gt;The second approach was to include all data, but to make it smaller through quantization&lt;sup class=&quot;footnote-ref&quot;&gt;&lt;a href=&quot;https://0x65.dev/blog/2019-12-07/indexing-billions-of-text-vectors.html#fn6&quot; id=&quot;fnref6&quot;&gt;[6]&lt;/a&gt;&lt;/sup&gt;&lt;sup class=&quot;footnote-ref&quot;&gt;&lt;a href=&quot;https://0x65.dev/blog/2019-12-07/indexing-billions-of-text-vectors.html#fn7&quot; id=&quot;fnref7&quot;&gt;[7]&lt;/a&gt;&lt;/sup&gt;. By allowing some rounding errors we can replace each 4 byte float in the original vector with a quantized 1 byte version. This reduces the amount of RAM required for the vectors by 75%. Despite this significant size reduction we need to fit almost 750 GB in RAM (still ignoring the size of the index structure itself), which still requires us to use a very large server.&lt;/p&gt;

&lt;p&gt;The approaches above did have merit, but they were lacking in cost efficiency and quality. Even though there are ANN libraries producing reasonable recall in less than 1 ms&lt;sup class=&quot;footnote-ref&quot;&gt;&lt;a href=&quot;https://0x65.dev/blog/2019-12-07/indexing-billions-of-text-vectors.html#fn8&quot; id=&quot;fnref8&quot;&gt;[8]&lt;/a&gt;&lt;/sup&gt;, for our use case we can accept sacrificing some of that speed for reduced server costs.&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/granne/granne&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;Granne&lt;/a&gt; (&lt;strong&gt;gr&lt;/strong&gt;aph-based &lt;strong&gt;a&lt;/strong&gt;pproximate &lt;strong&gt;n&lt;/strong&gt;earest &lt;strong&gt;ne&lt;/strong&gt;ighbors) is a HNSW-based library developed and used at Cliqz to find similar queries. &lt;em&gt;It is open-source, but still under active development. An improved version is on the way and will be published on &lt;a href=&quot;https://crates.io&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;crates.io&lt;/a&gt; in 2020&lt;/em&gt;. It is written in Rust with language bindings for Python and is designed for billions of vectors and with concurrency in mind. More interesting in the context of query vectors, is that Granne has a special mode that uses drastically less memory than previously available libraries.&lt;/p&gt;
&lt;h3&gt;Compact Representation of Query Vectors&lt;/h3&gt;
&lt;p&gt;Reducing the size of the query vectors themselves will give the most benefit. In order to do so, we will have to take a step back and consider how the query vectors are created in the first place. Since our queries consist of words and our query vectors are sums of word vectors, we can avoid storing the query vectors explicitly and compute them whenever they are needed.&lt;/p&gt;
&lt;p&gt;We could store the queries as a set of words and use a look-up table to find the corresponding word vector. However, we avoid the indirection by storing each query as a list of integer ids corresponding to the vectors of the words in the query. For example, we store the query &lt;code&gt;best restaurant of munich&lt;/code&gt; as&lt;/p&gt;
&lt;p class=&quot;katex-block&quot;&gt;&lt;span class=&quot;katex-display&quot;&gt;&lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;[ibest,irestaurant,iof,imunich][i_{\mathrm{best}}, i_{\mathrm{restaurant}}, i_{\mathrm{of}}, i_{\mathrm{munich}}]&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;mopen&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot;&gt;&lt;span&gt;&lt;span class=&quot;mtight sizing reset-size6 size3&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;&lt;span class=&quot;mord mtight mathrm&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;mord mtight mathrm&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;mord mtight mathrm&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;mord mtight mathrm&quot;&gt;t&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mpunct&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot;&gt;&lt;span&gt;&lt;span class=&quot;mtight sizing reset-size6 size3&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;&lt;span class=&quot;mord mtight mathrm&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;mord mtight mathrm&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;mord mtight mathrm&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;mord mtight mathrm&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;mord mtight mathrm&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;mord mtight mathrm&quot;&gt;u&lt;/span&gt;&lt;span class=&quot;mord mtight mathrm&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;mord mtight mathrm&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;mord mtight mathrm&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;mord mtight mathrm&quot;&gt;t&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mpunct&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot;&gt;&lt;span&gt;&lt;span class=&quot;mtight sizing reset-size6 size3&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;&lt;span class=&quot;mord mtight mathrm&quot;&gt;o&lt;/span&gt;&lt;span class=&quot;mord mtight mathrm&quot;&gt;f&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mpunct&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot;&gt;&lt;span&gt;&lt;span class=&quot;mtight sizing reset-size6 size3&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;&lt;span class=&quot;mord mtight mathrm&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;mord mtight mathrm&quot;&gt;u&lt;/span&gt;&lt;span class=&quot;mord mtight mathrm&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;mord mtight mathrm&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;mord mtight mathrm&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;mord mtight mathrm&quot;&gt;h&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mclose&quot;&gt;]&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;ibesti_{\mathrm{best}}&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot;&gt;&lt;span&gt;&lt;span class=&quot;mtight sizing reset-size6 size3&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;&lt;span class=&quot;mord mtight mathrm&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;mord mtight mathrm&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;mord mtight mathrm&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;mord mtight mathrm&quot;&gt;t&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; is the id of the word vector for &lt;code&gt;best&lt;/code&gt;, and so on. Assuming we have less than 16 million word vectors (more than that comes at a price of 1 byte per word), we can use a 3 byte representation for each word id. Thus, instead of storing 800 bytes (or 200 bytes in the case of the quantized vector) we only need to store 12 bytes&lt;sup class=&quot;footnote-ref&quot;&gt;&lt;a href=&quot;https://0x65.dev/blog/2019-12-07/indexing-billions-of-text-vectors.html#fn9&quot; id=&quot;fnref9&quot;&gt;[9]&lt;/a&gt;&lt;/sup&gt; for this query.&lt;/p&gt;
&lt;p&gt;Regarding the word vectors: we still need them. However, there are a lot fewer words than queries one can create by combining those words. Since they are so few in comparison to the queries, their size does not matter as much. By storing the 4 byte floating-point version of the word vectors in a simple array &lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;vv&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;v&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;, we need less than 1 GB per million of them, which can easily be stored in RAM. The query vector from the example above is then obtained as:&lt;/p&gt;
&lt;p class=&quot;katex-block&quot;&gt;&lt;span class=&quot;katex-display&quot;&gt;&lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;vibest+virestaurant+viof+vimunichv_{i_{\mathrm{best}}} + v_{i_{\mathrm{restaurant}}} + v_{i_{\mathrm{of}}} + v_{i_{\mathrm{munich}}}&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot;&gt;&lt;span&gt;&lt;span class=&quot;mtight sizing reset-size6 size3&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;&lt;span class=&quot;mord mtight mathdefault&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot;&gt;&lt;span&gt;&lt;span class=&quot;mtight sizing reset-size3 size1&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;&lt;span class=&quot;mord mtight mathrm&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;mord mtight mathrm&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;mord mtight mathrm&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;mord mtight mathrm&quot;&gt;t&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mbin&quot;&gt;+&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot;&gt;&lt;span&gt;&lt;span class=&quot;mtight sizing reset-size6 size3&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;&lt;span class=&quot;mord mtight mathdefault&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot;&gt;&lt;span&gt;&lt;span class=&quot;mtight sizing reset-size3 size1&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;&lt;span class=&quot;mord mtight mathrm&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;mord mtight mathrm&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;mord mtight mathrm&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;mord mtight mathrm&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;mord mtight mathrm&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;mord mtight mathrm&quot;&gt;u&lt;/span&gt;&lt;span class=&quot;mord mtight mathrm&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;mord mtight mathrm&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;mord mtight mathrm&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;mord mtight mathrm&quot;&gt;t&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mbin&quot;&gt;+&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot;&gt;&lt;span&gt;&lt;span class=&quot;mtight sizing reset-size6 size3&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;&lt;span class=&quot;mord mtight mathdefault&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot;&gt;&lt;span&gt;&lt;span class=&quot;mtight sizing reset-size3 size1&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;&lt;span class=&quot;mord mtight mathrm&quot;&gt;o&lt;/span&gt;&lt;span class=&quot;mord mtight mathrm&quot;&gt;f&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mbin&quot;&gt;+&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot;&gt;&lt;span&gt;&lt;span class=&quot;mtight sizing reset-size6 size3&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;&lt;span class=&quot;mord mtight mathdefault&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t vlist-t2&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot;&gt;&lt;span&gt;&lt;span class=&quot;mtight sizing reset-size3 size1&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;&lt;span class=&quot;mord mtight&quot;&gt;&lt;span class=&quot;mord mtight mathrm&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;mord mtight mathrm&quot;&gt;u&lt;/span&gt;&lt;span class=&quot;mord mtight mathrm&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;mord mtight mathrm&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;mord mtight mathrm&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;mord mtight mathrm&quot;&gt;h&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;vlist-s&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The final size of the query representation naturally depends on the combined number of words in all queries, but for 4 billion of our queries the total size ends up being around 80 GB (including the word vectors). In other words, we see a reduction in size by more than 97% compared to the original query vectors or around 90% compared to the quantized vectors.&lt;/p&gt;
&lt;p&gt;There is one concern that still needs to be addressed. For a single search, we need to visit around 200-300 nodes in the graph. Each node has 20-30 neighbors. Consequently, we need to compute the distance from the input query vector to 4000-9000 of the vectors in the index and before that, we need to generate the vectors. Is the time penalty for creating the query vectors on the fly too high?&lt;/p&gt;
&lt;p&gt;It turns out that, with a reasonably new CPU, it can be done in a few milliseconds. For a query that earlier took a millisecond, we will now need around 5 ms. But at the same time, we are reducing the RAM usage for the vectors by 90%—a trade-off we gladly accept.&lt;/p&gt;
&lt;h3&gt;Memory Mapping Vectors and Index&lt;/h3&gt;
&lt;p&gt;So far, we have focused solely on the memory footprint of the vectors. However, after the significant size reduction above, the limiting factor becomes the index structure itself, and we thus need to consider its memory requirements as well.&lt;/p&gt;
&lt;p&gt;The graph structure in Granne is compactly stored as adjacency lists with a variable number of neighbors per node. Thus, almost no space is wasted on metadata. The size of the index structure depends a lot on the construction parameters and the properties of the graph. Nevertheless, in order to get some idea about the index size, it suffices to say that we can build a useable index for the 4 billion vectors with a total size of around 240 GB. This might be acceptable to use in-memory on a large server, but we can actually do even better.&lt;/p&gt;
&lt;a href=&quot;https://0x65.dev/static/img/posts/granne/ram_ssd.svg&quot;&gt;&lt;img alt=&quot;Figure 3: Two different configurations of RAM/SSD placement&quot; loading=&quot;lazy&quot; src=&quot;https://0x65.dev/static/img/posts/granne/ram_ssd.svg&quot;/&gt;&lt;/a&gt;Figure 3: Two different configurations of RAM/SSD placement
&lt;p&gt;An important feature of Granne is its ability to memory map&lt;sup class=&quot;footnote-ref&quot;&gt;&lt;a href=&quot;https://0x65.dev/blog/2019-12-07/indexing-billions-of-text-vectors.html#fn10&quot; id=&quot;fnref10&quot;&gt;[10]&lt;/a&gt;&lt;/sup&gt; the index and the query vectors. This enables us to lazily load the index and share the memory between processes. The index and query files are actually split into separate memory mapped files and can be used with different configurations of SSD/RAM placement. If latency requirements are a bit less strict, by placing the index file on a SSD and the query file in RAM, we still obtain a reasonable query speed without paying for an excessive amount of RAM. At the end of this post, we will see what this trade-off looks like.&lt;/p&gt;
&lt;h3&gt;Improving Data Locality&lt;/h3&gt;
&lt;p&gt;In our current configuration, where the index is placed on a SSD, each search requires up to 200-300 read operations from the SSD. We can try to increase the data locality by ordering elements whose vectors are close so that their HNSW nodes are also closely located in the index. Data locality improves performance because a single read operation (usually fetching 4 kB or more) becomes more likely to contain other nodes needed for the graph traversal. This, in turn, reduces the number of times we need to fetch data during a single search.&lt;/p&gt;
&lt;a href=&quot;https://0x65.dev/static/img/posts/granne/data_locality.svg&quot;&gt;&lt;img alt=&quot;Figure 4: Data locality reduces the number of fetches&quot; loading=&quot;lazy&quot; src=&quot;https://0x65.dev/static/img/posts/granne/data_locality.svg&quot;/&gt;&lt;/a&gt;Figure 4: Data locality reduces the number of fetches
&lt;p&gt;It should be noted that reordering the elements does not change the results, but is merely a way of speeding up the search. This means that any ordering is fine, but not all of them will give a speed up. It is likely very difficult to find the optimal ordering. However, a heuristic that we have used sucessfully consists in sorting the queries based on the most &lt;em&gt;important&lt;/em&gt; word in each query.&lt;/p&gt;

&lt;p&gt;At Cliqz, we are using Granne to build and maintain a multi-billion query vector index for similar query search with relatively low memory requirements. Table 1. summarizes the requirements for the different methods. The absolute numbers for the search latencies should be taken with a grain of salt, since they are highly dependent on what is considered an acceptable recall, but they should at least give a hint about the relative performance between the methods.&lt;/p&gt;
&lt;table class=&quot;table&quot;&gt;&lt;thead&gt;&lt;tr&gt;&lt;th/&gt;
&lt;th&gt;Baseline&lt;/th&gt;
&lt;th&gt;Quantization&lt;/th&gt;
&lt;th&gt;Granne (RAM only)&lt;/th&gt;
&lt;th&gt;Granne (RAM+SSD)&lt;/th&gt;
&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;Memory&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;3000 + 240 GB&lt;/td&gt;
&lt;td&gt;750 + 240 GB&lt;/td&gt;
&lt;td&gt;80 + 240 GB&lt;/td&gt;
&lt;td&gt;80-150 GB&lt;sup class=&quot;footnote-ref&quot;&gt;&lt;a href=&quot;https://0x65.dev/blog/2019-12-07/indexing-billions-of-text-vectors.html#fn11&quot; id=&quot;fnref11&quot;&gt;[11]&lt;/a&gt;&lt;/sup&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;SSD&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;240 GB&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;Latency&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;1 ms&lt;/td&gt;
&lt;td&gt;1 ms&lt;/td&gt;
&lt;td&gt;5 ms&lt;/td&gt;
&lt;td&gt;10-50 ms&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;Table 1: A comparison of latency requirements for different setups&lt;br/&gt;&lt;/p&gt;&lt;p&gt;We would like to point out that some of the optimizations mentioned in this post are, of course, not applicable to the generic nearest neighbor problem with non-decomposable vectors. However, any situation where the elements can be generated from a smaller number of pieces (as is the case with queries and words), can be accommodated. If this is not the case, then it is still possible to use Granne with the original vectors; it will just require more memory, like with other libraries.&lt;/p&gt;
&lt;h2&gt;Footnotes&lt;/h2&gt;
&lt;hr class=&quot;footnotes-sep&quot;/&gt;&lt;section class=&quot;footnotes&quot;&gt;&lt;ol class=&quot;footnotes-list&quot; readability=&quot;-11.421691792295&quot;&gt;&lt;li class=&quot;footnote-item&quot; id=&quot;fn1&quot; readability=&quot;-22.082191780822&quot;&gt;
&lt;p&gt;Efficient Estimation of Word Representations in Vector Space &lt;a href=&quot;https://arxiv.org/pdf/1301.3781.pdf&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;paper&lt;/a&gt; &lt;a href=&quot;https://0x65.dev/blog/2019-12-07/indexing-billions-of-text-vectors.html#fnref1&quot; class=&quot;footnote-backref&quot;&gt;↩︎&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li class=&quot;footnote-item&quot; id=&quot;fn2&quot; readability=&quot;-21.068965517241&quot;&gt;
&lt;p&gt;GloVe: Global Vectors for Word Representation &lt;a href=&quot;https://nlp.stanford.edu/pubs/glove.pdf&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;paper&lt;/a&gt; &lt;a href=&quot;https://0x65.dev/blog/2019-12-07/indexing-billions-of-text-vectors.html#fnref2&quot; class=&quot;footnote-backref&quot;&gt;↩︎&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li class=&quot;footnote-item&quot; id=&quot;fn3&quot; readability=&quot;-21&quot;&gt;
&lt;p&gt;Nearest Neighbor Search: Exact methods - &lt;a href=&quot;https://en.wikipedia.org/wiki/Nearest_neighbor_search#Exact_methods&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;wiki&lt;/a&gt; &lt;a href=&quot;https://0x65.dev/blog/2019-12-07/indexing-billions-of-text-vectors.html#fnref3&quot; class=&quot;footnote-backref&quot;&gt;↩︎&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li class=&quot;footnote-item&quot; id=&quot;fn4&quot; readability=&quot;-21.626984126984&quot;&gt;
&lt;p&gt;Efficient and robust approximate nearest neighbor search using Hierarchical Navigable Small World graphs - &lt;a href=&quot;https://arxiv.org/abs/1603.09320&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;paper&lt;/a&gt; &lt;a href=&quot;https://0x65.dev/blog/2019-12-07/indexing-billions-of-text-vectors.html#fnref4&quot; class=&quot;footnote-backref&quot;&gt;↩︎&lt;/a&gt; &lt;a href=&quot;https://0x65.dev/blog/2019-12-07/indexing-billions-of-text-vectors.html#fnref4:1&quot; class=&quot;footnote-backref&quot;&gt;↩︎&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li class=&quot;footnote-item&quot; id=&quot;fn5&quot; readability=&quot;-22.985915492958&quot;&gt;
&lt;p&gt;4 billion is large enough to make the problem interesting, while still making it possible to store node ids in regular 4 byte integers. &lt;a href=&quot;https://0x65.dev/blog/2019-12-07/indexing-billions-of-text-vectors.html#fnref5&quot; class=&quot;footnote-backref&quot;&gt;↩︎&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li class=&quot;footnote-item&quot; id=&quot;fn6&quot;&gt;
&lt;p&gt;Quantization &lt;a href=&quot;https://en.wikipedia.org/wiki/Quantization&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;wiki&lt;/a&gt; &lt;a href=&quot;https://0x65.dev/blog/2019-12-07/indexing-billions-of-text-vectors.html#fnref6&quot; class=&quot;footnote-backref&quot;&gt;↩︎&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li class=&quot;footnote-item&quot; id=&quot;fn7&quot; readability=&quot;-23.1&quot;&gt;
&lt;p&gt;We tried a few other quantization techniques based on e.g. product-quantization, but did not manage to get them to work with sufficient quality at scale. &lt;a href=&quot;https://0x65.dev/blog/2019-12-07/indexing-billions-of-text-vectors.html#fnref7&quot; class=&quot;footnote-backref&quot;&gt;↩︎&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li class=&quot;footnote-item&quot; id=&quot;fn8&quot; readability=&quot;-16&quot;&gt;
&lt;p&gt;ANN Benchmarks &lt;a href=&quot;http://ann-benchmarks.com&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;link&lt;/a&gt; &lt;a href=&quot;https://0x65.dev/blog/2019-12-07/indexing-billions-of-text-vectors.html#fnref8&quot; class=&quot;footnote-backref&quot;&gt;↩︎&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li class=&quot;footnote-item&quot; id=&quot;fn9&quot; readability=&quot;-22.345971563981&quot;&gt;
&lt;p&gt;This is not completely true. Since queries consist of a varying number of words, the offset of the word index list for a certain query needs to be stored as well. This can be done using 5 bytes per query. &lt;a href=&quot;https://0x65.dev/blog/2019-12-07/indexing-billions-of-text-vectors.html#fnref9&quot; class=&quot;footnote-backref&quot;&gt;↩︎&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li class=&quot;footnote-item&quot; id=&quot;fn10&quot;&gt;
&lt;p&gt;mmap &lt;a href=&quot;https://en.wikipedia.org/wiki/Mmap&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;wiki&lt;/a&gt; &lt;a href=&quot;https://0x65.dev/blog/2019-12-07/indexing-billions-of-text-vectors.html#fnref10&quot; class=&quot;footnote-backref&quot;&gt;↩︎&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li class=&quot;footnote-item&quot; id=&quot;fn11&quot; readability=&quot;-20.574324324324&quot;&gt;
&lt;p&gt;By providing more memory than strictly required for the index, some nodes (often visited nodes in particular) will get cached, which in turn reduces the search latency. Note that this is without using any internal cache, but just relying on the operating system (Linux kernel) for caching. &lt;a href=&quot;https://0x65.dev/blog/2019-12-07/indexing-billions-of-text-vectors.html#fnref11&quot; class=&quot;footnote-backref&quot;&gt;↩︎&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;&lt;/section&gt;&lt;p class=&quot;share-text&quot;&gt;Share this article&lt;/p&gt;
&lt;hr class=&quot;share-hr&quot;/&gt;
</description>
<pubDate>Sat, 07 Dec 2019 16:34:10 +0000</pubDate>
<dc:creator>martinlaz</dc:creator>
<og:type>website</og:type>
<og:url>https://0x65.dev/blog/2019-12-07/indexing-billions-of-text-vectors.html</og:url>
<og:title>Indexing Billions of Text Vectors</og:title>
<og:image>https://0x65.dev/static/img/posts/granne/vectors.png</og:image>
<og:description>Optimizing memory-usage for approximate nearest neighbor search</og:description>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://0x65.dev/blog/2019-12-07/indexing-billions-of-text-vectors.html</dc:identifier>
</item>
</channel>
</rss>