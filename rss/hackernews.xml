<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="css/feed.xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/" xmlns:og="http://ogp.me/ns#">
<channel>
<atom:link rel="self" href="http://192.168.1.4/fivefilters/makefulltextfeed.php?url=hnrss.org%2Fnewest%3Fpoints%3D200&amp;max=10&amp;links=preserve&amp;exc=" />
<atom:link rel="alternate" title="Source URL" href="http://hnrss.org/newest?points=200" />
<atom:link rel="related" title="Subscribe to feed" href="http://www.subtome.com/#/subscribe?feeds=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dhnrss.org%252Fnewest%253Fpoints%253D200%26max%3D10%26links%3Dpreserve%26exc%3D&amp;back=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dhnrss.org%252Fnewest%253Fpoints%253D200%26max%3D10%26links%3Dpreserve%26exc%3D" />
<title>Hacker News: Newest</title>
<link>https://news.ycombinator.com/newest</link>
<description>Hacker News RSS</description>
<item>
<title>Signal threatens to dump US market if EARN IT act passes</title>
<link>https://uk.pcmag.com/security-5/125569/messaging-app-signal-threatens-to-dump-us-market-if-anti-encryption-bill-passes</link>
<guid isPermaLink="true" >https://uk.pcmag.com/security-5/125569/messaging-app-signal-threatens-to-dump-us-market-if-anti-encryption-bill-passes</guid>
<description>&lt;p id=&quot;affiliationDisclaimer&quot;&gt;We review products &lt;a href=&quot;https://www.pcmag.com/article2/0,2817,2355548,00.asp&quot; target=&quot;_blank&quot;&gt;independently&lt;/a&gt;, but we may earn affiliate commissions from buying links on this page. &lt;a href=&quot;https://www.ziffdavis.com/terms-of-use#endorsement&quot; target=&quot;_blank&quot;&gt;Terms of use&lt;/a&gt;.&lt;/p&gt;&lt;div id=&quot;id_text&quot; readability=&quot;93.938281901585&quot;&gt;
&lt;p&gt;&lt;a href=&quot;https://uk.pcmag.com/features/87219/7-signal-app-tips-for-secure-chats&quot;&gt;Signal&lt;/a&gt; is warning that an anti-encryption bill circulating in Congress could force the private messaging app to pull out of the US market. &lt;/p&gt;
&lt;p&gt;Since the start of the coronavirus pandemic, the free app, which offers end-to-end encryption, has seen a surge in traffic. But on Wednesday, the nonprofit behind the app published a &lt;a class=&quot;external&quot; href=&quot;https://signal.org/blog/earn-it/&quot; target=&quot;_blank&quot;&gt;blog post&lt;/a&gt;, raising the alarm around the EARN IT Act. “At a time when more people than ever are benefiting from these (encryption) protections, the &lt;a class=&quot;external&quot; href=&quot;https://www.govtrack.us/congress/bills/116/s3398/text&quot; target=&quot;_blank&quot;&gt;EARN IT bill&lt;/a&gt; proposed by the Senate Judiciary Committee threatens to put them at risk,” Signal developer Joshua Lund wrote in the post. &lt;/p&gt;
&lt;p&gt;Although the goal of the legislation, which has bipartisan support, is to stamp out online child exploitation, it does so by letting the US government regulate how internet companies should combat the problem—even if it means undermining the end-to-end encryption protecting your messages from snoops.&lt;/p&gt;

&lt;p&gt;If the companies fail to do so, they risk losing legal immunity under Section 230 of the Communications Decency Act, which can shield them from lawsuits concerning objectionable or illegal content posted on their websites or apps. &lt;/p&gt;
&lt;p&gt;“Some large tech behemoths could hypothetically shoulder the enormous financial burden of handling hundreds of new lawsuits if they suddenly became responsible for the random things their users say, but it would not be possible for a small nonprofit like Signal to continue to operate within the United States,” Lund wrote in the blog post. &lt;/p&gt;
&lt;br/&gt;&lt;img alt=&quot;Image of US Attorney General William Barr&quot; class=&quot;embed&quot; data-image-path=&quot;articles/01dprAqGJEjDfaib4tEKq9A-2.jpg&quot; data-src=&quot;https://i.pcmag.com/imagery/articles/01dprAqGJEjDfaib4tEKq9A-2.jpg&quot; src=&quot;data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2016%209'%3E%3C/svg%3E&quot;/&gt;&lt;p&gt;Why Signal is concerned the bill will undermine end-to-end encryption is because it gives US Attorney General William Barr— a major critic of encryption— the power to dictate how internet companies fight online child exploitation. In recent months, Barr has been &lt;a href=&quot;https://uk.pcmag.com/news/122899/us-to-demand-facebook-halt-encryption-on-messaging&quot;&gt;calling on&lt;/a&gt; Facebook to reverse a plan to expand end-to-end encryption across its services, on claims the technology is preventing law enforcement from tracking down criminals, including child sex offenders. &lt;/p&gt;
&lt;p&gt;“Companies should not deliberately design their systems to preclude any form of access to content, even for preventing or investigating the most serious crimes,” Barr wrote to Facebook back in October. “This puts our citizens and societies at risk by severely eroding a company’s ability to detect and respond to illegal content and activity, such as child sexual exploitation and abuse, terrorism.”&lt;/p&gt;
&lt;p&gt;However, Signal says the efforts to undermine end-to-end encryption risk doing more harm to innocent users than actual criminals, who will simply choose other ways to mask their activities online. “If easy-to-use software like Signal somehow became inaccessible, the security of millions of Americans (including elected officials and members of the armed forces) would be negatively affected,” Lund added. “Meanwhile, criminals would just continue to use widely available (but less convenient) software to jump through hoops and keep having encrypted conversations.”&lt;/p&gt;

&lt;p&gt;The EARN IT Act &lt;a class=&quot;external&quot; href=&quot;https://cyberlaw.stanford.edu/blog/2020/03/earn-it-act-here-surprise-it%E2%80%99s-still-bad-news&quot; target=&quot;_blank&quot;&gt;opposed&lt;/a&gt; by privacy advocates and tech lobbying groups but has received support from six Democratic US senators and four Republican senators. “Our goal is to do this in a balanced way that doesn’t overly inhibit innovation, but forcibly deals with child exploitation,” US Senator Lindsey Graham (R-South Carolina) said last month in &lt;a class=&quot;external&quot; href=&quot;https://www.judiciary.senate.gov/press/rep/releases/graham-blumenthal-hawley-feinstein-introduce-earn-it-act-to-encourage-tech-industry-to-take-online-child-sexual-exploitation-seriously&quot; target=&quot;_blank&quot;&gt;announcing&lt;/a&gt; the legislation. &lt;/p&gt;
&lt;p&gt;“Simply put, tech companies need to do better,” added Senator Richard Blumenthal (D-Connecticut). “Tech companies have an extraordinary special safeguard against legal liability, but that unique protection comes with a responsibility.”&lt;/p&gt;
&lt;p&gt;But other lawmakers say they're against the bill, citing its potential to be abused. &quot;This terrible legislation is a Trojan horse to give Attorney General Barr and Donald Trump the power to control online speech and require government access to every aspect of Americans' lives,&quot; said Senator Ron Wyden (D-Oregon) last month. &lt;/p&gt;

&lt;h3&gt;Further Reading&lt;/h3&gt;
&lt;h3 class=&quot;mt-8&quot;&gt;Security Reviews&lt;/h3&gt;
&lt;h3 class=&quot;mt-8&quot;&gt;Security Best Picks&lt;/h3&gt;
&lt;/div&gt;</description>
<pubDate>Thu, 09 Apr 2020 17:58:47 +0000</pubDate>
<dc:creator>tzm</dc:creator>
<og:image>https://sm.pcmag.com/t/pcmag_uk/news/m/messaging-/messaging-app-signal-threatens-to-dump-us-market-if-anti-enc_6zzp.1200.jpg</og:image>
<og:type>article</og:type>
<og:title>Messaging App Signal Threatens to Dump US Market if Anti-Encryption Bill Passes</og:title>
<og:description>Signal is calling on its users to oppose the EARN IT Act, which it fears will be used to undermine end-to-end encryption, forcing it to leave the US market.</og:description>
<og:url>https://uk.pcmag.com/security-5/125569/messaging-app-signal-threatens-to-dump-us-market-if-anti-encryption-bill-passes</og:url>
<dc:language>en-gb</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://uk.pcmag.com/security-5/125569/messaging-app-signal-threatens-to-dump-us-market-if-anti-encryption-bill-passes</dc:identifier>
</item>
<item>
<title>Launch HN: Art in Res (YC W20) – Buy art directly from artists</title>
<link>https://news.ycombinator.com/item?id=22824618</link>
<guid isPermaLink="true" >https://news.ycombinator.com/item?id=22824618</guid>
<description>Hi HN,
&lt;p&gt;I’m John Friel, cofounder of Art in Res (&lt;a href=&quot;https://artinres.com&quot; rel=&quot;nofollow&quot;&gt;https://artinres.com&lt;/a&gt;). Art in Res is an online marketplace where painters sell their art directly to buyers, instead of needing to work with an art gallery.&lt;/p&gt;&lt;p&gt;I studied art and moved to New York in 2008 dreaming of making it as an artist. It wasn’t easy. I lived in a maybe-legal warehouse space that doubled as a poorly-ventilated art studio. My first day job was stocking shelves at Trader Joe’s, which covered my rent and groceries but, at New York prices, not much else.&lt;/p&gt;
&lt;p&gt;My best friend in NYC had a side hustle making artist websites by hacking them out on top of WordPress. He was great at it. Through that side-hustle, he got approached to make an online store for a small business. Shopify wasn’t wasn’t widely known back then and he needed help. So he proposed to me: “Hey John, I know you have a nerdy side. Do you think you could learn to program and we could make the website together?” I told him “No way! That’s crazy! It would take me years to learn to program!” But he said “Look, there’s this new thing called Ruby on Rails. At least just Google that before you say ‘no’”. So I did a Rails tutorial and thought “Hmm, maybe I _could_ do this.” We accepted the gig and I’ve been a happy coder ever since. (We did _not_ ship the site on time.)&lt;/p&gt;
&lt;p&gt;I’m all in on coding now, but most of my artist friends are still making art, and still working day jobs. Their studios are full of amazing paintings that barely anyone gets to see. And for every one of my friends there are a thousand other artists out there, cranking out amazing work and not selling it because they don’t have galleries selling it for them.&lt;/p&gt;
&lt;p&gt;A couple years ago, my cofounder John (we’re both named John) told me that he had bought a painting from an artist he’d met. He couldn’t believe how great the paintings were, how cool the artist was, how the artists’ studio was this cool warehouse space that was overflowing with unsold paintings. He knew me as a programmer – but wasn’t I a painter before that? He had the idea that we could put our experiences together and make a website where people could buy art from all the amazing but not-famous artists around them.&lt;/p&gt;
&lt;p&gt;We started Art in Res as a nights-and-weekends project. We found lots of people who liked the idea of buying art – but we also realized that most people who aren’t hardcore art collectors think that paying over $100 for a painting is hard to swallow. The thing is though, that paintings are made by hand, often painstakingly over long periods of time, and so they don’t benefit from the economics of scale that create the prices that modern consumers expect.&lt;/p&gt;
&lt;p&gt;We resolve that by having our buyers purchase art on _installment plans_, where each payment results in a payment to the artist. In normal circumstances, revenue for artists tends to be spiky and unpredictable. Once an artist on Art in Res gets a couple installment plans going, they have a nice, predictable revenue stream. And a buyer who is purchasing this way gets to live with a unique, hand-made painting for ~$30-60 per month. It works really well for both parties.&lt;/p&gt;
&lt;p&gt;We’re working on Art in Res full-time now and our team has grown to 5 people (all creatives in some capacity or another.) We’re John, Dan, Noni, Emily and me. We think art should be affordable and artists should get paid. There’s so much amazing art out there, collecting dust in studios. It deserves to find loving homes. &amp;lt;3&lt;/p&gt;
&lt;p&gt;Thanks so much, and we can’t wait to hear your thoughts!&lt;/p&gt;
&lt;p&gt;–&lt;/p&gt;
&lt;p&gt;PS - I’ve been lurking HN for close to a decade and this is thrilling for me!&lt;/p&gt;
</description>
<pubDate>Thu, 09 Apr 2020 16:58:57 +0000</pubDate>
<dc:creator>JohnFriel</dc:creator>
<dc:format>text/html</dc:format>
<dc:identifier>https://news.ycombinator.com/item?id=22824618</dc:identifier>
</item>
<item>
<title>Temporal circuit of brain activity supports human consciousness</title>
<link>https://advances.sciencemag.org/content/6/11/eaaz0087</link>
<guid isPermaLink="true" >https://advances.sciencemag.org/content/6/11/eaaz0087</guid>
<description>&lt;div id=&quot;sec-1&quot; readability=&quot;71.617473435655&quot;&gt;
&lt;h2 class=&quot;&quot;&gt;INTRODUCTION&lt;/h2&gt;
&lt;p id=&quot;p-4&quot;&gt;Evidence from noninvasive functional neuroimaging studies has pointed to two distinct cortical systems that support consciousness. The default mode network (DMN) is an internally directed system that correlates with consciousness of self, and the dorsal attention network (DAT) is an externally directed system that correlates with consciousness of the environment (&lt;a id=&quot;xref-ref-1-1&quot; class=&quot;xref-bibr&quot; href=&quot;https://advances.sciencemag.org/content/6/11/eaaz0087#ref-1&quot;&gt;&lt;em&gt;1&lt;/em&gt;&lt;/a&gt;–&lt;a id=&quot;xref-ref-7-1&quot; class=&quot;xref-bibr&quot; href=&quot;https://advances.sciencemag.org/content/6/11/eaaz0087#ref-7&quot;&gt;&lt;em&gt;7&lt;/em&gt;&lt;/a&gt;). The DMN engages in a variety of internally directed processes such as autobiographical memory, imagination, and self-referencing (&lt;a id=&quot;xref-ref-6-1&quot; class=&quot;xref-bibr&quot; href=&quot;https://advances.sciencemag.org/content/6/11/eaaz0087#ref-6&quot;&gt;&lt;em&gt;6&lt;/em&gt;&lt;/a&gt;–&lt;a id=&quot;xref-ref-8-1&quot; class=&quot;xref-bibr&quot; href=&quot;https://advances.sciencemag.org/content/6/11/eaaz0087#ref-8&quot;&gt;&lt;em&gt;8&lt;/em&gt;&lt;/a&gt;). The DAT, on the other hand, mediates externally directed cognitive processes such as goal-driven attention, inhibition, and top-down guided voluntary control (&lt;a id=&quot;xref-ref-2-1&quot; class=&quot;xref-bibr&quot; href=&quot;https://advances.sciencemag.org/content/6/11/eaaz0087#ref-2&quot;&gt;&lt;em&gt;2&lt;/em&gt;&lt;/a&gt;, &lt;a id=&quot;xref-ref-6-2&quot; class=&quot;xref-bibr&quot; href=&quot;https://advances.sciencemag.org/content/6/11/eaaz0087#ref-6&quot;&gt;&lt;em&gt;6&lt;/em&gt;&lt;/a&gt;, &lt;a id=&quot;xref-ref-9-1&quot; class=&quot;xref-bibr&quot; href=&quot;https://advances.sciencemag.org/content/6/11/eaaz0087#ref-9&quot;&gt;&lt;em&gt;9&lt;/em&gt;&lt;/a&gt;). Moreover, the DMN and DAT appear to be in a reciprocal relationship with each other such that they are not simultaneously active, i.e., they are “anticorrelated.” This anticorrelation is presumed to be vital for maintaining an ongoing interaction between self and environment that contributes to consciousness (&lt;a id=&quot;xref-ref-5-1&quot; class=&quot;xref-bibr&quot; href=&quot;https://advances.sciencemag.org/content/6/11/eaaz0087#ref-5&quot;&gt;&lt;em&gt;5&lt;/em&gt;&lt;/a&gt;). Conversely, diminished anticorrelation between DMN and DAT activity has been reported in humans when consciousness was suppressed by general anesthesia (&lt;a id=&quot;xref-ref-10-1&quot; class=&quot;xref-bibr&quot; href=&quot;https://advances.sciencemag.org/content/6/11/eaaz0087#ref-10&quot;&gt;&lt;em&gt;10&lt;/em&gt;&lt;/a&gt;, &lt;a id=&quot;xref-ref-11-1&quot; class=&quot;xref-bibr&quot; href=&quot;https://advances.sciencemag.org/content/6/11/eaaz0087#ref-11&quot;&gt;&lt;em&gt;11&lt;/em&gt;&lt;/a&gt;) and in neuropathological patients with disorders of consciousness (&lt;a id=&quot;xref-ref-4-1&quot; class=&quot;xref-bibr&quot; href=&quot;https://advances.sciencemag.org/content/6/11/eaaz0087#ref-4&quot;&gt;&lt;em&gt;4&lt;/em&gt;&lt;/a&gt;, &lt;a id=&quot;xref-ref-12-1&quot; class=&quot;xref-bibr&quot; href=&quot;https://advances.sciencemag.org/content/6/11/eaaz0087#ref-12&quot;&gt;&lt;em&gt;12&lt;/em&gt;&lt;/a&gt;), supporting the hypothesis that a balance of the internally and externally directed systems is important for waking consciousness.&lt;/p&gt;
&lt;p id=&quot;p-5&quot;&gt;Despite some evidence for this temporal relationship, the anticorrelation of DMN and DAT over time has not been conclusively demonstrated. First, the anticorrelation of functional magnetic resonance imaging (fMRI) signals is generally inferred from temporally averaged functional connectivity, which does not allow a direct assessment of the temporal dynamics of networks. Second, the criticism has been raised that the anticorrelation of fMRI signals may be a by-product of global signal regression (GSR)—a necessary preprocessing step that most such studies have used (&lt;a id=&quot;xref-ref-13-1&quot; class=&quot;xref-bibr&quot; href=&quot;https://advances.sciencemag.org/content/6/11/eaaz0087#ref-13&quot;&gt;&lt;em&gt;13&lt;/em&gt;&lt;/a&gt;–&lt;a id=&quot;xref-ref-15-1&quot; class=&quot;xref-bibr&quot; href=&quot;https://advances.sciencemag.org/content/6/11/eaaz0087#ref-15&quot;&gt;&lt;em&gt;15&lt;/em&gt;&lt;/a&gt;). Therefore, the controversy about GSR characteristic of conventional static connectivity analysis prevents the unequivocal conclusion that the disruption of anticorrelation between DMN and DAT is a cause of disrupted consciousness. Furthermore, even assuming anticorrelation, the dynamic relationship of DMN and DAT to other networks of critical relevance to consciousness has not been elucidated.&lt;/p&gt;
&lt;p id=&quot;p-6&quot;&gt;To fill this gap of knowledge, an analysis of dynamic brain activity is necessary. Although the brain appears to engage in an ongoing exploration of its repertoire of distinct states (&lt;a id=&quot;xref-ref-16-1&quot; class=&quot;xref-bibr&quot; href=&quot;https://advances.sciencemag.org/content/6/11/eaaz0087#ref-16&quot;&gt;&lt;em&gt;16&lt;/em&gt;&lt;/a&gt;–&lt;a id=&quot;xref-ref-20-1&quot; class=&quot;xref-bibr&quot; href=&quot;https://advances.sciencemag.org/content/6/11/eaaz0087#ref-20&quot;&gt;&lt;em&gt;20&lt;/em&gt;&lt;/a&gt;), i.e., dynamic shaping and reshaping of functional brain configurations, it remains largely unknown if there is a structured exploration of its repertoire that is specific to the conscious versus unconscious brain. Accordingly, we hypothesized that the alternation of DMN and DAT over time is embedded in the ongoing exploration of all functional brain networks and that a disruption of this exploration may account for the diminished DMN-DAT anticorrelation when consciousness is suppressed. We also hypothesized that, in the conscious brain, the dynamic switching of networks including the DMN and DAT occurs along a set of structured transition trajectories, what might be conceived of as a “temporal circuit,” and that this temporal circuit is disrupted during diminished consciousness.&lt;/p&gt;
&lt;p id=&quot;p-7&quot;&gt;We tested our hypotheses by analyzing resting-state fMRI (rs-fMRI) signals from a cohort of 98 participants and patients in conditions that included conscious resting state and various unresponsive states induced by pharmacological (propofol and ketamine anesthesia, with distinct molecular targets) and neuropathological [unresponsive wakefulness syndrome (UWS)] etiologies. Although these conditions involve different molecular mechanisms, neural circuits, and brain functions, they share a common behavioral end point, i.e., a general unresponsiveness to external voice commands. Here, we conservatively use the term “unresponsiveness” instead of “unconsciousness” to allow for the possibility that covert or disconnected consciousness could occur in the absence of behavioral response. Combining data from different conditions allowed us to examine both the common and specific (anesthetic agent– and neuropathology-dependent) alterations of macroscale brain dynamics. We adopted an unsupervised machine learning approach to capturing transient, momentary coactivation patterns (CAPs) (&lt;a id=&quot;xref-ref-21-1&quot; class=&quot;xref-bibr&quot; href=&quot;https://advances.sciencemag.org/content/6/11/eaaz0087#ref-21&quot;&gt;&lt;em&gt;21&lt;/em&gt;&lt;/a&gt;–&lt;a id=&quot;xref-ref-24-1&quot; class=&quot;xref-bibr&quot; href=&quot;https://advances.sciencemag.org/content/6/11/eaaz0087#ref-24&quot;&gt;&lt;em&gt;24&lt;/em&gt;&lt;/a&gt;). The temporal dynamics of CAP transition trajectories were then analyzed as a Markov process, and the transition probability, persistence, and accessibility of CAPs were quantified. Last, we explored the stimulus modulations of CAPs during different conditions in a subset (&lt;em&gt;n&lt;/em&gt; = 37) of the main cohort and evaluated the specificity of our results in an independent cohort of 248 participants consisting of healthy control participants and patients with psychiatric disorders (schizophrenia, bipolar disorder, and attention deficit/hyperactive disorder), who might have altered brain networks but who were nonetheless conscious.&lt;/p&gt;
&lt;/div&gt;&lt;div id=&quot;sec-2&quot; readability=&quot;169.7611693326&quot;&gt;
&lt;h2 class=&quot;&quot;&gt;RESULTS&lt;/h2&gt;
&lt;p id=&quot;p-8&quot;&gt;We recorded fMRI data at two independent research sites in Shanghai (SHH) and Wisconsin (WI), which generated four datasets (i.e., propofol-SHH, propofol-WI, ketamine, and neuropathological patients) containing both control and test results (&lt;a id=&quot;xref-fig-1-1&quot; class=&quot;xref-fig&quot; href=&quot;https://advances.sciencemag.org/content/6/11/eaaz0087#F1&quot;&gt;Fig. 1A&lt;/a&gt;). CAPs of brain activity, i.e., sets of voxels simultaneously activated, were extracted from the entire dataset by &lt;em&gt;k&lt;/em&gt;-means clustering algorithm (see more details in Materials and Methods). We determined an optimized number of CAPs (&lt;em&gt;k&lt;/em&gt; = 8; from a search between 2 and 30) based on the non-GSR data for our main analysis scheme, and other selections of &lt;em&gt;k&lt;/em&gt; (both with and without GSR) served as control analysis. This was achieved by evaluating the clustering performance, trading off the interdataset similarity (fig. S1) and visually inspecting the spatial patterns corresponding to major known functional networks (fig. S2). The eight CAPs were classified as DMN+, DAT+, frontoparietal network (FPN+), sensory and motor network (SMN+), visual network (VIS+), ventral attention network (VAT+), and global network of activation and deactivation (GN+ and GN−) (&lt;a id=&quot;xref-fig-1-2&quot; class=&quot;xref-fig&quot; href=&quot;https://advances.sciencemag.org/content/6/11/eaaz0087#F1&quot;&gt;Fig. 1B&lt;/a&gt;). The eight CAPs could be divided into four pairs of “mirror” motifs, with a strong negative spatial similarity (Pearson correlation coefficient: &lt;em&gt;r&lt;/em&gt; = −0.97 to −1.00; &lt;a id=&quot;xref-fig-1-3&quot; class=&quot;xref-fig&quot; href=&quot;https://advances.sciencemag.org/content/6/11/eaaz0087#F1&quot;&gt;Fig. 1C&lt;/a&gt;). For instance, the DMN+ was accompanied by codeactivation of DAT (DAT−) and vice versa for DAT+ (DMN−). The “antiphasic” relationship between those mirror motifs is to be expected. Assuming that fMRI signals exhibit block correlation structure and that voxels fluctuate in their amplitude over time, then voxels will be “active” or “inactive” at different times with respect to the correlation structure and moving in blocks. In addition, the DMN+ and DAT+ were more spatially segregated (consisting of 18 and 14 clusters), distributed across widespread cortical and subcortical regions, compared to other CAPs (fig. S3). As expected, the CAPs could capture the instantaneous phase synchronizations at single-volume temporal resolution of fMRI (fig. S3).&lt;/p&gt;
&lt;div class=&quot;figure__head highwire-figure&quot;&gt;
&lt;div class=&quot;fig-inline&quot;&gt;&lt;a href=&quot;https://advances.sciencemag.org/content/advances/6/11/eaaz0087/F1.large.jpg?width=800&amp;amp;height=600&amp;amp;carousel=1&quot; title=&quot;Level of behavioral responsiveness across datasets and CAPs. (A) Dataset 1 (propofol-SHH) adopted Ramsay scale. Dataset 2 (propofol-WI) adopted observer’s assessment of alertness/sedation (OAAS). Dataset 3 (ketamine) adopted a button press task for every 30 s. Reaction time (RT) in milliseconds with respect to each instruction was recoded. By comparing the timing of verbal instruction and actual responsiveness during and after ketamine infusion, the periods during which a participant retained responsiveness (PreLOR), loss of responsiveness (LOR), and recovery of responsiveness were determined. Dataset 4 (neuropathological patients) adopted Coma Recovery Scale–Revised (CRS-R). Level of responsiveness is shown by the total score of six subscales (auditory, visual, motor, verbal, communication, and arousal). MCS, minimally conscious state. Error bars indicate ±SD. (B) Spatial maps of eight CAPs. The CAPs consist of DMN+, DAT+, FPN+, SMN+, VIS+, VAT+, GN+, and GN−. (C) The eight CAPs are composed of four pairs of mirror motifs with a strong negative spatial similarity, including DMN+ versus DAT+, VIS+ versus VAT+, FPN+ versus SMN+, and GN− versus GN+.&quot; class=&quot;fragment-images colorbox-load&quot; rel=&quot;gallery-fragment-images-1307286814&quot; data-figure-caption=&quot;&amp;lt;div class=&amp;quot;highwire-markup&amp;quot;&amp;gt;&amp;lt;span class=&amp;quot;fig-label&amp;quot;&amp;gt;Fig. 1&amp;lt;/span&amp;gt; &amp;lt;span class=&amp;quot;caption-title&amp;quot;&amp;gt;Level of behavioral responsiveness across datasets and CAPs.&amp;lt;/span&amp;gt;&amp;lt;p id=&amp;quot;p-9&amp;quot; class=&amp;quot;first-child&amp;quot;&amp;gt;(&amp;lt;strong&amp;gt;A&amp;lt;/strong&amp;gt;) Dataset 1 (propofol-SHH) adopted Ramsay scale. Dataset 2 (propofol-WI) adopted observer’s assessment of alertness/sedation (OAAS). Dataset 3 (ketamine) adopted a button press task for every 30 s. Reaction time (RT) in milliseconds with respect to each instruction was recoded. By comparing the timing of verbal instruction and actual responsiveness during and after ketamine infusion, the periods during which a participant retained responsiveness (PreLOR), loss of responsiveness (LOR), and recovery of responsiveness were determined. Dataset 4 (neuropathological patients) adopted Coma Recovery Scale–Revised (CRS-R). Level of responsiveness is shown by the total score of six subscales (auditory, visual, motor, verbal, communication, and arousal). MCS, minimally conscious state. Error bars indicate ±SD. (&amp;lt;strong&amp;gt;B&amp;lt;/strong&amp;gt;) Spatial maps of eight CAPs. The CAPs consist of DMN+, DAT+, FPN+, SMN+, VIS+, VAT+, GN+, and GN−. (&amp;lt;strong&amp;gt;C&amp;lt;/strong&amp;gt;) The eight CAPs are composed of four pairs of mirror motifs with a strong negative spatial similarity, including DMN+ versus DAT+, VIS+ versus VAT+, FPN+ versus SMN+, and GN− versus GN+.&amp;lt;/p&amp;gt;&amp;lt;div class=&amp;quot;sb-div caption-clear&amp;quot;/&amp;gt;&amp;lt;/div&amp;gt;&quot; data-icon-position=&quot;&quot; data-hide-link-title=&quot;0&quot;&gt;&lt;span class=&quot;hw-responsive-img&quot;&gt;&lt;img class=&quot;fragment-image lazyload&quot; aria-describedby=&quot;F1-caption&quot; src=&quot;data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7&quot; data-src=&quot;https://advances.sciencemag.org/content/advances/6/11/eaaz0087/F1.medium.gif&quot;/&gt;&lt;noscript&gt;
&lt;p&gt;&lt;img class=&quot;fragment-image&quot; aria-describedby=&quot;F1-caption&quot; src=&quot;https://advances.sciencemag.org/content/advances/6/11/eaaz0087/F1.medium.gif&quot;/&gt;&lt;/p&gt;
&lt;/noscript&gt;&lt;/span&gt;&lt;/a&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;span class=&quot;fig-label&quot;&gt;Fig. 1&lt;/span&gt; &lt;span class=&quot;caption-title&quot;&gt;Level of behavioral responsiveness across datasets and CAPs.&lt;/span&gt;
&lt;p id=&quot;p-9&quot; class=&quot;first-child&quot;&gt;(&lt;strong&gt;A&lt;/strong&gt;) Dataset 1 (propofol-SHH) adopted Ramsay scale. Dataset 2 (propofol-WI) adopted observer’s assessment of alertness/sedation (OAAS). Dataset 3 (ketamine) adopted a button press task for every 30 s. Reaction time (RT) in milliseconds with respect to each instruction was recoded. By comparing the timing of verbal instruction and actual responsiveness during and after ketamine infusion, the periods during which a participant retained responsiveness (PreLOR), loss of responsiveness (LOR), and recovery of responsiveness were determined. Dataset 4 (neuropathological patients) adopted Coma Recovery Scale–Revised (CRS-R). Level of responsiveness is shown by the total score of six subscales (auditory, visual, motor, verbal, communication, and arousal). MCS, minimally conscious state. Error bars indicate ±SD. (&lt;strong&gt;B&lt;/strong&gt;) Spatial maps of eight CAPs. The CAPs consist of DMN+, DAT+, FPN+, SMN+, VIS+, VAT+, GN+, and GN−. (&lt;strong&gt;C&lt;/strong&gt;) The eight CAPs are composed of four pairs of mirror motifs with a strong negative spatial similarity, including DMN+ versus DAT+, VIS+ versus VAT+, FPN+ versus SMN+, and GN− versus GN+.&lt;/p&gt;

&lt;div id=&quot;sec-3&quot; class=&quot;subsection&quot; readability=&quot;58.528868969154&quot;&gt;
&lt;h3&gt;Suppression of DMN+ and DAT+ in various forms of behavioral unresponsiveness&lt;/h3&gt;
&lt;p id=&quot;p-10&quot;&gt;We first tested whether there are common associations between the occurrence rates of CAPs (i.e., dividing the number of fMRI volumes belonging to a given CAP by the total number of volumes per scan) and level of responsiveness across various conditions. We found significant positive correlations between the occurrence rates of DMN and DAT (joint DMN+ and DAT+) and level of responsiveness for all datasets together (all pooled, rho = 0.58, &lt;em&gt;P&lt;/em&gt; &amp;lt; 0.0001), and individual datasets [propofol-SHH, rho = 0.64, &lt;em&gt;P&lt;/em&gt; &amp;lt; 0.0001; propofol-WI, rho = 0.43, &lt;em&gt;P&lt;/em&gt; = 0.0017; ketamine, rho = 0.55, &lt;em&gt;P&lt;/em&gt; = 0.0002; neuropathological patients, rho = 0.73, &lt;em&gt;P&lt;/em&gt; &amp;lt; 0.0001; false discovery rate (FDR)–corrected at α &amp;lt; 0.05] (&lt;a id=&quot;xref-fig-2-1&quot; class=&quot;xref-fig&quot; href=&quot;https://advances.sciencemag.org/content/6/11/eaaz0087#F2&quot;&gt;Fig. 2A&lt;/a&gt;). The correlations for DMN+ and DAT+ alone yielded similar results. In contrast, for instance, the occurrence rates of VIS+ and VAT+ (for propofol-SHH, propofol-WI, and neuropathological patients) and GN+ and GN− (for ketamine and neuropathological patients) showed negative correlations with the level of responsiveness (see fig. S4 for scatterplots and statistics).&lt;/p&gt;
&lt;div class=&quot;figure__head highwire-figure&quot;&gt;
&lt;div class=&quot;fig-inline&quot;&gt;&lt;a href=&quot;https://advances.sciencemag.org/content/advances/6/11/eaaz0087/F2.large.jpg?width=800&amp;amp;height=600&amp;amp;carousel=1&quot; title=&quot;Occurrence rates of CAPs. (A) Spearman rank correlations between the occurrence rates of joint mirror motifs or individual CAPs and the level of responsiveness. (B to E) The CAP occurrence rates in different conditions (conscious, intermediate, unresponsive, and recovered) and in different datasets. Intermediate conditions refer to propofol light sedation, PreLOR of ketamine induction, and patients with MCS; unresponsive conditions refer to propofol general anesthesia and deep sedation, LOR due to ketamine, and patients with UWS. Red squares in (A) and lines in (B) to (E) indicate significance at FDR-corrected α &amp;lt; 0.05. See fig. S4 and table S1 for full statistics. Error bars in (A) indicate 95% confidence interval, and error bars in (B) to (E) indicate ±SD.&quot; class=&quot;fragment-images colorbox-load&quot; rel=&quot;gallery-fragment-images-1307286814&quot; data-figure-caption=&quot;&amp;lt;div class=&amp;quot;highwire-markup&amp;quot;&amp;gt;&amp;lt;span class=&amp;quot;fig-label&amp;quot;&amp;gt;Fig. 2&amp;lt;/span&amp;gt; &amp;lt;span class=&amp;quot;caption-title&amp;quot;&amp;gt;Occurrence rates of CAPs.&amp;lt;/span&amp;gt;&amp;lt;p id=&amp;quot;p-11&amp;quot; class=&amp;quot;first-child&amp;quot;&amp;gt;(&amp;lt;strong&amp;gt;A&amp;lt;/strong&amp;gt;) Spearman rank correlations between the occurrence rates of joint mirror motifs or individual CAPs and the level of responsiveness. (&amp;lt;strong&amp;gt;B&amp;lt;/strong&amp;gt; to &amp;lt;strong&amp;gt;E&amp;lt;/strong&amp;gt;) The CAP occurrence rates in different conditions (conscious, intermediate, unresponsive, and recovered) and in different datasets. Intermediate conditions refer to propofol light sedation, PreLOR of ketamine induction, and patients with MCS; unresponsive conditions refer to propofol general anesthesia and deep sedation, LOR due to ketamine, and patients with UWS. Red squares in (A) and lines in (B) to (E) indicate significance at FDR-corrected α &amp;lt; 0.05. See fig. S4 and table S1 for full statistics. Error bars in (A) indicate 95% confidence interval, and error bars in (B) to (E) indicate ±SD.&amp;lt;/p&amp;gt;&amp;lt;div class=&amp;quot;sb-div caption-clear&amp;quot;/&amp;gt;&amp;lt;/div&amp;gt;&quot; data-icon-position=&quot;&quot; data-hide-link-title=&quot;0&quot;&gt;&lt;span class=&quot;hw-responsive-img&quot;&gt;&lt;img class=&quot;fragment-image lazyload&quot; aria-describedby=&quot;F2-caption&quot; src=&quot;data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7&quot; data-src=&quot;https://advances.sciencemag.org/content/advances/6/11/eaaz0087/F2.medium.gif&quot;/&gt;&lt;noscript&gt;
&lt;p&gt;&lt;img class=&quot;fragment-image&quot; aria-describedby=&quot;F2-caption&quot; src=&quot;https://advances.sciencemag.org/content/advances/6/11/eaaz0087/F2.medium.gif&quot;/&gt;&lt;/p&gt;
&lt;/noscript&gt;&lt;/span&gt;&lt;/a&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;span class=&quot;fig-label&quot;&gt;Fig. 2&lt;/span&gt; &lt;span class=&quot;caption-title&quot;&gt;Occurrence rates of CAPs.&lt;/span&gt;
&lt;p id=&quot;p-11&quot; class=&quot;first-child&quot;&gt;(&lt;strong&gt;A&lt;/strong&gt;) Spearman rank correlations between the occurrence rates of joint mirror motifs or individual CAPs and the level of responsiveness. (&lt;strong&gt;B&lt;/strong&gt; to &lt;strong&gt;E&lt;/strong&gt;) The CAP occurrence rates in different conditions (conscious, intermediate, unresponsive, and recovered) and in different datasets. Intermediate conditions refer to propofol light sedation, PreLOR of ketamine induction, and patients with MCS; unresponsive conditions refer to propofol general anesthesia and deep sedation, LOR due to ketamine, and patients with UWS. Red squares in (A) and lines in (B) to (E) indicate significance at FDR-corrected α &amp;lt; 0.05. See fig. S4 and table S1 for full statistics. Error bars in (A) indicate 95% confidence interval, and error bars in (B) to (E) indicate ±SD.&lt;/p&gt;

&lt;p id=&quot;p-12&quot;&gt;We next examined the differences of CAP occurrence rates between conditions. During unresponsive conditions, the occurrence rates of DMN+ and DAT+ were significantly reduced (a summary of statistics in table S1). As anticipated by the above correlation analysis, this phenomenon was reproducible in two independent datasets of propofol-induced unresponsiveness (propofol-SHH and propofol-WI) and generalizable from propofol-induced unresponsiveness to ketamine-induced unresponsiveness and to patients with minimally conscious state (MCS) and UWS (&lt;a id=&quot;xref-fig-2-2&quot; class=&quot;xref-fig&quot; href=&quot;https://advances.sciencemag.org/content/6/11/eaaz0087#F2&quot;&gt;Fig. 2B&lt;/a&gt;). In addition, the results were robust with respect to the choice of &lt;em&gt;k&lt;/em&gt; in the &lt;em&gt;k&lt;/em&gt;-means clustering method and to the option of GSR or not during data preprocessing (fig. S5).&lt;/p&gt;
&lt;p id=&quot;p-13&quot;&gt;We also found specific changes of CAP occurrence rates during various unresponsive conditions. Comparing to the conscious condition, an increased prevalence of VIS+ and VAT+ was seen during propofol-induced unresponsiveness (&lt;a id=&quot;xref-fig-2-3&quot; class=&quot;xref-fig&quot; href=&quot;https://advances.sciencemag.org/content/6/11/eaaz0087#F2&quot;&gt;Fig. 2C&lt;/a&gt;). An increased prevalence of GN+ and GN−, as well as a decreased prevalence of FPN+ and SMN+, respectively, was observed during ketamine-induced unresponsiveness (&lt;a id=&quot;xref-fig-2-4&quot; class=&quot;xref-fig&quot; href=&quot;https://advances.sciencemag.org/content/6/11/eaaz0087#F2&quot;&gt;Fig. 2, D and E&lt;/a&gt;). The patients with UWS shared those effects with propofol and ketamine anesthesia. Last, we measured the state entropy characterizing the uniformity of the occurrence rates of different CAPs. We found that the state entropy was significantly reduced in all unresponsive conditions (&lt;em&gt;P&lt;/em&gt; = 0.048 for conscious condition versus propofol-induced unresponsiveness; &lt;em&gt;P&lt;/em&gt; = 0.005 for conscious condition versus ketamine-induced unresponsiveness; &lt;em&gt;P&lt;/em&gt; = 0.022 for conscious condition versus patients with UWS). This suggests that the distribution of CAP occurrence rates tends to be less uniform (or imbalanced), and therefore more stereotypic, during unresponsive conditions.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&quot;sec-4&quot; class=&quot;subsection&quot; readability=&quot;91.441989758595&quot;&gt;
&lt;h3&gt;Persistence and transitions between CAPs distinguish conscious from behaviorally unresponsive conditions&lt;/h3&gt;
&lt;p id=&quot;p-14&quot;&gt;To advance the field beyond the typical approach of describing static patterns, we sought to delineate the temporal dynamics of these CAPs and compare fully unresponsive conditions to baseline consciousness (&lt;a id=&quot;xref-fig-3-1&quot; class=&quot;xref-fig&quot; href=&quot;https://advances.sciencemag.org/content/6/11/eaaz0087#F3&quot;&gt;Fig. 3, A and B&lt;/a&gt;, and see movie S1 for an illustration of CAP temporal dynamics). First, we observed distinct characteristics across different conditions in terms of preferred transitions (i.e., the probability of transitioning between two distinct CAPs is higher than a null model; see more details in Materials and Methods) and nonpreferred transitions (i.e., lower than null). During the conscious condition, the CAPs seemed to follow structured transition trajectories with relatively balanced preferred and nonpreferred paths. Second, in contrast, there were fewer trajectories reaching DMN+ and DAT+, and the trajectories were monopolized by a few specific “hosts” such as VIS+ and VAT+ during propofol-induced unresponsiveness and patients with UWS and VIS+, VAT+, GN+, and GN− during ketamine-induced unresponsiveness (&lt;a id=&quot;xref-fig-3-2&quot; class=&quot;xref-fig&quot; href=&quot;https://advances.sciencemag.org/content/6/11/eaaz0087#F3&quot;&gt;Fig. 3C&lt;/a&gt;). Last, the CAP persistence probabilities, i.e., the probability of remaining in a given CAP, for all conditions occurred significantly above the level of chance (higher than a null model). However, compared to the conscious condition, the persistence probabilities of the CAPs were overall weaker during the unresponsive conditions (&lt;a id=&quot;xref-fig-3-3&quot; class=&quot;xref-fig&quot; href=&quot;https://advances.sciencemag.org/content/6/11/eaaz0087#F3&quot;&gt;Fig. 3C&lt;/a&gt;). Ketamine-induced unresponsiveness was associated with an increased persistence of globally activated and deactivated brain states (GN+ and GN−).&lt;/p&gt;
&lt;div class=&quot;figure__head highwire-figure&quot;&gt;
&lt;div class=&quot;fig-inline&quot;&gt;&lt;a href=&quot;https://advances.sciencemag.org/content/advances/6/11/eaaz0087/F3.large.jpg?width=800&amp;amp;height=600&amp;amp;carousel=1&quot; title=&quot;Transition probabilities among CAPs. (A) Full transition probability matrix for conscious condition (conscious), propofol-induced unresponsiveness (propofol), ketamine-induced unresponsiveness (ketamine), and patients with UWS. The on-diagonal entries are referred to as the persistence probabilities. (B) Diagonal-free transition probability matrix, where the off-diagonal entries are referred to as transition probabilities by controlling for autocorrelation due to the CAP’s persistence. (C) Schematic illustration of the significant preferred paths (&amp;gt;null) and nonpreferred paths (&quot; class=&quot;fragment-images colorbox-load&quot; rel=&quot;gallery-fragment-images-1307286814&quot; data-figure-caption=&quot;&amp;lt;div class=&amp;quot;highwire-markup&amp;quot;&amp;gt;&amp;lt;span class=&amp;quot;fig-label&amp;quot;&amp;gt;Fig. 3&amp;lt;/span&amp;gt; &amp;lt;span class=&amp;quot;caption-title&amp;quot;&amp;gt;Transition probabilities among CAPs.&amp;lt;/span&amp;gt;&amp;lt;p id=&amp;quot;p-15&amp;quot; class=&amp;quot;first-child&amp;quot;&amp;gt;(&amp;lt;strong&amp;gt;A&amp;lt;/strong&amp;gt;) Full transition probability matrix for conscious condition (conscious), propofol-induced unresponsiveness (propofol), ketamine-induced unresponsiveness (ketamine), and patients with UWS. The on-diagonal entries are referred to as the persistence probabilities. (&amp;lt;strong&amp;gt;B&amp;lt;/strong&amp;gt;) Diagonal-free transition probability matrix, where the off-diagonal entries are referred to as transition probabilities by controlling for autocorrelation due to the CAP’s persistence. (&amp;lt;strong&amp;gt;C&amp;lt;/strong&amp;gt;) Schematic illustration of the significant preferred paths (&amp;gt;null) and nonpreferred paths (&amp;lt;null) for conscious versus null, propofol versus null, ketamine versus null, and patients with UWS versus null (all gray arrows). Red (higher than conscious condition) and green (lower than conscious condition) arrows indicate significant differences of persistence probabilities and transition probabilities comparing to baseline consciousness. The null model for each condition and the differences between conditions were generated by 1000 permutations across the entire dataset (see more details in Materials and Methods). Significance level was determined at &amp;lt;em&amp;gt;P&amp;lt;/em&amp;gt; &amp;lt; 0.001 by considering multiple comparison corrections (99.9th and 0.1th percentile of the null distributions; two-sided).&amp;lt;/p&amp;gt;&amp;lt;div class=&amp;quot;sb-div caption-clear&amp;quot;/&amp;gt;&amp;lt;/div&amp;gt;&quot; data-icon-position=&quot;&quot; data-hide-link-title=&quot;0&quot;&gt;&lt;span class=&quot;hw-responsive-img&quot;&gt;&lt;img class=&quot;fragment-image lazyload&quot; aria-describedby=&quot;F3-caption&quot; src=&quot;data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7&quot; data-src=&quot;https://advances.sciencemag.org/content/advances/6/11/eaaz0087/F3.medium.gif&quot;/&gt;&lt;noscript&gt;
&lt;p&gt;&lt;img class=&quot;fragment-image&quot; aria-describedby=&quot;F3-caption&quot; src=&quot;https://advances.sciencemag.org/content/advances/6/11/eaaz0087/F3.medium.gif&quot;/&gt;&lt;/p&gt;
&lt;/noscript&gt;&lt;/span&gt;&lt;/a&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;span class=&quot;fig-label&quot;&gt;Fig. 3&lt;/span&gt; &lt;span class=&quot;caption-title&quot;&gt;Transition probabilities among CAPs.&lt;/span&gt;
&lt;p id=&quot;p-15&quot; class=&quot;first-child&quot;&gt;(&lt;strong&gt;A&lt;/strong&gt;) Full transition probability matrix for conscious condition (conscious), propofol-induced unresponsiveness (propofol), ketamine-induced unresponsiveness (ketamine), and patients with UWS. The on-diagonal entries are referred to as the persistence probabilities. (&lt;strong&gt;B&lt;/strong&gt;) Diagonal-free transition probability matrix, where the off-diagonal entries are referred to as transition probabilities by controlling for autocorrelation due to the CAP’s persistence. (&lt;strong&gt;C&lt;/strong&gt;) Schematic illustration of the significant preferred paths (&amp;gt;null) and nonpreferred paths (&amp;lt;null) for conscious versus null, propofol versus null, ketamine versus null, and patients with UWS versus null (all gray arrows). Red (higher than conscious condition) and green (lower than conscious condition) arrows indicate significant differences of persistence probabilities and transition probabilities comparing to baseline consciousness. The null model for each condition and the differences between conditions were generated by 1000 permutations across the entire dataset (see more details in Materials and Methods). Significance level was determined at &lt;em&gt;P&lt;/em&gt; &amp;lt; 0.001 by considering multiple comparison corrections (99.9th and 0.1th percentile of the null distributions; two-sided).&lt;/p&gt;

&lt;p id=&quot;p-16&quot;&gt;These observations were supported by examining the entropy of Markov trajectories (&lt;a id=&quot;xref-ref-25-1&quot; class=&quot;xref-bibr&quot; href=&quot;https://advances.sciencemag.org/content/6/11/eaaz0087#ref-25&quot;&gt;&lt;em&gt;25&lt;/em&gt;&lt;/a&gt;, &lt;a id=&quot;xref-ref-26-1&quot; class=&quot;xref-bibr&quot; href=&quot;https://advances.sciencemag.org/content/6/11/eaaz0087#ref-26&quot;&gt;&lt;em&gt;26&lt;/em&gt;&lt;/a&gt;). This approach measured the descriptive complexity of trajectories (in bits) between each pair of CAPs (&lt;a id=&quot;xref-fig-4-1&quot; class=&quot;xref-fig&quot; href=&quot;https://advances.sciencemag.org/content/6/11/eaaz0087#F4&quot;&gt;Fig. 4A&lt;/a&gt;). A lower descriptive complexity from a starting point (initial CAP) to its destination (final CAP) indicates a higher accessibility for the destination. For example, if the transition probability from CAP &lt;em&gt;i&lt;/em&gt; to CAP &lt;em&gt;j&lt;/em&gt; equals 1, then the entropy of trajectory from CAP &lt;em&gt;i&lt;/em&gt; to CAP &lt;em&gt;j&lt;/em&gt; is 0 bits, reflecting the conditional determinism (i.e., high accessibility) of that path. In contrast, if the transition probability from CAP &lt;em&gt;i&lt;/em&gt; to CAP &lt;em&gt;j&lt;/em&gt; equals to 0, then CAP &lt;em&gt;i&lt;/em&gt; must first transition to other CAPs to end at CAP &lt;em&gt;j&lt;/em&gt;. In this scenario, the entropy of trajectory from CAP &lt;em&gt;i&lt;/em&gt; to CAP &lt;em&gt;j&lt;/em&gt; is higher (needs more bits), thus reflecting a higher uncertainty or lower accessibility of that path. The key finding across these various conditions is that unresponsiveness was associated with an isolation (i.e., less accessibility) of DMN+ and DAT+ from the trajectory space, which is monopolized by a few giant attractors. More specifically, compared to the conscious condition, propofol-induced unresponsiveness and patients with UWS were characterized by increased accessibility of VIS+ and VAT+ and decreased accessibility of DMN+ and DAT+. Ketamine-induced unresponsiveness was characterized by increased accessibility of GN+, GN−, VIS+, and VAT+ and decreased accessibility of DMN+, DAT+, FPN+, and SMN+ (&lt;a id=&quot;xref-fig-4-2&quot; class=&quot;xref-fig&quot; href=&quot;https://advances.sciencemag.org/content/6/11/eaaz0087#F4&quot;&gt;Fig. 4, B and C&lt;/a&gt;). The main finding regarding the decreased accessibility of DMN+ and DAT+ during unresponsive states was robust with respect to the choice of &lt;em&gt;k&lt;/em&gt; and to the option of GSR or not during data preprocessing (fig. S6).&lt;/p&gt;
&lt;div class=&quot;figure__head highwire-figure&quot;&gt;
&lt;div class=&quot;fig-inline&quot;&gt;&lt;a href=&quot;https://advances.sciencemag.org/content/advances/6/11/eaaz0087/F4.large.jpg?width=800&amp;amp;height=600&amp;amp;carousel=1&quot; title=&quot;Descriptive complexity of trajectories among CAPs and their in-degree accessibility. (A) Descriptive complexity of trajectories (in bits) between each pair of CAPs in the conscious condition (conscious), propofol-induced unresponsiveness (propofol), ketamine-induced unresponsiveness (ketamine), and in patients with UWS. (B) Significant differences of the descriptive complexity of trajectories for propofol versus conscious, ketamine versus conscious, and patients with UWS versus conscious. The null models were generated by 1000 permutations across the entire dataset. Significance level was determined at P &amp;lt; 0.001. (C) Schematic illustration for (A). The accessibility of each CAP is defined as the inverse of descriptive complexity. The node size is proportional to in-degree accessibility. The Gephi Force Atlas layout algorithm (https://gephi.org) was used.&quot; class=&quot;fragment-images colorbox-load&quot; rel=&quot;gallery-fragment-images-1307286814&quot; data-figure-caption=&quot;&amp;lt;div class=&amp;quot;highwire-markup&amp;quot;&amp;gt;&amp;lt;span class=&amp;quot;fig-label&amp;quot;&amp;gt;Fig. 4&amp;lt;/span&amp;gt; &amp;lt;span class=&amp;quot;caption-title&amp;quot;&amp;gt;Descriptive complexity of trajectories among CAPs and their in-degree accessibility.&amp;lt;/span&amp;gt;&amp;lt;p id=&amp;quot;p-17&amp;quot; class=&amp;quot;first-child&amp;quot;&amp;gt;(&amp;lt;strong&amp;gt;A&amp;lt;/strong&amp;gt;) Descriptive complexity of trajectories (in bits) between each pair of CAPs in the conscious condition (conscious), propofol-induced unresponsiveness (propofol), ketamine-induced unresponsiveness (ketamine), and in patients with UWS. (&amp;lt;strong&amp;gt;B&amp;lt;/strong&amp;gt;) Significant differences of the descriptive complexity of trajectories for propofol versus conscious, ketamine versus conscious, and patients with UWS versus conscious. The null models were generated by 1000 permutations across the entire dataset. Significance level was determined at &amp;lt;em&amp;gt;P&amp;lt;/em&amp;gt; &amp;lt; 0.001. (&amp;lt;strong&amp;gt;C&amp;lt;/strong&amp;gt;) Schematic illustration for (A). The accessibility of each CAP is defined as the inverse of descriptive complexity. The node size is proportional to in-degree accessibility. The Gephi Force Atlas layout algorithm (&amp;lt;a href=&amp;quot;https://gephi.org&amp;quot;&amp;gt;https://gephi.org&amp;lt;/a&amp;gt;) was used.&amp;lt;/p&amp;gt;&amp;lt;div class=&amp;quot;sb-div caption-clear&amp;quot;/&amp;gt;&amp;lt;/div&amp;gt;&quot; data-icon-position=&quot;&quot; data-hide-link-title=&quot;0&quot;&gt;&lt;span class=&quot;hw-responsive-img&quot;&gt;&lt;img class=&quot;fragment-image lazyload&quot; aria-describedby=&quot;F4-caption&quot; src=&quot;data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7&quot; data-src=&quot;https://advances.sciencemag.org/content/advances/6/11/eaaz0087/F4.medium.gif&quot;/&gt;&lt;noscript&gt;
&lt;p&gt;&lt;img class=&quot;fragment-image&quot; aria-describedby=&quot;F4-caption&quot; src=&quot;https://advances.sciencemag.org/content/advances/6/11/eaaz0087/F4.medium.gif&quot;/&gt;&lt;/p&gt;
&lt;/noscript&gt;&lt;/span&gt;&lt;/a&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;span class=&quot;fig-label&quot;&gt;Fig. 4&lt;/span&gt; &lt;span class=&quot;caption-title&quot;&gt;Descriptive complexity of trajectories among CAPs and their in-degree accessibility.&lt;/span&gt;
&lt;p id=&quot;p-17&quot; class=&quot;first-child&quot;&gt;(&lt;strong&gt;A&lt;/strong&gt;) Descriptive complexity of trajectories (in bits) between each pair of CAPs in the conscious condition (conscious), propofol-induced unresponsiveness (propofol), ketamine-induced unresponsiveness (ketamine), and in patients with UWS. (&lt;strong&gt;B&lt;/strong&gt;) Significant differences of the descriptive complexity of trajectories for propofol versus conscious, ketamine versus conscious, and patients with UWS versus conscious. The null models were generated by 1000 permutations across the entire dataset. Significance level was determined at &lt;em&gt;P&lt;/em&gt; &amp;lt; 0.001. (&lt;strong&gt;C&lt;/strong&gt;) Schematic illustration for (A). The accessibility of each CAP is defined as the inverse of descriptive complexity. The node size is proportional to in-degree accessibility. The Gephi Force Atlas layout algorithm (&lt;a href=&quot;https://gephi.org&quot;&gt;https://gephi.org&lt;/a&gt;) was used.&lt;/p&gt;

&lt;p id=&quot;p-18&quot;&gt;Furthermore, the transition probability and entropy of Markov trajectory matrices estimated from individual participants showed predictive value in distinguishing conscious versus unresponsive states. We did so by constructing a feature space based on these matrices and subsequently training a classifier of support vector machine (SVM; using sklearn.svm with default settings) by the leave-one-participant-out cross-validation procedure. We found that the SVM classifier achieved reliable performance. The mean classification accuracies for propofol versus conscious, ketamine versus conscious, and patients with UWS versus conscious were, respectively, 0.81 (&lt;em&gt;P&lt;/em&gt; &amp;lt; 0.001, permutation test), 0.83 (&lt;em&gt;P&lt;/em&gt; &amp;lt; 0.001), and 0.93 (&lt;em&gt;P&lt;/em&gt; &amp;lt; 0.001) based on the transition probability matrices and 0.77 (&lt;em&gt;P&lt;/em&gt; &amp;lt; 0.001), 0.75 (&lt;em&gt;P&lt;/em&gt; = 0.028), and 0.88 (&lt;em&gt;P&lt;/em&gt; &amp;lt; 0.001) based on the entropy of Markov trajectory matrices (fig. S7). We considered the above machine learning analyses as exploratory in supporting our major conclusions. Future investigations may be needed such as comparing different machine learning models, parameter optimization, or multiclass classification, which are beyond the scope of the current study.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&quot;sec-5&quot; class=&quot;subsection&quot; readability=&quot;42.760103819058&quot;&gt;
&lt;h3&gt;Antiphasic coactivation accounts for anticorrelation&lt;/h3&gt;
&lt;p id=&quot;p-19&quot;&gt;The reduced occurrence rates of antiphasic coactivation of DMN+ and DAT+ are consistent with the previously reported decreased DMN-DAT anticorrelation in various unresponsive conditions (&lt;a id=&quot;xref-ref-4-2&quot; class=&quot;xref-bibr&quot; href=&quot;https://advances.sciencemag.org/content/6/11/eaaz0087#ref-4&quot;&gt;&lt;em&gt;4&lt;/em&gt;&lt;/a&gt;, &lt;a id=&quot;xref-ref-10-2&quot; class=&quot;xref-bibr&quot; href=&quot;https://advances.sciencemag.org/content/6/11/eaaz0087#ref-10&quot;&gt;&lt;em&gt;10&lt;/em&gt;&lt;/a&gt;–&lt;a id=&quot;xref-ref-12-2&quot; class=&quot;xref-bibr&quot; href=&quot;https://advances.sciencemag.org/content/6/11/eaaz0087#ref-12&quot;&gt;&lt;em&gt;12&lt;/em&gt;&lt;/a&gt;). First, in line with those studies, we observed significantly weakened DMN-DAT anticorrelation (GSR procedure was applied), as well as weakened within-network functional connectivity for both DMN and DAT, during propofol-induced unresponsiveness, ketamine-induced unresponsiveness, and in both MCS and UWS (&lt;a id=&quot;xref-fig-5-1&quot; class=&quot;xref-fig&quot; href=&quot;https://advances.sciencemag.org/content/6/11/eaaz0087#F5&quot;&gt;Fig. 5A&lt;/a&gt; and see fig. S8 for results of other CAPs). We observed a strong negative correlation between the joint occurrence rates of DMN+ and DAT+ and the strength of DMN-DAT functional connectivity (&lt;em&gt;r&lt;/em&gt; = −0.72, &lt;em&gt;P&lt;/em&gt; &amp;lt; 0.0001) across all participants, suggesting that the lower the CAP prevalence in DMN+ and DAT+, the weaker the anticorrelation of DMN-DAT (&lt;a id=&quot;xref-fig-5-2&quot; class=&quot;xref-fig&quot; href=&quot;https://advances.sciencemag.org/content/6/11/eaaz0087#F5&quot;&gt;Fig. 5B&lt;/a&gt;). As expected, positive correlations were seen between the joint occurrence rates of DMN+ and DAT+ and the within-network functional connectivity for both DMN (&lt;em&gt;r&lt;/em&gt; = 0.71, &lt;em&gt;P&lt;/em&gt; &amp;lt; 0.0001) and DAT (&lt;em&gt;r&lt;/em&gt; = 0.65, &lt;em&gt;P&lt;/em&gt; &amp;lt; 0.0001).&lt;/p&gt;
&lt;div class=&quot;figure__head highwire-figure&quot;&gt;
&lt;div class=&quot;fig-inline&quot;&gt;&lt;a href=&quot;https://advances.sciencemag.org/content/advances/6/11/eaaz0087/F5.large.jpg?width=800&amp;amp;height=600&amp;amp;carousel=1&quot; title=&quot;Antiphasic coactivation accounts for anticorrelation. (A) Conventional static functional connectivity between DMN and DAT and within-network connectivity of DMN and DAT in different conditions (conscious, intermediate, unresponsive, and recovered) and in different datasets. Red lines indicate significance at FDR-corrected α &amp;lt; 0.05. Error bars indicate ±SD. (B) Pearson correlations between the joint occurrence rates of DMN+ and DAT+ and the strength of DMN-DAT functional connectivity (FC) (left), as well as within-network functional connectivity of DMN (middle) and DAT (right) across all participants.&quot; class=&quot;fragment-images colorbox-load&quot; rel=&quot;gallery-fragment-images-1307286814&quot; data-figure-caption=&quot;&amp;lt;div class=&amp;quot;highwire-markup&amp;quot;&amp;gt;&amp;lt;span class=&amp;quot;fig-label&amp;quot;&amp;gt;Fig. 5&amp;lt;/span&amp;gt; &amp;lt;span class=&amp;quot;caption-title&amp;quot;&amp;gt;Antiphasic coactivation accounts for anticorrelation.&amp;lt;/span&amp;gt;&amp;lt;p id=&amp;quot;p-20&amp;quot; class=&amp;quot;first-child&amp;quot;&amp;gt;(&amp;lt;strong&amp;gt;A&amp;lt;/strong&amp;gt;) Conventional static functional connectivity between DMN and DAT and within-network connectivity of DMN and DAT in different conditions (conscious, intermediate, unresponsive, and recovered) and in different datasets. Red lines indicate significance at FDR-corrected α &amp;lt; 0.05. Error bars indicate ±SD. (&amp;lt;strong&amp;gt;B&amp;lt;/strong&amp;gt;) Pearson correlations between the joint occurrence rates of DMN+ and DAT+ and the strength of DMN-DAT functional connectivity (FC) (left), as well as within-network functional connectivity of DMN (middle) and DAT (right) across all participants.&amp;lt;/p&amp;gt;&amp;lt;div class=&amp;quot;sb-div caption-clear&amp;quot;/&amp;gt;&amp;lt;/div&amp;gt;&quot; data-icon-position=&quot;&quot; data-hide-link-title=&quot;0&quot;&gt;&lt;span class=&quot;hw-responsive-img&quot;&gt;&lt;img class=&quot;fragment-image lazyload&quot; aria-describedby=&quot;F5-caption&quot; src=&quot;data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7&quot; data-src=&quot;https://advances.sciencemag.org/content/advances/6/11/eaaz0087/F5.medium.gif&quot;/&gt;&lt;noscript&gt;
&lt;p&gt;&lt;img class=&quot;fragment-image&quot; aria-describedby=&quot;F5-caption&quot; src=&quot;https://advances.sciencemag.org/content/advances/6/11/eaaz0087/F5.medium.gif&quot;/&gt;&lt;/p&gt;
&lt;/noscript&gt;&lt;/span&gt;&lt;/a&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;span class=&quot;fig-label&quot;&gt;Fig. 5&lt;/span&gt; &lt;span class=&quot;caption-title&quot;&gt;Antiphasic coactivation accounts for anticorrelation.&lt;/span&gt;
&lt;p id=&quot;p-20&quot; class=&quot;first-child&quot;&gt;(&lt;strong&gt;A&lt;/strong&gt;) Conventional static functional connectivity between DMN and DAT and within-network connectivity of DMN and DAT in different conditions (conscious, intermediate, unresponsive, and recovered) and in different datasets. Red lines indicate significance at FDR-corrected α &amp;lt; 0.05. Error bars indicate ±SD. (&lt;strong&gt;B&lt;/strong&gt;) Pearson correlations between the joint occurrence rates of DMN+ and DAT+ and the strength of DMN-DAT functional connectivity (FC) (left), as well as within-network functional connectivity of DMN (middle) and DAT (right) across all participants.&lt;/p&gt;

&lt;p id=&quot;p-21&quot;&gt;Note that the anticorrelation relationship between DMN and DAT, as measured by conventional static functional connectivity, was only seen when GSR was applied (fig. S8). Given that neither the identification of antiphasic CAPs of DMN+ and DAT+ (Fig. S2) nor the strong association between the occurrence rates of the two CAPs and their anticorrelations relies on the GSR procedure (fig. S9), it is plausible to assume that the anticorrelation structure underlying fMRI signals is not an artifact due to GSR; instead, it is inherent in the data and likely derives from the transient antiphasic CAPs. Therefore, our results may provide a more dynamic (i.e., reflecting transient neural events) and unbiased (i.e., avoiding the controversial methodology of GSR) account for the anticorrelation phenomenon commonly seen in fMRI signals and their associations with levels of consciousness.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&quot;sec-6&quot; class=&quot;subsection&quot; readability=&quot;52.974348932837&quot;&gt;
&lt;h3&gt;Stimulus modulations of CAPs and control analysis in psychiatric patients&lt;/h3&gt;
&lt;p id=&quot;p-22&quot;&gt;Next, we sought to provide additional support for the functional and cognitive relevance of DMN+ and DAT+. Prior work suggests that the DMN is associated with internally focused awareness and can be suppressed when attention is shifted to external stimuli. The suppression of DMN’s activation may be triggered by the activation of other functional networks such as DAT and VAT during top-down allocation of attention and/or detection of unexpected stimuli (&lt;a id=&quot;xref-ref-9-2&quot; class=&quot;xref-bibr&quot; href=&quot;https://advances.sciencemag.org/content/6/11/eaaz0087#ref-9&quot;&gt;&lt;em&gt;9&lt;/em&gt;&lt;/a&gt;). We thus hypothesized that, upon receiving external stimuli, the CAP occurrence rates of DMN+ would be attenuated, while the occurrence rates of other CAPs involved in stimulus processing would be elevated during conscious wakefulness. We also hypothesized that this modulation would be disrupted during reduced levels of responsiveness, which are presumably accompanied by reduced internal and/or external awareness. Accordingly, we investigated the effect of stimulus modulations on the CAP occurrence rates during different levels of responsiveness. We examined a subset of participants in dataset 1 (propofol-SHH) and dataset 4 (neuropathological patients) that received auditory stimuli (e.g., verbal names in propofol-SHH and verbal sentences in neuropathological patients) without any requirement of motor response (&lt;a id=&quot;xref-ref-27-1&quot; class=&quot;xref-bibr&quot; href=&quot;https://advances.sciencemag.org/content/6/11/eaaz0087#ref-27&quot;&gt;&lt;em&gt;27&lt;/em&gt;&lt;/a&gt;, &lt;a id=&quot;xref-ref-28-1&quot; class=&quot;xref-bibr&quot; href=&quot;https://advances.sciencemag.org/content/6/11/eaaz0087#ref-28&quot;&gt;&lt;em&gt;28&lt;/em&gt;&lt;/a&gt;). We assigned each time point of the task dataset to a particular CAP based on its maximal similarity to the CAP centroids derived from the main cohort resting-state data. The purpose of doing this was to make the results comparable and generalizable across datasets. As predicted, auditory stimuli were associated with an attenuation of CAP occurrence rates of DMN+ (as well as VIS+), with an elevated CAP occurrence rate of VAT+ in both datasets only during conscious conditions (&lt;a id=&quot;xref-fig-6-1&quot; class=&quot;xref-fig&quot; href=&quot;https://advances.sciencemag.org/content/6/11/eaaz0087#F6&quot;&gt;Fig. 6, A and B&lt;/a&gt;). The results support that the DMN+ identified in our main cohort could be suppressed when the brain attends to external stimuli, whereas this stimulus modulation was corrupted during unresponsiveness (propofol-induced and patients with UWS).&lt;/p&gt;
&lt;div class=&quot;figure__head highwire-figure&quot;&gt;
&lt;div class=&quot;fig-inline&quot;&gt;&lt;a href=&quot;https://advances.sciencemag.org/content/advances/6/11/eaaz0087/F6.large.jpg?width=800&amp;amp;height=600&amp;amp;carousel=1&quot; title=&quot;Stimulus modulations of CAPs and control analysis in psychiatric patients. (A) Stimulus-induced CAP occurrence rate changes (against stimulus onset, t = 0) in baseline conscious condition, light sedation, and general anesthesia (n = 15). Student’s t tests (against zero) for the CAP occurrence rate changes were performed during the peak period of stimulus-evoked fMRI signal activity (4 to 6 s). Asterisks indicate significance at α &amp;lt; 0.05 after FDR correction. (B) Stimulus-induced CAP occurrence rate changes in healthy controls (n = 12), patients with MCS (n = 4), and patients with UWS (n = 6). (C) Spatial similarity of the eight CAPs between the main cohort and psychiatric cohort data. (D) Comparisons of the CAP occurrence rates for healthy control participants (CONTROL) versus schizophrenic (SCHZ), bipolar disorder (BIPOLAR), and attention deficit/hyperactive disorder (ADHD) patients by Student’s t tests. Red solid lines indicate significant group differences at α &amp;lt; 0.05 after FDR correction, and red dash lines indicate uncorrected significance at P &amp;lt; 0.05. Error bars indicate ±SD.&quot; class=&quot;fragment-images colorbox-load&quot; rel=&quot;gallery-fragment-images-1307286814&quot; data-figure-caption=&quot;&amp;lt;div class=&amp;quot;highwire-markup&amp;quot;&amp;gt;&amp;lt;span class=&amp;quot;fig-label&amp;quot;&amp;gt;Fig. 6&amp;lt;/span&amp;gt; &amp;lt;span class=&amp;quot;caption-title&amp;quot;&amp;gt;Stimulus modulations of CAPs and control analysis in psychiatric patients.&amp;lt;/span&amp;gt;&amp;lt;p id=&amp;quot;p-23&amp;quot; class=&amp;quot;first-child&amp;quot;&amp;gt;(&amp;lt;strong&amp;gt;A&amp;lt;/strong&amp;gt;) Stimulus-induced CAP occurrence rate changes (against stimulus onset, &amp;lt;em&amp;gt;t&amp;lt;/em&amp;gt; = 0) in baseline conscious condition, light sedation, and general anesthesia (&amp;lt;em&amp;gt;n&amp;lt;/em&amp;gt; = 15). Student’s &amp;lt;em&amp;gt;t&amp;lt;/em&amp;gt; tests (against zero) for the CAP occurrence rate changes were performed during the peak period of stimulus-evoked fMRI signal activity (4 to 6 s). Asterisks indicate significance at α &amp;lt; 0.05 after FDR correction. (&amp;lt;strong&amp;gt;B&amp;lt;/strong&amp;gt;) Stimulus-induced CAP occurrence rate changes in healthy controls (&amp;lt;em&amp;gt;n&amp;lt;/em&amp;gt; = 12), patients with MCS (&amp;lt;em&amp;gt;n&amp;lt;/em&amp;gt; = 4), and patients with UWS (&amp;lt;em&amp;gt;n&amp;lt;/em&amp;gt; = 6). (&amp;lt;strong&amp;gt;C&amp;lt;/strong&amp;gt;) Spatial similarity of the eight CAPs between the main cohort and psychiatric cohort data. (&amp;lt;strong&amp;gt;D&amp;lt;/strong&amp;gt;) Comparisons of the CAP occurrence rates for healthy control participants (CONTROL) versus schizophrenic (SCHZ), bipolar disorder (BIPOLAR), and attention deficit/hyperactive disorder (ADHD) patients by Student’s &amp;lt;em&amp;gt;t&amp;lt;/em&amp;gt; tests. Red solid lines indicate significant group differences at α &amp;lt; 0.05 after FDR correction, and red dash lines indicate uncorrected significance at &amp;lt;em&amp;gt;P&amp;lt;/em&amp;gt; &amp;lt; 0.05. Error bars indicate ±SD.&amp;lt;/p&amp;gt;&amp;lt;div class=&amp;quot;sb-div caption-clear&amp;quot;/&amp;gt;&amp;lt;/div&amp;gt;&quot; data-icon-position=&quot;&quot; data-hide-link-title=&quot;0&quot;&gt;&lt;span class=&quot;hw-responsive-img&quot;&gt;&lt;img class=&quot;fragment-image lazyload&quot; aria-describedby=&quot;F6-caption&quot; src=&quot;data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7&quot; data-src=&quot;https://advances.sciencemag.org/content/advances/6/11/eaaz0087/F6.medium.gif&quot;/&gt;&lt;noscript&gt;
&lt;p&gt;&lt;img class=&quot;fragment-image&quot; aria-describedby=&quot;F6-caption&quot; src=&quot;https://advances.sciencemag.org/content/advances/6/11/eaaz0087/F6.medium.gif&quot;/&gt;&lt;/p&gt;
&lt;/noscript&gt;&lt;/span&gt;&lt;/a&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;span class=&quot;fig-label&quot;&gt;Fig. 6&lt;/span&gt; &lt;span class=&quot;caption-title&quot;&gt;Stimulus modulations of CAPs and control analysis in psychiatric patients.&lt;/span&gt;
&lt;p id=&quot;p-23&quot; class=&quot;first-child&quot;&gt;(&lt;strong&gt;A&lt;/strong&gt;) Stimulus-induced CAP occurrence rate changes (against stimulus onset, &lt;em&gt;t&lt;/em&gt; = 0) in baseline conscious condition, light sedation, and general anesthesia (&lt;em&gt;n&lt;/em&gt; = 15). Student’s &lt;em&gt;t&lt;/em&gt; tests (against zero) for the CAP occurrence rate changes were performed during the peak period of stimulus-evoked fMRI signal activity (4 to 6 s). Asterisks indicate significance at α &amp;lt; 0.05 after FDR correction. (&lt;strong&gt;B&lt;/strong&gt;) Stimulus-induced CAP occurrence rate changes in healthy controls (&lt;em&gt;n&lt;/em&gt; = 12), patients with MCS (&lt;em&gt;n&lt;/em&gt; = 4), and patients with UWS (&lt;em&gt;n&lt;/em&gt; = 6). (&lt;strong&gt;C&lt;/strong&gt;) Spatial similarity of the eight CAPs between the main cohort and psychiatric cohort data. (&lt;strong&gt;D&lt;/strong&gt;) Comparisons of the CAP occurrence rates for healthy control participants (CONTROL) versus schizophrenic (SCHZ), bipolar disorder (BIPOLAR), and attention deficit/hyperactive disorder (ADHD) patients by Student’s &lt;em&gt;t&lt;/em&gt; tests. Red solid lines indicate significant group differences at α &amp;lt; 0.05 after FDR correction, and red dash lines indicate uncorrected significance at &lt;em&gt;P&lt;/em&gt; &amp;lt; 0.05. Error bars indicate ±SD.&lt;/p&gt;

&lt;p id=&quot;p-24&quot;&gt;Last, we extended our observations from pharmacological and neuropathological data to an open access dataset from a cohort of patients with psychiatric disease (&lt;a id=&quot;xref-ref-29-1&quot; class=&quot;xref-bibr&quot; href=&quot;https://advances.sciencemag.org/content/6/11/eaaz0087#ref-29&quot;&gt;&lt;em&gt;29&lt;/em&gt;&lt;/a&gt;). We assessed whether the suppression of DMN+ and DAT+ is specific to the reduced level of responsiveness as opposed to disorders of cognitive function in general. Another motivation was to further understand the ketamine-specific alterations in the CAP occurrence rates, as altered states of consciousness induced by ketamine are often associated with psychoactive effects and unique brain dynamics (&lt;a id=&quot;xref-ref-30-1&quot; class=&quot;xref-bibr&quot; href=&quot;https://advances.sciencemag.org/content/6/11/eaaz0087#ref-30&quot;&gt;&lt;em&gt;30&lt;/em&gt;&lt;/a&gt;–&lt;a id=&quot;xref-ref-32-1&quot; class=&quot;xref-bibr&quot; href=&quot;https://advances.sciencemag.org/content/6/11/eaaz0087#ref-32&quot;&gt;&lt;em&gt;32&lt;/em&gt;&lt;/a&gt;). Using the same method applied in the task dataset (i.e., maximal similarity to the predefined CAP centroids from the main cohort), we identified eight comparable CAPs in the psychiatric cohort (&lt;a id=&quot;xref-fig-6-2&quot; class=&quot;xref-fig&quot; href=&quot;https://advances.sciencemag.org/content/6/11/eaaz0087#F6&quot;&gt;Fig. 6C&lt;/a&gt;). There were two main observations. First, we did not find any significant difference between healthy control participants and patients with schizophrenia, bipolar disorder, or attention deficit/hyperactive disorder in the occurrence rates of DMN+ and DAT+. Second, we found that the occurrence rates of GN+ and GN− were both significantly increased in schizophrenic patients, while the occurrence rates of FPN+ and SMN+ were both significantly decreased in patients with bipolar disorder (&lt;a id=&quot;xref-fig-6-3&quot; class=&quot;xref-fig&quot; href=&quot;https://advances.sciencemag.org/content/6/11/eaaz0087#F6&quot;&gt;Fig. 6D&lt;/a&gt;). Patients with attention deficit/hyperactive disorder did not show any significant difference compared to healthy control participants. Therefore, altered occurrence rates of DMN+ and DAT+ are specific to unresponsiveness (likely reflecting unconsciousness in these experimental groups) and do not simply occur as a result of any brain disorder. Furthermore, the results suggest that alterations of the occurrence rates of FPN+, SMN+, GN+, and GN− induced by ketamine are similar to those found in patients with schizophrenia and bipolar disorder.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;div id=&quot;sec-7&quot; readability=&quot;94.384078785392&quot;&gt;
&lt;h2 class=&quot;&quot;&gt;DISCUSSION&lt;/h2&gt;
&lt;p id=&quot;p-25&quot;&gt;The goal of this study was to determine the spatiotemporal dynamics of prevalent functional brain networks in the conscious state and their potential modification during unresponsiveness. Our results revealed both common and distinct characteristics of brain activity in anesthetized participants and neuropathological patients as compared to conscious conditions. The temporal prevalence of two CAPs, DMN+ and DAT+, was suppressed in both propofol- and ketamine-induced unresponsiveness as well as in patients with UWS. The changes specific to various unresponsive conditions included an increased prevalence of antiphasic activation of VIS+ and VAT+ with propofol and an increased prevalence of global network activity with ketamine. Patients with UWS shared the latter two effects. We demonstrate that conscious brain activity is characterized by a set of structured dynamic transition trajectories in which the accessibility of distinct brain states is relatively balanced. In contrast, during unresponsiveness, the trajectories are substantially altered such that the DMN and DAT become isolated, and the trajectories become monopolized by the visual, ventral attention, and global networks.&lt;/p&gt;
&lt;div id=&quot;sec-8&quot; class=&quot;subsection&quot; readability=&quot;52.574175035868&quot;&gt;
&lt;h3&gt;Common spatiotemporal characteristics during behavioral unresponsiveness&lt;/h3&gt;
&lt;p id=&quot;p-26&quot;&gt;A key finding of our study is the suppression of antiphasic activation of DMN+ and DAT+ that occurred in various conditions of behavioral unresponsiveness. Given that this result was obtained with different anesthetic agents with distinct molecular targets and in nonanesthetized neuropathological patients, we are inclined to tentatively conclude that DMN+ and DAT+ are two fundamental signatures of consciousness. Our results provide a dynamic account of the suppression of DMN+ and DAT+ prevalence during unresponsiveness. First, the sequential maintenance of the CAPs (measured by their persistence probabilities) was overall weaker in the unresponsive conditions compared to the conscious condition. This suggests that, during unresponsiveness, the brain states of DMN+ and DAT+ were less stable. Second, during unresponsiveness, the DMN+ and DAT+ were dissociated from the reciprocal relationship of CAPs that were instead monopolized by VIS+, VAT+, GN+, and GN− (e.g., &lt;a id=&quot;xref-fig-3-4&quot; class=&quot;xref-fig&quot; href=&quot;https://advances.sciencemag.org/content/6/11/eaaz0087#F3&quot;&gt;Fig. 3C&lt;/a&gt;). That is, it became difficult, along with the increased complexity of trajectories (less accessible), for the other CAPs to transition to DMN+ or DAT+ (e.g., &lt;a id=&quot;xref-fig-4-3&quot; class=&quot;xref-fig&quot; href=&quot;https://advances.sciencemag.org/content/6/11/eaaz0087#F4&quot;&gt;Fig. 4C&lt;/a&gt;). This finding provides new understanding, in terms of spatiotemporal brain dynamics, of how the previously known anticorrelation of DMN and DAT is diminished in unconsciousness (&lt;a id=&quot;xref-ref-4-3&quot; class=&quot;xref-bibr&quot; href=&quot;https://advances.sciencemag.org/content/6/11/eaaz0087#ref-4&quot;&gt;&lt;em&gt;4&lt;/em&gt;&lt;/a&gt;, &lt;a id=&quot;xref-ref-10-3&quot; class=&quot;xref-bibr&quot; href=&quot;https://advances.sciencemag.org/content/6/11/eaaz0087#ref-10&quot;&gt;&lt;em&gt;10&lt;/em&gt;&lt;/a&gt;–&lt;a id=&quot;xref-ref-12-3&quot; class=&quot;xref-bibr&quot; href=&quot;https://advances.sciencemag.org/content/6/11/eaaz0087#ref-12&quot;&gt;&lt;em&gt;12&lt;/em&gt;&lt;/a&gt;).&lt;/p&gt;
&lt;p id=&quot;p-27&quot;&gt;According to prior evidence from functional neuroimaging of disorders of consciousness (&lt;a id=&quot;xref-ref-4-4&quot; class=&quot;xref-bibr&quot; href=&quot;https://advances.sciencemag.org/content/6/11/eaaz0087#ref-4&quot;&gt;&lt;em&gt;4&lt;/em&gt;&lt;/a&gt;, &lt;a id=&quot;xref-ref-12-4&quot; class=&quot;xref-bibr&quot; href=&quot;https://advances.sciencemag.org/content/6/11/eaaz0087#ref-12&quot;&gt;&lt;em&gt;12&lt;/em&gt;&lt;/a&gt;) and anesthesia (&lt;a id=&quot;xref-ref-10-4&quot; class=&quot;xref-bibr&quot; href=&quot;https://advances.sciencemag.org/content/6/11/eaaz0087#ref-10&quot;&gt;&lt;em&gt;10&lt;/em&gt;&lt;/a&gt;, &lt;a id=&quot;xref-ref-11-2&quot; class=&quot;xref-bibr&quot; href=&quot;https://advances.sciencemag.org/content/6/11/eaaz0087#ref-11&quot;&gt;&lt;em&gt;11&lt;/em&gt;&lt;/a&gt;), an anticorrelated activity of the DMN and DAT is associated with internal versus external awareness (sometimes also referred to as disconnected and connected consciousness, respectively). In addition, a behavioral and neuroimaging experiment in healthy volunteers reported a periodic shift from internal to external awareness associated with the periodic neural activity in the DMN and DAT (&lt;a id=&quot;xref-ref-8-2&quot; class=&quot;xref-bibr&quot; href=&quot;https://advances.sciencemag.org/content/6/11/eaaz0087#ref-8&quot;&gt;&lt;em&gt;8&lt;/em&gt;&lt;/a&gt;). Consequently, in our results, the suppression of both DMN+ and DAT+ may indicate a lack of both forms of awareness (internal and external) during unresponsiveness. The observation that the degree of suppression of the DMN+ and DAT+ was similar across the pharmacological and neuropathological unresponsive conditions suggests that internal and external awareness may be tightly interacting and the give-and-take relationship of the two systems may be particularly important for normal levels of consciousness.&lt;/p&gt;
&lt;p id=&quot;p-28&quot;&gt;This interpretation is further supported by the results of stimulus modulation at different levels of responsiveness. Upon receiving auditory stimuli, the CAP occurrence rate of DMN+ was attenuated, while the occurrence rate of VAT+ (involved in auditory stimulus processing) was elevated only during conscious conditions. This is consistent with our expectation that the DMN+, associated with internal awareness, is suppressed when attention is shifted to external stimuli. The occurrence rate of stimulus-related attenuation of the DMN+ was not found in the unresponsive conditions (propofol-induced and patients with UWS). Although the DAT+ occurrence rate was not increased by the auditory stimulus, this may be expected. The DAT mediates top-down guided voluntary allocation of attention, whereas the VAT is involved in detecting unattended or unexpected stimuli and triggering shifts of attention (&lt;a id=&quot;xref-ref-9-3&quot; class=&quot;xref-bibr&quot; href=&quot;https://advances.sciencemag.org/content/6/11/eaaz0087#ref-9&quot;&gt;&lt;em&gt;9&lt;/em&gt;&lt;/a&gt;). As the stimulus applied in our study did not require voluntary execution, it did not, as would be predicted, activate the DAT+ system.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&quot;sec-9&quot; class=&quot;subsection&quot; readability=&quot;41.416666666667&quot;&gt;
&lt;h3&gt;Distinct spatiotemporal characteristics during behavioral unresponsiveness&lt;/h3&gt;
&lt;p id=&quot;p-29&quot;&gt;In addition to the common effects across unresponsive conditions, we observed some specific changes of CAP prevalence and transition dynamics. During propofol-induced unresponsiveness, VIS+ and VAT+ played a dominant role, where the prevalence of both CAPs was increased compared to the conscious condition. They served as attractors into which other CAPs transformed (e.g., &lt;a id=&quot;xref-fig-3-5&quot; class=&quot;xref-fig&quot; href=&quot;https://advances.sciencemag.org/content/6/11/eaaz0087#F3&quot;&gt;Figs. 3C&lt;/a&gt; and &lt;a id=&quot;xref-fig-4-4&quot; class=&quot;xref-fig&quot; href=&quot;https://advances.sciencemag.org/content/6/11/eaaz0087#F4&quot;&gt;4C&lt;/a&gt;). As the VIS+ and VAT+ are at a relatively low or intermediate level of hierarchical cortical functional organization (&lt;a id=&quot;xref-ref-33-1&quot; class=&quot;xref-bibr&quot; href=&quot;https://advances.sciencemag.org/content/6/11/eaaz0087#ref-33&quot;&gt;&lt;em&gt;33&lt;/em&gt;&lt;/a&gt;), we speculate that propofol may shift the hierarchical cortical functional organization to a lower order. However, the validity of this speculation will require more detailed investigations such as measuring the functional gradient of networks under propofol anesthesia.&lt;/p&gt;
&lt;p id=&quot;p-30&quot;&gt;During ketamine-induced unresponsiveness, GN+ and GN− increased their prevalence and persistence probabilities compared to the conscious condition and served as attractors. The changes were analogous to those of schizophrenic patients (e.g., &lt;a id=&quot;xref-fig-6-4&quot; class=&quot;xref-fig&quot; href=&quot;https://advances.sciencemag.org/content/6/11/eaaz0087#F6&quot;&gt;Fig. 6D&lt;/a&gt;). Prior studies have reported global hyperconnectivity of fMRI signals in schizophrenic patients (&lt;a id=&quot;xref-ref-34-1&quot; class=&quot;xref-bibr&quot; href=&quot;https://advances.sciencemag.org/content/6/11/eaaz0087#ref-34&quot;&gt;&lt;em&gt;34&lt;/em&gt;&lt;/a&gt;), as well as shared phenomenology between schizophrenic symptoms and ketamine’s dissociative/psychoactive effects (&lt;a id=&quot;xref-ref-30-2&quot; class=&quot;xref-bibr&quot; href=&quot;https://advances.sciencemag.org/content/6/11/eaaz0087#ref-30&quot;&gt;&lt;em&gt;30&lt;/em&gt;&lt;/a&gt;, &lt;a id=&quot;xref-ref-32-2&quot; class=&quot;xref-bibr&quot; href=&quot;https://advances.sciencemag.org/content/6/11/eaaz0087#ref-32&quot;&gt;&lt;em&gt;32&lt;/em&gt;&lt;/a&gt;). All participants receiving ketamine reported having dreams, and 8 of 12 participants in our study could recall their hallucinations (e.g., flying on a cloud, weird smells, taking an elevator, and thick mist) after recovery from anesthesia. Therefore, we speculate that the dominance of GN+ and GN− in the dynamic brain states may be associated with psychoactive effects.&lt;/p&gt;
&lt;p id=&quot;p-31&quot;&gt;In patients with UWS, the alterations of brain state dynamics seemed to be situated in between propofol and ketamine anesthesia. If we assume that the arousal of patients with UWS was relatively preserved, unlike the suppression of arousal in propofol-induced unresponsive participants, then the GN+ and GN− in UWS may reflect, to some extent, arousal fluctuations (&lt;a id=&quot;xref-ref-35-1&quot; class=&quot;xref-bibr&quot; href=&quot;https://advances.sciencemag.org/content/6/11/eaaz0087#ref-35&quot;&gt;&lt;em&gt;35&lt;/em&gt;&lt;/a&gt;, &lt;a id=&quot;xref-ref-36-1&quot; class=&quot;xref-bibr&quot; href=&quot;https://advances.sciencemag.org/content/6/11/eaaz0087#ref-36&quot;&gt;&lt;em&gt;36&lt;/em&gt;&lt;/a&gt;).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&quot;sec-10&quot; class=&quot;subsection&quot; readability=&quot;26.746280344558&quot;&gt;
&lt;h3&gt;Spatial characteristics of CAPs&lt;/h3&gt;
&lt;p id=&quot;p-32&quot;&gt;We identified six CAPs encompassing the DMN+, DAT+, FPN+, SMN+, VIS+, and VAT+ that resembled canonical resting-state networks in agreement with previous studies (&lt;a id=&quot;xref-ref-24-2&quot; class=&quot;xref-bibr&quot; href=&quot;https://advances.sciencemag.org/content/6/11/eaaz0087#ref-24&quot;&gt;&lt;em&gt;24&lt;/em&gt;&lt;/a&gt;, &lt;a id=&quot;xref-ref-37-1&quot; class=&quot;xref-bibr&quot; href=&quot;https://advances.sciencemag.org/content/6/11/eaaz0087#ref-37&quot;&gt;&lt;em&gt;37&lt;/em&gt;&lt;/a&gt;, &lt;a id=&quot;xref-ref-38-1&quot; class=&quot;xref-bibr&quot; href=&quot;https://advances.sciencemag.org/content/6/11/eaaz0087#ref-38&quot;&gt;&lt;em&gt;38&lt;/em&gt;&lt;/a&gt;). We also identified two other CAPs with globally activated and deactivated patterns (GN+ and GN−), which have been related to arousal or vigilance fluctuations in the context of the global brain signal (&lt;a id=&quot;xref-ref-35-2&quot; class=&quot;xref-bibr&quot; href=&quot;https://advances.sciencemag.org/content/6/11/eaaz0087#ref-35&quot;&gt;&lt;em&gt;35&lt;/em&gt;&lt;/a&gt;, &lt;a id=&quot;xref-ref-36-2&quot; class=&quot;xref-bibr&quot; href=&quot;https://advances.sciencemag.org/content/6/11/eaaz0087#ref-36&quot;&gt;&lt;em&gt;36&lt;/em&gt;&lt;/a&gt;). GN+ and GN− were present without applying GSR (e.g., fig. S2). Note that, compared to other CAPs, the DMN+ and DAT+ showed the highest within-network anatomical segregation as they consisted of 18 and 14 clusters, respectively, distributed across widespread cortical and subcortical regions (e.g., fig. S3). We speculate that spatial segregation is relevant for the higher-order abstract representations necessary for conscious processing. This is supported by evidence that the DMN and DAT are at a high position of a representational hierarchy, with a widespread backbone, relatively far from the sensory and motor systems in terms of both functional connectivity and anatomical distance (&lt;a id=&quot;xref-ref-33-2&quot; class=&quot;xref-bibr&quot; href=&quot;https://advances.sciencemag.org/content/6/11/eaaz0087#ref-33&quot;&gt;&lt;em&gt;33&lt;/em&gt;&lt;/a&gt;). This hierarchical disposition is thought to allow the two systems to process transmodal information in a way that is unconstrained by immediate sensory input.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&quot;sec-11&quot; class=&quot;subsection&quot; readability=&quot;53.869059165858&quot;&gt;
&lt;h3&gt;Methodologic strengths and limitations&lt;/h3&gt;
&lt;p id=&quot;p-33&quot;&gt;Our approach has unique strengths. First, the &lt;em&gt;k&lt;/em&gt;-means clustering method can capture transient, temporally localized coactivations, which reflect the underlying brain activity in a rather direct way when compared to conventional time-averaged analysis. The clustering procedure itself does not perform any transformation of the data, holds a minimal set of assumptions and constraints, and is free from the controversial aspects of GSR (&lt;a id=&quot;xref-ref-21-2&quot; class=&quot;xref-bibr&quot; href=&quot;https://advances.sciencemag.org/content/6/11/eaaz0087#ref-21&quot;&gt;&lt;em&gt;21&lt;/em&gt;&lt;/a&gt;). The method thus allowed us to reframe the known neural phenomenon—i.e., diminished, temporally averaged DMN-DAT anticorrelation in unresponsiveness—into a dynamic picture of brain activity where the DMN and DAT are embedded in a chain of transient explorations among distinct brain states. Second, the temporal dynamics of brain states were analyzed as a Markov process. This method allowed us to quantify temporal dependencies of brain states and their trajectories, leading us to form the concept of a temporal circuit. Third, we combined an unsupervised machine learning approach (&lt;em&gt;k&lt;/em&gt;-means clustering) with a supervised machine learning approach (i.e., maximal similarity to predefined cluster centroids), when comparing our results from the main cohort with another cohort. This method, with relatively low computational cost, may have the potential for “big data” analysis rendering the observations comparable and generalizable across multiple datasets or research sites. This idea may be analogous to the seed-based (supervised) functional connectivity analysis with a priori knowledge of seed regions.&lt;/p&gt;
&lt;p id=&quot;p-34&quot;&gt;A few limitations of our study are recognized. First, coactivation at the temporal resolution of 2 s is, at best, an indirect measure of large-scale brain connectivity. Second, the neural origin of transient CAPs remains unclear. Third, the richness of mental content and cognitive process seems far beyond the repertoire of CAPs we can detect. The functional association and the causal relationship between CAPs and cognitive functions remain unclear. Fourth, the relationship of CAP transitions to the fast transient topographical patterns of electroencephalography (EEG) (&lt;a id=&quot;xref-ref-39-1&quot; class=&quot;xref-bibr&quot; href=&quot;https://advances.sciencemag.org/content/6/11/eaaz0087#ref-39&quot;&gt;&lt;em&gt;39&lt;/em&gt;&lt;/a&gt;) and magnetoencephalography (&lt;a id=&quot;xref-ref-40-1&quot; class=&quot;xref-bibr&quot; href=&quot;https://advances.sciencemag.org/content/6/11/eaaz0087#ref-40&quot;&gt;&lt;em&gt;40&lt;/em&gt;&lt;/a&gt;), such as “microstates” on the order of 100 ms, remains to be determined. However, recent studies of EEG during anesthetic-induced unresponsiveness have used &lt;em&gt;k&lt;/em&gt;-means clustering and Markov analysis, suggesting that addressing the neurophysiologic time scale with these techniques is tractable (&lt;a id=&quot;xref-ref-41-1&quot; class=&quot;xref-bibr&quot; href=&quot;https://advances.sciencemag.org/content/6/11/eaaz0087#ref-41&quot;&gt;&lt;em&gt;41&lt;/em&gt;&lt;/a&gt;, &lt;a id=&quot;xref-ref-42-1&quot; class=&quot;xref-bibr&quot; href=&quot;https://advances.sciencemag.org/content/6/11/eaaz0087#ref-42&quot;&gt;&lt;em&gt;42&lt;/em&gt;&lt;/a&gt;). Fifth, the choice of &lt;em&gt;k&lt;/em&gt; (the number of CAPs) for clustering analysis was somewhat challenging. Arguably, any reasonable choice would far underestimate the actual diversity of meaningful brain states. The choice of &lt;em&gt;k&lt;/em&gt;, in general, is limited by the experimental approach and fMRI methodology. Sixth, we found that the reduced occurrence rates of DMN+ and DAT+ were accompanied by the decreased trajectory accessibility of the two CAPs during unresponsiveness. This coincidence may be expected. For instance, if other CAPs do not prefer to transition to DMN+ or DAT+, then the occurrence rates of the two CAPs (regardless of its own repetitions or persistence) will be likely lower than that of others. In this sense, the occurrence rates and transition probabilities may offer two views of the same temporal dynamics, whereas the information gained from the two quantities is partially overlapped. Furthermore, if we assume that the transition probabilities between CAPs are caused by certain neural mechanisms, then the occurrence rates are just statistical descriptions resulting from the transition probabilities. The precise neural mechanisms and the regulation of state transitions may be an important question for future investigations. Last, although our observations yield predictions that can guide future work, an important caveat is that the specific characteristics of CAPs in different states of consciousness were derived from rs-fMRI signals without subjective report of mental content. Therefore, the exact associations between those CAPs and conscious contents remain to be systematically studied.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;div id=&quot;sec-13&quot; readability=&quot;212.57911628855&quot;&gt;
&lt;h2 class=&quot;&quot;&gt;MATERIALS AND METHODS&lt;/h2&gt;
&lt;p id=&quot;p-36&quot;&gt;The fMRI data were recorded at two independent research sites (Shanghai and Wisconsin), which generated four datasets containing both control and test results. Dataset 1 included 23 participants during baseline conscious condition, propofol light sedation, and propofol general anesthesia collected in Shanghai, hereafter referred to as propofol-SHH. Dataset 2 included 14 participants during baseline conscious condition, propofol light sedation, propofol deep sedation, and recovery, which was collected in Wisconsin, hereafter referred to as propofol-WI. Dataset 3 included 12 participants during baseline conscious condition, ketamine induction period before loss of responsiveness (PreLOR), loss of responsiveness (LOR) period, and recovery of responsiveness period, hereafter referred to as ketamine. Dataset 4 includes 28 healthy controls (conscious condition), 8 patients diagnosed in an MCS, and 13 patients diagnosed in an UWS/vegetative state. This dataset, with patients of disorders of consciousness, was referred to as neuropathological patients. To minimize misdiagnosis, these states were defined by validated, objective scales as opposed to clinical interpretation alone.&lt;/p&gt;
&lt;div id=&quot;sec-14&quot; class=&quot;subsection&quot; readability=&quot;57.94683776352&quot;&gt;
&lt;h3&gt;Dataset 1: Propofol-SHH&lt;/h3&gt;
&lt;p id=&quot;p-37&quot;&gt;The dataset has been previously published using analyses different from those applied here (&lt;a id=&quot;xref-ref-28-2&quot; class=&quot;xref-bibr&quot; href=&quot;https://advances.sciencemag.org/content/6/11/eaaz0087#ref-28&quot;&gt;&lt;em&gt;28&lt;/em&gt;&lt;/a&gt;, &lt;a id=&quot;xref-ref-43-1&quot; class=&quot;xref-bibr&quot; href=&quot;https://advances.sciencemag.org/content/6/11/eaaz0087#ref-43&quot;&gt;&lt;em&gt;43&lt;/em&gt;&lt;/a&gt;). The study was approved by the Institutional Review Board (IRB) of Huashan Hospital, Fudan University. Informed consent was obtained from all participants (&lt;em&gt;n&lt;/em&gt; = 26; right-handed; male/female, 12/14; age, 27 to 64 years), who were undergoing an elective transsphenoidal approach for pituitary microadenoma resection. The pituitary microadenomas were diagnosed by their size (&amp;lt;10 mm in diameter without growing out of the sella) based on radiological examinations and plasma endocrinal parameters. The participants were American Society of Anesthesiologists (ASA) physical status I or II, with no history of brain dysfunction, vital organ dysfunction, or administration of neuropsychiatric drugs. They had no contraindication to an MRI examination, such as vascular clips or metallic implants. Among them, 3 participants had to be excluded from the study and further data analysis because of excessive movements, resulting in 23 participants for the following analysis.&lt;/p&gt;
&lt;p id=&quot;p-38&quot;&gt;Participants fasted for at least 8 hours from solid foods and 2 hours from liquids before the study. Vital signs including blood pressure, electrocardiography, pulse oximetry (SpO&lt;sub&gt;2&lt;/sub&gt;), and partial pressure of carbon dioxide were continuously monitored during the fMRI study. The participants received propofol light sedation (17 of 23) and general anesthesia (&lt;em&gt;n&lt;/em&gt; = 23), during which intravenous anesthetic propofol was infused through an intravenous catheter placed into a vein of the right hand or forearm. Propofol was administered using a target-controlled infusion (TCI) pump to obtain constant effect-site concentration, as estimated by the pharmacokinetic model of propofol (Marsh model). Remifentanil (1.0 μg/kg) and succinylcholine (1.5 mg/kg) were administered to facilitate endotracheal intubation under general anesthesia. TCI concentrations were increased in 0.1 μg/ml steps beginning at 1.0 μg/ml until reaching the appropriate effect-site concentration. A 5-min equilibration period was allowed to ensure equilibration of propofol distribution between compartments.&lt;/p&gt;
&lt;p id=&quot;p-39&quot;&gt;The TCI propofol was maintained at a stable effect-site concentration for light sedation (1.3 μg/ml) and for general anesthesia (4.0 μg/ml). Behavioral responsiveness was assessed by the Ramsay scale. The participants were asked to strongly squeeze the hand of the investigator. The participant was considered fully conscious if the response to verbal command (“strongly squeeze my hand!”) was clear and strong (Ramsay 1 and 2), in mild sedation if the response to verbal command was clear but slow (Ramsay 3 and 4), and in deep sedation or general anesthesia if there was no response to verbal command (Ramsay 5 and 6). For each assessment, the Ramsay scale verbal commands were repeated twice. The participants continued to breathe spontaneously, with supplemental oxygen via nasal cannula, during conscious resting state and light sedation. During general anesthesia, the participants were ventilated with intermittent positive pressure ventilation, setting a tidal volume at 8 to 10 ml/kg, a respiratory rate of 10 to 12 beats/min, and maintaining partial pressure of end tidal CO&lt;sub&gt;2&lt;/sub&gt; at 35 to 45 mmHg. Two certified anesthesiologists were present throughout the study and assured that resuscitation equipment was always available. Participants wore earplugs and headphones during the fMRI scanning.&lt;/p&gt;
&lt;p id=&quot;p-40&quot;&gt;rs-fMRI data acquisition consisted of three 8-min scans in baseline conscious condition, light sedation, and general anesthesia. The participant’s head was fixed in the scan frame and padded with spongy cushions to minimize head movement. The participants were asked to relax and assume a comfortable supine position with their eyes closed during scanning (an eye patch was applied). They were instructed not to concentrate on anything in particular during the resting-state scan. A Siemens 3T scanner (Siemens MAGNETOM, Germany) with a standard eight-channel head coil was used to acquire gradient-echo echo-planar imaging (EPI) images of the whole brain [33 slices; repetition time/echo time (TR/TE), 2000/30 ms; slice thickness, 5 mm; field of view, 210 mm; flip angle, 90°; image matrix, 64 × 64]. High-resolution anatomical images were also acquired for rs-fMRI coregistration.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&quot;sec-15&quot; class=&quot;subsection&quot; readability=&quot;40.964145168343&quot;&gt;
&lt;h3&gt;Dataset 2: Propofol-WI&lt;/h3&gt;
&lt;p id=&quot;p-41&quot;&gt;The dataset has been previously published using analyses different from those applied here (&lt;a id=&quot;xref-ref-44-1&quot; class=&quot;xref-bibr&quot; href=&quot;https://advances.sciencemag.org/content/6/11/eaaz0087#ref-44&quot;&gt;&lt;em&gt;44&lt;/em&gt;&lt;/a&gt;). The IRB of Medical College of Wisconsin (MCW) approved the experimental protocol. Fifteen healthy participants (male/female, 9/6; age, 19 to 35 years) received propofol sedation. The OAAS (observer’s assessment of alertness/sedation) was applied to measure the levels of behavioral responsiveness. During baseline conscious and recovery conditions, participants responded readily to verbal commands (OAAS score, 5). During light sedation, participants showed lethargic response to verbal commands (OAAS score, 4). During deep sedation, participants showed no response to verbal commands (OAAS score, 2 and 1). The corresponding target plasma concentrations vary across participants (light sedation, 0.98 ± 0.18 μg/ml; deep sedation, 1.88 ± 0.24 μg/ml) because of the variability in individual sensitivity to anesthetics. At each level of sedation, the plasma concentration of propofol was maintained at equilibrium by continuously adjusting the infusion rate to maintain the balance between accumulation and elimination of the drug. The infusion rate was manually controlled and guided by the output of a computer simulation developed for target-controlled drug infusion (STANPUMP) based on the pharmacokinetic model of propofol. Standard ASA monitoring was conducted during the experiment, including electrocardiogram, noninvasive blood pressure cuff, pulse oximetry, and end-tidal carbon dioxide gas monitoring. Supplemental oxygen was administered prophylactically via nasal cannula. One participant had to be excluded from the study and further data analysis because of excessive movements, resulting in 14 participants for the following analysis.&lt;/p&gt;
&lt;p id=&quot;p-42&quot;&gt;rs-fMRI data acquisition consisted of four 15-min scans in baseline conscious condition, light and deep sedation, and recovery. A 3T Signa GE 750 scanner (GE Healthcare, Waukesha, WI, USA) with a standard 32-channel transmit/receive head coil was used to acquire gradient-echo EPI images of the whole brain (41 slices; TR/TE, 2000/25 ms; slice thickness, 3.5 mm; field of view, 224 mm; flip angle, 77°; image matrix, 64 × 64). High-resolution anatomical images were also acquired for rs-fMRI coregistration.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&quot;sec-16&quot; class=&quot;subsection&quot; readability=&quot;44&quot;&gt;
&lt;h3&gt;Dataset 3: Ketamine&lt;/h3&gt;
&lt;p id=&quot;p-43&quot;&gt;The study was approved by the IRB of Huashan Hospital, Fudan University. Informed consent was obtained from all participants. Twelve right-handed participants were recruited (male/female, 7/5; age, 32 to 66 years), who were undergoing an elective transsphenoidal approach for resection of a pituitary microadenoma. The patient inclusion, anesthesia procedure, fMRI setting-up and scanning parameters, and vital sign monitoring were the same as those of propofol-SHH.&lt;/p&gt;
&lt;p id=&quot;p-44&quot;&gt;Ketamine was infused through an intravenous catheter placed into a vein of the left forearm. Continues fMRI scanning was conducted throughout the whole experiment for about 1 hour, ranging from 44 to 62 min (means ± SD, 54.6 ± 5.9 min). A 10-min baseline conscious condition was first acquired (except for two participants in which baseline condition was for 6 and 11 min). Then, 0.05 mg/kg per min of ketamine was infused for 10 min (0.5 mg/kg in total), and 0.1 mg/kg per min was infused for another 10 min (1.0 mg/kg in total), except for two participants who only received 0.1 mg/kg per min infusion for 10 min. After that, the ketamine infusion was discontinued, and participants regained their responsiveness spontaneously.&lt;/p&gt;
&lt;p id=&quot;p-45&quot;&gt;Behavioral responsiveness (button press) was assessed throughout the entire fMRI scan. Specifically, participants were asked to press a button using their right index finger after hearing a verbal instruction “press the button.” The instruction was programmed to play every 30 s using E-Prime 2.0 (Psychology Software Tools, Pittsburgh, PA) and was delivered via earphones designed for an MRI environment. The volume of the headphones was adjusted for participant comfort. By comparing the timing of verbal instruction and actual responsiveness during and after ketamine infusion, the periods during which a participant retained responsiveness (PreLOR), LOR, and recovery of responsiveness were determined. The duration (means ± SD in minutes) for each period across participants was 9.8 ± 1.0 for baseline conscious condition, 12.5 ± 4.5 for PreLOR, 18.2 ± 7.6 for LOR, and 14.1 ± 6.0 for recovery. In addition, reaction time with respect to each instruction was recoded for quantitative analysis of behavioral responsiveness.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&quot;sec-17&quot; class=&quot;subsection&quot; readability=&quot;26.864207879296&quot;&gt;
&lt;h3&gt;Dataset 4: Neuropathological patients&lt;/h3&gt;
&lt;p id=&quot;p-46&quot;&gt;The dataset has been previously published using analyses different from those applied here (&lt;a id=&quot;xref-ref-27-2&quot; class=&quot;xref-bibr&quot; href=&quot;https://advances.sciencemag.org/content/6/11/eaaz0087#ref-27&quot;&gt;&lt;em&gt;27&lt;/em&gt;&lt;/a&gt;, &lt;a id=&quot;xref-ref-43-2&quot; class=&quot;xref-bibr&quot; href=&quot;https://advances.sciencemag.org/content/6/11/eaaz0087#ref-43&quot;&gt;&lt;em&gt;43&lt;/em&gt;&lt;/a&gt;). The study was approved by the IRB of Huashan Hospital, Fudan University. Informed consent was obtained from the patients’ legal representatives and from the healthy participants. The dataset included 21 patients (male/female, 18/3) with disorders of consciousness and 28 healthy control participants (male/female, 14/14). The patients were assessed using the Coma Recovery Scale–Revised (&lt;a id=&quot;xref-ref-45-1&quot; class=&quot;xref-bibr&quot; href=&quot;https://advances.sciencemag.org/content/6/11/eaaz0087#ref-45&quot;&gt;&lt;em&gt;45&lt;/em&gt;&lt;/a&gt;) on the day of fMRI scanning. Of those assessed, 13 patients were diagnosed as having UWS, and 8 patients were diagnosed as being in MCS. None of the healthy controls had a history of neurological or psychiatric disorders nor were they taking any kind of medication.&lt;/p&gt;
&lt;p id=&quot;p-47&quot;&gt;rs-fMRI data were acquired on a Siemens 3T scanner (Siemens MAGNETOM, Germany). A standard eight-channel head coil was used to acquire gradient-echo EPI images of the whole brain (33 slices; TR/TE, 2000/35 ms; slice thickness, 4 mm; field of view, 256 mm; flip angle, 90°; image matrix, 64 × 64). Two hundred EPI volumes (6 min and 40 s) and high-resolution anatomical images were acquired.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&quot;sec-18&quot; class=&quot;subsection&quot; readability=&quot;21.666492420282&quot;&gt;
&lt;h3&gt;Data preprocessing&lt;/h3&gt;
&lt;p id=&quot;p-48&quot;&gt;Preprocessing steps were implemented in AFNI (Analysis of Functional NeuroImages; &lt;a href=&quot;http://afni.nimh.nih.gov/&quot;&gt;http://afni.nimh.nih.gov/&lt;/a&gt;). (i) The first two frames of each fMRI run were discarded; (ii) slice timing correction; (iii) rigid head motion correction/realignment within and across runs; frame-wise displacement (FD) of head motion was calculated using frame-wise Euclidean norm (square root of the sum squares) of the six-dimensional motion derivatives (&lt;a id=&quot;xref-ref-46-1&quot; class=&quot;xref-bibr&quot; href=&quot;https://advances.sciencemag.org/content/6/11/eaaz0087#ref-46&quot;&gt;&lt;em&gt;46&lt;/em&gt;&lt;/a&gt;). A frame and its each previous frame were tagged as zeros (ones, otherwise) if the given frame’s derivative value has a Euclidean norm above 0.4 mm of FD (&lt;a id=&quot;xref-ref-44-2&quot; class=&quot;xref-bibr&quot; href=&quot;https://advances.sciencemag.org/content/6/11/eaaz0087#ref-44&quot;&gt;&lt;em&gt;44&lt;/em&gt;&lt;/a&gt;); (iv) coregistration with high-resolution anatomical images; (v) spatial normalization into Talairach stereotactic space; (vi) using AFNI’s function 3dTproject, the time-censored data were high-pass filtered above 0.008 Hz. At the same time, various undesired components (e.g., physiological estimates and motion parameters) were removed via linear regression. The undesired components included linear and nonlinear drift, time series of head motion and its temporal derivative, binarized FD time series (output data included zero values at censored time points), and mean time series from the white matter and cerebrospinal fluid; (vii) spatial smoothing with 6-mm full width at half maximum isotropic Gaussian kernel; (viii) the time course per voxel of each run was normalized to zero mean and unit variance, accounting for differences in variance of non-neural origin (e.g., distance from head coil). GSR was not applied for our main analysis, as we were motivated to provide a dynamic and unbiased account for the anticorrelation phenomenon commonly seen in conventional static functional connectivity with GSR procedure. However, to evaluate the robustness of our results against different processing schemes, we also performed control analyses both with and without the GSR procedure.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&quot;sec-19&quot; class=&quot;subsection&quot; readability=&quot;62.84140969163&quot;&gt;
&lt;h3&gt;CAP analysis&lt;/h3&gt;
&lt;p id=&quot;p-49&quot;&gt;We adopted an unsupervised machine learning approach using &lt;em&gt;k&lt;/em&gt;-means clustering algorithm. It is a procedure for classifying a set of objects (e.g., fMRI volumes) into different categories (e.g., patterns) such that within category differences are smaller than across category differences. Accordingly, we classified fMRI volumes into &lt;em&gt;k&lt;/em&gt; clusters based on their spatial similarity and thus produced a set of CAPs or brain states (&lt;a id=&quot;xref-ref-22-1&quot; class=&quot;xref-bibr&quot; href=&quot;https://advances.sciencemag.org/content/6/11/eaaz0087#ref-22&quot;&gt;&lt;em&gt;22&lt;/em&gt;&lt;/a&gt;, &lt;a id=&quot;xref-ref-24-3&quot; class=&quot;xref-bibr&quot; href=&quot;https://advances.sciencemag.org/content/6/11/eaaz0087#ref-24&quot;&gt;&lt;em&gt;24&lt;/em&gt;&lt;/a&gt;). Hence, the original fMRI (&lt;sub&gt;three&lt;/sub&gt;-dimensional + time) data were translated into a one-dimensional time series of discrete CAP labels.&lt;/p&gt;
&lt;p id=&quot;p-50&quot;&gt;The above analysis was performed on the concatenated data of 69,010 fMRI volumes acquired from all 98 participants. There were 7.1% of the total volumes tagged as zeros based on the above motion censoring procedure, which were not included in the following analysis. Then, &lt;em&gt;k&lt;/em&gt;-means clustering was performed to partition the all fMRI volumes of the matrix (64,118 volumes × 6088 voxels) into &lt;em&gt;k&lt;/em&gt; clusters, which returned a 64,118 × 1 vector containing cluster indices (i.e., CAP labels) for each fMRI volume. The distance between two fMRI volumes was defined as one minus their Pearson’s correlation coefficient of the intensity values across voxels (&lt;a id=&quot;xref-ref-22-2&quot; class=&quot;xref-bibr&quot; href=&quot;https://advances.sciencemag.org/content/6/11/eaaz0087#ref-22&quot;&gt;&lt;em&gt;22&lt;/em&gt;&lt;/a&gt;, &lt;a id=&quot;xref-ref-24-4&quot; class=&quot;xref-bibr&quot; href=&quot;https://advances.sciencemag.org/content/6/11/eaaz0087#ref-24&quot;&gt;&lt;em&gt;24&lt;/em&gt;&lt;/a&gt;). The computational load of the &lt;em&gt;k&lt;/em&gt;-means clustering increases quickly with the number of fMRI volumes. As a trade-off between computational cost and spatial resolution, the preprocessed fMRI data were down-sampled to the spatial resolution of 6 mm by 6 mm by 6 mm while preserving the original temporal resolution (2 s) before &lt;em&gt;k&lt;/em&gt;-means clustering.&lt;/p&gt;
&lt;p id=&quot;p-51&quot;&gt;After clustering, the fMRI volumes assigned to the same cluster were simply averaged, resulting in &lt;em&gt;k&lt;/em&gt; maps that we defined as CAPs. These CAPs were then normalized by the SE (within cluster and across fMRI volumes) to generate &lt;em&gt;z&lt;/em&gt;-statistic maps, which quantify the degree of significance to which the CAP map values (for each voxel) deviate from zero (&lt;a id=&quot;xref-ref-22-3&quot; class=&quot;xref-bibr&quot; href=&quot;https://advances.sciencemag.org/content/6/11/eaaz0087#ref-22&quot;&gt;&lt;em&gt;22&lt;/em&gt;&lt;/a&gt;). The spatial characteristics of those CAPs were examined by counting the number of spatial clusters as a function of threshold (&lt;em&gt;z&lt;/em&gt; values; ranging from 1 to 100). A single spatial cluster was defined as the nearest-neighbor clustering (faces touching) encompassing at least six voxels, where positive and negative voxels in each CAP were calculated separately. In addition, we calculated the instantaneous phase synchrony for each CAP. For each voxel’s time series, the instantaneous phase traces were calculated using Hilbert transform. The phase synchrony across voxels as a function of time was quantified by the Kuramoto order parameter. Then, the phase synchrony values were sorted into &lt;em&gt;k&lt;/em&gt; bins according to the time series of CAP labels. The phase synchrony values within each bin were averaged yielding the mean phase synchrony for each CAP.&lt;/p&gt;
&lt;p id=&quot;p-52&quot;&gt;For each participant or each condition, the occurrence rate of each CAP was quantified by the ratio of the number of volumes that appeared versus the total number of volumes per scan. A challenge for clustering analysis is the choice of &lt;em&gt;k&lt;/em&gt;, i.e., the number of CAPs to be extracted from the data. We evaluated the clustering performance using a few indices including Silhouette, Calinski-Harabasz, Davies-Bouldin, and Dunn for the data with and without GSR (fig. S1). Broadly speaking, higher values of the Silhouette, Calinski-Harabasz, and Dunn and a lower value of the Davies-Bouldin indicate a better separation of clusters and more tightness inside the clusters. In line with a previous study by Liu &lt;em&gt;et al.&lt;/em&gt; (&lt;a id=&quot;xref-ref-22-4&quot; class=&quot;xref-bibr&quot; href=&quot;https://advances.sciencemag.org/content/6/11/eaaz0087#ref-22&quot;&gt;&lt;em&gt;22&lt;/em&gt;&lt;/a&gt;), who used the dataset from the 1000 Functional Connectomes Project, we also observed that different clustering evaluation criteria yielded inconsistent recommendations. We next sought to adopt an alternative strategy by identifying a &lt;em&gt;k&lt;/em&gt; with the best reliability of consistently identifying conscious conditions across datasets and the best distinction of conscious versus unresponsive conditions. Specifically, we determined an optimized &lt;em&gt;k&lt;/em&gt; (from a search between 2 and 30) by trading off the interdataset similarity (measured by Euclidean distance) of the averaged CAP occurrence rate distributions in each dataset. We derived an index, (CC + UU)/(2 × CU), as the ratio of interdataset similarity among conscious conditions (CC) and among unresponsive conditions (UU) versus the interdataset similarity among conscious and unresponsive conditions (CU) across the four datasets. We found that &lt;em&gt;k&lt;/em&gt; = 8 (non-GSR) yielded a high interdataset similarity among conscious conditions and among unresponsive conditions, with a low interdataset similarity among conscious and unresponsive conditions. In addition, to further evaluate the choice of &lt;em&gt;k&lt;/em&gt;, we inspected the spatial patterns in terms of consistency and redundancy from &lt;em&gt;k&lt;/em&gt; = 2 to &lt;em&gt;k&lt;/em&gt; = 16 with a step of two (fig. S2).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&quot;sec-20&quot; class=&quot;subsection&quot; readability=&quot;18.975324675325&quot;&gt;
&lt;h3&gt;Transition matrix&lt;/h3&gt;
&lt;p id=&quot;p-53&quot;&gt;For each condition, we concatenated all participants’ CAP time series and computed the transition probability between each pair of CAPs. These transition probability matrices can be described by a Markov process, where the probability of CAP &lt;em&gt;j&lt;/em&gt; (at time &lt;em&gt;t&lt;/em&gt; + 1) is determined by the CAP &lt;em&gt;i&lt;/em&gt; (at time &lt;em&gt;t&lt;/em&gt;). That is, we defined transition probability between two CAPs to be the probability of transitioning from state CAP &lt;em&gt;i&lt;/em&gt; to CAP &lt;em&gt;j&lt;/em&gt;, given that the current state is CAP &lt;em&gt;i&lt;/em&gt;. Those probabilities was encoded in a transition matrix with row sums equal to 1 and the &lt;em&gt;ij&lt;/em&gt;th elements of the matrix equal to the number of transitions from CAP &lt;em&gt;i&lt;/em&gt; to CAP &lt;em&gt;j&lt;/em&gt; divided by the number of occurrences of CAP &lt;em&gt;i&lt;/em&gt;. We referred to the diagonal entries in the full transition probability matrix as the persistence probabilities, i.e., the probability of remaining in a given CAP. We referred to the off-diagonal transition probability matrix as the transition probabilities, i.e., the probability of transitioning between two distinct CAPs. The off-diagonal transition probability matrix was calculated by removing repeating CAPs in the time series to control for autocorrelation due to the CAP’s persistence (&lt;a id=&quot;xref-ref-24-5&quot; class=&quot;xref-bibr&quot; href=&quot;https://advances.sciencemag.org/content/6/11/eaaz0087#ref-24&quot;&gt;&lt;em&gt;24&lt;/em&gt;&lt;/a&gt;). Note that the censored time point of head motion and the joint point between participants were tagged with zeros, such that the transition from a CAP to zero or from zero to a CAP was discarded in the above calculation. This may minimize the head motion effect and avoid the contamination of noncontinued data derived from concatenation.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&quot;sec-21&quot; class=&quot;subsection&quot; readability=&quot;22.186740331492&quot;&gt;
&lt;h3&gt;Entropy of Markov trajectories&lt;/h3&gt;
&lt;p id=&quot;p-54&quot;&gt;On the basis of the above off-diagonal transition probability matrices, we quantified the entropy of Markov trajectories (&lt;a id=&quot;xref-ref-25-2&quot; class=&quot;xref-bibr&quot; href=&quot;https://advances.sciencemag.org/content/6/11/eaaz0087#ref-25&quot;&gt;&lt;em&gt;25&lt;/em&gt;&lt;/a&gt;, &lt;a id=&quot;xref-ref-26-2&quot; class=&quot;xref-bibr&quot; href=&quot;https://advances.sciencemag.org/content/6/11/eaaz0087#ref-26&quot;&gt;&lt;em&gt;26&lt;/em&gt;&lt;/a&gt;). This approach measured the descriptive complexity of trajectories (in bits) between each pair of CAPs, e.g., routes starting from a particular CAP and ending to another. A lower descriptive complexity from a starting point (initial CAP) to its destination (final CAP) indicates a higher accessibility for the destination. More specifically, the entropy of Markovian trajectories is considered as a finite irreducible Markovian chain with transition matrix &lt;em&gt;P&lt;/em&gt; and associated entropy rate &lt;em&gt;H&lt;/em&gt;(&lt;em&gt;X&lt;/em&gt;) = −∑&lt;em&gt;&lt;sub&gt;i,j&lt;/sub&gt;&lt;/em&gt; μ&lt;em&gt;&lt;sub&gt;i&lt;/sub&gt; P&lt;sub&gt;ij&lt;/sub&gt;&lt;/em&gt; log &lt;em&gt;P&lt;sub&gt;ij&lt;/sub&gt;&lt;/em&gt;, where μ is the stationary distribution given by the solution of μ = μ&lt;em&gt;P&lt;/em&gt;. A trajectory &lt;em&gt;T&lt;sub&gt;ij&lt;/sub&gt;&lt;/em&gt; of the Markov chain is a path with initial state &lt;em&gt;i&lt;/em&gt;, final state &lt;em&gt;j&lt;/em&gt;, and no intervening states equal to &lt;em&gt;j&lt;/em&gt;. The entropy &lt;em&gt;H&lt;/em&gt;(&lt;em&gt;T&lt;sub&gt;ii&lt;/sub&gt;&lt;/em&gt;) of the random trajectory originating and terminating in state &lt;em&gt;i&lt;/em&gt; is given by &lt;em&gt;H&lt;/em&gt;(&lt;em&gt;T&lt;sub&gt;ii&lt;/sub&gt;&lt;/em&gt;) = &lt;em&gt;H&lt;/em&gt;(&lt;em&gt;X&lt;/em&gt;)/μ&lt;em&gt;&lt;sub&gt;i&lt;/sub&gt;&lt;/em&gt;. Therefore, the entropy of the random trajectory &lt;em&gt;T&lt;sub&gt;ii&lt;/sub&gt;&lt;/em&gt; is the product of the expected number of steps 1/μ&lt;em&gt;&lt;sub&gt;i&lt;/sub&gt;&lt;/em&gt; to return to state &lt;em&gt;i&lt;/em&gt; and the entropy rate &lt;em&gt;H&lt;/em&gt;(&lt;em&gt;X&lt;/em&gt;) per step for the stationary Markov chain. The entropies &lt;em&gt;H&lt;/em&gt;(&lt;em&gt;T&lt;sub&gt;ij&lt;/sub&gt;&lt;/em&gt;) is given by &lt;em&gt;H&lt;/em&gt; = &lt;em&gt;K&lt;/em&gt; − &lt;em&gt;K&lt;/em&gt;′ + &lt;em&gt;H&lt;/em&gt;&lt;sub&gt;Δ&lt;/sub&gt;, where &lt;em&gt;H&lt;/em&gt; is the matrix of trajectory entropies &lt;em&gt;H&lt;sub&gt;ij&lt;/sub&gt;&lt;/em&gt; = &lt;em&gt;H&lt;/em&gt;(&lt;em&gt;T&lt;sub&gt;ij&lt;/sub&gt;&lt;/em&gt;); &lt;em&gt;K&lt;/em&gt; = (&lt;em&gt;I&lt;/em&gt; − &lt;em&gt;P&lt;/em&gt; + &lt;em&gt;A)&lt;sup&gt;−1&lt;/sup&gt;&lt;/em&gt; (&lt;em&gt;H&lt;/em&gt;* − &lt;em&gt;H&lt;/em&gt;&lt;sub&gt;Δ&lt;/sub&gt;); &lt;em&gt;K&lt;/em&gt;′ is a matrix in which the &lt;em&gt;ij&lt;/em&gt;th element &lt;em&gt;K&lt;sub&gt;ij&lt;/sub&gt;&lt;/em&gt;′ equals the diagonal element &lt;em&gt;K&lt;sub&gt;ij&lt;/sub&gt;&lt;/em&gt; of &lt;em&gt;K&lt;/em&gt;; &lt;em&gt;A&lt;/em&gt; is the matrix of stationary probabilities with entries &lt;em&gt;A&lt;sub&gt;ij&lt;/sub&gt;&lt;/em&gt; = μ&lt;em&gt;&lt;sub&gt;j&lt;/sub&gt;&lt;/em&gt;; &lt;em&gt;H&lt;/em&gt;* is the matrix of single-step entropies with entries &lt;em&gt;H&lt;sub&gt;ij&lt;/sub&gt;&lt;/em&gt;* = &lt;em&gt;H&lt;/em&gt;(&lt;em&gt;P&lt;sub&gt;i&lt;/sub&gt;&lt;/em&gt;) = −∑&lt;em&gt;&lt;sub&gt;k&lt;/sub&gt; P&lt;sub&gt;ik&lt;/sub&gt;&lt;/em&gt; log &lt;em&gt;P&lt;sub&gt;ik&lt;/sub&gt;&lt;/em&gt;; and &lt;em&gt;H&lt;/em&gt;&lt;sub&gt;Δ&lt;/sub&gt; is a diagonal matrix with entries (&lt;em&gt;H&lt;/em&gt;&lt;sub&gt;Δ&lt;/sub&gt;)&lt;em&gt;&lt;sub&gt;ii&lt;/sub&gt;&lt;/em&gt; = &lt;em&gt;H&lt;/em&gt;(&lt;em&gt;X&lt;/em&gt;)/μ&lt;em&gt;&lt;sub&gt;i&lt;/sub&gt;&lt;/em&gt;. For further details, see the seminar work by Ekroot and Cover (&lt;a id=&quot;xref-ref-25-3&quot; class=&quot;xref-bibr&quot; href=&quot;https://advances.sciencemag.org/content/6/11/eaaz0087#ref-25&quot;&gt;&lt;em&gt;25&lt;/em&gt;&lt;/a&gt;), and the MATLAB code is available at &lt;a href=&quot;https://github.com/stdimitr/Entropy_of_Markov_Trajectories&quot;&gt;https://github.com/stdimitr/Entropy_of_Markov_Trajectories&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&quot;sec-22&quot; class=&quot;subsection&quot; readability=&quot;15&quot;&gt;
&lt;h3&gt;Conventional static functional connectivity analysis&lt;/h3&gt;
&lt;p id=&quot;p-55&quot;&gt;We defined functional networks based on the identified CAPs. As a CAP may include antiphasic coactivations (e.g., voxels with positive or negative values), presumably representing two anticorrelation networks, we thus only extracted the positive voxels within each CAP and binarized them to form a mask of a given network. Within-network connectivity was defined as the averaged Pearson correlation coefficients (Fisher’s &lt;em&gt;z&lt;/em&gt;-transformed) between all pairs of voxels within the network, and between-network connectivity was calculated by averaging the Pearson correlation coefficient between all pairs of voxels from different networks (i.e., excluding within-network voxel pairs). Both measurements were calculated for data with and without GSR procedure.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&quot;sec-23&quot; class=&quot;subsection&quot; readability=&quot;23.950844854071&quot;&gt;
&lt;h3&gt;Stimulus modulation&lt;/h3&gt;
&lt;p id=&quot;p-56&quot;&gt;A subset of participants in propofol-SHH (&lt;em&gt;n&lt;/em&gt; = 15) and neuropathological patients (&lt;em&gt;n&lt;/em&gt; = 22; 12 healthy controls, 4 MCS, and 6 UWS) received auditory stimuli. For propofol-SHH, an event-related design was adopted with 60 names delivered in a pseudorandom order [see more details in (&lt;a id=&quot;xref-ref-28-3&quot; class=&quot;xref-bibr&quot; href=&quot;https://advances.sciencemag.org/content/6/11/eaaz0087#ref-28&quot;&gt;&lt;em&gt;28&lt;/em&gt;&lt;/a&gt;)]. Each audio clip (0.5 s) was followed by intertrial intervals (ITIs) ranging unpredictably from 15.5 to 25.5 s (2-s step). The participants were required to pay attention and passively listen to the names without behavioral response or judgment. Three 18-min fMRI scans were acquired for each level of responsiveness (baseline conscious condition, light sedation, and general anesthesia). For neuropathological patients, an event-related design was applied with 160 sentences delivered in a pseudorandom order [see more details in (&lt;a id=&quot;xref-ref-27-3&quot; class=&quot;xref-bibr&quot; href=&quot;https://advances.sciencemag.org/content/6/11/eaaz0087#ref-27&quot;&gt;&lt;em&gt;27&lt;/em&gt;&lt;/a&gt;)]. Each audio clip (2 s) was followed by ITIs ranging unpredictably from 8.0 to 12.0 s (2-s step). All participants were instructed to silently answer the questions. Four 18-min fMRI scans were acquired for each participant.&lt;/p&gt;
&lt;p id=&quot;p-57&quot;&gt;After applying the same fMRI data preprocessing pipeline, we assigned each time point of the task dataset to a particular CAP based on its maximal similarity to the predefined CAP centroids from the main cohort data. The purpose of doing this was to make the results comparable and generalizable across datasets. This also avoided the potential stimulus-evoked contamination in the definition of CAPs, if otherwise resting state and task state were combined during &lt;em&gt;k&lt;/em&gt;-means clustering. The CAP occurrence rate was calculated across trials for each time point following stimulus onset (&lt;em&gt;t&lt;/em&gt; = 0) within the time window of 0 to 16 s for propofol-SHH and 0 to 10 s for neuropathological patients. The CAP occurrence rates for each time point (per condition and per participant) was corrected by subtracting the CAP occurrence rate at &lt;em&gt;t&lt;/em&gt; = 0, yielding a relative change against the stimulus onset.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&quot;sec-24&quot; class=&quot;subsection&quot; readability=&quot;30.948887056884&quot;&gt;
&lt;h3&gt;Psychiatric dataset&lt;/h3&gt;
&lt;p id=&quot;p-58&quot;&gt;The data were obtained from the OpenfMRI database. It is a shared neuroimaging dataset from the University of California, Los Angeles Consortium from Neuropsychiatric Phenomics (&lt;a id=&quot;xref-ref-29-2&quot; class=&quot;xref-bibr&quot; href=&quot;https://advances.sciencemag.org/content/6/11/eaaz0087#ref-29&quot;&gt;&lt;em&gt;29&lt;/em&gt;&lt;/a&gt;). The original dataset included 272 participants encompassing healthy individuals (&lt;em&gt;n&lt;/em&gt; = 130) and individuals with psychiatric disorders including schizophrenia (&lt;em&gt;n&lt;/em&gt; = 50), bipolar disorder (&lt;em&gt;n&lt;/em&gt; = 49), and attention deficit/hyperactivity disorder (&lt;em&gt;n&lt;/em&gt; = 43). Participants were excluded if they had no T1 images or resting-state data, the overall head motion range was above 3 mm, or the data had insufficient degree of freedom after band-pass filtering and motion scrubbing. This resulted in 116, 44, 49, and 39 participants for healthy individuals, schizophrenia, bipolar disorder, and attention deficit/hyperactivity disorder, respectively, in our analysis (248 in total).&lt;/p&gt;
&lt;p id=&quot;p-59&quot;&gt;As mentioned above, using maximal similarity to the predefined CAP centroids, we classified individual fMRI volumes into eight CAPs informed by the &lt;em&gt;k&lt;/em&gt;-means clustering approach from main cohort data. Accordingly, this produced a time series of discrete CAP labels per participant. The occurrence rates of each CAP per participant were calculated.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&quot;sec-25&quot; class=&quot;subsection&quot; readability=&quot;61.969888295289&quot;&gt;
&lt;h3&gt;Statistical analysis&lt;/h3&gt;
&lt;p id=&quot;p-60&quot;&gt;We performed Spearman rank correlations between the occurrence rates of joint mirror motifs and individual CAPs, with the level of responsiveness. Conscious and recovery conditions were ranked at 3, intermediate conditions (propofol light sedation, PreLOR of ketamine induction, and patients with MCS) were ranked at 2, and unresponsive conditions (propofol general anesthesia and deep sedation, LOR due to ketamine, and patients with UWS) were ranked as 1. In addition, Student’s &lt;em&gt;t&lt;/em&gt; tests (paired sample for propofol-SHH, propofol-WI, and ketamine; unpaired sample for neuropathological patients; two-sided) on the CAP occurrence rates were performed between conditions in each dataset. FDR correction (α &amp;lt; 0.05) was applied to correct for multiple comparisons.&lt;/p&gt;
&lt;p id=&quot;p-61&quot;&gt;To examine whether the persistence probabilities significantly deviated from uniformly random sequences, we generated null CAP time series by 1000 permutations, randomly and uniformly exchanging CAP positions in time, across the entire dataset. This null model was only used for assessing the statistical significance of CAP persistence for each condition alone (e.g., conscious state) but not for between conditions (see below). Because of the strong autocorrelation of fMRI signals, the CAP persistence probability shall be expected to be significantly higher than the null distribution. Therefore, this permutation test served as a proof of principle, which is not of interest in this study. To examine whether the transition probabilities and entropies of Markov trajectories significantly deviated from uniformly random sequences for a given condition (e.g., conscious state) and to examine the differences between conditions (e.g., conscious versus propofol) for transition probabilities, entropies of Markov trajectories, and persistence probability, we generated another null CAP time series by controlling the autocorrelation of fMRI signals (&lt;a id=&quot;xref-ref-24-6&quot; class=&quot;xref-bibr&quot; href=&quot;https://advances.sciencemag.org/content/6/11/eaaz0087#ref-24&quot;&gt;&lt;em&gt;24&lt;/em&gt;&lt;/a&gt;). That is, we preserved dwell times (approximately preserved autocorrelative properties) but otherwise permutated CAP cluster labels 1000 times across the entire dataset. Accordingly, the transition probabilities, entropies of Markov trajectories, and persistence probabilities for each surrogate condition (corresponding to the null time series) were calculated 1000 times to form null distributions for each condition. The deviation of each condition from null (except for the persistence probability that was tested by the first null model) and the deviation of differences between conditions from the null differences were determined at the significance level of &lt;em&gt;P&lt;/em&gt; &amp;lt; 0.001 by considering multiple comparison corrections (99.9th and 0.1th percentile of the null distributions; two-sided). Considering that our focus was the common and specific alterations between conscious and various unresponsive conditions, we did not assess the intermediate conditions (e.g., propofol light sedation, PreLOR during ketamine induction, and patients with MCS) and recovery conditions. We also collapsed the conscious conditions across the four datasets, and collapsed propofol-induced unresponsiveness of propofol-SHH and propofol-WI, to reduce the complexity of comparisons. These yielded four conditions with one conscious and three unresponsive conditions: propofol, ketamine, and patients with UWS.&lt;/p&gt;
&lt;p id=&quot;p-62&quot;&gt;For conventional static functional connectivity analysis, group-level &lt;em&gt;t&lt;/em&gt; tests (two-sided) on the functional connectivity values were performed, and significance was determined at FDR-corrected α &amp;lt; 0.05. For stimulus modulation analysis, Student’s &lt;em&gt;t&lt;/em&gt; tests (against zero; α &amp;lt; 0.05, FDR corrected; two-sided) for the CAP occurrence rate changes were performed during the peak period of stimulus-evoked fMRI signal activity (4 to 6 s) at the group level. For psychiatric dataset, comparisons of the CAP occurrence rates for healthy individuals versus schizophrenia, healthy individuals versus bipolar disorder, and healthy individuals versus attention deficit/hyperactivity disorder were performed at the group level by independent sample &lt;em&gt;t&lt;/em&gt; tests (two-sided; α &amp;lt; 0.05, FDR corrected).&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;div readability=&quot;47.008695652174&quot;&gt;&lt;strong&gt;Acknowledgments:&lt;/strong&gt; We thank G. Northoff, X. Wu, and P. Qin who shared the neuropathological data. We also appreciate assistance of X. Liu, K. Lauer, C. Roberts, S. Liu, S. Gollapudy, and W. Gross in performing the anesthetic procedures at the MCW and of Y. Chen, J. Xu, X. Li, Z. Yang, and J. Zhang in performing the anesthetic procedures at the Huashan Hospital. &lt;strong&gt;Funding:&lt;/strong&gt; This study was supported by Medical Guidance Supporting Project from Shanghai Municipal Science and Technology Commission No. 17411961400 (to J.Z.), Shanghai Municipal Science and Technology Major Project No. 2018SHZDZX01 (to J.Z.), and ZJLab. This study was also supported by a grant from the National Institute of General Medical Sciences of the NIH under award R01-GM103894 (to A.G.H.). The content is solely the responsibility of the authors and does not necessarily represent the official views of the NIH. &lt;strong&gt;Author contributions:&lt;/strong&gt; Z.H., J.Z., and A.G.H. designed the study. J.Z. and J.W. conducted the experiment, performed the anesthetic procedures, and collected the data of propofol-SHH and ketamine. A.G.H. collected the data of propofol-WI. Z.H. conducted the experiment and collected the task fMRI data in neuropathological patients. Z.H. and A.G.H. conceptualized the data analyses. Z.H. analyzed the entire dataset and prepared the figures. Z.H., G.A.M., and A.G.H. interpreted the data and edited the manuscript. Z.H., J.Z., G.A.M., and A.G.H. wrote the manuscript. &lt;strong&gt;Competing interests:&lt;/strong&gt; The authors declare that they have no competing interests. &lt;strong&gt;Data and materials availability:&lt;/strong&gt; All data needed to evaluate the conclusions in the paper are present in the paper and the Supplementary Materials. Additional data related to this paper may be requested from the authors. The psychiatric dataset is available at OpenfMRI (&lt;a href=&quot;https://openfmri.org/dataset/ds000030/&quot;&gt;https://openfmri.org/dataset/ds000030/&lt;/a&gt;).&lt;/div&gt;</description>
<pubDate>Thu, 09 Apr 2020 16:16:01 +0000</pubDate>
<dc:creator>hhs</dc:creator>
<og:title>Temporal circuit of macroscale dynamic brain activity supports human consciousness</og:title>
<og:url>https://advances.sciencemag.org/content/6/11/eaaz0087</og:url>
<og:description>The ongoing stream of human consciousness relies on two distinct cortical systems, the default mode network and the dorsal attention network, which alternate their activity in an anticorrelated manner. We examined how the two systems are regulated in the conscious brain and how they are disrupted when consciousness is diminished. We provide evidence for a “temporal circuit” characterized by a set of trajectories along which dynamic brain activity occurs. We demonstrate that the transitions between default mode and dorsal attention networks are embedded in this temporal circuit, in which a balanced reciprocal accessibility of brain states is characteristic of consciousness. Conversely, isolation of the default mode and dorsal attention networks from the temporal circuit is associated with unresponsiveness of diverse etiologies. These findings advance the foundational understanding of the functional role of anticorrelated systems in consciousness.</og:description>
<og:type>article</og:type>
<og:image>https://advances.sciencemag.org/content/6/11/eaaz0087/F1.large.jpg</og:image>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://advances.sciencemag.org/content/6/11/eaaz0087</dc:identifier>
</item>
<item>
<title>Simula: A VR window manager for Linux</title>
<link>https://github.com/SimulaVR/Simula</link>
<guid isPermaLink="true" >https://github.com/SimulaVR/Simula</guid>
<description>&lt;p&gt;&lt;a target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot; href=&quot;https://github.com/SimulaVR/Simula/blob/gdwlroots-xwayland/doc/TEMP_LOGO.png&quot;&gt;&lt;img src=&quot;https://github.com/SimulaVR/Simula/raw/gdwlroots-xwayland/doc/TEMP_LOGO.png&quot; alt=&quot;./doc/TEMP_LOGO.png&quot;/&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Simula is a VR window manager for Linux that runs on top of &lt;a href=&quot;https://godotengine.org/&quot; rel=&quot;nofollow&quot;&gt;Godot&lt;/a&gt;. It takes less than 1 minute to install.&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://www.youtube.com/watch?v=FWLuwG91HnI&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;https://camo.githubusercontent.com/26732cab5e0c9e94ff0b46a2e880586b28f8e297/687474703a2f2f696d672e796f75747562652e636f6d2f76692f46574c7577473931486e492f302e6a7067&quot; alt=&quot;http://img.youtube.com/vi/FWLuwG91HnI/0.jpg&quot; data-canonical-src=&quot;http://img.youtube.com/vi/FWLuwG91HnI/0.jpg&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Video:&lt;/strong&gt; &lt;a href=&quot;http://www.youtube.com/watch?v=FWLuwG91HnI&quot; rel=&quot;nofollow&quot;&gt;Demonstration.&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Compatibility:&lt;/strong&gt; Currently, Simula is only compatible with SteamVR headsets (e.g. HTC Vive, HTC Vive Pro, &amp;amp; Valve Index).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Mission:&lt;/strong&gt; Facilitate a Linux future for VR &amp;amp; AR Desktop. In the short-run, this means allowing people to run 2D Linux apps with current generation headsets. In the long-run, this means allowing people to run Linux in standalone AR &amp;amp; VR HMDs.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Origins:&lt;/strong&gt; Simula is a reimplementation fork of &lt;a href=&quot;https://github.com/evil0sheep/motorcar&quot;&gt;motorcar&lt;/a&gt;. To read about motorcar, see &lt;em&gt;&lt;a href=&quot;https://github.com/evil0sheep/MastersThesis/blob/master/thesis.pdf?raw=true&quot;&gt;Toward General Purpose 3D User Interfaces: Extending Windowing Systems to Three Dimensions&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;A common objection to the viability of VR Desktop is that it exhibits poor text quality; however, with our low pass filter, Simula has taken special care to make text quality as clear as possible:&lt;/p&gt;
&lt;p&gt;&lt;a target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot; href=&quot;https://github.com/SimulaVR/Simula/blob/gdwlroots-xwayland/doc/TextQuality2.gif&quot;&gt;&lt;img src=&quot;https://github.com/SimulaVR/Simula/raw/gdwlroots-xwayland/doc/TextQuality2.gif&quot; alt=&quot;./doc/TextQuality2.gif&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The left image is a VR terminal &lt;em&gt;without&lt;/em&gt; our filter applied; the right is the same image &lt;em&gt;with&lt;/em&gt; our filter applied. Compared to other VR Desktops, Simula allows for significantly longer sessions without uncomfortable eye strain.&lt;/p&gt;

&lt;p&gt;To install Simula on all Linux distros, run:&lt;/p&gt;
&lt;div class=&quot;highlight highlight-source-shell&quot; readability=&quot;10&quot;&gt;
&lt;pre&gt;
&lt;span class=&quot;pl-c&quot;&gt;&lt;span class=&quot;pl-c&quot;&gt;#&lt;/span&gt; Clone&lt;/span&gt;
git clone --recursive https://github.com/SimulaVR/Simula
&lt;span class=&quot;pl-c1&quot;&gt;cd&lt;/span&gt; Simula

&lt;span class=&quot;pl-c&quot;&gt;&lt;span class=&quot;pl-c&quot;&gt;#&lt;/span&gt; Download (or build, if downloading fails)&lt;/span&gt;
&lt;span class=&quot;pl-c1&quot;&gt;source&lt;/span&gt; ./utils/Helpers.sh &lt;span class=&quot;pl-k&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; installSimula

&lt;span class=&quot;pl-c&quot;&gt;&lt;span class=&quot;pl-c&quot;&gt;#&lt;/span&gt; Launch&lt;/span&gt;
./result/bin/simula &lt;span class=&quot;pl-c&quot;&gt;&lt;span class=&quot;pl-c&quot;&gt;#&lt;/span&gt; Needs SteamVR to be running&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Installing Simula should take less than 1 minute:&lt;/strong&gt; this script doesn’t actually compile anything on your system, but instead downloads the appropriate binaries from our cache in a way that is system and driver agnostic. Under the hood, we (i) check whether you have &lt;code&gt;nix&lt;/code&gt; and &lt;code&gt;cachix&lt;/code&gt; installed (and, if not, install them); (ii) check which graphics drivers you have and (iii) download Simula via &lt;code&gt;cachix&lt;/code&gt; with the appropriate driver flags, falling back to a &lt;code&gt;nix&lt;/code&gt; build if downloading fails.&lt;/p&gt;
&lt;p&gt;On NixOS systems, you must ensure&lt;/p&gt;
&lt;pre&gt;
nix.trustedUsers = [ &quot;root&quot; &quot;&amp;lt;your_user_name&amp;gt;&quot;];
&lt;/pre&gt;
&lt;p&gt;is added to your &lt;code&gt;configuration.nix&lt;/code&gt;, or the install command above will be unable to download Simula from our cache, instead falling back to a manual build (which takes 1hr+).&lt;/p&gt;

&lt;h2&gt;Mouse &amp;amp; Keyboard Controls&lt;/h2&gt;
&lt;p&gt;Windows become “active” once you look at them. Active windows receive typing events from the keyboard, and cursor events from mouse movement. In addition, the following window-manipulation shortcuts are hard-coded into Simula (we’re going to make this customizable in the near future):&lt;/p&gt;
&lt;table&gt;&lt;tbody readability=&quot;13&quot;&gt;&lt;tr&gt;&lt;th&gt;&lt;strong&gt;Key binding.&lt;/strong&gt;&lt;/th&gt;
&lt;th&gt;&lt;strong&gt;Action&lt;/strong&gt;&lt;/th&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;&lt;code&gt;Super + /&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Quick launch terminal (&lt;code&gt;terminator&lt;/code&gt;)&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;&lt;code&gt;Super + Apostrophe&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Send window cursor to gaze point (hold down to make cursor follow gaze)&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;&lt;code&gt;Super + Enter&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Left click surface cursor at gaze point&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;&lt;code&gt;Super + Alt&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Grab surface for movement (release to let go)&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;&lt;code&gt;Super + f&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Orient window towards user gaze&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;&lt;code&gt;Super + 9&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Scale window to smaller size&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;&lt;code&gt;Super + 0&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Scale window to larger size&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;&lt;code&gt;Super + -&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Increase window resolution (“zoom out”)&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;&lt;code&gt;Super + =&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Increase window resolution (“zoom in”)&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;code&gt;Super + Comma&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Move window towards you&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;&lt;code&gt;Super + Period&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Move window away from you&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;&lt;code&gt;Super + Backspace&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Kill surface being looked at&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;code&gt;Super + k&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Quick launch firefox&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;&lt;code&gt;Super + g&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Quick launch google-chrome&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;&lt;code&gt;Super + w&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Launch headset webcam view (requires &lt;code&gt;ffplay&lt;/code&gt;).&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;h2&gt;VR Controllers&lt;/h2&gt;
&lt;p&gt;&lt;a target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot; href=&quot;https://camo.githubusercontent.com/d729e7164b3b388e8e579a7b6b45318b3c6538bc/68747470733a2f2f7777772e657665746563682e636f2e7a612f7265706f7369746f72792f50726f64756374496d616765732f6874632d766976652d636f6e74726f6c6c65722d37333070782d76312e6a7067&quot;&gt;&lt;img src=&quot;https://camo.githubusercontent.com/d729e7164b3b388e8e579a7b6b45318b3c6538bc/68747470733a2f2f7777772e657665746563682e636f2e7a612f7265706f7369746f72792f50726f64756374496d616765732f6874632d766976652d636f6e74726f6c6c65722d37333070782d76312e6a7067&quot; alt=&quot;https://www.evetech.co.za/repository/ProductImages/htc-vive-controller-730px-v1.jpg&quot; data-canonical-src=&quot;https://www.evetech.co.za/repository/ProductImages/htc-vive-controller-730px-v1.jpg&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Left-clicking.&lt;/strong&gt; Use (7) gently (you don’t have to go all the way down to click).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Right-clicking.&lt;/strong&gt; Use (1).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Scrolling.&lt;/strong&gt; Scroll up and down via (2).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Text dragging.&lt;/strong&gt; Hold (7) down and drag.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Window manipulation.&lt;/strong&gt; Point at a window and, while holding (8), move your controller around. The windows should “levitate” in the direction of your movement.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Window rescaling.&lt;/strong&gt; Point at a window, hold (8) down, and then scroll up and down on (2).&lt;/li&gt;
&lt;/ul&gt;&lt;h2&gt;Mouse &amp;amp; Keyboard View&lt;/h2&gt;
&lt;p&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=D5c3Hfp8Hcw&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;https://camo.githubusercontent.com/c7a12a02cd3b135f554e0cd122dc367d558e3649/68747470733a2f2f7777772e776f6c6672616d636c6f75642e636f6d2f6f626a2f67656f7267652e772e73696e6765722f313036333531323536333835303438383436333034353934363435383932333939363937363333343330383236323434312e706e67&quot; alt=&quot;https://www.wolframcloud.com/obj/george.w.singer/1063512563850488463045946458923996976334308262441.png&quot; data-canonical-src=&quot;https://www.wolframcloud.com/obj/george.w.singer/1063512563850488463045946458923996976334308262441.png&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Simula has a headset &lt;a href=&quot;https://www.youtube.com/watch?v=D5c3Hfp8Hcw&quot; rel=&quot;nofollow&quot;&gt;webcam view&lt;/a&gt; (binded presently to &lt;code&gt;Super + w&lt;/code&gt;) that allows you to see your mouse and keyboard from VR.&lt;/p&gt;

&lt;p&gt;For troubleshooting and discussion, join our community at &lt;a href=&quot;https://discordapp.com/invite/a4PnP7n&quot; rel=&quot;nofollow&quot;&gt;https://discordapp.com/invite/a4PnP7n&lt;/a&gt;.&lt;/p&gt;
</description>
<pubDate>Thu, 09 Apr 2020 16:09:20 +0000</pubDate>
<dc:creator>georgewsinger</dc:creator>
<og:image>https://avatars2.githubusercontent.com/u/32070679?s=400&amp;v=4</og:image>
<og:type>object</og:type>
<og:title>SimulaVR/Simula</og:title>
<og:url>https://github.com/SimulaVR/Simula</og:url>
<og:description>Linux VR Desktop. Contribute to SimulaVR/Simula development by creating an account on GitHub.</og:description>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://github.com/SimulaVR/Simula</dc:identifier>
</item>
<item>
<title>ICQ New</title>
<link>https://icq.com/desktop/</link>
<guid isPermaLink="true" >https://icq.com/desktop/</guid>
<description>[unable to retrieve full-text content]
&lt;p&gt;Article URL: &lt;a href=&quot;https://icq.com/desktop/&quot;&gt;https://icq.com/desktop/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Comments URL: &lt;a href=&quot;https://news.ycombinator.com/item?id=22823743&quot;&gt;https://news.ycombinator.com/item?id=22823743&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Points: 296&lt;/p&gt;
&lt;p&gt;# Comments: 285&lt;/p&gt;
</description>
<pubDate>Thu, 09 Apr 2020 15:53:54 +0000</pubDate>
<dc:creator>LemonHotdog</dc:creator>
<dc:identifier>https://icq.com/desktop/en</dc:identifier>
</item>
<item>
<title>Japan to fund firms to shift production out of China</title>
<link>https://www.bloomberg.com/news/articles/2020-04-08/japan-to-fund-firms-to-shift-production-out-of-china</link>
<guid isPermaLink="true" >https://www.bloomberg.com/news/articles/2020-04-08/japan-to-fund-firms-to-shift-production-out-of-china</guid>
<description>[unable to retrieve full-text content]
&lt;p&gt;Article URL: &lt;a href=&quot;https://www.bloomberg.com/news/articles/2020-04-08/japan-to-fund-firms-to-shift-production-out-of-china&quot;&gt;https://www.bloomberg.com/news/articles/2020-04-08/japan-to-fund-firms-to-shift-production-out-of-china&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Comments URL: &lt;a href=&quot;https://news.ycombinator.com/item?id=22823058&quot;&gt;https://news.ycombinator.com/item?id=22823058&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Points: 445&lt;/p&gt;
&lt;p&gt;# Comments: 371&lt;/p&gt;
</description>
<pubDate>Thu, 09 Apr 2020 14:49:28 +0000</pubDate>
<dc:creator>Reedx</dc:creator>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.bloomberg.com/tosv2.html?vid=&amp;uuid=d0df4d70-7ac6-11ea-9532-f3f548bf112c&amp;url=L25ld3MvYXJ0aWNsZXMvMjAyMC0wNC0wOC9qYXBhbi10by1mdW5kLWZpcm1zLXRvLXNoaWZ0LXByb2R1Y3Rpb24tb3V0LW9mLWNoaW5h</dc:identifier>
</item>
<item>
<title>Yelp lays off 1000, furloughs 1100</title>
<link>https://blog.yelp.com/2020/04/planning-for-yelps-future</link>
<guid isPermaLink="true" >https://blog.yelp.com/2020/04/planning-for-yelps-future</guid>
<description>
&lt;div class=&quot;post-content col-md-8 col-md-offset-2&quot;&gt;
&lt;header&gt;
&lt;div class=&quot;entry-meta vcard small&quot;&gt;&lt;img src=&quot;https://blog.yelp.com/wp-content/themes/yelpblog-updated/images/yelp-avatar-meta.png&quot; alt=&quot;Jeremy Stoppelman&quot; class=&quot;img-responsive img-rounded pull-left photo&quot; width=&quot;36&quot; height=&quot;36&quot;/&gt;&lt;/div&gt;
&lt;div class=&quot;entry-content&quot; itemprop=&quot;articleBody&quot;&gt;
&lt;p&gt;&lt;em&gt;&lt;span&gt;In an internal email this morning, Yelp co-founder and CEO Jeremy Stoppelman shared with all employees that due to the impact of COVID-19 on our business, the company is taking the painful but necessary step to reduce the size of our workforce through a combination of layoffs, furloughs, and reduction of hours.&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;
&lt;hr/&gt;&lt;p&gt;&lt;span&gt;It’s been an extremely difficult and painful last month: the world is facing a global health crisis none of us have ever witnessed in our lifetimes. It has disrupted daily life for nearly everyone — from businesses that rely on foot traffic or human contact, to workers who have no visibility into when they will earn their next paycheck; and parents, including many of us here at Yelp, who are trying to juggle childcare with job responsibilities. People everywhere are staying in to stay safe, wondering when life will go back to normal. &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;The physical distancing measures and shelter-in-place orders, while critical to flatten the curve, have dealt a devastating blow to the local businesses that are core to our mission. The&lt;/span&gt; &lt;a href=&quot;https://www.yelpeconomicaverage.com/yelp-coronavirus-economic-impact-report&quot;&gt;&lt;span&gt;impact we’ve seen&lt;/span&gt;&lt;/a&gt; &lt;span&gt;on consumer behavior is staggering: interest in restaurants, our most popular category, has dropped 64% since March 10, and the nightlife category is down 81%. Gyms and similar businesses are down 73%,&lt;/span&gt; &lt;span&gt;and salons and other beauty businesses are down 83%. All told, the millions of local businesses hit hardest by the effects of COVID-19 face the prospect of closing and laying off their employees, without knowing when, or if, they’ll be able to reopen.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;Yelp connects people with these great local businesses, and as their worlds have been turned upside down, these businesses are understandably forced to pause or reduce spending on the products and services that Yelp provides. The duration and impact of this is unknown, but it will have a direct impact on our own revenues. As local businesses urgently figure out how to manage this crisis, we must do the same. To help Yelp get through this period of great uncertainty, we have had to make some incredibly hard decisions to reduce our operating costs. Today we will let 1,000 of our colleagues go and furlough approximately 1,100 more, while reducing hours for others.&lt;/span&gt; &lt;span&gt;Your department leaders will be in touch this morning to discuss how this affects you individually, and letters with more details and FAQs will follow this afternoon.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;We came to this decision as a last resort only after cutting non-employee expenses where possible. We have reduced server costs, deprioritized dozens of projects, and redone our budget based on ensuring company survival (instead of growth). We have implemented cost savings at the top, including 20-30% pay cuts for all execs. Beyond not taking a salary, I also will not vest any of my 2020 stock awards for the remainder of the year.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;These extreme actions wouldn’t make sense in normal times. We entered this crisis with a strong cash position, and had built serious revenue momentum across all categories in the last year. We did what many outside the company didn’t think was possible — we overhauled our business and re-accelerated growth. This was a testament to all the hard work and tenacity that you brought each and every day. We had an ambitious 2020 plan that we were executing successfully, and never could we have imagined such a rapid shutdown of the many local economies that drive our business.  &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;What led to this decision to part with employees, even temporarily, was not the present or near past, but where the data indicate we are headed. With revenue levels expected to be substantially lower, Yelp must make these severe cost reductions to sustain itself as a business, which I fully understand will negatively impact so many of my colleagues and friends. I do not take lightly the additional difficulties each one of those affected and their families will face in the coming months, and I’m truly sorry. Many of these colleagues have played an integral role in making Yelp the company it is today — from building great products for businesses and our users, and ensuring the quality and integrity of our content, to helping customers succeed on our platform, as well as supporting our teams in various other capacities. I’m forever grateful for their contributions.  &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;We want to do everything we can to support our departing colleagues. Employees affected by the layoff will be offered severance pay, and reimbursement for up to three months of health insurance coverage. Employees on furlough will be put on unpaid leave, unless otherwise noted, but will retain the bulk of their benefits during this time and receive two weeks of additional pay. Those who have hours reduced will also continue to retain their benefits. Your managers, directors, and VPs are here to support you through this transition and will reach out to you this morning, and over the course of the day.&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;This is very tough news to take in. In all of our nearly 16 years, I’ve never seen a crisis of this magnitude and impact on our business. Today is an awful day for all of us, and especially for our departing colleagues and friends. I want to be clear that these personnel decisions are not reflective of an individual’s talents or worth to Yelp and I hope you all remain proud of the impact you’ve had. We sincerely thank you, wish you well and will support you through this challenging transition as best we can. &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;We also want to continue to offer support to the small local businesses that are struggling to survive, as they are the lifeblood of our cities, our everyday life, and are so core to Yelp. I’m proud of how our teams rallied to find ways to provide aid — from working to waive fees and provide free products and services for hard-hit businesses, to quickly building new features to help them connect with their customers in today’s rapidly changing environment. I’m also encouraged by the steps the federal government is taking to help ensure their survival. Swift action by the public sector in containing the virus and providing continued financial support to local businesses will be critical in helping local economies recover from this disaster. &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;To those who are furloughed, we will be laser focused on getting the company to a point where we can all return to work. As we move beyond this crisis, Yelp will remain an essential resource, helping consumers and local businesses find and connect with one another. While this pandemic has dealt us an unprecedented and unexpected setback, I couldn’t be more proud of how our teams across the company came together over the past few weeks. The coming months will require us to stay nimble and adapt, like many local businesses have been doing. I have no doubt that ultimately we will come out of this stronger and more prepared to deal with the peaks and valleys that lay ahead in the years to come.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;Jeremy&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Cautionary Statement Regarding Forward-Looking Statements&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;The above communication contains forward-looking statements within the meaning of Section 27A of the Securities Act of 1933, as amended, and Section 21E of the Securities Exchange Act of 1934, as amended. Specific forward-looking statements include, without limitation, statements related to COVID-19 and its impact on the economy, consumers, local businesses, Yelp Inc. (the “Company”) and demand for its products, including the duration thereof; the recovery of local economies from COVID-19 and the resulting rebound of demand for the Company’s products and services; and the Company’s financial position, operating trends, its planned cost-cutting efforts, including the duration thereof, and the expected impact of such efforts, including their ability to position it well to serve both consumers and local businesses in the recovery and beyond. Forward-looking statements involve risks, uncertainties, assumptions and other factors that are difficult to predict and that could cause actual results to vary materially from those predicted or implied by such forward-looking statements.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;Factors that could cause or contribute to such differences include, among others, (x) the impact of fears or actual outbreaks of disease, changes in consumer behavior, economic conditions, governmental actions, actions of competitors and other factors beyond the Company’s control; and (y) those factors that could affect the Company’s business, operating results and stock price included under the captions “Risk Factors” and “Management’s Discussion and Analysis of Financial Condition and Results of Operations” in the Company’s Annual Report on Form 10-K for the year ended December 31, 2019. Undue reliance should not be placed on the forward-looking statements in the above communication, which are based on information available to the Company as of the date hereof.&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;

&lt;/header&gt;&lt;/div&gt;
</description>
<pubDate>Thu, 09 Apr 2020 14:23:05 +0000</pubDate>
<dc:creator>rpncreator</dc:creator>
<og:type>article</og:type>
<og:title>Planning for Yelp’s Future - Yelp</og:title>
<og:description>In an internal email this morning, Yelp co-founder and CEO Jeremy Stoppelman shared with all employees that due to the impact of COVID-19 on our business, the company is taking the painful but necessary step to reduce the size of our workforce through a combination of layoffs, furloughs, and reduction of hours. It’s been an... Read more</og:description>
<og:url>https://blog.yelp.com/2020/04/planning-for-yelps-future</og:url>
<og:image>https://blog.yelp.com/wp-content/uploads/2020/03/yelp.png</og:image>
<dc:language>en-US</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://blog.yelp.com/2020/04/planning-for-yelps-future</dc:identifier>
</item>
<item>
<title>Why I’m Leaving Elm</title>
<link>https://lukeplant.me.uk/blog/posts/why-im-leaving-elm/</link>
<guid isPermaLink="true" >https://lukeplant.me.uk/blog/posts/why-im-leaving-elm/</guid>
<description>
&lt;p&gt;Over the past year or so, I’ve reluctantly come to the conclusion I need to leave &lt;a class=&quot;reference external&quot; href=&quot;https://elm-lang.org/&quot;&gt;Elm&lt;/a&gt; and migrate to some other language (most likely &lt;a class=&quot;reference external&quot; href=&quot;https://bucklescript.github.io/&quot;&gt;Bucklescript&lt;/a&gt; via &lt;a class=&quot;reference external&quot; href=&quot;https://github.com/darklang/philip2&quot;&gt;philip2&lt;/a&gt;), and I definitely cannot recommend it to anyone else. This post is about my reasons for that, which are mostly about the way in which the leadership behave.&lt;/p&gt;
&lt;p&gt;I’m not going to talk about the good points of Elm as a technology. You can read them other places, and they will probably be true. Elm (up to version 0.18, at least) has been a joy to work with, and it will be hard to replace. I should also note “Your Mileage May Vary” etc. It would be entirely possible to use Elm and find it adequate for your needs, and therefore never bump into the things I hit very quickly.&lt;/p&gt;

&lt;div class=&quot;section&quot; id=&quot;aims-and-audience&quot;&gt;

&lt;p&gt;This post is for people who are assessing Elm, and may have something of benefit for people in other communities, especially leaders.&lt;/p&gt;
&lt;p&gt;If you are a part of the Elm core team, you might want to skip this post for the sake of your mental health. I have tried harder than in the past to be fair and reasoned, but it’s not likely to be easy reading.&lt;/p&gt;
&lt;p&gt;On the other hand, if people from within the Elm community have had the courage to ask you to read this, then maybe you should. I also think that the decisions and behaviour that I criticise here are actually causing you (the core Elm team) far more stress than is necessary, and changes would be very good for your mental well-being.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;section&quot; id=&quot;entitlement-and-expectations&quot;&gt;

&lt;p&gt;Since this post will mainly be complaints and criticism, I thought it worth addressing whether that is ever appropriate or not in Open Source.&lt;/p&gt;
&lt;p&gt;As a current maintainer of a handful of small Open Source projects, and having put in a lot of hours on some bigger ones, I’m well aware of the unwarranted sense of entitlement that many people have when it comes to interacting with Open Source projects. I agree this is a problem, but I don’t think that just because you are not being paid by people that they can have zero expectations about how you will behave.&lt;/p&gt;
&lt;p&gt;The first reason for this is that general ethical standards (including honesty and fairness) apply even if people are not paying you.&lt;/p&gt;
&lt;p&gt;The second is that if you advertise something as Open Source, there is a common set of assumptions about what that means, some of which are explicit in accepted definitions of the term.&lt;/p&gt;
&lt;p&gt;The third is that the Golden Rule applies. I think it is safe to say that every producer of Open Source software is also a massive consumer, and the Open Source movement is only possible because there are certain standards of behaviour which are adhered to.&lt;/p&gt;
&lt;p&gt;I think the degree to which we are responsible to other people who are not paying us does depend on a number of things. The benefit we derive from running an Open Source project is one factor. The number of people who will be affected by our decisions is another. And the contributions we received from people is a third, whether those contributions are code or not.&lt;/p&gt;
&lt;p&gt;In some cases, the authors, maintainers and sponsors of a project stand to gain a lot from the success of that project, especially when the project functions as a platform of some kind. This is why it is usually not hard for authors of thriving languages to find sponsors.&lt;/p&gt;
&lt;p&gt;And decisions made in popular languages can damage or sink someone’s project, someone’s career or even someone’s livelihood, for those who have made a gamble on investing in that language.&lt;/p&gt;
&lt;p&gt;For example, I’m well aware that my career has been hugely helped by being part of the Django core team, often in ways that don’t really feel fair. And changes we make to Django can affect a lot of people, for better or worse. This doesn’t mean that people can come along and demand any change they want and we have to do it, but it does mean that we ought to exercise a certain amount of care and responsibility.&lt;/p&gt;
&lt;p&gt;If the author(s) of a language think they can do whatever they want because they are providing the code for free, they must remember the army of people who have provided high quality libraries for free, who have done countless hours of bug reporting for free, done beta testing for free, done usability testing for free, — all at high personal risk, especially when they are early adopters — and, by no means least, provided the most effective kind of advertising and marketing entirely for free: personal, word of mouth recommendation and promotion.&lt;/p&gt;
&lt;p&gt;This means that even if a single person wrote every line of code of a language’s compiler themselves, when it comes to thinking about the project, &lt;strong&gt;they need to think of themselves as stewards and not owners&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;So this post is not about me demanding missing features in Elm (although certain features do affect the story), it’s about the wider issues of how you treat people, and the expectations that we can have in these areas.&lt;/p&gt;
&lt;p&gt;Some of my comments are on the level of personal preference or technical needs when it comes to what I’m looking for in Open Source projects, and others are definitely on the level of the ethics of how I think people should behave and be treated, both in general and in Open Source projects specifically.&lt;/p&gt;
&lt;p&gt;Now, onto my reasons:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;section&quot; id=&quot;i-messed-up-with-my-interactions-with-the-core-team&quot;&gt;

&lt;p&gt;One big factor in why I’m leaving the Elm community is that I messed up majorly in my interactions with the Elm core team.&lt;/p&gt;
&lt;p&gt;At the beginning it wasn’t entirely my fault — I was all set to do a positive “Show and Tell” post on &lt;a class=&quot;reference external&quot; href=&quot;https://discourse.elm-lang.org/&quot;&gt;Elm Discourse&lt;/a&gt;, when the core devs announced a change that would really hurt my project (along with many other people’s). So my introduction instead turned into something &lt;a class=&quot;reference external&quot; href=&quot;https://lukeplant.me.uk/blog/posts/two-experiences-with-elm/&quot;&gt;a lot more confrontational&lt;/a&gt;, so I feel slightly a victim of bad timing, though of course I accept responsibility for my own words.&lt;/p&gt;
&lt;p&gt;Since then I’ve not done a whole much better, although I have been trying.&lt;/p&gt;
&lt;p&gt;The story was this: I needed to internationalise my app, and, after years of seeing different solutions, particularly through the eyes of Django, and &lt;a class=&quot;reference external&quot; href=&quot;https://lukeplant.me.uk/blog/posts/translating-sentences-with-substitutions/&quot;&gt;thinking about some of their issues&lt;/a&gt;, I found Mozilla’s awesome &lt;a class=&quot;reference external&quot; href=&quot;https://projectfluent.org/&quot;&gt;Fluent&lt;/a&gt; project, and settled on that as a solution. I also had a look at all the existing Elm solutions I could find, and found them wanting — most of them don’t even attempt to solve the problems that Fluent solves.&lt;/p&gt;
&lt;p&gt;It turns out that Fluent can be used in a really elegant way in Elm, by compiling &lt;span class=&quot;caps&quot;&gt;FTL&lt;/span&gt; files to Elm source code, and I created &lt;a class=&quot;reference external&quot; href=&quot;https://github.com/elm-fluent/elm-fluent&quot;&gt;elm-fluent&lt;/a&gt; which implements this (complementing &lt;a class=&quot;reference external&quot; href=&quot;https://github.com/django-ftl/django-ftl&quot;&gt;django-ftl&lt;/a&gt; and &lt;a class=&quot;reference external&quot; href=&quot;https://github.com/django-ftl/fluent-compiler&quot;&gt;fluent-compiler&lt;/a&gt; that I also created for my Python backend).&lt;/p&gt;
&lt;p&gt;Like many other Elm projects that need i18n features, elm-fluent needs an official wrapper for &lt;a class=&quot;reference external&quot; href=&quot;https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Intl&quot;&gt;Intl&lt;/a&gt; (the initial version uses a non-official wrapper, which is impossible from Elm 0.19 onwards). I &lt;a class=&quot;reference external&quot; href=&quot;https://discourse.elm-lang.org/t/bindings-for-intl/1264/4&quot;&gt;attempted&lt;/a&gt; to get things going regarding an official wrapper, but it went nowhere. The topic of i18n came up again later on the Elm Discourse, and I contributed, but the thread was shut down in what I considered a really unhelpful way. Rather than starting a new thread to argue, I thought building something useful would be a better and more persuasive idea.&lt;/p&gt;
&lt;p&gt;But before I was ready with elm-fluent, Elm 0.19 was out with the restriction on native modules that made elm-fluent impossible (until an official wrapper for Intl is released). Rather than announce a project that was effectively dead in the water, only supporting an old Elm release, I started looking for ways round the restrictions.&lt;/p&gt;
&lt;p&gt;That led me eventually to some private emails with Richard Feldman. Unfortunately I messed these up too. The discussion was about native modules, and I used some of the arguments you’ll find below, but looking back at my email I’m ashamed — I used even less tact and care than I’ve managed here, and certainly less than was necessary. Although at multiple points I did ascribe good motivations to the Elm core team, I somehow succeeded in persuading Richard that I considered the core team to be bad faith actors, and that was the end of our communication. I apologize to the rest of the Elm community for the way I allowed my frustration to get the better of me and squandered that opportunity.&lt;/p&gt;
&lt;p&gt;In the Elm community, your hope of being useful depends on relationships, and not offending people, and I’m pretty sure I’ve blown that.&lt;/p&gt;
&lt;p&gt;So, if you are looking for a reason to dismiss this post as the rantings of someone who just can’t get along with people very well, it’s right here. However, I have never had these kind of problems with any other Open Source community, so I don’t think it is just me.&lt;/p&gt;
&lt;p&gt;If you are thinking of getting involved in the Elm community, take a lesson from this. There are other things about the community that make me pretty uncomfortable about being part of it, but if I hadn’t messed up here I might have considered persevering a little longer.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;section&quot; id=&quot;technical-limitations&quot;&gt;

&lt;p&gt;The technical limitation that is really killing me on my usage of Elm is the restriction on native modules. For those not in the know, native modules in Elm allow you to write part of an Elm module in Javascript. This feature is absolutely necessary in Elm and is used by many of the &lt;a class=&quot;reference external&quot; href=&quot;https://github.com/elm&quot;&gt;core libraries&lt;/a&gt;, and a bunch of other libraries in &lt;a class=&quot;reference external&quot; href=&quot;https://github.com/elm-community/&quot;&gt;elm-community&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Previously, there were tight restrictions on native modules uploaded to &lt;a class=&quot;reference external&quot; href=&quot;https://package.elm-lang.org/&quot;&gt;package.elm-lang.org&lt;/a&gt;. But you could work around that for your own needs if necessary using something like &lt;a class=&quot;reference external&quot; href=&quot;https://github.com/gdotdesign/elm-github-install&quot;&gt;elm-github-install&lt;/a&gt;. In Elm 0.19, however, the compiler itself limits the feature to certain official libraries — you cannot use it at all in your own projects.&lt;/p&gt;
&lt;p&gt;I &lt;a class=&quot;reference external&quot; href=&quot;https://lukeplant.me.uk/blog/posts/two-experiences-with-elm/&quot;&gt;blogged before&lt;/a&gt; about my need for native modules, and since then a bigger thing came up — I need a good wrapper for &lt;a class=&quot;reference external&quot; href=&quot;https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Intl&quot;&gt;Intl&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The restriction causes huge problems for lots of other people too. For example, if there is a bug in any core library, or something missing, you just have to wait for the core team to fix it, rather than being able to fix it yourself. You might need a performance fix, which can be done using Javascript but not in Elm (lack of destructive updates makes some things very hard to implement efficiently), and again you will be stuck having to explain to your boss “I know this is possible in Javascript, but we chose Elm and it makes it very hard”. The work-arounds are not attractive, and in some cases simply won’t work (for example, elm-fluent can’t work around the restriction without destroying its design).&lt;/p&gt;
&lt;p&gt;In my experience, things like this come up. I didn’t know that I was going to need an Intl wrapper, but then it happened. Without the ability to get out of these kind of sticky situations, Elm is not an attractive option to me, and I wouldn’t recommend it to other people, on that basis alone.&lt;/p&gt;
&lt;p&gt;The most difficult part to accept is that this is crippleware — by which I mean a deliberate limitation that takes additional work by the authors to impose. The feature is still very much there, and very much necessary, just disabled if the compiler can’t see that you are contributing to certain projects. For the foreseeable future something like it will be needed, as long as it is possible to distribute core libraries separate from the compiler itself.&lt;/p&gt;
&lt;p&gt;I have no doubt that the Elm core team believe this change is in people’s best interests. Evan initially expressed a belief that everyone would be able to upgrade to Elm 0.19. However, despite many people indicating that they cannot &lt;a class=&quot;footnote-reference&quot; href=&quot;https://lukeplant.me.uk/blog/posts/why-im-leaving-elm/#cannot-upgrade&quot; id=&quot;id2&quot;&gt;[1]&lt;/a&gt;, there has been no reversal of the decision. It appears that they believe long term they are still acting for the best, because forcing this change moves more of the ecosystem to pure Elm code, which Evan believes will benefit the project in the future. There are many holes and problems in this argument, but the attitude of treating existing projects as collateral damage is unacceptable in my book.&lt;/p&gt;
&lt;img alt=&quot;“Some of you may die, but it's a sacrifice I am willing to make” — Lord Farquaad from Shrek&quot; class=&quot;align-center&quot; src=&quot;https://lukeplant.me.uk/blogmedia/some_of_you_may_die.jpeg&quot;/&gt;&lt;/div&gt;
&lt;div class=&quot;section&quot; id=&quot;open-source&quot;&gt;

&lt;p&gt;Elm claims to be Open Source - for example, see the &lt;a class=&quot;reference external&quot; href=&quot;https://github.com/elm/compiler/blob/master/LICENSE&quot;&gt;licence&lt;/a&gt; on the compiler, and the fact that Evan delivers talks about Elm entitled things like &lt;a class=&quot;reference external&quot; href=&quot;https://www.youtube.com/watch?v=o_4EX4dPppA&quot;&gt;The Hard Parts of Open Source&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Bu I think this claim is increasingly hard to defend. For me, real Open Source goes beyond a &lt;span class=&quot;caps&quot;&gt;LICENSE&lt;/span&gt; file.&lt;/p&gt;
&lt;div class=&quot;section&quot; id=&quot;development-process&quot;&gt;
&lt;h3&gt;&lt;a class=&quot;toc-backref&quot; href=&quot;https://lukeplant.me.uk/blog/posts/why-im-leaving-elm/#id20&quot;&gt;Development process&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;This first point may be more of a personal preference, but for a start, I’d like to see some kind of openness in the development process before I considered something to be Open Source. In Elm, you cannot even see any records of the core team’s decision making process, let alone contribute to it (see section below for the latter). In the past, there used to the &lt;a class=&quot;reference external&quot; href=&quot;https://groups.google.com/forum/#!forum/elm-dev&quot;&gt;elm-dev Google group&lt;/a&gt;, but it is closed now, and it was &lt;a class=&quot;reference external&quot; href=&quot;https://groups.google.com/forum/#!msg/elm-dev/oZ3xW_nMPNo/0y8j-N8HCQAJ&quot;&gt;never&lt;/a&gt; a place where Elm’s design was discussed or you could contribute in that way.&lt;/p&gt;
&lt;p&gt;Today, there is no forum I can find where I can meaningfully see how Elm’s development decisions are made. &lt;a class=&quot;reference external&quot; href=&quot;https://discourse.elm-lang.org/&quot;&gt;Discourse&lt;/a&gt; is not designed for this kind of interaction at all (e.g. all threads close after 10 days automatically, there is no category for development discussions etc.), and Slack is obviously not appropriate for a multitude of reasons.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;section&quot; id=&quot;forkability&quot;&gt;
&lt;h3&gt;&lt;a class=&quot;toc-backref&quot; href=&quot;https://lukeplant.me.uk/blog/posts/why-im-leaving-elm/#id21&quot;&gt;Forkability&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Another requirement for Open Source in my book is forkability. Having forks &lt;em&gt;per se&lt;/em&gt; is not necessarily helpful or required, but it should be &lt;strong&gt;possible&lt;/strong&gt; to fork or patch it.&lt;/p&gt;
&lt;p&gt;As part of my investigations to make it possible for others to try out elm-fluent on Elm 0.19, I considered the possibility of patching Elm (a patch, not a long term fork). I shared this on a thread completely outside the normal Elm forums (on &lt;a class=&quot;reference external&quot; href=&quot;https://github.com/gdotdesign/elm-github-install/issues/62&quot;&gt;an elm-github-install issue&lt;/a&gt;). Richard Feldman arrived to attempt to shut this down — how he knew about it, or thought he had the right to do this, I have no idea. &lt;a class=&quot;reference external&quot; href=&quot;https://github.com/gdotdesign/elm-github-install/issues/62#issuecomment-415860947&quot;&gt;His comment&lt;/a&gt; to me made it clear that I will be &lt;em&gt;persona non grata&lt;/em&gt; in the Elm community if I patch the Elm compiler.&lt;/p&gt;
&lt;p&gt;The earlier versions of his comment were much more strongly worded, for which Richard apologised to me, but the intention of the revised version is the same, and I know where I stand. The core Elm developers deliberately and unnecessarily introduced restrictions into Elm 0.19 in order to stop you using features that they want to reserve for their exclusive use, but if you find and share any workaround for these things that have broken your project, &lt;strong&gt;you&lt;/strong&gt; are the one who will be considered an aggressor, the one who has ‘attacked’ Elm.&lt;/p&gt;
&lt;p&gt;Threatening a person with exclusion from a community for attempting to patch the source code is quite antithetical to the spirit of Open Source, as far as I can see. It is the opposite of behaviour you’ll see in other Open Source projects. For example, Dropbox &lt;a class=&quot;reference external&quot; href=&quot;https://blogs.dropbox.com/tech/2018/09/how-we-rolled-out-one-of-the-largest-python-3-migrations-ever/&quot;&gt;created their own Python 2 fork&lt;/a&gt; without the smallest thought of needing to apologise for such behaviour, and multiple competing implementations are considered healthy.&lt;/p&gt;
&lt;p&gt;An Open Source project should be forkable — the leaders need to accept people’s right to do that, and the community also needs to be ready to do it if they decide that the current leadership are not serving their interests. This is a big part of the point of Open Source. For example, people contributed to OpenOffice although it was ‘owned’ by a company, because the licence meant that if they started throwing their weight around in unwelcome ways (as they did), the community was able to fork it and carry on (as they did). A well run Open Source project will understand that this is an essential feature of Open Source, and welcome it, rather than resort to threats to maintain control.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;section&quot; id=&quot;discrimation&quot;&gt;
&lt;h3&gt;&lt;a class=&quot;toc-backref&quot; href=&quot;https://lukeplant.me.uk/blog/posts/why-im-leaving-elm/#id22&quot;&gt;Discrimation&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;The &lt;a class=&quot;reference external&quot; href=&quot;https://opensource.org/osd&quot;&gt;Open Source Definition&lt;/a&gt; written by &lt;span class=&quot;caps&quot;&gt;OSI&lt;/span&gt;, who are generally recognised as some kind of an authority in this area, includes “No Discrimination Against Persons or Groups” and “No Discrimination Against Fields of Endeavor” as items in its list of requirements for an Open Source licence. Technically Elm doesn’t fall foul of this, because Elm’s licence itself has no restrictions. But to me, it is pretty clear that building discrimination against certain libraries into the compiler (i.e. restriction of features for everything except the core libraries or libraries from certain GitHub organisations, which is what Elm 0.19 attempts to do) is clearly against the spirit of &lt;span class=&quot;caps&quot;&gt;OSI&lt;/span&gt;’s definition.&lt;/p&gt;
&lt;p&gt;In thinking about this, we do have to distinguish between primary and secondary users, whose rights are in tension. For example, if I run some Open Source blogging software, I can blog about any topic I like, and I can also heavily censor/moderate any comment from other users if I so choose. As the primary user, I get to choose how I use the software, and with &lt;span class=&quot;caps&quot;&gt;OSI&lt;/span&gt;’s definition, a licence is not Open Source if it tries to stop me from doing that on the basis of certain religious/political views etc. The &lt;span class=&quot;caps&quot;&gt;OSI&lt;/span&gt;’s definition gives all rights to the primary users, not the secondary users.&lt;/p&gt;
&lt;p&gt;So, I am a primary user of the Elm compiler, but a secondary user of &lt;a class=&quot;reference external&quot; href=&quot;https://package.elm-lang.org/&quot;&gt;package.elm-lang.org&lt;/a&gt;. For this reason I have no complaints about the fact that not all users of package.elm-lang.org have the same rights — that some can upload core packages and others cannot.&lt;/p&gt;
&lt;p&gt;At the same time, we all recognise that when proprietary services give away their client tools as Open Source software, this is really a token gesture, or done just to smooth the wheels for their proprietary service. For example, you would never claim “it’s Open Source” as a benefit of using &lt;a class=&quot;reference external&quot; href=&quot;https://github.com/boto/boto/&quot;&gt;boto&lt;/a&gt; (a Python front-end to Amazon Web Services).&lt;/p&gt;
&lt;p&gt;So, given that:&lt;/p&gt;
&lt;ul class=&quot;simple&quot;&gt;&lt;li&gt;the compiler you get when you install Elm is deliberately crippled (so that you cannot make bindings to browser APIs, for example), despite this being a necessary and present compiler feature,&lt;/li&gt;
&lt;li&gt;the compiler hard codes &lt;tt class=&quot;docutils literal&quot;&gt;&lt;span class=&quot;pre&quot;&gt;https://package.elm-lang.org&lt;/span&gt;&lt;/tt&gt; as a source of packages, which you have to use to get any functioning program,&lt;/li&gt;
&lt;li&gt;it gives you no ability to configure this source (and in fact you have no ability to turn off connecting to it),&lt;/li&gt;
&lt;li&gt;and you are a secondary user of &lt;tt class=&quot;docutils literal&quot;&gt;&lt;span class=&quot;pre&quot;&gt;package.elm-lang.org&lt;/span&gt;&lt;/tt&gt;, lacking key rights that other users have,&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;…then I think it is pretty inescapable that this is an essentially proprietary system. I’m not a Free Software purist type, so I don’t think that proprietary software is evil. But if Elm started out as an Open Source project, attracted users to it on that basis, but no longer meets the basic expectations of what those words mean to everyone else, we do have a problem. At the very least, potential users and contributors should be aware of this.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;section&quot; id=&quot;leadership-style&quot;&gt;

&lt;img alt=&quot;Calvin: “I've at peace with the world, I'm completely serene.” Hobbes: “Why's that?” Calvin: “I've discovered my purpose in life. I know why I was put here and why everything exists.” Hobbes: “Oh really?” Calvin: “Yes, I am here so everybody can do what I want.” Hobbes: “It's nice to have that cleared up.” Calvin: “Once everyone accepts it, they'll be serene too.”&quot; class=&quot;align-center&quot; src=&quot;https://lukeplant.me.uk/blogmedia/calvin_and_hobbes_serene.gif&quot;/&gt;&lt;p&gt;The leadership style in Elm is extremely aggressive and authoritarian.&lt;/p&gt;
&lt;p&gt;By that I do not mean impolite or rude. It is almost always very civil. But still ultimately aggressive and controlling.&lt;/p&gt;
&lt;p&gt;I gave an example above, which happened even outside the Elm forums. On Elm Discourse itself things are more tightly controlled. Within my first week of starting to contribute I had a post deleted and was blocked from contributing for a week. My offense was that, after the core team had announced their plans to restrict native modules in Elm 0.19, I posted a solution to someone’s problem that made use of native modules.&lt;/p&gt;
&lt;p&gt;You will find many similar reports across different sites on the internet (and I have more examples below). Sometimes you will find denials or defences from the core developers, but I really don’t think you can escape the conclusion that Elm has a very threatening, aggressive leadership style – for example, see &lt;a class=&quot;reference external&quot; href=&quot;https://news.ycombinator.com/item?id=17847124&quot;&gt;the edit at the bottom of this anonymous comment on a Hacker News post&lt;/a&gt;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;There are tons of bugs in 0.18 compiler and 0.18 libraries that will never be fixed. Many of those have / had pull requests by the community members open for more than a year but they were never merged. These are tiny fixes, not 200 lines of code adding a new feature. There’s no way to fork a package and apply a patch in 0.19 if the package contains native code. All you can do is report the bug and hope Evan fixes it before your deadline (which ranges from 1 week to 3 years).&lt;/p&gt;
&lt;p&gt;Edit: Using a throwaway so I don’t get banned from Elm Discourse and /r/elm. I still have production applications using Elm.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;In what kind of community is it necessary for people to anonymise their criticism in this way?&lt;/p&gt;
&lt;p&gt;Most of the time you won’t see this behaviour. If you never have reason to disagree with the leadership, you will likely find them very friendly and helpful. If a leadership style was judged by how the leaders behave when everyone agrees with them and does what they say, my assessment would be quite different. But of course, that’s not how you judge leadership styles.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;section&quot; id=&quot;why-don-t-you-just-ing&quot;&gt;&lt;span id=&quot;why-dont-you-just&quot;/&gt;

&lt;p&gt;I’ve borrowed this phrase from Evan’s talk on &lt;a class=&quot;reference external&quot; href=&quot;https://www.youtube.com/watch?v=o_4EX4dPppA&quot;&gt;The Hard Parts of Open Source&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Evan is complaining about people who make inadequately informed “Why don’t you just …” suggestions that take 20 seconds to make, while it takes 20 hours to explain why the suggestion won’t cut it.&lt;/p&gt;
&lt;p&gt;Despite knowing how incredibly frustrating this is, Evan and the core Elm team do the same thing to their community, but taken to a whole new level. They do not say “Why don’t you just”, they say “You must just” — despite not knowing anything about the rest of the project-specific constraints that you are taking into account and couldn’t explain — and then they build that opinion into the compiler itself.&lt;/p&gt;
&lt;p&gt;Now, if they were simply making design decisions about the language that they felt were right, this would be bearable — we’d just have to disagree about those language features. It is of course the job of language designers to decide which features go in and which get the cut. But in fact they &lt;strong&gt;know&lt;/strong&gt; for their own purposes that these solutions do not suffice, and therefore keep the features in, but reserve them for their own use.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;section&quot; id=&quot;fairness&quot;&gt;

&lt;p&gt;Distinct from whether you believe in Open Source or not, or whether Elm should be considered Open Source or not, the principle of fairness is an important enough ethical principle that it deserves it’s own section. The decision to limit certain features to certain people (i.e. GitHub organisations) goes right against this principle.&lt;/p&gt;
&lt;p&gt;(I’m deliberately using ‘fairness’ rather than ‘equality’, because in some senses it is impossible to treat people equally. If you recognise some people as leaders, or as worth listening to, and others as not, are you treating people equally? If you allow some people to publish standard library code, but not others, is that equality? Clearly not, but you can still treat people fairly without treating them equally).&lt;/p&gt;
&lt;p&gt;I’ll illustrate with two libraries:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;The first&lt;/strong&gt; is Evan’s &lt;a class=&quot;reference external&quot; href=&quot;https://github.com/elm-explorations/markdown&quot;&gt;markdown&lt;/a&gt; library. It bundles a minified Javascript library, and uses some kernel code and other internals so that you can use this fast, optimised Markdown parser with an Elm &lt;span class=&quot;caps&quot;&gt;API&lt;/span&gt; as a pure function. There is no way that you can characterise this library as merely a “compiler internal” — as Richard Feldman tried to claim was the only valid use case for kernel code.&lt;/p&gt;
&lt;p&gt;Since the restriction on kernel code in Elm 0.19, this has been part of &lt;tt class=&quot;docutils literal&quot;&gt;&lt;span class=&quot;pre&quot;&gt;elm-explorations&lt;/span&gt;&lt;/tt&gt;, and its description says it exists “for historical reasons” — but that is just dodging the issue. You can delete a repo with a few clicks. Why does it exist then? It’s not hard to imagine the kind of reasons:&lt;/p&gt;
&lt;ul class=&quot;simple&quot;&gt;&lt;li&gt;Evan wanted to write Markdown and convert it to &lt;span class=&quot;caps&quot;&gt;HTML&lt;/span&gt; within an Elm app.&lt;/li&gt;
&lt;li&gt;There was a Javascript library &lt;a class=&quot;reference external&quot; href=&quot;https://github.com/markedjs/marked&quot;&gt;marked&lt;/a&gt; that did the hard work, and did it well.&lt;/li&gt;
&lt;li&gt;In Elm he wanted a pure function (with signature &lt;tt class=&quot;docutils literal&quot;&gt;String &lt;span class=&quot;pre&quot;&gt;-&amp;gt;&lt;/span&gt; Html a&lt;/tt&gt;), because there is no reason why it shouldn’t be, and that would clearly be the nicest interface. In addition, he wanted to use it in code that would double as demo code, since &lt;a class=&quot;reference external&quot; href=&quot;https://github.com/elm/elm-lang.org/&quot;&gt;it is used in elm-lang.org&lt;/a&gt;, therefore it needed to clearly demonstrate the Elm architecture, rather than obscure it, as would happen if any other workaround for Javascript interop were used.&lt;/li&gt;
&lt;li&gt;He wanted it soon.&lt;/li&gt;
&lt;li&gt;It would take a long time to rewrite that Javascript code as a pure Elm module.&lt;/li&gt;
&lt;li&gt;Every minute he spent rewriting that working code as pure Elm is time that could be spent doing potentially more valuable things, for himself and for the Elm community.&lt;/li&gt;
&lt;li&gt;And a rewritten version might well be slow and buggy too — the original has been bug fixed and hand-optimized pretty well already, and it is very well known that in some situations pure functional languages can have serious problems producing performant code. Translating optimized &lt;span class=&quot;caps&quot;&gt;JS&lt;/span&gt; code into Elm is pretty hard too…&lt;/li&gt;
&lt;li&gt;Maybe Evan didn’t actually need to extend it in interesting ways, so for his usages at least its not going to benefit much from an Elm implementation. Therefore someone else, with more interest in an extendable Elm implementation, would probably be in a better position to do the rewrite.&lt;/li&gt;
&lt;li&gt;Of course, there are risks… he might have to fix that bit of native code every time there is a new compiler version…&lt;/li&gt;
&lt;li&gt;But the entire wrapper is pretty small, so even if he had to rewrite it, it’s not a huge amount of work (&lt;a class=&quot;reference external&quot; href=&quot;https://github.com/elm-explorations/markdown/commit/cf49e769858c6d6ef766666440aa5c840fe79089&quot;&gt;0.15&lt;/a&gt;, &lt;a class=&quot;reference external&quot; href=&quot;https://github.com/elm-explorations/markdown/commit/58297e2e075f6c7d0ef0148a6b516f7d9c535d6c&quot;&gt;0.17&lt;/a&gt;, &lt;a class=&quot;reference external&quot; href=&quot;https://github.com/elm-explorations/markdown/commit/3778417e9b159d8544a8fa9dc60036ca26f46bf8&quot;&gt;0.19 part 1&lt;/a&gt;, &lt;a class=&quot;reference external&quot; href=&quot;https://github.com/elm-explorations/markdown/commit/0744b0fc4dd724df3f1fc4d9dd9c1db1544d9552&quot;&gt;0.19 part 2&lt;/a&gt;)&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;This is all solid reasoning — and the decision to do this benefits everyone involves. The last thing I want is for Evan to stop doing other important things for Elm so he can rewrite already working code!&lt;/p&gt;
&lt;p&gt;What is the problem? The &lt;strong&gt;favouritism and unfairness&lt;/strong&gt; that puts the needs of the core Elm developers (and their friends — those who can create repos in certain GitHub organisations) above everyone else. &lt;strong&gt;Because every single reason why Evan may have chosen this course also applies to other developers as well&lt;/strong&gt;, with only small modifications. But instead of realising “hmm, sometimes developers are going to benefit from an escape hatch like this, so I shouldn’t try to stop them from using it”, he locked down the escape hatch for everyone but himself and his friends, and moved the code to &lt;tt class=&quot;docutils literal&quot;&gt;&lt;span class=&quot;pre&quot;&gt;elm-explorations&lt;/span&gt;&lt;/tt&gt; so that it would continue to work.&lt;/p&gt;
&lt;p&gt;In addition to this, other people in the community who have, in the past, chosen to do exactly the same thing as Evan and use kernel code to make an Elm wrapper for a Javascript library, are effectively accused of ‘blocking’ Elm, of doing what is bad for the community (&lt;a class=&quot;reference external&quot; href=&quot;https://groups.google.com/forum/#%21msg/elm-dev/1JW6wknkDIo/H9ZnS71BCAAJ&quot;&gt;“Choose not to block. Choose to make a cool thing in Elm”&lt;/a&gt;). The hypocrisy here is pretty galling. Ultimately we have to say he is using his position as leader to bully people into writing libraries for his project, even when it is against their interests.&lt;/p&gt;
&lt;p&gt;You might argue that we’re not all writing demo code to illustrate The Elm Architecture, and that would be right — we are doing something much more important: writing production code. If you think that demo code is more important than production code in terms of needing good architecture, then you have your priorities upside down.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;The second library&lt;/strong&gt; is Evan’s &lt;a class=&quot;reference external&quot; href=&quot;https://github.com/elm/parser&quot;&gt;elm/parser&lt;/a&gt;. This library, in common with many similar libraries from other languages, like Haskell’s &lt;a class=&quot;reference external&quot; href=&quot;https://hackage.haskell.org/package/parsec&quot;&gt;Parsec&lt;/a&gt;, defines &lt;a class=&quot;reference external&quot; href=&quot;https://github.com/elm/parser/blob/7506b07eaa93a93d13b508b948c016105b0953c8/src/Parser.elm#L55&quot;&gt;a couple of custom operators&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Custom operators are now limited to a few GitHub repos in Elm 0.19 and later. This means that if you want to write your own parsing library, you will have a hard time competing with Evan’s.&lt;/p&gt;
&lt;p&gt;Why is this important? For one thing a community may well need more than one parsing library. This is not a theoretical concern. As &lt;a class=&quot;reference external&quot; href=&quot;https://gist.github.com/evancz/769bba8abb9ddc3bf81d69fa80cc76b1#gistcomment-2986411&quot;&gt;mzero commented&lt;/a&gt;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Of all the changes in 0.19, this is the one that most hurt my code: I have parser combinator library, and used just two custom operators, for the very reasons that Evan points out in at the top.&lt;/p&gt;
&lt;p&gt;Now I learn that elm/parser can, and does, define two operators for parsing, for the same reasons my library had done so. There are indeed times when custom embedded languages with custom operators are worth the mental effort on the programming staff. Parsing is one of them, which Evan acknowledges, and indeed uses in elm/parser.&lt;/p&gt;
&lt;p&gt;However, it is not realistic to assume that elm/parser will become the only parsing package we ever need. For one, it only works on String. Parsing over byte arrays is quite common, (and what mine did). Even if elm/parse had been parameterized on the stream type - there are still differing implementation and functionality tradeoffs in parsers (backtracking, error tracking, error recovery, etc..) that make different parser libraries useful even they support the same stream type.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;So the current policy is bad for the Elm ecosystem, and discriminates against the needs of some users who don’t happen to have exactly the same needs as the core Elm team.&lt;/p&gt;
&lt;p&gt;But more important to me here is the principle of fairness. It seems that Evan and the core team have forgotten that languages, especially Open Source ones, operate as platforms, and in these platforms contributions from other developers and reputation are critical.&lt;/p&gt;
&lt;p&gt;If I am a library author, I need contributions from other developers for my library to be up to scratch. Also, if I can create a popular and well-recognised library, my reputation improves, and I may be able to get sponsors for working on the library, or other work based off my reputation. This is a hugely important part of the currency of Open Source work. (This is perhaps not a sustainable model of funding Open Source, by itself, but that’s the way it is right now, and Evan ought to understand this, given that No Red Ink currently sponsors his work on Elm.)&lt;/p&gt;
&lt;p&gt;So having a level playing field for library authors is vital. Instead, Evan has reserved some features for himself (and friends). As well as custom operators, &lt;tt class=&quot;docutils literal&quot;&gt;elm/parser&lt;/tt&gt; also benefits from &lt;a class=&quot;reference external&quot; href=&quot;https://github.com/elm/parser/blob/7506b07eaa93a93d13b508b948c016105b0953c8/src/Elm/Kernel/Parser.js&quot;&gt;kernel code&lt;/a&gt; for some performance critical parts. How are you going to compete with this?&lt;/p&gt;
&lt;p&gt;Fairness must be a central principle in any Open Source project. But if you choose to model your leadership after a dictatorship, it is critical to pay special attention to it.&lt;/p&gt;
&lt;p&gt;If you believe that your own good intentions are enough to stop any abuses of power (which include neglect), then you must be completely ignorant of the human condition, and of why we have concepts like democracy. The fact that both “tyrant” and “despot” originally meant simply “one who rules with absolute power”, without the overtones of cruelty that now exist, ought to be a clue.&lt;/p&gt;
&lt;p&gt;It is of course not possible to be perfectly fair, but you can try, and deliberately building discriminatory restrictions into a compiler, as they have done, is going out of your way to be unfair.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;section&quot; id=&quot;contribution-process&quot;&gt;

&lt;img alt=&quot;Excerpt from LEGO Movie: Unikitty: Hi! I am Princess Unikitty, and I welcome you all to Cloud Cuckoo Land! Emmet: So there are no signs on anything. How does anyone know what not to do? Unikitty: Here in Cloud Cuckoo Land, there are no rules: There's no government, no baby sitters, no bedtimes, no frowny faces, no bushy mustaches, and no negativity of any kind. Lucy: You just said the word &amp;quot;no&amp;quot; like a thousand times. Unikitty: And there's also no consistency. Batman: [the clown and the lizard man are dancing around him] I hate this place. Unikitty: Any idea is a good idea except the non-happy ones. Those we push down deep inside where you'll never, ever, ever, EVER find them!&quot; class=&quot;align-center&quot; src=&quot;https://lukeplant.me.uk/blogmedia/cloud_cuckoo_land.png&quot;/&gt;&lt;p&gt;Elm has no defined process for contributing to it. The closest you will find is &lt;a class=&quot;reference external&quot; href=&quot;https://discourse.elm-lang.org/t/building-trust-what-has-worked/975&quot;&gt;this post on “Building Trust: What Has Worked” by Richard Feldman&lt;/a&gt;. This is linked from the &lt;a class=&quot;reference external&quot; href=&quot;https://elm-lang.org/community&quot;&gt;official Elm web page&lt;/a&gt; in the section regarding contributing to Elm itself.&lt;/p&gt;
&lt;p&gt;Instead of a process, you are told you need to build trust with the core developers (which I’ve spectacularly failed at). “Elm is built on relationships”.&lt;/p&gt;
&lt;p&gt;I can understand why people think this sounds nice, but in practice it leads to an awful lot of frustration.&lt;/p&gt;
&lt;p&gt;Even worse, it means that the top tiers of the community will quickly become an Old Boy’s network. This is the opposite of the kind of community that I’ve enjoyed elsewhere in the Open Source world.&lt;/p&gt;
&lt;p&gt;Other Open Source projects have recognised that having a clearly documented contribution process is a good thing, and strive to keep that process working well. On GitHub this has standardised into a &lt;tt class=&quot;docutils literal&quot;&gt;&lt;span class=&quot;caps&quot;&gt;CONTRIBUTING&lt;/span&gt;.md&lt;/tt&gt; file. Sarah Dresner has an &lt;a class=&quot;reference external&quot; href=&quot;https://css-tricks.com/how-to-contribute-to-an-open-source-project/&quot;&gt;excellent guide on contributing to Open Source projects&lt;/a&gt;, but virtually nothing in it applies to Elm.&lt;/p&gt;
&lt;p&gt;The core Elm developers have rejected the accumulated wisdom of all these projects and instead put huge walls around contributing. My experience is that these walls, while blocking many people, are especially effective at blocking people who are already in minorities in technology communities. People who are already struggling to find their way in — for example due to being a non-native English speaker, or feeling in a minority for some other reason — will find the Elm contribution non-process an impossible barrier. &lt;strong&gt;In reality there always are processes and rules&lt;/strong&gt; (see later), &lt;strong&gt;it’s just that the Elm leadership are blind to them. And unwritten rules are a perfect way to discriminate, knowingly or unknowingly.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;All the while, the core team have effectively absolved themselves of any responsibility to potential contributors — where there is no process other than “relationships”, any failure of this process can be blamed on other people failing to build those relationships.&lt;/p&gt;
&lt;p&gt;I completely agree that relationships are key to Open Source projects, but relationships are not in themselves a process. In almost every other sphere of life (trading, government, starting a business etc.) if the only answer to the question of how to do anything was “relationships” — in other words, “it’s all about who you know” — you would not be optimistic about the ethics of how things were operating.&lt;/p&gt;
&lt;/div&gt;

&lt;div class=&quot;section&quot; id=&quot;communication&quot;&gt;

&lt;p&gt;I find certain elements about how the core Elm team communicate very hard to stomach.&lt;/p&gt;
&lt;p&gt;For example, take for instance &lt;a class=&quot;reference external&quot; href=&quot;https://elm-lang.org/news/small-assets-without-the-headache&quot;&gt;Evan’s blog post about Elm 0.19&lt;/a&gt;. He claims:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Every package on package.elm-lang.org is written entirely in Elm&lt;/strong&gt;. That means we have a 100% guarantee that there is nothing weird going on in any of your dependencies, so we can cut it up just as easily as your application. If packages contained arbitrary JavaScript code, we would inherit all the same optimization challenges and have to be more conservative.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Notice the emphasis, which is original. And this claim is repeated further down the page:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Again, this works across the entire Elm ecosystem because every single package on package.elm-lang.org written completely in Elm.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;You only have to click a few times on &lt;a class=&quot;reference external&quot; href=&quot;https://package.elm-lang.org/&quot;&gt;package.elm-lang.org&lt;/a&gt; to find some view source links, and discover that of the 6 “popular packages” listed at the top, 5 of them are partly written in Javascript — &lt;a class=&quot;reference external&quot; href=&quot;https://github.com/elm/core/tree/1.0.2/src/Elm/Kernel&quot;&gt;core&lt;/a&gt;, &lt;a class=&quot;reference external&quot; href=&quot;https://github.com/elm/json/tree/1.1.3/src/Elm/Kernel&quot;&gt;json&lt;/a&gt;, &lt;a class=&quot;reference external&quot; href=&quot;https://github.com/elm/browser/tree/1.0.1/src/Elm/Kernel&quot;&gt;browser&lt;/a&gt;, &lt;a class=&quot;reference external&quot; href=&quot;https://github.com/elm/url/tree/1.0.0/src/Elm/Kernel&quot;&gt;url&lt;/a&gt;, &lt;a class=&quot;reference external&quot; href=&quot;https://github.com/elm/http/tree/2.0.0/src/Elm/Kernel&quot;&gt;http&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;I think it is just about possible to defend Evan’s false statements here (which I reported to Richard Feldman many months ago) as a kind of marketing hyperbole.&lt;/p&gt;
&lt;p&gt;For myself, however, I prefer and would expect technical blog posts to have a higher regard for accuracy, especially when you are talking about something that directly relates to a very controversial decision. When you read posts from the core team, instead of being able to take them as a reliable source of information about how Elm works, it becomes more like deciphering political party propaganda.&lt;/p&gt;
&lt;p&gt;Or take &lt;a class=&quot;reference external&quot; href=&quot;https://gist.github.com/evancz/769bba8abb9ddc3bf81d69fa80cc76b1&quot;&gt;Evan’s post about the removal of custom operators&lt;/a&gt;. He starts with a pretty dubious statement:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Elm 0.19 removes the syntax for user-defined operators.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;What he means is that the syntax is still very much there, and very much used by some libraries, but not available for most people. Leaving that aside, let’s look at one angle of what follows — those who want to define custom operators for use in maths. Here are some excerpts:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Usage in Packages&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Elm has had this feature for a while, so I studied how it has been used so far in packages.&lt;/p&gt;
&lt;p&gt;…&amp;lt;snip&amp;gt;…&lt;/p&gt;
&lt;ol class=&quot;arabic simple&quot; start=&quot;3&quot;&gt;&lt;li&gt;Math Operators - Some packages are for math. Vector math. Matrix Math. They generally use operators like &lt;tt class=&quot;docutils literal&quot;&gt;|+|&lt;/tt&gt; or &lt;tt class=&quot;docutils literal&quot;&gt;|*|&lt;/tt&gt; that match the cultural norms. This is not as common as I would have hoped actually! More math!&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;…&amp;lt;snip&amp;gt;…&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Root Design Goal&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Each of these categories stems from a reasonable design goal. I will try to outline the design goal, and then point a path towards acheiving that goal in a nicer way:&lt;/p&gt;
&lt;p&gt;…&amp;lt;snip&amp;gt;…&lt;/p&gt;
&lt;ol class=&quot;arabic simple&quot; start=&quot;3&quot;&gt;&lt;li&gt;I want to do math! I really like this goal. I think languages like Julia have done an excellent job at overloading &lt;tt class=&quot;docutils literal&quot;&gt;+&lt;/tt&gt; and &lt;tt class=&quot;docutils literal&quot;&gt;*&lt;/tt&gt; in a reasonable way. Their approach is really lovely, but we would have to lose Elm’s type system to match them. Point being, rather than making &lt;tt class=&quot;docutils literal&quot;&gt;|+|&lt;/tt&gt; and &lt;tt class=&quot;docutils literal&quot;&gt;|*|&lt;/tt&gt; as a stopgap, perhaps it is possible to think about the broader question in a comprehensive way. Should there be a way to overload &lt;tt class=&quot;docutils literal&quot;&gt;+&lt;/tt&gt; for vector and matrix math? How would that work? How would you multiply a vector by a scalar? Perhaps the best design is to restore user-defined operators for bracketed math operations like &lt;tt class=&quot;docutils literal&quot;&gt;|+|&lt;/tt&gt; and &lt;tt class=&quot;docutils literal&quot;&gt;&lt;span class=&quot;pre&quot;&gt;|-|&lt;/span&gt;&lt;/tt&gt; with certain types? Or maybe it can just be done in a really nice way with a library. Worth exploring!&lt;/li&gt;
&lt;/ol&gt;&lt;/blockquote&gt;
&lt;p&gt;Do you see how enthusiastic Evan is about mathematics? Look at all those exclamation marks! And look at all those question marks — can you see how open he is to the community and their ideas?&lt;/p&gt;
&lt;p&gt;But what actually just happened here?&lt;/p&gt;
&lt;p&gt;If you are trying to do maths with Elm, you face some significant problems. First, with only some very basic operator overloading baked into the language (mathematics operators can work with Int or Float types), if you want to do other polymorphic operations using maths Elm isn’t much fun. In addition, like most pure functional languages, it presents significant challenges when trying to do high performance work, but Elm is worse than most because there are no escape hatches, and the compiler is still in its infancy when it comes to optimisations (like eliminating intermediate data structures). With Elm 0.18, there were a couple of plus points:&lt;/p&gt;
&lt;ul class=&quot;simple&quot;&gt;&lt;li&gt;Although there was no stable interface for importing functions written in Javascript (or compile-to-Javascript languages), there was the unstable interface known as native modules.&lt;/li&gt;
&lt;li&gt;You could write custom operators to make maths-y code at least look a bit nicer and be more readable.&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;Both have these have been taken away (for you, not for him). Evan says at the top he is going to “point a path towards achieving that goal in a nicer way”, but all he actually does for these users is leave them with a bunch of questions, and suggestions that they can do nothing about. “Worth exploring!” sounds like an invitation to explore, but once you’ve understood the context, Evan is the only person who is actually empowered to do anything.&lt;/p&gt;
&lt;p&gt;All of this just leads to the feeling that you are being gas-lighted. Do you think that Evan just added a completely unnecessary restriction that made your life much harder, taking away genuinely useful things for people like you trying to do mathematics, without any compensating improvements? You must be imagining things — he &lt;strong&gt;likes&lt;/strong&gt; math, he’s &lt;strong&gt;encouraging&lt;/strong&gt; it. “More math!” he said, it’s there in black and white! With lots of friendly exclamation marks too!&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;section&quot; id=&quot;an-analogy&quot;&gt;

&lt;p&gt;In evaluating the ethical issues I have, I find an analogy to government helpful.&lt;/p&gt;
&lt;p&gt;Suppose you have a leader whose job it is to make policies for the people. Whether this country functions as a democracy or not, you cannot expect that everyone in the country will have equal access to the leader. It would be neither desirable nor possible for everyone to be able to influence the leader to the same degree — a trusted advisor or even a spouse is inevitably going to have more influence.&lt;/p&gt;
&lt;p&gt;In the Elm community, they recognise this by talking about the need for relationships. They go further however — they pretty much make it a &lt;strong&gt;policy&lt;/strong&gt; that the leader will only listen to a very small group of people. To me, that is pretty unwise, but let’s say we can live with that for now.&lt;/p&gt;
&lt;p&gt;Suppose, now, the leader is a dictator, and they make laws which give preferential treatment to a group of people, like tax breaks. If we are looking for fairness in this government, such laws are immediately suspect — but could perhaps be justified if the preferential treatment is justified on the basis of the kind of work being done, and not simply certain people (e.g. everyone in the food industry gets certain tax breaks because of some special need in the country, and we can objectively decide who will get the tax break). But if the special treatment is limited to the leader and their friends, then we have definitely lost the plot ethically.&lt;/p&gt;
&lt;p&gt;The leaders in our hypothetical dictatorship already have special privilege by virtue of being lawmakers. The laws of the country, along with services provided by the government etc. (which correspond to the source code produced in this analogy) should apply equally to everyone, and whether it is a dictatorship or democracy this rule applies if we believe in fairness.&lt;/p&gt;
&lt;p&gt;The beauty of Open Source software is the way in which it can benefit anyone. My human relationships as a software author are inherently limited by human nature — I can’t build a relationship of trust with everyone. But the source code I produce does &lt;strong&gt;not&lt;/strong&gt; have those limitations. The unavoidable inequality intrinsic to the necessity of human relationships in a leadership structure cannot be used as an excuse for deliberately propagating unfairness by adding discriminatory restrictions into things I produce for people outside of that structure.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;section&quot; id=&quot;worked-example-intl&quot;&gt;

&lt;p&gt;To see what all of this looks like in practice, take the issue of needing a wrapper for &lt;a class=&quot;reference external&quot; href=&quot;https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Intl&quot;&gt;Intl&lt;/a&gt;, which I’ve mentioned a couple of times above.&lt;/p&gt;
&lt;p&gt;This has been a long standing problem for Elm users. Before Elm 0.19 it was solved by being able to write kernel code yourself to wrap &lt;tt class=&quot;docutils literal&quot;&gt;Intl&lt;/tt&gt; yourself, or use &lt;a class=&quot;reference external&quot; href=&quot;https://github.com/vanwagonet/elm-intl&quot;&gt;elm-intl&lt;/a&gt; and install it with &lt;tt class=&quot;docutils literal&quot;&gt;&lt;span class=&quot;pre&quot;&gt;elm-github-install&lt;/span&gt;&lt;/tt&gt;.&lt;/p&gt;
&lt;p&gt;Several people tried to do something about this:&lt;/p&gt;
&lt;p&gt;Unfortunately, Luke Westby’s response illustrated so many of the things that are wrong with the Elm leadership. I’ll quote most of it below:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;toastal:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;what steps are required to get this on the radar of the Elm dev team&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;It’s already on our radar.&lt;/p&gt;
&lt;p&gt;toastal:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;it seems many seem to agree that leveraging the browser’s Intl feature is the right thing to do&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;So do we.&lt;/p&gt;
&lt;p&gt;toastal:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;a wrapped implementation&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Making a wrapper for some browser &lt;span class=&quot;caps&quot;&gt;API&lt;/span&gt; and posting it is not the right way to propose something for the platform. We looked at &lt;a class=&quot;reference external&quot; href=&quot;https://github.com/vanwagonet/elm-intl&quot;&gt;https://github.com/vanwagonet/elm-intl&lt;/a&gt; and quickly decided not to consider it further because it just wraps the Intl &lt;span class=&quot;caps&quot;&gt;API&lt;/span&gt; instead of serving to explain what an ideal Elm &lt;span class=&quot;caps&quot;&gt;API&lt;/span&gt; that uses Intl could be. We think this is a pretty hard question in its own right considering how much stuff Intl actually does.&lt;/p&gt;
&lt;p&gt;toastal:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;v0.19 is what is going to kill the current solution (3rd party native code)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;It seems to me like this thread is really about how to do something in 0.19 that uses Native modules. The answer is to use ports or custom elements. This is going to happen for other people’s programs and other repos that distribute third party Native code. Intl isn’t special in that regard, nor is it uniquely poorly suited for ports and custom elements.&lt;/p&gt;
&lt;p&gt;If you want to help the process along while we finish 0.19 the first step is always a literature review. Find ways that other languages and platforms address the specific i18n use cases that you have in mind (Intl does a lot of stuff that we consider distinct APIs), present what you learned and share your sources.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Then immediately after he posted:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;This thread is getting long and fractious. Let’s do this:&lt;/p&gt;
&lt;ul class=&quot;simple&quot;&gt;&lt;li&gt;Make new threads for specific problems with converting i18n stuff with Intl to use ports and custom elements.&lt;/li&gt;
&lt;li&gt;Make a new thread for the fluent stuff that @spookylukey is working on, if that’s what @spookylukey wants to do. It’s definitely very interesting to me!&lt;/li&gt;
&lt;li&gt;Make a new thread if @toastal or anyone else wants to complete a review of prior work on the subject of i18n APIs that might use Intl in an Elm implementation. Feel free to find me in Slack or send me DMs here if you have questions about what the final product might look like.&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;p&gt;And closed the thread, blocking anyone from replying to his comments.&lt;/p&gt;
&lt;p&gt;The first major problem I have is the &lt;strong&gt;arrogance&lt;/strong&gt; demonstrated. (I’m not picking on Luke Westby here — he is merely demonstrating the attitude of the core team.)&lt;/p&gt;
&lt;p&gt;Despite multiple people having demonstrated experience and expressed willingness to help, including myself, it’s pretty clear that the Elm core team have consulted with very few, if any, of these people. There is no sense of “we might just possibly benefit from someone else’s expertise”.&lt;/p&gt;
&lt;p&gt;Then, Luke flatly contradicts the other people in the list. They have stated that ports/custom elements are really not suitable for wrapping &lt;tt class=&quot;docutils literal&quot;&gt;Intl&lt;/tt&gt;, and he, in effect, says “Yes they are” — but without any proof, despite it being very clear that the other people in the thread are much more experienced in this matter than he is. He’s a core dev, so he doesn’t need things like reasons, it seems, nor does he need to ask why other people hold their views. He just Knows Better.&lt;/p&gt;
&lt;p&gt;He then effectively accuses the people in the thread of being trouble makers: “It seems to me like this thread is really about how to do something in 0.19 that uses Native modules.” – I mean, how dare you bring up yet another piece of evidence that our previous decisions have caused huge problems with no adequate answers.&lt;/p&gt;
&lt;p&gt;The next major problem is that he clearly demonstrates &lt;strong&gt;just how little the core team understand “Intl”&lt;/strong&gt;. Pretty much everything he said is wrong-headed. &lt;a class=&quot;footnote-reference&quot; href=&quot;https://lukeplant.me.uk/blog/posts/why-im-leaving-elm/#misunderstanding-intl&quot; id=&quot;id9&quot;&gt;[2]&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Regarding &lt;strong&gt;process&lt;/strong&gt;, he scolds the people who’ve contributed so far for using the wrong process (“Making a wrapper for some browser &lt;span class=&quot;caps&quot;&gt;API&lt;/span&gt; and posting it is not the right way to propose something for the platform.”), and tells them what the right process is, according to him — a literature review, which as far as I can see is completely impractical &lt;a class=&quot;footnote-reference&quot; href=&quot;https://lukeplant.me.uk/blog/posts/why-im-leaving-elm/#literature-review&quot; id=&quot;id10&quot;&gt;[3]&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;So we discover that &lt;strong&gt;there are indeed rules and processes (there always are), but they are unwritten ones that you are just supposed to know&lt;/strong&gt;, and you can expect to be chided for not knowing them.&lt;/p&gt;
&lt;p&gt;But the biggest problem is that he &lt;strong&gt;immediately closes the thread&lt;/strong&gt;. He gives no-one any chance to respond to any of the specific points he makes. He gives a process which is extremely unlikely to go anywhere fast, and &lt;strong&gt;shuts down any meta-process at all&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;This is an extremely arrogant and aggressive way to interact with the community, and gives community members very few good options if we happen to disagree.&lt;/p&gt;
&lt;p&gt;You could choose to be silent (as I did on the Elm discourse board — even I have enough tact to realise that immediately opening a thread entitled “Why Everything You Said In The Last Thread Is Wrong” would have been a bad move); or you can be aggressive and confrontational in return (like I have eventually done in this blog post).&lt;/p&gt;
&lt;p&gt;The result of all this is entirely predictable — more than 18 months later (at the time of writing), as far as I can see there has been &lt;strong&gt;zero progress&lt;/strong&gt; on this front.&lt;/p&gt;
&lt;p&gt;And a further consequence of this is that &lt;strong&gt;non-English developers and end users are discriminated against&lt;/strong&gt;, due to the difficulty of formatting numbers and dates in correct ways for non-English locales.&lt;/p&gt;
&lt;p&gt;I’m not going to say something silly like “Elm is racist” — most programming languages have a very strong bias towards English in multiple ways, and it is perfectly reasonable to make a programming language use the natural language conventions of the authors by default. Nor do I think we need to feel guilty about the huge advantages this gives first language English speakers — the emergence of a common language is a phenomenon that has occurred throughout history, and it benefits everyone.&lt;/p&gt;
&lt;p&gt;However, we ought to be &lt;strong&gt;aware&lt;/strong&gt; of those advantages — the fact that we have benefited more than others. And if language authors &lt;strong&gt;go out of their way to build completely unnecessary discriminatory policies&lt;/strong&gt; into the compiler itself, despite this going against the whole spirit of Open Source, in ways that give additional special advantages (like access to certain compiler features) to people who already have advantages (like the core team), they cannot be surprised when this makes life even harder for minorities, and &lt;strong&gt;they are responsible for these discriminatory effects&lt;/strong&gt;, especially once these things have been pointed out to them.&lt;/p&gt;
&lt;p&gt;There is no technical reason or excuse for this level of discrimination against non-English internet users in Elm projects. The browser already provides web developers with &lt;span class=&quot;caps&quot;&gt;CLDR&lt;/span&gt; data needed for correctly formatting dates and numbers in different locales, and other localization issues, via the Intl APIs. The Elm compiler already has mechanisms for interfacing with browser APIs, and those mechanisms are not going to disappear. It’s perfectly acceptable that there is no Elm standard library for doing this, but not acceptable that the Elm core team should attempt to block you from using already existing compiler mechanisms and browser APIs to provide a solution to users.&lt;/p&gt;
&lt;p&gt;In this worked example, I’ve focused on the need for &lt;tt class=&quot;docutils literal&quot;&gt;Intl&lt;/tt&gt; wrappers, because it illustrates most of my previous points. However, the same thing will happen many times over with every group whose needs are not adequately represented in the core team — they will suffer the same unfairness and discrimination, even if it is not easy to put a name on that group or identify them.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;section&quot; id=&quot;conclusion&quot;&gt;

&lt;p&gt;I do not think I am asking too much of the Elm leadership. The principles I’ve laid out here I’ve seen put into practice in every other Open Source community I’ve worked in. Even in projects using the &lt;span class=&quot;caps&quot;&gt;BDFL&lt;/span&gt; model (such as Django at the beginning), I’ve never expected or seen the behaviour I’ve seen from the Elm leadership.&lt;/p&gt;
&lt;p&gt;Rather, the Elm leadership have gone out their way to ignore normal behaviour in Open Source projects.&lt;/p&gt;
&lt;p&gt;By doing so, in addition to abandoning basic principles of fairness, they have also made more work for themselves — only they are able to fix certain kinds of bugs and missing libraries, they have to make many decisions that they may be entirely unqualified to make, and they have blocked many valuable contributions from many people.&lt;/p&gt;
&lt;p&gt;The result is a project that I don’t feel inclined to contribute to. With any other Open Source project I’ve ever been involved in, if I work on some bug fix or feature, I have a very high degree of confidence that my contribution, if accepted, would benefit everyone in the community equally — or at least without any deliberate discrimination. In fact, &lt;strong&gt;this is one of the aspects of Open Source that I love and value the most — being able to share work in a way that benefits everyone, without the risk that someone is going to take those things away and use them for just a privileged few&lt;/strong&gt;. With Elm, I don’t have this confidence — the leaders have demonstrated that they don’t believe in the principles behind such expectations. That’s a huge turn-off for me, and I can only hope that other projects do not look to Elm for inspiration on how to run themselves.&lt;/p&gt;
&lt;/div&gt;
&lt;hr class=&quot;docutils&quot;/&gt;
</description>
<pubDate>Thu, 09 Apr 2020 11:16:31 +0000</pubDate>
<dc:creator>neillyons</dc:creator>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://lukeplant.me.uk/blog/posts/why-im-leaving-elm/</dc:identifier>
</item>
<item>
<title>Swift: Google’s Bet on Differentiable Programming</title>
<link>https://tryolabs.com/blog/2020/04/02/swift-googles-bet-on-differentiable-programming/</link>
<guid isPermaLink="true" >https://tryolabs.com/blog/2020/04/02/swift-googles-bet-on-differentiable-programming/</guid>
<description>&lt;p&gt;Two years ago, a small team at Google started working on making Swift the first mainstream language with &lt;strong&gt;first-class language-integrated differentiable programming&lt;/strong&gt; capabilities. The scope and initial results of the project have been remarkable, and general public usability is not very far off.&lt;/p&gt;&lt;p&gt;Despite this, the project hasn’t received a lot of interest in the machine learning community and remains unknown to most practitioners. This can be attributed in part to the choice of language, which has largely been met with confusion and indifference, as Swift has almost no presence in the data science ecosystem and has mainly been used for building iOS apps.&lt;/p&gt;
&lt;p&gt;This is unfortunate though, as even a cursory glance at Google’s project will show that it’s a massive and ambitious undertaking, which could establish Swift as a key player in the area. Furthermore, even though we mainly work with Python at Tryolabs, we think that choosing Swift was a superb idea, and decided to write this &lt;em&gt;short™&lt;/em&gt; post to help spread the word about Google’s plans.&lt;/p&gt;
&lt;p&gt;But before we get into Swift and what the term &lt;em&gt;differentiable programming&lt;/em&gt; actually means, we should first review the current state of affairs.&lt;/p&gt;
&lt;div&gt;&lt;span&gt;Due to the popularity of the post,&lt;/span&gt; &lt;span&gt;we will be hosting a Swift for ML live webinar.&lt;/span&gt; &lt;span&gt;Register to be notified when date &amp;amp; time are confirmed.&lt;/span&gt; &lt;a href=&quot;https://tryolabs.com/blog/2020/04/02/swift-googles-bet-on-differentiable-programming/#sign-up-form-swift&quot; onmouseover=&quot;this.style.background='#74A534';&quot; onmouseout=&quot;this.style.background='#9ACB00';&quot;&gt;Be updated&lt;/a&gt;&lt;/div&gt;
&lt;h2 id=&quot;what-is-wrong-with-you-python&quot;&gt;What is wrong with you, Python?!&lt;/h2&gt;
&lt;p&gt;Python is by far the most used language in machine learning, and Google has a ton of machine learning libraries and tools written in it. So, why Swift? What’s wrong with Python?&lt;/p&gt;
&lt;p&gt;To put it bluntly, Python is &lt;strong&gt;slow&lt;/strong&gt;. Also, Python is &lt;a href=&quot;https://wiki.python.org/moin/GlobalInterpreterLock&quot;&gt;not great for parallelism&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;To get around these facts, most machine learning projects run their compute-intensive algorithms via libraries written in C/C++/Fortran/CUDA, and use Python to &lt;em&gt;glue&lt;/em&gt; the different low-level operations together. For the most part, this has worked really well, but as with all abstractions, it can create some problems. Let’s go over some of those.&lt;/p&gt;
&lt;h3 id=&quot;external-binaries&quot;&gt;External binaries&lt;/h3&gt;
&lt;p&gt;Calling external binaries for every compute-intensive operation limits developers to working on a small portion of the algorithm’s surface area. Writing a custom way to perform convolutions, for example, becomes off limits unless the developer is willing to step down into a language like C. Most programmers choose not to do so, either because they have no experience with writing low level performant code, or because jumping back and forth between Python’s development environment and some low level language’s environment becomes too cumbersome to justify.&lt;/p&gt;
&lt;p&gt;This leads to the unfortunate situation in which programmers are motivated to write the least amount of sophisticated code they can, and default to calling external library operations. This is the opposite of what’s desirable in an area as dynamic as machine learning, where so much is still not settled, and new ideas are very much needed.&lt;/p&gt;
&lt;h3 id=&quot;library-abstractions&quot;&gt;Library abstractions&lt;/h3&gt;
&lt;p&gt;Having your Python code call lower level code is not as easy as mapping Python’s functions to C functions. The unfortunate reality is that the creators of machine learning libraries have had to make certain development choices in the name of performance, and that has complicated matters a bit. For example, in &lt;a href=&quot;https://www.tensorflow.org/api_docs/python/tf/Graph&quot;&gt;Tensorflow graph mode&lt;/a&gt;, which is the only performant mode in the library, your Python code doesn’t generally run when you think it would. Python actually acts as a sort of metaprogramming language for the underlying Tensorflow graph.&lt;/p&gt;
&lt;p&gt;The development flow is as follows: the developer first defines the network using Python, then the TensorFlow backend uses this definition to build the network and compile it into a blob whose internals the developer can no longer access. After compilation, the network is finally ready to run, and the developer can start feeding it data for training/inference jobs. This way of working makes debugging quite hard, as you can’t use Python to dig into what’s happening inside your network as it runs. You can’t use something like &lt;code&gt;pdb&lt;/code&gt;. Even if you wish to engage in good old print debugging, you’ll have to use &lt;code&gt;tf.print&lt;/code&gt; and build a print node into your network, which has to connect to another node in your network, and be compiled before anything can be printed.&lt;/p&gt;
&lt;p&gt;More straightforward solutions exist, though. In &lt;a href=&quot;https://pytorch.org/&quot;&gt;PyTorch&lt;/a&gt;, your code runs imperatively as is expected in Python, and the only non transparent abstraction is that the operations that run on the GPU execute asynchronously. This is generally a non-issue as PyTorch is smart about this and waits for all the async calls that are dependencies of any user interactive operations to finish before ceding control. Still, this is something to keep in mind, especially with things such as benchmarking.&lt;/p&gt;
&lt;h3 id=&quot;industry-lag&quot;&gt;Industry lag&lt;/h3&gt;
&lt;p&gt;All these usability problems aren’t just making it more difficult to write code, they are unnecessarily causing the industry to &lt;strong&gt;lag behind academia&lt;/strong&gt;. There have been several papers that tweak low level operations used in neural networks, introducing improvements in accuracy of a few percentage points in the process, and have still taken a long time for the industry to adopt.&lt;/p&gt;
&lt;p&gt;One reason for this is that even though these algorithmic changes tend to be quite simple themselves, the tooling problems mentioned above make them extremely difficult to implement. Hence, they may not be deemed worth the effort for what often results in only a 1% improvement in accuracy. This is especially problematic for small machine learning dev shops that usually lack the economies of scale to justify paying for their implementation/integration.&lt;/p&gt;
&lt;p&gt;Therefore, companies tend to ignore these improvements until they get added to a library like PyTorch or TensorFlow. This saves them the implementation and integration costs, but it also causes industry to lag behind academia by 1 or 2 years, as the library maintainers can’t be expected to immediately implement the findings of every new paper that is published.&lt;/p&gt;
&lt;p&gt;One concrete example of this issue are &lt;a href=&quot;https://arxiv.org/pdf/1703.06211.pdf&quot;&gt;Deformable Convolutions&lt;/a&gt;, which seem to improve the performance of most Convolutional Neural Networks (CNNs). An open source implementation appeared about 2 years ago. Nevertheless, the implementation was cumbersome to integrate into PyTorch/TensorFlow and the algorithm didn’t gain widespread use. Only just recently has PyTorch &lt;a href=&quot;https://github.com/pytorch/vision/pull/1586&quot;&gt;added support&lt;/a&gt; for it, and as of yet I am not aware of there being an official TensorFlow version.&lt;/p&gt;
&lt;p&gt;Now, let’s say this happens for several papers that each contribute a performance enhancement of 2%; the industry could be &lt;strong&gt;missing out on significant accuracy improvements&lt;/strong&gt; of &lt;em&gt;1.02^n%&lt;/em&gt; for no reason other than inadequate tooling. This is regrettable, considering the &lt;em&gt;n&lt;/em&gt; could be quite high.&lt;/p&gt;
&lt;h3 id=&quot;speed&quot;&gt;Speed&lt;/h3&gt;
&lt;p&gt;Using Python + fast libraries can still be slow in some cases. Yes, for CNNs running classification on images, using Python and PyTorch/TensorFlow will be really fast. What’s more, there is probably not much performance to be gained by coding your whole network in CUDA, as most of the inference time is spent on big convolutions that are already running in well-optimized implementations. This isn’t always the case though.&lt;/p&gt;
&lt;p&gt;Networks that consist of many &lt;strong&gt;small operations&lt;/strong&gt; are often the most susceptible to taking &lt;strong&gt;performance hits&lt;/strong&gt;, if they are not fully implemented in a low level language. As an example, in a &lt;a href=&quot;https://www.fast.ai/2019/03/06/fastai-swift/&quot;&gt;blogpost&lt;/a&gt; in which he professes his love for using Swift for deep learning, &lt;a href=&quot;https://www.fast.ai/&quot;&gt;Fast.AI&lt;/a&gt;’s &lt;a href=&quot;http://twitter.com/jeremyphoward&quot;&gt;Jeremy Howard&lt;/a&gt; reports that despite using PyTorch’s great JIT compiler, he still couldn’t make a particular RNN work as fast as a version completely implemented in pure CUDA.&lt;/p&gt;
&lt;p&gt;Furthermore, Python is not a very good language for cases where &lt;strong&gt;latency&lt;/strong&gt; is important, nor for very &lt;strong&gt;low level tasks&lt;/strong&gt; such as communicating with sensors. The way some companies choose to get around this is to start by developing their models in PyTorch/TensorFlow-Python. In this way, they take advantage of Python’s ease of use when experimenting with and training new models. After this, they &lt;a href=&quot;https://twitter.com/elonmusk/status/1224182478501482497&quot;&gt;rewrite their model in C++&lt;/a&gt; for production purposes. I’m not sure if they rewrite it completely, or if they simply serialize it using PyTorch’s tracing functionality or TensorFlow’s graph mode, and then rewrite the Python code around it in C++. Either way, a lot of Python code would need to be rewritten, which oftentimes is too costly for small companies to do.&lt;/p&gt;
&lt;p&gt;All these problems are well known. &lt;a href=&quot;https://twitter.com/ylecun&quot;&gt;Yann LeCun&lt;/a&gt;, who is widely considered one of the godfathers of deep learning, has stated that there is a need for a new machine learning language. In a &lt;a href=&quot;https://twitter.com/jeremyphoward/status/1097799892167122944&quot;&gt;twitter thread&lt;/a&gt; PyTorch co-creator Soumith Chintala and him discussed several languages as possible candidates, with Julia, Swift, and even improving Python being mentioned. On the other hand, Fast AI’s Jeremy Howard seems to be decidedly on the Swift train.&lt;/p&gt;
&lt;h2 id=&quot;google-accepts-the-challenge&quot;&gt;Google accepts the challenge&lt;/h2&gt;
&lt;p&gt;Lucky for us, Google’s &lt;a href=&quot;https://www.tensorflow.org/swift&quot;&gt;Swift for Tensorflow&lt;/a&gt; (S4TF) team took the matter into their own hands. What’s even better, they have been remarkably transparent about the whole process. In an &lt;a href=&quot;https://github.com/tensorflow/swift/blob/master/docs/WhySwiftForTensorFlow.md&quot;&gt;extremely thorough document&lt;/a&gt;, they detail the journey that got them to this decision, explaining what languages they considered for the task and why they ended up using Swift.&lt;/p&gt;
&lt;p&gt;Most notably, they considered:&lt;/p&gt;
&lt;ul readability=&quot;13.455089820359&quot;&gt;&lt;li readability=&quot;6.6410256410256&quot;&gt;
&lt;p&gt;&lt;a href=&quot;https://golang.org/&quot;&gt;Go&lt;/a&gt;: In the document, they state that Go relies too heavily on the dynamic dispatching that its interfaces provide, and that they would have had to make big changes to the language in order to implement the features they wanted. This goes against Go’s philosophy of being simple and having a small surface area. Conversely, Swift’s protocols &amp;amp; extensions afford a lot of freedom in terms of how static you want your dispatch to be. Also, the language is quite complex (and &lt;a href=&quot;https://forums.swift.org/t/function-builders/25167&quot;&gt;getting more complex every day&lt;/a&gt;), so making it a bit more complex to accommodate the features that Google wanted wouldn’t pose as big of a problem.&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;2.9734513274336&quot;&gt;
&lt;p&gt;C++ &amp;amp; &lt;a href=&quot;https://www.rust-lang.org/&quot;&gt;Rust&lt;/a&gt;: Google’s targeted user base is people who are used to working in Python for the most part, and who are more interested in spending their time thinking about the model and the data rather than thinking about things like the careful management of memory allocation or ownership. Rust and C++ have a level of complexity and attention to low level detail that is generally not justifiable when doing data science/machine learning development.&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;10.373134328358&quot;&gt;
&lt;p&gt;&lt;a href=&quot;https://julialang.org/&quot;&gt;Julia&lt;/a&gt;: If you read any &lt;a href=&quot;https://news.ycombinator.com/&quot;&gt;HackerNews&lt;/a&gt; or &lt;a href=&quot;https://www.reddit.com/r/S4TF/&quot;&gt;Reddit threads&lt;/a&gt; about S4TF, the first comment usually is, “Why didn’t they choose Julia?”. In the previously mentioned document, Google mentions that Julia looked promising too, but they didn’t really provide a solid reason as to why they didn’t go for it. They mentioned that Swift has a much larger community than Julia, which is true, but Julia’s scientific and data science communities are much larger than Swift’s, and these are arguably the communities that would make more use of S4TF. Something to keep in mind is that Google’s team had more expertise in Swift, given that Swift’s creator &lt;a href=&quot;https://twitter.com/clattner_llvm?lang=en&quot;&gt;Chris Lattner&lt;/a&gt; started the project, so this probably played a big part in the decision.&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;1&quot;&gt;
&lt;p&gt;A new language: I think they said it best in the manifesto: “Creating a language is a ridiculous amount of work”. This would take too long, and machine learning is moving way too fast.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;h2 id=&quot;what-s-so-cool-about-swift-then&quot;&gt;What’s so cool about Swift, then?&lt;/h2&gt;
&lt;p&gt;In short, Swift allows you to program at a very high level, in an almost Pythonic way, while at the same time being really fast. A data scientist could use Swift in much the same way as they use Python, while someone working in an optimized machine learning library built in Swift could be more careful about how they manage their memory, and could even drop down to the pointer level of abstraction when idiomatic Swift is too restrictive.&lt;/p&gt;
&lt;p&gt;Providing a detailed description of the language is probably overkill for the purpose of this article. The &lt;a href=&quot;https://docs.swift.org/swift-book/GuidedTour/GuidedTour.html&quot;&gt;official documentation&lt;/a&gt; already does a much better job than I ever could. Instead, I’ll describe a few things that I found to be cool about Swift as a new fan of the language, in hopes that this will entice people to try it. The following chapters will be an assortment of random cool things about Swift, in no particular order, and with no particular attention paid to their overall significance. After these, I’ll delve into differentiable programming and Google’s big plan for Swift.&lt;/p&gt;
&lt;h3 id=&quot;cool-thing-number-one&quot;&gt;Cool thing number one&lt;/h3&gt;
&lt;p&gt;It’s fast. This is the first thing I tested when I got started with Swift. I wrote a few short scripts to evaluate how well it would fare against Python and C. These tests are not particularly sophisticated, to be honest. They just fill an array with integers and then add them all up. This by itself is not a very thorough way of testing how fast idiomatic Swift is, but I was curious if Swift could &lt;em&gt;ever&lt;/em&gt; be as fast as C, not if Swift would &lt;em&gt;always&lt;/em&gt; be as fast as C.&lt;/p&gt;
&lt;p&gt;For the first comparison, I went with Swift vs Python. I took some artistic liberties with curly brace placement in Swift so that each line is basically doing the same thing in both cases.&lt;/p&gt;
&lt;div class=&quot;highlight&quot; readability=&quot;13&quot;&gt;
&lt;pre&gt;
&lt;code class=&quot;language-swift&quot; data-lang=&quot;swift&quot;&gt;&lt;span&gt;import&lt;/span&gt; &lt;span&gt;time&lt;/span&gt;                    &lt;span&gt;|&lt;/span&gt; &lt;span&gt;import&lt;/span&gt; &lt;span&gt;Foundation&lt;/span&gt;
                               &lt;span&gt;|&lt;/span&gt;
result = []                    &lt;span&gt;|&lt;/span&gt; &lt;span&gt;var&lt;/span&gt; result = [Int]()
&lt;span&gt;for&lt;/span&gt; it &lt;span&gt;in&lt;/span&gt; range(&lt;span&gt;15&lt;/span&gt;):           &lt;span&gt;|&lt;/span&gt; &lt;span&gt;for&lt;/span&gt; it &lt;span&gt;in&lt;/span&gt; &lt;span&gt;0.&lt;/span&gt;.&amp;lt;&lt;span&gt;15&lt;/span&gt; {
    start = time.time()        &lt;span&gt;|&lt;/span&gt;     &lt;span&gt;let&lt;/span&gt; start = CFAbsoluteTimeGetCurrent()
    &lt;span&gt;for&lt;/span&gt; &lt;span&gt;_&lt;/span&gt; &lt;span&gt;in&lt;/span&gt; range(&lt;span&gt;3000&lt;/span&gt;):      &lt;span&gt;|&lt;/span&gt;     &lt;span&gt;for&lt;/span&gt; &lt;span&gt;_&lt;/span&gt; &lt;span&gt;in&lt;/span&gt; &lt;span&gt;0.&lt;/span&gt;.&amp;lt;&lt;span&gt;3000&lt;/span&gt; {
        result.append(it)      &lt;span&gt;|&lt;/span&gt;         result.append(it)}
    sum_ = sum(result)         &lt;span&gt;|&lt;/span&gt;     &lt;span&gt;let&lt;/span&gt; sum = result.reduce(&lt;span&gt;0&lt;/span&gt;, &lt;span&gt;+&lt;/span&gt;)
    end = time.time()          &lt;span&gt;|&lt;/span&gt;     &lt;span&gt;let&lt;/span&gt; end = CFAbsoluteTimeGetCurrent()
    print(end &lt;span&gt;-&lt;/span&gt; start, sum_)   &lt;span&gt;|&lt;/span&gt;     print(end &lt;span&gt;-&lt;/span&gt; start, sum)
    result = []                &lt;span&gt;|&lt;/span&gt;     result = []}&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Although their syntax is very similar in this particular snippet, the Swift script proves to be 25 times faster than the Python one. Each outermost loop in the Python script completes in 360μs on average, vs 14μs for Swift. This is quite an improvement.&lt;/p&gt;
&lt;p&gt;There are yet other interesting things to note. Namely, &lt;code&gt;+&lt;/code&gt; is an operator as well as a function that gets passed to &lt;code&gt;reduce&lt;/code&gt; (which I’ll elaborate on later), &lt;code&gt;CFAbsoluteTimeGetCurrent&lt;/code&gt; reveals Swift’s quirks regarding legacy iOS namespaces, and the &lt;code&gt;..&amp;lt;&lt;/code&gt; range operator lets you choose if the range is inclusive, and on which end.&lt;/p&gt;
&lt;p&gt;This test doesn’t really tell us how fast Swift can be, though. To find that out, we need to compare it to C. So, that’s what I did, and much to my disappointment, the initial results weren’t good. The version &lt;a href=&quot;https://gist.github.com/joaqo/e019b00ba0dae567bf7d66ee971f7c9e&quot;&gt;written in C&lt;/a&gt; took an average of 1.5μs, which is ten times faster than our Swift code. Uh oh.&lt;/p&gt;
&lt;p&gt;To be fair, this isn’t a terribly honest comparison. The Swift script is using a dynamic array, which is getting repeatedly reallocated in the heap as it increases in size. This also means it’s performing bound checking on each append. To corroborate this, we can go look at its definition. Swift standard types like int, float, and array are not hardcoded into the compiler, they are structs defined in the standard library. Thus, according to the array’s &lt;a href=&quot;https://github.com/apple/swift/blob/master/stdlib/public/core/Array.swift#L1148&quot;&gt;append definition&lt;/a&gt;, we see there’s a lot going on. Knowing this, I evened the playing field by preallocating the array’s memory and using a pointer for filling the array. The resulting script is not much longer:&lt;/p&gt;
&lt;div class=&quot;highlight&quot; readability=&quot;13&quot;&gt;
&lt;pre&gt;
&lt;code class=&quot;language-swift&quot; data-lang=&quot;swift&quot;&gt;&lt;span&gt;import&lt;/span&gt; &lt;span&gt;Foundation&lt;/span&gt;

&lt;span&gt;// Preallocating memory&lt;/span&gt;
&lt;span&gt;var&lt;/span&gt; result = ContiguousArray&amp;lt;Int&lt;span&gt;&amp;gt;&lt;/span&gt;(repeating: &lt;span&gt;0&lt;/span&gt;, count: &lt;span&gt;3001&lt;/span&gt;)
&lt;span&gt;for&lt;/span&gt; it &lt;span&gt;in&lt;/span&gt; &lt;span&gt;0.&lt;/span&gt;.&amp;lt;&lt;span&gt;15&lt;/span&gt; {
    &lt;span&gt;let&lt;/span&gt; start = CFAbsoluteTimeGetCurrent()

    &lt;span&gt;// Using a buffer pointer for assignment&lt;/span&gt;
    result.withUnsafeMutableBufferPointer({ buffer &lt;span&gt;in&lt;/span&gt;
        &lt;span&gt;for&lt;/span&gt; i &lt;span&gt;in&lt;/span&gt; &lt;span&gt;0.&lt;/span&gt;.&amp;lt;&lt;span&gt;3000&lt;/span&gt; {
            buffer[i] = it
        }
    })
    &lt;span&gt;let&lt;/span&gt; sum = result.reduce(&lt;span&gt;0&lt;/span&gt;, &lt;span&gt;+&lt;/span&gt;)
    &lt;span&gt;let&lt;/span&gt; end = CFAbsoluteTimeGetCurrent()
    print(end &lt;span&gt;-&lt;/span&gt; start, sum)&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This new code takes 3μs, so it’s now half as fast as C, which is already a good place to be in. Just for the sake of completeness, though, I continued profiling the code in order to find what the difference with the C version was. It turns out that the &lt;code&gt;reduce&lt;/code&gt; method I was using is performing some &lt;a href=&quot;https://github.com/apple/swift/blob/06f82a53b5da26b67a8fd9414d8f8877eca8a3e1/stdlib/public/core/SequenceAlgorithms.swift#L576&quot;&gt;unnecessary indirection&lt;/a&gt; with the usage of a &lt;code&gt;nextPartialResult&lt;/code&gt; function, which is providing nonessential generalization. After rewriting it utilizing a pointer, I finally got it to C speed. However, this obviously defeats the purpose of using Swift, since at this point we are just writing more verbose and uglier C. Nevertheless, it’s good to know that you can get C speed if you really need it.&lt;/p&gt;
&lt;p&gt;To sum up: you won’t get C speed with a Python amount of work, but you will get a great tradeoff between the two.&lt;/p&gt;
&lt;h3 id=&quot;cool-thing-número-dos&quot;&gt;Cool thing número dos&lt;/h3&gt;
&lt;p&gt;Swift has taken an interesting approach to function signatures. In their most basic form, they are relatively simple:&lt;/p&gt;
&lt;div class=&quot;highlight&quot; readability=&quot;10&quot;&gt;
&lt;pre&gt;
&lt;code class=&quot;language-swift&quot; data-lang=&quot;swift&quot;&gt;&lt;span&gt;func&lt;/span&gt; &lt;span&gt;greet&lt;/span&gt;(person: String, town: String) -&amp;gt; String {
    &lt;span&gt;return&lt;/span&gt; &lt;span&gt;&quot;Hello &lt;/span&gt;&lt;span&gt;\(&lt;/span&gt;person&lt;span&gt;)&lt;/span&gt;&lt;span&gt;!  Glad you could visit from &lt;/span&gt;&lt;span&gt;\(&lt;/span&gt;town&lt;span&gt;)&lt;/span&gt;&lt;span&gt;.&quot;&lt;/span&gt;
}

greet(person: &lt;span&gt;&quot;Bill&quot;&lt;/span&gt;, town: &lt;span&gt;&quot;Cupertino&quot;&lt;/span&gt;)&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The function signature consists of the parameter names followed by their types; nothing too fancy. The only unusual thing is that Swift requires you to provide the parameter names when calling the function, so you have to write &lt;code&gt;person&lt;/code&gt; and &lt;code&gt;town&lt;/code&gt; when calling &lt;code&gt;greet&lt;/code&gt;, as evidenced by the last line of the snippet above.&lt;/p&gt;
&lt;p&gt;Things get more interesting when we introduce something called &lt;em&gt;argument labels&lt;/em&gt; into the mix.&lt;/p&gt;
&lt;div class=&quot;highlight&quot; readability=&quot;10&quot;&gt;
&lt;pre&gt;
&lt;code class=&quot;language-swift&quot; data-lang=&quot;swift&quot;&gt;&lt;span&gt;func&lt;/span&gt; &lt;span&gt;greet&lt;/span&gt;(&lt;span&gt;_&lt;/span&gt; person: String, from town: String) -&amp;gt; String {
    &lt;span&gt;return&lt;/span&gt; &lt;span&gt;&quot;Hello &lt;/span&gt;&lt;span&gt;\(&lt;/span&gt;person&lt;span&gt;)&lt;/span&gt;&lt;span&gt;!  Glad you could visit from &lt;/span&gt;&lt;span&gt;\(&lt;/span&gt;town&lt;span&gt;)&lt;/span&gt;&lt;span&gt;.&quot;&lt;/span&gt;
}

greet(&lt;span&gt;&quot;Bill&quot;&lt;/span&gt;, from: &lt;span&gt;&quot;Cupertino&quot;&lt;/span&gt;)&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Argument labels are just what they sound like: they are labels for your function’s parameters, and they are declared before their respective parameter in the function’s signature. In the sample above &lt;code&gt;from&lt;/code&gt; would be &lt;code&gt;town&lt;/code&gt;’s argument label, and &lt;code&gt;_&lt;/code&gt; would be &lt;code&gt;person&lt;/code&gt;’s argument label. I used &lt;code&gt;_&lt;/code&gt; for this last label because &lt;code&gt;_&lt;/code&gt; is a special case in Swift that means, “don’t provide any argument name when calling this parameter.”&lt;/p&gt;
&lt;p&gt;With argument labels, every parameter gets 2 different names: an argument label, which is used for calling the function, and a parameter name, which is used inside the function’s body definition. This may seem a bit arbitrary, but it makes your code easier to read.&lt;/p&gt;
&lt;p&gt;If you look at the function signature above, it’s almost like reading English: “Greet person from town.” The function call is just as descriptive: “Greet Bill from Cupertino.” Without argument labels, things become a bit more ambiguous: “Greet person town.” We don’t know what &lt;code&gt;town&lt;/code&gt; stands for. Is that the town we are in now? Is that the town in which we are going to meet the person? Or is it the town where the person is originally from? Without argument labels we would have to read the function’s body to know what’s happening, or resort to making the function name or the parameter names longer and more descriptive. This can get complicated if you have lots of parameters, and in my opinion tends to result in uglier code and needlessly long function names. Argument labels are prettier and scale better, and luckily, they are used extensively in Swift.&lt;/p&gt;
&lt;h3 id=&quot;the-third-of-the-cool-things&quot;&gt;The third of the cool things&lt;/h3&gt;
&lt;p&gt;Swift makes extensive use of closures. Therefore, it has some shortcuts to make their usage more ergonomic. This example taken from the language’s documentation highlights how concise and expressive these shortcuts can make Swift look.&lt;/p&gt;
&lt;p&gt;Let’s take an array that we want to sort backwards:&lt;/p&gt;
&lt;div class=&quot;highlight&quot; readability=&quot;11&quot;&gt;
&lt;pre&gt;
&lt;code class=&quot;language-swift&quot; data-lang=&quot;swift&quot;&gt;&lt;span&gt;let&lt;/span&gt; names = [&lt;span&gt;&quot;Chris&quot;&lt;/span&gt;, &lt;span&gt;&quot;Alex&quot;&lt;/span&gt;, &lt;span&gt;&quot;Ewa&quot;&lt;/span&gt;, &lt;span&gt;&quot;Barry&quot;&lt;/span&gt;, &lt;span&gt;&quot;Daniella&quot;&lt;/span&gt;]&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The less idiomatic way of doing this would be to use Swift’s &lt;code&gt;sorted&lt;/code&gt; method for arrays, and employ a custom function that tells it how to do pairwise order comparison on the array’s elements, like so:&lt;/p&gt;
&lt;div class=&quot;highlight&quot; readability=&quot;9&quot;&gt;
&lt;pre&gt;
&lt;code class=&quot;language-swift&quot; data-lang=&quot;swift&quot;&gt;&lt;span&gt;func&lt;/span&gt; &lt;span&gt;backward&lt;/span&gt;(&lt;span&gt;_&lt;/span&gt; s1: String, &lt;span&gt;_&lt;/span&gt; s2: String) -&amp;gt; Bool {
    &lt;span&gt;return&lt;/span&gt; s1 &lt;span&gt;&amp;gt;&lt;/span&gt; s2
}
&lt;span&gt;var&lt;/span&gt; reversedNames = names.sorted(by: backward)&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The &lt;code&gt;backward&lt;/code&gt; function compares two items at once, and returns true if they are in the desired order and false if they are not. The &lt;code&gt;sorted&lt;/code&gt; array method expects such a function as an input in order to know how to sort the array. As a side note, here we can also see the usage of the &lt;em&gt;argument label&lt;/em&gt; &lt;code&gt;by&lt;/code&gt;, which is oh so beautifully terse.&lt;/p&gt;
&lt;p&gt;If we resort to more idiomatic Swift, we find that there is a better way to do this using closures:&lt;/p&gt;
&lt;div class=&quot;highlight&quot; readability=&quot;8&quot;&gt;
&lt;pre&gt;
&lt;code class=&quot;language-swift&quot; data-lang=&quot;swift&quot;&gt;reversedNames = names.sorted(by: { s1, s2 &lt;span&gt;in&lt;/span&gt; &lt;span&gt;return&lt;/span&gt; s1 &lt;span&gt;&amp;gt;&lt;/span&gt; s2 } )&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The code between &lt;code&gt;{&lt;/code&gt; &lt;code&gt;}&lt;/code&gt; is a closure that is being defined and passed as an argument to&lt;code&gt;sorted&lt;/code&gt; at the same time. If you’ve never heard of them, closures are just unnamed functions which capture their context. A good way to think about them is as Python lambdas on steroids. The keyword &lt;code&gt;in&lt;/code&gt; in the closure is used to separate the closure’s arguments and its body. More intuitive keywords such as &lt;code&gt;:&lt;/code&gt; were already taken for signature type definitions (the closure’s argument types get automatically inferred from &lt;code&gt;sorted&lt;/code&gt;’s signature in this case, so they can be avoided), and we all know naming things is one of the hardest things to do in programming, so we are stuck with using the not so intuitive &lt;code&gt;in&lt;/code&gt; keyword for this.&lt;/p&gt;
&lt;p&gt;In any case, the code is already looking more concise.&lt;/p&gt;
&lt;p&gt;We can, however, do better:&lt;/p&gt;
&lt;div class=&quot;highlight&quot; readability=&quot;8&quot;&gt;
&lt;pre&gt;
&lt;code class=&quot;language-swift&quot; data-lang=&quot;swift&quot;&gt;reversedNames = names.sorted(by: { s1, s2 &lt;span&gt;in&lt;/span&gt; s1 &lt;span&gt;&amp;gt;&lt;/span&gt; s2 } )&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;We removed the return statement here because, in Swift, single line closures implicitly return.&lt;/p&gt;
&lt;p&gt;Still, we can go even deeper:&lt;/p&gt;
&lt;div class=&quot;highlight&quot; readability=&quot;7&quot;&gt;
&lt;pre&gt;
&lt;code class=&quot;language-swift&quot; data-lang=&quot;swift&quot;&gt;reversedNames = names.sorted(by: { $0 &lt;span&gt;&amp;gt;&lt;/span&gt; $1 } )&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Swift also has implicitly named positional parameters, so in the above case &lt;code&gt;$0&lt;/code&gt; is the first argument, &lt;code&gt;$1&lt;/code&gt; the second, &lt;code&gt;$2&lt;/code&gt; would be the third, and so on. The code is already compact and easy to understand, but we can do better yet:&lt;/p&gt;
&lt;div class=&quot;highlight&quot; readability=&quot;7&quot;&gt;
&lt;pre&gt;
&lt;code class=&quot;language-swift&quot; data-lang=&quot;swift&quot;&gt;reversedNames = names.sorted(by: &lt;span&gt;&amp;gt;&lt;/span&gt;)&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;In Swift, the &lt;code&gt;&amp;gt;&lt;/code&gt; operator is just a function named &lt;code&gt;&amp;gt;&lt;/code&gt;. Therefore, we can pass it to our &lt;code&gt;sorted&lt;/code&gt; method, making our code extremely concise and readable.&lt;/p&gt;
&lt;p&gt;This also applies to operators like &lt;code&gt;+=&lt;/code&gt;,&lt;code&gt;-=&lt;/code&gt;, &lt;code&gt;&amp;lt;&lt;/code&gt;, &lt;code&gt;&amp;gt;&lt;/code&gt;, &lt;code&gt;==&lt;/code&gt;, and &lt;code&gt;=&lt;/code&gt;, and you’ll find their &lt;a href=&quot;https://github.com/apple/swift/blob/06f82a53b5da26b67a8fd9414d8f8877eca8a3e1/stdlib/public/core/Integers.swift#L133&quot;&gt;definition&lt;/a&gt; in the standard library. The difference between these functions/operators and normal functions is that the former have been explicitly declared as operators using the &lt;code&gt;infix&lt;/code&gt;, &lt;code&gt;prefix&lt;/code&gt; or &lt;code&gt;suffix&lt;/code&gt; keywords in the standard library. For instance, the &lt;code&gt;+=&lt;/code&gt; function is defined as an operator on &lt;a href=&quot;https://github.com/apple/swift/blob/1ed846d8525679d2811418a5ba29405200f6e85a/stdlib/public/core/Policy.swift#L468&quot;&gt;this line&lt;/a&gt; of the Swift standard library. You can see that the operator conforms to several different protocols such as &lt;code&gt;Array&lt;/code&gt; and &lt;code&gt;String&lt;/code&gt;, as many different types have their own implementation of the &lt;code&gt;+=&lt;/code&gt; function.&lt;/p&gt;
&lt;p&gt;Of further interest is that we can define our own custom operators. One great example of this is in the &lt;a href=&quot;https://github.com/BradLarson/GPUImage2&quot;&gt;GPUImage2&lt;/a&gt; library. The library allows users to load a picture, modify it with a sequence of transformations, and then output it in some way. Naturally, the definition of these sequences of transformations shows up repeatedly in the library, so the library’s creator decided to define a new operator called &lt;code&gt;--&amp;gt;&lt;/code&gt; that would be used to chain these transformations together:&lt;/p&gt;
&lt;div class=&quot;highlight&quot; readability=&quot;9&quot;&gt;
&lt;pre&gt;
&lt;code class=&quot;language-swift&quot; data-lang=&quot;swift&quot;&gt;&lt;span&gt;func&lt;/span&gt; &lt;span&gt;--&amp;gt;&lt;/span&gt;(source:T, destination:T) -&amp;gt; T {
    source.addTarget(destination)
    &lt;span&gt;return&lt;/span&gt; destination
}

&lt;span&gt;infix&lt;/span&gt; &lt;span&gt;operator&lt;/span&gt; &lt;span&gt;--&amp;gt;&lt;/span&gt; : AdditionPrecedence&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;In the slightly simplified code above, the &lt;code&gt;--&amp;gt;&lt;/code&gt; function is first declared, and then defined as an &lt;code&gt;infix&lt;/code&gt; operator. Infix just means that to use the operator, you must place it between its two arguments. This allows you to write code such as the following:&lt;/p&gt;
&lt;div class=&quot;highlight&quot; readability=&quot;10&quot;&gt;
&lt;pre&gt;
&lt;code class=&quot;language-swift&quot; data-lang=&quot;swift&quot;&gt;&lt;span&gt;let&lt;/span&gt; testImage = UIImage(named:&lt;span&gt;&quot;WID-small.jpg&quot;&lt;/span&gt;)&lt;span&gt;!&lt;/span&gt;
&lt;span&gt;let&lt;/span&gt; toonFilter = SmoothToonFilter()
&lt;span&gt;let&lt;/span&gt; luminanceFilter = Luminance()

&lt;span&gt;let&lt;/span&gt; filteredImage = testImage.filterWithPipeline{input, output &lt;span&gt;in&lt;/span&gt;
    input &lt;span&gt;--&amp;gt;&lt;/span&gt; toonFilter &lt;span&gt;--&amp;gt;&lt;/span&gt; luminanceFilter &lt;span&gt;--&amp;gt;&lt;/span&gt; output  &lt;span&gt;// Interesting part&lt;/span&gt;
}&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The above is shorter and easier to understand than a bunch of chained methods, or a series of&lt;code&gt;source.addTarget(...)&lt;/code&gt; functions.&lt;/p&gt;
&lt;h3 id=&quot;the-fourth-of-the-cool-things&quot;&gt;The fourth of the cool things&lt;/h3&gt;
&lt;p&gt;Previously, I mentioned that the basic Swift types were structs defined in the standard library, and not hardcoded into the compiler as they usually are in other languages. One reason this is useful is that it lets us use a Swift feature called &lt;code&gt;extension&lt;/code&gt;, which allows us to add new functionality to any type, including the basic types. Here is how this can play out:&lt;/p&gt;
&lt;div class=&quot;highlight&quot; readability=&quot;8&quot;&gt;
&lt;pre&gt;
&lt;code class=&quot;language-swift&quot; data-lang=&quot;swift&quot;&gt;&lt;span&gt;extension&lt;/span&gt; &lt;span&gt;Double&lt;/span&gt; {
    &lt;span&gt;var&lt;/span&gt; radians: Double {
        &lt;span&gt;return&lt;/span&gt; &lt;span&gt;self&lt;/span&gt; &lt;span&gt;*&lt;/span&gt; (Double.pi &lt;span&gt;/&lt;/span&gt; &lt;span&gt;180&lt;/span&gt;)
    }
}

&lt;span&gt;360.&lt;/span&gt;radians &lt;span&gt;// -&amp;gt; 6.28319&lt;/span&gt;&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Though not particularly useful, this example shows how extensible the language is, as it lets you do things such as typing any number into a Swift interpreter, and call any custom method you want on it.&lt;/p&gt;
&lt;h3 id=&quot;last-one&quot;&gt;Last one&lt;/h3&gt;
&lt;p&gt;On top of having a compiler, Swift also has an interpreter and support for &lt;a href=&quot;https://jupyter.org/&quot;&gt;Jupyter Notebooks&lt;/a&gt;. The interpreter is particularly great for learning the language, as it allows you to type &lt;code&gt;swift&lt;/code&gt; at your command prompt and start trying out code right away, much in the same way you would with Python. On the other hand, the integration with Jupyter Notebooks is awesome for visualizing data, performing data exploration, and writing reports. Finally, when you want to run production code, you can compile it and take advantage of the great optimization &lt;a href=&quot;https://llvm.org/&quot;&gt;LLVM&lt;/a&gt; provides.&lt;/p&gt;
&lt;h2 id=&quot;google-s-master-plan&quot;&gt;Google’s master plan&lt;/h2&gt;
&lt;p&gt;I mentioned quite a few features in the paragraphs above, but there’s one feature that stands apart from the others: Jupyter support is very new, and was in fact added by the S4TF team. This is noteworthy because it gives us an idea of what Google’s state of mind is when working on this project: they don’t just want to create a library for Swift, they want to deeply improve the Swift language itself, along with its tooling, and then build a new Tensorflow library using this improved version of the language.&lt;/p&gt;
&lt;p&gt;This point is illustrated best by observing where the S4TF team has been spending most of its time. The majority of the work they’ve done has been on Apple’s Swift compiler repository itself. More specifically, most of the work Google has been doing lies in a &lt;a href=&quot;https://github.com/apple/swift/tree/tensorflow&quot;&gt;dev branch&lt;/a&gt; inside the Swift compiler repo. Google is adding new features to the Swift language, first creating and testing them in their own branch and then merging them into Apple’s master branch. This means that the standard Swift language running on iOS devices all around the world will eventually incorporate these improvements.&lt;/p&gt;
&lt;p&gt;Now, on to the juicy part: What are the features that Google is building into Swift?&lt;/p&gt;
&lt;p&gt;Let’s start with the big one.&lt;/p&gt;
&lt;h2 id=&quot;differentiable-programming&quot;&gt;Differentiable programming&lt;/h2&gt;
&lt;p&gt;Lately, there’s been a lot of hype surrounding differentiable programming. Tesla’s director of AI, Andrej Karpathy, &lt;a href=&quot;https://medium.com/@karpathy/software-2-0-a64152b37c35&quot;&gt;has called it Software 2.0&lt;/a&gt;, while Yan LeCun &lt;a href=&quot;https://www.facebook.com/yann.lecun/posts/10155003011462143&quot;&gt;has proclaimed&lt;/a&gt;: “Deep Learning est mort. Vive Differentiable Programming.” Others claim there will be a need for the creation of a whole new set of new tools, such as a new Git, new IDEs, and of course new programming languages. Wink wink.&lt;/p&gt;
&lt;p&gt;So, what is differentiable programming?&lt;/p&gt;
&lt;p&gt;In a nutshell, differentiable programming is a programming paradigm in which your program itself can be differentiated. This allows you to set a certain objective you want to optimize, have your program automatically calculate the gradient of itself with regards to this objective, and then fine-tune itself in the direction of this gradient. This is exactly what you do when you train a neural network.&lt;/p&gt;
&lt;p&gt;The most compelling thing about having a program tune itself is that it allows us to create the sorts of programs we seem to be completely incapable of programming by ourselves. An interesting way to think about this is that your program using its gradients to tune itself for a certain task is &lt;a href=&quot;https://twitter.com/karpathy/status/893576281375219712&quot;&gt;better at programming than you are&lt;/a&gt;. These past few years have shown that this is indeed true for an ever increasing number of cases, with no clear end to that growth in sight.&lt;/p&gt;
&lt;h3 id=&quot;a-differentiable-language&quot;&gt;A differentiable language&lt;/h3&gt;
&lt;p&gt;After that really long introduction, it’s finally time to introduce Google’s vision of how native differentiable programming will look in Swift:&lt;/p&gt;
&lt;div class=&quot;highlight&quot; readability=&quot;8&quot;&gt;
&lt;pre&gt;
&lt;code class=&quot;language-swift&quot; data-lang=&quot;swift&quot;&gt;&lt;span&gt;func&lt;/span&gt; &lt;span&gt;cube&lt;/span&gt;(&lt;span&gt;_&lt;/span&gt; x: Float) -&amp;gt; Float {
    &lt;span&gt;return&lt;/span&gt; x &lt;span&gt;*&lt;/span&gt; x &lt;span&gt;*&lt;/span&gt; x
}

&lt;span&gt;let&lt;/span&gt; cube&lt;span&gt;𝛁&lt;/span&gt; = gradient(of: cube)
cube(&lt;span&gt;2&lt;/span&gt;)   &lt;span&gt;// 8.0&lt;/span&gt;
cube&lt;span&gt;𝛁&lt;/span&gt;(&lt;span&gt;2&lt;/span&gt;)  &lt;span&gt;// 12.0&lt;/span&gt;&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Here we start by defining a simple function named &lt;code&gt;cube&lt;/code&gt;, which returns the cube of its input. Next comes the exciting part: we create the derivative function of our original function, merely by calling &lt;code&gt;gradient&lt;/code&gt; on it. There are no libraries or external code being used here, &lt;code&gt;gradient&lt;/code&gt; is simply a new function that is being introduced by the S4TF team into the Swift language. This function takes advantage of the changes the team made to Swift’s core, in order to automatically calculate gradient functions.&lt;/p&gt;
&lt;p&gt;This is Swift’s big new feature. You can take arbitrary Swift code and, as long as it’s differentiable, automatically calculate its gradient. The code above has no imports or weird dependencies, it’s just plain Swift. If you’ve ever used PyTorch, TensorFlow, or any of the other big machine learning libraries, they all support this feature, but only if you’re using their particular library specific operations. What’s more, working with gradients in these Python libraries is not as lightweight, transparent, or well integrated as it is in plain Swift.&lt;/p&gt;
&lt;p&gt;This is a massive new feature of the language and, as far as I can tell, Swift is the first mainstream language that has native support for such a thing.&lt;/p&gt;
&lt;p&gt;To further illustrate how this would look in the real world, the following script is a more thorough example of this new feature, applied to a standard machine learning training workflow:&lt;/p&gt;
&lt;div class=&quot;highlight&quot; readability=&quot;25&quot;&gt;
&lt;pre&gt;
&lt;code class=&quot;language-swift&quot; data-lang=&quot;swift&quot;&gt;&lt;span&gt;struct&lt;/span&gt; &lt;span&gt;Perceptron&lt;/span&gt;: @memberwise Differentiable {
    &lt;span&gt;var&lt;/span&gt; weight: SIMD2&amp;lt;Float&lt;span&gt;&amp;gt;&lt;/span&gt; = .random(&lt;span&gt;in&lt;/span&gt;: &lt;span&gt;-&lt;/span&gt;&lt;span&gt;1.&lt;/span&gt;.&amp;lt;&lt;span&gt;1&lt;/span&gt;)
    &lt;span&gt;var&lt;/span&gt; bias: Float = &lt;span&gt;0&lt;/span&gt;

    @differentiable
    &lt;span&gt;func&lt;/span&gt; &lt;span&gt;callAsFunction&lt;/span&gt;(&lt;span&gt;_&lt;/span&gt; input: SIMD2&amp;lt;Float&lt;span&gt;&amp;gt;&lt;/span&gt;) -&amp;gt; Float {
        (weight &lt;span&gt;*&lt;/span&gt; input).sum() &lt;span&gt;+&lt;/span&gt; bias
    }
}

&lt;span&gt;var&lt;/span&gt; model = Perceptron()
&lt;span&gt;let&lt;/span&gt; andGateData: [(x: SIMD2&amp;lt;Float&lt;span&gt;&amp;gt;&lt;/span&gt;, y: Float)] = [
    (x: [&lt;span&gt;0&lt;/span&gt;, &lt;span&gt;0&lt;/span&gt;], y: &lt;span&gt;0&lt;/span&gt;),
    (x: [&lt;span&gt;0&lt;/span&gt;, &lt;span&gt;1&lt;/span&gt;], y: &lt;span&gt;0&lt;/span&gt;),
    (x: [&lt;span&gt;1&lt;/span&gt;, &lt;span&gt;0&lt;/span&gt;], y: &lt;span&gt;0&lt;/span&gt;),
    (x: [&lt;span&gt;1&lt;/span&gt;, &lt;span&gt;1&lt;/span&gt;], y: &lt;span&gt;1&lt;/span&gt;),
]
&lt;span&gt;for&lt;/span&gt; &lt;span&gt;_&lt;/span&gt; &lt;span&gt;in&lt;/span&gt; &lt;span&gt;0.&lt;/span&gt;.&amp;lt;&lt;span&gt;100&lt;/span&gt; {
    &lt;span&gt;let&lt;/span&gt; (loss, &lt;span&gt;𝛁&lt;/span&gt;loss) = valueWithGradient(at: model) { model -&amp;gt; Float &lt;span&gt;in&lt;/span&gt;
        &lt;span&gt;var&lt;/span&gt; loss: Float = &lt;span&gt;0&lt;/span&gt;
        &lt;span&gt;for&lt;/span&gt; (x, y) &lt;span&gt;in&lt;/span&gt; andGateData {
            &lt;span&gt;let&lt;/span&gt; &lt;span&gt;ŷ&lt;/span&gt; = model(x)
            &lt;span&gt;let&lt;/span&gt; error = y &lt;span&gt;-&lt;/span&gt; &lt;span&gt;ŷ&lt;/span&gt;
            loss = loss &lt;span&gt;+&lt;/span&gt; error &lt;span&gt;*&lt;/span&gt; error &lt;span&gt;/&lt;/span&gt; &lt;span&gt;2&lt;/span&gt;
        }
        &lt;span&gt;return&lt;/span&gt; loss
    }
    print(loss)
    model.weight &lt;span&gt;-=&lt;/span&gt; &lt;span&gt;𝛁&lt;/span&gt;loss.weight &lt;span&gt;*&lt;/span&gt; &lt;span&gt;0.02&lt;/span&gt;
    model.bias &lt;span&gt;-=&lt;/span&gt; &lt;span&gt;𝛁&lt;/span&gt;loss.bias &lt;span&gt;*&lt;/span&gt; &lt;span&gt;0.02&lt;/span&gt;
}&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Again, the above code is all plain Swift with no external dependencies. In this snippet, we see that Google has introduced two new Swift features: &lt;code&gt;callAsFunction&lt;/code&gt; and &lt;code&gt;valueWithGradient&lt;/code&gt;. The first one is quite simple, it lets us instantiate classes and structs, and then call them as if they were functions. Here the &lt;code&gt;Perceptron&lt;/code&gt; struct gets instantiated as &lt;code&gt;model&lt;/code&gt;, and then &lt;code&gt;model&lt;/code&gt; gets called as a function in &lt;code&gt;let ŷ = model(x)&lt;/code&gt;. When you do this, &lt;code&gt;callAsFunction&lt;/code&gt; is the method actually being called. If you’ve ever used Keras or PyTorch models, you know that this is quite a common way of handling models/layers. While these two libraries use Python’s &lt;code&gt;__call__&lt;/code&gt; method to implement their &lt;code&gt;call&lt;/code&gt; and &lt;code&gt;forward&lt;/code&gt; methods, respectively, Swift had no such feature, and thus Google had to add it.&lt;/p&gt;
&lt;p&gt;The other interesting new feature in the above script is &lt;code&gt;valueWithGradient&lt;/code&gt;. This function returns the resulting value and gradient of a function or closure, evaluated at a particular point. In the case above, the closure we define and use as input for &lt;code&gt;valueWithGradient&lt;/code&gt; is actually our loss function. This loss function takes our model as an input, so when we say that &lt;code&gt;valueWithGradient&lt;/code&gt; will evaluate our function at a particular point, we mean that it will evaluate our loss function with our model in a particular weight configuration. After we have calculated the aforementioned value and gradient, we print the value (which is our loss), and update our model’s weights using the gradients. Repeat this a hundred times and we have a trained model. You’ll notice that we can access &lt;code&gt;andGateData&lt;/code&gt; inside our loss function, which is an example of Swift closures being able to capture their enclosing context.&lt;/p&gt;
&lt;h3 id=&quot;differentiating-external-code&quot;&gt;Differentiating external code&lt;/h3&gt;
&lt;p&gt;Another fantastic feature is that not only can we differentiate Swift operations, but we can also differentiate operations in external, non-Swift libraries, if we manually tell Swift what their derivatives are. This means you can use a C library with a very fast implementation of some operation not currently present in Swift, import it into your project, code the derivative, and then use this operation in your big neural network and have things like backpropagation work seamlessly.&lt;/p&gt;
&lt;p&gt;What’s more, making this happen is really simple:&lt;/p&gt;
&lt;div class=&quot;highlight&quot; readability=&quot;14&quot;&gt;
&lt;pre&gt;
&lt;code class=&quot;language-swift&quot; data-lang=&quot;swift&quot;&gt;&lt;span&gt;import&lt;/span&gt; &lt;span&gt;Glibc&lt;/span&gt;  &lt;span&gt;// we import pow and log from here&lt;/span&gt;

&lt;span&gt;func&lt;/span&gt; &lt;span&gt;powerOf2&lt;/span&gt;(&lt;span&gt;_&lt;/span&gt; x: Float) -&amp;gt; Float {
    &lt;span&gt;return&lt;/span&gt; pow(&lt;span&gt;2&lt;/span&gt;, x)
}

@derivative(of: powerOf2)
&lt;span&gt;func&lt;/span&gt; &lt;span&gt;dPowerOf2d&lt;/span&gt;(&lt;span&gt;_&lt;/span&gt; x: Float) -&amp;gt; (value: Float, pullback: (Float) -&amp;gt; Float) {
    &lt;span&gt;let&lt;/span&gt; d = powerOf2(x) &lt;span&gt;*&lt;/span&gt; log(&lt;span&gt;2&lt;/span&gt;)
    &lt;span&gt;return&lt;/span&gt; (value: d, pullback: { v &lt;span&gt;in&lt;/span&gt; v &lt;span&gt;*&lt;/span&gt; d })
}

powerOf2(&lt;span&gt;3&lt;/span&gt;),               &lt;span&gt;// 8&lt;/span&gt;
gradient(of: powerOf2)(&lt;span&gt;3&lt;/span&gt;)  &lt;span&gt;// 5.545&lt;/span&gt;&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Glibc is a C library, so the Swift compiler doesn’t know what the derivatives of its operations are. We can give the compiler this information by using &lt;code&gt;@derivative&lt;/code&gt; and then use these external operations along with our native operations to form big differentiable networks very easily. In the example, we import &lt;code&gt;pow&lt;/code&gt; and &lt;code&gt;log&lt;/code&gt; from Glibc and use them to create a &lt;code&gt;powerOf2&lt;/code&gt; function and its derivative.&lt;/p&gt;
&lt;p&gt;The current incarnation of the new TensorFlow library for Swift is being built using this feature. The library imports all of its operations from the C API of the TF Eager library, but instead of plugging into TensorFlow’s automatic differentiation system, it &lt;a href=&quot;https://github.com/tensorflow/swift-apis/blob/27c9f333960512668e805c2472e693cfc2a601c6/Sources/TensorFlow/Operators/NN.swift#L135&quot;&gt;specifies the derivative of each basic operation&lt;/a&gt; and lets Swift handle it. This isn’t required for all operations, though, as many are compositions of more basic operations, and therefore Swift can automatically infer their derivatives. Basing the current version of the library on TF Eager does, however, have one big downside: TF Eager is really slow, and therefore the Swift version is too. This seems to be a temporary problem which is getting fixed with the incorporation of &lt;a href=&quot;https://www.tensorflow.org/xla&quot;&gt;XLA&lt;/a&gt; (through x10) and &lt;a href=&quot;https://blog.tensorflow.org/2019/04/mlir-new-intermediate-representation.html&quot;&gt;MLIR&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Having said this, using this temporary solution is allowing Google’s devs to work on the Swift TensorFlow API, which is really starting to take shape. This is how a simple model training job looks:&lt;/p&gt;
&lt;div class=&quot;highlight&quot; readability=&quot;20&quot;&gt;
&lt;pre&gt;
&lt;code class=&quot;language-swift&quot; data-lang=&quot;swift&quot;&gt;&lt;span&gt;import&lt;/span&gt; &lt;span&gt;TensorFlow&lt;/span&gt;

&lt;span&gt;let&lt;/span&gt; hiddenSize: Int = &lt;span&gt;10&lt;/span&gt;
&lt;span&gt;struct&lt;/span&gt; &lt;span&gt;IrisModel&lt;/span&gt;: Layer {
    &lt;span&gt;var&lt;/span&gt; layer1 = Dense&amp;lt;Float&lt;span&gt;&amp;gt;&lt;/span&gt;(inputSize: &lt;span&gt;4&lt;/span&gt;, outputSize: hiddenSize, activation: relu)
    &lt;span&gt;var&lt;/span&gt; layer2 = Dense&amp;lt;Float&lt;span&gt;&amp;gt;&lt;/span&gt;(inputSize: hiddenSize, outputSize: hiddenSize, activation: relu)
    &lt;span&gt;var&lt;/span&gt; layer3 = Dense&amp;lt;Float&lt;span&gt;&amp;gt;&lt;/span&gt;(inputSize: hiddenSize, outputSize: &lt;span&gt;3&lt;/span&gt;)

    @differentiable
    &lt;span&gt;func&lt;/span&gt; &lt;span&gt;callAsFunction&lt;/span&gt;(&lt;span&gt;_&lt;/span&gt; input: Tensor&amp;lt;Float&lt;span&gt;&amp;gt;&lt;/span&gt;) -&amp;gt; Tensor&amp;lt;Float&lt;span&gt;&amp;gt;&lt;/span&gt; {
        &lt;span&gt;return&lt;/span&gt; input.sequenced(through: layer1, layer2, layer3)
    }
}

&lt;span&gt;var&lt;/span&gt; model = IrisModel()
&lt;span&gt;let&lt;/span&gt; optimizer = SGD(&lt;span&gt;for&lt;/span&gt;: model, learningRate: &lt;span&gt;0.01&lt;/span&gt;)
&lt;span&gt;let&lt;/span&gt; (loss, grads) = valueWithGradient(at: model) { model -&amp;gt; Tensor&amp;lt;Float&lt;span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;in&lt;/span&gt;
    &lt;span&gt;let&lt;/span&gt; logits = model(firstTrainFeatures)
    &lt;span&gt;return&lt;/span&gt; softmaxCrossEntropy(logits: logits, labels: firstTrainLabels)
}
print(&lt;span&gt;&quot;Current loss: &lt;/span&gt;&lt;span&gt;\(&lt;/span&gt;loss&lt;span&gt;)&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;)&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;As you can tell, it’s very similar to the no-import model training script we previously saw. It has a very PyTorch-like design, which is great.&lt;/p&gt;
&lt;h3 id=&quot;python-interoperability&quot;&gt;Python interoperability&lt;/h3&gt;
&lt;p&gt;One issue that Swift will have to deal with is that its current machine learning and data science ecosystems are still in their infancy. Fortunately, Google is addressing this issue with the inclusion of Python interoperability in Swift. The idea is to make it possible to write Python code inside Swift code, and in this way have access to the huge quantity of great Python libraries.&lt;/p&gt;
&lt;p&gt;A typical use case for this would be to train a model in Swift and use Python’s matplotlib to plot it:&lt;/p&gt;
&lt;div class=&quot;highlight&quot; readability=&quot;18&quot;&gt;
&lt;pre&gt;
&lt;code class=&quot;language-swift&quot; data-lang=&quot;swift&quot;&gt;&lt;span&gt;import&lt;/span&gt; &lt;span&gt;Python&lt;/span&gt;
print(Python.version)

&lt;span&gt;let&lt;/span&gt; np = Python.&lt;span&gt;import&lt;/span&gt;(&lt;span&gt;&quot;numpy&quot;&lt;/span&gt;)
&lt;span&gt;let&lt;/span&gt; plt = Python.&lt;span&gt;import&lt;/span&gt;(&lt;span&gt;&quot;matplotlib.pyplot&quot;&lt;/span&gt;)

&lt;span&gt;// let time = np.arange(0, 10, 0.01)&lt;/span&gt;
&lt;span&gt;let&lt;/span&gt; time = Array(stride(from: &lt;span&gt;0&lt;/span&gt;, through: &lt;span&gt;10&lt;/span&gt;, by: &lt;span&gt;0.01&lt;/span&gt;)).makeNumpyArray()
&lt;span&gt;let&lt;/span&gt; amplitude = np.exp(&lt;span&gt;-&lt;/span&gt;&lt;span&gt;0.1&lt;/span&gt; &lt;span&gt;*&lt;/span&gt; time)
&lt;span&gt;let&lt;/span&gt; position = amplitude &lt;span&gt;*&lt;/span&gt; np.sin(&lt;span&gt;3&lt;/span&gt; &lt;span&gt;*&lt;/span&gt; time)

plt.figure(figsize: [&lt;span&gt;15&lt;/span&gt;, &lt;span&gt;10&lt;/span&gt;])

plt.plot(time, position)
plt.plot(time, amplitude)
plt.plot(time, &lt;span&gt;-&lt;/span&gt;amplitude)

plt.xlabel(&lt;span&gt;&quot;Time (s)&quot;&lt;/span&gt;)
plt.ylabel(&lt;span&gt;&quot;Position (m)&quot;&lt;/span&gt;)
plt.title(&lt;span&gt;&quot;Oscillations&quot;&lt;/span&gt;)

plt.show()&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;It looks like plain old Python with the addition of &lt;code&gt;let&lt;/code&gt; and &lt;code&gt;var&lt;/code&gt; statements. This is a code sample provided by Google. The only modification I made was to comment out one Python line and rewrite it in Swift, to be able to see how well they interface together. It’s not as clean as doing it all in Python, since I had to use &lt;code&gt;makeNumpyArray()&lt;/code&gt; and &lt;code&gt;Array()&lt;/code&gt; but it works, which is awesome.&lt;/p&gt;
&lt;p&gt;Google managed to pull this off by introducing the &lt;code&gt;PythonObject&lt;/code&gt; type, which can represent any object in Python. The Python interop project is contained in a single Swift library, so the S4TF team only needed to make a few additions to the Swift language itself, such as &lt;a href=&quot;https://github.com/apple/swift-evolution/blob/master/proposals/0195-dynamic-member-lookup.md&quot;&gt;the addition&lt;/a&gt; of some improvements to accommodate for Python’s extreme dynamism. With regards to how much Python it supports, I’ve yet to find out how they expect to manage more idiomatic Python elements such as &lt;code&gt;with&lt;/code&gt; statements, and I am sure there are some other corner cases to be considered as well, but still, this is already an amazing feature as-is.&lt;/p&gt;
&lt;p&gt;While on the subject of Swift’s integration with other languages, one of my initial interests in Swift was to determine how well it would fare with a real-time computer vision task. For this reason, I ended up looking for a Swift version of &lt;a href=&quot;https://opencv.org/&quot;&gt;OpenCV&lt;/a&gt;, and through FastAI’s forum I ended up finding a promising OpenCV wrapper called &lt;a href=&quot;https://github.com/vvmnnnkv/SwiftCV&quot;&gt;SwiftCV&lt;/a&gt;. This library is peculiar, though: OpenCV is built in C++ (and has just deprecated its C API), and Swift doesn’t currently support C++ &lt;a href=&quot;https://forums.swift.org/t/manifesto-interoperability-between-swift-and-c/33874&quot;&gt;(though it is coming)&lt;/a&gt;. Hence, SwiftCV has had to resort to wrapping OpenCV’s code in a C compatible subset of C++ code, and then importing it as C. Only after this could they wrap it in Swift.&lt;/p&gt;
&lt;p&gt;I decided to add video support to SwiftCV, as I needed it and the project didn’t have it at the time. I also wanted to test Swift’s C interop capabilities in a more complex situation than what the tutorials describe. Therefore, I submitted &lt;a href=&quot;https://github.com/vvmnnnkv/SwiftCV/pull/5&quot;&gt;this pull request&lt;/a&gt;, which is a useful self-contained example of how Swift’s interop with C++ through a C wrapper looks. The process was painless, even for a Swift beginner such as myself, so props to the Swift devs for that.&lt;/p&gt;
&lt;h2 id=&quot;current-state-of-the-project&quot;&gt;Current state of the project&lt;/h2&gt;
&lt;p&gt;Even after all the praise I have showered the S4TF project with, I have to admit that it is still not ready for general production usage. The new APIs &lt;a href=&quot;https://github.com/apple/swift/commit/7041e2716f41113e14ad19aeaf510ea77c778cc5&quot;&gt;are still changing&lt;/a&gt;, performance of the new TensorFlow library is still not great, and even though its data science ecosystem is growing, it’s still in its infancy. On top of that, Linux support is still flaky, with only Ubuntu being officially supported at the moment. With all that in mind, there is a lot of work going into ensuring all of these issues are promptly fixed.&lt;/p&gt;
&lt;p&gt;Google is working hard on performance gains, including the recent &lt;a href=&quot;https://github.com/tensorflow/swift-apis/pull/719&quot;&gt;addition of x10&lt;/a&gt; and the efforts being made on getting MLIR up to par. Also, there are several projects aimed at replicating a lot of the Python data science ecosystem in Swift that originated at Google, such as &lt;a href=&quot;https://github.com/KarthikRIyer/swiftplot&quot;&gt;SwiftPlot&lt;/a&gt;, the Pandas-like &lt;a href=&quot;https://github.com/saeta/penguin&quot;&gt;Penguin&lt;/a&gt;, and the Scikit-learn-like &lt;a href=&quot;https://github.com/param087/swiftML&quot;&gt;swiftML&lt;/a&gt;, to name a few.&lt;/p&gt;
&lt;p&gt;What is most surprising, though, is that Apple is moving Swift in the same direction as Google is. On &lt;a href=&quot;https://forums.swift.org/t/on-the-road-to-swift-6/32862&quot;&gt;their roadmap&lt;/a&gt; for Swift’s next major version, they’ve established growing the Swift software ecosystem on non-Apple platforms as their primary objective. This is reflected by Apple’s support for several projects like the &lt;a href=&quot;https://swift.org/server/&quot;&gt;Swift Server Work Group&lt;/a&gt;, the numpy like &lt;a href=&quot;https://swift.org/blog/numerics/&quot;&gt;Numerics&lt;/a&gt;, an official &lt;a href=&quot;https://github.com/apple/sourcekit-lsp&quot;&gt;language server&lt;/a&gt; which runs on Linux, and the work being done to port Swift to Windows.&lt;/p&gt;
&lt;p&gt;Furthermore, &lt;a href=&quot;https://twitter.com/guggersylvain&quot;&gt;Sylvain Gugger&lt;/a&gt; from Fast.ai is currently building a &lt;a href=&quot;https://github.com/fastai/swiftai&quot;&gt;Swift version of FastAI&lt;/a&gt;, and Jeremy Howard has included lessons in Swift to their massively popular online course. Also, the first &lt;a href=&quot;https://twitter.com/eaplatanios/status/1229856859408011264&quot;&gt;academic papers&lt;/a&gt; built on &lt;a href=&quot;https://github.com/eaplatanios/swift-rl&quot;&gt;S4TF based libraries&lt;/a&gt; are starting to get published!&lt;/p&gt;
&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;In my personal opinion, while Swift has a huge chance of becoming a key player in the machine learning ecosystem, there are still risks. The biggest risk being that, in spite of its flaws, Python really is good enough for a huge portion of machine learning tasks. The inertia might be too large for many people who are already comfortable with Python and see no reason to switch over to another language. Additionally, there is the issue of Google having a well-deserved reputation for dropping large projects, and &lt;a href=&quot;https://twitter.com/rxwei/status/1185412505775927296&quot;&gt;some&lt;/a&gt;-&lt;a href=&quot;https://twitter.com/clattner_llvm/status/1221824735484362754&quot;&gt;key&lt;/a&gt;-&lt;a href=&quot;https://twitter.com/eugene_burmako/status/1229825664032763904&quot;&gt;departures&lt;/a&gt; from the S4TF project are &lt;a href=&quot;https://twitter.com/clattner_llvm/status/1222032740897284097&quot;&gt;leaving people worried&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Having provided these disclaimers, I still think that Swift is a great language, and the new additions are so innovative that it’s bound to eventually find its place in the machine learning community. Therefore, if you want to contribute to a project with enormous growth potential, now is a great time to start. Things are still not very established, there are a lot of tools that still need creating, and a small personal project now could become a huge community project in the future as the Swift machine learning ecosystem continues to grow.&lt;/p&gt;

</description>
<pubDate>Thu, 09 Apr 2020 08:54:24 +0000</pubDate>
<dc:creator>BerislavLopac</dc:creator>
<og:url>https://tryolabs.com/blog/2020/04/02/swift-googles-bet-on-differentiable-programming/</og:url>
<og:title>Swift: Google's bet on differentiable programming | Tryolabs Blog</og:title>
<og:type>article</og:type>
<og:description>Google's plans on making Swift the first mainstream language with first-class language-integrated differentiable programming capabilities. What's so cool about Swift?</og:description>
<og:image>https://tryolabs.com/images/blog/social/2020-04-02-Swift.143f7a10.png</og:image>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://tryolabs.com/blog/2020/04/02/swift-googles-bet-on-differentiable-programming/</dc:identifier>
</item>
<item>
<title>I graduated into the dot com bust as a programmer and made it – you will too</title>
<link>https://builtin.com/software-engineering-perspectives/dot-com-bust-programmer</link>
<guid isPermaLink="true" >https://builtin.com/software-engineering-perspectives/dot-com-bust-programmer</guid>
<description>&lt;p dir=&quot;ltr&quot;&gt;&lt;span&gt;&lt;span&gt;It’s February in the year 2001, and I am sick as a dog. I am a senior at Loyola University in Chicago, majoring in computer science; for my entire time here, everyone around me has looked forward to the well-paying jobs we would surely get when we graduated. A couple years ago, a good friend of mine dropped out to take one of those jobs. I wanted my degree, so I stuck it out —and now I’m also having to stick out a terrible stomach flu after eating from an unnamed national sandwich restaurant chain.&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p dir=&quot;ltr&quot;&gt;&lt;span&gt;&lt;span&gt;I decide to go to a job fair on campus, still feeling awful. I talk to an agtech company, which had sent a woman there to represent its needs for entry level programmers. I can detect in her voice that I won’t move forward with them; probably none of the people here will. The dot-com boom is already turning into a bust.&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p dir=&quot;ltr&quot;&gt;&lt;span&gt;&lt;span&gt;There are layoffs every week. All of the companies powered purely by potential but not by actual revenue — companies that had nevertheless snagged funding — are going out of business. As an almost-grad, I had wondered why anyone would hire me when there were going to be thousands of seasoned professionals to choose from instead. And, anyway, I still feel really sick, so I go home to lie in bed.&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p dir=&quot;ltr&quot;&gt; &lt;/p&gt;
&lt;h3 dir=&quot;ltr&quot;&gt;&lt;span&gt;&lt;span&gt;May 2001&lt;/span&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;p dir=&quot;ltr&quot;&gt;&lt;span&gt;&lt;span&gt;It’s May. I’m a new graduate in the wonderful field of computer science. I work in the computer lab at Loyola’s Crown Center for the Humanities, in what amounts to its basement. If people want to print something, it edges out from a computer behind a window counter, and I hand it to them from there. Sometimes, we play &lt;em&gt;Age of Empires II&lt;/em&gt; on the LAN. I’m just glad I have something to do.&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p dir=&quot;ltr&quot;&gt;&lt;span&gt;&lt;span&gt;Sometimes, I spread out newspapers on my desk and survey the classifieds for jobs. Monster.com is relatively new, and Dice.com is basically the Monster specifically for tech jobs. I use them both. But it’s still a tough time for an entry level programmer to find work. No one returns my calls. At any rate, I am starting to think I need to use my network to land a job.&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p dir=&quot;ltr&quot;&gt;&lt;span&gt;&lt;span&gt;I do know someone who works at Loyola, whose husband works at a real estate company. They need a database programmer.&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p dir=&quot;ltr&quot;&gt;&lt;span&gt;&lt;span&gt;American Invsco isn’t Sun Microsystems, or IBM, or any of the cool places I thought I’d end up. But the company offers me a programming job, and it pays. I take it, feeling fortunate to find a job that makes use of the skills I learned in college.&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p dir=&quot;ltr&quot;&gt; &lt;/p&gt;
&lt;h3 dir=&quot;ltr&quot;&gt;&lt;span&gt;&lt;span&gt;September 2001&lt;/span&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;p dir=&quot;ltr&quot;&gt;&lt;span&gt;&lt;span&gt;I start on September 10th. When I arrive, they don’t have a computer ready for me, but they do give me a large office. I spend the rest of the day writing pseudocode on a legal notepad.&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p dir=&quot;ltr&quot;&gt;&lt;span&gt;&lt;span&gt;As I’m showering for my second day of work in one of the most terrible economies for technical talent, one of the World Trade Center’s towers is struck by an airplane. I’m scared; I don’t know what this means, but I don’t want to be late. I board the Red Line train from Loyola’s campus to Clark/Division, on the north side of downtown, where I take the short walk to my new office. My colleagues are talking about two airplanes now. My boss’ small, portable TV, which sits on a row of filing cabinets in the main pit, tells us about the Pentagon.&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p dir=&quot;ltr&quot;&gt;&lt;span&gt;&lt;span&gt;We are all terrified that the John Hancock building will fall on us. At noon, I decide to leave for home. No one told us to go — we just decided on our own when our time was up that day.&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p dir=&quot;ltr&quot;&gt; &lt;/p&gt;
&lt;h3 dir=&quot;ltr&quot;&gt;&lt;span&gt;&lt;span&gt;April 2020 &lt;/span&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;p dir=&quot;ltr&quot;&gt;&lt;span&gt;&lt;span&gt;Things got better, of course. We were doing pretty well until 2008, when we weren’t doing so well. Then we did pretty well again. That’s the nature of life, isn’t it? It oscillates, like a sine wave, like the rise and fall of your chest as you breathe in and out.&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p dir=&quot;ltr&quot;&gt;&lt;span&gt;&lt;span&gt;I am, of course, eliding all of the terrible specifics of COVID-19. We’ve lost so many, and we’ll lose more. Our lives will change in ways we would not choose and that includes our economy, secondary though that may feel.&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p dir=&quot;ltr&quot;&gt;&lt;span&gt;&lt;span&gt;But we’ll also make it through. We must because, whether we choose it or not, this is our new reality.&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p dir=&quot;ltr&quot;&gt; &lt;/p&gt;
&lt;div class=&quot;snippet-box snippet-box-text&quot; readability=&quot;32&quot;&gt;
&lt;h2 class=&quot;title&quot;&gt;Expert Columnist&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Peter Evans&lt;/strong&gt; is the CTO of Built In.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;cta-line cta-line-purple&quot;&gt;
&lt;div class=&quot;cols&quot; readability=&quot;5.8159509202454&quot;&gt;
&lt;div class=&quot;col-left&quot; readability=&quot;10&quot;&gt;
&lt;p&gt;Expert Contributor Network&lt;/p&gt;
&lt;div class=&quot;description&quot; readability=&quot;11&quot;&gt;
&lt;p&gt;Built In’s expert contributor network publishes thoughtful, solutions-oriented stories and commentary written by innovative tech professionals. It is the tech industry’s definitive destination for sharing compelling, first-person accounts of problem-solving on the road to innovation.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;
</description>
<pubDate>Thu, 09 Apr 2020 01:08:52 +0000</pubDate>
<dc:creator>loumal</dc:creator>
<og:url>https://builtin.com/software-engineering-perspectives/dot-com-bust-programmer</og:url>
<og:title>I Graduated Into the Dot Com Bust as a Programmer and Made It. You Will Too.</og:title>
<og:description>To all the young programmers worrying about this uncertain job market, I promise things will get better.</og:description>
<og:image>https://builtin.com/sites/default/files/styles/og/public/2020-04/market.png</og:image>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://builtin.com/software-engineering-perspectives/dot-com-bust-programmer</dc:identifier>
</item>
</channel>
</rss>