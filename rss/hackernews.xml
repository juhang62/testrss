<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="css/feed.xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/" xmlns:og="http://ogp.me/ns#">
<channel>
<atom:link rel="self" href="http://192.168.1.4/fivefilters/makefulltextfeed.php?url=hnrss.org%2Fnewest%3Fpoints%3D200&amp;max=10&amp;links=preserve&amp;exc=" />
<atom:link rel="alternate" title="Source URL" href="http://hnrss.org/newest?points=200" />
<atom:link rel="related" title="Subscribe to feed" href="http://www.subtome.com/#/subscribe?feeds=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dhnrss.org%252Fnewest%253Fpoints%253D200%26max%3D10%26links%3Dpreserve%26exc%3D&amp;back=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dhnrss.org%252Fnewest%253Fpoints%253D200%26max%3D10%26links%3Dpreserve%26exc%3D" />
<title>Hacker News: Newest</title>
<link>https://news.ycombinator.com/newest</link>
<description>Hacker News RSS</description>
<item>
<title>The Psychological Trap of Freelancing</title>
<link>https://www.thecut.com/2019/02/why-freelancing-creates-anxiety-about-money.html</link>
<guid isPermaLink="true" >https://www.thecut.com/2019/02/why-freelancing-creates-anxiety-about-money.html</guid>
<description>&lt;div class=&quot;lede-image-wrapper inline horizontal has-secondary-area&quot;&gt;&lt;img src=&quot;https://pixel.nymag.com/imgs/fashion/daily/2016/10/19/19-money-mom.w700.h700.jpg&quot; class=&quot;lede-image&quot; data-src=&quot;https://pixel.nymag.com/imgs/fashion/daily/2016/10/19/19-money-mom.w700.h700.jpg&quot; data-content-img=&quot;&quot; alt=&quot;&quot;/&gt;&lt;div class=&quot;lede-image-data&quot;&gt;
&lt;div class=&quot;mobile-secondary-area&quot;&gt;
&lt;aside class=&quot;article-details&quot; data-uri=&quot;www.thecut.com/_components/article-details/instances/cjrw8637g000dj4y60oumwnhe@published&quot;&gt;&lt;div class=&quot;article-details-info&quot;&gt;
&lt;p class=&quot;article-details-body&quot; data-editable=&quot;body&quot;&gt;The Cut’s financial advice columnist Charlotte Cowles answers readers’ personal questions about personal finance. Email your money conundrums to &lt;a href=&quot;mailto:moneymom@nymag.com&quot;&gt;mytwocents@nymag.com&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/aside&gt;&lt;/div&gt;
&lt;div class=&quot;attribution&quot;&gt;&lt;span class=&quot;credit&quot;&gt;Photo: H. Armstrong Roberts/ClassicStoc/Getty Images&lt;/span&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p class=&quot;clay-paragraph&quot; data-editable=&quot;text&quot; data-uri=&quot;www.thecut.com/_components/clay-paragraph/instances/cjrw8637g000ij4y6bwuxnepv@published&quot; data-word-count=&quot;85&quot;&gt;For most of my career, I was paid a salary. It was not very much, especially at the beginning, but it also seemed to exist on a different plane from my actual job. I worked as hard and as much as I could, and then twice a month a dollar amount materialized in my checking account. My time did not feel tethered to this money. My paycheck was just a byproduct of going into an office every day, and a pretty arbitrary one at that.&lt;/p&gt;
&lt;p class=&quot;clay-paragraph&quot; data-editable=&quot;text&quot; data-uri=&quot;www.thecut.com/_components/clay-paragraph/instances/cjrw86791000w3g66617f6hsx@published&quot; data-word-count=&quot;102&quot;&gt;But once I started freelancing, things changed. I became hyperconscious of how much money I could (or should) charge for my time, and this made me unhappy and mean when my nonworking hours didn’t measure up to the same value. It was akin to the rage of watching cab fare tick up while you’re sitting in traffic, minutes and dollars dribbling away before your eyes. A freelancer friend recently commiserated: “I went outside to get coffee and ran into three different neighbors who wanted to chit-chat. I wanted to scream, ‘For every word that comes out of your mouth, I’m losing money!’”&lt;/p&gt;
&lt;aside data-uri=&quot;www.thecut.com/_components/ad/instances/cjrw8637g000ej4y6jnsso61j@published&quot; data-placeholder=&quot;settings&quot; class=&quot;ad vp-0-600&quot; data-name=&quot;/4088/The_Cut_Mobile&quot; data-sizes=&quot;300x250,300x252,320x100&quot; data-label=&quot;inArticleMobile&quot; data-site=&quot;TheCut&quot; id=&quot;ad-cid-zhRcmuWa&quot;/&gt;&lt;p class=&quot;clay-paragraph&quot; data-editable=&quot;text&quot; data-uri=&quot;www.thecut.com/_components/clay-paragraph/instances/cjrw867bl000x3g664iw2o6dv@published&quot; data-word-count=&quot;80&quot;&gt;The upside of becoming aware of the time/money connection is that I got better at managing my finances and asking for bigger fees — a good thing, especially when compared to how lackadaisical I’d been in this department previously. But I was also stressed out. I started sleeping less, and I stopped hanging out with my friends as much as I wanted. And I would sometimes fall apart completely, frittering away a Saturday in bed and feeling horrible about it.&lt;/p&gt;
&lt;aside data-uri=&quot;www.thecut.com/_components/ad/instances/cjrw8637g000fj4y6j92it0dg@published&quot; data-placeholder=&quot;settings&quot; class=&quot;ad vp-600-1024&quot; data-name=&quot;/4088/nym.thecut&quot; data-sizes=&quot;300x250&quot; data-label=&quot;inArticleTablet&quot; data-site=&quot;TheCut&quot; id=&quot;ad-cid-RdgDwpAf&quot;/&gt;&lt;aside data-uri=&quot;www.thecut.com/_components/ad/instances/cjrw8637g000hj4y617t43unb@published&quot; data-placeholder=&quot;settings&quot; class=&quot;ad vp-1024-plus&quot; data-name=&quot;/4088/nym.thecut&quot; data-sizes=&quot;528x379&quot; data-label=&quot;outStreamDesktop&quot; data-site=&quot;TheCut&quot; id=&quot;ad-cid-AE7nUFPc&quot;/&gt;&lt;p class=&quot;clay-paragraph&quot; data-editable=&quot;text&quot; data-uri=&quot;www.thecut.com/_components/clay-paragraph/instances/cjrw867e3000y3g665y6uuzvz@published&quot; data-word-count=&quot;56&quot;&gt;&lt;a href=&quot;https://www.hbs.edu/faculty/Publication%20Files/Making%20Seconds%20Count_24e6d6b5-5645-47a0-a4ab-70dd11653f5a.pdf&quot;&gt;New research&lt;/a&gt; explains the psychology behind my state of mind: People who attach dollar signs to their time — or “value time &lt;em&gt;like&lt;/em&gt; money” — tend to be overwhelmingly less happy than those who don’t, because their nonworking hours suddenly seem less important. “Free” time gets tainted with guilt because there’s a cost associated with it.&lt;/p&gt;
&lt;aside data-uri=&quot;www.thecut.com/_components/ad/instances/cjrw8637g000gj4y6armqus57@published&quot; data-placeholder=&quot;settings&quot; class=&quot;ad vp-0-600&quot; data-name=&quot;/4088/The_Cut_Mobile&quot; data-sizes=&quot;528x379&quot; data-label=&quot;outStreamMobile&quot; data-site=&quot;TheCut&quot; id=&quot;ad-cid-js7q1Z44&quot;/&gt;&lt;p class=&quot;clay-paragraph&quot; data-editable=&quot;text&quot; data-uri=&quot;www.thecut.com/_components/clay-paragraph/instances/cjrw867g2000z3g66wmedxyx5@published&quot; data-word-count=&quot;68&quot;&gt;Many Americans fall into this trap. A &lt;a href=&quot;https://journals.sagepub.com/doi/10.1177/1948550616649239&quot;&gt;2016 study&lt;/a&gt; found that 63 percent of respondents valued money over time, while the smaller percentage of people who valued time over money &lt;a href=&quot;https://journals.sagepub.com/doi/abs/10.1177/1948550615623842&quot;&gt;reported greater well-being&lt;/a&gt; than the larger group. This correlation was consistent even after researchers controlled for factors like income — which complicates the assumption that prioritizing time over money is a luxury that only rich people can afford.&lt;/p&gt;
&lt;p class=&quot;clay-paragraph&quot; data-editable=&quot;text&quot; data-uri=&quot;www.thecut.com/_components/clay-paragraph/instances/cjrw867i000103g666aw1sclz@published&quot; data-word-count=&quot;86&quot;&gt;As the economy moves away from traditional salaried jobs and toward contract gigs, more and more people are starting to feel like I did. &lt;a href=&quot;https://www.gsb.stanford.edu/insights/time-money-when-youre-paid-hour&quot;&gt;Other studies found&lt;/a&gt; that billing by the hour — no matter how much people charged — compounded the tendency to view time and money as one and the same. Those who did so were less likely to take pleasure in leisure activities, because they were too preoccupied by the opportunity cost of their time. Again, these trends were similar across income levels.&lt;/p&gt;
&lt;aside data-uri=&quot;www.thecut.com/_components/ad/instances/cjrw8637g000ej4y6jnsso61j@published&quot; data-placeholder=&quot;settings&quot; class=&quot;ad vp-0-600&quot; data-name=&quot;/4088/The_Cut_Mobile&quot; data-sizes=&quot;300x250,300x252,320x100&quot; data-label=&quot;inArticleMobile&quot; data-site=&quot;TheCut&quot; id=&quot;ad-cid-ECaMyRD7&quot;/&gt;&lt;p class=&quot;clay-paragraph&quot; data-editable=&quot;text&quot; data-uri=&quot;www.thecut.com/_components/clay-paragraph/instances/cjrw867kt00113g66280jm7dq@published&quot; data-word-count=&quot;151&quot;&gt;While time versus money anxiety may be more acute for freelancers, we aren’t the only ones who struggle with it. In a recent survey of 2.5 million Americans across all socioeconomic strata, &lt;a href=&quot;https://hbr.org/cover-story/2019/01/time-for-happiness&quot;&gt;80 percent of respondents&lt;/a&gt; said that they didn’t have enough time to do what they wanted every day. Psychologist Ashley Whillans, a professor at the Harvard Business School who researches “time poverty” (also known as the feeling of running 20 minutes late to everything in your life), attributes this to an increasingly volatile job landscape. “Most people don’t have the same jobs for 10 or 15 years like previous generations did, which leads to a feeling of financial insecurity,” she says. “It isn’t about how financially secure you really are, or how much money you have in the bank, but how financially secure you &lt;em&gt;feel&lt;/em&gt; that predicts whether you are willing to give up time to have more money.”&lt;/p&gt;
&lt;aside data-uri=&quot;www.thecut.com/_components/ad/instances/cjrw8637g000fj4y6j92it0dg@published&quot; data-placeholder=&quot;settings&quot; class=&quot;ad vp-600-1024&quot; data-name=&quot;/4088/nym.thecut&quot; data-sizes=&quot;300x250&quot; data-label=&quot;inArticleTablet&quot; data-site=&quot;TheCut&quot; id=&quot;ad-cid-V3aZpACL&quot;/&gt;&lt;p class=&quot;clay-paragraph&quot; data-editable=&quot;text&quot; data-uri=&quot;www.thecut.com/_components/clay-paragraph/instances/cjrw867m700123g660xveqr77@published&quot; data-word-count=&quot;171&quot;&gt;If valuing money over time is making us sad and paranoid, how do we stop? The solution, Whillans suggests, lies in changing your approach to time “off.” It may be too late to decouple time and money in our brains, especially when finances feel tight, but we can lean into that. “If we’re already in the time-is-money mindset, we can reframe our leisure time as something that enables us to be more productive in the future,” says Whillan. “When we’re conditioned to think of all our time as ‘on the clock,’ leisure time feels abstract and unsatisfying. But if we tell ourselves that leisure time is another means to achieve that goal or financial outcome, that can make us more likely to take the breaks that we need, enjoy them fully, and be happier in general.” If it helps you to think of it this way, great. But you also have permission to just relax, without worrying about how to improve your productivity when you’re once again hunched over your laptop.&lt;/p&gt;
&lt;aside data-uri=&quot;www.thecut.com/_components/ad/instances/cjrw8637g000ej4y6jnsso61j@published&quot; data-placeholder=&quot;settings&quot; class=&quot;ad vp-0-600&quot; data-name=&quot;/4088/The_Cut_Mobile&quot; data-sizes=&quot;300x250,300x252,320x100&quot; data-label=&quot;inArticleMobile&quot; data-site=&quot;TheCut&quot; id=&quot;ad-cid-xrhx2PYG&quot;/&gt;&lt;p class=&quot;clay-paragraph&quot; data-editable=&quot;text&quot; data-uri=&quot;www.thecut.com/_components/clay-paragraph/instances/cjrw867oa00133g66d98h36m4@published&quot; data-word-count=&quot;93&quot;&gt;Another trick is to figure out what you’re willing (and can afford) to outsource and what you’d prefer do yourself, says Elizabeth Dunn, a psychology professor at the University of British Columbia. She’s &lt;a href=&quot;https://dunn.psych.ubc.ca/&quot;&gt;currently researching&lt;/a&gt; time-versus-money tradeoffs through an app called Joy that asks users to rate which time-saving expenses make them happiest. (Laundry services rank high, she says, while fast-food purchases do not.) Here, of course, is where income makes a significant difference; not everyone can afford the luxury of ordering out so they can finish another draft of a freelance project.&lt;/p&gt;
&lt;p class=&quot;clay-paragraph&quot; data-editable=&quot;text&quot; data-uri=&quot;www.thecut.com/_components/clay-paragraph/instances/cjrw867qg00143g668hkeldxm@published&quot; data-word-count=&quot;92&quot;&gt;“Our work does show that buying time, or paying your way out of things that don’t bring you a lot of satisfaction, buffers people against the negative effects of time stress,” explains Dunn. What she does not recommend, however, is sacrificing healthy activities you enjoy in order to make more money, at least when you can help it. “If walking your dog is a fulfilling part of your day but you need to pay someone else to do it in order to work on a boring project, you might reconsider your priorities.”&lt;/p&gt;
</description>
<pubDate>Mon, 11 Feb 2019 09:10:30 +0000</pubDate>
<dc:creator>ingve</dc:creator>
<og:title>The Psychological Trap of Freelancing</og:title>
<og:url>https://www.thecut.com/2019/02/why-freelancing-creates-anxiety-about-money.html</og:url>
<og:description>The time-is-money mind-set is hard to escape.</og:description>
<og:image>https://pixel.nymag.com/imgs/fashion/daily/2016/10/19/19-money-mom.w1200.h630.jpg</og:image>
<og:type>article</og:type>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.thecut.com/2019/02/why-freelancing-creates-anxiety-about-money.html</dc:identifier>
</item>
<item>
<title>The Raspberry Pi store is much cooler than an Apple Store</title>
<link>https://techcrunch.com/2019/02/07/the-raspberry-pi-store-is-much-cooler-than-an-apple-store/</link>
<guid isPermaLink="true" >https://techcrunch.com/2019/02/07/the-raspberry-pi-store-is-much-cooler-than-an-apple-store/</guid>
<description>&lt;p id=&quot;speakable-summary&quot;&gt;The &lt;a class=&quot;crunchbase-link&quot; href=&quot;https://crunchbase.com/organization/raspberry&quot; target=&quot;_blank&quot; data-type=&quot;organization&quot; data-entity=&quot;raspberry&quot;&gt;Raspberry&lt;/a&gt; Pi Foundation just &lt;a href=&quot;https://www.raspberrypi.org/blog/guess-what/&quot;&gt;unveiled&lt;/a&gt; a brand new project — an actual &lt;a href=&quot;https://www.raspberrypi.org/raspberry-pi-store/&quot;&gt;store&lt;/a&gt;. If you live in Cambridge in the U.K., you can now buy a bunch of sweet Raspberry Pis with which to tinker and develop some cool stuff.&lt;/p&gt;
&lt;p&gt;The Raspberry Pi has always been about making coding more accessible. And a physical retail space fits the bill. The foundation has developed a lineup of insanely cheap computers with an ARM-based processor, a bunch of ports, Wi-Fi and Bluetooth.&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;embed-youtube embed breakout embed--video&quot;&gt;&lt;iframe class=&quot;youtube-player&quot; type=&quot;text/html&quot; width=&quot;640&quot; height=&quot;360&quot; src=&quot;https://www.youtube.com/embed/QLBVAUo586A?version=3&amp;amp;rel=1&amp;amp;fs=1&amp;amp;autohide=2&amp;amp;showsearch=0&amp;amp;showinfo=1&amp;amp;iv_load_policy=1&amp;amp;wmode=transparent&quot; allowfullscreen=&quot;true&quot;&gt;[embedded content]&lt;/iframe&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The latest flagship model, the Raspberry Pi 3 Model B+, costs only $35. But if you want something smaller and cheaper, there are other models for various needs.&lt;/p&gt;
&lt;p&gt;Maybe you just need a tiny computer for some Internet-of-Things project. You can opt for the Raspberry Pi 3 Model A+ for $25 in that case. It has a bit less RAM and fewer ports, but it works pretty much like any Raspberry Pi. There’s also power-efficient models that cost less than $10 — the Raspberry Pi Zero models.&lt;/p&gt;
&lt;p&gt;I never really thought about Raspberry Pi stores. But the introduction video makes a strong case in favor of such a store. The product lineup is getting a bit complicated and it’s always good to be able to talk to someone about your projects.&lt;/p&gt;
&lt;p&gt;Moreover, the foundation can use this store as a showcase for some cool examples. You can also buy goodies, such as mugs and plushy toys. The white-and-red keyboard and mouse look cool, too.&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;breakout alignnone size-full wp-image-1780080&quot; src=&quot;https://techcrunch.com/wp-content/uploads/2019/02/Raspberry-Pi-Peripherals.jpg&quot; alt=&quot;&quot; width=&quot;1024&quot; height=&quot;683&quot; srcset=&quot;https://techcrunch.com/wp-content/uploads/2019/02/Raspberry-Pi-Peripherals.jpg 6240w, https://techcrunch.com/wp-content/uploads/2019/02/Raspberry-Pi-Peripherals.jpg?resize=150,100 150w, https://techcrunch.com/wp-content/uploads/2019/02/Raspberry-Pi-Peripherals.jpg?resize=300,200 300w, https://techcrunch.com/wp-content/uploads/2019/02/Raspberry-Pi-Peripherals.jpg?resize=768,512 768w, https://techcrunch.com/wp-content/uploads/2019/02/Raspberry-Pi-Peripherals.jpg?resize=680,453 680w, https://techcrunch.com/wp-content/uploads/2019/02/Raspberry-Pi-Peripherals.jpg?resize=50,33 50w&quot; sizes=&quot;(max-width: 1024px) 100vw, 1024px&quot;/&gt;&lt;/p&gt;
</description>
<pubDate>Mon, 11 Feb 2019 03:49:06 +0000</pubDate>
<dc:creator>longdefeat</dc:creator>
<og:title>The Raspberry Pi store is much cooler than an Apple Store</og:title>
<og:description>The Raspberry Pi Foundation just unveiled a brand new project — an actual store. If you live in Cambridge in the U.K., you can now buy a bunch of sweet Raspberry Pis with which to tinker and develop some cool stuff. The Raspberry Pi has always been about making coding more accessible. And a physica…</og:description>
<og:image>https://techcrunch.com/wp-content/uploads/2019/02/Store-Outdside.jpg?w=600</og:image>
<og:url>http://social.techcrunch.com/2019/02/07/the-raspberry-pi-store-is-much-cooler-than-an-apple-store/</og:url>
<og:type>article</og:type>
<dc:language>en-US</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://techcrunch.com/2019/02/07/the-raspberry-pi-store-is-much-cooler-than-an-apple-store/</dc:identifier>
</item>
<item>
<title>Undercover spy exposed in NYC was one of many</title>
<link>https://apnews.com/a1d1af4256c04cc5a36347667e966a14</link>
<guid isPermaLink="true" >https://apnews.com/a1d1af4256c04cc5a36347667e966a14</guid>
<description>&lt;p&gt;LONDON (AP) — When mysterious operatives lured two cybersecurity researchers to meetings at luxury hotels over the past two months, it was an apparent bid to discredit their research about an Israeli company that makes smartphone hacking technology used by some governments to spy on their citizens. The Associated Press has now learned of similar undercover efforts targeting at least four other individuals who have raised questions about the use of the Israeli firm’s spyware.&lt;/p&gt;

&lt;p&gt;The four others targeted by operatives include three lawyers involved in related lawsuits in Israel and Cyprus alleging that the company, the NSO Group, sold its spyware to governments with questionable human rights records. The fourth is a London-based journalist who has covered the litigation. Two of them — the journalist and a Cyprus-based lawyer — were secretly recorded meeting the undercover operatives; footage of them was broadcast on Israeli television just as the AP was preparing to publish this story.&lt;/p&gt;
&lt;p&gt;All six of the people who were targeted said they believe the operatives were part of a coordinated effort to discredit them.&lt;/p&gt;
&lt;p&gt;“There’s somebody who’s really interested in sabotaging the case,” said one of the targets, Mazen Masri, who teaches at City University, London and is advising the plaintiffs’ attorney in the case in Israel.&lt;/p&gt;
&lt;p&gt;Masri said the operatives were “looking for dirt and irrelevant information about people involved.”&lt;/p&gt;
&lt;p&gt;The details of these covert efforts offer a glimpse into the sometimes shadowy world of private investigators, which includes some operatives who go beyond gathering information and instead act as provocateurs. The targets told the AP that the covert agents tried to goad them into making racist and anti-Israel remarks or revealing sensitive information about their work in connection with the lawsuits.&lt;/p&gt;
&lt;p&gt;NSO has previously said it has nothing to do with the undercover efforts “either directly or indirectly.” It did not return repeated messages asking about the new targets identified by the AP. American private equity firm Francisco Partners, which owns NSO, did not return a message from the AP seeking comment.&lt;/p&gt;
&lt;p&gt;The undercover operatives’ activities might never have been made public had it not been for two researchers who work at Citizen Lab, an internet watchdog group that is based out of the University of Toronto’s Munk School.&lt;/p&gt;

&lt;p&gt;In December, one of the researchers, John Scott-Railton, realized that a colleague had been tricked into meeting an operative at a Toronto hotel, then questioned about his work on NSO. When a second operative calling himself Michel Lambert approached Scott-Railton to arrange a similar meeting at the Peninsula Hotel in New York, Scott-Railton devised a sting operation, inviting AP journalists to interrupt the lunch and videotape the encounter.&lt;/p&gt;
&lt;p&gt;The story drew wide attention in Israel. Within days, Israeli investigative television show Uvda and The New York Times identified Lambert as Aharon Almog-Assouline, a former Israeli security official living in the plush Tel Aviv suburb of Ramat Hasharon.&lt;/p&gt;
&lt;p&gt;By then, Scott-Railton and the AP had determined the undercover efforts went well beyond Citizen Lab.&lt;/p&gt;
&lt;p&gt;Within hours of the story’s publication, Masri wrote to the AP to say that he and Alaa Mahajna, who is pursuing the lawsuit against NSO in Israel, had spent weeks parrying offers from two wealthy-sounding executives who had contacted them with lucrative offers of work and insistent requests to meet in London.&lt;/p&gt;
&lt;p&gt;“We were on our guard and did not take the bait,” Masri wrote.&lt;/p&gt;
&lt;p&gt;Masri’s revelation prompted a flurry of messages to others tied to litigation involving NSO. Masri and Scott-Railton say they discovered that Christiana Markou, a lawyer representing plaintiffs in a related lawsuit against NSO-affiliated companies in Cyprus, had been flown to London for a strange meeting with someone who claimed to be a Hong Kong-based investor. Around the same time, Masri found out that a journalist who had written about NSO was also invited to a London hotel — twice — and questioned about his reporting.&lt;/p&gt;
&lt;p&gt;“Things are getting more interesting,” Masri wrote as the episodes emerged.&lt;/p&gt;
&lt;p&gt;___&lt;/p&gt;
&lt;p&gt;Like Almog-Assouline, the undercover operative the AP exposed in New York, the covert agents who pursued the lawyers made a string of operational errors.&lt;/p&gt;
&lt;p&gt;The attempt to ensnare Alaa Mahajna, the lead lawyer in the Israeli suit, was a case in point.&lt;/p&gt;
&lt;p&gt;On Nov. 26 he heard from a man who said his name was Marwan Al Haj and described himself as a partner at a Swedish wealth management firm called Lyndon Partners. Al Haj offered Mahajna an intriguing proposition. Al Haj said one of his clients, an ultra-rich individual with family ties to the Middle East, needed legal assistance recovering family land seized by Jewish settlers following the 1967 Arab-Israeli war.&lt;/p&gt;
&lt;p&gt;“I believe you may be a good fit for this challenging task,” Al Haj wrote.&lt;/p&gt;
&lt;p&gt;The request made sense. As a human rights lawyer based in Jerusalem, Mahajna has defended Palestinian activists and others at the receiving end of the Israeli government’s ire. But Mahajna became suspicious as he tried to learn more about the case. Al Haj was cagey about his client and seemed unwilling to provide any paperwork, Mahajna told the AP.&lt;/p&gt;
&lt;p&gt;“Not even the basic stuff,” Mahajna said. “Usually people flood you with documents and stories.”&lt;/p&gt;
&lt;p&gt;Mahajna said he was unsettled when Al Haj suddenly offered him an all-expenses-paid trip to London; no one had even asked him whether the case had any hope of success.&lt;/p&gt;
&lt;p&gt;“At some point it was abundantly clear that this is not a bona fide approach,” Mahajna said.&lt;/p&gt;
&lt;p&gt;Ten days later, Masri, the legal adviser in the Israeli lawsuit, received an email offering him a place on the advisory board of a Zurich-based company called APOL Consulting.&lt;/p&gt;
&lt;p&gt;Masri became skeptical after he checked out the company’s website. Consulting firms typically trade on their employees’ intelligence and skill, so Masri expected the company’s site to prominently display the names, headshots and qualifications of its staff.&lt;/p&gt;
&lt;p&gt;“Here there wasn’t even a name of one human,” he said.&lt;/p&gt;
&lt;p&gt;When Masri turned down the position on APOL’s board, the representative who’d contacted him — a man who called himself Cristian Ortega — pressed Masri to see him in London anyway.&lt;/p&gt;
&lt;p&gt;“I would consider it a privilege to have a chance to meet you in person for a friendly chat,” Ortega said in a Jan. 7 email. “No strings attached of course.”&lt;/p&gt;
&lt;p&gt;Masri said that by then he and Mahajna had come to believe that Ortega and Al Haj were fictions and that their companies were imaginary.&lt;/p&gt;
&lt;p&gt;But they didn’t yet know how widespread the covert operations were.&lt;/p&gt;
&lt;p&gt;___&lt;/p&gt;
&lt;p&gt;The undercover agents got a little further with Christiana Markou, the lawyer who is pursuing the Cypriot case against NSO-affiliated entities.&lt;/p&gt;
&lt;p&gt;Her lawsuit, like Mahajna’s, draws heavily on reports by Citizen Lab that found that NSO spyware had been used to break into the phones of the Mexican activists and journalists who are the plaintiffs in both cases.&lt;/p&gt;
&lt;p&gt;Markou told the AP she was approached over email Dec. 21 by a man who presented himself as Olivier Duffet, a partner at Hong Kong-based ENE Investments.&lt;/p&gt;
&lt;p&gt;Duffet was ostensibly interested in inviting Markou — a leading data protection and privacy lawyer in Cyprus — to give a lecture at a conference. Markou said she proposed discussing the lecture over Skype, but he insisted on an in-person meeting in London, eventually flying her out, putting her up in a fancy hotel and chatting for a little more than an hour.&lt;/p&gt;
&lt;p&gt;Most of the discussion revolved around the proposed lecture — but then Duffet suddenly pivoted to the NSO case, asking her whether she felt the lawsuit was winnable and who was funding it.&lt;/p&gt;
&lt;p&gt;Markou said she “gave either incorrect answers or expressly refused to answer” because she found his questions suspicious.&lt;/p&gt;
&lt;p&gt;Yet another target, Eyad Hamid, a London-based journalist who wrote a story about NSO, said he was also invited to a London hotel on two separate occasions to discuss his coverage of the Israeli company.&lt;/p&gt;
&lt;p&gt;The purported company used in the operation targeting him was Mertens-Giraud Partners Management, which was described as a Brussels-based wealth management firm.&lt;/p&gt;
&lt;p&gt;Neither MGP — nor any of the other companies — truly existed. The AP’s searches of the Orbis database of some 300 million companies, local corporate registries and trademark repositories turned up no trace of a Swiss firm called APOL, a Swedish company called Lyndon partners, a Belgian company called Mertens-Giraud or a Hong Kong-based firm named ENE Investments. Local phone books didn’t carry listings for a Zurich-based man named Cristian Ortega, a Hong Kong-based man named Olivier Duffet or anyone in Sweden bearing the name Marwan Al Haj.&lt;/p&gt;
&lt;p&gt;There was no hint of APOL when the AP visited its supposed office not far from Zurich’s central train station; tenants said they’d never heard of the company. It was the same story in Hong Kong; a management representative at the Central Building, where ENE Investments was supposedly located, said he didn’t know anything about the company. An AP journalist wasn’t able to speak to anyone at Mertens-Giraud’s alleged office on Brussels’ Rue des Poissoniers; the entire building was boarded up for renovations.&lt;/p&gt;
&lt;p&gt;At the modern office block in downtown Stockholm where Lyndon Partners claimed to have its headquarters, service manager Elias Broberger said he could find no trace of the wealth management firm.&lt;/p&gt;
&lt;p&gt;“It says they are located here,” Broberger said as he examined Lyndon Partners’ professional-looking website. “But we don’t have them in any of our systems: not the booking system; not the member system. We don’t bill them; they don’t bill us.&lt;/p&gt;
&lt;p&gt;“I can’t find them.”&lt;/p&gt;
&lt;p&gt;___&lt;/p&gt;
&lt;p&gt;Who hired the undercover agents remains unclear, but their operational and digital fingerprints suggest they are linked.&lt;/p&gt;
&lt;p&gt;The six operatives all began approaching their targets around the same time with individually tailored pitches. Their bogus websites followed the same patterns; all of them were hosted on Namecheap and many were bought at auction from GoDaddy and used the Israeli web design platform Wix. The formatting of the websites was similar; in at least two instances — MGP and Lyndon Partners — it was identical. Even the operatives’ email signatures were the same — consisting of three neatly packed, colorful lines consisting of a phone number, web address and email.&lt;/p&gt;
&lt;p&gt;The operatives’ LinkedIn pages were similar, too, featuring men in sunglasses shot from a distance, facing away from the camera, or at unusual angles — a tactic sometimes use to frustrate facial recognition algorithms.&lt;/p&gt;
&lt;p&gt;Despite the indications that the undercover agents are all linked, there is no conclusive evidence who they might work for. An Israeli television channel, Channel 12, broadcast a report on Saturday claiming that an Israeli private investigation firm, Black Cube, had been investigating issues around the lawsuits against NSO. The TV channel showed secretly shot footage of the Cypriot lawyer, Markou, and the London journalist, Hamid, which matched the pair’s description of their encounters with undercover agents.&lt;/p&gt;
&lt;p&gt;The TV segment was critical of the lawyers suing NSO, and quoted NSO founder Shalev Hulio in an interview accusing Markou and her colleagues of pursuing the lawsuits as a “PR exercise.”&lt;/p&gt;
&lt;p&gt;NSO has previously denied hiring Black Cube, and Black Cube in a letter sent last month to the AP said it was not involved in the effort to ensnare researchers at Citizen Lab. “Black Cube had nothing to do with these alleged events,” the letter said, adding that no one acting on the company’s behalf did either.&lt;/p&gt;
&lt;p&gt;Black Cube does have a possible tie to Almog-Assouline, the man who held the hotel meeting about NSO in New York. During a long-running Canadian legal battle between two private equity firms — Catalyst Capital and West Face Capital — one man caught up in the litigation said he recognized Almog-Assouline because he’d been approached by the same operative under a different identity several years ago.&lt;/p&gt;
&lt;p&gt;“I recognized the individual, down to the accent and the anecdotes,” said the man, who spoke on condition of anonymity for fear of retaliation.&lt;/p&gt;
&lt;p&gt;In court filings, Black Cube has acknowledged dispatching agents to meet with “various individuals” involved in in the private equity firms’ feud. But it’s unclear if other investigations firms might also have done work connected to the two companies’ legal battle.&lt;/p&gt;
&lt;p&gt;Black Cube did not respond to repeated questions about whether it had ever employed Almog-Assouline. The firm previously drew international opprobrium for its unrelated work protecting the reputation of disgraced Hollywood mogul Harvey Weinstein.&lt;/p&gt;
&lt;p&gt;Almog-Assouline himself denied working for Black Cube when two AP reporters confronted him in New York last month.&lt;/p&gt;
&lt;p&gt;He has refused to answer any questions since.&lt;/p&gt;
&lt;p&gt;When an AP reporter rang the door at his penthouse in Tel Aviv suburb of Ramat Hasharon a week ago, a woman who identified herself as his wife said he wasn’t home. When the reporter followed up with a phone call to Almog-Assouline, he said: “I have no interest in speaking to you.”&lt;/p&gt;
&lt;p&gt;___&lt;/p&gt;
&lt;p&gt;Aron Heller in Ramat Hasharon, Israel, David Keyton in Stockholm, Sweden, Jamey Keaten in Zurich, Vincent Yu in Hong Kong, Sylvain Plazy in Brussels, Josef Federman in Jerusalem and Meneloas Hadjicostis in Nicosia, Cyprus, contributed to this report.&lt;/p&gt;
&lt;p&gt;___&lt;/p&gt;
&lt;p&gt;Online:&lt;/p&gt;
&lt;p&gt;Documents related to the undercover operation: &lt;a href=&quot;https://www.documentcloud.org/search/projectid:42174-Citizen-Lab-Undercover-Op&quot;&gt;https://www.documentcloud.org/search/projectid:42174-Citizen-Lab-Undercover-Op&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;___&lt;/p&gt;
&lt;p&gt;Raphael Satter can be reached on: &lt;a href=&quot;http://raphaelsatter.com&quot;&gt;http://raphaelsatter.com&lt;/a&gt;&lt;/p&gt;
</description>
<pubDate>Mon, 11 Feb 2019 02:58:33 +0000</pubDate>
<dc:creator>wglb</dc:creator>
<og:title>AP Exclusive: Undercover spy exposed in NYC was 1 of many</og:title>
<og:type>article</og:type>
<og:url>https://apnews.com/a1d1af4256c04cc5a36347667e966a14</og:url>
<og:image>https://storage.googleapis.com/afs-prod/media/media:22a0f4ea7d0c439cb0fa95ef06c203d2/3000.jpeg</og:image>
<og:description>LONDON (AP) — When mysterious operatives lured two cybersecurity researchers to meetings at luxury hotels over the past two months, it was an apparent bid to discredit their research about an Israeli company that makes smartphone hacking technology used by some governments to spy on their citizens. The Associated Press has now learned of similar undercover efforts targeting at least four other individuals who have raised questions about the use of the Israeli firm's spyware.</og:description>
<dc:format>text/html</dc:format>
<dc:identifier>https://apnews.com/a1d1af4256c04cc5a36347667e966a14</dc:identifier>
</item>
<item>
<title>38% of bugs at Airbnb could have been prevented by using types</title>
<link>https://www.reddit.com/r/typescript/comments/aofcik/38_of_bugs_at_airbnb_could_have_been_prevented_by/</link>
<guid isPermaLink="true" >https://www.reddit.com/r/typescript/comments/aofcik/38_of_bugs_at_airbnb_could_have_been_prevented_by/</guid>
<description>&lt;p class=&quot;s90z9tc-10 fHRkcP&quot;&gt;A &lt;em class=&quot;s90z9tc-15 kRPwUl&quot;&gt;good&lt;/em&gt; (i.e. not JavaScript), strong dynamic type system plus good tests does in my experience.&lt;/p&gt;
&lt;p class=&quot;s90z9tc-10 fHRkcP&quot;&gt;I think a lot of people don't realize that typescript's main benefit wasn't imposing a static type system but slightly unfucking JavaScript's type system.&lt;/p&gt;
&lt;p class=&quot;s90z9tc-10 fHRkcP&quot;&gt;It's as simple as 1+'1'=2. Or was it 11? Wait, no, it's ValueError.&lt;/p&gt;
</description>
<pubDate>Mon, 11 Feb 2019 00:55:54 +0000</pubDate>
<dc:creator>mbrodersen</dc:creator>
<og:title>r/typescript - 38% of bugs at Airbnb could have been prevented by TypeScript according to postmortem analysis</og:title>
<og:type>image</og:type>
<og:url>https://www.reddit.com/r/typescript/comments/aofcik/38_of_bugs_at_airbnb_could_have_been_prevented_by/</og:url>
<og:description>254 votes and 175 comments so far on Reddit</og:description>
<og:image>https://preview.redd.it/fi6ry4acqbf21.jpg?auto=webp&amp;s=d29d11c2e37ec8fa13cfacd78f3a953f90b43063</og:image>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.reddit.com/r/typescript/comments/aofcik/38_of_bugs_at_airbnb_could_have_been_prevented_by/</dc:identifier>
</item>
<item>
<title>Google Edge TPU Devices</title>
<link>https://aiyprojects.withgoogle.com/edge-tpu</link>
<guid isPermaLink="true" >https://aiyprojects.withgoogle.com/edge-tpu</guid>
<description>&lt;div readability=&quot;17&quot;&gt;
&lt;p&gt;The Edge TPU is a small ASIC designed by Google that provides high performance ML inferencing for low-power devices. For example, it can execute state-of-the-art mobile vision models such as MobileNet V2 at 100+ fps, in a power efficient manner.&lt;/p&gt;
&lt;p&gt;With one of the following Edge TPU devices, you can build embedded systems with on-device AI features that are fast, secure, and power efficient.&lt;/p&gt;
&lt;/div&gt;&lt;div id=&quot;faq&quot; readability=&quot;39.10531220876&quot;&gt;
&lt;h2&gt;Frequently asked questions&lt;/h2&gt;
&lt;h4&gt;Can the Edge TPU perform accelerated ML training?&lt;/h4&gt;
&lt;p&gt;No, the first-generation Edge TPU is capable of accelerating ML inferencing only.&lt;/p&gt;
&lt;h4&gt;What machine learning frameworks does the Edge TPU support?&lt;/h4&gt;
&lt;p&gt;&lt;a href=&quot;https://www.tensorflow.org/lite/&quot;&gt;TensorFlow Lite&lt;/a&gt; only.&lt;/p&gt;
&lt;h4&gt;How do I create a TensorFlow Lite model for the Edge TPU?&lt;/h4&gt;
&lt;p&gt;You need to create a &lt;a href=&quot;https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/quantize#quantization-aware-training&quot;&gt;quantized&lt;/a&gt; TensorFlow Lite model and then compile the model for compatibility with the Edge TPU. We will provide a cloud-based compiler tool that accepts your .tflite file and returns a version that's compatible with the Edge TPU.&lt;/p&gt;
&lt;p&gt;We will also provide several pre-compiled vision models that perform image classification and object detection.&lt;/p&gt;
&lt;h4&gt;What type of neural network does the Edge TPU support?&lt;/h4&gt;
&lt;p&gt;The first-generation Edge TPU is capable of executing deep feed-forward neural networks (DFF) such as convolutional neural networks (CNN), making it ideal for a variety of vision-based ML applications. The Edge TPU compiler will add support for various model architectures over time, as we verify compatibility and performance. In the first release, the Edge TPU compiler supports the following model architectures:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;MobileNet V1/V2&lt;br/&gt;224x224 max input size; 1.0 max depth multiplier&lt;/li&gt;
&lt;li&gt;MobileNet SSD V1/V2&lt;br/&gt;320x320 max input size; 1.0 max depth multiplier&lt;/li&gt;
&lt;li&gt;Inception V1/V2&lt;br/&gt;224x224 fixed input size&lt;/li&gt;
&lt;li&gt;Inception V3/V4&lt;br/&gt;299x299 fixed input size&lt;/li&gt;
&lt;/ul&gt;&lt;h4&gt;How can I integrate the Edge TPU with my system?&lt;/h4&gt;
&lt;p&gt;The Edge TPU Dev Board is a single-board computer that includes an SOC and Edge TPU integrated on the SOM, so it's a complete system. You can also remove the SOM (or purchase it separately) and then integrate it with other hardware via three board-to-board connectors—even in this scenario, the SOM contains the complete system with SOC and Edge TPU, and all system interfaces (I2C, MIPI-CSI/DSI, SPI, etc.) are accessible via 300 pins on the board-to-board connectors so you can connect your hardware interfaces. Details will be provided in the datasheet.&lt;/p&gt;
&lt;p&gt;With the Edge TPU Accelerator, you can simply connect to any Linux-based system with a USB cable (we recommend USB 3.0 for best performance).&lt;/p&gt;
&lt;h4&gt;How can I learn more?&lt;/h4&gt;
&lt;p&gt;&lt;a href=&quot;https://services.google.com/fb/forms/aiycommunicationpreferences/&quot;&gt;Sign up here for updates&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;</description>
<pubDate>Sun, 10 Feb 2019 23:42:43 +0000</pubDate>
<dc:creator>walterbell</dc:creator>
<og:type>website</og:type>
<og:url>https://aiyprojects.withgoogle.com/</og:url>
<og:image>https://aiyprojects.withgoogle.com/static/images/voice-v1/box-and-shadow.png</og:image>
<og:title>Edge TPU Devices</og:title>
<og:description>The Edge TPU is a small ASIC designed by Google that provides high performance ML inferencing for low-power devices. For example, it can execute state-of-the-art mobile vision models such as MobileNet V2 at 100+ fps, in a power efficient manner. With one of the following Edge TPU devices, you can build embedded systems with on-device AI features that are fast, secure, and power efficient.</og:description>
<dc:language>en_US</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://aiyprojects.withgoogle.com/edge-tpu</dc:identifier>
</item>
<item>
<title>Space Colony Art from the 1970s</title>
<link>https://publicdomainreview.org/collections/space-colony-art-from-the-1970s/</link>
<guid isPermaLink="true" >https://publicdomainreview.org/collections/space-colony-art-from-the-1970s/</guid>
<description>&lt;p&gt;In the 1970s the Princeton physicist Gerard O’Neill, with the help of NASA Ames Research Center and Stanford University, held a series of space colony summer studies which explored the possibilities of humans living in giant orbiting spaceships. Colonies housing about 10,000 people were designed and a number of artistic renderings of the concepts were made.&lt;/p&gt;
&lt;div class=&quot;hpy_post_meta_fields&quot;&gt;


&lt;div class=&quot;hpy_post_download_field hpy_meta_field&quot;&gt;&lt;img src=&quot;https://publicdomainreview.org/wp-content/themes/hpy_pdr/dist/img/download.png&quot; srcset=&quot;https://publicdomainreview.org/wp-content/themes/hpy_pdr/dist/img/download.png 1x, https://publicdomainreview.org/wp-content/themes/hpy_pdr/dist/img/download_2x.png 2x&quot; title=&quot;Download&quot; alt=&quot;Download&quot;/&gt;&lt;p&gt;Download: Right click on image or see source for higher res versions.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;



</description>
<pubDate>Sun, 10 Feb 2019 21:26:25 +0000</pubDate>
<dc:creator>tintinnabula</dc:creator>
<og:type>article</og:type>
<og:title>Space Colony Art from the 1970s</og:title>
<og:description>In the 1970s the Princeton physicist Gerard O’Neill, with the help of NASA Ames Research Center and Stanford University, held a series of space colony summer studies which explored the possibilities of humans living in giant orbiting spaceships. Colonies housing about 10,000 people were designed and a number of artistic renderings of the concepts were made.</og:description>
<og:image>https://publicdomainreview.org/wp-content/uploads/AC75-1086-1f.jpeg</og:image>
<og:url>https://publicdomainreview.org/collections/space-colony-art-from-the-1970s/</og:url>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://publicdomainreview.org/collections/space-colony-art-from-the-1970s/</dc:identifier>
</item>
<item>
<title>Why Swift for TensorFlow?</title>
<link>https://github.com/tensorflow/swift/blob/master/docs/WhySwiftForTensorFlow.md</link>
<guid isPermaLink="true" >https://github.com/tensorflow/swift/blob/master/docs/WhySwiftForTensorFlow.md</guid>
<description>
&lt;p&gt;The core &lt;a href=&quot;https://github.com/tensorflow/swift/blob/master/docs/GraphProgramExtraction.md&quot;&gt;graph program extraction algorithm&lt;/a&gt;, &lt;a href=&quot;https://github.com/tensorflow/swift/blob/master/docs/AutomaticDifferentiation.md&quot;&gt;automatic differentiation&lt;/a&gt;, and &lt;a href=&quot;https://github.com/tensorflow/swift/blob/master/docs/PythonInteroperability.md&quot;&gt;Python language interoperability&lt;/a&gt; features of Swift for TensorFlow can be implemented for other programming languages, and we are occasionally asked why we didn’t use some other one for this project.&lt;/p&gt;
&lt;p&gt;The engineers on the project were previously familiar with Swift (and several other languages), but the choice was guided by the goals of our project, which imposed specific technical requirements (explained below). This choice was also discussed extensively, debated with coworkers and other interested engineers, and we concluded that Swift was the best direction. In this document we're sharing our deliberation process with the community to help explain our decisions.&lt;/p&gt;
&lt;p&gt;That said, while our choice of language was guided by our specific project goals, we would love to see wider application of these techniques and ideas in the context of other programming languages! If you are interested in pursuing a similar project, please reach out to us and we will happily share our expertise.&lt;/p&gt;
&lt;h3&gt;How we got here&lt;/h3&gt;
&lt;p&gt;As discussed in the &lt;a href=&quot;https://github.com/tensorflow/swift/blob/master/docs/DesignOverview.md&quot;&gt;design overview document&lt;/a&gt; our project goal is to improve usability of TensorFlow. We quickly realized that our core &lt;a href=&quot;https://github.com/tensorflow/swift/blob/master/docs/GraphProgramExtraction.md&quot;&gt;static analysis-based Graph Program Extraction algorithm&lt;/a&gt; would not work well for Python given its highly dynamic nature. This led us down the path of having to pick another language to work with, and we wanted to approach this methodically. As such, we defined goals for the project, explored which properties of a programming language are important to achieve those goals, and then evaluated a lot of languages against these properties. You already know the outcome--we eventually settled on Swift.&lt;/p&gt;
&lt;p&gt;Below we explain &lt;a href=&quot;https://github.com/tensorflow/swift/blob/master/docs/WhySwiftForTensorFlow.md#project-goals&quot;&gt;our project goals&lt;/a&gt;, discuss the &lt;a href=&quot;https://github.com/tensorflow/swift/blob/master/docs/WhySwiftForTensorFlow.md#properties-of-programming-languages&quot;&gt;programming language properties&lt;/a&gt; that contribute to these goals, provide a short &lt;a href=&quot;https://github.com/tensorflow/swift/blob/master/docs/WhySwiftForTensorFlow.md#which-languages-fit-our-project-requirements&quot;&gt;evaluation of specific languages&lt;/a&gt; against those goals, and discuss the &lt;a href=&quot;https://github.com/tensorflow/swift/blob/master/docs/WhySwiftForTensorFlow.md#evaluating-swift-against-our-language-properties&quot;&gt;pros and cons of Swift&lt;/a&gt; specifically.&lt;/p&gt;
&lt;h2&gt;Project goals&lt;/h2&gt;
&lt;p&gt;TensorFlow is a world-class machine learning framework used by a wide range of different people for lots of different things. Our project goal is to provide a new interface to TensorFlow that builds on TensorFlow’s power and capabilities, while taking its usability to a whole new level. Our aim is to make machine learning researchers (both theoretical and applied), production engineers deploying at scale, and anyone else using TensorFlow more productive and joyful without sacrificing anything that already makes TensorFlow great.&lt;/p&gt;
&lt;p&gt;We defined goals around the properties that are important to maintain and improve in our system:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Expressiveness:&lt;/strong&gt; We want a define-by-run model that feels like you’re directly programming against a numeric API and the host language (like NumPy), without an explicit graph abstraction in the way. We should not put constraints on native control flow, use of native data structures like dictionaries, or other things that might feel natural.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;High Performance:&lt;/strong&gt; We want to get the most out of our hardware and accelerators, including CPUs, GPUs, Cloud TPUs, and future accelerators being developed across the industry. Performance is important for production deployments to save megawatts, but is just as important for researchers who want fast turnaround time on experiments.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Hardware Abstraction:&lt;/strong&gt; It should be possible to build a model without embedding hardware-specific information in it, and get &quot;good&quot; performance out of the hardware. We should provide the (opt-in) ability to further tune the model for specific accelerators to achieve full peak performance, and make sure that is a low-friction path that doesn’t require a rewrite of a model.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Large, Dynamic, and Self-Modifying Models:&lt;/strong&gt; We don’t know what ML models will look like in 5 years, but it seems clear they will be bigger, sparser, and less rigidly structured. We should solve today’s problems and embrace the next generation that researchers will come up with as compute continues to get cheaper. We should fully support dynamic models like attentional models, large models like &lt;a href=&quot;https://en.wikipedia.org/wiki/Mixture_of_experts&quot; rel=&quot;nofollow&quot;&gt;mixture of experts&lt;/a&gt;, as well as &lt;a href=&quot;https://en.wikipedia.org/wiki/Reinforcement_learning&quot; rel=&quot;nofollow&quot;&gt;reinforcement learning models&lt;/a&gt; that require frequent interactions with real or simulated environments (e.g. an Atari game).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Performance Predictability:&lt;/strong&gt; A key aspect of making a large and flexible system usable is to make it predictable: while it should be possible to express anything, it should be easy to predict what will run efficiently, and the tools should provide feedback about performance cliffs. Simple and predictable tooling is preferable to layers of magic that try to paper over the most common problems.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Fast Iteration Time:&lt;/strong&gt; We need to enable productive researcher workflows, where the tools dissolve out of the way, allowing the user to focus on the data and math.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Debuggability and Introspection:&lt;/strong&gt; An important part of R&amp;amp;D is figuring out what is happening in a model, diagnosing failures, and figuring out what to change. A system that diagnoses more errors earlier (e.g. shape mismatches at compile time) is more usable than one that only catches them at run time.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;High-End User Experience:&lt;/strong&gt; We should meet the users where they are, regardless of whether they like UI, console, or batch processing experiences. We should support terminal users (e.g. with an interpreter/REPL), Jupyter notebooks, users who prefer UNIX &lt;code&gt;#!&lt;/code&gt; scripts, and other common patterns.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Flexible Deployment:&lt;/strong&gt; We need to be able to deploy to inference-only mobile targets through &lt;a href=&quot;https://www.tensorflow.org/mobile/tflite/&quot; rel=&quot;nofollow&quot;&gt;TFLite&lt;/a&gt; in addition to supporting inference on high-end accelerators like GPUs and Cloud TPUs. We need to support production teams that want minimal dependencies, e.g. by being able to produce a single .o file for the CPU.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Fast Deployment:&lt;/strong&gt; The ML space is moving really fast: we should remove obstacles in place between research and production deployment wherever possible. Requiring a significant rewrite of &quot;research code&quot; to put it &quot;into production&quot; would be harmful both because it slows this down, but also because it makes it very difficult to iteratively improve production models. Rewrites can also introduce very subtle and pernicious errors.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Best-of-class &lt;a href=&quot;https://en.wikipedia.org/wiki/Automatic_differentiation&quot; rel=&quot;nofollow&quot;&gt;Automatic Differentiation&lt;/a&gt; (AD):&lt;/strong&gt; AD is a key feature of TensorFlow, but we can improve its user experience and pull in more advanced technologies from the AD communities. We should support higher-order AD, as well as the best-in-class implementations like specialized adjoints, easy calculation of Jacobians, per-example gradients, checkpointing, etc.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Embrace TensorFlow Graph Ecosystem:&lt;/strong&gt; GraphDef (and SavedModel) are the key for interchange, transport, deployment, integration with visualization tools etc.&lt;/p&gt;
&lt;p&gt;As you can see, this isn’t a short list of goals, and this isn’t easy to achieve. That said, we do believe we can do this in a single coherent system, and TensorFlow’s mature technology handles a lot of this for us.&lt;/p&gt;
&lt;p&gt;It is worth noting that as of our launch in April 2018, Swift for TensorFlow is not yet solving some of these goals (e.g. improved deployment and self-modifying models) but we have ideas that we expect will develop into great steps forward and cover each of these over time.&lt;/p&gt;
&lt;h2&gt;Properties of programming languages&lt;/h2&gt;
&lt;p&gt;Programming languages are an aggregation of a bunch of largely orthogonal design decisions (and their consequences) manifested into a single inseparable artifact. Each language offers different tradeoffs along each axis, so choosing one is akin to solving a highly multi-dimensional sparse optimization problem. To increase the challenge, many programming languages can be enhanced, so we need to factor in the likelihood of some deficiency being overcomeable by enhancements to the language and compiler (and the odds that the community would accept such a change).&lt;/p&gt;
&lt;p&gt;This section discusses some of these axes, and relates them back to our list of project goals above. Very few of these properties are &quot;absolutely required&quot;, but a weakness in one of these areas can cause follow-on effects. While we are deferring the specific language tradeoff discussion to the next section, we identify various classes of languages that are problematic for a given goal in some cases.&lt;/p&gt;
&lt;h3&gt;Strengths of Python&lt;/h3&gt;
&lt;p&gt;First, let’s start with the hopefully non-controversial strengths of Python which we must not jeopardize:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Community:&lt;/strong&gt; Having a large community of users is important: community drives books, tutorials, and all the little things that no one thinks about until they are missing (we need both emacs AND vim support... :-). This requirement generally excludes most research languages, and excludes the possibility of building a new language for TensorFlow.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Open-source and cross-platform:&lt;/strong&gt; TensorFlow is open source and has users on every imaginable platform. We want to be able to scale to support all of them.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Aesthetics and design:&lt;/strong&gt; Syntax is a language’s &quot;user interface&quot;, and has a deep effect on usability and how users work with the system. Good design is really hard work, but it matters - it is not just a matter of &quot;bikeshedding&quot;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&quot;Mainstream&quot; syntax:&lt;/strong&gt; TensorFlow is a mainstream system, most of its users are using Python, and we aim to appeal to that broad user base. This means that excessively &quot;non-mainstream&quot; languages will hurt adoption of our techniques. That said, we would be very interested for other communities to explore these techniques.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Shallow learning curve:&lt;/strong&gt; We want new users to spend their time learning TensorFlow, not struggling with a language that has a high learning curve. A steep learning curve also reduces the odds of existing TensorFlow users switching to our new system.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;High productivity:&lt;/strong&gt; People love Python because it has low boilerplate and &lt;a href=&quot;http://bryanpendleton.blogspot.com/2010/02/ceremony-vs-essence.html&quot; rel=&quot;nofollow&quot;&gt;low &quot;ceremony&quot;&lt;/a&gt;. Many people get frustrated when they feel like they’re wasting time placating the compiler or churning out boilerplate.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Debugger:&lt;/strong&gt; One of our goals for TensorFlow is for people to be able to debug their models more effectively, so we need a debugging experience. This generally excludes research languages that don’t have debuggers.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Interactivity:&lt;/strong&gt; Batch compilation has an important place in production, but REPLs, #! scripts, notebook environments, etc are widely used across research teams.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Predictable semantics:&lt;/strong&gt; The type system (whether dynamic or static) should have sensible behavior and compose without surprising behavior.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Memory safety:&lt;/strong&gt; We don’t want TensorFlow users to spend their time chasing dangling pointer bugs and undefined behavior in their models. This requirement generally excludes languages like C, C++ and Fortran. On the other hand, it is worth noting that interoperability with existing C code is really useful for large scale systems.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Python APIs:&lt;/strong&gt; TensorFlow users benefit from and rely on a huge collection of Python APIs outside the TensorFlow product, e.g. for visualization and data science stuff. If we ignore this reality, adoption of our new system (no matter how great it is) will be very slow.&lt;/p&gt;
&lt;h3&gt;Python challenges&lt;/h3&gt;
&lt;p&gt;Python is great at the points above, but it has some challenges as well. Here are some things that would make TensorFlow better if they were improved:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Performance:&lt;/strong&gt; Performance is a perennial problem with Python and causes a significant amount of additional work for TensorFlow core: it is most natural to write things in the Python layer, but many things can’t be done there for performance reasons. This leads users to having to write things as TensorFlow ops in C++, just to work around Python performance. This turns low performance into a significant usability issue for Tensorflow.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Concurrency:&lt;/strong&gt; Presence of the GIL increases complexity throughout the stack in large scale settings: it prevents model authors from achieving reasonable performance for some things (without themselves writing C++/CUDA), and prevents natural expression of concurrent algorithms in a model.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Deployment:&lt;/strong&gt; The Python interpreter and its package ecosystem are non-starters on mobile. It is also considered to be a significant liability for product teams that want hermetic low-dependency builds. Production users often train in Python, but write their inference logic against the TensorFlow C++ API for production - harming our goal to shrink the gap between R&amp;amp;D and production deployment.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Custom Ops:&lt;/strong&gt; Building a custom op currently requires writing C++ and Eigen/CUDA - which is a huge complexity cliff to jump off of, a barrier in some cases, reduces the free interchange of models (since they now depend on something outside their source), and can lock ML models to certain hardware vendors. It would be better if there was a path for high-performance kernels to be written in the same language as the model.&lt;/p&gt;
&lt;p&gt;These well-known problems with Python make the TensorFlow programming model more complicated than it would ideally be. They require advanced TensorFlow users to learn and deal with the C++ and CUDA layers of the stack. They slow down researchers, who are often the ones trying new things and pushing the limits of the current system.&lt;/p&gt;
&lt;h3&gt;Properties needed by Graph Program Extraction&lt;/h3&gt;
&lt;p&gt;The fundamental algorithms we use to &lt;a href=&quot;https://github.com/tensorflow/swift/blob/master/docs/GraphProgramExtraction.md&quot;&gt;automatically identify and extract graphs out a program&lt;/a&gt; are based on static analysis of the code. This means that we need to be able to look at code &quot;statically&quot; - i.e., without running it - and be able to &lt;em&gt;reliably&lt;/em&gt; identify Tensor operations and the data flow and control flow dependencies between them. In order to achieve the performance of graphs, we need to be able to connect together large chunks of tensor code - preferably with the same granularity as if you were to manually use an API like the TensorFlow session API. We also need to allow users to be able to use high-level APIs like layers and estimators (and build their own abstractions!) without breaking our ability to do this analysis.&lt;/p&gt;
&lt;p&gt;In proof systems, it is well known that it is difficult to make a static analysis that is both &lt;a href=&quot;https://en.wikipedia.org/wiki/G%C3%B6del%27s_incompleteness_theorems&quot; rel=&quot;nofollow&quot;&gt;&lt;em&gt;sound&lt;/em&gt; and &lt;em&gt;complete&lt;/em&gt;&lt;/a&gt;, meaning that you get a choice of 1) an unsound model that sometimes produces incorrect results but handles all programs, 2) a sound model that is always correct but handles a limited set of programs. Since we are using static analysis for code generation, we require the analysis to be correct! Let’s explore the conservatively correct but incomplete model.&lt;/p&gt;
&lt;p&gt;We can be provably correct if we limit our analysis to a bounded computational model that we know we can reliably analyze. In our graph transformation, this approach works out well, because we have a conservatively correct fallback to handle any situations that are outside our analysis capabilities: we can copy data from the graph back to the host CPU, and dynamically execute arbitrary logic to determine what to do next, then send data back to the graph computation.&lt;/p&gt;
&lt;p&gt;There are two things we need to make this approach work in practice: First, we need the subset of cases we handle to be large enough to include interesting things - including high level user abstractions. Second, we need the resultant model to be simple enough that normal humans can understand it: Lots of special cases and scenario-dependent behavior undermine the usability of the system.&lt;/p&gt;
&lt;p&gt;There are subtle, but critical aspects to making this work in a usable way, and many well-known programming languages (including Python and other OOP-centric languages) force unacceptable tradeoffs that prevent this from working well in practice. This issue affects any object oriented language whose dispatch model is semantically based on dynamic dispatch and mutable state. To explain the issue we use an intentionally simplified example in pseudo-Swift syntax (Note: this is not idiomatic code!):&lt;/p&gt;
&lt;div class=&quot;highlight highlight-source-swift&quot;&gt;
&lt;pre&gt;
&lt;span class=&quot;pl-k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;pl-en&quot;&gt;Layer&lt;/span&gt; { &lt;span class=&quot;pl-k&quot;&gt;...&lt;/span&gt; }
&lt;span class=&quot;pl-k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;pl-en&quot;&gt;Convolution2DLayer&lt;/span&gt; : &lt;span class=&quot;pl-e&quot;&gt;Layer &lt;/span&gt;{ &lt;span class=&quot;pl-k&quot;&gt;...&lt;/span&gt; }
&lt;span class=&quot;pl-k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;pl-en&quot;&gt;BatchNormalizationLayer&lt;/span&gt; : &lt;span class=&quot;pl-e&quot;&gt;Layer &lt;/span&gt;{ &lt;span class=&quot;pl-k&quot;&gt;...&lt;/span&gt; }

&lt;span class=&quot;pl-k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;pl-en&quot;&gt;ResNetBlock&lt;/span&gt; {
  &lt;span class=&quot;pl-c&quot;&gt;&lt;span class=&quot;pl-c&quot;&gt;//&lt;/span&gt; Layers this block is made out of.&lt;/span&gt;
  &lt;span class=&quot;pl-k&quot;&gt;var&lt;/span&gt; conv1, batchNorm1, conv2, batchNorm2&lt;span class=&quot;pl-k&quot;&gt;:&lt;/span&gt; Layer

  &lt;span class=&quot;pl-k&quot;&gt;init&lt;/span&gt;(&lt;span class=&quot;pl-smi&quot;&gt;&lt;span class=&quot;pl-en&quot;&gt;inFilterCount&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;pl-c1&quot;&gt;Int32&lt;/span&gt;, &lt;span class=&quot;pl-smi&quot;&gt;&lt;span class=&quot;pl-en&quot;&gt;outFilterCount&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;pl-c1&quot;&gt;Int32&lt;/span&gt;,
       &lt;span class=&quot;pl-smi&quot;&gt;&lt;span class=&quot;pl-en&quot;&gt;strides&lt;/span&gt;&lt;/span&gt;: (&lt;span class=&quot;pl-c1&quot;&gt;Int32&lt;/span&gt;, &lt;span class=&quot;pl-c1&quot;&gt;Int32&lt;/span&gt;)) {
    conv1 &lt;span class=&quot;pl-k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;pl-c1&quot;&gt;Convolution2DLayer&lt;/span&gt;(&lt;span class=&quot;pl-c1&quot;&gt;filterShape&lt;/span&gt;: [&lt;span class=&quot;pl-c1&quot;&gt;3&lt;/span&gt;, &lt;span class=&quot;pl-c1&quot;&gt;3&lt;/span&gt;, inFilterCount, outFilterCount],
                               &lt;span class=&quot;pl-c1&quot;&gt;strides&lt;/span&gt;: (&lt;span class=&quot;pl-c1&quot;&gt;1&lt;/span&gt;, strides.0, strides.1, &lt;span class=&quot;pl-c1&quot;&gt;1&lt;/span&gt;))
    batchNorm1 &lt;span class=&quot;pl-k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;pl-c1&quot;&gt;BatchNormalizationLayer&lt;/span&gt;(&lt;span class=&quot;pl-c1&quot;&gt;axis&lt;/span&gt;: &lt;span class=&quot;pl-c1&quot;&gt;0&lt;/span&gt;)
    conv2 &lt;span class=&quot;pl-k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;pl-c1&quot;&gt;Convolution2DLayer&lt;/span&gt;(&lt;span class=&quot;pl-c1&quot;&gt;filterShape&lt;/span&gt;: [&lt;span class=&quot;pl-c1&quot;&gt;3&lt;/span&gt;, &lt;span class=&quot;pl-c1&quot;&gt;3&lt;/span&gt;, outFilterCount, outFilterCount],
                               &lt;span class=&quot;pl-c1&quot;&gt;strides&lt;/span&gt;: (&lt;span class=&quot;pl-c1&quot;&gt;1&lt;/span&gt;, &lt;span class=&quot;pl-c1&quot;&gt;1&lt;/span&gt;, &lt;span class=&quot;pl-c1&quot;&gt;1&lt;/span&gt;, &lt;span class=&quot;pl-c1&quot;&gt;1&lt;/span&gt;))
    batchNorm2 &lt;span class=&quot;pl-k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;pl-c1&quot;&gt;BatchNormalizationLayer&lt;/span&gt;(&lt;span class=&quot;pl-c1&quot;&gt;axis&lt;/span&gt;: &lt;span class=&quot;pl-c1&quot;&gt;0&lt;/span&gt;)
  }
}
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This example uses a hypothetical layer library to set up a block from a residual network. This is intended to be reasonable code that uses the kind of abstractions a Java or Python programmer (for example) would use.&lt;/p&gt;
&lt;p&gt;However, the apparent simplicity of the code above underlies a number of complexities: the properties like &lt;code&gt;conv1&lt;/code&gt; could be reassigned after the block is set up. The method calls to &lt;code&gt;forward()&lt;/code&gt; and &lt;code&gt;backward()&lt;/code&gt; on layers (not shown) are dynamically dispatched, which means that the target of the call depends on dynamic properties of the code. The &quot;pointers&quot; to the layers could even be aliased to other references, making data flow analysis of reads and writes from each of the objects difficult to reason about. These possible behaviors make it difficult for a compiler to statically prove the result of the program - a prerequisite for reliably extracting a graph.&lt;/p&gt;
&lt;p&gt;Coming back to our choices above, we have a few options we could pick:&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;
&lt;p&gt;&lt;strong&gt;A predictable, explainable and limited model:&lt;/strong&gt; There is a (very small) subset of Java that we can analyze statically in a fully reliable way: if all code is in static methods, or in methods of final base classes, then we know that all calls are statically dispatched. If all variables are guaranteed to be assigned a single time, then we can do aggressive pointer tracking. The problem with this option is that we lose the ability to have high level abstractions, at least without having copies back and forth all over the place.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;An unpredictable, difficult to explain, but more general model:&lt;/strong&gt; It is well known that while many OOP languages are dynamically dispatched in theory and techniques like &lt;a href=&quot;https://dl.acm.org/citation.cfm?id=679523&quot; rel=&quot;nofollow&quot;&gt;class hierarchy analysis&lt;/a&gt; and &lt;a href=&quot;http://llvm.org/pubs/2005-05-04-LattnerPHDThesis.html&quot; rel=&quot;nofollow&quot;&gt;interprocedural alias analysis&lt;/a&gt; can discover many of these statically. We could use heuristic techniques like this to expand the case we can handle. Unfortunately, these techniques generally require &quot;whole program analysis&quot;, and subtle changes in one part of your program can cause &quot;spooky action at a distance&quot; because the analysis gets confused. This means that a small change to one part of the program can cause sends and receives to be added to other parts of the model, leading to a difficult or impossible to explain model for users.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;Our project goal is to provide a highly usable experience, which requires predictability and explainability from the programming model. This is particularly important because sends and receives can have a significant impact on performance: the data involved could be gigabytes in size! Because of this, we reject the heuristic-based approach and stick with the predictable, explainable, but limited model.&lt;/p&gt;
&lt;p&gt;All is not lost though: not all programming languages are limited in the same way. For example, if you compare C# and Java, the introduction of structs in C# allows it to reliably handle a slightly broader range of cases than Java does. A far extreme is C++, which has a Turing complete template metaprogramming system that is 100% static. Swift is somewhere in between, offering a lot of expressive power (in particular, due to its approach to protocol oriented programming) which we explain in the &lt;a href=&quot;https://github.com/tensorflow/swift/blob/master/docs/GraphProgramExtraction.md&quot;&gt;Graph Program Extraction&lt;/a&gt; deep dive.&lt;/p&gt;
&lt;h3&gt;Additional properties needed by Graph Program Extraction&lt;/h3&gt;
&lt;p&gt;In addition to reliable static analysis, we benefit from a few other properties of the language:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Restricted pointer aliasing:&lt;/strong&gt; Graph Program Extraction only works if it can reliably build dataflow def-use chains between operations. Languages that allow &lt;a href=&quot;https://en.wikipedia.org/wiki/Pointer_aliasing&quot; rel=&quot;nofollow&quot;&gt;unrestricted aliasing of pointers and references&lt;/a&gt; like C/C++ would force our static analysis to be overly conservative, making copies to the host in their presence.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Knowable tensor ops:&lt;/strong&gt; Since we are extracting the tensor ops out of the host code into a graph, we need to know what they are - either through designated syntax, a static type system, or some other hook.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Suitable compiler IR:&lt;/strong&gt; Graph Program Extraction is a non-trivial compiler transformation which requires a suitable &lt;a href=&quot;https://en.wikipedia.org/wiki/Intermediate_representation&quot; rel=&quot;nofollow&quot;&gt;Intermediate Representation&lt;/a&gt; (IR) to work on. This IR must be high-level enough to support the desugaring transformations we use, and be able to compile to a TensorFlow graph without losing essential information. The techniques required by Graph Program Extraction could theoretically be performed on a good AST, but are much easier to implement on a &lt;a href=&quot;https://en.wikipedia.org/wiki/Static_single_assignment_form&quot; rel=&quot;nofollow&quot;&gt;Control Flow Graph in SSA form&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;Static vs dynamic type systems&lt;/h3&gt;
&lt;p&gt;Finally, there is the topic of static vs dynamic typing. Static typing offers a number of advantages particularly relevant for our use case. Static types:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;can catch bugs at compile time instead of runtime. People get very frustrated when a silly type error brings down a long training run hours into it.&lt;/li&gt;
&lt;li&gt;directly improve tooling experience like code completion/intellisense, jump to definition, etc.&lt;/li&gt;
&lt;li&gt;make it easy to know what operations are Tensor operations.&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;On the other hand, statically typed languages can require a lot of ceremony and boilerplate, which is infuriating and directly harms productivity. There are promising middle grounds though, such as languages that are statically typed but that use type inference to eliminate explicit typing in the common case.&lt;/p&gt;
&lt;h2&gt;Which languages fit our project requirements?&lt;/h2&gt;
&lt;p&gt;This is a long list of goals, and there are a lot of languages to consider. As such, here we choose to address clusters of related languages, rather than building and evaluating the full cross product of these one-by-one. We apologize in advance if we have mischaracterized any language or community below, let us know and we’ll happily correct any mistakes!&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;A new language:&lt;/strong&gt; Creating a language is a ridiculous amount of work. Not only do you need a parser, but you need a debugger, all the tooling, books and educational material, and all the other things required to build and support a big community. Furthermore, even if we were willing to make the investment required to do this, it would take many years to do it right, and machine learning is moving too fast.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Python:&lt;/strong&gt; Given that the majority of the TensorFlow community is using Python already, using it for this work would be ideal. However, the dynamic nature of Python isn’t suitable for the reliable static analysis and Graph Program Extraction approaches we depend on. It is possible that some subset of Python could be compiled (as is done by &lt;a href=&quot;https://research.googleblog.com/2017/11/tangent-source-to-source-debuggable.html&quot; rel=&quot;nofollow&quot;&gt;Tangent&lt;/a&gt;), but it isn’t clear how to support high level abstractions like Python classes with that approach.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Ruby / Javascript / R / Typescript / etc:&lt;/strong&gt; These languages share the same problems for static analysis as Python. We are often asked specifically about TypeScript: while it introduces a really nice type system, it doesn’t improve on the fundamental dynamic dispatch and object aliasing challenges posed by Python.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Java / C# / Scala (and other OOP languages with pervasive dynamic dispatch):&lt;/strong&gt; These languages share most of the static analysis problems as Python: their primary abstraction features (classes and interfaces) are built on highly dynamic constructs, which means that static analysis of Tensor operations depends on &quot;best effort&quot; techniques like &lt;a href=&quot;http://llvm.org/pubs/2005-05-04-LattnerPHDThesis.html&quot; rel=&quot;nofollow&quot;&gt;alias analysis&lt;/a&gt; and &lt;a href=&quot;https://dl.acm.org/citation.cfm?id=679523&quot; rel=&quot;nofollow&quot;&gt;class hierarchy analysis&lt;/a&gt;. Further, because they are pervasively reference-based, it is difficult to reliably disambiguate pointer aliases.&lt;/p&gt;
&lt;p&gt;As with Python, it is possible that our approaches could work for this class of languages, but such a system would either force model developers to use very low-abstraction APIs (e.g. all code must be in a final class) or the system would rely on heuristic-based static analysis techniques that work in some cases but not others.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Go:&lt;/strong&gt; Go is a great language with a growing community, and many Go programmers were former Python programmers. Unfortunately, Go is not a great fit for this approach: it allows unstructured aliasing and abstractions are often implemented in terms of dynamic interface dispatches, calls to &lt;code&gt;reflect()&lt;/code&gt;, and dynamic casting from &lt;code&gt;interface{}&lt;/code&gt; to concrete types. Each of these dynamic features defeats reliable large scale abstract interpretation, so users would be forced to use only the static functions and struct features of Go - and it would be impractical to build high-level layer and estimator abstractions out of these (unless they were built into the language).&lt;/p&gt;
&lt;p&gt;Another significant issue is that the nature of Go would require adding significant language enhancements to the Go language, like a built-in Tensor type, some way to be able to express abstractions that are generic over the Tensor element type, automatic differentiation support, and an implementation of the core extraction algorithms. The Go community emphatically prefers to keep the language small, and using it for this project would require going against those core principles.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Rust:&lt;/strong&gt; We believe that Rust supports all the ingredients necessary to implement the techniques in this paper: it has a strong static side, and its traits system supports zero-cost abstractions which can be provably eliminated by the compiler. It has a great pointer aliasing model, a &lt;a href=&quot;https://blog.rust-lang.org/2016/04/19/MIR.html&quot; rel=&quot;nofollow&quot;&gt;suitable mid-level IR&lt;/a&gt;, a vibrant and engaging community, and a great &lt;a href=&quot;http://rust-lang.github.io/rfcs/&quot; rel=&quot;nofollow&quot;&gt;open language evolution process&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;A concern with using Rust is that a strong goal of this project is to appeal to the entire TensorFlow community, which is currently pervasively Python based. We love Rust, but it has a steep learning curve that may exclude data scientists and other non-expert programmers who frequently use TensorFlow. The ownership model is really great, but mostly irrelevant to the problems faced by today’s machine learning code implemented in Python.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;C++:&lt;/strong&gt; As with Rust, we believe that C++ supports all the ingredients necessary to implement the algorithms required for our work, including a &lt;a href=&quot;https://clang.llvm.org&quot; rel=&quot;nofollow&quot;&gt;mature compiler frontend&lt;/a&gt;, and an active standards committee. However, C++ is rife with undefined behavior, and much of its static composition system relies on C macros and template metaprogramming, which is not particularly usable. Furthermore, because C++ doesn’t generally appeal to Python programmers, we were concerned that choosing it would prevent a significant community from adopting our tools.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Julia:&lt;/strong&gt; Julia is another great language with an open and active community. They are currently investing in &lt;a href=&quot;https://juliacomputing.com/domains/ml-and-ai.html&quot; rel=&quot;nofollow&quot;&gt;machine learning techniques&lt;/a&gt;, and even have &lt;a href=&quot;https://github.com/JuliaPy/pyjulia&quot;&gt;good interoperability with Python APIs&lt;/a&gt;. The Julia community shares many common values as with our project, which they published in a &lt;a href=&quot;https://julialang.org/blog/2017/12/ml&amp;amp;pl&quot; rel=&quot;nofollow&quot;&gt;very like-minded blog post&lt;/a&gt; after our project was well underway. We are not experts in Julia, but since its compilation approach is based on type specialization, it may have enough of a representation and infrastructure to host the Graph Program Extraction techniques we rely on.&lt;/p&gt;
&lt;h3&gt;Final decision&lt;/h3&gt;
&lt;p&gt;In the end, we narrowed the list based on technical merits down to Swift, Rust, C++, and potentially Julia. We next excluded C++ and Rust due to usability concerns, and picked Swift over Julia because Swift has a much larger community, is syntactically closer to Python, and because we were more familiar with its internal implementation details - which allowed us to implement a prototype much faster.&lt;/p&gt;
&lt;h2&gt;Evaluating Swift against our language properties&lt;/h2&gt;
&lt;p&gt;It might be interesting to see how we evaluated Swift against the point-by-point language properties we were aiming for at the top of the document. Here is a brief summary of the these points - starting with the topics Python excels at. We also openly address Swift-specific limitations and challenges at the end.&lt;/p&gt;
&lt;h3&gt;Swift compared to Python’s strengths&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Community:&lt;/strong&gt; Swift is a &lt;a href=&quot;https://redmonk.com/fryan/2018/03/15/redmonk-language-rankings-over-time/&quot; rel=&quot;nofollow&quot;&gt;fast growing&lt;/a&gt; language that is among the &lt;a href=&quot;http://pypl.github.io/PYPL.html&quot; rel=&quot;nofollow&quot;&gt;top 10 programming languages&lt;/a&gt; in &lt;a href=&quot;http://redmonk.com/sogrady/2018/03/07/language-rankings-1-18/&quot; rel=&quot;nofollow&quot;&gt;recent surveys&lt;/a&gt; - it is believed to have well over a million programmers using it. It has a large and vibrant open source community and a well-developed ecosystem of tools. Swift’s stronghold is mobile development, but several communities are pushing on Swift for server and cloud applications.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Open source and cross-platform:&lt;/strong&gt; Yes.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Aesthetics and design:&lt;/strong&gt; This is a subjective topic and hard to measure, but this was a major focus of Swift 3. Swift benefited from a year of the open-source community working to improve the syntax to ensure consistency and elegance. Source-breaking changes to the language are very difficult to make now, but Swift definitely benefited from not locking down too early.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&quot;Mainstream&quot; Syntax:&lt;/strong&gt; Swift is designed to fit in with the &quot;extended C family&quot; of programming languages, and intentionally tries to feel &quot;familiar&quot;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Shallow learning curve:&lt;/strong&gt; A key design goal of Swift is to &lt;a href=&quot;https://en.wikipedia.org/wiki/Progressive_disclosure&quot; rel=&quot;nofollow&quot;&gt;progressively disclose complexity&lt;/a&gt; in the language, which makes it an extremely teachable language. This is one of the things that has enabled teaching Swift code to kids as their first programming language (targeting middle-school, 7th and 8th grade) in the &lt;a href=&quot;https://www.apple.com/swift/playgrounds/&quot; rel=&quot;nofollow&quot;&gt;Swift Playgrounds iPad app&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;High productivity:&lt;/strong&gt; Swift aims to maximize clarity of code, and thus it fights to reduce boilerplate. The top-end goal of Swift is to optimize the time it takes to write and maintain a working app, which includes debugging time and other things that go beyond just pounding out the code.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Debugger:&lt;/strong&gt; Swift has a full debugger with command line and IDE support.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Interactivity:&lt;/strong&gt; Swift supports batch compilation, a powerful REPL (with full debugger integration), and #! scripts. Notebook environments are freely available for Mac (Xcode Playgrounds), iOS (Swift Playgrounds), and a web version is also supported.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Predictable semantics:&lt;/strong&gt; Yes.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Memory safety:&lt;/strong&gt; Swift aims to be as &quot;safe by default&quot; language, both in terms of memory safety but also helping to catch logic bugs early. It also provides explicit &quot;unsafe&quot; APIs to interact with C code and for direct hardware access.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Python APIs:&lt;/strong&gt; When we started the project, the answer was &quot;no&quot;, which is why we prioritized building a new approach for &lt;a href=&quot;https://github.com/tensorflow/swift/blob/master/docs/PythonInteroperability.md&quot;&gt;expressive Swift/Python interoperability&lt;/a&gt;. The answer is now &quot;yes&quot;.&lt;/p&gt;
&lt;h3&gt;Swift compared to Python’s challenges&lt;/h3&gt;
&lt;p&gt;Next, there are the aspects that are problematic today for Python:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Performance:&lt;/strong&gt; Swift has great low-level performance and memory use, and because it is so widely used on mobile, there is a large community of people who are continuing to improve it. When &lt;a href=&quot;https://github.com/apple/swift/blob/master/docs/OwnershipManifesto.md&quot;&gt;explicit memory ownership support&lt;/a&gt; is added, Swift will be a credible replacement for many uses of C++.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Concurrency:&lt;/strong&gt; Swift doesn’t include language support for concurrency yet, but works fine with native APIs like pthreads, and it comes with a nice &lt;a href=&quot;https://www.raywenderlich.com/148513/grand-central-dispatch-tutorial-swift-3-part-1&quot; rel=&quot;nofollow&quot;&gt;work queuing API named Dispatch&lt;/a&gt; (aka &quot;GCD&quot;). A first-class concurrency model is a likely future feature of Swift, which could be &lt;a href=&quot;https://gist.github.com/lattner/31ed37682ef1576b16bca1432ea9f782&quot;&gt;based on async/await and Actors&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Deployment:&lt;/strong&gt; Swift can compile down to simple native machine code like C, and doesn’t depend on a garbage collector or other heavy runtime. It is entirely reasonable to compile a ML model into a .o/.h file with Swift.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Custom Ops:&lt;/strong&gt; Swift builds on top of LLVM and has direct access to all LLVM intrinsics - and LLVM can generate GPU kernels for both Nvidia/PTX and AMD cards. In principle, someone could build an embedded &quot;CUDA/OpenCL for Swift&quot; DSL. We are interested in exploring this over the long term, as it would lead to models being more self contained (thus easier to share) and would allow advanced users to use a single language.&lt;/p&gt;
&lt;h3&gt;Properties needed by Graph Program Extraction&lt;/h3&gt;
&lt;p&gt;Next, here are the aspects we care about in order to build the Graph Program Extraction model we describe here:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Reliable static analysis through high-level abstractions:&lt;/strong&gt; Swift has highly dynamic features (classes, existentials, and escaping closures) but it also has a well developed static side as well, which revolves around structs and enums. Structs and enums can be generic, have methods, and conform to protocols (which provide &quot;interface-like&quot; features, mixins, and other capabilities referred to as &lt;a href=&quot;https://www.raywenderlich.com/148448/introducing-protocol-oriented-programming&quot; rel=&quot;nofollow&quot;&gt;Protocol Oriented Programming&lt;/a&gt;). Swift depends on these static features being eliminable, because its basic types (like &lt;code&gt;Int&lt;/code&gt; and &lt;code&gt;Bool&lt;/code&gt;) are actually implemented in the standard library - not built into the compiler. As a result of these properties, Swift provides a simple and reliable conceptual model for developers: abstract interpretation is guaranteed to succeed and give you great performance, so long as you don’t use classes, existentials or other dynamic features. This is explained in depth in the &lt;a href=&quot;https://github.com/tensorflow/swift/blob/master/docs/GraphProgramExtraction.md&quot;&gt;Graph Program Extraction document&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Knowable tensor ops:&lt;/strong&gt; Swift has a static type system, which gives us a simple heuristic to start from: place anything of type &lt;code&gt;Tensor&lt;/code&gt; on the accelerator. We also chose to give tensor ops a distinct syntactic form (currently spelled &lt;code&gt;#tfop(...)&lt;/code&gt;), which isn’t required, but simplifies things.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Suitable compiler IR:&lt;/strong&gt; Swift is perfectly set up to do the transformations we need, because it has a &lt;a href=&quot;http://llvm.org/devmtg/2015-10/#talk7&quot; rel=&quot;nofollow&quot;&gt;high-level IR named SIL&lt;/a&gt;. This represents the code in SSA with a control flow graph, preserving source level type information (so we know what values are tensors) and provides the key transformations we need like inlining, generics specialization, etc. The presence of SIL makes it significantly cheaper to build the compiler pieces of our prototype. SIL includes IR serialization, &quot;inter-module optimization&quot;, &quot;cross module optimization,&quot; inlining, generics specialization, and all the other basic interprocedural optimization infrastructure we need to do this without reinventing basic compiler infrastructure wheels.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Restricted pointer aliasing:&lt;/strong&gt; Swift has an obscure but important feature called &lt;a href=&quot;https://github.com/apple/swift-evolution/blob/master/proposals/0176-enforce-exclusive-access-to-memory.md&quot;&gt;memory exclusivity&lt;/a&gt; which is built as part of the ongoing work to introduce a &lt;a href=&quot;https://github.com/apple/swift/blob/master/docs/OwnershipManifesto.md&quot;&gt;Rust inspired memory ownership model&lt;/a&gt; into Swift. Swift’s aliasing support means that static analysis based analysis and transformations can rely on very strong memory provenance guarantees even for &lt;code&gt;inout&lt;/code&gt; arguments. This provides similar analysis power to &lt;a href=&quot;https://en.wikipedia.org/wiki/Pointer_aliasing&quot; rel=&quot;nofollow&quot;&gt;Fortran references and &lt;code&gt;restrict&lt;/code&gt; pointers in C&lt;/a&gt;. Swift’s focus on value semantics is also a major help for our analysis of arrays and other value types.&lt;/p&gt;
&lt;h2&gt;Known disadvantages of using Swift&lt;/h2&gt;
&lt;p&gt;As explained above, Swift is a good fit for this project for a number of reasons. That said, it is not perfect by any stretch of the imagination. In an effort to capture the negative side of the discussion, these are the most commonly raised concerns about using Swift for this project:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;It is (relatively) new:&lt;/strong&gt; Swift has been in development since 2010 and had its first public release in 2014. As such, it is still relatively new, and thus the tools and surrounding ecosystem aren’t as mature as those for Python, which is over 25 years old.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Windows support:&lt;/strong&gt; Swift is cross platform, and is relatively mature on UNIX-like systems, including Apple platforms, Linux, BSD, and other UNIX-y things. That said, Windows support is still relatively early-on - but there is at least one &lt;a href=&quot;https://swiftforwindows.github.io/&quot; rel=&quot;nofollow&quot;&gt;active community of people&lt;/a&gt; working on it.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Large dependency:&lt;/strong&gt; Swift depends on LLVM and Clang, which means that it is a nontrivial dependency for TensorFlow. On the other hand, all alternatives (including Python) bring in a nontrivial set of dependencies. Swift is also well aligned with TensorFlow since it already depends on LLVM (through the &lt;a href=&quot;https://www.tensorflow.org/performance/xla/&quot; rel=&quot;nofollow&quot;&gt;XLA&lt;/a&gt; compiler backend).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Small data-science community:&lt;/strong&gt; Swift does not have much in the way of a data science community. It has a small community that we hope to engage with, but it is very small compared to the existing NumPy, SciPy, scikit-learn and other ecosystems available for Python. Given that most of these Python libraries are implemented as C code wrapped by Python, it is possible that the Swift ecosystem will eventually grow to include Swift wrappers for the same libraries. In the immediate term though, we feel that our Python interoperability approach is a very pragmatic and very general solution to the needs of TensorFlow users.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Error messages need improvement:&lt;/strong&gt; One of the disadvantages of type inference is that sometimes the error messages you get (particularly when playing with higher-order generic functional programming constructs) can be misleading. This is typically solved by breaking an expression into subexpressions.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Build times could be improved:&lt;/strong&gt; Developers with large applications (e.g. over 100K lines of code) are not happy with build times. This continues to be a focus of the Swift development community and is expected to improve over time, but this shouldn’t be a problem given the comparatively small size of machine learning models.&lt;/p&gt;
&lt;p&gt;As the project evolves, it is possible that other challenges will arise. If so, let us know and we’ll add them to the list.&lt;/p&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;In retrospect, it isn’t a surprise that Swift is a good fit for the needs of this project. Swift was designed and built by a close-knit team. That team previously built a highly modular and composable compiler infrastructure (&lt;a href=&quot;https://llvm.org&quot; rel=&quot;nofollow&quot;&gt;LLVM&lt;/a&gt;), a compiler and runtime for a highly dynamic Smalltalk-derived language (Objective-C), the compiler for a highly static language with a capable generics system (C++), and a path-sensitive static analysis engine (&lt;a href=&quot;https://clang-analyzer.llvm.org/&quot; rel=&quot;nofollow&quot;&gt;the Clang static analyzer&lt;/a&gt;). Furthermore, the goals for Swift’s design was to build something that was as easy to learn and use as a scripting language, but which had enough power to be used as a system’s programming language.&lt;/p&gt;
&lt;p&gt;You can see how each of these things is used by the Swift for TensorFlow project:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;the usability goals are directly aligned between the two projects&lt;/li&gt;
&lt;li&gt;the highly dynamic features allow natural interoperability with Python APIs&lt;/li&gt;
&lt;li&gt;the powerful static side allows the language to support the static analysis that underlies Graph Program Extraction and automatic differentiation&lt;/li&gt;
&lt;li&gt;the generics system is essential to making automatic differentiation a user-extensible language feature&lt;/li&gt;
&lt;li&gt;the goal to support path-sensitive static analysis contributed to the reasons to build the SIL intermediate representation that hosts this work&lt;/li&gt;
&lt;li&gt;the culture of modularity and composability allows us to define much our &quot;language&quot; features (like the &lt;code&gt;Tensor&lt;/code&gt; type) in the TensorFlow library, without having to make invasive changes to the language and compiler&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;The implementation of the Swift for TensorFlow features and capabilities is still not done, but we feel good about how the project is going in practice. That said, we’d really love to see the algorithms we are exploring get applied by other languages and communities!&lt;/p&gt;
</description>
<pubDate>Sun, 10 Feb 2019 19:58:29 +0000</pubDate>
<dc:creator>nnd</dc:creator>
<og:image>https://avatars2.githubusercontent.com/u/15658638?s=400&amp;v=4</og:image>
<og:type>object</og:type>
<og:title>tensorflow/swift</og:title>
<og:url>https://github.com/tensorflow/swift</og:url>
<og:description>Swift for TensorFlow project home page. Contribute to tensorflow/swift development by creating an account on GitHub.</og:description>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://github.com/tensorflow/swift/blob/master/docs/WhySwiftForTensorFlow.md</dc:identifier>
</item>
<item>
<title>Brave browser can inject headers in HTTP requests</title>
<link>https://github.com/brave/browser-android-tabs/commit/911770a07549ce53f49a9d87a5a19b4da29fb767#diff-35dd256442c3c60f5bec67e5b2a86cda</link>
<guid isPermaLink="true" >https://github.com/brave/browser-android-tabs/commit/911770a07549ce53f49a9d87a5a19b4da29fb767#diff-35dd256442c3c60f5bec67e5b2a86cda</guid>
<description>&lt;a href=&quot;https://github.com/brave/browser-android-tabs/commit/911770a07549ce53f49a9d87a5a19b4da29fb767&quot; class=&quot;d-none js-permalink-shortcut&quot; data-hotkey=&quot;y&quot;&gt;Permalink&lt;/a&gt;&lt;div class=&quot;commit full-commit px-2 pt-2&quot; readability=&quot;5.9050279329609&quot;&gt;&lt;a href=&quot;https://github.com/brave/browser-android-tabs/tree/911770a07549ce53f49a9d87a5a19b4da29fb767&quot; class=&quot;btn btn-outline float-right&quot; title=&quot;Browse the repository at this point in the history&quot; rel=&quot;nofollow&quot;&gt;Browse files&lt;/a&gt;
&lt;p class=&quot;commit-title&quot;&gt;Changes for supporting partner programs&lt;/p&gt;
&lt;div class=&quot;commit-branches&quot;&gt;
&lt;ul class=&quot;branches-list&quot;&gt;&lt;li class=&quot;loading&quot;&gt;Loading branch information&lt;span class=&quot;animated-ellipsis-container&quot;&gt;&lt;span class=&quot;animated-ellipsis&quot;&gt;...&lt;/span&gt;&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/div&gt;

&lt;/div&gt;


&lt;div id=&quot;files&quot; class=&quot;diff-view&quot; readability=&quot;5.9711447492904&quot;&gt;
&lt;div class=&quot;js-diff-progressive-container&quot;&gt;
&lt;div id=&quot;diff-0&quot; class=&quot;file js-file js-details-container Details Details--on open show-inline-notes&quot;&gt;

&lt;div class=&quot;js-file-content Details-content--hidden&quot;&gt;
&lt;div class=&quot;data highlight js-blob-wrapper&quot;&gt;
&lt;table class=&quot;diff-table js-diff-table tab-size&quot; data-tab-size=&quot;8&quot; data-diff-anchor=&quot;diff-8bb20343dc66ba6b1c09996a37c3d5ca&quot; readability=&quot;18&quot;&gt;&lt;tr class=&quot;js-expandable-line&quot; data-position=&quot;0&quot;&gt;&lt;td class=&quot;blob-num blob-num-expandable&quot; colspan=&quot;2&quot;/&gt;
&lt;td class=&quot;blob-code blob-code-inner blob-code-hunk&quot; colspan=&quot;2&quot;&gt;@@ -51,6 +51,7 @@&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td id=&quot;diff-8bb20343dc66ba6b1c09996a37c3d5caL51&quot; data-line-number=&quot;51&quot; class=&quot;blob-num blob-num-context js-linkable-line-number&quot;/&gt;
&lt;td id=&quot;diff-8bb20343dc66ba6b1c09996a37c3d5caR51&quot; data-line-number=&quot;51&quot; class=&quot;blob-num blob-num-context js-linkable-line-number&quot;/&gt;
&lt;td class=&quot;blob-code blob-code-context blob-code-marker-cell&quot; data-code-marker=&quot;&quot;/&gt;
&lt;td class=&quot;blob-code blob-code-context&quot;&gt;&lt;span class=&quot;blob-code-inner&quot;&gt;&lt;span class=&quot;pl-k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;pl-smi&quot;&gt;org.chromium.base.metrics.RecordHistogram&lt;/span&gt;;&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td id=&quot;diff-8bb20343dc66ba6b1c09996a37c3d5caL52&quot; data-line-number=&quot;52&quot; class=&quot;blob-num blob-num-context js-linkable-line-number&quot;/&gt;
&lt;td id=&quot;diff-8bb20343dc66ba6b1c09996a37c3d5caR52&quot; data-line-number=&quot;52&quot; class=&quot;blob-num blob-num-context js-linkable-line-number&quot;/&gt;
&lt;td class=&quot;blob-code blob-code-context blob-code-marker-cell&quot; data-code-marker=&quot;&quot;/&gt;
&lt;td class=&quot;blob-code blob-code-context&quot;&gt;&lt;span class=&quot;blob-code-inner&quot;&gt;&lt;span class=&quot;pl-k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;pl-smi&quot;&gt;org.chromium.base.metrics.RecordUserAction&lt;/span&gt;;&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td id=&quot;diff-8bb20343dc66ba6b1c09996a37c3d5caL53&quot; data-line-number=&quot;53&quot; class=&quot;blob-num blob-num-context js-linkable-line-number&quot;/&gt;
&lt;td id=&quot;diff-8bb20343dc66ba6b1c09996a37c3d5caR53&quot; data-line-number=&quot;53&quot; class=&quot;blob-num blob-num-context js-linkable-line-number&quot;/&gt;
&lt;td class=&quot;blob-code blob-code-context blob-code-marker-cell&quot; data-code-marker=&quot;&quot;/&gt;
&lt;td class=&quot;blob-code blob-code-context&quot;&gt;&lt;span class=&quot;blob-code-inner&quot;&gt;&lt;span class=&quot;pl-k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;pl-smi&quot;&gt;org.chromium.chrome.R&lt;/span&gt;;&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td class=&quot;blob-num blob-num-addition empty-cell&quot;/&gt;
&lt;td id=&quot;diff-8bb20343dc66ba6b1c09996a37c3d5caR54&quot; data-line-number=&quot;54&quot; class=&quot;blob-num blob-num-addition js-linkable-line-number&quot;/&gt;
&lt;td class=&quot;blob-code blob-code-addition blob-code-marker-cell&quot; data-code-marker=&quot;+&quot;/&gt;
&lt;td class=&quot;blob-code blob-code-addition&quot;&gt;&lt;span class=&quot;blob-code-inner&quot;&gt;&lt;span class=&quot;pl-k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;pl-smi&quot;&gt;org.chromium.chrome.browser.init.StatsUpdater&lt;/span&gt;;&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td id=&quot;diff-8bb20343dc66ba6b1c09996a37c3d5caL54&quot; data-line-number=&quot;54&quot; class=&quot;blob-num blob-num-context js-linkable-line-number&quot;/&gt;
&lt;td id=&quot;diff-8bb20343dc66ba6b1c09996a37c3d5caR55&quot; data-line-number=&quot;55&quot; class=&quot;blob-num blob-num-context js-linkable-line-number&quot;/&gt;
&lt;td class=&quot;blob-code blob-code-context blob-code-marker-cell&quot; data-code-marker=&quot;&quot;/&gt;
&lt;td class=&quot;blob-code blob-code-context&quot;&gt;&lt;span class=&quot;blob-code-inner&quot;&gt;&lt;span class=&quot;pl-k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;pl-smi&quot;&gt;org.chromium.chrome.browser.IntentHandler.IntentHandlerDelegate&lt;/span&gt;;&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td id=&quot;diff-8bb20343dc66ba6b1c09996a37c3d5caL55&quot; data-line-number=&quot;55&quot; class=&quot;blob-num blob-num-context js-linkable-line-number&quot;/&gt;
&lt;td id=&quot;diff-8bb20343dc66ba6b1c09996a37c3d5caR56&quot; data-line-number=&quot;56&quot; class=&quot;blob-num blob-num-context js-linkable-line-number&quot;/&gt;
&lt;td class=&quot;blob-code blob-code-context blob-code-marker-cell&quot; data-code-marker=&quot;&quot;/&gt;
&lt;td class=&quot;blob-code blob-code-context&quot;&gt;&lt;span class=&quot;blob-code-inner&quot;&gt;&lt;span class=&quot;pl-k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;pl-smi&quot;&gt;org.chromium.chrome.browser.IntentHandler.TabOpenType&lt;/span&gt;;&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td id=&quot;diff-8bb20343dc66ba6b1c09996a37c3d5caL56&quot; data-line-number=&quot;56&quot; class=&quot;blob-num blob-num-context js-linkable-line-number&quot;/&gt;
&lt;td id=&quot;diff-8bb20343dc66ba6b1c09996a37c3d5caR57&quot; data-line-number=&quot;57&quot; class=&quot;blob-num blob-num-context js-linkable-line-number&quot;/&gt;
&lt;td class=&quot;blob-code blob-code-context blob-code-marker-cell&quot; data-code-marker=&quot;&quot;/&gt;
&lt;td class=&quot;blob-code blob-code-context&quot;&gt;&lt;span class=&quot;blob-code-inner&quot;&gt;&lt;span class=&quot;pl-k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;pl-smi&quot;&gt;org.chromium.chrome.browser.appmenu.AppMenu&lt;/span&gt;;&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;js-expandable-line&quot; data-position=&quot;8&quot; readability=&quot;4&quot;&gt;&lt;td class=&quot;blob-num blob-num-expandable&quot; colspan=&quot;2&quot;&gt; &lt;/td&gt;
&lt;td class=&quot;blob-code blob-code-inner blob-code-hunk&quot; colspan=&quot;2&quot;&gt;@@ -1158,8 +1159,15 @@ private void createInitialTab() {&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td id=&quot;diff-8bb20343dc66ba6b1c09996a37c3d5caL1158&quot; data-line-number=&quot;1158&quot; class=&quot;blob-num blob-num-context js-linkable-line-number&quot;/&gt;
&lt;td id=&quot;diff-8bb20343dc66ba6b1c09996a37c3d5caR1159&quot; data-line-number=&quot;1159&quot; class=&quot;blob-num blob-num-context js-linkable-line-number&quot;/&gt;
&lt;td class=&quot;blob-code blob-code-context blob-code-marker-cell&quot; data-code-marker=&quot;&quot;/&gt;
&lt;td class=&quot;blob-code blob-code-context&quot;&gt;&lt;span class=&quot;blob-code-inner&quot;&gt;&lt;span class=&quot;pl-smi&quot;&gt;RecordHistogram&lt;/span&gt;&lt;span class=&quot;pl-k&quot;&gt;.&lt;/span&gt;recordBooleanHistogram(&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;3&quot;&gt;&lt;td id=&quot;diff-8bb20343dc66ba6b1c09996a37c3d5caL1159&quot; data-line-number=&quot;1159&quot; class=&quot;blob-num blob-num-context js-linkable-line-number&quot;/&gt;
&lt;td id=&quot;diff-8bb20343dc66ba6b1c09996a37c3d5caR1160&quot; data-line-number=&quot;1160&quot; class=&quot;blob-num blob-num-context js-linkable-line-number&quot;/&gt;
&lt;td class=&quot;blob-code blob-code-context blob-code-marker-cell&quot; data-code-marker=&quot;&quot;/&gt;
&lt;td class=&quot;blob-code blob-code-context&quot;&gt;&lt;span class=&quot;blob-code-inner&quot;&gt;&lt;span class=&quot;pl-s&quot;&gt;&lt;span class=&quot;pl-pds&quot;&gt;&quot;&lt;/span&gt;MobileStartup.LoadedHomepageOnColdStart&lt;span class=&quot;pl-pds&quot;&gt;&quot;&lt;/span&gt;&lt;/span&gt;, startupHomepageIsNtp);&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td id=&quot;diff-8bb20343dc66ba6b1c09996a37c3d5caL1160&quot; data-line-number=&quot;1160&quot; class=&quot;blob-num blob-num-context js-linkable-line-number&quot;/&gt;
&lt;td id=&quot;diff-8bb20343dc66ba6b1c09996a37c3d5caR1161&quot; data-line-number=&quot;1161&quot; class=&quot;blob-num blob-num-context js-linkable-line-number&quot;/&gt;
&lt;td class=&quot;blob-code blob-code-context blob-code-marker-cell&quot; data-code-marker=&quot;&quot;/&gt;
&lt;td class=&quot;blob-code blob-code-context&quot;&gt;&lt;span class=&quot;blob-code-inner&quot;&gt;}&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td id=&quot;diff-8bb20343dc66ba6b1c09996a37c3d5caL1161&quot; data-line-number=&quot;1161&quot; class=&quot;blob-num blob-num-deletion js-linkable-line-number&quot;/&gt;
&lt;td class=&quot;blob-num blob-num-deletion empty-cell&quot;/&gt;
&lt;td class=&quot;blob-code blob-code-deletion blob-code-marker-cell&quot; data-code-marker=&quot;-&quot;/&gt;
&lt;td class=&quot;blob-code blob-code-deletion&quot;&gt;&lt;span class=&quot;blob-code-inner&quot;&gt;&lt;br/&gt;&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td class=&quot;blob-num blob-num-addition empty-cell&quot;/&gt;
&lt;td id=&quot;diff-8bb20343dc66ba6b1c09996a37c3d5caR1162&quot; data-line-number=&quot;1162&quot; class=&quot;blob-num blob-num-addition js-linkable-line-number&quot;/&gt;
&lt;td class=&quot;blob-code blob-code-addition blob-code-marker-cell&quot; data-code-marker=&quot;+&quot;/&gt;
&lt;td class=&quot;blob-code blob-code-addition&quot;&gt;&lt;span class=&quot;blob-code-inner&quot;&gt;&lt;span class=&quot;pl-smi&quot;&gt;String&lt;/span&gt; partnerOfferPage &lt;span class=&quot;pl-k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;pl-smi&quot;&gt;StatsUpdater&lt;/span&gt;&lt;span class=&quot;pl-k&quot;&gt;.&lt;/span&gt;GetPartnerOfferPage();&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td class=&quot;blob-num blob-num-addition empty-cell&quot;/&gt;
&lt;td id=&quot;diff-8bb20343dc66ba6b1c09996a37c3d5caR1163&quot; data-line-number=&quot;1163&quot; class=&quot;blob-num blob-num-addition js-linkable-line-number&quot;/&gt;
&lt;td class=&quot;blob-code blob-code-addition blob-code-marker-cell&quot; data-code-marker=&quot;+&quot;/&gt;
&lt;td class=&quot;blob-code blob-code-addition&quot;&gt;&lt;span class=&quot;blob-code-inner&quot;&gt;&lt;span class=&quot;pl-k&quot;&gt;if&lt;/span&gt; (&lt;span class=&quot;pl-c1&quot;&gt;null&lt;/span&gt; &lt;span class=&quot;pl-k&quot;&gt;!=&lt;/span&gt; partnerOfferPage &lt;span class=&quot;pl-k&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&quot;pl-k&quot;&gt;!&lt;/span&gt;partnerOfferPage&lt;span class=&quot;pl-k&quot;&gt;.&lt;/span&gt;isEmpty()) {&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td class=&quot;blob-num blob-num-addition empty-cell&quot;/&gt;
&lt;td id=&quot;diff-8bb20343dc66ba6b1c09996a37c3d5caR1164&quot; data-line-number=&quot;1164&quot; class=&quot;blob-num blob-num-addition js-linkable-line-number&quot;/&gt;
&lt;td class=&quot;blob-code blob-code-addition blob-code-marker-cell&quot; data-code-marker=&quot;+&quot;/&gt;
&lt;td class=&quot;blob-code blob-code-addition&quot;&gt;&lt;span class=&quot;blob-code-inner&quot;&gt;url &lt;span class=&quot;pl-k&quot;&gt;=&lt;/span&gt; partnerOfferPage;&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td class=&quot;blob-num blob-num-addition empty-cell&quot;/&gt;
&lt;td id=&quot;diff-8bb20343dc66ba6b1c09996a37c3d5caR1165&quot; data-line-number=&quot;1165&quot; class=&quot;blob-num blob-num-addition js-linkable-line-number&quot;/&gt;
&lt;td class=&quot;blob-code blob-code-addition blob-code-marker-cell&quot; data-code-marker=&quot;+&quot;/&gt;
&lt;td class=&quot;blob-code blob-code-addition&quot;&gt;&lt;span class=&quot;blob-code-inner&quot;&gt;}&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;3&quot;&gt;&lt;td id=&quot;diff-8bb20343dc66ba6b1c09996a37c3d5caL1162&quot; data-line-number=&quot;1162&quot; class=&quot;blob-num blob-num-context js-linkable-line-number&quot;/&gt;
&lt;td id=&quot;diff-8bb20343dc66ba6b1c09996a37c3d5caR1166&quot; data-line-number=&quot;1166&quot; class=&quot;blob-num blob-num-context js-linkable-line-number&quot;/&gt;
&lt;td class=&quot;blob-code blob-code-context blob-code-marker-cell&quot; data-code-marker=&quot;&quot;/&gt;
&lt;td class=&quot;blob-code blob-code-context&quot;&gt;&lt;span class=&quot;blob-code-inner&quot;&gt;getTabCreator(&lt;span class=&quot;pl-c1&quot;&gt;false&lt;/span&gt;)&lt;span class=&quot;pl-k&quot;&gt;.&lt;/span&gt;launchUrl(url, &lt;span class=&quot;pl-smi&quot;&gt;TabLaunchType&lt;/span&gt;&lt;span class=&quot;pl-c1&quot;&gt;&lt;span class=&quot;pl-k&quot;&gt;.&lt;/span&gt;FROM_CHROME_UI&lt;/span&gt;);&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td class=&quot;blob-num blob-num-addition empty-cell&quot;/&gt;
&lt;td id=&quot;diff-8bb20343dc66ba6b1c09996a37c3d5caR1167&quot; data-line-number=&quot;1167&quot; class=&quot;blob-num blob-num-addition js-linkable-line-number&quot;/&gt;
&lt;td class=&quot;blob-code blob-code-addition blob-code-marker-cell&quot; data-code-marker=&quot;+&quot;/&gt;
&lt;td class=&quot;blob-code blob-code-addition&quot;&gt;&lt;span class=&quot;blob-code-inner&quot;&gt;&lt;span class=&quot;pl-k&quot;&gt;if&lt;/span&gt; (&lt;span class=&quot;pl-c1&quot;&gt;null&lt;/span&gt; &lt;span class=&quot;pl-k&quot;&gt;!=&lt;/span&gt; partnerOfferPage &lt;span class=&quot;pl-k&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&quot;pl-k&quot;&gt;!&lt;/span&gt;partnerOfferPage&lt;span class=&quot;pl-k&quot;&gt;.&lt;/span&gt;isEmpty()) {&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td class=&quot;blob-num blob-num-addition empty-cell&quot;/&gt;
&lt;td id=&quot;diff-8bb20343dc66ba6b1c09996a37c3d5caR1168&quot; data-line-number=&quot;1168&quot; class=&quot;blob-num blob-num-addition js-linkable-line-number&quot;/&gt;
&lt;td class=&quot;blob-code blob-code-addition blob-code-marker-cell&quot; data-code-marker=&quot;+&quot;/&gt;
&lt;td class=&quot;blob-code blob-code-addition&quot;&gt;&lt;span class=&quot;blob-code-inner&quot;&gt;&lt;span class=&quot;pl-c&quot;&gt;&lt;span class=&quot;pl-c&quot;&gt;//&lt;/span&gt; Clean up once it is loaded&lt;/span&gt;&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td class=&quot;blob-num blob-num-addition empty-cell&quot;/&gt;
&lt;td id=&quot;diff-8bb20343dc66ba6b1c09996a37c3d5caR1169&quot; data-line-number=&quot;1169&quot; class=&quot;blob-num blob-num-addition js-linkable-line-number&quot;/&gt;
&lt;td class=&quot;blob-code blob-code-addition blob-code-marker-cell&quot; data-code-marker=&quot;+&quot;/&gt;
&lt;td class=&quot;blob-code blob-code-addition&quot;&gt;&lt;span class=&quot;blob-code-inner&quot;&gt;&lt;span class=&quot;pl-smi&quot;&gt;StatsUpdater&lt;/span&gt;&lt;span class=&quot;pl-k&quot;&gt;.&lt;/span&gt;SetPartnerOfferPage(&lt;span class=&quot;pl-c1&quot;&gt;null&lt;/span&gt;);&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td class=&quot;blob-num blob-num-addition empty-cell&quot;/&gt;
&lt;td id=&quot;diff-8bb20343dc66ba6b1c09996a37c3d5caR1170&quot; data-line-number=&quot;1170&quot; class=&quot;blob-num blob-num-addition js-linkable-line-number&quot;/&gt;
&lt;td class=&quot;blob-code blob-code-addition blob-code-marker-cell&quot; data-code-marker=&quot;+&quot;/&gt;
&lt;td class=&quot;blob-code blob-code-addition&quot;&gt;&lt;span class=&quot;blob-code-inner&quot;&gt;}&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td id=&quot;diff-8bb20343dc66ba6b1c09996a37c3d5caL1163&quot; data-line-number=&quot;1163&quot; class=&quot;blob-num blob-num-context js-linkable-line-number&quot;/&gt;
&lt;td id=&quot;diff-8bb20343dc66ba6b1c09996a37c3d5caR1171&quot; data-line-number=&quot;1171&quot; class=&quot;blob-num blob-num-context js-linkable-line-number&quot;/&gt;
&lt;td class=&quot;blob-code blob-code-context blob-code-marker-cell&quot; data-code-marker=&quot;&quot;/&gt;
&lt;td class=&quot;blob-code blob-code-context&quot;&gt;&lt;span class=&quot;blob-code-inner&quot;&gt;}&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td id=&quot;diff-8bb20343dc66ba6b1c09996a37c3d5caL1164&quot; data-line-number=&quot;1164&quot; class=&quot;blob-num blob-num-context js-linkable-line-number&quot;/&gt;
&lt;td id=&quot;diff-8bb20343dc66ba6b1c09996a37c3d5caR1172&quot; data-line-number=&quot;1172&quot; class=&quot;blob-num blob-num-context js-linkable-line-number&quot;/&gt;
&lt;td class=&quot;blob-code blob-code-context blob-code-marker-cell&quot; data-code-marker=&quot;&quot;/&gt;
&lt;td class=&quot;blob-code blob-code-context&quot;&gt;&lt;span class=&quot;blob-code-inner&quot;&gt;&lt;br/&gt;&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td id=&quot;diff-8bb20343dc66ba6b1c09996a37c3d5caL1165&quot; data-line-number=&quot;1165&quot; class=&quot;blob-num blob-num-context js-linkable-line-number&quot;/&gt;
&lt;td id=&quot;diff-8bb20343dc66ba6b1c09996a37c3d5caR1173&quot; data-line-number=&quot;1173&quot; class=&quot;blob-num blob-num-context js-linkable-line-number&quot;/&gt;
&lt;td class=&quot;blob-code blob-code-context blob-code-marker-cell&quot; data-code-marker=&quot;&quot;/&gt;
&lt;td class=&quot;blob-code blob-code-context&quot;&gt;&lt;span class=&quot;blob-code-inner&quot;&gt;&lt;span class=&quot;pl-k&quot;&gt;@Override&lt;/span&gt;&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;js-expandable-line&quot; data-position=&quot;&quot;&gt;&lt;td class=&quot;blob-num blob-num-expandable&quot; colspan=&quot;2&quot;/&gt;
&lt;td class=&quot;blob-code blob-code-inner blob-code-hunk&quot; colspan=&quot;2&quot;/&gt;
&lt;/tr&gt;&lt;/table&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;js-diff-progressive-container&quot; readability=&quot;8&quot;&gt;&lt;img alt=&quot;&quot; class=&quot;js-diff-progressive-spinner&quot; src=&quot;https://github.githubassets.com/images/spinners/octocat-spinner-128.gif&quot; width=&quot;64&quot; height=&quot;64&quot;/&gt;&lt;p&gt;Oops, something went wrong. &lt;button type=&quot;button&quot; class=&quot;btn-link js-retry-button&quot;&gt;Retry&lt;/button&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;


</description>
<pubDate>Sun, 10 Feb 2019 18:13:54 +0000</pubDate>
<dc:creator>rvnx</dc:creator>
<og:image>https://avatars2.githubusercontent.com/u/30602739?s=200&amp;v=4</og:image>
<og:type>object</og:type>
<og:title>Changes for supporting partner programs · brave/browser-android-tabs@911770a</og:title>
<og:url>https://github.com/brave/browser-android-tabs/commit/911770a07549ce53f49a9d87a5a19b4da29fb767</og:url>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://github.com/brave/browser-android-tabs/commit/911770a07549ce53f49a9d87a5a19b4da29fb767</dc:identifier>
</item>
<item>
<title>On Being a Principal Engineer</title>
<link>https://blog.dbsmasher.com/2019/01/28/on-being-a-principal-engineer.html</link>
<guid isPermaLink="true" >https://blog.dbsmasher.com/2019/01/28/on-being-a-principal-engineer.html</guid>
<description>&lt;p&gt;read&lt;/p&gt;&lt;h3 id=&quot;the-managers-path&quot;&gt;The manager’s path&lt;/h3&gt;
&lt;p&gt;I bought and read &lt;a href=&quot;https://www.amazon.com/dp/1491973897/ref=cm_sw_r_cp_tai_Aq9tCbSNCEHAA&quot;&gt;The Manager’s Path&lt;/a&gt; by the awesome &lt;a href=&quot;https://twitter.com/skamille&quot;&gt;Camille Fournier&lt;/a&gt; when it first came out. At the time, I was a senior Database Engineer aspiring to become a principal engineer in my organization. At SendGrid, principal engineer and principal engineer 2 are manager and director level roles respectively without having human direct reports. We had just overhauled the career ladder to provide a full technical ladder, and I now had the opportunity to grow that did not require going into people management. It is not that I disliked managers or that I think it is easy work. To the contrary, I very much appreciate the complexity of engineering management work but I felt that I wanted to strengthen my technical expertise and solidify my career as an individual contributor before considering going fully into people management.&lt;/p&gt;
&lt;p&gt;Now, 2 years later, I have been a principal engineer for a year. I am now closer to more technical strategy decisions than I used to be and I decided to read the book again. The title of the book and its stated goal might be laying out the path in engineering management up to senior leadership, but reading it made it clear to me that the book is also of great value to individual contributors to help explain what all these titles mean, what each layer of management is supposed to focus on, and how engineering concerns converge ultimately with business concerns and crystallize into a strategy for a technical organization. I also realized that while I am still an individual contributor, the principal engineer role carries enough cross-organization work, and enough people skills, that it is much closer to management than it may seem without engineers reporting directly to me.&lt;/p&gt;
&lt;h3 id=&quot;career-ladders-and-the-myth-of-a-flat-org&quot;&gt;Career ladders and the myth of a flat org&lt;/h3&gt;
&lt;p&gt;It surprises me that many shops still claim to have a ‘flat org’ or claim that they do not believe in titles. I have heard it said about data stores that ‘all databases have schemas…even the ones that say they do not’ and I think the same applies to organizations that are larger than a small handful of individuals. They may claim or even believe that they are not encumbered by the politics of titles and organizational hierarchy but that simply means that the power structure is there and implied and not based on clear milestones or competencies either. When companies’ engineering teams grow past a handful, the engineering leadership has to document explicitly what they consider are the competencies of a senior engineer, not leave that up to interpretation. Implied competencies are easily colored by personal bias, both implicit and explicit. And these biases are a quick way to lose competent engineers.&lt;/p&gt;
&lt;h3 id=&quot;principal-not-senior-senior&quot;&gt;Principal. Not senior senior&lt;/h3&gt;
&lt;p&gt;One of the most common steps in defining titles when a company is hitting its growth stage is adding ‘Senior’ to the moniker of engineer but soon enough, especially if retention is good and people are staying on board a number of years, companies realize they need more than just a 2 level engineering ladder. This is where titles like ‘principal’ or ‘staff’ engineer become part of the defined career ladder. However, principal engineer should not be seen as a natural progression to senior engineering levels. It is an IC position that is on a different playing field as it involves competencies that no longer apply to only technical prowess. For an engineer to get to the Principal Engineer level, there needs to be cross organizational collaborative signals, there needs to be a clear understanding of architecture and design decisions that go far beyond the immediate technical area of expertise.&lt;/p&gt;
&lt;h3 id=&quot;a-force-multiplier&quot;&gt;A force multiplier&lt;/h3&gt;
&lt;p&gt;Once I became a principal engineer, it quickly became clear to me that my job involved a lot more than closing tickets and writing code to achieve things. Yes I am still a maker not a manager and I do not have anyone reporting to me but my new position now requires leadership duties that are best not left implicit or not handled with the same outcomes oriented focus as my past coding assignments. One of the most important competencies of a principal engineer is to become a force multiplier. This is a much more mature definition of ‘10x engineer’ than the Silicon Valley cargo cult likes to use. A PE does not produce 10x the features or fix 10x the tech debt tickets. A truly valuable PE makes their whole team better by advocating for best practices, gently reminding people of why the processes we have exist, and helping the less experienced engineers find ways to ‘level up’. A good PE can speak to technical aspects of the product, connect planned work to business strategy and to what makes the company more successful and maybe most importantly, have the interpersonal skills to influence others around them towards these goals.&lt;/p&gt;
&lt;p&gt;This is why promoting any engineer to PE without clear skills in more than just ‘the code’ would be a disservice to the team and a bad signal for the rest of the organization as to what things management actually values when it comes to the non manager career track. If you want to watch and see how the ‘brilliant jerk’ anecdote came to be, it is those promotions to senior IC titles based solely on code output and not all the value that inter human skills can bring into getting large numbers of humans rowing in the same direction.&lt;/p&gt;
&lt;h3 id=&quot;cheerleader-recruiter&quot;&gt;Cheerleader, recruiter&lt;/h3&gt;
&lt;p&gt;One thing the book especially focuses on explaining is “what does that person do, anyway?”. It lays that out by showing when/at what point a ‘manager’ changes focus from day to day tactical to the long term strategic. And few things are more strategic to a company than its ability to recruit great engineering talent.&lt;/p&gt;
&lt;p&gt;Managers carry a responsibility towards recruiting and representing the company well. That’s an obvious fact. As a principal engineer, recruitment is one of your responsibilities.&lt;/p&gt;
&lt;p&gt;When working at the senior engineer level, the focus is more on “getting tickets/projects done with little to no direction” and “being proactive in fixing tech debt or helping solve problems/bugs”. But once i became a principal, it became clear that by virtue of being one of a few, i now carried a larger impact on morale, organization culture and even on recruiting and representing my engineering organization outside of the company. Behaviours I display, either at the office or at tech events, are now a display of the behaviours my company rewards. My behavior is a signal to anyone who may consider working in my organization of whether we align in values or not.&lt;/p&gt;
&lt;h3 id=&quot;manager&quot;&gt;Manager?&lt;/h3&gt;
&lt;p&gt;A few years ago I was where a lot of senior engineers (&lt;a href=&quot;https://phys.org/news/2017-06-female-managerial-roles-unintended-consequences.html&quot;&gt;maybe more the women than the men&lt;/a&gt;) tend to be:. at a fork in the road. Do I become a people manager or do I stay in a technical IC role and focus on solving technical problems?&lt;/p&gt;
&lt;p&gt;Trick question! Once at a certain level, all problems are solved by people. There is no such thing as ‘purely technical problems’. In fact, this is the level where one wishes more problems were purely code because we can make code do a lot of things. Making people do anything is harder and influencing people to do what we want is harder still. This is what principal engineering is about. The role is far less about solving intricate technology problems (although there is that too) and more about being a good influence, convincing the rest of the technical team why Thing A should be solved with plan Foo and not plan Bar. There is a lot of solving for other people motivations, finding the right message for each audience while still working towards the business goals at the end.&lt;/p&gt;
&lt;h3 id=&quot;whats-next&quot;&gt;What’s next&lt;/h3&gt;
&lt;p&gt;The past year and a half working as a principal engineer have been eye opening into all the work that goes into getting a large group of humans all rowing in the same direction for the business to achieve planned goals. It is no small feat that is further complicated with our ever growing, ever complex systems of scale. I do not know whether my experience as a principal engineer will some day translate into becoming an engineering manager someday. Maybe it will. I do know that if I ever made the move to managing people that my time as a principal engineer has taught me plenty that I may have missed out on when focusing only on senior engineer competencies.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Many thanks to &lt;a href=&quot;https://twitter.com/whereistanya&quot;&gt;Tanya Reilly&lt;/a&gt; and &lt;a href=&quot;https://twitter.com/log1kal&quot;&gt;Sean Kilgore&lt;/a&gt; for both being great examples and for their excellent feedback on this. And to Camille Fournier for writing that book.&lt;/em&gt;&lt;/p&gt;
</description>
<pubDate>Sun, 10 Feb 2019 16:46:40 +0000</pubDate>
<dc:creator>kiyanwang</dc:creator>
<og:title>On Being A Principal Engineer</og:title>
<og:description>The manager’s pathI bought and read The Manager’s Path by the awesome Camille Fournier when it first came out. At the time, I was a senior Database Engineer aspiring to become a principal engineer ...</og:description>
<og:image>https://blog.dbsmasher.com/assets/images/unicorn_av.png</og:image>
<og:url>https://blog.dbsmasher.com/2019/01/28/on-being-a-principal-engineer.html</og:url>
<og:type>blog</og:type>
<dc:format>text/html</dc:format>
<dc:identifier>https://blog.dbsmasher.com/2019/01/28/on-being-a-principal-engineer.html</dc:identifier>
</item>
<item>
<title>Wayland misconceptions debunked</title>
<link>https://drewdevault.com/2019/02/10/Wayland-misconceptions-debunked.html</link>
<guid isPermaLink="true" >https://drewdevault.com/2019/02/10/Wayland-misconceptions-debunked.html</guid>
<description>&lt;p&gt;This article has been on my backburner for a while, but it seems Wayland FUD is making the news again recently, so I’ve bumped up the priority a bit. For those new to my blog, I am the maintainer of &lt;a href=&quot;https://github.com/swaywm/wlroots&quot;&gt;wlroots&lt;/a&gt;, a library which implements much of the functionality required of a Wayland compositor and is arguably the single most influential project in Wayland right now; and &lt;a href=&quot;https://swaywm.org&quot;&gt;sway&lt;/a&gt;, a popular Wayland compositor which is nearing version 1.0. Let’s go over some of the common misconceptions I hear about Wayland and why they’re wrong. Feel free to pick and choose the misconceptions you believe to read and disregard the rest.&lt;/p&gt;&lt;p&gt;The art of hating Wayland has become a cult affair. We don’t need to put ourselves into camps at war. Please try not to read this article through the lens of anger.&lt;/p&gt;
&lt;h3 id=&quot;wayland-isnt-more-secure-look-at-this-keylogger&quot;&gt;Wayland isn’t more secure, look at this keylogger!&lt;/h3&gt;
&lt;p&gt;There is an &lt;a href=&quot;https://github.com/Aishou/wayland-keylogger&quot;&gt;unfortunate GitHub project&lt;/a&gt; called “Wayland keylogger” whose mode of operation is using &lt;code class=&quot;highlighter-rouge&quot;&gt;LD_PRELOAD&lt;/code&gt; to intercept calls to the libwayland shared library and record keypresses from it. The problem with this “critique” is stated in the &lt;code class=&quot;highlighter-rouge&quot;&gt;README.md&lt;/code&gt; file, though most don’t read past the title of the repository. Wayland is only &lt;em&gt;one part&lt;/em&gt; of an otherwise secure system. Using &lt;code class=&quot;highlighter-rouge&quot;&gt;LD_PRELOAD&lt;/code&gt; is effectively equivalent to rewriting client programs to log keys themselves, and any program which is in a position to do this has already won. If I rephrased this as “Wayland can be keylogged, assuming the attacker can sneak some evil code into your .bashrc”, the obviousness of this truth should become immediately apparent.&lt;/p&gt;
&lt;p&gt;Some people have also told me that they can log keys by opening &lt;code class=&quot;highlighter-rouge&quot;&gt;/dev/input/*&lt;/code&gt; files and reading input events. They’re right! Try it yourself: &lt;code class=&quot;highlighter-rouge&quot;&gt;sudo libinput debug-events&lt;/code&gt;. The catch should also be immediately obvious: ask yourself why this needs to be run with &lt;code class=&quot;highlighter-rouge&quot;&gt;sudo&lt;/code&gt;.&lt;/p&gt;
&lt;h3 id=&quot;wayland-doesnt-support-screenshotscapture&quot;&gt;Wayland doesn’t support screenshots/capture!&lt;/h3&gt;
&lt;p&gt;The &lt;a href=&quot;https://github.com/wayland-project/wayland/blob/master/protocol/wayland.xml&quot;&gt;core Wayland protocol&lt;/a&gt; does not define a mechanism for taking screenshots. Here’s another thing it doesn’t define: how to open application windows, like gedit and Firefox. The Wayland protocol is very conservative and general purpose, and is built with use-cases other than desktop systems in mind. To this end it only implements the lowest common denominator, and leaves the rest to protocol extensions. There is a process for defining, implementing, maturing, and standardizing these extensions, though the last part is in need of improvements - which are under discussion.&lt;/p&gt;
&lt;p&gt;There are two protocols for the purpose of screenshots and screen recording, which are developed by wlroots and supported by a strong majority of Wayland compositors: &lt;a href=&quot;https://github.com/swaywm/wlroots/blob/master/protocol/wlr-screencopy-unstable-v1.xml&quot;&gt;screencopy&lt;/a&gt; and &lt;a href=&quot;https://github.com/swaywm/wlroots/blob/master/protocol/wlr-export-dmabuf-unstable-v1.xml&quot;&gt;dmabuf-export&lt;/a&gt;, respectively for copying pixels (best for screenshots) and exporting DMA buffers (best for real-time video capture).&lt;/p&gt;
&lt;p&gt;There are two approaches to this endorsed by different camps in Wayland: these Wayland protocols, and a dbus protocol based on Pipewire. Progress is being made on making these approaches talk to each other via &lt;a href=&quot;https://github.com/emersion/xdg-desktop-portal-wlr&quot;&gt;xdg-desktop-portal&lt;/a&gt;, which will make just about every client and compositor work together.&lt;/p&gt;
&lt;h3 id=&quot;wayland-doesnt-have-a-secondary-clipboard&quot;&gt;Wayland doesn’t have a secondary clipboard!&lt;/h3&gt;
&lt;p&gt;Secondary clipboard support (aka primary selection) was first implemented as &lt;a href=&quot;https://github.com/swaywm/wlroots/blob/master/protocol/gtk-primary-selection.xml&quot;&gt;gtk-primary-selection&lt;/a&gt; and was recently standardized as &lt;a href=&quot;https://github.com/wayland-project/wayland-protocols/blob/master/unstable/primary-selection/primary-selection-unstable-v1.xml&quot;&gt;wp-primary-selection&lt;/a&gt;. It is supported by nearly all Wayland compositors and clients.&lt;/p&gt;
&lt;h3 id=&quot;wayland-doesnt-support-clipboard-managers&quot;&gt;Wayland doesn’t support clipboard managers!&lt;/h3&gt;
&lt;p&gt;See &lt;a href=&quot;https://github.com/bugaevc/wl-clipboard&quot;&gt;wl-clipboard&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&quot;wayland-isnt-suitable-for-embedded-devices&quot;&gt;Wayland isn’t suitable for embedded devices!&lt;/h3&gt;
&lt;p&gt;Some people argue that Wayland isn’t supported on embedded devices or require proprietary blobs to work. This is &lt;em&gt;very&lt;/em&gt; untrue. Firstly, Wayland is a protocol: the &lt;em&gt;implementations&lt;/em&gt; are the ones that need support from drivers, and a Wayland implementation could be written for basically any driver. You could implement Wayland by writing Wayland protocol messages on pieces of paper, passing them to your friend in class, and having them draw your window on their notebook with a pencil.&lt;/p&gt;
&lt;p&gt;That being said, this is also untrue of the implementations. wlroots, which contains the most popular Wayland rendering backend, implements KMS+DRM+GBM, which is supported by all open source graphics drivers, and uses GLESv2, which is the most broadly supported graphics implementation, including on embedded (which is what the “E” stands for) and most older hardware. For ancient hardware, writing an fbdev backend is totally possible and I’d merge it in wlroots if someone put in the time. Writing a more modern KMS+DRM+GBM implementation for that hardware is equally possible.&lt;/p&gt;
&lt;h3 id=&quot;wayland-doesnt-have-network-transparency&quot;&gt;Wayland doesn’t have network transparency!&lt;/h3&gt;
&lt;p&gt;This is actually true! But it’s not as bad as it’s made out to be. Here’s why: X11 forwarding works on Wayland.&lt;/p&gt;
&lt;p&gt;Wait, what? Yep: all mainstream desktop Wayland compositors have support for &lt;strong&gt;Xwayland&lt;/strong&gt;, which is an implementation of the X11 server which translates X11 to Wayland, for backwards compatibility. X11 forwarding works with it! So if you use X11 forwarding on Xorg today, your workflow will work on Wayland unchanged.&lt;/p&gt;
&lt;p&gt;However, Wayland itself is not network transparent. The reason for this is that some protocols rely on file descriptors for transferring information quickly or in bulk. One example is GPU buffers, so that the Wayland compositor can render clients without copying data on the GPU - which improves performance dramatically. However, little about Wayland is inherently network &lt;em&gt;opaque&lt;/em&gt;. Things like sending pixel buffers to the compositor are already abstracted on Wayland and a network-backed implementation could be easily made. The problem is that no one seems to really care: all of the people who want network transparency drank the anti-Wayland kool-aid instead of showing up to put the work in. If you want to implement this, though, we’re here and ready to support you! Drop by the wlroots &lt;a href=&quot;https://webchat.freenode.net/?channels=sway-devel&quot;&gt;IRC channel&lt;/a&gt; and we’re prepared to help you implement this.&lt;/p&gt;
&lt;h3 id=&quot;wayland-doesnt-support-remote-desktop&quot;&gt;Wayland doesn’t support remote desktop!&lt;/h3&gt;
&lt;p&gt;This one is also true, but work is ongoing. Several of the pieces are in place: screen capture and keyboard simulation are there. If an interested developer wants to add pointer device simulation and tie it all together with librdesktop, that would be a great boon to the Wayland ecosystem. &lt;a href=&quot;https://webchat.freenode.net/?channels=sway-devel&quot;&gt;We’re waiting to help!&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&quot;wayland-requires-client-side-decorations&quot;&gt;Wayland requires client side decorations!&lt;/h3&gt;
&lt;p&gt;This was actually true for a long time, but there was deep contention in the Wayland ecosystem over this matter. We fought long and hard over this and we now have a protocol for negotiating client- vs server-side decorations, which is now fairly broadly supported, including among some of its opponents. You’re welcome.&lt;/p&gt;
&lt;h3 id=&quot;wayland-doesnt-support-hotkey-daemons&quot;&gt;Wayland doesn’t support hotkey daemons!&lt;/h3&gt;
&lt;p&gt;This is a feature, not a bug, but you’re free to disagree once you hear the rationale. There are lots of problems with the idea of hotkey daemons as it exists on X. What if there’s a conflict between several clients who want the same hotkey? What if the user wants to pick a different hotkey? On top of this, designing a protocol carefully to avoid keylogging concerns makes it more difficult still.&lt;/p&gt;
&lt;p&gt;To this end, I’ve been encouraging client developers who want hotkeys to instead use some kind of IPC mechanism and a control binary. For example, &lt;code class=&quot;highlighter-rouge&quot;&gt;mako&lt;/code&gt;, a notification daemon, allows you to dismiss notifications by running the &lt;code class=&quot;highlighter-rouge&quot;&gt;makoctl dismiss&lt;/code&gt; command. Users are then encouraged to use the compositor’s own keybinding facilities to execute this command. This is more flexible even outside of keybinding - the user might want to execute this behavior through a script, too.&lt;/p&gt;
&lt;p&gt;Still, if you &lt;em&gt;really&lt;/em&gt; want hotkeys, you should start the discussion for standardizing a protocol. It will be an uphill battle but I believe that a protocol which addresses everyone’s concerns is theoretically possible. &lt;em&gt;You&lt;/em&gt; have to step up, though: no one working on Wayland today seems to care. We are mostly volunteers working for free in our spare time.&lt;/p&gt;
&lt;h3 id=&quot;wayland-doesnt-support-nvidia&quot;&gt;Wayland doesn’t support Nvidia!&lt;/h3&gt;
&lt;p&gt;Actually, Nvidia doesn’t support us. There are three standard APIs which are implemented by all graphics drivers in the Linux kernel: DRM (display resource management), KMS (kernel mode setting), and GBM (generic buffer management). All three are necessary for most Wayland compositors. Only the first two are implemented by the Nvidia proprietary driver. In order to support Nvidia, Wayland compositors need to add code resembling this:&lt;/p&gt;
&lt;div class=&quot;language-c highlighter-rouge&quot; readability=&quot;6.5&quot;&gt;
&lt;div class=&quot;highlight&quot; readability=&quot;8&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;
&lt;code&gt;&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nvidia&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;proprietary&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;driver&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;cm&quot;&gt;/* several thousand lines of code */&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;cm&quot;&gt;/* several thousand lines of code */&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;That’s terrible! On top of that, we cannot debug the proprietary driver, we cannot send fixes upstream, and we cannot read the code to understand its behavior. The mesa code (where much of the important code for many drivers lives) is a frequent object of study among Wayland compositor developers. We cannot do this with the proprietary drivers, and it doesn’t even implement the APIs it needs to. They claim to be working on a replacement for GBM which they hope will satisfy everyone’s concerns, but 52 commits in 3 years with over a year of inactivity isn’t a great sign.&lt;/p&gt;
&lt;p&gt;To boot, Nvidia is a bad actor on Linux. Compare the talks at FOSDEM 2018 from the &lt;a href=&quot;https://archive.fosdem.org/2018/schedule/event/nouveau/&quot;&gt;nouveau developers&lt;/a&gt; (the open source Nvidia driver) and the &lt;a href=&quot;https://archive.fosdem.org/2018/schedule/event/amd_graphics/&quot;&gt;AMDGPU developers&lt;/a&gt; (the &lt;em&gt;only&lt;/em&gt;&lt;sup id=&quot;fnref:1&quot;/&gt; AMD driver - also open source). The Nouveau developers discuss all of the ways that Nvidia makes their lives difficult, up to and including &lt;em&gt;signed firmwares&lt;/em&gt;. AMDGPU instead talks about the process of upstreaming their driver, discuss their new open source Vulkan driver, and how the community can contribute - and this was presented by paid AMD staff. I met Intel employees at XDC who were working on a continuous integration system wherein Intel offers a massive Intel GPU farm to Mesa developers free-of-charge for working on the open source driver. Nvidia is clearly a force for bad on the Linux scene and for open source in general, and the users who reward this by spending oodles of cash on their graphics cards are not exactly in my good graces.&lt;/p&gt;
&lt;p&gt;So in short, people asking for Nvidia proprietary driver support are asking the wrong people to spend hundreds of hours working for free to write and maintain an implementation for &lt;em&gt;one&lt;/em&gt; driver which represents a harmful force on the Linux ecosystem and a headache for developers trying to work with it. With respect, my answer is no.&lt;/p&gt;
&lt;h3 id=&quot;wayland-doesnt-support-gaming&quot;&gt;Wayland doesn’t support gaming!&lt;/h3&gt;
&lt;p&gt;First-person shooters, among other kinds of games, require “locking” the pointer to their window. This requires &lt;a href=&quot;https://github.com/wayland-project/wayland-protocols/blob/master/unstable/pointer-constraints/pointer-constraints-unstable-v1.xml&quot;&gt;a protocol&lt;/a&gt;, which was standardized in 2015. Adoption has been slower, but it landed in wlroots several months ago and support was added to sway a few weeks ago.&lt;/p&gt;
&lt;h3 id=&quot;in-conclusion&quot;&gt;In conclusion&lt;/h3&gt;
&lt;p&gt;At some point, some of these things have been true. Some have never been true. It takes time to replace a 30-year incumbent. To be fair, some of these points are true on GNOME and KDE, but none are inherently problems with the Wayland protocol. wlroots is a dominating force in the Wayland ecosystem and the tide is clearly moving our way.&lt;/p&gt;
&lt;p&gt;Another thing I want to note is that Xorg still works. If you find your needs aren’t met by Wayland, just keep using X! We won’t be offended. I’m not trying to force you to use it. Why you heff to be mad?&lt;/p&gt;

&lt;hr/&gt;&lt;p&gt;Have a comment on one of my posts? Start a discussion in my &lt;a href=&quot;https://lists.sr.ht/~sircmpwn/public-inbox&quot;&gt;public inbox&lt;/a&gt; by sending an email to &lt;a href=&quot;mailto:~sircmpwn/public-inbox@lists.sr.ht?Subject=Re%3A%20Wayland%20misconceptions%20debunked&quot;&gt;~sircmpwn/public-inbox@lists.sr.ht&lt;/a&gt; &lt;small&gt;[&lt;a href=&quot;https://man.sr.ht/lists.sr.ht/etiquette.md&quot;&gt;mailing list etiquette&lt;/a&gt;]&lt;/small&gt;&lt;/p&gt;
</description>
<pubDate>Sun, 10 Feb 2019 16:33:42 +0000</pubDate>
<dc:creator>Sir_Cmpwn</dc:creator>
<og:title>Wayland misconceptions debunked</og:title>
<og:description>This article has been on my backburner for a while, but it seems Wayland FUD is making the news again recently, so I’ve bumped up the priority a bit. For those new to my blog, I am the maintainer of wlroots, a library which implements much of the functionality required of a Wayland compositor and is arguably the single most influential project in Wayland right now; and sway, a popular Wayland compositor which is nearing version 1.0. Let’s go over some of the common misconceptions I hear about Wayland and why they’re wrong. Feel free to pick and choose the misconceptions you believe to read and disregard the rest.</og:description>
<og:type>article</og:type>
<dc:format>text/html</dc:format>
<dc:identifier>https://drewdevault.com/2019/02/10/Wayland-misconceptions-debunked.html</dc:identifier>
</item>
</channel>
</rss>