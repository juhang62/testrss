<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="css/feed.xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/" xmlns:og="http://ogp.me/ns#">
<channel>
<atom:link rel="self" href="http://192.168.1.4/fivefilters/makefulltextfeed.php?url=hnrss.org%2Fnewest%3Fpoints%3D200&amp;max=10&amp;links=preserve&amp;exc=" />
<atom:link rel="alternate" title="Source URL" href="http://hnrss.org/newest?points=200" />
<atom:link rel="related" title="Subscribe to feed" href="http://www.subtome.com/#/subscribe?feeds=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dhnrss.org%252Fnewest%253Fpoints%253D200%26max%3D10%26links%3Dpreserve%26exc%3D&amp;back=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dhnrss.org%252Fnewest%253Fpoints%253D200%26max%3D10%26links%3Dpreserve%26exc%3D" />
<title>Hacker News: Newest</title>
<link>https://news.ycombinator.com/newest</link>
<description>Hacker News RSS</description>
<item>
<title>Use links not keys to represent relationships in APIs</title>
<link>https://cloudblog.withgoogle.com/products/application-development/api-design-why-you-should-use-links-not-keys-to-represent-relationships-in-apis/</link>
<guid isPermaLink="true" >https://cloudblog.withgoogle.com/products/application-development/api-design-why-you-should-use-links-not-keys-to-represent-relationships-in-apis/</guid>
<description>&lt;p&gt;The primary difference is that the relationships are expressed using links, rather than foreign key values. In these examples, the links are expressed using simple JSON name/value pairs (see the section below for a discussion of other approaches to writing links in JSON).&lt;/p&gt;
&lt;p&gt;Note also that the inverse relationship of the pet to its owner has been made explicit by adding the &quot;pets&quot; field to the representation of Joe.&lt;/p&gt;
&lt;p&gt;Changing &quot;id&quot; to &quot;self&quot; isn't really necessary or significant, but it’s a common convention to use &quot;self&quot; to identify the resource whose attributes and relationships are specified by the other name/value pairs in the same JSON object. &quot;self&quot; is the name &lt;a href=&quot;https://www.iana.org/assignments/link-relations/link-relations.xhtml&quot;&gt;registered at IANA&lt;/a&gt; for this purpose.&lt;/p&gt;
&lt;p&gt;Viewed from an implementation point of view, replacing all the database keys with links is a fairly simple change—the server converted the database foreign keys into URLs so the client didn't have to—but it significantly simplifies the API and reduces the coupling of the client and the server. Many URI templates that were essential for the first design are no longer required and can be removed from the API specification and documentation.&lt;/p&gt;
&lt;p&gt;The server is now free to change the format of new URLs at any time without affecting clients (of course, the server must continue to honor all previously-issued URLs). The URL passed out to the client by the server will have to include the primary key of the entity in a database plus some routing information, but because the client just echoes the URL back to the server and the client is never required to parse the URL, clients do not have to know the format of the URL. This reduces coupling between the client and server. Servers can even obfuscate their URLs with base64 or similar encoding if they want to emphasize to clients that they should not make assumptions about URL formats or infer meaning from them.&lt;/p&gt;
&lt;p&gt;In the example above, I used a relative form of the URIs in the links, for example /people/98765. It might have been slightly more convenient for the client (although less convenient for the formatting of this blog post), if I had expressed the URIs in absolute form, e.g., https://pets.org/people/98765. Clients only need to know the standard rules of URIs defined in the IETF specifications to convert between these two URI forms, so which form you choose to use is not as important as you might at first assume. Contrast this with the conversion from foreign key to URL described previously, which requires knowledge that is specific to the pet store API. Relative URLs have some advantages for server implementers, as described below, but absolute URLs are probably more convenient for most clients, which is perhaps why Google Drive and GitHub APIs use absolute URLs.&lt;/p&gt;
&lt;p&gt;In short, using links instead of foreign keys to express relationships in APIs reduces the amount of information a client needs to know to use an API, and reduces the ways in which clients and servers are coupled to each other.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Caveats&lt;br/&gt;&lt;/strong&gt;Here are some things you should think about before using links.&lt;/p&gt;
&lt;p&gt;Many API implementations have reverse proxies in front of them for security, load-balancing, and other reasons. Some proxies like to rewrite URLs. When an API uses foreign keys to represent relationships, the only URL that has to be rewritten by a proxy is the main URL of the request. In HTTP, that URL is split between the address line (the first header line) and the host header.&lt;/p&gt;
&lt;p&gt;In an API that uses links to express relationships, there will be other URLs in the headers and bodies of both the request and the response that would also need to be rewritten. There are a few different ways of dealing with this:&lt;/p&gt;
&lt;ol readability=&quot;11.5&quot;&gt;&lt;li readability=&quot;1&quot;&gt;
&lt;p&gt;Don't rewrite URLs in proxies. I try to avoid URL rewriting, but this may not be possible in your environment.&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;6&quot;&gt;
&lt;p&gt;In the proxy, be careful to find and map all URLs wherever they appear in the header or body of the request and response. I have never done this, because it seems to me to be difficult, error-prone, and inefficient, but others may have done it.&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;13&quot;&gt;
&lt;p&gt;Write all links relatively. In addition to allowing proxies some ability to rewrite URLs, relative URLs may make it easier to use the same code in test and production, because the code does not have to be configured with knowledge of its own host name. Writing links using relative URLs with a single leading slash, as I showed in the example above, has few downsides for the server or the client, but it only allows the proxy to change the host name (more precisely, the parts of the URL called the scheme and authority), not the path. Depending on the design of your URLs, you could allow proxies some ability to rewrite paths if you are willing to write links using relative URLs with no leading slashes, but I have never done this because I think it would be complicated for servers to write those URLs reliably. Relative URLs without leading slashes are also more difficult for clients to use—they need to use a standards-compliant library rather than simple string concatenation to handle those URLs, and they need to be careful to understand and preserve the base URL. Using a standards-compliant library to handle URLs is good practice for clients anyway, but many don't.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;Using links may also cause you to re-examine how you do API versioning. Many APIs like to put version numbers in URLs, like this:&lt;/p&gt;
</description>
<pubDate>Sun, 12 May 2019 02:37:32 +0000</pubDate>
<dc:creator>sarego</dc:creator>
<og:type>website</og:type>
<og:title>API design: Why you should use links, not keys, to represent relationships in APIs | Google Cloud Blog</og:title>
<og:description>When designing APIs, using web links rather than exposing database keys has several advantages.</og:description>
<og:image>https://cloud.google.com/blog/static/assets/GCP_Twitter_Card-2000×1000.png</og:image>
<og:url>https://cloud.google.com/blog/products/application-development/api-design-why-you-should-use-links-not-keys-to-represent-relationships-in-apis/</og:url>
<dc:format>text/html</dc:format>
<dc:identifier>https://cloud.google.com/blog/products/application-development/api-design-why-you-should-use-links-not-keys-to-represent-relationships-in-apis</dc:identifier>
</item>
<item>
<title>Why Recycling Doesn&amp;#039;t Work</title>
<link>https://thewalrus.ca/why-recycling-doesnt-work/</link>
<guid isPermaLink="true" >https://thewalrus.ca/why-recycling-doesnt-work/</guid>
<description>&lt;span&gt;Illustration by Ricky Leung&lt;/span&gt;&lt;p&gt;&lt;span class=&quot;dropcap&quot;&gt;M&lt;/span&gt;&lt;span class=&quot;smallcaps&quot;&gt;ost Canadians&lt;/span&gt; know the ritual: check the pickup schedule, sort the waste items, clean the jars, make sure the junk mail isn’t stained with coffee grounds. Then fill up the blue box (or blue bag, or blue cart, depending on the city), and on the appointed day, haul it to the curb. It’s an activity that Canadians have participated in eagerly for almost thirty years. Of the three Rs drilled into our heads in school—reduce, reuse, recycle—recycling is the only one that most of us regularly practise. In 2011, according to a survey by Stewardship Ontario, three-quarters of Ontarians considered the weekly act of sorting and disposing as their “primary environmental effort.”&lt;/p&gt;
&lt;p&gt;But as much as Canadians love the blue box, “its role in [our] hearts and minds…is much larger than its actual environmental impact,” wrote Dianne Saxe, Ontario’s environmental commissioner, in a report last October. In fact, recycling is one of the least environmentally friendly “environmental” things one can do.&lt;/p&gt;
&lt;p&gt;After being picked up, enormous volumes of recyclable waste are unloaded at a local materials-recovery facility (&lt;span class=&quot;smallcaps&quot;&gt;MRF&lt;/span&gt;, pronounced like “smurf”), dumped onto conveyor belts, and passed through a battery of sieves, magnets, optical sorters, and manual workers who separate each item into its own stream—plastic, paper, metal, and so on. The batches from each stream are then sent to gigantic balers, squeezed into cubes, and sold, often by middleman companies, to “end markets.” These are the manufacturers, in Canada and around the world, that profit from turning our waste into something new—toilet paper, perhaps, or plastic lawn furniture, egg cartons, or drywall. More than a public service, recycling is largely a commodity business, as dependent on supply and demand as any other. When municipalities produce more recyclable garbage than end markets can absorb, the value of the product decreases, and in the selling market, Canada faces competition from countries across the world.&lt;/p&gt;
&lt;p&gt;The limitations of a market-driven system mean that, once industrial- and commercial-waste streams are factored in, about two-thirds of Canadian waste still ends up in landfills.&lt;/p&gt;
&lt;span class=&quot;bctt-click-to-tweet&quot;&gt;&lt;span class=&quot;bctt-ctt-text&quot;&gt;&lt;a href=&quot;https://twitter.com/intent/tweet?url=https://thewalrus.ca/why-recycling-doesnt-work/&amp;amp;text=Recycling%20persists%20not%20because%20it%E2%80%99s%20efficient%20%28it%20isn%E2%80%99t%29%20or%20effective%20%28it%E2%80%99s%20much%20less%20so%20than%20we%20think%29%20but%20because%20we%20feel%20obligated%20to%20do%20it.&amp;amp;related&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;Recycling persists not because it’s efficient (it isn’t) or effective (it’s much less so than we think) but because we feel obligated to do it.&lt;/a&gt;&lt;/span&gt; &lt;a href=&quot;https://twitter.com/intent/tweet?url=https://thewalrus.ca/why-recycling-doesnt-work/&amp;amp;text=Recycling%20persists%20not%20because%20it%E2%80%99s%20efficient%20%28it%20isn%E2%80%99t%29%20or%20effective%20%28it%E2%80%99s%20much%20less%20so%20than%20we%20think%29%20but%20because%20we%20feel%20obligated%20to%20do%20it.&amp;amp;related&quot; target=&quot;_blank&quot; class=&quot;bctt-ctt-btn&quot; rel=&quot;noopener noreferrer&quot;&gt;Click To Tweet&lt;/a&gt;&lt;/span&gt;
&lt;p&gt;It helps us feel better about the waste we produce: according to one estimate, 850 kilograms of garbage, per capita, every year.&lt;/p&gt;
&lt;section class=&quot; in-content1 dynamic-widget widget doubleclick_widget-3 widget_doubleclick_widget&quot;&gt;
&lt;/section&gt;&lt;p&gt;&lt;span class=&quot;dropcap&quot;&gt;W&lt;/span&gt;&lt;span class=&quot;smallcaps&quot;&gt;hen they&lt;/span&gt; were first introduced, blue boxes on Canadian driveways and sidewalks seemed almost revolutionary. People were “extremely enthusiastic,” says Dan Hoornweg, a professor at the University of Ontario Institute of Technology. They “really wanted to recycle.” But the box came with conditions—an unfortunate compromise between environmentalists, government, and the soft-drink industry that created the perfect conditions for an explosion in litter.&lt;/p&gt;
&lt;p&gt;In mid-1980s Ontario, after years of arguments with the province, the soft-drink industry agreed to partially subsidize the blue box, which had been invented a few years earlier by a garbage collector in Kitchener, in exchange for being allowed to switch from refillable glass bottles to cheaper, disposable options. The deal helped create one of the world’s most popular residential-recycling programs, which soon began spreading nationwide. But it also gave industry a social licence to create one-time-use packaging—aluminum cans, yogurt containers, those plastic-wrapped cheese-and-cracker kits parents put in kids’ lunch boxes. In a sense, recycling became the preferred method for excusing wastefulness.&lt;/p&gt;
&lt;p&gt;To make matters worse, almost two-thirds of Canada’s waste is produced by the industrial, commercial, institutional, and construction-and-demolition sectors—in everything from factories to office buildings—which are serviced by private waste haulers. Unless they can make a profit selling recyclables, which depends on market prices at the time of sale, there’s little incentive for these haulers to recycle. All of this means that you can put your takeout containers and shredded paper into the office recycling bin, but the company that takes it away is under no legal obligation to recycle it. In Toronto, for example, 72 percent of waste material from apartment and condo buildings goes straight to a landfill.&lt;/p&gt;
&lt;p&gt;Ontario is the only province from which detailed financials are available. In 2016, blue-box collection cost municipalities a total of $347 million, and only about $95 million was recovered from subsequent sales. The rest of the bill was split between the municipality and industry. The idea, early on, was that sales of recyclables on the open market would pay in full for recycling programs. That, of course, never happened. Our blue boxes contain a lot of “lightweight, complicated materials that cost a fortune to recycle,” Saxe says. Whenever a confused resident places an unrecyclable item (say, a plastic-lined takeout coffee cup) into their box, it only aggravates the situation. “You basically end up paying to process [the item] twice,” says Jim McKay, who oversees Toronto’s solid-waste management services: once as recycling, at the &lt;span class=&quot;smallcaps&quot;&gt;MRF&lt;/span&gt;, and once as garbage. In the end, according to Saxe’s report, the blue box diverts only 8 percent of Ontario’s material from landfills. Other provinces, with fewer homes served by curbside pickup, probably recycle even less.&lt;/p&gt;
&lt;p&gt;Residential recycling itself also comes with a significant environmental footprint of its own, especially tied to transportation and carbon emissions. In some circumstances, recycling could actually end up as an environmental liability. “In rural areas you have trucks going half a kilometre between houses picking up recyclables,” Hoornweg says. “It makes no sense.” Once you tally up the emissions associated with picking up products, sorting them at a &lt;span class=&quot;smallcaps&quot;&gt;MRF&lt;/span&gt;, and sending a batch to far-flung end markets, it’s not difficult to imagine that it’s sometimes better to send recycling to the dump.&lt;/p&gt;
&lt;section class=&quot; in-content2 dynamic-widget widget doubleclick_widget-4 widget_doubleclick_widget&quot;&gt;
&lt;/section&gt;&lt;p&gt;&lt;span class=&quot;dropcap&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;smallcaps&quot;&gt;his january&lt;/span&gt;, China declared war against &lt;em&gt;yang laji&lt;/em&gt; (“foreign garbage”). After decades of purchasing recycling that was cluttered with undesirable objects, such as greasy pizza boxes, the country set strict cleanliness standards for the material it purchases. The announcement sent the global industry into a frenzy: for decades, China had been the end market for more than half of the world’s plastic and paper, which are used as raw materials in Chinese building and manufacturing. Many of the Canadian outfitters that relied on China were left stranded because they couldn’t guarantee the quality of their product.&lt;/p&gt;
&lt;p&gt;The effects were immediate: exports of plastics and scraps to China fell from 6,700 tonnes in January 2017 to 578 one year later. Paper-scrap exports fell from 53,000 to 15,800 tonnes. Some of that leftover material is finding its way to other foreign markets, mostly in southeast Asia and India. Some of it is ending up in landfills. Halifax has resorted to burning its plastics in waste-to-energy facilities. And, as of this May, Calgary was still storing more than 7,500 tonnes of paper. At that time, the city also hadn’t been able to find buyers for 1,000 tonnes of clamshell plastics—the little containers berries come in. “They’re laminated and covered in adhesive labels,” says Sharon Howland, Calgary’s leader of program management for waste and recycling. “Nobody wants them.”&lt;/p&gt;
&lt;p&gt;China’s ban forced many of us to confront the realities of a broken system. Canada is good at touting its green conscience; sacrificing comfort, convenience, and habit is a different matter. Yes, Justin Trudeau signed the Paris climate agreement in 2016, promising to reduce greenhouse-gas emissions by 30 percent from 2005 levels by 2030. But still, road pollution in the country is rising. Whenever gas prices drop, oil-sands projects slow down—which could be seen as environmental progress. But we also then buy bigger, less-fuel-efficient cars. And Canada is lagging behind most other industrialized countries when it comes to electric-vehicle purchases.&lt;/p&gt;
&lt;p&gt;The same problem can be seen with the blue box: we cling to our good intentions, but we seldom carry them out. We have always produced far more garbage than we could offload to end markets. Increasingly, our &lt;span class=&quot;smallcaps&quot;&gt;MRF&lt;/span&gt;s—and our streets, streams, and oceans—are overflowing with waste.&lt;/p&gt;
&lt;p&gt;Saxe’s &lt;em&gt;Beyond the Blue Box&lt;/em&gt; report was presented to Ontario’s legislature last fall, as the province was considering a sea change in its approach to garbage: a “circular economy” in which industry would be responsible for products’ post-consumer life and manufacturing would become a closed loop in which as much as possible is reused, in perpetuity, to create new products. But while Ontario passed the Waste Free Ontario Act in 2016, it provides only a guiding framework for this hypothetical future, with very few details and no concrete plan of action. “It’s certainly a great ambition to imagine this path forward,” Saxe says. “But it will clearly be very, very difficult.” The act’s success is entirely dependent on regulations yet to come, making it, at this point, little more than good intentions. Today, with a premier intent on rolling back the previous government’s environmental initiatives (also including the province’s cap-and-trade carbon-pricing measures) a waste-free future looks doubtful.&lt;/p&gt;
&lt;p&gt;Recycling alone will likely never be enough to make up for the garbage we produce. The fight, thirty years ago, to keep Canadians’ fizzy drinks in refillable glass bottles was a good thing to do all along. Making coffee the old-fashioned way is better than cycling through millions of single-use coffee pods. And yet most people who’ve spent their careers in waste management continue to encourage recycling—it’s better than nothing. And Canadians love it because it’s something each and every one of us can control: sort, clean, and carry to the curb.&lt;/p&gt;
</description>
<pubDate>Sun, 12 May 2019 00:42:49 +0000</pubDate>
<dc:creator>pseudolus</dc:creator>
<og:title>Why Recycling Doesn't Work | The Walrus</og:title>
<og:type>article</og:type>
<og:url>https://thewalrus.ca/why-recycling-doesnt-work/</og:url>
<og:image>https://s3.amazonaws.com/walrus-assets/img/FOB_Halliday_SEP18_Art-SMALL-740x493.gif</og:image>
<og:description>You may use the blue bin, but it doesn't mean you're helping the environment</og:description>
<dc:language>en-CA</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://thewalrus.ca/why-recycling-doesnt-work/</dc:identifier>
</item>
<item>
<title>What I gained, lost and learned while working for Microsoft</title>
<link>https://medium.com/@alicjaes/saying-goodbye-to-microsoft-bb5db8662656</link>
<guid isPermaLink="true" >https://medium.com/@alicjaes/saying-goodbye-to-microsoft-bb5db8662656</guid>
<description>&lt;div class=&quot;uiScale uiScale-ui--regular uiScale-caption--regular u-flexCenter u-marginVertical24 u-fontSize15 js-postMetaLockup&quot;&gt;
&lt;div class=&quot;u-flex0&quot;&gt;&lt;a class=&quot;link u-baseColor--link avatar&quot; href=&quot;https://medium.com/@alicjaes?source=post_header_lockup&quot; data-action=&quot;show-user-card&quot; data-action-source=&quot;post_header_lockup&quot; data-action-value=&quot;900bed37c214&quot; data-action-type=&quot;hover&quot; data-user-id=&quot;900bed37c214&quot; dir=&quot;auto&quot;&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/fit/c/100/100/1*98XepvFAD2aaVAoSF-dchQ.jpeg&quot; class=&quot;avatar-image u-size50x50&quot; alt=&quot;Go to the profile of Ala Is Early&quot;/&gt;&lt;/a&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;h3 name=&quot;13b5&quot; id=&quot;13b5&quot; class=&quot;graf graf--h3 graf-after--h3&quot;&gt;&lt;strong class=&quot;markup--strong markup--h3-strong&quot;&gt;What I gained, lost &amp;amp; learned while working for Microsoft.&lt;/strong&gt;&lt;/h3&gt;
&lt;p name=&quot;cba9&quot; id=&quot;cba9&quot; class=&quot;graf graf--p graf-after--h3&quot;&gt;Many people ask — &lt;em class=&quot;markup--em markup--p-em&quot;&gt;how does a person get into Microsoft? How is the interview? What is it like?&lt;/em&gt; For me it was everything for 3,5 years. Now, 18 months later, I feel ready to share my story and say a real goodbye.&lt;/p&gt;
&lt;p name=&quot;34b0&quot; id=&quot;34b0&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;I was interning at a marketing agency at the time after prior experience in a startup and was browsing job offers. Still in college at 23 and full of ideas and hopes for the future, I applied, just like that, for a MACH program — Microsoft Academy for College Hires. Recruitment process was long, had several stages and ended with an assessment center. &lt;em class=&quot;markup--em markup--p-em&quot;&gt;Fun fact: I was asked a ‘tricky’ question about why are the sewer covers round.&lt;/em&gt; And another, not that fun, but more important fact &lt;strong class=&quot;markup--strong markup--p-strong&quot;&gt;I got a position in the Developer Experience and Evangelism&lt;/strong&gt; &lt;strong class=&quot;markup--strong markup--p-strong&quot;&gt;Department&lt;/strong&gt; (now CSE? or something else, it evolves all the time…) as an Audience Marketing Manager located in Warsaw, Poland. My role was to get people, especially in small IT companies, to try out Microsoft Azure (responsible for the breadth market). It was 5 years ago, cloud services were a novelty and the press wasn’t that great. I got serious e-mails from entrepreneurs where Microsoft was spelled ‘&lt;em class=&quot;markup--em markup--p-em&quot;&gt;M$&lt;/em&gt;’.&lt;/p&gt;
&lt;p name=&quot;475c&quot; id=&quot;475c&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;One of the first things I noticed is that &lt;strong class=&quot;markup--strong markup--p-strong&quot;&gt;almost everyone working for Microsoft had this &lt;em class=&quot;markup--em markup--p-em&quot;&gt;perfect life&lt;/em&gt; — a spouse, kids, nice houses, good cars&lt;/strong&gt;. I wanted that too. Imagining that if I were to stay at this company, my life would become like theirs. (It was one of the illusions I had fallen for immediately, but I’ll get to the shattering reality later…) At that time, I was in a decent relationship myself and decided to take the most out of this chance focusing on my personal growth as well as the professional opportunities Microsoft provided.&lt;/p&gt;
&lt;p name=&quot;1560&quot; id=&quot;1560&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;And it has provided a ton. &lt;strong class=&quot;markup--strong markup--p-strong&quot;&gt;I got my first responsibilities and targets on the day 1&lt;/strong&gt;, but I also received a lot of support and training. As a newly hired employee I was participating in MGX (now it’s Inspire?) in Atlanta, had trainings in Amsterdam, Madrid. There were so many interesting people there who I met and self-assured and mean ones as well. It’s a whole spectrum. I was on calls with people from all around the world on a daily basis and I got paid well. &lt;em class=&quot;markup--em markup--p-em&quot;&gt;A dream job&lt;/em&gt;. My team at the time was consisting of i.a. 4 guys, more less my age, with whom I got along very well, so I started spending crazy hours at the office. &lt;strong class=&quot;markup--strong markup--p-strong&quot;&gt;As a person working for DX, I was encouraged to go to conferences, workshops, hackathons, meetups whenever I wanted to and so I did&lt;/strong&gt;. There was a time where I was barely at home. I was excited. I was meeting new, inspiring people and learning so much every day! Meanwhile the First Class travels, taxis, nice hotels and fancy restaurants were spoiling me. This and everyone’s admiration, that I made it.&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;1*lE6eCwF-IbzYEin22OD-jQ.jpeg&quot; data-width=&quot;2048&quot; data-height=&quot;1365&quot; data-is-featured=&quot;true&quot; data-action=&quot;zoom&quot; data-action-value=&quot;1*lE6eCwF-IbzYEin22OD-jQ.jpeg&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/1*lE6eCwF-IbzYEin22OD-jQ.jpeg&quot;/&gt;&lt;/div&gt;
The conference I co-organized, with Satya Nadella as a keynote speaker
&lt;p name=&quot;d287&quot; id=&quot;d287&quot; class=&quot;graf graf--p graf-after--figure&quot;&gt;On the other hand, it wasn’t all so glamorous. Many of the employees didn’t respect me, to them I was a “starlet”, this “stupid, young girl with a diastema” (yep, someone at the office called me that), some were mad that they hired a 23 year old girl instead of a “professional man”. But I was ok with that, I knew I had to prove myself first. What I wasn’t ok with, were the comments about my looks. A few guys working both for Microsoft and Partners were treating me like a cute puppy or telling me they wanted to have sex with me while drunk, but all of it seemed minor and acceptable — I was gettng so much in return.&lt;/p&gt;
&lt;p name=&quot;c433&quot; id=&quot;c433&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;Back home, my partner didn’t share my enthusiasm. He was under the belief we were to start building a home together, but I was barely there. &lt;strong class=&quot;markup--strong markup--p-strong&quot;&gt;Twenty something and living my life to maximum, or what I believed was a maximum at that time — working non stop and drinking way too much&lt;/strong&gt;. I remember writing e-mails at 2 a.m. in a club! Even now it doesn’t seem that crazy to me. My lack of self care wasn’t only the alcohol — I gained 10kg (22lb) during the first year. It’s a common thing to gain weight once you’re hired. We laughed about it, it was a standard. Everyone went through it.&lt;/p&gt;
&lt;p name=&quot;8a22&quot; id=&quot;8a22&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;Time was passing. People were either changing teams or getting fired. It was painful, I actually cried this one time while saying goodbye to one of my team members who was fired without any real explanation. He wasn’t a Full Time Employee, so he got no compensation (&lt;em class=&quot;markup--em markup--p-em&quot;&gt;for those who don’t know — you can be hired in MS either as an FTE, employed by Microsoft — with all the benefits, trips, trainings etc. or as a vendor — through a hiring agency and no privileges that FTEs have&lt;/em&gt;), but no one else seemed to care. I invested so much in this work by this point. I fought fights no one else wanted to pick up. I tried changing things, but I was constantly paying the price — with my health and with my relationships.&lt;/p&gt;
&lt;p name=&quot;26b9&quot; id=&quot;26b9&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;I went to Burning Man and moved out of the apartment I shared with my boyfriend. Got into an affair at the office, which turned out to be a usual thing. People have gotten into affairs all the time. I heard of a rule: &lt;em class=&quot;markup--em markup--p-em&quot;&gt;if it’s 100 km/80 miles from home, it doesn’t count&lt;/em&gt;. Guys were saying that as a joke, but then were actually caught on cheating. The whole illusion of these &lt;em class=&quot;markup--em markup--p-em&quot;&gt;‘perfect’ lives&lt;/em&gt; disappeared. &lt;strong class=&quot;markup--strong markup--p-strong&quot;&gt;Many were like me, working non stop not finding time for their close ones, although they were able to find partners who seemed ok with that.&lt;/strong&gt; I think this was a moment when I stopped believing in how awesome working at Microsoft was, even though everyone around still seemed so excited.&lt;/p&gt;
&lt;p name=&quot;8d24&quot; id=&quot;8d24&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;The atmosphere wasn’t there anymore, things were changing, they were no longer that fun, but I got more interesting responsibilities - meeting and working with the technical community leaders. &lt;strong class=&quot;markup--strong markup--p-strong&quot;&gt;I graduated the 2 year MACH program and was rewarded as the &lt;em class=&quot;markup--em markup--p-em&quot;&gt;Best Employee&lt;/em&gt; of the department.&lt;/strong&gt; I received a nice bonus and an offer to go to Redmond for a couple of months, for an employee exchange. I also had a 1:1 meeting with the Department Director, who told me that I can’t be a rebel anymore and kind of threatened me that I should be more careful, because Microsoft has provided me a “&lt;em class=&quot;markup--em markup--p-em&quot;&gt;golden cage”&lt;/em&gt; and if I ever get out, I will have to face a tough reality. Yep, that was the message: you were young and feisty, and that’s cool, but now chill and never think about leaving, because the world outside will eat you alive, ok?&lt;/p&gt;
&lt;p name=&quot;f27e&quot; id=&quot;f27e&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;&lt;strong class=&quot;markup--strong markup--p-strong&quot;&gt;Meanwhile my relationship ended, I was miserable, but somehow my career seemed to flourish.&lt;/strong&gt; I got this great opportunity to work in Redmond and have a chance to find myself a position there, so I can be one of the ‘&lt;em class=&quot;markup--em markup--p-em&quot;&gt;corp&lt;/em&gt;’ employees! How amazing! That’s something most of the people in the field dream of, right?&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;1*HJ8X4Qrt60zCdT63kv1mOg.png&quot; data-width=&quot;600&quot; data-height=&quot;600&quot; data-action=&quot;zoom&quot; data-action-value=&quot;1*HJ8X4Qrt60zCdT63kv1mOg.png&quot; src=&quot;https://cdn-images-1.medium.com/max/1200/1*HJ8X4Qrt60zCdT63kv1mOg.png&quot;/&gt;&lt;/div&gt;
The view from my apartment in Belltown, Seattle
&lt;p name=&quot;708d&quot; id=&quot;708d&quot; class=&quot;graf graf--p graf-after--figure&quot;&gt;I chose a corporate housing apartment in downtown Seattle, got a beautiful place (which was probably the best apartment I will ever live in in my life). Last floor of a fancy building and a balcony with an ocean view. Gorgeous. And then I started work. Huge campus, nice cafeterias, woods, a pond, overwhelming space. Everything seemed great, but… yes, unfortunately there was a but… but &lt;em class=&quot;markup--em markup--p-em&quot;&gt;the people&lt;/em&gt;. &lt;strong class=&quot;markup--strong markup--p-strong&quot;&gt;The people I had on my team, were extremely closed minded. Most of them with many years of experience working in a corporation, so even more closed minded, only caring about their manager’s approval&lt;/strong&gt;. I was devastated. They were the most fake people I have met still to this day. I cannot even explain how terrible it was for me to have to help them, show interest and pretend that I support what they’re doing. You might be thinking — &lt;em class=&quot;markup--em markup--p-em&quot;&gt;why weren’t you honest with them instead?&lt;/em&gt; I tried. On 1:1 peer conversations, with my manager, with my skip manager, but no one cared and my role was minimised, so at the end I was only doing a 1 Excel file. I am 100% certain that if I played by their rules and acted the way that they did, focusing on politics, I would do great there, but I refused to do that. &lt;strong class=&quot;markup--strong markup--p-strong&quot;&gt;I actually cared about my role, I cared about the people we were doing the Connect event for more than for my career and no one seemed to understand that.&lt;/strong&gt; I believe I slowly started to become depressed during this time. I stopped showing up at the office and was basically counting down the days to come back home. I have spent 3 months there.&lt;/p&gt;
&lt;p name=&quot;092e&quot; id=&quot;092e&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;When I got back, I was really happy for a first couple of days, but then that feeling started to fade fast. I didn’t want to come to the office in Warsaw either. &lt;strong class=&quot;markup--strong markup--p-strong&quot;&gt;I was staying home more and more everyday, often not even getting up from bed, just browsing e-mails and checking in on Skype to pretend that I’m working&lt;/strong&gt;. I wish I could say it was a day or two, but it was weeks. I thought about quitting all the time since I came back from Redmond, but I still enjoyed working with the community leaders and it was a part of my job that kept me going.&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;1*4NxC8I13Fo6uId_yKUT8sA.jpeg&quot; data-width=&quot;2048&quot; data-height=&quot;1151&quot; data-action=&quot;zoom&quot; data-action-value=&quot;1*4NxC8I13Fo6uId_yKUT8sA.jpeg&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/1*4NxC8I13Fo6uId_yKUT8sA.jpeg&quot;/&gt;&lt;/div&gt;
CEE MVP Summit, Belgrade, Serbia, march 2017
&lt;p name=&quot;c5af&quot; id=&quot;c5af&quot; class=&quot;graf graf--p graf-after--figure&quot;&gt;There were structural changes on a global level at Microsoft. I told my manager I don’t want any bonus that year, since I was in Redmond, didn’t have that much impact locally and he should reward other people. I didn’t deserve a bonus either, I couldn’t stand my job anymore, but still didn’t have the guts to quit. &lt;strong class=&quot;markup--strong markup--p-strong&quot;&gt;It was ‘&lt;em class=&quot;markup--em markup--p-em&quot;&gt;a dream job&lt;/em&gt;’, it has given me so much, it took so much from me&lt;/strong&gt;, but I needed a break. In a midst of the changes I asked for a 3 month unpaid leave. Others warned me that it was a bad idea and that it’s not the time, but I just couldn’t take it anymore.&lt;/p&gt;
&lt;p name=&quot;32f5&quot; id=&quot;32f5&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;I ended up receiving 5 weeks off and went to Portugal for a Workaway. It changed me as well as changed the way I perceived life. It gave me the fresh perspective of a minimalistic lifestyle and not needing all the Microsoft benefits and paychecks to be happy. During my vacation I got some signals that I might get fired. My job title at that time was a Technical Evangelist and it was a hoax. I wasn’t great technically, but the official blueprint stated that the team needed more TEs and I had learned to code, so it was given to me. One of the many ‘&lt;em class=&quot;markup--em markup--p-em&quot;&gt;little white lies&lt;/em&gt;’… Corporate was trying to minimize these local level hoaxes and I respect that, but it meant that &lt;strong class=&quot;markup--strong markup--p-strong&quot;&gt;I came back to Warsaw to receive the dismissal papers&lt;/strong&gt;. There was more going on with a new role proposal etc., but I had the best role (for me) there was in Poland and going back to Redmond seemed like the worst nightmare. I signed the papers and cried for more than an hour. From being the best employee one year, to being fired the next.&lt;/p&gt;
&lt;p name=&quot;8c72&quot; id=&quot;8c72&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;The saddest part is, it wasn’t my manager who told me this. &lt;strong class=&quot;markup--strong markup--p-strong&quot;&gt;My manager, who I worked with 3,5 years by then, didn’t even talk to me during this whole process at all&lt;/strong&gt;. Most of the friends I believed I had, all these people I have spent so much time with, immediately became strangers. I didn’t have a goodbye meeting, wasn’t invited to parties anymore. I had been dedicating myself to a job while sacrificing my relationships, myself and only 2 people from Microsoft cared (&lt;em class=&quot;markup--em markup--p-em&quot;&gt;1 of them because we were dating at that time&lt;/em&gt;). The kind words I have heard were from the people outside — the community leaders, who were appreciative and supportive for which I am forever grateful.&lt;/p&gt;
&lt;p name=&quot;1de3&quot; id=&quot;1de3&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;It wasn’t a ‘&lt;em class=&quot;markup--em markup--p-em&quot;&gt;golden cage&lt;/em&gt;’ I was in, &lt;strong class=&quot;markup--strong markup--p-strong&quot;&gt;it was a bubble of illusions that popped once I signed my dismissal papers. Illusions of importance, mission, friendships and luxury&lt;/strong&gt;. I found a job fairly easily with a similar salary, where they didn’t expect me to work 24/7. The only thing that really changed for ‘the worse’ is that I’m not Ubering that much and don’t spend money on fancy hotels.&lt;/p&gt;
&lt;p name=&quot;5db8&quot; id=&quot;5db8&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;Don’t get me wrong, I am extremely grateful for the opportunity Microsoft has given me. For all the trainings, all the experience, all the travels. I wouldn’t be the person I am today if it wasn’t for this organization, but I am even more grateful for being fired. I didn’t have it in me to quit myself and now I am much better + got the compensation money. I’m 28, have learned to put myself first and spent plenty of time on self care, enough to be able to share this publicly and hopefully not to make the same mistakes in the future.&lt;/p&gt;
&lt;p name=&quot;4d13&quot; id=&quot;4d13&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;So... Goodbye Microsoft! It was a lot.&lt;/p&gt;
&lt;p name=&quot;b068&quot; id=&quot;b068&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;P.S. I know there are teams at Microsoft that are different (shout out to VS Code engineering team!), but I just wasn’t lucky enough to work at one ;)&lt;/p&gt;
&lt;p name=&quot;3b69&quot; id=&quot;3b69&quot; class=&quot;graf graf--p graf-after--p graf--trailing&quot;&gt;P.S. 2 Thanks so much for reading my story, I appreciate it.&lt;/p&gt;
</description>
<pubDate>Sat, 11 May 2019 19:16:50 +0000</pubDate>
<dc:creator>newnoobpl</dc:creator>
<og:title>Saying goodbye to Microsoft</og:title>
<og:url>https://medium.com/@alicjaes/saying-goodbye-to-microsoft-bb5db8662656</og:url>
<og:image>https://cdn-images-1.medium.com/max/1200/1*lE6eCwF-IbzYEin22OD-jQ.jpeg</og:image>
<og:description>What I gained, lost &amp; learned while working for Microsoft.</og:description>
<og:type>article</og:type>
<dc:format>text/html</dc:format>
<dc:identifier>https://medium.com/@alicjaes/saying-goodbye-to-microsoft-bb5db8662656</dc:identifier>
</item>
<item>
<title>A city for the rich, built poorly: The construction of Hudson Yards</title>
<link>https://www.villagespoke.com/2019/05/03/a-city-for-the-rich-built-poorly-the-construction-of-hudson-yards/</link>
<guid isPermaLink="true" >https://www.villagespoke.com/2019/05/03/a-city-for-the-rich-built-poorly-the-construction-of-hudson-yards/</guid>
<description>&lt;h3&gt;In only a month after opening, New York’s most expensive private development is already falling apart.&lt;br/&gt;&lt;/h3&gt;
&lt;p&gt;If you look up from your phone camera for a second before you take a selfie of the Vessel, you’re bound to see something broken at Hudson Yards.&lt;/p&gt;
&lt;img src=&quot;https://i0.wp.com/www.villagespoke.com/wp-content/uploads/2019/04/4.29.19_HYardsBroken1.jpg?fit=1024%2C768&amp;amp;ssl=1&quot; alt=&quot;&quot; class=&quot;wp-image-50&quot; srcset=&quot;https://i0.wp.com/www.villagespoke.com/wp-content/uploads/2019/04/4.29.19_HYardsBroken1.jpg?w=4032&amp;amp;ssl=1 4032w, https://i0.wp.com/www.villagespoke.com/wp-content/uploads/2019/04/4.29.19_HYardsBroken1.jpg?resize=300%2C225&amp;amp;ssl=1 300w, https://i0.wp.com/www.villagespoke.com/wp-content/uploads/2019/04/4.29.19_HYardsBroken1.jpg?resize=768%2C576&amp;amp;ssl=1 768w, https://i0.wp.com/www.villagespoke.com/wp-content/uploads/2019/04/4.29.19_HYardsBroken1.jpg?resize=1024%2C768&amp;amp;ssl=1 1024w, https://i0.wp.com/www.villagespoke.com/wp-content/uploads/2019/04/4.29.19_HYardsBroken1.jpg?w=1710&amp;amp;ssl=1 1710w, https://i0.wp.com/www.villagespoke.com/wp-content/uploads/2019/04/4.29.19_HYardsBroken1.jpg?w=2565&amp;amp;ssl=1 2565w&quot; sizes=&quot;(max-width: 855px) 100vw, 855px&quot;/&gt;&lt;strong&gt;Misaligned cladding at the Shed Arts Center’s Bloomberg Building. |&lt;/strong&gt; Taidgh Barron / Village Spoke
&lt;p&gt;Hudson Yards bills itself as New York’s newest neighborhood, however it reflects many of the shortcomings of the city’s prior superblock development projects.&lt;/p&gt;
&lt;p&gt;The original World Trade Center’s Austin J. Tobin Plaza was an enclosure of skyscrapers along the Hudson River, inadvertently creating a brutal wind tunnel. Hudson Yards is much the same.&lt;/p&gt;
&lt;p&gt;Brooklyn’s MetroTech Center lacked a unified vision with its variety pack of 90s-fad architecture and is today largely unremarkable. Hudson Yards developer Related Companies took a similar approach, commissioning numerous so-called “starchitects” to build what &lt;em&gt;New York Times&lt;/em&gt; Architecture critic Micheal Kimmelman describes as an “&lt;a href=&quot;https://www.nytimes.com/interactive/2019/03/14/arts/design/hudson-yards-nyc.html&quot;&gt;architectural petting zoo.&lt;/a&gt;”&lt;/p&gt;&lt;p&gt;But Hudson Yards also appears to have created their own problems, particularly with the build quality of the development.&lt;/p&gt;
&lt;p&gt;Take the Shed’s Bloomberg Building, for example:&lt;/p&gt;
&lt;img src=&quot;https://i0.wp.com/www.villagespoke.com/wp-content/uploads/2019/04/4.29.19_HYardsBroken2.jpg?fit=1024%2C768&amp;amp;ssl=1&quot; alt=&quot;&quot; class=&quot;wp-image-51&quot; srcset=&quot;https://i0.wp.com/www.villagespoke.com/wp-content/uploads/2019/04/4.29.19_HYardsBroken2.jpg?w=4032&amp;amp;ssl=1 4032w, https://i0.wp.com/www.villagespoke.com/wp-content/uploads/2019/04/4.29.19_HYardsBroken2.jpg?resize=300%2C225&amp;amp;ssl=1 300w, https://i0.wp.com/www.villagespoke.com/wp-content/uploads/2019/04/4.29.19_HYardsBroken2.jpg?resize=768%2C576&amp;amp;ssl=1 768w, https://i0.wp.com/www.villagespoke.com/wp-content/uploads/2019/04/4.29.19_HYardsBroken2.jpg?resize=1024%2C768&amp;amp;ssl=1 1024w, https://i0.wp.com/www.villagespoke.com/wp-content/uploads/2019/04/4.29.19_HYardsBroken2.jpg?w=1710&amp;amp;ssl=1 1710w, https://i0.wp.com/www.villagespoke.com/wp-content/uploads/2019/04/4.29.19_HYardsBroken2.jpg?w=2565&amp;amp;ssl=1 2565w&quot; sizes=&quot;(max-width: 855px) 100vw, 855px&quot;/&gt;&lt;strong&gt;Cladding damage and incomplete sealing at the Shed’s Bloomberg Building. |&lt;/strong&gt; Taidgh Barron / Village Spoke &lt;img src=&quot;https://i1.wp.com/www.villagespoke.com/wp-content/uploads/2019/04/4.29.19_HYardsBroken3.jpg?fit=1024%2C768&amp;amp;ssl=1&quot; alt=&quot;&quot; class=&quot;wp-image-52&quot; srcset=&quot;https://i1.wp.com/www.villagespoke.com/wp-content/uploads/2019/04/4.29.19_HYardsBroken3.jpg?w=4032&amp;amp;ssl=1 4032w, https://i1.wp.com/www.villagespoke.com/wp-content/uploads/2019/04/4.29.19_HYardsBroken3.jpg?resize=300%2C225&amp;amp;ssl=1 300w, https://i1.wp.com/www.villagespoke.com/wp-content/uploads/2019/04/4.29.19_HYardsBroken3.jpg?resize=768%2C576&amp;amp;ssl=1 768w, https://i1.wp.com/www.villagespoke.com/wp-content/uploads/2019/04/4.29.19_HYardsBroken3.jpg?resize=1024%2C768&amp;amp;ssl=1 1024w, https://i1.wp.com/www.villagespoke.com/wp-content/uploads/2019/04/4.29.19_HYardsBroken3.jpg?w=1710&amp;amp;ssl=1 1710w, https://i1.wp.com/www.villagespoke.com/wp-content/uploads/2019/04/4.29.19_HYardsBroken3.jpg?w=2565&amp;amp;ssl=1 2565w&quot; sizes=&quot;(max-width: 855px) 100vw, 855px&quot;/&gt;&lt;strong&gt;Haphazardly installed sealing a week after the Shed’s grand opening. |&lt;/strong&gt; Taidgh Barron / Village Spoke &lt;img src=&quot;https://i0.wp.com/www.villagespoke.com/wp-content/uploads/2019/04/4.29.19_HYardsBroken4.jpg?fit=1024%2C768&amp;amp;ssl=1&quot; alt=&quot;&quot; class=&quot;wp-image-53&quot; srcset=&quot;https://i0.wp.com/www.villagespoke.com/wp-content/uploads/2019/04/4.29.19_HYardsBroken4.jpg?w=4032&amp;amp;ssl=1 4032w, https://i0.wp.com/www.villagespoke.com/wp-content/uploads/2019/04/4.29.19_HYardsBroken4.jpg?resize=300%2C225&amp;amp;ssl=1 300w, https://i0.wp.com/www.villagespoke.com/wp-content/uploads/2019/04/4.29.19_HYardsBroken4.jpg?resize=768%2C576&amp;amp;ssl=1 768w, https://i0.wp.com/www.villagespoke.com/wp-content/uploads/2019/04/4.29.19_HYardsBroken4.jpg?resize=1024%2C768&amp;amp;ssl=1 1024w, https://i0.wp.com/www.villagespoke.com/wp-content/uploads/2019/04/4.29.19_HYardsBroken4.jpg?w=1710&amp;amp;ssl=1 1710w, https://i0.wp.com/www.villagespoke.com/wp-content/uploads/2019/04/4.29.19_HYardsBroken4.jpg?w=2565&amp;amp;ssl=1 2565w&quot; sizes=&quot;(max-width: 855px) 100vw, 855px&quot;/&gt;&lt;strong&gt;Damage on the wheels of the Shed’s retractable assembly. |&lt;/strong&gt; Taidgh Barron / Village Spoke
&lt;p&gt;These construction flaws are troubling considering the labor history of the development. Related twice sued the multi-union construction bloc building the complex and convinced the largest unions in the bloc to &lt;a href=&quot;https://nypost.com/2018/08/07/developer-scores-big-win-against-union-over-hudson-yards-project/&quot;&gt;break ranks&lt;/a&gt;, and they won a judgment to use cheaper non-union labor.&lt;/p&gt;
&lt;p&gt;A month before its grand opening, Hudson Yards appeared to face the prospect of a reporters, politicians and &lt;a href=&quot;https://twitter.com/i/events/1106584377138376704?lang=en&quot;&gt;Big Bird from Sesame Street&lt;/a&gt; crossing a picket line to attend its ribbon cutting. But Related’s President Bruce Beale Jr. was able to avoid such a picture by cutting a deal with the weakened construction unions to end their weekly pickets and rallies in exchange for using &lt;em&gt;&lt;a href=&quot;https://www.6sqft.com/new-deal-framework-between-hudson-yards-developer-and-unions-ends-bitter-labor-fight/&quot;&gt;some&lt;/a&gt;&lt;/em&gt; union labor during the second phase of the development.&lt;/p&gt;
&lt;p&gt;Despite the deal, Hudson Yards’ labor history appears etched in the quality of its craftsmanship.&lt;/p&gt;
&lt;p&gt;Hudson Yards’ &lt;a href=&quot;https://www.hudsonyardsnewyork.com/discover/public-square-and-gardens&quot;&gt;website&lt;/a&gt; calls the Public Square and Gardens area of the complex “the smartest park ever built” and an “engineering marvel,” but the Public Square is lined with broken pavers and questionable construction.&lt;/p&gt;
&lt;img src=&quot;https://i1.wp.com/www.villagespoke.com/wp-content/uploads/2019/04/4.29.19_HYardsBroken6.jpg?fit=1024%2C768&amp;amp;ssl=1&quot; alt=&quot;&quot; class=&quot;wp-image-55&quot; srcset=&quot;https://i1.wp.com/www.villagespoke.com/wp-content/uploads/2019/04/4.29.19_HYardsBroken6.jpg?w=4032&amp;amp;ssl=1 4032w, https://i1.wp.com/www.villagespoke.com/wp-content/uploads/2019/04/4.29.19_HYardsBroken6.jpg?resize=300%2C225&amp;amp;ssl=1 300w, https://i1.wp.com/www.villagespoke.com/wp-content/uploads/2019/04/4.29.19_HYardsBroken6.jpg?resize=768%2C576&amp;amp;ssl=1 768w, https://i1.wp.com/www.villagespoke.com/wp-content/uploads/2019/04/4.29.19_HYardsBroken6.jpg?resize=1024%2C768&amp;amp;ssl=1 1024w, https://i1.wp.com/www.villagespoke.com/wp-content/uploads/2019/04/4.29.19_HYardsBroken6.jpg?w=1710&amp;amp;ssl=1 1710w, https://i1.wp.com/www.villagespoke.com/wp-content/uploads/2019/04/4.29.19_HYardsBroken6.jpg?w=2565&amp;amp;ssl=1 2565w&quot; sizes=&quot;(max-width: 855px) 100vw, 855px&quot;/&gt;&lt;strong&gt;Broken and cracking pavers outside the Vessel. |&lt;/strong&gt; Taidgh Barron / Village Spoke &lt;img src=&quot;https://i2.wp.com/www.villagespoke.com/wp-content/uploads/2019/04/4.29.19_HYardsBroken5.jpg?fit=1024%2C768&amp;amp;ssl=1&quot; alt=&quot;&quot; class=&quot;wp-image-56&quot; srcset=&quot;https://i2.wp.com/www.villagespoke.com/wp-content/uploads/2019/04/4.29.19_HYardsBroken5.jpg?w=4032&amp;amp;ssl=1 4032w, https://i2.wp.com/www.villagespoke.com/wp-content/uploads/2019/04/4.29.19_HYardsBroken5.jpg?resize=300%2C225&amp;amp;ssl=1 300w, https://i2.wp.com/www.villagespoke.com/wp-content/uploads/2019/04/4.29.19_HYardsBroken5.jpg?resize=768%2C576&amp;amp;ssl=1 768w, https://i2.wp.com/www.villagespoke.com/wp-content/uploads/2019/04/4.29.19_HYardsBroken5.jpg?resize=1024%2C768&amp;amp;ssl=1 1024w, https://i2.wp.com/www.villagespoke.com/wp-content/uploads/2019/04/4.29.19_HYardsBroken5.jpg?w=1710&amp;amp;ssl=1 1710w, https://i2.wp.com/www.villagespoke.com/wp-content/uploads/2019/04/4.29.19_HYardsBroken5.jpg?w=2565&amp;amp;ssl=1 2565w&quot; sizes=&quot;(max-width: 855px) 100vw, 855px&quot;/&gt;&lt;strong&gt;Overextended saw cuts and cracked pavers in Hudson Yard’s plaza. |&lt;/strong&gt; Taidgh Barron / Village Spoke &lt;img src=&quot;https://i0.wp.com/www.villagespoke.com/wp-content/uploads/2019/04/4.29.19_HYardsBroken9.jpg?fit=1024%2C768&amp;amp;ssl=1&quot; alt=&quot;&quot; class=&quot;wp-image-57&quot; srcset=&quot;https://i0.wp.com/www.villagespoke.com/wp-content/uploads/2019/04/4.29.19_HYardsBroken9.jpg?w=4032&amp;amp;ssl=1 4032w, https://i0.wp.com/www.villagespoke.com/wp-content/uploads/2019/04/4.29.19_HYardsBroken9.jpg?resize=300%2C225&amp;amp;ssl=1 300w, https://i0.wp.com/www.villagespoke.com/wp-content/uploads/2019/04/4.29.19_HYardsBroken9.jpg?resize=768%2C576&amp;amp;ssl=1 768w, https://i0.wp.com/www.villagespoke.com/wp-content/uploads/2019/04/4.29.19_HYardsBroken9.jpg?resize=1024%2C768&amp;amp;ssl=1 1024w, https://i0.wp.com/www.villagespoke.com/wp-content/uploads/2019/04/4.29.19_HYardsBroken9.jpg?w=1710&amp;amp;ssl=1 1710w, https://i0.wp.com/www.villagespoke.com/wp-content/uploads/2019/04/4.29.19_HYardsBroken9.jpg?w=2565&amp;amp;ssl=1 2565w&quot; sizes=&quot;(max-width: 855px) 100vw, 855px&quot;/&gt;&lt;strong&gt;Missing and misaligned pavers outside The Shops at Hudson Yards. |&lt;/strong&gt; Taidgh Barron / Village Spoke &lt;img src=&quot;https://i0.wp.com/www.villagespoke.com/wp-content/uploads/2019/04/4.29.19_HYardsBroken7.jpg?fit=1024%2C768&amp;amp;ssl=1&quot; alt=&quot;&quot; class=&quot;wp-image-58&quot; srcset=&quot;https://i0.wp.com/www.villagespoke.com/wp-content/uploads/2019/04/4.29.19_HYardsBroken7.jpg?w=4032&amp;amp;ssl=1 4032w, https://i0.wp.com/www.villagespoke.com/wp-content/uploads/2019/04/4.29.19_HYardsBroken7.jpg?resize=300%2C225&amp;amp;ssl=1 300w, https://i0.wp.com/www.villagespoke.com/wp-content/uploads/2019/04/4.29.19_HYardsBroken7.jpg?resize=768%2C576&amp;amp;ssl=1 768w, https://i0.wp.com/www.villagespoke.com/wp-content/uploads/2019/04/4.29.19_HYardsBroken7.jpg?resize=1024%2C768&amp;amp;ssl=1 1024w, https://i0.wp.com/www.villagespoke.com/wp-content/uploads/2019/04/4.29.19_HYardsBroken7.jpg?w=1710&amp;amp;ssl=1 1710w, https://i0.wp.com/www.villagespoke.com/wp-content/uploads/2019/04/4.29.19_HYardsBroken7.jpg?w=2565&amp;amp;ssl=1 2565w&quot; sizes=&quot;(max-width: 855px) 100vw, 855px&quot;/&gt;&lt;strong&gt;Pavers at the Public Square and Gardens of Hudson Yards. |&lt;/strong&gt; Taidgh Barron / Village Spoke
&lt;p&gt;During the unveiling of the Public Square’s design in 2016, Related Chairman Stephen Ross took inspiration from another New York superblock development, Rockefeller Center.&lt;/p&gt;
&lt;p&gt;“The most important place in New York is Rockefeller Center during Christmas time, I wanted to have a 12-month Christmas tree” &lt;a href=&quot;https://www.nytimes.com/2016/09/15/arts/design/hudson-yards-own-social-climbing-stairway.html&quot;&gt;Mr. Ross said.&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;And thus, &lt;em&gt;Vessel&lt;/em&gt; was commissioned to serve as a “vessel” to attract tourists to the West-side campus and vertical retail luxury mall that looks like any other global city mall.&lt;/p&gt;
&lt;p&gt;But even Hudson Yards’ crown jewel has misaligned cladding adorning its entrance.&lt;/p&gt;
&lt;img src=&quot;https://i2.wp.com/www.villagespoke.com/wp-content/uploads/2019/04/4.29.19_HYardsBroken8.jpg?fit=1024%2C768&amp;amp;ssl=1&quot; alt=&quot;&quot; class=&quot;wp-image-54&quot; srcset=&quot;https://i2.wp.com/www.villagespoke.com/wp-content/uploads/2019/04/4.29.19_HYardsBroken8.jpg?w=4032&amp;amp;ssl=1 4032w, https://i2.wp.com/www.villagespoke.com/wp-content/uploads/2019/04/4.29.19_HYardsBroken8.jpg?resize=300%2C225&amp;amp;ssl=1 300w, https://i2.wp.com/www.villagespoke.com/wp-content/uploads/2019/04/4.29.19_HYardsBroken8.jpg?resize=768%2C576&amp;amp;ssl=1 768w, https://i2.wp.com/www.villagespoke.com/wp-content/uploads/2019/04/4.29.19_HYardsBroken8.jpg?resize=1024%2C768&amp;amp;ssl=1 1024w, https://i2.wp.com/www.villagespoke.com/wp-content/uploads/2019/04/4.29.19_HYardsBroken8.jpg?w=1710&amp;amp;ssl=1 1710w, https://i2.wp.com/www.villagespoke.com/wp-content/uploads/2019/04/4.29.19_HYardsBroken8.jpg?w=2565&amp;amp;ssl=1 2565w&quot; sizes=&quot;(max-width: 855px) 100vw, 855px&quot;/&gt;&lt;strong&gt;The visitor’s entrance to The Vessel, with misaligned cladding over the portal. |&lt;/strong&gt; Taidgh Barron / Village Spoke
&lt;p&gt;The lack of attention to detail extends beyond the quality of construction work, too.&lt;/p&gt;
&lt;p&gt;Throughout the entire complex, glaring lapses in design stand out, such as six inch gaps between railings at the mall and staircases eight times wider than the walkways they lead to.&lt;/p&gt;
&lt;img src=&quot;https://i0.wp.com/www.villagespoke.com/wp-content/uploads/2019/04/4.29.19_HYardsBroken11.jpg?fit=1024%2C768&amp;amp;ssl=1&quot; alt=&quot;&quot; class=&quot;wp-image-60&quot; srcset=&quot;https://i0.wp.com/www.villagespoke.com/wp-content/uploads/2019/04/4.29.19_HYardsBroken11.jpg?w=4032&amp;amp;ssl=1 4032w, https://i0.wp.com/www.villagespoke.com/wp-content/uploads/2019/04/4.29.19_HYardsBroken11.jpg?resize=300%2C225&amp;amp;ssl=1 300w, https://i0.wp.com/www.villagespoke.com/wp-content/uploads/2019/04/4.29.19_HYardsBroken11.jpg?resize=768%2C576&amp;amp;ssl=1 768w, https://i0.wp.com/www.villagespoke.com/wp-content/uploads/2019/04/4.29.19_HYardsBroken11.jpg?resize=1024%2C768&amp;amp;ssl=1 1024w, https://i0.wp.com/www.villagespoke.com/wp-content/uploads/2019/04/4.29.19_HYardsBroken11.jpg?w=1710&amp;amp;ssl=1 1710w, https://i0.wp.com/www.villagespoke.com/wp-content/uploads/2019/04/4.29.19_HYardsBroken11.jpg?w=2565&amp;amp;ssl=1 2565w&quot; sizes=&quot;(max-width: 855px) 100vw, 855px&quot;/&gt;&lt;strong&gt;Unsafe railing gaps inside the Shops and Restaurants at Hudson Yard. |&lt;/strong&gt; Taidgh Barron / Village Spoke &lt;img src=&quot;https://i2.wp.com/www.villagespoke.com/wp-content/uploads/2019/04/4.29.19_HYardsBroken10.jpg?fit=1024%2C768&amp;amp;ssl=1&quot; alt=&quot;&quot; class=&quot;wp-image-59&quot; srcset=&quot;https://i2.wp.com/www.villagespoke.com/wp-content/uploads/2019/04/4.29.19_HYardsBroken10.jpg?w=4032&amp;amp;ssl=1 4032w, https://i2.wp.com/www.villagespoke.com/wp-content/uploads/2019/04/4.29.19_HYardsBroken10.jpg?resize=300%2C225&amp;amp;ssl=1 300w, https://i2.wp.com/www.villagespoke.com/wp-content/uploads/2019/04/4.29.19_HYardsBroken10.jpg?resize=768%2C576&amp;amp;ssl=1 768w, https://i2.wp.com/www.villagespoke.com/wp-content/uploads/2019/04/4.29.19_HYardsBroken10.jpg?resize=1024%2C768&amp;amp;ssl=1 1024w, https://i2.wp.com/www.villagespoke.com/wp-content/uploads/2019/04/4.29.19_HYardsBroken10.jpg?w=1710&amp;amp;ssl=1 1710w, https://i2.wp.com/www.villagespoke.com/wp-content/uploads/2019/04/4.29.19_HYardsBroken10.jpg?w=2565&amp;amp;ssl=1 2565w&quot; sizes=&quot;(max-width: 855px) 100vw, 855px&quot;/&gt;&lt;strong&gt;Step off the three foot wide walkway onto the rocks, even if to get to the staircase, and a security guard will shoo you away. |&lt;/strong&gt; Taidgh Barron / Village Spoke
&lt;p&gt;You get the distinct sense that you’re walking through a computer rendering rather than a real place. Aesthetic is prioritized over function everywhere you go.&lt;/p&gt;
&lt;p&gt;In the Shops and Restaurants at Hudson Yards, escalators are not positioned to allow a seamless flow up and down the levels of the mall, but rather, to make the complex photogenic; often requiring you to search at each level for the next escalator down in order to exit.&lt;/p&gt;
&lt;p&gt;On busy weekends it’s common to see tourists eating while &lt;a href=&quot;https://www.theinfatuation.com/new-york/guides/hudson-yards-restaurants&quot;&gt;sitting on the floor&lt;/a&gt; outside luxury retail chains because the food court lacks tables and seating.&lt;/p&gt;
&lt;img src=&quot;https://i0.wp.com/www.villagespoke.com/wp-content/uploads/2019/05/4.29.19_HYardsBroken12.jpg?fit=1024%2C768&amp;amp;ssl=1&quot; alt=&quot;&quot; class=&quot;wp-image-71&quot; srcset=&quot;https://i0.wp.com/www.villagespoke.com/wp-content/uploads/2019/05/4.29.19_HYardsBroken12.jpg?w=4032&amp;amp;ssl=1 4032w, https://i0.wp.com/www.villagespoke.com/wp-content/uploads/2019/05/4.29.19_HYardsBroken12.jpg?resize=300%2C225&amp;amp;ssl=1 300w, https://i0.wp.com/www.villagespoke.com/wp-content/uploads/2019/05/4.29.19_HYardsBroken12.jpg?resize=768%2C576&amp;amp;ssl=1 768w, https://i0.wp.com/www.villagespoke.com/wp-content/uploads/2019/05/4.29.19_HYardsBroken12.jpg?resize=1024%2C768&amp;amp;ssl=1 1024w, https://i0.wp.com/www.villagespoke.com/wp-content/uploads/2019/05/4.29.19_HYardsBroken12.jpg?w=1710&amp;amp;ssl=1 1710w, https://i0.wp.com/www.villagespoke.com/wp-content/uploads/2019/05/4.29.19_HYardsBroken12.jpg?w=2565&amp;amp;ssl=1 2565w&quot; sizes=&quot;(max-width: 855px) 100vw, 855px&quot;/&gt;&lt;strong&gt;It’s easy to get the feeling that the faceplates of brand-new signs popping off their fixtures were simply pixel-off details unnoticeable in a 100:1 scale virtual world.&lt;/strong&gt; &lt;strong&gt;|&lt;/strong&gt; Taidgh Barron / Village Spoke
&lt;p&gt;While Mr. Kimmelman in &lt;em&gt;the New York Times&lt;/em&gt; calls Hudson Yards “a spectacle” where “the peak ambitions of city life were consuming luxury goods and enjoying a smooth, seductive, mindless materialism,” saying it’s a place designed for a smooth experience is a stretch.&lt;/p&gt;
&lt;p&gt;I have a different way to wording it:&lt;/p&gt;
&lt;p&gt;Hudson Yards is designed to be a place where the peak ambitions of city life are to purchase something and vanish…&lt;/p&gt;
&lt;p&gt;That is, if you can find your way out.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;The&lt;/em&gt; &lt;em&gt;Village Spoke&lt;/em&gt; reached out to Hudson Yards for comment but they declined to return our calls and emails.&lt;/p&gt;
</description>
<pubDate>Sat, 11 May 2019 17:36:29 +0000</pubDate>
<dc:creator>jsjohnst</dc:creator>
<og:type>article</og:type>
<og:title>A city for the rich, built poorly: The construction of Hudson Yards - Village Spoke</og:title>
<og:description>In only a month after opening, New York’s most expensive private development is already falling apart. If you look up from your phone camera for ... Read moreA city for the rich, built poorly: The construction of Hudson Yards</og:description>
<og:url>https://www.villagespoke.com/2019/05/03/a-city-for-the-rich-built-poorly-the-construction-of-hudson-yards/</og:url>
<og:image>https://www.villagespoke.com/wp-content/uploads/2019/04/TGC01593-1024x681.jpg</og:image>
<dc:language>en-US</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.villagespoke.com/2019/05/03/a-city-for-the-rich-built-poorly-the-construction-of-hudson-yards/</dc:identifier>
</item>
<item>
<title>Boeing altered key switches in 737 MAX cockpit limiting ability to shut off MCAS</title>
<link>https://www.seattletimes.com/business/boeing-aerospace/boeing-altered-key-switches-in-737-max-cockpit-limiting-ability-to-shut-off-mcas/</link>
<guid isPermaLink="true" >https://www.seattletimes.com/business/boeing-aerospace/boeing-altered-key-switches-in-737-max-cockpit-limiting-ability-to-shut-off-mcas/</guid>
<description>&lt;p&gt;In the middle of Boeing 737 cockpits, sitting between the pilot seats, are two toggle switches that can immediately shut off power to the systems that control the angle of the plane’s horizontal tail.&lt;/p&gt;
&lt;p&gt;Those switches are critical in the event a malfunction causes movements that the pilots don’t want. And Boeing sees the toggles as a vital backstop to a new safety system on the 737 MAX – the Maneuvering Characteristics Augmentation System (MCAS) – which is suspected of repeatedly moving the horizontal tails on the Lion Air and Ethiopian Airlines flights that crashed and killed a total of 346 people.&lt;/p&gt;
&lt;p&gt;But as Boeing was transitioning from its 737 NG model to the 737 MAX, the company altered the labeling and the purpose of those two switches. The functionality of the switches became more restrictive on the MAX than on previous models, closing out an option that could conceivably have helped the pilots in the Ethiopian Airlines flight regain control.&lt;/p&gt;
&lt;p&gt;Boeing declined to detail the specific functionality of the two switches. But after obtaining and reviewing flight manual documents, The Seattle Times found that the left switch on the 737 NG model is capable of deactivating the buttons on the yoke that pilots regularly press with their thumb to control the horizontal stabilizer. The right switch on the 737 NG was labeled “AUTO PILOT” and is capable of deactivating just the automated controls of the stabilizer.&lt;/p&gt;
&lt;p&gt;On the newer 737 MAX, according to documents reviewed by The Times, those two switches were changed to perform the same function – flipping either one of them would turn off all electric controls of the stabilizer. That means there is no longer an option to turn off automated functions – such as MCAS – without also turning off the thumb buttons the pilots would normally use to control the stabilizer.&lt;/p&gt;
&lt;p&gt;Peter Lemme, a former Boeing flight-controls engineer who has been closely scrutinizing the MAX design and first raised questions about the switches &lt;a href=&quot;https://www.satcom.guru/2019/04/stabilizer-trim-loads-and-range.html&quot; target=&quot;_blank&quot; class=&quot;content-link external&quot;&gt;on his blog&lt;/a&gt;, said he doesn’t understand why Boeing abandoned the old setup. He said if the company had maintained the switch design from the 737 NG, Boeing could have instructed pilots after the Lion Air crash last year to simply flip the “AUTO PILOT” switch to deactivate MCAS and continue flying with the normal trim buttons on the control wheel. He said that would have saved the Ethiopian Airlines plane and the 157 people on board.&lt;/p&gt;
&lt;div class=&quot;ad-container u-bg-dark-off-white full-width-inset mb-4 mt-4 pt-0 ad-container-multiple body1&quot;&gt;
&lt;div class=&quot;ad-label font-micro u-tc u-mid-light-gray u-sans pv-10 u-upper&quot;&gt;Advertising&lt;/div&gt;

&lt;/div&gt;
&lt;p&gt;“There’s no doubt in my mind that they would have been fine,” Lemme said.&lt;/p&gt;
&lt;p&gt;Boeing said in a statement that the company had historically called for pilots to flip both switches to shut of a problematic or “runaway” stabilizer, so the change on the MAX ensured that the function of the switches matched that procedure. The company said the two switches “were retained for commonality of the crew interface.”&lt;/p&gt;
&lt;p&gt;“Boeing strongly disagrees with any speculation or suggestion that pilots should deviate from these long-established and trained safety procedures,” Boeing said.&lt;/p&gt;
&lt;p&gt;On the Lion Air flight in October, pilots were apparently unaware of MCAS. As various warnings went off in the cockpit, they never reached the conclusion to use the runaway stabilizer procedure. In the end, &lt;a href=&quot;https://www.seattletimes.com/business/boeing-aerospace/black-box-data-reveals-lion-air-pilots-struggle-against-boeings-737-max-flight-control-system/&quot; class=&quot;content-link&quot;&gt;data from the flight shows&lt;/a&gt;, the repeated commands of MCAS eventually sent the plane plummeting into the sea.&lt;/p&gt;
&lt;p&gt;After that crash, Boeing issued a directive calling for pilots to use the typical runaway stabilizer procedure to deal with MCAS in the event of a problem. Then pilots would be able to swivel the tail down manually by physically turning a control wheel that connects to the tail via cables.&lt;/p&gt;
&lt;p&gt;But on the Ethiopian Airlines flight, the pilots appear to have recognized the errant MCAS problem and flipped the cutoff switches as described in the checklist. But then it appears that the pilots were unable to move the manual wheel, &lt;a href=&quot;https://www.seattletimes.com/business/boeing-aerospace/boeings-emergency-procedure-for-737-max-may-have-failed-on-ethiopian-flight/&quot; class=&quot;content-link&quot;&gt;likely because the forces on the tail made it physically challenging to turn&lt;/a&gt;.&lt;/p&gt;
&lt;div class=&quot;ad-container u-bg-dark-off-white full-width-inset mb-4 mt-4 pt-0 ad-container-single&quot;&gt;
&lt;div class=&quot;ad-label font-micro u-tc u-mid-light-gray u-sans pv-10 u-upper&quot;&gt;Advertising&lt;/div&gt;

&lt;/div&gt;
&lt;p&gt;The bottom of Boeing’s runaway stabilizer checklist seems to acknowledge the possibility of this physically challenging scenario. It suggests that the pilots can first use the electric trim to neutralize those potential forces before hitting the cutout switches.&lt;/p&gt;
&lt;p&gt;After failing to manually control the stabilizer, the Ethiopian Airlines pilots appear to have flipped the cutoff switches back on, which awakened the MCAS system. It soon sent the plane diving to Earth.&lt;/p&gt;
&lt;div class=&quot;article-component embed-container column-width-embed u-border-t u-border-b u-border-light-gray mv-40 pv-20&quot;&gt;
&lt;h2&gt;Talk to us&lt;/h2&gt;
&lt;p&gt;We continue to seek information on the design, training and certification of the Boeing 737 MAX. If you have insights, please get in touch with aerospace reporter Dominic Gates at 206-464-2963 or &lt;a href=&quot;mailto:dgates@seattletimes.com&quot;&gt;dgates@seattletimes.com&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;To communicate on a confidential and encrypted channel, follow the options available at &lt;a href=&quot;https://st.news/newstips&quot;&gt;https://st.news/newstips&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Lemme said he’s surprised that Boeing made the change to take away the functionality that could have allowed the pilots to shut off MCAS without shutting off the electric switches at their thumbs.&lt;/p&gt;
&lt;p&gt;“I don’t get it at all,” Lemme said. “I don’t see what the benefit was for making that change. It was like change for change’s sake.”&lt;/p&gt;

&lt;p&gt;But Doug Moss, an aviation consultant who has worked as a commercial pilot on Boeing planes, said the cutout switches need to be as simple as possible. Asking the pilots to flip one of the switches – instead of what they have historically known about flipping two switches simultaneously – may have just added a layer of complexity that isn’t helpful in an intense scenario.&lt;/p&gt;
&lt;p&gt;“When you’re pulling on the column with 80-100 pounds of force trying to save your life, your troubleshooting techniques are very weak,” Moss said. “You need some gut-level instinctive things to do to solve the problem.”&lt;/p&gt;

&lt;p&gt;A veteran Boeing 737 test pilot said that all Boeing planes have two such cutoff switches, not just the 737. And both he and American Airlines Captain Dennis Tajer, a spokesman for the Allied Pilots Association who flies 737s, said they could think of no existing procedure that called for flipping only one of the switches.&lt;/p&gt;
&lt;p&gt;The procedure appears to be designed to prepare for a situation in which the plane’s stabilizer motor is for some reason jammed and moving uncommanded in one direction – a classic “runaway stabilizer” situation. That would require shutting off all power to the motor.&lt;/p&gt;
&lt;p&gt;As the FAA worked to inform pilots about the changes on the MAX airplane when it first came into service, the agency didn’t describe the new functionality of the switches. In its documentation, it simply noted a labeling change: “Stab Trim cutout switches panel nomenclature,” the Flight Standardization Board included on its list of differences between the plane models.&lt;/p&gt;
&lt;div data-section=&quot;business&quot; class=&quot;most-read-container module most-shared truncate show u-border-t u-border-b u-border-light-gray embed-container mt-40 mb-40&quot;&gt;
&lt;div class=&quot;most-read-wrapper mb-17&quot;&gt;
&lt;h2 class=&quot;mrw-header pt-27&quot;&gt;Most Read Business Stories&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Boeing did not answer questions Friday about the original purpose of the two-switch design on the 737 model – a plane that first entered service in the 1960s – or about whether the company plans any upcoming changes on the cutout switches.&lt;/p&gt;
&lt;p&gt;With the 737 MAX grounded around the world, &lt;a href=&quot;https://www.seattletimes.com/business/boeing-aerospace/faa-could-clear-boeing-max-to-fly-again-by-late-may-or-early-june/&quot; class=&quot;content-link&quot;&gt;Boeing is now working on a fix to its MCAS system&lt;/a&gt;. The software update is expected to limit the power of MCAS and will consider multiple inputs so that it won’t take action in response to a single faulty sensor.&lt;/p&gt;


</description>
<pubDate>Sat, 11 May 2019 17:05:49 +0000</pubDate>
<dc:creator>erentz</dc:creator>
<og:title>Boeing altered key switches in 737 MAX cockpit, limiting ability to shut off MCAS</og:title>
<og:type>article</og:type>
<og:url>https://www.seattletimes.com/business/boeing-aerospace/boeing-altered-key-switches-in-737-max-cockpit-limiting-ability-to-shut-off-mcas/</og:url>
<og:image>https://static.seattletimes.com/wp-content/uploads/2019/05/164929-1200x630.jpg</og:image>
<og:description>On Boeing’s 737 MAX, the company altered cutout switches to remove an option that would potentially allow pilots to shut off automated controls while keeping the functionality of the manual electric controls on the yoke. That change closed out an...</og:description>
<dc:language>en-US</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.seattletimes.com/business/boeing-aerospace/boeing-altered-key-switches-in-737-max-cockpit-limiting-ability-to-shut-off-mcas/</dc:identifier>
</item>
<item>
<title>Calculus with Julia</title>
<link>https://calculuswithjulia.github.io/</link>
<guid isPermaLink="true" >https://calculuswithjulia.github.io/</guid>
<description>&lt;p&gt;This is a set of notes for learning &lt;a href=&quot;http://en.wikipedia.org/wiki/Calculus&quot;&gt;calculus&lt;/a&gt;. Since the mid 90s there has been a push to teach calculus using many different points of view. The &lt;a href=&quot;http://www.math.harvard.edu/~knill/pedagogy/harvardcalculus/&quot;&gt;Harvard&lt;/a&gt; style rule of four says that as much as possible the conversation should include a graphical, numerical, algebraic, and verbal component. These notes use the programming language &lt;a href=&quot;http://julialang.org&quot;&gt;Julia&lt;/a&gt; to illustrate the graphical, numerical, and, at times, the algebraic aspects of calculus.&lt;/p&gt;
&lt;p&gt;There are many examples of integrating a computer algebra system (such as &lt;code&gt;Mathematica&lt;/code&gt;, &lt;code&gt;Maple&lt;/code&gt;, or &lt;code&gt;Sage&lt;/code&gt;) into the calculus conversation. Computer algebra systems can be magical. The popular &lt;a href=&quot;http://www.wolframalpha.com/&quot;&gt;WolframAlpha&lt;/a&gt; website calls the full power of &lt;code&gt;Mathematica&lt;/code&gt; while allowing an informal syntax that is flexible enough to be used as a backend for Apple's Siri feature. (&quot;Siri what is the graph of x squared minus 4?&quot;) For learning purposes, computer algebra systems model very well the algebraic/symbolic treatment of the material while providing means to illustrate the numeric aspects. Theses notes are a bit different in that &lt;code&gt;Julia&lt;/code&gt; is primarily used for the numeric style of computing and the algebraic/symbolic treatment is added on. Doing the symbolic treatment by hand can be very beneficial while learning, and computer algebra systems make those exercises seem kind of pointless, as the finished product can be produced much easier.&lt;/p&gt;
&lt;p&gt;Our real goal is to get at the concepts using technology as much as possible without getting bogged down in the mechanics of the computer language. We feel &lt;code&gt;Julia&lt;/code&gt; has a very natural syntax that makes the initial start up not so much more difficult than using a calculator. The notes restrict themselves to a reduced set of computational concepts. This set is sufficient for working the problems in mathematics, but do not cover thoroughly many aspects of programming. (Those who are interested can go off on their own and &lt;code&gt;Julia&lt;/code&gt; provides a rich opportunity to do so.) Within this restricted set, are operators that make many of the computations of calculus reduce to a function call of the form &lt;code&gt;action(function, arguments...)&lt;/code&gt;. With a small collection of actions that can be composed, many of the problems associated with introductory calculus can be attacked.&lt;/p&gt;
&lt;p&gt;These notes are presented in pages covering a fairly focused concept, in a spirit similar to a section of a book. Just like a book, there are try-it-yourself questions at the end of each page. All have self-graded answers.&lt;/p&gt;
&lt;h2&gt;Getting started with Julia&lt;/h2&gt;
&lt;p&gt;Before beginning, we need to get started with Julia. This is akin to going out and buying a calculator, though it won't take as long.&lt;/p&gt;
&lt;h2&gt;Precalculus&lt;/h2&gt;
&lt;p&gt;Many of the necessary computational skills needed for employing &lt;code&gt;Julia&lt;/code&gt; successfully to assist in learning calculus are in direct analogy to concepts of mathematics that are first introduced in precalculus or prior. This precalculus &lt;em&gt;review&lt;/em&gt;, covers some of the basic materials mathematically (though not systematically). More importantly it illustrates the key computational mechanics we will use throughout. A quick rundown of the &lt;code&gt;julia&lt;/code&gt; concepts alone is &lt;a href=&quot;https://calculuswithjulia.github.io/precalc/julia_overview.html&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;Number systems&lt;/h3&gt;
&lt;p&gt;Taking for granted a familiarity with basic calculators, we show in these two sections how &lt;code&gt;Julia&lt;/code&gt; implements the functionality of a calculator in a manner not so different.&lt;/p&gt;
&lt;p&gt;Calculators really only use one type of number – floating point numbers. Floating point numbers are a model for the real numbers. However, there are many different sets of numbers in mathematics. Common ones include the integers, rational numbers, real numbers, and complex numbers. As well, we discuss logical values and vectors of numbers. Though integers are rational numbers, rational numbers are real numbers, and real numbers may be viewed as complex numbers, mathematically, these distinctions serve a purpose. &lt;code&gt;Julia&lt;/code&gt; also makes these distinctions and more.&lt;/p&gt;
&lt;p&gt;Vectors as a mathematical object could be postponed for later, but they are introduced here as the &lt;code&gt;Julia&lt;/code&gt; implementation makes an excellent choice for a container of one or more values. We also see how to work with more than one value at a time, a useful facility in future work.&lt;/p&gt;
&lt;p&gt;An arithmetic progression is a sequence of the form $a, a+h, a+2h, \dots, a+kh$. For example $3, 10, 17, 24, .., 52$. They prove very useful in describing collections of numbers. We introduce the range operator that models these within &lt;code&gt;Julia&lt;/code&gt; and comprehensions that allow one to easily modify the simple sequences.&lt;/p&gt;
&lt;h3&gt;Functions&lt;/h3&gt;
&lt;p&gt;The use of functions within calculus is widespread. This section shows how the basic usage within &lt;code&gt;Julia&lt;/code&gt; follows very closely to common mathematical usage. It also shows that the abstract concept of a function is quite valuable.&lt;/p&gt;
&lt;p&gt;A graphing calculator makes it very easy to produce a graph. &lt;code&gt;Julia&lt;/code&gt;, using the &lt;code&gt;Plots&lt;/code&gt; package, makes it even easier and more flexible.&lt;/p&gt;
&lt;h4&gt;Polynomials&lt;/h4&gt;
&lt;p&gt;Polynomials play an important role in calculus. They give a family of functions for which the basic operations are well understood. In addition, they can be seen to provide approximations to functions. This section discusses polynomials and introduces the add-on package &lt;code&gt;SymPy&lt;/code&gt; for manipulating expressions in &lt;code&gt;Julia&lt;/code&gt; symbolically. (This package uses the SymPy library from Python.)&lt;/p&gt;
&lt;p&gt;The roots of a univariate polynomial are the values of $x$ for which $p(x)=0$. Roots are related to its factors. In calculus, the zeros of a derived function are used to infer properties of a function. This section shows some tools in &lt;code&gt;SymPy&lt;/code&gt; to find factors and roots, when they are available, and introduces the &lt;code&gt;Roots&lt;/code&gt; package for estimating roots numerically.&lt;/p&gt;
&lt;p&gt;A rational expression is the ratio of two polynomial expressions. This section covers some additional details that arise when graphing such expressions.&lt;/p&gt;
&lt;h4&gt;Exponential and logarithmic functions&lt;/h4&gt;
&lt;h4&gt;Trigonometric functions&lt;/h4&gt;
&lt;p&gt;Trigonometric functions are used to describe triangles, circles and oscillatory behaviors. This section provide a brief review.&lt;/p&gt;
&lt;h2&gt;Limits and Continuity&lt;/h2&gt;
&lt;p&gt;The notion of a limit is at the heart of the two main operations of calculus, differentiation and integration.&lt;/p&gt;
&lt;p&gt;Continuous functions are at the center of any discussion of calculus concepts. These sections define them and illustrate a few implications for continuous functions.&lt;/p&gt;
&lt;h2&gt;Derivatives&lt;/h2&gt;
&lt;p&gt;The derivative of a function is a derived function that for each $x$ yields the slope of the &lt;em&gt;tangent line&lt;/em&gt; of the graph of $f$ at $(x,f(x))$.&lt;/p&gt;
&lt;p&gt;The derivative of a function has certain features. These next sections explore one of the first uses of the derivative – using its zeros to characterize the original function.&lt;/p&gt;
&lt;p&gt;The tangent line to the graph of a function at a point has slope given through the derivative. That the tangent line is the best linear approximation to the curve yields some insight to the curve through knowledge of just the tangent lines.&lt;/p&gt;
&lt;p&gt;The derivative finds use outside of the traditional way of specifying a function or relationship. These two sections look at some different cases.&lt;/p&gt;
&lt;p&gt;A generalization of the tangent line as the &quot;best&quot; approximation to a function by a line leads to the concept of the Taylor polynomial.&lt;/p&gt;
&lt;h2&gt;Integration&lt;/h2&gt;
&lt;p&gt;The integral is initially defined in terms of an associated area and then generalized. The Fundamental Theorem of Calculus allows this area to be computed easily through a related function and specifies the relationship between the integral and the derivative.&lt;/p&gt;
&lt;p&gt;Integration is not algorithmic, but rather problems can involve an array of techniques. Many of these are implemented in &lt;code&gt;SymPy&lt;/code&gt;. Theses sections introduce the main techniques that find widespread usage.&lt;/p&gt;
&lt;h3&gt;Applications&lt;/h3&gt;
&lt;p&gt;Various applications of the integral are presented. The first two sections continue with the idea that an integral is related to area. From there, it is seen that volumes and arc-lengths may be expressed in terms of related integrals.&lt;/p&gt;
&lt;p&gt;Ordinary differential equations are an application of integration and the fundamental theorem of calculus.&lt;/p&gt;
&lt;h2&gt;Two-dimensional curves&lt;/h2&gt;
&lt;p&gt;In addition to curves generated by graphs of functions, there are other ways to describe curves in two dimensions. One involves parameterizing both the $x$ and $y$ coordinates by a third variable, such as time. The other, polar curves, describes position in terms of a angle from the positive $x$ axis and a radial distance.&lt;/p&gt;
&lt;h2&gt;Bibliography&lt;/h2&gt;
&lt;hr/&gt;&lt;div class=&quot;alert alert-success&quot; role=&quot;alert&quot; readability=&quot;8.8192771084337&quot;&gt;
&lt;div class=&quot;markdown&quot; readability=&quot;12.738955823293&quot;&gt;
&lt;p&gt;This is a work in progress. To report an issue, make a comment, or suggest something new, please file an &lt;a href=&quot;https://github.com/CalculusWithJulia/CalculusWithJulia.github.io/issues/&quot;&gt;issue&lt;/a&gt;. In your message add the tag &lt;code&gt;@jverzani&lt;/code&gt; to ensure it is not overlooked. Otherwise, an email to &lt;code&gt;verzani&lt;/code&gt; at &lt;code&gt;math.csi.cuny.edu&lt;/code&gt; will also work.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
<pubDate>Sat, 11 May 2019 16:30:26 +0000</pubDate>
<dc:creator>adamnemecek</dc:creator>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://calculuswithjulia.github.io/</dc:identifier>
</item>
<item>
<title>Why CRDT didn&amp;#039;t work out as well for collaborative editing xi-editor</title>
<link>https://github.com/xi-editor/xi-editor/issues/1187#issuecomment-491473599</link>
<guid isPermaLink="true" >https://github.com/xi-editor/xi-editor/issues/1187#issuecomment-491473599</guid>
<description>
&lt;p&gt;This reply is going to be scoped to the CRDT only. I have been meaning to write a larger retrospective of xi-editor; consider this the CRDT portion of that.&lt;/p&gt;
&lt;p&gt;I took on investigation of OT/CRDT with the hope that there was a &quot;right answer&quot; to collaborative editing, only needing to be discovered, and that one approach could unify a number of asynchrony-related issues, including IME being in a different process (actually the earliest motivation, as Android has serious asynchrony correctness problems around this), syntax highlighting being potentially slower than typing, and the effect where annotations from Language Server style modules being applied to incorrect regions in the face of concurrent editing, not to mention collaborative editing itself.&lt;/p&gt;
&lt;p&gt;I also hoped that a collaborative editing engine might be implemented, possibly with a tricky implementation, but so that the complexity could be encapsulated, and clients of this engine wouldn't have to worry about it.&lt;/p&gt;
&lt;p&gt;In hindsight, I believe these were reasonable assumptions, but I believe turned out to be wrong. I'll go into them in detail.&lt;/p&gt;
&lt;h2&gt;There is a &quot;right answer&quot; to collaborative editing&lt;/h2&gt;
&lt;p&gt;Here I was especially hopeful that CRDT would turn out to be that &quot;right answer,&quot; because it is on a sound mathematical footing (monotonic semi-lattices). Those mathematical structures might sound exotic to many, but are comforting and familiar to me (I had read and loved Dijkstra's &lt;a href=&quot;https://www.springer.com/us/book/9781461279242&quot; rel=&quot;nofollow&quot;&gt;Predicate Calculus and Program Semantics&lt;/a&gt; when it came out, so it would have been especially rewarding to see a new application of lattices).&lt;/p&gt;
&lt;p&gt;Indeed, the literature of CRDT does specify a &lt;em&gt;mathematically&lt;/em&gt; correct answer (see &lt;a href=&quot;https://www.cs.tau.ac.il/~mad/publications/podc2016-collabedit.pdf&quot; rel=&quot;nofollow&quot;&gt;Specification and Complexity of Collaborative Text Editing&lt;/a&gt; for a careful exposition of the specification as well as a result that it requires some form of tombstone to implement correctly). But this does not always line up with what humans would find the most faithful rendering of intent. Take for example, a document initially &quot;A B C&quot;, with one user deciding to change &quot;B&quot; to &quot;D&quot;, and the other user deciding that sentence needs rewriting, with &quot;E F G&quot; as the result. Clearly either &quot;A D C&quot; or &quot;E F G&quot; is a reasonable result, but a CRDT essentially demands that the result be either &quot;DE F G&quot; or &quot;E F GD&quot;, the tie resolved through timestamps or some similar mechanism.&lt;/p&gt;
&lt;p&gt;Different use cases for asynchronous editing have different intent:&lt;/p&gt;
&lt;ul readability=&quot;15.645793801392&quot;&gt;&lt;li readability=&quot;3&quot;&gt;
&lt;p&gt;In actual collaborative editing, you probably want to preserve the inserts, the CRDT is not unreasonable, at least you can likely get to a good state just by deleting stuff.&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;1.9632352941176&quot;&gt;
&lt;p&gt;IME is a complex beast in and of itself (as &lt;a class=&quot;user-mention&quot; data-hovercard-type=&quot;user&quot; data-hovercard-url=&quot;/hovercards?user_id=1976330&quot; data-octo-click=&quot;hovercard-link-click&quot; data-octo-dimensions=&quot;link_type:self&quot; href=&quot;https://github.com/lord&quot;&gt;@lord&lt;/a&gt; can attest from our work on this in Fuchsia). Suffice it to say that there is an impedance mismatch between platform IME protocols and a CRDT, and the fact that xi still has a somewhat hacky approach to IME makes my point.&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;4&quot;&gt;
&lt;p&gt;For syntax highlighting, any form of OT or CRDT is overkill; the highlighting is a stateless function of the document, so if there's a conflict, you can just toss the highlighting state and start again.&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;6.8372093023256&quot;&gt;
&lt;p&gt;For annotations from Language Server, you might not want to toss &lt;em&gt;all&lt;/em&gt; annotations in the face of concurrent editing (as this might add to latency between a result being available and presented to the user), but a simple approach can work well, no need to solve the &lt;a href=&quot;http://www.thinkbottomup.com.au/site/blog/Google_Wave_Intention_Preservation_Branching_Merging_and_TP2&quot; rel=&quot;nofollow&quot;&gt;TP2 puzzle&lt;/a&gt;. In cases that get really hairy, it is fine to discard and re-analyze, as it's unlikely that a heavily OT'ed result will be perfectly accurate in any case.&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;6.72&quot;&gt;
&lt;p&gt;One of the trickiest cases is insertion of whitespace and bracket balancing. The problem here is that, unlike the previous two cases, it's stateful. The plugin edits are direct responses to user-initiated edits. Another complicating factor is that these are not just string edits, the cursor position is affected (it's common for some whitespace to be inserted before the cursor, and say a newline after). This motivated the entire &quot;priority&quot; system, which I tried to explain in &lt;a href=&quot;https://xi-editor.io/docs/rope_science_10.html&quot; rel=&quot;nofollow&quot;&gt;Rope science part 10&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;My conclusion now is that these different cases are actually different, and a &quot;one size fits all&quot; approach does a disservice.&lt;/p&gt;
&lt;h2&gt;Encapsulating complexity&lt;/h2&gt;
&lt;p&gt;Successful software project management is mostly about taming complexity. A happy case is when you can define a module that might be complex internally, but that complexity is hidden from the rest of the system. An extreme example of this is a SAT solver - these are complex beasts, on which many academic careers have been made, but you can write a brute force one in an afternoon. Within text editing, an example I'd hold up is xi-rope. There's a lot of cool functionality (you can iterate by Unicode grapheme cluster!), excellent performance characteristics (especially worst-case, which is where ropes shine), but isn't significantly harder to use for editing tasks than strings.&lt;/p&gt;
&lt;p&gt;Sadly, contrary to my hopes, CRDT's do not have this property. By now we have lots of examples where trying to design features around the structure imposed by CRDT turned out to be a lot more complicated than it would be in a more synchronous world - we saw the auto-indent stuff above, difficulty getting the selection right in transpose (which required us to invent a new &quot;drift&quot; mechanic), interactions between &lt;a href=&quot;https://github.com/xi-editor/xi-editor/issues/458&quot; data-hovercard-type=&quot;issue&quot; data-hovercard-url=&quot;/xi-editor/xi-editor/issues/458/hovercard&quot;&gt;selection and undo&lt;/a&gt;, and, my personal most regretted, &lt;a href=&quot;https://github.com/xi-editor/xi-editor/pull/230&quot; data-hovercard-type=&quot;pull_request&quot; data-hovercard-url=&quot;/xi-editor/xi-editor/pull/230/hovercard&quot;&gt;soft spans&lt;/a&gt;, where we had a promising prototype, but it ultimately was abandoned because of impedance mismatch with the CRDT model.&lt;/p&gt;
&lt;p&gt;In &lt;em&gt;all&lt;/em&gt; of these cases, I believe the complexity exported by the CRDT is responsible, and we'd have solutions in hand if it weren't for that.&lt;/p&gt;
&lt;h2&gt;Actual collaborative editing is a lot harder&lt;/h2&gt;
&lt;p&gt;For a while, xi had difficulty making up its mind whether it was actually a collaborative editor or not. Tristan's intern project got us to a tech demo of collaborative editing on Fuchsia (it was very heartening to see!), but we always knew that building a real collaborative editor was a major increase in scope. At the back of my mind, I hoped that a solid CRDT engine would evolve into something that would relatively easily support collaborative editing.&lt;/p&gt;
&lt;p&gt;In retrospect, this was a pretty bad case of YAGNI. It would have been better to either commit to doing collaborative editing, and marshal the resources to make that happen, or to have it out of scope and reduce the complexity.&lt;/p&gt;
&lt;h2&gt;CRDT is a tradeoff&lt;/h2&gt;
&lt;p&gt;I still believe you &lt;em&gt;could&lt;/em&gt; build a collaborative editor on the basis of the original xi-editor roadmap, CRDT and all, and that would have some very desirable properties. This promise is one reason it's taken me so long to get to my current thinking.&lt;/p&gt;
&lt;p&gt;Aside from the mathematical foundation, the main thing CRDT buys you is the ability to propagate edits through a mesh-like network, exploiting local connections, as opposed to requiring a central server. I think that's appealing &lt;em&gt;if&lt;/em&gt; you're actually editing in such an environment. For large scale organizations (I'm familiar with those and have had great conversations more recently with &lt;a class=&quot;user-mention&quot; data-hovercard-type=&quot;user&quot; data-hovercard-url=&quot;/hovercards?user_id=14013&quot; data-octo-click=&quot;hovercard-link-click&quot; data-octo-dimensions=&quot;link_type:self&quot; href=&quot;https://github.com/dsp&quot;&gt;@dsp&lt;/a&gt;), I think it does make sense to treat the set of analysis and review tools as a form of collaborative editing, but those are also cases where a centralized server is completely viable.&lt;/p&gt;
&lt;p&gt;As a side note, I've heard an interesting theory about why CRDT-type solutions are relatively popular in the cloud. To do OT well, you need to elect a centralized server, which is responsible for all edits to a document. I believe the word for this is &quot;server affinity,&quot; and Google implements it very well. They need to, for Jupiter-style OT (Google Docs) to work. But when you're getting cloud resources from platforms like AWS, server affinity is much more difficult to attain, so in those cases you favor an eventually-consistent, federated network, where any server can accept any edit in any order, and it'll all work out.&lt;/p&gt;
&lt;p&gt;The flip side of the tradeoff is that you have to express your application logic in CRDT-compatible form. How do you represent the merge rules for soft spans as a monotonic semi-lattice? I bet it's possible (I actually love those kinds of puzzles), but it's probably a Masters level research topic, while doing it synchronously is something any of us could do. If we had a hard requirement to do collaborative editing over a mesh network, and resources to make that happen, I bet we could solve that and all the other problems. Indeed, this is pretty much what I hoped to be doing a couple years ago.&lt;/p&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;So I come to the conclusion that the CRDT is not pulling its (considerable) weight. When I think about a future evolution of xi-editor, I see a much brighter future with a simpler, largely synchronous model, that still of course has enough revision tracking to get good results with asynchronous peers like the language server. The &lt;em&gt;basic&lt;/em&gt; editing commands, including indentation and paren matching, are more simply done as synchronous operations, and I think avoiding that complexity is key.&lt;/p&gt;
&lt;p&gt;I hope this view into my thinking is useful. I might expand this into a blog post or at least link to it when I do get around to writing a retrospective.&lt;/p&gt;
</description>
<pubDate>Sat, 11 May 2019 16:19:42 +0000</pubDate>
<dc:creator>Supermighty</dc:creator>
<og:image>https://avatars0.githubusercontent.com/u/43351123?s=400&amp;v=4</og:image>
<og:type>object</og:type>
<og:title>Towards a text editor construction kit · Issue #1187 · xi-editor/xi-editor</og:title>
<og:url>https://github.com/xi-editor/xi-editor/issues/1187</og:url>
<og:description>Towards a text editor construction kit One of my goals in writing the rust playground for macOS was to see how much work would be involved in reusing components from the xi-editor core library (xi-...</og:description>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://github.com/xi-editor/xi-editor/issues/1187</dc:identifier>
</item>
<item>
<title>Show HN: Python Machine Learning – A Crash Course</title>
<link>https://github.com/machinelearningmindset/machine-learning-course</link>
<guid isPermaLink="true" >https://github.com/machinelearningmindset/machine-learning-course</guid>
<description>&lt;div class=&quot;Box-header d-flex flex-items-center flex-justify-between px-2&quot;&gt;
&lt;h3 class=&quot;Box-title pr-3&quot;&gt;README.rst&lt;/h3&gt;
&lt;/div&gt;
&lt;div class=&quot;Box-body&quot;&gt;
&lt;article class=&quot;markdown-body entry-content p-5&quot; itemprop=&quot;text&quot;&gt;&lt;div&gt;&lt;a href=&quot;https://machinelearningmindset.com/blog/'&quot; rel=&quot;nofollow&quot;&gt;&lt;img alt=&quot;_img/teaser.gif&quot; src=&quot;https://github.com/machinelearningmindset/machine-learning-course/raw/master/_img/teaser.gif&quot;/&gt;&lt;/a&gt;&lt;/div&gt;
&lt;div&gt;&lt;a href=&quot;https://machinelearningmindset.com/subscription/&quot; rel=&quot;nofollow&quot;&gt;&lt;img alt=&quot;_img/subscribe.png&quot; src=&quot;https://github.com/machinelearningmindset/machine-learning-course/raw/master/_img/subscribe.png&quot;/&gt;&lt;/a&gt;&lt;/div&gt;

&lt;h2&gt;A Machine Learning Course with Python&lt;/h2&gt;
&lt;a href=&quot;https://github.com/pyairesearch/machine-learning-for-everybody/pulls&quot;&gt;&lt;img alt=&quot;https://img.shields.io/badge/contributions-welcome-brightgreen.svg?style=flat&quot; src=&quot;https://camo.githubusercontent.com/926d8ca67df15de5bd1abac234c0603d94f66c00/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f636f6e747269627574696f6e732d77656c636f6d652d627269676874677265656e2e7376673f7374796c653d666c6174&quot; data-canonical-src=&quot;https://img.shields.io/badge/contributions-welcome-brightgreen.svg?style=flat&quot;/&gt;&lt;/a&gt; &lt;a href=&quot;https://github.com/ellerbrock/open-source-badge/&quot;&gt;&lt;img alt=&quot;https://badges.frapsoft.com/os/v2/open-source.png?v=103&quot; src=&quot;https://camo.githubusercontent.com/4fbc32cb2d4084799ae1d2a27995f5cc1fd17b7f/68747470733a2f2f6261646765732e66726170736f66742e636f6d2f6f732f76322f6f70656e2d736f757263652e706e673f763d313033&quot; data-canonical-src=&quot;https://badges.frapsoft.com/os/v2/open-source.png?v=103&quot;/&gt;&lt;/a&gt; &lt;a href=&quot;https://www.python.org/&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;https://camo.githubusercontent.com/0d52d0f4841a3d4194f8f654ab0d70b2a5dafa00/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4d616465253230776974682d507974686f6e2d3166343235662e737667&quot; data-canonical-src=&quot;https://img.shields.io/badge/Made%20with-Python-1f425f.svg&quot;/&gt;&lt;/a&gt; &lt;a href=&quot;https://github.com/machinelearningmindset/machine-learning-course/graphs/contributors&quot;&gt;&lt;img src=&quot;https://camo.githubusercontent.com/1d835148cab3ea86bf14b8670e1674591c967f8c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f636f6e7472696275746f72732f6d616368696e656c6561726e696e676d696e647365742f6d616368696e652d6c6561726e696e672d636f757273652e737667&quot; data-canonical-src=&quot;https://img.shields.io/github/contributors/machinelearningmindset/machine-learning-course.svg&quot;/&gt;&lt;/a&gt; &lt;a href=&quot;https://twitter.com/machinemindset&quot; rel=&quot;nofollow&quot;&gt;&lt;img alt=&quot;https://img.shields.io/twitter/follow/machinemindset.svg?label=Follow&amp;amp;style=social&quot; src=&quot;https://camo.githubusercontent.com/89e49bfb1506c4f2885a81de3c9ffef1ed5ac9bb/68747470733a2f2f696d672e736869656c64732e696f2f747769747465722f666f6c6c6f772f6d616368696e656d696e647365742e7376673f6c6162656c3d466f6c6c6f77267374796c653d736f6369616c&quot; data-canonical-src=&quot;https://img.shields.io/twitter/follow/machinemindset.svg?label=Follow&amp;amp;style=social&quot;/&gt;&lt;/a&gt; 
&lt;h2&gt;Table of Contents&lt;/h2&gt;


&lt;h3&gt;&lt;a href=&quot;https://github.com/machinelearningmindset/machine-learning-course#id4&quot;&gt;Introduction&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;The purpose of this project is to provide a comprehensive and yet simple course in Machine Learning using Python.&lt;/p&gt;

&lt;h3&gt;&lt;a href=&quot;https://github.com/machinelearningmindset/machine-learning-course#id5&quot;&gt;Motivation&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;Machine Learning&lt;/code&gt;, as a tool for &lt;code&gt;Artificial Intelligence&lt;/code&gt;, is one of the most widely adopted scientific fields. A considerable amount of literature has been published on Machine Learning. The purpose of this project is to provide the most important aspects of &lt;code&gt;Machine Learning&lt;/code&gt; by presenting a series of simple and yet comprehensive tutorials using &lt;code&gt;Python&lt;/code&gt;. In this project, we built our tutorials using many different well-known Machine Learning frameworks such as &lt;code&gt;Scikit-learn&lt;/code&gt;. In this project you will learn:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;What is the definition of Machine Learning?&lt;/li&gt;
&lt;li&gt;When it started and what is the trending evolution?&lt;/li&gt;
&lt;li&gt;What are the Machine Learning categories and sucategories?&lt;/li&gt;
&lt;li&gt;What are the mostly used Machine Learning algorithms and how to implement them?&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;a href=&quot;https://github.com/machinelearningmindset/machine-learning-course#id6&quot;&gt;Machine Learning&lt;/a&gt;&lt;/h3&gt;
&lt;table&gt;&lt;thead valign=&quot;bottom&quot;&gt;&lt;tr&gt;&lt;th&gt;Title&lt;/th&gt;
&lt;th&gt;Document&lt;/th&gt;
&lt;/tr&gt;&lt;/thead&gt;&lt;tbody valign=&quot;top&quot;&gt;&lt;tr&gt;&lt;td&gt;An Introduction to Machine Learning&lt;/td&gt;
&lt;td&gt;&lt;a href=&quot;https://github.com/machinelearningmindset/machine-learning-course/blob/master/docs/source/intro/intro.rst&quot;&gt;Overview&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;h4&gt;&lt;a href=&quot;https://github.com/machinelearningmindset/machine-learning-course#id7&quot;&gt;Machine Learning Basics&lt;/a&gt;&lt;/h4&gt;
&lt;div&gt;&lt;a target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot; href=&quot;https://github.com/machinelearningmindset/machine-learning-course/blob/master/_img/intro.png&quot;&gt;&lt;img alt=&quot;_img/intro.png&quot; src=&quot;https://github.com/machinelearningmindset/machine-learning-course/raw/master/_img/intro.png&quot;/&gt;&lt;/a&gt;&lt;/div&gt;

&lt;h4&gt;&lt;a href=&quot;https://github.com/machinelearningmindset/machine-learning-course#id8&quot;&gt;Supervised learning&lt;/a&gt;&lt;/h4&gt;
&lt;div&gt;&lt;a target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot; href=&quot;https://github.com/machinelearningmindset/machine-learning-course/blob/master/_img/supervised.gif&quot;&gt;&lt;img alt=&quot;_img/supervised.gif&quot; src=&quot;https://github.com/machinelearningmindset/machine-learning-course/raw/master/_img/supervised.gif&quot;/&gt;&lt;/a&gt;&lt;/div&gt;

&lt;h4&gt;&lt;a href=&quot;https://github.com/machinelearningmindset/machine-learning-course#id9&quot;&gt;Unsupervised learning&lt;/a&gt;&lt;/h4&gt;
&lt;div&gt;&lt;a target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot; href=&quot;https://github.com/machinelearningmindset/machine-learning-course/blob/master/_img/unsupervised.gif&quot;&gt;&lt;img alt=&quot;_img/unsupervised.gif&quot; src=&quot;https://github.com/machinelearningmindset/machine-learning-course/raw/master/_img/unsupervised.gif&quot;/&gt;&lt;/a&gt;&lt;/div&gt;

&lt;h4&gt;&lt;a href=&quot;https://github.com/machinelearningmindset/machine-learning-course#id10&quot;&gt;Deep Learning&lt;/a&gt;&lt;/h4&gt;
&lt;div&gt;&lt;a target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot; href=&quot;https://github.com/machinelearningmindset/machine-learning-course/blob/master/_img/deeplearning.png&quot;&gt;&lt;img alt=&quot;_img/deeplearning.png&quot; src=&quot;https://github.com/machinelearningmindset/machine-learning-course/raw/master/_img/deeplearning.png&quot;/&gt;&lt;/a&gt;&lt;/div&gt;

&lt;h3&gt;&lt;a href=&quot;https://github.com/machinelearningmindset/machine-learning-course#id11&quot;&gt;Pull Request Process&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Please consider the following criterions in order to help us in a better way:&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;The pull request is mainly expected to be a link suggestion.&lt;/li&gt;
&lt;li&gt;Please make sure your suggested resources are not obsolete or broken.&lt;/li&gt;
&lt;li&gt;Ensure any install or build dependencies are removed before the end of the layer when doing a build and creating a pull request.&lt;/li&gt;
&lt;li&gt;Add comments with details of changes to the interface, this includes new environment variables, exposed ports, useful file locations and container parameters.&lt;/li&gt;
&lt;li&gt;You may merge the Pull Request in once you have the sign-off of at least one other developer, or if you do not have permission to do that, you may request the owner to merge it for you if you believe all checks are passed.&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;&lt;a href=&quot;https://github.com/machinelearningmindset/machine-learning-course#id12&quot;&gt;Final Note&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;We are looking forward to your kind feedback. Please help us to improve this open source project and make our work better. For contribution, please create a pull request and we will investigate it promptly. Once again, we appreciate your kind feedback and support.&lt;/p&gt;

&lt;h3&gt;&lt;a href=&quot;https://github.com/machinelearningmindset/machine-learning-course#id13&quot;&gt;Developers&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Creator&lt;/strong&gt;: Machine Learning Mindset [&lt;a href=&quot;https://machinelearningmindset.com/blog/&quot; rel=&quot;nofollow&quot;&gt;Blog&lt;/a&gt;, &lt;a href=&quot;https://github.com/machinelearningmindset&quot;&gt;GitHub&lt;/a&gt;, &lt;a href=&quot;https://twitter.com/machinemindset&quot; rel=&quot;nofollow&quot;&gt;Twitter&lt;/a&gt;]&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Supervisor&lt;/strong&gt;: Amirsina Torfi [&lt;a href=&quot;https://github.com/astorfi&quot;&gt;GitHub&lt;/a&gt;, &lt;a href=&quot;https://astorfi.github.io/&quot; rel=&quot;nofollow&quot;&gt;Personal Website&lt;/a&gt;, &lt;a href=&quot;https://www.linkedin.com/in/amirsinatorfi/&quot; rel=&quot;nofollow&quot;&gt;Linkedin&lt;/a&gt; ]&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Developers&lt;/strong&gt;: Brendan Sherman*, James E Hopkins* [&lt;a href=&quot;https://www.linkedin.com/in/jhopk&quot; rel=&quot;nofollow&quot;&gt;Linkedin&lt;/a&gt;], Zac Smith [&lt;a href=&quot;https://www.linkedin.com/in/zac-smith-a7bb60185/i&quot; rel=&quot;nofollow&quot;&gt;Linkedin&lt;/a&gt;]&lt;/p&gt;
&lt;p&gt;*: equally contributed&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;
</description>
<pubDate>Sat, 11 May 2019 15:54:33 +0000</pubDate>
<dc:creator>irsina</dc:creator>
<og:image>https://avatars2.githubusercontent.com/u/43791934?s=400&amp;v=4</og:image>
<og:type>object</og:type>
<og:title>machinelearningmindset/machine-learning-course</og:title>
<og:url>https://github.com/machinelearningmindset/machine-learning-course</og:url>
<og:description>:speech_balloon: Machine Learning Course with Python - machinelearningmindset/machine-learning-course</og:description>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://github.com/machinelearningmindset/machine-learning-course</dc:identifier>
</item>
<item>
<title>Adults learn language to fluency nearly as well as children: study</title>
<link>https://medium.com/@chacon/mit-scientists-prove-adults-learn-language-to-fluency-nearly-as-well-as-children-1de888d1d45f</link>
<guid isPermaLink="true" >https://medium.com/@chacon/mit-scientists-prove-adults-learn-language-to-fluency-nearly-as-well-as-children-1de888d1d45f</guid>
<description>&lt;p name=&quot;2fbc&quot; id=&quot;2fbc&quot; class=&quot;graf graf--p graf-after--figure&quot;&gt;&lt;em class=&quot;markup--em markup--p-em&quot;&gt;Scott Chacon is CEO of the online language learning company&lt;/em&gt; &lt;a href=&quot;https://chatterbug.com&quot; data-href=&quot;https://chatterbug.com&quot; class=&quot;markup--anchor markup--p-anchor&quot; rel=&quot;nofollow noopener&quot; target=&quot;_blank&quot;&gt;&lt;em class=&quot;markup--em markup--p-em&quot;&gt;Chatterbug&lt;/em&gt;&lt;/a&gt;&lt;em class=&quot;markup--em markup--p-em&quot;&gt;.&lt;/em&gt;&lt;/p&gt;
&lt;p name=&quot;6ed0&quot; id=&quot;6ed0&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;This week a new paper was published in the journal &lt;a href=&quot;https://www.sciencedirect.com/science/article/pii/S0010027718300994&quot; data-href=&quot;https://www.sciencedirect.com/science/article/pii/S0010027718300994&quot; class=&quot;markup--anchor markup--p-anchor&quot; rel=&quot;noopener nofollow&quot; target=&quot;_blank&quot;&gt;Cognition&lt;/a&gt; titled “&lt;a href=&quot;https://www.sciencedirect.com/science/article/pii/S0010027718300994&quot; data-href=&quot;https://www.sciencedirect.com/science/article/pii/S0010027718300994&quot; class=&quot;markup--anchor markup--p-anchor&quot; rel=&quot;noopener nofollow&quot; target=&quot;_blank&quot;&gt;A Critical Period for Second Language Acquisition&lt;/a&gt;” that used a new, viral Facebook-quiz-powered method of gathering a huge linguistic dataset to provide new insights into how human beings learn language and what effect age has on that process.&lt;/p&gt;
&lt;p name=&quot;b0e5&quot; id=&quot;b0e5&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;In a nutshell, this team found that if you start learning a language before the age of 18, you have a much better likelihood of obtaining a &lt;em class=&quot;markup--em markup--p-em&quot;&gt;native-like&lt;/em&gt; mastery of the language’s grammar than if you start later. This is a much older age than has been generally assumed and is really interesting for reasons I’ll get into a bit later.&lt;/p&gt;
&lt;p name=&quot;8933&quot; id=&quot;8933&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;This data has also given us a really amazing insight into language learning in general and shows that adults of any age can obtain incredible mastery nearly as quickly as children.&lt;/p&gt;
&lt;p name=&quot;e71d&quot; id=&quot;e71d&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;Unfortunately, a number of journalists have &lt;a href=&quot;http://time.com/5261446/language-critical-period-age/&quot; data-href=&quot;http://time.com/5261446/language-critical-period-age/&quot; class=&quot;markup--anchor markup--p-anchor&quot; rel=&quot;nofollow noopener&quot; target=&quot;_blank&quot;&gt;misinterpreted&lt;/a&gt; this paper badly, resulting in a lot of articles falsely stating things as embarrassing and misleading as “&lt;a href=&quot;https://www.theguardian.com/education/shortcuts/2018/may/02/fluent-another-language-adult-impossible-try&quot; data-href=&quot;https://www.theguardian.com/education/shortcuts/2018/may/02/fluent-another-language-adult-impossible-try&quot; class=&quot;markup--anchor markup--p-anchor&quot; rel=&quot;nofollow noopener&quot; target=&quot;_blank&quot;&gt;Becoming fluent in another language as an adult might be impossible&lt;/a&gt;”, when in fact the opposite is shown. If you see an article saying that you need to start learning a language before you’re 10 to become fluent, be assured that it’s simply lazy reporting. The truth is much more interesting and encouraging.&lt;/p&gt;
&lt;p name=&quot;14ec&quot; id=&quot;14ec&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;We know this, because in an incredible move, the researchers have &lt;a href=&quot;https://osf.io/pyb8s/&quot; data-href=&quot;https://osf.io/pyb8s/&quot; class=&quot;markup--anchor markup--p-anchor&quot; rel=&quot;nofollow noopener&quot; target=&quot;_blank&quot;&gt;released the entire dataset&lt;/a&gt; they based this paper off of, letting us take a look. Let’s go through some interesting things that this amazing data shows us about learning languages and why it should motivate you to try.&lt;/p&gt;
&lt;h3 name=&quot;6aff&quot; id=&quot;6aff&quot; class=&quot;graf graf--h3 graf-after--p&quot;&gt;Many late learners become native-like&lt;/h3&gt;
&lt;p name=&quot;3cf0&quot; id=&quot;3cf0&quot; class=&quot;graf graf--p graf-after--h3&quot;&gt;Looking through the data, it’s quite clear that there is a statistical advantage to starting your learning earlier. If you compare the average score of learners who started at different ages, there is a clear advantage to having started earlier.&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;1*pJ7VIUsx1rvXHfQ6s4NsSA.png&quot; data-width=&quot;2530&quot; data-height=&quot;1144&quot; data-action=&quot;zoom&quot; data-action-value=&quot;1*pJ7VIUsx1rvXHfQ6s4NsSA.png&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/1*pJ7VIUsx1rvXHfQ6s4NsSA.png&quot;/&gt;&lt;/div&gt;
Accuracy as a function of years of experience, by age of first exposure for immersion learners (A) and non-immersion learners (B). Red: monolinguals. Orange: AoFE  20. (Image from original paper)
&lt;p name=&quot;94cd&quot; id=&quot;94cd&quot; class=&quot;graf graf--p graf-after--figure&quot;&gt;However, looking more closely at the data for the students who started learning after the age of 20, there are &lt;em class=&quot;markup--em markup--p-em&quot;&gt;a lot&lt;/em&gt; of late learners who outperformed many native English speakers.&lt;/p&gt;
&lt;p name=&quot;7380&quot; id=&quot;7380&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;First, we need to specify what “native-like” performance on this quiz is. Looking at the quiz results of the group of users who are tagged as native English speakers, we have a range of scores from 100% (which 12% of native speakers scored) down to scoring 90% for the bottom 5% of native speakers. To me, this indicates that scoring anything above a 90% on the test means you’re performing at least as well as many native speakers would.&lt;/p&gt;
&lt;p name=&quot;0a08&quot; id=&quot;0a08&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;Many articles have breathlessly stated that it’s just impossible to achieve native-like mastery if you start after the age of 10 (or 18, depending on the article), but is that true? Certainly &lt;em class=&quot;markup--em markup--p-em&quot;&gt;on average&lt;/em&gt; the later learner seems to have a rarer time getting there, but is it &lt;em class=&quot;markup--em markup--p-em&quot;&gt;impossible&lt;/em&gt;?&lt;/p&gt;
&lt;p name=&quot;0e72&quot; id=&quot;0e72&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;The data tells us that it’s not. On average less likely, certainly, but there are &lt;em class=&quot;markup--em markup--p-em&quot;&gt;thousands&lt;/em&gt; of people who took this quiz, got a score in the range that a native speaker would, and started learning the language after the age of 20.&lt;/p&gt;
&lt;blockquote name=&quot;c1aa&quot; id=&quot;c1aa&quot; class=&quot;graf graf--blockquote graf-after--p&quot; readability=&quot;5&quot;&gt;
&lt;p&gt;&lt;strong class=&quot;markup--strong markup--blockquote-strong&quot;&gt;Thousands of adults who started learning after 20 years old scored in a native-level range&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p name=&quot;0468&quot; id=&quot;0468&quot; class=&quot;graf graf--p graf-after--blockquote&quot;&gt;Instead of looking at the median of this late-learning group, let’s just look at the top quartile of the speakers who started learning after the age of 20. We can graph that adjusted by how many years since they started studying the language.&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;1*LNOS7St346gdYSHF-9kIFg.png&quot; data-width=&quot;1982&quot; data-height=&quot;1244&quot; data-action=&quot;zoom&quot; data-action-value=&quot;1*LNOS7St346gdYSHF-9kIFg.png&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/1*LNOS7St346gdYSHF-9kIFg.png&quot;/&gt;&lt;/div&gt;
The top quartile of results of learners who started after the age of 20, by number of years of exposure, showing that at around 8–10 years of exposure, many learners who started well into adulthood do just as well as many native speakers. All results above the 0.9 line are in the native results range.
&lt;p name=&quot;9d69&quot; id=&quot;9d69&quot; class=&quot;graf graf--p graf-after--figure&quot;&gt;Here we can see that many of the later learners score easily within the range that native speakers do (above the 0.9 line). In fact, if we graph the results of the top quartile of after-20 learners with the median scores of the other groups (those who started learning before 5, before 10 and before 20 years old), it doesn’t look much different.&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;1*P-7cF1El9WnRBX2_ewi6aA.png&quot; data-width=&quot;1966&quot; data-height=&quot;1228&quot; data-action=&quot;zoom&quot; data-action-value=&quot;1*P-7cF1El9WnRBX2_ewi6aA.png&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/1*P-7cF1El9WnRBX2_ewi6aA.png&quot;/&gt;&lt;/div&gt;
Comparing the performance of the top quartile of over-20 learners with students who started learning before 5 (red), before 10 (yellow) and before 20 (green)
&lt;p name=&quot;d77d&quot; id=&quot;d77d&quot; class=&quot;graf graf--p graf-after--figure&quot;&gt;Given the same amount of time, &lt;em class=&quot;markup--em markup--p-em&quot;&gt;the top quarter of learners from the over-20 group&lt;/em&gt; &lt;strong class=&quot;markup--strong markup--p-strong&quot;&gt;&lt;em class=&quot;markup--em markup--p-em&quot;&gt;do just as well&lt;/em&gt;&lt;/strong&gt; &lt;em class=&quot;markup--em markup--p-em&quot;&gt;as the average of those who started before 10&lt;/em&gt;.&lt;/p&gt;
&lt;p name=&quot;203d&quot; id=&quot;203d&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;(After about 20 years of learning exposure, the over-20 group line gets pretty wobbly, since we have less and less data to work with — starting at 20 and having 20 years of exposure makes the youngest group there at least 40 years old).&lt;/p&gt;
&lt;h3 name=&quot;8fae&quot; id=&quot;8fae&quot; class=&quot;graf graf--h3 graf-after--p&quot;&gt;Comparing apples to apples&lt;/h3&gt;
&lt;p name=&quot;7ddc&quot; id=&quot;7ddc&quot; class=&quot;graf graf--p graf-after--h3&quot;&gt;But why would we do this? Shouldn’t we compare the medians of all of the groups, like the very first graph? Shouldn’t we compare apples to apples — it’s not really fair to compare the median of one group with the best of another, right?&lt;/p&gt;
&lt;p name=&quot;4a38&quot; id=&quot;4a38&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;Well, the problem is that there is no way to compare apples to apples with this dataset, and the authors point this out.&lt;/p&gt;
&lt;p name=&quot;232b&quot; id=&quot;232b&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;This is because the “drop” in learning advantage happens at 17 or 18 years old according to this paper, but why is that? What happens at 18 years old? Is it that there is some incredible and magical brain-change that happens? Or is it that people’s lives fundamentally change on average — you go to college, you enter the workforce, you move out of your parents house, etc?&lt;/p&gt;
&lt;blockquote name=&quot;5cc1&quot; id=&quot;5cc1&quot; class=&quot;graf graf--blockquote graf--startsWithDoubleQuote graf-after--p&quot; readability=&quot;14&quot;&gt;
&lt;p&gt;“For instance, it remains possible that the critical period is an epiphenomenon of culture: the age we identified (17–18 years old) coincides with a number of social changes, any of which could diminish one’s ability, opportunity, or willingness to learn a new language. In many cultures, this age marks the transition to the workforce or to professional education, which may diminish opportunities to learn.” — from A Critical Period&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p name=&quot;af06&quot; id=&quot;af06&quot; class=&quot;graf graf--p graf-after--blockquote&quot;&gt;If you start “studying” a language at the age of 5, you’re not sitting down with a book and explicitly learning the language for an hour a day. You’re almost certainly in a classroom environment where that language is spoken, possibly for several hours per day. If you start learning a language after you’re 20 years old, you almost certainly cannot be in a classroom for several hours per day.&lt;/p&gt;
&lt;p name=&quot;0a61&quot; id=&quot;0a61&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;This brings up a big problem with the interpretation of this data. It gives us a lot of information, but it doesn’t give us the most important thing, which is the total amount of exposure that these students have had. I would argue that on average, your exposure per day to a language if you start after the age of 20 is going to be way lower than if you start when you’re 5.&lt;/p&gt;
&lt;p name=&quot;fe8f&quot; id=&quot;fe8f&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;If you’re in an English speaking school for 5 hours a day as a kid and your parent is studying the same language for an hour a day while you’re there and the kid learns 5 times faster than the parent, is it fair to then conclude that kids learn better than adults?&lt;/p&gt;
&lt;p name=&quot;7302&quot; id=&quot;7302&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;It’s highly possible that this learning difference by age is not due to some magic change in brain plasticity, but simply that adults don’t have as much time to be exposed as children and often hit a point where it stops being helpful to improve after a while. They become totally fluent at this slower pace and reaching native-level mastery provides little additional advantage. Maybe it’s not that it’s harder for older learners or that they’re not capable, maybe it’s just that they don’t have the same opportunity.&lt;/p&gt;
&lt;p name=&quot;e6a4&quot; id=&quot;e6a4&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;Comparing the top quartile of the post-20 group is a simple guess to isolate a cohort of language learners who may have had more opportunity for exposure. I would guess that the post-20 learners would have much less uniform types of opportunities than children, whose experiences are probably much more similar in nature. It’s certainly not perfect, but it does indicate that there is a cohort in the post-20 crowd that does very well.&lt;/p&gt;
&lt;h3 name=&quot;ee51&quot; id=&quot;ee51&quot; class=&quot;graf graf--h3 graf-after--p&quot;&gt;This quiz is incredibly hard&lt;/h3&gt;
&lt;p name=&quot;499f&quot; id=&quot;499f&quot; class=&quot;graf graf--p graf-after--h3&quot;&gt;There are a couple of other interesting things to note here. The first is how hard this quiz is. Even for the learners who started studying the language as a young child, it takes at least 7–8 years of exposure before any of the groups are consistently scoring above a 90% on this test.&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;1*1rutq4uB-XnvOz_bnbYhBA.png&quot; data-width=&quot;1070&quot; data-height=&quot;826&quot; data-action=&quot;zoom&quot; data-action-value=&quot;1*1rutq4uB-XnvOz_bnbYhBA.png&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/1*1rutq4uB-XnvOz_bnbYhBA.png&quot;/&gt;&lt;/div&gt;
Which image is &lt;strong class=&quot;markup--strong markup--figure-strong&quot;&gt;most&lt;/strong&gt; correct for this sentence?
&lt;p name=&quot;f014&quot; id=&quot;f014&quot; class=&quot;graf graf--p graf-after--figure&quot;&gt;This test is not about fluency, it’s about highly pedantic grammatical accuracy. If you got through this entire test at all, you’re probably pretty close to basic fluency.&lt;/p&gt;
&lt;p name=&quot;979c&quot; id=&quot;979c&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;If you’re thinking that this paper provides some reason why you’re not fluently speaking French after your 3 months of using some language-game app, you are wrong. Children won’t learn a language masterfully that way either.&lt;/p&gt;
&lt;blockquote name=&quot;e6fd&quot; id=&quot;e6fd&quot; class=&quot;graf graf--blockquote graf--startsWithDoubleQuote graf-after--p&quot; readability=&quot;16&quot;&gt;
&lt;p&gt;“Studies that compare children and adults exposed to comparable material in the lab or during the initial months of an immersion program show that adults perform better, not worse, than children (Huang, 2015; Krashen, Long, &amp;amp; Scarcella, 1979; Snow &amp;amp; Hoefnagel-Höhle, 1978), perhaps because they deploy conscious strategies and transfer what they know about their first language.” — from A Critical Period&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p name=&quot;517d&quot; id=&quot;517d&quot; class=&quot;graf graf--p graf-after--blockquote&quot;&gt;&lt;strong class=&quot;markup--strong markup--p-strong&quot;&gt;Adults are actually better in many ways at learning a language&lt;/strong&gt; up to a point of general fluency, but getting to where you can answer the most subtle of grammatical points with the accuracy of a native speaker takes a decade no matter how old you are when you start.&lt;/p&gt;
&lt;p name=&quot;cb3f&quot; id=&quot;cb3f&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;That so many adults who started learning a language after 20 years old (or even later) did so well on this test should be encouraging. If you want to put in the effort, it’s entirely possible to perform at a native level on an incredibly difficult test like this — &lt;em class=&quot;markup--em markup--p-em&quot;&gt;thousands&lt;/em&gt; of people did just that.&lt;/p&gt;
&lt;h3 name=&quot;ea75&quot; id=&quot;ea75&quot; class=&quot;graf graf--h3 graf-after--p&quot;&gt;It doesn’t matter what language you come from&lt;/h3&gt;
&lt;p name=&quot;46c8&quot; id=&quot;46c8&quot; class=&quot;graf graf--p graf-after--h3&quot;&gt;This paper also gives us some really interesting insights from a broad range of backgrounds. They had nearly 3/4 million people take the quiz and got demographic data from everyone.&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;1*HwAS9AxIQGb7Whtjh_qIBg.png&quot; data-width=&quot;1278&quot; data-height=&quot;1320&quot; data-action=&quot;zoom&quot; data-action-value=&quot;1*HwAS9AxIQGb7Whtjh_qIBg.png&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/1*HwAS9AxIQGb7Whtjh_qIBg.png&quot;/&gt;&lt;/div&gt;
&lt;p name=&quot;7a4f&quot; id=&quot;7a4f&quot; class=&quot;graf graf--p graf-after--figure&quot;&gt;The first thing to notice is how little data they actually were able to get from people who started after the age of 20. It’s a tiny fraction of their dataset.&lt;/p&gt;
&lt;p name=&quot;fe19&quot; id=&quot;fe19&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;The other thing is how many different languages learners came from.&lt;/p&gt;
&lt;p name=&quot;2e1c&quot; id=&quot;2e1c&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;It’s common to say “this language is hard to learn” or “that language is so easy”, but this data showed that these things may not be true. They found that there was little difference in the learning speeds or ultimate attainment of English coming from any linguistic background.&lt;/p&gt;
&lt;blockquote name=&quot;24fe&quot; id=&quot;24fe&quot; class=&quot;graf graf--blockquote graf--startsWithDoubleQuote graf-after--p&quot; readability=&quot;7&quot;&gt;
&lt;p&gt;“In fact, the differences across language groups were small (see Fig. S14) and generally not reliable.” — from A Critical Period&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;1*Fyo7I4yQGk1PevS2N5mwNQ.png&quot; data-width=&quot;1478&quot; data-height=&quot;716&quot; data-action=&quot;zoom&quot; data-action-value=&quot;1*Fyo7I4yQGk1PevS2N5mwNQ.png&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/1*Fyo7I4yQGk1PevS2N5mwNQ.png&quot;/&gt;&lt;/div&gt;
Fig S14, showing Boxplots (in red) overlayed on violin plots (white) for asymptotic immersion bilinguals overall (left) and for five language families (right) (only part B: age of first exposure 1–5)
&lt;h3 name=&quot;a1d8&quot; id=&quot;a1d8&quot; class=&quot;graf graf--h3 graf-after--figure&quot;&gt;Studying a language for a year can make you quite fluent&lt;/h3&gt;
&lt;p name=&quot;f5c8&quot; id=&quot;f5c8&quot; class=&quot;graf graf--p graf-after--h3&quot;&gt;Finally, the thing I would like everyone to take away from this is how good adults can be at language learning. It may be harder for us to get to where we could pass for a native, but that’s probably pretty obvious and not why most of us start learning a language, right? You’re not trying to be a spy.&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;1*U7gEN-fPZo0NFeMcHq8P3w.png&quot; data-width=&quot;1184&quot; data-height=&quot;818&quot; data-action=&quot;zoom&quot; data-action-value=&quot;1*U7gEN-fPZo0NFeMcHq8P3w.png&quot; src=&quot;https://cdn-images-1.medium.com/max/1200/1*U7gEN-fPZo0NFeMcHq8P3w.png&quot;/&gt;&lt;/div&gt;
Close-up of our previous graph, focusing on the results of the first few years of exposure.
&lt;p name=&quot;cfbb&quot; id=&quot;cfbb&quot; class=&quot;graf graf--p graf-after--figure&quot;&gt;Take a look at my previous graph of the various language groups. You can see that even after a year of studying, the 20+ year old start group is commonly scoring 80-85% on this incredibly difficult grammar test.&lt;/p&gt;
&lt;p name=&quot;0fb3&quot; id=&quot;0fb3&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;Sure, it takes another 10 years to get to where you might pass for a native on this test, but look at what you can do in a single year!&lt;/p&gt;
&lt;p name=&quot;6e24&quot; id=&quot;6e24&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;Don’t use poorly reported studies like this convince you not to try learning a language. The truth is that you’re almost certainly very good at it. People consistently learn new languages in a year or two from no knowledge to very capable, fluent levels and in my personal experience, much faster than children given the same amount of time.&lt;/p&gt;
&lt;p name=&quot;d9ab&quot; id=&quot;d9ab&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;That last mile, getting from fluent to native-like, is statistically more difficult, as this paper shows, but like any good 80/20 rule, the first 80% of the results takes 20% of the time.&lt;/p&gt;
&lt;blockquote name=&quot;a2fa&quot; id=&quot;a2fa&quot; class=&quot;graf graf--blockquote graf--startsWithDoubleQuote graf-after--p&quot; readability=&quot;7&quot;&gt;
&lt;p&gt;“What is remarkable about language is that we are (nearly) all extremely good at it, including adult learners.” — from A Critical Period&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p name=&quot;cf01&quot; id=&quot;cf01&quot; class=&quot;graf graf--p graf-after--blockquote graf--trailing&quot;&gt;You can become fluent in a language in a few years of work, I see it all the time. This paper further proves that even starting much later in life, it’s still possible (if not as common) to reach incredibly high levels of mastery.&lt;/p&gt;
</description>
<pubDate>Sat, 11 May 2019 15:47:18 +0000</pubDate>
<dc:creator>bluffroom</dc:creator>
<og:title>MIT Scientists prove adults learn language to fluency nearly as well as children</og:title>
<og:url>https://medium.com/@chacon/mit-scientists-prove-adults-learn-language-to-fluency-nearly-as-well-as-children-1de888d1d45f</og:url>
<og:image>https://cdn-images-1.medium.com/max/1200/1*OVTYwlItWmMK6awe6cgf4w.jpeg</og:image>
<og:description>Scott Chacon is CEO of the online language learning company Chatterbug.</og:description>
<og:type>article</og:type>
<dc:format>text/html</dc:format>
<dc:identifier>https://medium.com/@chacon/mit-scientists-prove-adults-learn-language-to-fluency-nearly-as-well-as-children-1de888d1d45f</dc:identifier>
</item>
<item>
<title>To reinvent the processor</title>
<link>https://medium.com/@veedrac/to-reinvent-the-processor-671139a4a034</link>
<guid isPermaLink="true" >https://medium.com/@veedrac/to-reinvent-the-processor-671139a4a034</guid>
<description>&lt;div class=&quot;uiScale uiScale-ui--regular uiScale-caption--regular u-flexCenter u-marginVertical24 u-fontSize15 js-postMetaLockup&quot;&gt;
&lt;div class=&quot;u-flex0&quot;&gt;&lt;a class=&quot;link u-baseColor--link avatar&quot; href=&quot;https://medium.com/@veedrac?source=post_header_lockup&quot; data-action=&quot;show-user-card&quot; data-action-source=&quot;post_header_lockup&quot; data-action-value=&quot;834168b90e67&quot; data-action-type=&quot;hover&quot; data-user-id=&quot;834168b90e67&quot; dir=&quot;auto&quot;&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/fit/c/100/100/1*gQSmKyVTWg_GC8aI3ruRTg.png&quot; class=&quot;avatar-image u-size50x50&quot; alt=&quot;Go to the profile of Veedrac&quot;/&gt;&lt;/a&gt;&lt;/div&gt;
&lt;div class=&quot;u-flex1 u-paddingLeft15 u-overflowHidden&quot;&gt;
&lt;div class=&quot;u-paddingBottom3&quot;&gt;&lt;a class=&quot;ds-link ds-link--styleSubtle ui-captionStrong u-inlineBlock link link--darken link--darker&quot; href=&quot;https://medium.com/@veedrac&quot; data-action=&quot;show-user-card&quot; data-action-value=&quot;834168b90e67&quot; data-action-type=&quot;hover&quot; data-user-id=&quot;834168b90e67&quot; dir=&quot;auto&quot;&gt;Veedrac&lt;/a&gt;&lt;span class=&quot;followState js-followState&quot; data-user-id=&quot;834168b90e67&quot;&gt;&lt;button class=&quot;button button--smallest u-noUserSelect button--withChrome u-baseColor--buttonNormal button--withHover button--unblock js-unblockButton u-marginLeft10 u-xs-hide&quot; data-action=&quot;sign-up-prompt&quot; data-sign-in-action=&quot;toggle-block-user&quot; data-requires-token=&quot;true&quot; data-redirect=&quot;https://medium.com/@veedrac/to-reinvent-the-processor-671139a4a034&quot; data-action-source=&quot;post_header_lockup&quot;&gt;&lt;span class=&quot;followState js-followState&quot; data-user-id=&quot;834168b90e67&quot;&gt;&lt;span class=&quot;button-label button-defaultState&quot;&gt;Blocked&lt;/span&gt;&lt;span class=&quot;button-label button-hoverState&quot;&gt;Unblock&lt;/span&gt;&lt;/span&gt;&lt;button class=&quot;button button--primary button--smallest button--dark u-noUserSelect button--withChrome u-accentColor--buttonDark button--follow js-followButton u-marginLeft10 u-xs-hide&quot; data-action=&quot;sign-up-prompt&quot; data-sign-in-action=&quot;toggle-subscribe-user&quot; data-requires-token=&quot;true&quot; data-redirect=&quot;https://medium.com/_/subscribe/user/834168b90e67&quot; data-action-source=&quot;post_header_lockup-834168b90e67-------------------------follow_byline&quot;&gt;&lt;span class=&quot;button-label button-defaultState js-buttonLabel&quot;&gt;Follow&lt;/span&gt;&lt;span class=&quot;button-label button-activeState&quot;&gt;Following&lt;/span&gt;&lt;/button&gt;&lt;/button&gt;&lt;/span&gt;&lt;/div&gt;
&lt;p&gt;&lt;time datetime=&quot;2019-04-01T00:31:34.001Z&quot;&gt;Mar 31&lt;/time&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p name=&quot;f8ec&quot; id=&quot;f8ec&quot; class=&quot;graf graf--p graf-after--h3&quot;&gt;&lt;em class=&quot;markup--em markup--p-em&quot;&gt;This is a very long, very dense, and very technical foray into CPU architecture. I’ve tried to make this approachable to enthusiast non-professionals, but if you don’t know roughly how CPUs work, you will struggle.&lt;/em&gt;&lt;/p&gt;
&lt;h3 name=&quot;0a80&quot; id=&quot;0a80&quot; class=&quot;graf graf--h3 graf-after--p&quot;&gt;Contents&lt;/h3&gt;
&lt;pre name=&quot;8442&quot; id=&quot;8442&quot; class=&quot;graf graf--pre graf-after--h3&quot;&gt;
&lt;strong class=&quot;markup--strong markup--pre-strong&quot;&gt;Introduction&lt;/strong&gt;
&lt;/pre&gt;
&lt;pre name=&quot;1850&quot; id=&quot;1850&quot; class=&quot;graf graf--pre graf-after--pre&quot;&gt;
&lt;strong class=&quot;markup--strong markup--pre-strong&quot;&gt;The fundamental work of an instruction&lt;br/&gt;— &lt;/strong&gt;Coarse-Grained Out-of-Order (CG-OoO)&lt;br/&gt;&lt;strong class=&quot;markup--strong markup--pre-strong&quot;&gt;—&lt;/strong&gt; The Mill
&lt;/pre&gt;
&lt;pre name=&quot;359b&quot; id=&quot;359b&quot; class=&quot;graf graf--pre graf-after--pre&quot;&gt;
&lt;strong class=&quot;markup--strong markup--pre-strong&quot;&gt;Dependencies, not order&lt;/strong&gt;&lt;br/&gt;&lt;strong class=&quot;markup--strong markup--pre-strong&quot;&gt;1.&lt;/strong&gt; False dependencies&lt;br/&gt;&lt;strong class=&quot;markup--strong markup--pre-strong&quot;&gt;2.&lt;/strong&gt; Control Flow&lt;br/&gt;&lt;strong class=&quot;markup--strong markup--pre-strong&quot;&gt;1.&lt;/strong&gt; Branch instructions impose ordering constraints ...&lt;br/&gt;&lt;strong class=&quot;markup--strong markup--pre-strong&quot;&gt;Idea:&lt;/strong&gt; Branch Predict and Branch Verify&lt;br/&gt;&lt;strong class=&quot;markup--strong markup--pre-strong&quot;&gt;2.&lt;/strong&gt; Branches outside the current context are opaque ...&lt;br/&gt;&lt;strong class=&quot;markup--strong markup--pre-strong&quot;&gt;3.&lt;/strong&gt; Variable-latency instructions
&lt;/pre&gt;
&lt;pre name=&quot;e1f6&quot; id=&quot;e1f6&quot; class=&quot;graf graf--pre graf-after--pre&quot;&gt;
&lt;strong class=&quot;markup--strong markup--pre-strong&quot;&gt;Memory&lt;/strong&gt;&lt;br/&gt;&lt;strong class=&quot;markup--strong markup--pre-strong&quot;&gt;— &lt;/strong&gt;Baseline approaches&lt;br/&gt;&lt;strong class=&quot;markup--strong markup--pre-strong&quot;&gt;— &lt;/strong&gt;Mill Computing's approach&lt;br/&gt;&lt;strong class=&quot;markup--strong markup--pre-strong&quot;&gt;Issue 1:&lt;/strong&gt; Function boundaries still prevent ...&lt;br/&gt;&lt;strong class=&quot;markup--strong markup--pre-strong&quot;&gt;Issue 2:&lt;/strong&gt; Loads potentially in the critical ...&lt;br/&gt;&lt;strong class=&quot;markup--strong markup--pre-strong&quot;&gt;Issue 3:&lt;/strong&gt; Converging dataflow&lt;br/&gt;&lt;strong class=&quot;markup--strong markup--pre-strong&quot;&gt;Issue 4:&lt;/strong&gt; It interacts badly with loop pipelining&lt;br/&gt;&lt;strong class=&quot;markup--strong markup--pre-strong&quot;&gt;— &lt;/strong&gt;Mill Computing's approach, cont.&lt;br/&gt;&lt;strong class=&quot;markup--strong markup--pre-strong&quot;&gt;— &lt;/strong&gt;Ideas for a better load&lt;br/&gt;&lt;strong class=&quot;markup--strong markup--pre-strong&quot;&gt;Idea 1:&lt;/strong&gt; Prodigy-Mill hybrid approach&lt;br/&gt;&lt;strong class=&quot;markup--strong markup--pre-strong&quot;&gt;Idea 2:&lt;/strong&gt; Restricted Asynchronous Dataflow&lt;br/&gt;&lt;strong class=&quot;markup--strong markup--pre-strong&quot;&gt;Idea 3:&lt;/strong&gt; Source-agnostic argument pickups&lt;br/&gt;&lt;strong class=&quot;markup--strong markup--pre-strong&quot;&gt;Idea 4:&lt;/strong&gt; Standard prefetch&lt;br/&gt;&lt;strong class=&quot;markup--strong markup--pre-strong&quot;&gt;— &lt;/strong&gt;Security
&lt;/pre&gt;
&lt;pre name=&quot;9e9a&quot; id=&quot;9e9a&quot; class=&quot;graf graf--pre graf-after--pre&quot;&gt;
&lt;strong class=&quot;markup--strong markup--pre-strong&quot;&gt;Concluding Remarks&lt;/strong&gt;
&lt;/pre&gt;
&lt;h3 name=&quot;03f5&quot; id=&quot;03f5&quot; class=&quot;graf graf--h3 graf-after--pre&quot;&gt;Introduction&lt;/h3&gt;
&lt;p name=&quot;98ec&quot; id=&quot;98ec&quot; class=&quot;graf graf--p graf-after--h3&quot;&gt;I’m tired of the dominance of the out-of-order processor. They are large and wasteful, the ever-popular x86 is especially poor, and they are hard to understand. Their voodoo would be more appreciated if they pushed better at the limits of computation, but it’s obvious that the problems people solve have a latent inaccessible parallelism far in excess of what an out-of-order core can extract. The future of computing should surely not rest on terawatts of power burnt to pretend a processor is simpler than it is.&lt;/p&gt;
&lt;p name=&quot;a4a3&quot; id=&quot;a4a3&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;There is some hope in the ideas of upstarts, like &lt;a href=&quot;https://millcomputing.com/&quot; data-href=&quot;https://millcomputing.com/&quot; class=&quot;markup--anchor markup--p-anchor&quot; rel=&quot;nofollow noopener&quot; target=&quot;_blank&quot;&gt;Mill Computing&lt;/a&gt; and &lt;a href=&quot;https://www.tachyum.com/&quot; data-href=&quot;https://www.tachyum.com/&quot; class=&quot;markup--anchor markup--p-anchor&quot; rel=&quot;nofollow noopener&quot; target=&quot;_blank&quot;&gt;Tachyum&lt;/a&gt;, as well as research ideas like &lt;a href=&quot;https://dl.acm.org/citation.cfm?id=3151034&quot; data-href=&quot;https://dl.acm.org/citation.cfm?id=3151034&quot; class=&quot;markup--anchor markup--p-anchor&quot; rel=&quot;nofollow noopener&quot; target=&quot;_blank&quot;&gt;CG-OoO&lt;/a&gt;. I don’t know if they will ever find success. I wouldn’t bet on it. Heck, the Mill might never even get far enough to have the opportunity to fail. Yet I find them exciting, and much of the offhand “sounds like Itanium” naysay is uninteresting.&lt;/p&gt;
&lt;p name=&quot;cf92&quot; id=&quot;cf92&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;This article focuses on architectures in proportion to how much creative, interesting work they’ve shown in public. This means much of this article comments on the Mill architecture, there is a healthy amount on CG-OoO, and the Tachyum is mentioned only in passing. There are more I could have discussed, like TRIPS (an older dataflow architecture), Denver (NVIDIA’s newish ARM architecture using binary translation) or VISC (Soft Machine’s ‘threadlet’ architecture that got killed by Intel), but I chose to look at the architectures that I consider most promising for general-purpose workloads.&lt;/p&gt;
&lt;p name=&quot;a416&quot; id=&quot;a416&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;Along with details and comments on these technologies, I have tried to supplement the article with my own untested ideas. These are formulated to get people to focus more directly on the underlying limits of the system, and anyone should feel free to take or extend those ideas if they can make something of them. Not all of my ideas are entirely unique, but I suspect some of them are new.&lt;/p&gt;
&lt;h3 name=&quot;9baf&quot; id=&quot;9baf&quot; class=&quot;graf graf--h3 graf-after--p&quot;&gt;The fundamental work of an instruction&lt;/h3&gt;
&lt;p name=&quot;9e53&quot; id=&quot;9e53&quot; class=&quot;graf graf--p graf-after--h3&quot;&gt;A typical instruction in a typical instruction set performs something like the following:&lt;/p&gt;
&lt;ul class=&quot;postList&quot;&gt;&lt;li name=&quot;7407&quot; id=&quot;7407&quot; class=&quot;graf graf--li graf-after--p&quot;&gt;Read the operands from the global register file.&lt;/li&gt;
&lt;li name=&quot;ec44&quot; id=&quot;ec44&quot; class=&quot;graf graf--li graf-after--li&quot;&gt;Perform the operation.&lt;/li&gt;
&lt;li name=&quot;4d3a&quot; id=&quot;4d3a&quot; class=&quot;graf graf--li graf-after--li&quot;&gt;Write the output to the global register file.&lt;/li&gt;
&lt;/ul&gt;&lt;p name=&quot;d1a2&quot; id=&quot;d1a2&quot; class=&quot;graf graf--p graf-after--li&quot;&gt;This looks inoffensive until you start looking at the critical path between instructions, especially with a high level of parallelism and where the operation is something cheap, like addition.&lt;/p&gt;
&lt;ul class=&quot;postList&quot;&gt;&lt;li name=&quot;5b4f&quot; id=&quot;5b4f&quot; class=&quot;graf graf--li graf-after--p&quot;&gt;Read 16 operands from the global register file simultaneously, at arbitrary locations.&lt;/li&gt;
&lt;li name=&quot;49a3&quot; id=&quot;49a3&quot; class=&quot;graf graf--li graf-after--li&quot;&gt;Perform 8 simultaneous operations.&lt;/li&gt;
&lt;li name=&quot;8c44&quot; id=&quot;8c44&quot; class=&quot;graf graf--li graf-after--li&quot;&gt;Write the 8 results to the global register file simultaneously, at arbitrary locations.&lt;/li&gt;
&lt;li name=&quot;638e&quot; id=&quot;638e&quot; class=&quot;graf graf--li graf-after--li&quot;&gt;Read 16 new operands from the global register file simultaneously, and subset of which may be any combination of the just-written results.&lt;/li&gt;
&lt;li name=&quot;5e55&quot; id=&quot;5e55&quot; class=&quot;graf graf--li graf-after--li&quot;&gt;Perform 8 simultaneous operations.&lt;/li&gt;
&lt;li name=&quot;733d&quot; id=&quot;733d&quot; class=&quot;graf graf--li graf-after--li&quot;&gt;…&lt;/li&gt;
&lt;/ul&gt;&lt;p name=&quot;601c&quot; id=&quot;601c&quot; class=&quot;graf graf--p graf-after--li&quot;&gt;It is difficult enough to figure out how to build a register file that can support this throughput on a cycle-by-cycle basis. It is another to use this as a primary method for routing data between functional units. You can only really mitigate the former issue, but the latter has a standard and inoffensive solution: &lt;a href=&quot;https://en.wikipedia.org/wiki/Operand_forwarding&quot; data-href=&quot;https://en.wikipedia.org/wiki/Operand_forwarding&quot; class=&quot;markup--anchor markup--p-anchor&quot; rel=&quot;nofollow noopener&quot; target=&quot;_blank&quot;&gt;operand forwarding&lt;/a&gt;.&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;1*GfQGVmWUWuOerJ2dQAkQsg.png&quot; data-width=&quot;1000&quot; data-height=&quot;854&quot; data-is-featured=&quot;true&quot; data-action=&quot;zoom&quot; data-action-value=&quot;1*GfQGVmWUWuOerJ2dQAkQsg.png&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/1*GfQGVmWUWuOerJ2dQAkQsg.png&quot;/&gt;&lt;/div&gt;
If the functional units need their output again at a low latency, they route through the highlighted path. Most such instructions still need to be written to the register file unless they are immediately overwritten, in case another instruction later on requires them.
&lt;p name=&quot;7067&quot; id=&quot;7067&quot; class=&quot;graf graf--p graf-after--figure&quot;&gt;This approach helps the situation, but scaling can still be a challenge. A Skylake CPU has &lt;em class=&quot;markup--em markup--p-em&quot;&gt;348 physical registers&lt;/em&gt; per core, split over two different register files. In contrast, there are 8 execution pipelines, only half of which have general ALUs, so the forwarding path is much smaller.&lt;/p&gt;
&lt;h4 name=&quot;0afa&quot; id=&quot;0afa&quot; class=&quot;graf graf--h4 graf-after--p&quot;&gt;Coarse-Grained Out-of-Order (CG-OoO)&lt;/h4&gt;
&lt;p name=&quot;ca80&quot; id=&quot;ca80&quot; class=&quot;graf graf--p graf-after--h4&quot;&gt;Modern cores have enough transistors to build these huge register files — a modern smartphone has billions — but they add latency, long wires and communication costs. The cost also scales with the increasing number of read and write ports. Even more importantly, out-of-order hardware struggles to scale because the core has to keep track of dependencies globally between a vast number of buffered instructions.&lt;/p&gt;
&lt;p name=&quot;3a4c&quot; id=&quot;3a4c&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;CG-OoO is a design intended to break this set of global dependencies whilst still allowing for long-ranged out-of-order execution. The key observation allowing this is that it seems possible to handle dependencies hierarchically, and circumvent the imperfections in the hierarchical approach — inefficient allocation of resources — by overprovisioning the execution resources.&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;1*ixC38jiCUY7Wi26Vn0jRtA.png&quot; data-width=&quot;1500&quot; data-height=&quot;577&quot; data-action=&quot;zoom&quot; data-action-value=&quot;1*ixC38jiCUY7Wi26Vn0jRtA.png&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/1*ixC38jiCUY7Wi26Vn0jRtA.png&quot;/&gt;&lt;/div&gt;
A simplified version of Fig 1. from the &lt;a href=&quot;https://dl.acm.org/citation.cfm?id=3151034&quot; data-href=&quot;https://dl.acm.org/citation.cfm?id=3151034&quot; class=&quot;markup--anchor markup--figure-anchor&quot; rel=&quot;nofollow noopener&quot; target=&quot;_blank&quot;&gt;CG-OoO paper&lt;/a&gt;. Block Windows (BW) feed instructions into execution clusters, each with a number of &lt;em class=&quot;markup--em markup--figure-em&quot;&gt;Execution Units (EU)&lt;/em&gt;. A BW contains a small, unshared Local Register File (LRF) and a subset of a shared Global Register File (GRF).
&lt;p name=&quot;a374&quot; id=&quot;a374&quot; class=&quot;graf graf--p graf-after--figure&quot;&gt;Each Block Window (BW) in the diagram above is responsible for the execution of a single basic block, a region of code without internal control flow that generally averages 5–20 instructions long. Each Block Window contains two small register files. One is a low-throughput Local Register File (LRF), which is only visible to the executing basic block, and another is a segment of a larger Global Register File (GRF), which communicates globally to all other Block Windows.&lt;/p&gt;
&lt;p name=&quot;fcec&quot; id=&quot;fcec&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;The Local Register File is used for approximately 1 in 3 operands and supports a BW with minimal amortized throughput, at only 2 reads and 2 writes per cycle. The LRF is short, but generously provisioned relative to the length of the basic block, 20 entries long for their models, avoiding hazards without renaming. According to the authors, this makes the LRF a factor of 25 cheaper per access than a 256-long heavily-multiported register file.&lt;/p&gt;
&lt;p name=&quot;883e&quot; id=&quot;883e&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;The Global Register File is shared and requires renaming — that is, the production of a mapping from the source register file indices to GRF indices such that all semanic writes are to different GRF indices, with reuse only after a later write to the source register file index is marked as non-speculative. Renaming maps writes by a Block Window to the local GRF segment, so only register reads are global.&lt;/p&gt;
&lt;p name=&quot;ac90&quot; id=&quot;ac90&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;Out-of-order execution also introduces costs for instruction issue and wakeup: In a fully out-of-order processor, any write to the LRF could make any locally-queued instruction ready to issue, and any write the the GRF could make any instruction ready to issue from any BW. Therefore, CG-OoO performs only a small amount of out-of-order execution, hierarchically. Within each BW, only from the first three or so unissued instructions are candidates for dispatch. Distant parallelism is only extracted by parallel execution of BWs.&lt;/p&gt;
&lt;p name=&quot;e66a&quot; id=&quot;e66a&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;The corresponding cost reductions are worth listing explicitly.&lt;/p&gt;
&lt;ol class=&quot;postList&quot;&gt;&lt;li name=&quot;388d&quot; id=&quot;388d&quot; class=&quot;graf graf--li graf-after--p&quot;&gt;Local instruction reordering is cheap, requiring hazard checking hardware and wakeup only over about three to five local instructions.&lt;/li&gt;
&lt;li name=&quot;6ee7&quot; id=&quot;6ee7&quot; class=&quot;graf graf--li graf-after--li&quot;&gt;Global wakeup affects only those instructions that take global registers and are in the small set of candidate operations for each BW.&lt;/li&gt;
&lt;li name=&quot;e7bd&quot; id=&quot;e7bd&quot; class=&quot;graf graf--li graf-after--li&quot;&gt;Stalled instructions are sufficiently limited in number that they can cache operands inside the issue hardware. They will then be able to read any missing operands in later cycles from the bypass, so only freshly queued instructions ever perform explicit GRF reads.&lt;/li&gt;
&lt;li name=&quot;5206&quot; id=&quot;5206&quot; class=&quot;graf graf--li graf-after--li&quot;&gt;Each GRF segment requires few ports, since GRF reads will be mostly distributed between segments.&lt;/li&gt;
&lt;/ol&gt;&lt;h4 name=&quot;126a&quot; id=&quot;126a&quot; class=&quot;graf graf--h4 graf-after--li&quot;&gt;The Mill&lt;/h4&gt;
&lt;p name=&quot;8e9d&quot; id=&quot;8e9d&quot; class=&quot;graf graf--p graf-after--h4&quot;&gt;Whereas CG-OoO allows for significant aggregate throughput at the expense of limiting local throughput to a single instruction per cycle amortized, and underperforms when local ILP is unusually large, the Mill first attempts to obliterate local throughput limits and uses secondary methods to extract nonlocal parallelism.&lt;/p&gt;
&lt;p name=&quot;5fb1&quot; id=&quot;5fb1&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;You can get most of the motivation needed to invent the Mill’s belt by noticing how much more headroom operand forwarding has than large global register files, primarily because of the comparatively miniscule number of sources. If the principle operations in a CPU should be those that can be done fast and cheap, the bypass should be the primary source of data movement and multiported register files should only be involved when necessary for long-term storage.&lt;/p&gt;
&lt;p name=&quot;1720&quot; id=&quot;1720&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;We can prioritize the use of the bypass by making operands more available from it using a small amount of buffering of the outputs at the end of each pipeline. In synergy, we can make register file operations opt-in; the Mill calls reads and writes to their register file substitute &lt;em class=&quot;markup--em markup--p-em&quot;&gt;fill&lt;/em&gt; and &lt;em class=&quot;markup--em markup--p-em&quot;&gt;spill&lt;/em&gt;.&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;1*UTVTSUwQUA4i39qerUWY6g.png&quot; data-width=&quot;1000&quot; data-height=&quot;854&quot; data-action=&quot;zoom&quot; data-action-value=&quot;1*UTVTSUwQUA4i39qerUWY6g.png&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/1*UTVTSUwQUA4i39qerUWY6g.png&quot;/&gt;&lt;/div&gt;
The Mill is different yet; their register file is replaced with a ‘scratchpad’, which is allocated per frame and accessed with byte offsets. It has a 3-cycle spill-to-fill latency, and their Silver core can handle only 4 spills and fills per cycle in total — entirely insufficient for a similar-width out-of-order, but easily in excess here.
&lt;p name=&quot;452d&quot; id=&quot;452d&quot; class=&quot;graf graf--p graf-after--figure&quot;&gt;With this it’s easy to see that this gives a greater opportunity for the hardware to scale, and detaches register pressure from overall throughput, this raises a few questions.&lt;/p&gt;
&lt;ol class=&quot;postList&quot;&gt;&lt;li name=&quot;b86a&quot; id=&quot;b86a&quot; class=&quot;graf graf--li graf-after--p&quot;&gt;How do you build a bypass that scales with the increased buffering in the system?&lt;/li&gt;
&lt;li name=&quot;71de&quot; id=&quot;71de&quot; class=&quot;graf graf--li graf-after--li&quot;&gt;How do you avoid this impacting the critical path latency, relative to the smaller, faster bypass in a standard processor?&lt;/li&gt;
&lt;li name=&quot;67eb&quot; id=&quot;67eb&quot; class=&quot;graf graf--li graf-after--li&quot;&gt;How much buffering is needed, and how do you prevent this becoming a bottleneck?&lt;/li&gt;
&lt;li name=&quot;a6c5&quot; id=&quot;a6c5&quot; class=&quot;graf graf--li graf-after--li&quot;&gt;&lt;strong class=&quot;markup--strong markup--li-strong&quot;&gt;How does the program interface with the hardware?&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;p name=&quot;4dcf&quot; id=&quot;4dcf&quot; class=&quot;graf graf--p graf-after--li&quot;&gt;The Mill has a straightforward approach to this challenge. A crossbar, a piece of hardware that connects N sources with M sinks, easily scales to the sizes involved here. Unfortunately, larger crossbars have more latency than the original bypass, slowing clock speeds. A solution to this issue is possible by building a fast path into the crossbar.&lt;/p&gt;
&lt;p name=&quot;ac1e&quot; id=&quot;ac1e&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;Latency-1 instructions immediately exit into a designated latency-1 buffer. Higher latency instructions enter corresponding higher-numbered buffers, and latency-1 instructions also migrate to higher-numbered buffers after their first cycle. These latency-1 buffers are small in number and latency-critical, and enter the crossbar fast-path. Instructions with higher latency are less impacted by increased routing delay and often don’t end cleanly on a cycle boundary, so can start their routing earlier in the cycle using the slow-path crossbar.&lt;/p&gt;
&lt;p name=&quot;666d&quot; id=&quot;666d&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;The amount of buffering needed is of major concern. Luckily, many values are completely temporary, and thus proper scheduling does not need much buffering for these at all. Further, the register file or scratchpad easily handles many longer-lived values. It would seem that few cycles of buffer may well suffice, to cover those outputs that live only just short enough that they cannot be migrated without overhead to the register file or scratchpad.&lt;/p&gt;
&lt;p name=&quot;92a9&quot; id=&quot;92a9&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;The Mill resolves some further rough-edges. Operations are migrated between buffers, and automatically spilled to a side buffer, to extend the life of operands in the case of skew pipeline usage. This automated data movement is made practical in part because these pathological cases are those with low throughput, at least in the Mill’s semantic model. When every pipeline is producing values every cycle, operands fall off the belt very fast. The only time operands last a long time on the belt (without explicitly recovered, and ignoring function calls) is when the belt is moving slowly.&lt;/p&gt;
&lt;p name=&quot;a74a&quot; id=&quot;a74a&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;The last question about the program-facing interface to the hardware is left open, and touched on in later sections.&lt;/p&gt;
&lt;h3 name=&quot;4524&quot; id=&quot;4524&quot; class=&quot;graf graf--h3 graf-after--p&quot;&gt;Dependencies, not order&lt;/h3&gt;
&lt;p name=&quot;e527&quot; id=&quot;e527&quot; class=&quot;graf graf--p graf-after--h3&quot;&gt;Exploring the CG-OoO’s approach shed some light on the trade-offs required in the construction of an out-of-order processor. However, the previous discussion intentionally did not clarify whether the Mill’s approach was for an in-order or out-of-order core. In fact, very little of the Mill’s approach seems to directly improve the cost-benefit ratio of out-of-order hardware, as it would seem all of the complex wakeup logic would still have to exist.&lt;/p&gt;
&lt;p name=&quot;1e61&quot; id=&quot;1e61&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;One might be tempted to consider a CG-OoO-Mill hybrid, if just for perspective. However, it is difficult to imagine; the belt is optimized for throughput on values with short lifetimes, so regardless of whether the core supports out-of-order execution, we must confront the challenge of extracting static parallelism directly.&lt;/p&gt;
&lt;p name=&quot;bdda&quot; id=&quot;bdda&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;Mill Computing claims that in-order computing is possible to do fast, and they give quite a few tools to get there. Before analyzing these, a causal understanding of the specific benefits out-of-order approach is warranted. The following shortlist, though brief, should be nearly exhaustive.&lt;/p&gt;
&lt;ol class=&quot;postList&quot;&gt;&lt;li name=&quot;1f64&quot; id=&quot;1f64&quot; class=&quot;graf graf--li graf-after--p&quot;&gt;Out-of-order hardware handles false dependencies, such as through condition codes and register hazards.&lt;/li&gt;
&lt;li name=&quot;0b9c&quot; id=&quot;0b9c&quot; class=&quot;graf graf--li graf-after--li&quot;&gt;Out-of-order hardware allows near-optimal scheduling around control flow.&lt;/li&gt;
&lt;li name=&quot;88db&quot; id=&quot;88db&quot; class=&quot;graf graf--li graf-after--li&quot;&gt;Out-of-order hardware efficiently schedules in the context of variable-latency instructions, particularly for memory access.&lt;/li&gt;
&lt;/ol&gt;&lt;h4 name=&quot;ccd6&quot; id=&quot;ccd6&quot; class=&quot;graf graf--h4 graf-after--li&quot;&gt;1. False dependencies&lt;/h4&gt;
&lt;p name=&quot;fa32&quot; id=&quot;fa32&quot; class=&quot;graf graf--p graf-after--h4&quot;&gt;Exceptions on integer division by zero and condition codes both create incidental dependencies: exceptions prevent the compiler from reordering instructions outside of loops and ifs, or across globally-visible memory writes, and condition codes make hardware speculation more difficult. The solution to both issues is to put these conditions into software, with division by zero resulting in a register value of some sort, and conditions being handled with booleans and comparisons. This solution is so noncontroversial that even the conservative RISC-V architecture takes this approach. Another issue in this category is exceptions on a failed memory load, but memory is better delegated to its own section due to its complexity.&lt;/p&gt;
&lt;p name=&quot;8cee&quot; id=&quot;8cee&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;Register hazards are an unavoidable consequence of using a limited number of names to refer to an unbounded number of source-level values. There are really only two issues from these hazards:&lt;/p&gt;
&lt;ol class=&quot;postList&quot;&gt;&lt;li name=&quot;ab26&quot; id=&quot;ab26&quot; class=&quot;graf graf--li graf-after--p&quot;&gt;Register hazards force storage elements to be used in program order, impeding dynamic reordering without renaming.&lt;/li&gt;
&lt;li name=&quot;0e75&quot; id=&quot;0e75&quot; class=&quot;graf graf--li graf-after--li&quot;&gt;Register name limits represent an upper bound on data that can be stored in the primary storage medium without renaming.&lt;/li&gt;
&lt;/ol&gt;&lt;p name=&quot;c362&quot; id=&quot;c362&quot; class=&quot;graf graf--p graf-after--li&quot;&gt;The Mill is affected by both issues, since the hardware state of the belt varies depending on how the current control block was reached. The Mill uses renaming to solve the first of these issues, and uses a sizeable scratchpad without renaming for the second. Rename hardware is cheap enough that this is not an unacceptable compromise, and the Mill’s rename tables are smaller than a comparable out-of-order processor’s regardless.&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;1*M16sgiZ2ZytAoMH4H2XD9w.png&quot; data-width=&quot;1200&quot; data-height=&quot;660&quot; data-action=&quot;zoom&quot; data-action-value=&quot;1*M16sgiZ2ZytAoMH4H2XD9w.png&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/1*M16sgiZ2ZytAoMH4H2XD9w.png&quot;/&gt;&lt;/div&gt;
Modified Fig 15 (b). from the &lt;a href=&quot;https://dl.acm.org/citation.cfm?id=3151034&quot; data-href=&quot;https://dl.acm.org/citation.cfm?id=3151034&quot; class=&quot;markup--anchor markup--figure-anchor&quot; rel=&quot;nofollow noopener&quot; target=&quot;_blank&quot;&gt;CG-OoO paper&lt;/a&gt;. The energy cost of rename dominates the rest of decode in their modelled processors, with the stage taking 9%, 14% and 0.2% of total execution power for each processor, respectively.
&lt;p name=&quot;7207&quot; id=&quot;7207&quot; class=&quot;graf graf--p graf-after--figure&quot;&gt;Whilst rename is an unavoidable cost of this sort of runtime-execution mismatch, it’s far from obvious that full, unstructured rename is the best we can do. In fact, it seems a variant of the CG-OoO architecture might allow for completely removing the rename stage, and the associated ad-hoc global communication.&lt;/p&gt;
&lt;p name=&quot;aba8&quot; id=&quot;aba8&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;In an out-of-order CPU, each instruction has its own view of the logical global register file — the program-visible registers at that point in the execution — , which are mapped onto some subset of the physical register file. Because a potentially unique view must exist for all of 200+ instructions in the reorder buffer, it’s important that this state is shared. This is what rename is good at.&lt;/p&gt;
&lt;p name=&quot;c23d&quot; id=&quot;c23d&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;In the CG-OoO architecture, each Block Window, not each instruction, has its own view of the logical global register file. Each Block Window writes to any given register at most once, and each basic block has a header that declares which registers will be written to. This makes sharing registers less necessary.&lt;/p&gt;
&lt;p name=&quot;dd9d&quot; id=&quot;dd9d&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;Consider if each Block Window had a complete, separate copy of the logical register file, and propagation happened on write, not read. Then each instruction could use only its local registers. Register forwarding paths could exist separately for each logical register, rather than supporting full, any-register-to-any-register communication.&lt;/p&gt;
&lt;p name=&quot;6bd1&quot; id=&quot;6bd1&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;I can think of two interesting approaches to build this. Each logical register could have an associated bus, and each BW’s copy would be instantiated to know which BW to take its result from. This would be efficient, and would only bottleneck when the same logical register is written to multiple times in the same cycle by different BWs. The second would be to allocate basic blocks to BWs in a specified order, and put each logical register on a special bus that captures the overwrite and not-ready semantics directly.&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;1*Ju5N1NW2jWane11oW05rrw.png&quot; data-width=&quot;1520&quot; data-height=&quot;1251&quot; data-action=&quot;zoom&quot; data-action-value=&quot;1*Ju5N1NW2jWane11oW05rrw.png&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/1*Ju5N1NW2jWane11oW05rrw.png&quot;/&gt;&lt;/div&gt;
Basic blocks are allocated to BWs 0, 3, 6, 1, 4, 7, 2, 5, 8, 0, …, in that order, to spread out demand for execution units. Signals can propagate through multiple BWs when the red lines are set, which happens when the corresponding BW will never write to that logical register, so the previous value is preserved. When a value is written, the orange-yellow line is enabled, and the BW’s value is pushed to the bus. The blue lines enable skip connections, which might reduce latency.
&lt;p name=&quot;14c2&quot; id=&quot;14c2&quot; class=&quot;graf graf--p graf-after--figure&quot;&gt;In this approach, each register communicates point-to-point, and there is no contention whatsoever, but the fixed order of BWs limits the overall depth of runahead execution.&lt;/p&gt;
&lt;h4 name=&quot;3dc1&quot; id=&quot;3dc1&quot; class=&quot;graf graf--h4 graf-after--p&quot;&gt;2. Control Flow&lt;/h4&gt;
&lt;p name=&quot;996b&quot; id=&quot;996b&quot; class=&quot;graf graf--p graf-after--h4&quot;&gt;The saving grace of computing has in many ways been the branch predictor. If we assume the predictor is 97% accurate, which is not unreasonable, and branch instructions (both taken and untaken) occur once every 5 instructions, the predictor accurately projects a path on average 5 / 0.03 ≈ 167 instructions into the future. The power of an out-of-order processor is that it is able to reorder instructions as it wills within as much of this window as currently processed. In an out-of-order processor, branch instructions &lt;em class=&quot;markup--em markup--p-em&quot;&gt;terminate&lt;/em&gt; dependency chains — that is, no instruction ever depends or thereby waits on a correctly-predicted branch instruction. So too with CG-OoO, where control flow terminates basic blocks, and many successive basic blocks can evaluate in parallel as their dependencies are resolved.&lt;/p&gt;
&lt;p name=&quot;a2d8&quot; id=&quot;a2d8&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;No in-order approach seems to recognize how much work out-of-order hardware puts in to making control flow a manageable issue — albeit the &lt;em class=&quot;markup--em markup--p-em&quot;&gt;effort&lt;/em&gt; it spends to get that work done is well understood. This is the first junction in this story where I will state I feel the Mill is insufficiently powerful to handle the performance demands of the competition. The frequency of control flow makes getting this right so important as to undermine any approach that fails to handle it well, which makes this discussion particularly interesting.&lt;/p&gt;
&lt;p name=&quot;b9e2&quot; id=&quot;b9e2&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;The approaches to try to extract this kind of behaviour from an in-order machine look at first blush quite limited. Branch prediction is still used to hide the instruction fetch and decode delay, and the Mill has a convincing argument that its predictor could be better than the standard approach, so that should not be a concern, and will not be detailed here. Branch delay slots, where a branch waits a number of cycles before happening, are mostly useless for correctly predicted branches, but the Mill does have a related and interesting idea with their ‘phasing’ concept (albeit they sell this as increasing performance more generally, which it does not). The idea there is equivalent in nature to a branch delay slot a fraction of a cycle long, where sink instructions in the exiting block can interleave with non-sink instructions in the entered block. This ‘tears’ the branch over several cycles, avoiding sparse ‘warm-up’ and ‘cool-down’ instructions where units go underutilized.&lt;/p&gt;
&lt;pre name=&quot;2690&quot; id=&quot;2690&quot; class=&quot;graf graf--pre graf-after--p&quot;&gt;
 standard VLIW         phasing (program)     phasing (execution)&lt;br/&gt;================================================================
&lt;/pre&gt;
&lt;pre name=&quot;3b21&quot; id=&quot;3b21&quot; class=&quot;graf graf--pre graf-after--pre&quot;&gt;
 read                  read modify write     read
&lt;/pre&gt;
&lt;pre name=&quot;c89e&quot; id=&quot;c89e&quot; class=&quot;graf graf--pre graf-after--pre&quot;&gt;
 read modify           read modify write     read modify
&lt;/pre&gt;
&lt;pre name=&quot;9031&quot; id=&quot;9031&quot; class=&quot;graf graf--pre graf-after--pre&quot;&gt;
 read modify write     read modify write     read modify write&lt;br/&gt;=====branch======     ======&lt;br/&gt;modify write     read modify write     read modify write&lt;br/&gt;===branch===&lt;br/&gt;write     read modify write     read modify write&lt;br/&gt;=====branch======                                     =======&lt;br/&gt;read                  read modify write     read modify write
&lt;/pre&gt;
&lt;pre name=&quot;39f6&quot; id=&quot;39f6&quot; class=&quot;graf graf--pre graf-after--pre&quot;&gt;
 read modify                                      modify write
&lt;/pre&gt;
&lt;pre name=&quot;4343&quot; id=&quot;4343&quot; class=&quot;graf graf--pre graf-after--pre&quot;&gt;
 read modify write                                       write
&lt;/pre&gt;
&lt;pre name=&quot;95b1&quot; id=&quot;95b1&quot; class=&quot;graf graf--pre graf-after--pre&quot;&gt;
      modify write
&lt;/pre&gt;
&lt;pre name=&quot;29ef&quot; id=&quot;29ef&quot; class=&quot;graf graf--pre graf-after--pre&quot;&gt;
             write
&lt;/pre&gt;
&lt;p name=&quot;f79c&quot; id=&quot;f79c&quot; class=&quot;graf graf--p graf-after--pre&quot;&gt;It should be noted that the delays in the VLIW example is illustrative of a typical dependency chain, but unusual instruction distributions could actually favour a standard VLIW.&lt;/p&gt;
&lt;p name=&quot;90c3&quot; id=&quot;90c3&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;The remaining 90% of the problem with control flow is of two parts.&lt;/p&gt;
&lt;p name=&quot;da32&quot; id=&quot;da32&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;&lt;strong class=&quot;markup--strong markup--p-strong&quot;&gt;2.1 Branch instructions impose ordering constraints on the program&lt;/strong&gt;&lt;/p&gt;
&lt;p name=&quot;8dbb&quot; id=&quot;8dbb&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;Let’s break down the first of these concerns with an example.&lt;/p&gt;
&lt;pre name=&quot;05e2&quot; id=&quot;05e2&quot; class=&quot;graf graf--pre graf-after--p&quot;&gt;
                           a = j + k&lt;br/&gt;b = x + y&lt;br/&gt;c = m * n&lt;br/&gt;if c &amp;gt; a&lt;br/&gt;/           \&lt;br/&gt;d = a + 7         d = a - b&lt;br/&gt;e = b + d         e = d + d
&lt;/pre&gt;
&lt;p name=&quot;e902&quot; id=&quot;e902&quot; class=&quot;graf graf--p graf-after--pre&quot;&gt;Assume purely for sake of demonstration that addition and subtraction have latency 1, whereas multiplication has latency 2, and that all machines are fully pipelined, have no resource contention, have a superscalar width of 2, and have accurate predictors. Different examples exist for cores with larger scalaraties, but are much harder to diagram.&lt;/p&gt;
&lt;p name=&quot;9317&quot; id=&quot;9317&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;A standard in-order approach struggles to extract parallelism.&lt;/p&gt;
&lt;pre name=&quot;af15&quot; id=&quot;af15&quot; class=&quot;graf graf--pre graf-after--p&quot;&gt;
       Left branch taken               Right branch taken
&lt;/pre&gt;
&lt;pre name=&quot;5303&quot; id=&quot;5303&quot; class=&quot;graf graf--pre graf-after--pre&quot;&gt;
    c = m * n     a = j + k         c = m * n     a = j + k&lt;br/&gt;b = x + y                       b = x + y&lt;br/&gt;c &amp;gt; a                           c &amp;gt; a&lt;br/&gt;d = a + 7                       d = a - b&lt;br/&gt;e = b + d                       e = d + d
&lt;/pre&gt;
&lt;p name=&quot;6a58&quot; id=&quot;6a58&quot; class=&quot;graf graf--p graf-after--pre&quot;&gt;An out-of-order processor can produce an optimal trace, assuming the compiler is smart enough to prioritize &lt;code class=&quot;markup--code markup--p-code&quot;&gt;c&lt;/code&gt; even without a directly exposed pipeline.&lt;/p&gt;
&lt;pre name=&quot;834a&quot; id=&quot;834a&quot; class=&quot;graf graf--pre graf-after--p&quot;&gt;
       Left branch taken               Right branch taken
&lt;/pre&gt;
&lt;pre name=&quot;5a39&quot; id=&quot;5a39&quot; class=&quot;graf graf--pre graf-after--pre&quot;&gt;
    c = m * n     a = j + k            c = m * n     a = j + k&lt;br/&gt;b = x + y     d = a + 7            b = x + y     d = a - b&lt;br/&gt;e = b + d       c &amp;gt; a              e = d + d       c &amp;gt; a
&lt;/pre&gt;
&lt;p name=&quot;6c23&quot; id=&quot;6c23&quot; class=&quot;graf graf--p graf-after--pre&quot;&gt;There are two common directions for mitigating this in-order disadvantage, typically part of what is termed ‘superblock scheduling’ in compilers: moving instructions to after the branch executes (‘hoist below’), or executing them early, before the branch (‘hoist above’). Host below allows you to overlap the critical path of the instructions in one basic block with the critical path of instructions in another, improving scheduling, but it adds a dependency on the branch at runtime. Hoist above removes a dependency on the branch, but requires simultaneous evaluation of both targets &lt;em class=&quot;markup--em markup--p-em&quot;&gt;even when the core has accurate predictions of the actual branch target.&lt;/em&gt;&lt;/p&gt;
&lt;pre name=&quot;eb2b&quot; id=&quot;eb2b&quot; class=&quot;graf graf--pre graf-after--p&quot;&gt;
                          Hoist below&lt;br/&gt;Left branch taken               Right branch taken
&lt;/pre&gt;
&lt;pre name=&quot;9954&quot; id=&quot;9954&quot; class=&quot;graf graf--pre graf-after--pre&quot;&gt;
    c = m * n     a = j + k         c = m * n     a = j + k&lt;br/&gt;(stall)                         (stall)&lt;br/&gt;c &amp;gt; a                           c &amp;gt; a&lt;br/&gt;b = x + y                       b = x + y&lt;br/&gt;d = a + 7                       d = a - b&lt;br/&gt;e = b + d                       e = d + d
&lt;/pre&gt;
&lt;pre name=&quot;e0cc&quot; id=&quot;e0cc&quot; class=&quot;graf graf--pre graf-after--pre&quot;&gt;
                          Hoist above&lt;br/&gt;Left branch taken               Right branch taken
&lt;/pre&gt;
&lt;pre name=&quot;5ee9&quot; id=&quot;5ee9&quot; class=&quot;graf graf--pre graf-after--pre&quot;&gt;
    a = j + k     b = x + y         a = j + k     b = x + y&lt;br/&gt;c = m * n     d = a + 7         c = m * n     d = a + 7&lt;br/&gt;D = a - b     e = d + d         D = a - b     e = d + d&lt;br/&gt;E = D + D       c &amp;gt; a           E = D + D       c &amp;gt; a
&lt;/pre&gt;
&lt;p name=&quot;fb75&quot; id=&quot;fb75&quot; class=&quot;graf graf--p graf-after--pre&quot;&gt;Hoist-above has the additional issue of requiring disambiguation between the two halves of its computation after the fact (you need to pick which values to keep), and risks exponential blowup if you are speculating more than one branch deep. The disambiguation required in hoist-above also forces following instructions to depend on both paths of the computation, independent of whether one side is much shorter and faster than the other. Compromises with less or mixed levels of hoisting suffer a similar mix of these issues.&lt;/p&gt;
&lt;p name=&quot;3c05&quot; id=&quot;3c05&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;The Mill intends to tackle this issue mostly with hoist-above, mitigating the cost of these extra computations by having very cheap (sub-cycle) disambiguation instructions and a significantly wider core than its direct competitors. This is wasteful, and still doesn’t schedule instructions efficiently.&lt;/p&gt;
&lt;p name=&quot;a9e5&quot; id=&quot;a9e5&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;&lt;strong class=&quot;markup--strong markup--p-strong&quot;&gt;&lt;em class=&quot;markup--em markup--p-em&quot;&gt;Idea: Branch Predict and Branch Verify&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p name=&quot;ed9f&quot; id=&quot;ed9f&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;&lt;em class=&quot;markup--em markup--p-em&quot;&gt;Edit: Tapabrata Ghosh (deepnotderp)&lt;/em&gt; &lt;a href=&quot;https://news.ycombinator.com/item?id=19887003&quot; data-href=&quot;https://news.ycombinator.com/item?id=19887003&quot; class=&quot;markup--anchor markup--p-anchor&quot; rel=&quot;nofollow noopener&quot; target=&quot;_blank&quot;&gt;&lt;em class=&quot;markup--em markup--p-em&quot;&gt;points to&lt;/em&gt;&lt;/a&gt; &lt;em class=&quot;markup--em markup--p-em&quot;&gt;a paper from 2015 that invented this same technique,&lt;/em&gt; &lt;a href=&quot;https://dl.acm.org/citation.cfm?id=2750400&quot; data-href=&quot;https://dl.acm.org/citation.cfm?id=2750400&quot; class=&quot;markup--anchor markup--p-anchor&quot; rel=&quot;nofollow noopener&quot; target=&quot;_blank&quot;&gt;&lt;em class=&quot;markup--em markup--p-em&quot;&gt;Branch vanguard: decomposing branch functionality into prediction and resolution instructions&lt;/em&gt;&lt;/a&gt;&lt;em class=&quot;markup--em markup--p-em&quot;&gt;.&lt;/em&gt;&lt;/p&gt;
&lt;p name=&quot;94f2&quot; id=&quot;94f2&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;This issue seems to be resolvable in part, with a few key insights. The out-of-order core is able to start executing down the right path ahead of time not because it went out of order, but because it trusted its predictor. An in-order processor can do this too! Let me introduce two very unique instructions.&lt;/p&gt;
&lt;p name=&quot;8777&quot; id=&quot;8777&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;&lt;strong class=&quot;markup--strong markup--p-strong&quot;&gt;&lt;em class=&quot;markup--em markup--p-em&quot;&gt;brp (Branch Predict):&lt;/em&gt;&lt;/strong&gt; &lt;em class=&quot;markup--em markup--p-em&quot;&gt;Takes an address to branch to, and takes the branch if and only if the branch predictor suggests to do so. This instruction does not take a predicate as an argument.&lt;/em&gt;&lt;/p&gt;
&lt;p name=&quot;c751&quot; id=&quot;c751&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;&lt;strong class=&quot;markup--strong markup--p-strong&quot;&gt;&lt;em class=&quot;markup--em markup--p-em&quot;&gt;brv (Branch Verify):&lt;/em&gt;&lt;/strong&gt; &lt;em class=&quot;markup--em markup--p-em&quot;&gt;Takes a predicate, and the tag of a&lt;/em&gt; &lt;strong class=&quot;markup--strong markup--p-strong&quot;&gt;&lt;em class=&quot;markup--em markup--p-em&quot;&gt;brp&lt;/em&gt;&lt;/strong&gt; &lt;em class=&quot;markup--em markup--p-em&quot;&gt;to update. If the predicate is false, branches to the other address in the&lt;/em&gt; &lt;strong class=&quot;markup--strong markup--p-strong&quot;&gt;&lt;em class=&quot;markup--em markup--p-em&quot;&gt;brp&lt;/em&gt;&lt;/strong&gt; &lt;em class=&quot;markup--em markup--p-em&quot;&gt;designated by a bit in the instruction; fallthrough if down the taken path, taken if down the fallthrough path. The verify instruction is never predicted to be taken. If the verify is taken, the branch predictor is updated for the corresponding Branch Predict instruction instead.&lt;/em&gt;&lt;/p&gt;
&lt;p name=&quot;b018&quot; id=&quot;b018&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;This pair may seem unintuitive at first, but it is really just a simple decomposition of parts of a branch instruction that were already there. This pair of instructions allows getting the good schedules of hoist-below without the dependencies it invokes.&lt;/p&gt;
&lt;pre name=&quot;bee6&quot; id=&quot;bee6&quot; class=&quot;graf graf--pre graf-after--p&quot;&gt;
       Left branch taken               Right branch taken
&lt;/pre&gt;
&lt;pre name=&quot;261b&quot; id=&quot;261b&quot; class=&quot;graf graf--pre graf-after--pre&quot;&gt;
              brp                             brp&lt;br/&gt;c = m * n     a = j + k         c = m * n     a = j + k&lt;br/&gt;b = x + y     d = a + 7         b = x + y     d = a - b&lt;br/&gt;e = b + d     brv c ≤ a         e = d + d     brv c &amp;gt; a
&lt;/pre&gt;
&lt;p name=&quot;6f6f&quot; id=&quot;6f6f&quot; class=&quot;graf graf--p graf-after--pre&quot;&gt;Note that &lt;code class=&quot;markup--code markup--p-code&quot;&gt;brp&lt;/code&gt; exists purely in control-flow, so like static branches it does not take a pipeline slot, and is only displayed to make the order of instructions clear.&lt;/p&gt;
&lt;p name=&quot;0774&quot; id=&quot;0774&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;There are still struggles with &lt;code class=&quot;markup--code markup--p-code&quot;&gt;brp&lt;/code&gt;, even if one agrees that it improves the situation.&lt;/p&gt;
&lt;ul class=&quot;postList&quot;&gt;&lt;li name=&quot;e1aa&quot; id=&quot;e1aa&quot; class=&quot;graf graf--li graf-after--p&quot;&gt;In the case of converging control flow, where multiple branches lead to the same block, hoist-below can fail, since incoming branches will want to hoist different instruction sequences. Fortunately, unconditional converging jumps can be tackled well by hoist-above.&lt;/li&gt;
&lt;li name=&quot;d9ee&quot; id=&quot;d9ee&quot; class=&quot;graf graf--li graf-after--li&quot;&gt;Hoist-below duplicates code down both sides of the branch. The cost of code duplication is exponential in the depth.&lt;/li&gt;
&lt;li name=&quot;7183&quot; id=&quot;7183&quot; class=&quot;graf graf--li graf-after--li&quot;&gt;The target branch must keep around the alternative branch target’s registers, in case of a failed branch verification, which is linear in depth.&lt;/li&gt;
&lt;li name=&quot;f067&quot; id=&quot;f067&quot; class=&quot;graf graf--li graf-after--li&quot;&gt;All Branch Predict targets become converging targets, including &lt;code class=&quot;markup--code markup--li-code&quot;&gt;brv&lt;/code&gt;, which requires state to be consistent regardless of which parent you come from. &lt;code class=&quot;markup--code markup--li-code&quot;&gt;brv&lt;/code&gt; could handle this with dedicated recovery code or hardware support, whichever works best.&lt;/li&gt;
&lt;li name=&quot;771e&quot; id=&quot;771e&quot; class=&quot;graf graf--li graf-after--li&quot;&gt;Store instructions cannot be performed speculatively without special hardware support, and load instructions still depend on them.&lt;/li&gt;
&lt;/ul&gt;&lt;p name=&quot;e37b&quot; id=&quot;e37b&quot; class=&quot;graf graf--p graf-after--li&quot;&gt;The exponential cost in code duplication, and significant register pressure at higher depths, means &lt;code class=&quot;markup--code markup--p-code&quot;&gt;brp&lt;/code&gt; should still be used fairly shallowly, maybe two deep. This is vastly less than an out-of-order processor can go, so &lt;code class=&quot;markup--code markup--p-code&quot;&gt;brp&lt;/code&gt; is far from a be-all solution on its own.&lt;/p&gt;
&lt;p name=&quot;0028&quot; id=&quot;0028&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;&lt;strong class=&quot;markup--strong markup--p-strong&quot;&gt;2.2 Branches outside the current context are opaque to the compiler&lt;/strong&gt;&lt;/p&gt;
&lt;p name=&quot;5df0&quot; id=&quot;5df0&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;A branch instruction to a function, or especially a branch instruction through a pointer, cannot generally have calculations hoisted across it. Static function calls can be inlined, which works pretty well when the cost of inlining is manageable, but those the compiler decides not to, as well as those that cannot be, are a wall to any standard static compiler.&lt;/p&gt;
&lt;p name=&quot;208b&quot; id=&quot;208b&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;The Mill has some very interesting approaches here, but nothing that changes the overall cost landscape. Function call overhead on the Mill is incredibly low; this is down to some fancy optimizations such as &lt;a href=&quot;https://millcomputing.com/topic/control-flow-divergence-and-the-belt/#post-3335&quot; data-href=&quot;https://millcomputing.com/topic/control-flow-divergence-and-the-belt/#post-3335&quot; class=&quot;markup--anchor markup--p-anchor&quot; rel=&quot;nofollow noopener&quot; target=&quot;_blank&quot;&gt;their single-cycle bulk rename&lt;/a&gt;. Function calls chain cheaply and don’t interrupt the local instruction schedule. Memory has some interesting but incomplete interactions, which will be covered in a memory section.&lt;/p&gt;
&lt;p name=&quot;fadc&quot; id=&quot;fadc&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;Alas, none of this changes the fact that the Mill can’t interleave the evaluation of two called functions. The only directly mitigating factors seem to be that inlining is fairly aggressive, and indirect branches are the most difficult branches for out-of-order hardware too. Perhaps the Mill’s faster calls and lower mispredict penalty will trade equal for this, but the world might not be so kind.&lt;/p&gt;
&lt;p name=&quot;c3ed&quot; id=&quot;c3ed&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;It would be nice to solve this issue, even if it is not problematic to get wrong as the section from before. I do not know how. This concludes the control flow section.&lt;/p&gt;
&lt;h4 name=&quot;6d52&quot; id=&quot;6d52&quot; class=&quot;graf graf--h4 graf-after--p&quot;&gt;3. Variable-latency instructions&lt;/h4&gt;
&lt;p name=&quot;cab2&quot; id=&quot;cab2&quot; class=&quot;graf graf--p graf-after--h4&quot;&gt;Scheduling statically for variable-latency instructions is hard. However, a convenient truth of hardware is that the efficient ways to calculate results are generally timing-agnostic with respect to their inputs. As far as I know, there are only three exceptions in a standard processor that are difficult to avoid.&lt;/p&gt;
&lt;ol class=&quot;postList&quot;&gt;&lt;li name=&quot;e34f&quot; id=&quot;e34f&quot; class=&quot;graf graf--li graf-after--p&quot;&gt;Branches, which are expensive when unpredictable. Hardware handles this by scheduling for the predicted scenario and trying to to avoid mispredicts getting too slow, which works very well.&lt;/li&gt;
&lt;li name=&quot;08ff&quot; id=&quot;08ff&quot; class=&quot;graf graf--li graf-after--li&quot;&gt;Division, except by a constant. Division instructions are rare enough not to strictly require efficient handling, with the Mill taking the unusual approach of just doing divides in software (utilizing fast hardware approximations to reduce the cost).&lt;/li&gt;
&lt;li name=&quot;5a34&quot; id=&quot;5a34&quot; class=&quot;graf graf--li graf-after--li&quot;&gt;&lt;strong class=&quot;markup--strong markup--li-strong&quot;&gt;Memory instructions. This is unavoidable and performance critical.&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;p name=&quot;a9cc&quot; id=&quot;a9cc&quot; class=&quot;graf graf--p graf-after--li&quot;&gt;Some other, less ‘standard’ instructions exist, such as transcendentals, which I will skip over.&lt;/p&gt;
&lt;p name=&quot;2bb9&quot; id=&quot;2bb9&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;Because the other two concerns are nearly non-issues, only the third point about memory will be addressed in detail. Other potential long-latency instructions can sometimes be modelled as memory accesses. Further, since memory latency interacts with the previously delegated concerns about memory, the topic deserves a section of its own, and this section will be cut short.&lt;/p&gt;
&lt;h3 name=&quot;af74&quot; id=&quot;af74&quot; class=&quot;graf graf--h3 graf-after--p&quot;&gt;Memory&lt;/h3&gt;
&lt;p name=&quot;6326&quot; id=&quot;6326&quot; class=&quot;graf graf--p graf-after--h3&quot;&gt;If the previous section gave the impression that, say, control flow is a particularly tough problem, but inventive methods can give powerful and practical tools to tackle it… good, that was the intent. In this section I want you to take that expectation and dash it against the rocks — memory is hard&lt;strong class=&quot;markup--strong markup--p-strong&quot;&gt;&lt;em class=&quot;markup--em markup--p-em&quot;&gt;.&lt;/em&gt;&lt;/strong&gt; Though there are prospective tools to tackle it, nothing truly looks like a solution, and it’s not clear that the most effective-looking solutions are even practical.&lt;/p&gt;
&lt;p name=&quot;9e54&quot; id=&quot;9e54&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;Memory is not just an issue because it is complex — but it is!—; memory is an issue because of how easily it can dwarf the concerns of the rest of the system. Whereas a branch predictor might fail once every hundred and fifty instructions, burning a dozen cycles in its wake each time it does, poorly written code may miss on cache at regular intervals, and a DRAM read takes literally hundreds of cycles. One load instruction can take more time to complete than the combined cost of 500 others, just by missing cache. A single load instruction that causes a TLB miss may take vastly longer still.&lt;/p&gt;
&lt;p name=&quot;e72d&quot; id=&quot;e72d&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;An inexhaustive overview of the issues involved will aid the following discussion on how different approaches tackle them.&lt;/p&gt;
&lt;ol class=&quot;postList&quot;&gt;&lt;li name=&quot;4b04&quot; id=&quot;4b04&quot; class=&quot;graf graf--li graf-after--p&quot;&gt;Reordering loads and stores over each other is normally only possible when they do not alias (they refer to different parts of memory). Despite this, hardware frequently wants to start loading from a known address before other addresses that might conflict with it are known.&lt;/li&gt;
&lt;li name=&quot;f56b&quot; id=&quot;f56b&quot; class=&quot;graf graf--li graf-after--li&quot;&gt;Memory accesses can fault, which normally results in an exception. This further prevents reordering of memory operations.&lt;/li&gt;
&lt;li name=&quot;e347&quot; id=&quot;e347&quot; class=&quot;graf graf--li graf-after--li&quot;&gt;Memory accesses take anywhere from a handful of cycles, commonly 3–4 for the top-level cache, to hundreds in the worst case. It is generally impossible provide guaranteed timings needed for static scheduling. Scheduling for throughput generally requires assuming latencies will be short, and scheduling for long latencies requires mixing distant instructions and can have lower throughput since it extends critical paths.&lt;/li&gt;
&lt;li name=&quot;745b&quot; id=&quot;745b&quot; class=&quot;graf graf--li graf-after--li&quot;&gt;Whether a memory instruction will miss cache is hard to predict. Compilers seldom have any nontrivial understanding of which instructions will be slow.&lt;/li&gt;
&lt;li name=&quot;82b4&quot; id=&quot;82b4&quot; class=&quot;graf graf--li graf-after--li&quot;&gt;Any given section of code might have multiple optimal schedules, depending on which instruction miss what levels of cache, if any. The prevalence of memory instructions and the small size of the top-level cache means that this risk is not safe to disregard.&lt;/li&gt;
&lt;li name=&quot;02bb&quot; id=&quot;02bb&quot; class=&quot;graf graf--li graf-after--li&quot;&gt;Hardware can handle multiple cache misses simultaneously, termed &lt;em class=&quot;markup--em markup--li-em&quot;&gt;memory level parallelism&lt;/em&gt;. The opportunity to do so goes up when significant cache misses occur, but extracting this parallelism requires the architecture to be able to execute operations correspondingly far ahead in the program during those cache misses.&lt;/li&gt;
&lt;li name=&quot;94a7&quot; id=&quot;94a7&quot; class=&quot;graf graf--li graf-after--li&quot;&gt;Speculating on memory can cause side channel attacks, the most famous being Spectre. These concerns will only be discussed at the end of this topic.&lt;/li&gt;
&lt;/ol&gt;&lt;h4 name=&quot;681b&quot; id=&quot;681b&quot; class=&quot;graf graf--h4 graf-after--li&quot;&gt;Baseline approaches&lt;/h4&gt;
&lt;p name=&quot;52f2&quot; id=&quot;52f2&quot; class=&quot;graf graf--p graf-after--h4&quot;&gt;Two historical approaches to memory are useful as a baseline to compare against. The simplest approach that significantly improves the situation for in-order processors is to delay a stall on an unfinished memory load until the result is demanded by a later instruction. A load-store queue is used to check that aliasing memory accesses do not reorder improperly relative to each other, and the core stalls to resolve conflicts if necessary. In theory, this approach can even avoid stalls on register-register moves, if proper bookkeeping is done. With appropriate scheduling by the compiler, this technique allows some load latency to be hidden. In certain circumstances a load might even be resolved after branches or function calls.&lt;/p&gt;
&lt;p name=&quot;b2a4&quot; id=&quot;b2a4&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;There are many restrictions to this approach. A load instruction cannot be issued as soon as its address is available if it has the potential to depend on a store later in the program; the hardware semantics mean that the declared program order is canonical. The instruction that first uses (‘&lt;em class=&quot;markup--em markup--p-em&quot;&gt;forces&lt;/em&gt;’) the load is scheduled statically, but the optimal position will depend on whether the load stalls. The load consumes a register as soon as it is issued, which increases the cost of delaying the consumer of the result. A memory operation also cannot be issued speculatively in the case that it might fault. This combination of concerns means the distance between the load and the forcing of the load will normally have to be small, so only small latencies can be hidden by it.&lt;/p&gt;
&lt;p name=&quot;34d4&quot; id=&quot;34d4&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;&lt;em class=&quot;markup--em markup--p-em&quot;&gt;Runahead&lt;/em&gt; is a much more heavyweight attempt to tackle the problem, with some popularity today, such as in NVIDIA’s Denver architecture. Runahead directs its effort primarily to the problem of extracting memory level parallelism during long memory stalls. After a cache miss has occurred, the processor speculatively executes down the most likely instruction path, ignoring any register values that are not known (eg. the missed load) or take too long to evaluate (eg. other loads that miss cache). When the initial cache miss has resolved, this speculative work is discarded. The intent of this speculative first pass is to start loads early, bringing their values into cache. Although the instructions executed are wasted, after resuming standard execution the core is less likely to miss cache, resulting in overall higher throughput.&lt;/p&gt;
&lt;p name=&quot;ba14&quot; id=&quot;ba14&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;Runahead is much cheaper than a traditional out-of-order approach to speculative execution, yet can still comfortably run many hundreds of instructions ahead, through arbitrary control flow and function calls. It tackles the most pathological memory issue, a cold cache, and it can synergize with other approaches. A common extension is to use address prediction, allowing early loads even when addresses depend on register values which are unknown.&lt;/p&gt;
&lt;h4 name=&quot;a9c1&quot; id=&quot;a9c1&quot; class=&quot;graf graf--h4 graf-after--p&quot;&gt;Mill Computing’s approach&lt;/h4&gt;
&lt;p name=&quot;91d0&quot; id=&quot;91d0&quot; class=&quot;graf graf--p graf-after--h4&quot;&gt;The Mill uses a variant of the first approach to loads, with several key advantages and — (though the company makes no mention of it) — several meaningful disadvantages. Keep in mind that they have also not announced any sort of runahead execution, so their approach needs to handle the entire long-tail distribution of memory stalls.&lt;/p&gt;
&lt;p name=&quot;8204&quot; id=&quot;8204&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;The specific approach the Mill has changed over time. The initially advertised approach will be discussed here, and the changes they have made will be discussed in a later security section.&lt;/p&gt;
&lt;p name=&quot;eebb&quot; id=&quot;eebb&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;Memory reads on the Mill are split into two parts, the initial &lt;code class=&quot;markup--code markup--p-code&quot;&gt;load&lt;/code&gt; that should be scheduled when the address is first generated, and the retire, which occurs either after a fixed number of cycles or on reaching a specific &lt;code class=&quot;markup--code markup--p-code&quot;&gt;pickup&lt;/code&gt; instruction that references the original &lt;code class=&quot;markup--code markup--p-code&quot;&gt;load&lt;/code&gt;. There is also a &lt;code class=&quot;markup--code markup--p-code&quot;&gt;refuse&lt;/code&gt; should the load be unwanted. In order for loads to be scheduled early, over potentially-hazarding stores, waiting loads must check (‘snoop’) outgoing stores. Loads are therefore semantically ordered by the location of their retire, rather than issue. The unit that handles the load and waits for retire is called the retire station. If a memory access faults, a specific ‘NaR’ data value is returned, and no exception is raised.&lt;/p&gt;
&lt;p name=&quot;df4b&quot; id=&quot;df4b&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;The fixed-latency &lt;code class=&quot;markup--code markup--p-code&quot;&gt;load&lt;/code&gt;, which produces its value after a fixed cycle count, is appropriate when the consumer is in a known location relative to the producer, which is common since the Mill is statically scheduled. This operation can pass through control flow, but requires all branches to accept a retiring load at the same point, and so is only really intended to be used in branchless code segments or loops. The &lt;code class=&quot;markup--code markup--p-code&quot;&gt;pickup&lt;/code&gt;-based retire is appropriate for diverging control flow, but tags are statically allocated which raises some specific challenges for code with loops or converging control flow that will be discussed later.&lt;/p&gt;
&lt;p name=&quot;ddf8&quot; id=&quot;ddf8&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;Being able to hoist the initial load over other memory operations makes it much easier to schedule early. A load is also allowed to cross a complete function call invocation, such that it retires only after the call is complete. If a called function uses up the limited retire stations (say, 16), load addresses from outer context frames are saved, and reissued upon return, such that the initial &lt;code class=&quot;markup--code markup--p-code&quot;&gt;load&lt;/code&gt; acted only as a prefetch. If the called function does not exhaust the units, the retire station remains active until its natural retire.&lt;/p&gt;
&lt;p name=&quot;6371&quot; id=&quot;6371&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;Some major issues are visible in this scheme, though some of them take some effort to uncover.&lt;/p&gt;
&lt;p name=&quot;3f51&quot; id=&quot;3f51&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;&lt;strong class=&quot;markup--strong markup--p-strong&quot;&gt;Issue 1: Function boundaries still prevent hoisting loads&lt;/strong&gt;&lt;/p&gt;
&lt;p name=&quot;edf8&quot; id=&quot;edf8&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;Consider the following code:&lt;/p&gt;
&lt;pre name=&quot;d74e&quot; id=&quot;d74e&quot; class=&quot;graf graf--pre graf-after--p&quot;&gt;
int f(int x, int *y) {&lt;br/&gt;return x + *y;&lt;br/&gt;}
&lt;/pre&gt;
&lt;pre name=&quot;4a0d&quot; id=&quot;4a0d&quot; class=&quot;graf graf--pre graf-after--pre&quot;&gt;
int g(int *x, int *y) {&lt;br/&gt;return f(*x, y);&lt;br/&gt;}
&lt;/pre&gt;
&lt;p name=&quot;a926&quot; id=&quot;a926&quot; class=&quot;graf graf--p graf-after--pre&quot;&gt;Unless &lt;code class=&quot;markup--code markup--p-code&quot;&gt;f&lt;/code&gt; is inlined, the Mill is unable to make two important transformations:&lt;/p&gt;
&lt;ol class=&quot;postList&quot;&gt;&lt;li name=&quot;82bd&quot; id=&quot;82bd&quot; class=&quot;graf graf--li graf-after--p&quot;&gt;The load of &lt;code class=&quot;markup--code markup--li-code&quot;&gt;x&lt;/code&gt; inside &lt;code class=&quot;markup--code markup--li-code&quot;&gt;g&lt;/code&gt; must be performed before entry to &lt;code class=&quot;markup--code markup--li-code&quot;&gt;f&lt;/code&gt;.&lt;/li&gt;
&lt;li name=&quot;9953&quot; id=&quot;9953&quot; class=&quot;graf graf--li graf-after--li&quot;&gt;The load of &lt;code class=&quot;markup--code markup--li-code&quot;&gt;y&lt;/code&gt; inside &lt;code class=&quot;markup--code markup--li-code&quot;&gt;f&lt;/code&gt; cannot be performed until after entry to &lt;code class=&quot;markup--code markup--li-code&quot;&gt;f&lt;/code&gt;.&lt;/li&gt;
&lt;/ol&gt;&lt;p name=&quot;44bc&quot; id=&quot;44bc&quot; class=&quot;graf graf--p graf-after--li&quot;&gt;This means that the Mill will never get memory level parallelism from this example. If &lt;code class=&quot;markup--code markup--p-code&quot;&gt;x&lt;/code&gt; and &lt;code class=&quot;markup--code markup--p-code&quot;&gt;y&lt;/code&gt; both miss the cache, you are spending twice the time waiting on memory.&lt;/p&gt;
&lt;p name=&quot;0645&quot; id=&quot;0645&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;Mill Computing has told me that they do have an approach that tackles this issue which they are not ready to disclose.&lt;/p&gt;
&lt;p name=&quot;1516&quot; id=&quot;1516&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;&lt;strong class=&quot;markup--strong markup--p-strong&quot;&gt;Issue 2: Loads potentially in the critical path cannot be delayed&lt;/strong&gt;&lt;/p&gt;
&lt;p name=&quot;e749&quot; id=&quot;e749&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;Consider the following code:&lt;/p&gt;
&lt;pre name=&quot;bdcc&quot; id=&quot;bdcc&quot; class=&quot;graf graf--pre graf-after--p&quot;&gt;
inf f(int **x, int **y) {&lt;br/&gt;return **x + **y;&lt;br/&gt;}
&lt;/pre&gt;
&lt;p name=&quot;3167&quot; id=&quot;3167&quot; class=&quot;graf graf--p graf-after--pre&quot;&gt;Each of the four load retires are allocated to a statically-determined cycle. The two retires on the left hand side must be in different cycles, and vice-versa for the right. All loads can potentially stall. For a given retire from the left hand side, only one load of the right hand side can potentially be active during that cycle. Therefore a stall in a dereference of &lt;code class=&quot;markup--code markup--p-code&quot;&gt;x&lt;/code&gt; will not always be able to cover a stall in a dereference of &lt;code class=&quot;markup--code markup--p-code&quot;&gt;y&lt;/code&gt;, regardless of how the code is compiled.&lt;/p&gt;
&lt;p name=&quot;547b&quot; id=&quot;547b&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;This may be illustrated by a specific example. Consider if the first load from each side happens simultaneously, and retire together, and then the second load from each side happens simultaneously, and retire together. If the first load on the left hand side, and the second load from the right hand side misses, those misses cannot be overlapped, despite their proximity in the source code and the availability of the address.&lt;/p&gt;
&lt;p name=&quot;e128&quot; id=&quot;e128&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;This issue has many forms, not just cascaded loads. Let &lt;code class=&quot;markup--code markup--p-code&quot;&gt;M&lt;/code&gt; represent any expensive computation.&lt;/p&gt;
&lt;pre name=&quot;0346&quot; id=&quot;0346&quot; class=&quot;graf graf--pre graf-after--p&quot;&gt;
int g(int *x, int *y) {&lt;br/&gt;return M(*x) + *M(y);&lt;br/&gt;}
&lt;/pre&gt;
&lt;p name=&quot;68cd&quot; id=&quot;68cd&quot; class=&quot;graf graf--p graf-after--pre&quot;&gt;If neither load misses, the two computations should mostly overlap. If both loads miss, the two computations should not overlap. No static schedule on the Mill can work for both cases.&lt;/p&gt;
&lt;p name=&quot;6edb&quot; id=&quot;6edb&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;&lt;strong class=&quot;markup--strong markup--p-strong&quot;&gt;Issue 3: Converging dataflow&lt;/strong&gt;&lt;/p&gt;
&lt;p name=&quot;47de&quot; id=&quot;47de&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;Consider the following code:&lt;/p&gt;
&lt;pre name=&quot;06af&quot; id=&quot;06af&quot; class=&quot;graf graf--pre graf-after--p&quot;&gt;
int f(bool cond, int *x, int y) {&lt;br/&gt;int ret;&lt;br/&gt;if (cond) {&lt;br/&gt;ret = *x;&lt;br/&gt;} else {&lt;br/&gt;ret = 0;&lt;br/&gt;}&lt;br/&gt;return M(y) + ret;&lt;br/&gt;}
&lt;/pre&gt;
&lt;p name=&quot;288d&quot; id=&quot;288d&quot; class=&quot;graf graf--p graf-after--pre&quot;&gt;The dereference of &lt;code class=&quot;markup--code markup--p-code&quot;&gt;x&lt;/code&gt; would like to be performed in parallel to the evaluation of &lt;code class=&quot;markup--code markup--p-code&quot;&gt;M(y)&lt;/code&gt;. However, only one side of the &lt;code class=&quot;markup--code markup--p-code&quot;&gt;if&lt;/code&gt; performs a load. On the Mill, unifying these branches requires forcing the load, since its value must be available after the branches converge.&lt;/p&gt;
&lt;p name=&quot;18b2&quot; id=&quot;18b2&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;&lt;strong class=&quot;markup--strong markup--p-strong&quot;&gt;Issue 4: It interacts badly with loop pipelining&lt;/strong&gt;&lt;/p&gt;
&lt;p name=&quot;1fee&quot; id=&quot;1fee&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;Loop pipelining is the structuring of a loop to operate over multiple sequential steps of a different iterations of a loop body. Each iteration of the original loop is split across multiple iterations of the pipelined loop, allowing the pipelined loop to operate with the latency of a single &lt;em class=&quot;markup--em markup--p-em&quot;&gt;stage&lt;/em&gt; of the original loop, but the same per-iteration throughput.&lt;/p&gt;
&lt;p name=&quot;5562&quot; id=&quot;5562&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;The latency-based &lt;code class=&quot;markup--code markup--p-code&quot;&gt;load&lt;/code&gt; retire is intended for this purpose. This fails in two ways. First, and particularly important, the latency of the &lt;code class=&quot;markup--code markup--p-code&quot;&gt;load&lt;/code&gt; is unable to change over the iterations of the loop. Consider the diagram, showing loop iterations phased over multiple cycles.&lt;/p&gt;
&lt;pre name=&quot;da6a&quot; id=&quot;da6a&quot; class=&quot;graf graf--pre graf-after--p&quot;&gt;
Optimal schedule when latency is low or loop has few iterations
&lt;/pre&gt;
&lt;pre name=&quot;91c2&quot; id=&quot;91c2&quot; class=&quot;graf graf--pre graf-after--pre&quot;&gt;
  read  exec  write&lt;br/&gt;read  exec  write&lt;br/&gt;read  exec  write&lt;br/&gt;read  exec  write
&lt;/pre&gt;
&lt;pre name=&quot;9caf&quot; id=&quot;9caf&quot; class=&quot;graf graf--pre graf-after--pre&quot;&gt;
Optimal schedule when latency is high or loop has many iterations
&lt;/pre&gt;
&lt;pre name=&quot;3269&quot; id=&quot;3269&quot; class=&quot;graf graf--pre graf-after--pre&quot;&gt;
  read  ... (many cycles) ...  exec  write&lt;br/&gt;read  ... (many cycles) ...  exec  write&lt;br/&gt;read  ... (many cycles) ...  exec  write&lt;br/&gt;read  ... (many cycles) ...  exec  write
&lt;/pre&gt;
&lt;p name=&quot;3b30&quot; id=&quot;3b30&quot; class=&quot;graf graf--p graf-after--pre&quot;&gt;When the Mill schedules like the first example, it is unable to cover very long misses with its loads. When the Mill schedules like the second example, if the loop ended up with few iterations and the load did not miss cache, many cycles would be wasted waiting on a that was available. An out-of-order machine starts off like the first example in early iterations, and transposes into the second example when a cache miss happens, or over many iterations of the loop if not decode limited.&lt;/p&gt;
&lt;p name=&quot;cffd&quot; id=&quot;cffd&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;Secondly, any control flow internal to the loop will still prevent a latency-based &lt;code class=&quot;markup--code markup--p-code&quot;&gt;load&lt;/code&gt;. The &lt;code class=&quot;markup--code markup--p-code&quot;&gt;pickup&lt;/code&gt; instruction will have to be used in this case, but it cannot be pipelined over more than a full iteration of the loop because the tags used to force the load are given statically.&lt;/p&gt;
&lt;h4 name=&quot;7d0d&quot; id=&quot;7d0d&quot; class=&quot;graf graf--h4 graf-after--p&quot;&gt;Mill Computing’s approach, cont.&lt;/h4&gt;
&lt;p name=&quot;8178&quot; id=&quot;8178&quot; class=&quot;graf graf--p graf-after--h4&quot;&gt;Mill Computing advertise their approach to memory accesses as roughly competitive to out-of-order hardware. This has been demonstrated to not be the case; not in the small sense like for control flow, where small modifications adjusted things back onto the right path, but in reaching, seemingly absolutist terms. As far as I can tell, the Mill’s approach to memory simply does not seem to come close to fixing memory’s performance gap between in-order and out-of-order hardware.&lt;/p&gt;
&lt;h4 name=&quot;38c7&quot; id=&quot;38c7&quot; class=&quot;graf graf--h4 graf-after--p&quot;&gt;Ideas for a better load&lt;/h4&gt;
&lt;p name=&quot;e9d1&quot; id=&quot;e9d1&quot; class=&quot;graf graf--p graf-after--h4&quot;&gt;At this point you should have a healthy fear of memory accesses. I will offer four angles to tackle this, but, as previously warned, no approach solves the problem, and some approaches may be expensive or infeasible to implement.&lt;/p&gt;
&lt;p name=&quot;2846&quot; id=&quot;2846&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;&lt;strong class=&quot;markup--strong markup--p-strong&quot;&gt;Idea 1: Prodigy-Mill hybrid approach&lt;/strong&gt;&lt;/p&gt;
&lt;p name=&quot;4da0&quot; id=&quot;4da0&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;The Tachyum Prodigy claims very impressive numbers from their simulations; a 4.0 GHz Prodigy is purportedly comparable to a 3.5 GHz Xeon. Their primary disclosed strategy for reducing long-tail memory latency is an unspecified variant of runahead. It is not clear what other techniques were used, but they report a degree of success, outperforming significantly an Itanium core on data cache stall counts.&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;1*jnc-16GZmzRL6vFm58iWqQ.png&quot; data-width=&quot;1200&quot; data-height=&quot;975&quot; data-action=&quot;zoom&quot; data-action-value=&quot;1*jnc-16GZmzRL6vFm58iWqQ.png&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/1*jnc-16GZmzRL6vFm58iWqQ.png&quot;/&gt;&lt;/div&gt;
source: &lt;a href=&quot;https://www.hotchips.org/hc30/2conf/2.09_Tachyum_Tachyum_Hotchips_2018.pdf&quot; data-href=&quot;https://www.hotchips.org/hc30/2conf/2.09_Tachyum_Tachyum_Hotchips_2018.pdf&quot; class=&quot;markup--anchor markup--figure-anchor&quot; rel=&quot;noopener nofollow&quot; target=&quot;_blank&quot;&gt;https://www.hotchips.org/hc30/2conf/2.09_Tachyum_Tachyum_Hotchips_2018.pdf&lt;/a&gt;
&lt;p name=&quot;4b07&quot; id=&quot;4b07&quot; class=&quot;graf graf--p graf-after--figure&quot;&gt;Runahead is a very widely applicable technique, and may be responsible for much of the difference between these approaches, especially as the Itanium’s load instructions were not themselves entirely naïve. Runahead should be possible to implement on a Mill-style CPU, which makes it a decent candidate for inclusion.&lt;/p&gt;
&lt;p name=&quot;0534&quot; id=&quot;0534&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;Mill Computing have told me they have considered the idea and found that unfortunately it did not expose significant opportunities. This contradicts what I’ve read in the literature, so I consider this an interesting idea to follow up on when it is easier to do so.&lt;/p&gt;
&lt;p name=&quot;a93c&quot; id=&quot;a93c&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;&lt;strong class=&quot;markup--strong markup--p-strong&quot;&gt;Idea 2: Restricted Asynchronous Dataflow&lt;/strong&gt;&lt;/p&gt;
&lt;p name=&quot;16d7&quot; id=&quot;16d7&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;One subset of concerns that seems possible to tackle independently is related to chains of multiple loads. This is very common in part to do with the commonly hierarchical structure of objects, where access to data may require chained dereferences. Dereferences like &lt;code class=&quot;markup--code markup--p-code&quot;&gt;a-&amp;gt;b-&amp;gt;c y&lt;/code&gt; or &lt;code class=&quot;markup--code markup--p-code&quot;&gt;a[i][j]&lt;/code&gt; use only a small subset of operations:&lt;/p&gt;
&lt;ul class=&quot;postList&quot;&gt;&lt;li name=&quot;f331&quot; id=&quot;f331&quot; class=&quot;graf graf--li graf-after--p&quot;&gt;Memory loads,&lt;/li&gt;
&lt;li name=&quot;1dd1&quot; id=&quot;1dd1&quot; class=&quot;graf graf--li graf-after--li&quot;&gt;Pointer addition with registers or small constants,&lt;/li&gt;
&lt;li name=&quot;3331&quot; id=&quot;3331&quot; class=&quot;graf graf--li graf-after--li&quot;&gt;Multiplication by small, often power-of-2 constants.&lt;/li&gt;
&lt;/ul&gt;&lt;p name=&quot;03cf&quot; id=&quot;03cf&quot; class=&quot;graf graf--p graf-after--li&quot;&gt;The arithmetic here is much simpler than even the most basic arithmetic pipeline. Additionally, loads always have a significant latency; 3 or 4 cycles for top-level cache is common. These make it sound feasible for this case to be handled with dedicated, overprovisioned hardware.&lt;/p&gt;
&lt;p name=&quot;1ce3&quot; id=&quot;1ce3&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;Consider if every retire station output to a specifically-allocated chain of asynchronous ALUs allowing the given set of operations, and that those ALUs were able to be prepared by the main core during the unit’s minimum load latency. Further, allow those ALUs to loop back into the load unit, buffering a chained load, and let this operation happen recursively up to a hardware-defined limit. As an optional extension to the idea, consider allowing the retire station to share any of its produced values with other unit’s ALUs. That allows operations like &lt;code class=&quot;markup--code markup--p-code&quot;&gt;a-&amp;gt;b-&amp;gt;c + a-&amp;gt;b-&amp;gt;d&lt;/code&gt; to happen fully asynchronously.&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;1*yqlHPqt35PoKkWyB_ft0lw.png&quot; data-width=&quot;1000&quot; data-height=&quot;743&quot; data-action=&quot;zoom&quot; data-action-value=&quot;1*yqlHPqt35PoKkWyB_ft0lw.png&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/1*yqlHPqt35PoKkWyB_ft0lw.png&quot;/&gt;&lt;/div&gt;
The path back to the address is for chained loads, and latency-critical. The dotted path is for communication between load units, requires some kind of crossbar, and is unlikely to be latency critical. The ALUs are asynchronous and buffer their sideloaded inputs. Buffering in the ALUs and output register is designed to handle multiply-dereferenced values.
&lt;p name=&quot;268e&quot; id=&quot;268e&quot; class=&quot;graf graf--p graf-after--figure&quot;&gt;The arithmetic capabilities of this design are naturally limited, and even with the optional inter-unit extension the communication between units is very restricted. As a design for a processor, this would be hopeless. However, it seems plausible that that this could be a realizable concept for the restricted cases given, which opens the door for more asynchronous memory-level parallelism without fully out-of-order hardware.&lt;/p&gt;
&lt;p name=&quot;ddfc&quot; id=&quot;ddfc&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;Two design decisions not discussed are how to enforce memory ordering with potentially-conflicting stores, and how the crossbar is controlled.&lt;/p&gt;
&lt;p name=&quot;e608&quot; id=&quot;e608&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;&lt;strong class=&quot;markup--strong markup--p-strong&quot;&gt;Idea 3: Source-agnostic argument pickups&lt;/strong&gt;&lt;/p&gt;
&lt;p name=&quot;76eb&quot; id=&quot;76eb&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;Likely the first thing stopping further delay of a &lt;code class=&quot;markup--code markup--p-code&quot;&gt;pickup&lt;/code&gt; instruction is its inability to handle function calls or converging control flow in the general case.&lt;/p&gt;
&lt;p name=&quot;7bdd&quot; id=&quot;7bdd&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;The first baseline approach, performing &lt;code class=&quot;markup--code markup--p-code&quot;&gt;pickup&lt;/code&gt; implicitly on first use, avoids this problem but means the only known serialization point is the initial &lt;code class=&quot;markup--code markup--p-code&quot;&gt;load&lt;/code&gt;. A simple hybrid approach is possible. A &lt;code class=&quot;markup--code markup--p-code&quot;&gt;preload&lt;/code&gt; instruction replaces the current &lt;code class=&quot;markup--code markup--p-code&quot;&gt;load&lt;/code&gt; and produces a tag that resides on the belt, referring to a retire unit in a &lt;code class=&quot;markup--code markup--p-code&quot;&gt;prefetch&lt;/code&gt; state. A &lt;code class=&quot;markup--code markup--p-code&quot;&gt;load&lt;/code&gt; instruction takes a tag to a &lt;code class=&quot;markup--code markup--p-code&quot;&gt;preload&lt;/code&gt; state retire unit and changes it into a &lt;code class=&quot;markup--code markup--p-code&quot;&gt;load&lt;/code&gt; state, which is the same as &lt;code class=&quot;markup--code markup--p-code&quot;&gt;preload&lt;/code&gt; except that the hardware guarantees order of &lt;code class=&quot;markup--code markup--p-code&quot;&gt;load&lt;/code&gt;s is conserved. A &lt;code class=&quot;markup--code markup--p-code&quot;&gt;pickup&lt;/code&gt; instruction takes &lt;em class=&quot;markup--em markup--p-em&quot;&gt;any&lt;/em&gt; belt value; if it is a value, that value is left unchanged, if it is a tag then the corresponding load is forced and the tag is replaced &lt;em class=&quot;markup--em markup--p-em&quot;&gt;in place&lt;/em&gt; with the value.&lt;/p&gt;
&lt;p name=&quot;43b7&quot; id=&quot;43b7&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;If functions must &lt;code class=&quot;markup--code markup--p-code&quot;&gt;pickup&lt;/code&gt; all of their arguments before use (with instructions to make that space-efficient), or have a way to signal to the caller which instructions will be picked up, then loads can cross function boundaries. Because the tags reside on the belt at all times, and &lt;code class=&quot;markup--code markup--p-code&quot;&gt;pickup&lt;/code&gt; is idempotent (you don’t need to know if the value requires &lt;code class=&quot;markup--code markup--p-code&quot;&gt;pickup&lt;/code&gt;), they can handle more arbitrary control flow and pipelining than the standard approach.&lt;/p&gt;
&lt;p name=&quot;3366&quot; id=&quot;3366&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;&lt;strong class=&quot;markup--strong markup--p-strong&quot;&gt;Idea 4: Standard prefetch&lt;/strong&gt;&lt;/p&gt;
&lt;p name=&quot;b11d&quot; id=&quot;b11d&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;One of the issues mentioned before was around long-latency instructions in pipelined loops. The solution here is surprisingly simple. The paper &lt;a href=&quot;https://www.cl.cam.ac.uk/~sa614/papers/Software-Prefetching-CGO2017.pdf&quot; data-href=&quot;https://www.cl.cam.ac.uk/~sa614/papers/Software-Prefetching-CGO2017.pdf&quot; class=&quot;markup--anchor markup--p-anchor&quot; rel=&quot;nofollow noopener&quot; target=&quot;_blank&quot;&gt;Software Prefetching for Indirect Memory Accesses&lt;/a&gt; shows how to use prefetch instructions for pipelinable loops. This should be considered mandatory for in-order hardware.&lt;/p&gt;
&lt;p name=&quot;648c&quot; id=&quot;648c&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;A major concern with prefetch instructions is that many prefetches are incorrect or unnecessary, wasting hardware bandwidth. For prefetches that conflict with automatic hardware prefetching, compiler heuristics should suffice. Other prefetches require more finesse. Prefetching 32 loads ahead in a loop is effective if the loop will last 32 load instructions more, but otherwise the prefetch is wasted memory bandwidth. Hardware heuristics for which prefetches are useful, including perhaps a prefetch warmup phase for loops, is an approach that would follow historic trends. Another possibility is a conditional prefetch instruction, allowing efficient suppression of prefetches that are known to go off the end of a loop.&lt;/p&gt;
&lt;h4 name=&quot;e66e&quot; id=&quot;e66e&quot; class=&quot;graf graf--h4 graf-after--p&quot;&gt;Security&lt;/h4&gt;
&lt;p name=&quot;82d8&quot; id=&quot;82d8&quot; class=&quot;graf graf--p graf-after--h4&quot;&gt;Computers are systematically vulnerable to side-channel attacks. For example, an operation may take more power with some inputs than others; therefore information about the value is learnt by looking at power usage. The most common and dangerous attacks are timing attacks. Control flow is one of the largest contributors. The largest, memory, is the topic of this section.&lt;/p&gt;
&lt;p name=&quot;1f96&quot; id=&quot;1f96&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;Whenever an address &lt;code class=&quot;markup--code markup--p-code&quot;&gt;a&lt;/code&gt; is used to access memory, the state of the cache may be changed in a way that allows side-channel attacks to discover &lt;code class=&quot;markup--code markup--p-code&quot;&gt;a&lt;/code&gt;. Therefore all values used as addresses should be considered leaked.&lt;/p&gt;
&lt;p name=&quot;2b91&quot; id=&quot;2b91&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;The typical response to this has been dismissal — &lt;em class=&quot;markup--em markup--p-em&quot;&gt;deal with it&lt;/em&gt;—because side channel attacks are incredibly difficult to mitigate or avoid, and secure keys and encryption could generally manually circumvent these issues with careful coding. Spectre is a particular instantiation of this exploit that can read arbitrary memory from a process in spite of these safeguards, which is why it is considered such a big deal.&lt;/p&gt;
&lt;p name=&quot;cbf3&quot; id=&quot;cbf3&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;A twice-indirect memory access of the form &lt;code class=&quot;markup--code markup--p-code&quot;&gt;**a&lt;/code&gt; leaks &lt;code class=&quot;markup--code markup--p-code&quot;&gt;*a&lt;/code&gt;. It is common for &lt;code class=&quot;markup--code markup--p-code&quot;&gt;a&lt;/code&gt; to be untrusted and restricted to a given range of allowed values. However, if the values to be accessed are guarded only by control flow, speculative execution may still start a load of &lt;code class=&quot;markup--code markup--p-code&quot;&gt;*a&lt;/code&gt; early, leaking data chosen by an adversary.&lt;/p&gt;
&lt;p name=&quot;aaaf&quot; id=&quot;aaaf&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;This is a major problem, invalidating almost all of the approaches mentioned so far in their naïve incarnations. This affects every out-of-order processor I know of, and the mitigations for it are largely incomplete and hacky. Since CG-OoO is just an out-of-order processor from a memory perspective, that too is vulnerable.&lt;/p&gt;
&lt;p name=&quot;7aa4&quot; id=&quot;7aa4&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;More surprisingly, the Mill’s approach is also susceptible to this. Their &lt;code class=&quot;markup--code markup--p-code&quot;&gt;load&lt;/code&gt; instructions are designed to be hoisted before control flow, and efficient compilation exposes the same side channel as seen in out-of-order processors. &lt;a href=&quot;https://millcomputing.com/blog/wp-content/uploads/2018/01/Spectre.03.pdf&quot; data-href=&quot;https://millcomputing.com/blog/wp-content/uploads/2018/01/Spectre.03.pdf&quot; class=&quot;markup--anchor markup--p-anchor&quot; rel=&quot;nofollow noopener&quot; target=&quot;_blank&quot;&gt;Mill Computing published a response to the discovery&lt;/a&gt;, claiming that “the Mill architecture is fundamentally immune to Spectre-like vulnerabilities” but instead that their vulnerability to Spectre was “a software bug in the Mill tool chain”. For the first time known to me, the conditional load instructions, &lt;code class=&quot;markup--code markup--p-code&quot;&gt;loadtr&lt;/code&gt; and &lt;code class=&quot;markup--code markup--p-code&quot;&gt;loadfl&lt;/code&gt;, are introduced, which allow for non-speculative condition checking.&lt;/p&gt;
&lt;p name=&quot;109f&quot; id=&quot;109f&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;This response is concerning. Ultimately, no manufacturer of out-of-order cores has responded to Spectre by abandoning speculation. Early mitigations did so at a heavy performance penalty; future processors will solve the hardest issues in hardware. It seems that either you solve this problem in hardware or you become uncompetitive; the Mill seems to be walking the latter path.&lt;/p&gt;
&lt;p name=&quot;3743&quot; id=&quot;3743&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;There are several approaches that hardware has which seem promising in avoiding Spectre. For instance, one can attempt to make loads delay writes to cache, allowing side-effect free speculation recovery. One can also focus specifically on the known exploitable variants, and prevent only that subset of speculation that leaks attacker-chosen data, such as by preventing the value of loads to be used speculatively, even if the instruction can be issued speculatively.&lt;/p&gt;
&lt;p name=&quot;a9b3&quot; id=&quot;a9b3&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;However, regardless of whether a mitigation exists, fast memory access is so vital to competitive performance that flushing state on context-switch would be a still be a better compromise than avoiding heavy speculation. This is an issue that must be prioritized to a major degree.&lt;/p&gt;
&lt;h3 name=&quot;201a&quot; id=&quot;201a&quot; class=&quot;graf graf--h3 graf-after--p&quot;&gt;Concluding Remarks&lt;/h3&gt;
&lt;p name=&quot;9753&quot; id=&quot;9753&quot; class=&quot;graf graf--p graf-after--h3&quot;&gt;Though this article has ended on a negative note, I do not want that to be the main take-away from this post. Rather, consider that the space of possibilities that is available to us is vastly larger than the space of things that has been tried. These architectures might not be perfect, but they’re making real steps towards solving difficult problems. I have given my own creative ideas in this post, but by no means do CG-OoO, the Mill, and my ideas cover every possible choice available.&lt;/p&gt;
&lt;p name=&quot;35d9&quot; id=&quot;35d9&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;If there is some more general thing to be taken from this post, perhaps the following would make a good summary.&lt;/p&gt;
&lt;h4 name=&quot;b89f&quot; id=&quot;b89f&quot; class=&quot;graf graf--h4 graf-after--p&quot;&gt;A. Throughput&lt;/h4&gt;
&lt;ol class=&quot;postList&quot;&gt;&lt;li name=&quot;b2a0&quot; id=&quot;b2a0&quot; class=&quot;graf graf--li graf-after--h4&quot;&gt;The architecture must be able to route instructions efficiently and with minimal latency between a large number of functional units.&lt;/li&gt;
&lt;li name=&quot;4b54&quot; id=&quot;4b54&quot; class=&quot;graf graf--li graf-after--li&quot;&gt;The architecture should be designed to handle decode and dispatch in significant excess of the available arithmetic ILP.&lt;/li&gt;
&lt;/ol&gt;&lt;h4 name=&quot;a3ca&quot; id=&quot;a3ca&quot; class=&quot;graf graf--h4 graf-after--li&quot;&gt;B. Dependencies and ILP extraction&lt;/h4&gt;
&lt;ol class=&quot;postList&quot;&gt;&lt;li name=&quot;fda7&quot; id=&quot;fda7&quot; class=&quot;graf graf--li graf-after--h4&quot;&gt;The architecture must avoid creating false dependencies of any kind.&lt;/li&gt;
&lt;li name=&quot;1fb2&quot; id=&quot;1fb2&quot; class=&quot;graf graf--li graf-after--li&quot;&gt;The architecture should have a wide receptive field over the and source-level program in order to see the full breadth of executable instructions.&lt;/li&gt;
&lt;/ol&gt;&lt;p name=&quot;8ecd&quot; id=&quot;8ecd&quot; class=&quot;graf graf--p graf-after--li graf--trailing&quot;&gt;This is a big ask, but both CG-OoO and the Mill make good steps towards them, and the future, though mysterious and uncertain, holds a good deal of promise.&lt;/p&gt;
</description>
<pubDate>Sat, 11 May 2019 12:52:26 +0000</pubDate>
<dc:creator>Veedrac</dc:creator>
<og:title>To reinvent the processor</og:title>
<og:url>https://medium.com/@veedrac/to-reinvent-the-processor-671139a4a034</og:url>
<og:image>https://cdn-images-1.medium.com/max/1200/1*GfQGVmWUWuOerJ2dQAkQsg.png</og:image>
<og:description>A detailed, critical, technical essay on upcoming CPU architectures.</og:description>
<og:type>article</og:type>
<dc:format>text/html</dc:format>
<dc:identifier>https://medium.com/@veedrac/to-reinvent-the-processor-671139a4a034</dc:identifier>
</item>
</channel>
</rss>