<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="css/feed.xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/" xmlns:og="http://ogp.me/ns#">
<channel>
<atom:link rel="self" href="http://192.168.1.4/fivefilters/makefulltextfeed.php?url=hnrss.org%2Fnewest%3Fpoints%3D200&amp;max=10&amp;links=preserve&amp;exc=" />
<atom:link rel="alternate" title="Source URL" href="http://hnrss.org/newest?points=200" />
<atom:link rel="related" title="Subscribe to feed" href="http://www.subtome.com/#/subscribe?feeds=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dhnrss.org%252Fnewest%253Fpoints%253D200%26max%3D10%26links%3Dpreserve%26exc%3D&amp;back=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dhnrss.org%252Fnewest%253Fpoints%253D200%26max%3D10%26links%3Dpreserve%26exc%3D" />
<title>Hacker News: Newest</title>
<link>https://news.ycombinator.com/newest</link>
<description>Hacker News RSS</description>
<item>
<title>Intel Exiting 5G Modems</title>
<link>https://newsroom.intel.com/news-releases/intel-modem-statement/#gs.639at4</link>
<guid isPermaLink="true" >https://newsroom.intel.com/news-releases/intel-modem-statement/#gs.639at4</guid>
<description>&lt;p&gt;SANTA CLARA, Calif., April 16, 2019 – Intel Corporation today announced its intention to exit the 5G smartphone modem business and complete an assessment of the opportunities for 4G and 5G modems in PCs, internet of things devices and other data-centric devices. Intel will also continue to invest in its 5G network infrastructure business.&lt;/p&gt;
&lt;p&gt;The company will continue to meet current customer commitments for its existing 4G smartphone modem product line, but does not expect to launch 5G modem products in the smartphone space, including those originally planned for launches in 2020.&lt;/p&gt;
&lt;p&gt;“We are very excited about the opportunity in 5G and the ‘cloudification’ of the network, but in the smartphone modem business it has become apparent that there is no clear path to profitability and positive returns,” said Intel CEO Bob Swan. “5G continues to be a strategic priority across Intel, and our team has developed a valuable portfolio of wireless products and intellectual property. We are assessing our options to realize the value we have created, including the opportunities in a wide variety of data-centric platforms and devices in a 5G world.”&lt;/p&gt;
&lt;p&gt;Intel expects to provide additional details in its upcoming first-quarter 2019 earnings release and conference call, scheduled for April 25.&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;small&quot;&gt;&lt;strong&gt;Forward-Looking Statements&lt;/strong&gt;Statements in this press release that refer to future plans and expectations are forward-looking statements that involve a number of risks and uncertainties. Words such as “anticipates,” “expects,” “intends,” “goals,” “plans,” “believes,” “seeks,” “estimates,” “continues,” “may,” “will,” “would,” “should,” “could,” and variations of such words and similar expressions are intended to identify such forward-looking statements. Statements that refer to or are based on estimates, forecasts, projections, uncertain events or assumptions, including statements relating to anticipated trends in our businesses or the markets relevant to them, also identify forward-looking statements. All forward-looking statements included in this release are based on management’s expectations as of the date of this release and, except as required by law, Intel disclaims any obligation to update these forward-looking statements to reflect future events or circumstances. Forward-looking statements involve many risks and uncertainties that could cause actual results to differ materially from those expressed or implied in such statements. Important factors that could cause actual results to differ materially from the company’s expectations are set forth in Intel’s earnings release dated January 24, 2019, which is included as an exhibit to Intel’s Form 8-K furnished to the SEC on such date. Additional information regarding these and other factors that could affect Intel’s results is included in Intel’s SEC filings, including the company’s most recent reports on Forms 10-K and 10-Q. Copies of Intel’s Form 10-K, 10-Q and 8-K reports may be obtained by visiting our Investor Relations website at www.intc.com or the SEC’s website at www.sec.gov.&lt;/span&gt;&lt;/p&gt;
</description>
<pubDate>Wed, 17 Apr 2019 00:10:53 +0000</pubDate>
<dc:creator>ItsTotallyOn</dc:creator>
<og:type>article</og:type>
<og:title>Intel to Exit 5G Smartphone Modem Business, Focus 5G Efforts on Network Infrastructure and Other Data-Centric Opportunities | Intel Newsroom</og:title>
<og:description>SANTA CLARA, Calif., April 16, 2019 – Intel Corporation today announced its intention to exit the 5G smartphone modem business and complete an assessment</og:description>
<og:url>https://newsroom.intel.com/news-releases/intel-modem-statement/</og:url>
<og:image>https://simplecore.intel.com/newsroom/wp-content/uploads/sites/11/2016/04/intel-logo-default.png</og:image>
<dc:language>en-US</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://newsroom.intel.com/news-releases/intel-modem-statement/</dc:identifier>
</item>
<item>
<title>Panic’s Next Editor</title>
<link>https://panic.com/next/</link>
<guid isPermaLink="true" >https://panic.com/next/</guid>
<description>&lt;head&gt;&lt;meta charset=&quot;utf-8&quot;/&gt;&lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, viewport-fit=cover&quot;/&gt;&lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;https://cloud.typography.com/7652892/6499212/css/fonts.css&quot;/&gt;&lt;link href=&quot;next.css&quot; rel=&quot;stylesheet&quot; type=&quot;text/css&quot;/&gt;&lt;title&gt;Panic - What's Next for Coda?&lt;/title&gt;&lt;meta name=&quot;title&quot; content=&quot;What's Next for Coda?&quot;/&gt;&lt;meta name=&quot;description&quot; content=&quot;The competition is free. The industry is moving fast. And we’re making a brand-new, fully native, web development editor just for the Mac. What are we thinking?&quot;/&gt;&lt;meta property=&quot;og:type&quot; content=&quot;website&quot;/&gt;&lt;meta property=&quot;og:url&quot; content=&quot;https:/panic.com/next/&quot;/&gt;&lt;meta property=&quot;og:title&quot; content=&quot;What's Next for Coda?&quot;/&gt;&lt;meta property=&quot;og:description&quot; content=&quot;The competition is free. The industry is moving fast. And we’re making a brand-new, fully native, web development editor just for the Mac. What are we thinking?&quot;/&gt;&lt;meta property=&quot;og:image&quot; content=&quot;https://panic.com/next/card.png&quot;/&gt;&lt;meta property=&quot;twitter:card&quot; content=&quot;summary_large_image&quot;/&gt;&lt;meta property=&quot;twitter:url&quot; content=&quot;https:/panic.com/next/&quot;/&gt;&lt;meta property=&quot;twitter:title&quot; content=&quot;What's Next for Coda?&quot;/&gt;&lt;meta property=&quot;twitter:description&quot; content=&quot;The competition is free. The industry is moving fast. And we’re making a brand-new, fully native, web development editor just for the Mac. What are we thinking?&quot;/&gt;&lt;meta property=&quot;twitter:image&quot; content=&quot;https://panic.com/next/card.png&quot;/&gt;&lt;/head&gt;&lt;body id=&quot;readabilityBody&quot; readability=&quot;80.827101631117&quot;&gt;
&lt;p&gt;&lt;a class=&quot;home&quot; href=&quot;https://panic.com/&quot;&gt;Panic Inc.&lt;/a&gt;&lt;/p&gt;
&lt;p readability=&quot;27.5&quot;&gt;What are we thinking?
&lt;section readability=&quot;55&quot;&gt;&lt;p&gt;Twelve years ago we introduced Coda, the world’s first web development editor. It put the tools you needed to make a web page together in one app, and nobody had ever done that before.&lt;/p&gt;
&lt;p&gt;But a lot has changed since then. Websites are now more like applications in the way they're built and run. Deployment is much more complex than an FTP upload. Languages, frameworks, toolchains — and possibilities — have exploded.&lt;/p&gt;
&lt;p&gt;We had to make a difficult choice: rewrite Coda for this new world, or leave it behind?&lt;/p&gt;
&lt;p&gt;We’ve been making apps for a long time. And we never stopped having a passion for creating beautiful, functional, useful tools that help people do their very best work.&lt;/p&gt;
&lt;p&gt;It’s what we are. It’s why we’re here.&lt;/p&gt;
&lt;p&gt;So, you can probably guess what we chose.&lt;/p&gt;
&lt;p&gt;Later this year, we’ll be releasing a preview of our next Mac web editor, one you can try for yourself.&lt;/p&gt;
&lt;h2&gt;Is it any good?&lt;/h2&gt;
&lt;p&gt;So far, yes. We think so. We’re using it every day.&lt;/p&gt;
&lt;p&gt;There are substantial new modern editor features, like multiple cursors, highlighting for identifiers, tag pairs, and brackets, editor overscroll, improved autocomplete, and more.&lt;/p&gt;
&lt;p&gt;There’s publishing to multiple destinations. A sidebar for build issues. Themes for the entire workspace. A new Terminal.&lt;/p&gt;
&lt;p&gt;And since it’s Mac native, it’s super smooth and hyper responsive, designed to get your work done as quickly as possible. It’s also way faster than Coda 2 — up to 40 times faster when parsing files and indexing a project.&lt;/p&gt;
&lt;p&gt;Most intriguingly, there’s still a lot we’re not quite ready to talk about — innovative new ways that our next editor can help you with your entire web development workflow.&lt;/p&gt;
&lt;/section&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://panic.com/next/screenshot.png&quot;/&gt;&lt;/p&gt;
&lt;section readability=&quot;60.647168059424&quot;&gt;&lt;h2&gt;How can we compete?&lt;/h2&gt;
&lt;p&gt;That’s a fair question. Many of our competitors are free, and we really rely on, well, revenue.&lt;/p&gt;
&lt;p&gt;But if there’s anything we believe, it’s this: when you build an amazing product that helps people be happier doing their jobs every day, you’ll find the customers you need to keep it going.&lt;/p&gt;
&lt;p&gt;Just look at Transmit, our file transfer client, which is still being actively developed, 20 years later.&lt;/p&gt;
&lt;p&gt;We know we’ll never crush the big guys. We won’t even be on Windows. But that’s OK, because crushing anything has never really been a goal. Instead, we’re working hard to give you something really amazing. Something you’ll use every day. Something worth switching to.&lt;/p&gt;
&lt;h2&gt;But change is always hard.&lt;/h2&gt;
&lt;p&gt;It’s not all great news. Our next editor will be entirely redesigned, which for Coda 2 users means some re-learning of how the app works. It was important for us to make it fast, modern, free of bloat, and out-of-your-way so you can work quickly. That meant totally starting over.&lt;/p&gt;
&lt;p&gt;Plus, some features from Coda 2 will be going away — at least for now — like the MySQL client and visual CSS editing.&lt;/p&gt;
&lt;p&gt;But we’re going to be moving fast. Iterating constantly. Listening to feedback daily. This is an app that won’t be standing still. And we’re counting on you to guide us.&lt;/p&gt;
&lt;h2&gt;And, it won’t be called Coda.&lt;/h2&gt;
&lt;p&gt;Yes, the next Coda is so different it won’t even be called Coda.&lt;/p&gt;
&lt;p&gt;Frankly, we were worried that developers may have tried Coda in the past, decided it wasn’t for them, and written the app off forever. This new version is so new, it deserves a fresh start.&lt;/p&gt;
&lt;p&gt;And then, incredibly, a new Coda arrived on the scene — a reimagined document at &lt;a href=&quot;http://coda.io&quot;&gt;coda.io&lt;/a&gt; — and we reached an agreement to let them have the name. They’re Coda now. And we’re free to look to the future.&lt;/p&gt;
&lt;p&gt;So the next Coda won’t be “Coda”. So what will it be?&lt;/p&gt;
&lt;h2&gt;It will be very special.&lt;/h2&gt;
&lt;p&gt;Yeah, it’s true, we do things a little… differently here at Panic. But we love the Mac. We love building professional tools. And we love helping you do your best work.&lt;/p&gt;
&lt;p&gt;Our next editor will be here before you know it.&lt;/p&gt;
&lt;footer&gt;&lt;a class=&quot;button&quot; href=&quot;https://panic-inc.typeform.com/to/Y85MXj&quot;&gt;Click here to be the first to know more.&lt;/a&gt;&lt;/footer&gt;&lt;/section&gt;&lt;/body&gt;</description>
<pubDate>Tue, 16 Apr 2019 22:19:03 +0000</pubDate>
<dc:creator>whalesalad</dc:creator>
<og:type>website</og:type>
<og:url>https:/panic.com/next/</og:url>
<og:title>What's Next for Coda?</og:title>
<og:description>The competition is free. The industry is moving fast. And we’re making a brand-new, fully native, web development editor just for the Mac. What are we thinking?</og:description>
<og:image>https://panic.com/next/card.png</og:image>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://panic.com/next/</dc:identifier>
</item>
<item>
<title>Pyodide: Bringing the scientific Python stack to the browser</title>
<link>https://hacks.mozilla.org/2019/04/pyodide-bringing-the-scientific-python-stack-to-the-browser/</link>
<guid isPermaLink="true" >https://hacks.mozilla.org/2019/04/pyodide-bringing-the-scientific-python-stack-to-the-browser/</guid>
<description>&lt;p&gt;&lt;a href=&quot;https://github.com/iodide-project/pyodide/&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;Pyodide&lt;/a&gt; is an experimental project from Mozilla to create a full Python data science stack that runs entirely in the browser.&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://alpha.iodide.io/notebooks/1663/?viewMode=report&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;&lt;img src=&quot;https://2r4s9p1yi1fa2jd7j43zph8r-wpengine.netdna-ssl.com/files/2019/04/311-oakdark-inferno-edited-cropped.gif&quot; alt=&quot;Density of 311 calls in Oakland, California&quot; width=&quot;749&quot; height=&quot;324&quot; class=&quot;alignnone size-full wp-image-33404&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The impetus for Pyodide came from working on another Mozilla project, &lt;a href=&quot;http://iodide.io/&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;Iodide&lt;/a&gt;, which we presented in an &lt;a href=&quot;https://hacks.mozilla.org/2019/03/iodide-an-experimental-tool-for-scientific-communicatiodide-for-scientific-communication-exploration-on-the-web/&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;earlier post&lt;/a&gt;.  Iodide is a tool for data science experimentation and communication based on state-of-the-art web technologies.  Notably, it’s designed to perform data science computation within the browser rather than on a remote kernel.&lt;/p&gt;
&lt;p&gt;Unfortunately, the “language we all have” in the browser, JavaScript, doesn’t have a mature suite of data science libraries, and it’s missing a number of features that are useful for numerical computing, such as &lt;a href=&quot;https://github.com/keithamus/ecmascript-operator-overloading-proposal&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;operator overloading&lt;/a&gt;. We still think it’s worthwhile to work on changing that and &lt;a href=&quot;https://github.com/iodide-project/awesome-browser-data-science-libraries&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;moving the JavaScript data science ecosystem forward&lt;/a&gt;. In the meantime, we’re also taking a shortcut: we’re meeting data scientists where they are by bringing the popular and mature Python scientific stack to the browser.&lt;/p&gt;
&lt;p&gt;It’s also been argued more generally that &lt;a href=&quot;https://www.youtube.com/watch?v=ITksU31c1WY&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;Python not running in the browser represents an existential threat to the language&lt;/a&gt;—with so much user interaction happening on the web or on mobile devices, it needs to work there or be left behind. Therefore, while Pyodide tries to meet the needs of Iodide first, it is engineered to be &lt;a href=&quot;https://github.com/iodide-project/pyodide/blob/master/docs/using_pyodide_from_javascript.md&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;useful on its own as well&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Pyodide gives you a full, standard Python interpreter that runs entirely in the browser, with full access to the browser’s Web APIs.  &lt;a href=&quot;https://alpha.iodide.io/notebooks/1663/?viewMode=report&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;In the example above&lt;/a&gt; (50 MB download), the density of calls to the City of Oakland, California’s “311” local information service is plotted in 3D. The data loading and processing is performed in Python, and then it hands off to Javascript and WebGL for the plotting.&lt;/p&gt;
&lt;p&gt;For another quick example, here’s a simple doodling script that lets you draw in the browser window:&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;py&quot;&gt;
from js import document, iodide

canvas = iodide.output.element('canvas')
canvas.setAttribute('width', 450)
canvas.setAttribute('height', 300)
context = canvas.getContext(&quot;2d&quot;)
context.strokeStyle = &quot;#df4b26&quot;
context.lineJoin = &quot;round&quot;
context.lineWidth = 5

pen = False
lastPoint = (0, 0)

def onmousemove(e):
    global lastPoint

    if pen:
        newPoint = (e.offsetX, e.offsetY)
        context.beginPath()
        context.moveTo(lastPoint[0], lastPoint[1])
        context.lineTo(newPoint[0], newPoint[1])
        context.closePath()
        context.stroke()
        lastPoint = newPoint

def onmousedown(e):
    global pen, lastPoint
    pen = True
    lastPoint = (e.offsetX, e.offsetY)

def onmouseup(e):
    global pen
    pen = False

canvas.addEventListener('mousemove', onmousemove)
canvas.addEventListener('mousedown', onmousedown)
canvas.addEventListener('mouseup', onmouseup)
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;And this is what it looks like:&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://2r4s9p1yi1fa2jd7j43zph8r-wpengine.netdna-ssl.com/files/2019/04/pyodide-draw.gif&quot; alt=&quot;Interactive doodle example&quot; width=&quot;900&quot; height=&quot;900&quot; class=&quot;alignnone size-full wp-image-33405&quot;/&gt;&lt;/p&gt;
&lt;p&gt;The best way to learn more about what Pyodide can do is to just go and try it! There is a &lt;a href=&quot;https://alpha.iodide.io/notebooks/300/&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;demo notebook&lt;/a&gt; (50MB download) that walks through the high-level features. The rest of this post will be more of a technical deep-dive into how it works.&lt;/p&gt;
&lt;h2&gt;Prior art&lt;/h2&gt;
&lt;p&gt;There were already a number of impressive projects bringing Python to the browser when we started Pyodide.  Unfortunately, none addressed our specific goal of supporting a full-featured mainstream data science stack, including &lt;a href=&quot;http://www.numpy.org/&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;NumPy&lt;/a&gt;, &lt;a href=&quot;https://pandas.pydata.org/&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;Pandas&lt;/a&gt;, &lt;a href=&quot;https://www.scipy.org/&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;Scipy&lt;/a&gt;, and &lt;a href=&quot;https://matplotlib.org/&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;Matplotlib&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Projects such as &lt;a href=&quot;https://www.transcrypt.org/&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;Transcrypt&lt;/a&gt; transpile (convert) Python to JavaScript. Because the transpilation step itself happens in Python, you either need to do all of the transpiling ahead of time, or communicate with a server to do that work. This doesn’t really meet our goal of letting the user write Python in the browser and run it without any outside help.&lt;/p&gt;
&lt;p&gt;Projects like &lt;a href=&quot;https://brython.info/&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;Brython&lt;/a&gt; and &lt;a href=&quot;http://www.skulpt.org/&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;Skulpt&lt;/a&gt; are rewrites of the standard Python interpreter to JavaScript, therefore, they can run strings of Python code directly in the browser.  Unfortunately, since they are entirely new implementations of Python, and in JavaScript to boot, they aren’t compatible with Python extensions written in C, such as &lt;a href=&quot;http://www.numpy.org/&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;NumPy&lt;/a&gt; and &lt;a href=&quot;https://pandas.pydata.org/&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;Pandas&lt;/a&gt;. Therefore, there’s no data science tooling.&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://pypyjs.org/&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;PyPyJs&lt;/a&gt; is a build of the alternative just-in-time compiling Python implementation, &lt;a href=&quot;https://pypy.org/&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;PyPy&lt;/a&gt;, to the browser, using emscripten.  It has the potential to run Python code really quickly, for the same reasons that PyPy does.  Unfortunately, it has the &lt;a href=&quot;http://doc.pypy.org/en/latest/faq.html#should-i-install-numpy-or-numpypy&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;same issues with performance with C extensions&lt;/a&gt; that PyPy does.&lt;/p&gt;
&lt;p&gt;All of these approaches would have required us to rewrite the scientific computing tools to achieve adequate performance.  As someone who used to &lt;a href=&quot;http://matplotlib.1069221.n5.nabble.com/ANN-Michael-Droettboom-matplotlib-lead-developer-td5037.html&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;work a lot on Matplotlib&lt;/a&gt;, I know how many untold person-hours that would take: other projects have &lt;a href=&quot;http://doc.pypy.org/en/latest/faq.html#what-about-numpy-numpypy-micronumpy&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;tried and stalled&lt;/a&gt;, and it’s certainly a lot more work than our scrappy upstart team could handle.  We therefore needed to build a tool that was based as closely as possible on the standard implementations of Python and the scientific stack that most data scientists already use.  &lt;/p&gt;
&lt;p&gt;After a discussion with some of &lt;a href=&quot;https://research.mozilla.org/webassembly/&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;Mozilla’s WebAssembly wizards&lt;/a&gt;, we saw that the key to building this was &lt;a href=&quot;https://emscripten.org/&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;emscripten&lt;/a&gt; and &lt;a href=&quot;https://webassembly.org/&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;WebAssembly&lt;/a&gt;: technologies to port existing code written in C to the browser.  That led to the discovery of an existing but dormant build of Python for emscripten, &lt;a href=&quot;https://github.com/dgym/cpython-emscripten&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;cpython-emscripten&lt;/a&gt;, which was ultimately used as the basis for Pyodide.&lt;/p&gt;
&lt;h2&gt;emscripten and WebAssembly&lt;/h2&gt;
&lt;p&gt;There are many ways of describing what &lt;a href=&quot;https://emscripten.org/&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;emscripten&lt;/a&gt; is, but most importantly for our purposes, it provides two things:&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;A compiler from C/C++ to WebAssembly&lt;/li&gt;
&lt;li&gt;A compatibility layer that makes the browser feel like a native computing environment&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;&lt;a href=&quot;https://developer.mozilla.org/en-US/docs/WebAssembly&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;WebAssembly&lt;/a&gt; is a new language that runs in modern web-browsers, as a complement to JavaScript.  It’s a low-level assembly-like language that runs with near-native performance intended as a compilation target for low-level languages like C and C++.  Notably, the most popular interpreter for Python, called CPython, is implemented in C, so this is the kind of thing emscripten was created for.&lt;/p&gt;
&lt;p&gt;Pyodide is put together by:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;Downloading the source code of the mainstream &lt;a href=&quot;https://github.com/python/cpython&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;Python interpreter&lt;/a&gt; (CPython), and the scientific computing packages (NumPy, etc.)&lt;/li&gt;
&lt;li&gt;Applying a very small set of changes to make them work in the new environment&lt;/li&gt;
&lt;li&gt;Compiling them to WebAssembly using emscripten’s compiler&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;If you were to just take this WebAssembly and load it in the browser, things would look very different to the Python interpreter than they do when running directly on top of your operating system. For example, web browsers don’t have a file system (a place to load and save files). Fortunately, emscripten provides a virtual file system, written in JavaScript, that the Python interpreter can use. By default, these virtual “files” reside in volatile memory in the browser tab, and they disappear when you navigate away from the page.  (emscripten also provides a way for the file system to store things in the browser’s persistent local storage, but Pyodide doesn’t use it.)&lt;/p&gt;
&lt;p&gt;By emulating the file system and other features of a standard computing environment, emscripten makes moving existing projects to the web browser possible with surprisingly few changes. (Some day, we may move to using &lt;a href=&quot;https://hacks.mozilla.org/2019/03/standardizing-wasi-a-webassembly-system-interface/&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;WASI&lt;/a&gt; as the system emulation layer, but for now emscripten is the more mature and complete option).&lt;/p&gt;
&lt;p&gt;Putting it all together, to load Pyodide in your browser, you need to download:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;The compiled Python interpreter as WebAssembly.&lt;/li&gt;
&lt;li&gt;A bunch of JavaScript provided by emscripten that provides the system emulation.&lt;/li&gt;
&lt;li&gt;A packaged file system containing all the files the Python interpreter will need, most notably the Python standard library.&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;These files can be quite large: Python itself is 21MB, NumPy is 7MB, and so on. Fortunately, these packages only have to be downloaded once, after which they are stored in the browser’s cache.&lt;/p&gt;
&lt;p&gt;Using all of these pieces in tandem, the Python interpreter can access the files in its standard library, start up, and then start running the user’s code.&lt;/p&gt;
&lt;h2&gt;What works and doesn’t work&lt;/h2&gt;
&lt;p&gt;We run CPython’s unit tests as part of Pyodide’s continuous testing to get a handle on what features of Python do and don’t work.  Some things, like &lt;a href=&quot;https://docs.python.org/3/library/threading.html&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;threading&lt;/a&gt;, don’t work now, but with the newly-available &lt;a href=&quot;https://developers.google.com/web/updates/2018/10/wasm-threads&quot;&gt;WebAssembly threads&lt;/a&gt;, we should be able to add support in the near future.  &lt;/p&gt;
&lt;p&gt;Other features, like &lt;a href=&quot;https://docs.python.org/3/library/socket.html&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;low-level networking sockets&lt;/a&gt;, are unlikely to ever work because of the browser’s security sandbox.  Sorry to break it to you, your hopes of running a Python &lt;a href=&quot;https://github.com/Yardanico/puremine&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;minecraft server&lt;/a&gt; inside your web browser are probably still a long way off. Nevertheless, you can still fetch things over the network using the browser’s APIs (more details below).&lt;/p&gt;
&lt;h2&gt;How fast is it?&lt;/h2&gt;
&lt;p&gt;Running the Python interpreter inside a JavaScript virtual machine adds a performance penalty, but that penalty turns out to be surprisingly small — in our benchmarks, around 1x-12x slower than native on Firefox and 1x-16x slower on Chrome. Experience shows that this is very usable for interactive exploration.&lt;/p&gt;
&lt;p&gt;Notably, code that runs a lot of inner loops in Python tends to be slower by a larger factor than code that relies on NumPy to perform its inner loops. Below are the results of running various &lt;a href=&quot;https://github.com/iodide-project/pyodide/tree/master/benchmark/benchmarks&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;Pure Python and Numpy benchmarks&lt;/a&gt; in Firefox and Chrome compared to natively on the same hardware.&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://2r4s9p1yi1fa2jd7j43zph8r-wpengine.netdna-ssl.com/files/2019/04/image1-1.png&quot;&gt;&lt;img class=&quot;alignnone size-full wp-image-33387&quot; src=&quot;https://2r4s9p1yi1fa2jd7j43zph8r-wpengine.netdna-ssl.com/files/2019/04/image1-1.png&quot; alt=&quot;Pyodide benchmark results: Firefox and Chrome vs. native&quot; width=&quot;800&quot; height=&quot;800&quot; srcset=&quot;https://hacks.mozilla.org/files/2019/04/image1-1.png 800w, https://hacks.mozilla.org/files/2019/04/image1-1-250x250.png 250w, https://hacks.mozilla.org/files/2019/04/image1-1-768x768.png 768w, https://hacks.mozilla.org/files/2019/04/image1-1-500x500.png 500w&quot; sizes=&quot;(max-width: 800px) 100vw, 800px&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Interaction between Python and JavaScript&lt;/h2&gt;
&lt;p&gt;If all Pyodide could do is run Python code and write to standard out, it would amount to a cool trick, but it wouldn’t be a practical tool for real work.  The real power comes from its ability to interact with browser APIs and other JavaScript libraries at a very fine level. WebAssembly has been designed to easily interact with the JavaScript running in the browser.  Since we’ve compiled the Python interpreter to WebAssembly, it too has deep integration with the JavaScript side.&lt;/p&gt;
&lt;p&gt;Pyodide implicitly converts many of the built-in data types between Python and JavaScript.  Some of these conversions are straightforward and obvious, but as always, it’s the corner cases that are interesting.&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://2r4s9p1yi1fa2jd7j43zph8r-wpengine.netdna-ssl.com/files/2019/04/image3.png&quot;&gt;&lt;img class=&quot;alignnone size-full wp-image-33388&quot; src=&quot;https://2r4s9p1yi1fa2jd7j43zph8r-wpengine.netdna-ssl.com/files/2019/04/image3.png&quot; alt=&quot;Conversion of data types between Python and JavaScript&quot; width=&quot;1536&quot; height=&quot;960&quot; srcset=&quot;https://hacks.mozilla.org/files/2019/04/image3.png 1536w, https://hacks.mozilla.org/files/2019/04/image3-250x156.png 250w, https://hacks.mozilla.org/files/2019/04/image3-768x480.png 768w, https://hacks.mozilla.org/files/2019/04/image3-500x313.png 500w&quot; sizes=&quot;(max-width: 1536px) 100vw, 1536px&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Python treats &lt;code&gt;dict&lt;/code&gt;s and &lt;code&gt;object&lt;/code&gt; instances as two distinct types. &lt;code&gt;dict&lt;/code&gt;s (dictionaries) are just mappings of keys to values.  On the other hand, &lt;code&gt;object&lt;/code&gt;s generally have methods that “do something” to those objects. In JavaScript, these two concepts are conflated into a single type called &lt;code&gt;Object&lt;/code&gt;.  (Yes, I’ve oversimplified here to make a point.)&lt;/p&gt;
&lt;p&gt;Without really understanding the developer’s intention for the JavaScript &lt;code&gt;Object&lt;/code&gt;, it’s impossible to efficiently guess whether it should be converted to a Python &lt;code&gt;dict&lt;/code&gt; or &lt;code&gt;object&lt;/code&gt;.  Therefore, we have to use a proxy and let “duck typing” resolve the situation.&lt;/p&gt;
&lt;p&gt;Proxies are wrappers around a variable in the other language.  Rather than simply reading the variable in JavaScript and rewriting it in terms of Python constructs, as is done for the basic types, the proxy holds on to the original JavaScript variable and calls methods on it “on demand”.  This means that any JavaScript variable, no matter how custom, is fully accessible from Python. Proxies work in the other direction, too.&lt;/p&gt;
&lt;p&gt;Duck typing is the principle that rather than asking a variable &lt;em&gt;“are you a duck?”&lt;/em&gt; you ask it &lt;em&gt;“do you walk like a duck?”&lt;/em&gt; and &lt;em&gt;“do you quack like a duck?”&lt;/em&gt; and infer from that that it’s probably a duck, or at least does duck-like things.  This allows Pyodide to defer the decision on how to convert the JavaScript &lt;code&gt;Object&lt;/code&gt;: it wraps it in a proxy and lets the Python code using it decide how to handle it. Of course, this doesn’t always work, the &lt;a href=&quot;https://www.illusionsindex.org/i/duck-rabbit&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;duck may actually be a rabbit&lt;/a&gt;. Thus, Pyodide also provides ways to &lt;a href=&quot;https://github.com/iodide-project/pyodide/blob/master/docs/api_reference.md#pyodideas_nested_listobj&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;explicitly handle these conversions&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;It’s this tight level of integration that allows a user to do their data processing in Python, and then send it to JavaScript for visualization. For example, in our &lt;a href=&quot;https://alpha.iodide.io/notebooks/1623/&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;Hipster Band Finder demo&lt;/a&gt;, we show loading and analyzing a data set in Python’s Pandas, and then sending it to JavaScript’s &lt;a href=&quot;https://plotly.org/&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;Plotly&lt;/a&gt; for visualization.&lt;/p&gt;
&lt;h2&gt;Accessing Web APIs and the DOM&lt;/h2&gt;
&lt;p&gt;Proxies also turn out to be the key to accessing the Web APIs, or the set of functions the browser provides that make it do things.  For example, a large part of the Web API is on the &lt;code&gt;document&lt;/code&gt; object. You can get that from Python by doing:&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;from js import document&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;This imports the &lt;code&gt;document&lt;/code&gt; object in JavaScript over to the Python side as a proxy.  You can start calling methods on it from Python:&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;document.getElementById(&quot;myElement&quot;)&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;All of this happens through proxies that look up what the &lt;code&gt;document&lt;/code&gt; object can do on-the-fly.  Pyodide doesn’t need to include a comprehensive list of all of the Web APIs the browser has.&lt;/p&gt;
&lt;p&gt;Of course, using the Web API directly doesn’t always feel like the most Pythonic or user-friendly way to do things.  It would be great to see the creation of a user-friendly Python wrapper for the Web API, much like how jQuery and other libraries have made the Web API easier to use from JavaScript.  &lt;a href=&quot;https://gitter.im/iodide-project/iodide&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;Let us know&lt;/a&gt; if you’re interested in working on such a thing!&lt;/p&gt;
&lt;h2&gt;Multidimensional Arrays&lt;/h2&gt;
&lt;p&gt;There are important data types that are specific to data science, and Pyodide has special support for these as well.  Multidimensional arrays are collections of (usually numeric) values, all of the same type. They tend to be quite large, and knowing that every element is the same type has real performance advantages over Python’s &lt;code&gt;list&lt;/code&gt;s or JavaScript’s &lt;code&gt;Array&lt;/code&gt;s that can hold elements of any type.&lt;/p&gt;
&lt;p&gt;In Python, &lt;a href=&quot;https://docs.scipy.org/doc/numpy/reference/generated/numpy.array.html&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;NumPy arrays&lt;/a&gt; are the most common implementation of multidimensional arrays. JavaScript has &lt;a href=&quot;https://developer.mozilla.org/en/docs/Web/JavaScript/Reference/Global_Objects/TypedArray&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;TypedArrays&lt;/a&gt;, which contain only a single numeric type, but they are single dimensional, so the multidimensional indexing needs to be built on top.&lt;/p&gt;
&lt;p&gt;Since in practice these arrays can get quite large, we don’t want to copy them between language runtimes.  Not only would that take a long time, but having two copies in memory simultaneously would tax the limited memory the browser has available.&lt;/p&gt;
&lt;p&gt;Fortunately, we can share this data without copying.  Multidimensional arrays are usually implemented with a small amount of metadata that describes the type of the values, the shape of the array and the memory layout. The data itself is referenced from that metadata by a pointer to another place in memory. It’s an advantage that this memory lives in a special area called the “WebAssembly heap,” which is accessible from both JavaScript and Python.  We can simply copy the metadata (which is quite small) back and forth between the languages, keeping the pointer to the data referring to the WebAssembly heap.&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://2r4s9p1yi1fa2jd7j43zph8r-wpengine.netdna-ssl.com/files/2019/04/image2.png&quot;&gt;&lt;img src=&quot;https://2r4s9p1yi1fa2jd7j43zph8r-wpengine.netdna-ssl.com/files/2019/04/image2.png&quot; alt=&quot;Sharing memory for arrays between Python and Javascript&quot; width=&quot;864&quot; height=&quot;480&quot; class=&quot;alignnone size-full wp-image-33389&quot; srcset=&quot;https://hacks.mozilla.org/files/2019/04/image2.png 864w, https://hacks.mozilla.org/files/2019/04/image2-250x139.png 250w, https://hacks.mozilla.org/files/2019/04/image2-768x427.png 768w, https://hacks.mozilla.org/files/2019/04/image2-500x278.png 500w&quot; sizes=&quot;(max-width: 864px) 100vw, 864px&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;This idea is currently implemented for single-dimensional arrays, with a suboptimal workaround for higher-dimensional arrays.  We need improvements to the JavaScript side to have a useful object to work with there. To date there is no one obvious choice for JavaScript multidimensional arrays. Promising projects such as &lt;a href=&quot;https://arrow.apache.org/&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;Apache Arrow&lt;/a&gt; and &lt;a href=&quot;https://xnd.io/&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;xnd’s ndarray&lt;/a&gt; are working exactly in this problem space, and aim to make the passing of in-memory structured data between language runtimes easier.  Investigations are ongoing to build off of these projects to make this sort of data conversion more powerful.&lt;/p&gt;
&lt;h2&gt;Real-time interactive visualization&lt;/h2&gt;
&lt;p&gt;One of the advantages of doing the data science computation in the browser rather than in a remote kernel, as &lt;a href=&quot;https://jupyter.org/&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;Jupyter&lt;/a&gt; does, is that interactive visualizations don’t have to communicate over a network to reprocess and redisplay their data.  This greatly reduces the latency — the round trip time it takes from the time the user moves their mouse to the time an updated plot is displayed to the screen.&lt;/p&gt;
&lt;p&gt;Making that work requires all of the technical pieces described above to function together in tandem.  Let’s look at this &lt;a href=&quot;https://alpha.iodide.io/notebooks/1658/&quot;&gt;interactive example that shows how log-normal distributions work&lt;/a&gt; using matplotlib. First, the random data is generated in Python using Numpy. Next, Matplotlib takes that data, and draws it using its built-in software renderer. It sends the pixels back to the JavaScript side using Pyodide’s support for zero-copy array sharing, where they are finally rendered into an HTML canvas.  The browser then handles getting those pixels to the screen. Mouse and keyboard events used to support interactivity are handled by callbacks that call from the web browser back into Python.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://2r4s9p1yi1fa2jd7j43zph8r-wpengine.netdna-ssl.com/files/2019/04/matplotlib-interacting-with-plots.gif&quot; alt=&quot;Interacting with distributions in matplotlib&quot; width=&quot;900&quot; height=&quot;700&quot; class=&quot;alignnone size-full wp-image-33398&quot;/&gt;&lt;/p&gt;
&lt;h2&gt;Packaging&lt;/h2&gt;
&lt;p&gt;The Python scientific stack is not a monolith—it’s actually a collection of loosely-affiliated packages that work together to create a productive environment.  Among the most popular are &lt;a href=&quot;http://www.numpy.org/&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;NumPy&lt;/a&gt; (for numerical arrays and basic computation), &lt;a href=&quot;https://www.scipy.org/&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;Scipy&lt;/a&gt; (for more sophisticated general-purpose computation, such as linear algebra), &lt;a href=&quot;https://matplotlib.org/&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;Matplotlib&lt;/a&gt; (for visualization) and &lt;a href=&quot;https://pandas.pydata.org/&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;Pandas&lt;/a&gt; (for tabular data or “data frames”).  You can see the full and constantly updated list of the packages that Pyodide builds for the browser &lt;a href=&quot;https://github.com/iodide-project/pyodide/tree/master/packages&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Some of these packages were quite straightforward to bring into Pyodide. Generally, anything written in pure Python without any extensions in compiled languages is pretty easy. In the moderately difficult category are projects like Matplotlib, which required special code to display plots in an HTML canvas. On the extremely difficult end of the spectrum, Scipy has been and remains a considerable challenge.  &lt;/p&gt;
&lt;p&gt;Roman Yurchak worked on making the large amount of legacy Fortran in Scipy compile to WebAssembly. Kirill Smelkov improved emscripten so shared objects can be reused by other shared objects, bringing Scipy to a more manageable size. (The work of these outside contributors was supported by &lt;a href=&quot;http://www.nexedi.com/&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;Nexedi&lt;/a&gt;).  If you’re struggling porting a package to Pyodide, please reach out to us &lt;a href=&quot;https://github.com/iodide-project/pyodide/&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;on Github&lt;/a&gt;: there’s a good chance we may have run into your problem before.&lt;/p&gt;
&lt;p&gt;Since we can’t predict which of these packages the user will ultimately need to do their work, they are downloaded to the browser individually, on demand.  For example, when you import NumPy:&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;import numpy as np&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;Pyodide fetches the NumPy library (and all of its dependencies) and loads them into the browser at that time.  Again, these files only need to be downloaded once, and are stored in the browser’s cache from then on.&lt;/p&gt;
&lt;p&gt;Adding new packages to Pyodide is currently a semi-manual process that involves adding files to the Pyodide build. We’d prefer, long term, to take a distributed approach to this so anyone could contribute packages to the ecosystem without going through a single project.  The best-in-class example of this is &lt;a href=&quot;https://conda-forge.org/&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;conda-forge&lt;/a&gt;. It would be great to extend their tools to support WebAssembly as a platform target, rather than redoing a large amount of effort.&lt;/p&gt;
&lt;p&gt;Additionally, Pyodide will &lt;a href=&quot;https://github.com/iodide-project/pyodide/pull/147&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;soon have support&lt;/a&gt; to load packages directly from &lt;a href=&quot;https://pypi.org/&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;PyPI&lt;/a&gt; (the main community package repository for Python), if that package is pure Python and distributes its package in the &lt;a href=&quot;https://pythonwheels.com/&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;wheel format&lt;/a&gt;.  This gives Pyodide access to around 59,000 packages, as of today.&lt;/p&gt;
&lt;h2&gt;Beyond Python&lt;/h2&gt;
&lt;p&gt;The relative early success of Pyodide has already inspired developers from other language communities, including &lt;a href=&quot;https://github.com/keno/julia-wasm&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;Julia&lt;/a&gt;, R, &lt;a href=&quot;https://github.com/louisabraham/domical&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;OCaml&lt;/a&gt;, &lt;a href=&quot;https://codepen.io/ds604/pen/d9791eed4e1ce19e11fb0f3c71000d72&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;Lua&lt;/a&gt;, to make their &lt;a href=&quot;https://github.com/iodide-project/iodide/blob/master/docs/language_plugins.md&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;language runtimes&lt;/a&gt; work well in the browser and integrate with web-first tools like Iodide.  We’ve defined a set of levels to encourage implementors to create tighter integrations with the JavaScript runtime:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;em&gt;Level 1:&lt;/em&gt; Just string output, so it’s useful as a basic console REPL (read-eval-print-loop).&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Level 2:&lt;/em&gt; Converts basic data types (numbers, strings, arrays and objects) to and from JavaScript.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Level 3:&lt;/em&gt; Sharing of class instances (objects with methods) between the guest language and JavaScript.  This allows for Web API access.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Level 4:&lt;/em&gt; Sharing of data science related types  (&lt;em&gt;n&lt;/em&gt;-dimensional arrays and data frames) between the guest language and JavaScript.&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;We definitely want to encourage this brave new world, and are excited about the possibilities of having even more languages interoperating together.  Let us know what you’re working on!&lt;/p&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;If you haven’t already tried Pyodide in action, go &lt;a href=&quot;https://alpha.iodide.io/notebooks/300/&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;try it now!&lt;/a&gt; (50MB download)&lt;/p&gt;
&lt;p&gt;It’s been really gratifying to see all of the cool things that have been created with Pyodide in the short time since its public launch.  However, there’s still lots to do to turn this experimental proof-of-concept into a professional tool for everyday data science work. If you’re interested in helping us build that future, come find us on &lt;a href=&quot;https://gitter.im/iodide-project/iodide&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;gitter&lt;/a&gt;, &lt;a href=&quot;https://github.com/iodide-project/pyodide&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;github&lt;/a&gt; and &lt;a href=&quot;https://groups.google.com/forum/#!forum/iodide-dev&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;our mailing list&lt;/a&gt;.&lt;/p&gt;
&lt;hr/&gt;&lt;p&gt;&lt;em&gt;Huge thanks to &lt;a href=&quot;https://github.com/bcolloran&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;Brendan Colloran&lt;/a&gt;, &lt;a href=&quot;http://github.com/hamilton&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;Hamilton Ulmer&lt;/a&gt; and &lt;a href=&quot;https://wrla.ch&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;William Lachance&lt;/a&gt;, for their great work on Iodide and for reviewing this article, and &lt;a href=&quot;http://github.com/tcaswell&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;Thomas Caswell&lt;/a&gt; for additional review.&lt;/em&gt;&lt;/p&gt;
&lt;section class=&quot;about&quot; readability=&quot;8.994708994709&quot;&gt;
&lt;p&gt;Michael Droettboom is a Data Engineer at Mozilla, using data to improve the web while respecting the privacy of its users. He has built software tools to support many other disciplines, including the computational humanities, astronomy and medicine. He is a former lead developer of matplotlib and the original author of airspeed velocity.&lt;/p&gt;
&lt;p&gt;&lt;a class=&quot;url&quot; href=&quot;https://hacks.mozilla.org/author/mdroettboommozilla-com/&quot;&gt;More articles by Michael Droettboom…&lt;/a&gt;&lt;/p&gt;
&lt;/section&gt;</description>
<pubDate>Tue, 16 Apr 2019 21:57:55 +0000</pubDate>
<dc:creator>barryvan</dc:creator>
<og:url>https://hacks.mozilla.org/2019/04/pyodide-bringing-the-scientific-python-stack-to-the-browser</og:url>
<og:title>Pyodide: Bringing the scientific Python stack to the browser – Mozilla Hacks - the Web developer blog</og:title>
<og:description>Pyodide is an experimental project from Mozilla to create a full Python data science stack that runs entirely in the browser. We think it’s worthwhile to work on moving the ...</og:description>
<og:image>https://hacks.mozilla.org/files/2019/04/pyodide-social.png</og:image>
<dc:language>en-US</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://hacks.mozilla.org/2019/04/pyodide-bringing-the-scientific-python-stack-to-the-browser/</dc:identifier>
</item>
<item>
<title>Qualcomm and Apple agree to drop all litigation</title>
<link>https://www.apple.com/newsroom/2019/04/qualcomm-and-apple-agree-to-drop-all-litigation/</link>
<guid isPermaLink="true" >https://www.apple.com/newsroom/2019/04/qualcomm-and-apple-agree-to-drop-all-litigation/</guid>
<description>Qualcomm invents breakthrough technologies that transform how the world connects, computes and communicates. When we connected the phone to the Internet, the mobile revolution was born. Today, our inventions are the foundation for life-changing products, experiences, and industries. As we lead the world to 5G, we envision this next big change in cellular technology spurring a new era of intelligent, connected devices and enabling new opportunities in connected cars, remote delivery of health care services, and the IoT — including smart cities, smart homes, and wearables. Qualcomm Incorporated includes our licensing business, QTL, and the vast majority of our patent portfolio. Qualcomm Technologies, Inc., a subsidiary of Qualcomm Incorporated, operates, along with its subsidiaries, all of our engineering, research and development functions, and all of our products and services businesses, including, the QCT semiconductor business. For more information, visit Qualcomm’s &lt;a href=&quot;https://www.qualcomm.com/&quot; target=&quot;_blank&quot;&gt;website&lt;/a&gt;, &lt;a href=&quot;https://www.qualcomm.com/news/onq&quot; target=&quot;_blank&quot;&gt;OnQ blog&lt;/a&gt;, &lt;a href=&quot;http://www.twitter.com/qualcomm&quot; target=&quot;_blank&quot;&gt;Twitter&lt;/a&gt; and &lt;a href=&quot;http://www.facebook.com/qualcomm&quot; target=&quot;_blank&quot;&gt;Facebook&lt;/a&gt; pages.</description>
<pubDate>Tue, 16 Apr 2019 19:23:12 +0000</pubDate>
<dc:creator>saeedjabbar</dc:creator>
<og:type>article</og:type>
<og:title>Qualcomm and Apple agree to drop all litigation</og:title>
<og:description>The companies have reached a global patent license agreement and a chipset supply agreement.</og:description>
<og:url>https://www.apple.com/newsroom/2019/04/qualcomm-and-apple-agree-to-drop-all-litigation/</og:url>
<og:image>https://www.apple.com/newsroom/images/defaultog.png.large.png?201904161907</og:image>
<dc:language>en-US</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.apple.com/newsroom/2019/04/qualcomm-and-apple-agree-to-drop-all-litigation/</dc:identifier>
</item>
<item>
<title>A Gentle Introduction to Text Summarization in Machine Learning</title>
<link>https://blog.floydhub.com/gentle-introduction-to-text-summarization-in-machine-learning/</link>
<guid isPermaLink="true" >https://blog.floydhub.com/gentle-introduction-to-text-summarization-in-machine-learning/</guid>
<description>&lt;blockquote readability=&quot;7&quot;&gt;
&lt;p&gt;Have you ever summarized a lengthy document into a short paragraph? How long did you take? Manually generating a summary can be time consuming and tedious. Automatic text summarization promises to overcome such difficulties and allow you to generate the key ideas in a piece of writing easily.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Text summarization is the technique for generating a concise and precise summary of voluminous texts while focusing on the sections that convey useful information, and without losing the overall meaning.&lt;br/&gt;Automatic text summarization aims to transform lengthy documents into shortened versions, something which could be difficult and costly to undertake if done manually.&lt;br/&gt;Machine learning algorithms can be trained to comprehend documents and identify the sections that convey important facts and information before producing the required summarized texts. For example, the image below is of &lt;a href=&quot;https://www.autosport.com/motogp/news/142779/marquez-calls-austin-crash-hard-to-understand&quot;&gt;this news article&lt;/a&gt; that has been fed into a machine learning algorithm to generate a summary.&lt;/p&gt;
&lt;img src=&quot;https://blog.floydhub.com/content/images/2019/04/Screenshot-2019-04-15-at-12.50.11.png&quot; class=&quot;kg-image&quot;/&gt;An online news article that has been summarized using a text summarization machine learning algorithm

&lt;p&gt;With the present explosion of data circulating the digital space, which is mostly non-structured textual data, there is a need to develop automatic text summarization tools that allow people to get insights from them easily. Currently, we enjoy quick access to enormous amounts of information. However, most of this information is redundant, insignificant, and may not convey the intended meaning. For example, if you are looking for specific information from an online news article, you may have to dig through its content and spend a lot of time weeding out the unnecessary stuff before getting the information you want. Therefore, using automatic text summarizers capable of extracting useful information that leaves out inessential and insignificant data is becoming vital. Implementing summarization can enhance the readability of documents, reduce the time spent in researching for information, and allow for more information to be fitted in a particular area.&lt;/p&gt;

&lt;p&gt;Broadly, there are two approaches to summarizing texts in NLP: extraction and abstraction.&lt;/p&gt;

&lt;p&gt;In extraction-based summarization, a subset of words that represent the most important points is pulled from a piece of text and combined to make a summary. Think of it as a highlighter—which selects the main information from a source text.&lt;/p&gt;
&lt;img src=&quot;https://blog.floydhub.com/content/images/2019/04/highlighter.jpeg&quot; class=&quot;kg-image&quot;/&gt;Highlighter = Extractive-based summarization 
&lt;p&gt;In machine learning, extractive summarization usually involves weighing the essential sections of sentences and using the results to generate summaries.&lt;/p&gt;
&lt;p&gt;Different types of algorithms and methods can be used to gauge the weights of the sentences and then rank them according to their relevance and similarity with one another—and further joining them to generate a summary. Here's an example:&lt;/p&gt;
&lt;img src=&quot;https://blog.floydhub.com/content/images/2019/04/extractive.gif&quot; class=&quot;kg-image&quot;/&gt;Extractive-based summarization in action.
&lt;p&gt;As you can see above, the extracted summary is composed of the words highlighted in bold, although the results may not be grammatically accurate.&lt;/p&gt;
&lt;h3 id=&quot;abstraction-based-summarization&quot;&gt;Abstraction-based summarization&lt;/h3&gt;
&lt;p&gt;In abstraction-based summarization, advanced deep learning techniques are applied to paraphrase and shorten the original document, just like humans do. Think of it as a pen—which produces novel sentences that may not be part of the source document.&lt;/p&gt;
&lt;img src=&quot;https://blog.floydhub.com/content/images/2019/04/pen.jpeg&quot; class=&quot;kg-image&quot;/&gt;Pen = Abstraction-based summarization 
&lt;p&gt;Since abstractive machine learning algorithms can generate new phrases and sentences that represent the most important information from the source text, they can assist in overcoming the grammatical inaccuracies of the extraction techniques. Here is an example:&lt;/p&gt;
&lt;img src=&quot;https://blog.floydhub.com/content/images/2019/04/Screenshot-2019-04-12-at-17.45.04.png&quot; class=&quot;kg-image&quot;/&gt;Abstraction-based summary in action.
&lt;p&gt;Although abstraction performs better at text summarization, developing its algorithms requires complicated deep learning techniques and sophisticated language modeling.&lt;/p&gt;
&lt;p&gt;To generate plausible outputs, abstraction-based summarization approaches must address a wide variety of NLP problems, such as natural language generation, semantic representation, and inference permutation.&lt;/p&gt;
&lt;p&gt;As such, extractive text summarization approaches are still widely popular. In this article, we’ll be focusing on an extraction-based method.&lt;/p&gt;

&lt;p&gt;Let’s use a short paragraph to illustrate how extractive text summarization can be performed.&lt;/p&gt;
&lt;p&gt;Here is the paragraph:&lt;/p&gt;
&lt;blockquote readability=&quot;11&quot;&gt;
&lt;p&gt;&lt;em&gt;“Peter and Elizabeth took a taxi to attend the night party in the city. While in the party, Elizabeth collapsed and was rushed to the hospital. Since she was diagnosed with a brain injury, the doctor told Peter to stay besides her until she gets well. Therefore, Peter stayed with her at the hospital for 3 days without leaving.”&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Here are the steps to follow to summarize the above paragraph, while trying to maintain its intended meaning, as much as possible.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Step 1: Convert the paragraph into sentences&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;First, let’s split the paragraph into its corresponding sentences. The best way of doing the conversion is to extract a sentence whenever a period appears.&lt;/p&gt;
&lt;p&gt;1. Peter and Elizabeth took a taxi to attend the night party in the city&lt;/p&gt;
&lt;p&gt;2. While in the party, Elizabeth collapsed and was rushed to the hospital&lt;/p&gt;
&lt;p&gt;3. Since she was diagnosed with a brain injury, the doctor told Peter to stay besides her until she gets well&lt;/p&gt;
&lt;p&gt;4. Therefore, Peter stayed with her at the hospital for 3 days without leaving&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Step 2: Text processing&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Next, let’s do text processing by removing the stop words (extremely common words with little meaning such as “and” and “the”), numbers, punctuation, and other special characters from the sentences.&lt;/p&gt;
&lt;p&gt;Performing the filtering assists in removing redundant and insignificant information which may not provide any added value to the text’s meaning.&lt;/p&gt;
&lt;p&gt;Here is the result of the text processing:&lt;/p&gt;
&lt;p&gt;1. Peter Elizabeth took taxi attend night party city&lt;/p&gt;
&lt;p&gt;2. Party Elizabeth collapse rush hospital&lt;/p&gt;
&lt;p&gt;3. Diagnose brain injury doctor told Peter stay besides get well&lt;/p&gt;
&lt;p&gt;4. Peter stay hospital days without leaving&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Step 3: Tokenization&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Tokenizing the sentences is done to get all the words present in the sentences. Here is a list of the words:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;['peter','elizabeth','took','taxi','attend','night','party','city','party','elizabeth','collapse','rush','hospital', 'diagnose','brain', 'injury', 'doctor','told','peter','stay','besides','get','well','peter', 'stayed','hospital','days','without','leaving']&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Step 4: Evaluate the weighted occurrence frequency of the words&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Thereafter, let’s calculate the weighted occurrence frequency of all the words. To achieve this, let’s divide the occurrence frequency of each of the words by the frequency of the most recurrent word in the paragraph, which is “Peter” that occurs three times.&lt;/p&gt;
&lt;p&gt;Here is a table that gives the weighted occurrence frequency of each of the words.&lt;/p&gt;
&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;Word&lt;/th&gt;
&lt;th&gt;Frequency&lt;/th&gt;
&lt;th&gt;Weighted Frequency&lt;/th&gt;
&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;peter&lt;/td&gt;
&lt;td&gt;3&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;elizabeth&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;0.67&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;took&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;0.33&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;taxi&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;0.33&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;attend&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;0.33&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;night&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;0.33&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;party&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;0.67&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;city&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;0.33&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;collapse&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;0.33&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;rush&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;0.33&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;hospital&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;0.67&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;diagnose&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;0.33&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;brain&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;0.33&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;injury&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;0.33&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;doctor&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;0.33&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;told&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;0.33&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;stay&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;0.67&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;besides&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;0.33&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;get&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;0.33&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;well&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;0.33&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;days&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;0.33&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;without&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;0.33&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;leaving&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;0.33&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;&lt;strong&gt;Step 5: Substitute words with their weighted frequencies&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Let’s substitute each of the words found in the original sentences with their weighted frequencies. Then, we’ll compute their sum.&lt;/p&gt;
&lt;p&gt;Since the weighted frequencies of the insignificant words, such as stop words and special characters, which were removed during the processing stage, is zero, it’s not necessary to add them.&lt;/p&gt;
&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;Sentence&lt;/th&gt;
&lt;th&gt;Add weighted frequencies&lt;/th&gt;
&lt;th&gt;Sum&lt;/th&gt;
&lt;th/&gt;
&lt;/tr&gt;&lt;/thead&gt;&lt;tbody readability=&quot;10&quot;&gt;&lt;tr readability=&quot;4&quot;&gt;&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;Peter and Elizabeth took a taxi to attend the night party in the city&lt;/td&gt;
&lt;td&gt;1 + 0.67 + 0.33 + 0.33 + 0.33 + 0.33 + 0.67 + 0.33&lt;/td&gt;
&lt;td&gt;3.99&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;5&quot;&gt;&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;While in the party, Elizabeth collapsed and was rushed to the hospital&lt;/td&gt;
&lt;td&gt;0.67 + 0.67 + 0.33 + 0.33 + 0.67&lt;/td&gt;
&lt;td&gt;2.67&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;6&quot;&gt;&lt;td&gt;3&lt;/td&gt;
&lt;td&gt;Since she was diagnosed with a brain injury, the doctor told Peter to stay besides her until she gets well.&lt;/td&gt;
&lt;td&gt;0.33 + 0.33 + 0.33 + 0.33 + 1 + 0.33 + 0.33 + 0.33 + 0.33 +0.33&lt;/td&gt;
&lt;td&gt;3.97&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;5&quot;&gt;&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;Therefore, Peter stayed with her at the hospital for 3 days without leaving&lt;/td&gt;
&lt;td&gt;1 + 0.67 + 0.67 + 0.33 + 0.33 + 0.33&lt;/td&gt;
&lt;td&gt;3.33&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;From the sum of the weighted frequencies of the words, we can deduce that the first sentence carries the most weight in the paragraph. Therefore, it can give the best representative summary of what the paragraph is about.&lt;/p&gt;
&lt;p&gt;Furthermore, if the first sentence is combined with the third sentence, which is the second-most weighty sentence in the paragraph, a better summary can be generated.&lt;/p&gt;
&lt;p&gt;The above example just gives a basic illustration of how to perform extraction-based text summarization in machine learning. Now, let’s see how we can apply the concept above in creating a real-world summary generator.&lt;/p&gt;

&lt;p&gt;Let’s get our hands dirty by creating a text summarizer that can shorten the information found in a lengthy web article. To keep things simple, apart from Python’s &lt;a href=&quot;https://www.nltk.org/&quot; rel=&quot;noreferrer nofollow noopener&quot;&gt;NLTK toolkit&lt;/a&gt;, we’ll not use any other machine learning library.&lt;/p&gt;
&lt;p&gt;Here is the code blueprint of the summarizer:&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-python&quot;&gt;# Creating a dictionary for the word frequency table
frequency_table = _create_dictionary_table(article)

# Tokenizing the sentences
sentences = sent_tokenize(article)

# Algorithm for scoring a sentence by its words
sentence_scores = _calculate_sentence_scores(sentences, frequency_table)

# Getting the threshold
threshold = _calculate_average_score(sentence_scores)

# Producing the summary
article_summary = _get_article_summary(sentences, sentence_scores, 1.5 * threshold)

print(article_summary)
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;Here are the steps for creating a simple text summarizer in Python.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Step 1: Preparing the data&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;In this example, we want to summarize the information found on &lt;a href=&quot;https://en.wikipedia.org/wiki/20th_century&quot; rel=&quot;noreferrer nofollow noopener&quot;&gt;this&lt;/a&gt; Wikipedia article, which just gives an overview of the major happenings during the 20th century.&lt;/p&gt;
&lt;p&gt;To enable us to fetch the article’s text, we’ll use the &lt;a href=&quot;https://www.crummy.com/software/BeautifulSoup/&quot; rel=&quot;noreferrer nofollow noopener&quot;&gt;Beautiful Soup library.&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Here is the code for scraping the article’s content:&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-python&quot;&gt;import bs4 as BeautifulSoup
import urllib.request  

# Fetching the content from the URL
fetched_data = urllib.request.urlopen('https://en.wikipedia.org/wiki/20th_century')

article_read = fetched_data.read()

# Parsing the URL content and storing in a variable
article_parsed = BeautifulSoup.BeautifulSoup(article_read,'html.parser')

# Returning &amp;lt;p&amp;gt; tags
paragraphs = article_parsed.find_all('p')

article_content = ''

# Looping through the paragraphs and adding them to the variable
for p in paragraphs:  
    article_content += p.text
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;In the above code, we begin by importing the essential libraries for fetching data from the web page. The &lt;strong&gt;BeautifulSoup&lt;/strong&gt; library is used for parsing the page while the &lt;a href=&quot;https://docs.python.org/3/library/urllib.html&quot; rel=&quot;noreferrer nofollow noopener&quot;&gt;&lt;strong&gt;urllib&lt;/strong&gt; library&lt;/a&gt; is used for connecting to the page and retrieving the HTML.&lt;/p&gt;
&lt;p&gt;BeautifulSoup converts the incoming text to Unicode characters and the outgoing text to UTF-8 characters, saving you the hassle of managing different charset encodings while scraping text from the web.&lt;/p&gt;
&lt;p&gt;We’ll use the &lt;code&gt;urlopen&lt;/code&gt; function from the &lt;code&gt;urllib.request&lt;/code&gt; utility to open the web page. Then, we’ll use the &lt;code&gt;read&lt;/code&gt; function to read the scraped data object. For parsing the data, we’ll call the &lt;code&gt;BeautifulSoup&lt;/code&gt; object and pass two parameters to it; that is, the &lt;code&gt;article_read&lt;/code&gt; and the &lt;code&gt;html.parser&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;find_all&lt;/code&gt; function is used to return all the &lt;code&gt;&amp;lt;p&amp;gt;&lt;/code&gt; elements present in the HTML. Furthermore, using &lt;code&gt;.text&lt;/code&gt; enables us to select only the texts found within the &lt;code&gt;&amp;lt;p&amp;gt;&lt;/code&gt; elements.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Step 2: Processing the data&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;To ensure the scrapped textual data is as noise-free as possible, we’ll perform some basic text cleaning.  To assist us to do the processing, we’ll import a list of &lt;strong&gt;stopwords&lt;/strong&gt; from the &lt;strong&gt;nltk&lt;/strong&gt; library.&lt;/p&gt;
&lt;p&gt;We’ll also import &lt;strong&gt;PorterStemmer&lt;/strong&gt;, which is an algorithm for reducing words into their root forms. For example, &lt;em&gt;cleaning&lt;/em&gt;, &lt;em&gt;cleaned&lt;/em&gt;, and &lt;em&gt;cleaner&lt;/em&gt; can be reduced to the root &lt;em&gt;clean&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Furthermore, we’ll create a dictionary table having the frequency of occurrence of each of the words in the text. We’ll loop through the text and the corresponding words to eliminate any stop words.&lt;/p&gt;
&lt;p&gt;Then, we’ll check if the words are present in the &lt;code&gt;frequency_table&lt;/code&gt;&lt;strong&gt;.&lt;/strong&gt; If the word was previously available in the dictionary, its value is updated by 1. Otherwise, if the word is recognized for the first time, its value is set to 1.&lt;/p&gt;
&lt;p&gt;For example, the frequency table should look like the following:&lt;/p&gt;
&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;Word&lt;/th&gt;
&lt;th&gt;Frequency&lt;/th&gt;
&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;century&lt;/td&gt;
&lt;td&gt;7&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;world&lt;/td&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;United States&lt;/td&gt;
&lt;td&gt;3&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;computer&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;Here is the code:&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-python&quot;&gt;from nltk.corpus import stopwords
from nltk.stem import PorterStemmer
def _create_dictionary_table(text_string) -&amp;gt; dict:
   
    # Removing stop words
    stop_words = set(stopwords.words(&quot;english&quot;))
    
    words = word_tokenize(text_string)
    
    # Reducing words to their root form
    stem = PorterStemmer()
    
    # Creating dictionary for the word frequency table
    frequency_table = dict()
    for wd in words:
        wd = stem.stem(wd)
        if wd in stop_words:
            continue
        if wd in frequency_table:
            frequency_table[wd] += 1
        else:
            frequency_table[wd] = 1

    return frequency_table
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Step 3:  Tokenizing the article into sentences&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;To split the &lt;code&gt;article_content&lt;/code&gt; into a set of sentences, we’ll use the built-in method from the &lt;strong&gt;nltk&lt;/strong&gt; library.&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-python&quot;&gt;from nltk.tokenize import word_tokenize, sent_tokenize

sentences = sent_tokenize(article)
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Step 4: Finding the weighted frequencies of the sentences&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;To evaluate the score for every sentence in the text, we’ll be analyzing the frequency of occurrence of each term. In this case, we’ll be scoring each sentence by its words; that is, adding the frequency of each important word found in the sentence.&lt;/p&gt;
&lt;p&gt;Take a look at the following code:&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-python&quot;&gt;def _calculate_sentence_scores(sentences, frequency_table) -&amp;gt; dict:   

    # Algorithm for scoring a sentence by its words
    sentence_weight = dict()

    for sentence in sentences:
        sentence_wordcount = (len(word_tokenize(sentence)))
        sentence_wordcount_without_stop_words = 0
        for word_weight in frequency_table:
            if word_weight in sentence.lower():
                sentence_wordcount_without_stop_words += 1
                if sentence[:7] in sentence_weight:
                    sentence_weight[sentence[:7]] += frequency_table[word_weight]
                else:
                    sentence_weight[sentence[:7]] = frequency_table[word_weight]

        sentence_weight[sentence[:7]] = sentence_weight[sentence[:7]] /        sentence_wordcount_without_stop_words
      
    return sentence_weight
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;Importantly, to ensure long sentences do not have unnecessarily high scores over short sentences, we divided each score of a sentence by the number of words found in that sentence.&lt;/p&gt;
&lt;p&gt;Also, to optimize the dictionary’s memory, we arbitrarily added &lt;strong&gt;sentence[:7],&lt;/strong&gt; which refers to the first 7 characters in each sentence. However, for longer documents, where you are likely to encounter sentences with the same first &lt;code&gt;n_chars&lt;/code&gt;, it’s better to use hash functions or smart index functions to take into account such edge-cases and avoid collisions.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Step 5: Calculating the threshold of the sentences&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;To further tweak the kind of sentences eligible for summarization, we’ll create the average score for the sentences. With this threshold, we can avoid selecting the sentences with a lower score than the average score.&lt;/p&gt;
&lt;p&gt;Here is the code:&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-python&quot;&gt;def _calculate_average_score(sentence_weight) -&amp;gt; int:
   
    # Calculating the average score for the sentences
    sum_values = 0
    for entry in sentence_weight:
        sum_values += sentence_weight[entry]

    # Getting sentence average value from source text
    average_score = (sum_values / len(sentence_weight))

    return average_score
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Step 6: Getting the summary&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Lastly, since we have all the required parameters, we can now generate a summary for the article.&lt;/p&gt;
&lt;p&gt;Here is the code:&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-python&quot;&gt;def _get_article_summary(sentences, sentence_weight, threshold):
    sentence_counter = 0
    article_summary = ''

    for sentence in sentences:
        if sentence[:7] in sentence_weight and sentence_weight[sentence[:7]] &amp;gt;= (threshold):
            article_summary += &quot; &quot; + sentence
            sentence_counter += 1

    return article_summary
&lt;/code&gt;
&lt;/pre&gt;

&lt;p&gt;Here is an image that showcases the workflow for creating the summary generator.&lt;/p&gt;
&lt;img src=&quot;https://paper-attachments.dropbox.com/s_5DD7360138DEDEB8828AD11E4B5921DC0A55833560A1BC79C451FADB6E7D209D_1554467410003_image.png&quot; class=&quot;kg-image&quot;/&gt;A basic workflow of creating a summarization algorithm
&lt;p&gt;Here is the entire code for the simple extractive text summarizer in machine learning:&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-python&quot;&gt;#importing libraries
from nltk.corpus import stopwords
from nltk.stem import PorterStemmer
from nltk.tokenize import word_tokenize, sent_tokenize
import bs4 as BeautifulSoup
import urllib.request  

#fetching the content from the URL
fetched_data = urllib.request.urlopen('https://en.wikipedia.org/wiki/20th_century')

article_read = fetched_data.read()

#parsing the URL content and storing in a variable
article_parsed = BeautifulSoup.BeautifulSoup(article_read,'html.parser')

#returning &amp;lt;p&amp;gt; tags
paragraphs = article_parsed.find_all('p')

article_content = ''

#looping through the paragraphs and adding them to the variable
for p in paragraphs:  
    article_content += p.text


def _create_dictionary_table(text_string) -&amp;gt; dict:
   
    #removing stop words
    stop_words = set(stopwords.words(&quot;english&quot;))
    
    words = word_tokenize(text_string)
    
    #reducing words to their root form
    stem = PorterStemmer()
    
    #creating dictionary for the word frequency table
    frequency_table = dict()
    for wd in words:
        wd = stem.stem(wd)
        if wd in stop_words:
            continue
        if wd in frequency_table:
            frequency_table[wd] += 1
        else:
            frequency_table[wd] = 1

    return frequency_table


def _calculate_sentence_scores(sentences, frequency_table) -&amp;gt; dict:   

    #algorithm for scoring a sentence by its words
    sentence_weight = dict()

    for sentence in sentences:
        sentence_wordcount = (len(word_tokenize(sentence)))
        sentence_wordcount_without_stop_words = 0
        for word_weight in frequency_table:
            if word_weight in sentence.lower():
                sentence_wordcount_without_stop_words += 1
                if sentence[:7] in sentence_weight:
                    sentence_weight[sentence[:7]] += frequency_table[word_weight]
                else:
                    sentence_weight[sentence[:7]] = frequency_table[word_weight]

        sentence_weight[sentence[:7]] = sentence_weight[sentence[:7]] / sentence_wordcount_without_stop_words

       

    return sentence_weight

def _calculate_average_score(sentence_weight) -&amp;gt; int:
   
    #calculating the average score for the sentences
    sum_values = 0
    for entry in sentence_weight:
        sum_values += sentence_weight[entry]

    #getting sentence average value from source text
    average_score = (sum_values / len(sentence_weight))

    return average_score

def _get_article_summary(sentences, sentence_weight, threshold):
    sentence_counter = 0
    article_summary = ''

    for sentence in sentences:
        if sentence[:7] in sentence_weight and sentence_weight[sentence[:7]] &amp;gt;= (threshold):
            article_summary += &quot; &quot; + sentence
            sentence_counter += 1

    return article_summary

def _run_article_summary(article):
    
    #creating a dictionary for the word frequency table
    frequency_table = _create_dictionary_table(article)

    #tokenizing the sentences
    sentences = sent_tokenize(article)

    #algorithm for scoring a sentence by its words
    sentence_scores = _calculate_sentence_scores(sentences, frequency_table)

    #getting the threshold
    threshold = _calculate_average_score(sentence_scores)

    #producing the summary
    article_summary = _get_article_summary(sentences, sentence_scores, 1.5 * threshold)

    return article_summary

if __name__ == '__main__':
    summary_results = _run_article_summary(article_content)
    print(summary_results)
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;You can click the following button to run the code on the FloydHub Notebook:&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://floydhub.com/run?template=https://github.com/Alfrick/textsummarizationcode.git&quot;&gt;&lt;img src=&quot;https://static.floydhub.com/button/button.svg&quot; alt=&quot;Run on FloydHub&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;In this case, we applied a threshold of 1.5x of the average score. It’s the &lt;a href=&quot;https://blog.floydhub.com/guide-to-hyperparameters-search-for-deep-learning-models/&quot; rel=&quot;noreferrer nofollow noopener&quot;&gt;hyperparameter&lt;/a&gt; value that generated for us good results after a couple of trials. Of course, you can fine-tune the value according to your preferences and improve the summarization outcomes.&lt;/p&gt;
&lt;p&gt;Here is an image of the summarized version of the Wikipedia article.&lt;/p&gt;
&lt;img src=&quot;https://lh3.googleusercontent.com/rqKnxalPrqjs1l4R6chltHSqr9J3hh9IU12xWksNSmWrOvDHjbRK8YrrJ3c4Z0BD4eS0EXqVZWQ1DIiU9YYmaGfbugujuf3VK_fuAJqU9CJ_A__CWKNZ5mgS52HZuF5AV851fP8W&quot; class=&quot;kg-image&quot;/&gt;A Wikipedia article summarized using a summarization algorithm
&lt;p&gt;As you can see, running the code summarizes the lengthy Wikipedia article and gives a simplistic overview of the main happenings in the 20th century.&lt;/p&gt;
&lt;p&gt;Nonetheless, the summary generator can be improved to make it better at producing a concise and precise summary of voluminous texts.&lt;/p&gt;

&lt;p&gt;Of course, this article just brushed the surface of what you can achieve with a text summarization algorithm in machine learning.&lt;/p&gt;
&lt;p&gt;To learn more about the subject, especially about abstractive text summarization, here are some useful resources you can use:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;Is it possible to combine the two approaches (abstractive and extractive)? It is the main idea behind the &lt;a href=&quot;https://arxiv.org/pdf/1704.04368.pdf&quot;&gt;pointer-generator network&lt;/a&gt; that gets the best of both worlds by combining both extraction(pointing) and abstraction(generating).&lt;/li&gt;
&lt;/ul&gt;&lt;img src=&quot;https://blog.floydhub.com/content/images/2019/04/coverage.gif&quot; class=&quot;kg-image&quot;/&gt;Image from &quot;&lt;a href=&quot;http://www.abigailsee.com/2017/04/16/taming-rnns-for-better-summarization.html&quot;&gt;Taming Recurrent Neural Networks for Better Summarization&lt;/a&gt;&quot;
&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/1810.09305.pdf&quot; rel=&quot;noreferrer nofollow noopener&quot;&gt;How to use WikiHow, a large-scale text summarization dataset&lt;/a&gt;—This paper introduces WikiHow, a new large-scale text summarization dataset that comprises of more than 230,000 articles extracted from the WikiHow online knowledge base. Most of the presently available datasets are not large enough for training sequence-to-sequence models, they may provide only limited summaries, and they are more suited to performing extractive summarization. However, the WikiHow dataset is large-scale, high-quality, and capable of achieving optimal results in abstractive summarization.&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/1902.09243.pdf&quot; rel=&quot;noreferrer nofollow noopener&quot;&gt;How a pretraining-based encoder-decoder framework can be used in text summarization&lt;/a&gt;—This paper introduces a unique two-stage model that is based on a sequence-to-sequence paradigm. The model makes use of &lt;a href=&quot;https://arxiv.org/abs/1810.04805&quot;&gt;BERT&lt;/a&gt; (&lt;a href=&quot;https://blog.floydhub.com/ten-trends-in-deep-learning-nlp/&quot;&gt;you can bet that we will continue to read about BERT in all 2019&lt;/a&gt;) on both encoder and decoder sides and focuses on reinforced objective during the learning process. When the model was assessed on some benchmark datasets, the outcome revealed that the approach performed better at text summarization, particularly when compared to other traditional systems.&lt;/li&gt;
&lt;/ul&gt;&lt;hr/&gt;&lt;p&gt;Special appreciation to the entire team at FloydHub, especially &lt;a href=&quot;https://www.linkedin.com/in/alessio-gozzoli-530aa2109/&quot; rel=&quot;noreferrer nofollow noopener&quot;&gt;Alessio&lt;/a&gt;,  for their valuable feedback and support in enhancing the quality and the flow of this article. You guys rock!&lt;/p&gt;
&lt;hr/&gt;&lt;p&gt;&lt;strong&gt;About Alfrick Opidi&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Alfrick is a web developer with a deep interest in exploring the world of machine learning. Currently, he’s involved in projects that implement machine learning concepts in producing agile and futuristic web applications. In his free time, he engages in technical writing to demystify complex machine learning concepts for humans. See him as an all-round tech geek with a keen eye on making the latest developments in the industry accessible and fun to learn. Alfrick is also a &lt;a href=&quot;https://blog.floydhub.com/write-for-floydhub/&quot; rel=&quot;noreferrer nofollow noopener&quot;&gt;FloydHub AI Writer.&lt;/a&gt; You can find out more about him &lt;a href=&quot;http://www.alfrickopidi.com/&quot; rel=&quot;noreferrer nofollow noopener&quot;&gt;here&lt;/a&gt;. You can connect with Alfrick on &lt;a href=&quot;https://ke.linkedin.com/in/alfrick-opidi-9139a629&quot; rel=&quot;noreferrer nofollow noopener&quot;&gt;LinkedIn&lt;/a&gt; and &lt;a href=&quot;https://github.com/Alfrick&quot; rel=&quot;noreferrer nofollow noopener&quot;&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
</description>
<pubDate>Tue, 16 Apr 2019 17:47:15 +0000</pubDate>
<dc:creator>ReDeiPirati</dc:creator>
<og:type>article</og:type>
<og:title>A Gentle Introduction to Text Summarization in Machine Learning</og:title>
<og:description>Text summarization is a common in machine learning. In this article, we'll explore how to create a simple extractive text summarization algorithm.</og:description>
<og:url>https://blog.floydhub.com/gentle-introduction-to-text-summarization-in-machine-learning/</og:url>
<og:image>https://blog.floydhub.com/content/images/2019/04/romain-vignes-53940-unsplash-2.jpg</og:image>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://blog.floydhub.com/gentle-introduction-to-text-summarization-in-machine-learning/</dc:identifier>
</item>
<item>
<title>EU gives &amp;#039;high-level&amp;#039; protection to whistleblowers</title>
<link>https://www.bbc.co.uk/news/world-europe-47936682</link>
<guid isPermaLink="true" >https://www.bbc.co.uk/news/world-europe-47936682</guid>
<description>&lt;figure class=&quot;media-landscape has-caption full-width lead&quot;&gt;&lt;span class=&quot;image-and-copyright-container&quot;&gt;
                
                &lt;img class=&quot;js-image-replace&quot; alt=&quot;People hold placards reading 'stand up for the whistle-blowers', as they demonstrate outside the courthouse in Luxembourg&quot; src=&quot;https://ichef.bbci.co.uk/news/320/cpsprodpb/9E75/production/_106456504_gettyimages-524412274.jpg&quot; width=&quot;976&quot; height=&quot;549&quot;/&gt;&lt;span class=&quot;off-screen&quot;&gt;Image copyright&lt;/span&gt;
                 &lt;span class=&quot;story-image-copyright&quot;&gt;Getty Images&lt;/span&gt;
                
            &lt;/span&gt;
            
            &lt;figcaption class=&quot;media-caption&quot;&gt;&lt;span class=&quot;off-screen&quot;&gt;Image caption&lt;/span&gt;
                &lt;span class=&quot;media-caption__text&quot;&gt;
                    The legislation would mark the first time whistleblowers have been given EU-wide protection
                &lt;/span&gt;
            &lt;/figcaption&gt;&lt;/figure&gt;&lt;p class=&quot;story-body__introduction&quot;&gt;Whistleblowers across the European Union have won greater protection under landmark legislation aimed at encouraging reports of wrongdoing.&lt;/p&gt;&lt;p&gt;The new law, approved by the European Parliament on Tuesday, shields whistleblowers from retaliation.&lt;/p&gt;&lt;p&gt;It also creates &quot;safe channels&quot; to allow them to report breaches of EU law. &lt;/p&gt;&lt;p&gt;It is the first time whistleblowers have been given EU-wide protection.&lt;/p&gt;&lt;p&gt;The rules have previously been in the hands of member states, resulting in a range of vastly different approaches. &lt;/p&gt;&lt;p&gt;The law was &lt;a href=&quot;http://www.europarl.europa.eu/news/en/press-room/20190410IPR37529/protecting-whistle-blowers-new-eu-wide-rules-approved&quot; class=&quot;story-body__link-external&quot;&gt;approved by 591 votes, with 29 votes against and 33 abstentions. &lt;/a&gt;&lt;/p&gt;&lt;h2 class=&quot;story-body__crosshead&quot;&gt;What does the law say? &lt;/h2&gt;&lt;p&gt;The new legislation gives whistleblowers who report breaches of EU law a &quot;high level of protection&quot;. &lt;/p&gt;&lt;p&gt;It establishes &quot;safe channels&quot; for reporting the information, both within an organisation and to public authorities.&lt;/p&gt;&lt;p&gt;If no appropriate action is taken or in cases where reporting to the authorities would not work, whistleblowers are permitted to make a public disclosure – including by speaking to the media. &lt;/p&gt;&lt;p&gt;&lt;a href=&quot;http://www.europarl.europa.eu/RegData/docs_autres_institutions/commission_europeenne/com/2018/0218/COM_COM(2018)0218_EN.pdf&quot; class=&quot;story-body__link-external&quot;&gt;The law&lt;/a&gt; protects whistleblowers against dismissal, demotion and other forms of punishment. &lt;/p&gt;&lt;p&gt;National authorities are required to train officials in how to deal with whistleblowers under the legislation.&lt;/p&gt;&lt;hr class=&quot;story-body__line&quot;/&gt;&lt;h2 class=&quot;story-body__crosshead&quot;&gt;You may also be interested in:&lt;/h2&gt;&lt;hr class=&quot;story-body__line&quot;/&gt;&lt;h2 class=&quot;story-body__crosshead&quot;&gt;Why was it introduced?&lt;/h2&gt;&lt;p&gt;The legislation says whistleblowers play a &quot;key role&quot; in preventing breaches of EU law and protecting society.&lt;/p&gt;&lt;p&gt;But, it argues, &quot;potential whistleblowers are often discouraged from reporting their concerns or suspicions for fear of retaliation.&quot;&lt;/p&gt;&lt;p&gt;&quot;We should protect whistleblowers from being punished, sacked, demoted or sued in court for doing the right thing for society,&quot; European Commission Vice President Frans Timmermans said.&lt;/p&gt;&lt;p&gt;&quot;This will help tackle fraud, corruption, corporate tax avoidance and damage to people's health and the environment.&quot;&lt;/p&gt;&lt;p&gt;Transparency International has said the &quot;pathbreaking legislation&quot; will also give employers &quot;greater legal certainty around their rights and obligations&quot;. &lt;/p&gt;&lt;hr class=&quot;story-body__line&quot;/&gt;&lt;h2 class=&quot;story-body__crosshead&quot;&gt;High-profile leaks&lt;/h2&gt;&lt;ul class=&quot;story-body__unordered-list&quot;&gt;&lt;li class=&quot;story-body__list-item&quot;&gt;
&lt;strong&gt;LuxLeaks: &lt;/strong&gt;&lt;a href=&quot;https://www.bbc.co.uk/news/world-europe-36662636&quot; class=&quot;story-body__link&quot;&gt;Whistleblowers working for PricewaterhouseCoopers leaked documents&lt;/a&gt; exposing favourable tax arrangements offered by Luxembourg to some of the world's biggest companies while European Commission President Jean-Claude Juncker was prime minister.&lt;/li&gt;
&lt;li class=&quot;story-body__list-item&quot;&gt;
&lt;strong&gt;Paradise Papers: &lt;/strong&gt;&lt;a href=&quot;https://www.bbc.co.uk/news/world-41880153&quot; class=&quot;story-body__link&quot;&gt;Millions of financial documents were leaked&lt;/a&gt;, detailing offshore tax-avoidance schemes. The papers revealed details about how the ultra-wealthy secretly invest cash in offshore tax havens.&lt;/li&gt;
&lt;li class=&quot;story-body__list-item&quot;&gt;
&lt;strong&gt;Cambridge Analytica: &lt;/strong&gt;&lt;a href=&quot;https://www.bbc.co.uk/news/technology-43465968&quot; class=&quot;story-body__link&quot;&gt;The British data analytics company was accused of harvesting the personal data of millions of Facebook users&lt;/a&gt; without their consent.&lt;/li&gt;
&lt;li class=&quot;story-body__list-item&quot;&gt;
&lt;strong&gt;Panama Papers:&lt;/strong&gt;&lt;a href=&quot;https://www.bbc.co.uk/news/world-us-canada-46449696&quot; class=&quot;story-body__link&quot;&gt;About 11 million confidential documents were leaked from a Panamanian law firm&lt;/a&gt;, showing how it helped clients to launder money, dodge sanctions and evade tax.&lt;/li&gt;
&lt;/ul&gt;&lt;hr class=&quot;story-body__line&quot;/&gt;&lt;h2 class=&quot;story-body__crosshead&quot;&gt;What were the previous rules on whistleblowing? &lt;/h2&gt;&lt;p&gt;Laws on whistleblowing were previously handled by the individual member states, resulting in major differences in legislation across the bloc. &lt;/p&gt;&lt;p&gt;The European Commission says just 10 members - France, Hungary, Ireland, Italy, Lithuania, Malta, the Netherlands, Slovakia, Sweden and the UK - had a &quot;comprehensive law&quot; protecting whistleblowers.&lt;/p&gt;&lt;h2 class=&quot;story-body__crosshead&quot;&gt;Has everyone supported the legislation?&lt;/h2&gt;&lt;p&gt;During the talks, some states sought to water down the legislation.&lt;/p&gt;&lt;p&gt;Luxembourg, Ireland and Hungary wanted tax matters to be excluded, but they were ultimately retained, according to Reuters.&lt;/p&gt;&lt;p&gt;If member states fail to properly implement the law, the European Commission can take formal disciplinary steps against the country and could ultimately refer the case to the European Court of Justice.  &lt;/p&gt;
            </description>
<pubDate>Tue, 16 Apr 2019 15:16:01 +0000</pubDate>
<dc:creator>toyg</dc:creator>
<og:title>Whistleblowers get EU-wide protection</og:title>
<og:type>article</og:type>
<og:description>New rules approved by the European Parliament aim to encourage people to report breaches of EU law.</og:description>
<og:url>https://www.bbc.com/news/world-europe-47936682</og:url>
<og:image>https://ichef.bbci.co.uk/news/1024/branded_news/9E75/production/_106456504_gettyimages-524412274.jpg</og:image>
<dc:language>en-GB</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.bbc.co.uk/news/world-europe-47936682</dc:identifier>
</item>
<item>
<title>5G Is Likely to Put Weather Forecasting at Risk</title>
<link>https://hackaday.com/2019/04/16/5g-buildout-likely-to-put-weather-forecasting-at-risk/</link>
<guid isPermaLink="true" >https://hackaday.com/2019/04/16/5g-buildout-likely-to-put-weather-forecasting-at-risk/</guid>
<description>&lt;p&gt;If the great Samuel Clemens were alive today, he might modify the famous meteorological quip often attributed to him to read, “Everyone complains about weather forecasts, but I can’t for the life of me see why!” In his day, weather forecasting was as much guesswork as anything else, reading the clouds and the winds to see what was likely to happen in the next few hours, and being wrong as often as right. Telegraphy and better instrumentation made forecasting more scientific and improved accuracy steadily over the decades, to the point where we now enjoy 10-day forecasts that are at least good for planning purposes and three-day outlooks that are right about 90% of the time.&lt;/p&gt;
&lt;p&gt;What made this increase in accuracy possible is supercomputers running sophisticated weather modeling software. But models are only as good as the raw data that they use as input, and increasingly that data comes from on high. A constellation of satellites with extremely sensitive sensors watches the planet, detecting changes in winds and water vapor in near real-time. But if the people tasked with running these systems are to be believed, the quality of that data faces a mortal threat from an unlikely foe: the rollout of 5G cellular networks.&lt;/p&gt;

&lt;h2&gt;Where’s the Water?&lt;/h2&gt;
&lt;p&gt;To understand how a new generation of wireless technology can deleteriously impact weather forecasting, it helps to take a look at exactly what powers the weather, and what these satellites are looking at. Our weather is largely the result of differences between air masses. Pressure, temperature, and moisture, each determined by energy inputs from the Sun, all team up in a complex manner to determine where and when clouds will form and which direction the winds will come from. Remotely sensing these differences is the key to accurately forecasting the weather.&lt;/p&gt;
&lt;p&gt;The satellites that watch our weather are largely passive sensor platforms that measure the energy reflected or emitted by objects below them. They gather data on temperature and moisture — pressure is still measured chiefly by surface measurements and by radiosondes — by looking at the planet in different wavelengths. Temperature is measured mainly in the optical wavelengths, both visible and infrared, but water vapor is a bit harder to measure. That’s where microwaves come in, and where weather prediction stands to run afoul of the 5G rollout.&lt;/p&gt;
&lt;a href=&quot;https://hackaday.com/wp-content/uploads/2019/04/AMSU-A1_instrument.jpg&quot; target=&quot;_blank&quot;&gt;&lt;img data-attachment-id=&quot;354362&quot; data-permalink=&quot;https://hackaday.com/2019/04/16/5g-buildout-likely-to-put-weather-forecasting-at-risk/amsu-a1_instrument/&quot; data-orig-file=&quot;https://hackaday.com/wp-content/uploads/2019/04/AMSU-A1_instrument.jpg&quot; data-orig-size=&quot;1600,1253&quot; data-comments-opened=&quot;1&quot; data-image-meta=&quot;{&amp;quot;aperture&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;credit&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;camera&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;caption&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;created_timestamp&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;copyright&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;focal_length&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;iso&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;shutter_speed&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;title&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;orientation&amp;quot;:&amp;quot;0&amp;quot;}&quot; data-image-title=&quot;AMSU-A1_instrument&quot; data-image-description=&quot;&quot; data-medium-file=&quot;https://hackaday.com/wp-content/uploads/2019/04/AMSU-A1_instrument.jpg?w=400&quot; data-large-file=&quot;https://hackaday.com/wp-content/uploads/2019/04/AMSU-A1_instrument.jpg?w=798&quot; class=&quot;wp-image-354362 size-medium&quot; src=&quot;https://hackaday.com/wp-content/uploads/2019/04/AMSU-A1_instrument.jpg?w=400&quot; alt=&quot;&quot; width=&quot;400&quot; height=&quot;313&quot; srcset=&quot;https://hackaday.com/wp-content/uploads/2019/04/AMSU-A1_instrument.jpg 1600w, https://hackaday.com/wp-content/uploads/2019/04/AMSU-A1_instrument.jpg?resize=250,196 250w, https://hackaday.com/wp-content/uploads/2019/04/AMSU-A1_instrument.jpg?resize=400,313 400w, https://hackaday.com/wp-content/uploads/2019/04/AMSU-A1_instrument.jpg?resize=798,625 798w&quot; sizes=&quot;(max-width: 400px) 100vw, 400px&quot;/&gt;&lt;/a&gt;NASA’s Advanced Microwave Sounding Unit (ASMU-A1). Source: &lt;a href=&quot;https://www.esa.int/Our_Activities/Observing_the_Earth/Meteorological_missions/MetOp/About_AMSU-A1&quot; target=&quot;_blank&quot;&gt;ESA&lt;/a&gt;
&lt;p&gt;Everything on Earth – the plants, the soil, the surface water, and particularly the gases in the atmosphere – both absorb and, to a lesser degree, emit microwave radiation. Measuring those signals from space is the business of satellites carrying microwave radiometers, essentially sensitive radio receivers tuned to microwave frequencies. By looking at the signals received at different wavelengths, and by adding in information about the polarization of the signal, microwave radiometry can tell us what’s going on within a vertical column of the atmosphere.&lt;/p&gt;
&lt;p&gt;For water vapor, 23.8-GHz turns out to be very useful, and very much in danger of picking up interference from 5G, which will use frequencies very close to that. Since microwave radiometers are passive receivers, they’ll see pretty much everything that emits microwave signals in that range, like the thousands of cell sites that will be needed to support a full 5G rollout. Losing faint but reliable water vapor signals in a sea of 5G noise is the essential problem facing weather forecasters, and it’s one they’ve faced before.&lt;/p&gt;
&lt;h2&gt;Real World Consequences&lt;/h2&gt;
&lt;p&gt;At &lt;a href=&quot;https://ams.confex.com/ams/2019Annual/meetingapp.cgi/ModuleProgramBook/0&quot; target=&quot;_blank&quot;&gt;the 2019 annual meeting of the American Meteorological Society&lt;/a&gt;, Sidharth Misra, a research engineer at NASA’s Jet Propulsion Laboratory, presented data showing how commercial enterprises can have unintended consequences on the scientific community. Between 2004 and 2007, satellite-based microwave radiometers detected an increase in noise in a curious arc across the top of the United States. A similar signal was detected by another satellite, with the addition of huge signals being returned from the waters off each coast and the Great Lakes. The signals turned out to be reflections from geosynchronous direct TV satellites, bouncing off the surface and swamping the water vapor signals the weather satellites were trying to measure.&lt;/p&gt;
&lt;a href=&quot;https://hackaday.com/wp-content/uploads/2019/04/interference.png&quot; target=&quot;_blank&quot;&gt;&lt;img data-attachment-id=&quot;354359&quot; data-permalink=&quot;https://hackaday.com/2019/04/16/5g-buildout-likely-to-put-weather-forecasting-at-risk/interference/&quot; data-orig-file=&quot;https://hackaday.com/wp-content/uploads/2019/04/interference.png&quot; data-orig-size=&quot;1861,1012&quot; data-comments-opened=&quot;1&quot; data-image-meta=&quot;{&amp;quot;aperture&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;credit&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;camera&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;caption&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;created_timestamp&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;copyright&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;focal_length&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;iso&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;shutter_speed&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;title&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;orientation&amp;quot;:&amp;quot;0&amp;quot;}&quot; data-image-title=&quot;interference&quot; data-image-description=&quot;&quot; data-medium-file=&quot;https://hackaday.com/wp-content/uploads/2019/04/interference.png?w=400&quot; data-large-file=&quot;https://hackaday.com/wp-content/uploads/2019/04/interference.png?w=800&quot; class=&quot;wp-image-354359 size-large&quot; src=&quot;https://hackaday.com/wp-content/uploads/2019/04/interference.png?w=800&quot; alt=&quot;&quot; width=&quot;800&quot; height=&quot;435&quot; srcset=&quot;https://hackaday.com/wp-content/uploads/2019/04/interference.png 1861w, https://hackaday.com/wp-content/uploads/2019/04/interference.png?resize=250,136 250w, https://hackaday.com/wp-content/uploads/2019/04/interference.png?resize=400,218 400w, https://hackaday.com/wp-content/uploads/2019/04/interference.png?resize=800,435 800w&quot; sizes=&quot;(max-width: 800px) 100vw, 800px&quot;/&gt;&lt;/a&gt;Reflections from DTV satellites can effectively blind microwave radiometers. Source: &lt;a href=&quot;https://ams.confex.com/ams/2019Annual/videogateway.cgi/id/51518?recordingid=51518&quot; target=&quot;_blank&quot;&gt;AMS meeting panel discussion, “The Wizard Behind the Curtain?—The Important, Diverse, and Often Hidden Role of Spectrum Allocation for Current and Future Environmental Satellites and Water, Weather, and Climate”&lt;/a&gt;
&lt;p&gt;But surely the scientists are overreacting, right? Can losing one piece of data from as complex a puzzle as weather prediction really have that much of an impact? Probably yes. The water vapor data returned by microwave radiometers like the &lt;a href=&quot;https://www.esa.int/Our_Activities/Observing_the_Earth/Meteorological_missions/MetOp/About_AMSU-A1&quot; target=&quot;_blank&quot;&gt;Advanced Microwave Sounding Unit&lt;/a&gt; (AMSU) aboard a number of weather satellites is estimated to reduce the error of weather forecasts by 17%, the largest contributor by far among a group of dozens of other modalities.&lt;/p&gt;
&lt;p&gt;The loss of microwave water vapor data could have catastrophic real-world consequences. In late October of 2012, as Hurricane Sandy barreled up the East coast of the United States, forecasts showed that the storm would take a late turn to the northwest and make landfall in New Jersey. An analysis of the forecast if the microwave radiometer data had not been available showed the storm continuing in a wide arc and coming ashore in the Gulf of Maine. The availability of ASMU data five days in advance of the storm’s landfall bought civil authorities the time needed to prepare, and probably reduced the casualties caused by the “Storm of the Century”, still the deadliest storm of the 2012 season.&lt;/p&gt;
&lt;a href=&quot;https://hackaday.com/wp-content/uploads/2019/04/sandy.png&quot; target=&quot;_blank&quot;&gt;&lt;img data-attachment-id=&quot;354361&quot; data-permalink=&quot;https://hackaday.com/2019/04/16/5g-buildout-likely-to-put-weather-forecasting-at-risk/sandy/&quot; data-orig-file=&quot;https://hackaday.com/wp-content/uploads/2019/04/sandy.png&quot; data-orig-size=&quot;1159,755&quot; data-comments-opened=&quot;1&quot; data-image-meta=&quot;{&amp;quot;aperture&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;credit&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;camera&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;caption&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;created_timestamp&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;copyright&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;focal_length&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;iso&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;shutter_speed&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;title&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;orientation&amp;quot;:&amp;quot;0&amp;quot;}&quot; data-image-title=&quot;sandy&quot; data-image-description=&quot;&quot; data-medium-file=&quot;https://hackaday.com/wp-content/uploads/2019/04/sandy.png?w=400&quot; data-large-file=&quot;https://hackaday.com/wp-content/uploads/2019/04/sandy.png?w=800&quot; class=&quot;wp-image-354361 size-full&quot; src=&quot;https://hackaday.com/wp-content/uploads/2019/04/sandy.png&quot; alt=&quot;&quot; width=&quot;1159&quot; height=&quot;755&quot; srcset=&quot;https://hackaday.com/wp-content/uploads/2019/04/sandy.png 1159w, https://hackaday.com/wp-content/uploads/2019/04/sandy.png?resize=250,163 250w, https://hackaday.com/wp-content/uploads/2019/04/sandy.png?resize=400,261 400w, https://hackaday.com/wp-content/uploads/2019/04/sandy.png?resize=800,521 800w&quot; sizes=&quot;(max-width: 1159px) 100vw, 1159px&quot;/&gt;&lt;/a&gt;Superstorm Sandy would have been predicted to track into the Gulf of Maine (red) without microwave water vapor data. It actually landed in New Jersey, as predicted five days out with the satellite data (black).
&lt;h2&gt;Auction Time&lt;/h2&gt;
&lt;p&gt;So exactly where are we with this process? The &lt;a href=&quot;https://auctiondata.fcc.gov/public/projects/auction102&quot; target=&quot;_blank&quot;&gt;FCC auction&lt;/a&gt; of licenses for the Upper Microwave Flexible Use Service (UMFUS), which offers almost 3000 licenses in the 24-GHz band, began on March 14, 2019, despite a letter from NASA Administrator Jim Bridenstine and Secretary of Commerce Wilbur Ross requesting that it be delayed. FCC Chairman Ajit Pai rejected the request, stating that there was an “absence of any technical basis for the objection.”&lt;/p&gt;
&lt;p&gt;Will the 5G rollout negatively impact weather forecasts? It’s not clear. Licensees are required to limit out-of-band emissions, but with so many 5G sites needed to cover the intended service areas, and with the critical 23.8-GHz water vapor frequency so close to the UMFUS band, there’s not much room for error. And once the 5G cat is out of the bag, it’ll be difficult to protect that crucial slice of the microwave spectrum.&lt;/p&gt;
&lt;p&gt;Whatever happens, it doesn’t look good for weather forecasting. The UMFUS auction proceeds apace, and has raised almost $2 billion so far. Companies willing to spend that much on spectrum will certainly do whatever it takes to realize their investment, and in the end, not only will science likely suffer, but lives may be put at risk for the sake of 5G as our toolset for predicting dangerous weather faces this new data-gathering challenge.&lt;/p&gt;
</description>
<pubDate>Tue, 16 Apr 2019 15:02:52 +0000</pubDate>
<dc:creator>szczys</dc:creator>
<og:type>article</og:type>
<og:title>How 5G is Likely to Put Weather Forecasting at Risk</og:title>
<og:url>https://hackaday.com/2019/04/16/5g-buildout-likely-to-put-weather-forecasting-at-risk/</og:url>
<og:description>If the great Samuel Clemens were alive today, he might modify the famous meteorological quip often attributed to him to read, “Everyone complains about weather forecasts, but I can’t fo…</og:description>
<og:image>https://hackaday.com/wp-content/uploads/2019/04/5G.jpg</og:image>
<dc:language>en-US</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://hackaday.com/2019/04/16/5g-buildout-likely-to-put-weather-forecasting-at-risk/</dc:identifier>
</item>
<item>
<title>Tech Industry-Funded Think Tanks Work to Overturn California Privacy Law</title>
<link>https://theintercept.com/2019/04/16/consumer-privacy-laws-california/</link>
<guid isPermaLink="true" >https://theintercept.com/2019/04/16/consumer-privacy-laws-california/</guid>
<description>&lt;div data-reactid=&quot;195&quot; readability=&quot;167.77195281782&quot;&gt;
&lt;p&gt;&lt;u&gt;After years of&lt;/u&gt; ignoring the issue, lawmakers on Capitol Hill are suddenly engaged in a furious fight over enacting national legislation to establish basic online privacy rights for consumers. As with the crafting of much legislation dealing with complicated issues, legislators are relying on experts to help codify the consumer protections.&lt;/p&gt;
&lt;p&gt;In a twist that is all too familiar in Washington, D.C., however, many of the groups that have positioned themselves as expert voices on consumer privacy are pushing for a bill that hews closely to tech industry interests. Lawmakers who are famously ignorant on technology issues are hearing largely from an army of industry lobbyists and experts funded by social media companies, online platforms, data brokers, advertisers, and telecommunication giants — the very same corporate interests that profit from the collection and sale of internet data.&lt;/p&gt;
&lt;p&gt;Take the Center for Democracy and Technology, one of the most prominent privacy-centered Beltway think tanks. The group is considered to be well-respected among congressional staffers, &lt;a href=&quot;https://www.cnet.com/news/privacy-advocates-tell-senators-what-they-want-in-a-data-protection-law/&quot;&gt;routinely&lt;/a&gt; testifies before committees on privacy legislation, and is a prime mover in the national online privacy bill discussion.&lt;/p&gt;
&lt;p&gt;Late last year, the organization circulated draft federal privacy legislation that would &lt;a href=&quot;https://cdt.org/insight/cdts-federal-privacy-legislation-section-by-section-analysis-and-explanation/&quot;&gt;nullify&lt;/a&gt; major state-level regulations. In March, when the Senate Judiciary Committee held its first hearing of the session on how to formulate a federal consumer privacy standard, the center’s Privacy and Data Project Director Michelle Richardson testified.&lt;/p&gt;
&lt;p&gt;The Center for Democracy and Technology is also awash in corporate money from the tech sector. Amazon, Verizon, and Google are among the corporate donors that each provide over $200,000 to the group. AT&amp;amp;T, Verizon, Uber, and Twitter are also major donors.&lt;/p&gt;
&lt;p&gt;Last Wednesday, the group hosted its annual gala, known as “&lt;a href=&quot;https://twitter.com/hashtag/techpromcdt?f=tweets&amp;amp;vertical=default&amp;amp;src=hash&quot;&gt;Tech Prom&lt;/a&gt;,” which &lt;a href=&quot;https://twitter.com/SpencerOverton/status/1116141809586135040&quot;&gt;brought&lt;/a&gt; together lobbyists and government affairs officials from leading Silicon Valley and telecom firms. Facebook, Google, Amazon, and Microsoft purchased tables at the event and served as sponsors, a privilege that came in exchange for a &lt;a href=&quot;https://cdt.org/files/2019/03/Tech-Prom-2019-Sponsorships.pdf&quot;&gt;$35,000&lt;/a&gt; donation to the center.&lt;/p&gt;
&lt;blockquote class=&quot;stylized pull-right&quot; data-shortcode-type=&quot;pullquote&quot; data-pull=&quot;right&quot; readability=&quot;5&quot;&gt;
&lt;p&gt;“Every one of these groups working on privacy that takes corporate money should return it.”&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;These industry-funded think tanks are pushing legislation in a direction that would have weak enforcement mechanisms, give consumers limited means for recourse, and perhaps most importantly for the industry, roll back state-level privacy standards being enacted by state legislatures.&lt;/p&gt;
&lt;p&gt;The stakes of the online privacy fight could have ramifications the world over. American standards on data collection could shape political and business decisions across the world, said Jeff Chester, president of the Center for Digital Democracy, a privacy think tank that opposes overturning of state-level privacy laws.&lt;/p&gt;
&lt;p&gt;“This is much bigger than Cambridge Analytica,” Chester said. Cambridge Analytica was involved in a scandal when, while working on behalf of Donald Trump’s presidential campaign, the data analytics firm illicitly scraped consumer data from Facebook in order to build advanced voter-targeting methods. The events stoked outrage over Facebook’s security around its users’ private data.&lt;/p&gt;
&lt;p&gt;Chester said the money lavished by the tech industry on privacy think tanks was tantamount to funding lobbyists. “These groups should not take a dime of corporate money. This is basically lobbying dollars,” Chester said. “I think every one of these groups working on privacy that takes corporate money should return it.”&lt;/p&gt;
&lt;p&gt;Meanwhile, actual tech industry lobby groups are pushing federal legislation along the same lines as that proposed by the tech-funded think tanks. One of the largest lobbying groups for Silicon Valley, NetChoice, has &lt;a href=&quot;https://www.bloomberg.com/news/articles/2019-01-30/tech-group-favors-privacy-bill-that-preempts-tougher-state-laws&quot;&gt;rallied behind&lt;/a&gt; Sen. Marco Rubio’s, R-Fla., privacy bill. His bill would roll back state regulation and place enforcement authority largely under the Federal Trade Commission, a notoriously toothless federal agency with no rule-making power, instead of letting consumers directly sue tech companies under the law.&lt;/p&gt;
&lt;p&gt;NetChoice lobbies on behalf of Facebook, Google, Twitter, Airbnb, and eBay, among other tech companies. (Pierre Omidyar, founder of The Intercept&lt;em&gt;’&lt;/em&gt;s parent company, First Look Media, is the chair of eBay.)&lt;/p&gt;
&lt;p&gt;&lt;u&gt;The sudden moves&lt;/u&gt; around online privacy kicked into high gear with a state-level privacy law that passed in California last year. In June 2018, state legislators passed California Consumer Privacy Act, a surprise turn of events that enshrined the strongest consumer privacy standard in the country.&lt;/p&gt;
&lt;p&gt;The law, set to take effect next year, gives California residents the power to view the types of data companies collect from them, request that the data be deleted, and allows residents to declare that their data not be sold to third parties. In response, similar bills are being proposed in several &lt;a href=&quot;https://www.infosecurity-magazine.com/infosec/washington-privacy-law-1-1-1/&quot;&gt;other&lt;/a&gt; &lt;a href=&quot;https://www.lexology.com/library/detail.aspx?g=e453c554-8292-49a5-8203-a40ed60fe3ad&quot;&gt;states&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The lobbying push to &lt;a href=&quot;https://www.washingtonpost.com/technology/2019/02/08/theres-going-be-fight-here-weaken-it-inside-lobbying-war-over-californias-landmark-privacy-law/?utm_term=.3b84c6e96ab4&quot;&gt;water down&lt;/a&gt; and &lt;a href=&quot;https://www.bizjournals.com/sacramento/news/2019/03/06/silicon-valley-lobbies-hard-to-kill-off.html&quot;&gt;overturn&lt;/a&gt; the California law has been so intense that some federal legislators are raising questions about whether the urgency for a national standard is simply a vehicle for lobbyists to push pre-emption, provisions in the federal law that would supersede and roll back the state-level privacy laws.&lt;/p&gt;
&lt;p&gt;“Are we here just because we don’t like the California law, and we just want the federal pre-emption law to shut it down?” asked Sen. Maria Cantwell, D-Wash., during one of the recent hearings on the bill.&lt;/p&gt;
&lt;p&gt;The Center for Democracy and Technology’s proposal for a draft bill contained such a pre-emption provision. The proposed bill would overturn the California Consumer Privacy Act and the Illinois Biometric Information Privacy Act, which compels technology companies to obtain consent from customers before collecting biometric data, including fingerprints and facial recognition models. Both Google and Facebook could faced &lt;a href=&quot;http://fortune.com/2019/01/28/facebook-face-scanning-bipa/&quot;&gt;lawsuits&lt;/a&gt; under the Illinois law.&lt;/p&gt;
&lt;p&gt;The Center for Democracy and Technology’s vice president for external affairs, Brian Wesolowski, defended the group’s draft proposal. “It’s a stronger bill than the California one when it comes to the privacy rights of all,” he said in an email to The Intercept, adding that the group maintains “clear lines between funding and policy positions.”&lt;/p&gt;
&lt;p&gt;The proposed draft from the Center for Democracy and Technology, however, does not reproduce the California law’s right for consumers to opt out of data collection. The California law also provides consumers with what is called a private right of action — meaning that they can file a lawsuit if the state attorney general does not act when companies violate the law — while the Center for Democracy and Technology’s draft simply calls for companies to respond to complaints within 30 days.&lt;/p&gt;
&lt;/div&gt;&lt;div data-reactid=&quot;205&quot; readability=&quot;57.628034814475&quot;&gt;
&lt;p&gt;Another think tank, the Center for Information Policy Leadership, which bills itself as a leading voice on privacy, has also called for a provision pre-empting state-level laws. In a memo for policymakers &lt;a href=&quot;https://www.informationpolicycentre.com/uploads/5/7/1/0/57104281/cipl_principles_for_a_revised_us_privacy_framework__21_march_2019_.pdf&quot;&gt;released&lt;/a&gt; last month, the group said the new federal bill should “preempt a patchwork of inconsistent state laws.” Similarly, another group, the Technology Policy Institute, has asked that a federal privacy law pre-empts state regulation and explicitly called for any new national standard to have “fewer restrictions on the use of information.”&lt;/p&gt;
&lt;p&gt;Both groups receive funding from Amazon, Google, and Facebook — and both strongly defended their positions.&lt;/p&gt;
&lt;p&gt;Markus Heyder, a vice president at the Center for Information Policy Leadership, told The Intercept in an email, “CIPL’s mission is not to advocate specific industry positions, but to help develop globally consistent policies and approaches to privacy regulation that maximize both the appropriate protection of consumers from privacy risks and harms and reasonable data use and innovation.”&lt;/p&gt;
&lt;p&gt;David Fish, a spokesperson for the Technology Policy Institute, dismissed concerns about industry funding, noting that his group’s position is “not supported universally by industry.”&lt;/p&gt;
&lt;p&gt;Just like NetChoice, the tech industry lobby group, the Center for Information Policy Leadership and the Center for Democracy and Technology have both called for a weak enforcement standard that rests largely with the Federal Trade Commission.&lt;/p&gt;
&lt;p&gt;The push for pre-emption, however, is not shared by all privacy and consumer think tanks. Electronic Privacy Information Center, Public Citizen, and U.S. Public Interest Research Group are among several major advocacy organizations that have demanded that any federal standard not pre-empt state privacy law. “Federal privacy legislation that preempts stronger state laws would only benefit technology companies at the expense of the public,” the groups wrote in a &lt;a href=&quot;https://www.eff.org/document/december-2018-preemption-letter&quot;&gt;letter&lt;/a&gt; to lawmakers.&lt;/p&gt;
&lt;p&gt;Jeff Chester’s group, the Center for Digital Democracy, also signed the letter demanding a redline on pre-emption. None of the four groups that signed the letter take corporate money.&lt;/p&gt;
&lt;/div&gt;</description>
<pubDate>Tue, 16 Apr 2019 14:21:54 +0000</pubDate>
<dc:creator>aburd</dc:creator>
<og:url>https://theintercept.com/2019/04/16/consumer-privacy-laws-california/</og:url>
<og:description>Silicon Valley-funded privacy think tanks’ positions on a federal online privacy bill mirror the tech industry’s lobbying priorities.</og:description>
<og:image>https://theintercept.imgix.net/wp-uploads/sites/1/2019/04/silicon-valley-privacy-law-illustration-09-03-03-1555431940.jpg?auto=compress%2Cformat&amp;q=90&amp;fit=crop&amp;w=1200&amp;h=800</og:image>
<og:type>article</og:type>
<og:title>Silicon Valley-Funded Privacy Think Tanks Fight in D.C. to Unravel State-Level Consumer Privacy Protections</og:title>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://theintercept.com/2019/04/16/consumer-privacy-laws-california/</dc:identifier>
</item>
<item>
<title>Rust: Beyond the Typechecker</title>
<link>https://blog.merigoux.ovh/en/2019/04/16/verifying-rust.html</link>
<guid isPermaLink="true" >https://blog.merigoux.ovh/en/2019/04/16/verifying-rust.html</guid>
<description>&lt;p&gt;This post will be different from the previous ones, since I’m going to present some of the early results of my work as a PhD student at the &lt;a href=&quot;https://prosecco.gforge.inria.fr/&quot;&gt;Prosecco team&lt;/a&gt; in Inria Paris, under the supervision of &lt;a href=&quot;https://prosecco.gforge.inria.fr/personal/karthik/&quot;&gt;Karthikeyan Bhargavan&lt;/a&gt; and &lt;a href=&quot;https://jonathan.protzenko.fr/&quot;&gt;Jonathan Protzenko&lt;/a&gt;. Indeed, my goal is to bring to Rust the power of deductive verification techniques to improve the level of assurance one can have about the correctness of their programs. So far, I can present two compelling case studies from &lt;a href=&quot;https://servo.org/&quot;&gt;Servo&lt;/a&gt; that showcase what using verification techniques can look like.&lt;/p&gt;
&lt;h2 id=&quot;when-do-we-know-programs-are-correct&quot;&gt;When do we know programs are correct?&lt;/h2&gt;
&lt;p&gt;First, we have to understand what it means for a program to be correct. Usually, programs are tested on a set of selected inputs against expected outputs. If the output of one test case matches, we can be a little bit more confident that our program is correct. But how can we be sure it will work in all situations? What if our test cases missed a corner case in our algorithm?&lt;/p&gt;
&lt;p&gt;One way to increase confidence is to test the program in more systematic ways, for instance by doing unit testing or measuring the code coverage and making sure it’s 100%. Let us say that we are testing the function:&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-rust&quot; data-lang=&quot;rust&quot;&gt;&lt;span class=&quot;k&quot;&gt;fn&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;foo&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;i32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;i32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;i32&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;err&quot;&gt;...&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;Unit testing means writing tests for every sub-function used in &lt;code class=&quot;highlighter-rouge&quot;&gt;foo&lt;/code&gt;. Having a code coverage of 100% on &lt;code class=&quot;highlighter-rouge&quot;&gt;foo&lt;/code&gt; means that your test case explore all the branches in the code of &lt;code class=&quot;highlighter-rouge&quot;&gt;foo&lt;/code&gt;: if &lt;code class=&quot;highlighter-rouge&quot;&gt;foo&lt;/code&gt; contains a test &lt;code class=&quot;highlighter-rouge&quot;&gt;x + y &amp;gt; 1&lt;/code&gt;, it means we should have at least one test case where &lt;code class=&quot;highlighter-rouge&quot;&gt;x + y &amp;gt; 1&lt;/code&gt;, and one where &lt;code class=&quot;highlighter-rouge&quot;&gt;x + y &amp;lt;= 1&lt;/code&gt;. But even a 100% code coverage does not guarantee that your tests reach all the program states that could cover bugs; overflow bugs are not always detected by such testing for example.&lt;/p&gt;
&lt;p&gt;Testing a program in such a systematic way is time-consuming, and requires the programmer to create a mental model on &lt;em&gt;how the code should work&lt;/em&gt;, in order to create test cases as relevant as possible. When all the tests are written with this methodology, there are two correlated outcomes:&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;The programmer has thought about the behavior of its code for all combinations of the input variables;&lt;/li&gt;
&lt;li&gt;The level of assurance about the correctness of the code is high enough for a production release.&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;However, these methods cannot tell you if you missed something; even if you carefully test your code to prevent a certain category of bug, there will always be a possibility that a bug of this category remains hidden somewhere.&lt;/p&gt;

&lt;p&gt;At &lt;a href=&quot;https://popl19.sigplan.org/&quot;&gt;POPL19&lt;/a&gt;, Mark Harman presented Sapiens, the very sophisticated analysis tool that detect and fixes bugs over the Facebook codebase. However, &lt;a href=&quot;https://youtu.be/CbQ6bJlOU7A?t=2792&quot;&gt;he admits&lt;/a&gt; that all the static analysis and machine learning techniques used in Sapiens have so far been devoted to fix null pointer related bugs.&lt;/p&gt;
&lt;p&gt;Why doesn’t this category of bugs exist for Rust programs? Simply because you cannot write a program that contains a null-pointer error. Indeed, the &lt;code class=&quot;highlighter-rouge&quot;&gt;Option&lt;/code&gt; type forces you to declare when writing the program which values can be &lt;code class=&quot;highlighter-rouge&quot;&gt;None&lt;/code&gt; and which values cannot. By making sure you think about this beforehand, the Rust compiler guides you into thinking about what happens to &lt;code class=&quot;highlighter-rouge&quot;&gt;None&lt;/code&gt; values inside your program &lt;em&gt;for all combinations of input values&lt;/em&gt;. Thanks to that mechanism, you do not have to care anymore about null pointer errors when testing the correctness of your program.&lt;/p&gt;
&lt;p&gt;What we see here is that the type system, by rejecting at compilation time programs susceptible to be buggy, can remove whole categories of bugs out of the way, enabling resources for testing more advanced correctness properties about the program. The specificity of Rust’s type system is that it is capable of guaranteeing that your program is memory safe and data-race free, two properties associated to categories of bugs both dreaded and notoriously hard to debug in C or C++.&lt;/p&gt;
&lt;p&gt;But how can the typechecking algorithm be so sure that what it claims is true for all combinations of inputs? Let’s take another example that builds on the &lt;code class=&quot;highlighter-rouge&quot;&gt;Option&lt;/code&gt; type:&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-rust&quot; data-lang=&quot;rust&quot;&gt;&lt;span class=&quot;k&quot;&gt;fn&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;bar&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;Option&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;i32&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;Option&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;i32&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;i32&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;match&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;Some&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
      &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;Some&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;Some&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
      &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;You may have already noticed that this program is incorrect; indeed, the Rust compiler reports:&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;error[E0004]: non-exhaustive patterns: `(None, Some(_))` not covered
 --&amp;gt; src/main.rs:5:9
  |
2 |   match (x,y) {
  |         ^^^^^ pattern `(None, Some(_))` not covered&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;How can the typechecker know that you missed this pattern? Actually, what the typechecker does is that it tries to &lt;em&gt;prove&lt;/em&gt; that for all &lt;code class=&quot;highlighter-rouge&quot;&gt;x&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;y&lt;/code&gt; of types &lt;code class=&quot;highlighter-rouge&quot;&gt;Option&amp;lt;i32&amp;gt;&lt;/code&gt;, the function will return a value of type &lt;code class=&quot;highlighter-rouge&quot;&gt;i32&lt;/code&gt;. And how would you do to prove such a property in a more mathematical setting? Simply by considering all the cases associated with &lt;code class=&quot;highlighter-rouge&quot;&gt;Option&lt;/code&gt;: either &lt;code class=&quot;highlighter-rouge&quot;&gt;Some&lt;/code&gt; or &lt;code class=&quot;highlighter-rouge&quot;&gt;None&lt;/code&gt;. Two cases for two different values so 4 cases in total; since the &lt;code class=&quot;highlighter-rouge&quot;&gt;match&lt;/code&gt; statement has only 3, one case is missing.&lt;/p&gt;
&lt;p&gt;This example shows a correspondance between the code and mathematical concepts, and this idea known as the &lt;a href=&quot;https://en.wikipedia.org/wiki/Curry%E2%80%93Howard_correspondence&quot;&gt;Curry-Howard correspondence&lt;/a&gt; is the foundation of modern programming language design and research. The goal of of this field of Computer Science is to get rid of more and more categories of bugs by proving their absence from programs, and to allow programmers to specify the correctness of their programs thanks to more expressive mathematical theories.&lt;/p&gt;
&lt;h2 id=&quot;a-plan-for-bringing-verification-to-rust-developers&quot;&gt;A plan for bringing verification to Rust developers&lt;/h2&gt;
&lt;p&gt;There are multiple ways to produce software that has been verified partially or totally. A lot of very successful techniques involve writing the program into a very high-level &lt;em&gt;specification&lt;/em&gt; language for which we know exactly how every language construct behaves. However, Rust was not designed with this goal in mind and lacks such a complete and official language formalisation. The &lt;a href=&quot;http://plv.mpi-sws.org/rustbelt&quot;&gt;Rustbelt&lt;/a&gt; project has brilliantly started to tackle this problem by proving that the &lt;code class=&quot;highlighter-rouge&quot;&gt;unsafe&lt;/code&gt; part of the standard library does not put in jeopardy all the properties that &lt;code class=&quot;highlighter-rouge&quot;&gt;safe&lt;/code&gt; code using the standard library should enjoy.&lt;/p&gt;
&lt;p&gt;More recently, the team developing the Viper verification framework &lt;a href=&quot;https://www.research-collection.ethz.ch/handle/20.500.11850/311092&quot;&gt;developed a frontend for a subset of Rust&lt;/a&gt; that allows for the automatic verification of memory safety and some arithmetic properties. Internally, Viper uses a verification technique called &lt;a href=&quot;https://en.wikipedia.org/wiki/Symbolic_execution&quot;&gt;symbolic execution&lt;/a&gt;, which builds proofs completely free of any user indications.&lt;/p&gt;
&lt;p&gt;During my PhD, I will experiment with a different verification technique called deductive verification. In this setting, every function of the program has a &lt;em&gt;precondition&lt;/em&gt; (a set of things that need to be true for the function to be called) and a &lt;em&gt;postcondition&lt;/em&gt; (a set of things that need to be true at the end of the function). The verification consists in proving that the body of the function makes the postcondition true, supposing the precondition is true.&lt;/p&gt;
&lt;p&gt;How could these preconditions and post-conditions be specified in Rust? The syntax and details are &lt;a href=&quot;https://github.com/rust-lang-nursery/wg-verification/issues/14&quot;&gt;being discussed&lt;/a&gt;, but it could look like this:&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-rust&quot; data-lang=&quot;rust&quot;&gt;&lt;span class=&quot;k&quot;&gt;struct&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Point&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;i32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;i32&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;fn&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;is_diagonal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Point&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;bool&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;.x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;.y&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;cp&quot;&gt;#[requires=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;is_diagonal(p)&quot;&lt;/span&gt;&lt;span class=&quot;cp&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;cp&quot;&gt;#[ensures=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;is_diagonal(new_p)&quot;&lt;/span&gt;&lt;span class=&quot;cp&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;fn&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;double&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Point&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;new_p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Point&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;Point&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;.x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;.x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;.y&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;The function &lt;code class=&quot;highlighter-rouge&quot;&gt;is_diagonal&lt;/code&gt; is the &lt;em&gt;specification&lt;/em&gt; of the function &lt;code class=&quot;highlighter-rouge&quot;&gt;double&lt;/code&gt;, and it is not intended to be executed. Rather, it serves as a mathematical description of the function. But how to prove this postcondition? Here, we just need to prove that &lt;code class=&quot;highlighter-rouge&quot;&gt;2 * p.y == p.x + p.x&lt;/code&gt; under the assumption that &lt;code class=&quot;highlighter-rouge&quot;&gt;p.x == p.y&lt;/code&gt;. Rather than building an &lt;em&gt;ad hoc&lt;/em&gt; verification framework for Rust, I am planning to use &lt;a href=&quot;https://www.fstar-lang.org/&quot;&gt;F*&lt;/a&gt;, a semi-automatic proof assistant based on deductive verification that uses the &lt;a href=&quot;https://github.com/Z3Prover/z3&quot;&gt;Z3&lt;/a&gt; theorem prover to alleviate the proof burden for the user.&lt;/p&gt;
&lt;p&gt;Since the Rust typechecker is very powerful and already partially verified thanks to projects like Rustbelt, I will focus on verifying properties not captured by the type system of Rust. Specifically, full functional correctness with properties like arithmetic correctness, in-bounds array accesses, state machines correctness, functional correctness with respect to an abstract specification or security properties. My main PhD work will be to produce a tool, Rox*, most likely integrated in some form to the Rust compiler, that will translate Rust programs into F* code that can later be verified automatically or with additional F* user annotations.&lt;/p&gt;
&lt;p&gt;Rust is very expressive and sophisticated, so I will use a reasonable subset that allows programs meaningful enough so that verification is relevant for them. This subset will probably be built upon &lt;a href=&quot;https://arxiv.org/abs/1903.00982&quot;&gt;Oxide&lt;/a&gt;, a new formalisation that focuses on single-threaded safe code using selected primitives from the standard library. So far, I have produced two case studies that showcase how my work could improve the assurance of correctness of real-world Rust programs.&lt;/p&gt;
&lt;h2 id=&quot;case-studies--textinput-and-bloom-filter&quot;&gt;Case studies : &lt;code class=&quot;highlighter-rouge&quot;&gt;TextInput&lt;/code&gt; and bloom filter&lt;/h2&gt;
&lt;p&gt;The two case studies are taken out of the &lt;a href=&quot;https://servo.org/&quot;&gt;Servo&lt;/a&gt; project, a new parallel browser engine written in Rust and sponsored by Mozilla. They are available &lt;a href=&quot;https://github.com/denismerigoux/rox-star&quot;&gt;here&lt;/a&gt;. In each case, I identified a piece of code that could benefit from some verification; then I manually translated the Rust code into functionally equivalent pure F* code and proved some properties on the F* code that increase our confidence on the Rust code. I plan to automate this translation later but these case studies help me evaluate how this approach could work before diving in the compiler development.&lt;/p&gt;
&lt;p&gt;The two case studies are presented in two separate posts &lt;a href=&quot;https://blog.merigoux.ovh/en/2019/04/16/textinput.html&quot;&gt;here&lt;/a&gt; and &lt;a href=&quot;https://blog.merigoux.ovh/en/2019/04/16/bloom-filter.html&quot;&gt;there&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&quot;conclusion-and-future-work&quot;&gt;Conclusion and future work&lt;/h2&gt;
&lt;p&gt;These two cases studies helped me identity how verification could benefit real-world pieces of Rust code. Some properties could be specified lightly inside Rust and then be proven automatically, while others require more knowledge of a proof assistant like F*. Not all code needs a confidence level requiring verification, and most of the time systematic testing is enough. However, verification could sometimes be faster than systematic testing, and offer a peace of mind that testing will never provide. The advantage of this method is that it is incremental: you can start from a codebase that just typechecks, and then go on proving one property or invariant at a time.&lt;/p&gt;
&lt;p&gt;Different verification techniques (symbolic execution, deductive verification) each have their advantages and drawbacks that depend on what you want to prove, so it is important that a future Rust plugin for verification allows to target different verification frameworks. I am planning to use &lt;a href=&quot;https://arxiv.org/abs/1903.00982&quot;&gt;Oxide&lt;/a&gt; as a semantic-full intermediate language accessible after Rust HIR; making it a plaftorm for all the later translations.&lt;/p&gt;
&lt;p&gt;The goal of my work will not be foundational, in the sense that I am not trying to verify any properties related to the type system of Rust. I do not intend to tackle the difficult problem of interaction between unsafe and safe Rust code; &lt;a href=&quot;http://plv.mpi-sws.org/rustbelt&quot;&gt;Rustbelt&lt;/a&gt; is the correct way to do it. Rather, the focus of my PhD will be to go &lt;em&gt;beyond the typechecker&lt;/em&gt; and enable gradual verification of higher-level properties about Rust code, some examples of which can be seen in the case studies.&lt;/p&gt;
&lt;p&gt;Getting formal methods into Rust has drawn attention of a number of researchers and companies, that are gathered in the &lt;a href=&quot;https://rust-lang.zulipchat.com/#narrow/stream/183875-wg-formal-methods&quot;&gt;Rust formal methods group&lt;/a&gt;. I hope my future work will help the Rust community to get more familiar with verification techniques and how they can be efficiently used to increase the level of confidence about the correctness of various Rust programs.&lt;/p&gt;
</description>
<pubDate>Tue, 16 Apr 2019 14:18:24 +0000</pubDate>
<dc:creator>Supermighty</dc:creator>
<og:image>https://denis.merigoux.fr/en/thumbnail.jpg</og:image>
<og:title>Literal translations • Rust: beyond the typechecker</og:title>
<dc:format>text/html</dc:format>
<dc:identifier>https://blog.merigoux.ovh/en/2019/04/16/verifying-rust.html</dc:identifier>
</item>
<item>
<title>The Notre Dame fire and the future of history</title>
<link>https://www.wired.com/story/the-notre-dame-fire-and-the-future-of-history/</link>
<guid isPermaLink="true" >https://www.wired.com/story/the-notre-dame-fire-and-the-future-of-history/</guid>
<description>&lt;p&gt;&lt;span class=&quot;lede&quot;&gt;Some of the&lt;/span&gt; wood that burned in the cathedral of Notre Dame in Paris on Monday was put in place in the year 1160. The beams and exterior of the roof over the nave, the long main section of the building, date from between 1220 and 1240. Nearly a millennium ago it was forest; today, after a catastrophe that cuts to the heart of French culture and human history, it’s ash.&lt;/p&gt;
&lt;p&gt;“It was one of the oldest—until today—surviving roofs of that kind,” says Robert Bork, an architectural historian at the University of Iowa. “It’s incomparable.”&lt;/p&gt;
&lt;p class=&quot;paywall&quot;&gt;The fire began Monday evening, around 6:30 pm, in the church’s attic. The building’s familiar towers and flying buttresses loomed over the Ile de la Cité for centuries, prompting the author Victor Hugo to locate Notre Dame not only at the literal center of the city of Paris but also at its historical center, as a symbol. Flames and a column of smoke made it even more striking, and as the flames spread the potential impact of the blaze became more clear. President Emmanuel Macron canceled a speech. Four hundred firefighters mustered. The cathedral’s lead-and-wood spire, built by Eugène-Emmanuel Viollet-le-Duc in 1860 as part of a controversial remodel, caught fire and fell.&lt;/p&gt;
&lt;p class=&quot;paywall&quot;&gt;By Monday night, the art and treasured objects kept in the cathedral had been saved, it seemed. But architectural historians around the world were emailing each other frantically: If the lower three-quarters of the building resist, if the stone walls stand, it’ll be possible to imagine restoring Notre Dame. “If the fire burns out while the stone vaults are intact, then the repair is a repair,” Bork says. “If the vaults start to crack and fall down, then the building is going to be lost. We’d be talking about rebuilding, not a repair.”&lt;/p&gt;

&lt;p class=&quot;paywall&quot;&gt;Parisian fire brigades held the line. They kept the fire from spreading into the towers of the western face of the cathedral. The wood—itself an architectural treasure—was lost. “Cathedrals like Chartres had all burned off,” Bork says. “This was quite special, and it was from the time that they were really developing roof techniques.” But the rest of the building seems to have been spared.&lt;/p&gt;

&lt;p class=&quot;paywall&quot;&gt;As a landmark, Notre Dame lives on in uncountable drawings, paintings, and photographs, not to mention the memories of people who visited, worshipped, and listened to music amid its incomparable acoustics. But because it survived largely intact into the digital era, Notre Dame lives on in the virtual world, too—and that may make its restoration all the more complete. For the last half-decade or so, an architectural historian named Andrew Tallon worked with laser scanners to capture the entirety of the cathedral’s interior and exterior in meticulous &lt;a href=&quot;https://news.nationalgeographic.com/2015/06/150622-andrew-tallon-notre-dame-cathedral-laser-scan-art-history-medieval-gothic/&quot; target=&quot;_blank&quot;&gt;3D point clouds&lt;/a&gt;. His billion points of light revealed a living structure; the magnificent flying buttresses had indeed held the walls true, but the Gallery of Kings, statues on the western facade, were a foot out of plumb, Tallon told &lt;em&gt;National Geographic&lt;/em&gt; in 2015.&lt;/p&gt;
&lt;p class=&quot;paywall&quot;&gt;Just as it had in Victor Hugo's day, the entire building had in fact fallen into disrepair by then. In 2017, the problems became too serious to ignore. &lt;em&gt;The New York Times&lt;/em&gt; &lt;a href=&quot;https://www.nytimes.com/2017/09/28/world/europe/paris-notre-dame-renovation.html&quot; target=&quot;_blank&quot;&gt;reported&lt;/a&gt; on stacks of masonry, fallen or removed, in the gardens. Gargoyles had given way to plastic pipes to drain away rainwater. A remodel was imperative, though as &lt;em&gt;Time&lt;/em&gt; &lt;a href=&quot;http://time.com/4876087/notre-dame-cathedral-is-crumbling/&quot; target=&quot;_blank&quot;&gt;reported&lt;/a&gt;, it wasn’t clear who would pay for it. This is the renovation project that was underway when the fire started, and architects now hope that Tallon’s scans may provide a map for keeping on track whatever rebuilding will have to take place.&lt;/p&gt;

&lt;p class=&quot;paywall&quot;&gt;Tallon died late last year, and his mentor, a pioneer in using modern engineering forensics in historic architecture named Robert Mark, died in early 2019. “Both of them loved this building,” Bork says. “I’m just glad they didn’t have to see this.”&lt;/p&gt;
&lt;p class=&quot;paywall&quot;&gt;As for what happens next, no one seems sure yet. In a statement, Macron insisted the cathedral would be rebuilt. And even if France finds the money to do so, what exactly will that entail? An exact copy, perhaps using Tallon’s scans? Something different? “This has not ever happened before in my lifetime, so I don’t have a paradigm to go to,” Bork says. “Original hand craftsmanship is irreplaceable. When you restore it, it’s not exactly the same thing. You lose information. You can tell sometimes when a stone has been carved by the kind of chisel marks on it. You can tell sometimes the chemical content of the mortar.”&lt;/p&gt;
&lt;p class=&quot;paywall&quot;&gt;That texture and detail—and the knowledge to be gained by studying it—is what a fire burns away. A new wall doesn’t contain any of that, even if it looks exactly like what once stood. “Do we clean it up and make it all look unified, or do we try to let the memory remain?” Bork asks. “Every time they have a cathedral that needs restoration and tender loving care, there’s the question of, do you make it Disneyland, or do you let it decay? In this case, God willing, the cathedral will have some of its original structure left, and they’ll put it back as best as they can.”&lt;/p&gt;
&lt;hr class=&quot;paywall&quot;/&gt;&lt;h3 class=&quot;paywall&quot;&gt;More Great WIRED Stories&lt;/h3&gt;
</description>
<pubDate>Tue, 16 Apr 2019 13:12:18 +0000</pubDate>
<dc:creator>pricklyPaper</dc:creator>
<og:type>article</og:type>
<og:title>The Notre Dame Fire and the Future of History</og:title>
<og:description>The fire turned the thousand-year-old roof to ash. But a digital replica of the cathedral could help make its restoration all the more complete.</og:description>
<og:image>https://media.wired.com/photos/5cb4ffc3d7df712212ad11de/191:100/pass/notredamefire-RTX6RSC7.jpg</og:image>
<og:url>https://www.wired.com/story/the-notre-dame-fire-and-the-future-of-history/</og:url>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.wired.com/story/the-notre-dame-fire-and-the-future-of-history/</dc:identifier>
</item>
</channel>
</rss>