<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="css/feed.xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/" xmlns:og="http://ogp.me/ns#">
<channel>
<atom:link rel="self" href="http://192.168.1.4/fivefilters/makefulltextfeed.php?url=hnrss.org%2Fnewest%3Fpoints%3D200&amp;max=10&amp;links=preserve&amp;exc=" />
<atom:link rel="alternate" title="Source URL" href="http://hnrss.org/newest?points=200" />
<atom:link rel="related" title="Subscribe to feed" href="http://www.subtome.com/#/subscribe?feeds=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dhnrss.org%252Fnewest%253Fpoints%253D200%26max%3D10%26links%3Dpreserve%26exc%3D&amp;back=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dhnrss.org%252Fnewest%253Fpoints%253D200%26max%3D10%26links%3Dpreserve%26exc%3D" />
<title>Hacker News: Newest</title>
<link>https://news.ycombinator.com/newest</link>
<description>Hacker News RSS</description>
<item>
<title>Dear Spotify, please let me unlink my Facebook account</title>
<link>https://eduardogarcia.xyz/blog/dear-spotify</link>
<guid isPermaLink="true" >https://eduardogarcia.xyz/blog/dear-spotify</guid>
<description>&lt;nav&gt;&lt;a href=&quot;http://eduardogarcia.xyz/&quot;&gt;← Home&lt;/a&gt;&lt;/nav&gt;
&lt;h2 class=&quot;subtitle&quot;&gt;Please let me unlink my Facebook account&lt;/h2&gt;
&lt;p class=&quot;last-updated&quot;&gt;Last updated: &lt;a href=&quot;https://github.com/thewarpaint/eduardogarcia.xyz/commit/a93032575199308c02668111ff74320af03b9165&quot;&gt;October 14, 2018 &lt;code&gt;(a930325)&lt;/code&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;It was 2014. I was young and reckless. When I saw the big blue button that read &quot;Sign up with Facebook&quot; I just couldn't resist. Now, four years later, I want out.&lt;/p&gt;
&lt;p&gt;In the light of the recent &lt;a href=&quot;https://www.vox.com/2018/10/13/17973190/facebook-data-breach-29-million-users&quot;&gt;Facebook data breach&lt;/a&gt; I have decided I no longer want to use my Facebook identity to log in to your service. I am aware that the official recommendation is to &lt;a href=&quot;https://support.spotify.com/us/article/i-want-to-use-spotify-without-facebook/&quot;&gt;cancel your current account, create a new one and manually move your playlists or contact support to do it for you,&lt;/a&gt; but I believe it would be better if you offered a straightforward way to do it.&lt;/p&gt;
&lt;p&gt;As a &lt;a href=&quot;https://community.spotify.com/t5/forums/searchpage/tab/message?q=unlink%20facebook&amp;amp;collapse_discussion=true&quot;&gt;quick search on your Community site&lt;/a&gt; reveals, I am far from the only person who would like to fix this. I can assure you all of us will be very grateful if this is implemented soon.&lt;/p&gt;
&lt;p&gt;Sincerely, a Spotify user.&lt;/p&gt;
</description>
<pubDate>Sun, 14 Oct 2018 11:18:42 +0000</pubDate>
<dc:creator>thewarpaint</dc:creator>
<og:title>Dear Spotify</og:title>
<og:type>article</og:type>
<og:url>http://eduardogarcia.xyz/blog/dear-spotify.html</og:url>
<dc:format>text/html</dc:format>
<dc:identifier>https://eduardogarcia.xyz/blog/dear-spotify</dc:identifier>
</item>
<item>
<title>Show HN: Comprehensive Tutorials in Deep Learning Using TensorFlow</title>
<link>https://github.com/open-source-for-science/TensorFlow-Course</link>
<guid isPermaLink="true" >https://github.com/open-source-for-science/TensorFlow-Course</guid>
<description>&lt;div class=&quot;Box-header px-2 clearfix&quot;&gt;
&lt;h3 class=&quot;Box-title pr-3&quot;&gt;README.rst&lt;/h3&gt;
&lt;/div&gt;
&lt;div class=&quot;Box-body p-6&quot;&gt;
&lt;article class=&quot;markdown-body entry-content&quot; itemprop=&quot;text&quot;&gt;
&lt;a href=&quot;https://github.com/open-source-for-science/TensorFlow-Course/pulls&quot;&gt;&lt;img alt=&quot;https://img.shields.io/badge/contributions-welcome-brightgreen.svg?style=flat&quot; src=&quot;https://camo.githubusercontent.com/926d8ca67df15de5bd1abac234c0603d94f66c00/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f636f6e747269627574696f6e732d77656c636f6d652d627269676874677265656e2e7376673f7374796c653d666c6174&quot; data-canonical-src=&quot;https://img.shields.io/badge/contributions-welcome-brightgreen.svg?style=flat&quot;/&gt;&lt;/a&gt; &lt;a href=&quot;https://github.com/ellerbrock/open-source-badge/&quot;&gt;&lt;img alt=&quot;https://badges.frapsoft.com/os/v2/open-source.svg?v=102&quot; src=&quot;https://camo.githubusercontent.com/2091d99fb3b1ea0dcacb2ce564d5a3fc099c9ee7/68747470733a2f2f6261646765732e66726170736f66742e636f6d2f6f732f76322f6f70656e2d736f757263652e7376673f763d313032&quot; data-canonical-src=&quot;https://badges.frapsoft.com/os/v2/open-source.svg?v=102&quot;/&gt;&lt;/a&gt;
&lt;p&gt;This repository aims to provide simple and ready-to-use tutorials for TensorFlow. Each tutorial includes &lt;code&gt;source code&lt;/code&gt; and most of them are associated with a &lt;code&gt;documentation&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;&lt;a target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot; href=&quot;https://github.com/open-source-for-science/TensorFlow-Course/blob/master/_img/mainpage/TensorFlow_World.gif&quot;&gt;&lt;img alt=&quot;_img/mainpage/TensorFlow_World.gif&quot; src=&quot;https://github.com/open-source-for-science/TensorFlow-Course/raw/master/_img/mainpage/TensorFlow_World.gif&quot;/&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2&gt;Table of Contents&lt;/h2&gt;


&lt;h3&gt;&lt;a href=&quot;https://github.com/open-source-for-science/TensorFlow-Course#id1&quot;&gt;Motivation&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;There are different motivations for this open source project. TensorFlow (as we write this document) is one of / the best deep learning frameworks available. The question that should be asked is why has this repository been created when there are so many other tutorials about TensorFlow available on the web?&lt;/p&gt;

&lt;h4&gt;&lt;a href=&quot;https://github.com/open-source-for-science/TensorFlow-Course#id2&quot;&gt;Why use TensorFlow?&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;Deep Learning is in very high interest these days - there's a crucial need for rapid and optimized implementations of the algorithms and architectures. TensorFlow is designed to facilitate this goal.&lt;/p&gt;
&lt;p&gt;The strong advantage of TensorFlow is it flexibility in designing highly modular models which can also be a disadvantage for beginners since a lot of the pieces must be considered together when creating the model.&lt;/p&gt;
&lt;p&gt;This issue has been facilitated as well by developing high-level APIs such as &lt;a href=&quot;https://keras.io/&quot; rel=&quot;nofollow&quot;&gt;Keras&lt;/a&gt; and &lt;a href=&quot;https://github.com/tensorflow/models/blob/master/inception/inception/slim/README.md//&quot;&gt;Slim&lt;/a&gt; which abstract a lot of the pieces used in designing machine learning algorithms.&lt;/p&gt;
&lt;p&gt;The interesting thing about TensorFlow is that &lt;strong&gt;it can be found anywhere these days&lt;/strong&gt;. Lots of the researchers and developers are using it and &lt;em&gt;its community is growing at the speed of light&lt;/em&gt;! So many issues can be dealt with easily since they're usually the same issues that a lot of other people run into considering the large number of people involved in the TensorFlow community.&lt;/p&gt;

&lt;h4&gt;&lt;a href=&quot;https://github.com/open-source-for-science/TensorFlow-Course#id3&quot;&gt;What's the point of this repository?&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;Developing open source projects for the sake of just developing something is not the reason behind this effort&lt;/strong&gt;. Considering the large number of tutorials that are being added to this large community, this repository has been created to break the jump-in and jump-out process that usually happens to most of the open source projects, &lt;strong&gt;but why and how&lt;/strong&gt;?&lt;/p&gt;
&lt;p&gt;First of all, what's the point of putting effort into something that most of the people won't stop by and take a look? What's the point of creating something that does not help anyone in the developers and researchers community? Why spend time for something that can easily be forgotten? But &lt;strong&gt;how we try to do it?&lt;/strong&gt; Even up to this very moment there are countless tutorials on TensorFlow whether on the model design or TensorFlow workflow.&lt;/p&gt;
&lt;p&gt;Most of them are too complicated or suffer from a lack of documentation. There are only a few available tutorials which are concise and well-structured and provide enough insight for their specific implemented models.&lt;/p&gt;
&lt;p&gt;The goal of this project is to help the community with structured tutorials and simple and optimized code implementations to provide better insight about how to use TensorFlow &lt;em&gt;quick and effectively&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;It is worth noting that, &lt;strong&gt;the main goal of this project is to provide well-documented tutorials and less-complicated code&lt;/strong&gt;!&lt;/p&gt;

&lt;h3&gt;&lt;a href=&quot;https://github.com/open-source-for-science/TensorFlow-Course#id4&quot;&gt;TensorFlow Installation and Setup the Environment&lt;/a&gt;&lt;/h3&gt;
&lt;a href=&quot;https://github.com/open-source-for-science/TensorFlow-Course/blob/master/docs/tutorials/installation&quot;&gt;&lt;img alt=&quot;alternate text&quot; src=&quot;https://github.com/open-source-for-science/TensorFlow-Course/raw/master/_img/mainpage/installation-logo.gif&quot;/&gt;&lt;/a&gt;
&lt;p&gt;In order to install TensorFlow please refer to the following link:&lt;/p&gt;
&lt;blockquote&gt;
&lt;/blockquote&gt;
&lt;a href=&quot;https://www.youtube.com/watch?v=_3JFEPk4qQY&amp;amp;t=2s&quot; rel=&quot;nofollow&quot;&gt;&lt;img alt=&quot;_img/mainpage/installation.gif&quot; src=&quot;https://github.com/open-source-for-science/TensorFlow-Course/raw/master/_img/mainpage/installation.gif&quot;/&gt;&lt;/a&gt;
&lt;p&gt;The virtual environment installation is recommended in order to prevent package conflict and having the capacity to customize the working environment.&lt;/p&gt;

&lt;h3&gt;&lt;a href=&quot;https://github.com/open-source-for-science/TensorFlow-Course#id5&quot;&gt;TensorFlow Tutorials&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;The tutorials in this repository are partitioned into relevant categories.&lt;/p&gt;
&lt;hr/&gt;
&lt;h4&gt;&lt;a href=&quot;https://github.com/open-source-for-science/TensorFlow-Course#id6&quot;&gt;Warm-up&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;&lt;a target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot; href=&quot;https://github.com/open-source-for-science/TensorFlow-Course/blob/master/_img/mainpage/welcome.gif&quot;&gt;&lt;img alt=&quot;alternate text&quot; src=&quot;https://github.com/open-source-for-science/TensorFlow-Course/raw/master/_img/mainpage/welcome.gif&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;hr/&gt;
&lt;h4&gt;&lt;a href=&quot;https://github.com/open-source-for-science/TensorFlow-Course#id7&quot;&gt;Basics&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;&lt;a target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot; href=&quot;https://github.com/open-source-for-science/TensorFlow-Course/blob/master/_img/mainpage/basics.gif&quot;&gt;&lt;img alt=&quot;alternate text&quot; src=&quot;https://github.com/open-source-for-science/TensorFlow-Course/raw/master/_img/mainpage/basics.gif&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;hr/&gt;
&lt;h4&gt;&lt;a href=&quot;https://github.com/open-source-for-science/TensorFlow-Course#id8&quot;&gt;Basic Machine Learning&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;&lt;a target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot; href=&quot;https://github.com/open-source-for-science/TensorFlow-Course/blob/master/_img/mainpage/basicmodels.gif&quot;&gt;&lt;img alt=&quot;alternate text&quot; src=&quot;https://github.com/open-source-for-science/TensorFlow-Course/raw/master/_img/mainpage/basicmodels.gif&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;hr/&gt;
&lt;h4&gt;&lt;a href=&quot;https://github.com/open-source-for-science/TensorFlow-Course#id9&quot;&gt;Neural Networks&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;&lt;a target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot; href=&quot;https://github.com/open-source-for-science/TensorFlow-Course/blob/master/_img/mainpage/CNNs.png&quot;&gt;&lt;img alt=&quot;alternate text&quot; src=&quot;https://github.com/open-source-for-science/TensorFlow-Course/raw/master/_img/mainpage/CNNs.png&quot;/&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h3&gt;&lt;a href=&quot;https://github.com/open-source-for-science/TensorFlow-Course#id10&quot;&gt;Some Useful Tutorials&lt;/a&gt;&lt;/h3&gt;
&lt;blockquote&gt;
&lt;/blockquote&gt;

&lt;h3&gt;&lt;a href=&quot;https://github.com/open-source-for-science/TensorFlow-Course#id11&quot;&gt;Contributing&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;When contributing to this repository, please first discuss the change you wish to make via issue, email, or any other method with the owners of this repository before making a change. &lt;em&gt;For typos, please do not create a pull request. Instead, declare them in issues or email the repository owner&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Please note we have a code of conduct, please follow it in all your interactions with the project.&lt;/p&gt;

&lt;h4&gt;&lt;a href=&quot;https://github.com/open-source-for-science/TensorFlow-Course#id12&quot;&gt;Pull Request Process&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;Please consider the following criterions in order to help us in a better way:&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul&gt;&lt;li&gt;The pull request is mainly expected to be a code script suggestion or improvement.&lt;/li&gt;
&lt;li&gt;A pull request related to non-code-script sections is expected to make a significant difference in the documentation. Otherwise, it is expected to be announced in the issues section.&lt;/li&gt;
&lt;li&gt;Ensure any install or build dependencies are removed before the end of the layer when doing a build and creating a pull request.&lt;/li&gt;
&lt;li&gt;Add comments with details of changes to the interface, this includes new environment variables, exposed ports, useful file locations and container parameters.&lt;/li&gt;
&lt;li&gt;You may merge the Pull Request in once you have the sign-off of at least one other developer, or if you do not have permission to do that, you may request the owner to merge it for you if you believe all checks are passed.&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;

&lt;h4&gt;&lt;a href=&quot;https://github.com/open-source-for-science/TensorFlow-Course#id13&quot;&gt;Final Note&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;We are looking forward to your kind feedback. Please help us to improve this open source project and make our work better. For contribution, please create a pull request and we will investigate it promptly. Once again, we appreciate your kind feedback and elaborate code inspections.&lt;/p&gt;

&lt;h3&gt;&lt;a href=&quot;https://github.com/open-source-for-science/TensorFlow-Course#id14&quot;&gt;Acknowledgement&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;I have taken huge efforts in this project for hopefully being a small part of TensorFlow world. However, it would not have been plausible without the kind support and help of my friend and colleague &lt;a href=&quot;https://github.com/vonclites/&quot;&gt;Domenick Poster&lt;/a&gt; for his valuable advices. He helped me for having a better understanding of TensorFlow and my special appreciation goes to him. I would also like to thanks &lt;a href=&quot;http://www.hadikazemi.com/&quot; rel=&quot;nofollow&quot;&gt;Hadi Kazemi&lt;/a&gt; for his contribution to this code for developing &lt;a href=&quot;https://github.com/open-source-for-science/TensorFlow-Course/blob/master/docs/tutorials/3-neural_network/autoencoder&quot;&gt;Undercomplete Autoencoders Tutorial&lt;/a&gt;.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;
</description>
<pubDate>Sun, 14 Oct 2018 03:48:21 +0000</pubDate>
<dc:creator>irsina</dc:creator>
<og:image>https://avatars2.githubusercontent.com/u/43791934?s=400&amp;v=4</og:image>
<og:type>object</og:type>
<og:title>open-source-for-science/TensorFlow-Course</og:title>
<og:url>https://github.com/open-source-for-science/TensorFlow-Course</og:url>
<og:description>Simple and ready-to-use tutorials for TensorFlow . Contribute to open-source-for-science/TensorFlow-Course development by creating an account on GitHub.</og:description>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://github.com/open-source-for-science/TensorFlow-Course</dc:identifier>
</item>
<item>
<title>CSS Layout cookbook</title>
<link>https://developer.mozilla.org/en-US/docs/Web/CSS/Layout_cookbook</link>
<guid isPermaLink="true" >https://developer.mozilla.org/en-US/docs/Web/CSS/Layout_cookbook</guid>
<description>&lt;article id=&quot;wikiArticle&quot; readability=&quot;32.209762532982&quot;&gt;&lt;p class=&quot;summary&quot;&gt;The CSS layout cookbook aims to bring together recipes for common layout patterns, things you might need to implement in your own sites. In addition to providing code you can use as a starting point in your projects, these recipes highlight the different ways layout specifications can be used, and the choices you can make as a developer.&lt;/p&gt;
&lt;div class=&quot;note&quot; readability=&quot;7.7938144329897&quot;&gt;
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: If you are new to CSS layout then you might first like to take a look at our &lt;a href=&quot;https://developer.mozilla.org/en-US/docs/Learn/CSS/CSS_layout&quot;&gt;CSS layout learning module&lt;/a&gt;, as this will give you the basic grounding you need to make use of the recipes here.&lt;/p&gt;
&lt;/div&gt;
&lt;h2 id=&quot;The_Recipes&quot;&gt;The Recipes&lt;/h2&gt;
&lt;h2 id=&quot;Contribute_a_Recipe&quot;&gt;Contribute a Recipe&lt;/h2&gt;
&lt;p&gt;As with all of MDN we would love you to contribute a recipe in the same format as the ones shown above. &lt;a href=&quot;https://developer.mozilla.org/en-US/docs/user:chrisdavidmills/Layout_Cookbook_Home/Contribute_a_recipe&quot;&gt;See this page&lt;/a&gt; for a template and guidelines for writing your own example.&lt;/p&gt;
&lt;/article&gt;&lt;div class=&quot;wiki-block contributors&quot;&gt;
&lt;h2 class=&quot;offscreen&quot;&gt;Document Tags and Contributors&lt;/h2&gt;



&lt;/div&gt;
</description>
<pubDate>Sat, 13 Oct 2018 20:40:37 +0000</pubDate>
<dc:creator>filipoi</dc:creator>
<og:type>website</og:type>
<og:image>https://developer.mozilla.org/static/img/opengraph-logo.72382e605ce3.png</og:image>
<og:title>CSS Layout cookbook</og:title>
<og:url>https://developer.mozilla.org/en-US/docs/Web/CSS/Layout_cookbook</og:url>
<og:description>The CSS layout cookbook aims to bring together recipes for common layout patterns, things you might need to implement in your own sites. In addition to providing code you can use as a starting point in your projects, these recipes highlight the different ways layout specifications can be used, and the choices you can make as a developer.</og:description>
<dc:language>en-US</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://developer.mozilla.org/en-US/docs/Web/CSS/Layout_cookbook</dc:identifier>
</item>
<item>
<title>It’s better to be born rich than gifted</title>
<link>https://www.washingtonpost.com/business/2018/10/09/its-better-be-born-rich-than-talented/</link>
<guid isPermaLink="true" >https://www.washingtonpost.com/business/2018/10/09/its-better-be-born-rich-than-talented/</guid>
<description>&lt;div data-elm-loc=&quot;0&quot; class=&quot;inline-content inline-video&quot;&gt;

&lt;/div&gt;&lt;div class=&quot;author-sig-line-wrapper analysis-story&quot;&gt;
&lt;div class=&quot;author-headshot&quot;&gt;&lt;a href=&quot;https://www.washingtonpost.com/people/andrew-van-dam/&quot;&gt;&lt;img src=&quot;https://www.washingtonpost.com/resizer/E1gVkMT73Jp3cHBxiBFmXzp_PaM=/200x200/s3.amazonaws.com/arc-authors/washpost/7946ef20-1f6f-4a60-a396-9d01eec6b3fc.png&quot; class=&quot;&quot;/&gt;&lt;/a&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;p data-elm-loc=&quot;1&quot;&gt;A revolution in genomics is creeping into economics. It allows us to say something we might have suspected, but could never confirm: money trumps genes.&lt;/p&gt;
&lt;p data-elm-loc=&quot;2&quot;&gt;Using one new, genome-based measure, economists found genetic endowments are distributed almost equally among children in low-income and high-income families. Success is not.&lt;/p&gt;
&lt;p data-elm-loc=&quot;3&quot;&gt;The least-gifted children of high-income parents graduate from college at higher rates than the most-gifted children of low-income parents.&lt;/p&gt;
&lt;p data-elm-loc=&quot;4&quot;&gt;First, consider the people whose genome scores in the top quarter on a genetic index the researchers associated with educational achievement.&lt;/p&gt;
&lt;p data-elm-loc=&quot;5&quot;&gt;Only about 24 percent of people born to low-income fathers in that high-potential group graduate from college.&lt;/p&gt;
&lt;p data-elm-loc=&quot;6&quot;&gt;That’s dwarfed by the 63 percent college graduation rate of people with similar genetic scores who are lucky enough to be born to high-income fathers.&lt;/p&gt;
&lt;p data-elm-loc=&quot;7&quot;&gt;Contrast that with a finding from the other end of the genetic scoring scale: about 27 percent of those who score at the bottom quarter of the genetic index, but are born to high-income fathers, graduate from college. That means they’re at least as likely to graduate from college as the highest-scoring low-income students.&lt;/p&gt;
&lt;p data-elm-loc=&quot;8&quot;&gt;The application of genetics to economics is in its infancy. Limitations abound. Most notably, researchers are forced to focus on white people. The world’s genomic data comes overwhelmingly from people of European descent, and genetic comparisons across races can produce &lt;a href=&quot;https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5384097/&quot;&gt;bizarre&lt;/a&gt; results.&lt;/p&gt;
&lt;p data-elm-loc=&quot;9&quot;&gt;But it can already begin to expose truths about the economy. The figures above come from a new, genome-based study of economic data which aims straight at the heart of the popular conception of America as a meritocracy.&lt;/p&gt;
&lt;p data-elm-loc=&quot;10&quot;&gt;“It goes against the narrative that there are substantial genetic differences between people who are born into wealthy households and those born into poverty,” said Kevin Thom, a New York University economist and author of a related &lt;a href=&quot;http://www.nber.org/papers/w25114&quot;&gt;working paper released&lt;/a&gt; recently by the National Bureau of Economic Research.&lt;/p&gt;
&lt;p data-elm-loc=&quot;11&quot;&gt;“If you don’t have the family resources, even the bright kids — the kids who are naturally gifted — are going to have to face uphill battles,” Thom said.&lt;/p&gt;
&lt;div data-elm-loc=&quot;12&quot; class=&quot;inline-content inline-photo inline-photo-normal&quot;&gt; &lt;img src=&quot;https://www.washingtonpost.com/resizer/TXJKur-cQ3m4AF9lqk_kkjfemkk=/3x2/www.washingtonpost.com/pb/resources/img/spacer.gif&quot; data-hi-res-src=&quot;https://www.washingtonpost.com/resizer/92tvvCWd_jko_hJYH_jn0dP_XVU=/1484x0/arc-anglerfish-washpost-prod-washpost.s3.amazonaws.com/public/UTD3B7DY7RFBBMOPIOORHCX6YU.png&quot; data-low-res-src=&quot;https://www.washingtonpost.com/resizer/Voly5dUb765HNODRts5BccVWxDU=/480x0/arc-anglerfish-washpost-prod-washpost.s3.amazonaws.com/public/UTD3B7DY7RFBBMOPIOORHCX6YU.png&quot; data-raw-src=&quot;https://arc-anglerfish-washpost-prod-washpost.s3.amazonaws.com/public/UTD3B7DY7RFBBMOPIOORHCX6YU.png&quot; data-threshold=&quot;480&quot; class=&quot;unprocessed _3-to-2 placeholder&quot;/&gt;&lt;br/&gt;&lt;/div&gt;
&lt;p data-elm-loc=&quot;13&quot;&gt;“Their potential is being wasted. And that’s not good for them, but that’s also not good for the economy,” his collaborator, Johns Hopkins economist Nicholas Papageorge said. “All those people who didn’t go to college who had those high genetic scores, could they have cured cancer?”&lt;/p&gt;
&lt;p data-elm-loc=&quot;14&quot;&gt;Thom and Papageorge’s analysis builds on the findings of &lt;a href=&quot;https://www.nature.com/articles/s41588-018-0147-3&quot;&gt;one of the biggest genome-wide studies yet conducted&lt;/a&gt;. Published by a separate team of a dozen authors in Nature Genetics in July, it’s the latest result of a lengthy, ongoing effort to &lt;a href=&quot;https://www.thessgac.org/&quot;&gt;bring genetic analysis to the social sciences&lt;/a&gt;.&lt;/p&gt;
&lt;p data-elm-loc=&quot;15&quot;&gt;The Nature Genetics team scanned millions of individual base pairs across 1,131,881 individual genomes for evidence of correlations between genes and years of schooling completed. They synthesized the findings into a single score we can use to predict educational attainment based on genetic factors.&lt;/p&gt;
&lt;p data-elm-loc=&quot;16&quot;&gt;Thom and Papageorge studied the team’s index after it was calculated for a &lt;a href=&quot;http://hrsonline.isr.umich.edu/&quot;&gt;long-running retirement survey&lt;/a&gt; sponsored by the Social Security Administration and the National Institute on Aging. About 20,000 of the survey’s respondents, born between 1905 and 1964, provided their DNA along with their responses, which allowed the economists to attach genetic scores individuals’ academic and economic achievements.&lt;/p&gt;
&lt;p data-elm-loc=&quot;17&quot;&gt;You already know their key finding, that being born rich trumps being born gifted. But that simple finding becomes more interesting as you come to understand what makes it unique, what it represents and the important ways in which it remains limited.&lt;/p&gt;
&lt;p data-elm-loc=&quot;18&quot;&gt;Studies fueled by huge genetic data sets likely won’t upend economics like they did the biological sciences, but they do allow economists to do something new: control for the environments that people grow up in.&lt;/p&gt;
&lt;p data-elm-loc=&quot;19&quot;&gt;Previous attempts to separate academic potential from the advantages given to children of wealthy families relied on measures such as IQ tests, which are &lt;a href=&quot;https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5479093/&quot;&gt;biased&lt;/a&gt; by parents’ education, occupation and income.&lt;/p&gt;
&lt;p data-elm-loc=&quot;20&quot;&gt;Such tests can’t be administered at conception, birth or infancy &lt;strong&gt;—&lt;/strong&gt; before high-income parents have given their young children a head start by feeding them well, &lt;a href=&quot;https://www.aecf.org/resources/early-reading-proficiency-in-the-united-states/&quot;&gt;reading to them at higher rates&lt;/a&gt; and &lt;a href=&quot;https://www.nytimes.com/2015/12/18/upshot/rich-children-and-poor-ones-are-raised-very-differently.html&quot;&gt;enrolling them in more activities&lt;/a&gt;.&lt;/p&gt;
&lt;p data-elm-loc=&quot;21&quot;&gt;“Two people who are genetically similar can have strikingly different IQ test scores because the richer ones have invested more in their kids,” Papageorge said. When you look at the raw genetic potential of the two people, though, “you see they’re actually quite similar.”&lt;/p&gt;
&lt;p data-elm-loc=&quot;22&quot;&gt;The analysis doesn’t hinge on a “smart gene.” Such a thing doesn’t exist. Genes interact in mysterious ways.&lt;/p&gt;
&lt;p data-elm-loc=&quot;23&quot;&gt;Rather than linking individual lines of genetic code to specific characteristics, scientists seek correlations along the 10 million or so steps on the double-helix ladder which explain most human diversity. They focus not on what each base pair might do, but what they might explain in the aggregate.&lt;/p&gt;
&lt;p data-elm-loc=&quot;24&quot;&gt;Geneticists, who had focused on biological attributes with clear genetic connections, were initially skeptical that an outcome as complex as education could be connected to a genetic index, Thom said. But outside tests have consistently proven the score can predict college graduation rates.&lt;/p&gt;
&lt;p data-elm-loc=&quot;25&quot;&gt;Some of the individual genetic encodings influence traits including fetal brain development and lifelong neurotransmitter secretion. Each has an infinitesimal impact on an individual’s achievement. Taken together, they explain 11-13 percent of the difference in academic achievement between people.&lt;/p&gt;
&lt;p data-elm-loc=&quot;26&quot;&gt;That variation is useless if you just want to use your kid’s 23andMe data to determine whether she’ll get the PhD that you never did. But combined with a large population, it allows researchers to do things that, just a few years ago, seemed like Hocus Pocus.&lt;/p&gt;
&lt;p data-elm-loc=&quot;27&quot;&gt;“We are just starting to enter an era where researchers are finding for the first time really credible linkages between genetic markers and social science outcomes,” Thom said.&lt;/p&gt;
&lt;p data-elm-loc=&quot;28&quot;&gt;Thom was drawn into the emerging field when colleagues got him interested in genetic markers that offered a biological measure of &lt;a href=&quot;https://cupc.colorado.edu/conferences/IGSS_2014/abstracts/Smoking,%20Genes,%20and%20Health_Thom_Turley.pdf&quot;&gt;elevated smoking risk&lt;/a&gt;.&lt;/p&gt;
&lt;p data-elm-loc=&quot;29&quot;&gt;“Once I got in there, it’s clear that there are all kinds of questions” we could answer with genetic analysis, Thom said.&lt;/p&gt;
&lt;p data-elm-loc=&quot;30&quot;&gt;The techniques Thom and Papageorge used can’t yet be widely applied. Unlike the retirement survey they used, most economic data doesn’t have a genetic component. Major economic surveys like those behind the unemployment rate aren’t distributed with little saliva collection kits for genome sequencing.&lt;/p&gt;
&lt;p data-elm-loc=&quot;31&quot;&gt;And their work has limitations, in addition to being limited to white people for now. The genetic scores they used are hard to separate from their environment. They reflect the genes that were most successful when and where those individuals were growing up. And behavior that led to academic success decades ago may not be so useful when pedagogy evolves.&lt;/p&gt;
&lt;p data-elm-loc=&quot;32&quot;&gt;When the genetic index Thom and Papageorge used was tested among genomes from siblings, the results &lt;a href=&quot;https://www.thessgac.org/faqs&quot;&gt;indicated&lt;/a&gt; as much as a quarter of the variation in score could be due to genetic code that correlates with environmental factors.&lt;/p&gt;
&lt;p data-elm-loc=&quot;33&quot;&gt;There may be genes associated with parenting behavior that creates an environment conducive to your child’s success. Children with that gene would tend to succeed in school not because that gene directly helped them study, but because they received both the gene and a success-friendly environment from their parents.&lt;/p&gt;
&lt;p data-elm-loc=&quot;34&quot;&gt;It’s a reminder that the study’s key finding is also its key caveat: genes aren’t destiny. Most achievement can’t be explained by genetic factors. Environmental factors like parents’ income, on the other hand?&lt;/p&gt;
</description>
<pubDate>Sat, 13 Oct 2018 18:16:19 +0000</pubDate>
<dc:creator>joeyespo</dc:creator>
<og:type>article</og:type>
<og:url>https://www.washingtonpost.com/business/2018/10/09/its-better-be-born-rich-than-talented/</og:url>
<og:image>https://www.washingtonpost.com/resizer/5dssrU-l7HNCO7acLzE6ceROLJ8=/1484x0/arc-anglerfish-washpost-prod-washpost.s3.amazonaws.com/public/DYTFICEDUEI6RHQGJW2SVRBOAU.jpg</og:image>
<og:title>Analysis | It’s better to be born rich than gifted</og:title>
<og:description>The least-gifted children of high-income parents graduate from college at higher rates than the most-gifted children of low-income parents, and other dispatches from the point where genetics intersects with economics.</og:description>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.washingtonpost.com/business/2018/10/09/its-better-be-born-rich-than-talented/?noredirect=on</dc:identifier>
</item>
<item>
<title>Teach Yourself to Echolocate: A beginner’s guide to navigating with sound</title>
<link>https://www.atlasobscura.com/articles/how-to-echolocate</link>
<guid isPermaLink="true" >https://www.atlasobscura.com/articles/how-to-echolocate</guid>
<description>&lt;p class=&quot;item-body-text-graf&quot;&gt;&lt;span class=&quot;section-start-text&quot;&gt;Daniel Kish navigates the world&lt;/span&gt; like a bat does—and he does so without ever leaving the ground.&lt;/p&gt;&lt;p class=&quot;item-body-text-graf&quot;&gt;After losing his vision as an infant, Kish taught himself to move around with the help of echolocation. Like bats, Kish uses his mouth to produce a series of short, crisp clicking sounds, and then listens to how those sounds bounce off the surrounding landscape. (Our winged neighbors tend to emit these clicks at &lt;a href=&quot;https://www.atlasobscura.com/articles/what-does-echolocation-sound-like&quot;&gt;frequencies humans can’t hear&lt;/a&gt;, but Kish’s clicks are perfectly audible to human ears.) From there, Kish makes a mental map of his environment, considering everything from broad contours—like walls and doors—down to textural details.&lt;/p&gt;
&lt;p class=&quot;item-body-text-graf&quot;&gt;Kish now &lt;a href=&quot;https://visioneers.org/&quot;&gt;teaches echolocation&lt;/a&gt;, mostly to students who are blind. For these students, Kish believes that an echolocation practice can buoy confidence and independence. Kish’s own experience is persuasive—he famously &lt;a href=&quot;https://www.youtube.com/watch?v=xATIyq3uZM4&quot;&gt;bikes along hilly, car-lined streets&lt;/a&gt;—and a &lt;a href=&quot;https://www.ncbi.nlm.nih.gov/pubmed/23538130&quot;&gt;growing body&lt;/a&gt; of &lt;a href=&quot;http://www.ingentaconnect.com/content/dav/aaua/2009/00000095/00000002/art00013?token=004d187194fb161639412f415d763f256f45504a6c4273516f2530482972715a614f6d4e227ac&quot;&gt;scholarly research&lt;/a&gt; &lt;a href=&quot;https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005670#sec015&quot;&gt;has begun to unpack exactly how&lt;/a&gt; expert echolocaters do their thing. This research has also backed up the idea that this skill &lt;a href=&quot;https://www.wired.com/2009/06/echolocation/&quot;&gt;is highly learnable&lt;/a&gt;. When &lt;a href=&quot;https://whitneylab.berkeley.edu/publications.html&quot;&gt;researchers at the University of California, Berkeley&lt;/a&gt;, asked novice echolocators to use tongue clicks to determine which of the two objects in front of them was larger, the newbies were &lt;a href=&quot;https://www.npr.org/sections/13.7/2013/01/28/170355712/be-like-a-bat-sound-can-show-you-the-way&quot;&gt;soon able to do so&lt;/a&gt; in a way that the scientists couldn’t attribute to chance.&lt;/p&gt;
&lt;p class=&quot;item-body-text-graf&quot;&gt;Whatever your sightedness, there’s something to be said for learning to listen more attentively to sonic scenery. Kish believes that vision has a way of blunting the other senses unless people work to really flex them. Deft echolocators, he says, are able to perceive fine differences—distinguishing, say, between an oleander bush (“a million sharp returns”) and an evergreen (“wisps closely packed together, which sound like a bit like a sponge or a curtain”). They’re discovering sonic wonder wherever they go. We asked Kish to tailor a lesson for first-timers just learning to listen to the landscape.&lt;/p&gt;
&lt;h2 class=&quot;article-subheading-pre-rd&quot;&gt;&lt;strong&gt;1) Practice tuning in&lt;/strong&gt;&lt;/h2&gt;
&lt;p class=&quot;item-body-text-graf&quot;&gt;Before you begin producing your own sounds, just practice noticing the ways that sounds change around you. Try this exercise next time you’re in a car (assuming you’re not in the driver’s seat).&lt;/p&gt;
&lt;p class=&quot;item-body-text-graf&quot;&gt;Crack open the window and close your eyes. This is a good chance to pass through a varied landscape pretty quickly, and begin to differentiate between sounds. “On a residential street, you should hear the sound of the car jump in and out as you pass other parked cars, possibly trees, posts, mailboxes, or houses near the curb,” Kish says. “Everything we pass reflects the sound of our car differently.” Prime yourself to pay attention to incidental soundtracks.&lt;/p&gt;
&lt;h2 class=&quot;article-subheading-pre-rd&quot;&gt;&lt;strong&gt;2) Pick your supplies&lt;/strong&gt;&lt;/h2&gt;
&lt;p class=&quot;item-body-text-graf&quot;&gt;If you are a sighted person, you’ll want a blindfold. “It’s very, very difficult to discern these kinds of subtleties if your eyes are working at the same time,” Kish says. Occluding one sense gives the less-dominant ones room to stretch their legs.&lt;/p&gt;
&lt;p class=&quot;item-body-text-graf&quot;&gt;Now is also a good time to stock up on what you’ll need for your practice sessions. First, you’ll need a metal tray or a bowl, so make sure you’ve got one on hand. Once you start moving through space later on, it will also help to have a trekking pole or a cane, or at least a partner you trust to shout if you wander too far off base.&lt;/p&gt;
&lt;img class=&quot;article-image with-structured-caption lazy&quot; src=&quot;https://assets.atlasobscura.com/assets/blank-11b9c95a68e295dddd0ea924647536578ce285b2c8469a223c01df1ff3166af1.png&quot; alt=&quot;For beginners, the best clicks are ones that you can make cleanly and reliably.&quot; width=&quot;auto&quot; data-kind=&quot;article-image&quot; id=&quot;article-image-59920&quot; data-src=&quot;https://assets.atlasobscura.com/article_images/lg/59920/image.jpg&quot;/&gt;For beginners, the best clicks are ones that you can make cleanly and reliably.
&lt;h2 class=&quot;article-subheading-pre-rd&quot;&gt;&lt;strong&gt;3) Choose an environment&lt;/strong&gt;&lt;/h2&gt;
&lt;p class=&quot;item-body-text-graf&quot;&gt;Expert echolocators like Kish can get a bit fancier with their choices, and try to hear the character of a room. Tin decor, buttresses, or other accoutrements that might make a realtor swoon will also give Kish reason to perk up his ears. “It will sound more alive,” he says. “It will sing to you.”&lt;/p&gt;
&lt;p class=&quot;item-body-text-graf&quot;&gt;For beginners, picking the right place is a bit of a Goldilocks situation: You don’t want a flat field, where there’s nothing for sound to bounce off. Then again, you ought to steer clear of spots where your hearing will be impeded by, say, a sea of carpet. “Probably the best is a fairly quiet, open space without a lot of clutter, maybe a non-reverberant room,” Kish says.&lt;/p&gt;
&lt;h2 class=&quot;article-subheading-pre-rd&quot;&gt;&lt;strong&gt;4) Practice your clicks&lt;/strong&gt;&lt;/h2&gt;
&lt;p class=&quot;item-body-text-graf&quot;&gt;Clicks are not created equal, and some of them will work against you. “The most commonly produced rubbish click is a ‘cluck,’” Kish says. A cluck sounds something like two clicks on top of each other, which masks the returning sound. A good click can’t be sloppy, and it must be possible to reliably reproduce.&lt;/p&gt;
&lt;p class=&quot;item-body-text-graf&quot;&gt;For beginners, Kish says that a dental click fits the bill (this is a &lt;em&gt;tsk-tsk&lt;/em&gt; sound, Kish says, “like you’re disappointed”). Another contender is the sound you might use to prompt a horse to giddy-up; a “ch” sound, as in “check” or “church,” is another option.&lt;/p&gt;
&lt;p class=&quot;item-body-text-graf&quot;&gt;The key is finding the option that’s comfortable for you. “You settle on whatever click you can do, and stick to it,” Kish says.&lt;/p&gt;
&lt;img class=&quot;article-image with-structured-caption lazy&quot; src=&quot;https://assets.atlasobscura.com/assets/blank-11b9c95a68e295dddd0ea924647536578ce285b2c8469a223c01df1ff3166af1.png&quot; alt=&quot;Tune in!&quot; width=&quot;auto&quot; data-kind=&quot;article-image&quot; id=&quot;article-image-59921&quot; data-src=&quot;https://assets.atlasobscura.com/article_images/lg/59921/image.jpg&quot;/&gt;Tune in!
&lt;h2 class=&quot;article-subheading-pre-rd&quot;&gt;&lt;strong&gt;5) Start simple&lt;/strong&gt;&lt;/h2&gt;
&lt;p class=&quot;item-body-text-graf&quot;&gt;The goal with clicking is to take stock of three things. The first is presence/absence (is something there?). Then, the location (what direction is it in?). Finally, distance (how far away is it?).&lt;/p&gt;
&lt;p class=&quot;item-body-text-graf&quot;&gt;To teach these skills, Kish often starts with this exercise: Students pair up with a partner who holds a bowl or flat paddle somewhere above their head. The student clicks, turns their head, and tries to gauge where the bowl is—straight above them, or off to the side?&lt;/p&gt;
&lt;p class=&quot;item-body-text-graf&quot;&gt;Kish doesn’t click all the time—only when he needs to refresh the mental map he’s working from. For beginning students, though, it’s helpful to practice the physical mechanics of clicking, in order to learn how to listen to bouncing sounds.&lt;/p&gt;
&lt;h2 class=&quot;article-subheading-pre-rd&quot;&gt;&lt;strong&gt;6) Get moving&lt;/strong&gt;&lt;/h2&gt;
&lt;p class=&quot;item-body-text-graf&quot;&gt;The next step is to do all of this while in motion. Walk along a hallway and try to listen for differences in sounds that might indicate corners or open doors.&lt;/p&gt;
&lt;p class=&quot;item-body-text-graf&quot;&gt;At first, you’ll shuffle and fumble through this exercise, and it’s bound to be frustrating. Go ahead and ask your partner whether or not you’re on the right track—but, if you’re using a blindfold, keep it on. “The temptation is very strong to pop the blindfold off and on,” Kish says. “I resist that because there is an adaptation process that has to happen here. You disrupt it entirely when you pull off the blindfold. I wouldn’t use vision to spot-check an experience; I would try to avoid that.”&lt;/p&gt;
&lt;h2 class=&quot;article-subheading-pre-rd&quot;&gt;&lt;strong&gt;7) Stop when you need to&lt;/strong&gt;&lt;/h2&gt;
&lt;p class=&quot;item-body-text-graf&quot;&gt;Moving through the world in a new way can be both thrilling and thoroughly disorienting. Kish has found that people who are sighted, and are unaccustomed to not being able to rely on their vision, need to take breaks every 30-45 minutes. His blind students, for whom non-visual navigation is routine, can hang in longer.&lt;/p&gt;
&lt;p class=&quot;item-body-text-graf item-body-last&quot;&gt;Echolocation takes patience and practice. Kish cautions that it’s hard to get good at this—it took him years. But trying it out can open your ears to the world.&lt;/p&gt;
</description>
<pubDate>Sat, 13 Oct 2018 15:16:39 +0000</pubDate>
<dc:creator>zebraman</dc:creator>
<og:title>Teach Yourself to Echolocate</og:title>
<og:url>http://www.atlasobscura.com/articles/how-to-echolocate</og:url>
<og:image>https://assets.atlasobscura.com/media/W1siZiIsInVwbG9hZHMvYXNzZXRzL2ZiNzFlOTE1YTBkMWNmNzFjM19FY2hvbG9jYXRpb25fMi5qcGciXSxbInAiLCJjb252ZXJ0IiwiLXF1YWxpdHkgODEgLWF1dG8tb3JpZW50Il0sWyJwIiwidGh1bWIiLCI2MDB4PiJdXQ/Echolocation_2.jpg</og:image>
<og:description>A beginner's guide to navigating with sound.</og:description>
<og:type>article</og:type>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.atlasobscura.com/articles/how-to-echolocate</dc:identifier>
</item>
<item>
<title>Ask HN: 40+ Career Advice?</title>
<link>https://news.ycombinator.com/item?id=18208076</link>
<guid isPermaLink="true" >https://news.ycombinator.com/item?id=18208076</guid>
<description>&lt;tr readability=&quot;0.55737704918033&quot;&gt;&lt;td bgcolor=&quot;#FF6600&quot;&gt;
&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td/&gt;
&lt;/tr&gt;&lt;tr readability=&quot;4.7139830508475&quot;&gt;&lt;td&gt;
&lt;table class=&quot;fatitem&quot; border=&quot;0&quot; readability=&quot;4.2425847457627&quot;&gt;&lt;tr class=&quot;athing&quot; id=&quot;18208076&quot; readability=&quot;0&quot;&gt;&lt;td align=&quot;right&quot; valign=&quot;top&quot; class=&quot;title&quot;/&gt;
&lt;td valign=&quot;top&quot; class=&quot;votelinks&quot;&gt;
&lt;center&gt;

&lt;/center&gt;
&lt;/td&gt;
&lt;td class=&quot;title&quot;&gt;&lt;a href=&quot;https://news.ycombinator.com/item?id=18208076&quot; class=&quot;storylink&quot;&gt;Ask HN: 40+ Career Advice?&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;0.70588235294118&quot;&gt;&lt;td colspan=&quot;2&quot;/&gt;
&lt;td class=&quot;subtext&quot;&gt;&lt;span class=&quot;score&quot; id=&quot;score_18208076&quot;&gt;336 points&lt;/span&gt; by &lt;a href=&quot;https://news.ycombinator.com/user?id=nextstep40plus&quot; class=&quot;hnuser&quot;&gt;nextstep40plus&lt;/a&gt; &lt;span class=&quot;age&quot;&gt;&lt;a href=&quot;https://news.ycombinator.com/item?id=18208076&quot;&gt;1 day ago&lt;/a&gt;&lt;/span&gt; &lt;span id=&quot;unv_18208076&quot;/&gt; | &lt;a href=&quot;https://news.ycombinator.com/hide?id=18208076&amp;amp;goto=item%3Fid%3D18208076&quot;&gt;hide&lt;/a&gt; | &lt;a href=&quot;https://hn.algolia.com/?query=Ask%20HN%3A%2040%2B%20Career%20Advice%3F&amp;amp;sort=byDate&amp;amp;dateRange=all&amp;amp;type=story&amp;amp;storyText=false&amp;amp;prefix&amp;amp;page=0&quot; class=&quot;hnpast&quot;&gt;past&lt;/a&gt; | &lt;a href=&quot;https://www.google.com/search?q=Ask%20HN%3A%2040%2B%20Career%20Advice%3F&quot;&gt;web&lt;/a&gt; | &lt;a href=&quot;https://news.ycombinator.com/fave?id=18208076&amp;amp;auth=af70f85a6fb0df756c5ec093f7ee3ae5c70889a3&quot;&gt;favorite&lt;/a&gt; | &lt;a href=&quot;https://news.ycombinator.com/item?id=18208076&quot;&gt;201 comments&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td/&gt;
&lt;/tr&gt;&lt;tr readability=&quot;14&quot;&gt;&lt;td colspan=&quot;2&quot;/&gt;
&lt;td readability=&quot;21&quot;&gt;So many recruiters are looking for senior developers like me to join their early stage team and to do development and assist junior devs via knowledge sharing.
&lt;p&gt;But I don't want to exhaust myself helping other people. I want to do things for myself and for a client. I would prefer to get a more rewarding position:&lt;/p&gt;
&lt;p&gt;* Not in an open office * Possibility to work from home * Android + Spring Boot * Not so many meetings * No incompetent managers who induce stress to people * Colleagues who are calm and quiet but enough sociable to perhaps grab an occasional beer and have a nice chat&lt;/p&gt;
&lt;p&gt;Do these kinds of jobs exist? Do you suggest I go solo and take on development jobs myself? I think part of the problem is that many companies around expect the workplace to have open office and so on and many cannot provide me with a work environment I can thrive in.&lt;/p&gt;
&lt;p&gt;I'm 40 years old without any children and would like to be able to not be stressed and work overtime and solve hard technical problems and move towards a more rewarding job where it's not so stressful but interesting creatively and my work is valued so that I can balance well with my life.&lt;/p&gt;
&lt;p&gt;Do you understand my question? I don't want to take on roles that people want me to do but find jobs (by your insightful ideas) that suit me better. Thank you!&lt;/p&gt;
&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td/&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td colspan=&quot;2&quot;/&gt;
&lt;td&gt;

&lt;/td&gt;
&lt;/tr&gt;&lt;/table&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;1&quot;&gt;&lt;td&gt;&lt;img src=&quot;https://news.ycombinator.com/s.gif&quot; height=&quot;10&quot; width=&quot;0&quot;/&gt;&lt;br/&gt;&lt;center&gt;&lt;span class=&quot;yclinks&quot;&gt;&lt;a href=&quot;https://news.ycombinator.com/newsguidelines.html&quot;&gt;Guidelines&lt;/a&gt; | &lt;a href=&quot;https://news.ycombinator.com/newsfaq.html&quot;&gt;FAQ&lt;/a&gt; | &lt;a href=&quot;mailto:hn@ycombinator.com&quot;&gt;Support&lt;/a&gt; | &lt;a href=&quot;https://github.com/HackerNews/API&quot;&gt;API&lt;/a&gt; | &lt;a href=&quot;https://news.ycombinator.com/security.html&quot;&gt;Security&lt;/a&gt; | &lt;a href=&quot;https://news.ycombinator.com/lists&quot;&gt;Lists&lt;/a&gt; | &lt;a href=&quot;https://news.ycombinator.com/bookmarklet.html&quot; rel=&quot;nofollow&quot;&gt;Bookmarklet&lt;/a&gt; | &lt;a href=&quot;http://www.ycombinator.com/legal/&quot;&gt;Legal&lt;/a&gt; | &lt;a href=&quot;http://www.ycombinator.com/apply/&quot;&gt;Apply to YC&lt;/a&gt; | &lt;a href=&quot;mailto:hn@ycombinator.com&quot;&gt;Contact&lt;/a&gt;&lt;/span&gt;
&lt;/center&gt;
&lt;/td&gt;
&lt;/tr&gt;</description>
<pubDate>Sat, 13 Oct 2018 14:25:18 +0000</pubDate>
<dc:creator>nextstep40plus</dc:creator>
<dc:format>text/html</dc:format>
<dc:identifier>https://news.ycombinator.com/item?id=18208076</dc:identifier>
</item>
<item>
<title>The Reason We Haven’t Directly Detected Dark Matter</title>
<link>https://medium.com/starts-with-a-bang/this-is-the-real-reason-we-havent-directly-detected-dark-matter-3d04021b314e</link>
<guid isPermaLink="true" >https://medium.com/starts-with-a-bang/this-is-the-real-reason-we-havent-directly-detected-dark-matter-3d04021b314e</guid>
<description>&lt;p name=&quot;1f7d&quot; id=&quot;1f7d&quot; class=&quot;graf graf--p graf--leading&quot;&gt;You can’t get mad at a team for trying the improbable, hoping that nature cooperates. Some of the most famous discoveries of all time have come about thanks to nothing more than mere serendipity, and so if we can test something at low-cost with an insanely high reward, we tend to go for it. Believe it or not, that’s the mindset that’s driving the direct searches for dark matter.&lt;/p&gt;
&lt;p name=&quot;120c&quot; id=&quot;120c&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;In order to understand how to find dark matter, however, you have to first understand what we know so far, and what the evidence points to as far as direct detection goes. We haven’t found it yet, but that’s okay. Not finding dark matter in an experiment is not evidence that dark matter doesn’t exist. The indirect evidence all shows that it’s real. The question before us is how to demonstrate its reality, hopefully by finding the particle responsible for it directly.&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;0*kJG3wtaFzU-GkyBW.jpg&quot; data-width=&quot;960&quot; data-height=&quot;583&quot; data-action=&quot;zoom&quot; data-action-value=&quot;0*kJG3wtaFzU-GkyBW.jpg&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/0*kJG3wtaFzU-GkyBW.jpg&quot;/&gt;&lt;/div&gt;
&lt;em class=&quot;markup--em markup--figure-em&quot;&gt;The particles and antiparticles of the Standard Model of particle physics are exactly in line with what experiments require, with only massive neutrinos providing a difficulty and requiring beyond-the-standard-model physics. Dark matter, whatever it is, cannot be any one of these particles, nor can it be a composite of these particles.&lt;/em&gt; (E. SIEGEL / BEYOND THE GALAXY)
&lt;p name=&quot;a089&quot; id=&quot;a089&quot; class=&quot;graf graf--p graf-after--figure&quot;&gt;Let’s begin with a basic recap of dark matter: the idea, the motivation, the observations, the theory and then we’ll talk about the hunt.&lt;/p&gt;
&lt;p name=&quot;d98a&quot; id=&quot;d98a&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;&lt;strong class=&quot;markup--strong markup--p-strong&quot;&gt;The idea&lt;/strong&gt;. You know the basics: there are all the protons, neutrons and electrons that make up our bodies, our planet and all the matter we’re familiar with, as well as some photons (light, radiation, etc.) thrown in there for good measure. Protons and neutrons can be broken up into even more fundamental particles — the quarks and gluons — and along with the other Standard Model particles, make up all the known matter in the Universe.&lt;/p&gt;
&lt;p name=&quot;85f4&quot; id=&quot;85f4&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;The big idea of dark matter is that there’s something other than these known particles contributing in a significant way to the total amounts of matter in the Universe. Why would we think such a thing?&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;0*M8KTw6rjW4T3Gtl2.jpg&quot; data-width=&quot;960&quot; data-height=&quot;766&quot; data-action=&quot;zoom&quot; data-action-value=&quot;0*M8KTw6rjW4T3Gtl2.jpg&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/0*M8KTw6rjW4T3Gtl2.jpg&quot;/&gt;&lt;/div&gt;
&lt;em class=&quot;markup--em markup--figure-em&quot;&gt;The two bright, large galaxies at the center of the Coma Cluster, NGC 4889 (left) and the slightly smaller NGC 4874 (right), each exceed a million light years in size. But the galaxies on the outskirts, zipping around so rapidly, points to the existence of a large halo of dark matter throughout the entire cluster.&lt;/em&gt; (ADAM BLOCK/MOUNT LEMMON SKYCENTER/UNIVERSITY OF ARIZONA)
&lt;p name=&quot;962d&quot; id=&quot;962d&quot; class=&quot;graf graf--p graf-after--figure&quot;&gt;&lt;strong class=&quot;markup--strong markup--p-strong&quot;&gt;The motivation&lt;/strong&gt;. We know how stars work, and we know how gravity works. If we look at galaxies, clusters of galaxies and go all the way up to the largest-scale structures in the Universe, we can extrapolate two things. One: how much mass there is in these structures at every level. We look at the motions of these objects, we look at the gravitational rules that govern orbiting bodies, whether something is bound or not, how it rotates, how structure forms, etc., and we get a number for how much matter there has to be in there. Two: we know how stars work, so as long as we can measure the starlight coming from these objects, we can know how much mass is there in stars.&lt;/p&gt;
&lt;p name=&quot;985a&quot; id=&quot;985a&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;These two numbers don’t match, and they don’t match spectacularly. There had to be something more than just stars responsible for the vast majority of mass in the Universe. This is true for the stars within individual galaxies of all sizes all the way up to the largest clusters of thousands of galaxies in the Universe.&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;0*Ut7-yssc_5VqrmJv.jpg&quot; data-width=&quot;960&quot; data-height=&quot;1309&quot; data-action=&quot;zoom&quot; data-action-value=&quot;0*Ut7-yssc_5VqrmJv.jpg&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/0*Ut7-yssc_5VqrmJv.jpg&quot;/&gt;&lt;/div&gt;
&lt;em class=&quot;markup--em markup--figure-em&quot;&gt;The predicted abundances of helium-4, deuterium, helium-3 and lithium-7 as predicted by Big Bang Nucleosynthesis, with observations shown in the red circles. The Universe is 75–76% hydrogen, 24–25% helium, a little bit of deuterium and helium-3, and a trace amount of lithium by mass. After tritium and beryllium decay away, this is what we’re left with, and this remains unchanged until stars form. Only about 1/6th of the Universe’s matter can be in the form of this normal (baryonic, or atom-like) matter.&lt;/em&gt; (NASA / WMAP SCIENCE TEAM)
&lt;p name=&quot;c410&quot; id=&quot;c410&quot; class=&quot;graf graf--p graf-after--figure&quot;&gt;&lt;strong class=&quot;markup--strong markup--p-strong&quot;&gt;The observations&lt;/strong&gt;. This is where it gets fun, because there are a ton of them; I’ll focus on just three. When we extrapolate the laws of physics all the way back to the earliest times in the Universe, we find that there was not only a time so early when the Universe was hot enough that neutral atoms couldn’t form, but there was a time where even nuclei couldn’t form! The formation of the first elements in the Universe after the Big Bang — due to Big Bang Nucleosynthesis — tells us with very, very small errors how much total “normal matter” is there in the Universe. Although there is significantly more than what’s around in stars, it’s only about one-sixth of the total amount of matter we know is there.&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;0*7CLouVQP8DVKdzrH.jpg&quot; data-width=&quot;960&quot; data-height=&quot;479&quot; data-action=&quot;zoom&quot; data-action-value=&quot;0*7CLouVQP8DVKdzrH.jpg&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/0*7CLouVQP8DVKdzrH.jpg&quot;/&gt;&lt;/div&gt;
&lt;em class=&quot;markup--em markup--figure-em&quot;&gt;The fluctuations in the Cosmic Microwave Background were first measured accurately by COBE in the 1990s, then more accurately by WMAP in the 2000s and Planck (above) in the 2010s. This image encodes a huge amount of information about the early Universe, including its composition, age, and history. The fluctuations are only tens to hundreds of microkelvin in magnitude, but definitively point to the existence of both normal and dark matter in a 1:5 ratio.&lt;/em&gt; (ESA AND THE PLANCK COLLABORATION)
&lt;p name=&quot;7989&quot; id=&quot;7989&quot; class=&quot;graf graf--p graf-after--figure&quot;&gt;The fluctuations in the cosmic microwave background are particularly interesting. They tell us what fraction of the Universe is in the form of normal (protons+neutrons+electrons) matter, what fraction is in radiation, and what fraction is in non-normal, or dark matter, among other things. Again, they give us that same ratio: that dark matter is about five-sixths of all the matter in the Universe.&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;0*7mXxfRk5VCtYNtPO.jpg&quot; data-width=&quot;960&quot; data-height=&quot;626&quot; data-action=&quot;zoom&quot; data-action-value=&quot;0*7mXxfRk5VCtYNtPO.jpg&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/0*7mXxfRk5VCtYNtPO.jpg&quot;/&gt;&lt;/div&gt;
&lt;em class=&quot;markup--em markup--figure-em&quot;&gt;The observations of baryon acoustic oscillations in the magnitude where they’re seen, on large scales, indicate that the Universe is made of mostly dark matter, with only a small percentage of normal matter causing these ‘wiggles’ in the graph above.&lt;/em&gt; (MICHAEL KUHLEN, MARK VOGELSBERGER, AND RAUL ANGULO)
&lt;p name=&quot;97da&quot; id=&quot;97da&quot; class=&quot;graf graf--p graf-after--figure&quot;&gt;And finally, there’s how structure forms on the largest scales. This is particularly important, because we can not only see the ratio of normal-to-dark matter in the magnitude of the wiggles in the graph above, but we can tell that the dark matter is cold, or moving below a certain speed even when the Universe is very young. This pieces of knowledge lead to outstanding, precise theoretical predictions.&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;0*WBBi-Ga24eBu2-G0.jpg&quot; data-width=&quot;960&quot; data-height=&quot;535&quot; data-action=&quot;zoom&quot; data-action-value=&quot;0*WBBi-Ga24eBu2-G0.jpg&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/0*WBBi-Ga24eBu2-G0.jpg&quot;/&gt;&lt;/div&gt;
&lt;em class=&quot;markup--em markup--figure-em&quot;&gt;According to models and simulations, all galaxies should be embedded in dark matter halos, whose densities peak at the galactic centers. On long enough timescales, of perhaps a billion years, a single dark matter particle from the outskirts of the halo will complete one orbit. The effects of gas, feedback, star formation, supernovae, and radiation all complicate this environment, making it extremely difficult to extract universal dark matter predictions.&lt;/em&gt;(NASA, ESA, AND T. BROWN AND J. TUMLINSON (STSCI))
&lt;p name=&quot;b709&quot; id=&quot;b709&quot; class=&quot;graf graf--p graf-after--figure&quot;&gt;&lt;strong class=&quot;markup--strong markup--p-strong&quot;&gt;The theory&lt;/strong&gt;. This tells us that around every galaxy and cluster of galaxies, there should be an extremely large, diffuse halo of dark matter. This dark matter should have practically no “collisions” with normal matter — upper limits indicate that it would take light-years of solid lead for a dark matter particle to have a 50/50 shot of interacting just once — there should be plenty of dark matter particles passing undetected through Earth, me and you every second, and dark matter should also not collide or interact with itself, the way normal matter does.&lt;/p&gt;
&lt;p name=&quot;01f8&quot; id=&quot;01f8&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;There are some indirect ways of detecting this: the first is to study what’s called gravitational lensing.&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;0*gdEy-FKIt5SoL5GE.jpg&quot; data-width=&quot;960&quot; data-height=&quot;686&quot; data-action=&quot;zoom&quot; data-action-value=&quot;0*gdEy-FKIt5SoL5GE.jpg&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/0*gdEy-FKIt5SoL5GE.jpg&quot;/&gt;&lt;/div&gt;
&lt;em class=&quot;markup--em markup--figure-em&quot;&gt;When there are bright, massive galaxies in the background of a cluster, their light will get stretched, magnified and distorted due to the general relativistic effects known as gravitational lensing.&lt;/em&gt; (NASA, ESA, AND JOHAN RICHARD (CALTECH, USA) ACKNOWLEDGEMENT: DAVIDE DE MARTIN &amp;amp; JAMES LONG (ESA / HUBBLE)NASA, ESA, AND J. LOTZ AND THE HFF TEAM, STSCI)
&lt;p name=&quot;58c3&quot; id=&quot;58c3&quot; class=&quot;graf graf--p graf-after--figure&quot;&gt;By looking at how the background light gets distorted by the presence of intervening mass (solely from the laws of general relativity), we can reconstruct how much mass is in that object. There’s got to be dark matter in there, but from looking at colliding clusters of galaxies, we learn something even more profound.&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;0*z-MFw0j_XQ3Y50IC.jpg&quot; data-width=&quot;960&quot; data-height=&quot;694&quot; data-action=&quot;zoom&quot; data-action-value=&quot;0*z-MFw0j_XQ3Y50IC.jpg&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/0*z-MFw0j_XQ3Y50IC.jpg&quot;/&gt;&lt;/div&gt;
&lt;em class=&quot;markup--em markup--figure-em&quot;&gt;The gravitational lensing map (blue), overlayed over the optical and X-ray (pink) data of the Bullet cluster. The mismatch of the locations of the X-rays and the inferred mass is undeniable.&lt;/em&gt; (X-RAY: NASA/CXC/CFA/M.MARKEVITCH ET AL.; LENSING MAP: NASA/STSCI; ESO WFI; MAGELLAN/U.ARIZONA/D.CLOWE ET AL.; OPTICAL: NASA/STSCI; MAGELLAN/U.ARIZONA/D.CLOWE ET AL.)
&lt;p name=&quot;5794&quot; id=&quot;5794&quot; class=&quot;graf graf--p graf-after--figure&quot;&gt;The dark matter really does pass right through one another, and accounts for the vast majority of the mass; the normal matter in the form of gas creates shocks (in X-ray/pink, above), and only accounts for some 15% of the total mass in there. In other words, about five-sixths of that mass is dark matter! By &lt;a href=&quot;https://www.forbes.com/sites/startswithabang/2018/10/01/the-most-important-x-ray-image-ever-taken-proved-the-existence-of-dark-matter&quot; data-href=&quot;https://www.forbes.com/sites/startswithabang/2018/10/01/the-most-important-x-ray-image-ever-taken-proved-the-existence-of-dark-matter&quot; class=&quot;markup--anchor markup--p-anchor&quot; rel=&quot;nofollow noopener nofollow noopener&quot; target=&quot;_blank&quot;&gt;looking at colliding galaxy clusters&lt;/a&gt; and monitoring how both the observable matter and the total gravitational mass behaves, we can come up with an astrophysical, empirical proof for the existence of dark matter.&lt;/p&gt;
&lt;p name=&quot;3945&quot; id=&quot;3945&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;But that’s indirect; we know there’s supposed to be a particle associated with it, and that’s what the hunt is all about.&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;0*lysX1ZmYGRPgsqR-.jpg&quot; data-width=&quot;960&quot; data-height=&quot;646&quot; data-action=&quot;zoom&quot; data-action-value=&quot;0*lysX1ZmYGRPgsqR-.jpg&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/0*lysX1ZmYGRPgsqR-.jpg&quot;/&gt;&lt;/div&gt;
&lt;em class=&quot;markup--em markup--figure-em&quot;&gt;If dark matter does have a self-interaction, its cross-section is tremendously low, as direct detection experiments have shown. It also doesn’t scatter very much off of nuclei.&lt;/em&gt; (Mirabolfathi, Nader arXiv:1308.0044 [&lt;a href=&quot;http://astro-ph.im/&quot; data-href=&quot;http://astro-ph.im/&quot; class=&quot;markup--anchor markup--figure-anchor&quot; rel=&quot;noopener noreferrer noopener nofollow noopener&quot; target=&quot;_blank&quot;&gt;astro-ph.IM&lt;/a&gt;])
&lt;p name=&quot;e26a&quot; id=&quot;e26a&quot; class=&quot;graf graf--p graf-after--figure&quot;&gt;&lt;strong class=&quot;markup--strong markup--p-strong&quot;&gt;The hunt&lt;/strong&gt;. This is the great hope: for direct detection. Because we don’t know what’s beyond the standard model — we’ve never discovered a single particle not encompassed by it — we don’t know what dark matter’s particle (or particles) properties should be, should look like, or how to find it. We don’t even know if it’s all one thing, or if it’s made up of a variety of different particles.&lt;/p&gt;
&lt;p name=&quot;96bb&quot; id=&quot;96bb&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;So we look at what we’d be able to detect instead, and look there. We can look for interactions down to a certain cross-section, but no lower. We can look for energy recoils down to a certain minimum energy, but no lower. And at some point, experimental limitations — natural radioactivity, cosmic neutrons, solar/cosmic neutrinos, etc. — make it impossible to extract a signal below a certain threshold.&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;0*wbFMqmK8nsUhZ-X7.jpg&quot; data-width=&quot;960&quot; data-height=&quot;542&quot; data-action=&quot;zoom&quot; data-action-value=&quot;0*wbFMqmK8nsUhZ-X7.jpg&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/0*wbFMqmK8nsUhZ-X7.jpg&quot;/&gt;&lt;/div&gt;
&lt;em class=&quot;markup--em markup--figure-em&quot;&gt;Hall B of LNGS with XENON installations, with the detector installed inside the large water shield. If there’s any non-zero cross section between dark matter and normal matter, not only will an experiment like this have a chance at detecting dark matter directly, but there’s a chance that dark matter will eventually interact with your human body.&lt;/em&gt; (INFN)
&lt;p name=&quot;7b3f&quot; id=&quot;7b3f&quot; class=&quot;graf graf--p graf-after--figure&quot;&gt;Long story short: the latest experiment to search for dark matter directly didn’t find it, at least not yet. That’s been the story for every direct detection experiment ever performed, confirmed, and robustly tested, over and over again.&lt;/p&gt;
&lt;p name=&quot;c084&quot; id=&quot;c084&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;And that’s okay! Unless dark matter happens to be of a certain mass with a certain interaction cross-section, none of the designed experiments are going to see it. That doesn’t mean dark matter isn’t real, it just means that dark matter is something else than what our experiments are optimized to find.&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;0*xRQ3h16gIVGiQS9L.jpg&quot; data-width=&quot;960&quot; data-height=&quot;1389&quot; data-action=&quot;zoom&quot; data-action-value=&quot;0*xRQ3h16gIVGiQS9L.jpg&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/0*xRQ3h16gIVGiQS9L.jpg&quot;/&gt;&lt;/div&gt;
&lt;em class=&quot;markup--em markup--figure-em&quot;&gt;The cryogenic setup of one of the experiments looking to exploit the hypothetical interactions between dark matter and electromagnetism. Yet if dark matter doesn’t have specific properties that current experiments are testing for, none of the ones we’ve even imagined will ever see it directly.&lt;/em&gt; (AXION DARK MATTER EXPERIMENT (ADMX) / LLNL’S FLICKR)
&lt;p name=&quot;c90c&quot; id=&quot;c90c&quot; class=&quot;graf graf--p graf-after--figure&quot;&gt;So we keep looking, we keep thinking of new possibilities for what it could be, and we keep thinking of new ways to search for it. That’s what science at the frontiers is like. Personally, I don’t expect these direct detection attempts to be successful; we’re stabbing in the dark hoping we hit something, and there are little-to-no good reasons for dark matter to be in these ranges. But it’s what we could see, so we go for it. If we find it, Nobel Prizes and new physics discoveries for everyone, and if we don’t, we know a little more about where the new physics isn’t. But just as you shouldn’t fall for the hyper-sensationalized claims that dark matter has been directly detected, you shouldn’t fall for the ones that say “there’s no dark matter” because a direct detection experiment failed.&lt;/p&gt;
&lt;p name=&quot;1e5a&quot; id=&quot;1e5a&quot; class=&quot;graf graf--p graf-after--p graf--trailing&quot;&gt;We are after the most fundamental stuff in the Universe, and we’ve only recently begun to understand it. It shouldn’t be a surprise if the search takes a little — or even a lot — longer. In the meantime, the journey for knowledge and understanding of just what it is that holds the Universe together continues.&lt;/p&gt;
</description>
<pubDate>Sat, 13 Oct 2018 10:03:47 +0000</pubDate>
<dc:creator>alex_young</dc:creator>
<og:title>This Is The Real Reason We Haven’t Directly Detected Dark Matter</og:title>
<og:url>https://medium.com/starts-with-a-bang/this-is-the-real-reason-we-havent-directly-detected-dark-matter-3d04021b314e</og:url>
<og:image>https://cdn-images-1.medium.com/max/1200/1*RMVo9TWlGGxIynenlMs2Tw.jpeg</og:image>
<og:description>Finding the particle we assume is responsible for dark matter has always been a guessing game. We guessed wrong.</og:description>
<og:type>article</og:type>
<dc:format>text/html</dc:format>
<dc:identifier>https://medium.com/starts-with-a-bang/this-is-the-real-reason-we-havent-directly-detected-dark-matter-3d04021b314e</dc:identifier>
</item>
<item>
<title>A Great Old Timey Game Programming Hack (2013)</title>
<link>http://blog.moertel.com/posts/2013-12-14-great-old-timey-game-programming-hack.html</link>
<guid isPermaLink="true" >http://blog.moertel.com/posts/2013-12-14-great-old-timey-game-programming-hack.html</guid>
<description>&lt;p&gt;A long time ago, when I was a college undergrad, I spent some time working on computer video games. This was in the 8-bit PC era, when the gaming hardware was almost impossibly slow by today’s standards.&lt;/p&gt;
&lt;p&gt;It might not surprise you, then, to learn that game programmers of yore did all sorts of crazy things to make their games run at playable speeds. Crazy, crazy things.&lt;/p&gt;
&lt;p&gt;This is a story about one of those things.&lt;/p&gt;
&lt;p&gt;While I’ve done my best to recall the important details, I may have gotten some things wrong. If I have, please forgive me. It was a long time ago.&lt;/p&gt;
&lt;p&gt;(&lt;em&gt;Note: This post contains some small images as inline-data URLs that some feed readers apparently don’t handle well. If you can’t see the images in your feed, click through to the original article to see them.&lt;/em&gt;)&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Update 2013-12-16: There have been lots of great comments about this story on &lt;a href=&quot;https://news.ycombinator.com/item?id=6913467&quot;&gt;Hacker News&lt;/a&gt; and &lt;a href=&quot;http://www.reddit.com/r/programming/comments/1t05uy/a_great_oldtimey_gameprogramming_hack/&quot;&gt;Proggit&lt;/a&gt;, as well as &lt;a href=&quot;http://blog.moertel.com/posts/2013-12-14-great-old-timey-game-programming-hack.html#disqus_thread&quot;&gt;here on the blog&lt;/a&gt;. Thanks for sharing, everyone!&lt;/em&gt;&lt;/p&gt;
&lt;h3 id=&quot;the-set-up&quot;&gt;The set-up&lt;/h3&gt;
&lt;p&gt;A friend of mine, a gifted programmer, was nearly finished with a new game. Somehow, he had squeezed into a 1980’s-era PC, pretty faithfully, what was at the time a graphically impressive coin-op game popular at the arcades.&lt;/p&gt;
&lt;p&gt;The only problem was that his version of the game was unplayable. It was too slow, and the choppy motion broke the player’s immersion. It was after all a side-scroller.&lt;/p&gt;
&lt;p&gt;My friend, who had been working on the game while also taking a full load of college courses, was starting to seem a little frazzled. Fearing that he had missed some easy optimization, he asked me to take a look at the code.&lt;/p&gt;
&lt;p&gt;I did. But there was no easy optimization to be had.&lt;/p&gt;
&lt;p&gt;The code was &lt;em&gt;tight&lt;/em&gt;. Everywhere I looked, he had already done all the things I could think of. Loops had been unrolled. Unneeded draws had been eliminated. All evidence of waste had vanished.&lt;/p&gt;
&lt;p&gt;And, with them, our hopes of an easy fix.&lt;/p&gt;
&lt;p&gt;But what about a hard fix? A crazy fix?&lt;/p&gt;
&lt;p&gt;Well, that was always a possibility.&lt;/p&gt;
&lt;p&gt;Before I get to the crazy stuff, however, I should back up and explain how graphics hardware worked back then.&lt;/p&gt;
&lt;h3 id=&quot;how-graphics-hardware-worked-back-then&quot;&gt;How graphics hardware worked back then&lt;/h3&gt;
&lt;p&gt;Here’s the quick version: The graphics hardware didn’t do jack squat.&lt;/p&gt;
&lt;p&gt;On the PC in question, if you wanted to draw something onto the screen, you had to do that yourself, byte by byte. No texture mappers, no blitters. Just bytes. Bytes that you had to move yourself.&lt;/p&gt;
&lt;p&gt;Fun.&lt;/p&gt;
&lt;p&gt;My friend’s game spent most of its time redrawing the background. (Again: side-scroller.) For every frame, it had to draw nearly a screen’s worth of background tiles, shifted for the player’s position.&lt;/p&gt;
&lt;p&gt;If my memory serves me, each tile was 28 by 28 pixels. Each pixel was one of 16 colors, taking half a byte to represent. Therefore, tiles were represented in memory as 28 contiguous rows of 14 bytes each. The first 14 bytes represented the first row, the second 14 bytes the second row, and so on.&lt;/p&gt;
&lt;p&gt;The screen, however, was 320 pixels wide by 240 pixels high. In memory, then, a screen buffer was laid out as 240 contiguous rows of 160 bytes each.&lt;/p&gt;
&lt;p&gt;So when copying a tile at address &lt;em&gt;X&lt;/em&gt; onto a screen buffer location starting at address &lt;em&gt;Y&lt;/em&gt;, you had to copy 28 rows. To copy each row, you had to copy 14 bytes. Fortunately, the processor for this game was a 6809, which had a few 16-bit index registers and delightful “auto-increment” addressing modes (sort of like applying the postfix &lt;code&gt;++&lt;/code&gt; operator to pointers in C). That meant you could copy 4 pixels at a time while advancing both the &lt;em&gt;X&lt;/em&gt; and &lt;em&gt;Y&lt;/em&gt; registers in passing:&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;    LDU ,X++     ; read a 2-byte word (= 4 pixels) from source tile
    STU ,Y++     ; write it to screen buffer&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;To copy a full row, you had to do that seven times, so you might sandwich those lines within a 7-count loop:&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;    LDB #7       ; remaining words &amp;lt;- tile width in words
@LOOP
    LDU ,X++     ; read a 2-byte word (= 4 pixels) from source tile
    STU ,Y++     ; write it to screen buffer
    DECB         ; reduce remaining-word count
    BNE @LOOP    ; loop while words remain&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;When you were done copying the row, you needed to advance the destination pointer &lt;em&gt;Y&lt;/em&gt; so that it pointed to the starting address for the next row you would draw into the screen buffer. Since the screen buffer was 160 bytes wide and a tile was only 14 bytes wide, that meant you had to add their difference to &lt;em&gt;Y&lt;/em&gt;:&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;    LEAY 160-14,Y&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;And, just like that, you have copied a row onto the screen.&lt;/p&gt;
&lt;p&gt;That’s one. To copy a full tile, you need to do the same thing 28 times. So, in turn, you sandwich &lt;em&gt;that&lt;/em&gt; code within a 28-count loop.&lt;/p&gt;
&lt;p&gt;Putting it all together, and giving names to the important numbers, you might end up with a subroutine like this:&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;;;; important constants

SCRW = 160          ; screen-buffer width in bytes (= 320 4-bit pixels)
TILW =  14          ; background-tile width in bytes (= 28 4-bit pixels)
TILH =  28          ; background-tile height in rows
WOFF = SCRW - TILW  ; s-b offset from end of one tile row to start of next


COPYTILE
;;;
;;; Copy a 28x28 background tile into a screen buffer.
;;; Arguments:
;;;   X = starting address of background tile
;;;   Y = starting address of destination in screen buffer
;;;
    LDA #TILH               ; remaining rows &amp;lt;- tile height
@COPYROW
    LDB #TILW/2             ; remaining words &amp;lt;- tile width in words
@LOOP
    LDU ,X++                ; read a word (= 4 pixels) from source tile
    STU ,Y++                ; write it to screen buffer
    DECB                    ; reduce remaining-word count
    BNE @LOOP               ; loop while words remain
    ;;
    LEAY WOFF,Y             ; advance dst ptr to start of next dst row
    DECA                    ; reduce remaining-row count
    BNE @COPYROW            ; loop while rows remain
    ;;
    RTS                     ; done! return to caller&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;And that code would be fine.&lt;/p&gt;
&lt;p&gt;If you didn’t care about speed.&lt;/p&gt;
&lt;h3 id=&quot;caring-about-speed&quot;&gt;Caring about speed&lt;/h3&gt;
&lt;p&gt;Knowing that the game is probably going to spend most of its time running that code, you do what any good programmer would: start counting cycles. Here’s the inner loop again, with setup and finishing, annotated with cycle counts:&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;    LDB #TILW/2             ; 2 cycles (set-up)
@LOOP
    LDU ,X++                ; 8
    STU ,Y++                ; 8
    DECB                    ; 2
    BNE @LOOP               ; 3
    ;;
    LEAY WOFF,Y             ; 8 (finishing)&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;Looking at those counts within the loop, you’re not likely to miss that you’re burning 21 cycles to copy just 4 pixels. To copy a full row, then, works out to 2 cycles + (7 iterations) * (21 cycles/iteration) + 8 cycles = 157 cycles. Ouch.&lt;/p&gt;
&lt;p&gt;But this isn’t your first time at the keyboard. You know what to do. Unroll that loop!&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;    LDU ,X++                ; 8 cycles
    STU ,Y++                ; 8
    LDU ,X++                ; 8
    STU ,Y++                ; 8
    LDU ,X++                ; 8
    STU ,Y++                ; 8
    LDU ,X++                ; 8
    STU ,Y++                ; 8
    LDU ,X++                ; 8
    STU ,Y++                ; 8
    LDU ,X++                ; 8
    STU ,Y++                ; 8
    LDU ,X++                ; 8
    STU ,Y++                ; 8
    LEAY WOFF,Y             ; 8 (finishing)&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;Now, with the loop overhead reduced to zero – you’ve even eliminated the set-up – each row takes only 7 * (8 + 8) + 8 = 120 cycles. That’s a 30-percent speed-up. Pretty good.&lt;/p&gt;
&lt;p&gt;And that’s where most programmers probably would have left it.&lt;/p&gt;
&lt;p&gt;But not my friend.&lt;/p&gt;
&lt;p&gt;He knew that those &lt;code&gt;++&lt;/code&gt; operations were costly, 3 cycles apiece. And, with the loop unrolled, he also knew exactly where each word to be read or written was located with respect to &lt;em&gt;X&lt;/em&gt; or &lt;em&gt;Y&lt;/em&gt;. So he cleverly replaced those 3-cycle post-increments with exact offsets. They cost only 1 cycle apiece, and the 0 offset is actually free:&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;    LDU  ,X                 ; 5 cycles
    STU  ,Y                 ; 5
    LDU 2,X                 ; 6
    STU 2,Y                 ; 6
    LDU 4,X                 ; 6
    STU 4,Y                 ; 6
    LDU 6,X                 ; 6
    STU 6,Y                 ; 6
    LDU 8,X                 ; 6
    STU 8,Y                 ; 6
    LDU 10,X                ; 6
    STU 10,Y                ; 6
    LDU 12,X                ; 6
    STU 12,Y                ; 6
    LEAX TILW,X             ; 8 (finishing)
    LEAY SCRW,Y             ; 8 (finishing)&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;With his optimizations, the cycle count per row had been reduced to (5 + 5) + 6 * (6 + 6) + (8 + 8) = 98 cycles. Compared to the original code, that’s 60 percent faster:&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;original_speed  = (1*row) / (157*cycle)
optimized_speed = (1*row) /  (98*cycle)

speed_up  =  optimized_speed / original_speed  =  157 / 98  =  1.60.&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;Putting it all together – and, again, I’m going by memory so the code might have been slightly different – the copy-tile subroutine looked something like this, and it copied a full tile, all 28 rows, in a lean 2893 cycles:&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;COPYTILE2
;;;
;;; Copy a 28x28 screen tile into a screen buffer.
;;; Arguments:
;;;   X = starting address of background tile
;;;   Y = starting address of destination in screen buffer
;;; Execution time:
;;;   4 + 28 * (82 + 8 + 8 + 2 + 3) + 5 = 2893 cycles
;;;
    LDA #TILH      ; initialize row count (4 cycles)
    ;;
@COPY1
    ;; unroll inner loop (copies one row of 28 pixels in 82 cycles)
    LDU ,X         ; (1) read 4 pixels (5 cycles)
    STU ,Y         ;     write 4 pixels (5 cycles)
    LDU 2,X        ; (2) (6 cycles)
    STU 2,Y        ;     (6 cycles)
    LDU 4,X        ; (3) ...
    STU 4,Y        ;     ...
    LDU 6,X        ; (4)
    STU 6,Y        ;
    LDU 8,X        ; (5)
    STU 8,Y        ;
    LDU 10,X       ; (6)
    STU 10,Y       ;
    LDU 12,X       ; (7)
    STU 12,Y       ;
    ;;
    LEAX TILW,X    ; advance src to start of next row (8 cycles)
    LEAY SCRW,Y    ; advance dst to start of next row (8 cycles)
    DECA           ; reduce remaining count by one (2 cycles)
    BNE @COPY1     ; loop while rows remain (3 cycles)
    ;;
    RTS            ; done!  return to caller (5 cycles)&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;This code, all in all, was 60% faster than the naive &lt;code&gt;COPYTILE&lt;/code&gt; code we started out with.&lt;/p&gt;
&lt;p&gt;But that wasn’t fast enough. Not nearly.&lt;/p&gt;
&lt;p&gt;So when my friend showed me his code and asked if I could make it faster, I really wanted to help him. I really wanted to be able to answer yes.&lt;/p&gt;
&lt;p&gt;But I had to answer no. I hated giving that answer. But, studying the code, I couldn’t see any way to speed it up.&lt;/p&gt;
&lt;p&gt;And yet, the hook was set.&lt;/p&gt;
&lt;p&gt;Later, I couldn’t get the problem out of my head. Maybe I had missed something. I had grown up on Apple II computers and their 6502 processors. My friend’s code, however, was for the 6809. Maybe it afforded optimizations that I didn’t know about.&lt;/p&gt;
&lt;p&gt;With renewing optimism, I dialed into the university’s library to access the card catalog. (These were the days before the World Wide Web.) Through a VT220 terminal emulator, I searched for books about the 6809.&lt;/p&gt;
&lt;p&gt;There was one. A 6809 microprocessor manual. It was in the engineering library. Luckily, I was an engineering student and had sign-out privileges.&lt;/p&gt;
&lt;p&gt;Just like that, I was off to the library.&lt;/p&gt;
&lt;h3 id=&quot;a-crazy-idea&quot;&gt;A crazy idea&lt;/h3&gt;
&lt;p&gt;When I got to the engineering library, I found the book right where it was supposed to be, looking a little beat up:&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://www.maddes.net/m6809pm/&quot;&gt;&lt;em&gt;The MC6809-MC6809E Microprocessor Programming Manual&lt;/em&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Not bothering to find a chair, I flipped through the pages standing, looking for some oddball, 6809-specific instruction that might throw a lot of bytes and throw them fast. Page after page, though, turned up nothing.&lt;/p&gt;
&lt;p&gt;Then I came upon &lt;a href=&quot;http://www.maddes.net/m6809pm/appendix_a.htm#PSHS&quot;&gt;PSHS&lt;/a&gt;. “Push registers on the hardware stack.”&lt;/p&gt;
&lt;p&gt;On my beloved 6502, if you wanted to save registers on the stack, you had to do it one register at a time and, even then, by transferring them through the accumulator. It was slow and expensive. So I had learned to avoid the stack when speed mattered.&lt;/p&gt;
&lt;p&gt;But on the 6809 you could save &lt;em&gt;all&lt;/em&gt; of the registers – or any subset of them – with &lt;em&gt;a single instruction&lt;/em&gt;. And, amazingly, it cost a mere 5 cycles, plus 1 cycle more per byte pushed.&lt;/p&gt;
&lt;p&gt;Since the processor had three 16-bit general-purpose registers – &lt;em&gt;D&lt;/em&gt;, &lt;em&gt;X&lt;/em&gt;, and &lt;em&gt;Y&lt;/em&gt; – I could load them up and then use a single &lt;code&gt;PSHS&lt;/code&gt; instruction to write 6 bytes in just 11 cycles. The corresponding pull instruction, &lt;code&gt;PULS&lt;/code&gt;, had the same low cost.&lt;/p&gt;
&lt;p&gt;Further, the 6809 had &lt;em&gt;two&lt;/em&gt; stack registers, &lt;em&gt;S&lt;/em&gt; and &lt;em&gt;U&lt;/em&gt;. I could use one as a source pointer and the other as a destination pointer. In theory, with a single &lt;code&gt;PULS&lt;/code&gt;/&lt;code&gt;PSHU&lt;/code&gt; pair, I could copy 6 bytes in 22 cycles.&lt;/p&gt;
&lt;p&gt;That’s crazy, crazy fast.&lt;/p&gt;
&lt;p&gt;Excitement mounting, I headed for the front desk and reached for my student ID. I was going to sign out that wonderful little book for further study.&lt;/p&gt;
&lt;h3 id=&quot;a-crazy-plan&quot;&gt;A crazy plan&lt;/h3&gt;
&lt;p&gt;Walking back to the dorms, I formed my plan.&lt;/p&gt;
&lt;p&gt;I would save the &lt;em&gt;S&lt;/em&gt; and &lt;em&gt;U&lt;/em&gt; registers somewhere, and then point &lt;em&gt;S&lt;/em&gt; at the background tile and &lt;em&gt;U&lt;/em&gt; at the screen buffer. Then I would pull from &lt;em&gt;S&lt;/em&gt; and push to &lt;em&gt;U&lt;/em&gt;, copying 6 bytes at a time, using &lt;em&gt;D&lt;/em&gt;, &lt;em&gt;X&lt;/em&gt;, and &lt;em&gt;Y&lt;/em&gt; as go-betweens. To copy the 14 bytes that make up a row would require three such iterations, which unrolled would be about 60 cycles.&lt;/p&gt;
&lt;p&gt;When I reached my room, I found a piece of paper and sketched it out:&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;    PULS D,X,Y    ; first 6 bytes    11 cycles
    PSHU D,X,Y    ;                  11
    PULS D,X,Y    ; second 6 bytes   11
    PSHU D,X,Y    ;                  11
    PULS D        ; final 2 bytes     7
    PSHU D        ;                   7
    LEAU -WOFF,U  ; advance dst ptr   8&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;Just 66 cycles, including the after-row adjustment to &lt;em&gt;U&lt;/em&gt; that prepares it for the next row. (Note that the adjustment is now negative.) For comparison, the naive row-copy loop that we looked at earlier took 157 cycles to do the same thing. And my friend’s optimized code took 98. Already, this crazy idea was looking like a big win.&lt;/p&gt;
&lt;p&gt;Still, that last &lt;code&gt;PULS&lt;/code&gt;/&lt;code&gt;PSHU&lt;/code&gt; pair! What a clunker. It was needed to handle the final two bytes per row, since the rows were 28 pixels = 14 bytes wide, and 6 doesn’t divide 14 evenly.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;That darn remainder of 2 bytes!&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;If only the game had used 24-by-24 tiles instead… But it hadn’t, so I pored through the manual, looking for a way to lower the cost of that inevitable last pair.&lt;/p&gt;
&lt;p&gt;And then, by surprise, I struck gold! It was another 6809 oddity, the &lt;em&gt;DP&lt;/em&gt; register.&lt;/p&gt;
&lt;p&gt;On the 6502 and most 8-bit processors of the era, the lowest 256 bytes of memory was called the &lt;em&gt;zero page&lt;/em&gt;. The zero page was special because its memory locations had single-byte addresses and could be accessed with shorter and usually faster instructions.&lt;/p&gt;
&lt;p&gt;The 6809’s designers took this idea one step further. They let you use the &lt;em&gt;DP&lt;/em&gt; register to designate &lt;em&gt;any&lt;/em&gt; page as the zero page, which they called the “direct page.”&lt;/p&gt;
&lt;p&gt;But none of my byte-slinging instructions needed to use the direct page. That meant I could use the &lt;em&gt;DP&lt;/em&gt; register as an additional one-byte go-between. Now I could copy 7 bytes per pull-push pair!&lt;/p&gt;
&lt;p&gt;And 14 &lt;em&gt;is&lt;/em&gt; evenly divisible by 7.&lt;/p&gt;
&lt;p&gt;With this change, I could copy a whole 28-pixel row and advance to the next in just 5 instructions:&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;    PULS D,X,Y,DP  ; first 7 bytes    12 cycles
    PSHU D,X,Y,DP  ;                  12
    PULS D,X,Y,DP  ; second 7 bytes   12
    PSHU D,X,Y,DP  ;                  12
    LEAU -WOFF,U   ; advance dst ptr   8&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;56 cycles! Fifty. Six. Cycles.&lt;/p&gt;
&lt;p&gt;That bit of code made me feel just &lt;em&gt;awesome&lt;/em&gt;. I had managed to harness every single available register on the machine for byte-slinging! &lt;em&gt;D&lt;/em&gt;, &lt;em&gt;X&lt;/em&gt;, &lt;em&gt;Y&lt;/em&gt;, &lt;em&gt;U&lt;/em&gt;, &lt;em&gt;S&lt;/em&gt;, and even the oddball &lt;em&gt;DP&lt;/em&gt; – they were all fully engaged.&lt;/p&gt;
&lt;p&gt;I was feeling great about this solution.&lt;/p&gt;
&lt;p&gt;Except for just one thing…&lt;/p&gt;
&lt;h3 id=&quot;ill-have-a-little-more-crazy-please&quot;&gt;I’ll have a little more crazy, please&lt;/h3&gt;
&lt;p&gt;If you’re acquainted with stacks, you may have noticed a subtle flaw in my brilliant plan:&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Pushes and pulls work in opposite directions.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;See, I lied about that little block of code I just showed you. It didn’t &lt;em&gt;actually&lt;/em&gt; copy one row from a background tile onto the screen. What it actually did was break the row into two 7-byte blocks – I’ll call them “septets” – and then draw them onto the screen &lt;em&gt;swapped&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Recall that tile rows were laid out sensibly in memory as 14 contiguous bytes, like this:&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;+---+---+---+---+---+---+---+---+---+---+---+---+---+---+
| 0   1   2   3   4   5   6   7   8   9   A   B   C   D |
+---+---+---+---+---+---+---+---+---+---+---+---+---+---+&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;So when you pulled-and-pushed a row onto the screen in 7-byte septets, it would get horizontally split like this:&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;+---+---+---+---+---+---+---+---+---+---+---+---+---+---+
| 7   8   9   A   B   C   D | 0   1   2   3   4   5   6 |
+---+---+---+---+---+---+---+---+---+---+---+---+---+---+&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;The first septet was now second, and the second now first. Note, however, that the bytes within each septet were unchanged; they retained their original ordering.&lt;/p&gt;
&lt;p&gt;Further, if you ran the row-copy code multiple times, the vertical stack of rows you copied would end up being upside down. That’s because the code uses pushes to write the rows onto the screen. Pushes move the stack pointer toward lower addresses, and lower addresses correspond to screen lines higher up on the display.&lt;/p&gt;
&lt;p&gt;To visualize the havoc that this row-reversal and septet-swapping would wreak, let’s say that you had the following 28-by-28 tile, representing a key:&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;data:image/gif;base64,R0lGODlhHAAcAIQQAE88FHZNAH19crB7ApCAT5+BNL6bN8+iIN2sEMqwavTGIfDNTfbbcPflmPbsvPz43v///////////////////////////////////////////////////////////////yH5BAEKABAALAAAAAAcABwAAAXOICSOZGmeaKqupeK6iMGiytI4TcMshjCTisZjSGzwfqLg0JEoJBwPY+KnYCwNBULB8GQcpiwFlDkYEATbHOIwUywThsOBABjkFogZ4uHA5eQEdg54en05OQxrCGpsLIs6hwwuDH8yjjoMmZkLlEYGBI6aopl3cz4qB5ScozsLBwWnKakNCK0Lt7cHWLEoswi4CGXCWSypiQvCA0gjA5kwysvMmQjP0SLNiS8DAdbNeM/c0QOKwWXh4tQKBwEAANYiAenr7yMBA3Lb9Pr7PyEAOw==&quot; alt=&quot;A pixel-art image of a key.&quot;/&gt;&lt;/p&gt;
&lt;p&gt;If you had used 28 applications of my row-copy code to draw it onto the screen, you would have ended up with this not-a-key:&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;data:image/gif;base64,R0lGODlhHAAcAIQQAE88FHZNAH19crB7ApCAT5+BNL6bN8+iIN2sEMqwavTGIfDNTfbbcPflmPbsvPz43v///////////////////////////////////////////////////////////////yH5BAEKABAALAAAAAAcABwAAAXQICSOZGmeaKquZTAcxxCwaoAoyjHT6HDnAQCAZ/IdEIiBckccDRiLX5LZhDwZP4VMNKhepV1IUqksEFZXXFK0aLsPhoJAdWBgF2S7Hro4yOkMDQhue3YNDX0Ecyl1glCFC4GIBmeAiIaHDDiScCwIeoeZCEeHozQIDQwOoTAEAw0OUaeHDgkGrQCviAinDr4JSooFBqUHpw8OyHEEwwkODAcJNAoP1cgJBc4PiNLTyQ3W1pNECgwPCguwmQsGizwKDRA48wgGVSIK9/r7/P0sIQA7&quot; alt=&quot;A distorted pixel-art image of a key; the original image has been reflected across its horizontal axis, cut in half from top to bottom, and had its left and right halves swapped.&quot;/&gt;&lt;/p&gt;
&lt;p&gt;So . . . &lt;em&gt;that&lt;/em&gt; was a problem.&lt;/p&gt;
&lt;p&gt;But this problem, too, had an elegant solution!&lt;/p&gt;
&lt;p&gt;To review:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;the rows were upside down&lt;/li&gt;
&lt;li&gt;the septets within each row were swapped&lt;/li&gt;
&lt;li&gt;but the bytes within each septet were unchanged&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;The breakthrough was to see “upside down” and “swapped” as two instances of the same thing. &lt;em&gt;Reversal.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Reversal has this handy property: it’s an &lt;a href=&quot;http://en.wikipedia.org/wiki/Involution_(mathematics)&quot;&gt;&lt;em&gt;involution&lt;/em&gt;&lt;/a&gt;. Reverse something twice, and you get back the original. With this in mind, I reasoned that if the tiles were pre-processed to reverse their rows and then the septets within the rows, the tiles would end up looking fine when they hit the screen. The mangling that occurred during copying and pre-processing would, in effect, undo each other.&lt;/p&gt;
&lt;p&gt;Working it out on paper, I also discovered that the pre-processing step could ignore the rows and just treat the tiles as one long, linear sequence of septets.&lt;a href=&quot;http://blog.moertel.com/posts/2013-12-14-great-old-timey-game-programming-hack.html#fn1&quot; class=&quot;footnoteRef&quot; id=&quot;fnref1&quot;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt; To see why this is so, let’s consider a small tile of 2 rows of 2 septets each:&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;+---+---+
| a   b |
+---+---+
| c   d |
+---+---+&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;In memory, it would be laid out in row-major order, that is, as 4 sequential septets:&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;+---+---+---+---+
| a   b | c   d |
+---+---+---+---+&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;So, reversing the rows and then swapping the septets within each row is the same as just reversing the septet order in memory:&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;+---+---+                  +---+---+                  +---+---+
| a   b |                  | c   d |                  | d   c |
+---+---+        =======&amp;gt;  +---+---+        =======&amp;gt;  +---+---+
| c   d |        reverse   | a   b |        swap      | b   a |
+---+---+        rows      +---+---+        septets   +---+---+

+---+---+---+---+          +---+---+---+---+          +---+---+---+---+
| a   b | c   d |          | c   d | a   b |          | d   c | b   a |
+---+---+---+---+          +---+---+---+---+          +---+---+---+---+&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;So the solution to the mangling problem turned out to be a simple, one-time pre-processing step: Just break each tile into septets and reverse their order.&lt;/p&gt;
&lt;p&gt;Knowing that the mangling problem could be solved, I was feeling good about my overall idea. I couldn’t see any other problems, so I sketched out a new copy-tile subroutine to present to my friend. Since the row-copy logic was now just 5 instructions, I used it 4 times, unrolling the sole remaining loop a bit. Now, instead of copying 28 single rows, I copied 7 quad-rows.&lt;/p&gt;
&lt;p&gt;The code looked something like this:&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;COPYTILE3
;;;
;;; Copy a 28x28 screen tile into a screen buffer.
;;; Arguments:
;;;   X = starting address of *septet-reversed* background tile
;;;   Y = starting address of destination in screen buffer
;;; Execution time:
;;;   34 + 7 * (224 + 7 + 3) + 7 + 10 = 1689 cycles
;;;
    ;; setup:  34 cycles
    PSHS U,DP      ; save U and DP (8 cycles)
    STS &amp;gt;SSAVE     ; save S (7 cycles)
    ;;
    LDA #TILH/4    ; initial quad-row count (2 cycles)
    STA &amp;gt;ROWCT     ; (5 cycles)
    ;;
    LEAS ,X                    ; initialize src ptr (4 cycles)
    LEAU (TILH-1)*SCRW+TILW,Y  ; initialize dst ptr (8 cycles)
    ;;
@COPY1
    ;; copy four rows of 28 pixels in 4 * (48 + 8) = 224 cycles
    PULS X,Y,D,DP
    PSHU X,Y,D,DP
    PULS X,Y,D,DP
    PSHU X,Y,D,DP
    LEAU -WOFF,U
    PULS X,Y,D,DP
    PSHU X,Y,D,DP
    PULS X,Y,D,DP
    PSHU X,Y,D,DP
    LEAU -WOFF,U
    PULS X,Y,D,DP
    PSHU X,Y,D,DP
    PULS X,Y,D,DP
    PSHU X,Y,D,DP
    LEAU -WOFF,U
    PULS X,Y,D,DP
    PSHU X,Y,D,DP
    PULS X,Y,D,DP
    PSHU X,Y,D,DP
    LEAU -WOFF,U
    ;;
    DEC &amp;gt;ROWCT     ; reduce remaining quad-row count by one (7 cycles)
    BNE @COPY1     ; loop while quad-rows remain (3 cycles)
    ;;
    LDS  &amp;gt;SSAVE    ; restore S (7 cycles)
    PULS U,DP,PC   ; restore regs and return to caller (10 cycles)

SSAVE ZMD  1       ; stash for saving S while drawing
ROWCT ZMB  1       ; var: remaining rows to copy&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;Adding up the cycles, the total was just 1689. I had shaved almost 1200 cycles off of my friend’s code. That’s a 70 percent speed-up!&lt;/p&gt;
&lt;p&gt;Beaming, I went to show my friend.&lt;/p&gt;
&lt;h3 id=&quot;the-acid-test&quot;&gt;The acid test&lt;/h3&gt;
&lt;p&gt;When I caught up with my friend and said I’d figured out how to make the copy-tile routine 70% faster, his face lit up. When I explained about the whole septets-and-mangling thing, though, his face unlit, doubts rising. But when I showed him the code, he got it. It clicked.&lt;/p&gt;
&lt;p&gt;“Let’s try it out!” he said.&lt;/p&gt;
&lt;p&gt;In about a half hour’s work, he had the code integrated into the game. After a rebuild and reboot, the game was loading.&lt;/p&gt;
&lt;p&gt;The title screen came up.&lt;/p&gt;
&lt;p&gt;He was into the game.&lt;/p&gt;
&lt;p&gt;And . . .&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Holy crap!&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;The game seemed amazingly fast. In truth, it was probably only a third to a half faster, but that was enough. Some important perceptual threshold had been crossed. The game-play was now smooth, natural. You could feel the difference.&lt;/p&gt;
&lt;p&gt;We just sat there, playing the game and grinning. It was a good day.&lt;/p&gt;
&lt;p&gt;But it would not last.&lt;/p&gt;
&lt;h3 id=&quot;in-for-a-penny-.-.-.&quot;&gt;In for a penny . . .&lt;/h3&gt;
&lt;p&gt;A few days after the speed problem was behind us – or so we thought – the game’s finishing touches were applied. One of those finishing touches was sampled sound effects. This required feeding byte-sized morsels to the audio-output DAC a few thousand times each second. To schedule the feedings, my friend had turned on a hardware-clocked interrupt.&lt;/p&gt;
&lt;p&gt;Worked like a charm. The sounds sounded great, and everything was perfect.&lt;/p&gt;
&lt;p&gt;Except for one thing.&lt;/p&gt;
&lt;p&gt;After playing into the game one night, we noticed that some of the tiles were getting corrupted. The more we played, the more corruption we saw.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Oh, no.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Something very bad was happening.&lt;/p&gt;
&lt;p&gt;And then it hit us.&lt;/p&gt;
&lt;p&gt;What happens if an interrupt goes off during the copy-tile routine?&lt;/p&gt;
&lt;p&gt;The processor, to prepare for calling the interrupt handler, would push its current state onto the system stack. But, during the copy-tile routine, &lt;em&gt;there was no system stack&lt;/em&gt;. The system-stack register &lt;em&gt;S&lt;/em&gt; had been commandeered. And where was it pointing? Right into the memory buffer that held the reference tiles!&lt;/p&gt;
&lt;p&gt;Oops.&lt;/p&gt;
&lt;p&gt;We slumped. After all that effort, to think that our all-important speed-up was causing memory corruption…&lt;/p&gt;
&lt;p&gt;Needing a break, we walked to an all-night diner near campus to eat and think. Over pancakes and bacon, scrapple and grilled stickies, we talked through the problem.&lt;/p&gt;
&lt;p&gt;There were only two stack registers, and without commandeering both of them, the copy-tile routine wouldn’t be nearly as fast. There was no way, then, to return the &lt;em&gt;S&lt;/em&gt; register to the system without losing our hard-won speed. &lt;em&gt;Rock.&lt;/em&gt; But there was also no way that we could get reliable sound without using interrupts. &lt;em&gt;Hard place.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;One way or another, then, interrupts were going to be triggered. And, when they were, if copy-tile was running, whatever &lt;em&gt;S&lt;/em&gt; was pointing to was going to get hammered.&lt;/p&gt;
&lt;p&gt;“How can we prevent the corruption?” I asked.&lt;/p&gt;
&lt;p&gt;We sat there, ignoring our food, the question hanging in the air.&lt;/p&gt;
&lt;p&gt;Suddenly, my friend slapped the table. He had it.&lt;/p&gt;
&lt;p&gt;“Don’t prevent it!” he said.&lt;/p&gt;
&lt;p&gt;“What?” I asked.&lt;/p&gt;
&lt;p&gt;“Don’t prevent the corruption,” he explained. “Let it happen. Just not to the reference tiles.”&lt;/p&gt;
&lt;p&gt;It was simple, really. He continued:&lt;/p&gt;
&lt;p&gt;“Just swap &lt;em&gt;S&lt;/em&gt; and &lt;em&gt;U&lt;/em&gt; in the copy-tile routine. &lt;em&gt;U&lt;/em&gt; will point at the reference tiles, and &lt;em&gt;S&lt;/em&gt; at the screen buffer. If an interrupt goes off, the corruption will happen where &lt;em&gt;S&lt;/em&gt; is pointing – &lt;em&gt;on the screen.&lt;/em&gt; The corruption will last only until we redraw the next frame.”&lt;/p&gt;
&lt;p&gt;“That’s brilliant!” I said.&lt;/p&gt;
&lt;p&gt;Eager to try his solution, we quickly finished our meal.&lt;/p&gt;
&lt;h3 id=&quot;in-for-a-pound&quot;&gt;. . . In for a pound&lt;/h3&gt;
&lt;p&gt;Walking back to the dorms, though, it bothered us that players might see screen glitches, even if for just a frame. We both felt that there had to be some way to make the hack perfect, if only we could find it.&lt;/p&gt;
&lt;p&gt;Later that night, we found it.&lt;/p&gt;
&lt;p&gt;Again, it was simple once we saw it. All we had to do was change the tile ordering. Instead of placing the tiles onto the screen from top to bottom, left to right, we would go right to left, bottom to top. In other words, from high addresses to low addresses.&lt;/p&gt;
&lt;p&gt;That way, when an interrupt went off and corrupted the memory locations immediately before the tile we were currently drawing, the corruption would be fixed when the very next tile was drawn. And since tile-drawing took place in a buffer that wasn’t displayed until it was fully drawn (and the vertical refresh had occurred), nobody would ever see the corruption.&lt;a href=&quot;http://blog.moertel.com/posts/2013-12-14-great-old-timey-game-programming-hack.html#fn2&quot; class=&quot;footnoteRef&quot; id=&quot;fnref2&quot;&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;It was the perfect hack!&lt;/p&gt;
&lt;h3 id=&quot;to-the-old-days&quot;&gt;To the old days!&lt;/h3&gt;
&lt;p&gt;And that’s the way things were. The challenge wasn’t overwhelming complexity, as it is today. The challenge was cramming your ideas into machines so slow, so limited that most ideas didn’t fit.&lt;/p&gt;
&lt;p&gt;You had to bang your ideas around, twist them, turn them, searching for something, &lt;em&gt;anything&lt;/em&gt; that would help you squeeze them into the machine. Sometimes you found it, and you got one step closer to realizing your ideas. Sometimes you didn’t.&lt;/p&gt;
&lt;p&gt;But the search was always instructive.&lt;/p&gt;
&lt;p&gt;In this case, the search yielded several small victories that, together, solved the problem. But when you consider all the things we had to do to make that darn game fast enough, it does seem crazy.&lt;/p&gt;
&lt;p&gt;We started with a tile-copying subroutine whose core was a hand-tuned, unrolled loop of machine instructions. Then, to buy a 70-percent speed-up:&lt;/p&gt;
&lt;ol type=&quot;1&quot;&gt;&lt;li&gt;We replaced this subroutine with a very special manifestation of insanity that commandeered both stack pointers and used pulls and pushes, and every single available register, to draw tiles &lt;em&gt;upside down and horizontally broken&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Then we pre-processed the tiles so that drawing them would actually &lt;em&gt;fix&lt;/em&gt; them.&lt;/li&gt;
&lt;li&gt;But then – &lt;em&gt;dammit!&lt;/em&gt; – interrupts that occurred during drawing could corrupt the reference tiles.&lt;/li&gt;
&lt;li&gt;So, to protect the reference tiles, we corrupted the screen buffer instead.&lt;/li&gt;
&lt;li&gt;But that corruption would be visible.&lt;/li&gt;
&lt;li&gt;So we changed the tile-placement order to repair – &lt;em&gt;on the fly&lt;/em&gt; – any corruption that might have occurred, before it could ever be displayed.&lt;/li&gt;
&lt;li&gt;And it all worked!&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;We did &lt;em&gt;that.&lt;/em&gt; For 70 percent.&lt;/p&gt;
&lt;p&gt;And it was &lt;em&gt;so&lt;/em&gt; worth it.&lt;/p&gt;
&lt;h3 id=&quot;tell-em-if-you-got-em&quot;&gt;Tell ’em if you got ’em&lt;/h3&gt;
&lt;p&gt;Anyway, I wanted to share that story with you for two reasons.&lt;/p&gt;
&lt;p&gt;The first is that it’s a fun story. It’s one my earliest memories of struggling with a messy computing problem and, through dogged persistence, zeroing in on a solution that was both effective and elegant. The result was powerfully satisfying.&lt;/p&gt;
&lt;p&gt;The struggle, I learned, is worth it.&lt;/p&gt;
&lt;p&gt;The second reason is to encourage you to tell your stories. I know that, “back in the day,” most video games probably gave rise to many stories like this one. I’d love to hear them. But too many of them are lost, having faded out of memory before anyone thought to preserve them.&lt;/p&gt;
&lt;p&gt;If you have a story, please don’t wait. Tell it. Every day you wait, it gets harder.&lt;/p&gt;
&lt;p&gt;Tell it.&lt;/p&gt;
&lt;section class=&quot;footnotes&quot;&gt;&lt;hr/&gt;&lt;ol&gt;&lt;li id=&quot;fn1&quot;&gt;
&lt;p&gt;Exercise: Prove that for all finite sequences of finite sequences, applying (&lt;em&gt;reverse&lt;/em&gt; ⋅ &lt;em&gt;concat&lt;/em&gt;) is the same as applying (&lt;em&gt;concat&lt;/em&gt; ⋅ &lt;em&gt;reverse&lt;/em&gt; ⋅ &lt;em&gt;map&lt;/em&gt; &lt;em&gt;reverse&lt;/em&gt;).&lt;a href=&quot;http://blog.moertel.com/posts/2013-12-14-great-old-timey-game-programming-hack.html#fnref1&quot;&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&quot;fn2&quot;&gt;
&lt;p&gt;We also had to make sure that nothing valuable was stored in the memory locations just before a screen buffer. They could, in theory, also be corrupted if an interrupt occurred while placing the top-left septet of the top-left corner tile. This septet’s address corresponded to the start of the buffer.&lt;a href=&quot;http://blog.moertel.com/posts/2013-12-14-great-old-timey-game-programming-hack.html#fnref2&quot;&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;&lt;/section&gt;</description>
<pubDate>Sat, 13 Oct 2018 04:41:17 +0000</pubDate>
<dc:creator>esaym</dc:creator>
<dc:format>text/html</dc:format>
<dc:identifier>http://blog.moertel.com/posts/2013-12-14-great-old-timey-game-programming-hack.html</dc:identifier>
</item>
<item>
<title>Air India Express 737 Hits ILS, Damages Wall on Departure, Flies for 4 Hours</title>
<link>https://www.flightradar24.com/blog/air-india-express-737-hits-ils-damages-wall-on-departure-flies-for-4-hours-before-diverting/</link>
<guid isPermaLink="true" >https://www.flightradar24.com/blog/air-india-express-737-hits-ils-damages-wall-on-departure-flies-for-4-hours-before-diverting/</guid>
<description>&lt;p&gt;Air India Express flight &lt;a href=&quot;https://www.flightradar24.com/data/flights/ix611#1e2da319&quot;&gt;&lt;span class=&quot;link-complex-target&quot;&gt;IX611&lt;/span&gt;&lt;/a&gt; appears to have struck the ILS &amp;amp; and damage a nearby wall at the departure end of RWY 27 in Trichy on departure early the morning of 12 October local time. The aircraft climbed to cruising altitude for 3 hours before safety diverting to Mumbai. No injuries have been reported.&lt;span id=&quot;more-6290&quot;/&gt;&lt;/p&gt;
&lt;div id=&quot;attachment_6298&quot; class=&quot;wp-caption aligncenter&quot; readability=&quot;33&quot;&gt;&lt;a href=&quot;https://www.flightradar24.com/data/flights/ix611#1e2da319&quot;&gt;&lt;img class=&quot;wp-image-6298 size-full&quot; src=&quot;https://blog.flightradar24.com/blog/wp-content/uploads/2018/10/IX611.jpg&quot; alt=&quot;&quot; width=&quot;1600&quot; height=&quot;1649&quot; srcset=&quot;https://www.flightradar24.com/blog/wp-content/uploads/2018/10/IX611.jpg 1600w, https://www.flightradar24.com/blog/wp-content/uploads/2018/10/IX611-768x792.jpg 768w&quot; sizes=&quot;(max-width: 1600px) 100vw, 1600px&quot;/&gt;&lt;/a&gt;
&lt;p class=&quot;wp-caption-text&quot;&gt;Flight path, speed and altitude graph of IX611&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Based on ADS-B data received from the aircraft, the flight bound for Dubai was not yet airborne at the end of the runway. Based on processing of granular ADS-B data, the last signal received from the aircraft on the ground was at 19:49:11.550 UTC, position 10.76525, 78.70596 at a ground speed of 155 kts.&lt;/p&gt;
&lt;div id=&quot;attachment_6299&quot; class=&quot;wp-caption aligncenter&quot; readability=&quot;32&quot;&gt;&lt;img class=&quot;size-full wp-image-6299&quot; src=&quot;https://blog.flightradar24.com/blog/wp-content/uploads/2018/10/IX611-Last-On-Ground-Data-Point.jpg&quot; alt=&quot;&quot; width=&quot;1200&quot; height=&quot;622&quot; srcset=&quot;https://www.flightradar24.com/blog/wp-content/uploads/2018/10/IX611-Last-On-Ground-Data-Point.jpg 1200w, https://www.flightradar24.com/blog/wp-content/uploads/2018/10/IX611-Last-On-Ground-Data-Point-768x398.jpg 768w&quot; sizes=&quot;(max-width: 1200px) 100vw, 1200px&quot;/&gt;&lt;p class=&quot;wp-caption-text&quot;&gt;Last on ground ADS-B data point from IX611&lt;/p&gt;
&lt;/div&gt;
&lt;p class=&quot;js-tweet-text tweet-text txt-size-variable--18 margin-b--10 with-linebreaks&quot; lang=&quot;en&quot;&gt;The next signal received from &lt;span class=&quot;link-complex-target&quot;&gt;IX611&lt;/span&gt;, at 19:49:22.538, reported a calibrated altitude of 625 ft, 161 kts ground speed from position 10.7644, 78.69791.&lt;/p&gt;
&lt;div id=&quot;attachment_6300&quot; class=&quot;wp-caption aligncenter&quot; readability=&quot;32&quot;&gt;&lt;img class=&quot;size-full wp-image-6300&quot; src=&quot;https://blog.flightradar24.com/blog/wp-content/uploads/2018/10/First-Airborne-IX611.jpg&quot; alt=&quot;&quot; width=&quot;1200&quot; height=&quot;672&quot; srcset=&quot;https://www.flightradar24.com/blog/wp-content/uploads/2018/10/First-Airborne-IX611.jpg 1200w, https://www.flightradar24.com/blog/wp-content/uploads/2018/10/First-Airborne-IX611-768x430.jpg 768w&quot; sizes=&quot;(max-width: 1200px) 100vw, 1200px&quot;/&gt;&lt;p class=&quot;wp-caption-text&quot;&gt;First airborne data point from IX611&lt;/p&gt;
&lt;/div&gt;
&lt;p lang=&quot;en&quot;&gt;IX611 climbed for 31 minutes after departure to a cruising altitude of 36,000 ft and stayed at FL360 or FL350 for 3 hr 16 min, before descending to its diversion airport in Mumbai. The exact point of diversion is unknown due to lack of coverage.&lt;/p&gt;
&lt;h2 lang=&quot;en&quot;&gt;Damage to the aircraft&lt;/h2&gt;
&lt;p&gt;The aircraft appears to have sustained substantial damage to the underside of the fuselage.&lt;/p&gt;
&lt;blockquote class=&quot;twitter-tweet&quot; data-conversation=&quot;none&quot; data-lang=&quot;en&quot; readability=&quot;5.4925373134328&quot;&gt;
&lt;p dir=&quot;ltr&quot; lang=&quot;en&quot;&gt;Air India Trichy pics coming in. Severe Boeing 737 damage &lt;a href=&quot;https://t.co/SJVGLiEQvx&quot;&gt;pic.twitter.com/SJVGLiEQvx&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;— Tarun Shukla (@shukla_tarun) &lt;a href=&quot;https://twitter.com/shukla_tarun/status/1050595274869993474?ref_src=twsrc%5Etfw&quot;&gt;October 12, 2018&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 lang=&quot;en&quot;&gt;The aircraft&lt;/h2&gt;
&lt;p&gt;IX611 was operated by Air India Express 737-800 registered &lt;a href=&quot;https://www.flightradar24.com/data/aircraft/vt-ayd&quot;&gt;VT-AYD&lt;/a&gt;. The aircraft was delivered to the airline in December 2009.&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.jetphotos.com/info/737-36340&quot;&gt;&lt;img class=&quot;aligncenter wp-image-6291 size-full&quot; src=&quot;https://blog.flightradar24.com/blog/wp-content/uploads/2018/10/34437_1529959382.jpg&quot; alt=&quot;&quot; width=&quot;1200&quot; height=&quot;835&quot; srcset=&quot;https://www.flightradar24.com/blog/wp-content/uploads/2018/10/34437_1529959382.jpg 1200w, https://www.flightradar24.com/blog/wp-content/uploads/2018/10/34437_1529959382-768x534.jpg 768w&quot; sizes=&quot;(max-width: 1200px) 100vw, 1200px&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Download Flightradar24 Data&lt;/h2&gt;
&lt;p&gt;Flightradar24 data related to this flight is available for download. The granular CSV file contains more frequent position reports and additional data fields than the basic CSV.&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://blog.flightradar24.com/blog/wp-content/uploads/2018/10/Flight_IX611_1e2da319.csv&quot;&gt;Download the IX611 basic CSV&lt;/a&gt;&lt;br/&gt;&lt;a href=&quot;https://blog.flightradar24.com/blog/wp-content/uploads/2018/10/IX611granulardata-1.csv&quot;&gt;Download the IX611 granular CSV file&lt;/a&gt;&lt;br/&gt;&lt;a href=&quot;https://blog.flightradar24.com/blog/wp-content/uploads/2018/10/IX611-1e2da319.kml_.zip&quot;&gt;Download the IX611 KML file&lt;/a&gt;&lt;/p&gt;

&lt;blockquote readability=&quot;0&quot;&gt;
&lt;p&gt;&lt;a href=&quot;https://www.jetphotos.com/photo/8999269&quot;&gt;Featured photo © Manuel Müller&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;footer class=&quot;line&quot;&gt;&lt;span class=&quot;entry-info&quot;&gt;&lt;strong&gt;Tags:&lt;/strong&gt; &lt;a href=&quot;https://www.flightradar24.com/blog/tag/737/&quot; rel=&quot;tag&quot;&gt;737&lt;/a&gt;, &lt;a href=&quot;https://www.flightradar24.com/blog/tag/air-india-express/&quot; rel=&quot;tag&quot;&gt;Air India Express&lt;/a&gt;, &lt;a href=&quot;https://www.flightradar24.com/blog/tag/ils/&quot; rel=&quot;tag&quot;&gt;ILS&lt;/a&gt;, &lt;a href=&quot;https://www.flightradar24.com/blog/tag/impact/&quot; rel=&quot;tag&quot;&gt;impact&lt;/a&gt;, &lt;a href=&quot;https://www.flightradar24.com/blog/tag/take-off/&quot; rel=&quot;tag&quot;&gt;Take off&lt;/a&gt;, &lt;a href=&quot;https://www.flightradar24.com/blog/tag/tiruchirapalli/&quot; rel=&quot;tag&quot;&gt;Tiruchirapalli&lt;/a&gt;, &lt;a href=&quot;https://www.flightradar24.com/blog/tag/trichy/&quot; rel=&quot;tag&quot;&gt;Trichy&lt;/a&gt;, &lt;a href=&quot;https://www.flightradar24.com/blog/tag/trz/&quot; rel=&quot;tag&quot;&gt;TRZ&lt;/a&gt;, &lt;a href=&quot;https://www.flightradar24.com/blog/tag/votr/&quot; rel=&quot;tag&quot;&gt;VOTR&lt;/a&gt;, &lt;a href=&quot;https://www.flightradar24.com/blog/tag/wall/&quot; rel=&quot;tag&quot;&gt;Wall&lt;/a&gt;&lt;/span&gt;&lt;/footer&gt;</description>
<pubDate>Fri, 12 Oct 2018 22:17:38 +0000</pubDate>
<dc:creator>sassyboy</dc:creator>
<dc:language>en-US</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.flightradar24.com/blog/air-india-express-737-hits-ils-damages-wall-on-departure-flies-for-4-hours-before-diverting/</dc:identifier>
</item>
<item>
<title>An Amateur Rap Crew Stole Surveillance Tech that Tracks Almost Every American</title>
<link>https://www.forbes.com/sites/thomasbrewster/2018/10/12/how-an-amateur-rap-crew-stole-surveillance-tech-that-tracks-almost-every-american/#33f5c0cd50f1</link>
<guid isPermaLink="true" >https://www.forbes.com/sites/thomasbrewster/2018/10/12/how-an-amateur-rap-crew-stole-surveillance-tech-that-tracks-almost-every-american/#33f5c0cd50f1</guid>
<description>&lt;p class=&quot;speakable-paragraph&quot;&gt;&lt;sup class=&quot;drop-cap color-accent font-accent&quot;&gt;O&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;n a June day last year, a skinny, dreadlocked 29-year-old rapper known as Tony Da Boss lay in bed in a redbrick apartment on a tree-lined street in Charlotte, North Carolina. It was not the kind of place you’d associate with a million-dollar criminal conspiracy. But Da Boss (real name Damonte Withers) was a leader of the &lt;a href=&quot;https://www.youtube.com/watch?v=3Ir0oV_RFe8&quot; target=&quot;_blank&quot; class=&quot;color-accent&quot;&gt;FreeBandz Gang&lt;/a&gt;, an amateur hip-hop crew of twentysomethings who were into much more nefarious activities &lt;a href=&quot;https://soundcloud.com/free-bandz-gang-x-bossent&quot; target=&quot;_blank&quot; class=&quot;color-accent&quot;&gt;than laying down tracks&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;There were warning signs that things were going to get real. Alerts on Da Boss’ iPhone warned that his Google Nest surveillance cameras with views into and outside the apartment had picked up movement. Outside, a full cast of law enforcement personnel from the Secret Service, the U.S. Postal Inspection Service and the local police department were primed to swoop in.&lt;/p&gt;
&lt;p&gt;Inside, they found piles of marijuana and multiple firearms. More intriguing, there were bundles of cash alongside fake-ID-card printers, 36 credit card blanks and reams of printouts containing American citizens’ personal data. Investigators spotted the Nest cameras and would soon make the first publicly known federal government demand for customer information and surveillance footage from Google’s smart home division.&lt;/p&gt;
&lt;p&gt;From January to June 2018, seven members of Da Boss’ gang pleaded guilty to various identity theft charges. In total they had caused about $1.2 million in damage, using stolen identities to buy luxury cars and iPhones and to lease apartments in Charlotte. Both they and their crimes would have been quickly forgotten as garden variety larceny were it not for the way they stole those identities.&lt;/p&gt;
&lt;p&gt;Cops alleged Da Boss and his co-conspirators had access to the Holy Grail for any Internet-age scam artist: a surveillance technology that police and debt collectors use to track most of the United States’ 325 million inhabitants via their Social Security numbers, license plates, address histories, names and dates of birth. &lt;a href=&quot;https://www.tlo.com/&quot; target=&quot;_blank&quot; class=&quot;color-accent&quot;&gt;The mass-monitoring tech, called TLO,&lt;/a&gt; is a product of the Chicago-based credit reporting giant TransUnion, which last year had revenues of nearly $1.9 billion. One brochure for the service promises access to a startling amount of personal data drawn from myriad sources: more than 350 million Social Security numbers of dead and living Americans, 225 million employment histories and four billion address records. Add to that billions of vehicle registrations and call records and you have one of the largest commercial surveillance databases in existence.&lt;/p&gt;
&lt;p&gt;It’s used not just by cops but also by debt collectors and private companies carrying out background checks. Private investigators use it to track cheating spouses. But in the wrong hands it can be used to steal the identity of almost anyone in America. And Da Boss and his crew got access to it.&lt;/p&gt;
&lt;p&gt;Writing in support of the court order to use the Nest camera footage in its investigation, U.S. Postal Service investigator Randall Berkland said TLO allowed users to research virtually anyone in the United States. Berkland would know: He’d used the tool extensively to investigate several crimes. And, he added, “Users would have unlimited access and resources to commit identity theft and fraud.”&lt;/p&gt;
&lt;p&gt;“The opportunity for misuse is massive,” says Cooper Quintin, a technologist with the Electronic Frontier Foundation, which advocates for Internet civil rights. “Even if one were to require a court order for access to this database it could still be stolen by hackers, spies or rogue employees and used for illegal and harmful purposes.”&lt;/p&gt;
&lt;p&gt;&lt;sup class=&quot;drop-cap color-accent font-accent&quot;&gt;F&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;ounded in 2009, TLO was the brainchild of the data mining pioneer Hank Asher, who died in 2013. The name, an abbreviation of The Last One, was Asher’s final entrepreneurial project, the third of a trio of massive data mining enterprises, which included Database Technologies and Seisint. Database Technologies, whose main product, AutoTrack, was used by insurance companies and cops to hunt down people’s vehicles, merged with Choicepoint in 2000; Seisint, which did much the same as Database Technology on a grander scale, sold to database goliath LexisNexis for $775 million in 2004. In 2008, Choicepoint was bought by LexisNexis’ parent company, Reed Elsevier, for $4.1 billion.&lt;/p&gt;
&lt;p&gt;Asher, a bulky, bearded, eccentric savant who admitted to smuggling cocaine into the U.S. in the 1980s (he never faced charges), was an innovator in the field of surveillance via data correlation, long before dark arts companies like Palo Alto, &lt;a href=&quot;https://www.forbes.com/sites/andygreenberg/2013/08/14/agent-of-intelligence-how-a-deviant-philosopher-built-palantir-a-cia-funded-data-mining-juggernaut/&quot; target=&quot;_blank&quot; class=&quot;color-accent&quot;&gt;California’s Palantir grew into unicorns sporting multibillion-dollar valuations.&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;“He was, in my humble opinion, a technology genius, a computer math genius,” says Martha Walters Barnett, a former TLO chief privacy officer. “He was among the first to acknowledge … that insignificant, unrelated pieces of data, when put together in the right way, could become a powerful tool.”&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.vanityfair.com/news/2004/12/matrix200412&quot; target=&quot;_blank&quot; class=&quot;color-accent&quot;&gt;According to a 2004 report in &lt;em&gt;Vanity Fair&lt;/em&gt;&lt;/a&gt;, Asher’s software helped identify associates of the 9/11 terrorists. It was later celebrated by Dick Cheney and Rudy Giuliani, though privacy activists warned it was a dangerous surveillance tool. Believing the privacy concerns around his work were overblown, Asher went on to create TLO. Though it was designed to hunt child predators, Asher had big ambitions for the product, which stalled after his death. A year later, &lt;a href=&quot;https://newsroom.transunion.com/transunion-completes-acquisition-of-tlo/&quot; target=&quot;_blank&quot; class=&quot;color-accent&quot;&gt;TransUnion bought TLO for $154 million&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Today TransUnion says TLO is capable of “processing trillions of records at sub-second speeds.” It can quickly uncover relevant data like individuals’ family members and social media profiles. One of the most important features for law enforcement combines photos from surveillance cameras with a huge trove of license plate numbers to nearly instantly track suspect vehicles. Among its biggest government clients are the Department of Justice, the Secret Service and the U.S. Navy. A license for a single user costs less than $1,500 a month.&lt;/p&gt;
&lt;p&gt;Barnett says she and Asher worked together to ensure there was no abuse of TLO. Onsite visits would be made to clients, who would undergo a strict vetting process. Only those who passed muster were given a login, Walters says. “We were very selective.”&lt;/p&gt;
&lt;p&gt;When it came to law enforcement, TLO was more trusting. From the very beginning, the software was made available to any cop in the country who wanted it.&lt;/p&gt;
&lt;p&gt;A TransUnion spokesperson says the same auditing processes are in place today, including site visits for every customer and multiple checks with state authorities to guarantee the authenticity of clients. But on occasion, crooks have found ways to slip through the cracks. And in 2017, the government alleged that a rogue employee at a debt collection company abused access to the database and worked with a group of young gangster rap wannabes to start stealing Americans’ identities.&lt;/p&gt;
&lt;p&gt;&lt;sup class=&quot;drop-cap color-accent font-accent&quot;&gt;I&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;t remains unclear just how many routes Da Boss and his crew had into TLO. But they had more than one. According to court records, Da Boss and a number of his crew (James Willingham, Deandre Howze and Alexsandera Mobley) had direct access to TLO information. Mobley was querying names on TLO as far back as October 2016, her indictment claims.&lt;/p&gt;
&lt;p&gt;At least at times, the rap crew bought their way in with the help of another charged coconspirator, Lakesiah Norman. Norman had direct access to TLO through her part-time work at an unnamed Charlotte debt collection agency between May and October 2017. That’s according to a court document supporting her plea agreement, signed in May 2018.&lt;/p&gt;
&lt;p&gt;Norman would query the database, find people with good credit ratings who were ripe targets for identity theft and sell their information, including name, Social Security number and date of birth. Norman did this for at least 20 people, charging just $100 for each victim’s data.&lt;/p&gt;
&lt;p&gt;Da Boss’ group got access in other ways, too. A TransUnion spokesperson told &lt;em&gt;Forbes&lt;/em&gt; that four other authorized customers of TLO had their access to the database abused by rogue employees to feed the FreeBandz Gang. The spokesperson declined to provide more detail.&lt;/p&gt;
&lt;p&gt;The irony that TLO was abused for months by the same kinds of thieves the surveillance tech was designed to ensnare has not been lost on critics of TransUnion. “Their whole business is supposedly identifying people,” says Jay Stanley, a senior policy analyst at the ACLU, “but they can’t even authenticate people who’re their customers.”&lt;/p&gt;
&lt;p&gt;&lt;sup class=&quot;drop-cap color-accent font-accent&quot;&gt;O&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;nce they’d stolen citizens’ identities, the rappers went on spending sprees, according to the government. The DOJ said the scammers used fake IDs to purchase and resell iPhones and iPads. They leased luxury apartments and purchased expensive cars. In one case, two of the coconspirators took out a fraudulent loan of about $30,000 and used the funds to acquire a 2014 Mercedes-Benz, according to North Carolina court filing supporting Mobley’s plea deal.&lt;/p&gt;
&lt;p&gt;It’s unclear if their Nest cameras were bought with illicit funds. But the purchase backfired. Just as the crooks turned the turbo-powered TLO software on its head, cops used the Nests against their owners. In June last year, Postal Service investigator Berkland obtained a warrant ordering Google to hand over all the data related to those cameras. The company complied, shipping surveillance footage back, along with personal details of its owners. It’s the first known case in the United States in which a federal law enforcement agency has demanded information from a Nest provider, and it has obvious implications for anyone who has purchased a smart home appliance that contains a camera or a microphone. The DOJ declined to comment.&lt;/p&gt;
&lt;p&gt;A Nest spokesperson says the company doesn’t comment on specific cases but notes that it has received demands for data from governments before, which it has revealed in a transparency report. Within that report are the number of requests received and the percentage of those requests that resulted in data being handed to the authorities. The report doesn’t break down requests by geography, and Nest didn’t provide information on the number of orders from the U.S. government.&lt;/p&gt;
&lt;p&gt;The various members of Da Boss’ gang pleaded guilty in July and are awaiting sentencing. It’s the first publicly known fraudulent use of TLO, but it has happened before. TransUnion says that while breaches like the one perpetrated by the FreeBandz Gang members are rare, it wasn’t the first time criminals have gained access to its databases. TransUnion declined to provide any specific detail on other incidents.&lt;/p&gt;
&lt;p&gt;Average citizens have little recourse. There’s no easy way to have their information removed from TLO. “As long as such a database exists,” says the EFF’s Quintin, “it is a threat to the privacy of every American.”&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Reach Thomas Brewster at tbrewster@forbes.com. Cover image by Richard Mia for Forbes.&lt;/em&gt;&lt;/p&gt;
</description>
<pubDate>Fri, 12 Oct 2018 20:52:56 +0000</pubDate>
<dc:creator>kawera</dc:creator>
<og:title>How An Amateur Rap Crew Stole Surveillance Tech That Tracks Almost Every American</og:title>
<og:image>https://thumbor.forbes.com/thumbor/0x0/smart/https%3A%2F%2Fspecials-images.forbesimg.com%2Fimageserve%2F5bc0a79a4bbe6f5889fcbbae%2F1920x0.jpg%3FcropX1%3D0%26cropX2%3D2720%26cropY1%3D0%26cropY2%3D1275</og:image>
<og:url>https://www.forbes.com/sites/thomasbrewster/2018/10/12/how-an-amateur-rap-crew-stole-surveillance-tech-that-tracks-almost-every-american/</og:url>
<og:description>Both the Freebandz Gang and its crimes would have been quickly forgotten as garden variety larceny were it not for the way it stole people's identities.</og:description>
<og:type>article</og:type>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.forbes.com/sites/thomasbrewster/2018/10/12/how-an-amateur-rap-crew-stole-surveillance-tech-that-tracks-almost-every-american/</dc:identifier>
</item>
</channel>
</rss>