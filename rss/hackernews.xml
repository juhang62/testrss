<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="css/feed.xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/" xmlns:og="http://ogp.me/ns#">
<channel>
<atom:link rel="self" href="http://192.168.1.4/fivefilters/makefulltextfeed.php?url=hnrss.org%2Fnewest%3Fpoints%3D200&amp;max=10&amp;links=preserve&amp;exc=" />
<atom:link rel="alternate" title="Source URL" href="http://hnrss.org/newest?points=200" />
<atom:link rel="related" title="Subscribe to feed" href="http://www.subtome.com/#/subscribe?feeds=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dhnrss.org%252Fnewest%253Fpoints%253D200%26max%3D10%26links%3Dpreserve%26exc%3D&amp;back=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dhnrss.org%252Fnewest%253Fpoints%253D200%26max%3D10%26links%3Dpreserve%26exc%3D" />
<title>Hacker News: Newest</title>
<link>https://news.ycombinator.com/newest</link>
<description>Hacker News RSS</description>
<item>
<title>Arrest Of U.S. Citizen For Assisting North Korea In Evading Sanctions</title>
<link>https://www.justice.gov/usao-sdny/pr/manhattan-us-attorney-announces-arrest-united-states-citizen-assisting-north-korea</link>
<guid isPermaLink="true" >https://www.justice.gov/usao-sdny/pr/manhattan-us-attorney-announces-arrest-united-states-citizen-assisting-north-korea</guid>
<description>&lt;p&gt;Geoffrey S. Berman, the United States Attorney for the Southern District of New York, John C. Demers, the Assistant Attorney General for National Security, John Brown, Assistant Director of the Federal Bureau of Investigation (“FBI”) Counterintelligence Division, and William F. Sweeney Jr., the Assistant Director-in-Charge of the New York Field Office of the FBI, announced today the unsealing of a criminal complaint charging VIRGIL GRIFFITH, a United States citizen, with violating the International Emergency Economic Powers Act (“IEEPA”) by traveling to the Democratic People’s Republic of Korea (“DPRK” or “North Korea”) in order deliver a presentation and technical advice on using cryptocurrency and blockchain technology to evade sanctions.  GRIFFITH was arrested at Los Angeles International Airport yesterday and will be presented in federal court in Los Angeles later today.&lt;/p&gt;
&lt;p&gt;U.S. Attorney Geoffrey S. Berman stated:  “As alleged, Virgil Griffith provided highly technical information to North Korea, knowing that this information could be used to help North Korea launder money and evade sanctions.  In allegedly doing so, Griffith jeopardized the sanctions that both Congress and the president have enacted to place maximum pressure on North Korea’s dangerous regime.”&lt;/p&gt;
&lt;p&gt;Assistant Attorney General John Demers said:  “Despite receiving warnings not to go, Griffith allegedly traveled to one of the United States’ foremost adversaries, North Korea, where he taught his audience how to use blockchain technology to evade sanctions.  By this complaint, we begin the process of seeking justice for such conduct.”&lt;/p&gt;
&lt;p&gt;FBI Assistant Director-in-Charge William F. Sweeney Jr. said:  “There are deliberate reasons sanctions have been levied on North Korea.  The country and its leader pose a literal threat to our national security and that of our allies.  Mr. Griffith allegedly traveled to North Korea without permission from the federal government, and with knowledge what he was doing was against the law.  We cannot allow anyone to evade sanctions, because the consequences of North Korea obtaining funding, technology, and information to further its desire to build nuclear weapons put the world at risk.  It’s even more egregious that a U.S. citizen allegedly chose to aid our adversary.”&lt;/p&gt;
&lt;p&gt;According to the Complaint unsealed today in Manhattan federal court&lt;a href=&quot;https://www.justice.gov/usao-sdny/pr/manhattan-us-attorney-announces-arrest-united-states-citizen-assisting-north-korea#_ftn1&quot; name=&quot;_ftnref1&quot; title=&quot;&quot; id=&quot;_ftnref1&quot;&gt;&lt;u&gt;[1]&lt;/u&gt;&lt;/a&gt;:&lt;/p&gt;
&lt;p&gt;Pursuant to the IEEPA and Executive Order 13466, United States Persons are prohibited from exporting any goods, services, or technology to the DPRK without a license from Department of the Treasury, Office of Foreign Assets Control (“OFAC”).&lt;/p&gt;
&lt;p&gt;In or about April 2019, GRIFFITH traveled to the DPRK to attend and present at the “Pyongyang Blockchain and Cryptocurrency Conference” (the “DPRK Cryptocurrency Conference”).  Despite that the U.S. Department of State had denied GRIFFITH permission to travel to the DPRK, GRIFFITH presented at the DPRK Cryptocurrency Conference, knowing that doing so violated sanctions against the DPRK.  At no time did GRIFFITH obtain permission from OFAC to provide goods, services, or technology to the DPRK.&lt;/p&gt;
&lt;p&gt;At the DPRK Cryptocurrency Conference, GRIFFITH and other attendees discussed how the DPRK could use blockchain and cryptocurrency technology to launder money and evade sanctions.  GRIFFITH’s presentation at the DPRK Cryptocurrency Conference had been approved by DPRK officials and focused on, among other things, how blockchain technology, including a “smart contract,” could be used to benefit the DPRK.  GRIFFITH identified several DPRK Cryptocurrency Conference attendees who appeared to work for the North Korean government, and who, during his presentation, asked GRIFFITH specific questions about blockchain and cryptocurrency and prompted discussions on technical aspects of those technologies.&lt;/p&gt;
&lt;p&gt;After the DPRK Cryptocurrency Conference, GRIFFITH began formulating plans to facilitate the exchange of cryptocurrency between the DPRK and South Korea, despite knowing that assisting with such an exchange would violate sanctions against the DPRK.  GRIFFITH also encouraged other U.S. citizens to travel to North Korea, including to attend the same DPRK Cryptocurrency Conference the following year.  Finally, GRIFFITH announced his intention to renounce his U.S. citizenship and began researching how to purchase citizenship from other countries.&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;*                      *                     *&lt;/p&gt;
&lt;p&gt;VIRGIL GRIFFITH, 36, is a resident of Singapore and citizen of the United States.  GRIFFITH is charged with conspiring to violate the IEEPA, which carries a maximum term of 20 years in prison.  The maximum potential sentence is prescribed by Congress and is provided here for informational purposes only, as any sentencing of the defendant will be determined by the judge.&lt;/p&gt;
&lt;p&gt;Mr. Berman praised the outstanding investigative work of the FBI and its New York Field Office, Counterintelligence Division, and thanked the Department of Justice’s National Security Division, Counterintelligence and Export Control Section, for their assistance.&lt;/p&gt;
&lt;p&gt;The case is being handled by the Office’s Terrorism and International Narcotics Unit.  Assistant U.S. Attorneys Kimberly Ravener, Michael K. Krouse, and Kyle A. Wirshba are in charge of the case, with assistance from Trial Attorneys Christian Ford and Matthew J. McKenzie of the Counterintelligence and Export Control Section.&lt;/p&gt;
&lt;p&gt;The charge in the Complaint is merely an accusation, and the defendant is presumed innocent unless and until proven guilty.&lt;/p&gt;
&lt;div readability=&quot;7.8969957081545&quot;&gt; 
&lt;hr align=&quot;left&quot; size=&quot;1&quot; width=&quot;33%&quot;/&gt;&lt;div readability=&quot;10.85652173913&quot;&gt;
&lt;p&gt;&lt;a href=&quot;https://usa.doj.gov/cloud/NYS/StAndrews/Shared/PressOffice/DRAFTS/Drafts%202019/11-November%202019/2019-11-29%20Virgil%20Griffith%20arrest%20PR/Virgil%20Griffith%20Arrest%20PR%20final.docx#_ftnref1&quot; name=&quot;_ftn1&quot; title=&quot;&quot; id=&quot;_ftn1&quot;&gt;&lt;u&gt;[1]&lt;/u&gt;&lt;/a&gt; As the introductory phrase signifies, the entirety of the text of the Complaint and the description of the Complaint set forth herein constitute only allegations, and every fact described should be treated as an allegation.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
</description>
<pubDate>Fri, 29 Nov 2019 18:34:58 +0000</pubDate>
<dc:creator>jmsflknr</dc:creator>
<og:type>article</og:type>
<og:title>Manhattan U.S. Attorney Announces Arrest Of United States Citizen For Assisting North Korea In Evading Sanctions</og:title>
<og:image>https://www.justice.gov/sites/all/modules/features/doj_sharing/images/doj-seal-fb.jpg</og:image>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.justice.gov/usao-sdny/pr/manhattan-us-attorney-announces-arrest-united-states-citizen-assisting-north-korea</dc:identifier>
</item>
<item>
<title>Open-Source Home Automation</title>
<link>https://www.home-assistant.io/?hn=true</link>
<guid isPermaLink="true" >https://www.home-assistant.io/?hn=true</guid>
<description>[unable to retrieve full-text content]
&lt;p&gt;Article URL: &lt;a href=&quot;https://www.home-assistant.io/?hn=true&quot;&gt;https://www.home-assistant.io/?hn=true&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Comments URL: &lt;a href=&quot;https://news.ycombinator.com/item?id=21665125&quot;&gt;https://news.ycombinator.com/item?id=21665125&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Points: 501&lt;/p&gt;
&lt;p&gt;# Comments: 159&lt;/p&gt;
</description>
<pubDate>Fri, 29 Nov 2019 16:06:31 +0000</pubDate>
<dc:creator>neya</dc:creator>
<og:title>Home Assistant</og:title>
<og:url>https://www.home-assistant.io/</og:url>
<og:type>website</og:type>
<og:description>Open source home automation that puts local control and privacy first.</og:description>
<og:image>https://www.home-assistant.io/images/default-social.png</og:image>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.home-assistant.io/?hn=true</dc:identifier>
</item>
<item>
<title>Syntax Highlighting Is Backwards (2018)</title>
<link>https://www.benkuhn.net/syntax</link>
<guid isPermaLink="true" >https://www.benkuhn.net/syntax</guid>
<description>&lt;p&gt;Most code editors color different pieces of your program in different ways. For instance, they’ll make keywords like &lt;strong&gt;&lt;code&gt;if&lt;/code&gt;&lt;/strong&gt; bold and bright so that you notice when you’ve misspelled them. They’ll make non-executable parts like comments and documentation fainter so that you know that the computer isn’t seeing that part of the program. Take this example in Pycharm colors:&lt;/p&gt;
&lt;pre&gt;
&lt;span class=&quot;kw&quot;&gt;def&lt;/span&gt; frobnicate(swizzle):
    &lt;span class=&quot;doc&quot;&gt;&quot;&quot;&quot;Frobnicates the given swizzle.&quot;&quot;&quot;&lt;/span&gt;
    &lt;span class=&quot;kw&quot;&gt;pass&lt;/span&gt;
&lt;/pre&gt;
&lt;p&gt;But isn’t this exactly backwards?&lt;/p&gt;
&lt;ul readability=&quot;4.5&quot;&gt;&lt;li readability=&quot;5&quot;&gt;
&lt;p&gt;I want the syntax of my language to get out of my way, not jump into the foreground. I can easily recognize keywords, and I’d rather focus on the parts of the code with higher information density—method names, arguments, and so on.&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;4&quot;&gt;
&lt;p&gt;If your code is locally readable, then there are only two times you need comments: (a) high level overviews and signposts; or (b) to call out some tricky non-local effect of the code. These are the two most important and least straightforward parts of programming: I want them &lt;em&gt;emphasized&lt;/em&gt;, not faded out!&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;Take as an example the following function definition from the Zulip codebase (&lt;a href=&quot;https://github.com/zulip/zulip/blob/83d422d5bc7008725d38fb2a29d8da925e6234dd/zerver/lib/avatar_hash.py#L30&quot;&gt;source&lt;/a&gt;):&lt;/p&gt;
&lt;pre&gt;
&lt;span class=&quot;kw&quot;&gt;def&lt;/span&gt; user_avatar_path(user_profile: UserProfile) -&amp;gt; &lt;span class=&quot;bi&quot;&gt;str&lt;/span&gt;:
    &lt;span class=&quot;doc&quot;&gt;# WARNING: If this method is changed, you may need to do
    # a migration similar to
    # zerver/migrations/0060_move_avatars_to_be_uid_based.py .&lt;/span&gt;
    &lt;span class=&quot;kw&quot;&gt;return&lt;/span&gt; user_avatar_path_from_ids(
        user_profile.id, user_profile.realm_id)
&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;def&lt;/code&gt; is the least important part of this snippet—I know it’s a function. The comment is way more important: if I update the code without reading it, I’ll probably ship a bug.&lt;/p&gt;
&lt;p&gt;So what if we flipped these two styles?&lt;/p&gt;
&lt;pre&gt;
&lt;span class=&quot;kw2&quot;&gt;def&lt;/span&gt; user_avatar_path(user_profile: UserProfile) -&amp;gt; str:
    &lt;span class=&quot;doc2&quot;&gt;# WARNING: If this method is changed, you may need to do
    # a migration similar to
    # zerver/migrations/0060_move_avatars_to_be_uid_based.py .&lt;/span&gt;
    &lt;span class=&quot;kw2&quot;&gt;return&lt;/span&gt; user_avatar_path_from_ids(
        user_profile.id, user_profile.realm_id)
&lt;/pre&gt;
&lt;p&gt;Seems better! The keywords fade into the background and I definitely won’t forget to write a migration. I’m not convinced about bolding every comment—it’s a little obtrusive—but I don’t have any better ideas and I’d rather read too many comments than not enough.&lt;/p&gt;
&lt;p&gt;I’ve been using this color scheme for a few weeks now and it’s been fine so far! The most noticeable effect is that my source code is way less noisy and distracting. I think I’m paying attention to comments more (and leaving them to be stale less often), but that’s a lot harder to tell so I can’t say for sure.&lt;/p&gt;
&lt;p&gt;Random notes:&lt;/p&gt;
&lt;ul readability=&quot;11.852280955829&quot;&gt;&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;I really do want to find something better than bold for comments.&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;5.8930693069307&quot;&gt;
&lt;p&gt;I was curious why many languages today display keywords in bold so I looked up the history of syntax highlighting on Wikipedia. It sounds like the first IDE to bold keywords may have been &lt;a href=&quot;https://en.wikipedia.org/wiki/Syntax_highlighting#cite_ref-macpascal_9-0&quot;&gt;MacPascal&lt;/a&gt;, which was written for a monochrome display. In that case it makes sense: with a monochrome display and one font, they could either make keywords bold or make everything else bold, and keywords was the less-intrusive option. But now that we have 16-million-color displays, maybe it’s time to revisit that.&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;4.9090909090909&quot;&gt;
&lt;p&gt;I started thinking about this after discovering Robert Melton’s &lt;a href=&quot;https://www.robertmelton.com/posts/syntax-highlighting-off/&quot;&gt;No Frils&lt;/a&gt; Vim theme, which I noticed also has an option “to turn on high contrast comments rather than the default faded style, for projects where the comments are not deceit and lies.” Maybe the deceit and lies problem is why this isn’t more popular? On the other hand, it seems like fading out comments and docstrings probably makes the staleness problem a lot worse.&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;4&quot;&gt;
&lt;p&gt;It’s also probably a lot easier to do this in codebases with familiar and obvious naming conventions (e.g. classes are &lt;code&gt;CamelCase&lt;/code&gt;, functions are verbs, decorators are adjectives, timestamps start with &lt;code&gt;when_&lt;/code&gt;…).&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;1&quot;&gt;
&lt;p&gt;I tried to search around for any systematic studies of what kinds of syntax highlighting help, and I couldn’t find a single one. I’d love any pointers.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;</description>
<pubDate>Fri, 29 Nov 2019 16:04:15 +0000</pubDate>
<dc:creator>pcr910303</dc:creator>
<og:title>Syntax highlighting is backwards</og:title>
<og:description>Most code editors color different pieces of your program in different ways. For instance, they’ll make keywords like if bold and bright so that you notice when you’ve misspelled them. They’ll make non-executable parts like comments and documentation fainter so that you know that the computer isn’t seeing that part of the program. But isn’t that exactly backwards?</og:description>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.benkuhn.net/syntax</dc:identifier>
</item>
<item>
<title>How Is NordVPN Unblocking Disney+?</title>
<link>https://medium.com/@derek./how-is-nordvpn-unblocking-disney-6c51045dbc30</link>
<guid isPermaLink="true" >https://medium.com/@derek./how-is-nordvpn-unblocking-disney-6c51045dbc30</guid>
<description>&lt;div readability=&quot;7.0674846625767&quot;&gt;

&lt;div class=&quot;dm&quot;&gt;
&lt;div class=&quot;n dn do dp dq&quot;&gt;
&lt;div class=&quot;o n&quot;&gt;
&lt;div&gt;
&lt;div class=&quot;dr ds dt&quot;&gt;

&lt;img alt=&quot;Derek Johnson&quot; class=&quot;r ea dt ds&quot; src=&quot;https://miro.medium.com/fit/c/96/96/1*dmbNkD5D-u45r44go_cf0g.png&quot; width=&quot;48&quot; height=&quot;48&quot;/&gt;&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p id=&quot;3d39&quot; class=&quot;fl fm dc bk fn b fo fp fq fr fs ft fu fv fw fx fy&quot;&gt;NordVPN, a company reeling from &lt;a href=&quot;https://twitter.com/gertvdijk/status/1186424630132776960&quot; class=&quot;at cg fz ga gb gc&quot; target=&quot;_blank&quot; rel=&quot;noopener nofollow&quot;&gt;careless security practices&lt;/a&gt; revealed as part of a &lt;a href=&quot;https://techcrunch.com/2019/10/21/nordvpn-confirms-it-was-hacked/&quot; class=&quot;at cg fz ga gb gc&quot; target=&quot;_blank&quot; rel=&quot;noopener nofollow&quot;&gt;security breach&lt;/a&gt; (one that they covered up for 6 months until they were finally &lt;a href=&quot;https://twitter.com/hexdefined/status/1185864801261477891&quot; class=&quot;at cg fz ga gb gc&quot; target=&quot;_blank&quot; rel=&quot;noopener nofollow&quot;&gt;outed&lt;/a&gt; for it), had promised to do better.&lt;/p&gt;
&lt;p id=&quot;05b1&quot; class=&quot;fl fm dc bk fn b fo fp fq fr fs ft fu fv fw fx fy&quot;&gt;From the &lt;a href=&quot;https://nordvpn.com/blog/security-plan/&quot; class=&quot;at cg fz ga gb gc&quot; target=&quot;_blank&quot; rel=&quot;noopener nofollow&quot;&gt;NordVPN blog&lt;/a&gt;:&lt;/p&gt;
&lt;blockquote class=&quot;gd ge gf&quot; readability=&quot;9&quot;&gt;
&lt;p id=&quot;11fb&quot; class=&quot;fl fm dc gg fn b fo fp fq fr fs ft fu fv fw fx fy&quot;&gt;This is about explaining what we’re going to do to take our security to the next level and make sure nothing like that ever happens again…. We’ve learned our lesson and we want to prove it to you with actions, not just words…. What we can promise is that we have taken this incident to heart and will do everything we can to improve and to win back your trust.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p id=&quot;78ef&quot; class=&quot;fl fm dc bk fn b fo fp fq fr fs ft fu fv fw fx fy&quot;&gt;That surely sounds nice, but is it true?&lt;/p&gt;
&lt;p id=&quot;5e46&quot; class=&quot;fl fm dc bk fn b fo fp fq fr fs ft fu fv fw fx fy&quot;&gt;What I’m about to tell you is shocking, and reveals the true nature of NordVPN’s business practices.&lt;/p&gt;

&lt;p id=&quot;5973&quot; class=&quot;fl fm dc bk fn b fo gv fq gw fs gx fu gy fw gz fy&quot;&gt;See the problem is, NordVPN is linked closely with a Lithuanian data mining company called Tesonet. NordVPN is said to be &lt;a href=&quot;https://news.ycombinator.com/item?id=18609655&quot; class=&quot;at cg fz ga gb gc&quot; target=&quot;_blank&quot; rel=&quot;noopener nofollow&quot;&gt;one of Tesonet’s projects&lt;/a&gt;, Oxylabs.io is another one.&lt;/p&gt;
&lt;p id=&quot;9903&quot; class=&quot;fl fm dc bk fn b fo fp fq fr fs ft fu fv fw fx fy&quot;&gt;So what’s the big deal? &lt;a href=&quot;https://oxylabs.io/&quot; class=&quot;at cg fz ga gb gc&quot; target=&quot;_blank&quot; rel=&quot;noopener nofollow&quot;&gt;Oxylabs.io&lt;/a&gt; advertises on its website “32M+ residential proxies…100% anonymous proxies from all over the globe with zero IP blocking.” Think of “residential proxies” this way: 1.) Oxylabs installs some malware on to a user’s device, unknown to the user, by bundling it with other software that the user downloads. 2.)This malware enables Oxylabs to sell off your bandwidth, your computing power, and your IP address to third parties, who will route their internet traffic through your device.&lt;/p&gt;
&lt;p id=&quot;1c65&quot; class=&quot;fl fm dc bk fn b fo fp fq fr fs ft fu fv fw fx fy&quot;&gt;Does that mean your device can be used by a third party to access child porn or hack into a bank? Absolutely! Another VPN provider named Hola was &lt;a href=&quot;https://www.pcworld.com/article/2928340/ultra-popular-hola-vpn-extension-sold-your-bandwidth-for-use-in-a-botnet-attack.html&quot; class=&quot;at cg fz ga gb gc&quot; target=&quot;_blank&quot; rel=&quot;noopener nofollow&quot;&gt;called out&lt;/a&gt; for reselling users’ bandwidth in this way through their B2B service (Luminati), and incidentally &lt;a href=&quot;https://restoreprivacy.com/lawsuit-names-nordvpn-tesonet/&quot; class=&quot;at cg fz ga gb gc&quot; target=&quot;_blank&quot; rel=&quot;noopener nofollow&quot;&gt;Hola is suing Tesonet&lt;/a&gt; for copying Hola’s technology.&lt;/p&gt;
&lt;p id=&quot;68a1&quot; class=&quot;fl fm dc bk fn b fo fp fq fr fs ft fu fv fw fx fy&quot;&gt;NordVPN has gone out of their way to downplay their ties to Oxylabs and Tesonet. In a &lt;a href=&quot;https://nordvpn.com/blog/nordvpn-false-allegations/&quot; class=&quot;at cg fz ga gb gc&quot; target=&quot;_blank&quot; rel=&quot;noopener nofollow&quot;&gt;blog post&lt;/a&gt; addressing the alleged corporate links between NordVPN and Tesonet (links that they never denied), NordVPN writes that it’s false “that our VPN clients are being used to turn our users into a botnet” and that “we have never in any way been related to any other projects developed by Tesonet.”&lt;/p&gt;
&lt;p id=&quot;3fab&quot; class=&quot;fl fm dc bk fn b fo fp fq fr fs ft fu fv fw fx fy&quot;&gt;So NordVPN has nothing to do with Oxylabs then, right? After all, they couldn’t possibly be incorporating any part of Oxylabs technology into NordVPN’s apps, according to NordVPN’s blog post. I decided to dig deeper.&lt;/p&gt;

&lt;p id=&quot;7317&quot; class=&quot;fl fm dc bk fn b fo gv fq gw fs gx fu gy fw gz fy&quot;&gt;Disney+ is a streaming service that launched on November 12, 2019. That’s more than 2 weeks after the NordVPN security breach reports surfaced, and it’s after NordVPN had promised to take actions to win back users’ trust.&lt;/p&gt;
&lt;p id=&quot;1dc8&quot; class=&quot;fl fm dc bk fn b fo fp fq fr fs ft fu fv fw fx fy&quot;&gt;Disney+ is currently available in select countries. If I live in the US I can subscribe and watch with no need for a VPN. But if I live in the UK I would need to proxy the stream through a remote US server using a service like NordVPN. It’s often the case that VPN users will find that services like Disney+ are blocked on many servers, presumably because the content provider is able to discover the VPN’s IP addresses and restrict access to those IPs. Sure enough, I tried 2 other VPN providers that I’m familiar with, and neither could unblock Disney+.&lt;/p&gt;
&lt;p id=&quot;e153&quot; class=&quot;fl fm dc bk fn b fo fp fq fr fs ft fu fv fw fx fy&quot;&gt;Then I decided to give NordVPN a try, and poof, it worked like a charm. How was this possible? Residential IPs was my guess. These would serve the purpose to confuse Disney+ and make them believe that the traffic was not coming from a VPN server housed in a data center. Simple obfuscation.&lt;/p&gt;

&lt;p id=&quot;091a&quot; class=&quot;fl fm dc bk fn b fo gv fq gw fs gx fu gy fw gz fy&quot;&gt;My first step was to see which CDN serves disneyplus.com content. According to &lt;a href=&quot;https://www.cloudflare.com/learning/cdn/what-is-a-cdn/&quot; class=&quot;at cg fz ga gb gc&quot; target=&quot;_blank&quot; rel=&quot;noopener nofollow&quot;&gt;Cloudflare&lt;/a&gt;, “a content delivery network (CDN) refers to a geographically distributed group of servers which work together to provide fast delivery of Internet content.” A web tool revealed that www.disneyplus.com uses Akamai.&lt;/p&gt;

&lt;p id=&quot;32f1&quot; class=&quot;fl fm dc bk fn b fo fp fq fr fs ft fu fv fw fx fy&quot;&gt;That’s perfect, because I know that Akamai provides an additional tool to help webmasters debug any issues they may be encountering with the CDN. In technical jargon it’s called a Pragma header, and using a command in Linux, Akamai allows you to observe the actual client IP address that is sending and receiving traffic.&lt;/p&gt;
&lt;p id=&quot;fdeb&quot; class=&quot;fl fm dc bk fn b fo fp fq fr fs ft fu fv fw fx fy&quot;&gt;So it’s really quite straightforward. I launched my Linux VM, connected to a US NordVPN server and ran a simple command to get the IP address.&lt;/p&gt;

&lt;p id=&quot;e400&quot; class=&quot;fl fm dc bk fn b fo fp fq fr fs ft fu fv fw fx fy&quot;&gt;NordVPN is sending traffic to Disney+ through 174.134.22.78. Next I looked up the IP.&lt;/p&gt;

&lt;p id=&quot;0f31&quot; class=&quot;fl fm dc bk fn b fo fp fq fr fs ft fu fv fw fx fy&quot;&gt;OK so Charter Communications aka Spectrum. Yes it’s a &lt;a href=&quot;https://www.spectrum.com/&quot; class=&quot;at cg fz ga gb gc&quot; target=&quot;_blank&quot; rel=&quot;noopener nofollow&quot;&gt;residential ISP&lt;/a&gt;, but they also provide services to &lt;a href=&quot;https://enterprise.spectrum.com/services/network/ethernet.html&quot; class=&quot;at cg fz ga gb gc&quot; target=&quot;_blank&quot; rel=&quot;noopener nofollow&quot;&gt;large companies&lt;/a&gt;. It’s not crazy to think that NordVPN could have bought an uplink from them and connected it in their data center. Nothing nefarious here on the surface.&lt;/p&gt;
&lt;p id=&quot;6f0c&quot; class=&quot;fl fm dc bk fn b fo fp fq fr fs ft fu fv fw fx fy&quot;&gt;OK, what else can I find? I decided to re-run the command in Linux…30 more times.&lt;/p&gt;

&lt;p id=&quot;8116&quot; class=&quot;fl fm dc bk fn b fo gv fq gw fs gx fu gy fw gz fy&quot;&gt;Below are the IPs I got back:&lt;/p&gt;

&lt;p id=&quot;3a97&quot; class=&quot;fl fm dc bk fn b fo fp fq fr fs ft fu fv fw fx fy&quot;&gt;OK now here we go…&lt;/p&gt;
&lt;p id=&quot;c8de&quot; class=&quot;fl fm dc bk fn b fo fp fq fr fs ft fu fv fw fx fy&quot;&gt;All the most common US ISPs are there… AT&amp;amp;T, Comcast, Verizon, CenturyLink. IPs from Charter Communications in their Midwest, Texas, Pacwest and Northeast regions. ISPs I’ve never heard of before… who the heck is Delcom? Turns out they are serving some &lt;a href=&quot;https://broadbandnow.com/DELCOM&quot; class=&quot;at cg fz ga gb gc&quot; target=&quot;_blank&quot; rel=&quot;noopener nofollow&quot;&gt;rural communities in Texas&lt;/a&gt;. Did NordVPN buy servers or connectivity from them?&lt;/p&gt;
&lt;p id=&quot;7891&quot; class=&quot;fl fm dc bk fn b fo fp fq fr fs ft fu fv fw fx fy&quot;&gt;So any theories on how NordVPN is getting all this terrific, unblockable, residential connectivity? Could they be buying it from Hola/Luminati, the very company that is suing them? Doubtful. The most likely conclusion is that they are using their own Oxylabs to do it, the very service that NordVPN claimed that they had nothing to do with.&lt;/p&gt;
&lt;p id=&quot;cbe1&quot; class=&quot;fl fm dc bk fn b fo fp fq fr fs ft fu fv fw fx fy&quot;&gt;As a NordVPN user, what does all of this mean for you? Are you less secure because your traffic is being routed through the PC of some random farmer in Texas? Not really. The traffic you send to disneyplus.com is encrypted and can’t be observed by the farmer (or his cows).&lt;/p&gt;

&lt;p id=&quot;7cd2&quot; class=&quot;fl fm dc bk fn b fo gv fq gw fs gx fu gy fw gz fy&quot;&gt;That’s really the key issue. The unsuspecting Texan downloaded a &lt;a href=&quot;https://cdn-resprivacy.pressidium.com/wp-content/uploads/2018/08/Luminati-Networks-LTD-vs-UAB-Tesonet.pdf&quot; class=&quot;at cg fz ga gb gc&quot; target=&quot;_blank&quot; rel=&quot;noopener nofollow&quot;&gt;GPS navigation app&lt;/a&gt; or a financial calculator app, and secretly embedded in the software is code that enables the Oxylabs residential proxy network to run from his device. Did our farmer friend download that app knowing that he’d be letting NordVPN freeload on his internet connection, passing users’ Disney+ traffic through his device? Hardly. He likely has never heard of NordVPN, and perhaps hasn’t heard of Disney+ either. What if NordVPN is passing other types of traffic through his device, including something much more nefarious than the Lion King movie?. Our friend would be none the wiser.&lt;/p&gt;
&lt;p id=&quot;b8bd&quot; class=&quot;fl fm dc bk fn b fo fp fq fr fs ft fu fv fw fx fy&quot;&gt;NordVPN had promised to do better, but this seems like a step back. They promised they had nothing to do with Oxylabs, but now that assertion seems to be false. They violate unsuspecting internet users, and even trample over &lt;a href=&quot;https://www.wilderssecurity.com/threads/nordvpn-app-sends-sensitive-data-to-various-trackers.412396/&quot; class=&quot;at cg fz ga gb gc&quot; target=&quot;_blank&quot; rel=&quot;noopener nofollow&quot;&gt;their own customers’ privacy&lt;/a&gt;. Yes, why would you send all your customer email addresses to a &lt;a href=&quot;https://iterable.com/&quot; class=&quot;at cg fz ga gb gc&quot; target=&quot;_blank&quot; rel=&quot;noopener nofollow&quot;&gt;3rd party marketing company&lt;/a&gt;, NordVPN?&lt;/p&gt;
&lt;p id=&quot;edeb&quot; class=&quot;fl fm dc bk fn b fo fp fq fr fs ft fu fv fw fx fy&quot;&gt;If you want to be taken seriously as a privacy and security company, why don’t you start acting like one? Farmers in Texas (and most of your customers) are depending on you to clean up your act.&lt;/p&gt;
</description>
<pubDate>Fri, 29 Nov 2019 14:51:56 +0000</pubDate>
<dc:creator>dagurp</dc:creator>
<og:type>article</og:type>
<og:title>How is NordVPN unblocking Disney+?</og:title>
<og:description>NordVPN, a company reeling from careless security practices revealed as part of a security breach (one that they covered up for 6 months…</og:description>
<og:url>https://medium.com/@derek./how-is-nordvpn-unblocking-disney-6c51045dbc30</og:url>
<og:image>https://miro.medium.com/max/1162/0*Z0F9J6GCkca6irdy</og:image>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://medium.com/@derek./how-is-nordvpn-unblocking-disney-6c51045dbc30</dc:identifier>
</item>
<item>
<title>The Siege of Gondor, Part I: Professionals Talk Logistics</title>
<link>https://acoup.blog/2019/05/10/collections-the-siege-of-gondor/</link>
<guid isPermaLink="true" >https://acoup.blog/2019/05/10/collections-the-siege-of-gondor/</guid>
<description>&lt;p&gt;This is the first part of a six-part (&lt;a href=&quot;https://acoup.blog/2019/05/17/collections-the-siege-of-gondor-part-ii-these-beacons-are-liiiiiiit/&quot;&gt;II&lt;/a&gt;, &lt;a href=&quot;https://acoup.blog/2019/05/24/collections-the-siege-of-gondor-part-iii-having-fun-storming-the-city/&quot;&gt;III&lt;/a&gt;, &lt;a href=&quot;https://acoup.blog/2019/05/31/collections-the-siege-of-gondor-part-iv-the-cavalry-arrives/&quot;&gt;IV&lt;/a&gt;, &lt;a href=&quot;https://acoup.blog/2019/06/07/collections-the-siege-of-gondor-part-v-just-flailing-about-flails/&quot;&gt;V&lt;/a&gt;, &lt;a href=&quot;https://acoup.blog/2019/06/14/collections-the-siege-of-gondor-part-vi-black-sails-and-gleaming-banners/&quot;&gt;VI&lt;/a&gt;) series I expect to roll out taking a historian’s look at the Siege of Gondor in Peter Jackson’s &lt;em&gt;Return of the King&lt;/em&gt;.  We’re going to discuss how historically plausible the sequence of events is and, in the process, talk a fair bit about how pre-gunpowder siege warfare works. As with other Collections posts, this series will come out one-per-week, on Friday, until it’s done.  This is, after all, a very long and involved sequence and there is a lot of context to work in.&lt;/p&gt;
&lt;blockquote class=&quot;wp-block-quote&quot;&gt;
&lt;p&gt;&lt;strong&gt;Book Notes&lt;/strong&gt;: While I am not going note &lt;em&gt;every&lt;/em&gt; time Jackson diverges from the books, I will note significant divergences when they impact the historical review.  When I do so, I’ll place those portions in a little box like this.  I am one of those people who was a book person first – I heard these stories for the first time literally before I could read, having them read to me by my parents.  That said, discussing the book here is more than just nostalgia.  Tolkien’s deep knowledge of Anglo-Saxon literature left him with a fairly keen sense of how pre-modern battle worked.  His own experience in the First World War also leaves deep impressions on the narrative, as we’ll see.  That deeper knowledge and personal experience is often most visible in places where the film and the books part ways, and offer some of the best opportunities to illuminate key details about pre-modern siege warfare.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;So, without further ado, let’s get to it.&lt;/p&gt;
&lt;h2&gt;&lt;em&gt;Objectives: Strategy and Operations&lt;/em&gt;&lt;/h2&gt;
&lt;img data-attachment-id=&quot;96&quot; data-permalink=&quot;https://acoup.blog/orc-army-minas-morgul-1/&quot; data-orig-file=&quot;https://acoupdotblog.files.wordpress.com/2019/05/orc-army-minas-morgul-1.png&quot; data-orig-size=&quot;926,659&quot; data-comments-opened=&quot;1&quot; data-image-meta=&quot;{&amp;quot;aperture&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;credit&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;camera&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;caption&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;created_timestamp&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;copyright&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;focal_length&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;iso&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;shutter_speed&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;title&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;orientation&amp;quot;:&amp;quot;0&amp;quot;}&quot; data-image-title=&quot;orc-army-minas-morgul-1&quot; data-image-description=&quot;&quot; data-medium-file=&quot;https://acoupdotblog.files.wordpress.com/2019/05/orc-army-minas-morgul-1.png?w=300&quot; data-large-file=&quot;https://acoupdotblog.files.wordpress.com/2019/05/orc-army-minas-morgul-1.png?w=926&quot; src=&quot;https://acoupdotblog.files.wordpress.com/2019/05/orc-army-minas-morgul-1.png&quot; alt=&quot;&quot; class=&quot;wp-image-96&quot;/&gt;Note that the orcs are five abreast and tightly packed. An army does not normally march this tightly over long distances (note, for instance, there is no space for backpacks or any of the other kit soldiers have to lug).
&lt;p&gt;We’re going to start here, with the army of Minas Morgul marshaling out of the main gate.  It is an incredible scene, the seemingly endless line of orcs marching past our hidden heroes, who crouch, overawed by the spectacle of it.&lt;/p&gt;
&lt;p&gt;That may seem a touch early to start a review of the siege, but there are two points to this, both of which are historically illuminating.  What we are watching at this stage is what is called &lt;em&gt;operations&lt;/em&gt; – the coordinated movement of large bodies of troops to their objective.  Operations is the level of analysis between tactics (how do I fight when I get there?) and strategy (why am I fighting at all?).  And its worth asking, before proceeding any further: what is Sauron’s overall plan and does it make sense?&lt;/p&gt;
&lt;img data-attachment-id=&quot;99&quot; data-permalink=&quot;https://acoup.blog/map/&quot; data-orig-file=&quot;https://acoupdotblog.files.wordpress.com/2019/05/map.png&quot; data-orig-size=&quot;1168,797&quot; data-comments-opened=&quot;1&quot; data-image-meta=&quot;{&amp;quot;aperture&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;credit&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;camera&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;caption&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;created_timestamp&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;copyright&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;focal_length&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;iso&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;shutter_speed&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;title&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;orientation&amp;quot;:&amp;quot;0&amp;quot;}&quot; data-image-title=&quot;map&quot; data-image-description=&quot;&quot; data-medium-file=&quot;https://acoupdotblog.files.wordpress.com/2019/05/map.png?w=300&quot; data-large-file=&quot;https://acoupdotblog.files.wordpress.com/2019/05/map.png?w=1024&quot; src=&quot;https://acoupdotblog.files.wordpress.com/2019/05/map.png&quot; alt=&quot;&quot; class=&quot;wp-image-99&quot;/&gt;This map is from the LotR Project (&lt;a href=&quot;http://lotrproject.com/&quot; rel=&quot;nofollow&quot;&gt;http://lotrproject.com/&lt;/a&gt;) – go check them out.
&lt;p&gt;Because we’re looking at &lt;em&gt;operations&lt;/em&gt;, a map is going to be useful, so here is one – I suggest pulling it out into a separate tab so you can keep a sense of where things are.&lt;/p&gt;
&lt;p&gt;In this context, the immediate operational goal of Sauron’s army is getting the army, intact, to Minas Tirith to lay siege to it; in comparison, the &lt;em&gt;strategic&lt;/em&gt; goal of the campaign is the destruction of the Kingdom of Gondor through the capture of its capital and primary defense (Minas Tirith).&lt;/p&gt;
&lt;p&gt;This set of objectives and the means chosen to achieve them are immediately historically plausible.  Pre-modern states – like the Kingdom of Gondor – often had a very limited administrative apparatus which was focused in a single place (it is hard to distribute your administration when the best communications technology you have is “man on horse”).  The destruction of that administrative center might very well be enough to end the war.&lt;/p&gt;
&lt;p&gt;More broadly, it is fair to say that &lt;em&gt;most&lt;/em&gt; pre-modern operations had this objective: to &lt;strong&gt;deliver the siege&lt;/strong&gt; (hat tip to &lt;a href=&quot;https://twitter.com/MilHist_Lee&quot;&gt;@MilHist_Lee&lt;/a&gt;).  While fiction tends to focus a lot on battles, an open field battle was rarely the objective of a campaign – rather a battle resulted because one army, in transit to an enemy city to begin a siege, was opposed by another army attempting to stop them. &lt;/p&gt;
&lt;p&gt;Let’s be clear on this point: ancient and medieval warfare was &lt;strong&gt;mostly about sieges&lt;/strong&gt;. Particularly during the Middle Ages (in Europe) sieges (and raiding) were common, but large pitched battles were rare. Pitched battles were far more common in the ancient world (think Persia, Macedon, Rome, etc) – this is a product of the larger size and greater organizational capabilities of those armies. Because of that, they were much more likely to win a siege – the defenders &lt;em&gt;know that&lt;/em&gt;, so if you cannot defeat them in battle, it was better to surrender than try to hold out (a city taken in a siege was often subject to pillaging and massacre). Of course, this only works if the army approaching you can credibly siege your city – even in the absence of a siege itself, the &lt;strong&gt;threat of siege&lt;/strong&gt; was crucial.&lt;/p&gt;
&lt;p&gt;Another short side-note here: we’ve been talking in terms of fortified cities, because that is what Minas Tirith is, but castles – which are fortified private residences – operate mostly on the same basic set of rules (the court and household of the military aristocrat whose house has been fortified is generally also the local administrative apparatus). In both cases, control of the fortified center is what allows for control of the countryside around it. Consequently, the goal of the army is not to fight a big battle, but to deliver a siege to the fortified center, castle or city, which can capture it and thus take over administration of the countryside (where most of the economic activity – farming – takes place).&lt;/p&gt;
&lt;p&gt;The goals here (operational objectives) of Sauron’s plan here absolutely check out.  Minas Tirith contains most of Gondor’s military, and functionally all of its leadership and administration – its destruction could very well be war-ending. At the very least, control of Minas Tirith would open the rest of Gondor to raiding as well as enable Sauron to control the resource-rich Pelennor Fields. Delivering a powerful and effective siege (the operational objective) is very likely to lead to victory over Gondor and territorial control of it (the strategic objective). Now the question is Sauron’s plan to achieve that operational objective (we will talk about Gondor’s planning too – a little later in the series).&lt;/p&gt;
&lt;p&gt;Now, as we’ve noted, operations are all about the problem of moving large armies.  Late season &lt;em&gt;Game of Thrones&lt;/em&gt; notwithstanding, armies do not generally teleport around the world, they have to march.  That imposes all sorts of restrictions and costs on movement: where are the roads?  Mountain passes?  River Crossings?  The terrain Sauron’s army must attack over is defined (as we’ll see) by a series of transport bottlenecks that have to be negotiated in order to deliver the siege.  Then there is the issue of supplies – even orcs need to eat.&lt;/p&gt;
&lt;h2&gt;&lt;em&gt;Logistics of the Army of Mordor&lt;/em&gt;&lt;/h2&gt;
&lt;p&gt;Looking at the logistics of moving the Army of Mordor to Minas Tirith is actually a great way to introduce some of these problems in more depth.  They say ‘amateurs talk tactics, but professionals study logistics.’  Well, pull up a chair at the Grown-Ups Table, and let’s study some logistics.&lt;/p&gt;
&lt;p&gt;The army Sauron sends against Minas Tirith is absolutely vast – an army so vast that it cannot fit its entire force in the available frontage, so the army ends up stacking up in front of the city:&lt;/p&gt;
&lt;img data-attachment-id=&quot;94&quot; data-permalink=&quot;https://acoup.blog/huge-orc-army/&quot; data-orig-file=&quot;https://acoupdotblog.files.wordpress.com/2019/05/huge-orc-army.png&quot; data-orig-size=&quot;1363,707&quot; data-comments-opened=&quot;1&quot; data-image-meta=&quot;{&amp;quot;aperture&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;credit&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;camera&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;caption&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;created_timestamp&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;copyright&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;focal_length&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;iso&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;shutter_speed&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;title&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;orientation&amp;quot;:&amp;quot;0&amp;quot;}&quot; data-image-title=&quot;huge-orc-army&quot; data-image-description=&quot;&quot; data-medium-file=&quot;https://acoupdotblog.files.wordpress.com/2019/05/huge-orc-army.png?w=300&quot; data-large-file=&quot;https://acoupdotblog.files.wordpress.com/2019/05/huge-orc-army.png?w=1024&quot; src=&quot;https://acoupdotblog.files.wordpress.com/2019/05/huge-orc-army.png&quot; alt=&quot;&quot; class=&quot;wp-image-94&quot;/&gt;We’ll come back to almost everything here later – but for now: I’m sure those trolls are thrilled to have to push the weight of all of these armored orcs what appears to be a mile or more to the wall. Rather than them, you know, getting in the tower a bit closer to the target. &lt;img data-attachment-id=&quot;100&quot; data-permalink=&quot;https://acoup.blog/2019/05/10/collections-the-siege-of-gondor/siege-of-gondor/&quot; data-orig-file=&quot;https://acoupdotblog.files.wordpress.com/2019/05/siege-of-gondor.png&quot; data-orig-size=&quot;1664,649&quot; data-comments-opened=&quot;1&quot; data-image-meta=&quot;{&amp;quot;aperture&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;credit&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;camera&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;caption&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;created_timestamp&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;copyright&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;focal_length&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;iso&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;shutter_speed&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;title&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;orientation&amp;quot;:&amp;quot;0&amp;quot;}&quot; data-image-title=&quot;siege of gondor&quot; data-image-description=&quot;&quot; data-medium-file=&quot;https://acoupdotblog.files.wordpress.com/2019/05/siege-of-gondor.png?w=300&quot; data-large-file=&quot;https://acoupdotblog.files.wordpress.com/2019/05/siege-of-gondor.png?w=1024&quot; src=&quot;https://acoupdotblog.files.wordpress.com/2019/05/siege-of-gondor.png?w=1024&quot; alt=&quot;&quot; class=&quot;wp-image-100&quot; srcset=&quot;https://acoupdotblog.files.wordpress.com/2019/05/siege-of-gondor.png?w=1024 1024w, https://acoupdotblog.files.wordpress.com/2019/05/siege-of-gondor.png?w=150 150w, https://acoupdotblog.files.wordpress.com/2019/05/siege-of-gondor.png?w=300 300w, https://acoupdotblog.files.wordpress.com/2019/05/siege-of-gondor.png?w=768 768w, https://acoupdotblog.files.wordpress.com/2019/05/siege-of-gondor.png 1664w&quot; sizes=&quot;(max-width: 1024px) 100vw, 1024px&quot;/&gt;Another look at the orc army. Note that it is so huge that the entire army cannot get to the city, because the rest of the army is in the way (there is insufficient frontage for the entire army to deploy), forcing the army to stack up.
&lt;p&gt;The books are vague on the total size of the orcish host (but we’ll come back to this), but interview material for the movies suggests that Peter Jackson’s CGI team assumed around 200,000 orcs.  This army has to exit Minas Morgul – apparently as a single group – and then follow the road to the crossing at Osgiliath.  Is this operational plan reasonable, from a transit perspective?&lt;/p&gt;
&lt;p&gt;In a word: &lt;strong&gt;no&lt;/strong&gt;.  It’s not hard to run the math as to why.  Looking at the image at the head of the previous section, we can see that the road the orcs are on allows them to march five abreast, meaning there are 40,000 such rows (plus additional space for trolls, etc). Giving each orc four feet of space on the march (a fairly conservative figure), that would mean the army &lt;em&gt;alone&lt;/em&gt; stretches 30 miles down a single road.  At that length, the tail end of the army would not even be able to leave camp before the front of the army had finished marching for the day.  For comparison, an army doing a ‘forced march’ (marching at rapid speed under limited load – and often taking heat or fatigue casualties to do it) might manage 20 to 30 miles per day.  Infantry on foot is more likely to average around 10 miles per day on decent roads.&lt;/p&gt;
&lt;p&gt;Ideally, the solution to this problem is to split the army up.  By moving in multiple columns and converging on the battlespace, you split one impossibly long column of troops into several more manageable ones.  There is a danger here – the enemy might try to overwhelm each smaller army in turn – but Faramir has had to pull his troops back out of Ithilien, so there is little risk of defeat in detail for the Army of Mordor.  The larger problem is terrain – we’ve seen Ithilien in this film and the previous one: it is heavily forested, with few roads.  What roads exist are overgrown and difficult to use.  Worse yet, the primary route through the area is not an east-west road, but the North-South route up from Near Harad to the Black Gate.  The infrastructure here to split the army effectively simply doesn’t exist.&lt;/p&gt;
&lt;img data-attachment-id=&quot;97&quot; data-permalink=&quot;https://acoup.blog/ulm_campaign_-_french_strategic_envelopment_26_september-9_october_1805/&quot; data-orig-file=&quot;https://acoupdotblog.files.wordpress.com/2019/05/ulm_campaign_-_french_strategic_envelopment_26_september-9_october_1805.jpg&quot; data-orig-size=&quot;1260,970&quot; data-comments-opened=&quot;1&quot; data-image-meta=&quot;{&amp;quot;aperture&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;credit&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;camera&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;caption&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;created_timestamp&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;copyright&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;focal_length&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;iso&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;shutter_speed&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;title&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;orientation&amp;quot;:&amp;quot;0&amp;quot;}&quot; data-image-title=&quot;ulm_campaign_-_french_strategic_envelopment_26_september-9_october_1805&quot; data-image-description=&quot;&quot; data-medium-file=&quot;https://acoupdotblog.files.wordpress.com/2019/05/ulm_campaign_-_french_strategic_envelopment_26_september-9_october_1805.jpg?w=300&quot; data-large-file=&quot;https://acoupdotblog.files.wordpress.com/2019/05/ulm_campaign_-_french_strategic_envelopment_26_september-9_october_1805.jpg?w=1024&quot; src=&quot;https://acoupdotblog.files.wordpress.com/2019/05/ulm_campaign_-_french_strategic_envelopment_26_september-9_october_1805.jpg&quot; alt=&quot;&quot; class=&quot;wp-image-97&quot; width=&quot;721&quot; height=&quot;554&quot; srcset=&quot;https://acoupdotblog.files.wordpress.com/2019/05/ulm_campaign_-_french_strategic_envelopment_26_september-9_october_1805.jpg?w=721&amp;amp;h=554 721w, https://acoupdotblog.files.wordpress.com/2019/05/ulm_campaign_-_french_strategic_envelopment_26_september-9_october_1805.jpg?w=150&amp;amp;h=115 150w, https://acoupdotblog.files.wordpress.com/2019/05/ulm_campaign_-_french_strategic_envelopment_26_september-9_october_1805.jpg?w=300&amp;amp;h=231 300w, https://acoupdotblog.files.wordpress.com/2019/05/ulm_campaign_-_french_strategic_envelopment_26_september-9_october_1805.jpg?w=768&amp;amp;h=591 768w, https://acoupdotblog.files.wordpress.com/2019/05/ulm_campaign_-_french_strategic_envelopment_26_september-9_october_1805.jpg?w=1024&amp;amp;h=788 1024w, https://acoupdotblog.files.wordpress.com/2019/05/ulm_campaign_-_french_strategic_envelopment_26_september-9_october_1805.jpg 1260w&quot; sizes=&quot;(max-width: 721px) 100vw, 721px&quot;/&gt;A map from regular Earth, rather than Middle Earth. This is Napoleon’s Ulm Campaign (1805) – note how Napoleon’s armies (the blue lines) are so large they have to move in multiple columns, which converge on the Austrian army (the red box labeled “FERDINAND”). This coordinated movement is the heart of operations: how do you get your entire army all to the battlefield intact and at the same time?
&lt;p&gt;This actually understates the problem, because the army of Morder also needs supplies in order to conduct the siege.  Orcs seem to be able to make do with very poor water supplies (Frodo and Sam comment on the foulness of Mordor water), so we can assume they use local water along the march, but that still leaves food.  Ithilien (the territory they are marching through), as we have seen in the film, is unpopulated – the army can expect no fresh supplies here (or in the Pelennor beyond, for reasons we’ll discuss shortly).  That is going to mean a baggage train to carry additional supplies, as well as materials for the construction of all of the fancy siege equipment (we, in fact, later see them bringing the towers pre-built – we’ll get to it).  This would lengthen the army train &lt;em&gt;even more&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;All of that raises a second point – from a &lt;em&gt;supply&lt;/em&gt; perspective, can this operation work?  Here, the answer is, perhaps surprisingly, &lt;strong&gt;&lt;em&gt;yes&lt;/em&gt;&lt;/strong&gt;&lt;em&gt;.&lt;/em&gt;  Minas Morgul is 20 leagues (around 60 miles) from Minas Tirith.  An infantryman might carry around (very roughly) 10 days or so of rations on his person, which is enough to move around 120 miles (these figures derive from K. Chase, &lt;em&gt;Firearms: A Global History to 1700&lt;/em&gt; (2003) – well worth a read! – but are broadly applicable to almost any army before the invention of the railroad).  The army is bound to be held up a bit along the way, so the Witch King would want to bring some wagons with additional supplies, but as a matter of &lt;em&gt;supply&lt;/em&gt;, this works.  The problem is transit.&lt;/p&gt;
&lt;p&gt;As a side note, the supply issue neatly explains the aggressive tactics the Witch king employs when he arrives at Minas Tirith, moving immediately for an assault rather than a siege.  Because the pack animals which pull wagons full of food eat food themselves, there is literally no amount of wagons which would enable an army of this size to sustain itself indefinitely in a long siege.  The Witch King is thus constrained by his operational plan: the raw size of his army means he &lt;em&gt;must&lt;/em&gt; either take the city in an assault quickly enough to march most of his army back, or fail.  He proceeds with the appropriate sense of urgency.&lt;/p&gt;
&lt;p&gt;That said, the distances here are short: 60 miles is a believable distance for an army to make an unsupported ‘lunge’ out of its logistics network.  One cannot help but notice the Stark (hah!) contrast with the multi-hundred-mile supply-free lunges in the TV version of &lt;em&gt;Game of Thrones&lt;/em&gt;, which are far less plausible.&lt;/p&gt;
&lt;h2&gt;&lt;em&gt;We’ve Had One Logistics, Yes.  But What About Second Logistics?&lt;/em&gt;&lt;/h2&gt;
&lt;blockquote class=&quot;wp-block-quote&quot;&gt;
&lt;p&gt;&lt;strong&gt;BOOK NOTE&lt;/strong&gt;: In the film, Jackson has split the host of Mordor into three groups (the fleet, the Haradrim and the Orcs) each of which moves and arrives as a single unit.  As discussed above, this is insufficient to resolve the overwhelming logistics problems of such large armies.  However, the books largely resolve this issue.  While the size of the orc army in the book is never spelled out, it is clearly quite a bit smaller than 200,000 (the ever-trusty wiki suggests around half the size – putting it just a bit over the upper-bound of an army that might move as a single group in this kind of terrain).&lt;/p&gt;
&lt;p&gt;But Tolkien notably does &lt;em&gt;not&lt;/em&gt; have the orc army move as a single massive group.  Instead it sets out from multiple logistics bases, with the main force leaving Minas Morgul and attacking as Osgiliath, but a secondary force leaving Mordor via the Black Gate and crossing the Anduin at Cair Andros (see the map) into Anorien (&lt;em&gt;RotK&lt;/em&gt;, 104).  Denathor had been aware of this possibility, but had concluded (correctly, it seems) that if he could not hold Osgiliath it would matter little if he held in the North and so prioritized one over the other – in the event he lost both, but it isn’t clear how that could have been avoided (&lt;em&gt;RotK&lt;/em&gt;, 98).&lt;/p&gt;
&lt;p&gt;Breaking up the orc army into two columns of 50,000 orcs with supplies resolves most of the problems of the previous section.  Moreover, by having those armies leave from multiple logistics bases, we may imagine an entire road network being used, instead of what we see in the film, where the orc army is bottlenecked by individual bridges and causeways.  The late arrival of the ‘Southrons’ makes perfect sense as well – their forces came north through Ithilien, but could not possibly cross at Osgiliath until the entire orc army was across.  Given that the Southrons – who have infantry, cavalry and war elephants in the books, rather than the nearly all-elephant army seen in the film – seem more mobile than the orc army (which is entirely on foot), one wonders if this column was intended as an exploitation force.  Once the orcs had taken Minas Tirith – or at least neutralized it via siege – the highly mobile Southron cavalry could scout and raid deeper into Gondor, exploiting the breach in the defenses at Osgiliath.  In that case, it makes perfect sense to put these soldiers further back in the marching order.&lt;/p&gt;
&lt;p&gt;In terms of supplies, the books keep very careful track of the timeline of the assault.  The main body of the army departs Minas Morgul on March 9&lt;sup&gt;th&lt;/sup&gt; (Frodo actually witnesses this event, placing it securely).  The army from the Black Gate heading to Caer Andros left earlier – it takes the crossing on the 9&lt;sup&gt;th&lt;/sup&gt;.  The assault on Osgiliath, perhaps 20 miles away (maybe less) comes on the night of the 11&lt;sup&gt;th&lt;/sup&gt; (suggesting a very plausible 10ish miles per day marching speed).   By the morning of March 12&lt;sup&gt;th&lt;/sup&gt;, Faramir has been forced from Osgiliath and is defending the &lt;em&gt;Rammas Echor&lt;/em&gt;, which is lost later that day.  The orcish army takes the Pelennor on the 13&lt;sup&gt;th&lt;/sup&gt;, and reaches Minas Tirith on the 14&lt;sup&gt;th&lt;/sup&gt;, taking thus two days to cross the Pelennor after taking the causeway forts (around 15 miles per day, quick but not unreasonable).  The assault begins in earnest on the night of the 14&lt;sup&gt;th&lt;/sup&gt;, with the Rohirrim arriving on the morning of the 15&lt;sup&gt;th&lt;/sup&gt;.&lt;/p&gt;
&lt;p&gt;We can suppose that the Witch King did not assume his army would be destroyed in the field for supply purposes – meaning he would have to be able to feed them after the battle (you might argue that an evil wraith cares little for his army and this may be true, but angering 120,000 starving &lt;strong&gt;and armed&lt;/strong&gt; orcs would be foolish). Given how aggressive the assault is, he probably also might have expected to take the city no later than the 16&lt;sup&gt;th&lt;/sup&gt; or perhaps 17&lt;sup&gt;th&lt;/sup&gt; (indeed, he very nearly takes it in the morning hours of the 15&lt;sup&gt;th&lt;/sup&gt;).  He can perhaps count on getting some supplies from the rich farmland of the Pelennor or from the storehouses of the city, once taken, but in practice then, he needs around 20 days of operational endurance (10 days out, 10 days back).  That is, in fact, well within the possible, but it will take a significant supply train.&lt;/p&gt;
&lt;p&gt;Indeed, the Witch King’s aggressive assault on the city makes good sense from two different perspectives: from the supply perspective, he cannot afford to settle down to a long siege with so large an army. From a larger operation perspective, he must know about the beacon system and that aid is likely en route to Gondor – better to move quickly with a massive force and overwhelm the defenders before Minas Tirith – a formidable defense position – could be reinforced.&lt;/p&gt;
&lt;p&gt;An infantryman can carry about 10 days’ worth of food.  Adding one large wagon per each company of 30 infantrymen doubles this distance, but diminishing returns hit fast (because the wagon-driver and animals eat the food in the wagon for each day travelled).  For the Minas Morgul army – around 60,000 strong – that would mean some 2,000 wagons (and the same number again for the army out of the Black Gate).  It’s a large number, but not an impossible one.&lt;/p&gt;
&lt;p&gt;However, there is a better option available than loading up on wagons: naval supply.  While the film only shows dedicated crossing craft in the assault on Osgiliath, the books note “floats and barges in great number” already in Osgiliath.  Naval supply, by riverboat or by ship, is &lt;em&gt;far&lt;/em&gt; more efficient than overland supply (moving supplies by water is roughly &lt;em&gt;twenty times&lt;/em&gt; more efficient than moving the same supplies by land in the pre-modern era).  Add in additional supplies stockpiled at Osgiliath and carried by the Umbar fleet.  By relying on those supplies, the Witch King’s own forces could travel light, with minimal wagons (for siege equipment) and thus move much faster.  Such audacious ‘lunges’ between supply networks were hallmarks of the success enjoyed by Caesar and Alexander, but they could also go brutally wrong – Marc Antony’s failure at Actium (and subsequent defeat in the Final War of the Roman Republic) is a textbook case of a risky lunge failing and it resulted in the complete loss of his army and nearly his entire fleet as well.&lt;/p&gt;
&lt;p&gt;I find such an audacious attack plan perfectly in keeping with both Sauron’s and the Witch King’s character and motivation.  The former has endless reserves to fall back on and so can afford to lose an army in a risky gambit.  Moreover, he is rushing his offensive in an attempt to forestall Aragorn, who he suspects has taken the One Ring (or so Gandalf, correctly it seems, supposes).  Meanwhile, the Witch King is, throughout the battle, confident to the point of arrogance (perhaps because he believes himself invulnerable).  Much like Alexander, he opts to lead storming attacks himself and flies down to fight an enemy king (Théoden) directly. For such an aggressive commander, an audacious plan to make an unsupported lunge and have the fleet catch up with naval supply later seems perfectly in character. &lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;In conclusion: While the broad outlines of Mordor’s plan make clear operational and strategic sense, Jackson has inflated the orc army to be a bit too large.  Shrinking that army back down and splitting it up – as the books do – resolve this issue into a largely plausible operational plan.  A lot of this may be credited to Tolkien, but I think Jackson’s skill with the material must also be noted.  Film is a very &lt;em&gt;compressed&lt;/em&gt; medium and Jackson simply does not have the time to show us Caer Andros (though he mentions it) or the orc army taking multiple routes to Osgiliath.&lt;/p&gt;
&lt;p&gt;Jackson does, however, do an admirable job in keeping track of where the armies are and where they are going even in that very compressed filmic medium – something the genre generally has struggled with (indeed, Jackson himself struggles with it in &lt;em&gt;The Battle of Five Armies&lt;/em&gt;, repeatedly losing track of where things are in the titular battle).&lt;/p&gt;
&lt;p&gt;So far, this is a good beginning: the bad guys have a solid plan.  Next week, we’ll see that plan contact the enemy, and take a look at the plan Jackson gives to the Good Guys (hint: it’s not as good), and actually get around to &lt;strong&gt;delivering that siege&lt;/strong&gt;.&lt;/p&gt;
&lt;img data-attachment-id=&quot;98&quot; data-permalink=&quot;https://acoup.blog/gondor-hiding-behind-walls/&quot; data-orig-file=&quot;https://acoupdotblog.files.wordpress.com/2019/05/gondor-hiding-behind-walls.png&quot; data-orig-size=&quot;1276,701&quot; data-comments-opened=&quot;1&quot; data-image-meta=&quot;{&amp;quot;aperture&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;credit&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;camera&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;caption&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;created_timestamp&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;copyright&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;focal_length&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;iso&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;shutter_speed&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;title&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;orientation&amp;quot;:&amp;quot;0&amp;quot;}&quot; data-image-title=&quot;gondor-hiding-behind-walls&quot; data-image-description=&quot;&quot; data-medium-file=&quot;https://acoupdotblog.files.wordpress.com/2019/05/gondor-hiding-behind-walls.png?w=300&quot; data-large-file=&quot;https://acoupdotblog.files.wordpress.com/2019/05/gondor-hiding-behind-walls.png?w=1024&quot; src=&quot;https://acoupdotblog.files.wordpress.com/2019/05/gondor-hiding-behind-walls.png&quot; alt=&quot;&quot; class=&quot;wp-image-98&quot;/&gt;Hey, uh, boss? Why are we hiding behind walls instead of in battle formation?
&lt;div id=&quot;jp-post-flair&quot; class=&quot;sharedaddy sd-like-enabled sd-sharing-enabled&quot;&gt;
&lt;div class=&quot;sharedaddy sd-sharing-enabled&quot;&gt;
&lt;div class=&quot;robots-nocontent sd-block sd-social sd-social-icon-text sd-sharing&quot;&gt;
&lt;h3 class=&quot;sd-title&quot;&gt;Share this:&lt;/h3&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sharedaddy sd-block sd-like jetpack-likes-widget-wrapper jetpack-likes-widget-unloaded&quot; id=&quot;like-post-wrapper-161773962-90-5de1be9e4c512&quot; data-src=&quot;//widgets.wp.com/likes/index.html?ver=20190321#blog_id=161773962&amp;amp;post_id=90&amp;amp;origin=acoupdotblog.wordpress.com&amp;amp;obj_id=161773962-90-5de1be9e4c512&amp;amp;domain=acoup.blog&quot; data-name=&quot;like-post-frame-161773962-90-5de1be9e4c512&quot;&gt;
&lt;h3 class=&quot;sd-title&quot;&gt;Like this:&lt;/h3&gt;
&lt;div class=&quot;likes-widget-placeholder post-likes-widget-placeholder&quot;&gt;&lt;span class=&quot;button&quot;&gt;&lt;span&gt;Like&lt;/span&gt;&lt;/span&gt; &lt;span class=&quot;loading&quot;&gt;Loading...&lt;/span&gt;&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
</description>
<pubDate>Fri, 29 Nov 2019 12:09:08 +0000</pubDate>
<dc:creator>_Microft</dc:creator>
<og:type>article</og:type>
<og:title>Collections: The Siege of Gondor, Part I: Professionals Talk Logistics</og:title>
<og:url>https://acoup.blog/2019/05/10/collections-the-siege-of-gondor/</og:url>
<og:description>This is the first part of a six-part (II, III, IV, V, VI) series I expect to roll out taking a historian’s look at the Siege of Gondor in Peter Jackson’s Return of the King.  We’re going to discuss…</og:description>
<og:image>https://acoupdotblog.files.wordpress.com/2019/05/siege-of-gondor.png?w=1200</og:image>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://acoup.blog/2019/05/10/collections-the-siege-of-gondor/</dc:identifier>
</item>
<item>
<title>What is energy, actually? (2011)</title>
<link>https://jancovici.com/en/energy-transition/energy-and-us/what-is-energy-actually/</link>
<guid isPermaLink="true" >https://jancovici.com/en/energy-transition/energy-and-us/what-is-energy-actually/</guid>
<description>&lt;p&gt;That’s an easy go: energy is the amount of (on) my electricity bill, or maybe of (on) my natural gas bill. If I am very concentrated, I might add that it is also the money I spend at the gasoline pump, and if I am even more concentrated I will suggest that it might have something to do with the filling up of my domestic fuel oil tank. Next question?&lt;/p&gt;&lt;p&gt;The economist might add that energy represents 7% of the spendings of households in France (in other OECD countries the percentage is probably close), and therefore that if the price of electricity increases it is annoying because it hurts a little the purchasing power, but nobody should die from it.&lt;/p&gt;
&lt;p&gt;But, with such an approach, that is bringing everything back to money, we will miss the biggest part, because in industrialized countries energy plays a physical role far more important than its share in our spendings. Physical, is that connected in any way with physics? Indeed, before being an amount on a bill, energy has a definition in physics: it is the notion that characterizes a change of state in a system. Woaw! This seems awfully complicated! Actually, it’s very simple: it just says that as soon as the world that surrounds us (= “a system”) changes, energy plays a role, and the amount of energy invoplved measures the magnitude of the changeof the system between before and after.&lt;/p&gt;
&lt;p&gt;If we look around us, we will witness that, indeed, as soon as “something happens”, there is energy playing a role:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;A change of temperature uses or yields energy. It’s this energy that we use to heat or cool a room, food, water for a shower (actually we seldom cool that one!), etc. All industrial machines that cook, sterilize, heat, cool or freeze therefore need – or use – energy,&lt;/li&gt;
&lt;/ul&gt;&lt;ul&gt;&lt;li&gt;A change of state of matter (going from solid to liquid, or liquid to gaseous), what physicists call a change of phase, uses or yields energy, called latent heat. Our body uses that energy to cool down when it’s too hot: its perspiration, which basically consists in evaporating water coming from our serum (which is why it makes the skin salted). Cooling machines (fridges, freezers), and machines that use the reverse process (heat pumps) use the latent heat of evaporation or condensation to transfer heat. All industrial processes that melt (about any process of production of raw materials melts something at some time) or evaporate use that kind of energy.&lt;/li&gt;
&lt;/ul&gt;&lt;ul&gt;&lt;li&gt;A change of speed of an object uses or yields energy. Putting cars, trucks, trains, planes and boats in motion uses about 20% or the overall energy consumption of the world,&lt;/li&gt;
&lt;/ul&gt;&lt;ul&gt;&lt;li&gt;A change of chemical composition uses or yields energy. A combustion, for example, is a chemical transformation that yields energy, through associating oxygen to the atoms of the initial coumpound, and symetrically reduction (the fact of removing oxygen from a molecule that has some, for example a metal oxide) requires energy. 10 to 15% of the world energy consumption is used to modify a chemical composition. 7% to 8% is used in chemical industries, that transform various natural resources (air, water, minerals, oil products, etc) into other molécules (hundreds of thousands!). 5% is used to reduce metal oxides, first of all iron oxides, to produce metals.&lt;/li&gt;
&lt;/ul&gt;&lt;ul&gt;&lt;li&gt;Creating or absorbing electromagnetic radiation is also a process involving energy. For example, the energy released by fusing nucleus in the Sun is transformed into radiation, that carries energy to the Earth, where it is absorbed and heats the surface and the atmosphere (and puts in motion the climate system and plant growth). Almost 100% of renewable energy we can access (except geothermal energy) is therefore coming from radiation transformation (and even oil, coal and gas are &lt;a href=&quot;http://jancovici.com/en/energy-transition/oil/how-do-oil-gas-and-coal-get-created/&quot;&gt;remote remains of past radiation&lt;/a&gt;!). It is also energy enclosed in radiation that carries the information allowing the radio, the TV, cellular phones and wifi device to operate, even if the amounts of energy associated are not considerable. The laser that cuts tissues in a cloth plant uses that energy also!&lt;/li&gt;
&lt;/ul&gt;&lt;ul&gt;&lt;li&gt;Changing a shape involves energy. A stamp mill and a potato peeler both change a shape (crushing ore in the first case and separatig a potato from its peel in the second), and energy is required in both cases (our arm is enough in the second case!). All industrial machines (or sometimes domestic ones) that crush, expand, add or remove matter, flatten, elongate, saw, cut, and modifiy the shape in whatever other way therefore require energy,&lt;/li&gt;
&lt;/ul&gt;&lt;ul&gt;&lt;li&gt;Moving a mass in a gravitational field involves energy. When the gravitational field is that of the Earth, we are talking about weight. It is against that energy that we are struggling during a mountain hike, and it is that energy that pulls us down when we ride a bike down the slope. Each time we use the weight of an object, it is actually gravitational energy that we use. And there are a number of devices that use weights, from lifts to cranes.&lt;/li&gt;
&lt;/ul&gt;&lt;ul&gt;&lt;li&gt;Any interaction between an electric current and a magnetic field involves energy. When a current in brought inside a magnetic field to get some motion, we are talking of an electric engine, which is now found everywhere around us, from water supply to sewers, from computer hard drives to freezers, from trains to vacuum cleaners, from industrial lines to gasoline pumps, from compressors to automatic doors, and from cable-cars to air-con… When it is motion that is brought to get some electricity out, it is an alternator, that can be found in any car and any power plant!&lt;/li&gt;
&lt;/ul&gt;&lt;ul&gt;&lt;li&gt;Changing an atom’s nucleus involves energy: it is nuclear energy. It is associated to radioactivity, fusion and fission. As nuclear energy is extremely intense (there is a much energy released by the fission of one gram of uranimum than by the burning of a ton of oil), men have limited its domestication to about three cases: electricity generation, bombs (alas), and radiotherapy (cobalt 60, a radioactive source, is used to irradiate tumor cells).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Again, nothing can happen in the physical world without energy interveining. The larger the change, and the more, by definition, energy is involved. As a logical consequence, if we carefully look at the way occidentals increased their material consumption, we will find energy everywhere:&lt;/p&gt;
&lt;p&gt;humanity has used more and more energy to extract (mechanical energy), transform (chemical energy), work on (mechanical energy), and displace (kinetic energy) mineral or biological resources that compose the innumerable amount of objects we now have at our disposal, including large objects such as buildings, cars and trains, plants, infrastructure, etc&lt;/p&gt;
&lt;p&gt;we have used more and more energy to put in motion machines that transport goods or… ourselves (automobiles, trucks, trains, planes, boats),&lt;/p&gt;
&lt;p&gt;we have used more and more energy to heat or cool spaces that we have separated from the “outside world”, that is buildings of all kind&lt;/p&gt;
&lt;p&gt;It is therefore logical that the average consumption per capita has strongly risen during the course of industrialization&lt;/p&gt;
&lt;div class=&quot;pure-g figure_layout&quot; readability=&quot;17.333333333333&quot;&gt;
&lt;div class=&quot;pure-u-1-1 gutter-1-2&quot; readability=&quot;29.851851851852&quot;&gt;&lt;img src=&quot;https://jancovici.com/wp-content/uploads/2016/04/energie_graph1.jpg&quot; alt=&quot;&quot;/&gt;&lt;p&gt;&lt;em&gt;Evolution of the average energy consumption per capita in the world, since 1880, wood included (estimated).&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;The vertical axis is graduated in kWh (1 kWh = 0,003 MBTU).&lt;br/&gt;An inhabitant of the planet therefore uses, on average, a little more than 20.000 kWh per year.&lt;/p&gt;
&lt;p&gt;The above diagram clearly outlines three distinctive periods since the beginning of the industrial revolution: for more than a century (1860 to 1979) the amount ef energy per capita has been rising strongly, and after the second oil shock in 1979 it remained almost constant until the beginning of the 2000 decade. There has been again a rise during the 2000’s, corresponding to a strong growth in the emerging countries fueled by coal, mostly China, &lt;a href=&quot;http://jancovici.com/en/energy-transition/long-series/china/&quot;&gt;where it is the first energy used&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;span&gt;Author’s compilation of the following primary sources: Shilling et al., BP statistical review, Energy Information Agency, United Nations.&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Because of what is exposed above, it is easy to understand that our productive system – and therefore the economy – depends strongly on energy. Our economy is “only” a large system to transform resources, taking into the environment all kind of things to turn them into products and services. As any transformation goes along with the use of energy, it seems logical that the output of the economy is strongly coupled to the amount of energy injected in the system. This energy can either come from our muscles, or from machines.&lt;/p&gt;
&lt;p&gt;But a quick calculation shows that, using its arms and legs, a human organism can yield at most &lt;a href=&quot;http://jancovici.com/en/energy-transition/energy-and-us/how-much-of-a-slave-master-am-i/&quot;&gt;150 kWh of mechanical output&lt;/a&gt; per year. What the above graph says, therefore, is that oil, gas and coal have enabled men to multiply by several hundreds their physical action on the environment. In Europe, where the energy consumption is rather around 60.000 kWh per person and per year (including the energy used to manufacture imported goods), the multiple is more something like 500.&lt;/p&gt;
&lt;div class=&quot;pure-g figure_layout&quot; readability=&quot;21.263422818792&quot;&gt;
&lt;div class=&quot;pure-u-1-1 gutter-1-2&quot; readability=&quot;37.904362416107&quot;&gt;&lt;img src=&quot;https://jancovici.com/wp-content/uploads/2016/10/decroissance_graph13_en-1024x515.png&quot; alt=&quot;&quot;/&gt;&lt;p&gt;&lt;em&gt;Simplified representation of the physical flows that sustain our productive system, which is nothing else than a tremendous organization to transform natural resources (that are free in conventional economics, and therefore can never lack), with work (thus energy).&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Work – a from of energy – comes, from a marginal fraction, from our muscles (that use the energy of food), and for the most from machines, that “eat”‘ energy (&lt;a href=&quot;http://jancovici.com/en/category/energy-transition/oil/&quot;&gt;oil products&lt;/a&gt;, &lt;a href=&quot;http://jancovici.com/en/category/energy-transition/electricity/&quot;&gt;electricity&lt;/a&gt; and therefore &lt;a href=&quot;http://jancovici.com/en/category/energy-transition/coal/&quot;&gt;coal&lt;/a&gt; and &lt;a href=&quot;http://jancovici.com/en/category/energy-transition/gas/&quot;&gt;gas&lt;/a&gt;, etc). On average, the energy coming from machines is worth &lt;a href=&quot;http://jancovici.com/en/energy-transition/energy-and-us/how-much-of-a-slave-master-am-i/&quot;&gt;200 times that coming from our muscles&lt;/a&gt;, and it amounts to 500 times for an European (and almost 1000 times for an American).&lt;/p&gt;
&lt;p&gt;“Productivity of work” is therefore a direct function of the number and size of machines we have per capita….&lt;/p&gt;
&lt;p&gt;Capital formation is an internal loop of the system: it is formed with past resources and work (I did not invent anything, it is exactely how it was dealt with in the &lt;a href=&quot;http://jancovici.com/en/readings/societies/the-limits-to-growth-donella-meadows-dennis-meadows-jorgen-randers-et-william-w-behrens-iii-1972/&quot;&gt;work of Meadows et al.&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;One easily understands, then, that if we have plenty of workers and plenty of capital, but no energy (examples: a caterpillar with no oil, a plant with no electricity), we won’t get any significant production!&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;In other words, what creates the industrial output in the world is first of all the energy we use, far ahead the work of people. As the tertiary sector depends on the industrial output, and does not exist independently, it means that energy is the true engine of the industrial civilisation, office work included. Our arms and legs are only there to manipulate switches and valves, that unleash the power of energy!&lt;/p&gt;
&lt;div class=&quot;pure-g figure_layout&quot; readability=&quot;15&quot;&gt;
&lt;div class=&quot;pure-u-1-1 gutter-1-2&quot; readability=&quot;25&quot;&gt;&lt;img src=&quot;https://jancovici.com/wp-content/uploads/2016/04/energie_graph2.jpg&quot; alt=&quot;&quot;/&gt;&lt;p&gt;&lt;em&gt;Respective year on year changes, since 1965, of the world GDP (blue curve), and the world energy consumption, excluding wood (green curve).&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;It is easy to see that the two evolve almost the same way. Besides in 1980, 1989, 1997, and 2005, the drop in energy supply preceded the drop of the GDP, that came shortly after.&lt;/p&gt;
&lt;p&gt;&lt;span&gt;Author’s calculation on primary information coming from BP Statistical Review, 2015, and World Bank 2015 (GDP).&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;pure-g figure_layout&quot; readability=&quot;10.5&quot;&gt;
&lt;div class=&quot;pure-u-1-1 gutter-1-2&quot; readability=&quot;16&quot;&gt;&lt;img src=&quot;https://jancovici.com/wp-content/uploads/2016/04/energie_graph9.jpg&quot; alt=&quot;&quot;/&gt;&lt;p&gt;&lt;em&gt;World GDP in constant dollars (vertical axis) plotted against the world energy consumption in million tonnes oil equivalent (horizontal axis), from 1965 to 2014.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;The correlation between the two variables is clear.&lt;/p&gt;
&lt;p&gt;&lt;span&gt;Author’s calculation on primary information coming from BP Statistical Review, 2015, and World Bank 2015 (GDP).&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;One should note that if we try to correlate the world GDP to oil price, than we get no clear pattern.&lt;/p&gt;
&lt;div class=&quot;pure-g figure_layout&quot; readability=&quot;14.5&quot;&gt;
&lt;div class=&quot;pure-u-1-1 gutter-1-2&quot; readability=&quot;24&quot;&gt;&lt;img src=&quot;https://jancovici.com/wp-content/uploads/2016/04/energie_graph12.jpg&quot; alt=&quot;&quot;/&gt;&lt;p&gt;&lt;em&gt;World GDP in constant dollars (vertical axis) plotted against the price per barrel of oil in constant dollars (horizontal axis), from 1960 to 2014.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;There is no obvious correlation: the GDP can increase with a decreasing oil price, but also with a rising oil price, and from 2008 to 2009 we also had a decreasing GDP with a decreasing price.&lt;/p&gt;
&lt;p&gt;Let’s recall that the world trade in general, and that of oil in particular, is a balanced system: when the importer pays more, the exporter earns more, and the net effect on the world GDP is nil.&lt;/p&gt;
&lt;p&gt;&lt;span&gt;Author’s calculation on primary information coming from BP statistical review &amp;amp; Energy Information Agency (energy) and World Bank (GDP).&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;What counts for the world economy is actually &lt;a href=&quot;http://jancovici.com/en/energy-transition/oil/is-the-price-of-oil-driving-the-economy/&quot;&gt;not the price of oil&lt;/a&gt;, but the volume of oil produced. Anyone will then say that if there is less oil the price will increase, and vice versa, but it happens that there is no such long term relation if we look at past statistics…&lt;/p&gt;
&lt;div class=&quot;pure-g figure_layout&quot; readability=&quot;11.5&quot;&gt;
&lt;div class=&quot;pure-u-1-1 gutter-1-2&quot; readability=&quot;18&quot;&gt;&lt;img src=&quot;https://jancovici.com/wp-content/uploads/2016/06/petrole_elastique_graph1.jpg&quot; alt=&quot;&quot;/&gt;&lt;p&gt;&lt;em&gt;World oil consumption (horizontal axis) plotted against the price per barrel of oil in constant dollars, from 1921 to 2014.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;There is no such thing as an elasticity between price and volume. Actually, there rather seems to be only two stable regimes: a constant or almost constant price with a highly variable consumption (1921 to 1973 and 1986 to 2001), or an almost constant consumption with a highly variable price (1973 to 1986 and 2002 to 2014).&lt;/p&gt;
&lt;p&gt;&lt;span&gt;Author’s calculation on primary information coming from BP statistical review &amp;amp; Shillig et al.&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;On the opposite, there is a very strong link between oil in volume and the world GDP. A simple explanation can be put forward: oil is king in transportation, and transportation is indispensable to any economic activity.&lt;/p&gt;
&lt;div class=&quot;pure-g figure_layout&quot; readability=&quot;14.5&quot;&gt;
&lt;div class=&quot;pure-u-1-1 gutter-1-2&quot; readability=&quot;24&quot;&gt;&lt;img src=&quot;https://jancovici.com/wp-content/uploads/2016/04/petrole_graph5.jpg&quot; alt=&quot;&quot;/&gt;&lt;p&gt;&lt;em&gt;The red curve gives a 3 year running mean for the variation of the volume of oil produced worldwide.&lt;/em&gt;&lt;br/&gt;&lt;em&gt;The blue one gives the 3 year running mean for the variation of the world average of the GDP per capita.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;It is easy to see that the two curves behave about the same way after 1986, &lt;strong&gt;with the change on the GDP per capita following the change on oil production and not the opposite&lt;/strong&gt;. It is also easy to seen that before 1986 the magnitude of the variation was greater for oil production than for GDP per capita, when after they became of the same magnitude.&lt;/p&gt;
&lt;p&gt;This suggest that the dependancy of our economic system on oil has increased and not decreased, which is consistent with the development of globalization, that heavily relies on international transportation.&lt;/p&gt;
&lt;p&gt;&lt;span&gt;Sources: BP Statistical Review (volume of oil) and World Bank (average GDP)&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;pure-g figure_layout&quot; readability=&quot;13&quot;&gt;
&lt;div class=&quot;pure-u-1-1 gutter-1-2&quot; readability=&quot;21&quot;&gt;&lt;img src=&quot;https://jancovici.com/wp-content/uploads/2016/04/energie_graph10.jpg&quot; alt=&quot;&quot;/&gt;&lt;p&gt;&lt;em&gt;GDP per capita – world average – in constant 2012 dollars (vertical axis) plotted against the world oil consumption in million tonnes oil equivalent (horizontal axis), from 1965 to 2014.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Green: data from 1965 to 1982,&lt;br/&gt;Red: data from 1983 to 2014.&lt;/p&gt;
&lt;p&gt;The correlation is better for recent years, which shows that the world economy is not less dependent on oil: the dependency has increased, even though we get “more GDP per barrel” today than before.&lt;/p&gt;
&lt;p&gt;&lt;span&gt;Author’s calculation on primary information coming from BP statistical review &amp;amp; Shilling et al. (energy) and World Bank (GDP).&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;This obviously brings in a question: what is the economy going to become with less oil?&lt;/p&gt;
&lt;h2&gt;Can I use more and more energy?&lt;/h2&gt;
&lt;p&gt;All that has been stated above is indeed absolutely fascinating, and even breathtaking, but if energy is available without any limit, it will mainly be useful for desperate attemps to draw attention during a diner with friends. The economy relies on energy, so be it, and all we have to do is use more and more energy to have more and more economy, and that will settle any issue with pension funds and the popularity of prime ministers.&lt;/p&gt;
&lt;p&gt;But… energy has a major characteristic, well known by physicists: in a closed system, it can &lt;strong&gt;neither be created, nor be destroyed, but only be transformed&lt;/strong&gt;. The energy used by a system has thus to come from outside the system, because it is absolutely forbidden that “more energy” appears spontaneously in this system. An engine does not “create” mechanical energy, it transforms in mechanical energy (and in heat) a previously existing chemical energy (that of the fuel) that comes from the outside. In the same respect, gasoline did not spontaneously appear in the ground, but comes from the &lt;a href=&quot;http://jancovici.com/en/energy-transition/oil/how-do-oil-gas-and-coal-get-created/&quot;&gt;conversion of old solar energy&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Incidentally, the expression “energy producer” should not be used to mention the operator of a power plant, or sometimes an oil producer. The proper expression should be “energy transformer” for a power plant, and “energy miner” for an oil company, because no human activity can create an energy that did not previously exist! Incidentally, when anyone claims to have discovered a machine that yields more energy than it receives from the environment, it is a variation of perpetual move: impossible! Even the heat pump, that seems to perform this apparent miracle, as the heat it yields represents more energy than the electricity used, actually gives back the energy it receives from the grid (electricity) and from the outside (calories).&lt;/p&gt;
&lt;p&gt;What changes, each time energy is used, is the “grade” of this energy, characterized by a notion which is called entropy, which measures the “degree of disorder” of the energy. Each transformation increases the entropy. Mechanical energy has the lowest entropy, low temperature heat the highest. This is why any use of energy ends with low temperature heat.&lt;/p&gt;
&lt;p&gt;As physics forbid to create energy, humanity will never be able to do anything else than taking advantage of energies that already exists in the environment: matter able to burn (wood and biomass, fossil fuels), fissile nucleus (uranium), existing radiation (Sun), existing movement (waterfalls, wind, tides), etc. And, of course, we are limited to consuming no more energy than the amounts available in the environment. Any energy that does not exist in the environment (electricity, &lt;a href=&quot;http://jancovici.com/en/publications-and-co/newspaper-articles-en/a-letter-published-in-the-readers-section-of-le-monde-about-jeremy-rifkin-and-hydrogen/&quot;&gt;hydrogen&lt;/a&gt;…) it cannot be considered as an energy source: it is just a way to use an energy that has to be drawn from the environment in the first place.&lt;/p&gt;
&lt;p&gt;A second limitation is often a major one: that of available power. Our industrial uses not only need a lot of energy, but they need even more a lot of power, that is the delivery of energy over a very short period of time. A car weighting one ton that travels at 100 km/h represents a kinetic energy of about 0,1 kWh. It is not tremendous: a man that cycles like mad can yield that energy in a couple hours. But what we want is our car to get to its cruising speed in a matter of tens of seconds, not in a few hours! It’s another way to say that the energy sources that are of some interest, for our “modern uses”, are those able to yield a lot of power.&lt;/p&gt;
&lt;p&gt;And the whole debate on renewables is there, because the Sun can very well send us each hour the energy that we use in a year, this energy is scattered on the full surface of the Earth, with a low power per surface unit. Getting that energy “concentrated” to bring it to the level of fossil fuels will often be the difficult part.&lt;/p&gt;
&lt;h2&gt;And then?&lt;/h2&gt;
&lt;p&gt;Now that the physical flows that generate the economic output are put in motion by an energy &lt;a href=&quot;http://jancovici.com/en/energy-transition/energy-and-us/how-much-of-a-slave-master-am-i/&quot;&gt;hundreds of times more powerful than that of our muscles&lt;/a&gt;, a reasonable hypothesis is to consider that our economy will not be able to grow faster than the energy supply, with a little “relief” granted by energy efficiency, but that is far from being massive &lt;a href=&quot;http://jancovici.com/en/climate-change/economy/what-is-kayas-equation/&quot;&gt;when examined for previous decades&lt;/a&gt;. It is pretty coherent with the fact that the evolution of oil production, that dominates by far the energy supply (oil represents 42% of the final energy consumption in the world), is the &lt;a href=&quot;http://jancovici.com/en/energy-transition/oil/is-the-price-of-oil-driving-the-economy/&quot;&gt;best indicator of the future evolution of the GDP&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;If we go back to the graph above that gives the average energy consumption per capita, we see that there have been two very different stages since the beginning of “industry for everyone”:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;until the two oil shocks, the supply per capita is following a steady growth of 2,5% per year on average,&lt;/li&gt;
&lt;/ul&gt;&lt;ul&gt;&lt;li&gt;since 1980, and even with the growth of the last 10 years, the increase is only 0,4% per year on average.&lt;/li&gt;
&lt;/ul&gt;&lt;div class=&quot;pure-g figure_layout&quot; readability=&quot;13.5&quot;&gt;
&lt;div class=&quot;pure-u-1-1 gutter-1-2&quot; readability=&quot;22&quot;&gt;&lt;img src=&quot;https://jancovici.com/wp-content/uploads/2016/04/energie_graph3.jpg&quot; alt=&quot;&quot;/&gt;&lt;p&gt;&lt;em&gt;Annual variation of the average energy consumption per capita in the world since 1860.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;The blue curve gives the annual change; the horizontal red line on the left gives the mean for the 1860-1980 period,&lt;br/&gt;The horizontal red line on the right gives the mean for the 1981-2014 period.&lt;/p&gt;
&lt;p&gt;It is easy to see that the two oil shocks correspond to a sharp drop in the average rate of increase of the energy consumption per capita: before it was 2,4% per year on average, after it fell to 0,4% per year on average.&lt;/p&gt;
&lt;p&gt;&lt;span&gt;Author’s calculations on primary data from Shilling et al., BP statistical review &amp;amp; Energy Information Agency (energy) and United Nations (Population).&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;It happens that the economic evolution of the 20th century (and the early 21st) also comprises two very different episodes:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;from 1880 to 1975, when energy per capita is strongly growing, the world undergoes just one major economic crisis, in 1929.&lt;/li&gt;
&lt;/ul&gt;&lt;ul&gt;&lt;li&gt;since 1975, after the rate of growth dramatically decreased, there has been a crisis every 5 to 10 years: 1975, 1980, 1991, 2000, 2008, 2012, and it would be no surprise to have a new one in the coming years.&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;As the role of energy is to help transforming things, all this is logical: less energy = a lower transformation capacity = less GDP &lt;a href=&quot;http://jancovici.com/en/energy-transition/societal-choices/could-the-economy-shrink/&quot;&gt;that only measures the amount of transformation&lt;/a&gt;. We can even go further in this direction with the simple maths that follows, and we will begin with an equation than anyone should agree on, which is that the world GDP is equal to itself (!).&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;wp-katex-eq&quot; data-display=&quot;false&quot;&gt;GDP= GDP&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;So far, we should all agree! Then we will multiply and divide, on the right hand side, by the world energy consumption, called NRJ.&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;wp-katex-eq&quot; data-display=&quot;false&quot;&gt;GDP= \frac{GDP} {NRJ}\times{NRJ}&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;We have just written that:&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;wp-katex-eq&quot; data-display=&quot;false&quot;&gt;\text{\scriptsize{World GDP}}=\text{ \scriptsize{GDP per energy unit} }\times \text{ \scriptsize{Energy consumption}}&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The term “GDP per energy unit” is nothing else than the energy efficiency of the economy: the more efficient the economic system is, the more GDP is produced with the same amount of energy. In other words, when this term increases, it means that for the same amount of kWh (or BTU!), we can have more furniture, glasses, cars, frozen peas, buildings or coffee machines.&lt;/p&gt;
&lt;p&gt;We will then bring that equality to amounts per capita, by dividing on both sides by the world population, named POP:&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;wp-katex-eq&quot; data-display=&quot;false&quot;&gt;\frac{GDP} {Pop}= \frac{GDP} {NRJ}\times \frac{NRJ} {Pop}&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;We have now written that:&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;wp-katex-eq&quot; data-display=&quot;false&quot;&gt;\text{\scriptsize{GDP per capita (world average)}}=\text{ \scriptsize{GDP per energy unit} }\times \text{ \scriptsize{Energy consumption per capita}}&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;We will now shift from the terms to their increase or decrease over time. Indeed, when two terms are equal, then their variation over time is also equal! And in doing so we will benefit from a little help from maths: when each of the righ hand side terms varies slowly over time, the variation of their product is equal – on the first order – to the sum of their variations.&lt;/p&gt;
&lt;p&gt;In other words, il we have A = B*C, then the change of A year on year, noted %A, is basically equal to %B+%C, for %B and %C that remain “small” (several % per year is OK on that respect). If the world population increases by 2% per year and the energy consumption per capita increases by 4% per year, the global energy consumption (which is the multiplication of the 2 previous terms) increases by 6% per year (4%+2%) and not 4%*2%!&lt;/p&gt;
&lt;p&gt;With this information we can then write:&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;wp-katex-eq&quot; data-display=&quot;false&quot;&gt;\%\frac{GDP} {Pop}= \% \frac{GDP} {NRJ} \times \% \frac{NRJ} {Pop}&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The left term is nothing else than… “growth per capita”.&lt;br/&gt;This equation therefore means that:&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;wp-katex-eq&quot; data-display=&quot;false&quot;&gt;\text{\scriptsize{Growth of GDP per capita}}=\text{ \scriptsize{Growth of GDP per energy unit} }\times \text{ \scriptsize{Growth of energy consumption per capita}}&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Then the first graph on this page shows that the term NRJ/POP abruptely shifted from a 2% yearly growth – that had been sustained for more than a century – to… zero. Meanwhile the term GDP/NRJ went on growing by a little less than 1% per year since 1970, and this rythm has not been modified much by the oil shocks.&lt;/p&gt;
&lt;div class=&quot;pure-g figure_layout&quot; readability=&quot;11.129032258065&quot;&gt;
&lt;div class=&quot;pure-u-1-1 gutter-1-2&quot; readability=&quot;17.41935483871&quot;&gt;&lt;img src=&quot;https://jancovici.com/wp-content/uploads/2016/04/energie_graph11.jpg&quot; alt=&quot;&quot;/&gt;&lt;p&gt;&lt;em&gt;Constant dollars of GDP produced per kWh of &lt;a href=&quot;http://jancovici.com/en/energy-transition/electricity/what-is-exactely-the-share-of-electricity-in-frances-energy-consumption/&quot;&gt;primary energy&lt;/a&gt; consumed, since 1965. What this curve shows is that to get a dollar of GDP in 2014 in the world, it requires 30% less energy than in 1965.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;The term GDP/NRJ therefore gained a little less than 1% per year since 1965 (0,8% per year to be precise!), but we notice that for the last decade it has been flat.&lt;/p&gt;
&lt;p&gt;&lt;span&gt;Source: BP Statistical Review 2015 for energy, World Bank 2015 for GDP.&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;In the past, this simple equation explains why the GDP per capita, in world average, abruptely went from a growth of 3% per year before 1980 (a little less than 1% per year for GDP/NRJ + 2% per year for NRJ/POP) to a little above 1% per year right after 1980 (still a little less than 1% per year for GDP/NRJ but 0,4% per year for NRJ/POP). All the rest (growing debt, unemployement impossible to get rid of, repetitive speculative bubbles) can quite logically be linked to this abrupt change.&lt;/p&gt;
&lt;div class=&quot;pure-g figure_layout&quot; readability=&quot;11&quot;&gt;
&lt;div class=&quot;pure-u-1-1 gutter-1-2&quot; readability=&quot;17&quot;&gt;&lt;img src=&quot;https://jancovici.com/wp-content/uploads/2016/04/energie_graph8-1.jpg&quot; alt=&quot;&quot;/&gt;&lt;p&gt;&lt;em&gt;Evolution of the GDP per capita since 1960 (blue line), and average per decade (red line).&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;The decrease after the first oil shock is clearly visible, as is the fact that since 1980 the increase is a little above 1% per year. When the energy per capita is going to decrease significantly (that will happen sooner or later), the GDP per capita is probably going to decrease accordingly.&lt;/p&gt;
&lt;p&gt;&lt;span&gt;Source: World Bank 2015 for the primary data, average calculated by the author&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;And what for the future ? If the future is strongly constrained on energy, and it will, particularly on &lt;a href=&quot;http://jancovici.com/en/category/energy-transition/oil/&quot;&gt;oil&lt;/a&gt; and &lt;a href=&quot;http://jancovici.com/en/category/energy-transition/gas/&quot;&gt;gas&lt;/a&gt;, then the term NRJ/POP will become negative, and &lt;a href=&quot;http://jancovici.com/en/energy-transition/societal-choices/could-the-economy-shrink/&quot;&gt;recurring recessions&lt;/a&gt; will become something normal in our economic system. This is fully consistent with the physical reality: less energy = less transformation capacity = less GDP that only measures a transformation.&lt;/p&gt;
&lt;p&gt;Decoupling energy and the GDP is much faster said than done…&lt;/p&gt;
</description>
<pubDate>Fri, 29 Nov 2019 11:55:09 +0000</pubDate>
<dc:creator>gorpovitch</dc:creator>
<dc:language>en-US</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://jancovici.com/en/energy-transition/energy-and-us/what-is-energy-actually/</dc:identifier>
</item>
<item>
<title>Michael Apted&amp;#039;s “Seven Up” series is reaching its conclusion</title>
<link>https://www.nytimes.com/2019/11/27/magazine/63-up-michael-apted.html</link>
<guid isPermaLink="true" >https://www.nytimes.com/2019/11/27/magazine/63-up-michael-apted.html</guid>
<description>&lt;div class=&quot;css-1fanzo5 StoryBodyCompanionColumn&quot;&gt;
&lt;div class=&quot;css-53u6y8&quot;&gt;
&lt;p class=&quot;css-exrw3m evys1bk0&quot;&gt;On a brisk Saturday morning, one uncommonly cloudless and bright for late autumn on England’s moody North Sea coast, the filmmaker Michael Apted paced a sloping headland of mud and stubble with an air of fretful preoccupation. Though the day’s shoot would amount, in the end, to an additional five-minute increment of the documentary project that had intermittently consumed the entirety of his working life, these occasions never ceased to surprise and unnerve him. He had known Jackie, whose arrival was imminent, for 56 years, but her interviews could be volatile, and this one was particularly important, he felt, to get right.&lt;/p&gt;
&lt;p class=&quot;css-exrw3m evys1bk0&quot;&gt;A series of posted warnings along the fraying seaside bluffs, where the stubble field gave abrupt way to the tides below, advertised the dangers of erosion and instability. Apted worried that even a short walk might unnecessarily tax Jackie: She suffered from an arthritic condition that kept her on disability benefits. Though she was now 63 years old, he first met and filmed her when she was 7, and from time to time couldn’t help referring to her as one of the children. She was well into adulthood before he learned to stop treating her as a child, and he no longer really thought of her as one, but he had no concise way to refer to a person who existed for him as all ages at once. Nor was there an easy way to describe her view of him. For more than a half century, Apted, now 78, played the role of a recording angel. Every seven years he turned up and asked her to account for her life.&lt;/p&gt;
&lt;/div&gt;
&lt;aside class=&quot;css-ew4tgv&quot; aria-hidden=&quot;true&quot;/&gt;&lt;/div&gt;&lt;span class=&quot;css-i48y28 e13ogyst0&quot;&gt;Jackie&lt;/span&gt;&lt;span class=&quot;css-cch8ym&quot;&gt;&lt;span class=&quot;css-1dv1kvn&quot;&gt;Credit&lt;/span&gt;&lt;/span&gt;
&lt;div class=&quot;css-1fanzo5 StoryBodyCompanionColumn&quot;&gt;
&lt;div class=&quot;css-53u6y8&quot;&gt;
&lt;p class=&quot;css-exrw3m evys1bk0&quot;&gt;Jackie arrived in a bright red parka and purple-trimmed glasses, colors selected to stand out on camera against the wintry brown of the stubble field and the indifferent gray-green of the sea, and made her way slowly from the parking lot. A cheerful German shepherd bounded ahead, and Apted shook off his reverie to greet the dog with warmth. As Jackie caught up, Apted, still stroking the grateful animal, lifted his face to her and said, “I’ve met her before.”&lt;/p&gt;
&lt;/div&gt;
&lt;aside class=&quot;css-ew4tgv&quot; aria-hidden=&quot;true&quot;/&gt;&lt;/div&gt;
&lt;div class=&quot;css-1fanzo5 StoryBodyCompanionColumn&quot;&gt;
&lt;div class=&quot;css-53u6y8&quot;&gt;
&lt;p class=&quot;css-exrw3m evys1bk0&quot;&gt;“No, you haven’t,” Jackie said, pleased to claim the advantage without delay. Apted looked puzzled. He was probably thinking, Jackie continued, of Lizzie, a family dog of a long-lapsed decade. “You filmed her in ’35.’ She joined the family photo.” Apted shrugged, allowing two dogs separated by 28 years to bleed together in his mind. It was in the nature of his project that time tended to slip the bonds of its ordinary drill. Jackie gave him a big, untidy kiss.&lt;/p&gt;
&lt;p class=&quot;css-exrw3m evys1bk0&quot;&gt;Claire Lewis, Apted’s longtime producer and collaborator, issued a brief safety lecture about the cliff. Jackie listened but continued to look at Apted, eager for the chance to score another point.&lt;/p&gt;
&lt;p class=&quot;css-exrw3m evys1bk0&quot;&gt;“You used to be like that, Michael,” she said.&lt;/p&gt;
&lt;p class=&quot;css-exrw3m evys1bk0&quot;&gt;“I’m getting old,” Apted replied in the restrained baritone that had long narrated her history, “and forgetting things.”&lt;/p&gt;
&lt;p class=&quot;css-exrw3m evys1bk0&quot;&gt;Jackie was delighted. “I never thought I’d hear you say that!”&lt;/p&gt;
&lt;p class=&quot;css-exrw3m evys1bk0&quot;&gt;Apted ignored the provocation. The morning’s B-roll, he explained, required Jackie, along with a small family entourage and this belated generation of an old familiar dog, to walk downhill from an operational lighthouse. A quadcopter drone would begin out over the water, taking in the irregular sweep of the Norfolk coast, and gradually zoom in until her tiny figure assumed recognizable proportions. He asked if Jackie felt well enough to comply.&lt;/p&gt;
&lt;p class=&quot;css-exrw3m evys1bk0&quot;&gt;“I’m all right, Mike,” she said. “I just don’t want to overdo it.”&lt;/p&gt;
&lt;p class=&quot;css-exrw3m evys1bk0&quot;&gt;Apted’s crew — a cameraman, George Jesse Turner, and sound engineer, Nick Steer, who have been with him since Jackie was 21; Lewis, who joined when Jackie was 28; and a few young people new to the program — began to set up, and he ambled around the periphery like an extra on his own set, taking a keen interest in the local dogs out for a walk. Apted is tall and narrow and was moving with a slight limp; his face, gaunt with age but rosy from the California sun, has in recent years taken on the grave warmth of his voice. He wore a green cap pulled down like a falcon’s hood, as if to conceal the challenge of his gaze. He is dryly funny, and occasionally he returned to the busy group to deliver a droll comment on the technological advances they’d witnessed since the early days of 16-mm handhelds and 12-inch television screens. Everyone else bellowed to be heard over the cold sea wind, but Apted’s own contributions never rose above the volume of a confident voice-over. When it was time, he gave a rusty action whistle. After a few takes, the young drone operator, new to the production, proposed one more, but Turner said that Jackie had already walked too far.&lt;/p&gt;
&lt;/div&gt;
&lt;aside class=&quot;css-ew4tgv&quot; aria-hidden=&quot;true&quot;/&gt;&lt;/div&gt;
&lt;div class=&quot;css-1fanzo5 StoryBodyCompanionColumn&quot;&gt;
&lt;div class=&quot;css-53u6y8&quot;&gt;
&lt;p class=&quot;css-exrw3m evys1bk0&quot;&gt;An hour later, the group reassembled a short distance up the coast at a pub called the Poachers Pocket. Jackie, accustomed since adolescence to location shoots, explained to the young bartender that they were there for a film project called the “Up” series — not the cartoon movie “Up,” she hastened to clarify, but a documentary. (The drone operator, much closer in age to the bartender than to Jackie, piped up to say that the cartoon movie was also worth seeing.) In 1963, as a schoolgirl in London’s working-class East End, she was interviewed for a television special called “Seven Up!” In late 1970, she appeared in a follow-up, “Seven Plus Seven,” and since then Apted and his crew have returned with biblical clockwork. The footage they were shooting at the pub — a conversation between Jackie and her older sister Ray — would appear in &lt;a class=&quot;css-1g7m0tk&quot; href=&quot;https://www.nytimes.com/2019/11/26/movies/63-up-review.html&quot; title=&quot;&quot;&gt;“63 Up,”&lt;/a&gt; the ninth installment in the series.&lt;/p&gt;
&lt;/div&gt;
&lt;aside class=&quot;css-ew4tgv&quot; aria-hidden=&quot;true&quot;/&gt;&lt;/div&gt;
&lt;div class=&quot;css-1fanzo5 StoryBodyCompanionColumn&quot;&gt;
&lt;div class=&quot;css-53u6y8&quot;&gt;
&lt;p class=&quot;css-exrw3m evys1bk0&quot;&gt;The bartender was taken aback. “So you started this when you were 7 years old? How did you get onto it, then?”&lt;/p&gt;
&lt;p class=&quot;css-exrw3m evys1bk0&quot;&gt;“Because I didn’t shut up,” Jackie said. “They asked the school to recommend children that wouldn’t be intimidated by the camera — there’s 14 of us — and I wouldn’t shut up.” Jackie, who has developed a proprietary relationship to the program, was momentarily distracted by the presence of a production assistant’s coat in the background. “Whose coat is this? You don’t want it in the shot!”&lt;/p&gt;
&lt;p class=&quot;css-exrw3m evys1bk0&quot;&gt;Apted arrived and Jackie and her sister joined him in the autumn sun on a terrace overlooking the sea. Visible beneath the shallow waves were the skeletal remains of a seaside village that was submerged, in 1953, by a tidal surge. The play of the submarine light made the old walls ripple.&lt;/p&gt;
&lt;p class=&quot;css-exrw3m evys1bk0&quot;&gt;“The early ones are easy to remember,” Jackie said. “There were certain milestones — the birth of the kids.”&lt;/p&gt;
&lt;p class=&quot;css-exrw3m evys1bk0&quot;&gt;“Now,” Apted replied, “it all gets muddled up.” Jackie nodded. The three of them debated whether a different pub location had appeared in “35 Up” or “42 Up.”&lt;/p&gt;
&lt;/div&gt;
&lt;aside class=&quot;css-ew4tgv&quot; aria-hidden=&quot;true&quot;/&gt;&lt;/div&gt;
&lt;div class=&quot;css-1fanzo5 StoryBodyCompanionColumn&quot;&gt;
&lt;div class=&quot;css-53u6y8&quot;&gt;
&lt;p class=&quot;css-exrw3m evys1bk0&quot;&gt;Jackie looked to her sister for a reference point. They agreed that they’d already lost their mum.&lt;/p&gt;
&lt;p class=&quot;css-exrw3m evys1bk0&quot;&gt;After a pause, Jackie moved closer to Michael and spoke more quietly. “Next week, that’ll be a strange one.” When Jackie was 7, Apted interviewed her along with two of her East End schoolmates, Sue and Lynn, and each successive episode included a segment in which he consulted the three of them together, always arranged in the same configuration. In the years since “56 Up,” Lynn had died. She was the first child they lost. The following week, Apted planned to film Jackie and Sue in Lynn’s absence. “There used to be three of us,” she continued, trailing off. “But life goes on … or it doesn’t.”&lt;/p&gt;
&lt;p class=&quot;css-exrw3m evys1bk0&quot;&gt;Apted meandered inside, and Lewis, his producer, came to fetch Jackie.&lt;/p&gt;
&lt;p class=&quot;css-exrw3m evys1bk0&quot;&gt;“Ready, girls?” she asked. Jackie nodded and sat down. “I’m ready, Mike. Are you?”&lt;/p&gt;
&lt;p class=&quot;css-exrw3m evys1bk0&quot;&gt;Apted assumed the sportive tone he reserves for expressions of total sincerity. “I live for this moment every seven years!”&lt;/p&gt;
&lt;/div&gt;
&lt;aside class=&quot;css-ew4tgv&quot; aria-hidden=&quot;true&quot;/&gt;&lt;/div&gt;
&lt;div class=&quot;css-79elbk&quot; data-testid=&quot;photoviewer-wrapper&quot;&gt;

&lt;div data-testid=&quot;photoviewer-children&quot; class=&quot;css-1a48zt4 ehw59r15&quot;&gt;
&lt;div class=&quot;css-1xdhyk6 erfvjey0&quot;&gt;&lt;span class=&quot;css-1ly73wi e1tej78p0&quot;&gt;Image&lt;/span&gt;&lt;img alt=&quot;“28 Up,” Michael Apted (seated) with Jackie, Lynn and Sue. &quot; class=&quot;css-1m50asq&quot; src=&quot;https://static01.nyt.com/images/2019/12/01/magazine/01mag-aptedcolor/01mag-aptedcolor-articleLarge.jpg?quality=75&amp;amp;auto=webp&amp;amp;disable=upscale&quot; srcset=&quot;https://static01.nyt.com/images/2019/12/01/magazine/01mag-aptedcolor/01mag-aptedcolor-articleLarge.jpg?quality=90&amp;amp;auto=webp 600w,https://static01.nyt.com/images/2019/12/01/magazine/01mag-aptedcolor/01mag-aptedcolor-jumbo.jpg?quality=90&amp;amp;auto=webp 1024w,https://static01.nyt.com/images/2019/12/01/magazine/01mag-aptedcolor/01mag-aptedcolor-superJumbo.jpg?quality=90&amp;amp;auto=webp 2048w&quot; sizes=&quot;((min-width: 600px) and (max-width: 1004px)) 84vw, (min-width: 1005px) 80vw, 100vw&quot; itemprop=&quot;url&quot; itemid=&quot;https://static01.nyt.com/images/2019/12/01/magazine/01mag-aptedcolor/01mag-aptedcolor-articleLarge.jpg?quality=75&amp;amp;auto=webp&amp;amp;disable=upscale&quot;/&gt;&lt;/div&gt;
&lt;span aria-hidden=&quot;true&quot; class=&quot;css-i48y28 e13ogyst0&quot;&gt;“28 Up,” Michael Apted (seated) with Jackie, Lynn and Sue. &lt;/span&gt;&lt;span itemprop=&quot;copyrightHolder&quot; class=&quot;css-ach9cc e1z0qqy90&quot;&gt;&lt;span class=&quot;css-1ly73wi e1tej78p0&quot;&gt;Credit...&lt;/span&gt;&lt;span&gt;ITV/Shutterstock&lt;/span&gt;&lt;/span&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;css-1fanzo5 StoryBodyCompanionColumn&quot;&gt;
&lt;div class=&quot;css-53u6y8&quot;&gt;
&lt;p class=&quot;css-exrw3m evys1bk0&quot;&gt;&lt;strong class=&quot;css-8qgvsz ebyp5n10&quot;&gt;To spend time&lt;/strong&gt; with a child is to dwell under the terms of an uneasy truce between the possibility of the present and the inevitability of the future. Our deepest hope for the children we love is that they will enjoy the liberties of an open-ended destiny, that their desires will be given the free play they deserve, that the circumstances of their birth and upbringing will be felt as opportunities rather than encumbrances; our greatest fear is that they will feel thwarted by forces beyond their control. At the same time, we can’t help poring over their faces and gestures for any signals of eventuality — the trace hints and betrayals of what will emerge in time as their character, their plot, their fate. And what we project forward for the children in our midst can rarely be disentangled from what we project backward for ourselves.&lt;/p&gt;
&lt;p class=&quot;css-exrw3m evys1bk0&quot;&gt;These are the tensions that have animated and shaped the “Up” programs on their way to becoming the longest-running documentary film series of all time. The narrator of 1964’s “Seven Up!” reminds the viewer that “the shop steward and the executive of the year 2000 are now 7 years old,” as the boys and girls arrayed before us in grainy black and white chase each other around during a special outing at the zoo. “This,” the episode concludes, “has been a glimpse of Britain’s future.”&lt;/p&gt;
&lt;p class=&quot;css-exrw3m evys1bk0&quot;&gt;The first film was conceived as a special one-off episode of a program called “World in Action.” The mid-1950s saw an end to the BBC’s monopoly on terrestrial broadcasting, and “World in Action” became the flagship current-affairs program of a Manchester-based commercial upstart called Granada Television. The show was run by a 30-something Australian émigré named Tim Hewat, a former editor of the northern Daily Express and an instrumental figure in the expansion of broadsheet vigor to television. As an expat, Hewat found absurd the idea that postwar Britain had at last begun to dismantle the rigid class determinations that striated the country for centuries, and he was looking for a novel way to expose the lie of the new egalitarianism.&lt;/p&gt;
&lt;/div&gt;
&lt;aside class=&quot;css-ew4tgv&quot; aria-hidden=&quot;true&quot;/&gt;&lt;/div&gt;
&lt;div class=&quot;css-1fanzo5 StoryBodyCompanionColumn&quot;&gt;
&lt;div class=&quot;css-53u6y8&quot;&gt;
&lt;p class=&quot;css-exrw3m evys1bk0&quot;&gt;Hewat was taken with the saying, “Give me a child until he is 7 and I will give you the man,” and proposed the idea for “Seven Up!” As one researcher remembered it, Hewat imagined an aerial shot of 20 7-year-olds subjected by voice-over to merciless prophecy: “ ‘Five are going to be winners (zoom in), and 15 are going to be losers (zoom in). Now we’re going to show you why.’ ” Years later, the researcher said, “we supposed artists nodded condescendingly at this barbarian tabloid conceit and then went out and made a film which, though not in those words, said exactly that.”&lt;/p&gt;
&lt;p class=&quot;css-exrw3m evys1bk0&quot;&gt;Apted, 22 and a fresh graduate of Granada’s trainee program, was enlisted as a researcher. His background made him an obvious choice. Apted’s mother was a Blitz evacuee, and he was born in the countryside northwest of London in 1941. His family returned in peacetime to Ilford, a middle-class town east of the city proper. His father worked as a surveyor for a fire-insurance company, and his mother brought up the children — Apted, a brother and a sister who was adopted after a string of miscarriages. He has described his mother as “a kind of tragic figure,” a very bright woman who, as the youngest of six siblings, was denied the educational foundation for a career. His father went to good schools but never attended university. Apted’s parents, in the hope that their children would reach the solid ranks of the respectable middle class, put what little money they had into education, and from age 10 he commuted on the underground to the prestigious City of London School.&lt;/p&gt;
&lt;/div&gt;
&lt;aside class=&quot;css-ew4tgv&quot; aria-hidden=&quot;true&quot;/&gt;&lt;/div&gt;
&lt;div class=&quot;css-1fanzo5 StoryBodyCompanionColumn&quot;&gt;
&lt;div class=&quot;css-53u6y8&quot;&gt;
&lt;p class=&quot;css-exrw3m evys1bk0&quot;&gt;The school’s location afforded Apted regular exposure to the theater and the cinema, and he describes his experience, at 15, of seeing Ingmar Bergman’s “Wild Strawberries” as his “road to Damascus” moment. Though he loved the French New Wave and the Italian Neorealists — films that had the “gravitas and seriousness of a book” — he was equally drawn to popular entertainments, musicals and comedies on the radio as well as follies and vulgar “end of pier” seaside attractions.&lt;/p&gt;
&lt;p class=&quot;css-exrw3m evys1bk0&quot;&gt;His schooling proceeded along the lines his parents envisioned. His Cambridge interview, he told me, consisted chiefly of questions about rugby. As a fullback, he could kick with both feet and was given a place at Downing College to read history. His era at Cambridge was one of great cultural ferment, and he joined in the flourishing theatrical activity. John Cleese was part of his cohort, and he worked on productions with Trevor Nunn, Mike Newell and Stephen Frears. He knew he wanted to direct but couldn’t imagine how to make a creditable career of it and switched from history to law, a subject that placated his parents and struck him as a way to put his socialist commitments to remunerative use.&lt;/p&gt;
&lt;p class=&quot;css-exrw3m evys1bk0&quot;&gt;Apted finished his time at university just as commercial television was beginning to take off in Britain. Despite Granada’s populist grandstanding, Apted recalls, the company’s trainee program drew exclusively from Oxford and Cambridge. His first real job at the company, as an assistant to the Canadian director Paul Almond, was on “Seven Up!” Almond had little knowledge of the British educational system, so it fell to Apted and another researcher to procure a mix of children. Over just six weeks, they visited schools all over the country, asking teachers to select from their charges a few candidates unlikely to be camera-shy, and then proceeded by instinct. It was more economical, both logistically and narratively, to gather children in groups. Among the 20 initially chosen, they took three patrician boys from a rarefied pre-preparatory school in Kensington; three girls and a boy from the working-class districts in London’s East End; two middle-class boys from a Liverpool suburb; and two boys from a charity home. The roster was filled out with the son of a colonial adventurer at a military-inflected boarding school and two representatives of rural England — a well-bred daughter of a wealthy landowner and a dreamy little boy from an isolated farm in the Yorkshire Dales.&lt;/p&gt;
&lt;/div&gt;
&lt;aside class=&quot;css-ew4tgv&quot; aria-hidden=&quot;true&quot;/&gt;&lt;/div&gt;
&lt;div class=&quot;css-1fanzo5 StoryBodyCompanionColumn&quot;&gt;
&lt;div class=&quot;css-53u6y8&quot;&gt;
&lt;p class=&quot;css-exrw3m evys1bk0&quot;&gt;Over the following few weeks, the children were filmed as they went about their disparate activities — schoolyard fights for the working classes, ballet lessons and the performance of “Waltzing Matilda” in Latin for those to the manner born — and then were brought together for a “very special day in London,” an outing that included a party and a trip to the zoo, where one of the posh boys tries in vain to get his social inferiors to stop throwing things at a polar bear. The day ends at a grim, hazardous-looking pit of an “adventure” playground, where the children “could do just what they liked.” (“Those from the children’s home,” the narrator observes, “set about building a house.”)&lt;/p&gt;
&lt;/div&gt;
&lt;aside class=&quot;css-ew4tgv&quot; aria-hidden=&quot;true&quot;/&gt;&lt;/div&gt;

&lt;span class=&quot;css-i48y28 e13ogyst0&quot;&gt;Lynn&lt;/span&gt;&lt;span class=&quot;css-cch8ym&quot;&gt;&lt;span class=&quot;css-1dv1kvn&quot;&gt;Credit&lt;/span&gt;&lt;/span&gt;
&lt;div class=&quot;css-1fanzo5 StoryBodyCompanionColumn&quot;&gt;
&lt;div class=&quot;css-53u6y8&quot;&gt;
&lt;p class=&quot;css-exrw3m evys1bk0&quot;&gt;Almond, eager to create a work of beauty and originality, instructed the cameraman to run after the children at eye level. Apted contributed to the seated interviews, with leading questions designed to elicit maximally contrastive answers. Where the posh pre-preparatory boys know exactly how their educational careers will unfold — “I’m going to Charterhouse,” Andrew says, “and after that Trinity Hall, Cambridge” — Paul from the charity home plaintively asks, “What does university mean?” The most memorable sections, however, are those in which the children act like children. Jug-eared little Bruce, subject to the punitive discipline of a remote boarding school, says, “My heart’s desire is to see my daddy, who is 6,000 miles away.” Here’s befuddled little Paul of the charity home, on marriage: “Say you had a wife, and say you had to eat what they cooked you, and say I don’t like greens — well, I don’t — and say she says, ‘You have to eat what you get,’ so I don’t like greens, say, she gives me greens and — and that’s it.”&lt;/p&gt;
&lt;p class=&quot;css-exrw3m evys1bk0&quot;&gt;“Seven Up!” aired on May 5, 1964. “It was one of those ideas,” Apted wrote later, “that sounded O.K. when you talked about it, but when you actually saw it, it was remarkable.” It landed like a grenade. “That first one,” Apted told me, “was extremely successful. It was the truth of the class system out of the mouths of babes, and the whole country was shocked — people were just gobsmacked by the rifts in English society on celluloid.”&lt;/p&gt;
&lt;p class=&quot;css-exrw3m evys1bk0&quot;&gt;The program had only ever been viewed as a one-off, and Apted went on to other things. His break into drama came a few years later. His friend Mike Newell was going on holiday, and Apted asked Granada management if he could take over a few episodes of the wildly popular soap opera “Coronation Street,” which Newell directed. In 1970, he was working on a comedy series called “The Lovers” when Denis Forman, a legend of British television and film, approached him in the company canteen. In a companion book to “35 Up,” Apted remembers it as an offhand exchange: “ ‘It’s nearly seven years since ‘Seven Up!’ he said. ‘Wouldn’t it be a nice idea to go and see how the children are doing now?’ I said that I thought it might, so as casually as that I re-embarked on a project that has engaged my entire working life.”&lt;/p&gt;
&lt;p class=&quot;css-exrw3m evys1bk0&quot;&gt;&lt;strong class=&quot;css-8qgvsz ebyp5n10&quot;&gt;By the time “42 Up”&lt;/strong&gt; appeared, in 1998, Andrew Sarris could speak for most critics &lt;a class=&quot;css-1g7m0tk&quot; href=&quot;https://observer.com/1999/11/shes-no-fanny-price-but-who-is/&quot; title=&quot;&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;when he called it, in The Observer&lt;/a&gt;, “clearly the most remarkable nonfiction film project in the history of the medium and officially the most temporally ambitious.” &lt;a class=&quot;css-1g7m0tk&quot; href=&quot;https://www.rogerebert.com/reviews/56-up-2013&quot; title=&quot;&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;Roger Ebert called the series&lt;/a&gt; “the noblest project in cinema history.” (The first eight installments can be seen on the BritBox streaming service, though a binge-watch, with its superabundance of life, might induce viewer vertigo; it is best consumed as intended, at seven-year intervals.) But the “Up” films, which Apted himself calls “the program,” are among other things about our halting steps to maturity, and from the moment Apted resumed work on it, when the children were 14, it took more than a decade for the project to find its way.&lt;/p&gt;
&lt;p class=&quot;css-exrw3m evys1bk0&quot;&gt;Apted has described “Seven Plus Seven” as the most painful one to film, and it is perhaps also the most difficult to watch. The blameless incandescence of the 7-year-olds has given way to cringing self-consciousness. Very few of them look directly at the camera, instead peering truculently at the ground or blandly off into the middle distance. The ephemera of social differentiation that marked the first installment — posh Andrew’s announcement that he reads The Financial Times to check his shares (except on Mondays, because markets are closed on weekends); the eagerness of Tony, the East End’s “cheeky chappie” and jockey manqué, to court schoolyard scraps — are no longer worn as lightly. John, in three-piece tweed, describes himself as “a bit more reactionary than most,” and is seen strolling the courtyard of Westminster School with lordly assurance. The posh boys generally bemoan worker strikes; the East Enders generally support them. The installment is, if anything, even more programmatic than its predecessor, where the milk-tooth winsomeness of the children held class-grooved destiny in abeyance.&lt;/p&gt;
&lt;/div&gt;
&lt;aside class=&quot;css-ew4tgv&quot; aria-hidden=&quot;true&quot;/&gt;&lt;/div&gt;

&lt;span class=&quot;css-i48y28 e13ogyst0&quot;&gt;Andrew&lt;/span&gt;&lt;span class=&quot;css-cch8ym&quot;&gt;&lt;span class=&quot;css-1dv1kvn&quot;&gt;Credit&lt;/span&gt;&lt;/span&gt;
&lt;div class=&quot;css-1fanzo5 StoryBodyCompanionColumn&quot;&gt;
&lt;div class=&quot;css-53u6y8&quot;&gt;
&lt;p class=&quot;css-exrw3m evys1bk0&quot;&gt;It couldn’t have been obvious at the time the program first aired, on Dec. 15, 1970, but “Seven Plus Seven” contains a few premonitions of what the series will ultimately become. The first is the tendency of even a diffident, restive 14-year-old to criticize the premise of the program itself. For all their adolescent confusion, the film’s subjects seem to understand that they’ve been pressed into service to settle an impersonal political score. Suzy, the child of rural privilege, wonders aloud if the whole thing wasn’t “just ridiculous.” The posh boys reject the way they were portrayed at 7, though at least one of them worried less about his snobbery and more about an error; he’d said “Trinity Hall, Cambridge,” when he’d meant “Trinity College, Cambridge.”&lt;/p&gt;
&lt;p class=&quot;css-exrw3m evys1bk0&quot;&gt;The other aspect of “Seven Plus Seven” that intrudes uneasily on the program’s stated aim are the oblique confessions of the human face. At 7, Neil was a heartbreakingly endearing, bushy-tailed youngster from Liverpool who wanted to be an astronaut or a motor-coach driver; at 14, his bright lantern eyes have gone red-rimmed and panicky. Though he remains on what appears to be an upwardly mobile track — he’s seen playing chess — it’s clear that, issues of social class aside, he’s showing signs of psychological strain. Bruce, on the other hand, who seemed so timid and defenseless at 7, has blossomed into a ruddy, flaxen-curled and entirely prepossessing teenager. Apted was learning to focus “more and more on the close-up at the expense of action and movement,” he later wrote. “I felt that watching the aging of people’s faces was going to be my most dramatic visual card and central to the essence of the series.”&lt;/p&gt;
&lt;p class=&quot;css-exrw3m evys1bk0&quot;&gt;Whatever lessons lurked there, Apted’s inclination for “21 Up,” which aired on May 9, 1977, was to double-down on the show’s early conviction. The children had reached what he called “gamecock maturity,” and the age difference between them — Apted was then 35 — had narrowed to the extent that he could begin to talk to them as peers. His questions are more pointed, his assumptions more overweening, his tone one of knuckle-rapping authority. Apted has conceded that his sensibility might be that of an “English middle-class neurotic,” a phrase he uses not to describe an individual pathology but a sociological bias. Apted has been frank about the problems with the aleatory, impulsive nature of the original 1964 casting: only four were women; only one represented an ethnic minority; and all but two were drawn from the relative extremes of the class divide. This last decision was made in part because it provided for more sensational television and in part because the filmmakers took their own upwardly mobile middle-class perspective, values and anxieties for granted. If the manifest motivation for the exercise from the beginning was a strong suspicion that England’s class distinctions remained insuperable, there was an equally important if latent hope that the broadening out of the middle-class emphasis on education, abstemiousness, modesty and discipline might confound the base perpetuation of class difference.&lt;/p&gt;
&lt;/div&gt;
&lt;aside class=&quot;css-ew4tgv&quot; aria-hidden=&quot;true&quot;/&gt;&lt;/div&gt;

&lt;span class=&quot;css-i48y28 e13ogyst0&quot;&gt;Tony&lt;/span&gt;&lt;span class=&quot;css-cch8ym&quot;&gt;&lt;span class=&quot;css-1dv1kvn&quot;&gt;Credit&lt;/span&gt;&lt;/span&gt;
&lt;div class=&quot;css-1fanzo5 StoryBodyCompanionColumn&quot;&gt;
&lt;div class=&quot;css-53u6y8&quot;&gt;
&lt;p class=&quot;css-exrw3m evys1bk0&quot;&gt;The tone of “21 Up” is thus one of mild and slightly smug disapproval — of the haughtiness and complacency Apted finds at one end of the spectrum and the passivity and complacency he finds at the other. Andrew has, as envisioned, gone to Charterhouse and then Trinity College, Cambridge. John, the reactionary, is shown in a Prince of Wales suit, then beagling for hares with his Oxford chums; he is well aware of his role in the ensemble and resents Apted on camera for the implication that his successes are due not to hard work but to some “indestructible birthright.” Bruce is at Oxford, studying mathematics with his tutor. Two of the three East End girls are married. After Apted asks Jackie whether it was a good idea to settle down so early, she hangs her head in what looks like shame — and which is, four installments later, revealed to have been fury. When things haven’t worked out for a child, Apted can scarcely conceal his disappointment. Neil, having failed to secure a place at Oxford, has dropped out of university after one term at Aberdeen and is living in a London squat. Tony, the cheeky chappie seen training at Tommy Gosling’s stable at Epsom, has abandoned his aspiration to become a jockey and is running numbers for bookies at the greyhound track. Apted encourages Tony to take him on a tour of East London’s criminal landmarks, with the obvious expectation that by 28, Tony will be in one of Her Majesty’s prisons.&lt;/p&gt;
&lt;p class=&quot;css-exrw3m evys1bk0&quot;&gt;The pivotal interim for the show — what turned a gripping if occasionally heavy-handed quasi-sociological experiment into one of the greatest works of art of our time — was the period between “21 Up” and “28 Up.” Several factors contributed to the transformation. In 1979, Apted, having directed a few successful films, moved to Hollywood to make “Coal Miner’s Daughter,” a Loretta Lynn biopic that earned seven Oscar nominations, including Best Picture, and a Best Actress win for Sissy Spacek. He had finally proved that popular entertainment was a real and serious job, one that could combine his political and his humanistic interests, and he was able to relax his neurotic grip on social issues. His family moved from London to settle with him in California, but the minute they arrived he was off to Europe to shoot “Gorky Park,” now in demand as a talented director on his way up.&lt;/p&gt;
&lt;p class=&quot;css-exrw3m evys1bk0&quot;&gt;As the interviews for “28 Up” approached, the project picked up a new researcher, Claire Lewis. Lewis discovered that nobody from the company, including Apted, had bothered to keep track of the participants over the preceding six years, and several participants seemed to have dropped off the face of the earth. “Finding Neil, who was completely missing, took three months,” Lewis once commented. “I literally had to try and do what the police do when you’re looking for a missing person.” She found him in North Wales, in a caravan in the middle of a field.&lt;/p&gt;
&lt;/div&gt;
&lt;aside class=&quot;css-ew4tgv&quot; aria-hidden=&quot;true&quot;/&gt;&lt;/div&gt;

&lt;span class=&quot;css-i48y28 e13ogyst0&quot;&gt;Neil&lt;/span&gt;&lt;span class=&quot;css-cch8ym&quot;&gt;&lt;span class=&quot;css-1dv1kvn&quot;&gt;Credit&lt;/span&gt;&lt;/span&gt;
&lt;div class=&quot;css-1fanzo5 StoryBodyCompanionColumn&quot;&gt;
&lt;div class=&quot;css-53u6y8&quot;&gt;
&lt;p class=&quot;css-exrw3m evys1bk0&quot;&gt;Lewis understood that the program stood no long-term chance of survival without deliberate reinforcement of the personal bonds that held it together. Apted was happy to drop his Hollywood work every seven years to descend once more into his participants’ lives, even if it meant forgoing more lucrative feature jobs, but he was too busy to devote much energy to interim upkeep. He also just didn’t think it was fair. The kinds of questions he asked them amounted to an existential audit, one that few among us could ever face with equanimity, and even once in seven years was nearly unendurable. Lewis understood that not only a softer touch was needed but also a more regular one.&lt;/p&gt;
&lt;p class=&quot;css-exrw3m evys1bk0&quot;&gt;Apted’s awakening humility found formal expression in the editing room. The first three programs were crosscut along thematic lines with sections about class, education or politics. Now, in part because the participants’ archival back stories had grown to unwieldy dimensions, the material could only be tamed if each individual were given his or her own chapter. The final cut felt much less abstract and much more personal.&lt;/p&gt;
&lt;p class=&quot;css-exrw3m evys1bk0&quot;&gt;Even Apted didn’t quite realize how the program had transfigured itself until American audiences were introduced to the series for the first time, with a theatrical premiere in 1985. The reception was extremely enthusiastic; Sarris, in The Village Voice, wrote, “The results are both staggering and chastening on so many levels that the entire enterprise may require years of amplification and analysis before we can even begin to answer all the perplexing questions it raises.” Apted reckoned that the series was too English to appeal to a wider audience. “But I was wrong,” he wrote in 2000. “People did respond to it, and not only here but all over the world. And then I had an epiphany: I realized for the first time, after 20 years on the project, that I really hadn’t made a political film at all. What I had seen as a significant statement about the English class system was in fact a humanistic document about the real issues of life.”&lt;/p&gt;
&lt;/div&gt;
&lt;aside class=&quot;css-ew4tgv&quot; aria-hidden=&quot;true&quot;/&gt;&lt;/div&gt;
&lt;div class=&quot;css-1fanzo5 StoryBodyCompanionColumn&quot;&gt;
&lt;div class=&quot;css-53u6y8&quot;&gt;
&lt;p class=&quot;css-exrw3m evys1bk0&quot;&gt;&lt;strong class=&quot;css-8qgvsz ebyp5n10&quot;&gt;Apted does not rehearse&lt;/strong&gt; his interviews and prefers to restrict all prefatory conversation to his favorite low-stakes subjects: dogs and sports. His handwritten shooting notes are a blunt instrument: “To Ask All: Happiest; saddest; crucial decisive moments; heroes; proud of; worries; show me a child until he is 7; future; has life between a success or failure.” He does, however, reconnoiter with Lewis, who reminds him which topics tend to be profitable and which are touchy or, worse, boring. Before Jackie’s formal interview, which was set to take place in her sister’s living room, Apted and Lewis conferred in the white crew van. They began by going over some basic background — questions about her family and her health — and quickly got to the crux of their expectations for the hearing.&lt;/p&gt;
&lt;p class=&quot;css-exrw3m evys1bk0&quot;&gt;“I think you should say to her,” Lewis said, “ ‘O.K., what I want to talk to you now about is that you’ve been quite angry at me over the years.’ ” Jackie had walked off the set of “21 Up.” Lewis added: “ ‘Can you tell me why?’ You know, ‘You had a go at me in “49 Up,” why was it?’ ” Jackie’s insurrection in “49” remains one of the most arresting and significant moments in the entirety of the program. After decades of chafing at his authorial control, she at last summons the courage to chasten him. When Apted asked how he had failed her, Jackie replied: “The last one was very much based on the sympathy and the illness that I’ve got and what I may or may not be able to do. It should have been about what I &lt;em class=&quot;css-2fg4z9 e1gzwzxm0&quot;&gt;can&lt;/em&gt; do, what I &lt;em class=&quot;css-2fg4z9 e1gzwzxm0&quot;&gt;am&lt;/em&gt; doing, what I &lt;em class=&quot;css-2fg4z9 e1gzwzxm0&quot;&gt;will&lt;/em&gt; do.” Jackie had since got over her sense of injury, in no small part because Apted included her rebellion in the final film, but Lewis thought that some things had been left unsaid. “You need to try and find out,” Lewis continued, “what made her so cross — remembering that it was your comments at 21.”&lt;/p&gt;
&lt;/div&gt;
&lt;aside class=&quot;css-ew4tgv&quot; aria-hidden=&quot;true&quot;/&gt;&lt;/div&gt;
&lt;div class=&quot;css-1fanzo5 StoryBodyCompanionColumn&quot;&gt;
&lt;div class=&quot;css-53u6y8&quot;&gt;
&lt;p class=&quot;css-exrw3m evys1bk0&quot;&gt;“Which were they?” Apted asked mildly.&lt;/p&gt;
&lt;p class=&quot;css-exrw3m evys1bk0&quot;&gt;“When you said to her, ‘Have you had enough relationships with men before you got married?’ and I think she thought you meant how many men have you slept with, and I know you didn’t — ”&lt;/p&gt;
&lt;p class=&quot;css-exrw3m evys1bk0&quot;&gt;“No.”&lt;/p&gt;
&lt;p class=&quot;css-exrw3m evys1bk0&quot;&gt;“But I think that’s what she thought, and she was insulted — ”&lt;/p&gt;
&lt;p class=&quot;css-exrw3m evys1bk0&quot;&gt;“And what was I asking?”&lt;/p&gt;
&lt;p class=&quot;css-exrw3m evys1bk0&quot;&gt;“And for the rest of that interview she stared at the floor, wouldn’t look at you and wouldn’t speak to you.”&lt;/p&gt;
&lt;p class=&quot;css-exrw3m evys1bk0&quot;&gt;“Yeah, right.” Apted seemed to recall the contretemps through a light fog.&lt;/p&gt;
&lt;p class=&quot;css-exrw3m evys1bk0&quot;&gt;Lewis reminded Apted that Jackie had expressed a desire to complete her education. “And she hasn’t gone back to school, she hasn’t done anything that she really wanted to do. So in a way her story is one of underachievement and of dreams. She’s a very intelligent woman, and she’s very brave, and I think what we need to try and get out of her is why, when everything is going so wrong all around her, how does she manage to stay so strong? Because she does.”&lt;/p&gt;
&lt;p class=&quot;css-exrw3m evys1bk0&quot;&gt;“Mm-hm.”&lt;/p&gt;
&lt;p class=&quot;css-exrw3m evys1bk0&quot;&gt;Act 3 of the interview, as they planned it, would return to the program’s original conceit. “Give me a child until he is 7” — is there any truth in that? Is there still social class in Britain and, if so, what continuing effects does it have? “And I think,” Lewis concluded, “you need to add, ‘Has she any fears for her grandchildren?’ For the world and her grandchildren, because she’s now got five grandchildren — it’s looking forward.”&lt;/p&gt;
&lt;p class=&quot;css-exrw3m evys1bk0&quot;&gt;There was a long pause.&lt;/p&gt;
&lt;p class=&quot;css-exrw3m evys1bk0&quot;&gt;“It never goes the way you expected,” Apted said.&lt;/p&gt;
&lt;p class=&quot;css-exrw3m evys1bk0&quot;&gt;“Of course it doesn’t. It’s not a script, is it? It’s merely a theme, merely an idea, and anyway I hope she’ll just do something unexpected, which will be lovely.”&lt;/p&gt;
&lt;p class=&quot;css-exrw3m evys1bk0&quot;&gt;Inside, he took a seat perhaps three feet away from Jackie, off to the side of the camera in a chair that Jackie had labeled “Director Apted.” Apted began the interview with some warm-up questions about where they were, why her sister became so important to her and how things stood at her home in Scotland.&lt;/p&gt;
&lt;p class=&quot;css-exrw3m evys1bk0&quot;&gt;“What,” Apted then asked, “have the big changes been since we sat down together?”&lt;/p&gt;
&lt;p class=&quot;css-exrw3m evys1bk0&quot;&gt;“Oh, God,” Jackie said, “here comes the horrible part.” Her eyes filled with tears. In “56 Up,” she was grief-stricken at the death of her former partner, Ian. The intervening years brought more pain: first the loss of Ian’s mother, Liz, with whom Jackie had been very close, and then the loss of her beloved father. “That was so hard — I was 30 years old when I lost my mum, and my dad was my rock.” Apted tried to steer her away from the agony of her bereavement and into the fortification of her anger with the state bureaucracy, but Jackie returned to Ian’s untimely death. Her children had been devastated; Ian’s mother, in the short time left to her, never recovered.&lt;/p&gt;
&lt;/div&gt;
&lt;aside class=&quot;css-ew4tgv&quot; aria-hidden=&quot;true&quot;/&gt;&lt;/div&gt;
&lt;div class=&quot;css-1fanzo5 StoryBodyCompanionColumn&quot;&gt;
&lt;div class=&quot;css-53u6y8&quot;&gt;
&lt;p class=&quot;css-exrw3m evys1bk0&quot;&gt;“Well, you know that,” Jackie said, in an exchange that Apted, keen to leave himself out of the program, would not share with his viewers. His eldest son, the Hollywood sound editor Paul Apted, was born three years after the first program was broadcast, and died of colon cancer, at 47, two years after the previous one. Many of the children sent him notes of condolence. “You know what it’s like.”&lt;/p&gt;
&lt;p class=&quot;css-exrw3m evys1bk0&quot;&gt;Apted’s voice was quiet as a shaken leaf. “Horrible.”&lt;/p&gt;
&lt;/div&gt;
&lt;aside class=&quot;css-ew4tgv&quot; aria-hidden=&quot;true&quot;/&gt;&lt;/div&gt;

&lt;span class=&quot;css-i48y28 e13ogyst0&quot;&gt;Nick&lt;/span&gt;&lt;span class=&quot;css-cch8ym&quot;&gt;&lt;span class=&quot;css-1dv1kvn&quot;&gt;Credit&lt;/span&gt;&lt;/span&gt;
&lt;div class=&quot;css-1fanzo5 StoryBodyCompanionColumn&quot;&gt;
&lt;div class=&quot;css-53u6y8&quot;&gt;
&lt;p class=&quot;css-exrw3m evys1bk0&quot;&gt;&lt;strong class=&quot;css-8qgvsz ebyp5n10&quot;&gt;There is no way&lt;/strong&gt; to describe the arc of the program without making it sound like an incidental soap opera of our short and ordinary days. Tony becomes a cabby, fails as a publican, confesses his marital infidelity on camera, buys a home in London’s outskirts, adds a vacation property in Spain, raises his granddaughter when his own daughter proves unable, tries and fails to open a sports pub, sells his home in Spain after the financial crisis and through it all talks about the celebrities he has driven in his taxi. John, one of the posh boys, drops out of the show before “28” and only returns at “35” on the condition that he can draw attention to the charity work he does in Bulgaria; he never makes it to Parliament, to his chagrin, but he wears the wig and the silk as a Queen’s Counsel. He never has children. (John, who declares in “35 Up” that the show feels like a “little pill of poison” injected into his veins, will not speak to Apted on camera; Lewis has conducted the interviews since 1991.) Bruce, who once dreamed of missionary work, teaches immigrant children in the East End — it’s the same school Tony attended, as it turns out, after the neighborhood’s great demographic shift — before marrying late, having two boys and abandoning the ideals of his youth to serve at an elite school that was founded in the year 948. They gain lined faces, put on weight, lose parents.&lt;/p&gt;
&lt;p class=&quot;css-exrw3m evys1bk0&quot;&gt;The original political aims of the series weren’t abandoned so much as rendered implicit. Apted experimented with various timely inquiries over the years — he once asked the participants about the death of Princess Diana — but the material never worked and he threw it out. Class, of course, never goes away. Though there is indeed some social mobility, the elites are running the country and the nonelites, while mostly comfortable, are not. In 2005, with the release of “49 Up,” &lt;a class=&quot;css-1g7m0tk&quot; href=&quot;https://www.theguardian.com/media/2005/sep/14/britishidentityandsociety.comment&quot; title=&quot;&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;the British journalist Jonathan Freedland wrote&lt;/a&gt;, “It seems Granada’s original premise — that background determines fate — has held up depressingly well.” The nature of the class system, however, had changed since the Thatcherite revolution of the early 1980s. As the British social historian Joe Moran noted, in 2002, the series “did not foresee the decline of the British economy’s manufacturing base, the fragmentation of the working class, the rising number of white-collar jobs and Thatcherism’s destruction of union power.” It also didn’t foresee the expansion of middle-class consumerism or the rise of the predatory gig economy.&lt;/p&gt;
&lt;p class=&quot;css-exrw3m evys1bk0&quot;&gt;Apted might not have anticipated these things, but they nevertheless find expression as the delimiting conditions of the participants’ lives. If in the early installments he attempted to recruit individual biography to dramatize socioeconomic history, the program’s attention is ultimately drawn to an even more profound dynamic: the interplay of self and environment. The narrative center of gravity of the “Up” films hovers somewhere between the stiff-necked documentarian and the unruly subjects to whom he is yoked. Apted, like a social scientist, emphasizes the role of big, obstinate forces; his participants almost invariably take the opposing side of agency and self-determination. What we get, as the show goes on, is an ever-fuller picture of how particular individuals at times shrink to inhabit the givens of an inheritance and at times spill over the sides of those constraints. What emerges are the countervailing qualities of structure and dignity.&lt;/p&gt;
&lt;p class=&quot;css-exrw3m evys1bk0&quot;&gt;The program is able to generate this surfeit of meaning in part through the frictional trajectory of its participants’ relationship with Apted himself — as both an individual and as a sort of imago, a figure of fraught authority. Apted has been candid about the odd, transactional nature of the exercise. The children retain an enormous amount of power over him. Many of them have made no secret of the fact that they wish they’d never been chosen; they endure it only out of loyalty. Which is not to say that they aren’t happy to exploit Apted’s vulnerability. Peter, who dropped out after the right-wing media tarred him for the vehement anti-Thatcherite politics he expressed in “28 Up,” was only coaxed to return when Apted agreed to help him promote his band. Still, the negotiations could be extremely difficult and often drove Apted to the end of his tether. He spent several “ludicrous” months trying to get Suzy to participate in “63 Up” — in which, among other ruses, he used other people’s phones to call so she wouldn’t know it was him — and she nevertheless bowed out, to his enduring peevishness.&lt;/p&gt;
&lt;p class=&quot;css-exrw3m evys1bk0&quot;&gt;When they have agreed to continue, Apted nevertheless has needed to remain cautious; he gets right up to the line of the unacceptable without crossing it. His perennial gambits, as he once acknowledged to an interviewer, are “Why?” and “What do you mean?” He recognizes that “why” is an aggressive question, yet he is perfectly happy to ask it and then sit in silence, to the point of sadism. “I never want to take advantage of them or be too soft on them,” he told me. “With people like Neil, who are very bright but very vulnerable, you don’t want them to think you’re being too judgmental.” Still, he can be frontal to an astonishing degree. At the end of his interview with Neil in “63 Up,” Apted risks asking what Neil makes of the maxim, which in Neil’s case would have predicted something other than a life of free-fall.&lt;/p&gt;
&lt;/div&gt;
&lt;aside class=&quot;css-ew4tgv&quot; aria-hidden=&quot;true&quot;/&gt;&lt;/div&gt;
&lt;div class=&quot;css-1fanzo5 StoryBodyCompanionColumn&quot;&gt;
&lt;div class=&quot;css-53u6y8&quot;&gt;
&lt;p class=&quot;css-exrw3m evys1bk0&quot;&gt;“At 7 and 14,” Apted says, “everybody was in love with you. … ”&lt;/p&gt;
&lt;p class=&quot;css-exrw3m evys1bk0&quot;&gt;Neil cuts him off, saying, “And now nobody speaks to me.”&lt;/p&gt;
&lt;p class=&quot;css-exrw3m evys1bk0&quot;&gt;Apted thought that was marvelous.&lt;/p&gt;
&lt;p class=&quot;css-exrw3m evys1bk0&quot;&gt;Over their three hours together, Jackie was alternately furious, despondent, cheerful, horrified, frustrated, disbelieving and amused. Every half an hour they would break, and Lewis would come to Apted’s corner like a boxer’s cut man. Eventually they got around to the material Apted and Lewis discussed in the van. Jackie conceded that something of the core of her character had been captured at 7, though what life would dole out to that child could not of course be anticipated with clarity. Apted pushed her.&lt;/p&gt;
&lt;p class=&quot;css-exrw3m evys1bk0&quot;&gt;“This is an odd question for you,” Apted began. “I mean, we all think you’re a very, very bright, very talented woman — I mean, could you have done more, do you think?”&lt;/p&gt;
&lt;p class=&quot;css-exrw3m evys1bk0&quot;&gt;“Yes, I should have done more. I should have done more. But the trouble is, when you’re 18, 20, 22, you think you know it all and you’ve done it all — or I did, let’s put it that way, but by the time you reach 35 you’re like, ‘Oh, dear, I didn’t know anything.’ But by then I had my children, so I had to concentrate on my children. I was going to say, ‘By the time they grew up and left home,’ but they haven’t!”&lt;/p&gt;
&lt;p class=&quot;css-exrw3m evys1bk0&quot;&gt;“We’ve talked about relationships,” Apted said, “but one we haven’t talked about is you and me — ”&lt;/p&gt;
&lt;p class=&quot;css-exrw3m evys1bk0&quot;&gt;Jackie giggled, a sound that has not changed since she was 7.&lt;/p&gt;
&lt;p class=&quot;css-exrw3m evys1bk0&quot;&gt;“ — which was a big part of our lives in a way, wasn’t it?”&lt;/p&gt;
&lt;p class=&quot;css-exrw3m evys1bk0&quot;&gt;“Yeah, of course it is,” Jackie said.&lt;/p&gt;
&lt;p class=&quot;css-exrw3m evys1bk0&quot;&gt;“What was that about? What’s your version of it?”&lt;/p&gt;
&lt;p class=&quot;css-exrw3m evys1bk0&quot;&gt;“Are you talking specifics?” Jackie asked. “You’re talking about ’49’?”&lt;/p&gt;
&lt;p class=&quot;css-exrw3m evys1bk0&quot;&gt;“Yeah, I think so.”&lt;/p&gt;
&lt;p class=&quot;css-exrw3m evys1bk0&quot;&gt;Jackie collected herself for a moment. “Now I appreciate,” she said, “that when we started at 7 most women were in the kitchen or were bringing up children, there weren’t many career women and those there were were frowned upon, but when we hit 21 I really thought you’d have had a better idea of how the world worked, shall I say?”&lt;/p&gt;
&lt;/div&gt;
&lt;aside class=&quot;css-ew4tgv&quot; aria-hidden=&quot;true&quot;/&gt;&lt;/div&gt;
&lt;div class=&quot;css-1fanzo5 StoryBodyCompanionColumn&quot;&gt;
&lt;div class=&quot;css-53u6y8&quot;&gt;
&lt;p class=&quot;css-exrw3m evys1bk0&quot;&gt;It wasn’t just about how many men Jackie had or hadn’t slept with. “I just didn’t feel that you had any idea of the changing role of women in the U.K. at that point,” she said. “That sounds awfully dismissive, but it was how I felt,” she went on. “I knew you knew you didn’t have enough women in it, and that’s why you introduced Debbie and some of the other wives, but you still asked us the most mundane, domestic questions, and I really wanted to go, ‘Rrrrrr.’ So by ’49’ I actually thought, You know what? No more. I’m not having this anymore.” This part was included in the film, in slightly shorter form, but the following exchange was not.&lt;/p&gt;
&lt;p class=&quot;css-exrw3m evys1bk0&quot;&gt;“I went to a boys’ school and all that sort of stuff,” Apted replied, “so I never saw the lives of a lot of women, girls and whatever, so you’re probably right, I was a bit. … ” Apted seemed to lose his train of thought.&lt;/p&gt;
&lt;p class=&quot;css-exrw3m evys1bk0&quot;&gt;Jackie laughed and rescued him. “I understand that,” she said, “and that’s why I’m saying. … I wanted to say what I wanted to say but that would never affect our relationship. I know if I picked up the phone and said, ‘Michael, I need help,’ you would be there.” Jackie’s voice began to catch, and her eyes shone. “You would say to me, ‘Where, when and how?’ and if it was humanly possible you would help me, I know that. I know you care about me, and I care about you, but that didn’t stop me having to have a go at you. Well, we’re a family, families fall out, families have arguments, but we are a family.”&lt;/p&gt;
&lt;p class=&quot;css-exrw3m evys1bk0&quot;&gt;Jackie stopped, unsure if she had it in her to say out loud the thing that was plainly on the mind of every person in that room. Apted was frail and prone to falls; he regularly misplaced his personal items; he could often enough recall the past with great detail but sought frequent clarification of where he was supposed to go and why. Apted, she feared, would not be well enough to make a movie in seven years’ time. The likelihood there would ever be a “70 Up” was vanishing.&lt;/p&gt;
&lt;p class=&quot;css-exrw3m evys1bk0&quot;&gt;“And this is one of the reasons, and I’ll tell you this now, it’s one of the reasons there’ll never be another program for me.” Her voice broke. Apted himself was not in tears; everyone else in the room was either openly crying or seemed to be struggling for composure. “This is me, I’m done. Because I’m not having somebody else sitting in that chair and somebody else sitting behind the cameras. I wouldn’t be able to trust them the way I trust all of you.”&lt;/p&gt;
&lt;/div&gt;
&lt;aside class=&quot;css-ew4tgv&quot; aria-hidden=&quot;true&quot;/&gt;&lt;/div&gt;

&lt;span class=&quot;css-i48y28 e13ogyst0&quot;&gt;Symon&lt;/span&gt;&lt;span class=&quot;css-cch8ym&quot;&gt;&lt;span class=&quot;css-1dv1kvn&quot;&gt;Credit&lt;/span&gt;&lt;/span&gt;
&lt;div class=&quot;css-1fanzo5 StoryBodyCompanionColumn&quot;&gt;
&lt;div class=&quot;css-53u6y8&quot;&gt;
&lt;p class=&quot;css-exrw3m evys1bk0&quot;&gt;&lt;strong class=&quot;css-8qgvsz ebyp5n10&quot;&gt;At a recent&lt;/strong&gt; celebration of Apted’s achievement, the filmmaker Alex Gibney noted that “63 Up” — the culmination of a program that has drawn its energy from the unfairness of class and its tenderness from the unfairness of flesh — is marked by a “profound sense of mortality.” Lynn has died; her husband, who had always kept his distance from the program, nevertheless agreed to appear, along with their daughters, in Lynn’s stead. Another of the participants, Nick, reveals that throat cancer has made him “seriously ill.” In its broad strokes, Nick’s life has had the greatest resemblance to Apted’s own: an Oxbridge degree, expatriation to the States, divorce. Nick has also provided some of the more astute on-camera commentary. In “56 Up,” he wonders aloud whether a few minutes of his life drawn almost at random every seven years can possibly say anything about who he is. “It isn’t a picture, really, of the essence of Nick,” he concludes. “It’s a picture of Everyman. It’s how a person — any person — how they change.”&lt;/p&gt;
&lt;/div&gt;
&lt;aside class=&quot;css-ew4tgv&quot; aria-hidden=&quot;true&quot;/&gt;&lt;/div&gt;
&lt;div class=&quot;css-1fanzo5 StoryBodyCompanionColumn&quot;&gt;
&lt;div class=&quot;css-53u6y8&quot;&gt;
&lt;p class=&quot;css-exrw3m evys1bk0&quot;&gt;In “63 Up,” this change has run its course, and Nick acknowledges that his thoughts extend no farther than the short term. The program’s dreamlike, foreshortened and haphazardly disobedient rapport with chronology renders not only his present but his past almost unbearably poignant: not a midcareer professor but a dying professor; not a newlywed but a dying newlywed; not a student but a dying student; not a child but a dying child.&lt;/p&gt;
&lt;p class=&quot;css-exrw3m evys1bk0&quot;&gt;This past February, a few months after Jackie’s shoot in Norfolk, I visited Apted in a rented editing suite in Santa Monica, Calif. The notes he got from the studio executives had been a cause for irritation — he felt as though they were trying to revise a formula that had worked for 56 years — but by his own admission he’d never been particularly agreeable about studio notes. Or rather, the notes weren’t terrible, he allowed; he just wasn’t going to use any of them. He felt as though the producers were too new to the series to appreciate its scope. Apted was irked by notes like “Lose Sue’s dog.”&lt;/p&gt;
&lt;p class=&quot;css-exrw3m evys1bk0&quot;&gt;Kim Horton, who has edited the series since “28 Up,” matched Apted’s indignation. “That dog’s been in it for two or three programs!”&lt;/p&gt;
&lt;p class=&quot;css-exrw3m evys1bk0&quot;&gt;“Sue’s dog is quite famous,” Apted said solemnly; he was again confusing two different dogs, but it didn’t matter. “He runs downstairs and watches an animal show on TV. The notes said, ‘That’s not their life, take it out’ — well, it is their life.”&lt;/p&gt;
&lt;p class=&quot;css-exrw3m evys1bk0&quot;&gt;As Apted finished the rough cut, he was also moving out of the bungalow that served, for the previous seven years, as his office. Recently he has had some difficulties securing work, and his professional future in Hollywood was uncertain. The office was in complete disorder, littered with decades of files, awards and scripts, as well as his youngest son’s childhood artwork, an embroidered West Ham pillow, business from his years as the president of the Director’s Guild and cartons of financial, medical and divorce records. “When this is over,” he said, “and I’m not doing anything for the rest of my life, I can go through these boxes.”&lt;/p&gt;
&lt;p class=&quot;css-exrw3m evys1bk0&quot;&gt;On his last day in the office, he peered at the assorted leavings and turned to Cort Kristensen, his producing partner; originally hired 18 years ago as Apted’s assistant, Kristensen now tends to Apted with filial devotion. “You’re sure we got everything done in here?”&lt;/p&gt;
&lt;p class=&quot;css-exrw3m evys1bk0&quot;&gt;“Stop panicking, Michael,” Kristensen said.&lt;/p&gt;
&lt;p class=&quot;css-exrw3m evys1bk0&quot;&gt;We sat at a picnic table outside the editing suite, and he evaluated his achievement. “On the whole,” he said of “63 Up,” “they’ve never been better, the people in it. They’ve had to pay attention to the whole life span, to confront themselves, and they seemed to be very serious. I was fairly thorough with them.” It hadn’t required a lot of prodding this time. “I suppose when you’re asked to look back on your life, it can’t be a flat experience; it has to be an emotional experience.”&lt;/p&gt;
&lt;/div&gt;
&lt;aside class=&quot;css-ew4tgv&quot; aria-hidden=&quot;true&quot;/&gt;&lt;/div&gt;
&lt;div class=&quot;css-1fanzo5 StoryBodyCompanionColumn&quot;&gt;
&lt;div class=&quot;css-53u6y8&quot;&gt;
&lt;p class=&quot;css-exrw3m evys1bk0&quot;&gt;I asked if any of them had surprised him. There were a handful of plot twists, long-delayed revelations and belated experiences, but those were par for the course. What struck him now were tonal shifts. He mentioned Nick, the ailing expat professor, who had only agreed to an interview in a last-minute text of three words, Apted told me. Apted had rushed back from Australia, where he was shooting Paul and Symon, to visit him in Wisconsin. Apted had been warned that Nick might have to stop every 10 minutes or so for a break, but Nick had spoken without pause for an hour and a half. “He wanted to settle things,” Apted said, “with himself and the people who knew him and the audience.” In the past, it had been a struggle for Nick to summon emotion; now he struggled to summon his old dispassion. “I’m still the same little kid, really,” he said over the footage of himself at 7. “I think all of us are.”&lt;/p&gt;
&lt;p class=&quot;css-exrw3m evys1bk0&quot;&gt;Apted paced the terrain of recollection; he never felt bound by archival chronology in the show — he had always loved Buñuel above all, and thought that the “Up” series’ desultory shuffle of the flashbacks mimicked the peregrinations of the unconscious — and now freely wandered the chambers of his memory. The excruciating time Tony admitted to adultery on camera. His anger with Charles, who dropped out after “21.” John, he felt, had never really trusted him; he supposed he might have been making fun of him a bit with the business of running him out with the hounds, but he’d always really liked him. Apted felt a strong reaction this time to the accordioned archives that began each segment. “To condense all that time to a hysterical pace — it’s terrifying, in sort of a bogus way, but it does dramatize how quickly things go by.” It gave him, he continued, “strange feelings about time and passage of time — it’s all so distorted.”&lt;/p&gt;
&lt;p class=&quot;css-exrw3m evys1bk0&quot;&gt;I asked him what he thought now of the maxim “Give me a child until he is 7, and I will give you the man.”&lt;/p&gt;
&lt;p class=&quot;css-exrw3m evys1bk0&quot;&gt;“It’s just a platitude,” he said, with little ceremony. “There’s no great wisdom. My two older boys, when I think back to how they were at 7, pretty much turned out how you’d expect — one serious, the other a jolly fellow, and they still are.” He stopped. “Well, the elder one died. But they stayed the same at heart. I don’t think it’s a particularly brilliant observation, frankly.&lt;/p&gt;
&lt;p class=&quot;css-exrw3m evys1bk0&quot;&gt;“This is my life, right in front of me,” he added — a life overlaid by 14 other, random lives, forever entwined with them, a life forever contoured in haunting outline by other people’s triumphs and other people’s pain. “My life is concentrated, the way it’s laid out now. ‘Seven Up!’ was the first serious piece of work I was involved with, and now it’s my whole working life in front of me.” He shielded his eyes from the sun. “I’m not going to be well enough to make another of these — it’s an irony that here are the bookends of my life. I might have 10 more years of sadness of not doing what I want, but there’s something beautiful about that — about having my life in that beautiful box.”&lt;/p&gt;
&lt;hr class=&quot;css-16zlh5b e1mu4ftr0&quot;/&gt;&lt;p class=&quot;css-l2wyn7 etfikam0&quot;&gt;&lt;strong class=&quot;css-8qgvsz ebyp5n10&quot;&gt;Gideon Lewis-Kraus&lt;/strong&gt; is a writer at large for the magazine. He last wrote &lt;a class=&quot;css-1g7m0tk&quot; href=&quot;https://www.nytimes.com/interactive/2019/02/21/magazine/wework-coworking-office-space.html&quot; title=&quot;&quot;&gt;about WeWork for the magazine’s Future of Work issue&lt;/a&gt;. &lt;strong class=&quot;css-8qgvsz ebyp5n10&quot;&gt;Dan Winters&lt;/strong&gt; is a photographer whose work has appeared in The New York Times Magazine since 1992. He is a World Press Photo recipient as well as an Alfred Eisenstadt Award winner.&lt;/p&gt;
&lt;p class=&quot;css-l2wyn7 etfikam0&quot;&gt;“Up” series photographs from BritBox, ITV/Shutterstock and YouTube. Photograph of young Apted from ITV/Shutterstock.&lt;/p&gt;
&lt;/div&gt;
&lt;aside class=&quot;css-ew4tgv&quot; aria-hidden=&quot;true&quot;/&gt;&lt;/div&gt;
</description>
<pubDate>Fri, 29 Nov 2019 11:51:52 +0000</pubDate>
<dc:creator>pseudolus</dc:creator>
<og:url>https://www.nytimes.com/2019/11/27/magazine/63-up-michael-apted.html</og:url>
<og:type>article</og:type>
<og:title>Does Who You Are at 7 Determine Who You Are at 63?</og:title>
<og:image>https://static01.nyt.com/images/2019/12/01/magazine/01MAG-APTEDPROMOSTILL/01MAG-APTEDPROMOSTILL-facebookJumbo-v2.png</og:image>
<og:description>In 1964, with “Seven Up!” Michael Apted stumbled into making what has become the most profound documentary series in the history of cinema. Fifty-five years later, the project is reaching its conclusion.</og:description>
<dc:language>en-US</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.nytimes.com/2019/11/27/magazine/63-up-michael-apted.html</dc:identifier>
</item>
<item>
<title>The first non-bullshit book about culture I&amp;#039;ve read</title>
<link>https://zwischenzugs.com/2019/11/27/the-first-non-bullshit-book-about-culture-ive-read/</link>
<guid isPermaLink="true" >https://zwischenzugs.com/2019/11/27/the-first-non-bullshit-book-about-culture-ive-read/</guid>
<description>&lt;p&gt;I’ve always been frustrated that people often talk about culture without giving actionable or realistic advice, and was previously prompted by this tweet to write about &lt;a href=&quot;https://zwischenzugs.com/2018/02/24/5-things-i-did-to-change-a-teams-culture/&quot;&gt;what I did&lt;/a&gt; when put in charge of a broken team:&lt;/p&gt;
&lt;div class=&quot;wp-block-image&quot;&gt;&lt;img src=&quot;https://zwischenzugs.files.wordpress.com/2018/02/charitymajorsontwitter.png&quot; alt=&quot;&quot;/&gt;&lt;/div&gt;
&lt;p&gt;Then the other week I met a change management type at a dinner who’d previously worked in manufacturing, and I asked him to recommend me some books. One of them was &lt;a href=&quot;https://www.amazon.co.uk/Turn-Ship-Around-Building-Breaking/dp/0241250943&quot;&gt;&lt;strong&gt;Turn the Ship Around&lt;/strong&gt;&lt;/a&gt; and it was exactly the book I wanted to read.&lt;/p&gt;
&lt;h2&gt;The Story&lt;/h2&gt;
&lt;p&gt;The book tells the story of David Marquet, newly-elevated commander of the &lt;strong&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/USS_Santa_Fe_%28SSN-763%29&quot;&gt;worst-performing nuclear submarine&lt;/a&gt;&lt;/strong&gt; in the US Navy. It was considered a basket case, and he was given it at the last moment, meaning his previous year’s meticulous preparation (for another ship) was for nought. He was under-prepared, and the odds were against him.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Within a year he’d turned it round&lt;/strong&gt; to be the best-performing, with the staff going on to bigger and better things, and the ship sustaining its newly-acquired status.&lt;/p&gt;
&lt;p&gt;Just the abstract blew my mind – it’s hard enough to turn around a group of IT types whose worst failure might be to lose some data. Never mind an &lt;em&gt;actual nuclear submarine&lt;/em&gt;, where &lt;strong&gt;as commander, you are &lt;em&gt;personally&lt;/em&gt; responsible for anything that goes wrong&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;I was greatly intrigued as to how he did it, and the book did not disappoint.&lt;/p&gt;
&lt;div class=&quot;wp-block-image&quot;&gt;&lt;img src=&quot;https://i0.wp.com/thearmyleader.co.uk/wp-content/uploads/2017/06/David-Marqet.png&quot; alt=&quot;&quot;/&gt;&lt;/div&gt;
&lt;h2&gt;What Marquet Did&lt;/h2&gt;
&lt;p&gt;By his own account, what Marquet did was improvise. Faced with the constraints he had on delivering any improvement, given:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;The poor state of crew morale on arrival&lt;/li&gt;
&lt;li&gt;His relative lack of knowledge about the ship itself&lt;/li&gt;
&lt;li&gt;The lack of time available to show an improvement&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;he had little option but either to: fail to make a significant improvement and ‘get by’ with the traditional management techniques, or do something drastic.&lt;/p&gt;
&lt;p&gt;As he explains, his drastic course of action was to &lt;strong&gt;overthrow the principle of commander-control&lt;/strong&gt; the US navy had assumed to be the best form of management for generations. The US navy’s traditional approach had been to give the commander absolute authority and responsibility on a ship. This resulted in what Marquet calls a ‘leader-follower’ mentality, which in many ways is a great way to run things.&lt;/p&gt;
&lt;p&gt;With good discipline (something the services excel at training for) and a highly trained leader, you can get good results, especially in a safety-critical environment. You can also get a demotivated, reactive, apathetic crew who develop a culture that focusses on ‘doing the minimum’. When the culture is broken, it’s hard to change this by simply shouting at the crew louder or doubling down on discipline.&lt;/p&gt;
&lt;h4&gt;Leader-Follower to Leader-Leader&lt;/h4&gt;
&lt;p&gt;Marquet sought to &lt;strong&gt;replace the leader-follower culture with a leader-leader one&lt;/strong&gt;. Since Marquet didn’t even fully understand his own ship, he had to delegate authority and responsibility down the ship’s command structure.&lt;/p&gt;
&lt;p&gt;This is brought home to him dramatically when he issues an order that was impossible to fulfil. He issues an order to a navigator to move the ship at a certain speed. He hears an ‘Aye, aye, sir!’, and then moments later wonders why his order doesn’t seem to have been followed. It turns out the ship he is on literally cannot move at that speed!&lt;/p&gt;
&lt;p&gt;This impresses on him that he has to do two things:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;Abandon the pretence of his own omniscience&lt;/li&gt;
&lt;li&gt;Encourage his staff to feed back information to him&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;In other words, he has to ‘&lt;strong&gt;give control&lt;/strong&gt;‘ to his crew &lt;strong&gt;without endangering&lt;/strong&gt; the world in the process. The book discusses how he achieves this, and gives some retrospective structure to his actions that make it easier to apply his experience to different environments where culture needs to be changed.&lt;/p&gt;
&lt;h2&gt;What Makes This Book So Different?&lt;/h2&gt;
&lt;h4&gt;It’s Credible&lt;/h4&gt;
&lt;p&gt;Morquand talks not only about what he did, but his concerns about his actions as he carried them out. For example, he describes how when he made chiefs responsible for signing off leave (and removed several layers of bureaucracy in the process), he worried that they would misuse their new power, or just make mistakes he himself would not make.&lt;/p&gt;
&lt;p&gt;In fact, these fears turned out to be unfounded, and by that action, he demonstrated that he wanted to make real change to the way the ship worked. This ceding of control had far more effect, he says, than any exhortation from above to more proactivity or responsibility from his underlings. He argues that such exhortations don’t work, as &lt;strong&gt;people don’t take words anywhere near as seriously as actions&lt;/strong&gt; when making change.&lt;/p&gt;
&lt;p&gt;Anyone who’s undergone any kind of corporate transformation effort when on the rank and file will know the difference between words and actions.&lt;/p&gt;
&lt;h4&gt;It’s Actionable&lt;/h4&gt;
&lt;p&gt;Far from offering vague advice, Marquet goes to the level of supplying specific sets of questions to put to your staff in meetings, and &lt;strong&gt;useful advice&lt;/strong&gt; on how to implement the policies and encourage the behaviours you need in your team.&lt;/p&gt;
&lt;p&gt;Early on in the process he uses a &lt;a href=&quot;https://www.nhs.uk/conditions/cognitive-behavioural-therapy-cbt/&quot;&gt;CBT&lt;/a&gt;-style technique of ‘act as though we are proud of the ship’ to kick-start the change he wants to see. Literally anyone in a leadership role looking to improve morale can implement something like that quickly.&lt;/p&gt;
&lt;hr class=&quot;wp-block-separator&quot;/&gt;&lt;p class=&quot;has-text-align-center&quot;&gt;&lt;em&gt;&lt;strong&gt;If you like this, you might like one of my books:&lt;br/&gt;&lt;a href=&quot;https://leanpub.com/learnbashthehardway?p=4369&quot;&gt;Learn Bash the Hard Way&lt;/a&gt;&lt;/strong&gt;&lt;/em&gt;&lt;br/&gt;&lt;em&gt;&lt;strong&gt;&lt;a href=&quot;https://leanpub.com/learngitthehardway?p=4369&quot;&gt;Learn Git the Hard Way&lt;/a&gt;&lt;/strong&gt;&lt;/em&gt;&lt;br/&gt;&lt;em&gt;&lt;strong&gt;&lt;a href=&quot;https://leanpub.com/learnterraformthehardway&quot;&gt;Learn Terraform the Hard Way&lt;/a&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;
&lt;div class=&quot;wp-block-image&quot;&gt;&lt;a href=&quot;https://leanpub.com/b/learngitbashandterraformthehardway&quot;&gt;&lt;img data-attachment-id=&quot;4450&quot; data-permalink=&quot;https://zwischenzugs.com/2018/08/06/anatomy-of-a-linux-dns-lookup-part-iv/learngitbashandterraformthehardway/&quot; data-orig-file=&quot;https://zwischenzugs.files.wordpress.com/2018/08/learngitbashandterraformthehardway.png&quot; data-orig-size=&quot;563,356&quot; data-comments-opened=&quot;1&quot; data-image-meta=&quot;{&amp;quot;aperture&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;credit&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;camera&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;caption&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;created_timestamp&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;copyright&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;focal_length&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;iso&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;shutter_speed&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;title&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;orientation&amp;quot;:&amp;quot;0&amp;quot;}&quot; data-image-title=&quot;LearnGitBashandTerraformtheHardWay&quot; data-image-description=&quot;&quot; data-medium-file=&quot;https://zwischenzugs.files.wordpress.com/2018/08/learngitbashandterraformthehardway.png?w=300&quot; data-large-file=&quot;https://zwischenzugs.files.wordpress.com/2018/08/learngitbashandterraformthehardway.png?w=563&quot; src=&quot;https://zwischenzugs.files.wordpress.com/2018/08/learngitbashandterraformthehardway.png?w=357&amp;amp;h=225&quot; alt=&quot;LearnGitBashandTerraformtheHardWay&quot; class=&quot;wp-image-4450&quot; srcset=&quot;https://zwischenzugs.files.wordpress.com/2018/08/learngitbashandterraformthehardway.png?w=357&amp;amp;h=225 357w, https://zwischenzugs.files.wordpress.com/2018/08/learngitbashandterraformthehardway.png?w=150&amp;amp;h=95 150w, https://zwischenzugs.files.wordpress.com/2018/08/learngitbashandterraformthehardway.png?w=300&amp;amp;h=190 300w, https://zwischenzugs.files.wordpress.com/2018/08/learngitbashandterraformthehardway.png 563w&quot; sizes=&quot;(max-width: 357px) 100vw, 357px&quot;/&gt;&lt;/a&gt;&lt;/div&gt;
&lt;div class=&quot;wp-block-image&quot;&gt;&lt;a href=&quot;https://www.manning.com/books/docker-in-practice-second-edition?a_aid=zwischenzugs&amp;amp;a_bid=550032fc&quot;&gt;&lt;img data-attachment-id=&quot;2590&quot; data-permalink=&quot;https://zwischenzugs.com/2017/03/04/1-minute-multi-node-vm-setup/eda41-0v9jkbliyi3uzefqq/&quot; data-orig-file=&quot;https://zwischenzugs.files.wordpress.com/2017/03/eda41-0v9jkbliyi3uzefqq.jpg&quot; data-orig-size=&quot;319,400&quot; data-comments-opened=&quot;1&quot; data-image-meta=&quot;{&amp;quot;aperture&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;credit&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;camera&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;caption&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;created_timestamp&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;copyright&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;focal_length&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;iso&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;shutter_speed&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;title&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;orientation&amp;quot;:&amp;quot;0&amp;quot;}&quot; data-image-title=&quot;eda41-0v9jkbliyi3uzefqq&quot; data-image-description=&quot;&quot; data-medium-file=&quot;https://zwischenzugs.files.wordpress.com/2017/03/eda41-0v9jkbliyi3uzefqq.jpg?w=239&quot; data-large-file=&quot;https://zwischenzugs.files.wordpress.com/2017/03/eda41-0v9jkbliyi3uzefqq.jpg?w=319&quot; src=&quot;https://zwischenzugs.files.wordpress.com/2017/03/eda41-0v9jkbliyi3uzefqq.jpg?w=220&amp;amp;h=276&quot; alt=&quot;&quot; class=&quot;wp-image-2590&quot; srcset=&quot;https://zwischenzugs.files.wordpress.com/2017/03/eda41-0v9jkbliyi3uzefqq.jpg?w=220&amp;amp;h=276 220w, https://zwischenzugs.files.wordpress.com/2017/03/eda41-0v9jkbliyi3uzefqq.jpg?w=120&amp;amp;h=150 120w, https://zwischenzugs.files.wordpress.com/2017/03/eda41-0v9jkbliyi3uzefqq.jpg?w=239&amp;amp;h=300 239w, https://zwischenzugs.files.wordpress.com/2017/03/eda41-0v9jkbliyi3uzefqq.jpg 319w&quot; sizes=&quot;(max-width: 220px) 100vw, 220px&quot;/&gt;&lt;/a&gt;&lt;/div&gt;
&lt;p class=&quot;has-text-align-center&quot;&gt;&lt;strong&gt;&lt;em&gt;&lt;a href=&quot;https://www.manning.com/books/docker-in-practice-second-edition?a_aid=zwischenzugs&amp;amp;a_bid=550032fc&quot;&gt;Get 39% off Docker in Practice with the code: 39miell2&lt;/a&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;hr class=&quot;wp-block-separator&quot;/&gt;&lt;h4&gt;It’s Honest&lt;/h4&gt;
&lt;p&gt;There’s very little sense of Marquet trying to sell a ‘perfect world’ story as he tells you what happened. In one vivid section, a normally dependable officer goes AWOL halfway through the year, and Marquet has to track him down. Marquet then takes the massive risk of letting the officer off, which further risks losing the respect of some of his subordinates, some of whom are hard-liners on discipline. None of this sounds like fun, or clear-cut.&lt;/p&gt;
&lt;p&gt;In another section, he describes how an officer ‘just forgot’ about not flicking a switch even though there was a standard ‘red tag’ on it signalling that it shouldn’t be touched. Again, &lt;strong&gt;rather than just punishing, he spent &lt;em&gt;8 hours&lt;/em&gt; discussing with his team&lt;/strong&gt; how they can prevent a recurrence in a practical way.&lt;/p&gt;
&lt;p&gt;After rejecting impractical solutions like ‘get sign off for every action from a superior’ their solution &lt;strong&gt;reduced mistakes&lt;/strong&gt; like this massively. The solution was another implementable tactic: &lt;strong&gt;‘deliberate action’&lt;/strong&gt;. Staff were required to call out what they are about to do, then pause before they do it, allowing others to intervene, while giving them literal pause for thought to correct their own mistakes.&lt;/p&gt;
&lt;h4&gt;It’s Well-Structured&lt;/h4&gt;
&lt;p&gt;The book ends up having a schema that is useful, and (mercifully) is not presented as a marketable framework, and which follows naturally from the story:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;He wants to give people control&lt;/li&gt;
&lt;li&gt;He can’t do that because: 1) they lack competence, and 2) they don’t know the broader context&lt;/li&gt;
&lt;li&gt;He gives control piece by piece, while working on 1) and 2) using various replicable techniques&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;Some of the techniques Marquet uses to achieve the competence and knowledge of context have been covered, but essentially &lt;strong&gt;he’s in a constant state of training everyone&lt;/strong&gt; to be leaders rather than followers within their roles.&lt;/p&gt;
&lt;p&gt;Some highlighted techniques:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;Encourage staff to ask for permission (‘I intend to […] because’) rather than wait for orders&lt;/li&gt;
&lt;li&gt;Don’t ‘brief’ people on upcoming tasks, ‘certify’ (give them their role, ask them to study, and test them on their competence)&lt;/li&gt;
&lt;li&gt;Creation of a creed (yes, a kind of ‘mission statement’, but one that’s in Q&amp;amp;A form and is also specific and actionable)&lt;/li&gt;
&lt;li&gt;Specify goals, not methods&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;All of this makes it very easy to apply these teachings to your own environment where needed.&lt;/p&gt;
&lt;h2&gt;Caveats&lt;/h2&gt;
&lt;p&gt;Despite my enthusiasm, I was left with a few question marks in my mind about the story.&lt;/p&gt;
&lt;p&gt;The first is that Marquet seems to have had great latitude to break the rules (indeed the subtitle of the book is ‘A True Story of Building Leaders by Breaking the Rules’). His superiors explicitly told him they were more focussed on outcomes than methods. This freedom isn’t necessarily available to everyone. Or maybe one of the points of the books is that &lt;strong&gt;to lead effectively you have to be prepared to ‘go rogue’ to some extent&lt;/strong&gt; and take risks to effect real changes?&lt;/p&gt;
&lt;p&gt;Another aspect I wondered about was that I suspected Marquet started from a point where he had &lt;strong&gt;a workforce that were very strong in one particular direction: following orders&lt;/strong&gt;, and that it’s easier to turn such people around than a group of people who are not trained to follow orders so well. Or maybe it’s harder, who knows?&lt;/p&gt;
&lt;p&gt;Also, the &lt;strong&gt;ship was at rock bottom&lt;/strong&gt; in terms of morale and performance, and everyone on board knew it. So there was a crisis that needed to be tackled. This made making change easier, as his direct subordinates were prepared to make changes to achieve better things (and get promotion themselves).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;This makes me wonder whether a good way to make needed change as a leader when there is no obvious crisis is to artificially create one so that people get on board…&lt;/strong&gt;&lt;/p&gt;
&lt;div id=&quot;jp-post-flair&quot; class=&quot;sharedaddy sd-like-enabled sd-sharing-enabled&quot;&gt;
&lt;div class=&quot;sharedaddy sd-sharing-enabled&quot;&gt;
&lt;div class=&quot;robots-nocontent sd-block sd-social sd-social-official sd-sharing&quot;&gt;
&lt;h3 class=&quot;sd-title&quot;&gt;Share this:&lt;/h3&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sharedaddy sd-block sd-like jetpack-likes-widget-wrapper jetpack-likes-widget-unloaded&quot; id=&quot;like-post-wrapper-20870870-4817-5de1bf11addda&quot; data-src=&quot;//widgets.wp.com/likes/index.html?ver=20190321#blog_id=20870870&amp;amp;post_id=4817&amp;amp;origin=zwischenzugs.wordpress.com&amp;amp;obj_id=20870870-4817-5de1bf11addda&amp;amp;domain=zwischenzugs.com&quot; data-name=&quot;like-post-frame-20870870-4817-5de1bf11addda&quot;&gt;
&lt;h3 class=&quot;sd-title&quot;&gt;Like this:&lt;/h3&gt;
&lt;div class=&quot;likes-widget-placeholder post-likes-widget-placeholder&quot;&gt;&lt;span class=&quot;button&quot;&gt;&lt;span&gt;Like&lt;/span&gt;&lt;/span&gt; &lt;span class=&quot;loading&quot;&gt;Loading...&lt;/span&gt;&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
</description>
<pubDate>Fri, 29 Nov 2019 08:25:04 +0000</pubDate>
<dc:creator>zwischenzug</dc:creator>
<og:type>article</og:type>
<og:title>The First Non-Bullshit Book About Culture I’ve Read</og:title>
<og:url>https://zwischenzugs.com/2019/11/27/the-first-non-bullshit-book-about-culture-ive-read/</og:url>
<og:description>I’ve always been frustrated that people often talk about culture without giving actionable or realistic advice, and was previously prompted by this tweet to write about what I did when put in…</og:description>
<og:image>https://zwischenzugs.files.wordpress.com/2017/03/eda41-0v9jkbliyi3uzefqq.jpg</og:image>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://zwischenzugs.com/2019/11/27/the-first-non-bullshit-book-about-culture-ive-read/</dc:identifier>
</item>
<item>
<title>Matrix Calculus for Deep Learning</title>
<link>https://explained.ai/matrix-calculus/index.html</link>
<guid isPermaLink="true" >https://explained.ai/matrix-calculus/index.html</guid>
<description>&lt;head&gt;&lt;meta http-equiv=&quot;Content-Type&quot; content=&quot;text/html; charset=UTF-8&quot; /&gt;&lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1&quot; /&gt;&lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;https://fonts.googleapis.com/css?family=Merriweather:300,700,700italic,300italic|Open+Sans:700,400&quot; /&gt;&lt;title&gt;The matrix calculus you need for deep learning&lt;/title&gt;&lt;meta property=&quot;og:title&quot; content=&quot;The matrix calculus you need for deep learning&quot; /&gt;&lt;meta property=&quot;og:image&quot; content=&quot;https://explained.ai/matrix-calculus/images/neuron.png&quot; /&gt;&lt;meta property=&quot;og:description&quot; content=&quot;Most of us last saw calculus in school, but derivatives are a critical part of machine learning, particularly deep neural networks, which are trained by optimizing a loss function. This article is an attempt to explain all the matrix calculus you need in order to understand the training of deep neural networks. We assume no math knowledge beyond what you learned in calculus 1, and provide links to help you refresh the necessary math where needed.&quot; /&gt;&lt;meta property=&quot;og:url&quot; content=&quot;https://explained.ai/matrix-calculus/index.html&quot; /&gt;&lt;meta property=&quot;og:type&quot; content=&quot;article&quot; /&gt;&lt;meta name=&quot;twitter:title&quot; content=&quot;The matrix calculus you need for deep learning&quot; /&gt;&lt;meta name=&quot;twitter:card&quot; content=&quot;summary_large_image&quot; /&gt;&lt;meta name=&quot;twitter:site&quot; content=&quot;@the_antlr_guy&quot; /&gt;&lt;meta name=&quot;twitter:creator&quot; content=&quot;@the_antlr_guy&quot; /&gt;&lt;meta name=&quot;twitter:description&quot; content=&quot;Most of us last saw calculus in school, but derivatives are a critical part of machine learning, particularly deep neural networks, which are trained by optimizing a loss function. This article is an attempt to explain all the matrix calculus you need in order to understand the training of deep neural networks. We assume no math knowledge beyond what you learned in calculus 1, and provide links to help you refresh the necessary math where needed.&quot; /&gt;&lt;meta name=&quot;twitter:image&quot; content=&quot;https://explained.ai/matrix-calculus/images/neuron.png&quot; /&gt;&lt;/head&gt;&lt;body id=&quot;readabilityBody&quot; readability=&quot;1031.8839785493&quot;&gt;



&lt;p&gt;&lt;a href=&quot;http://parrt.cs.usfca.edu&quot;&gt;Terence Parr&lt;/a&gt; and &lt;a href=&quot;http://www.fast.ai/about/#jeremy&quot;&gt;Jeremy Howard&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;(We teach in University of San Francisco's &lt;a href=&quot;https://www.usfca.edu/arts-sciences/graduate-programs/data-science&quot;&gt;MS in Data Science program&lt;/a&gt; and have other nefarious projects underway. You might know Terence as the creator of the &lt;a href=&quot;http://www.antlr.org&quot;&gt;ANTLR parser generator&lt;/a&gt;. For more material, see Jeremy's &lt;a href=&quot;http://course.fast.ai&quot;&gt;fast.ai courses&lt;/a&gt; and University of San Francisco's Data Institute &lt;a href=&quot;https://www.usfca.edu/data-institute/certificates/deep-learning-part-one&quot;&gt;in-person version of the deep learning course&lt;/a&gt;.)&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/1802.01528&quot; onclick=&quot;gtag('event', 'download', { 'video_title': 'PDF version', 'non_interaction': true });&quot;&gt;Printable version&lt;/a&gt; (This HTML was generated from markup using &lt;a href=&quot;https://github.com/parrt/bookish&quot; onclick=&quot;gtag('event', 'bookish', { 'video_title': 'bookish', 'non_interaction': true });&quot;&gt;bookish&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Abstract&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;This paper is an attempt to explain all the matrix calculus you need in order to understand the training of deep neural networks. We assume no math knowledge beyond what you learned in calculus 1, and provide links to help you refresh the necessary math where needed. Note that you do &lt;strong&gt;not&lt;/strong&gt; need to understand this material before you start learning to train and use deep learning in practice; rather, this material is for those who are already familiar with the basics of neural networks, and wish to deepen their understanding of the underlying math. Don't worry if you get stuck at some point along the way---just go back and reread the previous section, and try writing down and working through some examples. And if you're still stuck, we're happy to answer your questions in the &lt;a href=&quot;http://forums.fast.ai/c/theory&quot;&gt;Theory category at forums.fast.ai&lt;/a&gt;. &lt;strong&gt;Note&lt;/strong&gt;: There is a &lt;a href=&quot;https://explained.ai/matrix-calculus/index.html#reference&quot;&gt;reference section&lt;/a&gt; at the end of the paper summarizing all the key matrix calculus rules and terminology discussed here.&lt;/p&gt;

&lt;h2 id=&quot;intro&quot;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Most of us last saw calculus in school, but derivatives are a critical part of machine learning, particularly deep neural networks, which are trained by optimizing a loss function. Pick up a machine learning paper or the documentation of a library such as &lt;a href=&quot;http://pytorch.org&quot;&gt;PyTorch&lt;/a&gt; and calculus comes screeching back into your life like distant relatives around the holidays. And it's not just any old scalar calculus that pops up---you need differential &lt;em&gt;matrix calculus&lt;/em&gt;, the shotgun wedding of &lt;a href=&quot;https://en.wikipedia.org/wiki/Linear_algebra&quot;&gt;linear algebra&lt;/a&gt; and &lt;a href=&quot;https://en.wikipedia.org/wiki/Multivariable_calculus&quot;&gt;multivariate calculus&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Well... maybe &lt;em&gt;need&lt;/em&gt; isn't the right word; Jeremy's courses show how to become a world-class deep learning practitioner with only a minimal level of scalar calculus, thanks to leveraging the automatic differentiation built in to modern deep learning libraries. But if you really want to really understand what's going on under the hood of these libraries, and grok academic papers discussing the latest advances in model training techniques, you'll need to understand certain bits of the field of matrix calculus.&lt;/p&gt;
&lt;p&gt;For example, the activation of a single computation unit in a neural network is typically calculated using the dot product (from linear algebra) of an edge weight vector &lt;span class=&quot;eqnvec&quot;&gt;w&lt;/span&gt; with an input vector &lt;span class=&quot;eqnvec&quot;&gt;x&lt;/span&gt; plus a scalar bias (threshold): &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-EEDCFA4252D0992243A283CE0EB777A6-depth003.31.svg&quot; /&gt;. Function &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-C599D931407509E0FA08F8686B205B6D-depth003.25.svg&quot; /&gt; is called the unit's &lt;em&gt;affine function&lt;/em&gt; and is followed by a &lt;a href=&quot;https://goo.gl/7BXceK&quot;&gt;rectified linear unit&lt;/a&gt;, which clips negative values to zero: &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-66258AA93A4746DA10D306190271DE4B-depth003.25.svg&quot; /&gt;. Such a computational unit is sometimes referred to as an “artificial neuron” and looks like:&lt;/p&gt;
&lt;center&gt;
&lt;p&gt;&lt;img src=&quot;https://explained.ai/matrix-calculus/images/neuron.png&quot; alt=&quot;neuron.png&quot; width=&quot;250&quot; /&gt;&lt;/p&gt;
&lt;/center&gt;
&lt;p&gt;Neural networks consist of many of these units, organized into multiple collections of neurons called &lt;em&gt;layers&lt;/em&gt;. The activation of one layer's units become the input to the next layer's units. The activation of the unit or units in the final layer is called the network output.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Training&lt;/em&gt; this neuron means choosing weights &lt;span class=&quot;eqnvec&quot;&gt;w&lt;/span&gt; and bias &lt;span class=&quot;eqn&quot;&gt;b&lt;/span&gt; so that we get the desired output for all &lt;span class=&quot;eqn&quot;&gt;N&lt;/span&gt; inputs &lt;span class=&quot;eqnvec&quot;&gt;x&lt;/span&gt;. To do that, we minimize a &lt;em&gt;loss function&lt;/em&gt; that compares the network's final &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-7971D42A6C6C6A28D6443F0645E4A036-depth003.25.svg&quot; /&gt; with the &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-E146B831A1E53B95E4C63775285D62CF-depth003.25.svg&quot; /&gt; (desired output of &lt;span class=&quot;eqnvec&quot;&gt;x&lt;/span&gt;) for all input &lt;span class=&quot;eqnvec&quot;&gt;x&lt;/span&gt; vectors. To minimize the loss, we use some variation on gradient descent, such as plain &lt;a href=&quot;https://en.wikipedia.org/wiki/Stochastic_gradient_descent&quot;&gt;stochastic gradient descent&lt;/a&gt; (SGD), SGD with momentum, or &lt;a href=&quot;https://en.wikipedia.org/wiki/Stochastic_gradient_descent#Adam&quot;&gt;Adam&lt;/a&gt;. All of those require the partial derivative (the gradient) of &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-7971D42A6C6C6A28D6443F0645E4A036-depth003.25.svg&quot; /&gt; with respect to the model parameters &lt;span class=&quot;eqnvec&quot;&gt;w&lt;/span&gt; and &lt;span class=&quot;eqn&quot;&gt;b&lt;/span&gt;. Our goal is to gradually tweak &lt;span class=&quot;eqnvec&quot;&gt;w&lt;/span&gt; and &lt;span class=&quot;eqn&quot;&gt;b&lt;/span&gt; so that the overall loss function keeps getting smaller across all &lt;span class=&quot;eqnvec&quot;&gt;x&lt;/span&gt; inputs.&lt;/p&gt;
&lt;p&gt;If we're careful, we can derive the gradient by differentiating the scalar version of a common loss function (mean squared error):&lt;/p&gt;
&lt;div&gt;&lt;img class=&quot;blkeqn&quot; src=&quot;https://explained.ai/matrix-calculus/images/blkeqn-A129949CD1EF7BE2CA8BD424D34F9930.svg&quot; alt=&quot;&quot; /&gt;&lt;/div&gt;
&lt;p&gt;But this is just one neuron, and neural networks must train the weights and biases of all neurons in all layers simultaneously. Because there are multiple inputs and (potentially) multiple network outputs, we really need general rules for the derivative of a function with respect to a vector and even rules for the derivative of a vector-valued function with respect to a vector.&lt;/p&gt;
&lt;p&gt;This article walks through the derivation of some important rules for computing partial derivatives with respect to vectors, particularly those useful for training neural networks. This field is known as &lt;em&gt;matrix calculus&lt;/em&gt;, and the good news is, we only need a small subset of that field, which we introduce here. While there is a lot of online material on multivariate calculus and linear algebra, they are typically taught as two separate undergraduate courses so most material treats them in isolation. The pages that do discuss matrix calculus often are really just lists of rules with minimal explanation or are just pieces of the story. They also tend to be quite obscure to all but a narrow audience of mathematicians, thanks to their use of dense notation and minimal discussion of foundational concepts. (See the annotated list of resources at the end.)&lt;/p&gt;
&lt;p&gt;In contrast, we're going to rederive and rediscover some key matrix calculus rules in an effort to explain them. It turns out that matrix calculus is really not that hard! There aren't dozens of new rules to learn; just a couple of key concepts. Our hope is that this short paper will get you started quickly in the world of matrix calculus as it relates to training neural networks. We're assuming you're already familiar with the basics of neural network architecture and training. If you're not, head over to &lt;a href=&quot;http://course.fast.ai&quot;&gt;Jeremy's course&lt;/a&gt; and complete part 1 of that, then we'll see you back here when you're done. (Note that, unlike many more academic approaches, we strongly suggest &lt;em&gt;first&lt;/em&gt; learning to train and use neural networks in practice and &lt;em&gt;then&lt;/em&gt; study the underlying math. The math will be much more understandable with the context in place; besides, it's not necessary to grok all this calculus to become an effective practitioner.)&lt;/p&gt;
&lt;p&gt;&lt;em&gt;A note on notation&lt;/em&gt;: Jeremy's course exclusively uses code, instead of math notation, to explain concepts since unfamiliar functions in code are easy to search for and experiment with. In this paper, we do the opposite: there is a lot of math notation because one of the goals of this paper is to help you understand the notation that you'll see in deep learning papers and books. At the &lt;a href=&quot;https://explained.ai/matrix-calculus/index.html#notation&quot;&gt;end of the paper&lt;/a&gt;, you'll find a brief table of the notation used, including a word or phrase you can use to search for more details.&lt;/p&gt;
&lt;h2 id=&quot;sec2&quot;&gt;Review: Scalar derivative rules&lt;/h2&gt;
&lt;p&gt;Hopefully you remember some of these main scalar derivative rules. If your memory is a bit fuzzy on this, have a look at &lt;a href=&quot;https://www.khanacademy.org/math/ap-calculus-ab/ab-derivative-rules&quot;&gt;Khan academy vid on scalar derivative rules&lt;/a&gt;.&lt;/p&gt;
&lt;center&gt;
&lt;/center&gt;
&lt;p&gt;There are other rules for trigonometry, exponentials, etc., which you can find at &lt;a href=&quot;https://www.khanacademy.org/math/differential-calculus&quot;&gt;Khan Academy differential calculus course&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;When a function has a single parameter, &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-50BBD36E1FD2333108437A2CA378BE62-depth003.25.svg&quot; /&gt;, you'll often see &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-6BDA8AF54C40BC23ED858E9E9F5C11D2-depth002.72.svg&quot; /&gt; and &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-74CAF4D1EC90D3A36EA7C7BBFE65B516-depth003.25.svg&quot; /&gt; used as shorthands for &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-5BA9D16419154B1BDBECA39D99E8E809-depth004.58.svg&quot; /&gt;. We recommend against this notation as it does not make clear the variable we're taking the derivative with respect to.&lt;/p&gt;
&lt;p&gt;You can think of &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-624FEBB9A49A3FC96353C861D175C806-depth004.58.svg&quot; /&gt; as an operator that maps a function of one parameter to another function. That means that &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-EC0CEC5F9488EC510F8D688E7003222D-depth004.58.svg&quot; /&gt; maps &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-50BBD36E1FD2333108437A2CA378BE62-depth003.25.svg&quot; /&gt; to its derivative with respect to &lt;span class=&quot;eqn&quot;&gt;x&lt;/span&gt;, which is the same thing as &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-07A5EA519C4CEA1A3539E3A7FC289163-depth004.58.svg&quot; /&gt;. Also, if &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-FD91C508F91C2C84498680BD337C1D7A-depth003.25.svg&quot; /&gt;, then &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-B1ED3CF9BA4D6F25A5A4F481C45EC658-depth004.58.svg&quot; /&gt;. Thinking of the derivative as an operator helps to simplify complicated derivatives because the operator is distributive and lets us pull out constants. For example, in the following equation, we can pull out the constant 9 and distribute the derivative operator across the elements within the parentheses.&lt;/p&gt;
&lt;div&gt;&lt;img class=&quot;blkeqn&quot; src=&quot;https://explained.ai/matrix-calculus/images/blkeqn-A1EC7F214318E08949CC8BFCED138D94.svg&quot; alt=&quot;&quot; /&gt;&lt;/div&gt;
&lt;p&gt;That procedure reduced the derivative of &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-FDFD125C741CD062B2CA779DDE0524BE-depth003.25.svg&quot; /&gt; to a bit of arithmetic and the derivatives of &lt;span class=&quot;eqn&quot;&gt;x&lt;/span&gt; and &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-32F5240D0DBF2CCBE75EF7F8EF2015E0-depth000.14.svg&quot; /&gt;, which are much easier to solve than the original derivative.&lt;/p&gt;
&lt;h2 id=&quot;sec3&quot;&gt;Introduction to vector calculus and partial derivatives&lt;/h2&gt;
&lt;p&gt;Neural network layers are not single functions of a single parameter, &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-50BBD36E1FD2333108437A2CA378BE62-depth003.25.svg&quot; /&gt;. So, let's move on to functions of multiple parameters such as &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-3BAF1600AE50930A155F58AE172B51BD-depth003.25.svg&quot; /&gt;. For example, what is the derivative of &lt;span class=&quot;eqn&quot;&gt;xy&lt;/span&gt; (i.e., the multiplication of &lt;span class=&quot;eqn&quot;&gt;x&lt;/span&gt; and &lt;span class=&quot;eqn&quot;&gt;y&lt;/span&gt;)? In other words, how does the product &lt;span class=&quot;eqn&quot;&gt;xy&lt;/span&gt; change when we wiggle the variables? Well, it depends on whether we are changing &lt;span class=&quot;eqn&quot;&gt;x&lt;/span&gt; or &lt;span class=&quot;eqn&quot;&gt;y&lt;/span&gt;. We compute derivatives with respect to one variable (parameter) at a time, giving us two different &lt;em&gt;partial derivatives&lt;/em&gt; for this two-parameter function (one for &lt;span class=&quot;eqn&quot;&gt;x&lt;/span&gt; and one for &lt;span class=&quot;eqn&quot;&gt;y&lt;/span&gt;). Instead of using operator &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-624FEBB9A49A3FC96353C861D175C806-depth004.58.svg&quot; /&gt;, the partial derivative operator is &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-4D6C379F66675645B3FFE28A15306857-depth004.67.svg&quot; /&gt; (a stylized &lt;span class=&quot;eqn&quot;&gt;d&lt;/span&gt; and not the Greek letter &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-77A3B715842B45E440A5BEE15357AD29-depth000.22.svg&quot; /&gt;). So, &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-08DCCFBE629A14FCCD9FB9A20F2E367C-depth004.67.svg&quot; /&gt; and &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-1FDCF7A9F137AE48FA25EE34A69F8201-depth006.34.svg&quot; /&gt; are the partial derivatives of &lt;span class=&quot;eqn&quot;&gt;xy&lt;/span&gt;; often, these are just called the &lt;em&gt;partials&lt;/em&gt;. For functions of a single parameter, operator &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-4D6C379F66675645B3FFE28A15306857-depth004.67.svg&quot; /&gt; is equivalent to &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-624FEBB9A49A3FC96353C861D175C806-depth004.58.svg&quot; /&gt; (for sufficiently smooth functions). However, it's better to use &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-624FEBB9A49A3FC96353C861D175C806-depth004.58.svg&quot; /&gt; to make it clear you're referring to a scalar derivative.&lt;/p&gt;
&lt;p&gt;The partial derivative with respect to &lt;span class=&quot;eqn&quot;&gt;x&lt;/span&gt; is just the usual scalar derivative, simply treating any other variable in the equation as a constant. Consider function &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-D6DEAE7E403381C2C425D4B40CCA936E-depth003.25.svg&quot; /&gt;. The partial derivative with respect to &lt;span class=&quot;eqn&quot;&gt;x&lt;/span&gt; is written &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-F063B8EC812DF3D204F9327F5D094073-depth004.67.svg&quot; /&gt;. There are three constants from the perspective of &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-4D6C379F66675645B3FFE28A15306857-depth004.67.svg&quot; /&gt;: 3, 2, and &lt;span class=&quot;eqn&quot;&gt;y&lt;/span&gt;. Therefore, &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-D981BA4BD14AC44C43A4E4E0EC750B4A-depth004.67.svg&quot; /&gt;. The partial derivative with respect to &lt;span class=&quot;eqn&quot;&gt;y&lt;/span&gt; treats &lt;span class=&quot;eqn&quot;&gt;x&lt;/span&gt; like a constant: &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-55A3A400FAD3326FEF1BB9DDD2658383-depth006.34.svg&quot; /&gt;. It's a good idea to derive these yourself before continuing otherwise the rest of the article won't make sense. Here's the &lt;a href=&quot;https://www.khanacademy.org/math/multivariable-calculus/multivariable-derivatives/partial-derivative-and-gradient-articles/a/introduction-to-partial-derivatives&quot;&gt;Khan Academy video on partials&lt;/a&gt; if you need help.&lt;/p&gt;
&lt;p&gt;To make it clear we are doing vector calculus and not just multivariate calculus, let's consider what we do with the partial derivatives &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-84D799755A7F73945BD58B2E057121AB-depth004.67.svg&quot; /&gt; and &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-A2DE2EC029172B84A0A0E8A8D00F5A6F-depth006.34.svg&quot; /&gt; (another way to say &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-75645E70B6C95F7466C353E9C2306FE0-depth004.67.svg&quot; /&gt; and &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-B20FF70C037320C2D0B710F4B592927E-depth006.34.svg&quot; /&gt;) that we computed for &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-D6DEAE7E403381C2C425D4B40CCA936E-depth003.25.svg&quot; /&gt;. Instead of having them just floating around and not organized in any way, let's organize them into a horizontal vector. We call this vector the &lt;em&gt;gradient&lt;/em&gt; of &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-3BAF1600AE50930A155F58AE172B51BD-depth003.25.svg&quot; /&gt; and write it as:&lt;/p&gt;
&lt;div&gt;&lt;img class=&quot;blkeqn&quot; src=&quot;https://explained.ai/matrix-calculus/images/blkeqn-0C95BB61B2BFFB0C2A95A9DC5D8AF44E.svg&quot; alt=&quot;&quot; /&gt;&lt;/div&gt;
&lt;p&gt;So the gradient of &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-3BAF1600AE50930A155F58AE172B51BD-depth003.25.svg&quot; /&gt; is simply a vector of its partials. Gradients are part of the vector calculus world, which deals with functions that map &lt;span class=&quot;eqn&quot;&gt;n&lt;/span&gt; scalar parameters to a single scalar. Now, let's get crazy and consider derivatives of multiple functions simultaneously.&lt;/p&gt;
&lt;h2 id=&quot;sec4&quot;&gt;Matrix calculus&lt;/h2&gt;
&lt;p&gt;When we move from derivatives of one function to derivatives of many functions, we move from the world of vector calculus to matrix calculus. Let's compute partial derivatives for two functions, both of which take two parameters. We can keep the same &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-D6DEAE7E403381C2C425D4B40CCA936E-depth003.25.svg&quot; /&gt; from the last section, but let's also bring in &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-D182AD2135D1E887AFFCA045F432B2CA-depth003.25.svg&quot; /&gt;. The gradient for &lt;span class=&quot;eqn&quot;&gt;g&lt;/span&gt; has two entries, a partial derivative for each parameter:&lt;/p&gt;
&lt;div&gt;&lt;img class=&quot;blkeqn&quot; src=&quot;https://explained.ai/matrix-calculus/images/blkeqn-FDB56AA8804E0D13E1555DB8E0E1AAEE.svg&quot; alt=&quot;&quot; /&gt;&lt;/div&gt;
&lt;p&gt;and&lt;/p&gt;
&lt;div&gt;&lt;img class=&quot;blkeqn&quot; src=&quot;https://explained.ai/matrix-calculus/images/blkeqn-13AF8214DD5A2040D650C7B460C88129.svg&quot; alt=&quot;&quot; /&gt;&lt;/div&gt;
&lt;p&gt;giving us gradient &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-E2670D9705180E731C7455A4B46B7AF6-depth003.25.svg&quot; /&gt;.&lt;/p&gt;
&lt;p&gt;Gradient vectors organize all of the partial derivatives for a specific scalar function. If we have two functions, we can also organize their gradients into a matrix by stacking the gradients. When we do so, we get the &lt;em&gt;Jacobian matrix&lt;/em&gt; (or just the &lt;em&gt;Jacobian&lt;/em&gt;) where the gradients are rows:&lt;/p&gt;
&lt;div&gt;&lt;img class=&quot;blkeqn&quot; src=&quot;https://explained.ai/matrix-calculus/images/blkeqn-B45AD8AF1574CD63AE6980B44770D643.svg&quot; alt=&quot;&quot; /&gt;&lt;/div&gt;
&lt;p&gt;Welcome to matrix calculus!&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Note that there are multiple ways to represent the Jacobian.&lt;/strong&gt; We are using the so-called &lt;a href=&quot;https://en.wikipedia.org/wiki/Matrix_calculus#Layout_conventions&quot;&gt;numerator layout&lt;/a&gt; but many papers and software will use the &lt;em&gt;denominator layout&lt;/em&gt;. This is just transpose of the numerator layout Jacobian (flip it around its diagonal):&lt;/p&gt;
&lt;div&gt;&lt;img class=&quot;blkeqn&quot; src=&quot;https://explained.ai/matrix-calculus/images/blkeqn-B5113497453A60E25E3241A14CC582C3.svg&quot; alt=&quot;&quot; /&gt;&lt;/div&gt;
&lt;h3 id=&quot;sec4.1&quot;&gt;Generalization of the Jacobian&lt;/h3&gt;
&lt;p&gt;So far, we've looked at a specific example of a Jacobian matrix. To define the Jacobian matrix more generally, let's combine multiple parameters into a single vector argument: &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-8C56090E55CDB76D1CD0E738EBA7F164-depth003.25.svg&quot; /&gt;. (You will sometimes see notation &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-B07B5ABD67EE0B72F4136C82C68A0C48-depth000.14.svg&quot; /&gt; for vectors in the literature as well.) Lowercase letters in bold font such as &lt;span class=&quot;eqnvec&quot;&gt;x&lt;/span&gt; are vectors and those in italics font like &lt;span class=&quot;eqn&quot;&gt;x&lt;/span&gt; are scalars. &lt;span class=&quot;eqn&quot;&gt;x&lt;sub&gt;i&lt;/sub&gt;&lt;/span&gt; is the &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-97361F12A3555FC4FC4E2FFCE1799AC3-depth000.14.svg&quot; /&gt; element of vector &lt;span class=&quot;eqnvec&quot;&gt;x&lt;/span&gt; and is in italics because a single vector element is a scalar. We also have to define an orientation for vector &lt;span class=&quot;eqnvec&quot;&gt;x&lt;/span&gt;. We'll assume that all vectors are vertical by default of size &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-88512AB12706879FEC83C0C3AA79931F-depth001.08.svg&quot; /&gt;:&lt;/p&gt;
&lt;div&gt;&lt;img class=&quot;blkeqn&quot; src=&quot;https://explained.ai/matrix-calculus/images/blkeqn-D76C868C669197F65B05E96473454834.svg&quot; alt=&quot;&quot; /&gt;&lt;/div&gt;
&lt;p&gt;With multiple scalar-valued functions, we can combine them all into a vector just like we did with the parameters. Let &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-A16203A31AD7C6CC63FD297D522170F1-depth003.25.svg&quot; /&gt; be a vector of &lt;span class=&quot;eqn&quot;&gt;m&lt;/span&gt; scalar-valued functions that each take a vector &lt;span class=&quot;eqnvec&quot;&gt;x&lt;/span&gt; of length &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-E3114C625CDDDC18ED29BA629242BD65-depth003.25.svg&quot; /&gt; where &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-DEA8E196A572D082201CD5ABF2FA82DE-depth003.25.svg&quot; /&gt; is the cardinality (count) of elements in &lt;span class=&quot;eqnvec&quot;&gt;x&lt;/span&gt;. Each &lt;span class=&quot;eqn&quot;&gt;f&lt;sub&gt;i&lt;/sub&gt;&lt;/span&gt; function within &lt;span class=&quot;eqnvec&quot;&gt;f&lt;/span&gt; returns a scalar just as in the previous section:&lt;/p&gt;
&lt;div&gt;&lt;img class=&quot;blkeqn&quot; src=&quot;https://explained.ai/matrix-calculus/images/blkeqn-CD6121D27CD89157BF272E5E50AE32FE.svg&quot; alt=&quot;&quot; /&gt;&lt;/div&gt;
&lt;p&gt;For instance, we'd represent &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-D6DEAE7E403381C2C425D4B40CCA936E-depth003.25.svg&quot; /&gt; and &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-D182AD2135D1E887AFFCA045F432B2CA-depth003.25.svg&quot; /&gt; from the last section as&lt;/p&gt;
&lt;div&gt;&lt;img class=&quot;blkeqn&quot; src=&quot;https://explained.ai/matrix-calculus/images/blkeqn-AB738ABA2B35F37C4A171037A396E5F5.svg&quot; alt=&quot;&quot; /&gt;&lt;/div&gt;
&lt;p&gt;It's very often the case that &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-A193EBC083B4745370F6F1343383D9CC-depth000.14.svg&quot; /&gt; because we will have a scalar function result for each element of the &lt;span class=&quot;eqnvec&quot;&gt;x&lt;/span&gt; vector. For example, consider the identity function &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-23225C9E5521B6A9777579BE4B92245C-depth003.25.svg&quot; /&gt;:&lt;/p&gt;
&lt;div&gt;&lt;img class=&quot;blkeqn&quot; src=&quot;https://explained.ai/matrix-calculus/images/blkeqn-4BAF672444FD71616154DE2BE79A5DD6.svg&quot; alt=&quot;&quot; /&gt;&lt;/div&gt;
&lt;p&gt;So we have &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-A193EBC083B4745370F6F1343383D9CC-depth000.14.svg&quot; /&gt; functions and parameters, in this case. Generally speaking, though, the Jacobian matrix is the collection of all &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-FBFEB9C8459FEE5A2BD529C07B881153-depth001.08.svg&quot; /&gt; possible partial derivatives (&lt;span class=&quot;eqn&quot;&gt;m&lt;/span&gt; rows and &lt;span class=&quot;eqn&quot;&gt;n&lt;/span&gt; columns), which is the stack of &lt;span class=&quot;eqn&quot;&gt;m&lt;/span&gt; gradients with respect to &lt;span class=&quot;eqnvec&quot;&gt;x&lt;/span&gt;:&lt;/p&gt;
&lt;div&gt;&lt;img class=&quot;blkeqn&quot; src=&quot;https://explained.ai/matrix-calculus/images/blkeqn-C6F45926C0FEAD3BD359AA24A7FB23A2.svg&quot; alt=&quot;&quot; /&gt;&lt;/div&gt;
&lt;p&gt;Each &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-98F52E62B85A836D750F1CEDF32E1D68-depth004.67.svg&quot; /&gt; is a horizontal &lt;span class=&quot;eqn&quot;&gt;n&lt;/span&gt;-vector because the partial derivative is with respect to a vector, &lt;span class=&quot;eqnvec&quot;&gt;x&lt;/span&gt;, whose length is &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-A921357AFE67E47CC9D1DB575BCE1B77-depth003.25.svg&quot; /&gt;. The width of the Jacobian is &lt;span class=&quot;eqn&quot;&gt;n&lt;/span&gt; if we're taking the partial derivative with respect to &lt;span class=&quot;eqnvec&quot;&gt;x&lt;/span&gt; because there are &lt;span class=&quot;eqn&quot;&gt;n&lt;/span&gt; parameters we can wiggle, each potentially changing the function's value. Therefore, the Jacobian is always &lt;span class=&quot;eqn&quot;&gt;m&lt;/span&gt; rows for &lt;span class=&quot;eqn&quot;&gt;m&lt;/span&gt; equations. It helps to think about the possible Jacobian shapes visually:&lt;/p&gt;
&lt;div&gt;&lt;img class=&quot;blkeqn&quot; src=&quot;https://explained.ai/matrix-calculus/images/latex-6793E76E433509E38529D4B70EB4D956.svg&quot; alt=&quot; \begin{tabular}{c|ccl} &amp;amp; \begin{tabular}[t]{c} scalar\ \framebox(18,18){$x$}\ \end{tabular} &amp;amp; \begin{tabular}{c} vector\ \framebox(18,40){$\mathbf{x}$} \end{tabular}\ \hline \\[\dimexpr-\normalbaselineskip+5pt] \begin{tabular}[b]{c} scalar\ \framebox(18,18){$f$}\ \end{tabular} &amp;amp;\framebox(18,18){$\frac{\partial f}{\partial {x}}$} &amp;amp; \framebox(40,18){$\frac{\partial f}{\partial {\mathbf{x}}}$}&amp;amp;\ \begin{tabular}[b]{c} vector\ \framebox(18,40){$\mathbf{f}$}\ \end{tabular} &amp;amp; \framebox(18,40){$\frac{\partial \mathbf{f}}{\partial {x}}$} &amp;amp; \framebox(40,40){$\frac{\partial \mathbf{f}}{\partial \mathbf{x}}$}\ \end{tabular} &quot; /&gt;&lt;/div&gt;
&lt;p&gt;The Jacobian of the identity function &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-3ABE4A0471143ABFC180C9FA485E5F0A-depth003.25.svg&quot; /&gt;, with &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-E314355F5E2135483279531C62D7E8EC-depth003.25.svg&quot; /&gt;, has &lt;span class=&quot;eqn&quot;&gt;n&lt;/span&gt; functions and each function has &lt;span class=&quot;eqn&quot;&gt;n&lt;/span&gt; parameters held in a single vector &lt;span class=&quot;eqnvec&quot;&gt;x&lt;/span&gt;. The Jacobian is, therefore, a square matrix since &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-A193EBC083B4745370F6F1343383D9CC-depth000.14.svg&quot; /&gt;:&lt;/p&gt;
&lt;div&gt;&lt;img class=&quot;blkeqn&quot; src=&quot;https://explained.ai/matrix-calculus/images/latex-229DDEF6A61228EE3F98CD129BBF9663.svg&quot; alt=&quot; \begin{eqnarray*} \frac{\partial \mathbf{y}}{\partial \mathbf{x}} = \begin{bmatrix} \frac{\partial}{\partial {x}} f_1(\mathbf{x}) \ \frac{\partial}{\partial {x}} f_2(\mathbf{x})\ \ldots\ \frac{\partial}{\partial {x}} f_m(\mathbf{x}) \end{bmatrix} &amp;amp;=&amp;amp; \begin{bmatrix} \frac{\partial}{\partial {x_1}} f_1(\mathbf{x})~ \frac{\partial}{\partial {x_2}} f_1(\mathbf{x}) ~\ldots~ \frac{\partial}{\partial {x_n}} f_1(\mathbf{x}) \ \frac{\partial}{\partial {x_1}} f_2(\mathbf{x})~ \frac{\partial}{\partial {x_2}} f_2(\mathbf{x}) ~\ldots~ \frac{\partial}{\partial {x_n}} f_2(\mathbf{x}) \ \ldots\ ~\frac{\partial}{\partial {x_1}} f_m(\mathbf{x})~ \frac{\partial}{\partial {x_2}} f_m(\mathbf{x}) ~\ldots~ \frac{\partial}{\partial {x_n}} f_m(\mathbf{x}) \ \end{bmatrix}\\\ &amp;amp; = &amp;amp; \begin{bmatrix} \frac{\partial}{\partial {x_1}} x_1~ \frac{\partial}{\partial {x_2}} x_1 ~\ldots~ \frac{\partial}{\partial {x_n}} x_1 \ \frac{\partial}{\partial {x_1}} x_2~ \frac{\partial}{\partial {x_2}} x_2 ~\ldots~ \frac{\partial}{\partial {x_n}} x_2 \ \ldots\ ~\frac{\partial}{\partial {x_1}} x_n~ \frac{\partial}{\partial {x_2}} x_n ~\ldots~ \frac{\partial}{\partial {x_n}} x_n \ \end{bmatrix}\\\ &amp;amp; &amp;amp; (\text{and since } \frac{\partial}{\partial {x_j}} x_i = 0 \text{ for } j \neq i)\ &amp;amp; = &amp;amp; \begin{bmatrix} \frac{\partial}{\partial {x_1}} x_1 &amp;amp; 0 &amp;amp; \ldots&amp;amp; 0 \ 0 &amp;amp; \frac{\partial}{\partial {x_2}} x_2 &amp;amp;\ldots &amp;amp; 0 \ &amp;amp; &amp;amp; \ddots\ 0 &amp;amp; 0 &amp;amp;\ldots&amp;amp; \frac{\partial}{\partial {x_n}} x_n \ \end{bmatrix}\\\ &amp;amp; = &amp;amp; \begin{bmatrix} 1 &amp;amp; 0 &amp;amp; \ldots&amp;amp; 0 \ 0 &amp;amp;1 &amp;amp;\ldots &amp;amp; 0 \ &amp;amp; &amp;amp; \ddots\ 0 &amp;amp; 0 &amp;amp; \ldots &amp;amp;1 \ \end{bmatrix}\\\ &amp;amp; = &amp;amp; I ~~~(I \text{ is the identity matrix with ones down the diagonal})\ \end{eqnarray*} &quot; /&gt;&lt;/div&gt;
&lt;p&gt;Make sure that you can derive each step above before moving on. If you get stuck, just consider each element of the matrix in isolation and apply the usual scalar derivative rules. That is a generally useful trick: Reduce vector expressions down to a set of scalar expressions and then take all of the partials, combining the results appropriately into vectors and matrices at the end.&lt;/p&gt;
&lt;p&gt;Also be careful to track whether a matrix is vertical, &lt;span class=&quot;eqnvec&quot;&gt;x&lt;/span&gt;, or horizontal, &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-FAAEE783424BC0E27E9AA2F56A7B50B8-depth000.00.svg&quot; /&gt; where &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-FAAEE783424BC0E27E9AA2F56A7B50B8-depth000.00.svg&quot; /&gt; means &lt;span class=&quot;eqnvec&quot;&gt;x&lt;/span&gt; transpose. Also make sure you pay attention to whether something is a scalar-valued function, &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-D3172B9A65679CB6EF09F17BE0918890-depth002.65.svg&quot; /&gt;, or a vector of functions (or a vector-valued function), &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-BCAEE673D10908E8197A79E9D4FB6249-depth002.33.svg&quot; /&gt;.&lt;/p&gt;
&lt;h3 id=&quot;sec4.2&quot;&gt;Derivatives of vector element-wise binary operators&lt;/h3&gt;
&lt;p&gt;Element-wise binary operations on vectors, such as vector addition &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-F26AC9FE4C8C9B953164428DCE00BE9C-depth001.06.svg&quot; /&gt;, are important because we can express many common vector operations, such as the multiplication of a vector by a scalar, as element-wise binary operations. By “element-wise binary operations” we simply mean applying an operator to the first item of each vector to get the first item of the output, then to the second items of the inputs for the second item of the output, and so forth. This is how all the basic math operators are applied by default in numpy or tensorflow, for example. Examples that often crop up in deep learning are &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-E50C0CB908AF7566CCC6D4585634EDC2-depth003.25.svg&quot; /&gt; and &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-C65762AB635D8E08F759F1203D223C29-depth000.51.svg&quot; /&gt; (returns a vector of ones and zeros).&lt;/p&gt;
&lt;p&gt;We can generalize the element-wise binary operations with notation &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-E2E59AE84EE7A5B1C905E50FA7753A31-depth003.25.svg&quot; /&gt; where &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-5D19E7D8CDFE53DEB40F29D8936E6C89-depth003.25.svg&quot; /&gt;. (Reminder: &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-CF513DECF6E4ACE0E25CB1C932AAA049-depth003.25.svg&quot; /&gt; is the number of items in &lt;span class=&quot;eqn&quot;&gt;x&lt;/span&gt;.) The &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-1A74909B6CBAA4532A76D83B72C12DE0-depth002.52.svg&quot; /&gt; symbol represents any element-wise operator (such as &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-26B17225B626FB9238849FD60EABDF60-depth001.06.svg&quot; /&gt;) and not the &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-1B3C1A40F9CB094D47E8C6F9B0DF773F-depth000.00.svg&quot; /&gt; function composition operator. Here's what equation &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-E2E59AE84EE7A5B1C905E50FA7753A31-depth003.25.svg&quot; /&gt; looks like when we zoom in to examine the scalar equations:&lt;/p&gt;
&lt;div&gt;&lt;img class=&quot;blkeqn&quot; src=&quot;https://explained.ai/matrix-calculus/images/blkeqn-ADD1230AE3E64A1B7FA77851BB1F07A1.svg&quot; alt=&quot;&quot; /&gt;&lt;/div&gt;
&lt;p&gt;where we write &lt;span class=&quot;eqn&quot;&gt;n&lt;/span&gt; (not &lt;span class=&quot;eqn&quot;&gt;m&lt;/span&gt;) equations vertically to emphasize the fact that the result of element-wise operators give &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-A193EBC083B4745370F6F1343383D9CC-depth000.14.svg&quot; /&gt; sized vector results.&lt;/p&gt;
&lt;p&gt;Using the ideas from the last section, we can see that the general case for the Jacobian with respect to &lt;span class=&quot;eqnvec&quot;&gt;w&lt;/span&gt; is the square matrix:&lt;/p&gt;
&lt;div&gt;&lt;img class=&quot;blkeqn&quot; src=&quot;https://explained.ai/matrix-calculus/images/blkeqn-54F95B3CFFD404740FAD218B308DEF70.svg&quot; alt=&quot;&quot; /&gt;&lt;/div&gt;
&lt;p&gt;and the Jacobian with respect to &lt;span class=&quot;eqnvec&quot;&gt;x&lt;/span&gt; is:&lt;/p&gt;
&lt;div&gt;&lt;img class=&quot;blkeqn&quot; src=&quot;https://explained.ai/matrix-calculus/images/blkeqn-2693C112F589CD0E26853EAD5ED36CFD.svg&quot; alt=&quot;&quot; /&gt;&lt;/div&gt;
&lt;p&gt;That's quite a furball, but fortunately the Jacobian is very often a diagonal matrix, a matrix that is zero everywhere but the diagonal. Because this greatly simplifies the Jacobian, let's examine in detail when the Jacobian reduces to a diagonal matrix for element-wise operations.&lt;/p&gt;
&lt;p&gt;In a diagonal Jacobian, all elements off the diagonal are zero, &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-8B14469E98630C19F16578F90C45F62E-depth007.21.svg&quot; /&gt; where &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-B064F8555EC660F2F8BDC927D9636A06-depth002.72.svg&quot; /&gt;. (Notice that we are taking the partial derivative with respect to &lt;span class=&quot;eqn&quot;&gt;w&lt;sub&gt;j&lt;/sub&gt;&lt;/span&gt; not &lt;span class=&quot;eqn&quot;&gt;w&lt;sub&gt;i&lt;/sub&gt;&lt;/span&gt;.) Under what conditions are those off-diagonal elements zero? Precisely when &lt;span class=&quot;eqn&quot;&gt;f&lt;sub&gt;i&lt;/sub&gt;&lt;/span&gt; and &lt;span class=&quot;eqn&quot;&gt;g&lt;sub&gt;i&lt;/sub&gt;&lt;/span&gt; are contants with respect to &lt;span class=&quot;eqn&quot;&gt;w&lt;sub&gt;j&lt;/sub&gt;&lt;/span&gt;, &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-44C0281EC00A2C0E93E4E3863EE9083D-depth007.21.svg&quot; /&gt;. Regardless of the operator, if those partial derivatives go to zero, the operation goes to zero, &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-A180A4C31CAC188626034423680B71E0-depth002.52.svg&quot; /&gt; no matter what, and the partial derivative of a constant is zero.&lt;/p&gt;
&lt;p&gt;Those partials go to zero when &lt;span class=&quot;eqn&quot;&gt;f&lt;sub&gt;i&lt;/sub&gt;&lt;/span&gt; and &lt;span class=&quot;eqn&quot;&gt;g&lt;sub&gt;i&lt;/sub&gt;&lt;/span&gt; are not functions of &lt;span class=&quot;eqn&quot;&gt;w&lt;sub&gt;j&lt;/sub&gt;&lt;/span&gt;. We know that element-wise operations imply that &lt;span class=&quot;eqn&quot;&gt;f&lt;sub&gt;i&lt;/sub&gt;&lt;/span&gt; is purely a function of &lt;span class=&quot;eqn&quot;&gt;w&lt;sub&gt;i&lt;/sub&gt;&lt;/span&gt; and &lt;span class=&quot;eqn&quot;&gt;g&lt;sub&gt;i&lt;/sub&gt;&lt;/span&gt; is purely a function of &lt;span class=&quot;eqn&quot;&gt;x&lt;sub&gt;i&lt;/sub&gt;&lt;/span&gt;. For example, &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-2361C23CB78AC04537D7D642DF065EF5-depth001.06.svg&quot; /&gt; sums &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-4AF62C4A6B74D712D3FFD3FA4A0062BD-depth002.05.svg&quot; /&gt;. Consequently, &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-45553270D20A27EBD4AAE84292606CDD-depth003.25.svg&quot; /&gt; reduces to &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-5F2A3B3A730ABED47918785C5EBF5039-depth003.25.svg&quot; /&gt; and the goal becomes &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-767EBC7C8A1785557E38FD32A10FB123-depth007.21.svg&quot; /&gt;. &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-DB590A5BF8B0ACC05B1FEEDC07929CD7-depth003.25.svg&quot; /&gt; and &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-1BF8B4ED9F2C1D993DC0A1E547BDF5CB-depth003.25.svg&quot; /&gt; look like constants to the partial differentiation operator with respect to &lt;span class=&quot;eqn&quot;&gt;w&lt;sub&gt;j&lt;/sub&gt;&lt;/span&gt; when &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-B064F8555EC660F2F8BDC927D9636A06-depth002.72.svg&quot; /&gt; so the partials are zero off the diagonal. (Notation &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-DB590A5BF8B0ACC05B1FEEDC07929CD7-depth003.25.svg&quot; /&gt; is technically an abuse of our notation because &lt;span class=&quot;eqn&quot;&gt;f&lt;sub&gt;i&lt;/sub&gt;&lt;/span&gt; and &lt;span class=&quot;eqn&quot;&gt;g&lt;sub&gt;i&lt;/sub&gt;&lt;/span&gt; are functions of vectors not individual elements. We should really write something like &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-616C179024B43E6C340B1EE24D414DE8-depth003.25.svg&quot; /&gt;, but that would muddy the equations further, and programmers are comfortable overloading functions, so we'll proceed with the notation anyway.)&lt;/p&gt;
&lt;p&gt;We'll take advantage of this simplification later and refer to the constraint that &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-BD5A63074F44F11CB2ED06325816582A-depth003.25.svg&quot; /&gt; and &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-5E597DAA4E5D9263DCBFB6AB02BDB67F-depth003.25.svg&quot; /&gt; access at most &lt;span class=&quot;eqn&quot;&gt;w&lt;sub&gt;i&lt;/sub&gt;&lt;/span&gt; and &lt;span class=&quot;eqn&quot;&gt;x&lt;sub&gt;i&lt;/sub&gt;&lt;/span&gt;, respectively, as the &lt;em&gt;element-wise diagonal condition&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Under this condition, the elements along the diagonal of the Jacobian are &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-C196BF268027E86D3D2420C2A205AF28-depth005.92.svg&quot; /&gt;:&lt;/p&gt;
&lt;div&gt;&lt;img class=&quot;blkeqn&quot; src=&quot;https://explained.ai/matrix-calculus/images/blkeqn-4CFC6C644E4A95B5760435C5094BE095.svg&quot; alt=&quot;&quot; /&gt;&lt;/div&gt;
&lt;p&gt;(The large “0”s are a shorthand indicating all of the off-diagonal are 0.)&lt;/p&gt;
&lt;p&gt;More succinctly, we can write:&lt;/p&gt;
&lt;div&gt;&lt;img class=&quot;blkeqn&quot; src=&quot;https://explained.ai/matrix-calculus/images/blkeqn-3D114C6873F46EE41AF91BF8B1BB37CD.svg&quot; alt=&quot;&quot; /&gt;&lt;/div&gt;
&lt;p&gt;and&lt;/p&gt;
&lt;div&gt;&lt;img class=&quot;blkeqn&quot; src=&quot;https://explained.ai/matrix-calculus/images/blkeqn-78E1B2628221D9FD588A011D54670619.svg&quot; alt=&quot;&quot; /&gt;&lt;/div&gt;
&lt;p&gt;where &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-4935E4C6B875FD6C7C181871B566AB1A-depth003.25.svg&quot; /&gt; constructs a matrix whose diagonal elements are taken from vector &lt;span class=&quot;eqnvec&quot;&gt;x&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Because we do lots of simple vector arithmetic, the general function &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-5B39FE68B4FDD0AF04290BA579A993CB-depth003.25.svg&quot; /&gt; in the binary element-wise operation is often just the vector &lt;span class=&quot;eqnvec&quot;&gt;w&lt;/span&gt;. Any time the general function is a vector, we know that &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-BD5A63074F44F11CB2ED06325816582A-depth003.25.svg&quot; /&gt; reduces to &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-F5BDA09DDE6E00806B01094F5BED3026-depth003.25.svg&quot; /&gt;. For example, vector addition &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-DF3F5FDED9142A243031D03CF82121AE-depth001.06.svg&quot; /&gt; fits our element-wise diagonal condition because &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-1ED79D2E2BBE9EE796433D13773157A7-depth003.25.svg&quot; /&gt; has scalar equations &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-F7C644AAA7A70D588A0E003C7C9E439E-depth003.25.svg&quot; /&gt; that reduce to just &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-85550E18F87E4AF75645A38273B97A80-depth003.25.svg&quot; /&gt; with partial derivatives:&lt;/p&gt;
&lt;div&gt;&lt;img class=&quot;blkeqn&quot; src=&quot;https://explained.ai/matrix-calculus/images/blkeqn-A5DC35FE0CEC748B35BB5991933C4698.svg&quot; alt=&quot;&quot; /&gt;&lt;/div&gt;
&lt;div&gt;&lt;img class=&quot;blkeqn&quot; src=&quot;https://explained.ai/matrix-calculus/images/blkeqn-C2B0BF832F19994D832F90C18B1F04AF.svg&quot; alt=&quot;&quot; /&gt;&lt;/div&gt;
&lt;p&gt;That gives us &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-2935E504F134B53B2C03072175BCCD1F-depth004.67.svg&quot; /&gt;, the identity matrix, because every element along the diagonal is 1. &lt;span class=&quot;eqn&quot;&gt;I&lt;/span&gt; represents the square identity matrix of appropriate dimensions that is zero everywhere but the diagonal, which contains all ones.&lt;/p&gt;
&lt;p&gt;Given the simplicity of this special case, &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-BD5A63074F44F11CB2ED06325816582A-depth003.25.svg&quot; /&gt; reducing to &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-DB590A5BF8B0ACC05B1FEEDC07929CD7-depth003.25.svg&quot; /&gt;, you should be able to derive the Jacobians for the common element-wise binary operations on vectors:&lt;/p&gt;
&lt;div&gt;&lt;img class=&quot;blkeqn&quot; src=&quot;https://explained.ai/matrix-calculus/images/blkeqn-0C9CE28C888576E0D4873BDD69BC74EA.svg&quot; alt=&quot;&quot; /&gt;&lt;/div&gt;
&lt;div&gt;&lt;img class=&quot;blkeqn&quot; src=&quot;https://explained.ai/matrix-calculus/images/blkeqn-10B3C04502114250E4A74A1EB5F27F05.svg&quot; alt=&quot;&quot; /&gt;&lt;/div&gt;
&lt;p&gt;The &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-790C76CEB13E928D08EDC53D7AC4BB5C-depth001.08.svg&quot; /&gt; and &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-98FF0549EBE322C195C2B36FD5EEAD33-depth001.08.svg&quot; /&gt; operators are element-wise multiplication and division; &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-790C76CEB13E928D08EDC53D7AC4BB5C-depth001.08.svg&quot; /&gt; is sometimes called the &lt;em&gt;Hadamard product&lt;/em&gt;. There isn't a standard notation for element-wise multiplication and division so we're using an approach consistent with our general binary operation notation.&lt;/p&gt;
&lt;h3 id=&quot;sec4.3&quot;&gt;Derivatives involving scalar expansion&lt;/h3&gt;
&lt;p&gt;When we multiply or add scalars to vectors, we're implicitly expanding the scalar to a vector and then performing an element-wise binary operation. For example, adding scalar &lt;span class=&quot;eqn&quot;&gt;z&lt;/span&gt; to vector &lt;span class=&quot;eqnvec&quot;&gt;x&lt;/span&gt;, &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-6307CEA088D2D4E98E5B163B9CE8F510-depth002.33.svg&quot; /&gt;, is really &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-8D9C0B9B15490F45C353D9DE64565A4F-depth003.25.svg&quot; /&gt; where &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-3ABE4A0471143ABFC180C9FA485E5F0A-depth003.25.svg&quot; /&gt; and &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-BD2335FC4BBF16BE9590D2501CE8C030-depth003.25.svg&quot; /&gt;. (The notation &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-C2C0146718E407005D0C74774C5C5FFC-depth000.00.svg&quot; /&gt; represents a vector of ones of appropriate length.) &lt;span class=&quot;eqn&quot;&gt;z&lt;/span&gt; is any scalar that doesn't depend on &lt;span class=&quot;eqnvec&quot;&gt;x&lt;/span&gt;, which is useful because then &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-EBCC35EEAE3B420D59689973D8B6BD2E-depth005.92.svg&quot; /&gt; for any &lt;span class=&quot;eqn&quot;&gt;x&lt;sub&gt;i&lt;/sub&gt;&lt;/span&gt; and that will simplify our partial derivative computations. (It's okay to think of variable &lt;span class=&quot;eqn&quot;&gt;z&lt;/span&gt; as a constant for our discussion here.) Similarly, multiplying by a scalar, &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-C9A7B878F49F3D964AFEC9C1F78061CF-depth002.33.svg&quot; /&gt;, is really &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-93A461AB49FD151E602D9344358732CD-depth003.25.svg&quot; /&gt; where &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-790C76CEB13E928D08EDC53D7AC4BB5C-depth001.08.svg&quot; /&gt; is the element-wise multiplication (Hadamard product) of the two vectors.&lt;/p&gt;
&lt;p&gt;The partial derivatives of vector-scalar addition and multiplication with respect to vector &lt;span class=&quot;eqnvec&quot;&gt;x&lt;/span&gt; use our element-wise rule:&lt;/p&gt;
&lt;div&gt;&lt;img class=&quot;blkeqn&quot; src=&quot;https://explained.ai/matrix-calculus/images/blkeqn-F8F0A8F213DE2D87CB4F0C88B2CE8F4C.svg&quot; alt=&quot;&quot; /&gt;&lt;/div&gt;
&lt;p&gt;This follows because functions &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-3ABE4A0471143ABFC180C9FA485E5F0A-depth003.25.svg&quot; /&gt; and &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-BD2335FC4BBF16BE9590D2501CE8C030-depth003.25.svg&quot; /&gt; clearly satisfy our element-wise diagonal condition for the Jacobian (that &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-DAE17AB5EE9C0A7FFA3E9B1774E80201-depth003.25.svg&quot; /&gt; refer at most to &lt;span class=&quot;eqn&quot;&gt;x&lt;sub&gt;i&lt;/sub&gt;&lt;/span&gt; and &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-9F8AE8514327A98189F8F05E2ECD6496-depth003.25.svg&quot; /&gt; refers to the &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-97361F12A3555FC4FC4E2FFCE1799AC3-depth000.14.svg&quot; /&gt; value of the &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-49508A178E36D0863E041575526BEA1A-depth001.05.svg&quot; /&gt; vector).&lt;/p&gt;
&lt;p&gt;Using the usual rules for scalar partial derivatives, we arrive at the following diagonal elements of the Jacobian for vector-scalar addition:&lt;/p&gt;
&lt;div&gt;&lt;img class=&quot;blkeqn&quot; src=&quot;https://explained.ai/matrix-calculus/images/blkeqn-6B4EFB58ED5F9EBD623321FE1975FA4E.svg&quot; alt=&quot;&quot; /&gt;&lt;/div&gt;
&lt;p&gt;So, &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-5107D6819CDC50A8988D3EA0FB9B94CE-depth004.67.svg&quot; /&gt;.&lt;/p&gt;
&lt;p&gt;Computing the partial derivative with respect to the scalar parameter &lt;span class=&quot;eqn&quot;&gt;z&lt;/span&gt;, however, results in a vertical vector, not a diagonal matrix. The elements of the vector are:&lt;/p&gt;
&lt;div&gt;&lt;img class=&quot;blkeqn&quot; src=&quot;https://explained.ai/matrix-calculus/images/blkeqn-5B07C016CBBA27F3E3650DA92BF06A24.svg&quot; alt=&quot;&quot; /&gt;&lt;/div&gt;
&lt;p&gt;Therefore, &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-F05F04525E4A1B8959DE54DC7C692060-depth005.22.svg&quot; /&gt;.&lt;/p&gt;
&lt;p&gt;The diagonal elements of the Jacobian for vector-scalar multiplication involve the product rule for scalar derivatives:&lt;/p&gt;
&lt;div&gt;&lt;img class=&quot;blkeqn&quot; src=&quot;https://explained.ai/matrix-calculus/images/blkeqn-3E6008F6437DA818B481A79FD47D38E4.svg&quot; alt=&quot;&quot; /&gt;&lt;/div&gt;
&lt;p&gt;So, &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-3F231096152DFB321FAC62F57A808C35-depth004.67.svg&quot; /&gt;.&lt;/p&gt;
&lt;p&gt;The partial derivative with respect to scalar parameter &lt;span class=&quot;eqn&quot;&gt;z&lt;/span&gt; is a vertical vector whose elements are:&lt;/p&gt;
&lt;div&gt;&lt;img class=&quot;blkeqn&quot; src=&quot;https://explained.ai/matrix-calculus/images/blkeqn-C1C1AD1A9E7A6ECCAAACE952B8355BFB.svg&quot; alt=&quot;&quot; /&gt;&lt;/div&gt;
&lt;p&gt;This gives us &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-82B897A0A23D9C6BB66EDF17D1D3CB02-depth005.22.svg&quot; /&gt;.&lt;/p&gt;
&lt;h3 id=&quot;sec4.4&quot;&gt;Vector sum reduction&lt;/h3&gt;
&lt;p&gt;Summing up the elements of a vector is an important operation in deep learning, such as the network loss function, but we can also use it as a way to simplify computing the derivative of vector dot product and other operations that reduce vectors to scalars.&lt;/p&gt;
&lt;p&gt;Let &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-DC5FB5DC7AEB54D8C206744EED4AD748-depth003.31.svg&quot; /&gt;. Notice we were careful here to leave the parameter as a vector &lt;span class=&quot;eqnvec&quot;&gt;x&lt;/span&gt; because each function &lt;span class=&quot;eqn&quot;&gt;f&lt;sub&gt;i&lt;/sub&gt;&lt;/span&gt; could use all values in the vector, not just &lt;span class=&quot;eqn&quot;&gt;x&lt;sub&gt;i&lt;/sub&gt;&lt;/span&gt;. The sum is over the &lt;strong&gt;results&lt;/strong&gt; of the function and not the parameter. The gradient (&lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-4C8971A9939B0BB2D8AF44195C5BD833-depth001.08.svg&quot; /&gt; Jacobian) of vector summation is:&lt;/p&gt;
&lt;div&gt;&lt;img class=&quot;blkeqn&quot; src=&quot;https://explained.ai/matrix-calculus/images/blkeqn-40C0C67E5948039B40D9718ECC2858AE.svg&quot; alt=&quot;&quot; /&gt;&lt;/div&gt;
&lt;p&gt;(The summation inside the gradient elements can be tricky so make sure to keep your notation consistent.)&lt;/p&gt;
&lt;p&gt;Let's look at the gradient of the simple &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-5FAFFB6A723E437AC6433DCA0B269846-depth003.25.svg&quot; /&gt;. The function inside the summation is just &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-E314355F5E2135483279531C62D7E8EC-depth003.25.svg&quot; /&gt; and the gradient is then:&lt;/p&gt;
&lt;div&gt;&lt;img class=&quot;blkeqn&quot; src=&quot;https://explained.ai/matrix-calculus/images/blkeqn-B6DF766D85C48FF7434B8FFF7BEC9410.svg&quot; alt=&quot;&quot; /&gt;&lt;/div&gt;
&lt;p&gt;Because &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-9B32CEB09BA5F0B84935A24BF81D3C9C-depth007.21.svg&quot; /&gt; for &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-B064F8555EC660F2F8BDC927D9636A06-depth002.72.svg&quot; /&gt;, we can simplify to:&lt;/p&gt;
&lt;div&gt;&lt;img class=&quot;blkeqn&quot; src=&quot;https://explained.ai/matrix-calculus/images/blkeqn-9D07CB9DFE389978D329A8CFE7568825.svg&quot; alt=&quot;&quot; /&gt;&lt;/div&gt;
&lt;p&gt;Notice that the result is a horizontal vector full of 1s, not a vertical vector, and so the gradient is &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-DFB70C45B6CCB149DFDA0E3690715F92-depth000.00.svg&quot; /&gt;. (The &lt;span class=&quot;eqn&quot;&gt;T&lt;/span&gt; exponent of &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-DFB70C45B6CCB149DFDA0E3690715F92-depth000.00.svg&quot; /&gt; represents the transpose of the indicated vector. In this case, it flips a vertical vector to a horizontal vector.) It's very important to keep the shape of all of your vectors and matrices in order otherwise it's impossible to compute the derivatives of complex functions.&lt;/p&gt;
&lt;p&gt;As another example, let's sum the result of multiplying a vector by a constant scalar. If &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-729968724651D87C8269B6FFEAD6EA90-depth003.25.svg&quot; /&gt; then &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-A5D03DE59DCDBA948F463FAABD04791D-depth003.25.svg&quot; /&gt;. The gradient is:&lt;/p&gt;
&lt;div&gt;&lt;img class=&quot;blkeqn&quot; src=&quot;https://explained.ai/matrix-calculus/images/blkeqn-4C28E3734FC6110AF58C567604ED3462.svg&quot; alt=&quot;&quot; /&gt;&lt;/div&gt;
&lt;p&gt;The derivative with respect to scalar variable &lt;span class=&quot;eqn&quot;&gt;z&lt;/span&gt; is &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-5ED2D4C114D036610B8E20271C5026EF-depth001.08.svg&quot; /&gt;:&lt;/p&gt;
&lt;div&gt;&lt;img class=&quot;blkeqn&quot; src=&quot;https://explained.ai/matrix-calculus/images/blkeqn-709809A15FF63948512A3F83DF9F04EA.svg&quot; alt=&quot;&quot; /&gt;&lt;/div&gt;
&lt;h3 id=&quot;sec4.5&quot;&gt;The Chain Rules&lt;/h3&gt;
&lt;p&gt;We can't compute partial derivatives of very complicated functions using just the basic matrix calculus rules we've seen so far. For example, we can't take the derivative of nested expressions like &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-DCA4F9F0CE7F7CA365E8B26987ED972A-depth003.25.svg&quot; /&gt; directly without reducing it to its scalar equivalent. We need to be able to combine our basic vector rules using what we can call the &lt;em&gt;vector chain rule&lt;/em&gt;. Unfortunately, there are a number of rules for differentiation that fall under the name “chain rule” so we have to be careful which chain rule we're talking about. Part of our goal here is to clearly define and name three different chain rules and indicate in which situation they are appropriate. To get warmed up, we'll start with what we'll call the &lt;em&gt;single-variable chain rule&lt;/em&gt;, where we want the derivative of a scalar function with respect to a scalar. Then we'll move on to an important concept called the &lt;em&gt;total derivative&lt;/em&gt; and use it to define what we'll pedantically call the &lt;em&gt;single-variable total-derivative chain rule&lt;/em&gt;. Then, we'll be ready for the vector chain rule in its full glory as needed for neural networks.&lt;/p&gt;
&lt;p&gt;The chain rule is conceptually a divide and conquer strategy (like Quicksort) that breaks complicated expressions into subexpressions whose derivatives are easier to compute. Its power derives from the fact that we can process each simple subexpression in isolation yet still combine the intermediate results to get the correct overall result.&lt;/p&gt;
&lt;p&gt;The chain rule comes into play when we need the derivative of an expression composed of nested subexpressions. For example, we need the chain rule when confronted with expressions like &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-06D67DC7FE74C1895AEF564F8295E918-depth004.58.svg&quot; /&gt;. The outermost expression takes the &lt;span class=&quot;eqn&quot;&gt;sin&lt;/span&gt; of an intermediate result, a nested subexpression that squares &lt;span class=&quot;eqn&quot;&gt;x&lt;/span&gt;. Specifically, we need the single-variable chain rule, so let's start by digging into that in more detail.&lt;/p&gt;
&lt;h4 id=&quot;sec4.5.1&quot;&gt;Single-variable chain rule&lt;/h4&gt;
&lt;p&gt;Let's start with the solution to the derivative of our nested expression: &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-AB5ECA885C5685990CD778580665B3A4-depth004.58.svg&quot; /&gt;. It doesn't take a mathematical genius to recognize components of the solution that smack of scalar differentiation rules, &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-1A32AA532898DEBB80C0C7A818C5C70B-depth004.58.svg&quot; /&gt; and &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-DC7C2E5FB11394451EA6A2010904F0B2-depth004.58.svg&quot; /&gt;. It looks like the solution is to multiply the derivative of the outer expression by the derivative of the inner expression or “chain the pieces together,” which is exactly right. In this section, we'll explore the general principle at work and provide a process that works for highly-nested expressions of a single variable.&lt;/p&gt;
&lt;p&gt;Chain rules are typically defined in terms of nested functions, such as &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-281717E562B6C04AA861AC9F2801D016-depth003.25.svg&quot; /&gt; for single-variable chain rules. (You will also see the chain rule defined using function composition &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-88806005B64072FE5A06E4E609A9E251-depth003.25.svg&quot; /&gt;, which is the same thing.) Some sources write the derivative using shorthand notation &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-3D59985B51738C2BF54BA3D955AB8588-depth003.25.svg&quot; /&gt;, but that hides the fact that we are introducing an intermediate variable: &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-8C36385E70550C1C0EA86E14320174DF-depth003.25.svg&quot; /&gt;, which we'll see shortly. It's better to define the &lt;a href=&quot;http://m.wolframalpha.com/input/?i=chain+rule&quot;&gt;single-variable chain rule&lt;/a&gt; of &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-8BC3A7E80988236E8F017205F413461C-depth003.25.svg&quot; /&gt; explicitly so we never take the derivative with respect to the wrong variable. Here is the formulation of the single-variable chain rule we recommend:&lt;/p&gt;
&lt;div&gt;&lt;img class=&quot;blkeqn&quot; src=&quot;https://explained.ai/matrix-calculus/images/blkeqn-9D3919C42833D1FF1456DEA11D8CC927.svg&quot; alt=&quot;&quot; /&gt;&lt;/div&gt;
&lt;p&gt;To deploy the single-variable chain rule, follow these steps:&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;Introduce intermediate variables for nested subexpressions and subexpressions for both binary and unary operators; e.g., &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-60C13E05D3EC8C10B8564EAE7023D9DB-depth001.08.svg&quot; /&gt; is binary, &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-6FFE53F1F614CC1D470F85B6C56A3AFB-depth003.25.svg&quot; /&gt; and other trigonometric functions are usually unary because there is a single operand. This step normalizes all equations to single operators or function applications.&lt;/li&gt;
&lt;li&gt;Compute derivatives of the intermediate variables with respect to their parameters.&lt;/li&gt;
&lt;li&gt;Combine all derivatives of intermediate variables by multiplying them together to get the overall result.&lt;/li&gt;
&lt;li&gt;Substitute intermediate variables back in if any are referenced in the derivative equation.&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;The third step puts the “chain” in “chain rule” because it chains together intermediate results. Multiplying the intermediate derivatives together is the common theme among all variations of the chain rule.&lt;/p&gt;
&lt;p&gt;Let's try this process on &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-872F24FC57CA661E3704C0A10869C6B5-depth003.25.svg&quot; /&gt;:&lt;/p&gt;
&lt;ol readability=&quot;0&quot;&gt;&lt;li readability=&quot;3&quot;&gt;Introduce intermediate variables. Let &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-FA510039FEDBE5A935A70EF6E3B46394-depth000.14.svg&quot; /&gt; represent subexpression &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-32F5240D0DBF2CCBE75EF7F8EF2015E0-depth000.14.svg&quot; /&gt; (shorthand for &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-879B57F3F479F58707D2477B46B060CF-depth003.25.svg&quot; /&gt;). This gives us:
&lt;div&gt;&lt;img class=&quot;blkeqn&quot; src=&quot;https://explained.ai/matrix-calculus/images/blkeqn-165CA85C4E868C4589FDC97854EF5AFE.svg&quot; alt=&quot;&quot; /&gt;&lt;/div&gt;
&lt;p&gt;The order of these subexpressions does not affect the answer, but we recommend working in the reverse order of operations dictated by the nesting (innermost to outermost). That way, expressions and derivatives are always functions of previously-computed elements.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;Compute derivatives.
&lt;div&gt;&lt;img class=&quot;blkeqn&quot; src=&quot;https://explained.ai/matrix-calculus/images/blkeqn-33DB49B9B2BFE622EF83565332547027.svg&quot; alt=&quot;&quot; /&gt;&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;Combine.
&lt;div&gt;&lt;img class=&quot;blkeqn&quot; src=&quot;https://explained.ai/matrix-calculus/images/blkeqn-9D1B1984635759F4C2D23464EBBAA995.svg&quot; alt=&quot;&quot; /&gt;&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;Substitute.
&lt;div&gt;&lt;img class=&quot;blkeqn&quot; src=&quot;https://explained.ai/matrix-calculus/images/blkeqn-6E1052BD462233E4BEA04D695437A984.svg&quot; alt=&quot;&quot; /&gt;&lt;/div&gt;
&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;Notice how easy it is to compute the derivatives of the intermediate variables in isolation! The chain rule says it's legal to do that and tells us how to combine the intermediate results to get &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-E4D3AF86AC3E4315148DA23A886A72EA-depth003.25.svg&quot; /&gt;.&lt;/p&gt;
&lt;p&gt;You can think of the combining step of the chain rule in terms of units canceling. If we let &lt;span class=&quot;eqn&quot;&gt;y&lt;/span&gt; be miles, &lt;span class=&quot;eqn&quot;&gt;x&lt;/span&gt; be the gallons in a gas tank, and &lt;span class=&quot;eqn&quot;&gt;u&lt;/span&gt; as gallons we can interpret &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-70047C98E4163674E78BB42D0CF4AEA8-depth004.58.svg&quot; /&gt; as &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-F98E0EBA888E860C7E51565C7225EBFA-depth006.34.svg&quot; /&gt;. The &lt;span class=&quot;eqn&quot;&gt;gallon&lt;/span&gt; denominator and numerator cancel.&lt;/p&gt;
&lt;p&gt;Another way to to think about the single-variable chain rule is to visualize the overall expression as a dataflow diagram or chain of operations (or &lt;a href=&quot;https://en.wikipedia.org/wiki/Abstract_syntax_tree&quot;&gt;abstract syntax tree&lt;/a&gt; for compiler people):&lt;/p&gt;
&lt;center&gt;
&lt;p&gt;&lt;img src=&quot;https://explained.ai/matrix-calculus/images/sin-square.png&quot; alt=&quot;sin-square.png&quot; width=&quot;130&quot; /&gt;&lt;/p&gt;
&lt;/center&gt;
&lt;p&gt;Changes to function parameter &lt;span class=&quot;eqn&quot;&gt;x&lt;/span&gt; bubble up through a squaring operation then through a &lt;span class=&quot;eqn&quot;&gt;sin&lt;/span&gt; operation to change result &lt;span class=&quot;eqn&quot;&gt;y&lt;/span&gt;. You can think of &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-B13DB657CBF4B8318DBF2799E687D1A1-depth004.58.svg&quot; /&gt; as “getting changes from &lt;span class=&quot;eqn&quot;&gt;x&lt;/span&gt; to &lt;span class=&quot;eqn&quot;&gt;u&lt;/span&gt;” and &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-6E939E305B65D08F88FF95E7E028796B-depth004.58.svg&quot; /&gt; as “getting changes from &lt;span class=&quot;eqn&quot;&gt;u&lt;/span&gt; to &lt;span class=&quot;eqn&quot;&gt;y&lt;/span&gt;.” Getting from &lt;span class=&quot;eqn&quot;&gt;x&lt;/span&gt; to &lt;span class=&quot;eqn&quot;&gt;y&lt;/span&gt; requires an intermediate hop. The chain rule is, by convention, usually written from the output variable down to the parameter(s), &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-70047C98E4163674E78BB42D0CF4AEA8-depth004.58.svg&quot; /&gt;. But, the &lt;span class=&quot;eqn&quot;&gt;x&lt;/span&gt;-to-&lt;span class=&quot;eqn&quot;&gt;y&lt;/span&gt; perspective would be more clear if we reversed the flow and used the equivalent &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-256F5475DE15D99D8D55FE6F3A15CEA4-depth004.58.svg&quot; /&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Conditions under which the single-variable chain rule applies&lt;/strong&gt;. Notice that there is a single dataflow path from &lt;span class=&quot;eqn&quot;&gt;x&lt;/span&gt; to the root &lt;span class=&quot;eqn&quot;&gt;y&lt;/span&gt;. Changes in &lt;span class=&quot;eqn&quot;&gt;x&lt;/span&gt; can influence output &lt;span class=&quot;eqn&quot;&gt;y&lt;/span&gt; in only one way. That is the condition under which we can apply the single-variable chain rule. An easier condition to remember, though one that's a bit looser, is that none of the intermediate subexpression functions, &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-3BCB9E96DA63C9CDC1E56647C2071688-depth003.25.svg&quot; /&gt; and &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-C6E9D6FA0C33AA632E25E953C6E5C35D-depth003.25.svg&quot; /&gt;, have more than one parameter. Consider &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-026E2EF5E8E6906B6CE75FF6CDB0F14E-depth003.25.svg&quot; /&gt;, which would become &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-A1829C9E1CDCFF4FE0BA9C0E7A70E635-depth003.25.svg&quot; /&gt; after introducing intermediate variable &lt;span class=&quot;eqn&quot;&gt;u&lt;/span&gt;. As we'll see in the next section, &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-2C284C56D6E912E6D71990A11005902E-depth003.25.svg&quot; /&gt; has multiple paths from &lt;span class=&quot;eqn&quot;&gt;x&lt;/span&gt; to &lt;span class=&quot;eqn&quot;&gt;y&lt;/span&gt;. To handle that situation, we'll deploy the single-variable total-derivative chain rule.&lt;/p&gt;
&lt;div readability=&quot;34&quot;&gt;As an aside for those interested in automatic differentiation, papers and library documentation use terminology &lt;em&gt;forward differentiation&lt;/em&gt; and &lt;em&gt;backward differentiation&lt;/em&gt; (for use in the back-propagation algorithm). From a dataflow perspective, we are computing a forward differentiation because it follows the normal data flow direction. Backward differentiation, naturally, goes the other direction and we're asking how a change in the output would affect function parameter &lt;span class=&quot;eqn&quot;&gt;x&lt;/span&gt;. Because backward differentiation can determine changes in all function parameters at once, it turns out to be much more efficient for computing the derivative of functions with lots of parameters. Forward differentiation, on the other hand, must consider how a change in each parameter, in turn, affects the function output &lt;span class=&quot;eqn&quot;&gt;y&lt;/span&gt;. The following table emphasizes the order in which partial derivatives are computed for the two techniques.
&lt;center&gt;
&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th align=&quot;left&quot;&gt;Forward differentiation from &lt;span class=&quot;eqn&quot;&gt;x&lt;/span&gt; to &lt;span class=&quot;eqn&quot;&gt;y&lt;/span&gt;&lt;/th&gt;
&lt;th align=&quot;left&quot;&gt;Backward differentiation from &lt;span class=&quot;eqn&quot;&gt;y&lt;/span&gt; to &lt;span class=&quot;eqn&quot;&gt;x&lt;/span&gt;&lt;/th&gt;
&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td align=&quot;left&quot;&gt;&lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-256F5475DE15D99D8D55FE6F3A15CEA4-depth004.58.svg&quot; /&gt;&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;&lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-70047C98E4163674E78BB42D0CF4AEA8-depth004.58.svg&quot; /&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/center&gt;
&lt;p&gt;Automatic differentiation is beyond the scope of this article, but we're setting the stage for a future article.&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Many readers can solve &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-59B8E919C92D6DBE1DC50C5BE2CD8C1C-depth004.58.svg&quot; /&gt; in their heads, but our goal is a process that will work even for very complicated expressions. This process is also how &lt;a href=&quot;https://en.wikipedia.org/wiki/Automatic_differentiation&quot;&gt;automatic differentiation&lt;/a&gt; works in libraries like PyTorch. So, by solving derivatives manually in this way, you're also learning how to define functions for custom neural networks in PyTorch.&lt;/p&gt;
&lt;p&gt;With deeply nested expressions, it helps to think about deploying the chain rule the way a compiler unravels nested function calls like &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-7559A5FC5EC5CA0B3E50011742D0A87B-depth003.25.svg&quot; /&gt; into a sequence (chain) of calls. The result of calling function &lt;span class=&quot;eqn&quot;&gt;f&lt;sub&gt;i&lt;/sub&gt;&lt;/span&gt; is saved to a temporary variable called a register, which is then passed as a parameter to &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-36930D135F4763C21D1191803AC41B85-depth002.72.svg&quot; /&gt;. Let's see how that looks in practice by using our process on a highly-nested equation like &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-642FD3E590A2B2D21AFE5254BE8E832F-depth003.25.svg&quot; /&gt;:&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;Introduce intermediate variables.
&lt;div&gt;&lt;img class=&quot;blkeqn&quot; src=&quot;https://explained.ai/matrix-calculus/images/blkeqn-A153933499426CFC383D252C30A87953.svg&quot; alt=&quot;&quot; /&gt;&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;Compute derivatives.
&lt;div&gt;&lt;img class=&quot;blkeqn&quot; src=&quot;https://explained.ai/matrix-calculus/images/blkeqn-4561212E91367D4B2DCC40262E36921D.svg&quot; alt=&quot;&quot; /&gt;&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;Combine four intermediate values.
&lt;div&gt;&lt;img class=&quot;blkeqn&quot; src=&quot;https://explained.ai/matrix-calculus/images/blkeqn-2CF824877C0FB75B7648CE66E56FB509.svg&quot; alt=&quot;&quot; /&gt;&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;Substitute.
&lt;div&gt;&lt;img class=&quot;blkeqn&quot; src=&quot;https://explained.ai/matrix-calculus/images/blkeqn-9BC49A78C13740AC58294EAA333AF3CC.svg&quot; alt=&quot;&quot; /&gt;&lt;/div&gt;
&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;Here is a visualization of the data flow through the chain of operations from &lt;span class=&quot;eqn&quot;&gt;x&lt;/span&gt; to &lt;span class=&quot;eqn&quot;&gt;y&lt;/span&gt;:&lt;/p&gt;
&lt;center&gt;
&lt;p&gt;&lt;img src=&quot;https://explained.ai/matrix-calculus/images/chain-tree.png&quot; alt=&quot;chain-tree.png&quot; width=&quot;150&quot; /&gt;&lt;/p&gt;
&lt;/center&gt;
&lt;p&gt;At this point, we can handle derivatives of nested expressions of a single variable, &lt;span class=&quot;eqn&quot;&gt;x&lt;/span&gt;, using the chain rule but only if &lt;span class=&quot;eqn&quot;&gt;x&lt;/span&gt; can affect &lt;span class=&quot;eqn&quot;&gt;y&lt;/span&gt; through a single data flow path. To handle more complicated expressions, we need to extend our technique, which we'll do next.&lt;/p&gt;
&lt;h4 id=&quot;sec4.5.2&quot;&gt;Single-variable total-derivative chain rule&lt;/h4&gt;
&lt;p&gt;Our single-variable chain rule has limited applicability because all intermediate variables must be functions of single variables. But, it demonstrates the core mechanism of the chain rule, that of multiplying out all derivatives of intermediate subexpressions. To handle more general expressions such as &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-4E2EFF28C6823738FA61BFC9A3DD6D0F-depth003.25.svg&quot; /&gt;, however, we need to augment that basic chain rule.&lt;/p&gt;
&lt;p&gt;Of course, we immediately see &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-18EF15EC4DDA421BE5BC86F0295D36CD-depth004.58.svg&quot; /&gt;, but that is using the scalar addition derivative rule, not the chain rule. If we tried to apply the single-variable chain rule, we'd get the wrong answer. In fact, the previous chain rule is meaningless in this case because derivative operator &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-624FEBB9A49A3FC96353C861D175C806-depth004.58.svg&quot; /&gt; does not apply to multivariate functions, such as &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-89AE78BE880A004AA5404AC874A01BFF-depth001.95.svg&quot; /&gt; among our intermediate variables:&lt;/p&gt;
&lt;div&gt;&lt;img class=&quot;blkeqn&quot; src=&quot;https://explained.ai/matrix-calculus/images/blkeqn-5CB23F92FE51ABF1B1885A985EA61BC6.svg&quot; alt=&quot;&quot; /&gt;&lt;/div&gt;
&lt;p&gt;Let's try it anyway to see what happens. If we pretend that &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-400C939294CFCAC13949F5A92DD9537A-depth005.85.svg&quot; /&gt; and &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-8B1AAFE58A962E6F06775EBD2808D5FE-depth004.58.svg&quot; /&gt;, then &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-69A0BF0F0F217A5C8CDB490B4C60ABEE-depth005.85.svg&quot; /&gt; instead of the right answer &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-632334BF7A82AE1CEB6BF98756648B4E-depth001.06.svg&quot; /&gt;.&lt;/p&gt;
&lt;p&gt;Because &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-3DD76E5D04C44A4E7170558B8BFE3219-depth003.25.svg&quot; /&gt; has multiple parameters, partial derivatives come into play. Let's blindly apply the partial derivative operator to all of our equations and see what we get:&lt;/p&gt;
&lt;div&gt;&lt;img class=&quot;blkeqn&quot; src=&quot;https://explained.ai/matrix-calculus/images/blkeqn-7A7B19296641D8B6B96136527F381589.svg&quot; alt=&quot;&quot; /&gt;&lt;/div&gt;
&lt;p&gt;Ooops! The partial &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-9A001AB7445AD6C36176920C0E5D253F-depth004.67.svg&quot; /&gt; is wrong because it violates a key assumption for partial derivatives. When taking the partial derivative with respect to &lt;span class=&quot;eqn&quot;&gt;x&lt;/span&gt;, the other variables must not vary as &lt;span class=&quot;eqn&quot;&gt;x&lt;/span&gt; varies. Otherwise, we could not act as if the other variables were constants. Clearly, though, &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-0F0BF7F8711E6437357749F43EF529D8-depth003.25.svg&quot; /&gt; is a function of &lt;span class=&quot;eqn&quot;&gt;x&lt;/span&gt; and therefore varies with &lt;span class=&quot;eqn&quot;&gt;x&lt;/span&gt;. &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-78D6E87F2E36D9F4C482E9236F997C4C-depth004.67.svg&quot; /&gt; because &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-C9E3A40CD8239D58296F30B000154F1A-depth004.67.svg&quot; /&gt;. A quick look at the data flow diagram for &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-AC2672C7A79B0E068FB3AC3D7FBF94C9-depth003.25.svg&quot; /&gt; shows multiple paths from &lt;span class=&quot;eqn&quot;&gt;x&lt;/span&gt; to &lt;span class=&quot;eqn&quot;&gt;y&lt;/span&gt;, thus, making it clear we need to consider direct and indirect (through &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-D8F3471EF0522DC14012F0DC5D01D570-depth003.25.svg&quot; /&gt;) dependencies on &lt;span class=&quot;eqn&quot;&gt;x&lt;/span&gt;:&lt;/p&gt;
&lt;center&gt;
&lt;p&gt;&lt;img src=&quot;https://explained.ai/matrix-calculus/images/plus-square.png&quot; alt=&quot;plus-square.png&quot; width=&quot;150&quot; /&gt;&lt;/p&gt;
&lt;/center&gt;
&lt;p&gt;A change in &lt;span class=&quot;eqn&quot;&gt;x&lt;/span&gt; affects &lt;span class=&quot;eqn&quot;&gt;y&lt;/span&gt; both as an operand of the addition and as the operand of the square operator. Here's an equation that describes how tweaks to &lt;span class=&quot;eqn&quot;&gt;x&lt;/span&gt; affect the output:&lt;/p&gt;
&lt;div&gt;&lt;img class=&quot;blkeqn&quot; src=&quot;https://explained.ai/matrix-calculus/images/blkeqn-69B14AB41D9A7514E8C105FDDF9649C5.svg&quot; alt=&quot;&quot; /&gt;&lt;/div&gt;
&lt;p&gt;Then, &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-461DF6ABE0C0386D728B786B3116A5B1-depth002.65.svg&quot; /&gt;, which we can read as “the change in &lt;span class=&quot;eqn&quot;&gt;y&lt;/span&gt; is the difference between the original &lt;span class=&quot;eqn&quot;&gt;y&lt;/span&gt; and &lt;span class=&quot;eqn&quot;&gt;y&lt;/span&gt; at a tweaked &lt;span class=&quot;eqn&quot;&gt;x&lt;/span&gt;.”&lt;/p&gt;
&lt;p&gt;If we let &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-A255512F9D61A6777BD5A304235BD26D-depth000.14.svg&quot; /&gt;, then &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-433AD860B59D47738D7AECAB6367A8AD-depth002.65.svg&quot; /&gt;. If we bump &lt;span class=&quot;eqn&quot;&gt;x&lt;/span&gt; by 1, &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-60BD3A416346416B27D420F8EFEE9C9E-depth000.14.svg&quot; /&gt;, then &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-4DCF3FC9093036B469E832AEDCFDA608-depth003.25.svg&quot; /&gt;. The change in &lt;span class=&quot;eqn&quot;&gt;y&lt;/span&gt; is not &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-C4CA4238A0B923820DCC509A6F75849B-depth000.00.svg&quot; /&gt;, as &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-BE27DFA2B74F7608759BD413AF458EB2-depth003.25.svg&quot; /&gt; would lead us to believe, but &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-F0B6923B35563AE91BDFC8B06222E495-depth001.08.svg&quot; /&gt;!&lt;/p&gt;
&lt;p&gt;Enter the “law” of &lt;a href=&quot;https://en.wikipedia.org/wiki/Total_derivative&quot;&gt;total derivatives&lt;/a&gt;, which basically says that to compute &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-3BAFFD623D24688B6229E8808F4DD24A-depth004.58.svg&quot; /&gt;, we need to sum up all possible contributions from changes in &lt;span class=&quot;eqn&quot;&gt;x&lt;/span&gt; to the change in &lt;span class=&quot;eqn&quot;&gt;y&lt;/span&gt;. The total derivative with respect to &lt;span class=&quot;eqn&quot;&gt;x&lt;/span&gt; assumes all variables, such as &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-D33DEF0EB4933F91B88EB4E784ADAF05-depth001.95.svg&quot; /&gt; in this case, are functions of &lt;span class=&quot;eqn&quot;&gt;x&lt;/span&gt; and potentially vary as &lt;span class=&quot;eqn&quot;&gt;x&lt;/span&gt; varies. The total derivative of &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-20596CA2E264644A086ABF3ABCA89367-depth003.25.svg&quot; /&gt; that depends on &lt;span class=&quot;eqn&quot;&gt;x&lt;/span&gt; directly and indirectly via intermediate variable &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-D8F3471EF0522DC14012F0DC5D01D570-depth003.25.svg&quot; /&gt; is given by:&lt;/p&gt;
&lt;div&gt;&lt;img class=&quot;blkeqn&quot; src=&quot;https://explained.ai/matrix-calculus/images/blkeqn-09EB861D79D7E60D9B37567CE097631B.svg&quot; alt=&quot;&quot; /&gt;&lt;/div&gt;
&lt;p&gt;Using this formula, we get the proper answer:&lt;/p&gt;
&lt;div&gt;&lt;img class=&quot;blkeqn&quot; src=&quot;https://explained.ai/matrix-calculus/images/blkeqn-217390CDB48372744AC16E8277C9D0CC.svg&quot; alt=&quot;&quot; /&gt;&lt;/div&gt;
&lt;p&gt;That is an application of what we can call the &lt;em&gt;single-variable total-derivative chain rule&lt;/em&gt;:&lt;/p&gt;
&lt;div&gt;&lt;img class=&quot;blkeqn&quot; src=&quot;https://explained.ai/matrix-calculus/images/blkeqn-4586E8ADC3AA440DD41501217E7B6E67.svg&quot; alt=&quot;&quot; /&gt;&lt;/div&gt;
&lt;p&gt;The total derivative assumes all variables are potentially codependent whereas the partial derivative assumes all variables but &lt;span class=&quot;eqn&quot;&gt;x&lt;/span&gt; are constants.&lt;/p&gt;
&lt;p&gt;There is something subtle going on here with the notation. All of the derivatives are shown as partial derivatives because &lt;span class=&quot;eqn&quot;&gt;f&lt;/span&gt; and &lt;span class=&quot;eqn&quot;&gt;u&lt;sub&gt;i&lt;/sub&gt;&lt;/span&gt; are functions of multiple variables. This notation mirrors that of &lt;a href=&quot;http://mathworld.wolfram.com/TotalDerivative.html&quot;&gt;MathWorld's notation&lt;/a&gt; but differs from &lt;a href=&quot;https://en.wikipedia.org/wiki/Total_derivative&quot;&gt;Wikipedia&lt;/a&gt;, which uses &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-8A4956B34F845398E8CB25E9789E1477-depth003.25.svg&quot; /&gt; instead (possibly to emphasize the total derivative nature of the equation). We'll stick with the partial derivative notation so that it's consistent with our discussion of the vector chain rule in the next section.&lt;/p&gt;
&lt;p&gt;In practice, just keep in mind that when you take the total derivative with respect to &lt;span class=&quot;eqn&quot;&gt;x&lt;/span&gt;, other variables might also be functions of &lt;span class=&quot;eqn&quot;&gt;x&lt;/span&gt; so add in their contributions as well. The left side of the equation looks like a typical partial derivative but the right-hand side is actually the total derivative. It's common, however, that many temporary variables are functions of a single parameter, which means that the single-variable total-derivative chain rule degenerates to the single-variable chain rule.&lt;/p&gt;
&lt;p&gt;Let's look at a nested subexpression, such as &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-FD3AC7E953C3B294864C747188F6F370-depth003.25.svg&quot; /&gt;. We introduce three intermediate variables:&lt;/p&gt;
&lt;div&gt;&lt;img class=&quot;blkeqn&quot; src=&quot;https://explained.ai/matrix-calculus/images/blkeqn-B5215A178D5EDFCCA280ED63D64A8025.svg&quot; alt=&quot;&quot; /&gt;&lt;/div&gt;
&lt;p&gt;and partials:&lt;/p&gt;
&lt;div&gt;&lt;img class=&quot;blkeqn&quot; src=&quot;https://explained.ai/matrix-calculus/images/blkeqn-C3A02B93F5C0F2C8979E524BB28D35AC.svg&quot; alt=&quot;&quot; /&gt;&lt;/div&gt;
&lt;p&gt;where both &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-A5D73F881FB427D3CD136DA4815CACA4-depth004.67.svg&quot; /&gt; and &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-110F22244D49C5AD607D2BEFE91944A5-depth004.67.svg&quot; /&gt; have &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-4E8A57E5001AA58AEAA927CF98746B9C-depth004.67.svg&quot; /&gt; terms that take into account the total derivative.&lt;/p&gt;
&lt;p&gt;Also notice that the total derivative formula always &lt;strong&gt;sums&lt;/strong&gt; versus, say, multiplies terms &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-935DA2BFCBE67A179A8DAAB35E19A1DA-depth005.92.svg&quot; /&gt;. It's tempting to think that summing up terms in the derivative makes sense because, for example, &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-FCCD52402617C355E7BB85B3336D0142-depth002.65.svg&quot; /&gt; adds two terms. Nope. The total derivative is adding terms because it represents a weighted sum of all &lt;span class=&quot;eqn&quot;&gt;x&lt;/span&gt; contributions to the change in &lt;span class=&quot;eqn&quot;&gt;y&lt;/span&gt;. For example, given &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-5C5A09876AA823C381141FDAC1D28BA6-depth002.65.svg&quot; /&gt; instead of &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-C26DA96086B50304FCE872846D4BE19F-depth002.65.svg&quot; /&gt;, the total-derivative chain rule formula still adds partial derivative terms. (&lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-94E561C972A5FE1DDE82761012FB6DB1-depth001.08.svg&quot; /&gt; simplifies to &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-8C0FB3B076D9AEA142467B34F0F794EB-depth000.14.svg&quot; /&gt; but for this demonstration, let's not combine the terms.) Here are the intermediate variables and partial derivatives:&lt;/p&gt;
&lt;div&gt;&lt;img class=&quot;blkeqn&quot; src=&quot;https://explained.ai/matrix-calculus/images/blkeqn-A1BE672D8676E7C9DE634935C1CDEBBA.svg&quot; alt=&quot;&quot; /&gt;&lt;/div&gt;
&lt;p&gt;The form of the total derivative remains the same, however:&lt;/p&gt;
&lt;div&gt;&lt;img class=&quot;blkeqn&quot; src=&quot;https://explained.ai/matrix-calculus/images/blkeqn-50D1EABA22B46536559D83F8C21F749D.svg&quot; alt=&quot;&quot; /&gt;&lt;/div&gt;
&lt;p&gt;It's the partials (weights) that change, not the formula, when the intermediate variable operators change.&lt;/p&gt;
&lt;p&gt;Those readers with a strong calculus background might wonder why we aggressively introduce intermediate variables even for the non-nested subexpressions such as &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-32F5240D0DBF2CCBE75EF7F8EF2015E0-depth000.14.svg&quot; /&gt; in &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-06671AD4FF442E623460886DA749C797-depth001.06.svg&quot; /&gt;. We use this process for three reasons: (i) computing the derivatives for the simplified subexpressions is usually trivial, (ii) we can simplify the chain rule, and (iii) the process mirrors how automatic differentiation works in neural network libraries.&lt;/p&gt;
&lt;p&gt;Using the intermediate variables even more aggressively, let's see how we can simplify our single-variable total-derivative chain rule to its final form. The goal is to get rid of the &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-F6E0346D1D3410B0FBE32B41B85999AA-depth004.67.svg&quot; /&gt; sticking out on the front like a sore thumb:&lt;/p&gt;
&lt;div&gt;&lt;img class=&quot;blkeqn&quot; src=&quot;https://explained.ai/matrix-calculus/images/blkeqn-D8F0438A2B5867000190B7AB280DDD9A.svg&quot; alt=&quot;&quot; /&gt;&lt;/div&gt;
&lt;p&gt;We can achieve that by simply introducing a new temporary variable as an alias for &lt;span class=&quot;eqn&quot;&gt;x&lt;/span&gt;: &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-80A59ADB26E30571A3056E2EB3E8DDCB-depth002.69.svg&quot; /&gt;. Then, the formula reduces to our final form:&lt;/p&gt;
&lt;div&gt;&lt;img class=&quot;blkeqn&quot; src=&quot;https://explained.ai/matrix-calculus/images/blkeqn-DE79CDE41F7B81D0C8E5D49F3D9766BB.svg&quot; alt=&quot;&quot; /&gt;&lt;/div&gt;
&lt;p&gt;This chain rule that takes into consideration the total derivative degenerates to the single-variable chain rule when all intermediate variables are functions of a single variable. Consequently, you can remember this more general formula to cover both cases. As a bit of dramatic foreshadowing, notice that the summation sure looks like a vector dot product, &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-3F95AED50A8E6A5C514952D767B771CE-depth004.67.svg&quot; /&gt;, or a vector multiply &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-51D7B0B0455FB229AB4920E9CA4AB032-depth004.67.svg&quot; /&gt;.&lt;/p&gt;
&lt;p&gt;Before we move on, a word of caution about terminology on the web. Unfortunately, the chain rule given in this section, based upon the total derivative, is universally called “multivariable chain rule” in calculus discussions, which is highly misleading! Only the intermediate variables are multivariate functions. The overall function, say, &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-A5A7963264669BCFA0CCFA897853A1E0-depth003.25.svg&quot; /&gt;, is a scalar function that accepts a single parameter &lt;span class=&quot;eqn&quot;&gt;x&lt;/span&gt;. The derivative and parameter are scalars, not vectors, as one would expect with a so-called multivariate chain rule. (Within the context of a non-matrix calculus class, “multivariate chain rule” is likely unambiguous.) To reduce confusion, we use “single-variable total-derivative chain rule” to spell out the distinguishing feature between the simple single-variable chain rule, &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-9D3919C42833D1FF1456DEA11D8CC927-depth004.58.svg&quot; /&gt;, and this one.&lt;/p&gt;
&lt;h4 id=&quot;sec4.5.3&quot;&gt;Vector chain rule&lt;/h4&gt;
&lt;p&gt;Now that we've got a good handle on the total-derivative chain rule, we're ready to tackle the chain rule for vectors of functions and vector variables. Surprisingly, this more general chain rule is just as simple looking as the single-variable chain rule for scalars. Rather than just presenting the vector chain rule, let's rediscover it ourselves so we get a firm grip on it. We can start by computing the derivative of a sample vector function with respect to a scalar, &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-82C28F66A012D28717CA0CFC8ED7F09B-depth003.25.svg&quot; /&gt;, to see if we can abstract a general formula.&lt;/p&gt;
&lt;div&gt;&lt;img class=&quot;blkeqn&quot; src=&quot;https://explained.ai/matrix-calculus/images/blkeqn-428F0EFA4C7B2EEC64829258E8DAFF86.svg&quot; alt=&quot;&quot; /&gt;&lt;/div&gt;
&lt;p&gt;Let's introduce two intermediate variables, &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-E11BA37D5D784AF689E175BEC8A2F284-depth002.65.svg&quot; /&gt; and &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-D7F116997176D81A3BBD4E6DFC6FE6B0-depth002.65.svg&quot; /&gt;, one for each &lt;span class=&quot;eqn&quot;&gt;f&lt;sub&gt;i&lt;/sub&gt;&lt;/span&gt; so that &lt;span class=&quot;eqn&quot;&gt;y&lt;/span&gt; looks more like &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-C5AF10997DA85D7540CDF87F1F10016C-depth003.25.svg&quot; /&gt;:&lt;/p&gt;
&lt;div&gt;&lt;img class=&quot;blkeqn&quot; src=&quot;https://explained.ai/matrix-calculus/images/blkeqn-5CE597B34A604EDC0DD0B1AD97CFD690.svg&quot; alt=&quot;&quot; /&gt;&lt;/div&gt;
&lt;div&gt;&lt;img class=&quot;blkeqn&quot; src=&quot;https://explained.ai/matrix-calculus/images/blkeqn-E04563108617169E3793740388785DAB.svg&quot; alt=&quot;&quot; /&gt;&lt;/div&gt;
&lt;p&gt;The derivative of vector &lt;span class=&quot;eqnvec&quot;&gt;y&lt;/span&gt; with respect to scalar &lt;span class=&quot;eqn&quot;&gt;x&lt;/span&gt; is a vertical vector with elements computed using the single-variable total-derivative chain rule:&lt;/p&gt;
&lt;div&gt;&lt;img class=&quot;blkeqn&quot; src=&quot;https://explained.ai/matrix-calculus/images/blkeqn-63BFCE8E2B4E8F603E209ECA0C1DADCE.svg&quot; alt=&quot;&quot; /&gt;&lt;/div&gt;
&lt;p&gt;Ok, so now we have the answer using just the scalar rules, albeit with the derivatives grouped into a vector. Let's try to abstract from that result what it looks like in vector form. The goal is to convert the following vector of scalar operations to a vector operation.&lt;/p&gt;
&lt;div&gt;&lt;img class=&quot;blkeqn&quot; src=&quot;https://explained.ai/matrix-calculus/images/blkeqn-0EA3C72DBB9F820121EE6A27D76EC7CC.svg&quot; alt=&quot;&quot; /&gt;&lt;/div&gt;
&lt;p&gt;If we split the &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-97D1ACA90CB316ED8AE1EDFFAED02C77-depth007.21.svg&quot; /&gt; terms, isolating the &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-D513134B704605A9687A47F8841D7D29-depth004.67.svg&quot; /&gt; terms into a vector, we get a matrix by vector multiplication:&lt;/p&gt;
&lt;div&gt;&lt;img class=&quot;blkeqn&quot; src=&quot;https://explained.ai/matrix-calculus/images/blkeqn-692581F3416029FED8E1CE09890F4A5E.svg&quot; alt=&quot;&quot; /&gt;&lt;/div&gt;
&lt;p&gt;That means that the Jacobian is the multiplication of two other Jacobians, which is kinda cool. Let's check our results:&lt;/p&gt;
&lt;div&gt;&lt;img class=&quot;blkeqn&quot; src=&quot;https://explained.ai/matrix-calculus/images/blkeqn-4A8689EA58BF9FA2AF675AAE0C093010.svg&quot; alt=&quot;&quot; /&gt;&lt;/div&gt;
&lt;p&gt;Whew! We get the same answer as the scalar approach. This vector chain rule for vectors of functions and a single parameter appears to be correct and, indeed, mirrors the single-variable chain rule. Compare the vector rule:&lt;/p&gt;
&lt;div&gt;&lt;img class=&quot;blkeqn&quot; src=&quot;https://explained.ai/matrix-calculus/images/blkeqn-B0D7932C93DA81FD62418DA5DF3CBE14.svg&quot; alt=&quot;&quot; /&gt;&lt;/div&gt;
&lt;p&gt;with the single-variable chain rule:&lt;/p&gt;
&lt;div&gt;&lt;img class=&quot;blkeqn&quot; src=&quot;https://explained.ai/matrix-calculus/images/blkeqn-8617320E088DCA9EC6795865C614324A.svg&quot; alt=&quot;&quot; /&gt;&lt;/div&gt;
&lt;p&gt;To make this formula work for multiple parameters or vector &lt;span class=&quot;eqnvec&quot;&gt;x&lt;/span&gt;, we just have to change &lt;span class=&quot;eqn&quot;&gt;x&lt;/span&gt; to vector &lt;span class=&quot;eqnvec&quot;&gt;x&lt;/span&gt; in the equation. The effect is that &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-A24633DDE0B5346B4AE6B49395AC8B6D-depth004.67.svg&quot; /&gt; and the resulting Jacobian, &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-A9A13E2AE753365278B4F2CD198BBF92-depth004.67.svg&quot; /&gt;, are now matrices instead of vertical vectors. Our complete &lt;em&gt;vector chain rule&lt;/em&gt; is:&lt;/p&gt;
&lt;div&gt;&lt;img class=&quot;blkeqn&quot; src=&quot;https://explained.ai/matrix-calculus/images/blkeqn-63A95E8A883CCB871C2C68B2D8B6EAA4.svg&quot; alt=&quot;&quot; /&gt;&lt;/div&gt;
&lt;p&gt;The beauty of the vector formula over the single-variable chain rule is that it automatically takes into consideration the total derivative while maintaining the same notational simplicity. The Jacobian contains all possible combinations of &lt;span class=&quot;eqn&quot;&gt;f&lt;sub&gt;i&lt;/sub&gt;&lt;/span&gt; with respect to &lt;span class=&quot;eqn&quot;&gt;g&lt;sub&gt;j&lt;/sub&gt;&lt;/span&gt; and &lt;span class=&quot;eqn&quot;&gt;g&lt;sub&gt;i&lt;/sub&gt;&lt;/span&gt; with respect to &lt;span class=&quot;eqn&quot;&gt;x&lt;sub&gt;j&lt;/sub&gt;&lt;/span&gt;. For completeness, here are the two Jacobian components in their full glory:&lt;/p&gt;
&lt;div&gt;&lt;img class=&quot;blkeqn&quot; src=&quot;https://explained.ai/matrix-calculus/images/blkeqn-875D6B48E0F3610A491D91FA12067AED.svg&quot; alt=&quot;&quot; /&gt;&lt;/div&gt;
&lt;p&gt;where &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-99ADCB62C02EE5D10CC7B5F211BFA15B-depth003.25.svg&quot; /&gt;, &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-6E37471488C004C0ABACDF4148B8F3D6-depth003.25.svg&quot; /&gt;, and &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-26312045D51B3E69C8357FF7FAF3BB3F-depth003.25.svg&quot; /&gt;. The resulting Jacobian is &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-FBFEB9C8459FEE5A2BD529C07B881153-depth001.08.svg&quot; /&gt; (an &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-2DC13003CC069B1027F12896B1A00631-depth001.08.svg&quot; /&gt; matrix multiplied by a &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-6D999BBC8A6ECBB820C04121088529A1-depth001.08.svg&quot; /&gt; matrix).&lt;/p&gt;
&lt;p&gt;Even within this &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-A7896E2D919F33CF607DC9E972C70458-depth006.23.svg&quot; /&gt; formula, we can simplify further because, for many applications, the Jacobians are square (&lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-A193EBC083B4745370F6F1343383D9CC-depth000.14.svg&quot; /&gt;) and the off-diagonal entries are zero. It is the nature of neural networks that the associated mathematics deals with functions of vectors not vectors of functions. For example, the neuron affine function has term &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-DE94554BD6F158BD8A829624C65169F4-depth003.25.svg&quot; /&gt; and the activation function is &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-EA2DFCC1C759A6D2EE675EBD05B2C593-depth003.25.svg&quot; /&gt;; we'll consider derivatives of these functions in the next section.&lt;/p&gt;
&lt;p&gt;As we saw in a previous section, element-wise operations on vectors &lt;span class=&quot;eqnvec&quot;&gt;w&lt;/span&gt; and &lt;span class=&quot;eqnvec&quot;&gt;x&lt;/span&gt; yield diagonal matrices with elements &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-D840B92230E9F1C5F2545BCA90B34038-depth005.92.svg&quot; /&gt; because &lt;span class=&quot;eqn&quot;&gt;w&lt;sub&gt;i&lt;/sub&gt;&lt;/span&gt; is a function purely of &lt;span class=&quot;eqn&quot;&gt;x&lt;sub&gt;i&lt;/sub&gt;&lt;/span&gt; but not &lt;span class=&quot;eqn&quot;&gt;x&lt;sub&gt;j&lt;/sub&gt;&lt;/span&gt; for &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-B064F8555EC660F2F8BDC927D9636A06-depth002.72.svg&quot; /&gt;. The same thing happens here when &lt;span class=&quot;eqn&quot;&gt;f&lt;sub&gt;i&lt;/sub&gt;&lt;/span&gt; is purely a function of &lt;span class=&quot;eqn&quot;&gt;g&lt;sub&gt;i&lt;/sub&gt;&lt;/span&gt; and &lt;span class=&quot;eqn&quot;&gt;g&lt;sub&gt;i&lt;/sub&gt;&lt;/span&gt; is purely a function of &lt;span class=&quot;eqn&quot;&gt;x&lt;sub&gt;i&lt;/sub&gt;&lt;/span&gt;:&lt;/p&gt;
&lt;div&gt;&lt;img class=&quot;blkeqn&quot; src=&quot;https://explained.ai/matrix-calculus/images/blkeqn-4869BA6DCF2C9A404EECD993808A74B7.svg&quot; alt=&quot;&quot; /&gt;&lt;/div&gt;
&lt;div&gt;&lt;img class=&quot;blkeqn&quot; src=&quot;https://explained.ai/matrix-calculus/images/blkeqn-8866C26258F279CD69740D3A26C0CD90.svg&quot; alt=&quot;&quot; /&gt;&lt;/div&gt;
&lt;p&gt;In this situation, the vector chain rule simplifies to:&lt;/p&gt;
&lt;div&gt;&lt;img class=&quot;blkeqn&quot; src=&quot;https://explained.ai/matrix-calculus/images/blkeqn-2D82A2CFEA0A49E9B7D3C8F986DAF14A.svg&quot; alt=&quot;&quot; /&gt;&lt;/div&gt;
&lt;p&gt;Therefore, the Jacobian reduces to a diagonal matrix whose elements are the single-variable chain rule values.&lt;/p&gt;
&lt;p&gt;After slogging through all of that mathematics, here's the payoff. All you need is the vector chain rule because the single-variable formulas are special cases of the vector chain rule. The following table summarizes the appropriate components to multiply in order to get the Jacobian.&lt;/p&gt;
&lt;div&gt;&lt;img class=&quot;blkeqn&quot; src=&quot;https://explained.ai/matrix-calculus/images/latex-17BE59DB8766A07658ADAA8522995C53.svg&quot; alt=&quot; \begin{tabular}[t]{c|cccc} &amp;amp; \multicolumn{2}{c}{ \begin{tabular}[t]{c} scalar\ \framebox(18,18){$x$}\ \end{tabular}} &amp;amp; &amp;amp;\begin{tabular}{c} vector\ \framebox(18,40){$\mathbf{x}$}\ \end{tabular} \ \begin{tabular}{c}$\frac{\partial}{\partial \mathbf{x}} \mathbf{f}(\mathbf{g}(\mathbf{x}))$ = $\frac{\partial \mathbf{f}}{\partial \mathbf{g}}\frac{\partial\mathbf{g}}{\partial \mathbf{x}}$ \ \end{tabular} &amp;amp; \begin{tabular}[t]{c} scalar\ \framebox(18,18){$u$}\ \end{tabular} &amp;amp; \begin{tabular}{c} vector\ \framebox(18,40){$\mathbf{u}$} \end{tabular}&amp;amp; &amp;amp; \begin{tabular}{c} vector\ \framebox(18,40){$\mathbf{u}$}\ \end{tabular} \ \hline \\[\dimexpr-\normalbaselineskip+5pt] \begin{tabular}[b]{c} scalar\ \framebox(18,18){$f$}\ \end{tabular} &amp;amp;\framebox(18,18){$\frac{\partial f}{\partial {u}}$} \framebox(18,18){$\frac{\partial u}{\partial {x}}$} ~~~&amp;amp; \raisebox{22pt}{\framebox(40,18){$\frac{\partial f}{\partial {\mathbf{u}}}$}} \framebox(18,40){$\frac{\partial \mathbf{u}}{\partial x}$} &amp;amp; ~~~&amp;amp; \raisebox{22pt}{\framebox(40,18){$\frac{\partial f}{\partial {\mathbf{u}}}$}} \framebox(40,40){$\frac{\partial \mathbf{u}}{\partial \mathbf{x}}$} \ \begin{tabular}[b]{c} vector\ \framebox(18,40){$\mathbf{f}$}\ \end{tabular} &amp;amp; \framebox(18,40){$\frac{\partial \mathbf{f}}{\partial {u}}$} \raisebox{22pt}{\framebox(18,18){$\frac{\partial u}{\partial {x}}$}} &amp;amp; \framebox(40,40){$\frac{\partial \mathbf{f}}{\partial \mathbf{u}}$} \framebox(18,40){$\frac{\partial \mathbf{u}}{\partial x}$} &amp;amp; &amp;amp; \framebox(40,40){$\frac{\partial \mathbf{f}}{\partial \mathbf{u}}$} \framebox(40,40){$\frac{\partial \mathbf{u}}{\partial \mathbf{x}}$}\ \end{tabular} &quot; /&gt;&lt;/div&gt;
&lt;h2 id=&quot;sec5&quot;&gt;The gradient of neuron activation&lt;/h2&gt;
&lt;p&gt;We now have all of the pieces needed to compute the derivative of a typical neuron activation for a single neural network computation unit with respect to the model parameters, &lt;span class=&quot;eqnvec&quot;&gt;w&lt;/span&gt; and &lt;span class=&quot;eqn&quot;&gt;b&lt;/span&gt;:&lt;/p&gt;
&lt;div&gt;&lt;img class=&quot;blkeqn&quot; src=&quot;https://explained.ai/matrix-calculus/images/blkeqn-F3041D1B0AB2DA26CFE6581CCE10BF0F.svg&quot; alt=&quot;&quot; /&gt;&lt;/div&gt;
&lt;p&gt;(This represents a neuron with fully connected weights and rectified linear unit activation. There are, however, other affine functions such as convolution and other activation functions, such as exponential linear units, that follow similar logic.)&lt;/p&gt;
&lt;p&gt;Let's worry about &lt;span class=&quot;eqn&quot;&gt;max&lt;/span&gt; later and focus on computing &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-37826EBEE16CD487A60FA876F5038265-depth004.67.svg&quot; /&gt; and &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-45DA2FE78D565E2361F35FF898D806A8-depth004.67.svg&quot; /&gt;. (Recall that neural networks learn through optimization of their weights and biases.) We haven't discussed the derivative of the dot product yet, &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-31E193E45068EDA5F2E229B246720968-depth003.25.svg&quot; /&gt;, but we can use the chain rule to avoid having to memorize yet another rule. (Note notation &lt;span class=&quot;eqn&quot;&gt;y&lt;/span&gt; not &lt;span class=&quot;eqnvec&quot;&gt;y&lt;/span&gt; as the result is a scalar not a vector.)&lt;/p&gt;
&lt;p&gt;The dot product &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-9CA8C3CD16894AF7620468A20C53D6FA-depth000.00.svg&quot; /&gt; is just the summation of the element-wise multiplication of the elements: &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-4B722CF0EFB8F8ABCBB968086BB587E8-depth003.31.svg&quot; /&gt;. (You might also find it useful to remember the linear algebra notation &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-DE393E92B808CB595831DB7AF0D46F39-depth000.00.svg&quot; /&gt;.) We know how to compute the partial derivatives of &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-1B8AC0FD13AAD81B7EFBE58CDD162D02-depth003.25.svg&quot; /&gt; and &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-68EE6C0B6C39602AC2A620854B5785B2-depth001.08.svg&quot; /&gt; but haven't looked at partial derivatives for &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-307751654E2CF1B689CE1D06776B3934-depth003.25.svg&quot; /&gt;. We need the chain rule for that and so we can introduce an intermediate vector variable &lt;span class=&quot;eqnvec&quot;&gt;u&lt;/span&gt; just as we did using the single-variable chain rule:&lt;/p&gt;
&lt;div&gt;&lt;img class=&quot;blkeqn&quot; src=&quot;https://explained.ai/matrix-calculus/images/blkeqn-AA40E45F705402308665F4778260405C.svg&quot; alt=&quot;&quot; /&gt;&lt;/div&gt;
&lt;p&gt;Once we've rephrased &lt;span class=&quot;eqn&quot;&gt;y&lt;/span&gt;, we recognize two subexpressions for which we already know the partial derivatives:&lt;/p&gt;
&lt;div&gt;&lt;img class=&quot;blkeqn&quot; src=&quot;https://explained.ai/matrix-calculus/images/blkeqn-CB86F7761DC5757FCE7D9B440DEB6630.svg&quot; alt=&quot;&quot; /&gt;&lt;/div&gt;
&lt;p&gt;The vector chain rule says to multiply the partials:&lt;/p&gt;
&lt;div&gt;&lt;img class=&quot;blkeqn&quot; src=&quot;https://explained.ai/matrix-calculus/images/blkeqn-735EE304812513469D0BAE8D1D32E578.svg&quot; alt=&quot;&quot; /&gt;&lt;/div&gt;
&lt;p&gt;To check our results, we can grind the dot product down into a pure scalar function:&lt;/p&gt;
&lt;div&gt;&lt;img class=&quot;blkeqn&quot; src=&quot;https://explained.ai/matrix-calculus/images/blkeqn-8E233C707CFA165FFECCE145E88AEB24.svg&quot; alt=&quot;&quot; /&gt;&lt;/div&gt;
&lt;p&gt;Then:&lt;/p&gt;
&lt;div&gt;&lt;img class=&quot;blkeqn&quot; src=&quot;https://explained.ai/matrix-calculus/images/blkeqn-44FAB0E50B6FA0C7012FF79FB03EBD14.svg&quot; alt=&quot;&quot; /&gt;&lt;/div&gt;
&lt;p&gt;Hooray! Our scalar results match the vector chain rule results.&lt;/p&gt;
&lt;p&gt;Now, let &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-EABE2A2F7035C793F48B3885A2EA0009-depth002.65.svg&quot; /&gt;, the full expression within the &lt;span class=&quot;eqn&quot;&gt;max&lt;/span&gt; activation function call. We have two different partials to compute, but we don't need the chain rule:&lt;/p&gt;
&lt;div&gt;&lt;img class=&quot;blkeqn&quot; src=&quot;https://explained.ai/matrix-calculus/images/blkeqn-0F1D53EBF96D7DC463E2226B77812776.svg&quot; alt=&quot;&quot; /&gt;&lt;/div&gt;
&lt;p&gt;Let's tackle the partials of the neuron activation, &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-602D78206C69DAFE86EDC0775CF04CDB-depth003.25.svg&quot; /&gt;. The use of the &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-2E8B663420C79458FF788F7C8F198AA2-depth003.25.svg&quot; /&gt; function call on scalar &lt;span class=&quot;eqn&quot;&gt;z&lt;/span&gt; just says to treat all negative &lt;span class=&quot;eqn&quot;&gt;z&lt;/span&gt; values as 0. The derivative of the max function is a piecewise function. When &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-B960DEAE3DC80FA85FEA3304A9474DB5-depth001.72.svg&quot; /&gt;, the derivative is 0 because &lt;span class=&quot;eqn&quot;&gt;z&lt;/span&gt; is a constant. When &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-E929E61EB1C05B5B7AC234027C595BE2-depth001.05.svg&quot; /&gt;, the derivative of the max function is just the derivative of &lt;span class=&quot;eqn&quot;&gt;z&lt;/span&gt;, which is &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-C4CA4238A0B923820DCC509A6F75849B-depth000.00.svg&quot; /&gt;:&lt;/p&gt;
&lt;div&gt;&lt;img class=&quot;blkeqn&quot; src=&quot;https://explained.ai/matrix-calculus/images/blkeqn-61BE19B395EB3114577B2100997DFB6D.svg&quot; alt=&quot;&quot; /&gt;&lt;/div&gt;
&lt;div readability=&quot;18&quot;&gt;An aside on broadcasting functions across scalars. When one or both of the &lt;span class=&quot;eqn&quot;&gt;max&lt;/span&gt; arguments are vectors, such as &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-EA2DFCC1C759A6D2EE675EBD05B2C593-depth003.25.svg&quot; /&gt;, we broadcast the single-variable function &lt;span class=&quot;eqn&quot;&gt;max&lt;/span&gt; across the elements. This is an example of an element-wise unary operator. Just to be clear:
&lt;div&gt;&lt;img class=&quot;blkeqn&quot; src=&quot;https://explained.ai/matrix-calculus/images/blkeqn-94240FE4B77DEE9DA38F596CD4149F9D.svg&quot; alt=&quot;&quot; /&gt;&lt;/div&gt;
&lt;p&gt;For the derivative of the broadcast version then, we get a vector of zeros and ones where:&lt;/p&gt;
&lt;div&gt;&lt;img class=&quot;blkeqn&quot; src=&quot;https://explained.ai/matrix-calculus/images/blkeqn-5B3555A4691C5DA19688E4F76BA1C3AD.svg&quot; alt=&quot;&quot; /&gt;&lt;/div&gt;
&lt;div&gt;&lt;img class=&quot;blkeqn&quot; src=&quot;https://explained.ai/matrix-calculus/images/blkeqn-4EA88847E78682CFDBCA0019C1623945.svg&quot; alt=&quot;&quot; /&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;To get the derivative of the &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-FD043EAC3999F8DEAF1FF1E131B3346C-depth003.25.svg&quot; /&gt; function, we need the chain rule because of the nested subexpression, &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-6C156670CEC09096976A6722592523F3-depth001.06.svg&quot; /&gt;. Following our process, let's introduce intermediate scalar variable &lt;span class=&quot;eqn&quot;&gt;z&lt;/span&gt; to represent the affine function giving:&lt;/p&gt;
&lt;div&gt;&lt;img class=&quot;blkeqn&quot; src=&quot;https://explained.ai/matrix-calculus/images/blkeqn-261BC49758F84DF99117345CD8D22CFE.svg&quot; alt=&quot;&quot; /&gt;&lt;/div&gt;
&lt;div&gt;&lt;img class=&quot;blkeqn&quot; src=&quot;https://explained.ai/matrix-calculus/images/blkeqn-9E429AF61D15BF6942A3132FABAC77A2.svg&quot; alt=&quot;&quot; /&gt;&lt;/div&gt;
&lt;p&gt;The vector chain rule tells us:&lt;/p&gt;
&lt;div&gt;&lt;img class=&quot;blkeqn&quot; src=&quot;https://explained.ai/matrix-calculus/images/blkeqn-B0C84C12426A7A698FBBCB890502411F.svg&quot; alt=&quot;&quot; /&gt;&lt;/div&gt;
&lt;p&gt;which we can rewrite as follows:&lt;/p&gt;
&lt;div&gt;&lt;img class=&quot;blkeqn&quot; src=&quot;https://explained.ai/matrix-calculus/images/blkeqn-AE892FF5E074073E025BB3BBE586B9F5.svg&quot; alt=&quot;&quot; /&gt;&lt;/div&gt;
&lt;p&gt;and then substitute &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-F394C21EEE331911707D5EDBD9BCAE20-depth001.06.svg&quot; /&gt; back in:&lt;/p&gt;
&lt;div&gt;&lt;img class=&quot;blkeqn&quot; src=&quot;https://explained.ai/matrix-calculus/images/blkeqn-A123AAABD8432822C27BEE74393F78AD.svg&quot; alt=&quot;&quot; /&gt;&lt;/div&gt;
&lt;p&gt;That equation matches our intuition. When the activation function clips affine function output &lt;span class=&quot;eqn&quot;&gt;z&lt;/span&gt; to 0, the derivative is zero with respect to any weight &lt;span class=&quot;eqn&quot;&gt;w&lt;sub&gt;i&lt;/sub&gt;&lt;/span&gt;. When &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-E929E61EB1C05B5B7AC234027C595BE2-depth001.05.svg&quot; /&gt;, it's as if the &lt;span class=&quot;eqn&quot;&gt;max&lt;/span&gt; function disappears and we get just the derivative of &lt;span class=&quot;eqn&quot;&gt;z&lt;/span&gt; with respect to the weights.&lt;/p&gt;
&lt;p&gt;Turning now to the derivative of the neuron activation with respect to &lt;span class=&quot;eqn&quot;&gt;b&lt;/span&gt;, we get:&lt;/p&gt;
&lt;div&gt;&lt;img class=&quot;blkeqn&quot; src=&quot;https://explained.ai/matrix-calculus/images/blkeqn-9CE42F7BD715F354A87DF9043310E3BB.svg&quot; alt=&quot;&quot; /&gt;&lt;/div&gt;
&lt;p&gt;Let's use these partial derivatives now to handle the entire loss function.&lt;/p&gt;
&lt;h2 id=&quot;sec6&quot;&gt;The gradient of the neural network loss function&lt;/h2&gt;
&lt;p&gt;Training a neuron requires that we take the derivative of our loss or “cost” function with respect to the parameters of our model, &lt;span class=&quot;eqnvec&quot;&gt;w&lt;/span&gt; and &lt;span class=&quot;eqn&quot;&gt;b&lt;/span&gt;. Because we train with multiple vector inputs (e.g., multiple images) and scalar targets (e.g., one classification per image), we need some more notation. Let&lt;/p&gt;
&lt;div&gt;&lt;img class=&quot;blkeqn&quot; src=&quot;https://explained.ai/matrix-calculus/images/blkeqn-D9D9E4DA80EA78BCCCDDC0BE89A198CD.svg&quot; alt=&quot;&quot; /&gt;&lt;/div&gt;
&lt;p&gt;where &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-BEDD04B41054D234623B0BB3759ABF73-depth003.25.svg&quot; /&gt;, and then let&lt;/p&gt;
&lt;div&gt;&lt;img class=&quot;blkeqn&quot; src=&quot;https://explained.ai/matrix-calculus/images/blkeqn-F924EBF36B5E655648826C8AE83DE16D.svg&quot; alt=&quot;&quot; /&gt;&lt;/div&gt;
&lt;p&gt;where &lt;span class=&quot;eqn&quot;&gt;y&lt;sub&gt;i&lt;/sub&gt;&lt;/span&gt; is a scalar. Then the cost equation becomes:&lt;/p&gt;
&lt;div&gt;&lt;img class=&quot;blkeqn&quot; src=&quot;https://explained.ai/matrix-calculus/images/blkeqn-3D04A32BFDCD990F21451D8230C46FB1.svg&quot; alt=&quot;&quot; /&gt;&lt;/div&gt;
&lt;p&gt;Following our chain rule process introduces these intermediate variables:&lt;/p&gt;
&lt;div&gt;&lt;img class=&quot;blkeqn&quot; src=&quot;https://explained.ai/matrix-calculus/images/blkeqn-ED01A1463E7C7657E0DD1546F6C48BFB.svg&quot; alt=&quot;&quot; /&gt;&lt;/div&gt;
&lt;p&gt;Let's compute the gradient with respect to &lt;span class=&quot;eqnvec&quot;&gt;w&lt;/span&gt; first.&lt;/p&gt;
&lt;h3 id=&quot;sec6.1&quot;&gt;The gradient with respect to the weights&lt;/h3&gt;
&lt;p&gt;From before, we know:&lt;/p&gt;
&lt;div&gt;&lt;img class=&quot;blkeqn&quot; src=&quot;https://explained.ai/matrix-calculus/images/blkeqn-577C100C01A97DEA7FB361169DA383B5.svg&quot; alt=&quot;&quot; /&gt;&lt;/div&gt;
&lt;p&gt;and&lt;/p&gt;
&lt;div&gt;&lt;img class=&quot;blkeqn&quot; src=&quot;https://explained.ai/matrix-calculus/images/blkeqn-8E94E788919EA6D0BE11C2615A11C009.svg&quot; alt=&quot;&quot; /&gt;&lt;/div&gt;
&lt;p&gt;Then, for the overall gradient, we get:&lt;/p&gt;
&lt;div&gt;&lt;img class=&quot;blkeqn&quot; src=&quot;https://explained.ai/matrix-calculus/images/latex-9F8112A77C51E95057A9E56D29FFB669.svg&quot; alt=&quot; \begin{eqnarray*} \frac{\partial C(v)}{\partial \mathbf{w}} &amp;amp; = &amp;amp; \frac{\partial }{\partial \mathbf{w}}\frac{1}{N} \sum_{i=1}^N v^2\\\ &amp;amp; = &amp;amp; \frac{1}{N} \sum_{i=1}^N \frac{\partial}{\partial \mathbf{w}} v^2\\\ &amp;amp; = &amp;amp; \frac{1}{N} \sum_{i=1}^N \frac{\partial v^2}{\partial v} \frac{\partial v}{\partial \mathbf{w}} \\\ &amp;amp; = &amp;amp; \frac{1}{N} \sum_{i=1}^N 2v \frac{\partial v}{\partial \mathbf{w}} \\\ &amp;amp; = &amp;amp; \frac{1}{N} \sum_{i=1}^N \begin{cases} 2v\vec{0}^T = \vec{0}^T &amp;amp; \mathbf{w} \cdot \mathbf{x}_i + b \leq 0\ -2v\mathbf{x}^T &amp;amp; \mathbf{w} \cdot \mathbf{x}_i + b &amp;gt; 0\ \end{cases}\\\ &amp;amp; = &amp;amp; \frac{1}{N} \sum_{i=1}^N \begin{cases} \vec{0}^T &amp;amp; \mathbf{w} \cdot \mathbf{x}_i + b \leq 0\ -2(y_i-u)\mathbf{x}_i^T &amp;amp; \mathbf{w} \cdot \mathbf{x}_i + b &amp;gt; 0\ \end{cases}\\\ &amp;amp; = &amp;amp; \frac{1}{N} \sum_{i=1}^N \begin{cases} \vec{0}^T &amp;amp; \mathbf{w} \cdot \mathbf{x}_i + b \leq 0\ -2(y_i-max(0, \mathbf{w}\cdot\mathbf{x}_i+b))\mathbf{x}_i^T &amp;amp; \mathbf{w} \cdot \mathbf{x}_i + b &amp;gt; 0\ \end{cases}\ \phantom{\frac{\partial C(v)}{\partial \mathbf{w}}} &amp;amp; = &amp;amp; \frac{1}{N} \sum_{i=1}^N \begin{cases} \vec{0}^T &amp;amp; \mathbf{w} \cdot \mathbf{x}_i + b \leq 0\ -2(y_i-(\mathbf{w}\cdot\mathbf{x}_i+b))\mathbf{x}_i^T &amp;amp; \mathbf{w} \cdot \mathbf{x}_i + b &amp;gt; 0\ \end{cases}\\\ &amp;amp; = &amp;amp; \begin{cases} \vec{0}^T &amp;amp; \mathbf{w} \cdot \mathbf{x}_i + b \leq 0\ \frac{-2}{N} \sum_{i=1}^N (y_i-(\mathbf{w}\cdot\mathbf{x}_i+b))\mathbf{x}_i^T &amp;amp; \mathbf{w} \cdot \mathbf{x}_i + b &amp;gt; 0\ \end{cases}\\\ &amp;amp; = &amp;amp; \begin{cases} \vec{0}^T &amp;amp; \mathbf{w} \cdot \mathbf{x}_i + b \leq 0\ \frac{2}{N} \sum_{i=1}^N (\mathbf{w}\cdot\mathbf{x}_i+b-y_i)\mathbf{x}_i^T &amp;amp; \mathbf{w} \cdot \mathbf{x}_i + b &amp;gt; 0\ \end{cases} \end{eqnarray*} &quot; /&gt;&lt;/div&gt;
&lt;p&gt;To interpret that equation, we can substitute an error term &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-A90A948C72E3B6E10EF49E9CA3323248-depth002.65.svg&quot; /&gt; yielding:&lt;/p&gt;
&lt;div&gt;&lt;img class=&quot;blkeqn&quot; src=&quot;https://explained.ai/matrix-calculus/images/blkeqn-6F2CDC50A69419550C3127B318DB71CD.svg&quot; alt=&quot;&quot; /&gt;&lt;/div&gt;
&lt;p&gt;From there, notice that this computation is a weighted average across all &lt;span class=&quot;eqnvec&quot;&gt;x&lt;/span&gt;&lt;sub class=&quot;eqn&quot;&gt;i&lt;/sub&gt; in &lt;span class=&quot;eqn&quot;&gt;X&lt;/span&gt;. The weights are the error terms, the difference between the target output and the actual neuron output for each &lt;span class=&quot;eqnvec&quot;&gt;x&lt;/span&gt;&lt;sub class=&quot;eqn&quot;&gt;i&lt;/sub&gt; input. The resulting gradient will, on average, point in the direction of higher cost or loss because large &lt;span class=&quot;eqn&quot;&gt;e&lt;sub&gt;i&lt;/sub&gt;&lt;/span&gt; emphasize their associated &lt;span class=&quot;eqnvec&quot;&gt;x&lt;/span&gt;&lt;sub class=&quot;eqn&quot;&gt;i&lt;/sub&gt;. Imagine we only had one input vector, &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-75147DC2E59AB7AF04E48C0E3C2D71EA-depth003.25.svg&quot; /&gt;, then the gradient is just &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-26DDD7C22F3D8F5B07FC7EE421EEE6ED-depth003.45.svg&quot; /&gt;. If the error is 0, then the gradient is zero and we have arrived at the minimum loss. If &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-3104BCC503B3B8C16FFA2940B56AAF1C-depth001.95.svg&quot; /&gt; is some small positive difference, the gradient is a small step in the direction of &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-262A3BD0318D5034272A8F904D6FAD24-depth001.95.svg&quot; /&gt;. If &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-3104BCC503B3B8C16FFA2940B56AAF1C-depth001.95.svg&quot; /&gt; is large, the gradient is a large step in that direction. If &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-3104BCC503B3B8C16FFA2940B56AAF1C-depth001.95.svg&quot; /&gt; is negative, the gradient is reversed, meaning the highest cost is in the negative direction.&lt;/p&gt;
&lt;p&gt;Of course, we want to reduce, not increase, the loss, which is why the &lt;a href=&quot;https://en.wikipedia.org/wiki/Gradient_descent&quot;&gt;gradient descent&lt;/a&gt; recurrence relation takes the negative of the gradient to update the current position (for scalar learning rate &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-FFE9F913124F345732E9F00FA258552E-depth002.65.svg&quot; /&gt;):&lt;/p&gt;
&lt;div&gt;&lt;img class=&quot;blkeqn&quot; src=&quot;https://explained.ai/matrix-calculus/images/blkeqn-C50B63069D6F8CA47A43A8116F4AD21B.svg&quot; alt=&quot;&quot; /&gt;&lt;/div&gt;
&lt;p&gt;Because the gradient indicates the direction of higher cost, we want to update &lt;span class=&quot;eqnvec&quot;&gt;x&lt;/span&gt; in the opposite direction.&lt;/p&gt;
&lt;h3 id=&quot;sec6.2&quot;&gt;The derivative with respect to the bias&lt;/h3&gt;
&lt;p&gt;To optimize the bias, &lt;span class=&quot;eqn&quot;&gt;b&lt;/span&gt;, we also need the partial with respect to &lt;span class=&quot;eqn&quot;&gt;b&lt;/span&gt;. Here are the intermediate variables again:&lt;/p&gt;
&lt;div&gt;&lt;img class=&quot;blkeqn&quot; src=&quot;https://explained.ai/matrix-calculus/images/blkeqn-18067E5F73988B179A304788A7BC5786.svg&quot; alt=&quot;&quot; /&gt;&lt;/div&gt;
&lt;p&gt;We computed the partial with respect to the bias for equation &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-FBD5708C00E92A391A69A42591580BE0-depth003.25.svg&quot; /&gt; previously:&lt;/p&gt;
&lt;div&gt;&lt;img class=&quot;blkeqn&quot; src=&quot;https://explained.ai/matrix-calculus/images/blkeqn-97F6B2C0D2E31579875BAE3E458BF333.svg&quot; alt=&quot;&quot; /&gt;&lt;/div&gt;
&lt;p&gt;For &lt;span class=&quot;eqn&quot;&gt;v&lt;/span&gt;, the partial is:&lt;/p&gt;
&lt;div&gt;&lt;img class=&quot;blkeqn&quot; src=&quot;https://explained.ai/matrix-calculus/images/blkeqn-8C418D6F20C9CD5F0C56184F94005AF3.svg&quot; alt=&quot;&quot; /&gt;&lt;/div&gt;
&lt;p&gt;And for the partial of the cost function itself we get:&lt;/p&gt;
&lt;div&gt;&lt;img class=&quot;blkeqn&quot; src=&quot;https://explained.ai/matrix-calculus/images/latex-D2EB5E709D4D4474EDB3DE6699F91F9A.svg&quot; alt=&quot; \begin{eqnarray*} \frac{\partial C(v)}{\partial b} &amp;amp; = &amp;amp; \frac{\partial }{\partial b}\frac{1}{N} \sum_{i=1}^N v^2\\\ &amp;amp; = &amp;amp; \frac{1}{N} \sum_{i=1}^N \frac{\partial}{\partial b} v^2\\\ &amp;amp; = &amp;amp; \frac{1}{N} \sum_{i=1}^N \frac{\partial v^2}{\partial v} \frac{\partial v}{\partial b} \\\ &amp;amp; = &amp;amp; \frac{1}{N} \sum_{i=1}^N 2v \frac{\partial v}{\partial b} \\\ &amp;amp; = &amp;amp; \frac{1}{N} \sum_{i=1}^N \begin{cases} 0 &amp;amp; \mathbf{w} \cdot \mathbf{x} + b \leq 0\ -2v &amp;amp; \mathbf{w} \cdot \mathbf{x} + b &amp;gt; 0\ \end{cases}\\\ &amp;amp; = &amp;amp; \frac{1}{N} \sum_{i=1}^N \begin{cases} 0 &amp;amp; \mathbf{w} \cdot \mathbf{x} + b \leq 0\ -2(y_i-max(0, \mathbf{w}\cdot\mathbf{x}_i+b)) &amp;amp; \mathbf{w} \cdot \mathbf{x} + b &amp;gt; 0\ \end{cases}\\\ &amp;amp; = &amp;amp; \frac{1}{N} \sum_{i=1}^N \begin{cases} 0 &amp;amp; \mathbf{w} \cdot \mathbf{x} + b \leq 0\ 2(\mathbf{w}\cdot\mathbf{x}_i+b-y_i) &amp;amp; \mathbf{w} \cdot \mathbf{x} + b &amp;gt; 0\ \end{cases}\\\ &amp;amp; = &amp;amp; \begin{cases} 0 &amp;amp; \mathbf{w} \cdot \mathbf{x}_i + b \leq 0\ \frac{2}{N} \sum_{i=1}^N (\mathbf{w}\cdot\mathbf{x}_i+b-y_i) &amp;amp; \mathbf{w} \cdot \mathbf{x}_i + b &amp;gt; 0\ \end{cases} \end{eqnarray*} &quot; /&gt;&lt;/div&gt;
&lt;p&gt;As before, we can substitute an error term:&lt;/p&gt;
&lt;div&gt;&lt;img class=&quot;blkeqn&quot; src=&quot;https://explained.ai/matrix-calculus/images/blkeqn-2D57432B77DCFDC3D65FC04C9F6621A7.svg&quot; alt=&quot;&quot; /&gt;&lt;/div&gt;
&lt;p&gt;The partial derivative is then just the average error or zero, according to the activation level. To update the neuron bias, we nudge it in the opposite direction of increased cost:&lt;/p&gt;
&lt;div&gt;&lt;img class=&quot;blkeqn&quot; src=&quot;https://explained.ai/matrix-calculus/images/blkeqn-301542C82A1BF05D145392056ADC0AC2.svg&quot; alt=&quot;&quot; /&gt;&lt;/div&gt;
&lt;p&gt;In practice, it is convenient to combine &lt;span class=&quot;eqnvec&quot;&gt;w&lt;/span&gt; and &lt;span class=&quot;eqn&quot;&gt;b&lt;/span&gt; into a single vector parameter rather than having to deal with two different partials: &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-1C5C3BA710F818B84DF992E699DB50C3-depth003.25.svg&quot; /&gt;. This requires a tweak to the input vector &lt;span class=&quot;eqnvec&quot;&gt;x&lt;/span&gt; as well but simplifies the activation function. By tacking a 1 onto the end of &lt;span class=&quot;eqnvec&quot;&gt;x&lt;/span&gt;, &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-CDA92F9769DA156F5D82B4BF0D40A8B4-depth003.25.svg&quot; /&gt;, &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-6C156670CEC09096976A6722592523F3-depth001.06.svg&quot; /&gt; becomes &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-03741D422AA7DF7FF34288D8E4395143-depth000.00.svg&quot; /&gt;.&lt;/p&gt;
&lt;p&gt;This finishes off the optimization of the neural network loss function because we have the two partials necessary to perform a gradient descent.&lt;/p&gt;
&lt;h2 id=&quot;sec7&quot;&gt;Summary&lt;/h2&gt;
&lt;p&gt;Hopefully you've made it all the way through to this point. You're well on your way to understanding matrix calculus! We've included a reference that summarizes all of the rules from this article in the next section. Also check out the annotated resource link below.&lt;/p&gt;
&lt;p&gt;Your next step would be to learn about the partial derivatives of matrices not just vectors. For example, you can take a look at the matrix differentiation section of &lt;a href=&quot;https://atmos.washington.edu/~dennis/MatrixCalculus.pdf&quot;&gt;Matrix calculus&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Acknowledgements&lt;/strong&gt;. We thank &lt;a href=&quot;https://www.usfca.edu/faculty/yannet-interian&quot;&gt;Yannet Interian&lt;/a&gt; (Faculty in MS data science program at University of San Francisco) and &lt;a href=&quot;http://www.cs.usfca.edu/~duminsky/&quot;&gt;David Uminsky&lt;/a&gt; (Faculty/director of MS data science) for their help with the notation presented here.&lt;/p&gt;
&lt;h2 id=&quot;reference&quot;&gt;Matrix Calculus Reference&lt;/h2&gt;
&lt;h3 id=&quot;sec8.1&quot;&gt;Gradients and Jacobians&lt;/h3&gt;
&lt;p&gt;The &lt;em&gt;gradient&lt;/em&gt; of a function of two variables is a horizontal 2-vector:&lt;/p&gt;
&lt;div&gt;&lt;img class=&quot;blkeqn&quot; src=&quot;https://explained.ai/matrix-calculus/images/blkeqn-D72132A48C466D3BFB703D0F1E183152.svg&quot; alt=&quot;&quot; /&gt;&lt;/div&gt;
&lt;p&gt;The &lt;em&gt;Jacobian&lt;/em&gt; of a vector-valued function that is a function of a vector is an &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-FBFEB9C8459FEE5A2BD529C07B881153-depth001.08.svg&quot; /&gt; (&lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-4B7BE5D4BAEFA7643CD9638A527AC10F-depth003.25.svg&quot; /&gt; and &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-E3114C625CDDDC18ED29BA629242BD65-depth003.25.svg&quot; /&gt;) matrix containing all possible scalar partial derivatives:&lt;/p&gt;
&lt;div&gt;&lt;img class=&quot;blkeqn&quot; src=&quot;https://explained.ai/matrix-calculus/images/blkeqn-137DC03E772BD8D2A21C78E3A744132A.svg&quot; alt=&quot;&quot; /&gt;&lt;/div&gt;
&lt;p&gt;The Jacobian of the identity function &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-3ABE4A0471143ABFC180C9FA485E5F0A-depth003.25.svg&quot; /&gt; is &lt;span class=&quot;eqn&quot;&gt;I&lt;/span&gt;.&lt;/p&gt;
&lt;h3 id=&quot;sec8.2&quot;&gt;Element-wise operations on vectors&lt;/h3&gt;
&lt;p&gt;Define generic &lt;em&gt;element-wise operations&lt;/em&gt; on vectors &lt;span class=&quot;eqnvec&quot;&gt;w&lt;/span&gt; and &lt;span class=&quot;eqnvec&quot;&gt;x&lt;/span&gt; using operator &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-1A74909B6CBAA4532A76D83B72C12DE0-depth002.52.svg&quot; /&gt; such as &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-26B17225B626FB9238849FD60EABDF60-depth001.06.svg&quot; /&gt;:&lt;/p&gt;
&lt;div&gt;&lt;img class=&quot;blkeqn&quot; src=&quot;https://explained.ai/matrix-calculus/images/blkeqn-70BD11FE09064F041D0EBEC6D8E84FBA.svg&quot; alt=&quot;&quot; /&gt;&lt;/div&gt;
&lt;p&gt;The Jacobian with respect to &lt;span class=&quot;eqnvec&quot;&gt;w&lt;/span&gt; (similar for &lt;span class=&quot;eqnvec&quot;&gt;x&lt;/span&gt;) is:&lt;/p&gt;
&lt;div&gt;&lt;img class=&quot;blkeqn&quot; src=&quot;https://explained.ai/matrix-calculus/images/blkeqn-A61DCB134D4B8F779EA6856022B98B45.svg&quot; alt=&quot;&quot; /&gt;&lt;/div&gt;
&lt;p&gt;Given the constraint (&lt;em&gt;element-wise diagonal condition&lt;/em&gt;) that &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-BD5A63074F44F11CB2ED06325816582A-depth003.25.svg&quot; /&gt; and &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-5E597DAA4E5D9263DCBFB6AB02BDB67F-depth003.25.svg&quot; /&gt; access at most &lt;span class=&quot;eqn&quot;&gt;w&lt;sub&gt;i&lt;/sub&gt;&lt;/span&gt; and &lt;span class=&quot;eqn&quot;&gt;x&lt;sub&gt;i&lt;/sub&gt;&lt;/span&gt;, respectively, the Jacobian simplifies to a diagonal matrix:&lt;/p&gt;
&lt;div&gt;&lt;img class=&quot;blkeqn&quot; src=&quot;https://explained.ai/matrix-calculus/images/blkeqn-80D7EB6F16ABCCCAA6F1CFB0D7CA05D2.svg&quot; alt=&quot;&quot; /&gt;&lt;/div&gt;
&lt;p&gt;Here are some sample element-wise operators:&lt;/p&gt;
&lt;div&gt;&lt;img class=&quot;blkeqn&quot; src=&quot;https://explained.ai/matrix-calculus/images/blkeqn-0D9C6372E2681B466B6E1AF1373C07F4.svg&quot; alt=&quot;&quot; /&gt;&lt;/div&gt;
&lt;h3 id=&quot;sec8.3&quot;&gt;Scalar expansion&lt;/h3&gt;
&lt;p&gt;Adding scalar &lt;span class=&quot;eqn&quot;&gt;z&lt;/span&gt; to vector &lt;span class=&quot;eqnvec&quot;&gt;x&lt;/span&gt;, &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-6307CEA088D2D4E98E5B163B9CE8F510-depth002.33.svg&quot; /&gt;, is really &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-8D9C0B9B15490F45C353D9DE64565A4F-depth003.25.svg&quot; /&gt; where &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-3ABE4A0471143ABFC180C9FA485E5F0A-depth003.25.svg&quot; /&gt; and &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-BD2335FC4BBF16BE9590D2501CE8C030-depth003.25.svg&quot; /&gt;.&lt;/p&gt;
&lt;div&gt;&lt;img class=&quot;blkeqn&quot; src=&quot;https://explained.ai/matrix-calculus/images/blkeqn-32264352DB9E0540766087FB1B70A249.svg&quot; alt=&quot;&quot; /&gt;&lt;/div&gt;
&lt;div&gt;&lt;img class=&quot;blkeqn&quot; src=&quot;https://explained.ai/matrix-calculus/images/blkeqn-A328432124854CC510FE59FEC916AC6C.svg&quot; alt=&quot;&quot; /&gt;&lt;/div&gt;
&lt;p&gt;Scalar multiplication yields:&lt;/p&gt;
&lt;div&gt;&lt;img class=&quot;blkeqn&quot; src=&quot;https://explained.ai/matrix-calculus/images/blkeqn-2A0AFB09BE7BE042E565C9C7FCC8B136.svg&quot; alt=&quot;&quot; /&gt;&lt;/div&gt;
&lt;div&gt;&lt;img class=&quot;blkeqn&quot; src=&quot;https://explained.ai/matrix-calculus/images/blkeqn-82B897A0A23D9C6BB66EDF17D1D3CB02.svg&quot; alt=&quot;&quot; /&gt;&lt;/div&gt;
&lt;h3 id=&quot;sec8.4&quot;&gt;Vector reductions&lt;/h3&gt;
&lt;p&gt;The partial derivative of a vector sum with respect to one of the vectors is:&lt;/p&gt;
&lt;div&gt;&lt;img class=&quot;blkeqn&quot; src=&quot;https://explained.ai/matrix-calculus/images/blkeqn-77BD17F51D7E67D76D508948DB571A81.svg&quot; alt=&quot;&quot; /&gt;&lt;/div&gt;
&lt;p&gt;For &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-5FAFFB6A723E437AC6433DCA0B269846-depth003.25.svg&quot; /&gt;:&lt;/p&gt;
&lt;div&gt;&lt;img class=&quot;blkeqn&quot; src=&quot;https://explained.ai/matrix-calculus/images/blkeqn-7D69817EEF004855C22D1BB441F8C8BF.svg&quot; alt=&quot;&quot; /&gt;&lt;/div&gt;
&lt;p&gt;For &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-9D785998BBDB763E1D5EE5546D47E47E-depth003.25.svg&quot; /&gt; and &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-B00911788A7536593130B4C89B6653A2-depth003.25.svg&quot; /&gt;, we get:&lt;/p&gt;
&lt;div&gt;&lt;img class=&quot;blkeqn&quot; src=&quot;https://explained.ai/matrix-calculus/images/blkeqn-C49A553A6A2A5CFFDF4A4EE2C82A7C06.svg&quot; alt=&quot;&quot; /&gt;&lt;/div&gt;
&lt;div&gt;&lt;img class=&quot;blkeqn&quot; src=&quot;https://explained.ai/matrix-calculus/images/blkeqn-2FD6163B4277742378701A51750A9AB5.svg&quot; alt=&quot;&quot; /&gt;&lt;/div&gt;
&lt;p&gt;Vector dot product &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-CF556A1D1CDF0863FDD547594536501A-depth003.31.svg&quot; /&gt;. Substituting &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-02A67275B737296ACC7D3FACA124192C-depth001.08.svg&quot; /&gt; and using the vector chain rule, we get:&lt;/p&gt;
&lt;div&gt;&lt;img class=&quot;blkeqn&quot; src=&quot;https://explained.ai/matrix-calculus/images/blkeqn-8FF1F0A13C3FF271E22ADEC15D7F10DC.svg&quot; alt=&quot;&quot; /&gt;&lt;/div&gt;
&lt;p&gt;Similarly, &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-D0E108FD2A63FFC84018DF9BCBE4C91B-depth004.58.svg&quot; /&gt;.&lt;/p&gt;
&lt;h3 id=&quot;sec8.5&quot;&gt;Chain rules&lt;/h3&gt;
&lt;p&gt;The &lt;em&gt;vector chain rule&lt;/em&gt; is the general form as it degenerates to the others. When &lt;span class=&quot;eqn&quot;&gt;f&lt;/span&gt; is a function of a single variable &lt;span class=&quot;eqn&quot;&gt;x&lt;/span&gt; and all intermediate variables &lt;span class=&quot;eqn&quot;&gt;u&lt;/span&gt; are functions of a single variable, the single-variable chain rule applies. When some or all of the intermediate variables are functions of multiple variables, the single-variable total-derivative chain rule applies. In all other cases, the vector chain rule applies.&lt;/p&gt;
&lt;center&gt;
&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th align=&quot;left&quot;&gt;Single-variable rule&lt;/th&gt;
&lt;th align=&quot;left&quot;&gt;Single-variable total-derivative rule&lt;/th&gt;
&lt;th align=&quot;left&quot;&gt;Vector rule&lt;/th&gt;
&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td align=&quot;left&quot;&gt;&lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-32235B531450ABE9E39C9C91D083A8E2-depth004.58.svg&quot; /&gt;&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;&lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-ED4CD5FBA6B6EC8A51FA203E2AAFF531-depth004.67.svg&quot; /&gt;&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;&lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-6396586BD585A1CFB33959EB6FA8BFA0-depth006.23.svg&quot; /&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/center&gt;
&lt;h2 id=&quot;notation&quot;&gt;Notation&lt;/h2&gt;
&lt;p&gt;Lowercase letters in bold font such as &lt;span class=&quot;eqnvec&quot;&gt;x&lt;/span&gt; are vectors and those in italics font like &lt;span class=&quot;eqn&quot;&gt;x&lt;/span&gt; are scalars. &lt;span class=&quot;eqn&quot;&gt;x&lt;sub&gt;i&lt;/sub&gt;&lt;/span&gt; is the &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-97361F12A3555FC4FC4E2FFCE1799AC3-depth000.14.svg&quot; /&gt; element of vector &lt;span class=&quot;eqnvec&quot;&gt;x&lt;/span&gt; and is in italics because a single vector element is a scalar. &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-DEA8E196A572D082201CD5ABF2FA82DE-depth003.25.svg&quot; /&gt; means “length of vector &lt;span class=&quot;eqnvec&quot;&gt;x&lt;/span&gt;.”&lt;/p&gt;
&lt;p&gt;The &lt;span class=&quot;eqn&quot;&gt;T&lt;/span&gt; exponent of &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-FAAEE783424BC0E27E9AA2F56A7B50B8-depth000.00.svg&quot; /&gt; represents the transpose of the indicated vector.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-60D8CDDDBF54CF43BC22AF322D2BB8E3-depth003.31.svg&quot; /&gt; is just a for-loop that iterates &lt;span class=&quot;eqn&quot;&gt;i&lt;/span&gt; from &lt;span class=&quot;eqn&quot;&gt;a&lt;/span&gt; to &lt;span class=&quot;eqn&quot;&gt;b&lt;/span&gt;, summing all the &lt;span class=&quot;eqn&quot;&gt;x&lt;sub&gt;i&lt;/sub&gt;&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Notation &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-50BBD36E1FD2333108437A2CA378BE62-depth003.25.svg&quot; /&gt; refers to a function called &lt;span class=&quot;eqn&quot;&gt;f&lt;/span&gt; with an argument of &lt;span class=&quot;eqn&quot;&gt;x&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;eqn&quot;&gt;I&lt;/span&gt; represents the square “identity matrix” of appropriate dimensions that is zero everywhere but the diagonal, which contains all ones.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-4935E4C6B875FD6C7C181871B566AB1A-depth003.25.svg&quot; /&gt; constructs a matrix whose diagonal elements are taken from vector &lt;span class=&quot;eqnvec&quot;&gt;x&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;The dot product &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-9CA8C3CD16894AF7620468A20C53D6FA-depth000.00.svg&quot; /&gt; is the summation of the element-wise multiplication of the elements: &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-4B722CF0EFB8F8ABCBB968086BB587E8-depth003.31.svg&quot; /&gt;. Or, you can look at it as &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-CF0A6D64FC3321DB0EC98B7683024367-depth000.22.svg&quot; /&gt;.&lt;/p&gt;
&lt;p&gt;Differentiation &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-624FEBB9A49A3FC96353C861D175C806-depth004.58.svg&quot; /&gt; is an operator that maps a function of one parameter to another function. That means that &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-EC0CEC5F9488EC510F8D688E7003222D-depth004.58.svg&quot; /&gt; maps &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-50BBD36E1FD2333108437A2CA378BE62-depth003.25.svg&quot; /&gt; to its derivative with respect to &lt;span class=&quot;eqn&quot;&gt;x&lt;/span&gt;, which is the same thing as &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-07A5EA519C4CEA1A3539E3A7FC289163-depth004.58.svg&quot; /&gt;. Also, if &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-FD91C508F91C2C84498680BD337C1D7A-depth003.25.svg&quot; /&gt;, then &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-B1ED3CF9BA4D6F25A5A4F481C45EC658-depth004.58.svg&quot; /&gt;.&lt;/p&gt;
&lt;p&gt;The partial derivative of the function with respect to &lt;span class=&quot;eqn&quot;&gt;x&lt;/span&gt;, &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-2E335C72CE43928A54BED52C5A6FCC87-depth004.67.svg&quot; /&gt;, performs the usual scalar derivative holding all other variables constant.&lt;/p&gt;
&lt;p&gt;The gradient of &lt;span class=&quot;eqn&quot;&gt;f&lt;/span&gt; with respect to vector &lt;span class=&quot;eqnvec&quot;&gt;x&lt;/span&gt;, &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-69AA2CF3DFE9D41CB1DB567D1B0AD275-depth003.25.svg&quot; /&gt;, organizes all of the partial derivatives for a specific scalar function.&lt;/p&gt;
&lt;p&gt;The Jacobian organizes the gradients of multiple functions into a matrix by stacking them:&lt;/p&gt;
&lt;div&gt;&lt;img class=&quot;blkeqn&quot; src=&quot;https://explained.ai/matrix-calculus/images/blkeqn-620A2D5A110082A77BCB7A2BA1E00590.svg&quot; alt=&quot;&quot; /&gt;&lt;/div&gt;
&lt;p&gt;The following notation means that &lt;span class=&quot;eqn&quot;&gt;y&lt;/span&gt; has the value &lt;span class=&quot;eqn&quot;&gt;a&lt;/span&gt; upon &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-585B40029A25F6E19FF42DBC26AE5702-depth001.95.svg&quot; /&gt; and value &lt;span class=&quot;eqn&quot;&gt;b&lt;/span&gt; upon &lt;img src=&quot;https://explained.ai/matrix-calculus/images/eqn-CBECF4275AFD44DAD4B312042088DA7E-depth001.95.svg&quot; /&gt;.&lt;/p&gt;
&lt;div&gt;&lt;img class=&quot;blkeqn&quot; src=&quot;https://explained.ai/matrix-calculus/images/blkeqn-AE0AEA302ADBC6C30F0A32446C7912AA.svg&quot; alt=&quot;&quot; /&gt;&lt;/div&gt;
&lt;h2 id=&quot;sec10&quot;&gt;Resources&lt;/h2&gt;
&lt;p&gt;&lt;a href=&quot;http://www.wolframalpha.com/input/?i=D%5B%7Bx%5E2,+x%5E3%7D.%7B%7B1,2%7D,%7B3,4%7D%7D.%7Bx%5E2,+x%5E3%7D,+x%5D&quot;&gt;Wolfram Alpha&lt;/a&gt; can do symbolic matrix algebra and there is also a cool dedicated &lt;a href=&quot;http://www.matrixcalculus.org/&quot;&gt;matrix calculus differentiator&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;When looking for resources on the web, search for “matrix calculus” not “vector calculus.” Here are some comments on the top links that come up from a &lt;a href=&quot;https://www.google.com/search?q=matrix+calculus&amp;amp;oq=matrix+calculus&quot;&gt;Google search&lt;/a&gt;:&lt;/p&gt;
&lt;p&gt;To learn more about neural networks and the mathematics behind optimization and back propagation, we highly recommend &lt;a href=&quot;http://neuralnetworksanddeeplearning.com/chap1.html&quot;&gt;Michael Nielsen's book&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;For those interested specifically in convolutional neural networks, check out &lt;a href=&quot;https://arxiv.org/pdf/1603.07285.pdf&quot;&gt;A guide to convolution arithmetic for deep learning&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;We reference the law of &lt;a href=&quot;https://en.wikipedia.org/wiki/Total_derivative&quot;&gt;total derivative&lt;/a&gt;, which is an important concept that just means derivatives with respect to &lt;span class=&quot;eqn&quot;&gt;x&lt;/span&gt; must take into consideration the derivative with respect &lt;span class=&quot;eqn&quot;&gt;x&lt;/span&gt; of all variables that are a function of &lt;span class=&quot;eqn&quot;&gt;x&lt;/span&gt;.&lt;/p&gt;
&lt;/body&gt;</description>
<pubDate>Fri, 29 Nov 2019 02:29:56 +0000</pubDate>
<dc:creator>yarapavan</dc:creator>
<og:title>The matrix calculus you need for deep learning</og:title>
<og:image>https://explained.ai/matrix-calculus/images/neuron.png</og:image>
<og:description>Most of us last saw calculus in school, but derivatives are a critical part of machine learning, particularly deep neural networks, which are trained by optimizing a loss function. This article is an attempt to explain all the matrix calculus you need in order to understand the training of deep neural networks. We assume no math knowledge beyond what you learned in calculus 1, and provide links to help you refresh the necessary math where needed.</og:description>
<og:url>https://explained.ai/matrix-calculus/index.html</og:url>
<og:type>article</og:type>
<dc:format>text/html</dc:format>
<dc:identifier>https://explained.ai/matrix-calculus/index.html</dc:identifier>
</item>
<item>
<title>Ask HN: Burning Out</title>
<link>https://news.ycombinator.com/item?id=21661054</link>
<guid isPermaLink="true" >https://news.ycombinator.com/item?id=21661054</guid>
<description>&lt;td colspan=&quot;2&quot;/&gt;&lt;td readability=&quot;29&quot;&gt;Burning out as an early stage start-up employee. I’ve been employed there a few years, worked miracles, but getting recently getting some poor feedback. Confusing situation. Wondering if I should just quit? Is career salvageable? I solved the business’ biggest issue. Start-up was founded to do X, founders couldn’t figure out how to do X, I was asked to do X. Under enormous pressure I single handily figured out how to do X, conducted all the R&amp;amp;D, built the prototype, supervised the engineer and release. Its still a prototype, but solves one of the industries biggest problem. Non-founder team lead is unhappy some minor issues have slipping in the chaotic process of getting this to market. I’m doing several different jobs and do everything. My solution is going to change the market, the idea is worth millions of dollars, likely more.
&lt;p&gt;Founders are very please, but getting poor feedback from team lead. Team lead has hindered more than helped, gives conflicting advice, blows hot and cold, has created a toxic environment etc. Admittedly some minor things have slipped through the cracks, but much of this comes from my team lead playing politics, creating silos and conflicts etc.&lt;/p&gt;
&lt;p&gt;My team lead is grinding me down with their constant nitpicking and I really just want to go and do something else, anything else, work in a bar or something. Considered going to the founders with the issue, but I can’t see how this can be resolved beyond creating a new role or transferring out of my area of expertise. I did a sanity check and have reached out to others. Lots of others have take issue with my team lead as well, so its not just me.&lt;/p&gt;
&lt;p&gt;I’m pretty burnout, and definitely in need to some time out before moving on. I don’t think I’d come across very well (or as sharp as I usually) in interviews at the moment without a break.&lt;/p&gt;
&lt;p&gt;Anyone been through anything similar? Anyone have any advice?&lt;/p&gt;
&lt;/td&gt;
</description>
<pubDate>Fri, 29 Nov 2019 00:23:38 +0000</pubDate>
<dc:creator>burning_out_101</dc:creator>
<dc:format>text/html</dc:format>
<dc:identifier>https://news.ycombinator.com/item?id=21661054</dc:identifier>
</item>
</channel>
</rss>