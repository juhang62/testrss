<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="css/feed.xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/" xmlns:og="http://ogp.me/ns#">
<channel>
<atom:link rel="self" href="http://192.168.1.4/fivefilters/makefulltextfeed.php?url=hnrss.org%2Fnewest%3Fpoints%3D200&amp;max=10&amp;links=preserve&amp;exc=" />
<atom:link rel="alternate" title="Source URL" href="http://hnrss.org/newest?points=200" />
<atom:link rel="related" title="Subscribe to feed" href="http://www.subtome.com/#/subscribe?feeds=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dhnrss.org%252Fnewest%253Fpoints%253D200%26max%3D10%26links%3Dpreserve%26exc%3D&amp;back=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dhnrss.org%252Fnewest%253Fpoints%253D200%26max%3D10%26links%3Dpreserve%26exc%3D" />
<title>Hacker News: Newest</title>
<link>https://news.ycombinator.com/newest</link>
<description>Hacker News RSS</description>
<item>
<title>The Billionaire Behind Efforts to Kill the U.S. Postal Service [pdf]</title>
<link>https://www.inthepublicinterest.org/wp-content/uploads/ITPI_USPSPrivatization_July2020.pdf</link>
<guid isPermaLink="true" >https://www.inthepublicinterest.org/wp-content/uploads/ITPI_USPSPrivatization_July2020.pdf</guid>
<description>&lt;a href=&quot;https://www.inthepublicinterest.org/wp-content/uploads/ITPI_USPSPrivatization_July2020.pdf&quot;&gt;Download PDF&lt;/a&gt;</description>
<pubDate>Tue, 21 Jul 2020 22:33:49 +0000</pubDate>
<dc:creator>Firebrand</dc:creator>
<dc:format>application/pdf</dc:format>
<dc:identifier>https://www.inthepublicinterest.org/wp-content/uploads/ITPI_USPSPrivatization_July2020.pdf</dc:identifier>
</item>
<item>
<title>India, Jio, and the Four Internets</title>
<link>https://stratechery.com/2020/india-jio-and-the-four-internets/</link>
<guid isPermaLink="true" >https://stratechery.com/2020/india-jio-and-the-four-internets/</guid>
<description>&lt;p&gt;One of the more pernicious mistruths surrounding &lt;a href=&quot;https://stratechery.com/2020/the-tiktok-war/&quot;&gt;the debate about TikTok&lt;/a&gt; is that this will potentially lead to the splintering of the Internet; this completely erases the history of China’s Great Firewall, started 23 years ago, which effectively cut China off from most Western services. That the U.S. may finally respond in kind is a reflection of reality, not the creation of a new one.&lt;/p&gt;
&lt;p&gt;What is new is the increased splintering in the non-China Internet: the U.S. model is still the default for most of the world, but the European Union and India are increasingly pursuing their own paths.&lt;/p&gt;
&lt;h4&gt;The U.S. Model&lt;/h4&gt;
&lt;p&gt;The U.S. Internet model is a laissez-faire one, and it is hard to argue against its effectiveness. Not only is the technology sector the biggest driver of U.S. economic growth for many years now, but U.S. Internet companies have come to dominate most of the world, conveying U.S. soft power like McDonald’s and Hollywood on steroids. There are obvious downsides to this approach: the Internet’s &lt;a href=&quot;https://stratechery.com/2013/friction/&quot;&gt;lack of friction&lt;/a&gt; both leads to &lt;a href=&quot;https://stratechery.com/2015/aggregation-theory/&quot;&gt;Aggregators&lt;/a&gt; dominating markets and creates communities &lt;a href=&quot;https://stratechery.com/2019/a-framework-for-moderation/&quot;&gt;both good and bad&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;This article, though, is primarily focused on economics and politics, and in that regard the winners and losers of the U.S.’s approach are as follows:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Winners:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;Large U.S. tech companies operate freely in the U.S., giving them a large and profitable user base to fund expansion abroad.&lt;/li&gt;
&lt;li&gt;New U.S. tech companies face relatively few barriers to entry, particularly in terms of regulation of content or data collection.&lt;/li&gt;
&lt;li&gt;The U.S. government collects the vast majority of taxes from these U.S. companies, including from revenue generated abroad, and also sees the overall U.S. view of the world exported via U.S. tech companies, while also having access to the data of non-U.S. citizens.&lt;/li&gt;
&lt;li&gt;U.S. citizens operate with a high degree of freedom online, although there are minimal restrictions on the collection of the data generated from doing so by private companies.&lt;/li&gt;
&lt;li&gt;Non-U.S. citizens operate with a high degree of freedom online, although there are minimal restrictions on the collection of the data generated from doing so by private companies or the U.S. government.&lt;/li&gt;
&lt;li&gt;Non-U.S. companies are free to operate in the United States without restriction, and in other countries that follow the U.S.’s approach.&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;Losers:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;Non-U.S. governments have limited control over U.S. tech companies, limited access to their revenues, and limited control over the spread of information.&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;My biases should be obvious: I definitely believe that the U.S. approach is the best one. Certainly many will quibble with the effect on new companies, given how Aggregators tend to dominate their markets, while others are focused on the collection of data; I am concerned that &lt;a href=&quot;https://stratechery.com/2020/first-do-no-harm/&quot;&gt;proposed solutions&lt;/a&gt; are worse &lt;a href=&quot;https://stratechery.com/2019/privacy-fundamentalism/&quot;&gt;than the harms&lt;/a&gt;, particularly given the consumer benefit of &lt;a href=&quot;https://stratechery.com/2018/data-factories/&quot;&gt;data factories&lt;/a&gt;. Still, &lt;a href=&quot;https://stratechery.com/2020/apple-wins-e-u-tax-case-privacy-shield-struck-down-bans-censorship-and-the-first-amendment/&quot;&gt;as I noted yesterday&lt;/a&gt;, I believe the European Union Court of Justice makes a compelling case that the ability of the U.S. government to collect data from non-U.S. citizens is a serious privacy issue.&lt;/p&gt;
&lt;p&gt;Those quibbles, though, serve to highlight a point we can all agree on: non-U.S. governments have a lot of legitimate complaints about the hegemony of U.S. tech companies.&lt;/p&gt;
&lt;h4&gt;The China Model&lt;/h4&gt;
&lt;p&gt;The driving impetus of the China model is, first and foremost, control over information. This is evidenced by the fact that not only does China control access to Western services at the network level, but also employs huge numbers of censors for the Internet within China, and expects Chinese Internet companies like Tencent or ByteDance to have thousands of censors of their own.&lt;/p&gt;
&lt;p&gt;At the same time, the economic benefit of China’s approach &lt;em&gt;for China&lt;/em&gt; can not be denied. China is the only country to rival the U.S. for the sheer size and breadth of its Internet companies, thanks to the combination of a massive market and the lack of competition. Moreover, this led to all sorts of innovation, as China’s leapfrog to mobile avoided the baggage of PC-assumptions that still limits many U.S. companies.&lt;/p&gt;
&lt;p&gt;That noted, it is fair to wonder just how replicable the China model is. Smaller countries like Iran have instituted similar controls on U.S. tech companies, but without a market like China it is far more difficult to capture the economic upside of the Great Firewall. And, it should be noted, there are a lot of losers with the China model, including Chinese citizens.&lt;/p&gt;
&lt;h4&gt;The European Model&lt;/h4&gt;
&lt;p&gt;Europe, through regulations like GDPR and the Copyright Directive, along with last week’s court decision striking down the Privacy Shield framework negotiated by the European Commission and the U.S. International Trade Administration (and a previous decision striking down the Safe Harbor Privacy Principles framework), is splintering off into an Internet of its own.&lt;/p&gt;
&lt;p&gt;This Internet, though, feels like the worst of all possible outcomes. On one hand, large U.S. tech companies are winners, at least relative to everyone else: yes, all of the regulatory red tape increases costs (and, for targeted advertising, may reduce revenue), but the impact is far greater on would-be competitors. To put it in allegorical terms, the E.U. is restricting the size of the castle even as it dramatically increases the moat.&lt;/p&gt;
&lt;p&gt;E.U. citizens, meanwhile, are likely to see their data increasingly protected from the U.S. government, which is a win; other protections, meanwhile, seem unlikely to be particularly effective or outweigh the general annoyance and loss of relevance that comes from endless permission dialogs and non-targeted content. Moreover, per the previous point, the number of alternatives to established incumbents are likely to decrease, particularly relative to the U.S.&lt;/p&gt;
&lt;p&gt;It also seems unlikely that European competitors will fill in the gap. Any company that wishes to achieve scale needs to do so in its home market first, before going abroad, but it seems far more likely that Europe will make the most sense as a secondary market for companies that have done the messy work of iterating on data and achieving product-market fit in markets that are more open to experimentation and impose less of a regulatory burden. Higher costs mean you need a greater expectation of success, which means a proven model, not a speculative one.&lt;/p&gt;
&lt;p&gt;Worst of all, at least from the E.U.’s perspective, is that this approach doesn’t really have any upside for European governments. That’s the thing with rule by regulation: without a focus on growth it is harder to create win-win situations.&lt;/p&gt;
&lt;h4&gt;The Indian Model&lt;/h4&gt;
&lt;p&gt;The India market has always been a bit unique: while foreign companies have usually been unencumbered when it comes to digital goods, leading to a huge number of users for U.S. companies like Google and Facebook, and Chinese companies like TikTok, India has kept a much tighter leash when it comes to the physical layer of tech. This ranges from strong tariffs on electronics to a ban on foreign direct investment in things like e-commerce. Moreover, India has always been one of the most challenging markets in terms of Internet access and logistics.&lt;/p&gt;
&lt;p&gt;At the same time, the Indian market is the most enticing in the world for both U.S. and Chinese tech companies, which have largely saturated their home markets. This has led to a regular number of collisions between foreign tech companies and India regulators, whether it be &lt;a href=&quot;https://stratechery.com/2016/twitters-earnings-twitter-retrenches-facebook-andreessen-and-india/&quot;&gt;Facebook’s attempts to introduce Free Basics&lt;/a&gt; or WhatsApp payments, &lt;a href=&quot;https://stratechery.com/2017/microsoft-ebay-and-tencent-invest-in-flipkart-the-indian-e-commerce-market-lyft-raises-500-million/&quot;&gt;increasing restrictions on Amazon and Flipkart’s e-commerce operations&lt;/a&gt;, or most recently, &lt;a href=&quot;https://stratechery.com/2020/india-bans-chinese-apps-the-app-store-firewall-reddit-and-the-donald/&quot;&gt;the outright banning of TikTok&lt;/a&gt; on national security concerns.&lt;/p&gt;
&lt;p&gt;Over the last few months, though, a way to square this circle has become apparent to U.S. tech companies in particular, and it portends a fourth Internet: invest in Jio Platforms.&lt;/p&gt;
&lt;h4&gt;The Jio Bet&lt;/h4&gt;
&lt;p&gt;Jio, the dominant telecoms network in India, is one of the all-time greatest examples of the power of building, and the outsized returns that come from betting on technology-enabled disruption. I described the economics of the bet by Mukesh Ambani, India’s richest man, in an &lt;a href=&quot;https://stratechery.com/2020/facebook-invests-in-jio-platforms-the-building-of-jio-understanding-the-deal/&quot;&gt;April Daily Update&lt;/a&gt;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The key to understanding Ambani’s bet is that while all of the incumbent mobile operators in India were, like mobile operators around the world, companies built on voice calls that layered on data, Jio was built to be a data network — specifically 4G — from the beginning.&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;4G, unlike 2G and 3G, does not support traditional circuit-switched telephony services; voice calls are instead handled the same as any other data.&lt;/li&gt;
&lt;li&gt;Because everything is data, 4G networks can be built with commodity hardware in a way that 2G and 3G networks cannot.&lt;/li&gt;
&lt;li&gt;Because Jio was offering a data network, voice calls, which are relatively low bandwidth, were the cheapest services to offer, and capacity was effectively infinite.&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;To put it another way, Jio was a bet on zero marginal costs — or, at a minimum, drastically lower marginal costs than its competitors. This meant that the optimal strategy was — you know what is coming! — to spend a massive amount of money up front and then seek to serve the greatest number of consumers in order to get maximum leverage on that up-front investment.&lt;/p&gt;
&lt;p&gt;That is exactly what Jio did: it spent that $32 billion building a network that covered all of India, launched with an offer for three months of free data and free voice, and once that was up, kept the free voice offering permanently while charging only a couple of bucks for data by the gigabyte. It was the classic Silicon Valley bet: spend money up front, then make it up on volume because of a superior cost structure enabled by the zero-marginal nature of technology.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;What makes this story so compelling is the contrast to Facebook’s argument for Free Basics:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The end result is what Zuckerberg said must be done: hundreds of millions of Indians, a huge portion of them from the country’s poorest regions, were connected to the Internet. Unlike Free Basics, though, it was all of the Internet.&lt;/p&gt;
&lt;p&gt;That actually undersells just how much better Jio is for Indians than Free Basics would have ever been: Zuckerberg had no plan for upending India’s old mobile order, where operators focused most of their investment on India’s largest cities and competed for the richest parts of society, charging so much that Andreessen could declare, with a straight face, that to not offer Free Basics was “morally wrong.” In that world, India’s poor may have had access to Facebook, but little more, since there would have been no reason for non-Free Basics companies to invest. Instead they not only have the whole Internet but companies from India to China to the United States competing to serve them.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;I wrote that Daily Update on the occasion of Facebook investing $5.7 billion for a 10% stake into Jio Platforms; it turned out that was the first of many investments into Jio:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;In May, Silver Lake Partners invested $790 million for a 1.15% stake, General Atlantic invested $930 million for a 1.34% stake, and KKR invested $1.6 billion for a 2.32% stake.&lt;/li&gt;
&lt;li&gt;In June, the Mubadala and Adia UAE sovereign funds and Saudi Arabia sovereign fund invested $1.3 billion for a 1.85% stake, $800 million for a 1.16% stake, and $1.6 billion for a 2.32% stake, respectively; Silver Lake Partners invested an additional $640 million to up its stake to 2.08%, TPG invested $640 million for a 0.93% stake, and Catterton invested $270 million for a 0.39% stake. In addition, Intel invested $253 million for a 0.39% stake.&lt;/li&gt;
&lt;li&gt;In July, Qualcomm invested $97 million for a 0.15% stake, and Google invested $4.7 billion for a 7.7% stake.&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;With that flurry of fundraising Reliance completely paid off the billions of dollars it had borrowed to build out Jio. What is increasingly clear, though, is that the company’s ambitions extend far beyond being a mere telecoms provider.&lt;/p&gt;
&lt;h4&gt;Jio’s Vision&lt;/h4&gt;
&lt;p&gt;Last Wednesday, after announcing Google’s investment in Jio Platforms at Reliance Industries’ &lt;a href=&quot;https://www.youtube.com/watch?v=k0b0miKViYg&quot;&gt;Annual General Meeting&lt;/a&gt;, Ambani said:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;I would like to first share with you the philosophy that animates Jio’s current and future initiatives. The digital revolution marks the greatest disruptive transformation in the history of mankind, comparable only to the appearance of human beings with intelligence capability on our planet about 50,000 years ago. It is comparable because man is now beginning to infuse almost limitless intelligence into the world around him.&lt;/p&gt;
&lt;p&gt;We are today at the initial stages of the evolution of an intelligent planet. Unlike in the past this evolution will proceed with a revolutionary speed. Our world will change more unrecognizably in just eight remaining decades of the 21st century, than today’s world has changed from what it was 20 centuries ago. For the first time in history mankind has an opportunity to solve big problems inherited from the past. This will create a world of prosperity, beauty, and happiness for all. India must lead this change to create a better world. For this all our people and all our enterprises have to be enabled and empowered with the necessary technology infrastructure and capabilities. This is Jio’s purpose. This is Jio’s ambition.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://stratechery.com/wp-content/uploads/2020/07/jio-6-1024x578.png&quot; alt=&quot;The &amp;quot;Two Pillars of Jio&amp;quot; slide from Reliance's Annual Global Meeting&quot; width=&quot;640&quot; height=&quot;361&quot; class=&quot;aligncenter size-large wp-image-5125&quot; srcset=&quot;https://stratechery.com/wp-content/uploads/2020/07/jio-6-1024x578.png 1024w, https://stratechery.com/wp-content/uploads/2020/07/jio-6-300x169.png 300w, https://stratechery.com/wp-content/uploads/2020/07/jio-6-768x433.png 768w, https://stratechery.com/wp-content/uploads/2020/07/jio-6-1117x630.png 1117w, https://stratechery.com/wp-content/uploads/2020/07/jio-6.png 1280w&quot; sizes=&quot;(max-width: 640px) 100vw, 640px&quot;/&gt;&lt;/p&gt;
&lt;p&gt;Friends, Jio is now the undisputed leader in India with the largest customer base, the largest share of data and voice traffic, and a world-class next-generation broadband network that covers the length and the breadth of our country…Jio’s vision stands on two solid pillars. One is digital connectivity and the other is digital platforms.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;In short, Jio is determined to achieve the dream that has long eluded telecom providers in other countries: moving up the stack from fixed-cost infrastructure to high-margin services. Ambani’s vision is comprehensive:&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://stratechery.com/wp-content/uploads/2020/07/jio-8-1024x282.png&quot; alt=&quot;Jio's vision slides from Reliance's Annual Global Meeting&quot; width=&quot;640&quot; height=&quot;176&quot; class=&quot;aligncenter size-large wp-image-5138&quot; srcset=&quot;https://stratechery.com/wp-content/uploads/2020/07/jio-8-1024x282.png 1024w, https://stratechery.com/wp-content/uploads/2020/07/jio-8-300x83.png 300w, https://stratechery.com/wp-content/uploads/2020/07/jio-8-768x212.png 768w, https://stratechery.com/wp-content/uploads/2020/07/jio-8-1200x331.png 1200w, https://stratechery.com/wp-content/uploads/2020/07/jio-8.png 1280w&quot; sizes=&quot;(max-width: 640px) 100vw, 640px&quot;/&gt;&lt;/p&gt;
&lt;p&gt;What gives Jio a chance are three important differences from telecom efforts in other markets:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;First, Jio has created a huge portion of its addressable market; whereas a Verizon in the U.S., or a NTT DoCoMo in Japan was seeking to offer services on top of a competitive telecom market, Jio is the only option for a huge number of Indians (and for those that have options, Jio is so much cheaper because of its IP-based network that it can afford the extra costs).&lt;/li&gt;
&lt;li&gt;Second, instead of seeking to usurp companies like Facebook or Google that already have major marketshare in India, Jio is partnering with them.&lt;/li&gt;
&lt;li&gt;Third, Jio is positioning itself as an Indian champion, and the lynchpin of the Indian model.&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;Notice how Ambani introduced Jio’s 5G plans:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Jio’s global scale 4G and fiber network is powered by several core software technologies and components that have been developed by the young Jio engineers right here in India. This capability and know-how that Jio has developed positions Jio on the cutting edge of another exciting frontier: 5G.&lt;/p&gt;
&lt;p&gt;Today friends, I have great pride in announcing that Jio has designed and developed a complete 5G solution from scratch. This will enable us to launch a world-class 5G service in India using 100% homegrown technology and solution. This made in India 5G solution will be ready for trials as soon as 5G spectrum is available, and can be ready for field deployment next year. And because of Jio’s converged all-IP network architecture we can easily upgrade our 4G network to 5G.&lt;/p&gt;
&lt;p&gt;Once Jio’s 5G solution is proven at India-scale, Jio platforms would be well-positioned to be an exporter of 5G solutions to other telecom operators globally as a complete managed service. I dedicate Jio’s 5G solution to our Prime Minister Shri Narendra Modi’s highly motivating vision of ‘Atmanirhbhar Bharat’.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://stratechery.com/wp-content/uploads/2020/07/jio-5-1024x579.png&quot; alt=&quot;The &amp;quot;Motivations&amp;quot; slide from Reliance's Annual Global Meeting&quot; width=&quot;640&quot; height=&quot;362&quot; class=&quot;aligncenter size-large wp-image-5126&quot; srcset=&quot;https://stratechery.com/wp-content/uploads/2020/07/jio-5-1024x579.png 1024w, https://stratechery.com/wp-content/uploads/2020/07/jio-5-300x170.png 300w, https://stratechery.com/wp-content/uploads/2020/07/jio-5-768x434.png 768w, https://stratechery.com/wp-content/uploads/2020/07/jio-5-1114x630.png 1114w, https://stratechery.com/wp-content/uploads/2020/07/jio-5.png 1280w&quot; sizes=&quot;(max-width: 640px) 100vw, 640px&quot;/&gt;&lt;/p&gt;
&lt;p&gt;Friends, Jio Platform is conceived with this vision of developing original captive intellectual property using which we can demonstrate the transformative power of technology across multiple industry ecosystems, first in India, and then confidently offering these Made-in-India solutions to the rest of the world.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Make no mistake: Jio’s network and its work on 5G, which takes years, was by definition not motivated by a phrase Prime Minister Modi first deployed &lt;a href=&quot;https://en.wikipedia.org/wiki/Atmanirbhar_Bharat&quot;&gt;two months ago&lt;/a&gt;. Rather, Ambani’s dedication hinted at the role Jio investors like Facebook and Google are anticipating Jio will play:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;Jio leverages its investment to become the monopoly provider of telecom services in India.&lt;/li&gt;
&lt;li&gt;Jio is now a single point of leverage for the government to both exert control over the Internet, and to collect its share of revenue.&lt;/li&gt;
&lt;li&gt;Jio becomes a reliable interface for foreign companies to invest in the Indian market; yes, they will have to share revenue with Jio, but Jio will smooth over the regulatory and infrastructure hurdles that have stymied so many&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;What is fascinating about this approach is that the list of winners and losers gets pretty muddled pretty quickly. On one hand, Jio brought the Internet to hundreds of millions of Indians that would never have had access, and the benefits of that investment are only going to increase as Jio’s services and partnerships come on line. On the other hand, locking in a monopolistic player, particularly in the context of a government that has shown a desire for more control over the flow of information is a real downside.&lt;/p&gt;
&lt;p&gt;The economic outcomes are just as muddled. Monopolies always have deadweight loss; then again, if an efficient market means that all of the profits flow to Silicon Valley, why should India particularly care about efficiency? In a Jio-mediated market it is U.S. tech companies that make less than they would have, and not only does India collect more taxes along the way, Jio’s vision of being a national champion abroad could be a huge win for India in the long run.&lt;/p&gt;
&lt;h4&gt;The Indian Counterweight&lt;/h4&gt;
&lt;p&gt;It is increasingly impossible — or at least irresponsible — to evaluate the tech industry, at least the largest players, without considering the geopolitical concerns at stake. With that in mind, I welcome Jio’s ambition. Not only is it unreasonable and disrespectful for the U.S. to expect India to be some sort of vassal state technologically speaking, it is actually a good thing to not only have a counterweight to China geographically, but also a counterweight amongst developing countries specifically. Jio is considering problem-spaces that U.S. tech companies are all too often ignorant of, which matters not simply for India but also for much of the rest of the world.&lt;/p&gt;
&lt;p&gt;Still, Facebook, Google, Intel, Qualcomm, et al should proceed with their eyes wide-open: they are very much a means to an end for a company and a country that is on its own path. That is not to say these investments are not a good idea — I think they are, but India’s path is perhaps a more populist and nationalistic one than many Americans would prefer. Still, it is less antagonistic to Western liberalism than the Chinese Communist Party, and again, an important counterweight.&lt;/p&gt;
&lt;p&gt;The only question left, then, is whither Europe, and frankly, the picture is not pretty:&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://stratechery.com/wp-content/uploads/2020/07/jio-7-1024x749.png&quot; alt=&quot;The Four Internets&quot; width=&quot;640&quot; height=&quot;468&quot; class=&quot;aligncenter size-large wp-image-5124&quot; srcset=&quot;https://stratechery.com/wp-content/uploads/2020/07/jio-7-1024x749.png 1024w, https://stratechery.com/wp-content/uploads/2020/07/jio-7-300x219.png 300w, https://stratechery.com/wp-content/uploads/2020/07/jio-7-768x562.png 768w, https://stratechery.com/wp-content/uploads/2020/07/jio-7-862x630.png 862w, https://stratechery.com/wp-content/uploads/2020/07/jio-7.png 1280w&quot; sizes=&quot;(max-width: 640px) 100vw, 640px&quot;/&gt;&lt;/p&gt;
&lt;p&gt;What differs Europe’s Internet from the U.S., Chinese, or Indian visions is, well, the lack of vision. Doing nothing more than continually saying “no” leads to a pale imitation of the status quo, where money matters more than innovation.&lt;/p&gt;


</description>
<pubDate>Tue, 21 Jul 2020 16:12:54 +0000</pubDate>
<dc:creator>MindGods</dc:creator>
<og:type>article</og:type>
<og:title>India, Jio, and the Four Internets</og:title>
<og:url>https://stratechery.com/2020/india-jio-and-the-four-internets/</og:url>
<og:description>There are four Internets: China versus the U.S., and the E.U. and India. India’s potential new model rests on Jio.</og:description>
<og:image>https://stratechery.com/wp-content/uploads/2020/07/jio-7.png</og:image>
<dc:language>en-US</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://stratechery.com/2020/india-jio-and-the-four-internets/</dc:identifier>
</item>
<item>
<title>Facebook overrides fact-checks when climate science is “opinion”</title>
<link>https://arstechnica.com/tech-policy/2020/07/facebook-overrides-fact-checks-when-climate-science-is-opinion/</link>
<guid isPermaLink="true" >https://arstechnica.com/tech-policy/2020/07/facebook-overrides-fact-checks-when-climate-science-is-opinion/</guid>
<description>&lt;img src=&quot;https://cdn.arstechnica.net/wp-content/uploads/2019/10/GettyImages-1052446892-800x533.jpg&quot; alt=&quot;Photograph of busy open-plan office.&quot;/&gt;&lt;div class=&quot;caption-text&quot;&gt;&lt;a href=&quot;https://cdn.arstechnica.net/wp-content/uploads/2019/10/GettyImages-1052446892.jpg&quot; class=&quot;enlarge-link&quot; data-height=&quot;2667&quot; data-width=&quot;4000&quot;&gt;Enlarge&lt;/a&gt; &lt;span class=&quot;sep&quot;&gt;/&lt;/span&gt; Facebook's election &quot;War Room&quot; on Wednesday, Oct. 17, 2018.&lt;/div&gt;&lt;aside id=&quot;social-left&quot; class=&quot;social-left&quot; aria-label=&quot;Read the comments or share this article&quot;&gt;
&lt;h4 class=&quot;comment-count-before&quot;&gt;&lt;a title=&quot;76 posters participating&quot; class=&quot;comment-count icon-comment-bubble-down&quot; href=&quot;https://arstechnica.com/tech-policy/2020/07/facebook-overrides-fact-checks-when-climate-science-is-opinion/?comments=1&quot;&gt;reader comments&lt;/a&gt;&lt;/h4&gt;
&lt;a title=&quot;76 posters participating&quot; class=&quot;comment-count icon-comment-bubble-down&quot; href=&quot;https://arstechnica.com/tech-policy/2020/07/facebook-overrides-fact-checks-when-climate-science-is-opinion/?comments=1&quot;&gt;&lt;span class=&quot;comment-count-number&quot;&gt;120&lt;/span&gt; &lt;span class=&quot;visually-hidden&quot;&gt;with 76 posters participating&lt;/span&gt;&lt;/a&gt;
&lt;div class=&quot;share-links&quot;&gt;
&lt;h4&gt;Share this story&lt;/h4&gt;
&lt;/div&gt;
&lt;/aside&gt;&lt;p&gt;Facebook has touted its fact-checking process as one of the ways it intends to fight rampant disinformation heading into the 2020 US presidential election. New reports about the way the site handles the fact-checking of climate science stories, though, make clear that fact-checking can only work as well as Facebook allows it to—and that the months from now to November are going to be a slog.&lt;/p&gt;
&lt;p&gt;Facebook does not employ fact-checkers directly but rather &lt;a href=&quot;https://www.facebook.com/journalismproject/programs/third-party-fact-checking&quot;&gt;works with a range&lt;/a&gt; of third-party organizations to rate how true or false content shared in categories is. The efforts are not universal, however. While Facebook has &lt;a href=&quot;https://about.fb.com/news/2020/04/covid-19-misinfo-update/&quot;&gt;heavily invested&lt;/a&gt; in efforts to stem the overwhelming tide of false and misleading COVID-19 information, for example, it does not heavily fact-check information related to climate change.&lt;/p&gt;

&lt;p&gt;The New York Times &lt;a href=&quot;https://www.nytimes.com/2020/07/14/climate/climate-facebook-fact-checking.html&quot;&gt;recently explained&lt;/a&gt; the platform's reasoning behind how it handles climate change. Facebook considers opinion content &lt;a href=&quot;https://www.facebook.com/business/help/182222309230722&quot;&gt;largely exempt&lt;/a&gt; from review—and climate change can, as far as Facebook's rules are concerned, be a matter of opinion.&lt;/p&gt;
&lt;p&gt;Rarely reviewed, however, is different from never. &quot;When someone posts content based on false facts—even if it’s an op-ed or editorial—it is still eligible for fact-checking,&quot; Facebook Communications Director Andy Stone told the NYT. &quot;We're working to make this clearer in our guidelines so our fact checkers can use their judgment to determine whether it is an attempt to mask false information under the guise of opinion.&quot;&lt;/p&gt;
&lt;p&gt;The line has been clear as mud, so far, and Facebook has at least twice overturned the rulings of climate scientists who determine content to be partly or fully false. The first time, a group that partners with Facebook as one of its fact-checkers—Climate Feedback—marked a 2019 Washington Examiner op-ed as false. A climate-change denial organization, the CO2 Coalition, &lt;a href=&quot;https://www.eenews.net/stories/1063436369&quot;&gt;complained to Facebook&lt;/a&gt; about the fact-check, and the content warning was then removed.&lt;/p&gt;
&lt;p&gt;More recently, an article about climate change published by The Daily Wire, a right-leaning site that generates &lt;a href=&quot;https://www.newswhip.com/2020/06/top-publishers-facebook-may-2020/&quot;&gt;very high traffic&lt;/a&gt; on Facebook, also earned a &quot;partly false&quot; rating from Climate Feedback. The author of the Daily Wire article publicly complained about being &quot;censored,&quot; and Facebook staff reviewed the fact-check. Popular Information &lt;a href=&quot;https://popular.info/p/fact-check-of-viral-climate-misinformation&quot;&gt;obtained internal Facebook documents&lt;/a&gt; showing that the Facebook staff agreed with the &quot;partly false&quot; rating. An email thread that alerted high-ranking company executives to the kerfuffle showed that the fact-checking and communications teams apparently wanted to leave it alone, but the policy team said its &quot;stakeholders&quot; thought the fact-check was &quot;biased.&quot; The notice no longer appears on Facebook shares of the Daily Wire story.&lt;/p&gt;
&lt;h2&gt;Factually intermittent&lt;/h2&gt;
&lt;p&gt;Facebook and fact-checking have long had a rocky relationship.&lt;/p&gt;
&lt;p&gt;The company first established its system of third-party fact-checking &lt;a href=&quot;https://arstechnica.com/information-technology/2016/12/facebook-will-outsource-fact-checking-to-fight-fake-news/&quot;&gt;in late 2016&lt;/a&gt; in the wake of the half-dozen privacy and misinformation scandals surrounding the lead-up to that year's presidential election. Late last year, Facebook &lt;a href=&quot;https://arstechnica.com/tech-policy/2019/10/facebook-promises-to-beef-up-election-integrity-efforts-heading-into-2020/&quot;&gt;unveiled a slew of&lt;/a&gt; &quot;election integrity&quot; efforts aimed at avoiding the same pitfalls as we head into the 2020 election.&lt;/p&gt;
&lt;p&gt;That election is now just over 100 days away, and those efforts appear to have a mixed success rate at best. One of the few categories of political speech where Facebook does promise a bright line is any attempt at voter suppression. That includes advertisements that contain deliberate misinformation about voting, such as including the wrong date (the big day this year is November 3), as well as any ad that suggests &quot;voting is useless or meaningless, or advises people not to vote.&quot; The policy also prohibits ads that &quot;exclude people from political participation on the basis of things like race, ethnicity, or religion.&quot; Ads that say to vote or not to vote for a candidate because of their race or that threaten violence or intimidation fall under that guideline.&lt;/p&gt;

&lt;p&gt;Last week, however, &lt;a href=&quot;https://www.propublica.org/article/outright-lies-voting-misinformation-flourishes-on-facebook&quot;&gt;ProPublica reported&lt;/a&gt; that explicit misinformation about voting remains rampant on the platform. The problem is particularly pronounced with claims about voting by mail, which have increased as the COVID-19 pandemic has made remote voting seem the safer option for tens of millions of Americans.&lt;/p&gt;
&lt;p&gt;&quot;Many of these falsehoods appear to violate Facebook's standards yet have not been taken down or labeled as inaccurate,&quot; ProPublica notes. &quot;Some of them, generalizing from one or two cases, portrayed people of color as the face of voter fraud.&quot;&lt;/p&gt;
&lt;p&gt;False claims about voter fraud that come from politicians and candidates for office, including President Donald Trump, have proved particularly thorny for Facebook. While the platform &lt;a href=&quot;https://arstechnica.com/tech-policy/2020/03/facebook-pulls-trump-campaign-ads-for-fake-census-claims/&quot;&gt;did pull down ads&lt;/a&gt; from the Trump campaign that included misleading claims about the census, Facebook has been &lt;a href=&quot;https://arstechnica.com/tech-policy/2020/06/employees-civil-rights-groups-blast-facebook-inaction-on-trump-statements/&quot;&gt;highly reticent&lt;/a&gt; to touch statements from Trump or the Trump campaign, even when they violate Facebook's published standards.&lt;/p&gt;
&lt;p&gt;A group of senators led by Sen. Elizabeth Warren (D-Mass.) last week &lt;a href=&quot;https://www.warren.senate.gov/oversight/letters/warren-carper-whitehouse-schatz-call-on-mark-zuckerberg-and-facebook-to-stop-the-deliberate-spread-of-climate-disinformation-on-the-companys-social-media-platforms&quot;&gt;demanded Facebook explain&lt;/a&gt; its inconsistent position on fact-checking.&lt;/p&gt;
&lt;p&gt;&quot;Notably, since Facebook issued a blog post on its efforts to combat misinformation on Facebook in April 2017, disinformation campaigns on the platform have continued and expanded, often with state-sponsored support,&quot; the senators wrote. &quot;If Facebook is truly 'committed to fighting the spread of false news on Facebook and Instagram,' the company must immediately acknowledge in its fact-checking process that the climate crisis is not a matter of opinion and act to close loopholes that allow climate disinformation to spread on its platform.&quot;&lt;/p&gt;

</description>
<pubDate>Tue, 21 Jul 2020 13:11:27 +0000</pubDate>
<dc:creator>rbanffy</dc:creator>
<og:url>https://arstechnica.com/tech-policy/2020/07/facebook-overrides-fact-checks-when-climate-science-is-opinion/</og:url>
<og:title>Facebook overrides fact-checks when climate science is “opinion”</og:title>
<og:image>https://cdn.arstechnica.net/wp-content/uploads/2019/10/GettyImages-1052446892-760x380.jpg</og:image>
<og:description>Social network still has trouble separating “opinion” from disinformation.</og:description>
<og:type>article</og:type>
<dc:language>en-us</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://arstechnica.com/tech-policy/2020/07/facebook-overrides-fact-checks-when-climate-science-is-opinion/</dc:identifier>
</item>
<item>
<title>LinkedIn to cut 960 jobs worldwide</title>
<link>https://www.bbc.com/news/business-53484764</link>
<guid isPermaLink="true" >https://www.bbc.com/news/business-53484764</guid>
<description>&lt;figure class=&quot;media-landscape no-caption full-width lead&quot;&gt;&lt;span class=&quot;image-and-copyright-container&quot;&gt;
                
                &lt;img class=&quot;js-image-replace&quot; alt=&quot;Linked in logo with Coronavirus written behind&quot; src=&quot;https://ichef.bbci.co.uk/news/320/cpsprodpb/78AF/production/_113559803_gettyimages-1209215910.jpg&quot; width=&quot;976&quot; height=&quot;549&quot;/&gt;&lt;span class=&quot;off-screen&quot;&gt;Image copyright&lt;/span&gt;
                 &lt;span class=&quot;story-image-copyright&quot;&gt;Getty Images&lt;/span&gt;
                
            &lt;/span&gt;
            
        &lt;/figure&gt;&lt;p class=&quot;story-body__introduction&quot;&gt;Business networking site LinkedIn is to cut about 960 jobs worldwide after being hit by firms recruiting fewer staff amid the coronavirus pandemic. &lt;/p&gt;&lt;p&gt;The cuts will affect about 6% of the company's workforce across the globe, including the UK.&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://news.linkedin.com/2020/july/a-message&quot; class=&quot;story-body__link-external&quot;&gt;In a message&lt;/a&gt;, chief executive Ryan Roslansky said these were the only layoffs the firm was planning.&lt;/p&gt;&lt;p&gt;The announcement comes as sectors from retailing to airlines slash jobs around the world.&lt;/p&gt;&lt;p&gt;Microsoft-owned LinkedIn has offices in more than 30 cities around the world and employs 16,000 people. &lt;/p&gt;&lt;p&gt;The firm, which is based in California, is used by employers to find suitable candidates for jobs and by employees to search for new jobs.&lt;/p&gt;&lt;p&gt;Mr Roslansky said LinkedIn was &quot;not immune to the effects of the global pandemic&quot;.&lt;/p&gt;&lt;p&gt;&quot;Our Talent Solutions business continues to be impacted as fewer companies, including ours, need to hire at the same volume they did previously.&quot;&lt;/p&gt;&lt;p&gt;The job cuts are being made in the group's global sales and hiring divisions. &lt;/p&gt;&lt;p&gt;&quot;I want you to know these are the only layoffs we are planning,&quot; Mr Roslansky said.&lt;/p&gt;&lt;p&gt;In recent, months companies worldwide have shed tens of thousands of jobs, as they struggle to tackle the effects of reduced demand caused by coronavirus. &lt;/p&gt;&lt;p&gt;So far this week India's biggest airline IndiGo has said it will cut 10% of its staff and UK retailer Marks &amp;amp; Spencer has announced 950 job losses.  &lt;/p&gt;&lt;p&gt;Mr Roslansky said employees in Ireland, the UK, and Australia had already begun consultation about the potential impact on their jobs. &lt;/p&gt;&lt;p&gt;Staff in other parts of the world would find out about the impact on them over the coming days and months. &lt;/p&gt;&lt;p&gt;He added that LinkedIn would be investing in other parts of the business which would result in some job creation and the firm would &quot;work with employees impacted by today's announcement to explore these opportunities&quot;.&lt;/p&gt;
            </description>
<pubDate>Tue, 21 Jul 2020 12:26:31 +0000</pubDate>
<dc:creator>DarkContinent</dc:creator>
<og:title>LinkedIn to cut 960 jobs as recruitment falls</og:title>
<og:type>article</og:type>
<og:description>The networking site has been hit by fewer firms taking on staff amid the coronavirus pandemic.</og:description>
<og:url>https://www.bbc.com/news/business-53484764</og:url>
<og:image>https://ichef.bbci.co.uk/news/1024/branded_news/78AF/production/_113559803_gettyimages-1209215910.jpg</og:image>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.bbc.com/news/business-53484764</dc:identifier>
</item>
<item>
<title>Monitoring your own infrastructure using Grafana, InfluxDB, and CollectD</title>
<link>https://serhack.me/articles/monitoring-infrastructure-grafana-influxdb-connectd/</link>
<guid isPermaLink="true" >https://serhack.me/articles/monitoring-infrastructure-grafana-influxdb-connectd/</guid>
<description>&lt;p class=&quot;publish-date&quot;&gt;Published at July 21, 2020 – 9 min read&lt;/p&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;p&gt;&lt;img src=&quot;https://serhack.me/images/grafana/all%20together%20now_wide.jpg&quot; alt=&quot;Grafana, InfluxDB and CollectD&quot;/&gt;&lt;/p&gt;
&lt;h4 id=&quot;for-some-companies-infrastructure-is-the-heart-of-its-business-specifically-i-am-referring-to-those-companies-which-need-to-manage-data-and-applications-located-on-more-than-one-server&quot;&gt;For some companies, infrastructure is the heart of its business. Specifically, I am referring to those companies which need to manage data and applications located on more than one server.&lt;/h4&gt;
&lt;p&gt;It is essential for a company to monitor its infrastructure nodes, especially if the company does not have on-site access to intervene when issues arise. In fact, the intensive use of some resources can be an indication of malfunctioning or overcrowding. However, in addition to prevention, monitoring could be used to assess possible implications of new software in the production environment. Currently, there are several “ready-to-use” solutions on the market to keep track of all the resources consumed. These solutions, which appear reasonable, present two key problems: the high price of setup and security issues related to third parties.&lt;/p&gt;
&lt;p&gt;The first problem is related to cost. Prices vary from 10 euros per month up to thousands depending on how many hosts you need to monitor — with the former being consumer pricing and the latter being enterprise pricing. So, for example, let’s imagine that I have three nodes to monitor during the course of a year. At 10 euros per month, I would spend 120 euros. For smaller enterprises, where the price can range between 10,000 and 20,000 euro per year, such an expense can bloat its underlying cost structure and become financially untenable.&lt;/p&gt;
&lt;p&gt;The second problem is third party risk. Typically, infrastructure data must pass through a third party company in order to be seen and analysed for the customer — whether that be an individual consumer or an enterprise. How does the third party company capture the data and then present it to the customer? Simply put, the third party company often collects data through a custom agent that is installed onto a node and monitored. Quite often is it found that this installation is not up-to-date and compatible with operating systems. Previous work has been done by security researchers who cast light upon problems with &lt;a href=&quot;https://www.rapid7.com/db/modules/exploit/linux/misc/nagios_nrpe_arguments&quot;&gt;“proprietary collectors”&lt;/a&gt;. Would you trust them? I would not.&lt;/p&gt;
&lt;p&gt;In keeping nodes for both &lt;a href=&quot;https://trac.torproject.org/projects/tor/wiki/TorRelayGuide&quot;&gt;Tor&lt;/a&gt; and some &lt;a href=&quot;https://getmonero.org&quot;&gt;cryptocurrencies&lt;/a&gt;, I prefer to opt for a cost free, easy to configure, and open-source alternative. Here, we will use the triad: Grafana, InfluxDB, and CollectD.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://serhack.me/images/grafana/grafana-graphs.png&quot; alt=&quot;An example of a Grafana dashboard&quot;/&gt;&lt;/p&gt;
&lt;h2 id=&quot;monitoring&quot;&gt;Monitoring&lt;/h2&gt;
&lt;p&gt;In order to be able to analyse every metric of our infrastructure, it is necessary to use a program capable of capturing statistics on the machines we want to monitor. In this regard, &lt;a href=&quot;https://collectd.org/&quot;&gt;CollectD&lt;/a&gt; comes to your aid: it is a daemon that groups and collects (hence the name) all the parameters that can be stored on disk or sent over the network.&lt;/p&gt;
&lt;p&gt;The data will be transmitted to an instance of &lt;a href=&quot;https://www.influxdata.com/&quot;&gt;InfluxDB&lt;/a&gt;: a particular time series database that associates to each data the time (coded in UNIX timestamp) in which the server received it. In this way, the data sent by CollectD will already be set in a temporal way, as a succession of events.&lt;/p&gt;
&lt;p&gt;Finally, you will use &lt;a href=&quot;http://grafana.org/&quot;&gt;Grafana&lt;/a&gt; which will connect to InfluxDB to create flashy dashboards to display the data in a user-friendly way. Through histograms and graphs of every kind, it will be possible to observe in real time all the data related to CPU, RAM, etc.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://serhack.me/images/grafana/grafana-diagram.png&quot; alt=&quot;Grafana infrastructure&quot;/&gt;&lt;/p&gt;
&lt;h2 id=&quot;influxdb&quot;&gt;InfluxDB&lt;/h2&gt;
&lt;img data-original=&quot;/images/grafana/db_alone.jpg&quot; data-original-set=&quot;/images/grafana/db_alone_wide.jpg 2x&quot; src=&quot;https://serhack.me/images/grafana/db_alone_wide.jpg&quot; alt=&quot;&quot;/&gt;&lt;p&gt;Let’s start with InfluxDB, which is the beating heart of our monitoring “system”. InfluxDB is a time series database &lt;a href=&quot;https://github.com/influxdata/influxdb&quot;&gt;open-source&lt;/a&gt; developed in &lt;a href=&quot;https://golang.org/&quot;&gt;Go&lt;/a&gt; to store data as a sequence of events.&lt;/p&gt;
&lt;p&gt;Each time data is added, it is linked to &lt;a href=&quot;https://en.wikipedia.org/wiki/Unix_time&quot;&gt;a UNIX timestamp&lt;/a&gt; by default. This allows enormous flexibility for the user who no longer has to worry about saving, as an example, the “time” variable, which is sometimes cumbersome to configure. Let’s imagine we have several machines located in a number of continents. How do we manage the “time” variable? Do we use the &lt;a href=&quot;https://en.wikipedia.org/wiki/Greenwich_Mean_Time&quot;&gt;Greenwich&lt;/a&gt; meridian for all the data? Or do we set a different time zone for each node? If data is saved on different time zones, how can we accurately display the graphs? As you can see, this can be very complicated.&lt;/p&gt;
&lt;p&gt;As a time-aware database that automatically timestamps any data point, InfluxDB has the advantage of simultaneously being able to write to a certain database. This is why we often imagine InfluxDB as a timeline. Writing data does not affect the performance of the database (as sometimes happens in MySQL), since writing is simply the addition of a certain event to the timeline. The name of the program derives precisely from the conception of time as an infinite and indefinite “flow” that flows.&lt;/p&gt;
&lt;h3 id=&quot;installation-and-configuration&quot;&gt;Installation and configuration&lt;/h3&gt;
&lt;p&gt;Another advantage of InflxuDB is the &lt;a href=&quot;https://docs.influxdata.com/influxdb/v1.8/introduction/install/&quot;&gt;ease of installation&lt;/a&gt; and the extensive &lt;a href=&quot;https://docs.influxdata.com/&quot;&gt;documentation&lt;/a&gt; provided by the community that widely supports the project. It has two types of interfaces: via &lt;a href=&quot;https://docs.influxdata.com/influxdb/v1.8/tools/shell/&quot;&gt;Command Line&lt;/a&gt; (which is powerful and flexible for developers, but poorly prepared to see large amounts of data) and an &lt;a href=&quot;https://docs.influxdata.com/influxdb/v1.8/guides/write_data/#sidebar&quot;&gt;HTTP API&lt;/a&gt; that allows direct communication with the database.&lt;/p&gt;
&lt;p&gt;InfluxDB can be downloaded not only from the official website, but also from the package manager of the distribution (in this example we use a Debian system). It is advisable to check the package via GPG before installation, so (below) we import the keys of the InfluxDB package:&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;a href=&quot;https://serhack.me/cdn-cgi/l/email-protection&quot; class=&quot;__cf_email__&quot; data-cfemail=&quot;f785989883b799989392&quot;&gt;[email protected]&lt;/a&gt;#~: curl -sL https://repos.influxdata.com/influxdb.key | sudo apt-key add -
&lt;a href=&quot;https://serhack.me/cdn-cgi/l/email-protection&quot; class=&quot;__cf_email__&quot; data-cfemail=&quot;4e3c21213a0e20212a2b&quot;&gt;[email protected]&lt;/a&gt;#~: source /etc/os-release
&lt;a href=&quot;https://serhack.me/cdn-cgi/l/email-protection&quot; class=&quot;__cf_email__&quot; data-cfemail=&quot;bcced3d3c8fcd2d3d8d9&quot;&gt;[email protected]&lt;/a&gt;#~: echo &lt;span&gt;&quot;deb https://repos.influxdata.com/debian &lt;/span&gt;&lt;span&gt;$(&lt;/span&gt;lsb_release -cs&lt;span&gt;)&lt;/span&gt;&lt;span&gt; stable&quot;&lt;/span&gt; | sudo tee /etc/apt/sources.list.d/influxdb.list&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Finally, we update and install InfluxDB:&lt;/p&gt;

&lt;p&gt;To start it, we use &lt;code&gt;systemctl&lt;/code&gt;:&lt;/p&gt;

&lt;p&gt;To make sure that no one nefarious enters, we create the user “administrator”. InfluxDB uses a particular query language called &lt;a href=&quot;https://docs.influxdata.com/influxdb/v1.8/query_language/&quot;&gt;“InfluxQL”&lt;/a&gt;, similar to SQL, which allows you to interact with the database. To create a new entry, we use the query &lt;a href=&quot;https://docs.influxdata.com/influxdb/v1.8/administration/authentication_and_authorization/#user-management-commands&quot;&gt;&lt;code&gt;CREATE USER&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;a href=&quot;https://serhack.me/cdn-cgi/l/email-protection&quot; class=&quot;__cf_email__&quot; data-cfemail=&quot;5b2934342f1b35343f3e&quot;&gt;[email protected]&lt;/a&gt;#~: influx
Connected to http://localhost:8086
InfluxDB shell version: x.y.z
&amp;gt;
&amp;gt; CREATE USER admin WITH PASSWORD &lt;span&gt;'MYPASSISCOOL'&lt;/span&gt; WITH ALL PRIVILEGES&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;From the same CLI interface, we create the “metrics” database that will be used as a container for our metrics.&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&amp;gt; CREATE DATABASE metrics&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Next, let’s modify the configuration of InfluxDB (&lt;code&gt;/etc/influxdb/influxdb.conf&lt;/code&gt;) to have the interface open on port &lt;strong&gt;24589&lt;/strong&gt; (UDP) with direct connection to the database named “metrics” in support of CollectD. You also need to download and place the &lt;a href=&quot;https://raw.githubusercontent.com/collectd/collectd/master/src/types.db&quot;&gt;types.db&lt;/a&gt; file in &lt;code&gt;/usr/share/collectd/&lt;/code&gt; (or any other folder) to define the data that &lt;a href=&quot;https://docs.influxdata.com/influxdb/v1.8/supported_protocols/collectd/&quot;&gt;CollectD sends in native format&lt;/a&gt;.&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;a href=&quot;https://serhack.me/cdn-cgi/l/email-protection&quot; class=&quot;__cf_email__&quot; data-cfemail=&quot;e694898992a688898283&quot;&gt;[email protected]&lt;/a&gt;#~: nano /etc/influxdb/influxdb.conf
&lt;span&gt;[&lt;/span&gt;Collectd&lt;span&gt;]&lt;/span&gt;
enabled &lt;span&gt;=&lt;/span&gt; true
bind-address &lt;span&gt;=&lt;/span&gt; &lt;span&gt;&quot;:24589&quot;&lt;/span&gt;
database &lt;span&gt;=&lt;/span&gt; &lt;span&gt;&quot;metrics&quot;&lt;/span&gt;
typesdb &lt;span&gt;=&lt;/span&gt; &lt;span&gt;&quot;/usr/share/collectd/types.db&quot;&lt;/span&gt;&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;For further information on the CollectD block within the configuration, see the &lt;a href=&quot;https://docs.influxdata.com/influxdb/v1.8/administration/config/#collectd-settings&quot;&gt;reference to documentation&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&quot;collectd&quot;&gt;CollectD&lt;/h2&gt;
&lt;img data-original=&quot;/images/grafana/daemon_alone.jpg&quot; data-original-set=&quot;/images/grafana/daemon_alone_wide.jpg 2x&quot; src=&quot;https://serhack.me/images/grafana/daemon_alone_wide.jpg&quot; alt=&quot;&quot;/&gt;&lt;p&gt;CollectD is a data aggregator, in our monitoring infrastructure, that facilitates the transmission of data to InfluxDB. By default, CollectD captures metrics on CPU, RAM, memory (on disk), network interfaces, processes, etc. The potential of the program is endless, given that it can be extended with a preinstalled &lt;a href=&quot;https://collectd.org/wiki/index.php/Table_of_Plugins&quot;&gt;plugin enablement&lt;/a&gt; or through the &lt;a href=&quot;https://collectd.org/wiki/index.php/Roadmap#Wishlist_.2F_Ideas&quot;&gt;creation of new ones&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;As you can see, installing CollectD is simple:&lt;/p&gt;

&lt;p&gt;In a simplistic manner, let’s illustrate how CollectD works. Suppose that I want to check how many processes my node has. In doing so, CollectD does nothing more than make an API call to get the number of processes per time unit (defined as 5000 ms, by default). Once captured, the data will be sent to InfluxDB via a module (called “Network”) to be configured.&lt;/p&gt;
&lt;p&gt;Open the file &lt;code&gt;/etc/collectd.conf&lt;/code&gt; with our editor, scroll to find the &lt;code&gt;Network&lt;/code&gt; section, and edit as written in the following snippet. Be sure to specify the IP where the interface of InfluxDB (&lt;code&gt;INFLUXDB_IP&lt;/code&gt;) is located.&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;a href=&quot;https://serhack.me/cdn-cgi/l/email-protection&quot; class=&quot;__cf_email__&quot; data-cfemail=&quot;26544949526648494243&quot;&gt;[email protected]&lt;/a&gt;#~: nano /etc/collectd.conf
    ...
&amp;lt;Plugin network&amp;gt;
  &amp;lt;Server &lt;span&gt;&quot;INFLUXDB_IP&quot;&lt;/span&gt; &lt;span&gt;&quot;24589&quot;&lt;/span&gt;&amp;gt;
  &amp;lt;/Server&amp;gt;
  ReportStats true
&amp;lt;/Plugin&amp;gt;
    ...&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;My suggestion is to modify, within the configuration, the hostname that is sent to InfluxDB (which in our infrastructure is a “centralized” database, since it resides on a single node). In doing so, the data will not be redundant and there is no risk that other nodes will overwrite the information.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://serhack.me/images/grafana/tres_caballeros.jpg&quot; alt=&quot;Three daemon&quot;/&gt;&lt;/p&gt;
&lt;h2 id=&quot;grafana&quot;&gt;Grafana&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;https://serhack.me/images/grafana/grafana_alone.jpg&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;A graph is worth thousand of images&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;In remembrance of this famous “quote”, observing the infrastructure metrics live through graphs and tables enables us to act in an efficient and timely manner. To create and configure the dashboard, we will use Grafana.&lt;/p&gt;
&lt;p&gt;Grafana is an open-source tool, compatible with a wide range of databases (including InfluxDB), that presents a graphical representation of metrics and allows a user to create alerts if a particular piece of data meets a condition. For example, if your CPU reaches high peaks, you can be notified on Slack, Mattermost, by email, etc. In fact, I have personally configured an alert every time someone enters SSH, so I can actively monitor who “enters” my infrastructure.&lt;/p&gt;
&lt;p&gt;Grafana does not require any special settings: once again, it is InfluxDB that “scans” the “time” variable. The integration is simple. Let’s start by import the public key to add the package from the &lt;a href=&quot;https://grafana.com/grafana/download&quot;&gt;Grafana official website&lt;/a&gt; (it depends on the OS you are using):&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;
&lt;pre&gt;
&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;a href=&quot;https://serhack.me/cdn-cgi/l/email-protection&quot; class=&quot;__cf_email__&quot; data-cfemail=&quot;2d5f4242596d43424948&quot;&gt;[email protected]&lt;/a&gt;#~: wget -q -O - https://packages.grafana.com/gpg.key | sudo apt-key add -
&lt;a href=&quot;https://serhack.me/cdn-cgi/l/email-protection&quot; class=&quot;__cf_email__&quot; data-cfemail=&quot;cfbda0a0bb8fa1a0abaa&quot;&gt;[email protected]&lt;/a&gt;#~: echo &lt;span&gt;&quot;deb https://packages.grafana.com/oss/deb stable main&quot;&lt;/span&gt; | sudo tee -a /etc/apt/sources.list.d/grafana.list 
&lt;a href=&quot;https://serhack.me/cdn-cgi/l/email-protection&quot; class=&quot;__cf_email__&quot; data-cfemail=&quot;a8dac7c7dce8c6c7cccd&quot;&gt;[email protected]&lt;/a&gt;#~: apt-get update &lt;span&gt;&amp;amp;&amp;amp;&lt;/span&gt; apt-get install grafana&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Let’s start it through systemctl:&lt;/p&gt;

&lt;p&gt;Next, as we go to the localhost:3000 page through the browser, we should be presented with a login interface for Grafana. By default, you should use &lt;strong&gt;admin&lt;/strong&gt; as username and &lt;strong&gt;admin&lt;/strong&gt; as password (it is advisable to change the password after the first login).&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://serhack.me/images/grafana/login-page.png&quot; alt=&quot;Login page&quot;/&gt;&lt;/p&gt;
&lt;p&gt;Let’s go to Sources and add our Influx database:&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://serhack.me/images/grafana/add-data-source.png&quot; alt=&quot;Add data source to Grafana&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://serhack.me/images/grafana/influxdb.png&quot; alt=&quot;InfluxDB&quot;/&gt;&lt;/p&gt;
&lt;p&gt;The screen now shows a small green rectangle just below the New Dashboard. Hover your mouse over this rectangle and select Add Panel, then Graph:&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://serhack.me/images/grafana/add-new-panel.png&quot; alt=&quot;Add a new panel&quot;/&gt;&lt;/p&gt;
&lt;p&gt;A graph with the test data is now shown. Click on the title of this chart and choose Edit. Grafana allows the writing of intelligent queries: you do not have to know every field of the database, as Grafana proposes them through a list from which you can choose the parameter to analyse.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://grafana.com/static/img/docs/v45/influxdb_query.gif&quot; alt=&quot;Intelligent queries&quot;/&gt;&lt;/p&gt;
&lt;p&gt;Writing queries has never been easier: just select the measurement you would like to trace and click Refresh. I also recommend differentiating the metrics by hostname, so it is easier to isolate any problems. If you are looking for other ideas for creating dashboards, I recommend visiting &lt;a href=&quot;https://grafana.com/grafana/dashboards?orderBy=name&amp;amp;direction=asc&quot;&gt;Grafana showcase&lt;/a&gt; for inspiration.&lt;/p&gt;
&lt;p&gt;As we have noticed, Grafana is very extensible and allows us to compare data of different nature. There is no metric that cannot be captured, so creativity is your only limit. Monitor your machine and get a universal, live view of your infrastructure!&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://serhack.me/images/grafana/theend.jpg&quot; alt=&quot;the end&quot;/&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;span class=&quot;credits&quot;&gt;I really would like to thank &lt;a href=&quot;https://anhdr.es&quot;&gt;Andrés&lt;/a&gt; for his illustrations.&lt;/span&gt;</description>
<pubDate>Tue, 21 Jul 2020 12:02:37 +0000</pubDate>
<dc:creator>crecker</dc:creator>
<og:type>article</og:type>
<og:description>Have you ever wondered which node consumes more resources? Managing a bespoke dashboard for your infrastructure. Learn how to create it.</og:description>
<og:title>Monitoring your own infrastructure using Grafana, InfluxDB, and CollectD</og:title>
<og:image>https://serhack.me/images/grafana/socialmedia.jpg</og:image>
<og:url>https://serhack.me/articles/monitoring-infrastructure-grafana-influxdb-connectd/</og:url>
<dc:language>en-us</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://serhack.me/articles/monitoring-infrastructure-grafana-influxdb-connectd/</dc:identifier>
</item>
<item>
<title>Harvard CS professor David Malan built a distance-learning empire</title>
<link>https://www.newyorker.com/news/our-local-correspondents/how-harvards-star-computer-science-professor-built-a-distance-learning-empire</link>
<guid isPermaLink="true" >https://www.newyorker.com/news/our-local-correspondents/how-harvards-star-computer-science-professor-built-a-distance-learning-empire</guid>
<description>&lt;p class=&quot;has-dropcap has-dropcap__lead-standard-heading&quot;&gt;Gabriel Guimaraes grew up in Vitória, Brazil, in a yellow house surrounded by star-fruit trees and chicken coops. His father, who wrote software for a local bank, instilled in him an interest in computers. On weekends, when Guimaraes got bored with Nintendo video games, he programmed his own. In grade school, he built a humanoid robot and wrote enough assembly code to make it zip around his home. In Vitória, an island city, his most ambitious peers dreamed of attending university in São Paulo, an hour away by plane. Guimaraes set his sights on the Massachusetts Institute of Technology. By the time he was in high school, M.I.T. had released hundreds of its classes, free of charge, on the Internet, as a series of massive open online courses, or &lt;a href=&quot;https://www.newyorker.com/magazine/2013/05/20/laptop-u&quot;&gt;&lt;em class=&quot;small&quot;&gt;MOOCs&lt;/em&gt;&lt;/a&gt;. Guimaraes sampled the introductory computer-science class, but he found the lecturer, a “white-haired guy in front of a blackboard,” crushingly dull. In 2011, trawling YouTube for other course material, Guimaraes clicked on a lecture from Harvard’s introductory computer-science class, CS50, which was taught by a young professor named David Malan. Almost instantly, Guimaraes told me, he felt himself “hypnotized.”&lt;/p&gt;

&lt;p&gt;Malan, who had glossy black hair and an energetic mien, lectured from a grand auditorium on Harvard’s campus. In the first class, he illustrated an algorithm called binary search by inviting a volunteer onstage to find “Mike Smith” in the Yellow Pages; at Malan’s urging, the student opened up the phone book to a random spot, tore off the half of the book without the right name, and then repeated the process, halving the volume again and again, until only the desired page remained. Malan’s assignments, too, eased students into the arcana of computer science. Before learning C, a low-level programming language with finicky syntax, they created animated games in Scratch, a visual programming language designed for children. For a forensics problem set, inspired by a summer that Malan spent working in a district attorney’s office, students were asked to write code to restore a set of deleted photo files. “It felt like the coolest video game I’d ever gotten my hands on,” Guimaraes said.&lt;/p&gt;
&lt;p&gt;On Harvard’s campus, CS50 culminates in a festive exposition, where students show off their final coding projects and hobnob with technical recruiters from companies like Facebook and Google, many of whom are alumni of the class; Malan provides a bevy of free paraphernalia, including CS50-branded stress balls and T-shirts that read, “I TOOK CS50.” In Brazil, Guimaraes decided to conduct his own final project: a re-creation of Malan’s course materials and lectures in Portuguese. In his sophomore year of high school, he taught &lt;a class=&quot;external-link&quot; data-event-click=&quot;{&amp;quot;element&amp;quot;:&amp;quot;ExternalLink&amp;quot;,&amp;quot;outgoingURL&amp;quot;:&amp;quot;https://materiais.estudarfora.org.br/cc50/&amp;quot;}&quot; href=&quot;https://materiais.estudarfora.org.br/cc50/&quot; rel=&quot;nofollow noopener&quot; target=&quot;_blank&quot;&gt;CC50&lt;/a&gt;—&lt;em&gt;Ciência da Computação Cinquenta&lt;/em&gt;—to his peers, during eleven weeks of the fall term. When Guimaraes arrived for the first class, bearing, as Malan did, a gargantuan sheet cake as a welcome treat, he found about a hundred students snaking out the door. Dressed in a baggy Harvard shirt that he’d bought online, he delivered Malan’s first lecture, repeating the phone-book demonstration with an old dictionary. CS50’s course materials were freely distributed under a Creative Commons license, but, as a courtesy, Guimaraes had e-mailed Malan’s staff a heads-up about his project. During the sixth week of his lectures, he received a gift box from Malan, stuffed with CS50 swag.&lt;/p&gt;

&lt;p&gt;Malan, who took over CS50 in 2007, was a pioneer in distributing Harvard course materials online for free. In 2012, Harvard and M.I.T. launched their own online-learning platform, edX, which today offers several thousand &lt;em class=&quot;small&quot;&gt;MOOCs&lt;/em&gt;—both digital editions of existing university courses and original certificate programs designed by Microsoft, I.B.M., and other technology giants. But few, if any, combine the institutional credibility, the enormous reach, and the zealous engagement of Malan’s. In the decade since Guimaraes took it, CS50 has inspired satellite operations on every continent except Antarctica. Though most of the students who sign up for the edX version—more than two million to date—quit before finishing, those who stick with it often become diehards: earlier this year, in Baghdad, students restaged Malan’s project fair at al-Hikma University with identical trimmings, down to the emoji-shaped balloons and the custom “debugging” rubber ducks. To promote the expansion of CS50, Malan films welcome teasers for the remote cohorts, hosts annual educator workshops, and helps prop up outposts around the world. CS50 is less a single course than an “ecosystem of courses,” as one staff member put it, with spinoffs designed for specific audiences: lawyers, business students, gamers. In 2015, Harvard’s computer-science department launched an unprecedented partnership with Yale, live-streaming Malan’s lectures from Cambridge to New Haven.&lt;/p&gt;
&lt;p&gt;Malan’s investment in virtual learning has transformed the way that students engage with the class at its home base, too. CS50 is one of Harvard College’s most popular courses; it’s also the only one that students can watch live, in high definition, from their dorms. In the past, Malan has encouraged them to do so, writing, in a blog post from 2016, that it might well be “a better educational experience to watch CS50’s lectures online than attend them in person.” Prioritizing remote teaching to such an extent is still a rarity among Harvard professors. Even Michael Sandel’s Justice, another flagship Harvard lecture course, whose online counterpart predates CS50 and was broadcast on PBS, has little of Malan’s technological infrastructure. In March, when the &lt;a href=&quot;https://www.newyorker.com/tag/coronavirus&quot;&gt;coronavirus pandemic&lt;/a&gt; forced universities across the country to migrate classes online, no more than five hundred Harvard instructors had virtual teaching experience, the university’s president, Lawrence Bacow, told me in an e-mail. In a matter of days, the number “jumped to about three thousand,” the size of Harvard’s entire teaching staff.&lt;/p&gt;

&lt;p&gt;For many professors, the sudden transition was a struggle. For Malan, it was the natural extension of a decade’s worth of experimentation. “Our team is fortunate to have been doing this blend of education for quite some time,” he told me recently. “For us, it was very straightforward.” Malan’s contract at Harvard allows him to focus almost exclusively on CS50; even the research he publishes centers mainly on the class. In the spring, he happened to be piloting a small version of CS50, historically a fall course, using online-only lectures filmed in the previous term. The pandemic prompted him to move parts of the curriculum—office hours, a weekly tutorial, the project fair—to Zoom. But, while his colleagues were scrambling to retool their classes for virtual platforms—troubleshooting unfamiliar technology, shortening lessons, building in interactivity—the substance and presentation of CS50, as one student wrote in an end-of-term evaluation, “pretty much stayed the exact same.” Malan’s method of remote teaching is not easily replicable; CS50’s pyrotechnics would not be possible without an unusually deep well of resources and his own fanatical commitment. But, as universities attempt to reopen safely in the fall, with online learning at the forefront, the course’s spread and success provide a glimpse of where higher education might be headed.&lt;/p&gt;
&lt;p class=&quot;has-dropcap has-dropcap__lead-standard-heading&quot;&gt;One muggy morning in June, Malan visited Harvard’s campus. Sanders Theatre, where he lectures, was still officially closed, but a few members of CS50’s staff had received special permission to enter. I found Malan at a side door. He was wearing a mask and, over one shoulder, carried a backpack containing two laptops. Inside, signs in Harvard’s colors encouraged hand washing and social distancing. Doors had been propped open, to reduce human contact with knobs and handles; a red brick, stationed on the floor outside the bathroom, could be kicked aside to signal that someone was inside. Harvard had not yet finalized its reopening plans, but the university had released an interim report earlier in the week, stating that, “regardless of whether students are on campus, learning will be remote next year, with only rare exceptions.” For more than two months, Malan had been holding CS50’s office hours online, both for his Harvard class and, separately, for outside students, in sessions open to the public. Now he was going to try streaming his office hours from Sanders, to see how it would feel to teach there, in the fall, with only a virtual audience. More than a thousand students, from a hundred and nine countries, had registered to attend the day’s session.&lt;/p&gt;
</description>
<pubDate>Tue, 21 Jul 2020 11:22:39 +0000</pubDate>
<dc:creator>alienreborn</dc:creator>
<og:description>David Malan, of the hit class CS50, was working to perfect online teaching long before the pandemic. Is his method a model for the future of higher education?</og:description>
<og:image>https://media.newyorker.com/photos/5f160e2f68db026f7c859d83/16:9/w_1280,c_limit/Orbey-DavidMalanCS50-3.jpg</og:image>
<og:title>How Harvard’s Star Computer-Science Professor Built a Distance-Learning Empire</og:title>
<og:type>article</og:type>
<og:url>https://www.newyorker.com/news/our-local-correspondents/how-harvards-star-computer-science-professor-built-a-distance-learning-empire</og:url>
<dc:language>en-us</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.newyorker.com/news/our-local-correspondents/how-harvards-star-computer-science-professor-built-a-distance-learning-empire</dc:identifier>
</item>
<item>
<title>Invert, always, invert</title>
<link>https://www.anup.io/2020/07/20/invert-always-invert/</link>
<guid isPermaLink="true" >https://www.anup.io/2020/07/20/invert-always-invert/</guid>
<description>&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;man muss immer umkehren - Carl Gustav Jacob Jacobi&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;(loosely translated - Invert, always, invert)&lt;/p&gt;
&lt;p&gt;Today, we will look at one of my favourite mental models called - The &lt;strong&gt;&lt;em&gt;Inversion principle&lt;/em&gt;&lt;/strong&gt;. &lt;a href=&quot;https://fs.blog/mental-models/#what_are_mental_models&quot;&gt;Mental models&lt;/a&gt; are a set of simple, abstract but useful principles that help us make sense of the world around us.&lt;/p&gt;
&lt;p&gt;I came across the Inversion principle on the &lt;a href=&quot;https://fs.blog/2013/10/inversion/&quot;&gt;Farnam Street blog&lt;/a&gt;. It is also a favourite of Charlie Munger (Vice Chairman of Berkshire Hathaway and Warren Buffets mate) - &quot;...it is in the nature of things that many hard problems are best solved when they are addressed backward&quot;, he pontificates.&lt;/p&gt;
&lt;p&gt;In another interview, he recalls how, as an Air Force meteorologist during World War II, instead of asking what would keep pilots safe, he asked what would kill them and focussed all his efforts &quot;on trying to predict snow, ice or fog—and to ignore pretty much everything else.&quot;.&lt;/p&gt;
&lt;p&gt;I could write a book on all the other cool stuff Charlie Munger has said so I'll stop here.&lt;/p&gt;
&lt;h3 id=&quot;what-is-it&quot;&gt;What is it?&lt;/h3&gt;
&lt;p&gt;Inversion is based on the maxim - invert, always, invert. It is about considering an inverse (usually a negative) outcome and listing the reasons for these. It forces you to either stop doing certain things or avoid the actions that lead to the negative outcomes. It gives us &lt;em&gt;&lt;em&gt;new possibilities&lt;/em&gt; and capabilities&lt;/em&gt; that we might not have considered otherwise.&lt;/p&gt;
&lt;p&gt;The algorithm for inversion is very simple:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Define the problem&lt;/strong&gt; - what is it that  you're trying to achieve?&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Invert it&lt;/strong&gt; - what would guarantee the failure to achieve this outcome?&lt;/li&gt;
&lt;li&gt;Finally, &lt;strong&gt;consider solutions to avoid this failure&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;This is very abstract and vague, so let's look at a few examples:&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;Instead of asking how do we increase the adoption of a product or feature? You could instead consider - what are some of things preventing adoption? This would lead to a list like this that you could potentially fix:&lt;/li&gt;
&lt;/ol&gt;&lt;ul&gt;&lt;li&gt;Slow load time i.e. performance issues&lt;/li&gt;
&lt;li&gt;Not enough marketing, or marketing on the platform, or to the wrong audience&lt;/li&gt;
&lt;li&gt;The user guide instructions are not clear ... you get the idea&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;2.  Following the inversion principle it is &lt;em&gt;better to ask&lt;/em&gt; what is preventing me from reading all the unread books on my kindle/bookshelf, instead of asking how can i read more books? Possible reasons and something you could give up:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;I spend a lot of time on social media&lt;/li&gt;
&lt;li&gt;I watch too many shows on Netflix or Disney +&lt;/li&gt;
&lt;li&gt;Spend a lot of time on reddit or browsing hacker news&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;3. Instead of wondering how do I always choose a winning stock during investing, ask yourself how do you prevent losses in the long term?&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;Am I diversifying enough to prevent long term loss?&lt;/li&gt;
&lt;li&gt;Am I investing  based on sound principles, or am I speculating?&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;Hopefully this  gives you a flavour of how powerful inversion is as a mental model. I should add that it is NOT a silver bullet and it won't always give you concrete answers, but it will act as a forcing function to avoid obvious lapses in judgment. I'll leave you with another one of my favourite quotes about Inversion from Charlie.&lt;/p&gt;
&lt;blockquote readability=&quot;7&quot;&gt;
&lt;p&gt;&quot;It is remarkable how much long-term advantage people like us have gotten by trying to be consistently not stupid, instead of trying to be very intelligent.&quot;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr/&gt;&lt;p&gt;Further reading:&lt;/p&gt;
&lt;blockquote class=&quot;wp-embedded-content&quot; readability=&quot;0&quot;&gt;
&lt;p&gt;&lt;a href=&quot;https://fs.blog/2014/06/avoiding-stupidity/&quot;&gt;Avoiding Stupidity is Easier than Seeking Brilliance&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;div class=&quot;kg-bookmark-content&quot; readability=&quot;35&quot;&gt;
&lt;p&gt;Putting Mental Models to Practice Part 3: Better Trial and Error&lt;/p&gt;
&lt;p&gt;Instrumental rationality is the sort of thinking that allows you to achieve your goals. We take a closer look at what decision science says is the ‘best’ way to pursue this purpose.&lt;/p&gt;

&lt;/div&gt;
&lt;div class=&quot;kg-bookmark-thumbnail&quot;&gt;&lt;img src=&quot;https://commoncog.com/blog/content/images/2018/12/burst-530182-unsplash--1-.jpg&quot;/&gt;&lt;/div&gt;
&lt;p&gt;Thanks for taking the time to read this post, if you found it useful and if you have any comments or more tips, please hit me up on twitter (@&lt;a href=&quot;https://twitter.com/anup&quot;&gt;anup&lt;/a&gt;).&lt;/p&gt;
</description>
<pubDate>Tue, 21 Jul 2020 08:23:51 +0000</pubDate>
<dc:creator>anupj</dc:creator>
<og:type>article</og:type>
<og:title>Invert, always, invert</og:title>
<og:description>man muss immer umkehren - Carl Gustav Jacob Jacobi(loosely translated - Invert, always, invert) Today, we will look at one of my favourite mental models called - The Inversion principle. Mental models are a set of simple, abstract but useful principles that help us make sense of the world</og:description>
<og:url>https://www.anup.io/2020/07/20/invert-always-invert/</og:url>
<og:image>https://www.anup.io/content/images/2020/07/nine-kopfer-tJC6I9S3nBw-unsplash.jpg</og:image>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.anup.io/2020/07/20/invert-always-invert/</dc:identifier>
</item>
<item>
<title>Wiki.js</title>
<link>https://wiki.js.org/</link>
<guid isPermaLink="true" >https://wiki.js.org/</guid>
<description>[unable to retrieve full-text content]
&lt;p&gt;Article URL: &lt;a href=&quot;https://wiki.js.org/&quot;&gt;https://wiki.js.org/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Comments URL: &lt;a href=&quot;https://news.ycombinator.com/item?id=23904193&quot;&gt;https://news.ycombinator.com/item?id=23904193&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Points: 352&lt;/p&gt;
&lt;p&gt;# Comments: 189&lt;/p&gt;
</description>
<pubDate>Tue, 21 Jul 2020 03:49:05 +0000</pubDate>
<dc:creator>akandiah</dc:creator>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://wiki.js.org/</dc:identifier>
</item>
<item>
<title>Systems Design for Advanced Beginners</title>
<link>https://robertheaton.com/2020/04/06/systems-design-for-advanced-beginners/</link>
<guid isPermaLink="true" >https://robertheaton.com/2020/04/06/systems-design-for-advanced-beginners/</guid>
<description>&lt;blockquote readability=&quot;6.2542372881356&quot;&gt;
&lt;p&gt;This post is part of my &lt;a href=&quot;https://advancedbeginners.substack.com/&quot;&gt;Programming for Advanced Beginners series&lt;/a&gt;. &lt;a href=&quot;https://advancedbeginners.substack.com/&quot;&gt;Subscribe now&lt;/a&gt; to receive specific, actionable ways to make your code cleaner, every other week, entirely free.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;You’ve started &lt;a href=&quot;https://robertheaton.com/2018/07/09/how-tinder-keeps-your-location-a-bit-private/&quot;&gt;yet another&lt;/a&gt; &lt;a href=&quot;https://robertheaton.com/2017/10/09/tracking-friends-and-strangers-using-whatsapp/&quot;&gt;company&lt;/a&gt; with your good friend, Steve Steveington. It’s an online marketplace where people can buy and sell things and where no one asks too many questions. It’s basically a rip-off of Craigslist, but with Steve’s name instead of Craig’s.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://robertheaton.com/images/systems-cover.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;You’re going to be responsible for building the entire Steveslist technical platform, including all of its websites, mobile apps, databases, and other infrastructure. You’re excited, but also very nervous. You figure that you can probably cobble together a small website, since you’ve done that a few times before as part of your previous &lt;a href=&quot;https://robertheaton.com/2018/07/09/how-tinder-keeps-your-location-a-bit-private/&quot;&gt;entertaining&lt;/a&gt;-&lt;a href=&quot;https://robertheaton.com/2017/10/09/tracking-friends-and-strangers-using-whatsapp/&quot;&gt;if&lt;/a&gt;-&lt;a href=&quot;https://robertheaton.com/2014/12/08/fun-with-your-friends-facebook-and-tinder-session-tokens/&quot;&gt;morally&lt;/a&gt;-&lt;a href=&quot;https://robertheaton.com/2016/10/22/a-tale-of-love-betrayal-social-engineering-and-whatsapp/&quot;&gt;questionable&lt;/a&gt; &lt;a href=&quot;https://robertheaton.com/2019/01/15/a-brief-history-of-wi-fi-privacy-vulnerabilities/&quot;&gt;escapades&lt;/a&gt; with the Stevester. But you have no idea how to even start building out all of the other infrastructure and tools that you assume lie behind large, successful online platforms.&lt;/p&gt;
&lt;p&gt;You are in desperate need of a detailed yet concise overview of how real companies do this. How do they store their data? How do their different applications talk to each other? How do they scale their systems to work for millions of users? How do they keep them secure? How do they make sure nothing goes wrong? What are APIs, webhooks and client libraries, when you really get down to it?&lt;/p&gt;
&lt;hr/&gt;&lt;p&gt;You send a quick WhatsApp to your other good friend, Kate Kateberry, to see if she can help. You’ve &lt;a href=&quot;https://robertheaton.com/2019/01/15/a-brief-history-of-wi-fi-privacy-vulnerabilities/&quot;&gt;worked together very effectively in the past&lt;/a&gt;, and she has decades of experience creating these types of systems at Silicon Valley’s biggest and most controversial companies.&lt;/p&gt;
&lt;p&gt;She instantly accepts your job offer. You had actually only been ringing for some rough guidance and a good gossip, but you nonetheless instantly accept her acceptance. No point looking a gift horse in the mouth, even when you don’t have any money to pay her. Kate proposes that her first day be 5 weeks ago in order to help her smooth over some accounting irregularities. She can come into the office sometime next week. You feel encouraged and threatened by her eagerness.&lt;/p&gt;
&lt;hr/&gt;&lt;p&gt;Kate bounces into your offices in the 19th Century Literature section of the San Francisco Public Library. “OK let’s do this!” she shouts quietly. “What have we got so far? How are all our systems set up? What’s the plan?” You lean back in your chair and close your laptop, which was not turned on because you have left your charger at home. You steeple your fingers in a manner that you hope can be described as “thoughtful”.&lt;/p&gt;
&lt;p&gt;“Let me flip that question around, Kate. What do &lt;em&gt;you&lt;/em&gt; think the plan should be?”&lt;/p&gt;
&lt;p&gt;Kate takes a deep breath and paints an extremely detailed vision of the Steveslist platform five years into the future and the infrastructure that will power it.&lt;/p&gt;
&lt;hr/&gt;&lt;p&gt;Before we start (says Kate), I want to make it clear that I’m not saying that any of this is necessarily the “right” way to set up our infrastructure. If someone you trust more than me says something different then you should probably do what they say. There are many tools out there, each with different strengths and weaknesses, and many ways to build a technology company. The real, honest reasons that we will make many of our technological choices will be “we chose X because Sara knows a lot about X” and “we chose Y on the spur of the moment when it didn’t seem like a big decision and we never found the time to re-evaluate.”&lt;/p&gt;
&lt;p&gt;Nonetheless, let’s fast-forward five years into the future. Now Steveslist has two main consumer-facing products:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;The Steveslist web app&lt;/li&gt;
&lt;li&gt;The Steveslist smartphone apps&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;These are the main ways in which users directly interact with the Steveslist platform. In addition, we also provide an API that allows programmers to build power-tools on top of the Steveslist platform that, for example, create listings for hundreds of items programmatically. To support this, we offer:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;A Steveslist API&lt;/li&gt;
&lt;li&gt;Steveslist API &lt;em&gt;client libraries&lt;/em&gt; that make it easy for programmers to write code that talks to our API&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;Here, I’ll draw a diagram on the whiteboard:&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot; readability=&quot;32&quot;&gt;
&lt;div class=&quot;highlight&quot; readability=&quot;9&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;
&lt;code&gt;+-----------+   +--------------+   +-----------------+
|Web Browser|   |Smartphone App|   |Client Libraries/|
+-----+-----+   +------+-------+   |Other API code   |
      |                |           +-------+---------+
      |                v                   |
      |          +-----+------+            |
      +---------&amp;gt;+ Steveslist +&amp;lt;-----------+
                 |  Servers   |
                 +------------+
&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Finally, we have many, many services running in the background that provide the data and power to these external-facing applications:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;Webhooks - to notify users when something happens to their account, such as “order placed”&lt;/li&gt;
&lt;li&gt;User password authentication - to securely log users in&lt;/li&gt;
&lt;li&gt;SQL database - the main Steveslist data store. Needs to be highly scalable and reliable&lt;/li&gt;
&lt;li&gt;Free-text searching system - to power the search box where people can look for broad search terms like “TVs” or “motorbikes”&lt;/li&gt;
&lt;li&gt;Internal tools - to help us administer the Steveslist platform, and to take actions like issuing sternly-worded warnings to malicious users&lt;/li&gt;
&lt;li&gt;Cron jobs - to run regular tasks that do anything from generating invoices, to billing customers, to sending as much of our users’ data as possible to third-party ad networks&lt;/li&gt;
&lt;li&gt;“Pubsub” system - to allow us to take asynchronous actions on different trigger events (such as “when a new user signs up, send them a welcome email”)&lt;/li&gt;
&lt;li&gt;Big data analytics system - to allow us to run enormous queries over the entirety of Steveslist’s data&lt;/li&gt;
&lt;li&gt;And many more that we’ll talk about another day&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;Let’s go through each of these systems in turn. &lt;a href=&quot;https://robertheaton.com/about/&quot;&gt;Let me know&lt;/a&gt; if anything isn’t clear, if you have any questions, or if you think I’ve got something wrong.&lt;/p&gt;
&lt;h2 id=&quot;before-we-start---what-is-a-server-really&quot;&gt;Before we start - what is a server really?&lt;/h2&gt;
&lt;p&gt;Before we start, let’s define some important terms. In fact, let’s just define one. We’re going to talk a lot about “servers” today. But what is a server, when you really get down to it?&lt;/p&gt;
&lt;p&gt;For our purposes, a server is a computer that runs on a network and listens for communications from other computers. When it receives some data from another computer it performs some sort of action in response and - usually - sends back some data of its own. For example, a web server listens on a network for HTTP requests and sends back webpages and information in response. A database server listens for database queries and reads and writes data to the database that it is running.&lt;/p&gt;
&lt;p&gt;This brief description skips out entire degrees and careers of detail, and there are of course far more precise and accurate ways to define the word “server”. But this should get us through until dinnertime. What did you say? What’s a “network” really? A good question for another day.&lt;/p&gt;
&lt;p&gt;Now we’re ready to talk about the Steveslist platform.&lt;/p&gt;
&lt;h2 id=&quot;steveslist-web-app&quot;&gt;Steveslist web app&lt;/h2&gt;
&lt;p&gt;This is the main Steveslist product. It’s just a normal web app, very similar to any website that you’ve built before, except much bigger. It’s a modern “single-page app” (SPA). The “single” in “single-page app” refers to the fact that the user’s browser almost never has to fully reload the page as the user clicks around our site. Instead, when the browser makes its first &lt;em&gt;HTTP request&lt;/em&gt; to our servers, we send it back a basic, skeleton HTML page and a big pile of &lt;em&gt;JavaScript&lt;/em&gt; code. This JavaScript code executes inside the browser, and updates the view of the page in response to the user’s actions. When the JavaScript wants to send or retrieve data from Steveslist, it sends an Asynchronous JavaScript XML Request (almost always called AJAX for short) in the background to a URL. When our server responds, the JavaScript uses the response to update the browser view accordingly.&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot; readability=&quot;33&quot;&gt;
&lt;div class=&quot;highlight&quot; readability=&quot;11&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;
&lt;code&gt;+----------+1.User's browser visits steveslist.com. +----------+
|          |  It sends an HTTP request to the       |          |
|          |  Steveslist servers                    |          |
|          +---------------------------------------&amp;gt;|          |
|User's Web|                                        |Steveslist|
| Browser  |2.Steveslist server responds with a     | Servers  |
|          |  skeleton HTML page that instructs the |          |
|          |  browser to request additional         |          |
|          |  JavaScript files.                     |          |
|          |&amp;lt;---------------------------------------+          |
|          |                                        |          |
|          |3.User's browser requests and receives  |          |
|          |  these JavaScript files from the       |          |
|          |  Steveslist server.                    |          |
|          +---------------------------------------&amp;gt;|          |
|          |&amp;lt;---------------------------------------+          |
|          |                                        |          |
|          |4.User's browser executes the JavaScript|          |
|          |  code. The code sends more requests for|          |
|          |  the user's data to the Stevelist      |          |
|          |  server, and updates the browser UI to |          |
|          |  display it.                           |          |
|          +---------------------------------------&amp;gt;|          |
|          |&amp;lt;---------------------------------------+          |
+----------+                                        +----------+
&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;robertheaton.com&lt;/code&gt; is not a single-page app. Whenever you click on a link, the browser has to reload the entire page. &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;twitter.com&lt;/code&gt; &lt;em&gt;is&lt;/em&gt; a single-page app. Whenever you click on a link, the browser dynamically updates a small portion of tthe page without forcing a full refresh.&lt;/p&gt;
&lt;p&gt;SPAs are a lot of work to build and maintain, but they sure look good.&lt;/p&gt;
&lt;h2 id=&quot;steveslist-smartphone-apps&quot;&gt;Steveslist smartphone apps&lt;/h2&gt;
&lt;p&gt;We provide Steveslist smartphone apps for both iOS and Android. They are conceptually very similar to our single-page web app. Both our smartphone and web apps make HTTP requests to our servers. Then our servers receive these requests, do some work and return an HTTP response. Finally, both our smartphone and web apps update their display in order to communicate with the user.&lt;/p&gt;
&lt;p&gt;Since our smartphone apps are performing the same operations as the web app (for example, create listing, send message, etc), they can usually even send their requests to the exact same URLs as the web app. The only extra work that we have to do is to develop the frontends of the apps themselves. Some frameworks even make it possible to write mobile apps using JavaScript, allowing you to reuse code and logic across platforms.&lt;/p&gt;
&lt;h2 id=&quot;steveslist-api&quot;&gt;Steveslist API&lt;/h2&gt;
&lt;p&gt;We allow users and third-parties to write code that programmatically interacts with our platform. In the same way that people can use the Twitter API to write code that reads; likes; and creates Tweets, we allow them to use the Steveslist API to search; buy; and list items.&lt;/p&gt;
&lt;p&gt;Programmers use our API by writing code that makes HTTP requests to our &lt;em&gt;API endpoints&lt;/em&gt;. For example, in order to retrieve a list of all their listings, the programmer sends an HTTP &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GET&lt;/code&gt; request to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;api.steveslist.com/v1/listings&lt;/code&gt;. We respond with the data they requested, formatted as &lt;em&gt;JSON&lt;/em&gt;. JSON stands for JavaScript Object Notation, but JSON is not specific to JavaScript and can easily be interpreted by any programming language. A JSON response to a request to retrieve all of a user’s listings might look something like this:&lt;/p&gt;
&lt;div class=&quot;language-javascript highlighter-rouge&quot; readability=&quot;14&quot;&gt;
&lt;div class=&quot;highlight&quot; readability=&quot;23&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;
&lt;code&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;listings&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;id&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2178123867&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
      &lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;Stolen TV&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
      &lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;country&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;US&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
      &lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;city&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;San Francisco&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
      &lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;price_amount&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
      &lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;price_currency&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;usd&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
      &lt;span class=&quot;err&quot;&gt;#&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;etc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;...&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;id&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;182312679&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
      &lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;Stolen Bicycle&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
      &lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;country&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;US&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
      &lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;city&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;San Francisco&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
      &lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;price_amount&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
      &lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;price_currency&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;usd&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
      &lt;span class=&quot;err&quot;&gt;#&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;etc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;...&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;This structured response format is very easy for a program to parse, which means that the code that made the request can trivially interpret and use the data from our API.&lt;/p&gt;
&lt;p&gt;Users identify or &lt;em&gt;authenticate&lt;/em&gt; themselves to our API using an API key. This is, roughly speaking, the API equivalent of a password. It is a long, random string that we generate and display on a user’s “Settings” page. Users include their API key as an &lt;em&gt;HTTP header&lt;/em&gt; with every HTTP request that they (or their code) makes to the API. When we receive an API request we check to see whether the attached API key corresponds to a Steveslist user. If it does then we perform the request on behalf of that user.&lt;/p&gt;
&lt;p&gt;If a programmer wants to, they can manually build HTTP requests to our API themselves, using their language’s standard HTTP library. For example, in Python they might write:&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot; readability=&quot;11.5&quot;&gt;
&lt;div class=&quot;highlight&quot; readability=&quot;18&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;
&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;requests&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;url&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'https://api.steveslist.com/v1/listings/'&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;listing_params&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;s&quot;&gt;&quot;name&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;Stolen TV&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
  &lt;span class=&quot;s&quot;&gt;&quot;country&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;US&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
  &lt;span class=&quot;s&quot;&gt;&quot;city&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;San Francisco&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
  &lt;span class=&quot;s&quot;&gt;&quot;price_amount&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
  &lt;span class=&quot;s&quot;&gt;&quot;price_currency&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;usd&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;api_key&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;YOUR_API_KEY_GOES_HERE&quot;&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;response&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;requests&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;post&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;url&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;listing_params&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;headers&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;X-Steveslist-API-Key&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;api_key&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;However, we make life easier for programmers by providing &lt;em&gt;client libraries&lt;/em&gt;.&lt;/p&gt;
&lt;h2 id=&quot;steveslist-client-libraries&quot;&gt;Steveslist client libraries&lt;/h2&gt;
&lt;p&gt;A client library is a library that “wraps” the functionality of the Steveslist API. This means that anyone using the client library doesn’t need to know anything about the fine details of the Steveslist API. Instead, they can just write:&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot; readability=&quot;9&quot;&gt;
&lt;div class=&quot;highlight&quot; readability=&quot;13&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;
&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;steveslist&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;listing&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;steveslist&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Listing&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;create&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Stolen TV&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;country&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;US&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;city&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;San Francisco&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;price_amount&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;price_currency&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;usd&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;api_key&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;YOUR_API_KEY_GOES_HERE&quot;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Our libraries turn the parameters that they are given into appropriately formatted HTTP requests, which they send to the Steveslist API as normal. We’ve written client libraries for every major programming language that we could think of, and they are by far the most common way that people interact with our API.&lt;/p&gt;
&lt;h2 id=&quot;webhooks&quot;&gt;Webhooks&lt;/h2&gt;
&lt;p&gt;We’ve seen how Steveslist users can use our API to programmatically interact with their account. In addition, many users also want &lt;em&gt;us&lt;/em&gt; to proactively tell &lt;em&gt;them&lt;/em&gt; whenever something happens to their Steveslist profile. For example, suppose that someone wanted to fully automate the process of selling items on Steveslist. Whenever a customer pays for an item using our new, mostly-secure StevePay system, they want to send the customer a thank you email and automatically instruct their warehouse to ship a stolen TV to the order address. Our seller could constantly and repeatedly query the Steveslist API asking “Any new sales? Any new sales?” However, this would be very inefficient, and would put a lot of unnecessary load on our servers.&lt;/p&gt;
&lt;p&gt;Instead, we provide an industry standard system called &lt;em&gt;webhooks&lt;/em&gt;. A webhook is an HTTP request that we send to our users whenever something interesting happens to their account. It contains all the data describing the event that just happened - for example, the item ID, the price, the buyer ID, buyer address, and so on. Webhooks allow users to automatically perform response actions, such as the aforementioned email and auto-shipping.&lt;/p&gt;
&lt;p&gt;To use webhooks, the user tells us the URL to which they would like us to send their webhooks (for example, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;steveslistwebhooks.robertheaton.com&lt;/code&gt;. They set up a web server at that URL that will receive and action these webhook notifications.&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot; readability=&quot;34&quot;&gt;
&lt;div class=&quot;highlight&quot; readability=&quot;13&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;
&lt;code&gt;1.Buyer purchases an      3.The seller's server receives the webhook,
  item as normal.           and uses the information in it to
                            automatically process the order.
+---------------+           +-----------------+
|Buyer's Browser|           |Seller's Webhook-+
+------+--------+           |Receiving Server |
       |                    +------+----------+
       |                           ^
       |                           | 
       |                           |   
       |    +-----------+          |
       +---&amp;gt;+ Steveslist+----------+
            |   Server  |
            +-----------+
       2.Once the transaction has been completed,
         Steveslist looks up the seller's
         webhook URL (if set). We then send
         an HTTP request to this URL,
         containing the details of the purchase.
&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;The user deploys code on their web server that performs the appropriate response actions whenever it receives a webhook from us. We don’t only send webhooks when an item is purchased - we also send them when a user receives a message; when one of their items is removed by an admin; or when a buyer makes a complaint. This enables Steveslist sellers to automate not just the listing of items, but also the selling and shipping of them too.&lt;/p&gt;
&lt;h3 id=&quot;webhook-complications&quot;&gt;Webhook complications&lt;/h3&gt;
&lt;p&gt;Webhooks come with two main complications - security and reliability. First, let’s talk security. The endpoint to which the seller instructs us to send their webhooks is accessible to anyone on the internet. Anyone who knows the URL can send it fake webhooks, and if our seller isn’t careful this could allow an attacker to trick them into, for example, sending the attacker free stuff. A seller’s webhook URL should be difficult to find, since the seller won’t publicize its existence, but obscurity is not the same as security.&lt;/p&gt;
&lt;p&gt;To allow our sellers to verify that a webhook really was sent by Steveslist, we &lt;em&gt;cryptographically sign&lt;/em&gt; our webhook contents.&lt;/p&gt;
&lt;h4 id=&quot;cryptographic-signing&quot;&gt;Cryptographic signing&lt;/h4&gt;
&lt;p&gt;Cryptographic signing is a deep and subtle topic. Here’s a condensed version of how we use it to secure our webhooks.&lt;/p&gt;
&lt;p&gt;When a seller enables webhooks for their account, we generate a random “shared secret key”. We tell the seller to copy this key over to their webhook-receiving server and keep it secure, so that its value is known only by us and the seller. Whenever we send a webhook, we take this shared secret, combine it with the contents of the webhook by using a &lt;em&gt;cryptographic hash function&lt;/em&gt; called &lt;em&gt;HMAC&lt;/em&gt;, and get back a long, random-seeming, but entirely deterministic “signature” for the webhook.&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot; readability=&quot;31.5&quot;&gt;
&lt;div class=&quot;highlight&quot; readability=&quot;8&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;
&lt;code&gt;Webhook contents   +----------+
(eg. {&quot;id&quot;: 123...})          |
                              v
                          +---+----------+
                          |HMAC Algorithm|-----&amp;gt;Webhook signature
                          +---+----------+
                              ^
Shared secret key             |
(eg. 123mhu23jy8xdwgmd...)+---+
&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;We include this signature in our webhook body, for example:&lt;/p&gt;
&lt;div class=&quot;language-javascript highlighter-rouge&quot; readability=&quot;7.5&quot;&gt;
&lt;div class=&quot;highlight&quot; readability=&quot;10&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;
&lt;code&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;action&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;item_sold&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
  &lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;price&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
  &lt;span class=&quot;c1&quot;&gt;// ...more params...&lt;/span&gt;
  &lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;signature&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;234gj98d49j834978gf39t78ndn98g7dq3ng897308y7&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;When the seller’s webhook-receiving server receives a webhook, it takes the shared secret and webhook contents and calculates what it expects the signature to be in exactly the same way that we did. It compares the result to the signature attached to the webhook; if they match then it accepts and processes the webhook. Since the signature can only be generated using the shared secret known only by us and the seller, the webhook-receiving server can be confident that the webhook was sent by us. If the signatures don’t match, however, the server rejects the webhook.&lt;/p&gt;
&lt;p&gt;Note that all of the signature verification code must be written and maintained by the sellers. We can provide them with encouragement and examples, but we can’t force them to verify signatures correctly, or even at all. For some real-world examples, look at how &lt;a href=&quot;https://stripe.com/docs/webhooks/signatures&quot;&gt;Stripe&lt;/a&gt; and &lt;a href=&quot;https://developer.github.com/webhooks/securing/&quot;&gt;GitHub&lt;/a&gt; sign their webhooks.&lt;/p&gt;
&lt;h3 id=&quot;reliability&quot;&gt;Reliability&lt;/h3&gt;
&lt;p&gt;We also need to consider what happens when our webhooks go wrong and what guarantees we want to make to our users about them. If we try to send a webhook but can’t connect to the user’s server, what should we do? What if we successfully connect to their server and send the webhook, but their server sends back an error? What if we send the webhook but the server hangs for twenty seconds before disconnecting without telling us what happened?&lt;/p&gt;
&lt;p&gt;There are tradeoffs involved here that require clear communication and a surprising amount of infrastructure to manage. We at Steveslist choose to guarantee that we will deliver webhooks “at least once”. This means that if a webhook fails to send then we will keep trying (a large but not infinite number of times) until it does. If we’re not sure whether a webhook succeeded or failed, we will keep trying until we are sure that an attempt has succeeded. This might occasionally result in us sending the same webhook twice, but it’s the seller’s responsibility to have their code handle this gracefully instead of sending the same customer five stolen TVs instead of the one that they ordered.&lt;/p&gt;
&lt;hr/&gt;&lt;p&gt;“What do you think so far?” asks Kate. “Is this roughly what you’ve been thinking?” You make a non-committal face and take a big bite of a nearby sandwich in order to preclude any further discussion. Kate continues:&lt;/p&gt;
&lt;hr/&gt;&lt;p&gt;Let’s talk about the backend systems that will power some of our most important features.&lt;/p&gt;
&lt;h2 id=&quot;user-authentication-via-a-password&quot;&gt;User authentication via a password&lt;/h2&gt;
&lt;p&gt;Most users sign into the Steveslist website and smartphone apps using a username and password. There are other ways of signing into the website, like &lt;em&gt;OAuth&lt;/em&gt; - we’ll cover them another time.&lt;/p&gt;
&lt;p&gt;We will have to store our users’ passwords very securely. Not only is a user’s password the thing they use to sign in (or &lt;em&gt;authenticate&lt;/em&gt;) to Stevelist, but for many users they’re probably the same password that they use to sign in to many other services too, despite all the warnings that this is a bad idea. They only have so many children with so many birthdays, after all.&lt;/p&gt;
&lt;p&gt;Rupert Herpton has written &lt;a href=&quot;https://robertheaton.com/2019/08/12/programming-projects-for-advanced-beginners-user-logins/&quot;&gt;the seminal tutorial&lt;/a&gt; on how to secure passwords, which I’m sure you’ve read already. Just in case you need a refresher, the crux of the matter is that we mustn’t ever store passwords in their original, &lt;em&gt;plaintext&lt;/em&gt; form, anywhere. We mustn’t store them in plaintext in a database, in a log file, or in any other part of our system. Instead, before storing a password, we must first &lt;em&gt;hash&lt;/em&gt; it using a &lt;em&gt;hash function&lt;/em&gt; such as &lt;em&gt;bcrypt&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;A hash function is a “one-way” function that takes an input and deterministically converts it into a new, seemingly-random string. Calculating a hash value from an input is computationally very easy, but reversing the transformation and recovering the original input from its hash value takes so much time and computing power that it is, practically-speaking, impossible.&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot; readability=&quot;31.5&quot;&gt;
&lt;div class=&quot;highlight&quot; readability=&quot;8&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;
&lt;code&gt;+---------+     Easy    +----------+
|         |------------&amp;gt;|          |
|Plaintext|             |Hash value|
|         |&amp;lt;------------|          |
+---------+ Essentially +----------+
            Impossible
&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Since we only store the hash values of our users’ passwords, if a hacker somehow stole our password database (heaven forbid) (touch wood) then they would only be able to see the passwords’ hash values. They wouldn’t be able to easily turn these hash values back into &lt;em&gt;plaintext&lt;/em&gt; passwords, meaning that they wouldn’t be able to use them to login to Steveslist, and they won’t be able to take advantage of all the people who re-use passwords across different services.&lt;/p&gt;
&lt;p&gt;Since we only store password hash values, when we want to check whether a login password that a user has given us is correct we first calculate its hash value, and compare the result to the hash value in our password database.&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot; readability=&quot;33&quot;&gt;
&lt;div class=&quot;highlight&quot; readability=&quot;11&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;
&lt;code&gt;                 +--------------+
                 |User's Browser|
                 +-----------+--+
1.User attempts to  |        ^
log in:             |        |  3. Server logs the user in
                    |        |  if password matches, and
   username: steve  |        |  returns an error if it does not.
   password: 12345  v        |  
                 +--+--------+--+
                 |  Steveslist  |
                 |    Server    |
                 +--------------+
                        |
2.Server computes       |     |username|password_hash|
the hash of the         |     +----------------------+
password and compares   +----&amp;gt;+steve   |23jy7213y7jO |
it to the value in the        |kate    |21897213hh21 |
database.                     |...     |...          |
&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;As previously mentioned, we also have to be careful not to log passwords in any of our debug output. This can be an easy mistake to make - if you log all of the parameters of every HTTP request, just in case you need it, you will certainly be logging user passwords. Facebook logged passwords in plaintext for many years, and whilst it didn’t seem to affect their stock price I’m sure it made them feel pretty silly for a day or two.&lt;/p&gt;
&lt;hr/&gt;&lt;p&gt;Kate pauses for breath. You pretend to take notes on your out-of-battery laptop.&lt;/p&gt;
&lt;hr/&gt;&lt;p&gt;Let’s talk about infrastructure.&lt;/p&gt;
&lt;h2 id=&quot;database-servers&quot;&gt;Database servers&lt;/h2&gt;
&lt;p&gt;Steveslist’s primary data store runs a common flavor of SQL database called &lt;em&gt;MySQL&lt;/em&gt;. I won’t talk much about SQL here - the specifics of how it works aren’t too important, and you can find them on Google if you’re interested. Since we are so successful, we have a huge and growing amount of data to manage. We’ve started to become acutely aware that databases aren’t magic. They run on computers, just like any other program. As the volume of data in a database grows, the computer’s hard drive and memory starts to fill up. At the start of the company the easiest way to deal with this problem was to run our database on a single computer (or &lt;em&gt;machine&lt;/em&gt;) with an enormous hard drive. But this could only stave off the problem for so long. Eventually our database contained more data than could be stored on any reasonable hard drive, and the database started to get slower and slower as we forced it to search through more and more records.&lt;/p&gt;
&lt;p&gt;We had to take an entirely new approach, and reconfigure our database to store its data on multiple computers. We did this using &lt;em&gt;sharding&lt;/em&gt;.&lt;/p&gt;
&lt;h3 id=&quot;sharding&quot;&gt;Sharding&lt;/h3&gt;
&lt;p&gt;Sharding a database means splitting its data into chunks (or “shards”) and storing each chunk on a separate machine. All of the machines that make up a database are together known as a &lt;em&gt;database cluster&lt;/em&gt;. How you split data between machine in your cluster depends on your application and the types of operations you will be performing. For Steveslist we chose to split out our data by user. This means that all of the data for a given user is stored on the same machine. This includes their profile information, their listings, their messages, and so on. Data that doesn’t have a corresponding user (like “Deals of the Day”) can be sharded using a &lt;em&gt;shard key&lt;/em&gt; other than user, or not sharded at all if the dataset is sufficiently small.&lt;/p&gt;
&lt;p&gt;This means that we need an extra “routing” layer in front of our database, which knows which database machine is able to service which queries. We could either make our &lt;em&gt;application servers&lt;/em&gt; (the servers that execute our code) responsible for knowing the mapping of user IDs to database shards, or have a centralized “router” that all servers send their requests to, and which is responsible for working out the appropriate machine to forward the request on to. Both approaches have their advantages. Making application servers responsible for maintaining the mapping reduces the number of hops that a request has to make, speeding them up. But having a centralized router makes updating the shard mapping much easier, since you only have to update it in one place.&lt;/p&gt;
&lt;p&gt;If application servers are responsible for knowing the shard layout, we have a system that looks like this:&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot; readability=&quot;32.5&quot;&gt;
&lt;div class=&quot;highlight&quot; readability=&quot;10&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;
&lt;code&gt;            +          +          +
            |          |          |
            | Requests from users |
            |          |          |
            v          v          v
     +------+----------+--------------------+
     |            Application               |
     |               Server                 |
     |                                      |
     |Database sharding config:             |
     |* DB Server 1: IDs between 1-10000    |
     |* DB Server 2: IDs between 10000-20000|
     |* DB Server 3: IDs between 20000-30000|
     +-+----------------+-----------------+-+
       |                |                 |
       |ID:501          |ID:15362         |ID:22361
       |                |                 |
       v                v                 v
+-----------+     +-----------+     +-----------+
|DB Server 1|     |DB Server 2|     |DB Server 3|
+-----------+     +-----------+     +-----------+
&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;If we have a centralized database router, we have a system that looks like this:&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot; readability=&quot;33&quot;&gt;
&lt;div class=&quot;highlight&quot; readability=&quot;11&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;
&lt;code&gt;            +          +          +
            |          |          |
            | Requests from users |
            |          |          |
            v          v          v
     +------+----------+--------------------+
     |            Application               |
     |               Server                 |
     |                                      |
     |Database sharding config:             |
     |* ??? Application Server has no idea  |
     +------------+-----------+-------------+
                  |           |
      Application server sends all database
      queries to the database router, which
      forwards them to the correct shard.
                  |           |
                  v           v
   +--------------+-----------+-------------+
   |            Database router             |
   |                                        |
   |Database sharding config:               |
   |* DB Server 1: IDs between 1-10000      |
   |* DB Server 2: IDs between 10000-20000  |
   |* DB Server 3: IDs between 20000-30000  |
   +---+----------------+---------------+---+
       |                |               |
       |ID:501          |ID:15362       |ID:22361
       |                |               |
       v                v               v
+-----------+    +-----------+   +-----------+
|DB Server 1|    |DB Server 2|   |DB Server 3|
+-----------+    +-----------+   +-----------+
&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;How do we decide which database to assign each user to? However we want. We could start by saying that users with odd-numbered IDs are assigned to shard machine 1, and those with even-numbered ones are assigned to shard machine 2. We could hope that this random assignment results in balancing our data relatively evenly between our shards.&lt;/p&gt;
&lt;p&gt;However, it’s possible that we might have a small number of power users who create much, much more data than others. Maybe they create so much data that we want to allocate them a shard of their own. This is completely fine - we have complete control over how users are assigned to shards. Random assignments are usually easiest, but are by no means the only option. We can choose to assign users to shards randomly - except for user 367823, who is assigned to shard 15, which no other user is assigned to.&lt;/p&gt;
&lt;p&gt;If a shard gets too big and starts to fill up its machine’s hard-drive, we can split it up into multiple, smaller shards. How do we migrate the data to these new shards without having to turn off our platform for a while? Probably using a sequential process like:&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;“Double-write” new data to both the old and new shards. Continue reading data from the old shard&lt;/li&gt;
&lt;li&gt;Copy over all existing data from the old shard to the new shard. Continue double-writing to old and new shards&lt;/li&gt;
&lt;li&gt;Convince ourselves that the old and new shards contain the same data. We could do this by comparing snapshots of the databases, and/or by reading every query from both databases, comparing them, and alerting if the data is different&lt;/li&gt;
&lt;li&gt;Once we’re confident that the new and old shards contain the same data, we switch to reading from the new shards. We continue double-writing in case we need to switch back&lt;/li&gt;
&lt;li&gt;Once we’re confident that this step has been successful, stop double-writing and delete the old shard&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;Rupert Herpton has written &lt;a href=&quot;https://robertheaton.com/2015/08/31/migrating-bajillions-of-database-records-at-stripe/&quot;&gt;a great article about a broadly-similar type of migration&lt;/a&gt; that goes into much more detail. In short, the process of migrating data between database shards is detailed and finicky, but also entirely doable and logical. Some types of database can even automatically take care of sharding for you.&lt;/p&gt;
&lt;h3 id=&quot;replication&quot;&gt;Replication&lt;/h3&gt;
&lt;p&gt;We will take great care to make sure that our data doesn’t get accidentally deleted and our database servers don’t randomly stop working. But accidents happen, and sometimes computers do randomly stop working. To mitigate the fallout of a database-related disaster, we &lt;em&gt;replicate&lt;/em&gt; our data across multiple machines in (close to) realtime.&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot; readability=&quot;32&quot;&gt;
&lt;div class=&quot;highlight&quot; readability=&quot;9&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;
&lt;code&gt;       Client writes new
       data to DB Server A
                |
                v
          +-----+-----+
          |DB Server A|
          ++---------++
           |         | DB Server A quickly replicates
           v         v the new data to DB Servers B and C
+----------++      +-+---------+
|DB Server B|      |DB Server C|
+-----------+      +-----------+
&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Realtime replication has two main benefits. First, it means that if one of our database servers explodes, catches fire, or otherwise stops working, we have multiple almost-perfect copies of it that can seamlessly pick up the slack. In a straightforward, vanilla failure, users of our services may never know that anything has gone wrong. The second benefit of replication is that we can distribute queries for the same data across multiple database servers. If lots of users are asking to read data from the same database, we can split their queries up across all of our copies, meaning that we can handle more queries in parallel.&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot; readability=&quot;33&quot;&gt;
&lt;div class=&quot;highlight&quot; readability=&quot;11&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;
&lt;code&gt;  Clients can query the same data
  from any of DB Servers A,B,or C
    |  |    |   |   |    |  |
    |  |    v   v   v    |  |
    |  |  +-+---+---+-+  |  |
    |  |  |DB Server A|  |  |
    |  |  +-----------+  |  |
    |  |                 |  |
    v  v                 v  v
+---+-------+      +-----+-+---+
|DB Server B|      |DB Server C|
+-----------+      +-----------+
&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Note that database replication is not the same concept as making database backups. Replication happens in (close to) realtime, and is designed to deal on-the-fly with isolated problems in your live (or &lt;em&gt;production&lt;/em&gt;) systems. Database backups are performed on a schedule (for example, once a day), and the copies of the data are stored separately, away from production systems. Backups are designed as a final safeguard against widespread, catastrophic data loss, as might happen if all your data centers burned down.&lt;/p&gt;
&lt;p&gt;Pretend that you work in the call centre of a big bank, where people are constantly calling you up in order to send money transfers and ask about their current balance. Replication is the equivalent of hurriedly writing down transfer details into multiple books, as you receive them, just in case you lose one of the books. Making backups is the equivalent of photocopying those books once a day and storing the copies in your filing cabinet.&lt;/p&gt;
&lt;h3 id=&quot;replication-1&quot;&gt;Replication&lt;/h3&gt;
&lt;p&gt;The process of replication is conceptually quite straightforward. Whenever new data is written to our database, we copy it to multiple machines. This means that if/when a machine fails we can continue querying its siblings, with no user-facing impact. It also means that we can spread our queries out across multiple copies of the same data, resulting in faster query response times.&lt;/p&gt;
&lt;p&gt;However, the details of how we do this are important, subtle, and situation-dependent. There’s no right way to do replication - as is so often the case, the exact approach that you take depends on the specific requirements and constraints of your system.&lt;/p&gt;
&lt;p&gt;Replication is complicated by two inconvenient facts about the real world. First, database operations randomly fail sometimes. When we attempt to replicate our data from one server to another, things &lt;em&gt;will&lt;/em&gt; occasionally go wrong, causing our machines to become out of sync, at least for a period. Second, even in periods of smooth operation, replication is not instantaneous. When new data is written to our database cluster, some servers in the cluster will always know about the update sooner than others. When choosing a replication strategy we must be aware of these limitations and how they impact our particular application. For example, maybe it’s OK to risk the number of “likes” on a post being slightly out of sync and out of date, but not the amount of money in a user’s bank account.&lt;/p&gt;
&lt;p&gt;One of the biggest decisions we must make when choosing a replication strategy is whether we want our replication to be &lt;em&gt;synchronous&lt;/em&gt; or &lt;em&gt;asynchronous&lt;/em&gt;.&lt;/p&gt;
&lt;h3 id=&quot;asynchronous-vs-synchronous-replication&quot;&gt;Asynchronous vs synchronous replication&lt;/h3&gt;
&lt;p&gt;Replication can be handled either synchronously or asynchronously. These words come up in a lot of different places in systems design, but they always fundamentally mean the same thing. If an action is performed “synchronously” then this means that it is performed while something waits for it. If you wanted to send a letter synchronously then you would got to the Post Office, give your letter to a postal worker, sit and wait in the corner of the Post Office for a few days, and only go home when the postal worker confirmed that your letter had arrived safely.&lt;/p&gt;
&lt;p&gt;By contrast, if an action is performed “asynchronously” then this means that the initiator of the action doesn’t wait around for it to be finished. Instead, they just continue with the rest of their work while the action is worked on in the background. The real Postal Service is asynchronous; you give your letter to a postal worker, then leave and continue with your life while the Postal Service delivers your letter. Asynchronous actions can send back notifications of the outcome of the action if they want (“Your letter has arrived and was signed for” or “Mr. Heaton, your dry-cleaning is ready”), but they don’t have to.&lt;/p&gt;
&lt;p&gt;How do these principles apply to database replication? In synchronous replication a client writes its new data to a database server and then waits. This server doesn’t tell the client whether their write has been completed successfully until it has finished fully replicating the client’s data across all of its sibling servers. Then, and only then, does the client continue executing the rest of its code.&lt;/p&gt;
&lt;p&gt;In asynchronous replication the client writes its data to the first database server, as before. But this time the first server tells the client that the write was successful as soon as it has written the data to its own data store. It kicks off the replication process in the background, and doesn’t wait for it to complete, or even start, before it tells the client that the write was successful. This means that the asynchronous operation appears much faster than the synchronous one, because the client doesn’t have to wait for all the replication to complete before it can continue on with the rest of its work. However, if the background replication fails then the client will believe that it has successfully written its data to the database when it actually has not. This could cause problems, the imagination of which is left as an exercise for the reader.&lt;/p&gt;
&lt;p&gt;The synchronous approach is slower but “safer” than an asynchronous approach. The database never claims to have successfully received and stored any data until it has finished every single step of doing so. Because the client waits for full confirmation before proceeding, it is guaranteed to never encounter a situation where the client believes that it has written some data to the database, but the database has secretly partially dropped the data on the floor.&lt;/p&gt;
&lt;p&gt;Which approach is better? It depends. Do you care more about speed or correctness? Is it OK to occasionally have inconsistent data if it significantly speeds up the system’s operation? Or will even a single mistake cause airplanes to start falling out of the sky?&lt;/p&gt;
&lt;p&gt;Database replication systems face other interesting problems too. Many of these problems are “logical” rather than “technical”, and don’t require a detailed understanding of the complex software and networking protocols underlying the system. To help picture some of them, imagine that you’re back in the call centre from a few paragraphs ago. You work with many other colleagues. Together you play the role of database servers. People call you up to transfer money and ask about their current balance. You and your colleagues write information about new transfers down on paper, and replicate it between yourselves by calling each other up.&lt;/p&gt;
&lt;p&gt;The problems faced by our database cluster are identical to those faced by our call-centre. What happens if two people call in and try to update the same piece of data at the same time by talking to two different employees? Maybe we solve that by having a “leader” employee who is the only one authorized to serve calls from people trying to create transfers. All the other employees are only allowed to answer queries about current balances. OK, so what happens if the leader has a stroke and dies after they’ve received some new data, but before they’ve told everyone else about it? What if a “follower” employee has a temporary seizure for a few seconds and misses some data updates from the leader? What if we’re never entirely sure which of our employees are dead or alive?&lt;/p&gt;
&lt;p&gt;This is not an approximate metaphor that breaks down if you look too hard or start asking awkward questions. Understand this weird call-centre and you understand database replication. &lt;a href=&quot;https://www.brianstorti.com/replication/&quot;&gt;Read this blog post&lt;/a&gt; and you &lt;em&gt;really&lt;/em&gt; understand replication.&lt;/p&gt;
&lt;h3 id=&quot;backups&quot;&gt;Backups&lt;/h3&gt;
&lt;p&gt;In addition to realtime replication, we also store regular backups of our entire database in order to protect against catastrophic disaster. We copy all of the data in our database, store it somewhere safe, and mark it as something like “database backup, 2020-05-11:01:00”.&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot; readability=&quot;33&quot;&gt;
&lt;div class=&quot;highlight&quot; readability=&quot;11&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;
&lt;code&gt;+----------+  
| Database +----------------&amp;gt; database backup, 2020-05-11:01:00
+----------+                  database backup, 2020-05-10:01:00
                              database backup, 2020-05-09:01:00
&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;If our entire database - or some fraction of it - somehow gets wiped out, we grab the most recent backup available and load it into new database machines.&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot; readability=&quot;33&quot;&gt;
&lt;div class=&quot;highlight&quot; readability=&quot;11&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;
&lt;code&gt;+----------+
|   New    |
| Database +&amp;lt;---------------- database backup, 2020-05-11:01:00
+----------+                  database backup, 2020-05-10:01:00
                              database backup, 2020-05-09:01:00
&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Such a calamity could be caused by a cyberattack, a disaster in our data centre, a database migration gone horribly wrong, or any number of unlikely but potentially company-destroying reasons. Unlike realtime replication, restoring a database from a backup is a slow process that our users will definitely notice. Our entire system will likely be offline until the restoration is complete. We will have lost all database updates that occurred after the last backup but before the disaster. And there will no doubt be a large number of knock-on effects as users and systems try to access data that used to be there but is now lost forever. Nonetheless, these are all much less terrible than the complete, irrevocable loss of all our company’s data and with it, our company.&lt;/p&gt;
&lt;p&gt;That’s a whole lot of detail about our primary SQL database. Let’s talk about some other ways in which we store and query data.&lt;/p&gt;
&lt;h2 id=&quot;free-text-searching&quot;&gt;Free-text searching&lt;/h2&gt;
&lt;p&gt;A standard SQL database is very good at answering well-defined and specific queries. For example:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;Give me all the item listings created by user #145122 in the last 90 days&lt;/li&gt;
&lt;li&gt;Give me the listing details for item #237326921&lt;/li&gt;
&lt;li&gt;Give me the count of new listings per day created in San Francisco with the label “Electronics”&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;You can retrieve this kind of data using SQL queries that look something like this:&lt;/p&gt;
&lt;div class=&quot;language-sql highlighter-rouge&quot; readability=&quot;6&quot;&gt;
&lt;div class=&quot;highlight&quot; readability=&quot;7&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;
&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;items&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;WHERE&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;user_id&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;145122&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;created&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;currentDate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;90&lt;/span&gt;
&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;or&lt;/p&gt;
&lt;div class=&quot;language-sql highlighter-rouge&quot; readability=&quot;7.5&quot;&gt;
&lt;div class=&quot;highlight&quot; readability=&quot;10&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;
&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;DATE_TRUNC&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'day'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;created&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;day&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;COUNT&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;items&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;INNER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;JOIN&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;ON&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;id&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;item_id&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;WHERE&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;city&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'San Francisco'&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;text&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'electronics'&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;GROUP&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;ORDER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;DESC&lt;/span&gt;
&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;You’ll notice that these queries contain a lot of very “precise” operators, like equals- and greater-than-signs. But how would you write a SQL query that could return a list of items that match a Google-style “full-text” search, like “second-hand TV”?&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://robertheaton.com/images/systems-design-search.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;This would be difficult. You could try the SQL &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;LIKE&lt;/code&gt; operator, which allows you to find records containing a pattern, such as a sub-string. For example, the following query finds all items with a description containing the sub-string &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;second-hand TV&lt;/code&gt;:&lt;/p&gt;
&lt;div class=&quot;language-sql highlighter-rouge&quot; readability=&quot;6&quot;&gt;
&lt;div class=&quot;highlight&quot; readability=&quot;7&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;
&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;items&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;WHERE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;description&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;LIKE&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'%second-hand TV%'&lt;/span&gt;
&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;However, this query will only match the very specific sub-string that it was given. It won’t match “TV that is second-hand” or “2nd-hand TV”, or “sceond-hnad TV”. Given enough perseverance you could theoretically construct a giant SQL-query that covered as many of these permutations as you had patience for:&lt;/p&gt;
&lt;div class=&quot;language-sql highlighter-rouge&quot; readability=&quot;6.5&quot;&gt;
&lt;div class=&quot;highlight&quot; readability=&quot;8&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;
&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;items&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;WHERE&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;description&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;LIKE&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'%second%hand%TV'&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;OR&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;description&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;LIKE&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'%second%TV%hand'&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;OR&lt;/span&gt;
  &lt;span class=&quot;c1&quot;&gt;-- …and so on and so on for another bajillion ORs…&lt;/span&gt;
&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;However, the resulting query would be slow and cumbersome, and would still miss many important edge-cases that you hadn’t thought of. And even if you did get back a useful list of search results, you’d still have a lot of work left to do in order to decide how to order them. The ordering you want isn’t something strict like “most-recent first” or “alphabetically by title”. Instead it’s some much woolier notion of “best” or “most-relevant” first.&lt;/p&gt;
&lt;p&gt;All of this means that SQL databases are generally not very good at full-text searches. Fortunately, other types of database are, including one called &lt;em&gt;Elasticsearch&lt;/em&gt;. Elasticsearch is often described as a &lt;em&gt;document-oriented database&lt;/em&gt;. We don’t need to go into the details of how exactly it works, but the important part for us is that, unlike SQL databases, Elasticsearch is very good at taking queries like “second-hand TV” and returning a list, ordered by “relevance,” of the fuzzy matches that users have come to expect from their search engines.&lt;/p&gt;
&lt;p&gt;“Sounds like Elasticsearch is just better than SQL,” you might say. “Should we throw away our SQL databases and put everything in Elasticsearch instead?” Not so fast. Elasticsearch, and other databases like it, have their strengths, but they also have their weaknesses. They’re typically somewhat less reliable than SQL databases, and are somewhat more likely to accidentally lose data at large scale. They’re also often much slower to write new data to.&lt;/p&gt;
&lt;p&gt;As we’ve already noted, there’s rarely a single, universally “best” tool for any type of job. There’s certainly no such thing as “the best” database. Instead, different databases have different strengths and weaknesses, and different solutions are appropriate for different tasks. At Steveslist, we care so much about making sure that we use the right tool for the right job that we store our data in both a SQL database &lt;em&gt;and&lt;/em&gt; a document-oriented database like Elasticsearch.&lt;/p&gt;
&lt;p&gt;We use our SQL database as our primary data store. It is our authoritative “source-of-truth”, and we write all our new data to it before we write it anywhere else. We do all our simple, precise reads from it, especially when accuracy and up-to-date-ness are our principal requirements. If we want to show a user a list of all their open listings, we read it from our SQL database. If we want to validate a users password, we read that from our SQL database too. This plays to the strengths of SQL databases.&lt;/p&gt;
&lt;p&gt;However, in the background we also copy data from our SQL database into an Elasticsearch database, and send any full-text search queries made via our search box to Elasticsearch. This means that we benefit from the strengths of Elasticsearch, and are not impacted too much by its weaknesses. We copy over batches of records every few minutes, hours, or days, depending on the requirements of the specific dataset. Alternatively, we could watch the logs of our SQL database for new or updated records, and create or update the corresponding Elasticsearch records in near-realtime.&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot; readability=&quot;32.5&quot;&gt;
&lt;div class=&quot;highlight&quot; readability=&quot;10&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;
&lt;code&gt;                   |      |                   |
New data is always |      |Queries for        |Full-text search 
written to the SQL |      |specific data go   |queries go to
DB first           |      |to the SQL DB too  |Elasticsearch
                   V      V                   V
               +--------------+       +---------------+
               | SQL Database +------&amp;gt;+ Elasticsearch |
               +--------------+       +---------------+
                       New data is copied over from
                       the SQL DB to Elasticsearch
&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;When scouting Steveslist’s competition, I noticed that when you create a new Craigslist listing it says “your listing will be visible in search within the next 15 minutes”. I’ll bet pesos to pizza that this is because their primary datastore is a SQL database, but their search box is powered by an Elasticsearch-like engine. Their pipeline for replicating data from SQL to search probably takes around 15 minutes, which they’ve decided (very reasonably) is an acceptable delay for their particular use-case.&lt;/p&gt;
&lt;p&gt;We’ve said that Elasticsearch is somewhat less reliable than most SQL databases. If Elasticsearch accidentally loses a few of our records then they won’t appear in search results. This would be a shame that would make our product a bit worse, and we try our hardest to avoid it happening. However, it wouldn’t be a disaster in the same way that losing data from our primary data store would be. We only copy data over to Elasticsearch once it has been written to and safely captured by our source-of-truth SQL database, which is what really matters.&lt;/p&gt;
&lt;hr/&gt;&lt;p&gt;It’s 6pm, and the library is closing. A librarian tries to ask you to leave. Kate shoos him away with a barrage of crumpled-up balls of paper.&lt;/p&gt;
&lt;hr/&gt;
&lt;p&gt;Managing the Steveslist platform requires bespoke internal tools. We need to perform a wide range of administrative tasks, like deleting listings that are too illegal (even for us), issuing refunds, viewing a user’s personal details in order to help with support requests, and so on. Many of these tools will be used by people who work on other teams at Steveslist, like finance, compliance, legal, sales, and support. Since the tasks they need to perform are so specific to the way that Steveslist works, we can’t do them using third-party tools, and have to build our own instead.&lt;/p&gt;
&lt;p&gt;In the early days, we baked this functionality into the main Stevelist product and only exposed it to users who had the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;is_steveslist_employee = True&lt;/code&gt; database flag set. This was an OK approach for a small company, but was also fragile and easy to mess up. It was scary to think that we were exposing all of our superuser powers through the same servers that run our main product. It made the potential consequences of a security flaw in our application much worse, and created new types of mistake for us to make, such as forgetting to disable the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;is_steveslist_employee&lt;/code&gt; flag for an acrimoniously fired employee.&lt;/p&gt;
&lt;p&gt;Once Steveslist reached a certain level of maturity, we built ourselves an entirely separate admin platform, with separate, hardened authentication and authorization. The service runs on entirely separate servers, and requires a &lt;em&gt;VPN&lt;/em&gt; and a &lt;em&gt;TLS client certificate&lt;/em&gt; to access (which we’ll talk about another day). This separated out our internal- and external-facing products, and drastically reduced the chance of a boneheaded error exposing our admin tools to the world. We’re frequently building new internal tools - one for user administration, one for server management, one for fraud detection, and so on. These services all talk to the same database as our user-facing products, so they all have access to the same data. They just run on different servers that are completely inaccessible to the outside world.&lt;/p&gt;
&lt;h2 id=&quot;cron-jobs&quot;&gt;Cron jobs&lt;/h2&gt;
&lt;p&gt;There are lots of tasks that we’ll want our system to perform at fixed times and intervals. For example:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;Emailing ourselves weekly usage reports&lt;/li&gt;
&lt;li&gt;Sending marketing emails to users&lt;/li&gt;
&lt;li&gt;Charging the credit cards users who have a subscription plan with us&lt;/li&gt;
&lt;li&gt;Copying data from our SQL database to Elasticsearch&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;The most common tool used for running scheduled jobs is called &lt;em&gt;cron&lt;/em&gt;, a tool that is built into Unix operating systems. It’s so common that people will often call any kind of scheduled job a “cron job”, even when it’s not actually being run by cron.&lt;/p&gt;
&lt;p&gt;You can set up a cron job on your own computer by running:&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;
&lt;div class=&quot;highlight&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;
&lt;code&gt;crontab -e
&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Then typing into the prompt:&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot; readability=&quot;31&quot;&gt;
&lt;div class=&quot;highlight&quot; readability=&quot;7&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;
&lt;code&gt;*/5 * * * * $YOUR_COMMAND
&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;This will cause your computer to execute &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;$YOUR_COMMAND&lt;/code&gt; every 5 minutes.&lt;/p&gt;
&lt;p&gt;Steveslist currently has a very simple and slightly fragile cron setup. We have a single “scheduled jobs server”. We use &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;crontab&lt;/code&gt; on this server (as above) to tell it the commands that we want it to run, and the schedule that we want it to run them on. This setup isn’t scaling very well - if the scheduled jobs server explodes or even hiccups then we don’t always know which jobs it did and didn’t run, and have to scramble to bring up a replacement server. And even though the server is very beefy and powerful, eventually we’re going to want to run more jobs than it can handle at once. We’re considering either splitting up our cron jobs into multiple servers, or setting up a new system using a modern tool like &lt;em&gt;Kubernetes&lt;/em&gt;.&lt;/p&gt;
&lt;h2 id=&quot;pubsub&quot;&gt;Pubsub&lt;/h2&gt;
&lt;p&gt;Actions have consequences. This is both the subject line of the sinister emails that we send to people who write mean things about us on the internet, and the reason we have a &lt;em&gt;pubsub&lt;/em&gt; system.&lt;/p&gt;
&lt;p&gt;When a new user signs up, we want to send them an email welcoming them to Steveslist and reminding them about the action-consequence relationship I just described. When a new listing is added for a stolen TV in San Francisco, we want to notify users who have set up search alerts for TVs in the Bay Area. When a card is declined for a subscription, we want to email the responsible user to politely threaten them. When a new listing is added, we want to perform some extremely cursory anti-fraud checks. When an item is purchased, we want to sent a webhook to its seller. And so on.&lt;/p&gt;
&lt;p&gt;Technically, all of these actions could be performed synchronously (rememberer that word?) by the server executing the initiating action. However, this is often a bad idea, for two reasons. First, the response action (such as emailing all the users who are subscribed for notifications about new stolen TVs) may be very slow. Performing the response action synchronously means that if the initiating action was performed by a user then they will have to wait for all the response actions to finish too. This might not be the end of the world if the response action is small and quick, like sending a single email. But if it’s larger - like searching for and notifying all users who might be interested in a new item - then, well, it still won’t be the end of the world, but it will be a bad user experience.&lt;/p&gt;
&lt;p&gt;To mitigate this problem we have built a “publish-subscribe” or “pubsub” system. When a trigger action is performed, the code that performs it “publishes an event” describing the action, such as &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;NewListingCreated&lt;/code&gt; or &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SubscriptionCardDeclined&lt;/code&gt;. The words “event” and “publish” are quite loosely defined in this context, and don’t have a rigorous technical definition. An event is just some sort of record of something that happened, and to publish an event just means that you somehow make a note that something happened. The details of how you do so depend entirely on the pubsub system in question. In a simple system events might be stored in tables in a SQL database, and code would publish events by writing new records to a table.&lt;/p&gt;
&lt;p&gt;If a programmer at Steveslist wants a response action to be performed whenever a new event of a particular type is published, they can write a &lt;em&gt;consumer&lt;/em&gt;. This is a piece of code that “subscribes” to a type of event, and which is executed whenever a new event of that type is published. It uses the details of the event (for example, the user whose subscription payment failed) to asynchronously execute whatever actions the programmer wants (for example, sending the user a menacing email).&lt;/p&gt;
&lt;p&gt;Pubsub systems are often managed by a central &lt;em&gt;message broker&lt;/em&gt;. Systems publish events to the broker, and the broker is then responsible for getting the events to any subscribed consumers. This can be achieved using either a &lt;em&gt;push&lt;/em&gt; or a &lt;em&gt;pull&lt;/em&gt; mechanism. Consumers can pull messages from the broker by polling it and repeatedly asking “any new events? any new events?” or they can wait and listen and the broker can push notifications of new events out to them, for example by sending them an HTTP request.&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot; readability=&quot;33.5&quot;&gt;
&lt;div class=&quot;highlight&quot; readability=&quot;12&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;
&lt;code&gt;1. New user signs|
up to Steveslist |
                 v
       +-----------------+               +------------------------+
       |Steveslist Server|           +--&amp;gt;+SendWelcomeEmailConsumer|
       +---------+-------+           |   +------------------------+
                 |                   v
2. Server reports|     +-------------++  4. Consumers send welcome
a NewUserSignup  +----&amp;gt;+Pub/Sub Broker|  emails, check for spam,
event to the           +-------------++  etc.
Pub/Sub system                       ^
              3. Pub/Sub broker      |   +------------------------+
              notifies consumers     +--&amp;gt;+NewUserSpamCheckConsumer|
              that have subscribed to    +------------------------+
              NewUserSignup events.
&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Pubsub systems have many benefits:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;Non-critical actions are performed asynchronously, keeping the user experience snappy&lt;/li&gt;
&lt;li&gt;Our code is kept clean and well-separated. The code that publishes an event doesn’t have to care about what the events’ subscribers do in response&lt;/li&gt;
&lt;li&gt;If a subscriber’s action fails for some reason (for example, the email-sending system has a hiccup), the pubsub system can note this failure and retry again later&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;Next, let’s talk big data.&lt;/p&gt;
&lt;h2 id=&quot;big-data-and-analytics&quot;&gt;Big data and analytics&lt;/h2&gt;
&lt;p&gt;In order to understand and optimize our business, we need to be able to calculate complex statistics across the entire Steveslist platform. How many listings are created every day, segmented by country and city? How many users who signed up each month have created a listing within 90 days of signing up?&lt;/p&gt;
&lt;p&gt;To do this, we need to write database queries that aggregate over the entirety of our data. We don’t want to run these queries against our production SQL database, because they could put an enormous amount of load on it. We don’t want a huge query issued by an internal analyst to be able to bring our production database to a grinding halt, but we do want to provide this analyst with a tool that is well-suited to their needs. To complicate matters further, database engines that are quick at small queries (like returning all the listings belonging to a single user) are typically unacceptably slow (or indeed incapable) of answering giant queries (like calculating the total dollars spent on listings in each category, per day, for the last 90 days).&lt;/p&gt;
&lt;p&gt;Despite this, for the first year or so after Steveslist was founded, we took a risk and simply ran our analytics queries against the main production database. This was a gamble, but it just about worked. We didn’t have much data anyway, and we had more important things to focus on, like attracting the customers who would create the big data that would one day mean that we had to find a more scalable solution.&lt;/p&gt;
&lt;p&gt;Eventually we did bring down the production database with an overly-ambitious query, and decided that the time had come to invest in a data warehouse. A data warehouse is a data store that is well-suited to large, system-wide queries. Our warehouse is powered by a database engine called &lt;em&gt;Hive&lt;/em&gt;, but we could also have chosen Presto, Impala, Redshift, or any number of competing alternatives. Hive accepts queries written in SQL, but is much better at executing these queries against giant datasets than our MySQL database is.&lt;/p&gt;
&lt;p&gt;We replicate our data from our production SQL database to Hive, once a day, overnight. Steveslist analysts and programmers can query the same dataset using whichever database engine best suits their needs. They can use the production SQL database for small, precise, source-of-truth queries from production systems; Elasticsearch for full-text search queries; or the data warehouse for huge queries that aggregate over vast volumes of data.&lt;/p&gt;
&lt;hr/&gt;&lt;p&gt;It’s dark outside and you’re hungry. Is that pretty much it? you ask.&lt;/p&gt;
&lt;p&gt;“Oh god no,” Kate replies, “we could keep going forever. But this is a pretty good start. It’s helpful to have a broad understanding of a wide range of topics, but no one needs to know the details about everything. I find that once you know some basics you can keep picking up more basics and even a couple of details as you go along.”&lt;/p&gt;
&lt;p&gt;You ask if Kate could perhaps continue to elaborate on her five-year vision for Steveslist tomorrow.&lt;/p&gt;
&lt;p&gt;“Absolutely,” says Kate. We’ll talk about more of what goes on inside a real, large online platform, including:”&lt;/p&gt;
&lt;h3 id=&quot;security&quot;&gt;Security&lt;/h3&gt;
&lt;ul&gt;&lt;li&gt;HTTPS and other forms of encryption&lt;/li&gt;
&lt;li&gt;Two-factor authentication&lt;/li&gt;
&lt;li&gt;SAML&lt;/li&gt;
&lt;li&gt;Secret key management&lt;/li&gt;
&lt;/ul&gt;&lt;h3 id=&quot;server-management&quot;&gt;Server management&lt;/h3&gt;
&lt;ul&gt;&lt;li&gt;Deploying new code&lt;/li&gt;
&lt;li&gt;AWS and competitors&lt;/li&gt;
&lt;li&gt;Terraform&lt;/li&gt;
&lt;li&gt;Load balancers&lt;/li&gt;
&lt;li&gt;Containers&lt;/li&gt;
&lt;li&gt;Alerting when code breaks&lt;/li&gt;
&lt;/ul&gt;&lt;h3 id=&quot;big-data&quot;&gt;Big data&lt;/h3&gt;
&lt;ul&gt;&lt;li&gt;Map-reduce and other big data jobs&lt;/li&gt;
&lt;li&gt;Machine learning&lt;/li&gt;
&lt;li&gt;User tracking&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;“See you tomorrow at 7am?”&lt;/p&gt;
</description>
<pubDate>Tue, 21 Jul 2020 03:08:03 +0000</pubDate>
<dc:creator>_ttg</dc:creator>
<og:image>https://robertheaton.com/images/systems-cover.png</og:image>
<og:url>https://robertheaton.com/2020/04/06/systems-design-for-advanced-beginners/</og:url>
<og:type>article</og:type>
<og:title>Systems design for advanced beginners | Robert Heaton</og:title>
<og:description>This post is part of my Programming for Advanced Beginners series. Subscribe now to receive specific, actionable ways to make your code cleaner, every other week, entirely free.</og:description>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://robertheaton.com/2020/04/06/systems-design-for-advanced-beginners/</dc:identifier>
</item>
<item>
<title>Building a Developer Cult</title>
<link>https://subvert.substack.com/p/stripe-building-a-developer-cult</link>
<guid isPermaLink="true" >https://subvert.substack.com/p/stripe-building-a-developer-cult</guid>
<description>&lt;a class=&quot;image-link image2&quot; target=&quot;_blank&quot; href=&quot;https://cdn.substack.com/image/fetch/c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F6e4164c1-f22c-4fa9-a95d-72edae30fd97_1440x799.png&quot;&gt;&lt;img src=&quot;https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F6e4164c1-f22c-4fa9-a95d-72edae30fd97_1440x799.png&quot; data-attrs=&quot;{&amp;quot;src&amp;quot;:&amp;quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/6e4164c1-f22c-4fa9-a95d-72edae30fd97_1440x799.png&amp;quot;,&amp;quot;height&amp;quot;:null,&amp;quot;width&amp;quot;:null,&amp;quot;resizeWidth&amp;quot;:null,&amp;quot;bytes&amp;quot;:null,&amp;quot;alt&amp;quot;:null,&amp;quot;title&amp;quot;:null,&amp;quot;type&amp;quot;:null,&amp;quot;href&amp;quot;:null}&quot; alt=&quot;&quot;/&gt;&lt;/a&gt;&lt;p&gt;When I ask another developer who their favorite internet API company I usually get a one word response:&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;“Stripe.”&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;“What should our documentation look like?”&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;“Stripe’s docs.”&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;“Who’s your favorite payments company?”&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;“Stripe.”&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;It’s wild how passionate people get about just &lt;em&gt;rails&lt;/em&gt;. When I say rails, think rails on a train track. They serve as a utility for trains to travel on. You can consider Stripe the rails of commerce and the internet. &lt;em&gt;Stripe&lt;/em&gt; provides the rails to the internet that enable a large portion of online commerce and transacting. But still, at the end of the day it’s just an API.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Stripe&lt;/em&gt;’s mission is to increase the GDP of the internet. And they’ve done just that over that last decade. They’ve reached 96% of US adults. And they complete 250M API requests per day. That’s over 91B requests per year that they fulfill through their API.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;So what’s made them such a successful company when their functionality is matched by numerous other companies who can either beat them on rate or functionality?&lt;/em&gt;&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;Customer obsession.&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;&lt;ol start=&quot;2&quot; readability=&quot;-2&quot;&gt;&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;Developer’s First and Foremost &lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;&lt;ol start=&quot;3&quot;&gt;&lt;li&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;Developer Empathy &lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;&lt;ol start=&quot;4&quot;&gt;&lt;li&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;Design&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;Being obsessed with customers was something that John and Patrick from the beginning.&lt;/p&gt;
&lt;p&gt;Early on, Patrick would take customer success to the next level. He would go to customers’ houses to install Stripe. Obsessing over the user experience has become core to the company ever since. &lt;/p&gt;
&lt;a class=&quot;image-link image2 image2-826-1456&quot; target=&quot;_blank&quot; href=&quot;https://cdn.substack.com/image/fetch/c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Ffd01e832-e076-4e8f-aa7f-4dcfca9270e4_1600x908.png&quot;&gt;&lt;img src=&quot;https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Ffd01e832-e076-4e8f-aa7f-4dcfca9270e4_1600x908.png&quot; data-attrs=&quot;{&amp;quot;src&amp;quot;:&amp;quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/fd01e832-e076-4e8f-aa7f-4dcfca9270e4_1600x908.png&amp;quot;,&amp;quot;height&amp;quot;:826,&amp;quot;width&amp;quot;:1456,&amp;quot;resizeWidth&amp;quot;:null,&amp;quot;bytes&amp;quot;:null,&amp;quot;alt&amp;quot;:null,&amp;quot;title&amp;quot;:null,&amp;quot;type&amp;quot;:null,&amp;quot;href&amp;quot;:null}&quot; alt=&quot;&quot;/&gt;&lt;/a&gt;
&lt;p&gt;This philosophy comes through in the Stripe dashboard. A button that reads “Feedback about this page?” stands prominently in the top right corner of every page of the dashboard.&lt;/p&gt;
&lt;p&gt;Constantly improving the UX for customers is a never-ending goal of theirs. That’s what it means to be customer obsessed. If you ever settle, you’re doing it wrong. &lt;/p&gt;
&lt;p&gt;They even take it a step further. You can expect their employees who don’t even work on product to ask you how they can improve it and where you’ve experienced issues. &lt;/p&gt;
&lt;p&gt;That’s what &lt;strong&gt;customer obsession&lt;/strong&gt; looks like.&lt;/p&gt;

&lt;p&gt;Making developers feel special is key to Stripe’s success. When a developer gets to work with Stripe, it feels magical. &lt;/p&gt;
&lt;p&gt;Patrick and John experienced the problem. They were frustrated. And they responded.&lt;/p&gt;
&lt;p&gt;But their response wasn’t just building something that “just worked”. They built something that solved the problems they themselves had as developers. They fixed the things with that kept them up at night.&lt;/p&gt;
&lt;p&gt;Then they kept improving. They talked to customers constantly. They found their problems. They &lt;em&gt;&lt;strong&gt;empathized&lt;/strong&gt;&lt;/em&gt; with the developers who were the ones building things with their product. &lt;/p&gt;
&lt;p&gt;The act of empathy in developing a developer focused product is severely undervalued. The software engineers that are building their company’s software have opinions. More likely than not those opinions on the tech they use are religious. And developer religion is sacred. By focusing on creating the best developer experience possible, Stripe has earned the love, praise and promotion of developers all over the world. Stripe doesn’t need to force their product down anyone’s throat because they create a delightful experience in a sector that leaves people banging their heads against the wall. &lt;/p&gt;
&lt;p&gt;&lt;em&gt;But is it really worth it to invest so heavily in product and developer experience?&lt;/em&gt;&lt;/p&gt;
&lt;ol readability=&quot;5&quot;&gt;&lt;li readability=&quot;6&quot;&gt;
&lt;p&gt;Stripe was built to arm the rebels. They reduce the cost to start accepting payments securely to zero. Previously, businesses needed to invest heavily in building a compliant payment system that can take payments on their site. Not only is it expensive, but it’s also risky to do so and take on the liability of processing payments. With Stripe, you can process millions with a 30 minute integration from a remote cabin in the mountains. &lt;em&gt;&lt;strong&gt;Anyone, anywhere can rebel against the system with Stripe.&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;4&quot;&gt;
&lt;p&gt;&lt;em&gt;What comes around goes around&lt;/em&gt;. Stripe has spread good karma to developers by giving them an amazing experience and making them happy. In return, developers are promoters. They rep the brand and promote it where they can. &lt;em&gt;They fanboy over the slightest feature release and push for adoption wherever they can. Not surprisingly, they push to work with it at their jobs too. &lt;strong&gt;That’s bottom up adoption at it’s best.&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;&lt;em&gt;What actually differentiates stripe from the rest of the bunch though?&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;It’s the little things.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Stripe obsesses over creating a seamless customer experience. Small annoyances in applications compound. Sure, a user might not churn immediately because you have a bunch of unoptimized functionality or crappy UX, but it’s a recipe to create a grumpy user. And grumpy users aren’t always loyal users.&lt;/p&gt;
&lt;p&gt;Over the years, Stripe has taken developers’ grumpy feedback and made it their mission to make developers smile when using their platform. &lt;/p&gt;
&lt;a class=&quot;image-link image2 image2-799-1440&quot; target=&quot;_blank&quot; href=&quot;https://cdn.substack.com/image/fetch/c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F6e4164c1-f22c-4fa9-a95d-72edae30fd97_1440x799.png&quot;&gt;&lt;img src=&quot;https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F6e4164c1-f22c-4fa9-a95d-72edae30fd97_1440x799.png&quot; data-attrs=&quot;{&amp;quot;src&amp;quot;:&amp;quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/6e4164c1-f22c-4fa9-a95d-72edae30fd97_1440x799.png&amp;quot;,&amp;quot;height&amp;quot;:799,&amp;quot;width&amp;quot;:1440,&amp;quot;resizeWidth&amp;quot;:null,&amp;quot;bytes&amp;quot;:null,&amp;quot;alt&amp;quot;:null,&amp;quot;title&amp;quot;:null,&amp;quot;type&amp;quot;:null,&amp;quot;href&amp;quot;:null}&quot; alt=&quot;&quot;/&gt;&lt;/a&gt;
&lt;p&gt;Not only that, but Stripe has also managed to stay away from the enterprise jargon that makes developers and rebels alike cringe.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;Payments infrastructure for the internet&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;It’s sexy, accurate and true to Stripe. A true developer first brand staying loyal to their values.&lt;/p&gt;
&lt;p&gt;Also there’s this - &lt;/p&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;Design that inspires…&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Stripe doesn’t just value utility - they value the beauty in providing the utility. When you land on the Stripe home page you’re greeted with a design that inspires. Its beauty and attention to detail makes you want to build a better future. It makes you aspire to be like Stripe (the evidence is in the thousand startups that rip off their design yearly - as they say, mimicry is the best form of flattery).&lt;/p&gt;
&lt;p&gt;I’m no design expert, but I can safely say that when you compare the following, one makes you want to do something with your day, and the other makes you want to take a nap.&lt;/p&gt;
&lt;a class=&quot;image-link image2 image2-455-1456&quot; target=&quot;_blank&quot; href=&quot;https://cdn.substack.com/image/fetch/c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F206c5c19-8990-47ed-a4c0-ec972421e02b_1600x500.png&quot;&gt;&lt;img src=&quot;https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F206c5c19-8990-47ed-a4c0-ec972421e02b_1600x500.png&quot; data-attrs=&quot;{&amp;quot;src&amp;quot;:&amp;quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/206c5c19-8990-47ed-a4c0-ec972421e02b_1600x500.png&amp;quot;,&amp;quot;height&amp;quot;:455,&amp;quot;width&amp;quot;:1456,&amp;quot;resizeWidth&amp;quot;:null,&amp;quot;bytes&amp;quot;:null,&amp;quot;alt&amp;quot;:null,&amp;quot;title&amp;quot;:null,&amp;quot;type&amp;quot;:null,&amp;quot;href&amp;quot;:null}&quot; alt=&quot;&quot;/&gt;&lt;/a&gt;
&lt;p&gt;Like I said, it’s the small things. Braintree works. It functions. &lt;em&gt;&lt;strong&gt;But it doesn’t inspire. &lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Stripe has built a developer brand that’s helped propel them to success by embracing the little things and leaning into them. The effort in their aesthetic and interaction design doesn’t go unnoticed. &lt;/p&gt;
&lt;p&gt;When Stripe dropped their latest design upgrade, developer and design twitter went nuts. Everyone was talking about it for a couple days. &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;“What do you think of the new Stripe design?” &lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;That’s what I kept hearing for a solid 3 days. &lt;/p&gt;
&lt;p&gt;When people are buzzing about just a new site design, you know you’ve done something right. This is what happens when you invest heavily into the small things that go a long way for your audience. Stripe knows their customers are developers and developers tend to be obsessed with details. So Stripe makes sure all the details and small things(like the homepage) are delightful. &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;… so what does this mean for everyone else?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;If you’re building a developer first company - or a product that aims to empower developers to build something, you need to be obsessive about the developers who are going to build on top of you. &lt;/p&gt;
&lt;p&gt;Make them want to spend their &lt;em&gt;free time building on your product. &lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Make them want to &lt;em&gt;start a cult for your product. &lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Make them &lt;em&gt;your biggest fans.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;If you can do that, then the rest will come. Having a passionate developer audience behind your product will have compounding returns. They’ll build on top of your platform. They’ll promote it to others. And they’ll obsess over the product. &lt;/p&gt;
&lt;p&gt;Suffice to say, obsessing over your customers/developers will pay dividends. It’s somewhat imperative to obsess over them if you want to build a strong developer first product/company. Stripe may be the developer obsessive company on everyone’s mind right now, but be certain others have taken notice. There’s a new wave of companies coming who are developer obsessed and design driven. &lt;/p&gt;
&lt;p&gt;Keep your eyes peeled. &lt;/p&gt;
</description>
<pubDate>Tue, 21 Jul 2020 02:19:25 +0000</pubDate>
<dc:creator>jgecawich</dc:creator>
<og:type>article</og:type>
<og:title>Stripe: Building a Developer Cult</og:title>
<og:description>What makes Stripe a favorite of developers, the advantages of building a cult, and the how the little things add for developers</og:description>
<og:image>https://cdn.substack.com/image/fetch/h_600,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F6e4164c1-f22c-4fa9-a95d-72edae30fd97_1440x799.png</og:image>
<dc:format>text/html</dc:format>
<dc:identifier>https://subvert.substack.com/p/stripe-building-a-developer-cult</dc:identifier>
</item>
</channel>
</rss>