<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="css/feed.xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/" xmlns:og="http://ogp.me/ns#">
<channel>
<atom:link rel="self" href="http://192.168.1.4/fivefilters/makefulltextfeed.php?url=hnrss.org%2Fnewest%3Fpoints%3D200&amp;max=10&amp;links=preserve&amp;exc=" />
<atom:link rel="alternate" title="Source URL" href="http://hnrss.org/newest?points=200" />
<atom:link rel="related" title="Subscribe to feed" href="http://www.subtome.com/#/subscribe?feeds=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dhnrss.org%252Fnewest%253Fpoints%253D200%26max%3D10%26links%3Dpreserve%26exc%3D&amp;back=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dhnrss.org%252Fnewest%253Fpoints%253D200%26max%3D10%26links%3Dpreserve%26exc%3D" />
<title>Hacker News: Newest</title>
<link>https://news.ycombinator.com/newest</link>
<description>Hacker News RSS</description>
<item>
<title>Chrome will Soon Let You Share Links to a Specific Word or Sentence on a Page</title>
<link>https://www.chromestory.com/2019/02/chrome-scroll-to-text/</link>
<guid isPermaLink="true" >https://www.chromestory.com/2019/02/chrome-scroll-to-text/</guid>
<description>&lt;p&gt;Here is a really innovative and interesting Chrome feature that‚Äôs getting ready. I cannot explain this new feature in just one sentence, so stay with me.&lt;/p&gt;

&lt;p&gt;When you share a YouTube video, you now have an option to create a link that will start the video at a specific spot. For example, if you want your friend start playing the video at two minutes mark, you can create a link for that specific spot.&lt;/p&gt;
&lt;p&gt;Now, imagine you are sharing a link to a web page. There is one specific sentence or paragraph that you want your friend to read. The page does not have any anchor links.&lt;/p&gt;
&lt;p&gt;What will you do?&lt;/p&gt;
&lt;p&gt;Highlight in a screenshot? Ask him to do a Ctrl + F on the page for a specific word or phrase? Well, what if they are on mobile? It is difficult to even dot he Ctrl + F thing there!&lt;/p&gt;
&lt;h2&gt;Enter Scroll to Text&lt;/h2&gt;
&lt;p&gt;Scroll to Text is a new Chrome feature that will let you create a link targeting a word or phrase on a page.&lt;/p&gt;
&lt;p&gt;Here is the flag description, explaining this feature:&lt;/p&gt;
&lt;p&gt;‚ÄúEnables scrolling to text specified in URL‚Äôs fragment.‚Äù The flag is named ‚ÄúEnable Text Fragment Anchor‚Äù&lt;/p&gt;
&lt;p&gt;You can see the &lt;a href=&quot;https://chromium-review.googlesource.com/c/chromium/src/+/1470735&quot;&gt;code commit here&lt;/a&gt;. But wait. I have plenty more to show you! Looks like this is a small project available on GitHub and is being ported to Chrome. The &lt;a href=&quot;https://github.com/bokand/ScrollToTextFragment&quot;&gt;GitHub page&lt;/a&gt; is well documented and explains this feature in great detail.&lt;/p&gt;
&lt;blockquote class=&quot;wp-block-quote&quot; readability=&quot;13&quot;&gt;
&lt;p&gt;When referencing a specific section of a web page, for example as part of sharing that content via email or on social media, it is desirable to be able to link directly to the specific section. If a section is not linkable by a named anchor or element with id, it is not currently possible to share a link directly to a specific section. Users may work around this by sharing screenshots of the relevant portion of the document (preventing the recipient of the content from engaging with the actual web page that hosts the content), or by including extra instructions to scroll to a specific part of the document (e.g. ‚Äúskip to the sixth paragraph‚Äù). We would like to enable users to link to the relevant section of a document directly. Linking directly to the relevant section of a document preserves attribution, and allows the user following the URL to engage directly with the original publisher.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;I highly recommend reading the whole introduction on GitHub. It is a well-written document.&lt;/p&gt;
&lt;p&gt;This feature is being added as a flag to Chrome. It might take a week or so to show up in the Canary channel. I am hoping to get you a video demo of this feature pretty soon. (&lt;a href=&quot;https://www.youtube.com/user/chromestory&quot;&gt;Subscribe to my channel here&lt;/a&gt;.)&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://www.chromestory.com/wp-content/uploads/2019/02/chrome-scroll-to-text-1024x986.png&quot; alt=&quot;&quot; class=&quot;wp-image-25798&quot; srcset=&quot;https://www.chromestory.com/wp-content/uploads/2019/02/chrome-scroll-to-text-1024x986.png 1024w, https://www.chromestory.com/wp-content/uploads/2019/02/chrome-scroll-to-text-350x337.png 350w, https://www.chromestory.com/wp-content/uploads/2019/02/chrome-scroll-to-text-768x739.png 768w, https://www.chromestory.com/wp-content/uploads/2019/02/chrome-scroll-to-text.png 1498w&quot; sizes=&quot;(max-width: 1024px) 100vw, 1024px&quot;/&gt;&lt;/p&gt;

&lt;h2&gt;Here is How This will Work&lt;/h2&gt;
&lt;p&gt;Borrowing from the Github document:&lt;/p&gt;
&lt;blockquote class=&quot;wp-block-quote&quot; readability=&quot;11&quot;&gt;
&lt;p&gt;We propose encoding a text snippet in the URL fragment, prefixed with the¬†&lt;code&gt;targetText=&lt;/code&gt;¬†string. Since text can contain characters invalid in a URL (e.g. spaces), the text must be percent encoded. For example,¬†&lt;code&gt;#targetText=My%20Heading&lt;/code&gt;¬†would cause the first occurance of ‚ÄúMy Heading‚Äù on the page to be selected as the indicated part of the document.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Here is an example:&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://www.example.com/&quot; class=&quot;&quot;&gt;www.example.com&lt;/a&gt;#targetText=alpha%20beta,psi%20omega Will scroll and highlight a block of text starting with ‚Äúalpha beta‚Äù and ending with ‚Äúpsi omega‚Äù&lt;/p&gt;
&lt;h2&gt;Beyond Chrome&lt;/h2&gt;
&lt;p&gt;Here is what I think. Let me know your opinion too, in comments. I would say this is not going to be a Chrome-only feature. It is most likely that this will be added to other browsers like Firefox too.&lt;/p&gt;
&lt;p&gt;Microsoft‚Äôs &lt;a href=&quot;https://www.chromestory.com/2015/04/microsofts-edge-browser-will-run-chrome-and-firefox-extensions/&quot;&gt;new version of Edge is going to be based on Chromium&lt;/a&gt;, so this will be available on Edge too.&lt;/p&gt;
&lt;p&gt;What do you think?&lt;/p&gt;
&lt;h2&gt;Latest Video from Chrome Story&lt;/h2&gt;
&lt;p&gt;&lt;span class=&quot;embed-youtube&quot;&gt;&lt;iframe class=&quot;youtube-player&quot; type=&quot;text/html&quot; width=&quot;640&quot; height=&quot;360&quot; src=&quot;https://www.youtube.com/embed/GVN-WJw7x5U?version=3&amp;amp;rel=1&amp;amp;fs=1&amp;amp;autohide=2&amp;amp;showsearch=0&amp;amp;showinfo=1&amp;amp;iv_load_policy=1&amp;amp;wmode=transparent&quot; allowfullscreen=&quot;true&quot;&gt;[embedded content]&lt;/iframe&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;
&lt;h3 class=&quot;jp-relatedposts-headline&quot;&gt;&lt;em&gt;Related&lt;/em&gt;&lt;/h3&gt;
&lt;/p&gt;
</description>
<pubDate>Fri, 15 Feb 2019 04:22:11 +0000</pubDate>
<dc:creator>kumaranvpl</dc:creator>
<og:type>article</og:type>
<og:title>Chrome will Soon Let You Share Link to Specific Word or Sentence on a Page - Chrome Story</og:title>
<og:description>Here is a really innovative and interesting Chrome feature that‚Äôs getting ready. I cannot explain this new feature in just one sentence, so stay with me. When you share a YouTube video, you now have an option to create a link that will start the video at a specific spot. For example, if you want ‚Ä¶</og:description>
<og:url>https://www.chromestory.com/2019/02/chrome-scroll-to-text/</og:url>
<og:image>https://www.chromestory.com/wp-content/uploads/2019/02/chrome-scroll-to-text.png</og:image>
<dc:language>en-US</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.chromestory.com/2019/02/chrome-scroll-to-text/</dc:identifier>
</item>
<item>
<title>Sample cloud-native application with microservices</title>
<link>https://github.com/GoogleCloudPlatform/microservices-demo</link>
<guid isPermaLink="true" >https://github.com/GoogleCloudPlatform/microservices-demo</guid>
<description>&lt;div class=&quot;Box-body p-6&quot;&gt;
&lt;article class=&quot;markdown-body entry-content&quot; itemprop=&quot;text&quot;&gt;
&lt;p&gt;This project contains a 10-tier microservices application. The application is a web-based e-commerce app called &lt;strong&gt;‚ÄúHipster Shop‚Äù&lt;/strong&gt; where users can browse items, add them to the cart, and purchase them.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Google uses this application to demonstrate use of technologies like Kubernetes/GKE, Istio, Stackdriver, gRPC and OpenCensus&lt;/strong&gt;. This application works on any Kubernetes cluster (such as a local one), as well as Google Kubernetes Engine. It‚Äôs &lt;strong&gt;easy to deploy with little to no configuration&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;If you‚Äôre using this demo, please &lt;strong&gt;‚òÖStar&lt;/strong&gt; this repository to show your interest!&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;üëì&lt;strong&gt;Note to Googlers:&lt;/strong&gt; Please fill out the form at &lt;a href=&quot;http://go/microservices-demo&quot; rel=&quot;nofollow&quot;&gt;go/microservices-demo&lt;/a&gt; if you are using this application.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2&gt;Screenshots&lt;/h2&gt;
&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;Home Page&lt;/th&gt;
&lt;th&gt;Checkout Screen&lt;/th&gt;
&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;a href=&quot;https://github.com/GoogleCloudPlatform/microservices-demo/blob/master/docs/img/hipster-shop-frontend-1.png&quot;&gt;&lt;img src=&quot;https://github.com/GoogleCloudPlatform/microservices-demo/raw/master/docs/img/hipster-shop-frontend-1.png&quot; alt=&quot;Screenshot of store homepage&quot;/&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&quot;https://github.com/GoogleCloudPlatform/microservices-demo/blob/master/docs/img/hipster-shop-frontend-2.png&quot;&gt;&lt;img src=&quot;https://github.com/GoogleCloudPlatform/microservices-demo/raw/master/docs/img/hipster-shop-frontend-2.png&quot; alt=&quot;Screenshot of checkout screen&quot;/&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;h2&gt;Service Architecture&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Hipster Shop&lt;/strong&gt; is composed of many microservices written in different languages that talk to each other over gRPC.&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/GoogleCloudPlatform/microservices-demo/blob/master/docs/img/architecture-diagram.png&quot;&gt;&lt;img src=&quot;https://github.com/GoogleCloudPlatform/microservices-demo/raw/master/docs/img/architecture-diagram.png&quot; alt=&quot;Architecture of microservices&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Find &lt;strong&gt;Protocol Buffers Descriptions&lt;/strong&gt; at the &lt;a href=&quot;https://github.com/GoogleCloudPlatform/microservices-demo/blob/master/pb&quot;&gt;&lt;code&gt;./pb&lt;/code&gt; directory&lt;/a&gt;.&lt;/p&gt;
&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;Service&lt;/th&gt;
&lt;th&gt;Language&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;a href=&quot;https://github.com/GoogleCloudPlatform/microservices-demo/blob/master/src/frontend&quot;&gt;frontend&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Go&lt;/td&gt;
&lt;td&gt;Exposes an HTTP server to serve the website. Does not require signup/login and generates session IDs for all users automatically.&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;a href=&quot;https://github.com/GoogleCloudPlatform/microservices-demo/blob/master/src/cartservice&quot;&gt;cartservice&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;C#&lt;/td&gt;
&lt;td&gt;Stores the items in the user's shipping cart in Redis and retrieves it.&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;a href=&quot;https://github.com/GoogleCloudPlatform/microservices-demo/blob/master/src/productcatalogservice&quot;&gt;productcatalogservice&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Go&lt;/td&gt;
&lt;td&gt;Provides the list of products from a JSON file and ability to search products and get individual products.&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;a href=&quot;https://github.com/GoogleCloudPlatform/microservices-demo/blob/master/src/currencyservice&quot;&gt;currencyservice&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Node.js&lt;/td&gt;
&lt;td&gt;Converts one money amount to another currency. Uses real values fetched from European Central Bank. It's the highest QPS service.&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;a href=&quot;https://github.com/GoogleCloudPlatform/microservices-demo/blob/master/src/paymentservice&quot;&gt;paymentservice&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Node.js&lt;/td&gt;
&lt;td&gt;Charges the given credit card info (mock) with the given amount and returns a transaction ID.&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;a href=&quot;https://github.com/GoogleCloudPlatform/microservices-demo/blob/master/src/shippingservice&quot;&gt;shippingservice&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Go&lt;/td&gt;
&lt;td&gt;Gives shipping cost estimates based on the shopping cart. Ships items to the given address (mock)&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;a href=&quot;https://github.com/GoogleCloudPlatform/microservices-demo/blob/master/src/emailservice&quot;&gt;emailservice&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Python&lt;/td&gt;
&lt;td&gt;Sends users an order confirmation email (mock).&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;a href=&quot;https://github.com/GoogleCloudPlatform/microservices-demo/blob/master/src/checkoutservice&quot;&gt;checkoutservice&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Go&lt;/td&gt;
&lt;td&gt;Retrieves user cart, prepares order and orchestrates the payment, shipping and the email notification.&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;a href=&quot;https://github.com/GoogleCloudPlatform/microservices-demo/blob/master/src/recommendationservice&quot;&gt;recommendationservice&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Python&lt;/td&gt;
&lt;td&gt;Recommends other products based on what's given in the cart.&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;a href=&quot;https://github.com/GoogleCloudPlatform/microservices-demo/blob/master/src/adservice&quot;&gt;adservice&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Java&lt;/td&gt;
&lt;td&gt;Provides text ads based on given context words.&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;a href=&quot;https://github.com/GoogleCloudPlatform/microservices-demo/blob/master/src/loadgenerator&quot;&gt;loadgenerator&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Python/Locust&lt;/td&gt;
&lt;td&gt;Continuously sends requests imitating realistic user shopping flows to the frontend.&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;h2&gt;Features&lt;/h2&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://kubernetes.io&quot; rel=&quot;nofollow&quot;&gt;Kubernetes&lt;/a&gt;/&lt;a href=&quot;https://cloud.google.com/kubernetes-engine/&quot; rel=&quot;nofollow&quot;&gt;GKE&lt;/a&gt;:&lt;/strong&gt; The app is designed to run on Kubernetes (both locally on &quot;Docker for Desktop&quot;, as well as on the cloud with GKE).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://grpc.io&quot; rel=&quot;nofollow&quot;&gt;gRPC&lt;/a&gt;:&lt;/strong&gt; Microservices use a high volume of gRPC calls to communicate to each other.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://istio.io&quot; rel=&quot;nofollow&quot;&gt;Istio&lt;/a&gt;:&lt;/strong&gt; Application works on Istio service mesh.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://opencensus.io/&quot; rel=&quot;nofollow&quot;&gt;OpenCensus&lt;/a&gt; Tracing:&lt;/strong&gt; Most services are instrumented using OpenCensus trace interceptors for gRPC/HTTP.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://cloud.google.com/stackdriver/&quot; rel=&quot;nofollow&quot;&gt;Stackdriver APM&lt;/a&gt;:&lt;/strong&gt; Many services are instrumented with &lt;strong&gt;Profiling&lt;/strong&gt;, &lt;strong&gt;Tracing&lt;/strong&gt; and &lt;strong&gt;Debugging&lt;/strong&gt;. In addition to these, using Istio enables features like Request/Response &lt;strong&gt;Metrics&lt;/strong&gt; and &lt;strong&gt;Context Graph&lt;/strong&gt; out of the box. When it is running out of Google Cloud, this code path remains inactive.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/GoogleContainerTools/skaffold&quot;&gt;Skaffold&lt;/a&gt;:&lt;/strong&gt; Application is deployed to Kubernetes with a single command using Skaffold.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Synthetic Load Generation:&lt;/strong&gt; The application demo comes with a background job that creates realistic usage patterns on the website using &lt;a href=&quot;https://locust.io/&quot; rel=&quot;nofollow&quot;&gt;Locust&lt;/a&gt; load generator.&lt;/li&gt;
&lt;/ul&gt;&lt;h2&gt;Installation&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; that the first build can take up to 20-30 minutes. Consequent builds will be faster.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3&gt;Option 1: Running locally with ‚ÄúDocker for Desktop‚Äù&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;üí° Recommended if you're planning to develop the application.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ol&gt;&lt;li&gt;
&lt;p&gt;Install tools to run a Kubernetes cluster locally:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;kubectl (can be installed via &lt;code&gt;gcloud components install kubectl&lt;/code&gt;)&lt;/li&gt;
&lt;li&gt;Docker for Desktop (Mac/Windows): It provides Kubernetes support as &lt;a href=&quot;https://docs.docker.com/docker-for-mac/kubernetes/&quot; rel=&quot;nofollow&quot;&gt;noted here&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/GoogleContainerTools/skaffold/#installation&quot;&gt;skaffold&lt;/a&gt; (ensure version ‚â•v0.20)&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Launch ‚ÄúDocker for Desktop‚Äù. Go to Preferences:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;choose ‚ÄúEnable Kubernetes‚Äù,&lt;/li&gt;
&lt;li&gt;set CPUs to at least 3, and Memory to at least 6.0 GiB&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Run &lt;code&gt;kubectl get nodes&lt;/code&gt; to verify you're connected to ‚ÄúKubernetes on Docker‚Äù.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Run &lt;code&gt;skaffold run&lt;/code&gt; (first time will be slow, it can take ~20-30 minutes). This will build and deploy the application. If you need to rebuild the images automatically as you refactor he code, run &lt;code&gt;skaffold dev&lt;/code&gt; command.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Run &lt;code&gt;kubectl get pods&lt;/code&gt; to verify the Pods are ready and running. The application frontend should be available at &lt;a href=&quot;http://localhost:80&quot; rel=&quot;nofollow&quot;&gt;http://localhost:80&lt;/a&gt; on your machine.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;&lt;h3&gt;Option 2: Running on Google Kubernetes Engine (GKE)&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;üí° Recommended for demos and making it available publicly.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ol&gt;&lt;li&gt;
&lt;p&gt;Install tools specified in the previous section (Docker, kubectl, skaffold)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Create a Google Kubernetes Engine cluster and make sure &lt;code&gt;kubectl&lt;/code&gt; is pointing to the cluster.&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt; gcloud services enable container.googleapis.com

 gcloud container clusters create demo --enable-autoupgrade \
     --enable-autoscaling --min-nodes=3 --max-nodes=10 --num-nodes=5 --zone=us-central1-a

 kubectl get nodes
&lt;/code&gt;
&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Enable Google Container Registry (GCR) on your GCP project and configure the &lt;code&gt;docker&lt;/code&gt; CLI to authenticate to GCR:&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;gcloud services enable containerregistry.googleapis.com

gcloud auth configure-docker -q
&lt;/code&gt;
&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;In the root of this repository, run &lt;code&gt;skaffold run --default-repo=gcr.io/[PROJECT_ID]&lt;/code&gt;, where [PROJECT_ID] is your GCP project ID.&lt;/p&gt;
&lt;p&gt;This command:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;builds the container images&lt;/li&gt;
&lt;li&gt;pushes them to GCR&lt;/li&gt;
&lt;li&gt;applies the &lt;code&gt;./kubernetes-manifests&lt;/code&gt; deploying the application to Kubernetes.&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;Troubleshooting:&lt;/strong&gt; If you get &quot;No space left on device&quot; error on Google Cloud Shell, you can build the images on Google Cloud Build: &lt;a href=&quot;https://console.cloud.google.com/flows/enableapi?apiid=cloudbuild.googleapis.com&quot; rel=&quot;nofollow&quot;&gt;Enable the Cloud Build API&lt;/a&gt;, then run &lt;code&gt;skaffold run -p gcb --default-repo=gcr.io/[PROJECT_ID]&lt;/code&gt; instead.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Find the IP address of your application, then visit the application on your browser to confirm installation.&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;kubectl get service frontend-external
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Troubleshooting:&lt;/strong&gt; A Kubernetes bug (will be fixed in 1.12) combined with a Skaffold &lt;a href=&quot;https://github.com/GoogleContainerTools/skaffold/issues/887&quot;&gt;bug&lt;/a&gt; causes load balancer to not to work even after getting an IP address. If you are seeing this, run &lt;code&gt;kubectl get service frontend-external -o=yaml | kubectl apply -f-&lt;/code&gt; to trigger load balancer reconfiguration.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;&lt;h3&gt;Option 3: Using Static Images&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;üí° Recommended for test-driving the application on an existing cluster.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;Prerequisite&lt;/strong&gt;: a running Kubernetes cluster.&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;
&lt;p&gt;Clone this repository.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Deploy the application: &lt;code&gt;kubectl apply -f ./release/kubernetes-manifests&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Run &lt;code&gt;kubectl get pods&lt;/code&gt; to see pods are in a healthy and ready state.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Find the IP address of your application, then visit the application on your browser to confirm installation.&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;kubectl get service frontend-external
&lt;/code&gt;
&lt;/pre&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;h3&gt;(Optional) Deploying on a Istio-installed GKE cluster&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; you followed GKE deployment steps above, run &lt;code&gt;skaffold delete&lt;/code&gt; first to delete what's deployed.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ol&gt;&lt;li&gt;
&lt;p&gt;Create a GKE cluster (described above).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Use &lt;a href=&quot;https://cloud.google.com/istio/docs/istio-on-gke/installing&quot; rel=&quot;nofollow&quot;&gt;Istio on GKE add-on&lt;/a&gt; to install Istio to your existing GKE cluster.&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;gcloud beta container clusters update demo \
    --zone=us-central1-a \
    --update-addons=Istio=ENABLED \
    --istio-config=auth=MTLS_PERMISSIVE
&lt;/code&gt;
&lt;/pre&gt;
&lt;blockquote&gt;
&lt;p&gt;NOTE: If you need to enable &lt;code&gt;MTLS_STRICT&lt;/code&gt; mode, you will need to update several manifest files:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;code&gt;kubernetes-manifests/frontend.yaml&lt;/code&gt;: delete &quot;livenessProbe&quot; and &quot;readinessProbe&quot; fields.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;kubernetes-manifests/loadgenerator.yaml&lt;/code&gt;: delete &quot;initContainers&quot; field.&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;(Optional) Enable Stackdriver Tracing/Logging with Istio Stackdriver Adapter by &lt;a href=&quot;https://cloud.google.com/istio/docs/istio-on-gke/installing#enabling_tracing_and_logging&quot; rel=&quot;nofollow&quot;&gt;following this guide&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Install the automatic sidecar injection (annotate the &lt;code&gt;default&lt;/code&gt; namespace with the label):&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;kubectl label namespace default istio-injection=enabled
&lt;/code&gt;
&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Apply the manifests in &lt;a href=&quot;https://github.com/GoogleCloudPlatform/microservices-demo/blob/master/istio-manifests&quot;&gt;&lt;code&gt;./istio-manifests&lt;/code&gt;&lt;/a&gt; directory.&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;kubectl apply -f ./istio-manifests
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;This is required only once.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Deploy the application with &lt;code&gt;skaffold run --default-repo=gcr.io/[PROJECT_ID]&lt;/code&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Run &lt;code&gt;kubectl get pods&lt;/code&gt; to see pods are in a healthy and ready state.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Find the IP address of your istio gateway Ingress or Service, and visit the application.&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;INGRESS_HOST=&quot;$(kubectl -n istio-system get service istio-ingressgateway -o jsonpath='{.status.loadBalancer.ingress[0].ip}')&quot;

echo &quot;$INGRESS_HOST&quot;

curl -v &quot;http://$INGRESS_HOST&quot;
&lt;/code&gt;
&lt;/pre&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;h2&gt;Conferences featuring Hipster Shop&lt;/h2&gt;
&lt;hr/&gt;&lt;p&gt;This is not an official Google project.&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;
</description>
<pubDate>Fri, 15 Feb 2019 01:25:20 +0000</pubDate>
<dc:creator>zdw</dc:creator>
<og:image>https://avatars2.githubusercontent.com/u/2810941?s=400&amp;v=4</og:image>
<og:type>object</og:type>
<og:title>GoogleCloudPlatform/microservices-demo</og:title>
<og:url>https://github.com/GoogleCloudPlatform/microservices-demo</og:url>
<og:description>Sample cloud-native application with 10 microservices showcasing Kubernetes, Istio, gRPC and OpenCensus. Provided for illustration and demo purposes. - GoogleCloudPlatform/microservices-demo</og:description>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://github.com/GoogleCloudPlatform/microservices-demo</dc:identifier>
</item>
<item>
<title>A RISC-V CPU for $8</title>
<link>https://hackaday.com/2019/02/14/new-part-day-a-risc-v-cpu-for-eight-dollars/</link>
<guid isPermaLink="true" >https://hackaday.com/2019/02/14/new-part-day-a-risc-v-cpu-for-eight-dollars/</guid>
<description>&lt;p&gt;RISC-V is the new hotness, and companies are churning out code and announcements, but little actual hardware. Eventually, we‚Äôre going to get to the point where RISC-V microcontrollers and SoCs cost just a few bucks. This day might be here, with &lt;a href=&quot;https://www.seeedstudio.com/sipeed&quot; target=&quot;_blank&quot;&gt;Seeed‚Äôs Sipeed MAix modules&lt;/a&gt;. it‚Äôs a RISC-V chip you can buy right now, the bare module costs eight US dollars, there are several modules, and it has ‚ÄòAI‚Äô.&lt;/p&gt;
&lt;p&gt;Those of you following the developments in the RISC-V world may say this chip looks familiar. You‚Äôre right; last October, a seller on Taobao opened up preorders for the &lt;a href=&quot;https://hackaday.com/2018/10/08/new-part-day-the-risc-v-chip-with-built-in-neural-networks/&quot;&gt;Sipeed M1 K210 chip&lt;/a&gt;, a chip with neural networks. Cool, we can ignore some buzzwords if it means new chips. Seeed has been busy these last few months, and they‚Äôre now selling modules, dev boards, and peripherals that include a camera, mic array, and displays. It‚Äôs here now, and you can buy one. If it seems a little weird for Seeed Studios to get their hands on this, remember: the ESP8266 just¬†&lt;em&gt;showed up&lt;/em&gt; on their web site one day a few years ago. Look where we are with that now.&lt;/p&gt;
&lt;p&gt;The big deal here is the &lt;a href=&quot;https://www.seeedstudio.com/Sipeed-MAIX-I-module-WiFi-version-1st-RISC-V-64-AI-Module-K210-insid-p-3206.html&quot; target=&quot;_blank&quot;&gt;Sipeed MAix-I module&lt;/a&gt;¬†&lt;em&gt;with&lt;/em&gt; WiFi, sold out because it costs nine bucks. Inside this module is a Kendryte K210 RISC-V CPU with 8MB of on-chip SRAM and a 400MHz clock. This chip is also loaded up with a Neural Network Processor, an Audio Processor with support for eight microphones, and a ‚ÄòField Programmable IO array‚Äô, which sounds like it‚Äôs a crossbar on the 48 GPIOs on the chip. Details and documentation are obviously lacking.&lt;/p&gt;
&lt;p&gt;In addition to a chip that‚Äôs currently out of stock, we also have the same chip as above, without WiFi, for a dollar less. It‚Äôll probably be out of stock by the time you read this. &lt;a href=&quot;https://www.seeedstudio.com/Sipeed-MAix-Go-Suit-for-RISC-V-AI-IoT-p-2874.html&quot; target=&quot;_blank&quot;&gt;There‚Äôs a ‚ÄòGo Suit‚Äô&lt;/a&gt; that puts one of these chips in an enclosure with a camera and display, and there‚Äôs a microphone array add-on. There‚Äôs a binocular camera module if you want to play around with depth sensing.&lt;/p&gt;
&lt;p&gt;The first time we heard of this chip, it was just a preorder on Taobao. It told us two things: RISC-V chips are coming sooner than we expected, and you can do preorders on Taobao. Seeed has a history of bringing interesting chips to the wider world, and if you want a RISC-V chip¬†right now, here you go. &lt;a href=&quot;https://hackaday.com/submit-a-tip/&quot;&gt;Just be sure to tell us what you did with it.&lt;/a&gt;&lt;/p&gt;
</description>
<pubDate>Thu, 14 Feb 2019 21:42:43 +0000</pubDate>
<dc:creator>heywire</dc:creator>
<og:type>article</og:type>
<og:title>New Part Day: A RISC-V CPU For Eight Dollars</og:title>
<og:url>https://hackaday.com/2019/02/14/new-part-day-a-risc-v-cpu-for-eight-dollars/</og:url>
<og:description>RISC-V is the new hotness, and companies are churning out code and announcements, but little actual hardware. Eventually, we‚Äôre going to get to the point where RISC-V microcontrollers and SoC‚Ä¶</og:description>
<og:image>https://hackadaycom.files.wordpress.com/2019/02/rifroheader.jpg</og:image>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://hackaday.com/2019/02/14/new-part-day-a-risc-v-cpu-for-eight-dollars/</dc:identifier>
</item>
<item>
<title>Replacing JavaScript Hot Path with WebAssembly</title>
<link>https://developers.google.com/web/updates/2019/02/hotpath-with-wasm</link>
<guid isPermaLink="true" >https://developers.google.com/web/updates/2019/02/hotpath-with-wasm</guid>
<description>&lt;h2 id=&quot;its_consistently_fast_yo&quot;&gt;It's consistently fast, yo.&lt;/h2&gt;
&lt;section class=&quot;wf-byline&quot; itemprop=&quot;author&quot; itemscope=&quot;&quot; itemtype=&quot;http://schema.org/Person&quot;&gt;&lt;div class=&quot;attempt-left&quot;&gt;&lt;img itemprop=&quot;image&quot; src=&quot;https://developers.google.com/web/images/contributors/surma.jpg&quot; alt=&quot;Surma &quot;/&gt;&lt;/div&gt;
&lt;section class=&quot;wf-byline-meta&quot;&gt;
&lt;div class=&quot;wf-byline-desc&quot;&gt;Surma is a contributor to Web&lt;strong&gt;Fundamentals&lt;/strong&gt;&lt;/div&gt;
&lt;/section&gt;&lt;/section&gt;&lt;p&gt;In my &lt;a href=&quot;https://developers.google.com/web/updates/2018/03/emscripting-a-c-library&quot;&gt;previous&lt;/a&gt; &lt;a href=&quot;https://developers.google.com/web/updates/2019/01/emscripten-npm&quot;&gt;articles&lt;/a&gt; I talked about how WebAssembly allows you to bring the library ecosystem of C/C++ to the web. One app that makes extensive use of C/C++ libraries is &lt;a href=&quot;https://squoosh.app/&quot;&gt;squoosh&lt;/a&gt;, our web app that allows you compress images with a variety of codecs that have been compiled from C++ to WebAssembly.&lt;/p&gt;
&lt;p&gt;WebAssembly is a low-level virtual machine that runs the bytecode that is stored in &lt;code&gt;.wasm&lt;/code&gt; files. This byte code is strongly typed and structured in such a way that it can be compiled and optimized for the host system much quicker than JavaScript can. WebAssembly provides an environment to run code that had sandboxing and embedding in mind from the very start.&lt;/p&gt;
&lt;p&gt;In my experience, most performance problems on the web are caused by forced layout and excessive paint but every now and then an app needs to do a computationally expensive task that takes a lot of time. WebAssembly can help here.&lt;/p&gt;
&lt;aside class=&quot;note&quot;&gt;&lt;strong&gt;Note:&lt;/strong&gt; &lt;span&gt;Due to legal concerns, I won‚Äôt name any browsers in this article.&lt;/span&gt;&lt;/aside&gt;&lt;h2 id=&quot;the_hot_path&quot;&gt;The Hot Path&lt;/h2&gt;
&lt;p&gt;In squoosh we wrote a &lt;a href=&quot;https://github.com/GoogleChromeLabs/squoosh/blob/edd2c51eb6d0676a2e7b7e974337d58cbf00f1d1/src/codecs/rotate/processor.ts&quot;&gt;JavaScript function&lt;/a&gt; that rotates an image buffer by multiples of 90 degrees. While &lt;a href=&quot;https://developers.google.com/web/updates/2018/08/offscreen-canvas&quot;&gt;OffscreenCanvas&lt;/a&gt; would be ideal for this, it isn't supported across the browsers we were targeting, and a little &lt;a href=&quot;https://bugs.chromium.org/p/chromium/issues/detail?id=906619&quot;&gt;buggy in Chrome&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;This function iterates over every pixel of an input image and copies it to a different position in the output image to achieve rotation. For a 4094px by 4096px image (16 megapixels) it would need over 16 million iterations of the inner code block, which is what we call a &quot;hot path&quot;. Despite that rather big number of iterations, two out of three browsers we tested finish the task in 2 seconds or less. An acceptable duration for this type of interaction.&lt;/p&gt;
&lt;pre class=&quot;prettyprint notranslate&quot; translate=&quot;no&quot;&gt;
&lt;code&gt;for (let d2 = d2Start; d2 &amp;gt;= 0 &amp;amp;&amp;amp; d2 &amp;lt; d2Limit; d2 += d2Advance) {
  for (let d1 = d1Start; d1 &amp;gt;= 0 &amp;amp;&amp;amp; d1 &amp;lt; d1Limit; d1 += d1Advance) {
    const in_idx = ((d1 * d1Multiplier) + (d2 * d2Multiplier));
    outBuffer[i] = inBuffer[in_idx];
    i += 1;
  }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;One browser, however, takes over 8 seconds. The way browsers optimize JavaScript is &lt;em&gt;really complicated&lt;/em&gt;, and different engines optimize for different things. Some optimize for raw execution, some optimize for interaction with the DOM. In this case, we've hit an unoptimized path in one browser.&lt;/p&gt;
&lt;p&gt;WebAssembly on the other hand is built entirely around raw execution speed. So if we want fast, &lt;em&gt;predictable&lt;/em&gt; performance across browsers for code like this, WebAssembly can help.&lt;/p&gt;
&lt;h2 id=&quot;webassembly_for_predictable_performance&quot;&gt;WebAssembly for predictable performance&lt;/h2&gt;
&lt;p&gt;In general, JavaScript and WebAssembly can achieve the same peak performance. However, for JavaScript this performance can only be reached on the &quot;fast path&quot;, and it's often tricky to stay on that &quot;fast path&quot;. One key benefit that WebAssembly offers is predictable performance, even across browsers. The strict typing and low-level architecture allows the compiler to make stronger guarantees so that WebAssembly code only has to be optimized once and will always use the ‚Äúfast path‚Äù.&lt;/p&gt;
&lt;h3 id=&quot;writing_for_webassembly&quot;&gt;Writing for WebAssembly&lt;/h3&gt;
&lt;p&gt;Previously we took C/C++ libraries and compiled them to WebAssembly to use their functionality on the web. We didn't really touch the code of the libraries, we just wrote small amounts of C/C++ code to form the bridge between the browser and the library. This time our motivation is different: We want to write something from scratch with WebAssembly in mind so we can make use of the advantages that WebAssembly has.&lt;/p&gt;
&lt;h4 id=&quot;webassembly_architecture&quot;&gt;WebAssembly architecture&lt;/h4&gt;
&lt;p&gt;When writing &lt;em&gt;for&lt;/em&gt; WebAssembly, it's beneficial to understand a bit more about what WebAssembly actually is.&lt;/p&gt;
&lt;p&gt;To quote &lt;a href=&quot;https://webassembly.org/&quot;&gt;WebAssembly.org&lt;/a&gt;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;WebAssembly (abbreviated Wasm) is a binary instruction format for a stack-based virtual machine. Wasm is designed as a portable target for compilation of high-level languages like C/C++/Rust, enabling deployment on the web for client and server applications.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;When you compile a piece of C or Rust code to WebAssembly, you get a &lt;code&gt;.wasm&lt;/code&gt; file that contains a module declaration. This declaration consists of a list of &quot;imports&quot; the module expects from its environment, a list of exports that this module makes available to the host (functions, constants, chunks of memory) and of course the actual binary instructions for the functions contained within.&lt;/p&gt;
&lt;p&gt;Something that I didn't realize until I looked into this: The stack that makes WebAssembly a &quot;stack-based virtual machine&quot; is not stored in the chunk of memory that WebAssembly modules use. The stack is completely VM-internal and inaccessible to web developers (except through DevTools). As such it is possible to write WebAssembly modules that don't need any additional memory at all and only use the VM-internal stack.&lt;/p&gt;
&lt;aside class=&quot;note&quot;&gt;&lt;strong&gt;Note:&lt;/strong&gt; &lt;span&gt;(for the curious) Compilers like Emscripten still use the WebAssembly memory to implement their own stack. This is necessary so you can access values anywhere on the stack through constructs like pointers in C, something the VM-internal stack does not allow. So, somewhat confusingly, when you run C via WebAssembly, &lt;em&gt;two&lt;/em&gt; stacks are in use!&lt;/span&gt;&lt;/aside&gt;&lt;p&gt;In our case we will need to use some additional memory to allow arbitrary access to the pixels of our image and generate a rotated version of that image. This is what &lt;code&gt;WebAssembly.Memory&lt;/code&gt; is for.&lt;/p&gt;
&lt;h4 id=&quot;memory_management&quot;&gt;Memory management&lt;/h4&gt;
&lt;p&gt;Commonly, once you use additional memory you will find the need to somehow manage that memory. Which parts of the memory are in use? Which ones are free? In C, for example, you have the &lt;code&gt;malloc(n)&lt;/code&gt; function that finds a memory space of &lt;code&gt;n&lt;/code&gt; consecutive bytes. Functions of this kind are also called &quot;allocators&quot;. Of course the implementation of the allocator in use must be included in your WebAssembly module and will increase your file size. This size and performance of these memory management functions can vary quite significantly depending on the algorithm used, which is why many languages offer multiple implementations to choose from (&quot;dmalloc&quot;, &quot;emmalloc&quot;, &quot;wee_alloc&quot;,...).&lt;/p&gt;
&lt;p&gt;In our case we know the dimensions of the input image (and therefore the dimensions of the output image) before we run the WebAssembly module. Here we saw an opportunity: Traditionally, we'd pass the input image's RGBA buffer as a parameter to a WebAssembly function and return the rotated image as a return value. To generate that return value we would have to make use of the allocator. But since we know the total amount of memory needed (twice the size of the input image, once for input and once for output), we can put the input image into the WebAssembly memory using &lt;em&gt;JavaScript&lt;/em&gt;, run the WebAssembly module to generate a 2nd, rotated image and then use JavaScript to read back the result. We can get away without using any memory management at all!&lt;/p&gt;
&lt;h3 id=&quot;spoiled_for_choice&quot;&gt;Spoiled for choice&lt;/h3&gt;
&lt;p&gt;If you looked at the &lt;a href=&quot;https://github.com/GoogleChromeLabs/squoosh/blob/edd2c51eb6d0676a2e7b7e974337d58cbf00f1d1/src/codecs/rotate/processor.ts&quot;&gt;original JavaScript function&lt;/a&gt; that we want to WebAssembly-fy, you can see that it's a purely computational code with no JavaScript-specific APIs. As such it should be fairly straight forward to port this code to any language. We evaluated 3 different languages that compile to WebAssembly: C/C++, Rust and AssemblyScript. The only question we need to answer for each of the languages is: How do we access raw memory without using memory management functions?&lt;/p&gt;
&lt;aside class=&quot;note&quot;&gt;&lt;strong&gt;Note:&lt;/strong&gt; &lt;span&gt;I skipped the &quot;boring&quot; parts in the code samples and focused on the actual hot path and the memory access. The full version of each sample along with the benchmark can be found in the &lt;a href=&quot;https://gist.github.com/surma/0eb306fa9acc8bdf2f58150b2f1e82b4&quot;&gt;gist&lt;/a&gt;.&lt;/span&gt;&lt;/aside&gt;&lt;h4 id=&quot;c_and_emscripten&quot;&gt;C and Emscripten&lt;/h4&gt;
&lt;p&gt;Emscripten is a C compiler for the WebAssembly target. Emscripten's goal is to function as a drop-in replacement for well-known C compilers like GCC or clang and is mostly flag compatible. This is a core part of the Emscripten's mission as it wants to make compiling existing C and C++ code to WebAssembly as easy as possible.&lt;/p&gt;
&lt;p&gt;Accessing raw memory is in the very nature of C and pointers exist for that very reason:&lt;/p&gt;
&lt;pre class=&quot;prettyprint notranslate&quot; translate=&quot;no&quot;&gt;
&lt;code&gt;uint8_t* ptr = (uint8_t*)0x124;
ptr[0] = 0xFF;
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;Here we are turning the number &lt;code&gt;0x124&lt;/code&gt; into a pointer to unsigned, 8-bit integers (or bytes). This effectively turns the &lt;code&gt;ptr&lt;/code&gt; variable into an array starting at memory address &lt;code&gt;0x124&lt;/code&gt;, that we can use like any other array, allowing us to access individual bytes for reading and writing. In our case we are looking at an RGBA buffer of an image that we want to re-order to achieve rotation. To move a pixel we actually need to move 4 consecutive bytes at once (one byte for each channel: R, G, B and A). To make this easier we can create an array of unsigned, &lt;em&gt;32-bit&lt;/em&gt; integers. By convention, our input image will start at address 4 and our output image will start directly after the input image ends:&lt;/p&gt;
&lt;pre class=&quot;prettyprint notranslate&quot; translate=&quot;no&quot;&gt;
&lt;code&gt;int bpp = 4;
int imageSize = inputWidth * inputHeight * bpp;
uint32_t* inBuffer = (uint32_t*) 4;
uint32_t* outBuffer = (uint32_t*) (inBuffer + imageSize);

for (int d2 = d2Start; d2 &amp;gt;= 0 &amp;amp;&amp;amp; d2 &amp;lt; d2Limit; d2 += d2Advance) {
  for (int d1 = d1Start; d1 &amp;gt;= 0 &amp;amp;&amp;amp; d1 &amp;lt; d1Limit; d1 += d1Advance) {
    int in_idx = ((d1 * d1Multiplier) + (d2 * d2Multiplier));
    outBuffer[i] = inBuffer[in_idx];
    i += 1;
  }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;aside class=&quot;note&quot;&gt;&lt;strong&gt;Note:&lt;/strong&gt; &lt;span&gt;The reason we chose to start at address 4 and not 0 is because address 0 has a special meaning in many languages: It's the dreaded null pointer. While technically 0 is a perfectly valid address, many languages exclude 0 as a valid value for pointers and either throw an exception or just tumble into undefined behavior.&lt;/span&gt;&lt;/aside&gt;&lt;p&gt;After porting the entire JavaScript function to C, we can compile &lt;a href=&quot;https://gist.github.com/surma/0eb306fa9acc8bdf2f58150b2f1e82b4#file-rotate-c&quot;&gt;the C file&lt;/a&gt; with &lt;code&gt;emcc&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&quot;prettyprint notranslate&quot; translate=&quot;no&quot;&gt;
&lt;code&gt;$ emcc -O3 -s ALLOW_MEMORY_GROWTH=1 -o c.js rotate.c
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;As always, emscripten generates a glue code file called &lt;code&gt;c.js&lt;/code&gt; and a wasm module called &lt;code&gt;c.wasm&lt;/code&gt;. Note that the wasm module gzips to only ~260 Bytes, while the glue code is around 3.5KB after gzip. After some fiddling, we were able to ditch the glue code and instantiate the WebAssembly modules with the vanilla APIs. This is often possible with Emscripten as long as you are not using anything from the C standard library.&lt;/p&gt;
&lt;aside class=&quot;note&quot;&gt;&lt;strong&gt;Note:&lt;/strong&gt; &lt;span&gt;We are working with the Emscripten team to make the glue code smaller or even non-existent at times.&lt;/span&gt;&lt;/aside&gt;&lt;h4 id=&quot;rust&quot;&gt;Rust&lt;/h4&gt;
&lt;aside class=&quot;note&quot;&gt;&lt;strong&gt;Note:&lt;/strong&gt; &lt;span&gt;Since the release of this article, we have learned more about how to optimize Rust for WebAssembly. Please see the &lt;a href=&quot;https://developers.google.com/web/updates/2019/02/hotpath-with-wasm#update-rust&quot;&gt;update section&lt;/a&gt; at the end of this article.&lt;/span&gt;&lt;/aside&gt;&lt;p&gt;Rust is a new, modern programming language with a rich type system, no runtime and an ownership model that guarantees memory-safety and thread-safety. Rust also supports WebAssembly as a first-class citizen and the Rust team has contributed a lot of excellent tooling to the WebAssembly ecosystem.&lt;/p&gt;
&lt;p&gt;One of these tools is &lt;a href=&quot;https://rustwasm.github.io/wasm-pack/&quot;&gt;&lt;code&gt;wasm-pack&lt;/code&gt;&lt;/a&gt;, by the &lt;a href=&quot;https://github.com/rustwasm/team&quot;&gt;rustwasm working group&lt;/a&gt;. &lt;code&gt;wasm-pack&lt;/code&gt; takes your code and turns it into a web-friendly module that works out-of-the-box with bundlers like webpack. &lt;code&gt;wasm-pack&lt;/code&gt; is an extremely convenient experience, but currently only works for Rust. The group is considering to add support for other WebAssembly-targeting languages.&lt;/p&gt;
&lt;p&gt;In Rust, slices are what arrays are in C. And just like in C, we need to create slices that use our start addresses. This goes against the memory safety model that Rust enforces, so to get our way we have to use the &lt;code&gt;unsafe&lt;/code&gt; keyword, allowing us to write code that doesn't comply with that model.&lt;/p&gt;
&lt;aside class=&quot;note&quot;&gt;&lt;strong&gt;Note:&lt;/strong&gt; &lt;span&gt;This is not a best practice. In our experience it is usually worth it to use binding mechanisms like &lt;a href=&quot;https://developers.google.com/web/updates/2018/08/embind&quot;&gt;embind in Emscripten&lt;/a&gt; or &lt;a href=&quot;https://rustwasm.github.io/wasm-bindgen/&quot;&gt;wasm-bindgen&lt;/a&gt; for Rust to work at a higher level.&lt;/span&gt;&lt;/aside&gt;&lt;pre class=&quot;prettyprint notranslate&quot; translate=&quot;no&quot;&gt;
&lt;code&gt;let imageSize = (inputWidth * inputHeight) as usize;
let inBuffer: &amp;amp;mut [u32];
let outBuffer: &amp;amp;mut [u32];
unsafe {
  inBuffer = slice::from_raw_parts_mut::&amp;lt;u32&amp;gt;(4 as *mut u32, imageSize);
  outBuffer = slice::from_raw_parts_mut::&amp;lt;u32&amp;gt;((imageSize * 4 + 4) as *mut u32, imageSize);
}

for d2 in 0..d2Limit {
  for d1 in 0..d1Limit {
    let in_idx = (d1Start + d1 * d1Advance) * d1Multiplier + (d2Start + d2 * d2Advance) * d2Multiplier;
    outBuffer[i as usize] = inBuffer[in_idx as usize];
    i += 1;
  }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;Compiling the Rust files using&lt;/p&gt;
&lt;pre class=&quot;prettyprint notranslate&quot; translate=&quot;no&quot;&gt;
&lt;code&gt;$ wasm-pack build
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;yields a 7.6KB wasm module with about 100 bytes of glue code (both after gzip).&lt;/p&gt;
&lt;h4 id=&quot;assemblyscript&quot;&gt;AssemblyScript&lt;/h4&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/AssemblyScript/assemblyscript&quot;&gt;AssemblyScript&lt;/a&gt; is a fairly young project that aims to be a TypeScript-to-WebAssembly compiler. It's important to note, however, that it won't just consume any TypeScript. AssemblyScript uses the same syntax as TypeScript but switches out the standard library for their own. Their standard library models the capabilities of WebAssembly. That means you can't just compile any TypeScript you have lying around to WebAssembly, but it &lt;em&gt;does&lt;/em&gt; mean that you don't have to learn a new programming language to write WebAssembly!&lt;/p&gt;
&lt;pre class=&quot;prettyprint notranslate&quot; translate=&quot;no&quot;&gt;
&lt;code&gt;for (let d2 = d2Start; d2 &amp;gt;= 0 &amp;amp;&amp;amp; d2 &amp;lt; d2Limit; d2 += d2Advance) {
  for (let d1 = d1Start; d1 &amp;gt;= 0 &amp;amp;&amp;amp; d1 &amp;lt; d1Limit; d1 += d1Advance) {
    let in_idx = ((d1 * d1Multiplier) + (d2 * d2Multiplier));
    store&amp;lt;u32&amp;gt;(offset + i * 4 + 4, load&amp;lt;u32&amp;gt;(in_idx * 4 + 4));
    i += 1;
  }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;Considering the small type surface that our &lt;code&gt;rotate()&lt;/code&gt; function has, it was fairly easy to port this code to AssemblyScript. The functions &lt;code&gt;load&amp;lt;T&amp;gt;(ptr: usize)&lt;/code&gt; and &lt;code&gt;store&amp;lt;T&amp;gt;(ptr: usize, value: T)&lt;/code&gt; are provided by AssemblyScript to access raw memory. To compile &lt;a href=&quot;https://gist.github.com/surma/0eb306fa9acc8bdf2f58150b2f1e82b4#file-rotate-ts&quot;&gt;our AssemblyScript file&lt;/a&gt;, we only need to install the &lt;code&gt;AssemblyScript/assemblyscript&lt;/code&gt; npm package and run&lt;/p&gt;
&lt;pre class=&quot;prettyprint notranslate&quot; translate=&quot;no&quot;&gt;
&lt;code&gt;$ asc rotate.ts -b assemblyscript.wasm --validate -O3
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;AssemblyScript will provide us with a ~300 Bytes wasm module and &lt;em&gt;no&lt;/em&gt; glue code. The module just works with the vanilla WebAssembly APIs.&lt;/p&gt;
&lt;h3 id=&quot;webassembly_forensics&quot;&gt;WebAssembly Forensics&lt;/h3&gt;
&lt;p&gt;Rust's 7.6KB is surprisingly big when compared to the 2 other languages. There are a couple of tools in the WebAssembly ecosystem that can help you analyze your WebAssembly files (regardless of the language the got created with) and tell you what is going on and also help you improve your situation.&lt;/p&gt;
&lt;h4 id=&quot;twiggy&quot;&gt;Twiggy&lt;/h4&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/rustwasm/twiggy&quot;&gt;Twiggy&lt;/a&gt; is another tool from Rust's WebAssembly team that extracts a bunch of insightful data from a WebAssembly module. The tool is not Rust-specific and allows you to inspect things like the module's call graph, determine unused or superfluous sections and figure out which sections are contributing to the total file size of your module. The latter can be done with Twiggy's &lt;code&gt;top&lt;/code&gt; command:&lt;/p&gt;
&lt;pre class=&quot;prettyprint notranslate&quot; translate=&quot;no&quot;&gt;
&lt;code&gt;$ twiggy top rotate_bg.wasm
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;img src=&quot;https://developers.google.com/web/updates/images/2019/02/hotpath-with-wasm/twiggy.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;In this case we can see that a majority of our file size stems from the allocator. That was surprising since our code is not using dynamic allocations. Another big contributing factor is a &quot;function names&quot; subsection.&lt;/p&gt;
&lt;h4 id=&quot;wasm-strip&quot;&gt;wasm-strip&lt;/h4&gt;
&lt;p&gt;&lt;code&gt;wasm-strip&lt;/code&gt; is a tool from the &lt;a href=&quot;https://github.com/WebAssembly/wabt&quot;&gt;WebAssembly Binary Toolkit&lt;/a&gt;, or wabt for short. It contains a couple of tools that allow you to inspect and manipulate WebAssembly modules. &lt;code&gt;wasm2wat&lt;/code&gt; is a disassembler that turns a binary wasm module into a human-readable format. Wabt also contains &lt;code&gt;wat2wasm&lt;/code&gt; which allows you to turn that human-readable format back into a binary wasm module. While we did use these two complementary tools to inspect our WebAssembly files, we found &lt;code&gt;wasm-strip&lt;/code&gt; to be the most useful. &lt;code&gt;wasm-strip&lt;/code&gt; removes unnecessary sections and metadata from a WebAssembly module:&lt;/p&gt;
&lt;pre class=&quot;prettyprint notranslate&quot; translate=&quot;no&quot;&gt;
&lt;code&gt;$ wasm-strip rotate_bg.wasm
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;This reduces the file size of the rust module from 7.5KB to 6.6KB (after gzip).&lt;/p&gt;
&lt;h4 id=&quot;wasm-opt&quot;&gt;wasm-opt&lt;/h4&gt;
&lt;p&gt;&lt;code&gt;wasm-opt&lt;/code&gt; is a tool from &lt;a href=&quot;https://github.com/WebAssembly/binaryen&quot;&gt;Binaryen&lt;/a&gt;. It takes a WebAssembly module and tries to optimize it both for size and performance based only on the bytecode. Some tools like Emscripten already run this tool, some others do not. It's usually a good idea to try and save some additional bytes by using these tools.&lt;/p&gt;
&lt;pre class=&quot;prettyprint notranslate&quot; translate=&quot;no&quot;&gt;
&lt;code&gt;wasm-opt -O3 -o rotate_bg_opt.wasm rotate_bg.wasm
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;With &lt;code&gt;wasm-opt&lt;/code&gt; we can shave off another handful of bytes to leave a total of 6.2KB after gzip.&lt;/p&gt;
&lt;h4 id=&quot;no_std&quot;&gt;#![no_std]&lt;/h4&gt;
&lt;p&gt;After some consultation and research, we re-wrote our Rust code without using Rust's standard library, using the &lt;a href=&quot;https://doc.rust-lang.org/unstable-book/language-features/lang-items.html#writing-an-executable-without-stdlib&quot;&gt;&lt;code&gt;#![no_std]&lt;/code&gt;&lt;/a&gt; feature. This also disables dynamic memory allocations altogether, removing the allocator code from our module. Compiling &lt;a href=&quot;https://gist.github.com/surma/0eb306fa9acc8bdf2f58150b2f1e82b4#file-rotate-rs&quot;&gt;this Rust file&lt;/a&gt; with&lt;/p&gt;
&lt;pre class=&quot;prettyprint notranslate&quot; translate=&quot;no&quot;&gt;
&lt;code&gt;$ rustc --target=wasm32-unknown-unknown -C opt-level=3 -o rust.wasm rotate.rs
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;yielded a 1.6KB wasm module after &lt;code&gt;wasm-opt&lt;/code&gt;, &lt;code&gt;wasm-strip&lt;/code&gt; and gzip. While it is still bigger than the modules generated by C and AssemblyScript, it is small enough to be considered a lightweight.&lt;/p&gt;
&lt;aside class=&quot;note&quot;&gt;&lt;strong&gt;Note:&lt;/strong&gt; &lt;span&gt;According to Twiggy, the main contributor to the file size is &lt;code&gt;core::fmt&lt;/code&gt;, a module that generates turns data into strings (like C's &lt;code&gt;printf()&lt;/code&gt;). It is used by code paths that could trigger an exception as they generate a human-readable exception messages. Rust's WebAssembly team is aware of this and is actively working on improvements here.&lt;/span&gt;&lt;/aside&gt;&lt;h3 id=&quot;performance&quot;&gt;Performance&lt;/h3&gt;
&lt;p&gt;Before we jump to conclusions based on file size alone ‚Äî we went on this journey to optimize performance, not file size. So how did we measure performance and what were the results?&lt;/p&gt;
&lt;h4 id=&quot;how_to_benchmark&quot;&gt;How to benchmark&lt;/h4&gt;
&lt;p&gt;Despite WebAssembly being a low-level bytecode format, it still needs to be sent through a compiler to generate host-specific machine code. Just like JavaScript, the compiler works in multiple stages. Said simply: The first stage is much faster at compiling but tends to generate slower code. Once the module starts running, the browser observes which parts are frequently used and sends those through a more optimizing but slower compiler.&lt;/p&gt;
&lt;p&gt;Our use-case is interesting in that the code for rotating an image will be used once, maybe twice. So in the vast majority of cases we will never get the benefits of the optimizing compiler. This is important to keep in mind when benchmarking. Running our WebAssembly modules 10,000 times in a loop would give unrealistic results. To get realistic numbers, we should run the module once and make decisions based on the numbers from that single run.&lt;/p&gt;
&lt;aside class=&quot;note&quot;&gt;&lt;strong&gt;Note:&lt;/strong&gt; &lt;span&gt;Ideally, we should have automated this process of reloading the page and running the module once, and doing that process a large number of times. We decided that a few manual runs are good enough to make an informed decision based on those averaged numbers.&lt;/span&gt;&lt;/aside&gt;&lt;h4 id=&quot;performance_comparison&quot;&gt;Performance comparison&lt;/h4&gt;
&lt;p&gt;&lt;img width=&quot;100%&quot; src=&quot;https://developers.google.com/web/updates/images/2019/02/hotpath-with-wasm/speed-per-lang.svg&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;img width=&quot;100%&quot; src=&quot;https://developers.google.com/web/updates/images/2019/02/hotpath-with-wasm/speed-per-browser.svg&quot;/&gt;&lt;/p&gt;
&lt;p&gt;These two graphs are different views onto the same data. In the first graph we compare per browser, in the second graph we compare per language used. Please note that I chose a logarithmic timescale. It‚Äôs also important that all benchmarks were using the same 16 megapixel test image and the same host machine, except for one browser, which could not be run on the same machine.&lt;/p&gt;
&lt;p&gt;Without analyzing these graphs too much, it is clear that we solved our original performance problem: All WebAssembly modules run in ~500ms or less. This confirms what we laid out at the start: WebAssembly gives you &lt;em&gt;predictable&lt;/em&gt; performance. No matter which language we choose, the variance between browsers and languages is minimal. To be exact: The standard deviation of JavaScript across all browsers is ~400ms, while the standard deviation of all our WebAssembly modules across all browsers is ~80ms.&lt;/p&gt;
&lt;h3 id=&quot;effort&quot;&gt;Effort&lt;/h3&gt;
&lt;p&gt;Another metric is the amount of effort we had to put in to create and integrate our WebAssembly module into squoosh. It is hard to assign a numeric value to effort, so I won't create any graphs but there are a few things I would like to point out:&lt;/p&gt;
&lt;p&gt;AssemblyScript was frictionless. Not only does it allow you to use TypeScript to write WebAssembly, making code-review very easy for my colleagues, but it also produces glue-free WebAssembly modules that are very small with decent performance. The tooling in the TypeScript ecosystem, like prettier and tslint, will likely just work.&lt;/p&gt;
&lt;p&gt;Rust in combination with &lt;code&gt;wasm-pack&lt;/code&gt; is also extremely convenient, but excels more at bigger WebAssembly projects were bindings and memory management are needed. We had to diverge a bit from the happy-path to achieve a competitive file size.&lt;/p&gt;
&lt;p&gt;C and Emscripten created a very small and highly performant WebAssembly module out of the box, but without the courage to jump into glue code and reduce it to the bare necessities the total size (WebAssembly module + glue code) ends up being quite big.&lt;/p&gt;
&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;So what language should you use if you have a JS hot path and want to make it faster or more consistent with WebAssembly. As always with performance questions, the answer is: It depends. So what did we ship?&lt;/p&gt;
&lt;p&gt;&lt;img width=&quot;100%&quot; src=&quot;https://developers.google.com/web/updates/images/2019/02/hotpath-with-wasm/scatter.svg&quot;/&gt;&lt;/p&gt;
&lt;aside class=&quot;note&quot;&gt;&lt;strong&gt;Note:&lt;/strong&gt; &lt;span&gt;Again, please note that &lt;em&gt;both&lt;/em&gt; axis are logarithmic and that the x axis goes to 2000 Bytes, while the y axis goes up to 10 seconds.&lt;/span&gt;&lt;/aside&gt;&lt;p&gt;Comparing at the module size / performance tradeoff of the different languages we used, the best choice seems to be either C or AssemblyScript. &lt;a href=&quot;https://github.com/GoogleChromeLabs/squoosh/pull/438/files&quot;&gt;We decided to ship Rust&lt;/a&gt;. There are multiple reasons for this decision: All the codecs shipped in Squoosh so far are compiled using Emscripten. We wanted to broaden our knowledge about the WebAssembly ecosystem and use a different language &lt;em&gt;in production&lt;/em&gt;. AssemblyScript is a strong alternative, but the project is relatively young and the compiler isn't as mature as the Rust compiler.&lt;/p&gt;
&lt;p&gt;While the difference in file size between Rust and the other languages size looks quite drastic in the scatter graph, it is not that big a deal in reality: Loading 500B or 1.6KB even over 2G takes less than a 1/10th of a second. And Rust will hopefully close the gap in terms of module size soon.&lt;/p&gt;
&lt;p&gt;In terms of runtime performance, Rust has a faster average across browsers than AssemblyScript. Especially on bigger projects Rust will be more likely to produce faster code without needing manual code optimizations. But that shouldn't keep you from using what you are most comfortable with.&lt;/p&gt;
&lt;p&gt;That all being said: AssemblyScript has been a great discovery. It allows web developers to produce WebAssembly modules without having to learn a new language. The AssemblyScript team has been very responsive and is actively working on improving their toolchain. We will definitely keep an eye on AssemblyScript in the future.&lt;/p&gt;
&lt;h2 id=&quot;update-rust&quot;&gt;Update: Rust&lt;/h2&gt;
&lt;p&gt;After publishing this article, &lt;a href=&quot;https://twitter.com/fitzgen&quot;&gt;Nick Fitzgerald&lt;/a&gt; from the Rust team pointed us to their excellent Rust Wasm book, which contains &lt;a href=&quot;https://rustwasm.github.io/book/reference/code-size.html&quot;&gt;a section on optimizing file size&lt;/a&gt;. Following the instructions there (most notably enabling link time optimizations and manual panic handling) allowed us to write ‚Äúnormal‚Äù Rust code and go back to using &lt;code&gt;Cargo&lt;/code&gt; (the &lt;code&gt;npm&lt;/code&gt; of Rust) without bloating the file size. The Rust module ends up with 370B after gzip. For details, please take a look at &lt;a href=&quot;https://github.com/GoogleChromeLabs/squoosh/pull/462&quot;&gt;the PR I opened on Squoosh&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Special thanks to &lt;a href=&quot;https://twitter.com/ag_dubs&quot;&gt;Ashley Williams&lt;/a&gt;, &lt;a href=&quot;https://twitter.com/steveklabnik&quot;&gt;Steve Klabnik&lt;/a&gt;, &lt;a href=&quot;https://twitter.com/fitzgen&quot;&gt;Nick Fitzgerald&lt;/a&gt; and &lt;a href=&quot;https://twitter.com/MaxGraey&quot;&gt;Max Graey&lt;/a&gt; for all their help on this journey.&lt;/em&gt;&lt;/p&gt;
&lt;div class=&quot;devsite-tracking-question&quot;&gt;
&lt;div&gt;Was this page helpful?&lt;/div&gt;
&lt;div class=&quot;gc-analytics-event&quot; data-category=&quot;Helpful&quot; data-value=&quot;1&quot; data-label=&quot;/web/updates/2019/02/hotpath-with-wasm&quot;&gt;

&lt;div class=&quot;devsite-tracking-question&quot;&gt;
&lt;div&gt;What was the best thing about this page?&lt;/div&gt;
&lt;div class=&quot;gc-analytics-event&quot; data-category=&quot;Goals&quot; data-value=&quot;1&quot; data-label=&quot;/web/updates/2019/02/hotpath-with-wasm&quot;&gt;
&lt;div&gt;It helped me complete my goal(s)&lt;/div&gt;
&lt;div&gt;Thank you for the feedback. If you have specific ideas on how to improve this page, please &lt;a href=&quot;https://github.com/google/webfundamentals/issues/new&quot;&gt;create an issue&lt;/a&gt;.&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;gc-analytics-event&quot; data-category=&quot;Completeness&quot; data-value=&quot;1&quot; data-label=&quot;/web/updates/2019/02/hotpath-with-wasm&quot;&gt;
&lt;div&gt;It had the information I needed&lt;/div&gt;
&lt;div&gt;Thank you for the feedback. If you have specific ideas on how to improve this page, please &lt;a href=&quot;https://github.com/google/webfundamentals/issues/new&quot;&gt;create an issue&lt;/a&gt;.&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;gc-analytics-event&quot; data-category=&quot;Accuracy&quot; data-value=&quot;1&quot; data-label=&quot;/web/updates/2019/02/hotpath-with-wasm&quot;&gt;
&lt;div&gt;It had accurate information&lt;/div&gt;
&lt;div&gt;Thank you for the feedback. If you have specific ideas on how to improve this page, please &lt;a href=&quot;https://github.com/google/webfundamentals/issues/new&quot;&gt;create an issue&lt;/a&gt;.&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;gc-analytics-event&quot; data-category=&quot;Writing&quot; data-value=&quot;1&quot; data-label=&quot;/web/updates/2019/02/hotpath-with-wasm&quot;&gt;
&lt;div&gt;It was easy to read&lt;/div&gt;
&lt;div&gt;Thank you for the feedback. If you have specific ideas on how to improve this page, please &lt;a href=&quot;https://github.com/google/webfundamentals/issues/new&quot;&gt;create an issue&lt;/a&gt;.&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;gc-analytics-event&quot; data-category=&quot;Other&quot; data-value=&quot;1&quot; data-label=&quot;/web/updates/2019/02/hotpath-with-wasm&quot;&gt;
&lt;div&gt;Something else&lt;/div&gt;
&lt;div&gt;Thank you for the feedback. If you have specific ideas on how to improve this page, please &lt;a href=&quot;https://github.com/google/webfundamentals/issues/new&quot;&gt;create an issue&lt;/a&gt;.&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;gc-analytics-event&quot; data-category=&quot;Helpful&quot; data-value=&quot;0&quot; data-label=&quot;/web/updates/2019/02/hotpath-with-wasm&quot;&gt;

&lt;div class=&quot;devsite-tracking-question&quot;&gt;
&lt;div&gt;What was the worst thing about this page?&lt;/div&gt;
&lt;div class=&quot;gc-analytics-event&quot; data-category=&quot;Goals&quot; data-value=&quot;0&quot; data-label=&quot;/web/updates/2019/02/hotpath-with-wasm&quot;&gt;
&lt;div&gt;It didn't help me complete my goal(s)&lt;/div&gt;
&lt;div&gt;Thank you for the feedback. If you have specific ideas on how to improve this page, please &lt;a href=&quot;https://github.com/google/webfundamentals/issues/new&quot;&gt;create an issue&lt;/a&gt;.&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;gc-analytics-event&quot; data-category=&quot;Completeness&quot; data-value=&quot;0&quot; data-label=&quot;/web/updates/2019/02/hotpath-with-wasm&quot;&gt;
&lt;div&gt;It was missing information I needed&lt;/div&gt;
&lt;div&gt;Thank you for the feedback. If you have specific ideas on how to improve this page, please &lt;a href=&quot;https://github.com/google/webfundamentals/issues/new&quot;&gt;create an issue&lt;/a&gt;.&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;gc-analytics-event&quot; data-category=&quot;Accuracy&quot; data-value=&quot;0&quot; data-label=&quot;/web/updates/2019/02/hotpath-with-wasm&quot;&gt;
&lt;div&gt;It had inaccurate information&lt;/div&gt;
&lt;div&gt;Thank you for the feedback. If you have specific ideas on how to improve this page, please &lt;a href=&quot;https://github.com/google/webfundamentals/issues/new&quot;&gt;create an issue&lt;/a&gt;.&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;gc-analytics-event&quot; data-category=&quot;Writing&quot; data-value=&quot;0&quot; data-label=&quot;/web/updates/2019/02/hotpath-with-wasm&quot;&gt;
&lt;div&gt;It was hard to read&lt;/div&gt;
&lt;div&gt;Thank you for the feedback. If you have specific ideas on how to improve this page, please &lt;a href=&quot;https://github.com/google/webfundamentals/issues/new&quot;&gt;create an issue&lt;/a&gt;.&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;gc-analytics-event&quot; data-category=&quot;Other&quot; data-value=&quot;0&quot; data-label=&quot;/web/updates/2019/02/hotpath-with-wasm&quot;&gt;
&lt;div&gt;Something else&lt;/div&gt;
&lt;div&gt;Thank you for the feedback. If you have specific ideas on how to improve this page, please &lt;a href=&quot;https://github.com/google/webfundamentals/issues/new&quot;&gt;create an issue&lt;/a&gt;.&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p class=&quot;webFuRSSWidget&quot;&gt;&lt;span class=&quot;material-icons&quot;&gt;rss_feed&lt;/span&gt; Subscribe to our &lt;a href=&quot;https://goo.gl/siLiwf&quot; class=&quot;gc-analytics-event&quot; data-category=&quot;webFu&quot; data-label=&quot;feed-updates-rss-link&quot;&gt;RSS&lt;/a&gt; or &lt;a href=&quot;https://goo.gl/oc2PGP&quot; class=&quot;gc-analytics-event&quot; data-category=&quot;webFu&quot; data-label=&quot;feed-updates-atom-link&quot;&gt;Atom&lt;/a&gt; feed and get the latest &lt;strong&gt;updates&lt;/strong&gt; in your favorite feed reader!&lt;/p&gt;
</description>
<pubDate>Thu, 14 Feb 2019 21:28:24 +0000</pubDate>
<dc:creator>markdog12</dc:creator>
<og:type>website</og:type>
<og:url>https://developers.google.com/web/updates/2019/02/hotpath-with-wasm</og:url>
<og:title>Replacing a hot path in your app's JavaScript with WebAssembly ¬†|¬† Web ¬†|¬† Google Developers</og:title>
<og:description>One key benefit that WebAssembly offers is _predictable_ performance across browsers. But how do you turn hot path written in JavaScript into WebAssembly?</og:description>
<og:image>https://developers.google.com/web/images/social-webfu-16x9.png</og:image>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://developers.google.com/web/updates/2019/02/hotpath-with-wasm</dc:identifier>
</item>
<item>
<title>Moving from Ruby to Rust</title>
<link>http://deliveroo.engineering/2019/02/14/moving-from-ruby-to-rust.html</link>
<guid isPermaLink="true" >http://deliveroo.engineering/2019/02/14/moving-from-ruby-to-rust.html</guid>
<description>&lt;header readability=&quot;3.219512195122&quot;&gt;
&lt;p class=&quot;byline&quot;&gt;&lt;span class=&quot;byline&quot;&gt;Posted by &lt;span class=&quot;author&quot;&gt;&lt;a href=&quot;https://deliveroo.engineering/authors/andrii-dmytrenko&quot;&gt;Andrii Dmytrenko&lt;/a&gt;&lt;/span&gt; on &lt;time datetime=&quot;2019-02-14T00:00:00+00:00&quot; class=&quot;published&quot;&gt;Thursday, February 14, 2019&lt;/time&gt;&lt;/span&gt;&lt;/p&gt;
&lt;/header&gt;&lt;div class=&quot;excerpt&quot; readability=&quot;7&quot;&gt;
&lt;p&gt;How we migrated our Tier 1 service from ruby to rust and didn‚Äôt break production.&lt;/p&gt;
&lt;/div&gt;&lt;h2 class=&quot;no_toc&quot; id=&quot;table-of-contents&quot;&gt;Table of Contents&lt;/h2&gt;
&lt;ol id=&quot;markdown-toc&quot;&gt;&lt;li&gt;&lt;a href=&quot;https://deliveroo.engineering/2019/02/14/moving-from-ruby-to-rust.html#background&quot; id=&quot;markdown-toc-background&quot;&gt;Background&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://deliveroo.engineering/2019/02/14/moving-from-ruby-to-rust.html#why-rust&quot; id=&quot;markdown-toc-why-rust&quot;&gt;Why Rust?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://deliveroo.engineering/2019/02/14/moving-from-ruby-to-rust.html#how-we-made-ruby-talk-to-rust&quot; id=&quot;markdown-toc-how-we-made-ruby-talk-to-rust&quot;&gt;How we made Ruby talk to Rust&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://deliveroo.engineering/2019/02/14/moving-from-ruby-to-rust.html#moving-from-ruby-to-rust&quot; id=&quot;markdown-toc-moving-from-ruby-to-rust&quot;&gt;Moving from Ruby to Rust&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://deliveroo.engineering/2019/02/14/moving-from-ruby-to-rust.html#performance-improvements&quot; id=&quot;markdown-toc-performance-improvements&quot;&gt;Performance Improvements&lt;/a&gt;
&lt;ol&gt;&lt;li&gt;&lt;a href=&quot;https://deliveroo.engineering/2019/02/14/moving-from-ruby-to-rust.html#performance-numbers&quot; id=&quot;markdown-toc-performance-numbers&quot;&gt;Performance numbers&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://deliveroo.engineering/2019/02/14/moving-from-ruby-to-rust.html#conclusion&quot; id=&quot;markdown-toc-conclusion&quot;&gt;Conclusion&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;h2 id=&quot;background&quot;&gt;Background&lt;/h2&gt;
&lt;p&gt;In the Logistics Algorithms team, we have a service, called Dispatcher, the main purpose of which is to offer an order to the rider, optimally. For each rider we build a timeline, where we predict where riders will be at a certain point of time; knowing this, we can more efficiently suggest a rider for an order.&lt;/p&gt;
&lt;p&gt;Building each timeline involves a fair bit of computation: using different machine learning models to predict how long events will take, asserting certain constraints, calculating assignment cost. The computations themselves are quick, but the problem is that we need to do a lot of them: for each order, we need to go over all available riders to determine which assignment would be the best.&lt;/p&gt;
&lt;p&gt;The first version of the Dispatcher was written mainly in Ruby: this was a go-to language in the company, and it was performing adequately given our size at the time. However, as Deliveroo kept growing, the number of orders and riders increaed dramatically, and we saw that the dispatch process started taking much longer than before and we realised, that at some point it will be impossible to dispatch some areas within a time constraint that we put in place. We also knew that is was limiting us if we decided to implement more advanced algorithms, which would require even more computation time.&lt;/p&gt;
&lt;p&gt;The first thing we tried was to optimise the current code (cache some computations, try to find a bug in the algorithms), which didn‚Äôt help much. It was clear that Ruby was a bottleneck here and we started looking at the alternatives.&lt;/p&gt;
&lt;h2 id=&quot;why-rust&quot;&gt;Why Rust?&lt;/h2&gt;
&lt;p&gt;We considered a few approaches to how to solve the problem of dispatch speed:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;choose a new programming language with better performance characteristics and rewrite the Dispatcher&lt;/li&gt;
&lt;li&gt;identify biggest bottlenecks, rewrite those parts of the code and somehow integrate them in the current code&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;We knew that rewriting something from scratch is risky, as it can introduce bugs, and switching services over can be painful, so we didn‚Äôt feel quite comfortable with this approach. Another option, finding bottlenecks and replacing them, was something that we did already for one part of the code (we built a native extension gem for the Hungarian route matching algorithm, implemented in Rust), and that worked well. We decided to try this approach.&lt;/p&gt;
&lt;p&gt;There were several options how we could integrate parts of the code written in another language to work with Ruby:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;build an external service and provide an API to communicate with&lt;/li&gt;
&lt;li&gt;build a native extension&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;We quickly discarded an option to build an external service, because either we would need to call this external service hundreds of thousands of times per dispatch cycle and the overhead of the communication would offset all of the potential speed gains, or we would need to reimplement a big part of the dispatcher inside this service, which is almost the same as a complete rewrite.&lt;/p&gt;
&lt;p&gt;We decided that it has to be some sort of native extension, and for that, we decided to use Rust, as it ticked most of the boxes for us:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;it has high performance (comparable to C)&lt;/li&gt;
&lt;li&gt;it is memory safe&lt;/li&gt;
&lt;li&gt;it can be used to build dynamic libraries, which can be loaded into Ruby (using &lt;code class=&quot;highlighter-rouge&quot;&gt;extern &quot;C&quot;&lt;/code&gt; interface)&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;Some of our team members had experience with Rust and liked the language, also one part of the Dispatcher was already using Rust. Our strategy was to replace the current ruby implementation gradually, by replacing parts of the algorithm one by one. It was possible because we could implement separate methods and classes in Rust and call them from Ruby without a big overhead of cross-language interaction.&lt;/p&gt;
&lt;h2 id=&quot;how-we-made-ruby-talk-to-rust&quot;&gt;How we made Ruby talk to Rust&lt;/h2&gt;
&lt;p&gt;There a few different ways you can call Rust from Ruby:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;write a dynamic library in Rust with &lt;code class=&quot;highlighter-rouge&quot;&gt;extern &quot;C&quot;&lt;/code&gt; interface and call it using &lt;a href=&quot;https://github.com/ffi/ffi/wiki&quot;&gt;FFI&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;write a dynamic library, but use the Ruby API to register methods, so that you can call them from Ruby directly, just like any other Ruby code.&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;The first approach, using FFI would require us to come up with some custom C like interfaces in both Rust and Ruby and then create wrappers for them in both languages. The second approach, using Ruby API, sounded more promising, as there were already libraries to make our lives easier:&lt;/p&gt;
&lt;p&gt;We tried Helix first:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;it has macros which look like writing Ruby in Rust, which was a bit more magical for us than we were comfortable with&lt;/li&gt;
&lt;li&gt;the Coercion Protocol wasn‚Äôt well documented and it wasn‚Äôt clear how would you go about passing non-primitive Ruby objects into Helix methods&lt;/li&gt;
&lt;li&gt;we were not sure about the safety - it looked like Helix didn‚Äôt call Ruby methods using &lt;a href=&quot;https://silverhammermba.github.io/emberb/c/#rb_protect&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;rb_protect&lt;/code&gt;&lt;/a&gt;, which could lead to undefined behavior&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;Eventually, we decided to go with ruru/rutie, but keep the Ruby layer thin and isolated so that we could possibly switch in the future. We decided to use &lt;a href=&quot;https://crates.io/crates/rutie&quot;&gt;Rutie&lt;/a&gt;, a recent fork of &lt;a href=&quot;https://crates.io/crates/ruru&quot;&gt;Ruru&lt;/a&gt; which has more active development.&lt;/p&gt;
&lt;p&gt;Here‚Äôs a small example of how you can create a class with one method in ruru/rutie:&lt;/p&gt;
&lt;div class=&quot;language-rust highlighter-rouge&quot; readability=&quot;11&quot;&gt;
&lt;div class=&quot;highlight&quot; readability=&quot;17&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;
&lt;code&gt;&lt;span class=&quot;err&quot;&gt;#&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;macro_use&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;extern&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;crate&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rutie&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;use&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;rutie&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;::{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Class&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Object&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;RString&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;};&lt;/span&gt;

&lt;span class=&quot;nd&quot;&gt;class!&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;HelloWorld&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;nd&quot;&gt;methods!&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;HelloWorld&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;_itself&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;fn&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;hello&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;RString&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;RString&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;nn&quot;&gt;RString&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;new&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nd&quot;&gt;format!&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Hello {}&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;.unwrap&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;.to_string&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()))&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

&lt;span class=&quot;nd&quot;&gt;#[allow(non_snake_case)]&lt;/span&gt;
&lt;span class=&quot;nd&quot;&gt;#[no_mangle]&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;pub&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;extern&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;C&quot;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;fn&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;Init_ruby_rust_demo&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;mut&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;Class&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;new&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;RubyRustDemo&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;class&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;.define&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(|&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;itself&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;itself&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;.def_self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;hello&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hello&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;It‚Äôs great if all you need is to pass some basic types (like &lt;code class=&quot;highlighter-rouge&quot;&gt;String&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;Fixnum&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;Boolean&lt;/code&gt;, etc.) to your methods, but not that great if you need to pass a lot of data. In that case, you can pass the whole object, say &lt;code class=&quot;highlighter-rouge&quot;&gt;Order&lt;/code&gt; and then you would need to call each field you need on that object to move it into Rust:&lt;/p&gt;
&lt;div class=&quot;language-rust highlighter-rouge&quot; readability=&quot;10.5&quot;&gt;
&lt;div class=&quot;highlight&quot; readability=&quot;16&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;
&lt;code&gt;&lt;span class=&quot;k&quot;&gt;pub&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;struct&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;RustUser&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;address&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Address&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;pub&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;struct&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Address&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;pub&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;country&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;pub&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;city&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;nd&quot;&gt;class!&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;User&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;impl&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;VerifiedObject&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;User&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;fn&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;is_correct_type&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Object&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;object&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;bool&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;object&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;.send&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;class&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;.send&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;name&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;.try_convert_to&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;RString&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;.to_string&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;User&quot;&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;fn&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;error_message&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;'static&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;s&quot;&gt;&quot;Not a valid request&quot;&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;nd&quot;&gt;methods!&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;c&quot;&gt;// .. some code skipped&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;fn&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;hello&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;user&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;AnyObject&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Boolean&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;user&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;.send&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;name&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;.try_convert_to&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;RString&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;.unwrap&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;.to_string&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ruby_address&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;user&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;.send&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;address&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;country&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ruby_address&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;.send&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;country&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;.try_convert_to&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;RString&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;.unwrap&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;.to_string&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;city&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ruby_address&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;.send&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;city&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;.try_convert_to&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;RString&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;.unwrap&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;.to_string&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;address&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Address&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;country&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;city&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;};&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rust_user&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;RustUser&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;address&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;};&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;do_something_with_user&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rust_user&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;nn&quot;&gt;Boolean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;new&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;true&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;You can see a lot of routine and repetitive code here, proper error handling is missing as well. After looking at this code, it reminded us that this looks a lot like some manual parsing of something like JSON or similar. You &lt;em&gt;could&lt;/em&gt; instead serialize objects in Ruby to JSON and then parse it in Rust, and it works mostly OK, but you still need to implement JSON serializers in Ruby. Then we were curious, what if we implement &lt;code class=&quot;highlighter-rouge&quot;&gt;serde&lt;/code&gt; deserializer for &lt;code class=&quot;highlighter-rouge&quot;&gt;AnyObject&lt;/code&gt; itself: it will take ruties‚Äôs &lt;code class=&quot;highlighter-rouge&quot;&gt;AnyObject&lt;/code&gt; and go over each field defined in the type and call the corresponding method on that ruby object to get it‚Äôs value. It worked!&lt;/p&gt;
&lt;p&gt;Here‚Äôs the same method, but using our serde deserializer &amp;amp; serializer:&lt;/p&gt;
&lt;div class=&quot;language-rust highlighter-rouge&quot; readability=&quot;12&quot;&gt;
&lt;div class=&quot;highlight&quot; readability=&quot;19&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;
&lt;code&gt;&lt;span class=&quot;err&quot;&gt;#&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;derive&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Debug&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Deserialize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;pub&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;struct&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;User&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;pub&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;pub&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;address&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Address&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;nd&quot;&gt;#[derive(Debug,&lt;/span&gt; &lt;span class=&quot;nd&quot;&gt;Deserialize)]&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;pub&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;struct&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Address&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;pub&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;country&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;pub&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;city&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;String&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;nd&quot;&gt;class!&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;HelloWorld&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;nd&quot;&gt;rutie_serde_methods!&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;HelloWorld&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;_itself&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;nd&quot;&gt;ruby_class!&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Exception&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;

    &lt;span class=&quot;c&quot;&gt;// Notice that the argument has our defined type `User`, and the return type is plain bool&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;fn&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;hello_user&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;user&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;User&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;bool&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;do_something_with_user&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;user&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;kc&quot;&gt;true&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;You can see how much simpler the code in &lt;code class=&quot;highlighter-rouge&quot;&gt;hello_user&lt;/code&gt; is now - we don‚Äôt need to parse &lt;code class=&quot;highlighter-rouge&quot;&gt;user&lt;/code&gt; manually anymore. Since it‚Äôs serde, it can also handle nested objects (as you can see with the address). We also added a built-in error handling: if serde fails to ‚Äúparse‚Äù the object, this macro will raise an exception of a class that we provided (&lt;code class=&quot;highlighter-rouge&quot;&gt;Exception&lt;/code&gt; in this case), it also wraps the method body in the &lt;a href=&quot;https://doc.rust-lang.org/beta/std/panic/fn.catch_unwind.html&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;panic::catch_unwind&lt;/code&gt;&lt;/a&gt;, and re-raises panics as exceptions in Ruby.&lt;/p&gt;
&lt;p&gt;Using &lt;a href=&quot;https://crates.io/crates/rutie-serde/&quot;&gt;rutie-serde&lt;/a&gt; we could quickly and painlessly implement thin interfaces between ruby and rust.&lt;/p&gt;
&lt;h2 id=&quot;moving-from-ruby-to-rust&quot;&gt;Moving from Ruby to Rust&lt;/h2&gt;
&lt;p&gt;We came up with a plan to gradually replace all parts of the Ruby Dispatcher with Rust. We started by replacing with Rust classes which didn‚Äôt have dependencies on other parts of the Dispatcher and adding feature flags, something similar to this:&lt;/p&gt;
&lt;div class=&quot;language-ruby highlighter-rouge&quot; readability=&quot;10.5&quot;&gt;
&lt;div class=&quot;highlight&quot; readability=&quot;16&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;
&lt;code&gt;&lt;span class=&quot;k&quot;&gt;module&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;TravelTime&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;from_location&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;to_location&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;options&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# in the real world the feature flag would be more granular and enable you to do an incremental roll-out&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rust_enabled?&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;Feature&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;enabled?&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;ss&quot;&gt;:rust_travel_time&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;no&quot;&gt;RustTravelTime&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;from_location&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;to_location&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;options&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;
        &lt;span class=&quot;no&quot;&gt;RubyTravelTime&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;from_location&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;to_location&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;options&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;end&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;end&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;end&lt;/span&gt;
&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;There was also a &lt;strong&gt;master switch&lt;/strong&gt; (in this case &lt;code class=&quot;highlighter-rouge&quot;&gt;rust_enabled?&lt;/code&gt;), which allowed us to switch all the Rust code off by flipping just one feature flag.&lt;/p&gt;
&lt;p&gt;Since the API of both Ruby and Rust classes implementations remained largely the same, we were able to test both of them using the same tests, which gave us more confidence in the quality of the implementation.&lt;/p&gt;
&lt;div class=&quot;language-ruby highlighter-rouge&quot; readability=&quot;8.5&quot;&gt;
&lt;div class=&quot;highlight&quot; readability=&quot;12&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;
&lt;code&gt;&lt;span class=&quot;no&quot;&gt;RSpec&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;describe&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;TravelTime&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;do&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;shared_examples&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;travel_time&quot;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;do&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;let&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;ss&quot;&gt;:from_location&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;build&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;ss&quot;&gt;:location&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;let&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;ss&quot;&gt;:to_location&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;build&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;ss&quot;&gt;:location&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;let&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;ss&quot;&gt;:options&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;build&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;ss&quot;&gt;:travel_time_options&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;it&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'returns correct travel time'&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;do&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;expect&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;no&quot;&gt;TravelTime&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;from_location&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;to_location&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;options&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)).&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;eq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;123.45&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;end&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;end&lt;/span&gt;

  &lt;span class=&quot;n&quot;&gt;context&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;ruby implementation&quot;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;do&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;before&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;do&lt;/span&gt;
      &lt;span class=&quot;no&quot;&gt;Feature&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;disable!&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;ss&quot;&gt;:rust_travel_time&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;end&lt;/span&gt;

    &lt;span class=&quot;kp&quot;&gt;include&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;travel_time&quot;&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;end&lt;/span&gt;

  &lt;span class=&quot;n&quot;&gt;context&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;rust implementation&quot;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;do&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;before&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;do&lt;/span&gt;
      &lt;span class=&quot;no&quot;&gt;Feature&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;enable!&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;ss&quot;&gt;:rust_travel_time&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;end&lt;/span&gt;

    &lt;span class=&quot;kp&quot;&gt;include&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;travel_time&quot;&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;end&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;end&lt;/span&gt;
&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;It was also very important that, at any time, we could switch off the Rust integration and the Dispatcher would still work (because we kept the Ruby implementation along with Rust and kept adding feature flags).&lt;/p&gt;
&lt;h2 id=&quot;performance-improvements&quot;&gt;Performance Improvements&lt;/h2&gt;
&lt;p&gt;When moving more larger chunks of code into Rust, we noticed increased performance improvements which we were carefully monitoring. When moving smaller modules to Rust, we didn‚Äôt expect much improvement: in fact, some code became slower because it was being called in tight loops, and there was a small overhead to calling Rust code from the Ruby application.&lt;/p&gt;
&lt;h3 id=&quot;performance-numbers&quot;&gt;Performance numbers&lt;/h3&gt;
&lt;p&gt;In the Dispatcher, there are 3 main phases of the dispatch cycle:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;loading data&lt;/li&gt;
&lt;li&gt;running computation, calculating assignments&lt;/li&gt;
&lt;li&gt;saving/sending assignments&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;Loading data and saving data phases scale pretty much linearly depending on the dataset size, while the computation phase (which we moved to Rust) has an higher-order polynomial component in it. We are less worried about the loading/saving data phases, and we didn‚Äôt prioritise speeding up those phases yet. While loading data and sending data back were still parts of the Dispatcher written in Ruby, the total dispatch time was significantly reduced: for example, in one of our larger zones it dropped from ~4 sec to 0.8 sec.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://deliveroo.engineering/images/posts/moving-from-ruby-to-rust/total_dispatch_time.png&quot; alt=&quot;Total dispatch time&quot;/&gt;&lt;/p&gt;
&lt;p&gt;Out of those 0.8 seconds, roughly 0.2 seconds were spent in Rust, in the computation phase. This means 0.6 second is a Ruby/DB overhead of loading data and sending assignments to riders. It looks like the dispatch cycle is only 5 times quicker now, but actually, the computation phase in this example time was reduced from ~3.4sec to 0.2sec, which is a 17x speedup.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://deliveroo.engineering/images/posts/moving-from-ruby-to-rust/computation_time.png&quot; alt=&quot;Computation phase time&quot;/&gt;&lt;/p&gt;
&lt;p&gt;Keep in mind, that Rust code is almost a 1:1 copy of the Ruby code in terms of the implementation, and we didn‚Äôt add any additional optimisations (like caching, avoiding copying memory in some cases), so there is still room for improvement.&lt;/p&gt;
&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;Our project was successful: moving from Ruby to Rust was a success that dramatically sped up our dipatch process, and gave us more head-room in which we could try implementing more advanced algorithms.&lt;/p&gt;
&lt;p&gt;The gradual migration and careful feature flagging mitigated most of the risks of the project. We were able to deliver it in smaller, incremental parts, just like any other feature that we normally build in Deliveroo.&lt;/p&gt;
&lt;p&gt;Rust has shown a great performance and the absence of runtime made it easy to use it as a replacement of C in building Ruby native extensions.&lt;/p&gt;
&lt;hr/&gt;&lt;div class=&quot;about-author&quot; readability=&quot;9&quot;&gt;
&lt;h3&gt;About Andrii Dmytrenko&lt;/h3&gt;
&lt;img src=&quot;https://deliveroo.engineering/images/portraits/andrii-dmytrenko.jpg&quot; alt=&quot;A picture of Andrii Dmytrenko&quot; class=&quot;portrait&quot;/&gt;&lt;p&gt;Software Engineer from Ukraine&lt;/p&gt;
&lt;p&gt;I enjoy coding in Ru[st|by]&lt;/p&gt;
&lt;/div&gt;
</description>
<pubDate>Thu, 14 Feb 2019 21:06:14 +0000</pubDate>
<dc:creator>steveklabnik</dc:creator>
<og:title>Moving from Ruby to Rust</og:title>
<og:description>How we migrated our Tier 1 service from ruby to rust and didn‚Äôt break production.</og:description>
<og:url>http://deliveroo.engineering/2019/02/14/moving-from-ruby-to-rust.html</og:url>
<og:image>http://deliveroo.engineering/images/og-deliveroo-engineering.png</og:image>
<og:type>article</og:type>
<dc:format>text/html</dc:format>
<dc:identifier>https://deliveroo.engineering/2019/02/14/moving-from-ruby-to-rust.html</dc:identifier>
</item>
<item>
<title>Regulate Facebook and Twitter? The Case Is Getting Stronger</title>
<link>https://www.bloomberg.com/opinion/articles/2019-02-14/regulating-facebook-twitter-and-instagram</link>
<guid isPermaLink="true" >https://www.bloomberg.com/opinion/articles/2019-02-14/regulating-facebook-twitter-and-instagram</guid>
<description>[unable to retrieve full-text content]
&lt;p&gt;Article URL: &lt;a href=&quot;https://www.bloomberg.com/opinion/articles/2019-02-14/regulating-facebook-twitter-and-instagram&quot;&gt;https://www.bloomberg.com/opinion/articles/2019-02-14/regulating-facebook-twitter-and-instagram&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Comments URL: &lt;a href=&quot;https://news.ycombinator.com/item?id=19165286&quot;&gt;https://news.ycombinator.com/item?id=19165286&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Points: 223&lt;/p&gt;
&lt;p&gt;# Comments: 194&lt;/p&gt;
</description>
<pubDate>Thu, 14 Feb 2019 19:47:33 +0000</pubDate>
<dc:creator>pseudolus</dc:creator>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.bloomberg.com/tosv2.html?vid=&amp;uuid=f5ee9a70-313a-11e9-a9d0-3df68dddc998&amp;url=L29waW5pb24vYXJ0aWNsZXMvMjAxOS0wMi0xNC9yZWd1bGF0aW5nLWZhY2Vib29rLXR3aXR0ZXItYW5kLWluc3RhZ3JhbQ==</dc:identifier>
</item>
<item>
<title>RISC-V on the Verge of Broad Adoption</title>
<link>https://www.eetimes.com/document.asp?doc_id=1334311</link>
<guid isPermaLink="true" >https://www.eetimes.com/document.asp?doc_id=1334311</guid>
<description>[unable to retrieve full-text content]
&lt;p&gt;Article URL: &lt;a href=&quot;https://www.eetimes.com/document.asp?doc_id=1334311&quot;&gt;https://www.eetimes.com/document.asp?doc_id=1334311&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Comments URL: &lt;a href=&quot;https://news.ycombinator.com/item?id=19164491&quot;&gt;https://news.ycombinator.com/item?id=19164491&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Points: 287&lt;/p&gt;
&lt;p&gt;# Comments: 124&lt;/p&gt;
</description>
<pubDate>Thu, 14 Feb 2019 18:35:51 +0000</pubDate>
<dc:creator>childintime</dc:creator>
<dc:identifier>https://www.eetimes.com/document.asp?doc_id=1334311</dc:identifier>
</item>
<item>
<title>Winning the Blackbird Battle</title>
<link>https://blog.cloudflare.com/winning-the-blackbird-battle/</link>
<guid isPermaLink="true" >https://blog.cloudflare.com/winning-the-blackbird-battle/</guid>
<description>&lt;img src=&quot;https://blog.cloudflare.com/content/images/2019/02/Blackbird-Courthouse.jpg&quot; class=&quot;kg-image&quot;/&gt;&lt;a href=&quot;http://www.cafc.uscourts.gov/the-court/gallery&quot;&gt;US Court of Appeals for the Federal Circuit&lt;/a&gt;&lt;p&gt;Frequent readers of the Cloudflare blog are aware of the efforts we‚Äôve undertaken in response to &lt;a href=&quot;https://blog.cloudflare.com/standing-up-to-a-dangerous-new-breed-of-patent-troll/&quot;&gt;our first encounter with a patent troll&lt;/a&gt;. We‚Äôre happy to report that on Wednesday, the U.S. Court of Appeals for the Federal Circuit issued an opinion affirming a lower court decision dismissing the case brought by Blackbird Tech. This is the last step in the process &lt;sup&gt;&lt;a href=&quot;https://blog.cloudflare.com/winning-the-blackbird-battle/#footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;, we‚Äôve won.&lt;/p&gt;
&lt;img src=&quot;https://blog.cloudflare.com/content/images/2019/02/IdioticFarflungBluebottle-size_restricted.gif&quot; class=&quot;kg-image&quot;/&gt;&lt;p&gt;In addition to vigorously opposing this case in court, we created and sponsored &lt;a href=&quot;https://blog.cloudflare.com/project-jengo/&quot;&gt;Project Jengo&lt;/a&gt; to push back against the incentives that empower patent trolls like Blackbird Tech. Now that the case is over, we will be wrapping up Project Jengo and will report back with a summary of the Project‚Äôs successes in the near future.&lt;/p&gt;
&lt;p&gt;But before we move on from the litigation, I want to share a few reflections on this case.&lt;/p&gt;
&lt;p&gt;We &lt;a href=&quot;https://blog.cloudflare.com/standing-up-to-a-dangerous-new-breed-of-patent-troll/&quot;&gt;noted&lt;/a&gt; from the very beginning: ‚ÄúThe infringement claim is not a close one ‚Ä¶ if the ‚Äò335 patent is read broadly enough to cover our system (which shouldn‚Äôt happen), it would also cover any system where electronic communications are examined and redacted or modified.‚Äù&lt;/p&gt;
&lt;img src=&quot;https://blog.cloudflare.com/content/images/2019/02/Troll-Hunter.png&quot; class=&quot;kg-image&quot;/&gt;&lt;p&gt;Our initial observation, which we thought was obvious, was borne out. And we were able to prevail on our arguments as swiftly and cleanly as is possible in the federal court system. The U.S. District Court resolved the case on a motion to dismiss, meaning the court didn‚Äôt even consider the factual circumstances of the case, but looked at the face of the complaint and the language of the patent itself and determined that the claims in the patent were too vague to allow anyone to enforce it. It was so obvious to the court that Judge Chabbria‚Äôs decision was little more than a single page. You can read our discussion of the lower court decision in a &lt;a href=&quot;https://blog.cloudflare.com/bye-bye-blackbird/&quot;&gt;previous blog&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Yet Blackbird appealed that dismissal to the U.S. Court of Appeals for the Federal Circuit, a specialized court based in Washington, DC that hears appeals of all patent cases. A panel of three judges from that court heard arguments on the appeal last Friday, but didn‚Äôt ask our attorney a single question about the substance of our argument on the abstractness of the patent. He sat down with almost half of his 15 minutes of argument time left because there was nothing more to say. Yesterday, just three business days after that hearing, the court affirmed the lower court‚Äôs decision in summary fashion, which means they didn‚Äôt even write about the claims or arguments, they just said ‚ÄúAffirmed‚Äù (see below). ¬†&lt;/p&gt;
&lt;p&gt;If it were a boxing match, it would have been called by the referee in the first minute of the first round after three knockdowns. It was easy and painless, right? ¬†&lt;/p&gt;
&lt;p&gt;Not at all. ¬†&lt;/p&gt;
&lt;p&gt;Blackbird filed this case in March 16, 2017. For nearly two years, anyone doing due diligence on Cloudflare might have had questions about whether there was a cloud over our rights to our technology. And we had to go through a lot of briefing, and the related legal expenses, to get to this point. Blackbird‚Äôs combined legal filings at the district court and appellate court amounted to more than 650 pages, our responsive briefs were more than 900 pages.&lt;/p&gt;
&lt;p&gt;The two courts spent less than two pages describing a result that was obvious to them, but it took us two years of uncertainty and cost to get there. Federal court litigation doesn‚Äôt make anything easy. Even if Blackbird had won the case, it is not clear they would have been able to collect significant damages. Our allegedly infringing use was not a product or feature that we charged for or made money from ‚Äì it was essentially posting interstitial messages for various errors. Even though we were able to win this case early in the legal process and keep our costs as low as possible, it‚Äôs possible we spent more money resolving this matter than Blackbird would have been able to collect from us after trial.&lt;/p&gt;
&lt;p&gt;This is the dysfunction that makes patent trolling possible. It is why the option for a quick settlement, in the short term, is always so appealing to parties sued by patent trolls. It‚Äôs why we exerted efforts on &lt;a href=&quot;https://blog.cloudflare.com/project-jengo-celebrates-one-year-anniversary/&quot;&gt;Project Jengo&lt;/a&gt; to try and change the long-term calculus and help out others in the community who may soon find themselves in a similar predicament. ¬†&lt;/p&gt;
&lt;p&gt;A final note‚Ä¶&lt;/p&gt;
&lt;p&gt;Anthony Garza and Steven Callahan of Charhon Callahan Robson &amp;amp; Garza, a litigation boutique in Dallas, are great lawyers. They provided exceptional counseling, perfect legal work, and strong arguments at every step of this process. In every hearing, I was extremely happy that Anthony was the lawyer on our side -- he demonstrated complete control of both the relevant legal authorities and the intricate details of the patent and its various claims. He had the advantage of being right, but he never left any doubt who was making the better argument. ¬†My thanks for their hard work and guidance.&lt;/p&gt;
&lt;img src=&quot;https://blog.cloudflare.com/content/images/2019/02/Judgment-Page-1-1.png&quot; class=&quot;kg-image&quot;/&gt;&lt;img src=&quot;https://blog.cloudflare.com/content/images/2019/02/Judgment-Page-2-1.png&quot; class=&quot;kg-image&quot;/&gt;&lt;img src=&quot;https://blog.cloudflare.com/content/images/2019/02/Judgment-Page-3-1.png&quot; class=&quot;kg-image&quot;/&gt;&lt;h6 id=&quot;footnote&quot;&gt;Footnote&lt;/h6&gt;
&lt;p&gt;&lt;em&gt;&lt;small&gt;[1] Yes, I am aware that Blackbird could seek discretionary review of this decision at the U.S. Supreme Court. But the Supreme Court accepts less than 5% of the cases presented to it, so there isn‚Äôt even a request to that court in most cases unless the case is particularly significant or reflects a disagreement among federal courts. I don‚Äôt reasonably expect they would take this case.&lt;/small&gt;&lt;/em&gt;&lt;/p&gt;
</description>
<pubDate>Thu, 14 Feb 2019 18:15:45 +0000</pubDate>
<dc:creator>jgrahamc</dc:creator>
<og:type>article</og:type>
<og:title>Winning the Blackbird Battle</og:title>
<og:description>We‚Äôre happy to report that on Wednesday, the U.S. Court of Appeals for the Federal Circuit issued an opinion affirming a lower court decision dismissing the case brought by Blackbird Tech. This is the last step in the process, we‚Äôve won.</og:description>
<og:url>https://blog.cloudflare.com/winning-the-blackbird-battle/</og:url>
<og:image>https://blog.cloudflare.com/content/images/2019/02/Blackbird-Courthouse-1.jpg</og:image>
<dc:format>text/html</dc:format>
<dc:identifier>https://blog.cloudflare.com/winning-the-blackbird-battle/</dc:identifier>
</item>
<item>
<title>Ask HN: How to find profitable side project idea?</title>
<link>https://news.ycombinator.com/item?id=19164037</link>
<guid isPermaLink="true" >https://news.ycombinator.com/item?id=19164037</guid>
<description>&lt;tr readability=&quot;0.55737704918033&quot;&gt;&lt;td bgcolor=&quot;#FF6600&quot;&gt;
&lt;/td&gt;
&lt;/tr&gt;&lt;tr id=&quot;pagespace&quot; title=&quot;Ask HN: How to find profitable side project idea?&quot;&gt;&lt;td/&gt;
&lt;/tr&gt;&lt;tr readability=&quot;7.0239234449761&quot;&gt;&lt;td&gt;
&lt;table class=&quot;fatitem&quot; border=&quot;0&quot; readability=&quot;5.2679425837321&quot;&gt;&lt;tr class=&quot;athing&quot; id=&quot;19164037&quot; readability=&quot;0&quot;&gt;&lt;td align=&quot;right&quot; valign=&quot;top&quot; class=&quot;title&quot;/&gt;
&lt;td valign=&quot;top&quot; class=&quot;votelinks&quot;&gt;
&lt;center&gt;

&lt;/center&gt;
&lt;/td&gt;
&lt;td class=&quot;title&quot;&gt;&lt;a href=&quot;https://news.ycombinator.com/item?id=19164037&quot; class=&quot;storylink&quot;&gt;Ask HN: How to find profitable side project idea?&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;0.72289156626506&quot;&gt;&lt;td colspan=&quot;2&quot;/&gt;
&lt;td class=&quot;subtext&quot;&gt;&lt;span class=&quot;score&quot; id=&quot;score_19164037&quot;&gt;327 points&lt;/span&gt; by &lt;a href=&quot;https://news.ycombinator.com/user?id=adamfaliq&quot; class=&quot;hnuser&quot;&gt;adamfaliq&lt;/a&gt; &lt;span class=&quot;age&quot;&gt;&lt;a href=&quot;https://news.ycombinator.com/item?id=19164037&quot;&gt;22 hours ago&lt;/a&gt;&lt;/span&gt; &lt;span id=&quot;unv_19164037&quot;/&gt; | &lt;a href=&quot;https://news.ycombinator.com/hide?id=19164037&amp;amp;goto=item%3Fid%3D19164037&quot;&gt;hide&lt;/a&gt; | &lt;a href=&quot;https://hn.algolia.com/?query=Ask%20HN%3A%20How%20to%20find%20profitable%20side%20project%20idea%3F&amp;amp;sort=byDate&amp;amp;dateRange=all&amp;amp;type=story&amp;amp;storyText=false&amp;amp;prefix&amp;amp;page=0&quot; class=&quot;hnpast&quot;&gt;past&lt;/a&gt; | &lt;a href=&quot;https://duckduckgo.com/?q=Ask%20HN%3A%20How%20to%20find%20profitable%20side%20project%20idea%3F&quot;&gt;web&lt;/a&gt; | &lt;a href=&quot;https://news.ycombinator.com/fave?id=19164037&amp;amp;auth=c332d5a2293ac824d9703da5cbe2a4f3e6ef66a4&quot;&gt;favorite&lt;/a&gt; | &lt;a href=&quot;https://news.ycombinator.com/item?id=19164037&quot;&gt;170¬†comments&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td/&gt;
&lt;/tr&gt;&lt;tr readability=&quot;15.5&quot;&gt;&lt;td colspan=&quot;2&quot;/&gt;
&lt;td readability=&quot;18&quot;&gt;Hi there HNers,
&lt;p&gt;Last summer I worked on a startup as lead developer. I learnt about running a startup and talking to users while working there. I have now quit working there to focus on my studies (second year university in London).&lt;/p&gt;
&lt;p&gt;I would like to work on a side project that eventually would lead to some revenues this summer. My question is, how did you find problem(s) to solve ?&lt;/p&gt;
&lt;p&gt;I have read books and blogs suggesting that the best problem is the one that I have faced before. I find it difficult to do this when almost every problem that I found, there has always been existing solution or the solution can be solved with some quick searches.&lt;/p&gt;
&lt;p&gt;Any idea or thought is really appreciated. Thank you.&lt;/p&gt;
&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td/&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td colspan=&quot;2&quot;/&gt;
&lt;td&gt;

&lt;/td&gt;
&lt;/tr&gt;&lt;/table&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;0.73972602739726&quot;&gt;&lt;td&gt;&lt;img src=&quot;https://news.ycombinator.com/s.gif&quot; height=&quot;10&quot; width=&quot;0&quot;/&gt;&lt;br/&gt;&lt;center&gt;&lt;a href=&quot;https://www.ycombinator.com/apply/&quot;&gt;Applications are open for YC Summer 2019&lt;/a&gt;&lt;/center&gt;
&lt;br/&gt;&lt;center&gt;&lt;span class=&quot;yclinks&quot;&gt;&lt;a href=&quot;https://news.ycombinator.com/newsguidelines.html&quot;&gt;Guidelines&lt;/a&gt; | &lt;a href=&quot;https://news.ycombinator.com/newsfaq.html&quot;&gt;FAQ&lt;/a&gt; | &lt;a href=&quot;mailto:hn@ycombinator.com&quot;&gt;Support&lt;/a&gt; | &lt;a href=&quot;https://github.com/HackerNews/API&quot;&gt;API&lt;/a&gt; | &lt;a href=&quot;https://news.ycombinator.com/security.html&quot;&gt;Security&lt;/a&gt; | &lt;a href=&quot;https://news.ycombinator.com/lists&quot;&gt;Lists&lt;/a&gt; | &lt;a href=&quot;https://news.ycombinator.com/bookmarklet.html&quot; rel=&quot;nofollow&quot;&gt;Bookmarklet&lt;/a&gt; | &lt;a href=&quot;http://www.ycombinator.com/legal/&quot;&gt;Legal&lt;/a&gt; | &lt;a href=&quot;http://www.ycombinator.com/apply/&quot;&gt;Apply to YC&lt;/a&gt; | &lt;a href=&quot;mailto:hn@ycombinator.com&quot;&gt;Contact&lt;/a&gt;&lt;/span&gt;
&lt;/center&gt;
&lt;/td&gt;
&lt;/tr&gt;</description>
<pubDate>Thu, 14 Feb 2019 17:52:44 +0000</pubDate>
<dc:creator>adamfaliq</dc:creator>
<dc:format>text/html</dc:format>
<dc:identifier>https://news.ycombinator.com/item?id=19164037</dc:identifier>
</item>
<item>
<title>The Unreasonable Effectiveness of Deep Feature Extraction</title>
<link>http://www.basilica.ai/blog/the-unreasonable-effectiveness-of-deep-feature-extraction/</link>
<guid isPermaLink="true" >http://www.basilica.ai/blog/the-unreasonable-effectiveness-of-deep-feature-extraction/</guid>
<description>&lt;h2&gt;The Unreasonable Effectiveness of&lt;br/&gt;Deep Feature Extraction&lt;/h2&gt;
&lt;p&gt;There have been a small handful of times in my life where I've read the abstract of a paper -- thought about it for a few moments -- and then audibly exclaimed &quot;Oh shit!&quot;.&lt;/p&gt;
&lt;p&gt;Reading my first paper on deep feature extraction, back in 2014, was one of those times. The results from back then were amazing, and they've only gotten more impressive since.&lt;/p&gt;
&lt;p&gt;But let's start at the beginning. Back in 2014, deep learning was producing impressive results, but was still in its awkward adolescent period. Tensorflow was about a year away from being released, and for most people, myself included, deep learning felt very far away. I didn't have a dataset with millions of images, or a GPU cluster to train on. What did I need deep learning for?&lt;/p&gt;
&lt;p&gt;Then, I encountered &lt;a href=&quot;https://arxiv.org/pdf/1403.6382.pdf&quot;&gt;CNN Features off-the-shelf: an Astounding Baseline for Recognition&lt;/a&gt; by Razavian et al. I'm sure it isn't the first paper on the topic, or even the most well-known, but it's the one I encountered. To summarize, they took a deep neural network (&lt;a href=&quot;https://arxiv.org/pdf/1312.6229.pdf&quot;&gt;OverFeat&lt;/a&gt;), pretrained it on millions of images (&lt;a href=&quot;http://image-net.org/challenges/LSVRC/2013/&quot;&gt;ImageNet&lt;/a&gt;, and then repurposed it as a feature extractor.&lt;/p&gt;
&lt;p&gt;If you haven't heard the term before, pretraining is when you train a network on a big dataset that's different than the dataset you're actually interested in. It's a form a of transfer learning -- a way of learning how to solve one problem, and using that knowledge to perform better on a second problem. A feature extractor is anything that takes in data and spits out a set of numbers that describe the important parts of it, in the same way a tailor might describe your shape with a small set of measurements.&lt;/p&gt;
&lt;p&gt;Once they had this feature extractor, they fed images from smaller datasets into it, and then fed the resulting features into an support-vector machine, a very simple model that's existed since the 90s. Basically, the OverFeat network was used to preprocess images so that they could be modeled using well-known ML tools, like a mother bird regurgitating partially-digested food for her young.&lt;/p&gt;
&lt;p&gt;Doing this outperformed the existing state of the art in about a dozen tasks, many of which diverged wildly from the neural network's original input distribution. Performing well on highly-divergent inputs is a big deal. It's obvious that if you train a network on one problem, it will perform well on similar problems. But the network they'd trained on ImageNet, learning things like how to distinguish dogs from strawberries, worked well as a feature extractor for things like the &lt;a href=&quot;http://www.robots.ox.ac.uk/~vgg/data/flowers/&quot;&gt;Oxford Flowers&lt;/a&gt; dataset, where it has to make fine-grained distinctions between different types of flowers.&lt;/p&gt;
&lt;p&gt;Performing well on highly-divergent inputs means you've found a &lt;em&gt;general&lt;/em&gt; technique. In the authors' words: &quot;The results strongly suggest that features obtained from deep learning with convolutional nets should be the primary candidate in most visual recognition tasks.&quot;&lt;/p&gt;
&lt;p&gt;This was the &quot;oh shit!&quot; moment for me. Any time someone finds a general technique that outperforms something hand-tuned by experts, it's pretty exciting. When that general technique works across a dozen different tasks, it's even more exciting.&lt;/p&gt;
&lt;p&gt;But here's what really caught my attention: it was something I could actually &lt;em&gt;use&lt;/em&gt;. All I needed to do was download a pretrained deep convolutional net, and I could expect the features it extracted to work pretty well on whatever problem I had. Before reading this paper, I thought of &quot;deep learning&quot; as &quot;training a neural network from scratch&quot;. I usually didn't have a big enough dataset to do that, and even if I did, I didn't have access to the sort of specialized hardware that would let me do it quickly.&lt;/p&gt;
&lt;p&gt;But suddenly, I didn't need a million images to train on. I just needed a few thousand to run through the pretrained network and feed into a support-vector machine. I didn't need a GPU cluster. I could do it all on my laptop CPU, if I was willing to wait a while for the feature extraction to run.&lt;/p&gt;
&lt;p&gt;After reading this, deep learning didn't feel so far away any more.&lt;/p&gt;

&lt;p&gt;How does one actually repurpose a pretrained neural network as a feature extractor? Fortunately, doing the simplest possible thing works really well.&lt;/p&gt;
&lt;p&gt;As you probably already know, a deep neural network consists of a series of layers. The word &quot;layer&quot; usually refers to a big linear transformation, followed by a non-linear function called an activation. (A common activation is &lt;a href=&quot;http://www.cs.toronto.edu/~fritz/absps/reluICML.pdf&quot;&gt;ReLu&lt;/a&gt;, which is just &lt;code&gt;f(x) = max(x, 0)&lt;/code&gt;.) The outputs of the activation function are called the &quot;activations&quot; of the layer, and they're what get fed into the next layer.&lt;/p&gt;
&lt;p&gt;To turn a pretrained deep neural network into a feature extractor, you pick a layer toward the end of the network, feed in the image you want to extract features from, and then use the activations of that layer as features. It's sometimes helpful to do a little bit of post-processing, but once you have the activations of your chosen layer, you're basically done.&lt;/p&gt;
&lt;p&gt;Calling this vector of floats yanked from the inside of a neural network &quot;features&quot; might seem strange, since they don't have an obvious meaning. But they're features in the most important sense of the word, because you can use them to train a model that makes accurate predictions.&lt;/p&gt;
&lt;p&gt;I was confused for a long time about why this works as well as it does. Why would you expect the intermediate state of a neural network to produce features that are good for training traditional ML models?&lt;/p&gt;
&lt;p&gt;It turns out that you can &lt;a href=&quot;https://distill.pub/2017/feature-visualization/&quot;&gt;visualize&lt;/a&gt; what images correspond to a specific extracted feature. If you do, you see that the activations of late layers are capturing very high-level semantic concepts like eyes and clothing. (Activations of earlier layers tend to capture lower-level concepts like horizontal edges or blobs of color.)&lt;/p&gt;
&lt;p&gt;Interestingly, you can also choose an arbitrary linear combination of extracted features, and see what images cause &lt;em&gt;that&lt;/em&gt; to increase. If you do, you find that a surprising number of linear combinations also capture some high-level semantic concept. Essentially, the late layers of the neural network are learning to recognize features that can be linearly recombined to capture high-level semantic properties of the images in the training dataset.&lt;/p&gt;
&lt;p&gt;With that in mind, it kind of makes sense that feeding another dataset into this network produces features which are good for a huge variety of tasks.&lt;/p&gt;
&lt;h4 id=&quot;whatschangedsince2014&quot;&gt;What's changed since 2014?&lt;/h4&gt;
&lt;p&gt;I promised you &quot;unreasonable effectiveness&quot;, but so far all we've seen are a handful of impressive results from half a decade ago. What's happened since then?&lt;/p&gt;
&lt;p&gt;The field has changed a lot. Deep learning tools have improved dramatically, and knowledge on how to use them has spread. GPUs are faster, with more memory. Parallelization techniques have improved. Networks that used to take a month to train can train in days or hours.&lt;/p&gt;
&lt;p&gt;You might think this would make pretrained networks unnecessary, since it's now so much easier to train a deep neural network from scratch. But I find myself relying on deep feature extraction more, not less, as time goes on. It turns out that for most problems, the major limiting factor isn't ease of use -- it's dataset size.&lt;/p&gt;
&lt;p&gt;There's been some &lt;a href=&quot;https://arxiv.org/pdf/1712.00409.pdf&quot;&gt;empirical research&lt;/a&gt; on this, which confirms the unfortunate fact that the error rate of a neural network tends to improve extremely sublinearly with the amount of data used to train it. It also confirms the even more unfortunate fact that most architectual improvements don't change the shape of those curves very much. After a certain point, it takes a &lt;em&gt;lot&lt;/em&gt; of data to meaningfully improve your results.&lt;/p&gt;
&lt;p&gt;But let's focus on a specific example. In 2018, Facebook put out a paper called &lt;a href=&quot;https://arxiv.org/pdf/1805.00932.pdf&quot;&gt;Exploring the Limits of Weakly Supervised Pretraining&lt;/a&gt;. This was the paper that really convinced me of where things are headed, so I want to take a little while to dig into it.&lt;/p&gt;
&lt;p&gt;Back in 2014, ImageNet was a huge dataset. It was common to train on ImageNet, and then transfer that training to another problem. By 2018, ImageNet is considered small, and it's becoming common to train on another dataset and transfer that training to ImageNet.&lt;/p&gt;
&lt;p&gt;At the time of publication, Facebook's paper achieved the best performance ever recorded on ImageNet-1k single-crop top-1 accuracy. The key to these results was pretraining on billions of Instagram images, using the user-provided tags as noisy labels, and increasing the model capacity accordingly.&lt;/p&gt;
&lt;p&gt;Reading this paper was both exciting and discouraging for me. On the one hand, it's exciting that existing techniques seem to scale pretty much indefinitely, just by increasing their capacity and the amount of data available. On the other hand, who has billions of images to train on? Who has the resources to do architecture and hyperparameter search on these enormous models and datasets?&lt;/p&gt;
&lt;p&gt;Buried in the paper, though, is this very important aside:&lt;/p&gt;
&lt;blockquote readability=&quot;10&quot;&gt;
&lt;p&gt;The highest accuracies on val-IN-1k are 83.3% (source: IG-940M-1k) and 83.6% (source: IG-3.5B-17k), both with ResNeXt-101 32√ó16d. These results are obtained by training a linear classifier on fixed features and yet are nearly as good as full network finetuning, demonstrating the effectiveness of the feature representation learned from hashtag prediction.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;(The accuracy of the fully-finetuned network was 84.2%, the accuracy of a linear classifier with deep feature extraction was 83.6%, and the same architecture trained directly on ImageNet got 79.6%.)&lt;/p&gt;
&lt;p&gt;In other words, if you take this huge network pretrained on a billion images, repurpose it as a feature extractor, and use it to train a simple linear model on your dataset -- it's almost as good as finetuning the whole thing. Crucially, it significantly outperforms training a neural network directly on your dataset. &lt;em&gt;Even for a dataset as large as ImageNet.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Unless you have literally the largest dataset in the world, training a neural network on it from scratch will probably give worse results than using a huge pretrained net as a feature extractor and training a simple linear model on that. This is absolutely remarkable, because training a linear model is &lt;em&gt;way&lt;/em&gt; easier. We're talking ten lines of Python to implement, and training times measured in minutes.&lt;/p&gt;
&lt;p&gt;(You could get slightly better results by finetuning the huge pretrained net, and this will be worth it in some cases. But the performance improvement will probably be negligible for dataset sizes in the thousands, and less than a percent for larger datasets like ImageNet.)&lt;/p&gt;

&lt;p&gt;Another thing that's changed since 2014 is that deep feature extraction has sort of been eaten by the concept of embeddings. You might be familiar with word embeddings like Word2vec, which map words from a dictionary to a vector of floats. The idea is actually very general: anything which maps an object in one space to point in a vector space can be called an embedding. Usually the term implies either that the second space is lower-dimensional, or that objects which are similar by some important metric are close together in the second space. (In the case of Word2vec, two words are considered similar if they're used in similar contexts.)&lt;/p&gt;
&lt;p&gt;Deep feature extraction takes in an image, and spits out a vector of floats, so it's clearly an embedding in that sense. It turns out it meets the second property as well; semantically similar images tend to have similar features, so their points in the vector space end up being close together.&lt;/p&gt;
&lt;p&gt;Thinking of deep feature extraction as embedding images into a more tractable space turns out to be a very powerful idea. It lets you think interesting thoughts like &quot;what if I embed two different data types, like images and text, into the &lt;a href=&quot;https://cs224d.stanford.edu/reports/DufourNick.pdf&quot;&gt;same space&lt;/a&gt;?&quot; (The goal, of course, being to cluster points in that space in order to e.g. search for images based on a description.)&lt;/p&gt;
&lt;p&gt;I usually hate switching terminology mid-stream in a post, but you'll see both terms in the wild, and I think the idea of embeddings is important enough to warrant it. &lt;strong&gt;We'll use the term &quot;embedding&quot; from now on.&lt;/strong&gt;&lt;/p&gt;
&lt;h4 id=&quot;wherearethingsheaded&quot;&gt;Where are things headed?&lt;/h4&gt;
&lt;p&gt;There's a growing consensus that deep learning is going to be a centralizing technology rather than a decentralizing one. We seem to be headed toward a world where the only people with enough data and compute to train truly state-of-the-art networks are a handful of large tech companies.&lt;/p&gt;
&lt;p&gt;I think this consensus is probably correct, but that this world is better than it sounds. Right now, most people work in a paradigm where they're given a dataset, and their job is to fit a model on it from scratch. In this paradigm, it's pretty depressing if only a few companies have the data and compute to actually fit the best models from scratch.&lt;/p&gt;
&lt;p&gt;But in the future, I think ML will look more like a tower of transfer learning. You'll have a sequence of models, each of which specializes the previous model, which was trained on a more general task with more data available. If, for example, you want to train a visual similarity model on a catalogue of product images, your future pipeline will probably look something like this:&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;Some giant tech company pretrains a neural network on 1B-1T images.&lt;/li&gt;
&lt;li&gt;Someone else with access to significantly more product images than you finetunes the giant pretrained image network on 1M-1B product images.&lt;/li&gt;
&lt;li&gt;You use the pretrained product image network to embed your product images, and train your model on those embeddings.&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;Now, predicting the future is hard, and that last part is a pretty specific prediction. Why embeddings?&lt;/p&gt;
&lt;p&gt;We already talked about efficacy. Linear models trained on embeddings perform incredibly well. But embeddings have a bunch of other properties which are more important than people realize.&lt;/p&gt;
&lt;h4 id=&quot;embeddingshaveshorttraintestcycles&quot;&gt;Embeddings have short train-test cycles.&lt;/h4&gt;
&lt;p&gt;Models that take a long time to train kill productivity in the same way as long compile times or slow test suites. Real-world data science requires being able to quickly test hypotheses. Does this hand-engineered feature improve my model? Hm, no. What about this one? Maybe I should be normalizing differently? Ooh, maybe my labels are noisy. Does it work on a different dataset I know is clean?&lt;/p&gt;
&lt;p&gt;If you're training a deep neural network, the turnaround time on these questions might be measured in days, and your life will be awful. If you have a big hardware budget, it might be measured in hours, and your life will be merely miserable. A linear model trained on embeddings will often have a turnaround time measured in minutes.&lt;/p&gt;
&lt;h4 id=&quot;embeddingsletyoumixandmatchmodelarchitectures&quot;&gt;Embeddings let you mix and match model architectures&lt;/h4&gt;
&lt;p&gt;Embeddings provide a clean interface between models. You can change the model which produced the embedding, or change the model consuming the embedding, without worrying about the other one.&lt;/p&gt;
&lt;p&gt;Right now, the best image embeddings are produced by deep convolutional nets. But that might not be true forever. Maybe we invent something better in the future. Maybe an old technique makes a comeback, and in ten years we're using genetic algorithms to train image embeddings. If you're using embeddings as the input to a simpler model, your model can benefit from these improvements with as little effort as swapping Word2vec out for ELMo takes today.&lt;/p&gt;
&lt;h4 id=&quot;embeddingsplugdirectlyintoexistingpipelines&quot;&gt;Embeddings plug directly into existing pipelines&lt;/h4&gt;
&lt;p&gt;The biggest thing preventing most companies from adopting deep learning is legacy infrastructure. This is entirely reasonable. If my business depended on a random forest I'd spent five years painstakingly tuning, I'd be reluctant to get rid of it too.&lt;/p&gt;
&lt;p&gt;Embeddings provide an easy way to use deep learning to improve existing models. The features from the embedding can be fed into a traditional model alongside hand-crafted ones. Often the model's accuracy will improve with little or no feature engineering on the embedding.&lt;/p&gt;
&lt;h4 id=&quot;whatstillneedstohappen&quot;&gt;What still needs to happen?&lt;/h4&gt;
&lt;p&gt;All these amazing things we've been talking about -- fast training, good performance on small datasets, tools that work on your laptop, interoperability with existing models -- all of these depend on one thing. Someone has to do the grunt work of putting together giant datasets and training huge networks on them, so that everyone else can make use of the embeddings.&lt;/p&gt;
&lt;p&gt;Researchers today frequently release pretrained networks, but there are a handful of problems with this state of the world:&lt;/p&gt;
&lt;ol readability=&quot;4.5&quot;&gt;&lt;li readability=&quot;1&quot;&gt;
&lt;p&gt;The best pretrained networks are coming out of the big tech companies, and it isn't obvious they'll keep releasing them forever. Today's good PR is tomorrow's competitive advantage.&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;3&quot;&gt;
&lt;p&gt;Running state of the art pretrained networks with reasonable latency requires specialized hardware. A lot less hardware than it takes to train them, to be clear, but you don't want to be doing it on your laptop.&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;2&quot;&gt;
&lt;p&gt;There are good pretrained models available for big research topics, but nobody is training and releasing models specialized for the sorts of data most people work with. There's no good pretrained network for things like product images or typo-filled support requests.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;I'm not sure exactly how to solve those problems. I have a few ideas, but I'll leave them for a future post.&lt;/p&gt;
&lt;p&gt;Even if I'm not sure exactly how to solve them, though, those problems seem very surmountable. I'm basically convinced at this point that embeddings are going to be the main way most data scientists get value out of deep learning, which is really exciting. It's rare to get a convincing-feeling glimpse of the future, and this future seems particularly bright.&lt;/p&gt;
</description>
<pubDate>Thu, 14 Feb 2019 17:23:40 +0000</pubDate>
<dc:creator>hiphipjorge</dc:creator>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.basilica.ai/blog/the-unreasonable-effectiveness-of-deep-feature-extraction/</dc:identifier>
</item>
</channel>
</rss>