<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="css/feed.xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/" xmlns:og="http://ogp.me/ns#">
<channel>
<atom:link rel="self" href="http://192.168.1.4/fivefilters/makefulltextfeed.php?url=hnrss.org%2Fnewest%3Fpoints%3D200&amp;max=10&amp;links=preserve&amp;exc=" />
<atom:link rel="alternate" title="Source URL" href="http://hnrss.org/newest?points=200" />
<atom:link rel="related" title="Subscribe to feed" href="http://www.subtome.com/#/subscribe?feeds=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dhnrss.org%252Fnewest%253Fpoints%253D200%26max%3D10%26links%3Dpreserve%26exc%3D&amp;back=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dhnrss.org%252Fnewest%253Fpoints%253D200%26max%3D10%26links%3Dpreserve%26exc%3D" />
<title>Hacker News: Newest</title>
<link>https://news.ycombinator.com/newest</link>
<description>Hacker News RSS</description>
<item>
<title>I Miss Rails</title>
<link>https://chanind.github.io/rails/2019/03/28/why-i-miss-rails.html</link>
<guid isPermaLink="true" >https://chanind.github.io/rails/2019/03/28/why-i-miss-rails.html</guid>
<description>&lt;p&gt;The world of tech moves fast, and there’s always new frameworks and paradigms popping up that make developers’ lives easier and allow us to build more and more powerful applications. But, these transitions don’t always just make things better for developers - sometimes we take steps backwards and undo the progress we made in the past.&lt;/p&gt;
&lt;p&gt;Now, I know Rails isn’t universally beloved by developers, and I’m not suggesting that we give up React and es7 and go back to writing server-templated web-apps like it’s 2012 again. However, I do think that in the transition to the modern web stack (something like React / nodejs / graphql / etc), we’ve unsolved some of what tools like Rails made easy 10 years ago - and I don’t think it needs to be that way.&lt;/p&gt;
&lt;p&gt;Rails took all the boilerplate that comes with building any web application and make it trivial to implement. Since Rails owned the whole application stack, it was easy for the community to contribute plugins that would add any typical functionality you may need. Do you need user accounts with signup / login / forgot password emails / email confirmation? Install devise and you’re done. Do you want to be able to upload images, resize them, and upload them to s3? Great - install paperclip and you’re done. Need to index your data in elasticsearch or sphinx? Easy - just install a rails plugin to do that. Do you need Google and Facebook login? Cool - install omniauth and you’re done. Do you want to clean up your tests using factories? Install factory-girl and everything just works.&lt;/p&gt;
&lt;p&gt;Compare that to the state of the typical web stack now, with something like a nodejs / typescript graphql backend and React / Apollo on the frontend. There’s no longer a standardized way to get user accounts with a login/signup, forgot password and email confirmation flow, despite every application needing it, so instead we need to spend days rewriting this functionality anew on each project. Users need a way to change their account info? Get ready to spend a day working on a standard account settings page. Want to allow users to upload avatar images? Spend a day writing an image upload, resize, push to s3 flow from scratch. Do you want to add a search engine? Great - spend a day writing the code to index and search your documents from scratch. Need to add Google login? Get ready to spend another day on that.&lt;/p&gt;
&lt;p&gt;All these things that used to be easy in Rails take a fair bit of manual effort today because there’s not a standardized setup and eco-system. We’re spending a lot of time re-solving all these boilerplate issues that every web app needs and everyone has already solved countless times before. Part of this may be inevitable now that there’s both web and mobile frontends to think about, but I think the majority of the problem is just a result of fragmetation in the modern ecosystem. It’s no longer possible to make libraries that automatically handle all the glue code of integration into our apps because there’s no standard setup at all anymore.&lt;/p&gt;
&lt;p&gt;That being said, there are some good attempts at unified frameworks out there. &lt;a href=&quot;https://www.meteor.com/&quot;&gt;Meteor&lt;/a&gt; was the closest the JS world has come to something like Rails, but may have come too early and missed the graphQL / React / Typescript wave. &lt;a href=&quot;https://www.gatsbyjs.org/&quot;&gt;Gatsby&lt;/a&gt; is amazing as well, and is the closest project I’ve seen to what Rails used to provide, but it only generates static sites.&lt;/p&gt;
&lt;p&gt;I’m hopeful that a framework will emerge that can be the Rails of the modern web stack. Gatsby and Meteor show that it’s possible. And if the modern equivalent of Rails already exists, please let me know!&lt;/p&gt;
</description>
<pubDate>Thu, 28 Mar 2019 23:11:10 +0000</pubDate>
<dc:creator>chanind</dc:creator>
<og:title>Why I miss Rails</og:title>
<og:description>The world of tech moves fast, and there’s always new frameworks and paradigms popping up that make developers’ lives easier and allow us to build more and more powerful applications. But, these transitions don’t always just make things better for developers - sometimes we take steps backwards and undo the progress we made in the past.</og:description>
<og:url>https://chanind.github.io/rails/2019/03/28/why-i-miss-rails.html</og:url>
<og:type>article</og:type>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://chanind.github.io/rails/2019/03/28/why-i-miss-rails.html</dc:identifier>
</item>
<item>
<title>Lyft prices IPO at top of range</title>
<link>https://techcrunch.com/2019/03/28/lyft-prices-ipo-at-top-of-range/</link>
<guid isPermaLink="true" >https://techcrunch.com/2019/03/28/lyft-prices-ipo-at-top-of-range/</guid>
<description>&lt;p id=&quot;speakable-summary&quot;&gt;&lt;a class=&quot;crunchbase-link&quot; href=&quot;https://crunchbase.com/organization/lyft&quot; target=&quot;_blank&quot; data-type=&quot;organization&quot; data-entity=&quot;lyft&quot;&gt;Lyft&lt;/a&gt; raised more than $2 billion Thursday afternoon after pricing its shares at $72 apiece, the top of the expected range of $70 to $72 per share. This gives Lyft a fully diluted market value of $24 billion.&lt;/p&gt;
&lt;p&gt;The company will debut on the Nasdaq stock exchange Friday morning, trading under the ticker symbol “LYFT.”&lt;/p&gt;
&lt;p&gt;The initial public offering is the first-ever for a ride-hailing business and represents a landmark liquidity event for private market investors, which had invested billions of dollars in the San Francisco-based company. In total, Lyft had raised $5.1 billion in debt and equity funding, reaching a valuation of $15.1 billion last year.&lt;/p&gt;
&lt;p&gt;Lyft’s blockbuster IPO is unique for a number of reasons, in addition to being amongst transportation-as-a-service companies to transition from private to public. Lyft has the largest net losses of any pre-IPO business, posting losses of $911 million on revenues of $2.2 billion in 2018. However, the company is also raking in the largest revenues, behind only Google and Facebook, for a pre-IPO company. The latter has made it popular on Wall Street, garnering buy ratings from analysts prior to pricing.&lt;/p&gt;
&lt;p&gt;Uber is the next tech unicorn, or company valued north of $1 billion, expected out of the IPO gate. It will trade on the New York Stock Exchange in what is one of the most anticipated IPOs in history. The company, which reported $3 billion in Q4 2018 revenues with net losses of $865 million, is reportedly planning to &lt;a href=&quot;https://techcrunch.com/2019/03/14/uber-will-reportedly-file-for-ipo-next-month/&quot;&gt;unveil its IPO prospectus&lt;/a&gt; next month.&lt;/p&gt;
&lt;p&gt;Next in the pipeline is Pinterest, which &lt;a href=&quot;https://techcrunch.com/2019/03/22/pinterest-drops-its-ipo-filing/&quot;&gt;dropped its S-1&lt;/a&gt; last week and revealed a path to profitability that is sure to garner support from Wall Street investors. The visual search engine will trade on the NYSE under the symbol “PINS.” It posted revenue of $755.9 million last year, up from $472.8 million in 2017. The company’s net loss, meanwhile, shrank to $62.9 million last year from $130 million in 2017.&lt;/p&gt;
&lt;p&gt;Other notable companies planning 2019 stock offerings include Slack, Zoom — &lt;a href=&quot;https://techcrunch.com/2019/03/22/zoom-a-profitable-unicorn-files-to-go-public/&quot;&gt;a rare, profitable pre-IPO unicorn&lt;/a&gt; — and, potentially, Airbnb.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Updating&lt;/em&gt;.&lt;/p&gt;

</description>
<pubDate>Thu, 28 Mar 2019 21:48:16 +0000</pubDate>
<dc:creator>jkw</dc:creator>
<og:title>Lyft prices IPO at top of range</og:title>
<og:description>Lyft begins trading on the Nasdaq under the ticker symbol &quot;LYFT&quot; tomorrow.</og:description>
<og:image>https://techcrunch.com/wp-content/uploads/2019/03/GettyImages-909455640.jpg?w=600</og:image>
<og:url>http://social.techcrunch.com/2019/03/28/lyft-prices-ipo-at-top-of-range/</og:url>
<og:type>article</og:type>
<dc:language>en-US</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://techcrunch.com/2019/03/28/lyft-prices-ipo-at-top-of-range/</dc:identifier>
</item>
<item>
<title>An amphibian fungus has become “the most deadly pathogen known”</title>
<link>https://www.nytimes.com/2019/03/28/science/frogs-fungus-bd.html</link>
<guid isPermaLink="true" >https://www.nytimes.com/2019/03/28/science/frogs-fungus-bd.html</guid>
<description>&lt;div class=&quot;css-1fanzo5 StoryBodyCompanionColumn&quot;&gt;
&lt;div class=&quot;css-53u6y8&quot;&gt;
&lt;p class=&quot;css-1ygdjhk evys1bk0&quot;&gt;On Thursday, 41 scientists published the first worldwide analysis of a fungal outbreak that’s been wiping out frogs for decades. The devastation &lt;a class=&quot;css-1g7m0tk&quot; href=&quot;http://science.sciencemag.org/cgi/doi/10.1126/science.aav0379&quot; title=&quot;&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;turns out to be far worse than anyone had previously realized&lt;/a&gt;.&lt;/p&gt;
&lt;p class=&quot;css-1ygdjhk evys1bk0&quot;&gt;Writing in the journal Science, the researchers conclude that populations of more than 500 species of amphibians have declined significantly because of the outbreak — including at least 90 species presumed to have gone extinct. The figure is more than twice as large as earlier estimates.&lt;/p&gt;
&lt;p class=&quot;css-1ygdjhk evys1bk0&quot;&gt;“That’s fairly seismic,” said Wendy Palen, a biologist at Simon Fraser University who is a co-author of &lt;a class=&quot;css-1g7m0tk&quot; href=&quot;http://science.sciencemag.org/cgi/doi/10.1126/science.aax0002&quot; title=&quot;&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;a commentary accompanying the study&lt;/a&gt;. “It now earns the moniker of the most deadly pathogen known to science.”&lt;/p&gt;
&lt;p class=&quot;css-1ygdjhk evys1bk0&quot;&gt;&lt;strong class=&quot;css-8qgvsz ebyp5n10&quot;&gt;&lt;em class=&quot;css-2fg4z9 e1gzwzxm0&quot;&gt;[&lt;/em&gt;&lt;/strong&gt;&lt;strong class=&quot;css-8qgvsz ebyp5n10&quot;&gt;&lt;a class=&quot;css-1g7m0tk&quot; href=&quot;http://on.fb.me/1paTQ1h&quot; title=&quot;&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;&lt;em class=&quot;css-2fg4z9 e1gzwzxm0&quot;&gt;Like the Science Times page on Facebook.&lt;/em&gt;&lt;/a&gt;&lt;/strong&gt; &lt;em class=&quot;css-2fg4z9 e1gzwzxm0&quot;&gt;| Sign up for the&lt;/em&gt; &lt;strong class=&quot;css-8qgvsz ebyp5n10&quot;&gt;&lt;a class=&quot;css-1g7m0tk&quot; href=&quot;http://nyti.ms/1MbHaRU&quot; title=&quot;&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;&lt;em class=&quot;css-2fg4z9 e1gzwzxm0&quot;&gt;Science Times newsletter.&lt;/em&gt;&lt;/a&gt;&lt;/strong&gt;&lt;strong class=&quot;css-8qgvsz ebyp5n10&quot;&gt;&lt;em class=&quot;css-2fg4z9 e1gzwzxm0&quot;&gt;]&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p class=&quot;css-1ygdjhk evys1bk0&quot;&gt;Scientists first noticed in the 1970s that some frog populations were declining quickly; by the 1980s, some species appeared to be extinct. The losses were puzzling, because the frogs were living in pristine habitats, unharmed by pollution or deforestation.&lt;/p&gt;
&lt;/div&gt;
&lt;aside class=&quot;css-o6xoe7&quot;/&gt;&lt;/div&gt;&lt;div class=&quot;css-1fanzo5 StoryBodyCompanionColumn&quot;&gt;
&lt;div class=&quot;css-53u6y8&quot;&gt;
&lt;p class=&quot;css-1ygdjhk evys1bk0&quot;&gt;In the late 1990s, researchers discovered that frogs in both Australia and Panama &lt;a class=&quot;css-1g7m0tk&quot; href=&quot;https://www.pnas.org/content/95/15/9031&quot; title=&quot;&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;were infected with a deadly fungus&lt;/a&gt;, which they named Batrachochytrium dendrobatidis &lt;em class=&quot;css-2fg4z9 e1gzwzxm0&quot;&gt;—&lt;/em&gt; Bd, for short.&lt;/p&gt;
&lt;p class=&quot;css-1ygdjhk evys1bk0&quot;&gt;The fungus turned up in other countries, but studies of its DNA suggest that Bd &lt;a class=&quot;css-1g7m0tk&quot; href=&quot;https://www.nytimes.com/2018/05/10/science/frogs-fungus-korea.html?module=inline&quot; title=&quot;&quot;&gt;originated on the Korean Peninsula&lt;/a&gt;. In Asia, amphibians seem impervious to Bd, but when it got to other parts of the world — probably via the international trade in pet amphibians — the pathogen reached hundreds of vulnerable species.&lt;/p&gt;
&lt;p class=&quot;css-1ygdjhk evys1bk0&quot;&gt;Amphibians are infected with Bd by contact with other animals or by spores floating in the water. The fungus invades skin cells and multiplies. An infected frog’s skin will start to peel away as the animal grows sluggish. Before it dies, a frog may manage to hop its way to a new stream or pond, spreading the fungus further.&lt;/p&gt;
&lt;p class=&quot;css-1ygdjhk evys1bk0&quot;&gt;In 2007, researchers speculated that Bd &lt;a class=&quot;css-1g7m0tk&quot; href=&quot;https://link.springer.com/article/10.1007/s10393-007-0093-5&quot; title=&quot;&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;might be responsible for all known declines of frogs&lt;/a&gt; that had no other apparent cause — about 200 species. For the most part, however, scientists studied Bd at the local level, looking at its impacts on particular species in particular places.&lt;/p&gt;
&lt;p class=&quot;css-1ygdjhk evys1bk0&quot;&gt;“We knew that frogs were dying all around the world, but no one had gone back to the start and actually assessed what the impact was,” said Benjamin Scheele, an ecologist at Australian National University and the lead author of the new study.&lt;/p&gt;
&lt;/div&gt;
&lt;aside class=&quot;css-o6xoe7&quot;/&gt;&lt;/div&gt;
&lt;div class=&quot;css-1fanzo5 StoryBodyCompanionColumn&quot;&gt;
&lt;div class=&quot;css-53u6y8&quot;&gt;
&lt;p class=&quot;css-1ygdjhk evys1bk0&quot;&gt;In 2015, Dr. Scheele and his colleagues gathered data from over 1,000 published papers on Bd, and traveled around the world to meet with experts and hear their unpublished observations.&lt;/p&gt;
&lt;p class=&quot;css-1ygdjhk evys1bk0&quot;&gt;Not only did the team analyze data on living amphibians, but they also looked at data from museums, where scientists found Bd DNA embedded in preserved specimens tucked away in cabinets.&lt;/p&gt;
&lt;p class=&quot;css-1ygdjhk evys1bk0&quot;&gt;The new study showed that some amphibians are at greater risk than others.&lt;/p&gt;
&lt;p class=&quot;css-1ygdjhk evys1bk0&quot;&gt;The fungus thrives in cool, moist conditions. As a result, frogs that live in cloud forests on mountainsides have been hit particularly hard.&lt;/p&gt;
&lt;/div&gt;
&lt;aside class=&quot;css-o6xoe7&quot;/&gt;&lt;/div&gt;
&lt;div data-testid=&quot;photoviewer-wrapper&quot; class=&quot;css-79elbk ehw59r11&quot;&gt;

&lt;div data-testid=&quot;photoviewer-children&quot; class=&quot;css-1a48zt4 ehw59r111&quot;&gt;
&lt;div class=&quot;css-1xdhyk6 erfvjey0&quot;&gt;&lt;span class=&quot;css-1ly73wi e1tej78p0&quot;&gt;Image&lt;/span&gt;&lt;img alt=&quot;&quot; class=&quot;css-1m50asq&quot; src=&quot;https://static01.nyt.com/images/2019/03/28/science/28SCI-ZIMMER/28SCI-ZIMMER-articleLarge.jpg?quality=75&amp;amp;auto=webp&amp;amp;disable=upscale&quot; srcset=&quot;https://static01.nyt.com/images/2019/03/28/science/28SCI-ZIMMER/28SCI-ZIMMER-articleLarge.jpg?quality=90&amp;amp;auto=webp 600w,https://static01.nyt.com/images/2019/03/28/science/28SCI-ZIMMER/28SCI-ZIMMER-jumbo.jpg?quality=90&amp;amp;auto=webp 1024w,https://static01.nyt.com/images/2019/03/28/science/28SCI-ZIMMER/28SCI-ZIMMER-superJumbo.jpg?quality=90&amp;amp;auto=webp 1644w&quot; sizes=&quot;((min-width: 600px) and (max-width: 1004px)) 84vw, (min-width: 1005px) 60vw, 100vw&quot; itemprop=&quot;url&quot; itemid=&quot;https://static01.nyt.com/images/2019/03/28/science/28SCI-ZIMMER/28SCI-ZIMMER-articleLarge.jpg?quality=75&amp;amp;auto=webp&amp;amp;disable=upscale&quot;/&gt;&lt;/div&gt;
&lt;span class=&quot;css-8i9d0s e13ogyst0&quot;&gt;Espada’s marsupial frog, near the Gocta Waterfall in the Chachapoyas province of Peru.&lt;/span&gt;&lt;span itemprop=&quot;copyrightHolder&quot; class=&quot;css-vuqh7u e1z0qqy90&quot;&gt;&lt;span class=&quot;css-1ly73wi e1tej78p0&quot;&gt;Credit&lt;/span&gt;&lt;span&gt;Tiffany Kosch&lt;/span&gt;&lt;/span&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;css-1fanzo5 StoryBodyCompanionColumn&quot;&gt;
&lt;div class=&quot;css-53u6y8&quot;&gt;
&lt;p class=&quot;css-1ygdjhk evys1bk0&quot;&gt;Big frogs are at a greater risk, too, possibly because they don’t multiply as quickly as small ones.&lt;/p&gt;
&lt;p class=&quot;css-1ygdjhk evys1bk0&quot;&gt;Dr. Scheele and his colleagues identified 501 species in decline, far greater than the previous estimate of 200. Certain factors once thought to account for the decimation of frog populations — like climate change and deforestation — are not the greatest threats, the scientists found.&lt;/p&gt;
&lt;p class=&quot;css-1ygdjhk evys1bk0&quot;&gt;“A lot of those hypotheses have been discredited,” said Dr. Scheele. “And the more we find out about the fungus, the more it fits with the pattern.”&lt;/p&gt;
&lt;/div&gt;
&lt;aside class=&quot;css-o6xoe7&quot;/&gt;&lt;/div&gt;
&lt;div class=&quot;css-1fanzo5 StoryBodyCompanionColumn&quot;&gt;
&lt;div class=&quot;css-53u6y8&quot;&gt;
&lt;p class=&quot;css-1ygdjhk evys1bk0&quot;&gt;As it turns out, Bd wiped out some species long before it was discovered. Only by going back to museum specimens were scientists able to estimate the toll. “It’s scary that so many species can become extinct without us knowing,” said Dr. Scheele.&lt;/p&gt;
&lt;p class=&quot;css-1ygdjhk evys1bk0&quot;&gt;The decimation of frogs peaked in the 1980s, the researchers found, a decade before the discovery of Bd. Today, 39 percent of the species that suffered population declines in the past are still declining. Twelve percent are showing signs of recovery, possibly because natural selection is favoring resistant animals.&lt;/p&gt;
&lt;p class=&quot;css-1ygdjhk evys1bk0&quot;&gt;As dire as the study’s results turned out to be, Dr. Scheele is guardedly optimistic about future wildlife outbreaks. The element of surprise may have had a lot to do with Bd’s devastating success.&lt;/p&gt;
&lt;p class=&quot;css-1ygdjhk evys1bk0&quot;&gt;“It wasn’t expected or predicted, and so it took the research community a long time to catch up,” said Dr. Scheele.&lt;/p&gt;
&lt;p class=&quot;css-1ygdjhk evys1bk0&quot;&gt;In 2013, researchers discovered that a related fungus was attacking fire salamanders in Belgium. Called Batrachochytrium salamandrivorans (Bsal for short), it seemed &lt;a class=&quot;css-1g7m0tk&quot; href=&quot;https://www.nytimes.com/2015/08/04/science/importing-both-salamanders-and-their-potential-destruction.html?module=inline&quot; title=&quot;&quot;&gt;poised to do to salamanders what Bd has done to frogs&lt;/a&gt;.&lt;/p&gt;
&lt;p class=&quot;css-1ygdjhk evys1bk0&quot;&gt;But this time, things are playing out differently.&lt;/p&gt;
&lt;p class=&quot;css-1ygdjhk evys1bk0&quot;&gt;Researchers discovered the outbreak and identified Bsal quickly. They immediately began running experiments to understand the threat it posed. Thanks to &lt;a class=&quot;css-1g7m0tk&quot; href=&quot;https://www.nytimes.com/2016/01/13/science/us-restricts-movement-of-salamanders-for-their-own-good.html?module=inline&quot; title=&quot;&quot;&gt;barriers to trade now in place&lt;/a&gt;, Bsal has yet to threaten another species anywhere.&lt;/p&gt;
&lt;p class=&quot;css-1ygdjhk evys1bk0&quot;&gt;“We’ve learned, and we’re dealing with it better,” said Dr. Scheele. “I guess the question is always, ‘Are we doing enough?’ And that’s debatable.”&lt;/p&gt;
&lt;/div&gt;
&lt;aside class=&quot;css-o6xoe7&quot;/&gt;&lt;/div&gt;
&lt;div class=&quot;css-1fanzo5 StoryBodyCompanionColumn&quot;&gt;
&lt;div class=&quot;css-53u6y8&quot;&gt;
&lt;p class=&quot;css-1ygdjhk evys1bk0&quot;&gt;There’s still plenty of reason to worry about outbreaks to come. Bd has yet to reach New Guinea, home to a wealth of amphibian species found nowhere else on Earth.&lt;/p&gt;
&lt;p class=&quot;css-1ygdjhk evys1bk0&quot;&gt;If a Bd-infected frog got to either place — through the pet trade, or as an accidental stowaway — the fungus would have a vast number of vulnerable hosts to attack.&lt;/p&gt;
&lt;p class=&quot;css-1ygdjhk evys1bk0&quot;&gt;“It could be a meltdown of the ecosystems over there,” said Daniel Greenberg, a graduate student at Simon Fraser University and co-author of the Science commentary.&lt;/p&gt;
&lt;p class=&quot;css-1ygdjhk evys1bk0&quot;&gt;The loss of frogs can alter entire ecosystems.&lt;/p&gt;
&lt;p class=&quot;css-1ygdjhk evys1bk0&quot;&gt;Without tadpoles to guzzle algae, blooms may choke streams. Without frogs to eat insects, some disease-carrying species may become more common. Birds and other predators that eat frogs have to find alternatives.&lt;/p&gt;
&lt;p class=&quot;css-1ygdjhk evys1bk0&quot;&gt;Scientists are not even resting easy about the species that have emerged intact from the Bd assault. Another strain of Bd, or some different species of fungus altogether, may prove to be even deadlier.&lt;/p&gt;
&lt;p class=&quot;css-1ygdjhk evys1bk0&quot;&gt;“It’s just Russian roulette, with moving pathogens around the world,” said Dr. Scheele.&lt;/p&gt;
&lt;/div&gt;
&lt;aside class=&quot;css-o6xoe7&quot;/&gt;&lt;/div&gt;
&lt;div class=&quot;css-g92qtk epkadsg3&quot;&gt;
&lt;div class=&quot;css-1owp1gq epkadsg0&quot;&gt;Earlier reporting on frogs under threat&lt;/div&gt;
&lt;div class=&quot;css-15g2oxy epkadsg2&quot;&gt;
&lt;div class=&quot;css-2b3w4o e16ij5yr6&quot;&gt;
&lt;div class=&quot;css-i9gxme e16ij5yr4&quot;&gt;
&lt;div class=&quot;css-1hma5rr e16ij5yr2&quot;&gt;Frog-Killing Fungus Found to Have Origins on Korean Peninsula&lt;/div&gt;
&lt;time class=&quot;css-1yil5bp e16638kd0&quot; datetime=&quot;2018-05-10&quot;&gt;May 10, 2018&lt;/time&gt;&lt;/div&gt;
&lt;div class=&quot;css-rxyfbr e16ij5yr0&quot;&gt;&lt;img src=&quot;https://static01.nyt.com/images/2018/05/15/science/11TB-FUNGUS1/11TB-FUNGUS1-threeByTwoSmallAt2X.jpg&quot; class=&quot;css-32rbo2 e16ij5yr1&quot;/&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;css-2b3w4o e16ij5yr6&quot;&gt;
&lt;div class=&quot;css-i9gxme e16ij5yr4&quot;&gt;
&lt;div class=&quot;css-1hma5rr e16ij5yr2&quot;&gt;A Few Species of Frogs That Vanished May Be on the Rebound&lt;/div&gt;
&lt;time class=&quot;css-1yil5bp e16638kd0&quot; datetime=&quot;2018-03-29&quot;&gt;March 29, 2018&lt;/time&gt;&lt;/div&gt;
&lt;div class=&quot;css-rxyfbr e16ij5yr0&quot;&gt;&lt;img src=&quot;https://static01.nyt.com/images/2018/04/03/science/30Zimmer-1/30Zimmer-1-threeByTwoSmallAt2X.jpg&quot; class=&quot;css-32rbo2 e16ij5yr1&quot;/&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;css-2b3w4o e16ij5yr6&quot;&gt;
&lt;div class=&quot;css-i9gxme e16ij5yr4&quot;&gt;
&lt;div class=&quot;css-1hma5rr e16ij5yr2&quot;&gt;Frogs That Escaped Extinction&lt;/div&gt;
&lt;time class=&quot;css-1yil5bp e16638kd0&quot; datetime=&quot;2016-05-26&quot;&gt;May 26, 2016&lt;/time&gt;&lt;/div&gt;
&lt;div class=&quot;css-rxyfbr e16ij5yr0&quot;&gt;&lt;img src=&quot;https://static01.nyt.com/images/2016/05/27/science/27tb-frogs1/27tb-frogs1-videoLarge.jpg&quot; class=&quot;css-32rbo2 e16ij5yr1&quot;/&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;css-2b3w4o e16ij5yr6&quot;&gt;
&lt;div class=&quot;css-i9gxme e16ij5yr4&quot;&gt;
&lt;div class=&quot;css-1hma5rr e16ij5yr2&quot;&gt;A Reprieve for Fungus-Battered Frogs&lt;/div&gt;
&lt;time class=&quot;css-1yil5bp e16638kd0&quot; datetime=&quot;2016-01-04&quot;&gt;Jan. 4, 2016&lt;/time&gt;&lt;/div&gt;
&lt;div class=&quot;css-rxyfbr e16ij5yr0&quot;&gt;&lt;img src=&quot;https://static01.nyt.com/images/2016/01/05/science/05FUNG/0105-SCI-FUNG-videoLarge.jpg&quot; class=&quot;css-32rbo2 e16ij5yr1&quot;/&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
<pubDate>Thu, 28 Mar 2019 18:57:54 +0000</pubDate>
<dc:creator>jchanimal</dc:creator>
<og:url>https://www.nytimes.com/2019/03/28/science/frogs-fungus-bd.html</og:url>
<og:type>article</og:type>
<og:title>The Plague Killing Frogs Everywhere Is Far Worse Than Scientists Thought</og:title>
<og:image>https://static01.nyt.com/images/2019/04/02/science/28SCI-ZIMMER1/28SCI-ZIMMER1-facebookJumbo.jpg</og:image>
<og:description>As a threat to wildlife, an amphibian fungus has become “the most deadly pathogen known to science.”</og:description>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.nytimes.com/2019/03/28/science/frogs-fungus-bd.html</dc:identifier>
</item>
<item>
<title>Lucet: Native WebAssembly Compiler and Runtime</title>
<link>https://www.fastly.com/blog/announcing-lucet-fastly-native-webassembly-compiler-runtime</link>
<guid isPermaLink="true" >https://www.fastly.com/blog/announcing-lucet-fastly-native-webassembly-compiler-runtime</guid>
<description>&lt;p&gt;Today, we are thrilled to announce the &lt;a href=&quot;https://github.com/fastly/lucet&quot; title=&quot;Lucet&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;open sourcing of Lucet&lt;/a&gt;, Fastly’s native WebAssembly compiler and runtime. WebAssembly is a technology created to enable web browsers to safely execute programs at near-native speeds. It has been shipping in the four major browsers since early 2017.&lt;/p&gt;
&lt;p&gt;Lucet is designed to take WebAssembly beyond the browser, and build a platform for faster, safer execution on Fastly’s edge cloud. WebAssembly is already supported by many languages including Rust, TypeScript, C, and C++, and many more have WebAssembly support in development. We want to enable our customers to go beyond &lt;a href=&quot;https://docs.fastly.com/vcl/&quot; title=&quot;VCL&quot;&gt;Fastly VCL&lt;/a&gt; and move even more logic to the edge, and use any language they choose. Lucet is the engine behind Terrarium, our experimental platform for edge computation using WebAssembly. Soon, we will make it available on Fastly’s edge cloud as well.&lt;/p&gt;
&lt;p&gt;A major design requirement for Lucet was to be able to execute on every single request that Fastly handles. That means creating a WebAssembly instance for each of the tens of thousands of requests per second in a single process, which requires a dramatically lower runtime footprint than possible with a browser JavaScript engine. Lucet can instantiate WebAssembly modules in under 50 microseconds, with just a few kilobytes of memory overhead. By comparison, Chromium’s V8 engine takes about 5 milliseconds, and tens of megabytes of memory overhead, to instantiate JavaScript or WebAssembly programs.&lt;/p&gt;
&lt;p&gt;With Lucet, Fastly’s edge cloud can execute tens of thousands of WebAssembly programs simultaneously, in the same process, without compromising security. The Lucet compiler and runtime work together to ensure each WebAssembly program is allowed access to only its own resources. This means that Fastly’s customers will be able to write and run programs in more common, general-purpose languages, without compromising the security and safety we’ve always offered.&lt;/p&gt;
&lt;p&gt;Lucet separates responsibility for executing WebAssembly into two components: a compiler, which compiles WebAssembly modules to native code, and a runtime which manages resources and traps runtime faults. Lucet is designed for ahead-of-time (AOT) compilation of WebAssembly to native code, which dramatically simplifies the design and overhead of the runtime compared to the just-in-time (JIT) compilation strategy employed in browser engines.&lt;/p&gt;
&lt;h2&gt;How we built Lucet&lt;/h2&gt;
&lt;p&gt;Lucet is built on top of the &lt;a href=&quot;https://github.com/CraneStation/cranelift&quot; title=&quot;Cranelift code generator&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Cranelift code generator&lt;/a&gt;. The Cranelift project was created by Mozilla for use in Firefox’s WebAssembly and JavaScript JIT engines, and presently can be enabled by a &lt;a href=&quot;https://www.reddit.com/r/rust/comments/9mvnrk/in_firefox_nightly_an_option_has_arrived_to_use/&quot; title=&quot;Reddit Firefox Nightly&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;preference flag in Firefox Nightly&lt;/a&gt;. We &lt;a href=&quot;https://github.com/CraneStation/cranelift/graphs/contributors&quot; title=&quot;Cranelift Github&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;contributed&lt;/a&gt; to the design and implementation of Cranelift, and are excited that our efforts help make the web better for Firefox users as well.&lt;/p&gt;
&lt;p&gt;Lucet supports the &lt;a href=&quot;https://wasi.dev&quot; title=&quot;WASI&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;WebAssembly System Interface (WASI)&lt;/a&gt; — a new proposed standard for safely exposing low-level interfaces to the filesystem, networking, and other system facilities to WebAssembly programs. The Lucet team has partnered with Mozilla and others on the design, implementation, and standardization of this system interface.&lt;/p&gt;
&lt;p&gt;We’ve been working on this project behind the scenes since 2017, so we’re thrilled to finally make it public. Lucet also happens to be the first project started at Fastly using the &lt;a href=&quot;https://www.rust-lang.org/&quot; title=&quot;Rust&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Rust programming language&lt;/a&gt;, and we’re happy to report that Rust has been a huge success on this project. We found that new Rust users were able to become productive with the language quickly, and the library ecosystem provides many mature libraries for working with WebAssembly. Early in Lucet’s development, we implemented the first version of the runtime in C. However, we recently went back and translated the C runtime into Rust, and in the process, discovered and fixed several safety and concurrency bugs.&lt;/p&gt;
&lt;p&gt;As the engine behind the Terrarium project, Lucet has gotten months of production testing, running many thousands of different WebAssembly programs since launching in late 2018. It has also been the subject of an in-depth third-party security assessment.&lt;/p&gt;
&lt;h2&gt;A quick demo of Lucet&lt;/h2&gt;
&lt;p&gt;First, clone the Lucet repository from GitHub.&lt;/p&gt;
&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;$ git clone --recurse-submodules https://github.com/fastly/lucet&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;The &lt;a href=&quot;https://github.com/fastly/lucet/blob/master/README.md&quot; title=&quot;README&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;README&lt;/a&gt; contains instructions on using Docker to setup a development environment. If you already have Docker installed, there is just one step. It may take a few minutes to complete building everything.&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot; readability=&quot;6&quot;&gt;
&lt;div class=&quot;highlight&quot; readability=&quot;7&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;
&lt;code&gt;$ cd lucet  
$ source devenv_setenv.sh
&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Now, lets create a small C program, and use Clang to compile it to WebAssembly:&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot; readability=&quot;9&quot;&gt;
&lt;div class=&quot;highlight&quot; readability=&quot;13&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;
&lt;code&gt;$ mkdir demo
$ cd demo
$ cat &amp;gt; hello.c &amp;lt;&amp;lt;EOT

#include &amp;lt;stdio.h&amp;gt;
int main(int argc, char* argv[])
{
    if (argc &amp;gt; 1) {
            printf(&quot;Hello from Lucet, %s!\n&quot;, argv[1]);
    } else {
            puts(&quot;Hello, world!&quot;);
    }
    return 0;
}
EOT
$ wasm32-unknown-wasi-clang hello.c -o hello.wasm
&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Now we can compile the WebAssembly to native code, using the Lucet compiler, configured for use with WASI:&lt;/p&gt;
&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;$ lucetc-wasi hello.wasm -o hello.so&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Finally, we can execute the native code using the Lucet runtime configured for use with WASI:&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot; readability=&quot;7&quot;&gt;
&lt;div class=&quot;highlight&quot; readability=&quot;9&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;
&lt;code&gt;$ lucet-wasi hello.so  
Hello, world!  
$ lucet-wasi hello.so world  
Hello from Lucet, world!  
&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Documentation and additional examples are available in the Lucet repository.&lt;/p&gt;
&lt;h2&gt;Beyond the edge cloud&lt;/h2&gt;
&lt;p&gt;We are excited to open source Lucet because of all the possibilities WebAssembly holds beyond the web browser and edge cloud. For instance, Lucet’s support for WASI is a big step towards WebAssembly programs that can run on whatever platform the user wants — in the cloud, at the edge, on the browser, or natively on your laptop or smartphone — all while keeping the same strong guarantees about security in place. We want to enable WebAssembly to thrive inside any program that allows scripting or extensions, while using fewer resources than current solutions built on dynamic languages, interpreters, and JIT compilers.&lt;/p&gt;
&lt;p&gt;Most importantly, we want to collaborate with the open-source community on Lucet, Cranelift, WASI, and other WebAssembly-enabling technologies. Fastly is built on, and &lt;a href=&quot;https://www.fastly.com/open-source&quot; title=&quot;Open source&quot;&gt;committed to supporting&lt;/a&gt;, open source. Without it, we could never have built Lucet — and we hope that Lucet allows you to build new things that we haven’t even dreamed of.&lt;/p&gt;

&lt;h3&gt;&lt;span data-swiftype-index=&quot;false&quot;&gt;&lt;span&gt;You may also like:&lt;/span&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;section class=&quot;section&quot;&gt;&lt;div class=&quot;cards&quot; readability=&quot;18.5&quot;&gt;
&lt;article class=&quot;card__article&quot; readability=&quot;27&quot;&gt;
&lt;div id=&quot;newsletter-form-content&quot; readability=&quot;32&quot;&gt;
&lt;p class=&quot;post-title&quot;&gt;&lt;span class=&quot;card&quot;&gt;Subscribe to our newsletter&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;post-meta&quot;&gt;&lt;span class=&quot;card&quot;&gt;Get the latest news and industry insights in your inbox.&lt;/span&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&quot;newsletter-form-confirm&quot; class=&quot;hide&quot; readability=&quot;7&quot;&gt;
&lt;p class=&quot;post-title&quot;&gt;Subscribe to our newsletter&lt;/p&gt;
&lt;p class=&quot;post-meta&quot;&gt;Thanks for subscribing&lt;/p&gt;
&lt;/div&gt;
&lt;/article&gt;&lt;span class=&quot;card&quot;/&gt;
&lt;article class=&quot;card__article&quot; readability=&quot;35&quot;&gt;
&lt;p class=&quot;post-title&quot;&gt;&lt;span class=&quot;card&quot;&gt;Memory management in WebAssembly: guide for C and Rust programmers&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;card&quot;&gt;Recently we launched Fastly Terrarium, a multi-language, browser-based editor and deployment platform where you can experiment with edge technology. Now, for those well-versed in C and Rust, we’ll explore WebAssembly memory management and implementation.&lt;/span&gt;&lt;/p&gt;

&lt;/article&gt;&lt;span class=&quot;card&quot;/&gt;
&lt;article class=&quot;card__article&quot; readability=&quot;35&quot;&gt;
&lt;p class=&quot;post-title&quot;&gt;&lt;span class=&quot;card&quot;&gt;Edge programming with Rust and WebAssembly&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;card&quot;&gt;Take a developer deep dive into Terrarium, our multi-language, browser-based editor and deployment platform at the edge. Learn how to compile Rust programs to WebAssembly right on your local machine, interact with the Terrarium system,…&lt;/span&gt;&lt;/p&gt;

&lt;/article&gt;&lt;span class=&quot;card&quot;/&gt;
&lt;article class=&quot;card__article&quot; readability=&quot;32&quot;&gt;
&lt;p class=&quot;post-title&quot;&gt;&lt;span class=&quot;card&quot;&gt;How Terrarium reframes the compiler and sandbox relationship&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;card&quot;&gt;Get hands-on with Terrarium, a Fastly project that lets developers harness the power of edge computing in the languages they already use. See how this technology demonstration came to be (and why we’re even using…&lt;/span&gt;&lt;/p&gt;

&lt;/article&gt;&lt;/div&gt;
&lt;/section&gt;&lt;div class=&quot;blog-authors&quot;&gt;
&lt;h3&gt;&lt;span&gt;Author&lt;/span&gt;&lt;/h3&gt;
&lt;div class=&quot;author&quot; readability=&quot;6.5759162303665&quot;&gt;
&lt;div class=&quot;avatar&quot;&gt;&lt;img src=&quot;https://www.fastly.com/cimages/6pk8mg3yh2ee/5Mo709jMas0gIi2WMsmQ6K/14662889605f1ad566bcc03a5699ca4b/pat-hickey.jpg?width=150&amp;amp;height=150&amp;amp;fit=crop&quot;/&gt;&lt;/div&gt;
&lt;div class=&quot;bio&quot; readability=&quot;9.0418848167539&quot;&gt;
&lt;p&gt;&lt;a href=&quot;https://www.fastly.com/blog/pat-hickey&quot;&gt;Pat Hickey | Sr. software engineer&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Pat Hickey is a senior software engineer on Fastly’s isolation team. Previously, he worked on operating systems and compilers for safety-critical systems.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

</description>
<pubDate>Thu, 28 Mar 2019 17:19:33 +0000</pubDate>
<dc:creator>kickdaddy</dc:creator>
<og:title>Announcing Lucet: Fastly’s native WebAssembly compiler and runtime</og:title>
<og:url>https://www.fastly.com/blog/announcing-lucet-fastly-native-webassembly-compiler-runtime/</og:url>
<og:description>Today, we’re thrilled to announce the open sourcing of Lucet, our native WebAssembly compiler and runtime. WebAssembly is a technology created to enable web browsers to safely execute programs at near-native speeds, and it’s been shipping in the four major browsers since early 2017.</og:description>
<og:image>https://www.fastly.com/cimages/6pk8mg3yh2ee/4RGJh4DHD4HX2Zpa2NY1h8/87fe66f5db89c1f1b105c6306b4f2e3a/social_header_image_lucet.jpg?canvas=1200:630&amp;width=1200&amp;height=630&amp;fit=bounds&amp;bg-color=FFFFFF</og:image>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.fastly.com/blog/announcing-lucet-fastly-native-webassembly-compiler-runtime</dc:identifier>
</item>
<item>
<title>The FCC has fined robocallers $208M and collected $7k</title>
<link>https://www.foxnews.com/tech/the-fcc-has-fined-robocallers-208-million-its-collected-6790</link>
<guid isPermaLink="true" >https://www.foxnews.com/tech/the-fcc-has-fined-robocallers-208-million-its-collected-6790</guid>
<description>&lt;p class=&quot;speakable&quot;&gt;America’s telecommunications watchdogs have levied hefty financial penalties against illegal robocallers and demanded that bad actors repay millions to their victims. But years later, little money has been collected.&lt;/p&gt;


&lt;p class=&quot;speakable&quot;&gt;Since 2015, the Federal Communications Commission has ordered violators of the Telephone Consumer Protection Act, a law governing telemarketing and robodialing, to pay $208.4 million. That sum includes so-called forfeiture orders in cases involving robocalling, Do Not Call Registry and telephone solicitation violations.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.foxnews.com/tech/palantir-wins-800-million-army-contract-for-battlefield-intelligence-system&quot; target=&quot;_blank&quot;&gt;&lt;strong&gt;PALANTIR WINS $800M CONTRACT FOR ARMY'S BATTLEFIELD INTELLIGENCE SYSTEM&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;So far, the government has collected $6,790 of that amount, according to records obtained by The Wall Street Journal through a Freedom of Information Act request.&lt;/p&gt;
&lt;p&gt;The total amount of money secured by the Federal Trade Commission through court judgments in cases involving civil penalties for robocalls or National Do Not Call Registry-related violations, plus the sum requested for consumer redress in fraud-related cases, is $1.5 billion since 2004. It has collected $121 million of that total, said Ian Barlow, coordinator of the agency’s Do Not Call program, or about 8%. The agency operates the National Do Not Call Registry and regulates telemarketing.&lt;/p&gt;

&lt;p&gt;“That number stands on its own. We’re proud of it; we think our enforcement program is pretty strong,” Mr. Barlow said.&lt;/p&gt;
&lt;p&gt;An FCC spokesman said his agency lacks the authority to enforce the forfeiture orders it issues and has passed all unpaid penalties to the Justice Department, which has the power to collect the fines. Many of the spoofers and robocallers the agency tries to punish are individuals and small operations, he added, which means they are at times unable to pay the full penalties.&lt;/p&gt;
&lt;p&gt;“Fines serve to penalize bad conduct and deter future misconduct,” the FCC spokesman said. A spokeswoman for the Justice Department, which can settle or drop cases, declined to comment.&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.foxnews.com/tech/facebook-bans-white-nationalism-and-white-separatism&quot; target=&quot;_blank&quot;&gt;&lt;strong&gt;FACEBOOK BANS WHITE NATIONALISM AND WHITE SEPARATISM&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The dearth of financial penalties collected by the U.S. government for violations of telemarketing and auto-dialing rules shows the limits the sister regulators face in putting a stop to illegal robocalls. It also shows why the threat of large fines can fail to deter bad actors.&lt;/p&gt;
&lt;p&gt;“It’s great that we have these laws; it’s great that we have public enforcement, but because there are so many calls and so many callers, the public enforcement is a joke,” said Margot Saunders, senior counsel at consumer advocacy group National Consumer Law Center. “It doesn’t even make a dent.”&lt;/p&gt;
&lt;p&gt;There were 26.3 billion unwanted robocalls made to U.S. mobile phones in 2018, by one measure from robocall-blocking app Hiya. Another company that offers such services, YouMail Inc., puts the number of unwanted and illegal robocalls made in the U.S. last year even higher, at nearly 48 billion.&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.wsj.com/articles/the-fcc-has-fined-robocallers-208-million-its-collected-6-790-11553770803&quot; target=&quot;_blank&quot;&gt;&lt;strong&gt;&lt;em&gt;Read more of this story at The Wall Street Journal, where it was first published. &lt;/em&gt;&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;
</description>
<pubDate>Thu, 28 Mar 2019 17:06:53 +0000</pubDate>
<dc:creator>mudil</dc:creator>
<og:title>The FCC has fined robocallers $208 million. It's collected $6,790.</og:title>
<og:description>America’s telecommunications watchdogs have levied hefty financial penalties against illegal robocallers and demanded that bad actors repay millions to their victims. But years later, little money has been collected.</og:description>
<og:type>article</og:type>
<og:image>https://static.foxnews.com/foxnews.com/content/uploads/2018/09/robocall.jpg</og:image>
<og:url>https://www.foxnews.com/tech/the-fcc-has-fined-robocallers-208-million-its-collected-6790</og:url>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.foxnews.com/tech/the-fcc-has-fined-robocallers-208-million-its-collected-6790</dc:identifier>
</item>
<item>
<title>Internal Documents Show Apple Is Capable of Implementing Right to Repair</title>
<link>https://motherboard.vice.com/en_us/article/d3mqna/internal-documents-show-apple-is-capable-of-implementing-right-to-repair-legislation</link>
<guid isPermaLink="true" >https://motherboard.vice.com/en_us/article/d3mqna/internal-documents-show-apple-is-capable-of-implementing-right-to-repair-legislation</guid>
<description>&lt;p&gt;As Apple &lt;a href=&quot;https://motherboard.vice.com/en_us/article/nz85y7/apple-is-lobbying-against-your-right-to-repair-iphones-new-york-state-records-confirm&quot; target=&quot;_blank&quot;&gt;continues to fight legislation&lt;/a&gt; that would make it easier for consumers to repair their iPhones, MacBooks, and other electronics, the company appears to be able to implement many of the requirements of the legislation, according to an internal presentation obtained by Motherboard.&lt;/p&gt;
&lt;p&gt;According to the presentation, titled “Apple Genuine Parts Repair” and dated April 2018, the company has begun to give some repair companies access to Apple diagnostic software, a wide variety of genuine Apple repair parts, repair training, and notably places no restrictions on the types of repairs that independent companies are allowed to do. The presentation notes that repair companies can “keep doing what you’re doing, with … Apple genuine parts, reliable parts supply, and Apple process and training.”&lt;/p&gt;

&lt;p&gt;This is, broadly speaking, what &lt;a href=&quot;https://motherboard.vice.com/en_us/article/nex3dz/insurance-giant-allstate-buys-icracked-phone-repair-company-joins-right-to-repair-movement&quot; target=&quot;_blank&quot;&gt;right to repair activists&lt;/a&gt; have been asking state legislators to require companies to offer for years.&lt;/p&gt;
&lt;p&gt;“This looks to me like a framework for complying with right to repair legislation,” Kyle Wiens, CEO of iFixit and a prominent member of the right to repair movement, told me on the phone. “Right now, they are only offering it to a few megachains, but it seems clear to me that it would be totally possible to comply with right to repair.”&lt;/p&gt;
&lt;div class=&quot;article__media&quot;&gt;&lt;img src=&quot;https://video-images.vice.com/_uncategorized/1553537098400-Screen-Shot-2019-03-25-at-20443-PM.png?resize=320:*&quot; alt=&quot;1553537098400-Screen-Shot-2019-03-25-at-20443-PM&quot; class=&quot;col-12-xs&quot; data-src=&quot;https://video-images.vice.com/_uncategorized/1553537098400-Screen-Shot-2019-03-25-at-20443-PM.png&quot;/&gt;
&lt;/div&gt;
&lt;p&gt;Manufacturers across the board—including &lt;a href=&quot;https://motherboard.vice.com/en_us/article/kz5qgw/california-farm-bureau-john-deere-tractor-hacking-right-to-repair&quot; target=&quot;_blank&quot;&gt;tractor companies like John Deere&lt;/a&gt;, appliance &lt;a href=&quot;https://motherboard.vice.com/en_us/article/vbxk3b/appliance-companies-are-lobbying-against-right-to-repair&quot; target=&quot;_blank&quot;&gt;companies like LG&lt;/a&gt;, and tech companies like Apple, Microsoft, and Samsung—have slowly but surely monopolized the repair of their devices by implementing software that prevents repair, “authorized repair” programs, and by tightly controlling the sale of replacement parts to independent companies. Right to repair legislation that has been introduced in 20 states would return access to consumer goods to the consumers themselves by requiring electronics manufacturers to sell replacement parts and repair tools to independent repair shops and the general public. It would also require them to make internal repair guides and diagnostic tools public.&lt;/p&gt;
&lt;div class=&quot;article__media&quot;&gt;&lt;img src=&quot;https://video-images.vice.com/_uncategorized/1553536700485-Screen-Shot-2019-03-25-at-15743-PM.png?resize=320:*&quot; alt=&quot;1553536700485-Screen-Shot-2019-03-25-at-15743-PM&quot; class=&quot;col-12-xs&quot; data-src=&quot;https://video-images.vice.com/_uncategorized/1553536700485-Screen-Shot-2019-03-25-at-15743-PM.png&quot;/&gt;
&lt;/div&gt;
&lt;p&gt;Apple, John Deere, and the trade organizations that represent them have lobbied against this legislation all over the country over the past few years and have thus far been able to prevent any bills from becoming the law of the land. In the past, for example, Apple’s lobbyists told a Nebraska state lawmaker that the legislation &lt;a href=&quot;https://motherboard.vice.com/en_us/article/pgxgpg/apple-tells-lawmaker-that-right-to-repair-iphones-will-turn-nebraska-into-a-mecca-for-hackers&quot; target=&quot;_blank&quot;&gt;would turn the state into a “Mecca” for hackers and “bad actors&lt;/a&gt;.” A letter obtained by Motherboard that was sent last month to a Georgia lawmaker by 17 trade organizations that represent consumer tech, video game, wireless, home appliance, and air conditioning companies (including Apple) says that right to repair legislation “threatens consumer security and safety” and “stifles innovation.”&lt;/p&gt;
&lt;p&gt;The internal Apple presentation does not say who the company plans on rolling out its program to, but it notes that there are “3,700+ Apple Authorized Service Providers” and shows photos of four repair chains: Mobile Kangaroo, based in California; AA Mac, based in the United Kingdom; Simply Mac, based in Salt Lake City, Utah; and Makina Technologies, based in Dubai. Mobile Kangaroo, AA Mac, and Makina Technologies all say that they have “access to Apple diagnostic tools” on their websites, suggesting that it has already been rolled out to these companies. Mobile Kangaroo told me in an email that it recently got &quot;premium status&quot; from Apple but did not answer questions about the Apple Genuine Parts Repair presentation.&lt;/p&gt;

&lt;p&gt;Apple did not respond to a request for comment, and neither did Makina Technologies, AA Mac, or Simply Mac.&lt;/p&gt;
&lt;p&gt;The program described in Apple’s presentation is different from Apple’s standard Authorized Service Provider program, which allows repair companies to only complete specific, Apple-approved repairs; harder repairs require those companies to mail the phone back to Apple for service.&lt;/p&gt;
&lt;p&gt;“Apple authorized technicians can switch out screens and batteries and they essentially can’t do anything else,” Nathan Proctor, who is leading consumer rights group US PIRG’s right to repair campaign, told me on the phone. “Reversing that policy to let them do more standard repairs is a step toward right to repair and evidence that the people working on this issue have forced them to change.”&lt;/p&gt;
&lt;div class=&quot;article__media&quot;&gt;&lt;img src=&quot;https://video-images.vice.com/_uncategorized/1553536718224-Screen-Shot-2019-03-25-at-15730-PM.png?resize=320:*&quot; alt=&quot;1553536718224-Screen-Shot-2019-03-25-at-15730-PM&quot; class=&quot;col-12-xs&quot; data-src=&quot;https://video-images.vice.com/_uncategorized/1553536718224-Screen-Shot-2019-03-25-at-15730-PM.png&quot;/&gt;
&lt;/div&gt;
&lt;p&gt;The internal Apple presentation undercuts many of the arguments that electronics industry lobbyists have made, namely ones that note that repair is too difficult for any “unauthorized” people to do or that argue the security of products could be undermined by giving diagnostic tools to independent companies. Apple executives have in the past argued that &lt;a href=&quot;https://motherboard.vice.com/en_us/article/xwgg8z/apple-iphones-are-too-complex-to-allow-unauthorized-repair&quot; target=&quot;_blank&quot;&gt;iPhones are too &quot;complex&quot;&lt;/a&gt; for the company to open its repair supply chain. The presentation, however, notes that people outside of Apple are perfectly capable of doing good repair work. It says that independent repair companies will “own [their] customer” and that “you stand behind your workmanship.”&lt;/p&gt;
&lt;p&gt;“Manufacturers say it would undermine their security model, but if it’s possible for them to do what this document is saying and roll out their diagnostic software to thousands of unaffiliated companies, then lobbyists have been lying to legislators,” Wiens said.&lt;/p&gt;

&lt;p&gt;This raises questions, then, about why Apple is opening up its repair programs—even on a limited basis—while its lobbyists continue to fight legislation that would do just that. Wiens and Proctor believe that Apple is trying to kill the legislation by telling lawmakers that it's given the repair community what they want.&lt;/p&gt;
&lt;p&gt;“It’s an attempt to reduce pressure from the public for right to repair legislation,” Wiens said. “They’re negotiating on their own terms.”&lt;/p&gt;
&lt;div class=&quot;article__media&quot;&gt;&lt;img src=&quot;https://video-images.vice.com/_uncategorized/1553536747694-Screen-Shot-2019-03-25-at-15722-PM.png?resize=320:*&quot; alt=&quot;1553536747694-Screen-Shot-2019-03-25-at-15722-PM&quot; class=&quot;col-12-xs&quot; data-src=&quot;https://video-images.vice.com/_uncategorized/1553536747694-Screen-Shot-2019-03-25-at-15722-PM.png&quot;/&gt;
&lt;/div&gt;
&lt;p&gt;There’s &lt;a href=&quot;https://motherboard.vice.com/en_us/article/kz5qgw/california-farm-bureau-john-deere-tractor-hacking-right-to-repair&quot; target=&quot;_blank&quot;&gt;already a precedent for this in the right to repair world&lt;/a&gt;. Last year, soon after California introduced a right to repair bill, the Equipment Dealers Association, which represents John Deere and other agricultural giants, agreed to give farmers some minor concessions by promising to make repair manuals, product guides, and diagnostic service tools (but not parts) available to farmers by 2021.&lt;/p&gt;
&lt;p&gt;As a result, the California Farm Bureau Federation, which nominally represents farmers, ultimately stopped pursuing right to repair, and the legislation was dropped (it was reintroduced this year.) Which was the point all along: “There are several big wins that come to mind as we look back on 2018,” John Lagemann, a sales and marketing executive at John Deere, &lt;a href=&quot;https://www.aem.org/news/strong-focus-on-customer-connections-advocacy-strategic-planning-for-aem-ag-sector-board/&quot; target=&quot;_blank&quot;&gt;told an agricultural trade organization&lt;/a&gt; at the end of last year. “We rallied around the Right-to-Repair issue and were successful in thwarting that legislation in several states.”&lt;/p&gt;

&lt;p&gt;And so while Apple may be softening its stance on independent repair and may be preparing to make important concessions, it’s not a reason to give up on fighting for legislation that actually enshrines fair repair policies for all consumers, not just a few larger independent chains.&lt;/p&gt;
&lt;p&gt;“It’s still short of giving freedom to the consumer to make decisions to fix their own devices,” Proctor said. “I think it’s a sign that they know that we’ve kind of won the public messaging that they’re changing their policy to something they didn’t want to do, but what we’re asking for is the freedom to make choices for ourselves about the products we’ve bought and own.”&lt;/p&gt;
</description>
<pubDate>Thu, 28 Mar 2019 16:03:59 +0000</pubDate>
<dc:creator>kaboro</dc:creator>
<og:type>article</og:type>
<og:title>Internal Documents Show Apple Is Capable of Implementing Right to Repair Legislation</og:title>
<og:image>https://video-images.vice.com/articles/5c9916780b09d6000812dce6/lede/1553537166942-shutterstock_759694303.jpeg?crop=1xw:0.8438589693917087xh;center,center&amp;resize=1200:*</og:image>
<og:url>https://motherboard.vice.com/en_us/article/d3mqna/internal-documents-show-apple-is-capable-of-implementing-right-to-repair-legislation</og:url>
<og:description>A leaked internal document obtained by Motherboard outlines a program that looks almost exactly like the requirements of right to repair legislation that has been proposed in 20 states.</og:description>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://motherboard.vice.com/en_us/article/d3mqna/internal-documents-show-apple-is-capable-of-implementing-right-to-repair-legislation</dc:identifier>
</item>
<item>
<title>Garfield phones beach mystery finally solved</title>
<link>https://www.bbc.com/news/world-europe-47732553</link>
<guid isPermaLink="true" >https://www.bbc.com/news/world-europe-47732553</guid>
<description>&lt;figure class=&quot;media-landscape has-caption full-width lead&quot;&gt;&lt;span class=&quot;image-and-copyright-container&quot;&gt;
                
                &lt;img class=&quot;js-image-replace&quot; alt=&quot;A collection of assorted Garfield phone fragments are shown arranged around some seaweed on the beach, with and Ar Viltansou high-viz vest visible&quot; src=&quot;https://ichef.bbci.co.uk/news/320/cpsprodpb/1511D/production/_106210368_0f0e1cbf-880b-42ed-9c61-15ab33ffd32e.jpg&quot; width=&quot;976&quot; height=&quot;549&quot;/&gt;&lt;span class=&quot;off-screen&quot;&gt;Image copyright&lt;/span&gt;
                 &lt;span class=&quot;story-image-copyright&quot;&gt;Claire Simonin‎ / Ar Viltansou&lt;/span&gt;
                
            &lt;/span&gt;
            
            &lt;figcaption class=&quot;media-caption&quot;&gt;&lt;span class=&quot;off-screen&quot;&gt;Image caption&lt;/span&gt;
                &lt;span class=&quot;media-caption__text&quot;&gt;
                    Dismembered orange plastic cats and their electronic innards have plagued Finistère for years
                &lt;/span&gt;
            &lt;/figcaption&gt;&lt;/figure&gt;&lt;p class=&quot;story-body__introduction&quot;&gt;A French coastal community has finally cracked the mystery behind the Garfield telephones that have plagued its picturesque beaches for decades.&lt;/p&gt;&lt;p&gt;Since the 1980s, the Iroise coast in Brittany has received a supply of bright orange landline novelty phones shaped like the famous cartoon cat.&lt;/p&gt;&lt;p&gt;Anti-litter campaigners have been collecting fragments of the feline for years as they clean the beaches.&lt;/p&gt;&lt;p&gt;But now, the source of the problem has been found - a lost shipping container.&lt;/p&gt;&lt;p&gt;Last year, campaigners from the Ar Vilantsou anti-litter group made the novelty phone a symbol of the plastic pollution on the beaches of the Finistère region - part of which is a designated marine park.&lt;/p&gt;&lt;p&gt;Once a common household item, its eyes open when the landline receiver is picked up, and thousands were made and sold during the 1980s. &lt;a href=&quot;https://www.ebay.co.uk/sch/i.html?_from=R40&amp;amp;_trksid=p2380057.m570.l1313.TR3.TRC2.A0.H0.Xgarfield+phone.TRS0&amp;amp;_nkw=garfield+phone&amp;amp;_sacat=0&quot; class=&quot;story-body__link-external&quot;&gt;Collectors still buy and sell the vintage Garfield phone&lt;/a&gt; online today.&lt;/p&gt;&lt;figure class=&quot;media-landscape no-caption full-width&quot;&gt;&lt;span class=&quot;image-and-copyright-container&quot;&gt;
                
                
                
                
                
            &lt;/span&gt;
            
        &lt;/figure&gt;&lt;p&gt;The beach-cleaning teams had long suspected that a lost shipping container - perhaps blown overboard - had regurgitated its precious orange cargo. But they had never been able to find it.&lt;/p&gt;&lt;p&gt;The media attention on the new campaign, however, drew the eye of a local farmer who remembered the first&lt;i&gt; téléphone Garfield&lt;/i&gt; appearing after a storm in the early 1980s, when he was a young man. &lt;/p&gt;&lt;p&gt;He also knew the location of the container - in a secluded sea cave accessible only at low tide.&lt;/p&gt;&lt;figure class=&quot;media-landscape has-caption full-width&quot;&gt;&lt;span class=&quot;image-and-copyright-container&quot;&gt;
                
                
                
                
                
                 &lt;span class=&quot;off-screen&quot;&gt;Image copyright&lt;/span&gt;
                 &lt;span class=&quot;story-image-copyright&quot;&gt;Martine and Dominique Leczinski / Ar Viltansou&lt;/span&gt;
                
            &lt;/span&gt;
            
            &lt;figcaption class=&quot;media-caption&quot;&gt;&lt;span class=&quot;off-screen&quot;&gt;Image caption&lt;/span&gt;
                &lt;span class=&quot;media-caption__text&quot;&gt;
                    Volunteers' rubbish hauls frequently feature ocean-battered cartoon cats
                &lt;/span&gt;
            &lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;a href=&quot;https://www.francetvinfo.fr/monde/environnement/alerte-pollution/grace-a-alertepollution-une-association-retrouve-l-origine-des-telephones-garfield-qui-polluent-les-plages-du-finistere-depuis-plus-de-trente-ans_3249105.html&quot; class=&quot;story-body__link-external&quot;&gt;&quot;You had to really know the area well,&quot; he told Franceinfo, which had covered the campaign&lt;/a&gt;. &quot;We found a container aground in a fissure. It was open. Many of the things were gone, but there was a stock of phones,&quot; he recalled.&lt;/p&gt;&lt;p&gt;Members of the Ar Viltansou group, accompanied by Franceinfo journalists, set out to find it.&lt;/p&gt;&lt;p&gt;Climbing down the slippery rocks to the cave, the team spotted remnants of a destroyed shipping container - and soon, between the rocks, Garfield phones - in a more complete condition than any found before them.&lt;/p&gt;&lt;figure class=&quot;media-landscape no-caption full-width&quot;&gt;&lt;span class=&quot;image-and-copyright-container&quot;&gt;
                
                
                
                
                
            &lt;/span&gt;
            
        &lt;/figure&gt;&lt;p&gt;&quot;This is the first time in our lives that we've seen that,&quot; campaigner Claire Simonin-Le Meur told the reporters.&lt;/p&gt;&lt;p&gt;Inside the rock fissure, they found orange plastic poking out from beneath the rocks. The container appeared to remain somewhat buried after three decades.&lt;/p&gt;&lt;p&gt;The challenge of plastic pollution - a hot-button political issue over the last year - is not necessarily reduced by solving the mystery.&lt;/p&gt;&lt;p&gt;The container remains inaccessible and it is not known how much of its cargo is sealed within it. Another issue is that the novelty items that escaped and continue to wash up on Brittany's beaches will not decompose in a human lifetime.&lt;/p&gt;&lt;p&gt;In the meantime, both Ar Viltansou and local officials say they will continue to harvest Garfields from the coastline.&lt;/p&gt;
            </description>
<pubDate>Thu, 28 Mar 2019 14:20:49 +0000</pubDate>
<dc:creator>fpoling</dc:creator>
<og:title>Garfield phones mystery solved after 35 years</og:title>
<og:type>article</og:type>
<og:description>For years, novelty phones appear on Brittany's beaches - but the source is finally found.</og:description>
<og:url>https://www.bbc.com/news/world-europe-47732553</og:url>
<og:image>https://ichef.bbci.co.uk/news/1024/branded_news/1511D/production/_106210368_0f0e1cbf-880b-42ed-9c61-15ab33ffd32e.jpg</og:image>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.bbc.com/news/world-europe-47732553</dc:identifier>
</item>
<item>
<title>Looking for a new CEO</title>
<link>https://stackoverflow.blog/2019/03/28/the-next-ceo-of-stack-overflow/</link>
<guid isPermaLink="true" >https://stackoverflow.blog/2019/03/28/the-next-ceo-of-stack-overflow/</guid>
<description>&lt;div class=&quot;m-post-card__excerpt&quot; itemprop=&quot;articleBody&quot;&gt;After an exciting end to 2018, we kicked this year off with the first “hackathon” in Stack Overflow’s 10-year history. Unlike a traditional hackathon, it wasn’t just for our developers....&lt;/div&gt;&lt;div class=&quot;m-post-card__excerpt&quot; itemprop=&quot;articleBody&quot;&gt;For nine years, we at Stack Overflow have fielded a survey, asking people who code about their opinions on a variety of topics, from whether they prefer a dark or...&lt;/div&gt;&lt;div class=&quot;m-post-card__excerpt&quot; itemprop=&quot;articleBody&quot;&gt;Stack Overflow and InfoJobs are partnering to bring more job opportunities to the developer community in Spain. Since we launched Stack Overflow Jobs in 2009, its mission has been to...&lt;/div&gt;</description>
<pubDate>Thu, 28 Mar 2019 14:11:28 +0000</pubDate>
<dc:creator>g3rv4</dc:creator>
<og:type>article</og:type>
<og:title>The Next CEO of Stack Overflow - Stack Overflow Blog</og:title>
<og:description>Big news! We’re looking for a new CEO for Stack Overflow. I’m stepping out of the day-to-day and up to the role of Chairman of the Board. Stack Overflow has been around for more than a decade. As I look back, it’s really amazing how far it has come.  Only six months after we had launched Stack Overflow, my co-founder Jeff Atwood and I were invited to speak at a Microsoft conference for developers in Las Vegas. We were there, I think, to demonstrate that you could use their latest ASP.NET MVC technology on a real website without too much of a disaster. (In fact .NET has been a huge, unmitigated success for us, but you kids go ahead and have fun with whatever platform you want mkay? They’re all great, or, at least, above-average).It was a giant conference, held at the Venetian Hotel. This hotel was so big that other hotels stay there when they go on vacation. The main ballroom was the size of, approximately, Ireland. I later learned there were 5,000 developers in that room.I thought it would be a fun thing to ask the developers in the room how many of them had visited Stack Overflow. As I remember, Jeff was very much against this idea. “Joel,” he said, “That is going to be embarrassing and humiliating. Nobody is going to raise their hand.”Well, I asked it anyway. And we were both surprised to see about one-third of the hands go up. We were really making an impact! That felt really good.Anyway, I tried that trick again whenever I spoke to a large audience. It doesn’t work anymore. Today, audiences just laugh. It’s like asking, “Does anyone use gravity? Raise your hand if you use gravity.”Where are we at after 11 years? Practically every developer in the world uses Stack Overflow. Including the Stack Exchange network of 174 sites, we have over 100 million monthly visitors. Every month, over 125,000 wonderful people write answers. According to Alexa, stackoverflow.com is one of the top 50 websites in the world. (That’s without even counting the Stack Exchange network, which is almost as big.) And every time I see a developer write code, they’ve got Stack Overflow open in one of their browser windows. Oh and—hey!—we do not make you sign up or pay to see the answers.The company has been growing, too. Today we are profitable. We have almost 300 amazing employees worldwide and booked $70m in revenue last year. We have talent, advertising, and software products. The SaaS products (Stack Overflow for Teams and Enterprise) are growing at 200% a year. That speaks to the fact that we’ve recruited an incredibly talented team that has produced such fantastic results. But, we have a lot of work ahead of us, and it’s going to take a different type of leader to get us through that work. The type of people Stack Overflow serves has changed, and now, as a part of the developer ecosystem, we have a responsibility to create an online community that is far more diverse, inclusive, and welcoming of newcomers. In the decade or so since Stack Overflow started, the number of people employed as software developers grew by 64% in the US alone. The field is going to keep growing everywhere in the world, and the demand for great software developers far outstrips supply. So a big challenge for Stack Overflow is welcoming those new developers into the fold. As I’ve written:One thing I’m very concerned about, as we try to educate the next generation of developers, and, importantly, get more diversity and inclusiveness in that new generation, is what obstacles we’re putting up for people as they try to learn programming. In many ways Stack Overflow’s specific rules for what is permitted and what is not are obstacles, but an even bigger problem is rudeness, snark, or condescension that newcomers often see.I care a lot about this. Being a developer gives you an unparalleled opportunity to write the script for the future. All the flak that Stack Overflow throws in the face of newbies trying to become developers is actively harmful to people, to society, and to Stack Overflow itself, by driving away potential future contributors. And programming is hard enough; we should see our mission as making it easier.The world has started taking a closer look at tech, and understanding that software and the internet are not just tools; they are shaping the future of society. Big tech companies are struggling with their place in the world. Stack Overflow is situated at the right place to be influential in how that future develops, and that is going to take a new type of leader.It will not be easy to find a CEO who is the right person to lead that mission. We will, no doubt, hire one of those fancy executive headhunters to help us in the search. But, hey, this is Stack Overflow. If there’s one thing I have learned by now, it’s that there’s always someone in the community who can answer the questions I can’t. So we decided to put this announcement out there in hopes of finding great candidates that might have been under the radar. We’re especially focused on identifying candidates from under-represented groups, and making sure that every candidate we consider is deeply committed to making our company and community more welcoming, diverse, and inclusive.Over the years, Fog Creek Software created several incredible hits and many wonderful memories along the way. It is great to watch Trello (under Michael Pryor) and Glitch (under Anil Dash) growing into enormously valuable, successful, and influential products with dedicated leaders who took these products much further than I ever could have, and personally I’m excited to see where Stack Overflow can go and turn my attention to the next thing.</og:description>
<og:url>https://stackoverflow.blog/2019/03/28/the-next-ceo-of-stack-overflow/</og:url>
<og:image>https://zgab33vy595fw5zq-zippykid.netdna-ssl.com/wp-content/uploads/2017/12/SO_pattern.png</og:image>
<dc:language>en-US</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://stackoverflow.blog/2019/03/28/the-next-ceo-of-stack-overflow/</dc:identifier>
</item>
<item>
<title>Why Bother with What Three Words?</title>
<link>https://shkspr.mobi/blog/2019/03/why-bother-with-what-three-words/</link>
<guid isPermaLink="true" >https://shkspr.mobi/blog/2019/03/why-bother-with-what-three-words/</guid>
<description>&lt;p&gt;I'll be wording this post carefully as &lt;a href=&quot;https://what3words.com/&quot;&gt;What 3 Words&lt;/a&gt; (W3W) have a tenacious PR team and, probably, have a lot more lawyers than I do.&lt;/p&gt;
&lt;p&gt;W3W is a closed product. It is a for-profit company masquerading as an open standard. And that annoys me.&lt;/p&gt;
&lt;p&gt;A brief primer.&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;The world is a &lt;a href=&quot;https://simple.wikipedia.org/wiki/Oblate_spheroid&quot;&gt;sphere&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;We can reference any point on the surface of Earth using two co-ordinates, Longitude and Latitude.&lt;/li&gt;
&lt;li&gt;Long/Lat are numbers. They can be as precise or as vague as needed.&lt;/li&gt;
&lt;li&gt;Humans can't remember long strings of numbers, and reading them out is difficult.&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;W3W aims to solve this. It splits the world into a grid, and gives every square a unique three-word phrase.&lt;/p&gt;
&lt;p&gt;So the location &lt;code&gt;51.50799,-0.12803&lt;/code&gt; becomes &lt;code&gt;///mile.crazy.shade&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Brilliant, right?&lt;/p&gt;
&lt;p&gt;No.&lt;/p&gt;
&lt;p&gt;Here's all the problems I have with W3W.&lt;/p&gt;
&lt;h2&gt;It isn't open&lt;/h2&gt;
&lt;p&gt;The algorithm used to generate the words is proprietary. You are not allowed to see it. You cannot find out your location without asking W3W for permission.&lt;/p&gt;
&lt;p&gt;If you want permission, you have to agree to some pretty &lt;a href=&quot;https://what3words.com/terms/&quot;&gt;long terms and conditions&lt;/a&gt;. And understand their &lt;a href=&quot;https://what3words.com/privacy/&quot;&gt;privacy policy&lt;/a&gt;. Oh, and an &lt;a href=&quot;https://what3words.com/developers/api-licence-agreement/&quot;&gt;API agreement&lt;/a&gt;. And then make sure you &lt;a href=&quot;https://what3words.com/patents&quot;&gt;don't infringe their patents&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;You cannot store locations. You have to let them analyse the locations you look up. Want to use more than 10,000 addresses? Contact them for prices!&lt;/p&gt;
&lt;p&gt;It is the antithesis of open.&lt;/p&gt;
&lt;h2&gt;Cost&lt;/h2&gt;
&lt;p&gt;W3W refuses to publish their prices. You have to contact their sales team if you want to know what it will cost your organisation.&lt;/p&gt;
&lt;p&gt;Open standards are free to use.&lt;/p&gt;
&lt;h2&gt;Earthquakes&lt;/h2&gt;
&lt;p&gt;When an earthquake struck Japan, street addresses didn't change &lt;em&gt;but&lt;/em&gt; that &lt;a href=&quot;https://slate.com/news-and-politics/2011/03/japanese-earthquake-when-tectonic-plates-shift-does-gps-still-work.html&quot;&gt;their physical location did&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;That is, a street address is &lt;em&gt;still&lt;/em&gt; 42 Acacia Avenue - but the Longitude and Latitude has changed.&lt;/p&gt;
&lt;p&gt;Perhaps you think this is an edge case? It isn't. &lt;a href=&quot;https://news.nationalgeographic.com/2016/09/australia-moves-gps-coordinates-adjusted-continental-drift/&quot;&gt;Australia is drifting so fast that GPS can't keep up&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;How does W3W deal with this? Their grid is static, so &lt;a href=&quot;https://support.what3words.com/hc/en-us/articles/208506269-How-will-what3words-handle-continental-drift-&quot;&gt;any tectonic activity means your W3W changes&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;Internationalisation&lt;/h2&gt;
&lt;p&gt;Numbers are &lt;em&gt;fairly&lt;/em&gt; universal. Lots of countries use 0-9. English words are &lt;em&gt;not&lt;/em&gt; universal. How does W3W deal with this?&lt;/p&gt;
&lt;p&gt;Is &quot;cat.dog.goose&quot; straight translated into French? No! Each language has its own word list.&lt;/p&gt;
&lt;p&gt;There is no way to translate between languages. You have to beg W3W for permission for access to their API. They do not publish their word lists or the mappings between them.&lt;/p&gt;
&lt;p&gt;So, if I want to tell a French speaker where &lt;code&gt;///mile.crazy.shade&lt;/code&gt; is, I have to use &lt;code&gt;///embouchure.adjuger.saladier&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Loosely translated back as &lt;code&gt;///mouth.award.bowl&lt;/code&gt; an &lt;a href=&quot;https://map.what3words.com/mouth.award.bowl&quot;&gt;entirely different location&lt;/a&gt;!&lt;/p&gt;
&lt;p&gt;You're not allowed to know what word lists W3W use. They take a &lt;a href=&quot;https://support.what3words.com/hc/en-us/articles/203105521-Is-a-3-word-address-in-French-or-any-other-language-a-translation-of-the-same-3-words-in-English-&quot;&gt;paternalistic attitude&lt;/a&gt; to creating their lists - they know best. You cannot propose changes.&lt;/p&gt;
&lt;p&gt;Anecdotally, their &lt;a href=&quot;https://news.ycombinator.com/item?id=17423421&quot;&gt;non-English word lists are confusing even for native speakers&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;Cultural Respect&lt;/h2&gt;
&lt;p&gt;Numbers are (mostly) culturally neutral. Words are not. Is &quot;mile.crazy.shade&quot; a respectful name for a war memorial? How about &lt;a href=&quot;https://map.what3words.com/tribes.hurt.stumpy&quot;&gt;&lt;code&gt;///tribes.hurt.stumpy&lt;/code&gt;&lt;/a&gt; for a temple?&lt;/p&gt;
&lt;p&gt;How do you feel about &lt;a href=&quot;https://map.what3words.com/weepy.lulls.emerge&quot;&gt;&lt;code&gt;///weepy.lulls.emerge&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;https://map.what3words.com/grouchy.hormone.elevating&quot;&gt;&lt;code&gt;///grouchy.hormone.elevating&lt;/code&gt;&lt;/a&gt; both being at Auschwitz? Or &lt;a href=&quot;https://map.what3words.com/klartext.best%C3%BCckt.vermuten&quot;&gt;&lt;code&gt;///klartext.bestückt.vermuten&lt;/code&gt;&lt;/a&gt; - &quot;cleartext stocked suspect&quot;?&lt;/p&gt;
&lt;p&gt;This is a classic computer science problem. Every sufficiently long word list can eventually be recombined into a potentially offensive phrase.&lt;/p&gt;
&lt;h2&gt;Open Washing&lt;/h2&gt;
&lt;p&gt;W3W know that &lt;a href=&quot;https://wiki.openstreetmap.org/wiki/What3words&quot;&gt;the majority of technical people are not fooled&lt;/a&gt; by their attempts to lock down addressing.&lt;/p&gt;
&lt;p&gt;They include this paragraph to attempt to prove their openness:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;If we, what3words ltd, are ever unable to maintain the what3words technology or make arrangements for it to be maintained by a third-party (with that third-party being willing to make this same commitment), then we will release our source code into the public domain. We will do this in such a way and with suitable licences and documentation to ensure that any and all users of what3words, whether they are individuals, businesses, charitable organisations, aid agencies, governments or anyone else can continue to rely on the what3words system.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;I don't know how they propose to bind a successor organisation. They don't say &lt;em&gt;what&lt;/em&gt; licences they will use. If they go bust, there's no guarantee they'll be legally able to release this code, nor may they have the time to do so.&lt;/p&gt;
&lt;p&gt;There's nothing stopping W3W from releasing their algorithms now, subjecting them to scrutiny by the standards community. They could build up a community of experts to help improve the system, they could work with existing mapping efforts, they could help build a useful and open standard.&lt;/p&gt;
&lt;p&gt;But they don't. They guard their secrets and actively promote their proprietary product in the hope it will become widely accepted and then they can engage in rent-seeking behaviour.&lt;/p&gt;
&lt;h2&gt;This is not a new argument&lt;/h2&gt;
&lt;p&gt;My mate &lt;a href=&quot;https://blog.ldodds.com/2016/06/14/what-3-words-jog-on-mate/&quot;&gt;Leigh wrote about this three years ago&lt;/a&gt;. &lt;a href=&quot;https://knowwhereconsulting.co.uk/blog/location-grid-not-an-address/&quot;&gt;Lots&lt;/a&gt; &lt;a href=&quot;https://medium.com/@piesse/open-location-code-what3words-74a3f810c18d&quot;&gt;of&lt;/a&gt; &lt;a href=&quot;https://news.ycombinator.com/item?id=18646650&quot;&gt;people&lt;/a&gt; &lt;a href=&quot;https://www.quora.com/What-is-your-review-of-what3words&quot;&gt;have&lt;/a&gt; &lt;a href=&quot;https://stiobhart.net/2016-01-15-stupidest-idea-ever/&quot;&gt;criticised&lt;/a&gt; &lt;a href=&quot;http://blog.telemapics.com/?p=589&quot;&gt;W3W&lt;/a&gt;.&lt;/p&gt;
&lt;blockquote class=&quot;twitter-tweet&quot; data-width=&quot;550&quot; data-dnt=&quot;true&quot;&gt;
&lt;p lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;.&lt;a href=&quot;https://twitter.com/what3words?ref_src=twsrc%5Etfw&quot;&gt;@what3words&lt;/a&gt; is bad technical idea, and ethically terrible too. But all VCs like patented economic rents so the juggernaut rolls on. &lt;a href=&quot;https://twitter.com/hashtag/geomob?src=hash&amp;amp;ref_src=twsrc%5Etfw&quot;&gt;#geomob&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;— Andy Allan (@gravitystorm) &lt;a href=&quot;https://twitter.com/gravitystorm/status/753653845859962880?ref_src=twsrc%5Etfw&quot;&gt;July 14, 2016&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;But W3W have a great PR team - pushing press releases which are then reported as &lt;a href=&quot;https://www.bbc.co.uk/news/technology-40935774&quot;&gt;uncritical&lt;/a&gt; &lt;a href=&quot;https://www.bbc.co.uk/news/technology-47705912&quot;&gt;news&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The most recent press release contains a &lt;em&gt;ludicrous&lt;/em&gt; example:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;Person dials the emergency services&lt;/li&gt;
&lt;li&gt;Person doesn't know their location&lt;/li&gt;
&lt;li&gt;Emergency services sends the person a link&lt;/li&gt;
&lt;li&gt;Person clicks on link, opens web page&lt;/li&gt;
&lt;li&gt;Web page geolocates user and displays their W3W location&lt;/li&gt;
&lt;li&gt;Person reads out their W3W phrase to the emergency services&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;Here's the thing... If the person's phone has a data connection - the web page can just send the geolocation directly back to the emergency services! No need to get a human to read it out, then another human to listen and type it in to a different system.&lt;/p&gt;
&lt;p&gt;There is literally no need for W3W in this scenario. If you have a data connection, you can send your precise location without an intermediary.&lt;/p&gt;
&lt;h2&gt;What Next?&lt;/h2&gt;
&lt;p&gt;W3W succeeds because it has a superficially simple solution to a complex problems. It is a brilliant lesson in how marketing and PR can help a technologically inferior project look like it is a global open solution.&lt;/p&gt;
&lt;p&gt;I'm not joking. Their &lt;a href=&quot;https://www.edelman.co.uk/work/what3words/&quot;&gt;branding firm says&lt;/a&gt;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Edelman helped what3words frame their story to be compelling by tapping into human emotion.&lt;br/&gt;We also created a story for CEO Chris Sheldrick about how having an address can drive social transformation and business efficiency, securing profiling and speaker opportunities.&lt;br/&gt;Through paid social campaigns we re-targeted these stories, getting through to the decision makers that mattered most.&lt;br/&gt;We articulated their purpose narrative and refined their strategy to engage investors and excite the media.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;It takes &lt;a href=&quot;https://twitter.com/ziobrando/status/289635060758507521&quot;&gt;too much time to refute all their claims&lt;/a&gt; - but we must. Whenever you see people mentioning What3Words, politely remind them that it is not an open standard and should be avoided.&lt;/p&gt;
&lt;blockquote class=&quot;twitter-tweet&quot; data-width=&quot;550&quot; data-dnt=&quot;true&quot;&gt;
&lt;p lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;Your periodic reminder that W3W is a closed and proprietary system, with opaque licencing, hefty pricing, and poor internationalisation.&lt;br/&gt;It does have a very good PR team though. &lt;a href=&quot;https://t.co/Ch3e9cAfsn&quot;&gt;https://t.co/Ch3e9cAfsn&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;— Terence Eden (@edent) &lt;a href=&quot;https://twitter.com/edent/status/1110606981142925313?ref_src=twsrc%5Etfw&quot;&gt;March 26, 2019&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

</description>
<pubDate>Thu, 28 Mar 2019 13:25:15 +0000</pubDate>
<dc:creator>MagicAndi</dc:creator>
<og:type>article</og:type>
<og:title>Why bother with What Three Words?</og:title>
<og:url>https://shkspr.mobi/blog/2019/03/why-bother-with-what-three-words/</og:url>
<og:description>I’ll be wording this post carefully as What 3 Words (W3W) have a tenacious PR team and, probably, have a lot more lawyers than I do. W3W is a closed product. It is a for-profit company masque…</og:description>
<og:image>https://shkspr.mobi/blog/wp-content/uploads/2014/11/Men-confused-by-a-map.jpg</og:image>
<dc:language>en-GB</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://shkspr.mobi/blog/2019/03/why-bother-with-what-three-words/</dc:identifier>
</item>
<item>
<title>Common statistical tests are linear models</title>
<link>https://lindeloev.github.io/tests-as-linear/</link>
<guid isPermaLink="true" >https://lindeloev.github.io/tests-as-linear/</guid>
<description>&lt;a href=&quot;https://twitter.com/intent/tweet?text=Common%20statistical%20tests%20are%20linear%20models%20(or:%20how%20to%20teach%20stats)%20https%3A%2F%2Flindeloev.github.io%2Ftests-as-linear%20via%20%40jonaslindeloev&quot; class=&quot;twitter-hashtag-button&quot; data-size=&quot;large&quot; data-related=&quot;jonaslindeloev&quot; data-show-count=&quot;false&quot;&gt;Share on Twitter&lt;/a&gt; &lt;p&gt;This document is summarised in the table below. It shows the linear models underlying common parametric and non-parametric tests. Formulating all the tests in the same language highlights the many similarities between them. Get it &lt;a href=&quot;https://lindeloev.github.io/tests-as-linear/linear_tests_cheat_sheet.png&quot;&gt;as an image&lt;/a&gt; or &lt;a href=&quot;https://lindeloev.github.io/tests-as-linear/linear_tests_cheat_sheet.pdf&quot;&gt;as a PDF&lt;/a&gt;.&lt;/p&gt;
&lt;hr/&gt;&lt;p&gt;&lt;a href=&quot;https://lindeloev.github.io/tests-as-linear/linear_tests_cheat_sheet.pdf&quot;&gt;&lt;img src=&quot;https://lindeloev.github.io/tests-as-linear/linear_tests_cheat_sheet.png&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;hr/&gt;&lt;div id=&quot;the-simplicity-underlying-common-tests&quot; class=&quot;section level1&quot; readability=&quot;41.613259668508&quot;&gt;

&lt;p&gt;Most of the common statistical models (t-test, correlation, ANOVA; chi-square, etc.) are special cases of linear models or a very close approximation. This beautiful simplicity means that there is less to learn. In particular, it all comes down to &lt;span class=&quot;math inline&quot;&gt;\(y = a \cdot x + b\)&lt;/span&gt; which most students know from highschool. Unfortunately, stats intro courses are usually taught as if each test is an independent tool, needlessly making life more complicated for students and teachers alike.&lt;/p&gt;
&lt;p&gt;This needless complexity multiplies when students try to rote learn the parametric assumptions underlying each test separately rather than deducing them from the linear model.&lt;/p&gt;
&lt;p&gt;For this reason, I think that teaching linear models first and foremost and &lt;em&gt;then&lt;/em&gt; name-dropping the special cases along the way makes for an excellent teaching strategy, emphasizing &lt;em&gt;understanding&lt;/em&gt; over rote learning. Since linear models are the same across frequentist, Bayesian, and permutation-based inferences, I’d argue that it’s better to start with modeling than p-values, type-1 errors, Bayes factors, or other inferences.&lt;/p&gt;
&lt;p&gt;Concerning the teaching of &lt;em&gt;non-parametric&lt;/em&gt; tests in intro-courses, I think that we can justify &lt;a href=&quot;https://en.wikipedia.org/wiki/Lie-to-children&quot;&gt;lying-to-children&lt;/a&gt; and teach non-parametric tests as if they are merely ranked versions of the corresponding parametric tests. It is much better for students to think “ranks!” than to believe that you can magically throw away assumptions. Indeed, the Bayesian equivalents of non-parametric tests implemented in &lt;a href=&quot;https://jasp-stats.org&quot;&gt;JASP&lt;/a&gt; &lt;a href=&quot;https://arxiv.org/abs/1712.06941&quot;&gt;literally just do (latent) ranking&lt;/a&gt; and that’s it. For the frequentist non-parametric tests considered here, this approach is highly accurate for N &amp;gt; 15.&lt;/p&gt;
&lt;p&gt;Use the menu to jump to your favourite section. There are links to lots of similar (though more scattered) stuff under &lt;a href=&quot;https://lindeloev.github.io/tests-as-linear/#links&quot;&gt;sources&lt;/a&gt; and &lt;a href=&quot;https://lindeloev.github.io/tests-as-linear/#course&quot;&gt;teaching materials&lt;/a&gt;. I hope that you will join in suggesting improvements or submitting improvements yourself in &lt;a href=&quot;https://github.com/lindeloev/tests-as-linear&quot;&gt;the Github repo to this page&lt;/a&gt;. Let’s make it awesome!&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&quot;settings-and-toy-data&quot; class=&quot;section level1&quot; readability=&quot;50.5&quot;&gt;

Unfold this if you want to see functions and other settings for this notebook:
&lt;div class=&quot;fold s&quot; readability=&quot;50&quot;&gt;
&lt;pre class=&quot;r&quot;&gt;
&lt;code&gt;# Load packages for data handling and plotting
library(tidyverse)
library(patchwork)
library(broom)

# Reproducible &quot;random&quot; results
set.seed(40)

# To show tables. Rounds
print_df = function(D, decimals=4, navigate=FALSE) {
  DT::datatable(mutate_if(D, is.numeric, round, decimals), 
    rownames = FALSE,
    options = list(
      searching=FALSE, 
      lengthChange=FALSE, 
      ordering=FALSE, 
      autoWidth=TRUE, 
      bPaginate=navigate, 
      bInfo=navigate, 
      paging=navigate
    )
  )
}

# Generate normal data with known parameters
rnorm_fixed = function(N, mu=0, sd=1) scale(rnorm(N))*sd + mu

# Plot style.
theme_axis = function(P, jitter=FALSE, xlim=c(-0.5, 2), ylim=c(-0.5, 2), legend.position=NULL) {
  P = P + theme_bw(15) + 
  geom_segment(x=-1000, xend=1000, y=0, yend=0, lty=2, color='dark gray', lwd=0.5) +
  geom_segment(x=0, xend=0, y=-1000, yend=1000, lty=2, color='dark gray', lwd=0.5) +
  coord_cartesian(xlim=xlim, ylim=ylim) +
  theme(axis.title = element_blank(), 
        axis.text = element_blank(),
        axis.ticks = element_blank(),
        panel.border = element_blank(),
        panel.grid = element_blank(),
        legend.position = legend.position)
  
  # Return jittered or non-jittered plot?
  if(jitter) {
    P + geom_jitter(width=0.1, size=2)
  }
  else {
    P + geom_point(size=2)
  }
}&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;For a start, we’ll keep it simple and play with three standard normals in wide (&lt;code&gt;a&lt;/code&gt;, &lt;code&gt;b&lt;/code&gt;, &lt;code&gt;c&lt;/code&gt;) and long format (&lt;code&gt;value&lt;/code&gt;, &lt;code&gt;group&lt;/code&gt;):&lt;/p&gt;
&lt;pre class=&quot;r&quot;&gt;
&lt;code&gt;# Wide format (sort of)
y = rnorm_fixed(50, mu=0.3, sd=2)  # Almost zero mean
x = rnorm_fixed(50, mu=0, sd=1)  # Used in correlation where this is on x-axis
y2 = rnorm_fixed(50, mu=0.5, sd=1.5)  # Used in two means

# Long format data with indicator
value = c(y, y2)
group = rep(c('y1', 'y2'), each = 50)

# We'll need the signed rank function for a lot of the &quot;non-parametric&quot; tests
signed_rank = function(x) sign(x) * rank(abs(x))&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;div id=&quot;correlation&quot; class=&quot;section level1&quot; readability=&quot;37.877753129457&quot;&gt;

&lt;div id=&quot;theory-as-linear-models&quot; class=&quot;section level3&quot; readability=&quot;74.567668008671&quot;&gt;
&lt;h3&gt; Theory: As linear models&lt;/h3&gt;
&lt;p&gt;Model: the recipe for &lt;span class=&quot;math inline&quot;&gt;\(y\)&lt;/span&gt; is a slope (&lt;span class=&quot;math inline&quot;&gt;\(\beta_1\)&lt;/span&gt;) times &lt;span class=&quot;math inline&quot;&gt;\(x\)&lt;/span&gt; plus an intercept (&lt;span class=&quot;math inline&quot;&gt;\(\beta_0\)&lt;/span&gt;, aka a straight line).&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;math inline&quot;&gt;\(y = \beta_0 + \beta_1 x \qquad \mathcal{H}_0: \beta_1 = 0\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;… which is a math-y way of writing the good old &lt;span class=&quot;math inline&quot;&gt;\(y = ax + b\)&lt;/span&gt; (here ordered as &lt;span class=&quot;math inline&quot;&gt;\(y = b + ax\)&lt;/span&gt;). In R we are lazy and write &lt;code&gt;y ~ 1 + x&lt;/code&gt; which R reads like &lt;code&gt;y = 1*number + x*othernumber&lt;/code&gt; and the task of t-tests, lm, etc., is simply to find the numbers that best predict &lt;span class=&quot;math inline&quot;&gt;\(y\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Either way you write it, it’s an intercept (&lt;span class=&quot;math inline&quot;&gt;\(\beta_0\)&lt;/span&gt;) and a slope (&lt;span class=&quot;math inline&quot;&gt;\(\beta_1\)&lt;/span&gt;) yielding a straight line:&lt;/p&gt;
&lt;div class=&quot;fold s&quot; readability=&quot;41&quot;&gt;
&lt;pre class=&quot;r&quot;&gt;
&lt;code&gt;# Fixed correlation
D_correlation = data.frame(MASS::mvrnorm(30, mu=c(0.9, 0.9), Sigma=matrix(c(1, 0.8, 1, 0.8), ncol=2), empirical=TRUE))  # Correlated data

# Add labels (for next plot)
D_correlation$label_num = sprintf('(%.1f,%.1f)', D_correlation$X1, D_correlation$X2)
D_correlation$label_rank = sprintf('(%i,%i)', rank(D_correlation$X1), rank(D_correlation$X2))

# Plot it
fit = lm(I(X2*0.5+0.4) ~ I(X1*0.5+0.2), D_correlation)
intercept_pearson = coefficients(fit)[1]

P_pearson = ggplot(D_correlation, aes(x=X1*0.5+0.2, y=X2*0.5+0.4)) +
  geom_smooth(method=lm, se=FALSE, lwd=2, aes(colour='beta_1')) + 
  geom_segment(x=-100, xend=100, 
               y=intercept_pearson, yend=intercept_pearson, 
               lwd=2, aes(color=&quot;beta_0&quot;)) + 
  scale_color_manual(name=NULL, values=c(&quot;blue&quot;, &quot;red&quot;), labels=c(bquote(beta[0]*&quot; (intercept)&quot;), bquote(beta[1]*&quot; (slope)&quot;)))
  
theme_axis(P_pearson, legend.position=c(0.4, 0.9))&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;img src=&quot;https://lindeloev.github.io/tests-as-linear/index_files/figure-html/unnamed-chunk-4-1.png&quot; width=&quot;576&quot;/&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;This is often simply called a &lt;strong&gt;regression&lt;/strong&gt; model which can be extended to &lt;strong&gt;multiple regression&lt;/strong&gt; where there are several &lt;span class=&quot;math inline&quot;&gt;\(\beta\)&lt;/span&gt;s and on the right-hand side multiplied with the predictors. Everything below, from &lt;a href=&quot;https://lindeloev.github.io/tests-as-linear/#t1&quot;&gt;one-sample t-test&lt;/a&gt; to &lt;a href=&quot;https://lindeloev.github.io/tests-as-linear/#anova2&quot;&gt;two-way ANOVA&lt;/a&gt; are just special cases of this system. Nothing more, nothing less.&lt;/p&gt;
&lt;p&gt;As the name implies, the &lt;strong&gt;Spearman rank correlation&lt;/strong&gt; is a &lt;strong&gt;Pearson correlation&lt;/strong&gt; on rank-transformed &lt;span class=&quot;math inline&quot;&gt;\(x\)&lt;/span&gt; and &lt;span class=&quot;math inline&quot;&gt;\(y\)&lt;/span&gt;:&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;math inline&quot;&gt;\(rank(y) = \beta_0 + \beta_1 \cdot rank(x) \qquad \mathcal{H}_0: \beta_1 = 0\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The correlation coefficient of the linear model is identical to a “real” Pearson correlation, but p-values are an approximation which is is &lt;a href=&quot;https://lindeloev.github.io/tests-as-linear/simulate_spearman.html&quot;&gt;appropriate for samples greater than N=10 and almost perfect when N &amp;gt; 20&lt;/a&gt;. Such a nice and non-mysterious equivalence that many students are left unaware of! Visualizing them side by side including data labels, we see this rank-transformation in action:&lt;/p&gt;
&lt;div class=&quot;fold s&quot; readability=&quot;39&quot;&gt;
&lt;pre class=&quot;r&quot;&gt;
&lt;code&gt;# Spearman intercept
intercept_spearman = coefficients(lm(rank(X2) ~ rank(X1), D_correlation))[1]

# Spearman plot
P_spearman = ggplot(D_correlation, aes(x=rank(X1), y=rank(X2))) +
  geom_smooth(method=lm, se=FALSE, lwd=2, aes(color='beta_1')) + 
  geom_text(aes(label=label_rank), nudge_y=1, size=3, color='dark gray') + 
  geom_segment(x=-100, xend=100, 
               y=intercept_spearman, yend=intercept_spearman, 
               lwd=2, aes(color='beta_0')) + 
  scale_color_manual(name=NULL, values=c(&quot;blue&quot;, &quot;red&quot;), labels=c(bquote(beta[0]*&quot; (intercept)&quot;), bquote(beta[1]*&quot; (slope)&quot;)))

# Stich together using patchwork
(theme_axis(P_pearson, legend.position=c(0.5, 0.1)) + geom_text(aes(label=label_num), nudge_y=0.1, size=3, color='dark gray') + labs(title='         Pearson')) + (theme_axis(P_spearman, xlim=c(-7.5, 30), ylim=c(-7.5, 30), legend.position=c(0.5, 0.1)) + labs(title='         Spearman'))&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;img src=&quot;https://lindeloev.github.io/tests-as-linear/index_files/figure-html/unnamed-chunk-5-1.png&quot; width=&quot;768&quot;/&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&quot;r-code-pearson-correlation&quot; class=&quot;section level3&quot; readability=&quot;26.5&quot;&gt;
&lt;h3&gt; R code: Pearson correlation&lt;/h3&gt;
&lt;p&gt;It couldn’t be much simpler to run these models in R. They yield identical &lt;code&gt;p&lt;/code&gt; and &lt;code&gt;t&lt;/code&gt;, but there’s a catch: &lt;code&gt;lm&lt;/code&gt; gives you the &lt;em&gt;slope&lt;/em&gt; and even though that is usually much more interpretable and informative than the &lt;em&gt;correlation coefficient&lt;/em&gt; &lt;em&gt;r&lt;/em&gt;, you may still want &lt;em&gt;r&lt;/em&gt;. Luckily, the slope becomes &lt;code&gt;r&lt;/code&gt; if &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt; have a standard deviation of exactly 1. You can do this using &lt;code&gt;scale(x)&lt;/code&gt; or &lt;code&gt;I(x/sd(x))&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&quot;r&quot;&gt;
&lt;code&gt;a = cor.test(y, x, method = &quot;pearson&quot;) # Built-in
b = lm(y ~ 1 + x) # Equivalent linear model: y = Beta0*1 + Beta1*x
c = lm(scale(y) ~ 1 + scale(x))  # On scaled vars to recover r&lt;/code&gt;
&lt;/pre&gt;
Results:

&lt;div class=&quot;fold o&quot; readability=&quot;16&quot;&gt;
&lt;pre&gt;
&lt;code&gt;## 
##  Pearson's product-moment correlation
## 
## data:  y and x
## t = -1.6507, df = 48, p-value = 0.1053
## alternative hypothesis: true correlation is not equal to 0
## 95 percent confidence interval:
##  -0.47920849  0.04978276
## sample estimates:
##        cor 
## -0.2317767 
## 
## 
## Call:
## lm(formula = y ~ 1 + x)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -3.3393 -1.6593  0.3349  1.3629  3.5214 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&amp;gt;|t|)
## (Intercept)   0.3000     0.2780   1.079    0.286
## x            -0.4636     0.2808  -1.651    0.105
## 
## Residual standard error: 1.966 on 48 degrees of freedom
## Multiple R-squared:  0.05372,    Adjusted R-squared:  0.03401 
## F-statistic: 2.725 on 1 and 48 DF,  p-value: 0.1053
## 
## 
## Call:
## lm(formula = scale(y) ~ 1 + scale(x))
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -1.6697 -0.8297  0.1675  0.6815  1.7607 
## 
## Coefficients:
##               Estimate Std. Error t value Pr(&amp;gt;|t|)
## (Intercept) -1.341e-17  1.390e-01   0.000    1.000
## scale(x)    -2.318e-01  1.404e-01  -1.651    0.105
## 
## Residual standard error: 0.9828 on 48 degrees of freedom
## Multiple R-squared:  0.05372,    Adjusted R-squared:  0.03401 
## F-statistic: 2.725 on 1 and 48 DF,  p-value: 0.1053&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The CIs are not exactly identical, but very close.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&quot;r-code-spearman-correlation&quot; class=&quot;section level3&quot; readability=&quot;23&quot;&gt;
&lt;h3&gt; R code: Spearman correlation&lt;/h3&gt;
&lt;p&gt;Note that we can interpret the slope which is the number of ranks &lt;span class=&quot;math inline&quot;&gt;\(y\)&lt;/span&gt; change for each rank on &lt;span class=&quot;math inline&quot;&gt;\(x\)&lt;/span&gt;. I think that this is a pretty interesting number. However, the intercept is less interpretable since it lies at &lt;span class=&quot;math inline&quot;&gt;\(rank(x) = 0\)&lt;/span&gt; which is impossible since x starts at 1.&lt;/p&gt;
&lt;p&gt;See the identical &lt;code&gt;r&lt;/code&gt; (now “rho”) and &lt;code&gt;p&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&quot;r&quot;&gt;
&lt;code&gt;# Spearman correlation
a = cor.test(y, x, method = &quot;spearman&quot;) # Built-in
b = lm(rank(y) ~ 1 + rank(x)) # Equivalent linear model&lt;/code&gt;
&lt;/pre&gt;
Let’s look at the results:

&lt;div class=&quot;fold o&quot; readability=&quot;13&quot;&gt;
&lt;pre&gt;
&lt;code&gt;## 
##  Spearman's rank correlation rho
## 
## data:  y and x
## S = 25544, p-value = 0.1135
## alternative hypothesis: true rho is not equal to 0
## sample estimates:
##        rho 
## -0.2266026 
## 
## 
## Call:
## lm(formula = rank(y) ~ 1 + rank(x))
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -26.4655 -11.5603   0.4458  11.5628  25.6921 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&amp;gt;|t|)    
## (Intercept)  31.2784     4.1191   7.593 9.11e-10 ***
## rank(x)      -0.2266     0.1406  -1.612    0.114    
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 14.35 on 48 degrees of freedom
## Multiple R-squared:  0.05135,    Adjusted R-squared:  0.03159 
## F-statistic: 2.598 on 1 and 48 DF,  p-value: 0.1135&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&quot;one-mean&quot; class=&quot;section level1&quot;&gt;

&lt;div id=&quot;t1&quot; class=&quot;section level2&quot; readability=&quot;26.094102228047&quot;&gt;
&lt;h2&gt; One sample t-test and Wilcoxon signed-rank&lt;/h2&gt;
&lt;div id=&quot;theory-as-linear-models-1&quot; class=&quot;section level3&quot; readability=&quot;48.384573601304&quot;&gt;
&lt;h3&gt; Theory: As linear models&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;t-test&lt;/strong&gt; model: A single number predicts &lt;span class=&quot;math inline&quot;&gt;\(y\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;math inline&quot;&gt;\(y = \beta_0 \qquad \mathcal{H}_0: \beta_0 = 0\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;In other words, it’s our good old &lt;span class=&quot;math inline&quot;&gt;\(y = \beta_0 + \beta_1*x\)&lt;/span&gt; where the last term is gone since there is no &lt;span class=&quot;math inline&quot;&gt;\(x\)&lt;/span&gt; (essentially &lt;span class=&quot;math inline&quot;&gt;\(x=0\)&lt;/span&gt;, see left figure below).&lt;/p&gt;
&lt;p&gt;The same is to a very close approximately true for &lt;strong&gt;Wilcoxon signed-rank test&lt;/strong&gt;, just with the signed ranks of &lt;span class=&quot;math inline&quot;&gt;\(y\)&lt;/span&gt; instead of &lt;span class=&quot;math inline&quot;&gt;\(y\)&lt;/span&gt; itself (see right panel below and caveat in the end of this section):&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;math inline&quot;&gt;\(signed\_rank(y) = \beta_0\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://lindeloev.github.io/tests-as-linear/simulate_wilcoxon.html&quot;&gt;This approximation is good enough when the sample size is larger than 14 and almost perfect if the sample size is larger than 50&lt;/a&gt;.&lt;/p&gt;
&lt;div class=&quot;fold s&quot; readability=&quot;47&quot;&gt;
&lt;pre class=&quot;r&quot;&gt;
&lt;code&gt;# T-test
D_t1 = data.frame(y=rnorm_fixed(20, 0.5, 0.6),
                  x=runif(20, 0.93, 1.07))  # Fix mean and SD

P_t1 = ggplot(D_t1, aes(y=y, x=0)) + 
  stat_summary(fun.y=mean, geom = &quot;errorbar&quot;, aes(ymax = ..y.., ymin = ..y.., color='beta_0'), lwd=2) +
  scale_color_manual(name=NULL, values=c(&quot;blue&quot;), labels=c(bquote(beta[0]*&quot; (intercept)&quot;))) +
  
  geom_text(aes(label=round(y, 1)), nudge_x = 0.2, size=3, color='dark gray') + 
  labs(title='         T-test')

# Wilcoxon
D_t1_rank = data.frame(y = signed_rank(D_t1$y))

P_t1_rank = ggplot(D_t1_rank, aes(y=y, x=0)) + 
  stat_summary(fun.y=mean, geom = &quot;errorbar&quot;, aes(ymax = ..y.., ymin = ..y.., color='beta_0'), lwd=2) +
  scale_color_manual(name=NULL, values=c(&quot;blue&quot;), labels=c(bquote(beta[0]*&quot; (intercept)&quot;))) +

  geom_text(aes(label=y), nudge_x=0.2, size=3, color='dark gray') + 
  labs(title='         Wilcoxon')


# Stich together using patchwork
theme_axis(P_t1, ylim=c(-1, 2), legend.position=c(0.6, 0.1)) + 
  theme_axis(P_t1_rank, ylim=NULL,  legend.position=c(0.6, 0.1))&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;img src=&quot;https://lindeloev.github.io/tests-as-linear/index_files/figure-html/unnamed-chunk-12-1.png&quot; width=&quot;672&quot;/&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;One interesting implication is that &lt;em&gt;many “non-parametric tests” are precisely as parametric as their parametric counterparts with means, standard deviations, homogeneity of variance, etc. - just on transformed data&lt;/em&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&quot;r-code-one-sample-t-test&quot; class=&quot;section level3&quot; readability=&quot;16.5&quot;&gt;
&lt;h3&gt; R code: One-sample t-test&lt;/h3&gt;
&lt;p&gt;Try running the R code below and see that the linear model (&lt;code&gt;lm&lt;/code&gt;) produces the same &lt;span class=&quot;math inline&quot;&gt;\(t\)&lt;/span&gt;, &lt;span class=&quot;math inline&quot;&gt;\(p\)&lt;/span&gt;, and &lt;span class=&quot;math inline&quot;&gt;\(r\)&lt;/span&gt; as the built-in &lt;code&gt;t.test&lt;/code&gt;. The confidence interval is not presented in the output of &lt;code&gt;lm&lt;/code&gt; but is also identical if you use &lt;code&gt;confint(lm(...))&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&quot;r&quot;&gt;
&lt;code&gt;# Built-in t-test
a = t.test(y)

# Equivalent linear model: intercept-only
b = lm(y ~ 1)&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;Results:&lt;/p&gt;

&lt;div class=&quot;fold o&quot; readability=&quot;12&quot;&gt;
&lt;pre&gt;
&lt;code&gt;## 
##  One Sample t-test
## 
## data:  y
## t = 1.0607, df = 49, p-value = 0.294
## alternative hypothesis: true mean is not equal to 0
## 95 percent confidence interval:
##  -0.2683937  0.8683937
## sample estimates:
## mean of x 
##       0.3 
## 
## 
## Call:
## lm(formula = y ~ 1)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -3.521 -1.673  0.481  1.427  3.795 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&amp;gt;|t|)
## (Intercept)   0.3000     0.2828   1.061    0.294
## 
## Residual standard error: 2 on 49 degrees of freedom&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&quot;r-code-wilcoxon-signed-rank-test&quot; class=&quot;section level3&quot; readability=&quot;19&quot;&gt;
&lt;h3&gt; R code: Wilcoxon signed-rank test&lt;/h3&gt;
&lt;p&gt;In addition to matching &lt;code&gt;p&lt;/code&gt;-values, &lt;code&gt;lm&lt;/code&gt; also gives us the mean signed rank, which I find to be an informative number.&lt;/p&gt;
&lt;pre class=&quot;r&quot;&gt;
&lt;code&gt;# Built-in
a = wilcox.test(y)

# Equivalent linear model
b = lm(signed_rank(y) ~ 1)  # See? Same as above, just on signed ranks

# Bonus: of course also works for one-sample t-test
c = t.test(signed_rank(y))&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;Results:&lt;/p&gt;

&lt;div class=&quot;fold o&quot; readability=&quot;13&quot;&gt;
&lt;pre&gt;
&lt;code&gt;## 
##  Wilcoxon signed rank test with continuity correction
## 
## data:  y
## V = 731, p-value = 0.3693
## alternative hypothesis: true location is not equal to 0
## 
## 
## Call:
## lm(formula = signed_rank(y) ~ 1)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -49.74 -25.49   4.76  22.76  46.26 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&amp;gt;|t|)
## (Intercept)    3.740      4.151   0.901    0.372
## 
## Residual standard error: 29.36 on 49 degrees of freedom
## 
## 
##  One Sample t-test
## 
## data:  signed_rank(y)
## t = 0.90088, df = 49, p-value = 0.3721
## alternative hypothesis: true mean is not equal to 0
## 95 percent confidence interval:
##  -4.60275 12.08275
## sample estimates:
## mean of x 
##      3.74&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&quot;tpair&quot; class=&quot;section level2&quot; readability=&quot;23.37216&quot;&gt;
&lt;h2&gt; Paired samples t-test and Wilcoxon matched pairs&lt;/h2&gt;
&lt;div id=&quot;theory-as-linear-models-2&quot; class=&quot;section level3&quot; readability=&quot;29.558823529412&quot;&gt;
&lt;h3&gt; Theory: As linear models&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;t-test&lt;/strong&gt; model: a single number (intercept) predicts the pairwise differences.&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;math inline&quot;&gt;\(y_2-y_1 = \beta_0 \qquad \mathcal{H}_0: \beta_0 = 0\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;This means that there is just one &lt;span class=&quot;math inline&quot;&gt;\(y = y_2 - y_1\)&lt;/span&gt; to predict and it becomes a &lt;a href=&quot;https://lindeloev.github.io/tests-as-linear/#t1&quot;&gt;one-sample t-test&lt;/a&gt; on the pairwise differences. The visualization is therefore also the same as for the one-sample t-test. At the risk of overcomplicating a simple substraction, you can think of these pairwise differences as slopes (see left panel of the figure), which we can represent as y-offsets (see right panel of the figure):&lt;/p&gt;
&lt;div class=&quot;fold s&quot; readability=&quot;21&quot;&gt;
&lt;pre class=&quot;r&quot;&gt;
&lt;code&gt;# Data for plot
N = nrow(D_t1)
start = rnorm_fixed(N, 0.2, 0.3)
D_tpaired = data.frame(x = rep(c(0, 1), each=N), y = c(start, start + D_t1$y), id=1:N)

# Plot
P_tpaired = ggplot(D_tpaired, aes(x=x, y=y)) + 
  geom_line(aes(group=id)) + 
  labs(title='          Pairs')

# Use patchwork to put them side-by-side
theme_axis(P_tpaired) + theme_axis(P_t1, legend.position=c(0.6, 0.1))&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;img src=&quot;https://lindeloev.github.io/tests-as-linear/index_files/figure-html/unnamed-chunk-19-1.png&quot; width=&quot;672&quot;/&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Similarly, the &lt;strong&gt;Wilcoxon matched pairs&lt;/strong&gt; only differ from &lt;strong&gt;Wilcoxon signed-rank&lt;/strong&gt; in that it’s testing the signed ranks of the pairwise &lt;span class=&quot;math inline&quot;&gt;\(y-x\)&lt;/span&gt; differences.&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;math inline&quot;&gt;\(signed\_rank(y_2-y_1) = \beta_0 \qquad \mathcal{H}_0: \beta_0 = 0\)&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&quot;r-code-paired-sample-t-test&quot; class=&quot;section level3&quot; readability=&quot;13.5&quot;&gt;
&lt;h3&gt; R code: Paired sample t-test&lt;/h3&gt;
&lt;pre class=&quot;r&quot;&gt;
&lt;code&gt;a = t.test(y, y2, paired = TRUE) # Built-in paired t-test
b = lm(y - y2 ~ 1) # Equivalent linear model&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;Results:&lt;/p&gt;

&lt;div class=&quot;fold o&quot; readability=&quot;12&quot;&gt;
&lt;pre&gt;
&lt;code&gt;## 
##  Paired t-test
## 
## data:  y and y2
## t = -0.52642, df = 49, p-value = 0.601
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  -0.9634894  0.5634894
## sample estimates:
## mean of the differences 
##                    -0.2 
## 
## 
## Call:
## lm(formula = y - y2 ~ 1)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -6.5253 -1.5642 -0.0844  1.9715  5.0361 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&amp;gt;|t|)
## (Intercept)  -0.2000     0.3799  -0.526    0.601
## 
## Residual standard error: 2.686 on 49 degrees of freedom&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&quot;r-code-wilcoxon-matched-pairs&quot; class=&quot;section level3&quot; readability=&quot;24&quot;&gt;
&lt;h3&gt; R code: Wilcoxon matched pairs&lt;/h3&gt;
&lt;p&gt;Again, we do the signed-ranks trick. This is still an approximation, but a close one:&lt;/p&gt;
&lt;pre class=&quot;r&quot;&gt;
&lt;code&gt;# Built-in Wilcoxon matched pairs
a = wilcox.test(y, y2, paired = TRUE)

# Equivalent linear model:
b = lm(signed_rank(y - y2) ~ 1)

# Bonus: identical to one-sample t-test ong signed ranks
c = t.test(signed_rank(y - y2))&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;Results:&lt;/p&gt;

&lt;div class=&quot;fold o&quot; readability=&quot;13&quot;&gt;
&lt;pre&gt;
&lt;code&gt;## 
##  Wilcoxon signed rank test with continuity correction
## 
## data:  y and y2
## V = 614, p-value = 0.8243
## alternative hypothesis: true location shift is not equal to 0
## 
## 
## Call:
## lm(formula = signed_rank(y - y2) ~ 1)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -49.06 -23.81  -2.56  26.19  46.94 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&amp;gt;|t|)
## (Intercept)   -0.940      4.184  -0.225    0.823
## 
## Residual standard error: 29.58 on 49 degrees of freedom
## 
## 
##  One Sample t-test
## 
## data:  signed_rank(y - y2)
## t = -0.22469, df = 49, p-value = 0.8232
## alternative hypothesis: true mean is not equal to 0
## 95 percent confidence interval:
##  -9.347227  7.467227
## sample estimates:
## mean of x 
##     -0.94&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;For large sample sizes (N &amp;gt;&amp;gt; 100), this approaches the &lt;strong&gt;sign test&lt;/strong&gt; to a reasonable degree, but this approximation is too inaccurate to flesh out here.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&quot;two-means&quot; class=&quot;section level1&quot; readability=&quot;10.762569832402&quot;&gt;

&lt;div id=&quot;t2&quot; class=&quot;section level2&quot; readability=&quot;47.3558125097&quot;&gt;
&lt;h2&gt; Independent t-test and Mann-Whitney U&lt;/h2&gt;
&lt;div id=&quot;theory-as-linear-models-3&quot; class=&quot;section level3&quot; readability=&quot;19.933110367893&quot;&gt;
&lt;h3&gt; Theory: As linear models&lt;/h3&gt;
&lt;p&gt;Independent t-test model: two means predict &lt;span class=&quot;math inline&quot;&gt;\(y\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;math inline&quot;&gt;\(y_i = \beta_0 + \beta_1 x_i \qquad \mathcal{H}_0: \beta_1 = 0\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&quot;math inline&quot;&gt;\(x_i\)&lt;/span&gt; is an indicator (0 or 1) saying whether data point &lt;span class=&quot;math inline&quot;&gt;\(i\)&lt;/span&gt; was sampled from one or the other group. &lt;a href=&quot;https://en.wikipedia.org/wiki/Dummy_variable_(statistics)&quot;&gt;Indicator variables (also called “dummy coding”)&lt;/a&gt; underly a lot of linear models and we’ll take an aside to see how it works in a minute.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Mann-Whitney U&lt;/strong&gt; (also known as &lt;strong&gt;Wilcoxon signed-rank test&lt;/strong&gt; for two independent groups) is the same model to a very close approximation, just on the ranks of &lt;span class=&quot;math inline&quot;&gt;\(x\)&lt;/span&gt; and &lt;span class=&quot;math inline&quot;&gt;\(y\)&lt;/span&gt; instead of the actual values:&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;math inline&quot;&gt;\(rank(y_i) = \beta_0 + \beta_1 x_i \qquad \mathcal{H}_0: \beta_1 = 0\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;To me, equivalences like this make “non-parametric” statistics much easier to understand. The approximation is appropriate &lt;a href=&quot;https://lindeloev.github.io/tests-as-linear/simulate_mannwhitney.html&quot;&gt;when the sample size is larger than 11 in each group and virtually perfect when N &amp;gt; 30 in each group&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&quot;dummy&quot; class=&quot;section level3&quot; readability=&quot;37&quot;&gt;
&lt;h3&gt; Theory: Dummy coding&lt;/h3&gt;
&lt;p&gt;Dummy coding can be understood visually. The indicator is on the x-axis so data points from the first group are located at &lt;span class=&quot;math inline&quot;&gt;\(x = 0\)&lt;/span&gt; and data points from the second group is located at &lt;span class=&quot;math inline&quot;&gt;\(x = 1\)&lt;/span&gt;. Then &lt;span class=&quot;math inline&quot;&gt;\(\beta_0\)&lt;/span&gt; is the intercept (red line) and &lt;span class=&quot;math inline&quot;&gt;\(\beta_1\)&lt;/span&gt; is the slope between the two means (green line). Why? Because when &lt;span class=&quot;math inline&quot;&gt;\(\Delta x = 1\)&lt;/span&gt; the slope equals the difference because:&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;math inline&quot;&gt;\(slope = \Delta y / \Delta x = \Delta y / 1 = \Delta y = difference\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Magic! Even categorical differences can be modelled using linear models! It’s a true Swizz army knife.&lt;/p&gt;
&lt;div class=&quot;fold s&quot; readability=&quot;49&quot;&gt;
&lt;pre class=&quot;r&quot;&gt;
&lt;code&gt;# Data
N = 20  # Number of data points per group
D_t2 = data.frame(
  x = rep(c(0, 1), each=N),
  y = c(rnorm_fixed(N, 0.3, 0.3), rnorm_fixed(N, 1.3, 0.3))
)

# Plot
P_t2 = ggplot(D_t2, aes(x=x, y=y)) + 
  stat_summary(fun.y=mean, geom = &quot;errorbar&quot;, aes(ymax = ..y.., ymin = ..y.., color='something'), lwd=2) +
  geom_segment(x=-10, xend=10, y=0.3, yend=0.3, lwd=2, aes(color='beta_0')) + 
  geom_segment(x=0, xend=1, y=0.3, yend=1.3, lwd=2, aes(color='beta_1')) + 
  
  scale_color_manual(name=NULL, values=c(&quot;blue&quot;, &quot;red&quot;, &quot;darkblue&quot;), labels=c(bquote(beta[0]*&quot; (group 1 mean)&quot;), bquote(beta[1]*&quot; (slope = difference)&quot;), bquote(beta[0]+beta[1]%.%1*&quot; (group 2 mean)&quot;)))
  #scale_x_discrete(breaks=c(0.5, 1.5), labels=c('1', '2'))

theme_axis(P_t2, jitter=TRUE, xlim=c(-0.3, 2), legend.position=c(0.53, 0.08))&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;img src=&quot;https://lindeloev.github.io/tests-as-linear/index_files/figure-html/unnamed-chunk-26-1.png&quot; width=&quot;576&quot;/&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&quot;dummy2&quot; class=&quot;section level3&quot; readability=&quot;37&quot;&gt;
&lt;h3&gt; Theory: Dummy coding (continued)&lt;/h3&gt;
&lt;p&gt;If you feel like you get dummy coding now, just skip ahead to the next section. Here is a more elaborate explanation of dummy coding:&lt;/p&gt;
&lt;p&gt;If a data point was sampled from the first group, i.e., when &lt;span class=&quot;math inline&quot;&gt;\(x_i = 0\)&lt;/span&gt;, the model simply becomes &lt;span class=&quot;math inline&quot;&gt;\(y = \beta_0 + \beta_1 \cdot 0 = \beta_0\)&lt;/span&gt;. In other words, the model predicts that that data point is &lt;span class=&quot;math inline&quot;&gt;\(beta_0\)&lt;/span&gt;. It turns out that the &lt;span class=&quot;math inline&quot;&gt;\(\beta\)&lt;/span&gt; which best predicts a set of data points is the &lt;em&gt;mean&lt;/em&gt; of those data points, so &lt;span class=&quot;math inline&quot;&gt;\(\beta_0\)&lt;/span&gt; is the mean of group 1.&lt;/p&gt;
&lt;p&gt;On the other hand, data points sampled from the second group would have &lt;span class=&quot;math inline&quot;&gt;\(x_i = 1\)&lt;/span&gt; so the model becomes &lt;span class=&quot;math inline&quot;&gt;\(y_i = \beta_0 + \beta_1\cdot 1 = \beta_0 + \beta_1\)&lt;/span&gt;. In other words, we add &lt;span class=&quot;math inline&quot;&gt;\(\beta_1\)&lt;/span&gt; to “shift” from the mean of the first group to the mean of the second group. Thus &lt;span class=&quot;math inline&quot;&gt;\(\beta_1\)&lt;/span&gt; becomes the &lt;em&gt;mean difference&lt;/em&gt; between the groups.&lt;/p&gt;
&lt;p&gt;As an example, say group 1 is 25 years old (&lt;span class=&quot;math inline&quot;&gt;\(\beta_0 = 25\)&lt;/span&gt;) and group 2 is 28 years old (&lt;span class=&quot;math inline&quot;&gt;\(\beta_1 = 3\)&lt;/span&gt;), then the model for a person in group 1 is &lt;span class=&quot;math inline&quot;&gt;\(y = 25 + 3 \cdot 0 = 25\)&lt;/span&gt; and the model for a person in group 2 is &lt;span class=&quot;math inline&quot;&gt;\(y = 25 + 3 \cdot 1 = 28\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Hooray, it works! For first-timers it takes a few moments to understand dummy coding, but you only need to know addition and multiplication to get there!&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&quot;r-code-independent-t-test&quot; class=&quot;section level3&quot; readability=&quot;32.5&quot;&gt;
&lt;h3&gt; R code: independent t-test&lt;/h3&gt;
&lt;p&gt;As a reminder, when we write &lt;code&gt;y ~ 1 + x&lt;/code&gt; in R, it is shorthand for &lt;span class=&quot;math inline&quot;&gt;\(y = \beta_0 \cdot 1 + \beta_1 \cdot x\)&lt;/span&gt; and R goes on computing the &lt;span class=&quot;math inline&quot;&gt;\(\beta\)&lt;/span&gt;s for you. Thus &lt;span class=&quot;math inline&quot;&gt;\(y ~ 1 + x\)&lt;/span&gt; is the R-way of writing &lt;span class=&quot;math inline&quot;&gt;\(y = a \cdot x + b\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Notice the identical &lt;code&gt;t&lt;/code&gt;, &lt;code&gt;df&lt;/code&gt;, &lt;code&gt;p&lt;/code&gt;, and estimates. We can get the confidence interval by running &lt;code&gt;confint(lm(...))&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&quot;r&quot;&gt;
&lt;code&gt;# Built-in independent t-test on wide data
a = t.test(y, y2, var.equal = TRUE)

# Be explicit about the underlying linear model by hand-dummy-coding:
group_y2 = ifelse(group == 'y2', 1, 0)  # 1 if group == y2, 0 otherwise
b = lm(value ~ 1 + group_y2)  # Using our hand-made dummy regressor

# Note: We could also do the dummy-coding in the model 
# specification itself. Same result.
c = lm(value ~ 1 + I(group=='y2'))&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;Results:&lt;/p&gt;

&lt;div class=&quot;fold o&quot; readability=&quot;16&quot;&gt;
&lt;pre&gt;
&lt;code&gt;## 
##  Two Sample t-test
## 
## data:  y and y2
## t = -0.56569, df = 98, p-value = 0.5729
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  -0.9016152  0.5016152
## sample estimates:
## mean of x mean of y 
##       0.3       0.5 
## 
## 
## Call:
## lm(formula = value ~ 1 + group_y2)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -3.5211 -1.1259 -0.2124  0.9151  4.9268 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&amp;gt;|t|)
## (Intercept)   0.3000     0.2500   1.200    0.233
## group_y2      0.2000     0.3536   0.566    0.573
## 
## Residual standard error: 1.768 on 98 degrees of freedom
## Multiple R-squared:  0.003255,   Adjusted R-squared:  -0.006916 
## F-statistic:  0.32 on 1 and 98 DF,  p-value: 0.5729
## 
## 
## Call:
## lm(formula = value ~ 1 + I(group == &quot;y2&quot;))
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -3.5211 -1.1259 -0.2124  0.9151  4.9268 
## 
## Coefficients:
##                      Estimate Std. Error t value Pr(&amp;gt;|t|)
## (Intercept)            0.3000     0.2500   1.200    0.233
## I(group == &quot;y2&quot;)TRUE   0.2000     0.3536   0.566    0.573
## 
## Residual standard error: 1.768 on 98 degrees of freedom
## Multiple R-squared:  0.003255,   Adjusted R-squared:  -0.006916 
## F-statistic:  0.32 on 1 and 98 DF,  p-value: 0.5729&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&quot;r-code-mann-whitney-u&quot; class=&quot;section level3&quot; readability=&quot;13&quot;&gt;
&lt;h3&gt; R code: Mann-Whitney U&lt;/h3&gt;
&lt;pre class=&quot;r&quot;&gt;
&lt;code&gt;# Wilcoxon / Mann-Whitney U
a = wilcox.test(y, y2)

# As linear model with our dummy-coded group_y2:
b = lm(rank(value) ~ 1 + group_y2)  # compare to linear model above&lt;/code&gt;
&lt;/pre&gt;

&lt;div class=&quot;fold o&quot; readability=&quot;13&quot;&gt;
&lt;pre&gt;
&lt;code&gt;## 
##  Wilcoxon rank sum test with continuity correction
## 
## data:  y and y2
## W = 1211, p-value = 0.7907
## alternative hypothesis: true location shift is not equal to 0
## 
## 
## Call:
## lm(formula = rank(value) ~ 1 + group_y2)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -48.72 -24.64  -0.78  24.22  48.72 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&amp;gt;|t|)    
## (Intercept)   49.720      4.122  12.061   &amp;lt;2e-16 ***
## group_y2       1.560      5.830   0.268     0.79    
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 29.15 on 98 degrees of freedom
## Multiple R-squared:  0.0007302,  Adjusted R-squared:  -0.009466 
## F-statistic: 0.07161 on 1 and 98 DF,  p-value: 0.7896&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&quot;welch&quot; class=&quot;section level2&quot; readability=&quot;20.240506329114&quot;&gt;
&lt;h2&gt; Welch’s t-test&lt;/h2&gt;
&lt;p&gt;This is identical to the (Student’s) &lt;a href=&quot;https://lindeloev.github.io/tests-as-linear/#t2&quot;&gt;independent t-test&lt;/a&gt; above except that Student’s assumes identical variances and &lt;strong&gt;Welch’s t-test&lt;/strong&gt; does not. So the linear model is the same and the trick is in the variances, which I won’t go further into here.&lt;/p&gt;
&lt;pre class=&quot;r&quot;&gt;
&lt;code&gt;# Built-in
a = t.test(y, y2, var.equal=FALSE)

# As linear model with per-group variances
b = nlme::gls(value ~ 1 + group_y2, weights = nlme::varIdent(form=~1|group), method=&quot;ML&quot;)&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;Results:&lt;/p&gt;

&lt;div class=&quot;fold o&quot; readability=&quot;12&quot;&gt;
&lt;pre&gt;
&lt;code&gt;## 
##  Welch Two Sample t-test
## 
## data:  y and y2
## t = -0.56569, df = 90.875, p-value = 0.573
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  -0.9023034  0.5023034
## sample estimates:
## mean of x mean of y 
##       0.3       0.5 
## 
## Generalized least squares fit by maximum likelihood
##   Model: value ~ 1 + group_y2 
##   Data: NULL 
##        AIC      BIC    logLik
##   399.6287 410.0493 -195.8143
## 
## Variance function:
##  Structure: Different standard deviations per stratum
##  Formula: ~1 | group 
##  Parameter estimates:
##   y1   y2 
## 1.00 0.75 
## 
## Coefficients:
##             Value Std.Error   t-value p-value
## (Intercept)   0.3 0.2828427 1.0606602  0.2915
## group_y2      0.2 0.3535534 0.5656854  0.5729
## 
##  Correlation: 
##          (Intr)
## group_y2 -0.8  
## 
## Standardized residuals:
##        Min         Q1        Med         Q3        Max 
## -1.7784113 -0.7177541 -0.1430665  0.5635189  3.3178730 
## 
## Residual standard error: 1.979899 
## Degrees of freedom: 100 total; 98 residual&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&quot;three-or-more-means&quot; class=&quot;section level1&quot; readability=&quot;29.460461285008&quot;&gt;

&lt;p&gt;ANOVAs are linear models with (only) categorical predictors so they simply extend everything we did above, relying heavily on dummy coding. Do make sure to read &lt;a href=&quot;https://lindeloev.github.io/tests-as-linear/#dummy&quot;&gt;the section on dummy coding&lt;/a&gt; if you haven’t already.&lt;/p&gt;
&lt;div id=&quot;anova1&quot; class=&quot;section level2&quot; readability=&quot;48.821218074656&quot;&gt;
&lt;h2&gt; One-way ANOVA and Kruskal-Wallis&lt;/h2&gt;
&lt;div id=&quot;theory-as-linear-models-4&quot; class=&quot;section level3&quot; readability=&quot;65.7215815486&quot;&gt;
&lt;h3&gt; Theory: As linear models&lt;/h3&gt;
&lt;p&gt;Model: One mean for each group predicts &lt;span class=&quot;math inline&quot;&gt;\(y\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;math inline&quot;&gt;\(y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \beta_3 x_3 +... \qquad \mathcal{H}_0: y = \beta_1\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&quot;math inline&quot;&gt;\(x_i\)&lt;/span&gt; are indicators (&lt;span class=&quot;math inline&quot;&gt;\(x=0\)&lt;/span&gt; or &lt;span class=&quot;math inline&quot;&gt;\(x=1\)&lt;/span&gt;) where at most one &lt;span class=&quot;math inline&quot;&gt;\(x_i=1\)&lt;/span&gt; while all others are &lt;span class=&quot;math inline&quot;&gt;\(x_i=0\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Notice how this is just “more of the same” of what we already did in other models above. When there are only two groups, this model is &lt;span class=&quot;math inline&quot;&gt;\(y = \beta_0 + \beta_1*x\)&lt;/span&gt;, i.e. the &lt;a href=&quot;https://lindeloev.github.io/tests-as-linear/#t2&quot;&gt;independent t-test&lt;/a&gt;. If there is only one group, it is &lt;span class=&quot;math inline&quot;&gt;\(y = \beta_0\)&lt;/span&gt;, i.e. the &lt;a href=&quot;https://lindeloev.github.io/tests-as-linear/#t1&quot;&gt;one-sample t-test&lt;/a&gt;. This is easy to see in the visualization below - just cover up a few groups and see that it matches the other visualizations above, though I did omit adding green lines from the intercept (red) to the group means (blue) for visual clarity.&lt;/p&gt;
&lt;div class=&quot;fold s&quot; readability=&quot;66&quot;&gt;
&lt;pre class=&quot;r&quot;&gt;
&lt;code&gt;# Figure
N = 15
D_anova1 = data.frame(
  y=c(rnorm_fixed(N, 0.5, 0.3), 
      rnorm_fixed(N, 0, 0.3), 
      rnorm_fixed(N, 1, 0.3), 
      rnorm_fixed(N, 0.8, 0.3)), 
  x=rep(0:3, each=15)
)
ymeans = aggregate(y~x, D_anova1, mean)$y
P_anova1 = ggplot(D_anova1, aes(x=x, y=y)) + 
  stat_summary(fun.y=mean, geom = &quot;errorbar&quot;, aes(ymax = ..y.., ymin = ..y.., color='intercepts'), lwd=2) + 
  geom_segment(x=-10, xend=100, y=0.5, yend=0.5, lwd=2, aes(color='beta_0')) +
  geom_segment(x=0, xend=1, y=ymeans[1], yend=ymeans[2], lwd=2, aes(color='betas')) +
  geom_segment(x=1, xend=2, y=ymeans[1], yend=ymeans[3], lwd=2, aes(color='betas')) +
  geom_segment(x=2, xend=3, y=ymeans[1], yend=ymeans[4], lwd=2, aes(color='betas')) +
  
  scale_color_manual(
    name=NULL, values=c(&quot;blue&quot;, &quot;red&quot;, &quot;darkblue&quot;), 
    labels=c(
      bquote(beta[0]*&quot; (group 1 mean)&quot;), 
      bquote(beta[1]*&quot;, &quot;*beta[2]*&quot;,  etc. (slopes/differences to &quot;*beta[0]*&quot;)&quot;),
      bquote(beta[0]*&quot;+&quot;*beta[1]*&quot;, &quot;*beta[0]*&quot;+&quot;*beta[2]*&quot;, etc. (absolute intercepts)&quot;)
    )
  )
  

theme_axis(P_anova1, xlim=c(-0.5, 4), legend.position=c(0.7, 0.1))&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;img src=&quot;https://lindeloev.github.io/tests-as-linear/index_files/figure-html/unnamed-chunk-36-1.png&quot; width=&quot;576&quot;/&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;A one-way ANOVA has a log-linear counterpart called &lt;a href=&quot;https://lindeloev.github.io/tests-as-linear/#goodness&quot;&gt;goodness-of-fit&lt;/a&gt; test which we’ll return to. By the way, since we now regress on more than one &lt;span class=&quot;math inline&quot;&gt;\(x\)&lt;/span&gt;, the one-way ANOVA is a &lt;strong&gt;multiple regression&lt;/strong&gt; model.&lt;/p&gt;
&lt;p&gt;The &lt;strong&gt;Kruskal-Wallis&lt;/strong&gt; test is simply a &lt;strong&gt;one-way ANOVA&lt;/strong&gt; on the rank-transformed &lt;span class=&quot;math inline&quot;&gt;\(y\)&lt;/span&gt; (&lt;code&gt;value&lt;/code&gt;):&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;math inline&quot;&gt;\(rank(y) = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \beta_3 x_3 +...\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;This approximation is &lt;a href=&quot;https://lindeloev.github.io/tests-as-linear/simulate_kruskall.html&quot;&gt;good enough for 12 or more data points&lt;/a&gt;. Again, if you do this for just one or two groups, we’re already acquainted with those equations, i.e. the &lt;a href=&quot;https://lindeloev.github.io/tests-as-linear/#t1&quot;&gt;Wilcoxon signed-rank test&lt;/a&gt; or the &lt;a href=&quot;https://lindeloev.github.io/tests-as-linear/#t2&quot;&gt;Mann-Whitney U test&lt;/a&gt; respectively.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&quot;example-data&quot; class=&quot;section level3&quot; readability=&quot;38.359781121751&quot;&gt;
&lt;h3&gt; Example data&lt;/h3&gt;
&lt;p&gt;We make a three-level factor with the levels &lt;code&gt;a&lt;/code&gt;, &lt;code&gt;b&lt;/code&gt;, and &lt;code&gt;c&lt;/code&gt; so that the &lt;strong&gt;one-way ANOVA&lt;/strong&gt; basically becomes a “three-sample t-test”. Then we manually do the &lt;a href=&quot;https://lindeloev.github.io/tests-as-linear/#dummy&quot;&gt;dummy coding&lt;/a&gt; of the groups.&lt;/p&gt;
&lt;pre class=&quot;r&quot;&gt;
&lt;code&gt;# Three variables in &quot;long&quot; format
N = 20  # Number of samples per group
D = data.frame(
   value = c(rnorm_fixed(N, 0), rnorm_fixed(N, 1), rnorm_fixed(N, 0.5)), 
   group = rep(c('a', 'b', 'c'), each=N),
   
   # Explicitly add indicator/dummy variables
   # Could also be done using model.matrix(~D$group)
   group_a = rep(c(1, 0, 0), each=N),
   group_b = rep(c(0, 1, 0), each=N),
   group_c = rep(c(0, 0, 1), each=N))  # N of each level&lt;/code&gt;
&lt;/pre&gt;

&lt;p&gt;See? Exactly one parameter predicts a &lt;code&gt;value&lt;/code&gt; in a given row while the others are not included in the modeling of that &lt;code&gt;value&lt;/code&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&quot;r-code-one-way-anova&quot; class=&quot;section level3&quot; readability=&quot;23&quot;&gt;
&lt;h3&gt; R code: one-way ANOVA&lt;/h3&gt;
&lt;p&gt;OK, let’s see the identity between the built-in &lt;strong&gt;ANOVA&lt;/strong&gt; (&lt;code&gt;car::Anova&lt;/code&gt;) and the dummy-coded in-your-face linear model in &lt;code&gt;lm&lt;/code&gt;. Actually, &lt;code&gt;car::Anova&lt;/code&gt; and &lt;code&gt;aov&lt;/code&gt; are just wrappers around &lt;code&gt;lm&lt;/code&gt; so the identity comes as no surprise. The latter returns parameter estimates as well (bonus!), but we’ll just look at the overall model statistics for now. Note that I do not use the &lt;code&gt;aov&lt;/code&gt; function because it computes type-I sum of squares. There is a BIG polarized debate about whether to use type-II (as &lt;code&gt;car::Anova&lt;/code&gt; does by default) or type-III sum of squares, but let’s skip that for now.&lt;/p&gt;
&lt;pre class=&quot;r&quot;&gt;
&lt;code&gt;# Compare built-in and linear model
a = car::Anova(aov(value ~ group, D))  # Built-in ANOVA
b = lm(value ~ 1 + group_a + group_b + group_c, data=D)  # As in-your-face linear model&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;Results:&lt;/p&gt;

&lt;div class=&quot;fold o&quot; readability=&quot;13&quot;&gt;
&lt;pre&gt;
&lt;code&gt;## Anova Table (Type II tests)
## 
## Response: value
##           Sum Sq Df F value   Pr(&amp;gt;F)   
## group         10  2       5 0.009984 **
## Residuals     57 57                    
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Call:
## lm(formula = value ~ 1 + group_a + group_b + group_c, data = D)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -2.4402 -0.6427 -0.1393  0.8060  1.8574 
## 
## Coefficients: (1 not defined because of singularities)
##             Estimate Std. Error t value Pr(&amp;gt;|t|)  
## (Intercept)   0.5000     0.2236   2.236   0.0293 *
## group_a      -0.5000     0.3162  -1.581   0.1194  
## group_b       0.5000     0.3162   1.581   0.1194  
## group_c           NA         NA      NA       NA  
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 1 on 57 degrees of freedom
## Multiple R-squared:  0.1493, Adjusted R-squared:  0.1194 
## F-statistic:     5 on 2 and 57 DF,  p-value: 0.009984&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&quot;r-code-kruskal-wallis&quot; class=&quot;section level3&quot; readability=&quot;18&quot;&gt;
&lt;h3&gt; R code: Kruskal-Wallis&lt;/h3&gt;
&lt;pre class=&quot;r&quot;&gt;
&lt;code&gt;a = kruskal.test(value ~ group, D)  # Built-in
b = lm(rank(value) ~ 1 + group_a + group_b + group_c, D)  # As linear model
c = car::Anova(aov(rank(value) ~ group, D))  # Of course the same using the built-in ANOVA, which is just a wrapper around lm&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;Results:&lt;/p&gt;

&lt;div class=&quot;fold o&quot; readability=&quot;15&quot;&gt;
&lt;pre&gt;
&lt;code&gt;## 
##  Kruskal-Wallis rank sum test
## 
## data:  value by group
## Kruskal-Wallis chi-squared = 6.6777, df = 2, p-value = 0.03548
## 
## 
## Call:
## lm(formula = rank(value) ~ 1 + group_a + group_b + group_c, data = D)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -28.950 -12.213  -0.675  15.912  26.850 
## 
## Coefficients: (1 not defined because of singularities)
##             Estimate Std. Error t value Pr(&amp;gt;|t|)    
## (Intercept)   30.950      3.741   8.272 2.43e-11 ***
## group_a       -7.800      5.291  -1.474    0.146    
## group_b        6.450      5.291   1.219    0.228    
## group_c           NA         NA      NA       NA    
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 16.73 on 57 degrees of freedom
## Multiple R-squared:  0.1132, Adjusted R-squared:  0.08206 
## F-statistic: 3.637 on 2 and 57 DF,  p-value: 0.03261
## 
## Anova Table (Type II tests)
## 
## Response: rank(value)
##            Sum Sq Df F value  Pr(&amp;gt;F)  
## group      2036.7  2  3.6374 0.03261 *
## Residuals 15958.3 57                  
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&quot;anova2&quot; class=&quot;section level2&quot; readability=&quot;41.169226283048&quot;&gt;
&lt;h2&gt; Two-way ANOVA (plot in progress!)&lt;/h2&gt;
&lt;div id=&quot;theory-as-linear-models-5&quot; class=&quot;section level3&quot; readability=&quot;47.305957200694&quot;&gt;
&lt;h3&gt; Theory: As linear models&lt;/h3&gt;
&lt;p&gt;Model: one mean per group (main effects) plus these means multiplied across factors (interaction effects). The main effects are the &lt;a href=&quot;https://lindeloev.github.io/tests-as-linear/#anova1&quot;&gt;one-way ANOVA&lt;/a&gt;s above, though in the context of a larger model. The interaction effect is harder to explain in the abstract even though it’s just a few numbers multiplied with each other. I will leave that to the teachers to keep focus on equivalences here :-)&lt;/p&gt;
&lt;p&gt;Switching to matrix notation:&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;math inline&quot;&gt;\(y = \beta_0 + \beta_1 X_1 + \beta_2 X_2 + \beta_3 X_1 X_2 \qquad \mathcal{H}_0: \beta_3 = 0\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Here &lt;span class=&quot;math inline&quot;&gt;\(\beta_i\)&lt;/span&gt; are vectors of betas of which only one is selected by the indicator vector &lt;span class=&quot;math inline&quot;&gt;\(X_i\)&lt;/span&gt;. The &lt;span class=&quot;math inline&quot;&gt;\(\mathcal{H}_0\)&lt;/span&gt; shown here is the interaction effect. Note that the intercept &lt;span class=&quot;math inline&quot;&gt;\(\beta_0\)&lt;/span&gt;, to which all other &lt;span class=&quot;math inline&quot;&gt;\(\beta\)&lt;/span&gt;s are relative, is now the mean for the first level of all factors.&lt;/p&gt;
&lt;p&gt;Continuing with the dataset from the one-way ANOVA above, let’s add a crossing factor &lt;code&gt;mood&lt;/code&gt; so that we can test the &lt;code&gt;group:mood&lt;/code&gt; interaction (a 3x2 ANOVA). We also do the &lt;a href=&quot;https://lindeloev.github.io/tests-as-linear/#dummy&quot;&gt;dummy coding&lt;/a&gt; of this factor needed for the linear model.&lt;/p&gt;
&lt;pre class=&quot;r&quot;&gt;
&lt;code&gt;# Crossing factor
D$mood = c('happy', 'sad')

# Dummy coding
D$mood_happy = ifelse(D$mood == 'happy', 1, 0)  # 1 if mood==happy. 0 otherwise.
D$mood_sad = ifelse(D$mood == 'sad', 1, 0)  # Same, but we won't be needing this&lt;/code&gt;
&lt;/pre&gt;

&lt;p&gt;&lt;span class=&quot;math inline&quot;&gt;\(\beta_0\)&lt;/span&gt; is now the happy guys from group a!&lt;/p&gt;
&lt;div class=&quot;fold s&quot; readability=&quot;25&quot;&gt;
&lt;pre class=&quot;r&quot;&gt;
&lt;code&gt;# Add intercept line
# Add cross...
# Use other data?

means = lm(value ~ mood * group, D)$coefficients

P_anova2 = ggplot(D, aes(x=group, y=value, color=mood)) + 
  geom_segment(x=-10, xend=100, y=means[1], yend=0.5, col='blue', lwd=2) +
  stat_summary(fun.y=mean, geom = &quot;errorbar&quot;, aes(ymax = ..y.., ymin = ..y..),  lwd=2)
theme_axis(P_anova2, xlim=c(-0.5, 3.5)) + theme(axis.text.x = element_text())&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;img src=&quot;https://lindeloev.github.io/tests-as-linear/index_files/figure-html/unnamed-chunk-47-1.png&quot; width=&quot;576&quot;/&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&quot;r-code-two-way-anova&quot; class=&quot;section level3&quot; readability=&quot;52.749112426036&quot;&gt;
&lt;h3&gt; R code: Two-way ANOVA&lt;/h3&gt;
&lt;p&gt;Now let’s turn to the actual modeling in R. We compare the built-in ANOVA function to the linear model using &lt;code&gt;lm&lt;/code&gt;. Notice that in ANOVA, we are testing a full factor interaction all at once which involves many parameters (two in this case), so we can’t look at the overall model fit nor any particular parameter for the result. Therefore, I use a likelihood-ratio test to compare a full two-way ANOVA model (“saturated”) to one without the interaction effect(s). We do so using the &lt;code&gt;anova&lt;/code&gt; function. Even though that looks like cheating, it’s just computing likelihoods, p-values, etc. on the models that were already fitted, so it’s legit!&lt;/p&gt;
&lt;pre class=&quot;r&quot;&gt;
&lt;code&gt;# Built-in two-way ANOVA.
a = car::Anova(aov(value ~ mood * group, D), type='II')  # Normal notation. &quot;*&quot; both multiplies and adds main effects
b = car::Anova(aov(value ~ mood + group + mood:group, D))  # Identical but more verbose about main effects and interaction

# Testing the interaction terms as linear model.
full = lm(value ~ 1 + group_a + group_b + mood_happy + group_a:mood_happy + group_b:mood_happy, D)  # Full model
null = lm(value ~ 1 + group_a + group_b + mood_happy, D)  # Without interaction
c = anova(null, full)  # whoop whoop, same F, p, and Dfs&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;Results:&lt;/p&gt;

&lt;div class=&quot;fold o&quot; readability=&quot;10&quot;&gt;
&lt;pre&gt;
&lt;code&gt;## Anova Table (Type II tests)
## 
## Response: value
##            Sum Sq Df F value  Pr(&amp;gt;F)  
## mood        0.658  1  0.6314 0.43032  
## group      10.000  2  4.8003 0.01206 *
## mood:group  0.096  2  0.0459 0.95520  
## Residuals  56.247 54                  
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## Analysis of Variance Table
## 
## Model 1: value ~ 1 + group_a + group_b + mood_happy
## Model 2: value ~ 1 + group_a + group_b + mood_happy + group_a:mood_happy + 
##     group_b:mood_happy
##   Res.Df    RSS Df Sum of Sq      F Pr(&amp;gt;F)
## 1     56 56.342                           
## 2     54 56.247  2  0.095565 0.0459 0.9552&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Below, I present approximate main effect models, though exact calculation of ANOVA main effects &lt;a href=&quot;https://stats.idre.ucla.edu/stata/faq/how-can-i-get-anova-simple-main-effects-with-dummy-coding/&quot;&gt;is more involved&lt;/a&gt; if it is to be accurate and furthermore depend on whether type-II or type-III sum of squares are used for inference.&lt;/p&gt;
&lt;p&gt;Look at the model summary statistics to find values comparable to the &lt;code&gt;Anova&lt;/code&gt;-estimated main effects above.&lt;/p&gt;
&lt;pre class=&quot;r&quot;&gt;
&lt;code&gt;# Main effect of group.
e = lm(value ~ 1 + group_a + group_b, D)

# Main effect of mood.
f = lm(value ~ 1 + mood_happy, D)&lt;/code&gt;
&lt;/pre&gt;

&lt;div class=&quot;fold o&quot; readability=&quot;16&quot;&gt;
&lt;pre&gt;
&lt;code&gt;## 
## Call:
## lm(formula = value ~ 1 + group_a + group_b, data = D)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -2.4402 -0.6427 -0.1393  0.8060  1.8574 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&amp;gt;|t|)  
## (Intercept)   0.5000     0.2236   2.236   0.0293 *
## group_a      -0.5000     0.3162  -1.581   0.1194  
## group_b       0.5000     0.3162   1.581   0.1194  
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 1 on 57 degrees of freedom
## Multiple R-squared:  0.1493, Adjusted R-squared:  0.1194 
## F-statistic:     5 on 2 and 57 DF,  p-value: 0.009984
## 
## 
## Call:
## lm(formula = value ~ 1 + mood_happy, data = D)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -2.65275 -0.70847  0.00213  0.63391  1.88950 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&amp;gt;|t|)   
## (Intercept)   0.6047     0.1953   3.097  0.00301 **
## mood_happy   -0.2094     0.2761  -0.758  0.45136   
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 1.07 on 58 degrees of freedom
## Multiple R-squared:  0.009816,   Adjusted R-squared:  -0.007256 
## F-statistic: 0.575 on 1 and 58 DF,  p-value: 0.4514&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&quot;ancova&quot; class=&quot;section level2&quot; readability=&quot;53.614972393634&quot;&gt;
&lt;h2&gt; ANCOVA&lt;/h2&gt;
&lt;p&gt;This is simply ANOVA with a continuous regressor added so that it now contains continuous and (dummy-coded) categorical predictors. For example, if we continue with the &lt;a href=&quot;https://lindeloev.github.io/tests-as-linear/#anova1&quot;&gt;one-way ANOVA&lt;/a&gt; example, we can add &lt;code&gt;age&lt;/code&gt; and it is now called a &lt;strong&gt;one-way ANCOVA&lt;/strong&gt;:&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;math inline&quot;&gt;\(y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + ... + \beta_3 age\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;… where &lt;span class=&quot;math inline&quot;&gt;\(x_i\)&lt;/span&gt; are our usual dummy-coded indicator variables. &lt;span class=&quot;math inline&quot;&gt;\(\beta_0\)&lt;/span&gt; is now the mean for the first group at &lt;span class=&quot;math inline&quot;&gt;\(age=0\)&lt;/span&gt;. You can turn all ANOVAs into ANCOVAs this way, e.g. by adding &lt;span class=&quot;math inline&quot;&gt;\(\beta_N \cdot age\)&lt;/span&gt; to our &lt;strong&gt;two-way ANOVA&lt;/strong&gt; in the previous section. But let us go ahead with our one-way ANCOVA, starting by adding &lt;span class=&quot;math inline&quot;&gt;\(age\)&lt;/span&gt; to our dataset:&lt;/p&gt;
&lt;pre class=&quot;r&quot;&gt;
&lt;code&gt;# Update data with a continuous covariate
D$age = D$value + rnorm_fixed(nrow(D), sd=3)  # Correlated to value&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;This is best visualized using colors for groups instead of x-position. The &lt;span class=&quot;math inline&quot;&gt;\(\beta\)&lt;/span&gt;s are still the average &lt;span class=&quot;math inline&quot;&gt;\(y\)&lt;/span&gt;-offset of the data points, only now we model each group using a slope instead of an intercept. In other words, the one-way ANOVA is sort of &lt;a href=&quot;https://lindeloev.github.io/tests-as-linear/#t1&quot;&gt;one-sample t-tests&lt;/a&gt; model for each group (&lt;span class=&quot;math inline&quot;&gt;\(y = \beta_0\)&lt;/span&gt;) while the &lt;strong&gt;one-way ANCOVA&lt;/strong&gt; is sort of &lt;a href=&quot;https://lindeloev.github.io/tests-as-linear/#correlation&quot;&gt;Pearson correlation&lt;/a&gt; model for each group (&lt;span class=&quot;math inline&quot;&gt;\(y_i = \beta_0 + \beta_i + \beta_1 \cdot age\)&lt;/span&gt;):&lt;/p&gt;
&lt;div class=&quot;fold s&quot; readability=&quot;19&quot;&gt;
&lt;pre class=&quot;r&quot;&gt;
&lt;code&gt;# For linear model plot
D$pred = predict(lm(value ~ age + group, D))

# Plot
P_ancova = ggplot(D, aes(x=age, y=value, color=group, shape=group)) + 
  geom_line(aes(y=pred), lwd=2)

# Theme it
theme_axis(P_ancova, xlim=NULL, ylim=NULL, legend.position=c(0.8, 0.2)) + theme(axis.title=element_text())&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;img src=&quot;https://lindeloev.github.io/tests-as-linear/index_files/figure-html/unnamed-chunk-55-1.png&quot; width=&quot;576&quot;/&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;And now some R code to run the one-way ANCOVA as a linear model:&lt;/p&gt;
&lt;pre class=&quot;r&quot;&gt;
&lt;code&gt;# Built-in ANCOVA. The order of factors matter in pure-aov (type-I variance).
# Use type-II or type-III instead; implemented in car::Anova
a = car::Anova(aov(value ~ group + age, D))
#a = aov(value ~ group + age, D)  # Predictor order matters. Not nice!

# As dummy-coded linear model. 
full = lm(value ~ 1 + group_a + group_b + age, D)

# Testing main effect of age using Likelihood-ratio test
null_age = lm(value ~ 1 + group_a + group_b, D)  # Full without age. One-way ANOVA!
result_age = anova(null_age, full)

# Testing main effect of groupusing Likelihood-ratio test
null_group = lm(value ~ 1 + age, D)  # Full without group. Pearson correlation!
result_group = anova(null_group, full)&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;Results:&lt;/p&gt;

&lt;div class=&quot;fold o&quot; readability=&quot;10&quot;&gt;
&lt;pre&gt;
&lt;code&gt;## Anova Table (Type II tests)
## 
## Response: value
##           Sum Sq Df F value    Pr(&amp;gt;F)    
## group     10.118  2  6.4258 0.0030738 ** 
## age       12.910  1 16.3967 0.0001595 ***
## Residuals 44.090 56                      
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## Analysis of Variance Table
## 
## Model 1: value ~ 1 + group_a + group_b
## Model 2: value ~ 1 + group_a + group_b + age
##   Res.Df   RSS Df Sum of Sq      F    Pr(&amp;gt;F)    
## 1     57 57.00                                  
## 2     56 44.09  1     12.91 16.397 0.0001595 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## Analysis of Variance Table
## 
## Model 1: value ~ 1 + age
## Model 2: value ~ 1 + group_a + group_b + age
##   Res.Df    RSS Df Sum of Sq      F   Pr(&amp;gt;F)   
## 1     58 54.209                                
## 2     56 44.090  2    10.118 6.4258 0.003074 **
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&quot;proportions-chi-square-is-a-log-linear-model&quot; class=&quot;section level1&quot; readability=&quot;13.685546875&quot;&gt;

&lt;p&gt;Recall that when you take the logarithm, you can easily make statements about &lt;em&gt;proportions&lt;/em&gt;, i.e., that for every increase in &lt;span class=&quot;math inline&quot;&gt;\(x\)&lt;/span&gt;, &lt;span class=&quot;math inline&quot;&gt;\(y\)&lt;/span&gt; increases a certain percentage. This turns out to be one of the simplest (and therefore best!) ways to make count data and contingency tables intelligible. See &lt;a href=&quot;https://www.uni-tuebingen.de/fileadmin/Uni_Tuebingen/SFB/SFB_833/A_Bereich/A1/Christoph_Scheepers_-_Statistikworkshop.pdf&quot;&gt;this nice introduction&lt;/a&gt; to Chi-Square tests as linear models.&lt;/p&gt;
&lt;div id=&quot;goodness&quot; class=&quot;section level2&quot; readability=&quot;33.140794223827&quot;&gt;
&lt;h2&gt; Goodness of fit&lt;/h2&gt;
&lt;div id=&quot;theory-as-log-linear-model&quot; class=&quot;section level3&quot; readability=&quot;8.3076923076923&quot;&gt;
&lt;h3&gt; Theory: As log-linear model&lt;/h3&gt;
&lt;p&gt;Model: a single intercept predicts &lt;span class=&quot;math inline&quot;&gt;\(log(y)\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;I’ll refer you to take a look at &lt;a href=&quot;https://lindeloev.github.io/tests-as-linear/#contingency&quot;&gt;the section on contingency tables&lt;/a&gt; which is basically a “two-way goodness of fit”.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&quot;example-data-1&quot; class=&quot;section level3&quot; readability=&quot;21&quot;&gt;
&lt;h3&gt; Example data&lt;/h3&gt;
&lt;p&gt;For this, we need some wide count data:&lt;/p&gt;
&lt;pre class=&quot;r&quot;&gt;
&lt;code&gt;# Data in long format
D = data.frame(mood = c('happy', 'sad', 'meh'),
               counts = c(60, 90, 70))

# Dummy coding for the linear model
D$mood_happy = ifelse(D$mood == 'happy', 1, 0)
D$mood_sad = ifelse(D$mood == 'sad', 1, 0)&lt;/code&gt;
&lt;/pre&gt;

&lt;/div&gt;
&lt;div id=&quot;r-code-goodness-of-fit&quot; class=&quot;section level3&quot; readability=&quot;44.895436164067&quot;&gt;
&lt;h3&gt; R code: Goodness of fit&lt;/h3&gt;
&lt;p&gt;Now let’s see that the Goodness of fit is just a log-linear equivalent to a one-way ANOVA. We set &lt;code&gt;family = poisson()&lt;/code&gt; which defaults to setting a logarithmic &lt;a href=&quot;https://en.wikipedia.org/wiki/Generalized_linear_model#Link_function&quot;&gt;link function&lt;/a&gt; (&lt;code&gt;family = poisson(link='log')&lt;/code&gt;).&lt;/p&gt;
&lt;pre class=&quot;r&quot;&gt;
&lt;code&gt;# Built-in test
a = chisq.test(D$counts)

# As log-linear model, comparing to an intercept-only model
full = glm(counts ~ 1 + mood_happy + mood_sad, data=D, family=poisson())
null = glm(counts ~ 1, data=D, family=poisson())
b = anova(null, full, test='Rao')

# Note: glm can also do the dummy coding for you:
c = glm(counts ~ mood, data=D, family=poisson())&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;Let’s look at the results:&lt;/p&gt;

&lt;div class=&quot;fold o&quot; readability=&quot;12&quot;&gt;
&lt;pre&gt;
&lt;code&gt;## 
##  Chi-squared test for given probabilities
## 
## data:  D$counts
## X-squared = 6.3636, df = 2, p-value = 0.04151
## 
## Analysis of Deviance Table
## 
## Model 1: counts ~ 1
## Model 2: counts ~ 1 + mood_happy + mood_sad
##   Resid. Df Resid. Dev Df Deviance    Rao Pr(&amp;gt;Chi)  
## 1         2     6.2697                              
## 2         0     0.0000  2   6.2697 6.3636  0.04151 *
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Note the strange &lt;code&gt;anova(..., test='Rao')&lt;/code&gt; which merely states that p-values should be computed using the (Rao) &lt;a href=&quot;https://en.wikipedia.org/wiki/Score_test&quot;&gt;score test&lt;/a&gt;. We could also have jotted in &lt;code&gt;test='Chisq'&lt;/code&gt; or &lt;code&gt;test='LRT'&lt;/code&gt; which would have yielded approximate p-values. You may think that we’re cheating here, sneaking in some sort of Chi-Square model post-hoc. However, &lt;code&gt;anova&lt;/code&gt; only specifies how p-values are calculated whereas all the log-linear modeling happened in &lt;code&gt;glm&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;By the way, if there are only two counts and a large sample size (N &amp;gt; 100), this model begins to approximate the &lt;strong&gt;binomial test&lt;/strong&gt;, &lt;code&gt;binom.test&lt;/code&gt;, to a reasonable degree. But this sample size is larger than most use cases, so I won’t raise to a rule-of-thumb and won’t dig deeper into it here.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&quot;contingency&quot; class=&quot;section level2&quot; readability=&quot;53.953509244301&quot;&gt;
&lt;h2&gt; Contingency tables&lt;/h2&gt;
&lt;div id=&quot;theory-as-log-linear-model-1&quot; class=&quot;section level3&quot; readability=&quot;46.625325690464&quot;&gt;
&lt;h3&gt; Theory: As log-linear model&lt;/h3&gt;
&lt;p&gt;The theory here will be a bit more convoluted, and I mainly write it up so that you can get the &lt;em&gt;feeling&lt;/em&gt; that it really is just a log-linear &lt;a href=&quot;https://lindeloev.github.io/tests-as-linear/#anova2&quot;&gt;two-way ANOVA model&lt;/a&gt;. Let’s get started…&lt;/p&gt;
&lt;p&gt;For a two-way contingency table, the model of the count variable &lt;span class=&quot;math inline&quot;&gt;\(y\)&lt;/span&gt; is a modeled using the marginal proportions of a contingency table. Why this makes sense, is too involved to go into here, but &lt;a href=&quot;https://www.uni-tuebingen.de/fileadmin/Uni_Tuebingen/SFB/SFB_833/A_Bereich/A1/Christoph_Scheepers_-_Statistikworkshop.pdf&quot;&gt;see the relevant slides by Christoph Scheepers here&lt;/a&gt; for an excellent exposition. The model is composed of a lot of counts and the regression coefficients &lt;span class=&quot;math inline&quot;&gt;\(A_i\)&lt;/span&gt; and &lt;span class=&quot;math inline&quot;&gt;\(B_i\)&lt;/span&gt;:&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;math inline&quot;&gt;\(y_i = N \cdot x_i(A_i/N) \cdot z_j(B_j/N) \cdot x_{ij}/((A_i x_i)/(B_j z_j)/N)\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;What a mess!!! Here, &lt;span class=&quot;math inline&quot;&gt;\(i\)&lt;/span&gt; is the row index, &lt;span class=&quot;math inline&quot;&gt;\(j\)&lt;/span&gt; is the column index, &lt;span class=&quot;math inline&quot;&gt;\(x_{something}\)&lt;/span&gt; is the sum of that row and/or column, &lt;span class=&quot;math inline&quot;&gt;\(N = sum(y)\)&lt;/span&gt;. Remember that &lt;span class=&quot;math inline&quot;&gt;\(y\)&lt;/span&gt; is a count variable, so &lt;span class=&quot;math inline&quot;&gt;\(N\)&lt;/span&gt; is just the total count.&lt;/p&gt;
&lt;p&gt;We can simplify the notation by defining the &lt;em&gt;proportions&lt;/em&gt;: &lt;span class=&quot;math inline&quot;&gt;\(\alpha_i = x_i(A_i/N)\)&lt;/span&gt;, &lt;span class=&quot;math inline&quot;&gt;\(\beta_i = x_j(B_i/N)\)&lt;/span&gt; and &lt;span class=&quot;math inline&quot;&gt;\(\alpha_i\beta_j = x_{ij}/(A_i x_i)/(B_j z_j)/N\)&lt;/span&gt;. Let’s write the model again:&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;math inline&quot;&gt;\(y_i = N \cdot \alpha_i \cdot \beta_j \cdot \alpha_i\beta_j\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Ah, much prettier. However, there is still lot’s of multiplication which makes it hard to get an intuition about how the actual numbers interact. We can make it much more intelligible when we remember that &lt;span class=&quot;math inline&quot;&gt;\(log(A \cdot B) = log(A) + log(B)\)&lt;/span&gt;. Doing logarithms on both sides, we get:&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;math inline&quot;&gt;\(log(y_i) = log(N) + log(\alpha_i) + log(\beta_j) + log(\alpha_i\beta_j)\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Snuggly! Now we can get a better grasp on how the regression coefficients (which are proportions) independently contribute to &lt;span class=&quot;math inline&quot;&gt;\(y\)&lt;/span&gt;. This is why logarithms are so nice for proportions. Note that this is just &lt;a href=&quot;https://lindeloev.github.io/tests-as-linear/#anova2&quot;&gt;the two-way ANOVA model&lt;/a&gt; with some logarithms added, so we are back to our good old linear models - only the interpretation of the regression coefficients have changed! And we cannot use &lt;code&gt;lm&lt;/code&gt; anymore in R.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&quot;example-data-2&quot; class=&quot;section level3&quot; readability=&quot;36&quot;&gt;
&lt;h3&gt; Example data&lt;/h3&gt;
&lt;p&gt;Here we need some long data and we need it in table format for &lt;code&gt;chisq.test&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&quot;r&quot;&gt;
&lt;code&gt;# Contingency data in long format for linear model
D = data.frame(mood = c('happy', 'happy', 'meh', 'meh', 'sad', 'sad'),
               sex = c('male', 'female', 'male', 'female', 'male', 'female'),
               Freq = c(100, 70, 30, 32, 110, 120))

# ... and as table for chisq.test
D_table = D %&amp;gt;% 
  spread(key=mood, value=Freq) %&amp;gt;%  # Mood to columns
  select(-sex) %&amp;gt;%  # Remove sex column
  as.matrix()

# Dummy coding of D for linear model (skipping mood==&quot;sad&quot; and gender==&quot;female&quot;)
# We could also use model.matrix(D$Freq~D$mood*D$sex)
D$mood_happy = ifelse(D$mood == 'happy', 1, 0)
D$mood_meh = ifelse(D$mood == 'meh', 1, 0)
D$sex_male = ifelse(D$sex == 'male', 1, 0)&lt;/code&gt;
&lt;/pre&gt;

&lt;/div&gt;
&lt;div id=&quot;r-code-chi-square-test&quot; class=&quot;section level3&quot; readability=&quot;35.341081267218&quot;&gt;
&lt;h3&gt; R code: Chi-square test&lt;/h3&gt;
&lt;p&gt;Now let’s show the equivalence between a chi-square model and a log-linear model. This is very similar to our &lt;a href=&quot;https://lindeloev.github.io/tests-as-linear/#anova2&quot;&gt;two-way ANOVA&lt;/a&gt; above:&lt;/p&gt;
&lt;pre class=&quot;r&quot;&gt;
&lt;code&gt;# Built-in chi-square. It requires matrix format.
a = chisq.test(D_table)

# Using glm to do a log-linear model, we get identical results when testing the interaction term:
full = glm(Freq ~ 1 + mood_happy + mood_meh + sex_male + mood_happy*sex_male + mood_meh*sex_male, data=D, family=poisson())
null = glm(Freq ~ 1 + mood_happy + mood_meh + sex_male, data=D, family=poisson())
b = anova(null, full, test='Rao')  # Could also use test='LRT' or test='Chisq'

# Note: let glm do the dummy coding for you
full = glm(Freq ~ mood * sex, family=poisson(), data=D)
c = anova(full, test='Rao')

# Note: even simpler syntax using MASS:loglm (&quot;log-linear model&quot;)
d = MASS::loglm(Freq ~ mood + sex, D)&lt;/code&gt;
&lt;/pre&gt;

&lt;div class=&quot;fold o&quot; readability=&quot;16&quot;&gt;
&lt;pre&gt;
&lt;code&gt;## 
##  Pearson's Chi-squared test
## 
## data:  D_table
## X-squared = 5.0999, df = 2, p-value = 0.07809
## 
## Analysis of Deviance Table
## 
## Model 1: Freq ~ 1 + mood_happy + mood_meh + sex_male
## Model 2: Freq ~ 1 + mood_happy + mood_meh + sex_male + mood_happy * sex_male + 
##     mood_meh * sex_male
##   Resid. Df Resid. Dev Df Deviance    Rao Pr(&amp;gt;Chi)  
## 1         2     5.1199                              
## 2         0     0.0000  2   5.1199 5.0999  0.07809 .
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## Analysis of Deviance Table
## 
## Model: poisson, link: log
## 
## Response: Freq
## 
## Terms added sequentially (first to last)
## 
## 
##          Df Deviance Resid. Df Resid. Dev    Rao Pr(&amp;gt;Chi)    
## NULL                         5    111.130                    
## mood      2  105.308         3      5.821 94.132  &amp;lt; 2e-16 ***
## sex       1    0.701         2      5.120  0.701  0.40235    
## mood:sex  2    5.120         0      0.000  5.100  0.07809 .  
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## Call:
## MASS::loglm(formula = Freq ~ mood + sex, data = D)
## 
## Statistics:
##                       X^2 df   P(&amp;gt; X^2)
## Likelihood Ratio 5.119915  2 0.07730804
## Pearson          5.099859  2 0.07808717
## 
## Call:
## glm(formula = Freq ~ mood * sex, family = poisson(), data = D)
## 
## Deviance Residuals: 
## [1]  0  0  0  0  0  0
## 
## Coefficients:
##                 Estimate Std. Error z value Pr(&amp;gt;|z|)    
## (Intercept)       4.2485     0.1195  35.545  &amp;lt; 2e-16 ***
## moodmeh          -0.7828     0.2134  -3.668 0.000244 ***
## moodsad           0.5390     0.1504   3.584 0.000339 ***
## sexmale           0.3567     0.1558   2.289 0.022094 *  
## moodmeh:sexmale  -0.4212     0.2981  -1.413 0.157670    
## moodsad:sexmale  -0.4437     0.2042  -2.172 0.029819 *  
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## (Dispersion parameter for poisson family taken to be 1)
## 
##     Null deviance: 1.1113e+02  on 5  degrees of freedom
## Residual deviance: 3.9968e-15  on 0  degrees of freedom
## AIC: 48.254
## 
## Number of Fisher Scoring iterations: 3&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;If you unfold the raw R output, I’ve included &lt;code&gt;summary(full)&lt;/code&gt; so that you can see the raw regression coefficients. Being a log-linear model, these are the &lt;em&gt;percentage increase&lt;/em&gt;in &lt;span class=&quot;math inline&quot;&gt;\(y\)&lt;/span&gt; over and above the intercept if that category obtains.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&quot;links&quot; class=&quot;section level1&quot; readability=&quot;7.2&quot;&gt;

&lt;p&gt;Here are links to other sources who have exposed bits and pieces of this puzzle, including many further equivalences not covered here:&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&quot;course&quot; class=&quot;section level1&quot; readability=&quot;24.169701520556&quot;&gt;

&lt;p&gt;Most advanced stats books (and some intro-books) take the “everything is GLMM” approach as well. However, the “linear model” part often stay at the conceptual level. I wanted to make linear models the &lt;em&gt;tool&lt;/em&gt; in a really concise way. Luckily, more beginnier-friendly materials have emerged lately:&lt;/p&gt;
&lt;p&gt;Here are my own thoughts on what I’d do. I’ve done parts of this with great success already, but not the whole lot since I’m not assigned to do a full course yet.&lt;/p&gt;
&lt;p&gt;I would spend 50% of the time on linear modeling of data (bullet 1 below) since this contains 70% of what students need to know. The rest of the course is just fleshing out what happens if you have one group, two groups, etc.&lt;/p&gt;
&lt;p&gt;Note that whereas the understanding of sampling and hypothesis testing is usually the first focus of mainstream stats courses, it is saved for later here to make way for modeling.&lt;/p&gt;
&lt;ol readability=&quot;6.9374086702387&quot;&gt;&lt;li readability=&quot;-0.92611251049538&quot;&gt;
&lt;p&gt;&lt;strong&gt;Fundamentals of regression:&lt;/strong&gt;&lt;/p&gt;
&lt;ol readability=&quot;11.092003439381&quot;&gt;&lt;li readability=&quot;8.2130044843049&quot;&gt;
&lt;p&gt;Recall from high-school: &lt;span class=&quot;math inline&quot;&gt;\(y = a \cdot x + b\)&lt;/span&gt;, and getting a really good intuition about slopes and intercepts. Understanding that this can be written using all variable names, e.g., &lt;code&gt;money = profit * time + starting_money&lt;/code&gt; or &lt;span class=&quot;math inline&quot;&gt;\(y = \beta_1x + \beta_2*1\)&lt;/span&gt; or, suppressing the coefficients, as &lt;code&gt;y ~ x + 1&lt;/code&gt;. If the audience is receptive, convey the idea of these models &lt;a href=&quot;https://magesblog.com/post/modelling-change&quot;&gt;as a solution to differential equations&lt;/a&gt;, specifying how &lt;span class=&quot;math inline&quot;&gt;\(y\)&lt;/span&gt; &lt;em&gt;changes&lt;/em&gt; with &lt;span class=&quot;math inline&quot;&gt;\(x\)&lt;/span&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;1&quot;&gt;
&lt;p&gt;Extend to a few multiple regression as models. Make sure to include plenty of real-life examples and exercises at this point to make all of this really intuitive. Marvel at how briefly these models allow us to represent large datasets.&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;Introduce the idea of rank-transforming non-metric data and try it out.&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;2&quot;&gt;
&lt;p&gt;Teach the three assumptions: independence of data points, normality of residuals, and homoscedasticity.&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;1&quot;&gt;
&lt;p&gt;Confidence/credible intervals on the parameters. Stress that the Maximum-Likelihood estimate is extremely unlikely, so intervals are more important.&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;Briefly introduce &lt;span class=&quot;math inline&quot;&gt;\(R^2\)&lt;/span&gt; for the simple regression models above. Mention in passing that this is called &lt;a href=&quot;https://lindeloev.github.io/tests-as-linear/#correlation&quot;&gt;the Pearson and Spearman correlation coefficients&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;li readability=&quot;0.88608776844071&quot;&gt;
&lt;p&gt;&lt;strong&gt;Special case #1: One or two means (t-tests, Wilcoxon, Mann-Whitney):&lt;/strong&gt;&lt;/p&gt;
&lt;ol readability=&quot;7.0259481037924&quot;&gt;&lt;li readability=&quot;3.3220338983051&quot;&gt;
&lt;p&gt;*One mean:** When there is only one x-value, the regression model simplifies to &lt;span class=&quot;math inline&quot;&gt;\(y = b\)&lt;/span&gt;. If &lt;span class=&quot;math inline&quot;&gt;\(y\)&lt;/span&gt; is non-metric, you can rank-transform it. Apply the assumptions (homoscedasticity doesn’t apply since there is only one &lt;span class=&quot;math inline&quot;&gt;\(x\)&lt;/span&gt;). Mention in passing that these intercept-only models are called &lt;a href=&quot;https://lindeloev.github.io/tests-as-linear/#t1&quot;&gt;one-sample t-test and Wilcoxon Signed Rank test respectively&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;5.7556561085973&quot;&gt;
&lt;p&gt;&lt;strong&gt;Two means:&lt;/strong&gt; If we put two variables 1 apart on the x-axis, the difference between the means is the slope. Great! It is accessible to our swizz army knife called linear modeling. Apply the assumption checks to see that homoscedasticity reduces to equal variance between groups. This is called an &lt;a href=&quot;https://lindeloev.github.io/tests-as-linear/#t2&quot;&gt;independent t-test&lt;/a&gt;. Do a few worked examples and exercises, maybe adding Welch’s test, and do the rank-transformed version, called Mann-Whitney U.&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;2.3529411764706&quot;&gt;
&lt;p&gt;&lt;em&gt;Paired samples:&lt;/em&gt; Violates the independence assumption. After computing pairwise differences, this is equivalent to 2.1 (one intercept), though it is called the &lt;a href=&quot;https://lindeloev.github.io/tests-as-linear/#tpair&quot;&gt;paired t-test and Wilcoxon’s matched pairs&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;li readability=&quot;-0.89839572192513&quot;&gt;
&lt;p&gt;&lt;strong&gt;Special case #2: Three or more means (ANOVAs)&lt;/strong&gt;&lt;/p&gt;
&lt;ol readability=&quot;0.88414634146341&quot;&gt;&lt;li readability=&quot;0.95219123505976&quot;&gt;
&lt;p&gt;&lt;em&gt;&lt;a href=&quot;https://lindeloev.github.io/tests-as-linear/#dummy&quot;&gt;Dummy coding&lt;/a&gt; of categories:&lt;/em&gt; How one regression coefficient for each level of a factor models an intercept for each level when multiplied by a binary indicator. This is just extending what we did in 2.1. to make this data accessible to linear modeling.&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-0.64864864864865&quot;&gt;
&lt;p&gt;&lt;em&gt;Means of one variable:&lt;/em&gt; &lt;a href=&quot;https://lindeloev.github.io/tests-as-linear/#anova1&quot;&gt;One-way ANOVA&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-0.65789473684211&quot;&gt;
&lt;p&gt;&lt;em&gt;Means of two variables:&lt;/em&gt; &lt;a href=&quot;https://lindeloev.github.io/tests-as-linear/#anova2&quot;&gt;Two-way ANOVA&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;li readability=&quot;-0.90977443609023&quot;&gt;
&lt;p&gt;&lt;strong&gt;Special case #3: Three or more proportions (Chi-Square)&lt;/strong&gt;&lt;/p&gt;
&lt;ol readability=&quot;3.1551724137931&quot;&gt;&lt;li readability=&quot;5.6842105263158&quot;&gt;
&lt;p&gt;&lt;em&gt;Logarithmic transformation:&lt;/em&gt; Making multiplicative models linear using logarithms, thus modeling proportions. See &lt;a href=&quot;https://www.uni-tuebingen.de/fileadmin/Uni_Tuebingen/SFB/SFB_833/A_Bereich/A1/Christoph_Scheepers_-_Statistikworkshop.pdf&quot;&gt;this excellent introduction&lt;/a&gt; to the equivalence of log-linear models and Chi-Square tests as models of proportions. Also needs to introduce (log-)odds ratios. When the multiplicative model is made summative using logarithms, we just add the dummy-coding trick from 3.1, and see that the models are identical to the ANOVA models in 3.2 and 3.3, only the interpretation of the coefficients have changed.&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-0.66666666666667&quot;&gt;
&lt;p&gt;&lt;em&gt;Proportions of one variable:&lt;/em&gt; &lt;a href=&quot;https://lindeloev.github.io/tests-as-linear/#goodness&quot;&gt;Goodness of fit&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-0.63265306122449&quot;&gt;
&lt;p&gt;&lt;em&gt;Proportions of two variables:&lt;/em&gt; &lt;a href=&quot;https://lindeloev.github.io/tests-as-linear/#contingency&quot;&gt;Contingency tables&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;li readability=&quot;8&quot;&gt;
&lt;p&gt;&lt;strong&gt;Hypothesis testing:&lt;/strong&gt; Hypothesis testing is the act of choosing between a full model and one where a parameter is set to zero (effectively excluded from the model) instead of being estimated. For example, when set one of the two means in the t-test to be zero, we study how well the remaining mean explains all the data from both groups. If it does a good job, we prefer this model over the two-mean model because it is simpler. So hypothesis testing is just comparing linear models to make more qualitative statements than the truly quantitative statements which were covered in bullets 1-4 above. Therefore, hypothesis testing is less interesting and is mostly covered as an introduction to the general literature. Mention P-values (and misconceptions about them), Bayes Factors, and cross-validation.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;&lt;/div&gt;
&lt;div id=&quot;limitations&quot; class=&quot;section level1&quot; readability=&quot;6.6152671755725&quot;&gt;

&lt;p&gt;I have made a few simplifications for clarity:&lt;/p&gt;
&lt;ol readability=&quot;10.36690647482&quot;&gt;&lt;li readability=&quot;3&quot;&gt;
&lt;p&gt;I have not covered assumptions in the examples. This will be another post! But all assumptions of all tests come down to the usual three: a) independence of data points, b) normally distributed residuals, and c) homoscedasticity.&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;1&quot;&gt;
&lt;p&gt;I assume that all null hypotheses are the absence of an effect, but everything works the same for non-zero null hypotheses.&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;5.8318965517241&quot;&gt;
&lt;p&gt;I have not discussed inference. I am only including p-values in the comparisons as a crude way to show the equivalences between the underlying models since people care about p-values. Parameter estimates will show the same equivalence. How to do &lt;em&gt;inference&lt;/em&gt; is another matter. Personally, I’m a Bayesian, but going Bayesian here would render it less accessible to the wider audience. Also, doing &lt;a href=&quot;https://en.wikipedia.org/wiki/Robust_statistics&quot;&gt;robust models&lt;/a&gt; would be preferable, but fail to show the equivalence.&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;5.1805555555556&quot;&gt;
&lt;p&gt;Several named tests are still missing from the list and may be added at a later time. This includes the Sign test (require large N to be reasonably approximated by a linear model), Friedman as RM-ANOVA on &lt;code&gt;rank(y)&lt;/code&gt;, McNemar, and Binomial/Multinomial. See stuff on these in &lt;a href=&quot;https://lindeloev.github.io/tests-as-linear/#links&quot;&gt;the section on links to further equivalences&lt;/a&gt;. If you think that they should be included here, feel free to submit “solutions” to &lt;a href=&quot;https://github.com/lindeloev/tests-as-linear/&quot;&gt;the github repo&lt;/a&gt; of this doc!&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;&lt;/div&gt;
</description>
<pubDate>Thu, 28 Mar 2019 12:18:33 +0000</pubDate>
<dc:creator>homarp</dc:creator>
<dc:format>text/html</dc:format>
<dc:identifier>https://lindeloev.github.io/tests-as-linear/</dc:identifier>
</item>
</channel>
</rss>